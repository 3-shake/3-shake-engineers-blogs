<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="icon shortcut" type="image/png" href="https://blog.3-shake.com/logo.png" data-next-head=""/><title data-next-head="">Shu Kobuchi | 3-shake Engineers&#x27; Blogs</title><meta property="og:title" content="Shu Kobuchi" data-next-head=""/><meta property="og:url" content="https://blog.3-shake.com/members/kobuchi" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta property="og:site" content="3-shake Engineers&#x27; Blogs" data-next-head=""/><meta property="og:image" content="https://blog.3-shake.com/og.png" data-next-head=""/><link rel="canonical" href="https://blog.3-shake.com/members/kobuchi" data-next-head=""/><link rel="preload" href="/_next/static/css/683b82a315c74ead.css" as="style"/><link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;700&amp;family=Roboto:wght@300;400;500;700&amp;display=swap" rel="stylesheet"/><link rel="stylesheet" href="/_next/static/css/683b82a315c74ead.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-6ffd07a3317375c1.js" defer=""></script><script src="/_next/static/chunks/framework-de98b93a850cfc71.js" defer=""></script><script src="/_next/static/chunks/main-0e21001e2c71e4ad.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb27c9050fc0d186.js" defer=""></script><script src="/_next/static/chunks/736-d782d9dbb247c7cc.js" defer=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-505fa9f61659e527.js" defer=""></script><script src="/_next/static/rVplmCPTXat4Z1gtkOHXI/_buildManifest.js" defer=""></script><script src="/_next/static/rVplmCPTXat4Z1gtkOHXI/_ssgManifest.js" defer=""></script></head><body><link rel="preload" as="image" href="/logo.svg"/><link rel="preload" as="image" href="/avatars/kobuchi.jpeg"/><link rel="preload" as="image" href="/icons/twitter.svg"/><link rel="preload" as="image" href="/icons/github.svg"/><link rel="preload" as="image" href="https://www.google.com/s2/favicons?domain=speakerdeck.com"/><link rel="preload" as="image" href="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp"/><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.svg" alt="3-shake Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">3-shake<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a class="site-header__link" href="/feed.xml">RSS</a><a href="https://jobs-3-shake.com/" class="site-header__link">Recruit</a><a href="https://3-shake.com/" class="site-header__link">Company</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/kobuchi.jpeg" alt="Shu Kobuchi" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">Shu Kobuchi</h1><p class="member-header__bio">mammalian</p><div class="member-header__links"><a href="https://twitter.com/shu_kob" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@shu_kob" width="22" height="22"/></a><a href="https://github.com/shu-kob" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@shu-kob" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2026-01-23T05:00:00.000Z" class="post-link__date">20 days ago</time></div></a><a href="https://speakerdeck.com/shukob/google-clouddenodong-hua-jie-xi-tojian-suo-nosabisushao-jie-tobi-jiao" class="post-link__main-link"><h2 class="post-link__title">Google Cloudでの動画解析と検索のサービス紹介と比較</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-30T15:57:41.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2025/12/01/005741" class="post-link__main-link"><h2 class="post-link__title">学術的根拠から読み解くNotebookLMの音声活用法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-30T15:14:32.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2025/12/01/001432" class="post-link__main-link"><h2 class="post-link__title">MCP・A2A概要 〜Google Cloudで構築するなら〜</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-27T05:00:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://speakerdeck.com/shukob/mcpa2agai-yao-google-clouddegou-zhu-surunara" class="post-link__main-link"><h2 class="post-link__title">MCP・A2A概要 〜Google Cloudで構築するなら〜</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-25T05:00:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2" class="post-link__main-link"><h2 class="post-link__title">AIエージェントの自律性と協調性を解放する Google CloudによるMCP・A2A実装のエンタープライズ戦略</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-25T05:00:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made" class="post-link__main-link"><h2 class="post-link__title">AIエージェント入門 自律性の基礎からオープンプロトコルMCP・A2Aによる連携まで</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-11-22T05:00:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://speakerdeck.com/shukob/xue-shu-de-gen-ju-karadu-mijie-kunotebooklmnoyin-sheng-huo-yong-fa" class="post-link__main-link"><h2 class="post-link__title">学術的根拠から読み解くNotebookLMの音声活用法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-10-18T04:00:00.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade" class="post-link__main-link"><h2 class="post-link__title">AIエージェント入門 〜基礎からMCP・A2Aまで〜</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-09-05T09:52:02.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2025/09/05/185202" class="post-link__main-link"><h2 class="post-link__title">Gemini CLI AI駆動開発体験ハンズオン</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-08-07T04:00:00.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://speakerdeck.com/shukob/google-cloudsabisunosheng-cheng-aiguan-lian-sabisu" class="post-link__main-link"><h2 class="post-link__title">Google Cloudサービスの生成AI関連サービス</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-05-30T04:00:00.000Z" class="post-link__date">8 months ago</time></div></a><a href="https://speakerdeck.com/shukob/googlenoai-agent" class="post-link__main-link"><h2 class="post-link__title">GoogleのAI Agent</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-05-26T09:56:45.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2025/05/26/185645" class="post-link__main-link"><h2 class="post-link__title">RAGアプリ開発ハンズオン（後編：フロントエンド編）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-05-17T04:00:00.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang" class="post-link__main-link"><h2 class="post-link__title">React Tokyo LT大会「ストリームの実装」</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-05-16T04:00:00.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie" class="post-link__main-link"><h2 class="post-link__title">Google CloudのAI Agent関連のサービス紹介</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-04-28T09:56:21.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2025/04/28/185621" class="post-link__main-link"><h2 class="post-link__title">RAGアプリ開発ハンズオン（前編：バックエンド編）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-03-24T04:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents" class="post-link__main-link"><h2 class="post-link__title">論文紹介 ”A Survey on Large Language Model based Autonomous Agents”</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-02-28T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui" class="post-link__main-link"><h2 class="post-link__title">AIエージェント元年@日本生成AIユーザ会</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-02-22T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips" class="post-link__main-link"><h2 class="post-link__title">AI時代におけるMLOpsのTips</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-02-21T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/aiezientoyuan-nian" class="post-link__main-link"><h2 class="post-link__title">AIエージェント元年</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-01-28T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo" class="post-link__main-link"><h2 class="post-link__title">論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2025-01-21T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag" class="post-link__main-link"><h2 class="post-link__title">論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-12-20T05:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng" class="post-link__main-link"><h2 class="post-link__title">生成AIでGitHubソースコード取得して仕様書を作成</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-12-17T09:57:29.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/12/17/185729" class="post-link__main-link"><h2 class="post-link__title">プロンプトエンジニアリング プログラミング ハンズオン</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-12-03T14:28:56.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/12/03/232856" class="post-link__main-link"><h2 class="post-link__title">LLMのモデル更新や廃止による影響を考える</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-12-02T14:35:07.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/12/02/233507" class="post-link__main-link"><h2 class="post-link__title">Transformer論文を生成AIで要約してみた</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-12-01T14:22:29.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/12/01/232229" class="post-link__main-link"><h2 class="post-link__title">2025年の崖から考える我々のパーパス（序章）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-11-30T14:30:39.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/11/30/233039" class="post-link__main-link"><h2 class="post-link__title">Geminiのビジネス利用でのメリットを語る</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-11-19T08:24:52.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/11/19/172452" class="post-link__main-link"><h2 class="post-link__title">プロンプトエンジニアリングハンズオン</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-10-29T10:04:56.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/10/29/190456" class="post-link__main-link"><h2 class="post-link__title">WebサイトやGitHubソースコードを処理 (ハンズオン)</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-10-19T04:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e" class="post-link__main-link"><h2 class="post-link__title">生成AI入門</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-09-11T13:34:56.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/09/11/223456" class="post-link__main-link"><h2 class="post-link__title">AIを用いたOCR</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article><article class="post-link"><a class="post-link__author" href="/members/kobuchi"><img src="/avatars/kobuchi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">Shu Kobuchi</div><time dateTime="2024-09-10T14:56:54.000Z" class="post-link__date">a year ago</time></div></a><a href="https://shu-kob.hateblo.jp/entry/2024/09/10/235654" class="post-link__main-link"><h2 class="post-link__title">Apple Intelligence触ってみたい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=shu-kob.hateblo.jp" width="14" height="14" class="post-link__site-favicon"/>shu-kob.hateblo.jp</div></a></article></div><div class="post-list-load"><button class="post-list-load__button">LOAD MORE</button></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->3-shake Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"kobuchi","name":"Shu Kobuchi","role":"Software Developer","bio":"mammalian","avatarSrc":"/avatars/kobuchi.jpeg","sources":["https://shu-kob.hateblo.jp/feed","https://speakerdeck.com/shukob.rss"],"includeUrlRegex":"","twitterUsername":"shu_kob","githubUsername":"shu-kob","websiteUrl":""},"postItems":[{"title":"Google Cloudでの動画解析と検索のサービス紹介と比較","link":"https://speakerdeck.com/shukob/google-clouddenodong-hua-jie-xi-tojian-suo-nosabisushao-jie-tobi-jiao","contentSnippet":"https://genai-users.connpass.com/event/381737/\r\r日本生成AIユーザ会第20回勉強会\r\rGoogle Cloudでの動画解析と検索のサービス紹介と比較 〜Video Intelligence, Vision Warehouse, Gemini + Vertex AI Search〜\r動画コンテンツの爆発的な増加に伴い、「何が映っているか」を抽出するだけでなく、「特定のシーンをいかに高度に検索するか」というニーズが急増しています。本セッションでは、Google Cloud が提供する動画解析・検索ソリューションを網羅的に解説します。\r\r具体的には、長年の実績がある Video Intelligence API、大規模なメディア管理と画像・テキストによる横断検索を実現する Vision Warehouse、そしてマルチモーダル LLM Gemini と Vertex AI Search を組み合わせた動画 RAG アーキテクチャを紹介します。\r\r生成AIの進化により、従来のモデルでは困難だった「動画の文脈理解」や「自然言語による詳細なシーン特定」がどのように容易になったのか、デモを交えて解き明かします。各サービスのアーキテクチャやコスト、精度、ユースケースを徹底比較し、ビジネス課題に最適なサービス選定の指針を提示します。","isoDate":"2026-01-23T05:00:00.000Z","dateMiliSeconds":1769144400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/005741","contentSnippet":"この記事はQiita 3-shake Advent Calendar 2025 シリーズ1日目の記事です。2025年11月22日(土)に、Google Developer Group - DevFest Tokyo 2025があり、その招待制懇親会でLTをさせていただく機会がありました。「学術的根拠から読み解くNotebookLMの音声活用法」というタイトルで、NotebookLMの音声解説で学習する際のポイントを過去のマルチメディア学習の学術的根拠や実験を基にまとめました。 speakerdeck.com1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です2枚目2枚目は自己紹介です。3枚目Notebookでの音声を作る操作方法です。画面にドキュメントなどをアップロードし、音声解説ボタンを押すだけで簡単に作れます。音声は、男女掛け合いのPodcast形式です。4枚目仕事や学業で、難解なドキュメントを読む場面は多々あると思いますが、NotebookLMの音声解説機能により、学習効率が高められるか期待が高まっています。AIによって作られた音声がどれだけ学習効果があるか過去のマルチメディア学習の学術的根拠実験を基に解説していきます。5枚目学習効果を測定する実験も行いました。とある専門的なドキュメントを音声化して実験に用いました。被験者は熟達者（エキスパート）と初学者のグループに分かれます。熟達者、初学者でそれぞれ、音声の元となったドキュメントのみ読んで学習したグループ、音声のみ聴いて学習したグループ、両方を用いたグループに分かれ、学習後に4択の理解度チェックテストを受けてもらいました。GoogleスライドをPDF化して文字が崩れているので、直せるなら直しておきます。6枚目ドキュメント・音声の両方を用いたグループが優位に思えましたが、結果はご覧の通り。初学者は、実験を1回のみ行い、両方 \u003e 音声のみ \u003e ドキュメントのみ、という期待通りの結果でしたが、熟達者は、実験を3回行い、両方グループが最高点を取るとは限りませんでした。なぜ、熟達者は両方グループが優位とは限らなかったのでしょうか？7枚目初学者の説明です。初学者は音声学習を順書立てて勉強するのが有効です。構造的ガイダンスを提供することを足場かけ理論といいます。また、初学者の両方グループは音声を主、ドキュメントを従（文章を読むより、俯瞰的に見る）ことにより、認知負荷分散につながりました。8枚目一方の熟達者の説明です。熟達者は、初学者に有効な順序立てた構造的ガイダンスが邪魔になることがあります。熟達者の知識ネットワークに対して、手厚い構造的ガイダンスが知識をマッピングするのが非常に認知負荷が高いためです。これを熟達化のリバーサル効果といいます。また、熟達者の両方群は音声とドキュメント両方から情報を得ようと頑張り、認知負荷が高い状態でした。9枚目実験の制約により、不利な面もありました。実験の時間の都合上、音声の一時停止、巻き戻しを禁止していました。音声を一時停止、巻き戻して、自分のペースで聴けるなら、熟達者の両方グループは、音声とドキュメント両方からしっかり情報を取れていた可能性があります。学習者のペースを守らせることが効率を上げるのですが、例えば、音声や動画の学習をする際、数分ごとに区切って、学習者が「次へ」を押すことで次のパートが始まると学習がしやすいです。このことを「セグメンテーション原理」と呼ぶのですが、実験の制約上、阻害されたことになります。また、熟達者の実験の中で、音声のみグループの平均点が低いときがありました。それは、グラフ・図を見ていないと難しい問題が多く、音声でグラフ・図など視覚的な情報伝達が難しいことを意味します。また、各グループの点数のばらつきでは、ドキュメントのみグループが最も大きかったです。これは当然と言えば当然で、ドキュメント学習は各個人の学習能力に大きく左右されるためです。一方、音声は画一的な指導が可能とも言えます。10枚目実験や学術的根拠から読み解く、音声学習のおすすめとしては、学習者の習熟度を考慮し、初学者は音声とドキュメント両方を併用し、音声を主、ドキュメントを従とするのが良いでしょう。一方、熟達者は各個人で使い分けをするのがよく、概要把握や復習、思い出すなどの目的では音声、詳細や図表の把握はドキュメントを使うのがよく、安易に両方同時に使うと認知負荷を増大させるリスクがあります。11枚目参考文献です。一部、有料のものもありますが、Web検索等で概要を知ることもできます。12枚目終わりましたが、他の勉強会での登壇情報です。2025年11月27日(木)に、Jagu'e'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇した話は、ブログ記事にまとめていますので、よろしければご覧ください。shu-kob.hateblo.jp最後にqiita.com3-shake Advent Calendar 2025 シリーズ2の1日目はmasasuzuさんが書いてくれています。シリーズ1の2日目はyteraokaさんの「VPC Lattice を理解したい」シリーズ2の2日目はnwiizoさんの「生成AIエージェントによるブログレビュー環境の構築（上）」です。今後もお楽しみに！","isoDate":"2025-11-30T15:57:41.000Z","dateMiliSeconds":1764518261000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/001432","contentSnippet":"この記事はQiita Jagu'e'r Advent Calendar 2025の1日目の記事です。2025年11月27日(木)に、Jagu'e'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇させていただきましたので、その発表内容でのポイントを記事化したいと思います。AIエージェントが流行っているけど、MCPやA2Aという概念は難しいやろうと思い、噛み砕いて説明したいというのが発表のモチベーションでした。 speakerdeck.comなお、今回の資料は、NotebookLMで作成しました。ここまで作れるのはすごいです！1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です。2枚目2枚目は、アジェンダで、全体の話の流れを書いています。3枚目3枚目は、LLMの制約について述べています。LLMは「Brain in a Jar」（瓶の中の脳）とも言われ、賢いけど、手足を持たなくて実行能力のないものの例えです。例えば、学習時点までの知識しか知りません。これをナレッジカットオフといいます。「今日の株価」「明日の天気」「最新のニュース」などは分かりません。また、旅行のプランをLLMに尋ねても、航空券やホテルの予約はしてくれません。APIなどを操作し、データベースのトランザクション操作をする実行能力はないのです。4枚目ここで、LLMの制約を解決する手段として、MCPの話が出てくるのに加え、さらなる機能拡張のためにA2Aの話が出てきます。MCPはLLMに実行能力を与えます。A2Aはエージェント同士が連携し、より複雑なことができるようになる仕組みです。5枚目MCP(Model Context Protocol)は外部ツールやデータへのアクセスを標準化するプロトコルです。LLMという脳に手足を与えて、検索やAPI操作ができるようになり、APIを介してデータベースのトランザクション操作ができるようになるのです。ここでポイントは、推論機能と実行機能を分離して疎結合に実装するということです。6枚目A2A(Agent-to-Agent)は、AIエージェント同士で、連携するためのプロトコルです。能力を記述したAgent CardがAIエージェントの名刺となり、どのエージェントにどのタスクを任せるかの判断ができます。また、通信プロトコルが定められているため、拡張性に優れています。7枚目MCPとA2Aのご紹介をしましたが、Google CloudでMCPやA2Aをどう構築していくかのポイントに移りましょう。まず、認知（推論）機能と実行機能を分離することクラウドを利用する上で、サーバーレスファーストが大事であること（8枚目で詳説）誰も信頼せずとも動くゼロトラストセキュリティであることです。8枚目Google CloudでのMCPサーバー構築は、Cloud Runを使うのが定石です。サーバーレスでありコスト最適化できます。また、高いスケーラビリティに対応していて、コンテナベースで、デプロイが容易です。9枚目MCPサーバーをCloud Runで構築する際の注意点です。ローカル開発で使うようなstdio（Standard I/O）はCloud Runでは使用できないため、Streamable HTTPかSSE over HTTPを使う必要があります。最近では、新しいStreamable HTTPの方が推奨となっています。10枚目一方、A2A対応のエージェントの構築は、Vertex AI Agent Engineが最適です、フルマネージドサービスで、A2Aのプロトコルに準拠しており、Agent Registoryによるガバナンスも効いています。11枚目A2Aエージェントを構築するためのポイントです。スライドには文言が書いていませんが、ADK(Agent Development Kit)を用いた方法です。AgentCardの定義、使用するLLMやツールの定義、タスク処理のロジックを実装し、これらをA2Agentで統合し、A2A準拠のエージェントを作成できます。12枚目MCPとA2Aを連携させた構築例です。「Social Agent」というのは友人の好みを推論するエージェントです。外部連携、つまり実行部分はMCPを用いて、推論と実行の分離を行います。13枚目簡単にAIエージェントが開発できるようになると、企業内でみんな好き勝手にエージェントを作り始めて、野良エージェントが増えそうですが、Gemini Enterpriseによる一元管理でガバナンスを効かせられます。14枚目MCPもA2Aもオープンプロトコルであるため、拡張性に優れています。インターネットでもTCP/IPというオープンプロトコルのおかげで相互運用性があるように、AIエージェントもどんどん拡張していき、どんどん便利な世の中になるのかもしれません。最後にお読みいただきありがとうございました。2日目のQiita Jagu'e'r Advent Calendar 2025は、pHaya72さん「テクサミの宣伝」です。qiita.com空きもまだありますので、Jagu'e'r 会員の方はぜひ書きましょう！私もできれば、複数記事書きます！","isoDate":"2025-11-30T15:14:32.000Z","dateMiliSeconds":1764515672000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://speakerdeck.com/shukob/mcpa2agai-yao-google-clouddegou-zhu-surunara","contentSnippet":"「Jagu'e'r 月末 Tech Lunch Online#7 - Google Cloud を語る！-」にて、\rAIエージェントのMCPとA2Aの概要と、それらをGoogle Cloudで構築する上でのTipsを紹介させていただきました。\rhttps://jaguer-tech-lunch.connpass.com/event/362363/","isoDate":"2025-11-27T05:00:00.000Z","dateMiliSeconds":1764219600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェントの自律性と協調性を解放する Google CloudによるMCP・A2A実装のエンタープライズ戦略","link":"https://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの後半部分です。\rhttps://genai-users.connpass.com/event/376260/\r\r↓前半部分はこちらです\rhttps://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント入門 自律性の基礎からオープンプロトコルMCP・A2Aによる連携まで","link":"https://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの前半部分です。\rhttps://genai-users.connpass.com/event/376260/\r\r↓後半部分はこちらです\rhttps://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://speakerdeck.com/shukob/xue-shu-de-gen-ju-karadu-mijie-kunotebooklmnoyin-sheng-huo-yong-fa","contentSnippet":"2025年11月22日(土)に開催された「Google Developer Group - DevFest Tokyo 2025」の懇親会LTで発表させていただきました。\rhttps://gdg-tokyo.connpass.com/event/369416/\r\rNotebookLMで音声解説(Podcast)機能がありますが、初学者と上級者でドキュメントでの学習とどのように使い分けたら学習効率がいいかなどを、実験結果と複数の学術的根拠を元に解説しました。","isoDate":"2025-11-22T05:00:00.000Z","dateMiliSeconds":1763787600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント入門 〜基礎からMCP・A2Aまで〜","link":"https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade","contentSnippet":"https://genai-users.connpass.com/event/373059/\r2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。\r\r今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。","isoDate":"2025-10-18T04:00:00.000Z","dateMiliSeconds":1760760000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Gemini CLI AI駆動開発体験ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2025/09/05/185202","contentSnippet":"この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン🎯 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加🧠 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson \u0026\u0026 cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer((\"\", PORT), Handler) as httpd:    print(\"serving at port\", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、\u003e を使ってファイルに保存します。💻 実行するコマンド:gemini -p \"このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。\" -c  \u003e README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。💻 実行するコマンド:gemini -p \"このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。\" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると'Hello, Gemini!'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。💻 実行するコマンド:gemini -p \"現在のmain.pyを修正して、どのパスにアクセスしても 'Hello, Gemini!' というテキストを返すように変更してください。コード全体を提示してください。\" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header('Content-type', 'text/plain; charset=utf-8')        self.end_headers()        self.wfile.write('Hello, Gemini!'.encode('utf-8'))with socketserver.TCPServer((\"\", PORT), MyHandler) as httpd:    print(\"serving at port\", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。💻 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。💻 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに \"Hello, Gemini!\" と表示されれば、機能追加は成功です！","isoDate":"2025-09-05T09:52:02.000Z","dateMiliSeconds":1757065922000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudサービスの生成AI関連サービス","link":"https://speakerdeck.com/shukob/google-cloudsabisunosheng-cheng-aiguan-lian-sabisu","contentSnippet":"2025年8月7日(木)、日本生成AIユーザ会 で「Google Cloudサービスの生成AI関連サービス」について発表しました。\rhttps://genai-users.connpass.com/event/361798/","isoDate":"2025-08-07T04:00:00.000Z","dateMiliSeconds":1754539200000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"GoogleのAI Agent","link":"https://speakerdeck.com/shukob/googlenoai-agent","contentSnippet":"2025年5月30日(金) AI Agent 勉強会 Vol.3 にて、\rGoogle CloudのAI Agentサービスと\rGoogle I/O 2025 で発表された内容の概要を紹介させていただきました。\rhttps://almondo.connpass.com/event/355297/","isoDate":"2025-05-30T04:00:00.000Z","dateMiliSeconds":1748577600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"RAGアプリ開発ハンズオン（後編：フロントエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/05/26/185645","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\"gemini-2.0-flash-001\", location=\"us-west1\")    template = \"\"\"質問: {question}    ステップバイステップで考えてください。\"\"\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\"|\"を用いて簡単に実現    response = chain.invoke({\"question\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp↓@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\"gemini-2.0-flash-001\", location=\"us-west1\")    context_resp = retriever_service(question)    context = context_resp['search_result']    print(context)    template = \"\"\"質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    \"\"\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\"|\"を用いて簡単に実現    response = chain.invoke({\"question\": human_question, \"context\": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \"global\"    engine_id: str = 'DISCOVERY_ENGINE_ID'↓@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \"global\"    engine_id: str = os.environ['DISCOVERY_ENGINE_ID']動作確認QUESTION='{\"query\":\"情報セキュリティにおいて気をつけるべきことを教えてください\"}'curl -X POST -H \"Content-Type: application/json\" -d \"$QUESTION\" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob · Pull Request #4 · shu-kob/rag-app-handson · GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    \u003cmain className=\"flex items-center justify-center pt-16 pb-4\"\u003e      \u003cdiv className=\"flex-1 flex flex-col items-center gap-16 min-h-0\"\u003e        \u003cdiv\u003e          \u003cdiv\u003e            \u003clabel htmlFor=\"message\"\u003eメッセージ\u003c/label\u003e          \u003c/div\u003e          \u003cdiv\u003e            \u003ctextarea              id=\"message\"              rows={4}              cols={50}              style={{                padding: \"0.5rem\",                border: \"1px solid #ccc\",                outline: \"none\",                boxShadow: \"none\",              }}            /\u003e          \u003c/div\u003e          \u003cdiv\u003e            \u003cbutton              type=\"button\"              style={{                border: \"1px solid #ccc\",                padding: \"0.5rem 1rem\",              }}            \u003e              送信            \u003c/button\u003e          \u003c/div\u003e        \u003c/div\u003e      \u003c/div\u003e    \u003c/main\u003e  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from \"react\";export function Welcome() {  const [input, setInput] = useState(\"\");  const onSend = () =\u003e {    console.log(input)  }  return (    \u003cmain className=\"flex items-center justify-center pt-16 pb-4\"\u003e      \u003cdiv className=\"flex-1 flex flex-col items-center gap-16 min-h-0\"\u003e        \u003cdiv\u003e          \u003cdiv\u003e            \u003clabel htmlFor=\"message\"\u003eメッセージ\u003c/label\u003e          \u003c/div\u003e          \u003cdiv\u003e            \u003ctextarea              id=\"message\"              rows={4}              cols={50}              style={{                padding: \"0.5rem\",                border: \"1px solid #ccc\",                outline: \"none\",                boxShadow: \"none\",              }}              value={input}              onChange={(e) =\u003e setInput(e.target.value)}            /\u003e          \u003c/div\u003e          \u003cdiv\u003e            \u003cbutton              type=\"button\"              style={{                border: \"1px solid #ccc\",                padding: \"0.5rem 1rem\",              }}              onClick={onSend}            \u003e              送信            \u003c/button\u003e          \u003c/div\u003e        \u003c/div\u003e      \u003c/div\u003e    \u003c/main\u003e  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=[\"*\"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=[\"*\"],  # すべてのメソッドを許可    allow_headers=[\"*\"],  # すべてのヘッダーを許可    expose_headers=[\"*\"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () =\u003e {    fetch(\"http://localhost:8000/api/llm\", {      method: \"POST\",      headers: {        \"Content-Type\": \"application/json\",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob · Pull Request #6 · shu-kob/rag-app-handson · GitHub","isoDate":"2025-05-26T09:56:45.000Z","dateMiliSeconds":1748253405000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"React Tokyo LT大会「ストリームの実装」","link":"https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang","contentSnippet":"2025年5月17日React Tokyo LT大会にて、生成AIアプリケーションなどでよく使う「ストリーム実装」について話しました。\rhttps://react-tokyo.connpass.com/event/350715/","isoDate":"2025-05-17T04:00:00.000Z","dateMiliSeconds":1747454400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google CloudのAI Agent関連のサービス紹介","link":"https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie","contentSnippet":"https://3-shake.connpass.com/event/351861/\r3-shake SRE Tech Talk #12 にて、\rGoogle CloudのAI Agent関連のサービス紹介を行いました\r・Vertex AI Agent Builder\r・Agent Garden\r・Agent Engine\r・Vertex AI Search\r・Agentspace\rなど","isoDate":"2025-05-16T04:00:00.000Z","dateMiliSeconds":1747368000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"RAGアプリ開発ハンズオン（前編：バックエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/04/28/185621","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get('/')def index():  return 'hello'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post('/api/hello')def hello_service(user: User):    resp = { 'message': 'Hello, {}!'.format(user.name) }    return respUSER='{\"name\":\"平賀源内\"}'curl -X POST -H \"Content-Type: application/json\" -d \"$USER\" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post('/api/llm')def llm_service(question: Question):    prompt = question.query    vertexai.init(location=\"us-west1\") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel(\"gemini-2.0-flash-001\") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { 'answer': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION='{\"query\":\"プロンプトエンジニアリングとは何ですか？\"}'curl -X POST -H \"Content-Type: application/json\" -d \"$QUESTION\" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\"gemini-2.0-flash-001\", location=\"us-west1\")    template = \"\"\"質問: {question}    ステップバイステップで考えてください。\"\"\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\"|\"を用いて簡単に実現    response = chain.invoke({\"question\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記'DISCOVERY_ENGINE_ID'を書き換えます@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \"global\"    engine_id: str = 'DISCOVERY_ENGINE_ID' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -\u003e discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")            if location != \"global\"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble=\"文献の検索結果を要約してください\"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version=\"stable\",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { 'search_result': response.summary.summary_text }    print(resp)    return respQUESTION='{\"query\":\"情報セキュリティにおいて気をつけるべきことを教えてください\"}'curl -X POST -H \"Content-Type: application/json\" -d \"$QUESTION\" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。","isoDate":"2025-04-28T09:56:21.000Z","dateMiliSeconds":1745834181000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"論文紹介 ”A Survey on Large Language Model based Autonomous Agents”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents","contentSnippet":"https://genai-users.connpass.com/event/349197/\r\rこの論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。\r\r本論文を読むことで、AIエージェントの概要を体系的に知ることができます。","isoDate":"2025-03-24T04:00:00.000Z","dateMiliSeconds":1742788800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年@日本生成AIユーザ会","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui","contentSnippet":"https://genai-users.connpass.com/event/344332/\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\r\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\r\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-28T05:00:00.000Z","dateMiliSeconds":1740718800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AI時代におけるMLOpsのTips","link":"https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips","contentSnippet":"https://event.ospn.jp/osc2025-spring/session/2017030\rAI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜\rオープンソースカンファレンス2025 Tokyo/Spring\rライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。","isoDate":"2025-02-22T05:00:00.000Z","dateMiliSeconds":1740200400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian","contentSnippet":"https://genai-users.connpass.com/event/344292/\r\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\r\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\r\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo","contentSnippet":"https://gdg-tokyo.connpass.com/event/340671/\r\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\r\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-28T05:00:00.000Z","dateMiliSeconds":1738040400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag","contentSnippet":"https://genai-users.connpass.com/event/341391/\r\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\r\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-21T05:00:00.000Z","dateMiliSeconds":1737435600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AIでGitHubソースコード取得して仕様書を作成","link":"https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng","contentSnippet":"https://generative-ai-conf.connpass.com/event/335205/\r2024生成AI革命期を振り返る忘年会にて、\r「生成AIでGitHubソースコード取得して仕様書を作成する」というテーマでLTさせていただきました。","isoDate":"2024-12-20T05:00:00.000Z","dateMiliSeconds":1734670800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"プロンプトエンジニアリング プログラミング ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/12/17/185729","contentSnippet":"genai-users.connpass.comこの記事は上記勉強会の資料です。shu-kob.hateblo.jp↑上記記事を参考にサービスアカウントの設定をしてください。※ Google Cloudの無料期間が終了していると、課金されますが、ハンズオンの内容だけだと数百円もいかないと考えています。料金は確実には言えないので、Google Cloudはご自身の責任でご使用ください。github.com↑今回のサンプルコードgit clone https://github.com/shu-kob/prompt_engineeringcd prompt_engineeringpip install vertexaiLangChainを使わずVertex AIのライブラリを使用シンプルなVertex AIでGeminiを実行project_id = \"PROJECT_ID\" # 書き換える実行python3 generate_content.pyresponse = model.generate_content(  \"プロンプトエンジニアリングとは\")プロンプトを変更して実行してみましょう。Zero Shot プロンプティングproject_id = \"PROJECT_ID\" # 書き換える実行python3 zero_shot_prompting.pyprompt = \"\"\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開\"\"\"プロンプトを変更して実行してみましょう。Few Shot プロンプティングproject_id = \"PROJECT_ID\" # 書き換える実行python3 few_shot_prompting.pyprompt = \"\"\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」:政治「岡田将生\u0026高畑充希結婚 SNS反応」:芸能\"\"\"プロンプトを変更して実行してみましょう。LangChainを使用langchain_google_vertexai を使用pip install langchain_google_vertexaipython3 invoke.pymessages = [  (\"human\", \"ネコの鳴き真似をしてください。\"),]プロンプトを変更して実行してみましょう。PromptTemplateを使用pip install langchain_corepip install pydantic==2.9.0実行python3 prompt_template.pyプロンプトテンプレートやQuestionを変更して実行してみましょう。ChatPromptTemplateを使用実行python3 chat_prompt_template.pyprompt_template = ChatPromptTemplate.from_messages([    (\"system\", \"ステップバイステップで考えてください。\"),    (\"human\", \"{question}\"),])question = \"\"\"10 + 2 * 3 - 4 * 2\"\"\"システムプロンプトやQuestionを変更して実行してみましょう。参考資料python.langchain.compython.langchain.com参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門","isoDate":"2024-12-17T09:57:29.000Z","dateMiliSeconds":1734429449000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LLMのモデル更新や廃止による影響を考える","link":"https://shu-kob.hateblo.jp/entry/2024/12/03/232856","contentSnippet":"この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません · Issue #3 · harukaxq/langchain-book · GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。","isoDate":"2024-12-03T14:28:56.000Z","dateMiliSeconds":1733236136000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Transformer論文を生成AIで要約してみた","link":"https://shu-kob.hateblo.jp/entry/2024/12/02/233507","contentSnippet":"この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。","isoDate":"2024-12-02T14:35:07.000Z","dateMiliSeconds":1733150107000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年の崖から考える我々のパーパス（序章）","link":"https://shu-kob.hateblo.jp/entry/2024/12/01/232229","contentSnippet":"はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。","isoDate":"2024-12-01T14:22:29.000Z","dateMiliSeconds":1733062949000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Geminiのビジネス利用でのメリットを語る","link":"https://shu-kob.hateblo.jp/entry/2024/11/30/233039","contentSnippet":"この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。","isoDate":"2024-11-30T14:30:39.000Z","dateMiliSeconds":1732977039000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"プロンプトエンジニアリングハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/11/19/172452","contentSnippet":"genai-users.connpass.com↑上記勉強会の資料です。shu-kob.hateblo.jp↑こちらの記事の「プロンプトエンジニアリング」もご覧ください。（上記記事はChatGPT）先ずは復習してみましょうGeminiにアクセスgemini.google.comお好みで、ChatGPTやClaudeを使用しても構いません。プロンプトエンジニアリングJSON形式で出力カレーのレシピを教えてください。出力は以下のJSON形式にしてください。==============={  \"材料\": [\"材料1\", \"材料2\"],  \"手順\": [\"手順1\", \"手順2\"]}==============={  \"材料\": [    \"玉ねぎ 1個\",    \"にんじん 1本\",    \"じゃがいも 2個\",    \"牛肉 300g\",    \"カレールー 2箱\",    \"サラダ油 大さじ2\",    \"水 800ml\",    \"塩 少々\",    \"こしょう 少々\"  ],  \"手順\": [    \"玉ねぎ、にんじん、じゃがいもは食べやすい大きさに切る。\",    \"鍋にサラダ油を熱し、牛肉を炒め、色が変わったら玉ねぎを加えて炒める。\",    \"にんじん、じゃがいもを加えてさらに炒める。\",    \"水を加え、アクを取りながら煮込む。\",    \"野菜が柔らかくなったらカレールーを加えて溶かす。\",    \"塩こしょうで味を調え、5分ほど煮込む。\"  ]}出力結果をJSON Formatterで確認JSON Formatter \u0026 ValidatorZero-shotプロンプティングZero-Shotプロンプティングとは、大規模言語モデル（LLM）に対して、事前に具体的な例を示すことなく、一度の指示でタスクを実行させるプロンプトエンジニアリング手法です。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開芸能Few-shotプロンプティングFew-Shotプロンプティングは、大規模言語モデル（LLM）に対して、タスクを実行するための具体的な例をいくつか示すことで、モデルの性能を向上させるプロンプトエンジニアリングの手法です。Zero-Shotプロンプティングとの違いZero-Shotプロンプティングが、一切の例を示さずにタスクを実行させるのに対し、Few-Shotプロンプティングでは、少数の例を提示することで、モデルがより効率的にタスクを学習できるようにします。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」：政治「岡田将生\u0026高畑充希結婚 SNS反応」：芸能芸能Zero-shot Chain-of-ThoughtプロンプティングZero-shot Chain-of-Thought（CoT）プロンプティングは、大規模言語モデル（LLM）に対して、具体的な例を示すことなく、段階的な推論プロセスを踏ませるように指示するプロンプトエンジニアリングの手法です。回答だけ一言で出力してください。10 + 2 * 3 - 4 * 28ステップバイステップで考えてください。10 + 2 * 3 - 4 * 2## ステップバイステップで解いてみましょう！**与えられた式:** 10 + 2 * 3 - 4 * 2**解き方:**数学では、**掛け算と割り算**は、**足し算と引き算**よりも先に計算します。これを**優先順位**と言います。1.  **掛け算を計算する:**    * 2 * 3 = 6    * 4 * 2 = 8    式は、10 + 6 - 8 に変わります。2.  **残りの計算を行う:**    * 10 + 6 = 16    * 16 - 8 = 8**答え:** 8**まとめ:**与えられた式をステップバイステップで解くと、答えは**8**になります。**ポイント:*** **優先順位:** 掛け算と割り算は、足し算と引き算よりも先に計算します。* **計算順序:** 左から右へ計算していきます。**補足:**もし、計算の順番を変えたい場合は、**かっこ**を使います。例えば、(10 + 2) * 3 - 4 * 2 のようにかっこでくくると、最初に10と2を足してから3をかけることになります。**この説明で理解できましたか？** もし、まだ疑問な点があれば、遠慮なく質問してくださいね。Few-shot Chain-of-ThoughtプロンプティングFew-shot CoTプロンプティングは、大規模言語モデル（LLM）に、いくつかの例を示しながら、段階的な推論プロセスを踏ませることで、より複雑な問題を解かせる手法です。このグループの奇数を合計すると偶数になります。: 4、8、9、15、12、2、1。A: 奇数を全て加えると(9, 15, 1)25になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 17、10、19、4、8、12、24。A: 奇数を全て加えると(17, 19)36になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 16、11、14、4、8、13、24。A: 奇数を全て加えると(11, 13)24になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。A:参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門10倍速で成果が出る！ChatGPTスゴ技大全","isoDate":"2024-11-19T08:24:52.000Z","dateMiliSeconds":1732004692000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"WebサイトやGitHubソースコードを処理 (ハンズオン)","link":"https://shu-kob.hateblo.jp/entry/2024/10/29/190456","contentSnippet":"#7 WebサイトやGitHubソースコードを処理 (ハンズオン)【オンライン】 - connpassgenai-users.connpass.com勉強会の資料です。Google Cloudでクレデンシャルを取得IAMと管理 \u003e サービスアカウント↓こちらの記事を参考shu-kob.hateblo.jp環境変数にセット以下はMacで、.zprofileの場合export GOOGLE_APPLICATION_CREDENTIALS=\"/path/PROJECT_ID-XXXXXXXXXX.json\"source ~/.zprofileソースコードを取得github.comgit clone https://github.com/shu-kob/genai-web-github-loadercd genai-web-github-loadernpm iWebページを読んで要約loadWebPages.tsで、プロジェクトIDの書き換えconst project = 'PROJECT_ID' // 書き換える実行npx tsx loadWebPages.ts https://www.raumen.co.jp/rapedia/study_history/ソースコードの読み込んで仕様書を作成loadGitHubでプロジェクトIDの書き換えconst project = 'PROJECT_ID' // 書き換える実行npx tsx loadGitHub.ts https://github.com/shu-kob/genai-web-github-loader","isoDate":"2024-10-29T10:04:56.000Z","dateMiliSeconds":1730196296000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e","contentSnippet":"https://genai-users.connpass.com/event/333130/\rOSCオンラインで生成AIの基礎知識から、実際に活用できる技術まで、幅広く解説しました。\r\r生成AIとは何か、その仕組みを解説します。\r生成AIモデルを比較し、具体的なユースケースを紹介します。\rプロンプトエンジニアリング、RAG (Retrieval Augmented Generation)などの技術を説明します。\rオープンソースライブラリLangChainについてご紹介します。\r最後に生成AIが社会に与える影響や、今後の展望について考えます。","isoDate":"2024-10-19T04:00:00.000Z","dateMiliSeconds":1729310400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIを用いたOCR","link":"https://shu-kob.hateblo.jp/entry/2024/09/11/223456","contentSnippet":"OCRとは、Optical Character Recognitionの略で、日本語では光学文字認識といいます。OCRとは何か？OCRは、スキャンした書類や画像に含まれる文字を、コンピュータが読み取り、テキストデータに変換する技術です。つまり、紙に書かれた文字をデジタルの文字に変えて、パソコンで編集したり、検索したりできるようにするものです。OCRの仕組み画像の取り込み: スキャナーやデジタルカメラで、文字が書かれた紙の画像を撮影します。画像の前処理: 画像のノイズ除去や歪みの修正など、文字認識を円滑に行うための処理を行います。文字の切り出し: 画像から文字を一つずつ切り出します。文字の認識: 切り出した文字を、事前に登録された文字のパターンと照合し、どの文字か判定します。テキストデータへの変換: 認識された文字を、テキストデータに変換します。OCRの活用例書類のデジタル化: 紙の書類をスキャンしてテキストデータに変換することで、電子化し、保管や検索を効率化できます。データ入力の自動化: 請求書や領収書などの文字情報を自動的に読み込むことで、データ入力の手間を大幅に削減できます。検索の効率化: テキストデータに変換された文書は、キーワード検索が可能になり、必要な情報に素早くアクセスできます。翻訳: OCRでテキストデータに変換した後に、翻訳ソフトウェアを使って他の言語に翻訳することができます。OCRのメリット作業の効率化: 手作業でのデータ入力に比べて、大幅に作業時間を短縮できます。正確性の向上: 人による入力ミスを減らすことができ、データの正確性を高めます。コスト削減: 人件費の削減につながります。ペーパーレス化: 紙の書類を電子化することで、保管スペースを削減し、環境にも優しいです。OCRの種類OCRには、大きく分けて以下の2種類があります。OCRエンジン: ソフトウェア開発者が、OCR機能を自社のアプリケーションに組み込むために利用するソフトウェアです。OCRサービス: クラウド上で提供されるOCR機能で、APIなどを利用して簡単にOCR機能を導入できます。OCRの選び方OCRを選ぶ際には、以下の点に注意しましょう。認識精度: どの程度の精度で文字を認識できるか。対応言語: どの言語に対応しているか。対応フォント: どのフォントに対応しているか。対応ファイル形式: どのファイル形式に対応しているか。価格: 有料か無料か、料金体系はどうか。AIを用いたOCRcloud.google.comGoogle CloudなどパブリッククラウドでOCR機能が提供されています。Geminiで使用することもできます。OCRの活用の幅が広がり、工数削減に役立ちそうですね。まとめOCRは、紙の文書をデジタル化し、業務効率化に貢献する便利な技術です。様々な分野で活用されており、今後もその重要性はますます高まっていくでしょう。","isoDate":"2024-09-11T13:34:56.000Z","dateMiliSeconds":1726061696000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Apple Intelligence触ってみたい","link":"https://shu-kob.hateblo.jp/entry/2024/09/10/235654","contentSnippet":"k-tai.watch.impress.co.jpiPhone16で、Apple Intelligenceという名の生成AIが搭載されるようですね。Xなどではいまいち、盛り上がりに欠けているものの、生成AIを生業にするものとしては、触ってみたいです。Google PixelがGeminiを搭載したAIスマホとして売り出されていますが、iPhone・Apple Watch・Macユーザとしては、引き続きiPhoneですかね。Geminiは好きなので、Google Pixel欲しい気もしますがww","isoDate":"2024-09-10T14:56:54.000Z","dateMiliSeconds":1725980214000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AIにおけるベクトルインデックス","link":"https://shu-kob.hateblo.jp/entry/2024/09/06/234850","contentSnippet":"生成AIにおけるベクトルインデックス：詳細解説ベクトルインデックスとは？ベクトルインデックスは、生成AIにおいて、テキスト、画像、音声などの非構造化データを、数値のベクトルに変換し、そのベクトル間の類似度に基づいて検索や推薦を行うための技術です。なぜベクトルに変換するのか？意味の理解: 単語の並びだけでなく、単語間の関係性や文脈を数値として表現することで、コンピュータがより深くテキストの意味を理解できるようになります。高速な検索: 高次元空間上のベクトル間の距離を計算することで、従来のキーワード検索よりも高速かつ正確に類似したデータを検索できます。多様なデータの統合: テキストだけでなく、画像や音声などもベクトルに変換することで、異なる種類のデータを統一的に扱うことができます。ベクトルインデックスの仕組みベクトル化: テキストや画像などを、ニューラルネットワークなどのモデルを用いて数値のベクトルに変換します。インデックス作成: 変換されたベクトルを、効率的に検索できるようにインデックスを作成します。ベクトル検索: ユーザーのクエリをベクトル化し、作成されたインデックスから最も類似したベクトルを検索します。ベクトルインデックスの活用事例検索エンジン: キーワードだけでなく、文章の意味に基づいたより精度の高い検索を実現します。推薦システム: ユーザーの興味関心に基づいた商品やコンテンツを推薦します。チャットボット: ユーザーの質問に対して、より自然な回答を生成します。画像検索: 画像の内容に基づいた検索や、類似画像の検索を行います。ベクトルインデックスのメリット高精度な検索: キーワードマッチングだけでなく、意味に基づいた検索が可能になります。柔軟なデータ処理: テキストだけでなく、画像や音声など、様々な種類のデータを扱えます。スケーラビリティ: 大量のデータを効率的に処理できます。ベクトルインデックスの課題次元数の呪い: 高次元空間での計算コストが大きくなることがあります。モデルの選択: どのモデルを用いてベクトルに変換するかが、性能に大きく影響します。解釈の難しさ: ベクトル表現が抽象的であり、人間が直感的に理解することが難しい場合があります。今後の展望ベクトルインデックスは、生成AIのさらなる発展に不可欠な技術です。より大規模なデータセットへの対応、より高精度なベクトル化モデルの開発、そして、ベクトル表現の解釈に関する研究が進められていくことが期待されます。具体的な活用事例eコマース: ユーザーの過去の購入履歴や検索履歴に基づいた商品推薦カスタマーサポート: チャットボットによるFAQ検索や、ユーザーの問い合わせに対する自動応答医療: 医療論文の検索や、診断支援金融: リスク評価や不正検知まとめベクトルインデックスは、生成AIの性能を飛躍的に向上させるための重要な技術です。様々な分野での応用が期待されており、今後もその重要性はますます高まっていくでしょう。さらに詳しく知りたい場合は、以下のキーワードで検索してみてください。ベクトルデータベースベクトル検索自然言語処理機械学習ニューラルネットワーク何か他に聞きたいことがあれば、お気軽にご質問ください。より具体的な質問の例:特定のベクトルデータベースについて詳しく知りたいベクトルインデックスを構築する際の注意点ベクトルインデックスを生成AIの開発にどのように活用できるかこれらの質問に対して、より詳細な情報を提供できます。","isoDate":"2024-09-06T14:48:50.000Z","dateMiliSeconds":1725634130000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud Gemini向けの生成AIのプロンプトエンジニアリング","link":"https://shu-kob.hateblo.jp/entry/2024/09/05/235035","contentSnippet":"cloud.google.com生成AIのプロンプトエンジニアリングは様々な手法がありますが、Gemini for Google Cloudなんて出ているのですね。Google Cloud のプロダクトとサービスに関しては、Geminiは学習済のようで、詳しいようです。読んで勉強したいと思います。","isoDate":"2024-09-05T14:50:35.000Z","dateMiliSeconds":1725547835000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Mini-Omni OSSでSpeech-to-Speechができるようになる？","link":"https://shu-kob.hateblo.jp/entry/2024/09/04/233919","contentSnippet":"arxiv.orgGPT-4oの進化系で、リアルタイム音声会話のできる生成AIがOSSで出たようです。github.comその名もMini-Omni。小型モデルでどうリアルタイム音声会話を実現したのか興味深いですね。生成AIでリアルタイム音声会話は難しく、Speech-to-Text-to-Speechという変換手順を踏む必要があり、時間がかかっていたところ、リアルタイム、つまりSpeech-to-Speechで早く処理できるようになった、ということですね。ぜひ論文を読んでみたいと思います。以下、AbstractをGeminiで訳してみました。（OpenAIちゃうんかいw）言語モデルの進歩とMini-Omni言語モデルの最近の進歩は、大きな成果を上げています。GPT-4oは新たなマイルストーンとして、人間とのリアルタイム会話が可能となり、人間に近い自然な流暢さを示しています。このような人間とコンピュータのインタラクションを実現するには、音声モダリティで直接推論を行い、ストリーミングで出力生成できるモデルが必要となります。しかし、これは現在の学術的なモデルではまだ実現できていません。これらのモデルは通常、音声合成のために追加のTTSシステムに依存しており、望ましくない遅延が生じます。本論文では、リアルタイム音声インタラクションが可能なオーディオベースのエンドツーエンド会話モデルであるMini-Omniを紹介します。この機能を実現するために、テキスト指示による音声生成方法と、推論時のバッチ並列戦略を提案しています。この手法は、元のモデルの言語能力を最小限の劣化で保持するのに役立ち、他の研究がリアルタイムインタラクション機能を確立できるようにします。このトレーニング方法を「Any Model Can Talk」と呼んでいます。また、音声出力を最適化したモデルをファインチューニングするためのVoiceAssistant-400Kデータセットも紹介します。私たちの知る限り、Mini-Omniはリアルタイム音声インタラクションのための最初の完全なエンドツーエンド、オープンソースモデルであり、今後の研究に貴重な可能性を提供します。","isoDate":"2024-09-04T14:39:19.000Z","dateMiliSeconds":1725460759000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudの生成AIサンプルアプリEnterprise Knowledge Solution (EKS)","link":"https://shu-kob.hateblo.jp/entry/2024/09/03/235705","contentSnippet":"github.comGoogle Cloudの生成AIサンプルアプリ「Enterprise Knowledge Solution」 (EKS)がGitHubで公開されています。EKSはAmazon Elastic Kubernetes Serviceと紛らわしい（苦笑）「Enterprise Knowledge Solution」 はIAPとCloud RunベースでUI付きの生成AIアプリケーションをさっとデプロイできるようです。私はまだ試せていないですが、是非とも触ってみたいですね。terraformでデプロイできる模様。これは面白そう。コードも参考になりそうですね。","isoDate":"2024-09-03T14:57:05.000Z","dateMiliSeconds":1725375425000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChain Meetup Tokyo #2に登壇し、LangChainでWebサイトの内容取得やGitHubソースコード取得、というタイトルで発表しました","link":"https://shu-kob.hateblo.jp/entry/2024/09/02/224106","contentSnippet":"langchain.connpass.comLangChain Meetup Tokyo #2に登壇してきました。私は「LangChainでWebサイトの内容取得やGitHubソースコード取得」というタイトルで発表しました！次は @shu_kob によるLangChainでWebサイトの内容取得やGitHubソースコード取得👏 #LangChainJP pic.twitter.com/ryvFxqv6M1— こぎそ | Algomatic (@kgsi) 2024年9月2日   写真撮っていただけてました。ありがとうございます。ChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon「ChatGPT/LangChainによるチャットシステム構築［実践］入門」の著者、吉田 真吾さん、大嶋 勇樹さんにもお会いできました。お二人の会社、株式会社ジェネラティブエージェンツのCEO西見公宏さんにもお会いでき、コロッケそばさん、技術者としてステキ‼️ #langchainjp pic.twitter.com/N1GE4ArjJ0— 𝙎𝙝𝙞𝙣𝙜𝙤 吉田真吾 (@yoshidashingo) 2024年9月2日   65歳で登壇されたコロッケそばさんかっこよかったです！ speakerdeck.com↑私の資料はこちらにアップロードしています。様々な学びがあり、もっと生成AIを頑張ろう、と思えた刺激的なMeetupでした！","isoDate":"2024-09-02T13:41:06.000Z","dateMiliSeconds":1725284466000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでgithubリポジトリのソースコードを読む方法","link":"https://shu-kob.hateblo.jp/entry/2024/09/01/235529","contentSnippet":"shu-kob.hateblo.jp昨日の記事に関連して、今回はLangChainでgithubリポジトリのソースコードを読む方法です。github.com↑サンプルソースコードを載せています。js.langchain.com↑使い方はこちら実行例npx ts-node githubLoader.ts https://github.com/shu-kob/langchain-sample-codeDocument {  pageContent: \"import { CheerioWebBaseLoader } from '@langchain/community/document_loaders/web/cheerio'\\n\" +    \"import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters'\\n\" +    \"import { HtmlToTextTransformer } from '@langchain/community/document_transformers/html_to_text'\\n\" +    '\\n' +    'const url = process.argv[2]\\n' +    '\\n' +    'async function webLoad (url: string) {\\n' +    '  const loader = new CheerioWebBaseLoader(url)\\n' +    '  const docs = await loader.load()\\n' +    \"  const splitter = RecursiveCharacterTextSplitter.fromLanguage('html')\\n\" +    '  const transformer = new HtmlToTextTransformer()\\n' +    '  const sequence = splitter.pipe(transformer)\\n' +    '  const newDocuments = await sequence.invoke(docs)\\n' +    \"  console.log('newDocuments:')\\n\" +    '  console.log(newDocuments)\\n' +    '}\\n' +    '\\n' +    'webLoad(url)\\n',  metadata: {    source: 'cheerioWebBaseLoader.ts',    repository: 'https://github.com/shu-kob/langchain-sample-code',    branch: 'main'  },  id: undefined}Document {  pageContent: \"import { GithubRepoLoader } from '@langchain/community/document_loaders/web/github'\\n\" +    '\\n' +    'const url = process.argv[2]\\n' +    '\\n' +    'async function readSorceCodesFromGithub(url: string) {\\n' +    '\\n' +    '  const loader = new GithubRepoLoader(\\n' +    '    url,\\n' +    '    {\\n' +    '      branch: \"main\", // Defaultブランチが \"master\" でないか注意。他のブランチも選択可能\\n' +    '      recursive: true,\\n' +    '      processSubmodules: true,\\n' +    '      unknown: \"warn\",\\n' +    '      maxConcurrency: 5, // Defaults to 2\\n' +    '      ignorePaths: [\"*.json\", \"*.yaml\", \"*.yml\", \"*config*\", \"*.md\", \"Dockerfile\", \"*ignore\", \".eslintrc.js\", \"*.svg\"] // 除外するファイルパス\\n' +    '    }\\n' +    '  );\\n' +    '\\n' +    '  for await (const doc of loader.loadAsStream()) {\\n' +    '    console.log(doc)\\n' +    '  }\\n' +    '};\\n' +    '\\n' +    'readSorceCodesFromGithub(url)\\n',  metadata: {    source: 'githubLoader.ts',    repository: 'https://github.com/shu-kob/langchain-sample-code',    branch: 'main'  },  id: undefined}Document {  pageContent: \"import * as cheerio from 'cheerio'\\n\" +    '\\n' +    'const url = process.argv[2]\\n' +    '\\n' +    'async function webLoad (url: string) {\\n' +    '  // HTMLの取得\\n' +    '  const response = await fetch(url)\\n' +    '  const htmlText = await response.text()\\n' +    '  const cheerioText = cheerio.load(htmlText)\\n' +    '\\n' +    '  // styleとscriptを除去\\n' +    \"  cheerioText('style').remove()\\n\" +    \"  cheerioText('script').remove()\\n\" +    '\\n' +    \"  const bodyContent: string = cheerioText('body').text().replace(/\\\\s+/g, '')\\n\" +    '\\n' +    \"  console.log('bodyContent:')\\n\" +    '  console.log(bodyContent)\\n' +    '  return bodyContent\\n' +    '}\\n' +    '\\n' +    'webLoad(url)\\n',  metadata: {    source: 'webLoad.ts',    repository: 'https://github.com/shu-kob/langchain-sample-code',    branch: 'main'  },  id: undefined}これらのソースコードをプロンプトに含めて、生成AIに投げます。例えば、GitHubリポジトリの仕様を聞くなどです。多くの場合、ソースコードの文量は多くなり、それなりのトークン数になるので、200万トークン対応のGemini-1.5などを使うのが良いでしょう。","isoDate":"2024-09-01T14:55:29.000Z","dateMiliSeconds":1725202529000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでURLからWebページの中身を読み込む方法","link":"https://shu-kob.hateblo.jp/entry/2024/08/31/223416","contentSnippet":"langchain.connpass.com今度、Langchain Meetup Tokyoで喋るので、「LangChainでURLからWebページの中身を読み込む方法」を準備中github.com↑ソースコードを上げておきました。npx ts-node cheerioWebBaseLoader.ts https://shu-kob.hateblo.jp/entry/2024/08/29/234143という形で実行し、以下の結果が得られます。newDocuments:[  Document {    pageContent: 'Toilを無くして徒然なるままに日暮し硯に向かひたい 読者になる Toilを無くして徒然なるままに日暮し硯に向かひたい\\n' +      '生成AIアプリケーション開発などを行うエンジニアのブログです。 2024-08-29 オライリーのAWS生成AI本 AWSではじめる生成AI\\n' +      '―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje\\n' +      'Barth,Shelbee EigenbrodeオライリージャパンAmazon そういや、オライリージャパンからAWSの生成AI本出てますね。\\n' +      '欲しいと思いながらも買うてない。 現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、\\n' +      '面白そうなら買うてみるしか！ 翻訳はAWS Japanの久富木 隆一さん。 AWSの中の人が翻訳しているので確かでしょうね！ shu-kob\\n' +      '2024-08-29 23:41 読者になる',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: 'shu-kob 2024-08-29 23:41 読者になる 広告を非表示にする 関連記事 2024-08-04 日本生成AIユーザ会\\n' +      'Geminiマルチモーダルプログラミング（ハンズオン）を2024年8月13日(… genai-users.connpass.com\\n' +      'このブログで何回か書いておりますが… 2024-07-20 Google Gemini 1.5／LlamaIndex／LangChain\\n' +      '人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5 に対応した技…',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: '1.5／LlamaIndex／LangChain 人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5\\n' +      'に対応した技… 2024-06-07 Google Cloud Vertex AI Agent Builderの使い方\\n' +      'RAG(Retrieval-Augmented Generation) RAG（Retrieval Augmente… 2024-04-05\\n' +      '生成AIアプリケーション開発入門ハンズオン genai-users.connpass.com この記事は、日本生成AIユーザ会 #1 … 2023-12-17\\n' +      '生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: '生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\\n' +      'コメントを書く « SRETT#10 ~ 夏のSRE祭り！アーカイブ動画… 「SREをはじめよう」(Becoming SRE邦訳)が… » プロフィール\\n' +      'id:shu-kob 読者です 読者をやめる 読者になる 読者になる このブログについて 検索 リンク はてなブログ ブログをはじめる',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: 'このブログについて 検索 リンク はてなブログ ブログをはじめる 週刊はてなブログ はてなブログPro 最新記事 SRETT#10 ~\\n' +      '夏のSRE祭り！アーカイブ動画公開！ オライリーのAWS生成AI本 「SREをはじめよう」(Becoming SRE邦訳)が出版 Google Cloud\\n' +      'エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: 'Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\\n' +      '後継者不足のCOBOLを生成AIに引き継ぎ 月別アーカイブ ▼ ▶ 2024 2024 / 8 2024 / 7 2024 / 6 2024 / 5',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: '2024 / 6 2024 / 5 2024 / 4 2024 / 3 2024 / 2 ▼ ▶ 2023 2023 / 12',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: '2023 / 12 はてなブログをはじめよう！ shu-kobさんは、はてなブログを使っています。あなたもはてなブログをはじめてみませんか？\\n' +      'はてなブログをはじめる（無料） はてなブログとは Toilを無くして徒然なるままに日暮し硯に向かひたい Powered by Hatena Blog |\\n' +      \"ブログを報告する if (typeof window.Hatena === 'undefined') { window.Hatena = {}; } if\\n\" +      \"(!Hatena.hasOwnProperty('Star')) { Hatena.Star = { VERSION: 2, }; } (function(d,\\n\" +      's, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id))\\n' +      'return; js = d.createElement(s); js.id = id; js.src =',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  },  Document {    pageContent: 'VERSION: 2, }; } (function(d, s, id) { var js, fjs =\\n' +      'd.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js =\\n' +      'd.createElement(s); js.id = id; js.src =\\n' +      '\"//connect.facebook.net/ja_JP/sdk.js#xfbml=1\u0026appId=719729204785177\u0026version=v17.0\";\\n' +      \"fjs.parentNode.insertBefore(js, fjs); }(document, 'script', 'facebook-jssdk'));\\n\" +      '引用をストックしました ストック一覧を見る 閉じる 引用するにはまずログインしてください ログイン 閉じる 引用をストックできませんでした。再度お試しください\\n' +      '閉じる 限定公開記事のため引用できません。\\n' +      '\\n' +      '読者です 読者をやめる 読者になる 読者になる Hatena.Diary.GlobalHeader.init()',    metadata: {      source: 'https://shu-kob.hateblo.jp/entry/2024/08/29/234143',      loc: [Object]    },    id: undefined  }]npx  ts-node cheerioWebBaseLoader.ts https://www.gyomusuper.jp/ただし、例えば業務スーパーのホームページを読んだ際、余計なコードが多い。newDocuments:[  Document {    pageContent: \"$(function() { $('.sale_bnr_close').on('click', function() {\\n\" +      \"$('.sale_bnr').css('display', 'none'); }); }); /*onlineshopメニュー*/ .menu_ec:hover\\n\" +      '{ background:url(\"./img/menu_ec_on.png\") no-repeat left center #FFF; transition:\\n' +      'all .5s; } /*Gyomucaメニュー*/ .menu_gyomuca { display: inline-block; width: 260px;\\n' +      'height: 44px; text-align: center; text-decoration: none; line-height: 44px;\\n' +      'outline: none; background:url(\"./img/menu_gyomuca.png\") no-repeat left center;\\n' +      'text-indent:100%; white-space:nowrap; overflow:hidden; } .menu_gyomuca:hover {\\n' +      'background:url(\"./img/menu_gyomuca_on.png\") no-repeat left center #FFF;\\n' +      'transition: all .5s; } /*ここまで*/ .menu_gyomuca_on\\n' +      '{background:url(\"./img/menu_gyomuca_on.png\") no-repeat left center\\n' +      '#FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\n' +      'inline-block;width: 260px;height: 44px;line-height: 44px;}',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'left center #FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\n' +      'inline-block;width: 260px;height: 44px;line-height: 44px;}\\n' +      'お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針 ホーム 商品紹介 ミラクルレシピ 特集一覧 安心安全の取り組み\\n' +      '業務スーパーとは Gyomuca お問い合わせ オンラインショップ FC加盟店募集 会社案内 日本語 / ENGLISH / 中文 .fc_com_link {\\n' +      'display: flex; margin-left: 40px; margin-top: 5px; } #side_menu ul.fc_com_link\\n' +      'li { width: auto; height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) {\\n' +      'margin-right: 10px; } #side_menu ul.fc_com_link li a { position: relative;',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) { margin-right:\\n' +      '10px; } #side_menu ul.fc_com_link li a { position: relative; font-size: 12px;\\n' +      'color: #fff; font-weight: bold; text-shadow: 0px 0px 0.1px #fff; letter-spacing:\\n' +      '1px; padding:5px; } #side_menu ul.fc_com_link li a span { content: \"\"; display:\\n' +      'inline-block; width: 0; height: 0; border-style: solid; border-width: 5px 0 5px\\n' +      '8.7px; border-color: transparent transparent transparent #ffffff; padding-right:\\n' +      '8px; } #side_menu ul.fc_com_link li a:hover { background-color: #fff; color:\\n' +      '#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\n' +      'li a:hover span { border-color: transparent transparent transparent',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\n' +      'li a:hover span { border-color: transparent transparent transparent #00a55a;\\n' +      'transition: all .5s; } /*FCページの時*/ #side_menu ul.fc_com_link li a.menu_fc2_on {\\n' +      'background-color: #fff; color: #00a55a; text-decoration: none; text-shadow: 0px\\n' +      '0px 0.1px #00a55a; } #side_menu ul.fc_com_link li a.menu_fc2_on span {\\n' +      'border-color: transparent transparent transparent #00a55a; } /*ここまで*/ .lang_box\\n' +      '{ margin-left: 42px; display: flex; } .lang_box span:nth-child(n + 2) {\\n' +      'margin-left: 8px; } .social_box { margin-left: 38px; display: flex; margin-top:\\n' +      '20px; padding-left: 5px; } .social_box p img { width: 100%; } .social_box',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '{ margin-left: 38px; display: flex; margin-top: 20px; padding-left: 5px; }\\n' +      '.social_box p img { width: 100%; } .social_box p:nth-of-type(1) { margin-right:\\n' +      '18px; } .social_box p { width: 35px; } @media screen and (min-width: 1024px) {\\n' +      '#side_menu .social_box { padding-bottom: 80px; } } // 指定日時を超えたらセールスライド・バナー非表示\\n' +      \"var now = new Date(); var end = new Date('2024/10/31 23:59:59');\\n\" +      \"//（指定日時　時間は24h表記） if ( now \u003e end ) { $('.sale_slide_top').remove();\\n\" +      \"$('.sale_bnr').remove(); }else{ // 保持時間を設定 30分後を取得 var min = new Date();\\n\" +      'min.setTime( min.getTime() + ( 30 * 60 * 1000 )); console.log(min);\\n' +      `$('.sale_bnr').css('display','block'); $.cookie(\"sale_bnr\") ==`,    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'var min = new Date(); min.setTime( min.getTime() + ( 30 * 60 * 1000 ));\\n' +      `console.log(min); $('.sale_bnr').css('display','block'); $.cookie(\"sale_bnr\") ==\\n` +      `'on'?$('.sale_bnr').hide():$('.sale_bnr').show(); $.cookie(\"sale_bnr\",'on',{\\n` +      \"expires: min , path: '/' }); } // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date();\\n\" +      \"var end = new Date('2024/8/31 23:59:59'); //（指定日時　時間は24h表記） if ( now \u003e end ) {\\n\" +      \"$('.sale_bnr_img img').attr('src','img/main_sale20240901.png'); }\\n\" +      \"$(window).on('load', function(){ $('#bakudan').attr('data-lightbox','info01');\\n\" +      '}); // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new\\n' +      \"Date('2024/8/31 23:59:59'); //（指定日時　時間は24h表記） if ( now \u003e end ) {\\n\" +      \"$('.bakudan_slide').remove(); $('.sale_alide\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new Date('2024/8/31\\n\" +      \"23:59:59'); //（指定日時　時間は24h表記） if ( now \u003e end ) { $('.bakudan_slide').remove();\\n\" +      \"$('.sale_alide img').attr('src','img/main_sale20240901.png'); } NEW ITEM 新着商品 新着\\n\" +      'ホット＆スパイシーヌードル\\n' +      'ホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。\\n' +      '詳しくはこちら 詳しくはこちら PICK UP!おすすめ商品 商品をもっと見る 新着 パルメザンチーズのリゾット\\n' +      'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\n' +      '詳しくはこちら',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'パルメザンチーズのリゾット\\n' +      'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\n' +      '詳しくはこちら パルメザンチーズ[要冷蔵] 詳しくはこちら PICK UP!おすすめレシピ レシピをもっと見る SPECIAL TOPICS 特集\\n' +      '特集をもっと見る SNS 公式Instagram・公式X（旧Twitter） Tweets',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'Tweets by GyomusuperOFCL 公式Instagram 公式X（旧Twitter）',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '公式Instagram 公式X（旧Twitter）\\n' +      '2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭\\n' +      '日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\\n' +      '日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。\u003cセール期間\u003e【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）\u003cセール対象店舗\u003e全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。\\n' +      '一覧を見る 『世界の本物』を直輸入！\\n' +      '業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！\\n' +      '安さの秘密 自慢の国内自社工場の『オリジナル』\\n' +      '国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\n' +      '安全・安心の秘密',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '自慢の国内自社工場の『オリジナル』\\n' +      '国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\n' +      '安全・安心の秘密\\n' +      'スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。\\n' +      '神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。\\n' +      '.detail_footer{display: none;} @media screen and (max-width: 767px){\\n' +      '.detail_footer{ display: block; position: fixed; bottom: 0; width: 100%;\\n' +      'z-index: 20; } .detail_footer_con{ display: flex; justify-content: space-around;\\n' +      'align-items: flex-start; max-width: 400px; width: 97%; margin: 0 auto; }\\n' +      '.detail_footer_con a{ text-decoration: none; color: #fff; } .footer_btn{\\n' +      'background-color: #13a555; padding: 10px; border-radius: 10px 10px 0 0; width:\\n' +      '32%; font-size: 11px; color: #fff; display: flex; flex-direction: column;',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: '#13a555; padding: 10px; border-radius: 10px 10px 0 0; width: 32%; font-size:\\n' +      '11px; color: #fff; display: flex; flex-direction: column; justify-content:\\n' +      'center; align-items: center; height: 55px; } .footer_btn p{ margin: 0; }\\n' +      '.footer_btn img{ margin-bottom: 5px; } .shop_img{ width: 24%; } .bargain_img{\\n' +      'width: 23%; } .pro_img{ width: 21%; } .to_img{ width: 22%; } .re_img{ width:\\n' +      '25%; } .footer_x, .footer_insta{ width: 13%; border-radius: 40px; } .footer_x{\\n' +      'background-color: #000; padding: 13px; } .footer_insta{ background-color:\\n' +      '#ff0069; padding: 12px; } .footer_btn, .footer_x, .footer_insta{ box-shadow: 1px\\n' +      '1px 4px 0 rgba(0, 0, 0, .5); } } 店舗検索 特売情報 ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品\\n' +      '国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: 'ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品 国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み 商品開発事前チェック\\n' +      '現地工場チェック 品質安全検査 商品検証 FC加盟店募集 業務スーパー5つの強み 業務スーパーの特徴 オープンまでのプロセス 体制について 契約概要・加盟条件\\n' +      '物件・商品のご提案募集 お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針\\n' +      '〒675-0063兵庫県加古川市加古川町平野125番1 ©2018-document.write(new Date().getFullYear());\\n' +      'Gyomu Super All Rights Reserved. footer small { display: block; text-align:\\n' +      'right; padding-right: 10px; margin: 0 3%; color: #fff; } @media (max-width:64em)\\n' +      '{ footer small { display: block; text-align: left; padding-right: 10px; margin:\\n' +      \"20px 4%!important; color: #fff; } } $('.main_img\\n\" +      \".swiper-slide').click(function(){ var top_slide =\\n\" +      \"$(this).children('a').attr('href'); gtag('event', 'click', {'event_category' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"20px 4%!important; color: #fff; } } $('.main_img\\n\" +      \".swiper-slide').click(function(){ var top_slide =\\n\" +      \"$(this).children('a').attr('href'); gtag('event', 'click', {'event_category' :\\n\" +      \"'top_slide', 'event_label' : 'top_slide_'+top_slide+''}); gtag('event',\\n\" +      \"'top_slide', {'top_slide' : top_slide}); }); $('.topics').click(function() { var\\n\" +      \"page_url = $('.topics a').attr('href'); gtag('event', 'click', {'event_category'\\n\" +      \": 'topics_bnr', 'event_label' : 'topics_bnr_'+page_url+''}); gtag('event',\\n\" +      \"'topics_bnr', {'topics_bnr' : page_url}); });\\n\" +      \"$('.top_recipe_bnr').click(function(){ var top_recipe_bnr = $('.top_recipe_bnr\\n\" +      \"a').attr('href'); gtag('event', 'click', {'event_category' : 'top_recipe_bnr',\\n\" +      \"'event_label' : 'top_recipe_bnr_'+top_recipe_bnr+''}); gtag('event',\\n\" +      \"'top_recipe_bnr', {'top_recipe_bnr' : top_recipe_bnr}); });\\n\" +      \"$('.gs_forum').click(function(){ var gs_forum = $('.gs_forum .forumimg\\n\" +      \"img').attr('src'); gtag('event', 'click',\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"gtag('event', 'top_recipe_bnr', {'top_recipe_bnr' : top_recipe_bnr}); });\\n\" +      \"$('.gs_forum').click(function(){ var gs_forum = $('.gs_forum .forumimg\\n\" +      \"img').attr('src'); gtag('event', 'click', {'event_category' : 'gs_forum',\\n\" +      \"'event_label' : 'gs_forum_'+gs_forum+''}); gtag('event', 'gs_forum', {'gs_forum'\\n\" +      \": gs_forum}); }); $('.information dt').click(function(){ var news_title =\\n\" +      \"$(this).children('p').text(); gtag('event', 'click', {'event_category' : 'news',\\n\" +      \"'event_label' : 'news_'+news_title+''}); gtag('event', 'news', {'news' :\\n\" +      \"news_title}); }); $('.yasusa').click(function(){ gtag('event', 'click',\\n\" +      \"{'event_category' : 'yasusa_himitsu', 'event_label' : 'yasusa_himitsu'});\\n\" +      \"gtag('event', 'yasusa_himitsu', {'yasusa_himitsu' : 'yasusa_himitsu'}); });\\n\" +      \"$('.anzen').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'anzen_himitsu', 'event_label' : 'anzen_himitsu'}); gtag('event',\\n\" +      \"'anzen_himitsu', {'anzen_himitsu' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"gtag('event', 'click', {'event_category' : 'anzen_himitsu', 'event_label' :\\n\" +      \"'anzen_himitsu'}); gtag('event', 'anzen_himitsu', {'anzen_himitsu' :\\n\" +      \"'anzen_himitsu'}); }); $('.recipe_btm_link').click(function(){ gtag('event',\\n\" +      \"'click', {'event_category' : 'recipe_btm_link', 'event_label' :\\n\" +      \"'recipe_btm_link'}); gtag('event', 'recipe_btm_link', {'recipe_btm_link' :\\n\" +      \"'recipe_btm_link'}); }); $('.3step_btn').click(function(){ gtag('event',\\n\" +      \"'click', {'event_category' : '3step_btn', 'event_label' : '3step_btn'});\\n\" +      \"gtag('event', '3step_btn', {'3step_btn' : '3step_btn'}); });\\n\" +      \"$('.setsuyaku_btn').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'setsuyaku_btn', 'event_label' : 'setsuyaku_btn'}); gtag('event',\\n\" +      \"'setsuyaku_btn', {'setsuyaku_btn' : 'setsuyaku_btn'}); });\\n\" +      \"$('.quick_btn').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'quick_btn', 'event_label' : 'quick_btn'}); gtag('event', 'quick_btn',\\n\" +      \"{'quick_btn' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \": 'setsuyaku_btn'}); }); $('.quick_btn').click(function(){ gtag('event',\\n\" +      \"'click', {'event_category' : 'quick_btn', 'event_label' : 'quick_btn'});\\n\" +      \"gtag('event', 'quick_btn', {'quick_btn' : 'quick_btn'}); });\\n\" +      \"$('.honkaku_btn').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'honkaku_btn', 'event_label' : 'honkaku_btn'}); gtag('event', 'honkaku_btn',\\n\" +      \"{'honkaku_btn' : 'honkaku_btn'}); }); $('.recipe_item').click(function(){\\n\" +      \"gtag('event', 'click', {'event_category' : 'recipe_item', 'event_label' :\\n\" +      \"'recipe_item'}); gtag('event', 'recipe_item', {'recipe_item' : 'recipe_item'});\\n\" +      \"}); $('.all_recipe_btn').click(function(){ gtag('event', 'click',\\n\" +      \"{'event_category' : 'all_recipe_btn', 'event_label' : 'all_recipe_btn'});\\n\" +      \"gtag('event', 'all_recipe_btn', {'all_recipe_btn' : 'all_recipe_btn'}); });\\n\" +      \"$('.sports_wrap .bun_left').click(function(){ gtag('event', 'click',\\n\" +      \"{'event_category' : 'Visseel', 'event_label' : 'Visseel'}); gtag('event',\\n\" +      \"'Visseel', {'Visseel' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \": 'all_recipe_btn'}); }); $('.sports_wrap .bun_left').click(function(){\\n\" +      \"gtag('event', 'click', {'event_category' : 'Visseel', 'event_label' :\\n\" +      \"'Visseel'}); gtag('event', 'Visseel', {'Visseel' : 'Visseel'}); });\\n\" +      \"$('.sports_wrap .bun_right').click(function(){ gtag('event', 'click',\\n\" +      \"{'event_category' : 'DeNA', 'event_label' : 'DeNA'}); gtag('event', 'DeNA',\\n\" +      \"{'DeNA' : 'DeNA'}); }); $('.sale_bnr').click(function(){ gtag('event', 'click',\\n\" +      \"{'event_category' : 'sale_bnr_mini', 'event_label' : 'sale_bnr_mini'});\\n\" +      \"gtag('event', 'sale_bnr_mini', {'sale_bnr_mini' : 'sale_bnr_mini'}); });\\n\" +      \"$('.top_ec_btn').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'top_ec_btn', 'event_label' : 'top_ec_btn'}); gtag('event', 'top_ec_btn',\\n\" +      \"{'top_ec_btn' : 'top_ec_btn'}); }); $('.top_halal_btn').click(function(){\\n\" +      \"gtag('event', 'click', {'event_category' : 'top_halal_btn', 'event_label' :\\n\" +      \"'top_halal_btn'}); gtag('event', 'top_halal_btn', {'top_halal_btn' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"gtag('event', 'click', {'event_category' : 'top_halal_btn', 'event_label' :\\n\" +      \"'top_halal_btn'}); gtag('event', 'top_halal_btn', {'top_halal_btn' :\\n\" +      \"'top_halal_btn'}); }); $('.gyomuca_slide').click(function(){ gtag('event',\\n\" +      \"'click', {'event_category' : 'gyomuca_slide', 'event_label' : 'gyomuca_slide'});\\n\" +      \"gtag('event', 'gyomuca_slide', {'gyomuca_slide' : 'gyomuca_slide'}); });\\n\" +      \"$('.gyomuca_btn').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'gyomuca_btn', 'event_label' : 'gyomuca_btn'}); gtag('event', 'gyomuca_btn',\\n\" +      \"{'gyomuca_btn' : 'gyomuca_btn'}); }); $('.top_shop_bnr a').click(function(){\\n\" +      \"gtag('event', 'click', {'event_category' : 'top_shop_bnr', 'event_label' :\\n\" +      \"'top_shop_bnr'}); gtag('event', 'top_shop_bnr', {'top_shop_bnr' :\\n\" +      \"'top_shop_bnr'}); }); $('.top_bargain_bnr a').click(function(){ gtag('event',\\n\" +      \"'click', {'event_category' : 'top_bargain_bnr', 'event_label' :\\n\" +      \"'top_bargain_bnr'}); gtag('event', 'top_bargain_bnr', {'top_bargain_bnr' :\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"a').click(function(){ gtag('event', 'click', {'event_category' :\\n\" +      \"'top_bargain_bnr', 'event_label' : 'top_bargain_bnr'}); gtag('event',\\n\" +      \"'top_bargain_bnr', {'top_bargain_bnr' : 'top_bargain_bnr'}); });\\n\" +      \"$(document).ready(function() { $('.drawer').drawer(); }); //infoaccordion\\n\" +      `$(function(){ $(\".infoac dt\").not('#noicon').on(\"click\", function() {\\n` +      '$(this).next().slideToggle(); $(this).toggleClass(\"active\"); }); }); //scroll\\n' +      `$(function(){ // #で始まるリンクをクリックしたら実行されます $('a[href^=\"#\"]').click(function() { //\\n` +      'スクロールの速度 var speed = 600; // ミリ秒で記述 var href= $(this).attr(\"href\"); var target =\\n' +      `$(href == \"#\" || href == \"\" ? 'html' : href); var position =\\n` +      \"target.offset().top; $('body,html').animate({scrollTop:position}, speed,\\n\" +      \"'swing'); return false; }); }); //matchHeight $(function(){\",    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  },  Document {    pageContent: \"var position = target.offset().top; $('body,html').animate({scrollTop:position},\\n\" +      \"speed, 'swing'); return false; }); }); //matchHeight $(function(){\\n\" +      \"$('.mh').matchHeight(); }); function news_link(id,year) {\\n\" +      'document.newslink.ne_id.value=id; document.newslink.ne_year.value=year;\\n' +      'document.newslink.submit(); } $(function(){ $(\"#acMenu dt\").on(\"click\",\\n' +      'function() { $(this).next().slideToggle(); $(this).toggleClass(\"active\"); });\\n' +      '}); $(\".information dl dt\\n' +      `p:contains('「酒類の品目等の表示義務」改正に伴う「麦旨」の品目表示及び税率適用区分表示の変更について')\").find('a').attr({target:\"_blank\"});\\n` +      'objectFitImages();',    metadata: { source: 'https://www.gyomusuper.jp/', loc: [Object] },    id: undefined  }]CheerioWebBaseLoaderはbodyタグ内を読むのですが、styleタグやscriptタグが入ってしまっているからなんですね。そこで、CheerioWebBaseLoaderを使わず、URLからfetchして、cheerioTextで得たbodyタグの中からstyleタグやscriptタグの中身を除去したコードを実行。npx ts-node webLoad.ts https://www.gyomusuper.jp/綺麗に取れました！！bodyContent:お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針ホーム商品紹介ミラクルレシピ特集一覧安心安全の取り組み業務スーパーとはGyomucaお問い合わせオンラインショップFC加盟店募集会社案内日本語/ENGLISH/中文NEWITEM新着商品新着ホット＆スパイシーヌードルホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。詳しくはこちら詳しくはこちらPICKUP!おすすめ商品商品をもっと見る新着パルメザンチーズのリゾットイタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！詳しくはこちらパルメザンチーズ[要冷蔵]詳しくはこちらPICKUP!おすすめレシピレシピをもっと見るSPECIALTOPICS特集特集をもっと見るSNS公式Instagram・公式X（旧Twitter）TweetsbyGyomusuperOFCL公式Instagram公式X（旧Twitter）2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。\u003cセール期間\u003e【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）\u003cセール対象店舗\u003e全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。一覧を見る『世界の本物』を直輸入！業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！安さの秘密自慢の国内自社工場の『オリジナル』国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！安全・安心の秘密スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。店舗検索特売情報ホームWEBチラシ店舗案内ミラクルレシピ商品紹介直輸入商品国内自社工場商品業務スーパーとは安さの秘密安全安心の取り組み商品開発事前チェック現地工場チェック品質安全検査商品検証FC加盟店募集業務スーパー5つの強み業務スーパーの特徴オープンまでのプロセス体制について契約概要・加盟条件物件・商品のご提案募集お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針〒675-0063兵庫県加古川市加古川町平野125番1©2018-GyomuSuperAllRightsReserved.","isoDate":"2024-08-31T13:34:16.000Z","dateMiliSeconds":1725111256000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"SRETT#10 ~ 夏のSRE祭り！アーカイブ動画公開！","link":"https://shu-kob.hateblo.jp/entry/2024/08/30/230631","contentSnippet":"shu-kob.hateblo.jp2024年8月23日に弊社スリーシェイクのコミュニティ勉強会「SRETT #10 ~ 夏のSRE祭り！」が開催されました。www.youtube.comアーカイブ動画も公開されています！当日ご参加できなかった方もぜひご覧ください！自分は当日誘導係をやっていて、最初の菱田さんのセッション「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」は最後のちょびっとだけしか聴けていないから、観ようかな。","isoDate":"2024-08-30T14:06:31.000Z","dateMiliSeconds":1725026791000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オライリーのAWS生成AI本","link":"https://shu-kob.hateblo.jp/entry/2024/08/29/234143","contentSnippet":"AWSではじめる生成AI ―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje Barth,Shelbee EigenbrodeオライリージャパンAmazonそういや、オライリージャパンからAWSの生成AI本出てますね。欲しいと思いながらも買うてない。現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、面白そうなら買うてみるしか！翻訳はAWS Japanの久富木 隆一さん。AWSの中の人が翻訳しているので確かでしょうね！","isoDate":"2024-08-29T14:41:43.000Z","dateMiliSeconds":1724942503000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「SREをはじめよう」(Becoming SRE邦訳)が出版","link":"https://shu-kob.hateblo.jp/entry/2024/08/28/235736","contentSnippet":"SREをはじめよう ―個人と組織による信頼性獲得への第一歩作者:David N. Blank-EdelmanオライリージャパンAmazon「Becoming SRE」の邦訳である「SREをはじめよう」が2024/10/8オライリージャパンから発売されます！翻訳は、オライリーのSRE系の邦訳を数多く手掛けられてきた山口 能迪さん（Google所属）個人がSREになる、組織がSREになるという二面で書かれているようで、今からとても楽しみです！","isoDate":"2024-08-28T14:57:36.000Z","dateMiliSeconds":1724857056000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス","link":"https://shu-kob.hateblo.jp/entry/2024/08/27/235840","contentSnippet":"pages.sreake.comイベントで登壇していました。ご参加くださった方はありがとうございました！良い評価をいただけたようで光栄です！今回、「生成AI利活用を進めるためのプロセス」というテーマだったので、普段私があまり話さないことも話せて新鮮でした。genai-users.connpass.com普段は、日本生成AIユーザ会でハンズオンをやっているように、具体的技術を話すことが多いので。今回とても良い経験になりました。今後も良い発表ができるよう精進していきます！","isoDate":"2024-08-27T14:58:40.000Z","dateMiliSeconds":1724770720000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"後継者不足のCOBOLを生成AIに引き継ぎ","link":"https://shu-kob.hateblo.jp/entry/2024/08/26/235854","contentSnippet":"www.itmedia.co.jpIT media AI+より。虚構新聞かと思いましたが（笑）、本当にようです。ベトナムの研究者が論文を出したのですね。日本でもCOBOLで書かれたシステムはまだまだ残っていますが、COBOL書けるエンジニアが高齢になってきて、後継者不足でもあります。海外もベトナムも同様なのですね。リプレイスしていくのも大事かと思いますが、全部のCOBOLシステムのリプレイスも難しいでしょうし、リプレイスしつつも、生成AIに書かせるのが現実解なのかもしれません。","isoDate":"2024-08-26T14:58:54.000Z","dateMiliSeconds":1724684334000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AIアプリケーション開発ノーコードフレームワークDify","link":"https://shu-kob.hateblo.jp/entry/2024/08/25/233704","contentSnippet":"dify.ai最近、Difyの話題をよく聞くので、軽くご紹介したいと思います。Difyとは？ 生成AIアプリ開発を劇的に簡素化するプラットフォームDifyは、生成AIアプリケーションをノーコードで開発できる、非常に革新的なプラットフォームです。これまで、生成AIアプリの開発は、高度なプログラミングスキルを必要とし、専門エンジニアでなければ実現が難しいものでした。しかし、Difyの登場により、この状況が一変。非エンジニアでも、直感的な操作で複雑なAIアプリケーションを構築できるようになりました。Difyが選ばれる理由ノーコード開発: プログラミングの知識がなくても、ブロックを組み合わせるように視覚的にアプリを構築できます。RAG（Retrieval Augmented Generation）対応: 大規模言語モデル（LLM）と外部データソースを連携させ、より高度なAI機能を実現できます。オープンソース: プラットフォーム自体がオープンソースであり、自由にカスタマイズ・拡張できます。高機能: チャットボット、AIアシスタント、要約ツールなど、さまざまなタイプの生成AIアプリを開発可能です。企業との連携: 既存の企業システムとの連携もスムーズに行え、業務効率化に貢献します。Difyの主な特徴柔軟性: AIプロセスを自由に組み合わせて、柔軟なアプリケーションを開発できます。統合性: 既存のシステムとの連携が容易で、企業内の既存のデータやシステムと統合できます。監視性: 実行時の状況を監視し、AIモデルの性能を継続的に改善できます。スケーラビリティ: 需要に応じて、簡単にシステムを拡張できます。Difyでできることチャットボットの開発: 自然な会話ができるチャットボットを簡単に作成できます。AIアシスタントの開発: 顧客対応や業務支援を行うAIアシスタントを開発できます。文書の自動生成: レポートや記事などを自動生成できます。データ分析: 大量のデータを分析し、有益な情報を抽出できます。Difyが注目される理由生成AIの民主化: 生成AIの技術を、より多くの人々に開放し、AIの活用範囲を広げます。開発コストの削減: 高度なエンジニアを雇用する必要がなく、開発コストを大幅に削減できます。開発期間の短縮: ノーコード開発により、開発期間を大幅に短縮できます。まとめDifyは、生成AIの開発を劇的に簡素化するプラットフォームです。非エンジニアでも、高度なAIアプリケーションを開発できるため、生成AIの活用範囲が大きく広がることが期待されています。もし、生成AIに興味があり、独自のアプリケーションを開発したいと考えているのであれば、Difyは非常に魅力的な選択肢と言えるでしょう。さらに詳しく知りたい方へDify公式サイト: https://dify.ai/jpDifyの始め方（非エンジニアでも生成AIアプリが作れる最強ツール）: https://zenn.dev/en2enzo2/articles/824877e1099508Difyは、生成AIの分野で注目を集めているプラットフォームです。ぜひ、この機会にDifyについて詳しく調べてみてください。何か他に知りたいことがあれば、お気軽にご質問ください。","isoDate":"2024-08-25T14:37:04.000Z","dateMiliSeconds":1724596624000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"高度情報の午前Ⅱ試験を解くならこのサイト","link":"https://shu-kob.hateblo.jp/entry/2024/08/24/225803","contentSnippet":"もうすぐ9月。秋の情報処理技術者試験も近づいてますね。私はプロジェクトマネージャ試験を受けるので頑張らねば。応用情報午前試験の過去問アプリはたくさんあるのですが、高度情報はないですよね。IPA公式の過去問をPDFで開かずとも、スマホで気軽に過去問演習したいところ。そこで、高度情報の午前Ⅱ試験を解くならこのサイトをご紹介したいと思います。情報処理技術者試験の勉強(過去問題)をやり直し過去問を1問1答形式で時進められます。全ての高度情報に対応しています。こちらを活用して、午前Ⅱは余裕で通過できるようにしておきましょう１","isoDate":"2024-08-24T13:58:03.000Z","dateMiliSeconds":1724507883000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake SRE Tech Talk #10無事終了。英語は大事w","link":"https://shu-kob.hateblo.jp/entry/2024/08/23/231736","contentSnippet":"3-shake.connpass.comshu-kob.hateblo.jp初のオンサイト開催となる3-shake SRE Tech Talk #10無事終了しました。詳しいことは後日書くとして、私は誘導係をしました。会場となったGoogleさんの渋谷オフィスは渋谷ストリームという新しい建物にあるのですが、エントランスの長いエスカレータの下で誘導していたら外国人2組に道を聞かれました（笑）スリーシェイクTシャツ着て立っていたから、建物の係りの人と思われた？1人目の方には、スマホを見せられ、渋谷ストリーム内の串カツ屋の場所を聞かれました。飲食店マップがあったので、3Fか4Fにあるみたい、と拙い英語で説明w2組目の二人には、スマホを見せられ、半蔵門線渋谷駅の場所を聞かれました。エスカレータを指差し、「（エスカレータを）Down, Purple is Line Color.（半蔵門線のラインカラーは紫）」とまた拙い英語で説明したら、「ありがと！（Arigato）」とお礼を言われました。面白い経験をするとともに、Googleの音声翻訳など便利なものを使えばよかったと思いました。今後はもうちょっとまともな英語を答えられるよう頑張るぞ！","isoDate":"2024-08-23T14:17:36.000Z","dateMiliSeconds":1724422656000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10","link":"https://shu-kob.hateblo.jp/entry/2024/08/22/214001","contentSnippet":"shu-kob.hateblo.jp以前も書きましたが、2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10 です。初のオンサイト開催！（オンラインも併用）18:30からGoogle Cloudさんの渋谷オフィスで行います。無料の懇親会もあります。オンサイトは定員40人のところ、前日の8月22日21:36現在、37人と、3人の空きがあります。タイムテーブルはこちら株式会社Topotal 菱田 健太氏「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」株式会社スリーシェイク 阿部貴晶「LLMのO11yに触れる」グーグルクラウドジャパン合同会社 中谷 祐輔氏「スポンサーセッション」弊社スリーシェイクからは「LLMのO11yに触れる」というテーマで、生成AIのオブザーバビリティの話があります。私も会場誘導係として、参加予定です。生成AIに興味ある方もぜひご参加ください。","isoDate":"2024-08-22T12:40:01.000Z","dateMiliSeconds":1724330401000,"authorName":"Shu Kobuchi","authorId":"kobuchi"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"kobuchi"},"buildId":"rVplmCPTXat4Z1gtkOHXI","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>