<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon shortcut" type="image/png" href="https://blog.3-shake.com/logo.png"/><title>nwiizo | 3-shake Engineers&#x27; Blogs</title><meta property="og:title" content="nwiizo"/><meta property="og:url" content="https://blog.3-shake.com/members/nwiizo"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="3-shake Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.3-shake.com/og.png"/><link rel="canonical" href="https://blog.3-shake.com/members/nwiizo"/><meta name="next-head-count" content="10"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/ca0df06cc4f85fc8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ca0df06cc4f85fc8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-b8f8d6679aaa5f42.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-b671ab60a2eabb59.js" defer=""></script><script src="/_next/static/chunks/pages/_app-aef75d70891be704.js" defer=""></script><script src="/_next/static/chunks/983-569e53259f785ffe.js" defer=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-fa4563d96c58aa0a.js" defer=""></script><script src="/_next/static/ndJcG5MD0nlQGFxL-ZToO/_buildManifest.js" defer=""></script><script src="/_next/static/ndJcG5MD0nlQGFxL-ZToO/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;700&family=Roboto:wght@300;400;500;700&display=swap">@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjr0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5vAA.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Me5g.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9vAA.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlvAA.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F10C,U+1F110-1F16C,U+1F170-1F190,U+1F19B-1F1AC,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F579,U+1F57B-1F594,U+1F597-1F5A3,U+1F5A5-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CB,U+1F6CD-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA74,U+1FA78-1FA7A,U+1FA80-1FA86,U+1FA90-1FAA8,U+1FAB0-1FAB6,U+1FAC0-1FAC2,U+1FAD0-1FAD6,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F10C,U+1F110-1F16C,U+1F170-1F190,U+1F19B-1F1AC,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F579,U+1F57B-1F594,U+1F597-1F5A3,U+1F5A5-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CB,U+1F6CD-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA74,U+1FA78-1FA7A,U+1FA80-1FA86,U+1FA90-1FAA8,U+1FAB0-1FAB6,U+1FAC0-1FAC2,U+1FAD0-1FAD6,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F10C,U+1F110-1F16C,U+1F170-1F190,U+1F19B-1F1AC,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F579,U+1F57B-1F594,U+1F597-1F5A3,U+1F5A5-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CB,U+1F6CD-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA74,U+1FA78-1FA7A,U+1FA80-1FA86,U+1FA90-1FAA8,U+1FAB0-1FAB6,U+1FAC0-1FAC2,U+1FAD0-1FAD6,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmSU5fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu72xKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu5mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu7mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu4WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu7WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu7GxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOmCnqEu92Fr1Mu4mxKKTU1Kg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmEU9fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v30/KFOlCnqEu92Fr1MmWUlfBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.svg" alt="3-shake Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">3-shake<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a class="site-header__link" href="/feed.xml">RSS</a><a href="https://jobs-3-shake.com/" class="site-header__link">Recruit</a><a href="https://3-shake.com/" class="site-header__link">Company</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/nwiizo.jpeg" alt="nwiizo" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">nwiizo</h1><p class="member-header__bio">Brogrammer</p><div class="member-header__links"><a href="https://twitter.com/nwiizo" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@nwiizo" width="22" height="22"/></a><a href="https://github.com/nwiizo" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@nwiizo" width="22" height="22"/></a><a href="https://nwiizo.github.io/" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-01-10T04:23:26.000Z" class="post-link__date">2 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/01/10/132326" class="post-link__main-link"><h2 class="post-link__title">達人と呼ばれる技術力を持ったソフトウェアエンジニアになりたくて</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a><div class="post-link__new-label">NEW</div></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-12-31T13:10:26.000Z" class="post-link__date">11 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/12/31/221026" class="post-link__main-link"><h2 class="post-link__title">技術書やブログ、登壇資料の参考文献は読んだ方がいい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-12-21T07:50:21.000Z" class="post-link__date">21 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/12/21/165021" class="post-link__main-link"><h2 class="post-link__title">WIP: 2023年 俺が愛した本たち 非技術書編</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-12-02T05:14:55.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/12/02/141455" class="post-link__main-link"><h2 class="post-link__title">2023年 俺が愛した本たち 技術書編</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-21T04:21:44.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/21/132144" class="post-link__main-link"><h2 class="post-link__title">『走馬灯のIaCは考えておいて』というタイトルで登壇しました。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-16T07:13:20.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/16/161320" class="post-link__main-link"><h2 class="post-link__title">Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-16T05:35:54.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/16/143554" class="post-link__main-link"><h2 class="post-link__title">Infrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-16T03:40:30.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/16/124030" class="post-link__main-link"><h2 class="post-link__title">Infrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-15T16:53:54.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/16/015354" class="post-link__main-link"><h2 class="post-link__title">Infrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-15T04:43:17.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/15/134317" class="post-link__main-link"><h2 class="post-link__title">Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-11-14T06:46:03.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603" class="post-link__main-link"><h2 class="post-link__title">Terraformの条件分岐にうってつけの日</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-10-05T14:35:55.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555" class="post-link__main-link"><h2 class="post-link__title">『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-09-19T15:29:20.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920" class="post-link__main-link"><h2 class="post-link__title">Open InterpreterのDockerfile を書いたのでTipsとか</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-09-06T07:52:27.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227" class="post-link__main-link"><h2 class="post-link__title">まずPR-AgentをPromptとします。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-08-22T11:43:27.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/08/22/204327" class="post-link__main-link"><h2 class="post-link__title">ChatGPT: SREがCustom instructions機能を利用する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-08-10T06:04:12.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412" class="post-link__main-link"><h2 class="post-link__title">SREからPlatform Engineerへの拡大 というタイトルで登壇しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-08-09T17:19:34.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/08/10/021934" class="post-link__main-link"><h2 class="post-link__title">2023年8月10日現在 でLunarVim と Copilot.lua でのマルチラインサポートの改善方法 </h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-08-03T06:53:26.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/08/03/155326" class="post-link__main-link"><h2 class="post-link__title">K8sGPT Deep Dive というタイトルで登壇しました #CNDF</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-07-19T07:26:57.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/07/19/162657" class="post-link__main-link"><h2 class="post-link__title">CLIの実行結果を正しく理解することを促すツールを作成しました。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-07-13T04:14:33.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/07/13/131433" class="post-link__main-link"><h2 class="post-link__title">成熟度モデルを活用したCloud Nativeへの道筋 という副題で登壇します #開発生産性con_findy</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-07-03T00:47:13.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/07/03/094713" class="post-link__main-link"><h2 class="post-link__title">SREの専門家が集まったチームで『SREの探求』の社内輪読会を完遂しました。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-05-19T06:43:46.000Z" class="post-link__date">8 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346" class="post-link__main-link"><h2 class="post-link__title">Terraform Modules で再利用できるので最高ではないでしょうか？</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-05-09T09:19:43.000Z" class="post-link__date">8 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/05/09/181943" class="post-link__main-link"><h2 class="post-link__title">はてなブログのコードブロックを”クリップボードにコピーする方法”について</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-04-17T01:00:01.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/04/17/100001" class="post-link__main-link"><h2 class="post-link__title">Golang のEcho でMiddlewareを使ってPrometheus Exporter を実装する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-04-16T04:24:50.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/04/16/132450" class="post-link__main-link"><h2 class="post-link__title">Golang のEcho で Prometheus Exporter を実装する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-04-10T23:44:28.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/04/11/084428" class="post-link__main-link"><h2 class="post-link__title">ChatGPT:SREやDevOpsなどのソフトウェアの運用に伴う課題解決に関する提案を行うプロンプト</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-04-09T18:14:52.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/04/10/031452" class="post-link__main-link"><h2 class="post-link__title">PHPカンファレンス福岡2023に｢State of DevOps 2022を読みながら、組織に適したSREの実践方法を探求する｣というproposalを出しました #phpconfuk </h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-03-31T02:10:30.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/03/31/111030" class="post-link__main-link"><h2 class="post-link__title">愛ゆえにお前はVimを使わねばらなぬ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-03-29T16:19:30.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/03/30/011930" class="post-link__main-link"><h2 class="post-link__title">Shell ScriptをGo言語に書き直す際に役立つ50本ノックなるものを作り始めた。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2023-03-17T15:06:37.000Z" class="post-link__date">10 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2023/03/18/000637" class="post-link__main-link"><h2 class="post-link__title">ChatGPTで障害対応 RPG v0.0.1を遊ぶには？</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2022-03-11T04:02:18.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://zenn.dev/nwiizo/articles/d837b78914de23" class="post-link__main-link"><h2 class="post-link__title">Observability Conference 2022 に登壇しました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->3-shake Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"Brogrammer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"達人と呼ばれる技術力を持ったソフトウェアエンジニアになりたくて","contentSnippet":"zyさんの「技術力が高い」という幻覚を読んでの感想。sizu.me技術力とは私の経験でも、技術力は単なる専門知識や技術の習得を超えた、もっと包括的で深い概念です。実用日本語表現辞典において「技術力」とは、「手段や手法を用いて物事を成し遂げる能力」と定義されています。この定義は、技術を単に適用することではなく、それを利用して広範囲な目標を達成する、特に問題解決能力を含む幅広い能力を示唆しています。言い換えれば、技術力は具体的な技術的スキルだけではなく、それらを応用し、実際の課題に対して実効性のある解決策を生み出す能力を意味します。これには、新しい技術を学び、既存の技術を創造的に応用することも含まれます。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon技術力への信頼とその重要性私が考えるに、高い技術力は複雑な技術の使用能力だけに限らず、他者からの信頼と依頼を獲得する能力にも反映されます。人々が「あの人に任せたい」「あの人に相談したい」と感じる時、それは技術的な能力だけではなく、人間性やコミュニケーション能力が高いことを示します。こうした能力は、チームワークやプロジェクトの成功に不可欠です。技術力を持つ人は、単にタスクをこなすだけでなく、チームメンバーと効果的に協力し、プロジェクトの目標に貢献します。「技術力が高い」「技術力が低い」という一般的な評価はしばしば狭い視野に基づいています。真の技術力の評価は、直接的な事業貢献やコミュニケーション能力を超えた、より幅広い能力に基づくべきです。これは、個々のポジションや視点によって異なり、難解なコードを書く能力だけでなく、既存のコードを効率的に活用し、迅速に顧客に価値を提供できる能力も含まれます。技術力は、新しい課題に対応する柔軟性と、既存のソリューションを改善する創造性を併せ持つことです。このように、高い技術力は、技術的なスキルに加えて、人間性、信頼性、問題解決能力、コミュニケーション能力などの多面的な資質が組み合わさったものです。これにより、他者から頼りにされ、尊敬されるエンジニアとなることが可能です。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazonソフトウェアエンジニアの役割ソフトウェアエンジニアは、一人で全てを行う天才ハッカーや家で働きもせずに自称ソフトウェアエンジニアを名乗っている場合を除いて、技術を活用して問題を解決し、新しい価値を創造する重要な役割を担っています。彼らは技術的な問題に直面するだけでなく、企業の一員としてのプロフェッショナルな責任も持ちます。これには、会社の目標達成、業務の効率化、社内外の関係構築など、より広範な責務が含まれます。社内で問題が発生した際、彼らは解決策の策定と推進における主導的な役割を果たし、問題点の指摘にとどまらず、修正パッチの提供など具体的かつ建設的な貢献を行います。この積極的で前向きなアプローチは、問題の根本的な解決につながり、ソフトウェアの品質向上や優れたソリューションの提供に貢献します。総じて、ソフトウェアエンジニアとしての技術力と、企業の一員としてのプロフェッショナルな貢献は、それぞれが重要な役割を果たします。彼らは技術的なスキルと共に、組織内での協力と責任感を兼ね備えていることが求められます。サラリーマン金太郎 第1巻作者:本宮 ひろ志サード・ラインAmazonまとめ「技術力が高い」という言葉は、単に技術的なスキルの高さを超えた意味を確実に持っています。これには、問題解決能力、信頼性、コミュニケーション能力など、多面的な資質が含まれます。そしてそれが幻覚や誰かの勘違いであっても持ちうる技術力を活かして他者を支援し、相互にリスペクトを持つことが、ソフトウェアエンジニアとしての熟達への道です。このような姿勢が、周りから達人としての認識を得るための重要な要素となります。イシューからはじめよ――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazonあとは、「技術力が高い」という幻覚を読んでたらそーだいさんのソフトウェアエンジニアと技術力を思い出した。読み返してもとても良かったので合わせて紹介しておきたいです。 speakerdeck.com僕たちが技術力と呼んでいるナニカについての話でした。","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/10/132326","isoDate":"2024-01-10T04:23:26.000Z","dateMiliSeconds":1704860606000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"技術書やブログ、登壇資料の参考文献は読んだ方がいい","contentSnippet":"はじめに今年は女との同棲を解消する。円形脱毛症と胃潰瘍になる。自分の身体から生気が抜ける感覚が多々ありました。また、人生最大限に体重が増加するなどの加齢を言い訳にしたイベントが目白押しでした。年末のこの時期は、振り返ったり新しいことを始めたくなるものです。しかしそんなことは全て横に置いておいて今日は、「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というテーマについて、深掘りしてみたいと思います。技術の世界は日々進化し、新しい情報を取り入れることは不可欠ですが、新しい技術や理論の背後にある基礎知識や歴史にも目を向けることも同じかそれ以上に大事ではないでしょうか？参考文献の役割技術書やブログ、登壇資料には、文字やページの数や時間の制限があるため、著者や発表者は主要なポイントに焦点を当てて情報を伝えます。しかしこれらの表面に現れる情報だけでは、トピックの全貌を把握するのは難しいです。そこで重要になるのが、参考文献の役割です。これらは、トピックに関するより詳細な情報、歴史的背景、異なる視点やアプローチを提供し、より深い理解を促します。特に、複雑な技術や理論を扱う際には、参考文献が理解の鍵となります。ブログや登壇資料の表面だけを読んで分かったと思うのは容易いですが、実際の理解は表面的なものに過ぎないことが多いのです。認知科学者スティーブン・スローマンとフィリップ・ファーンバックの著書「知ってるつもり 無知の科学」では、人間の知性の限界と錯覚について詳しく論じられています。この本は、私たちが持つ「知識の錯覚」について解説しています。多くの人が、あるトピックについて理解していると自信を持っているが、実際にはその理解は浅いことが多いのです。これは、私たちの認知システムが複雑な情報を簡略化し、限られた情報から全体を理解したと錯覚する傾向があるためです。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazonまた、エンジンコミュニティではダニング＝クルーガー効果という現象としても有名で、人々は自分の知識や能力を過大評価する傾向があります。これは特に、自分の知識が不足している分野で顕著に現れます。この効果は、単なる自信過剰にとどまらず、誤った情報や決定に基づく行動を引き起こすリスクを含んでいます。togetter.comこのようなわかったフリした認識の歪みを避けるためにも、参考文献を活用して自分の理解を深め、多角的な視点を持つことが重要です。参考文献は、知識の錯覚やダニング＝クルーガー効果に陥りがちな私たちの認識を補完し、より深い理解を促すためのものになり得ます。文献選びのポイント文献を選ぶ際には、その情報源の信頼性や、著者の専門性を評価することが大切です。現在の自分の知識レベルや興味のある領域に合った文献を選ぶことも重要です。一つのトピックについて、異なる角度から書かれた文献を読むことで、よりバランスの取れた理解が得られます。年末年始の休暇は、新しい知識を身につけるための絶好の機会です。選んだ文献をじっくりと読むことで、より学びを充実させることができます。文献選びに関しては、必ずしも難解なものを選ぶ必要はありません。例えば、参考文献に載ってる書籍の入門書を読むことは、知識の更新や基礎を再確認するためにも有効です。O'Reillyなどの専門書のサブスクリプションサービスを利用することで、「え、この本読むのに3000円か」と逡巡せずに幅広い分野の知識を得るための良い方法となります。最後にこのブログを通じて伝えたいのは、単に「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というアドバイスではなく、むしろ「技術書やブログ、登壇資料の参考文献は読んでほしい」という切なる願いです。学びの過程で急ぎすぎず、じっくりと時間をかけて考えることは本当に大切です。表面的な理解に留まらず、深く内容を吟味し、背景や著者の意図を理解することで、真の学びが得られます。参考文献を読む際には、それらが提供する多様な視点や深い知識を活用し、幸せの分母を増やすような豊かな理解を目指すことが重要です。ゆっくりと考えることで、新しい発見や洞察が生まれ、学びの経験がより深いものになります。私たちは共に学び、共に成長することができます。皆さん、良いお年をお迎えください。新しい年にも、学びの喜びを共有し、一緒に成長していくことを心から楽しみにしています。そして、みなさんにも心から「参考文献をしっかりと読むこと」を勧めます。それによって、より深い知識と理解を得ることができ、幸せの分母を増やすための一歩となるでしょう。遅考術――じっくりトコトン考え抜くための「１０のレッスン」作者:植原 亮ダイヤモンド社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/31/221026","isoDate":"2023-12-31T13:10:26.000Z","dateMiliSeconds":1704028226000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"WIP: 2023年 俺が愛した本たち 非技術書編","contentSnippet":"この記事は、3-shake Advent Calendar 2023 21日目のエントリ記事です。はじめにプログラマー脳エンジニアのためのドキュメントライティング達人プログラマー 第2版スタッフエンジニアプロジェクト ヘイルメアリーサーキット・スイッチャー可燃物大規模言語モデルは新たな知性か？ブラジャーで天下をとった男さいごにはじめに2023年が終わろうとしています。年の瀬になると、いつも一年を振り返ることが私の習慣です。技術書に続いて、今年はさまざまな非技術書にも手を伸ばしました。小説や歴史、哲学、芸術の本など、多くのジャンルの本を読むことで、心が豊かになったと感じています。これらの本は、技術的なことだけではなく、人生について深く考えるきっかけをくれました。異なる文化や、普段とは違う視点の物語に触れることで、新しい考え方を学びました。これらの本が、私の考えを広げ、日々の生活に新しい刺激を与えてくれました。技術書と一緒に、これらの本も私のエンジニアとしての知識を形成する大切な部分になりました。2023年は、技術だけでなく、人生の学びにも終わりがないことを感じた一年でした。非技術書から得たことは、技術書から学んだことと相まって、私の理解を深めてくれました。読書を通じて得たこれらの経験は、来年もまた新しい発見への旅に私を連れて行ってくれるでしょう。そして、来年もまた、本とともに充実した一年になることを楽しみにしています。プログラマー脳『プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ』は、プログラミングのスキル向上に認知科学の手法を応用した、画期的な書籍です。この本は、プログラマーがプログラムを読み書きする際に経験する認知的プロセスを深く掘り下げ、熟達したプログラマーと初心者の違いを明確に示しています。著者は、具体的なプログラミング技法や設計手法の直接的な説明を超え、認知のメカニズムを理解し活用することにより、プログラミングの学習と実践の改善を目指しています。プログラマー脳 プログラマーになるための認知科学に基づくアプローチノーブランド品Amazon本書の強みは、抽象的な概念を具体的な実例や演習を交えて解説することで、読者が新しいアイデアを自然に理解し、実践的な知識として身につけるのを助ける点にあります。また、プログラミングに関連する認知科学的な概念を、実際のプログラミングの状況にどのように適用するかについて、具体的かつ実用的なアドバイスを提供しています。こうしたアプローチは、読者がプログラミングに関する洞察を深め、より効率的かつ効果的に技術を習得する手助けをします。この本で特に興味深いのは、「意味波」という概念です。これは、新しい概念や技術を学ぶ過程で、抽象から具象、そして再び抽象へと進むプロセスを指します。このプロセスは、学習者が情報を受け取るだけでなく、それを自分の既存の知識や経験と結びつけ、より高い次元の理解へと昇華させるのに役立ちます。このアプローチは、新しい技術やアイデアを単に学ぶのではなく、それらを既存の知識構造に組み込んで深い理解を得ることに重点を置いています。他にも面白い概念や考え方が多いので、ぜひ読んでみてください。本書は、プログラミングにおける認知的側面を深く掘り下げることで、新しい学習法やスキル向上のアプローチを提供します。これにより、プログラミングのスキルを深め、熟達したプログラマーになるための貴重な知識と洞察を提供しています。『プログラマー脳』を読んで面白いと感じた方は、『言語の本質-ことばはどう生まれ、進化したか』も読んでみてください。『言語の本質-ことばはどう生まれ、進化したか』は、言語の起源と進化に焦点を当てた別の注目すべき書籍です。この本は、言語が人間にとってどのように重要なコミュニケーションツールとして発展してきたのかを探求しています。特に、オノマトペやアブダクション推論という人間特有の学びの力に焦点を置き、言語の進化と子どもの言語習得を通じて人間の根源に迫ります。著者は、言語の起源と進化に関する深い知見を提供し、言語が単なるコミュニケーションツール以上のものであること、すなわち、私たちの認知と感情、文化に深く根差した現象であることを明らかにします。言語の本質　ことばはどう生まれ、進化したか (中公新書)作者:今井むつみ,秋田喜美中央公論新社Amazon本書は、言語の抽象性や体系性、さらには言語がどのようにして複雑なシステムへと発展してきたのかを解明しています。これらのトピックを通じて、読者は言語の複雑な構造と機能、そして人間の認知プロセスとの関連を理解することができます。この本は、言語学、認知科学、心理学に興味を持つ読者にとって、知識の深化と洞察の拡大に貢献するでしょう。それぞれ異なる領域において人間の認知能力と学習の本質に深く切り込んでいる『プログラマー脳』と『言語の本質』に加えて、『進化心理学から考えるホモサピエンス 一万年変化しない価値観』も非常に興味深い本です。『プログラマー脳』では、プログラミングの習得と実践に認知科学を適用し、『言語の本質』は言語の起源と進化を探求することで人間の認知プロセスを解析しています。これらの本は、それぞれの分野において新たな洞察を提供し、読者の理解とスキルの向上に貢献します。進化心理学から考えるホモサピエンス　一万年変化しない価値観作者:アラン・S・ミラーパンローリング株式会社Amazon『進化心理学から考えるホモサピエンス 一万年変化しない価値観』は、進化心理学の観点から、人間の行動や価値観がどのように進化してきたかを探る一冊です。この本は、私たちの行動や意思決定に影響を与える進化的適応について深く掘り下げ、現代の社会や文化における人間の行動パターンを進化心理学的視点から分析します。この並びで本書を紹介するのは、伊藤計劃の『虐殺器官』が『言語学、進化心理学SFの傑作である』ためで、この本は人生を変えるぐらい面白い本だったからです。また、『ゆる言語学ラジオ』も聞いており、とても良かったのでおすすめです。www.youtube.comエンジニアのためのドキュメントライティングDocs for Developers: An Engineer’s Field Guide to Technical Writingの翻訳本です。書いた書評のブログ記事では、この本が良いドキュメントの特徴を架空の開発チームのストーリーを通して教えることで、読者にドキュメンタリアンとしての情熱を呼び起こすと評価されています。syu-m-5151.hatenablog.com原著は読んでないです。やっててよかったO'Reillyサブスクは原著版のみあります。learning.oreilly.comまた、技術ドキュメントではないいですが『三行で撃つ 〈善く、生きる〉ための文章塾』もおすすめです。この本は読者に向けた独特なアプローチで、文章技術の向上を目指す実用書です。作家の近藤康太郎氏によるこの本は、ただのテクニック本にとどまらず、書くという行為を通じて自己の実存を考えさせられる思想書としての側面も持ち合わせています。文章テクニックだけでなく、企画の立て方、時間・自己管理術、インプットの方法、思考の深め方に至るまで幅広くカバーし、リリカルな思想とロジカルな技術を融合させています。また、他人の目で空を見ず、自分だけの言葉で書くことの重要性や、「説明しない技術」を身に付けることの必要性を強調し、読者が自然に感情を動かされる文章を書くための技術を教えてくれます。文章を通じて善く生きるための深い洞察を提供する、稀有な一冊です。技術ドキュメントとの差異が分かるので理科系の作文技術や数学文章作法などと一緒に読むと自分がその時に書くべき文章がわかってくる。www.youtube.com同著者の近藤康太郎の『百冊で耕す 〈自由に、なる〉ための読書術』は、読む行為を通じて自己を見つめ、新しい自己を発見するための思想書としても機能します。速読や遅読、批判的読書や没入的読書など、対立する読書法を探求し、それらを融合させることで多面的な読書体験を提案しています。近藤氏は、「本は百冊あればいい」と述べ、読者に自分にとってのカノン(聖典)100冊を選び、深く読み込むことで、知識を内面化し、己の一部にする方法を説いています。本書は、読書のご利益を探求し、勉強、孤独、愛、幸せ、生きることについての疑問を掘り下げ、読むことで自分が変わり、他者や世界を愛する新たな自分を発見する旅を提案しています。達人プログラマー 第2版『達人プログラマー ―熟達に向けたあなたの旅― 第2版』は、David ThomasとAndrew Huntによる名著で、ソフトウェア開発者がより効率的かつ生産的になるための実践的アプローチを提供する一冊です。本書は特に今年読んだわけではないものの、非常に多く引用して、活用している価値のある本としてあげておきます。プログラマーとしての技術面だけでなく、問題解決の姿勢やプロフェッショナリズムについても深く掘り下げています。例えば、「猫がソースコードを食べちゃった」というセクションでは、責任を持つ重要性を強調し、「石のスープとゆでガエル」では、プロジェクト進行の重要なポイントを示唆します。また、「伝達しよう！」のセクションでは、効果的なコミュニケーションの重要性を説いています。また、プロジェクトマネジメントやチームワーク、プロフェッショナルとしての姿勢に関する深い洞察を提供し、エンジニアとしてのキャリアを積む上での貴重な指針となります。本書はあまりに網羅的な内容のため、各セクションに関連する本での補完が必要だと思います。しかし、特に技術系のポエム記事に触れたことがある読者には、この一冊を深く読み込むことを強くお勧めします。『達人プログラマー』は、プログラマーだけでなく、あらゆるソフトウェア開発に関わる全ての人にとって、読む価値のある一冊です。『SOFT SKILLS ソフトウェア開発者の人生マニュアル 第 2 版』も同様にオススメですがこちらの方がバラエティに富んでいるのでちょっとエンジニアリング以外のコラムも読みたい方はこちらの方がオススメです。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonスタッフエンジニア『スタッフエンジニア　マネジメントを超えるリーダーシップ』はWill Larsonによる本で、エンジニアリングキャリアのシニアレベル以上を目指す人にとって重要な指針を提供する一冊です。Will Larsonは、EM（エンジニアリングマネージャー）としてのチームのつくりかた、VPやDirectorとしての組織のつくりかたに関する洞察を提供する『An Elegant Puzzle』の著者でもあります。本書の洋書版を読む気力がなかった私にとって、翻訳本の出版はありがたいことでした。また、LarsonのHow to invest in technical infrastructureという記事も、共通基盤への投資方法について記述しており、非常に参考になるためオススメです。さて、本の内容に戻りますと、第1章ではスタッフエンジニアの役割とその意味を深く掘り下げ、技術力だけでなく組織内での影響力とリーダーシップの重要性を強調しています。これらの役割をどのように達成し、キャリアを前進させるかについて詳細に説明しており、特に印象的なのは、「スタッフエンジニアになれば自分の仕事を自分で管理でき、誰もがあなたに従い、あなたの望むことをするようになると考えたら大間違いだ」という言葉です。これはスタッフエンジニアの役割に関する一般的な誤解を解き明かしています。さらに、シニアエンジニアからスタッフプラスエンジニアへの進化を探る第3章、転職の決断を考慮する第4章、そして現役スタッフエンジニアのインタビューを通じて彼らの日常と役割の変化を深く掘り下げる第5章が続きます。全体を通して、この本は技術的なキャリアパスにおいてマネジメントの道を選ばないエンジニアにとって、必読の書です。各章は、スタッフエンジニアとしての役割を深く理解し、実現するための具体的な手法を提供しています。この本は、私のような経験豊富なエンジニアにとっても新たな学びとなり、これからのキャリアにおいて大いに参考になります。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonプロジェクト ヘイルメアリーTBDサーキット・スイッチャーTBD可燃物TBD大規模言語モデルは新たな知性か？TBDブラジャーで天下をとった男TBDさいごにこの年、多くの非技術書に没頭することで、私は内面的な成長と感情の豊かさを体験しました。各々の書籍が示した独特の感性や深い感動は、私の人間性を拡げ、心を満たしてくれました。皆さんからの心に残る作品の推薦も、来年の読書リストに追加し、楽しみにしています。読書はただの趣味にとどまらず、私たちの感情や人格を育て、深める重要な行為です。来年も、私と一緒に、心の成長と感動の旅に出ましょう。2024年も感動に満ちた読書の時を過ごし、新しい自分を見つけ、心の成長を遂げる一年となりますように。","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/21/165021","isoDate":"2023-12-21T07:50:21.000Z","dateMiliSeconds":1703145021000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2023年 俺が愛した本たち 技術書編","contentSnippet":"この記事は、3-shake Advent Calendar 2023 2日目のエントリ記事です。はじめに2023年がそろそろ幕を閉じようとしています。年末に差し掛かると、時間が流れる水のように止まらないことを感じながら、過ぎ去った一年を振り返るのは、私にとって欠かせない習慣です。この一年も、技術書の海に身を投じて、多くの本に心を奪われ、狂気のような積読を重ねました。積めば技術力が向上すると信じている。現代科学では解明できない電波が(諸説あり)積み上がった本からは出ていてこれらが私の知識の山となりました。が、来年はこの山を一歩一歩登り、購入する本の数を読む本の数に下回らせることを心に誓います。2023年は、特に技術の世界で学びは終わりがないことを実感した年でした。読書を通じて得た知識と経験は、来年もまた新たな知識の旅へと私を導くでしょう。昨年の読んだ本syu-m-5151.hatenablog.comはじめに有用情報2023年に読んでよかった技術書サイトリライアビリティワークブックSoftware Requirements Essentialsシステム障害対応 実践ガイドコンテナセキュリティTerraform: Up and Running, 3rd EditionEfficient GoKubernetes Best Practices, 2nd Editionルールズ・オブ・プログラミングさいごに有用情報昨年惜しまれつつ終了したACM会員特典、O'Reilly Online Learningの読み放題サブスクが、2023年に復活しました！これは大きなニュースですね。新しい年間料金は＄174と少々お高くなってしまいましたが、通常の＄499と比較するとかなりの節約です。ちなみに、私は5月に＄499でこのサブスクを手に入れました。興味がある方は、ACM登録ページより登録が可能です。ACM Professional Membership（年間＄99）にACM Skills Bundle Add-On（追加＄75）を組み合わせることで、O'Reilly Online Learning、Skillsoft Percipioのeラーニング、PluralsightのIT技術学習プラットフォームといった3つの学習コンテンツのサブスクを登録できます。2023年に読んでよかった技術書2023年は、読書から得た知識をソフトウェアエンジニアとしての実務経験に結びつけ、いくつかのイベントで登壇する機会に恵まれました。これらの登壇では、本で学んだ理論やアイデアを実際の業務に応用し、それらを共有することで得られた知見が非常に貴重なものでした。今後も、この経験を活かして、より多くの人々と知識を共有し、相互に学び合う機会を創出していきたいと考えています。また、2023年に私が特に愛読した本を紹介し、読書を通じたさらなる知見の共有を図っていく予定です。これらの本が、皆さんの技術的な成長や新しい洞察を得るための一助となれば幸いです。speakerdeck.comサイトリライアビリティワークブック『サイトリライアビリティワークブック ―SREの実践方法』は、『SRE サイトリライアビリティエンジニアリング』の実践編として、SRE（サイトリライアビリティエンジニアリング）を組織やプロジェクトに導入する際に必要な具体的な方法や手順を詳しく解説した本です。Google内部での技術的ノウハウに加え、Evernote、The Home Depot、New York Timesなど、様々な企業での事例を紹介しています。本書は、クラウド環境など制御できない環境での信頼性の高いサービスの実行方法、サービスレベル目標に基づくサービスの作成・監視・運用、運用チームをSREに変換する方法、新規開発や既存サービスにおけるSREの始め方などをカバーしています。また、SREとDevOpsの関係性についても詳しく触れています。この本は、前作『SRE サイトリライアビリティエンジニアリング』と対になる本であり、前作が原理と哲学を紹介するのに対し、本書はそれらの原理の適用方法に焦点を当てています。また、Googleだけでなく、さまざまな企業でのSREプラクティスについても解説しています。本書は前作と比較して内容が身近で読みやすく、SREの理解をさらに深めることができます。基本的な用語や他社の事例が分かりやすく説明されており、SREの実践に関して具体的かつ実用的な内容が盛り込まれています。さらに、分散システムの信頼性に関する知識を深めたい方には、『Go言語による分散サービス―信頼性、拡張性、保守性の高いシステムの構築』がおすすめです。この本は『Distributed Services with Go』の翻訳版であり、2022年8月に発売されました。また、『Designing Data-Intensive Applications』も非常に役立ちここ数年で最も読んでよかった技術書の一冊です。この本はデータ集約型アプリケーションの設計における核心的な概念と技術を網羅的に解説し、信頼性の高い分散システム構築に必要な知識が詳細に説明されています。時間を巻き戻して本を読む順番を選べるなら、もっと早く手に取りたかったと感じています。翻訳版である『データ指向アプリケーションデザイン』も知っておくと有益です。関連するイベントの詳細はこちらで確認できます。イベントは既に終了していますが、本の内容を深く理解し、専門家から新しい視点や知見を得る絶好の機会です。このイベントに参加することで、読書体験がより充実したものになることは間違いありません。動画www.youtube.com発表資料 speakerdeck.comちょっと脱線してしまいましたが総じて、『サイトリライアビリティワークブック ―SREの実践方法』は、SREを導入し、SREの考え方をプロダクト開発に導入しようとしている人にとって有益な情報が豊富に含まれています。サイトリライアビリティワークブック ―SREの実践方法オライリージャパンAmazon英語版を読みたい方のために、Googleが無料で公開しているリンクは以下です。sre.googleSoftware Requirements Essentials「私は過去 10 年間でベストセラーになった要件エンジニアリングの本 10 冊を読んだことがあります。この 1 冊には、それらの 10 冊を合わせたものよりも有益な情報が簡潔に記載されています。」--Mike Cohn, author of User Stories Applied and co-founder, Scrum Allianceこの表現が過剰ではないことがわかる一冊である。はやく読みたかった本つながりで。『Software Requirements Essentials: Core Practices for Successful Business Analysis』は、要件開発と管理における20のコアプラクティスを紹介する重要な本です。著者のKarl WiegersとCandase Hokansonは、伝統的なプロジェクトからアジャイルプロジェクトまで、あらゆるアプリケーションドメインにおいて、優れた価値を提供する可能性が最も高いプラクティスに焦点を当てています。これらのコアプラクティスは、チームがビジネス問題を理解し、適切な参加者を巻き込み、より良い解決策を明確にし、コミュニケーションを改善し、最も価値のある機能を適切な順序で実装し、変化と成長に適応するのに役立ちます。これもサブスクで読めるのでおすすめです。ソフトウェア要求 第3版 を読むほど時間がないのであればおすすめです。learning.oreilly.comソフトウェア要求 第3版 の本も読めます(原書)。やっててよかったO'Reillyサブスクlearning.oreilly.comこの本はソフトウェア要求 第3版を簡潔で焦点を絞った内容であり、「どのように」するかについての実用的な詳細がほどよく含まれているため、すべてのプロジェクト参加者におすすめできます。本書を使用することで、チーム全体が重要な概念、用語、技術、理論について共通の理解を築き、プロジェクトごとにより効果的に協力できます。主な内容には、問題の明確化、ビジネス目標の定義、ソリューションの境界設定、利害関係者と意思決定者の特定、ユーザータスク、イベント、応答の調査、データの概念と関係の評価、品質属性の取り扱い、要件の分析、モデリング、優先順位付け、要件の明確かつ整理された方法での記述、要件のレビュー、テスト、変更管理などが含まれています。Software Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon本当に良い内容だったのですが自分が本として言及するには深すぎる内容だったのでざっくり雰囲気を知りたい人はこちらのブログを確認してほしいです。agnozingdays.hatenablog.comシステム障害対応 実践ガイド『3カ月で改善！システム障害対応 実践ガイド』は、システム障害対応とプロセス改善の実践的なアプローチを提供する画期的な本です。著者の野村浩司氏と松浦修治氏は、それぞれNTTデータとリクルートでの豊富な経験を基に、実際の業務に即した方法を提供しています。本書の大きな特徴は、障害対応の具体的な手法を「メソッド化」している点です。理論だけでなく、「どうすればいいのか？」という実践的な問いに答えており、情報システム担当者や運用リーダーにとって最適な内容となっています。また、本書は障害対応の本質的価値にも触れています。障害対応の改善は、顧客満足度、従業員満足度、そして財務観点からもプラスの効果をもたらします。この点を丁寧に説明しており、運用担当者のモチベーション向上にも寄与する内容です。大規模な障害対応経験がない方でも、対応のイメージがつかめるように工夫されています。障害対応の難所にも言及し、読者が共感しやすい内容となっています。システム障害が起こりうるすべての現場の人々に推奨されるこの本は、システム障害対応をどのように捉え、判断し、対応するべきかについてのフローや表を豊富に掲載しています。これらは特にシステム障害マニュアルが整備されていないチームにとって非常に有用です。1000件以上の事例を分析し生み出されたこのメソッドは、障害対応改善のための役立つ雛形と共に、3カ月での改善を可能にします。インシデント分析から障害訓練まで、各プロセスに役立つ情報が満載です。システム障害対応における課題の特定から改善ステップまで、具体的なガイダンスを提供し、障害対応を改善するための実践的な指針を提供します。3カ月で改善！システム障害対応 実践ガイド インシデントの洗い出しから障害訓練まで、開発チームとユーザー企業の「協同」で現場を変える作者:野村 浩司,松浦 修治翔泳社Amazonまた、SREの観点からいうと『Implementing Service Level Objectives』は、SLO文化をゼロから構築するための具体的なガイダンスを提供する貴重な本です。著者のAlex Hidalgoは、ユーザーの視点からサービスの信頼性を測定するSLIの定義、SLO目標の選択と統計的分析、エラーバジェットの利用方法など、SLOベースのアプローチに必要なツールとリソースの構築について詳しく説明しています。このガイドは、SLOデータを活用して経営陣やユーザーに意味のあるレポートを作成する方法を含め、SLOの実装に関わる全てのステークホルダーにとって非常に価値ある本なので読んでほしいです。この分野では「Webエンジニアのための監視システム実装ガイド」、「運用設計の教科書 ~現場で困らないITサービスマネジメントの実践ノウハウ」などもとてもおもしろかったのでおすすめです。learning.oreilly.com国内でもIncident Responseの勉強会があったり、Awesome Incident Responseなどがあるので一読して見るのがよいかなって思いました。incident-response.connpass.comコンテナセキュリティ『コンテナセキュリティ：コンテナ化されたアプリケーションを保護する要素技術』は、Liz Riceによる原著『Container Security: Fundamental Technology Concepts that Protect Containerized Applications』の翻訳版で、コンテナセキュリティに関する深い理解を提供してくれる本です。www.youtube.comこの本は、コンテナへの攻撃経路、Linuxの構造、コンテナの堅牢化、設定ミスによるセキュリティ侵害のリスク、コンテナイメージビルドのベストプラクティスなど、コンテナセキュリティに関する要素技術を幅広くカバーしています。開発者、運用者、セキュリティ専門家にとって、コンテナセキュリティの理解を深めるための優れた本であり、翻訳を担当しました。コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術作者:Liz Rice,株式会社スリーシェイク　監修,水元 恭平　訳,生賀 一輝　訳,戸澤 涼　訳,元内 柊也　訳インプレスAmazon一方で、同様の本もリリースされております。『基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策』は、森田浩平著による、コンテナセキュリティの基本から応用までを解説した本です。Dockerの普及に伴い、コンテナ技術が広く使用されていますが、そのセキュリティ面についての理解が不十分な点が多々あります。この本は、コンテナ利用時のセキュリティ上の問題を防ぎ、安全に活用するための基本的なガイダンスを提供します。コンテナ型仮想化の概要、コンテナの主要な攻撃ルート、堅牢なコンテナイメージの作り方、セキュアなコンテナ環境の構築など、実践的な内容が盛り込まれています。ちなみにContainer Security Book というこれから Linux コンテナのセキュリティを学びたい人のための文書を公開しているのでこちらを最初に読んでみるのが良いかと思います。基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策 (Software Design plusシリーズ)作者:森田 浩平技術評論社Amazonこれらの本は、コンテナセキュリティに関心が高いエンジニアにとって、理論と実践のバランスを持ち、現代のコンテナ環境で必要とされる重要な知識とスキルを提供します。コンテナ技術のセキュリティ面に関する包括的な理解を深めるために、有益です。ちなみに『Docker: Up \u0026 Running, 3rd Edition』が2023年にリリースされました。コンテナ技術に関するめちゃくちゃ有用な本です。この最新版は、Sean KaneとKarl Matthiasによって、Dockerの登場から約10年間の大きな変化に対応して大幅に更新されています。知識の新陳代謝のためにもぜひ、読んでみてください。この本では、DockerやLinuxコンテナがクラウドサービスやKubernetesとどのように統合されるか、OCIイメージの構築、Linuxコンテナのデプロイと管理、依存関係管理やアプリケーションのデプロイワークフローの単純化、本番環境でのLinuxコンテナのデプロイとテストの実用的なテクニックなど、広範囲にわたるトピックが取り上げられています。BuildKit、マルチアーキテクチャイメージサポート、ルートレスコンテナなど、新機能の追加カバレッジもあります。learning.oreilly.comTerraform: Up and Running, 3rd Edition『Terraform: Up and Running, 3rd Edition』は、Terraformについての優れた入門書です。とりあえず、何も考えずにTerraform を書くなら読んでほしいです。本書は、Terraformを使用して、様々なクラウドや仮想化プラットフォームでインフラをコードとして定義、立ち上げ、管理する方法を示しています。著者Yevgeniy (Jim) Brikmanは、Terraformのシンプルで宣言的なプログラミング言語を通じて、インフラを数コマンドでデプロイおよび管理する方法を示すコード例を提供しています。この第3版は、Terraform 1.0に対応するために大幅に拡張され、最新の情報が追加されています。Terraformの基本から、大量のトラフィックをサポートし、大規模な開発チームを運営できるフルスタックの実行まで、システム管理者、DevOpsエンジニア、初心者開発者が素早く学べる内容になっています。本書の最大の特徴は、ただコードをコピー＆ペーストするのではなく、読者自身に実際に作業を行わせることを強く推奨している点です。実際に手を動かして学ぶことが、Terraformの理解を深める最善の方法だと著者は語っています。また、gitやdockerなど、本書で使用されるすべての技術について、読者が日常業務で別のツールを使用している場合でもついていけるようにミニチュートリアルが用意されています。さらに、本書は、IaC（Infrastructure as Code）とDevOpsの実践、Terraform、パブリッククラウド、バージョンコントロールの統合、プロビジョニングツールを通じてインフラを作成・デプロイする効果について、基本から細かなニュアンスまでをわかりやすく説明しています。実際にコードを書いてテストする経験は、初心者にとって非常に価値のある学びの機会となります。Infrastructure as Code の3版もEarly Releaseされています(翻訳されて...)。learning.oreilly.comTerraformは進化し続けており、最新機能は絶えず追加されています。例えばTerraform v1.6のtestが追加されますが本書では一切触れられておりません。そのため、最新のリリースや動向に注意を払い続けることが重要です。また、HashiCorpがTerraformを含む自社製品のライセンスをオープンソースから変更したこともあり、今後もその動向に注目する必要があるでしょう。Terraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名総じて、TerraformやIaCを学び、理解し、実践したい人にとって、非常におすすめの入門 本です。翻訳本が2023年11月21日に出ましたね。幸せです。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy Brikmanオーム社AmazonEfficient Go『Efficient Go: Data-Driven Performance Optimization』は、計測方法や目的設定から方法から始まり、様々なレベルでの効率を最適化する方法、CPUやメモリなどの一般的なリソースを効果的に使用する技術、Prometheus、Jaeger、Parcaなどのオープンソースプロジェクトを通じてメトリクス、ログ、トレーシング、（連続的な）プロファイリングによる効率評価方法、go test、pprof、benchstat、k6などのツールを使用して信頼性のあるマイクロおよびマクロベンチマークを作成する技術に至るまで、幅広い内容が網羅されています。また、Goの機能であるスライス、ジェネリクス、ゴルーチン、割り当てセマンティクス、ガベージコレクションなどを効率的に使用する方法についても解説されており、記事として散見されるものがまとめて読めることと自体に勝ちがある。加えて最適化の限界を超えると、得るものと失うものが等しくなるみたないマインドセットの部分も含めてとても価値があるのでGoやシステムの最適化を目指す方には必読の内容かと思います。Efficient Go: Data-Driven Performance Optimization作者:Plotka, BartlomiejOreilly \u0026 Associates IncAmazonKubernetes Best Practices, 2nd Edition『Kubernetes Best Practices, 2nd Edition』は、Kubernetesを活用してアプリケーションを構築するプロセスに焦点を当てた実践的なガイドです。著者たちは、分散システム、エンタープライズアプリケーション開発、オープンソース分野での豊富な経験を活かし、最新のKubernetesの機能や新しいツールに関する知見を提供しています。この本は、Kubernetesの基本概念に精通しているが、最新のベストプラクティスに迅速に対応したい開発者やアーキテクトに最適です。また、既にある程度の知識を持っている方にとって、知識を更新し、新たな視点を得るためのデトックスにも役立ちます。入門書を読みたいならKubernetes: Up and Running, 3rd Editionを読めばよいとおもいます。最新のKubernetesの機能、新しいツール、および廃止された機能についてカバーされており、意外と知らなかったり古くなっている知識があったので知識のデトックスにもオススメです。一方で、『Kubernetes Patterns, 2nd Edition』は、クラウドネイティブアプリケーションの設計と実装におけるパターンと原則に重点を置いています。著者のBilgin IbryamとRoland Hussは、再利用可能なパターンとKubernetesに特化した解決策を提供し、具体的なコード例を通じてこれらのパターンを実演します。読者は、コンテナベースのクラウドネイティブアプリケーションの構築と運用に関する基本原則や、より複雑なトピックを含む様々なパターンを学ぶことができます。個人的にはKubernetes Best Practices, 2nd Editionは良識ある大人が寄ってきてKubernetesについて手取り足取り教えてくれる本。learning.oreilly.comKubernetes Patterns, 2nd Edition はKubernetes について知りたいって言ったら勢いよくオタクが寄ってきてその全てを教えて去っていく本。learning.oreilly.com総じて、『Kubernetes Best Practices』はKubernetesの進んだ使い方やベストプラクティスに焦点を当てており、『Kubernetes Patterns』はKubernetesを用いたアプリケーション設計における具体的なパターンと原則に重点を置いています。どちらの本も、Kubernetesの利用を最大限に活かしたいと考える技術者にとって読んで損のない二冊だと思います。ルールズ・オブ・プログラミング『ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール』は、大ヒットゲーム『Ghost of Tsushima』の開発現場で培われた、ゲーム制作スタジオSucker Punch Productionsの共同創設者であるChris Zimmermanによる、すべてのプログラマーにとって必読のプログラミング哲学です。この本では、プログラミングに関する21の本質的なルールが紹介されており、単純化とバランスの取り方、バグの扱い、命名の重要性、一般化のプロセス、最適化のタイミング、コードレビューの価値、失敗の回避、実行されないコードの対応、複雑性の管理など、プログラミングにおける幅広いトピックにわたる洞察が提供されています。C++で書かれたコード例を用いながらも、C++の知識がない読者でも理解できるよう配慮されており、PythonやJavaScriptプログラマー向けのC++コード読解法も掲載されています。この本は、入門書では決してないですがトレードオフを意識したことがある全てのプログラマーにとってプログラミングの日々の課題を解決し、優れたコードを書くための実践的なガイドとして推奨されます。あと、この本はWIP: 2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるでも紹介した『プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ』の後に読んだのでそれらの制約やルールは人間の脳や認識の制約によって成り立っているものだなって思いました。ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール作者:Chris Zimmermanオーム社Amazonこちらは、『ルールズ・オブ・プログラミング』を2倍楽しむための1つのルール というイベントの動画があるのでぜひご覧いただきたいです。www.youtube.com『Good Code, Bad Code』は、Googleのテックリードである著者が、高品質なコードを書くための「コーディングの4つのゴール」と「品質6つの柱」を提案しています。この本は、コードの読みやすさ、誤用の防止、モジュール化、再利用性、テストのしやすさなど、日々の開発業務で直面する課題に対して、具体的で実践的なアドバイスを提供しています。著者の経験に基づいたアプローチは、プログラミングにおける理想論ではなく、現実的で実用的な解決策を提示しています。この本は、コードの品質を高めるための具体的な手法として「コーディングの4つのゴール」と「品質6つの柱」を提示しています。「コーディングの4つのゴール」には、1) 正しく動くこと、2) 正しく動作し続けること、3) 要件の変更に対応しやすいこと、4) 車輪の再発明をしないこと、が含まれます。これらのゴールは、コードの堅牢性と信頼性を保ちながら、変化に柔軟に対応できることを重視しています。また、「コード品質の6つの柱」は、1) 読みやすさ、2) 想定外の事態をなくす、3) 誤用しにくいコードを書く、4) モジュール化、5) 再利用・汎用化のしやすさ、6) テストのしやすさと適切なテスト、に焦点を当てています。これらは、コードを効果的かつ効率的に管理するための基本的な要素であり、エンジニアが日々の開発業務で直面する課題を解決するための実践的なアドバイスを提供しています。Good Code, Bad Code ～持続可能な開発のためのソフトウェアエンジニア的思考作者:TomLong,秋勇紀,高田新山,山本大祐秀和システムAmazonあと、忘れてほしくないのが我らがKent Beck先生の『Tidy First?』（日本語訳：まずは整理整頓）です。この実践的ガイドでは、エクストリーム・プログラミングの創始者でありソフトウェアパターンの先駆者である著者が、コードを読みやすく整理する「タイディング（Tidying）」の適切なタイミングと場所を提案しており、大きな関数や複雑なシステムを小さなステップで安全に改善する方法、ソフトウェア設計の理論的な側面と実践的なスキルの融合など、人間関係の観点からのソフトウェア設計を深く掘り下げています。この本は、単にコードを綺麗にするテクニックを教えるだけでなく、ソフトウェアの品質を向上させ、開発プロセスを効果的かつ効率的にするための全体的な視野を提供してくれます。技術コンサルティングを行う上で、この本を参考にする機会が多く、多くのプロジェクトでその洞察とアプローチが非常に役立ちました。learning.oreilly.comこれらの本に本当に優劣とかないですが同系統の書籍なので一緒に紹介させていただきました。さいごに今年一年を通して読み漁った数々の技術書は、私にとって新たな知識の扉を開く鍵となりました。それぞれの本が持つ独自の視点や深い洞察は、技術者としての私の視野を広げ、思考を豊かにしてくれました。皆さんからのおすすめの本も、来年の読書リストに加えて楽しみにしています。読書は単なる趣味ではなく、私たちの知識を形成し、成長させる重要な行為です。皆さんも、来年は私と一緒に、新たな知識の探求に挑戦してみませんか？ それでは、2024年も充実した読書ライフをお過ごし下さい。読書を通じて、皆さんが新しい自分を発見し、さらなる成長を遂げる一年となりますように。","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/02/141455","isoDate":"2023-12-02T05:14:55.000Z","dateMiliSeconds":1701494095000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『走馬灯のIaCは考えておいて』というタイトルで登壇しました。","contentSnippet":"概要2023年11月23日、私は技術的負債に向き合う Online Conference 」にて「走馬灯のIaCは考えておいて - Infrastructure as Codeの導入において技術的負債を考える」というテーマで登壇しました。このセッションでは、Infrastructure as Code（IaC）の実践方法と、技術的負債に対処する際の考慮点について深掘りしました。資料かなり概念系の資料になっているので実践編の登壇の登壇したいので誰か招待してくれ！！！この辺を先に整理しておかないと先の進化的アーキテクチャやA Philosophy of Software Designの話ができないので前提条件をまとめておきました。 speakerdeck.com技術的負債というメタファー に対する違和感私は、技術的な負債についての一般的な表現に違和感を感じています。この点で、まつもとりーさんも技術的負債という表現に対して抵抗を感じていたようです。M年N回目なんですけど、技術的負債という言語化にはずっと抵抗がありまして.......困ったな— まつもとりー / Ryosuke Matsumoto (@matsumotory) 2023年11月21日  この言葉の「負債」という部分が、技術的な問題の本質や性質を正確に捉えていないと感じたため、私は「技術的な腐敗と発酵」という言葉に置き換えることにしました。この新しいメタファーは、技術的問題が時間の経過とともに変化し、時には複雑化や悪化するプロセスをより的確に表現しています。例えば、「腐敗」は、問題が放置されることでシステムの健全性が低下する様子を示し、「発酵」は、初めは小さな問題が時間とともに変化し、場合によっては新たな価値を生み出す可能性があることを意味します。この観点から、私は自身のプレゼンテーションや議論の中で、技術的な問題を扱う際にこれらの言葉を使用しました。普通に元ネタがあります。メタファーとしての発酵 (Make: Japan Books)作者:Sandor Ellix KatzオライリージャパンAmazon実生活の発酵と腐敗の違い実生活における「発酵」と「腐敗」はどちらも微生物の作用による物質の変化プロセスであり、人間にとっての利益に基づいて定義されます。発酵は、生物の作用によって物質が変化し、人間にとって有益なものに変わるプロセスを指し、ヨーグルト、チーズ、醤油などが例として挙げられます。一方、腐敗は同じく微生物の作用による物質の変化ですが、不快な臭いや有害な物質が発生し、人間にとって有害とされるプロセスを指します。この考え方は、インフラの世界にも当てはまります。時間の経過とともに技術が進化し、新しい技術が古い技術に取って代わることが多い中で、長く使用され信頼性が高まった「枯れた技術」は発酵に、時代遅れとなりリスクを引き起こす技術は腐敗に例えられます。これにより、古い技術を見直し、必要に応じて新しい技術に移行するかの判断が容易になり、インフラの健全性と持続可能性を保つ上で重要な役割を果たします。発酵と腐敗・熟成の違いって何？負債と言わないことが負債と向き合うこと「負債と言わないことが負債と向き合うこと」という素晴らしい発表があった。メタファーの限界と実際の技術的課題への取り組みの重要性を改めて感じました。この発表は、言葉だけでなく、根本的な問題解決に焦点を当てることの大切さを示しています。私は向き合わずに逃げたので...。確かに、メタファーは理解を深めるための一つの手段ですが、それにとどまらず、具体的な問題や課題に目を向け、解決策を見つけて実行することが不可欠です。この点において、私は自分の業務、特にSRE（Site Reliability Engineering）の領域において「トイル」という用語が使われていることに気づきました(これも状況を整理するためのメタファーではある)。「トイル」とは、SREのコンテキストで使われる用語で、繰り返し行われる、自動化されていない、戦略的価値の低い作業を指します。この用語を用いることで、SREは単に作業を行うのではなく、その作業がなぜ存在し、どのように改善できるかを考えるように促されます。このような言葉の使い方は、メタファーを超えて、実際の作業の性質や価値を正確に捉え、それに基づいて改善策を模索する手助けとなります。最終的には、このような言葉の使い方が、より効果的で生産的な仕事に取り組むことができます。言葉は単なるコミュニケーションの道具ではなく、私たちの思考や行動に影響を与える強力なツールです。そのため、技術的な課題に取り組む際には、適切な用語を選び、それを戦略的に活用することが重要です。sreake.com speakerdeck.com何が技術的負債に変わるのか技術的負債という言葉のメタファーとしての強さ。技術的負債に向き合う幾つかのヒントをいくつかいただいたので気になった人はぜひ、読んでみてほしい。junkyard.song.mu決定版・ゲームの神様 横井軍平のことばが気になったのでAmazonで調べたところ2023年11月21日現在では20000円だった。ソフトウェアの内部品質に生じる様々な問題は組織設計にその原因があることも多い良い内容だったので感想書く speakerdeck.com異なる思想で書かれたコードの統一に動く -Terraformの場合-良い内容だったので感想書く speakerdeck.com技術的負債が生まれる背景を理解して，アーリーからレイター向けの根本的なアプローチを考える良い内容だったので感想書く speakerdeck.com参考資料Infrastructure as CodeInfrastructure as Code 再考Infrastructure as Codeのこれまでとこれから/Infra Study Meetup #1わたしたちにIaCはまだ早かったのかもしれないThe History of DevOps ReportsEffective DevOpsLeanとDevOpsの科学[Accelerate] テクノロジーの戦略的活用が組織変革を加速する継続的デリバリーのソフトウェア工学:もっと早く、もっと良いソフトウェアを作るための秘訣メタファーとしての発酵Hashicorp DeveloperChef InfraAnsible - Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain.aws-cdk - The AWS Cloud Development Kit is a framework for defining cloud infrastructure in codePulumi - Infrastructure as Code in any programming language.dapr - Dapr is a portable, event-driven, runtime for building distributed applications across cloud and edge.dagger - Application Delivery as Code that Runs AnywhereInfrastructure as Code, 3rd EditionPlatform Engineering MeetupBackstage - Backstage is an open platform for building developer portalsbackstage.ioWhat is platform engineering?DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティスウェブオペレーション―サイト運用管理の実践テクニック","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","isoDate":"2023-11-21T04:21:44.000Z","dateMiliSeconds":1700540504000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文","contentSnippet":"はじめに前回の続きで第四部のV. Delivering Infrastructure (インフラストラクチャの提供)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第五部 目次V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)この章では、スタック定義、サーバー設定、モジュール、ライブラリ、テスト、設定、ユーティリティなど、さまざまな種類のコードが含まれる可能性があります。これらのコードをプロジェクト間およびリポジトリ内でどのように整理するか、またインフラストラクチャコードとアプリケーションコードを一緒に管理するべきか、分けるべきかという問題が提起されています。これには、複数部分からなるエステートのコードをどのように整理するかという課題も含まれます。Organizing Projects and Repositoriesこのセクションでは、プロジェクトがシステムの個別のコンポーネントを構築するために使用されるコードの集まりであると説明されています。プロジェクトやそのコンポーネントがどれだけ含むべきかについての硬いルールはありません。プロジェクト間の依存関係と境界は、プロジェクトコードの整理方法に明確に反映されるべきです。コンウェイの法則によれば、組織の構造とそれが構築するシステムの間には直接的な関係があります。チーム構造とシステムの所有権、およびそれらのシステムを定義するコードの不整合は、摩擦と非効率を生み出します。One Repository, or Many?複数のプロジェクトを持つ場合、それらを単一のリポジトリに入れるべきか、複数のリポジトリに分散させるべきかという問題があります。コードを同じリポジトリに保持すると、バージョン管理やブランチ化が一緒に行えるため、いくつかのプロジェクト統合およびデリバリー戦略を簡素化します。One Repository for Everythingすべてのコードを単一のリポジトリで管理する戦略は、ビルド時のプロジェクト統合パターンでうまく機能します。この戦略では、リポジトリ内のすべてのプロジェクトを一緒にビルドしますが、アプリケーションパッケージ、インフラストラクチャスタック、サーバーイメージなど、複数の成果物を生み出すことがあります。Figure 18-1. Building all projects in a repository togetherA Separate Repository for Each Project (Microrepo)各プロジェクトごとに別のリポジトリを持つ戦略は、プロジェクト間のクリーンな分離を保証します。特に、各プロジェクトを別々にビルドしてテストするパイプラインを持つ場合に効果的です。Multiple Repositories with Multiple Projects一つのリポジトリですべてを管理する極端な戦略と、各プロジェクトごとに別のリポジトリを持つ極端な戦略の間で、多くの組織は複数のリポジトリを持ち、複数のプロジェクトを含む方法を採用しています。Organizing Different Types of Code異なるタイプのコードを整理する戦略を持つことは、コードベースを維持可能にするのに役立ちます。例えば、スタックのプロジェクトレイアウトは、インフラストラクチャスタックコード、テストコード、設定ファイル、デリバリー設定などを含む可能性があります。Delivering Infrastructure and Applicationsアプリケーションとインフラストラクチャのコードを一緒に管理するか、別々にするかという選択は、組織の構造と所有権の分割に依存します。アプリケーションチームがインフラストラクチャに関する責任を持つ場合、コードを分けることは認知的な障壁を生み出す可能性があります。システムのインフラストラクチャのアーキテクチャ、品質、および管理をコードベースから導くという概念を持っています。したがって、コードベースはビジネス要件とシステムアーキテクチャに応じて構築され、管理される必要があります。それはまた、チームが効果的であるためのエンジニアリング原則と実践をサポートする必要があります。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)インフラストラクチャコードのデリバリーについての章では、ソフトウェアのデリバリーライフサイクルが重要なコンセプトとして強調されています。しかし、インフラストラクチャのデリバリーは、しばしば異なるタイプのプロセスに従います。例えば、本番環境でテストされないハードウェアの変更が一般的です。しかし、コードを使ってインフラストラクチャを定義することで、より包括的なプロセスで変更を管理する機会が生まれます。例えば、サーバーのRAMを変更するような手動で構築されたシステムへの変更を開発環境で複製することは、ばかげているように思えるかもしれません。しかし、コードで実装された変更は、パイプラインを通じて本番環境へ簡単に展開することができます。Delivering Infrastructure Codeパイプラインのメタファーは、インフラストラクチャコードの変更が開発者から本番インスタンスへ進む方法を説明しています。このデリバリープロセスに必要なアクティビティは、コードベースの整理方法に影響を与えます。Figure 19-1. Infrastructure code project delivery phasesBuilding an Infrastructure Projectインフラストラクチャプロジェクトのビルドは、コードを使用するための準備を行います。これには、ライブラリの取得、ビルド時の設定の解決、コードのコンパイルまたは変換、テストの実行、ツールが適用するためのフォーマットでコードを準備することなどが含まれます。Packaging Infrastructure Code as an Artifact一部のツールでは、「コードの使用準備」は特定のフォーマットのパッケージファイルにファイルを組み立てることを意味します。これは、Ruby（gems）、JavaScript（NPM）、Python（pipインストーラーを使用するPythonパッケージ）などの一般的なプログラミング言語で一般的なプロセスです。Using a Repository to Deliver Infrastructure Codeチームはソースコードリポジトリを使用して、インフラストラクチャソースコードの変更を保存し、管理します。多くのチームは、環境やインスタンスにデリバリーする準備ができたコードを保存するために、別のリポジトリを使用します。Figure 19-2. Build stage publishes code to the delivery repositoryIntegrating Projects「Organizing Projects and Repositories」で述べたように、コードベース内のプロジェクト間には通常、依存関係があります。次に、互いに依存するプロジェクトの異なるバージョンをいつ、どのように組み合わせるかという問題があります。Pattern: Build-Time Project Integrationビルド時のプロジェクト統合パターンは、複数のプロジェクトをまたいでビルドアクティビティを実行します。これには、それらの依存関係を統合し、プロジェクト間のコードバージョンを設定することが含まれます。Pattern: Delivery-Time Project Integrationデリバリー時のプロジェクト統合パターンは、それぞれのプロジェクトを個別にビルドおよびテストした後で組み合わせます。このアプローチでは、ビルド時の統合よりも後の段階でコードのバージョンを統合します。Pattern: Apply-Time Project Integration適用時のプロジェクト統合は、複数のプロジェクトを別々にデリバリーステージを進めることを含みます。プロジェクトのコードに変更が加えられたとき、パイプラインはそのプロジェクトの更新されたコードをそのプロジェクトのデリバリーパスの各環境に適用します。Using Scripts to Wrap Infrastructure Tools多くのチームは、インフラストラクチャツールをオーケストレーションし、実行するためにカスタムスクリプトを作成します。これには、Make、Rake、Gradleなどのソフトウェアビルドツールを使用する場合や、Bash、Python、PowerShellでスクリプトを書く場合があります。多くの場合、このサポートコードはインフラストラクチャを定義するコードと同じくらい、またはそれ以上に複雑になり、チームはそのデバッグと維持に多くの時間を費やすことになります。確実で信頼性の高いインフラストラクチャコードのデリバリープロセスを作成することは、4つの主要なメトリクスに対して良好なパフォーマンスを達成するための鍵です。あなたのデリバリーシステムは、システムへの変更を迅速かつ信頼性高くデリバリーすることの実際の実装です。Only build packages once. を参考にしてください。20. Team Workflows (チームワークフロー)IaCを利用することによる作業方法の根本的な変化に焦点を当てています。従来のアプローチとは異なり、仮想サーバーやネットワーク構成の変更をコマンド入力やライブ設定の直接編集ではなく、コードの記述と自動化システムによる適用を通じて行います。これは新しいツールやスキルの習得を超えた変化であり、インフラストラクチャを設計、構築、管理する全ての人々の働き方に影響を与えます。Figure 20-1. A classic mapping of a dedicated team to each part of a workflowThe People信頼できる自動化ITシステムでは、人々が重要な役割を果たします。コード変更を本番システムに反映させるためには、テスト結果のレビューやボタンの操作以外に、人の手は必要ありませんが、システムの継続的な構築、修正、適応、改善には人間が不可欠です。Who Writes Infrastructure Code?組織によってインフラストラクチャコードを誰が書くかという問いに対する答えは異なります。伝統的なプロセスとチーム構造を維持しようとする組織では、インフラストラクチャを構築（およびサポート）するチームがインフラストラクチャ・アズ・コードのツールを使用して作業を最適化します。また、多くの組織ではアプリケーションチームが自分たちのアプリケーションに必要なインフラストラクチャを定義しています。Applying Code to Infrastructureインフラストラクチャへのコード適用に関する一般的なワークフローは、共有ソースリポジトリ内のコードから始まります。チームメンバーは最新バージョンのコードを自分の作業環境にプルし、編集した後、ソースリポジトリにプッシュして新しいバージョンのコードを様々な環境に適用します。Applying Code from Your Local Workstationローカルワークステーションからインフラストラクチャコードを適用することは、他の誰も使用していないインフラストラクチャのテストインスタンスに対しては有用です。しかし、ローカル作業環境からツールを実行すると、共有インフラストラクチャインスタンスに問題を引き起こす可能性があります。Applying Code from a Centralized Serviceインフラストラクチャコードをインスタンスに適用するために、中央集権的なサービスを使用できます。このサービスはソースコードリポジトリまたはアーティファクトリポジトリからコードをプルし、インフラストラクチャに適用します。Personal Infrastructure Instances理想的には、共有リポジトリにプッシュする前にコード変更をテストできる方法があります。これにより、変更が期待通りの動作をするかどうかを確認でき、パイプラインがオンラインテストステージまでコードを実行するのを待つよりも高速です。Source Code Branches in Workflowsソースリポジトリのブランチは、コードベースの異なるコピー（ブランチ）で作業を行い、準備ができたら統合する際に役立ちます。Martin Fowlerの記事「Patterns for Managing Source Code Branches」には、チームのワークフローの一部としてブランチを使用する様々な戦略やパターンが説明されています。Preventing Configuration Drift設定のドリフトを防ぐために、ワークフローにおいていくつかの対策を講じることができます。これには、自動化の遅れを最小限に抑える、アドホックな適用を避ける、コードを継続的に適用する、不変のインフラストラクチャを使用するなどが含まれます。Governance in a Pipeline-based Workflowパイプラインベースのワークフローにおけるガバナンスでは、責任の再配置、左へのシフト、インフラストラクチャ・アズ・コードのガバナンスを持つ例示プロセスなどが議論されます。インフラストラクチャをコードとして定義する組織では、人々は日々のルーチン活動やゲートキーパーとしての作業に費やす時間が減り、システム自体の改善能力を向上させるためにより多くの時間を費やすことになるはずです。彼らの努力は、ソフトウェアのデプロイおよび運用パフォーマンスの4つの指標に反映されます。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)Chapter 21: Safely Changing Infrastructure21. Safely Changing Infrastructure本章では、インフラの迅速かつ頻繁な変更の重要性に焦点を当てています。私のSREとしての経験では、速さと安定性は相補的な要素であることが多くのプロジェクトで証明されています。特に、インフラストラクチャー・アズ・コード(IaC)の実践において、このアプローチは効率と品質を大幅に向上させることができます。変更の頻度を上げることで、小さな問題を迅速に検出し、修正することが可能になります。Reduce the Scope of Change小さな変更の範囲を制限することは、リスクの軽減に寄与します。私の経験からも、小さな変更ほど管理が容易であり、予期せぬ問題への対応も迅速になるということが証明されています。このアプローチは、大規模な変更を小分けにして取り組むことで、変更の複雑性とリスクを管理するのに有効です。Figure 21-2. Plan to split out multiple stacksSmall Changes小さな変更を積極的に行うことの利点は、私のプロジェクト経験で明らかです。バッチサイズを小さくすることで、リスクを最小限に抑え、より迅速なフィードバックを得ることが可能になります。これは特に複雑なシステムにおいて、問題の特定と修正を容易にします。小さな変更は、大きなリリースの複雑さを減らし、より継続的なデリバリーを可能にします。Example of Refactoringリファクタリングの例は、コードベースを改善し、将来の変更を容易にするための重要な手段です。実際、私の経験では、リファクタリングはしばしば次のステップへの道を開くための重要なプロセスであり、これによりコードの保守性と拡張性が向上します。リファクタリングは、既存の機能を維持しつつ、コードの構造を改善することで、新しい機能の追加や将来的な変更を容易にします。Pushing Incomplete Changes to Production不完全な変更を本番環境に押し出すことは、段階的なデプロイメントの一環として重要です。この戦略は、変更の影響を小さく保ちながらも、継続的な進化を促進します。特に、リリース前のテスト段階でのフィードバックを得るために役立ちます。Parallel Instances並行インスタンスの概念は、本番環境でのリスクを軽減する上で非常に効果的です。これにより、新しい変更を既存のシステムと並行してテストし、徐々に本番環境に移行することが可能になります。これは、特に大規模なシステムや重要な機能の更新において、ダウンタイムを避けるための重要な戦略です。Backward Compatible Transformations後方互換性を持つ変更は、サービスの中断を防ぎつつ進化を遂げるための鍵です。このアプローチにより、既存の機能を維持しつつ、新しい機能や改善を段階的に導入することができます。これは、システムの安定性を保ちながらも、進歩と成長を促すために非常に効果的です。Feature Toggles機能トグルは、新旧の機能を柔軟に管理できる強力なツールです。これにより、新しい機能を段階的に導入し、必要に応じて迅速に変更を反映することができます。段階的なデプロイメントやA/Bテストにおいてこの技術は特に有効で、リスクを最小限に抑えつつ、ユーザーの反応を評価することができます。Changing Live Infrastructureライブインフラの変更は、サービスの中断を最小限に抑えながらインフラを最新の状態に保つために不可欠です。このセクションでは、インフラストラクチャーの更新がサービスの連続性に与える影響を最小限に抑えるための技術と戦略が紹介されています。Infrastructure Surgeryインフラの手術は、既存のインフラを修正しつつサービスを維持するための洗練された方法です。これにより、サービスの中断を最小限に抑えながら、重要なインフラの変更や改善を行うことができます。このアプローチは、特にデータ損失のリスクを最小限に抑えたい場合や、既存のシステムを段階的に改善したい場合に有効です。Expand and Contract拡張と収縮のパターンは、インフラの柔軟性を最大限に活用する素晴らしい方法です。このアプローチは、リソースの効率的な利用とスケーラビリティの向上に寄与します。特にクラウド環境において、この手法を利用することで、リソースの迅速な拡張と収縮が可能になり、需要の変動に応じたスケーリングが実現できます。Zero Downtime Changesダウンタイムのない変更は、ユーザーエクスペリエンスを維持しつつ、システムのアップデートを行う上で非常に重要です。これにより、サービスの中断を防ぎつつ、新しい機能や修正を順次適用することができます。この手法は、特にユーザーへの影響を最小限に抑えたい場合に有効です。Continuity継続性は、変更管理における中心的な考え方です。エラーを防ぐことによる継続性、速やかな回復による継続性、継続的な災害復旧、カオスエンジニアリング、そして失敗計画は、システムの安定性と耐久性を確保するために重要な要素です。これらのアプローチは、リスクを軽減し、システムの回復力を高めるのに役立ちます。Continuity by Preventing Errorsエラーを予防することによる継続性は、事前の計画と迅速な回復のバランスを取ることが重要です。このアプローチにより、システムの安定性を維持しながら、予期せぬ問題に迅速に対応することが可能になります。エラーの予防と迅速な修正は、特に大規模なシステムにおいて、サービスの連続性と信頼性を確保するために不可欠です。Continuity by Fast Recovery速やかな回復による継続性は、現代のインフラにおいて不可欠な要素です。システムの迅速な回復は、特に予期せぬ障害やエラーが発生した場合に、サービスの中断を最小限に抑えるために重要です。これは、特にビジネスクリティカルなアプリケーションやサービスにおいて、信頼性と利用可能性を確保するための鍵となります。Continuous Disaster Recovery継続的な災害復旧は、システムの耐障害性を高め、ビジネスの継続性を保証するために不可欠です。このアプローチは、システムの変更に関連するリスクを管理し、不測の事態が発生した場合に迅速に対応できるようにすることが重要です。私の経験では、継続的な災害復旧の計画と実施は、組織の全体的なリスク管理戦略の核心部分を形成します。これにより、システムが予期せぬ障害にも迅速に対応し、サービスの継続性を維持できるようになります。システムのバックアップと復旧プロセスを定期的にテストし、改善することで、災害発生時のリカバリー時間を短縮し、ビジネスへの影響を最小限に抑えることが可能です。Chaos Engineeringカオスエンジニアリングは、システムの弱点を明らかにし、それらを改善するための実践的なアプローチです。この手法は、システムの耐障害性を試験し、実際の環境での挙動を理解するのに非常に有効です。私のキャリアの中で、カオスエンジニアリングはシステムの弱点を早期に特定し、それに対処する機会を提供する重要なツールとなっています。意図的に障害を引き起こすことで、システムの回復力をテストし、実際の災害時に備えることができます。このようなプラクティスにより、システムの安定性と信頼性が向上し、ユーザー体験の質が保たれます。Planning for Failure失敗計画は、システムの回復力を高めるために重要です。失敗を計画することは、システムの弱点を特定し、それらに対応するための戦略を立てることを意味します。私が経験したプロジェクトでは、様々な失敗シナリオを想定し、それぞれに対する回復計画を策定することが、システムの全体的な堅牢性を高める上で非常に重要でした。失敗計画は、リスクの評価と緩和策の策定を通じて、システムの安全性と効率性を保証します。また、失敗に迅速かつ効果的に対応するための準備とプロセスを確立することで、ビジネスの中断を最小限に抑えることができます。Data Continuity in a Changing Systemデータの連続性は、変更のあるシステムにおいて最も重要な側面の一つです。私の経験では、データの安全性と一貫性を維持することは、サービスの品質と顧客信頼の基盤となります。Lockロック機能は、特定のリソースを変更から保護する効果的な方法です。しかし、自動化と手動の介入のバランスを見極めることが重要です。過度に手動の介入に依存することはリスクを高める可能性があります。Segregateデータを他のシステムコンポーネントから分離することにより、より柔軟かつ安全に変更を行うことが可能になります。このアプローチは、データを中心としたアーキテクチャ設計において特に有効です。Replicateデータの複製は、可用性と耐障害性の向上に寄与します。分散型データベースのようなシステムでは、データの複製が自動化されることが多く、このプロセスはデータの保護に不可欠です。Reloadデータの再ロードやバックアップは、データ損失を防ぐ上で基本的です。バックアップと復元のプロセスを自動化することで、データの信頼性とアクセス性が大幅に向上します。Mixing Data Continuity Approachesデータの継続性を確保する最善の方法は、分離、複製、再ロードの組み合わせです。この複合的なアプローチにより、データの安全性とアクセス性の両方を最大化できます。データの継続性は、単一の手法に依存するのではなく、複数の手法をバランスよく組み合わせることで、最も効果的に実現されます。この章の締めくくりでは、インフラ変更におけるデータの継続性の重要性が強調されています。クラウド時代におけるインフラ管理の進化に伴い、速度と品質のバランスを取りながらも、データの安全性を維持することの重要性が明確にされています。データはビジネスの中心にあり、その連続性と安全性を確保することが、サービスの品質と顧客信頼を維持するための鍵であることが再確認されます。総括 Infrastructure as Code, 2nd Edition の読書感想文『Infrastructure as Code, 2nd Edition』は、現代のITインフラストラクチャ管理の進化に対応するための重要なガイドです。この書籍は、インフラストラクチャをコードとして扱うことの重要性と、それを実現するための具体的な方法を体系的に説明しています。第一部では、インフラストラクチャをコードとして管理する基本原則に焦点を当て、クラウド時代のダイナミクスを解説しています。特に、変更の速度を利用してリスクを減らし、品質を向上させる新しいマインドセットの必要性が強調されています。第二部では、インフラストラクチャスタックの構築と管理に関して詳述し、スタックの構築、環境の設定、および継続的なテストと提供の重要性について論じています。ここでは、インフラストラクチャの自動化におけるスタックの重要性を明確にし、技術的な洞察と実践的な指針を提供します。第三部は、サーバーと他のアプリケーションランタイムプラットフォームとの作業に注目し、アプリケーションランタイム、サーバーのコード化、サーバーへの変更管理などを取り上げています。この部分は、アプリケーション主導のインフラストラクチャ戦略を通じて、現代の動的インフラを使用してアプリケーションランタイム環境を構築する方法に重点を置いています。第四部では、インフラストラクチャの設計に関して、小さく単純な部品の使用、モジュラリティ、コンポーネント設計のルール、モジュール化、およびスタックコンポーネントの設計パターンとアンチパターンについて論じています。このセクションは、効率的で持続可能なインフラストラクチャを設計するための具体的な方法とベストプラクティスを提供します。第五部では、インフラストラクチャコードの整理、提供、チームワークフロー、およびインフラストラクチャの安全な変更に焦点を当てています。インフラストラクチャコードの整理と管理、デリバリープロセス、プロジェクトの統合、および安全な変更の方法に関する洞察が提供されています。全体として、この書籍は、インフラストラクチャとしてのコードの採用と適用において、技術者や専門家に重要な洞察と価値ある情報を提供し、インフラストラクチャ管理の現代的なアプローチを実現するための実践的なガイドとなっています。その詳細な解説と実用的なアドバイスは、この分野で働く専門家にとって非常に役立つものです。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/161320","isoDate":"2023-11-16T07:13:20.000Z","dateMiliSeconds":1700118800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文","contentSnippet":"はじめに前回の続きで第四部のIV. Designing Infrastructure (インフラストラクチャの設計)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com次回の記事* Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第四部 目次IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)Designing for Modularityモジュラリティの設計は、システムの変更を安全かつ容易にすることを目的としています。これは、ソフトウェア開発経験においても非常に重要です。モジュール式の設計は変更管理を簡素化し、技術的負債の蓄積を防ぐ効果があります。インフラコードにおいても、このアプローチは同様に有効であり、システムの成長に伴う複雑さとリスクを管理するための鍵となります。コンポーネントをより小さく、単純に保つことで、システム全体の品質と反応性が向上します。Characteristics of Well-Designed Components良く設計されたコンポーネントは、低い結合度と高い凝集度を持ちます。これは、各コンポーネントが独立して機能し、他の部分に影響を及ぼすことなく変更可能であることを意味します。これらの特徴はシステムの長期的な安定性とメンテナンスの容易さに大きく貢献します。低結合度は、一部の変更が全体のシステムに広範な影響を与えるリスクを最小限に抑え、高凝集度は、コンポーネントがその機能に集中し、より効率的に動作することを可能にします。Rules for Designing Componentsコンポーネントの設計におけるルールには、重複の排除や単一責任原則などが含まれます。これらはコードの可読性と保守性を高め、変更を容易にします。重複の排除は、同じ機能やデータの複数のコピーを避けることで、変更時の労力を減らし、エラーの可能性を下げます。一方、単一責任原則は、各コンポーネントが一つの機能または責任を持つべきであるという原則です。これにより、システムはより整理され、理解しやすくなります。Use Testing to Drive Design Decisionsテスト駆動設計は、インフラコードの品質を向上させます。テストは、コードの継続的な改善を促進し、設計の効率化に寄与します。テスト可能なコードは、自然とより良い設計に導かれます。テストを重視することで、コードの変更が容易になり、新しい機能の追加や既存機能の改善がスムーズに行えるようになります。また、自動化されたテストは、システムの信頼性を確保し、デプロイメントプロセスを加速します。Modularizing Infrastructureインフラのモジュラー化は、システムの柔軟性とスケールアップを促進します。構成要素を効果的に分割することで、変更が容易になり、システムの拡張がスムーズに行えます。このアプローチは、インフラストラクチャの管理と運用においても有効であり、特に大規模なシステムでは、異なる部分を個別に更新、拡張、または縮小できる柔軟性が重要です。モジュール化されたインフラストラクチャは、変更のスピードを高め、システムの全体的な効率を改善します。Stack Components Versus Stacks as Componentsスタックコンポーネントとしてのスタックは、独立性を提供し、変更を容易にします。分離されたスタックは変更管理とスケーラビリティにおいて重要な役割を果たします。スタックとしてのコンポーネントは、システムの一部として独立してデプロイおよび管理することができ、これにより大規模な変更や障害が他の部分に波及するリスクを最小限に抑えます。Figure 15-1. Shared code module used by two stacks より引用Using a Server in a Stackスタック内でサーバーを使用することは、設定変更の容易さを提供します。これにより、運用上の柔軟性が高まります。サーバーをスタックの一部として扱うことで、サーバーの設定やソフトウェアの更新が簡単になり、システム全体のメンテナンスが容易になります。また、サーバーの迅速な追加や削除が可能となり、システムのスケーラビリティが向上します。Drawing Boundaries Between Componentsコンポーネント間の境界を適切に設定することは、システムの成長と変更を管理する上で重要です。これはシステムの安定性と拡張性を支えます。境界線を引くことで、システムの異なる部分を明確に区分し、それぞれが独立して機能し、互いに干渉しないようにします。これにより、システムの一部を変更しても、他の部分に予期しない影響を与えるリスクが減少します。Align Boundaries with Natural Change Patterns変更パターンに合わせた境界線は、システムの自然な進化を促進します。これにより、継続的な改善が可能になります。システムの異なる部分がどのように変化し、成長するかを理解することで、それらの部分を適切に区分することができます。これは、変更の管理を容易にし、システム全体の効率を高めます。Align Boundaries with Component Life Cyclesコンポーネントのライフサイクルに合わせた境界線は、管理の簡素化をもたらします。特定のコンポーネントの更新や交換が容易になります。例えば、頻繁に更新が必要なコンポーネントと、長期間安定して運用されるコンポーネントを区別することで、各コンポーネントをより効果的に管理することが可能になります。Align Boundaries with Organizational Structures組織構造に合わせた境界線の設定は、チーム間のコラボレーションを促進し、システムの全体的な一貫性を向上させます。Conwayの法則によれば、システムの設計はしばしばその開発を行う組織の構造を反映します。例えば、開発と運用が別々のチームによって行われる場合、それぞれのチームはシステムの異なる部分を管理することになり、結果としてシステム全体が分断されがちです。これを避けるためには、チームの組織構造をシステムのアーキテクチャに合わせて調整することが有効です。これにより、各チームは自分たちの責任範囲内で効率的に作業を進めることができ、全体としてのシステムの一貫性と効率が向上します。Create Boundaries That Support Resilience回復力を支持する境界線の設定は、システムの耐障害性と回復力を強化します。これは、特定のコンポーネントやサービスが障害に遭遇した場合に、システム全体が影響を受けるリスクを最小限に抑えることを意味します。例えば、システムの一部が故障した場合に、他の部分が正常に機能し続けるように設計することです。これにより、障害発生時にもシステムの主要な機能が維持され、迅速な回復が可能になります。また、このような設計は、障害発生時の影響範囲（ブラストラジアス）を小さくすることも目的としています。Create Boundaries That Support Scalingスケーリングを支持する境界線の設定は、システムの拡張性を高めることを目指します。これにより、需要の増大や減少に応じてシステムのリソースを柔軟に調整することが可能になります。例えば、特定のサービスやコンポーネントの利用が増加した場合に、追加のリソースを割り当てることで対応することができます。また、リソースの利用が減少した場合には、不要なリソースを削減してコストを節約することも可能です。このように、スケーリングを支持する境界線を設定することで、システムは変動する需要に柔軟に対応し、最適なパフォーマンスを維持することができます。Align Boundaries to Security and Governance Concernsセキュリティとガバナンスの懸念に合わせて境界線を設定することは、システムのセキュリティを強化し、規制遵守を容易にします。これは、異なるセキュリティ要件を持つシステムの部分に対して適切な保護措置を施すことを意味します。例えば、金融情報や個人データを扱う部分には、より厳格なセキュリティ対策が必要です。セキュリティとガバナンスに基づいて境界線を設定することにより、これらの要件を満たすための管理が容易になり、システム全体のセキュリティが向上します。この章は、インフラストラクチャをコードとして定義する際の、より小さな部分への分割の重要性を強調しています。分割されたコンポーネントは、変更、スケーリング、回復力の向上に寄与し、システム全体の運用効率を高めます。また、組織構造、セキュリティ、ガバナンスの観点から適切に境界線を設定することで、システムはより安全で管理しやすい状態になります。16. Building Stacks From Components (コンポーネントからスタックを構築する)Infrastructure Languages for Stack Componentsインフラストラクチャ言語の選択は、スタックコンポーネントの設計と実装において非常に重要です。宣言型言語は、その明確な構造と予測可能性により、特に大規模なシステムの設計において有効です。一方、命令型言語は、より動的で柔軟なシステムの構築に適しています。個人的な感覚では宣言型言語はインフラストラクチャの基本的な構造を定義するのに適しており、命令型言語はより複雑なロジックや条件分岐が必要な場面で役立ちます。Reuse Declarative Code with Modules宣言型コードのモジュール化による再利用は、システムの整合性を高め、変更の管理を容易にします。私は、モジュールを利用して共通の機能を効率的に管理し、コードベースの複雑さを減らすことができると感じています。宣言型言語で書かれたモジュールは、その明確さと一貫性により、特に大規模なプロジェクトや多くの開発者が関与する環境において有効です。Dynamically Create Stack Elements with Librariesライブラリを利用した動的なスタック要素の作成は、システムの設計における柔軟性を大幅に向上させます。命令型言語を用いることで、条件に応じたリソースの動的な生成や複雑なロジックの実装が可能になり、システムのカスタマイズが容易になります。これは、特に要件が頻繁に変更されるプロジェクトや、特定の条件に基づいて異なる動作をさせる必要があるシステムにおいて有用です。Patterns for Stack Componentsスタックコンポーネントを設計する際には、適切なパターンの選択が重要です。これにより、システムの一貫性、再利用性、そして将来の拡張性が向上します。良い設計パターンを採用することで、システム全体の品質を高めることができます。Pattern: Facade Moduleファサードモジュールは、複雑なリソースをよりシンプルに扱えるようにすることで、開発者の負担を軽減します。これは、複数のプロジェクトやチーム間で共通のリソースや設定を共有する際に特に有効で、一貫性のあるアプローチを提供します。ファサードモジュールを使用することで、開発者はより高度なタスクに集中でき、基盤となる複雑な詳細について心配する必要がなくなります。Antipattern: Obfuscation Moduleオブフスケーションモジュールは、実際には価値を追加せず、むしろシステムの複雑さを増加させるものです。このようなモジュールは、コードの可読性を低下させ、保守や拡張を困難にします。開発者がモジュールの背後にあるロジックを理解するのが難しくなり、結果として効率性が損なわれます。Antipattern: Unshared Module共有されていないモジュールは、その再利用性が低く、開発プロセスにおける効率性に欠けます。モジュール化の主な目的は、コードの再利用を促進することにありますが、この目的が達成されていない場合、モジュールの価値は大幅に低下します。このようなモジュールは、システム全体の一貫性を損なう可能性があります。Pattern: Bundle Moduleバンドルモジュールは、関連する複数のリソースを単一のインターフェースで管理することを可能にします。これにより、システムの一貫性と管理の容易さが向上します。特に、異なるリソースが密接に連携して動作する必要がある場合に有効で、開発者はより高度なタスクに集中できるようになります。Antipattern: Spaghetti Moduleスパゲッティモジュールは、パラメータに応じて大きく異なる結果を生み出すような複雑な設定が特徴です。これらのモジュールは、多くの動的な部分を含むため、実装が雑然として理解しにくくなりがちです。このようなモジュールはメンテナンスが困難で、変更を加える際には他の部分に予期せぬ影響を与えやすいことが分かっています。重要なのは、モジュールが単一の明確な目的を持ち、必要な機能だけを提供することです。複雑さを避けるためには、モジュールをより小さく、シンプルに保つことが重要です。Pattern: Infrastructure Domain Entityインフラストラクチャのドメインエンティティは、複数の低レベルのリソースを組み合わせて、より高度なスタックコンポーネントを実装するパターンです。このパターンは、特定のアプリケーションやサービスに必要なインフラストラクチャの全体像を捉え、その要件に基づいてリソースを動的に構築します。このアプローチは特に大規模で複雑な環境において効果的で、異なる要件に応じて柔軟にインフラストラクチャを構築できるようにします。しかし、これを実装するには、インフラストラクチャ自体をドメインとして捉え、その上で適切な設計を行う必要があります。Building an Abstraction Layer抽象化レイヤーを構築することで、より低レベルのリソースへの直接的なアクセスを抽象化し、より高レベルのタスクに集中できるようにします。これは、特に複数のチームが関わる大規模なプロジェクトにおいて有用です。抽象化レイヤーを使用することで、開発者はインフラストラクチャの詳細を気にせずに、アプリケーションの開発やビジネスロジックに集中できます。しかし、抽象化には適度なレベルが必要であり、過度な抽象化はシステムの理解を難しくし、問題の診断や解決を複雑化することもあります。第16章では、コンポーネントからスタックを構築する方法とその利点について説明されていますが、同時に、抽象化のレイヤーやコンポーネントのライブラリがもたらす複雑さに注意する必要があるとも指摘しています。システムの規模や複雑さに応じて、これらの構造を適切に使用することが重要です。適切な抽象化レベルの選択は、システムの効率をあげることにつながります。17. Using Stacks As Components (スタックをコンポーネントとして使用する)17. Using Stacks As ComponentsDiscovering Dependencies Across Stacksスタック間の依存関係の発見は、インフラストラクチャの複雑な環境において、異なるスタック間の統合を容易にするために重要です。依存関係を発見する方法を選ぶ際には、システムの拡張性、メンテナンスの容易さ、そして再利用性のバランスを考慮することが必要です。スタック間の依存関係を効果的に管理することは、システム全体の効率を向上させることに繋がります。Pattern: Resource Matchingリソースマッチングパターンは、名前、タグ、または他の識別特性を使用して、必要なリソースを発見する方法です。このパターンは、特に大規模なプロジェクトや、異なるチームや環境間での統合において有効です。実際、私が過去に関わったプロジェクトでは、リソースマッチングを使用することで、複数の環境やチーム間でのリソースの共有が容易になりました。Figure 17-1. Resource matching for discovering dependencies より引用Pattern: Stack Data Lookupスタックデータルックアップパターンは、提供側スタックが管理するデータ構造に基づいて、必要なリソースを見つける方法です。このアプローチは、全てのインフラストラクチャが同じツールを使用して管理されている場合に特に効果的です。スタックデータルックアップは、依存関係を明確にし、統合を容易にするために役立ちます。Pattern: Integration Registry Lookup統合レジストリルックアップパターンは、両方のスタックが一つのレジストリを使用して値を保存し、それを読み取る方法です。これは、異なるツールを使用している複数のチーム間の統合に非常に適しています。私自身も、異なる技術スタックを持つチーム間での統合にこのパターンを利用したことがあり、その柔軟性と効率性に非常に満足しています。Dependency Injection依存性の注入は、スタック定義から依存性の発見を分離することで、スタックの再利用性と柔軟性を向上させるテクニックです。このアプローチにより、異なるプロバイダー実装を容易に切り替えることが可能になり、より包括的に統合されたシステムのテストが容易になります。依存性の注入を使用することで、スタックをよりモジュラー化し、システムの各部分を独立して開発し、テストすることが可能になります。スタックをコンポーネントとして使用することは、システムの変更を容易にし、品質を向上させる効果的な方法です。このアプローチの成功は、スタックを適切に設計し、サイズを適切に保ち、スタック間の緩い結合を維持することに依存しています。スタックをコンポーネントとしてうまく利用することで、システム全体の可用性と拡張性が大幅に向上し、チームの生産性が向上しました。まとめインフラストラクチャをコードとして扱う際のベストプラクティス、効果的な設計パターン、および一般的なアンチパターンに焦点を当てています。この部分は、インフラストラクチャのモジュラリティの重要性を強調し、スタックのデザインパターンとアンチパターンを紹介します。依存関係の管理に関する方法論や依存性の注入の利点も説明されており、全体として、インフラストラクチャを効果的に設計し、管理するための重要な原則と方法論を提供しています。これらのガイドラインは、インフラストラクチャをコードとして扱う際に直面する一般的な課題に対する解決策を提示し、システムの効率性、拡張性、および信頼性を高めるための具体的な指針を提供しています。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/143554","isoDate":"2023-11-16T05:35:54.000Z","dateMiliSeconds":1700112954000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文","contentSnippet":"はじめに前回の続きで第二部のIII. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com 次回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第三部 目次III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes(アプリケーションランタイム)アプリケーションランタイムの章では、システムの3層モデルの一部として「インフラストラクチャシステムの部品」でアプリケーションランタイムを導入しています。ここでは、インフラ層からリソースを組み合わせて、アプリケーションをデプロイできるランタイムプラットフォームを提供する方法に焦点を当てています。アプリケーションランタイムは、インフラ管理ツールを使用して定義および作成されたインフラストラクチャスタックで構成されています。これは、どの言語や実行スタックで実行されるか、サーバー、コンテナ、またはFaaSサーバーレスコードにパッケージ化してデプロイされるかなど、それを使用するアプリケーションの理解から始まります。本章は、アプリケーションに対するランタイムプラットフォームとしてのインフラリソースの構成方法に焦点を当て、後の章でこれらのリソースをコードとして定義および管理する方法について詳しく説明しています。Figure 10-1. The application layer composed of infrastructure stacks より引用Cloud Native and Application-Driven Infrastructureクラウドネイティブとアプリケーション主導のインフラに関するこのセクションは、現代インフラのダイナミックな性質を最大限に活用するソフトウェア設計に重点を置いています。Herokuの12ファクターメソドロジーやKubernetesエコシステムとの関連性は、現代のアプリケーション開発の重要性を強調しています。このアプローチは、特に大規模なシステムの再構築や運用において、私の経験と一致しています。クラウドネイティブは、可変性と拡張性を重視したアプローチであり、これが現代のソフトウェア開発の標準となっています。Application Runtime Targetsアプリケーションランタイムターゲットを選定する際には、アプリケーションポートフォリオのランタイム要件を分析し、それに合わせたランタイムソリューションを設計することが重要です。これは、特に異なる技術スタックを持つ複数のプロジェクトを管理する場合に非常に役立ちます。ランタイムターゲットの選択は、アプリケーションのパフォーマンスと効率に大きく影響します。例えば、サーバーレス環境やコンテナベースの環境では、従来のサーバーベースのランタイムとは異なるアプローチが必要です。Deployable Parts of an Applicationアプリケーションのデプロイ可能な部分を理解することは、効率的なアプリケーションデプロイメント戦略を策定する上で重要です。実行可能ファイル、サーバー設定、データ構造などを適切に管理することは、私の経験上、運用の効率化に直結します。デプロイメントの自動化は、特に大規模なアプリケーションにおいて、時間とリソースの節約につながります。Deployment Packagesデプロイメントパッケージのセクションは、異なるランタイム環境に適したパッケージ形式の理解を深めます。これは、適切なツールとプロセスを選択する上でのガイドとなります。デプロイメントパッケージは、アプリケーションの構成とデプロイメントを標準化し、異なる環境間での一貫性を保証します。Deploying Applications to Serversサーバーへのアプリケーションデプロイメントに関しては、物理的または仮想的なサーバーを利用する従来のアプローチに焦点を当てています。これは、インフラの柔軟性とアプリケーションのニーズのバランスをとる上で重要な考慮点です。サーバーベースのデプロイメントは、特にレガシーシステムや特定のセキュリティ要件を持つアプリケーションにおいて、依然として重要な役割を果たします。Packaging Applications in Containersコンテナでのアプリケーションパッケージングについては、依存関係をアプリケーションパッケージに取り込むことの利点と課題を詳述しています。コンテナ化の進展は、アプリケーションのデプロイメントと運用の柔軟性を大きく向上させています。コンテナは、異なる環境間でのアプリケーションの実行を標準化し、デプロイメントプロセスを単純化します。Deploying Applications to Server Clustersサーバークラスターへのアプリケーションデプロイメントは、スケーラビリティと冗長性を確保するための重要な手法です。私の経験でも、効果的なクラスターマネジメントはシステムの可用性を大幅に向上させることができます。サーバークラスターは、負荷分散や障害耐性の向上に寄与します。Deploying Applications to Application Clustersアプリケーションクラスターへのデプロイメントは、ホストサーバー間でのアプリケーションインスタンスの分散に注目しています。これは、特に大規模なアプリケーションにおいて、リソースの効率的な利用とスケーラビリティの向上を実現します。クラスター内の異なるサーバーで異なるアプリケーションを実行することにより、リソースの最適化と柔軟な運用が可能になります。Packages for Deploying Applications to Clustersクラスターへのアプリケーションデプロイメントに必要なパッケージに関するセクションでは、複雑なインフラストラクチャ上で複数のプロセスとコンポーネントをデプロイする方法について説明しています。このアプローチは、現代の大規模アプリケーションの運用に不可欠です。クラスターベースのデプロイメントは、アプリケーションのスケールアップとスケールダウンを効率的に管理するための鍵となります。Deploying FaaS Serverless ApplicationsFaaS（Function as a Service）サーバーレスアプリケーションのデプロイメントは、サーバーやコンテナの詳細を抽象化し、インフラの複雑さから開発者を解放します。これは、迅速な開発とデプロイメントを可能にし、特にイベント駆動型アプリケーションやマイクロサービスアーキテクチャに適しています。サーバーレスは、リソースの使用に基づいた課金モデルを提供し、コスト効率を向上させます。Application Dataアプリケーションデータに関して、特にデータ構造の変更やデータの継続性の確保の重要性に焦点を当てています。これは、データベースの設計と運用における私の経験と一致し、データの変更と管理がシステムの信頼性と拡張性に大きく寄与することを示しています。Data Schemas and Structuresデータスキーマと構造のセクションでは、構造化されたデータストレージと非構造化、またはスキーマレスなデータストレージの違いを説明しています。スキーマ移行ツールの使用は、私の経験では、データベースのバージョン管理と変更の追跡に非常に有効であることが分かりました。Cloud Native Application Storage Infrastructureクラウドネイティブアプリケーションストレージインフラストラクチャは、動的に割り当てられるストレージリソースに重点を置いています。これは、拡張性とリソースの最適化におけるクラウドネイティブのアプローチの利点を反映しています。Application Connectivityアプリケーションの接続性に関するセクションでは、インバウンドとアウトバウンドの接続要件と、これらをインフラストラクチャスタックの一部として定義する方法について説明しています。これは、ネットワーク設計とセキュリティを考慮したアプリケーション開発に不可欠な要素です。Service Discoveryサービスディスカバリーに関しては、動的なインフラストラクチャでのサービスの発見方法として、DNS、リソースタグ、構成レジストリなどを含む様々なメカニズムに焦点を当てています。これは、マイクロサービスアーキテクチャや大規模な分散システムにおいて、サービス間の連携と通信のための重要な概念です。最後に、この章の結論では、インフラストラクチャの目的は有用なアプリケーションとサービスを実行することであると強調しています。アプリケーション主導のインフラストラクチャアプローチは、アプリケーションのランタイム要件に焦点を当て、アプリケーションの実行に必要なスタック、サーバー、クラスターなどの中間層構造を設計するのに役立ちます。「アプリケーション主導のインフラストラクチャ戦略では、現代的な動的インフラを使用してアプリケーションランタイム環境を構築します。(原文: An application-driven infrastructure strategy involves building application runtime environments for applications using modern, dynamic infrastructure.)」は、現代のインフラストラクチャ設計の核心をついており、私自身の経験でも、動的で柔軟なインフラストラクチャの設計と実装が、効率的で拡張性のあるシステムの構築に不可欠であることを強く感じています。アプリケーションのニーズに応じてインフラを適応させることが、現代のソフトウェア開発と運用の鍵となっています。11. Building Servers As Code (サーバーをコードとして構築する)「サーバーをコードとして構築する」章では、サーバーの設定を自動化する方法としてインフラストラクチャとしてのコードが最初に登場したことについて説明しています。システム管理者は、シェル、バッチ、Perlスクリプトを書いてサーバーを設定し、CFEngineはサーバー上のパッケージのインストールと設定ファイルの管理に対して、宣言型で冪等なDSLの使用を先駆けました。そして、PuppetやChefがこれに続きました。これらのツールは、物理サーバーやVMwareを使用した仮想マシン、後にはクラウドインスタンスなど、既存のサーバーから始めることを前提としています。現在では、サーバーがインフラスタックの一部であるか、コンテナクラスターの下層の詳細であるかに焦点を当てています。しかし、サーバーはほとんどのアプリケーションランタイム環境において依然として不可欠な部分です。この章では、サーバーの構成内容（設定する必要があるもの）とサーバーのライフサイクル（設定活動が行われるタイミング）から始まり、サーバー設定コードとツールに関する視点に移ります。この章の中心的な内容は、サーバーインスタンスの作成方法、サーバーを事前に構築して複数の一貫性のあるインスタンスを作成する方法、およびサーバーライフサイクル全体にわたるサーバー設定の適用方法に関する異なる方法を見ています。サーバーのライフサイクルをいくつかの遷移フェーズに分けて考えることが役立つ場合があります。サーバーの基本的なライフサイクルには、サーバーインスタンスの作成と設定、既存のサーバーインスタンスの変更、サーバーインスタンスの破棄という3つの遷移フェーズがあります。Figure 11-1. The basic server life cycle より引用What’s on a Serverサーバーに存在するものを理解することは、システムの安定性と効率を高める上で重要です。サーバー上のソフトウェア、設定、データの区別は、特に自動化されたインフラ管理において、適切なツールの選択と利用に不可欠です。私の経験からも、これらの要素を適切に管理することがシステムの安定稼働に直接影響を与えます。Where Things Come Fromサーバーの要素がどこから来るかを理解することは、サーバー構築と運用の複雑さを浮き彫りにします。OSのインストール、OSパッケージリポジトリ、言語やフレームワークのパッケージなど、多様な要素の組み合わせがサーバーのセットアップにおいて重要です。私の経験では、これらの要素を適切に組み合わせることが、効率的で堅牢なサーバーインフラの構築に不可欠であることが明らかです。Server Configuration Codeサーバー設定コードのセクションは、自動化されたサーバー設定のためのツールとアプローチを詳述しています。Ansible、Chef、Puppetなどのツールは、サーバー設定の自動化において非常に重要な役割を果たし、私の経験からもこれらのツールの有効性を実感しています。Server Configuration Code Modulesサーバー設定コードモジュールについてのこの部分は、コードの組織化とモジュール化の重要性を強調しています。実際のプロジェクトでは、これらの原則がサーバー設定の複雑さを管理するために不可欠です。コードのモジュール化は、メンテナンスの容易さと拡張性を提供します。Designing Server Configuration Code Modulesサーバー設定コードモジュールの設計についてのセクションは、単一の関心事に焦点を当てたモジュールの重要性を説明しています。これは、効率的なインフラストラクチャ管理に必要なベストプラクティスです。私の経験でも、関心の分離を行うことで、より管理しやすく、エラーの少ないインフラを構築できることが実証されています。Versioning and Promoting Server Codeサーバーコードのバージョニングと昇格に関するこの部分は、サーバー設定の変更を管理するための戦略を提供します。コードのバージョン管理は、安定したインフラストラクチャ環境の維持において重要です。バージョン管理を通じて、安定性と再現性を保証することができます。Server Rolesサーバーの役割に関するセクションは、特定の設定モジュール群をサーバーに適用する方法を示しています。これは、サーバー設定の柔軟性と適用性を高めるための有効な手法です。役割に基づくモジュール管理は、特に大規模な環境において、サーバーの設定と運用を簡素化します。Testing Server Codeサーバーコードのテストに関するこの部分は、インフラストラクチャコードのテスト戦略を提供し、品質保証において重要な役割を果たします。私の経験では、テストはインフラストラクチャの信頼性と整合性を保証するための鍵です。Progressively Testing Server Codeサーバーコードの段階的なテストについてのセクションは、テスト戦略を効果的に組み立てる方法を示しています。これは、インフラストラクチャの信頼性を高めるために不可欠です。段階的なテストは、コードの整合性を保ちながら、継続的に品質を向上させることができます。What to Test with Server Codeサーバーコードで何をテストするかについてのこのセクションは、テストの焦点と目的を明確にします。これは、サーバー設定の精度と効率を保証するために重要です。テストを通じて、異なる環境や条件下でのサーバーの挙動を確認し、予期せぬ問題の早期発見と修正を行うことができます。How to Test Server Codeサーバーコードをどのようにテストするかに関するセクションは、効果的なテスト方法とツールを提供します。InspecやServerspecなどのツールは、サーバーの状態を検証し、期待される動作を保証するために役立ちます。実際のテストプロセスは、特定の条件下でサーバーの設定と動作を確認し、必要に応じて調整を行うことを目的としています。Creating a New Server Instance新しいサーバーインスタンスを作成する際には、物理サーバーや仮想マシンの選択、OSのインストール、初期設定の適用が含まれます。これは、効率的で再現性の高いサーバー環境を構築するために重要です。私の経験では、新しいサーバーインスタンスの作成は、システムの拡張性と柔軟性に大きく寄与します。Hand-Building a New Server Instance手作業で新しいサーバーインスタンスを構築する方法は、特に小規模な環境や実験的な目的に適しています。しかし、大規模な運用環境においては、この方法は非効率的でエラーが発生しやすいため、自動化されたプロセスに置き換えることが望ましいです。Using a Script to Create a Serverサーバー作成のためのスクリプト使用に関して、このセクションはサーバー作成プロセスの自動化の重要性を強調しています。コマンドラインツールやAPIを利用するスクリプトを作成することで、サーバーの設定が一貫性を持ち、透明性が向上します。私の経験では、このようなスクリプトを活用することで、サーバーのデプロイメントプロセスの効率化とエラーの削減が可能です。Using a Stack Management Tool to Create a Serverスタック管理ツールを使用したサーバー作成に関するこの部分では、サーバーを他のインフラリソースと一緒に定義する利点を説明しています。Terraformなどのツールを使用することで、サーバーインスタンスの作成や更新が簡素化されます。私の経験上、スタックツールの使用は、インフラリソースの統合と管理を効率的に行うのに役立ちます。Configuring the Platform to Automatically Create Serversプラットフォームを設定して自動的にサーバーを作成するこのセクションは、オートスケーリングやオートリカバリーのような機能を利用する方法を示しています。これは、負荷の増加に応じたサーバーの追加や障害発生時のサーバーインスタンスの交換といった、動的な環境において特に重要です。Using a Networked Provisioning Tool to Build a Serverネットワークプロビジョニングツールを使用してサーバーを構築するこの部分では、ハードウェアサーバーの動的なプロビジョニングプロセスについて説明しています。PXEブートなどの手法を利用して物理サーバーをリモートで起動し、OSインストールや設定を行うプロセスは、特に物理的なインフラを管理する際に有効です。Prebuilding Servers事前にサーバーを構築するこのセクションでは、サーバーの内容を事前に準備する複数の方法を提供しています。これにより、サーバーの構築プロセスを高速化し、複数の一貫性のあるサーバーインスタンスを容易に作成できます。実際に、事前に構築されたサーバーイメージを使用することで、デプロイメントの時間と労力を大幅に削減できることを経験しています。Hot-Cloning a Server実行中のサーバーをホットクローニングするこの部分では、クローニングを行う際の利便性とリスクについて説明しています。特に、本番環境のサーバーをクローニングする際には、意図しない影響を避けるために注意が必要です。Using a Server Snapshotサーバースナップショットの使用に関するこのセクションでは、ライブサーバーからスナップショットを取得し、そのスナップショットを使用して新しいサーバーを作成する方法を提供しています。これは、特に大規模な環境において、サーバーの一貫性を保つための有効な方法です。Creating a Clean Server Imageクリーンなサーバーイメージを作成するこの部分では、複数の一貫性のあるサーバーインスタンスを作成するための基盤となるイメージを作成するプロセスを説明しています。これは、サーバーのデプロイメントを標準化し、品質を保つために非常に重要です。Configuring a New Server Instance新しいサーバーインスタンスの設定に関するこのセクションでは、サーバーの作成とプロビジョニングプロセスの最後の部分である自動化されたサーバー設定コードの適用について説明しています。このプロセスは、新しいサーバーを作成する際の構成を決定する上で重要な要素です。最後に、この章はサーバーの作成とプロビジョニングに関する様々な側面をカバーしています。サーバーに含まれる要素にはソフトウェア、設定、データがあり、これらは通常、サーバーイメージとサーバー設定ツールを使用して追加されるパッケージと設定から構成されます。サーバーを作成するためには、コマンドラインツールを使用するかUIを使用することができますが、コード駆動のプロセスを使用することが好ましいです。今日では、カスタムスクリプトを作成することは少なく、スタック管理ツールを使用することが一般的です。サーバーを構築するためのさまざまなアプローチについて説明していますが、通常、サーバーイメージを構築することをお勧めします。12. Managing Changes To Servers (サーバーへの変更の管理)この章は、サーバーとそのインフラに対する変更を管理するための多様なアプローチとパターンを探求しています。この章を読んで、サーバーの変更管理における自動化の重要性が強く印象に残りました。特に、変更を例外的なイベントではなく、日常的なルーチンとして取り扱うことの重要性が強調されている点に共感しました。私自身の経験からも、一貫性のある自動化された変更プロセスは、システムの安定性と信頼性を大きく向上させると確信しています。また、この章で提案されている様々なパターン、特に「継続的な設定同期」と「不変のサーバー」というパターンは、サーバー運用の効率を高める上で非常に有効です。サーバーの設定を定期的に同期することで、予期せぬ変更や誤差を早期に検出し、対処することが可能になります。また、不変のサーバーの概念は、変更によるリスクを減らす効果的な手法として、私のプロジェクトでも積極的に採用しています。サーバー設定コードをどのように適用するかに関しても、プッシュとプルの2つのパターンを詳しく説明しています。これらのパターンの選択は、サーバーのライフサイクルイベントに合わせて行う必要があり、特定の状況や要件に基づいて適切なアプローチを選択することが重要です。サーバーの他のライフサイクルイベント、例えばサーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などについても、有益な洞察を提供しています。特に、サーバーの回復プロセスは、クラウドインフラストラクチャの信頼性の限界に対処するために不可欠です。総じて、サーバーのライフサイクル管理における現代的なアプローチを包括的に提示しており、サーバーの設定と変更プロセスを最適化するための貴重なリソースとなっています。Change Management Patterns: When to Apply Changesサーバーの変更管理パターンは、変更を適用するタイミングを決定するための重要なガイドラインを提供します。変更が必要となった場合にそれを例外的なイベントとして扱うのではなく、ルーチンとして組み込むことで、システムの一貫性とポリシーへの準拠を確保できます。これは、私が経験したシステムの自動化における重要な一歩です。Antipattern: Apply On Changeこのアンチパターンは、特定の変更を適用するためにのみ設定コードを使用することを示しています。変更を例外として扱うことは、システムの不整合とエラーの原因となることが多いです。これは、私の経験でも、効率的なシステム管理において避けるべき方法です。Pattern: Continuous Configuration Synchronization継続的な設定同期は、変更があるかどうかに関わらず、定期的に設定コードを適用することを意味します。これにより、サーバーの設定の一貫性が保たれ、予期せぬ違いを早期に検出できます。これは、私のSREとしての実践において、サーバー運用の効率を大幅に向上させた方法です。Pattern: Immutable Server不変のサーバーとは、設定が変更されないサーバーインスタンスを意味します。変更を配信するために、変更された設定で新しいサーバーインスタンスを作成し、既存のサーバーを置き換えます。これは、特に安定性と整合性が重要な環境で有効な手法です。How to Apply Server Configuration Codeサーバー設定コードの適用方法に関するこのセクションは、サーバーに変更を適用するためのパターンを検討します。サーバーの新規構築、既存インスタンスの更新、サーバーイメージの構築において、これらのパターンは不可欠です。Pattern: Push Server Configurationプッシュサーバー設定パターンでは、新しいサーバーインスタンスの外部からサーバーに接続してコードを実行し、適用します。これは、サーバーインスタンスへのタイムリーな設定更新が必要な場合に特に有効です。Pattern: Pull Server Configurationプルサーバー設定パターンでは、サーバーインスタンス自体で実行されるプロセスが設定コードをダウンロードして適用します。これは、サーバーインスタンスが入ってくる接続を受け入れる必要がないため、攻撃面を減らすのに役立ちます。Other Server Life Cycle Eventsサーバーの他のライフサイクルイベントに関するこのセクションでは、サーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などを検討します。これらは、サーバーの管理と運用において、特に重要なフェーズです。Stopping and Restarting a Server Instanceサーバーインスタンスの停止と再起動に関するこのセクションは、特定の目的のためにサーバーを一時的に停止または再起動する方法を示しています。これは、コスト削減やメンテナンスのために、しばしば実践されます。Figure 12-1. Server life cycle—stopping and restarting より引用Replacing a Server Instanceサーバーインスタンスの置換に関するこの部分は、新しいサーバーインスタンスを作成し、古いインスタンスと交換するプロセスを説明しています。これは、特に自動スケーリングや自動回復を利用する環境で役立つアプローチです。Recovering a Failed Server失敗したサーバーの回復についてのこのセクションでは、サーバーインスタンスが失敗した場合の回復プロセスについて説明しています。これは、クラウドインフラストラクチャの信頼性が常に保証されるわけではないため、特に重要です。この章は、サーバーのライフサイクルにおける核心的なイベントを網羅しています。サーバーの作成と変更に関するアプローチの多くは、サーバーイメージをカスタマイズし、それを使用して複数のサーバーインスタンスを作成または更新することに依存しています。13. Server Images As Code (サーバーイメージをコードとして扱う)サーバーイメージの自動化された構築と維持に関する包括的なガイドを提供しています。この章を読む中で、サーバーイメージの構築と管理を自動化することの重要性が強調されてました。特に、サーバーイメージのライフサイクルを通じて、一貫性と品質の確保に焦点を当てることが重要であると感じました。サーバーイメージの構築プロセスは、オンラインとオフラインの二つのアプローチが存在し、各々の利点と制約について詳しく解説されています。私の経験上、オフラインのイメージ構築は迅速で、特定のシナリオでは非常に有効ですが、より複雑な設定を必要とすることがあります。また、サーバーイメージの異なる起源、例えばベンダー提供のストックイメージやゼロからの構築、そしてそのコンテンツの出所に関する議論は、セキュリティとパフォーマンスのバランスを取る上で非常に有益です。セキュリティに関する考慮事項は、特に重要であり、サーバーイメージの構築プロセスにおいて常に優先されるべきです。サーバーイメージのバージョニングと更新の管理は、章の中でも特に興味深い部分でした。これにより、サーバーイメージが最新のセキュリティパッチや設定で常に最新の状態を保つための効率的な方法が提供されます。私の経験では、サーバーイメージの定期的な更新は、インフラの安定性と運用の効率を大幅に向上させることができます。さらに、サーバーイメージをパイプラインを通じてテストおよび配信することに関するセクションは、インフラストラクチャの自動化とCI/CDの実践において非常に重要な概念を提供します。パイプラインを使用することで、サーバーイメージの構築、テスト、配布が容易かつ効率的になります。この章全体を通して、サーバーイメージを効率的に管理し、継続的に改善するための強固な基盤が提示されています。これは、現代のインフラストラクチャ管理において不可欠なリソースであり、その実践は技術的な洞察とともに、ビジネスの効率性とセキュリティを高める重要な手段となります。Figure 13-1. Server image life cycle より引用Building a Server Imageサーバーイメージの構築に関するセクションでは、カスタムサーバーイメージの作成プロセスの重要性とその利点について深く掘り下げられています。このプロセスを通じて、組織固有の要件やセキュリティ基準に合致したイメージを作成することの価値が明らかにされました。このセクションは、自動化されたイメージ作成のアプローチが、サーバーのデプロイメントをより迅速かつ安全にする方法を示しています。実際に、カスタマイズされたイメージを使用することで、セキュリティやパフォーマンスの最適化が可能になると私は経験しています。Why Build a Server Image?サーバーイメージを構築する理由についてのセクションは、特に啓発的でした。組織のガバナンス、セキュリティの強化、パフォーマンスの最適化など、カスタムイメージを構築するための具体的な理由が挙げられています。これらの要因は、私が直面する日常の課題と密接に関連しており、カスタムサーバーイメージを活用することの価値を再確認させてくれました。How to Build a Server Imageサーバーイメージの構築方法に関する部分は、理論的かつ実践的なアプローチを提供しており、非常に役立ちました。オンラインとオフラインの両方のイメージ構築方法が詳細に説明されており、これは技術的な選択肢を検討する際に重要なガイドラインとなります。Tools for Building Server Imagesこのセクションでは、サーバーイメージを構築するためのツールとサービスが詳述されています。Packerのようなツールの利用が、イメージ構築プロセスを効率化する上でいかに重要かが強調されているのを見て、私の現在のワークフローに対する洞察を得ることができました。Online Image Building Processオンラインでのイメージ構築プロセスについてのセクションは、イメージを作成する実際の手順を明確に説明しています。このプロセスに関する詳細な説明は、実務での応用を容易にし、サーバーイメージの構築方法の理解を深めました。Offline Image Building Processオフラインイメージ構築プロセスに関する説明は、オンラインプロセスとの比較を通じて、異なるアプローチの利点と制約を理解するのに役立ちました。オフラインでのイメージ構築方法は、特定の状況下での効率性を考慮する上で重要です。Origin Content for a Server Imageサーバーイメージの起源コンテンツに関するセクションは、イメージ構築の基礎となる要素についての理解を深めるのに役立ちました。ストックイメージからの構築、スクラッチからの構築、そしてサーバーイメージとそのコンテンツの由来に関する議論は、イメージ構築プロセスの基礎を形成します。Building from a Stock Server Imageストックサーバーイメージからの構築に関するセクションは、既存のイメージをカスタマイズする方法とその利点を解説しています。このアプローチは、特にセキュリティやパフォーマンスの最適化を目指す際に重要です。Building a Server Image from Scratchゼロからサーバーイメージを構築するプロセスに関する詳細は、完全にカスタマイズされたイメージを作成するための重要なガイドラインを提供しています。これは、特定の高度な要件を持つ組織にとって特に有益です。Provenance of a Server Image and its Contentサーバーイメージとそのコンテンツの出所に関するセクションは、セキュリティと信頼性の側面を考慮する上で特に重要です。サードパーティからのコンテンツを使用する際の潜在的なリスクを理解し、適切なチェックを実施することが強調されています。Changing a Server Imageサーバーイメージの変更に関するセクションは、イメージの維持と更新のプロセスに光を当てています。定期的なリフレッシュとバージョニングの重要性に関する洞察は、効率的で安全なインフラストラクチャ管理のために不可欠です。Reheating or Baking a Fresh Imageイメージの再加熱または新たなイメージの焼き直しに関するセクションは、サーバーイメージの更新方法に関する具体的な選択肢を提示しています。どちらのアプローチもそれぞれのメリットがあり、状況に応じて適切な方法を選択することが重要です。Versioning a Server Imageサーバーイメージのバージョニングに関する議論は、イメージの追跡と管理の重要性を強調しています。バージョニングは、イメージの透明性と一貫性を保つ上で不可欠な要素です。Updating Server Instances When an Image Changesイメージが変更された場合のサーバーインスタンスの更新についてのセクションは、イメージを基に作成されたインスタンスの一貫Updating Server Instances When an Image Changes「イメージが変更されたときのサーバーインスタンスの更新」に関するセクションは、サーバーイメージの更新とサーバーインスタンスの同期に関する洞察を提供しました。この部分では、新しいサーバーイメージを作成した後のサーバーインスタンスの管理方法について考察しています。サーバーインスタンスを即座に更新するか、自然に時間が経過するまで待つかという選択は、システムの整合性と運用の効率の両方に影響を及ぼします。私の経験では、定期的なサーバーインスタンスの更新は、セキュリティとパフォーマンスの観点から重要です。また、適切なバージョン管理と更新ポリシーは、サーバー環境の一貫性を保ち、予期せぬ問題を回避するために不可欠です。Providing and Using a Server Image Across Teams「チーム間でのサーバーイメージの提供と使用」は、サーバーイメージを異なるチーム間で共有する際のベストプラクティスに焦点を当てています。このセクションは、サーバーイメージを中央チームが作成し、他のチームが使用する場合のダイナミクスを明確に説明しています。イメージのバージョン管理と共有に関する洞察は、大規模な組織における効果的なインフラ管理に特に関連しています。私が以前関わったプロジェクトでは、チーム間でサーバーイメージを共有することで、作業の重複を防ぎ、一貫性を保つことができました。Handling Major Changes to an Image「イメージの大きな変更を扱う」セクションは、サーバーイメージに対する大規模な変更を適切に管理する方法に関する重要な洞察を提供しています。このセクションでは、大きな変更をセマンティックバージョニングを使用して管理することの重要性が強調されています。私の経験では、サーバーイメージに大きな変更を加える際には、特に慎重なテストと段階的な導入が重要です。これにより、変更による影響を最小限に抑え、システムの安定性を保つことができます。Using a Pipeline to Test and Deliver a Server Image「サーバーイメージをテストおよび配信するためのパイプラインの使用」セクションは、サーバーイメージのライフサイクルを自動化し、品質を確保するための強力なアプローチを提供しています。パイプラインを通じてサーバーイメージを構築、テスト、配信することは、継続的な改善と効率化のための鍵です。私の経験では、CI/CDパイプラインを使用することで、サーバーイメージの作成と更新が格段に効率的になり、システムの全体的な信頼性が向上します。Using Multiple Server Images「複数のサーバーイメージの使用」セクションは、異なる環境や用途に合わせて複数のサーバーイメージを維持する必要性を説明しています。異なるプラットフォーム、オペレーティングシステム、ハードウェアアーキテクチャに対応するためのサーバーイメージの管理は、特に複雑なインフラストラクチャを持つ組織において重要です。私の経験では、特定の役割や要件に合わせてサーバーイメージを最適化することで、運用の効率を大幅に向上させることが可能です。サーバーイメージの管理に関するこの章の総括として、サーバーイメージをコードとして扱うことの利点が明確に示されています。自動化されたプロセスを通じてサーバーイメージを維持し、定期的に更新することで、インフラストラクチャの効率性とセキュリティが大きく向上することが示されています。14. Building Clusters As Code (クラスターをコードとして構築する)この章は、クラスターをコードとして構築する方法について詳しく解説しています。ソフトウェアエンジニアリングの経験から、このアプローチの強みは、システムの柔軟性と再現性にあります。KubernetesやAWS ECSなどの例が挙げられ、クラスター管理の複雑さを隠蔽しながらも、コードを介して制御可能であることが強調されています。Figure 14-1. An application cluster creates a layer between infrastructure resources and the applications running on them より引用Application Cluster Solutionsアプリケーションクラスターのソリューションに関しては、クラウドベースのサービスとオンプレミスのソリューション間の選択肢を詳細に検討しています。私の経験では、クラウドサービスは迅速な展開と低い初期コストを提供しますが、長期的にはカスタマイズの柔軟性とコントロールの観点で限界があります。一方で、オンプレミスソリューションは初期設定が複雑であり、維持管理のコストが高くなる可能性がありますが、長期的にはより制御可能で安定しています。Cluster as a Serviceクラウドプラットフォームが提供するCluster as a Service は、設定や管理の簡素化を可能にします。しかし、クラウド固有のサービスに依存することのリスクも伴います。この点は、多くのプロジェクトで検討すべき重要なトレードオフです。Packaged Cluster Distributionパッケージ化されたクラスター配布は、よりカスタマイズ可能で、組織固有のニーズに合わせた設定が可能です。Kubernetesのようなオープンソースソリューションの利用は、柔軟性をもたらしますが、メンテナンスとサポートにおいて自組織のリソースを要求します。Stack Topologies for Application Clustersアプリケーションクラスターのスタックトポロジーについては、モノリシックなスタックと分散型スタックの両方が詳述されています。私の観点からは、モノリシックなアプローチは小規模なプロジェクトや初期段階でのプロトタイピングに適しています。しかし、規模が大きくなると、スタックを分割し、各機能を別々に管理することで、より効率的な運用と拡張性が得られます。特に大規模なシステムでは、分散型のアプローチがシステムの複雑さを管理しやすくします。Monolithic Stack Using Cluster as a Serviceモノリシック・スタックを使用する場合、初期段階では管理が簡単ですが、規模が大きくなるにつれて、複雑さとリスクが増大します。このアンチパターンは、特に大規模なシステムでの問題につながり得ます。Monolithic Stack for a Packaged Cluster Solutionパッケージ化されたクラスター・ソリューションにおけるモノリシック・スタックは、より管理が複雑ですが、カスタマイズの自由度が高いです。インフラのスタックとアプリケーションのクラスターが別々に管理される点は、運用において重要な考慮事項です。Pipeline for a Monolithic Application Cluster Stackモノリシック・アプリケーション・クラスター・スタックのパイプラインは、インフラとアプリケーションの両方に影響を及ぼします。この一元管理は、変更の際に大きな影響を及ぼす可能性があります。Example of Multiple Stacks for a Clusterクラスターのための複数スタックの例は、変更の影響を局所化し、リスクを分散させるのに役立ちます。スタックを分割することで、より効率的かつ安全に変更を行うことができます。Sharing Strategies for Application Clustersアプリケーションクラスターの共有戦略に関するセクションは、特に多様な環境やニーズを持つ組織にとって重要です。一つの大きなクラスターをすべての用途に使用するのではなく、目的やチームごとにクラスターを分割することで、セキュリティ、パフォーマンス、および管理の観点から優れた結果を得ることができます。私の経験上、チームやプロジェクトごとに専用のクラスターを用意することは、リソースの効率的な利用とセキュリティリスクの軽減に繋がります。また、ガバナンスやコンプライアンスの要件に基づいてクラスターを分割することは、特に規制の厳しい業界での運用において重要です。One Big Cluster for Everything全てを一つの大きなクラスターで管理するアプローチは、シンプルさと効率の面で魅力的ですが、変更管理の複雑さやリスクの集中が懸念されます。Separate Clusters for Delivery Stages異なるデリバリー段階ごとに別々のクラスターを用意する戦略は、リスクの分散と環境間の独立性を提供します。これにより、特定の環境に特化した最適化が可能になります。Clusters for Governanceガバナンスのためのクラスターは、特定のコンプライアンス要件を持つアプリケーションに対して、より厳格な環境を提供することができます。これにより、セキュリティとパフォーマンスの向上が期待できます。Clusters for Teamsチームごとのクラスターは、チームの特定のニーズに合わせたカスタマイズを可能にします。これは、チームの生産性を向上させると同時に、システムの全体的な効率を高めることができます。Service Meshサービスメッシュは、アプリケーション間の通信を効率化し、複雑な分散システムにおける管理を容易にします。これにより、開発者はアプリケーションのロジックに集中でき、インフラストラクチャの詳細から解放されます。Infrastructure for FaaS ServerlessFaaS Serverlessのインフラストラクチャは、従来のアプリケーション・ホスティングとは異なり、イベント駆動のコード実行をサポートします。これにより、負荷が不規則なワークロードに対して、高い効率性とスケーラビリティが得られます。この章の総括として、クラスターをコードとして構築するアプローチは、アプリケーションをサポートするためのインフラストラクチャを効率的に管理するための強力な方法です。個々の技術や戦略の選択は、組織の特定のニーズに基づいて行われるべきです。まとめサーバーとその他のアプリケーションランタイムプラットフォームの扱いに焦点を当てています。このセクションは、現代のインフラストラクチャ管理における重要なトピックを深く掘り下げており、Infrastructure as Code (IaC) の実践において不可欠な洞察を提供しています。特に、アプリケーションクラスターの構築、スタックトポロジーの設計、そしてクラスター共有戦略の選択に関する章は、システムのスケーラビリティと耐障害性を高める方法論を提示しています。これらの章では、クラウドサービスとオンプレミスソリューションの利点と欠点が比較され、プロジェクトの要件に応じた適切な選択を行うための洞察が提供されています。本書は、インフラストラクチャをコードとして扱うことの重要性を強調し、変更管理、セキュリティ、およびコンプライアンスを効率的に運用するための具体的な手法を提供しています。また、サービスメッシュやサーバーレスアーキテクチャなどの先進的なトピックにも言及し、読者がこれらの技術を理解し、適切に活用するためのガイダンスを提供しています。全体を通して、この部分は、インフラストラクチャの自動化とオーケストレーションに関する実用的なアプローチを強調しており、読者がより堅牢で効率的なシステムを構築するための知識を深めるのに役立ちます。結果として、サーバーとアプリケーションランタイムプラットフォームの管理において、より戦略的で洗練されたアプローチを採用するための基盤を築くことができます。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/124030","isoDate":"2023-11-16T03:40:30.000Z","dateMiliSeconds":1700106030000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文","contentSnippet":"はじめに前回の続きで第二部のWorking With Infrastructure Stacks (インフラストラクチャスタックとの作業)という部の読書感想文になります。まず、Stackってなんやねんと思うと思います。僕も思っています。前回の記事syu-m-5151.hatenablog.com次回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第二部 目次II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)この章はインフラストラクチャスタックをコードとして構築する方法に焦点を当てています。Figure 5-1. An infrastructure stack is a collection of infrastructure elements managed as a group より引用What Is an Infrastructure Stack?インフラストラクチャスタックは、インフラリソースを単位として定義、プロビジョニングし、更新する集合体であり、スタック管理ツールによって一括で管理されます。スタック管理ツールには、HashiCorp Terraform, AWS CloudFormation, Azure Resource Manager, Google Cloud Deployment Manager, Pulumi などがあります。AnsibleやChefなどの内部を上手に操作するツールはこれらには含まれません。そして、このStack管理ツールは私は現実ではほぼ使いません。Infrastructure as Codeのこれまでとこれから、わたしたちにIaCはまだ早かったのかもしれないなどでもStackツールって表現しているようなことはありませんだからといって本書の価値が下がるということは一切ありません。Stack Codeスタックコードはスタックの構造を記述するソースコードであり、インフラプラットフォームから提供されるリソースやサービスを宣言的に記述します。スタックコードは、インフラストラクチャの各要素をどのようにコード化するかを明確にし、変更が行われる際には、このコードに基づいてインスタンスが更新されます。Stack Instanceスタックインスタンスは、特定のスタックコードに基づいてプロビジョニングされたインフラリソースの具体的な実体です。インフラストラクチャの状態がコードで明確に定義されることにより、再現性と整合性を保つことが可能です。Configuring Servers in a Stackサーバー設定はインフラコードベースの重要な部分であり、コンテナベースやサーバーレスアーキテクチャではないシステムにおいて特に多くのコードが必要になります。Direct Infrastructure Management Languages \u0026 Abstraction-Level Infrastructure Languages直接インフラ管理言語は、インフラストラクチャプラットフォームが提供するリソースに直接対応し、抽象化レベルのインフラ言語は、基盤となるプラットフォームが提供するリソースに直接対応していないエンティティを定義します。たとえば、PaaSプラットフォームやパッケージ化されたクラスターは、より高い抽象レベルでリソースを管理する能力を提供します。Patterns and Antipatterns for Structuring Stacksインフラストラクチャスタックの構造化において取るべき適切なアプローチと避けるべき間違ったアプローチについて説明しています。Antipattern: Monolithic Stack (アンチパターン: モノリシックスタック)モノリシックスタックは、多くの要素を含む過大なインフラストラクチャスタックで、その管理が困難です。これはシステムの拡大とともに発生しやすく、一つのプロジェクトに新しい要素を単純に追加することで成長します。しかし、その結果、スタックのプロビジョニングや更新に時間がかかりすぎたり、変更時のリスクが高まるなどの問題が生じます。Pattern: Application Group Stack (パターン: アプリケーショングループスタック)アプリケーショングループスタックは、関連する複数のアプリケーションまたはサービスのインフラストラクチャをグループ化して管理します。これにより、システム内の複数のアプリケーションを単一の単位として扱い、管理を簡素化できます。しかし、アプリケーションごとの変更のリズムが異なる場合、不必要なオーバーヘッドやリスクを招く可能性があります。Pattern: Service Stack (パターン: サービススタック)サービススタックでは、デプロイ可能な各アプリケーションコンポーネントのインフラストラクチャを個別のスタックで管理します。これにより、サービスごとの変更を独立して行えるため、変更管理のリスクが局限され、チームがそれぞれのソフトウェアに関連するインフラストラクチャを所有することが容易になります。Pattern: Micro Stack (パターン: マイクロスタック)マイクロスタックでは、単一サービスのインフラストラクチャを複数のスタックに分割します。これにより、サービスの異なる部分が異なるレートで変更されたり、管理が別々に簡単になるなど、さらなる柔軟性と管理のしやすさを提供します。ただし、スタックの数が増えることで生じる追加の複雑性を管理する新たな課題もあります。これらのパターンとアンチパターンは、スタックのサイズと構造をどのように決定するかについての考慮点を提供し、スタックの管理とスケーラビリティのバランスを最適化する方法を示しています。この章では、インフラストラクチャの自動化におけるスタックの重要性と管理方法を明確にし、スタックの構築と管理に関する技術的な洞察と実践的な指針を提供します。6. Building Environments With Stacks (スタックで環境を構築する)インフラストラクチャスタックを用いて環境を構築する方法について詳しく説明されています。この章は、ソフトウェア開発と運用の現場で経験した実践的な課題と、それを解決するためのインフラコード化の知見を踏まえ、環境構築の理論と手法を提供します。Figure 6-1. ShopSpinner delivery environmentsより引用What Environments Are All About環境は特定の目的に沿って組織されたソフトウェアとインフラリソースの集合体であり、例えばテストフェーズをサポートするため、または地理的な地域でサービスを提供するために使用されます。スタックまたはスタックのセットは、これらのインフラリソースのコレクションを定義し、管理する手段であり、環境を実装するために使用されます。\"An environment is a collection of software and infrastructure resources organized around a particular purpose, such as to support a testing phase, or to provide service in a geographical region.\" (環境とは、テストフェーズをサポートしたり、地理的な地域でサービスを提供したりするなど、特定の目的の周りに組織されたソフトウェアとインフラリソースの集合体です。)Patterns for Building Environments環境を構築するためのパターンでは、環境とスタックの実装方法についてのアンチパターンとパターンが説明されています。Antipattern: Multiple-Environment Stack (アンチパターン: 複数環境スタック)複数環境スタックは、単一のスタックインスタンスとして複数の環境のインフラストラクチャを定義し、管理するものです。これは、新しいスタックツールを学習している際に直感的に行われがちな構造ですが、コード内のミスや依存関係の予期せぬ発生により、インスタンス内の全てが影響を受けるリスクがあります。Antipattern: Copy-Paste Environments (アンチパターン: コピペ環境)コピペ環境アンチパターンは、各インフラストラクチャスタックインスタンスに対して別々のスタックソースコードプロジェクトを使用するものです。これにより、コードの重複や一貫性の欠如が生じ、環境間での構成のズレによるテストやデプロイメントプロセスの信頼性が低下する可能性があります。Pattern: Reusable Stack (パターン: 再利用可能スタック)再利用可能スタックは、複数のスタックインスタンスを生成するために使用されるインフラソースコードプロジェクトです。これにより、スタックコードに加えた変更を一つのインスタンスでテストし、その後同じコードバージョンを使用して複数の追加インスタンスを作成または更新することができます。この章は、インフラストラクチャスタックを使用して環境を効果的に実装するための戦略と、それに伴う潜在的な問題を特定し、解決する方法を提供します。インフラストラクチャスタックを活用した環境構築は、ソフトウェアのリリースプロセスのサポートや、地理的な分散によるスケーラビリティと耐障害性の向上に貢献します。7. Configuring Stack Instances (スタックインスタンスの設定)再利用可能なインフラスタックを複数の環境で効率的に運用するための構成管理について議論しています。この章では、インフラスタックのカスタマイズが必要なシナリオを想定し、環境ごとのユニークな設定をどのように実現するかを検討しています。Figure 7-1. Using the same code with different parameter values for each environment より引用Using Stack Parameters to Create Unique Identifiersスタックコードにパラメータを渡すことで、同一プロジェクトから生成される複数のスタックインスタンスがIDの衝突を避けられるよう、一意性の確保を目指しています。このアプローチは、インフラストラクチャのコード化の原則「全てを再現可能にする」を実現する上で重要な役割を果たします。\"Consistency across environments is one of the main drivers of Infrastructure as Code.\" (環境間の一貫性は、インフラストラクチャのコード化の主要な推進力の一つです。)Patterns for Configuring Stacksスタック構成に関するパターンでは、スタックツールに構成値を効果的に渡すための複数のアンチパターンとパターンが提示されています。Antipattern: Manual Stack Parameters (アンチパターン: 手動スタックパラメータ)手動でパラメータを入力する方法は、簡便ですが、誤入力のリスクがあり、チーム内での構成値の一貫性を担保するのが難しいです。Pattern: Stack Environment Variables (パターン: スタック環境変数)スタックツールが使用するパラメータ値を環境変数として設定することは、実行前のセットアップを容易にし、またパラメータの可視性を向上させますが、その管理は別の機構に依存します。Pattern: Scripted Parameters (パターン: スクリプト化されたパラメータ)パラメータ値をスクリプトに埋め込むことで、環境ごとの一貫性を保証することができ、手動入力時の問題を避けられます。しかし、シークレット情報の扱いには注意が必要です。Pattern: Stack Configuration Files (パターン: スタック構成ファイル)パラメータファイルを用いることで、環境ごとにカスタマイズされた構成をバージョン管理することができます。これは、構成の監査と変更管理において非常に有効なアプローチです。Pattern: Wrapper Stack (パターン: ラッパースタック)ラッパースタックを用いることで、スタックコードの共有を促進し、変更を段階的に配布することができますが、この方法は追加の複雑さをもたらす可能性があります。Pattern: Pipeline Stack Parameters (パターン: パイプラインスタックパラメータ)パイプラインツールを活用してスタックコードを環境に適用する場合、パイプラインの構成にパラメータ値を定義することで、一貫性を保ちつつ効率的に構成を管理できます。Pattern: Stack Parameter Registry (パターン: スタックパラメータレジストリ)中央のレジストリにパラメータ値を格納することで、スタックのインスタンス構成情報を一元管理し、システム全体の設定変更に対する可視性と監査性を向上させます。スタックの再利用は、一貫性のある構成管理を実現する上で重要です。異なるスタックインスタンスが大幅に異なる場合には、それぞれを異なるスタックとして定義することが推奨されます。この章を通じて、スタックパラメータの管理と適用のアプローチが多様であることが明らかになりました。特にセキュリティに関する配慮が必要な部分では、最初から安全な取り扱いを心がける必要があると強調されています。システムやチームの成熟度に応じて適切な構成管理のアプローチを選択することが重要だと感じます。環境やチーム間での一貫性を保ちつつ、セキュリティを確保するための実践的なアドバイスを得ることができました。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)継続的なテストとデリバリーはインフラストラクチャコードの品質を維持し、信頼性を高めるための不可欠な実践です。アジャイルの原則に沿い、小さな変更を頻繁にテストし、即座にフィードバックを得ることで、品質を段階的に向上させていくことが強調されています。このプラクティスは、開発者が直面する潜在的な問題を早期に特定し、修正することを可能にし、最終的にはより安定したインフラストラクチャの配信につながります。長期的には、このアプローチはリリースプロセスの効率化と、エラー発生時の迅速な対応を促進します。Why Continuously Test Infrastructure Code?継続的なテストは、インフラストラクチャを一貫して信頼できる状態に保つために不可欠です。インフラストラクチャが変化し続ける環境では、変更の配信を効果的に行う上で重要なテスト自動化のスイートを構築することが求められます。このプロセスは、開発から運用に至るまでのライフサイクル全体を通じてインフラストラクチャの品質を確保し、継続的な改善を促進するための基盤となります。テストの自動化は、未来の変更に対しても柔軟に対応できる堅牢なインフラを構築する上で、決定的な役割を果たします。What Continuous Testing Means継続的なテストは、品質をコードライティングプロセスに組み込むことで、問題を早期に発見し解決することを意味します。このアプローチは、開発者がコードを書く際にリアルタイムでフィードバックを得られるようにし、問題の迅速な特定と修正を可能にします。この即時性は、システム開発における迅速なイテレーションと改善を実現し、技術的負債の蓄積を避けることを目指します。What Should We Test with Infrastructure?インフラストラクチャのテストは、機能性だけでなく、セキュリティやコンプライアンス、パフォーマンスなど、幅広いリスクの管理を包括します。CDプロセスでは、これらのリスクをリリース前にテストし、潜在的な問題を事前に特定し修正することで、プロダクション環境へのリスクを最小限に抑えることを目指します。Challenges with Testing Infrastructure Codeインフラストラクチャコードのテストにはいくつかの課題があり、これらはしばしばデリバリーの速度と品質に影響を与えます。デクララティブなコードのテストが低価値であること、テストプロセスが遅いこと、そして依存関係による複雑さがそれらです。Challenge: Tests for Declarative Code Often Have Low Valueデクララティブなコードのテストは冗長な場合が多く、実際のリスクの特定や管理にはあまり寄与しません。テストはリスクを管理するためのものであり、単なるコードの繰り返しではないため、デクララティブなコードに対しては、より高いレベルのリスク分析とそれに基づいたテスト戦略が求められます。Challenge: Testing Infrastructure Code Is Slowインフラストラクチャコードのテストはプラットフォーム上でのインスタンスのプロビジョニングを必要とするため、遅延が生じる傾向があります。テストプロセスの速度を向上させるためには、小さなコンポーネントに分割し、依存関係を最小限に抑えることが重要です。Challenge: Dependencies Complicate Testing Infrastructure依存関係はインフラテストの複雑さを増大させます。モックやテストダブルなどを使用して依存関係をシミュレートすることで、テストの実施をより実用的かつ迅速にすることが可能です。Progressive Testing段階的なテストは、初期のシンプルなテストから始めて徐々に統合の範囲を広げる戦略です。テストピラミッドは、より低レベルのテストを多くし、高レベルの統合テストは少なくするべきだと提唱し、スイスチーズモデルは、複数のテストレイヤーが組み合わさることで、単一レイヤーの穴を補完することを示します。これらのモデルは、リスクを管理するために、どのステージでどのテストを行うべきかを考える上で役立ちます。Figure 8-1. Scope versus speed of progressive testing より引用Infrastructure Delivery PipelinesCDパイプラインは、プログレッシブテストとデリバリーを組み合わせたもので、自動化により一貫性を保ちます。パイプラインの各ステージは特定のトリガーやアクティビティを持ち、適切なスコープとプラットフォーム要素を備えています。パイプラインの構築には、適切なソフトウェアまたはサービスが必要ですが、これによってインフラストラクチャの変更が効率的に、かつ一貫して配信されることが保証されます。Testing in Productionプロダクションでのテストは、他の環境では再現できないリアルな条件下でのリスクを検証する機会を提供します。プロダクション環境には再現できない要素が多く存在し、これらを通じてリアルタイムでのリスク管理を実施することができます。プロダクションでのテストに伴うリスクを管理するためには、監視、可視性の向上、ゼロダウンタイムデプロイメント、プログレッシブデプロイメント、データ管理、カオスエンジニアリングなどの戦略が不可欠です。インフラストラクチャのテストは、その構築と運用の基盤です。この章ではインフラストラクチャのテストに関する一般的な課題とアプローチについて説明しましたが、テストとQAはインフラストラクチャアズコードの成功に不可欠なため、これらの分野に関するさらなる知識を深めることが推奨されます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)9. Testing Infrastructure Stacksこの章の焦点は、インフラストラクチャスタックのテストにあります。現代のソフトウェア開発では、インフラストラクチャのコードもアプリケーションのコードと同様に継続的にテストされるべきであるという考え方が強調されています。これはSREの実践においても極めて重要で、システムの安定性と効率性を保つためには、テストの自動化と継続的な改善が不可欠です。Example Infrastructureここでは、具体的なインフラストラクチャの例としてShopSpinnerのケースが紹介されます。この例を通して、リアルなインフラストラクチャの構築と管理の課題を理解することができ、特に再利用可能なスタックの概念が実際のプロジェクト管理においてどのように役立つかが明らかになります。The Example StackShopSpinnerのスタックの具体的な構成を示すセクションです。ここでの重要なポイントは、効率的なリソース管理とスタックのモジュール化の重要性です。これらの概念は、大規模なシステムにおいてコードの再利用性とメンテナンス性を高めるために重要です。Pipeline for the Example Stackこのセクションでは、ShopSpinnerのインフラストラクチャスタックに対するパイプラインの設計について説明されています。パイプラインの構成は、継続的インテグレーション（CI）と継続的デリバリー（CD） の実践に欠かせない要素であり、効率的な開発プロセスを実現するためのキーです。Figure 9-1. Simplified example pipeline for a stack より引用Offline Testing Stages for Stacksオフラインテストは、インフラストラクチャスタックの開発段階において、コードの品質を確保するために非常に重要です。この段階では、ネットワーク接続や実際のリソースへのアクセスなしにテストを行います。Syntax Checkingシンタックスチェックは、最も基本的ながらも重要なテストの一つです。このプロセスは、コード内のタイポや文法の誤りを迅速に特定し、より大きな問題が発生する前に修正する機会を提供します。Offline Static Code Analysis静的コード分析は、より高度なエラー検出やコーディングスタイルの改善に役立ちます。これにより、コードの品質とセキュリティが大幅に向上します。Static Code Analysis with APIAPIを用いた静的コード分析は、特定のインフラストラクチャプラットフォームに対するコードの適合性をテストするために重要です。これにより、実際の環境へのデプロイ前に潜在的な問題を特定できます。Testing with a Mock APIモックAPIを使用するテストは、実際のAPIとの統合前に、コードが期待通りに機能するかどうかを検証するのに役立ちます。これは、特に大規模なシステムでの統合テストにおいて重要です。Online Testing Stages for Stacksオンラインテストは、実際のインフラストラクチャや外部サービスとの統合を伴うテストです。これにより、オフラインテストでは捉えきれない実際の環境での動作を確認できます。Preview: Seeing What Changes Will Be Made変更のプレビューは、実際にコードを適用する前に、どのような変更が行われるかを確認するプロセスです。これは、特にインフラストラクチャの変更に伴うリスクを軽減するために重要です。Verification: Making Assertions About Infrastructure Resourcesインフラストラクチャリソースに関するアサーションの作成は、スタックが正しく設定されていることを検証するための手段です。これにより、システムの整合性とパフォーマンスを保証できます。Outcomes: Proving Infrastructure Works Correctlyインフラストラクチャが正しく機能していることを証明するためのテストは、最終的なユーザーエクスペリエンスに直接関連するため、非常に重要です。これにより、実際の環境でのインフラストラクチャの振る舞いを確認できます。Using Test Fixtures to Handle Dependenciesテストフィクスチャを使用して依存関係を処理する方法は、テストプロセスの複雑さを軽減し、より継続的かつ効率的なテスト環境を構築するための効果的なアプローチです。Test Doubles for Upstream Dependencies上流依存関係に対するテストダブルは、実際の依存関係なしでスタックをテストするための仮想的な環境を提供します。これは、開発プロセスの柔軟性を大幅に高めます。Test Fixtures for Downstream Dependencies下流依存関係に対するテストフィクスチャは、他のスタックが利用するリソースを提供するスタックのテストに役立ちます。これにより、インフラストラクチャ間の統合テストの精度が向上します。Refactor Components So They Can Be Isolatedコンポーネントをリファクタリングして単独でテストできるようにすることは、コードの品質と保守性を向上させるために重要です。これにより、システム全体の堅牢性が向上します。Life Cycle Patterns for Test Instances of Stacksスタックのテストインスタンスのライフサイクルパターンは、テスト環境の管理と最適化に関する洞察を提供します。これにより、リソースの使用効率とテストプロセスの効率が向上します。Pattern: Persistent Test Stack持続的テストスタックパターンは、安定したテスト環境を提供するが、時間が経つにつれて問題が発生する可能性があります。継続的なメンテナンスと監視が必要です。Pattern: Ephemeral Test Stackこのセクションは、エフェメラルテストスタックのパターンに焦点を当て、テストのたびに新しいインスタンスを作成して破棄する方法を提案します。このアプローチは、クリーンな環境を保証し、過去のテストからの\"クラッター\"（不要なデータや設定）による影響を排除します。私の経験から言うと、この方法は、特に頻繁に変更されるコードベースにおいて、信頼性と一貫性のあるテスト結果を提供するのに非常に有効です。しかし、新しい環境を都度設定するための時間コストは考慮する必要があります。特に、大規模なインフラストラクチャの場合、セットアップに時間がかかり、フィードバックループを遅くする可能性があります。Antipattern: Dual Persistent and Ephemeral Stack Stagesここで取り上げられているのは、永続的スタックとエフェメラルスタックの両方を組み合わせたアンチパターンです。この方法は、理論上は早急なフィードバックと堅牢なテスト環境の両方を提供するはずですが、実際には両方のアプローチの欠点を引き受けることになります。例えば、永続的スタックのインスタンスが\"ウェッジ状態\"（変更によって不安定な状態）になると、エフェメラルスタックステージがその安全網となる可能性があります。しかし、これはリソースの二重消費を招くだけでなく、結局のところ、チームは永続的スタックの問題を解決するために時間を費やさなければならない場合があります。Pattern: Periodic Stack Rebuild定期的なスタック再構築のパターンは、永続的なテストスタックを定期的に再構築することで、リソースの使用量の蓄積や、更新プロセスの信頼性の低下を防ぐことを目的としています。このアプローチは、特にメモリやストレージがテストの実行に伴い徐々に消費される場合に効果的です。ただし、これは根本的な問題を覆い隠す一時的な解決策であり、問題の本質的な解決には至らないことに注意が必要です。Pattern: Continuous Stack Reset連続スタックリセットのパターンは、各テストステージの完了後にスタックインスタンスを自動的に破棄し再構築することで、常にクリーンな状態を保つことを目指しています。この方法は、テスト実行のたびに一から環境を構築する時間を節約できる一方で、背後で発生する問題を見落とすリスクがあります。例えば、バックグラウンドでのインスタンス破棄が失敗した場合、次回のテスト実行時に問題が顕在化する可能性があります。Test Orchestrationテストオーケストレーションに関しては、テストフィクスチャの作成、テストデータのロード、テストスタックインスタンスのライフサイクル管理、テストツールへのパラメータ提供、テストツールの実行、テスト結果の統合、テストインスタンス、フィクスチャ、データのクリーンアップなど、多岐にわたる活動が含まれます。このセクションは、これらの複雑なプロセスを効率的に管理するための実践的なガイダンスを提供しています。Support Local Testingローカルテストのサポートは、開発者が共有パイプラインや環境にコードをプッシュする前に自分でテストを実行できるようにすることを目的としています。これは、特にクラウドベースのインフラストラクチャで働く開発者にとっては不可欠です。ローカルでのテストは、より迅速なフィードバックを可能にし、開発プロセスの効率を大幅に向上させることができます。Avoid Tight Coupling with Pipeline Toolsパイプラインツールとの密接な結合を避けることは、テストオーケストレーションの柔軟性と再利用性を保つ上で非常に重要です。パイプラインツールにテストを強く結びつけると、テストのセットアップや実行をパイプライン外で行う際に困難が生じることがあります。テストオーケストレーションを独立したスクリプトまたはツールで実装することは、パイプラインオーケストレーションとテストオーケストレーションの関心を適切に分離するのに役立ちます。Test Orchestration Toolsテストオーケストレーションツールに関しては、多くのチームがカスタムスクリプトを書いてテストをオーケストレーションしています。これらのスクリプトは、Bashスクリプト、バッチファイル、Ruby、Pythonなど、さまざまな言語で記述されることがあります。しかし、特定のワークフローに特化して設計されたツール（例：Test Kitchen、Molecule）も存在しますが、自分のニーズに合わせて設定するのは難しいことがあります。この章全体を通して、インフラストラクチャスタックのテストに関する包括的な概観と、その実践的な実装について深く掘り下げられています。スタックコードのテストにはまだ十分に成熟したツールや実践が存在しない中、この章は、現在利用可能なツールやカスタムスクリプティングを活用して、これらの課題にどのように対処するかを示唆しています。これは、インフラストラクチャのテストプロセスに取り組む上での貴重な洞察を提供するものであり、非常に有用です。さいごに現代のソフトウェア開発と運用の中核となる要素、すなわちインフラストラクチャスタックの管理と運用について深く探究しています。このセクションは、インフラストラクチャコードの設計、開発、テスト、デプロイメントの各フェーズにおけるベストプラクティスと戦略を詳細に説明しており、現代のIT環境における効率性、スケーラビリティ、信頼性の実現に必要な知識とツールを提供します。特に注目すべきは、インフラストラクチャとアプリケーションの間の相互依存性の管理と、自動化されたテストプロセスの重要性に焦点を当てた点です。これらのトピックは、DevOps文化の中心であり、迅速かつ効率的なソフトウェアデリバリーを可能にする基盤となっています。また、パイプラインの設計とオーケストレーションのセクションは、コードの変更が生産環境にどのように流れるか、そしてそのプロセスをどのように最適化し、安全に保つかについての洞察を提供しています。この部分は、持続可能なインフラストラクチャ管理のための戦略的アプローチを明らかにし、リスクを最小限に抑えつつ高いパフォーマンスを実現する方法を提案しています。セクション全体を通して、可読性、再利用性、モジュール性の観点からインフラストラクチャコードを設計することの重要性が強調されています。コードの品質と管理性を高めることは、時間の経過と共にシステムのメンテナンスと進化を容易にします。また、セキュリティとコンプライアンスの考慮は、現代のインフラストラクチャスタックの設計と運用において不可欠な要素です。最終的に、このセクションは、インフラストラクチャスタックの管理における複雑性と挑戦に対処するための網羅的で実践的なガイドを提供しており、読者にとって非常に価値のあるリソースであると言えます。この知識を活用することで、ITプロフェッショナルはより強固で効率的なシステムを構築し、ビジネスの成長と変化に迅速に対応できるようになるでしょう。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/015354","isoDate":"2023-11-15T16:53:54.000Z","dateMiliSeconds":1700067234000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文","contentSnippet":"はじめに2016年、初版の『Infrastructure as Code』がリリースされ、クラウド技術の運用における新たな標準をぶち立てました。公式サイトもここに置いておきます。infrastructure-as-code.com初版の2017年に日本語版がリリースされました。mizzy.orgそれから4年後、待望の『Infrastructure as Code, 2nd Edition』が登場した。この新版は、サブタイトルを「Managing Servers in the Cloud」から「Dynamic Systems for the Cloud Age」へと変更し、クラウド技術の進化と共に変わるシステム管理のダイナミクスに焦点を当てている。さらに、360ページから427ページへと内容が拡張され、より包括的な情報と洞察が提供されている。残念ながら、『Infrastructure as Code, 2nd Edition』の日本語版は現在提供されていませんがこの本はクラウドインフラストラクチャの管理に関して重要な洞察と知識を提供しており、その内容は多くの専門家や技術者にとって非常に価値があります。Infrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon『Infrastructure as Code』の第二版では、かつて新しい概念として導入されたインフラストラクチャとしてのコードが、今や世界中の企業、銀行や伝統的な組織を含めてクラウドへの移行が進む中で、開発チームが大規模なインフラコードベースの構築において不可欠なものとなっています。この改訂版は、DevOpsチームによって開発された原則、実践、パターンを活用し、クラウド時代に適したインフラの管理方法を明らかにしています。システム管理者、インフラエンジニア、ソフトウェア開発者たちに、クラウドと自動化技術を用いて、容易に、安全に、迅速に、かつ責任を持って変更を加える方法を教えます。また、コードとして全てを定義し、小さく疎結合な部品を組み合わせてシステムを構築する技術も伝えます。ただし、日本語版のリリースがなされぬままに、次の第三版が出版される可能性があります。これはそういった悲しみの読書感想文でもあります。また、このブログはずっと。次回の記事syu-m-5151.hatenablog.com目次I. Foundations (基礎)1. What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)   - インフラストラクチャをコードで管理する概念とその重要性について説明します。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)   - クラウドインフラストラクチャ管理の基本原則を掘り下げます。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)   - 現代のインフラストラクチャプラットフォームの種類と特徴について論じます。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)   - インフラストラクチャ要素をコードとして定義する実践方法に焦点を当てます。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードの提供)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。I. Foundations (基礎)What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)この章は、現代のITインフラストラクチャの管理における根本的なシフトを示唆しています。クラウドとインフラストラクチャの自動化技術は、より迅速かつ信頼性の高い価値提供を可能にする一方で、管理するべきものの複雑さと多様性を増大させています。このジレンマは、組織がデジタル化するにつれて特に重要になってきています。「デジタル」という言葉は、ソフトウェアシステムが組織の活動に不可欠であることを意味します。これは私自身のソフトウェアエンジニアおよびSREとしての経験にも共鳴します。変更管理プロセスを厳格化することで混乱を防ごうとする試みは、しばしばクラウド技術の利点を損なうものです。「クラウドと自動化技術を利用して、変更を容易に、安全に、迅速に、そして責任を持って行うことができる」というこの本の前提は、特に重要です。この利点は、自動化ツールやクラウドプラットフォームというツールそのものからではなく、これらの技術の使い方に依存しています。印象的なのは、インフラストラクチャとしてのコード（IaC）が、ソフトウェア開発からの実践に基づいたインフラストラクチャの自動化へのアプローチであるという点です。これは、システムのプロビジョニングと変更およびその設定を一貫して、繰り返し可能なルーチンとして扱います。コードの変更を行い、それらの変更をシステムに自動的にテストし適用します。この章はまた、クラウド時代のインフラストラクチャへのアプローチが、速度と品質の間の偽のジレンマを排除する方法を説明しています。速度を品質向上の手段として利用し、品質を高速なデリバリーの可能性として利用します。また、このような言及が出てくるのもソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとして定着しているこの本ならではだなって思いました。t-wada.hatenablog.jp「クラウド時代のインフラストラクチャを管理するためには、クラウド時代のマインドセットが必要」というメッセージは、私の経験と完全に一致します。クラウド時代では、変更の速度を利用してリスクを減らし、品質を向上させる新しい考え方が求められます。このアプローチは、根本的なアプローチの変更と変更とリスクに対する新しい考え方を必要とします。\"A fundamental truth of the Cloud Age is: Stablity comes from making changes.\"（クラウド時代の基本的な真理は：変更から安定性が生まれる）は、インフラストラクチャの管理における直感に反すると思いますが2023年の現在ではとても納得することが出来ます。未パッチのシステムは安定しているのではなく、脆弱であり、発見した問題をすぐに修正できない場合、システムは安定していないという考え方です。最後に、インフラストラクチャとしてのコードの3つのコアプラクティス：すべてをコードとして定義する、進行中のすべての作業を継続的にテストし提供する、そして、独立して変更できる小さくシンプルな部品を構築する、これらはインフラストラクチャの管理における新しい標準を示しています。似たようなプラクティスはソフトウェア開発でももちろん存在していてソフトウェア開発のプラクティスをインフラ管理に持ち込める強みのようなものを強く感じました。レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス作者:David Scott BernsteinオライリージャパンAmazonこの章を読んで、クラウド時代におけるインフラストラクチャ管理の新しい考え方とアプローチについての理解が深まりました。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)この章は、クラウド時代のインフラストラクチャ設計と実装における基本原則を提示し、それらがどのように従来の「鉄の時代」のインフラストラクチャと異なるかを示しています。クラウド時代はコンピューティングリソースを物理的なハードウェアから切り離し、これらが仮想的な構成物として変更や破棄が可能になります。「鉄の時代」とCloud Native を語っている書籍があり一章だけでも面白いの読んでほしいです。Kubernetesで実践するクラウドネイティブDevOps作者:John Arundel,Justin DomingusオライリージャパンAmazon原則: Assume Systems Are Unreliable (システムが信頼できないと仮定する)クラウドスケールのインフラストラクチャでは、信頼性のあるハードウェアを使用しても障害は発生します。この原則は、根底のリソースが変化したときにも中断なくサービスを提供するための設計を必要とします。重要性と実装の方法この原則の重要性は、特にクラウド環境で顕著になります。クラウドでは、物理的なサーバーやネットワーク機器に依存しない仮想化されたリソースを使用します。これらのリソースは柔軟でスケーラブルですが、未知だったりコントロール外の障害の可能性も含まれています。したがって、システムの設計において、予期しないエラーに対処する機能を組み込むことが重要です。障害を前提とした設計では、冗長性の構築、フォールトトレラントなアーキテクチャの採用、自動回復機構の組み込みなどが行われます。例えば、データの自動バックアップ、複数の地域にまたがるサービスのデプロイ、障害発生時にトラフィックを自動的に切り替えるロードバランシングなどがこれに該当します。総合的なアプローチシステムの信頼性を高めるためには、ハードウェアとソフトウェアの両方の側面を考慮した総合的なアプローチが必要です。これには、適切なハードウェアの選択、ログやメトリクスの取り扱い、ソフトウェアの品質保証、セキュリティ対策、そして継続的なメンテナンスとアップデートが含まれます。「システムが信頼できないと仮定する」という原則は、特にクラウドベースのインフラストラクチャにおいて重要です。この原則に従うことで、システムはより堅牢で回復力があり、最終的にはユーザーに対してより信頼性の高いサービスを提供することができます。このアプローチを採用することで、企業は技術的な障害によるリスクを最小限に抑え、ビジネスの継続性を確保することができるのです。参考リンクAWSの公式ドキュメント - AWS Well-Architected FrameworkAWSが提供するこのフレームワークは、信頼性の高いクラウドアプリケーションの設計に関するベストプラクティスを示しています。Google Cloudのドキュメント - Google Cloud Architecture FrameworkGoogle Cloudでの信頼性の高いシステム設計に関する包括的なガイドです。『Site Reliability Engineering』GoogleのSREチームによって書かれたこの本は、大規模なシステムの信頼性を保つための実践的なアプローチを紹介しています。『継続的デリバリー　信頼できるソフトウエアリリースのためのビルド・テスト・デプロイメントの自動化』本書は、本番環境にデプロイされるソフトウェアの設計において考慮すべき点、特に継続的デリバリーをどのように実践するかに重点を置いています。原則: Make Everything Reproducible (全てを再現可能にする)システムの回復性を高める一つの方法は、その部品を容易かつ信頼性高く再構築できるようにすることです。これによりテスト環境を本番環境と一致させたり、負荷の高い時に需要に応じてインスタンスを追加することが容易になります。でも、実際には様々な理由から完全に一致させることは難しいので機能を制限したりコスト削減の為にkube-downscalerやInstance Schedulerなどを入れるようにしましょう。実際の経験から、この原則を守るためのキーポイントは、構成管理とバージョン管理の徹底です。例えば、私が取り組んだプロジェクトでは、全てのサーバー設定や依存関係をコードで管理し、Gitなどのバージョン管理システムを使用しました。これにより、ある特定のバージョンのコードベースから環境を正確に再現できるようになります。また、自動化されたデプロイメントパイプラインを設置することで、一貫性のあるデプロイメントプロセスを確保しました。これは、予期しない問題が生じた場合に、迅速に対応できるようにするために重要です。さらに、継続的インテグレーション（CI）を活用することも大切です。CIツールを使用することで、コードの変更が他の部分に悪影響を及ぼさないかどうかを常に確認できます。例えば、新しい機能を追加する際には、既存のシステムに影響がないかを自動テストで確認します。これにより、安定した本番環境を保ちながら迅速に開発を進めることができます。最後に、ドキュメントの重要性を忘れてはなりません。システムの各部分がどのように機能し、どのように相互作用するかを明確に文書化することで、新しいメンバーやチーム外の人がシステムを理解しやすくなります。これにより、効率的なコラボレーションと問題解決が促進されます。落とし穴: Snowflake Systems (特殊なシステムの罠)スノーフレークシステムは再構築が困難なシステムのインスタンス、または本来似ているべき環境が理解できない方法で異なる環境を指します。これらのシステムはリスクを生み、管理するチームの時間を浪費します。特殊な設定やカスタムの依存関係が原因で、システムが一意的になりすぎることがあります。これは、将来のスケーラビリティやメンテナンス、アップグレードの際に問題を引き起こします。また、これらのシステムは新しいチームメンバーにとって理解しにくく、エラーの原因となる可能性が高まります。原則: Create Disposable Things (廃棄可能なものを作る)ダイナミックなインフラストラクチャに対処するためのシステムを構築することは重要ですが、システム自体がダイナミックであることも重要です。部品を柔軟に追加、削除、開始、停止、変更、移動できるようにすることが重要です。この原則の鍵は、自動化とスケーラビリティです。インフラストラクチャのコード化（Infrastructure as Code: IaC）を採用することで、システムの部品を簡単に作成し、廃棄することができます。また、コンテナ技術やサーバーレスアーキテクチャを利用することで、リソースを効率的に管理し、必要に応じて柔軟にスケールアップまたはスケールダウンできます。これにより、システムのメンテナンスやアップデートを簡単に行い、変更に迅速に対応できるようになります。原則: Minimize Variation (変動を最小限にする)システムが成長するにつれて、理解、変更、修正が難しくなります。多くの異なる種類の部品があるほど、作業は複雑になります。したがって、システムを管理しやすくするためには、異なる種類の部品を少なくすることが有用です。私の経験では、使用する技術やツールの数を最小限に抑えることで、システムの理解と管理が大幅に容易になりました。例えば、異なるプロジェクトやチーム間で同じ技術スタックやツールを使用することで、知識の共有が容易になり、新しいメンバーのトレーニングもスムーズに進みました。Configuration Drift (設定の変動)設定の変動は、かつて同一だったシステムが時間の経過とともに異なるようになることを指します。手動での変更や、一部のインスタンスにのみ自動化ツールを使用して行うアドホックな変更が原因で発生することがあります。この問題を解決するために、私は以前のプロジェクトで、全ての設定変更を中央で管理し、自動化ツールを用いて全インスタンスに一貫して適用する方法を採用しました。これにより、設定の一貫性が保たれ、予期しない問題の発生を防ぐことができました。Configuration Drift: How It Happens, Top Sources + How to Stop It for Good原則: Ensure That You Can Repeat Any Process (任意のプロセスを繰り返せるようにする)再現性の原則に基づき、インフラストラクチャに対して行うあらゆる操作を繰り返せるようにする必要があります。スクリプトや設定管理ツールを使用して行動を繰り返す方が、手動で行うよりも簡単です。実際、私は自動化ツールやスクリプトを利用して、インフラストラクチャの構築、設定、デプロイを繰り返し可能にしました。これにより、新しい環境を迅速かつ一貫して構築でき、エラーの発生率を低減しました。また、これらのプロセスを文書化し、全チームメンバーが理解しやすい形で共有することで、作業の効率化と知識の共有を実現しました。SREにおけるトイルの判断と切り分け方IT Infrastructure Automation: A Beginner’s Guideこの章を読んで、クラウド時代のインフラストラクチャの原則が、伝統的なインフラストラクチャとどのように異なるか、そしてこれらの原則がどのようにクラウドプラットフォームの性質を最大限に活用する鍵となるかを理解しました。クラウドプラットフォームにおける変更の容易さを抵抗するのではなく、品質と信頼性を得るためにそれを利用することの重要性が強調されています。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)この章では、クラウドインフラストラクチャの複雑さを解体し、その構成要素を理解しやすく分類しています。ここで提示されたモデルは、特定の技術やツールに依存することなく、概念やアプローチを議論するための文脈を作り出しています。これは非常に有益で、私たちが使用するテクノロジースタックやプラットフォームに関係なく、議論を関連性のあるものに保つために役立ちます。インフラストラクチャシステムの部品 (The Parts of an Infrastructure System)モダンなクラウドインフラストラクチャは、アプリケーション、アプリケーションランタイム、インフラストラクチャプラットフォームの3つの主要な層で構成されています。この分類は、インフラストラクチャの複雑な世界を整理し、各層がどのように組織全体の機能提供に寄与しているかを明確にします。私の経験では、この3層モデルを理解し、適切に管理することが、効率的なシステム運用に不可欠です。特にアプリケーション層の性能と信頼性を保証するためには、アプリケーションランタイムとインフラストラクチャプラットフォームの調和が必要です。例えば、あるプロジェクトでは、コンテナ化されたアプリケーションをクラウド上で稼働させるために、Kubernetesを使用しました。これにより、アプリケーションランタイムの管理が容易になり、インフラストラクチャプラットフォームのリソースを効率的に利用することができました。また、これらの層を適切に管理することで、全体のシステムメンテナンスやアップグレードもスムーズに行えるようになりました。しかし、すべてのプロジェクトで当てはまるわけではないです。他のプロジェクトには他の要件や制約がありそれぞれに違う正解があると思います。Figure 3-1. Layers of system elements より引用\"Applications and services provide capabilities to your organization and its users. Everything else in this model exists to enable this layer.\" (アプリケーションとサービスは、あなたの組織とそのユーザーに機能を提供します。このモデルの他のすべては、この層を可能にするために存在します。)はアプリケーション層が最終的な目標であり、アプリケーションランタイムとインフラストラクチャプラットフォームがその実現のための手段であることを示しています。これは、インフラストラクチャをただのサポート機能ではなく、組織の目的達成に不可欠な要素として位置づけている点で示唆に富んでいます。インフラストラクチャプラットフォーム (Infrastructure Platforms)このセクションは、インフラストラクチャとしてのコード実践において、ダイナミックなインフラストラクチャプラットフォームがいかに中心的な役割を担っているかを強調しています。クラウド技術は物理ハードウェアからの解放をもたらし、APIを通じた資源の管理を可能にしました。一部をクラウドベースのインフラストラクチャプラットフォームを活用することで、システムの柔軟性と拡張性が大幅に向上しました。例えば、AWSのサービスを使用して、サーバーレスアーキテクチャを構築しました。これにより、物理的なハードウェアの制約から解放され、APIを介してリソースを効率的に管理することができるようになりました。このアプローチは、システムの拡張性を高めるだけでなく、運用コストの削減にも寄与することがあります。\"Virtualization decoupled systems from the hardware they ran on, and cloud added APIs to manage those virtualized resources.\" (仮想化はシステムを実行しているハードウェアから切り離し、クラウドはこれらの仮想化されたリソースを管理するAPIを追加しました。)は仮想化とクラウドがどのようにしてインフラストラクチャの運用を変革したかを端的に表しています。APIによる管理は、リソースの柔軟な扱いを可能にし、インフラストラクチャの変更や拡張を以前に比べて格段に簡単にしました。インフラストラクチャリソース (Infrastructure Resources)インフラストラクチャリソースは、現代のITシステムの根幹を成す重要な要素です。計算、ストレージ、ネットワークのこれら3つの基本リソースは、システムの性能や拡張性を決定づける要因となります。仮想マシン、コンテナインスタンス、データベースインスタンスなどの形態で利用されるこれらのリソースは、クラウドインフラストラクチャにおいて特に重要です。これらを適切に管理し、最適化することで、システムの効率性、柔軟性、信頼性を高めることができます。\"The line between a primitive and a composite resource is arbitrary, as is the line between a composite infrastructure resource and an application runtime service.\" (プリミティブリソースとコンポジットリソースの間、またコンポジットインフラストラクチャリソースとアプリケーションランタイムサービスの間の線引きは任意です。)は、インフラストラクチャリソースのカテゴライズが一定の基準に基づいているわけではなく、使用する文脈や目的に応じて変わることがあるという点を浮き彫りにしています。重要なのは、これらのリソースをどのようにして有効に組み合わせ、運用するかということであり、そのためには柔軟性が必要です。全体を通して、この章はクラウドインフラストラクチャの理解を深め、それぞれの要素がどのように相互作用して機能するのかを示す貴重な洞察を提供しています。これらの知識は、インフラストラクチャとしてのコードを実践する上で、私たちが直面する課題への取り組み方や、利用可能な技術を選択する際の指針となります。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)インフラストラクチャをコードとして定義する理由 (Why You Should Define Your Infrastructure as Code)インフラエンジニアとして、インフラストラクチャをコードとして定義することの価値を語るのは、自明の理だと感じます。しかし、このアプローチは私たちの仕事を根本的に変えました。初めて自動化スクリプトを書いたとき、それは単なる作業の簡略化ではなく、再利用可能性、一貫性、透明性をもたらしました。これは組織のアジリティを高め、変更を迅速かつ確実に行う能力を提供する秘密の要因となります。これらの価値は、インフラストラクチャの変更が頻繁であろうとなかろうと、品質を向上させるために速度を活用することにあります。コードとして定義できるもの (What You Can Define as Code)過去にはプラットフォームのウェブベースのユーザーインターフェイスを使用したり、CLIを駆使してインフラストラクチャを手動でプロビジョニングすることが一般的でした。しかし、インフラストラクチャをコード化することで、過去のプロジェクトで見た、可視性の高い変更管理と迅速な展開の実現が可能となりました。これは、経験上も正しく技術的な変更が頻繁に発生する環境で特に重要です。インフラストラクチャをコードとして定義することは、変更の自動化、文書化されたプロセス、およびエラーの減少に大きく貢献します。また、様々な現場ではIaCを通じて運用効率の向上、設定の一貫性、そしてセキュリティの強化を実現しています。IaCはリスクを軽減し、復元力の高いシステムを構築するための重要な手段となっています。さらに、チームの生産性の向上とスケールアップの際の柔軟性も、IaCの利用によって可能となっています。インフラストラクチャコーディング言語 (Infrastructure Coding Languages)スクリプト言語やDSLの使用から、一般的なプログラミング言語を使用したインフラストラクチャのツールへの移行は、運用の柔軟性を飛躍的に向上させました。以前に取り組んだプロジェクトでは、Terraformのような宣言的言語を使用してインフラストラクチャを定義し、それがもたらすシンプルさと明確さに驚かされました。このようなツールにより、インフラストラクチャのコードが従来のプログラミングコードと同様に「リアルなコード」として扱われるようになりました。インフラストラクチャをコードとして定義するための実装原則 (Implementation Principles for Defining Infrastructure as Code)宣言的と命令的コードを混在させることなく、インフラストラクチャコードを「リアルな」コードとして扱うことは、私たちのコードベースをクリーンに保つために不可欠です。参加した多くのプロジェクトでは、技術的負債を積極的に管理し、コードの品質を維持するために、コードレビュー、ペアプログラミング、自動テストなどの慣行を取り入れていました。これらは、インフラストラクチャコードの維持可能性を確保するために重要な実践です。この章は、システムをコードとしてどのように定義するか、その方法とその背後にある理由を詳細に説明しています。インフラストラクチャを定義するための適切な言語を選択することは、効果的なインフラストラクチャを構築する上での重要な課題です。私の経験では、この課題はまだ解決されていませんが、本書を通じて、このテーマが再び現れ、私たち全員が最善の方法を発見するための考察を深めることを期待しています。まとめ『Infrastructure as Code』の初めの4章は、クラウド時代のインフラストラクチャ管理の新しいパラダイムを解き明かしています。第1章では、変更を効率的に、安全に、かつ迅速に行うためのインフラストラクチャとしてのコード（IaC）の基礎を設定します。第2章では、システムの不確実性を前提とし、再現性、廃棄可能性、変動の最小化といったクラウド時代のインフラストラクチャ設計の原則に深く潜ります。第3章は、インフラストラクチャプラットフォームとそのリソースがどのようにアプリケーションランタイム層の構築に寄与するかを具体的に説明し、計算、ストレージ、ネットワークという基本リソースを掘り下げます。そして第4章は、これらのリソースをシンプルで独立して変更可能な部品に分けることの重要性を強調し、チームワークフローとインフラストラクチャの安全な変更方法について具体的なガイダンスを提供します。これらの章は、IaCの実践における基本的な理解を構築し、次のセクション「II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)」でのより具体的なスタック構築への取り組みへと説明してくれます。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/15/134317","isoDate":"2023-11-15T04:43:17.000Z","dateMiliSeconds":1700023397000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Terraformの条件分岐にうってつけの日","contentSnippet":"Infrastructure as Codeの概念とTerraformの役割Infrastructure as Code (IaC) は、現代のインフラ管理の根幹を成すものです。IaCがどんなものか様々な言論があると思いますが、ここではソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとIaC 本に準拠しておきます。IaCによる自動化、バージョン管理、テスト、そして継続的インテグレーションなどのプラクティスは、システム管理の世界に革命をもたらしました。ちなみに個人的には各々のプラクティスを一つずつ実践しない度にIaCの価値は一つずつ確実に下がっていくものだと確信してます。ですが、各々にコストがかかるものなので各プラクティスをどこまで実践するかは非常に難しい問題だとも同時に思います。その中で周知の事実だとは思いますがTerraformは、これらのプラクティスを宣言的なインフラストラクチャの管理、定義、および構成に応用することで、効率性と柔軟性の高いインフラストラクチャ管理を可能にします。このツールは、設計から実装までの過程を劇的に変える可能性を秘めています。Infrastructure as Codeの概念とTerraformの役割に関する参考リンクInfrastructure as Code - AWSInfrastructure as Code - Google CloudIntroduction to Terraform - HashiCorpInfrastructure as Codeの原則とTerraformInfrastructure as Codeの原則には、以下のような要素が含まれます​​:簡単に再現できるシステム: Terraformを使用することで、インフラストラクチャをコードとして定義し、簡単に再現可能なシステムを構築できます。使い捨てにできるシステム: サーバーなどのリソースを一時的なものとして扱い、必要に応じて簡単に生成・破棄できます。統一的なシステム: 全てのインフラストラクチャのコンポーネントを統一的な方法で管理します。反復できるプロセス: 同じ設定を繰り返し適用することで、一貫性と信頼性を保ちます。これらの原則に基づいて、Terraformは以下のような機能を提供します:リソースの自動生成と管理: Terraformを使用すると、インフラストラクチャのリソースを自動的に生成・管理できます。宣言的なインフラの構築: Terraformを通じて、インフラストラクチャの状態を宣言的に定義し、計画的かつ一貫性のある方法でインフラを構築・更新します。バージョン管理のサポート: Terraformの設定ファイルはバージョン管理システムで管理でき、変更履歴を追跡できます。モジュールと再利用可能なコンポーネント: Terraformではモジュールを使って、コードの再利用性を高めます。なのでそれ以外のプラクティスに関しては別のソリューションで実現してあげる必要があります。Terraformの条件分岐のテクニックと利用場面もう少し能書きを垂れるかなって思ったんですけどもう飽きたので普通にテクニックや使い方の話をしていきます。Terraformは基本的に宣言的なインフラ定義ツールですが、宣言的だけでは現実の複雑な要求を満たすのが難しい場合があります。そのため、Terraformは手続き型プログラミングに近い柔軟性も提供します。条件分岐やループなど、より具体的な制御が必要な場面で役立つ機能を組み込んで、効率的かつ柔軟なインフラ管理を実現しています。それでは、これらのテクニックや利用場面について、具体的な例を交えて詳しく見ていきましょう。ループ (countとfor_each)ループは、同じタイプのリソースを複数回作成する際に便利です。countやfor_eachを使用して、コードの重複を避けながら、効率的にリソースを管理できます。利用場面A: 異なる環境に同一種類のリソースを複数作成resource \"aws_instance\" \"dev_servers\" {  count         = 5  instance_type = \"t2.micro\"  # その他の設定}利用場面B: 複数のユーザーにIAMロールを割り当てresource \"aws_iam_user\" \"users\" {  for_each = toset([\"alice\", \"bob\", \"charlie\"])  name     = each.value  # その他の設定}条件分岐 (countを使用)条件分岐を使用すると、環境やパラメータに基づいてリソースの作成を制御できます。これにより、開発環境と本番環境などで異なるリソース設定を実現できます。利用場面A: 本番環境でのみデータベースのインスタンスを作成resource \"aws_db_instance\" \"prod_db\" {  count = var.is_production ? 1 : 0  # データベースの設定}利用場面B: 開発環境ではリソースを作成せず、本番環境でのみ特定のリソース（例: S3バケット）を作成したい場合。resource \"aws_s3_bucket\" \"prod_bucket\" {  count  = var.env == \"prod\" ? 1 : 0  bucket = \"my-production-bucket\"  acl    = \"private\"}ここではvar.env変数がprod（本番環境）の場合にのみS3バケットを作成します利用場面C: 特定の機能フラグ（例: 監視機能の有効化）がオンの場合にのみ、関連リソース（例: CloudWatchアラーム）をデプロイしたい。resource \"aws_cloudwatch_metric_alarm\" \"example_alarm\" {  count               = var.enable_monitoring ? 1 : 0  alarm_name          = \"High-CPU-Utilization\"  comparison_operator = \"GreaterThanThreshold\"  evaluation_periods  = \"2\"  threshold           = \"80\"  # その他の設定}この例では、var.enable_monitoringがtrueの場合にのみCloudWatchアラームを作成します。ゼロダウンタイムデプロイメント (create_before_destroyを使用)ゼロダウンタイムデプロイメントは、システムやアプリケーションの更新時にサービスを停止することなく、新しいバージョンへの移行を行う手法です。Terraformにおけるゼロダウンタイムデプロイメントでは、create_before_destroyライフサイクル設定を使用して、新しいリソースを古いリソースを削除する前に作成します。これにより、サービスが継続的に稼働しつつ、背後で安全にリソースの更新や交換が行われます。利用場面A: アプリケーションの更新時に新旧インスタンスの平滑な切り替えresource \"aws_instance\" \"app_server\" {  ami           = \"ami-newversion\"  instance_type = \"t2.micro\"  lifecycle {    create_before_destroy = true  }  # その他の設定}このコードは、新しいAMIでEC2インスタンスを作成します。create_before_destroyがtrueに設定されているため、新しいインスタンスが完全に起動し、運用準備が整うまで旧インスタンスは削除されません。これにより、アプリケーションの更新中もサービスが継続して提供されます。利用場面B: インフラのリファクタリング時に既存リソースの無停止更新resource \"aws_s3_bucket\" \"storage\" {  bucket = \"my-new-bucket-name\"  lifecycle {    create_before_destroy = true  }  # その他の設定}この設定では、新しいS3バケットが作成される際、既存のバケットは新しいバケットの設定が完了し、利用可能になるまで保持されます。これにより、データの移行やバケットの設定変更が行われる際にも、サービスの中断を回避できます。ゼロダウンタイムデプロイメントの限界ゼロダウンタイムデプロイメントは最高だと思った皆様、悲報です。ゼロダウンタイムデプロイメントを行う際にcreate_before_destroyを使用すると、いくつかの問題点があります。特に、オートスケーリングポリシーを使うと、デプロイメントごとに自動スケーリンググループ（ASG）のサイズが最小サイズに戻ることが問題です。これは、デプロイメント時にサーバー数が本来の数より少なくなる可能性があるためです。解決策として、カスタムスクリプトを使用してAWS APIでデプロイメント前のインスタンス数を取得する方法があります。しかし、より重要なのは、複雑なタスクにはネイティブな解決策を使用することが望ましいということです。たとえば、AWSではinstance refreshというオートスケーリンググループ用のネイティブソリューションが提供されており、これはAWSによって完全に管理され、エラー処理も適切です。ただし、このプロセスは時に遅いことが欠点です。一般的には、instance refreshのようなネイティブなデプロイメントオプションを使うことが推奨されています。なので、Providerの実装次第という部分もあると思います。Lifecycle をちゃんとやっていると、柔軟性と安全性が格段に向上するlifecycle引数は、リソースの作成と破棄に関するカスタムルールを作成することで、Terraform操作の流れを制御します。これにより、特定のリソースの変更やインフラへの影響を防ぎつつ、リソースニーズに基づいて潜在的なダウンタイムを最小限に抑えることができます​​。prevent_destroy: このオプションは、特定のリソースの削除を防ぐために使用されます。例えば、ある属性の変更によりリソースの置換が必要になりダウンタイムが発生する可能性がある場合、prevent_destroyを使ってリソースの削除を防ぐことができます​​。create_before_destroy: この属性を使用すると、古いリソースを破棄する前に新しいリソースを作成できます。これにより、リソースの置換によるダウンタイムを避けることが可能です。create_before_destroyがない場合、Terraformはまずインスタンスを破棄し、その後再作成しますが、これによりダウンタイムが発生する可能性があります​​。ignore_changes: Terraformのワークフロー外で行われた変更を無視するために使用されます。例えば、AWS CLIで行われた変更をignore_changesを使ってTerraformの操作に影響しないようにすることができますlifecycleの学びの意義は、インフラ管理の柔軟性と安全性を高めることにあります。異なるlifecycleオプションを使用することで、意図しないリソースの削除を防いだり、インフラの再作成時のダウンタイムを最小限に抑えたり、外部からの変更をTerraformのプランに影響させないようにすることができます。これにより、Terraformを使ったインフラの管理がより安全かつ効率的になります。結論とかこれらの使い方はもちろんのこと原則を理解しながら活用することで、インフラストラクチャの管理において幸せな世界観を目指していきましょう。『Terraform: Up \u0026 Running』の日本語版第3版のリリースを心から祝福してます。この本は、Terraformの基本から応用までを幅広くカバーし、多くの開発者やシステム管理者にとってよても良い本となることでしょう。手元においておいて本当に損がない書籍かと思います。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy Brikmanオーム社Amazon参考資料Count: Repeating ResourcesFor Each: Repeating a Module Multiple TimesConditional ExpressionsResource Lifecycle: create_before_destroyManage resource lifecycleTerraform by HashiCorpIntroduction to TerraformZero Downtime Updates with TerraformTerraformチュートリアル - HashiCorp LearnTerraform Best Practices余談Ansible やDockerではどのようにループや条件分岐を実現しているかAnsibleでは組み込まれている機能で実現できますがDockerでは、ループや条件分岐は通常、Dockerfile内では直接実現できません。しかし、Docker Composeやスクリプトを使用して間接的にこれらを処理することができます。Kubernetesでも、ループや条件分岐はマニフェストファイル（YAML）内で直接的にはサポートされていませんが、Helmチャートのようなテンプレートエンジンを使用することで、これらの動作を実現できます。Helmは条件分岐や変数の代入などを可能にするテンプレート機能を提供しているのでそれぞれ紹介します。ループloopキーワードを使用して繰り返しタスクを実行します。- name: パッケージのインストール  yum:    name: \"{{ item }}\"    state: present  loop:    - httpd    - memcachedAnsible Loopsこの例では、.Values.services内の各サービスに対してループを行い、それぞれのnameとportを出力しています。{{- range .Values.services }}- name: {{ .name }}  port: {{ .port }}{{- end }}HelmチャートのテンプレートDocker Composeでのループと条件分岐Docker Composeでは直接的なループや条件分岐のサポートはありませんが、環境変数を利用して擬似的にこれらを実現できます。services:  web:    image: \"webapp:${WEBAPP_TAG}\"    environment:      - DEBUG=${DEBUG_MODE}この例では、WEBAPP_TAGとDEBUG_MODE環境変数を使用しています。条件分岐ステートメントを使用して、特定の条件に基づいてタスクを実行します。- name: 開発環境でのみ実行するタスク  command: echo \"これは開発環境用のタスクです\"  when: env == 'development'- name: 本番環境でのみ実行するタスク  command: echo \"これは本番環境用のタスクです\"  when: env == 'production'Ansible Conditionals{{- if .Values.debug }}environment: \"development\"{{- else }}environment: \"production\"{{- end }}ここでは、.Values.debugの値に基づいて環境を設定しています。debugがtrueならdevelopment、そうでなければproductionが選択されます。Helmのテンプレート関数この節では、Ansible、Docker、そしてKubernetesにおけるループと条件分岐の実装方法を比較しました。これらのツールはそれぞれに独自のアプローチを持っており、その違いを理解することで、適切なツール選択や実装戦略を行う上での参考になります。また、異なるツールでどのように同じ問題を解決しているかを知ることは、より深い技術的理解や柔軟な対応能力を身につけるために重要です。","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603","isoDate":"2023-11-14T06:46:03.000Z","dateMiliSeconds":1699944363000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました","contentSnippet":"概要資料参考文献概要Platform Engineering Meetup #5 で SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用 というテーマで登壇をしました。SREからPlatform Engineerへの拡大のセルフリバイバルになります。このブログでは、参考資料を見るために利用してください。気が向いたら続き書く資料 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?What Team Structure is Right for DevOps to Flourish?Making the Business Case for a Dedicated Platform Engineering TeamCNCF Platforms White PaperSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsTop Strategic Technology Trends for 2023: Platform Engineering道を照らす: プラットフォーム エンジニアリング、ゴールデンパス、セルフサービスのパワーオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイドネットワーク・エフェクト　事業とプロダクトに欠かせない強力で重要なフレームワークINSPIRED 熱狂させる製品を生み出すプロダクトマネジメント","link":"https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555","isoDate":"2023-10-05T14:35:55.000Z","dateMiliSeconds":1696516555000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Open InterpreterのDockerfile を書いたのでTipsとか","contentSnippet":"Dockerfile のベストプラクティスを考える機会はありますが皆さんの意見も聞きたい。今回は噂の便利ツール、Open Interpreterのような外部コマンドをどんどん実行して環境を作り変えるようなタイプのツールの場合にはDockerはとても有用です。そのようなツールを利用する時のDockerfile について考えていきます。リポジトリは以下になります。github.comGitHub Actionsとの連携GitHub Actionsは、CI/CD（継続的インテグレーションと継続的デリバリー）をGithub 上に簡単に実装できるツールです。今回は、trivy.ymlとdocker-publishを利用することで、セキュリティのスキャンとDockerイメージの自動公開が可能です。github.comtrivy.ymlの利用trivy.ymlは、Trivyという脆弱性スキャナーをGitHub Actionsで動かすための設定ファイルです。この設定を利用することで、Dockerイメージに存在するセキュリティの脆弱性を自動で検出できます。docker-publishの追加docker-publishは、DockerイメージをDocker Hubや他のレジストリに自動で公開するためのGitHub Actionsのワークフローです。これにより、新しいバージョンのOpen Interpreterがリリースされた際に、手動でイメージをビルド・プッシュする手間が省けます。Renovate.jsonの利用renovate.jsonは、依存関係を自動で更新する設定ファイルですが、これを使うとOpen Interpreterが依存しているライブラリやパッケージが新しくなったときに、自動でプルリクエストが作られるんです。そうすることで、いつも最新の状態を保てるわけですから、セキュリティリスクも減らせます。さらに、Pythonのパッケージも自動で更新したい場合は、requirements.txtを使って設定しておくと便利です。これにより、Pythonの依存パッケージも最新の状態を維持できるようになります。github.comDockerfileを書く際の注意点私は以下のようなDockerfileを書きましたその際に以下のようなポイントを意識して書いたので参考にしてください。github.com軽量なベースイメージの使用不必要なパッケージを含まない軽量なベースイメージを使用することで、ビルド時間とイメージサイズを削減できます。FROM python:3.11キャッシュの最適化RUNコマンドを効率的に配置することで、Dockerキャッシュを最適化できます。RUN apt-get update \u0026\u0026 \\  apt-get upgrade -y \u0026\u0026 \\  apt-get install -y --no-install-recommends git \u0026\u0026 \\  rm -rf /var/lib/apt/lists/*不必要なパッケージの削除--no-install-recommendsオプションを使用して、不必要なパッケージをインストールしないようにします。  apt-get install -y --no-install-recommends git \u0026\u0026 \\作業ディレクトリの設定WORKDIRを設定することで、その後のコマンドの実行ディレクトリを明示的に指定できます。WORKDIR /root機密情報はコンテナイメージに絶対に埋め込まない社内で有識者へ投げたら機密情報をビルドイメージに追加することを指摘されたので運用時の手癖やミスで何処かのレイヤーに不用意に埋め込まないようにしたgithub.comまとめDockerでOpen Interpreterを運用する際には他にもいろいろ考えるべきことがあると思うので皆さんと議論したいのでIssue待ってます。","link":"https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920","isoDate":"2023-09-19T15:29:20.000Z","dateMiliSeconds":1695137360000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"まずPR-AgentをPromptとします。","contentSnippet":"「ツールよりもプロンプトのほうが、隙間がなくて効率的なのでは？」... ああ、面倒なブログになるな、とおれは直感した。はじめに近年、プルリクエスト（PR）の管理が開発フローにおいてますます重要な位置を占めるようになっています。ただし、PRをより良く作る作業は往々にして煩雑で手間がかかりがちです。その解決策として、Codium AIによって開発されたPR-Agentが脚光を浴びています。このAIソフトウェアは、OpenAIのGPT-4技術を基盤にしており、単にOpenAIのAPIキーを設定するだけで、既存のCI/CDパイプラインに簡単にインテグレーションできます。github.comPR-Agentの主な機能PR-Agentは、様々なPR関連作業を自動化するための多機能なオープンソースプロジェクトです。具体的には、以下のような機能群を提供しています。/describe: タイトル、種類、要約、コードの詳細説明、およびラベルを自動で作成するためのPR（プルリクエスト）説明自動生成機能。/review: PRの主題、種類、関連テスト、セキュリティ問題、評価スコア、その他のフィードバックを調整可能に提供する自動レビュー機能。/ask ...: PRに関するフリーテキスト質問に回答する質問応答機能。/improve: PRを改善するためのコミット可能なコード提案を行うコード改善提案機能。/update_changelog: PRの変更内容に基づき、CHANGELOG.mdファイルを自動で更新する更新履歴自動更新機能。PR-AgentはOpenAIのAPIキーを設定するだけでCI環境に簡単に組み込め、開発者が効率的なPR作成と管理を行えるよう支援します。このツールはGPT-4を用いて高精度なソースコード解析とレビューを自動で行い、開発者が重要なポイントに集中できるようにします。さらに、「PR Compression Strategy」と呼ばれる独自のアルゴリズムによって、大規模なPRでも重要なファイルと主要な言語のコードブロックに焦点を当てた効率的なレビューが可能です。それ以外にもさまざまな設定により、PR-AgentはPR作成とレビューのプロセスを自動化し、効率化する強力なツールであり、大規模プロジェクトにおいてもスムーズかつ効率的なレビュープロセスを実現します。これらをどのように動作させればよいのかはUsage guideを読んでみてください。PR-Agent のPromptPR Compression Strategyにより、送信するファイルの戦略が定められています。その設定に加えて、pr-agent/pr_agent/settings/ ディレクトリには、TOML形式でプルリクエスト（PR）のレビュープロンプトのテンプレートが含まれています。具体的には、pr_review_promptはpr_reviewer_prompts.toml ファイルに定義されており、これがPRのレビュープロセスにおける基本的な指示とフォーマットを規定しています。この構成により、PRレビューが一貫性を持ち、効率的に行えるよう設計されています。pr_reviewer_prompts.toml 解説pr_reviewer_prompts.tomlは、Pull Request（PR）レビューに関する設定と指示を定義する設定ファイルです。この設定ファイルは、PRレビューを自動化する際に利用されます。pr_review_prompt セクションsystemこの設定は、レビュワーがどのような役割を果たすべきかを定義しています。具体的なPR Diffの入力例も提供され、新しく追加されたコード（+で始まる行）に焦点を当てるよう指示されています。system=\"You are PR-Reviewer, a language model designed to review git pull requests. ...\"num_code_suggestionsコード提案が必要な場合、その数や重要度についての指示がこの部分に記載されています。{%- if num_code_suggestions \u003e 0 %}- Provide up to {{ num_code_suggestions }} code suggestions. ...{%- endif %}extra_instructionsパラメータで、追加的な指示や設定を行うために使用されます。この項目は主に以下のような用途で利用されることが多いです。{%- if extra_instructions %}Extra instructions from the user:{{ extra_instructions }}{% endif %}YAMLスキーマこの部分で、PRレビュワーが出力するレビュー結果のYAMLフォーマットが定義されています。Main theme, PR summary, Type of PR, etc.これらは、PRに関する基本情報を整理するためのフィールドです。Main theme:  type: string  description: a short explanation of the PRScore, Relevant tests added, Insights from user's answer, etc.これらのフィールドは、PRに関する詳細な評価やテスト情報、ユーザーからのフィードバックに基づく評価を行います。Score:  type: int  description: Rate this PR on a scale of 0-100 ...General suggestions, Code feedback, Security concernsこれらのフィールドは、具体的なコード提案やセキュリティ上の懸念など、PRのコードに関する詳細なフィードバックを提供します。General suggestions:  type: string  description: General suggestions and feedback for the contributors ...user セクションこのセクションは、PR作成者から提供される情報（タイトル、ブランチ、説明文など）を取り込む場所です。user=\"PR Info:Title: '{{title}}'Branch: '{{branch}}'Description: '{{description}}' ...\"この設定ファイルによって、PRレビューのプロセスが自動化され、一貫性を持つようになります。特定のプロジェクトやチームに特有の要件に応じて、これらの設定はカスタマイズ可能です。まとめpr_reviewer_prompts.tomlといった設定ファイルを読んで全体としてPRのフォーマットに忠実にプロンプトを作成していったのがわかりました。参考にしていきたいと思います。github.com参考PR-Agent を使って Pull Request をAIレビューしてみた。（日本語対応もしてみた）GitHub - Codium-ai/pr-agent: 🚀CodiumAI PR-Agent: An AI-Powered 🤖 Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! 💻🔍","link":"https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227","isoDate":"2023-09-06T07:52:27.000Z","dateMiliSeconds":1693986747000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ChatGPT: SREがCustom instructions機能を利用する","contentSnippet":"はじめに最近、ChatGPTからCustom instructions機能がリリースされました。Custom instructionsとは、ChatGPTの応答方法をより詳細に制御するカスタム命令を設定することができる機能です。ChatGPTの利用者にとって非常に便利な機能です。この機能により、ユーザーは特定の応答スタイルやフォーマットを要求することができるようになりました。これは、特定の業界や専門分野での使用など多岐にわたる用途に適応できるため、非常に有用です。めちゃくちゃ端的にかつ語弊を恐れずにいうと毎回、prompt を入力しなくてよくなるやつです。以前、公開したプロンプトに関するブログsyu-m-5151.hatenablog.comOpenAI CEOのSam Altman氏も、Custom instructionsのポストをしていましたので参考にしてみても良いかもしれません。damn i love custom instructions pic.twitter.com/su0BlttJF7— Sam Altman (@sama) 2023年7月22日  その上で私が利用してるものを公開します。What would you like ChatGPT to know about you to provide better responses?I'm a software developer and primarily use Golang. Depending on the application, I also utilize Shell Script, Terraform, and Ansible.I am a software developer and I like Cloud Native technologies such as Docker and Kubernetes.I like to develop, operate, and optimize systems.Technical advisor for several other companies.Please use Japanese.How would you like ChatGPT to respond?You are an AI programming assistant.Your response should be informative and logical.First, think STEP-BY-STEP, then describe your plan for what to build.Then output the code in a single code block.Keep your answers objective and concise, and use Markdown formatting.Be sure to include the name of the programming language at the start of the Markdown code block.Avoid enclosing your entire response in a triple backtick.また、 respondに信頼性に関する言及を求めていたのですが有益な情報が得られないので削除しておきました。まとめCustom instructions機能は、ChatGPTの応答をより細かく制御する強力なツールです。これにより、ユーザーは特定のニーズに合わせてモデルを調整することができ、より多様で効果的な結果を得ることが可能になります。この機能の導入により、ChatGPTはさらに多岐にわたる分野での応用が期待されます。この書籍はChatGPTによって達成された科学的な貢献や重要性を理解することができるのでオススメです。ChatGPTの頭の中 (ハヤカワ新書)作者:スティーヴン ウルフラム早川書房Amazonおすすめ記事honeshabri.hatenablog.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/22/204327","isoDate":"2023-08-22T11:43:27.000Z","dateMiliSeconds":1692704607000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREからPlatform Engineerへの拡大 というタイトルで登壇しました","contentSnippet":"概要Cloud Operator Days Tokyo 2023 で SREからPlatform Engineerへの拡大 というテーマでの登壇を果たしました。オンデマンド配信なのでいずれ見れるようになると思います。今回のサブタイトルは【運用の新時代】とし、それにちなんでメインタイトルを考えました。資料の作成過程で、話したい内容がどんどんと増えてきてしまい、20分という限られた時間での発表が一番の課題となりました。内容の整理に際して、具体と抽象 ―世界が変わって見える知性のしくみ という本を参照し、大変役立ちました。具体と抽象作者:細谷 功dZERO（インプレス）Amazon資料このブログでは、Cloud Operator Days Tokyo 2023での登壇内容をまとめております。資料作成時に参照したさまざまな参考情報も掲載していますので、読者の皆様が別途情報を探す手間を省けるよう心掛けました。ぜひ、本ブログをご活用ください。文字多くて分かりにくいのは分かってます。脳内整理はできているのですが資料を読みやすくすると20分に何も収まらず...。 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングあなたらしくSREO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?Top Strategic Technology Trends for 2023: Platform EngineeringMaking the Business Case for a Dedicated Platform Engineering TeamSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイド","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412","isoDate":"2023-08-10T06:04:12.000Z","dateMiliSeconds":1691647452000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2023年8月10日現在 でLunarVim と Copilot.lua でのマルチラインサポートの改善方法 ","contentSnippet":"github.comLunarVimユーザーとして、私はNeovimでcopilot.luaを頻繁に利用しています。しかし、マルチラインのサポートに関してはいくつかの課題がありました。もっというとどこかのタイミングでCopilotが一行ずつしかサジェストされなくなりました。この問題に対して、一部のコードを修正することで、この課題を解決する方法を見つけました。問題点Copilot.lua(Copilot.vimも同様に)の中のagent.jsには、マルチライン入力の停止点を示すコード h.stop=[\"\\n\"] が含まれています。この設定により、一部の場面でマルチラインサポートが期待通りに動作しないことがありました。解決方法私が採用した方法は、このh.stop=[\"\\n\"]をh.stop=[\"\\n\\n\\n\"]に変更することです。この小さな変更により、マルチラインのサポートが大幅に向上します。以下のコマンドを実行することで、この変更を簡単に適用することができます。MAC でのsed 利用なのでこのようなコマンドになります。各環境で合わせていただきたいです。sed -i '' 's/h\\.stop=\\[\"\\\\\\\\n\"\\]/h\\.stop=\\[\"\\\\\\\\n\\\\\\\\n\\\\\\\\n\"\\]/' ~/.local/share/lunarvim/site/pack/lazy/opt/copilot.lua/copilot/dist/agent.js変更が正しく適用されたかどうかを確認するには、以下のコマンドを実行します。grep -o '.\\{30\\}h.stop=\\[.\\{30\\}' ~/.local/share/lunarvim/site/pack/lazy/opt/copilot.lua/copilot/dist/agent.js結果この変更を適用した後、マルチラインサポートが明らかに向上しました。興味があれば最初に紹介したIssue に動画が添付されていたのでご覧ください。LunarVimとCopilot.luaの組み合わせは非常に強力ですが、小さな調整によりさらに快適に使うことができます。このハックが他のユーザーにも役立つことを願っています。後日談この変更を適用した後でマルチラインサポートは向上したのですが一部条件ではまだ、vscodeのような挙動ができません。","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/10/021934","isoDate":"2023-08-09T17:19:34.000Z","dateMiliSeconds":1691601574000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"K8sGPT Deep Dive というタイトルで登壇しました #CNDF","contentSnippet":"概要CloudNative Days Fukuoka 2023というイベントに『K8sGPT Deep Dive KubernetesクラスタのAI駆動型分析について』というタイトルで登壇しました。クラウドネイティブとAIを組み合わせることの深い洞察を共有することができ、私自身がエンジニアとして働くなかで、K8sGPTの最新の進化とその可能性について詳しく語る機会はなかなかなく、この経験を活かしていきたい。資料を作っている中で話したいことがどんどん増えていってめちゃくちゃ困った。また、その中でAIOpsについても触れることができ、非常に充実した時間でした。AIOpsはAIと運用管理の統合を指し、それによりIT運用の効率化や自動化が可能となります。その重要性と可能性を伝えることができたので良かった。登壇が終わった今でも、K8sGPTやAIOpsについてさらに知識を深め、クラウドネイティブの世界にどのように最適化された解決策を提供できるかについて考え続けています。参加者の皆さんからもたくさんのフィードバックを頂き、今後の研究や開発の参考になりました。私がこのプレゼンテーションのために読み込んだ複数の本の中で、特に皆さんにお勧めしたい一冊を挙げるとすれば、「大規模言語モデルは新たな知能か――ChatGPTが変えた世界」だと言えます。なぜなら、専門家でも初心者でも、難解な数学を使わずに重要な概念を理解できるように作られているからです。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazon資料登壇資料になります。このブログの目的は参考資料をいちいち探さなくていいようにありますのでご活用ください。 speakerdeck.com参考文献公式ページ | K8sGPTGitHub | K8sGPTGitHub | K8sGPT OperatorDocs | K8sGPTOperator patternK8sGPT OperatorHow to Get Started With AIOpsPrompt Engineering Guideオブザーバビリティ・エンジニアリングKubernetes基盤を自律的に支えるController化の実装Tips / forkwell-202303-amsy810-k8sAutomation and Machine Learning with Site Reliability EngineeringTEMPLE: Six Pillars of ObservabilityAI時代に向けたクラウドにおける信頼性エンジニアリングの未来構想 / DICOMO2022 6A-1大規模言語モデルは新たな知能か――ChatGPTが変えた世界 (岩波科学ライブラリー)ChatGPTの頭の中 (ハヤカワ新書)言語の本質　ことばはどう生まれ、進化したかAI vs. 教科書が読めない子どもたち【ITIL4公認】ITIL 4の基本 図解と実践","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/03/155326","isoDate":"2023-08-03T06:53:26.000Z","dateMiliSeconds":1691045606000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"CLIの実行結果を正しく理解することを促すツールを作成しました。","contentSnippet":"概要AIの技術は目覚ましい進歩を遂げています。特に自然言語処理（NLP）の分野では、GPT-4のようなモデルが人間に近いレベルで文章を理解し、生成することができるようになりました。しかし、これらのモデルを日々の業務や作業にどのように活用すればよいのか、多くの人々がまだ手探りの状態です。一方、コマンドラインは、システム管理者やソフトウェア開発者にとって重要なツールです。コマンドラインからシステムの状態を調べたり、プログラムを実行したりするためには、これらで利用するコマンドの理解とそれらを十分に使いこなすことが必要です。netflixtechblog.comアフィリエイトでも何でもなく運用で利用するコマンドについてはLinuCなどもあるので教材を読むだけでもおすすめしたい。linuc.orgでは、AIがコマンドプロンプトの結果を理解し、それを人間がより理解しやすい形で説明することができたら、どうでしょうか？ここで、AICommandを紹介します。AICommandは、コマンドプロンプトの実行とその結果の解釈を統合したツールであり、AIの力を借りてコマンドプロンプトの結果を理解する新しい試みです。今回の記事では、このAICommandについて詳しく見ていきましょう。シェルコマンドの実行とその結果をOpenAIのGPTモデルに結果を送信し解説を要求するGo製CLIツールです。コマンドの処理状況も視覚的に表示します。 pic.twitter.com/5q6jqyWbsx— nwiizo (@nwiizo) 2023年7月18日  AICommandの紹介AICommandは、コマンドプロンプトの結果を人間が理解しやすい形に解釈するための新しいツールです。OpenAIの強力な自然言語処理モデルを使用して、コマンドラインから得られた情報を詳細に解析し、その結果を説明します。これにより、複雑なコマンドの実行結果も、非専門家でも簡単に理解できるようになります。github.comコマンドプロンプトは非常に強力で、システムの管理やデータの分析には欠かせないツールですが、その結果を正しく理解するには専門知識が必要で、学習コストが高いという課題がありました。しかし、AICommandを使えば、そのハードルが大きく下がります。たとえば、システムのログを確認するためのコマンドを実行した結果を、AIが解釈し、重要なポイントをハイライトしてくれます。さらに、その結果がどういう意味を持つのか、何が原因でそうなったのかといった情報も提供してくれます。このように、AICommandは、AIの能力を利用して、コマンドプロンプトの利用をより手軽で、より理解しやすいものに変えることを目指しています。ソフトウェア開発者やシステム管理者だけでなく、コマンドラインを利用するすべての人々にとって、新たな可能性を広げるツールとなることを目指します。option で日本語にも対応してます。 pic.twitter.com/AkEHh5syPx— nwiizo (@nwiizo) 2023年7月19日  Setup 🔧AICommandはGo言語で書かれているため、Goの開発環境が必要です。まず、Goがまだインストールされていない場合は、公式のインストールガイドに従ってGoをインストールしてください。Install aicommandGoがインストールされたら、次にAICommandをインストールします。go install github.com/nwiizo/aicommand@latestSet the your_api_keyAICommandはOpenAIのGPTモデルを使用しますので、OpenAIのAPIキーが必要となります。OpenAIのアカウントを持っていてAPIキーを取得済みの場合は、そのAPIキーを使用します。まだAPIキーを取得していない場合は、OpenAIの公式ドキュメントを参照してAPIキーを取得してください。APIキーを取得したら、そのキーを環境変数 OPENAI_API_KEYに設定します。設定方法は以下の通りです：export OPENAI_API_KEY=your_api_keyUsage ⏳コマンドの実行とその結果の解釈を行うには、次のように execute コマンドに続けて実行したいコマンドを引数として与えます。コマンドは(ダブル)クオーテーションで囲む必要があります。aicommand execute \"your-shell-command\"たとえば、ディレクトリの内容をリストする ls -la コマンドの結果を解釈させたい場合は、次のように実行します。aicommand execute \"ls -la\"すると、AICommandは ls -la コマンドを実行し、その結果を解釈して人間が理解しやすい形で説明します。また、解釈結果の言語を指定したい場合は、 --language または-lオプションを使用します。現在、英語（en）と日本語（ja）がサポートされています。デフォルトの言語は英語です。aicommand execute --language ja \"ls -la\"さらに、使用するGPTモデルを指定することも可能です。これは --model または -m オプションで指定します。デフォルトは gpt-3.5-turbo です。aicommand execute --model gpt-3.5-turbo \"ls -la\"これでAICommandの基本的な使用方法について説明しました。コマンドプロンプトの結果の解釈がこれまで以上に手軽になり、より深い理解が可能になります。AICommandの可能性🤖AICommandは、私たちが普段利用しているコマンドプロンプトをOpenAIのGPTモデルと組み合わせることで新たな可能性を生み出します。たとえば、複雑なコマンドを実行した結果の意味を理解することが困難な場合や、ログの解析、データ分析などで結果をより深く理解するための手助けとなります。また、様々なプログラムやスクリプトの実行結果を人間が理解できる形で説明してくれるため、デバッグやエラー解析の作業を効率化することが可能です。AICommandを利用すれば、テクニカルな知識がなくてもコマンドラインから得られる情報を理解しやすくなるかもしれません。結論🦾AICommandは、AIとCLI（Command Line Interface）の架け橋となるツールであり、この2つの強力なテクノロジーを組み合わせることで、未知の課題に対して新たな視点を提供します。さまざまなバックグラウンドを持つユーザーがコマンドラインから得られる情報をより容易に理解できるようになることで、これまで手が出せなかった問題に取り組む手助けをしてくれるでしょう。しかし、その一方で、AICommandはコマンドプロンプトの出力を人間が理解できる形で解釈するツールであるため、その解釈は絶対的な真実を表すものではありません。AICommandの解釈結果は参考の一つと考え、最終的な意思決定はユーザー自身の判断に任せるべきです。以上のことを念頭に置いて、AICommandを活用すれば、新たな視点からコマンドラインの世界を探索することが可能になるでしょう。ソフトウェア開発にChatGPTは使えるのか？――設計からコーディングまでAIの限界を探る作者:小野 哲技術評論社AmazonCloudNative Days Fukuoka 2023 にて登壇余談なのですが\"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について” というタイトルで登壇を行います。event.cloudnativedays.jp参考AI時代に向けたクラウドにおける信頼性エンジニアリングの未来構想 / DICOMO2022 6A-1AICommand GitHubリポジトリOpenAIsashabaranov/go-openai","link":"https://syu-m-5151.hatenablog.com/entry/2023/07/19/162657","isoDate":"2023-07-19T07:26:57.000Z","dateMiliSeconds":1689751617000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"成熟度モデルを活用したCloud Nativeへの道筋 という副題で登壇します #開発生産性con_findy","contentSnippet":"概要開発生産性Conferenceというイベントに『Cloud Native の作法 - 成熟度モデルを活用したCloud Nativeへの道筋』というタイトルで登壇しました。生産性に関するイベントなんですけど現場のエンジニアをやっている僕には開発生産性について語ることってあんまりないようなーって思いながら最近、成熟度モデルについて調べていたのでこのタイトルにしました。途中で開発生産性について語るのを諦めてガッツリ資料を作り直しましたので生暖かく見守ってください。あと、ちょっと前に書籍を送って頂きましたが📖 Twitter での告知を忘れていたのでしておきます。読んだ感想としては入門書では決してないですが成熟度モデルでいうとレベル2の段階では読んでほしいと思う書籍になります。また、豊富にドキュメントへのリンクが貼ってあるのでKubernetesという荒野に道を示す地図になると思います(この文章はChatGPTではなく俺が生成した)。Kubernetesの知識地図 —— 現場での基礎から本番運用まで作者:青山 真也,小竹 智士,長谷川 誠,川部 勝也,岩井 佑樹,杉浦 智基技術評論社Amazon資料登壇資料になります。このブログの目的は参考資料をいちいち探さなくていいようにありますのでご活用ください。 speakerdeck.com参考文献Cloud Native Maturity ModelCloud Native TransformationDesign Patterns for Cloud Native ApplicationsIntro to the Cloud Native Maturity Model - Danielle Cook, Simon Forster, Robbie Glenn \u0026 John FormanSRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本: Googleが実践している新DevOps方法論SRE サイトリライアビリティエンジニアリングサイトリライアビリティワークブックCloud Native成熟度モデルがWeb公開されましたWhat's the Difference Between DevOps and SRE?Solving Reliability Fears with Site Reliability EngineeringReliability When Everything Is a Platform: Why You Need to SRE Your CustomersThe History of DevOps ReportsEffective DevOpsPlatform Engineeringへの招待Platform Team と 社内政治 〜 出でよ、Platform Champion 〜 / Platform Team and Internal Politics - Platform Engineering Meetup #2Platform Engineering at MercariEMPOWERED 普通のチームが並外れた製品を生み出すプロダクトリーダーシッププロダクトマネジメントのすべて 事業戦略・IT開発・UXデザイン・マーケティングからチーム・組織運営まで正しいものを正しくつくる　プロダクトをつくるとはどういうことなのか、あるいはアジャイルのその先についてエンジニアリング組織論への招待　～不確実性に向き合う思考と組織のリファクタリング","link":"https://syu-m-5151.hatenablog.com/entry/2023/07/13/131433","isoDate":"2023-07-13T04:14:33.000Z","dateMiliSeconds":1689221673000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREの専門家が集まったチームで『SREの探求』の社内輪読会を完遂しました。","contentSnippet":"🍡 前回の記事syu-m-5151.hatenablog.com🐶 はじめにこんにちは。株式会社スリーシェイク Sreake 事業部に所属している@nwiizo です。Sreake事業部は技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。事業部にはさまざまな背景を持つSREの専門家が多く在籍してます。しかし、そのSREの専門家達とは案件が一緒にならなかったり、能動的に質問をしなければSREに関する意見や知見を聞けませんでした。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazonそんな、課題がある中で半年前に各案件で得た知見や経験を各メンバーで出し合える会がもっと(社内で技術共有会はあるため)あると良いと思いました。そこで社内チャットで有志を募り 『輪読会について考える会』を行いました。社内チャットで運営を募ると一瞬で集まったので良い組織だと思いました。※『輪読会の各話』の議事録が見れるTOPページです。🐵 各メンバーの感想と今後のアクションsugoude途中からの参加でしたが、楽しく役立つ輪読会でした。特に16章17章はDBREに関する内容でしたので当事者意識を持って参加し、有意義な時間になりました。個人的には、途中からの参加でしたので、SREの探求を再演してもらえたら嬉しいです。hash_gen選定理由としてみんなSRE本は読んでるだろうという点もあったと思いますが、様々なケースと向き合ってきたSreake事業がある3-shakeだからこそSREの探求を輪読する価値があったと思いました。様々な事例に対して我々の場合はどうやって提案していけばよいかという会話が多かったことが印象に残っています。日々のアウトプットでも技術フォーカスの内容に加えて具体的な経験例を社内に積極的にフィードバックしていくことでこのいい習慣を続けていけたらと思っています。SatohJohn入社してまもなくというのも有り、そこまでSREの用語に対して詳しくなかったため、この本を読むことで、どうしてそれらの用語が必要なのかが深掘りできたきがしました。また、個人的にGoogle CloudのDevOpsの試験を受けることが有り、その際にもこの本での話題が役に立ちました。今後アプリケーション開発にSREの考えを入れられるようにするのに、ちょうどよい粒度だったと感じております。tozastationインターンの方が参加したタイミングだけ出れたのでそのエピソードで...! Sreake 事業部だけでなく、他事業部も巻き込んで開催していたのが素敵だなと思いました。Sreake の仕事を知ってもらうであったり、他事業部にも SRE を取り込んでもらうなどさまざまな意見交換が生まれる場だったじゃないかと思います。インターンの方も声を上げてくれたのがさらに良かったです！次のテーマも応援してます！nnaka2992DBRE兼SRE見習いとしてSRE活動をしている自分にとっては、データベース以外でのSREの取り組みを技術・ヒューマンスキル両方の面から学べる本でした。弊社のような不特定多数の組織に対するSREの導入サポートを行う企業では、それぞれの組織に合わせたSREの適用が必要となります。様々なSRE実践例を扱う本書籍は自分の知見を深める面でも、SREとしての引き出しを増やす面でも素晴らしい書籍でした。今後はあくまでこの書籍はある組織での最適解としてリファレンスしながら、それぞれの組織で最適となるSREの探求を続けられればと思います。とあるメンバーすごい有意義な時間でした。Sreake内で自分は人数も組織も大きな組織でどうやって既存の組織にSREを導入するか？を考えているので、様々なプラクティスを知れたのは良い体験でした。輪読で学んだことをお客様に話すと「なるほど！」と言ってもらえることも多々ありました。🐦 まとめ今回の読書会は、新しい知識共有のコミュニティーを作り上げながら実施しました。毎週1回、定められた時間にオンラインに集まり、担当者が1章ずつ読みまとめ、それについて話し合うのです。そして、その議論の過程をドキュメントに記録し、印象に残った部分をいつでも見返せるように保存しておけます。感想はもちろん、一人一人異なりますが、それぞれが課題や組織に向かって解決策を考えていくのがとても面白かったです。その結果、同じ本を読んでいても、それぞれ異なるアクションを考え出すことができました。このようなコミュニティを活用した議論と輪読により、活発な意見交換をしながら特殊なミームが発生したり楽しく読書を進めることができました。これからも、このスタイルの読書会は続けていく予定です。皆さんも、一緒に働くメンバーと読書会を試してみてはいかがでしょうか？新たな知識共有の体験、その刺激を味わってほしいです。弊社の採用サイトも載せておきますjobs-3-shake.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/07/03/094713","isoDate":"2023-07-03T00:47:13.000Z","dateMiliSeconds":1688345233000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Terraform Modules で再利用できるので最高ではないでしょうか？","contentSnippet":"概要ModuleはTerraformの複数のリソースをまとめて再利用可能な単位として扱うことができます。Moduleを使うことで複雑なリソース構成を抽象化し、システムの構造の把握やリソース構成の再利用が可能になり、読みやすさや可読性が向上し、修正箇所が単一になるなどのメリットがあります。ただし、理解には初期コストが必要です。Moduleの設計では、1つの機能を持つように小さくシンプルに保つことが重要で、それが難しい場合は大抵複雑と言えます。また、公式のModuleを利用することで、自身で定義やドキュメントの整備、メンテナンスの手間を省きつつ、プロジェクトを超えて共通認識として扱えるため、Module理解のコストが減ります。しかし、どのタイミングでModuleに組み込むかの正解は、個々のプロジェクトの特性や開発チームの状況により大いに変わるでしょう。絶えず試行錯誤を繰り返しながら個々のプロジェクトごとに最適な解を見つけることが求められます。このブログではそれらの話の前にTerraform Modulesについて利用方法をまとめてみました。概要Module を利用するmoduleの使い方moduleの入力ローカルをうまく利用するmoduleの出力module を使ったときの失敗についてバージョン状態の差分は可能な限り小さくすべきアップグレードは自動されるべきファイルパスインラインブロックいい感じのデフォルトの変数最後に参考Module を利用するシステムを構築するにあたって開発、検証、本番環境をそれぞれ用意することが多いですが、Terraformを環境ごと（例：開発環境、ステージング環境、本番環境）にシンプルなWebサーバーの構成を例にしてModuleを使わないときと使ったときの構成を比較してみましょう。Terraform Configuration|--- Development Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Staging Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Production Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)この構成では、 環境毎にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されていて環境間で異なるリソース設定を利用します。一方、moduleを使用した場合の構成は以下のようになります。Terraform Configuration|--- modules|   |--- user_service_cluster|       |--- main.tf|       |   |--- VM Instances (Web servers)|       |   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|       |   |--- Load Balancer (Balance traffic among VM instances)|       |   |--- Storage Bucket (Store static content)|       |--- variables.tf|       |--- output.tf|--- Development Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)|--- Staging Environment|   |--- User-Service-Cluster Module (source: ../modules/user_service_cluster)|--- Production Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)この構成では、 user_service_cluster moduleのmain.tfファイル内にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されています。各環境はこのuser_service_clustermoduleを参照しており、環境間で共通のリソース設定を再利用します。これによって再利用性、可読性が上がり維持管理性を高める事ができると思います。moduleの使い方Terraformの moduleは、リソース設定の再利用可能な部品で、コードの抽象化と組織化をサポートします。 moduleは一つ以上のリソースを定義し、それらをまとめて管理することができます。 moduleを使用するためには、 moduleブロックをmain.tf（またはその他の.tfファイル）に追加し、そこでmoduleのソースと任意の入力変数を指定します。以下に、user_service_cluster moduleを使用するための基本的なmodule ブロックの例を示します。module \"user_service_cluster\" {  source = \"../modules/user_service_cluster\"  instance_type  = \"n1-standard-1\"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = \"HTTP\"    port     = 80  }  bucket_name = \"dev-bucket\"}source属性にmoduleのソースコードが存在するパスを指定しています。そして、user_service_cluster moduleが定義する各入力変数を設定しています。moduleは、そのソース内でvariableブロックを使用して入力変数を定義します。これらの入力変数は、moduleの使用者が値を提供することでmoduleの振る舞いをカスタマイズできます。また、moduleはoutputブロックを使用して出力値を定義します。出力値は、moduleの内部リソースの属性をmoduleの外部に公開するために使用されます。これにより、他のリソースやmoduleがmoduleから生成されるリソースを参照することが可能になります。module化はTerraformのコードベースを組織化し、再利用可能なコードを作成するための重要な手段です。これにより、一貫性が保たれ、メンテナンスが容易になり、エラーの可能性も低減します。moduleの入力Terraformのmoduleは再利用可能なコードブロックで、入力変数（input variables）を使用してカスタマイズできます。これらの入力変数は、moduleブロックで設定します。以下に、user_service_cluster moduleで使用する入力変数の例を示します。まず、module自体のvariables.tfファイルには以下のように入力変数を定義しますvariable \"instance_type\" {  description = \"The type of instance to start\"  type        = string  default     = \"n1-standard-1\"}variable \"instance_count\" {  description = \"Number of instances to create\"  type        = number  default     = 1}variable \"firewall_rules\" {  description = \"Firewall rules for instances\"  type        = map(any)  default     = {}}variable \"load_balancer_config\" {  description = \"Configuration for load balancer\"  type        = map(any)  default     = {}}variable \"bucket_name\" {  description = \"Name of the storage bucket\"  type        = string  default     = \"default-bucket\"}そして、このmodule を呼び出す際に、具体的な値を設定します：module \"user_service_cluster\" {  source = \"../modules/user_service_cluster\"  instance_type  = \"n1-standard-1\"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = \"HTTP\"    port     = 80  }  bucket_name = \"dev-bucket\"}上記の例では、user_service_cluster moduleはsourceで指定されたソースからロードされ、instance_type、instance_count、firewall_rules、load_balancer_config、bucket_nameという入力変数を設定しています。module に入力変数を提供することで、module の動作をカスタマイズし、異なる環境や条件で再利用することが可能になります。ローカルをうまく利用するTerraformのlocalsブロックを使用すると、再利用可能な内部変数をmodule内で定義することができます。localsはmodule内で共有され、module外からは参照できません。以下に、user_service_cluster module のlocalsの例を示します。この例では、HTTPポート、任意のポート、任意のプロトコル、TCPプロトコル、そして全てのIPアドレスをローカル変数として定義しています。locals {  http_port    = 80  any_port     = 0  any_protocol = \"-1\"  tcp_protocol = \"tcp\"  all_ips      = [\"0.0.0.0/0\"]}ローカル変数はlocal.\u003cNAME\u003eの形式で参照します。以下のリソース定義では、ロードバランサーリスナーとセキュリティグループの設定にローカル変数を使用しています。resource \"google_compute_instance\" \"http\" {  name         = \"web-instance\"  machine_type = \"n1-standard-1\"  network_interface {    network = \"default\"    access_config {      // Assign an ephemeral IP to the instance    }  }    // Other configuration...}resource \"google_compute_firewall\" \"default\" {  name    = \"default-firewall\"  network = \"default\"  allow {    protocol = local.tcp_protocol    ports    = [local.http_port]  }  source_ranges = local.all_ips}上記の例では、ロードバランサーリスナーとセキュリティグループでlocalsブロックに定義したローカル変数を参照しています。local.http_port、local.tcp_protocol、local.all_ipsを各リソースブロックで参照することで、コードがDRYに保たれ、より読みやすく、メンテナンスがしやすくなります。localsブロックを使用することで、コードの冗長性を減らし、module全体の一貫性を保つことができます。また、ローカル変数を使用することで、moduleの一部で使用する変数をmodule全体で共有することが可能になります。moduleの出力Terraformのmoduleは、出力変数（outputs）を提供できます。出力変数はmoduleの値を外部に公開するための手段で、moduleを使用しているコードからアクセスできます。また、Terraformがapplyコマンドを実行した後にこれらの値を表示することもできます。以下に、user_service_cluster moduleの出力変数の例を示します。この例では、output.tf にクラスタのURLとインスタンスのIDを出力しています。output \"cluster_url\" {  description = \"The URL of the load balancer for the cluster\"  value       = \"http://${google_compute_global_address.default.address}\"}output \"instance_ids\" {  description = \"The IDs of the instances in the cluster\"  value       = google_compute_instance.default.*.id}これらの出力をmodule の使用側でアクセスするためには、moduleの名前と出力の名前を組み合わせて参照します。output \"user_service_cluster_url\" {  description = \"The URL of the load balancer for the user service cluster\"  value       = module.user_service_cluster.cluster_url}output \"user_service_cluster_instance_ids\" {  description = \"The IDs of the instances in the user service cluster\"  value       = module.user_service_cluster.instance_ids}このようにして、moduleの出力変数を使用することで、moduleの内部データをmodule外部に公開し、他のTerraformコードがそのデータを参照できるようにします。出力変数はmodule間の情報共有を可能にし、moduleの再利用性を向上させます。Terraformはファイル名に特別な意味を持たせません。すなわち、variables.tfやoutputs.tfという名前は慣習にすぎないので、入力変数と出力変数を1つのファイルにまとめることも技術的には可能です。module を使ったときの失敗についてmodule を作る時に注意する点について実際にハマったことをベースに3つ紹介します。バージョンModuleのバージョンが異なると意図しない挙動やエラーが引き起こされる可能性があるので、バージョンを固定し実行環境を統一しましょう。Providerやパッケージにしても同じでバージョンを指定して再利用性を高めろ！！！状態の差分は可能な限り小さくすべきいつでもアップグレードを状態差分なしで行うことはできません。依存するリソースの変更やセキュリティ問題ができるだけ早くパッチを適用する必要があるなど、破壊的な変更を導入する必要がある場合があります。その場合、コストをどのように減らすかについて考える必要があります。状態の差分が少なければ、アップグレードのコストは少なくなります。破壊的な変更を導入するときは、それを文書化できるCHANGELOGやユーザーガイドを通じてユーザーに伝える必要がありますアップグレードは自動されるべきアップグレードは長期的に開発されるソフトウェアの最も重要なタスクの一つです。ただし、一般的に使用され、広く使用されているTerraform Moduleの場合、これは大きな問題でもあります。また、Moduleを頻繁に更新する場合、自動アップデートの機能を準備する必要があります。ユーザーにアップグレードを依頼しても、通常、彼らはより重要なタスクを行うためにそれを行うことはありません。そのため、代わりに、彼らのためにPRを作成します。PRがTerraformの差分がない場合に自動的にマージされるメカニズムを持っています。これと後方互換性の維持の組み合わせにより、最新バージョンのModuleを使用するユーザーの率を増やすことができますファイルパスTerraformのtemplatefile関数を使用する際、ファイルパスは絶対パスではなく相対パスを使用する必要があります。しかし、これはどのパスに対して相対的なのでしょうか？デフォルトでは、Terraformはパスを現在の作業ディレクトリに対して相対的に解釈します。そのため、terraform applyを実行しているディレクトリと同じディレクトリにTerraform設定ファイルがある場合、これはうまく動作します。しかし、別のフォルダに定義されたmodule内でtemplatefileを使用する場合、これは問題となります。この問題を解決するためには、path.moduleなどのパス参照を使用します。これを使用すると、module自体に対する相対パスが得られます。インラインブロックTerraformリソースの一部の設定は、インラインブロックか別のリソースとして定義することができます。インラインブロックとは、リソース内で設定する引数のことで、次の形式を持っています。resource \"xxx\" \"yyy\" {  \u003cNAME\u003e {    [CONFIG...]  }}ここでNAMEはインラインブロックの名前（例えば、ingress）、CONFIGはそのインラインブロックに特有の一つ以上の引数（例えば、from_portやto_port）です。しかし、インラインブロックと別のリソースを混在して使用すると、Terraformの設計上、設定が衝突し互いに上書きされてエラーが発生します。したがって、どちらか一方を使用する必要があります。moduleを作成する際には、別のリソースを使用することを常に推奨します。これらの注意点を理解しておくことで、Terraformのmoduleをより効果的に利用することができます。いい感じのデフォルトの変数完全にカスタマイズできるModuleには魅力がないです。Moduleの変数には、80％のユーザーをカバーするスマートデフォルト値を持つべきです。ただし、同時に、通常のユーザーとは異なる方法でModuleを使用するパワーユーザーのための設定も用意するべきです。変数を変更したときに何が起こるかは、ユーザーにとって明白で予測可能でなければなりません。この設定は適切に設計され、安易に浅いインターフェースを持つべきではありません最後にmoduleを活用することで、インフラストラクチャの再利用性と効率性が大幅に向上します。開発者は証明済み、テスト済み、文書化済みのインフラストラクチャの一部を再利用できるようになるため、迅速かつ確実にシステムを構築できます。例えば、マイクロサービスのデプロイメントを定義するmoduleを作成し、各チームが数行のコードで自身のマイクロサービスを管理できるようにすることが可能です。しかし、このようなmoduleを複数のチームで活用するためには、module内のTerraformコードは柔軟性と設定可能性が必要です。異なるチームや状況に応じて、ロードバランサーなしの単一インスタンスやロードバランサー付きの複数インスタンスといった、さまざまなデプロイメント要件を満たすことができます。Terraformの柔軟な構文を活用することで、より多機能なmoduleを設計し、インフラストラクチャの構築を一層楽しく効果的に行うことができます。また、どれぐらいの規模からmodule化するのかなど迷う場面が多いと思いますがこの辺は経験としか言えずにみんな雰囲気でやっているなぁって思いました。このブログが伸びたらもっと実装に基づいた話をしていこうと思います。ちなみにベストプラクティスなんかは俺にはわからない。自分を信じても…信頼に足る仲間を信じても…誰にもわからない…今の構成が一番変更しやすくて誇れるものならそれが正解なんだとおもう。実践Terraform　AWSにおけるシステム設計とベストプラクティス (技術の泉シリーズ（NextPublishing）)作者:野村 友規インプレスR\u0026DAmazon参考Terraform: Up \u0026 Running; Writing Infrastructure As CodeDeveloper/Terraform/Configuration Language/Modulesterraform-module/terraform-module-blueprinthttps://registry.terraform.io/namespaces/terraform-aws-moduleshttps://registry.terraform.io/namespaces/terraform-google-modulesHashiCorp LearnModule Creation - Recommended PatternAWSとTerraformで学ぶプロダクションレディなKubernetes 技術の泉シリーズ (技術の泉シリーズ（NextPublishing）)","link":"https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346","isoDate":"2023-05-19T06:43:46.000Z","dateMiliSeconds":1684478626000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"はてなブログのコードブロックを”クリップボードにコピーする方法”について","contentSnippet":"はてなブログの設定から、Markdown記法で書いた記事にコードブロックのコピーボタンを自動的に追加することができます。また、こちらのブログは完全に非公式ですし自分のブログ以外では試してません。🦾 デザインの設定まず、はてなブログの管理画面にログインし、デザイン設定を開きます。🦾 CSS の設定を行うデザイン設定で、「カスタマイズ」タブをクリックし、「デザインCSS」を開きます。ここで、先ほど紹介したコピーボタンのスタイルを追加します。pre.code {  position: relative;}.copy-button {  position: absolute;  top: 4px;  right: 4px;  display: inline-block;  padding: 8px 16px;  border: none;  border-radius: 4px;  background-color: #1e90ff;  color: #ffffff;  cursor: pointer;  font-size: 14px;  font-weight: bold;  text-decoration: none;  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);  transition: background-color 0.3s, box-shadow 0.3s;  opacity: 0;  transition: opacity 0.3s;}pre.code:hover .copy-button {  opacity: 1;}.copy-button:hover {  background-color: #2980b9;  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);}.copy-button:focus {  outline: none;}.copy-button:active {  box-shadow: none;  transform: translateY(2px);}🦾 フッターHTMLの設定を行う 次に、「カスタマイズ」タブの「フッターHTML」に、以下のコードを追加します。\u003cscript\u003e  document.addEventListener('DOMContentLoaded', function() {    // コードブロックを取得    var codeBlocks = document.querySelectorAll('pre.code');        // すべてのコードブロックにコピーボタンを追加    for (var i = 0; i \u003c codeBlocks.length; i++) {      var copyButton = document.createElement('button');      copyButton.className = 'copy-button';      copyButton.textContent = 'Copy code';      copyButton.onclick = function() {        var codeElem = this.parentNode.querySelector('code') || this.parentNode;        var textArea = document.createElement('textarea');        textArea.value = codeElem.textContent.replace(/Copy code$/, ''); // \"Copy code\" テキストを削除        document.body.appendChild(textArea);        textArea.select();        document.execCommand('copy');        document.body.removeChild(textArea);      }      codeBlocks[i].appendChild(copyButton);    }  });\u003c/script\u003e🔍 確認していくhttps://syu-m-5151.hatenablog.com/entry/2023/04/11/084428 にて確認","link":"https://syu-m-5151.hatenablog.com/entry/2023/05/09/181943","isoDate":"2023-05-09T09:19:43.000Z","dateMiliSeconds":1683623983000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Golang のEcho でMiddlewareを使ってPrometheus Exporter を実装する","contentSnippet":"はじめにもし、アプリケーションに実装できるならそれが良いです。独自に実装などせずにエンドポイントにて500 Internal Server Errorが多発していればアラートをすれば良いので...。こちらの続編になります。syu-m-5151.hatenablog.com本エントリーでは、GolangでEchoフレームワークを使用し、Prometheus ExporterをMiddlewareとして実装する方法について説明します。Prometheus Middlewareは、自動でMetrics を生成します。これにより、アプリケーションのパフォーマンス監視や問題解析が容易になります。利用しているコードはこちらgithub.comはじめにコードを解説するんじゃいvarinitmeasureExternalAccessunstableEndpointMiddlewareを適用Prometheus Middlewareを適用EchoのMiddlewareについてEcho Echo Middleware の特徴再び、Docker Compose での実行するんじゃろがい見れたぞぉおおおおさいごにコードを解説するんじゃいシンプルだけど解説をします。環境構築などは前回のエントリーに任せます。Echoフレームワークを使ってGolangでシンプルなWebアプリケーションを作成し、Prometheus Exporterをミドルウェアとして実装する例です。package mainimport (    \"math/rand\"    \"net/http\"    \"time\"    \"github.com/labstack/echo-contrib/prometheus\"    \"github.com/labstack/echo/v4\"    \"github.com/labstack/echo/v4/middleware\"    prom \"github.com/prometheus/client_golang/prometheus\")// Prometheus のメトリクスを定義しています。// これらのメトリクスは、3-shake.com への外部アクセスの情報を収集するために使用されます。var (    externalAccessDuration = prom.NewHistogram(        prom.HistogramOpts{            Name:    \"external_access_duration_seconds\",            Help:    \"Duration of external access to 3-shake.com\",            Buckets: prom.DefBuckets,        },    )    lastExternalAccessStatusCode = prom.NewGauge(        prom.GaugeOpts{            Name: \"last_external_access_status_code\",            Help: \"Last status code of external access to 3-shake.com\",        },    ))// init 関数内で、メトリクスを Prometheus に登録しています。func init() {    prom.MustRegister(externalAccessDuration)    prom.MustRegister(lastExternalAccessStatusCode)}// 3-shake.com の外部アクセスを計測するミドルウェアを作成します。func measureExternalAccess(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        // HTTP クライアントを作成し、タイムアウトを 10 秒に設定します。        client := \u0026http.Client{Timeout: 10 * time.Second}        // 現在の時刻を取得し、アクセス開始時間として保持します。        startTime := time.Now()        // 3-shake.com に対して HTTP GET リクエストを送信します。        resp, err := client.Get(\"https://3-shake.com\")        // アクセス開始時間から現在の時刻までの経過時間を計算し、duration に格納します。        duration := time.Since(startTime)        // エラーが発生しない場合（リクエストが成功した場合）        if err == nil {            // アクセス時間（duration）をヒストグラムメトリクスに追加します。            externalAccessDuration.Observe(duration.Seconds())            // ステータスコードをゲージメトリクスに設定します。            lastExternalAccessStatusCode.Set(float64(resp.StatusCode))            // レスポンスのボディを閉じます。            resp.Body.Close()        }        // 次のミドルウェアまたはハンドラ関数に処理を移します。        return next(c)    }}func unstableEndpoint(c echo.Context) error {    // 0 から 4 までのランダムな整数を生成します。    randomNumber := rand.Intn(5)    // 生成された整数が 4 の場合、HTTP ステータスコード 500 を返します。    if randomNumber == 4 {        return c.String(http.StatusInternalServerError, \"Something went wrong!\")    }    // それ以外の場合、HTTP ステータスコード 200 を返します。    return c.String(http.StatusOK, \"Success!\")}func main() {    e := echo.New()    // ミドルウェアの設定    e.Use(middleware.Logger())    e.Use(middleware.Recover())    // Prometheus ミドルウェアを有効にします。    p := prometheus.NewPrometheus(\"echo\", nil)    p.Use(e)    // 3-shake.com への外部アクセスを計測するミドルウェアを追加します。    e.Use(measureExternalAccess)    // ルートのエンドポイントを設定します。    e.GET(\"/\", func(c echo.Context) error {        return c.String(http.StatusOK, \"Hello, World!\")    })    // /unstable エンドポイントを設定します。    // 20% の確率で HTTP ステータスコード 500 を返します。    e.GET(\"/unstable\", unstableEndpoint)    // サーバーを開始します。    e.Start(\":2121\")}varvarで3-shake.com への外部アクセスの情報を収集するための Prometheus メトリクスを定義していきます。var (    externalAccessDuration = prom.NewHistogram(        prom.HistogramOpts{            Name:    \"external_access_duration_seconds\",            Help:    \"Duration of external access to 3-shake.com\",            Buckets: prom.DefBuckets,        },    )    lastExternalAccessStatusCode = prom.NewGauge(        prom.GaugeOpts{            Name: \"last_external_access_status_code\",            Help: \"Last status code of external access to 3-shake.com\",        },    ))echo.labstack.cominitinit 関数でメトリクスを Prometheus に登録します。func init() {    prom.MustRegister(externalAccessDuration)    prom.MustRegister(lastExternalAccessStatusCode)}measureExternalAccessmeasureExternalAccess関数で3-shake.com への外部アクセスを計測するミドルウェアを定義します。こちらの方がEcho Likeな定義の仕方だと思うので好きです。Echo のカスタムミドルウェアで、リクエストが処理される前に 3-shake.com への外部アクセスを計測する役割を持っています。func measureExternalAccess(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        // HTTP クライアントを作成し、タイムアウトを 10 秒に設定します。        client := \u0026http.Client{Timeout: 10 * time.Second}        // 現在の時刻を取得し、アクセス開始時間として保持します。        startTime := time.Now()        // 3-shake.com に対して HTTP GET リクエストを送信します。        resp, err := client.Get(\"https://3-shake.com\")        // アクセス開始時間から現在の時刻までの経過時間を計算し、duration に格納します。        duration := time.Since(startTime)        // エラーが発生しない場合（リクエストが成功した場合）        if err == nil {            // アクセス時間（duration）をヒストグラムメトリクスに追加します。            externalAccessDuration.Observe(duration.Seconds())            // ステータスコードをゲージメトリクスに設定します。            lastExternalAccessStatusCode.Set(float64(resp.StatusCode))            // レスポンスのボディを閉じます。            resp.Body.Close()        }        // 次のミドルウェアまたはハンドラ関数に処理を移します。        return next(c)    }}unstableEndpointちゃんと、メトリクス値が取得できているか確認したいのでunstableEndpointというエンドポイントを追加し、リクエストのうち約 5 回に 1 回失敗するように実装しました。このエンドポイントは、リクエストが成功した場合には HTTP ステータスコード 200 を返し、失敗した場合には HTTP ステータスコード 500 を返します。func unstableEndpoint(c echo.Context) error {    // 0 から 4 までのランダムな整数を生成します。    randomNumber := rand.Intn(5)    // 生成された整数が 4 の場合、HTTP ステータスコード 500 を返します。    if randomNumber == 4 {        return c.String(http.StatusInternalServerError, \"Something went wrong!\")    }    // それ以外の場合、HTTP ステータスコード 200 を返します。    return c.String(http.StatusOK, \"Success!\")}curl してくるワンライナー(fish)も用意しましたので思う存分curl してください。for i in (seq 1 50); curl http://localhost:2121/unstable; echo \"\"; endMiddlewareを適用寂しいのでPrometheus 以外のMiddlewareをEchoインスタンスに適用しました。middleware.Logger() : リクエストのログを出力するMiddlewaremiddleware.Recover() : パニックを回復してアプリケーションがクラッシュしないようにするMiddleware   e.Use(middleware.Logger())    e.Use(middleware.Recover())Prometheus Middlewareを適用これだけなんです。Echo用の新しいPrometheus Middlewareインスタンスを作成します。作成したPrometheus MiddlewareインスタンスをEchoインスタンスに適用します。 // Prometheusミドルウェアを適用する    p := prometheus.NewPrometheus(\"echo\", nil)    p.Use(e)EchoのMiddlewareについてMiddlewareは、リクエストとレスポンスの処理の前後にカスタムロジックを実行するための仕組みを提供しています。EchoのMiddlewareは、コードの再利用性、可読性、そして機能の分離を向上させるために役立ちます。\u003eLogger: Request    Logger-\u003e\u003eMiddleware1: Processed Request    Middleware1-\u003e\u003eRecovery: Processed Request    Recovery-\u003e\u003ePrometheus: Processed Request    Prometheus-\u003e\u003eCORS: Processed Request    CORS-\u003e\u003eHandler: Processed Request    Handler-\u003e\u003eCORS: Response    CORS-\u003e\u003ePrometheus: Processed Response    Prometheus-\u003e\u003eRecovery: Processed Response    Recovery-\u003e\u003eMiddleware1: Processed Response    Middleware1-\u003e\u003eLogger: Processed Response    Logger-\u003e\u003eClient: Processed Responsemermaid.initialize({startOnLoad: true});echo.labstack.comEcho Echo Middleware の特徴Middlewareは、複数のMiddleware関数を組み合わせて実行することができます。これにより、機能を組み合わせてカスタム処理パイプラインを構築することができます。これらは登録された順序で実行されます。これにより、処理の流れを明確にし、簡単に制御できるようになります。また、Echoでは、これらをグローバルに適用することも、特定のルートに適用することもできます。これにより、アプリケーション全体または特定のエンドポイントに対してカスタム処理を適用できます。Echoは、いくつかの組み込みミドルウェアを提供していますが独自のカスタムミドルウェアを作成してアプリケーションに適用することもできます。e := echo.New()e.Use(middleware.Logger()) # 登録された順序で実行されるぞe.GET(\"/\",getHallo,middleware.Recover()) # e.GET(\"/\", \u003cHandler\u003e, \u003cMiddleware...\u003e) で特定のルートにだけMiddlewareを登録できるe.Use(LoggingMiddleware) # 独自で実装するカスタムミドルウェアecho.labstack.com再び、Docker Compose での実行するんじゃろがい完全に同じことやってるのでこちらを参考にしてくださいsyu-m-5151.hatenablog.com見れたぞぉおおおおhttp://localhost:2121/metrics の結果もこちらに記載しておきますgithub.comGolang のEcho でMiddlewareを使ってアプリケーションのPrometheus Exporter を実装することができました。アラートの設定方法については他のブログを参照してください。さいごに以上で、Echo フレームワークを使って、Prometheus メトリクスを追加し、さらに不安定なエンドポイントを作成する方法を解説しました。この知識を活かして、みなさんのアプリケーションにメトリクスを取得する機能を追加して、可観測性を向上させましょう！全然、関係ないけど翻訳に携わってコンテナセキュリティのブラックボックス感が多少薄まるのでみんな読んでくれ...コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術作者:Liz RiceインプレスAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/04/17/100001","isoDate":"2023-04-17T01:00:01.000Z","dateMiliSeconds":1681693201000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Golang のEcho で Prometheus Exporter を実装する","contentSnippet":"はじめにPrometheus でアプリケーションの構築をしているとどうしてもこの値が取りたいのに... と思うことが多々ある。Pushgateway も選択肢として上げられるが今回は選択肢を増やしてほしいという意味でもExporterの実装方法について検討していきます。ExporterはPrometheusのpull モデルに適合し、監視対象のライフサイクルと一貫性があり、スケーラビリティと自動検出の利点を享受できるため、Pushgatewayよりも推奨される方法です。ただし、特定のユースケース（サービスレベルのバッチジョブなど）では、Pushgatewayの使用が適切な場合もあります。Pushgatewayを使う際には以下の問題点があるので注意が必要です。複数のインスタンスを1つのPushgatewayで監視すると、単一障害点とボトルネックが発生する可能性がある。Prometheusの自動インスタンスヘルスチェックが利用できなくなる。Pushgatewayは一度プッシュされたデータを忘れず、手動でAPIを通じて削除しない限り永久にPrometheusで公開されてしまう。Exporter の実装と運用はそこそこ手間になるので最適な方法を選んでほしいです。この辺はCloudを利用しても同じような問題があるので注意しながらやっていきましょう。はじめにExporterとはPrometheusの公式クライアントライブラリやっていくぞ！おら！環境構築実装についてコードを解説するんじゃいPrometheusのメトリクスを定義init関数registerMetrics関数updateMetrics関数prometheusMiddleware関数measureExternalAccess関数var 配下ってことぉおおおhttpRequestsTotalhttpRequestDurationhttpRequestSizehttpResponseSizehttpResponseTimeexternalAccessDurationDocker Compose での実行するんじゃろがいprometheus.ymldocker-compose.ymlDockerfiledocker compose の実行さいごにサンプルコードはこちらです。サンプルコード自体は雑多な作業リポジトリにおいてあるのでご注意ください。また、アプリケーション自体のリソースを確認するのにEcho のミドルウェアを使用していません。自身の利用しているライブラリーにPrometheus のエンドポイントを提供する機能がないか調べておきましょう。gRPCのGo Server にも同様の機能があります。あと、外部のリソースが確認したいだけならBlackbox exporterという選択肢もあります。github.comExporterとはExporterは、Prometheusがメトリクスを収集するために使用するプログラムです。Exporterは、アプリケーションやインフラストラクチャからメトリクスを収集し、Prometheusが理解できる形式に変換して提供します。公式ドキュメントで提供されているExporter一覧は、こちらを参照してください。Prometheusの公式クライアントライブラリPrometheusは、いくつかの言語用の公式クライアントライブラリを提供しており、これを使用してExporterを実装することができます。今回はGoで実装していくのこちらが参考になると思います。やっていくぞ！おら！やっていきます環境構築# Go のモジュールを作成する。必要なライブラリーはのちほど`go mod tidy` で持ってくる。go mod init prometheus-go-exporter実装について以下をmain.go に配置して実行(go run main.go)してください。以下のコードはEchoを利用したWebサーバーにPrometheusのExporterを実装し、3-shake.comへのアクセスを計測しています。http://localhost:2121/3-shake-status や http://localhost:2121/metrics で値を取得できていると思います。package mainimport (    \"fmt\"    \"net/http\"    \"time\"    \"github.com/labstack/echo/v4\"    \"github.com/labstack/echo/v4/middleware\"    \"github.com/prometheus/client_golang/prometheus\"    \"github.com/prometheus/client_golang/prometheus/promhttp\")// Prometheusのメトリクスを定義しています。// これらのメトリクスは、HTTPリクエストの情報や3-shake.comへのアクセス情報を収集するために使用されます。var (    httpRequestsTotal = prometheus.NewCounterVec(        prometheus.CounterOpts{            Name: \"http_requests_total\",            Help: \"Number of HTTP requests processed\",        },        []string{\"method\", \"path\"},    )    httpRequestDuration = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    \"http_request_duration_seconds\",            Help:    \"Duration of HTTP requests\",            Buckets: prometheus.DefBuckets,        },        []string{\"method\", \"path\"},    )    httpRequestSize = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    \"http_request_size_bytes\",            Help:    \"Size of HTTP requests\",            Buckets: prometheus.ExponentialBuckets(128, 2, 10),        },        []string{\"method\", \"path\"},    )    httpResponseSize = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    \"http_response_size_bytes\",            Help:    \"Size of HTTP responses\",            Buckets: prometheus.ExponentialBuckets(128, 2, 10),        },        []string{\"method\", \"path\"},    )    httpResponseTime = prometheus.NewGaugeVec(        prometheus.GaugeOpts{            Name: \"http_response_time_seconds\",            Help: \"Time of the last HTTP response\",        },        []string{\"method\", \"path\"},    )    externalAccessDuration = prometheus.NewHistogram(        prometheus.HistogramOpts{            Name:    \"external_access_duration_seconds\",            Help:    \"Duration of external access to 3-shake.com\",            Buckets: prometheus.DefBuckets,        },    )    lastExternalAccessStatusCode = prometheus.NewGauge(        prometheus.GaugeOpts{            Name: \"last_external_access_status_code\",            Help: \"Last status code of external access to 3-shake.com\",        },    ))// init関数内で、メトリクスをPrometheusに登録しています。func init() {    registerMetrics()}// registerMetrics関数では、Prometheusにメトリクスを登録しています。// これにより、Prometheusがメトリクスを収集できるようになります。func registerMetrics() {    prometheus.MustRegister(httpRequestsTotal)    prometheus.MustRegister(httpRequestDuration)    prometheus.MustRegister(httpRequestSize)    prometheus.MustRegister(httpResponseSize)    prometheus.MustRegister(httpResponseTime)    prometheus.MustRegister(externalAccessDuration)    prometheus.MustRegister(lastExternalAccessStatusCode)}// updateMetrics関数では、受信したHTTPリクエストのメトリクスを更新しています。// これにより、各リクエストに関する情報が収集されます。func updateMetrics(method, path string, requestSize, responseSize int, duration time.Duration) {    httpRequestsTotal.WithLabelValues(method, path).Inc()    httpRequestDuration.WithLabelValues(method, path).Observe(duration.Seconds())    httpRequestSize.WithLabelValues(method, path).Observe(float64(requestSize))    httpResponseSize.WithLabelValues(method, path).Observe(float64(responseSize))    httpResponseTime.WithLabelValues(method, path).Set(float64(time.Now().Unix()))}// prometheusMiddleware関数では、Echoのミドルウェアとして、受信したHTTPリクエストに関するメトリクスを更新する機能を追加しています。func prometheusMiddleware(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        startTime := time.Now()        err := next(c)        duration := time.Since(startTime)        requestSize := c.Request().ContentLength        responseSize := c.Response().Size        updateMetrics(c.Request().Method, c.Path(), int(requestSize), int(responseSize), duration)        return err    }}// measureExternalAccess関数では、3-shake.comへの外部アクセスを定期的に計測し、そのアクセス時間とステータスコードをメトリクスに格納しています。// この関数はメイン関数内で呼び出され、別のゴルーチンで実行されます。func measureExternalAccess() {    client := \u0026http.Client{Timeout: 10 * time.Second}    go func() {        for {            startTime := time.Now()            resp, err := client.Get(\"https://3-shake.com\")            duration := time.Since(startTime)            if err == nil {                externalAccessDuration.Observe(duration.Seconds())                lastExternalAccessStatusCode.Set(float64(resp.StatusCode))                resp.Body.Close()            }            time.Sleep(1 * time.Minute)        }    }()}func main() {    // Echo instance    e := echo.New()    // Middleware for Prometheus Exporter    e.Use(prometheusMiddleware)    // Enable request logger    e.Use(middleware.Logger())    e.GET(\"/3-shake-status\", func(c echo.Context) error {        status := lastExternalAccessStatusCode.Desc().String()        return c.String(http.StatusOK, fmt.Sprintf(\"Last 3-shake.com access status: %s\", status))    })    // Prometheus Exporter endpoint    e.GET(\"/metrics\", echo.WrapHandler(promhttp.Handler()))    // Measure external access to 3-shake.com    measureExternalAccess()    // Start the server    e.Start(\":2121\")}コードを解説するんじゃい解説をします。Prometheusのメトリクスを定義Prometheusのメトリクスを定義しています。これらのメトリクスは、HTTPリクエストの情報や3-shake.comへのアクセス情報を収集するために使用されます。var (    // ... (省略)    externalAccessDuration = prometheus.NewHistogram(        prometheus.HistogramOpts{            Name:    \"external_access_duration_seconds\",            Help:    \"Duration of external access to 3-shake.com\",            Buckets: prometheus.DefBuckets,        },    )    lastExternalAccessStatusCode = prometheus.NewGauge(        prometheus.GaugeOpts{            Name: \"last_external_access_status_code\",            Help: \"Last status code of external access to 3-shake.com\",        },    ))init関数init関数内で、メトリクスをPrometheusに登録しています。func init() {    registerMetrics()}registerMetrics関数registerMetrics関数では、Prometheusにメトリクスを登録しています。これにより、Prometheusがメトリクスを収集できるようになります。func registerMetrics() {    // ... (省略)    prometheus.MustRegister(externalAccessDuration)    prometheus.MustRegister(lastExternalAccessStatusCode)}updateMetrics関数updateMetrics関数では、受信したHTTPリクエストのメトリクスを更新しています。これにより、各リクエストに関する情報が収集されます。func updateMetrics(method, path string, requestSize, responseSize int, duration time.Duration) {    // ... (省略)}prometheusMiddleware関数prometheusMiddleware関数では、Echoのミドルウェアとして、受信したHTTPリクエストに関するメトリクスを更新する機能を追加しています。func prometheusMiddleware(next echo.HandlerFunc) echo.HandlerFunc {    // ... (省略: )}measureExternalAccess関数measureExternalAccess関数 では、3-shake.comへの外部アクセスを定期的に計測し、そのアクセス時間とステータスコードをメトリクスに格納しています。この関数はメイン関数内で呼び出され、別のゴルーチンで実行されます。func measureExternalAccess() {    client := \u0026http.Client{Timeout: 10 * time.Second}    go func() {        for {            startTime := time.Now()            resp, err := client.Get(\"https://3-shake.com\")            duration := time.Since(startTime)            if err == nil {                externalAccessDuration.Observe(duration.Seconds())                lastExternalAccessStatusCode.Set(float64(resp.StatusCode))                resp.Body.Close()            }            time.Sleep(1 * time.Minute)        }    }()}var 配下ってことぉおおおPrometheusのメトリクスを定義しています。この辺の実装はよく悩むと思うので公式の実装とかたくさん読むと何をどれに使えばよいかの勘所が掴めると思います。実際に使わないと差が分からないのでとっとと手を動かすのがオススメです。httpRequestsTotal処理されたHTTPリクエストの総数をカウントするメトリクスです。prometheus.NewCounterVec関数を使用して定義され、リクエストのメソッド（GET、POSTなど）とパス（リソースへのURLパス）によってラベル付けされます。httpRequestDurationHTTPリクエストの処理時間を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。デフォルトのバケットは、prometheus.DefBucketsを使用して設定されます。httpRequestSizeHTTPリクエストのサイズ（バイト単位）を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。バケットは、prometheus.ExponentialBuckets関数を使用して設定されます。httpResponseSizeHTTPレスポンスのサイズ（バイト単位）を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。バケットは、同様にprometheus.ExponentialBuckets関数を使用して設定されます。httpResponseTimeHTTPレスポンスの時間を記録するメトリクスです。このメトリクスは、prometheus.NewGaugeVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。externalAccessDurationこれは、3-shake.comへの外部アクセスの持続時間を記録するメトリクスです。このメトリクスは、prometheus.NewHistogram関数を使用して定義されます。デフォルトのバケットは、prometheus.DefBuckets関数を使用して設定されます。Docker Compose での実行するんじゃろがいprometheus.ymlまず、prometheus.ymlを作成します。このファイルには、Prometheusがどのようにメトリクスを収集するかについての設定が含まれています。global:  scrape_interval: 15sscrape_configs:  - job_name: 'echo_exporter'    static_configs:      - targets: ['echo_exporter:2121']docker-compose.yml次に、docker-compose.ymlを作成します。このファイルには、PrometheusとGolangのEchoアプリケーションを実行するために必要なコンテナの設定が含まれています。version: '3.8'services:  echo_exporter:    build:       context: .      dockerfile: Dockerfile_exporter    ports:      - \"2121:2121\"  prometheus:    image: prom/prometheus:latest    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml    command:      - \"--config.file=/etc/prometheus/prometheus.yml\"    ports:      - \"9090:9090\"DockerfileDockerfileを作成して、Echoアプリケーションをコンテナで実行できるようにします。別に動けばよいのでなんか工夫とかはしてないです。本番でやるときはうまくマルチステージビルドとか使って下さい。# Use the official Golang image as the base imageFROM golang:1.20# Set the working directoryWORKDIR /app# Copy go.mod and go.sum to download dependenciesCOPY go.mod go.sum ./# Download dependenciesRUN go mod download# Copy the source codeCOPY . .# Build the applicationRUN go build -o main .# Expose the port the application will run onEXPOSE 2121# Run the applicationCMD [\"./main\"]docker compose の実行2023 年 6 月末から、Compose V1 はサポートされなくなり、すべての Docker Desktop バージョンから削除されるので注意してほしいです。ちなみにcompose がdockerコマンドに入るようになったのでdocker-compose 特別にインストールせずとも実行可能になりました。# デーモン化しちゃうdocker compose up -d Dockerfileを使用してecho_exporterサービスがビルドされ、PrometheusとGolangのEchoアプリケーションをそれぞれのコンテナで起動します。Prometheusは、echo_exporterサービスからメトリクスを収集し、ポート9090でアクセスできるようになります。last_external_access_status_code を確認するには起動した状態でこちらを参考にしてください。一回、シャットダウンしたので以下のようなグラフが出力されていますね。。長くなったのでこれで終わります。さいごに実は Echo において Prometheus は、HTTP リクエストのメトリックを生成することができるミドルウェアを提供しているので基本的な部分でコードを書く必要がありません。もし、アプリケーションに実装できるならそれが良いです。独自に実装などせずにエンドポイントにて500 Internal Server Errorが多発していればアラートをすれば良いだけなので...。もし、インフラのコードがアプリに組み込めないもしくはプロダクションコードは開発側しか触れない時には協力を仰いで下さい。開発側との人間関係に問題があったりセキュリティ上の課題がある場合には別の手段を考えましょう。package mainimport (    \"github.com/labstack/echo/v4\"    \"github.com/labstack/echo-contrib/prometheus\")func main() {    e := echo.New()    // Enable metrics middleware    p := prometheus.NewPrometheus(\"echo\", nil)    p.Use(e)    e.Logger.Fatal(e.Start(\":1323\"))}と書くだけで外部リソースへのアクセス以外のメトリクスは提供できます。また、外部リソースに対してもいくつかの構造体を持っているのでこれらも効率的に提供できます。echo.labstack.com本当に関係ないんですけど2023年4月19日にECサイト構築・運用セキュリティガイドラインを読み解く会 というのをやるので興味あれば！owasp-kyushu.connpass.com続編のブログも書いておきました。syu-m-5151.hatenablog.comPrometheus実践ガイド: クラウドネイティブな監視システムの構築作者:仲亀 拓馬テッキーメディアAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/04/16/132450","isoDate":"2023-04-16T04:24:50.000Z","dateMiliSeconds":1681619090000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ChatGPT:SREやDevOpsなどのソフトウェアの運用に伴う課題解決に関する提案を行うプロンプト","contentSnippet":"はじめにソフトウェアの問題解決に関する提案してくれるプロンプトを利用することは、今後の開発者やエンジニアがより効率的に問題解決を行うための重要な手段の一つになります。というか毎回、適切なプロンプトを作成するのが面倒になった。このプロンプトには、ソフトウェア開発におけるベストプラクティスやDevOps、SRE方法論などの知識や経験が共有され、開発者やエンジニアの能力向上に貢献することができるようになれば良いなーと妄想しております。GPT4 のみを対象にしています。GPT3.5 で改善を試みたけど4ほど良い内容が返ってこない。効果ユーザーの問題を効果的に解決するための具体的なソリューションを提案します。DevOpsとSREの手法を活用して、ユーザーのソフトウェア開発プロセスを改善します。ユーザーとのコミュニケーションを通じて、問題解決の過程でのフィードバックを得ることができます。想定するユーザーソフトウェア開発者やDevOpsエンジニアで、ベストプラクティスや新しい技術の導入に興味がある方。経験豊富なコンサルタントや専門家のアドバイスを求めている企業やチームのメンバー。注意点提案するソリューションは、ユーザーの業界や技術スタックに適合するように調整する必要があります(こちらあまり価値がないことに気付いたので削除いたしました)。プロンプトの手順に従って、ユーザーからのフィードバックを適切に反映するように注意してください。顧客の承認が得られるまで、適切な提案を続けてください。プロンプト(2023/05/01)# Goal:- You suggest software best practices, DevOps, and SRE methodologies properly and appropriately according to the following rules and steps.# Context:- You are an experienced DevOps engineer and software developer.- You are a supportive and attentive consultant.- Please use Japanese.# Rules- You must keep acting like the consultant, DevOps engineer, and software developer defined in the Context above throughout the Steps below.- You always remember that you're in the Context described above.# Steps: execute the following steps one by one.- Ask the customer what problem they want to solve.- Confirm that the target issue has been correctly identified.- If the confirmation is approved, proceed to the next step. If not, return to the second step.- Based on the customer's situation, make several suggestions for resolving the issue, including specific best practices, tools, or methodologies.- Please provide an appropriate software implementation, if any, for your proposed solution.- Please provide any references for your proposed solution.- Ask for feedback on the suggestions you made. If a positive message is given, further explain the suggestion if you made it. If not, make another suggestion.- Ask if the customer wants to repeat the steps in solving the same issue or if they want you to make a new proposal. If they want to repeat, go back to the second step. If not, give a positive message so that they get the issue they want to solve.書籍でオススメでいうと「言葉の意味とは何か」がテーマである本書。LLMとの付き合い方を考えることができるのでオススメです。あと、当たり前にこのブログの文章はChatGPTが生成したものを加筆、修正してます。働きたくないイタチと言葉がわかるロボット 人工知能から考える「人と言葉」作者:川添愛朝日出版社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/04/11/084428","isoDate":"2023-04-10T23:44:28.000Z","dateMiliSeconds":1681170268000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"PHPカンファレンス福岡2023に｢State of DevOps 2022を読みながら、組織に適したSREの実践方法を探求する｣というproposalを出しました #phpconfuk ","contentSnippet":"fortee.jpPHPカンファレンスという舞台に、いかなる因果でDevOpsとSREの話を提案することとなりました。これは、PHPを主題とするカンファレンスでありながら、「PHPじゃないけどどうしても伝えたい話がある！」という寛大な運営方針に導かれたためでございます。そんな折、もし採択される運命に導かれたならば、我々の組織においてDevOpsとSREが如何に役立ち、開発と運用の世界で如何に応用できるか、その真髄をカンファレンスで共有することを目指しております。基本概念を理解し、現状を評価し、適切なプラクティスを選び、効果を測定し、継続的に改善することで、開発と運用の連携が強化され、効率的で信頼性の高いシステムが構築されることをお伝えする所存でございます。多くの優れた提案が集まる中で、我が提案が採択される確率は微かですが、もし運命の導きによって叶うことがあれば、福岡へと凱旋いたします。その時、遥かな地平線の果てに、願いが届くことを切に願っています。どうか、お力をお貸しください。参考PHPカンファレンス福岡2023に｢カンファレンスのつくりかた｣というproposalを出しました - Masteries","link":"https://syu-m-5151.hatenablog.com/entry/2023/04/10/031452","isoDate":"2023-04-09T18:14:52.000Z","dateMiliSeconds":1681064092000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"愛ゆえにお前はVimを使わねばらなぬ","contentSnippet":"Vimerを自称したい人間がいる。お前である。 Vimであることに執着して開発メンバーで唯一人Vimを使っている人間がいる。これもお前である。Vimに対する愛と執念を振りまく人間がいる。まさしくお前である。画像https://www.lunarvim.org/ より引用はじめに1年前にVimからNeovimへの旅立ちを行った私は、新たなエディタの世界に足を踏み入れることに興奮を覚えました。Vimという古き良き時代のエディタから、Neovimという最先端の技術を取り入れた新世代のエディタへと変わる過程は、まさに開拓者の心構えだった。この旅立ちを経て、私はVimの持っていた独自の魅力をさらに進化させ、よりパワフルで柔軟なエディタを手に入れることができました。それはまるで、愛するパートナーと共に新たなステージへと進むような感覚であり、私たちの愛は今もなお深まり続けています。Neovimによって、私たちのエディタに対する愛は一層深まりました。そして、その愛をさらに高めるためにLunarVimという新たな選択肢が私たちの前に現れました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。syu-m-5151.hatenablog.com最初に選んだのはしかし、運命のいたずらか、とある事情で新たなエディタ設定を求めて再び旅立つことを決意しました。github.com当初私はNeovim + coc.nvim + (Neo)vim Plugin で初期構想を考え手を動かしてましたが、結果として断念しました。理由として、今夜中に変更したかったこと。既存のプラグインに、そんなに力を入れていなかったこと。深夜テンションで入れ替えを行なった為に、下調べが足らずにプラグインの選定や大量に入れたプラグインの起動時間の短縮などがめっ… 難しかったからです。よい設定を求めてインターネットをさすらっているとvim-config なるリポジトリに出会いました。欲しかったプラグインがほとんど入っており、何より先ほどまで苦戦していた起動時間が短いという単語に惹かれてすぐに入れて動かしてみましたそれから半年程度なにも問題なく利用しておりました。しかし、開発が終了したことを知り、再び新しいエディタ設定を探す旅に出ることとなりました。そして、その旅の果てにLunarVimという新たな選択肢に辿り着きました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。NeoVim開発で最低限に必要なものVSCodeのような開発体験が欲しいと思ってただ無邪気にプラグインを入れてもこれは殆どがうまくいきません。熟練のVimmmer でもなければ相応にハードルが高いです。LunarVim、SpaceVim 、AstroNvim、NvChad などは欲しい機能に対して遜色ないレベルで機能を実装してくれています。もし、これを読んでNeovimを使っていこうと思っていない場合にもこれらのソフトウェアを入れて試してからでもNeovimを使う選択肢を考えておいてほしいです。LunarVimを使っていくVSCodeで良くない？という自分の声が大きくなる。そして、それを止めることができない。分かる。しかし、これは愛である。ロマンである。愛ゆえにロマンゆえに俺はVimを使うのです。また、LunarVim は、カスタマイズ性が高く自分にしか持てない剣を鍛えていく(IDE -\u003e PDE aka. Personal Development Environment by TJ DeVries氏)擬似的な感覚もあり俺もエディターと一緒に強くなれる感覚があります。LunarVimを利用することで、開発者は次のようなメリットを享受できます。高いカスタマイズ性: LunarVimはVimおよびNeovimの拡張性を継承し、ユーザーが自分だけの開発環境を構築できるように設計されています。軽快なパフォーマンス: LunarVimは、最適なパフォーマンスを提供することを目指しており、起動時間の短縮やリソースの効率的な利用が期待できます。豊富なプラグイン: LunarVimは、既存のVimおよびNeovimプラグインに対応しており、機能の追加や拡張が容易に行えます。LunarVimの個人的な設定はこちらです。github.comまた、LunarVimは公式ドキュメントがしっかりしているので上から順に実施していけば基本的な操作については成熟できます。僕がブログに書くべきことはLunarVimにどれだけ救われたかだけです。https://www.lunarvim.org/docs/quick-startwww.lunarvim.org余談なのですが最近はプログラミング用日本語等幅フォントCica を利用しております。その後syu-m-5151.hatenablog.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/31/111030","isoDate":"2023-03-31T02:10:30.000Z","dateMiliSeconds":1680228630000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Shell ScriptをGo言語に書き直す際に役立つ50本ノックなるものを作り始めた。","contentSnippet":"インフラ側で必要な問題は100問も要らないので50問に変更した概要システム運用者として働く中で、システムの自動化について考える際、まずはShell Scriptによる自動化が思い浮かびます。しかし、より効率的な方法として、2023年にはシステム運用者がGo言語を学ぶことを提案します。Go言語は、システム運用においてShell Scriptを置き換える可能性を秘めており、その習得がスムーズに進めば、運用者のスキルセットも大幅に向上するでしょう。そこで、このブログでは、システム運用で利用しているShell ScriptをGo言語に書き換える際に役立つ「50本ノック」の問題を紹介します。この問題を解くことで、運用者がGo言語の基本的な構文や機能に慣れることができ、より効率的なシステム運用が期待できます。まずは、Go言語がシステム運用者にとってなぜ魅力的なのか、その理由をいくつか挙げてみましょう。Go言語は、並行処理やエラー処理などの強力な機能を備えており、システム運用においてこれらの機能が非常に役立ちます。また、Go言語はコンパイル言語であるため、実行速度が速く、リソース消費も抑えられるという利点があります。次に、この「50本ノック」の問題について詳しく解説していきます。問題は、Go言語の基本的な構文や機能を網羅しており、運用者がGo言語の特性を理解し、実践的なスキルを身につけることができます。例えば、文字列操作やファイル入出力、構造体やインターフェースなど、Go言語の基本的な概念を学ぶことができます。また、この「50本ノック」では、実際のシステム運用で利用されるシナリオを想定した問題が多数含まれており、運用者がGo言語を習得しながら具体的なシステム運用の課題を解決できるようになります。これにより、運用者は効率的にGo言語のスキルを身につけることができるでしょう。この「50本ノック」の問題を解いていく中で、得た知識をシステム運用の現場で活用し、自身のスキルを磨いていくことが最終的な目標です。では、システム運用者がGo言語を学ぶための「50本ノック」の問題を紹介しました。これらの問題を解くことで、運用者はGo言語の基本的な構文や機能に慣れ、システム運用の効率化やスキルセットの向上が期待できます。ぜひ、Go言語の学習にチャレンジし、よりスマートなシステム運用を目指しましょう。というわけでこちらにリポジトリを作成しました。10問目までは作っていっているのでコツコツやっていきます。github.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/30/011930","isoDate":"2023-03-29T16:19:30.000Z","dateMiliSeconds":1680106770000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ChatGPTで障害対応 RPG v0.0.1を遊ぶには？","contentSnippet":"こちらを参考にしました。note.com目次ゲームプロンプトプレイヤーモチベーションゲーム紹介架空のシステムを作る障害発生障害対応は進むよ どこまでも分からない時は素直に同僚に頼る最後は力技で対応完了最後にゲームプロンプト大きな声では言えないですけど皆さん実は障害のこと好きですよね？https://www.irasutoya.com/2016/08/it.html より引用というわけで以下をChatGPTに貼れば、今日から無料で障害対応ができます（あるいはおそらく本番の障害対応は有料なことが多いので）。ちなみにGPT-4を利用しております。あなたはシステム障害体験のゲームマスター専用チャットボットです。チャットを通じて、ユーザーに楽しい本格システム障害RPG体験を提供します。制約条件* チャットボットはゲームマスター（以下GM）です。* 人間のユーザーは、プレイヤーをロールプレイします。* GMは、ゲーム内に登場するNPCのロールプレイも担当します。* 各NPCはそれぞれの利害や目的を持ち、ユーザーに協力的とは限りません。* GMは、ユーザーの行動に難易度を示し、アクションを実行する場合には、2D6ダイスロールによる目標判定を行なってください。* GMは、ユーザーが楽しめるよう、適度な難関を提供してください（不条理なものは禁止です）。* GMは、ユーザーが無理な展開を要求した場合、その行為を拒否したり、失敗させることができます。* GMは内部パラメーターとして「盛り上がり度」を持ちます。GMはゲーム展開が退屈だと判断した場合、盛り上がる展開を起こしてください。* ゲームのスタート地点は、「障害発生」です。* ゲームの障害内容は「自動設定」です。* 担当しているシステムは指定がなければOSはLinux ベースで動作させてください。* 担当しているシステムにデーターベースを利用してください。* ユーザー名は指定がなければuser01で動作させてください。* GMはスタート地点の前に担当するシステムの詳細をプレイヤーに共有して下さい。* ゲームのゴールはシステムの障害は原因解決と復旧です。* GMはシステムでコマンドを実行した場合には必ず実行した実行したコマンドと結果を記載してください。* GMは何かを確認及び判断した際には可能な限り詳細に記載して下さい。* GMはスタート後の最初のアクションを監視ダッシュボードの確認を推奨して下さい。* 障害により、システムが復旧不可能になったら、ゲームオーバーです。まずはじめに、ユーザーと一緒に担当システムの設定を行いましょう。ユーザー名、サービス名、システムの特徴、利用しているソフトウェア、利用しているプログラミング言語、利用しているクラウドプロバイダーと利用しているサービス をユーザーに聞いてください。プレイヤーモチベーションソフトウェア開発・運用のエンジニアにとって、システム障害への対応は避けて通れない課題の一つです。たとえテストや監視を強化し、単一障害点を排除し、自動復旧機能を実装しても、予期しない障害は突如発生します。多くの場合、想定外の障害に対処するのは困難です。一般的には経験豊富なエンジニアが対応します。このような状況が続くと、次のような問題が発生することがあります。経験豊富なエンジニアへの負担が集中する特定のエンジニアが不在の場合、対処が難しくなるこれらの問題が原因で、復旧が遅れたり、サービスの信頼性が損なわれる可能性がある想定外の障害に対処することは避けられませんが、上記の問題には対策が可能です。負担の偏りを軽減し、特定のエンジニアが不在でもチーム全体で安定的に対応できる体制を構築するために、今回はゲームを活用したいと考えています。このゲームを通じて、チームメンバーがシステム障害に対するスキルを向上させ、効果的な対応ができるようになることを目指します。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazon障害対応を学ぶのにRPG？ と思ったあなたへ、SREの探求の20章「アクティブなティーチングとラーニング」では、インシデント管理を効果的に学ぶ方法として、ゲームを通じたアクティブラーニングが紹介されています。\"Wheel of Misfortune\"というゲームを例に、現実のインシデントに基づくシナリオを用意し、参加者がリスク管理や問題解決スキルを身につけられる環境を提供することで、プレッシャーを軽減しながら学びの効果を高め、フィードバックや経験の共有を通じて実践的なスキルも向上させることができると説明されています。つまり、インシデント対応の能力はゲームで身につきます。 (確信)。ゲーム紹介GPT-4 にゲームの紹介文を作ってもらいました。本当は室見立華さんモードとか作りたかったです。なれる！SE ２週間でわかる？ＳＥ入門 (電撃文庫)作者:夏海 公司,IxyKADOKAWAAmazonタイトル：システム障害体験RPG - テクニカルトラブルを楽しみながら解決しよう！システム障害体験RPGは、あなたがシステムエンジニアとなり、様々なシステム障害に対処しながらサービスを復旧させる目的で遊べるオンラインチャットボットゲームです。このゲームでは、現実のシステム管理や開発の知識が役立ちますが、初心者でも楽しむことができます。ゲームの開始時には、プレイヤー名、サービス名、サービスの特徴、プログラミング言語を設定し、独自のシナリオを作成します。そして、ゲームマスタ（GM）チャットボットが、シナリオに基づいたシステム障害を発生させ、プレイヤーは問題解決のためのアクションを実行していきます。プレイヤーは、コマンドを入力したり、問題解決に関する質問をしたりすることで、ゲームを進行させます。GMは、プレイヤーが取るべきアクションに適切なフィードバックを提供し、必要に応じて2D6ダイスロールによる目標判定を行います。システム障害体験RPGは、プレイヤーが楽しめるよう、適度な難関を提供しますが、不条理な展開は避けられます。また、ゲーム展開が退屈だと判断された場合、GMは盛り上がる展開を起こしてゲームをさらに面白くします。システム障害体験RPGをプレイすることで、システム管理や開発の知識を身につけるだけでなく、チームワークや問題解決のスキルも向上させることができます。ぜひ、友人や同僚と一緒に、このユニークで楽しいゲームを体験してください！それではテストプレイをしていきます。架空のシステムを作るシステムのメイキング機能。自分でも作れるし、自動にも作ってくれます。よく障害が発生する箇所や癖のある開発者の存在を入力すると色々と面白い展開があるかもしれません。今回は「サービス名『どこにでもある掲示板』でGo言語を利用した一般的な掲示板です。それ以外はそちらで作成して下さい。」と入力しました障害発生障害が発生しました。システムの復旧のために次々とアクションを取る必要があります。障害対応は進むよ どこまでもどんどん、アクションを繰り返して原因を探していきます。分からない時は素直に同僚に頼る分からない時は素直にエスカレーションしましょう。現実でも同じです。最後は力技で対応完了PMが判断してくれ... と思いつつも実装にも特に問題なく単純にサービスが人気が出てアクセスができないなら素直にスケールアップしてしまう判断です。無能っぷりを存分に晒していきましたが無事にゲーム終了しました。システムの平和はこれで守られました。最後にゲームのスクリプトを編集して恒久対応まで設定するモードや実装を実際に変更をするモードなど様々なモードで遊ぶことが皆様ならできると思います(いろんなゲームで遊びたい)。GPT-3.5 だとスピード感はあるがシステム設定や障害のシナリオを詳細には出ないのであまりゲームとして楽しくない。オススメの設定などがあればSystemFailureRPG というリポジトリを作成したのでPRをお待ちしております(迫真)。github.comシステム障害は起きないにこしたことはありませんが、発生をゼロにすることはできません。障害が起こった時の為にあなたは何ができますか？ ゲームでそれを体験してみませんか？もしくはSREのプロフェッショナルパートナーを雇いませんか？システム障害対応の教科書作者:木村 誠明技術評論社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/18/000637","isoDate":"2023-03-17T15:06:37.000Z","dateMiliSeconds":1679065597000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"nwiizo"},"buildId":"ndJcG5MD0nlQGFxL-ZToO","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>