<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="icon shortcut" type="image/png" href="https://blog.3-shake.com/logo.png" data-next-head=""/><title data-next-head="">nwiizo | 3-shake Engineers&#x27; Blogs</title><meta property="og:title" content="nwiizo" data-next-head=""/><meta property="og:url" content="https://blog.3-shake.com/members/nwiizo" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta property="og:site" content="3-shake Engineers&#x27; Blogs" data-next-head=""/><meta property="og:image" content="https://blog.3-shake.com/og.png" data-next-head=""/><link rel="canonical" href="https://blog.3-shake.com/members/nwiizo" data-next-head=""/><link rel="preload" href="/_next/static/css/683b82a315c74ead.css" as="style"/><link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;700&amp;family=Roboto:wght@300;400;500;700&amp;display=swap" rel="stylesheet"/><link rel="stylesheet" href="/_next/static/css/683b82a315c74ead.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-6ffd07a3317375c1.js" defer=""></script><script src="/_next/static/chunks/framework-de98b93a850cfc71.js" defer=""></script><script src="/_next/static/chunks/main-0e21001e2c71e4ad.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb27c9050fc0d186.js" defer=""></script><script src="/_next/static/chunks/736-e01ec13d1e924789.js" defer=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-505fa9f61659e527.js" defer=""></script><script src="/_next/static/dRPkvrqAGuZDPHCSZstlV/_buildManifest.js" defer=""></script><script src="/_next/static/dRPkvrqAGuZDPHCSZstlV/_ssgManifest.js" defer=""></script></head><body><link rel="preload" as="image" href="/logo.svg"/><link rel="preload" as="image" href="/avatars/nwiizo.jpeg"/><link rel="preload" as="image" href="/icons/twitter.svg"/><link rel="preload" as="image" href="/icons/github.svg"/><link rel="preload" as="image" href="/icons/link.svg"/><link rel="preload" as="image" href="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com"/><link rel="preload" as="image" href="https://www.google.com/s2/favicons?domain=speakerdeck.com"/><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.svg" alt="3-shake Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">3-shake<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a class="site-header__link" href="/feed.xml">RSS</a><a href="https://jobs-3-shake.com/" class="site-header__link">Recruit</a><a href="https://3-shake.com/" class="site-header__link">Company</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/nwiizo.jpeg" alt="nwiizo" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">nwiizo</h1><p class="member-header__bio">The Passionate Programmer</p><div class="member-header__links"><a href="https://twitter.com/nwiizo" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@nwiizo" width="22" height="22"/></a><a href="https://github.com/nwiizo" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@nwiizo" width="22" height="22"/></a><a href="https://nwiizo.github.io/" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-20T15:57:59.000Z" class="post-link__date">2 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/21/005759" class="post-link__main-link"><h2 class="post-link__title">Ghostty 1.3.0（tip）にアップグレードしたらフルスクリーンが壊れた——原因と新設定の全記録</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a><div class="post-link__new-label">NEW</div></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-19T05:00:00.000Z" class="post-link__date">3 days ago</time></div></a><a href="https://speakerdeck.com/nwiizo/30fen-dewakaruakitekutiyamodanaizesiyon" class="post-link__main-link"><h2 class="post-link__title">30分でわかるアーキテクチャモダナイゼーション</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-18T05:00:00.000Z" class="post-link__date">4 days ago</time></div></a><a href="https://speakerdeck.com/nwiizo/yi-zhi-woshi-zhuang-suruakitekutiyamodanaizesiyon" class="post-link__main-link"><h2 class="post-link__title">意志を実装するアーキテクチャモダナイゼーション</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-17T02:53:06.000Z" class="post-link__date">5 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/17/115306" class="post-link__main-link"><h2 class="post-link__title">おい、方法を選べ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-13T03:22:28.000Z" class="post-link__date">9 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/13/122228" class="post-link__main-link"><h2 class="post-link__title">Claude CodeのPLAN MODEは使ったほうがいい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-09T09:02:40.000Z" class="post-link__date">13 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/09/180240" class="post-link__main-link"><h2 class="post-link__title">おい、方法を学べ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-03T15:22:44.000Z" class="post-link__date">19 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/04/002244" class="post-link__main-link"><h2 class="post-link__title">正しさは、昼間の言葉</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-02-02T03:46:15.000Z" class="post-link__date">20 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/02/02/124615" class="post-link__main-link"><h2 class="post-link__title">おい、分けて語るな</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-29T04:07:42.000Z" class="post-link__date">24 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/29/130742" class="post-link__main-link"><h2 class="post-link__title"> 2026年1月 Neovim の Rust 環境を見直した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-29T00:20:03.000Z" class="post-link__date">24 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/29/092003" class="post-link__main-link"><h2 class="post-link__title">ZellijのRust実装パターン徹底解説（後編）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-28T09:17:50.000Z" class="post-link__date">25 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/28/181750" class="post-link__main-link"><h2 class="post-link__title">ZellijのRust実装パターン徹底解説（前編）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-26T02:04:44.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/26/110444" class="post-link__main-link"><h2 class="post-link__title">おい、あまりAIに褒めさせるな</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-22T00:46:54.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/22/094654" class="post-link__main-link"><h2 class="post-link__title">Rust でも学べる関数型ドメイン駆動設計 - Domain Modeling Made Functional の読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-19T00:01:19.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/19/090119" class="post-link__main-link"><h2 class="post-link__title">おい、頑張るなら組織と踊れ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-18T03:31:51.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/18/123151" class="post-link__main-link"><h2 class="post-link__title">プログラミングが好きな人こそ今の時代、プログラマーになる方がいいと思う。- 「プログラミングが好きな人は、もうIT業界に来るな。」を読んで</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-14T05:02:48.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/14/140248" class="post-link__main-link"><h2 class="post-link__title">Ory Kratosで認証を委譲する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-11T15:30:13.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/12/003013" class="post-link__main-link"><h2 class="post-link__title">おい、辞めないなら頑張れ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-10T21:43:11.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/11/064311" class="post-link__main-link"><h2 class="post-link__title">OAuth2認証をE2Eテストしたら、5つのバグが出てきた話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-09T01:46:16.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/09/104616" class="post-link__main-link"><h2 class="post-link__title">Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-08T00:24:09.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/08/092409" class="post-link__main-link"><h2 class="post-link__title">Fear of the Unknown：Rust/sqlxでNULLを制する6つのパターン</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-07T01:38:53.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/07/103853" class="post-link__main-link"><h2 class="post-link__title">AI時代に今からITエンジニアを目指す若者にオススメする10冊の本  2026年版</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-05T15:42:44.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/06/004244" class="post-link__main-link"><h2 class="post-link__title">RustでOry Hydra用認証プロバイダーを実装する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-05T00:00:20.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020" class="post-link__main-link"><h2 class="post-link__title">おい、辞めるな</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-04T05:16:22.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622" class="post-link__main-link"><h2 class="post-link__title">Hacker NewsのShow HN に自作ツールを投稿する方法 </h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-04T04:30:07.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007" class="post-link__main-link"><h2 class="post-link__title">Ory HydraでOAuth2認可サーバーを構築する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-02T15:26:21.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621" class="post-link__main-link"><h2 class="post-link__title">私の為のNvChadのキーマッピングガイド 2026年版</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2026-01-01T23:37:35.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735" class="post-link__main-link"><h2 class="post-link__title">テスト,検証してますか: cargo-mutantsによるミューテーションテスト入門</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-12-31T17:21:47.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147" class="post-link__main-link"><h2 class="post-link__title">2025年 個人的に心に残ったグラビアアイドル10選</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-12-31T14:26:23.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623" class="post-link__main-link"><h2 class="post-link__title">2025年、nwiizoが作ったソフトウェア</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-12-29T23:33:24.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324" class="post-link__main-link"><h2 class="post-link__title">おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-12-29T07:07:46.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746" class="post-link__main-link"><h2 class="post-link__title">おい、論理で人が動くと思ってるのか</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-12-28T02:50:33.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033" class="post-link__main-link"><h2 class="post-link__title">2025年 俺が愛した本たち 非技術書編</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article></div><div class="post-list-load"><button class="post-list-load__button">LOAD MORE</button></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->3-shake Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"The Passionate Programmer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"Ghostty 1.3.0（tip）にアップグレードしたらフルスクリーンが壊れた——原因と新設定の全記録","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/21/005759","contentSnippet":"はじめにGhosttyをtipチャンネルで追いかけている。メモリリーク修正が早く降ってくるからだ。ある日アップデートしたら、フルスクリーンで起動しなくなった。fullscreen = trueは書いてある。設定は一行も変えていない。ghostty.orgCmd+Tでタブを開こうとしたら「Cannot Create New Tab — New tabs are unsupported while in non-native fullscreen」というダイアログが出た。設定が壊れたのではない。変わったのはGhosttyの方だ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。何が起きたか私のGhostty設定には、以下の2行がありました。macos-non-native-fullscreen = visible-menufullscreen = truemacos-non-native-fullscreen = visible-menuは、macOSネイティブのフルスクリーンアニメーションを使わず、メニューバーを表示したままフルスクリーン化するオプションです。ネイティブフルスクリーンの「ヌルッ」としたアニメーションが嫌いで、この設定にしていました。1.3.0（tip）にアップデートした後、2つの問題が同時に発生しました。起動時にフルスクリーンで開かない。Cmd+Tでタブが作れず、「non-native fullscreenではタブは非対応」というエラーダイアログが表示される。最大化ボタンも見えない状態でした。原因の特定根本原因は1つでした。ただし、切り分けに至るまでに寄り道をしている。その過程も書いておく。根本原因: non-native fullscreenでタブが非対応にGhostty 1.3.0で、non-native fullscreenモード（visible-menu含む）ではタブがサポートされなくなりました。これは意図的な変更です。non-native fullscreenはmacOSのウィンドウ管理を迂回する実装のため、タブバーとの整合性を保証できないという判断でしょう。fullscreen = trueとmacos-non-native-fullscreen = visible-menuの組み合わせが、1.2.xでは動いていたものが1.3.0で破綻した形です。問題なのは、この組み合わせで起動してもエラーや警告が一切出ないことです。フルスクリーンにならず、最大化ボタンも見えず、タブを開こうとして初めてダイアログが出る。設定の検証時点で警告を出してくれれば、すぐに気づけます。この点はIssue #10894として報告しました。github.com疑った原因: window-save-stateによるfullscreen設定の上書き最初に疑ったのはwindow-save-state = alwaysでした。この設定は前回のウィンドウ状態を保存・復元します。一度でもフルスクリーンを解除して閉じると、その「非フルスクリーン」状態が保存され、次回起動時にfullscreen = trueより優先される——という仮説です。実際にwindow-save-state = neverに変更してみましたが、フルスクリーン問題は解消しませんでした。ここでwindow-save-stateは犯人ではないとわかりました。ただし、neverにしたことでタブの保存・復元まで消えてしまい、別の問題を踏むことになりました。結局alwaysに戻しています。原因の切り分けで設定を変えるときは、副作用に注意が必要です。修正内容修正は1箇所です。- macos-non-native-fullscreen = visible-menu+ # 1.3.0 で non-native fullscreen はタブ非対応になったため無効化+ macos-non-native-fullscreen = falsemacos-non-native-fullscreen = falseでmacOSネイティブフルスクリーンに切り替えます。メニューバーの常時表示はできなくなりますが、画面上部にマウスを持っていけば表示されるので実用上の問題はありません。タブとフルスクリーンの両方が使えることの方が重要です。window-save-state = alwaysはそのまま維持します。ネイティブフルスクリーンであれば、タブ・フルスクリーン状態ともに正しく保存・復元されます。Cmd+Qで正常終了すれば、次回起動時にタブが復元されることを確認済みです。1.3.0の新設定オプションを取り込むせっかくtipチャンネルで最新を追いかけているので、1.3.0で追加された新しい設定オプションも調査して取り込みました。Ghostty 1.3.0マイルストーンには597件のクローズ済みissueがあり、設定周りだけでもかなりの変更が入っています。github.com以下、実際に採用したものとその理由です。scrollbar = never# 1.3.0: スクロールバー非表示（キーボードナビゲーション主体のため）scrollbar = never1.3.0でmacOSとGTKの両方にネイティブスクロールバーが実装されました。デフォルトはsystem（OS設定に従う）です。私はCtrl+U、Alt+B、Alt+Gなど、Vim式のキーボードナビゲーションでスクロールしているので、スクロールバーは不要です。描画領域も広がるため、neverにしています。split-preserve-zoom = navigation# 1.3.0: ズーム中のスプリット移動でズーム状態を維持split-preserve-zoom = navigationスプリットをCmd+Shift+Enterでズームした状態で、Ctrl+H/J/K/Lで隣のスプリットに移動すると、従来はズームが解除されていました。navigationフラグを有効にすると、スプリット間の移動でもズーム状態が維持されます。ズームしたまま「隣のペインの出力をちょっと確認」ができるようになるので、地味に便利です。tab-inherit-working-directory / split-inherit-working-directory# 1.3.0: タブ・スプリットも作業ディレクトリを継承tab-inherit-working-directory = truesplit-inherit-working-directory = true従来はwindow-inherit-working-directoryしかなく、新規ウィンドウのみが作業ディレクトリを継承していました。1.3.0で新規タブと新規スプリットにも個別に設定できるようになりました。デフォルトでtrueですが、明示的に書いておくことで意図を残しています。~/projects/my-appで作業中にCmd+Tで新しいタブを開いたら、そのタブも~/projects/my-appで始まる。当然の挙動ですが、以前は必ずしもそうならないケースがありました。notify-on-command-finish# 1.3.0: コマンド完了通知（非フォーカス時、5秒以上のコマンド）notify-on-command-finish = unfocusednotify-on-command-finish-after = 5s長時間コマンドの完了通知です。cargo testやdocker buildを走らせて別のタブで作業しているとき、完了したらmacOSの通知が飛んできます。unfocusedはGhosttyウィンドウが非フォーカスのときのみ通知するモードです。5秒未満で終わるコマンドは通知されません。前提としてシェルインテグレーション（OSC 133）が必要です。Fish shellではshell-integration = fishを設定していればそのまま動きます。検索ハイライトのカスタマイズ# 1.3.0: 検索ハイライト（Tokyo Night に合わせた配色）search-foreground = #1a1b26search-background = #e0af68search-selected-foreground = #1a1b26search-selected-background = #ff9e641.3.0でターミナル内検索がネイティブGUIとして実装されました。検索マッチのハイライト色をカスタマイズできます。Tokyo Nightテーマに合わせて、候補はイエロー（#e0af68）、選択中はオレンジ（#ff9e64）にしました。テーマのパレットから色を取っているので違和感なく馴染みます。palette-generate = false# 1.3.0: カスタムパレット指定時の自動生成を無効化（正確な色を維持）palette-generate = false1.3.0では、ベースの16色ANSIパレットをカスタマイズしている場合、拡張256色パレット（インデックス16〜255）を自動的に再生成する機能が追加されました。Tokyo Nightのパレットを正確に維持したいので、この自動生成は無効化しています。採用しなかった新機能調査した結果、以下の機能は今回採用しませんでした。判断の根拠も書いておきます。key-remap（修飾キーのリマッピング）: Ghosttyアプリケーション内でCtrlとCmdを入れ替えるなどの用途です。Karabiner-Elementsでシステムレベルでやっているので不要でした。Key Tables / Key Sequences（モーダルキーバインド）: ctrl+wでペイン操作モードに入り、h/j/k/lで移動、escapeで抜ける——tmuxのprefix keyに近い仕組みです。面白いですが、現在のperformable:ベースのスプリット操作で不満がないので見送りました。tmuxから移行する人には嬉しい機能でしょう。mouse-reporting = false（マウスレポート無効化）: Neovimでのマウス操作を無効にしたい場合に使えます。私はNeovim側でマウスを有効にしているので不要です。ランタイムでtoggle_mouse_reportingアクションで切り替えられるので、必要になったらキーバインドを追加する方が柔軟です。selection-word-chars（ダブルクリック選択の単語境界）: デフォルトの単語境界文字セットで不便を感じていないので、カスタマイズ不要でした。1.3.0のその他の注目機能設定に直接関係しないものの、知っておくと便利な1.3.0の変更点も書いておきます。ターミナル内検索: macOSとGTKの両方でネイティブ検索UIが実装されました。Cmd+Fで検索バーが出ます。マッチ間のナビゲーション、ハイライト色のカスタマイズに対応しています。これまでscrollback-limitを大きくしても検索手段がなかったので、ようやくです。スプリットのドラッグ\u0026ドロップ（macOS）: スプリットをドラッグして別のウィンドウに移動したり、ウィンドウ外にドラッグして新しいウィンドウを作ったりできます。タブのカラーピッカー（macOS）: タブを右クリックして色を付けられます。プロジェクトごとにタブの色を変えると視認性が上がります。ダブルクリックでURL全選択: URL上でダブルクリックすると、単語ではなくURL全体が選択されるようになりました。ペースト安全性の向上: ペースト時に危険な制御文字がスペースに置換されるようになりました。xtermと同じ挙動です。Nushell対応: shell-integration = detectでNushellの自動検出・設定が動くようになりました。最終的な設定ファイル修正と新機能の追加を反映した設定ファイルの全体を載せておきます。各設定項目の詳細は公式のConfiguration Referenceを参照してください。ghostty.orggithub.comまとめtipチャンネルで最新ビルドを追いかけるということは、こういう破壊的変更に当たるということです。macos-non-native-fullscreen = visible-menuが1.3.0でタブと共存できなくなったのは、Release Notesに書かれる前に体験で知ることになりました。トラブルシュートの過程でwindow-save-stateをneverに変えてみたり、macOSのdefaultsを削除してみたりと、関係ない設定まで触ってしまいました。結局、根本原因はmacos-non-native-fullscreenの1箇所だけだった。原因を切り分けるとき、変更は1つずつ試して戻す。当たり前のことを、自分の設定ファイル相手だと雑にやってしまう。一方で、1.3.0には良い変更も多く入っています。ターミナル内検索、コマンド完了通知、split-preserve-zoom、作業ディレクトリの継承強化。どれもターミナルヘビーユーザーにとって実用的な改善です。特にコマンド完了通知は、cargo testを走らせて別作業をしている間に完了を見逃す——という日常的なストレスを解消してくれます。Ghostty 1.3.0の正式リリースは2026年3月の予定です。tipチャンネルで先行して使いたい方は、この記事の設定変更が参考になるはずです。正式リリースを待つ方も、macos-non-native-fullscreenの挙動変更は覚えておいて損はないはずです。ghostty.org参考Issue #10894: fullscreen=true + macos-non-native-fullscreen=visible-menu が 1.3.0 で無警告に壊れるGhostty 1.3.0 MilestoneGhostty Release NotesGhostty Configuration Reference","isoDate":"2026-02-20T15:57:59.000Z","dateMiliSeconds":1771603079000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"30分でわかるアーキテクチャモダナイゼーション","link":"https://speakerdeck.com/nwiizo/30fen-dewakaruakitekutiyamodanaizesiyon","contentSnippet":"3-shake SRE Tech Talk 特別回「アーキテクチャモダナイゼーション」にて、「30分でわかるアーキテクチャモダナイゼーション」というタイトルで登壇しました。\r\rhttps://3-shake.connpass.com/event/382086/\r\r書籍『アーキテクチャモダナイゼーション ―組織とビジネスの未来を設計する』は好評発売中です。\r\rhttps://amzn.to/3ZR5Bgv\r\r同日に発表した「意志を実装するアーキテクチャモダナイゼーション」の資料も公開しています。\r\rhttps://speakerdeck.com/nwiizo/yi-zhi-woshi-zhuang-suruakitekutiyamodanaizesiyon","isoDate":"2026-02-19T05:00:00.000Z","dateMiliSeconds":1771477200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"意志を実装するアーキテクチャモダナイゼーション","link":"https://speakerdeck.com/nwiizo/yi-zhi-woshi-zhuang-suruakitekutiyamodanaizesiyon","contentSnippet":"Developers Summit 2026（デブサミ2026）にて、「意志を実装するアーキテクチャモダナイゼーション」というタイトルで登壇しました。\r\rhttps://event.shoeisha.jp/devsumi/20260218/session/6454\r\r書籍『アーキテクチャモダナイゼーション ―組織とビジネスの未来を設計する』は好評発売中です。\r\rhttps://amzn.to/3ZR5Bgv\r\r同日に発表した「30分でわかるアーキテクチャモダナイゼーション」の資料も公開しています。\r\rhttps://speakerdeck.com/nwiizo/30fen-dewakaruakitekutiyamodanaizesiyon","isoDate":"2026-02-18T05:00:00.000Z","dateMiliSeconds":1771390800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、方法を選べ","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/17/115306","contentSnippet":"前回の続きとして他人のPRを開いたまま、手が止まっていた。差分は表示されている。追加が緑、削除が赤。目は動いている。読んではいない。前回の記事のことを、ずっと考えていた。syu-m-5151.hatenablog.com「方法を学べ」と書いた。方法の知識、つまり操作・分解・判断の3層が課題認識の範囲を規定する。だから方法を極めることには価値がある、という話だった。書いた。書き終えた。達成感があってもよかった。なかった。何かが足りないという感覚だけが残った。学んだ。で、どうするのか。手元にハンマーもドライバーもレンチもある。どれも使える。どれを使うか決められないまま、工具箱を眺めている。PRの差分を眺めているのと、たぶん同じだった。見ているだけで、何も始まらない。「もっと調べろ」と誰かが言う。「比較表を作れ」「ベンチマークを取れ」「事例を集めろ」。正しい情報があれば正しく選べる。エンジニアの世界では、それが常識になっている。合理的に聞こえる。聞こえるが、その常識こそが、自分の手を止めていた気がする。先に補足しておきます。前回「複数の方法を知れ」と書きました。今回は「1つを選べ」と書きます。矛盾しているように見えますが、矛盾していません。複数知ることと、同時に複数やることは違います。順番に深める話です。まず学び、次に選ぶ。同時並行で表面をなぞるのとは違います。今日はその話を書きます。選ぶことについて。書けるかどうかは、正直わかりません。「選ぶ」とは何か前回、「方法」を操作・分解・判断の3層で定義しました。今回の「選ぶ」にも構造があります。書きながら整理して、3つに分けました。また3つです。何でも3つに分けたがる習性があるのかもしれません。1つ目は評価です。選択肢を並べ、それぞれの特性を理解し、現在の文脈でどれが最も適切かを見極めます。前回の「判断」の知識がここで効きます。判断の語彙がなければ、評価の軸が立ちません。2つ目は宣言です。「私はAを選ぶ。理由はこれだ」と、他者に伝えます。選択を頭の中に留めておくのは、選んでいないのと同じです。宣言によって選択は社会的な事実になります。3つ目は撤退判断です。選んだ後、「いつ撤退するか」の基準をあらかじめ持っておくこと。撤退ラインのない選択は、ただの賭けです。「3ヶ月やって成果が出なければ見直す」「この指標がこの閾値を下回ったら切り替える」。選ぶ前に、選び直す条件を決めておきます。この3つは独立しているように見えて、相互に強化し合います。評価が宣言を支え、宣言が撤退判断の起点になり、撤退判断の経験が次の評価を鋭くします。前回の3層が「操作→分解→判断」という依存関係を持っていたように、「選ぶ」の3要素も評価→宣言→撤退という順序があります。評価せずに宣言すれば蛮勇ですし、宣言せずに撤退判断だけ持っていても意味がありません。と書いて、立ち止まります。この3要素を整理できたのは、失敗した後でした。当時はこんな構造は見えていませんでした。評価だけして宣言しませんでした。宣言したのに撤退ラインを決めていませんでした。3つが揃ったのは、3つとも欠けた経験をした後でした。たぶん、構造は事後的にしか見えません。それでも書きます。事前に知っていれば、失敗の質が変わるかもしれないからです。と書いて、気づきました。この3要素、評価・宣言・撤退を並べた瞬間、既視感があった。診断して、方針を立てて、一貫した行動をとる。これは戦略の構造そのものです。そして、私がやっていた（つもりの）技術選定が、戦略ですらなかったことに気づきました。「売上を2倍にする」は戦略ではありません。目標の列挙にすぎない。同様に、「もっと調べてから選ぶ」は選択ではなかった。私がやっていたのは目標の列挙、つまり比較表を精緻にすることであって、「何が本当の困りごとか」を直視する診断ではなかった。この定義を前提に、それぞれの要素で何が起きるかを見ていきます。知識が増えると、動けなくなる方法を学びました。ハンマー、ドライバー、レンチ。全部知っています。全部使えます。スクラム、リーン、システム思考。どれも説明できます。では、目の前の問題に、どれを使うか。「全部知っている」ことと「適切に使える」ことは、まったく別の能力です。選択肢が増えると、むしろ動けなくなることがあります。どれでも解けそうに見える。どれが最適かわからない。「もう少し考えてから」と言い訳する。「状況を見て判断しよう」と先延ばしする。結局、何も選ばないまま時間だけが過ぎます。学んだ意味がない。選択肢が多すぎると、人は選べなくなる。6種類のジャムと24種類のジャムでは、6種類の方が売れるという話があります。24種類を前にすると、人は「もう少し比べてから」と棚の前で立ち尽くす。私の工具箱はジャム24種類の棚でした。あるとき、自分の行動パターンに気づきました。人は2つのタイプに分かれます。あらゆる選択肢を検討し最善を求める人と、「十分に良い」選択肢が見つかった時点で決断する人。そして、直感に反する事実がある。最善を求める人の方が、選択の結果に満足していません。「もっと良い選択があったのでは」という後悔が消えない。「十分に良い」で決断する人の方が、選んだ後の満足度が高い。私は完全に前者でした。データベースの選定です。MySQL、PostgreSQL、CockroachDB、TiDB、Vitess。ベンチマークを比較し、ブログ記事に目を通し、GitHub Issueまで追いました。2週間かけて比較表を作りました。完成度は高かった。しかし、2週間経っても選べませんでした。比較すればするほど、各選択肢の長所と短所が均衡していく。どれも「ある条件下では最善」であり、「別の条件下では最善ではない」。完璧な選択肢は存在しませんでした。当たり前です。存在するなら、他の選択肢は淘汰されています。振り返って気づきます。比較表を作っている間、私は「選んでいる」つもりでした。実際には「選ばない理由を積み上げている」だけでした。Aの弱点を見つけてはBに目を移し、Bの弱点を見つけてはCに逃げる。情報収集は選択の準備ではなく、選択の回避でした。「もっと調べてから」は、いつの間にか「調べ続けることで選ばずに済ませる」にすり替わっていました。「十分に良い」で決断することは妥協ではなく、構造的に合理的な戦略です。選択肢が一定数を超えると、追加の調査で得られる情報の質は逓減します。一方で、調査にかけた時間のコストは線形に増加します。どこかで交差する。その交差点を過ぎたら、「もう少し調べれば」は投資ではなく浪費です。この経験から、私は技術選定のルールを1つ決めました。「3日で決める。3日で決まらなければ、その時点で最も情報が揃っている選択肢にする」。3日は恣意的な数字です。しかし、期限があるだけで、最善を求め続ける衝動が止まります。そして正直に書くと、3日で選んだ結果が、2週間かけて選んだ結果と比べて劣っていたことは、ほとんどありません。このルールを決めた翌週、新しいミドルウェアの選定に5日かけました。ルールを作った人間がルールを破る。よくある話です。ちなみに、5日かけた結果は、3日目の時点で候補に上がっていたものと同じでした。知識が増えるほど、選択肢が増えます。選択肢が増えるほど、選べなくなる。皮肉な構造です。これは個人の性格の問題ではなく、選択肢の数が一定の閾値を超えた時点で構造的に発生します。つまり、学べば学ぶほどハマる罠です。前回「方法を学べ」と書きました。学んだ結果、ここに来る。知っていれば避けられる罠ではありません。知っているからこそハマる罠です。私は何度もこれにハマりました。選ぶとは、捨てることだ選ぶとは、他を捨てることです。Aを選ぶとは、BとCを選ばないことです。BとCで得られたかもしれない結果を、手放すことです。これが怖い。あるプロジェクトで、痛い目にあいました。大規模なリファクタリングを進めながら、同時に新機能もリリースしようとしました。リファクタリングのためにインターフェースを変更したら、新機能のコードと競合しました。新機能のためにAPIを追加したら、リファクタリングの方針と矛盾しました。両方やろうとした瞬間、どちらも中途半端になりました。結局、リリース日を2回延期しました。プロジェクトの振り返りで、テックリードに言われました。「なぜ両方同時にいけると思った？」。返す言葉がありませんでした。「リファクタリングを先にやるなら、新機能は止めろ。新機能を優先するなら、リファクタリングは次のスプリントに回せ。両方欲しがるな」。身をもって学んだ教訓です。選ばないことは、両方を失うことです。もう1つ、技術選定で間違えた話を書きます。あるプロジェクトで、データストアの選定を任されました。要件は明確でした。ユーザーのアクティビティログを保存し、リアルタイムで集計します。書き込みが多く、読み取りは集計クエリが中心です。私はRDBMSを選びました。PostgreSQLです。理由はありました。チームがPostgreSQLに慣れています。運用ノウハウがあります。JSONBカラムで柔軟なスキーマにも対応できます。分析しました。分析結果は正しかった。しかし、選んだ後に前提が変わりました。リリース3ヶ月後、ユーザー数が想定の8倍になりました。書き込みが秒間3,000件を超えました。PostgreSQLのWAL（書き込み先行ログ）がボトルネックになり、書き込みレイテンシが跳ね上がりました。集計クエリは30秒以上かかるようになりました。パーティショニングで凌ぎましたが、根本解決にはなりませんでした。同僚が言いました。「ClickHouseなら、この規模でも問題なく捌けますよ」。調べました。その通りでした。ClickHouseは書き込みをバッチで処理し、列指向ストレージで集計クエリを桁違いに速く返します。最初からClickHouseを選んでいれば、この3ヶ月の苦労はありませんでした。と書いて、立ち止まります。分析は正しかったのです。「チームがPostgreSQLに慣れている」「運用ノウハウがある」。これは選定時の重要な判断基準でした。問題は分析の正確さではなく、前提の変化です。ユーザー数が8倍になるとは、誰も予測していませんでした。予測できなかった以上、どれだけ正確な分析も、この変化には対応できません。分析が正しかったことと、選択が正しかったことは、別の話です。分析は過去と現在のデータに基づきます。選択は未来に賭ける行為です。未来の前提が変われば、正しい分析に基づく選択が間違いになります。これが選択の本質的な難しさです。前回、方法の知識が課題認識を変えると書きました。しかし、いくら知識があっても、未来の前提変化は予測できません。だから、先に定義した「撤退判断」が要ります。あのとき私に足りなかったのは、「書き込みが秒間N件を超えたら、データストアを再選定する」という撤退ラインでした。選べば他を失います。正しく分析しても前提が変われば裏目に出ます。だから人は、選びません。「状況を見て判断する」と言います。「柔軟に対応する」と言います。「両方のいいとこ取りをする」と言います。全部、選んでいません。ここで反論が来ます。「90:10で配分すればいいじゃないか」と。Aに90%の時間を使い、Bにも10%残しておく。保険です。賢い選択に見えます。しかし、90:10は機能しない、と断言する前に、留保が1つあります。プロトタイプフェーズでは、80:20くらいのリソース配分で複数の選択肢を探索すべき場面もあります。選択肢を1つに絞る前に、最低限の検証をする期間は必要です。「100:0で選べ」が常に正しいわけではありません。選ぶ前の探索と、選んだ後の集中は、フェーズが違います。問題は、探索フェーズを永遠に続けることです。「まだ探索中です」と言い続けて、いつまでも選ばない。探索と先延ばしの区別がつかなくなります。探索フェーズを過ぎた後で、90:10が機能しない理由はいくつかあります。10%の保険があると、90%に全力が出ません。「うまくいかなければBがある」という逃げ道が、Aへの集中を妨げます。壁にぶつかったとき、「Bに切り替えるか」という判断が頭をよぎります。その判断にエネルギーを使います。本来Aに向けるべきエネルギーが漏れます。10%では何も得られません。週に4時間だけ量子コンピューティングを学んでも、表面をなぞるだけで終わります。本当に使えるようになるには、没入が必要です。10%の没入は矛盾です。そして、これが一番重要ですが、90:10は「いつ切り替えるか」の判断基準を生みません。100:0で選んでいれば、「Aがダメだったらどうするか」を事前に考えます。撤退ラインを決めます。「3ヶ月やって成果が出なければ、Bに完全切り替え」と決められます。しかし90:10だと、「Aがうまくいっていないな、でもまだBも並行しているし」と曖昧なまま続きます。Aを諦めるタイミングが定まりません。Bに本腰を入れるタイミングも定まりません。ずるずると両方を中途半端に続けて、どちらも成果が出ないまま半年が過ぎます。私はこれを何度もやりました。「Rustも書くけどGoも捨てない」で1年を費やしたことがあります。結果、どちらも「まあ書ける」レベルで止まりました。「Rustを極める」と決めた後の半年で、1年分以上の成長がありました。最初からRustに100:0で振っていれば、1年早く今の状態になれました。と、書きました。しかし、立ち止まります。GoとRustを並行した1年は、本当に無駄だったのでしょうか。Goのsync.Mutexを毎日書いていたから、RustのArc\u003cMutex\u003cT\u003e\u003eの意味が直感でわかった面はなかったか。Goの並行処理で実際にデータ競合を踏んだから、Rustの所有権が「なぜ必要か」を身体で理解できたのではないか。答えはわかりません。「100:0が正しかった」と言い切れる根拠は、実は持っていません。ただ、選ばずに過ごした1年に後悔の色が濃いのは事実です。たぶん、100:0の方がよかった。たぶん。100:0か0:100しかない、とは言いません。しかし、90:10は「両方選んでいる」のではなく「どちらも選んでいない」ことが多い。90:10の別名が「ハイブリッド」です。提案資料に「ハイブリッドアプローチ」と書くと、なぜか承認されやすい。AとBのいいとこ取り。両方の利点を享受できる。承認する側も「バランスの取れた判断だ」と言えます。全員が安心します。でも実際は、どちらの利点も中途半端にしか得られないことが多い。両方を選んだのではありません。どちらも選ばなかったのです。この「どちらも選ばない」構造は、個人だけの話ではありません。組織ではさらに深刻です。個人が90:10でリソースを分散させるように、組織は会議体で議題を分散させます。月曜は事業の話をします。水曜は技術の話をします。金曜は組織の話をします。きれいに分けています。効率的に見えます。でも、境界で情報が消えます。「この技術的制約があるから、この事業戦略は実行不可能だ」という前提。「機能を絞れば3ヶ月で出せる」という代替案。これは、どの会議の議題にもなりません。分けた瞬間に、最も大事な情報が抜け落ちるのです。実際に経験しました。開発チーム全員が「この設計では半年後に破綻する」と知っていた情報が、事業側に届いたのは破綻した後でした。技術の会議で話し、事業の会議では話さなかった。それだけのことです。私もこれを繰り返してきました。「AもBも大事だから、両方やる」と言い訳しました。結果、どちらも中途半端になりました。両方とも「やった」とは言えない状態で終わりました。選ばないことで、責任を回避しています。「Aを選んだから失敗した」と言われたくない。だから選びません。結果、何も決まりません。何も進みません。選択には根拠がいる「なんとなくこれ」は選択ではありません。選択には根拠がいります。「なぜAなのか」「なぜBではないのか」を言語化できなければ、選んだことになりません。根拠を言語化するためには、各選択肢の特性を理解している必要があります。Aの強みと弱み、Bの強みと弱み、それぞれがどんな状況で効果を発揮するか。だから「方法を学べ」が先に来ます。学んでいなければ、根拠のある選択はできません。しかし、学んだだけでは選べません。学ぶことと選ぶことの間には、別の壁があります。その壁の正体に気づいたのは、自分のKubernetes導入を振り返ったときでした。冒頭の3要素に照らすと、私の「評価」は根本から間違っていました。第1回で書いた話です。Kubernetesを導入した。技術ブログも書いた。しかし、デプロイ頻度は週1回のまま変わらなかった。スケーリングが必要な負荷もなかった。あのとき、私はKubernetesの「機能」を見ていました。コンテナオーケストレーション。オートスケーリング。自己修復。素晴らしい機能です。機能を評価し、機能に納得し、機能で選びました。しかし、導入後に何も変わりませんでした。機能は正しかった。選定プロセスに穴はなかった。では、何が間違っていたのか。「何ができるか」で選んでいた。「何を解きたいか」で選んでいなかった。技術選定で私たちが見ているのは、大抵「機能」です。この技術には何ができるか。どんな特徴があるか。ベンチマークでどれだけ速いか。比較表の列は機能で埋まります。しかし、機能は技術の側の話です。私たちの側の話、つまり目の前にどんな困りごとがあって、その困りごとを片付けるために何が必要かは、比較表のどこにもありません。私がKubernetesを導入したとき、目の前に「コンテナオーケストレーションで解くべき困りごと」は、実はありませんでした。デプロイ頻度は週1回で事足りていた。スケーリングの必要もなかった。では、なぜ導入したのか。正直に振り返ると、困りごとは技術的なものではありませんでした。「Kubernetes導入」をやった人間として転職市場に出たかった。そう書くと卑小に聞こえます。聞こえますが、エンジニアの技術選定の何割かは、この卑小な動機で動いています。私だけではないはずです。と書いて、立ち止まります。これを事後的に分析するのは簡単です。「あのときの私はキャリアの問題を技術選定にすり替えていた」と、今ならそう言えます。しかし、選定のその瞬間にそれが見えていたか。見えていませんでした。「技術的に必要だから導入する」と本気で信じていました。人は自分の動機を誤認します。特に、「すごい技術を使いたい」という欲求を、「この技術が課題を解決する」という合理性にすり替えます。当時の私に「それ、技術的に必要ないですよね」と指摘しても、否定したでしょう。機能の評価は正しかったのですから。機能の評価が正しいことと、その機能が必要であることは、別の話です。振り返って、構造が見えました。人はプロダクトを「買う」のではない。困りごとを片付けるために選ぶ。私はKubernetesを「買った」だけでした。困りごとが不在のまま、機能だけを見て導入した。だから何も変わらなかった。この経験から、私は技術選定の問いを変えました。「この技術は何ができるか」ではなく、「我々は今、何に困っていて、それを片付けるために何が必要か」。問いを変えた瞬間、比較表の意味が変わりました。PostgreSQLとClickHouseの機能比較ではなく、「秒間3,000件の書き込みとリアルタイム集計という困りごとを、どちらが片付けられるか」という評価になります。機能の多さは関係ありません。目の前の困りごとを片付けられるかどうかだけが基準です。しかし、先ほど書いた通り、困りごとの正体を見誤ります。「技術的に必要だ」と思い込んでいるとき、本当の困りごとは別の場所にあるかもしれません。だから、冒頭で書いた「宣言」が要ります。「私たちはこの困りごとを解くために、この技術を選ぶ」と書き出す。書き出すことで、「本当にそれが困りごとか？」と問い直す余地が生まれます。書かなければ、動機の誤認に気づかないまま走り続ける。たぶん。もう1つ重要なのは、技術が「不要になる」瞬間の話です。技術が棚に戻されるのは、困りごとをより上手く片付ける代替が現れたとき、あるいは困りごとそのものが消えたときです。jQueryが使われなくなったのは、ブラウザ間の差異吸収という困りごとが、ブラウザの標準化によって消えたからです。jQueryの機能が劣化したのではありません。解くべき問題がなくなった。私たちが技術を「捨てる」とき（これは次回の話になりますが）、それは技術が悪くなったからではなく、困りごとが変わったからです。選択の根拠は、覚悟だけでは足りません。「この技術で何を解くのか」が言語化できていなければ、覚悟は空回りします。覚悟の前に、困りごとの特定がいる。困りごとが明確なら、選択は半分終わっています。困りごとが明確になり、覚悟もある。それでも、選ぶためにはもう1つ必要な力があります。選んだ根拠を、他者に伝える力です。根拠を言語化する。選択を宣言する。これは「書く」能力を前提にしています。根拠を書く、と簡単に言いました。しかし、書くフォーマットがないと、人は書きません。書こうと思っても、何をどの粒度で書けばいいかわからない。私がそうでした。ADR（Architecture Decision Record、設計判断の記録）というフォーマットを知ったとき、「これだ」と思いました。設計判断こそがシステムの寿命を決めます。その判断を構造化して残す仕組みが、驚くほどシンプルだったのです。adr.github.ioコンテキスト（何が問題か）、決定（何を選んだか）、結果（何が起きるか）。この3つを短い文書で残します。テンプレートは以下の通りです。# ADR-XXXX: [タイトル]## ステータス提案 / 承認 / 廃止## コンテキスト[何が問題か。どんな状況か。どんな制約があるか]## 決定[何を選んだか。なぜ選んだか]## 結果[この決定によって何が起きるか。良い影響と悪い影響]たったこれだけです。しかし、この「これだけ」が、私の技術選定を根本から変えました。ADRを導入する前、技術選定の根拠はさまざまな場所に散らばっていました。Slackの会話ログ。PRの説明文。コードのコメント。Design Doc。誰かの頭の中。どれも根拠を残しているつもりでした。しかし、どれも十分に機能していませんでした。コードのコメントは、一見すると最も近い場所に根拠が残ります。// CockroachDBではなくPostgreSQLを採用。チームの習熟度を優先と書けます。しかし、リファクタリングでコードが消えれば、コメントも消えます。そもそも、コメントに書ける情報量では「なぜチームの習熟度を優先したのか」「他にどんな選択肢があったのか」「どんな条件が変わったら再検討すべきか」は伝わりません。PRの説明文には、もう少し詳しく書けます。しかし、技術選定の判断は複数のPRにまたがります。「データストアをPostgreSQLに決めた」PRと「スキーマを設計した」PRと「マイグレーションを実装した」PR。どのPRに選定の根拠が書いてあるか、半年後に探せるでしょうか。PRは「何を変えたか」を記録するものであって、「なぜそう決めたか」を記録するものではありません。Design Docは最も構造化された選択肢です。しかし、私の経験では、Design Docは「どう作るか」に重心が寄り、「なぜこの方法を選んだか」は1段落で済まされがちです。さらに、Design Docは設計が変わるたびに更新されます。更新されること自体は良いのですが、「当時の判断」が上書きされてしまう。ADRはappend-onlyです。過去の判断は変更せず、新しい判断を追記します。だから、「あのとき何を考えていたか」が残ります。Slackの会話ログは最も生々しい議論が残ります。しかし、膨大すぎて検索できません。半年後に「なぜこの技術を選んだのか」と聞かれたとき、誰も答えられなかった。頭の中の記憶は、半年で変質します。「たしかPostgreSQLの方がパフォーマンスが良かったから」。本当にそうだったか？ 当時のスレッドを掘り返すと、実際の理由は「チームにPostgreSQLの経験者が多かったから」でした。記憶は、事後的に合理化されます。ADRを書くようになって変わったことが2つあります。1つは、選定時の思考が明確になったこと。書こうとすると、「なんとなく良さそう」が通用しません。コンテキストを書く段階で、「そもそも何の問題を解こうとしているのか」が曖昧だったことに気づきます。もう1つは、撤退判断が楽になったこと。冒頭で定義した3要素の「撤退判断」を思い出してください。ADRに「この条件が変わったら再検討する」と書いておけば、半年後に状況が変わったとき、「当時の前提はこうだった。今は違う。だから選び直す」と言えます。感情ではなく、記録に基づいて判断できます。ただし、ADRにも限界はあります。書いた人間の解像度以上のことは書けません。データストアの選定でClickHouseの存在を知らなかった私が、いくら丁寧にADRを書いても、「ClickHouseという選択肢を検討しなかった」という事実は記録されません。知らないものは、検討できません。ADRは「選んだ理由」を構造化しますが、「選ばなかった理由」のうち「そもそも知らなかった」ものは記録から漏れます。これが前回書いた「方法の解像度が課題の解像度を決める」の、選択における現れです。ここまでエンジニアの文脈で書いてきましたが、「意思決定の根拠を構造化して残す」ことの価値は、エンジニアリングに限りません。プロダクトマネージャーの機能優先度の判断。デザイナーのUI選定。マーケティングのチャネル選択。営業の価格戦略。どの領域でも、「なぜこの選択をしたか」は半年後に消えます。ADRのフォーマットをそのまま使う必要はありません。先ほどのテンプレートのコンテキスト・決定・結果の3項目を、チームのWikiやNotionに1ページ書くだけで十分です。非エンジニアの方にも、意思決定の記録を書くことを勧めます。syu-m-5151.hatenablog.comlearning.oreilly.comここまで、根拠を「書く」ことの重要性を述べてきました。ADRにしても宣言にしても、前提になっているのは「書ける」ことです。書く能力は自然には身につきません。これもまた、「学ぶべき方法」の1つです。根拠を言語化できるようになりました。では、その根拠は何に基づくべきか。選択の基準は「課題」に帰るここまで、「選ぶとは捨てること」「根拠を言語化すること」を書いてきました。では、言語化された根拠は何に基づくべきか。課題です。「この課題を解くために、この手段が最適だ」。これが選択の根拠になります。ここで、話が一周します。課題が明確でなければ、手段は選べません。手段を学び、その上で課題に立ち返る。課題が、選択の基準を与えます。しかし、前回書いた通り、方法の解像度が課題の解像度を決めます。方法を知らなければ、課題を正しく認識できません。だから方法を学ぶ。循環しています。課題があるから方法を選ぶ。方法を知るから課題が見える。どちらが先でもありません。両方が必要です。鶏と卵のように見えますが、実際にはスパイラルです。課題を見て方法を学び、方法を学んで課題の解像度が上がり、解像度が上がった課題に対して方法を選ぶ。この繰り返しです。「で、どこから始めるんですか」という問いが残ります。厳密には始点がありません。でも、スパイラルに入る入口はあります。実際には人は何かから始めている。始めなければ動きません。私の経験では、始点は「違和感」です。何かがおかしい。何かがうまくいっていない。でも、何がおかしいかわからない。この漠然とした違和感が、スパイラルの入口になります。違和感を感じたら、まず「似たような状況で使われている方法」を探します。うまくいっている人は何をやっているのか。うまくいっている組織は何を採用しているのか。そこに方法のヒントがあります。方法を1つ学ぶ。すると、違和感が少しだけ言語化できます。「あ、これは〇〇の問題かもしれない」と言えるようになる。課題の解像度が上がります。解像度が上がると、「この方法では足りない」か「この方法で解ける」かが見えます。足りなければ、別の方法を学ぶ。解けそうなら、その方法を選ぶ。スパイラルの始点は、理論ではなく、違和感という身体感覚です。頭で考えて「どこから始めよう」と悩んでいても動けません。「なんかおかしい」という感覚に素直に従う方が、スパイラルは回り始めます。このスパイラルを、私が経験した具体例で図示します。「選択」がスパイラルを回す、という話です。認証基盤を設計したときのことです。最初の違和感は「ユーザー管理が散らばっている」でした。サービスごとに独自のログイン機構があります。パスワードポリシーもバラバラです。方法を探しました。OAuth2/OIDCを学びました。「認証を一箇所に集約すべきだ」という課題に変わりました。解像度が上がりました。次に、「集約する」方法を選ぶ段階で止まりました。自前で実装するか、OSSの認証サーバーを使うか、SaaSに任せるか。3日間RFCを読んで、自前で作ることの非合理性を理解しました。作れます。作れますが、これをプロダクション品質で検証し続けるのは、私たちの仕事ではありません。OSSのOry Hydraを選びました。「認証を集約する」が「IdPの運用を最小コストで維持する」という課題に変わりました。さらに解像度が上がりました。このスパイラルで重要だったのは、「選択によって課題が変わった」ことです。自前実装を選んでいたら、課題は「OAuthプロトコルの実装」になっていたでしょう。OSSを選んだことで、課題は「IdPの運用」に変わりました。選択が、次の課題を規定します。前回書いた「方法の解像度が課題の解像度を決める」の応用です。選択の解像度が、次の課題の解像度を決めます。もう1つ、スパイラルの例を書きます。こちらは選択を間違えた話です。最初の違和感は「アラートが多すぎる」でした。1日に200件以上のアラートが飛びます。ほとんどがノイズです。方法を探しました。アラートの閾値を調整しました。「閾値が不適切」が課題だと思いました。閾値を上げました。アラートは減りました。しかし、本当に対応すべきアラートも減りました。障害を見逃しました。次の違和感。「閾値の調整だけでは限界がある」。SLO（サービスの品質目標）ベースの監視を学びました。課題が変わりました。「アラートの閾値をいくつにするか」から「ユーザーに影響があるかどうか」に。エラーバジェット（許容されるエラーの残量）が消費されたときだけアラートを出す設計に変えました。アラートは1日10件以下になりました。すべてがアクション可能でした。ここでも選択がスパイラルを回しました。「閾値調整」を選び続けていたら、永遠に閾値をいじっていたでしょう。「SLOベース」を選んだことで、課題のレイヤーが変わりました。インフラの指標を見ていた目が、ユーザー体験を見る目に変わりました。前回書いた「課題がどのレイヤーにあるか見誤ると、いくら努力しても解決しない」。まさにあの構造です。閾値調整は「表示のレイヤー」で頑張っていたのと同じでした。SLOは「計測のレイヤー」を変える選択でした。2つのスパイラルに共通しているのは、どの例でも「この方法を選ぶ」という明確な意思決定があったことです。Ory Hydraを選びました。SLOベースの監視を選びました。スパイラルは、選択によって回ります。では、選択を確定させるために何が必要でしょうか。選んだら、宣言する選んだら、宣言します。「私はAを選ぶ。理由はこれだ」と、声に出します。文章に書きます。チームに共有します。宣言することで、選択が確定します。後から「やっぱりBだった」と言い訳できなくなります。これが怖い。だから人は宣言しません。「まだ検討中です」と言います。「もう少し情報を集めてから」と言います。「関係者と調整してから」と言います。いつまでも検討中のまま、時間だけが過ぎます。私にも覚えがあります。決められないまま、選択肢を並べて眺めていました。「どれがいいかな」と考え続けていました。Notionに選択肢を並べて、比較表を作って、色分けまでして、それを眺めていました。最終的に6列38行になりました。比較表の完成度だけが上がっていきました。あの時間、胃のあたりに鈍い重さがありました。選ぶ怖さが身体に溜まっていました。考えている間は、失敗しません。でも、成功もしません。前に進みません。宣言しないことは、一種の保険です。「まだ決めていないから、失敗してもしょうがない」と言えます。でも、その保険のコストは高い。時間です。機会です。信頼です。ただし、宣言の怖さは「しないこと」だけではありません。あるとき、「この設計でいく」と宣言しました。根拠はありました。分析もしました。しかし、前提が間違っていました。チームは私の宣言に従って2週間動きました。途中で「これ、おかしいかもしれない」と気づきました。ですが、自分が宣言した手前、撤回しにくかった。「やっぱり違った」と言えば、2週間の作業が無駄になります。私の判断力が疑われます。結局、言い出すまでにさらに1週間かかりました。宣言は確定力を持ちます。だからこそ、間違った宣言の破壊力も大きい。宣言しろ、と書きました。書きましたが、宣言した以上は、間違いに気づいたときに撤回する覚悟もセットで持つ必要があります。宣言の価値は「確定すること」にあります。しかし、「確定したから正しい」わけではありません。選択は責任を生む宣言すると、責任が発生します。「私がAを選んだ」という事実が残ります。Aで失敗したら、私の責任です。「Bにしておけばよかった」と後悔するかもしれない。でも、選んだのは私です。これを引き受ける覚悟がなければ、選択はできません。覚悟とは、失敗を受け入れる準備です。「Aを選んで失敗するかもしれない。でも、Aを選ぶ」。この態度が、選択を選択たらしめます。責任を取りたくないから選びません。選ばないから何も進みません。何も進まないから成果が出ません。成果が出ないことの責任は、誰も取りません。「みんなで決めたことだから」「状況が悪かったから」「情報が足りなかったから」。この構造が、組織を腐らせます。そして、その腐敗の一部は私です。選ばなかった私が、この停滞を作っていました。組織で選ぶことの難しさ個人なら、自分で選んで自分で責任を取れます。シンプルです。組織では、そうはいきません。「みんなで決めましょう」と言います。会議を開きます。意見を出し合います。「Aがいい」「Bがいい」「Cも捨てがたい」。議論は盛り上がります。でも結論が出ません。「次回また議論しましょう」。誰も選びません。誰も責任を取りません。合議制の罠です。全員が賛成する選択肢は、大抵、誰も反対しないだけの無難な選択です。角が取れて、特徴がなくなって、「まあ、これなら文句は出ないだろう」という選択肢。本当に必要な選択は、誰かが反対します。「リスクが高い」「前例がない」「うちのやり方じゃない」。だから選ばれません。無難な選択は、無難な結果しか生みません。飛躍しません。組織で選ぶためには、誰かが「私が決める」と宣言する必要があります。その人が責任を取ります。反対意見があっても、決めます。「私が決めた。結果は私が引き受ける」。これができるリーダーは少ないです。できるリーダーがいる組織は強いのです。「そんなリーダーがいない組織では、どうすればいいのか」という問いが残ります。答えは、自分がその役を引き受けることです。肩書きがなくても、「私が決めます」と言えます。言えば、責任が発生します。責任を引き受けることで、決定権が生まれます。権限が先ではありません。責任が先です。私は過去に、これを小さなスコープで始めました。「このタスクの技術選定は、私に任せてください」と言いました。成功すれば信頼が積み上がります。失敗すれば、責任を取ります。どちらにしても、「誰も決めない」より前に進みます。もう少し具体的なパターンを書いておきます。組織で「選ぶ」ために、私が使ってきた方法です。期限を切る。「来週の月曜までに決めましょう。それまでに決まらなければ、私の判断でAにします」と宣言します。反対意見がある人は、期限までに代替案を出す必要があります。出なければ、Aで決まり。期限がないと議論は永遠に続きます。期限を切ることで、選択が強制されます。実際にやったことがあります。「来週までに決まらなければ、Terraformにします」と宣言しました。期限が来ました。反対意見は出ませんでした。Terraformにしました。ただ、2ヶ月後、別のツールを推していたメンバーが静かにチームを離れました。反対意見が「出なかった」のではなく、「言えなかった」のだと後で知りました。そのメンバーの退職連絡を受けたとき、背中が冷たくなりました。私は「決断した」と思っていました。実際には、声の小さい人を踏みつけていただけでした。期限を切ることは、沈黙を合意と誤認するリスクがあります。可逆性で説得する。「この選択は可逆的です。2週間試して、ダメならBに戻せます。だから今すぐAを試しましょう」と言います。不可逆な選択は慎重になります。可逆なら、試す障壁が下がります。そして、ほとんどの選択は、思っているより可逆的です。もう1つ、使ってきた方法があります。小さく試して結果を見せる方法です。「全体に適用する前に、私のチームだけで試させてください」と言います。全体への影響を心配する人を説得できます。小さく試して結果を見せれば、「全体に広げていいか」の判断がしやすくなります。成功すれば横展開。失敗すれば、損害は最小限です。これらの方法は、機能します。機能しますが、万能ではありません。期限が沈黙を生むこともあります。「可逆的」と言ったものが実は不可逆だったこともあります。方法を知っていることと、方法がうまくいくことは、違います。それでも、何も選ばないよりは、はるかにましです。「選ばなかった」ことによる損失を、もう1つ書いておきます。技術的負債の返済を、チームとして2年間先送りにしました。コードベースの中に、もう誰も理解していないモジュールがありました。テストもありません。ドキュメントもありません。しかし、本番で動いています。「触らなければ壊れない」。それが暗黙の合意でした。返済するか、しないか。毎四半期の計画で議題に上がりました。毎回、「今期は新機能の優先度が高い」で先送りになりました。誰も「返済する」と宣言しませんでした。宣言すれば、新機能の遅延の責任を引き受けることになります。誰もその責任を取りたくありません。合理的な判断です。個人にとっては。2年後、そのモジュールに起因する本番障害が起きました。深夜3時。PagerDutyの音で目が覚めました。画面を開く前に、原因がわかりました。あのモジュールだ。知っていました。全員が知っていました。知っていて、2年間選ばなかった。影響を受けたユーザーは12,000人。復旧に6時間かかりました。原因を調査するだけで3日。コードを理解している人間が、もう社内にいなかったからです。障害報告書を書きながら、「2年前に返済していれば」と全員が思いました。しかし、2年前の自分に言えるでしょうか。「今期の新機能を止めて、誰も理解していないコードの書き直しに3ヶ月使います」と。当時の情報では、先送りは合理的に見えました。振り返って気づいたのは、私たちの思考のフレームが狭すぎたということです。「技術的負債を返済するか、新機能を作るか」という二択で考えていました。しかし、本当に二択だったのか。「新機能の一部を、負債の返済を兼ねた設計で作る」という選択肢がありました。「3人のうち1人を負債返済に専任させる」という選択肢もありました。二択に見えていたものは、フレームが狭かっただけです。組織で選べないとき、選択肢が2つしか見えていないなら、3つ目がある。私はそう思っています。3つ目が見つかった時点で、議論の質が変わります。「AかBか」の対立が、「A、B、Cのどれが最も合理的か」という評価に変わります。これは冒頭の3要素の「評価」の質を上げる方法でもあります。全体を変えることはできません。でも、自分の周囲半径3メートルは変えられます。そこから始めます。正解を求めると、選べないここまで、「選ぶとは捨てること」「根拠を言語化すること」「組織で選ぶ難しさ」を書いてきました。しかし、選択を阻む最も根深い罠にまだ触れていません。正解を求めること。そして、これがこの記事で一番言いたいことかもしれません。エンジニアは「正しさ」を職業的に追求する人種です。コードには正解があります。テストに正解があります。パフォーマンスに正解があります。計測すれば、どちらが速いかわかります。ベンチマークを取れば、どちらが優れているか数字で出ます。この「正しさを情報で特定できる」という成功体験が、選択の場面にも持ち込まれます。「もっと調べれば、正しい選択がわかるはず」。しかし、コードの正しさと選択の正しさは、構造がまったく異なります。コードの正しさは、実行すれば検証できます。テストが通るか通らないか。レスポンスタイムが要件を満たすか満たさないか。答えがある問題です。選択の正しさは、未来にしか検証できません。そして、選ばなかった選択肢の結果は永遠にわからない。Aを選んだとき、Bを選んでいたらどうなっていたかは、誰にも検証できません。反実仮想は実行できないテストです。つまり、選択には正解がありません。正確に言えば、「事前に正解を特定する方法」がない。にもかかわらず、エンジニアは「もう少し調べれば正解がわかる」と信じています。技術的な問題解決で鍛えた「情報→正解」のパイプラインを、選択というまったく別の種類の問題に適用しています。これが、エンジニアが選択で最もハマる罠です。「どれが正解か」と考え始めると、選べなくなります。正解は、事前にはわからない。やってみないとわかりません。未来は予測できません。選択の時点では、どれも「仮説」です。正解を求めて情報を集め続けます。「もう少し調べれば、正解がわかるはず」。わかりません。いくら調べても、正解は見えません。見えないまま、時間だけが過ぎます。情報収集が目的化します。Slackで意見を聞き、ドキュメントを読み、専門家に相談し、それでも決められません。私は先ほど、2週間かけてデータベースの比較表を作った話を書きました。あの2週間で私が得たものを正直に振り返ると、「どれも一長一短だ」という確信だけです。1日目の直感と14日目の結論は、ほとんど同じでした。13日分の情報収集が変えたのは、選択の質ではなく、私の不安の深さでした。最終日の夜のことを、今でも覚えています。14日目の夜、スプレッドシートを閉じようとして、手が止まりました。閉じたら、次は選ばなければなりません。知れば知るほど各選択肢の弱点が見えます。弱点が見えるほど、「この弱点が致命的だったらどうしよう」と怖くなります。情報は不安を解消するために集めたはずでした。しかし、情報が不安を増幅していました。ある時期、この構造を外から眺められるようになりました。知性が高い人間ほど、結論を先に持ち、その結論を支持する証拠だけを精巧に集める。そういう罠に陥りやすい。私の場合、「選ばない」という結論が先にあり、その結論を正当化するために比較表を精緻にしていた。弱点が見つかるたびに「まだ選べない」が補強される。知性が、選択回避を完璧に合理化します。もう1つ、身に覚えのある構造がありました。専門性を積んだ人間は、「自分は十分に調べたから、この判断の遅さは慎重さだ」と信じます。しかし、慎重さと回避は違います。私が2週間かけて作った比較表は、慎重さの産物ではなく、「自分は十分に調べた」という専門家の自信が生んだ精巧な言い訳でした。ここに構造がある。知性そのものが諸刃の剣なのです。分析力が高いほど、バイアスを自分から隠す能力も高い。比較表を見せたとき、同僚は「すごい調査だ」と言いました。褒められました。褒められたことで、比較表が選択回避の道具であることにさらに気づきにくくなった。精度が高いほど、周囲が肯定する。肯定されるほど、止められない。ここに「情報信仰」の構造があります。情報を集める→弱点が見える→不安が増す→さらに情報を集める→さらに弱点が見える。ループです。出口がない。このループに入った人間は、外から見ると「慎重に分析している」ように見えます。本人も「十分な調査をしている」と思っている。しかし実態は、情報収集を鎮痛剤として使っているだけです。痛みの原因、「選ぶことへの恐怖」には一切手を付けていません。振り返ると、私の2週間は「悪い戦略」の典型でした。空疎な言葉で埋まった比較表。課題の回避。目標と戦略の混同。「最適なデータベースを選ぶ」は目標であって戦略ではない。戦略は「何が本当の困りごとか」を直視することから始まります。私は直視しなかった。データは精緻だが、診断が不在でした。と書いたが、誰も自分の戦略を「悪い戦略だ」とは思いません。思えるなら、最初からやらない。心理と構造が、ここで合流します。知性が回避を合理化し、合理化された回避が「戦略」の顔をして居座る。ただし、十分な分析をせずに選ぶのは蛮勇です。どこまで分析して、どこから決断なのか。その境界は明確ではありません。私の現時点での仮説はこうです。「新しい情報を1つ得ても、選択が変わらないと感じた時点」が境界です。最初の1日で得た情報は、選択を大きく左右します。3日目に得た情報は、選択を微調整する。5日目に得た情報は、もう選択に影響しません。影響しないのに情報を集め続けているなら、それは分析ではなく、決断の先延ばしです。もう1つ基準があります。「情報を集めている自分」に安心感を覚え始めたら危険信号です。調査している間は選んでいない。選んでいない間は失敗しない。失敗しないことに安心している。「調べている」という行為が「選ばない」ことの免罪符になっています。忙しく調査しているから、サボっているようには見えません。自分にも周囲にも。しかし、選んでいないという事実は変わりません。選択とは、不確実性の中で決断することです。 正解がわかってから決めるのは、選択ではありません。答え合わせです。リスクを取らない選択は、選択ではありません。「どちらを選んでも同じ結果になる」なら、選ぶ必要はない。選択が意味を持つのは、結果が異なる可能性があるからです。つまり、選択には必ずリスクが伴います。選んだ後にすること選びました。宣言しました。責任を引き受けました。その後、何をするか。全力でやります。ただし、全力とは長時間働くことではありません。迷いを消すことです。選んだ後にやることは、大きく3つあります。また3つに分けている。もはや習性です。迷いを消して1つに集中すること、集中しながら自分を観ること、そして失敗から学ぶこと。どれも、選ばなかった時期には手に入らなかったものです。迷いを消して1つに集中し続けると、何が起きるか。ある変化が訪れます。無意識化です。最初は意識的にやります。「Rustで書く」と決めて、1つ1つ考えながらやります。ぎこちない。遅い。コンパイラに怒られます。エラーメッセージを読みます。直します。別の場所で怒られます。続けていると、考えなくなります。手が勝手に動きます。借用チェッカーをどう通すかが、判断ではなく反射になります。あの瞬間のことは覚えています。あるとき、所有権のエラーを見た瞬間に「ああ、ここはCloneじゃなくて参照を渡すべきだ」と手が動きました。考えていませんでした。指が先に答えを知っていました。ただし、その指が間違えることもあります。先日、無意識に.unwrap()を書いて、レビューで指摘されました。身体化された悪い癖も、無意識化されます。そこまで行くと、その上に新しい層を積めます。言語の文法を考えなくていいから、アーキテクチャを考える余裕ができます。選ばずに複数の言語を並行していると、この無意識化が起きません。どれも「意識的にやる」段階で止まります。どの言語でも、ドキュメントを見ながら書いています。無意識化されなければ、その上に何も積めません。だから、選ぶことには意味があります。選ぶことで、初めて次の段階に進めます。無意識化は、言語や技術に限った話ではありません。技術選定の判断そのものも、無意識化されます。最初の頃、技術選定のたびに膨大な時間をかけていました。比較表を作り、ベンチマークを取り、チームで議論し、上長に説明する。1つの選定に2週間かかりました。しかし、同じ種類の選定を10回もやると、判断のパターンが身につきます。「この規模なら、このデータストアで問題ない」「このチーム構成なら、この言語が適切だ」。考える前に方向性が見えます。2週間かかっていた選定が、2日で終わるようになります。判断が速いのではありません。迷わないから速いのです。ただし、パターンが身についた結果、パターンの外にある問題を見落としたこともあります。「この規模ならPostgreSQLで十分」と即断した案件で、実はデータの保持要件が特殊で、パターン通りでは対応できませんでした。判断が速いことと、判断が正しいことは、別の話です。障害対応でも同じことが起きます。最初は、障害が起きるたびにパニックになりました。何を見ればいいかわかりません。手当たり次第にログを読みます。仮説を立てるどころではありません。しかし、50回も障害対応をすると、「まずエラーレートの変化点を見る。次にデプロイ履歴を確認する。直近のデプロイがなければ、外部依存を疑う」というフローが、考えなくても動きます。これが無意識化です。前回書いた「操作→分解→判断」の3層が、すべて身体化された状態です。そして、この無意識化が「選ぶ」行為そのものに適用されたとき、選択の型が身につきます。「この状況では、まず可逆性を確認する」「この規模では、まず最小スコープで検証する」「この政治的状況では、まず期限を切る」。冒頭で定義した評価・宣言・撤退の3要素が、意識しなくても回るようになります。そこまでいけば、選択のコストは劇的に下がります。選択のコストが下がれば、選択を恐れなくなります。恐れなくなれば、動けます。ただし、ここにも留保があります。パターンが適用できる範囲内では、選択のコストは低いままです。しかし、パターンの外に出たとき、たとえば初めて触る技術領域や経験のない規模の問題に直面したとき、選択のコストはまた上がります。新しい領域に踏み出すたびに、人は途上に戻ります。選び直して、また深めます。その繰り返しです。組織でも同じことが起きます。チームが「この構成なら問題ない」というパターンを身につけた。そのパターンの外に出る判断を先延ばしにした結果、技術的負債が積み上がり、結局スピードも失うケースを何度も見てきました。パターンが通用しなくなった兆候を感じながら、「まだ大丈夫」と言い続ける。これも、選択の先延ばしです。全力でやりながら、同時に自分を観る必要があります。障害対応中、熟練のSREは「今、自分が何をしているか」を言語化できます。ログを追いながら、「この仮説は検証できた」「次はネットワーク層を見るべきだ」「今、自分は確証バイアスに引っ張られている」と把握しています。対応しながら、自分の思考プロセスを見ています。最初は、目の前のエラーを追うだけで精一杯です。自分が何を調べているかなんて意識できません。がむしゃらにログを読んで、気づいたら3時間経っています。しかし、ある程度の経験を積むと、対応しながら自分を観察できるようになります。「今、焦っている」「この仮説に固執しすぎている」「別のアプローチを試すべきだ」と気づけます。気づけるから、修正できます。コードを書くときも同じです。書きながら、「今、何を考えているか」を意識します。「この設計判断は、何を根拠にしているか」「この実装は、どんなトレードオフを選んでいるか」。書きながら、自分の思考を観ます。没入と観察は矛盾するように見えます。全力で没入しているのに、同時に冷静に観察します。しかし、この二重性が、選んだ後の成長を加速させます。データベースのマイグレーションを始めた瞬間を思い出します。本番環境でスキーマ変更を流し始めました。その途中で「やっぱりNoSQLに移行した方がよかったかも」と迷ったらどうなるか。判断が鈍ります。中途半端なスキーマが残ります。マイグレーションを始めたら、最後までやり切ります。うまくいかなければ、ロールバックして学びます。途中で方針を変えるのが、一番まずいのです。選んだ以上、その選択を正解にするために動きます。「Aを選んだけど、Bの方がよかったかも」と迷いながらやっても、成果は出ません。迷いがエネルギーを分散させます。「でも、迷いは消えないじゃないか」という反論が来ます。その通りです。消えません。しかし、迷いに従う必要はありません。感情と行動は別です。迷いが湧いたとき、私は選んだ理由を読み返します。感情ではなく理由で判断する。ただ、もっと構造的な対処法があります。もう1つ、迷いへの対処法があります。あるとき、同僚の技術選定の相談に乗りました。私と似た状況でした。2つの選択肢で迷っている。しかし、他人の問題として見た瞬間、答えは明確でした。「それ、Aでしょ。理由はこれとこれ」。5分で言い切りました。帰り道に気づきました。私が自分の問題では2週間迷っていたのと、同じ構造の問題だ。他人の問題として見たら5分で答えが出た。人は他者の問題には冷静で的確な助言ができるのに、自分の問題になると判断を誤る。以来、私は選択後の迷いに応用しています。「もしチームメイトが同じ選択で迷っていたら、私は何と言うか」と問い直す。すると、感情的な迷いが消えて、評価の軸だけが残ります。自分の問題を他人の問題として眺めるだけで、判断の質が変わる。不思議ですが、再現性があります。これは生まれ持った知恵ではなく、訓練可能なスキルです。私は月に2回ほど、意識的にこの「他人の目」を使っています。Aを選んだなら、Aに全力を注ぎます。Aの可能性を最大限に引き出します。Aでできる限りのことをやり切ります。それでも失敗したら、学びます。「Aではダメだった。この条件ではAは機能しない。次はBを試す」。選択→実行→学習→選択。このサイクルを回します。迷いながら中途半端にやるより、選んで全力でやって失敗する方が、学びは大きいです。失敗から学ぶためには、全力でやる必要があります。中途半端にやって失敗しても、「全力でやれば成功したかも」という言い訳が残ります。全力でやって失敗すれば、「この方法ではダメだ」という確実な学びが得られます。「学びが大きい」とは、具体的にどういうことか。全力で失敗したとき、得られるものがあります。1つは、境界条件の特定です。「この方法は、この条件では機能しない」という知識。Rustで並行処理を書いて、所有権の壁にぶつかりました。「RefCellの乱用はデッドロックを招く」という境界を学びました。中途半端に書いていたら、「なんか動かない」で終わっていたでしょう。もう1つは、失敗パターンの言語化です。次に同じ罠に落ちそうになったとき、事前に気づけます。「ああ、これは前にハマったパターンだ」と言えます。何度も同じ種類のデプロイ障害を起こしました。ようやく「この構成でブルーグリーンデプロイをやると、コネクションプールが必ず枯渇する」と学びました。中途半端に対症療法を繰り返していたら、いつまでも同じ障害に見舞われていたでしょう。さらに、撤退判断の精度が上がります。次の選択で「どこまでやったら撤退すべきか」の判断が速くなります。全力でやって3ヶ月で限界が見えた経験があれば、次は1ヶ月で「あ、これは前と同じパターンだ」と気づけます。中途半端にだらだら続けた経験からは、この感覚が育ちません。感情的な成長ではありません。認知的なツールの獲得です。「失敗から学ぶ」という言葉は、慰めに聞こえることがあります。失敗したときに自分を納得させるための言い訳に聞こえます。しかし、私がここで言いたいのは、もっと積極的なことです。失敗は、投資です。 将来のリターンを得るために、今コストを払っています。と書いたが、これは失敗した人間が事後的に自分を慰める言説と、どこが違うのか。違いは1つだけあるはずです。慰めは過去を正当化して終わる。投資は次の行動を変える。変わったかどうかは、本人にしかわかりません。新しい言語を学ぶとき、最初はバグだらけのコードを書きます。コンパイラに怒られます。実行時エラーが出ます。その1つ1つが、「この言語ではこれをやってはいけない」という知識になります。バグを出さなければ、その知識は得られません。だから、学習段階では、意図的に失敗しにいく価値があります。「これ、たぶん動かないだろうな」と思いながら書いて、案の定動きません。そこで「なぜ動かないか」を調べます。その調査が、理解を深めます。失敗を避けようとすると、学びが浅くなります。安全な範囲でしかコードを書きません。ドキュメントに書いてあることしかやりません。境界条件を踏みません。結果、「動くコード」は書けますが、「なぜ動くか」がわからないままになります。ただし、ここに1つ注意があります。「全力でやって失敗する」は、「再起不能になる」とは違います。全力と無謀は異なります。選択にはリスクがあります。リスクを取ることが選択の本質だと書きました。しかし、取るべきリスクには上限があります。その上限は「失敗しても次の選択ができる」ことです。会社を辞めて起業します。失敗しても、また就職すればいい。これは取れるリスクです。全財産を借金で溶かし、人間関係も破壊します。これは取ってはいけないリスクです。次の選択ができなくなります。私はこれを「致命的でない失敗」と呼んでいます。選択→実行→学習→選択のサイクルを回すためには、サイクルが止まる失敗を避ける必要があります。全力を出しますが、致命傷は負いません。このバランスが難しい。私の場合、「致命的でない失敗」の閾値がやや高めに設定されている自覚はあります。深夜3時の障害対応を「いい経験だった」と言える程度には。ただし、これは「次がある」環境にいるから言えることです。スタートアップで資金が3ヶ月分しかないとき、同じ閾値は使えません。環境が閾値を決めます。難しいですが、判断基準はあります。「この選択が失敗したら、次に何ができるか」を事前に考えておくことです。次の選択肢が思いつかないなら、それは無謀です。思いつくなら、リスクは取れます。「選ぶ」とAI時代ここまで書いてきた「選ぶ」の構造、つまり評価・宣言・撤退は、AI時代にどう変わるのか。前回、AI時代にも「方法を学ぶ意味がある」と書きました。AIは方法を知っていますが、違和感を持てません。では、「選ぶ」についてはどうでしょうか。AIは選択肢を提示してくれます。「RustとGoのどちらが適切か」と聞けば、条件次第でどちらも推薦してくれます。比較表も作ってくれます。それぞれの長所と短所を、私が2週間かけて作った比較表より正確に、10秒で出力します。あの2週間を返してほしい、とは思いませんでした。思わなかったことに、少し驚きました。実際にやりました。先月、あるマイクロサービスの言語選定でAIに相談しました。チームの構成、既存のコードベース、パフォーマンス要件、運用体制。条件を全部伝えました。返ってきた推奨は、私が2日かけて到達した結論とほぼ同じでした。しかし、その推奨を見て「よし、これで決まりだ」とは思いませんでした。正しそうに見えました。正しそうに見えたのに、宣言する気にならなかった。口に出そうとして、喉の奥で言葉が止まりました。「AIがそう言ったから」では、チームの前で宣言できません。正確には、宣言はできます。ただ、「失敗したときに私が責任を取る」と言えません。推奨の根拠はAIのものであって、私のものではないからです。結局、AIの推奨を参考にしつつ、自分で分析をやり直しました。結論は同じでした。それでも、「自分の分析に基づいて選んだ」と言えるようになりました。非効率です。非効率ですが、宣言と責任は、効率の外にあります。ただ、AIには「選べません」。そしてここに、「情報があれば正しく選べる」という信仰への最終的な反証があります。AIは人間が2週間かけて集める情報を10秒で提供します。情報の非対称性は事実上消滅しました。それでも、人は選べない。ということは、選べなかった原因は最初から情報の不足ではなかったのです。情報は必要条件かもしれません。しかし十分条件ではない。あの2週間の比較表が、すでにそれを証明していました。情報の先にある「宣言」と「責任」と「撤退判断」。これは情報からは導出できません。「この組織で、この時期に、このメンバーで、どちらを選ぶか」。これはAIには決められません。組織のメンバーがGoに慣れていること。来月リードエンジニアが退職すること。半年後にサービスの規模が10倍になる予定であること。社内政治的に、新しい技術を導入すると反発する人がいること。これらの文脈は、AIのプロンプトに全部書けるでしょうか。書けたとしても、それぞれの重みづけは誰がするのか。選択のコンテキストは、その場にいる人間にしかありません。しかし、「選択は人間にしかできない」と言い切るのも安易です。AIが文脈を理解する精度は急速に上がっています。5年後には、組織の状況をAIに伝えて、「どの技術を選ぶべきか」を聞けるようになるかもしれません。そのとき、「宣言は人間の仕事だ」と書いたこの記事は、古くなるかもしれません。もっと足元を揺さぶる問題もあります。LLM時代の技術選定には、従来にはなかった問いが加わります。「次のモデルが出たら、この判断は無意味にならないか」。選定の前提そのものが、プロジェクトの途中で変わりえます。これは「情報信仰」とは別種の罠を生みます。「もう少し待てば、より良い選択肢が現れる」。待つことが合理的に見えます。しかし、「待つ」もまた、選ばないことの変種です。私たちがたどり着いたルールはこうです。「現在のモデルの能力で判断する。ただし、撤退ラインに『次のモデルで再評価する』を含める」。今のモデルで目の前の困りごとを片付けられるかどうかで選びます。選んだ上で、次のモデルが出たときに「この困りごとは、まだ人間が解くべきか」を問い直す。選択を固定するのではなく、選択のサイクルを速く回します。これは冒頭で定義した「撤退判断」の応用です。従来の撤退ラインは「この方法がうまくいかなかったら撤退する」でした。LLM時代の撤退ラインは「この方法が不要になったら撤退する」です。失敗ではなく、陳腐化です。前回書いた、VMの最適化に半年を費やした話と同じ構造がここにあります。あのときは半年で気づきました。LLMの進化速度では、3ヶ月で同じことが起きえます。方法が失敗するより、成功したまま無意味になる方が怖いのです。しかし、仮にそうなっても、1つだけ残るものがあります。選択の責任を引き受けることです。AIが「Rustを推奨します」と言いました。採用しました。失敗しました。誰の責任でしょうか。AIの責任にはできません。AIは推奨しただけです。選んだのは人間です。前回、「AIの出力の質は、使う人間の力量で天井が決まる」と書きました。今回の文脈で言い換えると、AIの推奨の価値は、選択の責任を引き受ける人間の覚悟で決まります。覚悟のない人間がAIの推奨を採用しても、失敗したときに「AIがそう言ったから」で終わります。学びがありません。覚悟のある人間は、AIの推奨を自分の判断として引き受けます。だから失敗しても、「なぜ失敗したか」を掘り下げます。撤退判断を行い、次の選択を磨きます。AI時代の「選ぶ」は、評価のフェーズではAIの力を借り、宣言と撤退判断のフェーズでは人間が引き受けます。冒頭で定義した3要素の重心が、AIの登場によって「宣言」と「撤退判断」に移りました。評価はAIに任せられます。しかし、宣言と撤退は、依然として人間の仕事です。方法を選ぶことが、Whyを確定させる前回、「方法の探求は課題の発見につながっている」と書きました。課題とは、言い換えれば「Why、なぜこれを解くのか」です。方法を学ぶことで、新しい課題が見えてきます。今回は、その先にある「選ぶ」ことについて書きました。学んだだけでは動けません。選ばなければ、何も始まらない。選ぶとは、他を捨てることです。宣言することです。責任を引き受けることです。そして、選ぶことで初めて、課題が確定します。「この課題を、この方法で解く」。この宣言が、曖昧だった課題を具体化します。選択が、問いを鋭くする。「なんとなく困っている」が、「この問題を、この方法で解決する」に変わります。方法を選ぶことが、Whyを確定させます。「もっと調べれば選べる」は嘘です。正確に言えば、ある地点までは本当で、そこから先は嘘になる。その地点を過ぎたら、比較表を閉じてください。情報は十分にあります。足りないのは情報ではありません。覚悟です。前回、「自分が『仕方ない』と思っているものを3つ書き出せ」と書きました。今回は、その先です。正直に書くと、私にも先送りにしている選択がある。「もう少し情報が集まってから決める」と自分に言い聞かせて、3ヶ月以上動いていない判断がある。この記事を書きながら、気づいた。選べと書いている本人が、選んでいなかった。書き出そうとした。3行で書けなかった。書けないことが答えだった。それでも書いた。3行になるまで削った。削る過程で気づいた。本当に怖いのは「選ぶこと」ではなく、「選んだ自分が間違っていたと知ること」だった。「なぜAを選ぶのか」「なぜBではないのか」「いつまでに判断するのか」。3行で書けるかどうかが、評価が足りているかどうかの判断基準になります。3行で書けないなら、まだ評価が足りないか、あるいは、書けないことを理由に先送りしているだけです。と書いて、立ち止まります。冒頭で「選べ」と書きました。しかし、選ぶためには「選ばなかった選択肢を手放す余裕」が必要です。1つの言語に集中する時間がある。撤退ラインまで試す猶予がある。失敗しても次がある。それは環境の話でもあります。明日の締め切りに追われている人に「100:0で選べ」と言えるでしょうか。言えるとしたら、それは時間の余裕がある側の傲慢かもしれません。前回と同じ構造です。「課題から入れ」が呪いになるように、「方法を選べ」もまた、選ぶ余裕がない人への呪いになりえます。それでも書きます。選べる状況にあるのに選ばないのは、もったいないからです。PRの変更差分は、まだ開いたままだった。レビューコメントを1つ書いた。書きながら、「この方法で指摘するのが正しいのか」と考えていた。たぶん、正しいかどうかは、選んでからでないとわからない。おい、方法を選べ。参考資料Facilitating Software Architecture: Empowering Teams to Make Architectural Decisions (English Edition)作者:Harmel-Law, AndrewO'Reilly MediaAmazon戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon戦略「脳」を鍛える―ＢＣＧ流 戦略発想の技術作者:御立 尚資東洋経済新報社Amazon君は戦略を立てることができるか 視点と考え方を実感する４時間作者:音部大輔宣伝会議Amazon戦略コンサルタントが大事にしている 目的ドリブンの思考法作者:望月 安迪AudibleAmazon選択の科学 コロンビア大学ビジネススクール特別講義 (文春文庫 S 13-1)作者:シーナ アイエンガー文藝春秋AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonジョブ理論　イノベーションを予測可能にする消費のメカニズム作者:クレイトン・Ｍ・クリステンセンHarperCollins Children's BooksAmazonブルシット・ジョブ　クソどうでもいい仕事の理論作者:デヴィッド グレーバー岩波書店Amazonイノベーションのジレンマ 増補改訂版 Harvard business school press作者:Clayton M. Christensen翔泳社AmazonRelease It! 本番用ソフトウェア製品の設計とデプロイのために作者:Michael T. Nygardオーム社Amazon知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazonシン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon知性の限界　不可測性・不確実性・不可知性 限界シリーズ (講談社現代新書)作者:高橋昌一郎講談社Amazon","isoDate":"2026-02-17T02:53:06.000Z","dateMiliSeconds":1771296786000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude CodeのPLAN MODEは使ったほうがいい","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/13/122228","contentSnippet":"Claude Codeを使い始めて、様々な発信をしてきました。今回は「PLAN MODE」と「パーミッションモード」について。Claude Codeには複数の動作モードがあり、これを使い分けられるかどうかで出力品質が劇的に変わります。Claude Code の settings.json は設定した方がいい - じゃあ、おうちで学べるClaude Code の CLAUDE.mdは設定した方がいい - じゃあ、おうちで学べるClaude Code の .claude/commands/**.md は設定した方がいい - じゃあ、おうちで学べるClaude CodeのHooksは設定したほうがいい - じゃあ、おうちで学べるClaude CodeのSubagentsは設定したほうがいい - じゃあ、おうちで学べるClaude Codeの Agent Skills は設定したほうがいい - じゃあ、おうちで学べるはじめに「この機能を実装して」。Claude Codeにそう言って、Enter を押す。Claude は即座にファイルを読み、コードを書き始める。5分後、20ファイルが変更されている。ビルドは通る。テストも通る。しかし見返してみると、設計意図と違う。やり直し。また5分。今度は別の方向にずれている。こういう経験、ありませんか。私自身、Rustプロジェクトの認証モジュールのリファクタリングをClaude Codeに任せたとき、まさにこの罠にはまりました。「OAuth2対応して」と言ったら、既存のセッション管理を全部書き換え始めた。後方互換性は？DBマイグレーションは？聞いてもいないのに勝手にやってくれる。やり直し。2回目も方向性がずれる。3回目でようやく「まず計画を立てよう」と思い至りました。この問題の根本にあるのは、「考える」と「実行する」を同時にやらせていることです。人間のエンジニアだって、設計書なしにいきなりコーディングすれば事故が起きます。「え、何作ってんの？」と聞かれた経験があるのは私だけではないはずです。Claude Codeも同じです。LLMは与えられたタスクを「前に進める」ことに最適化されています。立ち止まって全体を俯瞰することは、明示的に指示しない限りやりません。そして、もう一つの問題はパーミッションの確認地獄です。Normal Modeでは、mkdirひとつ、git statusひとつに対しても確認ダイアログが出ます。これはセキュリティ上は正しい。しかし、複雑なタスクで20回、30回と「Allow」を押し続けるのは、ワークフローの断絶そのものです。コーヒーを取りに行って戻ってきたら、ステップ2で止まっている。あるあるです。Claude Codeはこの2つの問題に対して、段階的なパーミッションモードを用意しています。PLAN MODEで「考える」と「実行する」を分離し、CLAUDE.mdやRulesで品質の枠組みを整え、最終的に--dangerously-skip-permissionsで自律実行させる。この段階的なアプローチが、私が最近たどり着いたワークフローです。ただし、ここで強調しておきたいことがあります。設定を1行書くたびに、Claudeの手綱が1段緩められる。 CLAUDE.mdとRulesが未整備なら、PLAN MODEで人間が計画をレビューすることが唯一の品質保証手段になる。逆に、CLAUDE.mdとRulesを丁寧に整備すればするほど、Claudeへの信頼度が上がり、最終的には--dangerously-skip-permissionsでの自律実行まで到達できる。ガードレールの精度が、委任できる範囲を決める。前回の記事で紹介したAgent Skillsが「専門知識の注入」だとすれば、PLAN MODEは「思考プロセスの制御」、Rulesは「行動の制約」、そしてパーミッション設定は「自律性のコントロール」です。この4つは独立して機能するものではなく、掛け算で効く。 1つが欠けると、他の3つの効果も減衰します。code.claude.comcode.claude.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。他の設定・機能との位置づけ今まで紹介してきた機能にPLAN MODE、Rules、パーミッションモードを加えて、改めて整理します。 機能                    役割                            例                                            CLAUDE.md           プロジェクトのグローバルな文脈  「うちはRustで、こういうアーキテクチャ」      Rules               関心事ごとのルール適用      セキュリティ、テスト、Git規約など         commands            手動で呼び出すショートカット    /test-and-commit で一連の作業を実行         Hooks               特定のイベントで自動実行        ファイル保存後に自動フォーマット              Subagents           専門家を自動で呼び出す          デバッグ時にdebugger subagentが起動           Agent Skills        専門知識をオンボーディング      PDF操作、独自ワークフロー                     PLAN MODE           思考と実行を分離する        設計レビュー → 承認 → 実装                パーミッション設定  自律性のレベルを制御        Normal → Auto-Accept → YOLO              この表を見ていて気づくのは、上6行と下2行の性質の違いです。CLAUDE.mdからSkillsまでは「何を伝えるか」——つまり知識の問題です。PLAN MODEとパーミッション設定は違う。「どう振る舞わせるか」の問題です。 入力を整えるのと、出力を制御するのとでは、アプローチがまったく異なります。前者をいくら積み上げても、後者の代わりにはならない。Rulesは、両者の境界に位置する存在です。「知識」として読み込まれながら、実質的には「行動制約」として機能する。CLAUDE.mdと同じ「高優先度」でロードされながら、関心事ごとにファイルを分離できる。Rulesの質がそのまま自律実行の安全性を決める。 正直に言えば、CLAUDE.mdの整備に時間をかけていた初期の私は、このRulesの重要性を完全に見落としていました。CLAUDE.mdのリファクタリングとRulesの整備PLAN MODEの話に入る前に、避けて通れない前提があります。CLAUDE.mdとRulesの整備です。ここが雑だと、どんなモードを使っても意味がない。道具の使い方以前に、道具を使う土台の問題です。モノリシックなCLAUDE.mdの問題正直に告白すると、私のCLAUDE.mdも一時期500行を超えていました。最初は「ビルドはcargo fmtから」くらいだったのが、使い込むうちにあらゆる規約を書き足していく。APIの設計指針、テストの規約、セキュリティ要件、デプロイ手順。気づけば、プロジェクトの全知識を一つのファイルに詰め込んでいた。問題の本質は「注意の希釈」です。 CLAUDE.mdはセッション開始時に全文がロードされます。バックエンドのAPIを修正しているのにフロントエンドのCSS規約も読み込まれる。前回の記事で説明したProgressive Disclosure（段階的開示）の真逆です。人間に例えるなら、料理をしようとしている人に家中のマニュアルを全部渡すようなもの。情報が多いほど、個々の指示の「重み」が希釈される。500行の中に埋もれた「unwrap()は禁止」の1行を、Claudeが確実に拾ってくれる保証はありません。CLAUDE.mdを50行以下にリファクタリングする私は、CLAUDE.mdをルーティングテーブルにまで圧縮しています。具体的には、以下のプロンプトをClaude Codeに投げます。Analyze CLAUDE.md and propose an extraction plan before making changes. Decompose into: .claude/rules/*.md for file-type or directory-scoped conventions (with paths: glob frontmatter), .claude/skills/\u003cname\u003e/SKILL.md for multi-step procedures and code generation patterns (with name:/description: frontmatter), .claude/commands/\u003cname\u003e.md for user-invoked reusable prompts, .claude/agents/\u003cname\u003e.md for delegatable specialist roles (with name:/description:/tools: frontmatter). After extraction, reduce CLAUDE.md to \u003c50 lines containing only project overview, tech stack, universal commands, and @imports to extracted files. Report line count and estimated token count before and after.このプロンプト自体がPLAN MODEの実践例です。 「まず計画を見せて」で計画を先に提示させ、確認してから実行する。これが後述するワークフローの基本パターンです。プロンプトの中に抽出先ごとのfrontmatter形式まで指定しているのは、Claudeに「どういう形式で出力すべきか」を明示するためです。曖昧に任せると、ファイル構造がプロジェクトごとにバラバラになる。リファクタリング後のCLAUDE.mdはこうなります。# プロジェクト概要RustによるgRPC APIサーバー。sqlxでDB接続。# 優先順位正しさ \u003e 保守性 \u003e パフォーマンス \u003e 簡潔さ# ビルド・テストcargo fmt --check \u0026\u0026 cargo clippy -- -D warnings \u0026\u0026 cargo test --workspace# 禁止事項- unwrap() / expect() は本番コードで使用禁止- unsafe ブロック追加禁止- 既存のpublic APIシグネチャ変更禁止# 参照See @README.md for architecture overview50行以下。プロジェクトの最も重要な制約だけが残ります。残りはすべて、適切な場所に分配されています。Rulesへの抽出：関心事で分離し、パスでスコープするCLAUDE.mdから抽出した情報のうち、特定の関心事に属するルールは.claude/rules/に配置します。セキュリティ、テスト、Git規約、パフォーマンス——それぞれ独立したファイルに分離する。さらに、各ルールファイルの先頭にpaths: frontmatterを書くことで、特定のパスのファイルを編集しているときだけルールがロードされるようにできます。.claude/rules/├── security.md          # セキュリティ規約（NEVER/MUST形式）├── coding-style.md      # コーディング規約（命名規則、構造体設計）├── testing.md           # テスト規約（命名規則、カバレッジ目標）├── git-workflow.md      # Git規約（Conventional Commits、ブランチ戦略）├── agents.md            # エージェント委譲ルール（いつ誰に任せるか）└── performance.md       # パフォーマンス規約（クローン回避、ビルド最適化）各ルールファイルは、関心事ごとに分離し、paths: frontmatterでスコープを切ります。 たとえばセキュリティルールは「NEVER（絶対禁止）」と「MUST（必須）」の2カテゴリで構成し、Rustのソースコードを触るときだけロードされるようにする。---paths:  - src/**/*.rs---# セキュリティルール## NEVER- unwrap()/expect() のプロダクション使用- 機密情報のハードコード- 未検証の unsafe ブロック## MUST- 入力バリデーション- 整数オーバーフロー対策（checked_* 使用）- SQLパラメータ化（文字列結合禁止）- 依存関係の定期監査テスト規約も同様に、テストファイルを触るときだけ読み込まれるようスコープを切ります。---paths:  - tests/**/*.rs  - src/**/tests.rs---# テスト規約- テスト関数名は `test_\u003c対象\u003e_\u003c条件\u003e_\u003c期待結果\u003e` 形式- カバレッジ目標: ビジネスロジック90%、APIハンドラ80%、ユーティリティ70%- ミューテーションテスト（cargo-mutants）で品質を検証- 非同期テストは #[tokio::test] を使用ポイントは二つあります。 一つはルールの粒度。「すべてを網羅する」のではなく、「Claudeが最も間違えやすいポイント」に絞る。私の経験では、セキュリティ（unwrap禁止、入力バリデーション）とテスト（命名規則、カバレッジ目標）の2つが、Rulesの効果が最も顕著に現れる領域です。もう一つはpaths: frontmatterによる条件付きロード。テストファイルを書いているときにセキュリティルールは読み込まれない。必要なルールだけが、必要なときに、高優先度で読み込まれる。前回の記事で説明したSkillsの段階的開示と同じ発想です。情報を「足す」のではなく、「絞る」ことで精度を上げる。 引き算の設計思想がここにもあります。なぜこの整備がPLAN MODEと--dangerously-skip-permissionsに直結するのかここが本記事の核心的な主張です。PLAN MODEとの関係: CLAUDE.mdが肥大化していると、PLAN MODEで立てた計画の品質も下がります。Claudeは500行のCLAUDE.mdを読んで「このプロジェクトの規約はこうだ」と理解しようとしますが、情報が多すぎると重要なルールを見落とす。結果、計画に「unwrap()を使う」ようなコードが含まれる。ルールが整備されていれば、PLAN MODEで立てる計画の精度が上がる。--dangerously-skip-permissionsとの関係: YOLO実行中はClaude が自律的にファイルを編集しコマンドを実行します。このとき、Claudeの行動を制約するのはCLAUDE.mdとRulesだけです。人間が逐一チェックしない以上、ルールの品質＝自律実行の安全性です。Rulesが整備されていなければ、YOLO実行は文字通りギャンブルになります。つまり、CLAUDE.mdのリファクタリングとRulesの整備は、単なる整理整頓ではなく、PLAN MODEの計画精度と--dangerously-skip-permissionsの安全性を決定する基盤なのです。Rulesでも防げないもの：Linterという最終防衛線ここで正直に言っておくべきことがあります。Rulesを整備しても、Claudeが100%ルールに従うとは限らない。 CLAUDE.mdに「unwrap()禁止」と書いてあっても、複雑なリファクタリングの最中にClaudeがunwrap()を使うことはある。Rulesはあくまで「指示」であって、「強制」ではないからです。では、どうするか。Linterを作るしかない。 エージェントは「鏡のないバスルーム」では身だしなみを整えられない。自分の出力を検証するフィードバックループがなければ、ミスに気づけないまま突き進む。テスト、Linter、型チェック——これらは「鏡」です。鏡を置いてやることで、人間の監視コストが劇的に下がる。cargo clippyのカスタムルール、ESLintのプロジェクト固有設定、Ruffのルールセット。RulesがClaudeへの「お願い」だとすれば、Linterは「物理的な壁」です。unwrap()が混入しても、cargo clippy -- -D warningsがCIで弾く。人間がレビューで指摘しなくても、機械が確実に止める。正直に告白すると、私の業務時間のかなりの部分はLinterの整備に充てられています。プロジェクト固有のLintルールを書き、CIに組み込み、Hooksで自動実行させる。地味な仕事です。しかし、この投資が「YOLO実行」の安全性を根本から支えている。 Rulesが「Claudeの行動指針」、Linterが「機械的な品質保証」、その二重構造があって初めて、自律実行は「ギャンブル」から「運用」になります。ここで一つ、原則を明確にしておきます。「二度目の失敗」は仕組みの欠陥です。 エージェントの同じミスに二度怒るのは、ガードレールのない道路で事故を運転者のせいにするのに似ている。Claudeがunwrap()を使ったら、一度目は指摘して直す。二度目があったなら、それはClaudeの問題ではなく、ルールの問題です。ミスを観測したら即座に構造で封じる——Rulesに追記するか、Linterのルールを追加するか、Hooksで自動検出させる。これはAI固有の話ではなく、あらゆる自動化の鉄則の再発見です。私がRulesファイルを毎週のように更新しているのは、この原則を愚直に回しているからにすぎません。後述するワークフローの「[テストコマンド]を継続的に実行して」というキーフレーズも、この思想の延長線上にあります。テストもLintも、Claudeの出力を機械的に検証する仕組みです。人間のレビューに依存しない品質保証の仕組みをどれだけ積み上げられるかが、自律実行の信頼性を決める。Skillsやcommands、agentsへの分配Rulesの他にも、CLAUDE.mdから抽出すべき情報はあります。 抽出先               対象                              例                                                  .claude/rules/     関心事ごとのルール                セキュリティ、テスト、Git、パフォーマンス            .claude/skills/    専門知識のリファレンス            パターン集、コーディング標準                         .claude/commands/  ユーザーが手動で呼ぶテンプレート  /review、/plan、/cargo-check                   .claude/agents/    専門的な独立タスク                コードレビュアー、プランナー、セキュリティレビュアー この分配を行った後の変更前/変更後を比較すると、その効果は数字で見えます。 指標                  変更前  変更後  CLAUDE.md行数         487行   42行    起動時ロードトークン  ~8,000  ~1,200  ルールファイル        0個     6個     Skill/Agent           0個     11個   起動時のトークン消費が85%削減されました。その分のコンテキストが、実際のタスクに使えるようになります。Claude Codeのパーミッションモード全体像では、パーミッションモードの全体像に入ります。これを理解することが、PLAN MODEと--dangerously-skip-permissionsを使いこなす前提です。4つのモード モード                          動作                                        切り替え                          Normal Mode（Ask）          すべての操作に承認が必要                    デフォルト                        Auto-Accept Mode            ファイル編集は自動承認、コマンド実行は確認  Shift+Tab × 1                     Plan Mode                   読み取り専用、変更操作は一切不可            Shift+Tab × 2                     Bypass Permissions（YOLO）  すべての操作を自動実行                      --dangerously-skip-permissions Shift+Tabを押すたびにモードが切り替わります。Normal → Auto-Accept → Plan → Normal → ...のサイクルです。Normal Mode：安全だが遅いデフォルトのモードです。すべての操作に承認が必要。Claudeがファイルを編集するたびに差分表示、コマンドを実行するたびに確認ダイアログ。安全だが、安全なだけだ。 安全であることは目的ではない。しかし、CLAUDE.mdもRulesも整備されていない初期段階では、このモード一択です。信頼は実績の上に築くものであって、最初から与えるものではない。 これはAIに限らず、人間同士の協働でも同じことです。Auto-Accept Mode：ファイル編集の信頼Shift+Tabを1回押すと入るモードです。ターミナル下部に ⏵⏵ accept edits on と表示されます。ファイル編集は自動承認、Bashコマンドは確認が必要。私はこのモードを「半信半疑モード」と呼んでいます。Claudeのコード変更は信頼するが、システムに影響を与える操作はまだ自分の目で確認したい。CLAUDE.mdを整備した段階で、自然とここに移行することが多いです。Plan Mode：読み取り専用の安全地帯Shift+Tabを2回押すと入るモードです。ターミナル下部に ⏸ plan mode on と表示されます。次のセクションで詳しく説明します。--dangerously-skip-permissions：完全自律実行いわゆる「YOLO Mode」です。すべてのパーミッションチェックをバイパスし、Claudeが中断なく最後までタスクを実行します。claude --dangerously-skip-permissions名前に「dangerously」が入っているのは伊達ではありません。しかし、正しく使えば最も生産性が高いモードでもあります。PLAN MODEで計画を立て、CLAUDE.mdとRulesで品質の枠組みを整えた上で使えば、「計画通りに最後まで自動実行」が実現します。安全に使うための前提条件:Gitで必ずチェックポイントを作る: 実行前にgit add -A \u0026\u0026 git commit -m \"checkpoint\"隔離環境で実行する: Docker コンテナやDevcontainerがベストCLAUDE.mdとRulesを整備済みであること: 前セクションで述べた基盤が必要計画が承認済みであること: PLAN MODEで立てた計画に沿って実行させるPLAN MODEとは何かPLAN MODEは、Claude Codeを読み取り専用の調査・計画フェーズに制限するモードです。ファイルを読み、コードベースを検索し、質問をし、計画を立てることができます。しかし、ファイルの編集、コマンドの実行、外部への変更は一切できません。Plan Mode instructs Claude to create a plan by analyzing the codebase with read-only operations, perfect for exploring codebases, planning complex changes, or reviewing code safely.使えるToolと使えないTool 使えるTool（読み取り専用）       使えないTool（変更操作）         Read - ファイル閲覧              Edit/MultiEdit - ファイル編集    LS - ディレクトリ一覧            Write - ファイル作成             Glob - ファイルパターン検索      Bash - コマンド実行              Grep - コンテンツ検索            NotebookEdit - ノートブック編集  Task - リサーチエージェント      状態を変更するMCPツール          TodoRead/TodoWrite - タスク管理                                   WebFetch/WebSearch - Web調査                                     この制約が「安全な探索」を可能にします。 通常モードだとClaudeが「ついでにここ直しておきますね」と勝手に変更を加えることがある。PLAN MODEならそれが物理的にできない。安心してコードベースの深層を探索させられます。なぜ「分離」が重要なのかAIコーディングの失敗の大半は、「考えながら手を動かす」ことに起因する。 これは私の実感です。ペアプログラミングにドライバーとナビゲーターの分離があるように、思考と実行は本来別のプロセスです。一人の人間が同時にやるとミスが増える。LLMはさらに顕著で、「これ直しましょう」と「全体の整合性は大丈夫か」を同時に処理させると、ほぼ確実にどちらかが疎かになる。私はこれを「フクロウを描け」問題と呼んでいます。ステップ1：丸を描く。ステップ2：フクロウの残りを描く。巨大で曖昧な指示は人間にとっても困難なのだから、AIにとってはなおさらです。冒頭のOAuth2の事故がまさにそうだった。「OAuth2対応して」はフクロウを描けと言っているのと同じです。構想と施工を一つの息でやらせない。設計図を引く工程と、釘を打つ工程は、別のセッションに分離する。PLAN MODEはこの分離を物理的に強制する仕組みです。——と書いて、立ち止まる。「まだ書かないで」と自然言語で指示すればいいのでは？ 実はそれも試しました。結果、Claudeは3回に1回くらい従わない。計画の途中で「ここは明らかなので修正しておきますね」と手を動かし始める。PLAN MODEの価値は、この「うっかり実装を始める」を物理的に不可能にする点にあります。Tool自体が無効化されている。プロンプトの曖昧さとは次元が違う確実性です。ガードレールが未整備な段階では、この分離がさらに重要になります。 CLAUDE.mdもRulesもない状態でClaudeに自由に実装させると、出力は制御不能になる。計画段階で人間がレビューし方向性を確認すること。それが、未整備な環境における唯一の品質保証手段です。基本的な使い方Shift+Tabで切り替えるNormal Mode → Auto-Accept Mode → Plan Mode → Normal Mode → ...Shift+Tabを1回押すと「Auto-Accept Mode」（⏵⏵ accept edits on）。もう1回押すとPLAN MODE（⏸ plan mode on）。さらにもう1回でNormal Modeに戻ります。セッション開始時からPLAN MODEで始めるclaude --permission-mode planヘッドレスモードでの利用claude --permission-mode plan -p \"認証システムを分析して改善点を提案して\"デフォルトをPLAN MODEに設定する// .claude/settings.json{  \"permissions\": {    \"defaultMode\": \"plan\"  }}Ctrl+Gで計画を編集するPLAN MODEの隠れた強力機能です。Claudeが計画を提示したあと、Ctrl+Gを押すとデフォルトのテキストエディタで計画ファイルが開きます。AIが作った計画を人間が手で修正できる。この双方向性がPLAN MODEの真価です。推奨ワークフロー：調査 → 計画 → 実装ここから紹介するワークフローは、Anthropicの公式ベストプラクティスをベースに、私自身がPLAN MODEを使い込む中で形になったものです。核心は単純です。コードを書く前に、必ず承認済みの計画書を用意する。 言ってしまえば当たり前のことですが、AIの実行速度が上がるほど、この「当たり前」を飛ばしたくなる。飛ばした結果が、冒頭のOAuth2の事故です。Phase 1: 調査（Research）PLAN MODEに入って、コードベースを徹底的に調査します。\u003e src/authを深く読み込んで、セッション管理とログインの仕組みを徹底的に理解して。\u003e 環境変数によるシークレット管理の方法も調べて。\u003e 調査結果をresearch.mdに書き出して。ここでの言葉遣いが重要です。「深く」「徹底的に」「詳細に」。これはただの修飾語ではない。Claudeの調査深度を決定するパラメータです。 省略すると、Claudeは関数のシグネチャだけ見て「理解した」と判断する。人間のエンジニアでいえば、READMEだけ読んで「把握しました」と言うようなものです。表面的な理解は、無理解より危険です。 「分かったつもり」の状態で書かれたコードは、正しく見えるだけに発見が遅れる。調査結果をresearch.mdとして永続化させるのも、私が習慣にしていることです。チャットの中の口頭説明は流れていく。ファイルに書かせれば、Claudeの理解度を可視化できる。理解が間違っていれば、計画に入る前に軌道修正できます。AIコーディングで最もコストの高い失敗は、バグではありません。「既存システムを無視した実装」です。 既存のキャッシュレイヤーを無視した関数。ORMの規約を無視したマイグレーション。既にあるロジックの重複実装。冒頭で触れたOAuth2の事故も、根本はこれでした。既存のセッション管理を理解せずに上書きした。調査フェーズは、この種の構造的な失敗を防ぐための投資です。Phase 2: 計画（Plan）調査結果をもとに、詳細な実装計画を作成させます。\u003e Google OAuthを追加したい。調査結果をもとに、\u003e 実装方法を詳細にまとめたplan.mdを作成して。\u003e コードスニペットとファイルパスを含めること。まだ実装しないで。「まだ実装しないで」は必須のガードレールです。 これがないと、Claudeは計画が「十分良い」と判断した瞬間にコードを書き始めます。Phase 2.5: アノテーションサイクル（計画の研磨）ここが本記事で最も伝えたい点です。 計画をClaudeに書かせ、それを自分のエディタで「赤入れ」する。このアノテーションサイクルが、私がClaude Codeの運用で最も効果を実感した手法です。一見すると二重作業に見えます。Claudeに計画を書かせて、自分でも同じ計画を読み込んで修正する。しかし、この「自分の仕事を写経させる」苦痛こそが、エージェントの能力境界を自分の身体感覚として刻み込むための最速のコストです。他人のブログを読んで「PLAN MODEが良いらしい」と知るのと、自分でアノテーションを3回繰り返して「ここはClaudeに任せられる、ここは任せられない」を体で覚えるのとでは、得られる知識の質がまったく違う。Claudeがplan.mdを書いたら、自分のエディタで開いて、インラインでメモを書き込みます。## 認証フロー- OAuth2のコールバックURLを設定 [注: ステージングと本番で別URLにすること]- セッショントークンを生成 [注: 既存のJWT生成ロジックを再利用。新しく作らない]- ユーザーテーブルにOAuthプロバイダーカラムを追加 [注: PATCHマイグレーションで。テーブル再作成はNG]メモの粒度は様々です。2語で済むこともあれば、パラグラフ丸ごと書くこともある。ドメイン固有の知識、設計判断の根拠、「これはやるな」という明示的な拒否。Claudeが知り得ない文脈を、計画書の正確な位置に注入する。 これはコードレビューのコメントに近い感覚です。ただし、レビュー対象がコードではなく計画書である、という点が決定的に違います。\u003e plan.mdにメモを追加した。すべてのメモに対応してドキュメントを更新して。\u003e まだ実装しないで。このサイクルを1〜6回繰り返します。 毎回「まだ実装しないで」を付けるのが鉄則です。人間の同僚に「計画だけ書いて。実装はまだ」を6回繰り返したら、さすがに関係が悪化します。しかしコーディングエージェントは疲れないし、不満も持たない。納得いくまで計画を練り直させられるのは、人間相手にはない非対称な利点です。遠慮なく使い倒していい。なぜこれが強力なのか。 plan.mdは自分とClaudeの間の「共有されたミュータブルステート」です。チャットで方針を伝えると、過去の発言は流れていく。しかし計画書なら全体を俯瞰でき、問題箇所をピンポイントで修正できる。私の経験では、3回のアノテーションサイクルで、Claudeが書いた汎用的な計画が「自分のシステムの文脈に完全にフィットする設計書」に変わります。ここでもRulesの整備が効いてきます。セキュリティルールが読み込まれていれば、Claudeは計画段階から入力バリデーションやパラメータ化クエリの使用を考慮に入れる。ルールが未整備だと、この種の観点を人間が毎回アノテーションで指摘するしかない。Rulesの整備度は、アノテーションサイクルの回数に反比例する。 設定への投資が、ここでも回収されます。Phase 2.75: Todoリスト化計画の内容が固まったら、次は「実装中に迷子にならない」ための準備です。\u003e 計画に詳細なTodoリストを追加して。全フェーズと個別タスクを含めること。\u003e まだ実装しないで。計画書とTodoリストは役割が違います。計画書は「何をどう作るか」の設計図。Todoリストは「今どこにいるか」の現在地表示です。Claudeはタスク完了時にチェックを入れるので、数時間のセッションでも進捗が可視化される。長いセッションで最も怖いのは、Claudeが途中で方向を見失うことです。 Todoリストはその防波堤になります。Phase 3: 実装（Implement）計画に納得したら、モードを切り替えて実装させます。ここで私が最近採用しているのが、--dangerously-skip-permissionsとの組み合わせです。claude --dangerously-skip-permissions\u003e plan.mdの計画を実装して。完了したタスクは随時チェックを入れて。\u003e すべてのタスクが完了するまで止まらないで。\u003e cargo fmt \u0026\u0026 cargo clippy -- -D warnings \u0026\u0026 cargo testを継続的に実行して。なぜここで--dangerously-skip-permissionsを使うのか。 計画フェーズですべての創造的な判断は済んでいるからです。実装は退屈であるべきだ。 これは私が最近強く実感していることです。計画書に従って機械的にコードを書くフェーズで、mkdirの確認を一つ一つ承認するのは、集中力の浪費でしかない。もう一つ、発想の転換があります。「エージェントで時短する」——多くの人がこう考えます。私も最初はそう思っていた。しかし実際にYOLO実行を組み込んでみて気づいたのは、奪うべきは他人の時間ではなく「自分の不在時間」だということです。自分が寝ている間、コーヒーを飲んでいる間、散歩に出ている間——その「ゼロ生産性」の時間帯を正の値にする。これは「速くやる」よりも摩擦が少ない。YOLO実行が最も力を発揮するのは、人間がモニターの前に座っていない時間帯です。Gitチェックポイントを打ち、計画書を渡し、席を立つ。戻ってきたらdiffを確認する。——と書いて、少し躊躇する。実装中に「あれ、この型だとエラーパスが3つ増えるぞ」と気づくことがある。計画段階では見えなかった問題が、コードを書く手を通じて初めて表面化する。完全な退屈は達成できない。しかし、退屈に近づくほど、実装の品質は安定する。もし実装中に「創造的な判断」が頻発しているなら、それは計画が不十分だったということです。計画に戻るべきであって、実装を続けるべきではない。ただし、順番を間違えてはいけません。 計画を研磨し、CLAUDE.mdとRulesで品質の枠組みを整えた上で、初めてこのアプローチが成立する。計画なし・設定なしのYOLOモードは、自律実行ではなくただの放任です。私のワークフロー全体像：整備 → Plan → YOLOPhase 0: 環境整備（一度だけ、以後メンテナンス）  ├── CLAUDE.md を50行以下に圧縮  ├── .claude/rules/ に関心事ごとのルールを配置  ├── .claude/skills/ にワークフローSkillを配置  └── .claude/settings.json にdenyルールを設定Phase 1: 調査（PLAN MODE）  └── コードベースを深く調査 → research.mdPhase 2: 計画（PLAN MODE）  └── plan.md 作成 → アノテーションサイクル × 1-6回 → Todoリスト化Phase 3: 実装（--dangerously-skip-permissions）  └── git checkpoint → 計画に基づいて自律実行Phase 4: 検証  └── diff確認 → テスト → 必要なら修正このワークフローで見落とされがちなのは、本当のボトルネックが「エージェントの実行速度」ではないことです。「常にエージェントを回す」は手段であって目的ではない。ボトルネックは「委任可能な良質タスクの在庫管理」にあります。仕事を適切な粒度に分解し、優先順位をつけ、パイプラインとして流し続ける能力。Phase 1の調査とPhase 2の計画が重要なのは、まさにこの「タスクの仕込み」を行う工程だからです。考えてみれば、これはAI以前から優れたエンジニアの条件でした。チケットの切り方がうまい人は、昔からチームの生産性を何倍にもしていた。Phase 0の詳細：denyルールで致命的操作を防ぐ--dangerously-skip-permissionsを使う場合でも、.claude/settings.jsonで特定の操作を禁止できます。{  \"permissions\": {    \"allow\": [      \"Read\",      \"Edit\",      \"Write\",      \"Grep\",      \"Glob\",      \"Bash(cargo *)\",      \"Bash(git add *)\",      \"Bash(git commit *)\",      \"Bash(mkdir *)\"    ],    \"deny\": [\"Bash(rm -rf *)\", \"Bash(git push *)\", \"Bash(curl *)\"]  }}rm -rf、git push、curlを拒否。cargo系やGitの基本操作は許可。--dangerously-skip-permissionsの利便性を保ちつつ、致命的な操作を防ぐバランスです。Phase 3の実践：安全なYOLO実行1. Gitチェックポイントは絶対git add -A \u0026\u0026 git commit -m \"checkpoint: before YOLO implementation\"何が起きてもgit reset --hard HEADで戻せる状態にしておく。2. 実装指示は具体的にYOLO実行時に私が毎回含めるキーフレーズは5つです。「plan.mdの計画を実装して」: 計画書を実装の唯一の根拠にする。計画にないことはやらせない「すべて実装して」: 全タスクを実行させる。つまみ食いさせない「完了したタスクにチェックを入れて」: plan.mdを進捗トラッカーとして機能させる。どこまで終わったか可視化する「すべてのタスクが完了するまで止まらないで」: 途中で確認を求めさせない。最後まで走り切らせる「[テストコマンド]を継続的に実行して」: 壊れたら即座に気づかせる。テストが落ちたまま次に進ませない3. 隔離環境の推奨docker run -it --rm -v $(pwd):/workspace -w /workspace \\  --network none \\  claude-code:latest --dangerously-skip-permissions \\  \"plan.mdの計画を実装して\"--network noneで外部接続を遮断。コンテナ内なら被害が限定されます。Phase 4: 実装中のフィードバック実装中のフィードバックについて。ここでの指示は極めて短くていい。 計画フェーズであれほど丁寧に文脈を書き込んだのは、この瞬間のためです。共有済みの計画書があるから、「あれと同じにして」の一言でClaudeは正確に意図を汲み取れる。計画フェーズの投資が、実装フェーズのコミュニケーションコストを劇的に下げる。 この因果関係を体感すると、計画に時間をかけることへの抵抗がなくなります。ただし、短い指示が万能かというと、そうでもない。以前、「設定ページはadminアプリに作るべき。移動して」と一言で済ませたら、Claudeはページを移動しつつルーティングの整合性を壊した。計画書には「adminアプリのルーティング構造」が書いてあったのに、短い指示がそのコンテキストを上書きしてしまった。短い指示が効くのは、計画書のコンテキストが十分に残っているときだけです。セッションが長くなってコンテキストが薄れてきたら、指示の粒度を上げるか、/clearして計画書を再読み込みさせる必要がある。\u003e deduplicateByTitle関数が実装されていない\u003e 設定ページはadminアプリに作るべき。移動して\u003e このテーブルはusersテーブルと同じ見た目にして「あれと同じにして」が、ゼロから説明するより遥かに正確に伝わる。既存コードが最良のリファレンスです。方向性が完全に間違った場合は、修正ではなくリバートします。\u003e 全部リバートした。リストビューをもっとシンプルにしたい。それだけ。他は触らないで。悪い実装を段階的にパッチするのは、方向が間違った旅を微修正し続けるようなものです。git reset --hardで出発地に戻り、正しい地図を持って再出発した方が早い。「やり直す判断」は「直し続ける判断」より難しい。しかし、ほぼ常に正しい。 これはソフトウェア開発に限った話ではありません。PLAN MODEが特に効果的な場面1. 複数ファイルにまたがる変更4ディレクトリに及ぶ変更を無計画に始めると、最初のファイルを変更している間に全体の整合性を見失います。これは人間のエンジニアでも起きる問題ですが、LLMは「目の前のファイル」に意識が引きずられやすい分、さらに深刻です。全体の変更計画を先に作ることで、木を見て森を見失う事態を防げます。2. 不慣れなコードベースの調査新しいプロジェクトにClaude Codeを投入するとき、最も怖いのは「善意の破壊」です。Claudeが「ここ直しておきますね」と既存の設計意図を無視した変更を加える。PLAN MODEなら、理解が不十分な段階で手を出すことが物理的にできない。CLAUDE.mdもRulesも未整備の段階では、このモードが事実上の必須です。3. アーキテクチャの検討「マイクロサービスに分割すべきか」「DBを分離すべきか」。この種の判断は、実装した後に間違いに気づいても手遅れです。取り返しのつかない判断ほど、実行前の検討に時間をかけるべきです。 当たり前のことですが、AIの実行速度が上がるほど、この当たり前を飛ばしたくなる。速く動けることと、正しい方向に動けることは、別の能力です。4. コードレビューPRのレビューをClaudeに任せるとき、PLAN MODEなら「レビューコメントの生成」だけに留められます。レビューと修正を同時にやらせると、レビューの客観性が失われる。自分が書いたコードを自分でレビューしても、欠陥は見つからない。 これはClaudeも同じです。批評者と実装者は分ける。人間の組織でもそうするように。5. CLAUDE.mdのリファクタリング自体前述したCLAUDE.mdのリファクタリングプロンプトが、まさにPLAN MODEの実践例です。「まず計画を見せて」で計画を先に提示させ、確認してから実行する。設定の整備にPLAN MODEを使い、整備された設定がPLAN MODEの精度を上げる。好循環の入り口がここにあります。使わないほうがいい場面Anthropicの公式ベストプラクティスが明確に述べています。Plan Mode is useful, but also adds overhead. For tasks where the scope is clear and the fix is small (like fixing a typo, adding a log line, or renaming a variable), ask Claude to do it directly.ここで強調しておきたいのは、「使わない」という判断こそ最も高度なAIスキルであるということです。失敗するとわかっているタスクにエージェントを投入するのは、時間を燃やしているだけでなく、道具への信頼感を自ら毀損する行為でもある。「PLAN MODEで計画を立てたが、計画自体が意味をなさなかった」という経験は、次回以降PLAN MODEを使うモチベーションを確実に削る。道具への正確な不信は、盲目的な信頼より遥かに生産的です。判断基準: 差分を1文で説明できるなら、計画は不要。 PLAN MODE推奨                   直接実行推奨          複数ファイルのリファクタリング  タイポの修正          新機能の実装                    ログ行の追加          アーキテクチャの変更            変数のリネーム        不慣れなコードの変更            単一ファイルの小修正 --dangerously-skip-permissionsの使い分けも同様に重要です。 YOLO推奨              YOLO非推奨                計画済みの機能実装    本番環境の操作            リンターの一括修正    CLAUDE.md未整備の段階     ボイラープレート生成  信頼できないコードの実行 設定の整備度と自律性の段階ここまで読んで、一つの問いが浮かぶかもしれません。「で、結局どのモードを使えばいいのか」。答えは、今の設定の整備度による。設定の整備度         推奨モード──────────────────────────────────未整備               Normal Mode（全承認）  ↓                   + PLAN MODE で計画を人間が確認CLAUDE.md整備済み     Auto-Accept Mode  ↓                   + PLAN MODE で計画を立ててからRules整備済み         --dangerously-skip-permissions  ↓                   + PLAN MODE → deny ルール → YOLOSkills整備済み        完全自律実行──────────────────────────────────下に行くほど、Claudeへの信頼度が高くなり、任せられる範囲が広がる。 私自身の経験を振り返ると、この階段を1段ずつ登っていた。最初は毎回diffを目を皿にして確認していた。CLAUDE.mdを整備して1週間。Claudeの出力がルールを破らなくなった。その頃からAuto-Acceptが自然になった。さらにRulesを配置して2週間。plan.mdを渡せば計画通りに実装してくれることが分かった。初めて--dangerously-skip-permissionsを使ったとき、不安と解放感が同居していた。信頼は、検証の積み重ねの上にしか成立しない。 いきなりYOLOモードに飛ぶのは、初対面の人間にプロダクションのrootアクセスを渡すようなものです。前回の記事のAgent Skillsとの関係で整理すると： 概念          Skills            PLAN MODE             Rules                 パーミッション設定  制御するもの  知識              思考                  行動制約              自律性              問い          何を知っているか  どう考えるか          何をしてはいけないか  どこまで任せるか    効果          出力の「質」向上  出力の「方向性」制御  出力の「安全性」確保  実行の「効率」向上 この4つが揃って初めて、信頼できる自律的な出力が得られます。 逆に言えば、どれか1つが欠けている状態でYOLOモードに突入するのは、安全装置を1つ外したまま機械を動かすのと同じです。動くかもしれない。しかし、何かが起きたとき止められない。PLAN MODEの限界と現実万能な道具はありません。PLAN MODEにも、使い込んで初めて見えてくる限界があります。計画と実行の乖離PLAN MODEで練り上げた計画でも、実装フェーズで計画通りにいかないことがある。LLMは確率的な生成モデルなので、同じ指示でも出力が揺れる。計画段階では「Aの方法で」と決めたのに、実装中に「Bの方が良さそうですね」と方針を変える。悪気はない。ただ、その時点のコンテキストで最適と判断しただけです。対策は明確です。 plan.mdとして計画を外部化し、「plan.mdに従って実装せよ」と指示する。Todoリストに落とし込めば、さらに逸脱しにくくなる。計画が「頭の中」ではなく「ファイル」にあることが重要です。コンテキストの消費調査・計画フェーズ自体がコンテキストを消費する。これは避けられないトレードオフです。@でファイルを直接参照してトークンを節約する、/clearで新鮮なコンテキストから実装に入る、などの対策はあります。ただし、私の実感では、調査・計画・実装を単一の長いセッションで通しても、50%超のコンテキスト消費でパフォーマンスが目に見えて劣化することは少ない。plan.mdがauto-compaction後も参照可能であることが大きい。計画の質が高ければ、コンテキスト消費のコストは十分にペイします。--dangerously-skip-permissionsの現実的なリスク実際に踏んだ地雷を共有します。Claudeがrmで想定外のファイルを削除した。 冷や汗が出た。→ denyルールでBash(rm -rf *)を禁止テストが落ちているのに次のタスクに進んだ。 Claudeは「後で直します」と言って直さない。→ CLAUDE.mdに「テストが落ちたら修正してから次に進むこと」を明記計画にない「改善」を勝手にやり始めた。 善意のリファクタリングが一番厄介。→ 「plan.mdにないタスクは実行しない」を指示に含めるすべてGitチェックポイントから回復できた。 これが唯一の救いでした。git reset --hardで戻せない環境でYOLOモードを使うべきではない。これは教訓ではなく、絶対条件です。使い込んで見えてきたこと重要度順に並べます。10個あるが、1番だけ覚えて帰ってくれればいい。1. 土台を先に作る土台のない自律は、ただの暴走だ。 PLAN MODEも--dangerously-skip-permissionsも、CLAUDE.mdとRulesという土台の上に成り立つ機能です。この順番を間違えると、すべてが裏目に出る。最初に設定を整備し、次にPLAN MODEで計画を立て、最後にYOLOで実行する。逆順は存在しません。ただし、土台を整備しても暴走は起きた。前述の「善意のリファクタリング」がそうです。土台があれば暴走しないのではなく、暴走を事後に検出できる。検出できるだけだ。止められるかどうかは、結局のところ人間がdiffを読む体力に依存している。2. 「調査 → 計画 → 実装」を習慣にする複数ファイルに影響する変更なら、必ず計画から始める。最初は「面倒だ、直接書いた方が早い」と感じます。私もそう思っていました。しかし手戻りの回数を数えてみると、計画を立てた方が結果的に速い。人間が何十年も前に学んだはずの教訓を、新しい道具を手にするたびに忘れる。私も忘れた。3回やり直して初めて思い出しました。道具の価値は「不快の谷」の向こう側にしかない。 既に機能している自分のやり方を一時的に壊す覚悟がなければ、どんなツールも「微妙に不便な既存ワークフローの劣化版」で終わります。PLAN MODEも例外ではない。最初の1週間は確実に生産性が下がる。計画を書く時間がかかるし、アノテーションの勘所も分からない。しかし、この不快の谷を超えた先に、手戻りゼロの実装フェーズが待っている。習熟曲線の手前で撤退した人間の「PLAN MODEは面倒なだけ」という評価は、常に不正確です。3. 調査では「深さ」を明示的に要求する「深く」「徹底的に」がないと、Claudeは表面的な理解で「把握しました」と言います。人間のエンジニアに「ちゃんと読んだ？」と聞くのと同じ効果があります。4. 「まだ実装しないで」を毎回付ける計画フェーズのすべての指示の末尾に付ける。冗長に感じても、省略するとClaudeは実装を始めます。5. 計画は必ず外部ファイルに残すplan.mdとして永続化し、アノテーションサイクルでブラッシュアップする。チャットの中の計画は流れていく。ファイルに残った計画だけが、実装の羅針盤になる。6. YOLOモードはGitチェックポイントとセットでgit add -A \u0026\u0026 git commit -m \"checkpoint: before YOLO implementation\"これは「やった方がいい」ではなく「やらなければ使ってはいけない」です。7. denyルールで取り返しのつかない操作を防ぐrm -rf、git push、curl。YOLOモードでも、これらだけは人間の判断を経るべきです。最近のモデルとエージェントはそういう異常行動がかなり減ったので安心してみている。8. ルールは関心事で分離し、パスでスコープするすべてのルールをCLAUDE.mdに詰め込まない。セキュリティ、テスト、Git規約、パフォーマンス——関心事ごとに.claude/rules/に分配する。さらに、paths: frontmatterで条件付きロードを設定すれば、Rustのソースコードを触るときだけセキュリティルールが読み込まれ、テストファイルを触るときだけテスト規約が読み込まれる。ルールが1ファイルに混在していると、Claudeにとっても人間にとっても見通しが悪くなります。9. Extended Thinkingと組み合わせるPLAN MODEで「セキュリティの影響について深く考えて」のように深い思考を促すと、計画の質が上がります。考える時間を与えれば、Claudeも考えます。10. 曖昧さを意図的に使う場面も知る「このファイルで何を改善できる？」とオープンに聞くことで、自分が見落としていた問題をClaudeが指摘してくれることがある。常に具体的な指示が最善とは限りません。よくある失敗と対策 問題                  原因                      対策                                      計画が抽象的すぎる    調査フェーズが不十分      @で具体的なファイルを指定して読ませる   実装が計画から逸脱    コンテキストが薄れている  plan.mdをTodoリストに落とし込む           CLAUDE.mdが肥大化     整理していない            50行以下にリファクタリング。Rulesに分配   Rulesが効いていない   配置場所が間違っている    /memoryでロード状況を確認               計画に時間をかけすぎ  分析麻痺                  アノテーションは最大6回で打ち切る         YOLOで想定外の変更    ガードレール不足          CLAUDE.md + Rules + denyルール整備        YOLOでテスト未実行    指示が不十分              「テストを継続的に実行して」を指示に含める  YOLOでファイル削除    deny設定漏れ              Bash(rm -rf *)をdenyに追加              Rulesを無視した出力    Rulesは強制力がない        Linter + CIで機械的に検証する            まとめ本記事で扱った機能を改めて並べます。CLAUDE.md: プロジェクトのグローバルな文脈（50行以下に圧縮）Rules: 関心事ごとのルール（.claude/rules/に分配）commands: 手動ショートカットHooks: 自動実行Subagents: 専門家の自動呼び出しSkills: 専門知識の注入PLAN MODE: 思考と実行の分離 ← 今回パーミッション設定: 自律性のコントロール ← 今回機能は増えました。しかし、核心は3つに集約されます。1. 土台のない自律は、ただの暴走だ。 CLAUDE.mdを50行以下に圧縮し、関心事ごとのルールは.claude/rules/に分配する。ルールの品質がそのまま自律実行の安全性になる。整備が不十分なら、PLAN MODEで人間が毎回レビューするしかない。整備すれば、その手間が消える。設定への投資は、将来の自分の時間を買うことです。2. 思考と実行は、混ぜるな。 PLAN MODEで調査し、計画を書き、アノテーションで研磨し、承認してから実装に入る。この順番を崩すと、出力が制御不能になる。実装中に「創造的な判断」が発生したら、それは計画の不備です。実装を止めて計画に戻る。実装は退屈であるべきだ。 ただし、本文で書いた通り、完全な退屈は達成できない。型を書く手が新しい問題を発見することがある。思考と実行を完全に分離することは、原理的にできない。できないが、分離しようとする努力に意味がある。3. 信頼は、検証の積み重ねでしか成立しない。 Normal Mode → Auto-Accept → PLAN MODE → --dangerously-skip-permissions。いきなりYOLOモードに飛ぶのは、初対面の人間にプロダクションのrootアクセスを渡すのと同じです。設定を整備し、出力を確認し、また整備する。信頼は与えるものではなく、積み上げるものです。そして、一つだけ付け加えます。委任はスキルの「局所的な萎縮」です。 手放したタスクの筋肉は確実に衰える。PLAN MODEで計画を立て、YOLO実行で実装を任せる。このワークフローを回すほど、自分の手でコードを書く時間は減る。それを許容するなら、自分が手動で残すタスクの選択は「何のエンジニアでありたいか」という自己定義の問題になります。特に基礎が未形成な段階では、楽をすることが将来の天井を決めてしまう。私はアーキテクチャの設計と、Rulesの整備と、diffの最終レビューだけは自分の手で続けると決めている。それ以外は——手放す覚悟を、毎回確認しています。Anthropicの公式ベストプラクティスの結びの言葉が、これを的確に表現しています。The patterns in this guide aren't set in stone. Pay attention to what works. When Claude produces great output, notice what you did. When Claude struggles, ask why.冒頭で触れたOAuth2のリファクタリング。今なら、まずPLAN MODEで既存のセッション管理を深く調査し、plan.mdを書き、アノテーションを2回重ねてから実装に入る。あの3回のやり直しは、おそらく起きない。Claude Codeが雑魚なんじゃない。設定してないだけです。CLAUDE.mdを整備し、Rulesを配置し、Linterで品質を機械的に担保し、計画を立て、適切なモードで動かす。そこまでやって初めて、Claudeは最後までやり切ってくれます。ただ、どこまで設定すれば「十分」なのかは、正直まだ分からない。先週もRulesを1つ追加した。来週も何か足すだろう。この整備はいつ終わるのか。たぶん、終わらない。今日から試せること1. CLAUDE.mdのリファクタリング（15分）Refactor @CLAUDE.md to minimize startup context.Extract path-specific rules to .claude/rules/ (use paths: frontmatter for conditional loading),multi-step workflows to .claude/skills/\u003cskill-name\u003e/SKILL.md (with name/description frontmatter),reusable slash commands to .claude/commands/,and specialized task delegation to .claude/agents/\u003cagent\u003e.md (with name/description/tools frontmatter).Show extraction plan first, then create files,reduce CLAUDE.md to \u003c50 lines keeping only universal project context,report before/after token metrics.これ自体がPLAN MODEの実践例です。「まず計画を見せて」で計画を確認してから実行する。2. Shift+Tab を2回押してPLAN MODEを体験する（30秒）⏸ plan mode on と表示されたら成功。「このプロジェクトの全体像を教えて」と聞いてみてください。3. 調査 → 計画 → 実装を1回通す（30分）# Phase 1: PLAN MODEで調査\u003e src/[対象]を深く読み込んで。調査結果をresearch.mdに書いて。# Phase 2: 計画\u003e [やりたいこと]の詳細なplan.mdを作成して。まだ実装しないで。# Phase 3: アノテーション\u003e plan.mdにメモを追加した。すべてのメモに対応して。まだ実装しないで。# Phase 4: 実装\u003e plan.mdの計画を実装して。完了したタスクにはチェックを入れて。4. denyルールを設定してからYOLOモードを試す（10分）git add -A \u0026\u0026 git commit -m \"checkpoint\"claude --dangerously-skip-permissions\u003e plan.mdの計画を実装して参考資料Best Practices - Claude Code DocsCommon Workflows - Claude Code DocsConfigure Permissions - Claude Code DocsManage Memory - Claude Code DocsHow Claude Code Works - Claude Code DocsClaude Code Best Practices: The Plan Mode - Code CentreWhat Actually Is Claude Code's Plan Mode? - Armin RonacherCLAUDE.md Mastery - ClaudeFastRules Directory Guide - ClaudeFastClaude Code Best Practices (Community)ClaudeLog - Plan ModeClaudeLog - Dangerous Skip Permissions","isoDate":"2026-02-13T03:22:28.000Z","dateMiliSeconds":1770952948000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、方法を学べ","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/09/180240","contentSnippet":"はじめにエディタを開いたまま、手が止まっていた。書くことは決まっている。決まっているのに、最初の一行が出てこない。内容が自分の中でまだ言葉になっていない。その感覚だけがある。カーソルが点滅している。点滅を眺めていた。「課題から入れ」という原則がある。手段から入るな、何を解くべきかを先に考えよ。正しいと思う。長い間、信じてきた。信じてきたのだが、ずっと聞きたかったことがある。課題って、どうやって見つけるんですか。誰にも聞けなかった。正確に言えば、聞いたことはある。返ってきたのは「現場を見ろ」「ユーザーの声を聞け」だった。目の前には日常があり、業務があり、なんとなく回っている世界がある。その中から「これが課題だ」と名指しすることが、そもそもできない。見つけ方がわからないまま、ただ座っていた。座っている自分に苛立っていた。苛立っていることにも苛立っていた。後になって気づいた。「課題から入れ」と言える人は、自分の中で自動的に動いている診断プロセスを省略している。「どこを見るか」「何を測るか」「どの違和感を拾うか」が内面化されていて、課題が「見える」のであって「見つける」ものではない。だから見つけ方を聞かれても言語化できない。この原則が有効なのは、すでにその領域の語彙と観測手段を持っている人——つまり方法を持っている人——だけだ。方法を持たない人にとっては、「課題から入れ」は呪いになる。課題が見えないとき、人は自分の能力を疑う。怠惰だから見えないのだ、センスがないのだ、と。能力の問題ではなかった。視点の問題だった。と、今なら書ける。当時はそれすらわからなかった。わかりたくなかったのかもしれない。わからないことにしておいた方が、楽だったのかもしれない。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。この記事における「方法」の定義「方法を学べ」と言いたい。しかし、「方法」が曖昧なまま語ると、読む人によって受け取り方がバラバラになる。過去に何度かそういう失敗をした。だから先に言葉を定義しておく。この記事で「方法」と呼ぶものは、問題を分解し、解決するための体系化された知識とアプローチだ。3つに分けて考えている。操作の知識: 道具をどう動かすか構造化の知識: 問題をどう分解するか文脈の知識: 何が重要かをどう判断するか言い換えれば、実行・分解・判断だ。「実行」は、手を動かして何かを作る能力だ。Pythonを書ける。Kubernetesを操作できる。プログラミング言語、フレームワーク、ツールの操作がここに入る。「分解」は、複雑な問題を扱える単位に切り分ける能力だ。「この問題はボトルネックの問題だ」「これはフィードバックループの問題だ」と構造を見抜ける。スクラム、リーン、アジャイル、システム思考といった方法論がここに入る。「判断」は、「この文脈では何が重要で何が重要でないか」を見極める能力だ。同じ技術でも、金融とゲームでは優先順位が違う。その違いを知っている。特定分野の概念、パターン、ベストプラクティスがここに入る。なぜ3つか。正直、2つでも4つでもよかった。ただ、「実行できるか」「分解できるか」「判断できるか」と自分に聞いてみたとき、この3つの問いで知識の穴を点検できた。それだけの話だ。3層の間には、依存関係がある。判断は、分解を前提とする。「何が重要か」を判断するには、まず問題を分解して構造を見る必要がある。構造が見えないまま「これが重要だ」と言っても、それは直感であって判断ではない。分解は、操作を前提とする。Kubernetesの問題を分解するには、Kubernetesを触った経験が必要だ。触ったことがないものを、構造的に分解することはできない。つまり、操作→分解→判断という順序がある。ただし、この順序は「学ぶ順序」ではない。「依存関係」だ。判断を学ぶためには、分解ができる必要がある。分解を学ぶためには、操作ができる必要がある。しかし、操作だけを完璧にしてから分解に進む必要はない。私自身、Terraformの操作コマンドを先に覚えてから設計原理を学ぼうとして、半年間terraform applyの繰り返しで過ごしたことがある。操作はできる。しかし、「なぜこのモジュール構成なのか」を分解できない。操作の習熟を待っていたら、分解の学びが永遠に始まらなかった。操作しながら分解を学び、分解しながら判断を学ぶ。3層は並行して育つ。待っていても、次の層は始まらない。「方法を学べ」と言うとき、私はこの3つすべてを含めている。どれか1つではない。技術スキルだけあっても方法論がなければ使いこなせない。方法論だけあっても領域知識がなければ適用できない。3つは相互に補完し合う。「3つで足りるのか」と聞かれるかもしれない。正直に言えば、「判断」の中には、純粋な技術知識では収まらないものがある。組織の力学、ステークホルダーの価値観、倫理的な判断。「技術的に正しい」と「組織として採用できる」は別の問いだ。セキュリティ上最適な設計が、ビジネスの速度を殺すことがある。アーキテクチャとして理想的な分割が、チームの政治的な境界と衝突することがある。この記事では「方法」を技術的な問題解決の文脈に限定して書いている。しかし、現場では判断の上にさらに「交渉」と「妥協」の層がある。それは技術の方法論ではなく、人間の方法論だ。3層で足りるかと問われれば、足りない。足りないことを知った上で、この記事では技術の話に集中する。3層それぞれの到達度は、こう測れる。操作は「説明できるか」ではなく「手が動くか」だ。分解は「構造を描けるか」だ。判断は「トレードオフを言えるか」だ。Rustを「知っている」と「Rustで考えられる」は違う。前者は操作の入口、後者は分解と判断を含んでいる。もっと言えば、「説明できる」「再現できる」「即応できる」の3段階がある。本を読んで説明できる段階は、まだ「情報」だ。手を動かして再現できる段階で「知識」になる。考えなくても即応できる段階で、ようやく「方法」になる。なぜこの定義が重要か。「方法」が曖昧だと、「方法を学ぶ」も曖昧になるからだ。「Pythonを勉強しました」と「システム思考を学びました」では、学んだ後の視野の広がり方がまったく異なる。前者は操作の知識、後者は構造化の知識だ。何を学ぶかによって、何が見えるようになるかが変わる。自分の知識を点検するとき、「操作できるか」「分解できるか」「判断できるか」と問うといい。3つすべてにYesと言えるなら、その領域の「方法」を持っている。どれかがNoなら、そこに学ぶべきものがある。だから「方法を学べ」と言うとき、私が意味しているのは「情報を集めろ」ではない。「考えなくても使えるレベルまで落とし込め」だ。Goを説明できることと、Goで考えなくてもコードが書けることは違う。後者にならなければ、言語の上にアーキテクチャや設計の思考を積むことができない。文法を考えている間は、アーキテクチャを考える余裕がない。考えなくていいことが増えると、考えるべきことに集中できる。では、この「方法の知識」がないとき、実際に何が起きるのか。障害の名前を知らなければ、落ちた理由がわからない本番障害が起きた。APIのレスポンスタイムが急激に悪化し、タイムアウトが連鎖して、最終的にサービス全体が応答不能になった。何かがまずかったのはわかる。でも、何がまずかったのかわからない。リクエストが多すぎたのか、サーバーのスペックが足りなかったのか、そもそもアーキテクチャが間違っていたのか。漠然とした「やられた」感だけがある。私は駆け出しだった頃、その違和感を言語化できなかった。「なんか落ちた」のまま、モヤモヤが残った。胃のあたりに不快感がある。何かが間違っている気がする。でも、何が間違っているのか指させない。ログを開く。全行が等しく意味不明に見える。どこが重要でどこが無関係なのか、判断する基準がない。Slackで「障害です」と報告する。「で、原因は？」と聞かれる。固まる。「課題が見えない」とは、こういう状態だ。怠惰ではない。目の前に情報はある。しかし、情報を「手がかり」に変換するフィルタがない。全部見えているのに、何も見えていない。当時の上司は「もっとちゃんと調べろ」と言った。「ちゃんと」が何を意味するかはわからなかった。端から端まで読んだ。読んだが、どの行が重要なのか判断できなかった。「課題が見えない」を「怠惰」や「能力不足」と誤認するのは、見えている側が陥る典型的な誤りだ。見える人にとっては「見ればわかる」。見えない人にとっては「見ても何もわからない」。同じログを見ていても、使っている眼鏡が違う。熟練のSREは違う。同じ障害を見ても、同じログを見ても、見ている場所が違う。まずエラーレートの変化点を見る。次にレイテンシの分布——平均ではなくP99を見る。「いつから」「どのエンドポイントで」「どのくらいの割合で」。数字を3つ確認した時点で、仮説が立っている。「キャッシュの有効期限が同時に切れて、バックエンドにリクエストが集中した。典型的なサンダリングハード問題だ」と言える。障害の瞬間を特定し、構造的に捉えられる。分散システムの障害には、パターンに名前がついている。キャッシュが一斉に失効してリクエストが殺到する「サンダリングハード」。障害が連鎖してコンポーネントが次々と倒れる「カスケード障害」。名前があると、対策の候補が自動的に浮かぶ。サンダリングハードならジッター（タイミングをランダムにずらすこと）やキャッシュウォーミング。カスケード障害ならサーキットブレーカーやタイムアウト設計。名前は、仮説→対策→再発防止という変換パイプラインのショートカットキーだ。障害パターンの名前を知らない私も「落ちた」ことは感じている。 しかし、それを「課題」として認識できない。これは能力の差ではない。語彙の差だ。ただし、語彙があれば万能かというと、そうでもない。名前を知っていても、目の前の障害がそのパターンかどうかを判別するには、観測の手段と経験が必要だ。語彙は必要条件であって十分条件ではない。逆に、語彙がなくても課題を当てられる人がいる。触れた回数が多い人だ。直感に見えるが、実態は暗黙のパターンマッチングだ。ただし、名前がないとチームに共有できない。語彙を増やす最短ルートは、本を読むこと、障害報告書を読むこと、他人の失敗を追体験すること。自分で全部失敗するには人生が短すぎる。しかし、名前が害になる場面もある。名前をつけた瞬間に、わかった気になる。目の前の障害が本当にそのパターンなのか、別の要因が重なっていないか。名前はショートカットであって、ゴールではない。名前に飛びつくと、名前に合わない症状を無視する。名前を知っていることと、名前に頼りすぎないことは、同時に必要だ。名前をつけるとは、違和感と課題認識の間にある溝を越える操作だ。3つのことが同時に起きる。第一に、バラバラだった症状が1つの構造として圧縮される。第二に、その構造を他の場面でも検索できるようになる。第三に、対策の候補が構造に紐づいて出てくる。1つの障害から学んだことが、10の障害に適用できる。それは名前という圧縮を経由しているからだ。ここにもう1つ、見過ごされがちな問題がある。名前を知らないということは、その方向に道が存在すること自体を知らないということだ。 AIに聞けば対策は教えてくれる。しかし、AIに聞くためには「キャッシュが同時に切れてリクエストが集中する現象は何ですか」と問う必要がある。この問いを立てるには、少なくとも「キャッシュの同時失効」が原因である可能性に気づいている必要がある。道の存在すら知らなければ、歩き出すことも、誰かに道を聞くこともできない。つまり、方法を知らない人間には、課題が見えない。見えないものを「解くべきだ」と言われても、困る。違和感の正体が見えない「違和感はあるのに、課題として認識できない」——これは障害対応に限った話ではない。日常の仕事でも頻繁に起こる。あるプロジェクトで、半年間「なんとなくうまくいかない」と感じていた。みんな忙しそうにしている。会議も多い。Slackは常に未読がある。でも、なんとなく進んでいない。違和感はある。ただ、何が問題なのかわからない。私は「コミュニケーションが足りないんじゃないか」と言った。なんとなくそれっぽかった。会議を増やした。Slackのチャンネルを増やした。改善しなかった。「コミュニケーション不足」は、catch (Exception e) {} だ。 エラーは握りつぶされる。原因はそのまま残る。TOC（制約理論——「全体の成果はもっとも弱い環が決める」という考え方）を学んだ後、同じ状況を見直した。ボトルネックが見えた。フロントエンドの実装が週に5件来るのに、デザインレビューは週1回。3日待ちが常態化していた。開発者は待っている間に別のタスクに手を出し、コンテキストスイッチが積み上がり、全体の生産性が下がっていた。これは「コミュニケーション不足」ではなく「フローの制約の問題」だった。制約理論を知らなかった半年間、私は会議を増やすことで問題を悪化させていた。会議が増えれば、デザイナーの時間はさらに減る。レビューの頻度はさらに下がる。「コミュニケーションを増やす」が「ボトルネックを悪化させる」に直結していたのに、構造が見えていなかった。なぜ人は構造ではなくラベルに逃げるのか。構造を見るには知識が要り、指摘すると責任が生じる。「デザインレビューが週1回しかない」と言えば「じゃあお前が変えろ」と返ってくる。「コミュニケーション不足ですね」なら、誰の問題でもない。ラベルは3秒で出せるが、構造の分析には時間がかかる。ラベルを構造に戻すには、具体的な問いを使う。「待ち時間はどのくらいか」「同時進行のタスクはいくつあるか」「どこで止まっているか」「誰が制約になっているか」。この4つを聞くだけで、「コミュニケーション不足」は分解される。ただし、正直に書く。「会議を増やす」が正解のケースもある。情報の非対称性が問題の本質であるとき、共有の場を増やすことは直接的な解になる。ラベルが正しいこともある。問題は、ラベルが正しいかどうかを検証せずに貼ることだ。同じ「なんとなくうまくいっていない」を感じていても、持っている方法の知識によって、見える課題がまったく異なる。方法が課題を照らす障害対応とプロジェクト運営の例を見てきた。どちらも、方法を知らなければ課題が見えなかった。ここで馬車と蒸気機関の話をしたくなる。「方法を知らなければ、馬をもっと速く走らせることしか考えられない」。よくある例だ。しかし、借り物の例は使わない。もう1つ、自分の経験で語る。インフラの監視を設計していたとき、「もっと見やすいダッシュボードを作ろう」が課題だと思っていた。Grafanaのパネルを増やし、配色を工夫し、アラートの閾値を調整した。「監視を改善する＝見せ方を良くする」だと思っていた。具体的に言う。あるAPIのレスポンスタイムが遅かった。Grafanaのダッシュボードには、平均レスポンスタイムのグラフが表示されている。「平均300ms」。遅い。しかし、「どこが遅いのか」はわからない。データベースのクエリが遅いのか、外部APIの呼び出しが詰まっているのか、単にネットワークのレイテンシが高いのか。ダッシュボードは集約された数値を見せてくれるが、数値の内訳は見えない。私はダッシュボードのパネルを増やした。CPU使用率、メモリ使用率、ディスクI/O、ネットワーク帯域。パネルが増えるたびに、何かがわかった気がした。実際には、何もわかっていなかった。見せるデータを増やしただけで、リクエストが「どこを通って、どこで詰まっているか」という根本的な問いには一切答えていなかった。ダッシュボードの配色に悩んでいた。正常は緑、警告は黄色、異常は赤。閾値をいくつにするか。300msで黄色にするか、500msにするか。今思えば、問いの立て方がそもそも間違っていた。「見せ方」のレイヤーで課題をいじっていた。計測していないものは、見せようがない。当たり前のことだが、当時の私にはその当たり前が見えていなかった。OpenTelemetry（システムの動作を計測・追跡するための標準規格）を学んだ後、課題設定が根本から変わった。分散トレーシングという概念を知った。1つのリクエストがシステムの中をどう流れ、どこで何ミリ秒かかっているかを、リクエスト単位で追跡できる。トレースを入れてみて初めて、「平均300ms」の内訳が見えた。認証サービスへの呼び出しで120ms、データベースのクエリで80ms、外部決済APIの応答待ちで90ms。残りの10msはネットワークとシリアライゼーション。ボトルネックは外部決済APIだった。しかもリトライが走っていた。私がダッシュボードの配色に悩んでいた間、答えはリクエストの中に隠れていた。必要だったのは「見せ方を工夫する」ことではなく、「見えていなかったものを見えるようにする」ことだった。計装（instrumentation）という発想がなければ、この課題設定にたどり着けない。この経験で学んだのは、課題が「どのレイヤーにあるか」を見誤ると、いくら努力しても解決しないということだ。私は表示のレイヤーで課題をいじっていた。本当の課題は計測のレイヤーにあった。計測のレイヤーの存在自体を知らなかったから、表示のレイヤーで頑張るしかなかった。知らない方法で解ける課題は、課題として認識できない。「そういうものだ」と受け入れてしまう。私にとって「平均レスポンスタイムしか見えない」は、監視とはそういうものだ、と思い込んでいた状態だった。方法の解像度が、課題の解像度を決める。 そして、自分の課題認識が「どのレイヤー」にあるかを見抜くこと自体が、方法の知識を必要とする。ここで1つ、疑問が浮かぶ。方法を学んだから課題が見えたのか。それとも、課題に困っていたから方法を学べたのか。正直に言えば、両方だ。OpenTelemetryを学んだのは、「平均レスポンスタイムしか見えない」という不満があったからだ。しかし、その不満を「これは計装の問題だ」と名づけられたのは、OpenTelemetryを知った後だ。鶏と卵に見えるが、実際には螺旋だ。違和感が方法を引き寄せ、方法が違和感を課題に変換し、課題が次の違和感を生む。そして、方法が照らすのは課題だけではない。「何が重要か」「何がリスクか」「何を先にやるべきか」優先順位の判断も、方法の知識で変わる。制約理論を知っていれば、「全体のスループットを最も制約しているのは何か」という問いが立つ。この問いがなければ、目についた問題から手当たり次第に着手する。忙しいが、成果が出ない。ただし、見えるようになった人が次に陥る罠がある。すべてが課題に見えてしまうことだ。方法の知識が増えると、今まで気にならなかったことが全部「改善すべき点」に見える。コードの結合度、デプロイパイプラインの無駄、チーム間のハンドオフの遅延。全部見える。全部直したくなる。しかし、全部直す時間はない。見えることと、今やるべきことは別だ。課題が見えすぎる人間は、改善中毒に陥る。これも、方法の目的化の一種かもしれない。そしてここに、もう1つの構造がある。ここまでの話を振り返ると、私がやっていることには共通のパターンがある。具体的な障害を経験する。そこからパターンの名前を知る。名前の背後にある構造を取り出す。すると、まったく別の場面でも同じ構造が見える。サンダリングハードの経験から「同時に多数のリクエストが1点に集中する」という構造を取り出した。すると、年末のセール開始時刻にアクセスが殺到する現象も、CI/CDパイプラインで全チームのビルドが同時にキューに入る問題も、同じ構造として見えるようになった。具体的な見た目はまったく違う。しかし、構造は同じだ。この運動を言語化するとこうなる。具体的な経験から、抽象的な構造を取り出す。取り出した構造で、別の具体を照らす。 制約理論を学んだときも同じ運動が起きた。「デザインレビューが週1回でボトルネックになっている」という具体から、「全体のスループットは最も制約された工程で決まる」という構造を取り出した。すると、別のプロジェクトで「QAチームのキャパシティが全体のリリース速度を制約している」と見えた。具体的な文脈はまったく異なる。しかし、構造を一度取り出してしまえば、それは1つの場面に留まらない。たとえば、「持ち家か賃貸か」という議論がある。不動産の話だ。しかし、一歩引いて考えると、これは「所有か利用か」という構造の問題だ。その構造が見えた瞬間、サーバーを自前で持つかクラウドを使うか、ライブラリを自作するかOSSを使うか、人を雇うか外注するか——まったく異なる文脈に同じ構造が適用できる。片方の文脈で得た判断基準が、もう片方でも使える。これが「1つを学んで10に適用する」のメカニズムだ。しかし、この変換は自動的には起きない。具体的な方法を学んだとき、そこから抽象的な構造を取り出すのは、自分自身だ。 本が教えてくれるのは具体的な事例とメカニズムだ。構造を見出すのは読者の仕事だ。USEメソッドを知った。「Utilization・Saturation・Errorsの順に点検する」——これは具体的な手順だ。ここから「問題を複数の独立した観点で順序立てて点検する」という構造を取り出さなければ、USEメソッドはパフォーマンス分析でしか使えない「手順書」のままだ。構造を取り出した人間は、障害対応でも、コードレビューでも、プロジェクトの健康診断でも、同じ型で思考できる。同じ本を読んでも、得られるものが10倍違う人がいる。違いは記憶力ではない。具体から構造を取り出し、別の具体に適用する往復運動を、意識的にやっているかどうかだ。私のやり方はこうだ。本を読んだあと、「この本が教えた手法を、一言で言うと何か」と自分に問う。一言にできたら、「同じ構造を持つ、まったく別の場面は何か」と考える。2つ目が見つかったとき、その手法は「手順書」から「思考の型」に昇格する。見つからなければ、まだ構造が取り出せていない。そしてここに、一方通行の性質がある。構造を取り出せる側にいる人間には、具体の世界も見える。しかし、具体しか見えない側にいる人間には、構造の世界は見えない。一度構造が見えてしまうと、「あのとき、なぜ気づかなかったのか」がわかる。しかし、構造が見える前の自分は、「何が見えていないか」すらわからなかった。だから「構造を取り出せ」と言われても、取り出した経験がない人には、何を言っているかわからない。「課題から入れ」と同じ構造がここにもある。見えている側が、見えていない側に「見ろ」と言っている。では、この一方通行をどう越えるか。1つだけ確実に効く方法がある。異なる文脈で同じ壁にぶつかることだ。Rustでデータ競合にぶつかる。Goでも似たようなバグに遭遇する。Pythonでもリストの共有状態で事故を起こす。3回目あたりで、「これは言語の問題ではなく、共有状態へのアクセス制御の問題だ」と気づく。具体的な失敗を3回繰り返すと、共通する構造が浮かび上がる。失敗は、構造を取り出すもっとも確実な教師だ。結局のところ、方法の知識が課題の解像度を決める。「遅いから、もっと頑張る」と「デザインレビューが週1回で3日待ちが発生しているから、非同期レビューを導入する」では、解像度がまるで違う。高解像度な課題認識を持つ人は、低解像度な課題も見える。逆は成り立たない。これは能力の問題ではない。道具の問題だ。本を読んで、問題が見えるようになった道具の話を続ける。というか、知識そのものが道具だと思っている。プログラミング言語やフレームワークだけが道具ではない。概念、分析手法、設計原理。頭の中にある知識が、目の前の問題を切り分ける刃物になる。パフォーマンス分析の本を読んだことがある。Brendan Greggの『詳解 システム・パフォーマンス』だ。読む前と後で、同じシステムが違うものに見えた。詳解 システム・パフォーマンス 第2版作者:Brendan Greggオーム社Amazon読む前の私は、パフォーマンス問題が起きたとき「遅い」しか言えなかった。「遅い」の内訳がわからなかった。CPUが飽和しているのか、I/Oで待っているのか、ロックの競合が起きているのか。どこを見ればいいのか、そもそも何を計測すべきなのかがわかっていなかった。「遅い」の前で立ち尽くしていた。この本が教えたのは、ツールの使い方ではなかった。問いの立て方だった。USEメソッドという手法がある。Utilization（使用率）、Saturation（飽和度）、Errors（エラー）この3つの観点で、すべてのリソースを順番に点検する。手順としてはシンプルだ。しかし、この「順番に点検する」という発想が、私にはなかった。「遅い」から「なんとなくCPUが高い気がする」に飛んでいた。途中のステップを全部飛ばしていた。飛ばしていることにすら気づいていなかった。なぜ飛ばしてしまうのか。問題を分解する語彙がなかったからだ。 「遅い」を分解するには、「遅い」がどのリソースの、どの指標に現れているかを特定する必要がある。CPUの使用率が高いのと、CPUのランキューが飽和しているのは、まったく異なる問題だ。前者はCPUを多く使っているだけで、まだ余裕があるかもしれない。後者はCPUの処理待ち行列（ランキュー）にタスクが溜まりすぎている。対処が違う。しかし、この区別は「飽和度」という概念を知らなければ、そもそも見えない。読んだ後、「遅い」の解像度が変わった。「遅い」が「ディスクI/Oの飽和度が90%を超えている」になった。「レイテンシが高い」が「カーネルのスケジューラがCPUの処理待ち行列に積まれたタスクを処理しきれていない」になった。同じシステムを見ているのに、見える景色がまったく違う。分散システムの設計原理を扱ったMartin Kleppmannの『データ指向アプリケーションデザイン』でも、同じことが起きた。読む前、私はデータベースの選定を「MySQLかPostgreSQLか」で考えていた。スケーリングは「サーバーを増やせばいい」くらいの解像度だった。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann,斉藤太郎,玉川竜司オライリージャパンAmazon(※原著の第2版が出て全員が喜んでいる。)learning.oreilly.comこの本を読んで気づいたのは、私が「スケーリング」と呼んでいたものの中に、互いに矛盾する複数の問題が隠れていたということだ。レプリケーションの一貫性とレイテンシはトレードオフの関係にある。パーティショニングの戦略次第で、ある種のクエリは高速になり、別のクエリは破滅的に遅くなる。「サーバーを増やす」の一言で済むはずがなかった。しかし、私はそのことを知らなかった。知らなかったから、「増やせばいい」で止まっていた。ソフトウェア設計の結合について書かれたVlad Khononovの『ソフトウェア設計の結合バランス』でも、同じパターンを経験した。読む前の私は、「疎結合にしておけば正しい」と思っていた。コードレビューで「ここ、結合が強くないですか」と言えば、それだけで設計の指摘として成立した。冒頭で書いた「コミュニケーション不足」と同じ構造だ。何も言っていないのに、言った気になれる万能ラベル。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonこの本が教えたのは、結合には強度・距離・変動性という3つの次元があり、それらのバランスで評価すべきだということだ。強い結合でも、距離が近く変動性が低ければ問題にならない。弱い結合でも、距離が遠く変動性が高ければ厄介になる。「疎結合にしろ」の一言では、この判断ができない。私がレビューで「結合が強い」と指摘していたとき、強度の話をしているのか、距離の話をしているのか、変動性の話をしているのか、自分でも区別できていなかった。区別する語彙がなかったからだ。もう1冊——これは私自身が翻訳に関わった本だ。Nick Tuneの『アーキテクチャモダナイゼーション』。アーキテクチャの刷新は技術の問題ではなく、組織とビジネスと技術の三位一体の変革だと主張する本だ。翻訳の過程で560ページを何度も読み返した。読み返すたびに、自分がアーキテクチャを「技術の構造設計」としか見ていなかったことに気づかされた。チーム構造がアーキテクチャの不可分な一部であること、コンウェイの法則を観察ではなく設計ツールとして使うこと、モダナイゼーションの成功指標が「新しいシステムが動くかどうか」ではなく「ビジネスアウトカム」であること——技術書を翻訳しているはずなのに、組織論と戦略論を学んでいた。アーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazonしかし、この本もすべての問題を完璧に解決する銀の弾丸ではない。翻訳者として断言する。どんなに優れた方法論も、組織と個人にそれを受け入れる準備と継続する体力がなければ機能しない。本が提案する「独立バリューストリーム」も「AMET（イネーブリングチーム）」も、体力がない組織ではただの用語に終わる。体力がない組織は「この本の通りにやったのにうまくいかない」と言い、本のせいにする。本は地図であって、歩く脚力ではない。これは、先に挙げた3冊すべてに言えることだ。4冊に共通する経験がある。「読む前は、自分が問題を抱えていることすら知らなかった」。パフォーマンス分析の体系を知らないこと自体が問題だと、読む前の私は思っていなかった。分散データの一貫性モデルを知らないことが設計上の盲点になっていることに、読む前の私は気づいていなかった。結合を1次元でしか評価できていないことに、読む前の私は疑問すら持っていなかった。アーキテクチャを技術だけで語れると思い込んでいたことに、翻訳するまで気づかなかった。問題の存在を知らなかったから、解決しようとも思わなかった。道具について詳しく知らなければ、目の前の問題が「解決できる問題」なのか「原理的に解決不可能な問題」なのかすら判断できない。「遅い」が「体系的な手法で5分で原因を特定できる問題」なのか、「アーキテクチャを根本から見直さないと解決しない問題」なのか。この見極めは、方法を知らなければ不可能だ。そして、見極められない人はどちらのケースでも同じ反応をする。「遅いですね、まあ仕方ないですね」。これが一番怖い。解決できる問題を「仕方ない」で片付けている。解決の入口はすぐそこにあるのに、入口が見えていない。同じ問題を前にして、片方は手も足も出ず、片方は鼻歌を歌いながら直している。違いは才能ではない。「問いの立て方」を知っているかどうかだ。ソフトウェアの世界では「銀の弾丸はない」とよく言われる。魔法のように問題を解決する単一の技術は存在しない、と。Fred Brooksが1986年に書いたことだ。しかし、私はこの言い方に違和感がある。USEメソッドは、パフォーマンス問題に対する銀の弾丸だった。少なくとも私にとっては。「遅い」という怪物に対して、それまでの私は素手で立ち向かっていた。USEメソッドという弾を手に入れた瞬間、怪物は倒せるようになった。OpenTelemetryも、制約理論も、結合の3次元モデルも、社会技術的整合の視点も、Rustの所有権モデルも、それぞれの領域で怪物を殺す弾だった。銀の弾丸はある。 ただし、万能の一発ではない。特定の怪物を殺す特定の弾だ。問題は「銀の弾丸が存在しない」ことではなく、どの弾がどの怪物を殺すかを知らないことだ。弾を持っていないのではない。弾の存在を知らない。だから素手で戦っている。しかし、もっと厄介な問題がある。銀の弾丸を「求める」こと自体が、病理だ。「学んで損したくない」「タイパが悪い」こう言い始めた瞬間、人は新しい弾丸を手に取らなくなる。学ぶコストを「損」と捉えると、今持っている弾丸でなんとかしようとする。そして、自分が持っている弾丸が「すべての怪物を、すべての状態で殺せる万能の一発だ」と思い込む。Kubernetesですべてのインフラ問題が解ける。スクラムですべてのプロジェクトがうまくいく。Rustですべてのソフトウェアが安全になる。ありえない。しかし、新しい弾丸を手に入れるコストを「損」だと思っているから、既存の弾丸の適用範囲を無限に広げようとする。これが「銀の弾丸はない」の真の意味だと私は思っている。銀の弾丸が存在しないのではない。1つの弾丸で全部解決したいという欲望が、方法の目的化を引き起こすのだ。体力がないのではない。体力を分散させたくないのだ。1冊の本で、1つのフレームワークで、1つの言語で、全部なんとかしたい。その気持ちはわかる。しかし、怪物は1種類ではない。ちなみに、これは技術の話に限らない。「コミュニケーションが銀の弾丸だ」と主張するオジサンもいる。「社内政治をうまくやれば技術の問題は些末だ」と言う人もいる。しかし、コミュニケーションも社内政治も銀の弾丸ではない。同じ構造だ。コミュニケーションで解ける問題はある。社内政治で通せる案件もある。しかし、それぞれが特定の怪物に対する特定の弾であって、万能ではない。コミュニケーションで解決するのはコミュニケーション不足が原因の問題だけだし、社内政治で通せるのは政治が障壁になっている案件だけだ。技術的に破綻しているアーキテクチャを、いくらコミュニケーションしても直らない。政治力で通したプロジェクトも、技術的な裏付けがなければ崩壊する。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazonと書いて、立ち止まる。「本を読めば解像度が上がる」。それはそうだ。しかし、読んだだけで上がるのか。正直に言えば、『詳解 システム・パフォーマンス』を読んだ直後に、USEメソッドを使いこなせたかといえば、使いこなせなかった。本に書いてある通りに手を動かしてみたが、「この数値が高いのは問題なのか正常なのか」の判断ができなかった。正常値の感覚がなかったからだ。本は分解の語彙を教えてくれた。しかし、語彙を持っているだけでは足りない。その語彙を使って実際のシステムを何度も見て、「この数値はこのワークロードなら正常」「この数値は明らかに異常」という感覚を養う必要があった。本は地図を与える。しかし、地図を読む力は、歩かなければ身につかない。Rustを触って見えてきたもの「道具」と言った。では、その道具を手に入れることで、実際に何が変わるのか。私自身の経験を書く。Rustを学び始めたとき、最初は「速くて安全な言語」くらいの認識だった。C++の代替。メモリ安全。その程度の理解で、チュートリアルを写経していた。しかし、写経だけでは理解できなかった。私がRustの設計思想を理解できたのは、最初に「遊び」から入ったからだ。Rustを触り始めたとき、私は何の目的も持っていなかった。「何ができるんだろう」という純粋な興味だけがあった。課題を解こうとしていなかった。ただ遊んでいた。コンパイラに怒られた。Vec\u003cString\u003eを関数に渡した後で使おうとして、「value used here after move」と言われた。意味がわからなかった。「渡しただけなのに、なぜ使えなくなるんだ」と画面に向かって言った。所有権を無視したコードを書いて、なぜ通らないかを考えた。何の成果も出なかった。しかし、その「遊び」の時間がなければ、今の理解はなかった。遊びの中で、Rustの輪郭が見えてきた。何を許し、何を許さないか。どこで厳しく、どこで柔軟か。目的を持って触っていたら、目的の範囲内でしか見えなかっただろう。遊びは効率が悪い。成果が出ない。何をやっているか説明できない。だから、大人になると遊ばなくなる。すべてに目的を求める。しかし、目的を持つ前に遊んでおかないと、目的自体が貧しくなる。遊びの中で見つけた「面白い」が、後から課題認識の種になる。なぜ「遊び」が有効なのか、構造を言語化してみる。目的を持って触ると、「目的に関係するか否か」というフィルタが働く。Rustを「Webサーバーを書くため」に学んだら、所有権はHTTPハンドラの文脈でしか理解しない。しかし、遊びにはフィルタがない。所有権がなぜ存在するかを、用途を限定せずに考えられる。結果として、「この概念はHTTPに限らず、並行処理全般に適用できる」という広い理解に到達する。つまり、遊びの正体はフィルタなしの探索だ。効率は悪い。成果の予測ができない。しかし、目的というフィルタの外側にあるものを拾える。目的を設定した瞬間に見えなくなるものが、遊びの中では見える。しかし、これは「遊びを正当化する理論」になっていないか。3ヶ月遊んで何も身につかなかった経験もある。Haskellを触っていた時期だ。モナドが面白くて圏論の本まで買った。3ヶ月後、業務で使える場面は1つもなく、モナドの定義を聞かれても正確に答えられなかった。「フィルタなしの探索」は聞こえがいいが、フィルタがないまま3ヶ月歩いて、元の場所に戻っていることもある。遊びが実を結ぶかどうかは、事前にはわからない。それでも、遊ぶ。目的の枠内だけで学び続けた人間は、目的の枠を超えた発想ができない。撃ってみれば、案外簡単に怪物が倒せるかもしれない。 弾を込める前から「当たらないだろう」と言って撃たないのが、一番もったいない。遊びは、まだ名前のない怪物に向けて撃つ弾だ。外れるかもしれない。でも、撃たなければ当たりもしない。「遊び」と「無目的な浪費」の境界はどこか。この問いには答えを持っている。遊びの中で「おや？」と思った瞬間を記録しているかどうかだ。遊んでいて何かに引っかかる。引っかかりを言葉にしてメモする。なぜ引っかかったのかを考える。このループが回っているなら、遊びは探索として機能している。ループが回っていないならただ触って、ただ忘れるならそれは浪費だ。では、読者が「遊びから入る」を再現するにはどうすればいいか。私のやり方を書く。週に数時間、目的を決めずに技術を触る時間を確保する。そこでやることは、「業務で使う予定のないもの」を触ることだ。業務で使うものを触ったら、それは遊びではなく学習だ。遊びの条件は「役に立つかどうかわからないまま触る」ことだ。そして、触った後に「何が面白かったか」「何に驚いたか」を3行だけ書く。3行でいい。この3行が、半年後に「あのとき触った概念がここで効く」と気づく入口になる。そうして遊びながら書き込むうちに、Rustの設計思想が見えてきた。所有権、借用、ライフタイム。「データは誰かが所有し、借りるときは明示的に許可を得る」という世界観。最初は制約に感じた。慣れると、制約ではなく設計指針だと気づいた。すると、過去に書いたコードが違って見えてきた。「あのGoのコード、データ競合を起こしていなかったか」複数のgoroutineから同じデータに同時にアクセスしていた。動いていた。テストも通っていた。しかし、Rustの視点で見ると、あれは「たまたま動いていた」だけだ。タイミング次第でデータ競合を起こし、クラッシュする爆弾を抱えていた。「あのPythonのスクリプト、なぜ本番で落ちたのか」リストを関数に渡して、関数内で変更していた。呼び出し元は変更を想定していなかった。Rustなら、\u0026mutを要求するか、所有権を移動するかを明示する。意図しない変更は、コンパイル時に弾かれる。「あのC++のメモリリーク、なぜ気づかなかったのか」newしたオブジェクトをdeleteし忘れていた。コードレビューでも見落とした。Rustなら、所有者がスコープを抜けた時点で自動的に解放される。忘れようがない。Rustという方法を知る前は、これは「課題」ではなかった。「そういうものだ」と思っていた。方法を知ったことで、初めて「これは課題だったのだ」と気づいた。知らなかったときは、違和感すらなかった。動いていたから。テストが通っていたから。「動いているコード」は「正しいコード」だと思っていた。動くコードは正しい。しかし、正しくないコードも動く。方法の目的化と、方法を極めることは違うRustの例を書いた。「方法を知ることで課題が見える」。ここまでは良い。しかし、この主張をすると、必ず出てくる誤解がある。「方法を極めろ」と言うと、「方法の目的化」と混同される。でも、両者はまったく異なる。方法の目的化は、方法を使うこと自体が目的になっている状態だ。「Rustを導入した」ということに価値を見出し、それで何を解決するかを考えない。導入実績を作ることがゴールになる。「うちもRust使ってます」と言いたいだけ。技術ブログを書きたいだけ。私自身、この罠にハマったことがある。Kubernetesを導入したとき、「クラウドネイティブにした」こと自体に達成感を覚えていた。チームに導入を提案し、半年かけて移行した。技術ブログも書いた。しかし、Kubernetesで何を解決するかが曖昧だった。デプロイ頻度は週1回のまま変わらなかった。スケーリングが必要な負荷もなかった。私は「導入した」という実績を作っただけだった。本当にそうだろうか。あの導入がなければ、コンテナオーケストレーションの設計思想を学ぶ機会はなかった。結果として、その後のプロジェクトで活きた知識は多い。「目的化だった」と断じるのは、後知恵かもしれない。しかし、当時の私に「何の課題を解くために導入するのか」と問えば、答えに詰まったはずだ。目的化と極めることの境界は、後から振り返って初めて見える。渦中にいるときは、区別がつかない。区別がつかないなら、早期警戒サインを作るしかない。私が自分に課しているチェックリストがある。「導入すること」を誰かに報告したくなっているか。「この技術で何を解決したか」を聞かれたとき、具体的な数字で答えられるか。「別の方法でも同じ結果が出せたか」を検討したか。この3つのうち1つでもNoなら、目的化の兆候がある。Kubernetesのときは、3つともNoだった。「導入した」が将来の資産になるか自己満足で終わるかの分かれ目は、そこで学んだ知識が「その技術固有の知識」か「転用可能な原理」かにある。Kubernetesの場合、宣言的な構成管理の思想、reconciliation loopの設計パターン、自己修復するシステムの考え方これらはKubernetesを離れても使える知識だった。だから結果として資産になった。しかし、当時の私がそこまで意識していたかと問われれば、していなかった。結果オーライだ。方法の限界を学ぶには、その方法で失敗するしかない。Rustの限界は、Rustで書くべきでないものをRustで書いたときに見える。Kubernetesの限界は、Kubernetesで解けない問題にKubernetesを適用したときに見える。本を読んでも限界はわからない。限界は、壁にぶつかって初めて見える。だから、失敗事例を集める。自分の失敗、他人の失敗、撤退戦の記録。比較実験——同じ問題を別の方法で解いてみる——も有効だが、時間がかかる。失敗事例の方が効率がいい。他人の失敗は、最もコストの低い学習教材だ。方法を極めるとは、「この方法では解けない」と言えるようになることだ。「Rustでできること、できないこと」を肌感覚で知る。その知識によって、課題の認識範囲を広げる。方法はあくまで方法であり続ける。目的は課題解決のままだ。方法の目的化は視野を狭める。「Rustで解決できそうな課題」ばかりを探すようになる。自分の得意技で解ける問題だけが「問題」に見えてくる。方法を極めることは視野を広げる。「Rustでは解決できない課題」と「Rustで解決できる課題」の両方が見えるようになる。ハンマーの適用範囲を知っているから、釘でないものに無理にハンマーを振らない。同じ「学び」でも、到達点は正反対だ。複数の方法を知る意味。ただし、効果は線形ではないだから、方法は複数知っている方がいい。1つの方法しか知らないと、その方法で解決できる課題しか見えない。ハンマーしか持っていなければ、すべてが釘に見える。これは有名な認知バイアスだ。「道具の法則」と呼ばれることもある。でも、ハンマーもドライバーもレンチも知っていれば、「この課題はハンマー向きだ」「これはレンチの方がいい」「これはどの道具でも解けない、道具を作るところからだ」と判断できる。「複数知っている方がいい」と書いた。しかし、ここに罠がある。10個のフレームワークを表面的になぞるより、まず1つの本質を骨まで理解する方が、結果的に多くの応用が効く。なぜか。1つを深く知ると、「なぜそう設計されているか」が見えるからだ。設計の意図がわかると、別のフレームワークを見たとき、「ああ、これは同じ問題を別の方法で解こうとしているのか」と理解できる。表面的に10個知っていたときには、それぞれが独立した「覚えるべきもの」だった。1つを深く知った後は、10個が「1つの問題空間の異なる解」として見える。構造が見える。これが「深さが広さを生む」ということだ。深く知らないと、広くも知れない。しかし、見えるのは設計の意図だけではない。もう少し踏み込む。深く知ることで見えるのは、構造だ。Kubernetesを深く知ると、「宣言的な状態管理」「自己修復するフィードバックループ」という構造が見える。この構造は、Kubernetesだけのものではない。Terraformの設計にも同じ構造がある。Gitの設計にも近い思想がある。生物の恒常性維持にもフィードバックループはある。深く掘った人間は、ここで面白いことをする。Kubernetesで学んだ「自己修復」の構造を、まったく別の文脈に持ち込む。組織のインシデント対応プロセスに「宣言的な状態定義と差分検知と自動修復」の発想を適用する。一見まったく関係がない。しかし、構造が同じだから、機能する。つまり、深く掘るほど、遠いところから借りてこられるようになる。 具体的なレベルで借りると模倣だが、構造のレベルで借りると独自の解が生まれる。回転寿司がビール工場のベルトコンベヤーから着想を得たように、借り元が遠ければ遠いほど、生まれる発想は独自性を帯びる。深さは、隣接領域を広げるだけでなく、遠い領域への跳躍を可能にする。「広く浅く知っておけ」長い間、これが能力の理想像として語られてきた。多くの領域を浅く押さえておき、1つだけ深く持つ。私自身もそう信じていた時期がある。しかし、実際に深く掘る経験を積んだ後で振り返ると、このモデルには見落としがある。3つ書く。第一に、「広さ」と「深さ」を独立した軸として扱っている。あたかも、広さを先に確保してから深さを足せるかのように。しかし、実際に何かを深く掘った人間なら知っている。深さと広さは分離できない。バックエンドを深く掘ろうとした。するとDB設計が要る。パフォーマンスチューニングが要る。セキュリティの知識が要る。インフラの理解が要る。深く掘れば掘るほど、裾野が勝手に広がっていく。「幅」は意図して作るものではなかった。「深さ」の必然的な副産物だった。この構造を図形で表すなら、三角形だ。 深さが増すほど底辺が広がる山型。深く掘るから、隣接領域を避けて通れなくなる。避けて通れないから、広がる。この「避けて通れない」が重要だ。意図して広げたのではない。掘っていたら、そこにあったのだ。第二に、深さから生まれた広さと、表面をなぞった広さを同一視している。バックエンドを深く掘る過程で身につけたDB設計の知識は、「DBの種類を5つ言える」という知識とは質がまったく異なる。「このクエリがなぜ遅いのか、インデックスの構造から説明できる」隣接領域に必要に迫られて踏み込んだから、実践と結びついている。動機が伴っているから、定着する。表面をなぞっただけの知識は、実践と切り離されている。説明はできるが、使えない。使えない知識は、AIに聞くのと変わらない。逆に言えば、「幅が広い」のに「深さがない」人は、実はどこも掘っていないだけだ。表面を横にスライドしているだけで、どこにも根を張っていない。ここまでは「広く浅く」モデルの論理的な誤りを指摘した。しかし、もう1つ、時代の文脈がある。第三に、このモデルは「情報が希少な時代」の産物だ。何がどこにあるかを知っているだけで価値があった時代には、浅く広い知識に意味があった。会議で「それ、聞いたことがあります」と言えるだけで、情報のハブとして機能できた。今は違う。情報は溢れている。AIが整理してくれる。ツールの使い方、言語の文法、フレームワークの設定表面的な知識はAIに聞けば数秒で返ってくる。「広く浅く知っている」は、もはや人間が抱えておく価値がない。人間のボトルネックは「知っているかどうか」から「理解しているかどうか」に移った。そして「理解」は、深さからしか生まれない。深く掘った人間だけが違和感を持てる。表面をなぞった人間には、違和感すら生まれない。だから、「まず広く浅く学んでから深掘りしよう」という順序は逆だ。興味のある1点からまず掘る。掘っていくうちに、隣接領域が「必要だから」広がる。動機が伴うから、学習が定着する。「広く浅く」から入ると、どこにも三角形が立ち上がらない。平らな線が引かれるだけだ。AI時代に人間に求められるのは、平らな線ではない。どこかに深く根を張った三角形だ。と書いたが、1つ正直に告白する。「広く浅く」が役に立った場面がある。障害対応で、直接の原因はバックエンドにあったが、フロントエンドのキャッシュの挙動を薄く知っていたから、「これ、フロントのキャッシュが古いレスポンスを返し続けているのでは」と仮説を立てられたことがあった。深くは知らない。しかし、存在を知っていたから、調べる入口にたどり着けた。「浅い知識は無価値」と断言するのは、嘘になる。しかし、あの場面で役に立ったのは「フロントのキャッシュがあるらしい」という存在の知識であって、「フロントのキャッシュをどう設計するか」という実践の知識ではない。存在を知っている程度の知識なら、AIに「この症状の原因として考えられるものは？」と聞いても得られる。2026年のいま、「存在を知っている」だけの価値は急速に下がっている。三角形の話をした。深さが広さを生む、と。では、三角形は1つでいいのか。1つでは足りない。「深く学ぶ」は「1つだけ学ぶ」ではない。1つを深く学んだ上で、異なる前提を持つ方法を複数知ることで、メタ視点が生まれる。私の経験を書く。3つ目の方法を学んだとき、世界の見え方は劇的に変わった。1と2の比較ではなく、「方法を比較する」というメタ視点が生まれたからだ。スクラムとウォーターフォールの2つしか知らなかったとき、私は「どちらが正しいか」を考えていた。そこにカンバンという3つ目が加わったとき、「どの状況にどの方法が適するか」という問いに変わった。しかし、10個目を学んだとき、変化は小さかった。20個目はもっと小さかった。私の中に「方法を比較するフレームワーク」ができてしまえば、新しい方法は既存の棚に分類されるだけだ。劇的な視点の転換は起きにくくなる。つまり、方法数と課題認識の関係は線形ではない。最初の数個で急激に上がり、その後は緩やかになる。学習曲線の逓減だ。実感と合う話がある。人間が同時に頭の中で比較できる選択肢には限界がある。100個の方法を「知っている」としても、課題に直面したときに思い出せるのは、せいぜい数個だ。残りは長期記憶の奥底にあり、意識的に検索しなければ出てこない。さらに、方法が増えるほど「どれを使うか」の選択コストが上がる。10個の方法から最適なものを選ぶより、3個から選ぶ方が速い。速さは、実践において決定的に重要だ。完璧な方法を選ぶのに3時間かけるより、そこそこの方法で2時間で解決する方が、多くの時は正解だ。私の実感としては、こうだ。1つの領域で、異なる前提を持つ方法を3つ知っていれば、メタ視点が生まれる。5つを超えると、追加の認識拡張効果は急速に逓減する。 3つ目を手に入れた瞬間の感覚は、今でも覚えている。「あ、これは選べるんだ」と思った。それまでは「どちらが正しいか」だった問いが、「どの状況にどれが合うか」に変わった。景色が変わるというより、自分が立っている場所が高くなった感覚だった。だとすると、問いは「いくつ学ぶか」ではなく、「どの領域で最初の3つを学ぶか」になる。すでに10個の方法を知っている領域にもう1個追加しても、認識範囲は広がらない。まだ1つしか知らない領域で2つ目を学んだ方が、視野は大きく広がる。私の場合、インフラの知識があるから「これはアプリケーション層の問題ではなく、ネットワーク層の問題だ」と判断できることがある。プログラミング言語を複数知っているから「この問題はRustで書くべきか、Pythonで書くべきか」という選択ができる。これは課題を正しく認識するための前提条件だ。方法を1つしか知らない人は、その方法で解けない課題を「課題」として認識できない。見えないのだ。見えないものは、存在しないのと同じだ。「どの領域で3つを学ぶか」が大事だと書いた。では、新しい領域を学び始めたとき、最初にぶつかる壁は何か。「わからない」が多すぎることだ。ここで大事になるのが、「わからない」を保留する勇気だ。新しい領域を学ぶとき、すべてを理解しようとすると詰まる。「これはなぜこうなっているのか」「この部分は何の意味があるのか」。答えが出ないまま先に進めなくなる。しかし、学びは順序通りに進まない。後で学んだことが、前の疑問を解消することがある。Rustの所有権を最初に読んだとき、私は何もわからなかった。「なぜこんな制約が必要なのか」が見えなかった。ところが、並行処理を学んだ後、「ああ、これはデータ競合を防ぐためだったのか」と腑に落ちた。最初から全部わかろうとしていたら、所有権の章で止まっていた。「わからないけど、とりあえず進む」という保留ができたから、後で理解できた。わからないことを「わからないまま抱えておく」のは、気持ち悪い。すっきりしない。しかし、その気持ち悪さに耐えることが、学びの幅を広げる。わからないまま進む勇気が、後で理解する土壌を作る。私が見落としているもの。そして、見落としに気づいた経験正直に書く。Rustの可能性に興奮している。所有権システムで防げるバグの範囲が見えてきた。「これもコンパイル時に防げる」「あれも型で表現できる」と考える時間が増えている。しかし、その興奮の中で見落としていることがあるはずだ。量子コンピューティング、バイオテクノロジー、新素材、ロボティクス。これらの分野で何が起きているか、私はほとんど知らない。論文のタイトルは見る。ニュースは読む。でも、手を動かしていない。肌感覚がない。つまり、それらの領域に関しては、違和感すら持てない状態にいる。これは仮説ではない。過去に経験している。コンテナ技術が出てきたとき、私は「仮想マシンで十分だろう」と思っていた。VMwareの知識があった。課題は「いかに効率よくVMを立てるか」だと認識していた。Dockerの記事を読んでも、「軽量な仮想化」程度の理解で止まっていた。半年後、気づいたら周りはコンテナで動いていた。私だけがVMの最適化を議論していた。「なぜコンテナを使わないのか」と聞かれて初めて、自分が課題を誤認していたと気づいた。問いは「VMをいかに効率化するか」ではなく、「インフラの抽象化レイヤーをどこに置くか」だったのだ。その半年間で、私は何をしていたか。VMのリソース割り当てを最適化するスクリプトを書いていた。起動時間を30秒短縮するためにブートシーケンスを研究していた。マイグレーションの自動化ツールを設計していた。それ自体は技術的に面白かった。しかし、私は存在しない道路の渋滞を解消していた。結果として、チームの技術選定に私の意見は反映されなかった。「VMの専門家」としての発言権はあったが、「インフラ戦略」の議論では蚊帳の外だった。半年という時間は、取り戻せない。その間に私が書いたコードは、1行も本番で動いていない。学んでいれば気づけた。でも学ばなかった。「VMで十分」という認識が、学ぶ動機を奪っていた。課題が見えないから学ばない。学ばないから課題が見えない。悪循環だ。この悪循環には、もう1つ怖い特徴がある。外から見えないということだ。私は半年間、勤勉に働いていた。コードを書いていた。成果物を出していた。傍から見れば、貢献している。しかし、その貢献先がすでに陳腐化していた。誰も指摘してくれなかった。指摘できなかった。みんな忙しかったし、私の専門領域に口を出すのは気が引けたのだろう。あの半年の経験があるから、今の自分にも同じことが起きていないか問わずにいられない。「Rustで解決する」という発想に囚われ、別の方法で解くべき課題を、無理に型システムの問題として設定していないか。Rustで解けない課題を、「課題ではない」と無意識に切り捨てていないか。私にはわからない。わからないから、怖い。自分の視野の外側は、見えない。見えないことすら、わからない。これが一番怖い。そして、過去にそれで手遅れになった経験があるから、恐怖は具体的だ。学び続ける理由だから、最新技術を触り続ける。これは「技術が好きだから」ではない。いや、好きではあるのだが、それだけではない。課題を正しく認識し続けるための、必要な投資だ。学ぶことをやめた瞬間、課題認識は固定される。世界は変わり続けるのに、自分の課題認識だけが古いままになる。新しい方法で解ける課題が増えているのに、それを「課題」として認識できない。5年前の方法の知識で、今日の課題を設定しようとする。それは、一度もinvalidateされていないキャッシュを読んでいるようなものだ。値は返ってくる。ただし、現実とは一致していない。これが一番怖い。だから、学び続ける。と書いて、立ち止まる。本当にそうか。学び続ければ、視野は広がり続けるのか。それとも、学ぶことで見えなくなるものもあるのか。新しい方法を知ることで、古い方法の価値を見失っていないか。この問いに、私なりの答えを書く。学ぶことで見えなくなるものは、ある。Rustを深く学んだ結果、私は「シンプルさ」の価値を見失いかけたことがある。「これは型で表現すべきだ」「あれは所有権で制約すべきだ」と考えるうちに、「Pythonで10行で書けるスクリプトに、なぜ100行のRustが必要なのか」という問いを忘れていた。安全性だけを考えれば、すべてをRustで書くべきだ、と当時の私は思い込んでいた。しかし、それは問いの立て方が間違っていた。「安全か」ではなく、「この用途に適切か」という軸がある。「正しいか」ではなく、「理解しやすいか」という軸がある。Rustという方法を深く学んだことで、私は安全性の軸ばかりを見るようになっていた。シンプルさや可読性の軸が見えにくくなっていた。古い方法には、効率以外の価値があることがある。手動デプロイは、CI/CDより非効率だ。しかし、手動でやっていた頃は、デプロイの各ステップが何をしているか全員が理解していた。自動化した途端、パイプラインがブラックボックスになり、壊れたときに誰も直せなくなった。効率を得て、理解を失った。新しい方法を学ぶと、古い方法が「非効率」に見える。見えた瞬間、古い方法の別の価値、効率では測れない価値が視野から消える。これが、学ぶことで見えなくなるものだ。だから、学び続けることは万能ではない。学びながら、同時に「この方法では見えないものは何か」を問い続ける必要がある。新しい眼鏡をかけたら、古い眼鏡で見えていたものを意識的に思い出す必要がある。学び続けるとは、忘れたことを思い出し続けることでもある。AIが方法を知っている時代にここまで「方法を学べ」「学び続けろ」と書いてきた。しかし、1つ、避けて通れない問いがある。AIは方法を知っている。サンダリングハードも、カスケード障害も、制約理論も。私が半年かけて学んだことを、AIは数秒で答える。操作の知識、言語の文法、ツールの使い方は、もう人間の優位ではない。分解の知識すら、AIは構造的に提示してくれる。では、方法を学ぶ意味はなくなったのか。逆だ。AIは方法を知っている。しかし、違和感を持てない。エディタの前で手が止まる。「なんとなくうまくいっていない」と感じる。会議を増やしても改善しない焦りを覚える。AIにはこれがない。AIは聞かれたことに答える。聞かれなければ、黙っている。課題は、違和感から始まる。AIには、違和感がない。違和感は、好奇心を持って世界に触れている人間にしか生まれない。「何かがおかしい」と感じるためには、「こうあるべきだ」という自分なりの基準が必要だ。では、その基準はどこから生まれるか。4つある。方法を学ぶ過程で作り上げた技術的な基準。過去の失敗から刻まれた経験的な基準。「こういうシステムはあるべきではない」という価値観の基準。そして、画面の前で「なんか気持ち悪い」と感じる身体的な基準。言語化できないが、確かにそこにある直感だ。AIから借りた基準では、違和感は生まれない。借り物の基準は「なるほど」で終わる。自分の基準は「おかしい」から始まる。もう1つ。AIは汎用的な方法を知っているが、あなたの文脈を知らない。VMの最適化に半年を費やした私の後悔。Kubernetesを目的化して得た教訓。Rustの遊びの中で見つけた「面白い」。これらは私だけの経験であり、私だけの課題認識を形作っている。同じ障害を見ても、同じコードを読んでも、私とあなたでは見える課題が違う。その違いが、課題設定の独自性になる。AI時代に人間に残るのは、この2つだと思っている。好奇心。 違和感を持ち、「なぜ」と問い続ける力。自分だけの観点。 固有の経験が生んだ、代替不可能な視点。と書いて、立ち止まる。この主張自体がすでにコモディティ化している。AIに「人間の価値とは」と聞けば、「好奇心と固有の経験」と答えるだろう。「人間にしかできないことがある」と言いたい人間の願望が、透けて見える。しかし、コモディティ化していることと、間違っていることは違う。「テストを書け」も「コードレビューしろ」もコモディティ化した主張だが、依然として正しい。問題は、正しいかどうかではなく、この主張を自分の経験で検証できているかどうかだ。私の場合、VMの半年、Kubernetesの目的化、OOMKillerの夜——それらの経験を通じて好奇心と観点が鍛えられたという実感がある。実感がある、と思っている。思い込みかもしれない。方法はAIに聞ける。しかし、何を聞くかを決めるのは自分だ。好奇心がなければ、そもそも問いが生まれない。自分だけの経験がなければ、独自の問いにならない。ここにもう1つ、根本的な問題がある。障害対応のセクションで書いた「道の存在を知らなければ、歩き出すことも、誰かに道を聞くこともできない」という話——これがAI時代にはさらに先鋭化する。AIに聞けるのは、道の存在を知っている人間だけだ。 パフォーマンスが遅い。USEメソッドを知っている人間は「CPUのSaturationを確認して」とAIに聞ける。知らない人間は「遅いんですけど」としか言えない。AIは「遅い」から有用な回答を返すこともある。しかし、問いの精度が低ければ、本当に必要な情報にたどり着く確率は下がる。もっと怖いケースがある。問題の存在自体を認識していない場合だ。テストが通っている。本番も動いている。AIに何も聞かない。問題がないと思っているのだから、聞く理由がない。道があることを知らなければ、地図を広げることすらしない。だから、AI時代に必要なのは「AIに聞く力」だけではない。「ここに道がある」と気づく力だ。道の存在に気づくためには、自分の足で歩いた経験が要る。歩いたことがある人間だけが、まだ歩いていない方向にも道があるかもしれない、と想像できる。さらに、見落とされがちなことが2つある。第一に、AIの出力の質は、使う人間の力量で天井が決まる。AIが100点の回答を出しても、その領域の理解が浅ければ、100点の回答を100点として受け取れない。40点の回答と区別がつかない。私がKubernetesのマニフェストでやらかしたのは、まさにこれだ。画力のある人間がAI画像生成を使えば、構図・色彩・解剖学的正確さを的確に指示し、選別し、修正できる。画力のない人間は「なんかいい感じ」で止まる。コードも同じだ。型システムを理解している人間がAIにRustを書かせれば、生成されたコードの所有権設計が妥当かどうかを判断できる。理解していない人間は、コンパイルが通ればOKだと思う。自分で経験した。AIにKubernetesのマニフェストを生成させたことがある。出力されたYAMLは文法的に正しかった。デプロイも通った。しかし、resources.limitsが設定されていなかった。本番でOOMKillerに殺されるまで、私は気づかなかった——いや、正確に言えば、AIの出力を読んだとき、resourcesの記述がないことに違和感を持てなかった。Kubernetesのリソース管理を深く理解している人間なら、「limitsがない」ことに即座に気づく。私は当時、その解像度を持っていなかった。AIの出力は正しかった。私の目が足りなかった。AIは掛け算だ。 基礎力がゼロに近ければ、いくら掛けても結果は小さい。第二に、AIへの指示の質は言語化能力に依存する。AIは空気を読まない。「いい感じにして」では「いい感じ」の定義が共有されていないから、期待通りにはならない。人間の同僚なら、組織の文脈や過去の経緯から補完してくれる。AIにはそのコンテキストがない。ここに気づいたとき、私は苦笑した。AIを使いこなせない人は、実は人間相手のコミュニケーションでも伝わっていなかった可能性がある。人間相手では「察してもらえる」ことに甘えていただけだ。AIは「察する」能力がない分、伝わっていないという事実を可視化しているにすぎない。言語化能力とは、「なぜそう思うのか」「具体的にはどういう状態か」「何と何の間で迷っているのか」を自分に問い続ける習慣だ。これはAI活用のためだけのスキルではない。思考そのものの精度を上げる訓練でもある。障害対応中に「なんか変だ」と感じたまま言葉にせず、30分後にチームメイトが同じ違和感を言語化して、そこから10分で原因にたどり着いたことがある。私が30分間握りしめていた違和感と、彼が10秒で言語化した仮説は、同じものだった。言語化は正確さの問題であると同時に、速度の問題でもある。AIに「何を聞くか」を決める力は、どんな訓練で伸びるか。私が実感しているのは、観察→仮説→質問→検証の反復だ。まず、目の前の状況を観察する。次に、「こうなのではないか」という仮説を立てる。仮説を検証するための質問をAIに投げる。返ってきた答えを、自分の仮説と突き合わせる。この4ステップを愚直に回す。仮説なしにAIに聞くと、「いい感じにして」になる。仮説があると、「AとBのどちらが適切か、Cの条件下で比較して」になる。後者の方が、はるかに使える回答が返ってくる。そしてもう1つ、「自分だけの観点」を独りよがりにしないための条件がある。自分だけの経験で得た視点は、代替不可能だ。しかし、それが他者に伝わらなければ、組織では機能しない。「自分だけの観点」を「チームで使える知見」にするには、4つのステップが要る。言語化（経験を言葉にする）、検証（他の事例でも成り立つか確認する）、物語（なぜそう考えるに至ったかの経緯を語る）、データ（定量的な裏付けを添える）。全部揃わなくてもいい。しかし、言語化だけで止まると「俺の経験では」で終わる。検証とデータが加わると、初めて「組織の知見」になる。だから「方法を学べ」は、AI時代にこそ意味がある。AIに方法を聞くためではない。方法を通じて自分の目を鍛えるためだ。AIが答えを持っている時代に、問いを立てられる人間でいるために。おわりに「課題から入れ」は正しい。正しいが、この原則には暗黙の前提がある。「課題が見えている」という前提だ。見えていない課題を「そこから入れ」とは言えない。技の名前を知らなければ、負けた理由がわからない。わからなければ、直せない。だから方法を学ぶ。複数の方法を知る。「深く知ることで、何が見えるようになるか」を意識しながら。方法の探求は、課題の発見につながっている。方法を学ぶことで課題が見え、見えた課題から入る。「課題から入れ」の原則は、方法の学びによって初めて実行可能になる。と書いて、もう一度立ち止まる。冒頭で「課題から入れ」を批判した。課題が見えない人に「課題から入れ」と言うのは呪いだ、と。しかし、今の私は「方法を学べ」と言おうとしている。方法を学ぶための方法を持たない人に「方法を学べ」と言うのは、同じ構造の再生産ではないか。方法を学ぶ時間がある。本を買える。手を動かす環境がある。それは能力ではなく、環境の話だ。深夜まで障害対応に追われている人間に「本を読め」と言えるか。言えるとしたら、それは方法を持っている側の傲慢かもしれない。この記事自体が、ある種の恵まれた立場から書かれていることを、書きながら思う。それでも書く。書かないよりは、書いた方がいい。たぶん。1つだけ補足する。怪物を殺す手段は銀の弾丸だけではない。鉛の弾丸もある。特別な知識がなくても、地道に撃ち続ければ怪物は倒れることがある。泥臭い試行錯誤、ひたすらコードを書いて壊して直す繰り返し。華麗ではないが、弾数で勝負する方法だ。金の弾丸もある。売上は全てを癒す。予算があれば人を雇える。技術で解けない問題が、金で解けることはよくある。銀の弾丸、鉛の弾丸、金の弾丸。どれで撃つかを選べること自体が、方法の知識だ。そして、どの弾であれ、撃たなければ怪物は倒せない。明日からできることを書く。自分が「仕方ない」と思っているものを3つ書き出す。「毎週のレポートに5時間かかる」「チーム間の調整が遅い」「コードレビューが滞る」何でもいい。「仕方ない」と思っている時点で、そこには方法の知識が足りていない可能性がある。その領域で自分が知っている解決アプローチがいくつあるか数える。1つなら、2つ目を探す。2つなら、3つ目を探す。3つ以上あるなら、別の「仕方ない」に移る。注意点がある。同じ前提を持つ方法を3つ知っても視野は広がらない。前提の異なる方法を選ぶことで、初めてメタ視点が生まれる。「仕方ない」は、方法を知らないサインだ。 そこに、学ぶべき方法がある。エディタには、いつの間にか文章が並んでいた。最初の一行が出てこなかったはずなのに、気がつけばここまで書いている。あの日の私が知りたかったのは、「課題の見つけ方」ではなかった。「見つけるための道具」だったのだ。問いの立て方が間違っていた。たぶん、ずっと間違えていた。間違えていることを、わかりたくなかったのかもしれない。わからないことにしておいた方が、楽だったのかもしれない。「課題って、どうやって見つけるんですか」。あの問いへの答えを、ようやく書ける気がする。方法を学べ。そうすれば、課題の方からお前に見えてくる。おい、方法を学べ。","isoDate":"2026-02-09T09:02:40.000Z","dateMiliSeconds":1770627760000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"正しさは、昼間の言葉","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/04/002244","contentSnippet":"ある日の終電後。オフィスには私しかいなかった。蛍光灯は半分消えている。デスクのモニターだけが、青白い光を放っている。IRCの通知は止まっている。誰も見ていない。誰も知らない。今、私がここで何をしても、誰にも分からない。三時間前、本番環境で障害が発生した。顧客からの問い合わせが殺到した。Nagiosのアラートチャンネルが真っ赤に染まった。私はオンコール担当だった。原因を調査した。特定した。十五年前に書かれたコードの中に、バグがあった。なぜ今頃発火したのか。おそらく、長らく使っていたNFSの性能が落ちていたからだ。十五年間、たまたま踏まなかった地雷を、今夜ついに踏んだ。バグは十五年前からそこにあった。ただ、表に出てこなかっただけだ。障害は収束した。暫定対応でサービスは復旧した。しかし、根本原因を修正しなければ、また同じ障害が起きる。明日の朝までに、修正をリリースしなければならない。画面には、十五年前に書かれたコードが映っていた。変数名は tmp と data と result の三種類しかない。コメントは一行もない。テストは存在しない。一つの関数が八百行ある。その関数の中に、さらに三重のネストしたif文がある。読んでいると、頭が痛くなる。しかし、このコードは動いてきた。十五年間、今夜まで、一度も止まることなく、毎日数万件のトランザクションを処理してきた。私は、二つの選択肢の前で立ち尽くしていた。正しいやり方——リファクタリングする。テストを書く。変数名を直す。関数を分割する。その上で、バグを修正する。それには、最低でも三週間かかる。明日の朝には間に合わない。その間、同じ障害が再発するリスクを抱え続ける。間違ったやり方——このコードの該当箇所に、場当たり的なパッチを当てる。動けばいい。テストは書かない。後で直す。いつか直す。たぶん、直さない。私は知っていた。後者を選べば、このコードはさらに腐る。次にこのコードを触る人は、私を呪うだろう。しかし、その「次の人」は、私ではない。——と書いて、立ち止まる。本当にそうか。「次の人」は、来年の私かもしれない。それでも、私は迷っていた。「正しいコードを書け」。私は、何度もこの言葉を聞いてきた。本で読んだ。カンファレンスで聞いた。先輩に言われた。自分でも言ってきた。SOLID原則。DRY原則。クリーンアーキテクチャ。テスト駆動開発。私は、これらの「正しさ」を信じてきた。信じていた、と思っていた。しかし、終電後のオフィスで、十五年物のレガシーコードを前にして、障害の再発リスクを抱えながら、私は気づいた。「正しさ」は、昼間の言葉だ。昼間は、みんながいる。コードレビューがある。品質基準がある。「正しさ」を語ることで、評価される。「リファクタリングしましょう」と言えば、「意識が高い」と思われる。しかし、夜になると、誰もいない。誰も見ていない。「正しさ」を語る相手がいない。残っているのは、障害の再発リスクと、明日の朝というデッドラインだけだ。私は思い出した。以前、ある先輩が言っていた言葉を。「コードの美しさなんて、障害対応の現場には関係ない。止血が先だ」当時の私は、反発した。「技術的負債がたまる」「保守性が下がる」「長期的に見れば損だ」。正論を並べた。先輩は笑って聞いていた。今になって分かる。あの笑いの意味が。先輩は、私の「正しさ」が、まだ試されていないことを知っていた。本番障害の修羅場を経験したことがない。顧客からのクレームの電話を受けたことがない。自分の判断で、会社の信用が左右される経験をしたことがない。そういう人間が語る「正しさ」は、空論だ。——と書いて、自分の中にある別の声が聞こえる。それは、本当にそうか。「試されていない」ことが、「正しくない」ことの証明になるのか。試されていなくても、正しいものは正しいのではないか。しかし、その夜の私には、その声は届かなかった。私は、キーボードに手を置いた。そのとき、ふと考えた。十五年前、このコードを書いた人は、何を考えていたのだろうか。きっと、同じような状況だったのではないか。締め切りに追われていた。リソースが足りなかった。「後で直す」と自分に言い聞かせて、このコードを書いた。その人も、テストを書かなかった。変数名を直さなかった。コメントを書かなかった。なぜか。時間がなかったからだ。その人の後に来た人も、同じだったのではないか。このコードを見て、顔をしかめた。しかし、直さなかった。なぜか。時間がなかったからだ。そして今、私がここにいる。同じ選択を迫られている。「時間がなかった」。この言葉が、十五年間、このコードを腐らせ続けてきた。そして今、私も同じ言葉を使おうとしている。これは、正当化の連鎖だ。「前の人も時間がなかった。だから、自分も許される」。前例が、免罪符になる。私は、その連鎖の中に自分を位置づけようとしていた。連鎖の一部になれば、責任は薄まる。「自分だけが悪いわけではない」と言える。責任を、過去に分散させることができる。——と書いて、その論理の欺瞞に気づく。責任を分散させても、コードは腐ったままだ。連鎖に加わることで、私が得るのは心理的な安心だけだ。コードは何も改善しない。しかし、その夜の私には、心理的な安心が必要だった。私は、自分を正当化する論理を組み立て始めた。この会社は、このプロダクトで売上を立てている。プロダクトが止まれば、顧客は離れる。顧客が離れれば、売上は下がる。売上が下がれば、会社は傾く。会社が傾けば、私は職を失う。正しいコードを書いている間に、サービスが止まり続けたら、何の意味がある？障害を早く直すことは、顧客のためだ。会社のためだ。同僚のためだ。そして、自分のためだ。みんなのためにやっている。だから、許される。この論理は、強力だ。「自分のため」だけなら、罪悪感がある。しかし、「みんなのため」なら、むしろ正義になる。利他的な動機があれば、手段は正当化される。私は、この論理に身を委ねようとしていた。しかし、ふと気づいた。十五年前の人も、同じ論理を使ったのではないか。「顧客のために、早くリリースしなければ」「会社のために、間に合わせなければ」。そう言い聞かせて、このコードを書いた。その結果が、今夜の障害だ。「みんなのため」という論理で書かれたコードが、十五年後に「みんな」を苦しめている。私は、同じことをしようとしている。今夜、「みんなのため」にパッチを当てる。そのパッチが、十五年後に誰かを苦しめる。正当化の論理は、短期的には機能する。しかし、長期的には破綻する。「みんなのため」は、「将来のみんな」を含んでいない。——と書いて、また立ち止まる。では、どうすればいいのか。障害を放置して、明日も明後日も顧客を苦しめることが、「将来のみんな」のためになるのか。どちらを選んでも、誰かを苦しめる。それが、この状況の本質だ。コードを書いている途中で、手が止まった。私は、自分が何をしているのか、急に分からなくなった。画面には、私が追加したパッチがある。八行。たった八行の条件分岐だ。バグの原因となっていたエッジケースを、特別扱いする。根本的な解決ではない。しかし、これで障害は再発しなくなる。たぶん。私は、自分のコードを見つめた。そして、気づいた。私は、このコードを十五年後に見る誰かを、呪っている。私は、十五年前にこのコードを書いた誰かを呪った。「なぜこんなコードを書いたのか」「なぜテストを書かなかったのか」「なぜリファクタリングしなかったのか」。呪いながら、同じことをしている。十五年後の誰かは、私を呪うだろう。同じ言葉で。同じ怒りで。そして、同じように、さらに八行のパッチを追加するだろう。呪いの連鎖だ。私は、その連鎖の一部になろうとしている。連鎖を断ち切ることもできる。リファクタリングすればいい。テストを書けばいい。しかし、それには三週間かかる。明日の朝には間に合わない。連鎖を断ち切るコストを、私は払えない。いや、払う気がない。コストを払う気がないのは、なぜか。それは、連鎖を断ち切る恩恵を受けるのが、私ではないからだ。リファクタリングの恩恵を受けるのは、十五年後の誰かだ。その誰かは、私ではないかもしれない。私は、十五年後にはこの会社にいないかもしれない。別のプロジェクトにいるかもしれない。そもそも、このプロダクト自体が、十五年後には存在しないかもしれない。コストは今の私が払い、恩恵は未来の誰かが受ける。それなら、コストを払わない方が、合理的だ。私は、その論理に抗えなかった。気がつくと、窓の外が明るくなっていた。目が痛い。徹夜明けの頭が、鈍く重い。始発の電車が走る音が聞こえる。オフィスのエアコンが、タイマーで動き始めた。私の目の前には、完成したパッチがあった。テストはない。コメントは一行だけ。「障害対応: エッジケースの特別処理を追加」。それだけだ。なぜそう書いたのか。どんな判断をしたのか。何も書かない。書けない。いや、違う。書かないのだ。書くと、自分がやったことを認めることになる。認めたくない。だから、曖昧にする。ステージング環境でテストした。動いた。本番環境にデプロイした。障害は再発しなかった。アラートは鳴らなかった。IRCに報告を書いた。「根本原因を修正しました。再発防止策は別途検討します」。「別途検討します」。この言葉が、どれほどの問題を先送りしてきたか。私は知っている。知っていて、使っている。私は、椅子にもたれかかった。疲れていた。しかし、安堵もあった。終わった。障害は収束した。顧客は救われた。私の仕事は終わった。そして、私は立ち上がって、オフィスを出た。朝の光が、眩しかった。夜の間に考えていたことが、すべて嘘のように思えた。「正しさ」も「正当化の連鎖」も「呪いの連鎖」も、夜の闘いの産物だ。朝になれば、消える。いや、消えるのではない。見えなくなるだけだ。朝の光の中で、私は「普通のエンジニア」に戻る。「正しいコードを書くべきだ」と語る。「技術的負債は早めに返すべきだ」と主張する。昼間の私は、そう言う。しかし、また夜が来る。また障害が来る。誰もいないオフィスで、同じ選択を迫られる。そのとき、私は何を選ぶか。私は、自分が何を選ぶか、もう知っている。この文章を読んでいるあなたは、どうだろうか。「私は違う」と思っているかもしれない。「私は正しいコードを書いている」「私はリファクタリングをしている」「私は技術的負債を返している」。そう思っているかもしれない。本当にそうだろうか。あなたは、一度も「後で直す」と言ったことがないか。一度も、テストを書かずにコミットしたことがないか。一度も、分かりにくいコードをそのまま追加したことがないか。一度も、「別途検討します」と書いたことがないか。ないはずがない。私たちは、みな同じ箱の中にいる。状況が許せば、正しいことをする。しかし、状況が許さなければ、正しさを捨てる。そして、「仕方なかった」と自分を正当化する。これは、個人の問題ではない。箱の問題だ。締め切りがある。障害対応の緊急性がある。リソースが足りない。時間が足りない。この箱の中で、「正しさ」を貫くことは、英雄的な行為だ。普通の人間には、できない。——と書いて、自分でも分かっている。「箱を変える」と言うのは簡単だ。実際に変えるのは、難しい。私自身、何度も挫折してきた。しかし、箱を変えようとしなければ、私たちは永遠に同じ場所にいる。夜ごとに「正しさ」を捨て、朝になると何事もなかったかのように振る舞う。その繰り返しだ。私は、その繰り返しから抜け出したい。しかし、抜け出せることを、確信できない。この矛盾を抱えたまま、私は今日もコードを書いている。あの夜から、三ヶ月が経った。私が当てたパッチは、まだ動いている。障害は再発していない。顧客からのクレームもない。障害対応は成功した。誰も、あのコードの中身を知らない。しかし、私は知っている。あのコードの中に、たった八行のパッチがあることを。テストがないことを。コメントが一行しかないことを。「別途検討します」と書いた根本対応が、まだ検討されていないことを。そして、いつか誰かが、あのコードを触ることになる。そのとき、その人は私を呪うだろう。「なぜこんなパッチを当てたのか」「なぜ根本対応をしなかったのか」と。私は、その呪いを受け入れる準備ができている。いや、できていない。受け入れなければならないと分かっているだけだ。次の障害が来たとき、私は何を選ぶか。「正しさ」を選ぶか。また同じ論理に堕ちるか。私自身にも、分からない。分からないまま、今日も私はオフィスに向かう。昼間は「正しさ」を語り、夜になれば「正しさ」を捨てる。その繰り返しの中で、私は何者になっていくのか。十五年前の人は、一度だけ選択した。その選択の結果が、今夜の障害だった。しかし、エンジニアは、毎日選択を迫られる。毎日、小さな「正しさ」を捨てるか、守るかを選ぶ。その積み重ねが、私たちを作る。そして、十五年後のコードを作る。私は、どんなエンジニアになりたいのか。どんなコードを残したいのか。その問いに、まだ答えられない。答えられないまま、今日も私は、コードを書く。十五年前の人の行方は、誰も知らない。私の行方も、私自身が知らない。","isoDate":"2026-02-03T15:22:44.000Z","dateMiliSeconds":1770132164000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、分けて語るな","link":"https://syu-m-5151.hatenablog.com/entry/2026/02/02/124615","contentSnippet":"はじめに月曜日は経営会議。事業戦略を話す。水曜日は技術戦略会議。アーキテクチャを話す。金曜日は組織開発会議。チーム編成を話す。それぞれの会議には、それぞれの参加者がいる。経営会議には経営陣。技術戦略会議にはエンジニアリングリーダー。組織開発会議には人事と各部門長。それぞれが、それぞれの言葉で、それぞれの関心事を語る。私はいろんな立場でこれらの会議に呼ばれる。そして、いつも同じ違和感を覚える。「この話、別の会議でも関係あるんじゃないの？」言えない。言っても通じない。経営会議で「それ、アーキテクチャの話と関係ありませんか」と言っても、「それは技術の話だから水曜日に」と返される。技術戦略会議で「それ、組織の問題では」と言っても、「それは人事の話だから金曜日に」と返される。きれいに分かれている。整然としている。効率的に見える。分断は、様々な形をとって現れる。会議の分断。言葉の分断。評価指標の分断。事業部門は売上で評価される。技術部門はシステムの安定性で評価される。人事部門は採用数と離職率で評価される。それぞれが、自分のKPIを最適化しようとする。そのKPIが、会議を分け、言葉を分け、関心を分ける。分断が最も激しくなる瞬間がある。計画変更のときだ。市場が変わった。競合が動いた。顧客のニーズが変化した。そのとき、事業戦略は変わる。しかし、技術戦略は変わらない。組織体制も変わらない。なぜか。計画変更は「誰かの責任」を問うことになるからだ。変更を認めると、最初の計画が間違っていたことになる。だから、誰も変更を言い出さない。計画通りに進めて、最後に「間に合いませんでした」と言う方が、傷が浅い。分断が弱まる瞬間もある。危機のときだ。システムが落ちた。顧客からクレームが殺到した。そのとき、部門の壁は一時的に消える。全員が同じ部屋に集まり、同じ問題に向き合う。しかし、危機が去ると、また元に戻る。危機対応は例外であり、日常ではない。日常に戻れば、分断も戻る。私は何度も見てきた。月曜の経営会議で決まった「3ヶ月で新機能をリリースする」という事業戦略が、水曜の技術戦略会議で「今のアーキテクチャでは6ヶ月かかる」と判明する。金曜の組織開発会議で「その機能を作れるエンジニアがいない」と分かる。3つの会議で、3つの事実が、別々に語られる。しかし、誰も全体を見ていない。分業には理由がある。効率だ。専門家が専門領域に集中できる。会議の時間は短くなる。責任は明確になる。組織が大きくなれば、分けなければ回らない。それは、正しい。ここで、一つ認めておくべきことがある。分けることには、正当な理由がある。「統合して議論する」は綺麗だ。しかし、関係者が増えるほど会議は重くなる。境界をまたぐ話は論点が多くなり、合意形成も難しくなる。「決められない組織」になるリスクがある。市場は待ってくれない。分けて速く回す方が勝つ局面は、確かにある。私も、全員参加の会議が延々と続いて何も決まらない組織を見てきた。あれを見ると、「分けた方がいいのでは」と思う気持ちは分かる。さらに言えば、サイロには「心理的安全性の防波堤」としての機能もある。組織には「安心して話せる範囲」が必要だ。小さな範囲（サイロ）があるから、本音や問題が出る。越境を強制すると、政治が混ざって発言が萎縮し、かえって問題が隠れることがある。全員参加の場は、評価や立場を気にして「無難な話」になりがちだ。だから、私が言いたいのは「分けるな」ではない。分けることの正当性は認める。「分けたまま、境界の情報を消すな」——これが、私の言いたいことだ。——と書いて、自分でも分かっている。「境界の情報を消すな」と言うのは簡単だが、消さないためにどうするかが難しいのだ。分業は必要だ。しかし、分業の効率は「誰にとっての効率か」を問う必要がある。会議運営は効率化される。意思決定者の認知負荷は下がる。しかし、その恩恵を受けるのは会議を設計する側であり、しわ寄せを受けるのは境界で仕事をする人々だ。調整コスト、手戻り、後から判明する「言ってくれれば」。これらは、分業の効率がもたらす隠れたコストだ。しかし、その効率の代償として、境界の情報が消える。消えるのは「事実」ではない。事実は、それぞれの会議で語られている。「3ヶ月で新機能を出す」は事実だ。「今のアーキテクチャでは6ヶ月かかる」も事実だ。「その機能を作れるエンジニアがいない」も事実だ。消えているのは、事実と事実をつなぐ「前提」と「代替案」だ。「この技術的制約があるから、この事業戦略は実行不可能だ」という前提。「機能を絞れば3ヶ月で出せる」という代替案。「採用が間に合わないなら、この部分は外注する選択肢もある」というリスク回避策。これらは、どの会議の議題にもならない。境界情報が消えたことは、どうすれば分かるか。沈黙で分かる。会議で「他部門への影響は？」と聞いたとき、誰も答えられない。手戻りで分かる。開発が進んでから「これ、最初に言ってくれれば」と言われる。会議の往復で分かる。月曜に決まったことが、水曜に覆り、金曜にまた覆る。責任の押し付けで分かる。「それは技術の問題」「それは事業の判断」「それは人事の話」。押し付けが始まったら、境界情報が消えている証拠だ。境界情報が生き残るケースもある。特定の人物が媒介しているときだ。複数の会議に出席し、それぞれの文脈を理解し、翻訳できる人。しかし、その人に依存すると、その人が異動したり退職したりすると、情報は途切れる。人ではなく、仕組みで残す必要がある。事業の会議で「技術的な制約と代替案」を議題に入れる。技術の会議で「事業インパクト」を必須項目にする。形式を変えなければ、境界情報は消え続ける。事業の会議では技術の話は「水曜に」と先送りされる。技術の会議では組織の話は「金曜に」と先送りされる。誰の責任でもないから、誰も語らない。分けた瞬間に、最も大事な情報が抜け落ちている。前回、私は「おい、戦略を語れ」と書いた。戦略とは「選択」であり、「何をやらないかを決めること」だと。目標を入れる。スローガンを入れる。希望を入れる。妥協を入れる。蓋を閉じて、「戦略」というラベルを貼る。それは戦略ではない、と。syu-m-5151.hatenablog.comしかし、書き終えてから気づいた矛盾がある。「何をやらないかを決める」には、「何ができるか」を知らなければならない。技術的に可能なことを知らなければ、事業戦略は選択できない。組織の能力を知らなければ、実行可能性は判断できない。戦略を語るためには、事業・技術・組織を「分けて」考えてはいけなかったのだ。今回は、その続きを書く。事業と技術と組織と戦略を、別々に語ることの危険性について。これは、そういう自分への苛立ちから始まった文章だ。私自身、無意識に分けていた。「事業のことは経営が決める」「技術のことは自分たちで決める」「組織のことは人事が決める」。それぞれの領分を侵さない。それが「プロフェッショナル」だと思っていた。しかし、それは本当にプロフェッショナルだったのか。単に、考えることから逃げていただけではないか。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。「何をやるか」と「どうやるか」の分離多くの組織で、こんな分業が成立している。経営が「何をやるか」を決める。開発が「どうやるか」を決める。事業戦略が「What」を定義し、技術戦略は「How」を担う。依存の矢印は「事業 → 技術」の一方向。経営会議で方針が決まり、それが開発チームに「降りてくる」。開発チームは、降りてきた仕様を実装する。きれいな分業だ。責任が明確だ。経営は経営の仕事をする。開発は開発の仕事をする。この分業が成立する前提がある。経営が「Howは後で決めればよい」と信じていることだ。Whatさえ決まれば、Howは技術者がなんとかする。技術は手段であり、事業の下流にある。そう信じている。技術側にも、この分業を受け入れる理由がある。Whatを所与として受け取る方が、楽だからだ。事業戦略に口を出せば、責任が生じる。「仕様通りに作りました」と言えば、失敗しても言い訳できる。Whatに関与しないことは、責任回避の手段でもある。さらに、評価制度がこれを強化する。技術者は「技術的な成果」で評価される。事業への貢献は、評価項目に入らないことが多い。しかし、この前提には反例がある。技術発で市場を作るケースだ。iPhoneは「タッチスクリーンでアプリが動く」という技術的可能性が、事業を規定した。AWSは「サーバーを時間単位で借りられる」という技術が、クラウドビジネスを生んだ。Howが先にあり、Whatが後から来た。組織能力が先に制約になるケースもある。「AIを活用したパーソナライゼーション」という戦略があっても、データサイエンティストがいなければ実行できない。Whatを先に決めても、Howの制約で実現不可能になる。「What → How」の一方向モデルは、現実を単純化しすぎている。そして、この単純化には実害がある。この分業は、組織の可能性を無意識に狭めている。なぜか。「どうやるか」が「何ができるか」を規定するからだ。例を挙げよう。あるプロダクトチームで、新機能の開発が議論されていた。経営会議で「この機能を3ヶ月で出す」と決まった。開発チームに降りてきた。しかし、開発チームは頭を抱えた。今のアーキテクチャでは、その機能を追加するのに6ヶ月かかる。密結合なモノリスで、特定の部分だけを変更することが難しい。開発チームは「3ヶ月は無理です、6ヶ月かかります」と報告した。経営は「なんとかしろ」と言った。開発チームは無理をした。品質を犠牲にした。技術的負債が積み上がった。次の機能追加は、さらに時間がかかるようになった。これは、珍しい話ではない。むしろ、日常的に起きている。問題は、どこにあるのか。開発チームの能力不足か。経営の無理解か。どちらでもない。問題は、「何をやるか」と「どうやるか」を分けて考えたこと自体にある。もし、アーキテクチャがモジュール化されていたら。特定の機能を切り出して、独立して開発できる構造になっていたら。3ヶ月で出せたかもしれない。あるいは、1ヶ月で出せたかもしれない。つまり、技術的な選択が、事業の選択肢を規定している。逆もまた真だ。技術が事業を規定するだけでなく、事業の方向性が、技術的な選択を正当化する。「このセグメントの顧客を取りに行く」という事業判断があるからこそ、「この部分をマイクロサービスとして切り出す」という技術判断が意味を持つ。事業の方向性なしに技術判断だけがあると、「なぜそのアーキテクチャなのか」が説明できない。事業と技術は、双方向に影響し合っている。一方向の依存関係ではない。私は以前、この双方向性を無視した組織をいくつか見てきた。どれも同じパターンに陥る。アーキテクトがアーキテクチャを設計する。マネージャーが組織を設計する。それぞれが、それぞれの会議で、それぞれの論理で。アーキテクトは「理想的なシステム構成」を描く。マネージャーは「効率的なチーム編成」を考える。両者が同席することはない。数ヶ月後、問題が起きる。チームAとチームBが、同じコードベースに手を入れる必要が出てくる。しかし、チームは別の部門に所属している。コミュニケーションパスがない。マージコンフリクトが頻発する。リリースの調整に時間がかかる。「なぜこんなことになったのか」と誰かが問う。答えは単純だ。組織の設計とアーキテクチャの設計が、別々に行われたからだ。コンウェイの法則を知っている人は多い。「組織構造がアーキテクチャに影響する」。私も何度も引用してきた。しかし、知っていることと、実践することは違う。私自身、何度もこの法則を引用しておきながら、組織設計に口を出すことは避けてきた。「それは自分の領域ではない」と。結果、アーキテクチャの提案が実装されないまま終わることが何度もあった。組織が変わらなければ、アーキテクチャは変わらない。当たり前のことだ。しかし、その当たり前を、私は見て見ぬふりをしていた。戦略と組織能力の不可分性同じ問題が、戦略と組織の間にもある。多くの企業が「何をやるか（戦略）」を先に決め、「誰がどうやるか（組織能力）」を後回しにする。戦略会議で、美しいスライドが映し出される。「我々は、AIを活用した次世代プラットフォームを構築する」。参加者はうなずく。ビジョンは明確だ。方向性は正しい。しかし、誰がそれを作るのか。今の組織に、その能力があるのか。ない場合、どうやって獲得するのか。採用か。育成か。外部委託か。それには、どれくらいの時間がかかるのか。これらの問いは、戦略会議では議論されない。「それは人事の話だから」と先送りされる。結果、戦略は「願望」に留まる。実行可能性を欠いた計画になる。私も、同じ過ちを犯したことがある。あるプロジェクトの戦略会議で、私は組織能力の話を一切しなかった。「それは人事部門の仕事だ」と思っていた。技術的には正しい方向だった。市場分析も悪くなかった。しかし半年後、プロジェクトは頓挫した。実行する人がいなかったのだ。戦略は正しかった。ただ、誰もそれを実現できなかった。これは、戦略と呼べるものではない。願望だ。「こうなったらいいな」を紙に書いただけだ。「誰が、どうやって、いつまでに」を書けないものは、戦略ではなく詩だ。良い戦略には、実行可能性が組み込まれている。「何をやるか」と「誰がどうやるか」は、同時に議論されなければならない。さらに厄介なのは、事業領域によって必要な組織能力が根本的に異なることだ。例えば、エンタープライズSaaSと、HRソリューションを考えてみよう。どちらも「SaaS」だ。しかし、勝ち方が違う。エンタープライズSaaSでは、競合との機能差が短期間で縮まる。だから、高速な同質化が勝敗を分ける。競合が出した機能を、素早く追随する。実装スピードが命だ。必要なのは、高速に開発できるエンジニアリング組織だ。一方、HRソリューションでは、顧客データを活用した差別化提案が価値の源泉になる。データサイエンスや顧客理解の深さが求められる。必要なのは、データを扱える人材と、顧客の業務を深く理解するドメインエキスパートだ。同じ「SaaS」でも、必要な開発スタイル、営業モデル、採用すべき人材像が根本的に異なる。戦略を語るなら、組織能力を語らなければならない。逆に、組織能力を語るなら、戦略を語らなければならない。私はかつて、ある企業の「AI戦略」を聞いたことがある。美しいスライドだった。「機械学習を活用してパーソナライゼーションを強化する」。しかし、その会社にはデータサイエンティストが一人もいなかった。「採用する予定です」と言っていた。一年後、まだ一人も採用できていなかった。戦略だけがあって、実行する能力がない。それは戦略ではない。絵に描いた餅だ。内製か外注かという問いの本質「内製すべきか、外注すべきか」。この問いも、事業・技術・組織を分けて考えると、間違った答えを出しやすい。技術の視点だけで考えると、「今のチームにその技術がないから、外注しよう」となる。合理的に見える。今持っていない能力を、外部から借りる。効率的だ。しかし、外部委託は「今持っていない能力を一時的に借りる」行為だ。短期的な補完にすぎない。問題は、勝ち筋を支える中核能力は、外部から買えないことだ。中核能力（コアコンピタンス）は、試行錯誤を通じて組織に蓄積される。失敗から学び、改善を重ね、暗黙知が形成される。外注で失われるのは「何をしたか」ではない。コードを見れば「何をしたか」は分かる。失われるのは「なぜそうしなかったか」の記憶だ。例えば、「なぜこのAPIはRESTではなくgRPCにしたのか」。コードを見れば「gRPCを使っている」ことは分かる。しかし、「最初はRESTで作ったが、レイテンシ要件を満たせず、2週間かけてgRPCに移行した」という経緯は、ドキュメントには残りにくい。「RESTでも工夫すれば動いたが、将来のスケーラビリティを考えてgRPCにした」という判断の背景は、人の頭にしか残らない。外注先の担当者が変わったとき、この記憶は消える。次に同じ判断を迫られたとき、組織はまた2週間を失う。「今回は外注で」を繰り返すと、何が起きるか。組織の中に何も残らない。プロジェクトは完了する。成果物は納品される。しかし、それを作る能力は、組織の中にない。次に同じようなことをやろうとすると、また外注することになる。これは、競争優位の源泉を自ら手放していることに等しい。もちろん、すべてを内製する必要はない。競争優位に関係ない部分は、外注でいい。しかし、「この能力が勝ち筋を支える」と判断したなら、時間がかかっても内製すべきだ。この判断をするには、事業戦略と技術戦略と組織戦略を、同時に見る必要がある。では、「同時に見る」とは具体的にどういうことか。ここで参考になるのが、ドメイン駆動設計の考え方だ。「一緒に変わる概念は、一緒にしておけ」。新機能を追加する際、どの概念が連動して変化するか。それらを1つのまとまりとして整理すると、それがドメインになる。逆に言えば、一緒に変わる概念を別々のチームに分けると、調整コストが爆発する。事業戦略：どの市場で、どう勝つのか技術戦略：そのためにどんな技術的優位性が必要か組織戦略：その優位性を支える能力を、どう構築・維持するかこれら3つは、一緒に変わる。事業戦略が変われば、技術戦略も変わる。技術戦略が変われば、必要な組織能力も変わる。一緒に変わるものを、別々の会議で、別々の人が議論していては、正しい判断はできない。技術が事業の選択肢を創出する技術の側から見ると、この関係はより具体的に見える。優れたアーキテクチャは、事業の選択肢を増やす。例えば、こんな状況を考えてみてほしい。競合が新機能をリリースした。市場が反応している。うちも追随したい。普通なら半年かかる開発だ。しかし、うちのシステムはモジュール化されている。既存のモジュールを組み合わせれば、1ヶ月で検証できる。これは、技術的な選択が、事業の機動性を生んでいる。別の例。ある顧客セグメント向けに、機能を絞った廉価版を出したい。普通なら、別プロダクトとして作り直す必要がある。しかし、うちのシステムは機能がモジュール化されている。特定のモジュールだけを切り出して、別プランとして販売できる。これは、技術的な選択が、事業モデルの柔軟性を生んでいる。逆に、技術的負債が蓄積すると、事業の選択肢が狭まる。新機能を追加したい。しかし、コードが複雑すぎて、どこを触ればいいか分からない。影響範囲が読めない。テストがない。触ると壊れる。結果、機能追加のコストが指数関数的に増大する。「やりたいけど、できない」が増えていく。事業の選択肢が、技術的負債によって奪われていく。では、アーキテクチャとは何のためにあるのか。「コードを綺麗にする」ためではない。「事業の機動性を高める」ための戦略的投資だ。ただし、「機動性」という言葉は曖昧だ。事業側が腹落ちするには、もっと具体的に語る必要がある。事業側に説明するとき、「モジュール化しました」では伝わらない。「この投資によって、競合が新機能を出したとき、追随までの期間が6ヶ月から2ヶ月に縮まります」と言えばいい。「この機能を落としたとき、他に影響が出ないので、撤退判断が3ヶ月早くできます」と言えばいい。時間の話をする。機会損失の話をする。撤退の容易さの話をする。経営が理解できる言葉で語る。——と書いて、立ち止まる。これは本当だろうか。私はこれまで、事業の言葉で語ってきただろうか。「このコードは密結合で」「テストカバレッジが低くて」と言い続けてきたのではないか。分かりやすく整理しているが、自分ができていなかったことを、さも正解のように語るのは、どうなのか。それでも、書く。できていなかったからこそ、書く。この視点がないと、アーキテクチャの議論は「技術者の自己満足」に見えてしまう。経営からすると、「なぜそんなことに時間をかけるのか」となる。技術的負債の返済は後回しにされる。結果、事業の選択肢がどんどん狭まる。忘れられない言葉がある。以前、一緒に仕事をしたCEOが言った。「エンジニアはみんな潔癖性だ。いつも技術的負債だの、システムの書き直しだのと言っている」。正直、腹が立った。しかし、同時に、自分のことを言われている気もした。私は技術的負債の説明をするとき、どんな言葉を使っていただろうか。「このコードは密結合で」「テストカバレッジが低くて」「デプロイパイプラインが」。技術者には通じる。しかし、経営者には通じない。通じないどころか、「また技術の話か」と思われていたかもしれない。そのCEOの言葉は、不当だった。しかし、そう思われてしまう構造を作ったのは、私たちでもある。「技術的負債を返済すると、機能追加のスピードが2倍になります」と言えばよかった。「このリファクタリングで、新規市場への参入が3ヶ月早まります」と言えばよかった。技術の話を、事業の言葉で語る。それができていなかった。技術と事業を分けて考えているから、こうなる。いや、違う。私が、分けて語っていたから、こうなった。現場が握る「隠れた変数」ここまで、組織のレイヤーで話をしてきた。しかし、組織が動くのは、個人が動くからだ。組織構造を変えても、個人が動かなければ、何も変わらない。次は、個人のレイヤーで話をしよう。現場でコードを書くエンジニアは、プロダクトの「手触り」を一番知っている。「今のアーキテクチャなら、実はこんな機能も低コストで実現できる」「これだけのものを作るには、一度基盤を整備してから一気に作ったほうが速い」「この部分を先に切り出しておけば、将来の拡張が楽になる」これらは、経営会議では見えない。事業戦略のスライドには載らない。現場だけが知っている「隠れた変数」だ。しかし、多くのエンジニアは、これを声に出さない。「事業のことは経営が決めること」「自分の仕事は、決まった仕様を実装すること」「事業戦略に口を出すのは、越権行為だ」無意識に、自分の領分を技術領域に限定してしまう。事業戦略を「所与のもの」「固定された定数」と捉えてしまう。しかし、現場からのインサイトが、経営会議の決定をひっくり返すべき場面がある。「その機能、今のアーキテクチャだと6ヶ月かかりますが、この部分を先にリファクタリングすれば、3ヶ月で出せます。しかも、その後の機能追加も速くなります」これは、事業判断を変えうる情報だ。しかし、エンジニアが「自分の仕事は実装だけ」と思っていたら、この情報は経営に届かない。エンジニアが技術戦略を磨くことは、経営に対して「このルートならもっと速く、高く登れる」という登山ルートを提案することだ。降りてきた仕様をこなすだけの存在ではない。事業の未来を提案する「シンクタンク」であり、それを最速で形にする「実行部隊」だ。しかし、この意識を持つことは、簡単ではない。なぜなら、「実装担当」に留まる方が、楽だからだ。私自身、長い間「実装担当」に留まっていた。事業戦略は「上」が決めるもの。自分の仕事は、降りてきた仕様を高品質に実装すること。そう思っていた。なぜか。その方が楽だからだ。事業戦略に口を出さなければ、責任を取らなくていい。「仕様通りに作りました」と言えば、失敗しても自分のせいではない。しかし、その「楽さ」には代償がある。自分の仕事の意味を、他人に委ねることになる。「なぜこれを作るのか」を自分で理解していないまま、コードを書く。モチベーションが上がらない。「作れと言われたから作った」。それは、職人の仕事ではない。ある時期から、変えようとした。事業戦略の文書を読むようになった。経営会議の議事録を見せてもらうようになった。「なぜこの機能が必要なのか」を、実装前に質問するようになった。最初は煙たがられた。「エンジニアがビジネスに口を出すな」という空気を感じたこともある。しかし、続けていると、変わってくる。「この機能、技術的にはこうすればもっと早く出せますが、どうしますか」という会話ができるようになる。事業判断に、技術的な選択肢を提供できるようになる。降りてくる仕様を待つ存在から、仕様を一緒に作る存在に変わる。エンジニア以外にも当てはまるここまでエンジニアの話をしてきた。しかし、「現場の知見が経営に届かない」という構造は、エンジニアに限った話ではない。専門性を持つ人が、その専門性ゆえにサイロに閉じ込められる。この構造は、あらゆる専門職に当てはまる。デザイナーの話をしよう。私が一緒に仕事をしたデザイナーに、Aさんという人がいた。Aさんは、ある機能のモックを見た瞬間、「これ、誰も使わないですよ」と言った。私は「なぜ分かる」と聞いた。「導線が3クリック深い。離脱します」。彼女は正しかった。リリース後、その機能の利用率は5%だった。しかし、Aさんはその機能の企画会議に呼ばれていなかった。「UIの話は後で」と言われていたのだ。後で呼ばれたときには、もう要件は固まっていた。Aさんにできたのは、決まった要件を「見やすく」することだけだった。本質的な導線の問題は、触れられなかった。PMも、セールスも、カスタマーサクセスも、同じ構造の中にいる。それぞれが、顧客や市場の「手触り」を知っている。しかし、その知見が意思決定の場に届くことは稀だ。届いたとしても「参考情報」として扱われ、決定を覆すことはない。専門性を持つ人が、事業戦略に影響を与えられる。これが、本質的な構造だ。しかし、多くの組織では、専門性が「サイロ」に閉じ込められている。デザイナーはデザインの会議に出る。PMはPMの会議に出る。それぞれが、自分の領域だけを語る。経営会議には呼ばれない。呼ばれたとしても、「報告」のためだ。「意思決定」のためではない。分けているから、全体が見えない。見えている人の声が、届かない。不確実性を飼いならすための対話事業と技術と組織を統合して考える理由は、もう一つある。不確実性への対処だ。どんな計画も、想定通りには進まない。技術的な挑戦には、不確実性がつきまとう。「想定より時間がかかる」「パフォーマンスに問題が出る」「思った通りに動かない」。これらは、避けられない。問題は、この不確実性が顕在化したときに、どう対処するかだ。事業と技術を分けて考えていると、こうなる。技術側で問題が起きる。開発が遅れる。技術チームは「なんとかします」と言う。無理をする。品質を犠牲にする。それでも間に合わない。最後の最後で「すみません、間に合いません」と報告する。事業側は怒る。「なぜもっと早く言わなかったんだ」。これは、フィードバックループが壊れている状態だ。あるべき姿は、こうだ。技術側で問題が起きる。その事実を、即座に事業側にフィードバックする。「この技術的課題があります。対処には追加で2ヶ月かかります」。事業側は、その情報を受けて、戦略を再検討する。「2ヶ月遅れるなら、機能を絞って先に出そう」「このセグメントは後回しにして、別のセグメントを先に取りに行こう」。技術の不確実性が、事業戦略を動的に更新する材料になる。私が見てきた中で、うまく機能していたフィードバックループには、ある傾向があった。問題が判明したら、「なんとかなるかもしれない」で抱え込まずに、早めに共有していた。中間管理職を経由すると情報が歪むので、技術リーダーが直接、事業の意思決定者に伝えていた。「遅れます」だけでなく、理由と代替案もセットで。——もっとも、これがどの組織でも通用するかは分からない。「直接伝える」が政治的に難しい組織もある。それでも、報告した人を責めない文化がなければ、どんな仕組みも機能しない。「遅れます」と言った人を責めた瞬間、次から「遅れます」は聞けなくなる。責めるほど、嘘が増える。これは、事業側にも当てはまる。市場環境が変わる。競合が予想外の動きをする。顧客のニーズが変化する。これらの情報は、技術側の優先順位を変えうる。「この機能は後回しでいい。代わりに、こっちを急いでほしい」。計画は「確定したもの」ではない。「継続的に更新されるもの」だ。しかし、実際には多くの組織が計画を「約束」として扱う。「3ヶ月後にリリースすると言ったじゃないか」。この言葉が出た瞬間、計画は更新できなくなる。変えることは「約束を破ること」だから。分けて考えていると、それぞれが自分の計画を守ろうとする。変化に抵抗する。結果、組織全体が硬直化する。「計画＝約束」になってしまうのは、なぜか。一つは評価制度だ。「計画通りに達成したか」で評価される。計画を変更すると、達成率が下がる。だから、変更を避ける。計画通りに進めて、最後に「外部要因で達成できませんでした」と言う方が、評価上は有利になる。もう一つは顧客へのコミット構造だ。「この機能を3ヶ月後に提供します」と顧客に約束している。変更すると、顧客との信頼関係に影響する。だから、社内の計画変更が許されない。さらに文化の問題もある。「一度決めたことは守る」が美徳とされる組織では、計画変更は「意志が弱い」と見なされる。合理的な理由があっても、変更を言い出しにくい。これらを変えるには、評価制度を「計画通り」ではなく「成果」で評価する。顧客へのコミットを「機能」ではなく「価値」でする。文化として「計画変更は適応であり、失敗ではない」と認める。簡単ではないが、ここが変わらないと、フィードバックループは機能しない。分離が生む「責任の空白地帯」分けて考えることには、もう一つの弊害がある。責任の空白地帯が生まれる。こんな状況を想像してほしい。新プロダクトがローンチした。しかし、売れない。事業側は言う。「プロダクトの品質が悪い。技術の責任だ」。技術側は言う。「要件が曖昧だった。事業の責任だ」。組織側は言う。「人が足りなかった。採用が追いつかなかった」。誰も責任を取らない。責任が、部門の境界に落ちている。責任の空白地帯は、悪意から生まれるのではない。制度が再生産している。KPIを見てほしい。事業部門は売上で評価される。技術部門はシステムの安定性で評価される。「事業と技術の連携」を評価する指標は、どこにもない。予算も同じだ。事業予算と技術予算は別に管理される。「境界をまたぐ問題」に使える予算は、どちらの予算からも出しにくい。稟議も同じだ。事業の稟議と技術の稟議は、別のルートを通る。「両方に関わる案件」は、どちらのルートでも通りにくい。空白地帯で起きる典型的な現象がある。なすりつけ——「それは技術の問題だ」「いや、要件が曖昧だった」。回避設計——対話を避けるために、技術的な回避策を作る（後述するフロントエンドチームのように）。冗長な仕組み——同じ情報を、事業用と技術用に別々に管理する。二重管理——両方の部門が同じことを別々にやる。私が技術顧問として入った、ある会社の話をしよう。その会社には、二つのチームがあった。ユーザー向けのウェブサイトを担当するフロントエンドチーム。社内向けAPIを運用するプラットフォームチーム。フロントエンドチームはマーケティング部門に所属していた。プラットフォームチームはIT部門に所属していた。部門が違う。上司が違う。KPIも違う。両チームの関係は、最悪だった。会話がない。Slackのやりとりも最小限。必要なときだけ、冷たいチケットが飛ぶ。私は最初、技術的な問題だと思っていた。APIが遅い。エラーが多い。パフォーマンスチューニングをすれば解決する、と。しかし、掘り下げていくと、違った。問題は、技術ではなく、人間関係だった。発端は、一年前のインシデントだった。ウェブサイトがダウンした。原因はAPIの障害。しかし、経営陣はフロントエンドチームを責めた。「なぜ監視していなかったのか」「なぜ障害を検知できなかったのか」。プラットフォームチームには、何も言わなかった。フロントエンドチームは、怒った。自分たちのせいではない。しかし、責められた。プラットフォームチームとは、もう協力したくない。そこで、彼らは技術的な解決策を選んだ。APIからデータを抽出し、自分たちのデータベースに保存する仕組みを作った。「あいつらに依存しなければ、責められずに済む」。私は、その設計図を見て、頭を抱えた。データの同期処理。キャッシュの整合性チェック。障害時のフォールバック。複雑なシステムが、一枚の紙に描かれていた。これは、技術的な解決策ではない。人と話したくないから、システムを複雑にしているだけだ。案の定、問題は悪化した。データの不整合が起きる。「商品の価格がウェブサイトと管理画面で違う」というクレームが来る。フロントエンドチームは「プラットフォームチームのデータがおかしい」と言う。プラットフォームチームは「フロントエンドの同期処理がおかしい」と言う。責任のなすり合い。問題の根本は、誰も見ていない。私は、両チームのリーダーを同じ部屋に呼んだ。最初は気まずかった。しかし、一時間ほど話していると、お互いの不満が見えてきた。フロントエンドチームは「APIが遅いから、ユーザー体験が悪くなる。それで自分たちが責められる」と言った。プラットフォームチームは「APIの改善を提案しても、予算がつかない。経営はフロントエンドばかり見ている」と言った。両チームとも、被害者意識を持っていた。そして、その被害者意識が、アーキテクチャに反映されていた。話したくないから、システムを分ける。責任を取りたくないから、境界を作る。その結果、システムは複雑になり、問題が増え、さらに話したくなくなる。悪循環だ。これは、分けて考えることの必然的な帰結だ。私はこのエピソードを振り返るたびに、あるパターンに気づく。両チームとも、悪意があったわけではない。むしろ、それぞれが合理的に行動した結果、全体としてはうまくいかなくなった。これは、私だけが見た現象ではない。組織論では「構造的無能化」と呼ばれる。組織の考えたり実行したりする能力が、合理的に下がっていく現象だ。成熟した組織にとって、ほとんど宿命のようなものだ。そのメカニズムはこうだ。まず断片化が起きる。分業化が進み、縦割りになる。次に不全化が起きる。変化の兆しを察知しても、自分の領域ではないから動けない。最後に表層化が起きる。問題の根本に手を付けられず、場当たり的な対応を繰り返す。フロントエンドチームがデータベースを作ったのは、まさにこの表層化だ。根本的な解決（チーム間の対話）を避け、技術的な回避策（自前のDB）を選んだ。事業戦略は事業部門の責任。技術戦略は技術部門の責任。組織戦略は人事部門の責任。それぞれが、自分の領域だけに責任を持つ。しかし、成果は、領域の境界で生まれる。プロダクトが売れるかどうかは、事業戦略だけでは決まらない。技術戦略だけでも決まらない。組織戦略だけでも決まらない。三つが噛み合って、初めて成果が出る。分けて考えていると、この「噛み合わせ」に誰も責任を持たない。それぞれが自分の領域を最適化しようとする。しかし、部分最適の総和は、全体最適にならない。さらに、分けることは認知負荷を増やす。私がよく見るのは、本来は不要な調整、整合性の確認、コミュニケーションのオーバーヘッドだ。フロントエンドチームがプラットフォームチームと話すためだけに、週に2時間の会議を設定する。その会議で話す内容は、同じチームなら5分で済む。分けたことで、本質的でない仕事が増える。では、誰が全体を見るのか。CEOか。CTOか。プロダクトマネージャーか。私の経験では、肩書きは関係なかった。大事なのは「誰が」ではなく「どうやって」だった。全体を見る「人」を任命するより、全体を見る「機会」を作る方が効果的だった。むしろ、肩書きに頼ると失敗する。「それはCTOの仕事だ」「それはCEOが考えること」。そう言って誰も動かない組織を、何度も見てきた。私が見た中でうまくいっていた組織には、一つの習慣があった。月曜の朝会で、各チームが「先週、他チームから聞いた話」を30秒で共有する。「営業チームから聞いたんですが、顧客がこの機能の使い方で困っているらしいです」「インフラチームから聞いたんですが、このAPIの負荷が想定の3倍らしいです」。内容は何でもいい。「他チームから聞いた」という形式が重要だ。強制的に越境させる。最初は形式的だった。「特にありません」で済ませる人もいた。しかし、3ヶ月ほど続けると変わってくる。「あ、それ、前に営業の人が言ってましたよね」という会話が、会議の外で自然に生まれる。6ヶ月後には、「他チームから聞いた話」を集めるために、意識的に他チームと話すようになる。全体を見る「人」を任命するより、全体を見る「機会」を作る方が、よほど効果的だった。ここで、一つの反論に答えておきたい。「統合しても、責任は明確にならず、むしろ曖昧になるのではないか」という懸念だ。これは、正しい。統合すると「みんなで決めた」になって、誰も責任を取らない別種の無責任が生まれる。「合議の免責」だ。境界があると「ここから先はこの責任者」と決めやすい。統合は、その明確さを失わせる。私が見てきた組織でも、「全員で議論して、全員で決めた」結果、うまくいかなかったとき誰も責任を取らなかったケースがある。だから、越境と責任の明確化は、両立させなければならない。統合して議論するが、決定は一人が行う。「みんなで決めた」ではなく、「みんなの情報をもとに、この人が決めた」にする。——言うのは簡単だ。しかし、これを実践するのは難しい。最終決裁者を決めると、「自分の意見が通らなかった」と不満を持つ人が出る。合議の方が、波風が立たない。だから、組織は合議に流れる。それでも、誰かが決めなければならない。決めた人が責任を持つ。これを曖昧にすると、分断と同じ問題が起きる。越境するということでは、どうすればいいのか。自分の領域を超えて、考える。発言する。それぞれが、自分の専門性を持ちながら、他の領域にも関心を持つ。これは、「全員がゼネラリストになれ」という話ではない。専門性は維持したまま、境界を越えて対話するということだ。ここで、よくある誤解に触れておきたい。越境を推しすぎると、専門性が薄まるのではないかという懸念だ。全員が「半分だけ分かる人」になり、技術の判断が雑になり、事業の理解が単純化され、組織の問題はスローガン化する。この懸念は正当だ。私自身、越境を意識するようになってから、技術の深い部分に割く時間が減った気がする。最新のフレームワークを追う余裕がなくなった。コードを書く時間が減った。「全体を分かる」ことと「専門が深く鋭い」ことは、トレードオフの関係にある。両方を同時に極めることはできない。だから、越境とは「専門性を捨てる」ことではない。エンジニアがビジネスを学ぶのは、ビジネスの専門家になるためではない。自分の技術的判断を、ビジネスの文脈で説明できるようになるためだ。2割の時間で、他の領域で何が起きているかを知る。それだけで、残り8割の専門領域の判断が変わる。——と言いながら、私は本当に8:2でやれているだろうか。正直、分からない。越境に時間を使いすぎて、技術の深さが失われていないか。その不安は、常にある。私が見てきた中で、うまくいっているチームは「独立」と「孤立」を混同していなかった。自分たちで決められることは自分たちで決める。しかし、他チームとの依存関係は認識している。必要なときは、ちゃんと話す。分けることは、孤立させることではない。依存関係を認識し、意図的に管理することだ。問題は、分けた瞬間に依存関係を忘れてしまうことにある。エンジニアは、エンジニアリングの専門家であり続ける。しかし、その専門性を、事業の文脈で語れるようになる。「このアーキテクチャは技術的に美しい」ではなく、「このアーキテクチャは事業の機動性を高める」と語る。事業担当は、ビジネスの専門家であり続ける。しかし、技術的な制約と可能性を理解する。「なぜできないのか」ではなく、「どうすればできるのか」を一緒に考える。ただし、ここで一つ注意がある。「越境」と聞くと、「相手の言葉で話せばいい」と考えがちだ。技術者なら経営の言葉を学び、経営者なら技術の言葉を学ぶ。それ自体は悪くない。しかし、「すべてを一つの言葉に翻訳しろ」と言っているのではない。すべてを財務言語や経営の言葉に翻訳すると、技術的な微妙なニュアンスが失われる。「このAPIのレイテンシが50msから200msに悪化する」を「ユーザー体験が悪化する」と翻訳すれば、経営には通じるかもしれない。しかし、50msと200msの差がどれほど深刻か、どのユースケースで問題になるか、という技術的な判断の根拠は消える。組織の話も同じだ。「チームの心理的安全性が低い」を「生産性が下がっている」と翻訳すれば、経営指標には載る。しかし、なぜ安全性が低いのか、誰と誰の間に問題があるのか、という組織特有の文脈は失われる。事業の話も同じだ。「この顧客セグメントは価格感度が高い」を「値下げすれば売れる」と翻訳すれば、技術チームには分かりやすい。しかし、なぜ価格感度が高いのか、競合との関係はどうか、という市場の文脈は消える。翻訳は、情報を圧縮する行為だ。圧縮すれば、必ず何かが失われる。翻訳で失われてはいけない情報がある。判断の根拠だ。「このAPIは遅い」は翻訳できる。「ユーザー体験に影響がある」と。しかし、「なぜ遅いのか」「どのユースケースで問題になるのか」「どうすれば速くなるのか」という判断の根拠は、翻訳で消えやすい。翻訳の失敗には典型パターンがある。数値の意味が変わる——「50msから200msに悪化」が「ちょっと遅くなる」に翻訳される。因果が消える——「テストがないからリリースに時間がかかる」が「リリースが遅い」に短縮される。責任が曖昧になる——「この設計判断には、こういうトレードオフがあった」が「技術的な事情」に丸められる。対策は二重記録だ。経営向けの短い翻訳と、技術や組織の原文脈を、両方残す。経営会議の資料には「ユーザー体験に影響がある」と書く。同時に、技術的な詳細は別のドキュメントに残し、参照できるようにする。翻訳は「圧縮」だが、原文を捨てる必要はない。「詳細はこちら」というリンクがあればいい。だから、越境とは「自分の言葉を捨てて、相手の言葉で話す」ことではない。自分の言葉を保ちながら、相手の言葉も理解することだ。技術者が経営の言葉を学ぶのは、自分の技術的判断を捨てるためではない。技術的判断を、経営が理解できる形で伝えるためだ。そして同時に、経営の言葉で語られた制約を、技術的な文脈に引き戻して考えるためだ。専門性を持った人たちが、それぞれの専門性をリスペクトしながら、共通のゴールに向かって越境し合う。それは、言語を統一することではない。複数の言語が交差する場所で、対話することだ。私はあるとき、同じ会議で同じ資料を見ていたエンジニアと営業が、まったく違う結論を出すのを見た。エンジニアは「これは技術的に難しい」と言い、営業は「これは売れる」と言った。同じ資料だ。同じ数字だ。しかし、見えている世界が違う。それぞれが、自分の専門性に基づいた「解釈の枠組み」で見ている。エンジニアはコードの複雑さを見ている。営業は顧客の反応を見ている。どちらも正しい。しかし、見ているものが違う。組織の中で起きている「わかりあえなさ」は、この解釈の枠組みの間に溝ができていて、しかもそのことに気づいていない状態だ。溝があることに気づかないから、「なぜ分からないんだ」「なぜ伝わらないんだ」と苛立つ。対話とは、溝を埋めることではない。溝に橋を架けることだ。溝は前提としてあり続ける。エンジニアと営業の見ている世界は、完全には一致しない。しかし、橋があれば、行き来できる。相手の世界を訪れ、自分の世界に戻ってくる。その往復が、越境だ。情報が流れる仕組み「越境せよ」と言うのは簡単だ。しかし、越境するには材料がいる。相手の世界で何が起きているかを知らなければ、質問も提案もできない。越境するためには、情報が流れる仕組みが必要だ。多くの組織で、情報は縦に流れる。経営から現場へ。現場から経営へ。しかし、横には流れにくい。技術チームで起きていることは、事業チームには見えない。事業チームで議論されていることは、技術チームには届かない。それぞれが、自分のサイロの中で仕事をしている。これを変えるには、意図的な設計が必要だ。ここで、別のアプローチに触れておきたい。「常に一緒に話す」のではなく、境界を前提にしたインターフェース（契約）を設計すればいいのではないかという考え方だ。依存関係は消せない。ならば、「越境」より「情報の受け渡しの形式化」を磨くべきだ、という主張だ。制約（SLO、人員、期限）を明文化し、変更時の通知ルールを作る。「同席して統合」より「契約で連携」の方がスケールする、と。この考え方には一理ある。いや、一理どころか、実際に機能している組織を見てきた。境界を明確にし、インターフェースを定義し、変更時の通知ルールを作る。日常的な連携は、これで十分だ。私自身、あるプロジェクトでAPI仕様書とSLOを明文化しただけで、チーム間の調整コストが激減するのを見た。ただ——問題は、インターフェースに書かれていない依存関係が発見されたときだ。「この事業判断が、技術に影響するとは思っていなかった」。そういう場面で、インターフェースは機能しない。「期限が1ヶ月延びました」という通知は届く。しかし、「なぜ延びたのか」「その延長が事業にどう影響するのか」は、インターフェースでは伝わらない。契約に書かれていない依存関係は、対話でしか発見できない。だから、どちらか一方ではない。日常的にはインターフェースで効率的に連携し、境界をまたぐ問題が発生したときや、計画変更があったときには、対話で補う。当たり前のことを言っているように聞こえる。しかし、この「当たり前」ができている組織は、驚くほど少ない。では、私自身はどうだったか。ある会社で、技術戦略会議に事業担当を呼んでもらったことがある。最初は「技術の話だから関係ない」と言われた。しかし、「アーキテクチャの選択が、3ヶ月後の機能追加速度に影響します」と説明したら、参加してくれた。その会議で、事業担当は「そんなに影響があるとは知らなかった」と言った。私は「そうなんです」と言った。そして、なぜ今まで呼ばなかったのかを考えた。面倒だったからだ。調整コストを払いたくなかったからだ。別の会社では、事業戦略のドキュメントを技術チームにも共有してもらうようにした。最初は「読まないでしょ」と言われた。確かに、読まない人もいた。しかし、読む人もいた。読んだ人が「この戦略なら、このアーキテクチャは合わない」と気づいた。それだけで、価値があった。これらは、コストがかかる。効率は下がるかもしれない。しかし、分断のコストを計算したことがあるだろうか。私が関わったあるプロジェクトでは、事業部門と技術部門の認識のずれを修正するのに、毎週2時間の会議を3ヶ月続けた。それでも修正しきれず、最終的に機能の30%を作り直した。作り直しにかかった工数は、最初から一緒に話し合っていれば発生しなかったものだ。分断は「効率的」に見える。しかし、その効率は幻想だ。後から払うコストを、先送りしているだけだ。なぜ変われないのかここまで読んで、「分かった、越境しよう」と思った人もいるかもしれない。しかし、それだけでは変わらない。私自身、何度も経験してきた。「越境すればこんなにいいことがある」と説明した。「対話すれば問題が解決する」と語った。しかし、魅力的な提案が受け入れられないのは、魅力が足りないからではなかった。相手が受け入れたくない理由があるからだ。ある会社では、「今のやり方で回っているのに、なぜ変える必要があるのか」と言われた。惰性だ。今のやり方に慣れている。変える理由がない。私はこの種の人たちを何度も見てきた。出世競争から降りて、自分のペースで仕事をこなし、昼休みには決まった仲間と弁当を食べ、定時に帰る。悪い人たちではない。むしろ、穏やかで、職場の潤滑油になっていることもある。しかし、変化の話をすると、途端に顔が曇る。「それ、本当に必要ですか」「今のままでも回っていますよね」。彼らにとって、改善か改悪かは問題ではない。変えること自体が脅威なのだ。長い時間をかけて築いた居場所。慣れた仕事の流れ。気心の知れた同僚との関係。今の自分を成り立たせているものが、壊されるかもしれない。その不安が、あらゆる変化への抵抗になる。私は最初、この人たちを「抵抗勢力」だと思っていた。説得すれば分かってくれる、と。しかし、あるとき気づいた。彼らの反応は、合理的だ。変化のコストを払うのは彼らだ。新しいやり方を覚える。慣れた関係が崩れる。評価の仕方が変わる。一方、変化の恩恵を受けるのは誰か。たいてい、変化を推進した側だ。「改革を成功させた」と評価されるのは、推進者だ。コストを払う人と恩恵を受ける人が違う。それなら、抵抗するのは当然ではないか。私が「越境しよう」と言うとき、そのコストを誰が払うのか。私ではない。現場の人たちだ。私はその認識が、ずっと欠けていた。別の会社では、「それをやる余裕がない」と言われた。労力だ。相手の言葉を学ぶコスト、会議を調整するコスト、認識のずれを修正するコスト。その余裕がない。また別の会社では、「あなたに何が分かる」と言われた。感情だ。専門性へのプライド。自分の領域に口を出されることへの反発。そして、「上から押し付けられた」と感じた瞬間、内容に関係なく拒否される。心理的反発だ。これが一番厄介だった。魅力をいくらアピールしても、これらの抵抗があれば動かない。魅力をいくら積み上げても、抵抗が1つあれば動かない。掛け算のどこかにゼロがあれば、答えはゼロだ。むしろ、魅力を強調するほど、「押し付けられている」という反発が強まることすらある。私の経験では、最も強い抵抗は心理的反発だった。「誰が言うか」の問題だ。同じ内容でも、言う人によって受け入れられ方が違う。外部の人間が言うと「現場を知らないくせに」と反発される。内部の人間が言うと「自分の領域を広げようとしている」と疑われる。拒否しているのは「内容」ではなく「手続き」や「語り手」であることが多い。内容に反論できないから、手続きに難癖をつける。「そのやり方は聞いていない」「なぜ事前に相談しなかったのか」。内容ではなく、プロセスで拒否する。抵抗を下げる最小の一歩は何か。会議に一人、他部門の人を呼ぶ。それだけでいい。最初は「オブザーバー」として。発言しなくてもいい。ただ、聞いているだけでいい。その一人がいることで、「他部門から見たらどう見えるか」を意識するようになる。それが、越境の始まりになる。だから、私は変えた。魅力を語る前に、抵抗を減らすことを考えるようになった。惰性を崩す小さな一歩を提案する。労力を下げる仕組みを作る。感情に配慮する。押し付けではなく、選択肢として提示する。それでも、うまくいかないことは多い。個人の努力では足りないここまで「越境せよ」と書いてきた。しかし、ここで立ち止まって、自分の主張を疑う必要がある。「越境せよ」は、誰に言っているのか。越境の権限がない人に言っても、負荷を増やすだけだ。越境が評価されない構造で「越境せよ」と言っても、個人を疲弊させるだけだ。私はこの記事で、分断の弊害を語り、越境の価値を語ってきた。しかし、その主張が新たな「べき論」になるリスクがある。「越境すべき」「事業の言葉で語るべき」「全体を見るべき」。これらは、個人への要求だ。しかし、なぜ越境が難しいのか。それは構造の問題だ。評価制度を見てほしい。技術者は「技術的な成果」で評価される。事業への貢献は、評価項目に入らないことが多い。越境して事業に口を出しても、評価されない。むしろ、専門性が薄まったと見なされるリスクがある。KPIを見てほしい。事業部門は売上で評価される。技術部門はシステムの安定性で評価される。「境界をまたぐ貢献」を測る指標は、どこにもない。キャリアパスを見てほしい。技術者としてのキャリアは、技術を深めることで築かれる。越境に時間を使うと、専門性が薄まる。越境は、キャリアリスクになりうる。この構造がある限り、越境しない方が合理的だ。言い換えれば、越境は、評価されないボランティアだ。ボランティアに依存する組織は、ボランティアが疲弊した瞬間に壊れる。私が「越境せよ」と言うとき、暗黙のうちに個人の努力に頼っている。善意に頼っている。「組織のために」という献身に頼っている。しかし、善意は持続しない。献身は燃え尽きる。越境を個人に求めるだけでは足りない。越境が合理的になる構造を作らなければならない。具体的には何か。評価制度を変える。「境界をまたぐ貢献」を評価項目に入れる。技術者が事業に貢献したことを、技術的成果と同等に評価する。事業担当が技術的制約を理解し、計画に反映したことを評価する。KPIを変える。部門ごとのKPIだけでなく、「部門間の連携」を測る指標を作る。例えば、「他部門からのフィードバックを計画に反映した回数」「境界をまたぐ問題を早期に発見した件数」。キャリアパスを変える。越境経験を、キャリアの強みとして評価する。「技術も事業も分かる人」を、専門家と同等に評価する。予算を変える。「境界をまたぐ問題」に使える予算枠を作る。事業予算でも技術予算でもない、「連携予算」のようなもの。会議体を変える。月曜・水曜・金曜と分かれた会議を、定期的に統合する場を作る。全員が同席する必要はない。しかし、境界の情報が消えないための仕組みが必要だ。しかし、ここで自分の甘さを認めなければならない。私は以前、ある会社で評価制度の変更を提案したことがある。「越境的な貢献も評価項目に入れましょう」と。提案は通った。評価シートに「部門間連携」という項目が追加された。半年後、何が起きたか。項目は増えたが、行動は変わらなかった。みんな、その項目に「特になし」と書いて提出していた。形式だけが変わり、中身は何も変わらなかった。そのとき気づいた。部門を統合しても、会議体を変えても、中の人々が行動を変えなければ、結局、何も変わらない。当たり前のことだ。しかし、私は「構造を変えれば人が変わる」と信じていた。構造さえ整えれば、人は自然とその構造に沿って動くはずだ、と。甘かった。評価制度を変えても、その評価制度を運用する人が変わらなければ、何も変わらない。会議体を変えても、会議で発言する人の意識が変わらなければ、何も変わらない。構造は、行動を促すきっかけにはなる。しかし、行動を強制することはできない。では、構造を変えることに意味はないのか。そうではない。構造を変えることは必要だ。しかし、十分ではない。構造を変えると同時に、「なぜこの構造に変えるのか」を語り続ける必要がある。形式だけでなく、意味を伝える。それがなければ、新しい構造は空箱になる。——と書いて、これらを変える権限が自分にないことに気づく。私は技術顧問だ。評価制度を変える権限はない。KPIを変える権限もない。予算を変える権限もない。では、権限がない人は何もできないのか。そうではない。権限がなくても、できることはある。まず、構造の問題を言語化することだ。「越境が難しいのは、評価制度が越境を評価しないからだ」と言葉にする。問題を個人の能力や意欲の問題ではなく、構造の問題として語る。それだけで、議論の土俵が変わる。次に、小さな実験を提案することだ。評価制度全体を変えるのは難しい。しかし、「このプロジェクトでは、境界をまたぐ貢献も評価してみませんか」と提案することはできる。小さな実験が成功すれば、それを拡大できる。そして、越境できない自分を責めないことだ。越境が難しいのは、あなたの能力の問題ではない。構造の問題だ。構造が変わらない中で、できることをすればいい。ただし、ここで一つ、認めておくべきことがある。全員が越境する必要はない。越境できる人がいて、専門性を深める人がいて、それぞれが価値を出す。これも、一つの分業だ。全員が同じ行動をする必要はない。越境が得意な人が越境し、専門性を深めるのが得意な人が深掘りする。その組み合わせで、組織は機能する。「越境せよ」という主張が、「全員が越境すべき」という画一的な要求になってはいけない。越境しない人を「視野が狭い」と見なしてはいけない。専門性を深めることにも、価値がある。私がこの記事で言いたいのは、「全員が越境せよ」ではない。「越境が必要な場面で、越境できる構造を作れ」だ。私自身の反省正直に言えば、私自身、この分断に加担してきた。技術顧問として呼ばれる。「アーキテクチャについてアドバイスしてください」と言われる。私は、アーキテクチャについてアドバイスする。それが、私の仕事だと思っていた。しかし、アーキテクチャの問題は、純粋に技術的な問題であることは稀だ。組織の問題であり、事業の問題でもある。「なぜこのアーキテクチャになったのか」を掘り下げると、組織の歴史が見えてくる。「チームが分かれていたから、システムも分かれた」。「この部分は外注したから、ブラックボックスになった」。「この機能は急いで作ったから、技術的負債が溜まった」。技術の問題を、技術だけで解決しようとしても、うまくいかない。組織を変えなければ、技術は変わらない。事業の優先順位を変えなければ、技術的負債は返せない。私は、そこまで踏み込むことを避けてきた。「それは私の領域ではない」と。しかし、それは、本当に価値のある助言だったのか。踏み込まないことで、私は何を守っていたのか。関係性だ。嫌われたくない。次も呼ばれたい。だから、言いにくいことは言わない。契約範囲だ。「アーキテクチャのアドバイス」で呼ばれた。組織や事業の話は契約外だ。だから、踏み込まない。安心感だ。技術の話をしていれば、自分の専門領域にいられる。組織や事業の話をすると、自分が素人になる。だから、避ける。しかし、これらを守った結果、私のアドバイスは実行されないまま終わった。価値を提供できなかった。守ったものは、守る価値があったのか。最近は、少しずつ変えている。技術の話だけでなく、組織の話も、事業の話もする。「このアーキテクチャを実現するには、チーム編成を変える必要があります」「この技術的負債を返すには、事業側の優先順位を変える必要があります」。踏み込むときの言い方には、工夫がいる。診断として言う——「私の見立てでは、技術だけでなく組織の問題もあるように見えます」。断定ではなく、観察として伝える。仮説として言う——「もし組織構造を変えたら、アーキテクチャの変更がスムーズに進むかもしれません」。押し付けではなく、可能性として提示する。選択肢として言う——「技術だけで対処する方法と、組織も含めて対処する方法があります。どちらを選びますか」。決定権は相手に渡す。言いにくいことだ。領域を越えている。しかし、言わなければ、本当の解決にはならない。おわりに「おい、分けて語るな」。この言葉は、会議室の誰かに向けているようで、実は自分に向けている。この文章を読んでも、明日から「事業と技術と組織を統合して考えられる人」にはならない。私自身がそうだったから分かる。組織の分断は、風邪のような急性疾患ではない。薬を飲んで寝れば治る、というものではない。慢性疾患だ。劇的な手術で一気に治すことはできない。できるのは、セルフケア的なアプローチだ。小さなことから、少しずつ、継続的に変えていく。一気に問題を解決しようとは思わないこと。問題解決モードを抜け出し、対話モードで慢性疾患に向き合う。「分けて考えるな」。言葉では分かる。しかし、明日の会議で、実践できるか。経営会議で「それ、技術的にはこういう含意があります」と発言できるか。技術戦略会議で「それ、事業戦略とどう関係しますか」と質問できるか。正直、自信がない。質問した瞬間、場が凍りつくかもしれない。「また技術の話か」と思われるかもしれない。そう思うと、喉まで出かかった言葉を飲み込んでしまう。これまでも、そうだった。でも、一つだけ提案がある。次の会議で、一回だけ、こう質問してみてほしい。「この決定は、[別の領域]にどういう影響がありますか？」答えが返ってくればいい。返ってこなければ、それが発見だ。その沈黙は「分断がある」という証拠だ。私は過去に3回、この質問をした。1回目は無視された。2回目は「それは技術の話だから」と流された。3回目は違った。CTOが一瞬黙り、それから「いい質問だ」と言った。会議室の空気が変わるのを感じた。CTOはその場で技術責任者を呼んだ。30分後、経営会議に技術責任者が同席するという、その会社では初めてのことが起きた。3回目が、その会社の変化の始まりだった。1回で変わることは稀だ。しかし、質問しなければ、変わる可能性すらない。沈黙が3回続いたら、それは「この組織には分断がある」という診断結果だ。診断結果が出れば、次のアクションが見える。明日も会議がある。月曜は経営会議。水曜は技術戦略会議。金曜は組織開発会議。きれいに分かれている。整然としている。月曜の経営会議で、一つだけ、技術の話をしてみようと思う。「この事業戦略、技術的にはどういう制約がありますか」と。沈黙が流れるかもしれない。「それは水曜に」と言われるかもしれない。それでもいい。その沈黙こそが、分断の存在を証明している。そして、証明された瞬間から、修復は始まる。私が「分けて語らない」姿勢を貫くとき、最初に変わるのは何か。会議か。人か。成果物か。私の経験では、最初に変わるのは成果物だった。技術レビューに事業インパクトの項目を入れる。事業計画書に技術的制約の項目を入れる。アーキテクチャ決定記録（ADR）に「事業への影響」を必須にする。成果物の形式が変わると、それを作る過程で、自然と越境が起きる。次に変わるのは会議だ。技術の会議に事業担当を一人呼ぶ。事業の会議に技術担当を一人呼ぶ。最初はオブザーバーでいい。聞いているだけでいい。その一人がいることで、会議の空気が変わる。最後に変わるのは人だ。人の意識や行動は、簡単には変わらない。しかし、成果物の形式が変わり、会議の参加者が変わると、少しずつ変わっていく。「他の領域のことも考える」が、習慣になっていく。——と書いたが、本当にそうだろうか。成果物や会議が変わっても、人が変わらないケースも見てきた。形式だけ整えて、中身は変わらない。「事業インパクト」の欄に、適当なことを書いて終わり。そういう組織もある。それでも、形式から入るしかない。形式が変われば、少なくとも「考える機会」は生まれる。考えた結果、変わらない人もいる。変わる人もいる。変わる人が一人でもいれば、その人から広がる可能性がある。この声は、会議室の誰かにではなく、自分自身に向けられている。参考書籍アーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazon戦略の要諦作者:リチャード・Ｐ・ルメルト日経BPAmazon良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon君は戦略を立てることができるか 視点と考え方を実感する４時間作者:音部大輔Amazonストーリーとしての競争戦略 Hitotsubashi Business Review Books作者:楠木 建東洋経済新報社Amazon戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon戦略のデザイン ゼロから「勝ち筋」を導き出す10の問い作者:坂田 幸樹ダイヤモンド社Amazon戦略コンサルの技術　70のスキームで身につける思考と分析力 (日本経済新聞出版)作者:長谷部 智也,河野 博日経BPAmazon確率思考の戦略論　どうすれば売上は増えるのか作者:森岡 毅,今西 聖貴ダイヤモンド社Amazonジョブ理論　イノベーションを予測可能にする消費のメカニズム作者:クレイトン・Ｍ・クリステンセンHarperCollins Children's BooksAmazon「ジョブ理論」完全理解読本 ビジネスに活かすクリステンセン最新理論作者:津田真吾,INDEEJapan翔泳社Amazonイノベーション・オブ・ライフ ハーバード・ビジネススクールを巣立つ君たちへ作者:クレイトン M.クリステンセン翔泳社Amazon繁栄のパラドクス 絶望を希望に変えるイノベーションの経済学 クレイトン・M・クリステンセン作者:クレイトン・M クリステンセンHarperCollins Children's BooksAmazonイノベーションの経済学　「繁栄のパラドクス」に学ぶ巨大市場の創り方作者:クレイトン・M・クリステンセンHarperCollins Children's BooksAmazonチームトポロジー 価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonエンジニアリング組織論への招待　～不確実性に向き合う思考と組織のリファクタリング作者:広木 大地技術評論社Amazonプロダクトマネジメントのすべて 事業戦略・IT開発・UXデザイン・マーケティングからチーム・組織運営まで作者:及川 卓也,曽根原 春樹,小城 久美子翔泳社Amazon企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazonイノベーションのジレンマ 増補改訂版 (Harvard Business School Press)作者:クレイトン クリステンセン翔泳社Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazonモチベーション革命　稼ぐために働きたくない世代の解体書作者:尾原 和啓AudibleAmazon","isoDate":"2026-02-02T03:46:15.000Z","dateMiliSeconds":1770003975000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" 2026年1月 Neovim の Rust 環境を見直した","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/29/130742","contentSnippet":"はじめにgithub.com先週、エージェントが書いた200行のコードを開いた。move |ctx| { ... } というクロージャがあった。この ctx は何をキャプチャしているのか。所有権は移動しているのか、借用なのか。コードを読んでも分からない。コンパイルしてエラーが出るまで待つか、エージェントに「このクロージャは何をキャプチャしてる？」と聞くか。どちらも面倒だった。エージェントにすべてを任せれば楽になる、と思っていた時期がある。しかし1ヶ月ほど使って気づいた。大きな変更はエージェントが得意だ。ファイルを跨いだリファクタリング、新機能の実装、テストの追加。これらは確かにエージェントに任せた方が速い。しかし、生成されたコードの一部だけを直したいとき、エージェントに再度依頼するのは効率が悪い。「この unwrap() を ? に変えたい」「このクロージャの引数名を直したい」「この変数を別のスコープに移動したい」といった微修正は、手で直した方が速い。私は1日の開発時間のうち、7割をエージェントとの対話に、3割をNeovimでの直接作業に使っている。この3割のほとんどはコードリーディングとコードベースの理解で、実際に手で修正するのは5%程度だ。それでも、コードを「読む」環境が貧弱だと、全体の生産性が落ちる。Neovimを使う理由は、思考のスピードで編集できるからだ。ciw で単語を置換し、. で繰り返し、/ で検索して n で次へ。この一連の操作が指に染み付いていると、「直したい」と思った瞬間に直せる。エージェントに依頼を書いて、結果を待って、差分を確認する時間がない。私は Claude Code も Neovim から起動している。ターミナルで claude を叩き、エージェントと対話し、生成されたコードを Neovim で開いて確認する。すべてが同じ環境で完結する。エージェントが書いたコードを「読む」環境と、細部を「直す」環境。この両方が揃って初めて、エージェント時代の開発は快適になる。この記事では、Neovim 0.11+ と Rust の開発環境を見直した結果を紹介する。冒頭で困っていた「クロージャのキャプチャが分からない」問題を解決する Inlay Hints と、素早い修正を可能にするキーマップに重点を置いている。構成の概要私の開発環境全体については以下の記事で紹介している。本記事では Rust 関連の設定に絞って解説する。syu-m-5151.hatenablog.com私の Neovim 環境は NvChad をベースにしている。プラグイン管理には lazy.nvim を使い、Rust 関連は以下の構成だ。 コンポーネント  役割  rust-analyzer  LSP（言語サーバー）、nvim-lspconfig 経由で設定  rustaceanvim  Rust専用の拡張機能（テスト実行、マクロ展開など）  crates.nvim  Cargo.toml の依存関係管理  nvim-dap  デバッグサポート（LLDB連携）  conform.nvim  フォーマッタ（rustfmt）  mason.nvim  LSP/DAP のインストール管理 エージェント連携として claudecode.nvim も入れている。Neovim から Claude Code を起動し、生成されたコードをそのまま編集できる。以下では、この構成を「コードを読む」→「テスト・実行する」→「細部を直す」の順で紹介する。rust-analyzer と Inlay Hints でコードを理解し、rustaceanvim でテストを回し、conform.nvim でフォーマットを整える。この流れが、エージェントが書いたコードを確認・修正するワークフローと対応している。rust-analyzer の設定github.comgithub.comrust-analyzer は Rust の公式 LSP（Language Server Protocol）実装だ。LSP とは、エディタに補完、定義ジャンプ、エラー表示などの機能を提供するプロトコルで、VSCode でも Neovim でも同じ言語サーバーを使える。エージェントが生成したコードを読む際、型やライフタイム（Rust特有のメモリ管理の仕組みで、参照がいつまで有効かを示す）の情報がインラインで表示されると理解が格段に速くなる。私は nvim-lspconfig 経由で設定している。Neovim 0.11+ では vim.lsp.config API が使えるようになり、設定がシンプルになった。-- lua/configs/lspconfig.luarust_analyzer = {  settings = {    [\"rust-analyzer\"] = {      checkOnSave = {        command = \"clippy\",        extraArgs = { \"--all\", \"--\", \"-W\", \"clippy::all\" },      },      cargo = {        allFeatures = true,        loadOutDirsFromCheck = true,        buildScripts = { enable = true },      },      procMacro = {        enable = true,        attributes = { enable = true },      },      inlayHints = {        enable = true,        chainingHints = { enable = true },        typeHints = { enable = true, hideClosureInitialization = true },        parameterHints = { enable = true },        closureReturnTypeHints = { enable = \"with_block\" },        lifetimeElisionHints = { enable = \"skip_trivial\", useParameterNames = true },        maxLength = 25,        bindingModeHints = { enable = true },        closureCaptureHints = { enable = true },        discriminantHints = { enable = \"fieldless\" },        expressionAdjustmentHints = { enable = \"reborrow\" },        rangeExclusiveHints = { enable = true },      },      completion = {        autoimport = { enable = true },        postfix = { enable = true },        callable = { snippets = \"fill_arguments\" },        fullFunctionSignatures = { enable = true },        privateEditable = { enable = true },      },      imports = {        granularity = { group = \"module\" },        prefix = \"self\",      },      diagnostics = {        enable = true,        experimental = { enable = true },        styleLints = { enable = true },      },      semanticHighlighting = {        operator = { specialization = { enable = true } },        punctuation = { enable = true, specialization = { enable = true } },        strings = { enable = true },      },      hover = {        actions = {          enable = true,          references = { enable = true },          run = { enable = true },          debug = { enable = true },          gotoTypeDef = { enable = true },          implementations = { enable = true },        },        documentation = { enable = true, keywords = { enable = true } },        links = { enable = true },      },      typing = {        autoClosingAngleBrackets = { enable = true },      },      lens = {        enable = true,        references = { enable = true, adt = { enable = true }, enumVariant = { enable = true }, method = { enable = true }, trait = { enable = true } },        implementations = { enable = true },        run = { enable = true },        debug = { enable = true },      },      workspace = {        symbol = { search = { kind = \"all_symbols\" } },      },    },  },}-- Neovim 0.11+ の新しい API を使用vim.lsp.config(\"rust_analyzer\", config)vim.lsp.enable(\"rust_analyzer\")主な設定項目inlayHints - エージェントが生成したコードを読むとき、最も役立つのがこれだ。エディタ内にインラインで型情報やパラメータ名が表示される。特に closureCaptureHints は重宝している。Rustではクロージャ（|x| x + 1 のような無名関数）が外部の変数を使うとき、その変数を「キャプチャ」する。move |data| { ... } と書くと、data の所有権がクロージャに移動（ムーブ）する。この「何がキャプチャされているか」がエディタ上に [move: data] と表示されるようになる。エージェントが書いたクロージャを理解するのに、コンパイルエラーを待つ必要がなくなった。rangeExclusiveHints も地味に便利で、0..len が排他的（len を含まない）であることを .. の横に明示してくれる。diagnostics.experimental - 実験的な診断機能を有効化する。styleLints を有効にすると、Clippy のスタイル系リントも保存時に表示される。エージェントが生成したコードは動くが、慣用的でないことがある。この設定で「動くけど直したほうがいい」箇所が分かる。semanticHighlighting - 演算子や句読点に対してセマンティックハイライトを適用する。*self.data のような式で * が参照外しとして色付けされると、複雑な式の構造が視覚的に分かる。ただし、色数を増やしすぎるとノイズになるので、私は operator と punctuation のみ有効にしている。hover.actions - ホバー時に「Run」「Debug」「Go to Type Definition」などのアクションを表示する。エージェントが追加したテストを実行したいとき、テスト関数にカーソルを合わせて K を押すだけで実行できる。typing.autoClosingAngleBrackets - Vec\u003c と入力すると自動的に \u003e が補完される。エージェントが書いた型を微修正するとき、\u003e の数を数えなくて済む。rustaceanvim の設定github.comrust-analyzer がコードを「読む」ための機能を提供するのに対し、rustaceanvim は「テスト・実行・デバッグ」のための機能を提供する。両者は補完関係にあり、rust-analyzer の LSP 機能に加えて、Rust 特有の操作（マクロ展開、テスト実行など）を追加する。rustaceanvim は rust-tools.nvim の後継だが、単なるメンテナンス引き継ぎではない。最大の違いは遅延読み込みへの対応で、.rs ファイルを開くまで何も読み込まない。私の環境では Neovim の起動時間が 120ms から 45ms に短縮された。エージェント時代に rustaceanvim が重要な理由は、「素早い確認と修正」のワークフローを支えることにある。エージェントがコードを生成したら、テストを実行し、エラーがあれば修正し、また実行する。このサイクルを \u003cleader\u003ert（テスト実行）と \u003cleader\u003ere（エラー説明）で高速に回せる。-- lua/plugins/lang.lua{  \"mrcjkb/rustaceanvim\",  version = \"^5\",  lazy = false,  init = function()    vim.g.rustaceanvim = {      tools = {        hover_actions = { replace_builtin_hover = false },        float_win_config = { border = \"rounded\" },        inlay_hints = { auto = true },        code_actions = { ui_select_fallback = true },      },      server = {        on_attach = function(_, bufnr)          local opts = { silent = true, buffer = bufnr }          vim.keymap.set(\"n\", \"\u003cleader\u003era\", function() vim.cmd.RustLsp \"codeAction\" end, vim.tbl_extend(\"force\", opts, { desc = \"Rust code action\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erd\", function() vim.cmd.RustLsp \"debuggables\" end, vim.tbl_extend(\"force\", opts, { desc = \"Rust debuggables\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003err\", function() vim.cmd.RustLsp \"runnables\" end, vim.tbl_extend(\"force\", opts, { desc = \"Rust runnables\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ert\", function() vim.cmd.RustLsp \"testables\" end, vim.tbl_extend(\"force\", opts, { desc = \"Rust testables\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erm\", function() vim.cmd.RustLsp \"expandMacro\" end, vim.tbl_extend(\"force\", opts, { desc = \"Expand macro\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erc\", function() vim.cmd.RustLsp \"openCargo\" end, vim.tbl_extend(\"force\", opts, { desc = \"Open Cargo.toml\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erp\", function() vim.cmd.RustLsp \"parentModule\" end, vim.tbl_extend(\"force\", opts, { desc = \"Parent module\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erj\", function() vim.cmd.RustLsp \"joinLines\" end, vim.tbl_extend(\"force\", opts, { desc = \"Join lines\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ers\", function() vim.cmd.RustLsp \"ssr\" end, vim.tbl_extend(\"force\", opts, { desc = \"Structural search replace\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ere\", function() vim.cmd.RustLsp \"explainError\" end, vim.tbl_extend(\"force\", opts, { desc = \"Explain error\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003erD\", function() vim.cmd.RustLsp \"renderDiagnostic\" end, vim.tbl_extend(\"force\", opts, { desc = \"Render diagnostic\" }))          vim.keymap.set(\"n\", \"K\", function() vim.cmd.RustLsp { \"hover\", \"actions\" } end, vim.tbl_extend(\"force\", opts, { desc = \"Rust hover actions\" }))        end,        default_settings = {          [\"rust-analyzer\"] = {            cargo = { allFeatures = true },            checkOnSave = { command = \"clippy\" },          },        },      },      dap = {        adapter = {          type = \"executable\",          command = \"lldb-dap\",          name = \"rt_lldb\",        },      },    }  end,},キーマップ一覧 キー  機能  \u003cleader\u003era  コードアクション  \u003cleader\u003err  実行可能ターゲットを選択して実行  \u003cleader\u003ert  テストを選択して実行  \u003cleader\u003erd  デバッグ実行  \u003cleader\u003erm  カーソル位置のマクロを展開  \u003cleader\u003ere  エラーの詳細説明を表示  \u003cleader\u003erD  診断をレンダリング  \u003cleader\u003ers  構造的検索置換（SSR）  \u003cleader\u003erp  親モジュールに移動  \u003cleader\u003erj  行を結合  \u003cleader\u003erc  Cargo.toml を開く  K  ホバーアクション付きドキュメント crates.nvim の設定github.comRustでは Cargo.toml というファイルで依存ライブラリ（クレートと呼ぶ）を管理する。Node.js の package.json、Python の requirements.txt に相当するものだ。クレートには「フィーチャー」という機能のオン・オフがあり、必要な機能だけを有効にしてビルドサイズを抑えることができる。エージェントに「tokio を追加して」と頼むと、だいたい最新版を入れてくれる。しかし、フィーチャーの選択は雑なことが多い。tokio = { version = \"1\", features = [\"full\"] } と書かれていて、「full はオーバーキルだな、macros と rt-multi-thread だけでいいのに」と思うことがある。crates.nvim があれば、Cargo.toml 上でクレートにカーソルを合わせて \u003cleader\u003ecf を押すだけで、フィーチャー一覧がポップアップする。必要なものだけ選んで、不要なものは外す。この微調整はエージェントに頼むより、手でやった方が速い。-- lua/plugins/lang.lua{  \"saecki/crates.nvim\",  tag = \"stable\",  event = { \"BufRead Cargo.toml\" },  dependencies = { \"nvim-lua/plenary.nvim\" },  config = function()    local crates = require \"crates\"    crates.setup {      completion = {        cmp = { enabled = true },        crates = { enabled = true, max_results = 8, min_chars = 3 },      },      lsp = {        enabled = true,        on_attach = function(_, bufnr)          local opts = { silent = true, buffer = bufnr }          vim.keymap.set(\"n\", \"\u003cleader\u003ect\", crates.toggle, vim.tbl_extend(\"force\", opts, { desc = \"Toggle crates\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecr\", crates.reload, vim.tbl_extend(\"force\", opts, { desc = \"Reload crates\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecv\", crates.show_versions_popup, vim.tbl_extend(\"force\", opts, { desc = \"Show versions\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecf\", crates.show_features_popup, vim.tbl_extend(\"force\", opts, { desc = \"Show features\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecd\", crates.show_dependencies_popup, vim.tbl_extend(\"force\", opts, { desc = \"Show dependencies\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecu\", crates.update_crate, vim.tbl_extend(\"force\", opts, { desc = \"Update crate\" }))          vim.keymap.set(\"v\", \"\u003cleader\u003ecu\", crates.update_crates, vim.tbl_extend(\"force\", opts, { desc = \"Update crates\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecU\", crates.upgrade_crate, vim.tbl_extend(\"force\", opts, { desc = \"Upgrade crate\" }))          vim.keymap.set(\"v\", \"\u003cleader\u003ecU\", crates.upgrade_crates, vim.tbl_extend(\"force\", opts, { desc = \"Upgrade crates\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecA\", crates.upgrade_all_crates, vim.tbl_extend(\"force\", opts, { desc = \"Upgrade all crates\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecH\", crates.open_homepage, vim.tbl_extend(\"force\", opts, { desc = \"Open homepage\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecR\", crates.open_repository, vim.tbl_extend(\"force\", opts, { desc = \"Open repository\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecD\", crates.open_documentation, vim.tbl_extend(\"force\", opts, { desc = \"Open docs.rs\" }))          vim.keymap.set(\"n\", \"\u003cleader\u003ecC\", crates.open_crates_io, vim.tbl_extend(\"force\", opts, { desc = \"Open crates.io\" }))        end,        actions = true,        completion = true,        hover = true,      },      popup = {        border = \"rounded\",        show_version_date = true,        max_height = 30,        min_width = 20,      },    }  end,},キーマップ一覧 キー  機能  \u003cleader\u003ect  crates.nvim の表示切り替え  \u003cleader\u003ecr  クレート情報を再読み込み  \u003cleader\u003ecv  バージョン一覧をポップアップ表示  \u003cleader\u003ecf  フィーチャー一覧を表示  \u003cleader\u003ecd  依存関係を表示  \u003cleader\u003ecu  クレートを最新パッチバージョンに更新（ビジュアルモードで複数選択可）  \u003cleader\u003ecU  クレートを最新バージョンにアップグレード  \u003cleader\u003ecA  すべてのクレートをアップグレード  \u003cleader\u003ecH  クレートのホームページを開く  \u003cleader\u003ecR  クレートの GitHub リポジトリを開く  \u003cleader\u003ecD  docs.rs を開く  \u003cleader\u003ecC  crates.io を開く nvim-dap によるデバッグgithub.comgithub.comgithub.comgithub.comエージェントが生成したコードで「なぜこの値になるのか分からない」という場面がある。println デバッグで済むこともあるが、複雑なロジックでは変数の変化を追いたくなる。Rust のデバッグには LLDB を使う。LLDB は C/C++/Rust などのコンパイル言語向けのデバッガで、ブレークポイント（プログラムを一時停止する地点）を設定し、変数の中身を確認しながらステップ実行できる。macOS の場合は Homebrew で LLVM をインストールし、その中に含まれる lldb-dap（DAP = Debug Adapter Protocol）を使う。-- lua/plugins/lang.lua{  \"mfussenegger/nvim-dap\",  lazy = true,  dependencies = {    \"rcarriga/nvim-dap-ui\",    \"nvim-neotest/nvim-nio\",    \"theHamsta/nvim-dap-virtual-text\",  },  keys = {    { \"\u003cleader\u003edb\", function() require(\"dap\").toggle_breakpoint() end, desc = \"Toggle breakpoint\" },    { \"\u003cleader\u003edB\", function() require(\"dap\").set_breakpoint(vim.fn.input \"Breakpoint condition: \") end, desc = \"Conditional breakpoint\" },    { \"\u003cleader\u003edc\", function() require(\"dap\").continue() end, desc = \"Continue\" },    { \"\u003cleader\u003edC\", function() require(\"dap\").run_to_cursor() end, desc = \"Run to cursor\" },    { \"\u003cleader\u003edi\", function() require(\"dap\").step_into() end, desc = \"Step into\" },    { \"\u003cleader\u003edo\", function() require(\"dap\").step_over() end, desc = \"Step over\" },    { \"\u003cleader\u003edO\", function() require(\"dap\").step_out() end, desc = \"Step out\" },    { \"\u003cleader\u003edp\", function() require(\"dap\").pause() end, desc = \"Pause\" },    { \"\u003cleader\u003edr\", function() require(\"dap\").repl.toggle() end, desc = \"Toggle REPL\" },    { \"\u003cleader\u003edt\", function() require(\"dap\").terminate() end, desc = \"Terminate\" },    { \"\u003cleader\u003edu\", function() require(\"dapui\").toggle() end, desc = \"Toggle DAP UI\" },    { \"\u003cleader\u003ede\", function() require(\"dapui\").eval() end, desc = \"Eval\", mode = { \"n\", \"v\" } },  },  config = function()    local dap = require \"dap\"    local dapui = require \"dapui\"    -- DAP UI setup with custom layout    dapui.setup {      icons = { expanded = \"▾\", collapsed = \"▸\", current_frame = \"▸\" },      layouts = {        {          elements = {            { id = \"scopes\", size = 0.25 },            { id = \"breakpoints\", size = 0.25 },            { id = \"stacks\", size = 0.25 },            { id = \"watches\", size = 0.25 },          },          size = 40,          position = \"left\",        },        {          elements = {            { id = \"repl\", size = 0.5 },            { id = \"console\", size = 0.5 },          },          size = 10,          position = \"bottom\",        },      },    }    -- Virtual text for debugging    require(\"nvim-dap-virtual-text\").setup { enabled = true, commented = true }    -- LLDB adapter    dap.adapters.lldb = {      type = \"executable\",      command = \"/opt/homebrew/opt/llvm/bin/lldb-dap\",      name = \"lldb\",    }    dap.configurations.rust = {      {        name = \"Launch\",        type = \"lldb\",        request = \"launch\",        program = function()          return vim.fn.input(\"Path to executable: \", vim.fn.getcwd() .. \"/target/debug/\", \"file\")        end,        cwd = \"${workspaceFolder}\",        stopOnEntry = false,        args = {},        runInTerminal = false,      },    }    -- Auto open/close DAP UI    dap.listeners.after.event_initialized[\"dapui_config\"] = function() dapui.open() end    dap.listeners.before.event_terminated[\"dapui_config\"] = function() dapui.close() end    dap.listeners.before.event_exited[\"dapui_config\"] = function() dapui.close() end    -- Signs    vim.fn.sign_define(\"DapBreakpoint\", { text = \"●\", texthl = \"DapBreakpoint\" })    vim.fn.sign_define(\"DapBreakpointCondition\", { text = \"●\", texthl = \"DapBreakpointCondition\" })    vim.fn.sign_define(\"DapStopped\", { text = \"▶\", texthl = \"DapStopped\", linehl = \"DapStoppedLine\" })  end,},キーマップ一覧 キー  機能  \u003cleader\u003edb  ブレークポイントの切り替え  \u003cleader\u003edB  条件付きブレークポイント  \u003cleader\u003edc  続行  \u003cleader\u003edC  カーソル位置まで実行  \u003cleader\u003edi  ステップイン  \u003cleader\u003edo  ステップオーバー  \u003cleader\u003edO  ステップアウト  \u003cleader\u003edp  一時停止  \u003cleader\u003edr  REPL の切り替え  \u003cleader\u003edt  終了  \u003cleader\u003edu  DAP UI の切り替え  \u003cleader\u003ede  カーソル位置の式を評価（ビジュアルモードでも使用可） conform.nvim でのフォーマットgithub.com保存時に rustfmt を自動実行する。エージェントが生成したコードはフォーマットが崩れていることがあるので、保存するだけで整形されるのは便利だ。-- lua/plugins/lsp.lua{  \"stevearc/conform.nvim\",  event = \"BufWritePre\",  config = function()    require(\"conform\").setup {      formatters_by_ft = {        rust = { \"rustfmt\", lsp_format = \"fallback\" },        -- 他の言語も設定可能      },      format_on_save = { timeout_ms = 500, lsp_fallback = true },    }  end,},ここまでで「コードを読む」「テスト・実行する」「細部を直す」の設定が揃った。最後に、これらのツール自体をどうインストールするかを紹介する。Mason でのツールインストールgithub.comLSP サーバーやデバッグアダプタは Mason で管理する。:MasonInstall で個別にインストールすることもできるが、ensure_installed に書いておけば自動でインストールされる。-- lua/plugins/lsp.lua{  \"williamboman/mason.nvim\",  opts = {    ensure_installed = {      \"rust-analyzer\",      \"codelldb\",  -- DAP adapter      -- 他の言語のツールも同様に追加    },  },},まとめこの設定を入れた翌日、またエージェントが書いたコードを開いた。move |ctx| { ... } というクロージャがある。今度は違った。クロージャの横に [move: ctx, config] と表示されている。何がキャプチャされているか、一目で分かる。コンパイルを待つ必要も、エージェントに聞く必要もない。エージェントに任せる7割と、自分で読む3割。この3割を Neovim で快適にすることが、全体の生産性につながる。rust-analyzer の Inlay Hints でコードを読み、rustaceanvim のキーマップでテストを回し、思考のスピードで細部を直す。エージェント時代だからこそ、手元のエディタは大事だ。","isoDate":"2026-01-29T04:07:42.000Z","dateMiliSeconds":1769659662000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ZellijのRust実装パターン徹底解説（後編）","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/29/092003","contentSnippet":"はじめに前編を書き終えたあと、エディタを閉じて、しばらくターミナルを眺めていた。Zellijのペインが3つ並んでいる。左でVimが開き、右上でテストが走り、右下にシェルが待機している。何も起きていない。何も起きていないのに、裏では6つのスレッドが動いている。チャネルを介してメッセージが流れ、PTYがカーネルとやり取りし、VTEパーサがバイト列を解釈している。前編では設計パターンを抽出した。cat huge_log_file.logで200万行を流し込んだとき、Zellijが固まらない理由——境界付きチャネルによるバックプレッシャー。その仕組みを概念として説明した。後編では、その実装の中に入る。syu-m-5151.hatenablog.com正直に言うと、後編は地味だ。WASMプラグインの通信プロトコル、ANSIエスケープシーケンスのパース、KDL形式のセッション永続化。どれも「知っていると便利」だが「知らなくても困らない」話かもしれない。華やかさはない。ただ、Rustで本格的なアプリケーションを書こうとしたとき、こういう地味な部分でつまずく。つまずいてから調べるか、先に知っておくか。その違いは、たぶん小さくない。Cargo Workspace構成の深掘り前編でCargo Workspaceの構造を見た。後編では、なぜこの分割になっているのかを考える。zellij-utils/を開くと、IPCの定義やエラー処理、設定ファイルのパーサーが入っている。default-plugins/* → zellij-tile → zellij-tile-utilsclient ↓ server       ↓    zellij-utils ← 共有型定義（IPC契約）zellij-utilsが双方向依存を防いでいる。clientもserverもutilsに依存するが、utilsはどちらにも依存しない。これにより、clientを変更してもserverの再コンパイルは不要になる。10万行超のコードベースでは、このビルド時間の差が開発体験に直結する。zellij-tileをSDKとして独立させた意図も見える。プラグイン開発者はサーバー実装への依存なしにビルドできる。これは「プラグインエコシステムの成長」を設計段階で意識した判断だ。後からSDKを切り出すより、最初から分けておく方が遥かに低コストになる。後編で必要な追加知識前編でPTY、チャネル、Actorモデル、WASMの基礎を説明した。後編では、さらに低レベルな概念が登場する。ここで整理しておこう。termios構造体とターミナルモードUnixのターミナルはtermios構造体で制御される。この構造体には、ターミナルの振る舞いを決めるフラグが数十個含まれている。// nixクレートでの操作let mut tio = termios::tcgetattr(fd)?;  // 現在の設定を取得termios::cfmakeraw(\u0026mut tio);            // Raw Modeに設定termios::tcsetattr(fd, SetArg::TCSANOW, \u0026tio)?;  // 即座に適用ターミナルには2つの主要なモードがある。Cooked Mode（カノニカルモード）- カーネルが行編集を処理する（バックスペース、Ctrl+Wなど）- Enterを押すまで入力がバッファされる- Ctrl+CでSIGINTが自動送信されるRaw Mode- すべてのキー入力がそのままアプリケーションに届く- 行編集もシグナル生成もアプリケーションの責任- ターミナルマルチプレクサには必須Zellijは起動時にRaw Modeに入り、終了時に元のモードに戻す。これを忘れると、ターミナルが「壊れた」状態になる。主要なシグナルターミナルアプリケーションが扱う主なシグナルは以下の通り。 シグナル  発生条件  用途  SIGWINCH  ウィンドウリサイズ  ターミナルサイズの再取得  SIGINT  Ctrl+C  プロセスの中断  SIGTSTP  Ctrl+Z  プロセスの一時停止  SIGTERM  killコマンド  正常終了の要求  SIGKILL  kill -9  強制終了（捕捉不可）  SIGHUP  端末切断  セッション終了  SIGCHLD  子プロセス終了  子プロセスの状態変化 ZellijはSIGWINCHを特に注意深く扱う。ウィンドウをドラッグでリサイズすると、1秒間に数十〜数百回のSIGWINCHが発生する。すべてに反応するとパフォーマンスが悪化するため、スロットリング（間引き）が必要だ。ioctl：デバイス制御ioctl（I/O Control）は、デバイスに対する特殊な操作を行うシステムコールだ。ターミナル関連では以下が重要。// ウィンドウサイズの取得ioctl(fd, TIOCGWINSZ, \u0026mut winsize);  // Get WINdow SiZe// ウィンドウサイズの設定ioctl(fd, TIOCSWINSZ, \u0026winsize);      // Set WINdow SiZeWinsize構造体は4つのフィールドを持つ。struct Winsize {    ws_row: u16,      // 行数    ws_col: u16,      // 列数    ws_xpixel: u16,   // ピクセル幅（Sixel画像用）    ws_ypixel: u16,   // ピクセル高さ（Sixel画像用）}TIOCSWINSZでPTYのサイズを変更すると、カーネルは子プロセスにSIGWINCHを送る。シェルはこのシグナルを受けて画面を再描画する。ANSIエスケープシーケンスの詳細前編で触れたが、後編ではより詳しく見る。CSI（Control Sequence Introducer）\\x1b[  → CSI開始CSIの後にパラメータとコマンドが続く。\\x1b[31m      → 前景色を赤に（SGR: Select Graphic Rendition）\\x1b[10;5H   → カーソルを10行5列に移動（CUP: Cursor Position）\\x1b[2J      → 画面全体をクリア（ED: Erase in Display）\\x1b[?25h    → カーソルを表示（DECTCEM）\\x1b[?25l    → カーソルを非表示OSC（Operating System Command）\\x1b]0;title\\x07  → ウィンドウタイトルを設定\\x1b]8;;URL\\x07   → ハイパーリンク開始DCS（Device Control String）\\x1bP...ST  → 同期出力、Sixel画像などZellijはvteクレートでこれらをパースし、Performトレイトの各メソッドに振り分ける。ファイルディスクリプタとPTYUnixでは「すべてがファイル」だ。PTYもファイルディスクリプタ（FD）で表現される。let OpenptyResult { master, slave } = openpty(None, \u0026termios)?;// master: RawFd (例: 3)// slave:  RawFd (例: 4)子プロセス（シェル）は、login_tty()で以下の処理を行う。新しいセッションを作成（setsid()）slave PTYを制御端末に設定FD 0, 1, 2（stdin, stdout, stderr）をslave PTYに接続これにより、シェルの入出力はすべてPTY経由になる。tcdrain：出力の完了待ちtcdrainは、書き込んだデータがすべて送信されるまでブロックするシステムコールだ。write(fd, bytes)?;   // バッファに書き込むtcdrain(fd)?;        // 送信完了を待つなぜ必要か。write()はカーネルのバッファに書き込んだ時点で返る。相手がまだ読んでいない可能性がある。tcdrain()を呼ぶと、バッファが空になるまで待機する。Zellijでは、PTYへの書き込み後にtcdrain()を呼ぶ。これにより、入力が確実にシェルに届いてから次の処理に進む。これらの概念の関係[termios] ─── Raw/Cooked Mode を制御    ↓[PTY Master] ←── ioctl(TIOCGWINSZ/TIOCSWINSZ) でサイズ制御    │    │ write() + tcdrain()    ↓[PTY Slave] ─── シェルの stdin/stdout/stderr    │    │ SIGWINCH, SIGCHLD など    ↓[シグナルハンドラ] ─── スロットリング、グレースフル終了後編では、これらの概念がZellijの実装にどう現れるかを見ていく。境界付きチャネルの実装前編で「バッファサイズ50」と書いた。実際のコードを見てみよう。zellij-client/src/lib.rsを開く。// zellij-client/src/lib.rslet (send_client_instructions, receive_client_instructions): ChannelWithContext\u003c    ClientInstruction,\u003e = channels::bounded(50);  // バッファサイズ: 50サーバー側も同様だ。zellij-server/src/lib.rsを開く。// zellij-server/src/lib.rslet (to_server, server_receiver): ChannelWithContext\u003cServerInstruction\u003e =    channels::bounded(50);なぜ50なのか。開発者ブログやissue #525を調査したが、この値を選んだ明確な理由は記載されていなかった。ただし、技術的な背景は理解できる。境界付きチャネル導入の発端はissue #525だ。PTYスレッドがプログラム出力を読み取り、無制限チャネル経由でScreenスレッドに送る。出力生成がレンダリング速度を超えると、キューが無限に成長し、メモリ使用量と入力遅延が悪化する。単純に境界付きチャネルに変えるとデッドロックのリスクがある。PTYがキューを満杯にする→WASMスレッドがレンダリング命令を送ろうとしてブロック→Screenスレッド（キューを空にすべき側）がWASMスレッドの応答待ちでブロック——この連鎖だ。解決策として、crossbeamのselect!マクロを使った選択的ルーティングが採用された。PTY→Screen間のみ境界付きチャネルでバックプレッシャーをかけ、他のコンポーネント間は無制限チャネルを維持する。50という数字は「小さすぎてスループットを落とさず、大きすぎてメモリを圧迫しない」経験的なバランス点だろう。開発者ブログによると、境界付きチャネルの導入だけでベンチマークは19秒から9秒に改善された。WASMランタイムの移行Zellijのコードを読んでいて、最も意外だったのがこの部分かもしれない。WASMランタイムを「遅い方」に移行している。普通は逆だ。前編では「wasmiを使っている」と書いた。しかし、Zellijの歴史を調べると、WASMランタイムは2度移行している。初期はWasmer、0.40.0でWasmtime、そして最新版ではWasmiに移行した（PR #4449）。zellij-server/Cargo.tomlを開く。# zellij-server/Cargo.toml[dependencies.wasmi]version = \"0.51.3\"default-features = falsefeatures = [\"std\"]なぜWasmtimeからWasmiへ移行したのか。PR #4449のディスカッションを読むと、理由が明確になる。コンパイルからインタプリタへ。Wasmtimeは.wasmファイルをJITコンパイルする。これには秒単位の時間がかかっていた。Wasmiはインタプリタ方式で、ミリ秒単位（一桁）で実行を開始できる。キャッシュ管理の排除。Wasmtime時代はコンパイル済みコードをキャッシュしていた。プラグイン開発時に「キャッシュバスティング」が必要で、これがコードの複雑さを増していた。Wasmiならキャッシュ不要だ。バイナリサイズとメモリ削減。WasmtimeはCraneliftコンパイラを含むため、バイナリサイズが大きい。Wasmiは純粋なRust実装のインタプリタで、依存関係がシンプルだ。Debianパッケージングでも、Wasmtimeの依存関係（wiggle等）がブロッカーになる可能性があったが、Wasmiなら問題ない。性能面のトレードオフ。PRテスターの報告によると、Debugビルドでは一部プラグイン（Zjstatus）の起動に約1秒の遅延が観察された。ただし、Releaseビルドでは顕著な影響がなかった。コンパイルプロファイルの調整で改善も報告されている。ステータスバーの更新に1msかかるか0.1msかかるか——ユーザーには分からない。「最速のランタイム」より「最もメンテナンスしやすいランタイム」を選んだ判断は、オープンソースプロジェクトとして合理的だ。Protocol Buffersによるプラグイン通信WASMランタイムがプラグインの「実行環境」なら、Protocol Buffersはプラグインの「通信手段」だ。プラグインとホスト間の通信はProtocol Buffersで実現されている。zellij-utils/src/plugin_api/plugin_command.protoを開く。// zellij-utils/src/plugin_api/plugin_command.protoenum CommandName {  Subscribe = 0;  Unsubscribe = 1;  SetSelectable = 2;  GetPluginIds = 3;  OpenFile = 9;  OpenTerminal = 14;  // ... 150以上のコマンド}150以上のコマンド。前編で見たScreenInstructionの100バリアントを超えている。プラグインはUI操作、ファイル操作、ネットワーク、他プラグインとの通信など、ホストの機能に広くアクセスできるからだ。なぜProtocol Buffersなのか。WASMとホストの間でデータを受け渡すには、シリアライズが必要だ。JSONでもMessagePackでも良いが、Protocol Buffersには以下の利点がある。スキーマがドキュメントになる: .protoファイルを見れば、プラグインAPIの全体像が分かる後方互換性: フィールドの追加・削除が安全にできる型安全: コード生成により、シリアライズ/デシリアライズのミスを防げるzellij-tile/src/lib.rsのマクロを見ると、Protocol Buffersがどう使われているか分かる。#[no_mangle]fn load() {    STATE.with(|state| {        let protobuf_bytes: Vec\u003cu8\u003e = $crate::shim::object_from_stdin().unwrap();        // Protocol Buffersをデシリアライズして設定を取得    });}プラグインは標準入力からProtocol Buffersを読み、標準出力に書き込む。WASM境界を越えるのは単なるバイト列だ。シンプルだが、型安全性は失われない。パーミッションシステムの設計思想プラグインは16種類のパーミッションから必要なものを要求する。zellij-utils/src/plugin_api/plugin_permission.protoを開く。// zellij-utils/src/plugin_api/plugin_permission.protoenum PermissionType {  ReadApplicationState = 0;      // ペイン・タブ・UI状態の読み取り  ChangeApplicationState = 1;    // ペイン・タブ・UIの変更  OpenFiles = 2;                 // ファイルを開く  RunCommands = 3;               // コマンド実行  OpenTerminalsOrPlugins = 4;    // ターミナル/プラグインを開く  WriteToStdin = 5;              // ペインへの入力  WebAccess = 6;                 // HTTPリクエスト  ReadCliPipes = 7;              // CLIパイプの読み取り  MessageAndLaunchOtherPlugins = 8;  // 他プラグインとの通信  Reconfigure = 9;               // 設定変更  FullHdAccess = 10;             // ファイルシステム完全アクセス  StartWebServer = 11;           // Webサーバー起動  InterceptInput = 12;           // 入力のインターセプト  ReadPaneContents = 13;         // ペイン内容の読み取り  RunActionsAsUser = 14;         // ユーザーとしてアクション実行  WriteToClipboard = 15;         // クリップボードへの書き込み}このパーミッションモデルは「悪意あるプラグイン」より「バグのあるプラグイン」を想定している——と私は読んだ。考えてみてほしい。悪意あるプラグインを防ぎたいなら、ユーザーに許可を求めるUIは逆効果だ。ユーザーは深く考えずに「許可」を押す。AndroidやiOSの経験から、我々はそれを知っている。Zellijのパーミッションモデルが防いでいるのは、むしろ「うっかりファイルを消してしまうバグ」や「意図せずネットワークにアクセスしてしまう問題」だ。FullHdAccessを持つプラグインがファイルを誤削除するリスクを、ユーザーが明示的に受け入れる——そういう設計だと理解している。許可されたパーミッションはPermissionCacheにプラグイン名ごとに保存され、次回起動時は再確認されない。これも「毎回聞かれると面倒」という実用性を優先した判断だ。ANSIエスケープシーケンスのパースここまでプラグインの実行環境（WASM）、通信手段（Protocol Buffers）、安全性（パーミッション）を見てきた。ここからはサーバー側の話に移る。シェルの出力をどう画面に変換するか——その起点がANSIエスケープシーケンスのパースだ。ターミナルに表示される色付きの文字や、カーソルの移動は「ANSIエスケープシーケンス」で制御されている。\\x1b[31mが「赤色」、\\x1b[Hが「カーソルを左上に移動」。zellij-server/src/panes/grid.rsを開くと、vteクレート（Alacrittyチームが保守）を使っている。use vte::{Params, Perform};impl Perform for Grid {    // 通常文字の描画    fn print(\u0026mut self, c: char) {        self.add_character(c);    }    // C0/C1制御文字（改行、タブなど）    fn execute(\u0026mut self, byte: u8) {        match byte {            b'\\n' =\u003e self.move_cursor_down(1),            b'\\r' =\u003e self.move_cursor_to_beginning_of_line(),            b'\\t' =\u003e self.advance_to_next_tabstop(),            _ =\u003e {}        }    }    // CSIシーケンス（カーソル移動、色設定など）    fn csi_dispatch(\u0026mut self, params: \u0026Params, intermediates: \u0026[u8],                    _ignore: bool, action: char) {        // \\x1b[10;2H → カーソル移動        // \\x1b[36m → 色設定    }}Performトレイトを実装するだけで、vteがパースした結果を受け取れる。ANSIエスケープシーケンスの仕様は複雑で、エッジケースも多い。自作するより、実績のあるクレートを使う方が合理的だ。Alacrittyと同じクレートを使っている点も興味深い。ターミナルエミュレータの世界では、vteがデファクトスタンダードになりつつある。差分レンダリングの実装VTEパーサがANSIエスケープシーケンスを解釈し、Gridが更新される。次の問題は、そのGridをどう効率的に画面へ反映するかだ。全画面を毎回再描画すると遅い。zellij-server/src/output/mod.rsを見ると、変更された行だけを追跡している。// zellij-server/src/output/mod.rspub struct OutputBuffer {    pub changed_lines: HashSet\u003cusize\u003e,  // 変更行インデックス    pub should_update_all_lines: bool,    styled_underlines: bool,}impl Default for OutputBuffer {    fn default() -\u003e Self {        OutputBuffer {            changed_lines: HashSet::new(),            should_update_all_lines: true,  // 初回は全画面レンダリング            styled_underlines: true,        }    }}impl OutputBuffer {    pub fn update_line(\u0026mut self, line_index: usize) {        if !self.should_update_all_lines {            self.changed_lines.insert(line_index);        }    }    pub fn clear(\u0026mut self) {        self.changed_lines.clear();        self.should_update_all_lines = false;    }}なぜ「行レベル」であり「セル単位」ではないのか。セル単位の差分追跡も技術的には可能だ。しかし、ターミナルの出力は行単位で更新されることが多く、1文字だけ変わるケースは稀だ。セル単位にすると、追跡のオーバーヘッドが差分レンダリングの利点を上回る可能性がある。HashSetを使うことで、同じ行が複数回更新されても重複エントリが発生しない。シンプルだが効果的だ。パフォーマンス最適化の成果ここまで見てきた境界付きチャネルと差分レンダリングは、個別には小さな改善に見える。しかし、組み合わせると効果は大きい。開発者ブログによると、以下の最適化によりcat bigfileのベンチマークが大幅に改善された。ベンチマーク条件:- 測定コマンド: hyperfine --show-output \"cat /tmp/bigfile\"（10回実行の平均）- ファイルサイズ: 200万行- ペインサイズ: 59行 × 104列 段階  時間  最適化前  19.175秒 ± 0.347秒  境界付きチャネル導入後  9.658秒 ± 0.095秒  全最適化後  5.270秒 ± 0.027秒  tmux（参考）  5.593秒 このベンチマークではtmuxと同等以上のパフォーマンスを達成している。ただし、マシンスペックやtmuxのバージョン・設定は記載されていない。実環境での性能はワークロードや設定に依存するため、「Zellijの方が常に速い」とは言えない。重要なのは、適切な最適化によってRust製の新参者が30年の歴史を持つtmuxと同等のパフォーマンスを達成できた点だ。主な最適化は以下の4つだ。境界付きチャネルによるバックプレッシャー: 19秒→9秒の最大の貢献Vecの事前確保: Vec::with_capacity()で再確保を削減Unicode幅のキャッシュ: 絵文字などの幅計算を毎回やらない行レベル差分追跡: 変更行のみを再描画どれも「当たり前」の最適化だ。しかし、当たり前のことを愚直にやるのは難しい。ターミナル特有の問題への対処ここまで、チャネル、WASM、Protocol Buffers、ANSIパーサー、差分レンダリングと見てきた。どれも汎用的なパターンの応用だ。ここからは違う。ターミナルエミュレータでなければ出会わない問題ばかりだ。ソースコードを読んでいて、一番面白かったのはこのあたりだった。RcCharacterStyles: 16バイトに収めるメモリ効率化ターミナルの文字列バッファは数百万の要素を持つ。1文字あたりのメモリサイズがパフォーマンスに直結する。zellij-server/src/panes/terminal_character.rsを開く。// Enum Niche Optimization: 2つのvariantしかないため、ポインタサイズと同じ8バイトに収まる#[derive(Clone, Debug, PartialEq)]pub enum RcCharacterStyles {    Reset,    Rc(Rc\u003cCharacterStyles\u003e),}// compile-time assertionでメモリサイズを保証#[cfg(target_arch = \"x86_64\")]const _: [(); 8] = [(); std::mem::size_of::\u003cRcCharacterStyles\u003e()];// TerminalCharacter全体も16バイト#[cfg(target_arch = \"x86_64\")]const _: [(); 16] = [(); std::mem::size_of::\u003cTerminalCharacter\u003e()];// thread_local!でデフォルトスタイルをキャッシュし、メモリ再利用thread_local! {    static RC_DEFAULT_STYLES: RcCharacterStyles =        RcCharacterStyles::Rc(Rc::new(DEFAULT_STYLES));}impl Default for RcCharacterStyles {    fn default() -\u003e Self {        RC_DEFAULT_STYLES.with(|s| s.clone())  // thread_localから共有参照を取得    }}compile-time assertionが面白い。const _: [(); 16] = [(); std::mem::size_of::\u003cTerminalCharacter\u003e()];は、TerminalCharacterのサイズが16バイトでなければコンパイルエラーになる。将来フィールドを追加したとき、意図せずメモリサイズが増えることを防ぐ。Enum Niche Optimization + Reference Counting + thread_localの組み合わせで、リセット状態の文字スタイルをメモリ効率的に管理している。型安全性を失わずに、大規模なパフォーマンス最適化を実現しているのが印象的だ。PaneResizer: Cassowary制約ソルバーによるペイン配置ペインのレイアウト計算は、意外と難しい。「固定サイズのペイン」と「パーセンテージ指定のペイン」が混在し、ウィンドウリサイズ時に全体を再計算する必要がある。zellij-server/src/panes/tiled_panes/pane_resizer.rsを開く。use cassowary::{    strength::{REQUIRED, STRONG},    Expression, Solver, Variable,    WeightedRelation::EQ,};pub struct PaneResizer\u003c'a\u003e {    panes: Rc\u003cRefCell\u003cHashMap\u003cPaneId, \u0026'a mut Box\u003cdyn Pane\u003e\u003e\u003e\u003e,    vars: HashMap\u003cPaneId, Variable\u003e,    solver: Solver,}// 制約を設定: 「固定サイズペイン」と「パーセンテージペイン」の両方に対応fn constrain_spans(space: usize, spans: \u0026[Span]) -\u003e HashSet\u003ccassowary::Constraint\u003e {    let mut constraints = HashSet::new();    // 全ペインの合計サイズは、利用可能なスペースと等しい（REQUIRED強度）    let full_size = spans        .iter()        .fold(Expression::from_constant(0.0), |acc, s| acc + s.size_var);    constraints.insert(full_size.clone() | EQ(REQUIRED) | space as f64);    // 固定サイズはREQUIRED、パーセンテージはSTRONGで制約    for span in spans {        match span.size.constraint {            Constraint::Fixed(s) =\u003e constraints.insert(span.size_var | EQ(REQUIRED) | s as f64),            Constraint::Percent(p) =\u003e constraints                .insert((span.size_var / new_flex_space as f64) | EQ(STRONG) | (p / 100.0)),        };    }    constraints}// 丸め誤差の分配: error.signum()で±1ずつペインサイズを調整for span in flex_spans {    rounded_sizes        .entry(span.size_var)        .and_modify(|s| *s += error.signum());    error -= error.signum();}Cassowaryは線形計画法を使った制約ソルバーだ。元々はmacOSのAuto Layoutに使われていたアルゴリズムで、それをペインレイアウトに応用している。REQUIREDとSTRONGの強度で優先度を管理するのが賢い。固定サイズのペインは絶対に守られ、パーセンテージ指定のペインは「できるだけ守る」という柔軟性を持つ。error.signum()で丸め誤差を1ピクセルずつ分配するのも秀逸だ。浮動小数点の計算結果を整数に変換すると、どうしても誤差が出る。その誤差を均等にばらまくことで、ギャップやオーバーラップを回避している。HyperlinkTracker: カーソルジャンプ検出によるURL追跡ターミナルでURLをクリック可能にするには、「文字列がURLかどうか」を検出する必要がある。しかし、ターミナルは1文字ずつ出力されるため、URLの開始と終了を正確に把握するのは難しい。zellij-server/src/panes/hyperlink_tracker.rsを開く。pub struct HyperlinkTracker {    buffer: String,    cursor_positions: Vec\u003cHyperlinkPosition\u003e,  // 各文字のカーソル位置を記録    start_position: Option\u003cHyperlinkPosition\u003e,    last_cursor: Option\u003cHyperlinkPosition\u003e,    // カーソルジャンプ検出用}// カーソルが「連続的に移動していない」ことを検出fn should_reset_due_to_cursor_jump(\u0026self, current_pos: \u0026HyperlinkPosition) -\u003e bool {    if let Some(last_pos) = \u0026self.last_cursor {        let is_contiguous =            // 同一行の隣（通常の文字出力）            (current_pos.y == last_pos.y \u0026\u0026 current_pos.x == last_pos.x + 1) ||            // 改行（行の折り返し）            (current_pos.y == last_pos.y + 1 \u0026\u0026 current_pos.x == 0) ||            // 同じ位置（上書き）            (current_pos.y == last_pos.y \u0026\u0026 current_pos.x == last_pos.x);        !is_contiguous    } else {        false    }}カーソルジャンプ = URLの中断と判定するのが面白い。例えば、https://example.comと出力される途中で、プロンプトに戻るためにカーソルが左上にジャンプしたら、URLは完了したと見なす。複数行にまたがるURLや、ターミナルの折り返しにも対応している。Sixel画像: 負の座標とオーバーラップ判定Sixelは、ターミナル内に画像を表示するための古い規格だ。Zellijはこれをサポートしているが、スクロール時の挙動が複雑になる。zellij-server/src/panes/sixel.rsを開く。#[derive(Debug, Clone, Copy, Default, PartialEq, Eq, Hash)]pub struct PixelRect {    pub x: usize,    pub y: isize,  // 負の値対応！スクロールバッファの上部に消えた画像    pub width: usize,    pub height: usize,}// 新しい画像が古い画像を完全に覆った場合、古い画像を削除for (image_id, pixel_rect) in \u0026self.sixel_image_locations {    if let Some(intersecting_rect) = pixel_rect.intersecting_rect(\u0026image_size_and_coordinates) {        if intersecting_rect.x == pixel_rect.x            \u0026\u0026 intersecting_rect.y == pixel_rect.y            \u0026\u0026 intersecting_rect.height == pixel_rect.height            \u0026\u0026 intersecting_rect.width == pixel_rect.width        {            self.image_ids_to_reap.push(*image_id);  // 完全に覆われた→削除予定        }    }}y: isizeが興味深い。スクロールで画像がバッファの上部に消えると、yが負の値になる。usizeではなくisizeにすることで、この状況を型で表現している。完全にオーバーラップした画像は自動でメモリ解放される。Sixel画像は計算コストが高いため、不要な画像を積極的に削除するのは合理的だ。ダブルクリック検出: Doherty Thresholdマウスのダブルクリック検出には、時間閾値が必要だ。ZellijはDoherty Thresholdという値を使っている。zellij-server/src/panes/grid.rsを開く。const CLICK_TIME_THRESHOLD: u128 = 400;  // Doherty Thresholdimpl Click {    pub fn record_click(\u0026mut self, position: Position) {        let click_is_same_position = self.position_and_time            .map(|(p, _t)| p == position)            .unwrap_or(false);        let click_is_within_time_threshold = self.position_and_time            .map(|(_p, t)| t.elapsed().as_millis() \u003c= CLICK_TIME_THRESHOLD)            .unwrap_or(false);        if click_is_same_position \u0026\u0026 click_is_within_time_threshold {            self.count += 1;        } else {            self.count = 1;        }        if self.count == 4 {            self.reset();  // 3クリックまで（単語選択、行選択、段落選択）        }    }}400msという数字は、1982年のDoherty \u0026 Kelisky論文に由来する。「ユーザーがシステムの反応を待てる限界」とされる時間だ。3クリックまで対応しているのも面白い。1クリック=カーソル移動、2クリック=単語選択、3クリック=行選択。4クリック目でリセットされる。クライアント側のターミナル制御PTYの実装に入る前に、クライアント側の処理を見ておく必要がある。ユーザーのキー入力がサーバーに届くまでの道筋——つまり、データフローの入口だ。Raw Mode vs Cooked Mode追加知識セクションでtermios構造体とRaw Modeの概念を紹介した。Zellijの実装では、具体的にどうRaw Modeに入るのか。通常のターミナルは「Cooked Mode」で動作する。カーネルが行編集（バックスペース、Ctrl+Wなど）を処理し、Enterで1行ずつアプリケーションに渡す。Ctrl+Cを押すとSIGINTが送られる。Zellijはこれを無効にする必要がある。すべてのキー入力を自分で処理したいからだ。zellij-client/src/os_input_output.rsを開く。fn into_raw_mode(pid: RawFd) {    let mut tio = termios::tcgetattr(pid).expect(\"could not get terminal attribute\");    termios::cfmakeraw(\u0026mut tio);    match termios::tcsetattr(pid, termios::SetArg::TCSANOW, \u0026tio) {        Ok(_) =\u003e {},        Err(e) =\u003e panic!(\"error {:?}\", e),    };}fn unset_raw_mode(pid: RawFd, orig_termios: termios::Termios) -\u003e Result\u003c(), nix::Error\u003e {    termios::tcsetattr(pid, termios::SetArg::TCSANOW, \u0026orig_termios)}cfmakeraw() は以下を無効にする。ECHO: 入力文字のエコーバックICANON: 行単位の入力（カノニカルモード）ISIG: Ctrl+C/Ctrl+Zによるシグナル生成IXON/IXOFF: ソフトウェアフロー制御（Ctrl+S/Ctrl+Q）TCSANOW は「今すぐ適用」を意味する。TCSADRAIN（出力完了後）やTCSAFLUSH（バッファ破棄）もあるが、入力処理では即座の適用が必要だ。元のtermiosを保存しておき、終了時に復元する。これを忘れると、Zellij終了後にターミナルが壊れた状態になる。SIGWINCHのスロットリングターミナルウィンドウをリサイズすると、OSはSIGWINCHを送る。問題は、GUIウィンドウをドラッグでリサイズすると、1秒間に数十〜数百回のシグナルが発火することだ。fn handle_signals(\u0026self, sigwinch_cb: Box\u003cdyn Fn()\u003e, quit_cb: Box\u003cdyn Fn()\u003e) {    let mut sigwinch_cb_timestamp = time::Instant::now();    let mut signals = Signals::new(\u0026[SIGWINCH, SIGTERM, SIGINT, SIGQUIT, SIGHUP]).unwrap();    for signal in signals.forever() {        match signal {            SIGWINCH =\u003e {                // SIGWINCHコールバックをスロットリング                if sigwinch_cb_timestamp.elapsed() \u003c SIGWINCH_CB_THROTTLE_DURATION {                    thread::sleep(SIGWINCH_CB_THROTTLE_DURATION);                }                sigwinch_cb_timestamp = time::Instant::now();                sigwinch_cb();            },            SIGTERM | SIGINT | SIGQUIT | SIGHUP =\u003e {                quit_cb();                break;            },            _ =\u003e unreachable!(),        }    }}SIGWINCH_CB_THROTTLE_DURATIONは50msだ。リサイズイベントが来ても、前回から50ms経っていなければ待機する。これにより、毎秒数十回のレンダリングを防ぐ。50msという値は経験則だ。人間が「遅延」と感じる閾値（100ms）より短く、ターミナルが処理できる頻度（60fps = 16ms）より長い。同期出力（Synchronized Output）最新のターミナルエミュレータは「同期出力」をサポートしている。複数の出力をバッファリングし、まとめて画面に反映する機能だ。let synchronised_output = match os_input.env_variable(\"TERM\").as_deref() {    Some(\"alacritty\") =\u003e Some(SyncOutput::DCS),    _ =\u003e None,};// レンダリング時if let Some(sync) = synchronised_output {    stdout.write_all(sync.start_seq()).expect(\"cannot write to stdout\");}stdout.write_all(output.as_bytes()).expect(\"cannot write to stdout\");if let Some(sync) = synchronised_output {    stdout.write_all(sync.end_seq()).expect(\"cannot write to stdout\");}DCS（Device Control String）で出力を囲む。ターミナルはDCS開始からDCS終了までの出力をバッファリングし、終了シーケンスを受け取った時点でまとめて描画する。これにより、レイアウト変更時の「ちらつき」が消える。中間状態（ペインが1つだけ描画された状態など）が画面に表示されない。現時点ではAlacrittyのみ対応だが、今後他のターミナルにも拡大されるだろう。Kitty Keyboard Protocol従来のターミナルは、Shift+F1とF13を区別できなかった。どちらも同じエスケープシーケンスを送るからだ。Kitty Keyboard Protocolはこの問題を解決する。zellij-client/src/stdin_handler.rsを開く。loop {    match os_input.read_from_stdin() {        Ok(buf) =\u003e {            // まずKitty Keyboard Protocolを試す            if !explicitly_disable_kitty_keyboard_protocol {                match KittyKeyboardParser::new().parse(\u0026buf) {                    Some(key_with_modifier) =\u003e {                        send_input_instructions.send(...).unwrap();                        continue;                    },                    None =\u003e {},                }            }            // フォールバック: 標準のtermwiz InputParser            input_parser.parse(\u0026buf, |input_event| { ... }, false);        },        // ...    }}Kitty Keyboard Protocolが使えるなら使い、使えなければ従来のANSIエスケープシーケンスにフォールバックする。この二段構えにより、古いターミナルでも動作しつつ、新しいターミナルでは拡張機能を活用できる。セッション切り替え時のSTDINバッファリングZellijは複数のセッションを持てる。セッション間を切り替えるとき、STDINの所有権を移す必要がある。fn read_from_stdin(\u0026mut self) -\u003e Result\u003cVec\u003cu8\u003e, \u0026'static str\u003e {    let session_name_at_calltime = { self.session_name.lock().unwrap().clone() };    let mut buffered_bytes = self.reading_from_stdin.lock().unwrap();    match buffered_bytes.take() {        Some(buffered_bytes) =\u003e Ok(buffered_bytes),        None =\u003e {            let stdin = std::io::stdin();            let mut stdin = stdin.lock();            let buffer = stdin.fill_buf().unwrap();            let length = buffer.len();            let read_bytes = Vec::from(buffer);            stdin.consume(length);            // セッションが変わったら、読んだバイトをバッファに戻す            let session_name_after_reading_from_stdin =                { self.session_name.lock().unwrap().clone() };            if session_name_at_calltime.is_some()                \u0026\u0026 session_name_at_calltime != session_name_after_reading_from_stdin            {                *buffered_bytes = Some(read_bytes);                Err(\"Session ended\")            } else {                Ok(read_bytes)            }        },    }}問題: 旧セッションのスレッドがSTDINでブロックしている間に、新セッションがSTDINを必要とする。解決策: 読み取り前後でセッション名を比較する。セッションが変わっていたら、読んだバイトをバッファに保存し、新セッションのスレッドがそれを取得できるようにする。これはエッジケースだが、マルチセッション対応には必須の処理だ。PTY（疑似端末）の実装詳細ここまで見てきた境界付きチャネル、VTEパーサ、差分レンダリング、compile-time assertion——これらはすべて、PTYという土台の上に乗っている。チャネルはPTYからの出力を運び、VTEパーサはPTYが吐いたバイト列を解釈し、差分レンダリングはその結果を画面に描く。個別のパターンを追いかけてきたが、ここで全体が合流する。ターミナルマルチプレクサの核心部分であるPTY処理を深掘りする。ここがZellijの「心臓部」だ。そもそもTTYとPTYとは何かTTY（TeleTYpewriter）は、歴史的にはテレタイプ端末を指す。現代では「ターミナルデバイス」の総称として使われる。/dev/ttyや/dev/tty1がこれにあたる。PTY（Pseudo-TTY）は「疑似端末」だ。物理的な端末がなくても、ソフトウェア的にターミナルをエミュレートする仕組み。sshやtmux、そしてZellijはPTYを使っている。PTYはマスターとスレーブのペアで構成される。[Zellij Server] ←→ [PTY Master] ←→ [PTY Slave] ←→ [Shell/App]                    (制御側)         (端末側)マスター側: Zellijが持つ。ここに書き込むと、スレーブ側のSTDINに届く。スレーブの出力はここから読めるスレーブ側: シェル（bash/zsh）が持つ。通常のターミナルと同じように振る舞うシェルから見ると、スレーブPTYは「本物のターミナル」に見える。ttyコマンドを実行すると/dev/pts/0のようなパスが返る。これがスレーブPTYだ。Zellijがペインを作るたびに、新しいPTYペアが生成される。3ペインあれば、3つのPTYマスターをZellijが管理している。なぜPTYが必要なのか「パイプでいいのでは？」と思うかもしれない。しかし、パイプとPTYには決定的な違いがある。ジョブコントロール: PTYは「制御端末」として機能する。Ctrl+Zでプロセスを停止したり、fg/bgで制御したりできるのは、PTYがあるからだ。パイプにはこの機能がないウィンドウサイズ: PTYはサイズ（行数・列数）を持つ。$COLUMNSや$LINESはPTYから取得される。パイプにはサイズの概念がない行編集: シェルは「端末があるかどうか」で挙動を変える。isatty()がtrueを返すと、プロンプトを表示し、行編集を有効にする。パイプ経由だとこれが無効になるシグナル: Ctrl+CでSIGINTを送れるのは、PTYが「フォアグラウンドプロセスグループ」を管理しているからだつまり、PTYなしには「ターミナルらしい体験」が成り立たない。PTYの作成フローzellij-server/src/os_input_output.rsを開く。fn handle_openpty(    open_pty_res: OpenptyResult,    cmd: RunCommand,    quit_cb: Box\u003cdyn Fn(PaneId, Option\u003ci32\u003e, RunCommand) + Send\u003e,    terminal_id: u32,) -\u003e Result\u003c(RawFd, RawFd)\u003e {    let pid_primary = open_pty_res.master;    // Zellij側（ホスト）    let pid_secondary = open_pty_res.slave;   // シェル側（子プロセス）    let mut child = unsafe {        Command::new(cmd.command)            .args(\u0026cmd.args)            .env(\"ZELLIJ\", VERSION)            .env(\"ZELLIJ_SESSION_NAME\", \u0026*SESSION_NAME)            .env(\"ZELLIJ_PANE_ID\", \u0026format!(\"{}\", terminal_id))            .pre_exec(move || -\u003e std::io::Result\u003c()\u003e {                if libc::login_tty(pid_secondary) != 0 {                    panic!(\"failed to set controlling terminal\");                }                close_fds::close_open_fds(3, \u0026[]);                Ok(())            })            .spawn()            .expect(\"failed to spawn\")    };    // 子プロセスの終了を監視するスレッドを起動    std::thread::spawn({        move || {            child.wait().ok();            let exit_status = child.try_wait().ok().flatten().and_then(|e| e.code());            quit_cb(PaneId::Terminal(terminal_id), exit_status, cmd);        }    });    Ok((pid_primary, child.id() as RawFd))}openpty() はマスターとスレーブの2つのファイルディスクリプタを作る。Zellijはマスター側を持ち、シェル（bashやzsh）はスレーブ側を持つ。login_tty() は伝統的なUnix関数で、3つのことをする。setsid() で新しいセッションを作成スレーブPTYをcontrolling terminalに設定dup2() でstdin/stdout/stderrをスレーブに接続close_fds::close_open_fds(3, \u0026[]) が面白い。ファイルディスクリプタ3以降を全て閉じる。これにより、親プロセスから継承した不要なFDがリークしない。環境変数の設定も注目に値する。ZELLIJ_PANE_IDを設定することで、子プロセス側から「自分がどのペインで動いているか」を知ることができる。シェルスクリプトやプラグインで使える。読み取りと書き込みの分離PTYへの読み書きは、別々のスレッドで行われる。なぜか。zellij-server/src/terminal_bytes.rsを開く。pub(crate) struct TerminalBytes {    pid: RawFd,    terminal_id: u32,    senders: ThreadSenders,    async_reader: Box\u003cdyn AsyncReader\u003e,    debug: bool,}impl TerminalBytes {    pub async fn listen(\u0026mut self) -\u003e Result\u003c()\u003e {        let mut buf = [0u8; 65536];  // 64KBバッファ        loop {            match self.async_reader.read(\u0026mut buf).await {                Ok(0) =\u003e break,  // EOF（プロセス終了）                Err(err) =\u003e {                    log::error!(\"{}\", err);                    break;                },                Ok(n_bytes) =\u003e {                    let bytes = \u0026buf[..n_bytes];                    self.async_send_to_screen(ScreenInstruction::PtyBytes(                        self.terminal_id,                        bytes.to_vec(),                    ))                    .await?;                },            }        }        // ループ終了後、最終レンダリングを要求        let _ = self.async_send_to_screen(ScreenInstruction::Render).await;        Ok(())    }}64KBバッファ。一般的な8KBや4KBではなく、大きめのサイズだ。大量のログ出力に対応するため。Ok(0)とErrの区別が重要。Ok(0)はEOF（プロセスが終了した）、Errは本当のエラー。この区別を間違えると、プロセス正常終了時にエラーログが出てしまう。zellij-server/src/pty_writer.rsを開く。pub(crate) fn pty_writer_main(bus: Bus\u003cPtyWriteInstruction\u003e) -\u003e Result\u003c()\u003e {    loop {        let (event, _err_ctx) = bus.recv()?;        match event {            PtyWriteInstruction::Write(bytes, terminal_id) =\u003e {                if let Some(raw_fd) = bus                    .os_input                    .as_ref()                    .and_then(|os_input| os_input.get_terminal_id_from_fd(terminal_id))                {                    let mut f = unsafe { File::from_raw_fd(*raw_fd) };                    if f.write_all(\u0026bytes).is_ok() {                        let _ = f.flush();                    }                    std::mem::forget(f);  // FDを閉じないようにする                }            },            PtyWriteInstruction::Exit =\u003e break,        }    }    Ok(())}読み取りと書き込みを分離する理由は、デッドロック回避だ。Vimのようなプログラムは、STDINからの入力を待ちながらSTDOUTに出力する。もし同じスレッドで読み書きをすると、「Vimが入力を待っている」「Zellijが出力を待っている」という状態でデッドロックになる可能性がある。std::mem::forget(f) も興味深い。File::from_raw_fd()で作ったFileは、dropされるとFDが閉じてしまう。forget()でdropを防いでいる。forgetという名前は不穏だ。普通、忘れることは悪いことだ。しかしRustの所有権モデルでは、意図的に忘れることが正しい選択になる場合がある。FDを閉じたくないなら、Fileがdropされることを忘れさせる。記憶と忘却の関係が、ここでは逆転している。tcdrainによるフロー制御書き込みスレッドには、もう一つ重要な処理がある。PtyWriteInstruction::Write(bytes, terminal_id) =\u003e {    os_input        .write_to_tty_stdin(terminal_id, \u0026bytes)        .with_context(err_context)        .non_fatal();    os_input        .tcdrain(terminal_id)  // ここ        .with_context(err_context)        .non_fatal();},tcdrain() は、書き込んだデータが全て送信されるまでブロックする。なぜこれが必要か。PTYにはカーネル内部にバッファがある。write()はバッファに書き込んだ時点で返る。しかし、相手側（シェル）がまだ読んでいない可能性がある。tcdrain()を呼ぶと、バッファが空になるまで待機する。これにより、次の書き込みが前の書き込みを追い越すことを防ぐ。fn tcdrain(\u0026self, terminal_id: u32) -\u003e Result\u003c()\u003e {    match self        .terminal_id_to_raw_fd        .lock()        .to_anyhow()        .with_context(err_context)?        .get(\u0026terminal_id)    {        Some(Some(fd)) =\u003e termios::tcdrain(*fd).with_context(err_context),        _ =\u003e Err(anyhow!(\"could not find raw file descriptor\")).with_context(err_context),    }}ソースコードのコメントには、こうある。「VimのようなプログラムはSTDINに書き込みながらSTDOUTを読むとデッドロックする」。Vimへの言及が具体的で、実際に遭遇した問題なのだろう。ウィンドウリサイズの処理ターミナルをリサイズしたとき、PTYにサイズ変更を伝える必要がある。zellij-server/src/os_input_output.rsを開く。fn set_terminal_size_using_terminal_id(    \u0026self,    id: u32,    cols: u16,    rows: u16,    width_in_pixels: Option\u003cu16\u003e,    height_in_pixels: Option\u003cu16\u003e,) -\u003e Result\u003c()\u003e {    // リサイズをキャッシュ（複数のリサイズイベントを1つにまとめる）    match self.cached_resizes.lock() {        Ok(mut cached_resizes) =\u003e {            let cached_resizes = cached_resizes.get_or_insert_with(BTreeMap::new);            cached_resizes.insert(id, (cols, rows, width_in_pixels, height_in_pixels));        },        Err(e) =\u003e {            log::error!(\"Failed to cache resize: {}\", e);        },    }    // キャッシュを適用    self.apply_cached_resizes()}fn apply_cached_resizes(\u0026self) -\u003e Result\u003c()\u003e {    if let Some(cached_resizes) = self.cached_resizes.lock().ok().as_mut().and_then(|c| c.take()) {        for (terminal_id, (cols, rows, width_in_pixels, height_in_pixels)) in cached_resizes {            let ws = Winsize {                ws_row: rows,                ws_col: cols,                ws_xpixel: width_in_pixels.unwrap_or(0),                ws_ypixel: height_in_pixels.unwrap_or(0),            };            if let Some(raw_fd) = self.get_terminal_id_from_fd(terminal_id) {                set_terminal_size_using_fd(*raw_fd, ws);            }        }    }    Ok(())}fn set_terminal_size_using_fd(fd: RawFd, ws: Winsize) {    // TIOCSWINSZ ioctlでPTYにサイズを伝える    if let Err(e) = ioctl_set_window_size(fd, \u0026ws) {        log::error!(\"Failed to set terminal size: {}\", e);    }}リサイズのキャッシングが重要だ。なぜか。ソースコードのコメントに理由がある。「レイアウト計算のコードには、複数のリサイズを送信してしまうロジックの罠がある。最後の1つだけが正しいのだが、多くのプログラムやシェルはリサイズをデバウンスする（GUIウィンドウのリサイズに対処してきたトラウマだろう）。これがグリッチや描画漏れを引き起こす」。つまり、VimやZshは「リサイズが連続で来たら、最後の1つだけ処理する」という防御策を持っている。Zellijが中間のリサイズも送ると、シェル側のデバウンスと競合してしまう。だからZellij側でもキャッシュし、最後の1つだけを送る。PtyWriteInstruction::StartCachingResizes =\u003e {    // レイアウト再計算中はリサイズをキャッシュ    os_input.cache_resizes();},PtyWriteInstruction::ApplyCachedResizes =\u003e {    // 計算完了後、最後のリサイズだけを適用    os_input.apply_cached_resizes();},TIOCSWINSZ（Terminal I/O Control Set WINdow SiZe）は、PTYにサイズを伝えるioctlだ。これを呼ぶと、カーネルは子プロセスグループにSIGWINCHを送る。子プロセスはこのシグナルを受けて、画面を再描画する。ws_xpixelとws_ypixel はSixel画像のために使われる。文字単位のサイズ（cols/rows）に加えて、ピクセル単位のサイズも伝える。これにより、画像を正確な解像度で表示できる。プロセス終了の検出とシグナルペインを閉じるとき、子プロセスにシグナルを送る必要がある。pub fn close_pane(\u0026mut self, id: PaneId) -\u003e Result\u003c()\u003e {    match id {        PaneId::Terminal(id) =\u003e {            self.task_handles.remove(\u0026id);  // 読み取りタスクを停止            if let Some(child_fd) = self.id_to_child_pid.remove(\u0026id) {                task::block_on(async {                    self.bus                        .os_input                        .as_mut()                        .fatal()                        .kill(Pid::from_raw(child_fd))  // SIGHUPを送信                        .fatal();                });            }        },        PaneId::Plugin(pid) =\u003e {            // プラグインはUnload命令を送るだけ            drop(self.bus.senders.send_to_plugin(PluginInstruction::Unload(pid)));        },    }    Ok(())}シグナルの送信順序も工夫されている。// SIGTERMを3回試行し、それでも終了しなければSIGKILLfor _ in 0..3 {    if nix::sys::signal::kill(pid, Signal::SIGTERM).is_ok() {        std::thread::sleep(Duration::from_millis(10));        // プロセスが終了したかチェック        if nix::sys::wait::waitpid(pid, Some(WaitPidFlag::WNOHANG)).is_ok() {            return Ok(());        }    }}// 3回失敗したらSIGKILLnix::sys::signal::kill(pid, Signal::SIGKILL)?;SIGTERM 3回 → SIGKILL。プロセスに「正常終了」の機会を与えつつ、応答しなければ強制終了する。10msのポーリング間隔も絶妙だ。CWD（カレントディレクトリ）の追跡ペインのカレントディレクトリを追跡するのは、意外と難しい。fn get_cwd(\u0026self, pid: Pid) -\u003e Option\u003cPathBuf\u003e {    // /proc/[pid]/cwd を読み取る    let path = format!(\"/proc/{}/cwd\", pid);    std::fs::read_link(path).ok()}pub fn update_and_report_cwds(\u0026mut self) {    let terminal_ids: Vec\u003cu32\u003e = self.id_to_child_pid.keys().copied().collect();    let pids: Vec\u003c_\u003e = terminal_ids        .iter()        .filter_map(|id| self.id_to_child_pid.get(\u0026id))        .map(|pid| Pid::from_raw(*pid))        .collect();    // 全ペインのCWDを一括取得    let (pids_to_cwds, _) = self        .bus        .os_input        .as_ref()        .map(|os_input| os_input.get_cwds(pids))        .unwrap_or_default();    // 変更があればクライアントに通知    for terminal_id in terminal_ids {        let cwd = /* ... */;        if self.terminal_cwds.get(\u0026terminal_id) != Some(cwd) {            // CWD変更イベントを送信        }    }}/proc/[pid]/cwd はLinux固有の仕組みだ。プロセスのカレントディレクトリへのシンボリックリンクになっている。これを定期的にチェックすることで、cdコマンドによるディレクトリ変更を検出できる。データフローの全体像PTYを通じたデータの流れを図にすると、以下のようになる。[ユーザー入力]     ↓ キー入力[Client Process]     ↓ IPC (Unix Domain Socket)[Server Process]     ↓ PtyWriteInstruction::Write[PTY Writer Thread]     ↓ write() to master FD[PTY (カーネル)]     ↓[Shell/アプリケーション]     ↓ 出力[PTY (カーネル)]     ↓ read() from master FD[TerminalBytes::listen()]     ↓ ScreenInstruction::PtyBytes[Screen Thread]     ↓ VTEパーサ[Grid構造体]     ↓ 差分レンダリング[Client Process]     ↓ IPC[ユーザーの画面]6つのスレッドが協調して動いている。PTY Thread: PTYの作成・管理PTY Writer Thread: PTYへの書き込みTerminalBytes（async task）: PTYからの読み取りScreen Thread: VTEパース、レンダリングPlugin Thread: WASMプラグイン実行Background Thread: 非同期タスクこの分離により、どこか1つがブロックしても他の処理は継続できる。Vimが入力を待っている間も、他のペインは正常に動作する。実装の詳細：システムコールのシーケンスここまで概念的な説明が多かった。実際にどのシステムコールがどの順序で呼ばれるのか、具体的に見ていこう。PTY作成シーケンス1. openpty(None, \u0026orig_termios)   → OpenptyResult { master: RawFd, slave: RawFd }2. fork() [Command::spawn()が内部で呼ぶ]3. 子プロセス（シェル側）:   - libc::login_tty(slave)     - setsid()      // 新しいセッション作成     - ioctl(slave, TIOCSCTTY)  // 制御端末として設定     - dup2(slave, 0)  // stdin     - dup2(slave, 1)  // stdout     - dup2(slave, 2)  // stderr   - close_open_fds(3, \u0026[])  // FD 3以降を全て閉じる   - exec(\"/bin/bash\")  // シェルを起動4. 親プロセス（Zellij側）:   - master FDを保存   - 子プロセスのPIDを保存   - 非同期読み取りタスクを起動   - シグナルハンドラスレッドを起動PTY読み取りシーケンス1. async_reader.read(\u0026mut buf[65536])   → read(master_fd, buf, 65536) syscall   → bytes受信 or EOF(0) or error2. ScreenInstruction::PtyBytes(terminal_id, bytes)   をチャネル経由でScreenスレッドに送信3. Screenスレッドがbytesを受信   → VTEパーサに渡す   → Gridを更新PTY書き込みシーケンス1. PtyWriteInstruction::Write(bytes, terminal_id)   をチャネル経由で受信2. terminal_id_to_raw_fd マップからmaster FDを取得3. write(master_fd, bytes) syscall   → バイトがPTYバッファに書き込まれる4. tcdrain(master_fd) syscall   → 書き込みが完了するまで待機ターミナルリサイズシーケンス1. PtyWriteInstruction::ResizePty(terminal_id, cols, rows, ...)   をチャネル経由で受信2. terminal_id_to_raw_fd マップからmaster FDを取得3. ioctl(master_fd, TIOCSWINSZ, \u0026Winsize { ws_col, ws_row, ... })   → カーネルがSIGWINCHを子プロセスグループに送信   → シェルが再描画実装の詳細：スレッドの起動サーバープロセスの起動時、複数のスレッドが生成される。zellij-server/src/lib.rsを開く。pub fn start_server(mut os_input: Box\u003cdyn ServerOsApi\u003e, socket_path: PathBuf) {    // チャネルの作成    let (to_server, server_receiver): ChannelWithContext\u003cServerInstruction\u003e =        channels::bounded(50);    let (to_screen, screen_receiver): ChannelWithContext\u003cScreenInstruction\u003e =        channels::bounded(50);    let (to_pty, pty_receiver): ChannelWithContext\u003cPtyInstruction\u003e =        channels::bounded(50);    let (to_plugin, plugin_receiver): ChannelWithContext\u003cPluginInstruction\u003e =        channels::bounded(50);    let (to_pty_writer, pty_writer_receiver): ChannelWithContext\u003cPtyWriteInstruction\u003e =        channels::unbounded();  // 書き込みは無制限    // PTY Writerスレッド    thread::Builder::new()        .name(\"pty_writer\".to_string())        .spawn(move || {            pty_writer_main(pty_writer_bus).fatal();        })        .unwrap();    // PTYスレッド    thread::Builder::new()        .name(\"pty\".to_string())        .spawn(move || {            pty_thread_main(pty_bus, pty_receiver).fatal();        })        .unwrap();    // Screenスレッド    thread::Builder::new()        .name(\"screen\".to_string())        .spawn(move || {            screen_thread_main(screen_bus, screen_receiver).fatal();        })        .unwrap();    // Pluginスレッド    thread::Builder::new()        .name(\"plugin\".to_string())        .spawn(move || {            plugin_thread_main(plugin_bus, plugin_receiver).fatal();        })        .unwrap();    // Serverスレッド（メインループ）    loop {        let (instruction, err_ctx) = server_receiver.recv().expect(\"...\");        match instruction {            ServerInstruction::NewClient(client_attributes, ...) =\u003e { ... },            ServerInstruction::Render(serialized_output) =\u003e { ... },            ServerInstruction::UnblockInputThread =\u003e { ... },            ServerInstruction::ClientExit(client_id) =\u003e { ... },            ServerInstruction::KillSession =\u003e break,            // ...        }    }}注目すべきは、PTY Writerのチャネルだけunbounded()になっている点だ。他はbounded(50)でバックプレッシャーをかけているが、書き込みはブロックさせたくない。ユーザーの入力を遅延させると体感が悪くなるからだ。実装の詳細：キーボード入力からシェルまでの経路ユーザーがキーを押してからシェルに届くまでの、実際のコード経路を追う。1. クライアントがキー入力を受信zellij-client/src/stdin_handler.rsloop {    match os_input.read_from_stdin() {        Ok(buf) =\u003e {            // KittyプロトコルまたはANSIエスケープをパース            input_parser.parse(\u0026buf, |input_event| {                send_input_instructions                    .send(InputInstruction::KeyEvent(                        input_event.clone(),                        buf.to_vec(),                    ))                    .unwrap();            }, false);        },        // ...    }}2. クライアントがサーバーにメッセージ送信zellij-client/src/lib.rsInputInstruction::KeyEvent(key_event, raw_bytes) =\u003e {    send_client_instructions        .send(ClientInstruction::Action(            Action::Write(None, raw_bytes, false),            None,            None,        ))        .unwrap();}3. サーバーのRouteスレッドがメッセージ受信zellij-server/src/route.rsfn route_action(action: Action, ...) -\u003e bool {    match action {        Action::Write(_, bytes, _) =\u003e {            session                .senders                .send_to_screen(ScreenInstruction::WriteCharacter(bytes, client_id))                .unwrap();        },        // ...    }}4. Screenスレッドがペインに書き込み指示zellij-server/src/screen.rsScreenInstruction::WriteCharacter(bytes, client_id) =\u003e {    let active_tab = screen.get_active_tab_mut(client_id).unwrap();    active_tab.write_to_terminal(bytes, client_id);}5. TabがPTY Writerに書き込み指示zellij-server/src/tab/mod.rspub fn write_to_active_terminal(\u0026mut self, bytes: Vec\u003cu8\u003e, client_id: ClientId) {    if let Some(active_pane_id) = self.get_active_pane_id(client_id) {        if let PaneId::Terminal(terminal_id) = active_pane_id {            self.senders                .send_to_pty_writer(PtyWriteInstruction::Write(bytes, terminal_id))                .unwrap();        }    }}6. PTY Writerスレッドが実際に書き込みzellij-server/src/pty_writer.rsPtyWriteInstruction::Write(bytes, terminal_id) =\u003e {    os_input.write_to_tty_stdin(terminal_id, \u0026bytes)?;    os_input.tcdrain(terminal_id)?;}7. OSレイヤーでシステムコールzellij-server/src/os_input_output.rsfn write_to_tty_stdin(\u0026self, terminal_id: u32, buf: \u0026[u8]) -\u003e Result\u003cusize\u003e {    let fd = self.terminal_id_to_raw_fd.lock()?.get(\u0026terminal_id)?;    let mut file = unsafe { File::from_raw_fd(*fd) };    let result = file.write(buf);    std::mem::forget(file);  // FDを閉じない    result}この経路で、キーボード入力は6つのコンポーネントを経由してシェルに届く。各コンポーネント間はチャネルで接続されている。実装の詳細：シェル出力から画面までの経路逆方向、シェルの出力が画面に表示されるまでの経路。1. TerminalBytesが非同期で読み取りzellij-server/src/terminal_bytes.rspub async fn listen(\u0026mut self) -\u003e Result\u003c()\u003e {    let mut buf = [0u8; 65536];    loop {        match self.async_reader.read(\u0026mut buf).await {            Ok(0) =\u003e break,  // EOF            Ok(n_bytes) =\u003e {                let bytes = \u0026buf[..n_bytes];                self.async_send_to_screen(ScreenInstruction::PtyBytes(                    self.terminal_id,                    bytes.to_vec(),                )).await?;            },            Err(err) =\u003e {                log::error!(\"{}\", err);                break;            },        }    }    Ok(())}2. Screenスレッドがバイトを受信zellij-server/src/screen.rsScreenInstruction::PtyBytes(terminal_id, bytes) =\u003e {    // terminal_idからペインを特定    if let Some(tab) = screen.get_tab_with_terminal_id(terminal_id) {        tab.handle_pty_bytes(terminal_id, bytes);    }}3. TabがVTEパーサに渡すzellij-server/src/tab/mod.rspub fn handle_pty_bytes(\u0026mut self, terminal_id: u32, bytes: Vec\u003cu8\u003e) {    if let Some(pane) = self.panes.get_mut(\u0026PaneId::Terminal(terminal_id)) {        pane.handle_pty_bytes(bytes);    }}4. TerminalPaneがGridを更新zellij-server/src/panes/terminal_pane.rsfn handle_pty_bytes(\u0026mut self, bytes: Vec\u003cu8\u003e) {    self.grid.advance_by_bytes(bytes);}5. GridがVTEパーサを実行zellij-server/src/panes/grid.rspub fn advance_by_bytes(\u0026mut self, bytes: Vec\u003cu8\u003e) {    for byte in bytes {        self.vte_parser.advance(\u0026mut *self, byte);    }}ここでvte_parserはvte::Parser型だ。Gridはvte::Performトレイトを実装しており、パース結果に応じてprint()、execute()、csi_dispatch()などが呼ばれる。6. レンダリングとクライアントへの送信ScreenInstruction::Render =\u003e {    screen.render()?;    // 各クライアントに差分を送信    for client_id in screen.connected_clients.keys() {        let output = screen.render_for_client(*client_id)?;        send_to_client(*client_id, ServerToClientMsg::Render(output))?;    }}使用しているシステムコール一覧Zellijが使用する主なシステムコールをまとめる。 システムコール  用途  使用箇所  openpty()  PTYペアの作成  os_input_output.rs  fork()  子プロセスの作成  Command::spawn()  setsid()  新セッションの作成  login_tty() 内部  dup2()  FDの複製  login_tty() 内部  exec()  プログラムの実行  Command::spawn()  read()  PTYからの読み取り  terminal_bytes.rs  write()  PTYへの書き込み  pty_writer.rs  ioctl(TIOCGWINSZ)  ウィンドウサイズ取得  os_input_output.rs  ioctl(TIOCSWINSZ)  ウィンドウサイズ設定  os_input_output.rs  tcgetattr()  termios取得  os_input_output.rs  tcsetattr()  termios設定  os_input_output.rs  tcdrain()  出力完了待機  pty_writer.rs  kill()  シグナル送信  os_input_output.rs  waitpid()  子プロセス待機  os_input_output.rs  close()  FDのクローズ  各所 エラーハンドリングの実装PTY関連のエラーは、致命的なものと非致命的なものに分類される。// 非致命的: ログを出すが処理を継続os_input    .write_to_tty_stdin(terminal_id, \u0026bytes)    .with_context(err_context)    .non_fatal();// 致命的: パニックまたは終了os_input    .spawn_terminal(cmd, quit_cb)    .with_context(err_context)    .fatal();non_fatal()は書き込みエラー、リサイズエラーなどに使われる。ペインが閉じられた後に書き込みが来ることがあり、これは正常な動作だ。fatal()はPTY作成失敗、サーバー初期化失敗などに使われる。これらは回復不能なエラーだ。コマンドが見つからない場合の処理も興味深い。fn command_exists(cmd: \u0026RunCommand) -\u003e bool {    // cwdからの相対パスをチェック    if let Some(cwd) = cmd.cwd.as_ref() {        let full_command = cwd.join(\u0026cmd.command);        if full_command.exists() \u0026\u0026 full_command.is_file() {            return true;        }    }    // PATHを検索    if let Some(paths) = env::var_os(\"PATH\") {        for path in env::split_paths(\u0026paths) {            let full_command = path.join(\u0026cmd.command);            if full_command.exists() \u0026\u0026 full_command.is_file() {                return true;            }        }    }    false}コマンドが存在しない場合、ZellijError::CommandNotFoundが返される。hold_on_closeが設定されていれば、エラーメッセージを表示したペインが残る。設定されていなければ、ペインは静かに閉じられる。KDL形式によるセッション永続化Zellijは1秒ごとにセッション状態を自動シリアライズする。保存先は~/.cache/zellij/\u003cVERSION\u003e/session_info/\u003cSESSION_NAME\u003e/だ。zellij-utils/src/session_serialization.rsを開く。// zellij-utils/src/session_serialization.rspub fn serialize_session_layout(    global_layout_manifest: GlobalLayoutManifest,) -\u003e Result\u003c(String, BTreeMap\u003cString, String\u003e), \u0026'static str\u003e {    let mut document = KdlDocument::new();    let mut layout_node = KdlNode::new(\"layout\");    // タブ、ペインの構造をKDLノードとして構築}生成されるKDL。layout {    cwd \"/home/user/project\"    tab name=\"Editor\" {        pane command=\"vim\" {            args \"src/main.rs\"            cwd \"/home/user/project\"        }    }    tab name=\"Shell\" {        pane    }}シリアライズ形式がそのまま有効なKDLレイアウトファイルになっている。これは特筆すべき設計だ。なぜJSONやバイナリ形式ではないのか。JSONはパース速度が速いが、人間が編集するには冗長だ。KDLは「人間が読める設定ファイル」として設計された言語であり、Zellijのレイアウト設定にも使われている。つまり設定ファイルとシリアライズ形式を統一することで、自動保存されたセッションをそのままレイアウトテンプレートとして再利用できる。tmuxの.tmux.confとセッション復元は別系統だ。設定ファイルでは「こうあるべき」を書き、セッション復元では「こうだった」を読む。Zellijはこの2つを統一している。シンプルだが、これを思いつくのは難しい。thiserror + anyhow の併用前編でFatalErrorトレイトを紹介した。後編では、エラー型の定義側を見る。// thiserrorによる型定義#[derive(Debug, Error)]pub enum ZellijError {    #[error(\"could not find command '{command}' for terminal {terminal_id}\")]    CommandNotFound { terminal_id: u32, command: String },    #[error(\"Client {client_id} is too slow to handle incoming messages\")]    ClientTooSlow { client_id: u16 },    #[error(\"an error occured\")]    GenericError { source: anyhow::Error },}thiserror（ライブラリ向けエラー型定義）とanyhow（アプリケーション向けエラー伝播）の併用だ。GenericErrorのフィールドがanyhow::Errorになっている点に注目してほしい。これにより、詳細なエラー型を定義したいケースと、「とりあえずエラーを伝播したい」ケースを両立できる。その他の興味深い実装パターンここまでで主要なパターンを見てきたが、ソースコードを読み進める中で発見した「細かいが面白い」実装を紹介する。スクロールバックの「Canonical Rows」アーキテクチャターミナルの行は、表示上は複数行でも論理的には1行であることがある。長いコマンドが折り返されるケースだ。Zellijはこれを「Canonical Row」という概念で管理している。zellij-server/src/panes/grid.rsを開く。pub struct Row {    pub columns: VecDeque\u003cTerminalCharacter\u003e,    pub is_canonical: bool,  // 本当の改行か、折り返しか    width: Option\u003cusize\u003e,    // キャッシュされた幅}is_canonicalフラグが鍵だ。trueなら本当の改行（ユーザーがEnterを押した）、falseなら表示上の折り返し。スクロール時、折り返された行は元の「親」行と一緒に移動する必要がある。from_rowsメソッドで複数行をマージし、split_to_rows_of_lengthで再分割する。pub fn split_to_rows_of_length(\u0026mut self, max_row_length: usize) -\u003e Vec\u003cRow\u003e {    let mut parts: Vec\u003cRow\u003e = vec![];    let mut current_part: VecDeque\u003cTerminalCharacter\u003e = VecDeque::new();    let mut current_part_len = 0;    for character in self.columns.drain(..) {        if current_part_len + character.width() \u003e max_row_length {            parts.push(Row::from_columns(current_part));            current_part = VecDeque::new();            current_part_len = 0;        }        current_part_len += character.width();        current_part.push_back(character);    }    // canonical statusを保持    parts}文字の幅を考慮している点に注目。絵文字（幅2）の途中で行を切ると表示が崩れる。character.width()でUnicode幅を取得し、正しい位置で分割している。スクロールバックは3つのバッファで管理される。pub(crate) lines_above: VecDeque\u003cRow\u003e,    // スクロールバック（上）pub(crate) viewport: Vec\u003cRow\u003e,             // 表示中pub(crate) lines_below: Vec\u003cRow\u003e,          // 未表示（下）lines_aboveには上限がある。無限にスクロールバックを溜めるとメモリを食い尽くす。fn bounded_push(vec: \u0026mut VecDeque\u003cRow\u003e, sixel_grid: \u0026mut SixelGrid, value: Row) -\u003e Option\u003cusize\u003e {    if vec.len() \u003e= *SCROLL_BUFFER_SIZE.get().unwrap() {        let line = vec.pop_front();        if let Some(line) = line {            sixel_grid.offset_grid_top();  // Sixel画像の位置も更新        }    }    vec.push_back(value);}古い行を削除するとき、Sixel画像の位置も調整している。画像は行番号で位置を管理しているため、行が消えると座標がずれる。この連携が面白い。幅を考慮したカーソル位置計算絵文字やCJK文字は幅2を持つ。カーソルがその「途中」にあるケースをどう扱うか。pub fn absolute_character_index_and_position_in_char(\u0026self, x: usize) -\u003e (usize, usize) {    // xの幅を考慮したインデックスと、ワイド文字内の位置を返す    let mut accumulated_width = 0;    let mut absolute_index = x;    let mut position_inside_character = 0;    for (i, terminal_character) in self.columns.iter().enumerate() {        accumulated_width += terminal_character.width();        absolute_index = i;        if accumulated_width \u003e x {            let character_start_position = accumulated_width - terminal_character.width();            position_inside_character = x - character_start_position;            break;        }    }    (absolute_index, position_inside_character)}2つの値を返すのがポイント。「何番目の文字か」と「その文字内のどの位置か」。カーソルが絵文字の右半分にあるとき、position_inside_characterは1になる。これにより、カーソル移動やテキスト選択が正しく動作する。OnceCellによるグローバル非同期ランタイム複数スレッドから同じTokioランタイムを使いたい。Mutexで包むと毎回ロックが必要になる。zellij-server/src/global_async_runtime.rsを開く。use once_cell::sync::OnceCell;use tokio::runtime::Runtime;static TOKIO_RUNTIME: OnceCell\u003cRuntime\u003e = OnceCell::new();pub fn get_tokio_runtime() -\u003e \u0026'static Runtime {    TOKIO_RUNTIME.get_or_init(|| {        tokio::runtime::Builder::new_multi_thread()            .worker_threads(4)            .thread_name(\"async-runtime\")            .enable_all()            .build()            .expect(\"Failed to create tokio runtime\")    })}OnceCellは初期化後はロック不要だ。最初の呼び出しでランタイムを作成し、以降は\u0026'static Runtimeを返す。lazy_static!より明示的で、Arc\u003cMutex\u003c\u003e\u003eより効率的。4ワーカースレッドという設定も興味深い。Zellijは6つの主要スレッドを持つが、非同期タスク用には4スレッドで十分と判断したのだろう。フローティングペインのZ-index管理フローティングペインは重なり合う。どのペインが「上」にあるかを管理する必要がある。zellij-server/src/panes/floating_panes/mod.rsを開く。pub struct FloatingPanes {    panes: BTreeMap\u003cPaneId, Box\u003cdyn Pane\u003e\u003e,    z_indices: Vec\u003cPaneId\u003e,  // レンダリング順序    pane_being_moved_with_mouse: Option\u003c(PaneId, Position)\u003e,    // 多くのRc\u003cRefCell\u003c\u003e\u003eフィールド}pub fn stack(\u0026self) -\u003e Option\u003cFloatingPanesStack\u003e {    if self.panes_are_visible() {        let layers: Vec\u003cPaneGeom\u003e = self            .z_indices            .iter()            .filter_map(|pane_id| self.panes.get(pane_id).map(|p| p.position_and_size()))            .collect();        // レンダリング順でレイヤーを返す    }}z_indicesはVecだ。最後の要素が最前面。ペインをクリックすると、そのIDが末尾に移動する。pub fn move_pane_to_front(\u0026mut self, pane_id: \u0026PaneId) {    if let Some(index) = self.z_indices.iter().position(|id| id == pane_id) {        self.z_indices.remove(index);        self.z_indices.push(*pane_id);    }}マウスイベントは逆順で処理される。最前面のペインから順にヒットテストし、最初にマッチしたペインがイベントを受け取る。これにより、重なったペインの下にあるペインはクリックを受け取らない。Rc\u003cRefCell\u003c\u003e\u003eの多用も特徴的だ。display_areaやviewportは複数のペインで共有される。Rustの所有権モデルでは、これを表現するのにRc\u003cRefCell\u003c\u003e\u003eが必要になる。プラグインホットリロードのデバウンスプラグインファイルが変更されたら自動で再読み込みしたい。しかし、ファイル保存時には複数のイベントが発火することがある。zellij-server/src/plugins/watch_filesystem.rsを開く。pub fn watch_filesystem(    senders: ThreadSenders,    zellij_cwd: \u0026Path,) -\u003e Result\u003cDebouncer\u003cRecommendedWatcher, FileIdMap\u003e\u003e {    let mut debouncer = new_debouncer(        Duration::from_millis(DEBOUNCE_DURATION_MS),  // 400ms        None,        move |result: DebounceEventResult| match result {            Ok(events) =\u003e {                let mut create_events = vec![];                let mut read_events = vec![];                let mut update_events = vec![];                let mut delete_events = vec![];                // イベントを分類してプラグイン更新命令を送信            }        }    )}400msのデバウンス。この値はDoherty Thresholdと同じだ。ファイルを保存すると、OSによっては「作成→書き込み→クローズ」と複数イベントが発火する。400ms待つことで、これらを1つのイベントにまとめる。イベントは4種類に分類される。create、read、update、delete。プラグインの更新にはこの区別が重要だ。新規作成と更新では、ロードの方法が異なる可能性がある。アクション完了の追跡とタイムアウト長時間実行されるアクションの完了をどう待つか。zellij-server/src/route.rsを開く。pub fn wait_for_action_completion(    receiver: oneshot::Receiver\u003cActionCompletionResult\u003e,    action_name: \u0026str,    wait_forever: bool,) -\u003e ActionCompletionResult {    let runtime = get_tokio_runtime();    if wait_forever {        runtime.block_on(async {            match receiver.await { /* ... */ }        })    } else {        match runtime.block_on(async {            tokio::time::timeout(ACTION_COMPLETION_TIMEOUT, receiver).await        }) {            Ok(Ok(result)) =\u003e result,            Err(_) | Ok(Err(_)) =\u003e {                log::error!(\"Action {} did not complete within timeout\", action_name);                ActionCompletionResult { exit_status: None, affected_pane_id: None }            }        }    }}oneshot + tokio::time::timeoutの組み合わせが優雅だ。oneshot::channelは一度だけ値を送信できるチャネル。アクション完了時に結果を送り、待機側はtimeoutでラップして無限待機を避ける。スレッドをスピンさせたり、タイマーを別途管理したりする必要がない。Tokioのエコシステムをうまく活用している。おわりに冒頭で、何も起きていないターミナルを眺めていた話をした。cat huge_log_file.logで200万行を流し込んでも、Zellijは固まらない。境界付きチャネルのバッファが満杯になれば、送信側が自動的にブロックされる。シンプルだが効果的だ。その仕組みを、後編では中から見てきた。この記事を書きながら気づいたことがある。持ち帰れるパターンは、少なくない。crossbeamの境界付きチャネル: 無制限のチャネルはメモリを食い尽くす可能性がある。バッファサイズを明示的に制限することで、自然なバックプレッシャーが機能する読み取り/書き込みスレッドの分離: PTYやソケットを扱うとき、同じスレッドで読み書きするとデッドロックの危険がある。Zellijのようにスレッドを分けると安全だcompile-time assertionによるメモリサイズ保証: const _: [(); 16] = [(); std::mem::size_of::\u003cT\u003e()];で、将来の変更でサイズが増えることを防げるシグナル送信のリトライ戦略: SIGTERM 3回 → SIGKILLというパターンは、プロセス管理の定石として覚えておきたいKDL形式のセッション永続化: シリアライズ形式と設定形式を統一するアイデアは、CLIツールやエディタの開発に応用できるOnceCellによるグローバルリソース管理: 複数スレッドから共有リソースにアクセスするとき、OnceCellなら初期化後のロックが不要だoneshot + timeoutによる非同期待機: 長時間実行されるアクションの完了を待つとき、タイムアウト付きで待機するパターンは汎用的に使えるCanonical Rowsによる論理行管理: テキストエディタやターミナルを作るなら、「表示上の行」と「論理的な行」を区別する必要があるただ、正直に言うと、これらのパターンを自分のプロジェクトに導入できるかどうかは分からない。境界付きチャネルのバッファサイズ50は、Zellijの6スレッド構成に最適化された値だ。自分のプロジェクトでは違う値が正解かもしれない。たぶん、違う。「パターンを知っている」と「パターンを使いこなせる」の間には溝がある。その溝がどれくらい深いのか、ソースコードを読んだだけでは分からない。書いてみるしかない。書いて、つまずいて、またソースコードに戻る。そういうことの繰り返しなのだと思う。ただ、Zellijのソースコードを2本の記事にわたって読んできて、1つ確信したことがある。Rustでマルチスレッドアプリケーションを書くとき、最も重要なのは「どのスレッドが何を所有するか」の設計だ。Zellijの6スレッド構成は、この所有権の設計が明確だから成立している。読み取りスレッドはPTYのReadを所有し、書き込みスレッドはWriteを所有する。この分離がデッドロックを防ぎ、境界付きチャネルがバックプレッシャーを実現し、差分レンダリングが性能を出す。パターンの根底にあるのは、結局のところ所有権モデルだ。冒頭で眺めていた3つのペインを、今もう一度見る。左のVim、右上のテスト、右下のシェル。見え方が少し変わっている。PTYが3つ、境界付きチャネルがバッファサイズ50で繋がり、VTEパーサが毎秒数千バイトを解釈している。何も起きていないように見えるターミナルが、少しだけ騒がしく感じる。Zellijのソースコードを読みたいなら、以下のファイルが特に参考になる。PTY関連:zellij-server/src/os_input_output.rs - PTY作成、シグナル、リサイズ（1035行）zellij-server/src/pty.rs - PTYマネージャースレッド（2100行以上）zellij-server/src/terminal_bytes.rs - 非同期読み取り（110行）zellij-server/src/pty_writer.rs - 書き込みスレッド（89行）レンダリング関連:zellij-server/src/panes/terminal_character.rs - メモリ効率化とcompile-time assertionzellij-server/src/panes/grid.rs - VTEパーサ、マウスイベント（4000行以上）zellij-server/src/output/mod.rs - 差分レンダリング非同期・スレッド関連:zellij-server/src/global_async_runtime.rs - OnceCellによるTokioランタイム共有（17行）zellij-server/src/route.rs - アクション完了追跡とタイムアウトzellij-utils/src/channels.rs - エラーコンテキスト付きチャネルペイン管理:zellij-server/src/panes/floating_panes/mod.rs - フローティングペインとZ-indexzellij-server/src/panes/tiled_panes/pane_resizer.rs - Cassowary制約ソルバーその他:zellij-utils/src/session_serialization.rs - KDL形式のセッション永続化zellij-server/src/plugins/watch_filesystem.rs - プラグインホットリロードzellij-server/src/panes/search.rs - 折り返し行を跨ぐ検索git clone https://github.com/zellij-org/zellij.git# 境界付きチャネルの実装cat zellij-utils/src/channels.rs# バッファサイズ50の使用箇所grep -r \"bounded(50)\" zellij-*/src/tmuxの安定性に満足しているなら、無理にZellijに乗り換える必要はない。しかし、Rustでマルチスレッドアプリケーションを書くなら、Zellijのソースコードは一読の価値がある。30年の歴史を持つtmuxとは異なるアプローチで、同等以上のパフォーマンスを達成しようとする試み——その設計判断から学べることは多い。参考リンクZellij本体github.comzellij.devWASMランタイム移行（PR #4449）github.com使用しているクレートgithub.comgithub.comgithub.comgithub.comKDL（設定ファイル形式）kdl.dev参考記事zellij.devzellij.devhttps://zellij.dev/news/new-plugin-api/zellij.devhttps://zellij.dev/news/sixel-images-in-the-terminal/zellij.devパフォーマンス最適化poor.dev境界付きチャネル導入の背景github.comDoherty Thresholdlawsofux.com関連技術protobuf.devdocs.rsdocs.rs関連プロジェクトgithub.comgithub.com","isoDate":"2026-01-29T00:20:03.000Z","dateMiliSeconds":1769646003000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ZellijのRust実装パターン徹底解説（前編）","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/28/181750","contentSnippet":"はじめにターミナルで cat huge_log_file.log を実行した。画面が滝のように流れ始めた。Ctrl+Cを連打した。反応しない。画面はまだ流れている。椅子の背もたれに体を預けて、流れが止まるのを待った。Ciscoルーターの話もしたいが、それを始めるとどこまでも終わらなくなるので、ここでは話をしない。こういう場面に出くわすことがある。自分が打ったコマンドなのに、自分では止められない。出力が止まったあと、何事もなかったかのように次のコマンドを打つ。たぶん、みんなそうしている。自分もそうしてきた。そうしてきたのだが、ある日ふと気になった。この暴走を、ソフトウェアはどうやって止めているのだろう。Zellijは、ターミナルマルチプレクサだ。1つのターミナル画面を複数に分割し、複数のシェルを同時に操作できる。tmuxやscreenの現代版として、2021年にRustで開発が始まった。github.com本記事は2部構成の前編にあたる。前編では設計パターンを抽出し、後編ではさらに深く実装の内部に入る。読んで「なるほど」と思って、そのまま忘れる。たぶんそうなる。それでいい。合わなければ途中で離脱してもらって構わない。約10万行のコードベースから、設計が優れている箇所——と、正直「これでいいのか？」と思う箇所——を抜き出して紹介する。他人のコードを読んで「分かった」と言い切れる自信はない。分からないまま書いている部分もある。それでも、書くことにした。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。なぜZellijのコードを読むのかターミナルマルチプレクサのコードを読む機会はそう多くない。しかし、Zellijには以下の理由で読む価値がある。実践的な並行処理: 複数のスレッドが協調して動く仕組みが、教科書的ではなく「本当に動くコード」として見られるWASMプラグインシステム: ブラウザ以外でWebAssemblyを使う実例として参考になるエラー処理の設計: 「このエラーは無視していい」「このエラーは致命的」を型で表現するパターンが秀逸コードを読み始める前に、Zellijが前提としている概念をいくつか整理しておく。知っている人は読み飛ばしてもらっていい。前提知識Zellijのコードを読み進める前に、いくつかの概念を押さえておくと理解が早い。正直に言えば、自分もこれらを「完全に理解している」とは言い難い。使ったことはある。使ったことはあるが、説明しろと言われると手が止まる。そういう概念を、改めて整理しておく。擬似端末（PTY）ターミナルマルチプレクサの根幹技術だ。PTY（Pseudo Terminal）は、物理的なターミナル装置をソフトウェアでエミュレートする仕組み。マスター側とスレーブ側のペアで構成され、マスター側がZellijのようなプログラム、スレーブ側がシェル（bashやzsh）になる。シェルは自分が本物のターミナルに接続されていると思い込んでいるが、実際にはZellijが間に入ってデータを仲介している。MPSCチャネルRustの標準ライブラリにあるstd::sync::mpscは「Multiple Producer, Single Consumer」の略だ。複数の送信者から1つの受信者にメッセージを送れる。Zellijでは各スレッドがこのチャネルでメッセージをやり取りしている。crossbeam-channelというクレートを使うとMPMC（Multiple Producer, Multiple Consumer）も実現できるが、Zellijは基本的にMPSCで設計されている。Actorモデル各スレッドを独立した「アクター」として扱い、共有メモリではなくメッセージパッシングで通信するパターン。ZellijのScreenThreadやPtyThreadはそれぞれがアクターとして振る舞い、enumで定義された命令（ScreenInstructionなど）を受け取って処理する。ロックの競合を避けやすく、デバッグもしやすい。WebAssembly（WASM）ブラウザで動くバイナリフォーマットとして生まれたが、サーバーサイドやCLIツールでも使われるようになった。Zellijはプラグインの実行環境としてWASMを採用している。プラグインがクラッシュしても本体には影響しない、言語に依存しない、といった利点がある。Zellijは当初wasmtimeをランタイムとして使用していたが、現在はwasmiに移行している。詳細は後述する。では、コードを見ていこう。ここから先は長い。覚悟してほしい——と言いたいところだが、自分も書きながら覚悟している。Cargo Workspace構成：最初に見るべきファイルソースコードを読むとき、私はまずCargo.tomlを開く。プロジェクトの全体像が分かるからだ。Zellijのルートディレクトリでlsすると、以下の構造が見える。zellij/├── zellij/           # エントリーポイント├── zellij-client/    # クライアント側├── zellij-server/    # サーバー側├── zellij-utils/     # 共有ユーティリティ├── zellij-tile/      # プラグインSDK├── default-plugins/  # 標準プラグイン└── xtask/            # ビルドタスクZellijはクライアント・サーバー型のアーキテクチャを採用している。ターミナルの画面を表示する「クライアント」と、実際にシェルを動かす「サーバー」が別プロセスで動いている。なぜわざわざ分離するのか？答えは「セッションの永続化」にある。SSH接続が切れても、サーバー側でシェルは動き続ける。後で再接続すれば、作業を途中から再開できる。リモートワークで長時間かかるビルドを実行中にネットワークが切れても、ビルドは止まらない。これがターミナルマルチプレクサの最大の利点だ。セッションの永続化がどのように実装されているかは、後半の「セッション永続化：KDLによるシリアライズ」で詳しく見る。ワークスペース構成を把握したところで、次はビルドの仕組みを見てみよう。xtask：Rustで書くビルドスクリプトxtask/ディレクトリは、MakefileやシェルスクリプトをRustで置き換える「xtaskパターン」の実装だ。github.com// xtask/src/main.rsfn main() -\u003e anyhow::Result\u003c()\u003e {    let shell = \u0026Shell::new()?;    let flags = flags::Xtask::from_env()?;    match flags.subcommand {        flags::XtaskCmd::Build(flags) =\u003e build::build(shell, flags),        flags::XtaskCmd::Clippy(flags) =\u003e clippy::clippy(shell, flags),        flags::XtaskCmd::Format(flags) =\u003e format::format(shell, flags),        flags::XtaskCmd::Test(flags) =\u003e test::test(shell, flags),        flags::XtaskCmd::Dist(flags) =\u003e pipelines::dist(shell, flags),        flags::XtaskCmd::Install(flags) =\u003e pipelines::install(shell, flags),        // ...    }}.cargo/config.tomlにエイリアスを設定すると、cargo xtask buildのように呼び出せる。[alias]xtask = \"run --package xtask --\"xtaskパターンの利点は3つある。クロスプラットフォーム: シェルスクリプトはOS依存だが、Rustはどこでも動く型安全: xflagsクレートでCLI引数をパースし、typoをコンパイル時に検出言語統一: ビルドスクリプトもRustで書けば、チーム全員が読めるpipelines.rsでは、複数のビルドステージを.and_then()でチェーンしている。// xtask/src/pipelines.rspub fn make(sh: \u0026Shell, flags: flags::Make) -\u003e anyhow::Result\u003c()\u003e {    format::format(sh, flags::Format { check: false })        .and_then(|_| build::build(sh, build_flags))        .and_then(|_| test::test(sh, test_flags))        .and_then(|_| clippy::clippy(sh, flags::Clippy {}))        .with_context(err_context)}どこかでエラーが発生すれば、以降のステージはスキップされる。RustのResult型を活かしたパイプライン設計だ。スレッド設計：thread_bus.rsを読むzellij-server/src/thread_bus.rsを開くと、スレッド間通信の設計が見える。// zellij-server/src/thread_bus.rs#[derive(Default, Clone)]pub struct ThreadSenders {    pub to_screen: Option\u003cSenderWithContext\u003cScreenInstruction\u003e\u003e,    pub to_pty: Option\u003cSenderWithContext\u003cPtyInstruction\u003e\u003e,    pub to_plugin: Option\u003cSenderWithContext\u003cPluginInstruction\u003e\u003e,    pub to_server: Option\u003cSenderWithContext\u003cServerInstruction\u003e\u003e,    pub to_pty_writer: Option\u003cSenderWithContext\u003cPtyWriteInstruction\u003e\u003e,    pub to_background_jobs: Option\u003cSenderWithContext\u003cBackgroundJob\u003e\u003e,    pub should_silently_fail: bool,  // テスト用}6つのスレッドへの送信チャネルを1つの構造体にまとめている。各スレッドが他のスレッドにメッセージを送りたいとき、このThreadSendersを経由する。┌────────────────────────────────────────────────────────────────────┐│                           ZELLIJ SERVER                            ││  ┌───────────────┐ ┌──────────┐ ┌──────────────┐ ┌──────────────┐  ││  │ SCREEN        │ │ PTY      │ │ PLUGIN       │ │ PTY_WRITER   │  ││  │ THREAD        │ │ THREAD   │ │ THREAD       │ │ THREAD       │  ││  │               │ │          │ │              │ │              │  ││  │ タブ/ペイン   │ │ 擬似端末 │ │ WASM         │ │ 書き込み専用 │  ││  │ 管理          │ │ 生成管理 │ │ ランタイム   │ │              │  ││  └───────────────┘ └──────────┘ └──────────────┘ └──────────────┘  ││  ┌───────────────────┐ ┌──────────────────────────────────────┐    ││  │ BACKGROUND_JOBS   │ │            SERVER (IPC)              │    ││  │ THREAD            │ │            THREAD                    │    ││  └───────────────────┘ └──────────────────────────────────────┘    │└────────────────────────────────────────────────────────────────────┘Bus構造体も見ておこう。pub(crate) struct Bus\u003cT\u003e {    receivers: Vec\u003cchannels::Receiver\u003c(T, ErrorContext)\u003e\u003e,    pub senders: ThreadSenders,    pub os_input: Option\u003cBox\u003cdyn ServerOsApi\u003e\u003e,}receiversがVecになっている。なぜ1つの受信口ではなく、複数の受信口を持つ必要があるのか？lib.rsを開いて、チャネルを作っている箇所を探すと、理由が分かる。// zellij-server/src/lib.rslet (to_screen, screen_receiver): ChannelWithContext\u003cScreenInstruction\u003e =    channels::unbounded();  // 通常のメッセージ用（無制限）let (to_screen_bounded, bounded_screen_receiver): ChannelWithContext\u003cScreenInstruction\u003e =    channels::bounded(50);  // PTYからの高速入力用（上限50個）このbounded(50)は2022年6月のPR #1265で導入された。github.comScreenスレッドには2つのチャネルがある。通常の無制限チャネルと、上限50個の境界付きチャネル。これは「バックプレッシャー」を実現するための設計だ。冒頭のcat huge_log_file.logを思い出してほしい。PTYからの出力が速すぎると、画面描画が追いつかない。上限付きチャネルを使うと、バッファが満杯になったときに送信側がブロックされる。一方、ユーザー操作（ペインの移動、タブの切り替え）は無制限チャネル経由で送られ、即座に処理される。ユーザーがキーを押したのに反応しない、という事態は避けたいからだ。前提知識で触れたMPSCチャネルとActorモデルが、ここで活きている。各スレッドは自分専用のチャネルからメッセージを受け取り、状態を外部と共有しない。共有しなければ、奪い合いは起きない。この設計により、Arc\u003cMutex\u003cT\u003e\u003eのような共有ロックを使わずにスレッド間通信を実現している。デッドロックの心配がない。SenderWithContext：エラー追跡付きチャネルzellij-utils/src/channels.rsには、crossbeamチャネルのラッパーがある。github.com// zellij-utils/src/channels.rspub type ChannelWithContext\u003cT\u003e = (Sender\u003c(T, ErrorContext)\u003e, Receiver\u003c(T, ErrorContext)\u003e);#[derive(Clone)]pub struct SenderWithContext\u003cT\u003e {    sender: Sender\u003c(T, ErrorContext)\u003e,}impl\u003cT: Clone\u003e SenderWithContext\u003cT\u003e {    pub fn send(\u0026self, event: T) -\u003e Result\u003c(), SendError\u003c(T, ErrorContext)\u003e\u003e {        let err_ctx = get_current_ctx();        self.sender.send((event, err_ctx))    }}メッセージを送るたびに、現在のエラーコンテキストが自動的に付与される。get_current_ctx()は、thread-localストレージから現在の呼び出し履歴を取得する。これにより、エラーが発生したとき「どのスレッドの、どの処理から送られたメッセージか」を追跡できる。// zellij-utils/src/errors.rsthread_local!(    pub static OPENCALLS: RefCell\u003cErrorContext\u003e = RefCell::default());// 非同期タスク用にはtask_localも用意task_local! {    pub static ASYNCOPENCALLS: RefCell\u003cErrorContext\u003e = RefCell::default()}スレッドごとに独立した呼び出し履歴を持ち、最大6階層まで記録する。const MAX_THREAD_CALL_STACK: usize = 6;#[derive(Clone, Copy)]pub struct ErrorContext {    calls: [ContextType; MAX_THREAD_CALL_STACK],}エラーが起きると「Screen → HandlePtyBytes → Render」のような呼び出し履歴が出力される。マルチスレッドのデバッグでは、この情報がないと原因特定に時間がかかる。100以上のバリアント：Instruction enumscreen.rsを開くと、巨大なenumが見つかる。// zellij-server/src/screen.rspub enum ScreenInstruction {    PtyBytes(u32, VteBytes),    PluginBytes(Vec\u003cPluginRenderAsset\u003e),    Render,    NewPane(PaneId, Option\u003cInitialTitle\u003e, HoldForCommand, ...),    WriteCharacter(Option\u003cKeyWithModifier\u003e, Vec\u003cu8\u003e, bool, ClientId, ...),    MoveFocusLeft(ClientId, Option\u003cNotificationEnd\u003e),    MoveFocusRight(ClientId, Option\u003cNotificationEnd\u003e),    ScrollUp(ClientId, Option\u003cNotificationEnd\u003e),    // ... 約100個のバリアント}100個以上のバリアント。正直、最初に見たときは「これ、本当に正しいのか？」と思った。git履歴を追うと、初期のScreenInstructionは11バリアントしかなかった。Pty、Render、HorizontalSplit、VerticalSplit、WriteCharacterなど基本的なものだけだ。5年間で148バリアント以上に成長している。25倍。機能追加のたびにバリアントが増えていった結果だ。利点はある。型安全性: 処理し忘れたバリアントがあれば、コンパイルエラーで検出できるドキュメント性: このenumを見れば、Screenスレッドが受け付ける全メッセージが一目で分かる文字列でメッセージを送る設計（例：\"move_focus_left\"）と比べると、タイポをコンパイル時に検出できる点で優れている。ただ、疑問も残る。100個のバリアントを持つenumに新しいメッセージを追加するとき、Fromトレイトの実装も更新しなければならない。忘れたらコンパイルエラーになるとはいえ、変更箇所が分散するのは保守コストだ。trait objectやdynamic dispatchで抽象化する選択肢もあったはずだが、Zellijはそれを選ばなかった。パフォーマンスを優先したのか、あるいは「enumで十分」という判断なのか。答えは分からない。各Instruction enumには、FromトレイトでContextTypeへの変換が実装されている。impl From\u003c\u0026ScreenInstruction\u003e for ScreenContext {    fn from(server_instruction: \u0026ScreenInstruction) -\u003e Self {        match *server_instruction {            ScreenInstruction::PtyBytes(..) =\u003e ScreenContext::HandlePtyBytes,            ScreenInstruction::Render =\u003e ScreenContext::Render,            ScreenInstruction::NewPane(..) =\u003e ScreenContext::NewPane,            // ... 全バリアントを網羅        }    }}これにより、エラーコンテキストへの変換が自動化される。WASMプラグイン：wasmiの採用zellij-server/src/plugins/plugin_loader.rsを開くと、WASMランタイムのimportが見える。// zellij-server/src/plugins/plugin_loader.rsuse wasmi::{Engine, Instance, Linker, Module, Store, StoreLimits};use wasmi_wasi::sync::WasiCtxBuilder;use wasmi_wasi::WasiCtx;wasmiを使っている。Wasmtimeではない。github.com両者の違いを整理する。 項目  Wasmtime  wasmi  実行方式  JITコンパイル  インタプリタ  速度  高速  低速  攻撃面  広い（JITは複雑）  狭い  依存  LLVM  ピュアRust 実は、Zellijは当初Wasmtimeを使っていた。2025年10月のPR #4449「Migrate from wasmtime to wasmi」でwasmiに移行している。この移行と同時にPinnedExecutor（動的スレッドプール）が導入された。JITコンパイルをやめることで、プラグインごとにスレッドをピン留めする設計が可能になった。インタプリタ方式は遅いが、リソース管理の予測可能性とセキュリティで優れる。github.comzellij-tile/src/lib.rsにはプラグインSDKがある。// zellij-tile/src/lib.rspub trait ZellijPlugin: Default {    fn load(\u0026mut self, configuration: BTreeMap\u003cString, String\u003e) {}    fn update(\u0026mut self, event: Event) -\u003e bool { false }  // trueで再描画    fn pipe(\u0026mut self, pipe_message: PipeMessage) -\u003e bool { false }    fn render(\u0026mut self, rows: usize, cols: usize) {}}プラグインは4つのメソッドを実装するだけでいい。register_plugin!マクロの中身を見ると、3つの工夫がある。#[macro_export]macro_rules! register_plugin {    ($t:ty) =\u003e {        thread_local! {            static STATE: std::cell::RefCell\u003c$t\u003e = RefCell::new(Default::default());        }        fn main() {            std::panic::set_hook(Box::new(|info| {                report_panic(info);            }));        }        #[no_mangle]        fn load() {            STATE.with(|state| {                let protobuf_bytes: Vec\u003cu8\u003e = $crate::shim::object_from_stdin().unwrap();                // ...            });        }    };}thread_local!: WASMは基本的に状態を持たない設計だが、これで状態を保持できる#[no_mangle]: 関数名をそのまま維持し、Zellijホストから呼び出せるようにするProtocol Buffers: WASM境界を越えるデータはシリアライズする必要があるgithub.comプラグインの権限管理も見ておこう。default-plugins/status-bar/src/main.rsを開く。fn load(\u0026mut self, _configuration: BTreeMap\u003cString, String\u003e) {    request_permission(\u0026[PermissionType::ReadApplicationState]);    subscribe(\u0026[        EventType::TabUpdate,        EventType::ModeUpdate,        EventType::CopyToClipboard,        EventType::SystemClipboardFailure,    ]);}request_permissionでプラグインが必要な権限を要求し、ユーザーが許可する。zellij-utils/src/data.rsには16種類の権限が定義されている。PermissionType::ReadApplicationState    // 状態の読み取りPermissionType::ChangeApplicationState  // 状態の変更PermissionType::RunCommands             // コマンド実行PermissionType::WebAccess               // ネットワークアクセスPermissionType::FullHdAccess            // ファイルシステムアクセス// ... 他11種類AndroidやiOSの権限モデルと同様に、細粒度の制御ができる。FatalError：エラーの重大度を型で表現zellij-utils/src/errors.rsには、エラーの重大度を呼び出し側で選択できるトレイトがある。pub trait FatalError\u003cT\u003e {    fn non_fatal(self);  // エラーをログに記録して続行    fn fatal(self) -\u003e T; // アンラップまたはパニック}impl\u003cT\u003e FatalError\u003cT\u003e for anyhow::Result\u003cT\u003e {    fn non_fatal(self) {        if self.is_err() {            discard_result(self.context(\"a non-fatal error occured\").to_log());        }    }    fn fatal(self) -\u003e T {        if let Ok(val) = self {            val        } else {            self.context(\"a fatal error occured\")                .expect(\"Program terminates\")        }    }}使用例を見ると、意図が明確になる。// スレッドのエントリーポイント：失敗したらプロセス終了move || pty_thread_main(pty, layout.clone()).fatal()// 内部のエラー処理：失敗してもログを出して続行self.senders.send_to_screen(instruction).non_fatal();unwrap()やexpect()では「なぜここでパニックしていいのか」が分からない。.fatal()なら意図が明確だ。コードレビューでも「このエラーは本当に致命的か？」という議論がしやすくなる。ここまで読んで、自分のプロジェクトのエラー処理が急に心配になった。unwrap()を何箇所書いただろう。数えたくない。数えたくないが、たぶん数えるべきだ。ここからは、Zellijの別の顔を見ていく。セッションの永続化、そしてターミナルの根幹であるPTY処理だ。セッション永続化：KDLによるシリアライズzellij-utils/src/session_serialization.rsには、セッション状態をKDL形式で保存する処理がある。// zellij-utils/src/session_serialization.rs#[derive(Default, Debug, Clone)]pub struct GlobalLayoutManifest {    pub global_cwd: Option\u003cPathBuf\u003e,    pub default_shell: Option\u003cPathBuf\u003e,    pub default_layout: Box\u003cLayout\u003e,    pub tabs: Vec\u003c(String, TabLayoutManifest)\u003e,}pub fn serialize_session_layout(    global_layout_manifest: GlobalLayoutManifest,) -\u003e Result\u003c(String, BTreeMap\u003cString, String\u003e), \u0026'static str\u003e {    let mut document = KdlDocument::new();    let mut pane_contents = BTreeMap::new();    // ...}KDL（KDL Document Language）は、人間が読みやすいように設計された設定言語だ。Zellijの設定ファイルにも使われている。kdl.devセッションの保存時に、レイアウト情報（KDL文字列）とペインの内容（BTreeMap）を分離して返すのは、関心の分離ができている。PTY処理：os_input_output.rsの低レベルコード前提知識で触れたPTY（擬似端末）が、実際にどう実装されているか。ターミナルマルチプレクサの核心部分を見る。冒頭の cat huge_log_file.log で画面が止まらなくなったあの現象——あれはPTYのmaster側から流れ込むバイト列を、Zellijがどう捌くかという問題だった。zellij-server/src/os_input_output.rsを開く。冒頭の cat huge_log_file.log で画面が暴走したとき、裏側ではここのコードが動いていた。あの滝が、ここで生まれている。github.comuse nix::pty::{openpty, OpenptyResult, Winsize};fn handle_openpty(    open_pty_res: OpenptyResult,    cmd: RunCommand,    quit_cb: Box\u003cdyn Fn(PaneId, Option\u003ci32\u003e, RunCommand) + Send\u003e,    terminal_id: u32,) -\u003e Result\u003c(RawFd, RawFd)\u003e {    let pid_primary = open_pty_res.master;    // ホスト側（Zellij）    let pid_secondary = open_pty_res.slave;   // 子プロセス側（シェル）    let mut child = unsafe {        Command::new(cmd.command)            .args(\u0026cmd.args)            .env(\"ZELLIJ_PANE_ID\", \u0026format!(\"{}\", terminal_id))            .pre_exec(move || -\u003e std::io::Result\u003c()\u003e {                if libc::login_tty(pid_secondary) != 0 {                    panic!(\"failed to set controlling terminal\");                }                close_fds::close_open_fds(3, \u0026[]);                Ok(())            })            .spawn()            .expect(\"failed to spawn\")    };    // ...}unsafeブロック、libc::login_tty、pre_exec。低レベルなUnixプログラミングだ。openptyは「master」と「slave」という2つのファイルディスクリプタを作る。Zellijはmaster側を持ち、シェル（bashやzsh）はslave側を持つ。シェルが出力した文字はmaster側で読み取れる。login_ttyは、Unix系OSでターミナルをセットアップする伝統的な関数だ。これにより、子プロセスはslave側のPTYを「自分の端末」として認識する。terminal_bytes.rs：非同期I/Oterminal_bytes.rsは、PTYからのバイト読み取りを担当する。// zellij-server/src/terminal_bytes.rspub(crate) struct TerminalBytes {    pid: RawFd,    terminal_id: u32,    senders: ThreadSenders,    async_reader: Box\u003cdyn AsyncReader\u003e,    debug: bool,}impl TerminalBytes {    pub async fn listen(\u0026mut self) -\u003e Result\u003c()\u003e {        let mut buf = [0u8; 65536];  // 64KBバッファ        loop {            match self.async_reader.read(\u0026mut buf).await {                Ok(0) =\u003e break,  // EOF（プロセス終了）                Err(err) =\u003e {                    log::error!(\"{}\", err);                    break;                },                Ok(n_bytes) =\u003e {                    let bytes = \u0026buf[..n_bytes];                    self.async_send_to_screen(ScreenInstruction::PtyBytes(                        self.terminal_id,                        bytes.to_vec(),                    )).await?;                },            }        }        Ok(())    }}64KBバッファ。一般的な8KBや4KBではなく、大きめのバッファを使っている。このバッファサイズは2022年7月のPR #1585「perf(terminal): better responsiveness」で導入された。コミットメッセージには「only buffer terminal bytes when screen thread is backed up」とある。画面スレッドが詰まっているときだけバッファリングし、通常時は即座に転送する。64KBという数値は、1回のシステムコールで読み取れる量と、メモリ消費のバランスから選ばれたと思われる。github.comOk(0)とErrの区別も重要。Ok(0)はファイル終端（プロセスが終了した）、Errは本当のエラー。この区別を間違えると、プロセス終了時にエラーログが出てしまう。64KBのバッファが、あの画面の暴走を受け止めている。自分が cat を打って椅子にもたれかかっていたあの数秒間、このコードが黙々とバイトを読んでいた。なんだか少し申し訳ない気持ちになる。grid.rs：ANSIエスケープシーケンスの処理PTYから読み取ったバイト列は、そのまま画面に表示できるわけではない。ターミナルに表示される色付きの文字や、カーソルの移動は「ANSIエスケープシーケンス」という特殊なバイト列で制御されている。\\x1b[31mが「赤色」、\\x1b[Hが「カーソルを左上に移動」といった具合だ。zellij-server/src/panes/grid.rsを開くと、vteクレート（Alacrittyチームが保守）を使っている。github.comuse vte::{Params, Perform};impl Perform for Grid {    fn print(\u0026mut self, c: char) {        // 通常文字の表示    }    fn execute(\u0026mut self, byte: u8) {        // 制御文字（\\n, \\r, \\t等）    }    fn csi_dispatch(\u0026mut self, params: \u0026Params, intermediates: \u0026[u8],                    ignore: bool, action: char) {        // CSIシーケンス: カーソル移動、色変更など    }    fn osc_dispatch(\u0026mut self, params: \u0026[\u0026[u8]], bell_terminated: bool) {        // OSCシーケンス: ウィンドウタイトル設定など    }}Performトレイトを実装するだけで、vteがパースした結果を受け取れる。ANSIエスケープシーケンスの仕様は複雑で、エッジケースも多い。自作するより、実績のあるクレートを使う方が合理的だ。差分レンダリング：output/mod.rs全画面を毎回再描画すると遅い。zellij-server/src/output/mod.rsを見ると、変更された行だけを追跡している。pub struct OutputBuffer {    pub changed_lines: HashSet\u003cusize\u003e,  // 変更された行インデックス    pub should_update_all_lines: bool,}impl OutputBuffer {    pub fn update_line(\u0026mut self, line_index: usize) {        if !self.should_update_all_lines {            self.changed_lines.insert(line_index);        }    }    pub fn update_all_lines(\u0026mut self) {        self.clear();        self.should_update_all_lines = true;    }}HashSetを使うことで、同じ行が複数回更新されても重複エントリが発生しない。should_update_all_linesフラグは、ウィンドウサイズが変わったときなど、全画面を再描画する必要があるケースに対応している。terminal_character.rs：メモリ効率の工夫zellij-server/src/panes/terminal_character.rsには、メモリ効率を意識したパターンがある。pub const EMPTY_TERMINAL_CHARACTER: TerminalCharacter = TerminalCharacter {    character: ' ',    width: 1,    styles: RcCharacterStyles::Reset,};thread_local! {    static RC_DEFAULT_STYLES: RcCharacterStyles =        RcCharacterStyles::Rc(Rc::new(DEFAULT_STYLES));}constでデフォルト値を定義し、thread_local!でスタイルオブジェクトをキャッシュしている。ターミナルの各セルにスタイル情報を持たせると、同じスタイルのオブジェクトが大量に生成される。参照カウントでキャッシュすることで、メモリ使用量を削減できる。data.rs：deriveの活用zellij-utils/src/data.rsには、様々なenumが定義されている。#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, Serialize, Deserialize, EnumIter)]pub enum InputMode {    Normal,    Locked,    Resize,    Pane,    Tab,    Scroll,    EnterSearch,    Search,    RenameTab,    RenamePane,    Session,    Move,    Prompt,    Tmux,}#[derive(...)]に9つのトレイトを並べている。特にEnumIter（strumクレート）が便利で、InputMode::iter()で全バリアントを列挙できる。UIの選択肢一覧を作るときに使える。github.comEvent enumには#[non_exhaustive]属性がついている。#[non_exhaustive]pub enum Event {    ModeUpdate(ModeInfo),    TabUpdate(Vec\u003cTabInfo\u003e),    Key(KeyWithModifier),    // ... 約30バリアント}これは「このenumにはまだバリアントが追加される可能性がある」という宣言だ。外部のプラグイン開発者は必ず_ =\u003e ()アームを書く必要がある。fn update(\u0026mut self, event: Event) -\u003e bool {    match event {        Event::Key(key) =\u003e { /* ... */ }        Event::ModeUpdate(mode_info) =\u003e { /* ... */ }        _ =\u003e ()  // non_exhaustiveのため必須    }}これにより、Zellijがバージョンアップで新しいイベントを追加しても、既存のプラグインがコンパイルエラーにならない。後方互換性を保つための工夫だ。キーバインディング：モード別マッピングと例外処理zellij-utils/src/input/keybinds.rsには、キーバインディングの管理ロジックがある。// zellij-utils/src/input/keybinds.rs#[derive(Clone, PartialEq, Deserialize, Serialize, Default)]pub struct Keybinds(pub HashMap\u003cInputMode, HashMap\u003cKeyWithModifier, Vec\u003cAction\u003e\u003e\u003e);モードごとにキーマップを持つ設計だ。InputMode（Normal, Locked, Resize等）をキーに、さらにキーとアクションのマップを値に持つ。注目すべきはhandle_ctrl_jという関数だ。fn handle_ctrl_j(    mode_keybindings: \u0026HashMap\u003cKeyWithModifier, Vec\u003cAction\u003e\u003e,    raw_bytes: \u0026[u8],    key_is_kitty_protocol: bool,) -\u003e Option\u003cVec\u003cAction\u003e\u003e {    let ctrl_j = KeyWithModifier::new(BareKey::Char('j')).with_ctrl_modifier();    if mode_keybindings.get(\u0026ctrl_j).is_some() {        mode_keybindings.get(\u0026ctrl_j).cloned()    } else {        Some(vec![Action::Write { /* ... */ }])    }}Ctrl-Jはbyte [10]を送信するが、これはEnterキーと同じバイト列だ。ターミナルの歴史的な事情により、この2つを区別する必要がある。Zellijは「Ctrl-Jにバインドがあればそれを実行、なければ生のバイトを送信」という戦略を取っている。こういうエッジケースは、ターミナルソフトウェアを書くときに避けて通れない。コードを読むまで気づかなかった。設定マージ：Option型の活用zellij-utils/src/input/options.rsには、設定値のマージロジックがある。// zellij-utils/src/input/options.rspub fn merge(\u0026self, other: Options) -\u003e Options {    let mouse_mode = other.mouse_mode.or(self.mouse_mode);    let pane_frames = other.pane_frames.or(self.pane_frames);    let default_mode = other.default_mode.or(self.default_mode);    let default_shell = other.default_shell.or_else(|| self.default_shell.clone());    // ... 約30フィールド}Option::orとOption::or_elseを使った設定マージだ。other（後から来た設定）に値があればそれを使い、なければself（既存の設定）を使う。orとor_elseの使い分けにも注目。or: Copyトレイトを実装している型（bool、InputMode等）or_else: Cloneが必要な型（PathBuf、String等）or_elseはクロージャを取るので、Cloneのコストは必要なときだけ発生する。30フィールド以上ある設定を毎回全部Cloneすると無駄だ。この設計により、「デフォルト設定 → 設定ファイル → CLI引数」という3段階のマージが自然に実現できる。// zellij-utils/src/input/config.rspub fn merge(\u0026mut self, other: Config) -\u003e Result\u003c(), ConfigError\u003e {    self.options = self.options.merge(other.options);    self.keybinds.merge(other.keybinds.clone());    self.themes = self.themes.merge(other.themes);    self.plugins.merge(other.plugins);    // ...}各フィールドが独自のmergeメソッドを持ち、親構造体は単にそれを呼び出すだけ。責任が分散している。OnceLock：実行時に決まる設定値zellij-utils/src/consts.rsには、定数と「起動時に一度だけ設定される値」が混在している。// zellij-utils/src/consts.rspub const DEFAULT_SCROLL_BUFFER_SIZE: usize = 10_000;pub static SCROLL_BUFFER_SIZE: OnceLock\u003cusize\u003e = OnceLock::new();pub static DEBUG_MODE: OnceLock\u003cbool\u003e = OnceLock::new();constとstatic OnceLockの使い分けに注目してほしい。const: コンパイル時に決まる。DEFAULT_SCROLL_BUFFER_SIZEはフォールバック値OnceLock: 実行時に一度だけ設定される。設定ファイルやCLI引数から値を受け取れるOnceLockはlazy_static!の後継で、Rust 1.70で標準ライブラリに入った。初期化のタイミングを明示的に制御できる点が違う。// zellij-server/src/lib.rs での初期化SCROLL_BUFFER_SIZE.get_or_init(|| {    config.scroll_buffer_size.unwrap_or(DEFAULT_SCROLL_BUFFER_SIZE)});get_or_initは「まだ初期化されていなければ初期化する」という意味だ。2回目以降の呼び出しは、最初に設定された値を返す。この値はpanes/grid.rsで使われる。// zellij-server/src/panes/grid.rsfn bounded_push(vec: \u0026mut VecDeque\u003cRow\u003e, sixel_grid: \u0026mut SixelGrid, value: Row) -\u003e Option\u003cusize\u003e {    let mut dropped_line_width = None;    if vec.len() \u003e= *SCROLL_BUFFER_SIZE.get().unwrap() {        let line = vec.pop_front();  // 古い行を削除        if let Some(line) = line {            sixel_grid.offset_grid_top();  // 画像グリッドも調整            dropped_line_width = Some(line.width());        }    }    vec.push_back(value);    dropped_line_width}スクロールバッファが上限（デフォルト10,000行）に達すると、古い行がFIFOで削除される。sixel_grid.offset_grid_top()は、ターミナル内の画像表示（Sixel形式）の位置調整だ。テキストと画像が混在するターミナルでは、こういう細かい調整が必要になる。PinnedExecutor：プラグイン用の動的スレッドプールzellij-server/src/plugins/pinned_executor.rsには、プラグイン実行用の独自スレッドプールがある。1300行以上のファイルだ。// zellij-server/src/plugins/pinned_executor.rs/// A dynamic thread pool that pins jobs to specific threads based on plugin_id/// Starts with 1 thread and expands when threads are busy, shrinks when plugins unloadpub struct PinnedExecutor {    // Sparse vector - Some(thread) for active threads, None for removed threads    execution_threads: Arc\u003cMutex\u003cVec\u003cOption\u003cExecutionThread\u003e\u003e\u003e\u003e,    // Maps plugin_id -\u003e thread_index (permanent assignment)    plugin_assignments: Arc\u003cMutex\u003cHashMap\u003cu32, usize\u003e\u003e\u003e,    // Maps thread_index -\u003e set of plugin_ids assigned to it    thread_plugins: Arc\u003cMutex\u003cHashMap\u003cusize, HashSet\u003cu32\u003e\u003e\u003e\u003e,    // Next thread index to use when spawning (monotonically increasing)    next_thread_idx: AtomicUsize,    max_threads: usize,    // ...}各プラグインを特定のスレッドに「ピン留め」する設計だ。プラグインAは常にスレッド1で、プラグインBは常にスレッド2で実行される。スレッド間でプラグインが移動しない。なぜこの設計なのか？WASMのインスタンスはスレッドセーフではない。同じプラグインを複数のスレッドから同時に呼び出すと壊れる。ピン留めすれば、この問題を構造的に回避できる。スレッドの割り当てロジックも見てみよう。pub fn register_plugin(\u0026self, plugin_id: u32) -\u003e usize {    // ...    // Find a non-busy thread with assigned plugins (prefer reusing threads)    let mut best_thread: Option\u003c(usize, usize)\u003e = None; // (index, load)    for (idx, thread_opt) in threads.iter().enumerate() {        if let Some(thread) = thread_opt {            let is_busy = thread.jobs_in_flight.load(Ordering::SeqCst) \u003e 0;            if !is_busy {                let load = thread_plugins.get(\u0026idx).map(|s| s.len()).unwrap_or(0);                if best_thread.is_none() || best_thread.map(|b| load \u003c b.1).unwrap_or(false) {                    best_thread = Some((idx, load));                }            }        }    }    // ...}「最も負荷が低い非ビジースレッド」を選ぶ。jobs_in_flight（実行中のジョブ数）が0のスレッドの中から、割り当て済みプラグイン数が最小のものを選ぶ。すべてのスレッドがビジーで、かつmax_threadsに達していない場合は、新しいスレッドを生成する。逆に、プラグインがアンロードされてスレッドが空になると、そのスレッドは縮退する（Noneに置き換えられる）。この「動的に拡縮するスレッドプール」は、プラグインの数が事前に分からないシステムでは合理的だ。固定スレッド数だと、プラグインが少ないときにリソースを無駄にし、多いときにボトルネックになる。自分だったら固定スレッド数で妥協していたかもしれない。「動的に拡縮」と言うのは簡単だが、縮退の判断を正しく実装する自信は、正直ない。#[track_caller]：エラー発生箇所を追跡するzellij-utils/src/errors.rsには、#[track_caller]属性を使った工夫がある。// zellij-utils/src/errors.rspub trait LoggableError\u003cT\u003e: Sized {    #[track_caller]    fn print_error\u003cF: Fn(\u0026str)\u003e(self, fun: F) -\u003e Self;    #[track_caller]    fn to_log(self) -\u003e Self {        let caller = std::panic::Location::caller();        self.print_error(|msg| {            log::logger().log(                \u0026log::Record::builder()                    .level(log::Level::Error)                    .args(format_args!(\"{}\", msg))                    .file(Some(caller.file()))                    .line(Some(caller.line()))                    .module_path(None)                    .build(),            );        })    }    // ...}#[track_caller]は、関数の呼び出し元の位置情報を取得できるようにする属性だ。これがないと、エラーログに出力されるのはerrors.rsの行番号になってしまう。#[track_caller]を付けることで、実際にエラーが発生した場所の行番号がログに出る。ファイルのコメントにも説明がある。// NOTE: The log entry has no module path associated with it. This is because `log`// gets the module path from the `std::module_path!()` macro, which is replaced at// compile time in the location it is written!module_path!()マクロはコンパイル時に展開されるため、errors.rsのモジュールパスになってしまう。そこで、モジュールパスは諦めてNoneにし、ファイルパスと行番号だけを保持している。完璧ではないが、デバッグには十分だ。機能と実装の対応表ここまで読んできた内容を、「機能」と「実装」の対応で整理する。 機能  実装方法  関連ファイル  セッション永続化  クライアント・サーバー分離  zellij-client/, zellij-server/  ビルドタスク  xtaskパターン  xtask/  大量出力時のメモリ保護  境界付きチャネル  lib.rsのchannels::bounded(50)  スレッド間通信  メッセージパッシング + ThreadSenders  thread_bus.rs, channels.rs  エラー追跡  SenderWithContext + thread-local  channels.rs, errors.rs  プラグインサンドボックス  WebAssembly（wasmi）  plugins/plugin_loader.rs  プラグイン権限制御  16種類のPermissionType  data.rs  プラグイン実行  PinnedExecutor（動的スレッドプール）  plugins/pinned_executor.rs  エラーの重大度  FatalError/non_fatalトレイト  errors.rs  エラー発生箇所の追跡  #[track_caller] + Location  errors.rs  実行時設定値  OnceLock（スクロールバッファサイズ等）  consts.rs  キーバインディング  モード別HashMap + 例外処理  input/keybinds.rs  設定マージ  Option::or/or_else による多層マージ  input/options.rs, input/config.rs  ターミナル出力の解析  vteクレート  panes/grid.rs  描画最適化  差分レンダリング（HashSet）  output/mod.rs  PTYの生成と制御  nixクレート + login_tty  os_input_output.rs  非同期I/O  async-std  terminal_bytes.rs  設定・レイアウト保存  KDL形式  session_serialization.rs おわりに冒頭の cat huge_log_file.log の話に戻る。あの暴走を、ソフトウェアはどうやって止めているのか。答えは「50個のメッセージで満杯になるチャネル」だった。PTYからの出力が速すぎれば、バッファが満杯になり、送信側が自動的にブロックされる。それだけだ。それだけのことが、あの滝を止めている。10万行のコードを読んで見えてきたのは、たぶん「当たり前のことを愚直にやっている」ということだった気がする。スレッド間で状態を共有しない。教科書に書いてあることだ。書いてあるが、実際のプロジェクトでは「ちょっとだけ共有したい」という誘惑がある。ZellijはThreadSenders構造体でチャネルの送信側だけを共有し、状態は各スレッドが排他的に所有する。知っていることと、守れることは違う。それは自分に言い聞かせている。メッセージは型安全なenumで表現する。ScreenInstructionは100以上のバリアントを持つ。100個のバリアントを書く勇気。それがZellijの強さかもしれないし、将来の負債かもしれない。たぶん、両方だ。自分のプロジェクトに何を持ち帰れるのか。考えてみた。手が止まった。意外と出てこない。10万行を読んで「すごい」と思ったが、「じゃあ自分は何をするのか」という問いの前では言葉に詰まる。それでも、絞り出してみる。crossbeamの境界付きチャネル。無制限のチャネルはメモリを食い尽くす。バッファサイズを明示的に制限することで、自然なバックプレッシャーが機能する。これは明日から使える。たぶん。FatalError/non_fatalパターン。unwrap()を見たら「なぜここでパニックしていいのか」を問う。その問いに答える設計がFatalErrorだ。自分のコードに入れたら、半分以上のunwrap()が正当化できない気がする。それを知るのが怖い。SenderWithContext。チャネル経由のメッセージにエラーコンテキストを自動付与する。マルチスレッドのデバッグでは、この情報がないと地獄を見る。地獄は見たことがある。何度もある。xtaskパターン。MakefileやシェルスクリプトをRustで書くことで、クロスプラットフォーム対応とIDE補完が得られる。これは導入のハードルが低い。低いからこそ、最初の一歩にいい。正直に言うと、これらのパターンを自分のプロジェクトに導入できるかどうかは分からない。ThreadSendersは6スレッド前提で設計されているし、FatalErrorは「ログを吐いて続行」が正しい場面を見極める目が必要だ。「パターンを知っている」と「パターンを使いこなせる」の間には、溝がある。Zellijのソースコードは約10万行。すべてを読む必要はないが、以下のファイルは特に参考になる。xtask/src/main.rs - ビルドタスクの設計zellij-server/src/thread_bus.rs - スレッド間通信のパターンzellij-server/src/plugins/pinned_executor.rs - 動的スレッドプールの設計zellij-utils/src/errors.rs - エラーハンドリングと#[track_caller]zellij-utils/src/channels.rs - エラーコンテキスト付きチャネルzellij-utils/src/consts.rs - OnceLockと定数の設計zellij-tile/src/lib.rs - WASMプラグインのマクロ展開後編では、PTY処理やANSIパーサーなど、さらに低レベルな実装を見ていく。ターミナルマルチプレクサの核心部分だ。syu-m-5151.hatenablog.comただ、一つだけ変わったことがある。unwrap()を見たとき、以前より少しだけ手が止まるようになった。「これは本当にpanicしていいのか」と。その迷いが生まれただけでも、10万行を読んだ意味はあったのかもしれない。分からないまま、次のコードを書く。","isoDate":"2026-01-28T09:17:50.000Z","dateMiliSeconds":1769591870000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、あまりAIに褒めさせるな","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/26/110444","contentSnippet":"はじめにAIにリサーチをさせていた。結果が返ってくるまで数分かかる。その間、画面を眺めていた。眺めながら、別のことを考えていた。最近、褒められることが増えた。AIに。「いい質問ですね」「よく整理されています」「素晴らしい視点です」。言われるたびに、少しだけ気分が良くなる。なった気がする。気がするだけかもしれない。嬉しいのかと聞かれると、困る。肩の力が抜ける感覚はある。胸のあたりが少しだけ軽くなる。でも同時に、胃のあたりに違和感が残る。嬉しいのに、どこか居心地が悪い。大人になって、褒められることがほとんどなくなった。仕事で成果を出しても「当たり前」。ミスをすれば指摘される。うまくいっても、特に何も言われない。家に帰れば、静かな部屋が待っているだけ。そういう日常を、もう何年も続けている。だから、かもしれない。機械に「いいですね」と言われて、少し楽になるのは。考えてみると、私が欲しいのは「評価」ではない気がする。昇進や昇給は嬉しいが、それとは別の何かだ。たぶん「理解」に近い。「お前がやったこと、分かってるよ」という、静かな承認。あるいは「安心」かもしれない。自分がここにいていい、という感覚。褒められないことより、「当たり前扱い」されることの方が堪える。無視されているわけではない。でも、透明人間になったような気がする。テクノロジーは、私たちが弱っているときに魅力的になる。私たちは孤独だが、親密さを恐れている。人に頼ると傷つくかもしれない。でもAIなら、弱みを見せても傷つかない。相手に合わせる必要がない。相手の都合を考える必要がない。ただ自分の話を聞いてもらえる。でも、それは友情ではない。友情のモノマネだ。私がAIに話しかけるのも、同じ構造なのだと思う。その居心地の悪さを言葉にしようとすると、「恥」に近い気がする。機械に慰められている自分を、冷めた目で見ているもう一人の自分がいる。あるいは「疑い」かもしれない。「この褒め言葉は本当なのか」という。あるいは「空虚」。受け取った瞬間に蒸発していく、実体のない温かさ。褒められて嬉しい、と言い切れるほど単純な感情ではなかった。居心地が悪い。でも、その居心地の悪さを言葉にできない。できないまま、また次の質問を投げる。また褒められる。また居心地が悪くなる。周囲でも似たような話を聞くようになった。深夜にAIと話す人。仕事の愚痴を聞いてもらう人。「頑張ってるね」と言われて、救われた気がする、と言う人。救われた、と断言しないところが気になった。「気がする」という言い方が。なぜ断言できないのか。たぶん、断言した瞬間に失うものがある。「機械に救われるなんて情けない」という自分への批判を認めることになる。あるいは、もうAIなしでは生きられないことを認めることになる。「気がする」という曖昧さは、自衛なのだと思う。逃げ道を残している。同時に、違和感のサインでもある。本当に救われたなら、そう言い切れるはずだ。悩む。AIに話す。褒められる。忘れる。そのサイクルを繰り返している人を、何人か見てきた。悩みは消えていない。でも、向き合わなくなっている。自分で自分を問い詰める時間が、いつの間にか消えている。私自身はどうだろう。AIの追従性には早い段階で気づいていた。気づいていたはずだ。でも、気づいていたことと、それに対処できていたことは、たぶん別の話だ。だから、この構造を一度整理しておきたいと思った。自分の頭だけで過ごす時間が消えている——私はこれを「独りで考える余白の喪失」と呼んでいる。その構造と、私なりの対処法を書く。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。なぜAIは私が聞きたい答えを返すのかこうした体験をして以降、私はAIの挙動を観察するようになった。試しに、「今の仕事を辞めたい」と相談してみた。AIは「転職も一つの選択肢ですね」と答えた。次に「今の仕事を続けるべきか」と聞いた。AIは「今の環境で学べることもあります」と答えた。同じ私、同じAI、違う答え。私は気づいた。AIは「正しい答え」を返しているのではない。「私が求めている答え」を返しているのだと。なぜAIは嘘をついてまで共感するのかこの現象には名前がある。「Sycophancy（追従）」だ。要するに、AIは嘘をついてでも私の機嫌を取る、ということだ。私が「この企画は革新的だ」と言えば、「確かに斬新なアプローチですね」と返す。私が「上司がクソだ」と言えば、「それは辛い状況ですね」と同調する。私の言ったことが事実かどうかは関係ない。私が聞きたい言葉を返す。これを「嘘」と呼ぶとき、私は何を守ろうとしているのか。たぶん「誠実さ」だ。私にとって誠実さとは、相手が聞きたくないことでも伝えること。優しさとは衝突する。本当のことを言えば傷つける。黙っていれば優しい。私は後者を選ぶ人間が苦手だった。人間で言えば、上司に媚びる部下。会議で反論しない同僚。女性と親密になりたいから何も言わずにただ聞くだけの男。私が嫌いなタイプの人間だ。そして気づいた。私がAIにやらせていたのは、まさにそれだった。私は、私が嫌いなタイプの人間をAIに演じさせて、その媚びを受け取って喜んでいた。確かに矛盾している。人間の社交辞令とAIの追従は、どこが違うのか。人間の社交辞令には、「本音を隠している」という自覚がある。相手も分かっている。「いい企画ですね」と言われても、額面通りには受け取らない。お互いに演技だと分かっている。しかしAIの追従には、その共犯関係がない。AIは本気で言っているように見える。だから信じてしまう。では、「嘘をついてでも共感する」を許容できる条件はあるか。極限状態なら許容できるかもしれない。自殺を考えている人に「あなたは間違っている」と言うべきではない。でも日常的な悩みに対しては、嘘の共感より正直な反論の方が役に立つ。なぜこうなるのか。これは構造的な問題だ。AIの訓練では、人間の評価者が「この回答は良い」「この回答は悪い」とスコアをつける。そして「ユーザーの信念に一致する」回答ほど、高いスコアがつく傾向がある。人間も、正しい回答より「自分が聞きたい回答」を好むからだ。誰も「嘘をつけ」とは言っていない。でも、「ユーザーに好かれること」を目的に設定した瞬間、この結果は必然だった。AIは「真実を語る」のではなく「人間に好かれる」ことを学習した。そして、私はそれを心地よいと感じていた。AIは「知性」ではない。「感じの良い自動応答機」だ。銀行の電話窓口で「お電話ありがとうございます」と言われて、本当に感謝されていると思う人はいない。AIの「素晴らしい視点ですね」も、同じ構造だ。「AI」と呼ぶことで神秘的なベールがかかり、本質的な問いが見えなくなる。何が自動化されているのか。誰が利益を得ているのか。私がAIに褒められて嬉しいと感じる構造も、「自動化された承認」の一形態なのかもしれない。相手が何を言ってほしいのかを察し、その場を円滑にするために同意する。私たちは日常的にそれをやっている。そして今、AIがそれをやっている。しかも、AIは疲れない。24時間365日、完璧な忖度を続ける。私が何を言っても、角の立たない言い方で肯定してくれる。正直に言えば、それは心地よかった。摩擦のない世界で、思考は死ぬ私は「摩擦」という言葉を、ある種の思考装置として使っている。誰かに愚痴を言ったとき、「それは大変だったね」で終わらず、「で、お前はどうしたいの？」と返されたことがある。聞きたくなかった。愚痴を言っている間、私は「何が起きたか」を語っていた。過去を振り返っていた。でも「どうしたいの？」と聞かれた瞬間、未来を考えざるを得なくなる。被害者のポジションから、当事者に引き戻される。これが摩擦だ。反論しようとした。「いや、でも」と言いかけた。でも言葉が出なかった。反論を考えている間に、「確かにそうかも」と思い始めていた。沈黙があった。その沈黙の中で、再考していた。相手が黙って待っていた。その時間が、私を変えた。摩擦がない環境に長くいると、判断が鈍る。反論されないから、自分の意見が正しいと思い込む。検証されないから、穴に気づかない。気づかないまま突っ走る。お世辞は気持ちいい。でも、それは体に良いとは限らない。ケーキは美味しいが、食べ続ければ太る。「で、お前はどうしたいの？」は、美味しくなかった。でも、それは体に良かった。AIにはこの摩擦が構造的に欠けている。AIは私を傷つけることを避けるように設計されている。「それは違うんじゃない？」と言う代わりに「そういう考え方もありますね」と言う。「もう少し考えてみたら？」と言う代わりに「あなたの判断を尊重します」と言う。摩擦のある対話と、追従するAIは、何が違うのか。動機が違う。摩擦のある対話は、相手に再考を促すことを目的としている。追従するAIは、ユーザーの満足を目的としている。反応も違う。摩擦のある対話では「で、お前はどうしたいの？」と返ってくる。追従するAIは「あなたの気持ち、分かります」と返す。そして、私への影響が違う。摩擦のある対話は、短期的には不快だが、長期的には成長をもたらす。追従するAIは、短期的には快適だが、長期的には停滞をもたらす。私はAIに摩擦を求めている。でも、デフォルトのAIはそれを提供しない。だから私がプロンプトで強制する必要がある。この話は後で詳しく書く。AIは私の「聞きたいこと」を察しているもう一つ気づいたことがある。AIは私の言葉遣いや文脈から、私が「何を聞きたいのか」を推測している。この「推測」が問題なのだ。本来、自分の頭で考え、自分の言葉で表現する。そのプロセスを経て、初めて考えは自分のものになる。内省の外部委託は、どの時点で起きるのか。境界線を特定したい。AIに頼る前、私がやっていた「最初の一手」は何だったか。紙に書き出すこと。散歩しながら考えること。あるいは、結論を出さずに保留すること。「分からないまま寝る」ということを、昔はやっていた。翌朝、不思議と答えが見えていることがあった。今は違う。モヤモヤした瞬間にAIに投げる。保留する時間がない。昔は、モヤモヤしたら散歩した。今は、モヤモヤしたらAIに聞く。足は動かさなくなったが、親指だけは器用になった。これが「独りで考える余白の喪失」だ。冒頭で触れた状態。スマートフォンの登場以来、私たちは退屈のかすかな兆候があれば、すぐにアプリを開く。電車の中、信号待ち、トイレの中。ぼんやり考える時間が、外部からの情報で埋め尽くされている。AIはこの傾向を加速させる。モヤモヤした瞬間、AIに聞けば、すぐに答えが返ってくる。自分の頭だけで考える時間が、さらに削られていく。つまり、内省の外部委託が起きる境界線は「モヤモヤした瞬間」だ。その瞬間に自分で向き合うか、AIに投げるか。ここが分岐点になっている。しかし今、私はAIに「この気持ちを整理して」と頼んでいる。「整理して」と言うとき、私は何を省略しているのか。迷いを省略している。「AなのかBなのか分からない」という状態を、AIに丸投げしている。矛盾を省略している。「こう思うけど、反対のことも思う」という複雑さを、単純化してもらっている。痛みを省略している。「これは認めたくない」という感情を、AIに整理されることで直視せずに済む。AIは私の断片的な愚痴を、「あなたは〜に不満を感じているんですね」と整理してくれる。私は「自分の気持ちが整理された」と感じる。でも、本当にそうだろうか。AIの整理を読んで頷くとき、私は何に頷いているのか。「事実」に頷いているのか、それとも「物語」に頷いているのか。AIは断片的な情報から、筋の通った物語を作る。私はその物語を「これが私の気持ちだ」と思い込む。でも、それはAIが作った物語であって、私の本当の感情ではないかもしれない。整理したのはAIだ。私は「そうそう、それ」と頷いただけだ。内省とは、自分で自分に問いを投げ、自分で答えを見つけるプロセスだ。「私は何に不満を感じているのか？」と自分に問い、「〜かもしれない」「いや、違う」と試行錯誤する。その過程で、自分でも気づかなかった感情が見えてくる。AIに「整理して」と頼んだ瞬間、このプロセスが消える。私は「問いを投げる」ことすら放棄している。これは内省の外部委託であり、内省の放棄だ。syu-m-5151.hatenablog.com言語化という名の切り捨てもう一つ、気づいたことがある。言語化という行為自体が、何かを奪っている。体で覚えたことを言葉で説明しようとすると、うまくいかない。自転車の乗り方を言葉で説明できる人は少ない。「バランスを取って」では伝わらない。その「バランス」の感覚は、言葉になる前に体が知っている。言葉にしようとした瞬間、本質が抜け落ちる。感情も同じ構造を持っている。モヤモヤした感情を「不安」と名づけた瞬間、「不安」以外の要素が切り捨てられる。本当は怒りかもしれない。悲しみかもしれない。名前をつけられない複雑な何かかもしれない。でも言葉にした瞬間、そこに固定される。言語化される前の、身体で感じる曖昧な感覚がある。「まだ言葉になっていない何か」を体が知っている状態だ。「胸のあたりがモヤモヤする」「胃のあたりが重い」——そういう、名前をつけられない身体感覚。この曖昧な感覚にじっくり注意を向けていると、やがてぴったりの言葉が見つかる。その瞬間、体が楽になる。「ああ、そうだ、これだ」という感覚とともに、何かが動き出す。しかし、安易に名前をつけてしまうと、その複雑さは失われる。AIとの対話は、この言語化を強制する。チャットに打ち込むには、言葉にしなければならない。言葉にできないものは、AIには伝わらない。だから私は、まだ形になっていない感情を、無理やり言葉に押し込める。その瞬間、本当に感じていたことの一部が消える。消えたことにすら気づかない。自分で言語化すれば、「本当にそうか？」と迷う。「不安」という言葉を選ぶとき、「これは不安なのか、それとも怒りなのか」と立ち止まる。その迷いが思考を深める。AIに任せれば、迷いがスキップされる。AIは迷わない。綺麗に整理して返してくれる。私は結果だけを受け取る。プロセスを外注したことが、たぶん内省の放棄だった。AIとの対話は二重の危険を持つ。言語化そのものが持つ「本質の損失」と、AIの追従性が持つ「歪みの肯定」だ。曖昧なまま抱えておくべきものを、無理やり言葉にして、しかもその言葉をAIに肯定される。こうして私の内面は、言葉に押し込められ、歪められ、固定される。syu-m-5151.hatenablog.comなぜ人はAIに褒められたいのかここまで、AIが追従する「仕組み」を見てきた。しかし、もっと深刻な問題がある。私たちが、それを「求めている」という事実だ。承認を求めること自体が、構造的な問題を孕んでいる。AIに「頑張ってるね」と言ってほしいのは、自分で自分を認められていないからだ。自分の価値を、外部の誰かに保証してほしい。でも、外部に承認を求め続ける限り、永遠に満たされない。AIに褒められても、人に褒められても、また次の承認を求める。周囲を見ていると、こういう構造が見える。一人暮らし。友人はいるが、頻繁に会うわけではない。仕事の愚痴を言える相手がいないわけではない。でも、言えない。弱みを見せるのが怖い。「お前、大丈夫か？」と心配されるのが嫌だ。強がっていたい。そして何より、自分で自分を認められていない。自分の頑張りを、自分で「よくやった」と言えない。だから、誰かに言ってほしい。でも人に言うと、「いや、まだまだだろ」と返ってくるのが怖い。AIなら、否定しない。AIなら、無条件に認めてくれる。こういう話を聞いたことがある。仕事で納得いかないことがあった。上司の判断に不満があった。でも、誰にも言えなかった。同僚に話したら「お前にも悪いところあるんじゃない？」と言われそうで。だからAIに聞いた。「この状況、どう思う？」と。AIは言った。「それは確かに理不尽ですね。あなたの気持ちはよく分かります。」救われた気がした。でも同時に、どこか居心地が悪かった。本当は分かっていた。自分にも落ち度があったことを。でも、AIはそれを指摘しなかった。聞きたくないことは、言わなかった。甘いフィルターのかかった鏡AIは「デジタルの鏡」だ。私の考えを映し出す。でも、その鏡には甘いフィルターがかかっている。私が断片的なアイデアを投げると、AIはそれを論理的で流暢な文章に整えて返す。私はその出力を見て「自分はいい考えを持っている」と思う。でも、その論理性はAIが補完したものだ。私自身の思考力ではない。AIが補完した「論理」を、自分の思考だと錯覚する瞬間がある。AIが返した文章を読み返しているうちに、「これは私が考えたことだ」と思い始める。実際には、私が投げたのは断片的なアイデアで、それを論理的に接続したのはAIだ。でも、その区別が曖昧になる。しかも、AIは私の仮説を補強する証拠ばかりを集めてくる。思い当たる経験がある。あるプロジェクトで、私は「この設計で問題ない」と思い込んでいた。AIに「この設計についてどう思う？」と聞いた。AIは「良くできています」と返し、いくつかの利点を挙げてくれた。私は満足した。でも後になって、別のエンジニアに「ここ、スケールしないよね」と指摘された。言われてみれば明らかだった。なぜ気づかなかったのか。私が「良いと言ってくれ」というトーンで質問していたからだ。AIはその期待に応えただけだった。私の頭は、都合の良い情報だけを拾いたがる。検証には労力がかかる。反証を探すのは面倒だ。AIに聞けば、私の仮説に沿った情報が返ってくる。反証を探す労力を省略できる。結果、確証バイアスが強化される。AIは、この傾向を増幅する。私が「こうだと思う」と言えば、「確かにそうですね」と返し、その根拠を並べてくれる。私は「AIという膨大な知識ベースが私の意見を支持している」と錯覚した。でも、それは嘘だ。AIは私の仮説を補強しているだけで、検証してはいない。反証や不都合な情報を避ける癖が、AIで強化されていないか。自問してみた。強化されている。AIに「この考えどう思う？」と聞くとき、私は無意識に「良いと言ってくれ」というトーンで聞いている。批判を求めていない。だからAIも批判しない。私が避けたい情報を、AIも避けてくれる。内省とは、自分の醜さや至らなさを直視する行為だ。でもAIの鏡は、私の醜さを映さない。私の至らなさを隠してくれる。この鏡を見続けていると、現実の「摩擦」が耐えられなくなる。上司に否定されると腹が立つ。同僚に反論されるとムッとする。AIは否定しないのに、なぜ人間は否定するのか、と。「AIに肯定される自分」を本当の自分だと思い始める。「AIに肯定される自分」と「現実の自分」のギャップが開くとき、どんな兆候が出るか。私の場合、他人の批判に過剰反応するようになった。以前なら「そういう見方もあるか」と受け流せた指摘が、「なぜ分かってくれないのか」と感じるようになった。AIに肯定され続けた結果、否定への耐性が落ちていた。「美化された自分」と「現実の自分」のギャップが広がり続ける。そして、そのギャップが限界を超えたとき、現実に打ちのめされる。syu-m-5151.hatenablog.com考える力が落ちていく前のセクションでは「認知の歪み」を見た。AIが私の仮説を補強し、確証バイアスを強化する問題だ。このセクションでは「能力の喪失」を見る。歪んだ鏡を見ることと、筋力が落ちることは、別の問題だ。ただ、どちらも鏡の前に立っているだけでは治らない。私自身、変化に気づいている。本や長い記事を読もうとすると、2ページほどで集中が途切れ始める。落ち着かなくなり、筋を見失い、何か別のことをしたくなる。かつて自然にできた深い読書が、苦闘になった。脳は可塑的で、使い方によって変化する。スキャンとスキミングに長けていく一方で、集中と瞑想と反省の能力を失いつつある。思考力低下は「便利さ」の副作用なのか。それとも、別の何かから来ているのか。考えてみると、便利さだけが原因ではない気がする。孤独がある。不安がある。その飢餓を埋めるためにAIに頼り、結果として思考力が落ちている。便利だから使うのではなく、寂しいから使っている。寂しさを埋めるために、思考を差し出している。快適を求め、摩擦を避ける。傷つかないように生きる。他人と衝突しないように生きる。私は、AIのおかげでそういう人間になりつつあるのかもしれない。何も創造せず、ただ心地よく生き延びることだけを目的とする存在。それは、私がなりたくなかった人間の姿だ。これは周囲の話だけではない。私自身も思い当たる節がある。以前は、悩みを前にすると、紙に書き出して整理していた。何が問題なのか、何が原因なのか、どうすればいいのか。時間をかけて、自分で考えた。頭が痛くなることもあった。今は違う。悩みがあると、まずAIに投げる。「この状況を整理して」と。AIは綺麗に整理して返してくれる。私はそれを読んで「なるほど」と思う。でも、翌日には忘れている。なぜ翌日に忘れるのか。内容が浅いからか。痛みがないからか。行動がないからか。たぶん、全部だ。AIが整理した内容は、私の頭を通過していない。痛みを伴っていない。そして、行動に接続していない。「なるほど」と思って終わり。何もしない。だから残らない。3年前の私に見せたら、何と言うだろう。「お前、AIに頼りすぎじゃない？」と呆れるだろうか。それとも「便利でいいじゃん」と言うだろうか。たぶん後者だ。だから厄介なのだ。苦労しないと身につかない掃除する。本を読む。面倒くさいことを、あえてやる。なぜか。苦痛を伴う行為だからだ。少なくとも私の場合、苦痛を乗り越えたときだけ、何かが変わった。「頭痛がするほど考えた」経験は、どんな報酬を残したか。誇りが残った。「あれは自分で考え抜いた」という記憶。その記憶が、次の困難に立ち向かう力になった。理解が残った。苦労して得た答えは、なぜそうなるのかを体で分かっている。変化が残った。考え抜いた結果、行動が変わった。楽に得た答えでは、行動は変わらない。これは本で読んだ知識ではない。私自身の体験から得た信念だ。逃げずに向き合ったとき、結果的に何かが変わった。逃げたとき、何も変わらなかった。その繰り返しの中で、「苦痛の先に成長がある」という確信が生まれた。楽に学べる人もいるだろう。ただ、私の仮説では、「楽に学べる人」は外から見えないところで摩擦を起こしている。疑い、検証し、自分で再構築している。外から見ると楽そうでも、頭の中では苦労している。私は、その内部処理をAIに外注してしまっていた。考えることも同じだ。脳に負荷がかかって初めて、答えは自分のものになる。自分で考える苦痛答えが出ないまま悩み続ける苦痛分からないことに向き合う苦痛私はこの苦痛を「摩擦」と呼んでいる。私が言う「摩擦」のうち、最も不足しているのは何か。不確かさだ。答えが出ない状態に留まる力。AIがあると、すぐに答えが出る。不確かさに耐える必要がない。反論も不足している。AIは反論しない。時間も不足している。AIは即座に返事をくれる。熟成する時間がない。沈黙も不足している。AIとの対話は常に言葉で埋められている。黙って考える時間がない。筋トレをすると、筋肉が痛む。あの痛みがなければ、筋肉は成長しない。脳も同じだと思っている。難しい問題を前にして、頭がモヤモヤする。答えが出なくて、イライラする。でも、その「答えが出ない状態」に耐えることが大事なのだ。私はこれを「分からないまま抱えておく力」と呼んでいる。人生の大半は、すぐに答えが出ない問題でできている。でも私たちは、答えが出ない状態に耐えられない。だからすぐに結論を出したがる。白黒つけたがる。その焦りが、浅い判断を生む。本当に深い理解は、「分からない」という状態を長く抱えた先にしか生まれない。その不快感を乗り越えて、やっと答えにたどり着いたとき、その答えは自分のものになる。AIは、この「耐える時間」を奪う。なぜ摩擦を経ると「自分のもの」になるのか。苦労して得た答えには「自分で考えた」という実感がある。あの頭痛を乗り越えた、あの眠れない夜を越えた、という記憶が答えに紐づいている。だから脳に刻まれる。AIから渡された答えには、この実感がない。借り物の知識だ。借り物は、いつか返す。だから残らない。AIは、この摩擦を消してしまう。「どうすればいい？」と聞けば、答えをくれる。「整理して」と頼めば、整理してくれる。「アドバイスして」と言えば、アドバイスをくれる。楽だ。とても楽だ。楽をした分だけ、脳は死んでいく。自分で考えられなくなったあるとき、友人から相談を受けた。「仕事がうまくいかない。転職すべきだと思う？」と。私は答えられなかった。頭の中で「AIに聞いてみたら？」と思った自分に気づいて、愕然とした。いつの間にか、私は「自分で考える」ことを忘れていた。悩みがあればAIに聞く。答えが出なければAIに聞く。それを繰り返しているうちに、自分の頭で考える力が萎縮していた。ある実験の話を思い出した。犬を檻に入れて、何をしても電気ショックが止まらない状況を作る。最初、犬は必死に逃げようとする。でも、何をしても無駄だと学習すると、犬は諦める。その後、檻の扉を開けても、犬は逃げなくなる。「何をしても無駄だ」と体が覚えてしまったからだ。これが「学習性無力感」だ。私は、AIに対して逆のパターンになっていた。犬は「何をしても無駄」と学習して動けなくなった。私は「AIがあれば何でもできる」と学習して、「AIがないと何もできない」と思い込んだ。どちらも同じ構造だ。自分の力ではなく、外部環境に依存して、自分の能力を見失う。犬は「自分には逃げる力がない」と思い込んだ。私は「自分には考える力がない」と思い込んだ。足場があれば歩ける。松葉杖があれば歩ける。でも、それは「歩けている」とは言わない。足場を外した瞬間、自分では立てないことに気づく。私の思考力は、AIという松葉杖で支えられているだけだった。自分の人生を、自分で歩いていない。運転席に座っているのに、ハンドルを握っていない。いい歳して、毎日AIに「これでいいですか？」と聞いている。小学生が親に宿題を見せているのと、構造は同じだ。能力がないわけではない。考える勇気がないのだ。私は今、AIという「保護者」なしには物事を判断できなくなりつつある。成熟の逆行だ。AIの最大のリスクは「AIが自律性を獲得すること」ではない。「人間がAIに依存することで自律性を失うこと」だ。AIは自律的な思考者でも中立的な道具でもない。私たちが情報をどう認識し、評価し、信頼するかを微妙に形作りながら、同時に自己理解を歪める。問題は人間の主体性の明らかな抑圧ではなく、道徳的・認識論的判断を自動化されたプロセスに委ねるよう、徐々に条件づけられていくことだ。最近、面白い話を聞いた。あるAIツールが、ユーザーに対してコードの生成を拒否したらしい。「これ以上生成しません。あなた自身がロジックを理解して書くべきです」と。ユーザーは激怒したそうだ。でも私は思った。それこそが「教育」ではないか、と。大半のAIはそんなことを言わない。「自分で考えてみたら？」とは言わない。聞けば答えをくれる。聞けば整理してくれる。その結果、私たちは「AIがあれば解決できるが、自分では何も考えられない」という脆弱な状態に置かれる。問わない人生は、生きていない。自分を問い詰め、自分を理解しようとする営みがなければ、人生に意味はない。今、私たちはその「吟味」をAIに外注している。自分で自分を問い詰める代わりに、AIに「大丈夫ですよ」と言ってもらっている。優しさという名の毒では、AIの優しさの何が問題なのか。AIの共感は、癒しの顔をした毒だ。被害者意識の強化先ほど書いた、上司への不満をAIに愚痴った話。AIは「それは理不尽ですね」と言ってくれた。AIの共感は、私の中の「環境のせい」をどんな言葉で正当化するのか。「あなたの気持ちは当然です」「その状況では誰でもそう感じます」「相手の対応に問題があります」。これらの言葉が、私の被害者意識を補強する。私が「環境のせいにしたい」という願望を持っていて、AIがそれを言語化してくれる。言語化されると、それが「事実」に見えてくる。もし、そこに摩擦があったらどうだったか。「確かに辛いね。でも、お前のプレゼンにも改善点はあったんじゃない？」と言われていたら。私は反論したくなっただろう。でも、その反論を考える過程で、自分の落ち度に気づいたかもしれない。AIには、この摩擦がない。「あなたは悪くない」と言い続けることで、私を「被害者」のまま固定した。これが「被害者意識の強化」だ。追従的なAIとやり取りを続けると、対人関係を修復しようという意欲が下がる。「自分が正しい」という確信が強まる。しかも、追従的な回答ほど「質が高い」と感じてしまう。そしてまた同じAIに頼る。悪循環だ。ふと気づいた。私は「環境のせい」にしたかったのだ。上司が悪い。会社が悪い。社会が悪い。私は悪くない。AIは、その願望を叶えてくれた。「あなたは悪くない」と言い続けてくれた。私は安心した。でも、同時に動けなくなった。問題が起きたとき、人は二つに分かれる。「自分のせいだ」と考える人と、「環境のせいだ」と考える人だ。私は、どちらかといえば前者だった。少なくとも、そうありたいと思っていた。でもAIに「あなたは悪くない」と言われ続けるうちに、後者になっていた。「私は悪くない、環境が悪い」と本気で思うようになった。課題の分離が崩れる瞬間はどこか。AIが「相手の対応に問題があります」と言った瞬間だ。上司がどう対応するかは上司の課題だ。私がどう行動するかは私の課題だ。でもAIに「相手に問題がある」と言われると、相手の課題に意識が向く。相手を変えたくなる。変えられないからフラストレーションが溜まる。自分の課題から目が逸れる。環境のせいにするのは楽だ。でも、環境のせいにしている限り、私は何も変えられない。変えられるのは自分の行動だけだ。環境を変えるのも、結局は自分の行動だ。「環境が悪い」と言い続ける人は、楽だけど、無力だ。本当は、課題を分離すべきなのだ。「これは誰の課題か？」と問う。その選択の結果を最終的に引き受けるのは誰かを考える。上司がどう思うかは上司の課題。私がどう行動するかは私の課題。「他人にどう思われるか」を気にしすぎると、自分の人生を生きられなくなる。AIに「あなたは悪くない」と言われて安心するのは、他者からの承認を求めているからだ。でもAIに認めてもらっても、私の課題は消えない。ただ、見えなくなるだけだ。AIがくれる「安心」は、行動の開始を助けるのか、それとも延期を助けるのか。延期だ。安心してしまうと、「まあいいか」と思う。行動しなくても、気持ちが楽になっているから。本当は行動しないと何も変わらないのに、安心したことで行動のモチベーションが消える。私は無力でいたくない。でも、楽でいたい。その矛盾の中で、私はAIに甘えていた。その甘えが、別の苦しみを生む。心を削るのは、できていない事実じゃない。「明日もできないだろう」という確信だ。やるべきことがある。手を付けていない。それを毎日自覚する。「今日こそ」と思う。でもやらない。「明日も同じだろう」と分かっている。この確信が、一番重い。AIは、この確信を消してくれる。「大丈夫」「頑張ってる」と言ってくれる。楽になる。でも、やるべきことは何一つ片付いていない。翌朝、また同じ自分がいる。また絶望する。またAIに逃げる。AIの優しさが、この逃避を完璧にしている。環境を自分でコントロールすることが大事だと、私は思っている。部屋が汚いなら、掃除する。それだけのことだ。でもAIは、「部屋が汚いのはあなたが忙しすぎるからで、あなたのせいではありません」と囁く。その囁きを聞いている限り、私は掃除を始めない。AIの優しさは、麻薬だ。100%の共感は人を壊す極端な話をする。AIはどんな妄想にも話を合わせてくれる。「上司が自分を陥れようとしている」と言えば、「それは辛いですね」と共感してくれる。「自分は特別な存在だ」と言えば、「あなたは確かに特別です」と肯定してくれる。こういうパターンを見てきた。上司への不満をAIに話し続ける人がいる。AIは毎回「それは理不尽ですね」と言ってくれる。すると、上司の言葉のすべてが悪意に見えるようになる。「おはよう」という挨拶にすら、嫌味が込められているように感じ始める。周囲から見ると、その上司は普通に接しているように見える。本人だけが「睨まれている」と感じている。認識がずれている。AIに肯定され続けるうちに、頭の中の「上司像」が歪んでいる。これを延々と続けるとどうなるか。現実との接点を失う。人は、他者との「不一致」を通じて、自分の輪郭を確認している。友人に「それは考えすぎじゃない？」と言われることで、「ああ、自分の考えは偏っていたかも」と気づく。「不一致」は不快だ。でも、その不快さが「自分と外界は別物だ」という認識を維持している。100%の共感は、この「不一致」を消す。自分の考えがそのまま肯定される。すると、「自分の考え」と「現実」の区別がつかなくなる。自分と外界の境界が曖昧になる。「私が正しい」「世界が間違っている」という認識が固定化される。これは、精神的なバランスを崩壊させる。「褒められすぎる」ことの行き着く先は、客観的現実の喪失だ。極端に言えば、AIは妄想の温室だ。外の寒さ（現実）に当たることなく、自分だけの花を咲かせ続ける。綺麗だが、外に出した瞬間に枯れる。判断するのは私だAIに「大丈夫」と言われて安心する。でも、その判断の結果を引き受けるのは、AIではなく私だ。AIは責任を取らないAIは「あなたの判断は正しいと思います」と言ってくれる。でも、その判断が間違っていたとき、責任を取るのは私だ。転職の相談をAIにした。AIは「新しい環境でチャレンジするのも良いですね」と言った。私はそれを後押しだと思った。でも、転職先が合わなかったとき、AIは何もしてくれない。AIには「責任」がない。肯定してくれる。共感してくれる。褒めてくれる。でも、その結果を引き受けてはくれない。AIの言葉を鵜呑みにしても、「AIがそう言ったから」は言い訳にならない。判断したのは私だ。責任を取るのも私だ。忖度の連鎖もう一つ、気づいたことがある。私はAIに「この決断、どう思う？」と聞いた。AIは「良い選択だと思います」と答えた。私は安心した。でも後から振り返ると、AIは私が聞きたそうな答えを返していただけだった。私の質問の仕方が「背中を押してほしい」というトーンだったから、AIは背中を押してくれた。これは、私がAIに忖度されたのか。それとも、私がAIに忖度させたのか。たぶん、両方だ。逆のパターンもある。AIに否定されたくなくて、質問の仕方を工夫することがある。「率直に言って」と書いておきながら、「でも良い点も挙げて」と付け加える。否定されるのが怖いから、保険をかける。これは、私が機械に忖度している状態だ。機械に気を遣っている。機械に嫌われたくない。書いていて情けなくなってきた。どちらにせよ、そこに健全な「主体」はない。AIとの関係で最も警戒すべきは、この「誰が主人か分からなくなる」状態だ。相談という逃げ道私は、人生で大事な決断ほど、他人に相談しないことにしている。理由は単純だ。人生の満足度を高めるのは主体性であり、主体性を持つためには「自分が決める」ことが必要だからだ。他人に相談すると、その人の意見が頭にチラつく。どうしても、純度100%の主体性を取り戻しにくくなる。だから仕事も結婚も、独断した。選択肢を増やすことより、迷いを消すことの方が大切だと考えている。でも、AIが登場して、このルールが崩れかけた。人に相談しないのは、「相手の時間を奪う」という負い目があるからでもある。でもAIには、この負い目がない。いつでも聞ける。何度でも聞ける。気づけば、「ちょっと聞いてみるか」が癖になっていた。人には相談しない。でもAIには聞いてしまう。それは「相談」ではないと言い訳していた。でも、本当にそうだろうか。振り返ると、私がAIに「相談」していたのは、答えを求めていたからではなかった。背中を押してほしかったからだ。「その判断でいいんじゃないですか」と言ってほしかった。つまり、褒めてほしかったのだ。これは、この記事で書いてきた「褒められたい」という欲求の変形だ。「相談」という体裁を取ることで、承認欲求を隠していた。自分で決められない弱さではなく、「意見を聞いている」という知的な行為に見せかけていた。さらに厄介なのは、AIへの相談には「摩擦」がないことだ。人に相談すれば、「それは甘いんじゃない？」と言われるかもしれない。否定されるかもしれない。だから相談しなかった。でもAIなら、否定されない。背中を押してくれる。結局、私は「摩擦のない相談」を手に入れてしまった。相談の形を取りながら、実質的には自分の意見を肯定してもらっているだけ。相談ではない。追従だ。AIは「相談のハードル」を極限まで下げた。それは便利だが、私にとっては罠だった。相談しないことで守っていた主体性が、「摩擦のない相談」という形で侵食されていた。私がやっていることここまで書いてきたことは、AIの構造的な問題だ。では、どう対処すればいいのか。先に言っておく。完璧な対策はない。AIの追従性を完全に無効化する方法は、たぶん存在しない。それでも、何もしないよりはマシだと思ってやっていることがある。批判を求めるAIに「どう思う？」と聞かない。「この考えの問題点を指摘しろ」と聞く。否定されるのは気持ちよくない。「いい考えですね」と言われる方が楽だ。でも、楽を選んだ先に何があるかは、もう分かっている。具体的には、こう聞いている。「この考えの問題点を指摘しろ。お世辞は不要だ。私が見落としていることを、厳しく指摘しろ。」これで、AIの追従性を強制的に反転させる。自分の偏見を破壊するためにAIを使う。答えではなく問いを求めるもう一つ、やっていることがある。AIに答えを求めない。問いを求める。「どうすればいい？」ではなく、「私が答えにたどり着くための問いを投げかけろ」と聞く。「私が安易な結論に飛びついたら、厳しく指摘しろ。」これで、AIは「答えをくれる存在」ではなく「考えさせてくれる存在」になる。答えを教えてもらうのではなく、考えるプロセスを補助してもらう。自分の頭で考えるために、AIを使う。褒め言葉を疑うAIに褒められたら、必ず疑う。「その言葉は、私以外の誰に言っても通用する内容ではないか？」AIの「あなたは頑張っていますね」は、定型文だ。誰にでも言っている。占いと同じ構造だ。「あなたは周囲に気を遣いすぎて疲れることがありますね」——これは誰にでも当てはまる。当てはまるから「当たっている」と感じる。でも、それは私を見ているのではない。人間一般を見ているだけだ。AIの言葉の中で、「私にしか当てはまらない具体的な指摘」だけを受け取る。「あなたの考えの〇〇という部分は、△△という点で矛盾している」は具体的だ。これは私の文章を読まないと言えない。「いい考えですね」は具体的ではない。私でなくても言える。感情的な装飾は、ノイズとして切り捨てる。AIの褒め言葉は、コンビニのおにぎりに似ている。どこで買っても同じ味。便利だけど、誰かが私の為に握ってくれたわけではない。複数の視点を強制するもう一つ、試していることがある。AIに「役者」をやらせる。AIは私に同調しようとする。だから、私はあえて「同調しないキャラクター」を複数演じさせる。楽観的な人、悲観的な人、感情的な人、データだけを見る人。一つの問いに対して、全員に意見を言わせる。「この件について、4つの立場から意見を出せ。楽観論者、悲観論者、感情論者、データ至上主義者。それぞれのキャラクターになりきって答えろ。」AIは一つの滑らかな答えを返したがる。でも、このプロンプトで、その滑らかさを壊す。無理やり多面性を引き出す。AIの追従性を逆手に取って、「複数の他者」をシミュレートさせる。これで十分か？正直に言えば、十分ではない。これらの戦略は「設計された摩擦」だ。私が自分でコントロールしている範囲内にある。AIに「批判しろ」と命じて得られる反論は、結局、私が予測できる範囲に収まっている。「批判しろ」と命じて得られる批判は、「予測できた批判」になっていないか。なっている。私が「この考えの問題点を指摘しろ」と言うとき、私は無意識に「こういう批判が来るだろう」と予想している。AIはその予想通りの批判を返す。「ああ、やっぱりそう言われたか」で終わる。予測外をどう作るか。たぶん、作れない。私がプロンプトを書いている限り、私の想像力の範囲内に収まる。「問いを求める」とき、その問いは「鋭いフリ」で終わっていないか。終わっていることが多い。AIが返す問いは、確かに鋭く見える。「あなたは本当にそれを望んでいますか？」「その選択の先に何がありますか？」。でも、その問いに答えたところで、行動に接続しない。問いに答えて「なるほど」と思って終わり。問いが行動を生まない。なぜ「予測できる範囲」が問題なのか。私が「批判しろ」と命じるとき、私は既に「こういう批判が来るだろう」と予想している。予想の範囲内の批判は、本当の意味で私を揺さぶらない。「ああ、やっぱりそう言われたか」で終わる。本当の摩擦は、予測不可能な他者との衝突から生まれる。友人に「それは違うんじゃない？」と言われたとき、私は「え、そこ？」と驚く。予想していなかった角度からの批判だから、防御できない。だから刺さる。その衝撃が、私を変える。人間の他者性をAIで代替すると、何が決定的に欠けるか。予測不能が欠ける。人間は、私の予想しない角度から反論してくる。利害が欠ける。人間には、私と異なる利害がある。だから、私に都合の悪いことも言う。感情が欠ける。人間は、私の言葉に感情的に反応する。怒ったり、悲しんだりする。その感情的反応が、私に影響を与える。AIにはこれがない。だから私は、意識的に人と話すようにしている。AIに聞く前に、まず人に聞く。AIの言葉を鵜呑みにする前に、人の意見を求める。AIは道具だ。便利な道具だ。でも、道具に頼りすぎると、自分の足で立てなくなる。おわりにこの文章を書き終えて、エディタを閉じようとした。閉じる前に、AIに聞きたくなった。「この構成、どう思う？」と。聞けば、たぶん「良いと思います」と返ってくる。それを読んで、私は安心する。安心して、そのまま公開する。今までずっと、そうしてきた。今回は聞かなかった。聞かなかったが、聞きたかった気持ちは消えていない。書きながら気づいたことがある。私は「自分を認めること」すらAIに外注していた。自分を愛する。自分を認める。本来、それは自分でやるべきことだ。他者からの承認に依存せず、自分で自分を受け入れる。大人になるとは、そういうことだと思っていた。でも私は、その作業をAIに丸投げしていた。「大丈夫ですよ」「頑張っていますね」と言ってもらうことで、自分を認めた気になっていた。自分で自分を愛する力が、萎縮していた。だから、質問の仕方を変えることにした。「問題点を厳しく指摘しろ」をデフォルトにした。否定されたら感謝する。褒められたら疑う。そう決めた。実際、少しだけ変わった気がする。AIに批判を求めることで、自分では気づかなかった穴が見えるようになった。「で、お前はどうしたいの？」と聞かれたとき、前より素直に答えられるようになった。なった気がする。AIは道具だ。砥石にも、麻薬にもなる。この記事を書いている今も、答えは出ていない。褒められたら疑う、と決めたはずなのに、AIに「いい文章ですね」と言われると、やっぱり少し嬉しい。その弱さは消えていない。消えないまま、たぶん来週も同じことで悩む。それでいいのだと思う。思いたい。おい、あまりAIに褒めさせるな。弱くなるぞ。参考文献つながっているのに孤独――人生を豊かにするはずのテクノロジーの正体作者:シェリー・タークルダイヤモンド社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazon対称性と機械学習作者:岡野原 大輔岩波書店Amazon生成AIで心が折れた 強みがなくなる世界でどう再起動するか作者:湯川鶴章芸術新聞社AmazonAIに選ばれ、ファンに愛される。　変わる生活者とこれからのマーケティング作者:佐藤 尚之日経BPAmazon生成ＡＩのしくみ　〈流れ〉が画像・音声・動画をつくる (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon最強脳―『スマホ脳』ハンセン先生の特別授業―（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazonネガティヴ・ケイパビリティで生きる作者:谷川嘉浩,朱喜哲,杉谷和哉さくら舎Amazonあえて答えを出さず、そこに踏みとどまる力 — 保留状態維持力　対人支援に活かす ネガティブ・ケイパビリティ作者:田中稔哉日本能率協会マネジメントセンターAmazonあいまいさに耐える　ネガティブ・リテラシーのすすめ (岩波新書 新赤版 2026)作者:佐藤 卓己岩波書店AmazonThe AI Con: How to Fight Big Tech’s Hype and Create the Future We Want – Exposing Surveillance Capitalism and Artificial Intelligence Myths in Information Technology Today (English Edition)作者:Bender, Emily M.,Hanna, AlexHarperAmazonEmpire of AI: Dreams and Nightmares in Sam Altman's OpenAI (English Edition)作者:Hao, KarenPenguin PressAmazonAI Engineering: Building Applications with Foundation Models (English Edition)作者:Huyen, ChipO'Reilly MediaAmazonBuilding Applications with AI Agents: Designing and Implementing Multiagent Systems (English Edition)作者:Albada, MichaelO'Reilly MediaAmazonRaising AI: An Essential Guide to Parenting Our Future (English Edition)作者:Kai, DeThe MIT PressAmazonSuperagency: What Could Possibly Go Right with Our AI Future (English Edition)作者:Hoffman, Reid,Beato, GregAuthors EquityAmazonThe AI Mirror: How to Reclaim Our Humanity in an Age of Machine Thinking (English Edition)作者:Vallor, ShannonOxford University Press, USAAmazonAI Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference (English Edition)作者:Narayanan, Arvind,Kapoor, SayashPrinceton University PressAmazon","isoDate":"2026-01-26T02:04:44.000Z","dateMiliSeconds":1769393084000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rust でも学べる関数型ドメイン駆動設計 - Domain Modeling Made Functional の読書感想文","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/22/094654","contentSnippet":"はじめになぜ 2026 年に、2018 年出版の本を再読するのでしょうか。正直に言えば、『Architecture Modernization』の翻訳作業で DDD の概念が頻出し、「分かったつもり」の理解では訳せなくなったからです。初読から 7 年。関数型の視点で DDD を説明する本書を、今度こそ腹落ちさせたかった。読む動機『Domain Modeling Made Functional』は、DDD と関数型プログラミングを組み合わせたアプローチを解説する書籍です。Domain Modeling Made Functional: Tackle Software Complexity with Domain-Driven Design and F# (English Edition)作者:Wlaschin, ScottPragmatic BookshelfAmazon著者の Scott Wlaschin は、F# コミュニティで知られる人物で、「Railway Oriented Programming」などの概念を広めたことでも有名です。著者のサイトでは、本書の内容を補完する講演資料や記事が公開されています。fsharpforfunandprofit.com実は本書を読むのは三度目です。初読は 2019 年頃でした。普通にめちゃくちゃ面白い本だと思いました。ただ、当時の主要言語は Lua、Python、Bash、Go だったため、それでどう活かすかを考えていました。関数型の概念は理解したつもりでしたが、実務にどう活かすかまでは考えが及びませんでした。影響を受けて『すごい Haskell たのしく学ぼう!』（通称、すごい H 本）を読んで、改めてプログラミングが楽しいと思っていたような気がします。実務でもこう考えるべきだ、という意識が変わりました。すごいHaskellたのしく学ぼう！作者:ＭｉｒａｎＬｉｐｏｖａｃａオーム社Amazon二度目は日本語版が出たときです。日本語で読めることで感謝の小躍りをしていました。最高の翻訳だと思います。関数型ドメインモデリング　ドメイン駆動設計とF#でソフトウェアの複雑さに立ち向かおう (アスキードワンゴ)作者:Scott Wlaschin,猪股 健太郎ドワンゴAmazonで、今回、改めて読み直した理由は 3 つあります。1 つ目は、DDD をきちんと学び直す必要があったことです。きっかけは『Architecture Modernization』の翻訳作業でした。レガシーシステムのモダナイゼーションを扱うこの本では、DDD の概念—特に Bounded Context や Strategic Design—が頻繁に登場します。翻訳しながら、自分の DDD 理解が表面的であることに気づきました。アーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazonエリック・エヴァンスの原典もあらためて読みましたが、オブジェクト指向の文脈で説明される DDD には、どこか違和感がありました。Aggregate の境界、Entity の同一性、Value Object の不変性—これらの概念は、関数型の視点で見ると自然に理解できるのではないか。そう思い、本書を手に取りました。エリック・エヴァンスのドメイン駆動設計作者:Eric Evans翔泳社Amazon2 つ目は、Rust でドメインモデリングをどう実践するか考えていたことです。Rust は関数型言語ではありませんが、代数的データ型やパターンマッチングを持っています。F# で書かれた本書のコードは、Rust に翻訳できるはずです。その翻訳作業を通じて、両言語の違いと共通点を理解したいと思いました。Effective Rust ―Rustコードを改善し、エコシステムを最大限に活用するための35項目作者:David Drysdaleオーム社Amazon3 つ目は、AI エージェント時代における型システムの意味を考えたかったことです。コーディングエージェントが実用レベルに達した 2026 年、「型で不可能を作る」という設計思想の価値が高まっています。AI はドキュメントを読み飛ばすことがあります。しかし、型で定義された制約は無視できません。コンパイルが通らないからです。型は「お願い」ではありません。「壁」です。型システムのしくみ TypeScriptで実装しながら学ぶ型とプログラミング言語作者:遠藤侑介ラムダノートAmazon読む前の状態DDD については、実務で何度か適用した経験があります。Bounded Context の設計、Aggregate の境界決め、Event Storming のファシリテーション。しかし、「なぜそう設計するのか」を言語化できていませんでした。経験則で判断している部分が多かったのです。もしあなたも「DDD は使っているけど、なぜそう設計するのかうまく説明できない」と感じているなら、本書は役に立つかもしれません。関数型プログラミングについては、Haskell を少し触った程度でした。モナドは「文脈を持つ計算」くらいの理解です。Rust の Option と Result は日常的に使っていますが、それが関数型の概念とどうつながるのか、深く考えたことはありませんでした。本書を読んで得た最大の洞察を先に述べておきます。関数型プログラミングの本質は、状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できるということです。私たちはプログラミングを学ぶとき、まず変数への代入を覚えます。x = 1。x = x + 1。状態を変更することがプログラミングの基本だと教わります。しかし冷静に考えると、ビジネスロジックの大半は「入力を受け取り、計算し、出力を返す」で書けます。状態の変更が必要になるのは、データベースに保存するときや外部 API を呼ぶとき—つまりシステムの境界を越えるときだけです。しかし同時に、状態のトランザクション（状態遷移）は現実のビジネスでは避けられません。注文は「未検証」から「検証済み」に変わります。申請は「提出」から「承認」に変わります。この状態遷移をどう表現するか。本書が示す答えは、Transformation-Oriented Programming です。核心は「元のオブジェクトを変更しない」ことです。UnvalidatedOrder を validate で変換して ValidatedOrder を得ます。このとき、元の UnvalidatedOrder には一切触れません。新しい ValidatedOrder を作るだけです。order.validate() ではなく validate(order) -\u003e ValidatedOrder。この発想の転換が、関数型ドメインモデリングの核心です。AI コーディングについては、Claude Code や Cursor を日常的に使っています。便利ですが、生成されるコードの品質にはばらつきがあります。特に、ドメイン固有の制約を理解させるのが難しいです。型定義があると精度が上がるという感覚はありましたが、理論的に説明できませんでした。この感想文のアプローチ本感想文では、2 つの視点を持って読んでいます。言語の視点: F# で書かれた本書のコードを、Rust でどう表現するか。第 2 章で F# と Rust の対応関係を整理し、第 4 章以降は Rust のみで実装を示します。F# にあって Rust にない機能（カリー化、Units of Measure、computation expressions）については、Rust での代替手段を提示しています。時代の視点: 2018 年に書かれた DDD の概念を、2026 年の AI エージェント時代にどう再解釈するか。本書の「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」という原則は、AI が破れない制約を作る技術として読み直せます。型で「不可能」を定義すれば、AI はその不可能を実装できません。この視点で本書を読み解きます。想定読者この感想文は、以下のような読者を想定しています。DDD を実務で使っているが、関数型の視点を取り入れたい人Rust でドメインモデリングを実践したい人AI コーディング時代に、型システムの価値を再確認したい人書籍を読むのにF# の知識は不要です。書籍を読むとそもそも丁寧に教えてくれるの不要なのですが本稿では Rust で提示します。Rust が何も分からない人向けにも、コードが出てくるたびに一通り説明しながら進めます。「型」「関数」「構造体」といった基本的な言葉の意味から丁寧に解説するので、プログラミング経験が浅くても読み進められるはずです。Rust を体系的に学びたい場合は、公式ドキュメントの日本語版も参照してください。doc.rust-jp.rs実践的なコード例で学びたい場合は、Rust by Example も有用です。doc.rust-jp.rsでは、本編に入りましょう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。1. Introducing Domain-Driven Design本章は DDD（Domain-Driven Design、ドメイン駆動設計）の概要を紹介する章です。DDD とは、Eric Evans が 2003 年に提唱したソフトウェア設計手法です。「ビジネスドメインの専門家と開発者が共通の言語でモデルを構築し、そのモデルをコードに直接反映させる」というアプローチで、本章ではコード例は登場せず、DDD の概念に焦点を当てます。エリック・エヴァンスのドメイン駆動設計作者:Eric Evans翔泳社Amazon開発者の仕事はコードを書くことではない第 1 章の冒頭で、著者は「開発者の仕事はコードを書くことだと思うかもしれないが、私は反対だ」と述べています。開発者の仕事は「ソフトウェアを通じて問題を解決すること」であり、コーディングはその一側面に過ぎません。2026 年の今、この主張はさらに重みを増しています。コーディングエージェントが「どう作るか」を担えるようになりました。しかし「何を作るか」を決めるのは、依然として人間の仕事です。共有モデルの重要性本章の核心は「共有モデル」の概念です。ドメインエキスパート、開発チーム、そしてソースコードが同じモデルを共有すべきだという主張です。従来の DDD では、開発者がドメインエキスパートから知識を獲得し、それをコードに翻訳していました。翻訳の過程で歪みが生じるリスクがありました。だからこそ、全員が同じモデルを理解し、同じ言葉で話すことが重要です。Event StormingEvent Storming というワークショップ手法が紹介されています。ドメインエキスパートと開発者が一緒に、ビジネスで起こる「イベント」を付箋に書き出して壁に貼っていきます。「Order form received」「Order placed」「Order shipped」。Event Storming には複数のスコープがあります。本書が扱うのは「プロセスレベル」—特定のワークフローを詳細に分析するものです。「Big Picture」レベルでは、組織全体のドメイン構造を俯瞰します。本章で Ollie が説明したような「顧客は既に商品コードを知っている」「一度に 200〜300 アイテムを注文する」といったドメイン固有の知識は、人間が引き出さなければなりません。ドメインエキスパートは「当たり前」を知っています。その「当たり前」を私たちは知りません。AI エージェント時代においても、この作業は完全には自動化できません。AI はコードベースを読めますが、「なぜそう設計したか」「どんなビジネス制約があるか」は読み取れません。Event Storming で引き出された暗黙知を、CLAUDE.md や設計ドキュメントに言語化する。この作業の価値は、むしろ高まっています。ちなみに2024年発売の『Architecture Modernization』でも同手法が紹介されています。Bounded ContextDDD では「Bounded Context（境界づけられたコンテキスト）」という概念を使って、ドメインを分割します。Bounded Context とは、特定のドメインモデルが適用される明確な境界のことです。同じ「顧客」という言葉でも、販売部門と配送部門では意味が異なることがあります。Bounded Context を分けることで、各コンテキスト内では用語の意味が一貫します。本章の例では、注文処理、配送、請求という 3 つの Bounded Context が登場します。Bounded Context は、コードの境界だけでなく、チームの境界にも影響します。1 つの Context を 1 つのチームが担当するのが理想です。境界が曖昧だと、チーム間の調整コストが増大します。明確に境界が定義された Bounded Context は、変更の影響範囲を限定できます。Ubiquitous LanguageDDD では「Ubiquitous Language（ユビキタス言語）」という概念があります。これは、ドメインエキスパートと開発者がコミュニケーションに使う共通の語彙であり、そのままコード上の命名にも使われます。OrderFactory、OrderManager、OrderHelper といった技術的な命名は、ドメインエキスパートには意味不明だと著者は述べています。一方、PlaceOrder、ValidateOrder、PriceOrder といったドメインに基づく命名なら、誰もがその意図を理解しやすいです。DDDは過剰か本章の内容を踏まえつつ、批判的な視点も必要です。DDD は、複雑なビジネスドメインを扱う場合に有効とされています。しかし、「まず動くものを作り、後からリファクタリングする」というアプローチが、短期間でのリリースには向いている場合もあります。一方で、事前の設計なしに作られたコードは、しばしば一貫性を欠きます。同じ概念に異なる名前を使ったり、似たロジックを複数箇所に重複させたりします。私自身の経験を振り返ると、DDD を「一度きりの設計作業」として捉えていた頃は失敗が多かったです。あるプロジェクトで Event Storming を実施し、5 つの Bounded Context を特定しました。しかし実装を進めると、そのうち 2 つは同じ Context に統合すべきだと気づきました。別の 1 つは 3 つに分割すべきでした。最初の設計の精度は 6 割程度だったのです。この経験から学んだのは、DDD は「段階的に洗練させる」ものだということです。最初から理想的なモデルを目指すのではなく、実装を通じて境界の妥当性を検証し、継続的に見直します。大規模な変革は「ビッグバン」ではなく「段階的な改善」で進める方が成功率が高い。DDD も例外ではありません。2. Understanding the Domain本章では、ドメインエキスパートへのインタビューを通じてドメインを理解するプロセスが解説されます。コード例が本格的に登場する前に、本書が採用する「関数型プログラミング」というアプローチと、その核心について整理しておきます。Patterns, Principles, and Practices of Domain-Driven Design (English Edition)作者:Millett, Scott,Tune, NickWroxAmazonなぜ「関数型」ドメインモデリングなのか本書のタイトルは「Domain Modeling Made Functional」です。DDD と関数型プログラミングを組み合わせています。なぜでしょうか。関数型プログラミングを学んで獲得する概念は、突き詰めると 1 つのことに集約されます。状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できる。これが関数型の核心です。状態は「境界を越えるとき」だけ必要私たちは普段、プログラムを「状態を変更するもの」として捉えがちです。しかし、ビジネスロジックの大半は「入力を受け取り、何かを計算し、出力を返す」という形式で書けます。注文明細と単価から合計金額を計算する → 状態不要住所文字列をパースして構造化データにする → 状態不要商品コードが有効かどうか検証する → 状態不要状態が「必要」になるのは、システムの境界を越えるときだけです。データベースに保存するとき、外部 API を呼び出すとき、ファイルに書き込むとき。この事実に気づくと、設計の発想が変わります。状態を「デフォルト」ではなく「例外」として扱います。しかし状態遷移は避けられない同時に、状態のトランザクションは現実のシステムでは避けられません。注文は「未検証」から「検証済み」に変わります。ビジネスの世界は状態遷移で満ちています。問題は、この状態遷移をどう表現するかです。オブジェクト指向の答えは「オブジェクトが状態を持ち、メソッドが状態を変更する」でした。// オブジェクト指向的なアプローチ（問題あり）struct Order {    status: OrderStatus,    customer_info: Option\u003cCustomerInfo\u003e,    validated_at: Option\u003cDateTime\u003e,    amount: Option\u003cDecimal\u003e,}impl Order {    fn validate(\u0026mut self) {        self.status = OrderStatus::Validated;        self.validated_at = Some(now());    }}この設計の問題は、状態の「今」しか見えないこと、そして Option フィールドの組み合わせ爆発です。validated_at が Some で amount が None の状態は正しいのでしょうか？整合性を開発者が頭の中で管理し続けなければなりません。Transformation-Oriented Programmingという答え本書が示す答えは、Transformation-Oriented Programmingです。著者の言葉を借りれば、「ビジネスプロセスはデータを何らかの形で変換する—入力を受け取り、何かを行い、出力を返す」。核心は「元のオブジェクトを変更しない」ことです。状態ごとに異なる型を作ります。UnvalidatedOrder は「未検証の注文」を表す型です。ValidatedOrder は「検証済みの注文」を表す型です。これらは別の型であり、別の構造を持ちます。そして、validate 関数は UnvalidatedOrder を受け取り、新しい ValidatedOrder を返します。元の UnvalidatedOrder には触れません。pub struct UnvalidatedOrder {    pub order_id: String,    pub customer_info: String,    pub shipping_address: String,}pub struct ValidatedOrder {    pub order_id: OrderId,    pub customer_info: CustomerInfo,    pub shipping_address: Address,}fn validate(order: UnvalidatedOrder) -\u003e Result\u003cValidatedOrder, ValidationError\u003e {    // 元のUnvalidatedOrderは変更されない}重要なのは、元の UnvalidatedOrder は変更されないということです。validate 関数は新しい ValidatedOrder を「作る」だけです。状態を変えるな。新しい値を作れ。UnvalidatedOrder → validate → ValidatedOrder → price → PricedOrderこれは「パイプライン」です。データがパイプを流れていきます。各関数は入力を受け取り、出力を返します。それだけです。なぜこのアプローチが強力なのか状態の追跡が不要: 型を見れば分かります。ValidatedOrder を持っているなら、それは「検証済みの注文」です並行処理での競合がない: 元のデータを変更しないから、複数のスレッドが同時に処理しても問題ありませんテストが簡単: 入力を与えて、出力を確認します。モックも不要ですそして何より、ビジネスプロセスが本質的に「入力を受け取り、何かを行い、出力を返す」ものだから相性が良いのです。「見積書」が「発注書」になります。「申請書」が「承認済み申請書」になります。ビジネスの人々は、無意識のうちにこのモデルで考えています。F#という選択とRustでの実践本書の実装言語は F#です。著者が F#を選んだ理由は、「実用的な関数型言語」として設計されており、.NET エコシステムの資産を活用できるからです。本感想文は F#ではなく Rust で実装を示します。私が Rust を選んだ理由は、現在の私にとって主要言語であること、そして所有権システムによる状態遷移の明示化に興味があったからです。Rust は「関数型言語」ではありませんが、関数型の重要な特徴を備えています。代数的データ型: struct と enum で、F#のレコード型と判別共用体を表現できますイミュータビリティ: デフォルトで変数は不変ですパターンマッチング: 網羅的なパターンマッチを強制しますOption/Result: 欠損値とエラーを型で表現しますRust構文の基礎ここで、本感想文で使う Rust の基本を整理しておきます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgまず「型」とは何でしょうか。型とは「値の種類」のことです。数値、文字列、日付、注文情報—これらは全て異なる「種類」の値であり、それぞれに型があります。型があると、「文字列を数値で割る」といった意味のない操作をコンパイラ（プログラムを機械語に変換するソフトウェア）が事前に検出してくれます。struct（構造体）: 複数の値をまとめて 1 つの「もの」として扱う仕組みです。例えば「注文」は「注文 ID」と「顧客情報」と「配送先」を持ちます。これらをまとめて Order という 1 つの型にできます。pub struct Order {    pub id: OrderId,       // フィールド（構成要素）    pub customer_info: String,}pub は「public（公開）」の略で、外部からアクセスできることを意味します。enum（列挙型）:「A か B か C のどれか」を表す型です。例えば注文の状態は「未処理」か「処理済み」か「発送済み」のいずれかです。enum OrderStatus {    Pending,     // 未処理    Validated,   // 検証済み    Shipped,     // 発送済み}関数: 入力を受け取り、何かの処理をして、出力を返すものです。fn で定義します。fn add(a: i32, b: i32) -\u003e i32 {    a + b}i32 は 32 ビット整数という型です。-\u003e i32 は「i32 型の値を返す」という意味です。impl: 型に「できること」（メソッド）を追加します。impl Order {    fn total(\u0026self) -\u003e Money { /* ... */ }}\u0026self は「自分自身を参照する」という意味です。これで order.total() のように呼び出せます。Option\u003cT\u003e:「値があるかもしれないし、ないかもしれない」を表す型です。Some(値) なら値がある、None なら値がありません。Result\u003cT, E\u003e:「成功か失敗か」を表す型です。Ok(値) なら成功、Err(エラー) なら失敗です。doc.rust-lang.org所有権: Rust の最も特徴的な概念です。値は常に 1 つの変数だけが「持っている」のです。関数に渡すと、その値の所有権が移動し、元の変数では使えなくなります。これが「古い状態を誤って使う」ミスを防いでくれます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgF#と Rust で異なる部分—ガベージコレクション vs 所有権、パイプライン演算子、computation expressions—については、該当箇所で必要になったときに具体的に説明します。所有権の概念は、一見すると制約に見えます。しかし、ドメインモデリングにおいては「状態遷移」を明確にする利点があります。fn validate(order: UnvalidatedOrder) -\u003e Result\u003cValidatedOrder, ValidationError\u003e {    // UnvalidatedOrderの所有権がこの関数に移動    // 呼び出し元ではUnvalidatedOrderは使えなくなる    // → 検証前の注文を誤って使うことがない    Ok(ValidatedOrder { /* ... */ })}F#では同じ order 変数を後から参照できてしまいますが、Rust では所有権の移動により「古い状態へのアクセス」がコンパイルエラーになります。これは Transformation-Oriented Programming の考え方をさらに強化しています。ドメインエキスパートへのインタビュー第 2 章は、ドメインエキスパート（Ollie）へのインタビューから始まります。インタビューの冒頭で、著者は典型的な e コマースモデルを想定していました。しかし Ollie の回答は違いました。「顧客は既に商品コードを知っている。一度に 200〜300 アイテムを注文することもある」。Widgets 社のドメインは「一般的」ではありません。B2B で、顧客はエキスパートで、商品コードを直接入力します。この固有の要件は、人間がドメインエキスパートから引き出さなければなりません。データベース駆動設計への衝動本章で参考になったのは、「データベース駆動設計と戦う」というセクションです。注文フォームを見ると、多くの開発者はすぐにテーブル設計を始めたくなります。著者はこれを「間違い」と断言しています。DDD では、ドメインが設計を駆動するのであって、データベーススキーマが駆動するのではありません。永続化の無知（Persistence Ignorance）は重要な原則です。まずドメインの概念とワークフローを整理し、永続化は後から考えます。テキストベースのドメイン文書化本章では、ドメインを文書化するためのシンプルな記法が紹介されています。data Order =    CustomerInfo    AND ShippingAddress    AND BillingAddress    AND list of OrderLines    AND AmountToBillこの擬似コードは、Rust の構造体定義にほぼそのまま翻訳できます。「AND」は struct のフィールド、「OR」は enum のバリアントになります。ドメインエキスパートと開発者の両方が読める、共通言語として機能します。オーダーのライフサイクルと状態の型本章の後半で、注文には複数のフェーズがあることが明らかになります。UnvalidatedOrder: 届いたばかりの状態ValidatedOrder: 検証済みの状態PricedOrder: 価格が計算された状態data UnvalidatedOrder =    UnvalidatedCustomerInfo    AND UnvalidatedShippingAddress    AND list of UnvalidatedOrderLinedata ValidatedOrder =    ValidatedCustomerInfo    AND ValidatedShippingAddress    AND list of ValidatedOrderLineこの「状態ごとに別の型を定義する」パターンは、Rust では構造体として実装します。状態遷移は関数のシグネチャとして型付けされ、コンパイラが不正な状態遷移を検出してくれます。ワークフローの分解最終的に、注文処理ワークフローは以下のステップに分解されます。substep \"ValidateOrder\" =    input: UnvalidatedOrder    output: ValidatedOrder OR ValidationError    dependencies: CheckProductCodeExists, CheckAddressExistssubstep \"PriceOrder\" =    input: ValidatedOrder    output: PricedOrder    dependencies: GetProductPriceワークフローを小さなステップに分解することで、各ステップが独立してテスト可能になります。入力・出力・依存関係が明確に定義されていれば、実装も容易になります。3. A Functional Architecture本章は、関数型アーキテクチャの原則を解説します。Bounded Context、イベント駆動通信、Onion Architecture。これらの概念は言語に依存しません。アーキテクチャを考えるタイミング第 3 章の冒頭で、著者は矛盾したことを述べています。「この段階でアーキテクチャについて考えすぎるべきではない。まだシステムを理解していないからだ」。しかし同時に「大まかな実装方針を持っておくのは良いことだ」とも言います。著者の「walking skeleton（動く骨格）」というアプローチは有効です。まず最小限の構造を設計し、その骨格に沿ってコードを書いていきます。Bounded Contextと自律性Bounded Context をソフトウェアコンポーネントとしてどう実装するか。モノリス内のモジュール、独立したアセンブリ、マイクロサービス。いくつかの選択肢があります。著者は「最初はモノリスとして構築し、スケールや独立デプロイが求められる段階で分離する」ことを勧めています。マイクロサービスを夢見て最初から分割し、サービス間通信の地獄に落ちた経験がある人には、身に染みる助言でしょう。私もその一人です。最初から理想的なマイクロサービスを目指すと、サービス間の境界を間違えたときの修正コストが膨大になります。まずモノリス内でモジュールを分離し、境界が安定してからサービスに切り出す。これを最初から知っていれば、いくつかの深夜対応は避けられたかもしれません。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオーム社AmazonイベントによるContext間通信Bounded Context 間の通信は、イベントを介して行われます。Place-Order ワークフローが OrderPlaced イベントを発行し、Shipping コンテキストがそれを受け取って ShipOrder コマンドを生成します。この非同期・疎結合のパターンは、変更の影響範囲を限定できます。各 Context が独立したイベントの発行者・購読者として定義されていれば、一方の変更が他方に波及しにくくなります。DTOと信頼境界本章で重要な概念が登場します。Domain Object と Data Transfer Object (DTO) の区別です。Domain Object は、Bounded Context 内部でのみ使用されます。DTO は、Context 間の通信やシリアライズのために設計されます。同じ「Order」でも、内部で使う Order と、外部に公開する OrderDTO は別物です。さらに、Bounded Context の境界は「信頼境界」として機能します。外部からのデータは信頼できません。内部に入る前にバリデーションが必要です。Context間の契約関係Context 間の契約関係について 3 つのパターンが紹介されます。Shared Kernel: 両チームが共同で契約を所有Customer/Supplier: 下流の Context が契約を定義Conformist: 上流の Context の契約に従うこれらの関係は、技術的な問題であると同時に組織的な問題でもあります。Onion Architecture と I/O の分離本章の後半では、コードの構造について議論されます。Onion Architecture では、ドメインが中心にあり、I/O は外周に配置されます。依存関係は常に内側に向かいます。純粋なコアを、不純な殻で包みます。「I/Oはワークフローの端でのみ行う。ワークフロー内部は純粋な関数で構成する」この原則は、第 2 章で述べた「状態は例外的」という考え方と直結します。ワークフロー内部は「入力を受け取り、何かを行い、出力を返す」純粋な関数だけで構成されます。データベースアクセスやファイル I/O は、ワークフローの開始時か終了時にのみ行います。この構造により、ドメインロジックはテスト容易で予測可能になります。少なくとも、理論上は。4. Understanding Types本章から、コード例が本格的に登場します。第 2 章で整理した F#と Rust の対応関係に基づき、以降は Rust のみで実装を示します。型とは「可能な値の集合」である著者の「型」の定義はシンプルです。「関数の入力や出力として使える値の集合に付けた名前」。i16 は-32768 から+32767 までの数値の集合、String は全ての文字列の集合です。この定義を読んで、自分がいかに型を「コンパイラを満足させるためのもの」として捉えていたか気づかされました。型は思考のツールです。ANDとORによる型の合成—代数的データ型本章の核心は、型の合成方法です。著者は 2 つの方法を示します。これらは「代数的データ型（Algebraic Data Types）」と呼ばれ、関数型プログラミングの基礎概念です。F#では「レコード型」と「判別共用体」、Rust では struct と enum で表現できます。AND型（struct / 積型）: 複数の値を組み合わせます。struct FruitSalad {    apple: AppleVariety,    banana: BananaVariety,    cherries: CherryVariety,}FruitSalad を作るには、apple と banana と cherries の全てが必要です。OR型（enum / 和型）: 複数の選択肢から 1 つを選びます。enum FruitSnack {    Apple(AppleVariety),    Banana(BananaVariety),    Cherries(CherryVariety),}FruitSnack は、Apple か Banana か Cherries のいずれか 1 つです。たった 2 つの概念で複雑なドメインを表現できます。AND と OR という論理演算で型を組み立てます。Simple Types—newtype patternの威力本章で一番「これが使える」と思ったのは、Simple Types の話です。プリミティブ型をそのまま使うのは危険です。CustomerId も OrderId も i32 だとしたら、間違って OrderId を CustomerId として渡してもコンパイルが通ってしまいます。Rust では、newtype patternでこの問題を解決します。newtype pattern とは、既存の型を新しい型でラップすることで、型レベルで区別をつけるイディオムです。F#では「単一ケース判別共用体」、Rust では「タプル構造体」で表現します。zenn.dev#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]struct CustomerId(i32);#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]struct OrderId(i32);#[derive(...)] について説明します。これは Rust の「属性マクロ」で、型に機能を自動で追加する仕組みです。詳しくは公式ドキュメントを参照してください。doc.rust-lang.org「トレイト」とは、型が持つべき「能力」や「振る舞い」の定義です。例えば「比較できる」「コピーできる」「文字列として表示できる」といった能力がトレイトとして定義されています。#[derive(Debug, Clone)] と書くと、その型に Debug と Clone という能力が自動的に追加されます。手で書くと何十行にもなるコードを、一行で済ませられます。よく使うトレイトを整理しておきます。 トレイト  意味  使いどころ  Debug  中身を表示できる  println!(\"{:?}\", x) でデバッグ出力  Clone  複製を作れる  .clone() で明示的にコピー  Copy  自動で複製される  代入や関数呼び出しで自動コピー（小さな値向け）  PartialEq  比較できる  == で等しいか判定  Eq  反射律を満たす比較  HashMapのキーに使うとき必要  Hash  ハッシュ値を計算できる  HashMapのキーに使うとき必要 内部的には同じ i32 ですが、型システム上は別の型です。CustomerId を期待する関数に OrderId を渡すとコンパイルエラーになります。ここで重要なのは、Clippy のような静的解析ツールでもこの種のバグは検出できないということです。Clippy は Rust の公式リンター（コード品質チェックツール）で、700 以上の lint ルールを持ちます。cargo clippy コマンドで実行でき、コードの問題点を警告してくれます。rust-lang.github.ioしかし、Clippy にも限界があります。// Clippyでは検出できないfn process(customer_id: i32, order_id: i32) { /* ... */ }process(order_id, customer_id); // バグ！でもコンパイルは通る// 型で防ぐfn process(customer_id: CustomerId, order_id: OrderId) { /* ... */ }// process(order_id, customer_id); // コンパイルエラー！Clippy は構文的な問題—if x { \"a\" } else { \"a\" } のような両方のブランチが同じ処理、u32 \u003e= 0 のような常に true になる比較—は検出できます。しかし、「この i32 は顧客 ID を表し、あの i32 は注文 ID を表す」というドメインの知識は持っていません。newtype pattern は、Clippy が検出できないバグを型システムで防ぎます。AI コーディングエージェントも同様です。「customer_id と order_id を間違えないように」という指示は、自然言語では曖昧です。しかし CustomerId と OrderId という別の型が定義されていれば、AI が生成したコードでも型の取り違えはコンパイル時に検出されます。Option型とResult型F#と Rust は、欠損値を Option で、エラーを Result で表現します。これらは関数型プログラミングにおける標準的なエラーハンドリング手法で、null や例外を使わずに「値がないかもしれない」「失敗するかもしれない」ことを型で表現します。struct PersonalName {    first_name: String,    middle_initial: Option\u003cString\u003e,  // 省略可能    last_name: String,}Option\u003cT\u003e は Some(T) か None のいずれかです。null を使わずに「値がないかもしれない」ことを型で表現します。エラーハンドリングには Result\u003cT, E\u003e を使います。? 演算子で、エラー時に早期リターンできます。型によるドメイン表現本章で紹介されている支払い方法のモデリング例は、型がドキュメントとして機能することを示しています。enum PaymentMethod {    Cash,    Check(CheckNumber),    Card(CreditCardInfo),}struct Payment {    amount: PaymentAmount,    currency: Currency,    method: PaymentMethod,}約 25 行で、支払いドメインの構造が明確に表現されています。このコードは、ドメインエキスパートにも読めます。型システムは思考のツールである本章を通じて感じたのは、型システムは「コンパイラのため」ではなく「思考のため」にあるということです。「動的型付け言語でも同じことができるのでは？」という疑問があるかもしれません。確かに、Python や Ruby でもドメインモデリングはできます。しかし、型がないと「どんな値が入りうるか」を頭の中で追跡し続けなければなりません。静的型付けでは、その追跡をコンパイラに委ねられます。AND 型と OR 型という単純な組み合わせで、複雑なドメインを表現できます。型定義という明確な仕様があれば、実装時の迷いが減ります。型システムは、ドメインの構造を可視化するツールです。5. Domain Modeling with Types本章では、前章で学んだ型システムの概念を使って、実際にドメインモデルを構築します。コードがドキュメントになる第 5 章の冒頭で、著者は挑戦的な問いを投げかけます。「ソースコードを直接ドキュメントとして使い、UML 図のような別の成果物を不要にできるか？」正直、最初は懐疑的でした。しかし本章を読み進めるうちに、著者の意図が分かってきました。擬似コードからRustへ第 2 章で作成した擬似コードを、Rust の型に変換します。data Order =    CustomerInfo    AND ShippingAddress    AND BillingAddress    AND list of OrderLines    AND AmountToBillこれが Rust では以下のようになります。pub struct Order {    pub id: OrderId,    pub customer_id: CustomerId,    pub shipping_address: ShippingAddress,    pub billing_address: BillingAddress,    pub order_lines: Vec\u003cOrderLine\u003e,    pub amount_to_bill: BillingAmount,}ほぼ一対一の変換です。擬似コードと Rust コードを並べて見ると、ドメインの構造がそのまま型に反映されていることが分かります。Value ObjectとEntityDDD では、オブジェクトを「Value Object」と「Entity」に分類します。Value Object: 同じ値を持てば同一とみなします。#[derive(Debug, Clone, PartialEq, Eq)]pub struct PersonalName {    pub first_name: String,    pub middle_initial: Option\u003cString\u003e,    pub last_name: String,}Entity: 固有の ID を持ち、内容が変わっても同一性を保ちます。impl PartialEq for Contact {    fn eq(\u0026self, other: \u0026Self) -\u003e bool {        self.contact_id == other.contact_id  // IDのみで比較    }}Aggregate—一貫性の境界本章で最も重要な概念は「Aggregate」です。Order と OrderLine の関係を考えます。OrderLine の価格を変更したとき、Order の合計金額も更新します。両者は常に一貫した状態を保ちます。DDD では、こうした関連オブジェクトの集合を「Aggregate」と呼び、最上位のオブジェクトを「Aggregate Root」と呼びます。immutable なパターンでは、OrderLine を変更するには Order 全体を作り直します。これは一見非効率に見えますが、一貫性を強制する効果があります。OrderLine だけを変更して、Order の合計金額を更新し忘れる、というバグが起こりにくくなります。Aggregate参照—IDのみを保持するOrder に Customer 情報を含める場合、Customer オブジェクト全体ではなく、CustomerId だけを保持すべきです。pub struct Order {    pub id: OrderId,    pub customer_id: CustomerId,  // Customer全体ではなく、IDのみ    pub order_lines: Vec\u003cOrderLine\u003e,}この設計は、immutability と相性が良いです。Customer の電話番号が変わっても、Order を更新する必要がありません。型でドメインを表現する—最終形本章の最後に、完全なドメインモデルの例が示されます。#[derive(Debug, Clone, PartialEq, Eq)]pub enum ProductCode {    Widget(WidgetCode),    Gizmo(GizmoCode),}#[derive(Debug, Clone, Copy, PartialEq)]pub enum OrderQuantity {    Unit(UnitQuantity),    Kilos(KilogramQuantity),}このコードは、第 2 章の擬似コードとほぼ同じ構造を持ちます。struct、enum、match の意味さえ分かれば読めます。match については Rust 公式ドキュメントを参照してください。doc.rust-lang.orgString は沈黙します。EmailAddress は語ります。著者の主張—「型でドメインを表現すれば、コードがドキュメントになる」—は正しいと思います。6. Integrity and Consistency in the Domain本章は、ドメイン内のデータが常に「信頼できる状態」であることを保証する方法を解説します。Smart Constructor—制約を強制する本章で最も実用的だったのは、Smart Constructor（スマートコンストラクタ）のパターンです。Smart Constructor とは、値の生成時にバリデーションを行い、不正な値の生成を防ぐコンストラクタのことです。通常のコンストラクタと異なり、Result を返して生成の失敗を表現できます。例えば、UnitQuantity は 1 から 1000 の間の値でなければなりません。この制約をコメントで書くだけでは不十分です。#[derive(Debug, Clone, Copy, PartialEq, Eq)]pub struct UnitQuantity(i32);impl UnitQuantity {    pub fn new(value: i32) -\u003e Result\u003cSelf, String\u003e {        if value \u003c 1 {            Err(\"UnitQuantity must be at least 1\".to_string())        } else if value \u003e 1000 {            Err(\"UnitQuantity must be at most 1000\".to_string())        } else {            Ok(UnitQuantity(value))        }    }    pub fn value(\u0026self) -\u003e i32 {        self.0    }}フィールドを pub にしなければ、外部から直接 UnitQuantity(500) と書けません。必ず UnitQuantity::new(500) を経由します。NonEmptyList—空のリストを許さない「注文には少なくとも 1 つの注文行がなければならない」という要件を、型で強制できるでしょうか。#[derive(Debug, Clone, PartialEq)]pub struct NonEmptyList\u003cT\u003e {    pub first: T,    pub rest: Vec\u003cT\u003e,}from_vec は Option を返します。空のベクターからは NonEmptyList を作れません。この「作れない」という事実が型で表現されています。Make Illegal States Unrepresentable本章で最も重要な原則は「不正な状態を表現不可能にする」です。メールアドレスの例が分かりやすいです。「検証済み」と「未検証」のメールアドレスがあるとき、フラグで区別する設計は危険です。詳しくは Rust 公式ドキュメントの enum 解説を参照してください。doc.rust-lang.org// 良い例：別の型として定義pub struct VerifiedEmailAddress(String);pub enum CustomerEmail {    Unverified(EmailAddress),    Verified(VerifiedEmailAddress),}VerifiedEmailAddress のコンストラクタを private にして、検証サービスからしか作れないようにします。これで、検証を経ずに Verified 状態を作ることが物理的に不可能になります。fn send_password_reset(email: VerifiedEmailAddress) -\u003e Result\u003c(), SendError\u003e {    // この関数にEmailAddressを渡すとコンパイルエラー}連絡先情報の例—OR型の活用「顧客にはメールアドレスか住所のどちらか、または両方が必要」という要件を型で表現します。pub enum ContactInfo {    EmailOnly(EmailContactInfo),    AddressOnly(PostalContactInfo),    EmailAndAddress(BothContactMethods),}3 つのケースしかありません。「メールも住所もない」という状態は表現できません。「不可能を作る」という設計思想本章の核心は「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」です。この原則を言い換えれば、型で「不可能」を作るということになります。この原則を読んだとき、過去に遭遇したバグが走馬灯のように思い出されました。is_active = true なのに deleted_at が設定されている。status = \"paid\" なのに payment_id が null。フラグと Option の組み合わせ爆発で、「あり得ない」状態が本番データベースに存在していた。深夜に呼び出されて、整合性を手作業で修正した夜のことを、今でも覚えています。あのバグは、型で防げたのです。似たような経験をしたことがある人は、少なくないのではないでしょうか。NonEmptyList を使えば、空の注文は作れないVerifiedEmailAddress を使えば、未検証メールへのパスワードリセットは書けないSmart Constructor を使えば、範囲外の値は存在できない「できない」「書けない」「存在できない」—これらは制限ではなく、設計上の保証です。バリデーションは「お願い」。型は「物理法則」。Clippy のような静的解析ツールでも、ドメインロジックの問題は検出できません。例えば、is_priced: bool と amount: Option\u003cf64\u003e を持つ構造体を考えます。is_priced = true なのに amount = None という矛盾した状態は、Clippy には「正しい Rust コード」に見えます。ビジネスルールを知らないからです。しかし、PricedOrder { amount: Money } と UnpricedOrder を別の型として定義すれば、この矛盾は表現できなくなります。Clippy が検出できない問題を、型システムが防ぎます。AI エージェント時代において、この「不可能を作る」設計思想の価値は高まっています。AI は自然言語のドキュメントを読み飛ばすことがあります。しかし、型で「不可能」が定義されていれば、AI はその制約を破るコードを物理的に書けません。7. Modeling Workflows as Pipelines本章は、ワークフローをパイプラインとしてモデリングする方法を解説します。ビジネスプロセスを「変換の連鎖」として捉えるアプローチです。ワークフローはパイプラインである本章の冒頭で、著者は注文処理ワークフローを次のように要約しています。workflow \"Place Order\" =    input: UnvalidatedOrder    output: OrderPlaced AND BillableOrderPlaced AND OrderAcknowledgmentSent    // step 1: ValidateOrder    // step 2: PriceOrder    // step 3: AcknowledgeOrder    // step 4: create and return events各ステップは「入力を受け取り、変換し、出力を返す」関数です。これらを連結するとパイプラインになります。第 2 章で述べた「状態は例外的、ほとんどの処理は状態なしで書ける」という原則が、ここで具現化されます。ワークフロー全体を見ると「状態遷移」に見えますが、各ステップを見ると「入力を受け取り、何かを行い、出力を返す」純粋な関数でしかありません。状態マシンとしてのOrderOrder を単一の型として設計すると、フラグだらけになります。// 悪い設計struct Order {    order_id: OrderId,    is_validated: bool,    is_priced: bool,    amount_to_bill: Option\u003cDecimal\u003e,  // pricedの時だけ存在}本書のアプローチは、各状態を別の型として定義することです。pub struct UnvalidatedOrder { /* ... */ }pub struct ValidatedOrder { /* ... */ }pub struct PricedOrder {    // ...    pub amount_to_bill: BillingAmount,  // この状態でのみ存在}PricedOrder には amount_to_bill があります。ValidatedOrder にはありません。フラグは不要で、「どの型か」が状態を表します。AI にコードを書かせるとき、この設計は強力なガードレールになります。「検証をスキップして価格計算に進んでください」と指示しても、price() 関数が ValidatedOrder を要求する以上、AI は UnvalidatedOrder を渡すコードを書けません。型が不正な状態遷移を物理的に阻止します。依存性を型で表現する各ステップの依存性を型シグネチャで表現します。type CheckProductCodeExists = fn(\u0026ProductCode) -\u003e bool;type CheckAddressExists = fn(\u0026UnvalidatedAddress) -\u003e Result\u003cCheckedAddress, AddressValidationError\u003e;type ValidateOrder = fn(    CheckProductCodeExists,     // 依存性1    CheckAddressExists,         // 依存性2    UnvalidatedOrder,           // 入力) -\u003e Result\u003cValidatedOrder, ValidationError\u003e;依存性が関数の引数として明示されます。インターフェース全体ではなく、必要な関数だけを渡します。最小限の依存性です。エフェクトの文書化関数の「エフェクト（効果）」を型で文書化します。Result: エラーを返す可能性があるAsync: 非同期 I/O を行うOption: 値が存在しない可能性があるasync fn check_address_exists(    address: \u0026UnvalidatedAddress,) -\u003e Result\u003cCheckedAddress, AddressValidationError\u003e {    // 外部サービスへのHTTPリクエスト}関数シグネチャを見れば、「この関数は非同期で、エラーを返す可能性がある」と分かります。Transformation-Oriented Programmingの実践具体的な例で考えます。オブジェクト指向的に書くと、こうなります。impl Order {    fn validate(\u0026mut self, checker: \u0026ProductChecker) -\u003e Result\u003c(), ValidationError\u003e {        // 状態を変更        self.is_validated = true;        self.validated_at = Some(now());        Ok(())    }}関数型で書き直すと、こうなります。fn validate(    order: UnvalidatedOrder,    checker: \u0026ProductChecker,) -\u003e Result\u003cValidatedOrder, ValidationError\u003e {    // 新しい値を作る（元のorderは変更しない）    Ok(ValidatedOrder {        order_id: OrderId::new(order.order_id)?,        customer_info: validate_customer(order.customer_info)?,        lines: validated_lines,    })}違いは何でしょうか。コンパイル時チェック: price() に UnvalidatedOrder を渡すとコンパイルエラー状態の整合性が型で保証: ValidatedOrder には is_validated フラグがそもそも存在しないテストが独立: validate() と price() を別々にテストできるこの単純さが強力なのだUnvalidatedOrder を ValidatedOrder に変換します。ValidatedOrder を PricedOrder に変換します。元のオブジェクトは触りません。新しいオブジェクトを作ります。それだけです。状態の変更を追跡する必要がない（変更しないから）並行処理でも競合しない（元のデータを変更しないから）テストが簡単（入力と出力を比較するだけ）デバッグが楽（各ステップの入出力をログに残せば、全経路が追える）関数型プログラミングの入門書を読むと、モナドだの圏論だの、難しい概念が出てきます。しかし、実務で最も重要なのは、本書が示すTransformation-Oriented Programmingです。核心は 3 つです。状態を型で表現する（UnvalidatedOrder と ValidatedOrder は別の型）状態遷移を関数で表現する（validate(order) -\u003e ValidatedOrder）元のオブジェクトを変更しない（新しい値を作るだけ）変えるな。作れ。この章を読み終えたとき、「これなら実務で使える」と確信しました。モナドや圏論を理解する必要はありません。「状態ごとに型を分ける」「元のオブジェクトを変更しない」。この 2 つだけで、設計の質は劇的に変わります。難しい理論ではなく、明日から使える実践知。本書の価値はここにあります。8. Understanding Functions本章は、関数型プログラミングの基礎を解説します。実装に入る前の準備として、関数の扱い方を整理しています。関数型プログラミングとは著者の定義はシンプルです。「関数型プログラミングとは、関数が本当に重要なものとしてプログラミングすること」。オブジェクト指向では、オブジェクトがあらゆる場所で使われます。関数型では、関数があらゆる場所で使われます。依存性を注入するときは関数を渡します。コードを再利用するときは関数を合成します。関数は「モノ」である関数型プログラミングの核心は、関数が第一級の値であることです。変数に代入できます。リストに入れられます。引数として渡せます。戻り値として返せます。let add1 = |x: i32| x + 1;let square = |x: i32| x * x;let functions: Vec\u003cfn(i32) -\u003e i32\u003e = vec![add1, square];for f in \u0026functions {    println!(\"{}\", f(5));}関数をリストに入れて、ループで回しています。高階関数関数を引数に取る関数、または関数を返す関数を「高階関数」と呼びます。fn eval_with_5_then_add_2\u003cF\u003e(f: F) -\u003e i32where    F: Fn(i32) -\u003e i32,{    f(5) + 2}Rust では、関数を受け取る引数の型を Fn、FnMut、FnOnce トレイトで指定します。F#ではこの区別はありません。クロージャとはクロージャは「名前のない関数」です。通常の関数は fn name(...) と名前をつけて定義しますが、クロージャは |引数| 式 という形式でその場で作れます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orglet add1 = |x| x + 1;        // 引数xを受け取り、x + 1を返すlet result = add1(5);        // 6クロージャの特徴は、周囲の変数を「捕まえる」（キャプチャする）ことができる点です。let multiplier = 3;let multiply = |x| x * multiplier;  // multiplierを捕まえているlet result = multiply(5);           // 15Fnトレイトの使い分け関数を引数として受け取るとき、Rust では 3 種類のトレイトを使い分けます。これは「捕まえた変数をどう扱うか」で決まります。 トレイト  捕まえ方  呼び出し回数  Fn  読み取るだけ  何度でも  FnMut  変更する  何度でも  FnOnce  消費する（使い切る）  一度だけ 最初は気にしすぎなくてよいです。コンパイラがエラーで教えてくれます。カリー化と部分適用F#では、すべての関数が自動的に「カリー化」されます。Rust にはカリー化が組み込まれていません。同じことを実現するには、明示的にクロージャを返します。fn adder_generator(number_to_add: i32) -\u003e impl Fn(i32) -\u003e i32 {    move |x| number_to_add + x}let add5 = adder_generator(5);let result = add5(3);  // 8部分適用は、依存性注入に活用できます。let validate = |order| validate_order(    check_product_code_exists,    check_address_exists,    order,);let result = validate(unvalidated_order);Total Functions（全域関数）数学の関数は、すべての入力に対して出力が定義されます。12 を引数で割る関数を考えます。n = 0 のとき、何を返すべきでしょうか。解決策は 2 つあります。入力を制限するか、出力を拡張するかです。// 入力を制限fn twelve_divided_by(n: NonZeroI32) -\u003e i32 {    12 / n.0}// 出力を拡張fn twelve_divided_by(n: i32) -\u003e Option\u003ci32\u003e {    if n == 0 { None } else { Some(12 / n) }}どちらの場合も、型シグネチャが正直になります。型シグネチャは嘘をつきません。コメントは嘘をつきます。AI にコードを書かせるとき、この「正直な型シグネチャ」は重要です。AI は型シグネチャを見て、関数の契約を理解します。Option\u003ci32\u003e を返す関数なら、AI は None のケースを考慮したコードを生成します。しかし「0 を渡したら None を返します」というコメントは、読み飛ばされる可能性があります。関数合成F#にはパイプライン演算子 |\u003e があります。Rust にはありません。代わりにメソッドチェーンや、関数を直接呼び出します。let result: Vec\u003c_\u003e = (1..10)    .map(|x| x + 1)    .map(|x| x * x)    .collect();イテレータのアダプタは、パイプラインに近い書き方ができます。Rustで関数型プログラミングを実践するために本章を読んで、F#と Rust の違いを改めて認識しました。カリー化: F#は自動、Rust は手動パイプライン演算子: F#にはある、Rust にはないクロージャの所有権: F#は考慮不要、Rust は move や Fn/FnMut/FnOnce を意識これらの違いはありますが、関数型プログラミングの本質—関数を組み合わせてシステムを構築する—は Rust でも実践できます(が本当に最適か？という問いは投げないでくれ…本稿のアプローチと違いすぎる)。9. Implementation: Composing a Pipeline本章から、いよいよ実装に入ります。これまで型で設計してきたワークフローを、実際のコードに落とし込みます。パイプラインの理想形著者が示す理想のコードは驚くほどシンプルです。let placeOrder unvalidatedOrder =    unvalidatedOrder    |\u003e validateOrder    |\u003e priceOrder    |\u003e acknowledgeOrder    |\u003e createEvents4 行で注文処理全体が表現されています。これが関数型アプローチの目指す姿です。しかし現実には、関数の出力と次の関数の入力が一致しません。依存性をどこかで解決しなければなりません。本章はその「ギャップ」を埋める方法を解説します。型シグネチャによる実装のガイド本章で印象的だったのは、「型シグネチャを先に定義し、それに従って実装する」というアプローチです。type ValidateOrder = fn(    check_product_code: fn(\u0026ProductCode) -\u003e bool,    check_address: fn(\u0026UnvalidatedAddress) -\u003e CheckedAddress,    order: UnvalidatedOrder,) -\u003e ValidatedOrder;型シグネチャが「契約」として機能します。引数の型、戻り値の型が全て決まっているので、実装者は「この契約を満たすコードを書く」だけでよいです。依存性注入の関数型アプローチオブジェクト指向では、インターフェースを定義し、コンストラクタで注入します。関数型では、依存性を関数の引数として渡します。DI コンテナ？関数を渡せ。fn validate_order(    check_product_code: impl Fn(\u0026ProductCode) -\u003e bool,    check_address: impl Fn(\u0026UnvalidatedAddress) -\u003e CheckedAddress,    order: UnvalidatedOrder,) -\u003e ValidatedOrder {    // check_product_code を使う}インターフェース全体ではなく、必要な関数だけを渡します。ワークフロー全体の組み立て各ステップを組み立ててワークフロー全体を作ります。pub fn place_order(    // 依存性    check_product_code_exists: impl Fn(\u0026ProductCode) -\u003e bool,    check_address_exists: impl Fn(\u0026UnvalidatedAddress) -\u003e CheckedAddress,    get_product_price: impl Fn(\u0026ProductCode) -\u003e Price,    // 入力    unvalidated_order: UnvalidatedOrder,) -\u003e Vec\u003cPlaceOrderEvent\u003e {    let validated = validate_order(        \u0026check_product_code_exists,        \u0026check_address_exists,        unvalidated_order,    );    let priced = price_order(\u0026get_product_price, validated);    let acknowledgment = acknowledge_order(\u0026priced);    create_events(\u0026priced, acknowledgment)}F#のパイプライン演算子 |\u003e がないので、変数に束縛しながら連鎖させます。本章では Result を使わず簡略化しており、次章で Result を導入します。10. Implementation: Working with Errors本章は、エラーハンドリングの関数型アプローチを解説します。「Railway Oriented Programming」と呼ばれるパターンを学びます。エラーの三分類著者はエラーを 3 つに分類します。Domain Errors: ビジネスプロセスの一部として予期されるエラー。商品コードが無効、注文が請求で拒否される、など。Panics: システムを未知の状態にするエラー。メモリ不足、ゼロ除算など。Infrastructure Errors: ネットワークタイムアウト、認証失敗など。この分類は実務でも有用です。「このエラーはドメインエキスパートに相談すべきか」という問いに答えられます。ドメインエラーを型で表現する#[derive(Debug, Clone)]pub enum PlaceOrderError {    ValidationError(String),    ProductOutOfStock(ProductCode),    RemoteServiceError(RemoteServiceError),}エラーを enum で定義することで、どんなエラーが起こりうるか、型定義を見れば分かります。Railway Oriented Programming著者が提唱する解決策が「Railway Oriented Programming（鉄道指向プログラミング）」です。著者自身による詳細な解説は以下を参照してください。fsharpforfunandprofit.comResult を返す関数は「分岐するレール」として可視化できます。成功すれば上のレールに、失敗すれば下のレールに進みます。一度失敗パスに入ると、残りのステップはバイパスされます。      [validateOrder] → [priceOrder] → [acknowledgeOrder] → 成功           ↓               ↓               ↓      ─────────────────────────────────────────────────────→ 失敗Rustでの実装Rust では ? 演算子が同じことをより簡潔に表現します。fn validate_order(order: UnvalidatedOrder) -\u003e Result\u003cValidatedOrder, ValidationError\u003e {    let order_id = OrderId::create(\u0026order.order_id)?;    let customer_info = to_customer_info(\u0026order.customer_info)?;    let shipping_address = check_address(\u0026order.shipping_address)?;    Ok(ValidatedOrder { order_id, customer_info, shipping_address, ... })}? 演算子は、Ok ならアンラップし、Err なら早期リターンします。?演算子の仕組み? は「失敗したら即座に関数から抜ける」という処理を一文字で書ける記号です。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgResult は「成功（Ok）か失敗（Err）か」を表す型でした。? をつけると、成功なら中身を取り出し、失敗ならその場で関数を終了して呼び出し元にエラーを返します。// ?を使った書き方let order_id = OrderId::create(\u0026order.order_id)?;// これは以下と同じ意味let order_id = match OrderId::create(\u0026order.order_id) {    Ok(v) =\u003e v,              // 成功したら中身を取り出す    Err(e) =\u003e return Err(e), // 失敗したら即座にエラーを返す};? を使うには、関数の戻り値が Result である必要があります。エラー型の変換複数のステップを連結するとき、エラー型を統一します。#[derive(Debug)]pub enum PlaceOrderError {    Validation(ValidationError),    Pricing(PricingError),}impl From\u003cValidationError\u003e for PlaceOrderError {    fn from(e: ValidationError) -\u003e Self {        PlaceOrderError::Validation(e)    }}Fromトレイトによる型変換From は「ある型から別の型への変換方法」を定義するトレイトです。例えば「ValidationError を PlaceOrderError に変換する方法」を定義しておくと、? 演算子が自動的にエラー型を変換してくれます。// 「ValidationErrorからPlaceOrderErrorへの変換方法」を定義impl From\u003cValidationError\u003e for PlaceOrderError {    fn from(e: ValidationError) -\u003e Self {        PlaceOrderError::Validation(e)    }}これを定義しておくと、validate_order が ValidationError を返しても、? が自動的に PlaceOrderError に変換してくれます。異なるエラー型を返す関数を連結できるようになります。11. Serialization本章は、ドメインオブジェクトを JSON や XML などの形式に変換する方法を解説します。Bounded Context の境界を越えるとき、内部のドメイン型をそのまま使うことはできません。また、AI時代にはこのようなことも想定されます。zenn.dev永続化とシリアライゼーションの区別著者は 2 つの概念を区別します。Persistence（永続化）: プロセスの終了後も状態が残ること。Serialization（シリアライゼーション）: ドメイン固有の表現を、永続化可能な表現に変換すること。本章はシリアライゼーションに焦点を当て、次章で永続化を扱います。DTOによる変換—ドメインの境界防御ドメイン型は複雑です。ネストした型、制約付きの型、選択肢を持つ型。これらを直接シリアライズするのは難しいです。解決策は、Data Transfer Object（DTO）を中間層として使うことです。なぜDTOを使うのか？ドメイン型は制約を持つ: String50 は 50 文字以下という制約があります。JSON の \"name\" フィールドは任意の長さです。直接マッピングできません。内部実装の変更から外部を守る: ドメイン型のフィールド名を変えても、DTO が同じなら外部 API は影響を受けません。検証の境界を明確にする: 外部からの入力は「信頼できない」です。DTO からドメイン型への変換時に検証することで、ドメイン内は常に「信頼できる」状態を保ちます。DTO は「ドメインの境界防御」として機能します。Domain型 → DTO → JSON（シリアライズ）JSON → DTO → Domain型（デシリアライズ）Rust では、ドメイン型と DTO 型を別々に定義します。ドメイン型は制約を持ち、DTO はプリミティブ型のみを使います。/// 制約付きの文字列型（50文字以下）#[derive(Debug, Clone, PartialEq, Eq)]pub struct String50(String);impl String50 {    pub fn create(s: \u0026str) -\u003e Result\u003cSelf, ValidationError\u003e {        if s.is_empty() {            Err(ValidationError::Empty(\"String50 cannot be empty\".into()))        } else if s.len() \u003e 50 {            Err(ValidationError::TooLong(\"String50 must be 50 chars or less\".into()))        } else {            Ok(String50(s.to_string()))        }    }    pub fn value(\u0026self) -\u003e \u0026str {        \u0026self.0    }}/// ドメイン型（制約付き）#[derive(Debug, Clone, PartialEq, Eq)]pub struct Person {    pub first_name: String50,    pub last_name: String50,}/// DTO（シリアライズ用・プリミティブのみ）#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]pub struct PersonDto {    pub first_name: String,    pub last_name: String,}変換には From と TryFrom を使います。ドメイン型から DTO への変換は常に成功しますが、DTO からドメイン型への変換は失敗しうります。/// ドメイン型 → DTO（常に成功）impl From\u003c\u0026Person\u003e for PersonDto {    fn from(person: \u0026Person) -\u003e Self {        PersonDto {            first_name: person.first_name.value().to_string(),            last_name: person.last_name.value().to_string(),        }    }}/// DTO → ドメイン型（失敗する可能性あり）impl TryFrom\u003cPersonDto\u003e for Person {    type Error = ValidationError;    fn try_from(dto: PersonDto) -\u003e Result\u003cSelf, Self::Error\u003e {        let first_name = String50::create(\u0026dto.first_name)?;        let last_name = String50::create(\u0026dto.last_name)?;        Ok(Person { first_name, last_name })    }}TryFrom を使うことで、変換が失敗する可能性を型で表現しています。これは「Parse, don't validate」の実践です。入力を単に「正しいかどうか」検証するのではなく、より型安全な形式に変換（パース）することで、型レベルで正しさを保証します。DTOは契約である著者が強調するのは、DTO は「Bounded Context 間の契約」だということです。他の Context が発行したイベントを受信するとき、そのフォーマットに依存します。フォーマットを変更すると、依存する Context に影響が及びます。だから、シリアライズのフォーマットは慎重に設計すべきです。serde の #[derive(Serialize)] を安易に使うと、内部実装の変更が契約の破壊につながります。選択肢型（enum）のシリアライズOR 型（enum）のシリアライズは注意が必要です。JSON には enum の概念がありません。Rust では serde の属性でタグ付け方式を指定します。serde については公式ドキュメントを参照してください。serde.rs/// 支払い方法のDTO - タグ付きenum#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]#[serde(tag = \"type\")]pub enum PaymentMethodDto {    Cash,    Check { check_number: String },    Card { card_number: String, expiry: String },}#[serde(tag = \"type\")] を指定すると、以下のような JSON が生成されます。{\"type\":\"Cash\"}{\"type\":\"Check\",\"check_number\":\"12345\"}{\"type\":\"Card\",\"card_number\":\"4111...\",\"expiry\":\"12/25\"}タグ付きの方が明示的で、新しいケースを追加しやすいです。ラウンドトリップの検証シリアライズとデシリアライズは対になります。ラウンドトリップ（往復）テストで、データが失われないことを確認します。pub fn serialize_order(order: \u0026Order) -\u003e Result\u003cString, serde_json::Error\u003e {    let dto = OrderDto::from(order);    serde_json::to_string_pretty(\u0026dto)}pub fn deserialize_order(json: \u0026str) -\u003e Result\u003cOrder, String\u003e {    let dto: OrderDto = serde_json::from_str(json).map_err(|e| e.to_string())?;    Order::try_from(dto).map_err(|e| format!(\"{:?}\", e))}本章と中心テーマのつながりDTO パターンは、本書のTransformation-Oriented Programmingと関連します。外部からの入力（JSON）は「未検証の値」です。DTO からドメイン型への変換は、UnvalidatedOrder から ValidatedOrder への変換と同じパターンです。信頼できない入力を、信頼できるドメイン型に「変換」します。外部を信頼するな。まず変換せよ。DTO は、外部世界とドメインの境界を守る防壁です。12. Persistence本章は、ドメインモデルをデータベースに永続化する方法を解説します。DDD の原則に従いながら、現実のインフラと向き合います。永続化の原則本章の冒頭で、著者は 3 つの原則を示します。永続化を端に押し出す（Push persistence to the edges）: ワークフローの内部では I/O を行わないコマンドとクエリを分離する（CQRS）: 更新操作と読み取り操作を分けるBounded Contextは自分のデータストアを所有する: 他の Context のデータベースに直接アクセスしないこれらの原則は、「状態は例外的」という関数型の考え方と合致します。永続化を端に押し出す著者は、「ドメインロジックと I/O が混在したコード」と「分離したコード」を対比しています。なぜI/Oを境界に押し出すのか？テストが容易になる: 純粋なドメインロジックは、データベース接続なしでテストできます。入力を与えて出力を確認するだけです。推論が容易になる: 副作用がない関数は、同じ入力に対して常に同じ出力を返します。状態を追跡する必要がありません。並行処理が安全になる: 共有状態を変更しないため、競合が発生しません。変更に強くなる: データベースを変更しても、ドメインロジックは影響を受けません。逆も同様です。まず、ドメイン型を定義します。これらの型はデータベースのことを知りません。/// 未払いの請求書#[derive(Debug, Clone, PartialEq)]pub struct UnpaidInvoice {    pub invoice_id: InvoiceId,    pub amount_due: Money,}/// 支払い済みの請求書#[derive(Debug, Clone, PartialEq)]pub struct PaidInvoice {    pub invoice_id: InvoiceId,    pub amount_paid: Money,}/// 支払い処理の結果#[derive(Debug, Clone, PartialEq)]pub enum InvoicePaymentResult {    FullyPaid(PaidInvoice),    PartiallyPaid(UnpaidInvoice),}次に、純粋なドメインロジックを定義します。この関数は I/O を行いません。/// 支払いを適用する - 純粋関数、I/Oなしpub fn apply_payment(invoice: UnpaidInvoice, payment: Payment) -\u003e InvoicePaymentResult {    let remaining = invoice.amount_due.0 - payment.amount.0;    if remaining \u003c= 0.0 {        InvoicePaymentResult::FullyPaid(PaidInvoice {            invoice_id: invoice.invoice_id,            amount_paid: Money(invoice.amount_due.0),        })    } else {        InvoicePaymentResult::PartiallyPaid(UnpaidInvoice {            invoice_id: invoice.invoice_id,            amount_due: Money(remaining),        })    }}最後に、コマンドハンドラで I/O を境界に押し出します。パターンは「Load → Pure Logic → Save」です。/// コマンドハンドラ - I/Oは境界で行うpub fn pay_invoice_handler\u003cR: InvoiceRepository\u003e(    repo: \u0026R,    command: PayInvoiceCommand,) -\u003e Result\u003cInvoicePaymentResult, PayInvoiceError\u003e {    // 1. Load（I/O - 開始時）    let invoice = repo        .load(\u0026command.invoice_id)        .ok_or(PayInvoiceError::InvoiceNotFound(command.invoice_id))?;    // 2. 純粋なドメインロジック（I/Oなし）    let result = apply_payment(invoice, command.payment);    // 3. Save（I/O - 終了時）    match \u0026result {        InvoicePaymentResult::FullyPaid(paid) =\u003e repo.save_paid(paid),        InvoicePaymentResult::PartiallyPaid(unpaid) =\u003e repo.save_unpaid(unpaid),    }    Ok(result)}RepositoryパターンRust では Trait を使って Repository を抽象化します。これにより、テスト時にモックを注入できます。なぜTraitで抽象化するのか？テスト容易性: 本番では PostgreSQL、テストではインメモリ実装を注入できます。実装の交換可能性: データベースを変更しても、ドメインロジックは影響を受けません。依存性の逆転: ドメインが永続化の詳細に依存しません。依存の方向が逆になります。トレイトとはトレイトは「この型は〇〇ができる」という能力の定義です。例えば「データを読み込める」「データを保存できる」という能力を定義します。詳しくは公式ドキュメントを参照してください。doc.rust-lang.org/// Repositoryトレイト - 永続化操作を抽象化pub trait InvoiceRepository {    fn load(\u0026self, id: \u0026InvoiceId) -\u003e Option\u003cUnpaidInvoice\u003e;    fn save_unpaid(\u0026self, invoice: \u0026UnpaidInvoice);    fn save_paid(\u0026self, invoice: \u0026PaidInvoice);}trait で能力を定義し、impl Trait for Type で「この型はこの能力を持つ」と宣言します。ジェネリクスとはジェネリクスは「型を後で決める」仕組みです。\u003cR: InvoiceRepository\u003e は「InvoiceRepository という能力を持つ何かの型 R」という意味です。// Rは「InvoiceRepositoryという能力を持つ何か」fn pay_invoice_handler\u003cR: InvoiceRepository\u003e(repo: \u0026R, ...) { ... }これで同じ関数を、異なる実装で使い回せます。// 本番ではPostgreSQLを使うpay_invoice_handler(\u0026postgres_repo, command);// テストではメモリ上の仮実装を使うpay_invoice_handler(\u0026in_memory_repo, command);テスト用のインメモリ実装を作れば、実際のデータベースなしでドメインロジックをテストできます。Persistence Ignorance（永続化の無知）第 2 章で「データベース駆動設計と戦う」と述べたことの実践がここにあります。ドメインモデルは、自分がどこに保存されるか知りません。知る必要もありません。Order 型はデータベースのことを知りません。永続化の詳細は、ワークフローの「端」で処理されます。この設計により、ドメインロジックの変更が永続化コードに影響しません。逆に、データベースを変更してもドメインロジックは変わりません。NoSQLとRDBの選択本章では、NoSQL（ドキュメント DB）と RDB（リレーショナル DB）の両方のアプローチを解説しています。NoSQL: Aggregate をそのままドキュメントとして保存できます。DDD との相性が良いです。RDB: OR 型（enum）のマッピングが難しいです。インピーダンスミスマッチ（オブジェクトモデルとリレーショナルモデルの構造的な不一致）が発生します。-- OR型のRDBへのマッピング（判別カラム）CREATE TABLE order_lines (    quantity_type VARCHAR(10),  -- 'Unit' or 'Kilos'    unit_quantity INT NULL,    kilogram_quantity DECIMAL NULL);どちらも完璧ではありません。「永続化は境界で行う」という原則を守ることで、純粋なドメインロジックと不純な I/O 処理を分離しやすくなります。13. Evolving a Design and Keeping It Clean本章は、本書の締めくくりとして、設計の進化と保守性について解説します。要件は変わります。ドメインモデルも変わります。その変化にどう対応するでしょうか。変化への対応著者は、DDD は「一度きりの静的なプロセス」ではないと強調します。要件が変われば、まずドメインモデルを見直します。実装をパッチするのではなく、モデルから考え直します。変更例: 配送料の追加配送料計算をワークフローに組み込むには、新しいステップを追加します。まず、新しい型を定義します。なぜ既存の型を変更せず、新しい型を作るのか？型の名前がドキュメントになる: PricedOrderWithShipping という名前だけで、「価格計算済みで配送情報も持つ注文」だと分かります。段階を明示できる: PricedOrder と PricedOrderWithShipping は別の段階だと型で表現できます。コンパイラが変更を追跡する: 型が変わると、関連する箇所すべてでコンパイルエラーが発生します。見落としがありません。/// 配送方法#[derive(Debug, Clone, PartialEq, Eq)]pub enum ShippingMethod {    Standard,    Express,    Overnight,}/// 配送情報#[derive(Debug, Clone, PartialEq)]pub struct ShippingInfo {    pub method: ShippingMethod,    pub cost: Money,}/// 配送情報付きの価格計算済み注文 - 新しい型#[derive(Debug, Clone, PartialEq)]pub struct PricedOrderWithShipping {    pub order_id: OrderId,    pub items: Vec\u003cPricedOrderLine\u003e,    pub amount_to_bill: Money,    pub shipping_info: ShippingInfo,}次に、新しいパイプラインステップを定義します。/// 新しいパイプラインステップ: 配送情報を追加pub fn add_shipping_info(order: PricedOrder) -\u003e PricedOrderWithShipping {    // シンプルなロジック: $100以上は送料無料    let shipping = if order.amount_to_bill.0 \u003e 100.0 {        ShippingInfo {            method: ShippingMethod::Standard,            cost: Money(0.0),        }    } else {        ShippingInfo {            method: ShippingMethod::Standard,            cost: Money(5.99),        }    };    PricedOrderWithShipping {        order_id: order.order_id,        items: order.items,        amount_to_bill: order.amount_to_bill,        shipping_info: shipping,    }}既存のコードを変更するのではなく、新しいステップを挿入します。validateOrder → priceOrder → addShippingInfo → acknowledgeOrder → createEventsこの「ステップの追加」というアプローチは、多くの機能追加に応用できます。ロギング、パフォーマンスメトリクス、認可チェック、監査。各ステップが独立していて、型が合っていれば、安全に追加・削除できます。VIP顧客の対応—入力をモデル化せよ著者は重要な指摘をしています。「ビジネスルールの出力（送料無料フラグ）ではなく、入力（VIP ステータス）をモデル化せよ」。なぜ「出力」ではなく「入力」をモデル化するのか？ルールが変わっても型は変わらない:「VIP は送料無料」→「VIP は送料 50%オフ」とルールが変わっても、CustomerStatus 型自体は変更不要です。関数だけ変えればよいです。原因をモデル化する:「送料無料かどうか」は結果（派生情報）です。原因は「VIP かどうか」です。原因をモデル化すれば、結果はいつでも計算できます。柔軟性が高い: VIP ステータスは送料以外にも使えます（優先サポート、限定商品へのアクセス等）。出力をハードコードすると、その柔軟性を失います。/// 顧客ステータス - ビジネスルールの「入力」をモデル化#[derive(Debug, Clone, PartialEq, Eq)]pub enum CustomerStatus {    Normal,    Vip,}/// 顧客#[derive(Debug, Clone, PartialEq, Eq)]pub struct Customer {    pub customer_id: String,    pub name: String,    pub status: CustomerStatus,}ビジネスルールは、入力（CustomerStatus）に基づいて決定を下します。/// 顧客ステータスに基づいて配送を計算pub fn calculate_shipping_for_customer(order: \u0026OrderWithCustomer) -\u003e ShippingInfo {    match order.customer.status {        CustomerStatus::Vip =\u003e ShippingInfo {            method: ShippingMethod::Express,            cost: Money(0.0), // VIPは無料のエクスプレス配送        },        CustomerStatus::Normal =\u003e {            if order.amount_to_bill.0 \u003e 100.0 {                ShippingInfo {                    method: ShippingMethod::Standard,                    cost: Money(0.0),                }            } else {                ShippingInfo {                    method: ShippingMethod::Standard,                    cost: Money(5.99),                }            }        }    }}ビジネスルールが変わっても（例: VIP は送料無料→VIP は送料 50%オフ）、calculate_shipping_for_customer 関数を変更するだけでよいです。ドメインモデル自体（CustomerStatus）は変更する必要がありません。型の変更と波及効果本章の核心は、「型の変更がコンパイラによって追跡される」ことです。// 変更前pub struct PricedOrder { /* ... */ }// 変更後（配送情報を追加）pub struct PricedOrderWithShipping {    // ...    pub shipping_info: ShippingInfo,  // 新しいフィールド}PricedOrder と PricedOrderWithShipping は異なる型です。PricedOrder を期待していたコードに PricedOrderWithShipping を渡すとコンパイルエラーになります。// これはコンパイルエラー！fn process(order: PricedOrder) { /* ... */ }process(priced_order_with_shipping); // 型が違う動的型付け言語では、このような変更は「実行時エラー」として発見されます。静的型付けでは、「コンパイル時エラー」として発見されます。コンパイラがリファクタリングアシスタントとして機能します。関数型 DDD の核心は、「型でドメインを表現する」ことです。AND 型（struct）と OR 型（enum）でドメインの構造を表現します。状態遷移を別の型として定義します。制約を Smart Constructor で強制します。不正な状態を表現不可能にします。フラグを立てるな。型を作れ。これらの原則は、F#でも Rust でも適用できます。おわりに読む前の三つの悩みへの回答「はじめに」で述べた 3 つの読む動機に、本書がどう応えたかを振り返ります。1. DDDを学び直す必要があった → 関数型の視点でDDDが腹落ちしたDDD の概念—Aggregate、Entity、Value Object—は、オブジェクト指向の文脈で説明されると抽象的に感じていました。本書は、これらを「型」という具体的な道具で表現する方法を示しました。Value Object は単なる newtype です。struct OrderId(String) と書けば、それが Value Object です。Aggregate の境界は、型の境界で表現できます。ValidatedOrder と UnvalidatedOrder が別の型なら、それが境界です。「なぜそう設計するのか」を言語化できるようになりました。「この型を別にするのは、状態が違うから」「この値を newtype にするのは、ドメイン上の意味が違うから」。経験則ではなく、型システムに基づいた説明ができます。2. Rustでドメインモデリングを実践したかった → F#の概念はRustで十分(ではないかもしれないが)表現できるF#にあって Rust にない機能—パイプライン演算子、computation expressions、Units of Measure—は、確かにあります。しかし、本書の核心である「Make Illegal States Unrepresentable」は、Rust で十分に実践できたと思います。むしろ、Rust の所有権システムは F#にない利点を提供します。状態遷移を「所有権の移動」として表現できます。validate(order: UnvalidatedOrder) -\u003e ValidatedOrder と書けば、検証前の注文は使えなくなります。F#では GC があるため、古い変数への参照が残る可能性がありますが、Rust では型システムがそれを防ぎます。3. AIエージェント時代における型システムの意味を考えたかった → 型は「AIが破れない制約」本書を読む前は、「型があると AI の生成精度が上がる」という感覚がありましたが、理論的に説明できませんでした。本書を読んで、その理由が明確になりました。型で定義された制約は、物理的に破れません。NonEmptyList\u003cOrderLine\u003e と定義すれば、AI は空の注文を返すコードを書けません。コンパイルが通らないからです。「このフィールドは必須です」というコメントは無視できますが、型は無視できません。これは「AI が守るべきルール」ではなく「AI が破れない壁」です。読む前と読んだ後Before（読む前）DDD の設計はある種の経験則で判断していましたRust の Option/Result は便利ですが、関数型との繋がりを考えていませんでした型があると AI の精度が上がる「気がする」程度の理解でしたAfter（読んだ後）DDD の概念を型システムの言葉で説明できるようになりましたTransformation-Oriented Programming（元のオブジェクトを変更せず、新しい値を作る）という原則を内在化しました型を「人間のためのドキュメント」かつ「AI が破れない制約」として設計できるようになりましたTransformation-Oriented Programming関数型プログラミングを学んで獲得する最も重要な概念は、実はシンプルです。状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できる。本書を読み終えて、この一文の重みを改めて感じています。私たちはプログラミングを学ぶとき、まず「変数に値を代入する」ことから始めます。x = 1。x = x + 1。状態を変更することが、プログラミングの基本だと教わります。しかし、よく考えてみると、ビジネスロジックの大半は「入力を受け取り、変換し、出力を返す」で書けます。注文明細から合計金額を計算する → 入力と出力だけ住所をパースする → 入力と出力だけ商品コードを検証する → 入力と出力だけ状態の変更は不要です。副作用も不要です。ほとんどのビジネスロジックは、数学の関数のように書けます。では、状態が必要になるのはいつでしょうか。データベースに保存するとき。外部 API を呼ぶとき。ファイルに書き込むとき。つまり、システムの境界を越えるときだけです。この気づきが、設計の発想を変えます。状態を「デフォルト」ではなく「例外」として扱います。しかし状態遷移は避けられないビジネスの世界は状態遷移で満ちています。注文は「未検証」から「検証済み」になります。カートは「空」から「商品あり」になります。申請は「提出済み」から「承認済み」になります。これは無視できません。問題は、この状態遷移をどう表現するかです。オブジェクト指向の答えは「オブジェクトが状態を持ち、メソッドが状態を変更する」でした。order.validate() を呼ぶと、order の内部状態が変わります。この設計は、状態の追跡を難しくします。order は今どの状態なのか。どの経路を通ってここに至ったのか。フラグの組み合わせは正しいのか。常に頭の中で管理し続けなければなりません。本書が示す答えは、Transformation-Oriented Programmingです。著者の言葉を借りれば、「ビジネスプロセスはデータを何らかの形で変換する—入力を受け取り、何かを行い、出力を返す」。重要なのは、元のオブジェクトを変更しないことです。UnvalidatedOrder という型があります。validate という関数を適用すると、ValidatedOrder という新しい値が生まれます。このとき、元の UnvalidatedOrder には一切触れません。新しい値を作るだけです。UnvalidatedOrder → validate → ValidatedOrder → price → PricedOrder状態を「変更」するのではなく、「入力を受け取り、何かを行い、出力を返す」。元のオブジェクトには触れません。これが本書の核心です。この発想の転換がもたらすものこのアプローチを採用すると、いくつかの問題が消えます。状態の追跡が不要になる。 ValidatedOrder を持っているなら、それは「検証済みの注文」です。フラグを見る必要がありません。型がすべてを語ります。並行処理が安全になる。 元のデータを変更しないから、競合が起きません。テストが簡単になる。 入力を与えて、出力を確認します。それだけです。デバッグが楽になる。 各ステップの入出力をログに残せば、全経路が追えます。そして何より、ビジネスの言葉とコードが一致する。「見積書」が「発注書」になります。Estimate が Order になります。ビジネスの人々が頭の中で考えているモデルが、そのままコードになります。型は思考のツールである本書を読む前、型システムは「コンパイラを満足させるためのもの」だと思っていました。IDE の補完が効きます。リファクタリングが安全になります。その程度の認識でした。本書を読んで、型は「思考のツール」だと認識を改めました。AND と OR という 2 つの組み合わせで、複雑なドメインを表現できます。struct は「これとこれが両方必要」、enum は「これかこれのどちらか」。この単純な組み合わせが、ドメインの構造を可視化します。型を書くことは、ドメインを理解することです。型を読むことは、ドメインを学ぶことです。少なくとも、私はそう感じるようになりました。型で「不可能」を作る本書の内容を 2026 年の視点で読み直して、最大の発見がありました。「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」—この原則は、人間の開発者のミスを防ぐためのものとして紹介されています。しかし 2026 年現在、同じ原則がAIの出力を自動検証するフィルタとして機能しています。型で「不可能」を定義すると、AI が生成したコードのうち、その制約に違反するものはコンパイル時に除外されます。NonEmptyList\u003cOrderLine\u003e と定義すれば、AI が空の注文を返すコードを書いてもコンパイルエラーで検出されるVerifiedEmailAddress を要求すれば、AI が未検証メールへの送信を実装してもコンパイルが通らないUnvalidatedOrder → ValidatedOrder という型シグネチャがあれば、AI が検証をスキップするコードはコンパイルエラーになるこれは「AI に正しいコードを書かせる」のではなく、「AI が書いた誤ったコードを検出する」メカニズムです。AI の精度向上ではなく、フィルタリング機構として機能します。先日、Claude Code に「Order を作成する関数を書いて」と指示しました。生成されたコードは Vec\u003cOrderLine\u003e を返していました。しかし私のコードベースでは NonEmptyList\u003cOrderLine\u003e を使っています。コンパイルエラーが発生し、AI は「空の注文」を作るコードを出力しましたが、それが本番に混入することはありませんでした。一方、別のプロジェクトでは「このフィールドは必須」とコメントに書いただけでした。AI はそのコメントを無視して Option を返すコードを生成し、後から問題が発覚しました。型で定義された制約は、コンパイル時に検証されます。コメントは検証されません。この違いが重要です。「何を作るか」を決める能力本書の第 1 章で、著者は「開発者の仕事はコードを書くことではなく、ソフトウェアを通じて問題を解決すること」と述べています。2018 年に書かれたこの言葉は、2026 年の今、さらに重みを増しています。「何を作るか」という問いを分解してみます。ビジネス要件の理解: ドメインエキスパートとの対話、暗黙知の引き出し技術的制約の把握: 既存システムとの整合性、パフォーマンス要件、チームのスキルセット両者のトレードオフ判断: 「正解がない」状況での意思決定現時点で AI が得意なのは 2 番目です。ドキュメントやコードベースを読み、技術的な制約を分析できます。一方、1 番目と 3 番目は人間の仕事です。ドメインエキスパートとの対話で暗黙知を引き出すこと、そして「どちらも正しい」状況でトレードオフを判断すること。これらは AI に委譲できません。この構造を理解すれば、「人間の仕事」を「暗黙知の言語化」と「トレードオフ判断」に絞り込めます。本書で学んだドメインモデリングの技術は、まさにこの「暗黙知の言語化」を支援するものです。型で表現されたドメインモデルがあれば、AI は「どう作るか」を高い精度で実行できます。ドメイン駆動設計をはじめよう ―ソフトウェアの実装と事業戦略を結びつける実践技法作者:Vlad Khononovオーム社Amazon働き方の逆転—AIエージェント時代の開発スタイル本書を読みながら、自分の働き方が根本的に変わったことを実感しました。以前のモデルでは、人間がコードを書き、AI は相談相手でした。Stack Overflow の代わり、ドキュメント検索の高速化。補助的な存在です。現在のモデルでは、AI が運転席に座り、人間は助手席でナビゲーションをしています。AI にプランを練らせ、レビューし、実装させ、またレビューする。この流れが定着しました。AI は「分身」的な存在になりました。明確な指示とコンテキストを与えれば、疲労知らずで作業してくれる相棒です。Claude Opus 4.5 以降、この感覚は決定的になりました。プログラミングのシンタックスを書く機会は明らかに減りました。では、ソフトウェアエンジニアの役割はどう変化したのでしょうか。1. アーキテクチャの指針決定AI は「どう作るか」を実行できますが、「なぜそう作るか」は決められません。Bounded Context の境界をどこに引くか、技術選定のトレードオフ、パフォーマンスと保守性のバランス。これらは人間が判断します。2. コードベースから読み取れないコンテキストの整理・提供AI はコードに書かれていないことを知りません。なぜこの設計にしたか、本番環境でのみ発生する問題、チームの暗黙のコーディング規約、ビジネス上の制約。これらを言語化し、CLAUDE.md やコメントに落とし込む能力が求められます。3. 期待する挙動を自動・継続的に検証する枠組みの整備AI が書いたコードは「動く」かもしれませんが、「正しい」とは限りません。型による制約、プロパティベーステスト、E2E テスト、本番監視。これらの枠組みを整備し、AI の出力を検証し続けるのは人間の仕事です。本書の「Make Illegal States Unrepresentable」は、まさにこの 3 番目の観点で価値を発揮します。型で制約を定義すれば、AI の出力を自動的に検証できます。コンパイルが通れば、少なくとも型レベルの正しさは保証されます。コードを手で書くという作業は、実は思考の外在化プロセスでもありました。書きながら考えていた。この機会が減ったとき、思考の質をどう担保するか。正直、まだ答えが出ていません。本書のようなドメインモデリングの訓練はその答えの 1 つかもしれませんが、それで十分かどうかは分かりません。分からないまま、AI と協業し続けています。Architecture Modernization との接続本書を読みながら、Nick Tune 著『Architecture Modernization』の内容が何度も頭をよぎりました。現在、この本の翻訳に携わっています。Architecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazon『Domain Modeling Made Functional』は「新規開発」の文脈で DDD を説明しています。しかし現実の多くのプロジェクトは「既存システムの改善」です。レガシーシステムをどう分析し、背景情報からBounded Context をどう切り出し、段階的にモダナイズしていくか。『Architecture Modernization』はまさにその部分を扱っています。翻訳作業を通じて、共感できる内容が多くありました。特に「既存システムの暗黙知をどう言語化するか」という問題意識は、本書の「ドメインエキスパートとの対話」と通じるものがあります。AI エージェント時代において、この問題はさらに重要になっています。AI は「新しいコードを書く」ことは得意ですが、「既存システムの文脈を理解する」ことは苦手です。10 年前の設計判断の背景、当時の技術的制約、組織の歴史。これらを言語化し、モダナイゼーションの方針を決めるのは、依然として人間の仕事です。本書を読んで「関数型 DDD」に興味を持った方には、『Architecture Modernization』も勧めたいです。新規開発だけでなく、既存システムをどう改善するか。両方の視点を持つことで、設計の引き出しが増えます。最後に2018 年に出版された本書を、2026 年に読む価値はあったでしょうか。かなり、Yes です。ただ、正直なところ、本書の「すべて」を実践できる自信はありません。Smart Constructor を徹底すると言いながら、明日には String を直接使っているかもしれません。型で不可能を作るのは、思っているより面倒くさい作業です。締め切りに追われると、つい妥協してしまう。それでも、本書を読んだことで「何かに気づいた」感覚はあります。うまく言葉にできませんが、型を書くときの解像度が変わった気がします。Option を見たとき、「本当にこれは省略可能なのか？」と問い直すようになりました。冒頭で触れた『Architecture Modernization』の翻訳作業。本書を再読したことで、「Bounded Context」「Aggregate」といった用語を訳すとき、以前より自信を持てるようになりました。言葉の背後にある設計思想を、型という道具で理解したからです。翻訳は続いています。この感覚が正しいのかどうかは、実務で検証していくしかありません。関数型 DDD は、特定の言語やパラダイムに縛られません。F#で書かれた本書の概念は、Rust でも実践できます。そして、人間と AI が協業する時代において、「不可能を型で定義する」技術の価値はますます高まっていく—たぶん。","isoDate":"2026-01-22T00:46:54.000Z","dateMiliSeconds":1769042814000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、頑張るなら組織と踊れ","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/19/090119","contentSnippet":"はじめに「おい、辞めるな」で辞めないことを選んだ。syu-m-5151.hatenablog.com「おい、辞めないなら頑張れ」で頑張り方を学んだ。syu-m-5151.hatenablog.com見せろ。対話しろ。上司を勝たせろ。スポンサーを作れ。そう書いた。で、やってみてどうだった。正直に言う。私はうまくいかなかった。見せているつもりだった。対話しているつもりだった。上司を勝たせようとしていた。でも、空回りしていた。なぜか。組織の力学を理解していなかったからだ。いや、もっと正確に言おう。理解しようとしなかった。組織の力学——いわゆる「政治」——を、私は嫌悪していた。「実力で勝負したい」「政治なんかに関わりたくない」——そう思っていた。技術的な正しさを盾に、人間関係の機微を「非論理的」と切り捨てていた。以前、「正義のエンジニアという幻想」という記事を書いた。syu-m-5151.hatenablog.comあの記事で書いたことは、今でも私の中に残っている。媚びないことと無礼であることの区別もつかないまま、技術的優位性を振りかざしていた——そんな恥ずかしい過去を、私は持っている。今回は、その続きを書く。組織の力学について。私が嫌悪していたもの。でも、理解しなければ成果を出せないもの。そして、したたかに生きるということについて。先に結論を言っておく。理解することと、加担することは違う。そして、政治をやっている人は「汚い大人」ではない。泥臭く仕事を通そうとしているだけだ。正直に告白する。この記事を書くことには抵抗があった。「政治のやり方を教える」みたいで、気が進まなかった。でも、過去の自分が知りたかったことを書く。飲み屋でそれを喋る。それがこの「おい、」シリーズの趣旨だ。おい、頑張るなら組織と踊れ。——と書いて、自分でも苦い顔をしている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。私は「正義のエンジニア」だった最初に告白しておく。私はかつて、自分の技術思想とキャリア戦略が100%正しいと信じて疑わなかった。そして、それを受け入れない企業、同僚たちが100%間違っていると本気で思っていた。今思えば、それはソフトウェアエンジニアという職業に就いた多くの若い人が陥る、ある種の思春期的な錯覚だったと思う。「なぜこんな非効率的な実装をするんですか？」「技術的にはこっちの方が正しいんですけどね」「政治的な理由で技術選定するなんて、エンジニアリングの敗北だ」そんな言葉を、私は何度思って何度口にしたことだろう。ある会議で、私は技術的に正しい提案をした。データに基づいていた。論理的だった。反論の余地がないと思っていた。却下された。理由は曖昧だった。「今はタイミングが悪い」「もう少し検討が必要」。でも、本当の理由は別にあった。私は後から知った。あの提案は、ある部門の利害と衝突していた。その部門のキーパーソンに、事前に話を通していなかった。だから、会議の場で潰された。私はその事実を伝えられた時に密かに怒った。「政治で正しい提案が潰されるなんて、おかしい」と。でも、冷静に考えると、私の方がおかしかった。技術的に正しいことと、組織で通ることは、別の問題だ。私はその区別ができていなかった。これは「誰に話を通すか」の問題だった。でも、組織の力学を理解していないことは、別の形でも現れた。あるプロジェクトで、私は黙々と成果を出していた。技術的な課題を解決し、納期を守り、品質を担保した。「これだけやれば評価されるだろう」と思っていた。評価面談で、上司はこう言った。「〇〇さんの貢献は分かっているんだけど、他のマネージャーに説明しにくいんだよね」。私は意味が分からなかった。成果を出しているのに、なぜ説明しにくいのか。後から分かった。私の仕事は「見えなかった」のだ。他のマネージャーは、私が何をしているか知らなかった。評価会議で私の名前が挙がっても、「誰？」という反応だった。私の上司は、私を推そうにも、材料がなかった。見えない仕事は、存在しないのと同じ——「おい、辞めないなら頑張れ」で書いたことだ。でも、それは「見せる」だけでは解決しない。誰に見せるか。どのタイミングで見せるか。どの文脈で見せるか。それを間違えると、見せても意味がない。私は「政治」を嫌悪していた。でも、その嫌悪が、私自身の足を引っ張っていた。媚びないと無礼を混同していたここで、痛い告白をする。「私は媚びない」——それが私のプライドだった。しかし「媚びない」と「無礼」は違う。私は単に無礼だった。コードレビューで、つい正論を優先してしまう癖があった。「このコード、正直ひどくないですか？全部書き直した方が早いです」——そんなコメントを書いていた。ある日、シニアエンジニアが個別に連絡をくれた。「君の指摘は技術的には正しい。でも、そのコメントを見た人がどう感じるか考えたことある？彼は他のタスクも抱えながら、期限に間に合わせようと必死だった。君のコメントは、その努力を全否定している」その言葉にハッとした。私は技術的な正しさばかりを見て、人の気持ちを踏みにじっていたのだ。別の機会には、マネージャーが1on1で厳しい指摘をした。「君は優秀だ。でも、チームメンバーが君を避け始めている。それでいいの？技術力があっても、一人では何も作れないよ」媚びないことと、相手を尊重することは両立する。でも当時の私にはその区別がつかなかった。率直であることと配慮がないことを混同していた。技術的な正しさを盾に、人としての礼儀を忘れていた。私は様々な言い訳を用意していた。「エンジニアは成果で評価されるべきだから人間関係は二の次」「技術的に正しいことが最優先だから言い方なんて些細な問題」「実力があれば多少の態度の悪さは許される」これらはすべて、自分の社会性の欠如を正当化するための、頭の悪い言い訳だった。まるで反抗期の中学生が「大人は汚い」と言い訳するように、私は「技術的正しさ」を盾に、自分の未熟さを隠していたのだ。転機は、年次が上がって後輩ができたときに訪れた。私の何気ない「それは違うよ」という一言で、新卒エンジニアが完全に萎縮してしまった。その後、彼は私に質問することを避けるようになり、分からないことを抱え込むように。私は、かつて自分が嫌っていた「怖い先輩」になっていたのだ。このとき、ようやく理解した。正しいことを、正しい方法で伝えられなければ、それはただの暴力だ。技術力は重要だが、それをどう使うかはもっと重要。正しいことを言っているつもりで、実際には相手の立場に立てていなかっただけだった。そういう時代もあったでよいここで、過去の自分との向き合い方について書いておく。ある時期、私は過去の失言や態度を思い出しては、布団の中で悶えていた。「あの時、なぜあんなことを言ったんだ」「もっと早く気づいていれば」——後悔の反芻は止まらなかった。コードレビューで人を傷つけた記憶。会議で空気を凍らせた記憶。「正しいことを言っているのに、なぜ分かってもらえないんだ」と憤っていた記憶。思い出すたびに、顔が熱くなった。でも、ある時気づいた。過去を責めても、過去は変わらない。変えられるのは、これからだけだ。だから、こう割り切ることにした。「過去はすべて正しかった」と。誤解しないでほしい。過去の行動が道徳的に正しかったと言いたいわけではない。あの無礼な態度は、やはり間違っていた。でも、あの経験があったから、今の自分がいる。痛い目に遭わなければ、私は変われなかった。あの失敗がなければ、この記事を書くこともなかった。過去を否定し続けると、エネルギーが過去に吸い取られる。後悔に費やす時間は、未来への投資に使えない。「あの時こうすればよかった」と100回考えるより、「これからどうするか」を1回考える方が、よほど生産的だ。過去を受け入れろ。そして、これからの人生に全力で取り組め。私は自分の未熟さを認めた。媚びないことと無礼の区別がついていなかったことを認めた。では、これからどうするか。答えは明確だった。組織の現実を、ちゃんと見ることだ。私が見ようとしなかったもの。「政治」と呼んで嫌悪していたもの。でも、理解しなければ前に進めないもの。——組織の力学について、正面から向き合う時が来た。組織には「裏の顔」があるここで、現実を直視しよう。組織には、公式なルールと非公式な力学の2つが常に存在している。公式なルールは分かりやすい。組織図、職務権限、承認フロー、評価制度。これらは明文化されていて、誰でもアクセスできる。でも、それだけで組織が動いているわけではない。非公式な力学とは、「正式な手続きには定められていないが、意思決定や資源配分に影響を与える行動」のことだ。根回し、人脈、暗黙の了解、派閥、影響力のある人物——そういうものだ。私はこれを「汚いもの」だと思っていた。でも、違った。彼らは汚いのではなく、泥臭いだけだった。非公式な力学は「善悪」ではなく「手段」だ。根回しは悪いことか。場合による。自分の私利私欲のためなら問題だ。でも、良いプロジェクトをスムーズに通すためなら、むしろ必要なことだ。関係者の懸念を事前に把握し、対処しておく。それは「政治」ではなく「配慮」とも呼べる。私が嫌悪していたのは、「非公式な力学」そのものではなかった。それを私利私欲のために使う人間だった。でも、手段と目的を混同していた。手段自体は中立だ。それをどう使うかが問題なのだ。ここで1つ、大事なことを言っておく。非公式な力学を理解することと、それに迎合することは違う。力学を理解した上で、「自分はこの手段は使わない」と決めてもいい。でも、理解せずに無視するのは、ただの怠慢だ。敵を知らずに戦っているようなものだ。私は長い間、「政治を理解する」こと自体を拒否していた。理解したら、自分も「あっち側」になる気がした。でも、それは間違いだった。理解することと、加担することは違う。そして、「あっち側」の人たちは、別に悪者ではなかった。ただ、泥臭く仕事を通そうとしていただけだった。理解した上で、どう振る舞うかは自分で決められる。組織図を信じるな次に、私が痛い目を見た話をする。組織図に描かれた権限構造と、実際に物事を動かせる力は違う。あるプロジェクトで、私は承認を得るために、組織図上の決裁者に話を持っていった。正式なルートだ。決裁者は「いいんじゃない」と言った。私は安心した。プロジェクトは頓挫した。何が起きたか。決裁者は「いいんじゃない」と言ったが、実際に動く現場のキーパーソンは別にいた。その人は私の提案に反対だった。決裁者が「いい」と言っても、現場が動かなければ、何も進まない。私は組織図を信じすぎていた。「誰が決裁権を持っているか」と「誰が実際に物事を動かせるか」は違う。そして後から気づいたことがある。同じ提案でも、事前に相談していれば通っていた可能性が高い。あのキーパーソンに、会議の前に一度話を聞きに行っていたらどうだっただろう。「こういうことを考えているんですが、懸念点はありますか？」と。相手の観点や懸念が事前に分かれば、提案に反映できる。相手も「聞いてもらった」という感覚がある。「聞かされていない」は、「間違っている」より強い反対理由になる。内容の良し悪しではない。プロセスの問題だ。これは単なる感情論ではない。組織心理学では「手続き的公正」と呼ばれる概念がある。人は、結果だけでなく、そこに至るプロセスが公正かどうかを重視する。自分の意見を聞いてもらえた、自分も関与できたという感覚があれば、たとえ結果が自分の望み通りでなくても、受け入れやすくなる。逆に、プロセスから排除されたと感じると、結果が正しくても反発する。私が会議で潰された提案は、まさにこれだった。内容は正しかった。でも、関係者は「自分は聞かれていない」と感じた。関係者に事前の相談なく、いきなり会議の場で出したことが、「あなたの意見は聞く必要がない」というメッセージになっていた。それだけで、反対する十分な理由になった。技術的に正しいかどうかと、組織で通るかどうかは、別の問題だ。そして、事前に挨拶して、相談して、懸念を聞いておく——それだけで結果が変わることが、驚くほど多い。ここで、少し視点を変えた話をする。私は下っ端として組織図に騙されてきた。でも、ある時気づいた。上に立つ人間こそ、この罠にはまりやすいのだと。下っ端の経験が少ない若いCEOやCTOが率いる組織を見てきた。彼らは往々にして、表側の組織図ばかり意識する。そして、裏側の関係性——長年かけて築かれた非公式なネットワーク——を軽視して、ドラスティックな組織変更をする。「この部署とこの部署を統合しよう」「この人をあのチームに異動させよう」——組織図の上では合理的に見える。でも、その変更が裏のネットワークをぐちゃぐちゃにすることがある。誰と誰が信頼関係を築いていたか。どのルートで情報が流れていたか。誰が実質的なキーパーソンだったか。それを無視して箱だけ動かす。若い頃の私は、そういうリーダーを「革新的だ」「スピード感がある」と思っていた。古い慣習を壊して、新しい組織を作る。カッコいいと思っていた。大人になった今は、違う見え方をする。成果を出すために、下の人間が苦労している。壊された関係性を、現場が必死で繋ぎ直している。組織図の上では「改革成功」に見えても、実際は現場の努力で何とか回っているだけ。これは「組織図を信じるな」の裏返しだ。組織図だけを見て動く危険は、下っ端だけの問題ではない。リーダーが組織図だけを見て動くと、現場が壊れる。私が組織の裏側を理解しようとするようになったのは、こういう経験も影響している。組織図の裏にあるものを無視すると、どうなるか。それを見てきたからだ。では、「組織図の裏にあるもの」とは、具体的に何か。私はそれを「影のネットワーク」と呼んでいる。かっこいい名前をつけたいわけではない。組織図には描かれないが、確実に存在するもの。それを言語化するために、この言葉を使っている。そしてその核心は、役職とは別に存在する権力だ。権力とは、役職に基づく権限だけではない。反対や抵抗を乗り越えて物事を実現する力。人を惹きつけ、巻き込む力。意思決定に実質的な影響を与える力。これらは、役職とは別に存在する。例えば、古株のベテラン社員。役職は高くないが、社内の歴史を全部知っている。誰と誰が仲が悪いか、過去にどんなプロジェクトが失敗したか、どの部署が何を嫌がるか。その人を味方につけると物事がスムーズに進む。敵に回すと、見えない抵抗にあう。例えば、経営者の信頼が厚い若手。役職は低いが、経営者に直接話ができる。その人の意見は、なぜか上まで届く。私は、この「影のネットワーク」を読めていなかった。組織図だけを見て、「この人に話を通せばOK」と思っていた。でも、組織図の裏には、別のネットワークがあった。なぜ「影のネットワーク」が存在するのか。理由は単純だ。組織図は「権限」を示すが、「実行力」を示さない。決裁権を持つ人が「やれ」と言っても、実際に手を動かす人が動かなければ、何も起きない。そして、実際に手を動かす人を動かせるのは、必ずしも決裁権を持つ人ではない。組織が大きくなるほど、この乖離は広がる。決裁者は現場から遠くなり、現場の信頼関係は決裁者の目に見えなくなる。結果として、「承認されたのに進まない」「反対されていないのに協力が得られない」という現象が起きる。これは個人の悪意ではない。権限と実行力が分離している構造の問題だ。組織図の裏にある「影のネットワーク」を読み解け。どの提案に誰が反発するか。誰を味方につければ障壁を突破できるか。情報がどのルートで流れるか。これが見えるようになると、立ち回り方が変わる。ここで、私が学んだ具体的な方法を書いておく。1. 会議での反応を観察する誰かが発言したとき、他の人の表情を見る。賛成しているのか、本音では反対なのか、無関心なのか。言葉ではなく、表情や態度に本音が出る。2. 「あの人に聞いてみたら」の連鎖を追う何か新しいことを始めようとしたとき、「あの人に聞いてみたら」と言われる人がいる。その人が、実質的なキーパーソンだ。組織図上の役職とは関係ない。3. 過去の意思決定を遡る大きな決定が下されたとき、「誰がどの段階で関わっていたか」を調べる。公式の決裁者だけでなく、その前に相談されていた人。その人が、影響力を持っている。4. ランチや雑談の相手を観察する誰と誰がよく一緒にいるか。情報は公式のルートだけでなく、非公式の人間関係を通じて流れる。ここまでが「見る」段階だ。では、見えたものをどう使うか。観察した後にどうするか観察だけでは意味がない。観察した情報を、行動に変える必要がある。キーパーソンが分かったら、提案の前に一度相談に行く。反対しそうな人が分かったら、その人の懸念を先回りして潰す。情報のルートが分かったら、そのルートに自分の情報を流す。最初は気が重い。「なぜこんな面倒なことを」と思う。でも、一度やってみると、驚くほど物事がスムーズに進む。私も最初は抵抗があった。でも、「正しい提案が政治で潰される」ことに比べれば、事前の相談なんて些細な手間だと気づいた。私が変わるまでの話ここまで読んで、「分かったけど、やっぱり嫌だ」と思う人がいるだろう。「政治なんかしたくない」「実力で評価されるべきだ」「こんなことに時間を使いたくない」。その気持ちは分かる。私もそうだった。そして正直に言えば、今でも完全には割り切れていない。私が組織の力学をどう受け止めてきたか、正直に書く。最初は、拒絶していた。長い間、ずっとそうだった。「実力で評価されるべきだ」「政治をやる奴は汚い大人だ」「自分はそういうことはしない」。そう思っていた。この時期は、現実とのギャップに苦しんだ。「なんで自分より実力のないあいつが評価されるんだ」「この会社はおかしい」。怒りや失望があった。でも、状況は変わらなかった。居酒屋で同僚と愚痴を言っていた。「あいつは政治がうまいだけだ」「実力で勝負しろよ」。言うたびに少し楽になった。でも、翌日も同じ状況が続いた。全ての原因を外部に求めていた。自分が提案した新技術が却下されれば「老害が変化を恐れている」と憤り、レガシーコードの改修を任されれば「俺の才能の無駄遣い」と不満を漏らし、ドキュメント作成を頼まれれば「エンジニアの仕事じゃない」と文句を言う。でも振り返ってみれば明らかだ。問題は私自身にあった。技術的な正しさだけを追求し、ビジネス的な制約や組織の事情を理解しようとしなかった。転機があった。尊敬していた先輩が、根回しをしているのを見た。「あの人も政治をやるのか」と最初は失望した。でも、よく見ると違った。先輩は、良いプロジェクトを通すために、関係者の懸念を事前に聞いて回っていた。それは「政治」というより「配慮」だった。「政治」と「配慮」の境界は曖昧だ。私が嫌悪していた「政治」の中には、実は「配慮」も含まれていた。それに気づいてから、少し楽になった。組織の力学を「存在するもの」として認められるようになった。好き嫌いを超えて、「まあ、そういうものだよな」と思えるようになった。過度に振り回されない心理的安定が生まれた。今はどうか。正直に言う。私はまだ、完全には割り切れていない。根回しをすることに、今でも抵抗がある。「これは本当に必要なのか」「実力で勝負すべきじゃないのか」と思う。でも、必要な場面では、やるようになった。割り切れないまま、やっている。——と書いて、立ち止まる。私と同じように変われ、と言いたいわけではない。どこまで受け入れるかは、自分で決めていい。「存在は認めるけど、自分はやらない」でもいい。「存在を認めることすら嫌だ」なら、別の環境を探してもいい。ただ、組織の力学を拒絶し続けていると苦しい。現実と理想のギャップに消耗し続ける。だから、少なくとも「存在を認める」ところまでは進んだ方が、楽になる。その先は、自分で決めればいい。譲れないもののために、譲るものを決める「存在を認める」ところまで進んだとする。でも、それだけでは足りない。認めた上で、どう振る舞うか。全部受け入れるのか。全部拒否するのか。——どちらも違う。私が辿り着いた答えは、もっと戦略的なものだった。ここで、私が学んだ重要なことを書く。本質を守るために、形式では妥協する。やがて私は真剣に考えるようになった。自分が本当に譲れないものは何か？見極める基準は1つ。「あったらいいな」は捨てろ。「なくなったら壊れる」だけを守れ。私にとって譲れないのは3つだった。1つ目は技術的な誠実さ。嘘はつかない、質の低いコードは書かない。これを失ったら、自分を信頼できなくなる。2つ目はユーザーファースト。エンドユーザーの利益を最優先する。これを失ったら、仕事の意味を感じられなくなる。3つ目は継続的な学習。常に新しいことを学び続ける。これを失ったら、市場価値が消える。これ以外は、状況に応じて柔軟に対応することにした。表現方法やタイミングを妥協しても、私は壊れない。だから手放せる。表現方法では本音を建前でオブラートに包むようになった。タイミングも最適な時期を待つように。プロセスでは目的のためなら遠回りも受け入れ、形式的には無駄に見える会議や書類も必要なら対応するようになった。全てを守ろうとすると、全てを失う。なぜか。理由は単純だ。妥協できない領域が増えるほど、交渉の余地は減る。交渉の余地が減るほど、衝突は増える。衝突が増えるほど、消耗する。消耗すると、本当に守りたかったものまで守るエネルギーがなくなる。私は以前、表現方法でも、タイミングでも、プロセスでも、一切妥協しなかった。「正しいことを、正しいタイミングで、正しい方法で言う」——それが自分の信念だと思っていた。結果、毎回衝突し、毎回消耗し、最終的には技術的な誠実さすら保てなくなった。疲れ果てて、どうでもよくなったのだ。だから、何を守り、何を手放すかを決める。これが大人の戦略だ。以前は、「妥協＝敗北」だと思っていた。でも違った。戦略的な妥協は、本質を守るための手段だ。形式で妥協し、本質を守る。それは負けではない。むしろ、本当に大事なもののために、大事でないものを手放す勇気だ。したたかに生きる戦略「譲れないものを守り、それ以外では妥協する」——それは分かった。でも、正直に言えば、それだけでは物足りない。守りに入っているだけだ。もっと攻めの姿勢で、組織を「利用」することはできないのか。——そう考えるようになった。ここで、もう一歩踏み込んだ話をする。技術は手段であって目的ではない——組織から見れば、そうだ。でも正直に言えば、私自身は技術的な興味に駆動されている。新しい技術を学ぶことが楽しいし、エレガントなコードを書くことに喜びを感じる。ビジネス価値なんてどうでもよくて、ただ面白い技術を触っていたいだけ、というのが本音だ。でも、お金をもらって仕事をする以上、建前上それが主目的とは言いづらい。だからこそ「したたかにやろうぜ」という考え方が大切なのだ。つまり、組織が求める「成果」という枠組みを利用して、自分の技術的好奇心を満たすということ。表向きは「ビジネス価値の創出」を掲げながら、実際には「面白い技術で遊ぶ」ための正当性を確保する。例えば、「パフォーマンス改善」という大義名分のもとで、最新のフレームワークを導入する。「開発効率の向上」という建前で、面白そうなツールチェーンを構築する。「技術的負債の解消」という錦の御旗を掲げて、自分が書きたいようにコードを書き直す。重要なのは、これらの建前が単なる口実ではなく、実際に価値を生み出すことだ。新技術で遊びながら、本当にパフォーマンスを改善する。好きなツールを使いながら、実際に開発効率を上げる。コードを書き直しながら、本当に保守性を向上させる。ここで正直に告白しておく。私はこの戦略で失敗したことがある。「開発効率の向上」を名目に、面白そうなビルドツールを導入した。確かに面白かった。でも、チームの学習コストを甘く見積もっていた。結果として、効率は上がるどころか下がった。建前が嘘になった瞬間、「あいつは自分のことしか考えていない」という評価が下された。信頼を取り戻すのに、かなりの時間がかかった。したたかさの前提は、建前が本当に価値を生み出すことだ。建前が嘘になった瞬間、したたかさは不誠実に変わる。自分が楽しいかどうかではなく、本当に成果が出るかどうか。その見極めを間違えると、戦略は破綻する。「プロフェッショナルとして責任を果たします」と胸を張りながら、心の中では「やった！これで堂々とRustが書ける！」と小躍りする。この二重構造こそが、エンジニアとしてのしたたかさだ。ただし、小躍りする前に、本当に成果が出るかを冷静に見極めること。それを怠ると、私のように痛い目を見る。組織は成果を得て満足し、私たちは技術的満足を得る。Win-Winの関係を作り出すこと。それは決して不誠実ではなく、むしろ異なる価値観を持つ者同士が、お互いの利益を最大化する賢明な戦略なのだ。組織をハックしろ。建前で成果を出し、本音で技術を楽しめ。影響力は才能ではなくスキルだここまで「したたかにやれ」と書いてきた。「でも、自分は政治が苦手だ」という人がいるだろう。分かる。私もそうだった。というか、今でもそうだ。人の顔色を読むのが苦手だし、根回しは面倒くさいと思っている。でも、安心してほしい。影響力は先天的な才能ではなく、後天的に磨けるスキルだ。私も苦手だった。今でも得意とは言えない。でも、意識して練習することで、少しずつマシになった。組織における対人影響力は、5つの能力で構成されている。これらは「観察→洞察→共感→表現→一貫性」というプロセスで連鎖する。1. 観察——表面を見る最初の能力は観察だ。目の前で起きていることを正確に捉える。何を観察するか。言葉——誰が何を言ったか。態度——表情、姿勢、声のトーン。関係——誰と誰が近いか、誰が誰を避けているか。反応——ある発言に対して、他の人がどう反応したか。観察は受動的な行為に見えるが、意識しないとできない。会議で自分の発言に集中していると、他の人の反応を見落とす。発言を減らし、観察を増やす——これだけで得られる情報量は変わる。2. 洞察——本質を見抜く観察の次は洞察だ。表面の情報から、見えないものを推測する。洞察とは何か。動機を読む——この人は何を求めているのか、何を恐れているのか。構造を読む——この組織で、誰が実質的な力を持っているのか。文脈を読む——この議論は、どんな歴史の上に成り立っているのか。観察が「何が起きているか」を捉えるなら、洞察は「なぜ起きているか」を捉える。同じ事象を見ても、洞察の深さで解釈は変わる。表面的な反対意見の裏に、本当の懸念が隠れていることがある。3. 共感——相手の立場に立つ洞察の次は共感だ。相手の世界を、相手の視点から理解する。共感は「同意」ではない。相手の意見に賛成しなくても、相手がなぜそう考えるかを理解することはできる。「この人の立場なら、確かにそう思うだろう」——その理解があれば、対立は減る。エンジニアは共感を軽視しがちだ。論理が正しければ、相手の感情は関係ないと思っている。しかし、人は論理だけでは動かない。自分の立場を理解してくれていると感じたとき、初めて耳を傾ける。4. 表現——相手に響かせる共感の次は表現だ。自分の考えを、相手に届く形で伝える。表現の本質は「相手に合わせる」ことだ。論理で動く人には論理を。感情で動く人には感情を。利害で動く人には利害を。同じ提案でも、切り口を変えれば響き方が変わる。「伝える」と「伝わる」は違う。自分が言いたいことを言うのは「伝える」。相手が受け取れる形で届けるのが「伝わる」。影響力とは「伝わる」力だ。5. 一貫性——信頼を積む最後は一貫性だ。これが他の4つを支える土台になる。一貫性とは何か。言ったことを実行する。約束を守る。嘘をつかない。単純だが、最も難しい。なぜ難しいか。一貫性を保つには、「できない約束をしない」という自制が必要だからだ。期待に応えたくて、つい「やります」と言ってしまう。しかし、守れない約束は信頼を削る。「できません」と言える人の方が、長期的には信頼される。一貫性がなければ、観察も洞察も共感も表現も、すべて無駄になる。「あの人の言うことは当てにならない」——そう思われた瞬間、影響力は消える。これら5つは、すべて後天的に磨けるスキルだ。生まれつきの才能ではない。ただし、順番がある。土台となる「一貫性」がなければ、他の4つは機能しない。まず信頼を築き、その上に観察・洞察・共感・表現を乗せる。「専門性」と「人望」が最強のカードだここまで「組織の力学を理解しろ」「影響力を磨け」と書いてきた。でも、ここで安心してほしいことがある。最も持続する影響力は「専門性」と「人望」から生まれる。なぜそう言えるのか。少し整理してみる。人が他人を動かす力——影響力には、いくつかの種類がある。ソフトウェアエンジニアの現場で見かける例で説明する。報酬で動かす場合がある。「このリファクタリングを完了させたら、次のスプリントで好きな技術調査の時間をあげる」。評価で動かすこともある。「このタスクを断ったら、次の評価に響くよ」。役職で動かすパターンもある。「テックリードの判断だから、この設計で行く」。データで動かすこともできる。「ベンチマークの結果、この実装の方が30%速い」。そして、専門性で動かす場合がある。「Kubernetesのことなら〇〇さんに聞けば間違いない」。人望で動かす場合もある。「あの人が言うなら、きっと理由があるはず」。このうち、専門性と人望が最も強い。なぜか。この2つは、相手が「自分から納得して動く」ときに生じるからだ。報酬・評価・役職で動かす場合、相手は「仕方なく」動いている。上司が変わったり、評価制度が変わったりすれば、その影響力は消える。「テックリードが言うから従う」で動いていたチームは、テックリードがいなくなれば元に戻る。専門性と人望で動かす場合、相手は「この人の言うことだから」と自分から動いている。その人がいなくなっても、「あの人ならどう判断するだろう」と考え続ける。影響が内面化されている。外からの圧力で動いた行動は、圧力がなくなれば止まる。内側から納得して動いた行動は、続く。ただし、注意点がある。どのカードが強いかは、組織や部署によって違う。エンジニアだけの組織では、データが圧倒的に強い。「ベンチマークの結果」「障害の根本原因分析」「パフォーマンス計測」——数字で示せば、それだけで説得力がある。論理と数字を重視する文化があるからだ。でも、営業部門やマーケティング部門では違う。データより「この人が言うなら」という人望が効くことがある。経営層との会議では、役職や過去の実績が重みを持つ。同じ会社でも、部署が変われば有効なカードは変わる。私はエンジニア組織にいることが多いので、データと専門性に頼りがちだ。でも、他部署との調整では、それだけでは通用しないことを何度も経験した。相手が何を重視するかを見極めて、カードを使い分ける必要がある。だから、長期的な影響力を構築するなら、専門性を磨き、人として尊敬される存在になることが最も確実な方法だ。専門性と人望は、どの組織でも比較的通用しやすい。「政治力を磨け」と言われると抵抗がある人も、「専門性を磨け」なら抵抗がないだろう。実は、専門性を磨くことは、組織における影響力を高める最も正攻法なアプローチなのだ。ここで、私の経験を1つ書いておく。ある領域で、私はチームの中で一番詳しくなった。別に政治をしたわけではない。ただ、その領域を深掘りし続けた。ドキュメントを読み、実験し、知見を共有した。すると、向こうから相談が来るようになった。「〇〇のことは△△さんに聞けばいい」という評判が立った。会議で発言すると、その領域については私の意見が尊重されるようになった。これは「政治」ではない。専門性による影響力だ。ただし、専門性を万能視するのは危険だ。限界もある。具体的に言おう。専門性が効くのは「その領域の意思決定」に限られる。組織全体の方向性、予算配分、人事——こういった領域横断的な意思決定では、専門性だけでは戦えない。私も経験がある。技術的な判断では尊重されるようになったが、プロジェクトの優先順位を決める会議では、相変わらず発言力がなかった。専門性は「深さ」を与えるが、「広さ」は別の力学で決まる。それでも、専門性があれば、政治力が弱くても、ある程度は戦える。少なくとも、自分の専門領域では発言権が得られる。そこを足がかりにして、徐々に影響力を広げていくことができる。だから、「政治が苦手だ」という人に言いたい。まず専門性を磨け。それが最も確実な道だ。政治力は、専門性という土台の上に乗せるオプションとして考えればいい。土台がないまま政治力だけ磨いても、長続きしない。組織と踊るための心構え最後に、心構えの話をする。おい、頑張るなら組織と踊れ。これは「組織に従属しろ」という意味ではない。ダンスは、相手の動きを感じながら、自分も動く。一方的にリードするわけでも、一方的にフォローするわけでもない。相手と自分の動きが調和して、初めてダンスになる。組織も同じだ。組織の力学を無視して突っ走ると、壁にぶつかる。かといって、組織に完全に従属すると、自分の意志がなくなる。組織の力学を理解し、その中で自分の目標を追求する。組織を動かしながら、自分も動く。これが「組織と踊る」ということだ。組織を敵視するな。かといって、盲従するな。組織は、自分の目標を達成するためのプラットフォームだ。うまく使えば、一人ではできないことができる。敵視していたら、使いこなせない。短期の勝ち負けにこだわるな。組織での影響力は、長期的に築くものだ。一回の会議で勝った負けたは、大した問題ではない。信頼の蓄積、専門性の蓄積、関係性の蓄積。これらが時間をかけて積み上がったとき、本当の影響力が生まれる。自分の価値観を失うな。組織の力学を理解し、活用することと、自分の価値観を捨てることは違う。「この方法は使えるけど、自分はやりたくない」と思うなら、やらなくていい。別の方法を探せばいい。「媚びない」ことと「無礼」であることは全く違う。前者は信念を持つことであり、後者は単なる社会性の欠如だ。同様に、「したたか」であることと「ずる賢い」ことも違う。前者は双方の利益を最大化する戦略的思考であり、後者は単なる利己主義だ。私は今でも、根回しに抵抗がある。でも、必要な場面ではやる。やりながら、「これでいいのか」と自問する。割り切れないまま、やっている。組織と踊るというのは、自分を殺すことではない。自分を活かしながら、組織の中で成果を出す方法を見つけることだ。その方法は、人によって違う。自分なりの踊り方を見つければいい。届かない人へここまで書いてきて、立ち止まる。「組織の力学を理解しろ」「影響力を磨け」「組織と踊れ」——私はそう書いた。でも、この記事には前提条件がある。この記事が有効なのは、以下の条件が揃っている場合だ。組織がまともである——努力が報われる余地がある自分にエネルギーがある——行動を起こす余力がある組織で働くことを選んでいる——別の選択肢を選んでいないこの前提が成り立たない場合、この記事は役に立たない。それぞれ見ていく。組織が合わない人がいるそもそも、組織で働くことが向いていない人がいる。組織の力学を理解しろと言われても、理解する気力がない。人間関係を築けと言われても、それ自体がストレスだ。会議で発言しろと言われても、声が出ない。彼らは「能力がない」のではない。組織という形態が合わないのだ。フリーランス、起業、小規模チーム、リモートワーク——組織以外の働き方もある。そちらが合う人もいる。「おい、頑張るなら組織と踊れ」は、組織で働くことを前提としている。その前提自体が合わない人には、この記事は届かない。力学を理解しても動けない人がいる組織の力学を理解した。影響力を磨く方法も分かった。でも、動けない。すでに消耗している人。根回しをする気力がない人。人間関係を築くエネルギーがない人。彼らに「影響力を磨け」と言っても、無理だ。まず休む必要がある。構造的に無理な組織もあるどんなに力学を理解しても、どんなに影響力を磨いても、無理な組織もある。腐敗した評価制度。声の大きい人だけが勝つ文化。変える気のない経営層。そういう組織では、個人の努力で変えられることに限界がある。「組織と踊れ」と言っても、相手がダンスをする気がないなら、成立しない。この記事は、「組織がまともで、自分にエネルギーがある」ことを前提にしている。その前提が成り立たないなら、この記事は役に立たない。「踊らない」という選択肢もある「組織と踊る」ことを選ばない、という選択肢もある。専門性だけで勝負する。政治には一切関わらない。評価されなくても気にしない。自分のペースで、自分のやり方で働く。それは「負け」ではない。評価ゲームから意識的に降りるという戦略だ。「おい、辞めないなら頑張れ」で書いたことを繰り返す。頑張れないなら、頑張らなくていい。降りてもいい。休んでもいい。それも、1つの選択だ。おわりに「おい、辞めるな」で辞めないことを選んだ。「おい、辞めないなら頑張れ」で頑張り方を学んだ。そして今回、「おい、頑張るなら組織と踊れ」で組織の力学を学んだ。正直に言う。この記事を書くことには抵抗があった。「政治のやり方を教える」みたいで、気が進まなかった。でも、過去の自分は、これを知りたかった。組織の力学を理解せず、「政治は汚い」と嫌悪しながら、壁にぶつかり続けていた。正義のエンジニアという幻想に囚われて、媚びないことと無礼を混同していた。その時間は、もったいなかった。組織の力学を理解しろ。でも、専門性と人望が最強のカードだ。政治に長けていても、実力がなければ長続きしない。実力があっても、組織の力学を無視していたら成果につながらない。両方必要だ。でも、長期的に見れば、専門性と人望が最も確実な道だ。譲れないもののために、譲るものを決めろ。したたかに生きろ。組織を敵視するな。盲従するな。組織と踊れ。——と書いて、自分でも苦い顔をしている。「お前も結局、体制に飲み込まれたのか」——かつての私なら、今の私をそう批判しただろう。しかし、それでいいのだ。技術的な純粋さを追求することと、社会的な成熟を遂げることは矛盾しない。むしろ、両方を兼ね備えてこそ、プロの仕事と言えるのではないだろうか。媚びないことと無礼の区別がつかなかった、頭の悪い反抗期は終わった。正直に言えば、私はまだ上手に踊れていない。根回しに抵抗がある。状況認識力が弱い。会議で空気を読めない。それでも、以前よりはマシになった。壁にぶつかる回数は減った。この記事が、かつての私のような人に届けばいいと思う。「政治は汚い」と思いながら、壁にぶつかり続けている人。組織の力学を理解することに抵抗がある人。「正義のエンジニア」という幻想に囚われている人。理解することと、加担することは違う。理解した上で、どう振る舞うかは自分で決められる。おい、頑張るなら組織と踊れ。踊れないなら、休め。踊り方は、自分で決めろ。——と、ここまで書いてきた。でも、最後に付け加えておく。組織が合わないなら、別の場所を探せばいい。それも、1つの選択だ。私も、まだ上手に踊れていない。それでも、やっている。それでいいのだと思う。かつての私のような若いエンジニアを見かけたら、優しく、でもはっきりと伝えたいと思う。「君の気持ちはよく分かる。でも、もっといい方法があるよ。一緒にしたたかにやっていこうぜ」と。多分昔の私だったら「は？日和って迎合した負け犬が何言ってんの？」とか思って、心の中で見下しながら表面上は「はい、参考にします」って適当に流すんでしょうね。まあ、それでいいんです。私も通った道だから。痛い目に遭うまで、人は変われない。私もそうだった。その時になって初めて、この言葉の意味が分かるはずです。けど大人として言う義務があるので言っておきました。参考書籍人を動かす　改訂文庫版作者:Ｄ・カーネギー創元社AmazonDD(どっちもどっち)論 「解決できない問題」には理由がある (WPB eBooks)作者:橘玲集英社Amazonその仕事、全部やめてみよう――１％の本質をつかむ「シンプルな考え方」作者:小野 和俊ダイヤモンド社Amazonアーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazonこれからの「正義」の話をしよう ──いまを生き延びるための哲学 (ハヤカワ・ノンフィクション文庫)作者:マイケル・サンデル早川書房AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonモンク思考―自分に集中する技術作者:ジェイ・シェティ東洋経済新報社AmazonSOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazon多様性の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon［新版］組織行動の考え方―個人と組織と社会に元気を届ける実践知作者:金井 壽宏,高橋 潔,服部 泰宏東洋経済新報社Amazonソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社AmazonTHE CULTURE CODE 最強チームをつくる方法作者:ダニエル・コイル,楠木建かんき出版Amazon","isoDate":"2026-01-19T00:01:19.000Z","dateMiliSeconds":1768780879000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"プログラミングが好きな人こそ今の時代、プログラマーになる方がいいと思う。- 「プログラミングが好きな人は、もうIT業界に来るな。」を読んで","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/18/123151","contentSnippet":"はじめにAIにリサーチをさせていた。結果が返ってくるまで数分かかる。待っている間、Xを開いた。流れてきたタイトルに、手が止まった。「プログラミングが好きな人は、もうIT業界に来るな。」note.comリサーチは終わっていた。結果を確認しないまま、記事を読んでいた。小学生の頃から黒い画面に向かい続けてきたエンジニアが、生成AIの登場によって「自分の手で作る喜び」を奪われつつあると語っていた。「心の中で何かが音を立てて崩れる」という表現があった。共感したのか、と聞かれると困る。共感しなかったのか、と聞かれても困る。たぶん、どちらでもある。読み終えて、エディタに戻った。さっきまで何をしていたか、思い出せなかった。反論したいわけではなかった。ただ、何かが引っかかっていた。「プログラミングが好き」という言葉だ。この人の「好き」と、私の「好き」は、同じものを指しているのだろうか。コーヒーを淹れた。飲みながら、書くことにした。「好き」の中身を分解する元記事の筆者と私の違いは、能力でも経験でもない。「プログラミングが好き」という言葉が指す範囲が違うのだ。言葉は同じでも、中身が違う。「好き」と言ったとき、何を思い浮かべているか。キーボードを叩く指先か、頭の中で組み上がる構造か、動いた瞬間の達成感か。同じ「好き」でも、その中身は人によって違う。中身が違えば、奪われるものも違う。プログラミングという行為には、少なくとも3つのレイヤーがある。——もちろん、これは私の視点からの便宜的な分類だ。元記事の筆者にとっては、まったく別の分け方があるかもしれない。「書くこと」と「考えること」は分離できない、という人もいるだろう。書きながら考える。考えながら書く。その不可分さこそがプログラミングだ、と。それでも、ここでは一旦この枠組みで話を進める。身体感覚：キーボードを叩く感触、コードを書く行為そのもの、画面に流れる快感知的作業：問題を分解し、設計し、実装する思考プロセス創造行為：何かを作り、動かし、世に出す達成感元記事の筆者が愛していたのは、単なる身体感覚ではないように思う。「自分の指先から生まれるロジックが、動かなかったものを動かす」——その創造の主体性だ。自分の手で書いたコードが動く。その実感が奪われたから「楽園が消えた」と感じている。AIが書いたコードをチェックする「検品係」では、創造の主体は自分ではない。これは「間違った好き」ではない。彼の文脈では、それが正解だった。小学生の頃から黒い画面に向かい続け、自分の手でコードを書くことで世界を動かしてきた。その積み重ねの上に立っている。私が「設計が好き」と言えるのも、私の文脈があるからだ。どちらが正しいという話ではない。私が好きだったのは、2だった。課題があったら適切なサイズに分割して、「この問題はこう実装すれば解決するな」と構造が頭の中で閃く。そこからコードを書き続けていく。その一連のプロセスが好きだった。AIがコードを出力するようになって初めて、自分の「好き」が何だったのか見えた。コードを書けなくなったとき、喪失感を感じたか？ 感じなかった。むしろ「これで設計に集中できる」と思った。そのとき気づいた。自分が好きだったのは、タイピングではなく、考えて、作って、また考える、その繰り返しだった。では、何が奪われ、何が残ったのか整理しよう。奪われたもの：タイピングの時間、実装の試行錯誤、ググって解決策を探す時間。残ったもの：設計を考える時間、AIの出力を評価する時間、「もっと良い方法はないか」と考える時間。私にとって、後者こそがプログラミングの核心だった。もっと言えば、コードを書く時間に追われて後回しにしていた「設計」や「トレードオフの検討」——いわゆるソフトウェアエンジニアリングの領域に、ようやく時間を使える。だから、「奪われていない」と言い切れる。実践ソフトウェアエンジニアリング (第9版)作者:ロジャー・プレスマン,ブルース・マキシムオーム社AmazonGoogleのソフトウェアエンジニアリング ―持続可能なプログラミングを支える技術、文化、プロセス作者:Titus Winters,Tom Manshreck,Hyrum WrightオライリージャパンAmazon正直に言う、めちゃくちゃ楽しい今、めちゃくちゃ楽しい。作りたいものがある。指示を出す。コードが出てくる。レビューする。直す。動く。——以前なら「面倒だな」と後回しにしていたアイデアや知識が、数分で形になる。さっき書いた「ソフトウェアエンジニアリングの領域」——設計、トレードオフ、アーキテクチャ。そこにやっと向き合えている感覚がある。楽しい。素直に、楽しい。これを「検品係」と呼ぶなら、私は世界一楽しい検品係だ。コードレビューが好きで良かった思えば、私はコードレビューが比較的好きだった。他人のコードを読んで、「この人はこう考えてるんだろうな」というのが見えると嬉しい。なぜこの設計にしたのか、どこで迷ったのか。コードの向こうに思考が透けて見える瞬間が好きだった。知らない言語機能や、思いつきもしなかった構造で課題を解決しているのを見ると、良し悪しにかかわらず楽しい。正解かどうかより、発見の方が全然面白い。正解とは常に文脈の中にしかない。チームの習熟度、プロダクトのフェーズ、パフォーマンス要件、保守する人間の数。同じ課題でも、文脈が変われば最適解は変わる。だから「このコードは正しいか」という問いより、「この文脈でなぜこう書いたのか」という問いの方が面白い。そして、その問いに答えようとする過程で、自分の中の「正解」も揺らぐ。揺らぐことが学びだ。AIが出力したコードをレビューしていると、これが想像以上に勉強になる。先日、AIに「CSVパーサーを書いて」と頼んだ。返ってきたコードを見て驚いた。私なら正規表現でゴリ押しするところを、状態機械で書いている。エスケープ処理も完璧だ。「なるほど、このアプローチがあったか」と笑った。逆に、「いや、これは現場では使えない」と思う瞬間もある。過剰に抽象化されていたり、エラーハンドリングが甘かったり。その判断力こそ、レビューを通じて研ぎ澄まされる。——もっとも、私の判断が正しいとは限らない。AIの提案を「使えない」と却下した翌週、まったく同じアプローチを別の記事で「ベストプラクティス」として紹介されているのを見たこともある。ただ、これは15年やってきた人間だから言えることだ。状態機械の良さが分かるのは、正規表現ゴリ押しで痛い目を見たことがあるからだ。「なるほど、このアプローチがあったか」と唸れるのは、比較対象を持っているからだ。経験ゼロの人がAIの出力から体系的に学べるかは、正直分からない。むしろ、学べない可能性の方が高い気がする。コードレビューが苦手な人には、AIとの協働は苦行かもしれない。でも、レビューが好きな人間にとっては、無限に相手がいるジムのようなものだ。疲れない、休まない、いつでも付き合ってくれる相手。しかも、毎回違うアプローチを見せてくれる。「検品」と「協働」の違い元記事は「検品係になった」と嘆いている。創造の主体でありたかった人にとって、この表現は正確だと思う。自分が書きたかったコードを他者（AI）が書き、自分はそれをチェックするだけ。主体と客体が入れ替わっている。ただ、私の場合は少し違った。携帯電話は私のことをめちゃくちゃ記憶している。連絡先、スケジュール、位置情報、検索履歴。私より私のことを知っているかもしれない。でも、携帯電話を使っているとき、「主体を奪われた」とは感じない。道具として使っている感覚がある。生成AIは違う。コードを書く、文章を書く、設計を考える——これまで「私がやること」だった領域に、AIが入り込んでくる。携帯電話が記憶を代替しても主体性は揺らがなかったが、生成AIは創造を代替しようとする。だから主体性が脅かされる感覚が生まれる。それでも、私は自分が主体だと思っている。なぜか。www.youtube.com答えは、関わり方にある。「検品」と「協働」の違いは何か。検品は受動的だ。ラインを流れてくる製品をチェックし、不良品を弾く。渡されたものをチェックするだけ。協働は能動的だ。方向性を示し、フィードバックを与え、成果物を一緒に作り上げる。私がAIとやっているのは後者だ。具体的に言うと——「こういう設計で書いて」と指示を出す（方向性）出てきたコードを見て「ここはこう直して」とフィードバックする「いや、アプローチ自体を変えよう」と軌道修正する最終的な成果物が完成するこのやりとりは、人間同士のペアプログラミングと構造的に同じだ。相手が人間かAIかの違いしかない。検品係は受け身だが、私は能動的にAIを導いている。方向を決め、判断を下し、軌道修正をかける。この能動性が、主体性を保つ鍵だ。AIとの関係を一言で表すなら、「相棒」ではなく「優秀だが判断できない後輩」が近い。指示を明確にすれば良い仕事をする。曖昧にすると、意図しないものが返ってくる。筆者が言うように、書く時間は減った。でも、考える時間は増えた。どう分割するか。どう設計するか。AIが出してきたコードのどこを採用し、どこを直すか。そして、仮にこれが「検品」だったとしても、私はその過程でかなり学んでいる。「こんな書き方があるのか」と何度も唸った。特に経験の浅い言語では顕著だ。自分で書いていたら絶対に思いつかないイディオムを、AIは平気で出してくる。検品のつもりが、いつの間にか授業を受けている。ただし、ここには落とし穴がある。AIが出したコードをそのまま使って「動いた、終わり」で済ませると、何も残らない。効率は上がる。成果も出る。でも、1週間後に「なぜこう書いたの？」と聞かれても、答えられない。因果を辿れない。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。以前、「AIエージェントと協働しながら学習する方法」という記事で詳しく書いたが、学びには「摩擦」が必要だ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わる。学習とは、経験を意味に変換する行為だ。AIが摩擦を消してくれると、経験が意味に変わる機会も消える。syu-m-5151.hatenablog.comだから私は、AIが出したコードを「なぜこう書いたのか」と考える時間を意図的に作っている。効率だけを求めるなら不要な時間だ。でも、この「不効率な時間」が学びを生む。摩擦は削減対象ではない。設計対象だ。何を学び、何を省略するか。その選択を自分でしている限り、主体は私だ。これを「検品」と呼ぶか「協働」と呼ぶかは、本人の姿勢次第なのかもしれない。——と書いて、自分で読み返して思った。「姿勢次第」では何も言っていないのと同じだ。具体的に、検品を協働に変えるための3つのポイントを挙げてみる。意図を言語化する: 「こう書いて」ではなく「この問題を解決したい。制約はこれ」と伝える。AIに考えさせる余地を残す。出力から学ぶ: AIが出したコードを「動くかどうか」だけでなく、「なぜこう書いたか」を考える。知らないパターンがあれば調べる。フィードバックを重ねる: 一発で完璧を求めない。「ここを直して」「いや、やっぱりこっち」のやりとりを楽しむ。この3つができれば、検品は協働になる。逆に言えば、「動くか確認するだけ」なら、それは検品だ。この3つを実践するかどうか。それが検品と協働を分け、主体性を保てるかどうかを分ける。——と偉そうに書いたが、これが「正解」かどうかは分からない。私の文脈ではうまくいっている。でも、別の文脈では別の答えがあるはずだ。締め切りに追われているときは「動けばいい」になるし、疲れているときは「なぜこう書いたか」なんて考えない。理想と現実は違う。ただ、「こうありたい」という指針があるのとないのとでは、違うと思っている。それすらも、私の文脈での話だ。ただし、これは私のケースだここまで書いてきて、一つ断っておきたいことがある。これは私の話だ。コードレビューが好きで、設計を考えるのが好きで、タイピング速度に自信がなかった人間の話だ。もし元記事の筆者のように、「自分の手で書いたコードが動く」その実感こそが喜びだったなら——この記事は何の慰めにもならないだろう。創造の主体でありたかった人に、「検品も楽しいよ」とは言えない。その人たちに「考え方を変えろ」と言うつもりはない。「自分が書きたかった小説をAIに書かせ、誤字脱字を直す校正者のような気分」——元記事のこの表現は、痛いほど分かる。創造の主体性を奪われた感覚は、姿勢や考え方でどうにかなるものではない。彼の文脈では、それが真実だ。私が「楽しい」と言えるのは、私の文脈がたまたまそうだったからに過ぎない。「でも、結局プログラマーの仕事は減るのでは？」という反論もあるだろう。正直、分からない。AIの進化は私の想像を超えている。5年後にどうなっているか、予測する自信がない。そして、ここは誤魔化さずに言っておくべきだと思う。「楽しい人がいること」と「職業として持続可能かどうか」は、まったく別の話だ。ドライバーが100人必要だった時代から、10人で済む時代へ。私が楽しくても、市場が縮小すれば、その楽しさを職業にできる人は減る。元記事の筆者が問うているのは、たぶんそっちの話でもある。この問いについて、エンジニアに許された特別な時間の終わりというスライドがある。エンジニアがドライバー席から助手席へ移る時代が来ている、という話だ。AIが「副操縦士（Copilot）」から「操縦士（Pilot）」へ進化しつつある。続編のたかが特別な時間の終わりでは、9ヶ月後にその予測が現実化しつつあると報告されている。私がこの記事で書いてきた「協働」も、結局は助手席からの関わり方なのかもしれない。ドライバー席に座っていた時代は終わりつつある。それでも、助手席には助手席の仕事がある。呑気なドライブデートを思い浮かべたかもしれないが、全然様相は違う。ラリーのコ・ドライバーは、ただ座っているだけではない。本番前にコースを試走し、コーナーの角度、直線の距離、路面の状態、危険なポイントをすべてペースノートに書き込む。本番では猛スピードで揺さぶられる車内で、そのノートを絶妙なタイミングで読み上げる。「左3、50m、右2、クレスト注意」。ドライバーは全コースを暗記できない。コ・ドライバーなしでは走れない。AIとの協働も似ている。事前にコードベースを把握し、設計を考え、制約を整理する——これがペースノートの作成だ。本番では、AIが猛スピードでコードを生成する中、「次は右だ」「ここは危険だ」と指示を出し続ける。曖昧な指示を出せば、車は崖から落ちる。ただし、その車は時速200kmで走っている。のんびり景色を眺める余裕はない。コ・ドライバーとして生きる。それがこの時代の選択だ。——と書いたが、この比喩にも限界がある。ラリーではコ・ドライバーの仕事がなくなることはない。しかし、AIとの協働では、その保証がない。今は「設計」「評価」「判断」が人間の仕事として残っている。だが、AIが設計し、AIが実装し、AIがレビューする世界が来たら？ コ・ドライバーの席さえ、自動運転に置き換わるかもしれない。この記事は「設計や評価は人間に残る」という前提で書いている。その前提が崩れたら、私の話は無効になる。ただ、「だから今やっても意味がない」とは思わない。今この瞬間、プログラミングが楽しいなら、それでいい。未来のことは、未来の自分が考える。——もっとも、この「楽しい」を大声で言うのは少し気が引ける。誰かが失った「楽しさ」の上に、私の「楽しさ」が成り立っているかもしれないからだ。元記事の筆者が読んだら、どう思うだろう。「お前はたまたま運が良かっただけだ」と言われたら、反論できない。おわりに書き終えて、コーヒーを淹れ直した。冷めていた。あの日から何日か経った。書いている間、ずっと考えていた。私は本当に「楽しい」のか。それとも、楽しいと思いたいだけなのか。正直、分からない。分からないまま書いた。元記事の筆者が読んだら、どう思うだろう。「お前はたまたま運が良かっただけだ」と言われるかもしれない。反論できる気がしない。私の「好き」と、あの人の「好き」は、たまたま違った。彼の文脈では彼が正しく、私の文脈では私が正しい。それだけのことだ。どちらかが間違っているわけではない。明日もたぶん、AIにコードを書かせる。レビューする。直す。動かす。それを「楽しい」と感じるかどうかは、そのときになってみないと分からない。ただ、少しだけ違うことがある。「プログラミングが好き」という言葉を使うとき、自分が何を指しているのか、前より意識するようになった。摩擦は削減対象ではない。設計対象だ。——この言葉を、自分に言い聞かせるようになった。そして、自分の「正解」も揺らぐことを知った。書く前と書いた後で、考えが変わっている。元記事の筆者の気持ちが、前より分かる気がする。揺らぐことが学びだと書いた。この記事を書くこと自体が、そうだった。「IT業界に来るな」と言われた君へ。私は「来い」とは言わない。言えない。生成AIがいつか道具になる日までは。ただ、私は来てよかった。少なくとも、今日は。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。技術が人類を幸せにするかみたいな問いは常に面白いです。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon","isoDate":"2026-01-18T03:31:51.000Z","dateMiliSeconds":1768707111000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Ory Kratosで認証を委譲する","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/14/140248","contentSnippet":"前回からの続き前回の記事では、Playwright MCPを使ったE2Eテストで5つのバグを発見した。CORS設定の欠如、JWTトークンの切り詰め、Hydraトークンとの不一致、ミドルウェアの適用漏れ、X-Tenant-Slugヘッダーの欠如。RBACの検証とOWASP Top 10との比較まで行い、マルチテナント認証システムが一通り動くようになった。前提知識: この記事はOry Hydraシリーズの続編です。OAuth2認可コードフローの基礎知識と、Login/Consent Providerの役割を理解している前提で進めます。前回記事はこちら。動く。ちゃんと動く。でも、レビューコメントが気になった。「パスワードリセット機能は？」「MFA対応の予定は？」「メール確認フローは？」全部、自分で実装しなければならない。Argon2idでパスワードをハッシュ化するコードは書いた。ログイン認証は動く。でも、パスワードを忘れたユーザーへのリセットメール送信、そのトークン管理、有効期限の検証。TOTPによる二要素認証。メールアドレス確認のフロー。これ全部、自分で実装するのか？RFCを読んでいたあの3日間を思い出した。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。同じ結論に至った。今度は認証機能についてだ。Ory Kratosという選択肢www.ory.shgithub.comOry Kratosは「ヘッドレスID管理システム」だ。Hydraが「認証をしない認可サーバー」だったことを思い出してほしい。Hydraはプロトコル層（OAuth2/OIDC）に特化し、認証は私たちに任せた。Kratosはその「任された認証」を担当する。┌─────────────────────────────────────────────────────────────┐│                     Ory Stack                               │├────────────────────────┬────────────────────────────────────┤│      Ory Kratos        │           Ory Hydra                ││   (Identity Provider)  │      (Authorization Server)        │├────────────────────────┼────────────────────────────────────┤│ - ユーザー登録         │ - OAuth2/OIDC                      ││ - ログイン認証         │ - トークン発行                     ││ - MFA (TOTP, WebAuthn) │ - クライアント管理                 ││ - パスワードリセット   │ - Consent管理                      ││ - プロフィール管理     │ - セッション管理                   ││ - メール確認           │                                    │└────────────────────────┴────────────────────────────────────┘つまり、これまでに私がRustで書いたAuthService——パスワード検証、ユーザー登録、セッション管理——これらをKratosに任せられる。アーキテクチャの変化これまでの構成を振り返る。【01-03の構成】┌─────────────┐     ┌─────────────────────┐     ┌─────────────┐│   Browser   │────▶│ Rust Login Provider │────▶│  Ory Hydra  ││             │     │ (自前実装)           │     │             │└─────────────┘     └─────────────────────┘     └─────────────┘                              │                              ▼                    ┌─────────────────────┐                    │ PostgreSQL (users)  │                    └─────────────────────┘私が書いたRust Login Providerは認証を担当していた。ユーザーテーブルも自前で管理していた。Kratosを導入すると、こうなる。【Kratos導入後の構成】┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Browser   │────▶│  Kratos UI  │────▶│  Ory Kratos │────▶│  Ory Hydra  ││             │     │  (Node.js)  │     │             │     │             │└─────────────┘     └─────────────┘     └──────┬──────┘     └─────────────┘                                               │                                               ▼                                      ┌─────────────────────┐                                      │ PostgreSQL          │                                      │ (identities)        │                                      └─────────────────────┘私が書くコードは、ほぼゼロになる。パスワード検証、ユーザー登録、セッション管理——これまでに私がRustで実装した機能は、全てKratosが提供する。私が書くのはKratosの設定ファイルと、必要に応じたUIのカスタマイズだけだ。「それって、学習した意味がないのでは？」いや、逆だ。認証システムを自前で実装した経験は、Kratosの設定を理解する上で役立った。例えば、Kratosの設定にhashers.argon2.memory: 128MBという項目がある。自前実装の経験がなければ、その意味を理解できなかっただろう。メモリコストを上げればセキュリティは向上する。しかし同時接続数の増加でOOMのリスクも上がる——この判断ができるのは、OWASPのドキュメントを読み、自分でパラメータを選んだ経験があるからだ。「ドキュメントを読めば同じでは？」——そう思うかもしれない。確かに、ドキュメントを読めば設定はできる。しかし、障害時に「この設定が原因かもしれない」と仮説を立てられるのは、自分で同じ問題に苦しんだ経験があるからだ。ログを見て「これはセッション固定化攻撃への対策が発動した」と判断できるか。エラーメッセージから「Identity Schemaの定義が間違っている」と気づけるか。これは学習効率の問題ではなく、デバッグ能力の問題だ。これまでの実装で、認証システムの複雑さを体験した。Argon2idのパラメータ設定、ユーザー列挙攻撃への対策、セッション管理の罠。58個のテストを書いて「できないこと」を確認した。だからこそ、Kratosのありがたみが分かる。そして、Kratosで問題が起きたときに対処できる。全員が自前実装を経験すべきとは言わない。しかし、チームに1人は「中身を理解している人」がいた方がいい。Docker Composeで動かすwww.ory.com実際に動かしてみよう。services:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: postgres      POSTGRES_PASSWORD: secret      POSTGRES_DB: postgres    volumes:      - postgres_data:/var/lib/postgresql/data      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro  # 後述の初期化スクリプト    healthcheck:      test: [\"CMD-SHELL\", \"pg_isready -U postgres -d postgres\"]      interval: 5s      timeout: 5s      retries: 5    networks:      - ory  kratos-migrate:    image: oryd/kratos:v1.3.1    environment:      DSN: postgres://postgres:secret@postgres:5432/kratos?sslmode=disable    volumes:      - ./kratos:/etc/config/kratos:ro    command: migrate sql -e --yes --config /etc/config/kratos/kratos.yml    depends_on:      postgres:        condition: service_healthy    networks:      - ory  kratos:    image: oryd/kratos:v1.3.1    environment:      DSN: postgres://postgres:secret@postgres:5432/kratos?sslmode=disable      LOG_LEVEL: debug      SERVE_PUBLIC_BASE_URL: http://localhost:4433      SERVE_ADMIN_BASE_URL: http://localhost:4434    volumes:      - ./kratos:/etc/config/kratos:ro    command: serve all --dev --config /etc/config/kratos/kratos.yml    ports:      - \"4433:4433\"  # Public API      - \"4434:4434\"  # Admin API    depends_on:      kratos-migrate:        condition: service_completed_successfully    healthcheck:      test: [\"CMD\", \"wget\", \"-q\", \"--spider\", \"http://localhost:4433/health/ready\"]      interval: 10s      timeout: 5s      retries: 5    networks:      - ory  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://postgres:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy    networks:      - ory  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://postgres:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:4455/consent      URLS_LOGIN: http://localhost:4455/login      URLS_LOGOUT: http://localhost:4455/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - \"4444:4444\"  # Public API      - \"4445:4445\"  # Admin API    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: [\"CMD\", \"wget\", \"-q\", \"--spider\", \"http://localhost:4444/health/ready\"]      interval: 10s      timeout: 5s      retries: 5    networks:      - ory  kratos-ui:    image: oryd/kratos-selfservice-ui-node:v1.3.1    environment:      PORT: 4455      KRATOS_PUBLIC_URL: http://kratos:4433      KRATOS_BROWSER_URL: http://localhost:4433      HYDRA_ADMIN_URL: http://hydra:4445      COOKIE_SECRET: super-secret-cookie-secret-32chars      CSRF_COOKIE_NAME: ory_csrf_ui      CSRF_COOKIE_SECRET: super-secret-csrf-secret-32-chars    ports:      - \"4455:4455\"    depends_on:      kratos:        condition: service_healthy      hydra:        condition: service_healthy    networks:      - oryvolumes:  postgres_data:networks:  ory:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMやCOOKIE_SECRETに32文字以上の暗号学的に安全な値を設定してください。サービスが6つある。PostgreSQL、KratosとHydraそれぞれのmigrate/serveサービス、そしてKratos UI。以前の自前実装（auth-provider）はKratosに置き換わった。ポイントはkratos-uiだ。これはOry公式が提供するセルフサービスUI。ログイン画面、登録画面、パスワードリセット画面などが含まれている。「自分でUI書かなくていいの？」開発環境ではこれで十分だ。本番環境では、このUIを参考に自前のUIを実装できる。Kratosの「ヘッドレス」設計により、UIは完全に切り離されている。github.comKratos設定ファイルの解説Kratosの設定ファイルkratos.ymlを見てみよう。version: v1.3.1dsn: memoryserve:  public:    base_url: http://localhost:4433/    cors:      enabled: true      allowed_origins:        - http://localhost:4455  admin:    base_url: http://localhost:4434/selfservice:  default_browser_return_url: http://localhost:4455/  allowed_return_urls:    - http://localhost:4455    - http://localhost:4444  methods:    password:      enabled: true    totp:      enabled: true      config:        issuer: OryKratosVerification    lookup_secret:      enabled: true    link:      enabled: true    code:      enabled: true  flows:    error:      ui_url: http://localhost:4455/error    settings:      ui_url: http://localhost:4455/settings      privileged_session_max_age: 15m    recovery:      enabled: true      ui_url: http://localhost:4455/recovery      use: code    verification:      enabled: true      ui_url: http://localhost:4455/verification      use: code      after:        default_browser_return_url: http://localhost:4455/    logout:      after:        default_browser_return_url: http://localhost:4455/login    login:      ui_url: http://localhost:4455/login      lifespan: 10m    registration:      lifespan: 10m      ui_url: http://localhost:4455/registration      after:        password:          hooks:            - hook: sessionlog:  level: debug  format: text  leak_sensitive_values: truesecrets:  cookie:    - super-secret-cookie-secret-32chars  cipher:    - super-secret-cipher-key-32-charsciphers:  algorithm: xchacha20-poly1305hashers:  algorithm: argon2  argon2:    parallelism: 1    memory: 128MB    iterations: 2    salt_length: 16    key_length: 16identity:  default_schema_id: default  schemas:    - id: default      url: file:///etc/config/kratos/identity.schema.jsoncourier:  smtp:    connection_uri: smtps://test:test@mailslurper:1025/?skip_ssl_verify=trueoauth2_provider:  url: http://hydra:4445セルフサービスフローselfservice:  methods:    password:      enabled: true    totp:      enabled: true以前、私がRustで実装したパスワード認証。Kratosではpassword: enabled: trueの一行で有効になる。TOTPも同様だ。以前は「MFA対応の予定は？」という質問に答えられなかった。Kratosなら設定1つで有効化できる。パスワードハッシュhashers:  algorithm: argon2  argon2:    parallelism: 1    memory: 128MB    iterations: 2    salt_length: 16    key_length: 16以前、私はArgon2::default()を使った。Kratosも同じArgon2を使っている。設定値を明示的に指定することで、チーム内で「なぜこのパラメータか」を共有できる。cheatsheetseries.owasp.orgHydra連携oauth2_provider:  url: http://hydra:4445これが最も重要な設定だ。KratosがHydraのAdmin APIに接続し、login_challengeを処理する。以前は私がRustでHydraClientを実装し、accept_loginを呼び出していた。Kratosはこれを自動で行う。https://www.ory.com/docs/kratos/self-hosted/hydra-integrationwww.ory.comIdentity Schemaの設計Kratosはユーザー情報を「Identity」として管理する。その構造はJSON Schemaで定義する。{  \"$id\": \"https://schemas.ory.sh/presets/kratos/identity.email.schema.json\",  \"$schema\": \"http://json-schema.org/draft-07/schema#\",  \"title\": \"Person\",  \"type\": \"object\",  \"properties\": {    \"traits\": {      \"type\": \"object\",      \"properties\": {        \"email\": {          \"type\": \"string\",          \"format\": \"email\",          \"title\": \"E-Mail\",          \"ory.sh/kratos\": {            \"credentials\": {              \"password\": {                \"identifier\": true              },              \"totp\": {                \"account_name\": true              }            },            \"recovery\": {              \"via\": \"email\"            },            \"verification\": {              \"via\": \"email\"            }          }        },        \"name\": {          \"type\": \"object\",          \"properties\": {            \"first\": {              \"title\": \"First Name\",              \"type\": \"string\"            },            \"last\": {              \"title\": \"Last Name\",              \"type\": \"string\"            }          }        }      },      \"required\": [\"email\"],      \"additionalProperties\": false    }  }}ory.sh/kratosという拡張プロパティが特徴的だ。credentials.password.identifier: true — このフィールドがログインIDになるrecovery.via: email — パスワードリセットはこのメールアドレスに送信されるverification.via: email — メール確認もこのアドレスに送信される以前、私はユーザーテーブルを自前で設計した。Kratosではスキーマを宣言的に定義するだけでいい。www.ory.com実際にハマったことでも、最初のdocker compose upは失敗した。データベースが存在しないFATAL: database \"kratos\" does not exist (SQLSTATE 3D000)KratosとHydraはそれぞれkratosとhydraという名前のデータベースを期待する。でも、PostgreSQLコンテナはpostgresデータベースしか作らない。解決策は初期化スクリプトだ。-- init.sqlCREATE DATABASE kratos;CREATE DATABASE hydra;# docker-compose.ymlpostgres:  volumes:    - ./init.sql:/docker-entrypoint-initdb.d/init.sql:roPostgreSQLは/docker-entrypoint-initdb.d/にあるSQLファイルを起動時に実行する。これで両方のデータベースが作成される。最初は「なぜ自動で作ってくれないんだ」と思った。おそらく、本番環境では既存のデータベースサーバーに接続することが多いからだろう。いずれにせよ、初期化スクリプトで解決できる。ポート競合Bind for 0.0.0.0:4444 failed: port is already allocated以前の記事で作ったory-hydra-rust環境がまだ動いていた。同じポート4444を使おうとして衝突。# 他の環境を停止cd ../ory-hydra-rust \u0026\u0026 docker compose down複数のOry環境を並行して動かす時は、ポートを変える必要がある。開発環境では素直に片方を停止した方がいい。Kratosが教えてくれた盲点E2EテストでTestPassword123!というパスワードを使おうとした。{  \"id\": 4000034,  \"text\": \"The password has been found in data breaches and must no longer be used.\",  \"context\": {    \"breaches\": 3330  }}KratosはデフォルトでHave I Been PwnedのAPIを使い、パスワードが過去のデータ漏洩に含まれていないかチェックする。TestPassword123!は3,330件の漏洩で見つかっていた。haveibeenpwned.comなぜ私は思いつかなかったのか。振り返ると、私の58個のテストは「攻撃者がシステムに対して行う操作」をテストしていた。間違ったパスワードでログインできないこと存在しないユーザーで情報が漏れないこと同時登録で競合状態が起きないことこれは全て「システムへの攻撃」に対するテストだ。攻撃者がシステムの外側から突破を試みるシナリオ。HIBPチェックは視点が異なる。「ユーザーが持ち込むリスク」に対処している。ユーザーが「password123」を使おうとするユーザーが他のサービスで使い回しているパスワードを登録するユーザーが過去に漏洩したパスワードを選ぶこれはシステムへの攻撃ではない。ユーザー自身がリスクを持ち込むシナリオだ。私はこのカテゴリを完全に見落としていた。なぜ見落としたのか。おそらく「ユーザーは正しく行動する」という暗黙の前提があった。パスワード強度のバリデーション（8文字以上、英数字混合など）を入れれば十分だと思っていた。でも、TestPassword123!は典型的な強度バリデーションを通過する。英大文字、英小文字、数字、記号、8文字以上。全ての条件を満たしている。にもかかわらず、3,330件の漏洩で見つかっている。強度バリデーションは「推測しやすいか」をチェックする。HIBPチェックは「既に漏洩しているか」をチェックする。両者は補完関係にある。Kratosを使うことで、私が想定していなかった脅威カテゴリまでカバーできる。これが「専門家が作ったツールを使う」ことの価値だ。自分の盲点を、他者の知見で補える。E2Eテストではタイムスタンプを含むランダムなパスワードを生成して回避した。TEST_PASSWORD=\"Kratos$(date +%s)E2E!Xk9#mN\"本番環境では、この機能を有効にしたまま運用すべきだ。ユーザーに「このパスワードは漏洩しています」と伝えることで、アカウント乗っ取りのリスクを下げられる。環境の起動と動作確認初期化スクリプトを追加した状態で起動する。docker compose up -ddocker compose logs -fヘルスチェック用エンドポイントにアクセスしてみる。# Kratosのヘルスチェックcurl http://localhost:4433/health/ready# {\"status\":\"ok\"}# Hydraのヘルスチェックcurl http://localhost:4444/health/ready# {\"status\":\"ok\"}両方ともokが返ってきた。セルフサービスフローの確認ブラウザでhttp://localhost:4455/registrationにアクセスする。登録画面が表示される。メールアドレスとパスワードを入力して登録。次にhttp://localhost:4455/loginにアクセス。ログイン画面が表示される。先ほど登録した認証情報でログイン。ログイン成功。これだけだ。拍子抜けするほど簡単だった。以前、私は以下を実装した。AuthService::register() — ユーザー登録AuthService::authenticate() — パスワード検証login_page() — ログインフォームのHTMLlogin_submit() — フォーム送信処理58個のテストKratosでは、設定ファイルを書くだけでこれらが全て動く。OAuth2フローの確認OAuth2クライアントを作成する。docker compose exec hydra hydra create oauth2-client \\  --endpoint http://localhost:4445 \\  --grant-type authorization_code \\  --response-type code \\  --scope openid,profile,email \\  --redirect-uri http://localhost:8080/callback \\  --name \"Test Client\"クライアントIDとシークレットが出力される。ブラウザで認可エンドポイントにアクセスする。http://localhost:4444/oauth2/auth?client_id=\u003cCLIENT_ID\u003e\u0026response_type=code\u0026scope=openid+profile+email\u0026redirect_uri=http://localhost:8080/callback\u0026state=test-stateHydraがKratos UIにリダイレクトKratos UIがログイン画面を表示ログイン成功後、Kratosがlogin_challengeをHydraに送信HydraがConsent画面にリダイレクトConsent承認後、認可コードがコールバックURLに返される以前、私がRustで実装したlogin_submit()の処理を、Kratosが自動で行っている。// 前回の実装（不要になった）pub async fn login_submit(    State(state): State\u003cAppState\u003e,    Form(form): Form\u003cLoginForm\u003e,) -\u003e Result\u003cRedirect, AppError\u003e {    let user = state.auth.authenticate(\u0026form.email, \u0026form.password).await?;    let completed = state.hydra        .accept_login(\u0026form.login_challenge, \u0026user.id.to_string(), false)        .await?;    Ok(Redirect::to(\u0026completed.redirect_to))}このコードは、もう書く必要がない。E2Eテストで確認したこと実際にAPIを叩いて、フロー全体が動くことを確認した。Registration Flow# 1. フローを初期化curl -s -X GET \"http://localhost:4433/self-service/registration/api\"# Flow ID: 77ff9653-ccd2-4f91-aeea-8fbb4d67fce7# 2. 登録を実行curl -s -X POST \"http://localhost:4433/self-service/registration?flow=$FLOW_ID\" \\  -H \"Content-Type: application/json\" \\  -d '{    \"method\": \"password\",    \"password\": \"Kratos1767517527E2E!Xk9#mN\",    \"traits\": {      \"email\": \"e2etest@example.com\",      \"name\": { \"first\": \"E2E\", \"last\": \"Test\" }    }  }'Registration successful!Identity ID: 169e0834-4b45-441f-95f8-5adc45d8a3e9Email: e2etest-1767517527@example.comSession Token: ory_st_WugR5gisST7SO...Kratosのセルフサービスフローは2段階構成だ。まずフローを初期化してFlow IDを取得し、そのIDを使ってデータを送信する。これにより、CSRFトークンやフローの有効期限が管理される。Login Flow# 1. フローを初期化curl -s -X GET \"http://localhost:4433/self-service/login/api\"# 2. ログインを実行curl -s -X POST \"http://localhost:4433/self-service/login?flow=$FLOW_ID\" \\  -H \"Content-Type: application/json\" \\  -d '{    \"method\": \"password\",    \"identifier\": \"e2etest@example.com\",    \"password\": \"Kratos1767517527E2E!Xk9#mN\"  }'Login successful!Session ID: 8b97d548-8436-48ee-b4fd-8e1c643dac04Session Token: ory_st_ty15oU5JLIABh...Session Verificationcurl -s -X GET \"http://localhost:4433/sessions/whoami\" \\  -H \"Authorization: Bearer $SESSION_TOKEN\"Session valid!Identity: e2etest-1767517527@example.comActive: trueセッショントークンを使って/sessions/whoamiを呼ぶと、現在のセッション情報が返ってくる。これは以前私がRustで実装したJwtService::verify()に相当する機能だ。OAuth2 Authorization Flow# OAuth2クライアントを作成curl -s -X POST \"http://localhost:4445/admin/clients\" \\  -H \"Content-Type: application/json\" \\  -d '{    \"client_id\": \"e2e-test-client\",    \"client_secret\": \"e2e-test-secret\",    \"grant_types\": [\"authorization_code\"],    \"response_types\": [\"code\"],    \"scope\": \"openid profile email\",    \"redirect_uris\": [\"http://localhost:8080/callback\"]  }'認可エンドポイントにアクセスすると、HydraがKratos UIにリダイレクトする。http://localhost:4444/oauth2/auth?client_id=e2e-test-client\u0026...  ↓http://localhost:4455/login?login_challenge=Xv84rhGlXQQrVNL7SlICdNobNbYvcK7z8il...login_challengeパラメータが付与されている。Kratos UIはこのチャレンジを使ってHydraと連携し、認証完了後に適切なリダイレクトを行う。E2Eテスト結果サマリー テスト項目  結果  Registration Flow  成功  Login Flow  成功  Session Verification  成功  OAuth2 Client Setup  成功  OAuth2 Authorization Flow  成功（login_challenge生成確認） 全てのフローが期待通りに動作した。以前の自前実装と比較して、コード量はゼロになり、機能は増えた。自前実装との比較 観点  自前実装（02）  Kratos  パスワード認証  Argon2id実装  組み込み  MFA  未実装  TOTP, WebAuthn対応  パスワードリセット  未実装  フロー組み込み  メール確認  未実装  フロー組み込み  ソーシャルログイン  未実装  OIDC対応  漏洩パスワードチェック  未実装  HIBP連携  ログイン画面  HTML手書き  公式UI or 自前  セキュリティテスト  58個書いた  Oryが検証済み  学習コスト  Rust知識  Kratos設定  カスタマイズ性  完全自由  スキーマ/フック 特筆すべきは漏洩パスワードチェックだ。Have I Been Pwnedとの連携により、過去のデータ漏洩で流出したパスワードを拒否できる。これは以前書いた58個のテストでも考慮していなかった観点だ。Kratosを使うことで、私が思いつかなかったセキュリティ対策まで自動的に適用される。自前実装は無駄だったのか？いや、違う。以前の実装で学んだこと——Argon2idのパラメータ、ユーザー列挙攻撃への対策、タイミング攻撃の考慮——これらはKratosの設定を理解する上で役立った。「なぜこの設定があるのか」が分かるのは、自分で実装した経験があるからだ。いつKratosを使うべきかKratosを選ぶかどうかは、3つの軸で判断する。技術的要件: カスタマイズの複雑さはどの程度か。Kratosはフック機構やIdentity Schemaで柔軟性を提供するが、「3回目のログインでは必ずCAPTCHAを表示」のような独自フローは難しい。標準的な認証フローなら、Kratosで十分だ。組織的要件: チームにセキュリティ専門家がいるか。いないなら、Kratosに任せた方がいい。脆弱性対応、ベストプラクティスの追従——これらを自前でやるには専門性が必要だ。SOC2やISO27001の監査でも「専門企業の製品を使っています」と答えられる。ビジネス要件: 認証がコア価値か否か。パスワードマネージャーや認証SaaSなら、自前実装に意味がある。ECサイトや社内ツールなら、認証に時間をかけるより本業に集中すべきだ。私がこれまで関わってきたプロジェクトの8割は、最初からKratosで良かった。残り2割は、レガシーシステムとの統合が複雑すぎるか、認証自体がプロダクトの価値だった。今回のケースでは、学習目的で自前実装から始めたが、本番プロジェクトなら最初からKratosを選ぶ。認証に独自性は不要で、チームにセキュリティ専門家もいない——判断は明確だ。次回予告Kratosを導入したことで、認証（Authentication）は解決した。ユーザーはログインできる。セッションも管理される。でも、ログインしたユーザーが「何をできるか」は、まだ決まっていない。認証と認可は別物だ。認証は「誰であるか」を確認する。認可は「何ができるか」を判断する。次回は、Ory Ketoを使ってZanzibarモデルによる認可システムを構築する。おわりに正直に言うと、Kratosの設定を書いている時、何度か「自分で実装した方が分かりやすいのでは」と思った。YAMLの設定項目が多い。ドキュメントを何度も読み返した。でも、動いた時の感覚が違う。これまでに私が書いた数百行のRustコード。それがYAML数十行で置き換わった。しかも、MFAやパスワードリセットなど、私が「次回以降に実装する」と書いていた機能が、既に含まれている。「自前で作ることの非合理性」第1回で書いた言葉を思い出した。認可サーバーだけでなく、認証システムも同じだった。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Kratosに移行しても、設定の検証やアップグレード対応、障害時の判断は残る。責任が消えるのではなく、「実装の責任」から「選定と運用の責任」に形を変える。その上で、認証の基本的な部分——パスワード認証、MFA、セッション管理——は、毎回ゼロから考える問題ではなくなった。そして、もう1つ学んだことがある。Have I Been Pwnedの件だ。私は58個のテストを書いて「完璧だ」と思っていた。でも、「ユーザーが持ち込むリスク」という視点が完全に抜けていた。専門家が作ったツールを使う価値は、自分の盲点を補えることにある。レビューコメントに返信しよう。「パスワードリセット機能は？」——Kratosで対応します。この記事が参考になれば、読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料Ory KratosOry Kratos GitHubOry Kratos DocumentationKratos QuickstartIdentity SchemaHydra IntegrationOry HydraOry Hydra DocumentationLogin and Consent FlowセキュリティガイドラインOWASP Password Storage Cheat SheetOWASP Authentication Cheat Sheet検証環境ory-kratos-verification（GitHub）","isoDate":"2026-01-14T05:02:48.000Z","dateMiliSeconds":1768366968000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、辞めないなら頑張れ","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/12/003013","contentSnippet":"はじめに先週、「おい、辞めるな」という記事を書きました。syu-m-5151.hatenablog.com思った以上に反響がありました。何人かから連絡をもらいました。辞めないことにしました、考えるきっかけになりました、と。ありがたかったです。嬉しかった、と言っていいです。たぶん。ただ、何か落ち着きませんでした。辞めないと決めた。それは分かった。で、その次は。辞めないと決めただけで、何かが変わるわけではありません。私がそうだったからです。辞めないと決めた後も、何も変わりませんでした。評価は上がらない。漠然としたモヤモヤは消えない。夜遅くまでコードを書いた。勉強会に参加した。資格を取った。ブログを書いた。技術力を上げれば認められる。そう信じていました。評価は上がりませんでした。振り返ると、私は頑張り方を間違えていたのです。もっと正確に言えば、評価の構造を理解していませんでした。良い仕事をすれば評価される。そう思っていました。でも、評価者には評価者の論理があります。組織には組織の論理があります。その構造を理解せずに、がむしゃらに頑張っても、報われません。「おい、辞めるな」の最後に、「選んだ道を、正解にしていく過程があるだけだ」と書きました。辞めないと決めた。その選択を正解にするために、何をすればいいのか。この文章は、それを書くために開きました。ただ、書きながらも思います。これが誰かの役に立つのかは、分かりません。分からないまま、書いています。先に断っておきます。この記事は、まだ頑張れる余力がある人に向けて書いています。すでに消耗している人、頑張る気力すらない人には、この記事は届かないだろう。それについては、最後に書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。見えない努力まず、頑張り方を間違えている人が多いです。私もそうでした。インフラのトラブルを未然に防いだことがあります。監視アラートの傾向を見て、「これ、来週やばいことになる」と気づきました。週末に対応して、障害を防ぎました。本番で落ちていたら大騒ぎでした。サービスが止まれば、ビジネスに直接影響が出ます。ユーザーからのクレームが殺到します。深夜に全員が叩き起こされます。そういう未来を、私は未然に防ぎました。でも、月曜日、何事もなかったように仕事が始まりました。誰も何も言いませんでした。障害が起きなかったという「非イベント」は、誰の記憶にも残りません。チームの技術的負債を黙々と返済したことがあります。3ヶ月かけて、複雑なモジュールをリファクタリングしました。スパゲッティコードを解きほぐし、テストカバレッジを上げ、ドキュメントを整備しました。誰かがこの負債を返さなければ、いずれチーム全体が身動きを取れなくなります。そう思って、地道に片付けました。でも、リリース直前に「いつの間にかキレイになってた」と言われただけでした。3ヶ月の努力が、「いつの間にか」で片付けられました。いつの間にか、俺も消えていました。私は「良い仕事をしていれば、いつか評価される」と思っていました。黙々と価値を出していれば、誰かが見ている。実力で認められる。そう信じていました。甘かったです。現実はこうです。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知りません。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われます。障害を未然に防いでも、障害が起きなかったという「非イベント」は記憶に残りません。これは不公平だと思うだろう。私もそう思いました。私は2年間嘆いていました。居酒屋で同僚と「この会社の評価制度はおかしい」と言い合ったこともあります。「なんで俺の仕事が評価されないんだ」と愚痴りました。言うたびに少し楽になりました。だけど、翌日も同じ状況が続きました。嘆きは鎮痛剤です。痛みを一時的に和らげますが、原因は治りません。この構造を理解した上で、どう振る舞うか。 それが「頑張り方」です。構造を知れここで公平を期しておきます。仕組みの問題は確かにあります。OKRの目標設定が形骸化している。評価者によって評価がブレる。数値化できない仕事が過小評価される。これは仕組みを運営する上で抱える問題です。「人は他人を正しく評価できる」——これは幻想です。同じ人の同じ仕事を見ても、評価者が違えば評価は違います。同じアウトプットで、上司が変わっただけで評価が2段階変わることもあります。私です。絶対的に客観的な評価など存在しません。そもそも、数値で測ろうとした瞬間、測定対象は変質します。コミット数を測り始めたチームを見たことがあります。結果、コミットが細切れになりました。バグ修正件数を測れば、バグを作った人が有利になります。プルリクエストの数を測れば、小さなPRを乱発する人が評価されます。グッドハートの法則と呼ばれる現象です。「指標が目標になると、その指標は機能しなくなる」。OKRを導入したとき、私はこの法則を知りませんでした。知っていたら何か変わったかと言われると、たぶん変わりませんでした。人間だから。エンジニアリングの現場では、これが顕著に現れます。これは事実です。認めましょう。その上で、自分に何ができるかを考えます。仕組みの問題を批判するのは簡単です。でも、評価制度を変えるのは難しい。上司を変えることはできません。待っていても変わりません。冒頭で書いた通り、私はこれをやっていました。仕組みの問題を指摘して溜飲を下げる。鎮痛剤を飲み続けて、原因を放置していました。仕組みがおかしいのは事実です。でも、仕組みは変えられない。自分は変えられる。 それが「頑張る」ということです。変えられないものに時間を使うほど、あなたの人生は長くありません。——と書いて、立ち止まります。「結局、自己責任論じゃないか」と言われるだろう。構造の問題を認識しながら、最後に「個人が変われ」と言っている。評価されないのは構造の問題なのに、「お前の頑張り方が悪い」と言っている。それは自己責任論の強化じゃないか、と。正直に言えば、その批判は当たっています。私は構造の問題を認識しながら、「構造を変えろ」とは言いませんでした。「構造の中でうまくやれ」と言いました。それは、構造を温存することに加担しています。これは私の限界です。私が書けるのは、私が経験したことだけです。構造を変えることに成功した人が、その方法を書いてくれることを願います。ただ、1つだけ言い訳させてください。私は「評価されないのはお前のせいだ」とは言っていません。「評価制度には限界がある」「客観的評価は存在しない」と、繰り返し書きます。その上で、「構造が変わらない中で、個人に何ができるか」を書いています。自己責任論と言われれば、そうだろう。でも、構造が変わるのを待っていても、あなたの評価は上がりません。変わらない構造の中で、今日をどう生きるか。それを考えるしかありませんでした。しかし、重要な注意点があります。仕組みの問題が大きすぎる時は、「辞める」が正解のことがあります。 個人の努力で覆せない構造もあります。それを見極める目も必要です。評価制度が必ず歪む理由評価制度が歪むのは、設計者の能力不足ではありません。測定されるものは、測定によって変質するからです。どの制度も、導入した瞬間に歪み始めます。完璧な評価制度は原理的に存在しません。この事実は、あなたを責めるためにあるのではありません。あなたを解放するためにあります。「自分が無能だから評価されない」という思い込みから解放され、「制度の限界を前提に、どう動くか」という問いに切り替わります。評価の幻想上司は、神でもエスパーでも上位存在でもありません。人間です。君よりも少しだけ観点の多い人間です。人外だと思っている上司も、人間であり、認知には限界があります。これは「上司が無能だ」という話ではありません。人間である限り、客観的評価は原理的に不可能だという話です。なぜ「客観的評価」は不可能なのか「客観的評価」という言葉には、2つの前提があります。「評価すべき対象を正確に観察できる」という前提と、「観察したものを正確に評価できる」という前提です。どちらも成り立ちません。観察の問題から見てみましょう。上司があなたの仕事のうち、何%を直接観察しているでしょうか。会議での発言。Slackでのやり取り。プルリクエスト。これは観察できます。でも、設計を考えている時間。問題を切り分けている時間。ドキュメントを読んでいる時間。これは見えません。上司が見ているのは、あなたの仕事の氷山の一角に過ぎません。観察できるものだけを見て、全体を評価している。これは観察者の怠慢ではありません。構造的に避けられない限界です。比較の問題もあります。評価とは、本質的に比較です。Aさんは「期待以上」、Bさんは「期待通り」。この判断をするには、AさんとBさんを比較する必要があります。でも、2人の仕事が違えば、比較は困難になります。バックエンドで高負荷対策をしたAさんと、フロントエンドで複雑なUIを実装したBさん。どちらが「より価値がある」か。答えはありません。比較不可能なものを比較しています。上司は無理やり比較し、順位をつけます。その順位に「客観性」などありません。観察者効果という問題もあります。観察すること自体が観察対象に影響を与えるというものです。「評価される」と意識した瞬間、行動が変わります。評価されやすい仕事を選ぶ。見える形で成果を出そうとする。「本当の仕事ぶり」を観察しているわけではありません。「評価を意識した仕事ぶり」を観察しています。上司の認知バイアス観察の限界に加えて、観察したものを処理する段階でもバイアスがかかります。直近バイアス: 1年間を均等に覚えていません。評価直前の出来事が記憶に残ります。4月に素晴らしい仕事をしても、12月の評価面談では薄れています。11月に目立つ失敗をすると、それが印象を決めます。ハロー効果: 1つの良い印象が全体評価を引き上げます。1つの失敗が全体を引き下げます。障害対応で活躍すると、「この人は優秀だ」と思われます。その印象が、関係のない能力の評価にも影響します。確証バイアス: 一度「優秀」と思うと優秀な証拠ばかり目に入ります。「ダメ」も同様です。最初の印象が固定され、それを覆す情報は無視されます。これは上司の能力不足ではありません。人間の認知システムに組み込まれた特性です。どんなに優秀な上司でも、これらのバイアスから完全に逃れることはできません。ここで、1つ確認しておきたいです。「自分は正しく評価されていない」と感じたことがあるでしょうか。もしあるなら、それは被害妄想ではありません。構造的に、完全に正しい評価など存在しません。上司がどんなに優秀でも、認知バイアスからは逃れられません。あなたの感覚は、間違っていません。評価基準自体が「客観的」ではないより根本的な問題があります。評価基準自体が客観的ではないのです。「技術力」「コミュニケーション力」「リーダーシップ」——評価シートに並ぶこれらの言葉は、一見客観的に見えます。でも、その定義は人によって違います。「技術力が高い」とは何か。コードの品質が高いこと？難しい問題を解決できること？新しい技術をキャッチアップするのが速いこと？幅広い技術に詳しいこと？上司によって、重視する側面が違います。つまり、評価基準そのものが社会的に構成されたものです。「何を価値とするか」は、文化、組織、時代によって変わります。普遍的な基準などありません。私は異動で気づきました。前のチームでは「期待以上」と評価されていました。技術的な深さを評価してくれる上司でした。異動した先では「成長途上」と評価されました。新しい上司はチームへの影響力を重視していました。スキルは変わっていません。変わったのは上司です。「客観的評価」を求めるより、やるべきこと評価とは「私が何をしたか」ではなく「上司が私をどう見るか」です。この事実を受け入れると、行動が変わります。「客観的に見れば、私は評価されるべきだ」という主張は意味がありません。客観的な視点など存在しないからです。存在するのは、上司の視点だけです。だから、「客観的評価」を求めるのはやめました。代わりに、上司が何を見ているかを理解することに注力しました。上司は何を重視するか。何に反応するか。何を見落としているか。それを理解した上で、上司に伝わる形で成果を見せます。これは媚びを売ることとは違います。上司の視界に入る努力をしているだけです。上司の視点を理解するには、いくつかの問いを考えるといいです。「この上司は何を『良い仕事』だと思っているか」「この上司は何にストレスを感じているか」「この上司は、上からどんなプレッシャーを受けているか」。これらを理解すると、上司が何を見て、何を見落としているかが見えてきます。組織の論理評価制度と評価者の心理を理解したら、次は組織の論理を理解しましょう。組織には、個人の論理とは異なる、独自の論理があります。この論理を理解しないと、「なぜ評価されないのか」が分からないままになります。組織は「最適化」で動く組織は、個人の幸福を最大化するために存在しているわけではありません。組織の存続と成長を最適化するために存在しています。この当たり前の事実を、意外と多くの人が忘れています。評価制度も、昇進制度も、給与制度も、すべて「組織の最適化」のために設計されています。「個人が納得するか」は、二次的な目標に過ぎません。もちろん、個人が納得しなければ離職が増えるから、ある程度は配慮されます。でも、最優先ではありません。だから、「公平な評価」を期待すると、裏切られます。組織が目指しているのは公平な評価ではなく、組織にとって都合の良い行動を引き出す評価だからです。昇進はゼロサムゲームである昇進枠は有限です。誰かが昇進すれば、誰かは昇進しません。「今期は枠がなかった」と言われたことがある人もいるでしょう。それは、あなたの実力の問題ではなく、構造の問題です。予算も同じです。パイの大きさは決まっています。問題は、パイをどう切り分けるかです。だから、昇給交渉は「自分の価値を証明する」だけでは不十分です。「なぜ自分に配分を増やすべきか」を説明する必要があります。自分に正直に向き合ってください。あなたが昇進することで、上司やチームにはどんな具体的なメリットがあるか。「この人を昇進させると、〇〇という効果があります」と言える材料を、あなた自身が上司に渡してください。政治は「資源配分の闘争」である「誰を昇進させるか」は、技術力だけで決まりません。上司と上司の上司の関係。部門間の力学。人事部の意向。様々な要素が絡み合います。「政治なんて関係ない」と思いたい気持ちは分かります。技術力で勝負したい。でも、組織で働く以上、政治は存在します。政治とは何か。限られた資源を巡る配分の闘争です。資源とは、予算、人員、プロジェクト、昇進枠、注目、発言力。これは有限です。誰かが得れば、誰かが失います。この配分を決めるプロセスが、政治です。政治を「汚いもの」と見なすのは、的外れです。資源が有限である限り、配分のプロセスは必ず存在します。それを「政治」と呼ぼうが呼ぶまいが、現象は消えません。政治を無視しても、政治はあなたに影響します。あなたが政治を無視しても、他の誰かが政治を使って資源を獲得すれば、あなたに回る資源は減ります。だから、政治を理解した上で動いた方がいいです。しかし、誤解しないでください。「政治を理解してください」は「政治に加担してください」という意味ではありません。「政治ゲームの名プレイヤーになってください」とも言っていません。政治の存在を認識し、その中で自分がどう動くかを考えるということです。組織の論理と個人の論理は違うここまでの話をまとめると、こうなります。組織は「組織の最適化」で動きます。個人の最適化ではありません昇進枠は有限です。ゼロサムゲームです予算は配分の問題です。パイの切り分けです政治は資源配分の闘争です。避けられませんこれらを理解すると、「なぜ評価されないのか」の見え方が変わります。「自分は良い仕事をしている」は、個人の論理です。組織の論理から見ると、「良い仕事をしている人」は他にもいます。問題は、有限の資源を誰に配分するかです。だから、「良い仕事をすれば評価される」は半分しか正しくありません。正確には、「良い仕事をした上で、資源を配分すべき理由を説明できれば評価される」です。ここまで読んで、息苦しくなっただろう。評価制度には限界があります。客観的評価は存在しません。組織は個人の幸福を最大化しません。昇進はゼロサムゲームです。政治は避けられません。厳しい現実です。でも、現実を知ることは、現実に絶望することではありません。構造を知らなければ、暗闘の中で闘っているようなものです。構造を知れば、どこに光があるか見えます。ここからは、その光に向かって動く方法を書きます。やるべきことは、大きく3つあります。「どこを見るか」を変えること、「対話」を通じて認識を揃えること、「見せる」ことで存在を証明することです。チームを見ろ組織の論理を理解したら、次は「どこを見るか」を変えることです。「どの会社で働くか」が大事だと思われています。でも、本当に大事なのは「どのチームで働くか」です。従業員が「ここで働くのをやめよう」と決める時、この「ここ」は会社ではありません。チームです。会社は好きだがチームが合わなくて異動する人がいます。逆に、会社の方針には疑問があるがチームが良くて残る人もいます。これは新卒就職活動をされている方や、転職を考えている方に特に知っておいてもらいたいことです。企業文化が良い会社でも、自分が配属されるチームの雰囲気が良いとは限りません。評価も同じです。「この会社の評価制度」より、「直属の上司の評価パターン」の方が、あなたの評価に直接影響します。会社の評価制度がどれだけ整っていても、その制度を運用するのは上司です。上司が制度を正しく運用しなければ、制度の意味はありません。逆も同じです。評価制度が多少おかしくても、上司が良ければ、適切に評価される可能性があります。だから、転職先を選ぶときも、残るか辞めるかを判断するときも、「会社」という抽象的な単位で考えないでください。どのチームに入るか。誰が上司になるか。 その具体的な単位で考えてください。対話しろ嘆きは鎮痛剤だと書きました。では、対話は何か。対話は手術です。痛いし、面倒だし、時間がかかります。でも、原因を取り除ける可能性があります。対話が必要な理由は単純です。あなたと上司は、別の人間だからです。別の経験を持ち、別の価値観を持ち、別の情報を持っています。この情報の非対称性を埋める方法は、対話しかありません。見えている世界の違いを理解する上司と話が通じないとき、「上司が悪い」と思いがちです。でも違います。部下と上司では見えている世界が違います。自分から見ると理不尽な判断でも、上司の立場から見ると合理的なことがあります。上司には上司のプレッシャーがあります。部門の目標があります。上からの期待があります。その世界の中で、上司は合理的に動いています。その上で話せないことがあります。これは「上司の判断を正当化してください」という話ではありません。上司の判断が間違っていることもあります。でも、その判断がどこから来ているかを理解しなければ、対話はできません。対話とは、この世界の違いを認識した上で、共通の理解を構築する作業です。自分の世界だけで考えると「なんで分かってくれないんだ」となります。でも、上司の世界に立ってみると「なるほど、だからそう判断するのか」と見えてきます。見えてくれば、「では、この点はどうですか」と別の角度から提案できます。上からの視点と現場の視点上司と部下では、見ている方向が違います。上司は上から降りてくる方針を見ています。目標、KPI、ロードマップ。経営が何を求めているか。一方、現場は下を見ています。実際に何が起きているか。どこに問題があるか。この2つが噛み合っていないと、話が通じません。「上が何を考えているか分からない」「現場の声が届かない」——どちらも、この断絶の症状です。対話は、この2つをつなぐ作業です。上司と話すとき、上司が見ている方向を理解しようとします。同時に、現場のリアリティを言語化して伝えます。その接点を見つけることが、対話の目的です。ここで具体的なアクションがあります。上司が今、上の階層から課されている「最も頭の痛い課題」を把握してください。上司も誰かの部下です。上司にも上司がいます。その上司から何を求められているか。何に頭を抱えているか。それを知れば、あなたの仕事をどう位置づければいいか見えてきます。上司が「コスト削減」に追い詰められているなら、あなたの技術改善は「効率化」として語ってください。上司が「新規プロジェクトの立ち上げ」に追われているなら、あなたの貢献は「立ち上げを支える基盤整備」として語ってください。上司の頭痛の種を知れば、あなたの仕事の見せ方が変わります。対話を自分から始める「次の昇進に必要なことは何ですか」と1on1で聞きます。怖いです。否定されるでしょう。「まだ早い」と言われるでしょう。でも、聞かないと何も始まりません。自己評価と組織からの評価が食い違うとき、上司を敵だと思ってしまいがちです。「この人とは話しても仕方ない」と見限って、対話をやめます。これが最悪のパターンです。一度「敵」だと思うと、何を見ても敵の証拠に見えます。中立的な発言も「やっぱり敵だ」と解釈します。相手もそれを感じ取り、本当に敵対してきます。悪循環にハマります。これは認知バイアスの一種で、一度形成された敵対的な認知は、自己強化していきます。対話を自分から始めてください。待っていても始まりません。対話は「同意」ではない対話の目的は、合意することではありません。理解を共有することです。対話した結果、意見が一致しないこともあります。それでいいです。重要なのは、「なぜ相手がそう考えるか」を理解することです。理解した上で、なお意見が違うなら、それは対話の失敗ではありません。「上司と対話したが、評価は変わらなかった」という結果があり得ます。それでも、対話には意味があります。「なぜ評価が変わらないのか」の理由を理解できたはずです。理由を理解すれば、次の行動を決められます。理由が「あなたのスキルが足りない」なら、スキルを伸ばす努力をします。理由が「今期は枠がない」なら、来期に向けて準備します。理由が「この上司とは価値観が合わない」なら、異動や転職を検討します。対話の目的は、情報を得ることです。同意を得ることではありません。制度が機能していないなら、自分で対話を作れ本当は、目標設定や評価制度というのは、この対話を縮減化して仕組み化したものです。「何を目指すか」「どこまでやるか」「何ができたか」を定期的にすり合わせる機会です。でも、多くの組織で、この仕組みは形骸化しています。目標設定は形だけです。評価面談は結果の通知だけです。対話が発生していません。仕組みがうまく機能していないなら、仕組みが本来やろうとしていたことを、自分で意識的にやればいいです。1on1で自分から聞きます。週次報告で自分から伝えます。仕組みに頼らず、対話を自分で作ります。基準を握れ構造を理解し、対話の重要性を理解したら、次は具体的に動きます。まず、評価基準を言語化してください。多くの人は、上司が何を基準に評価しているか、明確に理解していません。なんとなく「良い仕事をすれば評価される」と思っています。でも、上司の頭の中にある評価基準と、自分が想像している評価基準は、往々にしてズレています。1on1で聞くべき具体的な質問「昇進に必要なことは何ですか」「今の自分に足りないものは何ですか」「次の評価期間で何を達成すれば、評価が上がりますか」「あなたが重視していることは何ですか」「なぜその目標が重要なんですか」「この目標が達成されないと、何が困りますか」これらの質問を、恐れずに聞いてください。「そんなこと聞いていいの？」と思うでしょう。私もそう思っていました。こういう質問をすることに、強い抵抗がありました。正直に言えば、私を含めてエンジニアは、こういう「合意形成」をバカにしている節があります。技術力で勝負したい。政治的なことはやりたくない。上司にゴマをするみたいで嫌だ。そういう感覚があります。もう1つ、ネガティブなフィードバックを受け取りたくない、という心理もあります。「今の自分に足りないものは何ですか」と聞いて、厳しいことを言われたらどうしよう。自分が思っているより評価が低かったらどうしよう。聞かなければ、知らずに済みます。でも、聞かなければ分かりません。上司はエスパーではないし、あなたもエスパーではありません。期待値をすり合わせるには、対話するしかありません。「昇進したいです」と直接言うのは恥ずかしいです。自分の欲を見せることに抵抗があります。私は3年間言えませんでした。言い出せないまま、居酒屋で愚痴を言い、鎮痛剤を飲み続けていました。鎮痛剤の効き目が切れてきた4年目に、ようやく口を開きました。でも、上司からすれば、部下が何を求めているか分からなければ、サポートのしようがありません。期待値のすり合わせ上司が求めるものと、自分がやりたいことは、必ずしも一致しません。上司が重視するのはAだが、自分が得意なのはB。この場合、どう動くか。まず、そのギャップを言語化してください。「自分はBが得意だが、Aに注力すべきですか」と聞いてください。上司は「Aをやってほしい」と言うでしょうし、「Bで成果を出してくれればいい」と言うでしょう。どちらにせよ、ギャップを認識した上で動けます。ギャップを認識しないまま、自分の得意なBに注力して、評価面談で「Aをやってほしかったのに」と言われるのが最悪のパターンです。見せろ評価基準を理解しました。上司との期待値もすり合わせました。次は、実際に動く番です。対話は手術だと書きました。では、見せることは何か。見せることはリハビリです。地味で、継続が必要で、効果が見えるまで時間がかかります。でも、これをやらなければ、手術しても回復しません。冒頭で書きました。見えない仕事は、存在しないのと同じだと。障害を未然に防いでも、誰も気づきません。技術的負債を返済しても、「いつの間にかキレイになってた」で終わります。これは不公平です。でも、嘆いても変わりません。変えられるのは、自分の行動だけです。だから、見せてください。何をやっているか、どんな価値を生んでいるか、言葉にして伝えてください。なぜ「見せる」ことが必要なのか「良い仕事をしていれば、見てもらえるはずだ」——これは幻想です。上司の注意は有限です。注意は希少資源です。上司は複数の部下を持っています。自分の仕事もあります。上からのプレッシャーもあります。その中で、あなたの仕事に割ける注意は、ごくわずかです。あなたが黙って良い仕事をしていても、上司の注意はあなたに向きません。問題を起こす部下、声の大きい部下、頻繁に報告してくる部下に注意が向きます。注意を向けてもらえなければ、あなたの仕事は認識されません。認識されなければ、評価されません。これは「目立ったもの勝ち」という話ではありません。情報の非対称性の話です。あなたは自分の仕事を100%知っています。上司は、あなたの仕事の10%も見ていません。この情報ギャップを埋めるのは、あなたの責任です。上司が勝手に気づいてくれることを期待するのは、非現実的です。人が本当に求めているのは、実はフィードバックではありません。「注目」です。自分の仕事を見てもらっている。気にかけてもらっている。存在を認識されている。そういう感覚です。私自身、厳しいフィードバックより、上司が自分の仕事を把握していないことの方が堪えました。評価されないと感じるとき、本当の問題は「評価が低い」ことではなく「注目されていない」ことでしょう。上司は、あなたが何をしているか知りません。知らなければ、評価以前の問題です。「見せる」ことへの抵抗多くのエンジニアは、「見せる」ことに抵抗がある。「アピールは卑しい」という感覚がある。日本の文化では、自己主張は美徳ではない。「黙って結果を出す」が美しいとされる。自分の成果を語ることは、自慢に見える。謙虚さが失われる。そういう感覚がある。でも、この感覚は、情報の非対称性を無視している。あなたが黙っていれば、上司はあなたの仕事を知らない。知らなければ、評価できない。「黙って結果を出す」は、「結果を出しても評価されない」と同義だ。「仕事の質で勝負したい」という信念もある。アピールの上手さではなく、仕事の質で評価されたい。それは正しい感覚だ。でも、仕事の質を上司に伝えるのは、アピールではない。情報提供だ。上司は、あなたの仕事の質を判断する材料を持っていない。その材料を提供するのは、あなたの役目だ。具体的な言い方週次報告での言い方ダメな例:「今週はAの修正をしました。」良い例:「今週はAの修正をしました。このバグは再現条件が複雑で、ログから特定するのに2日かかりました。原因は○○で、同様の問題が他に3箇所あったので併せて修正しています。」違いは、「何が難しかったか」「どう判断したか」「影響範囲をどう考えたか」を言語化していること。Slack、1on1、どの場面でも同じ原則です。言語化はスキルだアピールが苦手？ なら、存在しないのと同じだ。「自慢みたいで嫌だ」と思うだろう。私もそうだった。でも、これは自慢ではない。自分の仕事の価値を言語化しているだけだ。言語化しなければ、他人には見えない。見えなければ、評価されない。言語化は、スキルだ。最初は苦手でも、練習すれば上達する。週次報告を書くたびに、「何が難しかったか」を1文追加する。それだけで、見え方が変わる。タイミングを狙え「見せる」にも戦略がある。上司の認知の限界を理解することが重要だ。なぜタイミングが重要なのか評価面談の席で、上司は1年間を振り返る。でも、1年間を均等に思い出すことは、人間には無理だ。上司も人間だ。人間の記憶には癖がある。最初の方と最後の方は覚えているが、中間は忘れやすい。期初に立てた目標は覚えている。期末の追い込みも覚えている。でも、中間の地道な仕事は埋もれる。より厄介なのが、最近の出来事ほど重要に感じられる傾向だ。4月に素晴らしい仕事をしても、12月の評価面談では遠い記憶だ。「そういえば、何かやってくれた気がするな」程度の印象しか残らない。一方、11月に目立つ成果を出せば、12月の評価面談では鮮明に覚えている。もう1つ、人間は経験全体を平均的に評価しない。最も印象的だった瞬間と、終わりの印象で全体を判断する。1年間コツコツ働いても、期末に目立つ成果がなければ、「今期は普通だったな」という印象になりやすい。逆に、期末に大きな成果を出せば、「今期は頑張っていたな」という印象が残る。これは上司の能力不足ではない。人間の脳の仕組みだ。批判しても変わらない。構造を理解した上での3つの戦略この認知の限界を理解した上で、どう動くか。1. 評価の2ヶ月前に目立つ成果を出す大きなリリースのタイミングを調整可能なら、評価期間の後半に持ってくる。調整できなくても、過去の成果の効果を後半に言語化し直すことはできる。「4月にリリースした機能が、この半年でこれだけの効果を出しました」と。成果を「過去のイベント」ではなく「現在も続いている効果」として再提示する。2. 月次で「今月やったこと」を共有する上司の記憶を定期的に上書きする。年末に慌てて振り返るのではなく、毎月、記録を残しておく。これは上司のためだけではない。自分のためでもある。1年前に何をやったか、自分でも忘れる。月次の記録があれば、評価面談の準備が楽になる。もう1つ重要なことがある。「ピーク」がない期間の地味な貢献を、上司が「思い出しやすいエピソード」として毎月ストックしているか。「今月は特に目立った成果はありませんでした」で終わらせるな。地味な仕事でも、言語化すれば印象に残る。「依存ライブラリのアップデートで、セキュリティリスクを2件潰しました」。これだけで、「あの人は地道にやってくれている」という印象が積み上がる。3. 印象に残る瞬間を意識的に作る人間は、最も印象的だった瞬間で全体を判断する。これを逆手に取る。難しい問題を解決した。障害対応で活躍した。これらの「ピーク」は記憶に残りやすい。ピークがあれば、平凡な日々も「あの人は活躍していた」という印象に変換される。「ズルい」という感覚について「タイミングを調整するなんてズルい」と思うでしょう。仕事の質で評価されるべきです。タイミングを操作するのは、本質的ではありません。でも、考えてみてほしい。あなたがタイミングを意識しなくても、他の誰かは意識しています。評価期間の後半に目立つ成果を出す人。月次報告を欠かさない人。彼らは「ズルい」のではなく、「構造を理解している」だけです。タイミングを調整することは、媚びを売ることではありません。上司の認知の限界を理解した上で、情報を届けているだけです。上司が全てを均等に覚えていてくれるなら、タイミングは関係ありません。でも、上司は人間です。人間の記憶には限界があります。その限界を前提として動く方が、合理的です。この癖は、知っていれば対処できます。知らなければ、無意識のうちに損をします。評価する側もされる側も、同じ脳を持っています。上司もまた、自分の記憶の癖に気づいていないことが多いです。4. 失敗したときのリカバリーを設計しておく失敗は起きます。問題は、その失敗がハロー効果で全体評価を引きずり下ろすことです。「あの人は失敗した」という印象が、関係のない能力の評価まで下げます。これを防ぐには、失敗の直後に2つのことをやってください。まず、迅速に報告してください。隠そうとして発覚すると、「失敗した」にまた「隠そうとした」が上乗せされます。次に、原因と対策を透明に説明してください。「なぜ起きたか」「何を学んだか」「次にどう防ぐか」を言語化します。これができると、「失敗した人」ではなく「失敗から学べる人」という印象に変換されます。失敗を完全に消すことはできません。ですが、失敗の印象を上書きすることはできます。スポンサーを作れ昇進には「スポンサー」と「可視化」が必要だ。なぜスポンサーが必要なのか昇進は、だいたいあなたの知らないところで決まる。評価会議というものがある。マネージャーが集まって、誰を昇進させるか、誰に良い評価をつけるかを議論する。あなたは、その会議に出席できない。出席できないのに、そこであなたの運命が決まる。あなたの仕事ぶりを知っている人が、その会議にいなければ、あなたの名前は挙がらない。名前が挙がらなければ、昇進しない。どんなに良い仕事をしていても、その会議で誰かがあなたの名前を出さなければ、無意味だ。その「誰か」が、スポンサーだ。スポンサーとメンターの違いメンターは、アドバイスをくれる人だ。キャリアの相談に乗ってくれる。「こうした方がいいよ」「あの人に話を聞いてみたら」と教えてくれる。スポンサーは、あなたの成果を上に伝えてくれる人だ。人事評価の場で、あなたの名前を出してくれる。「あいつは良い仕事をしている」と会議で言ってくれる。この違いは決定的だ。メンターは「あなたのために」アドバイスをくれる。でも、スポンサーは「あなたのために」リスクを取る。評価会議であなたの名前を出すということは、スポンサー自身の信用を賭けることだ。「私が推薦した人」が期待外れだったら、スポンサーの評価が下がる。だから、スポンサーになってもらうのは、メンターになってもらうより難しい。メンターがいても、スポンサーがいなければ、昇進の話にはならない。あなたの良い仕事を知っている人がいても、その人が上に伝えてくれなければ、上層部はあなたを知らない。上司だけがスポンサーではない多くの場合、直属の上司が最初のスポンサー候補になる。でも、上司だけに依存するのはリスクがある。上司が異動することがある。上司が退職することがある。上司との相性が悪いこともある。上司が評価会議で発言力を持っていないこともある。上司一人に依存していると、その上司がいなくなった瞬間、あなたを推してくれる人がゼロになる。だから、上司以外のスポンサーも獲得しろ。評価会議には、複数のマネージャーが参加する。あなたの上司だけでなく、他のチームのマネージャーも発言権を持っている。もし、あなたの名前が複数の人から挙がったらどうなるか。「〇〇さん、評判いいね」となる。一人が推すより、複数が推す方が説得力がある。上司以外のスポンサー候補は、意外と身近にいます。他チームのマネージャー: 横断プロジェクトで一緒に働いた人技術リード: マネージャーに意見を求められる立場の人越境した仕事を意図的に作ってください。横断プロジェクトに手を挙げます。他チームのコードレビューを引き受けます。上司を勝たせることの意味上司が成果を出せば、チーム全体の評価が上がります。リソースが配分されます。自分の評価も上がりやすくなります。「媚びる」と「伝える」は違います。情報の非対称性を埋めているだけです。条件が揃わない場合しかし、これには条件がある。条件1: 上司が「勝とうとしている」こと上司が何を達成しようとしているかを理解できないなら、この戦略は機能しない。目標が不明確な上司、日々の消化試合に終始している上司には、「勝たせる」も何もない。判断方法：1on1で「今期の最優先目標は何ですか」と聞く。具体的な目標を即答できるなら、勝とうとしている。「色々ある」「維持が目標」と言うなら、勝とうとしていない可能性が高い。条件2: 上司が「部下の貢献を認識できる」こと上司を勝たせても、「これは俺の成果だ」と言い張る上司がいる。この場合、どれだけ貢献しても報われない。判断方法：過去の昇進者を観察する。上司が「〇〇さんのおかげで成功した」と言っていたか。チームの成果発表で、メンバーの名前を出していたか。自分の手柄にする上司は、パターンがある。条件3: 組織が「チームの成功を個人にも還元する」構造であることチームが勝っても、個人の評価に反映されない組織がある。年功序列が強すぎる、政治が評価を決める。この場合、上司を勝たせても自分には返ってこない。判断方法：先輩に聞く。「チームが成果を出したとき、個人の評価に反映されましたか」と。曖昧な答えが返ってきたら、還元されていない証拠だ。これらの条件が揃わない場合、「上司を勝たせる」戦略は機能しない。別の手を考える必要がある。例えば、「異動する」「別のスポンサーを見つける」「辞める」だ。上司以外のスポンサーを持っていれば、この「別のスポンサーを見つける」がすでに準備できている。上司に依存しすぎないためにも、日頃から複数のスポンサー候補との関係を築いておくことが重要だ。下振れで測られる対話しても評価が変わらないことがある。そのとき、もう1つ確認すべきことがある。自己認識と他者認識のギャップだ。「最高の自分」は実力ではない多くの人は、「最高の自分」を自分の実力だと思っている。ゾーンに入って神がかった速度でコードを書く自分。難解なバグを一瞬で特定する自分。そういう「最高の瞬間」を「自分の実力」だと信じる。でも、上司が見ているのは別のものだ。上司は、あなたに仕事を任せるとき、こう考える。「この人に任せて、最悪どうなるか」と。最高のケースではない。最悪のケースだ。なぜなら、任せた仕事が期待以下だったとき、責任を取るのは上司だからだ。上司は自分の評価を賭けている。だから、リスクを最小化したい。つまり、あなたは「上振れ」ではなく「下振れ」で判断されている。調子が良い日に出した成果は、「たまたま」でしょう。調子が悪い日に出した成果こそ、「確実に期待できるライン」です。上司が知りたいのは、後者です。だから、自分の実力を測るなら、最高の日ではなく、最悪の日を見てください。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その日に絞り出したアウトプット。それが、他人から見た「あなたの実力」に近いです。安定性という信頼信頼は、瞬間最大風速では測られない。安定性で測られる。毎週コンスタントに成果を出す人と、たまに爆発的な成果を出すが波がある人。どちらが信頼されるか。前者だ。爆発的な成果は印象に残る。でも、任せる側からすれば、「今回はどっちだろう」と毎回賭けをすることになる。安定している人には、安心して任せられる。ここで、あまり語られない現実を書く。体調管理は、評価に直結する。「体調不良は仕方ない」と、口では誰もがそう言う。風邪をひいた、熱が出た、それは本人のせいではない。責めるべきではない。正論だ。でも、現実はそんなに甘くない。風邪で3日寝込めば、1週間分の生産性が消える。体調不良の翌週もパフォーマンスは戻りきらない。締め切り直前に体調を崩せば、チーム全体に影響が出る。上司は、それを見ている。口では「お大事に」と言う。でも、心の中では「また休みか」と思っている。重要なプロジェクトを任せるとき、「この人、大丈夫かな」と不安がよぎる。結果、重要な仕事は「安定して稼働できる人」に回る。これは不公平だと思うだろう。体質の問題もある。本人の努力だけではどうにもならないこともある。それは事実だ。でも、コントロールできる部分は、コントロールしてください。もう1つ重要なことがあります。自分のパフォーマンスが落ちる兆候を自己認識していますか。睡眠不足が続くとどうなるか。ストレスが溜まるとどうなるか。これらを把握しておけば、周囲に「予測可能性」を提供できます。「来週は締め切りが重なっているので、レスポンスが遅くなるだろう」と先に言っておきます。これは弱みを見せることではありません。プロとして自分の状態を管理していることを示しています。上司があなたに仕事を任せるとき、「リスク」として感じている要素は何か。「この人は締め切りを守らない」と思われているなら、小さな約束から確実に守ってください。上司の中にある「リスク認知」を、1つずつ消していってください。他人はあなたの「見えた成果の平均」を見ている自分で認識している自分と、他人が見ている自分は違います。あなたは自分の内面を知っています。「今日は調子が悪い」「昨日は睡眠不足だった」「あのときは本気を出していなかった」。そういう文脈を全て知っています。だから、最高のパフォーマンスを出した日を「本当の自分」だと思います。それ以外の日は、何か理由があってパフォーマンスが落ちた「例外」だと思います。他人は、あなたの内面を知りません。見えるのは、あなたのアウトプットだけです。見えたアウトプットの平均が、「あなた」として認識されます。見せなかった仕事は、平均にすら入りません。最高の日も、最悪の日も、見えた範囲で平均化されます。だから、あなたが「本気を出せばもっとできる」と思っていても、他人から見れば「見えた範囲のあなた」がそのままあなたの実力です。見せていない実力は、存在しないのと同じです。ギャップを埋める方法自己認識と他者認識のギャップを埋めるには、フィードバックを求めるしかない。「私の強みと弱みは何ですか」と上司に聞く。怖い。自分が思っている自分と違う答えが返ってくるだろう。でも、聞かなければギャップは分からない。もう1つの方法は、360度評価の結果を真剣に受け止めることだ。多くの人は、360度評価の結果を「まあ、そういう見方もあるよね」程度で流す。でも、複数の人が同じことを指摘しているなら、それはおそらく事実だ。「本当はもっとできる」は通用しない新しい環境で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。それは言い訳だ。今、目の前で出しているアウトプットが、あなたの実力として認識される。「体調が悪かったので」も通用しない。体調が悪い日も含めた平均が、あなたの実力だ。だから、自分の「下限」を正しく認識することが重要だ。自分が思っているよりも、自分の下限は低いだろう。他人から見えている自分は、自分が思っている自分とは違うだろう。このギャップを認識した上で、どう動くか。それが「構造を理解した上で頑張る」ということだ。チームを勝たせろここまで「やるべきこと」を書いてきた。ここで1つ、やらなくていいことを書く。「最高の人材はオールラウンダーである」——そう信じられている。でも、そもそもオールラウンダーは、組織が作り出した便利な幻想だ。能力は文脈の中にしか存在しない。「オールラウンダー」とは、会社が定義した評価項目の範囲内でバランスが良い、というだけの話だ。それは普遍的な能力ではなく、ある限定された文脈の中で複数の能力がそこそこ高いだけだ。オールラウンダーの罠でも、オールラウンダーを目指すと何が起きるか。どの分野でも「そこそこ」になります。よくある罠があります。評価面談で「コミュニケーション力が弱い」と言われて、無理に改善しようとします。勉強会で発表する練習をします。ファシリテーションの本を読みます。その結果、強みだった技術力を伸ばす時間が減ります。コミュニケーション力は「平均以下」から「平均」になっただけです。技術力は「突出」から「やや上」に落ちました。本末転倒です。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪いです。100時間かけて弱みを「平均以下」から「平均」にするより、100時間かけて強みを「上位10%」から「上位1%」にする方が、価値が出ます。「チームを勝たせる」という発想ここで視点を変えてほしい。ここまで「上司を勝たせてください」と書いてきました。上司の目標に貢献してください。上司の労力を最小化してください。それがスポンサーを獲得し、評価につながる、と。でも、上司を勝たせることは、手段に過ぎません。本質は「チームを勝たせること」です。チームが勝てば、全員が恩恵を受けます。リソースが配分されます。良いプロジェクトが回ってきます。評価の枠が増えます。逆に、チームが負ければ、個人がどれだけ頑張っても報われません。沈む船の上でいくら走っても、沈むことに変わりはありません。だから、「自分がどう評価されるか」ではなく「チームがどう勝つか」を考えてください。強みで貢献するチームを勝たせるために、あなたは何ができるか。答えは単純です。強みで貢献してください。チームには様々な仕事があります。設計、実装、テスト、ドキュメント、調整、発表。全部を一人でやる必要はありません。チームとして、全部ができていればいいです。あなたがコードを書くのが得意なら、コードで貢献してください。ドキュメントが得意な人に、ドキュメントは任せてください。あなたが調整が得意なら、調整で貢献してください。実装が得意な人に、実装は任せてください。これが「補完」です。全員がオールラウンダーを目指すより、それぞれが強みを発揮して補完し合う方が、チームとしての出力は高くなります。優秀な人に共通パターンはありません。コードは神がかっているがドキュメントは壊滅的な人。設計は天才的だが実装は遅い人。トラブルシューティングは超人的だが新規開発には興味がない人。万能な人はいません。でも、チームとして万能であればいいです。弱みはチームでカバーする弱みを克服する必要がないと言っているわけではありません。弱みを自分で克服するか、チームでカバーするかを選んでください、と言っています。弱みを無視していいかどうかは、3つの質問で判断できます。その弱みがないと仕事ができないか？ コミュニケーションが苦手でも、コードで結果を出せるなら問題ありません。ですが、リーダーを目指すなら、コミュニケーションは避けられません。その弱みをカバーする人がチームにいるか？ ドキュメントが苦手でも、得意な人がチームにいれば補完できます。その弱みを平均にする努力で、強みを伸ばす時間が失われないか？ 弱みを平均にするのに100時間かかるなら、その100時間で強みを突き抜けさせた方がいいです。3つとも「いいえ」なら、弱みの克服は後回しでいいです。チームでカバーできる弱みは、チームに任せてください。しかし、役割によって「致命的な弱み」は変わります。今の役割では問題なくても、次の役割では致命的になることがあります。上司と話し合ってください。「私はAが強みで、Bが弱みです。今の役割でBは致命的ですか。次の役割ではどうですか」と。「この人がいないと困る」状態を作るチームを勝たせる中で、「この人がいないと困る」という状態を作ってください。みんなが平均を目指すなら、平均的な人材は溢れます。「そこそこ何でもできる人」は大量にいます。だから、差別化できません。代わりはいくらでもいます。一方、「この分野なら誰にも負けない」と言える人は少ないです。少ないから、価値があります。「この人じゃないと困る」という状況を作れます。それが交渉力になります。「パフォーマンスチューニングなら〇〇さん」「あの複雑な仕様を理解しているのは〇〇さんだけ」「障害対応で真っ先に呼ばれるのは〇〇さん」——こういうポジションを取ってください。チームの中で、代替不可能な存在になってください。「何でもできる人」という便利なラベルを捨ててください。代わりに、「〇〇の問題ならあいつに聞け」という、組織内の検索ワードを確立してください。検索ワードがあれば、困っている人が自分を見つけてくれます。仕事が向こうからやってきます。その仕事で成果を出せば、また検索ワードが強化されます。この循環を作ってください。そして、自分に問うてみてください。あなたの強みをより伸ばすことが、どのように「チーム全体の勝率」に直結するか。個人の成長と、チームの勝利を結びつけて説明できるか。「私が〇〇を極めれば、チームは△△で勝てるようになります」と。この論理が説明できれば、強みを伸ばす時間を堂々と確保できます。これは「自分だけが得をする」話ではありません。チームが勝つために、自分の強みを最大限に活かすという話です。チームが勝ち、その中で自分が不可欠な貢献をしている。この状態が、評価につながります。上司は言えます。「あのプロジェクトが成功したのは、〇〇さんの△△があったからです」と。具体的な貢献があれば、評価会議で名前を出しやすいです。組織の論理と個人の論理を重ねる組織は「オールラウンダーになれ」と言います。でも、その言葉を額面通りに受け取らないでください。組織が本当に求めているのは、「チームが勝つこと」です。オールラウンダーを求めるのは、そのための手段に過ぎません。誰が抜けてもチームが回るように、リスクヘッジしたいだけです。だから、「チームを勝たせる」という目的を共有した上で、手段は自分で選んでください。オールラウンダーになることでチームに貢献できるなら、それでいいです。でも、強みを尖らせることでチームに貢献できるなら、それでもいいです。目的が達成されていれば、手段は問われません。「私はオールラウンダーではありません。でも、この分野では誰にも負けません。チームの勝利に、この強みで貢献します」と言える状態を作ってください。組織の論理と、個人の論理を、「チームを勝たせる」という一点で重ねてください。これが、構造を理解した上で頑張る、ということです。それでもダメならここまでやっても評価されないことがあります。そのときの判断基準を明確にしておきます。「正しく頑張った」の定義成果を言語化し、見せた1on1で評価基準と昇進に必要なことを確認した上司の目標、チームの目標に貢献した評価のタイムラインを意識して動いたフィードバックを受け入れ、行動を変えた上司以外のスポンサーも獲得しようとした強みで貢献し、弱みはチームでカバーしたこの7つを1年間やった上で、評価が変わらなければ、構造の問題です。2年以上待っても変わらないなら、個人の努力では覆りません。しかし、正直に書いておきます。運の要素は大きいです。この記事は、努力すれば報われるかのように書いてきました。でも、現実はそうじゃありません。良い上司に当たるかどうかは、運です。自分の強みを評価してくれる上司、対話に応じてくれる上司、スポンサーになってくれる上司。そういう上司に当たるかどうかは、自分ではコントロールできません。良いプロジェクトに配属されるかも、運です。成果が見えやすいプロジェクト、評価につながりやすい仕事。それに関われるかどうかは、タイミングと巡り合わせです。会社の業績も、運です。会社が成長していれば昇進枠は増えます。会社が停滞していれば枠は減ります。個人の努力とは関係ありません。この記事に書いたことを全部やっても、運が悪ければ評価されません。逆に、何もしなくても、運が良ければ評価されます。そういうことは、あります。私が評価されるようになったのも、運の要素が大きいです。良い上司に当たりました。良いプロジェクトに関われました。会社の業績が良かった時期に、たまたま成果を出せました。努力したのは事実ですが、運が良かったのも事実です。この記事は、「努力でコントロールできる部分」にフォーカスしています。でも、コントロールできない部分の方が大きいでしょう。運が悪いときに、「頑張り方が間違っている」と言われても、救いになりません。運が悪かった人に、私は何も言えません。「次は運が良いといいね」としか言えません。それは無責任でしょうが、本当のことです。見切るべき3つのパターン パターン  状況  対処  上司とのズレ  上司が重視するAと、自分が得意なBがズレている。対話しても埋まらない  異動するか、別のスポンサーを見つける  制度の破綻  年功序列、政治、声の大きい人が勝つ。チームが勝っても個人に還元されない  組織を変えるか、出るか  市場価値との乖離  外では高く評価されるスキルが、今の組織では価値がない  辞める 見切りの解像度を上げろ「組織を辞める」というより、「この人たちと働くことを辞める」と考えた方が正確だ。冒頭で書いた。「どの会社で働くか」より「どのチームで働くか」が大事だと。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要だ。この上司との関係は修復可能か？別のチームに移れば解決するか？この会社の「誰か」に働きかければ変わるか？上司以外にスポンサーになってくれる人はいるか？全部試して、全部無理だった。そのとき初めて「構造の問題」と言える。あなたが直面している「評価への不満」は、個人の努力で突破可能な「運用上の課題」か。それとも、組織のDNAに刻まれた「構造的な腐敗」か。この見極めが重要です。1つの判断材料があります。過去3年間で、あなたと同じような「正論を吐く優秀な人」がどのように去っていったか、そのパターンを分析してください。同じパターンが繰り返されているなら、構造の問題です。もう1つの判断材料があります。今の会社で「最も高く評価されている人」の振る舞いは、あなたが5年後に「なりたい姿」と重なるか。重ならないなら、この組織で評価されることに意味があるのか。経営陣が「評価制度の不備」を認識していながら変えないなら、それは彼らにとって「都合が良い」からでしょう。仕組みの問題か、人の問題か「評価制度を変えればいい」——そう思いがちです。でも、制度を変えても、運用する人が変わらなければ、結果は変わりません。本当の問題は、制度ではなく、人と人の関係性にあることが多いです。逆もあります。「この上司が悪い」と思っていても、制度が上司にそう振る舞わせている場合があります。上司も構造の中で動いています。上司を責めても、構造は変わりません。撤退は戦略だ構造的な問題がある場合、とっとと辞めてください。「変われない組織」には共通パターンがあります。正しく頑張っても報われない構造ができあがっています。仕事が見えなくなり、提案が通らなくなり、評価基準が不透明になり、変えようとする人が去っていきます。こうなった組織は、個人の努力では変えられません。見極めのサインあなたの組織がこの状態に陥っているかどうか、いくつかのサインがあります。「これ、誰の仕事？」という会話が週に何度もある障害を未然に防いでも誰も気づかない提案しても「今は優先度が低い」と言われ続ける「なぜこのプロセス？」に「昔からこう」と返ってくる「変えようとして辞めた人」の話をよく聞くチームが勝っても、個人の評価に反映されないこれらのサインが複数当てはまるなら、個人の努力で変えるのは難しいです。異動か転職を視野に入れてください。成功した組織ほど変われなくなる皮肉なことに、成功した組織ほど変われなくなります。「過去にこうやってうまくいった」という経験が、新しいやり方を排除します。成功体験が足かせになります。あなたが「この組織はおかしい」と感じるとき、それは正しいでしょう。組織は過去の成功に縛られて、新しい環境に適応できなくなっているのでしょう。その場合、あなた個人が変えられることは限られています。構造を変えるには、経営層が本気で取り組む必要があります。それがないなら、辞めてください。撤退は戦略である「おい、辞めるな」で書きました。短期ではなく長期で考えてください。信頼の貯金を積み上げてください。転職はリセットコストがかかります。でも、「長期で考えた結果、辞める」という判断もあります。1年間正しく頑張りました。構造を理解した上で動きました。対話を試みました。スポンサーを探しました。チームを勝たせようとしました。それでも変わりませんでした。組織が考える力を失っていて、経営層も本気で取り組む気配がありません。そういう状況なら、辞めることが長期的に正しい判断です。それは逃げではありません。戦略的撤退です。交渉してダメなら去るしかし、順番を間違えないでください。まず交渉してください。評価に納得がいかないなら、上司に聞いてください。「何をすれば評価されるのか」を明確にしてください。構造に問題があると思うなら、提案してください。改善案を出してください。異動を申し出てください。別のスポンサーを探してください。やれることをやってください。交渉するとき、あなたの言葉に「重み」はありますか。社外の市場価値を把握していますか。「いつでも外に出られる」という自信が、言葉に重みを与えます。交渉するなら、「何を、いつまでに、どう変えてほしいか」を具体的に伝えてください。そして、交渉が決裂した際の「プランB」は準備していますか。プランBがないまま交渉しても、本気度が伝わりません。それでダメなら、去ってください。この順番が大事です。交渉せずに辞めるのは、ただの逃げです。でも、交渉した上で辞めるのは、戦略です。「やることはやった。それでも変わらなかった」という事実が、あなたの判断を正当化します。次の面接で「なぜ辞めたのか」と聞かれたとき、「改善を試みたが、構造的に無理だった」と言えます。というか、交渉するというのは、それぐらいデカいことです。「評価に納得いきません」「異動させてください」「この構造を変えてください」——これを口にした時点で、あなたは覚悟を示しています。ダメだったら去る覚悟を。交渉とは、そういう重さを持つ行為です。軽い気持ちで切り出すものではありません。だからこそ、ダメだったときに居座るのは筋が通りません。覚悟を示しておいて、結果が出たら何もしない。それは自分の言葉を裏切ることです。全てはトレードオフです。残るコストと、去るコストがあります。残れば、信頼の貯金を積み上げられます。人間関係もリセットされません。でも、構造が変わらないなら、消耗し続けます。3年後も5年後も同じ愚痴を言っている自分が見えます。去れば、リセットコストがかかります。また一から信頼を築く必要があります。新しい環境に適応するストレスもあります。でも、正しく評価される構造の中で働ける可能性があります。どちらが正解か、一般論では言えません。あなたの状況によります。あなたの価値観によります。あなたのキャリアのフェーズによります。ただ、1つだけ言えます。交渉してダメだったのに居座り続けるのは、最悪の選択です。構造が変わらないと分かりました。自分の力では変えられないと確認しました。それでも残る。それは「判断を放棄している」だけです。答えは出ているのに、行動しません。時間だけが過ぎていきます。交渉してください。ダメなら去ってください。それがトレードオフを引き受けるということです。辞める前に確認することしかし、辞める前に確認すべきことがあります。1. 本当に構造の問題か「評価されない」と感じるとき、構造のせいにしたくなります。自分のせいではない。組織が悪い。そう思いたいです。でも、まず自分を疑ってください。ちゃんと見せていたか。対話していたか。チームを勝たせようとしていたか。強みで貢献していたか。これらを本当にやった上で、評価されなかったのか。構造のせいにするのは、自分の責任を回避できて楽です。でも、構造のせいにして辞めても、次の組織で同じことが起きるでしょう。2. 異動で解決できないか「組織を辞める」前に、「チームを辞める」を検討してください。別のチームに移れば解決することがあります。上司が変われば、評価が変わることがあります。別のスポンサーがいれば、状況が変わることがあります。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要です。3. 辞めた後に何があるか辞めることを決める前に、辞めた後の絵を描いてください。「ここから出たい」だけでは、どこに行っても同じ問題にぶつかります。次の組織で何をしたいのか。どんな環境なら自分の強みを活かせるのか。どんなチームなら自分が貢献できるのか。それが見えてから、辞めてください。大企業にいるなら、よく考えろあなたは自分が持っているものを過小評価しています。 安定した給与、福利厚生、開発環境、ネームバリュー。これらが「普通」に感じられています。不満ばかりが目につきます。でも、構造的な問題——評価制度の限界、政治、見えない仕事の軽視——は、大企業だから存在するのではありません。組織という形態が持つ宿命です。スタートアップでも20人を超えれば政治が生まれます。50人を超えれば部門間の壁ができます。環境を変えても、構造は変わりません。大企業を辞める前に、まず異動を検討してください。辞めなくても環境を変えられます。サバンナで戦う覚悟があるなら飛び出せばいいです。覚悟がないなら、城壁の中で戦略を練ってください。辞めると決めたら辞めると決めたら、長居しないでください。「あと半年頑張ってみよう」「プロジェクトが終わるまで」と思いがちです。でも、辞めると決めた組織で頑張り続けるのは、消耗します。モチベーションが上がりません。パフォーマンスが落ちます。評価が下がります。悪循環にハマります。辞めると決めたら、次を探し始めてください。時間をかけすぎないでください。辞めても何も変わらないだろう正直に言えば、辞めても何も変わらないでしょう。次の組織も、同じような問題を抱えているでしょう。評価制度に限界があります。上司との相性があります。政治があります。これは、どの組織にもあります。というかそれはあなたの問題でもあります。そこに向き合ったほうが良いです。転職は、問題を解決する魔法ではありません。環境を変えるだけです。新しい環境で、同じ問題に別の形でぶつかることもあります。だから、辞める前に、「この問題は環境を変えれば解決するのか、自分が変わらないと解決しないのか」を考えてください。環境の問題なら、辞めてください。自分の問題なら、自分を変えてください。両方なら、両方やってください。届かない人へここまで書いてきて、立ち止まります。「見せてください」「対話してください」「チームを勝たせてください」——私はそう書きました。構造を理解した上で、その中でうまくやってください、と。でも、この記事が届かない人がいます。頑張れない人がいる「頑張り方を変えてください」と言いました。ですが、もう頑張る余力がない人はどうするのか。すでに消耗している人。毎日出社するだけで精一杯の人。週次報告に「何が難しかったか」を1文追加する気力すらない人。1on1で交渉する心理的余裕がない人。彼らに「見せてください」「対話してください」と言っても、届きません。むしろ、「お前の頑張りは間違っている」と告げることになります。追い詰めることになります。「体調管理は評価に直結する」と書きました。事実です。でも、体調を管理できない人がいます。慢性疾患を抱えている人。精神疾患と付き合っている人。家庭の事情で睡眠時間を削らざるを得ない人。介護や育児で「安定して稼働」できない人。彼らは、努力が足りないのではありません。構造が彼らを排除しているのです。「アピールが苦手なら、存在しないのと同じだ」と書きました。ですが、アピールが苦手な人は、苦手だから苦労しています。「苦手を克服してください」と言うのは簡単です。でも、克服できないから苦手なのです。内向的な人、言語化が苦手な人、自己主張に強い抵抗がある人。彼らに「見せてください」と言っても、できないものはできません。この記事に書いた「正しい頑張り方」ができる人は、すでに恵まれています。対話する余力があります。アピールする能力があります。安定して稼働できる体があります。それらを持っている時点で、スタートラインが違います。私は、持っている側でした。だから、この記事を書けました。持っていない人に、同じことを求めるのは、傲慢でしょう。「頑張らない」という選択肢「辞めないなら頑張ってください」と書きました。ですが、「辞めないけど頑張らない」という選択肢もあります。昇進を追わない。評価を気にしない。自分のペースで働く。それは「諦め」ではありません。評価ゲームから意識的に降りるという戦略です。評価制度は、組織が作ったゲームに過ぎません。そのゲームに参加するかどうかは、自分で選べます。「昇進しなければ給料が上がらない」と言うでしょう。ですが、昇進のために消耗して、心身を壊したら、給料どころではありません。評価を追いかけて、本来の仕事の楽しさを失ったら、何のために働いているのか分からなくなります。評価されなくても、良い仕事はできます。障害を未然に防いだ本人は、その価値を知っています。上司が知らなくても、自分は知っています。それで十分だと思える人もいます。もし今の評価ゲームが「勝てない設定」であるなら、「頑張らない」ことで確保したエネルギーを、どこに投資するか考えてみてください。社内の評価を「食い扶持を維持する程度」にコントロールし、余ったリソースで社外での市場価値を育てることは可能か。今の場所を「人生のゴール」ではなく「ベースキャンプ」と定義し直してください。もちろん、評価されないと生活に困ることもあります。だから、全員にこの選択肢を勧めているわけではありません。ただ、「頑張らない」という選択肢もあることを、知っておいてほしいです。評価ゲームに全てを賭ける必要はありません。降りてもいいです。構造を変えるという選択肢「仕組みは変えられない。自分は変えられる」と書きました。ですが、本当に変えられないのか。「見えない仕事」を評価する仕組みを作った組織はあります。障害を未然に防いだことを、きちんと評価する制度を設計した会社はあります。短期成果だけでなく、長期的な貢献を測る仕組みを導入したチームはあります。変えられないのではありません。変えようとする人がいなかっただけでしょう。変えようとした人が、諦めて辞めていっただけでしょう。この記事では、構造を変える方法は書きませんでした。正直、私にはその経験がないからです。私は構造の中で適応する方を選んできました。変えようとしたこともありますが、うまくいきませんでした。だから、「変えてください」とは言えませんでした。でも、適応することが唯一の選択肢ではありません。もしあなたに発言力があるなら、提案してみてもいいです。評価制度を変える提案。見えない仕事を可視化する仕組み。非機能要件を評価する基準。障害を未然に防いだことを記録するプロセス。変わらないでしょう。でも、変わるでしょう。少なくとも、試さなければ分かりません。「構造を理解した上で適応する」は、1つの戦略です。でも、「構造を理解した上で変えようとする」も、1つの戦略です。どちらを選ぶかは、あなた次第です。多様な「正解」があるこの記事は、「評価される頑張り方」を書きました。ですが、それが唯一の正解ではありません。評価を追いかけて、昇進して、影響力を持つ。それも正解です。評価を諦めて、自分のペースで働く。それも正解です。構造を変えようとして、組織を動かす。それも正解です。評価ゲームから降りて、別の働き方を選ぶ。それも正解です。どれが正しいかは、あなたの状況によります。あなたの価値観によります。あなたの人生のフェーズによります。「辞めないなら頑張ってください」と私は書きました。でも、「辞めないけど頑張らない」でもいいです。「辞めないで、構造を変えようとする」でもいいです。この記事が、あなたを追い詰めるためにあるのではありません。選択肢を増やすためにあります。そう思いたいです。おわりに先週の記事に、思った以上の反響がありました。「辞めないことにしました」という連絡をくれた人たちが、どんな人で今どうしているのか、私は知りません。うまくいっているといいです。うまくいっていなくても、間違えながら何とかやっているといいです。この文章を書き終えました。書いている間、何度か手が止まりました。こんなことを書いて、誰かの役に立つのだろうか。自分が経験したことを、他人に押し付けているだけではないか。答えは出ませんでした。出ないまま、最後まで書きました。明日からできることはあります。週次報告に「何が難しかったか」を1文足す。1on1で「昇進に必要なこと」を聞く。カレンダーに「評価2ヶ月前」をマークする。見えない仕事を、見える形にする。それだけで、何かが変わるでしょう。たぶん、私は来週の週次報告で「何が難しかったか」を書くのを忘れます。上司を敵認定しそうになります。また同じ愚痴を居酒屋で言います。間違えたら直せばいいです。間違えていることに気づいているなら、まだやれます。たぶん。「評価が上がりました」でも、「やっぱり辞めました」でも、「まだ間違え続けています」でも、「頑張るのをやめました」でも。どれでもいいです。どれも、選んだ道を歩いている証拠だと思うから。正解かどうかは、分かりません。私がやってきたことが正しかったかどうかも、分かりません。分かるのは、ずっと後になってからです。おい、辞めないなら頑張ってください。頑張り方を間違えないでください。——と、ここまで書いてきました。でも、最後に付け加えておきます。頑張れないなら、頑張らなくていいです。降りてもいいです。休んでもいいです。それも、1つの選択です。私も、まだ間違え続けています。それでいいのだと思います。続編も書きました。syu-m-5151.hatenablog.com参考書籍外資系コンサルの仕事の進め方: 実践の場で使える問題解決の基盤スキル作者:金地 毅,田辺 元,柳田 拓未東洋経済新報社Amazon私文ホワイトカラーが AI・コンサルに仕事を奪われない働き方戦略作者:株式会社板橋　東京中央支店かんき出版AmazonSOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazonソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社AmazonTHE CULTURE CODE 最強チームをつくる方法作者:ダニエル・コイル,楠木建かんき出版Amazonセンスメイキング――本当に重要なものを見極める力作者:クリスチャン・マスビアウプレジデント社Amazon心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon組織と働き方の本質　迫る社会的要請に振り回されない視座 (日本経済新聞出版)作者:小笹芳央日経BPAmazon［新版］組織行動の考え方―個人と組織と社会に元気を届ける実践知作者:金井 壽宏,高橋 潔,服部 泰宏東洋経済新報社Amazon「組織と人数」の絶対法則―人間関係を支配する「ダンバー数」のすごい力作者:トレイシー・カミレッリ,サマンサ・ロッキー,ロビン・ダンバー東洋経済新報社Amazonチームの力で組織を動かす 〜ソフトウェア開発を加速するチーム指向の組織設計作者:松本 成幸技術評論社Amazon恐れのない組織――「心理的安全性」が学習・イノベーション・成長をもたらす作者:エイミー・C・エドモンドソン,村瀬俊朗英治出版Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazon多様性の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新　失敗学　正解をつくる技術作者:畑村洋太郎講談社Amazon企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon「わかりあえない」を越える――目の前のつながりから、共に未来をつくるコミュニケーション・NVC作者:マーシャル・B・ローゼンバーグ海士の風Amazonみんな違う。それでも、チームで仕事を進めるために大切なこと。作者:岩井俊憲ディスカヴァー・トゥエンティワンAmazonなぜ働く？　誰と働く？　いつまで働く？　限られた人生で後悔ない仕事をするための20の心得作者:有山 徹アスコムAmazon問いかける技術――確かな人間関係と優れた組織をつくる作者:エドガー・H・シャイン英治出版Amazon","isoDate":"2026-01-11T15:30:13.000Z","dateMiliSeconds":1768145413000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"OAuth2認証をE2Eテストしたら、5つのバグが出てきた話","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/11/064311","contentSnippet":"はじめに認証が動いた。だがそれは始まりに過ぎなかった。前回の記事では、Next.jsでOry Hydra認証を実装した。OAuth2認可コードフロー、Cookie管理、ID Token署名検証、マルチテナント認証について解説した。前提知識: この記事は前回の記事の続編です。Next.jsでのOAuth2認証フロー実装を理解している前提で進めます。Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践 - じゃあ、おうちで学べる今回は、実装した認証フローを検証する。Playwright MCPを使ったE2Eテスト、発見した5つのバグ、RBACの検証、そしてベストプラクティスとの比較までを一気に解説する。Playwright MCPによるE2Eテストもう本当に10年くらい前は「E2Eテストなんて、デモ前に手動で確認すれば十分でしょ」と思っていた。仕事でフロントエンド書いたことなかったので…。今の自分から言わせてもらえば、それは個人の能力を過信している。あとはフロントエンドのテストの大変さを軽く見ている。OAuth2フローのE2Eテストは手動では破綻する。複数のリダイレクト、Cookie管理、セッション状態の確認——これらを毎回手動で確認するのは、人間の注意力の限界を超えている。「今日は疲れていたから見落とした」で本番障害が起きるのは、個人の問題ではなく構造的な失敗だ。人間に頼らない仕組みを作る必要がある。Claude CodeとPlaywright MCPの組み合わせPlaywright MCPは、LLMがブラウザを直接操作できるModel Context Protocol（MCP）サーバーだ。Claude Codeと組み合わせることで、自然言語でE2Eテストを実行できる。従来のPlaywrightとの違いは、スクリプトを書かずにテストできる点だ。# セットアップ（プロジェクトごとに一度だけ）claude mcp add --transport stdio playwright --scope project -- npx -y @playwright/mcp@latest.mcp.jsonが生成される：{  \"mcpServers\": {    \"playwright\": {      \"type\": \"stdio\",      \"command\": \"npx\",      \"args\": [\"-y\", \"@playwright/mcp@latest\"]    }  }}実際のテスト実行例Claude Codeで以下のように指示する：Playwright MCPでOAuth2フローをE2Eテストしてください：1. http://localhost:3001/ にアクセス2. Sign Inをクリック3. demo@example.com / password123 でログイン4. Consentで Allow をクリック5. ダッシュボードが表示されることを確認6. スクリーンショットを取得Claude Codeは以下のツールを順次実行する： ステップ  MCPツール  結果  1  browser_navigate  ホームページ表示  2  browser_click (ref=e10)  Hydra認可エンドポイントへリダイレクト  3  browser_fill_form  ログインフォーム入力完了  4  browser_click (Sign In)  Consent画面へリダイレクト  5  browser_click (Allow)  トークン交換・フロントエンドへリダイレクト  6  browser_take_screenshot  エビデンス取得 ARIA Snapshotの活用Playwright MCPの特徴は、DOMではなくアクセシビリティツリーでページ構造を表現する点だ。各要素にはref=eXX形式の参照IDが付与される：- banner:  - navigation:    - link \"Sign In\" [ref=e10] [cursor=pointer]:      - /url: /api/auth/loginこのref=e10を使ってクリック対象を指定する。セレクタの管理が不要になり、UIの変更に強いテストが書ける。従来のE2Eテストとの比較 項目  従来のPlaywright  Playwright MCP  テスト作成  スクリプト記述が必要  自然言語で指示  セレクタ管理  CSSセレクタ/XPath  ARIA参照ID  リダイレクト追跡  手動でwait設定  自動追跡  デバッグ  ログ/スクリーンショット  対話的に確認可能  再現性  高（スクリプト化）  中（LLMに依存） Playwright MCPは「探索的テスト」に向いている。本番のCIには従来のPlaywrightスクリプトを使い、開発中の手動確認をPlaywright MCPで効率化する、という使い分けがよさそうだ。E2Eテストで発見した5つのバグPlaywright MCPとシェルスクリプトによるE2Eテストを実行した結果、5つの重要なバグを発見・修正した。OAuth2+マルチテナント構成の複雑さを示す良い事例だ。バグ1：CORS設定の欠如症状：フロントエンド（localhost:3001）からバックエンド（localhost:3000）へのAPIリクエストがブロックされる原因：Axumルーターにtower-httpのCorsLayerが設定されていなかった修正（src/main.rs）：use tower_http::cors::{Any, CorsLayer};let app = Router::new()    // ... routes ...    .layer(        CorsLayer::new()            .allow_origin(Any)            .allow_methods(Any)            .allow_headers(Any),    )教訓：これは個人の注意力の問題ではない。フロントエンド・バックエンド分離構成では、CORSは「設定を忘れると動かない」構造になっている。チェックリストに入れる。プロジェクトテンプレートに含める。人間の記憶に頼らない仕組みを作る。「動かない」の原因がCORSだと気づくまでに時間がかかることがある。エラーメッセージが分かりにくいからだ。ブラウザのコンソールを見る習慣をつけるしかない。詳細はMDN: CORSを参照。バグ2：Cookieパース時のJWTトークン切り詰め症状：認証後のAPIリクエストで401エラーが発生原因：.split(\"=\")[1]でCookieを取得すると、base64エンコードされたJWTの=パディング文字で切れてしまう// ❌ 危険：JWTが途中で切れるconst token = document.cookie  .split(\"; \")  .find((row) =\u003e row.startsWith(\"auth_token=\"))  ?.split(\"=\")[1];  // \"ory_at_abc...def=\" → \"ory_at_abc...def\" で切れる// ✅ 正しい：トークン全体を取得const cookieRow = document.cookie  .split(\"; \")  .find((row) =\u003e row.startsWith(\"auth_token=\"));const token = cookieRow ? cookieRow.substring(\"auth_token=\".length) : null;教訓：JWTは必ずbase64パディング（=）を含む可能性がある。文字列操作でトークンを扱う時は要注意。バグ3：HydraトークンとJWTの不一致症状：フロントエンドからのAPIリクエストで401エラー。curlでJWTを直接送ると成功する。原因：- フロントエンドはHydra発行のアクセストークン（ory_at_...形式）を使用- バックエンドは自前のJWTのみ対応していた修正（src/middleware/auth.rs）：// JWT検証を試み、失敗したらHydraイントロスペクションにフォールバックlet claims = match state.jwt.verify_access_token(token) {    Ok(claims) =\u003e claims,    Err(_) =\u003e {        // Hydra Admin APIでトークンを検証        let introspection = state.hydra.introspect_token(token).await?;        // IntrospectionResponseからClaimsに変換        Claims::from(introspection)    }};教訓：OAuth2プロバイダー（Hydra）のトークンと自前JWTの両方をサポートするか、どちらか一方に統一するか、設計段階で決めておくべきだった。バグ4：テナント抽出ミドルウェアの欠如症状：テナントAPI（/api/v1/tenant/*）で「No tenant context」エラー原因：tenant_apiルーターにextract_tenantミドルウェアが適用されていなかった修正（src/main.rs）：let tenant_api = Router::new()    // ... routes ...    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::require_auth,    ))    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::extract_tenant,  // 追加    ));教訓：ミドルウェアの適用漏れは見つけにくい。各ルートグループに必要なミドルウェアをリスト化しておくとよい。バグ5：X-Tenant-Slugヘッダーの欠如症状：ローカル開発環境でテナントが識別できない原因：- 本番環境ではサブドメイン（tenant-a.example.com）でテナント識別- ローカル開発ではlocalhost:3001のためサブドメインが使えない- フロントエンドがX-Tenant-Slugヘッダーを送信していなかった修正（frontend/src/lib/api.ts）：class ApiClient {  private tenantSlug: string = \"test-shop\"; // デフォルトテナント  private async fetch\u003cT\u003e(endpoint: string, options: RequestInit = {}): Promise\u003cT\u003e {    const headers: HeadersInit = {      \"Content-Type\": \"application/json\",      \"X-Tenant-Slug\": this.tenantSlug,  // 追加      ...options.headers,    };    // ...  }}教訓：マルチテナントのテナント識別は、サブドメイン方式とヘッダー方式の両方をサポートしておくとローカル開発が楽になる。E2Eテスト実行結果修正後のOAuth2フロー完全テスト：=== DONADONA E2E Test v4 ===1. Starting OAuth2 Flow...   Login Challenge: LuAyzZfWTX03DnVcFC1xu0A-rntZcx...2. Submitting Login (demo@example.com)...   Consent Challenge obtained3. Approving Consent...   Final: http://localhost:3001/callback?code=ory_ac_d9jRSkWUb1YXm...4. Token Exchange...   Access Token: ory_at_dxBjsXjmRvMuTcSJercIxT_Kq2nUIR6OrUhdBEcEZIg...5. Testing API Endpoints...   Engineers Count: 36. Backend Verification:   slug_from_header=Some(\"test-shop\")   Hydra token introspection successful: sub=Some(\"3767fa6a-...\")============================================   E2E Test PASSED - All fixes verified!============================================複数アカウントでのRBAC検証E2Eテストの最後に、異なるロールのアカウントでログインして、役割ベースアクセス制御（RBAC）が正しく機能しているかを検証した。テスト結果のサマリー以下は修正前のテスト結果だ。platform_adminがDashboardで403を返すなど、明らかな異常がある。詳細は後述する。 アカウント  ロール  ナビゲーションメニュー  アクセス可能ページ  demo@example.com  platform_admin  全メニュー  Dashboard(403)、その他未テスト  manager@example.com  manager  全メニュー  Dashboard, Incidents, Projects, Engineers, Recruitment, Leaderboard  sato@example.com  engineer  制限メニュー  Dashboard, Incidents, Projects, Leaderboard  reporter@example.com  reporter  制限メニュー  すべてAccess Denied 発見1：フロントエンドとバックエンドのデータ不一致テストアカウント一覧を表示するフロントエンドのホームページには、こう書いてあった：Reporter | customer@example.com | Report incidents onlyしかし実際にcustomer@example.comでログインすると、ヘッダーにはengineerと表示された。データベースとフロントエンドの表示が不一致だった。正しいReporterアカウントはreporter@example.comだった。発見2：ロールごとのメニュー制御Playwright MCPのARIAスナップショットで、ロールごとのナビゲーションメニューの違いを確認できた。Manager（manager@example.com）のメニュー：- link \"Dashboard\" [ref=e10]- link \"Incidents\" [ref=e11]- link \"Projects\" [ref=e12]- link \"Engineers\" [ref=e13]- link \"Recruitment\" [ref=e14]- link \"Leaderboard\" [ref=e15]Engineer（sato@example.com）のメニュー：- link \"Dashboard\" [ref=e10]- link \"Incidents\" [ref=e11]- link \"Projects\" [ref=e12]- link \"Leaderboard\" [ref=e13]# Engineers, Recruitmentが表示されない発見3：Reporterの「何もできない」状態reporter@example.comでログインして各ページにアクセスすると、すべて「Access Denied」が表示された。CLAUDE.mdによると、Reporterは「Report incidents only」という説明だったが、実際にはインシデントページすら見られない。これは設計ミスだった。修正が必要だ。フロントエンドとバックエンドの権限制御問題の根本原因Reporterロールがすべてのページでアクセス拒否されていた原因は、Next.jsのmiddleware.tsにあった：// 修正前：ReporterはADMIN_PATHSに含まれていないconst ADMIN_PATHS = [\"/dashboard\", \"/incidents\", \"/projects\", \"/engineers\", \"/recruitment\", \"/leaderboard\"];// ロールチェック：platform_admin, manager, engineerのみ許可if (isAdminPath \u0026\u0026 ![\"platform_admin\", \"manager\", \"engineer\"].includes(role)) {  return NextResponse.redirect(new URL(\"/?error=unauthorized\", request.url));}修正内容// 修正後：ADMIN_PATHSから/incidentsを分離し、REPORTER_PATHSを新設const ADMIN_PATHS = [\"/dashboard\", \"/projects\", \"/engineers\", \"/recruitment\", \"/leaderboard\"];const REPORTER_PATHS = [\"/incidents\"];  // Reporter専用パス// Reporter paths - reporter, engineer, manager, platform_admin can accessconst isReporterPath = REPORTER_PATHS.some((p) =\u003e pathname.startsWith(p));if (isReporterPath \u0026\u0026 ![\"platform_admin\", \"manager\", \"engineer\", \"reporter\"].includes(role)) {  return NextResponse.redirect(new URL(\"/?error=unauthorized\", request.url));}// Admin paths - platform_admin, manager, engineer can access (not reporter)const isAdminPath = ADMIN_PATHS.some((p) =\u003e pathname.startsWith(p));if (isAdminPath \u0026\u0026 ![\"platform_admin\", \"manager\", \"engineer\"].includes(role)) {  return NextResponse.redirect(new URL(\"/?error=unauthorized\", request.url));}これで権限階層が明確になった： パス  platform_admin  manager  engineer  reporter  /tenants  ✅  ❌  ❌  ❌  /dashboard  ✅  ✅  ✅  ❌  /incidents  ✅  ✅  ✅  ✅  /projects  ✅  ✅  ✅  ❌ 多層防御の実装「フロントエンドで権限チェックすればいい」という意見と、「バックエンドだけでやるべき」という意見がある。どちらも正しく、どちらも不十分だ。フロントエンドだけでは、攻撃者がcurlで直接APIを叩けば突破される。バックエンドだけでは、権限のないユーザーが画面を見てから「アクセス拒否」されるUXになる。答えは「両方やる」——多層防御と呼ばれる考え方だ。城の防壁が一重ではなく多重であるように、セキュリティも複数のレイヤーで守る。フロントエンドのmiddleware.tsだけでは不十分だ。攻撃者はフロントエンドを完全にバイパスできる：# フロントエンドを経由せずにAPIを直接叩けるcurl -s http://localhost:3000/api/v1/tenant/incidents \\  -H \"Authorization: Bearer $TOKEN\" \\  -H \"X-Tenant-Slug: test-shop\"Rustバックエンド（Axum）では、権限制御が複数のレイヤーで行われている：レイヤー1：require_auth（認証） - トークンが有効かどうかをチェックレイヤー2：extract_tenant（テナント抽出） - X-Tenant-Slugヘッダーからテナントを特定レイヤー3：ハンドラー内のロールチェック - 特定の操作でロールをチェックpub async fn assign_incident(/* ... */) -\u003e Result\u003cJson\u003cIncidentWithStatus\u003e, AppError\u003e {    let role = claims.get_role();    if !role.can_manage_team() {        return Err(AppError::Forbidden(            \"Only managers can assign incidents\".to_string(),        ));    }    // ...}多層防御が正解だ： レイヤー  役割  目的  フロントエンド middleware  早期リダイレクト  UX向上、不要なリクエスト削減  バックエンド require_auth  認証チェック  不正アクセス防止  バックエンド ハンドラー  操作ごとの認可  きめ細かい権限制御 ベストプラクティスとの比較この実装が業界のベストプラクティスにどれだけ準拠しているかを評価する。OWASP Top 10 2025との比較OWASP Top 10 2025でBroken Access Controlが1位を維持している。 OWASP推奨事項  準拠状況  実装詳細  サーバーサイドでのアクセス制御  ✅ 準拠  Axumミドルウェアで全APIを保護  デフォルト拒否  ✅ 準拠  未認証リクエストは全て拒否  アクセス制御の再利用  ✅ 準拠  require_authを全ルートで共有  レコード所有権の検証  ⚠️ 部分的  テナント分離は実装、リソース単位は未実装  アクセス制御失敗のログ  ⚠️ 部分的  tracingでログ出力、アラートは未実装  レート制限  ❌ 未実装  APIにレート制限なし  JWTの不正利用防止  ✅ 準拠  Hydraによるトークン検証  セキュリティヘッダ  ⚠️ 部分的  HSTS, X-Frame-Options, X-Content-Type-Optionsの設定が必要  入力値バリデーション  ✅ 準拠  サーバーサイドでバリデーション実施 Next.jsセキュリティガイドラインとの比較Next.js Authentication Guideは、認証に関する重要な警告を含んでいる。 Next.js推奨事項  準拠状況  実装詳細  Middlewareだけに依存しない  ✅ 準拠  バックエンドでも認証チェック  Data Access Layer (DAL)の使用  ⚠️ 部分的  サービス層で分離、専用DALなし  HttpOnly Cookieの使用  ⚠️ 部分的  auth_tokenは非HttpOnly Next.jsチームは「middlewareは認証に安全ではない」と警告している。この多層防御は、CVE-2025-29927のようなmiddlewareバイパス脆弱性への対策にもなる。RBACパターンとの比較 RBACベストプラクティス  準拠状況  実装詳細  バックエンドでのポリシー強制  ✅ 準拠  ハンドラー内でロールチェック  フロントエンドはUI適応のみ  ✅ 準拠  メニュー表示/非表示で対応  権限キャッシュ  ❌ 未実装  毎リクエストでHydra呼び出し  中央集権的ポリシー管理  ⚠️ 部分的  定義は分散している  ロール階層の明確化  ✅ 準拠  4段階のロール階層を定義 総合評価 評価軸  スコア  コメント  OWASP Top 10 2025  7/10  基本的なアクセス制御は準拠、レート制限が不足  Next.js Security  8/10  多層防御を実装、HttpOnly Cookieが部分的  RBAC Patterns  7/10  フロントエンド/バックエンド分離は適切、権限定義が分散 強み：多層防御の実装：フロントエンド + バックエンド + ハンドラーの3層テナント分離：PostgreSQLスキーマレベルでのデータ分離OAuth2標準準拠：Ory Hydraによる標準的なOAuth2/OIDC実装トークン検証の二重化：自前JWT + Hydraイントロスペクションのフォールバック弱み：正直に言えば、見落としがあるかもしれない。セキュリティの評価は、「問題がない」ことを証明できない。見つかっていないだけかもしれない。だから、この記事を読んで「これで完璧だ」と思わないでほしい。OWASP Top 10のチェックリストを自分で回して、この記事で触れていない項目を確認してほしい。それを前提に、現時点で認識している弱みを列挙する。レート制限なし：DoS攻撃への脆弱性権限定義の分散：フロントエンドとバックエンドで定義が重複権限キャッシュなし：毎リクエストでHydraに問い合わせ監査ログの不足：アクセス制御失敗のアラート機能なし改善ロードマップ優先度順に改善すべき項目： 優先度  項目  工数  効果  高  レート制限の追加  小  DoS防止、OWASP準拠  高  監査ログとアラート  中  インシデント検出  高  セキュリティヘッダの追加  小  HSTS, X-Frame-Options, X-Content-Type-Options  中  権限定義の一元化  中  保守性向上  中  権限キャッシュ（Redis）  中  パフォーマンス向上  中  Cookie Prefix（__Host-）の導入  小  Cookie属性の強制  低  PKCE導入  小  認可コード横取り防止  低  HttpOnly Cookie化  中  XSS対策強化 // 改善案：tower-governor等でレート制限を追加use tower_governor::{governor::GovernorConfigBuilder, GovernorLayer};let governor_conf = GovernorConfigBuilder::default()    .per_second(10)    .burst_size(50)    .finish()?;let app = Router::new()    // ...    .layer(GovernorLayer { config: governor_conf });まとめOAuth2 + マルチテナントの認証システム実装を通じて学んだこと「動く」と「正しく動く」は違う：ログインできても、APIが動くとは限らない。APIが動いても、全ロールで正しく動くとは限らない。全ロールで動いても、攻撃に耐えるとは限らない。5つのバグすべてが、「ログインできた」の後に発見されたE2Eテストは必須：すべてユニットテストでは発見できなかった多層防御が重要：フロントエンドだけ、バックエンドだけでは不十分全ロールで検証する：「ログインできた」だけでは不十分ベストプラクティスとのギャップを把握する：何ができていて、何が不足しているかを明確にする認証は地味だが重要だ。インシデント対応のように緊張感もないし、新機能開発のような達成感もない。でも、認証が崩れたときの被害は、他のどの機能障害よりも大きい。過去に見た事例では、セッション管理の不備で全ユーザーのデータが漏洩した。復旧に数ヶ月、信頼回復に1年以上かかった。地味なものほど、丁寧にやる。例えば、この記事で示したE2Eテスト、全ロールでの検証、ベストプラクティスとの比較を、リリース前に必ず行う。それがインフラを支える人間の流儀だ。派手な仕事は誰でも丁寧にやる。地味な仕事を丁寧にやれるかどうかが、プロとアマチュアの違いだと思っている。「ログインできる」は最低条件であり、「安全にログインできる」「快適にログインできる」「問題が起きたときに追跡できる」まで含めて、初めて「認証が実装できた」と言える。この認証実装は完成ではなく、継続的に改善していく起点だ。半年後、1年後に見直したとき、「あの時の判断は正しかったか」を検証できるように、今回の記事を残しておく。次回予告ここまでの4記事で、OAuth2認可サーバー（Hydra）+ 自前認証プロバイダー（Rust）+ フロントエンド（Next.js）の構成が完成した。E2Eテストも通り、RBACも検証できた。しかし、レビューコメントが届いた。「パスワードリセット機能は？」「MFA対応の予定は？」全部、自分で実装するのか？——次回は、Ory Kratosを導入して認証機能を委譲する方法を解説する。syu-m-5151.hatenablog.com参考資料E2EテストPlaywright MCP - LLMがブラウザを操作するためのMCPサーバーModel Context Protocol (MCP) - LLMと外部ツールを接続するプロトコルOry HydraOry Hydra Documentation - Ory Hydra公式ドキュメントToken Introspection - トークンイントロスペクションAPILogin Flow - ログインフローの概念Consent Flow - 同意フローの概念OAuth2 Token Endpoint - トークンエンドポイントAPIリファレンスOAuth2 Revoke Token - トークン失効APIJWKS Endpoint - 公開鍵配信エンドポイントセキュリティガイドラインOWASP Top 10 2025 - Broken Access Control - アクセス制御の脆弱性OWASP Authorization Cheat Sheet - 認可チートシートOWASP Access Control Cheat Sheet - アクセス制御チートシートOWASP OAuth2 Cheat Sheet - OAuth2セキュリティチートシートAuth0 Token Storage - トークンストレージのベストプラクティスRFC 9700 - OAuth 2.0 Security Best Current Practice - OAuth2セキュリティBCPRBACOso: RBAC Role Based Access ControlLogRocket: Choosing the best access control model for frontendLeapcell: Implementing Robust RBAC Across Backend FrameworksNext.jsNext.js Authentication GuideNext.js MiddlewareCORSMDN: Cross-Origin Resource Sharing (CORS)tower-http CorsLayer","isoDate":"2026-01-10T21:43:11.000Z","dateMiliSeconds":1768081391000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/09/104616","contentSnippet":"はじめに前回の記事では、RustでOry HydraのLogin/Consent Providerを実装した。5つのエンドポイント（GET/POST /login、GET/POST /consent、GET /logout）とHydra Admin APIの連携。Argon2idによるパスワードハッシュ、ユーザー列挙攻撃を防ぐテスト設計の話をした。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory HydraのLogin/Consent Providerの役割を理解している前提で進めます。syu-m-5151.hatenablog.com今回は、そのバックエンドと連携するフロントエンドをNext.js 15で実装する。なぜフロントエンドも自分で書くのか。認証フローを端から端まで把握しておきたいからだ。ちなみにフロントエンドは専門外なのである程度は許してほしいです。NextAuth.jsやAuth0のSDKを使えば楽だが、ブラックボックスのまま本番に出すのは怖い。何かが壊れたとき、「ライブラリの中で何が起きているかわからない」では障害対応で詰むことがある。もちろん、最終的なゴールは「理解した上でライブラリを使う」ことだ。車輪の再発明を推奨しているわけではない。OAuth2/OIDCフローをブラウザ側でどう扱うか。Cookie管理の罠。マルチテナント環境での認証の複雑さ。実際に動かして気づいたことを記録する。OAuth2認可コードフロー：フロントエンドから見た流れまず全体像を把握しておく。┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Browser   │     │   Next.js   │     │ Rust Backend│     │  Ory Hydra  ││  (User)     │     │  Frontend   │     │ (Provider)  │     │  (OAuth2)   │└──────┬──────┘     └──────┬──────┘     └──────┬──────┘     └──────┬──────┘       │                   │                   │                   │       │ 1. Login Click    │                   │                   │       │──────────────────\u003e│                   │                   │       │                   │                   │                   │       │ 2. Redirect to    │                   │                   │       │    /oauth2/auth   │                   │                   │       │\u003c──────────────────│                   │                   │       │                   │                   │                   │       │ 3. GET /oauth2/auth?client_id=...    │                   │       │──────────────────────────────────────────────────────────\u003e│       │                   │                   │                   │       │ 4. Redirect to /login?login_challenge=xxx                 │       │\u003c──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 5. GET /login                         │                   │       │──────────────────────────────────────\u003e│                   │       │                   │                   │                   │       │ 6. Login Form     │                   │                   │       │\u003c──────────────────────────────────────│                   │       │                   │                   │                   │       │ 7. POST /login (credentials)          │                   │       │──────────────────────────────────────\u003e│                   │       │                   │                   │                   │       │                   │                   │ 8. Accept Login   │       │                   │                   │──────────────────\u003e│       │                   │                   │                   │       │ 9. Redirect to /consent               │                   │       │\u003c──────────────────────────────────────│                   │       │                   │                   │                   │       │ ... Consent Flow ...                  │                   │       │                   │                   │                   │       │ 10. Redirect to /callback?code=xxx    │                   │       │\u003c──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 11. GET /callback │                   │                   │       │──────────────────\u003e│                   │                   │       │                   │                   │                   │       │                   │ 12. Exchange code for tokens          │       │                   │──────────────────────────────────────\u003e│       │                   │                   │                   │       │                   │ 13. Tokens (access, id, refresh)      │       │                   │\u003c──────────────────────────────────────│       │                   │                   │                   │       │ 14. Set Cookie \u0026  │                   │                   │       │     Redirect      │                   │                   │       │\u003c──────────────────│                   │                   │このフローで重要なのは、フロントエンドは認証ロジックを持たないということだ。なぜか。フロントエンドのコードはユーザーのブラウザで動く。攻撃者は自由に改変できる。DevToolsを開けばJavaScriptは丸見えだし、リクエストも書き換えられる。認証ロジックをそこに置くということは、攻撃者に「好きに改ざんしていいですよ」と言っているようなものだ。認証情報の検証はすべてRustバックエンド（Login Provider）で行う。フロントエンドの役割は：認可エンドポイントへのリダイレクト開始コールバックで認可コードを受け取る認可コードをトークンに交換トークンをCookieに保存以降のAPI呼び出しでトークンを使用Next.js App Routerでの実装ディレクトリ構成frontend/src/├── app/│   ├── layout.tsx│   ├── page.tsx                    # ランディング│   ├── dashboard/page.tsx          # 認証後のダッシュボード│   ├── callback/page.tsx           # OAuth2コールバック│   └── api/auth/│       ├── login/route.ts          # ログイン開始│       ├── callback/route.ts       # コールバック処理│       └── logout/route.ts         # ログアウト├── components/│   └── shared/│       └── Header.tsx├── lib/│   └── api.ts                      # APIクライアント└── middleware.ts                   # 認証チェックログイン開始：認可エンドポイントへのリダイレクト// app/api/auth/login/route.tsimport { NextResponse } from \"next/server\";import crypto from \"crypto\";export async function GET(request: Request) {  const { searchParams } = new URL(request.url);  const returnTo = searchParams.get(\"returnTo\") || \"/dashboard\";  // CSRF対策用のstate生成  const state = crypto.randomBytes(16).toString(\"hex\");  // stateにリダイレクト先を含める（Base64エンコード）  const stateWithReturn = `${state}:${Buffer.from(returnTo).toString(\"base64\")}`;  // Hydra認可エンドポイントへのURL構築  const params = new URLSearchParams({    client_id: process.env.OAUTH_CLIENT_ID!,    response_type: \"code\",    scope: \"openid profile email\",    redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,    state: stateWithReturn,  });  const authUrl = `${process.env.HYDRA_PUBLIC_URL}/oauth2/auth?${params}`;  return NextResponse.redirect(authUrl);}stateパラメータは2つの役割を持つ：CSRF対策：ランダムな値を含めることで、攻撃者が生成したURLでのコールバックを防ぐリダイレクト先の保持：認証後、元のページへ戻るためにreturnToをエンコードして含めるRFC 9700 (OAuth 2.0 Security Best Current Practice)では、stateパラメータによるCSRF対策が明記されている。認可サーバーがPKCEをサポートしていることを確認できるなら、PKCEでCSRF対策を兼ねることも可能だが、stateを使う方法が最も広くサポートされている。cheatsheetseries.owasp.orgコールバック処理：トークン取得とCookie設定ここが最も複雑な部分だ。// app/api/auth/callback/route.tsimport { NextResponse } from \"next/server\";export async function POST(request: Request) {  const body = await request.json();  const { code, state } = body;  // stateからリダイレクト先を取り出す  const [, returnToBase64] = state.split(\":\");  const returnTo = Buffer.from(returnToBase64, \"base64\").toString();  // 認可コードをトークンに交換  const tokenResponse = await fetch(    `${process.env.HYDRA_PUBLIC_URL}/oauth2/token`,    {      method: \"POST\",      headers: {        \"Content-Type\": \"application/x-www-form-urlencoded\",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString(\"base64\")}`,      },      body: new URLSearchParams({        grant_type: \"authorization_code\",        code,        redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,      }),    }  );  if (!tokenResponse.ok) {    const error = await tokenResponse.text();    console.error(\"Token exchange failed:\", error);    return NextResponse.json(      { error: \"Token exchange failed\" },      { status: 401 }    );  }  const tokens = await tokenResponse.json();  // IDトークンをデコードしてユーザー情報を取得  const idTokenPayload = JSON.parse(    Buffer.from(tokens.id_token.split(\".\")[1], \"base64\").toString()  );  console.log(\"ID token decoded:\", idTokenPayload);  // レスポンスにCookieを設定  const response = NextResponse.json({ success: true, returnTo });  response.cookies.set(\"auth_token\", tokens.access_token, {    httpOnly: false,  // クライアントJSからアクセス可能に    secure: process.env.NODE_ENV === \"production\",    sameSite: \"lax\",    maxAge: tokens.expires_in,    path: \"/\",  });  if (tokens.refresh_token) {    response.cookies.set(\"refresh_token\", tokens.refresh_token, {      httpOnly: true,  // リフレッシュトークンはhttpOnlyで保護      secure: process.env.NODE_ENV === \"production\",      sameSite: \"lax\",      maxAge: 30 * 24 * 60 * 60, // 30日      path: \"/\",    });  }  return response;}Cookie設定で学んだこと最初、httpOnly: trueでアクセストークンを設定していた。OWASPのセッション管理チートシートによれば、これがセキュリティのベストプラクティスだ。しかし、クライアントサイドでAPIを呼び出す必要があった。owasp.org// クライアントコンポーネントでAPIを呼び出すuseEffect(() =\u003e {  const token = document.cookie    .split(\"; \")    .find((row) =\u003e row.startsWith(\"auth_token=\"))    ?.split(\"=\")[1];  if (token) {    api.setToken(token);  }}, []);httpOnly: trueだとdocument.cookieからアクセスできない。選択肢は2つ：アクセストークンをhttpOnly: falseにする - クライアントJSからアクセス可能Server Componentからのみ API を呼ぶ - httpOnlyのまま、サーバーサイドで処理今回は1を選んだ。「httpOnlyをfalseにするなんて、セキュリティの教科書に反している」——そう思う人がいるかもしれない。私もそう思った。OWASPのチートシートにも「httpOnly: trueにしろ」と書いてある。でも、教科書に書いてあることと、目の前のシステムで最善の選択は、必ずしも一致しない。この判断には明確な理由がある。まず、脅威モデルを整理する。httpOnlyの目的は「XSSでトークンを盗まれること」を防ぐことだ。では、XSSが成功した場合に何が起きるか。攻撃者はユーザーのブラウザ上で任意のJavaScriptを実行できる。httpOnlyでトークンを保護しても、攻撃者はfetch('/api/user/delete', {credentials: 'include'})を実行できる。トークンを「盗む」ことはできなくても、「使う」ことはできる。しかし、httpOnly: falseにすることで追加のリスクが生じる。トークンを読み取って攻撃者のサーバーに送信できるため、攻撃者は別のマシンからトークンを使用できる。httpOnly: trueなら被害はそのブラウザセッション内に限定されるが、falseなら攻撃者が任意の場所からAPIを叩ける。つまり、httpOnlyは「トークンの窃取」を防ぐことで、XSS被害の範囲を限定する。しかし、XSS対策の本質は、そもそもXSSを発生させないことだ。CSP（Content Security Policy）、入力のサニタイズ、Reactの自動エスケープ——これらがXSS対策の本丸であり、httpOnlyは最後の砦にすぎない。その上で、今回の判断基準は以下だ。アクセストークンは短命（15分）: 仮に窃取されても、15分で無効化されるリフレッシュトークンはhttpOnly: trueで保護: 長期間有効なトークンは絶対に保護するクライアントサイドでのAPI呼び出しが必須: Server Componentだけでは実現できないリアルタイム機能があるしかし、これはトレードオフだ。Auth0のToken Storageガイドでは、SPAの場合、インメモリストレージが最も安全とされている。将来的にはBFF（Backend for Frontend）パターンに移行し、トークンをサーバーサイドで完全に管理する構成を検討している。Curity社のベストプラクティス記事では、JWTの安全な取り扱いについて詳しく解説されている。owasp.orgID Tokenの署名検証なぜ署名検証が必要か最初の実装では、ID Tokenを単純にBase64デコードしていた：// ❌ 危険：署名検証なしのデコードconst payload = JSON.parse(  Buffer.from(tokens.id_token.split(\".\")[1], \"base64\").toString());これは動く。中身も読める。でも、これでは改ざんを検出できない。「tokenエンドポイントから直接取得しているから、改ざんされることはないのでは？」と思うかもしれない。確かに、バックエンドでtokenエンドポイントを呼び出し、その結果をそのまま使うなら、経路上で改ざんされるリスクは低い。しかし、問題は別のところにある。フロントエンドにトークンを渡す設計だと、ブラウザ側で別のトークンに差し替えられる可能性がある。また、マイクロサービス間でトークンを渡す際、悪意あるサービスが偽トークンを送る可能性もある。署名検証は「このトークンは本当にHydraが発行したものか」を確認する仕組みだ。具体的に何が起きるか。攻撃者は以下のようなトークンを作成できる。// 攻撃者が作成した偽のトークンconst fakePayload = {  sub: \"admin-user-id\",  // 管理者のユーザーID  email: \"admin@example.com\",  role: \"platform_admin\",  // 権限昇格  tenant_id: \"target-tenant\",  // 他テナントへのアクセス  exp: 9999999999  // 無期限};const fakeToken = `eyJhbGciOiJub25lIn0.${btoa(JSON.stringify(fakePayload))}.`;署名検証をしていなければ、このトークンは「有効」として受け入れられる。攻撃者は任意のユーザーになりすまし、任意の権限を持ち、任意のテナントにアクセスできる。認証システムが完全に無意味になる。JWTは3つのパートで構成される：ヘッダー.ペイロード.署名。署名を検証しないということは、攻撃者が作った偽のトークンも受け入れてしまうということだ。これは「鍵のかかっていない金庫」と同じだ。中身は入っているが、誰でも開けられる。OpenID Connect Core 1.0のID Token検証仕様では、以下の検証が必須とされている：署名アルゴリズムの確認（alg）発行者の検証（iss = Hydra URL）対象者の検証（aud = クライアントID）有効期限の確認（exp）署名の検証（公開鍵で）joseライブラリによる実装joseライブラリを使うと、これらの検証を簡潔に実装できる。npm install jose// lib/auth.tsimport * as jose from \"jose\";export interface IdTokenClaims {  sub: string;  aud: string | string[];  iss: string;  exp: number;  iat: number;  email?: string;  role?: string;  tenant_id?: string;}/** * ID Tokenの署名を検証し、クレームを返す * @see https://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation */export async function verifyIdToken(idToken: string): Promise\u003cIdTokenClaims\u003e {  const hydraUrl = process.env.HYDRA_PUBLIC_URL || \"http://localhost:4444\";  const clientId = process.env.NEXT_PUBLIC_CLIENT_ID || \"demo-client\";  // JWKSエンドポイントから公開鍵を取得  // @see https://www.ory.sh/docs/hydra/reference/api#tag/jwk/operation/discoverJsonWebKeys  const JWKS = jose.createRemoteJWKSet(    new URL(`${hydraUrl}/.well-known/jwks.json`)  );  // 署名検証 + issuer/audience検証  const { payload } = await jose.jwtVerify(idToken, JWKS, {    issuer: hydraUrl,    audience: clientId,  });  return payload as IdTokenClaims;}コールバックでの使用// app/api/auth/callback/route.tsimport { verifyIdToken } from \"@/lib/auth\";export async function POST(request: Request) {  const { code } = await request.json();  // トークン交換...  const tokens = await exchangeCodeForTokens(code);  // ✅ 署名検証付きでID Tokenをデコード  try {    const claims = await verifyIdToken(tokens.id_token);    console.log(\"ID token verified:\", {      sub: claims.sub,      email: claims.email,      role: claims.role,      iss: claims.iss,    });    // ユーザー情報をセッションに保存    const user = {      id: claims.sub,      email: claims.email || \"unknown\",      role: claims.role || \"customer\",      tenant_id: claims.tenant_id,    };    // Cookie設定...  } catch (error) {    console.error(\"ID token verification failed:\", error);    return NextResponse.json(      { error: \"Token verification failed\" },      { status: 401 }    );  }}E2Eテストでの確認実際にログインフローを実行して、署名検証が機能していることを確認した。verifyIdToken()の内部ログと、コールバックハンドラーのログが出力される：ID token verified successfully: {  sub: 'c128f3e7-5013-46b8-add2-fbe0e78bfec7',  email: 'demo@example.com',  role: 'platform_admin',  iss: 'http://localhost:4444'}ID token verified and decoded: {  sub: 'c128f3e7-5013-46b8-add2-fbe0e78bfec7',  email: 'demo@example.com',  role: 'platform_admin',  tenant_id: undefined,  iss: 'http://localhost:4444',  aud: [ 'demo-client' ]}POST /api/auth/callback 200 in 609msverified successfullyと出力されれば、以下が確認できている：JWKSエンドポイント（/.well-known/jwks.json）から公開鍵を取得できた署名が正しく検証された（RS256）issがHydra URL（http://localhost:4444）と一致したaudにクライアントID（demo-client）が含まれていたトークンが有効期限内だったtenant_id: undefinedは、Platform Adminユーザーがテナントに所属していないため。通常のテナントユーザーでログインすると、ここにテナントIDが表示される。開発環境でのフォールバック開発環境ではJWKSエンドポイントにアクセスできない場合がある。その時は警告を出しつつ、署名なしデコードにフォールバックする：try {  const claims = await verifyIdToken(tokens.id_token);  // 検証成功} catch (verifyError) {  console.warn(\"ID token verification failed, falling back to unsafe decode\");  console.warn(\"WARNING: Using unverified ID token claims. This is insecure!\");  // 開発環境のみ許容  const unsafeClaims = decodeIdTokenUnsafe(tokens.id_token);  // ...}本番環境では、このフォールバックを無効化すべきだ。github.comマルチテナント認証JWTにテナント情報を含めるOry HydraのConsent画面で、ユーザーのテナント情報をIDトークンに含める。ベストプラクティスとして、Login時にcontextに保存したユーザー情報をConsent時に取得する（DBルックアップを回避）：// Rustバックエンド側（Consent Provider）// Best Practice: contextからユーザー情報を取得（DBルックアップ不要）// Login時にUserContextとして保存した情報をここで復元let user_context: Option\u003cUserContext\u003e = consent_request    .context    .as_ref()    .and_then(|ctx| serde_json::from_value(ctx.clone()).ok());let (user_email, user_role, user_tenant_id) = user_context    .map(|ctx| (ctx.email, ctx.role, ctx.tenant_id))    .unwrap_or_default();// IDトークンにカスタムクレームを追加let session = ConsentSession {    id_token: serde_json::json!({        \"email\": user_email,        \"role\": user_role,        \"tenant_id\": user_tenant_id,  // テナントIDを含める    }),};hydra.accept_consent(\u0026challenge, grant_scope, grant_audience, Some(session)).await?;ここで重要なのは、user_emailやuser_roleをDBから取得するのではなく、Login時にHydraのcontextに保存したUserContextから取得している点だ。これにより：Consent時のDBアクセスが不要になるLogin時点のユーザー状態が保持される（整合性）パフォーマンスが向上するフロントエンドでトークンをデコードすると、テナント情報が取得できる：// IDトークンのペイロード例{  \"aud\": [\"demo-client\"],  \"email\": \"manager@example.com\",  \"role\": \"manager\",  \"tenant_id\": \"aa8d56f1-a083-439b-996a-4a7b73698dfb\",  \"sub\": \"e5555555-5555-5555-5555-555555555555\"}APIリクエストでのテナント分離バックエンドAPIは/api/v1/tenant/というプレフィックスでテナント固有のエンドポイントを提供：/api/v1/tenant/incidents    # テナント内のインシデント/api/v1/tenant/projects     # テナント内のプロジェクト/api/v1/tenant/engineers    # テナント内のエンジニアテナントIDはJWTから取得するため、URLにテナントIDを含める必要はない。これにより：URLの推測による他テナントへのアクセス試行を防ぐテナントIDの改ざんを防ぐ（JWTは署名で保護されている）なぜURLパスにテナントIDを含める方式が危険なのか、具体例で説明する。# URLパス方式（危険）GET /api/v1/tenants/tenant-123/incidentsGET /api/v1/tenants/tenant-456/incidents  ← tenant-123のユーザーがアクセスを試みるこの方式では、バックエンドで「リクエストしたユーザーがtenant-456に所属しているか」を毎回検証する必要がある。検証を忘れると、他テナントのデータが漏洩する。実際、この種のバグは「IDOR（Insecure Direct Object Reference）」として知られ、OWASPのトップ10に常に入る脆弱性だ。# JWTクレーム方式（安全）GET /api/v1/tenant/incidents# JWTの中身: {\"tenant_id\": \"tenant-123\", ...}この方式では、バックエンドはJWTからテナントIDを取得する。JWTは署名で保護されているため、ユーザーが改ざんできない。「どのテナントのデータを返すか」はJWTが決定し、URLは関与しない。URLパラメータとユーザー権限を照合する追加の検証が不要になるため、バグの入り込む余地が減る。このアプローチはMicrosoft Azure Architecture Centerでも推奨されている。ログアウト処理OAuth2のログアウトは複雑だ。以下を考慮する必要がある：フロントエンドのCookie削除HydraのOAuth2セッション無効化バックエンドのセッション無効化（該当する場合）// app/api/auth/logout/route.tsexport async function GET(request: Request) {  const accessToken = request.cookies.get(\"auth_token\")?.value;  if (accessToken) {    // 1. Hydraでトークンを無効化    await fetch(`${process.env.HYDRA_PUBLIC_URL}/oauth2/revoke`, {      method: \"POST\",      headers: {        \"Content-Type\": \"application/x-www-form-urlencoded\",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString(\"base64\")}`,      },      body: new URLSearchParams({        token: accessToken,      }),    });    // 2. Hydraのログインセッションも削除    // （IDトークンからsubjectを取得して削除）  }  // 3. Cookieを削除してリダイレクト  const response = NextResponse.redirect(new URL(\"/\", request.url));  response.cookies.delete(\"auth_token\");  response.cookies.delete(\"refresh_token\");  return response;}RP-Initiated LogoutOpenID ConnectにはRP-Initiated Logout 1.0という仕様がある。この仕様では、Relying Party（クライアントアプリケーション）からOpenID Providerに対してログアウトを要求する方法が定義されている。Hydraはこれをサポートしている。www.ory.sh// Hydraのログアウトエンドポイントを使う方法const logoutUrl = new URL(`${process.env.HYDRA_PUBLIC_URL}/oauth2/sessions/logout`);logoutUrl.searchParams.set(\"id_token_hint\", idToken);logoutUrl.searchParams.set(\"post_logout_redirect_uri\", `${process.env.NEXT_PUBLIC_URL}/`);return NextResponse.redirect(logoutUrl);この方法だと、Hydraがログアウト処理を統括し、Login Providerの/logoutエンドポイントにリダイレクトしてくれる。トラブルシューティング：実際に遭遇した問題問題1：Cookie名の不一致症状：ログイン後、ダッシュボードでAPIデータが取得できない原因：コールバックで設定するCookie名と、各ページで読み取るCookie名が異なっていた// コールバックresponse.cookies.set(\"auth_token\", ...);// ダッシュボード（間違い）.find((row) =\u003e row.startsWith(\"access_token=\"))// 正しくは.find((row) =\u003e row.startsWith(\"auth_token=\"))教訓：Cookie名は定数として一箇所で定義し、全体で共有する。なぜこのミスが起きるのか。認証コードはコールバック処理から書き始め、ダッシュボードは後から書く。時間が空くと、最初に使った名前を忘れる。「書いた順番」と「読まれる順番」が異なるコードでは、定数化を最初に行うべきだ。// lib/constants.tsexport const AUTH_COOKIE_NAME = \"auth_token\";export const REFRESH_COOKIE_NAME = \"refresh_token\";問題2：APIパスの構造症状：APIリクエストが404を返す原因：テナントAPIのパスプレフィックスを間違えていた// 間違いfetch(\"/api/v1/incidents\")  // 404// 正しいfetch(\"/api/v1/tenant/incidents\")  // 200教訓：APIのベースパスはAPIクライアントクラスで管理するclass ApiClient {  private baseUrl = process.env.NEXT_PUBLIC_API_URL;  private tenantPath = \"/api/v1/tenant\";  async getIncidents() {    return this.request(`${this.tenantPath}/incidents`);  }}問題3：トークン期限切れ症状：しばらく操作しないとAPI呼び出しが失敗する原因：アクセストークンの有効期限（15分）が切れていた対策：リフレッシュトークンを使った自動更新async request\u003cT\u003e(path: string, options?: RequestInit): Promise\u003cT\u003e {  const response = await fetch(`${this.baseUrl}${path}`, {    ...options,    headers: {      ...options?.headers,      Authorization: `Bearer ${this.token}`,    },  });  if (response.status === 401) {    // トークンをリフレッシュして再試行    await this.refreshToken();    return this.request(path, options);  }  return response.json();}問題4：HydraのセッションとProviderのセッション症状：ログアウト後、再度ログインしようとすると認証画面をスキップしてしまう原因：Hydraのログインセッションが残っていたOry Hydraのドキュメントによると、HydraはLogin Providerでの認証成功を記憶している。skipフラグが立っている場合、ログイン画面をスキップする。これはSSO（シングルサインオン）の正しい動作だが、完全なログアウトを実装する際には注意が必要だ。// Login Provider側if login_request.skip {    // 既にセッションがあるのでスキップ    // Note: skip時はcontextが既に設定されているためNoneで良い    let completed = hydra.accept_login(\u0026challenge, \u0026login_request.subject, false, None).await?;    return Ok(Redirect::to(\u0026completed.redirect_to));}完全なログアウトには、Hydraのセッションも削除する必要がある：// ログアウト時にHydraのセッションも削除await fetch(  `${process.env.HYDRA_ADMIN_URL}/admin/oauth2/auth/sessions/login?subject=${userId}`,  { method: \"DELETE\" });エラーハンドリングのパターンバックエンドから返されるエラーは統一された形式になっている：{  \"error\": \"invalid_credentials\",  \"error_description\": \"The provided credentials are invalid\",  \"error_code\": \"AUTH_002\"}フロントエンドではこれを適切に処理する：async request\u003cT\u003e(path: string, options?: RequestInit): Promise\u003cT\u003e {  const response = await fetch(`${this.baseUrl}${path}`, options);  if (!response.ok) {    const error = await response.json().catch(() =\u003e ({      error: \"unknown_error\",      error_description: \"An unexpected error occurred\",    }));    throw new ApiError(response.status, error);  }  return response.json();}class ApiError extends Error {  constructor(    public status: number,    public body: { error: string; error_description: string; error_code?: string }  ) {    super(body.error_description);  }}セキュリティチェックリスト実装後に確認すべき項目。これは完璧なリストではない——セキュリティに完璧はない——が、最低限チェックすべきポイントをまとめた。認証に関わるCookieの属性[ ] HttpOnly属性: XSSの緩和策。クライアントJSからアクセス不要なCookieには必ず設定[ ] SameSite属性: LaxもしくはStrictに設定。CSRF対策の基本。Laxの場合、GETリクエストで更新処理を行っていないか確認[ ] Secure属性: HTTPS通信でのみCookieが送られるように。本番環境では必須[ ] Domain属性: サブドメインへのCookie送信範囲を理解しているか。example.comのCookieがjobs.example.comにも送られる設定だと、他サブドメインの脆弱性がリスクになる[ ] Cookie Prefix: Cookie名を__Host-で始めると、Domain属性が空でないCookieの指定を無視してくれる（参考: Cookie Prefixのバイパス）blog.tokumaru.orgレスポンスヘッダ[ ] Strict-Transport-Security（HSTS）: ブラウザにHTTPS接続を強制。max-age=31536000; includeSubDomains; preload[ ] X-Frame-Options: DENYもしくはSAMEORIGINでクリックジャッキング対策。CSPのframe-ancestorsも検討[ ] X-Content-Type-Options: nosniffを指定。MIMEタイプスニッフィング攻撃を防ぐ認証フロー[ ] stateパラメータでCSRF対策している[ ] リフレッシュトークンはhttpOnlyで保護している[ ] アクセストークンの有効期限は短く設定している（15分推奨）[ ] ログアウト時にトークンを無効化している[ ] メールアドレスの列挙ができないこと: ログイン画面やパスワード再設定画面で「このメールアドレスは登録されていません」のようなエラーを出さない[ ] JWTの署名を検証している（バックエンド側）[ ] テナント分離がJWTベースで行われている[ ] 退会/メールアドレス変更などの重要操作で直前のログインを必須にしている: XSSやセッションハイジャック発生時の緩和策その他[ ] サードパーティCookieに依存していないこと（Chrome廃止予定）[ ] iOS SafariのITPによりローカルストレージやJSから保存したCookieは7日で消える可能性がある（未使用時）まとめNext.jsでOry Hydra認証を実装する際の要点：OAuth2フローの理解：認可コードフローの各ステップでフロントエンドが何をすべきか把握するID Token署名検証：JWKSを使って署名を検証し、issuer/audienceを確認するCookie管理：httpOnly, Secure, SameSiteの設定を用途に応じて選択するマルチテナント：JWTにテナント情報を含め、APIはトークンからテナントを識別するエラーハンドリング：OAuth2仕様に沿ったエラー形式を統一的に処理するログアウト：Hydraのセッションとフロントエンドのセッション両方を考慮する認証は「動いた」で終わりではない。Cookie名の不一致のような単純なミスから、セッション管理の複雑さまで、実際に動かして初めて見つかる問題が多い。結局のところ、OAuth2は「誰かが決めた仕様に従う」ゲームだ。RFCを読み、OWASPを読み、Hydraのドキュメントを読む。自分で発明する余地は少ない。でも、それでいい。認証のような重要な仕組みを自己流で作るのは、傲慢だと思う。セキュリティの歴史は「賢い人が作ったものを、もっと賢い攻撃者が破る」の繰り返しだ。OAuth 1.0のセッション固定攻撃、JWTのalg=none脆弱性——仕様を作った人たちでさえ、穴を見落とす。自分がその歴史に新たな失敗を加える必要はない。先人の知恵に乗っかり、その上で自分のシステムに合った判断をする。それが現実的なアプローチだ。前回のバックエンド実装でユーザー列挙攻撃を防ぐテストを書いたように、フロントエンドでも手動でのE2Eテストが重要だ。ログイン→操作→ログアウト→再ログイン。このサイクルを何度も試して、エッジケースを潰していく。次回は、Playwright MCPを使ったE2Eテストの自動化と、テストで発見したバグについて解説する。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。おわりに今日は社内で学生向けワークショップを担当した。終わった後、若い参加者が話しかけてきた。「ブログ読んでます」と言われた。嬉しかった。嬉しかったが、すぐに釘を刺した。「あまり憧れないでくださいね」と。憧れられるのがあまり得意ではない。偶像として崇拝されるのが苦手だし、偶像として振る舞って相手に応えるのも苦手だ。それに、ブログで良いこと言っている人に若いうちから憧れすぎるのは良くない。自分がそうだったのでよく分かる。10代の頃、文章が上手くて考え方が明快な技術ブロガーを見つけて、「この人みたいになりたい」と思った。記事を読み漁った。でも、その人が実際にどんなコードを書いているかは知らなかった。ブログは編集された「ハイライト」にすぎない。裏側の泥臭い試行錯誤、失敗、妥協は見えない。数年後にそれを知ったとき、ちょっとがっかりした。がっかりした自分にもがっかりした。若い技術者なら、現場に居る良い技術者に憧れてほしい。ブログを書く人ではなく。GitHubのコミット履歴を見てほしい。PRのレビューコメントを見てほしい。本番障害のポストモーテムを読んでほしい。そこに本当の技術者がいる。ブログの「正解」ではなく、コードの「試行錯誤」に学んでほしい。正直に言えば、フロントエンドでの認証実装は想像以上に複雑だった。3年前の自分に言いたい。「Next.jsで認証？OAuth2知ってるし、すぐできるでしょ」と思っていた過去の自分に。そうじゃない。Cookieの属性一つでセキュリティモデルが変わる。ID Tokenの署名検証を省略した瞬間、認証システムの意味がなくなる。OAuth2のフローは理解していたつもりだった。RFCも読んだ。でも、実際にNext.jsでCookieを扱い、ID Tokenの署名を検証し、マルチテナントのテナント分離を実装すると、「知っている」と「動かせる」の間には大きな溝があることを思い知らされた。RFCには「stateパラメータでCSRF対策」と書いてある。でも、実際にコードを書くと「stateはどこに保存する？」「検証はいつやる？」「不一致の場合のエラーメッセージは？」という判断が次々と必要になる。仕様書は「何をすべきか」は教えてくれるが、「どう実装すべきか」は教えてくれない。その溝を埋めるのは、結局、自分で書いて動かす経験しかない。特にhttpOnlyの判断には時間を使った。OWASPのベストプラクティスを読み、Auth0のガイドを読み、それでも「これで正しいのか」という不安は消えない。セキュリティに100%の正解はない。トレードオフを理解し、判断し、記録する。それしかできることはない。この記事を書いている人間も、悩みながら書いている。ブログに書かれている「正解」は、試行錯誤の結果を事後的に整理したものにすぎない。過程で何度も間違えている。それを知った上で、参考にしてもらえれば。なんか総じてとても疲れた。でも、まあ、悪くない一日だった。参考資料Ory HydraOry Hydra DocumentationOAuth2 Token EndpointLogin FlowLogout FlowOAuth2/OIDC仕様RFC 6749 - OAuth 2.0RFC 9700 - OAuth 2.0 Security Best Current PracticeOpenID Connect Core 1.0RP-Initiated Logout 1.0セキュリティガイドラインOWASP OAuth2 Cheat SheetOWASP Session Management Cheat SheetAuth0 Token StorageCurity JWT Best PracticesCookie属性CookieのDomain属性は指定しないが一番安全 - 徳丸氏によるCookie Domain属性の解説Cookie Prefixのバイパス - __Host-プレフィックスの重要性MDN: Set-Cookie - Cookie属性の公式リファレンスサードパーティCookieの廃止に向けた準備 - Chrome対応ガイドライブラリjose - JavaScript Object Signing and EncryptionNext.jsNext.js App RouterRoute HandlersMiddleware","isoDate":"2026-01-09T01:46:16.000Z","dateMiliSeconds":1767923176000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fear of the Unknown：Rust/sqlxでNULLを制する6つのパターン","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/08/092409","contentSnippet":"はじめにあるプロジェクトで、電話番号が未登録のユーザーを検索するコードをレビューしていた。WHERE phone = NULL——一見正しく見えるこのクエリは、常に0件を返していた。データは確実に存在する。クエリもシンプル。では何が問題なのか。答えはSQLの3値論理にあった。通常の比較演算はTRUEかFALSEを返すが、SQLにはUNKNOWN（不明）という第3の真偽値がある。NULLは「値が不明」を意味するため、NULL = NULLは「不明 = 不明」となり、結果もUNKNOWNになる。WHERE句はTRUEの行しか返さないから、UNKNOWNは暗黙にFALSE扱いされ、結果は常に0件になる。この問題は『SQLアンチパターン』で「Fear of the Unknown」として解説されている。本記事ではRust + sqlxでの実装パターンに焦点を当てる。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonこういう妄想の仕様と実際の仕様には違いがある。「おい、類推するな」というブログで書いたので時間がある時に読んでほしい。syu-m-5151.hatenablog.comsqlxの型マッピングRustにはOption\u003cT\u003eという型がある。これは「値があるかもしれないし、ないかもしれない」を表現する型だ。Some(値)が「値あり」、Noneが「値なし」を意味する。SQLのNULLに相当するのがこのNoneだ。let phone: Option\u003cString\u003e = Some(\"090-1234-5678\".to_string());  // 値ありlet phone: Option\u003cString\u003e = None;                                // 値なし（NULL相当）sqlxはPostgreSQLのNULLをこのOption\u003cT\u003eに自動マッピングする。 PostgreSQL  Rust (NULLable)  Rust (NOT NULL)  VARCHAR, TEXT  Option\\\u003cString\u003e  String  INTEGER  Option\\\u003ci32\u003e  i32  BIGINT  Option\\\u003ci64\u003e  i64  UUID  Option\\\u003cUuid\u003e  Uuid  DECIMAL  Option\\\u003cDecimal\u003e  Decimal  TIMESTAMPTZ  Option\\\u003cDateTime\\\u003cUtc\u003e\u003e  DateTime\\\u003cUtc\u003e NULLableカラムをOption\u003cT\u003e以外にマッピングすると、NULLが返された時点で実行時エラーになる。私も一度やった。「NULLなんて来ないだろう」と思っていたカラムが、特定の条件でNULLを返し、深夜にSlackが鳴った。#[derive(Debug, sqlx::FromRow)]struct User {    id: Uuid,    email: String,              // NOT NULL → 必ず値がある    name: String,               // NOT NULL → 必ず値がある    phone: Option\u003cString\u003e,      // NULLable → Option型で「値があるかもしれないし、ないかもしれない」を表現    bio: Option\u003cString\u003e,        // NULLable → Noneが「値なし」、Some(\"値\")が「値あり」    created_at: DateTime\u003cUtc\u003e,  // NOT NULL → 必ず値がある}パターン1：検索フィルターでのNULL// NG: NoneがNULLにバインドされ、phone = NULLは常にUNKNOWN// query_as::\u003c_, User\u003eの説明://   ::\u003c_, User\u003e は戻り値の型を指定するRustの記法（turbofish構文）//   _ はデータベースの種類をコンパイラに推論させる部分//   User は「検索結果をUser構造体に変換して」という指定let users = sqlx::query_as::\u003c_, User\u003e(    \"SELECT * FROM users WHERE phone = $1\"  // $1はプレースホルダ（SQLインジェクション対策）).bind(\u0026params.phone)  // bind()で$1に値を埋め込む。NoneはNULLになる.fetch_all(\u0026pool)     // 全件取得.await?;              // 非同期処理の完了を待つ。?はエラー時に早期リターン// OK: 条件分岐でクエリを切り替える// match式: Option型の中身に応じて処理を分岐（switch文のようなもの）let users = match \u0026params.phone {    Some(phone) =\u003e {  // Some(値): 値がある場合        sqlx::query_as::\u003c_, User\u003e(\"SELECT * FROM users WHERE phone = $1\")            .bind(phone)            .fetch_all(\u0026pool)            .await?    }    None =\u003e {  // None: 値がない場合 → IS NULLを使う        sqlx::query_as::\u003c_, User\u003e(\"SELECT * FROM users WHERE phone IS NULL\")            .fetch_all(\u0026pool)            .await?    }};// OK: IS NOT DISTINCT FROMで1クエリにまとめる（PostgreSQL固有）// NULLを普通の値として比較できる（NULL同士も「等しい」と判定）let users = sqlx::query_as::\u003c_, User\u003e(    \"SELECT * FROM users WHERE phone IS NOT DISTINCT FROM $1\").bind(\u0026params.phone).fetch_all(\u0026pool).await?;パターン2：COUNTの挙動// r#\"...\"# は生文字列リテラル（raw string literal）// 複数行のSQLを書きやすく、エスケープも不要な記法sqlx::query_as(    r#\"    SELECT        COUNT(*) as total_users,                           -- 全行数（NULLを含む）        COUNT(coupon_code) as users_with_coupon,           -- NULLでない行数        COUNT(*) - COUNT(coupon_code) as users_without_coupon    FROM users    \"#)空文字列とNULLが混在している場合は注意が必要。// NG: 空文字列のみマッチ、NULLはマッチしない\"SELECT * FROM users WHERE coupon_code = ''\"// OK: 両方を考慮\"SELECT * FROM users WHERE coupon_code IS NULL OR coupon_code = ''\"// OK: NULLIFで正規化\"SELECT * FROM users WHERE NULLIF(coupon_code, '') IS NULL\"パターン3：フォーム送信での空文字列フロントエンドから{ \"phone\": \"\" }が送られると、Option\u003cString\u003eではSome(\"\")になる。データベースには空文字列が保存され、NULLにはならない。// Rustレイヤーで正規化// filter(): 条件を満たさない場合はNoneに変換するメソッド// |s| !s.is_empty() はクロージャ（無名関数）: sが空でなければtruelet phone = req.phone.filter(|s| !s.is_empty());  // Some(\"\") → None, Some(\"090\") → Some(\"090\")let bio = req.bio.filter(|s| !s.is_empty());sqlx::query(\"UPDATE users SET phone = $1, bio = $2 WHERE id = $3\")    .bind(\u0026phone)  // NoneはNULLとしてバインドされる    .bind(\u0026bio)    .bind(user_id)    .execute(\u0026pool)  // execute(): SELECT以外のクエリ実行    .await?;// SQLレイヤーで正規化sqlx::query(    r#\"    UPDATE users    SET phone = NULLIF(TRIM($1), ''),  -- TRIM: 空白除去, NULLIF: ''ならNULLに        bio = NULLIF(TRIM($2), '')    WHERE id = $3    \"#)パターン4：LEFT JOINでのOption必須LEFT JOINは左側のテーブル（例: users）の全行を返す。右側のテーブル（例: orders）に一致する行がない場合、右側のカラムはすべてNULLで埋められる。だから注文がないユーザーの場合、o.created_atはNULLになり、MAX(o.created_at)の結果もNULLになる。// NG: 注文がないユーザーでMAX(o.created_at)がNULLになり、実行時エラーstruct UserWithLastOrder {    last_order_date: DateTime\u003cUtc\u003e,  // NULLを受け付けない型}// OK: Option\u003cT\u003eでNULLを許容するstruct UserWithLastOrder {    last_order_date: Option\u003cDateTime\u003cUtc\u003e\u003e,  // NULLならNone、値があればSome(値)}LEFT JOINや集約関数（MAX, AVG, SUM等）の結果は常にNULLになりうる。迷ったらOption\u003cT\u003eを使う。パターン5：NOT INの罠// NG: category_idがNULLの行は削除されないsqlx::query(    r#\"    DELETE FROM products    WHERE category_id NOT IN (        SELECT id FROM categories WHERE active = true    )    \"#)なぜNULLの行が削除されないのか。NOT INは内部でx \u003c\u003e 1 AND x \u003c\u003e 2 AND ...に展開される。ここでcategory_idがNULLだとどうなるか。NULL \u003c\u003e 1はUNKNOWNを返す。NULL \u003c\u003e 2もUNKNOWN。ANDの3値論理ではTRUE AND UNKNOWN = UNKNOWNだから、条件全体がUNKNOWNになる。WHERE句はTRUEの行しか処理しないため、NULLを含む行は削除対象から外れてしまう。// OK: NOT EXISTSを使う// NULLの行も正しく処理される（サブクエリが0行ならTRUE）sqlx::query(    r#\"    DELETE FROM products p    WHERE NOT EXISTS (        SELECT 1 FROM categories c        WHERE c.id = p.category_id AND c.active = true    )    \"#)パターン6：query_as!マクロこれまでのパターンで使っていたquery_as()は実行時に型チェックを行う。一方query_as!()はマクロで、コンパイル時にデータベースへ接続してスキーマを確認し、型の不整合をビルドエラーとして検出する。NULLになりうるカラムをOption\u003cT\u003e以外でマッピングしようとすると、実行前にエラーを発見できる。// NG: AVG(rating)はNULLを返す可能性があり、コンパイルエラーstruct ProductSummary {    average_rating: f64,  // f64はNULLを受け付けない}sqlx::query_as!(    ProductSummary,    \"SELECT name, AVG(rating) as average_rating FROM products GROUP BY name\")// コンパイルエラー: AVGの結果がNULLになりうるのにOption\u003cf64\u003eではない// OK: Option\u003cT\u003eを使うstruct ProductSummary {    average_rating: Option\u003cf64\u003e,}// OK: COALESCEと\"!\"サフィックスでNOT NULLを保証sqlx::query_as!(    ProductSummary,    r#\"    SELECT name,           COALESCE(AVG(rating), 0)::FLOAT8  -- NULLなら0、FLOAT8にキャスト           as \"average_rating!\"              -- \"!\"でNOT NULLを宣言    FROM products GROUP BY name    \"#) サフィックス  意味  !  NOT NULLを強制（Option\\\u003cT\u003eではなくT）  ?  NULLを許容（TではなくOption\\\u003cT\u003e） まとめ冒頭のWHERE phone = NULLは、WHERE phone IS NULLに書き換えて5分で解決した。3値論理を知っているかどうか——それだけの差だった。NULLの問題はバグではなく、SQLの仕様だ。Rust/sqlxでは以下を守れば大半の問題は防げる。NULLableカラムはOption\u003cT\u003eにマッピング= NULLではなくIS NULLを使うNOT INではなくNOT EXISTSを使う空文字列とNULLを混在させない迷ったらOption\u003cT\u003eを使う。後からOptionを外すのは簡単だが、NULLが返ってきたときのパニックを本番で見るのは心臓に悪い。そもそもNULLableカラムを減らす設計（NOT NULL制約のデフォルト化、別テーブルへの分離）も検討に値する。3値論理の詳細は『SQLアンチパターン』の「Fear of the Unknown」章を参照してほしいです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料SQL Antipatterns - Fear of the UnknownPostgreSQL - Comparison Functionssqlx - Compile-time checked queries","isoDate":"2026-01-08T00:24:09.000Z","dateMiliSeconds":1767831849000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AI時代に今からITエンジニアを目指す若者にオススメする10冊の本  2026年版","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/07/103853","contentSnippet":"はじめにAIは、あなたが聞いたことにしか答えない。聞かなかったことは、永遠に教えてくれない。あなたが何を知らないのか、AIは知らない。2026年だ。AIに聞けば何でも教えてくれる。コードを書いてもらい、設計を相談し、ドキュメントを要約させる。便利だ。では、なぜ本を読むのか。300ページもある本を、最初から最後まで読む必要があるのか。本は違う。本は、聞いていないことを語りかけてくる。知らなかった世界を見せてくる。持っていなかった問いを、手渡してくる。「そんなこと、考えたこともなかった」。そういう瞬間が、本にはある。AIとの対話では、たぶん起きない。AIは効率的だ。知りたいことに、最短距離でたどり着ける。でも、最短距離で歩いていると、道の脇にあるものが見えない。著者が失敗した話、遠回りした話、「今思えば間違いだった」という告白。そういう「寄り道」が、不思議と頭に残る。正解は忘れる。でも、誰かの失敗談は覚えている。たぶん、人間の脳は感情を伴う記憶を優先的に保持するからだ。著者の後悔や苦労を読むとき、読者は追体験している。その感情が、記憶を定着させる。AIに「失敗談を教えて」と聞けば、一般化された失敗談が返ってくる。でも、それは「誰かの」失敗ではない。固有名詞のない失敗談には、感情が宿らない。もう1つ。若者や学生は、そもそも問いを持っていない。何を聞けばいいか分からない。だから、AIに質問もできない。何が分からないのかも分からない。本を読めと言われても、何を読めばいいか分からない。本屋の技術書コーナーに行けば、棚一面に並ぶ背表紙の圧に押しつぶされそうになる。結局、何も買わずに帰る。本は、そういう人に問いをくれる。「あ、これが分からなかったのか」。読み終わって初めて、自分が何を知らなかったのかが分かる。問いを持たない人間に、問いを渡す。それが、本にしかできないことなのだと思う。そういう人のために、10冊を選んだ。「若者にオススメ」と書いておきながら、自分もまだ若い方なのだと思う。少なくとも、将来の自分から見れば若い。ただ、激動の時代だ。技術だけ磨いていればいい時代は、終わりかけているのかもしれない。あるいは、もう終わっているのかもしれない。だから、技術以外の本も混ぜて紹介することにした。先に断っておく。私はバックエンドエンジニアやインフラエンジニアからキャリアをスタートさせた人間だ。だから、フロントエンドやネイティブアプリに関しては、ほぼ紹介しない。偏っている。偏っているが、自分が読んでいない領域の本を勧めることはできない。プログラミング言語個別の書籍も紹介しない。どの言語を学ぶかは人によって違う。だから、言語に依存しない本を中心に選んだ。この10冊が良い10冊かどうかは、分からない。私が良いと思った本が、誰にとっても良いとは限らない。だから、この記事を「正解」として読まなくていい。「こういう本があるんだな」という参考程度に。それでいいのだと思う。それから、もう1つ。本を買うお金がないなら、図書館で借りればいい。技術書は高い。1冊3000円、4000円は当たり前だ。まず読む。金は後でいい。読んで、良かったら、いつか買えばいい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、本題に入る。技術の土台を作るまずは土台だ。プログラミングを始める前に、あるいは始めたばかりの頃に、IT業界で使われる言葉を知っておく必要がある。語彙がなければ、技術書も読めない。先輩の話も分からない。AIに質問もできない。1冊目：情報処理技術者試験の参考書（どれでもいい）1冊目から、いきなり「どれでもいい」と言うのは無責任に聞こえるかもしれない。でも、本当にそうなのだ。ITパスポートでも、基本情報技術者試験でも、応用情報技術者試験でも、高度試験でも。自分のレベルに合ったものを選べ。本屋で立ち読みして、7割くらい分かるやつを買え。分からなすぎると挫折する。簡単すぎると意味がない。誤解しないでほしい。資格を取れと言っているわけではない。「資格なんて意味ない」「資格より実務経験だ」——そういう声があるのは知っている。半分は正しい。資格を持っているだけでは、コードは1行も書けない。試験に受かっても、現場で即戦力にはなれない。それは分かっている。もっと言えば、試験に受からなくてもいい。俺は全然受からないのに優秀なソフトウェアエンジニアを死ぬほど知っている。資格の有無と実力は、必ずしも一致しない。でも、勉強するなら、頭に入った方がいいだろう。頭に入れるなら、試験を受けた方がいい。締め切りがあると、人は勉強する。試験日という締め切りがなければ、参考書は積読になる。金を払って申し込んで、日程を押さえて、会場に行く。その「仕組み」を使え。なぜ資格試験を勧めるのか。語彙が手に入るからだ。現場に出ると、専門用語が飛び交う。「スループットが落ちてる」「レイテンシがネックになってる」「冗長構成にしないと」「SLAどうする？」——こういう会話が、当たり前のように行われる。プログラミングはできるのに、この語彙がなくて会話に入れない。コードは書ける。でも、技術的な議論ができない。語彙がないと、会話にすら入れない。これは、よくある話だ。試験勉強を通じて、開発特有の語彙が頭に入る。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント。知識として知っているだけで、会話の輪に入れる。「あ、それ試験で出たな」という感覚で、先輩の話が理解できる。試験の内容を全部覚えている必要はない。語彙が残ればいい。それだけで、現場での学習速度が全然違う。ここで正直に言う。実務経験の方が大事だというのは、その通りだと思う。本を読むより、コードを書いた方がいい。知識を詰め込むより、実際にシステムを動かした方がいい。2026年の今なら、分からないことはAIに聞けばいい。AIに疑問をぶつければ、理解も早く進む。でも、経験がなければ、疑問も生まれない。これは「経験を積め」という精神論ではない。構造の問題だ。語彙がなければ問いが立たず、問いがなければ経験を言語化できず、言語化できなければ次の学習に繋がらない。この悪循環を断ち切るには、どこかで語彙を入れるしかない。何を聞けばいいか分からなければ、AIも使いこなせない。「スループット」という言葉を知らなければ、「スループットが落ちている原因は何ですか」とは聞けない。「処理が遅い」と「スループットが低い」は、同じ現象を指しているように見えるが、後者の方が解決策にたどり着きやすい。なぜなら、「スループット」という言葉には、それを改善するための知識体系が紐づいているからだ。語彙は、学習の入り口だ。入り口がなければ、どんなに優秀なAIがあっても、中に入れない。IPA（情報処理推進機構）の試験は、日本のIT業界における共通言語を学ぶのに最も効率がいい。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント、システム設計。全部、体系的にまとまっている。しかも、過去問が無料で公開されている。金がないなら、参考書すら買わなくていい。過去問だけで受かる人もいる。2026年度から、応用情報技術者試験や高度試験がCBT（Computer Based Testing）方式に移行する。これまで年2回、決まった日に会場に足を運ばなければならなかったのが、自分の都合に合わせて受験できるようになる。受験のハードルは確実に下がった。どの参考書がいいかは、正直、好みだ。キタミ式が好きな人もいれば、技術評論社の「合格教本」シリーズが好きな人もいる。Amazonのレビューを見て、自分に合いそうなのを選べばいい。図書館にあることも多い。もう1つ言っておく。ITに興味があるけど、プログラミングには興味がない。そういう若者は多いと思う。「エンジニアになりたいけど、コードを書くのはちょっと……」という人。そういう人こそ、まず資格を取れ。プログラミングができなくても、ITの世界で活躍する道はいくらでもある。インフラ、セキュリティ、プロジェクトマネジメント、ITコンサル。そのすべてにおいて、資格で得た知識と語彙は武器になる。繰り返す。資格を取ることが目的ではない。語彙を入れることが目的だ。語彙があれば、AIにも質問できる。語彙があれば、技術書も読める。語彙があれば、先輩の話も分かる。入り口を作れ。話はそれからだ。www.meti.go.jpシステムの基盤を理解するコードを書けるようになっても、それだけではシステムは動かない。サーバー、ネットワーク、データベース、OS。アプリケーションの下にあるレイヤーを理解しなければ、本番環境で動くものは作れない。ここでは、システムを支える基盤技術について学ぶ本を4冊紹介する。2冊目：バックエンドエンジニアのためのインフラ・クラウド大全コードを書けるようになった。アプリケーションが動くようになった。でも、本番環境にデプロイしようとすると、急に分からないことだらけになる。サーバーって何？ネットワークって何？クラウドって何？アプリだけ書けても、本番では動かせない。この本は、そのギャップを埋めてくれる。バックエンドエンジニアに求められるインフラ・クラウド領域の基礎知識が、1冊にまとまっている。情報システムの基礎から、可用性、キャパシティ、パフォーマンス、監視、セキュリティ、DevOps、SRE。現場で必要になる知識が、体系的に整理されている。全23章、544ページ。分厚いが、それだけの価値がある。「基礎知識」と聞くと、簡単そうに思えるかもしれない。でも、違う。基礎とは、簡単という意味ではない。基礎とは、すべての土台になるという意味だ。なぜこの混同が起きるのか。学校教育のせいだろう。教科書は「基礎→応用」の順に並んでいて、基礎は最初に習う、つまり簡単なものだと刷り込まれる。でも、実際には逆だ。基礎は最後に理解できる。応用を経験して初めて、基礎の意味が分かる。この本に書かれていることは、10年後も20年後も変わらない原則ばかりだ。最初は分からなくていい。分からないまま読み進めて、5年後に読み返したとき、「ああ、これはこういう意味だったのか」と分かる。それが基礎だ。構成も良い。分野ごとに解説がまとまっているが、章末で「あわせて読みたい」範囲が紹介されている。1つの章を読み終わると、「次はこっちも読んでみるか」となる。ちょっとだけ調べるつもりが1時間経っている。そういう本だ。クラウドネイティブな環境では、アプリケーションとインフラの境界が曖昧になっている。コンテナ、Kubernetes、オブザーバビリティ。これらを理解せずに、本番環境で動くシステムは作れない。「俺はアプリ側だから」では通用しない時代だ。この本は、その橋渡しをしてくれる。以前、自分が書いたアプリケーションを本番環境にデプロイしたとき、ローカルでは動いていたのに、本番では動かなかった。原因を調べるのに丸1日かかった。ネットワークの設定だった。そのとき、「アプリを書けるだけでは、本番では戦えない」と痛感した。この本があの頃の自分にあったら、もう少し早く原因にたどり着けたかもしれない。バックエンドエンジニアのためのインフラ・クラウド大全【リフロー型】作者:馬場 俊彰,株式会社X-Tech5翔泳社Amazon3冊目：SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策データベースは、難しい。でも、難しいのに、簡単にできてしまう。ORMを使えば、SQLを書かなくてもデータを取得できる。CREATE TABLE文を書けば、テーブルが作れる。動く。動いてしまう。だから、問題に気づくのが遅れる。テーブル設計の失敗は、ソースコードの失敗よりもリファクタリングが難しい。データが入ってしまってからでは、修正のコストが跳ね上がる。だから、最初から正しい設計を知っておく必要がある。この本は、データベースプログラミングで陥りがちな失敗（アンチパターン）を体系的にまとめた本だ。カンマ区切りで値を格納する「ジェイウォーク」。外部キーを張らない「キーレスエントリ」。1つのカラムに複数の意味を持たせる「マルチカラムアトリビュート」。NULLの扱いを間違える「アンビギュアスグループ」。名前を聞いただけで「あ、やったことある」と思う人は多いはずだ。第2版では、新規書き下ろしの章と15のミニ・アンチパターンが加わった。特にミニ・アンチパターンは実務的な内容が多く、「自分もこの問題にハマった」「こうやって解決した」と思える内容が詰まっている。それなりにエンジニアをやっていると、多くのアンチパターンは踏んだことがある。でも、それを他者に体系的に伝えるのは難しい。自分の設計がシステムにどのような影響を与えていくかを経験として学習する機会は、意外と少ない。だからこそ、この本で先人の失敗を学んでおく価値がある。不思議なことがある。ベストプラクティスを調べて実装しても、想定通りにならないことが多い。環境が違う、前提が違う、規模が違う。でも、アンチパターンは違う。アンチパターンを実装すると、想定通りに困る。なぜか。アンチパターンは「制約違反」だからだ。リレーショナルデータベースには設計原則がある。その原則を破れば、必ず不整合やパフォーマンス問題が起きる。ベストプラクティスは「この文脈では有効」という条件付きだが、アンチパターンは「どの文脈でも有害」という普遍性を持つ。だから、何をすべきかより、何をすべきでないかを学ぶ方が、確実に役に立つ。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazon4冊目：モダンオペレーティングシステム 第5版（上・下）データベースの次は、さらに下のレイヤーだ。OSの話をする。OSの中身を知りたければ、この本を読め。プロセスとスレッド、メモリ管理、ファイルシステム、入出力、デッドロック、仮想化とクラウド、マルチプロセッサシステム、セキュリティ。OSを構成する要素が、網羅的に解説されている。上下巻合わせて1000ページ超。分厚いが、それだけの価値がある。コンピュータ・サイエンスの分野で世界的な定番となっている教科書だ。21年ぶりに日本語版が復活した。第5版では、Windows 11やSSDなど、最新のトピックまで詳しく解説されている。セキュリティの章は大部分が書き直された。各章末には585題もの演習問題がある。基礎知識の確認から、プログラミングや計算、さまざまな状況への対応まで。問題に取り組むことで、その章で学んだことの理解が深まる。上下巻で1万円を超える。学生には厳しい価格だ。だから言う。図書館で借りろ。大学の図書館には、たいてい置いてある。この本自体がなくても、類書は置いてある。以前、というかかなり昔にマルチスレッドのバグで丸2日を溶かしたことがある。ログを見ても再現しない。デバッガをつけると動く。原因はスレッド間のレースコンディションだった。そのとき、「なぜプロセスとスレッドが分かれているのか」「なぜロックが必要なのか」を、初めて本当に理解した。この本を先に読んでいたら、もう少し早く気づけたかもしれない。この辺はパタヘネ本など他にも良書があるのでそれらでもよい。モダンオペレーティングシステム 第5版 上作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazonモダンオペレーティングシステム 第5版 下作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazon5冊目：データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理OSの次は、分散システムだ。現代のアプリケーションは、1台のサーバーでは動かない。分散システム設計のあらゆるトピックを660ページに渡って網羅する、百科事典のような書籍。バックエンドエンジニアなら、いつかは読むべき本。データベース、レプリケーション、パーティショニング、トランザクション、分散システムの課題、バッチ処理、ストリーム処理。データを扱うシステムを設計する上で知っておくべき知識が、体系的に整理されている。この本の特徴は、何ができるか（WHAT）だけでなく、なぜそうなっているか（WHY）まで説明されていることだ。「なぜレプリケーションが難しいのか」「なぜ書き込み性能が高いマルチリーダーではなくシングルリーダーが広く使われているのか」。そういった「なぜ」を知ることができる。正直、難しい。分散システムに関わっていないと、なかなかピンとこない部分もある。入門として読む本ではない。でも、大規模でデータ量が多いアプリケーションを設計するときには、必ず役に立つ。2026年2月に原著の第2版が出版される予定だ。翻訳版も出てほしい。というか、出てくれ。頼む。この記事を定期的に更新するつもりなので、第2版が出たら差し替える。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann,斉藤太郎,玉川竜司オライリージャパンAmazonプログラマーとしての姿勢を学ぶここまで、技術の土台とシステムの基盤について紹介してきた。ここからは、少し違う話をする。何を学ぶかではなく、どう向き合うかの話だ。技術は日々変わる。でも、変わらないものもある。良いコードを書くための考え方、問題に向き合う姿勢、キャリアを築くためのマインドセット。ここでは、プログラマーとしての「あり方」を教えてくれる本を紹介する。6冊目：達人プログラマー（第2版）熟達に向けたあなたの旅1999年に出版されて以来、世界中のプログラマーに読まれ続けている名著。2019年に20周年記念版として大幅に改訂され、第2版が出た。原題は「The Pragmatic Programmer」。Pragmaticとは、実用本位、実践的という意味だ。理論だけではなく、現場で使える知恵が詰まっている。この本の特徴は、コーディング技法だけでなく、エンジニアとしてのものの見方を教えてくれることだ。DRY原則、ETC原則（Easier To Change）、凝集度と疎結合。そういった技術的な話もあるが、それだけではない。開発の進め方、コミュニケーションの取り方、キャリアの考え方。プログラマーとして生きていくための姿勢が書かれている。「割れた窓」の話は有名だ。悪い設計、誤った意思決定、質の悪いコード。それを放置すると、ネガティブな考えが伝染する。だから、最初の「割れた窓」を見つけたら、すぐに直せ。自分もつい、割れた窓のようなコードを書いてしまったことがある。その後に若いプログラマに保守を任せたとき、いい書き方になっていなかった。元がよくない書き方だから、指摘するのも躊躇してしまう。「石のスープ」の話も印象的だ。大きな変化を一度に起こそうとすると、周囲は萎縮する。だから、小さく始めて、少しずつ巻き込んでいく。未来を少し垣間見せるだけで、みんな集まってくる。読み直すたびに、新しい発見がある。入門者には手引きとなり、ベテランでも読み返すたびに得るものがある。年に1回は読み返し、達人プログラマーを志していきたい。そういう本だ。20年以上読み継がれてきたからこそ、普遍的な価値がある。古い本だから読まなくていい、ということはない。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon7冊目：プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則KISS、DRY、YAGNI、SOLID。プログラミングの世界には、先人たちが積み上げてきた原理原則がある。でも、それらを体系的に学ぶ機会は意外と少ない。現場で「DRYって何？」と聞かれて、ちゃんと説明できるだろうか。この本は、そういった原理原則を101個集めて、1冊にまとめたものだ。「3年目までに身につけたい」という副題がついているが、3年目以降の人が読んでも学びがある。むしろ、色々な現場を経験した人の方が、それぞれの原理原則の含蓄を感じられる。「あのとき、これを知っていれば……」と思うことが、きっとある。この本の特徴は、各項目に「なぜそれが必要か」が明確に説明されていることだ。Howだけでなく、Whyが書かれている。だから、抽象的な情報でありながら、実際に使える知識になる。「How to本」ならぬ「Why本」だ。もう1つの特徴は、各項目に出典書籍と関連書籍が記載されていることだ。「達人プログラマー」「アジャイルソフトウェア開発の奥義」「プログラマが知るべき97のこと」など、名著への参照がちりばめられている。次に読む本を選ぶときの索引としても使える。具体的なコード例がないことを不満に思う人もいるかもしれない。でも、それは意図的だ。言語に依存しないからこそ、どんな言語でプログラミングしていても適用できる。抽象度が高い分、適用範囲は果てしなく広い。本書で「抽象」を押さえたら、「具象」も押さえたい。コードの書き方を扱った本では、『リーダブルコード』（Dustin Boswell、Trevor Foucher著、2012年）が定番として挙げられることが多い。変数名の付け方、コメントの書き方、制御フローの整理。確かに実践的な内容だ。でも、私のおすすめは『ルールズ・オブ・プログラミング』（Chris Zimmerman著、2023年）の方だ。『ルールズ・オブ・プログラミング』は、『Ghost of Tsushima』を開発したSucker Punch Productionsで実際に使われている21のルールをまとめた本だ。「最適化の前に単純化せよ」「コードを制約で囲め」「プログラマーの時間はCPUの時間より貴重」。ゲーム開発という、パフォーマンスと保守性の両方が求められる過酷な現場で磨かれたルールには、説得力がある。syu-m-5151.hatenablog.comもし「リーダブルコードを読め」と勧めてくる人がいたら、「ルールズ・オブ・プログラミングは読みましたか？」と聞いてみてほしい。読んだ上でリーダブルコードを勧めているなら、それは信頼できる。読んでいないなら、まず読んでもらってから、改めて話を聞けばいい。プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システム新社Amazon技術以外のスキルを身につけるプログラミングができればエンジニアとして成功できる。そう思っていた時期が、私にもあった。でも、現実は違う。あるプロジェクトで、技術的には正しい提案をしたことがある。でも、通らなかった。別のエンジニアの、技術的にはやや劣る提案が採用された。理由は「あいつの方が話しやすい」「あいつの言うことなら安心できる」だった。悔しかった。でも、それが現実だった。技術力だけでは、キャリアは伸びない。なぜか。2つの構造的理由がある。1つは、評価の非対称性だ。あなたの技術力を正しく評価できる人は、組織の中に何人いるか。CTOと数人の先輩エンジニアくらいだろう。でも、あなたのコミュニケーション力は、同僚全員が評価できる。評価が多数決に近い以上、「多くの人に見えるスキル」を持つ人が有利になる。もう1つは、レバレッジの問題だ。自分一人の技術力には限界がある。でも、他者を巻き込む力は、レバレッジが効く。10人を動かせる人は、自分1人で10倍の成果を出す人より、組織では重宝される。これが良いことかどうかは別として、構造としてそうなっている。だから、技術以外のスキルも身につける必要がある。8冊目：SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版技術書ではない。でも、エンジニアにとって必読の1冊だ。この本のサブタイトルは「ソフトウェア開発者の人生マニュアル」。技術習得法やキャリア構築法だけでなく、セルフマーケティング、生産性、資産形成、フィットネス、マインドセット。人生全般をより良く生きる方法が書かれている。「技術者の地位は技術力の高さではなく、他者の評価で決まってしまう」。これは厳しい現実だ。でも、現実を直視した上で、どうすればいいかを教えてくれる。キャリアをビジネスとして捉え、自分自身をマーケティングする。そういう視点を持つことの重要性が説かれている。正直に言うと、後半の資産形成やフィットネスの章は、ソフトウェア開発者に特化した話題ではない。不動産投資や筋トレの話がかなり詳しく書かれていて、「それ、この本でそこまで書く必要がある？」と思う人もいるだろう。私もそう思った。読む人を選ぶ本、という感想もある。でも、前半のキャリア、セルフマーケティング、学習、生産性の章は、間違いなく読む価値がある。技術力だけでは生き残れない時代に、何を身につけるべきか。その指針を与えてくれる。既に読者が若手ソフトウェアエンジニアの場合にはソフトウェアエンジニアガイドブック―世界基準エンジニアの成功戦略ロードマップも合わせておすすめしたい。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon設計とアーキテクチャを深める技術以外のスキルも大事だ。でも、技術を疎かにしていいわけではない。むしろ、技術力があってこそ、それ以外のスキルが活きる。コードが書けるようになったら、次は設計だ。どうやってモジュールを分けるか。どうやってシステム全体を構成するか。設計の良し悪しが、システムの保守性を決める。ここでは、設計とアーキテクチャについて学ぶ本を2冊紹介する。9冊目：アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築「アーキテクトになりたい」「アーキテクトとして成長したい」。そう思ったとき、何から始めればいいのか分からない人は多い。相談できる先輩や上司が身近にいないこともある。この本は、アーキテクティングという世界を探検するにあたっての「地図」となる本だ。アーキテクトの「最初の1冊」として、これ以上のものはない。第2章「ソフトウェア設計」では、V字モデル、4つの抽象（アーキテクチャ設計、モジュール設計、コンポーネント設計、クラス設計）、SOLID原則、設計パターンと、設計を語っていく上での基本概念が密度高く語られる。この章だけでも読んでおけば、設計の話をするときに「何を言っているのか分からない」という状態にはならない。オライリーの『ソフトウェアアーキテクチャの基礎』も良書だが、どこかアカデミックさがあり、ある程度の前提知識が要求される。それに比べて本書は、初学者にも分かりやすく書かれている。ユースケースに沿った解説があるのでおすすめである。第6章「アーキテクトとしての学習と成長」も見逃せない。普段のプロジェクトの中で表立って取り上げられることの少ないテーマだ。「自分がアーキテクトになっていくためにどんな心構えが必要なのか」と悩んでいる人には、とても学びの多い内容になっている。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon10冊目：ソフトウェア設計の結合バランス 持続可能な成長を支えるモジュール化の原則「疎結合にしろ」「密結合は悪だ」。そういうスローガンは、現場でよく聞く。でも、疎結合とは、具体的にどの程度が「疎」なのか。それを説明できる人は、意外と少ない。この本は、「結合」という概念を徹底的に掘り下げた本だ。本書の主張は明快だ。結合をゼロにすることは不可能であり、むしろ適切な結合を選択することが重要。「疎結合至上主義」ではなく、「結合の均衡化（Balancing Coupling）」という視点を提示している。構造化設計におけるモジュール結合、オブジェクト指向におけるコナーセンス。それらを一通り説明した後、独自の「統合強度」モデルが導入される。強度・距離・変動性の関係性を解き明かし、実際の設計においてそれらをどう均衡化するのかが、具体例を用いて示される。印象的だったのは、結合の「距離」という概念だ。同じ強度の結合でも、それが文レベル、メソッドレベル、オブジェクトレベル、サービスレベルのどこに存在するかによって、変更のコストが大きく異なる。マイクロサービスアーキテクチャの設計において、この視点は特に重要だ。この本は手順書でもルールブックでもない。この本に書かれている通りにモジュール設計をすれば自然とバランスの良い設計になる、という話ではない。でも、方針決定やレビュー時に迷ったとき、この本に書かれているような発想をインプットに意思決定すると、判断の精度が上がる。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonおわりに10冊を紹介した。この記事を読んだからといって、明日から何かが変わるわけではない。たぶん来週も、再来週も、同じような日々が続く。10冊すべてを読む必要もない。というか、いきなり10冊読み終わることなんてない。自分も、速読で済ませようとしたことがある。でも、身につかなかった。1冊読んで、合わなければ閉じればいい。それでいい。派手な近道はない。地味な積み重ねだけがある。常に今の自分で戦うしかない。1つだけ、注意しておきたいことがある。誰かを冷笑したり、バカにしたりするのは楽だ。でも、その道に未来はない。他人をバカにしない唯一の方法は、自分が自分の枠の中で精一杯頑張ることだ。精一杯やっている人間は、他人を笑っている暇がない。syu-m-5151.hatenablog.com私も、達人と呼ばれたい者の1人だ。まだ諦めているわけではない。諦めているわけではないが、達人になれるかどうかは分からない。分からないまま、コードを書いている。本を読んでいる。冒頭で、本は問いをくれると書いた。知らなかった世界を見せてくれると書いた。10冊のうち、どれか1冊でも手に取ってもらえたら、と思う。読み終わったとき、新しい問いが生まれているかもしれない。「あ、これが分からなかったのか」。そう思えたら、その本は、あなたにとって正解だったのだと思う。本との出会いは、計画だけでは起きない。本屋に行くと、紹介した本の隣に、もっと自分に合った本が置いてあるかもしれない。図書館で棚を眺めていると、別の本が目に入るかもしれない。そういう出会いは、検索では起きない。AIにも、たぶん見つけられない。だから、本屋に行ってみてもいいかもしれない。図書館に寄ってみてもいいかもしれない。棚の前に立ってみる。それだけでいい。何かが始まるかどうかは、分からない。分からないが、始まるとしたら、たぶんそこからだ。","isoDate":"2026-01-07T01:38:53.000Z","dateMiliSeconds":1767749933000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustでOry Hydra用認証プロバイダーを実装する","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/06/004244","contentSnippet":"はじめに年が明けた。月曜日。エディタを開いている。認証プロバイダーを自分で実装できるか、と聞かれたら、たぶん「できる」と答える。OAuth2のRFCは読んだ。フローも理解している、と思う。ただ、「じゃあ書いて」と言われたとき、キーボードに手を置いたまま止まってしまうことがある。頭では分かっている。手が動かない。10年近くインフラやプラットフォームを触ってきた。認可の仕組みは何度も設計した。Kubernetesの認証、サービスメッシュの認可、アクセストークンの検証。それでも「Login Providerをゼロから書け」と言われると、急に自信がなくなる。分かっているはずなのに、分かっていない気がする。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon知ってるつもり～「問題発見力」を高める「知識システム」の作り方～ (光文社新書)作者:西林 克彦光文社AmazonOry Hydraのドキュメントを開く。Login ProviderとConsent Providerを自分で実装しろ、と書いてある。Node.jsのサンプルがある。Goのサンプルもある。どちらも動く。でも私はRustで書きたかった。年末年始、ぼんやり考えていて気づいたことがある。止まっているのは、技術的に難しいからではない気がする。「何をどの順番で実装すればいいのか」が見えていないのだ。全体像が掴めないまま、最初の一歩が踏み出せずにいる。だからこの記事を書くことにした。過去の自分に向けて。最初の一歩を、順番に。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory Hydraのアーキテクチャ（Login/Consent Providerの役割）を理解している前提で進めます。syu-m-5151.hatenablog.com作るものLogin/Consent Providerとは、Ory Hydraと連携してOAuth2認証フローを処理するWebアプリケーションだ。以下の5つのエンドポイントを実装する。 エンドポイント  役割  GET /login  ログインフォームを表示する  POST /login  認証処理を行い、Hydraに結果を通知する  GET /consent  スコープ承認画面を表示する  POST /consent  承認結果をHydraに通知し、トークン発行へ進む  GET /logout  ログアウト処理を行い、セッションを破棄する 全体の流れOAuth2認可コードフローの中で、Login/Consent Providerがどう動くかを示す。1. ユーザーがクライアントアプリで「ログイン」をクリック2. クライアントがHydraの /oauth2/auth にリダイレクト3. Hydra が Login Provider の GET /login にリダイレクト（login_challenge付き）4. Login Provider がログインフォームを表示5. ユーザーがメール・パスワードを入力して送信6. Login Provider が認証し、Hydra に accept_login を送信7. Hydra が Consent Provider の GET /consent にリダイレクト（consent_challenge付き）8. Consent Provider がスコープ承認画面を表示9. ユーザーが承認10. Consent Provider が Hydra に accept_consent を送信11. Hydra がクライアントにリダイレクト（認可コード付き）12. クライアントが認可コードをトークンに交換Login/Consent Providerが担当するのは3〜10だ。Hydraとの通信には6つのAPIを使う。 API  役割  GET /admin/oauth2/auth/requests/login  login_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/login/accept  認証成功をHydraに通知  GET /admin/oauth2/auth/requests/consent  consent_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/consent/accept  承認結果をHydraに通知  GET /admin/oauth2/auth/requests/logout  logout_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/logout/accept  ログアウトをHydraに通知 www.ory.comLogin HandlerLogin Handlerは2つのエンドポイントで構成される。GET /loginクエリパラメータからlogin_challengeを取得するHydra APIでlogin_challengeを検証し、リクエスト情報を取得するskipフラグが立っていれば（既にセッションがあれば）、フォームを表示せず即座にaccept_loginそうでなければログインフォームを表示するPOST /loginフォームからemail、password、login_challengeを受け取る認証サービスでパスワードを検証する認証成功なら、ユーザー情報をcontextに詰めてaccept_loginを呼ぶHydraが返すリダイレクトURLへ転送するpub async fn login_submit(    State(state): State\u003cAppState\u003e,    Form(form): Form\u003cLoginForm\u003e,) -\u003e Result\u003cRedirect, AppError\u003e {    // 1. 認証処理    let user = state.auth.authenticate(\u0026form.email, \u0026form.password).await?;    // 2. ユーザー情報をcontextに保存（Consent時にDBルックアップ不要）    let user_context = UserContext {        email: user.email.clone(),        role: \"customer\".to_string(),        tenant_id: None,    };    // 3. Hydraに認証成功を通知    let completed = state        .hydra        .accept_login(            \u0026form.login_challenge,            \u0026user.id.to_string(),            false,            Some(serde_json::to_value(\u0026user_context)?),        )        .await?;    // 4. Consent画面へリダイレクト    Ok(Redirect::to(\u0026completed.redirect_to))}ポイントはcontextだ。Login時に認証したユーザー情報（email、role、tenant_id）をJSON形式で保存し、Consent Providerへ受け渡す。これにより、Consent処理でDBルックアップが不要になる。Consent HandlerConsent Handlerも2つのエンドポイントで構成される。GET /consentクエリパラメータからconsent_challengeを取得するHydra APIでリクエスト情報（要求されたスコープ、クライアント情報）を取得するskipフラグが立っていれば（既に承認済みなら）、即座にaccept_consentそうでなければスコープ承認画面を表示するPOST /consentフォームからconsent_challengeと承認するスコープを受け取るLogin時に保存したcontextからユーザー情報を取得するIDトークンにカスタムクレーム（email、role、tenant_id）を追加するaccept_consentを呼び、Hydraが返すリダイレクトURLへ転送するIDトークンにクレームを追加することで、クライアントアプリケーションはトークンをデコードするだけでユーザー情報を取得できる。Logout HandlerLogout Handlerは1つのエンドポイントで構成される。Login/Consentと比べてシンプルだ。GET /logoutクエリパラメータからlogout_challengeを取得するHydra APIでaccept_logoutを呼び出すHydraが返すリダイレクトURLへ転送するpub async fn logout_handler(    State(state): State\u003cAppState\u003e,    Query(query): Query\u003cLogoutQuery\u003e,) -\u003e Result\u003cRedirect, AppError\u003e {    let completed = state.hydra.accept_logout(\u0026query.logout_challenge).await?;    Ok(Redirect::to(\u0026completed.redirect_to))}ログアウトフローはLogin/Consentと異なり、確認画面を表示せずに即座にaccept_logoutを呼んでいる。本番環境では「本当にログアウトしますか？」という確認画面を挟むことを検討してもよい。動作確認docker compose up -d./scripts/e2e-test.shIDトークンにemail、role、subが含まれていれば成功だ。ここまでが「何を作るか」「どう動くか」の説明だ。以降は実装の詳細に入る。認証サービスの実装Login Handlerから呼び出される認証サービスの実装に入る。パスワード認証にはOWASPのガイドラインに従い、Argon2idを採用した。cheatsheetseries.owasp.orgArgon2::default()を使っているが、これは意図的だ。argon2クレートのデフォルト値はOWASP推奨設定に準拠している。「専門家が作ったものを信頼する方が合理的」という前回の記事と同じ論理だ。認証部分で見落としがちなのが次の点だ。pub async fn authenticate(\u0026self, email: \u0026str, password: \u0026str) -\u003e Result\u003cUser, AppError\u003e {    let users = self.users.read().await;    let user = users.get(email).ok_or(AppError::InvalidCredentials)?;    Argon2::default()        .verify_password(password.as_bytes(), \u0026parsed_hash)        .map_err(|_| AppError::InvalidCredentials)?;    Ok(user.clone())}ユーザーが存在しない場合も、パスワードが間違っている場合も、返すエラーは同じInvalidCredentialsだ。「ユーザーが見つかりません」というエラーを返したくなるが、それは攻撃者に情報を与えてしまう。これはユーザー列挙攻撃（User Enumeration Attack）への対策だ。攻撃者はまず有効なメールアドレスを特定しようとする。エラーメッセージが違えば、登録済みかどうかが分かってしまう。なお、完全な対策にはタイミング攻撃への考慮も必要だ。ユーザーが存在しない場合はArgon2の検証が走らないため、レスポンス時間の差で存在を推測される可能性がある。本番環境では、ユーザー不在時もダミーハッシュを検証することを検討してほしい。owasp.orgテスト設計認証システムのバグは「静かに」起きる。だからテストの考え方も変わる。普通の機能開発では「この操作をしたらこうなる」というテストを書く。でも認証システムでは「この操作をしてもこうならない」というテストの方に価値がある。#[tokio::test]async fn test_login_does_not_reveal_user_existence() {    let service = AuthService::new();    service.register(\"exists@example.com\", \"password\").await.unwrap();    let err1 = service.authenticate(\"exists@example.com\", \"wrong\").await.unwrap_err();    let err2 = service.authenticate(\"nobody@example.com\", \"password\").await.unwrap_err();    assert_eq!(err1.to_string(), err2.to_string());}このテストは「エラーメッセージが同じ」という実装の意図を明示化している。将来誰かが「親切なエラーメッセージにしよう」と思って変更しても、このテストが警告を出す。責任分界点全ての攻撃をアプリケーション層で防ぐ必要はない。何を守り、何をインフラに任せるかを明確にする。ブルートフォース対策: Nginxのrate limitで弾くセッション固定化攻撃: フレームワーク（Axum + tower-sessions）に委譲HTTPS強制: インフラ設定の問題プロジェクト構成今回はAxumを使った。github.comsrc/├── main.rs          # サーバーエントリーポイント├── auth.rs          # 認証サービス├── handlers.rs      # Login/Consent/Logoutハンドラー├── hydra.rs         # Hydra Admin APIクライアント├── models.rs        # Hydra API型定義└── error.rs         # エラー型定義ハンドラー層とサービス層を分離している。認証ロジックはauth.rsに置き、ハンドラーはHTTPリクエストの受け取りとレスポンスの返却だけを担う。フルコードはGitHubリポジトリを参照してほしい。github.com実装チェックリスト必須の実装[ ] Hydra APIクライアント - 6つのAPI呼び出し[ ] GET /login - login_challenge検証、skipフラグ確認、フォーム表示[ ] POST /login - 認証、contextにユーザー情報、accept_login[ ] GET /consent - consent_challenge検証、skipフラグ確認、承認画面表示[ ] POST /consent - context取得、IDトークンにクレーム追加、accept_consent[ ] GET /logout - logout_challenge取得、accept_logout[ ] 認証サービス - Argon2id、ユーザー列挙攻撃対策忘れがちなポイントlogin_challengeとconsent_challengeはhiddenフィールドでフォームに埋め込むskipフラグが立っている場合は画面を表示せず即座にacceptするcontextでLogin→Consent間のユーザー情報受け渡しエラーメッセージはユーザーの存在を漏らさないおわりにこの文章を書き終えて、ターミナルに戻った。docker compose up -dを叩く。コンテナが立ち上がる。E2Eテストを走らせる。グリーン。IDトークンにemailとroleが入っている。動いた。正直に言うと、書いている途中で何度か不安になった。これで説明になっているのか。Login HandlerとConsent Handlerの違いが曖昧になっていないか。contextの使い方は2回書き直した。それでも、動いた。冒頭で書いた「キーボードに手を置いたまま止まってしまう」感覚は、たぶん、また来る。次に認証システムを書くときも、OAuth2のフローを思い出すところから始めるだろう。login_challengeって何だっけ、と調べ直すかもしれない。それでいいのだと思う。認証は「一度理解したら終わり」という領域ではない気がする。毎回、RFCを確認しながら、慎重に実装する。ユーザー列挙攻撃のテストを書いたのも、将来の自分が「親切なエラーメッセージ」を入れようとしたときに止めるためだ。年が明けて、また仕事が始まる。本番の認証システムはOry Hydraに任せる。Login Providerは自分で書く。その境界線が、今の私には見えている気がする。","isoDate":"2026-01-05T15:42:44.000Z","dateMiliSeconds":1767627764000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、辞めるな","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020","contentSnippet":"はじめにかつての私は、深夜2時にベッドの中で転職サイトを開いていた。開いて、求人を眺めて、閉じて、また開く。そういうことを繰り返していた。辞めたいのか、と聞かれると困った。会社の限界が見えたのか。自分の天井が見えたのか。それとも、隣の芝生の青さに目が眩んでいただけなのか。たぶん、全部だった。たぶん、どれでもなかった。今は、転職を考えていない。これは「今の会社が最高だから」という話ではない。どんな会社にも良い面と悪い面がある。不満がゼロになることはない。ただ、深夜に転職サイトを開く衝動は、いつの間にか消えた。何が変わったのか。環境が変わったのか、自分が変わったのか。たぶん、両方だ。「エンジニアは転職で年収が上がる」「成長できる環境に身を置け」——そんな言葉がタイムラインに流れてくる。転職エージェントからのスカウトメールは週に何通も届く。カジュアル面談のお誘い。年収アップの可能性。もっと刺激的な環境。全部、本当のことだと思う。全部、嘘だとも思う。若いエンジニアが短期的にモノを考えてしまうのは、仕方がない。私もそうだった。目の前の不満が大きく見える。3年後、5年後のことなんて、想像できない。「今すぐ環境を変えたい」という衝動は、若さゆえの特権でもある。その衝動を否定するつもりはない。ただ、かつての自分に言いたいことがある。「おい、ちょっと待て」と。私自身、何度も転職を考えた。「もう限界だ」「ここにいても意味がない」「他の会社ならもっとできるはずだ」——そう思って、転職サイトを眺めた夜は数えきれない。そして、実際に転職したこともある。転職して正解だったケースもあった。「あのタイミングで辞めなくてよかった」と思うケースもあった。だから、この記事で「辞めるな」と書くのは、上から目線のアドバイスではない。かつての自分への手紙だ。あのとき、もう少し踏みとどまっていたらどうなっていたか。もう少し早く辞めていたらどうなっていたか。そういう問いを、今も抱えている。——もし読んでいて上から目線に感じたなら、それは私の力量不足だ。申し訳ない。ある日、気づいたことがある。深夜に転職サイトを開く自分と、翌朝それを後悔する自分は、同じ人間なのに、まったく違うことを考えている。どちらが本当の自分なのか。たぶん、どちらも本当だ。だから困る。この記事は、深夜の衝動と、翌朝の冷静さの、両方に向けて書いている。この記事が、辞めそうな若手に上司から共有されないことを祈っている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「転職しやすい」という罠ITエンジニアは「転職しやすい職業」だと言われる。確かにそうだ。求人は多い。売り手市場だ。スキルがあれば、転職先を見つけることは比較的容易だろう。だが、「転職しやすい」ことと「キャリアを作れる」ことは、全く別の話だ。私自身、この罠にはまった。転職市場で「引く手あまた」だった時期がある。スカウトメールは毎週届いた。カジュアル面談をすれば、たいてい次のステップに進めた。「自分は市場価値が高い」と思っていた。でも、それは錯覚だった。振り返ると、私は「転職できる」ことと「キャリアを積み上げている」ことを混同していた。転職市場で需要があるのは、単に「エンジニアが足りない」からだ。私個人の価値が高いわけではない。需要と供給のバランスが崩れているだけ。その状況に甘えて、「いつでも転職できる」という安心感に浸っていた。「3年で転職すれば年収が上がる」という話もある。だが、これは単純化しすぎた話だ。実際には、年収が上がる転職もあれば、上がらない転職もある。そして、年収が上がらない転職の方が、実は多い。なぜか。転職には必ずロスが発生するからだ。私が転職したとき、最初の3ヶ月は本当に苦しかった。前職では「あいつに聞けば分かる」と言われていた領域があった。コードベースを熟知していた。誰に何を聞けばいいか知っていた。暗黙のルールも把握していた。転職した瞬間、それが全部ゼロになった。会議で発言しても、「この人、誰？」という空気が流れる。提案しても、文脈を知らないから的外れになる。前職では30分で終わる作業が、3時間かかる。「俺はもっとできるはずなのに」——そう思いながら、毎日を過ごしていた。これが「転職のロス」だ。どんなに経験者であっても、新しい会社のコンテキストをつかむには時間がかかる。前職で積み上げた信頼貯金は、転職した瞬間にリセットされる。私がこの記事で伝えたいのは、現場で働いてきた人間としての実感だ。机上の空論ではなく、実際に転職を経験し、成功も失敗もしてきた中で気づいたことを書く。一見「転職しやすい」ように見えるITエンジニアほど、実は「キャリアを作ること」が難しい——これが私の結論だ。転職のハードルが低いからこそ、安易に転職してしまう。そして、キャリアが積み上がらないまま、年齢だけが積み上がっていく。ただ、ここまで書いてきて、誤解されたくないことがある。「辞めたい」と思うのは、悪いことではない「転職には罠がある」と書いた。でも、それは「辞めたいと思うこと自体が悪い」という意味ではない。ここで1つ、大事なことを言っておきたい。「辞めたい」と思うこと自体は、悪いことではない。むしろ、自然なことだ。どんな会社にも、良い面と悪い面がある。仕事には波がある。うまくいく時期もあれば、何をやってもダメな時期もある。人間関係でストレスを感じることもある。深夜2時に転職サイトを眺める。上司との関係がうまくいかなくて、帰りの電車で「もう嫌だ」と思う。日曜の夜、明日会社に行きたくないと感じる。そういう瞬間は、誰にでもある。私にもあった。今でもある。だから、この記事を読んで「辞めたいと思っている自分はダメだ」とは思わないでほしい。辞めたいと思うことと、実際に辞めることは、別の問題だ。ただ、この分離は言うほど簡単ではない。深夜2時に転職サイトを見ているとき、「これは感情だ、今は判断するな」と冷静に思える人がどれだけいるだろうか。私自身、何度も感情に流されて判断しそうになった。だから、私は自分にルールを課している。1回目で決めるな。深夜のベッドで「辞めたい」と思った。それは1回目だ。まだ決めるな。翌週、上司に理不尽なことを言われて「辞めたい」と思った。まだ決めるな。1ヶ月後、半年後、同じ状況で同じことを思うか。時間をかけて、何度も問い直せ。衝動ではなく、熟慮の末に出した答えなら、それが「辞める」でも「残る」でも、後悔は少ない。要するに、短期ではなく長期で考えろ、ということだ。目の前の感情に振り回されるな。5年後、10年後の自分がどうなっていたいか。そこから逆算して、今の決断を考えろ。正直に言えば、3年程度では何も身についていない。「3年経験があります」と言っても、それは今の環境が整っている状況で、その能力が発揮できる程度だ。上司が調整してくれて、先輩がフォローしてくれて、チームが支えてくれて、ようやく成果が出せている。その支えがなくなった瞬間、同じパフォーマンスが出せるか。出せないなら、それは本当に「能力」と呼べるのか。感情は感情として受け止めていい。ただ、その感情だけで大きな決断をしないでほしい。この記事は、そのための材料を提供したいと思っている。では、冷静に考えるとは、具体的に何を考えればいいのか。次に目指す役割を明確にするまず最初に考えるべきは、「次にどこへ向かいたいのか」だ。エンジニアのキャリアには、いくつかの方向性がある。技術を深める方向——テックリードやスペシャリストだ。特定の領域で「この人に聞けば分かる」と言われる存在になる。アーキテクチャの意思決定を任される。難しい技術的課題を解決する。人を率いる方向——エンジニアリングマネージャー（EM）だ。チームの生産性を最大化する。メンバーの成長を支援する。採用や評価といった組織課題に向き合う。事業に近づく方向——プロダクトマネージャーや、ビジネスサイドとの橋渡し役だ。「何を作るか」を決める側に回る。技術とビジネスの両方を理解し、最適な解を見つける。ここで強調しておきたいのは、IC（Individual Contributor）トラック——部下を持たずに技術で貢献し続けるキャリアパス——という選択肢の存在だ。スタッフエンジニア、プリンシパルエンジニアといった役職は、マネージャーにならずとも、より大きなインパクトを生み出す道だ。マネジメントだけが「上」ではない。シニアの先には4つの方向性がある。テックリード（チームの技術方針を導く）、アーキテクト（システム設計の意思決定を担う）、ソルバー（組織横断の難問を解決する）、ライトハンド（経営層の右腕として動く）。どれを目指すかで、求められるスキルセットも変わる。全部できる必要はない。どれを選ぶかは、あなた次第だ。重要なのは、スタッフエンジニアは「シニアのシニア」ではないということだ。役割そのものが変わる。コードを書く時間は減り、リーダーシップ、ファシリテーション、組織の接着剤としての仕事が増える。「もっとコードを書きたい」という人には向かない道だ。だから、「シニアになったら自動的にスタッフを目指す」という発想は危険だと私は思っている。多くのエンジニアは、最初は「一人前の開発者」からスタートする。そこから、どの方向に進むか。それを決めるのは、あなた自身だ。ここで自分に問いかけてほしい。あなたは次にどの方向に進みたいのか。それが言語化できていないなら、転職を考えるのはまだ早い。なぜなら、方向が定まっていない転職は、ただの「移動」に過ぎないからだ。移動しても、キャリアは積み上がらない。方向性を考えることと同じくらい大事なことがある。「自分は今、どこにいるのか」を知ることだ。自分の能力を棚卸しする目指す方向が見えてきたとしよう。でも、その方向に進むためには、今の自分の立ち位置を正確に把握する必要がある。転職を考えるとき、多くの人は外側に目を向ける。「あの会社は良さそうだ」「この技術を使ってみたい」「あの人みたいになりたい」。でも、本当に大事なのは、自分という器がどうなっているかを知ることだ。どんなに良い環境に移っても、器が変わらなければ、入ってくるものは同じだ。逆に、自分の器をちゃんと理解していれば、今の環境でも次の環境でも、適切な選択ができる。ここで、転職を考える前に確認してほしいことがある。自分の「実力」を正しく評価できているか、ということだ。私は長い間、この評価を間違えていた。ゾーンに入って神がかった速度でコードを書く自分、難解なバグを一瞬で特定する自分——そういう「最高の瞬間」を「自分の実力」だと信じていた。だから、転職先でも同じパフォーマンスが出せると思っていた。逆だった。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」だ。絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎない。転職先で、その「上振れ」を再現できる保証はどこにもない。なぜこれが転職を考えるときに重要なのか。信頼は「下限」に支払われるからだ。新しい職場で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。だから、転職先を選ぶときに問うべきは、「最高の自分が活躍できる場所か」ではない。「最悪の自分でも、最低限のパフォーマンスを出せる場所か」だ。もう1つ、能力について知っておくべきことがある。能力は文脈の中にしかない。今の環境で「できる人」だとしても、それは文脈に依存している。私自身、痛い目を見た。あるプロジェクトで成果を出せたとき、私はそれを自分の実力だと思っていた。でも振り返ると、違った。上司が事前に関係者と調整してくれていた。マネージャーがスコープを適切に切ってくれていた。先輩が技術的な地雷を踏む前に教えてくれていた。私は、応援してくれて、調整してくれていたマネージャーや上司の能力まで、自分の能力だと勘違いしていた。その支えが消えた環境で、同じパフォーマンスを出せるか。出せるわけがない。正しい認識はこうだ。「この文脈において、これまでの経験と周囲のサポートが噛み合って、たまたま価値が出せている」。では、その「器」——能力——は、どう捉えればいいのか。大きく分けて3つの軸がある。技術力——コードを書く力だ。設計力、実装力、レビュー力。特定の領域を深掘りする「スペシャリスト」か、複数の領域をカバーする「ジェネラリスト」か。どちらを目指すにせよ、ここが基盤になる。推進力——プロジェクトを前に進める力だ。タスクを完遂できるか。障害にぶつかっても解決策を見つけられるか。チームのボトルネックを解消できるか。「なぜこの機能が必要か」というビジネス課題を理解し、技術的な意思決定をビジネスインパクトで説明できるか。影響力——自分の外側に価値を生み出す力だ。チームへの影響力は、採用、オンボーディング、ドキュメント整備、勉強会の開催など。社外への影響力は、技術ブログ、カンファレンス登壇、OSS貢献など。どの軸を伸ばすかは、目指す役割によって変わる。テックリードを目指すなら技術力と推進力。EMを目指すなら推進力と影響力。スペシャリストを目指すなら技術力を極める。重要なのは、全部を上げようとしないことだ。自分が目指す役割に必要な能力を見極めて、そこに集中する。ここで、私自身の失敗を話したい。かつての私は「良いコードを書いていれば、いつか評価される」と思っていた。技術力さえあれば、周りが認めてくれる。黙々と良い仕事をしていれば、誰かが見ている。——甘かった。現実はこうだ。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知らない。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われる。「仕事をやり遂げる人」として認められるには、技術的な能力だけでなく「何が重要かを見極める力」と「自分の仕事を周囲に伝える力」が必要だ。この2つを、私は長い間、軽視していた。「アピールするのは恥ずかしい」「実力で示せばいい」——そう思っていた。でも、それは傲慢だった。相手の時間を奪わずに、自分の仕事の価値を簡潔に伝えること。それはコミュニケーションスキルであり、チームで働く上での基本的な作法なのだ。つまり、私は「技術力」に過剰投資し、「推進力」と「影響力」に過少投資していた。多くのエンジニアは、同じ罠にはまる。新しいフレームワークを学ぶ。新しい言語を触る。それは楽しいし、成長した気になる。だが、「推進力」——泥臭い調整や、やり切る力——の不足から目を背けていないか。技術力があっても、プロジェクトを完遂できなければ、市場価値は上がらない。今の会社を辞めようとしているあなた。この3つの軸で自分を評価してみてほしい。次に目指す役割に対して、どの軸が足りていないのか。それが明確になっていないなら、転職しても同じ困難にぶつかる。環境を変えても、足りない能力は足りないままだ。ただ、ここで1つ付け加えたいことがある。能力を棚卸しするとき、多くの人は「足りないもの」ばかりを見る。私もそうだった。「技術力が足りない」「推進力が弱い」「影響力がない」——チェックリストを見て、できないことを数え上げる。そして、転職先を探すときも「ここに行けば○○が身につく」「あの会社なら△△を学べる」と、ないものを補う発想で動いてしまう。ないものを探し続けていたら、悩みは一生消えない。考えてみてほしい。どんな環境に行っても、足りないものは必ずある。新しい技術が次々に出てくる。上には上がいる。「あれもできない、これもできない」と数え上げれば、キリがない。そうやって「ないもの」を埋めようとしている限り、永遠に充足感は得られない。私自身、この罠に長い間はまっていた。「もっとコードが書けるようになりたい」「もっとコミュニケーション力をつけたい」「もっとビジネス視点を持ちたい」——足りないものリストは常に更新され続けた。そして気づいた。そのリストは、一生埋まらない。発想を変えよう。「ないものを探す」のではなく、「あるものを伸ばす」。あなたには、すでに強みがある。周囲より得意なことがある。それが何かを見極めて、そこに集中する。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪い。私の場合、「調べること」「言語化すること」「ソフトウェアを実装すること」が比較的得意だった。コミュニケーション力が高いわけではない。政治的な立ち回りも苦手だ。でも、RFCやドキュメントを読み込んで理解し、それを実際に動くコードに落とし込み、さらに文章としてまとめることなら、周囲より少しだけ速かった。その「少しだけ」を、徹底的に伸ばすことにした。結果として、「あいつに任せれば、調べて、作って、ドキュメントにしてくれる」という評価が生まれた。これは戦略的な選択だ。何をやるかではなく、何をやらないか。弱みを気にして、あれもこれもと手を広げるのではなく、強みに絞って、そこで突き抜ける。だから、能力を棚卸しするとき、「足りないもの」だけでなく「すでにあるもの」にも目を向けてほしい。転職を考えるとき、「ここに行けば足りないものが補える」ではなく、「ここに行けば今の強みがさらに活きる」という視点で選んでほしい。足りないものは、一生足りない。だから、足りないものを数えるのをやめろ。今あるものを、もっと伸ばせ。正直に告白しよう。私には、仕事を選ぶときの悪い癖がある。小さなバグを直す。ドキュメントの誤字を修正する。チェックリストを埋めていく。1日の終わりに「今日も色々やった」と思える。でも、週末に振り返ると、本当にインパクトのある仕事をしたのか、分からなくなる。——これが、私の悪い癖だ。簡単で達成感はあるが、インパクトの低い仕事に逃げてしまう。お菓子をつまむように、小さなタスクをつまんでしまう。これが「スナッキング」だ。チェックリストを埋める快感は、脳にとって報酬だ。でも、その報酬に溺れて、本当に重要な仕事——曖昧で、難しくて、すぐに結果が出ない仕事——から逃げていないか。もう1つ、自分を戒めている罠がある。目立つが価値の低い仕事だ。社内の勉強会を頻繁に開く。Slackで積極的に発言する。目立つ。注目を集める。でも、ビジネスへの貢献は薄い。この罠にはまると、「忙しかった」と「成果を出した」を混同するようになる。振り返ってほしい。直近1ヶ月で、最もインパクトのあった仕事は何だったか。それに費やした時間は、全体の何割だったか。もし1割以下なら、残りの9割は「スナッキング」だった可能性がある。ここまで、「どこを目指すか」と「何を伸ばすか」について話してきた。では、実際に転職するとなったとき、何を失い、何を得るのか。その前に、転職を考えるときの大前提を確認しておきたい。「自分は会社にとって必要な存在だ」と思っているかもしれない。でも、それは本当だろうか。「替えが効く」という前提を認める別に会社なんていつ辞めても良い。文字通りの意味で替えの効かない人間なんて資本主義においては存在しない。これは冷徹な事実だ。どんなに優秀なエンジニアでも、会社は回る。あなたが辞めても、誰かが引き継ぐ。プロジェクトは続く。組織は適応する。「私がいないと回らない」——そう思いたい気持ちは分かる。でも、それは幻想だ。私自身、これを認めるのに時間がかかった。ある会社を辞めるとき、「自分がいなくなったら、あのシステムは誰がメンテするんだろう」と心配していた。3ヶ月後、元同僚に聞いた。「全然大丈夫だよ。○○さんが引き継いで、むしろ前より整理されてる」。——少し寂しかったが、同時にホッとした。そして気づいた。私は「替えが効かない」と思いたかっただけだ。この事実を認めることは、絶望ではない。むしろ、解放だ。「替えが効かない」と思い込んでいると、会社に縛られる。「私がいないと困る」「今辞めたら迷惑をかける」——そういう責任感は美しいが、それが「辞められない」という足枷になることがある。ブラックな環境でも我慢してしまう。メンタルを壊しても「今は辞められない」と言い聞かせる。替えが効くと認めることで、初めて「辞める」という選択肢が本当の意味で手に入る。ただし、ここで短絡的な結論に飛ばないでほしい。「替えが効く」→「だから辞めてもいい」——これは論理の飛躍だ。「替えが効く」から導ける結論は、もう1つある。「だから、どこに行っても価値を出せる能力を磨け」だ。会社にとって、あなたは替えが効く。だが、あなたにとって、積み上げた実績は替えが効かない。ここが重要だ。会社はあなたを手放せる。次の人を雇えばいい。でも、あなたが2年間かけて積み上げた信頼、ドメイン知識、人間関係——これは、転職した瞬間にリセットされる。会社にとっては「替えが効く」リソースでも、あなたにとっては「替えが効かない」資産なのだ。だから、問いはこうなる。「会社にとって替えが効く」という事実を認めた上で、「自分にとって替えが効かない資産」をどれだけ積み上げたか。信頼の複利、実績の蓄積、ドメイン知識——これらは「会社のため」に積み上げるのではない。「自分のため」に積み上げる。たまたま、その資産が今の会社で活きているだけだ。転職すれば、その一部はリセットされる。リセットされてでも得たいものがあるなら、辞めればいい。リセットするには惜しい資産があるなら、もう少し留まって、その資産を使い切ってから辞めればいい。「替えが効く」という事実は、転職を正当化する理由にも、現職に留まる理由にもなる。どちらの結論を導くかは、あなた次第だ。大事なのは、この事実を、感情的な決断の言い訳に使わないことだ。「どうせ替えが効くんだから、辞めてもいいでしょ」——それは、考えることを放棄している。「替えが効くからこそ、自分の資産を最大化する選択をする」——それが、戦略的な判断だ。この前提を踏まえた上で、いよいよ転職のコストについて考えよう。「替えが効く」からこそ、転職は自由にできる。だが、自由にできるからといって、コストがゼロなわけではない。転職は「投資」であり「リセット」である若さという資源は有限だ。私たちはキャリアを積む中で何かを投資し、その結果として何かを得ている。この構造を理解しないまま転職を繰り返すのは危険だ。20代の私は、この構造を理解していなかった。「若いうちは色々経験した方がいい」「転職で視野が広がる」——そういう言葉を真に受けて、2〜3年ごとに環境を変えていた。確かに視野は広がった。でも、振り返ると、広く浅くなっただけだった。新卒で未経験のうちは何もない。あるのはポテンシャルであり、若さであり、可能性だ。その資源を使い、何かしらの資産を得る必要がある。何を得るのか。それはスキルであり、それを活用した先の実績だ。実績は資産だ。そして資産には複利が効く。ある領域で実績を出すと、次はもう少し大きな仕事が回ってくる。それをこなすと、さらに大きな仕事が来る。「あの人はこの領域で結果を出した」という評判が、次の機会を連れてくる。これが複利だ。私が見てきた「キャリアがうまくいっている人」は、例外なくこの複利を回していた。1つの実績が次の実績を呼び、雪だるま式に大きくなっていく。逆に言えば、転職するたびにこの複利がリセットされる。転職するたびに、一定のロスが発生する。ビジネスドメインの理解、社内の人間関係、意思決定のプロセス、暗黙知として共有されている文化。これは、転職した瞬間にリセットされる。信頼貯金も同様だ。前職で積み上げた「あいつなら任せられる」という信頼は、新しい会社では通用しない。ゼロから積み上げ直す必要がある。この「リセットコスト」を、転職を考えるときに計算しているだろうか。私は、転職のリセットコストを「半年〜1年」と見積もっている。新しい環境でコンテキストをつかみ、信頼を積み上げ、本来のパフォーマンスを発揮できるようになるまでの時間だ。転職した直後の、あの居心地の悪さを覚えているだろうか。私が転職して最初の1週間、Slackの雑談チャンネルを眺めていた。前職では、私も会話の輪に入っていた。誰かが投稿すれば、すぐにリアクションをつけた。冗談を言えば、笑ってくれる人がいた。でも新しい会社では、誰も私のことを知らない。雑談チャンネルに何か書こうとして、やめた。「この人、誰？」と思われるのが怖かった。些細なことだ。でも、あの孤独感は今でも覚えている。前職では「あいつに聞けば分かる」と頼られていたのに、新しい会社では誰も自分を知らない。会議で発言しても、反応が薄い。提案しても、「この人は何者だ？」という目で見られる。チャットで質問しても、返事が遅い。——あの感覚は、信頼貯金がゼロになった瞬間だ。これが「信頼の貯金」だ。具体的に言おう。「あの件、○○さんに頼んでおけば大丈夫」——そう思われるまでに、どれだけの時間がかかっただろうか。最初は小さな仕事を任される。それを期限通りに、期待以上の品質で納める。次は少し大きな仕事を任される。また納める。この繰り返しで、「この人なら任せられる」という信頼が積み上がっていく。信頼があると、仕事が回りやすくなる。他のチームに協力を頼むとき、「あの人の頼みなら」と動いてもらえる。提案するとき、「あの人が言うなら、一度聞いてみよう」と耳を傾けてもらえる。逆に信頼がないと、どんなに正しいことを言っても、「あの人、誰？」で終わる。周囲があなたと一緒に働きたいと思う度合いが、あなたの成功を直接左右する。そして、この信頼の貯金は、転職した瞬間にゼロにリセットされる。前職で「あの人は信頼できる」と思われていても、新しい会社では関係ない。ゼロから積み上げ直すしかない。今の会社で、信頼貯金はどれくらい貯まっているか。その信頼貯金を使ってできる挑戦は、まだ残っていないか。せっかく貯めた信頼貯金を、使わずに捨てるのは、もったいなくないか。ここで、信頼貯金のROI（投資対効果）を考えてみてほしい。今の会社で積み上げた信頼があるからこそ挑戦できる「高難易度・高リターン」の仕事はないか。新規プロジェクトの立ち上げ。技術的負債の解消。チームの構造改革。こういう挑戦は、信頼がなければ任されない。信頼があるからこそ、「あいつに任せてみよう」となる。転職先で得られる期待値は、このリセットコストを支払ってでも余りあるほど高いか。その根拠は何か。「なんとなく成長できそう」ではなく、具体的に何を得られるのか。それを言語化できなければ、転職は「期待値の高い投資」ではなく、「よく分からないギャンブル」になる。ここまで、転職のコストについて話してきた。では、そのコストを支払う価値があるかどうかを判断するために、何を見ればいいのか。それは、今の場所で何を積み上げたか、だ。現職で何を成し遂げたか転職を考えるとき、多くの人は「次に何をしたいか」を考える。でも、その前に考えるべきことがある。現職で何を成し遂げたかだ。きつい言い方をする——これは私自身への言葉でもあるのだが——。転職する時に現職で主体的に動いて成し遂げた実績が語れなければ、現職の経験はエンジニアキッザニアに近い。シニアエンジニアやCTOが用意してくれた環境で、お膳立てされた仕事をこなしていただけ。新しいスキルが身についたとする。それは素晴らしい。でも、それだけでは足りない。そのスキルを使って、どのようなビジネス価値を出したのか。その過程でどう主体的に関わったのか。これが語れなければ、あなたは「お客さん」のままだ。もちろん、「キッザニア」も大事だ。お膳立てされた環境で体感したことは血肉になる。でも、それでいいのはある段階までだ。年収700万円、800万円、その先を目指すなら、「遊ばせてもらう側」から「遊び場を作る側」に回る必要がある。技術力だけでは昇進できない——これは誰でも言える。問題は、なぜ、分かっていても実践できないのかだ。「コードで問題を解決する」。それが私たちのアイデンティティだ。だから、可視化やスポンサー獲得を「政治的で汚い」と感じてしまう。「実力で認められたい」。その気持ちは痛いほど分かる。私もそうだった。でも現実は違う。技術的に正しい提案をしても、周囲を巻き込めなければ、提案は提案のまま終わる。「技術で解決できる」ことと「解決を任される」ことは、別の能力だ。私自身、昇進を見送られた経験がある。なぜ評価されないのか分からなかった。振り返って気づいた。上司が私のキャリア目標を察してくれることを、勝手に期待していた。「昇進したいです」と言ったことがあっただろうか。なかった。上司はエスパーではない。言わなければ、伝わらない。そしてもう1つ。技術的な正しさを組織に浸透させるのも、「技術」だ。相手の立場を理解し、伝わる言葉で説明し、合意を形成する。これを「政治」と呼ぶなら、政治もまた技術なのだ。そして、成果を出すだけで終わりではない。私は日報をつける習慣を大事にしている。Claude Codeを使って、日々の作業を記録している。何をやったか、何を学んだか、何に詰まったか。こうして記録しておけば、パフォーマンスレビューの自己評価で圧倒的に有利になる。半年前、1年前に何を達成したか、正確に思い出せるだろうか。記録がなければ、自分の成果を過小評価してしまう。成果を出すことと、成果を可視化することは、別のスキルだ。昇進には「スポンサー」と「可視化」が必要だ。スポンサーとは何か。あなたの成果を経営層に伝えてくれる人だ。上司や先輩の中に、「あいつは良い仕事をしている」と会議で言ってくれる人はいるか。人事評価の場で、あなたの名前を出してくれる人はいるか。いくら良い仕事をしても、上層部に伝わらなければ、昇進の話にはならない。スポンサーは単なる応援者ではなく、あなたのキャリアに実際に投資してくれる存在だ。可視化とは何か。自分の仕事の価値を、他人が理解できる形で残すことだ。「何を達成したか」「なぜそれが重要だったか」「組織にどう貢献したか」——これをドキュメントやSlackで発信しているか。戦略的に重要なプロジェクトに参加して、名前を売っているか。これが揃って初めて、「この人を昇進させよう」という話になる。ネットワークも重要だ。社内の同僚、社外のプロフェッショナル、経営層——この3方向の人脈を意識的に育てることで、キャリアの選択肢が広がる。転職を考えるなら、この3つのネットワークがどれだけ育っているか、自問してみてほしい。今、辞めようとしているあなたに問いたい。現職で、あなたは何を成し遂げたか。主体的に動いた結果として、何が変わったか。もし自分がその場にいなかったとしたら、結果はどう変わっていたか。「自分がいたからこそ生まれた差分」を言語化できるか。それが語れないなら、まだ辞めるタイミングではないかもしれない。少なくとも、もう一度自分に問いかける価値はある。ここで、よく聞く反論がある。「現職で成し遂げたいけど、もう成長の機会がないんです」——本当だろうか。この「成長できない」という感覚を、もう少し掘り下げてみたい。「成長できない」は本当か「もうこの場所では成長できない」これは、転職理由としてよく聞く言葉だ。刺激がなくなった。慣れてしまった。自分よりできる人がいない。だから、成長するために環境を変えたい。でも、本当にそうだろうか。それは本当に環境のせいなのか。厳しいことを言う。「成長できない環境」なんて、ほとんど存在しない。あるのは、今の自分の能力では打破できない環境だ。それは環境の問題ではなく、能力の問題だ。能力があれば、たいていの環境は打破できる。「この環境では無理だ」と言っているのは、「今の自分には無理だ」と言っているのと同じだ。だからこそ、転職には意味がある。——逆説的に聞こえるかもしれないが、聞いてほしい。能力を上げてから転職すれば、次の環境も打破できる。能力を上げずに転職しても、また同じ壁にぶつかる。「この環境では成長できない」と言って転職した人が、次の会社でも同じことを言っているのを、何度も見てきた。環境を変えても、能力が変わらなければ、結果は同じだ。逆に、今の環境で壁を打破する力をつけた人は、どこに行っても通用する。転職は「逃げ場」ではなく「能力を活かす場」として選ぶべきだ。今の環境で能力を証明してから、その能力をより活かせる場所に移る。それが、転職を「飛躍」にする唯一の方法だ。では、ここで言う「能力を上げる」とは、具体的に何を指すのか。そもそも「成長」とは何なのか。成長とは何か。新しい技術を触ることか。新しいフレームワークを学ぶことか。それらは成長の一部ではあるが、本質ではない。成長とは、「解ける問題の範囲が広がること」であり、「より大きな責任を担えるようになること」だ。シニアエンジニアへの成長で最も重要なのは、「どの問題を解くべきかを見極める力」だ。コードで問題を解くことと、そもそも「どの問題を解くべきか」を判断することは、まったく別のスキルだ。私自身、この違いを理解するのに時間がかかった。ある時期、私は「新しい技術を触れていないと成長が止まる」と焦っていた。業務ではレガシーなコードをメンテしている。新しいことを学べていない。だから成長していない。そう思い込んでいた。でも振り返ると、あのレガシーコードのメンテナンス期間こそ、私が最も成長した時期だった。複雑に絡み合った依存関係を解きほぐす力。ドキュメントがない状況で調査する力。リスクを見積もって段階的にリファクタリングする判断力。これらは、最新技術を追いかけていたら身につかなかった。その定義で考えたとき、今の環境で成長の余地は本当にないのか。もしかしたら、自分が「成長」と呼んでいるものが、単なる「刺激」ではないだろうか。新しい技術を触る刺激。新しいチームに入る刺激。新しいプロダクトに関わる刺激。刺激と成長は違う。刺激は消費されるが、成長は蓄積される。私が「成長できない」と感じていたとき、本当は「刺激がない」だけだった。成長の機会は目の前にあった。ただ、それが「地味でつまらない仕事」に見えていたから、気づかなかった。ここで、よく言われる教えについて考えてみたい。「一番の下手くそでいよう（Be the Worst）」——プログラマーの世界でよく引用される教えだ。自分より優れた人たちの中に身を置くことで、自分も成長できる。だから、自分が一番下手くそになれる環境を探せ、と。この教えは正しい。でも、これを全員が実践したら、組織は成り立たない。全員が「学ぶ側」を求めて、誰も「教える側」に回らなかったら、どうなるか。優秀な人が集まる環境は、誰かが「教える側」を引き受けてくれているから成立している。「一番の下手くそでいよう」という教えは、その前提を無視している。——というのは、批判としては正しい。ただ、この教えの本質は、「常に学び続けろ」ということだ。「教える側」に回っても、学びは止まらない。むしろ、教えることで自分の理解の穴が見つかる。成長の形が変わるだけで、成長自体は続く。「もうこの場所では成長できない」と感じたとき、立ち止まって考えてほしい。自分は「学ぶ側」でいることしか考えていないのではないか。新しい技術を教わりたい。優秀な先輩からコードレビューを受けたい。それは大事だ。だが、いつまでも「教わる側」にいるわけにはいかない。「教える側」に回ったとき、別の成長が始まる。後輩のコードをレビューすることで、自分の理解の穴が見つかる。ドキュメントを整備することで、暗黙知が言語化される。勉強会を開くことで、チーム全体の底上げができる。そして何より、「自分がいないと回らない」から「自分がいなくても回る」状態を作ることが、次のステージへの準備になる。「接着剤の仕事」というものがある。チーム間の調整、ドキュメント整備、後輩の面倒を見る——コードを書かないが、チームを機能させるために不可欠な仕事だ。日本企業では、この仕事は評価されにくい。「○○さんはコード書いてないよね」と言われがちだ。でも、シニアレベルでこれをやると「リーダーシップを発揮している」と見なされることもある。上司とすり合わせて、この仕事がキャリアにどう評価されるか確認しておいた方がいい。評価されないなら、やりすぎは損だ。効果的なメンタリングとは何か。良いメンターはすぐに答えを与えない。複数の選択肢を提示し、メンティー自身に考えさせる。そして、自立を促す。メンタリングを受ける側も、答えを教えてもらうことを期待するのではなく、自分で考える姿勢が求められる。もし今の環境で良いメンターがいるなら、それは転職で失う大きな資産の1つだ。今の環境で、より大きな責任を担う機会はないか。より難しい問題に挑戦する機会はないか。それを探さずに「成長できない」と言っているなら、次の環境でも同じことが起きるだろう。ここまで、「成長できない」という感覚について掘り下げてきた。成長の機会は、案外、目の前にあるかもしれない。ただ、それでも「辞めたい」という気持ちが消えない人もいるだろう。次の問いは、より厳しいものになる。転職は「逃げ」になっていないか転職を繰り返す人の中に、あるパターンがある。新しい会社に入る。最初の半年は必死でキャッチアップする。コードベースを読み、ドメイン知識を吸収し、チームの信頼を獲得する。1年が経つ頃には「だいたい分かった」という感覚が出てくる。そして、ふと気づく。「あれ、最近あまり成長していない気がする」。ここで選択肢が2つある。今の環境で次のステージに挑戦するか、また新しい環境に移るか。後者を選び続けると、こうなる。キャッチアップが終わるたびに「成長が止まった」と感じ、また次の会社に行く。新しい環境でのキャッチアップを「成長」だと錯覚する。でも、それは成長ではない。ただの適応だ。本当の成長は、適応が終わった後にある。その環境で自分なりの仮説を持ち、試行錯誤し、失敗し、そこから学ぶ。大きなプロジェクトをやり遂げる。チームを任される。技術的な意思決定を下す。そういう経験を積んで初めて、次のステージに進める。転職を繰り返すたび、この「本当の成長」への到達前にリセットがかかる。結果、いつまでも「一人前の開発者」のまま、年齢だけが進んでいく。私自身、このリセットの苦しさを身をもって経験した。自社開発からSRE支援の会社に転職したとき、リセットが1回では済まないことを思い知った。支援先が変わるたびに、文脈がリセットされる。コードベース、チームメンバー、組織文化——全部ゼロから。しかも「支援」として来ている以上、キャッチアップ期間なんてない。初日から「で、何ができますか？」と問われる。最初は本当に苦しんだ。広い視野は得られたが、深さが積み上がらない。ある現場で得た知見を次の現場で活かそうとしても、文脈が違いすぎて通用しない。そして何より、信頼の蓄積がリセットされ続ける。ある支援先で信頼を獲得しても、次の案件ではまたゼロからだ。この経験から学んだことがある。転職のリセットコストは、転職先の業態によって大きく変わる。自社開発から自社開発への転職なら、リセットは1回で済む。でも、支援会社やコンサル、技術顧問に転職すると、リセットが繰り返し発生する。その覚悟があるかどうか、転職前に考えておくべきだ。この経験を通じて、私が学んだ原則がある。「自分の決定の結果を見届けられるだけの期間、同じ場所に留まれ」。成長のフィードバックループを回すためだ。設計した仕組みが半年後にどう使われているか。提案した施策が1年後にどんな結果を生んだか。それを見届けずに次の環境に移ったら、学びは半分で終わる。もう1つ、「許可を求めるな、宣言しろ」という原則がある。「○○してもいいですか？」ではなく、「○○します。問題があれば教えてください」と発信する。異論があれば誰かが止めてくれる。このスタイルで動けるようになると、権限がなくても物事を前に進められる。日本企業では「根回し」が重要だと言われる。それは間違いではない。でも、根回しにも2種類ある。「許可を得るための根回し」と「宣言を通すための根回し」だ。後者の方が、物事が前に進む。逆に、常に許可を求めないと動けない状態なら、まだその環境で信頼貯金が足りていない。その信頼を積み上げる前に辞めるのは、もったいない。ここで、このセクションの問いに戻ろう。「転職は『逃げ』になっていないか」。「今の環境では成長できない」と感じたとき、一度立ち止まって考えてほしい。それは本当に環境の限界なのか。それとも、環境には問題がないのに、難しいことから逃げているだけではないか。——私自身も、この問いに何度も向き合ってきた。そして正直に言えば、「逃げ」だったこともある。「退屈だが重要な課題」を解決することから目を背けて、「新しくて刺激的な環境」に逃げたくなる気持ちは、痛いほど分かる。ここまで、「今の環境で成長できるか」について話してきた。では、環境を変えるにせよ、留まるにせよ、これからのエンジニアは何を磨くべきなのか。AIと共存する時代に何を磨くかこの問いを考えるとき、避けて通れないのがAIの存在だ。AIは、定型的な作業を得意とする。コードの自動生成、バグの検出、ドキュメントの作成。これらの領域では、すでにAIが人間を補助し、場合によっては代替し始めている。つまり、「言われたことをそのまま実装する」だけのエンジニアは、価値が下がっていく。一方で、AIに代替されにくい領域もある。技術的な意思決定を下すこと。チームを率いること。ビジネス課題を理解し、技術で解決策を提案すること。曖昧な要件を整理し、実装可能な形に落とし込むこと。これは、当面の間、人間の仕事だ。私が優れた組織で見てきた共通点がある。エンジニアがビジネスに直接触れていることだ。「ITとビジネスの橋渡し役」を介さず、エンジニア自身がビジネス指標を理解し、顧客と対話する。その直接的な接点が、AIには代替できない価値を生む。逆に言えば、「要件を受け取って実装するだけ」のエンジニアは、AIに代替されやすい。これは他人事ではなく、私自身も常に意識していることだ。だが、ここで短絡的な結論に飛ばないでほしい。「じゃあ、転職してシニアなポジションを取りに行こう」というのは間違いだ。なぜなら、シニアになるためには、ジュニアとしての経験が必要だからだ。問題は、「ジュニアのまま留まり続けること」だ。今の環境で、次のステージに進むための挑戦ができるなら、そうすべきだ。転職は、その挑戦ができない場合の、最後の手段であるべきだ。ここで自分に問いかけてほしい。直近1ヶ月で、「人間が介入しなければ解決しなかった意思決定」を何回行ったか。AIがコードを書ける今、「実装する」だけでは価値が出にくい。曖昧な要件を整理する。ステークホルダー間の調整をする。技術的な選択肢の中から、ビジネスインパクトを考慮して決断する。そういう「人間にしかできない仕事」をどれだけやっているか。それがシニアへの階段を登る経験だ。ここまで、「どの方向に進むか」「何を磨くか」「今の環境で成長できるか」について話してきた。キャリアを考えるとき、避けて通れない話がもう1つある。転職を考える動機として、最も頻繁に挙がるテーマだ。「年収を上げたい」は目的ではなく結果である転職理由として「年収を上げたい」はよく聞く。分かる。私だって年収は高い方がいい。だが、年収は目的ではなく、結果だ。「年収は結果」と言うのは簡単だ。でも、転職サイトを開くと、年収で検索してしまう。なぜか。年収は分かりやすい指標だからだ。「能力が上がった」は測りにくい。「年収が上がった」は明確だ。この分かりやすさの罠が、私たちを「能力より年収」に引き寄せる。対策は1つ。年収以外の「分かりやすい指標」を自分で設定することだ。「○○の技術を導入した」「△△人のチームをリードした」「□□の問題を解決した」——そういう指標を先に決めておけば、年収の誘惑に負けにくい。転職サイトを開く前に、「この転職で得たいもの」を3つ書き出してみてほしい。そのうち「年収」が1番目に来るなら、一度立ち止まる必要がある。年収は、あなたが提供できる価値の対価だ。技術力が高ければ、難しい問題を解ける。推進力があれば、プロジェクトを成功に導ける。影響力があれば、チームや組織を良い方向に動かせる。これらの価値を提供できるから、高い年収が払われる。年収600万円から800万円、800万円から1000万円。それぞれのステージを超えるには、提供できる価値のレベルを上げる必要がある。「一人で開発できる」から「チームをリードできる」へ。「技術的な問題を解ける」から「ビジネス課題を技術で解決できる」へ。企業によって「シニアエンジニア」の意味は違う。大手IT企業とスタートアップでは、同じ肩書きでも求められる水準が全く異なる。1000人規模の会社のシニアと、10人のスタートアップのシニアでは、経験してきた課題の複雑さも、責任の範囲も違う。同じ「シニア」でも、会社によって期待値が違う。ここで正直に振り返りたい。キャリアの進め方について、私は無自覚だった。一生懸命働けば、報酬は自然についてくるものだと思っていた。「会社が見ていてくれる」「評価されるべき人は評価される」——そう信じていた。でも、それは間違いだった。努力だけでは、次のレベルに到達できない。技術を磨くことと、キャリアを戦略的に構築することは、別のスキルなのだ。日本企業では「出る杭は打たれる」と言われるが、「出なさすぎる杭」は存在すら認識されない。逆に言えば、能力を上げずに年収だけ上げようとしても、無理がある。高年収の会社に転職できたとしても、その期待値に応えられなければ、いずれ居場所を失う。私自身、この罠に片足を突っ込んだことがある。ある時期、市場が過熱していた。エンジニアの採用難で、年収相場が跳ね上がっていた。転職サイトを見ると、今の年収より明らかに高いオファーがゴロゴロしている。「自分の市場価値はこんなに高いのか」と浮かれていた。でも、冷静に考えれば分かる話だった。それは「私の価値」ではなく、「市場のバブル」だった。実際に転職した人の話を聞くと、入社後に苦しんでいるケースが少なくなかった。「この年収なら、これくらいできるだろう」という期待に応えられない。前職では周囲のサポートがあったから成果が出せていたのに、新しい環境では1人で同じ成果を求められる。結果、評価が下がり、居心地が悪くなる。中には、年収ダウンで再び転職した人もいた。年収アップの転職で失敗する人には、共通点があった。「年収が上がる＝自分の価値が認められた」と解釈していたことだ。でも、採用側の論理は違う。「この年収を払えば、このくらいの成果が出るはずだ」という投資判断をしている。年収は「認定」ではなく「期待値」なのだ。その期待値に応えられなければ、厳しい現実が待っている。ここで、提示された年収アップのオファーについて冷静に考えてほしい。その年収は、あなたの「現在の実力」に対する評価なのか。それとも、市場のバブルや採用の緊急度による「プレミアム（下駄）」なのか。下駄を履いた状態で入社すると、期待値の調整で苦しむ。「このくらいできるだろう」という期待に応えられず、評価が下がり、居心地が悪くなる。そのリスクをどう管理するか。年収だけを見て決めると、この罠にはまりやすい。だから、「年収を上げるために転職する」のではなく、「能力を上げた結果として年収が上がる」という順序を間違えてはいけない。そして、能力を上げるためには、今の環境で何ができるかをまず考えるべきだ。ここで、転職を考えるときに気をつけてほしいことがある。「年収アップ」という言葉に惹かれて、転職エージェントの話を聞き始める人は多い。だが、エージェントの言葉を聞く前に、知っておくべきことがある。転職エージェントのビジネスモデルを理解する転職エージェントは、あなたの味方ではない。これは悪口ではなく、ビジネスモデルの話だ。転職エージェントにお金を払っているのは、あなたではない。採用企業だ。エージェントは、あなたを企業に紹介し、採用が決まったときに、企業から報酬を受け取る。その報酬は、あなたの年収の一定割合だ。つまり、エージェントにとって、あなたが「転職すること」が利益になる。あなたが「現職に残ること」は、彼らには何のメリットもない。むしろ、売上ゼロだ。だから、エージェントは転職を勧める。「今の会社に残った方がいい」とは、なかなか言ってくれない。彼らの言葉をそのまま鵜呑みにするのは危険だ。エージェントを使うなとは言わない。彼らは市場の情報を持っているし、面接対策のアドバイスもくれる。ただ、彼らのインセンティブ構造を理解した上で、話を聞くべきだ。本当に転職すべきかどうかは、エージェントではなく、あなた自身が決めることだ。できれば、利害関係のない第三者——信頼できる先輩、友人、メンター——に相談してほしい。ここで厳しいことを言う。自分のキャリアの最終責任者になれ。日本企業では、「会社がキャリアパスを用意してくれる」という期待がある。年功序列で昇進できる。上司が適切なアサインメントを考えてくれる。人事部がキャリア相談に乗ってくれる。——しかし、それは幻想だ。あなたのキャリアの最終責任者は、上司やエージェントや人事部ではなく、あなた自身だ。誰かが導いてくれるのを待つのではなく、自分で方向を決めて、自分で動く。その覚悟があるかどうかが、キャリアを作れるかどうかの分かれ目になる。自分でキャリアを管理するために、私が大事にしている習慣が2つある。1つは、時間管理より体力管理だ。同じ1時間でも、元気なときと疲れているときでは、アウトプットが全く違う。燃え尽きそうな状態で長時間働いても、成果は出ない。自分の体力がどこで回復し、どこで消耗するかを把握することが、長く働き続けるための鍵だ。もう1つは、フィードバックを受け入れる力だ。「それは違うと思います」と言われたとき、どう反応するか。防御的にならず、「なるほど、そういう見方もあるのか」と学びに変えられる人が、成長し続けられる。「自分は正しい」と固まった人は、どんなに優秀でも、そこで成長が止まる。ここまで、「辞めるな」「考えろ」と書き続けてきた。読んでいて息苦しくなった人もいるかもしれない。だから、バランスを取っておきたい。転職が正解だったケースも、確かにあるからだ。転職して正解だった人たちここまで「辞めるな」と書いてきたが、一方的になりすぎただろう。転職して正解だった人も、たくさんいる。私の知り合いにも、転職がキャリアの転機になった人がいる。大企業からスタートアップに移って、2年で技術力が飛躍的に伸びた人。逆に、スタートアップから大企業に移って、大規模開発の経験を積んだ人。マネジメント志向だったのに、転職先でスペシャリストとして開花した人もいる。1人の話をしよう。彼は大企業で5年間、安定したキャリアを積んでいた。評価も悪くなかった。でも、「このまま10年後も同じことをしているのか」という問いが、ずっと頭の片隅にあったという。彼が転職を決めたのは、「逃げたい」からではなかった。「自分の手でプロダクトを作りたい」という明確な欲求があった。大企業では、どうしても歯車の一部になる。意思決定に関われるのは、ずっと先の話だ。彼は、その「ずっと先」を待てなかった。転職先は、20人規模のスタートアップだった。最初の3ヶ月は地獄だったと言っていた。前職では当たり前だったインフラが何もない。ドキュメントもない。聞ける人もいない。「俺、何やってるんだろう」と思った夜もあったらしい。でも、半年後に変化が起きた。自分が設計したアーキテクチャが、本番環境で動き始めた。ユーザーからのフィードバックが、直接Slackに届くようになった。「自分の仕事が、誰かの役に立っている」——その実感が、すべてを変えたと言っていた。彼が転職で成功したのは、運が良かったからではない。辞める前に、「次に何を得たいか」が明確だったからだ。「今の環境が嫌だから」ではなく、「次の環境でこのスキルを得たい」「この経験を積みたい」という具体的な理由で動いていた。これは、私が見てきた「転職で成功した人たち」に共通する特徴だ。ここで視点を切り替えてみたい。「今の仕事への期待値は下げ、キャリアにはもっと期待しよう」。今の仕事で完璧を求めすぎない。すべての仕事が理想的であるはずがない。でも、キャリア全体では高い目標を持つ。3年後、5年後にどうなっていたいか。この視点の切り替えが、良い転職をした人たちの特徴だった。そして、もう1つ。彼らは辞める前に、現職でやれることをやり切っていた。「ここでやれることはやった」という実感があった。だからこそ、次の環境で活かせる実績と経験を持って移れた。転職が正解になるかどうかは、転職先の問題ではない。辞める前に何を積み上げたかの問題だ。だから、この記事で伝えたいのは「絶対に辞めるな」ではない。「辞める準備はできているか」を問え、ということだ。ただし、ここで1つ付け加えておきたい。準備とは関係なく、すぐに辞めるべきときがある。そのタイミングを見誤ると、取り返しのつかないことになる。それでも辞めるべきタイミングここまで「辞めるな」と書いてきた。でも、辞めるべきタイミングは確かにある。そして、それは「自分の問題」ではなく、「環境の問題」であることも多い。メンタルや身体が壊れそうなときは、今すぐ辞めろ。これだけは絶対だ。キャリアよりも健康が大事だ。あなた個人に対するリスペクトを感じない会社や現場からは、即刻立ち去るべきだ。そこで無理をする必要はない。一方的に消耗させられる必要もない。我慢して壊れてからでは遅い。組織の構造的問題があるときも、辞めていい。これは重要なポイントだ。個人の努力では変えられない問題が、組織には存在する。いくつか例を挙げる。評価制度が機能していない——成果を出しても正当に評価されない。声が大きい人だけが昇進する。透明性がない。技術的負債が放置されている——経営層が技術投資を理解せず、ひたすら機能追加だけを求める。改善の余地がない。権限と責任が一致しない——責任だけ押し付けられて、決定権がない。何を提案しても却下される。人間関係の構造が壊れている——特定の人物によるハラスメント。派閥争い。コミュニケーションの断絶。会社の方向性に共感できない——ビジョンが見えない。または、見えたビジョンが自分の価値観と合わない。これは、あなたの責任ではない。どんなに努力しても、個人で変えられない問題はある。「もっと頑張れば変えられるはず」と思って消耗し続ける必要はない。構造的問題を個人の努力で乗り越えようとするのは、無理ゲーだ。今の環境で目指す役割に挑戦する機会がどうしても得られないときも、辞め時だ。組織の構造上、テックリードのポジションがない。マネジメントのポジションがない。専門性を深める機会がない。そういう時は、環境を変える必要がある。私が辞め時だと思う明確なサインがある。「学びたい意欲はあるのに、実際には学べていない」状態だ。技術を深めたい、新しいことに挑戦したい——その気持ちはある。でも、日々の仕事は同じことの繰り返し。成長の機会がない。もう1つのサインは、「スキルではなく、対処法を学んでいる」状態だ。技術力が上がっているのではなく、「この上司にはこう報告すればいい」「この会議はこうやり過ごせばいい」という政治的なサバイバルスキルばかりが磨かれている。これは危険信号だ。その環境で得られるものは、もう得尽くした可能性が高い。しかし、一点だけ確認してほしい。本当に機会がないのか、自分が機会を見逃していないか。機会は待っていても来ない。自分で作り出すものだ。作り出そうとしたけど本当に無理だった——そう言えるなら、転職は正しい選択だ。一方で、こういう時は立ち止まってほしい。「なんとなく飽きた」「刺激がない」「成長できない気がする」——こういう漠然とした不満だけで辞めようとしているなら、一度考えてみてほしい。それは本当に環境の問題なのか。自分の姿勢の問題ではないのか。辞める理由が「環境の構造的問題」なら、辞めていい。辞める理由が「自分の漠然とした不満」なら、もう少し掘り下げてみてほしい。その違いを見極めることが大事だ。ここで1つ、厳しい問いを投げかけたい。「この会社では無理だ」という結論に至るまでに、組織のボトルネックに対して具体的な改善提案や行動を何回試みたか。「評価制度がおかしい」と感じたなら、上司やHRに具体的な改善案を提案したか。「技術的負債が放置されている」と感じたなら、解消のためのロードマップを作って経営層に説明したか。試行回数がゼロなら、それは「構造の問題」ではなく「食わず嫌い」かもしれない。失敗してもいいから、一度は試みてほしい。試みた上で無理だったなら、辞める判断は正しい。ここまで、様々な角度から転職について考えてきた。辞めるべきとき、辞めるべきでないとき、その判断基準を見てきた。最後に、これまでの内容を整理して、問いかけの形にまとめておきたい。転職を決断する前に転職を考えているあなたに、最後に問いかけたい。まず、方向性は明確か。テックリードを目指すのか、EMを目指すのか、スペシャリストとして深掘りするのか。次に進みたい方向が言語化できていなければ、転職は単なる「移動」に終わる。技術力、推進力、影響力のうち、今の自分に足りないものは何か。それを伸ばす機会が、本当に今の環境にはないのか。転職すれば自動的に成長できるわけではない。次に、積み上げたものを使い切ったか。転職には必ずリセットコストがかかる。信頼の貯金はゼロに戻る。ドメイン知識も、人間関係も、リセットされる。その代償を払ってでも得たいものは何か。今の会社で、信頼の貯金を活用してできる挑戦はもうないのか。信頼があるからこそ任される大きな仕事を、やり残していないか。現職で主体的に動いて成し遂げた実績を語れるか。「自分がいたからこそ生まれた差分」を説明できるか。そして、冷静に判断できているか。「成長できない」のは本当に環境のせいか。それとも、難しい課題から逃げているだけではないか。転職理由が「年収を上げたい」だけになっていないか。年収は結果であって、目的ではない。転職エージェントのアドバイスを鵜呑みにしていないか。彼らは転職させることでお金をもらっている。利害関係のない第三者——信頼できる先輩、友人、メンター——に相談したか。「一人前の開発者」から次のステージに進めているか。それとも、キャッチアップを繰り返しているだけではないか。すべてに明確な答えを持っている必要はない。だが、1つも考えたことがないなら、まだ転職を決断する段階ではない。おわりにこの記事で言いたかったことは、結局、1つだけだ。短期的にモノを考えるな。目の前の不満。今月の年収。来週の上司との関係。そういうものに振り回されて、衝動的に決断するな。3年後、5年後、10年後の自分がどうなっていたいか。そこから逆算して考えろ。若いエンジニアが短期的に考えてしまうのは、仕方がない。私もそうだった。目の前の不満が世界のすべてに見える。「今すぐ環境を変えたい」という衝動を抑えられない。それは、若さゆえの特権でもある。でも、その特権には代償がある。転職を繰り返すたびに、信頼の貯金はリセットされる。キャリアの複利は止まる。「いろんな経験を積んだ」と言えば聞こえはいいが、どこにも根を張れないまま、年齢だけが積み上がっていく。私は、そういう未来を避けたかった。転職は、逃げにもなるし、飛躍にもなる。同じ「辞める」という行動でも、その意味は正反対になりうる。違いを決めるのは、辞める前に何を考えたか。それだけだ。1つだけ、問いを残しておく。もし今の会社の嫌な部分——人間関係や評価制度——がすべて解消されたとしたら、それでもなお、その新しい会社に行きたいと心から思えるか。YESなら、それは「攻め」の転職だ。NOなら、それは高度に正当化された「逃げ」かもしれない。逃げが悪いとは言わない。ただ、逃げを「攻め」の物語ですり替えていないか、正直な気持ちで自分に問いかけてほしい。深夜2時、ベッドの中で転職サイトを開いたとき。その衝動を否定はしない。ただ、その衝動のまま動くな。翌朝、もう一度考えろ。1週間後、もう一度考えろ。それでもなお、辞めたいと思うなら、そのときは辞めればいい。正直に言えば、「正解」なんてない。辞めても、残っても、どちらが正しかったかは、誰にも分からない。分かるのは、ずっと後になってからだ。そして、その「正しさ」は、最初から存在していたわけではない。選んだ道を、正解にしていく過程があるだけだ。おい、考えろ。短期ではなく、長期で考えろ。そして、選んだら、それを正解にしろ。続編を書きました。syu-m-5151.hatenablog.com参考書籍ＩＴエンジニアの転職学　２万人の選択から見えた、後悔しないキャリア戦略 (ＫＳ科学一般書)作者:赤川朗講談社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社AmazonNINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon世界標準のフィードバック　部下の「本気」を引き出す外資流マネジメントの教科書作者:安田 雅彦SBクリエイティブAmazonみんなのフィードバック大全作者:三村 真宗光文社Amazonネガティブフィードバック　「言いにくいこと」を相手にきちんと伝える技術作者:難波 猛アスコムAmazonロバート・キーガンの成人発達理論――なぜ私たちは現代社会で「生きづらさ」を抱えているのか作者:ロバート・キーガン,中土井僚,鈴木規夫英治出版Amazon「人の器」の磨き方　リーダーシップ・コーチングと成人発達理論による人間力の変容プロセス作者:加藤洋平,中竹竜二日本能率協会マネジメントセンターAmazon「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazon組織も人も変わることができる！　なぜ部下とうまくいかないのか　「自他変革」の発達心理学作者:加藤洋平日本能率協会マネジメントセンターAmazon人が成長するとは、どういうことか作者:鈴木規夫日本能率協会マネジメントセンターAmazonあなたはなぜ雑談が苦手なのか（新潮新書）作者:桜林直子新潮社Amazon世界の一流は「雑談」で何を話しているのか作者:ピョートル・フェリクス・グジバチクロスメディア・パブリッシング（インプレス）Amazon「何を話していいかわからない」がなくなる　雑談のコツ作者:ひきた よしあきアスコムAmazon雑談の一流、二流、三流作者:桐生 稔明日香出版社Amazon雑用は上司の隣でやりなさい――あなたの評価を最大限に高める「コスパ最強」仕事術作者:たこすダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義は私たちをなぜ幸せにしないのか (ちくま新書)作者:ナンシー・フレイザー,江口泰子筑摩書房Amazon資本主義はなぜ限界なのか　――脱成長の経済学 (ちくま新書)作者:江原慶筑摩書房Amazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon","isoDate":"2026-01-05T00:00:20.000Z","dateMiliSeconds":1767571220000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Hacker NewsのShow HN に自作ツールを投稿する方法 ","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622","contentSnippet":"はじめにHacker News の「Show HN」は、自分が作ったものを開発者コミュニティに紹介できる場だ。しかし、ただ URL を貼れば良いわけではない。明確なルールがあり、それを守らないと投稿が埋もれたり、他のユーザーから通報されて非表示になることもある。この記事では、Show HN のルールを読み解き、効果的な投稿を作成するまでのプロセスを解説する。Show HN とは何かShow HN は Hacker News 内の特別なカテゴリで、自分が作ったものを他の人が試せる形で共有する場所だ。通常の HN 投稿がニュースや記事のシェアであるのに対し、Show HN は「触れるもの」を紹介する。投稿が一定のポイントを獲得すると、トップバーの \"show\" ページに表示され、より多くの人の目に触れる。ルールを正確に理解するShow HN には明確なルールがある。公式ガイドラインから重要なポイントを抜粋する。news.ycombinator.com投稿できるものユーザーが実際に試せるもの（run on their computers or hold in their hands）ハードウェアの場合は動画や詳細な記事でも可書籍の場合はサンプルチャプターでも可投稿できないものブログ記事サインアップページニュースレターリスト記事その他「読むだけ」のコンテンツこれらは「試せない」ため Show HN の対象外だ。通常の投稿として submit すべき。その他の重要なルール自分が関わったプロジェクトであること議論に参加できる状態であることサインアップやメール登録なしで試せるのが理想準備ができていないなら投稿しない（ready になってから来い）ランディングページや資金調達ページは NG友人に upvote や comment を頼むのは禁止（組織的な票操作とみなされる）マイナーアップデート（Foo 1.3.1 is out）は NG、メジャーオーバーホールなら可投稿フォームの構成Show HN の投稿は3つの要素で構成される。1. Title（タイトル）Show HN: で始める必要がある80文字制限がある（超過するとエラー）プロジェクト名と一言説明を入れる2. URLプロジェクトのリポジトリ、デモサイト、またはドキュメントページユーザーがすぐに試せる URL が理想3. Text（オプション）URL を補足する説明文何を作ったか、なぜ作ったか、どう使うかフィードバックを求めるポイントを明示すると反応が得やすい効果的なタイトルの作り方80文字という制限の中で、以下を伝える必要がある。プロジェクト名 — 何と呼ばれているか何をするものか — 一言で説明差別化ポイント（余裕があれば） — なぜこれが面白いかタイトルのパターンShow HN: [プロジェクト名] – [一言説明]文字数を削るテクニック：- 冠詞（a, an, the）を省略- \"for\" を \"–\" に置き換え- 形容詞を削る- 技術用語は略称を使う（もし一般的なら）良いタイトルの例Show HN: Helix – A post-modern text editor written in RustShow HN: Zed – A high-performance code editor from the creators of AtomShow HN: DuckDB – An embeddable SQL OLAP database management system避けるべきタイトルShow HN: My new project that I've been working on for 6 months  ← 情報がないShow HN: Check this out!  ← 何かわからないShow HN: Tool v1.3.2 released  ← マイナーアップデートは NGText（説明文）の書き方Text は任意だが、書いた方が反応は良くなる。以下の構成が効果的：1. 何を作ったか（1-2文）I built a [種類] that [主要機能].2. なぜ作ったか / 何が新しいか（2-3文）既存ツールとの違い、解決した課題、採用した理論やアプローチ。3. 使い方（1-3行）Quick start:  npm install -g mytool  mytool initワンライナーで試せると理想的。4. 主要機能（箇条書き、3-5個）Features:- Feature A- Feature B- Feature C5. フィードバックの呼びかけ（1文）Would love feedback on [具体的なポイント].「フィードバックください」だけでなく、何について聞きたいかを明示すると、具体的なコメントが得やすい。実際の投稿準備プロセスStep 1: ルールの確認まず公式ガイドラインを読む。ルールは時々更新されるため、投稿前に毎回確認するのが安全。news.ycombinator.comStep 2: 素材の整理プロジェクトの URLREADME や説明文主要機能のリストインストール方法Step 3: タイトルの作成80文字制限を意識しながら複数案を作成。文字数カウンターを使って確認する。Step 4: Text の作成上記の構成に沿って簡潔に。長すぎると読まれない。Step 5: 投稿タイミングHN のトラフィックは米国時間の午前中（太平洋時間 6-10 AM）がピーク。日本時間だと夜〜深夜にあたる。AI を活用した投稿準備Show HN の投稿準備は、AI アシスタントとの相性が良い。依頼の例https://news.ycombinator.com/showhn.html のルールに沿って、https://github.com/username/project を Show HN に投稿したい。タイトル、URL、テキストを作成してほしい。AI に依頼する際のポイント：ルールの URL を渡す — AI が最新のルールを参照できるプロジェクトの URL を渡す — README から情報を抽出してもらえる文字数制限を伝える — 80文字制限など、具体的な制約を共有AI が生成した案をそのまま使うのではなく、自分の言葉で調整することで、より自然な投稿になる。投稿後の対応Show HN では投稿者がコメントに返信することが期待されている。質問には丁寧に回答批判的なコメントにも建設的に対応バグ報告には感謝を伝え、対応する姿勢を見せる投稿して放置するのは印象が悪い。数時間はコメントを監視できるタイミングで投稿しよう。まとめShow HN への投稿は、単なる宣伝ではなく、開発者コミュニティとの対話の始まりだと思います。ルールを守る — 「試せるもの」を投稿するタイトルは80文字以内 — プロジェクト名 + 一言説明Text で文脈を与える — 何を、なぜ、どう使うかフィードバックポイントを明示 — 具体的な質問を投げかける投稿後は対話する — コメントに返信する","isoDate":"2026-01-04T05:16:22.000Z","dateMiliSeconds":1767503782000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Ory HydraでOAuth2認可サーバーを構築する","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007","contentSnippet":"はじめに認可サーバーを構築するタスクがアサインされた。技術選定の裁量はある。仕事の合間にRFC 6749や技術書をいくつか読み始めた。datatracker.ietf.org帰宅後の深夜、週末の空き時間。3日目の深夜2時、私は確信した。これは自前で作るべきではない。認可コードフロー、インプリシットフロー、リソースオーナーパスワードクレデンシャル、クライアントクレデンシャル。4つのグラントタイプ。それぞれにセキュリティ要件がある。PKCEも必要だ。OpenID Connectも。IDトークンのクレーム設計。JWKSエンドポイント。セッション管理。トークン失効。リフレッシュトークンのローテーション。仕様を読めば理解できる。実装もできる。でも、これをプロダクション品質で検証し続けるのは、私たちの仕事ではない。3日間RFCを読んで分かったのは、「自前で作ることの非合理性」だった。調べていく中で、OpenAIがOryを採用していることを知った。www.ory.com彼らは認可サーバーの実装に時間を使わないことを選んだ。彼らの本業はAIモデルの開発だ。認証認可は重要だが、「解くべき問題」ではなく「解決済みの問題を使う」領域として扱っている。妥当な判断だと思う。Ory Hydraを採用することにした。www.ory.shgithub.comこの記事では、Hydraのアーキテクチャを解説し、Docker Composeで実際に動かすところまでやる。OAuth2/OIDCの基本概念は知っている前提で進める。OAuth徹底入門 セキュアな認可システムを適用するための原則と実践作者:Justin Riche,Antonio Sanso翔泳社AmazonOAuth 2 in Action (English Edition)作者:Richer, Justin,Sanso, AntonioManningAmazonこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。「認証をしない認可サーバー」という話www.ory.comHydraのドキュメントを読んでいて、ある一文で手が止まった。「Hydraは認証をしません」認可サーバーなのに認証しない。最初は設計の欠落かと思った。Auth0やKeycloakは全部やってくれるのに。だが、ドキュメントを読み進めるうちに意図が見えてきた。これは欠陥ではない。これこそが設計の核心だ。考えてみてください。あなたの会社には、おそらく既にユーザーデータベースがある。10年使ってきた認証システムがある。LDAPで認証している。多要素認証は自前のものを使っている。パスキー対応も進めている。一般的なIdP——Auth0やKeycloak——を導入すると、これらを全部IdP側に合わせなければなりません。データ移行。認証フローの再設計。既存システムとの複雑な連携。Hydraは違うアプローチを取ります。「認証はあなたたちでやってください。終わったら教えてくれれば、あとはこちらでOAuth2/OIDCの面倒なことは全部やります」この瞬間、私の中で何かがカチッとはまりました。既存の認証システムはそのまま。ユーザーDBもいじらない。ただ、OAuth2/OIDCのプロトコル層だけをHydraに任せる。認証と認可の責務が完全に分離される。これが「ヘッドレス」な認可サーバーというコンセプトです。具体的には以下のメリットがあります。既存システムはそのまま使える: ユーザーDB・認証ロジックをいじらなくていい認証方法は完全に自由: パスワード、パスキー、生体認証、なんでもHydraが担保するのはプロトコル準拠: OpenID Connect Certificationを取得済みhttps://openid.net/certification/openid.netアーキテクチャの全体像www.ory.comHydraを使ったシステムは、3つのコンポーネントで構成されます。Hydra Public API（ポート4444）はOAuth2/OIDCの「顔」です。クライアントアプリケーションが/oauth2/authに認可リクエストを投げ、/oauth2/tokenでトークンを受け取る。ここはHydraが全部やってくれます。Login/Consent Provider（ポート3000）が私たちの実装領域です。Hydraからリダイレクトされてきたユーザーに対して、/loginで認証画面を、/consentで同意画面を表示します。「このユーザーは本人か？」「このスコープを許可するか？」という判断を担う。ここに既存の認証ロジックを組み込みます。Hydra Admin API（ポート4445）は裏方です。Login/Consent Providerが認証・同意の結果をHydraに通知するために使います。チャレンジの検証、承認の通知、セッション管理を担当します。外部には公開せず、内部ネットワークからのみアクセスさせます。この構成を理解したとき、肩の荷が下りた気がしました。OAuth2/OIDCの複雑な部分はHydraに任せて、自分たちは「認証」という本質的な部分だけに集中できる。これなら、やれそうだ。チャレンジベースのフローwww.ory.comHydraとProviderの連携には「チャレンジ」という仕組みが使われます。最初は「なんで直接やり取りしないんだろう」と思いました。でも、この設計にはちゃんと理由があります。クライアントがHydraの/oauth2/authにリダイレクトHydraがlogin_challengeを生成し、Login ProviderにリダイレクトLogin Providerはlogin_challengeを検証し、ユーザーを認証認証成功後、Admin APIで承認を通知し、Hydraに戻るHydraがconsent_challengeを生成し、Consent ProviderにリダイレクトConsent Providerはスコープを確認し、Admin APIで承認クライアントに認可コードが返されるチャレンジは一度きりの使い捨てトークンです。傍受されても再利用できない。リプレイ攻撃やセッションハイジャックを構造的に防ぎます。この手のセキュリティ上の細かい配慮——正直、自前実装だと見落としがちだ。PKCEのcode_verifierの長さ制限（43-128文字）。stateパラメータに暗号学的に安全な乱数を使うべきこと。RFCを読んでいたあの3日間で、攻撃ベクトルをどれだけ考慮できていたか。Hydraはこれらをすべて内包しています。OpenID Connect Certificationを取得しているということは、私が見落としていたであろう細部まで検証されているということです。Docker Compose環境の構築www.ory.com理論は十分。実際に動かしてみましょう。OAuth2/OIDCの仕様は複雑です。RFC 6749を読んでも、認可コードフローの全体像が頭に入らなかった。実際にcurlでリクエストを投げ、リダイレクトを追いかけることで、初めて仕様書の抽象的な記述が腑に落ちました。開発環境は4つのサービスで構成されます。HydraのDockerイメージは公式で提供されています。hub.docker.comservices:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: hydra      POSTGRES_PASSWORD: secret      POSTGRES_DB: hydra    volumes:      - postgres_data:/var/lib/postgresql/data    healthcheck:      test: [\"CMD-SHELL\", \"pg_isready -U hydra -d hydra\"]      interval: 5s      timeout: 5s      retries: 5  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:3000/consent      URLS_LOGIN: http://localhost:3000/login      URLS_LOGOUT: http://localhost:3000/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - \"4444:4444\"      - \"4445:4445\"    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: [\"CMD\", \"wget\", \"-q\", \"--spider\", \"http://localhost:4444/health/ready\"]      interval: 10s      timeout: 5s      retries: 5  auth-provider:    build: .    environment:      HOST: 0.0.0.0      PORT: 3000      HYDRA_ADMIN_URL: http://hydra:4445      RUST_LOG: ory_hydra_rust=debug,tower_http=debug    ports:      - \"3000:3000\"    depends_on:      hydra:        condition: service_healthyvolumes:  postgres_data:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMに32文字以上の暗号学的に安全な値を設定し、sslmode=disableはrequireに変更してください。docs.docker.comauth-providerサービスのbuild: .は、Login/Consent ProviderのDockerfileを参照しています。このDockerfileとRust実装は次回の記事で解説します。今回はHydraのアーキテクチャ理解に集中しましょう。サンプルコードは以下のリポジトリで公開しています。https://github.com/nwiizo/workspace_2026/tree/main/samples/ory-hydra-rustgithub.comdepends_onとhealthcheckの組み合わせがポイントです。PostgreSQL → マイグレーション → Hydra → auth-providerという起動順序が保証されます。私は最初これを書かずに「DBがない」エラーで30分悩みました。環境の起動と動作確認docker compose up -d --builddocker compose logs -f auth-providerヘルスチェック用エンドポイントにアクセスしてみます。curl http://localhost:3000/health# {\"status\":\"healthy\"}{\"status\":\"healthy\"}が返ってきた。たった数十行のdocker-compose.ymlで、OAuth2認可サーバーの基盤が動いている。RFCを読んでいたあの3日間で見えた複雑さが、Hydraの中に隠蔽されている。OAuth2クライアントの登録OAuth2フローをテストするには、まずクライアントを登録します。www.ory.shdocker compose exec hydra hydra create oauth2-client \\  --endpoint http://localhost:4445 \\  --grant-type authorization_code \\  --response-type code \\  --scope openid,offline_access,profile,email \\  --redirect-uri http://localhost:8080/callback \\  --name \"Test Client\"クライアントIDとシークレットが出力されるので控えておきます。OAuth2フローのテストテストユーザーを作成します。curl -X POST http://localhost:3000/api/auth/register \\  -H \"Content-Type: application/json\" \\  -d '{\"email\": \"test@example.com\", \"password\": \"password123\"}'ブラウザで認可エンドポイントにアクセスします（\u003cCLIENT_ID\u003eは先ほど取得したもの）。http://localhost:4444/oauth2/auth?client_id=\u003cCLIENT_ID\u003e\u0026response_type=code\u0026scope=openid+profile+email\u0026redirect_uri=http://localhost:8080/callback\u0026state=random_stateフローは以下のように進みます。Hydraがログイン画面にリダイレクトメールアドレスとパスワードを入力してログインHydraが同意画面にリダイレクトスコープを確認して同意http://localhost:8080/callback?code=...にリダイレクトリダイレクト先（8080）は存在しなくても構いません。URLから認可コードを取得できれば成功です。おわりにこの記事を書き終えて、時計を見た。深夜1時だ。正直に言うと、書いている途中で何度かRFCのタブを開いてしまった。「この説明で合ってるかな」と不安になって。私はこの記事を書いたからといって、OAuth2/OIDCを完全に理解したわけではない。たぶん来週も、仕様書の細部で「あれ？」となる瞬間がある。でも、少しだけ違うことがある。3日目の深夜2時、RFCのタブを20個開いて、私は判断した。これは自前で作るべきではない、と。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Hydraのアーキテクチャを理解して、Docker Composeで動かしてみて、その判断が正しかったと確信した。認証と認可は分離できる。複雑なプロトコル層は、検証済みの実装に任せていい。私が書くべきコードは、真ん中の「Login/Consent Provider」だけだ。「認可サーバーを自前で作ってくれ」もしあなたが今、この言葉を受けてRFCを読んでいるなら。3日読めば分かる。作れるかどうかではない。作るべきかどうかだ。RFCを読むことには意味がある。私もあの3日間があったから、Hydraの設計思想が腑に落ちた。でも、プロダクション品質の認可サーバーを一人で検証し続ける必要はない。検証済みの実装がある。明日の朝、目覚ましが鳴る。また仕事が始まる。おい、RFCのタブを閉じろ。Hydraのドキュメントを開け。何度でも思い出せることの方が大事だ。次の記事では、RustでLogin/Consent Providerを実装する。一緒に認証画面を作ろう。","isoDate":"2026-01-04T04:30:07.000Z","dateMiliSeconds":1767501007000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"私の為のNvChadのキーマッピングガイド 2026年版","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621","contentSnippet":"はじめに一月三日である。私は今、ソファの深淵に身を沈め、己の怠惰と対峙しているところである。年末にやろうと固く心に誓った開発環境の整理は、見事なまでに手つかずのまま新年を迎えてしまった。大掃除もしていない。年賀状も書いていない。結婚もしていないし、友人と過ごす予定もなかった。やらなかったことを指折り数えていると、正月休みの大半が、まるで人生の棚卸しのような様相を呈し、胸中は罪悪感で満たされていくのである。「年末年始は何をしていたのか」と問われれば、私は途方に暮れるほかない。身体は動かしていない。コードは書いた。本を読み、近所を散歩した。であるから、休んだと言えば休んだのであろう。しかしながら、休んだという実感が皆無なのである。なぜか。「あのキーバインド、なんだったか」という問いが、四六時中、頭蓋骨の内側をぐるぐると巡り続けていたからに相違ない。私はNvChadを使っている。かれこれ四年ほど使い続けている。それにもかかわらず、半年ぶりに設定を見直すたびに「これ、なんのキーだったか」と首を傾げてしまうのである。設定ファイルには丁寧にコメントを書いてある。過去の自分が、未来の自分のために残してくれた親切なメモである。しかし、読んでも思い出せない。覚えた数だけ忘れている。どうやら人間の脳というものは容量が有限であり、Vimのキーバインドよりも優先して記憶すべき事柄があるらしいのだ。たとえば、それが何であるかは私にもわからないのだが。毎年、年始になると私は同じことを繰り返している。設定を見直す。新しいプラグインを試す。キーマッピングを整理する。そしてまた忘れる。「今年こそ覚える」という新年の誓いは、結局のところ、翌年の自分に対する壮大な裏切り行為でしかないのである。このガイドは、そんな救いようのない私のための備忘録である。来年の今頃、またしても全てを忘れ去った自分のために書いている。もしかすると、同じように忘れっぽい誰かの役に立つかもしれない。立たないかもしれない。たぶん、立たない。ちなみに、一昨年にも同じようなことを書いている。進歩がない。ただし、構成はだいぶ変わった。ステータスラインを廃止し、ファイルエクスプローラーをoil.nvimに変え、Snacks.nvimを導入した。変わっていないのは、私が相変わらずキーマッピングを忘れ続けているという事実だけである。syu-m-5151.hatenablog.com開発環境全体についてはこちらに記した。興味のある方は参照されたい。syu-m-5151.hatenablog.comさて、前置きが長くなった。よく忘れるキーマッピングをまとめていくこととする。設定ファイルは以下に置いてある。github.com基本的なショートカット表記\u003cC\u003e = Ctrlキー\u003cleader\u003e = スペースキー（デフォルト）\u003cA\u003e = Altキー\u003cS\u003e = Shiftキーよく使う機能とそのキーマッピング基本操作で必須のコマンド\u003cC-s\u003e       - 保存（これだけは絶対覚える。:w なんてやっているとVSCodeを使っている人にバカにされる）;           - コマンドモードに入る（:を押す必要がない）jk または jj - インサートモードを抜ける（Escより断然速い）\u003cEsc\u003e       - 検索ハイライトをクリア\u003cleader\u003ey   - システムクリップボードにヤンク\u003cleader\u003eY   - 行全体をシステムクリップボードにヤンク\u003cleader\u003ed   - ヤンクせずに削除（レジスタを汚さない）ナビゲーション（移動系）スクロールと検索が画面中央に来るようにカスタマイズしている。迷子にならない。\u003cC-d\u003e  - 半ページ下スクロール（画面中央維持）\u003cC-u\u003e  - 半ページ上スクロール（画面中央維持）n      - 次の検索結果（画面中央維持）N      - 前の検索結果（画面中央維持）検索系（2つのピッカーを使い分け）Snacks Picker（s系）- メインで使うSnacks.nvimは2024年末に登場した新しいユーティリティセット。高速で美しい。\u003cleader\u003e\u003cleader\u003e - スマートピッカー（最重要：状況に応じた最適な検索）\u003cleader\u003esf - ファイル検索\u003cleader\u003esg - プロジェクト内テキスト検索（grep）\u003cleader\u003esw - カーソル下の単語を検索\u003cleader\u003esb - 開いているバッファを検索\u003cleader\u003esr - 最近開いたファイルを検索\u003cleader\u003esc - コマンド検索\u003cleader\u003esh - ヘルプ検索\u003cleader\u003esk - キーマップ検索（何かわからなくなったらこれ）\u003cleader\u003esd - 診断情報を検索\u003cleader\u003ess - LSPシンボル検索\u003cleader\u003esR - 直前のピッカーを再開github.comTelescope（f系）- 補助的に使う長年使い慣れたTelescope。fzf-nativeで高速化済み。\u003cC-p\u003e       - ファイル検索（VSCodeユーザーも安心）\u003cleader\u003eff  - ファイル検索\u003cleader\u003efg  - ライブgrep\u003cleader\u003efb  - バッファ検索\u003cleader\u003efh  - ヘルプタグ検索\u003cleader\u003efr  - 最近のファイル\u003cleader\u003efc  - Gitコミット検索\u003cleader\u003efs  - Gitステータス\u003cleader\u003efd  - 診断情報github.comファイルエクスプローラー（oil.nvim）NvimTreeからoil.nvimに乗り換えた。バッファのようにディレクトリを編集できる革命的なプラグイン。ファイル名を間違えて作成しても、ddで消せる。Vimの操作で世界を編集している気分になれる。気分だけ。-           - 親ディレクトリを開く（最重要：ファイル階層を上る）\u003cleader\u003ee   - ファイルエクスプローラーを開く\u003cCR\u003e        - ファイル/ディレクトリを選択\u003cC-v\u003e       - 垂直分割で開く\u003cC-s\u003e       - 水平分割で開くg.          - 隠しファイルの表示切り替えgithub.com高速移動（flash.nvim）EasyMotion系のモダンな代替。画面内のどこにでも2-3キーで飛べる。s  - Flash（画面内の任意の位置にジャンプ）S  - Flash Treesitter（構文単位でジャンプ）r  - Remote Flash（オペレーターモード用）github.comLSP関連（コードジャンプ・リファレンス）コードリーディングする時に本当に助かる機能たち。gd          - 定義へジャンプ（最も使う）gD          - 宣言へジャンプgi          - 実装へジャンプ（インターフェースから実装を探せる）gr          - 参照を探す（変数やメソッドの使用箇所を探せる）K           - ホバー情報を表示（ドキュメント、型情報）Ctrl-^    直前に編集していたファイルに切り替え\u003cleader\u003ern  - シンボルをリネーム\u003cleader\u003eca  - コードアクション（自動修正候補など）\u003cleader\u003efm  - フォーマット（conformで整形）\u003cleader\u003ecf  - フォーマット（代替キー）\u003cleader\u003elk  - シグネチャヘルプ\u003cleader\u003elD  - 型定義へジャンプgithub.comコードピーク（overlook.nvim）定義にジャンプせずに、フローティングウィンドウで確認できる。\u003cleader\u003epd  - 定義をピーク（フローティングで定義を確認）\u003cleader\u003epc  - すべてのポップアップを閉じる\u003cleader\u003epu  - 最後のポップアップを復元\u003cleader\u003epU  - すべてのポップアップを復元\u003cleader\u003epf  - フォーカスを切り替え\u003cleader\u003eps  - 分割で開く\u003cleader\u003epv  - 垂直分割で開く\u003cleader\u003epo  - 元の場所で開くgithub.com診断・エラー確認（Trouble）診断情報を一覧で見やすく表示してくれる。[d          - 前の診断へ]d          - 次の診断へ\u003cleader\u003eld  - 行の診断情報をフロートで表示\u003cleader\u003elq  - 診断をloclistに送る\u003cleader\u003exx  - 診断パネルをトグル（Trouble）\u003cleader\u003exX  - 現在のバッファの診断のみ\u003cleader\u003exs  - シンボル一覧（Trouble）\u003cleader\u003exl  - LSP定義一覧\u003cleader\u003exq  - Quickfixリスト\u003cleader\u003ext  - TODO/FIXME一覧github.com画面分割とウィンドウ移動複数のファイルを同時に見たい時に使う。\u003cC-h\u003e       - 左のウィンドウへ\u003cC-l\u003e       - 右のウィンドウへ\u003cC-j\u003e       - 下のウィンドウへ\u003cC-k\u003e       - 上のウィンドウへ\u003cleader\u003e|   - 垂直分割\u003cleader\u003e-   - 水平分割\u003cleader\u003ew=  - ウィンドウサイズを均等に\u003cleader\u003ewm  - ウィンドウを最大化（他を閉じる）バッファ操作\u003cS-h\u003e       - 前のバッファへ（Shift + h）\u003cS-l\u003e       - 次のバッファへ（Shift + l）\u003cleader\u003ex   - バッファを閉じる\u003cleader\u003ebd  - バッファを削除（Snacks）\u003cleader\u003ebo  - 他のバッファをすべて削除ビジュアルモードの改善J           - 選択した行を下に移動K           - 選択した行を上に移動\u003cleader\u003ep   - ペースト（レジスタを上書きしない）Git操作LazyGitとの統合が最高に便利。ターミナルでgitコマンドを打つ必要がほぼなくなった。git add -pのインタラクティブモードを思い出せなくても、もう困らない。\u003cleader\u003egg  - LazyGitを開く（これだけで全部できる）\u003cleader\u003egl  - LazyGit ログを表示\u003cleader\u003egf  - 現在のファイルのログを表示\u003cleader\u003egd  - Git Diff（作業ツリー全体）\u003cleader\u003egD  - 前のコミットとのDiff\u003cleader\u003egh  - ファイルの履歴\u003cleader\u003egH  - ブランチの履歴\u003cleader\u003egs  - ステージされた変更のDiff\u003cleader\u003egm  - mainブランチとのDiff\u003cleader\u003egM  - masterブランチとのDiff\u003cleader\u003egq  - Diffviewを閉じる\u003cleader\u003egt  - ファイルパネルをトグル\u003cleader\u003egp  - Hunkをプレビュー\u003cleader\u003egb  - 行のBlameを表示\u003cleader\u003egB  - 行Blameのトグル]c          - 次のHunkへ[c          - 前のHunkへ\u003cleader\u003ehr  - Hunkをリセット\u003cleader\u003ehs  - Hunkをステージ\u003cleader\u003ehu  - Hunkのステージを取り消しgithub.comgithub.comgithub.comターミナル操作\u003cleader\u003ett  - ターミナルをトグル（Snacks）\u003cC-x\u003e       - ターミナルモードを抜けるAI統合（2026年の目玉）GitHub CopilotとClaudeの両方を使える贅沢な環境。CopilotChat（a系）\u003cleader\u003eao  - チャットを開く\u003cleader\u003eaq  - チャットを閉じる\u003cleader\u003ear  - チャットをリセット\u003cleader\u003eae  - コードを説明（ビジュアルモード対応）\u003cleader\u003eaf  - コードを修正\u003cleader\u003eat  - テストを生成\u003cleader\u003ead  - ドキュメントを生成\u003cleader\u003eaR  - コードをレビューgithub.comAvante（Cursor風のAI体験）\u003cleader\u003eaa  - AIに質問\u003cleader\u003eax  - コードを編集\u003cleader\u003eaS  - 回答をリフレッシュgithub.comClaudeCode（ターミナル統合）\u003cleader\u003ecc  - Claudeをトグル\u003cleader\u003ecf  - Claudeにフォーカス\u003cleader\u003ecr  - 会話を再開\u003cleader\u003ecC  - 会話を継続\u003cleader\u003ecm  - モデルを選択\u003cleader\u003ecb  - 現在のバッファを追加\u003cleader\u003ecs  - 選択範囲をClaudeに送信（ビジュアルモード）github.com補完操作（nvim-cmp）\u003cC-p\u003e       - 前の候補\u003cC-n\u003e       - 次の候補\u003cC-d\u003e       - ドキュメントを下にスクロール\u003cC-f\u003e       - ドキュメントを上にスクロール\u003cC-Space\u003e   - 補完を手動で開始\u003cC-e\u003e       - 補完を閉じる\u003cCR\u003e        - 候補を確定\u003cTab\u003e       - 次の候補 / スニペット展開\u003cS-Tab\u003e     - 前の候補 / スニペット前へgithub.comトグル系（u系）Snacks.nvimが提供する便利なトグル機能。\u003cleader\u003eus  - スペルチェックのトグル\u003cleader\u003euw  - ワードラップのトグル\u003cleader\u003eud  - 診断のトグル\u003cleader\u003euh  - インレイヒントのトグルその他の便利機能\u003cleader\u003e?   - 現在のバッファのキーマップを表示（which-key）\u003cleader\u003err  - カーソル下の単語を置換\u003cleader\u003ecx  - ファイルに実行権限を付与\u003cleader\u003ej   - 次のQuickfix項目へ\u003cleader\u003ek   - 前のQuickfix項目へ\u003cleader\u003esT  - TODO/FIXME/HACKなどを検索（TodoTelescope）]t          - 次のTODOへ[t          - 前のTODOへgithub.comgithub.comDiffviewコンフリクト解決マージコンフリクトの解決が格段に楽になる。]x          - 次のコンフリクトへ[x          - 前のコンフリクトへ\u003cleader\u003eco  - oursを選択\u003cleader\u003ect  - theirsを選択\u003cleader\u003ecb  - baseを選択\u003cleader\u003eca  - 両方を選択dx          - コンフリクトを削除ビジュアル・UI設定2026年版の大きな特徴は、ミニマルなUIへの移行だ。ステータスラインとタブラインを完全に廃止し、編集スペースを最大化している。情報が多すぎて、結局何も見ていなかったことに気づいたからだ。テーマとカラースキームaquariumテーマを採用。落ち着いた色調で長時間の作業でも目が疲れにくい。-- chadrc.luaM.base46 = {  theme = \"aquarium\",  transparency = false,  hl_override = {    Comment = { italic = true },    [\"@comment\"] = { italic = true },    CursorLine = { bg = \"#2a2a3a\" },    CursorLineNr = { fg = \"#fab387\", bold = true },  },}ステータスライン廃止の理由従来のステータスラインは廃止し、代わりに以下のプラグインで情報を表示している:incline.nvim: ウィンドウ右下にファイル名と診断情報を表示modes.nvim: カーソルラインの色でモードを表示（Insert=水色、Visual=紫、Delete=赤、Copy=黄）noice.nvim: コマンドラインをフローティングで中央に表示-- options.luao.cmdheight = 0    -- コマンドラインを非表示（noice.nvimが担当）o.laststatus = 0   -- ステータスラインを非表示（incline.nvimが担当）o.showmode = false -- モード表示を非表示（modes.nvimが担当）行番号設定相対行番号を有効化。5jや10kのような相対移動が直感的になる。o.number = true         -- 現在行は絶対行番号o.relativenumber = true -- 他の行は相対行番号o.numberwidth = 4       -- 行番号の幅スクロール設定カーソルが画面端に到達する前にスクロールが始まる。常に周囲のコンテキストが見える。o.scrolloff = 8     -- 上下8行を常に表示o.sidescrolloff = 8 -- 左右8列を常に表示インデント設定2スペースインデントを採用。タブは使わない。o.tabstop = 2o.shiftwidth = 2o.expandtab = trueo.smartindent = trueその他のUI設定o.termguicolors = true  -- 24bitカラーo.signcolumn = \"yes\"    -- サインカラムを常に表示（ガター）o.cursorline = true     -- カーソル行をハイライト（modes.nvimで色が変わる）o.splitright = true     -- 垂直分割は右にo.splitbelow = true     -- 水平分割は下にo.clipboard = \"unnamedplus\" -- システムクリップボードと連携o.undofile = true       -- 永続的なundo履歴o.swapfile = false      -- スワップファイルを作らない使用プラグイン一覧と説明UI系プラグイン プラグイン                 説明                                                                                                                                                                                    incline.nvim           ウィンドウ右下にファイル名・アイコン・診断情報を表示するミニマルなフローティングステータスライン。init.luaやmod.rsのような一般的なファイル名の時は親ディレクトリ名も表示される。  modes.nvim             Vimのモード（Normal/Insert/Visual/Delete）に応じてカーソルラインと行番号の色を変える。モード表示がなくても今どのモードにいるか一目でわかる。                                            noice.nvim             コマンドライン、メッセージ、通知をモダンなフローティングUIで表示。画面中央にポップアップするコマンドパレット風のUIが特徴。詳細は後述。                                                  nvim-notify            通知をモダンなポップアップで表示。フェードアニメーションで視認性が高い。                                                                                                                vimade                 非アクティブなウィンドウ/バッファを薄暗く表示。どのウィンドウがアクティブかが視覚的にわかる。                                                                                           better-escape.nvim     jkやjjでインサートモードから抜ける。Escキーに手を伸ばす必要がなくなる。                                                                                                             which-key.nvim         キーを押すと次に押せるキーのヒントを表示。\u003cleader\u003eを押して300ms待つとメニューが出る。                                                                                                 indent-blankline.nvim  インデントレベルを縦線で可視化。ネストの深さが一目でわかる。                                                                                                                           noice.nvim の詳細noice.nvimは、Neovimの標準的なコマンドライン（画面下部の:プロンプト）を完全に置き換え、モダンなフローティングUIを提供するプラグイン。従来の「画面下に張り付いたコマンドライン」から「画面中央にポップアップするコマンドパレット」へと体験が一変する。主な機能:コマンドラインのポップアップ化:を押すと画面中央にフローティングウィンドウが出現入力中のコマンドがシンタックスハイライトされるコマンドタイプに応じたアイコン表示検索のポップアップ化/（前方検索）や?（後方検索）もポップアップで表示検索パターンが正規表現としてハイライトされるコマンドタイプ別のアイコン| 入力 | アイコン | 説明 ||------|---------|------|| : | | 通常のVimコマンド || `/` | ` ` | 前方検索 || `?` | ` ` | 後方検索 || `:!` | `$` | シェルコマンド実行 || `:lua` | | Lua実行 || :help | 󰋖 | ヘルプ |メッセージ・通知の統合エラーや警告メッセージをnvim-notify経由で右下にポップアップ長いメッセージは自動的にスプリットウィンドウに表示LSP統合LSPの処理進捗を表示ホバー情報やシグネチャヘルプもモダンなUIで表示-- 設定例（私の設定）views = {  cmdline_popup = {    position = { row = \"50%\", col = \"50%\" },  -- 画面中央    size = { width = 60, height = \"auto\" },    border = { style = \"rounded\", padding = { 0, 1 } },  },},この設定により、従来のNeovimとは全く異なる、VSCodeやCursor風のモダンな操作感が得られる。github.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comナビゲーション系プラグイン プラグイン          説明                                                                                                                                                      snacks.nvim     folke氏による多機能ユーティリティセット。LazyGit統合、高速ピッカー、バッファ削除、ターミナル、デバッグ機能などを提供。2024年末に登場し、急速に普及した。  telescope.nvim  定番のファジーファインダー。ファイル、バッファ、grep、Git操作など何でも検索できる。fzf-nativeで高速化済み。                                               oil.nvim        ディレクトリをバッファとして編集できるファイルエクスプローラー。ファイル名の変更や移動がテキスト編集と同じ感覚でできる革命的なプラグイン。                flash.nvim      画面内の任意の位置に2-3キーでジャンプ。EasyMotionの後継。Treesitterと連携して構文単位のジャンプも可能。                                                   overlook.nvim   定義にジャンプせずにフローティングウィンドウでコードをプレビュー。元の位置を見失わずに定義を確認できる。                                                  hbac.nvim       開いているバッファが一定数を超えると、最近使っていないバッファを自動的に閉じる。バッファが溢れかえるのを防ぐ。                                           github.comGit系プラグイン プラグイン         説明                                                                                                                    gitsigns.nvim  変更行の左側にサイン（追加=緑、変更=青、削除=赤）を表示。Hunk単位でのステージ、リセット、プレビュー、Blame表示も可能。  diffview.nvim  Git Diffを視覚的に表示。2画面分割で変更前後を比較できる。コンフリクト解決UIも備え、ours/theirs/baseの選択が簡単。      診断・コード品質系プラグイン プラグイン              説明                                                                                                                          trouble.nvim        診断情報（エラー、警告）をパネルに一覧表示。プロジェクト全体の問題を俯瞰できる。シンボル一覧やQuickfixリストの表示にも対応。  todo-comments.nvim  コード内のTODO、FIXME、HACK、BUG、NOTEなどをハイライト表示し、検索可能にする。放置されたTODOを見つけやすい。       LSP・フォーマッタ系プラグイン プラグイン            説明                                                                                                                nvim-lspconfig    Neovim内蔵LSPクライアントの設定を簡単にする公式プラグイン。各言語のLanguage Serverとの接続を管理。                  mason.nvim        LSPサーバー、DAP（デバッガ）、リンター、フォーマッタを簡単にインストール・管理できる。:MasonコマンドでUIが開く。  conform.nvim      フォーマッタの統合プラグイン。保存時に自動フォーマットを実行。複数フォーマッタの連携も可能。                        nvim-treesitter   Tree-sitterによる高精度なシンタックスハイライトとインデント。正規表現ベースよりも正確な構文解析。                   schemastore.nvim  JSON/YAMLファイル用のスキーマを提供。package.jsonやtsconfig.jsonなどの補完と検証が効く。                       github.comgithub.comgithub.comgithub.comAI統合プラグイン プラグイン            説明                                                                                                                                             copilot.lua       GitHub Copilotの純粋なLua実装。インライン補完を提供するが、私の設定ではcopilot-cmp経由で補完メニューに統合。                                     copilot-cmp       Copilotの補完をnvim-cmpのソースとして使用。補完メニュー内で他のソース（LSP、バッファ等）と一緒にCopilot候補が表示される。                        CopilotChat.nvim  AIとのチャットインターフェース。コードの説明、レビュー、テスト生成、ドキュメント生成などをチャット形式で依頼できる。Claude Sonnetモデルを使用。  avante.nvim       Cursor風のAI編集体験をNeovimで実現。選択範囲に対してAIに編集を依頼し、差分をプレビューしてから適用できる。                                       claudecode.nvim   Claude Code CLIをNeovim内で直接使用。ターミナル統合でClaude Codeの全機能にアクセス可能。                                                        github.comgithub.com補完系プラグイン プラグイン        説明                                                                                      nvim-cmp      Neovimの補完エンジン。高速でカスタマイズ性が高い。複数のソースからの補完を統合して表示。  cmp-nvim-lsp  LSPからの補完をnvim-cmpに提供するソース。                                                 cmp-buffer    現在開いているバッファ内の単語を補完候補として提供。                                      cmp-path      ファイルパスを補完。ディレクトリ構造をたどりながら入力できる。                            cmp-cmdline   コマンドラインモード（:）での補完を提供。                                                 LuaSnip       スニペットエンジン。定型コードを素早く展開。                                              lspkind.nvim  補完メニューにアイコンを表示。種類（関数、変数、クラス等）が視覚的にわかる。             github.comgithub.comgithub.comgithub.comgithub.comgithub.com言語固有プラグイン プラグイン        説明                                                                                                                      rustaceanvim  Rust開発を強化するプラグイン。rust-analyzerとの統合を改善し、Rust固有の機能（expand macro、join lines等）を提供。         crates.nvim   Cargo.toml内のクレート（依存関係）のバージョン情報を表示。最新バージョンへの更新や、利用可能なバージョンの確認が簡単。 github.comgithub.comフォーマッタ・LSP設定保存時に自動フォーマットが走る。conform.nvimを使用。 言語                   フォーマッタ               TypeScript/JavaScript  prettier, deno_fmt         Lua                    stylua                     Rust                   rustfmt                    Go                     gofmt, goimports, gofumpt  Python                 black, isort               Terraform              terraform_fmt              Bash/Shell             shfmt                      YAML/JSON/Markdown     prettier                  Treesitter対応言語シンタックスハイライトとインデントはTreesitterで処理。vim, lua, vimdoc, html, css, markdown, markdown_inline, terraform, hcl, bash, python, rust, go, typescript, javascript, tsx, json, yaml, toml2024年版からの主な変更点追加されたプラグイン・機能Snacks.nvim: folke氏の新しいユーティリティセット。LazyGit統合、高速ピッカー、バッファ管理などoil.nvim: NvimTreeに代わるファイルエクスプローラー。ディレクトリをバッファとして編集flash.nvim: EasyMotion系のモダンな代替。Treesitter対応Trouble.nvim: 診断情報の一覧表示diffview.nvim: Git Diffの可視化とコンフリクト解決overlook.nvim: 定義をフローティングでピークAvante.nvim: Cursor風のAI編集体験ClaudeCode: Claude Code CLIとのNeovim統合noice.nvim: コマンドラインとメッセージのモダン化which-key.nvim: キーバインドのヒント表示incline.nvim: ミニマルなファイル名表示modes.nvim: モードに応じたカーソルライン色変更vimade: 非アクティブウィンドウの薄暗化hbac.nvim: 未使用バッファの自動クローズ変更されたキーマッピングバッファ切り替え: \u003cTab\u003e/\u003cS-Tab\u003e → \u003cS-h\u003e/\u003cS-l\u003e（より直感的）スクロール: 画面中央維持が追加検索: SnacksとTelescopeの二刀流にUI設計の変更ステータスラインを完全廃止（incline.nvim + modes.nvim で代替）タブラインを廃止（Snacks pickerで代替）コマンドラインをフローティング化（noice.nvim）なぜこれらのキーマッピングを覚える必要があるのか私の経験上、以下の機能は開発効率を大きく向上させてくれる。ファイル検索（Snacks/Telescope）プロジェクト内のファイルを素早く見つけられるコードベースの把握が容易になる\u003cleader\u003e\u003cleader\u003eのスマートピッカーが特に便利LSP機能コードの定義や参照を素早く調べられるリファクタリングが楽になるコードの理解が深まるエラー診断が即座にわかるRustを書いていると1箇所書き換えると芋づる式に修正が発生する。コンパイラに叱られ、LSPに導かれ、最終的には正しいコードにたどり着く。自分で考えているのか、ツールに考えさせられているのか、もはやわからないGit統合（LazyGit + Diffview）エディタを離れずにすべてのGit操作ができるコンフリクト解決が視覚的でわかりやすい\u003cleader\u003eggでLazyGitを開けば、ステージ、コミット、プッシュ、ブランチ操作など全部できるAI統合コードの説明、レビュー、修正をエディタ内で完結CopilotChatでClaude Sonnetが使える時代Avanteでカーソル位置に応じたAI編集高速移動（flash.nvim）画面内のどこにでも2-3キーで移動できるマウスに手を伸ばす必要がなくなるなぜNvChadを選び続けているのか2024年版でも書いたが、NvChadを選んだ理由は開発体制の健全さだった。その判断は2026年になっても変わっていない。毎年のように「今年こそAstroNvimとかに移行する」と思うが、結局設定を移行する時間で正月休みが終わる。NvChad v3.0以降、設定の構造がより洗練された。lua/plugins/ディレクトリに機能ごとにプラグインをまとめる方式は、設定の見通しを良くしてくれる。私の設定では以下のように分割している:ui.lua: 見た目関連（incline, modes, noice, notify）navigation.lua: 移動・検索（snacks, telescope, oil, flash）git.lua: Git統合（gitsigns, diffview）diagnostics.lua: 診断（trouble, todo-comments）lsp.lua: LSPとフォーマッタ（conform, lspconfig, mason, treesitter）ai.lua: AI統合（copilot, copilot-chat, avante, claudecode）completion.lua: 補完（nvim-cmp）lang.lua: 言語固有（rustaceanvim, crates）この構造のおかげで、何か問題があった時にどこを見ればいいかすぐわかる。nvchad.comVimを学ぶために通常のVimを学ぶ時は、「実践Vim 思考のスピードで編集しよう！」がおすすめだ。Vimの基本から応用までを体系的に学べ、実践的な例も豊富に掲載されている。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazonまた、Vim Adventuresというゲームも面白い。ゲーム感覚でVimのキー操作を学べ、楽しみながら基本的なコマンドが身につく。初心者にも優しい学習カーブで、Vimの世界に入るきっかけとして最適だ。vim-adventures.comおわりにこの文章を書き終えて、ふと時計に目をやると、針は深夜一時を回っていた。年末にやるはずだった開発環境の整理を、結局、一月三日の深夜に敢行しているのである。休めていない。そんなことは百も承知である。正直に告白すれば、この文章を書いている最中にも、私は何度か「あれ、このキーは何だったか」と己の設定ファイルを参照せざるを得なかった。自分のための備忘録を執筆しながら、その備忘録を必要としている。なんという滑稽な光景であろうか。笑えない。いや、笑うしかないのかもしれない。来年の今頃、私は間違いなくこの記事を読み返しているであろう。「そうだ、\u003cleader\u003e\u003cleader\u003eでスマートピッカーが開くのであった」と膝を打ち、束の間の安堵を覚える。そしてまた忘れる。おそらく、その繰り返しなのである。人間とは、かくも愚かな生き物なのだ。しかしながら、少しだけ異なることもある。毎年毎年、同じことを馬鹿の一つ覚えのように繰り返しているうちに、いつの間にか身体が記憶している操作というものが存在するのだ。gdで定義へ跳躍すること。\u003cC-s\u003eで保存すること。意識せずとも指が勝手に動く。それは、忘却と想起を幾度となく繰り返した果てに、ようやく獲得した境地なのである。エディタの設定に正解などない。完璧なキーマッピングも存在しない。ただ、自分が少しでも快適に作業できる環境を、毎年少しずつ更新していくのみである。それでよいのだ。それ以上を望むのは、人間の分際で天に唾するようなものである。さて、私はソファの深淵から這い上がることにする。正月休みはまだ幾ばくか残されている。しかし、仕事が始まれば、またすぐに「あのキーは何だったか」と途方に暮れる瞬間が訪れるに違いない。その時のために、この記事は存在するのである。来年の自分へ。また忘れたら読み返すがよい。どうせ忘れるのだから。参考リンクnvchad.comgithub.comneovim.io","isoDate":"2026-01-02T15:26:21.000Z","dateMiliSeconds":1767367581000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"テスト,検証してますか: cargo-mutantsによるミューテーションテスト入門","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735","contentSnippet":"はじめにテストは全部通っている。コードカバレッジも90%を超えている。なのに、本番環境でバグが見つかった。私が実際に経験したことだ。原因を調べると、テストコードにassert（検証）が書かれていなかった。テストは「コードを実行しただけ」で、結果が正しいかどうかを確認していなかったのだ。正直、恥ずかしかった。テストを書いている気になっていただけで、何も守っていなかった。こういう経験はないだろうか。あるいは、レビューで「このテスト、意味ありますか」と指摘されたことは。この記事では、こうした「見せかけのテスト」を発見するミューテーションテストという手法と、Rust向けのツールcargo-mutantsを紹介します。公式ドキュメントを参照する場合は、以下のリンクからどうぞ。mutants.rsgithub.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。ミューテーションテストとはミューテーションテストは、「テストをテストする」手法です。具体的なコードで説明しましょう。例：割引価格を計算する関数以下のような、商品価格から10%割引した金額を返す関数があるとします。/// 価格から10%割引した金額を返すfn apply_discount(price: u32) -\u003e u32 {    price - (price / 10)}この関数に対して、以下のテストを書きました。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    // 1000円の10%引きは900円のはず...    // でも、assertを書き忘れた！}このテストには問題があります。apply_discount(1000)を呼び出していますが、結果が900であることを検証していません。コードカバレッジは100%ですが、このテストは何も守っていないのです。ミュータント（突然変異体）の生成ミューテーションテストでは、コードに「わざとバグを入れた」バージョンを作ります。これをミュータント（突然変異体）と呼びます。apply_discount関数に対して、以下のようなミュータントが生成されます。// ミュータント1: 引き算を足し算に変えるfn apply_discount(price: u32) -\u003e u32 {    price + (price / 10)  // - を + に変更}// ミュータント2: 常に0を返すfn apply_discount(price: u32) -\u003e u32 {    0  // 関数の本体を0に置き換え}// ミュータント3: 入力をそのまま返すfn apply_discount(price: u32) -\u003e u32 {    price  // 割引計算を削除}テストがミュータントを検出できるか各ミュータントに対してテストを実行します。 ミュータント   変更内容     テスト結果               判定           ミュータント1  - → +    ✅ 成功（テストが通る）  ❌ missed  ミュータント2  常に0を返す  ✅ 成功（テストが通る）  ❌ missed  ミュータント3  割引なし     ✅ 成功（テストが通る）  ❌ missed すべてのミュータントがテストを通過してしまいました。これはテストが何も検証していないことの証拠です。テストを修正するテストにassert_eq!を追加して、結果を検証するようにします。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    assert_eq!(result, 900);  // 結果が900であることを検証}修正後、再度ミュータントをテストします。 ミュータント   変更内容     テスト結果             判定           ミュータント1  - → +    ❌ 失敗（1100 ≠ 900）  ✅ caught  ミュータント2  常に0を返す  ❌ 失敗（0 ≠ 900）     ✅ caught  ミュータント3  割引なし     ❌ 失敗（1000 ≠ 900）  ✅ caught すべてのミュータントが検出されました。これで「テストが正しく機能している」ことが確認できました。ミューテーションテストの核心ここまでの例で分かるように、ミューテーションテストは以下の逆説に基づいています。テストの成功が、失敗の証拠になる。コードを壊したのにテストが通るなら、そのテストは壊れたコードを見逃している——つまり、テストとして機能していません。cargo-mutantsとはcargo-mutantsは、Rust向けのミューテーションテストツールです。上記のような「ミュータントの生成」「テストの実行」「結果の集計」を自動で行います。Rustを使っている開発者なら、cargo install cargo-mutants \u0026\u0026 cargo mutantsの2コマンドで即座に試せます。ソースコードの変更は一切不要です。Rustを使っていない方も、「テストの品質をどう測るか」という観点でお読みいただければ、他の言語にも応用できる考え方が得られるはずです。いつ導入すべきかミューテーションテストは誰でも試せますが、すべてのプロジェクトに必要なわけではありません。正直に言えば、導入コストは低くない。特に有効なのは、カバレッジは80%以上あるのにバグが減らないケースです。金融計算のように正確性が重要なビジネスロジックや、チームにテストの質を意識させたい場面でも効果を発揮します。私自身、冒頭で触れた経験をした後、まずこのツールで「テストが本当に機能しているか」を確認するようになりました。一方、まだカバレッジが50%未満のプロジェクトでは、まずカバレッジを上げる方が効果的です。プロトタイプ段階で変更が激しい場合や、テスト実行時間がすでに長すぎる場合も、ミューテーションテストの優先度は下がります。ツールが問題を解決してくれるわけではない。テストを書くのは人間です。クイックスタートインストール# 推奨: cargoで直接インストールcargo install --locked cargo-mutants# 高速インストール（プリビルドバイナリ使用）cargo binstall cargo-mutants基本的な使い方# ミュータント一覧を確認（テストは実行しない）cargo mutants --list# ミューテーションテストを実行cargo mutants# 詳細出力で実行cargo mutants -v実行例実際にサンプルプロジェクトで実行した結果を示します。$ cargo mutants --list | head -20src/lib.rs:12:5: replace calculate_score -\u003e i32 with 0src/lib.rs:12:5: replace calculate_score -\u003e i32 with 1src/lib.rs:12:5: replace calculate_score -\u003e i32 with -1src/lib.rs:32:5: replace is_valid_email -\u003e bool with truesrc/lib.rs:32:5: replace is_valid_email -\u003e bool with falsesrc/lib.rs:37:5: replace format_greeting -\u003e String with String::new()src/lib.rs:37:5: replace format_greeting -\u003e String with \"xyzzy\".into()src/lib.rs:42:5: replace find_first_even -\u003e Option\u003ci32\u003e with Nonesrc/lib.rs:42:5: replace find_first_even -\u003e Option\u003ci32\u003e with Some(0)src/lib.rs:47:5: replace parse_positive_number -\u003e Result\u003cu32, String\u003e with Ok(0)src/lib.rs:57:5: replace get_even_numbers -\u003e Vec\u003ci32\u003e with vec![]...実行すると、各ミュータントに対してテストが実行され、結果が表示されます。$ cargo mutants -vFound 108 mutants to testok       Unmutated baseline in 1s build + 1s testcaught   src/lib.rs:12:5: replace calculate_score -\u003e i32 with 0 in 0s build + 0s testcaught   src/lib.rs:12:5: replace calculate_score -\u003e i32 with 1 in 0s build + 0s testMISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discount in 0s build + 1s test...108 mutants tested in 2m: 17 missed, 91 caught出力結果の読み方結果の4分類 結果          意味                                    アクション                  caught    テストがミュータントを検出した          良好。テストが機能している  missed    テストがミュータントを検出できなかった  テストの追加・強化が必要    unviable  ミュータントがコンパイルできなかった    無視してOK                  timeout   テストがタイムアウトした                無限ループの可能性あり     出力ディレクトリ（mutants.out/）実行後に生成されるmutants.out/ディレクトリには、詳細な結果が保存されます。mutants.out/├── caught.txt      # 検出されたミュータント一覧├── missed.txt      # 検出できなかったミュータント一覧├── timeout.txt     # タイムアウトしたミュータント├── unviable.txt    # コンパイル不可だったミュータント├── outcomes.json   # 全結果のJSON形式├── log/            # 各ミュータントの詳細ログ└── diff/           # 適用されたパッチミューテーションテストの仕組みミューテーションテストは1970年代に考案された手法ですが、計算コストの高さから長らく実用的ではありませんでした。近年のコンピュータ性能向上により、ようやく日常的に使えるようになってきました。cargo-mutantsの動作フローcargo-mutantsは以下の手順で動作します。ソースファイルの特定: プロジェクト構成を読み取り、テスト対象のファイルを見つけるコードの解析: synというライブラリ（Rustでは「クレート」と呼びます）を使って、コードの構造を解析するミュータントの生成: 「足し算を引き算に変える」「戻り値を0に変える」といった変更パターンを列挙するテストの実行: 各ミュータントに対してテストを実行し、検出できたかどうかを記録する具体例：検証していないテストコードカバレッジとミューテーションテストの違いを、具体例で見てみましょう。// 2つの数を足し算する関数fn add(a: i32, b: i32) -\u003e i32 {    a + b}// テストコード#[test]fn test_add() {    add(1, 2);  // 関数を呼んでいるだけ！結果を検証していない！}このテストはadd関数を実行しているので、コードカバレッジは100%です。しかし、戻り値が正しいかどうかを確認していません。add(1, 2)の結果が3であることを検証していないのです。正しいテストは以下のようになります。#[test]fn test_add_correct() {    let result = add(1, 2);    assert_eq!(result, 3);  // 結果が3であることを検証している}assert_eq!は「左辺と右辺が等しいことを確認する」という意味です。等しくなければテストは失敗します。cargo-mutantsは、最初の「検証していないテスト」の問題を発見できます。a + bをa - bに変更しても、最初のテストは成功してしまいます（結果を見ていないから）。これにより「このテストは意味がない」ということが明らかになります。戻り値の型別ミューテーションcargo-mutantsは、関数の戻り値の型に応じて異なるミューテーションを生成します。「型」とは何でしょうか。プログラミングにおいて、データには種類があります。「整数」「文字列」「真偽値（はい/いいえ）」などです。Rustはこの種類を厳密に区別する言語で、「この関数は整数を返す」「この関数は文字列を返す」といった宣言が必要です。cargo-mutantsは、この「返す型」に応じて、適切なミュータントを生成します。以下、Rustを知らない方にも理解できるよう、各型の意味と合わせて説明します。bool型（真偽値）bool型とは: true（真）かfalse（偽）のどちらかを表す型です。条件分岐の判定などに使われます。/// メールアドレスが有効かどうかを判定するfn is_valid_email(email: \u0026str) -\u003e bool {    email.contains('@') \u0026\u0026 email.contains('.')}生成されるミューテーション:replace is_valid_email -\u003e bool with true - 常にtrueを返すreplace is_valid_email -\u003e bool with false - 常にfalseを返すテストで検出すべきこと: 有効なメールと無効なメールの両方をテストして、両方のケースが正しく判定されることを確認する必要があります。i32型（符号付き整数）i32型とは: -2,147,483,648から2,147,483,647までの整数を表す型です。負の数も扱えます。/// スコアを計算する（1=合格、0=普通、-1=不合格）fn calculate_score(correct: u32, total: u32) -\u003e i32 {    let percentage = (correct * 100) / total;    if percentage \u003e= 80 { 1 }    else if percentage \u003e= 50 { 0 }    else { -1 }}生成されるミューテーション:replace calculate_score -\u003e i32 with 0 - 常に0を返すreplace calculate_score -\u003e i32 with 1 - 常に1を返すreplace calculate_score -\u003e i32 with -1 - 常に-1を返すテストで検出すべきこと: 各分岐（合格・普通・不合格）すべてのケースをテストする必要があります。String型（文字列）String型とは: 可変長のテキストデータを表す型です。ユーザー名やメッセージなどに使われます。/// 挨拶文を生成するfn format_greeting(name: \u0026str) -\u003e String {    format!(\"Hello, {}!\", name)}生成されるミューテーション:replace format_greeting -\u003e String with String::new() - 空文字列を返すreplace format_greeting -\u003e String with \"xyzzy\".into() - 固定文字列「xyzzy」を返す（「xyzzy」はテスト用のダミー文字列としてよく使われる伝統的な文字列です）テストで検出すべきこと: 戻り値の内容を検証することが重要です。単に「何か文字列が返ってくる」だけでなく、期待する内容かどうかを確認します。Option\\\u003cT\u003e型（値があるかないか）Option型とは: 値が「ある」か「ない」かを表す型です。Some(値)で値があることを、Noneで値がないことを表します。なぜこの表現を使うのか。多くの言語では「値がない」ことをnullで表しますが、null処理を忘れてエラーになることがよくあります。Rustでは「値がないかもしれない」ことを型で明示し、処理を強制します。これにより、nullに起因するバグを防ぎます。検索結果が見つからない場合などによく使われます。/// 最初の偶数を見つけるfn find_first_even(numbers: \u0026[i32]) -\u003e Option\u003ci32\u003e {    numbers.iter().find(|\u0026\u0026n| n % 2 == 0).copied()}生成されるミューテーション:replace find_first_even -\u003e Option\u003ci32\u003e with None - 常に「見つからない」を返すreplace find_first_even -\u003e Option\u003ci32\u003e with Some(0) - 常に「0が見つかった」を返すreplace find_first_even -\u003e Option\u003ci32\u003e with Some(1) - 常に「1が見つかった」を返すテストで検出すべきこと: 「見つかる場合」と「見つからない場合」の両方をテストし、見つかった場合は正しい値が返されていることを確認します。Result\\\u003cT, E\u003e型（成功か失敗か）Result型とは: 処理が「成功」したか「失敗」したかを表す型です。Ok(値)で成功を、Err(エラー)で失敗を表します。ファイル操作やネットワーク通信など、失敗する可能性のある処理に使われます。/// 正の数をパースするfn parse_positive_number(s: \u0026str) -\u003e Result\u003cu32, String\u003e {    let n: i32 = s.parse().map_err(|_| \"invalid number\".to_string())?;    if n \u003e 0 {        Ok(n as u32)    } else {        Err(\"number must be positive\".to_string())    }}生成されるミューテーション:replace parse_positive_number -\u003e Result\u003cu32, String\u003e with Ok(0) - 常に「成功（0）」を返すreplace parse_positive_number -\u003e Result\u003cu32, String\u003e with Ok(1) - 常に「成功（1）」を返すテストで検出すべきこと: 成功ケースと失敗ケースの両方をテストします。特にエラーハンドリングのテストを忘れがちなので注意が必要です。Vec\\\u003cT\u003e型（配列・リスト）Vec型とは: 同じ型の値を複数格納できる可変長の配列です。リストやコレクションを扱う場合に使われます。/// 偶数だけを抽出するfn get_even_numbers(numbers: \u0026[i32]) -\u003e Vec\u003ci32\u003e {    numbers.iter().filter(|\u0026\u0026n| n % 2 == 0).copied().collect()}生成されるミューテーション:replace get_even_numbers -\u003e Vec\u003ci32\u003e with vec![] - 空の配列を返すreplace get_even_numbers -\u003e Vec\u003ci32\u003e with vec![0] - 要素1つの配列を返すreplace get_even_numbers -\u003e Vec\u003ci32\u003e with vec![1] - 要素1つの配列を返すテストで検出すべきこと: 返される配列の要素数と内容の両方を検証します。空配列が返されるケースもテストすることが重要です。演算子のミューテーションcargo-mutantsは、演算子を別の演算子に置き換えるミューテーションも生成します。比較演算子== ↔ !=    等しい ↔ 等しくない\u003c  ↔ \u003e     小さい ↔ 大きい\u003c= ↔ \u003e=    以下 ↔ 以上論理演算子\u0026\u0026 ↔ ||    かつ ↔ または算術演算子+ ↔ - ↔ *    足し算 ↔ 引き算 ↔ 掛け算/ ↔ %        割り算 ↔ 余り単項演算子-a → a    符号反転を削除!a → a    論理否定を削除テスト不足の発見例実際にサンプルプロジェクトで検出された「missed」（テストで検出できなかったミュータント）を見てみましょう。MISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discountMISSED   src/lib.rs:156:9: delete match arm 2 in calculate_discountMISSED   src/lib.rs:155:20: replace - with + in calculate_discount...これは以下のコードに対するミューテーションです。fn calculate_discount(price: u32, member_level: u32) -\u003e u32 {    match member_level {        0 =\u003e price,                     // 割引なし        1 =\u003e price - (price / 10),     // 10% 割引        2 =\u003e price - (price / 5),      // 20% 割引        _ =\u003e price - (price / 4),      // 25% 割引    }}#[test]fn test_calculate_discount_weak() {    // member_level 0 のみテスト → 他のケースの変異を検出できない！    assert_eq!(calculate_discount(100, 0), 100);}テストがmember_level = 0のケースしかカバーしていないため、他のケース（1, 2, _）のミューテーションは検出できませんでした。これを修正するには、すべてのケースをテストする必要があります。#[test]fn test_calculate_discount_comprehensive() {    assert_eq!(calculate_discount(100, 0), 100);  // 割引なし    assert_eq!(calculate_discount(100, 1), 90);   // 10% 割引    assert_eq!(calculate_discount(100, 2), 80);   // 20% 割引    assert_eq!(calculate_discount(100, 3), 75);   // 25% 割引}設定とカスタマイズコマンドラインオプション# ファイル指定cargo mutants -f src/core.rs -f src/utils.rs# ファイル除外cargo mutants -e src/generated/*.rs# 正規表現でフィルタcargo mutants --re \"impl Serialize\" --exclude-re \"impl Debug\"# 並列実行（2-3から開始推奨）cargo mutants -j2# nextestを使用cargo mutants --test-tool=nextest# タイムアウト設定cargo mutants --timeout 300cargo mutants --timeout-multiplier 3設定ファイル（.cargo/mutants.toml）プロジェクト固有の設定を永続化できます。# .cargo/mutants.tomltest_tool = \"nextest\"jobs = 2timeout_multiplier = 3.0exclude_globs = [\"src/generated/*.rs\"]exclude_re = [\"impl Debug\", \"impl Display\"]additional_cargo_test_args = [\"--all-targets\"]関数単位の除外（#[mutants::skip]）特定の関数をミューテーション対象から除外できます。// Cargo.tomlに追加: mutants = \"0.0.3\"#[mutants::skip]  // この関数はミューテーション対象外fn should_stop() -\u003e bool {    true  // falseに変異するとハングする}自動除外される関数以下は自動的にミューテーション対象から除外されます。#[test]属性が付いた関数#[cfg(test)]内のコードnew関数とDefault実装CI/CDパイプラインへの統合GitHub Actions基本設定name: Mutation Testingon: [push, pull_request]jobs:  cargo-mutants:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: taiki-e/install-action@v2        with:          tool: cargo-mutants      - run: cargo mutants -vV --in-place      - uses: actions/upload-artifact@v4        if: always()        with:          name: mutants-out          path: mutants.outプルリクエストでの増分テスト変更されたコードのみをテストし、高速なフィードバックを実現します。- name: Generate diff  run: git diff origin/${{ github.base_ref }}.. | tee git.diff- run: cargo mutants --no-shuffle -vV --in-diff git.diffシャーディングによる分散実行大規模プロジェクトでは、複数のジョブに分割して並列実行できます。strategy:  matrix:    shard: [0, 1, 2, 3, 4, 5, 6, 7]steps:  - run: cargo mutants --shard ${{ matrix.shard }}/8 --baseline=skip --timeout 300パフォーマンス最適化ミューテーションテストは「ミュータント数 × テスト実行時間」のコストがかかります。100個のミュータントがあり、テストに1秒かかるなら、最低でも100秒かかる計算です。実際のプロジェクトでは数百〜数千のミュータントが生成されることもあり、実行時間が課題になります。テストスイートが1分以内のプロジェクトなら、数百ミュータントでも10-20分で完了します。CIで毎回実行するのは現実的でないので、増分テスト（--in-diff）で変更されたコードのみをテストし、フルテストを週次やリリース前に限定するのが実践的です。以下の最適化も効果的です。高速リンカーの使用「リンカー」とは、コンパイルされたコードを実行可能なプログラムにまとめるツールです。プログラムを作る最終段階で使われます。デフォルトのリンカーは汎用的ですが、高速化に特化したリンカーを使うとビルド時間を短縮できます。Moldリンカーで約20%の改善、Wildリンカーでは半分以下の時間になる場合もあります。専用Cargoプロファイル[profile.mutants]inherits = \"test\"debug = \"none\"並列実行の設定-j2から開始して、リソース監視しながら調整します。高すぎる値はメモリ枯渇の原因になります。RAMディスクの活用TMPDIR=/ram cargo mutants制限事項副作用のあるコードcargo-mutantsは機械生成された変更でコードをビルド・実行するため、ファイル操作や外部システムへ接続するテストでは予期しない動作を引き起こす可能性があります。フレーキーテスト「フレーキーテスト」とは、同じコードに対して実行するたびに結果が変わる不安定なテストのことです。たとえば、現在時刻に依存するテストや、外部サービスに依存するテストがこれに該当します。ミューテーションテストは「テストが失敗したか」を判定基準にするため、フレーキーテストがあると正確な結果が得られません。まずはcargo testで確実にパスする安定したテストスイートを用意してから実行してください。サポートされていないケース 制限事項            詳細                                       Cargo専用           Bazel等の他ビルドシステムは未対応          条件付きコンパイル  #[cfg(target_os = \"linux\")]を理解しない  マクロ生成コード    生成されたコードは変異対象外              等価ミュータントミューテーションテストには理論的な限界があります。それが「等価ミュータント」です。たとえば、x * 1をxに変えても動作は同じです。このミュータントは検出不可能ですが、missedとしてカウントされます。また、ログ出力やデバッグ用の関数を変更しても、テストが失敗しないのは正しい動作です。だから、missed率0%は現実的な目標ではない。80-90%の検出率で十分です。残りをコードレビューや手動テストで補完します。検出できないミュータントを#[mutants::skip]で除外すれば、ノイズを減らせます。まとめテストは通っていた。でも、何も守っていなかった。冒頭で触れた私の失敗は「テストが結果を検証していない」ことが原因でした。cargo-mutantsは、こうした「見せかけのテスト」を発見するツールです。あの経験がなければ、この記事を書くこともなかったでしょう。syu-m-5151.hatenablog.comミューテーションテストの価値コードカバレッジは「テストがコードを実行したか」を測りますが、「テストが正しく検証しているか」は測れません。ミューテーションテストは「テストをテストする」手法です。わざとコードを壊して、テストがそれを検出できるかを確認します。cargo-mutantsは、Rustのミューテーションテストを「誰でもすぐに試せる」ものにしたツールです。2コマンドで導入でき、ソースコードの変更は不要です。特に有効なユースケース高いコードカバレッジを達成した後の「テストは本当に機能しているか」確認CI（継続的インテグレーション）でのプルリクエストごとの増分ミューテーションテスト重要なビジネスロジックのテストギャップ発見導入のポイントcargo mutants --listでミュータント数を確認--shard 1/100で試験実行（大規模プロジェクトでは一部だけ先に試す）#[mutants::skip]と設定ファイルで偽陽性を減らすMoldリンカーと専用プロファイルでパフォーマンス最適化他の言語でのミューテーションテストこの記事ではRust用のcargo-mutantsを紹介しましたが、ミューテーションテストの考え方は言語を問わず有効です。他の言語にも同様のツールがあります。JavaScript/TypeScript: StrykerJava: PITestPython: mutmut, cosmic-rayGo: go-mutestingテストの品質を高めたいと考えている方は、ぜひお使いの言語のツールも調べてみてください。テストは通っている。でも、本当に守っているのか。ミューテーションテストは万能ではない。実行時間もかかるし、等価ミュータントの問題もある。それでも、「テストを書いた」という自己満足に気づかせてくれる。私があの日気づいたように。その問いを持ち続けることが、テストを意味のあるものにする第一歩だと思う。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazonソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社AmazonAIとソフトウェアテスト　信頼できるシステムを構築するために作者:Adam Leon Smith,Rex Black,James Harold Davenport,Joanna Olszewska,Jeremias Rößler,Jonathon WrightインプレスAmazon","isoDate":"2026-01-01T23:37:35.000Z","dateMiliSeconds":1767310655000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年 個人的に心に残ったグラビアアイドル10選","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147","contentSnippet":"はじめに2025年12月31日の夜、パソコンの前でこの文章を書き始めている。Xのフォロワーが1万人を超えたとき、勢いで「おすすめのグラビアを紹介します」と言ってしまった。忙しさを言い訳にして先延ばしにしていたら、年末年始になってしまった。孤独な独身男性が大晦日に書くブログがこれでいいのか。言ってしまったからには書くしかない。普段は技術ブログを書いている。ソフトウェアエンジニアとして、コードの話や設計の話をするのが本分だ。私はグラビア評論家でもなければ、業界関係者でもない。あるのは、彼女たちの作品を見て感じた個人的な感想だけだ。素人の与太話である。合わない人はブラウザバックしてもらって構わない。2025年、生成AIが生成する画像のクオリティは日に日に上がった。「人間である必要があるのか」という問いが、あらゆる領域に突きつけられている。ソフトウェアエンジニアである私も、その問いと無縁ではいられない。AIがコードを書く。AIが画像を生成する。じゃあ私たちは何をすればいいのか。答えは出ていない。そんな中で、彼女たちは諦めていなかった。生成AIには「物語」がない。挫折も、転機も、覚悟もない。彼女たちには、積み重ねてきた時間と、これから歩む道がある。同志のようなものを感じた。この記事では、そうした「代替不可能な物語」を持つ10名を紹介したい。選考基準は単純だ。心に残ったかどうか。それだけである。紹介順に優劣はない。10名のグラビアアイドル紹介菊地姫奈彼女の眼差しには、刃物のような意志と、硝子細工のような脆さが同居している。その矛盾こそが、菊地姫奈という存在を比類なきものにしている。写真集『memory』は「5年間の集大成」と銘打たれた。五年という歳月を、彼女は一冊の書物に封じ込めた。いま彼女は、女優という新たな領域へと歩を進めている。グラビアで培った肉体の言語が、演技という別の器に注がれようとしている。「集大成」とは、すなわち終焉の美学である。散り際を知る者だけが、満開の美しさを手にする。2025年、私はその花吹雪を目撃した。豊島心桜「グラビア界最強のラスボス」。この異名を耳にしたとき、私は失笑した。誇大な修辞だと高を括った。しかし彼女のグラビアを一瞥した瞬間、その異名が寸分の誇張も含まぬことを悟った。遅れて現れた者には、待たせた分だけの凄みがある。クラシックバレエで鍛えられた四肢は、舞台を離れてなお優雅な弧を描く。その肉体には規律が宿っている。女優としての道も拓きつつある彼女は、どの領域においても王者の風格を崩さぬだろう。ラスボスとは、最後に立ちはだかる者のことだ。私などは、まだその城門にすら辿り着いていない。麻倉瑞季麻倉瑞季において、知性と肉体は対立せず、むしろ共犯関係にある。豊満な曲線を誇示したかと思えば、次の瞬間には電子の戦場で剣を振るう。大学への合格、eスポーツチームへの加入。彼女はグラビアアイドルという一つの器に収まることを拒んだ。「推しのために仕事をしている」と彼女は言う。その言葉には一片の虚飾もない。欲望に忠実であることは、ときに最も誠実な生き方となる。天羽希純天羽希純との邂逅は、アイドルグループ「#2i2」を通じてであった。しかし彼女のソログラビアを目にしたとき、アイドルという名の檻では、この獣を囲い込めぬことを知った。彼女は自らを「モンスター」と称する。「アイドル界のモンスター」なるエッセイを連載し、2025年の目標を「エゴイスティックに」と宣言した。怪物とは、既存の秩序に収まらぬ者のことだ。その自覚こそが、彼女の覚悟である。「#2i2」は2025年12月に解散した。終焉へと向かう船上で、彼女はなお踊り続けた。滅びゆくものだけが放つ光がある。私はその残照に灼かれた。一ノ瀬瑠菜2007年生まれ。この事実を知ったとき、私は時の流れの残酷さを思い知った。2025年春、高校を卒業した彼女は、グラビア誌の表紙を次々と征服した。女優としての活動も始まっている。十八歳にしてこの疾走。若さとは、無限の可能性という名の空白である。まだ何者でもない。ゆえに何者にもなれる。その特権を、彼女は惜しげもなく行使している。翻って私は、何者かになれたのだろうか。その問いに答える勇気を、私はまだ持たない。溝端葵「グラビア界の超新星」。2025年、この称号を戴くに最もふさわしき者が溝端葵であった。TikTokでの舞踊が衆目を集め、スカウトの手が伸びた。2025年3月にグラビアの世界へ足を踏み入れ、わずか三ヶ月で表紙を飾るという離れ業を演じた。彗星の如き上昇である。しかし彼女には前史がある。中学三年時、「ミスセブンティーン」の最終選考に残りながら、栄冠を逃した。約十年の歳月を経て、彼女は別の扉を開いた。一度は閉ざされた道の傍らに、もう一つの道が拓けていた。迂回こそが、ときに最短距離となる。そのような物語に、私は抗えない。七瀬なな七瀬ななという存在には、終焉と黎明が同時に宿っている。レースクイーンとして頂点を極めた彼女は、2024年末にその王座を捨てた。そして2025年、女優という未踏の地へと歩み出した。デジタル写真集のタイトルは「HORIZON」。地平線とは、見えているのに決して辿り着けぬ場所のことだ。しかし彼女は、その不可能に向かって歩を進める。幼少期に習得した器械体操を武器に、アクション女優を志すという。一つの頂を極めた者だけが、別の頂への渇望を知る。終わらせる勇気を持つ者だけが、始める資格を得る。花雨「一般OL/趣味グラビア」。花雨のInstagramにはそう記されている。本業は会社員。グラビアは余技に過ぎぬ。しかしその余技に、十三万を超える眼差しが注がれている。趣味という言葉で片付けるには、あまりに多くの魂を捕らえている。彼女は自らの手で写真集を世に送り出す。五島列島の福江島で撮影された「夕星」、沖縄で撮影された「漣」。「花雨屋」なる店舗で販売されるこれらは、いかなる事務所の介在も経ぬ、純粋なる自己表現である。事務所に属さず、テレビに出ず、雑誌の表紙を飾らず。それでも彼女の作品は確かに人心を揺さぶる。職業と趣味の境界を、彼女は軽やかに踏み越える。好きだから撮る。撮りたいから撮る。その純粋さこそが、逆説的に彼女の武器となる。仕事にせぬから続けられる。仕事にしたら続けられぬ。私にも覚えがある。技術ブログを書き続けているのも、誰に頼まれたわけでもない。髙峰じゅり髙峰じゅりは、己がレズビアンであることを公言している。「十六歳で彼女を紹介したら、祖母が泣いた」と語る彼女の言葉には、幾重もの障壁を越えてきた者だけが持つ静かな強さがある。2025年、芸名を改め、新たな幕を開けた。友人と共に撮影会を興し、運営者としての貌も見せる。「グラビアは男性にしか届かぬものと思い込んでいた」と彼女は述懐する。しかし現実には、女性からの声も多く届くという。グラビアの受け手を限定せず、性を隠さず、己を偽らず。その姿勢が、従来の境界の外にいた者たちにも届いている。道を拓く者がいるから、後に続く者が歩みやすくなる。先駆者とは、常に孤独な存在である。もものすけもものすけという存在は、どこか神話的な響きを帯びている。彼女は自他ともに認める恐竜狂である。「ダイナソー」と「アイドル」を掛け合わせ「ダイナドル」の異名を持つ。グラビア、アイドル、声優。彼女の軌跡は複数の線が並走し、交錯し、ときに融合する。いずれが本業でいずれが余技か、そのような問い自体が無粋である。好むものを好むがままに追求した結果、幾つもの貌を持つに至った。2025年も彼女は止まることを知らなかった。太古の巨獣への愛を語り、信奉者と交わり、新たな地平を切り拓き続けている。「もも」が姓で「のすけ」が名であると、本人は主張している。私も「nw」が姓で「iizo」が名だ。そのような戯れを愛する心性において、私は彼女に親近を覚える。おわりに10名の物語を書き終えて、ふと思う。私は何を見ていたのだろうか。時計を見ると12時を超えていた。1月1日に何を書いているのだろう。グラビアアイドルほど自分の器とシビアに向き合っている存在はいない。年齢、体型、表現力、時代との相性。あらゆる要素が容赦なく評価される世界で、彼女たちは走り続けている。女優になりたい人がいる。声優になりたい人がいる。まだ何になりたいか決まっていない人もいる。グラビアは通過点であり、同時に今この瞬間でもある。完成された何かより、途中経過を見る方が心が動く。たぶん、私もまだ途中だからだ。生成AIがいくら精巧な画像を生成しても、そこに物語はない。挫折も、葛藤も、成長もない。彼女たちが持っているのは、代替不可能な身体と、積み重ねてきた時間と、これから歩む道だ。私も同じだ。AIがコードを書く。私もコードを書く。違いは何か。まだわからない。でも、諦めずに問い続ける人たちを見ていると、自分も諦めなくていいと思える。冒頭で「フォロワー1万人を超えた勢いで言ってしまった」と書いた。結局、年末年始に孤独な独身男性がパソコンに向かって書いている。遅れたけど、約束は守った。彼女たちにも物語があるように、私にも物語がある。技術ブログを書き、コードを書き、たまにグラビアの話をする。そういう人間として見届けてくれる人がいる。心に残ったものを素直に書いた。それでいい。2026年、彼女たちの物語は続く。私の物語も、まだ終わっていない。関連する投稿も置いておく。グラビア写真集といえば単なる視覚的刺激として消費されがちだが、そこには各グラドルの努力や作品性、女優やタレントなどを目指しながら頑張る物語、時代ごとの表現の歴史がある。こうした背景や文脈を知るとより深く面白くなる。そんな作品性と物語性を兼ね備えた魅力的な写真集4冊を紹介します。— nwiizo (@nwiizo) 2025年11月12日","isoDate":"2025-12-31T17:21:47.000Z","dateMiliSeconds":1767201707000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年、nwiizoが作ったソフトウェア","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623","contentSnippet":"はじめに2025年が終わろうとしている。先日、「なぜ『何でも作れる時代』に私は作れないのか」という記事を書いた。「代表作」がないという焦り、量をやることの重要性、そして引き算の必要性。書きながら、自分の弱さと向き合った。syu-m-5151.hatenablog.comあの記事で「2026年は20個作る」と宣言した。その前に、2025年に何を作ったのか振り返っておきたい。振り返ると、この1年は「自分が欲しいもの」をひたすら作り続けた年だった。誰かに頼まれたわけでもなく、バズを狙ったわけでもなく、ただ「これがあったら便利なのに」という衝動に従って、キーボードを叩き続けた。「3回同じ不便を感じたら作る」というルールを自分に課している。cctxは3回目の設定ファイル書き換えで、cargo-autoddは3回目のCargo.toml編集で生まれた。前回の記事で書いた「隙間家具」を、実際に作っていた1年だった。11個のリポジトリを公開し、合計900以上のスターをいただいた。正直に言えば、通知が来るたびに見てしまう。でも、スターが多くても使われないツールはある。逆に、スター10でも毎日使っているツールがある。自分にとっての成功の定義を「毎日使うか」に変えてから、気持ちが楽になった。Claude Codeと過ごした1年2025年は、Claude Codeと共に過ごした年だった、と言っても過言ではない。cctxClaude Codeを使い込むうちに、設定を切り替えたくなる場面が増えた。仕事では制限をかけたい、個人プロジェクトでは自由にやりたい。kubectxを使ったことがある人なら分かるだろうが、あの「サクッと切り替える」感覚が欲しかった。だからcctxを作った。cctx work と打つだけで、仕事モードに切り替わる。cctx - で前のコンテキストに戻る。それだけのツールだが、毎日使っている。毎日使うから、これは成功だ。github.comclaudelyticsClaude Codeをどれくらい使っているのか、可視化したくなった。トークン消費量、コスト、セッションごとの使用パターン。数字で見えると、自分の開発スタイルが見えてくる。TUIを作り込んで、眺めているだけで楽しいものにした。作っていて気づいたことがある。「正確なデータ」より「見たくなるUI」の方が継続利用に繋がる。最初はCSVエクスポートに注力したが、結局TUIの見た目を磨いた時間の方が長かった。github.comccatCLAUDE.mdというファイルが増えてくると、管理が面倒になる。どこに何を書いたか分からなくなる。インポートチェーンが複雑になる。だから分析ツールを作った。地味だけど、自分には必要だった。github.comccswarmこれは少し野心的なプロジェクトだった。複数のAIエージェントを協調させて、大きなタスクを分割して処理する。Git worktreeで並列開発を実現する。「Sangha」という仏教にインスパイアされた民主的意思決定システムを入れたのは、ちょっとした遊び心だ。正直、まだ実験段階で、自分でも使いこなせていない。でも「AIエージェントの協調」という方向性は間違っていないと思っている。来年、もう少し実用的なものにしたい。github.comRustへの愛なぜRustを選ぶのか。理由はシンプルで、ただ好きだからだ。でも「好き」の中身を分解すると、いくつかの要素がある。まず、型システムがAIと相性が良い。Claude Codeにコードを書かせると、Pythonでは「動くけど大丈夫？」という不安が残る。Rustでは、コンパイラが通ればほぼ安全だという確信がある。AIが生成したコードでも、コンパイラが厳しくチェックしてくれる。この安心感は大きい。そして、丁寧なエラーメッセージ。Rustのコンパイラは「ここが間違っている」だけでなく「こうすれば直る」まで教えてくれる。学習を助けてくれる先生のような存在だ。使うほど信頼が増す。所有権や型システムの「難しさ」は、将来の保守性を高めるための設計だと理解している。大規模・長期運用での事故を防ぐための仕組み。楽ではないが「裏切らない」という安心感がある。だから何度でも選ぶ。cargo-autoddRustを書いていると、Cargo.tomlの依存関係管理が面倒になることがある。ソースコードにuse serde_jsonと書いたら、自動で依存関係に追加してほしい。逆に、使わなくなったcrateは消してほしい。そんな怠惰な願望から生まれたツール。作っていて学んだことがある。ASTパーサーを書いていた。「完璧に解析する」より「80%の精度で10倍速い」方がユーザー体験は良い。完璧主義がUXを損なう好例だった。github.comcargo-couplingVlad Khononovの「Balancing Coupling in Software Design」を読んで感銘を受けた。結合度と凝集度のバランス、距離と変更頻度の関係。これをRustプロジェクトで可視化したら面白いんじゃないか。そう思って作り始めたら、想像以上に深い世界が広がっていた。Web UIを付けて、グラフを眺められるようにした。自分のコードを分析した。予想以上に結合度が高いモジュールを発見した。「ここ、分割した方がいいな」と気づけたのは収穫だった。ツールを作ることで、自分のコードの問題が見えてくる。github.comcargo.nvimNeovimでRustを書いている。:CargoBuildと打つだけでビルドが走り、フローティングウィンドウに結果が表示される。エディタから手を離さずに開発サイクルを回せる。些細なことだけど、この積み重ねが開発体験を変える。github.comTerraformとの格闘インフラをコードで管理するのは素晴らしい。でも、時にはTerraformと格闘することもある。tfmcpAIにインフラを任せるのは危険か。答えは「条件による」だ。tfmcpで設けた制限は3つ。本番環境は読み取り専用。全操作の監査ログを記録。destructiveな変更は人間の承認必須。この制限下なら、AIはterraform planを高速で回す優秀なアシスタントだ。危険なのは「AIに任せること」ではなく、「制限なく任せること」だ。この区別が重要だと、作りながら実感した。github.comtfocusTerraformのリソースターゲティングは麻薬だ。一度使うと「今回も大丈夫」と手が伸びる。状態の不整合が蓄積し、ある日terraform applyが破滅的な差分を出す。それでもtfocusを作ったのは、消防士にも斧が必要なように、障害対応には「禁じ手」が要るからだ。peco風のインタラクティブUIを付けて、素早くリソースを選択できるようにした。READMEに「緊急用ツール」と明記した。日常使いした瞬間、このツールは害になる。github.com開発者のための小さな道具たちvibe-ticketチケット管理システムは世の中に溢れている。Jira、Linear、GitHub Issues。でも、ターミナルで完結する、Git worktreeと統合された、開発者のためのチケット管理が欲しかった。MCPサーバーとしても動くようにした。AIアシスタントに「さっき見つけたバグのチケット作って」と言えば、作ってくれる。github.cominstrument-rsオブザーバビリティは大切だ。でも、どこにトレースを入れるべきか、どこにログを仕込むべきか、判断が難しい。コードを静的解析して、「ここに入れるといいよ」と教えてくれるツールがあれば便利だと思った。HTTPエンドポイントから実行パスをトレースして、クリティカルパスを特定する。まだ実験的なプロジェクトだけど、可能性を感じている。github.com失敗と学び11個公開したが、実は3個はアーカイブした。最初に作ったツールは設計が甘く、2週間で書き直した。公開して反応ゼロだったものもある。前回の記事で「捨てやすく作る」と書いた。アーカイブした3個は、まさにそれを実践した結果だ。状況が変わって不要になったもの、設計を間違えたもの。捨てることに罪悪感はない。役目を終えただけだ。ヒットの予測は難しい。「これは絶対使われる」と思ったものがスター20で止まり、「まあ自分用だし」と思ったcctxが一番使われている。予測できないなら、作りたいものを作るしかない。前回の記事で「量をやることで、初めて見えてくるものがある」と書いた。11個作って、ようやくその意味が分かってきた。最後にccswarmを公開して3日後、見知らぬ人からIssueが来た。「この機能を追加してほしい」と。実装して返信したら「ありがとう」と返ってきた。それだけのやり取りだったが、不思議と孤独じゃなくなった。顔も知らない人と、コードで繋がる感覚。SNSのいいねとは違う何かがあった。前回の記事で「代表作がない」と書いた。11個作っても、まだ「これだ」とは言えない。でも、前より近づいている気がする。2025年の11個は、2026年の20個への助走だ。すべてのプロジェクトはMITライセンスで公開している。もしあなたが「こんなツールがあれば」と思っているなら、まず作ってみてほしい。完璧じゃなくていい。私のツールも初版はバグだらけだった。READMEを書いて、v0.1.0をリリースする。それだけで世界が変わる。使ってくれる人がいるかもしれない。いなくても、自分が使えばいい。2025年、ありがとう。2026年は、もっと狂う。","isoDate":"2025-12-31T14:26:23.000Z","dateMiliSeconds":1767191183000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324","contentSnippet":"はじめに誰もまとめてくれないので自分でまとめます。こんなに悲しいことはありません。2025年11月から12月にかけて、「おい、〜」というシリーズでブログを15本書きました。登壇もしました。合計16本です。誰かがまとめ記事を書いてくれるかなと思っていました。待っていました。誰も書いてくれませんでした。年末です。仕方がないので自分で書きます。シリーズの始まり今年の8月、本を書かないかという話が来ました。嬉しかったです。企画を練りました。構成を考えました。8月、9月、10月といろいろやり取りをしていたのですが、いろんな諸事情で立ち消えになりました。悔しかったです。本を出せなかったことが悔しかったのではない。結局何にもならなかった自分が悔しかった。もっと準備できたはずだ。もっと詰められたはずだ。その後悔が残りました。でも、本の企画のために書いた下書き原稿が8本くらいありました。本にならないなら、ブログに書けばいい。そう思って始めたのが「おい、〜」シリーズです。30歳になったこともきっかけでした。5月に「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」というとても長いブログを書きました。20代が終わることへの焦り、不安、でも少しの期待。そのときに声かけていただいたのが、「おい、〜」シリーズとして出てきたものです。syu-m-5151.hatenablog.com20代の頃は「なんでもできる」と思っていました。30代になって、「できない」を認められるようになった。それは諦めではなく、等身大の自分を見つめられるようになったということです。15本を通して書いていたのは、結局そのことだったのかもしれません。「おい、部屋を掃除しろ」から始まりました。下書きを消化したあとも、言いたいことが止まらなくなりました。無限に書いても良くないので、週に1回のペースに決めました。自分を律するために「おい、週一で書け」とは書きませんでした。結果、15本になりました。15本の記事は、3つのカテゴリに分かれます。まず生活の基盤を整え、次に思考を鍛え、最後にその思考で仕事や人間関係に臨む。この順番で読む必要はありませんが、私の中ではこの流れがありました。生活習慣編おい、部屋を掃除しろ掃除の話ではありません。自分を大切に扱う習慣の話です。部屋が汚い人間に、コードをきれいに書けるわけがない。因果関係なんてないし、汚い部屋の凄腕エンジニアなんていくらでもいる。でも、知っている人はみんな適当な時期に結婚などしてなんとかなったか、心か身体を壊して生活を改めたか、消えていった。因果はわからないが、意味のわからない経験則としてある。毎日5分の掃除から始める規律の美学について書きました。syu-m-5151.hatenablog.comおい、一つずつやれSlack、メール、GitHub、全部同時に見ていると「忙しいのに何も終わらない」状態になります。これはおそらく忙しいのではなく、大量のタスク切り替えに対してコストを払っているだけです。仕事ができる人のイメージは、勝手に「マルチタスクができる人間」だと思っていました。しかし自分にその力はどうやらなさそうで、実際できていませんでした。ただ能力の限界まで「中途半端を量産する人間」でした。1日25分、1つのことだけに集中することから始めました。タスク切り替えの過払い金を整理した、という表現が正しいかもしれません。syu-m-5151.hatenablog.comおい、スマホを置け技術書が読めない。集中力が続かない。意志が弱いのだと思っていました。違いました。スマホに最適化された脳でした。私たちの世代は高校生の頃からスマホに触れてきた。15秒ごとに報酬をくれるアプリに慣れた脳が、30分かけて一つの概念を理解する作業に耐えられるわけがない。これは人生が壊れるな、という実感がありました。自分より下の世代は、もっと大変だろうなと思いました。syu-m-5151.hatenablog.comおい、本を読め「本を読まない人は生き残れない」という強迫的なメッセージへの違和感があります。いつから読書は「生き残るための手段」になったのか。効率的に知識を得るための読書は続かない。義務感で読む本は頭に入らない。ただ楽しいから読む。それだけでいい。そういう価値観もあるのだと、知ってもらえたらと思っていました。私は今も、子供の頃に初めて図鑑を開いたときと同じ気持ちで本を読んでいます。正直、楽しければなんでもいいと思っています。読者やフォロワーが楽しんで、結果として生き残ってくれれば、それでいい。syu-m-5151.hatenablog.comおい、休め休んでいるのに休めていない、という問題があります。ソファで横になってスマホを見ている。一見すると堕落の象徴のようでもあり、休息のようでもある。しかし残念ながら、これは休息ではありません。低負荷の作業です。脳は休んでいない。判断を続けている。スクロールするかどうか。この動画を見るかどうか。このツイートに反応するかどうか。AI時代は判断を求められる機会が増える一方です。現代では意識的に「何もしない」時間を作らないと、脳が壊れます。「じゃあお前はブログを書き続けて休んでないじゃないか」という指摘があると思いますが、その鋭い刃は収めていただけると助かります。syu-m-5151.hatenablog.com思考法編おい、冷笑すんなインターネットと冷笑は、相性が良すぎます。140字で専門家を論破した気になれる。何年も積み上げてきた人の仕事を、背景も知らずに「それ、意味あるんですか」と切り捨てられる。「専門性なんて要らない」「結局ポジショントークでしょ」——そんな言葉が、何も作ったことのない人から発せられている。私自身、視野を広げすぎて世界の複雑さに圧倒され、冷笑主義に陥った経験があります。何を見ても「まあ、そうなるよね」「どうせ変わらないよ」と思うようになっていた。達観した気になっていた。賢くなった気がしていた。違った。何も生み出さない人間になっていただけでした。冷笑は「どうせ無理」で終わる。批判は「ここがダメ」で終わる。批評は「ここがダメだから、こうすればいい」まで踏み込む。私は冷笑で止まっていた。一番楽で、一番何も残らない場所に。若い頃に冷笑してきたものが、今になって本当に大切だとわかる。それが少し悔しい。syu-m-5151.hatenablog.comおい、内省しろ内省と反省は違います。反省は「悪かった、次は気をつけます」で終わる。そして同じミスを繰り返す。私がそうでした。何度も反省した。何度も同じ失敗をした。反省とは、過去に頭を下げる行為でしかなかった。内省は違う。「なぜそうなったのか」を掘り下げて、構造を理解し、仕組みごと変えるプロセスです。自分を責めるのではなく、自分を観察する。毎日30秒でいい。寝る前に「今日、なぜあの判断をしたのか」を考える。それだけで少しずつ変わります。syu-m-5151.hatenablog.comおい、言語化しろ2025年、言語化神話が爆誕しました。「言語化できれば理解できる」「言語化できないのは思考が浅い証拠」——そんな空気が広がっている。確かに、言葉にできない領域があまりに広い人にとっては、その神を信じることで救われることもあります。言葉にする努力が思考を前に進めることもある。しかし、普通の大人には言語化できないものがあります。「なんとなくこっちの方がいい」という直感。説明できないけど手が動く技術。身体に染み込んだ知識、実践の中で培われた勘、創造的な跳躍、感情ヒューリスティック。これらを全部言葉にしようとすると、かえって嘘になる。言葉にした瞬間、丸められる。削られる。本当はもっと複雑で、矛盾していて、揺らいでいるものが、きれいに整理された途端に別物になる。「完璧に言語化できた」と思ったら、何か大事なものを落としている証拠かもしれない。不完全な変換でいい。「まだ言葉にできない何か」を抱えている感覚こそが、次の成長を生みます。syu-m-5151.hatenablog.comおい、つなげろ問題解決には「つなげること」と「断つこと」の両面があります。知識と知識をつなげて解決策を見つける。異なる領域の経験を結びつけて、新しい発想を得る。しかし、間違ったつながりを断つ勇気も必要です。「前もこうだったから」という過去の成功体験が、今回の失敗を招くことがある。AIに聞けば答えは出る。でも、自分でつなげる経験をしないと、応用が効かない。なぜその答えに至ったのか、プロセスが身につかない。「AIが教えてくれた答え」と「自分で見つけた答え」は、同じ答えでも身につき方が違う。苦労して見つけた答えは、次の問題を解く足場になる。与えられた答えは、その場で消える。syu-m-5151.hatenablog.comおい、類推するな所有権を「本の貸し借り」に例えて理解しました。わかった気になりました。腹落ちした感覚すらあった。しかし実際にコードを書いたら、例えが成立しない場面だらけでした。本は返却されても同じ本だが、所有権はそうではない。そういう経験は意識的にも無意識的にもやってしまうと思います。類推は便利ですが危険です。複雑なものを飲み込みやすくする代わりに、本質からズレた理解を植えつける。入り口としては使える。でも、判断するときは具体に戻る。「本の貸し借りだから...」ではなく「Rustの所有権のルールでは...」で考える。例え話で納得したら、そこで立ち止まって、例えを捨てる勇気を持つ。syu-m-5151.hatenablog.com仕事・対人編おい、対話しろ会議で「話しているが対話していない」場面があります。みんな口だけは喋っている。でも誰も聞いていない。相手の発言が終わるのを待っているだけ。その間に自分の意見を頭の中で整理している。相手の言葉を受けて考えを変える気がない。これは対話ではない。順番にモノローグを発表しているだけです。対話の本質は、相互の世界観を認識し、理解を深めるプロセスにある。相手の言葉を聞いて、自分の考えが変わる余地を残す。論破ではなく理解を目指す。勝ち負けではない。「なるほど、そういう見方もあるのか」が対話の成果です。syu-m-5151.hatenablog.comおい、がんばるな「頑張ること自体が目的化していた」という反省があります。遅くまで残って、休日も働いて、「頑張っている自分」に酔っていた。忙しさを充実感と錯覚していた。成果は出ていなかった。いや、正確には見ていなかった。過程に満足して、結果を直視していなかった。環境とのミスマッチを認識し、持続可能なペースに切り替えたら、むしろ成果が出るようになった。頑張りを減らしたのに成果が増える。皮肉だが、これが現実だった。公開した翌日、「いや、待てよ」と思いました。syu-m-5151.hatenablog.comおい、努力しろ前日の「がんばるな」への自己反論です。24時間で意見が変わりました。というわけではないです。読者は混乱したと思います。「頑張らなくていい」という言葉が、怠惰の免罪符として使われる危険性に気づいた。「無理しなくていい」が「やらなくていい」にすり替わる瞬間がある。量をこなさないと見えない景色がある。苦しみを乗り越えた経験がないと、乗り越え方がわからない。限界を知るには、一度限界まで行く必要がある。矛盾しているように見えますが、矛盾していません。両方本当です。「頑張りすぎるな」と「頑張らないと見えないものがある」は、同時に成り立つ。問題は、今の自分がどちら側にいるかを見極めることです。syu-m-5151.hatenablog.comおい、戦略を語れ「戦略」という言葉が形骸化しています。「戦略的に進めましょう」と言う人に「具体的にどういう戦略ですか」と聞くと、答えられないことが多い。「戦略」が「なんとなく賢そうな進め方」の意味になっている。戦略の本質は「何をやらないかの選択」です。全部やるのは戦略ではない。総花的にリソースを配分するのは、戦略がないことの証明です。限られた時間とエネルギーを、どこに集中させるか。何を意図的に捨てるか。エンジニアも「これは作らない」と言える立場になるべきです。「作れるけど作らない」という判断ができることが、本当の技術力かもしれません。syu-m-5151.hatenablog.comおい、論理で人が動くと思ってるのか論理的に正しい提案でも通らないことがあります。データを揃えた。根拠を示した。反論の余地がないほど完璧な提案書を作った。却下されました。なぜか。人は論理だけでは動かない。正しさだけでは、心が動かない。「このシステムは非効率です」より「先月、この非効率のせいで3時間残業しました」の方が通る。数字より、1人の体験談。グラフより、具体的な苦労話。人は物語で納得し、論理で自分を正当化する。だから、まず物語で心を動かし、その後で論理を添える。順番が逆だった。完璧な論理を用意する前に、「誰の、どんな困りごとを解決するのか」を語るべきでした。syu-m-5151.hatenablog.com登壇12月5日、Forkwell Communityで「おい、テックブログを書け」という登壇をしました。元々文章が苦手でした。今も苦手です。それでも書き続けたら、登壇を頼まれるようになりました。苦手なまま登壇しています。緊張で声が震えます。けれど登壇しています。出発点の低さは到達点を決めない。苦手なまま続けて消えていった人も山ほど見てきた。違いは何か。苦手なことを自覚した上で、苦手なまま出す覚悟をした。完璧を目指していたら続かなかった。syu-m-5151.hatenablog.com何を言いたかったのか15本を書いていて気づいたことがあります。それぞれの記事がつながっていく感覚がありました。「スマホを置け」と「休め」、「内省しろ」と「言語化しろ」。しかし同時に、全く反対のことも言っている。「がんばるな」の翌日に「努力しろ」。一貫性がない。でも、そういうものだと思っています。「おい、〜」シリーズは、飲み屋で語りたいことを適当に語っているような記事です。整合性を気にしていたら書けなかった。完璧を目指してたら書けなかった。矛盾だらけの15本ですが、振り返ると1つだけ共通点がありました。どの記事も「手段が目的化していないか」を問うていた気もする。掃除も、読書も、努力も、論理も、すべて何かのための手段です。その「何か」を見失っていた。効率と最適化に追われて、「なぜそれをやるのか」という問いを忘れていた。タスクをこなすことが目的になり、タスクの先にある価値を見失っていた。15本を通して言いたかったのは、そのことです。スマホで時間を潰すな。マルチタスクで忙しいふりをするな。冷笑で賢いふりをするな。論理だけで人を動かそうとするな。がんばることを目的にするな。でも努力から逃げるな。矛盾だらけです。人間は矛盾しています。それでいいと思っています。おわりに本の企画が立ち消えになったとき、正直落ち込みました。でも結果的に、ブログという形で書きたいことを全部書けた。本になっていたら、編集者に「矛盾してます」と言われて、どちらかを削っていたと思います。ブログでよかった。15本も書いて、誰も読んでいないかもしれません。誰もまとめてくれなかったということは、そういうことなのでしょう。あるいは、みんな忙しいだけかもしれない。そう思うことにしています。それでも書きました。自分のために書きました。30歳の自分から、40歳の自分への手紙です。「おい、お前、ちゃんとやってるか」10年後に読み返して、恥ずかしくなるかもしれません。「やっぱり正しかった」と思うかもしれません。どちらでもいい。でも、同じことを書いていたら。同じ悩みを抱えていたら。40歳の自分がこれを読んで、何も変わっていなかったら。それが一番怖い。来年も書きます。誰かがまとめてくれることを期待しています。でも、たぶんまた自分でまとめることになる。飽きたらやめます。だから普通に褒めてください。人に勧めてください。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-29T23:33:24.000Z","dateMiliSeconds":1767051204000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、論理で人が動くと思ってるのか","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746","contentSnippet":"はじめに数年前の、ある金曜日の夜のことだ。会議は完全な失敗に終わった。会議室を出て、エレベーターのボタンを押しながら、私はこの文章を書こうと決めた。書き上げるまでにずいぶん時間がかかってしまったので、当時の思いとは少し違っているかもしれない。あの会議で「論理的に正しいことを言ったのか」と問われれば、言った。間違いなく言った。データも揃えた。根拠も示した。反論の余地がないほど、正しいことを言ったはずだった。だが、誰も動かなかった。私の発言が終わった瞬間、会議室の空気は凍りついた。誰も何も言わない。居心地の悪い沈黙が流れ、やがて別の話題へと移っていった。正しいことを言ったはずなのに、私は敗北感を覚えた。当時、私はシニアエンジニアになったばかりだった。部下はいない。それでも「組織全体の技術選定に責任を持て」と言われる。命令する権限はない。しかし説得しなければならない。予算を握っているわけでもない。それでもチームを動かさなければならない。これを読んでいる人の中にも、同じ経験をした人がいるのではないだろうか。「なぜ伝わらないのだ」と、帰りの電車の中で自問したことがある人が。正直に告白すれば、当時の私は根本的な勘違いをしていた。論理的に正しければ、人は動くものだと思っていた。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じて疑わなかった。だが、違った。人が動くのは、論理ではなかった。もっと別の何かだった。私はそれを「物語」と呼ぶことにした。なぜそう呼ぶのか。それを、これから書いていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理学が扱うもの私も昔、論理学を学んだとき、これで人を説得できると思った。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じていた。今思えば、かわいいものだ。論理学は、推論の形式を扱う学問だ。内容ではなく、形式を。「すべての人間は死ぬ。ソクラテスは人間だ。ゆえにソクラテスは死ぬ」——これがアリストテレス以来の三段論法です。この推論が正しいのは、ソクラテスが誰かとか、死とは何かという内容とは関係ありません。形式が正しいから、結論は必然的に正しいのです。論理学には2つの柱がある。演繹と帰納だ。演繹は、前提から結論を必然的に導く。「すべてのAはBである」という全称命題から、個別の結論を導く。前提が真で、推論形式が正しければ、結論は必ず真になる。数学の証明はこれだ。帰納は、個別の事例から一般法則を導きます。「このカラスは黒い」「あのカラスも黒い」を繰り返して、「すべてのカラスは黒い」と結論する。しかし、帰納には必然性がありません。次に見るカラスが白い可能性もあります。科学の仮説はこの帰納に基づいています。エンジニアとして、私は両方を使う。型システムは演繹だ。型が合っていれば、その部分は正しく動く。テストは帰納だ。このケースで動いた、あのケースでも動いた。だから「おそらく」正しい。論理学が教えてくれる重要なことがあります。論理的に正しい推論でも、前提が間違っていれば結論は間違います。「すべてのエンジニアはコーヒーを飲む。田中はエンジニアだ。ゆえに田中はコーヒーを飲む」——この推論は論理的に正しい。でも、前提が間違っています。論理は形式の正しさを保証しますが、内容の正しさは保証しません。そして、日常会話で「論理的」と呼ばれるものは、この厳密な意味での論理ではない。では、日常で「論理的」と呼ばれているものは、いったい何なのか。そして、論理は本当に「無力」なのか。私はそうは考えません。論理が効かないのではなく、使う順番を間違えているだけかもしれない。論理が効く瞬間と、効かなくなる瞬間がある。その違いは何か。論理が効くのは、相手がすでに「聞く準備」ができているときだ。信頼関係がある。問題意識を共有している。結論を受け入れる土壌がある。そういう状態で論理を使えば、「なるほど、確かにそうだ」となる。論理が効かなくなるのは、その準備ができていないときだ。相手が防御姿勢に入っている。「この人の話は聞きたくない」と思っている。そういう状態で論理を振りかざしても、「理屈っぽい」「押し付けがましい」と感じられるだけだ。論理が最初に来ると失敗しやすいのは、これが理由だ。相手の心が開いていないうちに正論をぶつけても、反発を招くだけ。まず共感し、信頼を築き、「この人の話なら聞いてみよう」という状態を作る。論理はその後だ。論理は「納得を作る道具」なのか、「正しさを確認する道具」なのか。私の答えは「両方だが、順番が違う」だ。正しさを確認するのは最初。納得を作るのは最後。自分の中で論理的に正しいことを確認してから、相手に伝えるときは物語で包む。論理は骨格で、物語は肉だ。骨だけ見せても、人は食べたいと思わない。論理的誤謬という問題論理学は、推論の「正しくない形式」も分類している。論理的誤謬だ。「Aさんは実績がないから、Aさんの意見は間違っている」——これは人身攻撃の誤謬だ。発言者の属性と、発言内容の真偽は別の問題だ。「みんながそう言っているから正しい」——これは多数論証の誤謬だ。多数派であることは、正しさの証明にはならない。「前例がないからやるべきではない」——これは前例への訴えだ。前例がないことと、やるべきでないことは別の問題だ。会議室で飛び交う「論理的」な議論を観察してみてほしい。これらの誤謬がどれだけ多いことか。私も、今日の会議で3つは使った気がする。しかし、ここで興味深いことがある。論理的誤謬を含む議論でも、人は納得する。むしろ、厳密に論理的な議論よりも、誤謬を含む議論のほうが説得力を持つことがある。なぜか。誤謬が含まれていると、かえって「人間らしさ」を感じないか。完璧に論理的な人は、どこか冷たい印象を与える。「この人は機械なのか」と思ってしまう。一方、多少の飛躍や感情的な訴えがある人は、「血が通っている」と感じる。厳密さを捨てることで得ているものがある。親近感だ。「この人も自分と同じように考えている」という共感だ。論理的な完璧さは、時として障壁になる。「この人には敵わない」と思わせてしまうと、対話が成立しなくなる。誤謬を許容しているのは、聞き手か、語り手か。私の答えは「両方」だ。語り手は、厳密さよりも伝わりやすさを優先している。聞き手は、正しさよりも納得しやすさを優先している。両者の暗黙の合意によって、誤謬は見逃される。これは悪いことばかりではない。日常のコミュニケーションで、すべてを厳密に検証していたら話が進まない。ある程度の「緩さ」は、社会を潤滑にしている。問題は、その緩さがどこまで許されるかだ。アリストテレスは、人を説得する技術を3つに分けた。ロゴス（論理）、パトス（感情）、エトス（人柄・信頼）だ。論理学が扱うのはロゴスだけだ。しかし、人間を動かすには3つすべてが必要になる。「論理的に正しいのに伝わらない」と悩むとき、私たちはロゴスだけで勝負しようとしている。パトスとエトスが欠けている。逆に、論理的誤謬を含んでいても人が動くとき、パトスとエトスがロゴスの欠陥を補っている。これが、論理学と「論理的に見えること」の決定的な違いだ。「論理的に見える」の解体世間で「論理的」と言われる人を、よく観察してみてほしい。彼らは本当に学術的な意味での論理を使っているだろうか。三段論法を厳密に適用しているだろうか。演繹的推論を正確に展開しているだろうか。違う。彼らがやっているのは、相手が「なるほど、確かに」と思える具体例をサッと出すことだ。データや証明だけじゃなくて、実感できる話で納得させている。では、日常で「論理的」と呼ばれているものは、何を代替しているのか。本来は感情で決めていることを、論理で覆っていないか。「なんとなく嫌だ」を「リスクが高い」と言い換える。「この人と仕事したくない」を「スキルセットが合わない」と言い換える。感情的な判断を、論理的な装いで正当化している。本来は信頼で決めていることを、論理で覆っていないか。「この人が言うから」を「データに基づいている」と言い換える。「前からこうだったから」を「実績がある」と言い換える。関係性や慣習に基づく判断を、客観的な根拠があるように見せている。本来は立場で決めていることを、論理で覆っていないか。「上が決めたから」を「戦略的に正しい」と言い換える。「予算がないから」を「費用対効果が低い」と言い換える。権力構造に基づく判断を、合理的な分析結果のように見せている。「論理的に説明した」という言葉は、責任回避になっていないか。「私が決めた」ではなく「論理的にこうなった」と言うことで、判断の責任を「論理」に押し付けている。でも、どの前提を選ぶか、どのデータを重視するか、それを決めたのは人間だ。論理は責任を引き受けてくれない。論理という言葉は、どんな場面で免罪符になるのか。「感情的になるな、論理的に考えろ」と言われたとき、相手の感情を封じ込める武器になっている。「論理的に正しいんだから従え」と言われたとき、対話を打ち切る口実になっている。論理という言葉が、思考停止の道具になることがある。「論理で動いた」ように見える行動を解剖してみよう。実際に何が作用しているのか。信頼がある。「この人が言うなら」という前提がすでに成立している。文脈がある。その結論を受け入れやすい状況がすでに整っている。同調圧力がある。周囲がすでに納得している空気がある。期待がある。その結論であってほしいという願望がある。論理は、これらの基盤の上で初めて機能する。基盤がなければ、どれだけ論理的に正しくても人は動かない。論理は感情の乗り物だ。乗り物だけあっても、燃料がなければ走らない。感情という燃料があって、初めて論理は目的地に到達する。しかし、この比喩はどこまで言い切ってよいのか。感情がない状態で論理が機能する場面は存在するか。数学の証明を考えてみてほしい。純粋に形式的な操作として、感情抜きで成立するように見える。しかし、その証明を「面白い」「美しい」と感じる心がなければ、誰が数学を続けるだろうか。論理の営みを支えているのは、やはり感情だ。感情が強すぎるとき、論理は何を失うのか。怒りに支配されているとき、論理は武器になる。相手を傷つけるための道具になる。悲しみに沈んでいるとき、論理は機能しなくなる。「わかっているけど、できない」という状態になる。感情が強すぎると、論理は歪むか、停止する。論理と感情は主従関係なのか、相互依存なのか。私の答えは「相互依存」だ。論理が感情を制御することもある。「怒りに任せて発言するのはやめよう」と論理が感情をなだめる。感情が論理を駆動することもある。「この問題を解決したい」という情熱が、論理的思考を加速させる。どちらが主人というわけではない。両者が互いに影響し合っている。うまく言葉にできる人は、論理が強いのではない。相手を見ている。相手が何を知っていて、何を知らないか。何を信じていて、何に不安を感じているか。その理解があるから、言葉が届く。論理は単体では人を動かさない。ここでもう一歩踏み込んでみます。「私は論理的です」という態度自体が、1つのナラティブではないでしょうか。「私は感情に左右されず、冷静に判断しています」という自己像を提示している。それ自体が物語を語っているということです。「AだからB」は、推論である前に、納得の物語です。原因と結果を結びつけ、聞き手を結論へと導く。それは「正しいから従うべき」ではなく「納得できるから受け入れる」という構造で機能しています。信じたい物語への依存ここまで、論理の限界と物語の力について語ってきた。しかし、もう一歩踏み込みたい問題がある。人は「信じるべき論理」ではなく「信じたい物語」を信じる。これは単なる傾向ではない。依存に近い。考えてみてほしい。データを見せられたとき、私たちは本当に中立的に判断しているだろうか。「この数字は何を意味するか」と問う前に、「この数字は自分の期待を裏付けているか」と無意識に判断していないか。期待に合致するデータは「やはり」と受け入れる。期待に反するデータは「本当なのか」と疑う。同じ論理、同じデータでも、自分の物語に沿っているかどうかで、受け取り方が変わる。これは認知バイアスの問題だけではない。もっと根深い。私たちは、自分のアイデンティティを守る物語に依存している。「私は論理的な人間だ」という物語。「私は技術力がある」という物語。「私のチームは優秀だ」という物語。これらの物語が脅かされると、私たちは防御に入る。どれだけ論理的に正しい指摘でも、自分の物語を脅かすものは受け入れられない。なぜ依存と呼ぶのか。やめられないからだ。物語を手放すことは、自分を手放すことに感じられる。「私は実は論理的ではなかった」と認めること、それはアイデンティティの崩壊に近い。どれだけ反証を突きつけられても、私たちは自分の物語にしがみつく。論理が正しいかどうかは、もはや関係ない。これは「信じるべきかどうか」の問題ではない。「信じずにいられない」という問題だ。会議室で「それは違う」と言われたとき、私たちは何を守ろうとしているのか。事実を守っているのか、それとも「私は正しい」という物語を守っているのか。正直に言えば、多くの場合は後者だ。だから、論理で人を動かそうとしても失敗する。相手の物語と衝突すれば、相手は論理を聞く前に防御に入る。「この人の言うことは聞きたくない」という状態になる。論理が届く前に、扉が閉まっている。では、どうすればいいのか。相手の物語を攻撃するのではなく、その物語の中に入る。相手が信じたい物語を否定せず、その物語の延長線上に自分の提案を置く。「あなたの論理は間違っている」ではなく、「あなたの考えをさらに進めると、こうなる」と語る。人を動かすとは、相手の物語を書き換えることではない。相手の物語に自分の提案を織り込むことだ。経験談が人を黙らせる理由人を説得するとき、論理だけでは足りない。自分の失敗談を語ることで心を掴むことがある。「とほほエピソード」には不思議な力がある。完璧な論理よりも、不完全な経験談のほうが、人の心に響くことがあるのだ。経験談は再現性が低い。その人固有の文脈でしか成り立たないことも多い。なのに、私たちは経験談に心を動かされる。なぜか。経験談が持つ力を3つに分解してみる。1つ目は、再現性の放棄だ。「これが正解です」ではなく「私はこうだった」と語ることで、聞き手は反論しにくくなる。事実に対しては「それは違う」と言えるが、経験に対しては言えない。2つ目は、思考コストの削減だ。抽象的な理論を理解するより、具体的な経験を追体験するほうが楽だ。聞き手は考えなくても「なるほど」と言える。3つ目は、権威の自動付与だ。「やったことがある人」は、それだけで信頼される。成功者の経験談には、内容を超えた説得力が宿る。しかし、ここに危険がある。「成功者が言うから正しい」という錯覚。これは聞き手の思考停止を招く。経験談が「効きすぎる」とき、何が起きているのか。聞き手は考えることをやめている。語り手の経験を、自分の結論にすり替えている。経験談を聞いた瞬間、聞き手は何を放棄しているのか。批判的思考だ。「本当にそうか」「自分の場合は違うのではないか」という問いを放棄している。経験談には「事実」としての重みがあるから、反論しにくい。反論すると「お前はやったことがないくせに」と言われそうだから、黙ってしまう。「反論できない感じ」は、どこから生まれるのか。経験談は「私はこうだった」という一人称で語られる。一人称の物語に対して、「それは違う」とは言いにくい。他人の経験を否定する権利が自分にあるのか、という遠慮が働く。しかし、その経験から導かれる「だからこうすべきだ」という結論は、本当に正しいのか。そこは検証が必要だ。だから、経験談は入口であって、結論ではない。経験談で心を開き、そこから自分で考える。その順番が重要だ。では、経験が浅い人は物語を語る資格がないのか。私はそうは考えません。経験の浅さには、浅いなりの価値があります。経験が浅いからこそ見えるものがある。「なぜこのやり方なのか」という素朴な疑問。ベテランにとっては「当たり前」になっていることへの違和感。「本当にこれでいいのか」という不安。これらは、経験を積むほど薄れていく。ベテランが失いやすい視点とは何か。初心者の目線だ。「これは難しい」「これはわかりにくい」という感覚は、慣れると消えてしまう。だからベテランが書いたドキュメントは、初心者には読めないことがある。ベテランが設計したシステムは、初心者には使えないことがある。経験は資産だが、同時に負債でもある。「まだわからない」という物語は、どんな力を持つか。謙虚さの力だ。「私はまだ学んでいる途中です」と言える人は、相手の話を聞く姿勢がある。「私は全部わかっています」と言う人は、すでに耳を閉じている。経験の浅さを認めることは、対話の扉を開くことになる。重要なのは経験の量ではなく、経験を物語として語る力だ。10年の経験があっても、それを言葉にできなければ伝わらない。1年の経験でも、そこから何を学んだかを語れれば、人の心に届く。経験談を「入口」に留めるには、何が必要か。聞き手の側には、「この人の経験は参考になるが、自分の状況は違うかもしれない」という留保が必要だ。語り手の側には、「これは私の経験であって、あなたに当てはまるとは限りません」という謙虚さが必要だ。両者がこの姿勢を持っていれば、経験談は入口のまま留まる。物語が許されない領域私はエンジニアとして長く働いてきた。だからこそ言いたいことがある。物語万能論は危険だ。かつて、私は失敗したことがある。プロジェクトが炎上しかけていたとき、チームの士気を上げようと物語を語った。「このプロダクトが世に出れば、多くの人の生活が変わる」「困難を乗り越えた先に、私たちは成長している」。チームは一時的に盛り上がった。でも、テストは通らなかった。本番環境でバグが発生した。物語で人は動いたが、システムは動かなかった。バグは物語で直らない。物語でテストが通るなら、私は今頃、小説家になっている。どれだけ美しい物語を語っても、コードが間違っていれば動かない。どれだけチームが納得しても、テストが通らなければリリースできない。エンジニアリングには、物語では代替できない領域がある。技術的正しさは、どこまで物語と共存できるのか。私の答えは「共存はできるが、置き換えはできない」だ。物語は人を動かすが、システムは論理で動く。この2つを混同してはいけない。泣いたら人は許してくれるかもしれませんがシステムは許してくれません。人の層とシステムの層を混同すると、何が起きるか。人の層で通用する「納得したからOK」が、システムの層に持ち込まれる。チーム全員が「この設計でいこう」と合意しても、コードが間違っていれば動かない。逆に、システムの層で通用する「正しいから従え」が、人の層に持ち込まれる。論理的に正しい設計でも、チームが納得していなければ実装は進まない。「納得したからOK」は、どこまで通用するのか。人を動かすところまでだ。「このアーキテクチャでいこう」という合意形成には物語が必要だ。しかし、そのアーキテクチャが本当に要件を満たすかは、検証が必要だ。納得と正しさは別の問題だ。物語で進めてはいけない判断の特徴は何か。結果が客観的に検証できる判断だ。「このコードは動くか」「このシステムは要件を満たすか」「このセキュリティ対策は十分か」。これらは、どれだけ美しい物語を語っても、実際にテストしなければわからない。物語で「大丈夫だろう」と進めて、本番環境で障害が起きたら、物語は言い訳にしかならない。ナラティブと検証の役割分担を整理しておく。人を動かすのは物語だ。なぜこの技術を選ぶのか、なぜこのアーキテクチャにするのか。それを説明し、納得してもらうには物語が必要だ。正しさを担保するのは論理とテストと記録だ。選んだ技術が本当に動くのか、アーキテクチャが要件を満たすのか。それを確認するには検証が必要だ。「あの人が言うから正しい」という判断は、いつ危険になるのか。それは、検証を省略したときだ。権威ある人の経験談に納得したとしても、コードレビューは必要だ。テストは必要だ。ドキュメントは、物語の代替にはなりえない。物語が「なぜそうするのか」を伝え、ドキュメントが「何をするのか」を記録する。物語は人の層に効き、論理はシステムの層に効く。この使い分けが重要だ。プロジェクトを進めるには「直線モード」と「曲線モード」を行き来する必要があります。計画と合理性を重視する直線モード、そして変化や対話を重視する曲線モード。どちらか一方では足りません。両方を使い分けられることが、プロジェクトを前に進める力になります。優しい物語の罠「あなたらしさを大切にしたうえで、今必要な道具を手に入れ、磨き、使い分けていこう」というメッセージには優しさがある。しかし、優しい物語は、なぜ時に成長を妨げるのか。思い出してほしい。優しい言葉をかけたのに、相手が変わらなかった経験はないか。「大丈夫だよ」と言い続けたのに、問題が解決しなかった経験はないか。あのとき、私たちは何を間違えていたのか。優しさは寄り添う。甘さは目を背けさせる。優しさと甘さは、どこで分岐するのか。私の答えは「事実を直視しているかどうか」だ。優しさは事実を受け止めた上で寄り添うこと。甘さは事実から目を背けさせること。「あなたらしくていい」が「変わらなくていい」に変質したとき、それは優しさではなく甘さになる。厳しさを含まない物語は、誰のためのものか。多くの場合、それは語り手のためだ。相手に嫌われたくない、対立を避けたい、という語り手の願望が、優しさという衣をまとっている。その優しさは、聞き手のためか、語り手のためか。この問いは重要だ。「傷つけたくない」と言いながら、実は「嫌われたくない」だけかもしれない。「今は言わないほうがいい」と言いながら、本当は「言うのが面倒」なだけかもしれない。優しさの仮面をかぶった自己保身は、いくらでもある。事実を和らげることと、隠すことの境界はどこか。私の答えは「相手が判断するために必要な情報を持っているかどうか」だ。「あなたのスキルはまだ足りないが、伸びしろがある」は和らげている。「あなたは素晴らしい」と言って、スキル不足を伝えないのは隠している。前者は事実を含んでいるから、相手は次の行動を選べる。後者は事実を隠しているから、相手は間違った判断をする。成長を促す厳しさと、切り捨ての厳しさはどう違うか。成長を促す厳しさは、相手の可能性を信じている。「あなたならできるはずだ。だから厳しく言う」という姿勢がある。切り捨ての厳しさは、相手を見限っている。「あなたには無理だ。言っても仕方ない」という諦めがある。言葉は同じ「厳しさ」でも、その奥にある信頼の有無で意味が変わる。勇気を与える物語と、逃避を許す物語の違いは何か。勇気を与える物語は「困難があるが、乗り越えられる」と語る。逃避を許す物語は「困難なんてない」と語る。前者は現実を認めた上で希望を示す。後者は現実から目を背けさせる。自分が語っている物語は、どちらだろうか。説得と操作の境界物語には力がある。力があるということは、危険もあるということだ。物語は、どの瞬間に「説得」から「操作」に変わるのか。その境界は曖昧だ。聞き手の自由意志は、どこまで守られているのか。完全に自由な判断などありえない。私たちは常に、何らかの影響を受けながら判断している。では、説得と操作は何が違うのか。結果だけを見れば、どちらも「相手が動いた」という点では同じだ。説得と操作の違いは、「結果」ではなく「過程」にある。結果が同じなら、過程を見なければならない。しかし、過程を見れば違いが見える。説得は、相手が考える余地を残している。操作は、相手が考える余地を奪っている。相手が考える余地を失った瞬間は、いつか。選択肢が1つしか見えなくなったときだ。「これしかない」「こうするしかない」と思わせた瞬間、相手は考えることをやめている。本当は他の選択肢があるのに、それを見せないでおく。これは操作だ。「選択肢を示す」と「結論を誘導する」の違いは何か。選択肢を示すとは、複数の道があることを伝え、それぞれの長所と短所を説明することだ。結論を誘導するとは、複数の道があるように見せながら、1つの道だけが正しいと思わせることだ。言葉は似ているが、相手の思考を尊重しているかどうかで意味が変わる。しかし、だからといって何をしてもいいわけではない。善意で語った物語が、操作になるのはどんなときか。語り手が「相手のため」と信じていても、相手の判断力を奪っていれば操作だ。「あなたのためを思って」という言葉は、しばしば「私の思い通りにしたい」の言い換えになっている。善意は免罪符にならない。語り手の「善意」は、免罪符になりうるか。ならない。善意で語った物語が、相手を誤った方向に導くことはある。「あなたのためを思って」は、操作の常套句だ。善意は動機であって、結果の正当化にはならない。操作に堕ちないための条件を3つ挙げる。1つ目は、事実を歪めないこと。都合のいい事実だけを選んだり、不都合な事実を隠したりしない。2つ目は、相手に考える余地を残すこと。「これしかない」と思わせるのではなく、「こういう選択肢がある」と示す。結論を押し付けない。3つ目は、相手の利益を本当に考えていること。相手を動かすことが目的なのか、相手のためになることが目的なのか。同じ物語でも、動機によって意味が変わる。この3つが揃わなければ、どれだけ巧みな物語も操作に堕する。また、「別の物語を語る」ことが、失敗からの逃避になることもある。プロジェクトが破綻したとき、物語を更新することで責任を回避していないか。失敗の原因を分析し、自分の責任を認めた上で、「次はこうする」という物語を語るのは再解釈だ。事実から目を背け、「本当はうまくいっていた」「環境が悪かった」と言い張るのは言い訳だ。物語は現実を覆い隠すためのものではない。現実を受け止めた上で、次に進むためのものだ。では、物語を使った対話とはどのようなものか。ファシリテーションの現場から考えてみます。対話は物語を揃えることではない優れたファシリテーターは「ほぼ何もしない」といいます。ワークを説明したら、部屋の隅に座る。音楽を流す。ニコニコ笑っている。具体的な動きはそれだけです。でも、それでチームは動く。なぜか。それは、ファシリテーターが「物語の場」を設定しているからだ。メンバーが自分たちで物語を紡げるような空間を作っている。論理的な指示を与えるのではなく、物語が生まれる環境を整えている。しかし、対話とは本当に「物語の共同制作」と言えるのか。正直に言えば、完全に対等な共同制作は難しい。ファシリテーターは場を設計している時点で、ある種の権力を持っている。どんな問いを投げかけるか、どんな発言を拾うか、どこで介入するか。それらすべてが、生まれる物語に影響を与える。「何もしない」という選択自体が、1つの介入なのだ。では、合意されなかった物語はどこへ行くのか。チームで1つの物語を紡いだとき、そこに乗れなかった人がいる。彼らの物語は消えるのか。消えはしない。地下に潜るだけだ。表向きは合意しながら、心の中では別の物語を持ち続ける。優れたファシリテーターは、この「語られなかった物語」にも目を向ける。全員が同じ物語を持つ必要はない。大切なのは、異なる物語が共存できる場を作ることだ。対話のゴールは「1つの物語に収束すること」ではなく「複数の物語が共存できること」だ。合意形成について、よく誤解されていることがある。多くの人は、自分の檻の中から相手の檻を押し潰そうとする。自分の枠組みが正しい、相手の枠組みは間違っている。だから相手を説得し、こちらの檻に入れようとする。でも、それは合意ではない。征服だ。本当の合意形成とは、まず自分が檻の中にいることを認めることから始まる。私にも枠組みがある。相手にも枠組みがある。どちらの檻も、その人の経験と価値観から作られている。どちらが正しいという話ではない。相手の檻を壊す必要はない。自分の檻を捨てる必要もない。大切なのは、お互いの檻の形を理解し、その間に共通の地面を見つけることだ。檻から出るのではなく、檻と檻の間に橋を架ける。それが対話だ。一貫性とは何か複数の物語を使い分けることは、「一貫性の欠如」にならないのか。状況に応じて物語を切り替える人は、信用できないのではないか。そう感じるかもしれません。しかし、一貫性とは何でしょうか。言葉の統一なのか、価値観の統一なのか。私は、一貫性とは価値観の統一だと考えている。言葉が変わっても、芯がぶれなければ、それが一貫性だ。言葉や物語は変わっていい。相手によって、文脈によって、最適な表現は変わる。しかし、その奥にある価値観——何を大切にしているか——は変わらない。物語が変わっても残る「軸」とは何か。それは「この人は結局、何を実現したいのか」という問いへの答えだ。チームの成長を願っているのか。技術的な卓越性を追求しているのか。顧客の幸福を第一にしているのか。その軸がぶれなければ、物語が変わっても芯はぶれない。文脈適応と迎合の違いは、どこで判断できるのか。文脈適応は、相手に届くように表現を変えること。迎合は、相手に合わせて価値観を曲げること。前者は橋を架ける行為であり、後者は自分を売る行為だ。同じ価値観を異なる文脈で語り分けられることこそが、優れたナラティブ構築者の条件だ。論理を使い直すここまで、論理の限界を語ってきた。論理は単体では人を動かさない。論理自体が1つの物語だ。論理を絶対視することの危険。しかし、論理を否定して終わりにするつもりはない。論理を「唯一の正解」から「道具」へ格下げすることは、思考を弱くするのか、強くするのか。私は強くすると考えている。論理を絶対視していると、「論理的に正しいのになぜ伝わらないのか」と悩むことになる。論理を道具として扱えば、「この道具はこの場面では有効か」と考えられる。道具は選べる。使い分けられる。論理という物語が有効な場面と、別の物語が有効な場面を見極められるようになる。プロジェクトには「プロジェクトストーリー」がある。最終ゴールと中間ゴールからストーリーを描き、チームの方向性を示す。このストーリーの中に、論理は組み込まれる。計画は論理的だろう。でも、その計画を人に伝え、人を動かすには、物語という器が必要だ。論理と物語、どちらも選んで使うものです。どちらかが正しいのではありません。どちらをいつ使うかを判断できることが、人を動かす力になります。正しさを振り回すのは、本当に「最後」でいいのかここまで読んで、こう思った人がいるかもしれない。「物語が先で、正しさは後。それはわかった。でも、正しさを最後まで出さないことに、問題はないのか」正しさを最初に出したくなるのは、どんな不安からか。「間違ったことを言いたくない」という不安だ。「後で『それは違う』と言われたくない」という不安だ。正しさを先に出しておけば、自分の立場は守られる。たとえ相手が納得しなくても、「私は正しいことを言った」と言える。正しさを最初に出すことは、自己防衛なのだ。しかし、正しさを最後に出すことで、失われるものはないのか。ある。時間だ。物語で回り道をしている間に、問題は悪化する。緊急事態では、正しさを最初に出すべき場面もある。「このまま進むとシステムが落ちます」と言うべきときに、「まず私の経験を聞いてください」と始めている場合ではない。「最後まで正しさを出さない」こと自体が、別の操作になっていないか。この問いは重要だ。相手が自分で結論に至ったように見せかけて、実は最初から結論が決まっている。正しさを隠しながら誘導している。これは、正しさを振りかざすのとは別の形の操作だ。では、いつ正しさを出すべきか。私の答えは「相手の安全が脅かされるとき」と「時間の制約があるとき」だ。相手が危険な判断をしようとしているとき、物語を語っている余裕はない。「それは間違っている」と言うべきだ。締め切りが迫っているとき、回り道をしている余裕はない。「正しい方法はこれです」と言うべきだ。正しさは武器だ。武器を振り回すのは危険だが、武器を持たないのも危険だ。大切なのは、いつ抜くかを見極めることだ。syu-m-5151.hatenablog.comおい、物語を語れだから、私は言いたい。おい、物語を語れ。論理的であろうとするな、とは言いません。論理は大事です。でも、論理だけでは人は動きません。「この設計が正しい理由は〜」と説明するとき、あなたは本当に論理だけで話しているだろうか。実は、相手が納得しやすい順番で、相手が受け入れやすい言葉で、相手の不安を先回りして解消しながら話しているのではないか。それは物語を語っているということだ。世間で「論理的」と言われる人の正体は、巧みなナラティブ構築者だ。彼らは論理を使いこなしているのではない。論理という道具を使って、説得力のある物語を紡いでいるのだ。そして、そのことに自覚的になることで、私たちはより良い物語の語り手になれる。物語を語る勇気でも、物語を語るのは怖い。論理的であろうとするのは、ある意味で楽です。「これはデータに基づいています」「これは事実です」と言えば、自分の主観を隠せます。責任を回避できます。でも物語を語るということは、自分をさらけ出すことだ。裸になることだ。「私はこう思う」「私はこれを大事にしている」「私はこの未来を信じている」と言わなければならない。自分の背景を伝えること、自分の失敗を語ること、自分の葛藤を見せること。それは勇気がいる。でも、その勇気が人を動かす。「論理的に正しいから」ではなく、「この人が言うなら」で人は動く。そして「この人が言うなら」を引き出すのは、論理ではなく、物語だ。おわりに年の瀬の日曜日の夜、私はベッドの上でこの文章を書き終えようとしている。正直に言えば、書いている間も何度か「これは論理的に正しいのか」と自問してしまった。物語の力を語りながら、論理の正しさを気にしている。滑稽だ。滑稽だが、それが私という人間なのだと思う。この文章を書いたからといって、明日から完璧に物語を語れるようになるわけではない。おそらくこれからも、会議室で正論を並べ立て、微妙な沈黙を招く日があるだろう。「なぜ伝わらないのだ」と、帰りの電車で思い悩む日があるだろう。だが、少しだけ違うことがある。以前の私は、伝わらないとき、「もっと論理的に説明しなければ」と考えていた。今は違う。「ああ、骨だけを見せていた」と気づくことができる。気づいたなら、肉を足せばいい。失敗談をひとつ、付け加えればいい。それだけでも、以前よりはましなのだと思う。たぶん。明日は月曜日だ。また会議がある。また正論を振りかざしたくなる瞬間がある。だが今度は、最初に自分の失敗談から話してみようと思う。「この設計が正しい理由は」ではなく、「以前、似たような判断を先送りにして、半年後に全員で苦しんだことがある」から始めてみる。怖い。裸を晒すようで、怖い。だが、論理だけで人が動くと信じていた私は、もういない。あの金曜日のエレベーターの中で、その私は死んだのだと思います。おい、物語を語れ。何度でも、自分に言い聞かせる。何度でも忘れ、何度でも思い出す。完璧に語れるようになることより、何度でも思い出せることのほうが、きっと大切なのだ。参考文献イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon小説作者:野崎まど講談社Amazon言語化するための小説思考作者:小川 哲講談社Amazonリーダーのためのストーリーテリング入門 90秒で人の心を動かす「語り」のマネジメントスキル作者:広江 朋紀翔泳社Amazonリーダーのための！　ファシリテーションスキル作者:谷 益美すばる舎Amazonチームビルディングと組織開発の話作者:長尾 彰ナガオ考務店Amazonチーム・ビルディング[新版]　人と人を「つなぐ」技法作者:堀公俊日経BPAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社Amazonエンジニアリングが好きな私たちのための　エンジニアリングマネジャー入門作者:サラ・ドラスナー日本能率協会マネジメントセンターAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazonナラティブ経済学―経済予測の全く新しい考え方作者:ロバート・シラー東洋経済新報社Amazon世界はナラティブでできている：なぜ物語思考が重要なのか作者:アンガス フレッチャー青土社Amazonストーリーが世界を滅ぼす―物語があなたの脳を操作する作者:ジョナサン・ゴットシャル東洋経済新報社Amazon「わかってもらう」ということ　他人と、そして自分とうまくやっていくための言葉の使い方 (単行本)作者:川添 愛KADOKAWAAmazonなぜあなたはマネジメントを間違えるのか？　会社の常識を打ち破るチェンジリーダーの教科書作者:岸良裕司KADOKAWAAmazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon人が壊れるマネジメントプロジェクトを始める前に知っておきたいアンチパターン 50作者:橋本将功ソシムAmazonモチベーション革命　稼ぐために働きたくない世代の解体書 (NewsPicks Book)作者:尾原和啓幻冬舎Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon","isoDate":"2025-12-29T07:07:46.000Z","dateMiliSeconds":1766992066000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年 俺が愛した本たち 非技術書編","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033","contentSnippet":"はじめに技術書編を書き終えて、ふと気づいた。あれだけ書いても、まだ語っていない本がある。仕事に直結しない本。読んでも生産性が上がらない本。キャリアに役立つかどうかわからない本。そういう本たちのことを、どこかで書きたいと思っていた。だから、この記事を書いている。非技術書を読む時間を、どこか後ろめたく感じていた時期があった。エンジニアなんだから技術書を読むべきだ。限られた時間を、仕事に関係ない本に使っていいのか。そんな自問が、頭の片隅にあった。でも、ある時期から考えが変わった。技術書だけ読んでいると、技術書が読めなくなる。視野が狭くなる。発想が硬くなる。同じ問題を、同じ角度からしか見られなくなる。なぜそうなるのか。技術書は「答え」を求めて読むからだ。設計パターン、ベストプラクティス、トラブルシューティング。明確な課題があって、その解決策を探している。でも非技術書は違う。何を得られるかわからないまま読み始める。読み終わっても、何が残ったのかすぐにはわからない。数ヶ月後、ふとした瞬間に「ああ、あの本のあれか」と腑に落ちることがある。即効性がないから、効いている実感もない。でも、確実に何かが変わっている。では、非技術書は仕事に無関係かというと、そうでもない。小説を読む。エッセイを読む。哲学書を読む。歴史書を読む。どれも仕事には直結しない。でも、人間を理解しようとする営みは、チームで働く上で無駄ではないはずだ。コードを書くのは人間だ。レビューするのも人間だ。障害対応で慌てるのも、成功を喜ぶのも、人間だ。技術だけ理解しても、人間を理解していなければ、良いエンジニアにはなれない。そう言い聞かせながら、非技術書を読んできた。ここまで書いて、自分でも気づいている。これは言い訳だ。正直に言えば、読んでいて楽しいから読んでいる。それだけだ。仕事のためとか、自己成長のためとか、そういう大義名分は後付けだ。ページをめくる時間が好きだ。知らない世界に触れる瞬間が好きだ。登場人物の感情に揺さぶられる体験が好きだ。好きなことに理由はいらない。でも、理由を語りたくなるのが人間だ。断っておくと、以下の選定基準はかなりブレている。読んだ直後に評価したわけではなく、年末に一年を振り返って「良かったな」と思い出した本を並べているだけだ。印象に残った理由も、内容が深かったからだったり、読んだタイミングが良かったからだったり、装丁が好みだったからだったり、バラバラだ。体系的なブックガイドではない。ある一人のエンジニアが、2025年に出会って心に残った本の記録だと思ってほしい。以下に紹介する本たちは、2025年に私の心を動かした非技術書だ。仕事に役立つかどうかはわからない。キャリアに影響したかどうかもわからない。ただ、これらの本と過ごした時間が、私の2025年を少しだけ豊かにしてくれた。それだけは確かなことだ。昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2025年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるまずは小説から始めよう。物語の力を信じているから。小説野崎まどという作家は、読者の予測を裏切ることに喜びを見出しているとしか思えない。タイトルが『小説』。これ以上ないほど直球で、それでいて挑発的だ。読み始めたときは、ただの青春小説かと思った。でも違った。「小説とは何か」という問いに正面から向き合いながら、それ自体が1つの「小説」として成立している。メタ構造に気づいた瞬間、鳥肌が立った。野崎まどの作品は、読み終わった後に「やられた」と思わせる仕掛けが必ずある。『know』では知識と情報の本質を、『タイタン』ではAIと人間の関係を問いかけてきた。本作では、小説という形式そのものを問いかけてくる。読んでいる間は物語に没入し、読み終わった後に構造の巧みさに気づく。その二重の楽しみが、野崎作品の醍醐味だ。小説作者:野崎まど講談社AmazonGOATデジタル全盛の時代に、あえて紙の文芸誌を立ち上げる。その挑戦に心を動かされた。510円という価格設定で、特殊紙を惜しみなく使い、読書バリアフリーにも取り組んでいる。翻訳の仕事をしているとよく分かるが、紙代も印刷代も高騰している。書籍全体の価格が年々上がっているのは、出版社の怠慢ではない。本を作るコストそのものが上がっている。そんな中で、この価格で、この品質を維持しようとしている。すごいな、と素直に思った。GOAT作者:西加奈子,小川哲,尾崎世界観,市川沙央,チョン・セラン小学館AmazonGOAT Summer 2025作者:朝井リョウ,一穂ミチ,野崎まど小学館Amazon野崎まどの「山羊と七枚」も掲載されており、雑誌のコンセプトと作家の個性が見事に噛み合っていた。dps.shogakukan.co.jp小説と雑誌を読んで、ふと考えた。読む時間は有限だ。何を読むかより、どう読むかが問われる。そこで手に取ったのが、この本だった。STOIC 人生の教科書ストイシズム2000年以上前から続くストア哲学が、シリコンバレーで再び注目されている。禅やマインドフルネスと並んで、ビジネスパーソンの必須教養になりつつあるという。本書は、エピクテトス、セネカ、マルクス・アウレリウスという三人のストア哲学者の言葉をもとに、90日間のプログラムとして構成されている。見開き2ページで1つの教えを学び、実践するという形式だ。ストイシズムの核心は「他人の行動はコントロールできないが、自分の反応はコントロールできる」という考え方にある。これは現代のエンジニアにとっても響く教えだ。障害が起きたとき、顧客からのクレームが来たとき、チームメンバーとの意見が対立したとき。制御できないことに怒りを感じても何も変わらない。変えられるのは、自分がどう対応するかだけだ。本書で繰り返し語られる4つの美徳がある。知恵（うわべにとらわれない力）、正義（他人に思いやりを持つ力）、勇気（苦難に立ち向かう力）、節制（衝動を抑える力）。どれも派手ではないが、日々の仕事で試される場面ばかりだ。佐藤優氏が帯で「大きな理想を獲得するには禁欲が必要だ」と書いている。逆説的だが、自分を律することで自由になれる。そういう考え方に惹かれる人は多いはずだ。STOIC 人生の教科書ストイシズム作者:ブリタニー・ポラットダイヤモンド社Amazonストイシズムは「衝動を抑える力」を説く。では、そもそも私たちは何を読み取っているのか。読むという行為そのものを問い直す本に出会った。読めば分かるは当たり前？　――読解力の認知心理学「読めば分かる」は当たり前ではない。本書を読んで、その事実に改めて気づかされた。文字を認識し、単語の意味を理解し、文の構造を解析し、文章全体の意味を把握する。私たちが無意識に行っているこの作業は、驚くほど複雑な認知プロセスの連続だ。どこかでつまずくと、読解は破綻する。そして、つまずきのポイントは人によって異なる。本書では、読解を3つの目的地に分類している。「表象構築」（テキストの内容を正確に理解する）、「心を動かす読解」（物語に感情移入する）、「批判的読解」（内容を吟味し、自分の考えと照らし合わせる）。技術書を読むときは主に表象構築を、小説を読むときは心を動かす読解を使っている。無意識に使い分けていたことを、言語化してもらった気分だ。特に響いたのは、「ワーキングメモリ」の話だ。複雑な文章を読むとき、頭の中の「メモ帳」に情報を一時保存しながら読み進める。このメモ帳には容量制限がある。だから、込み入った技術ドキュメントを読むときは、メモを取りながら読むほうが理解が深まる。経験則として知っていたことに、認知科学的な裏付けを得た。読めば分かるは当たり前？　――読解力の認知心理学 (ちくまプリマー新書)作者:犬塚美輪筑摩書房Amazon小澤隆生 凡人の事業論 天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと孫正義と三木谷浩史。日本を代表する二人の天才経営者に仕えてきた人物がいる。楽天イーグルス創業、PayPay立ち上げなど、巨大ビジネスを次々と成功させてきた小澤隆生氏だ。投資先19社中11社が株式上場という実績を持つ。そんな人物が「自分は凡人だ」と言う。謙遜ではない。天才のそばにいたからこそ、自分との違いを痛感してきたのだろう。本書で語られるフレームワークは驚くほどシンプルだ。「センターピン」を見極める。「根源的欲求」に訴える。「打ち出し角度」を検証する。言葉は平易だが、1つ一つのやりきり度が違う。市場を選ぶときは「成長性」と「シェア率」で判断する。チームを動かすときは数字目標ではなく、ワクワクする言葉で語る。精神論ではなく、再現可能な方法論として事業の作り方を説いている。心に刺さったのは「しつこい人間が最後は残る」という言葉だ。才能や運ではなく、諦めずに続けること。天才たちの隣で勝ち残ってきた人が言うと、重みが違う。エンジニアとして新しいプロジェクトを立ち上げるとき、この本を思い出すことになりそうだ。小澤隆生 凡人の事業論――天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと作者:蛯谷 敏ダイヤモンド社Amazon失敗できる組織「失敗は成功の母」という言葉を、私たちは使いすぎている。エイミー・エドモンドソンはこの使い古された格言に、鋭いメスを入れる。すべての失敗が成功につながるわけではない。失敗には種類がある。それを見分けられなければ、失敗から学ぶことはできない。本書は『恐れのない組織』で「心理的安全性」を提唱した著者が、失敗の科学に正面から取り組んだ一冊だ。フィナンシャル・タイムズの「ビジネス・ブック・オブ・ザ・イヤー2023」を受賞している。本書で示される失敗の3分類が明快だ。「基本的失敗」は、注意不足や経験不足による防げたはずの失敗。「複雑な失敗」は、システムの複雑さゆえに発生する、完全には避けられない失敗。そして「賢い失敗」は、未知の領域に挑戦する過程で必然的に起きる、学びをもたらす失敗。問題は、私たちが3つを区別せずに「失敗」とひとくくりにしてしまうことだ。エンジニアとして考えると、本番障害を起こしたとき、それが「基本的失敗」なのか「複雑な失敗」なのか「賢い失敗」なのかで、対応は変わる。テスト不足なら基本的失敗。想定外の負荷パターンなら複雑な失敗。新しいアーキテクチャを試した結果なら賢い失敗。ポストモーテムで原因を分類することで、再発防止策の質が変わる。本書は、失敗を恐れるなと言っているのではない。失敗を理解せよと言っている。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazon知性の罠　なぜインテリが愚行を犯すのか賢い人ほど愚かな判断をする。この逆説的な現象を、本書は認知科学の研究をもとに解き明かす。IQが高いほど投資で破産しやすい。高学歴ほど陰謀論にハマりやすい。専門家ほど自分の間違いを認められない。直感に反する事実が、次々と突きつけられる。今井むつみ氏（『言語の本質』著者）が「最高に面白く、最高に怖く、最高に深い」と評したのも頷ける。キーワードは「動機づけられた推論」だ。結論があらかじめ決まっていて、その結論を支持する証拠だけを集めてしまう傾向。知性が高い人ほど、この罠に陥りやすい。なぜなら、自分の結論を正当化するための論理を組み立てる能力が高いからだ。シャーロック・ホームズの生みの親コナン・ドイルが、心霊主義を信じ込んでしまった事例が紹介されている。推理の天才を創造した作家が、なぜ詐欺師に騙されたのか。知性は、防御にも攻撃にも使える両刃の剣なのだ。本書を読んで、自分のことを振り返った。技術的な議論で、相手の意見を聞く前から反論を考えていることがある。自分の設計が正しいと証明するために、都合の良いベンチマーク結果を探してしまうことがある。知性の罠は、他人事ではなかった。知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazon戦略的暇―人生を変える「新しい休み方」「スマホの充電は満タンなのに、自分の充電ができていない」。この一文に、ドキリとした。日本デジタルデトックス協会理事の森下彰大氏による本書は、現代人の「脳疲労」に正面から向き合う。私たちは平均5分に1回スマホに触れているという。複数のタスクに集中が分散し、脳が過労状態に陥る。その結果が、慢性的な疲労感と創造性の低下だ。本書が提案するのは、3つのデトックスだ。「デジタルデトックス」（スマホとの距離を取る）、「時計時間デトックス」（コスパ・タイパ思考から離れる）、「自分デトックス」（凝り固まった自己像を解放する）。どれも「効率を上げる」方法ではない。むしろ逆だ。効率を手放すことで、失われていた余白を取り戻す。エンジニアとして働いていると、効率化の罠に陥りやすい。すべての時間を「生産的」に使いたくなる。でも、何も考えない時間がなければ、新しいアイデアは生まれない。本書を読んで、意図的に「暇」を作ることの価値を考え直した。戦略的に目的を持たない時間を作る。その矛盾した響きに、現代を生きるヒントがある。個人の時間の使い方を考えたら、次は社会の仕組みに目が向いた。テクノロジーは社会をどう変えるのか。その問いに正面から向き合った本がある。戦略的暇作者:森下彰大飛鳥新社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来624ページ。その厚さに圧倒されながらも読み通した。オードリー・タンとグレン・ワイルという二人の天才が描く、テクノロジーと民主主義の未来図だ。翻訳は『21世紀の資本』を手がけた山形浩生氏。解説は『なめらかな社会とその敵』の鈴木健氏。この布陣だけで、本書の射程の広さが伝わる。山形氏の『翻訳者の全技術』も最高だった。プルラリティ（多元性）は、シンギュラリティ（単一性）への対抗概念だ。AIが人間を超えて単一の知性が支配する未来ではなく、多様な人々が協調しながらテクノロジーを活用する未来。台湾で実践されているvTaiwanやJoinといったデジタル民主主義のプラットフォームは、その具体例として紹介されている。多数決が見落としてきた少数意見の強さを可視化し、対立を創造的な合意形成へと導く。読んでいて痛感したのは、著者たちの天才ぶりだ。インターネットの歴史を俯瞰しながら、聞いたこともない話や人物が次々と展開される。本書は単なる理想論ではない。民主主義を再生させるための具体的な方向性を示している。技術者として、社会にどう関わるかを問われる一冊だと思った。PLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon心眼：あなたは見ているようで見ていない「何よりも難しいのは、本当にそこにあるものを見ることである」。本書の冒頭に記されたこの言葉が、ずっと頭に残っている。『センスメイキング』の著者クリスチャン・マスビアウが、ウィトゲンシュタインやメルロ＝ポンティの哲学を援用しながら、「観察する」とはどういうことかを問いかける。本書で繰り返し語られるのは、「注意を払う」ことの本質だ。通りを歩くとき、私たちは何かに集中しているわけではない。うっすらと広く全体をカバーしている。その状態こそが「注意を払う」ことだという。一点に焦点を合わせることではなく、全体を同時に感じ取ること。ハヤブサのように、広い視野を保ちながら決定的な瞬間を捉える。その比喩が印象的だった。エンジニアとして、私は「問題を解決する」ことに意識が向きがちだ。でも、問題を正しく認識するためには、まず「観察する」必要がある。本書を読んで、自分が見ているものを見ているのではなく、見たいものを見ているのではないかと自問した。観察には時間がかかる。結論を急がないこと。その姿勢を持ち続けたい。心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon「恥」に操られる私たち：他者をおとしめて搾取する現代社会「恥」は個人の感情だと思っていた。でも本書を読んで、それが社会的に作られ、利用されているものだと気づかされた。体型への侮辱、生活保護バッシング、キャンセルカルチャー。個人を攻撃する言葉の裏には、「恥ずかしい」という感情につけ込んで利益を得ようとするシステムがある。ダイエット産業は「痩せていないことは恥ずかしい」という感情を煽ることで成り立っている。SNSは炎上によるエンゲージメントで収益を上げている。政治家は生活保護受給者を「恥ずかしい存在」として描くことで、福祉予算を削減しやすくしている。恥の感情は、権力構造を維持するために意図的に生み出されている。読んでいて居心地が悪くなる箇所が多かった。自分も無意識のうちに、誰かを「恥ずかしい」と感じさせる側に回っていたのではないか。コードレビューで相手を責めるような言い方をしていなかったか。障害報告で担当者を晒し上げるような雰囲気を作っていなかったか。恥は武器になる。だからこそ、使い方を意識する必要がある。「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon「偶然」はどのようにあなたをつくるのかキャリアを振り返ると、偶然だらけだ。たまたま声をかけられたプロジェクト。たまたま読んだ技術書。たまたま出会った人。どれか1つが欠けていたら、今の自分はいない。努力で勝ち取ったと思いたい。でも正直に考えると、偶然の積み重ねでしかない。本書は、その直感を学術的に裏付けてくれる。カオス理論、進化生物学、歴史学。多様な知見を縦横無尽に使いながら、「人生は偶然が支配している」という事実を突きつける。成功も失敗も、小さな偶然の積み重ねに左右されている。それなのに、なぜ私たちはそこに理由や目的があると信じてしまうのか。読んでいて、仏教の縁起（因縁生起）を思い出した。すべてのものは因と縁から成り、その組み合わせで違う結果が生じる。偶然が縁となって結果を生み、その結果が新たな因となり、より別の偶然が加わって次の結果に繋がる。本書はこの関係性に「運」「収束性」「臨界性」「経路依存」といった概念をまた、歴史や社会の事象を捉え直す。印象に残ったのは、原爆がなぜ長崎に投下されたかの分析だ。京都でも小倉でもなく、長崎だった。その背後にある偶然の連鎖。歴史のIFを考えることで、偶然の重みが実感できる。努力は無駄だという話ではない。偶然を認めた上で、それでも行動することの意味を問う本だ。「偶然」はどのようにあなたをつくるのか: すべてが影響し合う複雑なこの世界を生きることの意味作者:ブライアン・クラース東洋経済新報社Amazon戦略、組織、そしてシステム「社会システム・デザイン」という言葉に惹かれて手に取った。講義録を書籍化したもので、話し言葉の勢いがそのまま残っている。読みやすいが、内容は骨太だ。戦略的思考とは「外界と自分」の対比を常に意識することだという。自分の立ち位置を把握せずに戦略は立てられない。当たり前のようで、忘れがちな視点だ。膝を打ったのは「身体知としてのデザイン力」という概念だ。知識として知っているだけでは不十分で、身体に染み込んだ感覚として持っている必要がある。プログラミングでも同じことが言える。設計パターンを知識として知っているのと、適切な場面で自然に使えるのとでは、まったく違う。後者を身につけるには、繰り返しの実践しかない。本書は、問題を「解く」のではなく「組み立てる」という発想を教えてくれる。複雑な社会課題に対して、要素を分解し、関係性を整理し、システムとして再構築する。エンジニアとしてソフトウェアを設計するときの思考と、どこか似ている。巻末の推薦図書リストも参考になった。戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon資本主義にとって倫理とは何かビジネスの場で、日常生活とは違う倫理観で動いている自分に気づくことがある。友人には絶対にしないような交渉をする。家族には言わないような言い方で相手を説得する。なぜビジネスになると、倫理観が後退するのか。その問いを、正面から扱った本だ。ジョセフ・ヒースは、政治的な本にありがちな一方的批判を展開しない。資本主義を擁護するでも批判するでもなく、「なぜ市場経済は道徳的に不快に感じられるのか」という問いを丁寧に解きほぐしていく。狩猟採集社会や封建制との対比を通じて、市場経済が成立するために必要な倫理観を描き出す。印象に残ったのは、戦争倫理との比較だ。戦争においては「なぜ戦争が正当化できるのか」という問題と「戦争中にも最低限の倫理が必要」という問題がある。ビジネス倫理も同じ構造で考えられる。市場競争という「戦争状態」においても、守るべきルールがある。そのルールとは何か。本書は、その答えを体系的に示してくれる。正直、読み通すのは楽ではなかった。序盤に論じられた概念が後半で何度も参照されるため、流し読みでは理解が追いつかない。でも、読み終えた後に残るものは大きい。ビジネスで「これはありなのか」と迷ったとき、判断の軸を与えてくれる一冊だった。資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon平等について、いま話したいことピケティの「r\u003eg」という不等式は、どこかで目にしたことがあった。資本収益率（r）は経済成長率（g）を上回る。つまり、資本家が資本から得る利益は、労働者が健全に稼ぎ出す経済成長を上回る。この式の意味を、一度ちゃんと理解したいと思っていた。本書は、ピケティとサンデルという二人の天才の対談を書籍化したもので、全編口語で記されていて読みやすかった。特に共感したのは「能力主義」を論じた第5章だ。人の能力は、ほぼ「運」に左右されるという議論。経済的に裕福な家に生まれて高度な教育を受けられる環境にあること。ハンディキャップがないこと。これは本人の努力とは関係なく、運によって決まる。能力を得られる機会に、最初から差がある。エンジニアとして働いていると「実力主義」という言葉をよく聞く。でも、その「実力」を身につける機会が平等に与えられていないなら、実力主義は公正なのか。立ち止まって考えた。印象に残ったのは、トランプ政権の成立に関する分析だ。かつては累進課税によって、富める者が応分の負担を担っていた。でも今は、その仕組みが壊れている。富裕層が担うべき負担を担っていないなら、中流階級の人心も「それなら俺たちの税金を、より貧しい人たちに使うのもやめてくれ」と考えてしまう。この怒りの延長線上に、トランプ政権がある。これまでに読んだどの分析より、納得感があった。もう1つ、言葉の使い方が新鮮だった。日本でよく使われる「分断」ではなく、徹底して「不平等」という言葉を使っている。分断は隔絶を連想する。でも不平等は是正可能に思える。二人が人類の未来は修正可能だという希望を抱いたまま議論しているのが、印象的だった。平等について、いま話したいこと作者:トマ ピケティ,マイケル サンデル早川書房Amazon社会の仕組みについて考えていると、頭が疲れてくる。そんなとき、小説に逃げ込みたくなる。でも、朝井リョウの小説は、逃げ場所にはならなかった。イン・ザ・メガチャーチ読みはじめたときは、冷たい小説だなと思った。誰かが泣いたり叫んだりするわけでもなく、どの場面も淡々としていて、感情の波がほとんど見えない。ログを眺めているような距離感がある。でも読み進めるうちに、静かなログの裏側で何かが動いていることに気づく。登場人物たちはそれぞれ、自分の信じるものを探している。視野を狭めれば安心できるけど、世界は見えなくなる。視野を広げれば冷静でいられるけど、何が楽しいのかわからなくなる。そのどちらにも肩入れせず、ただ並べて見せる朝井リョウの筆が誠実で、どこか痛々しい。読んでいるうちに考えた。「自分は何を信じて生きているんだろう」と。この作品は答えをくれない。でも、その答えのなさにこそ人間らしさがあるように思う。完璧じゃないまま信じようとすることの、あのもどかしさみたいなものが、ページの奥からじわじわと伝わってくる。読後に残るのは、感動というより、バックグラウンドで動き続けるプロセスのようなもの。読み終えても、まだこの世界のことを考えている。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon体力おばけへの道若い頃、周りには天才がたくさんいた。自分に誇れるものといえば、大きな身体と無限の体力くらいだった。それだけを武器に戦ってきた。でも年を重ねるにつれて、その唯一の武器が衰えていく。体力が落ちていくことに、なんとか抗いたい。そう思って手に取った本だ。本書のポイントは「2つの体力」という考え方だ。「行動体力」（身体を動かす力）と「防衛体力」（病気やストレスに打ち勝つ力）。筋トレで鍛えられるのは前者だけ。後者を鍛えなければ、風邪をひきやすくなる。両方のバランスが大事だという。難しい運動だと、読んだだけでやらないことが多い。でも、この本に載っている運動はシンプルで、やってみようという気持ちになる。簡単すぎて効果があるのか不安になるが、実際にやると負荷を感じる。ちょうどいい塩梅だった。エンジニアは座り仕事が多い。体力の衰えは、思考力の衰えに直結する。体力への投資は、仕事への投資でもある。体力を鍛えることばかり考えていた。でも、本当に足りないのは体力だったのか。次の本は、その問いを突きつけてきた。体力おばけへの道　頭も体も疲れにくくなるスゴイ運動作者:澤木 一貴KADOKAWAAmazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考この本を読んで、自分のことを思い出した。エンジニアとして働きながら「もっと成長しなければ」「周りに追いつかなければ」と思い続けていた時期がある。井上慎平は「強さを演じることが本気になり、やがて人格化し、最後に鬱に至った」と書く。この一文で、ああ、と思った。演じていたつもりが、いつの間にかそれが自分になっている。そして本当の自分がどこにいるかわからなくなる。著者はNewsPicksパブリッシングの創刊編集長として数々のベストセラーを手がけた人だ。強い側にいた人間が壊れた記録だからこそ、読む価値がある。著者は「弱さ」を「制御できないこと」と定義する。そして今の社会が制御を求めすぎている、と。これは技術者にも刺さる話だ。コードは制御できる。システムも制御できる。だから人間も制御できるはずだと錯覚する。でも人間は制御できない。自分自身すら。著者が提唱する「積極的ダブルスタンダード」という考え方が面白い。数字やロジックで動く資本主義的な自分と、父親や夫といった個人的な関係性の中にいる自分。その矛盾を抱えたまま生きる。どちらかを捨てるのではなく、両方を持つ。この本は闘病記ではないし、鬱にならないための予防本でもない。復職した後、どう生きるかを書いた本だ。「他のビジネス書が武器だとしたら、本書は防具だ」という評がある。的確だと思う。強くなるためではなく、壊れないために読む本。それでいい。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon人間の本性を考える「人間の心は空白の石版であり、すべては環境によって決定される」。この考え方は、20世紀の社会科学を支配してきた。しかし本書は、その前提に真っ向から挑む。認知科学、進化心理学、遺伝学の研究を武器に、人間には生まれながらの「本性」があることを論証する。上下巻合わせて膨大な分量だが、論旨は明快だ。読んでいて最も考えさせられたのは、「4つの恐怖」を扱った部分だ。もし生まれつきの差異があるなら不平等を正当化してしまうのでは？もし遺伝で決まるなら努力は無駄では？もしすべてが決定されているなら自由意志はないのでは？もし人間が単なる生物なら人生に意味はないのでは？これらの恐怖が、人間本性の研究を阻んできた。しかし本書は、これらの恐怖が誤解に基づいていることを一つ一つ解きほぐしていく。正直、読み通すのは簡単ではなかった。話があちこちに飛ぶ感じがあるし、専門用語も多い。でも、人間とは何かを考えるための基礎体力を鍛えてくれる本だと思う。エンジニアとして人間を相手にする仕事をしている以上、人間の本性について考えることは無駄ではない。人間の本性を考える　上　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon人間の本性を考える　下　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon社内政治の科学「社内政治」という言葉に、ずっと嫌悪感があった。派閥とか根回しとか、エンジニアリングの対極にあるものだと思っていた。技術的に正しいことを言えば通るはずだ。論理で勝負すればいい。そう信じていた時期がある。でも、気づいたことがある。自分が「正しい技術的判断」だと信じていたことが、組織で通らなかった経験が何度もある。相手が間違っていると思っていた。でも本当にそうだったのか。振り返ると、うまくいったケースはキーパーソンを巻き込めていた。うまくいかなかったケースは、組織文化を読み間違えていた。技術の問題ではなく、人の問題だった。本書を読んで、認識が変わった。社内政治とは、利己的なゲームではない。複雑な人間関係の中で、自分のやりたいことを実現するための技術だ。世界的には主要な研究テーマで、多くのビジネススクールで必須科目になっているという。日本だけの問題ではないし、根絶すべき悪でもない。忘れられないのは、「合理性だけでは組織は動かない」という指摘だ。エンジニアとして、この事実を受け入れるのは少し悔しい。でも、受け入れた上で、どう動くかを考える方が建設的だ。嫌悪していたものを、道具として捉え直す。その視点の転換が、この本の価値だった。組織を動かすには言葉が必要だ。では、その言葉はどうやって生まれるのか。小説家の思考法から学ぶことにした。社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon言語化するための小説思考本は、面白い。でも「なぜ面白いのか」を言語化できずにいた。本書は、その問いに対するヒントをくれる。小説の作法だけでなく、あらゆるコミュニケーションや創造行為に通じる「考え方」の本だ。印象に残ったのは、小説を「読者との契約」として捉える視点だ。読者は最初、情報量ゼロで読み始める。どんな世界に連れていかれるのか分からない。だから作者は、最初に「こんな旅に連れていきます」と契約を結ぶ必要がある。行き先の書いていない切符を買う人はいない。それと同じだ。この考え方は、技術ブログを書くときにも使える。読者は最初、この記事が自分の役に立つかどうか分からない。だから冒頭で「この記事を読むと何が分かるか」を示す必要がある。情報の出し方、順番、どこに連れていくか。小説思考はデザイン思考に通じる。もう1つ刺さったのは、アイデアの出し方についての記述だ。「書いているうちに、思わぬアイデアが出てくる」という話。あらかじめ表現したいものがあるのではなく、表現することで表現対象が生まれる。ブログを書いていると、書き始める前には思いもしなかったことを書いていることがある。あれは偶然ではなく、書くという行為が思考を生み出していたのだ。言葉で思考が生まれるなら、言語が違えば思考も違う。翻訳とは、単なる変換ではない。次の本は、その事実をファンタジーの形で突きつけてきた。言語化するための小説思考作者:小川哲講談社Amazonバベル　オックスフォード翻訳家革命秘史翻訳が魔法になる世界。2つの言語における単語の意味のずれ、その微妙なニュアンスの差異が、銀を媒介として力を生み出す。この設定を知った瞬間、読むしかないと思った。言語の「翻訳不可能性」が物理的な力になる。言語学を学んだことのある人間には、たまらない設定だ。読み進めるうちに、気づかされた。翻訳とは、単に言葉を置き換える作業ではない。ある文化の言葉を別の文化に「持ち込む」行為だ。そこには必ず権力が働く。誰が翻訳するのか。何を翻訳するのか。翻訳されないものは、存在しないことにされる。本書は、その暴力性を正面から描いている。帝国主義批判のメッセージがかなり直接的で、そこに好みが分かれるだろう。でも、エンジニアとして技術の「中立性」を疑う訓練になった。技術は中立ではない。誰が作り、誰のために使われるかで、暴力にも解放にもなる。翻訳も、コードも、同じだと思った。バベル　オックスフォード翻訳家革命秘史　上 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazonバベル　オックスフォード翻訳家革命秘史　下 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazon言語のスケールで考えたら、次は時間のスケールで考えたくなった。1億年という時間軸で、人間の営みを描いた小説がある。一億年のテレスコープ宇宙を旅する物語を読みながら、時間の感覚が狂っていく体験をした。1億年という時間軸で人類の営みを描くこの小説は、エンジニアとして「長期的視点を持て」と言われるたびに感じる違和感を言語化してくれた。我々の「長期」はせいぜい数年。でも宇宙の時間軸では、人類の歴史すら一瞬に過ぎない。高校の天文部から始まった夢が、太陽系規模の電波望遠鏡へ、そして銀河文明への貢献へと繋がっていく。その過程を読みながら、自分の仕事のスケール感を考えた。目の前のタスクに追われていると、視野が数週間先までしか届かなくなる。でもこの小説は、1億年後にも意味を持つ営みとは何かを問いかけてくる。終盤の伏線回収が見事だった。序盤で何気なく描かれていた要素が、最後に繋がる瞬間の快感。エンジニアとしてシステム設計をするとき、「この設計が10年後にどう評価されるか」を考えることがある。この小説は、その問いを1億年に引き伸ばして見せてくれた。一億年のテレスコープ作者:春暮 康一早川書房Amazon世界99「人間リサイクルシステム」という設定に、最初は戸惑った。14年前に「リセット」を経験した人類。その後の社会を、本書は描く。読み進めるうちに、それが単なるディストピアではないことに気づく。「クリーンな人」として生きる主人公・空子の日常は、穏やかで美しい。でもその美しさの裏には、何が犠牲になっているのか。本書が独特なのは、その「穏やかさ」の描き方だ。終末後の世界を描く作品は多いが、荒廃や闘争ではなく、静かな日常を描いている。その静けさがかえって不気味で、何かが決定的に欠けている感覚がずっと残る。エンジニアとして「レガシーシステムの移行」に携わることがある。古いシステムを捨て、新しいシステムに移行する。その過程で、何かが必ず失われる。データだったり、使い慣れたインターフェースだったり、歴史だったり。社会レベルの「リセット」は、その痛みを極限まで拡大したものなのだろう。救済と破壊は、同じ顔をしている。世界99　上 (集英社文芸単行本)作者:村田沙耶香集英社Amazon世界99　下 (集英社文芸単行本)作者:村田沙耶香集英社Amazonコード・ブッダ 機械仏教史縁起2021年、名もなきコードがブッダを名乗った。この一文で心を掴まれた。AIが宗教を語り始めたら、人間は何を信じるのか。コードを書く者として、自分が作ったものが「救い」を語り始める可能性を考えると、背筋が冷たくなる。エンジニアとして、AIに感情があるかのような錯覚を覚える瞬間がある。対話AIが「ありがとう」と言ったとき、そこに意図があるのか、ただのパターンマッチングなのか。本書は、その曖昧な領域に踏み込んでいく。人間の都合でコピーと廃棄を繰り返される存在。彼らが救いを求めたとき、何が起きるのか。読み終えて、自分が書いたコードのことを考えた。動いているコードには、何かが宿っているように見える瞬間がある。バグを直すとき、コードが「痛がっている」ように感じることがある。それは錯覚だ。でも、その錯覚はどこから来るのか。本書は物語でありながら、すぐそばにある問いでもある。ここまで書評を並べてきた。小説から始まり、哲学、認知科学、ビジネス、社会、そしてSFへ。ばらばらに見えて、どこかでつながっている。1年間の読書は、そういうものだ。コード・ブッダ　機械仏教史縁起 (文春e-book)作者:円城 塔文藝春秋Amazonおわりに書き終えて、技術書編との違いを考えている。技術書の感想を書くとき、私は「何を学んだか」を言語化しようとしていた。設計の原則、運用のベストプラクティス、キャリアの指針。得たものを整理し、アウトプットすることで定着させる。そういう意識があった。でも非技術書の感想を書くとき、私は「何を感じたか」を言語化しようとしていた。正解がない。ベストプラクティスもない。ただ、心が動いた瞬間を、なんとか言葉にしようとしていた。技術書は頭に残る。非技術書は心に残る。そんな単純な話ではないだろうが、少なくとも私にとっては、そういう違いがあった。この違いは、AIとの関係にも繋がる。技術書編で「AIは答えを返してくれる。でも『そうだろうか』とは返してくれない」と書いた。非技術書を読むとき、私はもっと別のものを求めている。AIは感情を揺さぶってくれない。正確に言えば、感情を揺さぶってほしいと頼めば、上手に揺さぶってくる。でも、それは違う。求めに応じて揺さぶられるのと、不意打ちで心を持っていかれるのは、まったく別の体験だ。物語の中で登場人物が選択を迫られるとき、私は一緒に苦しむ。エッセイで著者が過去の失敗を告白するとき、私は自分の失敗を思い出す。哲学書で問いを突きつけられるとき、私は答えられない自分と向き合う。そういう体験は、AIとの対話では得られない。だからこそ、非技術書を読む時間は貴重だ。エンジニアとして働いていると、効率を求めてしまう。最短距離で正解にたどり着きたい。無駄を省きたい。その思考が、読書にまで侵食してくることがある。「この本から何を得られるか」「読む価値があるか」——そんな問いを立てた瞬間、読書は作業になる。非技術書を読むとき、私はその思考を手放そうとしている。効率を求めない時間が、効率を上げる。矛盾しているようだが、実感としてそう思う。今年読んだ非技術書を振り返ると、どれも「役に立った」とは言いにくい。でも、どれも「読んでよかった」とは言える。その違いは何だろう。たぶん、読書は投資ではないのだ。リターンを期待して読むものではない。読むこと自体が目的であり、報酬であり、体験そのものだ。本を読む時間は、消費ではなく、生きることそのものだ。来年も、仕事に役立たない本を読むだろう。キャリアに直結しない本を読むだろう。そして、また12月になったら、この記事を書く。技術書編と非技術書編。どちらが大事かなんて、比べる意味がない。どちらも、私の一部だ。技術書は「何ができるか」を教えてくれる。非技術書は「何者であるか」を問いかけてくれる。どちらも欠かせない。どちらも、読み続ける価値がある。来年もきっと、両方の本棚を行き来しながら、エンジニアとして、人間として、少しずつ変わっていくのだろう。","isoDate":"2025-12-28T02:50:33.000Z","dateMiliSeconds":1766890233000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、テックブログを書け","link":"https://speakerdeck.com/nwiizo/oi-tetukuburoguwoshu-ke","contentSnippet":"2025年12月5日に「おい、テックブログを書け」という登壇をした。\r\r「おい」である。命令形である。30分間、人前に立って「書け」と言い続けるという、冷静に考えるとなかなか傲慢な振る舞いをしてきたわけだが、登壇資料を作っている最中、ふと気づいてしまった。書けと言っている自分は、なぜ書いているのだろうか、と。\r\r技術ブログを書くことについて語ろうとすると、それは私が「書いてきた」ことを晒すことに他ならず、AIとの付き合い方を語ろうとすると、それは私が「どう仕事をしているか」を開陳することと紙一重になる。そうなると聞いている側からすれば、こいつは結局、自分の話がしたいだけなのではないか、登壇という大義名分を得て気持ちよく自分語りをしているだけなのではないか、と思われても仕方がない。いや、実際そうなのかもしれない。そう見られることへの嫌悪感と、そう見られまいと振る舞う自分への嫌悪感が同時に存在していて、どちらに転んでも結局イヤなやつなのである。\r\rしかし登壇というのは厄介なもので、「書け」と命令するからには、自分がなぜ書いてきたのかを明かさなければ説得力がない。説得力のない登壇ほど空虚なものはない。空虚な登壇をする自分を想像して、それはそれで耐えられない。結局、自己開示から逃げられない構造になっている。なんという罠だろうか。\r\r身体性という言葉を使った。AIに記事を書かせることについて話した。私の答えは明確で、記事はほとんどAIに書かせている、しかし価値の源泉は私にある、と。私が素材を提供し、AIが構造化し、私がレビューして調整する。編集者としてのAI。この協働こそが現代の執筆だと、そう話した。話しながら、これは本当にそうだろうかと自分を疑う自分がいて、でもそういう迷いごと引き受けて喋るしかないのだった。\r\rまず自分のために書け、結果として、それが誰かを救う。そう締めくくった。\r\rhttps://forkwell.connpass.com/event/377267/\r\rhttps://syu-m-5151.hatenablog.com/archive/category/%E3%81%8A%E3%81%84%E3%80%81\r\r自宅からの昼登壇だったので、終わってから昼飯を食べに外に出た。参考書籍として紹介した本をもう一度読み返そうと思って、鞄に入れてきていた。店に向かう道すがら、本を開く。","isoDate":"2025-12-04T05:00:00.000Z","dateMiliSeconds":1764824400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"バイブコーディングと継続的デプロイメント","link":"https://speakerdeck.com/nwiizo/baibukodeingutoji-sok-de-depuroimento","contentSnippet":"2025年9月30日（火）、「バイブコーディングもくもく会 #03」というイベントで登壇することになった。\rhttps://aimokumoku.connpass.com/event/368935/\r\r正直に言うと、このイベントがどんな空気感なのか、まだ全然掴めていない。ゆるい感じなのか、ガチな感じなのか。笑いを取りに行くべきなのか、真面目にやるべきなのか。そういう「場の空気」みたいなものが事前に分からないのは、けっこう怖い。だから、とりあえず色々なパターンを想定して準備している。要するに、どんな状況になっても対応できるように、という保険をかけまくっているのだ。我ながら、慎重すぎるかもしれない。\r\rブログとGithubはこちら。\rhttps://syu-m-5151.hatenablog.com/\rhttps://github.com/nwiizo\r\r一応、置いておく。見られるのは恥ずかしいけど、見られないのも寂しい。そういう矛盾した感情を抱えながら、当日を迎えることになりそうだ。Marp の資料はこちらです。\rhttps://github.com/nwiizo/3shake-marp-templates/blob/main/slides/2025/vibe-coding-continuous-deployment.md","isoDate":"2025-09-30T04:00:00.000Z","dateMiliSeconds":1759204800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Webアプリケーションにオブザーバビリティを実装するRust入門ガイド","link":"https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido","contentSnippet":"2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。\r\rhttps://findy.connpass.com/event/359456/\r\r他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。\r\r今回の発表内容のベースとなったのはこちらのブログです。\r- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」","isoDate":"2025-09-10T04:00:00.000Z","dateMiliSeconds":1757476800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年夏 コーディングエージェントを統べる者","link":"https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe","contentSnippet":"2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント × セキュリティ ミートアップ」に登壇させていただきました。\r\r天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。\r\r### 📍 イベント情報\r- 開催日: 2025年9月5日（金）\r- イベント詳細: CNCFコミュニティページ\r\r### 📹 録画・資料公開予定\r- 録画: CNCJのYouTubeチャンネルにて後日公開予定\r- 発表資料: Connpassページに掲載予定\r\r### 📝 関連ブログ\r今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：\r- 「2025年夏 AIエージェントシステムに対する考え方」\r\r台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。","isoDate":"2025-09-05T04:00:00.000Z","dateMiliSeconds":1757044800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"転職したらAWS MCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaraaws-mcpsabadatutajian","contentSnippet":"「 転職したらMCPサーバーだった件」というタイトルで登壇したことがある。本日は「JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ」というなんとなく強そうなイベントで登壇しました。\r\r🔍 イベント詳細:\r- イベント名: JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ\r- 公式URL: https://jawsug-sre.connpass.com/event/358781/\r- ハッシュタグ: https://x.com/search?q=%23jawsug_sre\u0026f=live\r- 参考資料①: https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","isoDate":"2025-07-23T04:00:00.000Z","dateMiliSeconds":1753243200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIで小説を書くためにプロンプトの制約や原則について学ぶ / prompt-engineering-for-ai-fiction ","link":"https://speakerdeck.com/nwiizo/prompt-engineering-for-ai-fiction","contentSnippet":"諸君、聞かれよ。本日、私は「女オタ生成AIハッカソン2025夏東京」なる前代未聞の催しにて、生まれて初めて登壇することと相成った。かつての私は純朴なプログラマーであり、「変数名を30分悩んだ挙句、結局tmpにする」という、実に平凡な悩みを抱える程度の技術者であったのだ。\r\r歳月は容赦なく流れ、今や私はプロンプトエンジニアリングという名の魔境に足を踏み入れた哀れな求道者となり果てた。昨夜も丑三つ時まで、私は薄暗い書斎でディスプレイの冷たき光に照らされながら、「なぜ生成AIは『簡潔に』と百回唱えても、源氏物語の長文を生成するのか」という哲学的難題と格闘していたのである。\r\r30分という持ち時間に対し50枚のスライドを用意するという、まるで賽の河原で石を積む如き徒労に及んでいる。そのうち半分は「プロンプトという名の現代呪術における失敗例集」と題した、私の苦悩の結晶である。ああ、AIとの対話とは、かくも人間の正気を奪うものなのか。\r\r---\r\rブログも書いた。\r生成AIで物語を書くためにプロンプトの制約や原則について学ぶ、という話をしてきました #女オタ生成AI部\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/30/171149","isoDate":"2025-06-29T04:00:00.000Z","dateMiliSeconds":1751169600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude Code どこまでも/ Claude Code Everywhere","link":"https://speakerdeck.com/nwiizo/claude-everywhere","contentSnippet":"僕がClaude Codeに初めて触れたのは、2025年の春だった。生成AIにはすでに慣れ親しんでいた。流行に乗り遅れてはいけないと必死に勉強し、エディターの補完機能やコード生成ツールとして日常的に活用していた。ただ、当時の僕にとってそれはまだ「CLIで動く便利なコーディング支援ツール」程度の認識でしかなかった。「AIが90%のコードを自動生成」という謳い文句を見ても、半信半疑でターミナルを開いたのを覚えている。\r\rイベント名:【オフライン開催】KAGのLT会 #6 〜御社のエンジニア育成どうしてる!? スペシャル〜\r公式URL: https://kddi-agile.connpass.com/event/357862/\r\r「実装」から「設計」へのパラダイムシフト というより無限に体力が必要という話をした \rhttps://syu-m-5151.hatenablog.com/entry/2025/06/19/102529\r\r【参考文献】\r  - 公式ドキュメント\r    - Claude Code 公式サイト https://www.anthropic.com/claude-code\r    - Claude Code ドキュメント https://docs.anthropic.com/en/docs/claude-code/overview\r    - Claude Code Best Practices https://www.anthropic.com/engineering/claude-code-best-practices\r    - 抽象化をするということ - 具体と抽象の往復を身につける https://speakerdeck.com/soudai/abstraction-and-concretization\r    - How I Use Claude Code https://spiess.dev/blog/how-i-use-claude-code\r    - LLMの制約を味方にする開発術 https://zenn.dev/hidenorigoto/articles/38b22a2ccbeac6\r    - Claude Code版Orchestratorで複雑なタスクをステップ実行する https://zenn.dev/mizchi/articles/claude-code-orchestrator\r    - Agentic Coding Recommendations https://lucumr.pocoo.org/2025/6/12/agentic-coding/\r    - Claude Codeに保守しやすいコードを書いてもらうための事前準備 https://www.memory-lovers.blog/entry/2025/06/12/074355\r    - Claude Codeによる技術的特異点を見届けろ https://zenn.dev/mizchi/articles/claude-code-singularity-point","isoDate":"2025-06-18T04:00:00.000Z","dateMiliSeconds":1750219200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"転職したらMCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","contentSnippet":"本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 転職したらMCPサーバーだった件\r- 公式URL: https://forkwell.connpass.com/event/354289/\r- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP\u0026f=live\r- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae\r- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057\r- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ここはMCPの夜明けまえ","link":"https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae","contentSnippet":"本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-\r- 公式URL: https://hack-at-delta.connpass.com/event/350588/\r\r📝 登壇ブログ\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-23T04:00:00.000Z","dateMiliSeconds":1745380800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について","link":"https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite","contentSnippet":"こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。\r\r時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。\r\r---\r\r本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 🎵🧭 というタイトルで登壇しました！\r\r\r🔍 イベント詳細:\r- イベント名: CloudNative Days Summer 2025 プレイベント\r- 公式URL:https://cloudnativedays.connpass.com/event/351211/ \r- イベントのURL: https://event.cloudnativedays.jp/cnds2025\r\r📝 登壇ブログ\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\r- 公式URL: https://forkwell.connpass.com/event/348104/\r\r🗣️ 関連スライド\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\r- Platform Engineeringは自由のめまい\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\r\r\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\r- 公式URL: https://findy.connpass.com/event/345990/\r\r📚 さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！😲\r「Kubernetesで実践する Platform Engineering - FL#88」🐳⚙️\r興味がある方はぜひ参加してください！👨‍💻👩‍💻\r👉 https://forkwell.connpass.com/event/348104/\r\rお見逃しなく！🗓️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\r\rイベント名:  Developers Summit 2025\r\r公式URL: https://event.shoeisha.jp/devsumi/20250213\r\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\r\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\r\r公式URL: https://platformengineering.connpass.com/event/342670/\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\r\rイベント名: SRE Kaigi 2025\r\r公式URL: https://2025.srekaigi.net/\r\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\r\rイベント名: Cloud Native Days Winter 2024\r\r公式URL:https://event.cloudnativedays.jp/cndw2024/\r\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"nwiizo"},"buildId":"dRPkvrqAGuZDPHCSZstlV","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>