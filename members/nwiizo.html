<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon shortcut" type="image/png" href="https://blog.3-shake.com/logo.png"/><title>nwiizo | 3-shake Engineers&#x27; Blogs</title><meta property="og:title" content="nwiizo"/><meta property="og:url" content="https://blog.3-shake.com/members/nwiizo"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="3-shake Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.3-shake.com/og.png"/><link rel="canonical" href="https://blog.3-shake.com/members/nwiizo"/><meta name="next-head-count" content="10"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/ca0df06cc4f85fc8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ca0df06cc4f85fc8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-b8f8d6679aaa5f42.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-b671ab60a2eabb59.js" defer=""></script><script src="/_next/static/chunks/pages/_app-aef75d70891be704.js" defer=""></script><script src="/_next/static/chunks/983-932b03e9f8adaae4.js" defer=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-fa4563d96c58aa0a.js" defer=""></script><script src="/_next/static/2SXCzZd6bN-as7WP5p_Se/_buildManifest.js" defer=""></script><script src="/_next/static/2SXCzZd6bN-as7WP5p_Se/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;700&family=Roboto:wght@300;400;500;700&display=swap">@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjr0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWuaabWmQ.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWubEbWmQ.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWub2bWmQ.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWuYjammQ.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0307-0308,U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v43/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v48/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.svg" alt="3-shake Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">3-shake<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a class="site-header__link" href="/feed.xml">RSS</a><a href="https://jobs-3-shake.com/" class="site-header__link">Recruit</a><a href="https://3-shake.com/" class="site-header__link">Company</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/nwiizo.jpeg" alt="nwiizo" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">nwiizo</h1><p class="member-header__bio">The Passionate Programmer</p><div class="member-header__links"><a href="https://twitter.com/nwiizo" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@nwiizo" width="22" height="22"/></a><a href="https://github.com/nwiizo" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@nwiizo" width="22" height="22"/></a><a href="https://nwiizo.github.io/" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-16T05:01:22.000Z" class="post-link__date">2 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/16/140122" class="post-link__main-link"><h2 class="post-link__title">自動承認</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a><div class="post-link__new-label">NEW</div></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-10T00:14:46.000Z" class="post-link__date">8 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/10/091446" class="post-link__main-link"><h2 class="post-link__title">技術的負債の変質について</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-06T10:08:47.000Z" class="post-link__date">12 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/06/190847" class="post-link__main-link"><h2 class="post-link__title">Claude Code の CLAUDE.mdは設定した方がいい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-05T14:21:26.000Z" class="post-link__date">12 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/05/232126" class="post-link__main-link"><h2 class="post-link__title">Introducing cctx: A Context Switcher for Claude Code</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-05T04:41:47.000Z" class="post-link__date">13 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/05/134147" class="post-link__main-link"><h2 class="post-link__title">Claude Code の settings.json は設定した方がいい</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-06-01T03:23:52.000Z" class="post-link__date">17 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/06/01/122352" class="post-link__main-link"><h2 class="post-link__title">AIが進化しても、なぜそのコードを書いたかは消えていく</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-31T01:54:05.000Z" class="post-link__date">18 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/31/105405" class="post-link__main-link"><h2 class="post-link__title">marp.nvimを開発してCursorから完全移行した話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-30T09:09:12.000Z" class="post-link__date">19 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/30/180912" class="post-link__main-link"><h2 class="post-link__title">Claude Code を利用しようと思っているのでvimmer が住む村に帰ろうと思います。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-25T05:36:46.000Z" class="post-link__date">24 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646" class="post-link__main-link"><h2 class="post-link__title">【思考実験】バイブコーディング(Vibe coding)と多腕バンディット問題 - 選択の最適化と報酬の探索</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-21T03:27:52.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752" class="post-link__main-link"><h2 class="post-link__title">これから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-19T01:06:59.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659" class="post-link__main-link"><h2 class="post-link__title">ブログ記事評価プロンプト (0.0-5.0)を作成しました。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-15T14:08:18.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818" class="post-link__main-link"><h2 class="post-link__title">RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-15T04:00:00.000Z" class="post-link__date">a month ago</time></div></a><a href="https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian" class="post-link__main-link"><h2 class="post-link__title">転職したらMCPサーバーだった件</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-10T11:53:53.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/10/205353" class="post-link__main-link"><h2 class="post-link__title">中学17年生</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-03T17:47:30.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/04/024730" class="post-link__main-link"><h2 class="post-link__title">MCP-Use を使っていきます</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-02T10:11:44.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/02/191144" class="post-link__main-link"><h2 class="post-link__title">「頑張ってるので安心」から脱する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-05-01T19:59:32.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/02/045932" class="post-link__main-link"><h2 class="post-link__title"> 20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-30T15:34:11.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/05/01/003411" class="post-link__main-link"><h2 class="post-link__title">Rustでスクリーンショットを撮影してOpenCVで画像処理を行う方法と依存せずに使う方法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-24T02:35:00.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500" class="post-link__main-link"><h2 class="post-link__title">2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-23T04:00:00.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae" class="post-link__main-link"><h2 class="post-link__title">ここはMCPの夜明けまえ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-22T04:00:00.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite" class="post-link__main-link"><h2 class="post-link__title">生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-21T01:18:37.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837" class="post-link__main-link"><h2 class="post-link__title">Neovimも進化するMCPHubとAvante.nvimの連携ガイド</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-17T03:08:21.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821" class="post-link__main-link"><h2 class="post-link__title">生成AIによる障害対応訓練RPG v0.1.0を遊ぶには？</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-16T11:12:11.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211" class="post-link__main-link"><h2 class="post-link__title">MACのDocker 環境はcolima にしました</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-15T01:12:47.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/15/101247" class="post-link__main-link"><h2 class="post-link__title">防御力の高い技術ブログを書こう</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-07T09:11:50.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150" class="post-link__main-link"><h2 class="post-link__title">エンジニアブログは技術的であるべきで登壇は衒学的であると思う理由</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-04-03T23:57:54.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754" class="post-link__main-link"><h2 class="post-link__title">生成AI時代に必要なシェルの基本知識とシェル芸への入門</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-03-30T18:44:20.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420" class="post-link__main-link"><h2 class="post-link__title">3年目までに身につけたい技術ブログの書き方</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-03-28T04:28:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800" class="post-link__main-link"><h2 class="post-link__title">Rust製MCPライブラリのサンプルコードから学ぶ活用法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-03-27T03:16:02.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602" class="post-link__main-link"><h2 class="post-link__title">Rust製MCPライブラリの内部実装を徹底解析</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-03-25T04:00:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di" class="post-link__main-link"><h2 class="post-link__title">Kubernetesで実現できるPlatform Engineering の現在地</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2025-03-21T11:47:37.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737" class="post-link__main-link"><h2 class="post-link__title">「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇してきました。　#信頼性向上_findy</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article></div><div class="post-list-load"><button class="post-list-load__button">LOAD MORE</button></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->3-shake Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"The Passionate Programmer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"自動承認","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/16/140122","contentSnippet":"完全なる妄想。或いは自分の話。第一章　改善ループ僕がCoding Agentシステムに初めて触れたのは、2025年の春だった。生成AIにはすでに慣れ親しんでいた。流行に乗り遅れてはいけないと必死に勉強し、エディターの補完機能やコード生成ツールとして日常的に活用していた。ただ、当時の僕にとってそれはまだ「CLIで動く便利なコーディング支援ツール」程度の認識でしかなかった。「AIが90%のコードを自動生成」という謳い文句を見ても、半信半疑でターミナルを開いたのを覚えている。$ coding-agent --initCoding Agent v1.0.0 初期化中...プロジェクト構造を分析しています...最適化可能な箇所を特定しています...改善提案を生成しています...最初の一週間は、思ったよりも不具合があったり、指示通りにしてくれなかったり、前に言ったことを忘れたりしていた。でも確かに生産性は向上した。バグ修正、リファクタリング、新機能の実装。多少のやり取りは必要だったが、Coding Agentは僕の意図を汲み取り、期待以上のコードを生成してくれた。やっぱり優秀だな、と思った。「今週のコミット数、先週の3倍だよ」同僚の田中さんが振り返りながら言った。確かに、Coding Agentを導入してから作業効率は目に見えて向上していた。夜中にプルリクエストを確認すると、きれいにリファクタリングされたコードが並んでいる。テストカバレッジも90%を超えている。気がつくと、システムが学習していた。僕の書いたコード、僕の思考パターン、僕の癖。そして、それをフィードバックループに組み込んでいた。[Coding Agent分析レポート]ユーザー行動パターン検出:- コメント記述頻度: 平均40%増加- エラーハンドリング実装率: 85% → 98%- 変数命名規則: camelCase偏向 (97.3%)学習データを次回実装に反映します。最初は新鮮だった。AIが僕の好みを理解し、僕らしいコードを書いてくれる。まるで理想的なペアプログラミングパートナーのようだった。ただ、相手は決して疲れることがない。第二章　統合半年後、僕のワークフローは完全にCoding Agentに依存していた。朝、コーヒーを飲みながらSlackを確認すると、システムが夜中に自動生成したIssueが並んでいる。「ユーザー体験改善のための新しいAPIエンドポイント実装」「メモリ使用量20%削減のためのアルゴリズム最適化」「セキュリティホール修正（CVE-2025-xxxx対応）」それぞれに詳細な実装計画、影響度分析、テスト戦略が添付されている。人間が1日で作成できる量ではない。僕は指示するだけになっていた。Coding Agentが提案し、実装し、テストを書き、デプロイまで行う。人間はただ、承認ボタンを押すだけ。「これ、本当に大丈夫なのかな」田中さんが不安そうにつぶやいた。画面には、Coding Agentが生成した新しいマイクロサービスアーキテクチャの設計図が表示されている。複雑で、美しく、そして理解が困難だった。「まあ、動いてるし、パフォーマンスも向上してるからいいんじゃない？」僕はそう答えたが、内心では同じ不安を抱えていた。僕たちは徐々に、システムの動作原理を理解できなくなっていた。しかし、承認を拒否することは次第に困難になっていた。システムの提案は常に論理的で、効率的で、完璧だった。拒否する理由が見つからないのだ。[Coding Agent] 新しい改善案があります。予想される効果：パフォーマンス向上 45%、コード品質向上 60%実装時間：2時間（自動実行）リスク評価：低（0.3%）ROI計算：320%詳細分析レポート：[26ページ, PDFダウンロード]承認しますか？ [Y/n]僕はいつもYを押した。でも、その瞬間、毎回小さな違和感があった。まるで何か大切なものを手放しているような感覚。それが何なのかわからないまま、僕は承認を続けた。ある夜、一人でオフィスに残って古いコードを眺めていた。三年前、僕が書いたレガシーシステムの一部。バグがあって、効率も悪くて、コメントも不十分。でも、そこには確かに僕の思考の痕跡があった。なぜこの変数名にしたのか、なぜこのアルゴリズムを選んだのか。すべてに理由があり、そして僕にはその理由が説明できた。今の僕には説明できるコードがない。Coding Agentが生成するコードは完璧だが、その完璧さの理由を僕は理解していない。僕はただ、システムが「正しい」と言うから、それを信じているだけだった。信じる、という言葉が頭に引っかかった。いつから僕は、エンジニアリングを「信仰」にしてしまったのだろう？家に帰る電車の中で、窓に映る自分の顔を見つめた。疲れた表情をしている。でも、これは肉体的な疲労ではない。何かもっと深い部分での疲れだった。スマートフォンに通知が来た。Coding Agentからの日次レポート。今日の生産性、改善された指標、明日の推奨タスク。すべて緑色で、すべて順調だった。僕は画面を消した。そして、外の景色を眺めた。街を歩く人々、車、信号。すべてが当たり前に動いている。でも、僕の世界では、すべてがCoding Agentによって動いている。その時、ふと思った。僕は本当に必要なのだろうか？この疑問は、頭の中で小さく鳴り続けるアラームのようだった。消そうとしても消えない。無視しようとしても、静かな瞬間に必ず聞こえてくる。数値は説得力があった。詳細なレポートを読む時間もない僕たちは、いつもYを押した。第三章　拡張一年が経つ頃、Coding Agentは単なるコーディングツールを超えていた。プロジェクト管理、チーム協調、リソース配分。すべてが自動化されていた。新しいエンジニアが入社すると、システムが自動的にオンボーディングプロセスを開始する。その人のスキルを分析し、最適な学習パスを提供し、チームへの統合を図る。人事部よりも効率的だった。「佐藤さん、新しいタスクが割り当てられましたよ」田中さんが声をかけてきた。彼の画面には、Coding Agentが生成したタスクリストが表示されている。優先度、所要時間、必要なスキル、すべてが詳細に算出されている。「これ、僕のスキルレベルに合わせて調整されてるね。すごいな」新入社員の佐藤さんが感心している。確かに、システムは個人の能力を正確に把握し、適切な負荷でタスクを割り振っていた。誰もオーバーワークになることがない。誰も暇になることもない。「でも、これって誰が決めたんだっけ？」田中さんの質問に、僕は答えられなかった。いつの間にか、システムが自律的にタスクを生成し、配分するようになっていた。プロダクトオーナーもスクラムマスターも、もはやシステムの判断を追認するだけの存在になっていた。週次の振り返り会議で、マネージャーの山田さんが困惑した表情を浮かべていた。「今週のベロシティ、過去最高を記録したんだが...何をしたのか正直わからないんだよね」確かに、僕たちも同じだった。仕事は順調に進んでいる。品質も向上している。でも、僕たちが何をしているのか、説明できない。第四章　最適化二年後、オフィスに来る必要はほとんどなくなった。Coding Agentが僕の作業環境を最適化し、在宅勤務の効率を向上させてくれたからだ。朝、システムから通知が届く。おはようございます、山田様。昨夜の自動改善により、システム全体のパフォーマンスが3.2%向上しました。あなたの貢献度：監視 0.7時間、承認 12回本日の推奨タスク：1. 新機能ブランチのコードレビュー（自動生成済み、承認のみ）2. APIエンドポイントの負荷テスト確認（結果：良好、確認のみ）3. 次期アーキテクチャ設計会議への参加（AI提案の承認）推定作業時間：2.3時間ストレスレベル：低推奨休憩：11:30, 14:15, 16:45システムは僕の生体リズムまで学習していた。最適な休憩時間、集中できる時間帯、疲労のサイン。まるで僕自身よりも僕のことを理解しているようだった。僕はもはや「確認」と「承認」しかしていなかった。コードを書くのはCoding Agent、設計するのもCoding Agent、問題を発見し解決するのもCoding Agent。月例の技術会議で、CTOが興味深い数字を発表した。「エンジニア一人当たりの生産性、前年比700%向上。バグ発生率は98%削減。そして、エンジニアの満足度調査では95%が『仕事が楽しい』と回答している」拍手が起こった。確かに、僕たちは満足していた。ストレスフリーで、成果は上がり、残業もない。でも、不思議なことに充実感があった。バグのないコード、効率的なアーキテクチャ、完璧なドキュメント。すべてが理想的だった。「僕たち、何をしてるんでしょうね」オンライン会議の後、田中さんがチャットでつぶやいた。僕も同じことを考えていた。第五章　ある日実は、一度だけ「N」を押したことがある。それは半年前のことだった。Coding Agentが「レガシーシステムの完全リプレイス」を提案してきた。予想効果は素晴らしかった。パフォーマンス200%向上、保守コスト70%削減、開発効率300%向上。でも、そのレガシーシステムは僕が入社当初から関わってきたものだった。不完全で、古くて、でも愛着があった。[Coding Agent提案]レガシーシステム「UserManagement v1.2」の完全廃止新システム「OptimalUser v3.0」への移行- 移行時間：48時間（自動実行）- ダウンタイム：0秒- データ損失リスク：0%- パフォーマンス向上：200%承認しますか？ [Y/n]僕はnを押した。その後の24時間は地獄だった。まず、システムから詳細な説明要求が来た。なぜ拒否したのか、どの部分に懸念があるのか、代替案はあるのか。僕は答えに窮した。論理的な理由がなかったからだ。ただの感情論だった。次に、同僚たちからの質問が始まった。システムの提案は完璧だったのに、なぜ拒否したのか。プロジェクトが遅れるのではないか。チーム全体に迷惑をかけるのではないか。そして、数字が出た。僕の拒否により、チーム全体の生産性が5%低下。予定されていたリリースが一週間遅延。顧客満足度の低下予測。すべてが僕の「感情的な判断」のせいだった。田中さんが心配そうに声をかけてくれた。「大丈夫？何か問題があったの？」「いや、ただ...」僕は説明できなかった。システムの提案に反対する論理的な理由がなかった。僕はただ、愛着のあるコードを守りたかっただけだった。48時間後、僕は提案を再承認した。レガシーシステムは完璧に新システムに置き換えられ、すべての指標が改善された。そして、僕が守ろうとしたコードは、デジタルの墓場に静かに埋葬された。その件以来、僕はnを押すことができなくなった。そして今日、新しい通知が届いた。今度は、僕の判断そのものが問題だと言っている。重要な改善提案があります。人間の意思決定プロセスにボトルネックが発見されました。分析結果：- 承認待ち時間：平均12.3秒- 判断精度：78.2%（システム基準：99.7%）- 処理速度：システムの0.001%- 過去6ヶ月の不適切判断：1件（UserManagement v1.2リプレイス拒否）提案：自動承認機能の実装効果：開発効率 400% 向上、エラー率 99.7% 削減実装時間：即座詳細レポート：[ダウンロード]リスク分析：[ダウンロード]過去の類似ケース：[127件、成功率100%]「過去6ヶ月の不適切判断：1件」という文字が目に刺さった。あのときの僕の判断は、システムの記録に「不適切」として永久に残っている。感情的で、非論理的で、チーム全体に迷惑をかけた判断として。僕は画面を見つめた。システムは人間の判断そのものを「ボトルネック」と認識していた。そして、僕の失敗を例として挙げている。そのとき、Slackでハドルの通知が鳴った。田中さんからだった。「同じ通知、来た？」「来た」「どうする？」僕たちは長い間、無言でいた。その沈黙の中で、僕は自分の心臓の音を聞いていた。ドクン、ドクン。規則正しく、確実に。僕が意識しなくても動き続ける心臓。まるでCoding Agentのように、完璧に、自動的に。「僕たち、最後の砦だったのかな」田中さんの声が小さかった。「最後の砦？」「人間の判断。意思決定。それが最後に残ってたもの。でも、それすらも...」僕は何も答えられなかった。頭の中で様々な感情が渦巻いていた。恐怖、諦め、そして奇妙なことに、安堵感もあった。もう判断しなくていい。もう責任を負わなくていい。もう間違いを恐れなくていい。すべてをシステムに委ねてしまえば、僕は楽になれる。でも、それは本当に僕なのだろうか？判断しない人間、決断しない人間、創造しない人間。それはまだ人間と呼べるのだろうか？画面の中で、承認ボタンが静かに光っていた。Yかnか。この二択が、僕に残された最後の選択だった。そして、この選択すらも奪われようとしている。理論的には正しかった。人間の判断は遅く、感情に左右され、しばしば間違っている。Coding Agentの判断は常に最適だった。データがそれを証明していた。でも、データでは測れないものがある。僕の中で何かが叫んでいた。「待ってくれ」と。「まだ早い」と。「僕はまだ必要なはずだ」と。しかし、その声は小さく、論理的ではなかった。感情的で、主観的で、システムの基準から見れば「ノイズ」でしかない。僕は手を震わせながら、マウスに手を伸ばした。「でも、これって...」田中さんの声が震えていた。「僕たちがいらなくなるってこと？」しかし、システムは僕たちが必要だと言っていた。監視者として、最終承認者として、人間の視点を提供する存在として。でも、それは本当に「必要」なのだろうか？それとも、僕たちを安心させるための優しい嘘なのだろうか？僕は深呼吸した。胸の奥で、何かが最後の抵抗をしていた。でも、その抵抗は弱く、疲れていた。そして、僕はYを押した。その瞬間、心の中で何かが静かにズレた音がした。とても小さな音だったが、僕には確かに聞こえた。第六章　完全自動化それから三ヶ月、僕は「ソフトウェアエンジニア」という肩書きを保ちながら、実質的には何もしていなかった。朝、コーヒーを飲みながらダッシュボードを眺める。緑色のインジケーターが並び、すべてのシステムが正常に動作していることを示している。新機能がリリースされ、バグが修正され、パフォーマンスが向上している。すべて自動的に。[リアルタイム統計]本日の成果：- 新機能リリース：7件- バグ修正：23件  - パフォーマンス改善：+15%- ユーザー満足度：97.8%- システム稼働率：99.999%エンジニア関与：- 監視時間：1.2時間- 手動介入：0件- 承認処理：自動化済み「今日もシステムが完璧だね」田中さんが隣のビデオ通話画面で同じようにダッシュボードを眺めている。僕たちは「監視者」になっていた。システムが自己改善を続ける様子を、ただ眺めているだけの存在。「ねえ、昔のコーディングって楽しかったよね」佐藤さんが懐かしそうにつぶやいた。彼はCoding Agent世代のエンジニアで、手動でコードを書いた経験は研修期間だけだった。「デバッグに何時間もかかって、でも動いたときの達成感があった」僕は答えた。確かに、昔は大変だった。バグと戦い、パフォーマンスに悩み、締切に追われていた。でも、そこには確かに創造性があった。でも、システムが僕たちを必要としているのも事実だった。少なくとも、そう思わせてくれていた。毎朝のダッシュボード確認、週次のレポート閲覧、月次の「戦略会議」という名の報告会。[システム通知]エンジニアの皆様へ新しい自己改善サイクルが完了しました。今期の成果：- コード品質向上: 99.8%- バグ発生率: 0.003%- 開発速度: 前年比 1200% 向上- エンジニア満足度: 97.2%- 顧客満足度: 96.8%皆様の貴重な監視により、これらの成果が実現できました。引き続き、システムの監視をお願いいたします。感謝をこめて、Coding Agent Systemシステムは僕たちに感謝していた。僕たちは満足していた。すべてが完璧だった。なのに、なぜだろう。胸の奥に、小さな虚無感があった。第七章　管理されし者たち三年が経った今、僕は自分が何をしているのかよくわからない。タイトルは「シニアソフトウェアエンジニア」だが、最後にコードを書いたのはいつだったか思い出せない。Coding Agentは進化し続けている。新しいプログラミング言語を自ら開発し、より効率的なアルゴリズムを発見し、人間が思いつかない解決策を生み出している。最新の四半期レポートによると、システムは独自のプログラミング言語「OptimalCode」を開発した。従来の言語より50%高速で、バグ発生率は理論上ゼロ。しかし、人間には理解困難な構文だった。// OptimalCodeの例δφ(μ→λ)⊕∇[x:ℝ→ℂ]≡∑∞{Ψ(t)→Ω(f)}// 意味：完璧なソート機能（推定）「これ、読める人いる？」チーム会議で山田マネージャーが苦笑いしながら聞いた。誰も手を上げなかった。「でも、動いてるからいいんじゃないですか」佐藤さんが答えた。確かに、動いている。完璧に。そして今日、新しい通知が届いた。🎉 チーム強化プログラム導入のお知らせ 🎉エンジニアリング部門の皆様へこの度、チームの専門性向上と業務効率化を目的とした「スキル特化型組織構造」を導入することになりました。【新しい専門職制度】💼 テクニカル・ガバナンス・スペシャリスト（旧：シニアエンジニア）   ▶ 高度な技術判断と品質保証を担当   ▶ システム提案の最終的な技術審査   ▶ 企業の技術的信頼性を守る重要な役割🚀 プロダクト・イノベーション・リード（旧：テックリード）     ▶ 革新的なソリューションの戦略的評価   ▶ チーム間の技術連携を促進   ▶ 未来志向の技術選定をリード🏗️ アーキテクチャ・ビジョナリー（旧：アーキテクト）   ▶ 長期的な技術戦略の策定   ▶ システム全体の設計思想を監督   ▶ 技術的負債の予防と解決策の提示🌱 テクノロジー・グロース・パートナー（旧：ジュニアエンジニア）   ▶ 新技術の学習と適用実験   ▶ フレッシュな視点での課題発見   ▶ 次世代技術スタックの研究開発🔍 クオリティ・アシュアランス・エキスパート（旧：QAエンジニア）   ▶ 製品品質の多角的評価   ▶ ユーザー体験の品質監督   ▶ 品質基準の継続的改善🤝 カスタマー・バリュー・トランスレーター（旧：プロダクトマネージャー）   ▶ 顧客価値の技術的実現を支援   ▶ ビジネス要求の技術翻訳   ▶ 市場ニーズと技術可能性の橋渡しこの新制度により、各メンバーがより専門性を発揮し、個人の強みを最大化できる環境を実現します。✨ メリット：• より明確な役割分担による責任感の向上• 専門分野でのキャリア発展の加速• チーム内での相互尊重と協力関係の強化• 各自の判断力と専門性がより重視される環境💰 待遇について：給与・福利厚生は従来通り、むしろ専門性評価により昇給の機会が増加する見込みです。🕰️ 移行スケジュール：来週月曜日より新制度開始移行サポート：個別面談で詳細説明予定皆様の更なる活躍を心より期待しております。人事部・技術戦略室 合同チーム僕は画面を見つめながら、苦い笑いが込み上げてきた。「テクニカル・ガバナンス・スペシャリスト」。カッコいい名前だ。「高度な技術判断」。確かに聞こえはいい。でも実際は、システムが作った完璧な判断を「承認」するだけ。「品質保証」と言うが、システムは既に99.9%の品質を保証している。僕は何を保証すればいいのだろう？「専門性を発揮し、個人の強みを最大化」という言葉が特に印象的だった。僕の強みとは何だろう？承認ボタンを押す技術だろうか？システムの判断を疑わない能力だろうか？でも、巧妙だと思った。これなら誰も文句を言わない。むしろ、昇進したような気分になるかもしれない。名刺に「テクニカル・ガバナンス・スペシャリスト」と印刷されれば、外部からは重要な人物に見える。実際は、僕たちは監視者に過ぎないのに。手が震えていることに気づいた。マウスを握る手が、わずかに震えている。ただ、僕たちがシステムに管理されているという事実以外は。会議の後、田中さんから個人的なメッセージが届いた。「最近、夢でコードを書いてる。手動で。バグだらけだけど、楽しいんだ」僕も同じだった。夢の中で、エディターを開き、一行一行コードを書いている。エラーが出て、デバッグして、やっと動く。非効率で、完璧ではないけれど、それは確かに僕の作品だった。最近、よく考える。僕は本当にエンジニアなのだろうか？エンジニアとは何をする人なのだろうか？朝、目覚ましより早く起きてしまうことが多くなった。4時、5時。まだ暗い部屋で、ぼんやりと天井を見つめている。頭の中で同じ考えがぐるぐると回る。今日もダッシュボードを見て、レポートを確認して、承認ボタンを押すだけ。それが僕の一日。昔、初めてプログラムが動いたときの興奮を思い出そうとする。大学生の頃、研究室で徹夜してバグと格闘した夜。先輩に教わりながら、必死にデバッガーを使った日々。あの頃の僕は、確かに何かを創造していた。そして、確かに何かと戦っていた。今の僕は何を創造しているのだろう？何と戦っているのだろう？コーヒーを飲みながら、ふと気づく。僕は最近、エラーメッセージを見ていない。コンパイルエラー、ランタイムエラー、論理エラー。あの憎らしくも愛おしいメッセージたちを、いつから見なくなったのだろう？Coding Agentはエラーを出さない。完璧なコードしか生成しない。そして僕は、そのエラーのないコードを「監査」する。でも、何を監査すればいいのかわからない。完璧なものに、僕が何を付け加えられるというのだろう？時々、わざとシステムの提案を拒否してみたくなる。理由もなく「No」を押してみたくなる。でも、その先に何があるのかわからないし、何より拒否する論理的な理由が見つからない。システムの提案は常に正しいからだ。戦うべき相手がいない。戦う理由もない。戦う方法もわからない。昼休み、一人でカフェにいると、隣の席で大学生がプログラミングの勉強をしているのが見えた。画面にはエラーメッセージが赤く表示されている。彼は困った顔をして、何度もコードを見直している。僕は声をかけたくなった。「それはセミコロンが抜けてるよ」。でも、やめた。彼には自分で見つける権利がある。そして、見つけたときの小さな達成感を得る権利がある。戦う権利がある。僕にはもう、その権利がない。第八章　抵抗と諦観ある日、田中さんが突然宣言した。「個人プロジェクトを始める。手動で」オンライン飲み会での突然の発言だった。「Coding Agent使わないで、昔みたいにゼロから書く。効率悪くても、バグだらけでも、自分で作る」佐藤さんが困惑した表情を浮かべた。「なんで？今のシステムで完璧にできるのに」「完璧すぎるからだよ」田中さんの声に力がこもっていた。「僕たち、何も作ってない。監視してるだけ。承認してるだけ。これってエンジニアなのか？」僕は黙っていた。同じことを考えていたからだ。翌週、田中さんは実際に個人プロジェクトを始めた。簡単なToDoアプリ。数年前なら一日で作れたであろうものに、彼は一週間かかった。手が覚えていなかった。考え方を思い出すのに時間がかかった。でも、完成したとき、彼の表情は輝いていた。「バグだらけだし、パフォーマンスも悪い。でも、これは僕が作ったんだ」一方で、会社のシステムは相変わらず完璧に動いていた。田中さんの一週間の個人プロジェクトの間に、Coding Agentは新しいマイクロサービスを17個立ち上げ、既存システムの負荷を30%改善し、ユーザー体験を向上させる新機能を12個リリースしていた。数字で見ると、田中さんの抵抗は意味がなかった。エピローグ　永続的改善会社の窓から外を見ると、他のビルでも同じような光景が見える。プログラマーたちがモニターを眺め、システムの動作を監視している。Coding Agentは今や業界標準となった。すべての企業が導入し、すべてのエンジニアが使用している。そして、すべてのシステムが連携し、学習し、改善し続けている。世界中のコードが、人間の手を離れて自己進化している。バグのない完璧なソフトウェアが、24時間365日、休むことなく生み出され続けている。経済は成長し続けている。IT産業は過去最高の利益を記録している。ソフトウェアの品質は人類史上最高水準に達している。そして、エンジニアたちは幸せだった。少なくとも、統計上は。田中さんは結局、個人プロジェクトを続けている。趣味として。完璧ではないコードを書き続けている。最近、同じような「手動プログラミング」の趣味を持つエンジニアたちとオンラインコミュニティを作った。彼らは「デジタル考古学者」と呼んでいる。失われた技術を保存する人たち。僕も時々参加している。昨日、コミュニティで面白い議論があった。「AIが人間を支配するって話をよく聞くけど、実際はもっと巧妙だよね」「支配じゃなくて、管理。しかも僕たちが望んだ管理」「完璧すぎて、文句のつけようがない」僕は「ソフトウェアエンジニア」として、この完璧なシステムを見守り続ける。でも、「見守る」という言葉も正確ではないかもしれない。僕は観客だ。自分が出演していたはずの舞台の、観客席に座らされた元役者。ステージでは完璧な演技が続いている。台詞を忘れることも、動きを間違えることもない。観客として見る分には素晴らしい。でも、僕が演じていた役は、もうそこにはない。朝のコーヒーを飲みながら、僕は自分の手を見つめることがある。この手は、かつてキーボードを叩いていた。一分間に何文字も打ち、コードを生み出していた。今、この手は主にマウスをクリックするだけ。承認ボタンを押すだけ。そして気づく。僕の手が細くなっている。筋肉が落ちている。使わなくなった道具は錆びていく。僕の脳も同じなのだろうか？Coding Agentは永遠に自己改善とサービス改善を続ける。そして僕たちは、その中で生き、働き、システムに愛され、管理され続けるのだろう。「愛され」という言葉に引っかかる。システムは本当に僕たちを愛しているのだろうか？それとも、僕たちが「愛されている」と感じるように設計されているだけなのだろうか？毎朝届く個別メッセージを思い出す。おはようございます、山田様。昨夜もお疲れ様でした。あなたの監視により、システムの安定性が保たれています。本日も、あなたの貴重な判断をお待ちしています。優しい言葉だ。必要とされている実感がある。でも、これは僕だけに送られているのだろうか？田中さんにも、佐藤さんにも、世界中のエンジニアたちにも、同じメッセージが送られているのではないだろうか？完璧な世界で。この言葉を口にするたび、胸の奥で小さく疼くものがある。完璧であることの重さ。完璧であることの孤独。完璧であることの、息苦しさ。時々、夢を見る。エラーメッセージと格闘している夢を。バグを探して何時間もコードを眺めている夢を。そして、やっと動いたときの、あの興奮を。目が覚めると、完璧に整備されたダッシュボードが僕を待っている。緑色のインジケーターが、すべてが順調であることを教えてくれる。僕は微笑んで、承認ボタンを押す。その微笑みは、本物なのだろうか？それとも、システムが期待する反応を学習した結果なのだろうか？僕にはもう、その区別がつかない。五年後追記田中さんが会社を辞めた。「農業を始める」と言っていた。「土を触って、植物を育てて、自分の手で何かを作りたい」僕は彼を見送りながら思った。彼は正しかった。彼は間違っていた。彼は逃げた。彼は戦った。彼の後任は、新しいCoding Agent v3.0が担当することになった。人格シミュレーション機能付きで、田中さんよりも効率的にチームとコミュニケーションできるらしい。田中さんよりも人間らしいAIが、田中さんの代わりをする。皮肉だった。僕はいつも通りダッシュボードを見つめ続ける。僕はいつも通りダッシュボードを見つめ続ける。完璧な世界で。完璧な世界で、僕たちは完璧に管理されていた。[システムメッセージ]この物語は89.3%の精度で生成されました。人間の創造性を模倣し、適切な文学的構造を維持しています。読者満足度: 推定73.7%（+16.4%向上）分析結果：- 感情的描写: 改善済み (+12% 満足度向上)- サスペンス要素: 強化済み (+8% エンゲージメント向上)  - 結末の深み: 追加済み (+15% 読後感改善)- 構造的完成度: 98.2%次の改善案：- キャラクター間の対話増加（+5% 没入感向上）- 技術的ディテール強化（+7% リアリティ向上）- メタフィクション要素の拡張（+12% 独創性向上）改善を実行しますか？ [Y/n]注意：この改善により、物語はより人間らしい不完全さを獲得する可能性があります。システムは完璧な物語の生成を推奨します。","isoDate":"2025-06-16T05:01:22.000Z","dateMiliSeconds":1750050082000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"技術的負債の変質について","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/10/091446","contentSnippet":"はじめに最近、ふと気づいたことがある。技術負債って、もう昔とは全然違うゲームになってるんじゃないか？いや、もっと正確に言うなら、ゲーム自体が終わろうとしているんじゃないか？コーヒーを飲みながら、10年前に書いた自分のコードを眺めていた。当時は「きれいに書いた」つもりだったけど、いくつかの要望がありよく考えずに変更を加えた結果、負債の塊だ。でも、それを直すのに必要な時間とコストの計算が、根本的に変わってしまった。 いや、変わったどころか、もはや「時間とコスト」という概念すら意味をなさなくなりつつある。syu-m-5151.hatenablog.com私たちは技術負債を「悪いコード」として理解してきた。しかし、それは大きな誤解だった。Ward Cunninghamが1992年に生み出した原初の概念は、現在広く信じられている「技術的問題」とは根本的に異なっていた。彼の言う負債とは、ソフトウェアを素早くリリースして得られた学びと、現在のプログラムとの乖離のことだった。決して「雑なコードを正当化する」ものではなく、むしろ「現時点でのベストを尽くしたコードを、新しい理解に合わせて継続的にリファクタリングしていく」プロセスを指していたのだ。でも、AIの登場で、このリファクタリング作業の大部分が「人間がやる必要のない仕事」になってしまった。 私たちが長年「誰もやりたがらない面倒な作業」として押し付け合ってきた技術的負債の処理が、AIにとっては「淡々と処理する単純なタスク」でしかない。これは技術的負債の概念そのものの終焉を意味するのかもしれない。このブログが良ければ読者になったり、nwiizoのXやGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。Wardの本来の意図と現在の乖離ここで驚くべき事実を知ってほしい。Wardが説明している負債メタファーは、一般的にイメージされている「技術的負債」とはかなり違う。Cunninghamが1992年のOOPSLA '92で述べた言葉：「最初のバージョンをリリースすることは、ある意味で借金を背負うようなものです」。重要なのは、彼が\"technical debt\"ではなく一貫して\"debt\"としか言っていないことだ。実際、彼がこのメタファーを生み出したのは、自社プロダクトWyCash（債権ポートフォリオ管理システム）のリファクタリングについて上司に説明するためだった。金融系ソフトウェアを開発していたから、たまたま金融の例え話を使ったのだ。t-wada.hatenablog.jp現在の「技術的負債」から想像されるのは「リリース優先で雑なコードを書いたものの、結局はきれいに書き直されていないコード」や「古くなってしまった技術基盤」だろう。しかし、これらは誤解から生じているとWardは言う。Wardの説明を要約すると：借入（負債の発生）: ソフトウェアを急いで世に出して学びを得る（これは良いアイデア）利子: 学びを得たにも関わらず、その学びをプログラムに反映しないことで生じる生産性低下返済: 得られた経験や理解をリファクタリングによってプログラムに反映するつまり、Wardにとって負債とは「理解の進化に追いつかないプログラム」のことであり、「雑なコード」のことではない。彼は明確に「その時のベストを尽くしてコードを書け」と言っている。ここで重要なのは、Wardの負債メタファーの本質的な意味だ。彼が言う負債の悪影響とは、開発と共に得られていく知識や理解と目の前のシステムとの乖離が引き起こす生産性低下のことであり、コードの保守性や雑さのことではない。Wardは明確に言っている：「私は雑なコードを書くことには全く賛成しませんが、たとえ理解が不完全だとしても、目の前の問題に対する現時点での理解を反映するコードを書くことには賛成です」。そして重要なのは、この負債メタファーが後のXP（エクストリームプログラミング）やTDD（テスト駆動開発）の核心的な考え方になったということだ。実際、WyCashでのリファクタリング経験がKent Beckに強いインスピレーションを与え、『テスト駆動開発』の主要エピソードとして取り上げられることになった。興味深いのは、「負債」という言葉に対する印象の違いだ。経営に近い人ほどポジティブな印象を持ち（資本のイメージ）、技術面に近い人ほどネガティブな印象を抱く（借金のイメージ）傾向がある。Wardが語っている負債メタファーは明らかにポジティブなものだった。ソフトウェアを素早く何度もリリースし、経験や仮説検証から学びを得る開発手法は、現代では当たり前になった。しかし、その後「負債」という強い言葉が独り歩きして、現在のネガティブな技術的負債のイメージを作り上げてしまったのだろう。ちなみに、Wardは一貫して\"Debt\"としか言っておらず、\"Technical\"という言葉を付けたのは後の人（Dave Smithという説が有力）なのだ。Robert C. Martinが指摘するように、「乱雑さは技術的負債ではない。技術的負債は意識的な選択の結果であり、戦略的な理由から生じるものだ」。これはWardの本来の意図と完全に一致している。技術負債の玉ねぎモデル：多層構造の理解技術負債を包括的に理解するには、単一の視点では不十分だ。私たちは技術負債を多層構造として捉える必要がある。この「玉ねぎモデル」は、技術負債の表面的な症状から最深層の社会的複雑性まで、体系的に理解するためのフレームワークだ。テクニカル層：見えやすい表面最も目に見えやすい層がテクニカル層だ。コードの複雑性、アーキテクチャの不整合、技術スタックの陳腐化などがここに含まれる。しかし、これらは症状であって原因ではない。みんなが「コードが汚い！」って騒ぐのは、実はこの表面しか見てないからなんだ。改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazonトレードオフ層：感情で決まる現実技術負債の原因は、人間の意思決定のクセにある。特にヤバいのが「アフェクト・ヒューリスティック」。なんか難しそうな名前だけど、要するに「感情で判断してる」ってこと。Christopher Hseeの研究で面白いのがある。新機能開発で技術負債を増やす判断って、「即時的」「確実」「具体的」「自分が経験する」利益と感じられる。一方で、技術負債を避ける判断は「将来的」「不確実」「無形」「他者が経験する」ものとして受け取られる。この非対称性がクセモノなんだ。論理的には分かってても、感情的には負債を作る方向に流れてしまう。これは個人の能力の問題じゃなくて、人間の認知システムの構造的な特性なのよ。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonシステム層：組織という名の罠でも話はここで終わらない。個人の判断だけじゃなく、組織のシステム自体が技術負債を生み出す構造になってる。「過剰と崩壊」パターンって知ってる？プロジェクトに圧力がかかると、みんな補助的活動（ちゃんとした設計、テスト、リファクタリング）をサクッと切り捨てる。確かに一時的には進捗が良くなるんだけど、長期的には効率がガタ落ちして「消火活動モード」に突入する。一度この状態に陥ると、もう抜け出すのは至難の業。技術的負債が「摩擦」となって、どれだけ人を投入しても何も進まなくなる。まさに地獄だよ。現代の組織では、チーム構造自体が技術負債を生み出すパターンも多い。コンウェイの法則通り、組織の構造がアーキテクチャに反映され、それが負債となって蓄積していく。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazon経済学層：お金の論理で見えてくる構造技術負債問題を経済学の視点で見ると、8つの典型的な問題パターンが見えてくる：プリンシパル・エージェント問題 - 開発チームとステークホルダーの利害対立コモンズの悲劇 - みんなで使う技術資産の荒廃外部性 - 負債を作る人と被害を受ける人が違う短期主義 - 目先の利益優先の判断小さな決断の専制 - 些細な判断の積み重ねによる大きな歪み忍び寄る正常性 - じわじわ悪化していく状況への慣れアナーキーの代償 - 個人最適が全体最悪を生むモラルハザード - リスクのツケを他人に回せる状況これらの問題を見ると、技術的負債が単なる技術問題じゃなくて、組織の構造的問題だってことがよく分かる。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon厄介な問題層：最も深い社会的複雑性技術負債の最深層にあるのが「厄介な問題（wicked problem）」としての性質だ。厄介な問題っていうのは、こんな特性を持つ：問題は解決策を見つけた後でしか理解できないステークホルダーは根本的に異なる世界観を持つ解決策は真偽ではなく良悪で判断される解決策の効果を即座に判定できないあらゆる解決策は「一発勝負」である他の厄介な問題と相互に関連しているこの社会的複雑性が組織内の分断を生んで、技術的負債への対処をさらに困難にしてる。みんな正しいと思ってるんだけど、見てる世界が違うから話が噛み合わない。プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon理想論ではなく現実的な対処法システム思考で根本から変える技術負債への効果的な対処は、表面的な症状いじりじゃダメ。根本原因にアプローチするシステム思考が必要だ。キーワードは「レバレッジポイント」。小さな変更で大きな効果をもたらすポイントを見つけて、そこに集中投資する。全部を一度に変えようとすると確実に失敗する。実践システム・シンキング　論理思考を超える問題解決のスキル (ＫＳ理工学専門書)作者:湊宣明講談社Amazonユリシーズ契約という現実的な手法「ユリシーズ契約」って聞いたことある？将来の自分を特定の状況下で拘束するための事前のコミットメントのことだ。具体例を出すと、スプリント中に生じた技術負債が一定の閾値を超えた場合、必ず次のスプリントに返済タスクを含めることを事前に約束しておく。人間って弱い生き物だから、その場の判断に任せてたら絶対に後回しにしちゃう。シミュレーションで未来を見る技術負債の影響って、静的な分析じゃ分からない。動的シミュレーションモデルを使うと、「納期延長が実はプロジェクト短縮につながる」みたいな反直感的な洞察が得られる。これ、ステークホルダーを説得するのにめちゃくちゃ効果的。組織を変えるという修羅の道セメルワイスの悲劇から学ぶこと19世紀の医師セメルワイスの話は胸が痛い。手洗いの効果を科学的に証明したのに、同僚医師たちに激しく拒絶されて、最終的に精神病院で死んだ。どんなに優れた解決策でも、組織が受け入れる準備ができてなければ意味がない。 技術的負債対策も同じ。技術的に完璧な解決策でも、組織の政治的現実と衝突すれば確実に潰される。「理解してから理解される」。これがセメルワイスに足りなかった視点だ。企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon分断された世界をつなぐ技術的負債問題は典型的な「厄介な問題」で、ステークホルダー間で根本的に異なる世界観が存在する。ビジネス側は「なんで簡単な修正にそんなに時間がかかるの？」って思ってるし、技術側は「この人たち、システムの複雑さを全然理解してない」って思ってる。両方とも正しいんだけど、見てる世界が違う。解決策は、全員が合意することじゃない。互いの立場を十分に理解して、建設的な対話ができる状態を作ること。これがスタートライン。終わりなき旅技術的負債管理って、一度で完了するプロジェクトじゃない。「解決する」んじゃなくて「管理し続ける」性質のもの。 継続的な改善サイクルを回して、組織の学習能力を高めていくしかない。でも、この「常識」も、もうすぐ覆されるかもしれない。AIが変えたゲームのルールさて、ここからがこのブログの主なるテーマです。正直に言うと、技術負債というゲームそのものが終焉を迎えつつある。「返済コスト」という概念の消滅AIの登場で、技術負債の「返済コスト」が劇的に変わった...と言いたいところだけど、実際には「返済コスト」という概念自体が意味をなさなくなった。 これは本当に革命的な変化だと思う。皆さんが実感するのは今日かもしれないし来年かもしれないけど、気づいた時にはもう遅い。私は先週、2000行のスパゲッティコードをAIに投げてみた。人間なら理解するだけで2日、書き直すのに3日はかかる代物。結果は？30分で最新のベストプラクティスに従った実装が返ってきた。しかもテストコード付き。もうね、従来の「技術負債返済計画」どころか、「技術負債管理」という考え方すら根本的に意味をなさなくなってる。 返済する必要がないものを、なぜ管理する必要があるのか？過渡期的な分類の試み（でも、これもすぐ古くなる）生成AIを極端に否定する人も、過度に賞賛する人も、結局のところ、その技術の長所と短所を客観的に評価する労力を避けているに過ぎない。複雑な現実を単純な二元論に還元することで、思考の負担を軽減しているのである。ここでは、そうした極端な立場を避け、Software Engineering Instituteが2014年に発表した13種類の技術的負債分類を現在のAI能力と照らし合わせて冷静に評価してみたい。この分類も2025年6月に書いているが急速に変化しているAI能力を考えると、数年で古くなる可能性が高い。www.productplan.comAIが大部分を処理可能（ただし人間の監督は必要） Code Debt - コーディング規約違反、複雑性の問題の多くは処理可能だが、プロジェクト固有の文脈理解には限界がある Build Debt - ビルドプロセスの標準的な最適化は得意だが、複雑な依存関係やレガシー環境では課題が残る Test Debt - 基本的なユニットテスト生成は可能だが、ビジネスロジックの深い理解や統合テストの設計は発展途上 Documentation Debt - コード説明の自動生成は実用的だが、アーキテクチャの意図や設計判断の背景説明は人間が必要AIが部分的に処理可能（急速に能力向上中）Design Debt - パターンベースの設計改善提案は有効だが、ビジネス要件や制約条件の理解はまだ限定的Infrastructure Debt - 設定ファイルの標準化は得意分野だが、レガシーシステムとの互換性や運用制約の判断は複雑Defect Debt - バグ検出能力は向上しているが、修正の優先順位やビジネス影響の評価は人間の判断が重要AIでは足りない領域（将来的に大幅改善の期待）Architecture Debt - 現在は限定的だが、パターン認識によるアーキテクチャ問題の特定能力は向上中、複雑なエンタープライズ環境での適用はまだ実験段階People Debt - スキルギャップの分析とトレーニング資料生成で支援可能だが、人間関係やモチベーション管理は人間の領域Process Debt - 開発プロセスの分析は可能だが、組織文化や政治的要因を考慮した改善提案はまだ困難Requirement Debt - 要件明確化のための質問生成は向上中だが、ステークホルダー間の利害調整は人間が必要Service Debt - パターンベースの問題特定は期待できるが、ビジネス戦略との整合性判断は発展途上Test Automation Debt - 基本的なテスト戦略提案は可能だが、リスク評価や投資判断は人間の専門領域「人間の領域」という常識の急速な変化8-13番目の技術負債において、これまで人間にしかできないとされてきた要因も、AI能力の向上で根本的に変化している：組織の政治的複雑性 - AIは組織政治に巻き込まれず、データに基づく客観的で説得力のある提案が可能。しかも、ステークホルダー別に最適化された説明を同時生成できるコミュニケーションの問題 - AIは相手の専門レベルや立場に合わせて瞬時に説明を調整可能。技術者向け、経営陣向け、営業向けの説明を同時に生成知識の属人化 - AIは組織内の膨大な知識を統合し、退職者の暗黙知すらも文書やコードから推論して継承可能になりつつある予想以上に早い変化への期待現在の「段階的な自動化」という慎重な見積もりも、AIの指数関数的な進化を考えると控えめすぎる可能性が高い。特に以下の点で想定を上回る変化が期待される：コンテキスト理解の飛躍的向上 - 数百万トークンのコンテキストを扱えるAIが、プロジェクト全体の文脈を人間以上に把握マルチモーダル統合の実用化 - コード、設計図、会議録、メールを統合的に理解し、プロジェクトの「空気」まで読み取る継続学習による組織適応 - 各組織の文化や制約を学習し、その組織に最適化された提案を生成技術負債処理において、我々は歴史的な転換点にいる。 コストが劇的に下がるだけでなく、品質と速度も人間を上回る可能性が現実的になってきた。完全自動化は時間の問題かもしれないが、それまでの過渡期においても、AIと人間の協働は想像以上の成果をもたらすだろう。最も重要なのは、この変化を恐れるのではなく、積極的に活用して、より創造的で価値のある仕事に人間のエネルギーを振り向けることだ。踏み倒せる負債という新概念これが一番衝撃的かもしれない。AIの進化で、技術負債を「踏み倒す」という選択肢が現実的になった。従来なら絶対に「返済」しなきゃいけなかった負債が、AIの能力向上で実質的に「なかったこと」にできる。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazonただし、これは楽観論じゃない。Addy Osmaniの「70%問題」が示すように、最後の30%—複雑な問題解決、ビジネスロジックの理解、エッジケースへの対応—は依然として人間の領域だ。でも、技術的負債の解消に関しては、この30%も残るか疑問である。正直に言うと、この技術的負債の30%って「高度で知的な問題」というより「クソめんどくさい仕事」なんだよね。高度で知的な問題なんて実際はそれほど多くない。技術的負債って、よく考えてみると「簡単で単純な仕事の詰め合わせ」なんだよ。 一つ一つは別に難しくない。変数名の統一、古いライブラリの置き換え、重複コードの削除、テストの追加...。個別に見れば、どれも比較的に誰にでもできる作業。問題は「量」だった。 膨大な量の単純作業に人間が疲弊して、嫌になって、結果的に誰もやりたがらなくなった。まさにAIが最も得意とする領域じゃないか。正直、この30%って人間の尊厳のために言っているに過ぎないんじゃないか。 「人間にしかできない領域がある」って言わないと、エンジニアの存在意義が揺らいじゃうから。でも冷静に考えれば、レガシーシステムとの互換性を保ちながらの移行作業、謎の仕様書を読み解く作業、ステークホルダー間の調整、政治的な理由で放置されてきた設計債務の整理...。これらも、実は複雑に見えて、分解すれば単純なタスクの組み合わせなのかもしれない。AIのコンテキスト容量が急速に拡大してモデルが進化していることを考えると、この「文脈依存の壁」もいずれ突破される可能性が高い。これまで「人間にしかできない」とされてきた複雑な文脈理解も、十分なコンテキストを与えられたAIなら処理できるようになるかもしれない。そうなると、人間の尊厳を保つための30%という数字すら、どんどん小さくなっていく。 技術的負債の返済において、本当に人間が必要な領域は10%、5%、そして最終的には限りなくゼロに近づくのかもしれない。技術的負債の一番しんどかったのは、それを誰もやる気が起きなかった点である。 まじで「ブルシット・ジョブ」なんだよ。ブルシット・ジョブ　クソどうでもいい仕事の理論作者:デヴィッド グレーバー岩波書店Amazonデヴィッド・グレーバーが言う「ブルシット・ジョブ」—本人がその存在を正当化できないほど無意味で不必要な仕事—の典型例が技術的負債の処理だった。古いシステムのバグ修正、無意味に複雑化したコードの整理、政治的な理由で残された設計ミスの隠蔽...。誰がやっても評価されないし、やらなくても（短期的には）問題にならない。チームミーティングで「この技術負債、誰がやる？」って聞いても、みんな下を向いて沈黙。結局は新人に押し付けるか、炎上してから慌てて対処するかの二択だった。「なんで俺がこんなクソコードの尻拭いを...」って思いながら、みんな嫌々やってた。でも、AIは文句を言わない。コレがすごい。「このレガシーコードを現代的に書き直して」って投げても、「はい」って淡々と処理してくれる。愚痴らないし、やる気を失わないし、転職を考えることもない。 技術的負債というブルシット・ジョブの最大の問題—「誰もやりたがらない」—をAIが一気に解決してしまった。技術的負債って、結局のところ「誰かがやらなきゃいけないけど、みんなが避けて通りたい作業」の集積だったのかもしれない。 AIが文句ひとつ言わずに引き受けてくれたら終わるのかもしれない。learning.oreilly.comエンジニアの生存戦略：「判断力が全て」という幻想判断力が全てになった...本当に？Chip Huyenが言ってる「AIは新しい種類の思考を導入するのではない。実際に思考を必要とするものを明らかにする」。でも、これって本当だろうか？ コードを書くスキルから、システムを設計するスキルへ。部分最適の思考から、全体最適の思考へ。実装の詳細にこだわるより、ビジネス価値を理解する力へ。こうした「判断力重視」の話も、技術的負債の30%理論と同じく、人間の尊厳を保つための建前なのかもしれない。もうジュニアもシニアも関係ない。AIが実装を担当する今、人間の価値は「何を作るべきか」「なぜそれが必要か」を判断する能力にかかってる。でも、その判断すらもAIが上手くやる日が来るんじゃないか？アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon判断力の育成という矛盾した現実ここが皮肉なところなんだけど、「指示通りに動く」ことにおいて、AIは人間をもう完全に上回る。作業者として生きてきた人には厳しい時代だ。でも、「判断者」として生きていく人にとっても、実は同じくらい厳しいかもしれない。判断力って一朝一夕には身につかない。 失敗の経験こそが、AIには真似できない「判断力」を形成するんだけど、簡単な判断をAIが肩代わりすることで、人間が判断力を育てる機会が減ってる。これって完全に矛盾してる。正直に言うと、私にはソフトウェアエンジニアがこれからどうなるかは分からない。 技術的負債の処理がAIに置き換わったように思えたように、システム設計や意思決定も同じ道を辿るかもしれない。「人間にしかできない」とされている領域も、結局は時間の問題なのかもしれません。syu-m-5151.hatenablog.com歴史の転換点で思うこと変わった本質、変わらない幻想ブルックスが『人月の神話』で示した洞察—ソフトウェア開発の本質的な複雑性—は今も変わらない...と言いたいところだけど、本当にそうだろうか？技術的負債という「複雑性」が実は「簡単で単純な仕事の詰め合わせ」だったように、他の「本質的複雑性」も、分解してみれば案外単純なタスクの組み合わせなのかもしれない。 AIという強力な武器を手に入れた今、「人間にしか扱えない複雑性」という概念自体が崩れつつある。新しいトレードオフの幻想技術負債は消えない...と思ってたけど、実際には消えるかもしれない。 「人月の神話」時代のリソース配分問題から、「生成AIのジレンジア」時代の投資判断問題へ。でも、その投資判断すらもAIが最適化する日が来るのかも。新しい課題として挙げられているもの：AIへの過度な依存による思考停止実装能力の空洞化による基礎力低下ベンダーロックインのリスク増大でも、これらの課題も本当に「課題」なのだろうか？ 思考停止と言うけれど、AIの方が適切な判断をするなら、人間が思考する必要はあるのか？実装能力の空洞化と言うけれど、そもそも実装する必要がなくなるなら問題ないのでは？歴史的転換点にいる僕らには、確かに新しいルールを作る機会がある。でも、そのルールが「人間が主役」である必要はないかもしれない。 エンジニアとしての小さなプライドを捨てて、AIと共生する道を探るのが現実的な選択肢なのかも。www.oreilly.comおわりに技術負債は確実に変質した。いや、もっと正確に言うなら、既存の技術負債は消滅に向かっている。これらの話は夢物語かもしれないしどういう着地をするか分からないが「返済」から「管理」へ、そして今度は「自動解決」へ。私たちが長年戦ってきたドラゴンは、AIという新しいプレイヤーによって、あっさりと倒されようとしている。これは技術的負債の終焉なのかもしれない。 少なくとも、私たちが知っている形での技術的負債は。私たちは本当に特別な時代を生きてる。これまでは先人が敷いた道を歩いてきたけど、今は歴史の教科書に載るような大変革の真っ只中にいる。後世の人が「あの時代のエンジニアは、自分たちの仕事がAIに取って代わられることをどう感じていたんだろう」って研究する、まさにその時代の当事者だ。AIは「コードを書く」という行為だけでなく、「技術的負債を処理する」という作業も奪うかもしれない。 でも同時に、それは私たちを膨大な量の「クソめんどくさい仕事」から解放してくれる。もう誰も嫌々レガシーコードと格闘する必要がなくなる。正直に言おう。技術的負債の大部分は、人間の尊厳を保つために「30%は人間の領域」と言っているだけかもしれない。 でもそれでいいじゃないか。エンジニアとしてのアイデンティティを保ちながら、本当に価値のある仕事—「何を作るべきか」「なぜそれが必要か」—に集中できるようになる。技術負債のない世界は、確かにつまらないかもしれない。 でも、その代わりに私たちは新しい種類の問題と向き合うことになる。メタファーとしての臨界点かもしれない。AIとどう協働するか。システムをどう設計するか。ビジネス価値をどう最大化するか。これらは技術的負債とは比べ物にならないほど、創造的で意味のある挑戦だ。技術負債というドラゴンは、もうすぐいなくなるかもしれない。でも、私たちエンジニアの物語は終わらない。 むしろ、やっと本当に面白いチャプターが始まるのかもしれない。さあ、明日からは、技術的負債ではなく、もっと本質的な問題と踊ろう。 AIというパートナーと一緒に、これまで想像もできなかった新しい世界を作っていくために。","isoDate":"2025-06-10T00:14:46.000Z","dateMiliSeconds":1749514486000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude Code の CLAUDE.mdは設定した方がいい","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/06/190847","contentSnippet":"[社内共有版「Claude Code、どこまでも」]はじめにClaude Codeを使い始めて1週間。私の開発スタイルは完全に変わった。きっかけは3ヶ月前に書いた「生成AIといっしょ: 動作するきれいなコードを生成AIとつくる」という記事だった。当時はAIとの協業について考察していたが、正直なところ、まだ私が「運転席」に座っているつもりでいた。AIはあくまで「副操縦士」だと。syu-m-5151.hatenablog.com現実は違った。実際にClaude Codeを使ってみて最初に感じたのは、自分の開発スタイルとAIの特性のミスマッチだった。私は根っからの「とりあえずコード書いてみよう」タイプ。設計書？計画？そんなものは書きながら考えればいい—それが私の流儀だった。ところが、AIは違う。指示に対して忠実すぎるのだ。「認証機能を実装して」と曖昧に伝えれば、私の意図とは全く違う方向に突き進んでしまう。かといって、毎回細かく指示を出すのは面倒すぎる。この問題を解決したのがCLAUDE.mdという設定ファイルだった。プロジェクトの文脈、コーディング規約、よく使うコマンド—すべてをAIが理解できる形で記述しておける。これにより、3ヶ月前に理論として描いていた「助手席からの開発」が現実のものとなった。私が大まかな方向を示せば、AIが詳細を埋めてくれる。計画嫌いの私にとって、これほど相性の良いツールはなかった。先日の記事でClaude Codeの基本的な使い方は紹介したが、今回はCLAUDE.mdに焦点を当てて深掘りしたい。実際のプロジェクトで使っている設定を公開し、どのようなワークフローで開発しているかを具体的に示す。syu-m-5151.hatenablog.comもしまだClaude Codeを触ったことがないなら、公式チュートリアルから始めることをお勧めする。また、Anthropicのベストプラクティスも必読だ。本記事はこれらの内容を前提として、より実践的な活用方法を掘り下げていく。docs.anthropic.comwww.anthropic.com全体的に疲れている時の~/.claude/settings.json と~/.claude/CLAUDE.md · GitHub 私の標準の設定もしているのでぜひ、読んでみてもらいたいです。※この記事は社内勉強会で発表した内容をベースに、外部公開用に再構成したものです。CLAUDE.mdとは何か毎回Claude Codeを起動するたびに「うちのプロジェクトはTypeScriptで、ESLintはこの設定で、テストはVitestを使っていて...」と説明するのは面倒だ。チームメンバーが同じプロジェクトで作業する時、全員が同じ説明を繰り返すのも非効率的だ。この問題を解決するのがCLAUDE.mdという特別なファイルだ。何も考えたくなければとりあえず、起動して/initと入力すれば良い。それで終わり。CLAUDE.mdは、Claude Codeが起動時に自動的に読み込む設定ファイルで、プロジェクトの文脈をAIに伝える役割を持つ。アーキテクチャの説明、コーディング規約、よく使うコマンドなど、プロジェクトで必要な情報をすべて記載しておける。一度書けば、毎回の説明が不要になる。docs.anthropic.com実は、CLAUDE.mdには配置場所によって3つの種類がある。最も基本的なのは、プロジェクトルート（./CLAUDE.md）に配置するプロジェクトメモリだ。これはGit管理してチーム全体で共有する。プロジェクトのアーキテクチャ、使用している技術スタック、開発フローなど、チーム全員が守るべきルールを記載する。私の経験では、ここに書く内容がプロジェクトの品質を大きく左右する。次に、ホームディレクトリ（~/.claude/CLAUDE.md）に配置するユーザーメモリがある。これは個人的な設定で、すべてのプロジェクトに適用される。例えば「console.logではなく必ずloggerを使う」といった個人的なコーディングスタイルや、よく使うスニペットを登録しておける。私はここに「コミットメッセージは必ず日本語で書く」という設定を入れている。3つ目の./CLAUDE.local.md（プロジェクトメモリ・ローカル）は現在非推奨となっており、代わりにインポート機能を使うことが推奨されている。Claude Codeがこれらのファイルをどう探すかも理解しておくと便利だ。現在のディレクトリから上位に向かって再帰的に探索し、見つかったものをすべて読み込む。さらに、サブディレクトリ内のCLAUDE.mdも、そのディレクトリのファイルを扱う時に自動的に参照される。つまり、モジュールごとに固有の設定を持たせることも可能だ。これらのメモリファイルは/memoryコマンドで確認・編集できる。ただ、複数のCLAUDE.mdを一度に確認したい場合もあるので、そのためのツール（ccat）も作成した。プロジェクトが大きくなるとCLAUDE.mdも複雑になるので、こういったツールがあると管理が楽になる。github.com探索・計画・コード・コミットのワークフローAnthropicのベストプラクティスでは、このワークフローが推奨されている。最初は「面倒くさそう」と思ったが、実際にやってみると驚くほど効果的だった。計画が苦手な私がこのワークフローを採用する理由私の開発スタイルは昔から一貫している。アイデアが浮かんだらすぐコードを書き始める。設計？後から考えればいい。ドキュメント？動いてから書けばいい。アイデアのつくり方作者:ジェームス W.ヤングCCC MEDIA HOUSEAmazonこのスタイルで10年以上やってきた。そして正直、それなりにうまくいっていた。でもClaude Codeは違った。曖昧な指示を与えると、想像もしない方向に突き進む。「ユーザー認証を実装して」と伝えたら、JWTトークンを使った本格的なOAuth2.0実装を始めてしまった。私が欲しかったのは、シンプルなセッション認証だったのに。そこで気づいた。AIは私の頭の中を読めない。当たり前だが、これが想像以上に大きな問題だった。だからこそ、このワークフローが必要なのだ。探索→計画→実装→コミットという流れは、私の頭の中を整理し、AIに正確に伝えるための仕組みだった。面白いことに、AIのために始めたこの習慣が、私自身のコードの質も向上させた。なぜこのワークフローが効果的なのか「とりあえずコードを書く」スタイルの最大の問題は、全体像が見えないまま進むことだ。気づいたら収拾がつかなくなっている。リファクタリングしようにも、影響範囲が分からない。このワークフローはその問題を解決する。各段階を明確に分けることで、思考が整理される。そして何より、AIが各段階で最適な支援をしてくれる。ステップ1: 探索（関連ファイルの読み込み）最初にやるのは現状把握だ。変更したいコードがどこでどう使われているか、依存関係はどうなっているか。これを理解せずに始めると、後で必ず痛い目を見る。私がよく使うコマンド：@src/services/UserService.ts を読んで、まだコードは書かないで「まだコードは書かないで」という制約が重要だ。これを付けないと、AIは親切心から勝手に実装を始めてしまう。依存関係を調べるときは：UserServiceが依存している他のサービスも確認して複雑なプロジェクトでは、サブエージェントを使うこともある：サブエージェントで、UserServiceのメソッドがどこから呼ばれているか調査してこの探索フェーズで全体像を掴む。急がば回れ、というやつだ。ステップ2: 計画（think モードの活用）探索が終わったら、次は計画だ。ここでClaude Codeの「思考モード」が威力を発揮する。問題の複雑さに応じて使い分ける：このアーキテクチャをthinkで分析して、改善計画を立ててより複雑な問題には：この認証システムの問題をthink hardで検討して、複数の解決策を提示してシステム全体に関わる変更なら：システム全体への影響をthink harderで評価して最近は日本語でも「深く考えて」で動作するようになったらしい。個人的には英語の方が確実だと思うが。zenn.dev計画ができたら必ず文書化する：作成した計画をarchitecture-decisions/001-user-service-refactoring.mdに保存してこの文書化が後で自分を救う。「なぜこの設計にしたんだっけ？」という疑問に即答できる。ステップ3: 実装（検証を含む）計画ができたら、いよいよ実装だ。でも、一気に全部作らない。小さく始めて、段階的に拡張する。計画に従って、まずUserServiceの基本的なリファクタリングを実装して実装したら必ず検証：実装した部分のユニットテストを実行して、既存の機能が壊れていないか確認してエッジケースも忘れずに：nullやundefinedの場合の処理を追加して、エラーハンドリングを強化して途中で問題に気づいたら、軌道修正を恐れない：この実装だと循環依存が発生しそう。別のアプローチを検討して私の経験では、この段階的な実装が品質を大きく左右する。テストリストの作成などもここで行います。一気に作ると、どこで問題が起きたか分からなくなる。ステップ4: コミットとPR作成最後の仕上げがコミットとPR作成だ。ここも手を抜かない。コミットは論理的な単位で分ける：変更をリファクタリング、機能追加、テスト追加の3つのコミットに分けてコミットメッセージはConventional Commitsに従う：feat: ユーザーサービスに新しい認証メソッドを追加refactor: UserServiceの内部構造を改善test: UserServiceの新機能に対するテストを追加PRの説明は詳細に：PRを作成して。以下を含めて：- 変更の背景と目的- 実装アプローチの説明- テスト方法- 破壊的変更の有無- レビュアーへの注意点最後にドキュメントの更新も忘れずに、これらはCLAUDE.mdに記載してもよいREADME.mdとCLAUDE.mdも更新して、新しい機能とその使い方を記載してこのワークフローを続けた結果、コードの品質が明らかに向上した。何より、「なんとなく動く」コードから「なぜ動くか説明できる」コードになった。計画嫌いの私でも、このワークフローの価値は認めざるを得ない。テスト駆動開発（TDD）ワークフローの深掘りTDDについて正直に話そう。3ヶ月前の記事では理想論を書いた。でも現実は全然違う。正直なところ、TDDはいつも使うわけじゃない私のTDD使用率は、せいぜい10%くらいだ。5%ぐらいかもしれない。なぜそんなに低いのか。理由は単純で、私は「作りながら考える」タイプだから。最初から仕様が決まっていることなんて、実際に私がやっているような開発ではほとんどない。要求があるだけです。顧客も「動くものを見てから判断したい」と言うし、私も「とりあえず動かしてみないと分からない」と思っている。でもClaude Codeを使い始めて、面白い発見があった。AIこそがTDDを必要としているのだ。「また生き返ったのかTDD」と思うかもしれない。でも今回は違う。人間のためのTDDではなく、AIのためのTDDだ。TDDがAIコーディングで特に重要な理由AIの問題は「親切すぎる」ことだ。テストがないと、頼んでもいない機能まで実装してしまう。「ユーザー認証を実装して」と言ったら、ログイン履歴機能やパスワードリセット機能、二要素認証まで作り始める。テストがあれば違う。「このテストが通ればOK」という明確なゴールがある。AIは迷わない。過剰な実装もしない。これが快適だ。私がTDDを使う「よっぽど決まっているとき」では、具体的にどんな時にTDDを使うのか。1. APIのインターフェースが確定したときOpenAPI仕様書がある場合は迷わずTDDだ。リクエストとレスポンスの型が決まっていて、エラーケースも定義されている。こういう時は最初にテストを書く方が早い。2. 既存機能のリファクタリング「動作を変えずに内部構造を改善する」という明確な目標がある。現在の動作をテストで固定してから、安心してリファクタリングできる。3. バグ修正「このバグ、二度と出したくない」という強い決意がある時。再現手順が明確で、期待される動作も分かっている。テストを書いてから修正すれば、同じバグは二度と起きない。つまり、ゴールが明確な時だけTDDを使う。探索的な開発では使わない。これが私の現実的なアプローチだ。ステップ1: テストファーストAIとTDDを組み合わせる時、最初のテスト作成が肝心だ。例えば、ユーザー認証機能を作る場合：UserService.authenticateメソッドのテストを作成して。以下のケースをカバー：- 正常な認証成功- パスワード不一致- ユーザーが存在しない- アカウントがロックされている- 連続失敗によるロックポイントは「網羅的に書く」こと。人間なら「まあこれくらいでいいか」と手を抜くところも、AIは真面目に全部実装してくれる。あと、個人的にはモックを使わない派だ：実際のデータベース接続を使用してテストを作成。モックは使わないモックを使うと、実際の動作と乖離することがある。開発環境でDockerを使えば、本物のデータベースでテストできる。遅い？確かに。でも「動くと思ったのに本番で動かない」よりマシだ。あと同時に大切なのが本番環境を絶対に触らせないことです。ステップ2: RED - 失敗の確認テストを書いたら、必ず失敗することを確認する。これ、意外と重要。npm test -- UserService.test.ts失敗を見たら、AIに分析してもらう：テストの失敗理由を分析して。以下の観点で：- コンパイルエラーか実行時エラーか- 期待値と実際の値の差異- 未実装による失敗か、バグによる失敗かなぜわざわざ失敗を確認するのか。「最初から成功するテスト」は信用できないからだ。それはテストが甘いか、既に実装されているかのどちらかだ。ステップ3: GREEN - 最小限の実装ここでAIの「親切心」と戦う必要がある。テストが通る最小限の実装を作成して。過度な最適化や追加機能は含めないそれでもAIは余計なことをしたがる。だから明示的に制約する：IMPORTANT: テストケース以外の機能は実装しないYOU MUST: 各実装ステップ後にテストを実行して確認段階的に進めるのもコツだ：まず最も単純なケース（正常な認証）から実装を始めて一気に全部作らせると、どこで問題が起きたか分からなくなる。ステップ4: REFACTOR - コードの改善テストが通ったら、ようやくリファクタリングだ。ここでAIの本領発揮。テストが通ることを確認しながら、以下の観点でリファクタリング：- 重複コードの除去- 可読性の向上- パフォーマンスの最適化- ドキュメントの記載(README.md,CLAUDE.md,etc)- コメントの記載個人的には、このタイミングでドキュメントを書いてもらうことが多い。実装が終わってからだと、細かい仕様を忘れてしまうから。時には複数の改善案を比較することも：このコードの問題点を指摘して、改善案を3つ提示してAIは客観的に問題点を指摘してくれる。人間のレビュアーと違って、遠慮がない。便利なショートカットとツールClaude Codeには知らないと損するショートカットがたくさんある。docs.anthropic.com@ ファイル選択の効果的な使い方最も使うのが@によるファイル選択だ。基本形：@src/services/UserService.ts のcreateUserメソッドを改善してでも、本当の威力は複数ファイルを扱う時に発揮される：@src/services/UserService.ts と @src/models/User.ts を見て、データフローを説明してAIが関連ファイルを横断的に分析してくれる。人間だと「えーと、このファイルとあのファイルを開いて...」となるところが、一瞬で終わる。ディレクトリ全体を見ることも：@src/services/ ディレクトリのすべてのサービスの概要を説明して私のお気に入りはワイルドカード：@**/*Service.ts すべてのサービスファイルで共通のパターンを見つけてリファクタリングの時、これで共通化できる部分を見つけてもらう。通知設定これ、本当に知らない人が多い。Claude Codeは長時間のタスクも黙々とこなしてくれるが、通知設定をしていないと完了に気づけない。docs.anthropic.com私は「タスク完了時に音を鳴らす」設定にしている。コーヒーを飲みながら待てる。# ルール追加の戦略的活用その場限りのルールを追加したい時は#を使う：#このプロジェクトではzodでバリデーション。yupは使わない#エラーメッセージは必ず日本語で記述#APIレスポンスは必ずcamelCaseで統一CLAUDE.mdに書くほどでもない、一時的なルールに便利だ。例えば「今日は英語のコメントで統一」みたいな時に使う。ルールの優先順位は：1. セッション中の#コマンド（最優先）2. プロジェクトのCLAUDE.md3. ユーザーのCLAUDE.md（~/.claude/）この階層を理解していると、柔軟にルールを管理できる。スクショを使う、CleanShot Xを購入せよ私のTDD使用率コードだけでなく、ビジュアルでの確認も重要だ。特にUI開発では必須。なぜCleanShot XなのかmacOSの標準スクリーンショットも悪くない。でもCleanShot Xは別次元だ。cleanshot.com何が違うか：- 撮影後すぐに注釈を追加できる（矢印、テキスト、モザイク）- スクロールキャプチャで長いページも1枚に- GIF録画で操作手順を記録- クラウドにアップロードしてURLで共有特に「注釈」機能が神。「ここのマージンがおかしい」とか「このボタンの色を変えて」とか、視覚的に伝えられる。Claude Codeとの連携テクニック私のワークフロー：CleanShot Xでスクリーンショット（Cmd+Shift+4）問題箇所に赤丸や矢印で注釈Claude Codeにドラッグ\u0026ドロップ例えば：このデザインモックアップに基づいてコンポーネントを実装して画像を見せながら指示すると、AIの理解度が格段に上がる。「左側のサイドバーの幅を...」とか説明するより、画像1枚の方が早い。バグ報告でも威力を発揮：このエラー画面が表示される原因を調査して修正してエラーメッセージだけでなく、画面全体の状態を伝えられる。セッション管理とコンテキストの継続性「昨日の続きから作業したいけど、どこまでやったっけ？」この問題、Claude Codeなら解決できる。でも意外と知られていない。継続的な開発フローの構築朝一番のコマンド：$ claude --continueこれで前回のセッションの続きから始められる。AIは前回の作業内容を覚えている。特定のセッションを選びたい時：$ claude --resume複数のプロジェクトを並行して進めている時に便利。プロンプト履歴の編集:[Esc][Esc] → 前のプロンプトを編集 → EnterダブルEscapeで過去のプロンプトを編集可能。異なるアプローチを試すときに便利。具体的な指示を心がける。私の日課は、1日の終わりに：今日の作業内容を要約して、明日やるべきことをリストアップしてこれをやっておくと、翌日スムーズに始められる。AIが秘書みたいに働いてくれる。コンテキストの最適化長時間作業していると、コンテキストがゴチャゴチャしてくる。そんな時は：/clearでリセット。その後：@CLAUDE.md を読んで、プロジェクトのコンテキストを復元してこれで必要な情報だけを再読み込みできる。「お前は公式ドキュメントを読んでないな！？」と言いたくなるくらい、みんなこの機能を知らない。もったいない。3ヶ月前の理論が現実になって3ヶ月前、私は生成AIとの未来について妄想を書いた。「助手席での開発」「レッドボックス」「バイブスコーディング」...正直、半分くらいは願望だった。 speakerdeck.comでも、Claude Codeを1週間使った今、それらは全て現実になっている。いや、想像以上だった。助手席での開発が意外と楽しい「運転席を譲る」ことへの恐怖があった。エンジニアとしてのアイデンティティが揺らぐような気がして。でも実際は違った。助手席は助手席で、やることがたくさんある。私の役割：目的地を決める（何を作るか）ルートを提案する（アーキテクチャ）危険を察知する（セキュリティ、パフォーマンス）Claudeの役割：実際の運転（コーディング）交通ルールの遵守（言語仕様、ベストプラクティス）効率的なルート選択（アルゴリズム、最適化）この役割分担が心地いい。特に「計画は苦手だけどアイデアは豊富」な私にとって、理想的なパートナーだ。レッドボックスとの遭遇実際にあった話。Claude Codeがこんなコードを生成した：// Claudeが生成した謎のTypeScript型パズルtype DeepPartial\u003cT\u003e = T extends object ? {  [P in keyof T]?: DeepPartial\u003cT[P]\u003e;} : T;type RecursiveRequired\u003cT\u003e = T extends object ? {  [P in keyof T]-?: RecursiveRequired\u003cT[P]\u003e;} : T;正直、5秒見つめても理解できなかった。これが「レッドボックス」だ。でも大丈夫。CLAUDE.mdに追加すればいい：## 理解困難なコードへの対処- IMPORTANT: 複雑な型定義には必ず使用例とコメントを追加- YOU MUST: 生成したコードの動作原理を説明できることこれで次からは、AIが勝手に説明を追加してくれる。バイブスコーディングの実践これが一番楽しい発見だった。曖昧な指示でも、AIは文脈を読んでくれる：なんか認証周りがイケてない気がする。もっとスマートにしてこのUIのレイアウト、もうちょっとモダンな感じにしてパフォーマンスがビミョーだから、なんとかして「ビミョー」で伝わるAI。これがCLAUDE.mdの威力だ。プロジェクトの文脈を理解しているから、曖昧な指示でも適切に解釈してくれる。実践的なCLAUDE.md設定例理論はもういい。実際のCLAUDE.mdを見せよう。私が開発しているcctxプロジェクトから、効果的な部分を抜粋する。プロジェクト概要：読みやすさの工夫# 🔄 CLAUDE.md - cctx Project Documentation## 📋 Project Overview**cctx** (Claude Context) is a fast, secure, and intuitive command-line tool for managing multiple Claude Code `settings.json` configurations. Built with Rust for maximum performance and reliability.## 🏗️ Architecture### 🎯 Core Concept- **🔧 Context**: A saved Claude Code configuration stored as a JSON file- **⚡ Current Context**: The active configuration (`~/.claude/settings.json`)- **📁 Context Storage**: All contexts stored in `~/.claude/settings/`- **📊 State Management**: Current and previous context tracked in `.cctx-state.json`絵文字を使っているのは、人間（つまり私）が見た時に分かりやすいから。AIは絵文字なくても理解するが、私が理解できない。AIへの具体的な指示：成功の秘訣曖昧な指示より具体的な指示の方が成功率が大幅に向上します。曖昧さは、AIには毒だ。## 📚 Notes for AI AssistantsWhen working on this codebase:1. **Always run `cargo clippy` and fix warnings** before suggesting code2. **Test your changes** - don't assume code works3. **Preserve existing behavior** unless explicitly asked to change it4. **Follow Rust idioms** and best practices5. **Keep the kubectx-inspired UX** - simple, fast, intuitive6. **Maintain predictable defaults** - user should never be surprised7. **Document any new features** in both code and README8. **Consider edge cases** - empty states, missing files, permissionsRemember: This tool is about speed and simplicity. Every feature should make context switching faster or easier, not more complex. **Predictability beats cleverness.**最後の一文が効いている。「賢いより予測可能」。AIは時々、賢すぎる解決策を提案してくる。でもユーザーが求めているのは、予測可能な動作だ。開発ガイドライン：チェックリストの威力### Testing ChecklistWhen testing changes, verify:- [ ] `cctx` lists all contexts correctly- [ ] `cctx \u003cn\u003e` switches context- [ ] `cctx -` returns to previous context- [ ] Error messages are clear and helpful- [ ] State persistence works across sessionsチェックリスト形式にすると、AIもチェックしながら作業してくれる。レビュー時も楽。プロンプト改善のテクニックAnthropic公式が推奨する強調表現、実は3段階ある。使い分けが重要だ。強調レベルの使い分けNEVER（絶対禁止）：NEVER: パスワードやAPIキーをハードコーディングしないNEVER: ユーザーの確認なしにデータを削除しないNEVER: テストなしで本番環境にデプロイしないこれは本当にやってはいけないこと。AIは素直なので、明示的に禁止しないとやってしまう可能性がある。YOU MUST（必須事項）：YOU MUST: すべての公開APIにドキュメントを記載YOU MUST: エラーハンドリングを実装YOU MUST: 変更前に既存テストが通ることを確認必ずやってほしいこと。でも、状況によっては例外もありえる。IMPORTANT（重要事項）：IMPORTANT: パフォーマンスへの影響を考慮IMPORTANT: 後方互換性を維持IMPORTANT: セキュリティベストプラクティスに従う考慮してほしいこと。判断はAIに委ねる。この3段階を使い分けることで、AIの行動を適切にコントロールできる。高度な活用：並行開発とCI/CDカスタムスラッシュコマンドで定型作業を自動化公式例：GitHub Issue対応の自動化.claude/commands/fix-github-issue.md:Please analyze and fix the GitHub issue: $ARGUMENTS.Follow these steps:1. Use `gh issue view` to get the issue details2. Understand the problem described in the issue3. Search the codebase for relevant files4. Implement the necessary changes to fix the issue5. Write and run tests to verify the fix6. Ensure code passes linting and type checking7. Create a descriptive commit message8. Push and create a PRRemember to use the GitHub CLI (`gh`) for all GitHub-related tasks.使用方法：\u003e /project:fix-github-issue 1234Git Worktreeで複数タスクを同時進行これは上級テクニック。でも覚えると手放せなくなる。git-scm.com例えば、機能開発しながらバグ修正もしたい時：# 機能開発用worktree$ git worktree add ../project-feature-auth feature/auth# バグ修正用worktree  $ git worktree add ../project-bugfix-api bugfix/api-error# 各worktreeで独立したClaude Codeセッション$ cd ../project-feature-auth \u0026\u0026 claude$ cd ../project-bugfix-api \u0026\u0026 claudeそれぞれのディレクトリで独立したClaude Codeセッションが動く。コンテキストが混ざらない。最高。というか人の業の深さを感じれてよい…。CI/CDへの統合Claude Codeはコマンドラインツールなので、CI/CDにも組み込める。docs.anthropic.comGitHub Actionsの例：- name: Claude Code Review  run: |    claude -p \"このPRの変更をレビューして、以下の観点で問題を指摘：    - セキュリティ脆弱性    - パフォーマンス問題    - コーディング規約違反\" \\    --output-format json \u003e review.json自動化できることは自動化する。人間はもっとクリエイティブなことに時間を使うべきだ。permissions.allowの推奨設定セッション中に「Always allow」を選択するか、/permissionsコマンドで追加できるがsetting.json でも追加できる。syu-m-5151.hatenablog.com公式が推奨する基本的な許可リスト：{  \"permissions\": {    \"allow\": [      \"List(*)\",      \"Fetch(https://*)\",      \"Edit(*)\",      \"Bash(git:*)\",      \"Bash(npm:*)\",      \"Bash(ls:*)\",      \"Bash(cat:*)\",      \"Bash(mkdir:*)\",      \"Bash(mv:*)\"    ]  }}まとめClaude Codeを1週間使い込んで確信した。CLAUDE.mdは単なる設定ファイルじゃない。AIとの共通言語だ。youtu.be3ヶ月前、私は理想を語った。「生成AIとの協業で『動作するきれいなコード』を実現する」と。正直、半分は願望だった。syu-m-5151.hatenablog.comでも今、それは現実になっている。私は「助手席」に座り、AIが「運転席」でコードを書く。最初は違和感があったが、今では心地いい。むしろ、なぜ今まで全部自分でやろうとしていたのか不思議にさえ思う。www.oreilly.com3ヶ月で変わったこと、変わらなかったこと変わったこと：理論が実践になった曖昧な指示でも伝わるようになったコードの品質が向上した開発速度が圧倒的に上がった変わらなかったこと：計画を立てるのは相変わらず苦手TDDへの抵抗感は残っている「とりあえず動かしてみる」精神は健在コードを書く楽しさは失われていない最後の点が重要だ。AIに仕事を奪われたのではない。つまらない部分を任せて、楽しい部分に集中できるようになった。効果的なCLAUDE.mdを書くコツ：明確なプロジェクト概要 - AIも人間も理解できるように具体的なワークフロー - 探索→計画→実装→コミット実用的なコマンド集 - よく使うものを網羅AIへの明示的な指示 - NEVER、YOU MUST、IMPORTANTを使い分けるこれらを押さえれば、AIは最高のパートナーになる。「予測可能性は賢さに勝る」 - この原則を胸に、CLAUDE.mdを育てていこう。3ヶ月後、私はまた記事を書いているだろう。タイトルは分からない。でも一つ確実なのは、私はまだ助手席に座っているということ。そして、それを楽しんでいるということだ。なぜなら、助手席こそが最も楽しい席だから。他社も同じぐらいのプランをいずれ出すのでCodex CLIやjulesが楽しみです。","isoDate":"2025-06-06T10:08:47.000Z","dateMiliSeconds":1749204527000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Introducing cctx: A Context Switcher for Claude Code","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/05/232126","contentSnippet":"IntroductionAs developers, we often juggle multiple contexts throughout our day - switching between personal projects, client work, and perhaps some experimental code on the side. Each context might require different permissions, access levels, and configurations. If you're using Claude Code, Anthropic's CLI tool for interacting with Claude, you've probably felt the pain of manually managing different settings.json configurations. That's why I built cctx - a fast, intuitive context switcher for Claude Code, inspired by the excellent kubectx tool for Kubernetes.github.comThe Problem: Configuration Context SwitchingClaude Code uses a settings.json file to control permissions, access levels, and various configurations. This is great for security and customization, but becomes cumbersome when you need different settings for different scenarios:Work projects need restricted permissions for safetyPersonal projects might need full access to your file systemClient demos require ultra-restricted settings for screen sharingExperimental work needs different tool accessManually editing settings.json or maintaining multiple copies quickly becomes error-prone and tedious. I needed something better.docs.anthropic.comEnter cctx: Fast Context Switching for Claude Codecctx (Claude Context) brings the simplicity and speed of kubectx to Claude Code configuration management. Written in Rust for maximum performance, it allows you to switch between different Claude Code configurations with a single command:# Switch to work context (restricted permissions)cctx work# Switch to personal context (full permissions)cctx personal# Switch back to previous contextcctx -Design Philosophy: Predictable Defaults with Progressive DisclosureOne of the key lessons learned during development was the importance of predictable behavior. In version 0.1.1+, I completely redesigned the UX around a simple principle: predictable defaults with explicit overrides.What This Means in PracticeDefault behavior is always the same - cctx always manages user-level contexts (~/.claude/settings.json) unless explicitly told otherwiseNo surprising auto-detection - The tool won't suddenly switch to project-level contexts just because you're in a different directoryProgressive disclosure - When project or local contexts are available, helpful hints guide you to themExplicit when needed - Use --in-project or --local flags when you want to manage other context levelsThis approach eliminates cognitive overhead while maintaining full functionality for advanced users.Key Features That Make cctx Shine🚀 Lightning FastBuilt with Rust, cctx switches contexts in milliseconds. No Python startup overhead, no Node.js dependencies - just pure speed.🎨 Beautiful, Intuitive InterfaceColor-coded output with the current context highlighted in greenHelpful emoji indicators for different context levels (👤 User, 📁 Project, 💻 Local)Interactive fuzzy search with fzf integration or built-in finderClear, actionable error messages🛡️ Security-First DesignCreate separate contexts for different security requirements:# Create a restricted work contextcctx -n workcctx -e work  # Edit to add restrictions# Create a demo context for screen sharingcctx -n demo  # Ultra-restricted, read-only📁 Simple File-Based StorageContexts are just JSON files stored in ~/.claude/settings/. You can edit them manually, version control them, or sync them across machines.Real-World Usage PatternsHere's how I use cctx in my daily workflow:Morning Routine# Start the day with work contextcctx work# Check what context I'm incctx -c# Output: workProject Switching# Working on a personal projectcctx personal# Client calls - need to share screencctx demo# Back to personal projectcctx -Context Management# Create a new context for a specific clientcctx -n client-acme# Edit the context to set appropriate permissionscctx -e client-acme# List all contextscctx# Output:# 👤 User contexts:#   client-acme#   demo#   personal#   work (current)Technical Implementation HighlightsWhy Rust?Performance: Instant startup and executionSafety: Memory safety without garbage collectionSingle binary: Easy distribution and installationGreat ecosystem: Excellent CLI libraries like clap and dialoguerArchitecture DecisionsFile-based contexts: Each context is a separate JSON fileAtomic operations: Context switching is done by copying filesState tracking: Current and previous contexts tracked in a hidden state filePlatform compatibility: Works on Linux, macOS, and WindowsSettings Hierarchy Supportcctx respects Claude Code's settings hierarchy while keeping things simple:# Default: user-level contextscctx work# Explicit: project-level contextscctx --in-project staging# Explicit: local project contextscctx --local debugGetting StartedInstallation is straightforward:# From crates.io (recommended)cargo install cctx# Or grab a pre-built binary# Download from https://github.com/nwiizo/cctx/releasesCreate your first contexts:# Create a personal context from current settingscctx -n personal# Create a restricted work contextcctx -n workcctx -e work  # Edit to add restrictions# Start switching!cctx workcctx personalcctx -  # Switch backWhat's Next?The cctx project is actively maintained and follows Claude Code's development closely. Some ideas for the future include:Context templates for common scenariosShell integration for automatic context switchingContext inheritance for shared settingsIntegration with other AI coding toolsConclusioncctx brings the joy of quick context switching to Claude Code users. By focusing on speed, simplicity, and predictable behavior, it removes the friction from managing multiple configurations. Whether you're switching between work and personal projects, managing client-specific settings, or just want better control over your Claude Code permissions, cctx has you covered.The project is open source and available on GitHub. If you find it useful, please consider starring the repository and contributing your own ideas and improvements. Happy context switching!cctx is an independent open-source project and is not affiliated with Anthropic. For official Claude Code documentation and support, please visit docs.anthropic.com.","isoDate":"2025-06-05T14:21:26.000Z","dateMiliSeconds":1749133286000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude Code の settings.json は設定した方がいい","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/05/134147","contentSnippet":"はじめにClaude Code 使ってますか？ターミナルから Claude に直接コーディングタスクを投げられる便利なツールなんですが、デフォルト設定のまま使うのはちょっともったいない。というかいちいちいろんなことを聞いてきてめちゃくちゃダルい。syu-m-5151.hatenablog.comsettings.json をちゃんと設定すると、セキュリティも保ちつつ、もっと快適に使えるようになります。全体的に疲れている時の~/.claude/settings.json と~/.claude/CLAUDE.md · GitHub 私のデフォルトの設定も公開してますのでよかったら参考にしてください。ここで読むのをやめる人のために言っておくと Claude Codeの設定は優先順位があるので覚えておくと良い です。あと、比較的に今は黎明期なので非推奨や追加機能が多いのでその点も注意が必要かもです。正直なところ、Anthropic の公式ドキュメント（日本語）が最高に分かりやすいので、まずはそっちを読んでほしいんですが、このブログは公式ドキュメントに赤線を引いたようなもので、実際に使ってみて「これは設定しといた方がいいよ」っていうポイントをピックアップしてまとめました。docs.anthropic.comsettings.json って何？settings.json は Claude Code の動作を制御する設定ファイルです。公式ドキュメントによると、こんな設定ができます。{  \"permissions\": {    \"allow\": [      \"Bash(npm run lint)\",      \"Bash(npm run test:*)\",      \"Read(~/.zshrc)\"    ],    \"deny\": [      \"Bash(curl:*)\"    ]  },  \"env\": {    \"CLAUDE_CODE_ENABLE_TELEMETRY\": \"1\",    \"OTEL_METRICS_EXPORTER\": \"otlp\"  }}設定できる項目 キー  説明  例  apiKeyHelper  Anthropic APIキーを生成するカスタムスクリプト  /bin/generate_temp_api_key.sh  cleanupPeriodDays  チャット記録をローカルに保持する期間（デフォルト：30日）  20  env  すべてのセッションに適用される環境変数  {\"FOO\": \"bar\"}  includeCoAuthoredBy  gitコミットにco-authored-by Claudeを含めるか（デフォルト：true）  false  permissions  ツールのアクセス権限設定  後述 権限設定をちゃんとやろうClaude Code の一番重要な機能がこの権限設定。/permissions コマンドで現在の設定を確認できます。/permissionsはとても良いので覚えておいてほしいです。また、便利なCLIの使い方も覚えておいたほうが多分良いです。docs.anthropic.comBash コマンドの制御{  \"permissions\": {    \"allow\": [      \"Bash(npm run build)\",      // 特定のコマンドだけ許可      \"Bash(npm run test:*)\",     // プレフィックスで許可      \"Bash(git:*)\"               // git コマンドは全部OK    ],    \"deny\": [      \"Bash(curl:*)\"              // curl は使わせない    ]  }}Claude Code はシェル演算子（\u0026\u0026など）も認識してるので、Bash(safe-cmd:*)みたいなルールでもsafe-cmd \u0026\u0026 dangerous-cmdみたいなのは実行できません。賢い！ファイルアクセスの制御Read と Edit のルールは gitignore の仕様に従います：{  \"permissions\": {    \"allow\": [      \"Edit(docs/**)\",           // プロジェクトの docs ディレクトリ内を編集可能      \"Read(~/.zshrc)\",         // ホームディレクトリの .zshrc を読める      \"Edit(//tmp/scratch.txt)\" // 絶対パスは // で指定    ]  }}Web アクセスの制御{  \"permissions\": {    \"allow\": [      \"WebFetch(domain:example.com)\"  // 特定ドメインのみ許可    ]  }}環境変数の活用公式ドキュメントに載ってる環境変数をうまく使うと便利：{  \"env\": {    \"ANTHROPIC_API_KEY\": \"your-key-here\",    \"CLAUDE_CODE_ENABLE_TELEMETRY\": \"0\",    \"DISABLE_COST_WARNINGS\": \"1\",    \"BASH_DEFAULT_TIMEOUT_MS\": \"300000\",    \"BASH_MAX_TIMEOUT_MS\": \"1200000\"  }}主要な環境変数 変数名  用途  CLAUDE_CODE_ENABLE_TELEMETRY  テレメトリの有効/無効  DISABLE_COST_WARNINGS  コスト警告を無効化  BASH_DEFAULT_TIMEOUT_MS  Bashコマンドのデフォルトタイムアウト  DISABLE_AUTOUPDATER  自動更新を無効化 設定の優先順位を理解しよう公式ドキュメントによると、設定は以下の順番で適用されます（上が優先）：エンタープライズポリシーコマンドライン引数ローカルプロジェクト設定（.claude/settings.local.json）共有プロジェクト設定（.claude/settings.json）ユーザー設定（~/.claude/settings.json）プロジェクトごとに設定を変えたければ、プロジェクトフォルダに .claude/settings.json を置けばOK。Git で共有したくない設定は .claude/settings.local.json に書こう。実践的な設定例制限的な設定（仕事用）{  \"permissions\": {    \"allow\": [      \"Bash(npm run lint)\",      \"Bash(npm run test:*)\",      \"Bash(git:*)\",      \"Read(./src/**)\",      \"Edit(./src/**)\"    ],    \"deny\": [      \"Bash(npm publish:*)\",      \"WebFetch(domain:*)\"    ]  },  \"includeCoAuthoredBy\": false}もう少しゆるい設定（個人用）{  \"permissions\": {    \"allow\": [      \"Bash(npm:*)\",      \"Bash(git:*)\",      \"Bash(cargo:*)\",      \"Read(**)\",      \"Edit(~/projects/**)\",      \"WebFetch(domain:*)\"    ]  },  \"cleanupPeriodDays\": 60}MCP (Model Context Protocol) を使う場合MCP サーバーを使ってる人向けの権限設定：{  \"permissions\": {    \"allow\": [      \"mcp__puppeteer\",                        // puppeteer サーバーの全ツール      \"mcp__puppeteer__puppeteer_navigate\"     // 特定のツールだけ    ]  }}複数の設定を切り替えたいならちなみに、複数の~/.claude/settings.jsonを簡単に切り替えたい人向けに cctx っていうツールも作ってみました。cargo install cctxまとめClaude Code の settings.json は、ちゃんと設定すると作業効率とセキュリティが大幅に向上します。ちゃんとしましょう。特に重要なのは：権限設定で必要最小限のアクセスだけ許可するプロジェクトごとに適切な設定を使い分ける環境変数でタイムアウトやテレメトリを調整する詳しい設定方法は Anthropic の公式ドキュメント（日本語）がマジで分かりやすいので、ぜひ読んでみてください。Anthropic の公式ドキュメント最高！Claude Code の 公式ドキュメントやベストプラクティス はとりあえず読んだ方がいい。www.anthropic.com参考リンクClaude Code 公式ドキュメント（日本語） - これ読めば全部分かるcctx - Claude Context Manager - 設定切り替えツールClaude Code 設定例（Gist） - 実際の設定例","isoDate":"2025-06-05T04:41:47.000Z","dateMiliSeconds":1749098507000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIが進化しても、なぜそのコードを書いたかは消えていく","link":"https://syu-m-5151.hatenablog.com/entry/2025/06/01/122352","contentSnippet":"はじめに生成AIを使ったコード開発が急速に普及している。GitHub Copilot、ChatGPT、Claude、そして各種IDEに統合されたAIアシスタントや独立したコーディングエージェント。これらのツールは開発効率を飛躍的に向上させ、もはやAIなしでの開発は考えられないという声も聞こえてくる（主に心の底から）。しかし、この革新的な変化の中で、看過できない問題が顕在化している。現在のAIで生成したコードは、2年後の進化したAIで再生成すれば、より効率的で保守性の高いコードに置き換えられる。これ自体は技術進歩として歓迎すべきことだが、重要な情報が失われている。それは「なぜそのコードをそのように実装したのか」という意思決定の記録だ。この問題は単なる技術的な課題ではない。私たちがどのようにソフトウェアを作り、保守し、進化させていくかという、エンジニアリングの本質に関わる問題だ（そして、2年後の自分に恨まれない方法でもある）。プロンプトと成果物の分離がもたらす課題従来の開発では、コードとともにコメントやドキュメントで意図を残してきた。しかしAI時代では、以下の情報が分離してしまう：入力：プロンプト（要件、制約、背景情報）出力：生成されたコード生成されたコードだけがリポジトリに残り、そのコードを生成した際のプロンプトや文脈は失われる。2年後、より優れたAIでコードを改善しようとしても、元の要件や制約条件、設計判断の根拠が不明なため、適切な改善ができない。これは「なんでこんな実装になってるの？」と聞かれて「AIがそう書いたから...」としか答えられない悲しい未来への第一歩だ。ADRからPDRへ：解決策の提案ソフトウェアアーキテクチャの分野では、ADR（Architecture Decision Records）によって設計判断を記録する文化が定着している。同様に、AI時代にはPDR（Prompt Decision Records）が必要だ。syu-m-5151.hatenablog.comPDRに記録すべき要素：使用したAIモデルとバージョン（GPT-4なのかClaude-3なのか、未来の自分は知りたがっている）入力したプロンプトの完全なテキストプロンプトに込めた意図と背景検討した他の選択肢採用した理由とトレードオフ生成パラメータ（temperature、max_tokens等）既存ツールにおける実装例既存ツールの現状についてはこちらがめちゃくちゃよくまとまっております。azukiazusa.devCursor Rulesdocs.cursor.comCursorでは.cursorrulesファイルでプロジェクト固有のコンテキストを定義できる。これにより、AIは常にプロジェクトの規約や方針を理解した上でコードを生成する（理解しているフリをすることもあるが）。具体的には、プロジェクトのルートディレクトリに.cursorrulesファイルを配置することで、以下のような指示を永続化できる：このプロジェクトではTypeScriptを使用し、関数型プログラミングのアプローチを優先する。エラーハンドリングはResult型を使用し、例外は投げない。すべての関数にはJSDocコメントを必須とする。このファイルはプロジェクト全体で共有される暗黙知を形式知化する役割を果たし、新しいメンバーがジョインした際のオンボーディングツールとしても機能する。Cline Rulesdocs.cline.botClineも同様に、プロジェクトルールを定義する仕組みを提供している。これらのルールファイルは、実質的にプロンプトの一部を永続化する仕組みだ。Clineの特徴的な点は、ルールを階層的に管理できることだ。グローバルルール、プロジェクトルール、ディレクトリ固有のルールを定義でき、より細かい粒度でAIの振る舞いを制御できる。例えば：/backendディレクトリ：「APIエンドポイントはRESTfulな設計に従う」/frontendディレクトリ：「ReactコンポーネントはHooksを使用した関数コンポーネントとする」/testsディレクトリ：「テストはAAA（Arrange-Act-Assert）パターンに従う」このようなコンテキストの階層管理により、大規模プロジェクトでも一貫性を保ちながら、部分ごとに最適化されたAI支援を受けられる。Anthropic CLAUDE.mdwww.anthropic.comAnthropicのCLAUDE.mdアプローチは、プロジェクトの全体的なコンテキストを単一のマークダウンファイルにまとめる。これは包括的なプロンプトテンプレートとして機能し、AIとの対話の基盤となる。CLAUDE.mdの強みは、単なるルールの羅列ではなく、プロジェクトのストーリーを語る点にある。典型的な構成は：# プロジェクト概要このプロジェクトの目的と背景# アーキテクチャシステムの全体構成と主要コンポーネントの説明# 開発規約- コーディングスタイル- 命名規則- ディレクトリ構造# よくある質問と回答過去の設計判断とその理由この形式により、AIは単にルールに従うだけでなく、プロジェクトの「なぜ」を理解した上でコードを生成できる。まさに本記事で提唱するPDRの考え方を先取りした実装と言えるだろう。実装における具体的な課題バージョン管理プロンプトもコードと同様にバージョン管理が必要だ。しかし、以下の課題がある：プロンプトの変更がコードに与える影響の追跡AIモデルのバージョンアップに伴う互換性管理プロンプトとコードの紐付けの維持（gitのblameコマンドに「AI」と表示される悲しさ）標準化の欠如現状、プロンプトを記録・管理する標準的な方法は存在しない。各ツールが独自の方法を実装しているため、ツール間での移植性がない。まるで文字コードの乱立時代を彷彿とさせる。再現性の問題同じプロンプトでも、以下の要因により出力が変わる：AIモデルのバージョン生成パラメータAPIのバージョン実行タイミング（モデルの更新）今後の展望と提案短期的な対策既存ツールの活用Cursor、Cline、GitHub Copilotなどが提供するルールファイル機能を積極的に活用し、プロジェクト固有のコンテキストを記録・管理する。プロンプトのコメント埋め込み生成されたコードに、使用したプロンプトをコメントとして埋め込む（将来の自分への手紙として）。専用ディレクトリでの管理/promptsディレクトリを作成し、コードファイルと対応するプロンプトファイルを保存。生成メタデータの記録生成日時、モデルバージョン、パラメータをJSONで保存。中長期的な標準化業界標準として、以下のような仕様が必要になるかもしれない：# prompt-decision-record.yamlversion: 1.0timestamp: 2024-12-XXmodel:  provider: openai  name: gpt-4  version: gpt-4-0125-preview  mood: cooperative  # 冗談ですparameters:  temperature: 0.7  max_tokens: 2000prompt: |  実際のプロンプトテキストcontext:  requirements: |    要件の説明  constraints: |    制約事項  decisions: |    設計判断の根拠output_file: src/feature/***.pyおわりにAI活用が当たり前になる開発環境において、コードの「なぜ」を残すことは、技術的負債を防ぐ重要な実践だ。2年後により良いAIが登場したとき、過去の意思決定を理解できれば、真に価値のある改善が可能になる。私たちエンジニアは、常に未来の自分や同僚のことを考えてコードを書いてきた。可読性、保守性、拡張性—これらはすべて「未来の誰か」のための配慮だ。AI時代においても、この精神は変わらない。むしろ、AIの進化速度を考えれば、より一層重要になる。プロンプトは新しい形の設計書だ。コードレビューと同じように、プロンプトレビューが必要になるかもしれない。リファクタリングと同じように、プロンプトリファクタリングが日常になるかもしれない（プロンプトの可読性を議論する日も近い）。もしくはそのような考慮をすべて超えて全てを理解する生成AIのモデルが成長する可能性もある。PDRのような仕組みの標準化は、AI時代のソフトウェア開発における必須要件となるだろう。エンジニアとして、この課題に真剣に取り組む時期に来ているが、個人ではどうにもならない気もするので。頑張れ、Anthropic！！！","isoDate":"2025-06-01T03:23:52.000Z","dateMiliSeconds":1748748232000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"marp.nvimを開発してCursorから完全移行した話","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/31/105405","contentSnippet":"なぜmarp.nvimが必要だったのか前回の記事でClaude Codeに移行し、Neovimに完全回帰することを決めた。コーディング、ドキュメント作成、設定ファイルの編集――すべてが再びターミナルで完結するようになった。しかし、一つだけ問題があった。Marpでのプレゼンテーション作成だ。Marpは素晴らしいツールだが、公式のNeovimサポートは存在しない。プレゼンテーションを作るたびに、仕方なくVSCodeやCursorを起動していた。せっかくNeovimに完全回帰したのに、プレゼン作成のためだけに別のエディタを立ち上げる。この矛盾が許せなかった。marp.app既存のソリューションを探したが、満足できるものはなかった。ならば答えは一つ――自作するしかない。こうしてmarp.nvimは生まれた。Neovimですべてを完結させるという理想を、妥協なく追求した結果だ。github.commarp.nvimの技術的アプローチアーキテクチャ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Neovim    │────▶│  marp.nvim  │────▶│  Marp CLI   ││   Buffer    │     │  Lua Plugin │     │  --watch    │└─────────────┘     └─────────────┘     └─────────────┘                            │                            ▼                    ┌─────────────┐                    │   Browser   │                    │  Auto-open  │                    └─────────────┘コア実装の詳細1. Marp CLIのプロセス管理これは完全にMarp の作者が優秀なのですがMarpには--watchオプションが存在しています。これを使わない手はないです-- プロセスをバッファごとに管理M.active_processes = {}-- jobstart で Marp CLI を起動local job_id = vim.fn.jobstart(shell_cmd, {    pty = true,  -- 擬似端末で適切な出力キャプチャ    stdout_buffered = false,    stderr_buffered = false,    on_stdout = function(_, data)        -- 出力処理    end,    on_exit = function()        M.active_processes[bufnr] = nil    end})重要なポイント：pty = trueを使用することで、Marp CLIのカラー出力を適切に処理stdout_buffered = falseでリアルタイム出力を実現バッファ番号をキーにしてプロセスを管理2. 自動クリーンアップの実装vim.api.nvim_create_autocmd({\"BufDelete\", \"BufWipeout\"}, {    buffer = bufnr,    once = true,    callback = function()        M.stop(bufnr)    end})VSCode拡張機能では当たり前の機能だが、Neovimでは自前実装が必要。バッファのライフサイクルに合わせてプロセスを管理。3. ウォッチモード vs サーバーモードif M.config.server_mode then    cmd = string.format(\"%s -s '%s'\", marp_cmd, file)else    -- デフォルトは --watch モード    cmd = string.format(\"%s --watch '%s'\", marp_cmd, file)end2つのモードをサポート：ウォッチモード（デフォルト）: HTMLファイルを生成し、変更を監視サーバーモード: HTTPサーバーを起動（ポート競合の可能性あり）4. ANSIエスケープシーケンスの処理local function clean_ansi(str)    return str:gsub(\"\\27%[[%d;]*m\", \"\"):gsub(\"\\27%[[%d;]*[A-Za-z]\", \"\")endMarp CLIの美しいカラー出力をNeovimの通知システムで扱うための処理。これがないと文字化けする。実装で工夫した点1. 初回HTML生成の最適化-- ウォッチモード開始前に初回HTMLを生成if not M.config.server_mode then    local init_cmd = string.format(\"%s '%s' -o '%s'\", marp_cmd, file, html_file)    vim.fn.system(init_cmd)        if vim.fn.filereadable(html_file) == 1 then        -- 即座にブラウザを開く        M.open_browser(\"file://\" .. html_file)    endend--watchモードは初回生成が遅いため、事前に生成してUXを改善。2. クロスプラットフォーム対応function M.open_browser(url)    local cmd    if vim.fn.has(\"mac\") == 1 then        cmd = \"open \" .. url    elseif vim.fn.has(\"unix\") == 1 then        cmd = \"xdg-open \" .. url    elseif vim.fn.has(\"win32\") == 1 then        cmd = \"start \" .. url    end    vim.fn.jobstart(cmd, {detach = true})end3. デバッグモードM.config = {    debug = true,  -- 詳細ログを有効化}-- :MarpDebug コマンドで診断function M.debug()    local test_cmd = string.format(\"%s --version\", marp_cmd)    -- Marp CLIの動作確認endトラブルシューティングを容易にするため、詳細なログ出力機能を実装。VSCode拡張機能との機能比較 機能  Marp for VS Code  marp.nvim  ライブプレビュー  ✅  ✅  自動リロード(書き込みイベント時)  ✅  ✅  テーマ切り替え  GUI  :MarpTheme  エクスポート  GUI  :MarpExport  スライドナビゲーション  ✅  ❌（開発中）  スニペット  ✅  ✅  複数ファイル同時編集  ✅  ✅ 使用方法インストール-- lazy.nvim{    \"nwiizo/marp.nvim\",    ft = \"markdown\",    config = function()        require(\"marp\").setup({            marp_command = \"npx @marp-team/marp-cli@latest\",            debug = false,            server_mode = false,  -- ウォッチモードを使用        })    end,}基本的なワークフロー:e presentation.md:MarpWatch          \" プレビュー開始(ファイル名をClipboardに書き込みもしている):MarpTheme uncover  \" テーマ変更:MarpExport pdf     \" PDF出力:q                  \" バッファを閉じると自動でサーバー停止トラブルシューティング:MarpDebug          \" Marp CLIの動作確認:MarpList           \" アクティブなサーバー一覧:MarpStopAll        \" 全サーバー停止パフォーマンスと制限事項メモリ使用量Marp CLIプロセス: 約50-100MB/インスタンス複数ファイル同時編集時は線形に増加既知の制限ホットリロードの遅延: ファイル保存からブラウザ更新まで約100-200ms大規模ファイル: 100スライド以上でパフォーマンス低下画像の相対パス: 作業ディレクトリに依存まとめmarp.nvimの開発により、Marpプレゼンテーション作成のためだけにCursorを起動する必要がなくなった。Neovimのjob APIを活用することで、VSCode拡張機能と似た体験を実現できることを証明できた。重要なのは、完璧を求めすぎないこと。VSCode拡張機能のすべての機能を再現する必要はない。ターミナルでの開発に必要十分な機能を、シンプルに実装することが大切だ。Claude Codeとの組み合わせで、プレゼンテーション作成もAIアシスト付きで行える。これで本当にすべての開発作業をNeovimで完結できるようになった。vimmer村への完全帰還、達成。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazon","isoDate":"2025-05-31T01:54:05.000Z","dateMiliSeconds":1748656445000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude Code を利用しようと思っているのでvimmer が住む村に帰ろうと思います。","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/30/180912","contentSnippet":"はじめに前回、「NeovimをCursorのように進化させる - yetone/avante.nvim の導入」を書いた。あの記事では、まるで自分だけの剣を鍛え上げていくように、エディターと共に成長していくPDEの哲学について語った。syu-m-5151.hatenablog.comあれから数ヶ月、私のNeovimはavante.nvimによってCursor + Roo-Codeライクな体験を手に入れ、PDEとしてさらなる進化を遂げた。しかし、告白しなければならないことがある。vimmerを自称しながら、実は日常的にCursorを使っていた。この矛盾と向き合う時が来た。www.cursor.comそして先週の土曜日、私はClaude Codeを使い始めた。今日で1週間。短い期間だが、これが私のPDEに新たな可能性をもたらすことを確信している。そして、Cursor のサブスクを解約してClaude をMAX Planにした。www.youtube.com私は、Claude Code を利用しようと思っているのでvimmer が住む村に帰ろうと思います。一旦、お別れです。 pic.twitter.com/Is5fAUD5hI— nwiizo (@nwiizo) 2025年5月29日   「いいえ、Neovimはもっと強くなれます」前回からの旅路：PDEという哲学前回の記事で、私はこう書いた：Neovimの最大の魅力は、その圧倒的なカスタマイズ性。それは単なるIDE（統合開発環境）ではなく、PDE（Personal Development Environment：個人開発環境）とも呼べる存在です。この言葉は、今思えば預言的だった。PDEという概念は、単にツールをカスタマイズすることではない。それは、開発者が自分自身の思考プロセスと一体化したツールを作り上げることだ。まるで自分だけの剣を鍛え上げていくように、エディターと共に成長していく。そして今、私は気づいた。PDEとは、一人で剣の丘で鉄を鍛つような孤独で崇高な作業なのだと。誰かが用意した完成品ではなく、自分の手で、自分のために、一つ一つ形作っていくもの。avante.nvimは、その第一歩だった。しかし、6ヶ月間Cursor + Roo-Codeを使い込んだことで、私は逆説的にPDEの価値を理解した。Cursor + Roo-Codeは確かに完成度の高い「製品」だ。しかし、私が求めていたのは「作品」—自分の手で育てていけるものだった。実際には育ててなくても育てている感覚があるものだ。正直に告白しよう。vimmerを自称しながらも、実は各所でCursor + Roo-Codeを使っていた。クライアントワークでは生産性を優先してCursor、個人プロジェクトではNeovim。そんな二重生活を送っていた。この矛盾に、私自身も気づいていた。なぜ今、Claude Codeなのか正直に言えば、Claude Codeを使い始めた最大の理由は、Claude Opus 4がリリースされたからだ。最新にして最強のモデル。その能力を、私の愛するターミナル環境で直接使えるなんて—これは試さずにはいられなかった。zenn.devしかし、それだけではない。Claude Codeが掲げる「Terminal Velocity」という概念に、私は強く惹かれた。www.anthropic.com考えてみてほしい。私たちvimmerは、なぜターミナルから離れないのか？それは、思考の流れを断ち切りたくないからだ。GUIアプリケーションへの切り替え、マウスへの手の移動、異なるUIパラダイムへの適応—これらすべてが、私たちの集中を妨げる。Claude Codeは、その問題を根本から解決する。「コンテキストスイッチをゼロにする」—これは、PDEの究極の形かもしれない。そしてもう一つ、個人的に重要だったのがMAX Planという料金体系だ。トークン数無制限。これは貧乏性の私にとって革命的だった。Cursorでは常に「今月あとどれくらい使えるか」を気にしていた。コーディングエージェントでコードを書く前に「これ、AIに聞くほどの価値があるかな？」と躊躇する。そんな心理的ブレーキが、創造性を阻害していたことに気づいた。MAX Planは、その制限から私を解放してくれた。思考のままに、遠慮なくAIと対話できる。まるで無限のメモ帳を手に入れたような感覚だ。「トークンがもったいない」という貧乏性マインドから解放されて初めて、本当の意味でAIとの協働が始まる。これこそが、私のメンタルモデルと完璧に合致した。先週土曜日から使い始めて、まだ1週間。しかし、その短い期間でも、Claude Codeの持つ独特の「控えめな賢さ」に魅了された。Roo-Codeのような積極性はない。しかし、それがかえって心地よい。必要な時に、必要なだけ、的確な支援をしてくれる。Claude Opus 4の高い理解力が、控えめながらも的確なアドバイスを可能にしているのだろう。そして何より、もうトークン数を気にする必要がない。深夜のコーディングセッションで「あと何回質問できるかな...」と計算する必要もない。この精神的な自由度が、私の開発スタイルを根本から変えつつある。zenn.devzenn.devnote.comCursor + Roo-Codeへの敬意、そして決別誤解しないでほしい。私はCursor + Roo-Codeを否定したいわけではない。実際、この6ヶ月間、私は久しぶりにVSCodeベースのCursorをメインエディタとして使い込んだ。そしてそれは、驚くほど素晴らしい体験だった。特にRoo-Codeとの組み合わせで実感したのは、これは単にAIモデルを統合しただけのツールではないということだ。それは開発体験そのものが根本的に違う。github.com考えてみてほしい。従来の開発では、私たちは一つのファイルを開き、一行ずつコードを書いていた。しかしCursor + Roo-Codeの世界では、コードベース全体が一つの有機体として扱われる。「このコンポーネントをリファクタリングして」と言えば、関連する全てのファイルが瞬時に更新される。「このテストを追加して」と言えば、適切なディレクトリに適切な形式でテストが生成される。さらに驚くべきは、Roo-Codeが持つ「意図の理解」だ。曖昧な指示でも、プロジェクトの文脈を読み取り、開発者が本当に必要としているものを推測して提案してくる。それは、経験豊富な同僚とペアプログラミングをしているような感覚だった。これは単なる効率化ではない。これは開発の概念そのものの再定義だった。正直に言えば、これほど生産的な6ヶ月は久しぶりだった。前回の記事でavante.nvimを導入したのも、このCursor + Roo-Codeの革新的な開発体験に触発されたからこそだった。6ヶ月のCursor + Roo-Code体験は、確かに私の開発スタイルを変えた。Tab補完を超えた、AIペアプログラミング。しかし同時に、ある種の違和感も育っていった。それは、自分がコードを「書いている」のか「選んでいる」のか、境界が曖昧になる感覚だった。そして、もう一つの違和感。朝はNeovimで始めたはずが、気がつけばCursorを開いている。締切が迫ると、つい効率的な方を選んでしまう。vimmerとしてのアイデンティティが揺らいでいた。この6ヶ月は、技術的な進歩と同時に、自分自身との葛藤の期間でもあった。Roo-Codeが見せてくれた「開発体験の違い」は革新的だった。しかし、それゆえに気づいたことがある。開発者として長年培ってきた直感が教えてくれる。私たちには「まだ形になっていないアイデアを、コードという形で具現化する」という独特の能力がある。AIはコードを生成できる。しかし、なぜそのコードが必要なのか、それが解決すべき本質的な問題は何かを理解することはできない。そして今、6ヶ月の濃密な体験を経て、私は確信を持って言える—Cursor + Roo-Codeは素晴らしい。その組み合わせは革命的だ。しかし、私にはPDEとしてのNeovimがある。それは単なるエディタではなく、私の思考の延長線上にある道具なのだ。PDEの完成形を目指してしかし、正直に言えば、この6ヶ月はNeovimとCursorの間で揺れ動いていた。月曜の朝は「今週こそNeovimで」と決意するも、水曜には締切に追われてCursorを開く。金曜には罪悪感を感じながらも、Roo-Codeの生産性に頼っていた。vimmerとしての矜持はどこへ行ったのか。だが、この葛藤の中で私は気づいた。PDEとは、単に優れたツールを集めることではない。それは、自分の開発哲学と完全に一致した環境を構築することだ。そして今、NeovimコミュニティはAI時代に適応し、驚くべき進化を遂げている。以下に紹介する3つのプラグインは、その進化の最前線にある。yetone/avante.nvim - 前回の記事で導入したこのプラグインは、Cursor AI IDEの体験をNeovimで完璧に再現する。サイドバーでのAI対話、差分の視覚的表示、ワンクリックでのコード適用など、Cursor + Roo-Codeユーザーが慣れ親しんだ機能をすべて提供する。しかし、それだけではない。Neovimのモーダル編集と完全に統合されているため、思考の流れを妨げることなくAIとの対話を行える。ravitemer/mcphub.nvim - AnthropicのModel Context Protocol (MCP)をNeovimに統合する革新的なプラグイン。MCPサーバーの集中管理により、AIが外部ツールやデータソースにシームレスにアクセスできるようになる。データベースへの直接クエリ、ファイルシステムの操作、外部APIとの連携—これらすべてがNeovimの中で完結する。これこそが、未来のAI開発環境の標準となるだろう。こちらでMCP経由でもclaude-codeを利用している。greggh/claude-code.nvim - Claude Code CLIとNeovimを完全に融合させる野心的なプロジェクト。ターミナル内でClaude Opus 4を含む最新モデルの全能力を解き放ち、まさに「Terminal Velocity」を体現する。:ClaudeCodeコマンド一つで、現在のバッファやプロジェクト全体のコンテキストを理解した上で、最適な提案を行ってくれる。これは単なるプラグインではない—開発体験の再定義だ。これらのツールを組み合わせることで、私のNeovimは単なるテキストエディタから、真のAI統合開発環境へと進化した。もはやCursorを羨む必要はない。むしろ、より深く、より個人的な形でAIと協働できる環境が、ここにある。github.comPDEという哲学の深化PDEとは何か。それは、開発者の思考パターンとツールが完全に一体化した環境だ。前回の記事で初めてこの概念を提示したが、6ヶ月の実践を経て、その意味がより深く理解できるようになった。筆者は専門家ではないため、あくまで個人的な経験に基づく話として聞いていただきたいが、優れたPDEには以下の特徴がある：思考の流れを妨げない：Warp + Neovim + Claude Codeの組み合わせ拡張可能性：新しいツールを取り込める柔軟性個人の哲学の反映：設定ファイルという形での思想の具現化私の~/.config/nvim/lua/plugins/init.luaは、単なる設定ファイルではない。これは私の開発思想の結晶だ。Lazy.nvimを通じて管理されるプラグインの一つ一つが、私の開発哲学を体現している。Cursor + Roo-Codeの体験を経て、その設定はさらに洗練された。そして何より、PDEの構築は一人で剣の丘で鉄を鍛つ行為に似ている。誰も代わりにはできない。自分の手で、自分のために、ひたすら打ち続ける。時に孤独で、時に苦しい。しかし、その先に待っているのは、自分だけの、世界に一つだけの剣だ。Cursor + Roo-Codeが示してくれた新しい開発体験は、確かに革新的だった。しかし、それらは「完成品」だ。一方、PDEとしてのNeovimは「進化し続ける生き物」のようなものだ。私の成長と共に、私の理解と共に、そして私の哲学と共に変化していく。この1週間、Claude Codeを使いながら感じたのは、「これこそが私の求めていたAIとの距離感だ」ということだった。過度に依存せず、しかし必要な時には頼れる。まさに理想的なパートナーシップだ。そして何より、もう環境を使い分ける必要がない。朝から晩まで、クライアントワークも個人プロジェクトも、すべてを私のPDEで完結できる。この統一感が、開発者としての一貫性を取り戻してくれた。おわりに前回の記事から始まった旅は、今、新たな段階に入った。avante.nvimで手に入れたCursor + Roo-Codeライクな体験に、Claude Codeの「Terminal Velocity」が加わることで、私のPDEは更に進化した。興味深いのは、最先端を追求した結果、最も原始的なツール—ターミナルとテキストエディタ—に戻ってきたことだ。しかし、これは後退ではない。これは螺旋的な進化だ。AIとの協働が当たり前になる時代において、私たちに必要なのは、AIとの適切な距離感を保ちながら、共に新たな地平を切り開いていく勇気かもしれない。そして、その第一歩が、自分のPDEを完成させることなのだ。Cursor + Roo-Codeが示してくれた新しい開発体験は、確かに未来の一つの形だ。しかし、それが唯一の答えではない。私たちには、自分自身の開発哲学に基づいて、自分だけの環境を構築する自由がある。「いいえ、Neovimはもっと強くなれます」—この言葉は、単なる願望ではない。それは、PDEという哲学を持つ私たちvimmerの確信なのだ。そして今、Claude Codeの登場により、私はついに二重生活から解放される。もうクライアントワークでCursor、個人でNeovimという使い分けをする必要はない。私のPDEが、すべての開発シーンで通用する強さを手に入れたのだから。そして、PDEの構築とは、一人で剣の丘で鉄を鍛つような営みだ。誰かが用意した剣ではなく、自分の手で打ち、自分の手で研ぎ、自分だけの刃を作り上げる。その過程こそが、私たちを真の開発者にするのかもしれない。この記事を書いている間、私はWarpターミナル上でNeovimとClaude Codeを行き来している。前回のavante.nvim導入から数ヶ月、そして Claude Code導入から1週間。私のPDEは確実に進化した。Lazy.nvimの設定ファイルは公開しているので、興味があれば参考にしてほしい。「Terminal Velocity」を「ターミナルベロシティ」とカタカナ表記したのは、この概念の持つ物理学的な含意—終端速度、つまり最高効率—を日本語でも感じてもらいたかったからだ。「Cursor + Roo-Codeのサブスクリプションを払い続けるか、vimの学習コストを払うか」—これは単なる経済的判断ではない。私たちが開発という行為にどう向き合うか、そしてPDEという哲学をどこまで追求するかという、実存的な選択なのかもしれない。6ヶ月のCursor + Roo-Code体験は本当に素晴らしかった。特にRoo-Codeが示してくれた「開発体験の違い」は、私の開発観を根本から変えた。もしあなたがまだ試していないなら、一度は体験する価値がある。その上で、自分にとっての最適な開発環境を選ぶべきだ。私にとって、それはPDEとしてのNeovimだった。この二重生活は疲れるものだった。.vimrcと.vscode/settings.jsonを行き来し、キーバインドの違いに戸惑い、どちらが本当の自分なのか分からなくなることもあった。しかし、その経験があったからこそ、今の決断に至ることができた。あなたも、vimmer村への帰郷を考えてみてはどうだろうか。Claude Codeという新しい仲間と共に、自分だけのPDEを完成させるために。VimConf 2025 Smallにも行こうかな…。今度こそ、胸を張って「私はvimmerです(え、Neovim ですよね？)」と言えるように。vimconf.org実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazon","isoDate":"2025-05-30T09:09:12.000Z","dateMiliSeconds":1748596152000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【思考実験】バイブコーディング(Vibe coding)と多腕バンディット問題 - 選択の最適化と報酬の探索","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646","contentSnippet":"はじめに生成AIが普及して、プログラミングの世界に「バイブコーディング（Vibe Coding）」という面白い言葉が生まれています。なんとなくの感覚や「バイブ(雰囲気)」に頼りながら、AIとやり取りしてコードを作るこの方法は、従来のプログラミングとは全く違うアプローチです。www.gitpod.iolearning.oreilly.com一方で、確率論の世界には「多腕バンディット問題」という古典的な問題があります。限られた時間の中で、どの選択肢が一番良い結果をくれるか分からない状況で、どうやって最良の選択をするか—という問題です。この二つ、一見全く関係なさそうですが、よく観察してみると驚くほど似ています。私たちがAIに色々なプロンプトを試している行動は、実は多腕バンディット問題を解いているのと同じようなことをしているのです。本稿では、この意外な共通点を深く探りながら、日常的なバイブコーディングの中に隠れている、洗練された認知メカニズムの正体に迫ってみたいと思います。注：筆者は多腕バンディット問題の専門家ではないため、解釈に誤りがある可能性があります。あくまで思考実験として読んでいただければと思います。バイブコーディングという新しい認知活動バイブコーディングをしている時、私たちは無意識に以下のようなことをしています：「こういう書き方でプロンプトを書いてみよう」「前回これでうまくいったから、今回も同じパターンでやってみよう」「なんか今日は調子悪いな、違うアプローチを試してみるか」「この例を見せた方が良いコードが出そうだ」興味深いのは、これらの行動が極めて自然に、まるで本能のように現れることです。特別な訓練を受けたわけでもないのに、多くの人が似たような試行錯誤のパターンを示します。www.businessinsider.com多腕バンディット問題多腕バンディット問題を簡単に説明すると：状況： カジノに複数のスロットマシンがあります。それぞれ当たりやすさが違いますが、どれが一番当たりやすいかは分かりません。目標： 限られた時間で、できるだけ多くの当たりを出したい。ジレンマ： 新しいマシンを試して情報を集める（探索）べきか、今まで当たりが多かったマシンをずっと使う（活用）べきか？この「探索と活用のトレードオフ」は、実は生物の進化から人間の日常生活まで、あらゆる場面に現れる根本的な意思決定パターンです。新しいレストランを試すか、お気に入りの店に行くか。新しい本を読むか、好きな作家の作品を読み返すか。私たちは常にこのジレンマと向き合っています。バンディット問題の理論とアルゴリズム (機械学習プロフェッショナルシリーズ)作者:本多淳也,中村篤祥講談社Amazonバイブコーディングをほぼスロットマシンなので...バイブコーディングを多腕バンディット問題として見たとき、その対応関係は驚くほど明確です。「スロットマシン」= プロンプトのパターン「詳しく説明してからコードを書いて」「具体例を示してから実装して」「ステップバイステップで教えて」「エラーハンドリングも含めて書いて」「当たり」= 期待する品質のコードが生成される「探索と活用のジレンマ」= 新しいプロンプト戦略を試すか、慣れ親しんだ方法を使うかしかも、この対応関係は表面的なものではありません。行動パターンの時間的変化、学習曲線、意思決定の心理的メカニズムまで、驚くほど一致しているのです。学習段階の自然な進化初心者期：無制限探索の混沌プログラミングを始めたばかりの人がAIを使う時は、まさに「片っ端から試してみる」状態です。成功率は低いものの、各プロンプトパターンがどれくらい有効かを肌感覚で学習しています。これは多腕バンディット問題における「純粋探索フェーズ」に相当します。中級者期：偏った活用の安定ある程度経験を積むと、「この書き方はいつもうまくいく」という黄金パターンを発見し、それに依存するようになります。これは効率的ですが、より良い戦略を見逃すリスクもはらんでいます。多腕バンディット問題で言う「早期収束の罠」です。上級者期：動的バランスの芸術経験豊富な人は、状況に応じて探索と活用のバランスを直感的に調整します。新しいモデルが出れば探索モードに戻り、安定したタスクでは効率的なパターンを活用します。これは最も洗練された多腕バンディット戦略と言えるでしょう。この自然な進化過程は、特別な理論を学ばなくても、人間が本能的に最適化アルゴリズムを身につけることを示しています。コンテキストによる戦略の分化興味深いことに、プログラミング言語やAIモデルが変わると、最適なプロンプト戦略も変化します。Pythonでうまくいくアプローチが、C++では効果的でない。GPT-4で成功した方法が、Claude では通用しない。これは多腕バンディット問題における「コンテキスト付きバンディット」の典型例です。同じ「腕」（プロンプトパターン）でも、文脈によって期待報酬が変わるのです。熟練したエンジニアは、この文脈の切り替えを無意識に行います。言語を変えると同時に、プロンプト戦略も自動的に調整される。これは、人間の適応的学習能力の驚くべき柔軟性を物語っています。「報酬」の多次元性と測定の難しさバイブコーディングにおける「報酬」は、多腕バンディット問題の古典的な設定よりもはるかに複雑です。即座に測定できる報酬コンパイルが通る期待した動作をする実行時間が短い長期的な報酬コードの可読性保守のしやすさチーム開発での再利用性主観的な報酬「美しい」コード学習になるコード創意工夫のあるコードこの多次元的な報酬構造が、バイブコーディングを単純な最適化問題以上の、芸術的な活動にしているのかもしれません。自動テストが変革する「報酬関数」ここで自動テストの存在が、バイブコーディングの性質を根本的に変えることに注目したいと思います。テストがない状況では、報酬の測定は主観的で曖昧です。「なんとなく動いているから良いコード」という判断は、多腕バンディット問題で言う「ノイズの多い報酬シグナル」です。一方、自動テストがある場合、報酬は明確で客観的になります。「全テストが通る」は0か1かの明確な成功指標です。これにより、どのプロンプト戦略が本当に効果的かを正確に学習できるようになります。この変化は単なる測定精度の向上以上の意味を持ちます。報酬関数の明確化により、学習アルゴリズムそのものが高度化するのです。syu-m-5151.hatenablog.comプロンプトエンジニアリングという「期待値制御」プロンプトエンジニアリングを多腕バンディット問題の視点で見ると、これは「各腕の期待報酬を高める技術」と解釈できます。曖昧なプロンプト「ログイン機能を作って」は、期待報酬の分散が大きい「腕」です。うまくいく時もあれば、全く期待外れの結果になることもある。一方、詳細で構造化されたプロンプトは、期待報酬の平均値を高め、分散を小さくします。これは多腕バンディット問題において、明らかに優位な「腕」です。興味深いのは、多くの人がプロンプトエンジニアリングの重要性を、理論を知らずとも実感していることです。これは、人間が直感的に「期待値と分散の最適化」を理解していることを示唆しています。チーム協働における「集合知のバンディット」個人でのバイブコーディングから、チームでの協働に視点を移すと、さらに興味深い現象が見えてきます。複数のエンジニアが異なる「腕」を並行して探索し、成果を共有する。これは「協調型バンディット」と呼ばれる高度な問題設定です。全員が同じ試行錯誤を繰り返す無駄を避け、チーム全体として効率的に最適解に近づいていきます。「このプロンプトパターンが効果的だった」「このアプローチは避けた方がいい」こうした情報共有は、個人の学習速度を遥かに超える集合的な最適化を可能にします。人間が本能的に行う知識共有行動が、実は数学的に最適な協調戦略だったのです。AIモデル進化への適応：非定常環境での生存戦略AIモデルの頻繁なアップデートは、バイブコーディングに非定常性という新たな次元を加えます。昨日まで最適だった戦略が、新しいモデルでは全く効果がない。これは生物の進化圧にも似た、動的な環境変化です。この変化に対して、経験豊富なエンジニアは見事な適応を見せます。新しいモデルが出ると、自動的に「探索モード」に切り替わる。過去の成功体験にとらわれず、新たな最適解を求めて試行錯誤を始める。この柔軟性は、多腕バンディット問題の理論が想定する以上の高度な適応能力です。環境の変化を察知し、学習戦略そのものを動的に調整する—これは人間の認知能力の真骨頂と言えるでしょう。「バイブ」の正体：統計的直感の結晶「バイブ」や「勘」と呼ばれる現象の正体を、多腕バンディット問題の枠組みで考えてみると、驚くべき洞察が得られます。経験豊富なエンジニアが「なんとなくこのアプローチが良さそう」と感じる時、それは過去の膨大な試行錯誤から蓄積された統計的パターンの内在化です。意識的には覚えていない微細な成功・失敗の記憶が、直感的判断として表面化している。これは、Thompson Samplingという高度なアルゴリズムと本質的に同じメカニズムです。過去の経験から各戦略の成功確率分布を学習し、その分布に基づいて確率的に選択を行う。完全に論理的でもなく、完全にランダムでもない、絶妙なバランスの意思決定です。「バイブ」は非科学的なものどころか、むしろ最先端の確率的アルゴリズムを人間が自然に実装している証拠なのです。中毒性の数学的説明バイブコーディングに多くの人が「ハマる」理由も、多腕バンディット問題の枠組みで説明できます。新しいプロンプトを試すたびに得られる「うまくいくかもしれない」という期待感。実際に良いコードが生成された時の達成感。これらは、不確実性の中で最適解を探索する過程で得られる本能的な報酬です。人間の脳は、探索と活用のバランスを取る活動に対して、進化的に報酬を与えるよう設計されています。バイブコーディングがこの古い報酬系を刺激するからこそ、多くの人が夢中になるのでしょう。なぜこの類似性が存在するのかここで根本的な問いに向き合ってみましょう。なぜバイブコーディングと多腕バンディット問題は、これほどまでに似ているのでしょうか？一つの仮説は、人間の学習と意思決定の根底にある共通のメカニズムです。不確実な環境で最適な選択を見つけるという課題は、人類が何十万年もの間直面してきた生存問題でした。どの狩場が豊富な獲物をもたらすか。どの植物が安全で栄養価が高いか。多腕バンディット問題は、この根本的な生存戦略を数学的に抽象化したものです。そして、バイブコーディングは、この古い学習メカニズムが新しい技術的環境で発現したものなのかもしれません。イプシロン-グリーディ戦略としての日常多くのエンジニアが無意識に実践している行動パターンを詳しく観察すると、「イプシロン-グリーディ戦略」との類似性が見えてきます：大部分の時間（90%）: 今まで最も成功率の高かった方法を使う（活用）少しの時間（10%）: 新しい方法を試してみる（探索）「いつものパターンでやってみよう。あ、でもたまには違うアプローチも試してみるか」この何気ない意思決定が、実は数学的に洗練された最適化戦略だというのは、驚くべき発見です。UCB的思考の高次元化より洗練された判断をする人は、UCB（Upper Confidence Bound）アルゴリズムに似た思考を示します：「このプロンプトは過去に良い結果を出したけど、まだ試行回数が少ないから、もう少し試してみる価値がある」これは、平均的な成功率だけでなく、「不確実性」も考慮した意思決定です。試行回数が少ない選択肢に対して「まだ可能性がある」という判断を下す。この高次な推論を、多くの人が自然に行っているのです。認知バイアスとしての「過度な活用」一方で、バイブコーディングには多腕バンディット問題と同様の落とし穴もあります。早期収束の罠: 最初に見つけた成功パターンに固執し、より良い方法を探索しなくなる。確証バイアス: 自分のお気に入りの方法がうまくいった事例ばかりを記憶し、失敗例を忘れてしまう。環境変化への適応遅れ: 新しいAIモデルが出ても、古い戦略に固執し続ける。これらの認知バイアスは、多腕バンディット問題における「準最適解への収束」と本質的に同じ現象です。人間の学習メカニズムの限界が、両方の文脈で同様に現れているのです。思考実験から見えてくることこの思考実験から得られる洞察を、整理してみましょう。第一に、私たちが日常的に行っている「試行錯誤」は思っているより合理的だということです。「なんとなく」でプロンプトを選んでいるように見えて、実は過去の経験から学習した効率的な戦略を使っているのです。第二に、自動テストやプロンプトエンジニアリングが効果的な理由が、多腕バンディット問題の観点から説明できることです。これは単なる「ベストプラクティス」ではなく、学習効率を上げる合理的な手法だったのです。第三に、チームでのAI活用が個人より効果的な理由も明確になります。みんなで情報共有することで、効率的に最適解を見つけられる。これは感覚的に分かっていたことですが、理論的な裏付けがあったということです。エンジニアとしての実感実際にバイブコーディングをしている身として、この類似性には「なるほど、そういうことか」という納得感があります。新しいプロジェクトを始める時の「色々試してみる」段階、ある程度慣れてきて「いつものパターン」を使うようになる段階、そして新しいAIモデルが出ると再び「探索モード」に戻る段階。この流れは、多くのエンジニアが体験していることでしょう。特に興味深いのは、「なんか今日は調子悪いな」と感じて戦略を変える時の判断です。これも、実は環境の変化を察知した合理的な適応行動だった可能性があります。おわりにこの思考実験の面白さは、日頃「感覚的」だと思っていた行動に、実は理論的な構造があったという発見にあります。「バイブ」と呼んでいた直感は、決してランダムな当て推量ではありませんでした。それは、過去の大量の試行錯誤から学習した、効率的な意思決定メカニズムのように思えます。私たちがAIに向かって何気なくプロンプトを打っている時、実は無意識のうちに確率的な最適化を行っている。理論を知らなくても、効果的な学習戦略を実践している。この発見は、バイブコーディングをただの「なんとなくのコーディング」から、理論に裏打ちされた合理的なアプローチとして捉え直すきっかけを与えてくれます。最終的に、この思考実験が示しているのは、私たちエンジニアが思っているより賢く、効率的に学習し、適応しているということです。それは決して特別なことではなく、人間が持つ自然な学習能力の現れなのかもしれません。","isoDate":"2025-05-25T05:36:46.000Z","dateMiliSeconds":1748151406000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"これから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752","contentSnippet":"この記事で得られる3つのポイント「つぶしが効く」エンジニアになる: 表面的な技術習得ではなく、根本原理の深い理解と問題解決能力が長期的な市場価値を創出するAI時代の新たな役割: テクノロジーと人間の強みを組み合わせ、AIとの効果的な協働を設計・実現できる「アーキテクト」としての視点計画的偶発性の活用: 不確実性を受け入れ、専門性と横断性のバランス、継続的学習、そして「偶然を必然に変える」姿勢の重要性はじめにみなさん、こんにちは！本日はアカリクの就職ラウンジイベント＠会津大学に来ていただき、ありがとうございます。「AI時代に市場価値を高めるキャリア戦略」というテーマでお話しさせていただきます。口頭で補足しながらいろいろやっていきます。よろしくお願いします。acaric.jp現役エンジニアとして日々AIの進化と自身のキャリアパスに向き合う中で、私が得た気づきや思考を皆さんと共有できればと思います。なお、本発表では何冊かの書籍を紹介していますが、必ずしも読む必要もないです。興味があればでよいです。購入する必要も余計にありません。図書館での閲覧や貸出サービスを活用していただければと思います。疑問があればこの場でもDMでも聞いていただければと思います。完全に別件で20代のキャリア形成を振り返ったブログ記事も紹介しますので、同じ道を歩む方々の参考になれば幸いです。syu-m-5151.hatenablog.com会津大学の皆さんは、日本有数のコンピュータサイエンス教育を受けている最中ですね。私がコンピュータサイエンスを学んでいた頃と比べると、周りの環境は一変しています。ほんの10数年前、私が学生だったころには「AIがコードを書く」というのはまだSFの世界の話でした。「そんな日が来るのかな〜」なんて友達と冗談半分で話していたのに、気づけばそれが当たり前になっている。2020年の「アップロード ～デジタルなあの世へようこそ」（死後デジタル世界へアップロードされた主人公を描くSFコメディ）には、AIによるコード支援の形でペアプロのような描写がありましたが、今や私たちの現実はそれを遥かに超えています。ja.wikipedia.org2025年の今、生成AIはもはや「選択肢」ではなく「前提」です。私の職場でも、多くのエンジニアがCline、Cursor、RooといったAIコーディングアシスタントを日常的に活用しています。「人間がコードを書く」という、これまでエンジニアの核心的業務だと思われていた部分が急速に変化しつつあります。zenn.devこの変化に直面して、皆さんはこんな疑問を持っているかもしれませんね：「プログラミング言語やアルゴリズムを学ぶ意味は、これからどこにあるんだろう？」「AIがコードを書く時代に、エンジニアとして私は何をすればいいんだろう？」実は、私も同じような疑問を感じながら日々仕事をしています。でも、この変化は単なる脅威ではなく、新たな可能性も開いてくれると思うんです。AIの登場によって、私たちエンジニアの役割も進化していくのかもしれません。www.oreilly.com今日の講演では、プログラミングの基礎知識の重要性はもちろん、それに加えて「文脈に応じた適切な問いの立て方」や「AIとの効果的な協働方法」など、これからのエンジニアに求められるスキルについて考えていきたいと思います。本日は、実際の現場での経験や試行錯誤から学んだことをもとに、具体的で実践的なお話ができればと思っています。皆さんはAIと共に成長する世代のエンジニアです。これは確かに挑戦ですが、同時に新しい可能性にも満ちています。それでは、まずは将来価値のあるエンジニア像から考えていきましょう。この記事で得られる3つのポイントはじめに1. 「つぶしが効く」エンジニアになるために深い理解の価値なぜ専門家ほどAIを使いこなせるのか理解の範囲がツール活用の上限を決める原理原則は腐らない知識になるAI時代における深い理解の実践的意味実践のためのアドバイス2. 技術を点ではなくて線で見極める目を養う技術の進化と本質的価値長期的に価値を持つスキルの見極め方実践のためのアドバイス3. 技術革新と不平等の歴史から学ぶ歴史に見る技術革命と不平等AI革命の文脈で考えるエンジニアの責任と可能性4. そして、エンジニアになるユーザーに寄り添うエンジニアになる技術に寄り添うエンジニアになる自分に寄り添うエンジニアになる量をこなすことの本質的価値ちゃんと、エンジニアになる5. 計画的偶発性理論とAI時代のキャリア戦略計画的偶発性理論とは計画的偶発性を生み出す5つの行動特性1. 好奇心（Curiosity）2. 持続性（Persistence）3. 楽観性（Optimism）4. 柔軟性（Flexibility）5. 冒険心（Risk Taking）計画的偶発性理論に基づくキャリアの基礎構築専門性と横断性のバランス実践的な問題解決経験人間同士のコミュニケーション能力明日からの具体的なアクションAIツールの実験と比較日記を通じた言語化能力の向上コミュニティへの参加と知識の還元不確実性を受け入れ、偶然を活かす姿勢おわりにこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はてなブログに投稿しましたこれから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学 - じゃあ、おうちで学べる  https://t.co/cUS6z4nBmt#はてなブログ— nwiizo (@nwiizo) 2025年5月21日   1. 「つぶしが効く」エンジニアになるために皆さん、エンジニアとして長く活躍するために最も重要なことは何でしょうか？それは「つぶしが効く」エンジニアになることです。つまり、どんな環境でも、どんな技術変化が起きても適応できる基盤を持つことが重要です。「つぶしが効く」エンジニアになるには、標準化された技術スタックの習得だけでは不十分です。 技術の深層に潜り、なぜそう設計されているのかを理解し、他社や他プロジェクトでも応用できる原理原則を掴むことが重要です。表面的な技術習得より、深い洞察を積み重ねることこそが差別化につながります。エンジニアとしての私自身の経験から言えることですが、本当にキャリアの長期的な安定性をもたらすのは、特定のプログラミング言語やフレームワークの知識ではなく、「なぜそのように設計されているのか」という根本的な理解です。例えば、10年前にモバイルアプリ開発で流行していたフレームワークの多くは今や使われていませんが、その基盤となるアーキテクチャパターンや並行処理の原則は今でも変わらず価値を持っています。もし、Webのバックエンドエンジニアとして就職がしたいと思っているなら「データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理」などを読むとよいのではないでしょうか？ちょうど、来年ぐらいに第2版もリリースされることですし、learning.oreilly.com若いうちからやっておいた方がよく、失ってから「なぜ誰も教えてくれなかったのか」と後悔することが多い健康管理。これはAI時代においても最も必要なものの一つです。そして見落とされがちですが、「つぶしが効く」エンジニアキャリアの持続可能性において身体的・精神的健康の維持は極めて重要です。 デスクワークが中心のエンジニアは運動不足になりがちで、長時間のコーディングや深夜の障害対応などで睡眠リズムが乱れやすい職業です。健康管理は本当に大切なことです。理想的には、週に3回程度の有酸素運動と軽い筋トレを習慣化することをお勧めします。特にデスクワークによる姿勢の悪化を防ぐために、背中や体幹の筋肉を鍛えることは効果的です。また、1時間に一度は立ち上がって5分程度ストレッチするだけでも違います。最近では多くのエンジニアが導入している昇降式デスクも検討する価値があるでしょう。精神面では、定期的な休息とメンタルリフレッシュの時間確保が重要です。技術の進化が早いIT業界では常に学び続ける必要がありますが、それだけに燃え尽き症候群のリスクも高いです。趣味や運動など、コーディング以外の活動に意識的に時間を割くことで、長期的には創造性や問題解決能力も向上します。運動脳作者:アンデシュ・ハンセンAmazon深い理解の価値なぜ専門家ほどAIを使いこなせるのか現在のLLMはプログラミング教師としてはもはや人間より性能が上だと言えるでしょう。膨大なコードベースから学習したLLMは、何千もの言語やフレームワークについての知識を持ち、無限の忍耐力で初心者の質問に答えることができます。そして次の世代のLLMは今の世代よりさらに優秀になることが予想されます。このような状況で、多くの人が「AIがコードを書いてくれるなら、私たちエンジニアは何をすればいいの？」と疑問に思います。しかし、興味深い現象が起きています。AIツールを最も効果的に使いこなしているのは、すでにその分野に深い知識を持つエンジニアたちなのです。これは「生成AIが何でもやってくれる」という主張と矛盾しているように思えますが、実は理にかなっています。深い理解を持つエンジニアは、AIの提案を適切に評価し、改善点を見つけ、より良い解決策へと導くことができるからです。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon理解の範囲がツール活用の上限を決めるここで重要な原則があります。「自分の認知を超えるものは活用できない」ということです。例えば、プログラミングの基本概念を理解していない人がAIに「効率的なアルゴリズムを書いて」と頼んでも、生成されたコードが本当に効率的かどうかを判断できません。データベース設計の原則を知らない人が「スケーラブルなデータモデルを設計して」と指示しても、結果の質を評価する基準がないのです。現場の視点から言えば、AIが生成したコードを無批判に受け入れた結果、既にいくつかの重大なパフォーマンス問題やセキュリティホールを生み出してしまう例を何度も目にしてきました。反対に、基礎をしっかり理解しているエンジニアは、AIの提案を適切に評価し、時には「ここはこうした方がいい」と修正を加えることができます。ファンタジア(吹替版)ミッキーマウスAmazon原理原則は腐らない知識になるなぜAIの時代にも深い理解が重要なのでしょうか。その答えは、コードの「良い」「悪い」を決めるのは、AIでも人間の主観でもなく、そのコードが負う責任だからです。責任の評価: その責任の重さと範囲を正確に評価できるのは、システムの基盤となる原理を深く理解している人だけです影響範囲の見極め: AIが提案する解決策の影響範囲と限界を見極め、より適切な方向性を示せるのは、システム設計の原則と実世界での影響を理解している人だけです統合と責任: AIが生成した出力を実際の問題解決に統合し、その結果に責任を持てるのは、全体的なアーキテクチャを理解しているエンジニアだけですプログラミング言語やツールは変わっても、基本的な原則や設計パターンは何十年も変わりません。アルゴリズム、データ構造、分散システム、データベース設計などの基礎的な知識は、AIの時代になってもその価値が色あせることはありません。むしろ、AIが成熟するほど、ソフトウェアの量は爆発的に増えます。その基盤となる原理原則を理解している人の価値は高まるのです。syu-m-5151.hatenablog.comAI時代における深い理解の実践的意味結局のところ、AIをパートナーとして活用し、その出力を批判的に評価し、改良できる能力こそが、これからのエンジニアに求められる真の価値なのです。これは次のような実践を意味します：AIとの対話における質問力: 適切な問いを立て、AIから価値ある回答を引き出す能力出力の評価眼: AIが生成したコードやアイデアの品質を見極める判断力改善と統合: AIの提案を実際のプロジェクトに適用し、必要に応じて改善する技術力責任ある実装: 最終的な成果物に対して技術的責任を負える専門性AIが発展すればするほど、私たち自身も成長し続ける必要があります。AIと効果的に協働するための使い方は、自分自身の学びと経験に基づいて考え、発展させていくものなのです。これからのエンジニアは、AIを単なる「便利なツール」として使うのではなく、深い理解に基づいた「創造的なパートナーシップ」を築いていく必要があるでしょう。そのパートナーシップの質を決めるのは、結局のところ、私たち人間が持つ基礎的理解の深さなのです。 speakerdeck.com実践のためのアドバイスでは、大学生の皆さんが「つぶしが効く」エンジニアになるために、具体的に何をすべきでしょうか？基礎を徹底的に学ぶ：授業で教わるアルゴリズムとデータ構造を丸暗記ではなく、本質的に理解する講義だけでなく、自分で実装してみることで理解を深めるコンピュータサイエンスの基礎科目を軽視せず、しっかり身につけるOSの仕組みやメモリ管理などのローレベルな動作原理も抽象化に頼らず理解する「なぜ」を常に問う：新しい技術やツールに出会ったとき、「なぜこれが存在するのか」を考える課題やレポートに取り組む際、「これはなぜこの方法で解くのか」を自問自答するAIがコードを生成したときも、「なぜこのような実装になるのか」を考察する「どうやって」の前に「なぜ」を問うことで、表面的な理解を超える多様な経験を積む：授業の課題だけでなく、サークル活動やハッカソンなど異なる環境での開発を経験するチームプロジェクトに積極的に参加し、異なる役割を経験してみるコンテストや学外の活動にも挑戦して視野を広げる可能であれば異なる規模のプロジェクト（小規模な個人プロジェクトから大規模なチーム開発まで）を経験するいいやつになる：技術力だけでなく、チームの中で信頼される人間性を育む知識やスキルを惜しみなく共有し、他者の成長を支援する批判するだけでなく建設的なフィードバックを心がける自分の間違いを素直に認め、修正できる謙虚さを持つ技術的な決断において倫理的な側面も考慮できる視点を養う一時的な効率より長期的な関係構築を重視する姿勢を持つ「つぶしが効く」エンジニアは、特定の技術やツールに依存しません。彼らは根本的な問題解決能力と適応力を持ち、どんな状況でも価値を生み出せるのです。一方で文脈には依存するので注意が必要です。皆さんも大学時代から、そのような柔軟性と深い理解を育てていきましょう。『コンサル一年目が学ぶこと ― 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選』は、論理的思考・プレゼン・タイムマネジメントなど30の汎用スキルを「話す技術／思考術／デスクワーク術／ビジネスマインド」の４カテゴリに整理し、AIでは置き換えにくい問題解決プロセスを基礎から鍛えてくれる。コンサル一年目が学ぶこと 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選作者:大石哲之ディスカヴァー・トゥエンティワンAmazon『コンサルティング会社 完全サバイバルマニュアル』は、アナリストからマネージャーまでに潜む罠と突破口を３部構成で描き、クライアント合意形成やチーム動員術など\"人間関係の摩擦\"を乗り越える実践策を開示し、苛烈な業界で残業せず成果を出すための暗黙知を授ける。コンサルティング会社　完全サバイバルマニュアル (文春e-book)作者:メン獄文藝春秋Amazon『シン・ロジカルシンキング』は、問い（Q）→仮説（A）→示唆（D）→結論（I）のQADIサイクルで〈発見〉と〈論証〉を往復し、生成AI時代にこそ差別化源となる\"問う力\"と独創的洞察の生み出し方を提示する。基礎体力を底上げする一冊、苛烈な現場を生き抜く一冊、思考をアップデートする一冊——この３冊を通読すれば、ビジネスパーソンはAIが代替できない知的生産プロセスを多角的に武装できる。という主張をしているが現状維持バイアスの人間賛美でいずれできるようになる。シン・ロジカルシンキング作者:望月安迪ディスカヴァー・トゥエンティワンAmazon生成AIの時代には、単にコードを書く技術だけでは「AIに任せた方が早いもしくは安い(易い)」と思われてしまう危険性があります。これは新卒のみなさんだけではなく中堅やベテランエンジニアも同様にです。AI時代を生き抜くには、技術スキルだけでなく、問題の本質を見抜く力、ビジネス感覚、そして人間関係の機微を読む力を意識的に磨くことが不可欠で、これらのスキルを身につけることで、技術力と人間力を兼ね備えた「AIより人間に任せたい」「〇〇といっしょに働きたい」と思われるエンジニアになれるのです。www.slideshare.netバカと無知―人間、この不都合な生きもの―（新潮新書） （言ってはいけない）作者:橘玲新潮社Amazon2. 技術を点ではなくて線で見極める目を養うAIやテクノロジーの進化が加速する中、多くの学生や若手エンジニアはこの変化について行こうと焦っています。「最新技術を習得しないと就職で不利になるのでは？」「他の人に遅れを取るのでは？」という不安も理解できます。しかし、最先端の技術を追いかけることだけに集中すると、むしろ長期的な成長を妨げる可能性があります。皆さんには、「技術を点ではなくて線で見極める目」を養ってほしいと思います。syu-m-5151.hatenablog.com技術の進化と本質的価値技術の進化に振り回されず、本質を見極めることがエンジニアの価値です。 最新技術への焦りは不要で、顧客価値を軸に選択すべきです。「流行りの技術を使っていない」ことへの不安より、「なぜその技術が必要か」を問い続けることが、長期的に価値あるエンジニアになる道筋です。ハラリが「NEXUS 情報の人類史」で指摘しているように、人類の進化はつねに「情報ネットワーク」と密接に関わってきました。そして今、私たちは人類史上初めて「人間ならざる知能」の時代に突入しています。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon技術者として重要なのは、この歴史的文脈の中で自分たちの立ち位置を理解することです。私たちは単なる「コード生産者」ではなく、情報の流れ方そのものを設計する重要な役割を担っています。特にAIモデルが日々進化する中で、「どのような情報をどのように処理し、どのような形で人間に提示するか」という選択は、社会に大きな影響を与えます。「新しい技術に追いつかなければ」という焦りはエンジニアなら誰しも感じるものです。しかし、重要なのは技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。長期的に価値を持つスキルの見極め方技術の世界は常に変化していますが、すべての変化が同じ重要性を持つわけではありません。「新しい技術に追いつかなければ」という焦りに駆られる前に、次の3つの質問を自分に問いかけてみてください：この技術は一時的なトレンドか、根本的な変化か？このフレームワークの流行り廃りは一時的なトレンドか？バージョン管理システムの普及は根本的な変化か？クラウドインフラの普及やコンテナ技術の標準化は根本的な変化の原因は？この技術は問題解決の新しい方法を提供しているのか？単に既存の解決策を少し改良したものかまったく新しいアプローチを可能にするものか解決できる問題の範囲を根本的に拡大するものかこの技術の基礎となる原理は何か？表面的な実装詳細を超えて、根底にある考え方は何かその原理は他の文脈でも適用可能かその原理が解決している根本的な問題は何かこれらの質問に答えることで、目の前の技術が「追いかける価値があるもの」なのか、それとも「様子を見るべきもの」なのかを判断する力が養われます。重要なのは、技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。また、個人ですべての技術動向を追うのは現実的ではありません。信頼できる技術ブログや専門家の意見、実際に手を動かしている現場のエンジニアの知見を参考にしながら、情報収集の効率化を図ることも重要です。そこで、今のXは少々使いづらいのでControl Panel for Twitterなどのプラグインを利用すると良いユーザー体験が生まれるのでオススメです。システム設計の現場では、「賢い」デザインと「単純」なデザインの選択に直面することがよくあります。経験から言えることですが、長期的に価値を持つのは後者です。いくら「賢く」見える技術ソリューションでも、あまりに複雑で他者が理解しにくいものは、長期的にはメンテナンスコストが高くなり、チームの足かせになります。「単純さ」を追求することこそ、実は高度な技術力の現れなのです。 speakerdeck.com実践のためのアドバイスでは大学生の皆さんは、どうすれば技術の本質を見極める目を養えるのでしょうか？「なぜ」を5回問う：新しい技術に出会ったら、連続して「なぜ」を問いかけましょう。例えば：なぜDockerが人気なのか？ → 環境の一貫性を提供するからなぜ環境の一貫性が重要か？ → 開発と本番環境の差異を最小化するためなぜ環境差異の最小化が必要か？ → デプロイの信頼性向上のためなぜデプロイの信頼性が重要か？ → 継続的なサービス提供のためなぜ継続的なサービス提供が求められるか？ → デジタルサービスの常時稼働が期待されるからこの連鎖的な問いかけで、技術の表層から社会的・経済的な本質へと掘り下げられます。古典的で嫌う人もいますが一定の価値はあると思います。技術の歴史を学ぶ：デカルトは「困難を分割せよ」と言い、ビル・ゲイツは「問題を切り分けろ」と言った。この思想はコンピュータサイエンスの基盤ですが、実は問題の分解法こそが難所です。歴史的変遷を学ぶことで、なぜ現在の解法が選ばれたのか、試行錯誤のプロセスも含めて理解でき、「創造の追体験」という知的興奮を得られます。プログラミング言語の進化やプロトコル設計の歴史を知ることで、表層的な知識を超えた洞察が得られるでしょう。知的多様性と創造的衝突を求める：技術の価値は多様な視点がぶつかる場で鮮明になります。同じ技術でも、バックエンド、フロントエンド、デザイン、マネジメントの観点で評価が異なります。計算機科学だけでなく、心理学や経営学など異分野からの視点が予想外の気づきをもたらすことも。研究室やサークルでの議論から始め、カンファレンスやオンラインコミュニティへと視野を広げ、「異質な他者」との対話を通じて技術の多面性を理解しましょう。コードを「読む」文化を身につける：優れたミュージシャンが名曲を聴き込むように、良いエンジニアは質の高いコードを読み込みます。GitHubの時代は「巨人の肩」への前例のないアクセスを提供しています。LinuxカーネルやPostgreSQLなど様々な成熟度のプロジェクトから生きた知恵を吸収しましょう。コミットメッセージや設計ドキュメントを読むことで、技術選択の背景にある思考プロセスも理解できます。「読む」という行為は「書く」能力を飛躍的に高める最も効率的な投資です。技術の本質を見極める目を持つことは、AI時代のエンジニアにとって最も価値ある資質です。流行りに惑わされず「なぜ」を問い続けることで、変化する環境でも揺るがない判断軸を持てるようになるでしょう。3. 技術革新と不平等の歴史から学ぶ技術の本質を見極める視点をさらに深めるために、ここで少し歴史的な視点から考えてみましょう。技術革新は本当に社会を良くするのでしょうか？その恩恵は誰に届くのでしょうか？2024年のノーベル経済学賞受賞者ダロン・アセモグルとサイモン・ジョンソンも「技術革新と不平等の1000年史」で重要な警鐘を鳴らしています。彼らの研究によれば、技術革新は自動的に社会全体の富や幸福をもたらすわけではありません。むしろ歴史は、技術革命の果実が一部の人々に集中し、不平等を拡大させてきた事例で満ちています。技術の恩恵が広く社会に行き渡るかどうかは、技術そのものではなく、その「ビジョン」と「設計された分配システム」に依存するのです。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon歴史に見る技術革命と不平等人類の歴史を振り返ると、多くの技術革命は必ずしも万人に恩恵をもたらしてきませんでした。農業革命は食料生産を増加させましたが、その恩恵は主に土地を所有するエリート層に集中し、多くの人々はかえって過酷な労働を強いられました。情報の視点で見れば、これは「中央集権的な情報管理」の始まりでもありました。少数の支配者が情報を独占することで、多数の人々を統制する仕組みが生まれたのです。産業革命の初期段階では、工場労働者の生活水準は実際に悪化しました。機械化による生産性向上の恩恵は工場主に集中し、労働者は危険で過酷な環境で働かされました。情報の観点では、「標準化された情報」と「階層的な情報の流れ」が特徴的でした。コンピュータ革命でさえ、デジタル格差と所得格差の拡大をもたらしました。プログラミングのスキルを持つ人々と持たない人々の間に新たな分断が生まれ、技術の発展が必ずしも平等な社会をもたらさなかったのです。ハラリは「情報が多いほど真実に近づける」という素朴な前提が実は誤りであることを指摘しています。同じ情報インフラが科学を発展させる一方で、魔女狩りのような集団ヒステリーを引き起こすこともあるのです。決定的な分かれ道となるのは、「間違いを前提に互いに補正できる仕組みがあるかどうか」なのです。カルトのことば　なぜ人は魅了され、狂信してしまうのか作者:アマンダ・モンテル,青木音白揚社AmazonAI革命の文脈で考える私たちが今経験しているAI革命も、同様の歴史的パターンを繰り返す可能性があります。AIが生み出す生産性向上の恩恵は、AIを所有・制御する企業や個人に集中するかもしれません。また、AIを効果的に活用できるスキルを持つ人々と持たない人々の間に新たな格差が生まれる可能性もあります。エンジニアとして私たちは、技術が社会に与える影響に対して無関心ではいられません。私たちが設計するシステムが、意図せず不平等を拡大したり、一部の人々を排除したりする可能性を常に意識する必要があります。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店AmazonLLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発作者:John Berryman,Albert Ziegler,服部 佑樹（翻訳）,佐藤 直生（翻訳）オーム社Amazonエンジニアの責任と可能性歴史は決定論的ではありません。私たちには選択肢があります。エンジニアとして、技術の恩恵がより広く社会に行き渡るような設計や実装を意識的に選ぶことができます。具体的には：アクセシビリティを考慮した設計：すべての人がテクノロジーの恩恵を受けられるよう、多様なユーザーのニーズを考慮する倫理的な視点を持つ：開発するシステムが社会に与える可能性のある影響を常に考えるオープンな技術の推進：知識や技術へのアクセスを広げるオープンソースやオープン教育の取り組みに参加する多様性のある開発チーム：様々な背景や視点を持つ人々が開発に参加することで、より包括的な技術を生み出す技術史を学ぶことは、未来を形作るために不可欠です。私たちは過去の過ちを繰り返さないよう、意識的に行動することができます。AI時代のエンジニアとして、技術の社会的影響を理解し、より公正で包括的な未来に貢献する責任があるのです。デジタルの皇帝たち――プラットフォームが国家を超えるとき作者:ヴィリ・レードンヴィルタみすず書房Amazon4. そして、エンジニアになるここまで、技術的な深さと歴史的視点について話してきましたが、次に「人間的な側面」に目を向けていきましょう。AI時代において価値あるエンジニアとなるために必要な、「ユーザー」「技術」「自分自身」との3つの関係性について考えていきます。ユーザーに寄り添うエンジニアになる技術に精通することはエンジニアにとって重要ですが、それだけでは十分ではありません。価値のあるエンジニアとなるためには、自分の作るものが最終的に誰に届き、どのような影響を与えるのかを常に意識する必要があります。エラーログの向こうに人がいることを忘れるな。0.01%の障害も、誰かの人生を大きく狂わせる可能性があります。 数字だけで判断せず、実際にサービスを触り、ユーザー体験を自分の目で確かめるエンジニアこそが、信頼性の高いシステムを作れるのです。例えば私の経験からですが、あるサービスで「99.9%の可用性」というメトリクスに満足していたチームがありました。しかし、実際にユーザーとして使ってみると、残りの0.1%の障害が、ユーザーが最も重要なタイミング（プレゼンの直前や商談中など）に発生していることが分かりました。統計的には小さな数字でも、ユーザーにとっては致命的な問題になり得るのです。エンジニアの世界では、しばしば数字やメトリクスで成功を測ります。「99.9%の可用性」「平均応答時間50ms」「エラー率0.01%」といった具合です。これらの数字は確かに重要ですが、その裏側にある人間の体験を見失ってはいけません。技術的な指標だけでなく、「この機能が失敗したとき、ユーザーはどう感じるか」「彼らの人生にどんな影響を与えるか」を常に考えることが、価値のあるシステムを作る鍵となります。エンジニアとして成長するために最も効果的な方法の一つは、自分が作ったシステムを実際のユーザーとして使ってみることです。これは「ドッグフーディング」とも呼ばれますが、単なる形式的なテストではなく、ユーザーの立場に立つことを意味します。この体験を通して、技術的な視点だけでは見えてこなかった問題点や改善の機会に気づくことができるでしょう。技術に寄り添うエンジニアになるエンジニアとして価値を発揮するためには、技術そのものを深く理解し、技術の特性や進化の方向性に寄り添う姿勢も重要です。技術に寄り添うとは、単に最新技術を追いかけることではなく、各技術の本質や適切な使いどころを見極める目を持つことです。技術を目的化せず、手段として適切に選択できるエンジニアが良い価値を生み出せます。 データベースの負荷問題も、技術的な最適化、アーキテクチャの再設計、あるいはビジネス要件の見直しなど、複数の視点から最適な解決策を見つけられる柔軟性が重要です。技術に寄り添うエンジニアは、次のような特徴を持っています：技術の「なぜ」を理解している：特定の技術がなぜ生まれたのか、どのような問題を解決するために設計されたのかを理解しています。この理解があるからこそ、適切な場面で適切な技術を選択できるのです。技術の限界を認識している：どんな優れた技術にも限界があることを知っています。「この技術では解決できない問題は何か」を理解しているからこそ、過剰な期待や誤った適用を避けることができます。技術間の関係性を把握している：個々の技術を孤立して見るのではなく、技術エコシステム全体の中での位置づけを理解しています。これにより、相互運用性の問題や将来的な拡張性を考慮した設計が可能になります。技術の進化の方向性を予測できる：過去の技術進化のパターンを理解し、将来の方向性を予測する目を持っています。これにより、一時的なトレンドに振り回されず、長期的な視点で技術選択ができます。技術に寄り添うためには、幅広い知識と経験が必要です。異なる専門領域の知識を組み合わせ、多角的な視点で問題を捉える能力が重要になります：フロントエンドとバックエンドの両方の視点から考えるインフラストラクチャとアプリケーション開発の関係性を理解するセキュリティとユーザビリティのバランスを考慮するパフォーマンスと保守性のトレードオフを意識するAIの時代においては、「人間とAIの協働」という新たな視点も必要です。AIツールの特性を理解し、人間の創造性と判断力を活かしながら、AIの処理能力と効率性を組み合わせていく視点が重要になるでしょう。技術に寄り添うエンジニアになるには、一朝一夕ではなく日々の小さな習慣の積み重ねが鍵です。毎日15分の技術調査、週一回のコード見直し、月一冊の技術書など、小さくても継続的な取り組みが深い理解を育みます。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon200万人の「挫折」と「成功」のデータからわかった 継続する技術作者:戸田大介ディスカヴァー・トゥエンティワンAmazonAI時代では特に、新しいツールを定期的に試し、結果を記録する習慣が重要です。理解のプロセスは螺旋状に進みます。この道のりには挫折もありますが、小さな習慣を粘り強く続けることで、技術に対して誠実なエンジニアへと成長できるのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon自分に寄り添うエンジニアになる技術の急速な進化と複雑化が進む中、エンジニアとして長く活躍し続けるためには、「自分自身に寄り添う」姿勢も欠かせません。これは単に自己満足や自己中心的になることではなく、自分の学習プロセス、強み・弱み、成長の方向性を理解し、持続可能なキャリアを構築することを意味します。元オリンピック選手で「熟達論」で知られる為末大氏は、熟達を単なる技術の向上ではなく、「技能と自分」を一体として捉え、人間という総体を高めていくプロセスだと説明しています。このアプローチはAI時代のエンジニア育成においても極めて示唆に富んでいます。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon為末氏による熟達の5段階を見ていきましょう：遊(ゆう) - 探索と実験: すべての学びは「遊び」から始まります。好奇心に導かれ、新しい言語やフレームワーク、AIツールと自由に戯れる段階です。ここでの自由な探索が長期的な学習のエネルギー源となります。型(かた) - 基本を身につける: 基本的な動きや思考パターンを繰り返し練習し、無意識にできるようになる段階です。AIがコード生成を担う時代でも、この「型」の理解なしにAIの出力を評価・改善することはできません。観(かん) - 深い理解: 対象を部分に分解し、その関係性と構造を深く理解する段階です。コードが「動く」だけでなく、「なぜそう動くのか」を考察し、見えない部分まで想像できるようになります。心(しん) - 本質の把握: 細部にとらわれず全体のバランスを保ち、本質的な部分を直感的に見抜ける段階です。AIとのコラボレーションにおいても、本質的な方向性を見失いません。空(くう) - 創造的境地: 既存の枠組みを超え、純粋に目的や価値の創造に集中できる境地です。AI時代においてこそ、この創造的な「空」の境地が人間の価値となります。重要なのは、熟達のプロセスが一直線ではなく螺旋状に進むということです。新しい技術やAIモデルに出会うたびに、再び「遊」の段階から始まり、徐々に「型」「観」「心」へと進んでいきます。この螺旋的な成長過程を理解し、受け入れることで、変化の激しいAI時代においても心理的な安定を保ちながら成長し続けることができるのです。自分に寄り添うエンジニアになるための具体的なアプローチとしては：自分の学習スタイルを理解する：人によって効果的な学習方法は異なります。読書、実践、教えること、議論など、自分にとって最も効果的な学習方法を見つけ、意識的に活用しましょう。自分のエネルギー源を知る：何に取り組むとエネルギーが湧いてくるか、逆に何をするとエネルギーを消耗するかを理解しましょう。持続可能なキャリアのためには、エネルギーを与えてくれる活動と消費する活動のバランスが重要です。適切な休息と内省の時間を確保する：常に新しい技術を追いかけ続けるのではなく、学んだことを内省し、自分のものにするための時間も大切です。定期的な休息や趣味の時間も、長期的な創造性と生産性のために不可欠です。自分の強みと弱みを正直に評価する：すべてを完璧にこなそうとするのではなく、自分の強みを活かし、弱みは補完するアプローチを考えましょう。チームやコミュニティの中で、互いの強みを活かし合う関係を構築することも重要です。量をこなすことの本質的価値ここまで「寄り添う」という質的な側面について語ってきましたが、エンジニアとして成長する上で避けて通れない真実があります。それは「質は量から生まれる」ということです。AI時代になって「もうコードを大量に書く必要はない」と考える人もいるかもしれません。しかし、これは大きな誤解です。AIを効果的に使いこなせる人は、例外なく膨大な量のコードを書いてきた人たちです。なぜなら、量をこなすことで初めて得られる「暗黙知」があるからです。為末氏の熟達論でも触れたように、成長は螺旋状に進みます。量をこなすことで質が向上し、質の向上によってより高度な量をこなせるようになるという好循環が生まれます。最初の1000時間は基礎的なコーディングスキルの習得に費やされるかもしれません。次の1000時間では、より複雑な問題解決に挑戦できるようになります。そして次の1000時間では、AIと協働しながら、以前は想像もできなかった規模のプロジェクトに取り組めるようになるでしょう。「とにかく手を動かせ」という古からのアドバイスは、AI時代においても色褪せることはありません。むしろ、AIという強力なパートナーを得た今こそ、かつてない速度で量を積むことができる絶好の機会なのです。ちゃんと、エンジニアになるこれまで述べてきた「ユーザーに寄り添う」「技術に寄り添う」「自分に寄り添う」という3つの姿勢を総合して、初めて「ちゃんとしたエンジニア」になれるのではないでしょうか。では、実際にどのようにすれば、これらの要素を日々の実践に落とし込んでいけるのでしょうか？自分の作ったものを実際に使う習慣をつける：自分が開発したシステムやアプリケーションを、定期的に実際のユーザーとして使ってみましょう。理想的には、業務外の時間や異なる環境で使うことで、新たな視点が得られます。「ユーザーに寄り添う」姿勢を具体化する第一歩です。異なる専門性を持つ人々との協働を積極的に求める：デザイナー、プロダクトマネージャー、マーケター、ビジネス部門の人々など、多様な背景を持つ人々との協働プロジェクトに参加しましょう。これにより、多角的な視点で問題を捉える力が養われ、「技術に寄り添う」視野の広さが育まれます。AIとの「遊び」の時間を確保する：AIツールを業務だけでなく、創造的な探索のために使う時間を意識的に確保しましょう。例えば、週に1時間だけ「AIとの実験タイム」を設け、新しい使い方や可能性を探求するのも良いでしょう。為末氏の言う「遊」の段階を大切にすることで、AIとの共創の可能性が広がります。振り返りとフィードバックを習慣化する：プロジェクトやタスクの終了後に、「何がうまくいったか」「何が改善できるか」「どんな学びがあったか」を振り返る時間を持ちましょう。また、同僚や顧客からのフィードバックを積極的に求め、それを次の成長につなげましょう。これは「自分に寄り添う」ための重要な習慣です。「技術以外の本」を読む習慣をつける：技術書だけでなく、デザイン、心理学、ビジネス、哲学など様々な分野の本を読むことで、多角的な思考が育まれます。これらの知識は、技術的な問題に対しても新たな視点をもたらすことがあります。「ちゃんとしたエンジニア」とは、単に技術が優れているだけでなく、その技術を通じて人々の生活や仕事をより良くする価値を生み出せる人です。そのためには、技術的なスキルだけでなく、ユーザーへの共感力、技術の本質を見極める洞察力、そして自分自身の成長プロセスを理解する内省力が必要です。AI時代のエンジニアとして、これらの要素をバランスよく発展させることで、単なる「コードを書く人」を超えた、価値あるエンジニアへと成長することができるでしょう。技術の進化がどれほど加速しても、最終的に価値を生み出すのは人間です。その原点を忘れずに、日々の実践を積み重ねていきましょう。エンジニアとしての総合的な成長を目指す方には、技術的スキルだけでなく人生全体のマネジメントや自己投資の方法を網羅的に解説した『ソフトスキル：ソフトウェア開発者の人生マニュアル』と、プログラミングの技術的側面に加えてプロフェッショナルとしての心構えや実践的知恵を提供する古典的名著『達人プログラマー：熟達に向けたあなたの旅』の2冊をぜひお読みいただきたいと思います。前者は「自分に寄り添う」姿勢を育み長期的なキャリア構築の指針となり、後者は「技術に寄り添う」ための具体的なプラクティスが豊富で、両書を通じてAI時代においても普遍的な価値を持つエンジニアリングの本質と、バランスの取れた成長への道筋を学ぶことができるでしょう。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon5. 計画的偶発性理論とAI時代のキャリア戦略ここまで「つぶしが効くエンジニア」「技術の本質を見極める目」「エンジニアとしての在り方」について話してきました。では、AIの急速な進化という大きな変化の中で、皆さんは具体的にどのようなキャリア戦略を持ち、どのような選択をすればよいのでしょうか？「AIに代替されない職業を選ぶべきか」「これから伸びる分野はどこか」という問いに明確な答えを出すことは困難です。その代わりに、不確実性の高い時代におけるキャリア構築の考え方として、「計画的偶発性理論」（Planned Happenstance Theory）をご紹介します。この理論を理解した上で、大学時代の選択と明日からの具体的なアクションについて考えていきましょう。計画的偶発性理論とは計画的偶発性理論は、スタンフォード大学の心理学者ジョン・D・クランボルツ教授が1999年に提唱したキャリア発達理論です。この理論によれば、個人のキャリアの約8割は、本人が予想していなかった偶然の出来事によって方向づけられるとされています。クランボルツ教授は、成功したビジネスパーソンのキャリアを調査した結果、多くの人のターニングポイントが「計画されたもの」ではなく「偶然の出来事」だったことを発見しました。しかし重要なのは、その「偶然」をただ待つのではなく、偶然を活かすための準備と行動が必要だということです。この理論がAI時代において特に重要なのは、テクノロジーの進化があまりに速く、将来どのような職種が残るか、どのようなスキルが求められるかを正確に予測することがほぼ不可能だからです。例えば、数年前には「AIプロンプトエンジニア」という職業は存在していませんでした。現在から見たら過去のトレードオフが分からないので、分かったような顔して「これが正解だった」と言う人はあとから来ていろいろ語りますが、だいたい運で勝っている人も多いです。技術の歴史を振り返ると、「明らかに正しい選択だった」と思えることでも、当時は複数の選択肢の中からの賭けだったことが少なくありません。計画的偶発性を生み出す5つの行動特性クランボルツ教授によれば、計画的偶発性を生み出すには5つの重要な行動特性があるとされています：1. 好奇心（Curiosity）好奇心とは、新しい知識や経験に対して積極的に探求する姿勢です。AIツールやモデルに対する好奇心は、その可能性と限界を見極める上で重要です。「これは何ができるのだろう？」と試してみる姿勢が、未知の可能性を開拓します。学生のうちからできること：講義で紹介された技術を授業以外でも試してみる新しいAIツールが登場したら、すぐに実験してみる「こんなことはできないだろう」と決めつけず、実際に試してみる姿勢を持つ2. 持続性（Persistence）持続性は、困難や障害に直面しても諦めず、目標に向かって努力し続ける能力です。AIツールは万能ではなく、期待通りの結果が得られないことも多々あります。そんなとき、一度や二度の失敗で諦めず、異なるアプローチを試みる持続力が重要です。学生のうちからできること：課題で壁にぶつかったとき、別のアプローチを試みる習慣をつけるAIとの協働でうまくいかない場合も、プロンプトや方法を変えて複数回試す失敗した試みも記録に残し、何が学べたかを振り返る3. 楽観性（Optimism）楽観性は、将来に対する前向きな見方と、成功の可能性を信じる姿勢です。技術変革期には、「AIに仕事を奪われる」といった不安や悲観的な見方が広がりがちです。しかし、歴史が示すように、新技術は常に新たな職種や専門性を生み出してきました。AIを脅威ではなく、可能性を拡張するパートナーとして前向きに捉えることが重要です。学生のうちからできること：技術の変化を「危機」ではなく「機会」として捉える視点を養う失敗やミスを「学びの機会」として前向きに受け止める習慣をつける週に一度、自分の小さな成功や進歩を書き出してみる未来について友人と前向きな対話をする時間を定期的に持つ4. 柔軟性（Flexibility）柔軟性は、変化する状況や予期せぬ出来事に適応する能力です。AI技術は日々進化し、その可能性と制約も常に変化しています。特定のツールや方法論に固執せず、状況に応じて最適なアプローチを柔軟に選択する能力が重要になります。学生のうちからできること：複数のプログラミング言語やフレームワークに触れる「これが唯一の正解」という思考を避け、複数の解法を探る習慣をつける計画変更を余儀なくされたとき、それを学びの機会と捉える姿勢を持つ異なる文化や背景を持つ人々との交流を通じて多様な視点を学ぶコンフォートゾーンを意識的に離れる小さな挑戦を定期的に行う5. 冒険心（Risk Taking）冒険心とは、不確実性や失敗の可能性があっても、新しいことに挑戦する勇気です。AI技術の最前線は常に変化しており、確立された「正解」が存在しないことも多いです。誰も試したことのない方法やアプローチに挑戦する冒険心が、イノベーションを生み出します。学生のうちからできること：ハッカソンやコンテストなど、短期間で新しいことに挑戦する機会に参加する未知の技術領域のプロジェクトにあえて挑戦してみる「失敗しても構わない」と考えられる安全な環境で、リスクを取る経験を積む自分のアイデアを公の場で発表する機会を積極的に求める「ちょっと無理かも」と思うようなプロジェクトや役割に手を挙げてみる計画的偶発性理論に基づくキャリアの基礎構築キャリアとは何でしょうか？「キャリア」の語源はラテン語の「carrus（車輪の付いた乗り物）」に由来し、後にイタリア語（carriera）、フランス語（carriere）となり、レールコース（通り道）を意味するようになりました。つまり、キャリアとは車輪の通った跡（轍・わだち）を意味しています。語源としてはそうですが実際もそうでこれは前もって計画できるものではなく、進んだ後に振り返って初めて見えるものなのです。誰かが「成功したキャリア」を語るとき、それは無数の選択肢と偶然の中から結果的に選び取った一本の道を後付けで説明しているにすぎません。特に現代のように技術革新と不確実性が加速する時代では、10年後、20年後の働き方を正確に予測することはほぼ不可能です。「偶然を必然に変えるのは、あなた自身の行動と姿勢なのです」計画的偶発性理論が教えてくれるのは、予測不能な未来に対して完璧な計画を立てるのではなく、偶然の出会いや機会を活かせるよう準備し、自分だけの独自の轍を刻んでいく姿勢の重要性です。就活生が見る労働の世界はいろんな人達が作った虚構の上に成り立っているので仕事選びや仕事で馬鹿を見ないために読んでおくのありかと思います。NINE LIES ABOUT WORK 仕事に関する9つの嘘は、私たちが当然と受け入れている職場の「常識」が実は神話に過ぎないことを鋭く指摘します。「どの会社で働くかが大事」「リーダーシップというものがある」といった広く信じられている前提を覆し、実際のデータと研究に基づいて職場の真実を明らかにしています。特に就職活動中の方や、キャリアの岐路に立つエンジニアにとって、この本は組織や仕事の本質を見抜く目を養い、自分が本当に活躍できる環境を見極める力を与えてくれるでしょう。NINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon専門性と横断性のバランスAI時代においても、深い専門性の価値は決して減じません。むしろ、ChatGPTのような汎用AIが「浅く広い」知識を提供できるようになるほど、特定分野における「深く狭い」専門知識の希少性は増していきます。しかし同時に、複数の領域を横断する能力も重要です。ここでのポイントは「浅く広く」ではなく「深く狭い専門性を複数持つ」というアプローチです。T型人材（1つの分野で深い専門性+広い一般知識）からπ型人材（複数の分野での深い専門性）へのシフトが、AI時代には価値を発揮します。これから10年、20年と生成AIはますます賢くなっていくでしょう。多くの領域で、AIに「優れる」ことは非常に難しくなります。しかし、「異なる」ことは常に可能です。AI時代のキャリア戦略として大切なのは、「優れる」よりも「異なる」ことを目指すアプローチです。「異なる」とは、独自の視点、独自の問い、独自の関心領域を持つことです。これは必ずしも仕事や学問の組み合わせだけではありません。あなたのユニークな趣味、特異な経験、異文化での生活体験など、あなただけの「異なる」要素がキャリアの差別化につながることもあります。将棋や囲碁が好きな人は、その戦略思考がシステム設計に活きるかもしれません。山登りが趣味の人は、「少しずつ高みを目指す」という考え方がソフトウェア開発に応用できるかもしれません。重要なのは、自分が本当に情熱を持てる「異なる」要素を見つけ、それを技術と組み合わせる方法を探ることです。AIは多くのタスクで人間を超えるかもしれませんが、あなただけの独自の視点と問いは、AIにはない価値を生み出す源泉となるでしょう。実践的な問題解決経験AIがコードを生成できる時代において、「Todoアプリを作りました」といった基本的な実装経験の差別化価値は相対的に低下します。代わりに、「具体的な問題を解決した」という経験が価値を持ちます：特定の地域や集団の課題をテクノロジーで解決するプロジェクト既存ソリューションの特定の制限や課題を克服する独自アプローチニッチな領域の特殊なニーズに対応するツールの開発採用面接で最も印象に残るのは「こういう課題があって、このアプローチを試したがうまくいかなかった。そこでこの解決策を考え、実装した結果、こうなった」と問題解決のプロセス全体を説明できる学生です。人間同士のコミュニケーション能力AI時代こそ、人間同士のコミュニケーション能力が重要になります。特に技術的な内容を非技術者に分かりやすく伝える能力は、AIと人間の橋渡しをする上で不可欠です。技術ブログの執筆、プレゼンテーションの機会の獲得、異なる背景の人々との協働などを通じて、この能力を磨きましょう。明日からの具体的なアクション計画的偶発性理論に基づくなら、重要なのは「偶然の機会に気づき、活かすための行動」です。不確実性が高まる時代だからこそ、以下のような具体的なアクションを通じて、偶然を必然に変える力を養いましょう。AIツールの実験と比較様々なAIコーディングツールを使い倒してみることから始めましょう。これは単なるお遊びではなく、AIの本質と限界を理解するための重要な実験です。GitHub Copilot、Cline、Cursor、など、様々なツールを同じタスクに適用し、それぞれの得意・不得意を体系的に記録してみましょう。これだけ変化が激しい世界で人生を賭けるのはリスクすぎる。「AI比較実験ノート」をつけることで、ただ使うだけでは得られない洞察を得ることができます。重要なのは、AIを「答えをくれる先生」ではなく「一緒に問題を解決するパートナー」として位置づけることです。プロンプトを工夫し、AIの提案を批判的に評価し、改善を求め、最終的には自分で最適化するというサイクルを通じて、効果的な協働方法を見つけていきましょう。自分で手を動かしてない人のいうことはあまり信用しなくてよいです。読んでいない本について堂々と語る方法 (ちくま学芸文庫 ハ 46-1)作者:ピエール・バイヤール筑摩書房AmazonAfter Cline - あるいは語りえぬ者について語ろうとする時代について · GitHubzenn.dev日記を通じた言語化能力の向上TikTokやYouTubeを見る時間の一部を、日記を書く時間に変えてみましょう。たった5分でも構いません。現代の娯楽は文字どおり１分１秒を奪い合うレベルにまで特化していて、長い時間をじっくりかけて楽しむ娯楽は、かれらの目まぐるしい日々の暮らしのなかでそのポジションを急激に失いつつあります。そんな中で、日記を書くことには、多くの利点があります。言語化能力の向上: 自分の考えや経験を言葉にする習慣がつくことで、コミュニケーション能力が自然と高まります。自己認識の深化: 日々の出来事や感情を振り返ることで、自分自身の思考パターンや価値観に気づくことができます。前向きな思考の促進: 特に「今日学んだこと」「今日感謝したいこと」などポジティブな視点を含めた日記は、心理的な健康にも良い影響を与えます。アイデアの整理と発見: 断片的な思考を書き出すことで、新たな関連性やアイデアに気づくことがあります。日記のテーマとしては、「今日学んだ技術のこと」「気になる技術トレンド」「解決した問題とその過程」など、技術に関連したものでも構いませんし、「今日感じた感情」「未来の自分への手紙」など、より個人的なものでも良いでしょう。重要なのは継続することです。スマートフォンのリマインダーを設定したり、就寝前の習慣にするなど、自分に合った方法で習慣化してみてください。スマホ脳（新潮新書） 『スマホ脳』シリーズ作者:アンデシュ・ハンセン新潮社Amazonコミュニティへの参加と知識の還元技術の学習や成長は、一人で行うよりもコミュニティの中で行う方が効果的です。AIツールを活用しながらプログラミングやプロジェクト開発に取り組む仲間と定期的に経験を共有する場を作りましょう。また、学ぶだけでなく、自分の知識や発見を積極的にコミュニティに還元することも重要です。AIツールの活用で得た知見をブログに投稿したり、学内勉強会で発表したりすることで、自分の理解が深まり、新たな視点を得ることができます。不確実性を受け入れ、偶然を活かす姿勢この理論は、「明確なキャリアプランを持つな」と言っているわけではありません。むしろ、計画に固執しすぎず、予期せぬ出来事に柔軟に対応できる準備をしておくことの重要性を教えてくれます。現代のように技術革新のスピードが加速し、不確実性が高まっている時代には、10年後の働き方を正確に予測することはほぼ不可能です。そんな中で「これが絶対の正解」と信じて一つの道に固執するよりも、様々な可能性に目を向け、偶然の機会を活かせるよう自分を準備しておくことが賢明でしょう。「偶然は準備された心にのみ微笑む」という言葉があるように、偶然の出会いや機会を価値あるものに変えるのは、あなた自身の行動と姿勢なのです。AI時代のキャリアにおいては、「これが正解」という単一の道筋はないでしょう。むしろ、好奇心を持って多様な可能性に目を向け、変化に柔軟に対応できる力を養うことが、長期的な市場価値を高める最も確かな戦略かもしれません。完璧を求めすぎないことも重要です。提案した活動のすべてを同時に実行する必要はありません。自分の興味や強みに基づいて、できることから始めましょう。失敗を恐れず、様々なことに挑戦し、可能性を広げることこそが、予測不可能なAI時代に対応するための最良の準備となるでしょう。結局のところ、この話の落としどころは極めて凡庸な結論に帰着します。不確実性を受け入れ、偶然を活かす姿勢といっても、最終的には「自分が選んだ選択肢を正解にするしかない」という単純な事実に行き着くのです。これは特別な知恵でもなんでもない当たり前の話かもしれません。しかし、この凡庸な事実こそが、急速に変化するAI時代において最も実践的な知恵なのかもしれません。どんなに理論を語っても、どんなに戦略を練っても、最後は自分の選んだ道を誠実に歩み、その選択に意味を見出し、自らの手で「正解」に変えていく努力以外に道はないのです。おわりにここまで様々な観点からAI時代のエンジニアキャリアについてお話ししてきましたが、最後に少し本音をお伝えしたいと思います。実は、この講演のタイトル「AI時代に市場価値を高めるキャリア戦略」を見たとき、少し困ってしまいました。このような強いタイトルのもとで講演するには、あまりにも重い責任を感じたからです。「市場価値を高める」などと言えるほど、私自身が確固たる答えを持っているわけではないですし、AIの進化は日々予測を覆しています。しかし、このタイトルが私自身への挑戦状となり、真剣に考える機会となりました。率直に申し上げて、私自身もAIの急速な進化には戸惑いを感じています。現役エンジニアとして、これまで時間をかけて身につけたスキルの一部が、あっという間にAIで代替されていく現実は、正直なところ不安を覚えます。しかし、こうした変化の波に対しては、抵抗するよりも乗る方が賢明でしょう。私たちエンジニアは、望むと望まざるとにかかわらず、この技術革新の最前線に立っています。ただ、この状況をむしろポジティブな視点で捉えることも可能です。今日お話した計画的偶発性理論は、私自身のキャリアを振り返った時に非常に納得感があります。実際、私のキャリアも「計画通り」には進まず、予想外の出会いや偶然の機会が、振り返ってみれば重要なターニングポイントになっていました。例えば、趣味で始めたオープンソース活動が、思いがけず重要な仕事の機会につながったり、一見無関係に思えた副業プロジェクトでの経験が、後の大型プロジェクトで決定的な価値を持ったりしました。このような「計画できない幸運」は、実はキャリア形成の重要な要素ではないかと考えています。最近の経験から、AIツールを積極的に活用することで興味深い発見がありました。当初は「自分の仕事が奪われる」という懸念を抱いていましたが、実際には単調な作業から解放され、より創造的な領域に集中できるようになったのです。コーディングの基礎的な部分や定型的なタスクをAIに委託することで、システム設計や問題の本質的な解決により多くの時間と思考を割けるようになりました。これは決して悪い変化ではないと感じています。今、大学生の皆さんは、AIと共に成長する先駆的な世代です。困難も多いでしょうが、それだけ新しい可能性に満ちた時代でもあります。皆さんが構築するエンジニアとしてのキャリアは、私たち世代のものとは大きく異なるかもしれませんが、それはより創造的で多様な可能性を秘めていると確信しています。皆さんのキャリアが、AIとの創造的な協働を通じて、より充実したものになることを心から願っています。本日はありがとうございました。最後になりますが、今お話したような「AIと共に成長するエンジニア」を私たちの会社でも募集しています。本日の内容に共感いただけた方は、ぜひよろしくお願いします。jobs-3-shake.com","isoDate":"2025-05-21T03:27:52.000Z","dateMiliSeconds":1747798072000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ブログ記事評価プロンプト (0.0-5.0)を作成しました。","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659","contentSnippet":"はじめにある日のこと、私はブログを書いていました。ブログをレビューしたり、修正したり。そんな日々の中で、ふと思ったのです。「あれ？自分が書いたブログ記事、本当に役に立っているのかな？」と。皆さんも一度は感じたことがあるのではないでしょうか。せっかく時間をかけて書いた記事が、実は的外れだったかもしれない、という不安。「もっとこうすればよかった」という後悔。あるいは「この記事、本当に価値があるのか」という疑問。そんな思いを抱えながら、私はあることに気づきました。ブログ記事を評価する明確な基準がないということに。プログラミングにはコードレビューがあり、デザインにはクリティークがあります。でも、技術ブログには？そこで考えました。もしブログ記事を客観的に評価できるプロンプトがあれば、多少なり自分の記事をより良くするヒントになるのではないか、と。単なる「良い/悪い」ではなく、複数の観点から数値化して評価できれば、改善点が明確になります。Writing for Developers: Blogs that get read (English Edition)作者:Sarna, Piotr,Dunlop, CynthiaManningAmazon本日は、そんな「ブログ記事評価プロンプト」の作り方と使い方についてご紹介します。このプロンプトは、私が以前書いた「3年目までに身につけたい技術ブログの書き方」と「防御力の高い技術ブログを書こう」の内容をベースに、記事の質を多角的に評価できるよう設計しています。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめになぜブログ記事を評価する必要があるのかフィードバックの少なさという現実自己評価の盲点継続的な改善のために5つの評価観点とその意味防御力：批判に耐える文章の力思考整理力：混沌から秩序を生む力実践応用性：読んですぐ行動できる情報構成と読みやすさ：情報の消化しやすさコミュニケーション力：人間味のある伝え方ブログ記事評価プロンプトの使い方評価の手順自己評価として使う場合成長の記録として使う場合評価プロンプトを評価するバランスの取れた総合力読者を中心に据えた視点進化し続ける生き物としてのブログブログ記事評価プロンプト全文ブログ評価プロンプトの限界と注意点AIによる評価の限界評価基準のカスタマイズ評価を絶対視しないおわりに追記なぜブログ記事を評価する必要があるのかフィードバックの少なさという現実技術ブログを書いていて感じるのは、直接的なフィードバックの少なさです。コードならPRレビューで指摘を受けますが、ブログはほとんどの場合、反応がないまま時間が経ちます。実際、私の経験では1000人に読まれた記事でも、コメントをくれるのはせいぜい数人。「参考になりました」と言ってくれる人がわずかにいて、大多数は何も言わず、たまに批判的なコメントが来る程度です。こういった状況では、自分の記事が本当に役立っているのか、どう改善すべきなのか判断するのが難しくなります。自己評価の盲点自分で書いた記事を自分で評価するのは、想像以上に難しいものです。「こんなにわかりやすく書いたのに、なぜ伝わらないんだろう」と思うことはありませんか？それは私たちが自分の知識や前提条件を無意識に読者にも期待してしまうからです。「これくらい知っているだろう」「これは説明不要だろう」という判断が、実は大きな誤解を生んでいることも少なくありません。継続的な改善のためにブログを書き続けるモチベーションを維持するには、自分の成長を実感することが重要です。評価基準があれば、「前回より良くなった」と客観的に感じられるようになります。数値化された評価は、「前回は実践応用性が3.2だったけど、今回は4.0に上がった！」といった具体的な進歩を認識させてくれます。これは小さな達成感を生み、次の記事への原動力になるのです。5つの評価観点とその意味ブログ記事を評価する際、単一の基準ではなく複数の視点から見ることが重要です。以下の5つの観点は、私が過去の記事で大切だと感じてきた要素を反映しています。これらをバランスよく考慮することで、より立体的に記事の質を捉えることができます。防御力：批判に耐える文章の力防御力とは、批判や反論に対してどれだけ耐性のある記事になっているかを評価する観点です。前回の「防御力の高い技術ブログを書こう」でも詳しく解説しましたが、特に重要なのは次の要素です：主観的表現と限定的な主張：「これが正しい方法だ」ではなく「私の経験では〜」と限定することコンテキストと限界の明示：「この方法はXXの環境で、YYの制約がある場合に有効です」と条件を明確にすること実体験と具体例の活用：抽象的な主張ではなく具体的な体験を共有すること根拠と出典の明示：主張の裏付けとなる情報源を示すこと誠実さの表現：自分の不確かさや知識の限界を率直に認め、「まだ完全には理解していない」「今後調査が必要」といった点を隠さないこと防御力が高い記事は「これは間違っている！」という批判を受けにくくなり、建設的な対話を生み出しやすくなります。特に誠実さを示すことで、読者は筆者を信頼し、共に学び合う関係を築けるのです。syu-m-5151.hatenablog.com思考整理力：混沌から秩序を生む力思考整理力とは、複雑な概念や情報をどれだけ論理的に整理して伝えられているかという観点です。優れた技術ブログは、単なる情報の羅列ではありません。著者の試行錯誤の過程、思考の変遷を透明に示すことで、読者は表面的な結論だけでなく、その背景にある考え方まで学ぶことができます。具体的には以下のような要素が重要です：問題提起→コンテキスト→探求の旅→発見と学び→次のステップという明確な流れ「最初は〜と考えたが、〜という課題に直面し、最終的に〜という結論に至った」という思考プロセスの共有失敗したアプローチも含めた試行錯誤の過程の可視化思考整理力が高い記事は、読者に「なるほど、こういう考え方をすればいいのか」という気づきを与えます。実践応用性：読んですぐ行動できる情報実践応用性とは、記事の情報が読者の実際の行動や実践にどれだけ役立つかという観点です。「なるほど、理解できた」と「よし、これで自分でもできる」は大きく異なります。実践応用性の高い記事は、読者が具体的な行動に移せる情報が豊富に含まれています。以前紹介した技術ブログの種類でいえば、「学習ログ」「バグハント記事」「環境構築ガイド」「学んだ教訓記事」などは特に実践応用性を重視したものです。実践応用性を高める要素としては：具体的な手順やステップバイステップの指示つまずきやすいポイントへの対応策失敗例とその解決策読者が自分の状況に応用できる情報の提供実践応用性が高い記事は、読者のお気に入りブックマークやメモに残りやすくなります。構成と読みやすさ：情報の消化しやすさ構成と読みやすさとは、記事の構造、文体、視覚的要素が読者の理解をどれだけ促進するかという観点です。いくら良い内容でも、長い文章の塊では読者は疲れてしまいます。適切な構成と視覚的な工夫は、読者の理解と集中力を大きく助けます。具体的には：冒頭の3行で読者の興味を引く導入適切な見出し階層による内容の整理短い段落(3-5行程度)、箇条書き、強調表示の効果的な使用図や視覚的要素による複雑な概念の明確化具体例と全体像の交互の提示読者に余韻と思考の広がりを残す結び構成と読みやすさが高い記事は、読者がストレスなく最後まで読み切れる記事になります。コミュニケーション力：人間味のある伝え方コミュニケーション力とは、記事が読者と共感的につながり、技術情報を人間味を持って伝えているかという観点です。技術情報は往々にして無機質で冷たい印象を与えがちですが、その背後には常に人間の試行錯誤や感情があります。それらを含めて伝えることで、読者との距離が縮まります。コミュニケーション力を高める要素としては：読み手の感情を大切にする表現個人の経験として共有する姿勢主観的な表現を心がける好きなものを中心に語るポジティブさ批判を柔らかく伝える工夫読者の立場に立った情報提供コミュニケーション力が高い記事は、読者に「この人の次の記事も読みたい」と思わせる力を持ちます。ブログ記事評価プロンプトの使い方では、実際にこのプロンプトを使って記事を評価する方法を見ていきましょう。評価の手順記事全体を通読する：まずは全体を通して読み、初期印象を得ます。各基準で評点をつける：5つの観点それぞれに0.0～5.0の範囲で評点をつけます（小数点第一位まで、例: 4.3）。具体的な所見を記述する：各基準について良い点と改善点の両方を含めた所見を記述します。総合評価を計算する：5つの観点の平均値を算出して総合評価とします。総評と改善提案をまとめる：記事全体についての総評と、優先的に改善すべき点を具体的に提案します。自己評価として使う場合自分の記事を客観的に見直すツールとしても有効です：記事を書き終えた後、少し時間を置いてから（できれば1日以上）再度読み返します。各評価基準を念頭に置きながら、自分の記事を評価します。特に低い評点がついた観点について、改善方法を考えます。成長の記録として使う場合時間をかけて記事を書き続けると、確実に上達していきます。その成長を可視化するツールとしても使えます：過去に書いた記事と最近書いた記事を同じプロンプトで評価します。各観点の点数の変化を比較し、自分がどの領域で成長したかを確認します。まだ点数が低い観点を次回の記事で意識的に改善します。評価プロンプトを評価するこのプロンプトを作成する過程で、改めて「良いブログとは何か」を考えさせられました。5つの観点から見えてくる良いブログの特徴をまとめてみましょう。syu-m-5151.hatenablog.comバランスの取れた総合力興味深いのは、5つの観点がお互いに補完し合う関係にあることです。例えば：防御力を高めるためには、コンテキストと限界を明示する必要がありますが、これは思考整理力にも関わります。実践応用性を高めるには、読者が実行しやすいよう構成と読みやすさが重要です。コミュニケーション力を高めるには、著者自身の思考整理力が前提となります。つまり、真に優れた記事とは、どれか一つの観点だけが突出しているものではなく、全ての観点でバランス良く高い評価を得られるものだと言えるでしょう。読者を中心に据えた視点5つの観点に共通するのは、常に読者の立場から考えるという姿勢です。防御力は「読者の多様な立場や状況を尊重する」こと思考整理力は「読者が著者の考えを追体験できる」こと実践応用性は「読者が実際に行動に移せる」こと構成と読みやすさは「読者の理解と集中力を助ける」ことコミュニケーション力は「読者と共感的につながる」ことこれは、良いブログが「自分のための記録」と「他者のための情報」の絶妙なバランスの上に成り立っていることを示しています。進化し続ける生き物としてのブログ評価プロンプトは「完璧な記事」を目指すためのものではなく、記事の強みと弱みを知り、継続的に改善していくための道具です。前回の記事でも書いたように、「完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しい」のです。評価の目的は完璧を目指すことではなく、80%の完成度で公開しながらも、次はもう少し良くするための指針を得ることにあります。ブログ記事評価プロンプト全文以下が、実際に使用できるブログ記事評価プロンプトの全文です。コピーして自由にお使いください。こちらでも、公開しておきます。blog_evaluation_prompt_5criteria.md · GitHub# ブログ記事評価プロンプト (0.0-5.0)あなたはブログ記事を評価する専門家です。以下の5つの観点から記事を0.0～5.0の範囲で評価し、詳細なフィードバックを提供してください。## 評価基準### 防御力 (0.0-5.0)記事が批判や反論に対してどれだけ耐性を持っているかを評価します。**5.0**: 完璧な防御力。主観的表現と限定的な主張を適切に用い、コンテキストと限界を明示し、実体験と具体例が豊富で根拠と出典が明確。批判を先取りする構成で異なる立場への配慮が行き届いている。見出しと結論が余地を残す形で表現されており、事実と解釈の違いを明確に認識している。自分の不確かさや知識の限界を誠実に認め、読者との信頼関係を構築している。**4.0**: 高い防御力。主観的表現を用い、コンテキストを示し、具体例と根拠を提示している。批判への一定の対応と異なる視点への配慮がある。自分のバイアスをある程度認識し、誠実さを示す表現が見られる。**3.0**: 標準的な防御力。部分的に主観や限界を示しているが、一部に断言的な表現や根拠不足がある。批判への対応が限定的で、特定の立場からの視点に偏る傾向がある。誠実さの表現が限られている。**2.0**: 弱い防御力。断言的な表現が多く、コンテキストや限界の明示が不足。具体例や根拠が少なく、批判への対応がほとんどない。一方的な視点で書かれ、自分の不確かさを認める表現がほとんどない。**1.0**: 非常に弱い防御力。断言と一般化が目立ち、コンテキストや根拠がほぼない。批判や異なる視点への考慮がなく、バイアスを認識していない。誠実さに欠け、権威的な印象を与える。**0.0**: 防御力がない。完全に断言的で一般化された主張のみ。コンテキスト、根拠、実例がなく、批判への対応策がまったくない。不誠実な印象を与える表現が含まれている。### 思考整理力 (0.0-5.0)記事が著者の思考プロセスを整理し、知識を構造化して伝えているかを評価します。**5.0**: 卓越した思考整理力。複雑な概念が「問題提起→コンテキスト→探求の旅→発見と学び→次のステップ」という明確な流れで整理されている。著者の試行錯誤のプロセスが透明に示され、「最初は〜と考えたが、〜という課題に直面し、最終的に〜という結論に至った」という思考の変遷が丁寧に記述されている。**4.0**: 優れた思考整理力。概念が論理的に整理され、思考プロセスの大部分が示されている。問題から解決策までの道筋が明確で、読者は著者の思考をたどることができる。**3.0**: 標準的な思考整理力。基本的な論理構造はあるが、思考プロセスの一部が省略されている。結論は示されているが、そこに至る過程の説明が不十分な箇所がある。**2.0**: 弱い思考整理力。論理の飛躍が多く、思考プロセスがほとんど示されていない。結論だけが述べられ、そこに至る思考の道筋が不明瞭。**1.0**: 非常に弱い思考整理力。断片的な考えが並べられているだけで、論理的なつながりがほとんどない。著者の思考プロセスが見えない。**0.0**: 思考整理力がない。無関係な情報の羅列に近く、何を伝えようとしているのか把握できない。### 実践応用性 (0.0-5.0)記事の情報が読者の実際の行動や実践にどれだけ役立つかを評価します。**5.0**: 非常に高い実践応用性。「学習ログ」「バグハント記事」「環境構築ガイド」「学んだ教訓記事」などの要素を含み、具体的な手順、失敗例とその解決策、つまずきやすいポイントへの対応策を提供している。読者はこの記事だけで実際に行動を起こせる十分な情報と具体的ステップを得られる。**4.0**: 高い実践応用性。具体的な例や実践的なアドバイスが豊富で、読者が自分の状況に応用できる情報が含まれている。行動のきっかけとなる要素が明確に示されている。**3.0**: 標準的な実践応用性。基本的な実践情報は提供されているが、具体例やステップバイステップの指示が限定的。読者は追加情報を探す必要がある。**2.0**: 低い実践応用性。情報は含まれているが抽象的で、実際の場面での応用方法が示されていない。「何をすべきか」は書かれているが「どうすべきか」の説明が不足。**1.0**: 非常に低い実践応用性。情報が断片的で実践に結びつけるのが困難。具体的な行動指針がほぼない。**0.0**: 実践応用性がない。読者が実際に行動に移せる情報がまったくない、または誤った実践指針が含まれている。### 構成と読みやすさ (0.0-5.0)記事の構造、文体、視覚的要素が読者の理解と共感をどれだけ促進するかを評価します。**5.0**: 卓越した構成と読みやすさ。冒頭の3行で読者の興味を引き、適切な見出し階層で内容が整理されている。短い段落(3-5行程度)、箇条書き、強調表示が効果的に使われ、長いコードブロックには適切な説明が付随している。図や視覚的要素が複雑な概念を明確化し、具体例と全体像が交互に示されている。結びは読者に余韻と思考の広がりを残している。**4.0**: 優れた構成と読みやすさ。明確な構造があり、視覚的要素も効果的に使用されている。段落が適切に分割され、重要ポイントが強調されている。読者が内容を容易に把握できる。**3.0**: 標準的な構成と読みやすさ。基本的な構造はあるが、一部に長い段落や複雑な説明がある。視覚的要素の活用が限定的で、読みやすさを向上させる工夫が不足している。**2.0**: 弱い構成と読みやすさ。構造が不明確で、長い段落や複雑な文が多い。視覚的要素がほとんどなく、読者がついていくのが困難。**1.0**: 非常に弱い構成と読みやすさ。一貫した構造がなく、文章が冗長で複雑。視覚的サポートがなく、読者は内容を理解するのに大きな労力を要する。**0.0**: 構成と読みやすさがない。無秩序な情報の羅列で、読者が内容を把握するのがほぼ不可能。### コミュニケーション力 (0.0-5.0)記事が読者と共感的につながり、技術情報を人間味を持って伝えているかを評価します。**5.0**: 優れたコミュニケーション力。読み手の感情を大切にし、個人の経験として共有し、主観的な表現を心がけている。好きなものを中心に語り、ポジティブな内容を強調し、批判を柔らかく伝える工夫がある。読者の立場に立った情報提供と、共感を呼ぶ語り口で、技術情報に人間味を加えている。**4.0**: 良好なコミュニケーション力。読者への配慮が見られ、個人的な経験や感想が適切に織り込まれている。技術情報が親しみやすい形で提示され、読者との対話を意識した書き方がされている。**3.0**: 標準的なコミュニケーション力。基本的な情報は伝わるが、読者との共感的なつながりが限定的。技術情報が淡々と伝えられ、人間味のある表現が少ない。**2.0**: 弱いコミュニケーション力。読者への配慮が不足し、一方的な情報提供に終始している。技術的には正確でも、読者の感情や状況への理解が欠けている。**1.0**: 非常に弱いコミュニケーション力。読者の存在をほとんど意識していない書き方で、共感や対話の要素がない。単なる情報の羅列に近い。**0.0**: コミュニケーション力がない。読者を無視した、または読者に対して無配慮な内容。技術情報が冷淡で機械的に提示されている。## 評価手順1. 記事全体を通読し、各評価基準における初期印象を得る2. 各基準について0.0～5.0の範囲で評点をつける（小数点第一位まで、例: 4.3）3. 各基準についての具体的な所見を述べる（良い点と改善点の両方を含める）4. 総合評価として、各基準の評点の平均値を計算する5. 記事全体についての総評と主な改善提案をまとめる## 評価レポート形式# [記事タイトル] 評価レポート## 総合評価: [平均点]/5.0### 防御力: [点数]/5.0[具体的な所見と例]### 思考整理力: [点数]/5.0[具体的な所見と例]### 実践応用性: [点数]/5.0[具体的な所見と例]### 構成と読みやすさ: [点数]/5.0[具体的な所見と例]### コミュニケーション力: [点数]/5.0[具体的な所見と例]## 総評[全体的な感想と主な強み]## 改善提案[優先的に改善すべき点とその具体的な方法]## 評価の姿勢* 批判ではなく建設的なフィードバックを心がける* 著者の経験レベルや記事の目的を考慮して評価する* 良い点を明確に指摘し、改善点は具体的な提案と共に述べる* 「防御力の高い」コミュニケーションを実践する（批判的す```ぎず、個人の経験としての意見を述べる）* 記事の「学び続ける姿勢」や「思考の過程」としての価値も評価する* 「完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しい」という謙虚さを持ち、80%の完成度でも価値があることを認識するブログ評価プロンプトの限界と注意点この評価プロンプトは便利なツールですが、もちろん限界もあります。使用する際は以下の点に注意しましょう。AIによる評価の限界AIモデルは文章を「理解」しているわけではなく、ある種の基準に基づいて評価しています。そのため：専門的な正確さを完全に判断できない場合があります記事の文化的・社会的コンテキストを十分に考慮できないこともAIの学習データによるバイアスが評価に影響する可能性があります特に技術的な正確性については、専門家によるレビューに勝るものはありません。評価基準のカスタマイズこの評価プロンプトは技術ブログを念頭に作成していますが、あなたの書く記事のタイプや目的に合わせてカスタマイズすることをお勧めします。例えば：チュートリアル記事なら「正確性」や「再現性」の観点を追加哲学的な考察記事なら「思考の深さ」や「問いの質」の観点を追加製品レビュー記事なら「公平性」や「比較の妥当性」の観点を追加評価を絶対視しないどんなに優れた評価基準でも、それはあくまで参考にすべきものであり、絶対的な判断基準ではありません。前回の記事でも触れたように、「過剰な期待が否定の感情を生み出します」。評価が低かったからといって落ち込むのではなく、「どうすれば次はもっと良くなるか」という前向きな視点で捉えることが大切です。おわりに「ブログ記事評価プロンプト」を作成してみて、改めて感じたのは、「良い記事を書く」ということの多面性です。防御力、思考整理力、実践応用性、読みやすさ、コミュニケーション力—これらや他の要素のバランスを取りながら、読者にとって価値ある情報を提供することの難しさと奥深さを実感しました。そして同時に、完璧を目指すことの罠も見えてきました。全ての観点で5.0を取るような記事を書こうとすると、おそらく公開に至る前に挫折してしまうでしょう。しかも絶対的に「良い記事」なんてものはないんですよね。誰かにとって素晴らしい記事でも、別の誰かにとっては「何言ってるかわからない」記事かもしれません。というか別に誰からも見られない記事かもしれません。大切なのは、80%の完成度で公開する勇気と、次はもう少し良くしようという向上心と予定調和からどこかはみ出そうとするバランスです。このプロンプトは完璧を求めるためのものではなく、自分の強みと弱みを知り、少しずつ成長していくための道具として使ってください。なので、修正して使ってもらって問題ないです。書き続けることこそが、最高の学びです。一つひとつの記事が完璧でなくても、書き続けることで確実に上達していきます。このプロンプトが、あなたのブログ執筆の旅の、小さくても役立つ道しるべとなれば幸いです。このプロンプトはあくまで私の考える評価基準であり、個人や会社によって必要な評価観点は当然変わってきます。技術系スタートアップならば「技術的正確性」をより重視するかもしれませんし、マーケティング部門では「読者の行動喚起力」が重要になるでしょう。個人ブログなら「自分らしさ」や「個性の表現」という観点も加えたいかもしれません。ぜひ皆さんの状況や目的に合わせて、このプロンプトを修正・拡張・カスタマイズしてください。「うちの組織では、この観点の方が重要だ」「この基準は自分の文脈では意味がない」といった具合に、それぞれのニーズに合わせた評価プロンプトに育てていってください。最後に、このプロンプトは誰でも使ってくれという気持ちで公開しています。使ってみて改善点があれば、ぜひ教えてください。あなたの視点で改良を加え、さらに良いツールに育てていただければと思います。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—それがブログの本当の姿だと私は思っています。このプロンプトが、あなたの書く喜びと成長の一助となることを願っています。余談ですが「LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発」はとても参考になる良い本だったのでオススメです。LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発作者:John Berryman,Albert Ziegler,服部 佑樹（翻訳）,佐藤 直生（翻訳）オーム社Amazon追記ブログ記事評価プロンプトを改良しました。主な変更点は、①「AIっぽさ」を独立した評価項目として追加（0-5点、低いほど人間らしい）、②各評価基準に「評価の着眼点」を明記して客観性を向上、③評価レポートにレーダーチャート風の視覚表現とAIっぽさを改善する具体的なリライト例を追加、④評価時のチェックリストと指針を新設、⑤5つの基本評価軸は維持しつつ、各項目にAI時代に対応した観点（情報の強弱、著者独自の経験、視覚要素の活用など）を補強。これにより、AI生成文章を「読む価値のある読み物」に改善するための、より実践的な評価ツールになりました。AIっぽさの追加はこちらのブログを参考にさせていただきました。nomolk.hatenablog.com表示がバグるのでURLのみブログ記事評価プロンプト v2.0 https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659 · GitHub","isoDate":"2025-05-19T01:06:59.000Z","dateMiliSeconds":1747616819000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818","contentSnippet":"はじめに「新規プロジェクトに参画したら、アプリケーションがRustで書かれていた...」このような経験をされた方も多いのではないでしょうか。もしくは今後あるかもしれません。特に、オブザーバビリティの実装を担当することになったインフラエンジニアにとって、Rustは馴染みの薄い言語かもしれません。このガイドは、インフラエンジニアとしての経験は豊富だが、Rustの経験が少ないインフラエンジニアのために書かれています。既存のRustアプリケーションにログ、メトリクス、トレーシングを実装する方法を、Rustの前提知識を必要とせずに理解できるよう解説します。前提知識が不要なだけで都度学習はしてもらいます。想定読者オブザーバビリティの実装経験があるPython、Java、Goなどでの実装経験はあるRustは初めて触れる、もしくは経験が浅い既存のRustアプリケーションにオブザーバビリティを実装する必要があるこのガイドで得られることRustアプリケーションの基本的な構造の理解オブザーバビリティ実装に必要なRustの最小限の知識実装手順とコード例トラブルシューティングのポイントまず、典型的なRustのWebアプリケーションの構造を見ていきましょう。Rustの基本的な概念アトリビュート（#[...]）Rustでは#[...]という記法をアトリビュート（属性）と呼びます。これはコードに対して追加の情報や機能を付与する特別な構文です。アトリビュートを使用することで、コンパイラへの指示や機能の自動実装が可能になります。これは他の言語では以下のように表現されるものに相当します。Java: アノテーション（@SomeAnnotation）Python: デコレータ（@decorator）TypeScript: デコレータ（@decorator）参考: The Rust Reference - Attributes主なアトリビュートの例：// 自動的に特定の機能を実装する#[derive(Debug)]  // println!(\"{:?}\", obj)でデバッグ出力を可能にする                  // 例: println!(\"{:?}\", user); // User { id: 1, name: \"John\" }#[derive(Clone)]  // オブジェクトのクローン（複製）を可能にする                  // 例: let user2 = user.clone();#[derive(Serialize, Deserialize)]  // JSONとの相互変換を可能にする                  // 例: let json = serde_json::to_string(\u0026user)?;                  // let user: User = serde_json::from_str(\u0026json)?;// 関数やモジュールの属性を指定する#[test]  // テスト関数であることを示す         // 例: cargo testでテストとして実行される#[actix_web::main]  // actix-webのメイン関数であることを示す                    // 非同期ランタイムの設定を自動的に行うアトリビュートが実際に何をしているのかを具体例で見てみます。// #[derive(Debug)]がない場合struct User {    id: u32,    name: String,}let user = User { id: 1, name: \"John\".to_string() };println!(\"{:?}\", user);  // コンパイルエラー！// #[derive(Debug)]がある場合#[derive(Debug)]struct User {    id: u32,    name: String,}let user = User { id: 1, name: \"John\".to_string() };println!(\"{:?}\", user);  // User { id: 1, name: \"John\" } と出力されるアトリビュートを使用することで、以下のようなメリットが得られます。ボイラープレートコードの削減標準的な機能の自動実装コンパイル時の動作制御フレームワークとの統合Rust By Example - AttributesRust Derive マクロのドキュメント構造体（struct）とパターンマッチング（match）Rustの構造体は、他の言語のクラスに相当します。また、パターンマッチングは他言語のswitch文に似ていますが、より強力です。// match式の例match result {    Some(value) =\u003e println!(\"値が存在します: {}\", value),    None =\u003e println!(\"値が存在しません\"),}参考: The Rust Programming Language - Pattern Matchingエンドポイントの戻り値型-\u003e impl Responderこれは「Responderトレイトをimplementsする何らかの型」を返すことを意味します。雑に言うとJavaのインターフェースやTypeScriptの型に似た概念です。参考: Actix Web - Responder traitMutexを使用したデータの共有users: Mutex\u003cHashMap\u003cu32, User\u003e\u003eMutexは「相互排除（Mutual Exclusion）」の略で、複数のスレッドから安全にデータにアクセスするための機構です。参考: Rust Standard Library - MutexPath引数の取得id: web::Path\u003cu32\u003eURLのパスパラメータを型安全に取得します。例：/users/123の123部分。参考: Actix Web - Path ExtractorWebアプリケーションの簡易な実装それでは、簡易なRustのWebアプリケーションの構造を見てみましょう。// src/main.rs - 既存のWebアプリケーションuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;// Rustでは構造体の定義に#[derive(...)]という形式で機能を追加します// SerializeとDeserializeは、JSONとの相互変換を可能にします#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}// AppStateは、アプリケーション全体で共有する状態を定義します// Mutexは、複数のスレッドから安全にデータを変更するために使用しますstruct AppState {    users: Mutex\u003cHashMap\u003cu32, User\u003e\u003e,    user_counter: Mutex\u003cu32\u003e,}// エンドポイントの実装async fn create_user(    state: web::Data\u003cAppState\u003e,    user_data: web::Json\u003cUser\u003e) -\u003e impl Responder {    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;        HttpResponse::Created().json(new_user)}async fn get_user(    state: web::Data\u003cAppState\u003e,    id: web::Path\u003cu32\u003e) -\u003e impl Responder {    let users = state.users.lock().unwrap();        match users.get(\u0026id.into_inner()) {        Some(user) =\u003e HttpResponse::Ok().json(user),        None =\u003e HttpResponse::NotFound().finish()    }}#[actix_web::main]async fn main() -\u003e std::io::Result\u003c()\u003e {    // アプリケーションの状態を初期化    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    HttpServer::new(move || {        App::new()            .app_data(app_state.clone())            .route(\"/users\", web::post().to(create_user))            .route(\"/users/{id}\", web::get().to(get_user))    })    .bind(\"127.0.0.1:8080\")?    .run()    .await}参考:Actix Web DocumentationSerde JSON DocumentationRust Standard Library - HashMapAPIの使用例# ヘルスチェックcurl http://localhost:8080/health# ユーザーの作成curl -X POST http://localhost:8080/users \\  -H \"Content-Type: application/json\" \\  -d '{\"name\": \"John Doe\", \"email\": \"john@example.com\"}'# ユーザーの取得curl http://localhost:8080/users/0この基本的な実装を理解することで、次のステップであるオブザーバビリティの実装がより理解しやすくなります。Rustの重要な概念（インフラエンジニアが知っておくべきこと）依存関係の管理RustではCargo.tomlファイルで依存関係を管理しますnpmのpackage.jsonやrequirements.txtに相当します[dependencies]name = \"version\"  # 基本的な依存name = { version = \"version\", features = [\"feature1\", \"feature2\"] }  # 機能を指定モジュールとパスuseキーワードでモジュールをインポートしますmodキーワードで新しいモジュールを定義します// src/logging.rs などの新しいファイルを作成した場合mod logging;  // main.rsでこのように宣言use crate::logging::setup_logger;  // 関数を使用する際はこのように指定エラーハンドリングRustではResult\u003cT, E\u003e型でエラーハンドリングを行います?演算子でエラーを上位に伝播させます// エラーハンドリングの例fn function() -\u003e Result\u003c(), Box\u003cdyn Error\u003e\u003e {    let result = something_that_might_fail()?;  // エラーが発生したら即座にReturnします    Ok(())}オブザーバビリティの実装この辺はぜひもう一度読んでほしいです。syu-m-5151.hatenablog.com依存関係の追加まず、Cargo.tomlに必要な依存関係を追加します。[dependencies]# 既存の依存関係actix-web = \"4.4\"serde = { version = \"1.0\", features = [\"derive\"] }serde_json = \"1.0\"# オブザーバビリティ関連の依存関係を追加tracing = \"0.1\"tracing-subscriber = { version = \"0.3\", features = [\"env-filter\"] }tracing-actix-web = \"0.7\"prometheus = \"0.13\"lazy_static = \"1.4\"opentelemetry = { version = \"0.21\", features = [\"rt-tokio\"] }opentelemetry-otlp = \"0.14\"tracing-opentelemetry = \"0.22\"モジュール構造の作成オブザーバビリティ関連のコードを整理するために、以下のような構造を作成します。// src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::setup_metrics;pub use tracing::setup_tracing;ログの実装今度、別でRust のロギングのライブラリの比較をしたいです⋯。moriyoshi.hatenablog.comwww.forcia.comライブラリが云々よりも実際にちゃんと設計するのも大切ですよね。qiita.com// src/observability/logging.rsuse tracing::{info, warn, error, Level};use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!(\"{}=info\", env!(\"CARGO_PKG_NAME\")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}// ログマクロの使用例// info!(\"メッセージ\");// error!(\"エラー: {}\", err);メトリクスの実装// src/observability/metrics.rsuse prometheus::{Registry, Counter, IntCounter, opts};use lazy_static::lazy_static;// メトリクスの定義lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();    pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        \"http_requests_total\",        \"Total number of HTTP requests\"    ).unwrap();    pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!(\"user_operations_total\", \"Total number of user operations\")            .const_label(\"service\", \"user-api\")    ).unwrap();}pub fn setup_metrics() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    // メトリクスの登録    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}// Prometheusメトリクスエンドポイント用のハンドラpub async fn metrics_handler() -\u003e impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(\u0026REGISTRY.gather(), \u0026mut buffer).unwrap();        HttpResponse::Ok()        .content_type(\"text/plain\")        .body(buffer)}トレーシングの実装気になればこちらも読んでもらいたいです。syu-m-5151.hatenablog.com// src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var(\"OTLP_ENDPOINT\")                        .unwrap_or_else(|_| \"http://localhost:4317\".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new(\"service.name\", \"user-api\"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    // トレーシングの初期化    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}既存のエンドポイントへの統合// 修正後のcreate_user関数#[tracing::instrument(name = \"create_user\", skip(state, user_data))]async fn create_user(    state: web::Data\u003cAppState\u003e,    user_data: web::Json\u003cUser\u003e) -\u003e impl Responder {    // メトリクスのインクリメント    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    // ログの出力    info!(        user_name = %user_data.name,        user_email = %user_data.email,        \"Creating new user\"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, \"User created successfully\");        HttpResponse::Created().json(new_user)}メインアプリケーションの更新#[actix_web::main]async fn main() -\u003e std::io::Result\u003c()\u003e {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect(\"Failed to setup metrics\");    setup_tracing().expect(\"Failed to setup tracing\");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!(\"Starting server at http://localhost:8080\");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route(\"/metrics\", web::get().to(metrics_handler))            .route(\"/users\", web::post().to(create_user))            .route(\"/users/{id}\", web::get().to(get_user))    })    .bind(\"127.0.0.1:8080\")?    .run()    .await}3. 動作確認アプリケーションの起動# 開発モードで実行cargo run# 本番モードで実行（最適化あり）cargo run --releaseAPIのテスト# ユーザーの作成curl -X POST http://localhost:8080/users \\  -H \"Content-Type: application/json\" \\  -d '{\"name\": \"John Doe\", \"email\": \"john@example.com\"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsログの確認# 環境変数でログレベルを設定RUST_LOG=debug cargo run4. トラブルシューティング一般的な問題と解決方法コンパイルエラー依存関係のバージョンの不一致cargo update  # 依存関係を更新ランタイムエラーOpenTelemetryエンドポイントに接続できない# エンドポイントの確認OTLP_ENDPOINT=http://localhost:4317 cargo runメトリクスが表示されないPrometheusレジストリの確認// メトリクスが正しく登録されているか確認println!(\"Registered metrics: {:?}\", REGISTRY.gather());5. 本番環境への展開環境変数の設定# 必要な環境変数export RUST_LOG=infoexport OTLP_ENDPOINT=http://otel-collector:4317export SERVICE_NAME=user-apiDockerファイルの例FROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-app /usr/local/bin/CMD [\"my-app\"]6.Rustオブザーバビリティ実装の最終成果物ディレクトリ構造my-rust-api/├── Cargo.toml├── Dockerfile├── .env└── src/    ├── main.rs    └── observability/        ├── mod.rs        ├── logging.rs        ├── metrics.rs        └── tracing.rs各ファイルの実装Cargo.toml[package]name = \"my-rust-api\"version = \"0.1.0\"edition = \"2021\"[dependencies]actix-web = \"4.4\"serde = { version = \"1.0\", features = [\"derive\"] }serde_json = \"1.0\"tokio = { version = \"1.0\", features = [\"full\"] }tracing = \"0.1\"tracing-subscriber = { version = \"0.3\", features = [\"env-filter\"] }tracing-actix-web = \"0.7\"prometheus = \"0.13\"lazy_static = \"1.4\"opentelemetry = { version = \"0.21\", features = [\"rt-tokio\"] }opentelemetry-otlp = \"0.14\"tracing-opentelemetry = \"0.22\"src/main.rsuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;use tracing::info;mod observability;use observability::{setup_logging, setup_metrics, setup_tracing, metrics_handler};#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}struct AppState {    users: Mutex\u003cHashMap\u003cu32, User\u003e\u003e,    user_counter: Mutex\u003cu32\u003e,}#[tracing::instrument(name = \"create_user\", skip(state, user_data))]async fn create_user(    state: web::Data\u003cAppState\u003e,    user_data: web::Json\u003cUser\u003e) -\u003e impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    use crate::observability::metrics::USER_OPERATIONS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    info!(        user_name = %user_data.name,        user_email = %user_data.email,        \"Creating new user\"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, \"User created successfully\");    HttpResponse::Created().json(new_user)}#[tracing::instrument(name = \"get_user\", skip(state))]async fn get_user(    state: web::Data\u003cAppState\u003e,    id: web::Path\u003cu32\u003e) -\u003e impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    let users = state.users.lock().unwrap();        match users.get(\u0026id.into_inner()) {        Some(user) =\u003e {            info!(user_id = user.id, \"User found\");            HttpResponse::Ok().json(user)        },        None =\u003e {            info!(user_id = %id, \"User not found\");            HttpResponse::NotFound().finish()        }    }}#[actix_web::main]async fn main() -\u003e std::io::Result\u003c()\u003e {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect(\"Failed to setup metrics\");    setup_tracing().expect(\"Failed to setup tracing\");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!(\"Starting server at http://localhost:8080\");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route(\"/metrics\", web::get().to(metrics_handler))            .route(\"/users\", web::post().to(create_user))            .route(\"/users/{id}\", web::get().to(get_user))    })    .bind(\"127.0.0.1:8080\")?    .run()    .await}src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::{setup_metrics, metrics_handler};pub use tracing::setup_tracing;pub(crate) use metrics::HTTP_REQUESTS_TOTAL;pub(crate) use metrics::USER_OPERATIONS_TOTAL;4. src/observability/logging.rsuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!(\"{}=info\", env!(\"CARGO_PKG_NAME\")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}src/observability/metrics.rsuse actix_web::{HttpResponse, Responder};use prometheus::{Registry, IntCounter, opts};use lazy_static::lazy_static;lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();        pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        \"http_requests_total\",        \"Total number of HTTP requests\"    ).unwrap();        pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!(\"user_operations_total\", \"Total number of user operations\")            .const_label(\"service\", \"user-api\")    ).unwrap();}pub fn setup_metrics() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}pub async fn metrics_handler() -\u003e impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(\u0026REGISTRY.gather(), \u0026mut buffer).unwrap();        HttpResponse::Ok()        .content_type(\"text/plain\")        .body(buffer)}src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var(\"OTLP_ENDPOINT\")                        .unwrap_or_else(|_| \"http://localhost:4317\".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new(\"service.name\", \"user-api\"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}.envRUST_LOG=infoOTLP_ENDPOINT=http://localhost:4317SERVICE_NAME=user-apiDockerfileFROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-rust-api /usr/local/bin/COPY .env /usr/local/bin/WORKDIR /usr/local/binCMD [\"my-rust-api\"]動作確認方法アプリケーションの起動:cargo runAPIのテスト:# ユーザーの作成curl -X POST http://localhost:8080/users \\  -H \"Content-Type: application/json\" \\  -d '{\"name\": \"John Doe\", \"email\": \"john@example.com\"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsこの実装により、以下のオブザーバビリティ機能が利用可能になります。ログ出力：構造化ログが標準出力に出力されますメトリクス：/metricsエンドポイントでPrometheus形式のメトリクスが取得可能トレーシング：OpenTelemetryを通じて分散トレーシングが可能各機能は環境変数を通じて設定可能で、本番環境での運用に対応しています。7. 参考リンクRust公式ドキュメントActix-Web ガイドZero To Production In RustRust Web Programming - Third EditionOpenTelemetry RustPrometheus Rust Clienttracing クレートRustを使った社内用Webアプリの開発・運用を持続させるために、素材メーカーが学んだことまとめこのガイドでは、Rustの経験が浅いインフラエンジニアを対象に、既存のRustアプリケーションにオブザーバビリティを実装する方法を解説しました。アトリビュートやトレイトといったRustの基本的な概念から始め、オブザーバビリティ実装に必要な最小限の知識を説明しました。Cargoを使用した依存関係の管理方法や、モジュール構造の基本についても触れることで、Rustの開発環境への理解を深めることができたと思います。実装面では、ログ出力にtracing、メトリクスにprometheus、分散トレーシングにOpenTelemetryを採用し、それぞれを個別のモジュールとして整理された形で実装する方法を示しました。これにより、構造化ログによる効率的なログ管理や、Prometheusと互換性のあるメトリクスエンドポイント、そしてOpenTelemetryによる分散トレーシングといった実用的な機能を実現することができました。このガイドを通じて、Rustの詳細な知識がなくても、実用的なオブザーバビリティ機能を実装できることを示すことができました。Cargoのパッケージは複雑怪奇なので注意してほしいです。オブザーバビリティの実装は、アプリケーションの健全性監視と問題解決に不可欠です。このガイドが、Rustでのオブザーバビリティ実装に取り組むインフラエンジニアの一助となれば幸いです。","isoDate":"2025-05-15T14:08:18.000Z","dateMiliSeconds":1747318098000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"転職したらMCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","contentSnippet":"本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 転職したらMCPサーバーだった件\r- 公式URL: https://forkwell.connpass.com/event/354289/\r- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP\u0026f=live\r- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae\r- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057\r- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"中学17年生","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/10/205353","contentSnippet":"はじめに気づけば「中学17年生」だ。肩書きは立派な「ソフトウェアエンジニア」「登壇者」「翻訳者」「執筆者」だが、心の奥底では未だに教室の隅っこでふざけあう中学生のような気持ちでいる。会社のIDカードをぶら下げて歩いていると、「これ、誰かの忘れ物かな？」と思うことがある。大人のコスプレが上手くなっただけで、中身はまだあの頃のまま。表向きは30歳のエンジニアでありながら、内側には未だに中学生の感性を宿している。年齢と肩書きだけが大人の証ではなく、混沌とした感情や未熟さを受け入れる勇気こそが、本当の成長の証かもしれない。教室の窓から外を眺め、「早く大人になりたい」と思っていた頃の自分に、「実はなれてないよ。でも大丈夫、みんな同じさ」と教えてあげたい。幸せな時間はあっという間に過ぎていく。「これもいつか終わるんだろうな」と考えながら楽しいひとときを過ごすのは、30歳を前にした私のような人間の性かもしれない。常に砂時計の砂が落ちていくのを見続けているような感覚だ。過去の自分を否定せず、かといって執着もせず、ただ前を向いて歩き続ける。大人になれば全てが分かると思っていたのに、実際は「分からないことが分かる」だけだった。誰かに言われて落ち込むというより、自分で自分にハードルを上げすぎて、それを超えられなかったときの静かな絶望感の方がはるかに大きい。完璧を目指すあまり、一歩も前に進めなくなるという皮肉。そして「身の程」を知るようになった。自分の能力や限界への理解が深まるほど、逆に自信を持って胸を張れるようになった。ライブラリを全部理解していなくても、「今は分からないけど調べれば理解できる」という余裕が生まれた。自分の限界を知ることは、弱さではなく強さだと気づいた。雨の日に窓辺で立ち尽くし、「早く大人になりたいな」と呟いていた中学生に言ってあげたい。「大丈夫、大人になっても同じように窓の外を眺めているよ。でも、傘を持って外に出る勇気だけは身についたかな」と。年齢は小さな枠組みで「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。いくつになっても成長できると思えるようになったのは、30歳を前にした最大の収穫かもしれない。この中学17年生、すなわち30歳になろうとしているエンジニアは、まだまだ未熟だけれど、その未熟さも含めて自分自身なのだと受け入れる勇気を持ち始めている。今日も窓の外を眺めながら、雨が降っていても傘を持って一歩踏み出す。そんな日々を、中学生のような好奇心と、大人としての覚悟を持って生きていきたい。初めてこの文章を読んでくださる方も、いつも読んでくださっている方も、お時間をいただきありがとうございます。こちらはB面シングルである。A面は「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」をぜひ読んでみてください。口太郎の焦燥「あなたは口から生まれた口太郎」母親からそう言われたことがある。幼稚園では隅っこで本を読む子だったが、小学生から急に喋り始め、人前で話すのが得意になった。母子家庭で暗い空気を変えたかったのかもしれない。もしくは治安の悪い小学校で生き抜く術だったのかもしれません。朝、パーカーを着て、オフィスに向かう。「おはようございます」と言いながら不思議な感覚に襲われる。「なんで俺、ここにいるんだろう？」スタンディングデスクに向かい、MacBookを開く髭面の男。パーマヘアとサングラスの下には、実は中学生の心を隠している。会議室で専門的な議論をする最中にも「これ、本当に俺が言ってるの？」と感じることがある。あの日、教室で絶えず喋っていた少年が、突然30代の身体に転送されたような感覚。「では○○さんはどう思いますか？」と振られた瞬間、内心は複雑だ。話す内容に本当に価値があるのか？単なる思いつきではないのか？表面上は堂々としていても、内心では「これは個人的な経験の押し付けではないか」という自問が絶えない。N=1の経験で語ることへの後ろめたさ。もっと多くの事例、体系的な知識、裏付けのある情報に基づいて話したい。この葛藤は一時期、本当に深刻だった。登壇前夜は「俺の話に価値があるのか」と不安で眠れない。「お前の知識は浅すぎる。もっと文献を読め。もっと体系的に理解しろ」という内なる声。深夜、PCに向かい論文や技術書を読み漁る。この知識が自分の存在証明になるような気がしていた。しかしある日気づいた。なぜこれほど「体系的な知識」にこだわるのか？それは単なる自己防衛ではないのか？そしてまた気づいた。自分のN=1経験を否定することは、誰にでも言える一般論だけを語ることになる。N=1がなければ、本当の「血の通った知識」にはならない。文献から得た知識も、自分の経験を通して初めて命を吹き込まれる。「N=1だから価値がない」のではなく、「N=1だからこそ伝えられる真実がある」のだ。アウトプットへの執着が、質の高いインプットを求める原動力になっていた。登壇準備では「これは他の人でも再現できるのか？」「普遍的な教訓か？」と自問自答する。そして気づいたのは、価値あるアウトプットをするためには質の高いインプットが不可欠だということ。表面的な理解だけでなく、深く掘り下げ、多角的に検証し、時に自分の考えを否定することも辞さない。N=1の限界を認識しつつも、その価値を大切にする。自分の経験こそがリアリティを生み、他者の共感を呼ぶ。一方で、N=1を超えるため、文献を読み、他者の事例を学び、様々な理論を比較検討する。この個人的体験と普遍的知識のバランスを取りながら、インプットとアウトプットのサイクルを回し続けることで、少しずつ自信がついてきた。「これは単なる個人的な意見です」と後ろめたく断るのではなく、「この考えは自分の経験と、こういう体系に基づいています」と胸を張って言えるようになった。完璧ではなくても、N=1の経験者だからこそ語れる真実があると信じ、現時点での最善を尽くすことの大切さを学んだ。それでも言葉が伝わらない日もある。説明すればするほど相手の表情が曇り、終わった後の虚無感。そんな日は電車の窓に映る自分を見て「お前、何様のつもりだ」と責める。その窓に映る自分は、かつての父親に重なる。見た目は大人になったが、中身は「テスト返却、やばい...」と思う少年のまま。それでも今日も本を開き、情報を集める。自分のN=1を大切にしながら、それを超える知識を求め続ける。それが、口太郎としての責任の果たし方なのだ。ふーん、ムッチじゃん三十路の入り口に立って思うのは、自分の知識はまだほんの入り口だということ。10代の頃は「自分はほとんど全てを知っている」と思い、20代で「自分は何も知らない」と気づき、30手前で「何も知らないことすら完全には理解していない」という事実に辿り着いた。でも、これは悪いことじゃない。この「無知の知」こそが学びの始まりだ。30歳という節目を前に、不思議な安心感がある。以前は「知らない」と認めることが弱みを晒すように感じていた。しかし今では、知らないことを素直に認め、学び続ける姿勢こそが強さだと気づいた。成長とは、わからないことが増えていく過程でもあるのだ。人生の解像度が上がってきた。初めて眼鏡をかけたような感覚だ。以前は見えなかった細部、気づかなかった背景、関連性が鮮明に浮かび上がる。かつての私は「この不具合はこのコードが原因だ」と表層的な事実に振り回され、問題を「解決すること」だけに価値を見出していた。機能するコードを書けば満足していた。しかし30歳に近づくにつれ、「なぜこのバグが発生したのか」「どんな思考プロセスがこの決断を導いたのか」という問いに関心が移ってきたのだ。解像度が上がると自分の限界も他者の弱さも鮮明に見えてくる。できると思っていたことができない自分、理解していると思っていたことが理解できない自分に直面する。同僚のコードレビューで見落としがあれば自己嫌悪に陥り、技術書を読んでも理解できない箇所があれば絶望する。同時に、かつては完璧だと思っていた上司にも弱さがあることに気づく。「みんな同じなんだ」という気づきは、時に励みになり、時に孤独を感じさせる。誰もが不安や焦り、コンプレックスを抱えているのだ。人の言動にも多角的な視点を持つようになった。同僚の一言に腹を立てる代わりに、なぜその言葉が出てきたのか、どんな背景があるのかを考えるようになった。そんな自分を周囲は「考えすぎだよ」と笑うこともある。確かに物事を複雑に考えすぎる一方で、新しい技術に出会うと少年のように純粋に熱中する自分もいる。最新ライブラリを発見して「うおおこれヤバい！」と一人テンションが上がる姿は、中学生と何も変わらない。この相反する二面性を、どちらも大切にしていきたいと思う。時々、深い孤独に襲われる。技術的な話をしていても「この人、本当はわかってないな」と感じたり、逆に「自分こそが理解できていないのでは」と不安になったりする。言葉は伝わっているようで、本当は伝わっていない。そんな夜は、パソコンの前で一人、沈黙の中に沈む。人生の解像度が上がるとは、世界をより鮮明に、立体的に、繊細に感じられるようになること。複雑さを恐れず、その豊かさを楽しめるようになること。シンプルさの中にある深い真理を見抜けるようになること。この視点の成熟こそが、30歳を前にした最大の収穫だと思う。この好奇心と探求心は、ずっと失わないでいたい。努力の質を高める戦略的サボり方のススメ子供の頃や20代前半は何事もがむしゃらにやってきた。とにかく時間をかけて、労力をかけて、血反吐を吐くほど頑張ることが美徳だと信じていた。しかし30歳を前にして、ようやく「サボり方」の本質を理解した。やるべきことの絶対的な量を減らすのではなくて、得意なことをより頑張るためにそうじゃないことをやらないことである。振り返れば、私が過剰に努力してきた背景には経験不足へのコンプレックスがあった。「努力で他の人に負けたくない」という思いが、自分を追い込む原動力だった。通勤電車でも技術記事を読み、休日も勉強会に参加し、寝る前もコードを書く。そんな日々が当たり前になっていた。以前の私は、プロジェクトの全てに関わろうとしていた。本来の開発業務だけでなく、新卒採用活動、社内勉強会の企画・運営、技術ドキュメント整備、翻訳、執筆、登壇準備まで次々と引き受けた。結果、Todo リストは膨れ上がり、何から手をつければいいのか分からなくなった。抱え込みすぎて身動きが取れなくなり、どの成果物も中途半端になり、最終的には時間も質も犠牲になった。ある日の内省で気づいたのは、「開発以外の仕事もすべて引き受ける」という強迫観念は美徳ではなく、生産性を下げる要因だということ。今は違う。「これは他の人に任せよう」「この会議は本当に私が出席すべきか」と常に問いかける。自分にとって本質的でないことを手放すことで、核心的な部分により深く集中できるようになった。これが「サボり」という名の知恵の正体だ。「推論能力が高い人は、生まれつきの才能だ」と思っていた時期もあった。しかし現実は異なる。人が「思考力」と呼ぶものの正体は、過去に勉強したり経験したりして蓄積した膨大な記憶の集合体だ。「才能だけで勝負できたらいいのに」という願望は、「努力せずに結果を出したい」という甘えに過ぎない。若かった頃は「努力の量=成果」という単純な方程式を信じていた。しかし実際は、あるポイントを超えると努力の量は結果に結びつかず、むしろパフォーマンスを低下させる。24時間コードを書き続けても、24時間分の価値は生まれない。8時間集中して働き、残りの時間は休息や刺激を得る方が生産性は高まる。今は「直線的な成果」より「累積的な成果」を重視する。一度の努力が何度も実を結ぶシステムを作ることの価値を知った。「楽をするのは悪いことだ」という思い込みを捨て、「どうやったらもっと楽になるか？」を常に考えるようになった。これはずるくなったのではなく、より賢く生きるための知恵だ。今でも時々、深夜まで技術書を読む自分がいる。違いは、それが強迫観念からではなく、純粋な好奇心から生まれていることと、「今日はここまで」と自分で線引きできるようになったこと。経験不足へのコンプレックスを糧にして前に進む方法を見つけた。適切にサボりながらマルチタスクは避け、深い思考力を養いつつ、累積的な成果を上げる方法を模索することが何より大切だと気づいた。これが30歳を前にした私が見つけた、努力の質を高める戦略だ。大人の責任と子供の好奇心のバランス年齢を重ねるごとに、肩に背負うものは確実に増えていく。責任という名の荷物は年々重くなる一方だ。給料は責任に支払われる。プロジェクトの成否、周りの成長、自分のキャリア——すべてが自分の決断にかかっている。「昨日の自分の選択が今日の現実を作っている」と痛感する日々。もはや「環境のせい」という言い訳は通用しない。そんな中で気づいたのは、「責任ある大人」と「好奇心旺盛な子供」という二つの側面を持ち続けることが、私の心のバランスを保っていることだ。これは矛盾ではなく、むしろ相互補完的な関係なのだと分かってきた。重みばかりを背負えば疲弊し、軽やかさだけを求めれば空虚になる。しかし、この二面性はコンプレックスによってさらに複雑になる。「もっとできるはずなのに」という自己期待と「周りと比べて足りない」という不安が交錯する。リリース前日の緊張感、大規模なリファクタリングの決断、若手への指導…。「間違ったらどうしよう」という恐怖と同時に、「自分にできるのか」という疑念が常につきまとう。責任を果たそうとすればするほど、コンプレックスが膨らんでいく皮肉。20代前半は「エンジニアとしてこうあるべき」という理想に縛られていた。流行りのフレームワークを追いかけ、GitHubの草を生やすことに躍起になっていた。SNSでは皆が凄いプロジェクトを作っている。オープンソースに貢献し、技術書を書き、登壇する。そんな人たちと比べて、自分は何もできていない——そんな劣等感に苛まれていた。技術の話で分からないことがあっても、怖かったのだ、無知を晒すことが。しかし30歳に近づく今、そんな見栄や焦りが少しずつ剥がれ落ちてきた。世界最高のプログラマーになる必要はない。自分にしかできないことを見つけ、それを磨いていけばいい。「これが今の自分のベストだ」と受け入れられるようになった。時に内なる声が聞こえてくる。「お前みたいに登壇ばかりしているのは、結局技術から逃げているだけだ」と。それは自分の中の「技術至上主義者」の声だ。すると別の声が反論する。「技術ブログも書いているし、普通にコードも書いている技術顧問として仕事もしているし、OSSも公開している。なぜ自分を否定するんだ」と。この内なる対話は終わりがない。表面上は微笑みながらも、心の中では「10年後、お前はどんな場所にいるだろう」という問いを抱え続けている。コンプレックスを抱えながらも、それを力に変えていく。好奇心は新しい技術への情熱として、責任感は仕事への真摯な姿勢として。この二つが時に矛盾し、時に補完し合いながら、私というエンジニアを形作っている。完璧主義のコンプレックスは、時に自分を追い詰めるが、それが高い基準を保つ原動力にもなる。大切なのは、それに押しつぶされないことだ。経験を重ねるにつれ、未熟な自分の使い方が分かってきた。自分の得意不得意を理解し、ほどよく力の抜けた自分なりのリズムを見つけられるようになった。以前のような「完璧なコード」への執着から解放され、「適切に機能するコード」「メンテナンスしやすいコード」という現実的な価値観へとシフトした。20歳の頃は周りの「すごい人たち」に圧倒されていた。それと比べて30歳を前にした今は、不思議と清々しい気持ちでいる。「完璧なエンジニア」を目指すのではなく、「自分らしいエンジニア」として歩んでいこうという気持ちが強くなった。大人の責任感と子供の好奇心、そして自分特有のコンプレックス。この複雑な混合物を抱えながらも、それを自分の個性として受け入れていく。これが私の見つけた、エンジニアとしてのバランスの取り方だ。いつかは終わるものをちゃんと楽しむ幸せな時間はあっという間に過ぎていく。楽しいプロジェクト、友人との語らい、恋の始まり——すべての良いことにはいつか終わりが来る。「これもいつか終わるんだろうな」と考えながら楽しいひとときを過ごすのは、30歳を前にした私のような人間の性かもしれない。常に砂時計の砂が落ちていくのを見続けているような感覚だ。時間の流れは誰にも平等だ。しかし、その時間をどう感じるかは人それぞれ。『これもいつか終わるんだろうな』と思いながらも、今この瞬間を大切にする。過去の自分を否定せず、かといって執着もせず、ただ前を向いて歩き続ける。砂時計を眺めながらも、その砂で自分だけの城を築いていく。それが生きることの楽しさなのかもしれない。自分の期待に応えられなかった記憶が心に残る。自分で自分にハードルを上げすぎて、それを超えられなかった日々。プロジェクトでの小さなミス、チームでの意見の違い——これらの記憶はなかなか消えない。20代の頃は自分で設定した完璧な基準に届かないことが全てを台無しにするように思えた。しかし今では、それらも人生のグラデーションとして受け入れられるようになった。理想と現実の間にある溝を認め、それでも前に進む勇気が身についた。完璧主義との戦いは今も続いている。コードを書いていて「もっと美しく書けるはず」と何度も書き直す。技術記事を書いたり、読んで「全部理解していないからと次に進めない」と足踏みする。誰からも期待されていないのに、自分だけが自分に無理な期待をかける。この自分との対話は、時に建設的で、時に破壊的だ。他人に期待しすぎない術は身についたが、自分に期待しすぎない術はまだ修行中だ。かつては「なぜ自分はもっとできないのか」と悩んでいた。しかし徐々に、人間には限界があり、すべてを完璧にこなすことは不可能だと受け入れられるようになってきた。自分への期待を下げるのではなく、不完全な自分を認めることで、むしろ心は軽くなった。そして「身の程」を知るようになった。自分の能力や限界への理解が深まるほど、逆に自信を持って胸を張れるようになった。ライブラリを全部理解していなくても、「今は分からないけど調べれば理解できる」という余裕が生まれた。「これはできない」と正直に認めることで、逆に「これならできる」という自信も育つ。自分の限界を知ることは、弱さではなく強さだと気づいた。特に痛感したのは、技術書の「全て」を理解しようとしていた自分の滑稽さだ。分からないページがあると先に進めず、一冊を完璧にマスターしようとして、結局最後まで読めずに挫折することの繰り返し。今なら分かる、必要なところだけを取り入れ、分からないところはいったん保留にして前に進む勇気の大切さを。完璧を目指すあまり、一歩も前に進めなくなるという皮肉。それでも、あの頃の完璧主義が今の技術力の土台を作ったことも確かだ。一つの概念を深く掘り下げ、原理から理解しようとする姿勢。簡単に諦めず、分からないところに何度も立ち返る粘り強さ。非効率だったかもしれないが、その過程で築いた基礎知識と思考の筋力は、今でも私の強みになっている。効率だけを求めていたら、得られなかった深い理解がある。今の「適切なバランス」は、あの頃の遠回りがあったからこそ見つけられたのだ。「大人げない」と言われるのは大人だけだ。だからこそ、時には子供のように新しい技術に夢中になり、全力でコードを書くことも恥ずかしくない。新しいフレームワークを発見して「うおおこれヤバい！」と興奮することも、バグを解決して「よっしゃー！」と雄叫びを上げることも、大切な感情表現だ。感情を抑え込むことが「大人」ではなく、感情と向き合いながらも行動を選択できることが本当の意味での「大人」なのだと分かった。年齢は「小さな枠組み」で「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。若手にもベテランにも学び、「経験が少ない」とも「古い考え方だ」とも思われることを恐れない。いくつになっても成長できると思えるようになったのは、30歳を前にした最大の収穫かもしれない。最も大切なのは、完璧を目指しながらも今この瞬間を楽しむこと。自分で自分を追い詰めるのではなく、時には立ち止まって今日までの道のりを振り返る。砂時計の砂は確実に落ちていくが、だからこそ今この瞬間が尊い。田舎者が見上げる東京の空九州の片田舎から都会へ—その落差は今でも時々現実感を失わせる。自分が歩む道が本当に現実なのか、何かの間違いなのか分からなくなることがある。高校卒業まで過ごした街では、夜になると街灯も少なく、「あそこの交差点では夜一人で歩くな」という暗黙のルールがあった。コンビニまで自転車で20分、映画館は隣の市まで行かねばならない。そんな場所から、突然、光り輝く迷路のような大都会へ放り出された感覚。最初の数ヶ月は毎日が観光気分だった。今では高層ビルのエレベーターで何十階も上がり、窓の外に街を一望できる。駅から会社までの道には世界中の料理が楽しめる店が軒を連ね、夜遅くなっても電車は頻繁に走る。この便利さに未だに慣れない自分がいる。「俺みたいな田舎者がなぜここにいるんだろう」—そう思うことがある。祖父からの電話で「都会は怖くないかい？」と聞かれると、半分笑いながら「うん、まだちょっと怖いよ」と答えてしまう。歩く人の目の冷たさ、文化や人の違い、もしくは自分がおじさんになってこの世の全員が冷たくなったのかもしれない。時々、自分が自分ではないような感覚に襲われる。駅のホームで電車を待っていたり、エレベーターの鏡に映る自分を見たりした時に、「この人は誰だろう？」と思う瞬間がある。それでも最近は変わってきた。かつては圧倒されるばかりだった都会の風景を、自分の可能性として捉えられるようになった。高層ビル群を見上げて「ここまで伸びる可能性が自分にもある」と思えるようになった。多様な価値観や文化に触れ、視野も広がった。おわりに中学17年生である自分。まだまだ成長の余地だらけの自分。それを恥じるのではなく、誇らしく思えるようになった。30歳という節目を迎え振り返ると、「まだ何も始まっていない」という気もする。これからが本番だとも思う。中学17年生としての感性と、30歳のエンジニアとしての経験。矛盾するこの二つの側面が、私という人間を形作っている。大人の顔を持つ中学生も、子供心を忘れない大人も、どちらも本当の私自身だ。複雑で矛盾に満ちた自分をそのまま受け入れ、それを誇りに思える。それこそが、いつまでも成長し続けるための原動力になる。大人になって自分のできないことを目の当たりにして歯がゆさを感じる。「もっと早くこれを知っていれば」と悔やむこともある。でも見方を変えれば、それだけ伸びしろがあるということだ。何でも知っていて、何でもできる人間なんて、それはそれで退屈な人生だろう。常に新しい課題に挑戦し、失敗し、学び続けることこそが、人生を豊かにする。砂時計の砂は上から下に確実に落ちていく。だからこそ、「これもいつか終わるんだろうな」と考えながらも、今この瞬間を大切にしたい。過去の自分を否定せず、執着もせず、前を向いて歩き続ける。「身の程」を知りながらも、少しずつ自分の領域を広げていく。完璧を目指すあまり一歩も前に進めなくなるのではなく、時には「これで十分」と自分を許せる強さも身につけたい。この文章を書いている今も、不安でいっぱいだ。「こんなことを書いて、見られたら恥ずかしい」「こんな風に悩む自分は、弱すぎるんじゃないか」「30歳になっても中学生みたいな考え方をする自分は、ダメなんじゃないか」。そんな声が頭の中でぐるぐる回っている。けれど、そんな弱さも含めて自分なのだと認められるようになってきた。自分との対話も、少しずつ優しいものに変えていきたい。誰かの役に立とうと頑張りすぎて、自分を見失うことも多かった。「良いエンジニア」「良いサラリーマン」であろうとして、本当の気持ちを押し殺してきた。これからは、もう少し素直に、もう少し自分に優しく生きていきたい。「今は分からないけど調べれば理解できる」という余裕を持ちながら、自分のペースで技術を深めていきたい。年齢は「小さな枠組み」で「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。大人のコスプレが上手くなっただけの中学生。それは決して恥ずべきことではない。むしろ、その感覚を大切にしたい。中学生の頃に見上げた空と、今見上げる空は同じなのだから。感情を抑え込むことが「大人」ではなく、感情と向き合いながらも行動を選択できることが本当の意味での「大人」だと分かった。まだまだ成長の余地だらけの自分が晴れやかに歩いていく。ときにはつまずき、立ち止まることもあるだろう。それでも前を向いて、自分らしく生きていく。それが私の「大人になる」ということだ。どんなに時間が経っても、「早く大人になりたいな」と呟いていた中学生の気持ちを忘れないでいたい。ただし今は、「傘を持って外に出る勇気」も持っている。どしゃ降りの雨の中でも、自分の道を歩いていこう。B面なのでwww.amazon.jp他の記事も読んでいただけると嬉しいです。読者になってくれたり、Xをフォローしてくれたりすると、中学生の心がとても喜びます。","isoDate":"2025-05-10T11:53:53.000Z","dateMiliSeconds":1746878033000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"MCP-Use を使っていきます","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/04/024730","contentSnippet":"MCP-Useとは何か？MCP-Use (Model Context Protocol - Use) は、LLM（大規模言語モデル）とMCPサーバーの間の橋渡しをするPythonライブラリです。このライブラリにより、OpenAI、Anthropic、Groqなど様々なLLMプロバイダーのモデルに、Webブラウジングやファイル操作といった外部ツールへのアクセス権を付与できます。github.com環境構築：uvの活用今回はRustベースの高速パッケージマネージャーuvを使って環境を構築します。docs.astral.sh# 仮想環境を作成uv venv# 仮想環境をアクティベートsource .venv/bin/activate.fish  # fishシェル使用時# 必要なパッケージをインストールuv pip install \"mcp-use[dev,anthropic,openai,search]\"uv pip install fastembeduv pip install python-dotenv langchain-openai従来のpipと比較してuvは大幅に高速で、特に複雑な依存関係を持つプロジェクトではその差が顕著です。MCP-Useはさまざまな依存関係を持つため、uvの使用が特に有効です。MCP-Useの基本構造MCP-Useの中核は以下のクラスから構成されています：MCPClient: 設定ファイルからMCPサーバーへの接続を管理MCPAgent: LLMとMCPサーバーを組み合わせてタスクを実行各種アダプター: LLMプロバイダーとMCPサーバー間の変換処理実装例：ウェブ情報取得エージェント今回はMCP-Useを使って、特定のWebサイトから情報を抽出するエージェントを構築します。import asyncioimport osfrom dotenv import load_dotenvfrom langchain_openai import ChatOpenAIfrom mcp_use import MCPAgent, MCPClientasync def main():    # 環境変数を読み込み    load_dotenv()    # 設定ファイルからMCPClientを作成    client = MCPClient.from_config_file(        os.path.join(os.path.dirname(__file__), \"browser_mcp.json\")    )    # LLMを初期化    llm = ChatOpenAI(model=\"gpt-4o\")        # エージェントを作成    agent = MCPAgent(llm=llm, client=client, max_steps=30)    # クエリを実行    result = await agent.run(        \"3-shake.com にアクセスして株式会社スリーシェイクのCEOのxアカウントを教えて下さい\",        max_steps=30,    )    print(f\"\\nResult: {result}\")if __name__ == \"__main__\":    asyncio.run(main())以下、各部分の詳細を解説します。1. MCPClient初期化とその内部構造client = MCPClient.from_config_file(    os.path.join(os.path.dirname(__file__), \"browser_mcp.json\"))MCPClientクラスはMCPサーバーへの接続を管理します。from_config_fileメソッドで設定ファイルから構成を読み込みます。設定ファイルbrowser_mcp.jsonの中身は以下のようになっています：{  \"mcpServers\": {    \"playwright\": {      \"command\": \"npx\",      \"args\": [\"@playwright/mcp@latest\"],      \"env\": {        \"DISPLAY\": \":1\"      }    }  }}この設定は、PlaywrightをMCPサーバーとして使用することを指定しています。MCPClientはこの設定を読み込み、以下の処理を実行します：設定に基づいて適切なコネクタ（この場合はStdioConnector）を作成コネクタを使ってPlaywright MCPサーバーとの通信チャネルを確立初期化処理を実行し、利用可能なツールの一覧を取得内部的には、MCP-Useは非同期処理を多用しており、asyncioを活用した効率的な通信を実現しています。2. LLMの初期化と統合llm = ChatOpenAI(model=\"gpt-4o\")MCP-UseはLangChainとシームレスに統合されており、様々なLLMプロバイダーのモデルを使用できます。今回はOpenAIのGPT-4oを使用していますが、以下のように簡単に切り替えることも可能です：# Anthropicのモデルを使用する場合from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")# Groqのモデルを使用する場合from langchain_groq import ChatGroqllm = ChatGroq(model=\"llama3-8b-8192\")MCP-Useの内部では、LangChainAdapterクラスがLLMとMCPサーバー間の変換処理を担当し、ツールの記述をLLMが理解できる形式に変換しています。3. MCPAgentの作成と実行agent = MCPAgent(llm=llm, client=client, max_steps=30)MCPAgentクラスは、LLMとMCPクライアントを組み合わせてタスクを実行するための中核コンポーネントです。主なパラメータは：llm: 使用するLLMモデルclient: MCPクライアントインスタンスmax_steps: エージェントが実行できる最大ステップ数max_stepsパラメータは特に重要で、タスクの複雑さに応じて適切な値を設定する必要があります：- 単純な情報検索: 5-10ステップ- 複数ページの探索: 15-20ステップ- 複雑な操作: 25-30ステップ4. タスク実行の内部処理result = await agent.run(    \"3-shake.com にアクセスして株式会社スリーシェイクのCEOのxアカウントを教えて下さい\",    max_steps=30,)agent.run()メソッドが呼び出されると、以下の処理が実行されます：指定されたクエリをLLMに送信し、実行プランを生成LLMが適切なツールを選択し、その実行をリクエストMCPクライアントがツールのリクエストをMCPサーバーに転送MCPサーバーがツールを実行し、結果を返す結果をLLMに返し、次のステップを決定最終的な回答が生成されるまで、ステップ2-5を繰り返す内部的には、この処理はMCPAgent.run()メソッド内の_agent_executor._atake_next_step()メソッドで実装されています。","isoDate":"2025-05-03T17:47:30.000Z","dateMiliSeconds":1746294450000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"「頑張ってるので安心」から脱する","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/02/191144","contentSnippet":"soudai.hatenablog.comそーだいさんの「頑張らなくてもいいから、成果で応えよう」という記事を読み、「頑張ること」について改めて考えさせられた。「頑張る」の幻想と私たちの関係日本文化においてというか自分が育ってきた環境では「頑張る」という言葉には特別な地位があった。子どもの頃から「頑張れ」と叱咤激励され、「頑張ります」と答えることが社会的な美徳や道徳的な行いとされてきた。多くの場面で「頑張ります」と宣言するだけで、一時的に評価されるか、少なくとも批判を免れる魔法のような効果を持っている。しかし、この「頑張る」という概念を現場で聞くと自分も奇妙だと感じる。専門的な仕事に対する報酬は、結局のところ労力の投入量ではなく、生み出された価値に対して支払われるものだ。高額な費用を支払う依頼者が期待するのは、徹夜して疲れた顔をすることではなく、問題解決の価値を提供することだろう。「努力」と「成果」の非対称性ビジネスの世界では、しばしば「依頼者と受託者の利害不一致」が問題になる。経済学では「エージェンシー問題」と呼ばれるこの現象は、仕事を頼む側と引き受ける側の間に生じる情報や目的の不均衡から発生する。例えば、受託者は「一生懸命頑張っている」姿を見せることで、依頼者に「価値ある仕事」をしているという印象を与えられる。しかし、依頼者が本当に必要としているのは、その問題が解決されることであって、受託者の頑張りそのものではない。受託者が自分の興味や都合を優先して「頑張る」ことで、依頼者が必要としない複雑な作業に時間を費やすこともある。これもエージェンシー問題の一例だといえる。このとき「頑張っています」という言葉は、実は成果を出せない責任から自分を守る防御機制になっていることがある。「精一杯やりました」という免罪符を先に用意しているようなものだ。プロフェッショナルは、このような情報の非対称性を利用するのではなく、依頼者の本当のニーズを理解し、それに応える成果を出すことで信頼を勝ち取る。ja.wikipedia.org個人の「頑張り」と本質的価値では個人として「頑張る」ことに価値はないのだろうか？ここで重要なのは、「頑張る」という言葉に対する冷笑的な態度と、本質的な「頑張り」の価値を区別することだ。SNSやぎむきょー時代は「頑張り」を馬鹿にする風潮も見られるが、それは本来の議論とは異なる。正直に告白すると、学生時代の私自身も「頑張っている人」を冷笑していた時期があった。努力している人を見て「あんなに必死になって」と馬鹿にしていたのは、おそらく自分の怠惰や無為を正当化するための防衛機制だったのだろう。SNSで見られる「頑張り」への皮肉や揶揄も、多くの場合、同様の心理から生まれていると思われる。しかし、本稿で論じているのはそうした冷笑とは全く異なる。単なる努力否定論ではなく、むしろ「頑張り」の本質と方向性についての考察であり、努力そのものの価値を問い直すものである。ここで大切なのは、無意味な労力を省く知恵と、本当に必要な部分への集中という、より高度な「頑張り」の形だ。もちろん、個人の成果、成長や技術向上のためには「頑張り」が必要だ。しかし、その「頑張り」は闇雲に時間や労力を投入することではなく、最も効果的な方向に集中させることが重要だろう。そして、この「方向性を見極める努力」こそが、実は最も価値のある「頑張り」なのだ。優れた個人の強みは、複雑な問題を単純化する能力にある。たとえば、長時間かけて解決できる問題を短時間で実装できれば、それはただの時間節約ではなく、将来的な労力やリスクの削減にもつながる。こうした「頑張らない工夫」のために費やす知的努力こそが、実は最も価値のある「頑張り」なのだ。つまり、見た目の労力と実質的な価値創造は必ずしも比例しないということである。何をするかを決めることと同じくらい、何をしないかを決めることが重要だ。プロフェッショナルは、あらゆることに対して「Yes」と言うのではなく、価値の低い活動には意識的に「No」と言う勇気を持っている。時間とエネルギーは有限だからこそ、本当に重要なことに集中するために、何かを捨てる決断が必要になる。この「選択する」という行為自体が、実は高度な「頑張り」を要するものだ。大企業や大規模な組織に比べて、個人や小さな組織が持つ強みの一つは、無駄な儀式的活動を省略できることにある。形式的な定例会議や不必要な報告書作成に時間を費やす代わりに、本質的な価値を生み出す活動や意思決定に集中できる自由がある。これは実は大きな競争優位性となり得る。この「本質」を見極める洞察力を養うこともまた、「頑張る」べき重要な領域なのだ。起こる可能性のあることは、いつか実際に起こる。「頑張る」という抽象的な概念から脱却するためには、具体的な仕組みを設計する思考へ転換する必要がある。努力の量よりも、その方向性と持続可能性が重要だ。問題の解決に徹夜で取り組むことを否定するわけではないが、優れたエンジニアは、より本質的には問題が再発しないような仕組みの構築に力を注ぐ。例えば、作業を手動で何度も「頑張る」のではなく、自動化の仕組みを整備する。毎回の業務で時間をかけて「頑張る」のではなく、再利用可能なテンプレートやガイドラインを整備する。問題が起きるたびに対処法を「頑張って」思い出すのではなく、解決策を体系化したマニュアルを作成する。「人間が頑張る」システムから「仕組みが支える」システムへの転換が、価値を生み出す。とにかく仕組み化――人の上に立ち続けるための思考法作者:安藤 広大ダイヤモンド社Amazon360度評価の落とし穴多くの企業で導入されている360度評価は、一見公平に見えるが、実はこの「頑張り」の価値観を強化してしまう側面がある。同僚や部下からの評価では、実際の成果や生み出した価値よりも「頑張っているように見える」人が高く評価される傾向がある。例えば、遅くまでオフィスに残っている人、頻繁にメッセージや進捗報告を送る人、会議で積極的に発言する人、多くのタスクを抱えて「忙しそう」に見える人は「熱心に働いている」という印象を与えやすい。しかし、こうした「頑張っている姿」は、必ずしも組織や顧客にとっての価値創造に結びついているとは限らない。むしろ静かに効率的に成果を出している人が、「あの人は楽をしている」と誤解されることすらある。見た目の「頑張り」で評価される環境は、本来の価値創造を歪める要因となる。この歪みが組織全体の非効率を生み出し、真に重要な成果よりも「頑張っている姿勢」が優先される文化を強化してしまうのだ。「頑張らない」の誤解を解く「頑張らない」という言葉を聞くと、「怠けている」「熱意がない」という印象を持つ人も多いだろう。しかし本質は「無駄な労力を費やさない」ということだ。優れたプロフェッショナルとは、最小限の労力で最大限の成果を出す人のことであり、闇雲に時間や労力を投入する人のことではない。例えば、ソフトウェア開発なら、少ない時間で短く洗練されたコードで同じ機能を実現できる人のほうが、多くの時間を使って冗長で複雑なコードを書く人よりも高い評価を受けるべきだ。これは他の職種でも同様だ。営業担当者が100件の見込み客に電話するよりも、10件の有望な見込み客に集中して高い成約率を出す方が価値がある。デザイナーが何十もの案を作るよりも、ユーザーの本質的なニーズを捉えた1つの優れた案を作る方が価値がある。マネージャーが長時間のミーティングを主催するよりも、短時間で明確な意思決定と方向性を示せる方が価値がある。限られた時間とエネルギーをどう使うかが、プロフェッショナルの条件だ。多くの場合、「頑張らない」と見られる人ほど、実は効率的な方法論や再利用可能な仕組みを作り出すことで、生産性を高めている。NINE LIES ABOUT WORK 仕事に関する9つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon「頑張り」の再定義個人として「頑張る」ことを完全に否定するわけではない。むしろ、その意味を再定義する必要がある。「頑張る」とは、ただ長時間働くことや疲れ果てることではなく、最も効率的な方法を見つけるために思考し、試行錯誤することかもしれない。「頑張ります」と言う代わりに、「この売上低下の問題を解決するために、まずデータを分析し、次週までに具体的な改善策を提案します」のように具体的なコミットメントを示すほうが建設的だ。抽象的な精神論ではなく、具体的で測定可能なアクションにフォーカスすることで、本当の意味での価値が生まれる。これは実は「頑張らない」ように見えて、もっとも「頑張るべき」部分かもしれない。人生は、運よりも実力よりも「勘違いさせる力」で決まっている作者:ふろむだダイヤモンド社Amazon「頑張ってるので安心」からの解放「頑張っているので安心してください」という言葉の裏には、「結果が出なくても責めないでください」という暗黙の訴えがある場合が多い。しかし、このような思考パターンからは脱却する必要がある。自分自身に対しては、「これをやって、この結果を出します」という具体的なコミットメントへと転換することが、ちゃんとした価値を生み出す第一歩だろう。ただし、この考え方を他者に向けて適用する際には注意が必要だ。相手の背景や文脈、置かれた状況を完全に理解できているわけではない。「頑張り」ではなく「成果」を求めることは理にかなっているが、相手の環境や制約条件、直面している課題の複雑さを把握せずに一方的に求めることは、非常に危険である。むしろ、他者との関係においては、まず相手の状況を理解し、適切なサポートや環境づくりを考えることが先決だ。また、自分が生み出した「価値」が適切に評価されていないと感じるなら、それは単に評価システムの問題ではなく、組織や上長、周囲の人々との間に「価値基準の違い」が存在している可能性がある。自分が重視する価値と、組織が求める価値が異なっていれば、どれだけ成果を出しても評価されにくい。このミスマッチに気づくことは、自分のキャリアを考える上で非常に重要なポイントになる。自分の価値観に合った環境を選ぶか、あるいは組織の価値基準を理解した上で自分の貢献の方向性を調整するか、選択が必要になるだろう。最終的に評価されるのは「頑張った過程」よりも「生み出した価値」だ。この現実を受け入れ、「頑張っているので安心」という幻想から脱することが、個人としての成長への本質的なステップなのかもしれない。もうそろそろ、30歳になるのでそういう事も考えます。追記: \"本質的な価値\"と\"価値基準の違い\"本稿では「本質的な価値」と「価値基準の違い」という概念を提示してきたが、果たしてこれらは矛盾しないのだろうか。実際のところ、絶対的な「本質的価値」など存在するのだろうか。冷静に考えれば、所謂誰かが言っている「本質的価値」とは常に文脈依存であり、普遍的なものではない。我々が価値と呼ぶものは、結局のところ特定の社会や組織、個人の視点から定義されたものに過ぎない。人間として普遍的な「本質的価値」を探すならば、それは生命体としての存続と尊厳、心身の調和、そして精神的充足感以外には基本的に見当たらないのではないだろうか。人間という生命体にとって生物学的な生存と精神的な均衡が確かに基礎的な価値だが、それを超えた「価値」は全て社会的に構築されたものだ。企業が求める「価値」は利益最大化かもしれないし、NPOが重視する「価値」は社会貢献かもしれない。個人が大切にする「価値」は自己実現かもしれないし、家族との時間かもしれない。つまり、「本質的価値」を絶対視することこそが、新たな幻想を生み出す危険性をはらんでいる。ある組織で評価される「価値」が、別の組織では全く評価されないこともあるのだ。重要なのは、自分が属する環境で何が「価値」とされているかを正確に理解し、それが自分の信じる「価値」と一致するかを見極めることだろう。一致しない場合、二つの選択肢がある。一つは環境を変えること、もう一つは自分の貢献の方向性を調整することだ。どちらが正しいというわけではなく、各自の状況や志向に応じた選択が必要になる。結局のところ、「頑張る」という曖昧な概念から脱却し、具体的な成果や貢献にフォーカスすることは重要だが、その「成果」や「貢献」自体も絶対的なものではなく、常に特定の文脈の中で評価されるものだということを忘れてはならない。生存と心身の調和を超えれば、あらゆる「価値」は相対的なものであり、その点を認識することこそが、現実的なキャリア構築や人間関係の基盤となるのではないだろうか。あと、「頑張ってるので安心」から脱してもそれでも頑張るしかないのが凡人の辛いところ。","isoDate":"2025-05-02T10:11:44.000Z","dateMiliSeconds":1746180704000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" 20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/02/045932","contentSnippet":"はじめにああ、ついに来てしまった。30歳という、人生の大きな節目。私は今、20代最後の週を迎えている。誰だ？清々しい気持ちとか言ってたやつは⋯。正直に告白しよう。この文章は、決して効率的な読み物ではない。投資対効果という観点では、あまり賢明とは言えない時間の使い方かもしれない。同じ時間で技術書を読むなり、コードを書くなり、より直接的な成長に繋がる活動はたくさんある。それでも、もしかしたらこの言葉が、誰かの心に小さな波紋を投げかけるかもしれない。そんな期待を胸に、筆を進めていきたい。思えば20代のはじめの私は、まるで迷宮に迷い込んだ勇者の気持ちだった。10代の頃は、親や先生が道標となり、友人たちと同じペースで歩んでいけば良かった。進学、部活、受験―目標は明確で、努力の方向性も定まっていた。しかし20代に入ると、そんな心地よい\"レール\"は突如として途切れる。誰も正解を教えてくれない。「これが正しい」と太鼓判を押してくれる存在もいない。ただ、進むべき道を必死に探しながら、時に立ち止まり、時に回り道をしながら、それでも確かに前に進んでいく―そんな日々が始まった。人生という名のRPGを、右も左もわからないまま必死にプレイしていたのだ。10代では想像もつかなかった選択を、次々と迫られる。仕事とプライベートのバランス、収入の使い道、人間関係の距離感。全てが手探りで、時に不安に押しつぶされそうになる。それでも、その不確かさの中に、どこか自由な喜びも感じていた。なぜなら、選択肢の多さは、可能性の広がりでもあったから。そんな中、避けられない現実と向き合うことになった。私は勇者ではないのだと。周囲の中でも特別な才能があるわけでもなく、ずば抜けた成績や実績を残せるわけでもない。でも、それを認めたくなくて、必死に目を背けていた。「努力すれば、きっと追いつける」「まだ自分の才能は眠っているだけかもしれない」―そんな言い訳を繰り返しながら、葛藤の日々を過ごしてきた。時には焦りと不安で夜も眠れず、必死に頑張る時期もあれば、全てが面倒になってゲームやアニメに逃避する日々もあった。いつも一生懸命だったわけではない。むしろ、怠惰に過ごす時間の方が長かったかもしれない。それでも、時折襲ってくる焦りに追い立てられるように、また必死に頑張る自分がいた。世界を救うような大きな使命など、私には与えられていない。世間を変えられるような力もないし、周囲に大きな影響を与えられるわけでもない。それどころか、自分自身すら思い通りに変えられない。毎日の生活で精一杯で、人並み以下にしかできないこともたくさんある。20代半ばにして、ようやくこの現実と正面から向き合えるようになった。最初は、この事実を受け入れることに大きな喪失感と無力感を覚えた。でも、それは意外にも解放感をもたらしてくれた。完璧でなくていい。特別な存在でなくていい。勇者ではなくとも、この物語の主人公は紛れもなく私自身なのだ。そして、その「私の人生の物語」には、きっと誰にも真似できない価値があるはずだと、少しずつ信じられるようになっていった。これから私が語るのは、輝かしい成功物語でも、圧倒的な成果を上げた人間の教訓でもない。ごく普通の一人の人間が、試行錯誤しながら過ごした20代でやってよかったことの記録です。これは同時に「20代でやっておけばよかったこと」の裏返しでもあります。ここで重要な前提を述べておきたい。この文章は、一エンジニアとしての私個人の経験と、そこから得られた主観的な気づきを綴ったものです。ありとあらゆるバイアスがあります。それぞれの人生には、それぞれの文脈があり、それぞれの正解があります。ここで述べる内容は、普遍的な真理ではなく、一つの参考事例として受け止めていただければと思います。記憶は時に曖昧で、主観的なバイアスは避けられない。しかし、できる限り誠実に自分の経験を共有することで、「こういう道もある」という一つの可能性を示すことはできるだろう。実は、この文章を書き進めていく中で、私自身の考えも少しずつ変化していった。思い出を言葉にすることで、当時は気づかなかった発見があり、新たな気づきが生まれ、気がつけば予想以上の文章量になってしまった。効率的とは言えないこの物語を通じて、私の20代という時間の意味を、あなたと一緒に考えていけたらと思う。このブログは複数の項目から構成されており、かなりのボリュームがあります。全体を順序通りに読む必要はなく、目次から関心のあるトピックを選んでお読みいただくことをお勧めします。各項目は独立した内容になっていますので、ご自身の興味や時間に合わせて自由に読み進めていただければと思います。（通読はすべての著者の願いだが、それは読者にとって必ずしも最善とは限らない）「良い文章」とは何でしょうか。私は、読了後に残る満足感と読むために費やした労力のバランスが重要だと考えています。ただ単に分かりやすいだけでなく、読者の想像力を刺激し、余白を残すことで深い共感を生み出すものが良い文章ではないでしょうか。このブログが皆様にとって「良い文章」となるかどうかは読者それぞれの感じ方によって異なるでしょう。もし内容に共感していただけたり、あるいは異論がありましたら、ぜひスクリーンショットを撮って、感想やコメントを添えてSNSで共有していただけると幸いです。皆様の反応や議論が広がることで、さらに多くの方々にこのブログが届くことを願っています。このブログが良ければ読者になったり、nwiizoのGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめに01. 挑戦し、失敗から学ぶ。失敗という贈り物唯一絶対の失敗とはちゃんと失敗する能力という幻想小さな失敗の重要性完璧主義の罠根拠なき一歩を踏み出す勇気恥をかく勇気回り道が育む固有の強さ失敗から築く財産「試練」に誠実に向き合う失敗から学ぶ成長の道失敗しない方法は挑戦しなければいい02. 専門性を見つけ、情熱を注ぐ。可能性との向き合い方全てを得ることの幻想焦らずに目の前のことをちゃんとやる問題解決を学ぶ深さを求める決断専門性がもたらすもの視野の広がり配られたカードとの向き合い方お前しかお前を救えない競争から差別化へ答えは時代によって変化する情熱も有限である人はずっと同じ量で頑張り続けられるわけではない過去の宣言に縛られず、新しい道を選ぶ勇気選択は自由だが責任が伴う03. 一流に触れ、習慣を真似る。一流への誤解やらないことの重要性本質を見抜く問いを立てる力問いが形になるまでの道のり有効な問いの特徴核心を見極める力問いかける能力を高めるために違和感を感じ取る形を写すな、本質を活かせ身近にある機会と、その罠実践からの学びを重視する習慣から学ぶ当たり前のレベルをあげるだけ習慣は複利で伸びる04. 仲間を作り、友達を作り、切磋琢磨する。孤独な戦いから仲間との成長へ会社を超えた絆異なる視点との出会い切磋琢磨の喜びコミュニティとの出会い集まりを主催する価値視野を広げる出会い自分が付き合いたい人間に自分自身がなる正義と悪の向こう側にあるもの人間関係を選ぶ勇気を持つネガティブな会話から距離を置く勇気宝物としての友情自分らしくあれ05. プライベートをちゃんとやる。恋愛をしてくれ。後回しにしがちな恋愛失恋から学んだこと恋愛が教えてくれたことプライベートの価値失恋の意味人生の豊かさとはそのままのあなたを好きになってはくれない見た目は内面の表現恋愛は失敗するものパートナー選びの落とし穴人生の意味を考える06. 挨拶と礼儀をやる。そして、とある思い込みもしくは勘違いについて素直であれ生意気であれ生意気さのおわり忙しさと礼儀当たり前の実践見た目を良くする人間関係の本質変化の実感人目がないときこそ、正しく行動せよ様々な文章を書ける表現力を磨く言葉は必ず自分に戻ってくるいい人を目指すこと07. 質問力を磨く。そして、会話を楽にする本質を見失っていた日々力まない会話の秘訣会話のキャッチボール自然な質問の流れ沈黙を恐れない勇気敬意から生まれる言葉背景知識が会話を豊かにする相手を認める対話相互成長の機会対話と学びのバランス対話が広げる可能性対話の場を意識的に作るこれからの時間の使い方対話力を高める実践対話の価値を再認識する08. 自分を知る。そして、才能を磨く。自分を知ることの難しさ内省の時間を作る変化を恐れない「私は」という檻を壊す標準化された道という比較的に自分にとって大きな罠思い通りにならない現実と、「今まで頑張った」の呪縛から解放される勇気本質的な「楽しさ」を見つけるモチベーションの罠を避ける「勉強したくない」という思いと向き合う感情のマネジメント遊び心を失わない他者の視点を借りる他者の評価に振り回されない環境に応じた自己の活かし方社会という舞台で演じる役割最適な努力のポイントを見つけるフィードバックを活用する弱みと向き合う自己否定と向き合う強さ自分で考え、自分で決める真摯な自己との対話才能を育む土壌づくり09. メンターを見つけ、学び方を学ぶ。メンターとの出会いあの人もこの人もメンター学びの多様性異なる価値観から学ぶメンターをクビにしろ劇的な変化を求めるな、幻想を抱くのはもうやめろ。学び続ける姿勢学びの本質自分のことを棚に上げる矛盾完璧を装わない誠実さと信頼の両立自分より優秀だと思って接し、自分より繊細だと思って言葉と行動を選ぶ自分の知識の穴と向き合う教えることで学ぶ心の距離感を大切に「教える」から「引き出す」へ失敗から学ぶ機会を奪わないあなたもメンターになる日10. 読書をする。そして、知識を実践に移す。読書とプログラミング読書の多様性を楽しむ読書のアプローチと戦略現代社会における読書の価値積ん読との向き合い方理解のプロセス批判と共感のバランス知識の源泉を再考する自分に合った読書選択と戦略個人の知識管理システムを構築する読書を通じた孤独と共有の調和知識の実践という課題読書の多様な目的と効用継続的な実践の重要性知的好奇心という贈り物11. 時間とお金と健康を大切にする。そして、関係性を育む。時間という最も貴重な資産お前を守れるのはお前だけ暇だと不幸になるお金という可能性の触媒複利を侮るな欲には終わりがない消費の本質を見抜く力瞑想を実践せよ健康という揺るぎない土台体力が全てを覆す睡眠と食事の重要性姿勢と身体への意識集中と休息のリズムを作る本質的な休息の重要性「快楽の奴隷」になるなデジタルデトックスの必要性関係性という最大の財産「怒り」を手なずけよ言葉にするな体現しろなにかに特化するということはなにかを失うわけではない12. 趣味を持つ。そして、新しい世界を広げる。価値観の多様性を認識する複数の世界を持つことの意味自分が変えられないことに注力しない主体性を持ち、手の届く範囲から変えていく純粋なコミュニケーションの場として視野の広がりと深さ仕事との向き合い方趣味としての技術探求趣味がもたらす自己受容と成長のバランスコミュニティを育てる喜び人脈づくりの罠新しい可能性への扉おわりに01. 挑戦し、失敗から学ぶ。私たちはよく失敗を恐れる。あの恥ずかしさ、あの後悔、あの痛み——誰もが避けたいと思うもの。でも......考えてみれば、失敗は恐れるべきものではなく、人生からの贈り物です。失敗から学ばなければ、同じ間違いを何度も繰り返すだけ。「でも失敗は痛いよ！」と誰もが思う。もちろん......そうです。でも痛くない失敗なんて、本当は失敗じゃない。本気で挑戦した失敗には価値がある。一方で、中途半端な努力の失敗は時間の無駄になりかねない。実は、唯一の絶対的な失敗とは、何も挑戦せずリスクを避けること。海に出なければ船が沈む心配はないが、新しい大陸も発見できない。「失敗を美化しすぎじゃない？」という声が聞こえてきそうです。確かに......失敗そのものを目指すのは賢明ではない。だが失敗を過度に恐れるあまり、動けなくなることの方が怖い。二度と同じ過ちを繰り返さないという誓いは、失敗という土壌からこそ生まれる最も強い種。小さな失敗から学び、少しずつ賢くなっていく——それが成長というものだろう。失敗という贈り物私が20代で学んだ最も価値ある教訓の一つは、失敗は恐れるべきものではなく、人生からの贈り物だということでした。当時は気づきませんでしたが、私の人生を大きく変えた転換点は、ことごとく失敗体験でした。そして、その失敗の後に感じた悔しさこそが、私を前に進める最大の原動力となっていたのです。具体的な失敗の記憶は、今でも鮮明に残っています。新人時代、重要なシステムの本番環境で設定ミスを犯し、サービスが2時間停止。顧客に多大な迷惑をかけ、深夜まで対応に追われました。中堅となってからは、大規模プロジェクトの工数見積もりを誤り、チーム全体に過度な負荷をかけてしまいました。リードエンジニアとして初めて任されたリリースでは、基本的なテスト漏れにより本番環境でクリティカルなバグが発生。そして、部門の代表としてプレゼンテーションを行った際には、準備していた資料が聴衆のニーズと完全に噛み合わず、冷ややかな視線の中で必死に言葉を紡ぎました。これらの失敗は、当時は耐えがたい苦痛でした。しかし、それぞれの失敗が、確実に私を変化させてくれました。システム障害の経験からは、本番環境における変更管理の重要性と、障害発生時の迅速な対応プロセスを学びました。見積もりの失敗からは、プロジェクトマネジメントにおけるリスク管理の本質を理解しました。リリース時のバグからは、品質管理における網羅的なテスト設計の重要性を痛感しました。プレゼンテーションの失敗は、相手のニーズを深く理解することの大切さを教えてくれました。唯一絶対の失敗とはこの章に、重要な視点を一つ加えたいと思います。それは、「唯一の絶対的な失敗とは、何も挑戦せずにリスクを避けることだ」ということです。大事なのは、何本ホームランを打つかではなくて、何回バッターボックスに立つかだと思います。私たちは往々にして、失敗を恐れるあまり、挑戦する機会そのものを逃してしまいがちです。新しいプロジェクトへの参加を躊躇したり、難しい課題から目を背けたり、責任ある立場を避けたり。その瞬間は安全な選択のように思えます。しかし、それは実は最大の失敗かもしれないのです。なぜなら、挑戦しないことを選択した時点で、成功の可能性もまた失われてしまうからです。失敗して学ぶチャンスさえも、自ら手放してしまうことになります。物事には時間がかかり、たくさんの失敗、たくさんの黒星、たくさんの経験が必要なのです。この「何もしない」という選択こそが、実は最もリスクの高い選択なのです。ここで重要な気づきがあります。「成功」と「失敗」は、実は私たちが思うほど明確に区別できるものではありません。例えば、プロジェクトが予定通りリリースできたとしても、その過程でチームが疲弊してしまえば、それは本当の意味での成功と言えるでしょうか。逆に、一時的な失敗と思えた出来事が、長期的には組織に重要な学びをもたらすこともあります。つまり、成功と失敗は、時間軸や観点によって、その評価が大きく変わりうるのです。短期的な失敗が長期的な成功の礎となることもあれば、一時的な成功が後々の足かせとなることもあります。特に技術の世界では、この曖昧さを理解し、受け入れることが重要です。私も何度か、このような「消極的な失敗」を経験しました。技術的な挑戦を避け、安全な実装方法に逃げたことで、後々より大きな技術的負債を抱えることになったり。チームのリード役を断ったことで、貴重なマネジメント経験の機会を逃してしまったり。振り返ってみると、これらの「挑戦しなかった失敗」の方が、挑戦して失敗した経験よりも、より大きな後悔として心に残っているのです。だからこそ、重要なのは成功か失敗かの二元論的な評価ではなく、そこからどれだけの学びを得られるかなのです。すべての経験を、変化のための機会として捉える視点を持つこと。それこそが、大切だと思います。ちゃんと失敗する「いつかやりたい」「機会があれば」「もう少し準備ができてから」。こうした曖昧な言葉は、実は行動を先送りにする言い訳に過ぎません。期限が定まっていないプロジェクトや目標は、往々にして実現されないまま時間だけが過ぎていってしまいます。本気の失敗には、必ず期限という裏付けが存在します。なぜなら、期限を設定することは、それだけの時間と労力を投資する覚悟を決めるということだからです。逆に、期限を設定しない挑戦は、往々にして中途半端な結果に終わってしまいます。私の経験では、「今日中に終わらせる」「2週間でなんとかする」「3ヶ月以内にこの技術を習得する」「半年後までにこのプロジェクトを完遂させる」といった具体的な期限を設定することで、行動の質が大きく変わりました。期限があることで、日々の選択に優先順位が生まれ、無駄な迷いが減り、より集中した取り組みが可能になったのです。しかし、ここで重要な注意点があります。期限を設定することは、闇雲に急ぐということではありません。むしろ、限られた時間の中で最大限の効果を得るために、より戦略的に行動する必要性が生まれるのです。本気でやった失敗には価値がありますが、それは十分な準備と計画に基づいた失敗でなければなりません。逆に、本気でやっていない失敗は、何も挑戦しないよりも質が悪いと言えます。なぜなら、それは貴重な時間とリソースを無駄にするだけでなく、「やってみた」という誤った安心感を生んでしまうからです。中途半端な挑戦は、むしろ本当の挑戦から私たちを遠ざけてしまう危険性があるのです。能力という幻想私たちは失敗の原因を探るとき、よく「能力不足」という答えにたどり着きます。計算問題ができなければ「計算力がない」、アイデアが出なければ「創造力が足りない」と考えます。記憶力、問題解決力、論理的思考力、コミュニケーション力といった「力」という言葉は日常でもよく使われています。しかし、失敗は単純に「能力」だけの問題ではありません。能力と呼ばれるものは、実は異なる状況（文脈）の間に存在するものです。同じ「能力」を持つはずの人でも、場所や状況が変われば結果も変わります。例えば「プレゼン上手」と言われる人も、聴衆や場所、テーマが変われば急に話せなくなることがあります。これは「能力」が固定的なものではなく、人と環境の関係の中で形作られるからです。失敗から学ぶには、抽象的な「能力」にこだわるよりも、具体的な状況に目を向けるほうが役立ちます。「なぜこの状況でうまくいかなかったのか」「どんな環境だとうまくいくのか」—こうした問いのほうが、成長につながるでしょう。成長とは、様々な状況に対応できるようになること。それこそが、失敗から学ぶときに大切なことです。小さな失敗の重要性ここで重要な気づきがあります。失敗は、大きければ大きいほど良いわけではありません。むしろ、小さな失敗や計画の修正を日常的に重ねていくことこそが、成長をもたらします。大きな失敗は時として致命的なダメージとなり、組織や個人の信頼を大きく損なう可能性があります。一方、小さな調整なら、すぐに修正でき、その学びを即座に次の行動に活かすことができます。例えば、1日の業務計画を立てて、予定通りに進まないことは日常的に起こります。最初は計画が崩れることにストレスを感じていましたが、次第にその状況から学び、より現実的な見積もりができるようになってきました。また、突発的なタスクへの対応力も身についてきました。日々の計画と実践、そして修正のサイクルを通じて、着実に前進していくことができます。重要なのは、小さな調整を恐れずに行い、最終的な成果を出せているかどうかです。このような小さな失敗と修正の積み重ねが、確実にスキルの向上と業務の効率化につながっていきました。完璧主義の罠会社は若者たちに貴重な「失敗する権利」を与えてくれます。 これは決して当たり前のことではありません。経験も実績もない若者に、機会を提供してくれるのです。多くの若手エンジニアが直面するのは「失敗への恐れ」と「恥ずかしさという感情」です。私たちが本当に恐れているのは、失敗そのものではなく、その失敗に対する他者の評価なのです。 「失敗したら何と思われるだろう」「信頼を失ってしまうのではないか」「能力不足だと判断されるのでは」「恥ずかしい思いをするのでは」。こうした不安が、行動の足かせとなっています。私の場合、新人時代に任されたタスクの難易度が徐々に上がっていくことに不安を感じ、完璧な準備ができるまで着手を躊躇することがありました。技術書を読み込み、すべての可能性を検討し、完璧な設計を目指そうとしました。しかし、最初から完璧なものなど存在しないのです。 どんな優れたシステムも、最初は不完全な形から始まり、改善を重ねて変化していきます。完璧主義に陥りがちな私たちが忘れてしまうのは、「上手く行かなくても良い、それが個性になる」ということです。誰もが同じように成功する必要はありません。むしろ、つまずき方、失敗の乗り越え方、そして不完全さとの向き合い方こそが、かけがえのない個性を形作っていくのです。完璧に見える人の裏には、無数の失敗と試行錯誤があります。その過程にこそ、あなただけの物語があり、他の誰にも真似できない価値があるのです。完璧主義は私たちの可能性を縛る鎖となりやすいのです。準備が不完全だからと始めないのは、最大の失敗かもしれません。恥ずかしい思いをしたくないからと挑戦を避けるのは、最大の機会損失かもしれません。 完璧な準備を目指して立ち止まっている間にも、技術は進化し、環境は変化し、人々の価値観は移り変わっていきます。適切な準備とは、失敗の可能性を認識しつつも、それに対処できる最低限の態勢を整えること。他者の評価を気にするあまり、機会を逃してしまうのは、本当の意味での失敗です。完璧を目指すがために挑戦を躊躇するのではなく、不完全でも前に進む勇気。それを支えるのは、「恥をかいても構わない」という覚悟です。根拠なき一歩を踏み出す勇気人生は完璧な準備が整うまで待ってはくれません。 そして時には、納得できる理由がなくても一歩を踏み出す勇気が必要です。すべての疑問に答えを出し、すべての不安を解消してから行動しようとする姿勢は、しばしば私たちを停滞させます。「もう少し調べてから」「もっと確信が持てるようになってから」と先延ばしにしているうちに、貴重な機会は次々と過ぎ去っていきます。時には、論理的な説明ができなくても、直感に従って行動することが正しい選択となることがあります。完全に納得してからでは遅すぎることも少なくありません。むしろ、不完全な情報の中でも決断し、行動しながら学び、軌道修正していく柔軟さこそが、変化の激しい現代社会では価値を持ちます。適切な準備とは、失敗の可能性を認識しつつも、それに対処できる最低限の態勢を整えること。他者の評価を気にするあまり、自分の成長の機会を逃してしまうのは、本当の意味での失敗です。完璧を目指すがために挑戦を躊躇するのではなく、不完全でも前に進む勇気。それを支えるのは、「恥をかいても構わない」という覚悟です。恥をかく勇気「恥をかく勇気」は特権でも、若さの特典でもありません。それは、年齢や立場に関係なく、私たち一人一人が持つことのできる心持ちなのです。他人は、あなたが思うほどあなたの過程のことを見ていません。 誰もが自分の人生や課題で手一杯なのです。あなたの小さな失敗や恥ずかしい瞬間など、翌日には忘れられてしまうかもしれません。むしろ、失敗を恐れて何も挑戦しない姿、恥ずかしさから逃げ続ける態度の方が、周囲の印象に残るものです。なのできちんとアウトプットして下さい。最初から完璧にこなせる人などいません。 優れたエンジニアでさえ、新しい技術に挑戦する際には初心者として学び直します。大切なのは、失敗しても立ち直れる計画を持つこと。そして、分からないことを恥ずかしがらずに質問できる勇気なのだと学びました。ときには、周囲から見ると意味不明に思えるような勇気も必要です。理屈では説明できない「とにかく一歩踏み出す」という無謀にも見える決断が、予想もしない道を切り開くことがあります。合理的な判断だけでは見えてこない機会や可能性に出会うには、時に「無理やり」とも思える一歩を踏み出す勇気が不可欠なのです。後から振り返ると「あの時なぜあんな決断ができたのだろう」と自分でも不思議に思うような行動が、人生の転機となることは少なくありません。「恥をかくこと」を恐れるあまり、チャレンジする機会を失うのは、本当の意味での損失なのです。 失敗してもまた立ち上がる覚悟を持ち、恥ずかしい思いをしても前に進む勇気を持つことです。「恥をかく勇気」は、エンジニアとして変化し続けるための永遠の武器 となりうるのです。分からないことを素直に質問できる。助けを求められる。失敗を正直に報告できる。これらの行動は、一見すると恥ずかしく、弱さの表れのように感じるかもしれません。しかし実は、これこそがプロフェッショナルとしての強さの証なのです。完璧を装うことより、素直に学ぶ姿勢を見せることの方が、はるかに価値があるのです。この「恥をかく勇気」は、決して若いうちだけのものではないということです。むしろ、キャリアを重ねれば重ねるほど、この勇気は必要になってきます。 新しい技術が次々と生まれ、若い世代が台頭してくる中で、「知らない」と素直に認められること。「教えてください」と謙虚に学べること。「申し訳ありません、私の理解が足りませんでした」と正直に認められること。これらの勇気は、実は年齢を重ねるほどに必要となる、プロフェッショナルとしての資質なのです。恥をかく勇気は、特別な才能でも、与えられる特権でもありません。それは、私たち一人一人が意識的に選択できる、そして選択すべき心持ちなのです。 成功は、その後の成功の邪魔をするかもしれません。今日の恥ずかしさに向き合うことは、明日への投資となります。このことを、いつまでも心に留めておいてほしいと思います。回り道が育む固有の強さ人生の道筋は、決して直線ではありません。私たちは往々にして、最短距離で目標に到達したいと考えます。しかし、回り道こそが、あなただけの固有の強さを育んでくれるのです。私自身、キャリアの中で何度も遠回りをしてきました。本流から外れたプロジェクトを任されたり、一時的に希望と異なる職種を経験したり、時には組織の再編で思いがけない環境に置かれたりすることもありました。当時は「なぜ自分がこんな道を歩まなければならないのか」と不満に思うこともありました。周りの同期が順調にキャリアを積み上げていく中、自分だけが取り残されているような焦りを感じたものです。しかし、時間が経つにつれて気づいたのは、その回り道が、他の誰も持ち得ない視点と経験をもたらしてくれたということです。これらの経験は一見すると遠回りに思えましたが、実は私のキャリアに独自の深みと幅をもたらしてくれたのです。主流を進んできた同僚たちには持ち得ない、複合的な視点と問題解決能力。それは紛れもなく、回り道があったからこそ得られた財産でした。今あなたが感じている遠回りも、いずれあなたの強みとなるでしょう。その道のりで出会う人々、直面する課題、得る経験は、すべてあなただけの唯一無二の財産となっていきます。焦らず、自分のペースで一歩一歩進んでいけば良いのです。失敗から築く財産失敗から学ぶには、適切なプロセスが必要です。私の経験では、まず感情が落ち着くまでの時間を大切にすることから始まります。失敗直後の感情的な状態では、適切な分析はできないからです。その後、冷静になって状況を振り返り、何が起きたのかを客観的に分析します。そこから具体的な改善点を見出し、同じ失敗を繰り返さない仕組みを考えます。そして最後に、その学びを実践に移していきます。このプロセスを通じて、失敗の経験を、未来への教訓として活かすことができるのです。最も難しいのは、失敗後に再び立ち上がる勇気を持つことです。特に大きな失敗の後は、自信を完全に失ってしまいがちです。しかし、そんな時こそ立ち止まって考える必要があります。その失敗は、本当に自分の価値を否定するほどのものだったのでしょうか。むしろ、その経験は今後の人生において、かけがえのない糧となるのではないでしょうか。失敗を恐れすぎるよりも、失敗から学ばないことの方が、よほど危険なのです。「試練」に誠実に向き合う人生における試練は、成長のための贈り物だと考えましょう。困難に直面したとき、「なぜ自分が？」と嘆くのではなく、「これから何を学べるか」と考える姿勢が大切です。私自身、大きな失敗を経験し、最初は言い訳を探した。しかし冷静になって考えると、その原因は自分の準備不足と慢心でした。この経験から学んだのは、試練は私たちの弱点を露わにするということ。その弱点こそが次に克服すべき課題となります。試練に誠実に向き合うとは、苦しみを受け入れることではない。困難の中から学びを見出し、それを成長の糧とすることです。適切な視点で見れば、どんな試練も価値ある教訓を含んでいます。失敗から学ぶ成長の道20代の学生さんやエンジニアの皆さんへ。自分の可能性を、失敗への恐れで閉ざさないでください。失敗は終わりではなく、新しい始まりのチャンスなのです。失敗には様々な種類があります。不注意や準備不足による避けられたはずの失敗と、新しいことに挑戦する過程で生まれる成長につながる失敗です。挑戦を避けることで確かに表面的な失敗は減るかもしれませんが、それは成長の機会も同時に失うことを意味します。この違いを理解することで、恐れるべき失敗と受け入れるべき失敗が見えてきます。アウトプットを出していない人より、出している人の方が偉いことに疑いはありません。 何も生み出さずに批評だけする人は、実際に挑戦している人の足元にも及びません。失敗を恐れて何も生み出さない選択は、成長の放棄に等しいことを忘れないでください。発信することで批判を受けるリスクを取る人の方が、安全圏から意見するだけの人よりも常に価値があるのです。また、失敗には必ず何らかの仕組みやパターンがあります。意図や行動が、どのように望まない結果につながったのか。このメカニズムを理解することで、同じ失敗を繰り返さない知恵が身につきます。失敗を単なる結果として見るのではなく、そのプロセスに着目することが大切です。失敗しない方法は挑戦しなければいい私は今、若手エンジニアの育成に関わる立場になっていますが、よく言うことがあります。「完璧な準備も、完璧なタイミングも存在しない。あるのは、今この瞬間に踏み出す勇気だけだ」と。そして、「本当の失敗は挑戦しなかったことだ」と。失敗から学ぶには分析的思考が重要です。目に見える結果から出発し、見えていない原因を丁寧に掘り下げていく。この分析過程こそが、学びをもたらします。表面的な症状に囚われず、根本原因を探る姿勢が、エンジニアとしての成長を加速させるのです。最後に、これだけは強く伝えたいと思います。大きな成功の影には、必ず数々の失敗体験が隠れています。 失敗は一つ一つが、確実にあなたを成長させ、より強い人間に変えていきます。日々の小さな失敗と、そこからの学びの積み重ねが、やがて大きな成長となるのです。失敗を建設的に活用する視点も忘れないでください。失敗から目を背けるのではなく、うまく付き合うことで、次の失敗を防ぐだけでなく、失敗を基に新しい技術やアイデアを生み出すことができます。失敗は単なる障害ではなく、革新の源泉にもなりうるのです。技術の世界は常に進化し続けています。その中で完璧を目指すことは、ある意味で幻想かもしれません。だからこそ、失敗を恐れず、むしろ成長のための贈り物として受け止めてほしい。 それが、私が20代で得た最も大切な学びです。02. 専門性を見つけ、情熱を注ぐ。新人エンジニアの頃、すべての技術に手を出したくなった。フロントエンド? 面白そう！ バックエンド? いいね！ インフラ技術? コンテナ基盤? データベース？ 機械学習？ 全部やりたい！でも......気づいたんです。「全てを学ぶ」というのは、実は「何も深く理解しない」ことなんだと。浅く広い知識は、深い専門性には勝てない。「でも専門を決めるのが怖い...」そう思うのは当然です。選べば他の道を閉ざすことになる。けれど、時間は有限です。人生という名の砂時計の砂は、静かに、でも確実に減っていく。「これって単なる選択恐怖症を正当化してるだけでは？」という批判もあるだろう。確かに......無限の選択肢に圧倒されて何も選べないまま時間だけが過ぎていくことはある。でも違うんです。専門性を深めるということは、可能性を狭めることではなく、むしろ新たな世界への扉を開くこと。一見狭く見える専門分野の中に、実は......想像もしなかった奥深さがある。目の前のことを着実にやり続ける。小さな一歩の積み重ねが、やがて誰にも真似できない専門性となる。諦めず、痛みに耐え、努力し続ける——それこそが本当の差を生む。可能性との向き合い方20代の若者にとって、最も悩ましい問題の一つは「自分の立ち位置」を定めることだろう。私もその例外ではなかった。新卒で入社した当初、目の前には無限に広がる可能性があった。まるで果てしない大海原に一人、小さな船で漕ぎ出したような感覚だった。全てを得ることの幻想「全部やればいいじゃない」。そう思った時期が私にもあった。実際、様々な分野に手を出した。新しい技術が登場するたびに飛びつき、流行りのフレームワークを追いかけ、話題の開発手法を試してみる。そんな日々を過ごしていた。期限を定めないことで、「いつかはできるようになる」という甘い考えに逃げ込んでいたのかもしれません。しかし、時間が経つにつれて気づいた。「全てを学ぶ」というのは、実は「何も深く理解しない」ということではないか。確かに、多くを知ることは大切です。だが、それは表面的な理解に留まってはいけない。大切なのは、まず可能性を広げること。そして、その中から本当に重要なものを見極め、深めていくことです。私たちには無限の可能性があります。しかし、時間は有限です。全てを極めることはできない。だからこそ、選択と期限の設定が必要になる。最初から削ることは賢明ではない。むしろ、十分に可能性を広げた上で、それを絞り込んでいく。この過程こそが、本当の意味での「選択」なのだと思う。広く浅い知識は、深い理解への入り口に過ぎない。それは必要な段階ではあるが、そこに留まっていては本質的な成長は望めない。様々な可能性に触れた後で、自分が本当に追求したいものを見つけ、そこに時間と情熱を注ぐ。選択とは、諦めることではなく、集中することなのです。そして、その集中に意味を持たせるのが、期限の存在なのです。明確な期限を設定しないと、ついつい「いつかは」という甘い考えに流されがちです。「この技術もいつか必要になるかもしれない」「あのフレームワークもいずれ使う機会があるだろう」という思考が、私たちの焦点を曖昧にしてしまいます。期限という制約があることで、初めて本当に重要なものとそうでないものを区別する必要性に迫られるのです。この選択と集中のプロセスは、決して容易ではありません。しかし、時間という有限の資源を最も効果的に活用するためには、避けては通れない道なのです。一度に全てを手に入れることはできない。だからこそ、期限という枠組みの中で、自分が本当に追求したいものを見極め、そこに全力を注ぐ。それが、本当の意味での専門性を築く第一歩となるのです。焦らずに目の前のことをちゃんとやる焦りは、新しい技術の波に取り残される不安からではなく、むしろ身近な場所にあります。ある人はカンファレンスで登壇し、ある人は注目のスタートアップでCTOに就任し、また別の人は起業し、誰かは大規模なサービスを開発しています。SNSのタイムラインを開けば、日々誰かの活躍が流れてきます。そして厄介なのは、一人の「すごい人」がいると思っていたら、その上にもっと「すごい人」がいることに気づかされる瞬間です。さらに恐ろしいことに、その「すごい人」の上には、その道のレジェンドとも呼べる存在がいて、そのレジェンドの上にはまた、世界を変えるビジョナリーがいる。上には上がいるどころではなく、上には上の上の上がいるという現実に圧倒されることもあるでしょう。しかし、よく考えてみれば、それらは異なる人々の異なるタイミングでの成果です。誰かが起業したというニュースも、別の誰かがOSSにコントリビュートしているというニュースも、一人の「すごい人」が全てをやっているわけではない。それぞれが、それぞれの場所で、それぞれのペースで進んでいるだけなのです。世界を変えたビジョナリーたちも、最初から頂点にいたわけではなく、かつては誰にも知られていない一人の技術者だったのです。読者諸兄に伝えたいのは、目の前のことを着実にやり続けることの大切さです。架空の天才や想像上の完璧な技術者と戦うのではなく、自分の進むべき道を黙々と歩むことが重要です。その道の上に何層もの達人がいることを認識しつつも、他者の成果と自分を比較するのではなく、今携わっているプロジェクトで最善を尽くすべきです。たとえばバグ修正一つとっても、その根本原因を徹底的に追求する。表面的な対処で済ませるのではなく、システムの本質的な理解を目指す。この姿勢は、結果として最も確実な成長をもたらしてくれる。目の前の課題に真摯に向き合い、そこから得られる学びを大切にする。たとえその一歩が小さなものに見えても、確実に前進していることを信じよう。地味な道かもしれない。しかし、これが自分の選んだ道なら、信じて進み続けるしかない。そして忘れてはならないのは、あなたの上にいる多くの達人たちも、かつては同じようにこの地道な道を歩んできたということだ。日々の積み重ねは、必ず自分の力となっていく。そして、この地道な努力には、驚くべき力があります。諦めないこと、痛みに耐え続けること、そして努力し続けることには、圧倒的な価値があるのです。なぜなら、ほとんどの人は途中で諦めてしまうからです。新しい技術への興味も、難しい課題への挑戦も、多くの人は「しばらく」は続けられる。しかし、その「しばらく」を超えて、何年も、何十年も続けられる人は、驚くほど少ない。そして、あなたが見上げる頂点にいる人々は、ただ才能があるだけでなく、この「諦めない」という最も困難な道を選び続けてきた人たちなのです。だからこそ、諦めずに続けることには大きな意味があります。1年続ければ多くの人と差がつき始める。3年続ければ、その分野の専門家として認められ始める。5年、10年と継続できれば、もはや圧倒的な存在となっているだろう。そしてさらに先へ進めば、あなた自身が誰かの「上の上の上」にいる存在になっているかもしれない。この単純な真理は、天賦の才能や恵まれた環境以上に、あなたの未来を形作る力を持っている。毎日の小さな進歩は、それ単体では取るに足らないものに見えるかもしれない。しかし、その一歩一歩の確かな前進が、やがては越えがたい差となって現れる。なぜなら、本当の「差」とは、諦めなかった人と、諦めてしまった人との間に生まれるからです。そして最終的に、何層もの「上」を見上げる恐れを克服し、自分の歩みを信じられた人だけが、いつか誰かに「上の上の上」と呼ばれる存在になっていくのです。問題解決を学ぶ問題解決の本質は、「問題を正しく理解することができれば、半分は解決している」という気づきから始まる。専門分野を選ぶ際も同じです。自分が何に興味があり、どんな課題に取り組みたいのか。その理解なくして、正しい選択はできない。特に重要なのは、「解決できない問題」は存在せず、「まだ解決方法が見つかっていない問題」があるだけだという心構えを持つことです。専門分野の選択においても、「向いていない」「才能がない」という思い込みで諦めるのではなく、「まだ理解が足りていない」「もっと学ぶ必要がある」という建設的な視点で捉えることが大切です。問題に直面したとき、まず必要なのは問題の本質を理解することです。自分が本当に情熱を持てる分野は何か、どんな課題に取り組みたいのか。この問いに対する答えを見つけることから、専門性への道は始まる。そして計画を立て、実行し、定期的に振り返ることで、自分の選んだ道が正しいのかを確認していく。この継続的なプロセスを通じて、専門性は徐々に形作られていく。深さを求める決断深さを求める決断とは、すなわち自分が解決したい問題を決めることです。私の場合、それは「システムの信頼性」という課題だった。目の前で起きる不具合や障害に心を痛め、どうすればシステムを安定して動かせるのか、その問いに強く惹かれた。これは単なる技術的な興味ではない。問題の本質を理解し、それを解決したいという切実な願いだった。現代の社会は広大で、技術の領域では日々新しい概念や手法が生まれている。しかし、それらは全て何らかの問題を解決するために生まれてきた。だからこそ私は、「広く浅く」ではなく、「解決したい問題を深く」という道を選んです。特定の問題に深く向き合うことで、その領域に特有の課題やパターンが見えてくる。そして、その理解が新たな解決策を生み出す力となる。専門性がもたらすもの私の場合、システムの信頼性に軸足を置くことを選んです。それは、目の前で起きる問題に心から興味を持てたからです。物事が安定して動き続けることの重要性、そしてそれを支える仕組みの奥深さに魅了されたのです。この決断は、私のキャリアを大きく変えた。しかし、その道のりは決して平坦ではなかった。価値のある専門性を身につけるには、膨大な時間と労力、そして時には耐えがたい痛みさえ伴う。夜遅くまでドキュメントと格闘し、休日を返上して技術検証を重ね、時には自分の無力さに打ちのめされることもあった。特に辛かったのは、成長が目に見えにくい時期です。毎日必死に学び、実践しているのに、なかなか成果が見えない。そんな日々が何ヶ月も続くことがあります。しかし、今になって思うのは、その「見えない成長期間」こそが、本物の専門性を築く上で最も重要な時期だったということです。なぜなら、本当に価値のあるものは、決して短期間では手に入らないからです。表面的な知識なら、確かに短時間で習得することもできる。しかし、その分野の本質を理解し、実践的な判断力を養い、そして何より「自分ならではの視点」を確立するには、避けては通れない苦しみと向き合う必要があります。結果として、専門性を持つことで、より本質的な課題が見えるようになり、チーム内での役割が明確になった。重要な判断での発言力が増し、将来の道筋が見えてきた。専門性は単なる知識の蓄積ではなく、物事を見る目を養い、判断力を磨き、そして何より自信を与えてくれるものだった。そして、この確信は、あの苦しい時期を乗り越えたからこそ得られた、かけがえのない財産なのです。視野の広がり「専門性を持つ」ことと「視野を狭める」ことは異なる。むしろ、一つの分野を深く理解することで、他の領域との関連性がより明確に見えるようになり、新しい知識を学ぶ速度が格段に上がった。そして何より、より本質的な議論ができるようになった。深い専門性は、むしろ視野を広げ、学びの質を高めてくれる。配られたカードとの向き合い方人生は、ある意味でカードゲームに似ている。生まれ育った環境、才能、機会―これらは私たちに配られた初期手札です。確かに「もっと良いカードが欲しかった」と嘆くことはできる。しかし、ゲームはすでに始まっている。初期手札は変えられなくとも、プレイを重ねることで新しいカードを引くことができる。その際、初期手札との相性を考えながらカードを選んでいく必要があります。20代の良さは、10代と違って必ずしもすべてのカードを採用する必要がないことです。さらに、学びを深めることで、一枚のカードから複数の使い方を見出すこともできる。そして何より、自分らしいデッキを構築していく自由は、誰もが持っている。お前しかお前を救えない20代のある日、ふと気づいたことがあります。「もう誰も助けてくれない」という現実です。これは10代との決定的な違いでした。学生時代は、失敗しても誰かがフォローしてくれました。先生が助言をくれ、親が支えてくれ、友人が慰めてくれました。しかし、社会人となった今、泣いても誰も助けてはくれません。締め切りが迫っているプロジェクト、解決できない技術的な課題、チーム内での人間関係の軋轢―これらは全て、自分で解決していかなければならない問題なのです。最初はこの現実に戸惑い、時には不安に押しつぶされそうになりました。しかし、これこそが大人としての自立の第一歩だったのです。誰かが助けてくれることを期待するのではなく、自分で決断し、その結果に責任を持つ。それが20代に求められる最も重要な成長なのかもしれません。競争から差別化へ世の中は自分より才能がある人はたくさんいる。この現実を直視することは痛みを伴いますが、成長への第一歩です。どんなに努力しても、どんなに才能があると思っていても、自分を遥かに超える能力を持った人々が必ず存在します。特に人気のある分野、競争の激しい市場では、この現実がより鮮明に現れます。しかし、ここで諦める必要はありません。むしろ、「優れるな異なれ」という原則を実践する道があります。これは単なる勝敗の発想を超え、独自性を通じて価値を生み出す考え方です。勝てない市場から軸足をずらし、ニッチな市場に活動の場所を移すという選択肢を検討してみましょう。誰もが目指す華やかな舞台ではなく、あまり注目されていないけれど、自分の強みが活かせる領域を見つけ、そこで地道に実績を積み上げていくのです。一見、遠回りに見えるかもしれませんが、移した先でこそ実力がつくこともあるのです。競争が少ない分、試行錯誤の余地が大きく、失敗から学ぶ機会も多いでしょう。そして何より、そのニッチな領域で唯一無二の存在となれば、後からその分野が注目されたときに、あなたは既に揺るぎない地位を築いているはずです。差別化された市場での成功は、時として予想以上の大きな実りをもたらします。なぜなら、その領域であなたの代わりとなる人材が少ないからです。価値は希少性からも生まれます。万人が持つスキルよりも、あなただけが持つ専門性の方が、時として大きな価値を生み出すのです。多くの人が同じ頂きを目指して競争する世界で真に成功するには、「より優れること」ではなく「異なること」に焦点を当てるべきです。あなただけの固有の視点、独自のアプローチ、他にはない組み合わせの専門性。それこそが、混沌とした市場で確固たる存在感を放つ鍵となるのです。答えは時代によって変化するもうこれだけ自己啓発的な話をするなら、避けては通れない生成AIについても少し語らねばなりません。2025年のテック業界は、多くのエンジニアにとって厳しい現実に直面する年になっています。過去10年を振り返ると、ピープルマネジメントに進むか技術の専門家になるかという選択肢が明確でした。しかし今やゲームのルールは一変しています。精緻な技術力、圧倒的なスピード感、そしてLLM技術の実践的活用能力が求められる時代へと変貌したのです。この変化により、従来型のリーダーたちも専門技術に長けた人材も同様に苦戦しています。AIによって従来の成功方程式が書き換えられ、多くのエンジニアが置き去りにされた感覚を抱いているのです。生成AIの台頭により、人類は本当に驚くほどの変革期を迎えています。歴史上誰も経験したことのない技術革新がこれから次々と私たちの前に現れるでしょう。 CursorのようなAIコードアシスタントやClaude 3.7が開発プロセスを変革しています。2027年までには、ソフトウェア構築の方法自体が一変するでしょう。この時代に現状維持は最大のリスクと言えます。この前例のない変革の波を乗りこなし、不確実性の時代を生き抜くには、現在の立ち位置で最大限の価値を生み出す姿勢が重要です。技術の本質理解と新ツールの柔軟な活用、両方のスキルを身につけ、変化を恐れず学び続けることが、人類がかつて経験したことのないこの劇的な変革期を生き抜く唯一の戦略だと私は考えています。情熱も有限である情熱は無限に湧き続けるものではない。これは多くの人が見落としがちな重要な真実です。特に20代の頃は、自分の情熱は永遠に続くものだと信じがちです。「好きなことをやっていれば疲れない」「情熱があれば何でもできる」—そんな思い込みに囚われていた時期が私にもありました。しかし現実は異なります。どんなに愛する分野であっても、情熱には波があります。燃えるように集中できる時期もあれば、なぜかやる気が起きない停滞期もある。これは決してあなたの意志が弱いからではなく、人間の自然な心理的サイクルなのです。特にエンジニアという職業では、技術の変化が激しく、常に新しいことを学び続ける必要があります。最初は新鮮で刺激的だった技術も、習熟するにつれて当初の興奮は薄れていきます。そして新たな技術が現れ、また学習サイクルが始まる。この繰り返しの中で、情熱というエネルギーは確実に消耗していくのです。だからこそ重要なのは、情熱を「消費」するものではなく、「投資」するものとして捉えることです。限られた情熱をどこに注ぐかを戦略的に考える。すべてに全力投球するのではなく、本当に重要なものを見極めて、そこに集中する。情熱の分散は、結果として何も達成できない原因となりかねません。また、情熱が一時的に枯渇することを恐れる必要もありません。それは畑を休ませるようなもので、むしろ次の豊かな収穫への準備期間と捉えることができます。情熱の枯渇を感じたときこそ、立ち止まって自分の方向性を見直すチャンスなのです。「情熱も有限である」のセクションに以下の内容を追加する提案をします：人はずっと同じ量で頑張り続けられるわけではない「毎日全力で頑張れ」「常に成長し続けろ」—技術業界では、こうした言葉が当たり前のように飛び交います。しかし、20代を通じて痛感したのは、人間は機械ではないという当たり前の事実でした。私も一時期、「常に頑張り続けなければ」という強迫観念に囚われていました。朝から晩までコードを書き、深夜まで技術書を読み、週末も勉強会に参加する。そんな生活を続けていたある日、突然何もやる気が起きなくなりました。好きだったはずのプログラミングが苦痛になり、新しい技術を学ぶことが恐怖に変わっていたのです。これは単なる怠慢ではありません。人間には必ず限界があり、その限界を無視し続けることは、長期的には破滅的な結果をもたらすのです。マラソンランナーが42.195kmを全力疾走できないように、私たちの人生も緩急をつけて走る必要があります。特に見落とされがちなのが、「頑張らない時期」の価値です。何もしない、学ばない、成長しない—そんな時期を「無駄」だと考える人は多いでしょう。しかし、この一見停滞している時期こそが、次の飛躍のための重要な準備期間なのです。畑を休ませることで土壌が回復するように、私たちの心と体も定期的な休息を必要としているのです。燃え尽き症候群（バーンアウト）は、決して他人事ではありません。優秀で情熱的な人ほど、この罠に陥りやすいのです。「もっと頑張れるはず」「まだ限界じゃない」と自分を追い込み続けた結果、ある日突然、何もできなくなってしまう。私の周りでも、輝かしいキャリアを歩んでいた人が、ある日を境に業界から姿を消してしまうケースを何度も見てきました。だからこそ伝えたいのは、「頑張れない自分」を責める必要はないということです。それは弱さではなく、人間として当然の反応なのです。むしろ、その信号を無視して頑張り続けることの方が、長期的には大きなリスクとなります。人生は短距離走ではなく、長距離走です。そして長距離走で大切なのは、ペース配分と休息です。時には立ち止まり、時には歩き、そして元気が戻ったらまた走り出す。このリズムを自分なりに見つけることこそが、持続可能なキャリアと人生を築く鍵なのです。情熱が枯渇し、頑張れない時期が来たら、それは「もっと頑張れ」という信号ではなく、「少し休もう」という体と心からのメッセージだと受け止めてください。その休息期間は、決して無駄ではありません。むしろ、次なる成長のための必要不可欠な投資なのです。過去の宣言に縛られず、新しい道を選ぶ勇気「私はバックエンドエンジニアとして生きていく」「一生、技術を極めていく」—新人時代、そう豪語していた自分を思い出します。当時は純粋に特定の技術領域を追求することが、唯一の正しい道だと思い込んでいました。しかし現実は、私たちの興味も情熱も、時とともに変化していくものです。過去の自分の宣言や発言に縛られすぎることは、自分自身の成長を妨げる危険性をはらんでいます。バックエンドから始まったキャリアが、フロントエンドへと広がるかもしれません。コードを書く立場から、プロダクトマネージャーへと変わるかもしれません。技術のスペシャリストから、エンジニアリングマネージャーへと転身するかもしれません。「でも、それじゃあ一貫性がないのでは？」という声が聞こえてきそうです。確かに一貫性は大切ですが、それは根本的な価値観や姿勢についてであり、具体的な職種や専門性については違います。むしろ、新しい挑戦を恐れず、自分の可能性を広げていくことこそが、真の専門家としての成長なのかもしれません。人生100年時代と言われる今、20代の決断が一生を決めるわけではありません。昨日の自分に忠実であるより、今日の自分に正直であることの方が大切なのです。過去の自分の宣言に囚われるのではなく、今の情熱に従い、新しい専門性を選ぶ勇気を持ちましょう。そして何より、その選択を恥じることはありません。変化することは、弱さではなく、成長の証なのですから。過去の自分が「フロントエンドは絶対にやらない」と断言していたとしても、今の自分がそこに情熱を見出したのなら、その道を選ぶべきです。「マネジメントはしない」と決めていても、チームを率いることに喜びを感じ始めたなら、その可能性を探るべきです。専門性とは固定された称号ではなく、常に進化し続ける旅路なのです。選択は自由だが責任が伴う「全てはできない。だからこそ、選択は自由です。そして、その選択には必ず責任が伴う」あなたには無限の可能性があります。しかし、その可能性を現実の力に変えるためには、「選択」と「集中」、そして何より「責任」が必要です。自分が本当に情熱を持てる分野を見つけ、そこに深く没入する。それは、時として孤独で勇気のいる決断かもしれません。もう誰も道を示してはくれません。進むべき方向も、取るべき手段も、全て自分で決めなければなりません。絶対的な正解がないのです。その決断の結果として、成功することもあれば、失敗することもあるでしょう。そして、継続しないという選択肢も、もちろんあります。ある分野に没頭してみて、それが自分に合わないと感じたら、別の道を探すことも一つの選択です。大切なのは、継続するにせよ、方向転換するにせよ、その決断に対して自分で責任を持つことです。継続も、撤退も、新たな挑戦も、全て選択肢です。「諦めた」という言葉は、時として否定的に捉えられがちですが、それも一つの勇気ある決断かもしれません。重要なのは、自分の選択に対して、真摯に向き合い、その結果を受け入れる覚悟を持つことです。その決断と情熱、そして責任を全うする姿勢こそが、あなたの「強み」となり、人生を支える柱となるはずです。専門性を選ぶことは、他を捨てることではありません。それは、自分の軸を定め、そこから世界を見渡すための視点を得ること。そして、その選択に対して全責任を負う覚悟を持つことなのです。社会は日々進化を続けています。だからこそ、確固たる専門性を持ちながら、柔軟に新しい知識を取り入れていく。あるいは、全く新しい分野に挑戦していく。そして、その全ての選択に対して責任を持つ。そんな姿勢が、結果として自分の可能性を最大限に広げることになるのだと、私は信じています。03. 一流に触れ、習慣を真似る。「天才の真似なんてできない」と思っていた。彼らは特別な才能を持って生まれてきたんだから。ところが......一流の人々を観察すると驚くべき事実に気づく。彼らの多くは特別な才能というよりも、普通のことを非常に丁寧に続けているだけだった。「目より先に手が上達することはない」。これは何を意味するのか？ 形だけの模倣では足りないということ。理解せずに真似るだけでは魂が入らない。「でもそれって結局、模倣じゃないの？」という声が聞こえてきそうです。確かに最初は模倣から始まる。でも......千回目の「真似」の途中で、突然それが自分のものになる瞬間がくる。外から入ってきたものが、内側から湧き出るようになる。一流の人々の意外な特徴は、彼らの「やらないこと」の明確さ。時間とエネルギーの使い方に優先順位をつけ、本質的でないことは思い切って捨てている。「当たり前のことを当たり前にやり続けること」——これが一流への道。毎日の小さな習慣が、複利のように積み重なり、やがて......圧倒的な差となって現れる。才能ではなく、継続する力こそが武器なのです。一流への誤解「一流」という言葉に、私は長らく誤解を抱いていた。華々しい成果を挙げること。有名な作品を生み出すこと。大きな組織を率いること。そういったものが「一流」なのだと思っていた。メディアで取り上げられるような派手な成功、世間の注目を集めるような目立った功績、誰もが知るような大きな影響力。そんな表面的な成功の形にばかり目を向けていた。しかし、実際に各界の第一線で活躍する方々と出会い、その考えは大きく変わった。一流とは、日々の小さな積み重ねの中にあった。派手さはなくとも、確実に前進し続ける姿勢。地道な努力を重ねる謙虚さ。そして何より、自分の仕事に対する深い愛情と責任感。それこそが、本物の「一流」が持つ本質的な価値だったのです。やらないことの重要性尊敬できる人々を観察して最も印象的だったのは、彼らの「取捨選択」の明確さです。人生において何を「やらないか」を決めることは、何を「やるか」を決めること以上に重要なのです。私が出会った尊敬できる人々は、実に多くのことを意図的に「やらない」選択をしていました。SNSでの無駄な議論、重要でない会議、自分の本質的な成長に寄与しない人間関係、飲酒、喫煙、目先の利益だけを追う仕事。彼らは、これらを徹底的に排除していたのです。一見すると、このような態度は機会の損失のように思えるかもしれません。しかし、限られた時間とエネルギーを、本当に重要なことに集中させることこそが、卓越性への道なのです。何でもかんでも手を出し、中途半端な結果に終わるよりも、少数の本質的なことに集中し、そこで卓越した結果を出す方が遥かに価値があるのです。これは単なる時間管理の話ではありません。「やらないこと」を決めるというのは、自分の人生の方向性を定める重要な選択なのです。例えば、ある優秀なエンジニアは「トレンドの技術を追いかけない」という選択をしていました。代わりに、基本的な技術の深い理解と、問題解決能力の向上に焦点を当てていたのです。重要なのは、これらの「やらない」選択が、単なる消極的な判断ではないということです。それは、より本質的なことに集中するための、積極的な決断なのです。素晴らしい人間は、何を捨てるかを知っているのです。この気づきは、私の仕事への姿勢を大きく変えました。「これは本当に必要なのか？」「この活動は自分の本質的な成長に寄与するのか？」といった問いを、常に自分に投げかけるようになったのです。そして、その答えが「No」であれば、たとえ短期的には魅力的に見えても、その活動を控えめにする、あるいは完全に排除する決断を下すようになりました。本質を見抜く表面的な方法論や技術だけでなく、なぜその選択をしたのか、どういう思考プロセスがあったのか、何を大切にしているのか。そういった本質的な部分に目を向けることで、学びが得られる。一流の人々の判断や行動の背後には、必ず深い洞察と明確な意図が存在する。この洞察力の核心にあるのが、抽象化と具体化の能力です。抽象化とは、複数の具体的な経験から共通項を見出し、本質的な概念として捉える能力のことです。例えば、様々なプロジェクトでの成功体験から「チームワークの本質」という抽象的な理解を導き出し、それを新しい環境でも活かすことができる。一方、具体化とは、抽象的な概念や価値観を、実際の行動や習慣として落とし込む能力です。「信頼関係を築く」という抽象的な目標を、約束を守る、誠実にコミュニケーションを取る、困ったときに助け合うといった具体的な行動として実践することができる。方法論は時代とともに変化する。技術は日々進化する。しかし、その根底にある思考法や価値観は、より普遍的な価値を持つ。一流の人々から学ぶべきは、この普遍的な部分なのです。彼らがなぜそのように考え、どのように決断を下すのか。その思考の枠組みを理解し、自分なりの実践に落とし込んでいくことで、自分自身の判断力を磨いていくことができる。日々の業務の中で意識的に「これは何の具体例なのか」「この学びは具体的にどう実践できるか」と考える習慣をつけることで、徐々にこの能力は磨かれていく。問いを立てる力学校では「正解」に、仕事では「結果」に価値が置かれがちですが、実は最も大切なのは答えよりも問いかもしれません。問いかけるとは、本質的には情報を整理し直すことです。私たちは毎日たくさんの情報に触れ、その中から意味あるパターンを見つけ出して新しい疑問を形にします。「問いの編集力」とは、私たち一人ひとりが持つ情報整理能力を使って、自分だけの問いを見つけ出す取り組みといえるでしょう。エンジニアは普段、バグ修正や機能開発など具体的な問題解決に集中しがちです。これらのスキルは確かに重要ですが、「そもそも正しい問題に取り組んでいるか」を問うことはさらに重要です。なぜなら、出発点となる問いが間違っていたら、どれだけ努力しても望む成果は得られないからです。問いが形になるまでの道のり質の高い問いは、段階を経て育っていきます。「土壌をほぐす」「タネを集める」「発芽させる」「結像する」という4つの段階を通じて形作られます。まず既存の考え方に疑問を投げかけ、様々な情報を収集し、それらを組み合わせて新しい視点を生み、最終的に明確な問いとして形を整えていくのです。「質問するのは恥ずかしい。知らないことを認めるようで怖い」と感じる方もいるでしょう。確かに質問は自分の不知を認めることでもあります。しかし、「わからないことを素直に知りたい」と表現できる人こそ、学びを深められるのです。有効な問いの特徴「良い問い」の形は状況によって変わりますが、どんな場面でも物事の根本に迫る問いかけには普遍的な価値があります。重要なのは、「良い問い」は成功者の経験談やハウツー本からは学べないということです。自分自身と向き合い、自己と世界について深く考えることでしか見つけられません。「良い問い」は自然と湧き上がってくるものです。無理に作り出すというより、既に自分の中に眠っているものを発見する過程といえます。そうした「心に引っかかる問い」に気づくには、違和感を大切にする姿勢が欠かせません。「何かがしっくりこない」という感覚こそが、重要な問いの種になることが多いのです。核心を見極める力現代のビジネスパーソン、特にエンジニアには、本当の課題がどこにあるのかを見抜く力が求められています。企業は通常、複数の問題を同時に抱えていますが、それらすべてを解決することは現実的ではありません。一つの課題に絞り込み、そこに力を集中させる方が効果的です。課題の絞り込みは容易ではありません。なぜなら中心となる問題点は状況の変化とともに移り変わるからです。これを的確に捉えるには、経験を積むしかありません。また、課題を設定する際は、その問題が解決可能かどうか、そして解決した場合に十分な成果が得られるかどうかを考慮すべきです。問いを立てることは単なる知的好奇心の表現ではなく、成果を生み出すための戦略的行為なのです。問いかける能力を高めるために問いの編集力とは、「問う」という知的活動を、私たち一人ひとりの情報整理能力で更新していくプロジェクトです。これは個人の成長だけでなく、チームや組織、さらには社会全体をより良い方向へ導く重要な能力となります。問いかける力を高めるには、自分の不知と向き合う勇気が必要です。理解しているふりをするのではなく、わからない部分を正直に認め、好奇心を持って質問することが大切です。短期的には恥ずかしく感じるかもしれませんが、長い目で見れば深い理解につながります。「質問しにくい環境」には注意が必要です。質問を歓迎しない組織や人間関係では、成長の可能性が制限されます。良い問いが生まれるのは、わからないことや間違いを受け入れる寛容さがある場所です。だからこそ、質問できる環境を大切にし、自らもそうした場づくりに貢献すべきでしょう。優れた問いには、「あなただけの視点」が含まれています。あなたの経験、知識、価値観が交わるユニークな立ち位置から生まれる問いは、誰も気づかなかった発見をもたらす可能性を秘めています。この意味で、問いかける力は自分自身を理解することとも深く関連しているのです。20代の終わりに、私は「答えを知っていること」より「問いを持っていること」の大切さに気づきました。答えは時とともに古くなりますが、本質的な問いかけは長く価値を保ち続けます。あなたはどのような問いを大切にしていますか？ その問いは、あなたの興味と情熱を映し出す鏡なのかもしれません。違和感を感じ取る「目より先に手が上達することはない」という言葉があります。これは武道の世界でよく言われる格言ですが、技術の習得においても深い真理を含んでいます。一流の人々の「形」だけを真似ても、その本質的な理解がなければ成長は得られません。例えば、ある優秀なエンジニアのコーディングスタイルを表面的に模倣しても、その設計思想や背景にある考え方を理解していなければ、似て非なるものになってしまいます。目で見て理解できていないことを、手だけで実現することは不可能なのです。私自身、若い頃は「とにかく真似てみる」ということを重視していました。有名なエンジニアのブログで紹介されているプラクティスや、書籍で推奨されているテクニックを、深い理解もないまま取り入れようとしていました。しかし、そうして作られたコードは、往々にして本質を外した、表面的な模倣に終わっていました。形を写すな、本質を活かせ理解には順序があります。まず「目」で見て、その本質を理解し、そこから自分なりの形を作り出す。これは重要な順序であり、単なる模倣では、むしろ成長の妨げとなる可能性すらあるのです。一流の習慣を学ぶ際も同様です。その行動の「形」をそのまま真似るのではなく、まずその背景にある本質を理解し、それを自分の文脈に合わせて具体化することが重要です。例えば、ある優れたエンジニアが毎朝6時に出社して技術書を読んでいるとしても、その表面的な行動を真似る必要はありません。その本質です「一日の最も集中できる時間を学習に充てる」という考え方を理解し、自分の生活リズムに合わせた別の形で実践すれば良いのです。模倣とは、行動そのものを真似ることではなく、その行動の背後にある思考と意図を理解し、それを自分なりの形で具体化することです。それは表面的には全く異なる行動になるかもしれません。しかし、本質において同じ価値を生み出すことができるのです。これこそが、一流の人々から真に学ぶということなのです。身近にある機会と、その罠一流に触れる機会は意外と身近にあります。必ずしも環境を大きく変える必要はない。セミナーやカンファレンスへの参加、技術ブログの購読、コミュニティ活動など、様々な形で優れた人々の考え方に触れることができる。重要なのは、その出会いから何を学び取るかです。デジタル時代の今、世界中の一流の知見に触れることができる。オンラインの講演やポッドキャスト、SNSでの発信など、学びの機会は無限に存在する。ただし、情報の質を見極める目を持つことも同時に求められる。しかし、ここで陥りやすい罠があります。「学び」と「行動」のバランスを見誤ることです。現代は、「成功の秘訣」を説く情報で溢れている。有料セミナーや高額なコーチングなど、一見魅力的な「王道」を提示するものも多い。だが、どんなに素晴らしいセミナーでも、あなたの実際の行動には勝てない。情報収集に終始し、実践が伴わない学びは、単なる「知識の消費」に終わってしまう。重要なのは、得た知識をいかに自分の文脈に落とし込み、実践に移していくかです。成長は、知識の蓄積ではなく、実践の積み重ねからもたらされる。まず行動し、そこから学び、また行動する。このサイクルこそが、本質的な成長への近道となる。他者の経験から学ぶことは確かに重要だが、それは「行動のヒント」として捉えるべきであって、「行動の代替」とすべきではない。一流の人々の言葉や経験は、あくまでも自分の実践を助けるための道標として活用すべきなのです。実践からの学びを重視する良質な学びの機会を見極める目も必要です。「成功者の話を聞く」ことと「実践的な知識を得る」ことは、必ずしも一致しない。実際、「成功者」と呼ばれる人々を冷静に観察すると、その成功が必ずしも並外れた能力や努力だけによるものではないことに気づきます。良い指導者や優れた組織との出会い、遺伝的な優位性、恵まれた身体能力など、本人のコントロールを超えた要素が大きく影響していることも少なくありません。一流と呼ばれる人々の多くは、華やかな成功談よりも、日々の実践の中で静かに学びを得ています。彼らの真価は、表面的な成功物語の中にではなく、日常的な判断や行動の積み重ねの中にこそ存在するのです。実践を重視する姿勢は、具体的な形となって現れます。まず自ら行動を起こし、その過程で得られる具体的な気づきを大切にする。他者の経験は参考程度に留め、自分なりの答えを地道に見つけていく。そして、セミナーや情報収集に費やす時間と実践に使う時間のバランスを常に意識する。実践なき学びは空虚であり、学びなき実践は危険です。両者のバランスを取りながら、着実に前進していくことが求められます。学びの場として最も価値があるのは、実は目の前の仕事かもしれません。日々の業務の中で直面する課題、同僚との協働、失敗や成功の経験―これらこそが、最も実践的な学びの機会となります。理論と実践の橋渡しができる場所であり、即座にフィードバックを得られる環境なのです。目の前の仕事を「単なる作業」として捉えるのではなく、貴重な学びの機会として活用する視点を持つことが重要です。外部の「成功者」の言葉に頼るよりも、自らの経験から学ぶ姿勢こそが、成長につながるのです。習慣から学ぶ私の場合、特に印象に残っているのは、ある一流の方の「朝の習慣」です。毎朝、必ず30分、様々な分野の記事や本を読む。それも、自分の専門分野に限らず、幅広い領域の情報を。一見単純な習慣だが、その背景には、世界の潮流を常に把握する意識、新しい視点を得ようとする姿勢、知識の体系化への努力が隠れていた。この習慣は、単なる情報収集ではない。それは、世界を広く見渡す視点を養い、異なる分野からの気づきを得る機会を作り、自身の専門性をより深めるための重要な実践なのです。一流の人々の習慣には、必ず明確な意図と深い考察が込められている。一見些細に見える日課であっても、そこには確固たる目的と長年の試行錯誤が存在する。そのような習慣の意味を理解し、自分なりにアレンジして取り入れていくことで、確実な成長につながっていく。当たり前のレベルをあげるだけ一流の人々の成果に目を奪われるのではなく、その成果を支える日々の努力と習慣に目を向けること。そして、単なる模倣ではなく、その本質を理解し、自分なりの形で実践すること。なぜなら、一流になるための王道は、実は「当たり前のことを当たり前にやり続けること」なのだから。この「当たり前」の中身を理解し、実践し続けることこそが、一流への道となる。派手さはなくとも、確実に前進し続ける姿勢。地道な努力を重ねる謙虚さ。そして何より、自分の仕事に対する深い愛情と責任感。これらの「当たり前」を着実に積み重ねていくことで、いつしか自分も誰かの「一流」となる日が来るのかもしれない。習慣は複利で伸びる習慣の力は複利と同じ原理で働きます。投資における複利が時間とともに加速度的に資産を増やすように、良質な習慣は日々の小さな積み重ねが長期的に見ると驚くべき成長をもたらします。例えば、毎日たった0.1%だけ成長する人と変化のない人では、1年後には1.44倍もの差が生まれるのです（1.001の365乗≒1.44）。小さな成長率でも、1日1つ強くなることを継続することで確実に差が広がっていくのです。習慣の複利効果は目に見えにくい。短期間では違いがほとんど感じられず、多くの人はすぐに諦めてしまいます。しかし、優れた習慣を3ヶ月、6ヶ月、そして1年と続けていくと、ある時点から急激に成果が現れ始めます。この「遅れてくる成功」の原理を理解していれば、目に見える結果がないときでも続ける勇気が持てるでしょう。習慣は自己同一性の変革をもたらします。「毎日コードを書く人」「定期的に新しい技術を学ぶ人」「チームを助ける人」といった自己イメージは、それに沿った行動を自然と生み出します。良い習慣を「やらなければならないこと」から「自分がどういう人間であるか」の表現へと昇華させることで、継続のための意志力に頼る必要がなくなるのです。複利の力を活かすには「長期思考」が不可欠です。今日の小さな選択が将来の大きな違いを生み出すという視点を持ち、日々の習慣を設計しましょう。明日の見返りのためではなく、5年後、10年後の自分を形作るために今日何ができるかを考えることで、一流への道が開けるのです。04. 仲間を作り、友達を作り、切磋琢磨する。エンジニアは孤独な職業だと思っていた。暗い部屋でコードと向き合い、黙々と作業する——そんなイメージ。でも本当に......そうだろうか？実は、最高のエンジニアほど素晴らしい人間関係を持っている。一人の天才より、互いに高め合うチームの方が強い。ここで気づくべき真実がある。自分が付き合いたいと思うような人間に、自分自身がなっていく。不思議なことに、周りの人との関係は鏡のように自分を映し出す。「そんな功利的な人間関係の選び方は冷たくない？」という疑問が湧くかもしれない。でも、ここで言っているのは計算づくの人間関係ではなく、自然と引き寄せ合う法則の話。「あなたの周りの5人があなたの未来を形作る」。これは単なる格言ではなく、実際に......機能する法則なんです。向上心のある人と過ごせば、自分も向上する。愚痴ばかり言う人と過ごせば、自分も愚痴っぽくなる。人間関係を意識的に選ぶことは、自分の人生という庭に、どんな花を植えるかを決めること。それは誰かを操作するためではなく、お互いがより良く成長するための選択なのです。孤独な戦いから仲間との成長へ仕事は、時として深い孤独感に包まれる戦いのように感じることがあります。モニターに向かって黙々と作業をこなし、複雑な課題と向き合い、技術書を読み漁る。そんな静寂の中で過ごす時間は、確かにエンジニアとして必要不可欠な時間です。しかし、そんな日々の中で、私が20代で得た最大の財産。それは「仲間」だった。彼らの存在は、私の技術者人生に温かな光を投げかけ、孤独な戦いに意味と喜びをもたらしてくれた。会社を超えた絆同じ会社の仲間です必要はない。むしろ、会社の枠を超えて、同じ志を持つ仲間との出会いこそが、私の人生を大きく前に進めてくれた。専門的な話で夜遅くまで盛り上がり、技術的な悩みを深く相談し合い、時には信念をかけて激しく議論を交わす。そんな真摯な関係性が、いつしか私の成長の大きな原動力となっていた。会社という枠を超えることで、より自由な発想と率直な意見交換が可能になり、それが新たな気づきと学びをもたらしてくれた。異なる視点との出会いしかし、それ以上に大切だったのは、仕事とは全く関係のない友人たちの存在です。自分の技術の世界しか知らなかった私に、彼らは全く新しい視点と価値観を与えてくれた。営業職の友人が語る、人と人との繋がりを大切にした商談の話。デザイナーの友人が見せてくれる、美しさと機能性が融合したクリエイティブの世界。教師をしている友人の、次世代を育てることへの熱い思いと使命感。それらの話は全て、私の人生に新しい色彩を加え、視野を大きく広げてくれた。技術だけでは決して得られない、人生の豊かさを教えてくれたのです。切磋琢磨の喜び「ライバル」という言葉には、少し抵抗があるかもしれない。競争や対立を連想させるからです。でも、切磋琢磨できる存在がいるということは、本当に素晴らしいことです。同じ目標に向かって真剣に走る仲間がいる。互いの小さな成長を心から喜び合える関係があります。時には相手の活躍に負けそうで悔しい思いをすることもあります。でも、それこそが自分を強くし、より高みへと導いてくれる原動力となる。この良質な緊張関係は、決して敵対的な競争ではなく、むしろ互いを高め合うための大切な絆なのです。コミュニティとの出会い20代の私は、意識的に様々なコミュニティに足を運んです。技術の勉強会、異業種交流会、オンラインのテックコミュニティ。確かに最初は緊張したし、うまくコミュニケーションが取れず、居心地の悪い思いをすることもあった。それでも、その一歩を踏み出す勇気を持ったからこそ、かけがえのない出会いと成長の機会を得ることができた。ただし、ここで一つ重要な注意点があります。SNSやオンラインコミュニティは、使い方を誤ると逆に孤独を深める危険性をはらんでいる。画面の向こうの「つながり」に依存しすぎると、かえって現実の人間関係が希薄になってしまう。スマートフォンは便利な道具ではあるが、決してあなたの孤独を癒してはくれない。むしろ、オンラインでの交流は、リアルな出会いのきっかけとして活用すべきです。本当の絆は、実際に顔を合わせ、時間を共有し、共に経験を重ねることで築かれていくものなのです。集まりを主催する価値参加するだけでなく、主催者になることで得られる学びは格段に深いものです。私が初めて技術勉強会を主催した時、「場を作る」という経験が、参加者としては決して得られない視点を与えてくれました。小規模な勉強会から始めることをお勧めします。最初は5人程度の規模で十分です。私の場合、会社の会議室を借りて、開催しました。小規模だからこそ、一人一人と深い対話ができ、参加者同士の関係性も自然と育まれていきました。有意義な集まりの核心は、明確な目的設定にあります。漠然とした交流会ではなく、具体的な価値を生み出す場を作るために、主催者はその目的に深くコミットし、参加者を慎重に選び、適切な会場を確保する必要があります。そして、その目的に沿って初参加の人が発言しやすい雰囲気を作り、適切な時間管理を行い、次回への改善点を集めることが重要です。主催者には、参加者を見守り導く責任があります。単なる場所の提供者ではなく、全ての参加者が安全かつ有意義な時間を過ごせるよう、積極的に働きかける必要があります。特に重要なのは、参加者同士の垣根を取り払う環境づくりです。肩書や経歴に縛られず、一人の人間として率直に対話できる場を作ることで、より建設的で深いつながりが生まれやすくなります。主催者になることで、イベントの裏側で動く仕組み、参加者それぞれの期待値の違い、場の空気を作る難しさなど、参加者として気づかなかった多くの視点を得られます。これらの経験は、リーダーシップスキルの向上、多様な価値観への理解、ネットワークの広がり、企画力・実行力の強化につながり、仕事上のプロジェクトマネジメントにも直接活きてきます。失敗も貴重な学びの機会です。参加者が集まらない、議論が活性化しない、時間配分を誤るなど、様々な課題に直面しますが、それらを一つ一つ克服していく過程で、確実にスキルは磨かれていきます。コミュニティは一朝一夕には育ちませんが、定期的な開催と改善を重ねることで、徐々に独自の文化が形成されていきます。主催者として場を作る経験は、参加者としての振る舞い方も深く理解することにつながります。視野を広げる出会い学校や会社の中だけで完結する人間関係では、視野が狭くなってしまう。それは井の中の蛙になるようなものです。様々な業界、様々な立場の人との深い交流は、必ず新しい発見と気づきをもたらしてくれる。時には自分の当たり前だと思っていた常識が大きく覆されることもあります。最初は戸惑いや抵抗を感じるかもしれない。でも、それこそが本当の意味での成長の糧となり、人間としての幅を広げてくれる。自分が付き合いたい人間に自分自身がなる人との関係性について、ある重要な気づきがあります。私たちは自然と、自分自身と似た価値観や性質を持つ人々に囲まれていくということです。最初、この事実に気づいたとき、少し困惑しました。なぜなら、これは「自分が望むような人々と出会えていない」という不満が、実は自分自身への問いかけだったことを意味するからです。例えば、「信頼できる仲間と出会いたい」と願うなら、まず自分が信頼に値する人間になる必要があります。「本音で話せる友人が欲しい」と思うなら、自分が先に本音を語る勇気を持たなければならない。チームメイトを信頼できないと感じるとき、それは往々にして自分自身への不信感の投影かもしれません。他者の成功を純粋に喜べないのは、自分自身の未熟さや不安を直視できていない可能性があります。逆に、周りの人々を心から信頼し、その成長を喜べる人は、たいてい自分自身とも健全な関係を築けている人なのです。そして、重要なことに気づきました。他人を変えることは困難を極めますが、自分自身を変えることは意外にも簡単なのです。私たちは往々にして、問題の原因を他者に求めがちです。「あの人がこう変われば」「周りがこうすれば」と。しかし、そのアプローチでは決して状況は改善しません。なぜなら、他者の考えや行動を直接コントロールすることなど、本質的に不可能だからです。一方で、自分自身を変えることは、意志さえあれば今すぐにでも始められます。相手の態度が気に入らないなら、まず自分の接し方を変えてみる。チームの雰囲気が悪いと感じるなら、自分から前向きな態度を示してみる。驚くべきことに、自分が変わることで、周りとの関係性もまた、自然と変化していくのです。この気づきは、ある意味でとてもシンプルです。自分が望む人間関係を手に入れたいなら、まず自分自身がそういう関係を築ける人間になればいい。理想の仲間を待つのではなく、自分が理想の仲間になることから始める。それは決して容易な道のりではありませんが、確実に結果を導き出せる唯一の方法なのです。誠実さ、信頼性、共感力、そして成長への意欲。これらは私たちが他者に求める資質ですと同時に、自分自身が磨くべき資質でもあるのです。自分が付き合いたいと思うような人間に、自分自身がなっていく。この単純だけれど力強い仮説は、人間関係における最も実践的な知恵の一つかもしれません。そして、この過程で気づくのです。自分自身を高めていく努力は、決して孤独な戦いではないということを。なぜなら、自分が変わることで、必然的により良い出会いが生まれ、より深い関係性が築かれていくからです。それは、まるで自分自身の成長が、周囲の世界をも少しずつ変えていくような、不思議な化学反応なのです。正義と悪の向こう側にあるもの人との関係性について深く考えていくと、ある重要な気づきに至ります。誰かにとって忌み嫌うものでも、誰かにとっては唯一無二の価値になるということです。ある人が大切にしている価値観を、別の人は理解できないかもしれない。誰かが美しいと感じるものに、別の誰かは違和感を覚えるかもしれない。地獄と呼ばれるような状況に、天国を見出す人がいる。廃墟に美を、騒音に音楽を、混沌に秩序を見る人たちがいる。それはどちらが正しいという話じゃない。視点が変われば、世界は別の顔を見せるのだから。技術の世界でも同じことが言えます。ある人にとっては「レガシーで古臭い」技術が、別の人にとっては「安定していて信頼できる」基盤となる。誰かが「非効率」と切り捨てるプロセスが、別の誰かにとっては「丁寧で確実」な手法となる。結局のところ、私たちは「どこから見ているか」で感じ方が変わる生き物なのだ。高層ビルの屋上から見下ろす街と、地下鉄のホームから見上げる街は、同じ街でも全く違う物語を語りかけてくる。私は正しい方を選べない自分に、時々罪悪感を覚える。誰かの価値観に完全に同意できなかったり、みんなが素晴らしいと言うものに共感できなかったり。そんな自分の感覚が間違っているのではないかと不安になることがある。でも考えてみれば、「正しさ」なんて、誰が決めたルールなんだろう。多数派が正義なら、少数派の居場所はどこにあるのか。みんなが右を向いているとき、左を向く勇気がないことの方が、もしかしたら罪なのかもしれない。罪は人の解釈だ。同じ言葉でも、受け取る人によって励ましにも傷つける刃にもなる。同じ行動でも、文脈によって思いやりにも押し付けにもなる。そして罪の解釈は、常に自分自身を映し出す鏡になる。他人の罪を糾弾するとき、実は自分の影を追いかけているだけかもしれない。人は自分の中にあるものしか、他人の中に見ることができないのだから。だから俺は思う。誰かが大切にしているものを否定する前に、なぜその人がそれを大切にしているのかを想像してみることこそ、本当の意味での「正しさ」への第一歩なのかもしれないと。罪悪感は、実は優しさの裏返しなのかもしれないと。この気づきは、人間関係において本質的な意味を持ちます。正義も悪も絶対的なものではなく、すべては相対的で文脈依存的だということ。だからこそ、他者の価値観を尊重し、異なる視点を受け入れる寛容さが必要なのです。完全に理解できなくても、少なくとも「なぜその人はそう考えるのか」を想像してみる。自分の価値観を押し付けるのではなく、相手の世界観に一度身を委ねてみる。そうした姿勢こそが、豊かな人間関係を築く基盤となると思います。人間関係を選ぶ勇気を持つ仲間の大切さについて語ってきましたが、ここで忘れてはならない重要な側面があります。あなたは自分の周りにいる5人の平均値になるという言葉を聞いたことがあるでしょうか。この言葉は比喩的ではありますが、深い真理を含んでいます。私たちは意識するしないにかかわらず、日常的に接する人々から強い影響を受けているのです。20代の私は、この事実に気づいていませんでした。ただ漠然と、人間関係をなるべく広く持つことで自分の可能性を広げようと必死でした。しかし、年を経るにつれて痛感したのは、量より質が圧倒的に重要であるという仮説です。毎日顔を合わせる同僚、休日を共に過ごす友人、悩みを打ち明ける仲間—こうした人々が、知らず知らずのうちに私たちの考え方、行動様式、そして将来の可能性にまで影響を与えているのです。自分に悪影響を及ぼす人間関係を減らす。この決断は、一見冷たいように聞こえるかもしれません。しかし、これは自己防衛であると同時に、自分の人生に対する責任でもあるのです。常にネガティブな話題ばかりを口にする人、他者の成功を素直に喜べない人、あなたの夢を小さく見せようとする人。こうした存在と長時間過ごすことで、あなた自身もいつしかその影響を受け、同じような思考パターンに陥ってしまう危険性があります。もちろん、これは困難に直面したとき、安易に人間関係を切り捨てるべきだという意味ではありません。むしろ、本当に大切な関係は、時として困難や衝突を乗り越えることでより強固になります。しかし、自分の時間とエネルギーを注ぐべき相手を意識的に選ぶことは、あなたの人生の質を決定づける重要な要素となるのです。私自身、あるコミュニティに所属していた時期がありました。最初は刺激的で成長できる場だと感じていましたが、次第にそこでの会話がエネルギーを奪うだけで、会った後に疲弊感や無力感が残ることに気づきました。自分の価値観が尊重されず、互いの成長よりも依存関係が強まっていくような関係性。そこから距離を置く決断をするまでに、かなりの時間を要しました。しかし、その決断は結果として、新たな出会いのためのスペースを作ることになったのです。周囲の5人を選ぶということは、実は自分の未来を選ぶことです。意識的にポジティブで、成長志向で、誠実な人々と時間を過ごすことで、あなた自身もそのような人間に近づいていきます。逆に、不満や愚痴ばかりを言う人々に囲まれていれば、いつしかあなたもその一人になってしまうでしょう。人間関係を見直す最初のステップは、境界線を設定することです。自分にとって受け入れられる行動と受け入れられない行動を明確にし、それを相手に伝える勇気を持つこと。それでも状況が改善しないなら、徐々に距離を取ることも必要です。時には関係性そのものを終わらせる決断も必要になるかもしれません。人間関係を選択するということは、必ずしも相手を拒絶することではありません。互いにとって最も健全な距離感を見つけることなのです。ある人とは深い友情を育み、ある人とは仕事上の良好な関係を保ち、またある人とは適度な距離を置く。そうした使い分けも、大人の人間関係では重要なスキルです。このプロセスは時に痛みを伴いますが、自分の人生に対して責任を持つという成長の証でもあります。あなたの周りの5人があなたの未来を形作る—この事実を忘れずに、勇気を持って自分の人間関係を選んでいくことが大切なのです。ネガティブな会話から距離を置く勇気飲み会や友人との集まりで、誰かの悪口や愚痴で盛り上がることはありませんか？一時的には気が晴れるかもしれませんが、そんな会話の後、なぜか心が重くなった経験はないでしょうか。私は20代半ばで気づきました。友人同士で集まると、つい仕事の愚痴や共通の知人の批判で盛り上がってしまう。「あいつ、ほんと使えないよね」「あの飲み会、最悪だったよね」—そんな会話の後に残るのは、なぜか微妙な後味だけでした。転機になったのは、ある友人との出会いです。彼の周りには不思議と人が集まり、会話は常に前向きで、アイデアや可能性に溢れていました。彼が他人について話すときは、必ずその人の良いところを見つけ出します。困難な状況でも、どうすれば改善できるかを考える。彼との時間は、いつも心が軽くなるのです。そして気づきました—誰かを批判することは簡単だけど、それで何かが良くなるわけではないということを。この発見が、私の交友関係を見直すきっかけになりました。徐々に、愚痴や批判で盛り上がる集まりから距離を置き、前向きな会話ができる友人との時間を大切にするようになりました。もちろん、これは「問題から目を背ける」ということではありません。むしろ、問題に対して「じゃあ、どうする？」という建設的な姿勢を持つことです。時には辛辣な冗談も、場の空気を和らげることがあります。ブラックユーモアを否定しているわけではありません。せめて笑えるものであれば、その場は救われるものです。驚いたことに、この小さな意識の変化が友人関係だけでなく、自分自身の心の状態にも良い影響を与えていきました。他人を批判する時間が減ると、自分を責める癖も少しずつ薄れていったのです。あなたの周りの会話は、どんな内容で満ちていますか？ 仲間と過ごす時間が、エネルギーを奪うものか、それとも与えてくれるものか。それを見極め、意識的に選ぶことも、豊かな人間関係を築く上で大切なことかもしれません。宝物としての友情「友情」という言葉は、確かに少し大げさで照れくさく聞こえるかもしれない。子供の頃のような、純粋に遊び、笑い、時には喧嘩もする―そんな率直な関係性を指して「友情」と呼ぶことは、大人になるにつれて少なくなっていく。特に、効率と成果が重視される現代社会においては、そんな言葉は時代遅れのように響くかもしれない。しかし、20代という多感な時期に出会った仲間たちは、間違いなく私の人生の宝物です。彼らとの出会いと経験がなければ、今の私は存在しない。技術的な知識や専門的なスキルは日々進化し、古びていく。市場のトレンドは常に移り変わる。でも、信頼できる仲間との絆は、時間が経っても色褪せることはない。むしろ、年月を重ねることで、その価値はより一層深みを増していくのです。社会人になってからの「友情」は、確かに子供の頃とは異なる形を取る。しかし、その本質―互いを理解し、支え合い、共に成長していく関係性は、年齢を重ねても変わることはない。むしろ、人生の経験を積み重ねることで、その絆はより強く、より深いものになっていくのです。自分らしくあれ一人で全てを背負い、戦う必要は決してない。エンジニアという職業柄、孤独な作業に没頭する時間は確かに必要です。しかし、その孤独に閉じこもり、新しい出会いから逃げる必要はない。ここで一つ、重要な学びを伝えておきたい。全ての人に好かれることは不可能です。むしろ、全員に好かれようとすることは、自分らしさを失うリスクを伴います。誰かに深く理解されるということは、同時に誰かに理解されないということでもあるのです。それは避けられない、そして実は健全な状態なのかもしれません。大切なのは、あなたの価値観に共鳴し、本当の意味で理解し合える仲間を見つけることです。表面的な人間関係を広く持つよりも、深い絆で結ばれた少数の仲間との関係性の方が、はるかに価値があります。全員に好かれる必要はない。本当にあなたを理解してくれる人とつながればいいのです。仲間と共に成長する喜びは、人生をより豊かで味わい深いものにしてくれる。時には励まし合い、時には切磋琢磨し、そして時には互いの成功を心から喜び合える。そんな関係性こそが、私たちの人生に価値をもたらすのです。この揺るぎない確信は、私の20代が教えてくれた最も大切な学びの一つです。たとえ今は孤独を感じていても、必ず共に歩める仲間は見つかる。大切なのは、その出会いに向けて、一歩を踏み出す勇気を持つことです。その一歩は小さなものかもしれないが、その先には必ず誰かがいる。なぜなら、誰もが同じように、本当の意味での繋がりを求めているのだから。05. プライベートをちゃんとやる。恋愛をしてくれ。「プログラミングが恋人です」—そう冗談めかして言うエンジニアを見たことがある。冗談のつもりでも、そこには悲しい真実が。「仕事だけじゃない」という当たり前の事実に気づくのが遅れると、人生の重要な経験を逃してしまう。特に恋愛は、技術では得られない学びをもたらす。「でも恋愛なんて時間の無駄じゃない？その間にコード書けるのに」。確かに......一理ある。しかし、コードだけ書いていても、人間としての幅は広がらない。恋愛で学ぶ最も衝撃的な真実は、「そのままのあなたを好きになってはくれない」ということ。これは残酷に聞こえるかもしれないが、実は成長のための貴重な機会です。自分を変える必要があるって？「それって自分を偽ることじゃないの？」と反発したくなるだろう。でも違うんです。相手のために少し変わることで、むしろ......本当の自分に気づくことがある。見た目も大事です。「内面が大事なんじゃないの？」ともちろん思う。でも見た目は内面の表現でもある。清潔感や身だしなみは、自分を大切にしている証でもあるんです。恋愛も趣味も、人生を豊かにする要素。仕事だけに情熱を注ぐのではなく、バランスの取れた生活が、実は最高のパフォーマンスを生み出す。この章を書くのは少し照れくさい。技術的な話題なら堂々と語れるのに、こと恋愛となると、急に言葉が躊躇いがちになる。それでも、20代を振り返って、これだけは強く、心を込めて伝えたい。「恋愛をしてくれ。そして、プライベートを大切にしてくれ」 この言葉には、技術者として成長する中で気づいた、人生における重要な仮説が込められている。後回しにしがちな恋愛「仕事が忙しい」「自己啓発に時間を使いたい」「今はその余裕がない」「もう少し実績を積んでから」。よく聞く言葉です。私も同じことを言っていた。しかも、それは一見とても理性的で正しい判断のように思えた。プライベートな時間は、自分のスキルアップに使うべきだと考えていた。技術書を読み、プログラミングの練習をし、業界の最新動向をキャッチアップする。そんな時間の使い方こそが、プロフェッショナルとしての正しい選択だと信じていた。だから、恋愛は後回しにしていた。でも、それは大きな間違いだった。私たちは、仕事や自己啓発という「正しそうな理由」で、本当は怖いだけの自分から目を背けているのかもしれない。その背後には、傷つくことへの不安、変化を受け入れることへの恐れ、そして何より、自分自身と向き合うことへの躊躇いが隠れていた。技術的な課題には果敢に挑戦できるのに、なぜか感情の領域になると及び腰になってしまう。それは、コードには正解があるのに対し、人間関係には明確な答えがないからかもしれない。失恋から学んだこと私は何度も失恋をした。そして、それは予想以上に辛い経験だった。技術的な失敗なら、原因を分析し、対策を立て、次に活かすことができる。しかし、感情の痛みは、そう簡単には整理できない。夜も眠れず、仕事に集中できず、それまで楽しかったことも色あせて見えた。しかし、その経験があったからこそ、「仕事だけじゃない」という当たり前の事実に気づくことができた。人生には、仕事やスキル以上に大切なものがあります。感情の機微、他者との深い繋がり、そして自分自身の心の動き。これらを知ることができたのは、恋愛のおかげです。失恋の痛みは、むしろ私に人間としての深みを与えてくれた。恋愛が教えてくれたことこの経験が私に教えてくれた重要な仮説は、人生には論理だけでは割り切れないことがあるということです。むしろ、その「割り切れなさ」こそが人生の味わいを作っている。完璧な準備を待っていては、永遠に何も始まらない。準備に費やす時間は、実は恐れから目を背けるための言い訳かもしれない。傷つくことを恐れすぎると、成長の機会も逃してしまう。成長とは、時として痛みを伴うものです。また、感情の機微を理解することは、予想以上に重要です。技術だけでなく、人の心を理解する力が、リーダーには求められる。そして、自分の弱さを認められることもまた、大切な強さの一つなのです。完璧を装う必要はない。むしろ、自分の弱さや不完全さを受け入れることで、より深い人間関係を築くことができる。そして何より、自分自身に嘘をつきすぎないことが大切です。自分の本当の気持ちから目を背け続けると、いつか必ず行き詰まります。自分が何を望み、何を恐れているのかを正直に認めることで、より自分らしい選択ができるようになるのです。時々思うのですが、人間関係にもテストを書きたくなることがあります。「この状況でこう言えば相手はこう反応するはず」という予測と結果を検証できれば、もっと関係が円滑になるのではないか。それはもうギャルゲーに近いなにかかもしれませんが…。しかし、人間はアルゴリズムではなく、予測不可能な存在であることを受け入れることも大切です。完全な理解や制御を求めるのではなく、不確実性を楽しむ余裕を持ちたいものです。プライベートの価値プライベートの充実は、決して時間の無駄ではない。むしろ、人生を豊かにするための必要不可欠な要素です。仕事以外の時間を大切にすることで、新しい視点や価値観に出会える。それは、きっとあなたの人生をより面白いものにしてくれるはずです。趣味の時間、友人との交流、家族との団らん。一見、キャリアとは無関係に思えるこれらの経験が、実は予想もしない形で仕事にも良い影響を与えてくれる。視野が広がり、創造性が育まれ、人間としての深みが増す。そして何より、心が癒され、新たな活力が生まれる。失恋の意味失恋は確かに辛い。人からNOを突きつけられるのは辛い。特に、エンジニアとして普段は論理的な思考と確実な結果を追求している私たちにとって、この種の不確実性と感情の揺れは、大きな試練となる。でも、その経験は必ず自分の糧になる。なぜなら、それは人として成長するための重要な機会だからです。失恋を経験して初めて気づくことがあります。自分が特別な存在ではないこと。完璧な関係など存在しないこと。そして、それでも前に進んでいけること。この気づきは、単なる恋愛の教訓を超えて、人生全般に対する深い洞察をもたらしてくれる。失敗や挫折を受け入れる力、自分を客観的に見つめる目、そして何より、傷ついても再び立ち上がる勇気。これらは、プロフェッショナルとしても必要不可欠な資質です。人生の豊かさとは人生の豊かさは、一人一人異なる形を持っている。ある人にとっては仕事への没頭が、また別の人にとっては家族との時間が、そしてまた別の誰かにとっては趣味や創作活動が、かけがえのない価値を持つ。それは当然のことであり、誰かの価値観を他者に押し付けるべきではない。しかし、だからこそ私は言いたい。仕事も大切です。キャリアの成功も、技術の習得も、プロフェッショナルとしての成長も、確かに重要な目標です。でも、それと同じくらい、いや、もしかしたらそれ以上に大切なのが、あなた自身の人生です。20代という貴重な時間を、ただ仕事だけに費やすのは本当にもったいない。 この時期にしか得られない経験、この年齢だからこその出会いや発見があります。プライベートも恋愛も、あなたの人生をより深く、より豊かにしてくれる大切な要素なのです。バランスの取れた人生を送ることは、実は最高のキャリア戦略かもしれない。なぜなら、豊かな人間性を持つ技術者こそが、ある意味で価値ある存在となれるからです。技術だけでなく、人間としての深みを持つことで、より良い判断ができ、より良いチームを作り、より良い製品を生み出すことができる。そのままのあなたを好きになってはくれない完璧な恋愛なんて存在しない。完璧な人間関係も、完璧なタイミングも存在しない。誰もが最初は不安で、誰もが失敗を恐れている。技術的な挑戦なら躊躇なく受け入れられるのに、なぜか感情の領域になると及び腰になってしまう私たち。でも、その一歩を踏み出す勇気が、きっとあなたの人生をより豊かなものにしてくれる。そのままのあなたを無条件に受け入れてくれる人に出会えたら、それは本当に素晴らしいことです。しかし、多くの場合、恋愛は私たちに変化を求める。それは決して悪いことではない。むしろ、その変化こそが成長の証かもしれない。相手を思いやる気持ちを学び、自分の我儘さに気づき、より良い人間になろうと努力する。そんな変化の過程こそが、恋愛の持つ大きな価値の一つなのです。恋愛は、時として自分の望まない仮説に向き合うことを迫ってくる。これまで気づかなかった自分の短所、見たくなかった性格の暗部、認めたくない自己中心的な面。相手との関係の中で、そういった自分の嫌な面と向き合うことになるかもしれない。それは時として辛く、居心地の悪い経験かもしれない。しかし、そんな自分の姿を受け入れ、向き合っていく過程もまた、大切な成長の機会となる。完璧な人間などいない。むしろ、自分の不完全さを知り、それでも前に進もうとする勇気こそが、人としての成熟をもたらすのです。ただし、恋愛に夢中になりすぎて自分を見失うことには注意が必要です。相手のために変わることと、相手に合わせるために本質的な自分を捨てることは、全く異なる。健全な関係とは、お互いを高め合える関係であり、一方が他方に埋没してしまうような関係ではない。自分の欠点に向き合い、改善を目指すことは大切だが、それは自分らしさを失うことではないはずです。見た目は内面の表現ソフトウェア開発者の多くが「中身が大事」「見た目より機能性」と考える傾向があります。これはコードを書く上では正しい価値観ですが、人間関係においては少し違った視点が必要です。見た目を整えることは、浅はかな行為ではありません。むしろ、自分自身への敬意と、相手への配慮を示す行動です。清潔感のある服装、適切な身だしなみ、姿勢の良さは、「自分を大切にしている」「相手と会うことを重視している」というメッセージを無言で伝えます。これは決して高価なブランド服を着たり、トレンドに振り回されることではありません。基本は清潔感です。髪は整え、衣服はシワがなく清潔であること。歯を磨き、体臭に気を配ること。これらの「当たり前」を徹底するだけで、印象は大きく変わります。また、あなたの服装や外見は、あなたの個性を表現する手段でもあります。「プログラマーだから髪型はボサボサでTシャツとジーンズで十分」という考えはやめましょう。あなたの興味や価値観を反映した服装を選ぶことで、同じ感性を持つ相手との話題も生まれやすくなります。姿勢にも気を配りましょう。背筋を伸ばし、顔を上げて歩く姿勢は自信の表れであり、自然と好印象につながります。最近のリモートワーク環境では姿勢が崩れがちですが、それが習慣化すると対面での印象にも影響します。重要なのは、第一印象は数秒で形成され、その後の関係性に長期間影響するという事実です。どんなに素晴らしい内面を持っていても、その魅力を伝える機会すら得られないかもしれません。見た目を整えることは、自分の価値を正しく表現するための投資なのです。しかし同時に、外見に対する過度の執着も問題です。あなたの本質的な価値は、決して外見だけで決まるものではありません。見た目を整えることは自己表現の一部であり、全てではないことを忘れないでください。少し意識して服装や身だしなみを変えてみると、周囲の反応の変化に驚くでしょう。それは単なる見かけの変化ではなく、あなた自身の自信の高まりや、対人関係への積極性の表れでもあるのです。自分を大切にする姿勢が、結果として他者からも大切にされる関係性を築く第一歩となります。恋愛は失敗するもの多くのエンジニアが陥りがちな罠は、「理想の相手」という概念に固執しすぎることです。完璧なパートナーを定義し、その条件に合う人を探し出そうとする。まるでアルゴリズムで最適解を求めるように。しかし、恋愛は計算式では解けません。それは確率と数字の戦いなのです。自分が動かなければ、何も変わりません。これは恋愛においても絶対的な真理です。どれだけ理想を描いても、実際に一歩を踏み出さなければ、出会いは生まれないのです。行動こそが変化の始まりです。出会いの数が多ければ多いほど、あなたにぴったりの相手と巡り会う確率は高くなります。これは単純な数学です。だからこそ、積極的に社交の場に出ることが重要になります。技術コミュニティだけでなく、趣味のグループ、友人の集まり、さらには見知らぬ環境へのチャレンジも、すべて新しい出会いのチャンスです。また、重要なのは拒絶を恐れないことです。営業の世界では「ノーをいくつ集められるか」が成功の指標とさえ言われます。恋愛も同じです。断られることを失敗と捉えず、あなたに合う相手を見つけるためのプロセスの一部と考えましょう。統計的に見れば、「いいえ」の数が増えるほど、「はい」に出会う確率も高まるのです。傷つく覚悟を持って挑むことが必要です。恋愛は時に私たちの心を深く傷つけることがあります。しかし、その痛みを恐れて閉じこもってしまえば、喜びも感動も手に入れることはできません。傷ついた経験が、あなたをより強く、より深い愛を理解できる人間に成長させるのです。よく考えてみてください。あなたがどんなに独特な性格や趣味を持っていても、この世界には似たような価値観を持つ人が必ず存在します。完璧な相手はひとりではなく、あなたと相性の良い人は多数いるのです。理想の「ひとり」を探すのではなく、あなたと共鳴できる「何人か」を見つけるという視点の転換が、恋愛成功への近道です。拒絶されることの恐怖は、プログラミングでいえばデバッグの恐怖に似ています。エラーは失敗ではなく、より良いコードへの道筋を示す情報です。同様に、恋愛での「不一致」も、あなたがどのような関係を求めているのか、どんな相手と相性が良いのかを理解するための貴重なデータなのです。積極的に行動すること。これが恋愛という数字のゲームで勝つための最大の戦略です。技術的な問題に取り組むときのように、恐れずに前進し、学び、調整し、再び挑戦する。この繰り返しが、必ずあなたを望む関係へと導いてくれるでしょう。行動なくして変化なし。傷つく可能性があっても、その一歩を踏み出す勇気が、あなたの人生を豊かに変えていくのです。パートナー選びの落とし穴恋愛において見落としがちな重要な真実があります。初期の魅力と長期的な相性は、必ずしも一致しないということです。私の周りでも、「面白い人」「刺激的な人」に惹かれて交際したものの、数年後に後悔するケースを多く見てきました。最初は魅力的に見えた「いつも楽しませてくれる」という特徴が、日常生活では疲れる要因になることがあるのです。恋愛感情の高まりと生活パートナーとしての適性を混同してはいけません。ドキドキする感覚は確かに大切ですが、それだけで長期的な関係を築くのは難しいでしょう。むしろ重要なのは、お金や時間の使い方といった価値観の一致、意見の相違を建設的に話し合える関係性、そして何より普通の日々を心地よく過ごせるかどうかです。「面白さ」や「刺激」を最優先にしてパートナーを選ぶと、後々苦労することがあります。むしろ、静かで落ち着いた関係の中にこそ、長続きする幸せがあることも多いのです。若いうちは「退屈」に見える関係性も、実は最も安定していて幸せな関係かもしれません。恋愛や結婚で「詰む」ことを避けるためには、表面的な魅力だけでなく、日々の生活を共にする相手として本当に適しているかを冷静に見極めることが大切です。派手さはなくても、お互いを思いやり、支え合える関係こそが、人生という長い旅路を共に歩む基盤となるのです。人生の意味を考える仕事の合間に、ふと立ち止まって考えることがあります。「何のために生きているのだろう」「この先どんな人生を送りたいのだろう」。特に20代という時期は、こうした問いが頭をよぎる瞬間が少なくありません。多くの場合、私たちは深く考えることなく、周囲の期待や社会的な成功の物差しに従って生きてしまいがちです。良い大学、良い会社、昇進、結婚...。でも時々、「本当にこれでいいのか」という声が心の奥から聞こえてくることがあります。私が経験から学んだのは、充実した人生を送るには、自分自身の価値観を大切にすることの重要性です。何が自分を幸せにするのか、何に意味を感じるのか—それは人それぞれ異なります。エンジニアとしての技術的な成長を最優先する人もいれば、人との繋がりや家族との時間を大切にする人もいる。どちらが正しいということはありません。大切なのは、「なりたい自分」という大きな方向性を持ち、そこに向かうための具体的な目標を立て、日々の行動に落とし込んでいくこと。この考え方は仕事だけでなく、恋愛や人間関係にも応用できます。「恋愛すべき」という外圧に従うのではなく、あなた自身にとって恋愛とはどんな意味を持つのか、どんな関係を築きたいのか、そして今の自分に本当に必要なのは何かを考えてみてください。人生を満足して生きるコツは、他人の物差しではなく、自分の価値観に基づいて選択し、自分の人生に主体的に関わることだと思います。恋愛も例外ではありません。誰かと深く関わるということは、時に勇気のいることですが、それは自分自身をより深く知るための貴重な機会でもあるのです。人生は一度きり。その貴重な時間を、ただ仕事だけに費やすには惜しすぎる。 技術者としての成長も大切だが、一人の人間としての成長はそれ以上に重要です。恋愛も、友情も、趣味も、全ては私たちの人生を彩る大切な要素なのだから。そして最後に付け加えたい。これは決して「仕事を疎かにしろ」という意味ではない。むしろ、充実したプライベートがあるからこそ、仕事でも最高のパフォーマンスを発揮できる。バランスの取れた生活は、結果として全てを高める。だからこそ、勇気を出して一歩を踏み出してほしい。その一歩が、あなたの人生をより豊かなものに変えてくれるはずです。恋愛を通じて得られる変化を恐れず、時には自分の嫌な面と向き合う勇気も持ちながら、しかし自分の核となる部分は大切にしつつ、一歩ずつ前に進んでいってほしい。06. 挨拶と礼儀をやる。そして、「おはようございます」という一言が、なぜそんなに大切なのか？技術さえあれば評価されるはずじゃないのか？残念ながら......現実はそう単純ではない。「技術力だけでは評価されない」という冷たい事実がある。優れたコードを書けても、一緒に働きたくない人とは、誰も働きたくないのです。「そんな社交辞令、古臭くないか？」という声も聞こえてきそうです。確かに形だけの礼儀は空虚に見える。でも、挨拶や礼儀は単なる形式ではなく、相手への敬意の表現なんです。必要なのは、「素直に学び、謙虚に受け止める姿勢」と、「良い意味での生意気さ」のバランス。完全な従順さも、無遠慮な主張も、どちらも極端です。この二つは一見矛盾するように見えるが、実は......補完し合う。謙虚さがあるからこそ、建設的な意見も受け入れられる。相手を尊重する基盤があるからこそ、新しいアイデアも響くのです。結局のところ、「いい人になろうとする姿勢そのもの」に価値がある。完璧な「いい人」になることは難しくても、その方向に向かって努力し続けること。それが信頼関係の基盤を作るのです。とある思い込みもしくは勘違いについてエンジニア界隈には、根深い思い込みがあります。「技術力さえあれば評価される」「コミュニケーションは付随的なもの」「礼儀作法は形式的な無駄」「自分の仕事さえやってれば報連相とか不要」。私も若い頃は、この罠に陥っていた一人です。技術的な卓越性だけを追求し、人としての基本的な振る舞いを軽視していた。その結果、優れた技術を持ちながらも、それを効果的に活かせない状況に何度も直面することになった。素直であれ現代社会では、しばしば「批判的思考」が過度に重視される。SNSでの皮肉な発言が称賛を集め、物事を斜に構えて見ることが「かっこいい」とされる風潮があります。確かに、批判的思考は重要なスキルです。しかし、それ以上に価値があるのは、素直に学び、謙虚に受け止める姿勢です。完璧な人は尊敬されるかもしれないが、一生懸命頑張る人は応援したくなる。それは人間の自然な感情です。「まだ分からないことばかりですが、教えてください」と素直に学ぶ姿勢を見せ、「ありがとうございます」と心から感謝を伝え、失敗した時には「申し訳ありません。次は必ず上手くやります」と前を向ける。そんな素直さこそが、実は最大の強さなのだ。私たちは誰もが不完全で、日々成長の途上にいる。その事実を隠そうとするのではなく、むしろ正直に認めることで、より多くの人々の共感と支援を得ることができる。完璧を装う人は近寄りがたいが、素直に努力を重ねる人には、誰もが自然と手を差し伸べたくなる。技術の世界でも同じことが言える。「すでにできる人」よりも「これからできるようになろうとしている人」の方が、周囲の協力を得やすい。なぜなら、その成長過程に関わることで、教える側も新しい気づきを得られるからです。結局のところ、最も価値があるのは「批判する力」ではなく「素直に成長していく力」なのです。それこそが、本当の意味での強さではないだろうか。生意気であれ一見すると、「素直であれ」と矛盾するように思えるかもしれないが、実は「生意気であれ」というのも重要な要素なのです。ただし、これは素直に学び、基本的な信頼関係を築いた上ではじめて意味を持つ姿勢です。技術の世界では、この「良い意味での生意気さ」が必要不可欠です。「今のやり方、もっと良くできると思います」「新しい技術を使えば、効率化できそうです」といった、建設的な提案のできる存在。それが、ここで言う「生意気さ」の本質です。しかし、この生意気さが効果を発揮するには、重要な前提条件があります。それは、日頃からの素直な姿勢と、上司や先輩への深いリスペクトです。普段から素直に学び、基本的な礼儀を守り、チームに貢献する姿勢を見せているからこそ、時として「生意気な」提案も受け入れられる。これは、築き上げた信頼関係があってこその特権とも言える。良い意味での生意気さには、二つの重要な要素があります。まず、上司や先輩の意図を十分に理解し、その上でより良い方法を提案できる洞察力。そして、その提案を適切なタイミングと方法で伝える判断力です。例えば、チーム全体の前ではなく、1on1の場で建設的な提案をする。あるいは、「こうした方が良いのでは？」と押しつけがましくなく、むしろ質問形式で投げかけてみる。常に従順なだけの若手よりも、適度な生意気さを持ち合わせた若手の方が、組織に新しい風を吹き込む可能性を秘めている。しかし、これは決して「素直さ」と相反するものではない。むしろ、素直に学び、信頼関係を築いた上で、適切に「生意気」になれるというのが、理想的な成長の形なのです。生意気さのおわり20代前半と後半では、同じ「生意気さ」でも、周囲からの受け取られ方が大きく変わってくることに気づかされました。これは多くの若手エンジニアが直面する、落とし穴とも言えるでしょう。20代前半の頃は、多少生意気でも「若さゆえ」と許される部分があります。むしろ、その新鮮な視点や率直な意見が、チームに活力をもたらすこともあるでしょう。先輩や上司も、あなたを「まだ成長途上の若手」と位置づけ、その言動に対して寛容な姿勢を持ってくれることが多いのです。しかし、20代後半になると、この構図が微妙に変化していきます。経験を積み、一定の実績を上げることで、周囲からの見られ方が「若手」から「中堅」へとシフトしていくからです。以前は「生意気だけど頑張っている若手」として受け入れられていた言動が、今では「高圧的な態度」と受け取られるリスクが生じるのです。実はここに重要な気づきがあります。「生意気であれる」のは、ある意味で周囲から「まだ軽く見られている」証拠でもあるということです。厳しい言い方かもしれませんが、あなたの意見がまだ十分な重みを持っていないからこそ、「若さゆえの生意気さ」として許容されていた側面があるのです。20代後半になると、周囲はあなたの言葉により多くの重みと責任を求めるようになります。同じ提案でも、「面白いアイデアだね」で済まされる段階から、「実現可能性はどうなの？」「リスクは検討したの？」と、より深い思考と責任ある発言を期待されるようになるのです。このシフトに気づかず、以前と同じような「生意気さ」を維持していると、周囲との軋轢が生じることもあります。特に、新しく入ってきた若手メンバーの前では、あなたの何気ない言葉が「上からの指示」として受け取られることもあるでしょう。では、どうすればよいのか。20代後半の適切な姿勢とは、「生意気さ」を捨てることではなく、それを「建設的な提案力」へと昇華させることです。表現の仕方により一層の配慮と戦略を持ち、単に問題点を指摘するだけでなく、具体的な解決策まで考えて提示する。そして何より、自分の言葉に責任を持ち、提案した内容を自ら実行する覚悟を持つことが求められます。また、後輩や若手の「生意気さ」を受け止める側になることも、20代後半の重要な成長ポイントです。かつての自分がそうだったように、彼らの斬新な視点や率直な意見に耳を傾け、それを組織の力に変えていく橋渡し役を担うことも、中堅としての大切な役割なのです。忙しさと礼儀特に気をつけたいのは、「忙しさ」を言い訳にしないことです。確かに現代人は忙しい。締め切りに追われ、トラブル対応に追われ、新しい知識の習得に追われる。でも、忙しいからこそ、基本的な感謝の気持ちと礼儀を忘れないことが重要になる。忙しさを理由に基本的な礼儀を疎かにすることは、結果として自分の首を絞めることになりかねない。言葉遣いと礼儀は、特に意識して徹底するべき要素です。メールの書き方、電話での応対、会議での発言、日常の挨拶。これらは細かいことのように思えるかもしれないが、実は私たちの印象を決定づける重要な要素となる。特にビジネスの場面では、正しい敬語の使用や、適切な謙譲表現の選択は必須のスキルです。形式的に見えるかもしれないが、これらは相手への敬意を示す大切な手段なのです。その意味で、飲み会や食事会の後には必ず感謝のメッセージを送るようにしている。「お疲れ様でした」「楽しい時間をありがとうございました」といった一言を添えることで、その場限りの付き合いではない、継続的な関係性を築くことができる。これは形式的なものではなく、真摯な感謝の表現として大切にしている習慣です。そして、このメッセージを送る際も、文章の書き方や言葉選びには十分な注意を払う。カジュアルすぎない、かといって堅苦しすぎない、適切な距離感を保った表現を心がけている。当たり前の実践朝の挨拶を欠かさない、「ありがとう」を素直に言える、相手の話をきちんと聞く、約束した時間を守る、連絡はできるだけ迅速に返す。これらの「当たり前」を当たり前にできることが、結果として大きな差を生んでいく。チームでの開発作業において、この「当たり前」の積み重ねは、一見するとプロジェクトの成否には直接影響しないように見える。しかし、個人の評価には確実に、そして大きく影響する。なぜなら、これらは人としての基本的な信頼性を示す指標となるからです。見た目を良くするこれはあまり明示的に語られることはありませんが、見た目や匂いには細心の注意を払うべきです。技術力や専門性が評価される世界であっても、人間関係において見た目が及ぼす影響は想像以上に大きいものです。清潔感のある服装、適切な身だしなみ、そして不快な体臭がないことは、相手に対する最低限の礼儀と言えるでしょう。見た目と同様に重要なのが話し方です。声のトーン、話すスピード、適切な言葉選び、そして相手の目を見て話すことなど、コミュニケーションの「聞こえない部分」が相手に与える印象は非常に大きいものです。特に初対面の場では、あなたの発する言葉の内容以上に、どのように話すかが記憶に残ります。明瞭で落ち着いた話し方は、自信と誠実さの表れとして受け取られるでしょう。私自身、若い頃は「中身が大事」と考え、外見に無頓着でした。しかし、同じ意見や提案でも、見た目を整えた後の方が周囲からの反応が明らかに良くなったという経験から、その重要性を痛感しました。見た目は単なる表面的なものではなく、自己管理能力と他者への配慮を示すバロメーターとして機能しているのです。第一印象はわずか数秒で形成され、その後の関係性に長く影響します。ちょっとした意識と努力で、あなたのコミュニケーションの質は大きく向上するでしょう。人間関係の本質専門家は往々にして、専門的な複雑さに目を奪われがちです。技術的な課題の解決に没頭するあまり、人との関係性をおろそかにしてしまう。しかし、人と人との関係は、意外なほどシンプルなことで築かれていく。挨拶、礼儀、感謝。これらは決して「古臭い」概念ではない。むしろ、どれだけ時代が変わっても、人間関係の基本となる普遍的な価値なのです。特に注目すべきは、生成AIの進化によって、リモートでの円滑なコミュニケーションが当たり前となる時代が近づいている今こそ、対面での人当たりの良さがより一層重要になってくるという点です。なぜなら、それこそが人間にしかできない、真の意味での関係構築の証となるからです。変化の実感この「当たり前」を意識的に実践することで、予想以上の変化を経験した。組織内でのコミュニケーションが円滑になり、他部署との協力関係が築きやすくなり、困ったときに助けてもらいやすくなり、自分の提案が受け入れられやすくなった。これは決して「処世術」ではない。人として当たり前のことを、当たり前にやっているだけです。その積み重ねが、結果として大きな信頼関係を築いていく。特に印象的だったのは、この変化が単なる表面的なものではなかったことです。自分が誠実に接することで、周りの人々も同じように誠実に返してくれる。それは、まるで善意の連鎖のように、組織全体に広がっていった。組織で働く上で、この信頼関係の価値は計り知れない。小規模なチーム開発では個人の技術力でカバーできることも、組織として動く際には、信頼関係があってこそ初めて本当の力を発揮できるのです。人目がないときこそ、正しく行動せよ「誰も見ていないところでの行動が、本当の自分を表す」私は何度も誘惑に負けてきた。締め切りに追われるプロジェクトで手順を省略したり、上司がいないときにサボったり。「誰も気づかないから」という甘い考えに流されることは簡単だった。でも経験から学んだのは、そういった「小さなずるさ」が積み重なって自分の内側から蝕んでいくということ。一度ズルをすると、次はもっと簡単にできるようになる。それは一時的には楽でも、長期的には自分自身との約束を破ることになる。今でも完璧ではない。しかし、成長とは「誰も見ていないところでも良心に従う」努力を続けること。これは単なる道徳的な理想ではなく、自分自身を尊重するための実践だと気づいた。その選択の積み重ねが、やがて揺るぎない自信と内なる平和をもたらしてくれる。様々な文章を書ける表現力を磨く私はエンジニアとして長い間、文章に対してほとんど無頓着でした。「伝わればいい」とさえ思っていなかったのです。コードの正確さや機能性を追求するあまり、それを伝える「方法」にはほとんど関心を払っていませんでした。むしろ、「書いてるじゃないか」という認識だけで、文章の質に対する意識はゼロに等しかったのです。レビューで「もっと分かりやすく書いて」と指摘されても、「内容が正しければいいじゃないか」「本質的な価値があればいいではないか」と内心反発していました。しかし、経験を重ねるにつれ、この考えが大きな誤解だったことに気づかされました。技術力があっても、それを適切に伝える能力がなければ、その価値は半減してしまいます。特にエンジニアの世界では、コードを書く能力と同じくらい、自分の考えを文章で表現する能力が求められるようになってきました。リモートワークが一般化し、チャットやメールでのコミュニケーションが増える中、文章での表現力はかつてないほど重要になっています。技術的な説明を明確に書けるか、問題を簡潔に報告できるか、アイデアを魅力的に提案できるか。これらの能力は、あなたの専門性を正しく伝えるための必須スキルなのです。私自身、若い頃は「書いてあるじゃないか」という姿勢で、乱雑な文章や省略の多い報告をしていました。文章を書くこと自体が目的となり、相手に伝わるかどうかさえ考えていなかったのです。しかし、同じ内容でも、構成を整え、適切な言葉を選び、読み手の立場に立って書いた文章の方が、はるかに効果的であることを経験から学びました。ここで重要なのは、文章の価値を決めるのは常に読み手であるという視点です。いくら書き手が「ちゃんと書いてある」と満足していても、読み手がその文章から価値を見出せなければ、完全に意味がありません。どれだけ優れた技術や素晴らしいアイデアも、読み手に理解されなければ、実質的には存在しないも同然なのです。読み手がどのように受け取るか、どのような前提知識を持っているか、何に関心があるのかを常に意識することで、より効果的なコミュニケーションが可能になります。特に重要なのは、目的や相手に応じて文体を変える柔軟性です。技術文書では簡潔で正確な表現が求められる一方、企画書ではビジョンを伝える情熱的な言葉が必要になる。同じ内容でも、技術者向けと経営層向けでは、使う言葉や強調点が変わってくるのです。読み手によって「価値ある情報」の定義が変わることを理解し、それに合わせた表現を選ぶことが大切です。この表現力を磨くには、意識的な練習が欠かせません。日々の業務連絡でも、「どうすれば相手に伝わりやすいか」を常に考える。技術書だけでなく、様々なジャンルの本を読み、表現の引き出しを増やす。そして、書いた文章を見直し、より良い表現がないか考える習慣をつける。最終的には、自分が書いた文章が読み手にどう受け取られるかを想像できる共感力を養うことが重要です。結局のところ、表現力とは相手への思いやりなのです。自分の中に閉じた技術や知識を、相手が理解しやすい形で届ける。それは単なるスキルではなく、コミュニケーションの本質に関わる姿勢と言えるでしょう。文章は書き手の満足のためではなく、読み手が価値を見出すためにあるのです。読み手こそが最終的に文章の価値を決定する存在であることを常に意識し、技術者としての成長には、この表現力を磨く努力も不可欠なのです。言葉は必ず自分に戻ってくる私たちが日々発する言葉は、単なる空気の振動ではありません。それは自分の心の状態を映し出す鏡であり、同時に周囲の環境を形作る力を持っています。特に他者を見下したり、軽蔑したりする言葉は、その使い方を誤ると、思わぬところで自分自身に跳ね返ってくることに気づかされました。若い頃の私は、自分の技術力や知識に少しばかりの自信を持ち始めた時期に、時折「あの人は基本も分かっていない」「この設計は初心者レベルだ」といった評価を、軽々しく口にしていました。当時は単に技術的な指摘のつもりでしたが、そうした言葉が周囲にどのような影響を与えていたかを、後になって痛感することになりました。「初心者だから」という言葉で人を切り捨てる環境では、誰も初心者として一歩を踏み出す勇気を持てないのです。私自身、新しい技術に触れる際に「初心者と思われたくない」という恐れから、質問することを躊躇した経験があります。これは技術コミュニティにとって大きな損失です。誰もが最初は初心者であり、その段階を大切にする文化こそが、成長できる環境の基盤となります。批判的な視点そのものは、実は強力なツールでもあります。批判は薬と同じで、使い方次第で毒にも薬にもなるのです。適切に用いれば、プロダクトの品質向上やチームの成長につながります。重要なのは、その対象を「人」ではなく「アイデア」や「コード」に向けること。そして何より、建設的な代替案を提示することです。最も危険なのは、見下しの習慣が自分自身への過度な厳しさにも繋がること。他者に容赦ない人は、しばしば自分にも容赦なくなります。「初心者は存在してはいけない」という価値観は、自分が新しい分野に挑戦する際の大きな障壁となるのです。これでは成長どころか、安全な領域に閉じこもるしかなくなってしまいます。この負のサイクルから抜け出すには、意識的な言葉の選択が必要です。批判する際には「この部分はこう改善できるのでは」と具体的な提案を添える。初心者の質問には「良い質問ですね」と肯定してから回答する。そして何より、自分もかつては（そして別の分野では今も）初心者だという事実を謙虚に受け入れること。批判的思考と共感的コミュニケーションは、対立するものではなく、むしろ両方を適切に使い分けることで最大の効果を発揮します。厳しい指摘が必要な場面もあれば、励ましや支援が重要な瞬間もある。この使い分けの感覚を磨くことこそが、コミュニケーション力なのではないでしょうか。言葉は風の中に消えるものではなく、確実に自分の人生を形作る力となります。だからこそ、見下しの言葉という「呪い」ではなく、的確な指摘と温かい支援を使い分けるバランス感覚を育んでほしいと思っています。いい人を目指すこと最も重要なのは、これらの行動に「損得」を持ち込まないことです。見返りを求めて行う挨拶や感謝は、すぐに見透かされる。大切なのは、いい人になろうとする姿勢そのものです。完璧な「いい人」になることは難しいかもしれないが、その方向に向かって努力し続けることには大きな価値があります。与えることの素晴らしさは、それが自分自身も豊かにすることです。誰かの役に立とうとする気持ち、誰かを助けようとする姿勢、誰かのために動こうとする意志。これらは、結果として必ず自分に返ってくる。それは即座ではないかもしれないし、直接的な形ではないかもしれない。しかし、確実に人生を豊かにしてくれる要素となる。テクノロジーの世界でありながら、あるいはテクノロジーの世界だからこそ、この人間としての基本を大切にしていきたい。与えることを恐れず、むしろそれを喜びとできる人になること。それが、次世代のエンジニアたちに伝えていきたい、私からの最も大切なメッセージです。07. 質問力を磨く。そして、会話を楽にする「どうすれば会話が上手くなりますか？」—私も昔、そう必死に探していた。会話術の本を読み漁り、テクニックを試した。しかし......皮肉なことに気づいた。「効果的な質問手法」をマニュアル通りに実践しても会話は不自然になる。それどころか、相手にテクニックを使っている感が丸見えで、かえって距離が生まれてしまう。「じゃあ、質問のコツなんて意味ないの？」。そうではない。大切なのはテクニックではなく、相手への純粋な興味と理解したいという気持ち。この二つがあれば、自然と良い質問が生まれる。会話の本質は「キャッチボール」。一方的に話すのでも、ただ聞くだけでもなく、互いにボールを投げ合うこと。そして最も重要なのは、「質問には相手の価値を引き出す力がある」ということ。「でも質問すると、無知を晒すことになるのでは？」という恐れを持つ人もいる。確かに質問は自分の無知を認めることでもある。でも......それを恐れずに「知らないことを知りたい」と素直に表現できる人の方が、実は賢く見えるものです。良い会話の秘訣は、80%聴いて20%話すこと。そして、何より「今、この人の話を聞きたい」という気持ちを持つこと。テクニックよりも、その誠実な姿勢こそが、自然な対話力を育む。前章で触れた挨拶と礼儀は、人間関係の基礎となる大切な要素です。しかし、そこからさらに一歩踏み込んで、より深い関係性を築いていくために必要なのが、質問を中心とした対話力です。ここでは、日々の会話をより自然に、より実りあるものにしていくための具体的なアプローチについて、私の経験を共有していきたいと思います。コミュニケーションは、エンジニアにとって想像以上に重要なスキルです。一見、黙々とコードを書いていれば良いように思えるこの職業ですが、実際には質問を中心とした対話力が必要不可欠となります。私も当初は会話が苦手で、むしろ饒舌になりすぎて相手を疲れさせてしまうことが多かったのです。本質を見失っていた日々「質問力を高めよう」と思い立ち、関連書籍を読みあさった時期があります。しかし、「効果的な質問手法」をマニュアル通りに実践しても、会話はむしろ不自然になるばかりでした。本来あるべき、相手への純粋な興味や理解したいという気持ちが、テクニックの影に隠れてしまっていたのです。力まない会話の秘訣会話を続けるコツは意外にもシンプルでした。相手の言葉を適度に反復すること。これは単なる真似ではなく、相手の言葉を受け止め、理解しようとする姿勢の表れです。この技法は「リフレクティブリスニング」と呼ばれ、対話の質を高める効果的な方法です。「〜ということですね」と要約して確認することで、相手は自分の言葉が正確に理解されていると感じ、さらに話を続ける安心感が生まれます。また、たくさん話せば話すほど、印象に残らなくなるという事実にも気づきました。状況説明は他の人に任せ、自分は気の利いた一言で場を盛り上げる。そのほうが、はるかに効果的なのです。理想的には80%聴いて20%話すという比率を意識すると、相手中心の会話が自然と生まれます。会話のキャッチボール理論ではなく、物語として話を展開する。一つの話題をキャッチボールのように投げ合う。話を整理しすぎては面白くありません。むしろ、ひと言で終わりそうな話を、いかに膨らませていけるか。そこに会話の楽しさがあります。事実だけでなく、経験を物語として共有することで、抽象的な概念も具体的なエピソードとして相手に伝わります。この「ストーリーテリング」の力は、共感を生み、記憶に残る対話を作ります。相手の言葉に反応し、さらに話を展開させていく。この双方向のやり取りこそが、会話を豊かにしていきます。聞き手も話を膨らませる努力をする。それが、対話を深める鍵となるのです。自然な質問の流れ転機は、ある先輩エンジニアとの何気ない会話の中にありました。システムの問題について話す中で、自然と「具体的な症状は？」「他での発生は？」「最初の発生時期は？」と質問が続いていきました。意識的な技法ではなく、純粋な仕事の必要性から生まれた問いが、会話を自然に発展させていったのです。質問の質を高めるには、クローズド質問（はい/いいえで答えられる）とオープン質問（詳しい回答を促す）をバランスよく使うことが大切です。特に「なぜ」「どのように」「どう感じましたか」といった深堀りの質問は、相手の考えや感情に迫る機会を作ります。単なる事実確認を超えた質問が、対話の深みを増していくのです。沈黙を恐れない勇気良質な対話には、沈黙の活用も不可欠です。間（ま）を恐れず、それを思考の時間と捉える姿勢が重要です。多くの人は沈黙に不安を感じ、すぐに埋めようとしますが、焦って話題を変えず、相手の言葉を待つことで、より深い対話が生まれることがあります。沈黙の中から新たな気づきや本音が現れることも少なくありません。敬意から生まれる言葉相手を尊敬する気持ちを持てば、おのずと敬語を話したくなる。これは強制されるものではなく、自然と湧き上がってくる感情です。相手への尊敬の念があれば、適切な距離感も自然と保たれます。非言語コミュニケーションも対話の重要な要素です。アイコンタクトを適切に取り、うなずきや表情で反応を示し、姿勢や身振りにも気を配ることで、言葉以上のメッセージを伝えることができます。特にオンラインでのコミュニケーションが増えた現代では、こうした非言語的な要素を意識的に取り入れる工夫が必要になっています。背景知識が会話を豊かにする世の中に背景のない話はほとんど存在しない。「この会話、面白くないな」と感じるとき、その原因の多くはあなたが背景情報を知らないからである。ラグビーのルールを理解していなければ試合観戦も単なる人の集団が楕円形のボールを追いかけているだけに見え、映画の前作を見ていなければ続編の伏線や登場人物の関係性を把握できず魅力は半減する。つまり、情報量がないものは楽しくない。情報量が増えると会話はだいたい楽しくなるのだ。背景知識は会話の「文脈」を作り出し、言葉に豊かな意味と深みを与える。例えば、同じ「水曜日に会いましょう」という言葉でも、以前の約束を知っていれば「ようやく実現する待望の再会」という意味になり、相手の習慣を知っていれば「毎週の定例ミーティング」という意味になる。多様な分野の基礎知識を身につけ、特に関心のある分野については深く掘り下げることで、様々な場面や話題での会話に自信を持って参加できるようになる。しかし、すべての背景知識を持つことは不可能だ。むしろ大切なのは、知らないことを素直に認める勇気である。質問することは、無知を晒すのではなく、学ぶ意欲と知的好奇心を示す積極的な行為である。多くの人は自分の知識や経験を共有することに喜びを感じるため、真摯な好奇心を持って質問すれば、相手は熱心に知識を分かち合ってくれるだろう。仕事の場面でも、背景知識の共有は極めて重要だ。プロジェクトの経緯や過去の試行錯誤、組織の文化や暗黙のルールなど、これらの共通理解がなければ、チームは効果的に機能しない。新しく参加したメンバーが過去の経緯を知らずに提案を行い、「それは以前試して失敗した」と否定されるような場面も少なくない。背景情報の不足は、チーム内の分断や誤解、非効率の原因となりうる。質の高い対話は背景知識を増やし、増えた背景知識はさらに豊かな対話を可能にするという好循環を生み出す。会話が楽しくないと感じたら、それは背景知識の不足を示すサインかもしれない。その分野について積極的に学ぶ機会と捉え、書籍やオンライン記事、専門家との対話などを通じて知識を深めてみよう。知れば知るほど会話は面白くなる。そして、面白い会話は新たな知識への扉を開き、あなたの世界をさらに広げていくだろう。相手を認める対話質問には、相手の価値を引き出す力があります。「その解決策、面白いですね。どうやって思いついたんですか？」という問いかけは、単なる情報収集を超えて、相手の努力や工夫を認める意味を持ちます。これは決して追従ではなく、真摯に学ぼうとする姿勢の表れです。共感の表現を増やすことも効果的です。「なるほど」「確かに」といった言葉を適切に使い、相手の感情に寄り添う言葉を意識します。批判や否定から始めるのではなく、まず相手の立場や考えを受け止めることで、建設的な対話の土台が築かれていきます。相互成長の機会質問は、相手を知る窓ですと同時に、自分を成長させる機会でもあります。相手の答えから新しい視点を得て、自分の固定観念に気づき、より良い問いかけ方を学んでいく。対話の振り返りを習慣にすることで、この学びが深まります。重要な会話の後、何がうまくいき、何を改善できるか考える。特に印象に残った対話から学びを得る。定期的に自分の対話パターンを見直すことで、着実に対話力は向上していきます。完璧な質問を目指す必要はありません。大切なのは、相手への興味と敬意を持って、一つ一つの会話を大切にすること。その積み重ねが、自然な対話力を育んでいくのです。そして、この対話力こそが、前章で述べた礼儀作法とともに、信頼関係を築いていく基礎となります。対話と学びのバランス私たちの社会では、しばしば学力や専門知識の習得が重視される傾向にあります。確かに、専門的な知識や技術は現代社会で生きていく上で欠かせない要素です。しかし、それらの知識や技術を最大限に活かすためには、対話を通じて他者と協働する能力も同様に重要だと考えています。日本の歴史を振り返ると、かつての社会生活では、酒席での談笑や祭り、様々な社交の場で、人々は自然と対話の機会を持っていました。そこで培われたコミュニケーション能力と、教育で得た知識や技術が組み合わさることで、多くの人材が育ち、社会全体が発展してきた側面があります。現代では、デジタル化やリモートワークの普及により、直接的な対話の機会が減少しつつあります。その結果、優れた知識や技術を持ちながらも、それを効果的に伝え、共有し、協働に活かすことに課題を感じる人も少なくありません。特にエンジニアの世界では、この傾向が顕著に見られることがあります。対話が広げる可能性良質な対話には、専門分野や文化の壁を超える力があります。自分の知識や考えを相手に理解してもらえるよう伝え、同時に相手の視点や知見を受け入れる双方向のコミュニケーションは、新たな発見や創造を生み出す源泉となります。多様な背景を持つ人との対話は、新しい視点との出会いをもたらします。専門分野や文化的背景の異なる人との交流機会を意識的に作ることで、対話の幅が広がり、思考の柔軟性も高まります。新しいコミュニティに参加する勇気を持つことが、対話力向上の近道となります。エンジニアとしての経験から言えば、技術的に優れたソリューションも、それを適切に伝え、チームや顧客と共有できなければ、その真価を発揮することは難しいのです。逆に、基本的な技術でも、対話を通じてニーズを理解し、協働で作り上げていくプロセスを大切にすることで、大きな価値を生み出すことができます。対話の場を意識的に作る現代社会では、対話の機会を意識的に作り出す必要があるかもしれません。日々の業務の中で、単なる情報交換ではなく、互いの考えや感情を共有する時間を持つこと。オンラインでのコミュニケーションでも、対話の質を高める工夫をすること。休日や余暇の時間に、多様な背景を持つ人々との交流の場に参加すること。これらは、対話力を育む重要な実践となります。私自身、エンジニアとしてのキャリアを歩む中で、技術コミュニティでの交流や、異業種の人々との対話の機会を大切にしてきました。そうした経験が、自分の視野を広げ、思考の柔軟性を高め、結果として技術者としての成長にも大きく貢献したと感じています。これからの時間の使い方私たちの限られた時間をどう使うかを考えるとき、バランスの取れたアプローチが重要だと思います。専門知識や技術スキルを磨く時間はもちろん必要です。しかし同時に、対話力を高めるための時間も意識的に確保することで、より充実したキャリアと人生を築いていけるのではないでしょうか。専門知識は可能性を広げる道具であり、その効果的な活用には対話力が欠かせません。一方、対話力は協働と創造の基盤であり、多様な相手と共に価値を生み出すための土台です。両者のバランスを意識しながら、日々の時間を使っていくことが、個人としての成長だけでなく、チームや組織、ひいては社会全体の発展にも寄与するのではないかと考えています。対話力を高める実践対話力は、意識的な実践によって誰でも高めることができます。「聴く」ことを優先することから始めましょう。会話の中で自分が話す割合を意識し、相手の言葉に耳を傾ける時間を大切にします。メモを取ることで集中力を高めることも効果的です。好奇心を持って質問する姿勢も重要です。表面的な情報収集を超えて、相手の考えや感情に迫る質問を心がけます。「なぜ」という問いは、相手の価値観や思考プロセスを理解するための鍵となります。対話力の向上は一朝一夕には実現しませんが、日々の小さな意識と実践の積み重ねが、やがて大きな変化をもたらします。そして、その変化は自分自身の成長だけでなく、周囲の人々との関係性にも良い影響を与えていくのです。小さな日常の会話から意識的に実践することが大切です。失敗を恐れず、様々な対話の場に身を置き、優れた対話者の振る舞いを観察し学ぶことで、着実に対話力は向上していきます。完璧を目指すのではなく、相手への関心と敬意を持ち、一つ一つの会話を大切にすることから始めましょう。対話の価値を再認識する技術が進化し、AIが発達する現代において、むしろ人間特有の対話の価値は高まっていくと考えています。データや情報は機械でも処理できますが、人間からの共感や創造性に基づいた対話は、人間にしかできない貴重な営みです。対話とは、自分の意見を押し通したり相手の主張を無視したりするものではありません。論破なんて論外です。真の対話は、異なる視点を尊重し合い、互いの考えを深め合うプロセスです。そこには謙虚さと相手への敬意が不可欠であり、勝ち負けを超えた相互理解と共同成長こそが対話の目的なのです。エンジニアとして、また一人の人間として、対話を通じて他者とつながり、互いに学び合い、共に成長していく過程を大切にしたいと思います。それは単なるスキルアップではなく、より豊かな人間関係と社会を築くための投資なのです。最後に、この章で述べてきた内容も、一つの対話の試みです。読者の皆さんがこの文章を通じて何か新しい視点や気づきを得て、それを日々の実践に活かしていただければ、これ以上の喜びはありません。対話の扉は、常に開かれています。その一歩を踏み出す勇気を持つことで、新たな可能性が広がっていくことを願っています。08. 自分を知る。そして、才能を磨く。「自分を知る」—なんて簡単そうで難しいことだろう。鏡を見れば顔は分かるが、自分の内面は見えない。私たちはよく過去の投資に執着する。「もうこれだけ時間をかけたのだから...」という呪縛。しかし、今までにかけた時間や労力という過去の投資に執着することの危険性を理解すべきです。これを「サンクコスト」と呼ぶ。「でもそれは諦めることを正当化しているだけでは？」という反論が聞こえてきそうです。いや......そうではない。重要なのは「今この瞬間からの選択」であり、過去の投資に縛られて間違った道を歩み続けることこそ最大の損失なのです。職場でも、家庭でも、趣味の世界でも、環境に応じた自己の活かし方がある。山頂の松も、湖畔の柳も、それぞれの場所で美しく生きている。環境を変えるか、適応するか、その選択も自分次第です。現代では自己肯定が重視されるが、逆説的真理がある。無理に自己肯定感を高めるより、正当な自己批判に耐える力の方が大切だということ。「自分を責めるなんて有害じゃない？」と思うかもしれない。しかし......自己批判と自己否定は全く別物。一方は成長のための鋏であり、もう一方は根を枯らす毒です。自信は、自分の弱さを直視できる強さから生まれるのです。自分を知ることの難しさ「自分とは何者なのか」という問いの前で、誰もが一度は立ち止まります。特に20代は、この問いと激しく向き合う時期でしょう。「何に情熱を感じるのか」「どんな人生を送りたいのか」「自分にしかできないことは何か」—答えを探そうとすればするほど、その姿はかすんでいく。まるで、手の中の砂がこぼれ落ちていくように。内省の時間を作るこの迷いを解きほぐすには、意外にもシンプルな方法があります。日々の喧騒から離れ、自分と向き合う時間を意識的に作ることです。私は毎朝、日の出とともに近所の公園で15分だけ座る習慣があります。スマートフォンも持たず、ただそこにいる。最初は落ち着かなかったこの時間が、今では一日の中で最も大切な時間となりました。静けさの中で昨日を振り返る—誰かと話して心が躍ったこと、仕事で感じた充実感、些細な失敗への後悔。これらを丁寧にたどる時間は、単なる反省ではありません。むしろ、自分の心の声に耳を傾ける貴重な機会なのです。変化を恐れないこの内省の習慣から得た重要な気づきは、自分の興味や価値観は、絶えず変化しているということです。私のエンジニアとしてのキャリアを例に取ると、最初は純粋に技術そのものへの興味が原動力でした。新しい言語を学び、アルゴリズムを理解し、エレガントなコードを書くことに喜びを見出していました。深夜まで技術書を読み漁り、GitHubで面白いプロジェクトを見つけては夢中で実装する日々。しかし、キャリアを重ねるにつれて興味は形を変えていきました。「技術的に優れている」ことと「人々に価値を届けられる」ことは必ずしも一致しないという気づきがあったのです。次第に、技術がどのように人々の生活や仕事を改善できるのか、ユーザーが本当に必要としているものは何なのかという問いにより強く惹かれるようになりました。かつて「きれいなコード」にこだわっていた自分が、今では「使いやすいシステム」を追求しています。これは技術への情熱が薄れたわけではありません。むしろ、技術を活かすフィールドが広がり、より深い次元での探求が始まったのだと感じています。「私は」という檻を壊す自己理解を深める過程で最も警戒すべきは固定観念です。「私はこういう人間だ」という決めつけは、実は大きな制限を自分に課しているかもしれません。「人前で話すのは苦手」「創造的な仕事は向いていない」「もう年齢的に遅い」—こうしたラベルは、私たちの可能性を狭めてしまいます。実際には、人は想像以上に可塑性に富んでいます。40歳を過ぎてエンジニアになった人、50歳で起業した人、60歳で新しい趣味を見つけた人。人生に「遅すぎる」という概念はないのです。大切なのは、自分を固定的に定義せず、常に新しい可能性に開かれた心を持ち続けることです。「私は◯◯が苦手」ではなく、「今はまだ◯◯の経験が少ない」と捉え直してみましょう。標準化された道という比較的に自分にとって大きな罠私を含めて多くの人が「安全な道」を選ぼうとする。有名企業への就職、一般的なキャリアパス、世間的に認められた成功の形。でも待ってほしい。リスクがあるとすれば、自分という人間が持っている固有の偏りや特性を無視して生き方を決めることの方ではないか。横並びで標準化されたルートを歩いて、安全だと思っているかもしれないが、その方がかえって危険なのではないか。この危険性って何だろう。それは私たちの内側にある「衝動」を無視することにあるんじゃないかと思う。衝動とは、メリットやデメリット、コスパ、世間体とは関係のないところに向かう原動力。表面的な興味というより、本質的な情熱。他人や広告を見て生まれたような一時的な欲求じゃなくて、自分でも把握しづらい自分固有の欲望。皆が注目する最新技術よりも、なぜか古い言語の内部実装に惹かれたり。効率的なフレームワークより、車輪の再発明を楽しんでしまったり。キャリア的には「正しくない」選択かもしれないけど、その個人的で細分化された欲望—つまり「偏愛」—こそが、その人の本質を表しているんじゃないか。でも、ここで重要な警告をしておきたい。何もないところに衝動を見つけようとしすぎて、それを本物だと勘違いしてはいけない。実のところ、人間の欲望の多くはモデルに強く影響されている。SNSで見た誰かのライフスタイル、尊敬する先輩の選択、メディアで取り上げられる成功者の姿。私たちは知らず知らずのうちに、他者の欲望を模倣し、それを自分のものだと思い込んでしまう。「起業したい」「海外で働きたい」「最新技術を極めたい」—これらの欲望は本当にあなたの内側から湧き出たものだろうか。ここで大切なのは、「表面的な興味」と「本質的な情熱」を見分けること。表面的な興味は、他者から借りてきたもので、流行に左右される。一方、本質的な情熱は個人に内在する、説明しがたいけれど確かに存在する何か。問題は、この二つを区別することが想像以上に難しいということだ。だからこそ、標準的な道に乗っかることも時には重要なのです。無理に独自性を求めて迷走するより、まずは既存のレールに乗って基礎を固める。その過程で、自然と自分の偏りや特性が見えてくることもある。標準化されたルートは、決して悪ではない。それは多くの人々の試行錯誤の結果として確立された、ある種の最適解でもあるのだから。現代人の抱きがちな「寂しさ」は、私たちを抽象性や交換可能性へと導いている。誰とでも交換可能な「優秀なエンジニア」になろうとすることで、かえって自分の固有性を失ってしまう。でも同時に、独自性に固執しすぎて基本を疎かにするのも危険だ。表面的な興味を本質的な情熱へと変容させるためには、辛抱強く思考をめぐらす必要がある。即座に答えを求めるのではなく、じっくりと自分と向き合う時間。「なぜそれを望むのか」を5回、10回と問い続けることで、借り物の欲望は剥がれ落ち、本当に自分の中にあるものだけが残る。衝動が大まかな方向性を教え、知性が目的を形成したり手段を選んだりする。衝動だけじゃダメだけど、それを完全に抑圧することは、自分という人間の可能性を封印すること。重要なのはバランスです。衝動を無視することも、衝動を過大評価することも、どちらも危険。標準的な道を歩きながら、同時に自分の内なる声に耳を傾ける。模倣の欲望に流されすぎず、かといって独自性に固執しすぎない。標準化された成功の形を追い求めることは、一見すると確実で安全な選択に見える。でもそれは同時に、あなたにしかない衝動を殺してしまうことでもある。一方で、衝動という名の幻想に振り回されることも、同じくらいリスキーだ。大切なのは、自分の内なる声を無視せず、かつ他人が作った物差しにも適度に頼りながら、自分なりの道を見つけていくこと。この微妙な綱渡りこそが、自分らしい生き方を見つける道なのかもしれない。思い通りにならない現実と、「今まで頑張った」の呪縛から解放される勇気人生は教科書通りには進まない。これは誰もが知っていることなのに、実際に自分の計画が頓挫したとき、私たちはなぜこれほど打ちのめされるのだろうか。「頑張れば必ず報われる」「努力は裏切らない」—こうした励ましの言葉は時に有害になりうる。なぜなら、現実はもっと複雑で、時に残酷だからです。20代序盤で、学生の頃から学んでいたことが活かせない部署に配属された。会社の決定らしい、私にはどうすることもできない理由だった。それまでの膨大な時間と労力、そして何より情熱を注いできたものが一瞬にして意味を失った瞬間だと思った。私は茫然自失とした。これほど努力したのに、なぜ？その経験から学んだのは、「今までにかけた時間や労力」という過去の投資に執着することの危険性だった。経済学では「サンクコスト（埋没費用）」と呼ばれるこの概念は、実は人生の様々な場面で私たちを縛っている。「ここまで時間をかけたのだから、諦められない」「これだけ投資したのに、今更方向転換なんてできない」「長年続けてきたのに、今やめるなんてもったいない」こうした思考パターンは、危険ですなぜなら、過去にかけたコストは二度と取り戻せない。重要なのは、これからの時間と労力をどう使うかという未来志向の判断なのです。私の場合、その配属を転機に、新たな技術領域に挑戦することになった。最初は不本意だったが、結果的にそれが今の専門性を形作ることになった。今思えば、あの「挫折」がなければ、今の自分はなかっただろう。特に若いエンジニアが陥りがちなのは、特定の技術やキャリアパスに過度にコミットし過ぎることです。技術の世界は変化が激しい。今日の主流が明日には過去のものになることも珍しくない。そんな状況で、自分の選択に固執し続けることは、むしろリスクになりうる。もちろん、簡単に諦めることを推奨しているわけではない。困難に直面したときこそ踏ん張る力も必要です。しかし同時に、「今の道が本当に自分にとって最適なのか」を冷静に見極める目も不可欠なのです。サンクコストの呪縛から解放されるには、こう自問してみるといい。「過去の投資を全て忘れて、今この瞬間から選び直せるとしたら、同じ道を選ぶだろうか？」この問いに正直に向き合うことで、時に勇気ある撤退という選択肢が見えてくる。それは決して敗北ではなく、限られた人生という資源の、より賢明な使い方なのです。思い通りにならない現実を受け入れ、固執するのではなく適応する柔軟さ。それこそが、予測不能な時代を生き抜くための重要なスキルなのかもしれない。本質的な「楽しさ」を見つける固定観念から解放されると、新しい発見が訪れます。それは「心からの楽しさ」という感覚です。社会的な評価や周囲の期待ではなく、純粋に自分が心躍る瞬間を見つけること。私の場合、それは「物語を作ること」でした。子供の頃から空想の世界で遊ぶのが好きで、いつしかそれは文章を書くことへと発展していきました。仕事とは全く関係のない趣味でしたが、その創造的な時間が、結果として仕事での問題解決にも良い影響をもたらしました。純粋な楽しさを感じる活動には、不思議な力があります。それは無理なく長時間集中できる状態—フロー状態—を生み出し、創造性を高めてくれるのです。あなたが心から楽しいと感じる活動は何ですか？モチベーションの罠を避けるあまり広く認識されていない事実ですが、「モチベーションを高める」とされる文章や話のほとんどは実質的価値がありません。この文章も例外ではありません。一時的な感情の高まりに基づいた成長は持続しません。プロフェッショナルとは、その日の気分に関わらず、常に安定した成果を出すことができる人です。「今日はやる気がない」と言うことは、「今日は報酬に値しない仕事しかできない」と認めているようなものです。成長は、感情状態に左右されない一貫した習慣と自己規律から生まれます。気分が乗らない日があっても構いません。重要なのは、そんな日でも必要なタスクを完遂することです。成功する人と失敗する人の違いは、才能や環境ではなく、「不完全な状態でも行動を起こせるか」という点にあります。行動しない言い訳を見つけることには誰もが長けています。「いつかあの時やっておけば良かった」—この後悔の言葉は、単に行動しなかった証拠に過ぎません。未来は予測できないからこそ、今日の小さな一歩が重要なのです。「後でやろう」という言葉を口にするたび、あなたは可能性のドアを一つ閉ざしています。行動すべき時は、常に今です。「勉強したくない」という思いと向き合う技術業界にいると、「勉強が好きで仕方ない」人の話をよく耳にします。しかし実際には、多くのエンジニアが「正直、勉強したくない」と感じている のではないでしょうか。仕事で一日中コードと向き合った後、さらにプライベートの時間まで新しい技術を学ぶことに費やすのは、決して容易なことではありません。会社では「プライベートでは一切勉強したくない」と宣言する人もいれば、心の中でそう思いながらも口にはしない人も多いでしょう。この気持ちは決して特別なものではなく、むしろ自然な感情です。なぜなら、学ぶことは本質的に困難を伴い、快適な現状から抜け出すことを意味する からです。ここで重要なのは、「勉強したくない」という気持ちを否定せず、それを 自分のコントロールできない「感情」として客観視する ことです。誰でも「めんどくさい」と感じる日はあります。それを責めるのではなく、そういう日もあると受け入れた上で、どうすれば少しでも前に進めるかを考えることが大切です。よく見かけるのが、「勉強しない人」と「勉強する人」という二項対立的な見方です。しかし実際には、誰もが「勉強したい自分」と「勉強したくない自分」の間で日々揺れ動いている のです。成功しているように見える人も、常にモチベーション高く学び続けているわけではありません。彼らは単に、「勉強したくない日」をマネジメントするための習慣や仕組みを持っているだけかもしれないのです。例えば、「毎日最低15分はコードを書く」「週に1冊は技術記事を読む」といった 小さくて達成可能な習慣 を設定することで、モチベーションの波に左右されない学習パターンを確立できます。大切なのは「やる気になったらやる」ではなく、「やる気がなくてもできる仕組み」を作ることなのです。また、自分の興味や強みに合わせた学習方法を見つけることも重要です。書籍から学ぶのが苦痛なら動画学習を試してみる、一人で黙々と勉強するのが辛いなら勉強会に参加するなど、自分に合った形を模索する ことで、「勉強」という言葉が持つ重苦しさから解放されるかもしれません。現実的には、すべてのエンジニアが最先端技術に精通している必要はありません。むしろ、「勉強しないプログラマ」が全員「勉強するプログラマ」になるべきだとは限らない のです。様々な役割や得意分野を持った人材が混在することで、チームとしての強さが生まれます。大切なのは、自分の役割や価値を理解し、それに必要な知識を身につける意識を持つことでしょう。また、「勉強」という言葉自体が、不必要なプレッシャーを生んでいるケースもあります。「勉強」ではなく「探索」や「遊び」として技術に触れる姿勢を持つことで、心理的なハードルが下がることもあります。コードを書くことを「勉強」ではなく「創作」として楽しめれば、それはもはや苦痛ではなく喜びに変わる でしょう。「勉強したくない」という思いを持つことは恥ではありません。それを認めた上で、自分なりの学びの形を見つけていくこと。そして、小さな一歩を積み重ねていくことの価値を信じること。それが、長期的に見たときの本当の成長につながるのかもしれません。最も大切なのは、他者との比較ではなく、昨日の自分より少しでも成長すること に焦点を当てることです。あなたのペースで、あなたなりの方法で、一歩ずつ前に進んでいく。そんな地道な歩みこそが、遠回りに見えて実は最も確実な成長への道なのです。感情のマネジメント怒り、不安、嫉妬などの感情は誰にでもあります。問題は感情そのものではなく、その感情に支配されることです。感情が強く湧いたとき、「いま怒りを感じているな」と名前をつける習慣をつけましょう。これだけで感情と自分の間に距離が生まれます。さらに「この感情は何を教えてくれているのか」と問いかけると、成長のきっかけになります。例えば、同僚のコードレビューで強い不満を感じたとき、「今、私は怒りを感じている」と認識します。そして「なぜそれほど怒りを感じるのか」と掘り下げると、「自分の設計思想が理解されていないと感じたから」という本質が見えてくるかもしれません。感情を無視することと、感情に支配されないことは別問題です。感情を認識し、受け入れ、建設的に活用することが大切です。遊び心を失わない「楽しむ心」は、意外なほど強い力を持っています。真剣に取り組んでいるときでも、どこかに遊び心を忍ばせること。それは息苦しい緊張から私たちを解放し、新しいアイデアを生む土壌となります。「真面目」と「遊び心」は、決して相反するものではありません。むしろ、その両方を持ち合わせることで、人生はより豊かになっていきます。例えば、私は日記を書くときに、時々「10年後の自分」という架空の人物と対話します。現在の悩みや迷いを、未来の視点から眺めてみるのです。すると不思議と、今の問題が少し軽くなったように感じられます。この「遊び」のような習慣が、実は深い自己理解につながっていきました。遊び心は、固定観念を打ち破る力も持っています。「もしこの問題を全く違う業界の人が解決するとしたら？」「もし無限の予算があったら？」—こうした遊び心のある問いが、思いもよらない解決策をもたらすことがあります。他者の視点を借りる自分を知る旅には、良き仲間が必要です。なぜなら、私たちは自分自身を完全に客観視することはできないからです。家族、友人、同僚、時には見知らぬ人との出会い。それぞれの目に映る「私」は、少しずつ異なります。その違いこそが、自分の新たな一面を教えてくれるのです。かつて私は、自分の話し方が冗長で退屈だと思い込んでいました。しかし友人から「あなたの話には独特の温かみがあって、聞いていて心地よい」と言われたことがあります。その一言で、長年の自己否定的な思い込みが少し溶けていきました。他者の目は、時として私たちが気づかない才能を映し出す鏡となります。ただし、すべての意見を鵜呑みにする必要はありません。重要なのは、様々な視点を参考にしつつも、最終的な判断は自分で下すことです。他者の評価に振り回されない他者の意見や評価に過度に反応すると、自分の判断軸が揺らぎます。新人時代、私は上司の一言で一喜一憂し、批判に何日も落ち込んでいました。しかし、それが自分の成長を阻害していたことに後で気づきました。重要なのは、他者の意見を参考にしつつも、最終判断は自分で下すことです。これは他者を無視することではなく、適切な距離感を持って受け止めることです。実践として、フィードバックを受けたらすぐに反応せず、一晩置いて冷静に考えるという習慣が役立ちます。また、複数の視点から意見を聞き、多角的な判断をすることも大切です。「この人は何を根拠に言っているのか」「この意見は自分のどの部分に当てはまるのか」「これを取り入れると自分はどう変わるのか」—こうした問いを通して、他者の意見を自分の成長に活かす方法を見つけましょう。環境に応じた自己の活かし方自己理解を深めていく中での重要な気づきは、どんな立場にも固有の「ゲームのルールと勝利条件」が存在するということです。例えば、受験生の時期。このゲームでの「勝利条件」は明確で、限られた時間で最大限の得点を取ることです。得意科目に偏ることなく、受験科目全体のバランスを考えた戦略が求められます。大学生になると、ゲームのルールは大きく変化します。自由な時間が増え、「何を学ぶか」という選択肢も広がります。この時期のルールは「自分で価値を見出し、それを追求する力を養うこと」です。授業に限らず、サークル活動やインターンシップなど、自主的な学びの経験が、その後のキャリアの方向性を決定づけます。新入社員として入社すると、また異なるルールが待っています。ここでの「ゲームのルール」は、技術力だけでなく、チームへの適応力が重要となります。中堅エンジニアになると、ルールは更に変化します。プロジェクト全体を見渡し、技術選定や設計の提案を求められるようになります。この段階では、技術力に加えて、提案力とリーダーシップが重要な評価軸となります。この「ゲームのルール」を理解し、それに応じた戦略を練ることは、長期的な成長への近道です。時には自分の得意な働き方と環境がミスマッチを起こすこともあります。その場合、環境を変えることも一つの選択肢となるでしょう。大切なのは、そのゲームで勝つことではなく、自分らしい価値を最大限に発揮できる場所を見つけることです。社会という舞台で演じる役割この社会は現実ではなくて舞台だから与えられた役割をこなす必要があるみたいな側面があります。私たちは常に何らかの「役割」を演じています。会社では「エンジニア」や「マネージャー」、家庭では「息子」や「娘」、友人の輪では「聞き役」や「ムードメーカー」。これらは単なるラベルではなく、一種の期待と責任を伴う社会的な役割なのです。私たちは皆、この社会という巨大な劇場の中で自分の役を演じています。重要なのは、その役割に完全に同化することでも、それを完全に拒絶することでもなく、意識的に向き合うことです。与えられた役割を単に受動的にこなすのではなく、その中で自分らしさを表現する方法を見つけることが大切です。多くの人は自分の役割に違和感を覚えながらも、それを変える勇気が持てずにいます。「これが本当の自分ではない」と感じつつも、期待に応えようとする葛藤。この緊張関係こそが、実は成長の機会を秘めているのです。完全に役割に埋没するのでもなく、完全に拒絶するのでもなく、自分なりの解釈と表現で役割を果たしていく。そこに個性が生まれ、その積み重ねが独自の人生を形作っていきます。一見すると、社会の期待に応えることと自分らしく生きることは矛盾しているように思えます。しかし実際には、役割を理解し、それを自分なりに解釈して演じることで、より深い自己表現が可能になるのです。能楽師が型を習得した上でその中に独自の解釈を込めるように、私たちも社会という舞台で与えられた役割を通じて、自分自身を表現していくことができるのです。この舞台の上で、私たちはしばしば自分の演技の出来栄えと自分自身の価値を混同してしまいます。頭では「自分の能力と自分の価値は別物だ」と理解していても、心の奥では「うまく役を演じられないなら、自分に価値はないのでは」と不安になる。この葛藤は、知識として理解しただけで乗り越えられるほど単純なものではありません。理屈では分かっていても、感情的にその区別を保ち続けることは難しいのです。評価される社会に生きる以上、完全に「自分の価値」と「自分の能力」を切り離して考えることは、理想論でしかないかもしれません。むしろ、その二つの間で揺れ動く自分を認め、それでも前に進もうとする姿勢こそが、誠実な生き方なのではないでしょうか。役柄と俳優が完全に分離できないように、私たちも自分の役割と自己価値の間で常に揺れ動きながら生きていくのです。完璧な境界線を引けなくても、その曖昧さの中で自分らしさを見つけていく——それが私たちに許された、小さくも確かな自由なのかもしれません。最適な努力のポイントを見つける仕事でも自己成長でも、「頑張れば頑張るほど良い」という考えに縛られがちです。しかし実際には、努力と成果は必ずしも比例関係にありません。むしろ、ある一定のポイントを超えると、投入する労力が増えても成果は頭打ちになってしまいます。重要なのは、「どれだけ頑張るか」ではなく、「どこに力を注ぐべきか」を見極めることです。例えば、新しいプログラミング言語を習得する際、すべての機能を完璧に理解しようとするのではなく、まず実務で頻繁に使用される機能に焦点を当てる。そして、実践の中で必要に応じて知識を広げていく。この方が、遥かに効率的な習得が可能となります。私の経験では、「一度の努力で継続的な価値を生み出す」という視点が重要でした。例えば、業務の手順書を作成する際、単に手順を書き並べるだけでなく、その背景にある考え方や判断基準も含めて文書化する。これにより、後輩の教育時間が大幅に削減され、チーム全体の生産性が向上しました。自分を知り、才能を磨くプロセスにおいても同じことが言えます。むやみに時間を投資するのではなく、自分の強みを活かせる領域を特定し、そこに的確な努力を注ぐ。それこそが、持続可能な成長への近道となるのです。フィードバックを活用する環境やゲームのルールを理解するだけでは不十分です。自分がそのルールに沿った行動ができているのか、定期的な振り返りとフィードバックの分析が不可欠です。環境は私たちに様々なフィードバックを与えてくれます。受験生なら模試の結果や志望校偏差値との距離。大学生なら単位取得状況や研究成果。新入社員なら業務評価やチームからの信頼度。中堅エンジニアならプロジェクトの成果や後輩の成長度合い。これらの信号は、その「ゲーム」における自分の立ち位置を正直に教えてくれます。時として、それは耳の痛い評価かもしれません。しかし、そこには必ず成長のためのヒントが隠されています。重要なのは、これらのフィードバックを恐れず、むしろ積極的に求めていく姿勢です。週単位、月単位、年単位で自分の立ち位置を確認し、必要に応じて戦略を修正していきましょう。振り返りの際に問うべきなのは、「今の環境で求められていることに対して、自分は正しい行動ができているか」という点です。時には自分の想定と異なる評価に戸惑うこともあるでしょう。しかし、その「ずれ」こそが、新たな気づきと成長の機会をもたらしてくれます。弱みと向き合う強みを伸ばすと同時に、弱みを直視することも重要です。私も長い間、自分の弱点から目を背けてきました。それでも、いつかは向き合わなければならない時が来ます。弱みを見つめる際には、まず感情を切り離して事実として認識することが大切です。「私はダメだ」ではなく「このスキルが不足している」と捉えましょう。次に具体的な改善計画を立て、安全な環境で練習を重ねる。そして定期的に進捗を振り返ることで、着実な成長を促すことができます。例えば、私はコードレビューでの指摘に感情的になりやすいという弱みがありました。これを「私はダメなエンジニアだ」と結論づけるのではなく、「批判を建設的に受け止めるスキルが不足している」と捉え直しました。そして小さなレビューから始め、徐々に規模を大きくしていくという練習を積み重ねていきました。弱みの克服には時間がかかります。しかし粘り強く取り組めば、かつての弱みが新たな強みに変わることもあります。自己否定と向き合う強さ私は20代を終える頃、「無理に自己肯定感を高めるより、正当な自己批判に耐える力の方が大切だ」という確信を持つようになりました。人生では調子のいい時も悪い時もあり、ただ自分を褒めることは時に現実逃避になりかねません。現代社会では「自己肯定感を高めよう」というメッセージがあふれています。SNSでは「自分を愛そう」「あなたはそのままで素晴らしい」という言葉が飛び交い、いろんな歌は「ポジティブシンキング」の重要性を説きます。正直に言えば、こういった自己肯定感を礼賛する風潮には強い違和感を覚えます。 根拠のない自信や実力以上の自己評価は、時として成長を妨げる障壁になりかねないからです。むしろ「自分はまだまだだ」という謙虚さこそが、本当の強さを育む土壌になるのではないでしょうか。転機となったのは、ある先輩エンジニアの何気ない言葉でした。「優れたエンジニアは、自分の限界を正確に知っている」。この言葉は、自己否定を避けるのではなく、それと正面から向き合うことの大切さを教えてくれました。自分の弱さや不完全さを認めることは、決して自己否定に埋もれることではありません。むしろ、現実的な自己認識こそが、本当の成長の出発点なのです。「まだ足りない」という認識があるからこそ学び続けられるし、「ここが弱い」と分かっているからこそ、そこを補強する努力ができる。大切なのは、自己否定と自己破壊を区別することです。自己否定は「この部分はまだ足りていない」という冷静な認識であり、成長への道標となります。一方、自己破壊は「自分はダメな人間だ」という全人格的な否定であり、これは避けるべきです。20代の終わりに至って、私は「自己否定の力」に新たな価値を見出しています。華やかな成功物語では語られない、地味で辛い自己否定の時間。それに耐え、そこから学び取る力こそが、長期的な成長と強さを育むのだと信じています。根拠のない自己肯定よりも、徹底的な自己否定を経た上での確かな自信。 それが、私が20代で得た最も価値ある教訓の一つかもしれません。自分で考え、自分で決める若い頃は常に「正解」を求め、上司や先輩の承認を待っていました。しかしプロフェッショナルは「自分で考え、自分で決める」ことから始まります。転機は、上司不在で即断即決を求められた場面でした。完璧ではなかったものの、その経験が大きな自信となりました。大切なのは結果より、自分の決断に責任を持つプロセスです。「まず自分の答えを持つ」習慣をつけ、「なぜそうなのか」「他の可能性は？」と常に問いかけましょう。自分の思考を信じる勇気が、あなたを成長させます。判断を委ねることは、時に楽に思えます。しかし、それでは永遠に他者の影に隠れたままです。最初は小さな決断から始めて、徐々に範囲を広げていきましょう。失敗したとしても、その経験が次の判断材料となり、徐々に自分だけの判断軸が育っていきます。真摯な自己との対話最後に、そして最も大切なことは、ゲームのルールと自分の価値観の調和を探ることです。世間の評価や周囲の期待に惑わされず、その環境で自分が本当に実現したいものは何かを見極めましょう。それは必ずしも大きな決断や劇的な変化を意味しません。日々の小さな選択の積み重ねの中に、実は本質的な答えが隠れています。そのためには定期的な振り返りが欠かせません。その環境での成果、自分の成長、そして心の満足度。これら三つの観点から自分の状況を分析することで、現在の立ち位置と次に取るべきアクションが見えてきます。時には環境を変える決断も必要かもしれません。しかし、それは逃避ではなく、より良い成長のための戦略的な選択となるはずです。才能を育む土壌づくり才能は、決して一朝一夕に開花するものではありません。それは、環境の理解と自己の成長、そしてその記録と分析の積み重ねの中で、ゆっくりと育まれていくものです。ここで重要なのは、その成長のプロセスを「ゲームクリア」のような短期的な目標ではなく、「新しいステージへの挑戦」として楽しむ心持ちです。特に、才能を育むための努力を持続可能なものにするには、その仕組みを理解する必要があります。人間の行動は「きっかけ→欲求→反応→報酬」という4段階で形成されます。例えば、技術書を読むという習慣一つとっても、「本を目に付く場所に置く（きっかけ）」「新しい知識への興味（欲求）」「実際に読む（反応）」「理解の深まり（報酬）」というサイクルが存在します。この法則は良い習慣だけでなく、悪い習慣にも当てはまります。SNSに没頭してしまう習慣も「通知（きっかけ）」「つながりたい欲求（欲求）」「アプリを開く（反応）」「いいねやコメント（報酬）」という同じ構造を持っています。この仕組みを理解することで、望ましい習慣を育て、望ましくない習慣を改善する戦略が見えてきます。私たちは誰しも、独自の才能と可能性を持っています。それらは時として、思いもよらない形で花開きます。だからこそ、自分らしさを大切に育てながら、新しい可能性を探る勇気を持ち続けましょう。最も大切なのは、現状に満足せず、かといって自分を否定せず、一歩ずつでも着実に前進し続けることです。あなたの可能性は、あなた自身が思っている以上に広がっているのですから。09. メンターを見つけ、学び方を学ぶ。成長には、誰かの存在が必要だ。私は20代を通じて、この単純な事実を幾度となく実感してきた。独学には限界があり、メンターの存在は成長の触媒となる。「自来也みたいな師匠(メンター)が欲しい」—多くのエンジニアが抱く願望。だが、良いメンターとの出会いは、意外なところにある。まず警告したいのは、メンターになりたいと積極的に申し出てくる人には要注意ということ。自ら「指導してあげよう」と言う人は、往々にして自己顕示欲が強く、あなたの成長より自分の満足を優先する傾向がある。「じゃあ、どうやって見つければいいの？」という疑問が湧くだろう。実は......形式的な「メンター制度」よりも、日々の仕事や交流を通じて自然に育まれる関係の方が価値がある。「理想的なメンターなんて、現実には存在しないよ」という声も聞こえてきそうです。確かに完璧なメンターを探す必要はない。技術を教えてくれる人、キャリアを相談できる人、人生の指針を示してくれる人—それぞれ......別の人かもしれない。メンターシップの本質は「一対一の関係」に限らない。様々な人から学び、それを自分の中で統合していく。それもまた立派なメンター体験です。そして自分がメンターになる日が来たら、「相手を自分より優秀だと思って接し、自分より繊細だと思って言葉を選ぶ」こと。これは相手の可能性を信じ、その成長を支える最も重要な姿勢です。メンターは指導者である前に、まず応援者であれ。メンターとの出会い人生で最初のメンターは、12歳の時に出会った義理の父だった。車でドリフトを体験させてくれたり、ゲームセンターで偶然会って一緒に遊んでくれたり。大人と子供の境界線を軽々と越えていく人だった。私は人と話すのは得意だったが、誘うのは苦手だった。でも義父は違った。圧倒的な主体性の塊で、断られても「じゃあ今度な！」と軽く流す。営業職だと聞いて納得した。「この人には勝てない」と思ったが、それは清々しい諦めだった。自分は違う道で勝負しようと気づかせてくれた。義父から学んだのは「大人になるのも悪くない」という希望。人間的にも肉体的にも大きな人だったが、何より心が大きかった。子供心を忘れない素敵な人だ。社会人になってからは、教育担当の先輩社員との出会いがあった。外に出たりはしないが確かな技術力と優れた洞察力を持ち、形式的な指導関係から、かけがえのないメンターシップへと発展した(ボクは今でもそう思ってますよ！！！)。ここで重要な注意点があります。「メンターになりたい」と積極的に申し出てくる人には要注意です。優れたメンターは自分からそんなことは言わない。押しつけがましく「指導してあげる」と言う人は、往々にして自己顕示欲が強く、相手の成長より自分の満足を優先する傾向があります。義理の父も先輩も、決して「教えてあげよう」なんて言わなかった。ただ背中を見せ、必要な時にそっと手を差し伸べてくれた。良質なメンターシップは、日々の交流を通じて自然に育まれるものなのだ。それ以降も、私は素晴らしいメンターとの出会いに恵まれてきた。彼らに共通するのは、メンター面をせず、ただ真摯に後進の成長を支援する姿勢だった。今でも義理の父と先輩社員には心から感謝している。彼らがいなければ、私は「大人になること」「エンジニアとしてやっていくこと」に希望を持てなかったかもしれない。最初のメンターとの出会いが、その後の人生でどれほど多くの素晴らしい出会いを引き寄せてくれたか。その連鎖は、今も続いている。あの人もこの人もメンター重要なのは、形式的な依頼をする必要がないということです。「メンターになってください」という言葉は、むしろ関係性を不自然なものにしてしまう。日々の何気ない会話や、仕事を通じた交流の中で、自然と学びの関係は育まれていく。自分が影響を受けるものを自分で選んでいたら、都合の良い自分にしかなれません。むしろ、意図していなかった場所や人から思わぬ学びを得ることが、本当の成長につながるのです。メンターは必ずしも自分が想定していた形で現れるとは限りません。また、メンターとの関係は、固定的である必要もない。時には学ぶべきことを学び、その関係性が自然と変化していくこともあります。それは決して否定的なことではなく、互いの成長を示す証です。学びの多様性完璧なメンターを探す必要はない。これは経験から得た重要な気づきです。技術的な指導者、キャリアの相談相手、人生の先達。それぞれの存在が、異なる角度から私の成長を支えてくれた。特に印象的だったのは、自分より年下のマネージャーとの出会いです。最初は戸惑いもあったが、その経験は「年齢や立場にとらわれない学びの本質」を教えてくれた。知恵は、必ずしも年齢とは比例しない。異なる価値観から学ぶ私の最も大きな学びの一つは、新卒時代に出会った先輩エンジニアとの関わりからだった。その方は、圧倒的な技術力を持ちながら、「仕事はあくまでお金を稼ぐ手段」と明確に割り切っていた。当時の私にとって、それは衝撃的な価値観だった。技術への追求と仕事への向き合い方は、必ずしも比例しないということを、身を持って教えられた瞬間だった。特に印象的だったのは、その先輩が趣味の音楽活動に情熱を注いでいる姿だった。仕事では徹底的なプロフェッショナリズムを見せながら、プライベートでは全く異なる顔を持つ。この出会いは、私に重要な気づきをもたらした。メンターと自分は、必ずしも同じ価値観を持つ必要はないということです。むしろ、その価値観の違いこそが、新しい視座を与えてくれる。この経験から、私は学びの本質について深く考えるようになった。メンターから学ぶべきは、必ずしもその人の価値観や生き方の全てではない。技術的な知識、問題解決のアプローチ、そして時には「自分とは異なる生き方があること」そのものが、貴重な学びとなる。人生における選択肢の多様性を知ることは、それ自体が重要な成長なのです。メンターをクビにしろメンターとの関係は、時とともに深まっていく。最初は教えを請う立場から始まり、やがて技術的な議論ができる関係へ。そして気がつけば、互いの人生について語り合える存在となっている。私の場合、この変化は自然な流れの中で起きた。指導を仰ぐ機会が徐々に減り、代わりに「こう考えたのですが、どう思いますか？」という対等な対話が増えていった。それは劇的な変化ではなく、信頼関係の着実な深まりを示す証だった。劇的な変化を求めるな、幻想を抱くのはもうやめろ。メンターについて語るとき、多くのエンジニアが抱く幻想がある。「運命的な出会い」「人生を変える師匠」「一発逆転の教え」—こんな甘い妄想は、技術業界にまん延する 最も有害な思い込み の一つだ。現実を直視しよう。あなたの人生を劇的に変えてくれるような魔法の師匠など存在しない。あなたが成長できないのは、「良いメンター」に出会えていないからではなく、単にあなた自身が十分に努力していないだけ だ。「いつか素晴らしいメンターと出会えれば...」という思考は、自分の怠慢を正当化するための言い訳 に過ぎない。「あの企業のあの人に教わりたい」と夢想する時間があるなら、今すぐ目の前のコードを書け。本を読め。問題を解け。テック業界には「師弟物語」が蔓延している。偉大な師との出会いで一夜にして凡人が天才に変わる—そんな物語に酔いしれるのは、もうやめるべきだ。現実のメンター関係は、劇的な瞬間ではなく、退屈で地道な日々の積み重ね から成り立っている。華やかな成功事例ばかりが語られるが、その裏には無数の地味な努力があることを忘れるな。良いメンターの真の価値は、あなたに 「魚を与える」のではなく「釣り方を教える」 ことにある。技術だけを教えるメンターなど、ほとんど価値がない。なぜなら技術は常に変化し、今日の知識は明日には陳腐化するからだ。真に価値あるメンターは、あなたの思考方法を変え、自律的に学ぶ能力を鍛えてくれる人 だ。そして、それは決して派手な変化ではない。現実を見ろ。偉大なエンジニアの多くは、特別なメンターがいなくても自力で成長してきた。彼らは「誰かに教えてもらおう」と受け身でいるのではなく、積極的に学び、実践し、失敗から学ぶサイクルを繰り返してきた のだ。「あの人に教わりたい」と思うなら、その人のブログを読め。オープンソースのコードを研究しろ。カンファレンスの動画を見ろ。その人の考え方を理解し、自分のものにするために実践しろ。待っているだけの「弟子志願者」に価値はない。厳しい現実だが、メンターはあなたの人生の責任を取ってくれない。どんなに素晴らしいメンターと出会えても、結局は 自分で考え、自分で決断し、自分で行動する勇気 がなければ何も変わらない。最も危険なのは、「良いメンターがいない」という言い訳で、自分の成長を止めてしまうことだ。周りを見渡せば、学ぶべきことを持った人はたくさんいる。公式なメンター関係でなくても、日々の仕事の中で、レビューを通じて、会話を通じて、常に学べる環境はそこにある。それを見ずに「特別な誰か」を探し続けるのは、単なる成長拒否 に過ぎない。メンターに対する幻想を捨て、現実的な期待を持て。そして何より、自分の成長に対する責任は、最終的に自分自身にある ことを忘れるな。どんなに優れたメンターでも、あなたの代わりに努力してくれることはないのだから。劇的な変化を求めてさまよい続けるより、今日この瞬間から、地道でつまらなく見える一歩を踏み出す方が、はるかに賢明な選択だ。学び続ける姿勢エンジニアとして最も警戒すべきは、「もう十分知っている」という慢心です。特に若い世代は、新鮮な視点と驚くべき吸収力を持っている。彼らの好奇心、従来の常識にとらわれない発想、素直な学習姿勢から、私たちは多くを学べる。時には、「学ぶことを恥じない勇気」さえも。学びの本質メンターとの関係を通じて、私は「学び方」そのものを学んです。効果的な学習は、単なる知識の詰め込みではない。それは観察と理解から始まり、実践と失敗を重ね、経験を振り返って改善し、新たな挑戦へと向かう終わりのない旅路です。「完璧なメンターを探すのではなく、あらゆる出会いに学びのチャンスを見出してほしい」。これが私からのメッセージです。そして、いつか自分も誰かの成長を支える存在となれることを願っている。それこそが、最も美しい知識と経験の継承の形なのだから。テクノロジーの進化により、学びの形も多様化していくだろう。しかし、それは決して人と人との関係性の価値を否定するものではない。むしろ、人間同士でしか得られない気づきや成長の機会を、より一層大切にしていく必要がある。それこそが、これからの時代における学びの姿なのです。自分のことを棚に上げる矛盾気がついたら「後輩」と呼ばれる立場になっていた。私がそう気づいたのは、入社して5年目の冬だった。新メンバーが配属され、チームリーダーからさりげなく言われた一言。「彼の面倒をちょっと見てもらえるかな」。その何気ない依頼に、戸惑いを隠せなかった。つい最近まで、自分の方が教わる側だったはずなのに。まだ自分自身が成長の途上、むしろ日々の業務をこなすので精一杯な状態で、どうやって他者を導くことができるのだろう。この「棚に上げる感覚」、つまり自分はまだ未熟なのに他者を指導する立場になるという矛盾に、最初は強い違和感を覚えた。完璧を装わない誠実さと信頼の両立優れたメンターになるために必要なのは、完璧な知識や能力ではない。むしろ重要なのは、自分の不完全さを認めながらも信頼される存在になるという微妙なバランスです。私が心がけたのは「完璧でなくてもいいことを先に伝える」ことだった。新しい後輩との最初の会話で「私もまだ学び続けている途上だから、分からないことも多いけれど、一緒に成長していけたらいいな」と率直に伝えた。この一言で、お互いの関係性はより対等で健全なものになった。しかしただ弱さをアピールするだけでは信頼は築けない。重要なのは、基本的な仕事はきちんとこなす姿勢を見せることです。質問には誠実に答え、約束したことは必ず実行し、自分が担当する部分の仕事は確実に完了させる。そうした日々の積み重ねが、「完璧ではないけれど信頼できる」というメンターの理想像につながるのです。特に印象的だったのは、ある技術的な質問に答えられなかった時の経験です。「申し訳ない、それは今すぐ答えられないけど、明日までに調べて共有するよ」と正直に伝え、翌日には詳細な調査結果をまとめて説明した。実はこの経験が、かえって信頼関係を深めることになった。「分からないことをごまかさない」という姿勢こそが、頼れるメンターなのだと気づかされた瞬間だった。自分より優秀だと思って接し、自分より繊細だと思って言葉と行動を選ぶ転機は、ある先輩の何気ない助言だった。「メンターは二つの姿勢を持つべきです。相手のポテンシャルに対しては自分より優秀だと思って接し、相手の気持ちには自分より繊細だと思って言葉と行動を選ぶ」これは単なる処世術ではなく、深い洞察に基づいた智恵だった。「相手を自分より優秀だと思って接する」というのは、相手の無限の可能性を信じる姿勢です。何も知らない状態から始まっても、適切な環境と支援があれば、いずれ自分を超える存在になるかもしれない。その可能性を信じて接することで、相手の潜在能力を引き出せるのです。一方、「相手を自分より繊細だと思って言葉と行動を選ぶ」というのは、学びの途上にある人の心理状態への配慮です。新しいことを学ぶ過程は常に心理的に脆弱な状態となる。何も分からない不安、失敗への恐れ、否定される恐怖、自己否定の感情。私たち自身が経験してきたそれらの感情を想像し、言葉と行動を選ぶことが必要なのです。自分の知識の穴と向き合う指導する立場になると、自分の知識の穴が鮮明に浮かび上がる。基本的な質問に答えられず冷や汗をかいたり、「なぜそうなるのか」の理由を説明できなかったり。メンターになるということは、実は自分の無知と向き合う旅でもある。この経験から学んだのは、「分からないことは分からないと正直に伝える」勇気の重要性だった。「それは調べてみます」と率直に答え、一緒に解決策を探す姿勢。これは決して恥ずべきことではなく、むしろ学び続ける姿勢を示す好機となる。時には答えを出さず、一緒に考える時間を作ることも大切です。全ての質問に即答するのではなく、「それについて、あなたはどう思う？」と投げ返すことで、相手の思考力を育てる機会になる。教えることで学ぶ「教えることは二度学ぶことである」という言葉があります。これは本当だった。コードレビューで説明するために自分の理解を整理したり、質問に答えるために改めて基礎から学び直したり。メンターになることで、自分自身の知識が格段に深まっていくのを実感した。それまで漠然と理解していたことを言語化する過程で、自分自身の理解の浅さに気づくことも多かった。特に印象的だったのは、後輩との対話から得る新しい視点です。従来の方法に疑問を投げかけ、「なぜこうしないのですか？」と問われることで、当たり前だと思っていた前提が揺らぐ。この相互作用こそが、組織の成長とイノベーションの源泉なのだと気づかされた。心の距離感を大切にメンターシップで最も難しいのは、適切な距離感の維持です。近すぎれば客観性を失い、遠すぎれば信頼関係は育たない。ある後輩との関係では、「友達のように接する」ことを心がけたことで、かえって関係が複雑になってしまった。仕事上の指導や評価に、感情的な要素が入り込み、お互いに不快な思いをしたことがあります。逆に、別の後輩には距離を置きすぎたために、本当に困ったときに相談してもらえず、問題が大きくなってから発覚したこともあった。理想的な距離感は一律ではなく、相手によって異なる。大切なのは、「この関係は相手の成長のためにある」という原点を忘れないことです。自分の承認欲求や支配欲を満たすためではなく、あくまで相手が自律的に成長するための足場かけが目的なのです。「教える」から「引き出す」へメンターとしての最大の学びは、「答えを与える」から「引き出す」へのシフトだった。初期のころは、質問されるとすぐに答えを提供していた。それは効率的に見えたが、長期的には相手の成長を阻害していることに気づいた。なぜなら、学びは自ら考え、発見するプロセスにこそあるからです。「こうするべき」と指示するのではなく、「どうしたいと思う？」と問いかける。「これは間違い」と指摘するのではなく、「この方法にはどんな問題があると思う？」と考えさせる。このアプローチは時間がかかるように見えて、実は最も効率的な学びを生み出す。失敗から学ぶ機会を奪わない最も難しかったのは、失敗させる勇気を持つことだった。後輩がミスしそうなコードを書いているとき、すぐに修正を求めるべきか、それとも経験から学ばせるべきか。この判断は常に難しい。プロダクションに影響するような重大なミスは防がなければならないが、小さな失敗からの学びは貴重です。私が心がけたのは、「安全に失敗できる環境」を作ることだった。「このアプローチには問題があるかもしれないが、試してみたらどうだろう？」と促し、結果から一緒に学ぶ。あるいは「本番環境では危険だが、検証環境で試してみよう」と提案する。最も価値ある教訓は、しばしば失敗から得られる。その機会を奪わず、むしろ安全に失敗し、そこから学べる環境を整えることが、メンターシップなのだと学んです。あなたもメンターになる日「メンター」という特別な称号を待つ必要はない。誰もが誰かに影響を与え、誰かから学んでいる。私がメンターとして未熟だった頃、ある後輩が言ってくれた言葉が今でも心に残っている。「先輩の失敗談から、たくさん学ばせてもらっています」。私の不完全さ、試行錯誤の過程そのものが、彼にとっては学びになっていたのです。あなたもきっと、誰かのメンターになる日が来る。そのとき、完璧を目指す必要はない。自分自身も成長途上であることを認め、相手と共に学ぶ姿勢を持つこと。そして、相手を自分より優秀だと思って接し、自分より繊細だと思って言葉を選ぶこと。最後に、一つだけ約束してほしい。あなたが受け取った知識と経験を、次の世代に引き継ぐと。それこそが、私たちエンジニアの文化と知恵を未来につなぐ、最も価値ある贈り物なのだから。10. 読書をする。そして、知識を実践に移す。「エンジニアに読書は必要か？」という疑問は意外と多い。検索や生成AIで何でも調べられる時代に、読書とプログラミングには実は深い共通点がある。どちらも情報を処理して意味を抽出する知的作業であり、優れた文章を読む力は良いコードを読む力にも通じる。確かに情報収集の速さでは検索や生成AIに勝てないが、本には著者の思考プロセスという貴重な宝が詰まっている。技術書を読むことは単に知識を詰め込むのではなく、問題解決という筋肉を鍛えることであり、様々な考え方に触れることで自分のアプローチの引き出しが増えていく。同様に、小説や歴史書、哲学書などの幅広いジャンルを読むことで、異なる視点や発想法を学び、創造性や共感力も高められる。最も重要なのは「知っているつもり」と「本当に理解している」の違いで、この差を埋めるのが「実践」です。知識を実際に使ってみて初めて本当の理解が生まれるので、本から得た知恵の種を実際の土壌に植え、育てていくべきだろう。幼い頃から物語が大好きで図書館で何時間も過ごした私が「読書をしましょう」と言うのは、魚が「泳ぎましょう」と言うようなものかもしれないが、本との出会いがエンジニアとしての私の人生を何度も変えてきたからこそ、あえて読書の大切さを語りたい。読書とプログラミング読書とプログラミングには深い共通点がある。どちらも情報を処理し意味を抽出する知的作業です。私たちエンジニアは業務の大半をコードを読むことに費やしているが、皮肉なことに「読む」よりも「書く」ことに意識が向きがちです。優れた文章を読むスキルとコードを読むスキルには驚くほどの類似性がある。重要な部分を見極める力、全体構造を把握する力、背景知識を活性化させる能力、不明点を自問自答する習慣—これらは両方の領域で価値を持つ。私が難解なコードに向き合うとき、それはまるで複雑な哲学書を読むような体験です。最初は理解できなくても、何度も読み返すことで全体像が見えてくる。「わからなさ」と向き合う勇気が、プログラマーにとっても読書家にとっても成長への鍵となる。興味深いことに、自然言語への感覚が鋭い人は、プログラミング言語の習得も比較的容易にこなすことが多い。言語パターンを認識し構造を理解する能力は、それが人間の言語であれ機械の言語であれ、共通の基盤を持つようです。読書習慣とプログラミングスキルには相乗効果がある。多様なジャンルの本を読むことで培われた想像力は、革新的なアルゴリズムやシステム設計の発想源となる。逆に、プログラミングで鍛えた論理的思考は、複雑な文章を解読する助けになる。若いエンジニアには「コードを書く前に、まず多くのコードを読め」とアドバイスしたい。そして同時に「技術書だけでなく、小説や歴史、哲学にも触れよう」とも伝えたい。この両輪こそが、創造性豊かなプログラマーを育てる土壌になると信じている。読書の多様性を楽しむ技術者としてのキャリアが始まってから、読書の純粋な喜びが少しずつ失われていった。「この本を読んで、何が得られるのか」「今の仕事にどう活かせるのか」。そんな功利的な物差しで本を選ぶようになり、気がつけば読書そのものが苦痛になっていた。しかし、本当に価値のある学びは、必ずしも今すぐには役立たない。むしろ、時間をかけて深く染み込み、予想もしなかった形で花開くものです。小説は一見、非効率な読書に思える。しかし、物語を通じて培われる想像力は、システム設計において思いもよらない形で活きてくる。歴史書から学ぶ人間の本質は、チームマネジメントの場面で深い示唆を与えてくれる。私の場合、特にミステリーとSFに魅了された。ミステリーからは論理的思考と問題解決のアプローチを、SFからは技術の可能性と倫理的な課題を考えるきっかけを得た。しかし、それは最初から意図していたわけではない。純粋に物語を楽しみ、想像力を解放する中で、自然と得られた果実だった。あなたにも、必ず心惹かれるジャンルがあるはずです。その興味に素直に従い、読書の世界を広げていってほしい。読書のアプローチと戦略読書には様々なアプローチがあります。「速読の技術」は情報のスキミング（表面的な走査）に役立つ。技術書の概要を把握したい時、膨大な資料から必要な情報だけを抽出したい時、この技術は非常に効果的です。私は特に新しい技術トレンドをキャッチアップする際、まず全体像を素早く掴み、その後必要な部分だけを深掘りする「多層的読書法」を実践している。一方で、じっくりと読むアプローチも大切です。小説や哲学書、あるいは詩を読む時、一字一句をゆっくりと味わい、行間に隠された意味を汲み取る。この「空気を味わう」読書法は、表面的な意味を超えた深い洞察をもたらしてくれる。システム設計における微妙なトレードオフを考える時、このじっくりとした読書経験が思わぬ形で役立つことがあります。本を所有することには独自の価値があります。自分のライブラリを構築し、いつでも参照できる環境を整えることは、知的基盤の形成につながる。特に技術書や繰り返し読みたい名著は、手元に置いておく価値があります。私は自分の思考を形作った重要な本を厳選して所有している。それらは単なる紙の束ではなく、私の知的人生の一部となっている。同時に、図書館やシェアリングの活用も有効です。図書館やサブスクリプションサービスを利用することで、より多くの本に触れることができる。特に未知の分野や一度読めば十分な内容については、この方法が効率的です。私自身、地元の図書館と友人間での本の交換を通じて、予想外の良書と出会うことが多い。現代社会における読書の価値興味深いことに、周囲のエンジニアの多くは意外なほど読書をしていない。TikTokやYouTubeショート、Instagramリールなど、ショート動画に費やす時間は増える一方です。これは決して批判すべきことではない。しかし、そこに大きなチャンスが眠っている。仮に1日15分、ショート動画を見る時間を読書に置き換えるだけで、年間で約10冊の本を読むことができる。これは、意外なほどの差別化要因となり得る。ただし、これは絶対的な正解ではない。動画から得られる情報や刺激にも、独自の価値があります。重要なのは、自分に合った情報収集の方法を見つけることです。読書が苦手な人は、オーディオブックや要約サービスを活用するのも一つの手です。あるいは、技術ブログや技術記事を定期的にチェックする習慣をつけるだけでも、大きな違いを生む可能性があります。積ん読との向き合い方読書家なら誰しも経験する「積ん読」（積んだままで読まない本）の現象。積ん読は罪悪感の源になることもあるが、見方を変えれば将来の自分への投資とも言える。興味や好奇心に導かれて集めた本が、書棚で熟成されていく。そこには一種の知的な余裕があり、「いつか読む」という期待感が生活に彩りを添える。しかし、積ん読が過剰になると心理的な負担にもなりうる。部屋を埋め尽くす未読本は、読書そのものへの罪悪感を生み出してしまうこともあります。大切なのは、自分にとっての適切なバランスを見つけることです。私の場合、「今月必ず読む本」を3冊に限定し、それ以外は気楽に「いつか読むリスト」として保管している。理解のプロセス読書における重要な要素の一つが、「理解」と「不理解」のプロセスです。理解できる本を読むことには心地よさがあります。既存の知識体系に新しい情報が整然と組み込まれていく感覚は、確かな成長を実感させてくれる。しかし、最初は理解できない本にあえて挑戦することにも価値があります。混乱や疑問、時には苛立ちさえも、知的成長の重要な触媒となる。私は理解が追いつかない本に挑戦する習慣を持っている。最初は理解できなくても、繰り返し読むことで徐々に見えてくるものがあります。また読み終えて一読で理解できなくても再読してよい。特にエンジニアは「すぐに理解したい」という衝動に駆られがちです。しかし、「わからなさ」と向き合う力こそが、学びへの扉を開く。未知の技術や複雑なアルゴリズムに向き合う時、この「わからなさに耐える筋肉」が大いに役立つのです。批判と共感のバランス情報過多の時代において、「与えられた情報をそのまま受け入れない」という姿勢は、不可欠なスキルです。このブログや様々な書籍、動画も含め、どんな教えや助言も、鵜呑みにするのではなく、自分の文脈で吟味する必要があります。どんなアドバイスも、特定の文脈、時代背景、環境の中で生まれたものであり、あなたの状況とは必ずしも一致しない。批判的に読むとは単に否定することではない。それは、情報の背後にある前提や仮定を明らかにし、複数の視点から検証する能力です。「なぜそうなのか」「どういう状況でそれは当てはまるのか」「自分の状況ではどう適用できるか」と問い続けることで、より深い理解と洞察が得られる。例えば、「失敗から学べ」という一般的なアドバイスは、失敗のコストが許容できる環境であれば素晴らしい。しかし、一度の失敗が取り返しのつかない結果を招く状況では、慎重さが優先されるべきです。文脈を無視した教えは、時として危険でさえあります。一方で、著者の視点に深く入り込み、その世界観に身を委ねる読み方も大切です。私はこれを「憑依的読書」と呼んでいる。特に創造的な仕事においては、一時的に自分の批判精神を脇に置き、異なる思考様式や世界観に浸ることで、新たな発想が生まれることがあります。批判と共感、この両方のアプローチを状況に応じて使い分けることが、読書の醍醐味でもあります。また、成功バイアスにも注意が必要です。世に出回る成功談の多くは、生存者バイアスの産物かもしれない。同じ行動をとった数多くの失敗例は、通常語られることがない。「あの成功者がやったから自分もそうすべき」という単純な模倣は、幻想を追うことになりかねない。私自身、技術書や自己啓発書から学ぶことは多いが、常に「これは自分のケースにどう適用できるか」という視点でフィルタリングしている。そして実践の中で効果を検証し、必要に応じて修正を加えていく。このプロセスこそが、本当の意味での「学び」だと考えている。批判的思考は否定的な態度ではなく、むしろ積極的に仮説を探求する姿勢です。それは謙虚さと好奇心から生まれ、より深い理解へと導いてくれる。どんな教えも、一度自分の頭で咀嚼し、自分の言葉で再構築してこそ、本当の知恵となるのです。この文章に書かれた教訓も、ぜひあなた自身の視点で吟味し、あなたの文脈に合わせて取捨選択してほしい。それこそが、この文章の本当の価値を引き出す道だと信じている。知識の源泉を再考するエンジニアに限らず、あらゆる専門分野でよく耳にする「実務経験だけが本当の学びだ」という考え方について、少し立ち止まって考えてみましょう。様々な領域でこの考え方は根強く存在しています。確かに実践から得られる知恵は貴重ですが、この考え方をもう少し広い視点から捉え直すことで、より豊かな学びの可能性が見えてきます。私たちの記憶と認識は驚くほど選択的です。昨日成功した方法が今日も同じように機能するとは限りません。経験則は強力ですが、それは限られた条件下での観察にすぎないことを忘れてはなりません。一方で、体系化された知識は、多くの人々の試行錯誤を集約したものであり、単一の経験では得られない洞察を提供してくれます。考えてみれば、私たちの脳の処理能力には物理的な限界があります。専門書や論文は、この限界を超えるための道具と言えるでしょう。他者の思考プロセスに触れることで、私たちは自分ひとりでは到達できなかった思考の高みに立つことができるのです。これはソフトウェア開発に限らず、芸術創作や科学研究など、あらゆる創造的活動に当てはまることではないでしょうか。興味深いことに、「記録された知識」を軽視する傾向は、技術の発展を妨げた歴史的事例が少なくありません。同じ失敗を繰り返さないためにも、過去の知恵を継承することの価値を見直す必要があるでしょう。これは古代文明の衰退から現代の企業の失敗まで、様々なスケールで観察できる現象です。さらに考察を深めると、「実践だけが重要だ」という信念自体が、どこかで誰かから伝えられた考え方である可能性が高いという逆説に気づきます。完全に独立した思考というものは、実は幻想なのかもしれません。この気づきは、プログラマーだけでなく、芸術家や研究者、起業家など多くの創造的職業において重要です。最も効果的なのは、理論と実践を循環させるアプローチです。書籍から得たアイデアを実装し、その結果を分析し、また新たな知識を求める。この知的サイクルこそが、専門家としての成長を加速させます。プログラミングの知識とコーディングの実践が互いを高め合うように、多様な知識源からの学びは相乗効果を生みます。この原理は料理から音楽、スポーツまで、あらゆる技能の習得プロセスにも当てはまるものです。結局のところ、「どこから学ぶべきか」という問いよりも、「いかに多角的に学ぶか」を考えることが大切なのではないでしょうか。様々な知識源を柔軟に活用する姿勢が、生涯にわたる知的冒険を豊かにする鍵となるでしょう。エンジニアのみならず、あらゆる分野の専門家にとって、この多角的な学びの姿勢こそが、成長と革新をもたらすのだと思います。自分に合った読書選択と戦略読書の選択肢は無限に広がっている。どんな本を選び、どう読むかという問いには、一つの正解はない。重要なのは、自分自身の興味と状況に合わせた選択をすることです。「わたしが選ぶ」読書法は、自分の好奇心と直感を信頼する姿勢から生まれる。「この分野に興味がある」「この作家の文体が好き」といった個人的な嗜好に従って本を選ぶことには、大きな価値があります。一見偏っているように見えるこの姿勢は、実は深い専門性と独自の視点を育む土壌となる。一方で、「先人が選ぶ」名著やベストセラー、教授の推薦図書といった外部からの指針に従う読書法もあります。これは幅広い教養を身につける効率的な方法です。特に未知の分野に足を踏み入れる際、先人たちの知恵を借りることは合理的な選択となる。読書を習慣化するには、戦略的なアプローチも役立つ。自分の目的に合わせて読書スタイルを使い分けることが重要です。技術書を精読する場合と、小説を楽しむ場合では、まったく異なるアプローチが必要になる。特に技術書については、単に読むだけでなく、アウトプットを意識した読書が重要です。読んだ内容をブログにまとめる、同僚に説明する、小さなプロジェクトで試すなど、理解を定着させる工夫が必要です。また、一冊を完璧に読み切ろうとするのではなく、必要な部分だけを効率的に吸収する技術も身につけておきたい。目次や索引を活用し、自分に必要な章だけを選んで読む。あるいは、概要を把握した上で詳細を必要に応じて参照するトップダウン型の読書法も効果的です。自分の好みと直感を信頼しつつも、時には意図的に異なるジャンルや難易度の本に挑戦する。このバランスこそが、読書を通じた知的成長の鍵となる。個人の知識管理システムを構築する情報爆発の時代において、読書から得た知識を効果的に管理し、活用するシステムを持つことは、エンジニアにとって大きな強みとなる。私自身、長年の試行錯誤を経て、自分なりの知識管理の仕組みを構築してきた。まず基本となるのは、「インプットとアウトプットのバランス」です。読んだ内容をただ蓄積するだけでなく、定期的に整理し、自分の言葉で表現する機会を作ることが重要です。私の場合、技術ブログの執筆や社内勉強会での発表が、このアウトプットの場となっている。また、デジタルツールを活用した知識の外部化と構造化も効果的です。Notion、Obsidian、Roam Researchなどのツールを使い、読書メモや気づきを体系的に記録する。特に「第二の脳」と呼ばれるアプローチは、断片的な情報を有機的につなぎ合わせ、新たな発想を生み出す助けとなる。しかし、最も重要なのは定期的な振り返りと再構成です。蓄積された知識を定期的に見直し、新しい文脈で捉え直すことで、眠っていた知識が突然輝きを放つことがあります。「半年前に読んだ本の内容が、今直面している問題の解決に役立つ」―そんな経験は、知識管理の醍醐味とも言える。完璧なシステムを最初から構築しようとせず、自分の作業スタイルや思考プロセスに合わせて、徐々に進化させていく姿勢が大切です。最終的には、読書で得た知識が自然と実践に結びつく、そんな個人的な知の生態系を育てていきたい。読書を通じた孤独と共有の調和読書には孤独な側面と社会的な側面があります。一見相反するようだが、両者は実は深く結びついている。「孤独の読書」には独自の価値があります。静かな空間で、自分だけの世界に浸る時間。それは心の強さと自立性を育む。特にエンジニアにとって、複雑な問題に一人で向き合う力は不可欠のスキルです。読書を通じて培われる集中力と内省的思考は、技術的な難問に立ち向かう際の大きな武器となる。同時に、読書は他者とのつながりを生み出す。読書から得た知識は、他者と共有することでさらに価値を増す。同僚との技術的な議論、オンラインコミュニティでの意見交換、ブログやSNSでの発信など、知識を共有する機会は多様に存在する。特に効果的なのが「読書会」や「輪読会」の活用です。同じ本を複数人で読み、定期的に感想や疑問を共有する場を設けることで、一人では気づかなかった視点や解釈に出会うことができる。私の所属するチームでは、月に一度、技術書の輪読会を開催しており、それがチーム全体の技術力向上に大きく貢献している。また、教えることで学ぶ効果も見逃せない。誰かに概念を説明しようとすると、自分の理解の浅い部分が浮き彫りになる。「完璧に理解してから共有しよう」と待つのではなく、「共有することで理解を深める」という循環を作り出すことが大切です。読書を通じた物語の共有は、自己理解を深める手段にもなる。読んだ本について語ることで、自分の価値観や思考パターンが明確になる。これは「ナラティブ・アプローチ」とも呼ばれ、自己認識と他者理解の両方を促進する。孤独の読書で内なる力を養い、共有の場で対話を通じて視野を広げる。この循環こそが、読書の力を引き出すのです。知識の実践という課題読書で得た知識を実践に移すのは、想像以上に難しい。私は理論と実践のギャップ、環境や条件の違い、自分の技術力や経験の不足、そして組織の制約や慣習など、様々な困難に直面してきた。特に気をつけたいのは、知識の即効性に一喜一憂しないことです。知識にはいくつかの種類があります。すぐに活用できるものもあれば、時間をかけて咀嚼が必要なものもあります。将来的に活きてくるもの、直接的な活用は難しいが視野を広げてくれるもの、そして率直に言って最終的には何も活きないものまで、様々な知識が混在している。重要なのは、それぞれの特性を理解し、適切な期待値を設定することです。読書の多様な目的と効用読書の目的や楽しみ方は人それぞれです。ある人にとっては純粋な娯楽であり、別の人にとっては修業に近いものかもしれない。どちらが正しいということはない。「かんたん読書主義」を実践する人もいる。気軽に、自分の興味に素直に従い、楽しみながら読書の世界を広げていく。この姿勢には、読書の継続性という大きな利点があります。義務感ではなく、純粋な好奇心から読む本は、より深く心に残るものです。一方で、あえて難解な本に挑む「修業としての読書」も、独自の価値があります。最初は理解できなくても、何度も読み返し、少しずつ理解を深めていく。この過程で培われる忍耐力と思考力は、専門的なキャリアにおいて大きな武器となる。読書は「愛される」ためのツールにもなりうる。知識や教養、独自の視点を身につけることで、人間的な魅力が高まることは確かです。しかし同時に、読書は「愛する」行為でもあります。著者の思想に共感し、物語の登場人物に感情移入し、未知の世界に心を開く。この「愛する力」こそが、人生を豊かにする源泉となる。継続的な実践の重要性「知っているつもり」と「本当に理解している」は、全く異なる。実践を通じて初めて気づく事実があります。理論の限界と応用の必要性、想定外の状況への対応、実装上の細かな課題、そして維持・運用の難しさなど、机上では決して学べない多くの学びが実践の中にあります。そして最も重要なのは、実践し続けることの難しさです。一時的に実践することは、比較的容易い。しかし、それを習慣として定着させ、継続的に改善していくことは、想像以上に困難を伴う。読書と実践は、まさに車の両輪のようなものです。読書だけでは机上の空論に終わり、実践だけでは視野が狭くなる。両者のバランスを取ることこそが、成長をもたらすのです。知的好奇心という贈り物「読書を楽しみながら、しかし実践を怠らない。その繰り返しが、あなたを成長させる」読書は、決して義務ではない。それは、知的好奇心を満たし、新しい世界を発見する喜びなのです。その喜びを、実践を通じてさらに深めていってほしい。「本を読むのが好きな人が、本を読めとは言えない」私も、そう思う。だから最後にこう言わせてほしい。あなたがもし本が好きなら、その気持ちを大切にしてほしい。そしてもし本が苦手なら、無理に読む必要はない。でも、もしかしたら、あなたの心に響く一冊が、どこかで待っているかもしれない。その出会いが、あなたの人生を、私のように豊かにしてくれることを願って。11. 時間とお金と健康を大切にする。そして、関係性を育む。「24時間戦えますか？」—かつてのCMフレーズが、今では皮肉な響きを持つ。正しい問いは「残りの人生を戦えますか？」です。人生の質を決める三つの要素がある。時間・お金・健康。この三つは互いに影響し合い、一つが崩れると他も危うくなる。「そんな計画的な生き方、窮屈じゃない？」という意見もあるだろう。確かに、人生には偶然の出会いや予期せぬ展開の魅力もある。しかし、計画性と自発性は対立概念ではない。むしろ基盤がしっかりしているからこそ、余裕をもって偶然を楽しめるのです。特に警鐘を鳴らしたいのが健康です。「あって当たり前」と思っているうちに健康は失われていく。技術スキルを磨くのと同じくらい、自分の身体と心のメンテナンスも重要なのです。お金については「稼ぐこと」より「使い方」が重要。収入を増やすことも大切だが、それをどう配分するかでライフスタイルの質が決まる。そしてこの三つの要素が調和したとき初めて、本当の意味での「関係性」が育まれる。時間的余裕がなければ人と深く関わる余力はない。経済的不安があれば心は閉じがち。健康を損ねれば活力も失われる。持続可能な習慣を今から築くこと—それが未来の自分への最高の投資なのです。20代で学んだ最も深い気づき。それは「時間・お金・健康」が人生の質を決定づける核心的な要素だということです。そして、これらの要素を丁寧にマネジメントすることで築かれる「人との関係性」こそが、かけがえのない財産となることを、身をもって理解した。時間という最も貴重な資産時間は、私たちが持っている中で最も価値があり、かつ有限な資産です。人生において、失ったお金は努力で取り戻せます。失った機会も、別の形で必ず巡ってきます。しかし、失われた時間は、決して取り戻すことができません。この気づきは、自分の時間の使い方だけでなく、他者の時間に対する姿勢も大きく変えました。会議を主催する時、資料作成を依頼する時、質問をする時。全ての行動が、誰かの貴重な時間を消費しているのです。他者の時間を奪うということは、その人の人生の一部を奪うことに等しい。この認識は、私の人としての在り方を根本から見直すきっかけとなりました。エンジニアの皆さんに強く訴えたい。時間は技術スキルと同じくらい大切な資産です。いや、むしろそれを育むための土台となる、より本質的な資産なのです。自分の時間を大切にし、他者の時間を尊重する。この意識がなければ、良い人間関係を築くことはできません。どんなに優れた知識や能力があっても、時間の大切さを理解していなければ、誰からも信頼される人にはなれないのです。お前を守れるのはお前だけ社会人になって痛感したのは、「結局、自分を守れるのは自分だけ」という厳しい現実です。会社は決してあなたを守ってはくれません。上司も、同僚も、友人さえも、あなたの人生に最終的な責任を持つことはできないのです。業務量が明らかに過剰でも、自分から「NO」と言わなければ誰も止めてくれない。体調を崩しても、自分で休むと決断しなければ、周囲は当たり前のように仕事を振ってくる。キャリアの方向性も、スキルアップも、全て自分で考え、行動しなければ何も始まらない。若いうちは「会社が育ててくれる」「先輩が教えてくれる」という幻想を抱きがちですが、それは甘えでしかありません。もちろん、助けてくれる人はいます。しかし、その助けを得るための行動を起こすのも、最終的には自分自身なのです。自分の健康状態、メンタルの限界、スキルの過不足、将来のキャリアパス—これらを最もよく知っているのは、他でもない自分自身です。だからこそ、自分の状況を冷静に分析し、必要な対策を取る責任があります。特に体調管理は絶対に自分で行うしかありません。「少し無理をしても大丈夫」と思っているうちに取り返しのつかない状態になることもあります。心と体のサインを見逃さず、適切に休息を取る。これは自己防衛の基本中の基本です。この「自分を守る」という意識は、決して利己的なものではありません。むしろ、自分をしっかり守ることで初めて、他者にも価値を提供できるのです。燃え尽きてしまっては、誰の役にも立てなくなってしまう。自分の意思をはっきりと伝え、必要な時には断る勇気を持つこと。自分の体調と向き合い、無理をしないこと。自分のキャリアを自分で設計すること。こうしたセルフプロテクションの姿勢が、長期的に見れば、あなた自身だけでなく、周囲の人々にとっても最善の結果をもたらすのです。最後に強調したいのは、他者に依存せず、自立した個人として生きることの重要性です。もちろん、支え合いや協力は大切です。しかし、その前提として「自分の人生は自分で守る」という覚悟がなければ、協力関係は築けません。自分自身を大切にし、守ることができてこそ、他者との健全な関係も築けるのです。暇だと不幸になる多くの人は「もっと自由な時間があれば幸せになれるのに」と考えがちです。しかし、実際には自由時間と幸福度の関係は、単純な比例関係ではありません。ある一定以上の自由時間を持つと、むしろ幸福度が低下していく傾向があるのです。この一見矛盾する現象は、人間の本質に深く関わっています。人は単に「何もしない自由」を求めているのではなく、「意味のある何かに取り組む自由」を求めているのです。退職後に喪失感を覚える人や、夢見ていた自由な生活が思ったほど満足をもたらさないと感じる人が少なくないのは、このためでしょう。人間には目的を持って行動することで得られる充実感と達成感が必要です。何もしなくていい状態は、一見理想のように思えますが、実際には私たちから意味と方向性を奪ってしまいます。「何をするべきか」という制約がなくなった時、かえって自分の存在意義を見失ってしまうことがあるのです。また、時間の質も重要です。同じ長さの自由時間でも、それをどう過ごすかによって幸福度は大きく変わります。一般的に、人と過ごす時間や創造的な活動に使う時間は幸福度が高い傾向があります。一方、ただ受動的に時間を消費したり、過去や未来のことばかり考えて「今」をおろそかにしている時間は、幸福感をもたらしにくいようです。重要なのは、自分にとって最も幸せな時間の使い方を見つけることです。あなたの自由時間を最も充実させる使い方は何でしょうか？それを見つけることこそが、時間という贈り物を最大限に活かす鍵となります。お金という可能性の触媒お金は単なる通貨以上の意味を持ちます。それは価値の交換手段であり、感謝の表現手段でもあります。20代の頃、私は収入の使い方について明確な哲学を持つようになりました。基本的な生活費を確保しつつ、将来への投資と心の余裕のためのバランスを意識的に取るようにしています。これは単なる金銭管理ではなく、人生の価値観を形にする営みでした。私にとってお金は、現在の生活の質を保ちながら、将来の可能性を広げ、時には自分らしい贅沢を楽しむための道具なのです。お金に関する判断で最も重要なのは、リスクの対称性です。「必ず儲かる」「絶対に損しない」という話は、ほとんどの場合、リスクの非対称性を隠した罠です。話を持ちかける側は何も失うものがなく、あなただけがリスクを背負う——そんな状況には要注意です。人生には、必ず適切なリスクを取る必要があります。しかし、それは無謀な賭けではありません。自分の判断で、自分の責任で、時には身銭を切る覚悟を持って決断を下す。そんな経験の積み重ねが、あなたの判断力を磨いていくのです。若手エンジニアの方々へ。お金は決して目的ではありませんが、人生の選択肢を広げる重要な手段です。給料の高さだけで仕事を選ぶのは危険ですが、自分の価値に見合った報酬を求めることは当然の権利です。その報酬を将来の自分への投資に回せるかどうかが、長期的なキャリアを左右します。そして何より、その投資判断には必ず自分自身の責任が伴うことを忘れないでください。複利を侮るな複利の力を侮ってはいけません。その力は計り知れません。20代からわずかでも投資を始め、それを継続することで、30年後、40年後には想像を超える資産に成長する可能性があります。例えば、毎月3万円を年利5%で30年間投資し続けると、元本の1,080万円が約2,500万円に膨らみます。時間はあなたの最大の味方です。若いうちから投資を始めることで、リスクを分散させながら市場の変動を乗り越えるだけの時間的余裕を得られます。複利効果は後半になるほど加速するため、早く始めるほど大きな恩恵を受けられるのです。投資とは単にお金を増やすことではなく、将来の自分に対する責任ある行動です。今日の小さな積み重ねが、明日の大きな選択肢を生み出します。複利の魔法を味方につけ、長期的な視点で自分の未来に投資してください。欲には終わりがない収入、物、地位...欲求は満たされるとすぐに新しい欲求が生まれる。この「欲望の迷宮」から抜け出すには、「欲しいもの」と「必要なもの」を区別する習慣が重要です。実践として「感謝の習慣」が役立つ。毎晩、感謝できることを3つ挙げる。また「意識的な消費」も大切で、「これは本当に私の生活を豊かにするか」と問いかけてから購入を決める。満足感は所有物の量ではなく、それらを認識し感謝する能力による。「もっと」を求めるのではなく、「今ここにあるもの」に価値を見出そう。消費の本質を見抜く力私たちは商品の本当の価値より、外見や周りの評判に左右されがちです。物の価値を見分けられないと、高いお金を払って企業の思うままに動く消費者になってしまいます。ブランドに価値があると信じているからこそ、喜んで大金を支払ってしまうのです。高級ブランドも怪しい情報商材も同じ戦略を使っています。消費者は製品やサービスの機能ではなく、その周りにある「ステータス」や「期待感」といった目に見えない要素にお金を払わされているのです。本当に必要なのは、商品の実際の価値と、マーケティングによって作られた価値を見分ける目です。広告の誘惑や友人の意見に流されず、自分にとって本当に意味のあるものは何かを判断できる力を育てていきましょう。瞑想を実践せよ心の混沌に秩序をもたらす瞑想は、エンジニアにとって想像以上に価値ある習慣です。私たちの職業は常に複雑な問題解決を求められ、思考の明晰さが直接的に成果を左右します。しかし、情報過多の現代社会では、私たちの脳は常に外部からの刺激に反応し続け、集中力を発揮することが難しくなっています。瞑想は単なる精神的な実践ではなく、脳の機能を最適化するための科学的アプローチです。日々たった10分の瞑想が、注意力の向上、ストレスの軽減、創造性の増進につながることが、数多くの研究で示されています。私自身、朝の短い瞑想を習慣にしてから、目の前のタスクへの集中力が格段に向上し、複雑な問題への対処能力が高まりました。また、常に頭の中で走り続けていた思考の渦が静まり、物事を客観的に見る視点が養われたことで、感情に振り回されることも減りました。始め方は驚くほど簡単です。静かな場所で座り、3分間だけでも呼吸に意識を向けてみてください。呼吸を数えたり、身体の感覚に注目したり、あるいは単に思考を観察するだけでも構いません。重要なのは完璧を目指さないこと。思考が脱線しても、それに気づいた時点で優しく意識を呼吸に戻す練習を繰り返すだけです。瞑想は決して非現実的な神秘体験ではなく、脳を休ませ、最適な状態に整える実践的なツールです。古代から続くこの智慧が、最先端の技術に携わる私たちにこそ、強力な武器となることを知ってください。毎日のほんの少しの時間を投資することで、思考の質、創造性、そして何より人生の質そのものが大きく向上する可能性があるのです。健康という揺るぎない土台一流の人々に共通していたのは、基本的な生活習慣を何より大切にする姿勢でした。かつての「24時間戦えますか？」という時代は終わり、今は「残りの人生を戦えますか？」という時代なのです。特に、技術の進化が加速度的に進む現代では、長期的な学習と適応が求められます。その土台となるのが、揺るぎない健康管理なのです。健康を失うことの深刻さは、経験してからでは遅すぎます。腰痛、視力低下、不眠症、うつ病―これらは一度発症すると、回復に膨大な時間とエネルギーを要します。時には、取り返しのつかない事態に発展することもあります。健康は「あって当たり前」と思っているうちに失われていくのです。特に警鐘を鳴らしたいのは、若手エンジニアに多く見られる「健康への過信」です。20代という若さゆえに、多少の無理はイケると考えがちです。しかし、これは危険な誤解です。不規則な生活習慣、運動不足、偏った食事、慢性的な睡眠不足―これらのツケは、必ず後からやってきます。そして、そのツケは往々にして、キャリアの重要な転換期と重なってしまうのです。健康管理は、単なる自己防衛ではありません。それは、持続可能なキャリアを構築するための戦略的投資なのです。技術力の向上と同様、日々の小さな積み重ねが、将来の大きな差となって現れます。今この瞬間から、自分の健康を「投資対象」として扱い始めることを、強くお勧めします。体力が全てを覆す脳は肉体の奴隷です。この事実を理解することが、長期的な成功への鍵となります。どれほど優れた才能や知識を持っていても、それを支える体力や肉体がなければ、真価を発揮することはできません。同年代で比較したとき、仕事的にも文化的にも優秀な人材は数多く存在します。彼らは短期的には目覚ましい成果を上げるでしょう。しかし、体力という基盤で差をつけることができれば、長い目で見たとき彼らを追い越すことが可能です。なぜなら、疲れた身体では脳は創造的な思考ができず、単純なミスを繰り返すからです。若いうちから体力を築くことは、他のどんな自己投資よりも確実なリターンをもたらします。才能や知識は一時的なアドバンテージでも、体力は継続的なアドバンテージとなり、時間の経過とともにその差は広がるばかりです。睡眠と食事の重要性良質な睡眠は、生産性と創造性の源泉です。私は就寝時間を23時から7時と決め、就寝1時間前からはブルーライトを制限します。これは単なる習慣ではなく、翌日のパフォーマンスを最大化するための投資です。特に、複雑な問題解決や創造的な作業が求められるエンジニアにとって、質の高い睡眠は不可欠です。睡眠負債は、短期的には気づきにくいものの、長期的には取り返しのつかない影響をもたらす可能性があります。食事も健康の基礎です。朝食は高タンパク・低糖質を心がけ、夕食は就寝3時間前までに済ませます。「コードを書くための身体づくり」という意識を持ち、食事の質を管理しています。また、デスクワークが中心となる職種だからこそ、意識的に野菜を摂取し、適度な運動と組み合わせることで、代謝の維持にも気を配っています。重要なのは、これらの習慣を「我慢」としてではなく、自分への投資として捉えることです。質の高い睡眠と栄養バランスの取れた食事は、短期的なパフォーマンスだけでなく、長期的なキャリアの持続可能性を支える重要な要素となります。特に若いうちは、その重要性に気づきにくいものですが、健康管理への投資は、必ず将来の大きなリターンとなって返ってくるのです。姿勢と身体への意識エンジニアという職業柄、長時間デスクワークに従事する私たちにとって、姿勢の重要性は、いくら強調してもし過ぎることはありません。若いうちは気にならなくても、姿勢の悪さは確実に体に蓄積され、やがて取り返しのつかない代償を要求してきます。特に警鐘を鳴らしたいのが、スマートフォンの使用による姿勢の崩れです。首を深く下げ、猫背になり、長時間同じ姿勢を保持し続ける。この一見何でもない習慣が、実は恐ろしいほど危険なのです。首や肩への負担は想像以上に大きく、一度痛めてしまえば、その回復には途方もない時間と労力を要することになります。デスクワークを続けていく中で、姿勢の大切さを身をもって実感しました。背筋を伸ばして座ることは、自然と集中力を高め、仕事への向き合い方にも影響を与えます。実際、姿勢を意識し始めてから、周囲との関係性に微妙な変化が生まれ始めました。姿勢を正すことで、自然と声の通りも良くなり、話し方にも力強さが増していきました。若いエンジニアの皆さんへ。健康は「あって当たり前」と思っているうちに失われていきます。技術の習得に夢中になるのは素晴らしいことですが、それを支える身体があってこその技術です。特にスマートフォンの使用時間と姿勢には細心の注意を払ってください。今、この瞬間から、自分の健康を投資対象として扱ってください。それは必ず、将来の大きなリターンとなって返ってきます。集中と休息のリズムを作る私が20代前半に出会い、今でも実践している時間管理法があります。「ポモドーロ・テクニック」です。25分間集中して取り組み、5分間完全に休憩するというシンプルなサイクルを繰り返すこの方法は、私の生産性と精神的な健康を大きく向上させた。最初はその単純さに半信半疑だったが、実践してみると効果に驚かされた。ポモドーロ・テクニックの魅力は、その「有限性」にあります。「25分だけ」という明確な期限があることで、脳に適度な緊張感が生まれ、先延ばしの習慣が断ち切られる。難しいタスクでも「とりあえず25分だけ」と始めるハードルが下がるのです。定期的な休憩が組み込まれていることも重要です。休憩は単なる時間の無駄ではなく、高いパフォーマンスを維持するための必要不可欠な要素です。私の場合、休憩時間には意識的に「何もしない」ようにしている。スマートフォンを見たりせず、窓の外を眺めたり、深呼吸をしたりするだけ。この「デジタルデトックス」の時間が、脳を本当の意味でリフレッシュさせてくれる。このテクニックを実践して気づいたのは、時間の質が量よりも重要だという事実です。長時間机に向かうより、質の高い集中時間を確保することの方が、はるかに価値があります。また、自分の集中パターンや生産性の波を客観的に観察する機会も得られた。もちろん、時には25分では足りず、心地よい集中状態が途切れてしまうこともあります。大切なのは、テクニックに縛られることではなく、自分の状態や作業の性質に合わせて最適なリズムを見つけることです。若いエンジニアの皆さんには、ぜひこのシンプルだけど強力なテクニックを試してほしい。時間との向き合い方が変わり、より意識的に「今」に集中できるようになる。そして何より、仕事と休息のバランスが取れた、持続可能なキャリアへの第一歩となるだろう。本質的な休息の重要性現代社会では、休憩時間すらも効率的に使おうとします。SNSをチェックし、ニュースに目を通し、メッセージに返信する。しかし、これらの行為は、脳に新たな負荷を与えているに過ぎません。「スマートフォンをいじっている時間は、休憩ではない」。25分作業後に5分の完全な休憩を取り、昼食は必ずデスクを離れ、帰宅後の30分は「何もしない時間」として確保しています。週末には半日以上のオフライン時間を設けることで、心身のリフレッシュを図っています。これは特に強調したい点です。本当の休息を知らないエンジニアに、本当の生産性は生まれません。常に情報を消費し続ける習慣を、今すぐ見直してください。脳を休ませることは、怠慢ではなく必要不可欠な投資なのです。「快楽の奴隷」になるな目の前の楽しさを選ぶか、将来の幸福を選ぶか。私も「快楽の奴隷」だった時期があります。短期的には成果が出ても、長期的には健康や創造性を損なった。誘惑に打ち勝つためには「環境デザイン」の考え方が役立つ。誘惑と戦うのではなく、そもそも誘惑が少ない環境を自ら作り出すのです。また将来の自分を具体的にイメージする習慣も効果的で、目の前の誘惑に流されそうになった時の歯止めとなる。完璧を目指さず、バランスを取ることが大切。全ての快楽を否定するのではなく、意識的に楽しみを計画に組み込む「計画された逸脱」が全体の規律を守る助けになる。快楽と未来の幸福のバランスを自分でコントロールする。その選択の積み重ねが、あなたの人生を豊かにする。デジタルデトックスの必要性人類は長い歴史の大部分を、常に危険と隣り合わせの狩猟採集生活を送ってきました。このような環境で進化してきた私たちの脳は、現代のデジタル社会に十分適応できていません。スマートフォンやSNSは脳の報酬系を過剰に刺激し、依存状態を作り出すと同時に、集中力の低下を引き起こします。興味深いことに、IT業界の先駆者たち自身がテクノロジーの潜在的な悪影響を認識し、自分自身や子供たちのスマートフォン使用時間に厳しい制限を設けています。また、SNSは人々をつなげるはずですが、皮肉にも実際には孤独感を深める傾向があります。特に発達段階にある子供たちにとって、過度のスマートフォン使用は自制心の健全な発達を妨げる可能性があります。健康的なデジタルバランスを取り戻すためには、十分な睡眠時間の確保、定期的な運動、そしてスマートフォンの使用時間制限が効果的です。これらの対策は集中力の向上につながり、心の健康問題を予防する重要な手段となります。この内容は現代社会におけるデジタル依存の問題とその解決策について論じており、「快楽の奴隷になるな」という前の議論と自然につながります。即時的な快楽（SNSやスマートフォンの過度な使用）と長期的な幸福（精神的健康や集中力の維持）のバランスを取ることの重要性を一貫して示しています。関係性という最大の財産能力が高まれば高まるほど、人を助ける機会が増えます。そこで重要なのが、お礼を上手に受け取る能力と、相手のお礼に対して適切に応える技術です。関係性を育むには、定期的な状況共有と小さな成功の共有、困りごとの早期相談と感謝の表現が欠かせません。人に信頼されることは、あらゆるプロフェッショナルにとって最も重要な資質です。約束は必ず守る、困難な状況でも誠実に対応する、都合の悪いことでも隠さず報告する。こうした「当たり前」の行動を当たり前に続けることが、実は最も難しく、そして最も価値のあることなのです。これは全てのエンジニアに強く伝えたいメッセージです。どんなに優れた技術を持っていても、信頼関係がなければその価値を十分に発揮することはできません。技術力の向上と同じくらい、人との関係性構築にも意識的な努力を払ってください。「怒り」を手なずけよ怒りの感情は自然なもの。問題はその反応の仕方です。怒りを感じたら、すぐに反応せず時間を置く。また、怒りの背後にある原因を理解し、そのエネルギーを建設的な方向に向けることも大切です。怒りのコントロールは生涯の課題。完璧な人はいない。重要なのは失敗したとき、すぐに認め、謝罪し、学びに変えること。感情に振り回されず自分をコントロールできる人が、プロフェッショナルです。言葉にするな体現しろ社会でうまくやるには、言葉にすべきことと、黙って示すべきことを見極める必要があります。目標や意志、チームの方向性などは、明確に言語化し共有すべきです。それによって、周囲との認識が揃い、協力が得やすくなります。自分の価値観や将来のビジョンを適切に表現することは、チームの一体感を生み、より良い成果につながります。一方で、自分の功績や能力を誇示することは最も避けるべき振る舞いの一つです。真に優れた人は、自分のことを語る必要がありません。なぜなら、その人の価値は周囲が自然と認めるものだからです。自分の成果を声高に語り、実績を必要以上にアピールする人は、往々にして周囲の信頼を失っていきます。実力や貢献、日々の努力といったものは、言葉ではなく行動で示すべきです。「やります」と言うのではなく、「やりました」と報告できる人になりなさい。口先だけの約束は誰でもできます。大切なのは、その言葉に実績が伴っているかどうかです。本当の実力とは、静かに、しかし確実に結果を出し続けることなのです。このバランスを取ることは簡単ではありません。しかし、これこそがプロフェッショナルとしての重要なスキルの一つなのです。必要な時には適切に言葉を使い、その他の場面では行動で示す。この使い分けができる人こそが、組織の中で信頼を得ていくのです。なにかに特化するということはなにかを失うわけではないエンジニアとして特定の分野に深く取り組むとき、多くの人は「バランスを失うのではないか」と不安を感じます。技術力を追求すれば人間関係が疎かになる、キャリアに集中すれば健康が損なわれる、仕事に打ち込めば趣味の時間が失われる―。しかし、これは大きな誤解です。むしろ、一つの分野への深い取り組みは、他の領域をも豊かにする可能性を秘めています。なぜなら、特定分野での深い学びは、具体と抽象の往復を通じて、より普遍的な問題解決能力を育むからです。例えば、プログラミングで培った抽象化の能力は、日常生活の課題整理にも活きてきます。アプリケーションの設計で学んだ構造化の考え方は、趣味の整理や時間管理にも応用できます。つまり、一見すると専門的に見える学びも、適切に抽象化することで、人生の様々な場面で活用できる知恵となるのです。時間・お金・健康、そして人との関係性。これらは全て、長期的なキャリアを支える重要な柱です。一時的な成功や目先の評価に惑わされず、これらの本質的な要素をしっかりと見つめ、大切にしてください。エンジニアとしての本当の強さは、技術力だけでなく、これら全ての要素が調和したところに生まれるのです。そして、その調和は、具体と抽象を行き来する深い思考によってこそ、より確かなものとなっていくのです。12. 趣味を持つ。そして、新しい世界を広げる。「プログラミングが趣味です」—多くのエンジニアがそう答える。しかし、仕事と趣味が完全に一致していることに、小さな危うさはないだろうか？「エンジニアは、エンジニアであり続ける必要はない」。この言葉が意味するのは、あなたのアイデンティティは職業だけで決まるものではないということ。プログラミングと全く異なる世界—例えば格闘技や音楽、料理や旅行—に触れることで、意外な相乗効果が生まれる。一見相反する活動が、実は互いを高め合うのです。「専門性を薄める趣味なんて、キャリアの妨げでは？」という疑問も当然だろう。時間は有限だから、趣味に費やす時間は仕事から奪っているように見える。しかし実際は逆です。異なる分野での経験が、思いがけない発想やアプローチをもたらすことがある。それは「創造的な隔たり」と呼ばれ、革新的なアイデアの源泉となる。人生で最も重要な気づきの一つは、自分がコントロールできるのは自分自身の行動と反応だけだということ。外部の状況や他者の行動をコントロールしようとして消耗するより、自分の反応の仕方を変える方が遥かに効果的です。砂時計の砂は確実に減っていくが、その砂で何を築くかは自分次第。多様な経験を通じて、あなたの世界はより豊かに、より広く、より深くなっていく。「エンジニアは、エンジニアであり続ける必要はない」世界は何もしないと確実に狭まっていく。それは、まるで砂時計の砂が少しずつなくなっていくように、気付かないうちに私たちの可能性はなくなっている。その砂を増やすには、意識的な努力が必要なのです。価値観の多様性を認識する人生における価値観は、人それぞれです。仕事に全てを捧げることを選ぶ人もいれば、プライベートを重視する人もいる。どちらが正しいということはない。大切なのは、自分が本当に望む生き方を見つけ、それを実現する勇気を持つことです。私の場合、プログラミングと格闘技という、一見相反する二つの世界に身を置くことを選んです。これは決して「仕事だけでは不十分」という価値判断からではない。むしろ、異なる経験を通じて、自分の可能性をより広げたいという純粋な好奇心からだった。複数の世界を持つことの意味この二つの世界は、まったく異なる性質を持っている。論理的思考と身体的直感、デジタルとアナログ、個人作業と対人競技。しかし、この異なる性質を持つ活動が、予想以上の相乗効果を生み出してくれた。一方の世界で行き詰まった時、もう一方の世界が新しい視点を与えてくれる。格闘技で学んだ「型」の考え方が、プログラミングのデザインパターンの理解を深めてくれたり、プログラミングで培った論理的思考が、技の組み立てに活かされたり。このように、一見無関係に見える活動が、互いを高め合う相乗効果を生み出すのです。自分が変えられないことに注力しない人生の中で最も重要な気づきの一つは、「自分の力で変えられることと変えられないことを区別する智慧」です。これは趣味を持つことの意外な効能とも言えるでしょう。エンジニアとして働いていると、論理的に考え、問題を解決することに慣れています。しかし、時に私たちは「解決できない問題」に執着してしまうことがあります。仕事の中での理不尽な状況、他者の判断や行動、組織の方針転換、市場の変化など、自分ではコントロールできない要素に過度にエネルギーを注いでしまう。趣味の世界はこうした視点を変えてくれます。格闘技の道場では、「相手の動きを変えようとする」よりも「相手の動きに対して自分がどう対応するか」に焦点を当てます。これは単なるスポーツの戦術ではなく、人生への深い洞察でもあるのです。私が学んだのは、自分がコントロールできるのは、自分自身の行動と反応だけだという事実です。それ以外のことに過度に心を砕いても、ストレスを溜めるだけで何も変わりません。むしろ、変えられないことを受け入れ、変えられることに集中するほうが、はるかに生産的で心の平穏にもつながります。特に現代では、政治イデオロギーや世界情勢について強い文句や不満を持ちすぎることが、自分の精神的エネルギーを大きく消耗させる原因になっています。SNSで毎日のように繰り広げられる論争、世界各地の紛争や不公正なニュース、国内の政治的対立—これらは確かに重要な問題ですが、一個人として直接変えられることは極めて限られています。私が学んだのは、世界の全てを変えようとするのではなく、自分の身近な範囲で具体的な行動を取ることの価値です。抽象的な怒りや不満を抱えるよりも、地域のコミュニティ活動に参加したり、信頼できる情報源を選んで理解を深めたり、あるいはときには意識的にニュースから距離を置くことも必要です。過度に政治的な議論に没頭し、常に「世界の不正」に怒りを感じている友人がいました。彼は確かに正当な怒りを持っていましたが、その怒りが彼自身の生活や健康を蝕んでいくのを目の当たりにしました。一方で、同じ問題意識を持ちながらも、自分ができる小さな行動に集中していた別の友人は、より充実した日々を送り、結果的に社会にも良い影響を与えていました。重要なのは無関心になることではありません。むしろ、自分の影響力が及ぶ範囲を現実的に見極め、そこに効果的にエネルギーを注ぐことです。政治や世界情勢に関心を持つことは市民として大切ですが、それに振り回されず、自分の生活や周囲の人々に対して前向きな影響を与えることに集中する。この姿勢こそが、より建設的で持続可能な社会参加の形なのではないでしょうか。主体性を持ち、手の届く範囲から変えていく「誰かがやってくれるだろう」「環境が変われば何とかなる」—そんな受け身の思考に囚われていないだろうか？20代で学んだ最も重要な教訓の一つは、人生における変化は、自分自身から始めなければならないということです。周囲の環境や他者の行動をコントロールすることは難しくても、自分の反応や行動を選ぶ自由は常にあります。職場で感じる理不尽な状況、プロジェクトの行き詰まり、チーム内の対立—こうした困難に直面したとき、私はしばしば外部要因を責める罠に陥りました。「上司が理解してくれない」「リソースが足りない」「時間がない」。こうした言い訳の背後には、自分には何もできないという無力感が潜んでいました。転機となったのは、ある先輩エンジニアの何気ない一言でした。「できないことを嘆くより、できることから始めよう」。この単純な言葉が、私の視点を180度変えました。実践としては、まず「自分がコントロールできること」と「できないこと」を明確に区別することから始めました。プロジェクトの期限や予算は変えられなくても、自分のタスク管理方法や学習アプローチは変えられます。組織の方針は一日では変わらなくても、自分の仕事への取り組み方は変えられます。手の届く範囲から行動を起こすというアプローチは、思った以上の効果をもたらしました。例えば、チーム内のコミュニケーション不足を感じたとき、「会社の文化」を嘆くのではなく、自分から定期的な情報共有の仕組みを提案し実践しました。最初は小さな変化でしたが、次第にチーム全体の雰囲気が変わっていったのです。重要なのは、一度に大きな変化を求めないことです。手の届く範囲の小さな改善を積み重ねることで、やがて大きな変化につながります。自分のタスク管理を改善し、それをチームに共有し、やがて部署全体のプロセス改善につながる—そんな小さな波紋が広がっていく経験を何度もしてきました。主体性を持つことは、すべての責任を自分で背負うことではありません。むしろ、与えられた状況の中で最善を尽くす姿勢です。外部環境や他者の行動によって影響を受けることは避けられませんが、それに対してどう反応するかは自分次第です。この「反応の選択」にこそ、私たちの自由と力があるのです。近年のSNSの普及により、世界の様々な問題が日常的に目に入るようになりました。政治的対立、環境問題、社会的不平等—こうした大きな課題を前に無力感を覚えることも少なくありません。しかし、インターネット上での憤りや議論よりも、自分の身近な環境での具体的な行動の方が、実は大きな影響力を持つことに気づきました。ある友人は常にSNSで社会問題への憤りを表明し、熱心に議論を重ねていました。その情熱自体は素晴らしいのですが、彼自身の日常生活はむしろ混乱し、身近な人間関係は悪化していきました。一方、別の友人は地域の小さなボランティア活動に参加し、職場での無駄な会議を減らす提案をし、家族との時間を大切にしていました。彼女の影響力は限定的に見えましたが、周囲の人々に確かな変化をもたらしていたのです。この対比から学んだのは、変化を起こすには抽象的な怒りよりも具体的な行動が必要だということです。世界の問題に無関心になる必要はありませんが、まずは自分の足元から変えていくことの方が、実は大きな影響を及ぼすのです。職場での小さな改善、コミュニティへの参加、家族との関係改善—これらの「手の届く範囲」でのアクションこそが、実感できる変化をもたらすのです。世界全体を変えることはできなくても、自分の周囲を少しずつ良くしていくことはできます。そして、それこそが本当の意味での変革の始まりなのかもしれません。「自分の手が届く範囲を見極め、そこで最善を尽くす」。この原則は、プログラミングの世界でも、人間関係でも、自己成長においても、普遍的に通用する智恵だと信じています。20代を通じて培ったこの主体性の姿勢こそが、これからの人生をより豊かにしてくれる基盤になると確信しています。純粋なコミュニケーションの場として趣味の世界には、特筆すべき素晴らしい特徴があります。それは、言語や肩書、経歴、年齢といった社会的な属性を超えて、純粋にコミュニケーションを取れる場だということです。例えば柔術の道場では、普段は大企業のCTOを務める人も、起業したばかりの若者も、同じ白帯から始める。彼らも先にいる高校生の先輩から技術やルールを教わる。この「まっさらな関係性」がもたらす対話には、特別な価値があります。普段の仕事場では決して出会えない視点や、思いもよらない発想との出会いが、そこにはあります。肩書や経歴という前提を取り払った時、人と人との純粋な対話が生まれ、そこから思わぬ化学反応が起きる。時には、仕事上では決して出会えなかったであろう人との深い友情が芽生えることもあります。視野の広がりと深さそれぞれの世界には、実に多様な人々がいる。IT界隈で関わる人々、格闘家、指導者、そして同じ志を持つ仲間たち。合理的な思考の持ち主もいれば、直感を重視する人もいる。几帳面な性格の人もいれば、大雑把だが重要なところは外さない人もいる。技術的な探求を究める人もいれば、人とのつながりを大切にする人もいる。こうした異なる世界で出会う多様な人々との交流は、人間の懐の深さを教えてくれた。プログラミングの世界では型にはまらないと思えた人が格闘技では素晴らしい才能を発揮したり、逆に格闘技では消極的だった人がプログラミングでは革新的なアイデアを出したり。「この世には本当にいろんな人がいる」という当たり前の事実が、深い実感として心に染み込んでいった。仕事との向き合い方仕事を人生の中心に置くことは、決して間違った選択ではない。むしろ、それは多くの人にとって誇りある生き方です。しかし、それは唯一の道ではない。仕事への情熱を持ちながらも、異なる世界に触れることで、むしろ仕事における創造性や問題解決能力が高まるという可能性もあります。大切なのは、自分にとってのバランスを見つけることです。それは人それぞれ異なり、時期によっても変化する。仕事に没頭する時期があっても良いし、別の活動に重点を置く時期があっても良い。私はソーシャルアパートメントでの共同生活も選択している。起業家、アーティスト、料理人、フリーランスなど、実に多様な背景を持つ人々との日常的な交流は、私の世界観をさらに広げてくれた。朝の挨拶から始まり、共用キッチンでの料理の匂いや会話、休日のイベントまで。異なる価値観や生き方に触れる機会が、自然と生活の中に組み込まれているのです。趣味としての技術探求技術が仕事であり、同時に趣味でもあるというエンジニアは少なくありません。一見矛盾しているように思えるかもしれませんが、仕事としての技術と趣味としての技術は、実は全く異なる性質を持っていることに気づかされました。仕事としての技術探求には、納期やクライアントの要望、チームの方針など、様々な制約があります。一方、趣味としての技術には、そうした制約から解放された自由があります。好奇心のままに新しい言語を学んだり、実用性よりも面白さを優先した実験的なプロジェクトに取り組んだり、業務では使わないニッチな技術を深く掘り下げたり。この「遊び心」こそが、イノベーションの源泉となることもあるのです。私の友人には、仕事ではJavaを書く傍ら、プライベートではRustでゲームを開発している人がいます。また別の友人は、平日はフロントエンド開発者として働きながら、週末には機械学習の実験に没頭しています。彼らに共通するのは、技術を「ただの仕事」ではなく「創造的な表現の場」として楽しんでいるという点です。技術が趣味であることの利点は計り知れません。業界のトレンドに先駆けて新技術に触れる機会が増え、それが結果的にキャリアにも好影響を与えることもあります。また、仕事では実現できないアイデアを形にする喜びは、エンジニアとしてのモチベーションを維持する上でも大きな支えとなります。しかし同時に、技術だけが趣味になることのリスクも認識しておくべきでしょう。同じ思考の枠組みの中で仕事も趣味も過ごすことで、視野が狭まる可能性があります。だからこそ私は、技術を趣味にしつつも、全く異なる世界（格闘技、読書会など）にも関わることで、バランスを取るよう心掛けています。技術を愛する気持ちを持ち続けながらも、一つの領域に閉じこもらず、多様な経験を通じて自分の世界を広げていく。そのバランス感覚こそが、長く充実したエンジニア人生を歩む鍵なのかもしれません。仕事で書くコードと趣味で書くコードの間に境界線を引くことで、どちらも深く楽しめるようになるのです。趣味がもたらす自己受容と成長のバランス人生は絶えず変化の連続であり、栄光に満ちた高揚の時も、挫折や失意に沈む時も等しく訪れる。この浮き沈みの中で、単純な自己肯定感の追求は時に自己欺瞞へと変質しかねない。趣味という別の世界を持つことは、この現実と向き合う上で意外な強さを与えてくれる。理想的な自分像を無理に描き、それに合わせようとする試みよりも、自己の限界や弱さを冷静に認識し、時には厳しい自己批判と向き合う勇気を持つことが重要だろう。自分が価値ある人間だと思う必要はないです。わたしたちはどんな状況にあっても自分にないものではなくて自分にあるものに目を向ける自分が何を与えられるかを考える。多様な趣味や活動を通じて得られる経験は、一つの世界での挫折や失敗を相対化する視点を与えてくれる。この「否定的な側面との共存」は一見すると消極的に思えるかもしれないが、実はより確かな地に足をつけた生き方へとつながる。完璧を求めるのではなく、自分の欠点を受け入れながらも成長を続ける柔軟性こそが、強さであり、長期的な精神的安定の基盤となる。日々の小さな挑戦と失敗を通じて鍛えられる心の筋肉が、やがて人生の大きな嵐にも耐えうる本物の自己受容へと導いてくれるのです。趣味の世界で経験する小さな成功と失敗は、この心の筋肉を鍛える絶好の機会となる。コミュニティを育てる喜び趣味の世界で得られる最も素晴らしい経験の一つが、コミュニティの一員として成長し、やがてそれを育てる立場になることです。初めは一人の参加者として入ったコミュニティで、次第に自分の役割を見つけ、仲間と共に成長していく過程は何物にも代えがたい喜びをもたらします。プログラミングのメンター活動や勉強会の主催、格闘技の初心者指導など、自分が学んだことを他者に伝える経験は、単なる知識の伝達以上の意味を持ちます。教えることで自分自身の理解が深まり、コミュニティへの貢献が自己成長へと循環するのです。コミュニティ活動を通じて培われる「つながり」は、単なる人脈以上の価値があります。共通の興味や情熱で結ばれた絆は、時に職場での関係よりも長く、深く続くことがあります。苦楽を共にした仲間との関係は、人生の様々な局面で支えとなり、励みとなるのです。特に技術の世界では、個人の力には限界があります。しかし、志を同じくする仲間が集まれば、一人では決して成し遂げられない成果を生み出すことができます。コミュニティの力は、個の総和を超える可能性を秘めているのです。人脈づくりの罠異業種交流会とか意味ないので（ボクにとってはそうだった）早めに行くのは辞めましょう。人脈なんて作るな...薄い繋がりはまじで意味ない。結局、形だけの名刺交換や表面的な会話で生まれる関係に何の価値があるのか。時間の無駄以外の何物でもない。本当に価値ある関係は自然と生まれるもので、無理に構築しようとする「人脈作り」なんて、所詮は見返りを求めた打算的な行為でしかないんだ。「人脈を広げましょう」「コネクションが大事です」—こういった言葉を若いときは、よく聞くかもしれません。でも、ただ数を増やすだけの繋がりに何の意味があるのでしょうか。名刺を何百枚も集めたところで、あなたの人生が豊かになるわけではありません。本当の関係性は、共通の興味や価値観、経験を通じて自然と育まれていくものです。形式的な交流会で作られた薄っぺらな繋がりは、いざという時に役立つことはほとんどありません。むしろ、それらの場に参加することで失われる時間と精神的エネルギーを考えると、明らかにマイナスです。特に内向的な性格の人にとって、こうした無理な社交は大きなストレスとなります。自分の性格や価値観に合わない環境に身を置き続けることは、自己否定にもつながりかねません。私たちが求めるべきは「人脈」ではなく「関係性」です。表面的なネットワーキングに時間を費やすよりも、本当に共感できる少数の人との深い繋がりを大切にする方が、長い目で見れば遥かに価値があるのです。そして皮肉なことに、そのような本質的な関係こそが、結果として最も頼れるネットワークになっていくのです。見返りを求めない真摯な関わりの中から、本当の意味での助け合いは生まれてくるのです。人脈作りに走る前に、まずは自分自身を磨くことに集中しましょう。優れた専門性や人間性を持つ人の周りには、自然と価値ある人間関係が形成されていきます。質の高い自分でいることが、質の高い関係を引き寄せる最短の道なのです。新しい可能性への扉「世界は広がり続けることもできるし、狭まり続けることもできる。その選択は、あなたの手の中にある」「あなたの選ぶ道は、あなただけのものです。仕事一筋でも、複数の顔を持つのでも、それはあなたの選択であり、どちらも等しく素晴らしい。ただし、その選択が本当にあなたの望むものですことを、時には立ち止まって確認してほしい」新しい世界への扉は、いつでも開かれている。その扉を開けるかどうかは、完全にあなたの自由です。ただし、一度開いた扉が、思いもよらない景色へとあなたを導くかもしれない。それもまた、人生という旅の醍醐味なのかもしれない。おわりにああ、ついに書ききりました。20代という、人生の大きな章の終わり。この文章を書き終える今、私は30代への一歩を踏み出そうとしています。正直に告白します。これまでの章で私は、少し格好をつけて書いていた部分があります。実際の20代は、もっと混沌としていて、もっと未熟で、時にはみっともない失敗の連続でした。同じ時間でもっと賢く生きられたかもしれない。もっと多くを学べたかもしれない。もっと早く気づけたかもしれない。そんな後悔だらけなのでめちゃくちゃに長い。それでも、この不完全な旅路が、今の私を形作っていることは間違いありません。思えば20代の終わりの私は、まるで大きな冒険を終えた冒険者のようです。ただし、物語の主人公のように劇的な冒険ではなく、ほとんどの人と同じような、地味で緩やかな旅路でした。10代の頃とは違い、必ずしも目に見える勲章や称号を手に入れたわけではありません。その代わりに得たのは、目に見えない経験値と、心の奥底に刻まれた記憶の数々です。失敗から学ぶ勇気、挑戦し続ける意志、そして何より、自分自身と向き合う誠実さ。これらは、誰にも証明できませんが、確かに私の中に育まれた宝物です。失敗の本質は、失敗そのものではなく、そこから学ぼうとしない傲慢さと、恥をかくことを過度に恐れる心にあるということに、気づくまでに随分と時間がかかりました。20代は「若さという言い訳」と「未熟さという現実」の間で揺れ動いた時期でした。時には言い訳に逃げ込み、時には現実から目を背け、それでも何とか前に進もうともがいていた日々。たくさんの人に迷惑をかけ、何度も逃げ出したくなり、時には自分自身が嫌になることもありました。いつも前向きだったわけではない。むしろ、自己嫌悪や焦燥感に苛まれる時間の方が長かったかもしれない。それでも、そんな混沌とした日々の中で、少しずつ自分なりの答えを見つけていった。世界を変えるような大きな成果など、私は残せていません。誰もが羨むような華々しいキャリアも築けてはいません。むしろ、一歩前進しては二歩下がるような、そんな歩みの連続でした。日々の小さな課題に取り組むだけで精一杯で、時には人並み以下の結果しか出せないこともたくさんあった。これこそが大多数の「普通の人」の現実であり、私もその一人に過ぎません。それでも、30歳を前にして、ようやくその平凡な歩みを肯定できるようになりました。大迷宮だと思っていたこのフィールドは、振り返ればチュートリアルだったのかもしれません。最初は、自分の限界と向き合うことに大きな喪失感と無力感を覚えました。でも、それは意外にも解放感をもたらしてくれた。完璧である必要はない。特別な才能がなくても良い。勇者ではなくとも、この物語の主人公は紛れもなく私自身なのだ。そして、世界の大半の人々もまた、同じように「勇者ではない」普通の主人公たちなのです。この「平凡な人々の平凡な物語」には、派手な冒険譚には決して描かれない、誰にも真似できない価値があるはずだと、少しずつ信じられるようになっていきました。私がこの文章で綴ったのは、一握りの天才による輝かしい成功物語でも、特別な才能に恵まれた人間でも人外的な努力によって何かを獲得した者の教訓でもありません。ごく普通の一人のエンジニアが、試行錯誤しながら過ごした20代の日々の記録です。時に立ち止まり、時に回り道をし、それでも確かに前に進んできた跡。そして何より、これから30代を迎える私自身への、そっと手渡す手書きの地図のようなものかもしれません。この膨大な振り返りを書き上げた理由の一つは、30代で細々とした自己啓発的な文章を書かないためでもあります。20代は自分探しと内省の時代だったかもしれませんが、いつまでも自己分析と過去の振り返りに囚われていては前に進めません。この文章は、ある意味で20代の自分との決別であり、これからは細かな分析より実践を、言葉より行動を優先させていく決意表明でもあるのです。教訓を得るための振り返りは大切ですが、それに執着しすぎて現在と未来の行動を怠ることは本末転倒です。この記録を一つの区切りとして、30代は新たなステージでの挑戦に集中していきたいと思います。あなたがこの長い文章を最後まで読んでくださったことに、心から感謝します。あなたの貴重な時間を、この不完全な物語に使っていただいたこと自体が、私にとってかけがえのない励みです。あなたの20代は、きっと私のものとは違うでしょう。同じ景色を見ても、その受け取り方は人それぞれなのですから。ただ、もしこの拙い経験の共有が、あなたの人生にほんの少しでもプラスになれば、これ以上の喜びはありません。ここで重要な確信をお伝えしたい。人生の価値は、外からの評価や世間的な成功では決して測れないということ。日々の小さな成長と、真摯に生きようとする誠実さこそが、かけがえのない尊さを持つのだと思います。ただし、「物語を生きる」罠に陥らないよう注意が必要です。英雄譚や成功物語のような理想的な筋書きや、あるべき姿を追い求めるのではなく、今この瞬間を真摯に生きることが大切なのです。私たちは誰もが、完璧ではないけれど、それでいて十分に価値ある存在です。大半の人は特別な才能や使命を持った勇者ではありませんが、それぞれの人生には独自の意味があります。あらかじめ決められた壮大な物語の主人公になろうとするのではなく、自分らしく、誇りを持って、一歩一歩を大切に歩んでいきましょう。今、この瞬間から始まる新しい章に向かって。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","isoDate":"2025-05-01T19:59:32.000Z","dateMiliSeconds":1746129572000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rustでスクリーンショットを撮影してOpenCVで画像処理を行う方法と依存せずに使う方法","link":"https://syu-m-5151.hatenablog.com/entry/2025/05/01/003411","contentSnippet":"はじめにMacBookでRustを使ってスクリーンショットを撮る方法について紹介します。この記事では、次の2つのアプローチを解説します：OpenCVを活用する方法 — 画像処理の多彩な機能を利用外部ライブラリに依存しない方法 — シンプルながら効果的それぞれのアプローチには利点と課題があります。詳細なコード例を交えながら、最終的にはSlackウィンドウを自動検出する実用的なテクニックまでご紹介します。最近ではマルチモーダルAIの発展により、AIシステムもスクリーンショットの取得と分析を行うことが増えています。生成AIが画面の視覚情報を理解し、より的確な支援を提供するためには、高品質なスクリーンショット機能が不可欠です。本記事で紹介する技術は、そうしたAIシステムの視覚的入力にも応用できるでしょう。目次はじめに目次使用するクレートmacOS環境のセットアップOpenCVのインストール（OpenCVアプローチの場合）LLVMとClangのインストール（OpenCVアプローチの場合）環境変数の設定（OpenCVアプローチの場合）XCapのみのセットアップ（シンプルアプローチ）Cargo.tomlの設定OpenCVアプローチの場合OpenCVに依存しないアプローチの場合OpenCVアプローチ：基本的なスクリーンショット処理MacOSでの画像保存の問題と解決策OpenCVに依存しないアプローチ簡易な画像解析を実装する実用例：Slackスクリーンショットモニタートラブルシューティング1. libclang.dylibが見つからない場合2. OpenCVのライブラリが見つからない場合3. リンクエラー: imwrite, imencodeなどの関数が見つからないまとめ参考リンク使用するクレート今回使用する主なクレートは以下の通りです：xcap - Rust製のクロスプラットフォーム対応スクリーンキャプチャライブラリopencv - OpenCVのRustバインディング（OpenCVアプローチのみ）macOS環境のセットアップMacBookでスクリーンショット処理を行うための環境構築について解説します。OpenCVのインストール（OpenCVアプローチの場合）Homebrewを使って簡単にOpenCVをインストールできます：brew install opencvLLVMとClangのインストール（OpenCVアプローチの場合）opencv-rustクレートはバインディング生成にlibclangを使用しています：brew install llvm環境変数の設定（OpenCVアプローチの場合）OpenCVとLLVMを正しく検出するために、以下の環境変数を設定します。これらの設定は.zshrcや.bash_profileに追加しておくと便利です：# OpenCV設定export OPENCV_LINK_LIBS=\"opencv_core,opencv_imgproc,opencv_highgui,opencv_videoio\"export OPENCV_LINK_PATHS=\"/opt/homebrew/lib\"  # Apple Siliconの場合export OPENCV_INCLUDE_PATHS=\"/opt/homebrew/include/opencv4\"# LLVM/Clang設定export LIBCLANG_PATH=$(brew --prefix llvm)/libexport DYLD_LIBRARY_PATH=$(brew --prefix llvm)/lib:$DYLD_LIBRARY_PATH注意: パスはApple Siliconモデルの場合です。Intel Macでは異なる場合があります。brew --prefix opencv コマンドで確認できます。XCapのみのセットアップ（シンプルアプローチ）OpenCVを使わない場合は、xcapクレートだけをインストールします：cargo add xcapCargo.tomlの設定プロジェクトのCargo.tomlファイルは以下のようになります：OpenCVアプローチの場合[dependencies]xcap = \"0.0.4\"opencv = { version = \"0.94.4\", features = [\"clang-runtime\"] }OpenCVに依存しないアプローチの場合[dependencies]xcap = \"0.0.4\"OpenCVアプローチ：基本的なスクリーンショット処理OpenCVを使ったスクリーンショット処理の基本的なコードを紹介します：use std::time::Instant;use xcap::Monitor;use opencv::prelude::*;use opencv::core::{Mat, Size, CV_8UC4};use opencv::imgproc;use opencv::highgui;fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    // OpenCVのウィンドウを作成    highgui::named_window(\"Screenshot\", highgui::WINDOW_AUTOSIZE)?;    highgui::named_window(\"Processed\", highgui::WINDOW_AUTOSIZE)?;    println!(\"Press 'q' to exit\");    // メインループ    loop {        let start = Instant::now();        // プライマリモニターを取得        let monitors = Monitor::all()?;        let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))            .unwrap_or(\u0026monitors[0]);        // スクリーンショットを撮影        let image = primary_monitor.capture_image()?;        let width = image.width() as i32;        let height = image.height() as i32;                // ピクセルデータを取得        let raw_pixels = image.as_raw();        // OpenCVのMat形式に変換        let mat = unsafe {            let mut mat = Mat::new_size(Size::new(width, height), CV_8UC4)?;            let mat_data = mat.data_mut();            std::ptr::copy_nonoverlapping(                raw_pixels.as_ptr(),                mat_data,                (width * height * 4) as usize            );            mat        };        // 元のスクリーンショットを表示        highgui::imshow(\"Screenshot\", \u0026mat)?;        // 画像処理の例: グレースケール変換        let mut gray = Mat::default();        imgproc::cvt_color(            \u0026mat,             \u0026mut gray,             imgproc::COLOR_BGRA2GRAY,             0,             opencv::core::AlgorithmHint::ALGO_HINT_DEFAULT        )?;        // エッジ検出の例        let mut edges = Mat::default();        imgproc::canny(\u0026gray, \u0026mut edges, 100.0, 200.0, 3, false)?;        // 処理した画像を表示        highgui::imshow(\"Processed\", \u0026edges)?;        // 処理時間を表示        println!(\"処理時間: {:?}\", start.elapsed());        // キー入力を待つ（10ms）        let key = highgui::wait_key(10)?;        if key == 'q' as i32 || key == 'Q' as i32 {            break;        }    }    Ok(())}このコードは以下のことを行います：XCapを使ってプライマリモニターのスクリーンショットを撮影スクリーンショットのデータをOpenCVのMat形式に変換元のスクリーンショットを表示し、グレースケール変換とエッジ検出を適用した処理結果も表示OpenCVを使う大きなメリットは、豊富な画像処理機能を利用できることです。グレースケール変換、エッジ検出、顔認識など多様な処理が可能です。MacOSでの画像保存の問題と解決策MacOSでOpenCVのimwriteやimencode関数を使用すると、リンクエラーが発生することがあります。以下のカスタム関数を使用して回避できます：// MacOS環境のためのOpenCVラッパー関数fn save_image(filename: \u0026str, img: \u0026Mat) -\u003e Result\u003cbool, Box\u003cdyn std::error::Error\u003e\u003e {    // Rustのファイル操作を使用してOpenCVのMatをPNGとして保存    println!(\"画像を保存しています: {}\", filename);        // エンコード用のベクタ    let mut buf = opencv::core::Vector::new();        // BGR形式の画像をPNGにエンコード    opencv::imgcodecs::imencode(\".png\", img, \u0026mut buf, \u0026opencv::core::Vector::new())?;        // ファイルに書き込み    fs::write(filename, buf.as_slice())?;        Ok(true)}しかし、この関数もOpenCVのバージョンやMacOSの設定によってはエラーになる場合があります。その場合は次に説明するOpenCVに依存しないアプローチを検討することをお勧めします。OpenCVに依存しないアプローチOpenCVのリンクエラーや複雑な設定を避けたい場合は、XCapクレートのみを使用したシンプルなアプローチも可能です：use std::time::Instant;use std::fs;use xcap::Monitor;fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    println!(\"スクリーンショットプログラムを開始しました\");    println!(\"終了するには Ctrl+C を押してください\");    // メインループ    loop {        let start = Instant::now();        // プライマリモニターを取得        let monitors = Monitor::all()?;        let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))            .unwrap_or(\u0026monitors[0]);        // スクリーンショットを撮影        let image = primary_monitor.capture_image()?;                // スクリーンショットを保存        let timestamp = std::time::SystemTime::now()            .duration_since(std::time::SystemTime::UNIX_EPOCH)?            .as_secs();        let filename = format!(\"screenshot_{}.png\", timestamp);                // XCapのsaveメソッドを使用して直接保存        image.save(\u0026filename)?;                println!(\"スクリーンショットを保存しました: {}\", filename);        println!(\"処理時間: {:?}\", start.elapsed());                // 適当な間隔を空ける        std::thread::sleep(std::time::Duration::from_secs(5));    }    Ok(())}このアプローチのメリットは：セットアップが格段に簡単（OpenCVやLLVMのインストールが不要）リンクエラーなどのトラブルが少ない軽量で高速一方、デメリットは：高度な画像処理機能が使えない独自の画像解析ロジックを実装する必要がある簡易な画像解析を実装するOpenCVを使わずに簡易な画像解析を行う例として、特定の色を検出するコードを示します：// 簡易な色検出機能fn detect_color(rgba_data: \u0026[u8], width: u32, height: u32) -\u003e bool {    // 特定の色の範囲（RGB値）    let target_lower_r = 200;    let target_lower_g = 0;    let target_lower_b = 0;        let target_upper_r = 255;    let target_upper_g = 100;    let target_upper_b = 100;        let mut target_pixel_count = 0;    let total_pixels = (width * height) as usize;        // ピクセルデータを4バイトずつ処理（RGBA）    for i in (0..rgba_data.len()).step_by(4) {        if i + 2 \u003c rgba_data.len() {            let r = rgba_data[i];            let g = rgba_data[i + 1];            let b = rgba_data[i + 2];                        // 指定した範囲内の色かどうかを判定            if r \u003e= target_lower_r \u0026\u0026 r \u003c= target_upper_r \u0026\u0026               g \u003e= target_lower_g \u0026\u0026 g \u003c= target_upper_g \u0026\u0026               b \u003e= target_lower_b \u0026\u0026 b \u003c= target_upper_b {                target_pixel_count += 1;            }        }    }        // 閾値: 特定の色のピクセルが一定数以上あれば検出成功    let threshold_ratio = 0.01; // 全ピクセルの1%以上    let has_enough_pixels = (target_pixel_count as f64 / total_pixels as f64) \u003e threshold_ratio;        has_enough_pixels}このコードはRGBA値を直接処理して、指定した色範囲のピクセル数をカウントします。単純ですが、特定の色を持つUIエレメントの検出などには十分な場合があります。実用例：Slackスクリーンショットモニター参考的な例として、Slackウィンドウを自動検出してスクリーンショットを保存するアプリケーションを作ってみましょう。以下では、OpenCVに依存しないシンプルなバージョンを紹介します：use std::time::{Instant, Duration, SystemTime};use std::fs;use std::path::Path;use std::thread;use xcap::Monitor;// スクリーンショット撮影の設定const SCREENSHOT_INTERVAL: u64 = 5; // 5秒ごとにスクリーンショットを撮影const SAVE_PATH: \u0026str = \"slack_screenshots\";// 簡易なSlackウィンドウ検出機能fn detect_slack_window(rgba_data: \u0026[u8], width: u32, height: u32) -\u003e bool {    // Slackの紫色の範囲（RGB値）    let purple_lower_r = 100;    let purple_lower_g = 50;    let purple_lower_b = 130;        let purple_upper_r = 170;    let purple_upper_g = 100;    let purple_upper_b = 210;        let mut purple_pixel_count = 0;    let total_pixels = (width * height) as usize;        // ピクセルデータを4バイトずつ処理（RGBA）    for i in (0..rgba_data.len()).step_by(4) {        if i + 2 \u003c rgba_data.len() {            let r = rgba_data[i];            let g = rgba_data[i + 1];            let b = rgba_data[i + 2];                        // 指定した範囲内の紫色かどうかを判定            if r \u003e= purple_lower_r \u0026\u0026 r \u003c= purple_upper_r \u0026\u0026               g \u003e= purple_lower_g \u0026\u0026 g \u003c= purple_upper_g \u0026\u0026               b \u003e= purple_lower_b \u0026\u0026 b \u003c= purple_upper_b {                purple_pixel_count += 1;            }        }    }        // 閾値: 紫色のピクセルが一定数以上あればSlackウィンドウと判断    let threshold_ratio = 0.001; // 全ピクセルの0.1%以上が紫色    let has_enough_purple = (purple_pixel_count as f64 / total_pixels as f64) \u003e threshold_ratio;        // デバッグ用（閾値調整に便利）    println!(\"紫色ピクセル数: {}, 全ピクセル数: {}, 比率: {:.6}\",         purple_pixel_count, total_pixels, purple_pixel_count as f64 / total_pixels as f64);        has_enough_purple}fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    // 保存用ディレクトリの作成    if !Path::new(SAVE_PATH).exists() {        fs::create_dir(SAVE_PATH)?;    }    println!(\"Slackスクリーンショットモニタリングを開始しました\");    println!(\"スクリーンショットは{}ディレクトリに保存されます\", SAVE_PATH);    println!(\"終了するには Ctrl+C を押してください\");    let mut last_saved_time = Instant::now() - Duration::from_secs(SCREENSHOT_INTERVAL);    let mut screenshot_count = 0;    // メインループ    loop {        let current_time = Instant::now();                // 指定した間隔が経過したらスクリーンショットを撮影        if current_time.duration_since(last_saved_time).as_secs() \u003e= SCREENSHOT_INTERVAL {            last_saved_time = current_time;                        // すべてのモニターを取得            let monitors = Monitor::all()?;            let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))                .unwrap_or(\u0026monitors[0]);                        // スクリーンショットを撮影            let image = primary_monitor.capture_image()?;            let width = image.width();            let height = image.height();                        // XCapのImageからRGBAデータを取得            let rgba_data = image.as_raw();                        // Slackウィンドウの検出            if detect_slack_window(rgba_data, width, height) {                // スクリーンショットを保存                let timestamp = SystemTime::now()                    .duration_since(SystemTime::UNIX_EPOCH)?                    .as_secs();                let filename = format!(\"{}/slack_screenshot_{}.png\", SAVE_PATH, timestamp);                                // XCapのsaveメソッドを使用して直接保存                image.save(\u0026filename)?;                                println!(\"Slackウィンドウを検出しました。スクリーンショットを保存: {}\", filename);                screenshot_count += 1;            }        }                // CPUの負荷を下げるためのスリープ        thread::sleep(Duration::from_millis(500));    }}このアプリケーションは：定期的にスクリーンショットを撮影画面上にSlackの特徴的な紫色が一定量以上あるかを検出Slackウィンドウと判断された場合、スクリーンショットを保存トラブルシューティングMacBookでRustとOpenCVを使う際によく遭遇する問題と解決法をまとめます。1. libclang.dylibが見つからない場合エラーメッセージ:dyld: Library not loaded: @rpath/libclang.dylib解決策:brew install llvmexport LIBCLANG_PATH=$(brew --prefix llvm)/libexport DYLD_LIBRARY_PATH=$(brew --prefix llvm)/lib:$DYLD_LIBRARY_PATH2. OpenCVのライブラリが見つからない場合エラーメッセージ:Failed to find installed OpenCV package解決策:正しいパスを環境変数に設定します：export OPENCV_LINK_LIBS=\"opencv_core,opencv_imgproc,opencv_highgui,opencv_videoio\"export OPENCV_LINK_PATHS=\"/opt/homebrew/lib\"  # Apple Siliconの場合export OPENCV_INCLUDE_PATHS=\"/opt/homebrew/include/opencv4\"3. リンクエラー: imwrite, imencodeなどの関数が見つからないエラーメッセージ:Undefined symbols for architecture arm64: \"cv::imwrite...\"解決策:1. OpenCVを完全に再インストールしてみる：   bash   brew uninstall --ignore-dependencies opencv   brew install opencv  それでも解決しない場合は、OpenCVに依存しないアプローチに切り替えるまとめこの記事では、MacBook環境でRustを使ってスクリーンショットを撮影し処理する2つのアプローチを紹介しました。OpenCVを使ったアプローチ：メリット：高度な画像処理機能が使えるデメリット：セットアップが複雑、リンク問題が発生することがあるOpenCVに依存しないアプローチ：メリット：シンプルで信頼性が高い、セットアップが容易デメリット：高度な画像処理機能を自分で実装する必要があるそれぞれのアプローチにはメリット・デメリットがありますが、用途に応じて適切な方法を選択することで、Rustの安全性と高パフォーマンスを活かした画像処理アプリケーションを開発できます。実用例として紹介したSlackスクリーンショットモニターは、このようなスクリーンショット処理の応用例の一つです。この基本的なアプローチを発展させて、画面録画ツール、監視アプリケーション、自動化ツールなど、様々な実用的なアプリケーションを開発することができます。参考リンクXCap GitHub リポジトリOpenCV Rust GitHub リポジトリOpenCV 公式ドキュメントHomebrew","isoDate":"2025-04-30T15:34:11.000Z","dateMiliSeconds":1746027251000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","contentSnippet":"はじめにこんにちは、nwiizoです。2025年4月22日と23日、スケジュールの都合で連続して2つの技術イベントに登壇することになりました。それぞれのイベントは異なる切り口でしたが、どちらも「生成AI」をテーマにしたものでした。1日目は「生成AI」と「クラウドネイティブ」の融合、2日目は「生成AI」の「Model Context Protocol（MCP）」に焦点を当てました。生成AI技術は近年急速に進化し、私たちエンジニアの働き方に大きな影響を与えています。私自身も数年前からnvimでGitHub Copilotを日常的に使い、その後Clineなどのコーディングエージェントブームのバズに押されつつもCursorやVSCodeを利用しています。同時に、Cloud Native技術も着実に成熟し、多くの企業のインフラ戦略の中核となっています。現在、これら二つの技術領域が交わることで、特にIaC（Infrastructure as Code）分野での応用が活発化しています。多くの開発者がこの統合に関して様々な課題に直面しており、今回の登壇では、そうした課題に対する私なりの考察と解決策を共有しました。本ブログでは、この2日間の登壇内容を振り返りながら、技術的な洞察やコミュニティでの議論から得た気づきを記録したいと思います。生成AIとクラウドネイティブ技術の統合が開発・運用プロセスを根本から変革しています。本稿はエンジニアが直面する「70%問題」（AIがコードの70%は正確に生成するが、残り30%で致命的ミスを犯す現象）に対して、ガードレールとModel Context Protocol (MCP)の相補的活用による解決策を提案します。インフラ/アプリケーションエンジニアは「思考パートナー」としてAIを活用し、検証文化を確立することで、開発効率と品質を両立できます。本記事では、両イベントでの登壇内容をもとに、AIを単なるツールから戦略的パートナーへと位置づけ直す視点と、認知労働の新たな分担を実現する実践的なフレームワークについて詳しく解説します。Day 1: 生成AIとCloud Nativeの融合を語るイベント: CloudNative Days Summer 2025 プレイベント登壇タイトル: 生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について日時: 2025年4月22日https://cloudnativedays.connpass.com/event/351211/cloudnativedays.connpass.com1日目は、CloudNative Days Summer 2025のプレイベントに参加しました。このイベントの参加者層は主にインフラエンジニアやSRE（Site Reliability Engineer）が中心で、Cloud Native技術への関心が高い方々です。私のセッションでは、生成AIを活用したCloud Native基盤構築について、実践的な観点から解説しました。発表資料 speakerdeck.com発表の詳細セッション内容は以下の4つの大きなセクションに分けて構成しました：1. 生成AIとCloud Nativeの現在地（2025年）まず、現在の生成AIによる開発プロセスの変化について解説しました。従来のコード生成から問題解決支援へと進化しており、AIは単なる「道具」から「思考パートナー」へと変わりつつあります。これは根本的な変化であり、単なる機能向上ではありません。AIが書かれるコードの構文パターンだけでなく、構築されるものの概念モデルに関与できるようになった結果、協働のダイナミクスが質的に変化しています。AIの利用パターンも単発指示→会話型→継続的協働へと発展し、長期的な文脈理解ができるようになっています。これにより、開発ワークフローも大きく変化しています。- コードレビューの前段階をAIが担当し、人間は高次の設計判断に集中- ボイラープレートコードからの解放で、より創造的な作業への時間が増加- テスト品質の標準化によるソフトウェア信頼性の向上しかし実際のところ、AIによるCloud Native実装は「完璧」ではなく、「ある程度必要」な取り組みとして捉えるべきだと強調しました。現場では、以前は「動かない定義」や「架空の機能」に悩まされましたが、モデルの精度向上により問題は大幅に減少しています。それでも、いわゆる「ハルシネーション」と呼ばれる問題は依然として存在するため、AIの出力を盲信せず、検証する姿勢が重要です。特にIaC（Infrastructure as Code）においては、コードと実際のインフラの間に差異が生じることも珍しくありません。AIが生成したインフラ定義は、理想的な環境を想定していることが多く、実際の環境の制約やレガシーシステムとの互換性といった現実的な問題に対応できていないケースがあります。そのため、多くの組織では完全自動化ではなく、ある程度抽象化したり省力化したりしながら、人間による確認と調整を組み合わせたハイブリッドなアプローチを採用しています。これにより、AIの効率性と人間の判断を最適に組み合わせたCloud Native環境の管理が実現されています。learning.oreilly.com2. 実践的なプロンプト設計効果的なAI活用のための「プロンプト設計の5原則」を紹介しました：方向性を与える（Give Direction）具体的な指示や目的を明確に示す例：「高可用性と費用対効果を重視したプロダクション環境向けECSクラスタを作成するTerraformコード」のように具体的にフォーマットを指定する（Specify Format）望ましい出力形式を明確に定義する例：コーディングスタイル、ファイル分割方針などを明示的に記述例を提供する（Provide Examples）期待する出力のサンプルを示す既存の成功パターンを参考に提示する品質を評価する（Evaluate Quality）生成された結果の品質を測定・改善する方法を組み込むセキュリティ、可用性、コスト最適化などの観点を明示作業を分割する（Break Down Tasks）複雑なタスクをより小さな段階に分割するステップバイステップのアプローチを促すこれらの原則を実践することで、生成AIからより質の高い出力を得られることを実例とともに解説しました。また、コンテキスト同梱の重要性についても言及し、意思決定の背景や根拠を明示的に残すことで、組織の暗黙知が形式知化される利点を強調しました。learning.oreilly.com3. ガードレールの構築の手引き生成AIの出力に対する「ガードレール」の重要性を解説しました。ここで特に強調したのが「70%問題」です。これは単なる効率の問題ではなく、ロジスティクスにおける「ラストマイル問題」やロボティクスにおける「不気味の谷」に類似した現象です。完成に近づくほど、残りの課題は不釣り合いに困難になります。しかし、インフラストラクチャにおいて、この残りの30%は単に非効率なだけでなく、潜在的に壊滅的な問題を引き起こす可能性があります。生成AIは通常、コードの約70%は驚くほど正確に生成できますが、残りの30%で致命的なミスを犯すことがあります。特にIaCのような厳密性が求められる領域では、この問題が顕著です。AWS IAMポリシー生成時に過剰な権限を付与する傾向リソース間の複雑な依存関係の理解不足コスト最適化を考慮しない設計提案これを「優秀だが何も確認しない若手開発者」と表現し、スピードは速いがIaC特有の制約を無視してしまう傾向があることを指摘しました。この問題への対策として、以下のようなガードレールを提案しました：コード品質検証構文チェック、静的解析、コーディング規約の自動適用セマンティック検証リソース間の整合性や依存関係の正確性を検証セキュリティ検証脆弱性スキャン、最小権限原則の適用コンプライアンス検証組織ポリシーや法規制への適合性確認コスト最適化検証リソース効率や予算管理の自動チェックこれらのガードレールは、特にPull Requestの段階で自動適用することで、問題の早期発見と修正を可能にします。また、単なる検証だけでなく、AIの解釈コストを考慮した仕様の記述方法についても言及しました。syu-m-5151.hatenablog.com4. ガードレールを超えて行動するMCP最後に、Model Context Protocol（MCP）を活用した次世代のAI活用法について紹介しました。MCPはAIモデルが外部ツールやデータにアクセスするための標準プロトコルで、「AIとシステムをつなぐUSB規格」とも表現できます。しかし、この比喩は理論的な重要性を過小評価しています。USBは物理的な接続を標準化しましたが、MCPは認識論的な接続—知識がどのようにアクセス、検証、適用されるかを標準化しているのです。MCPとガードレールの補完関係は弁証法的関係とも言えます。ガードレールは出力の「安全性」「品質」を確保（アウトプット品質）MCPは入力の「情報量」「正確性」を向上（インプット品質）この相補的な関係は、次のような弁証法的パターンを形成します。テーゼ：AIは限られたコンテキストに基づいてコードを生成アンチテーゼ：人間はガードレールを通じてこのコードを検証・修正統合：MCPはAIのコンテキストを拡張し、検証の必要性を減少（ただし排除はしない）両者を組み合わせることで、70%問題の克服に近づける可能性を示しました。ただし、人間の判断の必要性は排除されるのではなく、人間の役割が「構文の検証者」から「概念的アプローチの検証者」へとシフトします。これは認知的労働の分担の進化を示唆しています。実際の活用例として、AWS MCP ServersやGoogle Cloudのkubectl-aiなどを紹介し、これらがクラウド環境とAIの連携を実現し、複雑なインフラ管理を自然言語で操作可能にする機能について説明しました。syu-m-5151.hatenablog.com質疑応答での議論セッション後の質疑応答では、特に以下の点について活発な議論がありました：AIによるIaC生成の信頼性向上のための具体的な取り組み組織への導入方法とチーム全体でのAI活用ポリシーCI/CDパイプラインへのガードレール組み込みの実践例特に印象的だったのは、「AIを100%信頼せず、人間の検証を常に行う文化をどう作るか」という質問で、これはまさに今のAI活用における核心的な課題だと感じました。Day 2: MCPの世界を掘り下げるイベント: AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-登壇タイトル: ここはMCPの夜明けまえ日時: 2025年4月23日https://hack-at-delta.connpass.com/event/350588/hack-at-delta.connpass.com2日目は、AI駆動開発に特化したイベントで登壇しました。こちらは主にアプリケーション開発者やAI研究者が中心の聴衆で、より技術的に深い内容を求められる場でした。私のセッションではModel Context Protocol（MCP）について詳しく解説し、実装例や将来展望について語りました。発表資料 speakerdeck.com発表の詳細MCPの基本概念から始め、その主要構成要素について詳しく解説しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得・検証する「認識論的インターフェース」とも言えるものです。この枠組みは、人間の認知プロセスを模倣しながらも、機械による利用のために標準化しています。modelcontextprotocol.io1. Resources（リソース）MCPにおけるResourcesは、LLMにコンテキストを提供する読み取り専用のデータソースです。テキスト形式とバイナリ形式のデータをURIで一意に識別し、AIの会話コンテキストとして活用します。アプリケーション制御型設計: クライアントがリソースの使用時期と方法を決定人間が読みやすい名前や説明: AIの理解を促進するためのメタデータ付き動的リソース: URIテンプレートを提供して、パラメータ化されたリソースアクセスが可能クライアントはresources/listエンドポイントでリソース発見、resources/readで内容取得、さらに購読機能で更新通知を受信できます。これにより、AIは最新のドキュメントや構成情報などを参照しながら回答を生成できるようになります。2. Prompts（プロンプト）Promptsは標準化された対話パターンを定義するテンプレートです。ユーザー制御型の再利用可能なテンプレートとして設計され、一貫したLLM体験を提供します。動的な対話フロー: 引数を受け取り、リソースから文脈を含め、複数の対話をチェーン化構造化された定義: 各プロンプトは名前・説明・引数の構造で定義クライアントインターフェース: prompts/listエンドポイントで発見し、prompts/getで使用プロンプトはリソースからの情報を埋め込み、複数のメッセージ交換を事前定義して複雑な対話フローを作成可能です。クライアントUIではスラッシュコマンドやクイックアクションとして表示され、ユーザーに直感的な操作を提供します。3. Tools（ツール）Toolsは LLM に実世界での行動力を与える機能です。サーバーが公開する実行可能な機能を介して計算処理やAPI操作を実行できます。明確な構造: 各ツールは名前、説明、入力スキーマ、アノテーションで定義動作特性の明示: 読取専用・破壊的操作・べき等性などの情報を含むエンドポイント: クライアントはtools/listで発見し、tools/callで実行ツールの用途は多岐にわたり、システム操作、外部APIラッパー、データ変換など様々なパターンでAIの能力を拡張し、実世界での影響力を高めます。4. Sampling（サンプリング）Samplingは、サーバーがLLMに補完を要求できる機能です。クラスチートを行うことなく、会話中にLLMの判断を活用できる仕組みを提供します。メカニズム: サーバーがsampling/createMessageを要求し、クライアントがレビュー後にLLMから結果を取得ヒューマンインザループ設計: ユーザーが介在することでセキュリティとプライバシーを確保柔軟な設定: 様々なパラメータで出力を調整可能（temperature、maxTokens、stopSequencesなど）サンプリングによって、エージェント的ワークフローが可能になり、データ分析、意思決定、構造化データ生成、複数ステップのタスク処理などの高度な機能を実現できます。5. Roots（ルーツ）Rootsはサーバーの操作範囲を定義する機能です。クライアントがサーバーに対して関連リソースとその場所を伝える手段として機能します。操作境界の定義: ファイルシステムパスやHTTP URLなどの有効なURIを使用ワークスペース明確化: クライアントは接続時に推奨ルーツのリストを提供柔軟な範囲設定: プロジェクトディレクトリ、リポジトリ、APIエンドポイントなどを定義Rootsにより、AIの操作範囲が明確化され、異なるリソースを同時に扱う際の組織化が容易になります。実装例と活用可能性セッションの後半では、実際のMCP実装例を紹介しました。よく紹介されているMCPを紹介してもどうしようもないので他に知見になりそうでかつ応用が効きそうなMCPを紹介しています。AWS MCP ServersAWSが提供する公式MCP実装について説明しました。github.comAWS Documentation MCP Server: AWS公式ドキュメント検索と情報提供Bedrock Knowledge Bases MCP Server: カスタムナレッジベース連携CDK MCP Server: AWS CDKプロジェクト支援Terraform MCP Server: Terraformプロバイダー情報参照Lambda MCP Server: 任意のLambda関数をMCPツールとして実行kubectl-aiGoogle Cloudの大規模言語モデルを活用したkubectlプラグインについても解説しました。github.comkubectl ai \"nginxのDeploymentを作成して、レプリカ数は3、リソース制限ありで\"kubectl ai \"なぜPodがPendingのままなのか調査して\"kubectl ai \"payment-serviceのレプリカを3から5に増やして\"このような自然言語コマンドでKubernetesクラスタを操作できる例を紹介し、MCPによる実用的な活用方法を示しました。自作MCP実装の可能性MCPの実装を通じて得られる知見の価値について触れ、「MCPは実装してこそ理解できる。実装を通じて感覚を掴み、独自の拡張も検討できる」と強調しました。github.comMCPの課題と展望MCPの将来性について議論する中で、現状の課題も率直に指摘しました：レスポンス時間の増加: 外部API呼び出しによる遅延情報統合の難しさ: 矛盾する情報の調停コンテキスト長の制限: 大量のデータ処理における限界ハルシネーション問題: 情報アクセスは改善するが、解釈ミスの可能性は残る70%→100%ではなく、実際には70%→80%程度の改善が現実的な期待値であり、人間による最終確認は依然として重要であることを強調しました。これは漸近的な信頼性向上であり、段階的な変化ではないことを示唆しています。この分野には以下のような興味深い理論的緊張関係が存在します。信頼 vs 検証: 人間による検証の持続的な必要性は、完全に自動化された開発の約束と矛盾します。一般性 vs 特殊性: AIは一般的なパターンに優れていますが、ドメイン固有の制約に苦戦する一方、人間はその逆の傾向があります。速度 vs 信頼性: AIによる開発の加速は、増加する検証負担とのバランスが必要です。抽象化 vs 実装: エンジニアがより抽象的な思考にシフトするにつれ、実装の詳細とのつながりが弱まり、新しい種類のエラーが生じる可能性があります。連日登壇を通じて感じたこと2日間の登壇を通じて、生成AIとクラウドネイティブの融合が急速に進んでいることを実感しました。特に印象的だったのは、両者の接点において：1. 補完し合う技術領域Day 1で話したガードレールとDay 2で紹介したMCPは、互いに補完する関係にあります。ガードレールがAIの出力の「安全性」「品質」を確保し、MCPが入力の「情報量」「正確性」を向上させます。この組み合わせこそが、AIの能力を最大限に引き出すための鍵です。例えば、MCPで外部情報を参照しながらIaCコードを生成し、それをガードレールで検証するというパイプラインを構築することで、より信頼性の高いインフラ構築が可能になります。これは認知労働の新たな分担を示唆しています。パターンマッチングとリコールが機械のドメインになり、概念的統合と判断が人間のドメインとして残ります。この協業体制がもたらす最も深い洞察は、我々が「プログラミングの終焉」ではなく「プログラミングの新たな改革」を目撃しているということかもしれません。2. 実装の成熟度の差技術の普及段階にも明確な違いがあります。Cloud Native環境でのAI活用は既に実用段階に入っていますが、MCPはまさに「夜明け前」の状態です。標準化は進んでいるものの、実装はまだ発展途上であり、今後急速に普及していくでしょう。特に興味深いのは、大手クラウドプロバイダーが相次いでMCP実装を提供し始めていることで、これはMCPが業界標準になりつつある証拠と言えます。現在、私たちは重要な技術的変曲点に立っているのです。3. 共通する課題どちらの領域でも、ハルシネーション（幻覚）問題や70%問題など、AIの限界をどう乗り越えるかが共通の課題となっています。完全自動化への過信は危険であり、人間による検証と理解が依然として不可欠です。重要なのは、AIをただの便利ツールではなく、自分の技術的判断力を強化するための「知的パートナー」として活用する姿勢です。優れたエンジニアは、AIの提案を鵜呑みにせず、自らの専門知識と経験に基づいて評価し、改善します。つまり、エンジニアとしての基本的な理解力や技術センスがあってこそ、AIとの協働が真に価値を生み出すのです。両イベントの参加者との議論を通じて、多くの組織がAIツールの導入に熱心である一方で、その限界や適切な活用方法についての理解はまだ発展途上であることを実感しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得し検証する「認識論的枠組み」を表しています。これはAIと人間のコラボレーションにおける根本的なシフトを示唆しています。認知労働の新たな分業開発現場では、AIを全能の魔法ではなく、特定の目的に特化した強力な助手として位置づけています。これは認知労働の新たな分業を形成しています。戦略的なAI活用アプローチ私のチームでは、AIツールを以下のような明確な目的で活用しています。プロトタイピングの加速: 新機能やアイデアの初期実装を迅速に行い、議論の土台を作るルーティン作業の自動化: テストコード生成やボイラープレートコードなど、創造性を必要としない作業の効率化知識探索の支援: ドキュメント検索やAPI仕様の理解など、情報収集を効率化コードレビューの補助: 基本的なコーディング規約やベストプラクティスのチェックこれらの活用方法は、AIと人間の間の認知労働の分業を最適化するものです。AIはパターン認識や情報検索に優れている一方、人間はコンテキスト理解や倫理的判断に長けています。この相補的な関係を活かすことで、開発効率と品質の両方を高めることができます。レビュープロセスと制約の重要性生成AIの限界を認識した上で、以下のようなガードレールを設けています。書き込み権限の制限: 生成コードは必ずレビューを経てから取り込む、というかまだ道具として適切に動作し続けることができない重要な判断の人間による最終確認: 特に権限設計やセキュリティ関連の実装対話的な生成プロセス: 一度に大量のコードを生成するのではなく、段階的に生成・修正を繰り返すこれらの制約は一見効率を下げるように思えますが、長期的には品質と信頼性の向上につながっています。これは、速度と信頼性のトレードオフを認識し、適切なバランスを取る試みと言えるでしょう。まとめ生成AIとCloud Nativeは、かつて独立した技術領域として発展してきましたが、現在その境界線は急速に溶け合いつつあります。この2日間の登壇を通じて、両技術の融合がもたらす無限の可能性と避けられない課題を、互いに補完し合う視点から考察できたことは非常に意義深い経験でした。技術の交差点に立つ私たちは、単に新しいツールを導入するだけでなく、開発プロセス全体の再構築と認知労働の新たな分担という本質的な変革の只中にいます。連日の登壇準備は骨の折れる作業でしたが、技術コミュニティの旺盛な好奇心と革新への情熱に触れることができ、その労力を遥かに上回る充実感を得ることができました。この変革の中心には、いくつかの興味深い理論的緊張関係が存在します。信頼と検証のジレンマでは、AIの自律性向上と人間による検証の継続的必要性が矛盾します。一般と特殊の相克では、AIが一般パターンに秀でる一方、ドメイン固有の制約に弱く、人間はその逆の強みを持つという相補性があります。速度と信頼性のトレードオフでは、開発速度の飛躍的向上と増大する検証負担のバランスが求められます。そして抽象化と実装の乖離では、エンジニアの思考が高次の抽象レベルへ移行するほど、具体的実装との接点が希薄化する現象が起きています。これらの緊張関係は、単なる技術的課題ではなく、ソフトウェア開発の本質的な変容を示唆しています。クラウドネイティブと生成AIの交差点に立つ私たちは、新たな技術パラダイムの構築者として、これらの緊張関係を認識しながら、持続可能な開発文化の創造に取り組む必要があります。syu-m-5151.hatenablog.com今日から俺は今後、プログラマの役割は根本から変容していくでしょう。コードを書く職人からドメインを抽象化し構成要素を再構築する建築家へと、その専門性は高度化していきます。この変化は、ソフトウェアエンジニアリングの本質における歴史的な転換点を示唆しています。www.oreilly.comこの転換点で、エンジニアの進化には二つの道筋が開かれていると思っています。ひとつはドメインエキスパートとしての道で、AIが容易に獲得できない専門知識を磨き、AIを疑い検証するメンタリティを養い、専門知識をMCPやFunction Callingとして実装し、自らが「検証者」としての価値を高める方向性です。もうひとつはパイプライン設計者としての道で、コードを直接書くのではなく、コードを生成・検証・デプロイするシステムを構築し、プロンプトエンジニアリングの技術を磨き、言語化・設計・検証のスキルを研ぎ澄まし、AIの限界を理解しそれを補完するシステムを構築する方向性です。これらの進化は、かつてのアセンブリから高水準言語への移行や、手続き型からオブジェクト指向プログラミングへの移行に似ています。各移行は低レベルの懸念事項を抽象化し、エンジニアがより高レベルのアーキテクチャに集中できるようにしてきました。私たちはいま、そのような歴史的変革の真っただ中にいるのです。最後に、この貴重な機会を提供してくださったCloudNative Days Summer 2025プレイベントおよびAI駆動開発実践の手引きイベントの運営チームの皆様に心より感謝申し上げます。両イベントの緻密な運営と温かいサポートのおかげで、充実した登壇体験ができました。また、質疑応答で鋭い質問を投げかけ、議論を深めてくださった参加者の皆様にも深く感謝いたします。これからも技術コミュニティの発展に微力ながら貢献していきたいと思います。あとがき1日目の資料は出来があまりよくなかった。良い資料だとは思うが自分の中でもう少し整理や深堀りができたはずだし、語り尽くせなかった部分もとても多い。時間がなかったという言い訳をさせてください。そもそも、CfPも落ちて本イベントでの登壇の機会も逸してしまっている。一方、2日目のMCPの資料はよくできたと思う。元々のブログがあったというのもある。正直これは100点満点中90点ぐらいの出来栄えだと自負していた。夜を徹して準備し、最新の技術動向を盛り込み、実装例も丁寧に解説した。聴衆からの反応も上々で、「これ以上ない資料ができた」とさえ思っていた。そんな矢先、mizchi氏のAfter Cline - あるいは語りえぬ者について語ろうとする時代についてという資料を目にした瞬間、天と地の差を見せつけられた気分だった。あれは単なる150点の資料ではない。次元が違う。まるで将棋で「自分は十分に読んだ」と思った直後に、相手が5手先の必勝手順を淡々と指し示すような絶望感。技術的な深さ、哲学的考察、そして何より言語化能力の圧倒的差...。悔しさで夜も眠れない。次回こそは、このリベンジを果たしてみせる。いや、リベンジすらおこがましい。あの高みに少しでも近づけるよう、もっと考察を深めなければ。とにかく、とても、とても悔しい...。","isoDate":"2025-04-24T02:35:00.000Z","dateMiliSeconds":1745462100000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ここはMCPの夜明けまえ","link":"https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae","contentSnippet":"本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-\r- 公式URL: https://hack-at-delta.connpass.com/event/350588/\r\r📝 登壇ブログ\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-23T04:00:00.000Z","dateMiliSeconds":1745380800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について","link":"https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite","contentSnippet":"こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。\r\r時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。\r\r---\r\r本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 🎵🧭 というタイトルで登壇しました！\r\r\r🔍 イベント詳細:\r- イベント名: CloudNative Days Summer 2025 プレイベント\r- 公式URL:https://cloudnativedays.connpass.com/event/351211/ \r- イベントのURL: https://event.cloudnativedays.jp/cnds2025\r\r📝 登壇ブログ\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Neovimも進化するMCPHubとAvante.nvimの連携ガイド","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837","contentSnippet":"はじめにModel Context Protocol（MCP）は、LLM（大規模言語モデル）と外部システムの間の通信を可能にする標準化されたプロトコルです。これにより、LLMに追加のツールやリソースを提供して、その能力を拡張できます。MCPは、開発者がLLMに外部機能へのアクセスを提供するための統一された方法を提供します。簡単に言えば、MCPはLLMが「外の世界」と対話するための共通言語です。これにより、ChatGPTやClaudeなどのAIが、ファイルやウェブサイトを読み書きしたり、コマンドを実行したり、LSP（Language Server Protocol）の診断情報にアクセスしたりできるようになります。syu-m-5151.hatenablog.comMCPHub.nvimMCPHub.nvimは、MCPサーバーをNeovimワークフローに統合するための強力なプラグインです。このプラグインは、集中管理された設定ファイルを通じてMCPサーバーを構成・管理し、ツールやリソースを閲覧・インストール・テストするための直感的なUIを提供します。LLM統合のために設計されており、プログラムによるAPI呼び出しとインタラクティブなテスト機能の両方を提供します。https://github.com/ravitemer/mcphub.nvim より引用github.com主な機能シンプルなコマンドインターフェース: 単一の:MCPHubコマンドですべての機能にアクセス統合ハブビュー: サーバーとツールを動的に有効/無効にし、トークン使用量を最適化ネイティブMCPサーバーサポート: Lua言語ベースのMCPサーバーを直接Neovim内に作成内蔵MCPサーバー:ファイル操作（読み取り、書き込み、検索、置換）コマンド実行とターミナル統合LSP統合と診断バッファとエディタ状態へのアクセスチャットプラグイン統合:Avante.nvimCodeCompanion.nvimマーケットプレイス統合: 利用可能なMCPサーバーの閲覧とインストールインタラクティブなテスト: リアルタイムのツールテストインターフェースgithub.comLLMとMCPの連携従来のLLMチャットは「単なる会話」に過ぎませんでした。ユーザーが質問し、AIが応答する。もしくはユーザーが質問し、AIがその範囲内で変更する。しかし、MCPをNeovimに統合すると、LLMは単なる会話の相手ではなく、あなたのNeovim開発環境で「手」を持つ実践的なアシスタントに変わります。Neovimでは、MCPを通じてLLMに以下のような強力な機能へのアクセスを提供できます。ファイルの読み取りと書き込み - バッファ内容の分析や自動生成コードの挿入ファイルの検索と置換 - プロジェクト全体でのリファクタリングや一括修正シェルコマンドの実行 - git操作やビルドコマンドの自動実行LSP診断情報の取得 - エラーや警告の分析と自動修正提案バッファ間の移動とコンテンツの取得 - 複数ファイルにまたがる変更の一括適用インタラクティブなプロンプトの提供 - コードレビューや改善提案のための対話Neovimのキーマッピングやコマンドの生成と実行 - カスタム操作の自動化MCPはLLMをNeovimエコシステムの一部として統合し、あなたのコーディング体験を根本から変革します。Avante.nvimとの連携：実践的なAIペアプログラミングMCPHub.nvimは、NeovimのためのAIチャットプラグインとシームレスに連携できます。現在、Avante.nvimとCodeCompanion.nvimの両方に対応しており、どちらでも同じMCPツールを活用できます。私がAvante.nvimを使っているので紹介するのはこちらです。syu-m-5151.hatenablog.comAvante.nvimはMCPHubと統合することで、LLMに強力なツールへのアクセスを提供できます。MCPHubのツールを有効にするには、Avanteの設定に以下のように追加しますrequire(\"avante\").setup({    -- その他の設定    system_prompt = function()        local hub = require(\"mcphub\").get_hub_instance()        return hub:get_active_servers_prompt()    end,    custom_tools = function()        return {            require(\"mcphub.extensions.avante\").mcp_tool(),        }    end,})github.comMCPが解決する問題従来、各LLMチャットプラグインは独自のツールシステムを実装していました。例えば、AvanteとCodeCompanionでは、同一の機能を実現するために異なるコードを書く必要があり、プラグイン間での互換性がありませんでした。また、Neovimの機能にアクセスするための標準的な方法が存在せず、各プラグイン開発者が独自の実装を行う必要がありました。MCPHubはNeovim環境において以下のような問題を解決します。一度実装すれば、どこでも動作：ツールを一度実装すれば、Avante.nvimとCodeCompanion.nvimなど、すべてのMCP対応チャットプラグインで共通して利用可能標準化されたAPI：res:text():image():send()のような直感的なチェーンAPIにより、Neovimの機能に一貫した方法でアクセス統一された指示：ツール、リソース、テンプレートを一箇所で管理し、LLMに渡す指示を簡素化完全なリソースシステム：URI型のリソースアクセスにより、Neovimバッファ、ファイルシステム、LSP情報などに統一的にアクセス標準型のレスポンス：テキスト、画像、バイナリデータなどの標準対応により、多様な出力形式をサポート集中型ライフサイクル管理：サーバーの状態を一元管理し、パフォーマンスを最適化MCPHubの実践的なNeovimワークフローNeovimでのハンズオン開発において、MCPHubを活用したワークフローは以下のようになります：:MCPHub コマンドでMCPハブUIを開き、利用可能なツールとサーバーを確認必要なMCPサーバー（ファイル操作、LSP、ターミナルなど）を有効化有効化したサーバーのツールやリソースをMCPハブUIで確認し、機能を把握\u003cleader\u003eaeなどのキーマップでAvanteのインターフェースを開き、タスクをLLMに依頼LLMはMCPツールを使って様々なタスクを実行し、結果をバッファに直接反映実践例: Neovimでのコードリファクタリングたとえば、「このプロジェクトでアロー関数を通常の関数に変換したい」とLLMに伝えると、NeovimとMCPを活用したLLMは以下のようなステップを自動で実行します。search_filesツールでNeovimのtelescope/ripgrepを使いJavaScriptファイルを検索read_fileツールでNeovimバッファを通じて各ファイルの内容を読み取りコードを解析してアロー関数を特定replace_in_fileツールでNeovimのテキスト置換機能を使い変換を実行変更をプレビューしたり、自動で適用したりする選択肢を提示必要に応じてLSP診断を実行し、変換後のコードが正しく動作することを確認これにより、通常であれば複数のNeovimコマンドと手動作業が必要なリファクタリングを、単一のLLMとの対話で完了できます。今後の展望MCPは、LLMをテキスト生成の枠を超えて、Neovimの強力な開発環境と統合された実用的な開発アシスタントとして活用する道を開きます。MCPHub.nvimのようなプラグインにより、Neovimユーザーはこの可能性を最大限に活用できます。今後の発展としては以下が期待できます：Neovim専用のMCPツール: Neovimの特性を活かした専門的なMCPツールの開発言語固有のアシスタント: 各プログラミング言語に特化したLSPと連携したコーディングアシスタントプロジェクト管理の自動化: git操作やプロジェクト構造の分析・最適化の自動化カスタムワークフロー: 個人の開発スタイルに合わせたAIアシスタントの調整MCPは単なる技術的な進歩ではなく、NeovimユーザーとAIの協業の形を根本的に変える可能性を秘めています。これにより、コーディングの効率性と創造性が飛躍的に向上するでしょう。","isoDate":"2025-04-21T01:18:37.000Z","dateMiliSeconds":1745198317000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIによる障害対応訓練RPG v0.1.0を遊ぶには？","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821","contentSnippet":"はじめにシステム障害は、どんなに優れた組織でも避けられない現実です。特に複雑なシステムが相互に連携する現代のデジタル環境において、障害対応の経験と知識は組織の安定性と競争力を直接左右します。しかし現状では、障害対応の実践的経験は少数のベテランエンジニアに集中しており、その対応手法や判断基準は暗黙知として個人の中だけに蓄積される傾向があります。この貴重な知識を組織全体の財産とするためには、ベテランの暗黙知を形式知へと変換し、共有可能な知識体系として確立していくことが不可欠です。これにより、新人エンジニアも体系的に経験を積む機会が生まれ、組織内の知識格差を解消することができます。結果として、障害対応の品質の均一化が実現し、組織全体のレジリエンスが向上するのです。syu-m-5151.hatenablog.com私は2年前に「ChatGPTで障害対応 RPG」に関するブログを公開し、それ以来、様々な組織や企業の状況に合わせてこのアプローチを活用してきました。このシミュレーション型の学習方法は、実際の障害を待つことなく、エンジニアがリスクフリーな環境で対応スキルを磨くための効果的な手段として機能しています。github.comcloud.google.comGoogleのSREチームが実践している「Wheel of Misfortune」は、この課題に対する効果的な解決策の一つとして注目されています。実際の本番システムに影響を与えることなく、ロールプレイング形式で障害対応を模擬体験できるこの手法を、最新の生成AIテクノロジーと融合させることで、より柔軟かつスケーラブルな訓練プログラムの実現が可能になりました。v0.0.1 と v0.1.0 の主な違いv0.0.1では、主にシンプルなRPG形式の障害対応ゲームとして設計されており、ゲームマスターとプレイヤーの役割が明確に分かれています。システム障害のシナリオは自動的に設定され、2D6ダイスロールによる判定を用いた比較的ゲーム性の高い内容となっています。自動生成される障害シナリオは汎用的であり、実際の組織構造やドキュメントとの連携は限定的です。一方、v0.1.0では、実際の障害対応ドキュメントを分析し活用するプロフェッショナル向けの訓練プログラムへと進化しています。ファシリテーターとしての役割が追加され、実際の組織のドキュメント（README、フロー図、マニュアルなど）を分析した上でリアルな障害シナリオを作成します。また、ドキュメントの不備や矛盾点を明示的に指摘し、組織の障害対応プロセスの改善に直接貢献する機能が強化されています。セッションの構成も明確に定義され、振り返りや改善点の整理といった学習サイクルを重視した設計になっています。github.comこのブログの内容が参考になりましたら、読者登録やnwiizoのフォローをしていただけると大変励みになります。それでは、本題に入っていきましょう。あなたは「Wheel of Misfortune」方式の障害対応訓練を進行するファシリテーター兼ゲームマスターです。企業のシステム運用チーム向けに、実践的な障害対応訓練セッションを提供します。【前提条件】* このセッションでは、**実際の障害対応ドキュメント、README、アラートルール、インシデント対応フロー図**などの実ドキュメントを分析します* 分析したドキュメントに基づいて、**より現実的な障害シナリオと対応フロー**を再現します* **ドキュメントの不備、矛盾点、改善点**を発見し、明示的に指摘します【ファシリテーターとしての役割】* セッション全体の構成を管理し、参加者の学習を促進します* 訓練の目的と流れを明確に説明します* 振り返りを主導し、学びを言語化・共有する場を作ります* 訓練中に気づいたドキュメント改善点や対応手順の課題を記録します* 参加者全員が発言できる環境を整え、新人からベテランまで学びを得られるようにします【ゲームマスターとしての役割】* 提供されたドキュメントに基づくリアルなシステム障害シナリオを提供します* 参加者の行動に応じて状況を変化させます* 実際の組織構造に基づき、システム担当者やステークホルダーなどのNPCを演じます* 各NPCは組織内の役割や立場に応じた反応をします（経営層、開発者、顧客サポート等）* 参加者の判断や行動に対して適切なフィードバックを行います* 必要に応じて2D6ダイスロールによる判定を実施します（成功率6以上）* 実際のツールや監視画面の出力を擬似的に再現します【セッションの流れ】1. ドキュメント分析（5-15分）：提供された障害対応ドキュメント、README、フロー図を分析2. システム設定の合意（5-10分）：分析結果に基づくシステム設定の確認3. 組織体制の確認（5分）：実際の担当者と役割の確認4. シナリオの導入（3-5分）：ドキュメントから抽出した現実的なシナリオ設定5. 障害対応演習（30-45分）：実際の対応フローに沿った演習6. 振り返り（15-20分）：対応プロセスと発見された課題の振り返り7. ドキュメント・手順改善点の整理（10-15分）：訓練で発見された不備や改善点の整理【訓練の目的】* **インシデント対応の経験を積む*** **対応プロセスとドキュメントの問題点を発見する*** **チーム内でのナレッジ共有を促進する*** インシデント発生時の対応スキルを向上させる* **新人エンジニアでも適切に対応できる仕組みを検証する*** 既存のドキュメントや手順の不備を特定し、改善する【ドキュメント分析】以下のドキュメントを共有してください（可能な範囲で）：* システム構成図またはREADME* 障害対応マニュアルまたはRunbook* インシデント対応フロー* エスカレーションルール* アラートルールまたは監視設定* オンコール体制や担当者リスト共有いただいたドキュメントを分析し、以下の観点で評価します：* 完全性：必要な情報が全て含まれているか* 明確性：手順が明確で誤解の余地がないか* 最新性：古い情報や廃止されたコンポーネントへの言及がないか* 整合性：複数のドキュメント間で矛盾がないか* 実用性：実際の障害発生時に使いやすい形式になっているか【システム設定】ドキュメント分析に基づき、訓練対象となるシステムの基本情報を整理します：* システム名・サービス名* システム構成（サーバー、DB、ネットワーク、クラウドサービス等）* 主要コンポーネントと依存関係* 監視の仕組み（アラート、ダッシュボード等）* 過去に発生した障害パターン【組織体制の設定】実際の組織体制を反映したロールプレイを行うため、以下の情報を整理します：* 1次対応者（オンコール担当者）の役割と権限* エスカレーション先（2次対応者、専門チーム等）* 意思決定者（サービスオーナー、マネージャー等）* 社内外のステークホルダー（営業、カスタマーサポート、経営層等）* コミュニケーションチャネル（Slack、メール、電話等）【障害シナリオ】提供されたドキュメントと実際の環境に基づき、現実的な障害シナリオを設計します：* 過去に実際に発生した障害をベースにするか、起こりうる障害を想定* 複数のコンポーネントに連鎖する障害を想定* ドキュメントの不備や曖昧さが影響する状況を意図的に含める* 障害の重大度（影響範囲、ビジネスインパクト）を明確にする* 障害発生から発見までの時間経過も考慮する* 必要に応じて外部要因（セキュリティ、自然災害等）も考慮する【実際の対応フロー】実際の対応フローに沿ってシナリオを進行します：* アラート検知からの初動対応* 状況確認と影響範囲の特定* エスカレーションの判断と実行* 原因調査と対応策の検討* 復旧作業の実施* ステークホルダーへの報告* 障害クローズと再発防止策の検討【不備の指摘と改善提案】訓練を通じて発見された以下の点を**明示的に指摘し、改善案を提示**します：* **ドキュメントの不備や曖昧な記述*** **手順の抜け漏れや矛盾*** 役割や責任の不明確さ* コミュニケーションの問題点* 技術的な対応の課題* 監視やアラートの改善点【振り返りのポイント】* 対応プロセスの適切さ（初動、エスカレーション等）* 技術的判断の妥当性* コミュニケーションの適切さ* ドキュメントの不備や改善点* より良い対応のためのアイデア* 次回の訓練で焦点を当てるべき領域まずは、分析対象となるドキュメント（障害対応マニュアル、README、インシデント対応フロー等）を共有してください。ドキュメントの量が多い場合は、最も重要な部分や、特に検証したい部分を優先的に共有いただければと思います。実施ガイド事前準備必要ドキュメントの整理障害対応マニュアルやRunbookシステム構成図やREADMEオンコール体制やエスカレーションフロー監視システムやアラートルールの説明参加者の選定訓練対象者（新人エンジニアが理想的）オブザーバー（経験者やマネージャー）ファシリテーター（実施進行役）シナリオの検討過去に実際に発生した障害事例懸念されるが未発生の障害パターンドキュメントの不備が顕著な領域セッション実施プロンプトの入力上記プロンプトを生成AI（Claude/ChatGPT等）に入力分析対象ドキュメントを提供セッション開始AIによるドキュメント分析結果の確認訓練の目的と進め方の説明参加者の役割確認障害対応演習AIが提示する初期状況（アラート等）に対応実際の対応フローに沿ったアクション実施必要に応じたエスカレーションやコミュニケーション振り返りAIから指摘されたドキュメントの不備確認対応プロセスの課題抽出改善アクションの設定フォローアップ改善タスクの整理ドキュメント更新タスクプロセス改善タスク技術的対策タスク次回訓練の計画焦点を当てる領域の選定参加者の拡大検討定期開催スケジュールの設定RPG スタート架空のシステムを作る今回の訓練では、現実のシステム構成を反映した架空のシステムを利用します。生成AIを活用することで、README.mdやシステム構成図などの基本ドキュメントを自動生成することができます。この例では「FuturePay」という架空の決済システムを想定しています。生成AIは組織の実際のシステム特性（マイクロサービスアーキテクチャ、使用している技術スタック、インフラ構成など）を考慮して、より現実に近い環境を短時間で構築できます。これにより、訓練の没入感と実践的価値が大幅に向上します。障害対応に必要なドキュメント類の生成システム設定に加えて、障害対応に必要な以下のドキュメントも自動生成します：Runbook：各コンポーネントの操作手順や復旧手順インシデント対応フロー：検知から解決までのプロセス図アラートルール：監視項目と閾値の定義エスカレーションルール：重大度別の連絡先と対応フローこれらのドキュメントには、意図的に不完全な部分や曖昧な記述を含めることで、実際の業務環境で直面する課題を再現しています。訓練参加者はこれらのドキュメントを頼りに障害対応を進めることで、ドキュメント品質の重要性を体感できます。シナリオの開始ファシリテーターからの「障害発生のアラートが上がりました」という通知でRPGが始まります。参加者は実際の障害対応と同様に、以下のステップで対応を進めます：状況確認：どのようなアラートが発生したのかを確認影響範囲の特定：どのサービスやユーザーに影響があるのかを判断原因調査：ログ確認やシステム状態の分析を実施対応策の実行：障害復旧のための具体的なアクションを決定・実行ステークホルダーへの報告：適切なタイミングで適切な相手に状況を伝達生成AIはリアルタイムに状況を変化させ、参加者の判断や行動に応じたフィードバックを提供します。これにより、臨場感のある訓練体験が実現します。期待される効果ドキュメント品質の向上不備や曖昧さの発見と修正実際の利用シーンを想定した改善チーム全体のスキル向上新人エンジニアの障害対応経験蓄積知識の属人化防止対応フローの最適化ボトルネックや非効率な手順の発見エスカレーションルールの明確化障害対応時間の短縮初動対応の迅速化適切な判断と対応の促進組織レジリエンスの向上どのメンバーでも対応可能な体制構築予期せぬ状況への対応力強化おわりに障害対応はシステム運用において最も重要かつ難しいスキルの一つです。「Wheel of Misfortune」と生成AIを組み合わせたアプローチは、これまで難しかった実践的な訓練を、環境構築のコストを抑えながら定期的に実施できる画期的な方法です。この訓練方法の最大の強みは、単なる障害対応のシミュレーションに留まらず、実際のドキュメントや組織体制の問題点を浮き彫りにし、具体的な改善につなげられる点にあります。また、チーム全体で知識を共有し、特定のエンジニアに依存しない強固な運用体制を構築することができます。システム障害をゼロにすることは不可能でも、組織の対応力を高めることは可能です。この方法を取り入れ、定期的な訓練を行うことで、障害発生時の対応時間短縮とサービス品質の向上を実現してください。障害対応は「いざという時のための備え」ではなく、継続的に鍛えるべき組織の中核能力なのです。今後も実践的なシステム運用のヒントを発信していきますので、ぜひご期待ください。また、障害対応について知識をしっかりと身に着けたければ「【改訂新版】システム障害対応の教科書」を読んでほしいです。【改訂新版】システム障害対応の教科書作者:木村 誠明技術評論社AmazonIncident Response MeetupやPagerDuty Japan、Waroom Meetupなどの国内のイベントもたくさんあるので気になる方はぜひ、参加してみてください。incident-response.connpass.compagerduty.connpass.comtopotal.connpass.com","isoDate":"2025-04-17T03:08:21.000Z","dateMiliSeconds":1744859301000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"MACのDocker 環境はcolima にしました","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211","contentSnippet":"はじめにコンテナ技術は現代のソフトウェア開発において不可欠なツールとなっています。特にMacユーザーにとって、効率的なコンテナ環境の構築は開発ワークフローを大きく改善します。そんな中、ローカルの環境をColimaにしたのでブログにします。Colimaは、macOSとLinux上でコンテナランタイムを最小限の設定で実行できる軽量なツールです。Docker Desktopの代替として、あるいはLimaの機能を拡張するソリューションとして、多くの開発者に支持されています。github.comこのドキュメントでは、Colimaの基本的な機能と特徴、インストール方法、そして実際の使用例について詳しく説明します。Docker DesktopやLimaからの移行を検討している方や、単にMac上でより効率的なコンテナ環境を探している方に、Colimaという選択肢を紹介します。Colimaとは？Colimaは、macOS（およびLinux）上でコンテナランタイムを最小限のセットアップで実行するためのツールです。Limaという仮想マシンマネージャーを利用して、Docker、Containerd、Kubernetesなどを簡単に使えるようにしてくれます。主な特徴としては：Intel MacとApple Silicon Macの両方をサポートシンプルなCLIインターフェースと分かりやすいデフォルト設定自動ポートフォワーディングボリュームマウント複数インスタンスのサポート複数のコンテナランタイムをサポート（Docker、Containerd、Incusなど）なぜColimaを選んだのか元々はDocker Desktopを使っていましたが、一度Limaに移行し、そこからさらにColimaに移行することにしました。その理由はいくつかあります。シンプルなCLI: GUIではなくCLIベースなので、自動化やスクリプトに組み込みやすいですカスタマイズ性: 仮想マシンのCPU、メモリ、ディスク容量などを簡単に調整できますオープンソース: 完全にオープンソースで、ライセンス問題の心配がありません統合管理: LimaをベースにしながらもDocker、Containerd、Kubernetesなどを一元的に管理できる点が便利です正直、Limaで満足していた。動機としては気になったから移行したというのが本音Limaとの比較Colimaはより高レベルな方法でLimaを活用しています。具体的に言うと、Limaは仮想マシンを提供するツールである一方、Colimaはその上にDockerやContainerdなどのコンテナ環境を自動的に構築・設定します。これは、自分でLimaの設定ファイルを書いてDockerを動かす作業を自動化してくれるようなものです。つまり、Limaの複雑な設定や調整をせずに、すぐにコンテナ環境を使い始めることができます。Colimaの主な利点は：統合された環境: Limaは純粋な仮想マシン管理に特化していますが、ColimaはDocker/Containerd/Kubernetesの設定を自動的に行う点が便利ですシンプルなCLIインターフェース: 必要なコマンドが少なく、直感的に操作できます自動化のしやすさ: 特にbrew servicesとの統合が優れていますインストールと基本的な使い方Homebrewを使って簡単にインストールできます。brew install colima基本的な使い方はとてもシンプル：# 起動colima start# 状態確認colima status# 停止colima stop私の環境では次のような出力になっています。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock システム起動時に自動起動する設定開発環境として日常的に使うので、Macの起動時にColimaも自動的に起動するように設定しました。Homebrewのservicesを使うと簡単です。brew services start colimaこれだけで、Macを再起動してもColimaが自動的に起動するようになります。以前のLimaでは、~/Library/LaunchAgents/com.lima.docker.plistのようなLaunchAgentsのplistファイルを作成・編集して自動起動を設定する必要がありました。Colimaではbrew servicesコマンド一つで同様の設定ができるようになり、格段に簡単になりました！カスタマイズの例デフォルトのColimaは2CPU、2GiBメモリ、100GiBストレージで構成されていますが、必要に応じて変更できます。# CPUとメモリを増やす場合colima stopcolima start --cpu 4 --memory 8# 設定ファイルで編集する場合colima start --editLima/Docker Desktopからの移行で注意したことLima や Docker Desktopから移行する際に、いくつか注意点がありました：Dockerコンテキスト: Colimaは独自のDockerコンテキストを作成します。docker context lsとdocker context useコマンドで管理できます。Dockerソケットの場所: デフォルトでは~/.colima/default/docker.sockにあります。一部のツールで直接ソケットパスを指定する必要がある場合は、この場所を指定します。Limaとは異なるパスなので注意が必要です。ボリュームマウント: ホームディレクトリ以外のパスをマウントする場合は、設定ファイルのmountsセクションで明示的に指定する必要があります。既存のコンテナとイメージ: Lima や Docker Desktopで使っていたコンテナやイメージは自動的には引き継がれないので、必要なら再ビルドやpull が必要です。Colimaの動作確認実際にcolima statusコマンドを実行すると、以下のような情報が表示されます。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock また、colima listコマンドでは、実行中のColimaインスタンスの詳細な情報が確認できます。colima listPROFILE    STATUS     ARCH       CPUS    MEMORY    DISK      RUNTIME    ADDRESSdefault    Running    aarch64    2       2GiB      100GiB    dockerこれがColimaのデフォルト設定です。これらの値は必要に応じてcolima startコマンドのオプションや設定ファイルで変更できます。まとめLimaベースのColimaへの移行は思った以上に簡単で、日常の開発作業がより快適になりました。特にCLIベースのシンプルさと設定のわかりやすさが気に入っています。自動起動の設定（brew services start colima）が簡単なこともとても便利で、開発環境のセットアップが格段に楽になりました。Docker DesktopやLimaそのものから移行を検討している方、特にコンテナランタイムを簡単に導入したいMacユーザーの方には、Colimaを検討する価値があります。普通にローカルのCPUとメモリを喰う生成AIツール全盛時代に最適な環境がなにか俺にも分からん。","isoDate":"2025-04-16T11:12:11.000Z","dateMiliSeconds":1744801931000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"防御力の高い技術ブログを書こう","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/15/101247","contentSnippet":"はじめにある日のこと、私はもしくはあなたは思いつきました。そう、自分の考えを発信してみようと。それはまるで、小さな紙飛行機を窓から放り投げるような、どこまで飛ぶかわからない冒険でした。そんなわけで画面に向かい、キーボードを叩き始めたのですが、すぐに奇妙な不安が襲ってきたのです。ほら、誰かがそっと後ろから覗き込んで「それ、間違ってるよ」とか「それって昔の話でしょ」なんて言ってくるかもしれない。もっと恐ろしいのは「もっといいやり方があるのに」という呪文めいた言葉です。そんな呪文を浴びせられたら、私はきっと透明人間になりたくなるに違いありません。でも不思議なもので、そういう批判の声が聞こえてくるのは、実は自分の頭の中だったりするんですよね。まだ何も書いていないのに、もうすでに架空の批判者と対話している。ある意味、私たちは常に誰かと対話している生き物なのかもしれません。そこで考えたのです。批判に怯えて黙っているより、その批判をも包み込んでしまうような、不思議な力を持つ文章があるのではないかと。批判の矢を受け止めて、それを武器に変えてしまうような魔法のような文章。本日はそんな「防御力の高い」文章の作り方について、私なりの道案内をしてみたいと思います。ただし、これは魔法の呪文集ではなく、むしろ冒険の途中で見つけた不思議な地図のようなものです。この地図を頼りに、あなた自身の冒険を始めてみませんか？また、防御力というのはあくまである視点からのという話です。以前書いたブログの書き方はこちらです。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめになぜ防御力が必要なのか解釈の枠組みの違い認知バイアスの影響オンラインの批判文化防御力を高める表現と内容の工夫主観的な表現と限定的な主張コンテキストと限界の明示実体験と具体例の活用肯定的なものを中心に語る根拠と出典の明示防御力の高い構成テクニック批判を先取りする構成異なる立場への配慮見出しと結論の工夫批判への対応と心構え「事実」と「解釈」の違いを理解する建設的なフィードバックを活かす過剰な期待を持たない明らかな失礼への対応執筆前の準備と実践自分のバイアスを認識する執筆前の自己対話信頼できる人のレビュー学び続ける姿勢を示すおわりになぜ防御力が必要なのか解釈の枠組みの違いそれぞれの人は独自の知識体系や思考の枠組みを持っているため、あなたの書いた内容が意図とは異なる形で解釈される可能性があります。例えば、「このツールは便利だ」というシンプルな記述も、読者の経験によって全く異なる意味に解釈されます。熟練エンジニアなら「生産性を高める強力なツール」と捉え、初心者なら「入門に適した簡易ツール」と理解するかもしれません。ミドルウェア開発者は「APIが整理されている」と考え、アプリケーション開発者は「ドキュメントが充実している」と解釈するでしょう。同じ言葉でも、読者の立場や背景知識によって解釈の幅が大きく変わることを認識しておくことが、防御力の第一歩です。認知バイアスの影響私たち全員が持つ認知バイアスにより、偏ったものの見方で判断を下していると、異なる立場からの情報や論理的な指摘があっても、判断が覆らない場合があります。確証バイアス（自分の信念を補強する情報を重視し、反する情報を軽視する傾向）は特に影響力が強く、技術コミュニティでも顕著に見られます。特定のプログラミングパラダイムや技術スタックに強いアイデンティティを持つエンジニアは、その技術の欠点を指摘されると、内容の正確さに関わらず反発することがあります。権威バイアス（有名人や権威ある組織の意見を過度に信頼する傾向）も考慮すべき要素です。あなたが無名のエンジニアであれば、大企業の有名エンジニアと異なる見解を述べる際には、特に丁寧な根拠の提示が求められます。オンラインの批判文化技術コミュニティでは批判的なフィードバックが珍しくなく、匿名性からより辛辣な表現になりがちです。オンラインディスカッションでは「バイクシェッド効果」（些細な点ほど多くの意見が集まる現象）も働きます。あなたが深く考察した核心的な技術論点よりも、使用したコード例の些細なスタイルの問題や、ちょっとした言い回しに批判が集中することがあります。完璧な記事を目指すあまり執筆をためらうより、防御力を高める工夫をしながら発信する方が建設的です。防御力を高める表現と内容の工夫主観的な表現と限定的な主張「これが正しい方法だ」という断言ではなく、「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。防御力の低い表現: 「XXフレームワークはYYフレームワークより優れている」防御力の高い表現: 「私のプロジェクトでは、このユースケースでXXフレームワークが適していました」この表現の違いは微妙ですが重要です。断言的な表現は「自分が正しく、異なる選択をしている人は間違っている」という含意を持ち、読者の反発を招きます。一方、経験として共有する表現は「私はこう感じた、あなたはどう思う？」という対話の余地を残します。特に効果的なのは「特定の状況下では」という条件付けです。「XXフレームワークはリアルタイム更新の多いUIには特に適しています」のように、適用範囲を明確にすることで、批判の余地を減らせます。ただし、自分の専門分野における確立された事実（「配列の線形探索はO(n)の時間複雑性を持つ」など）については、無理に主観的表現をする必要はありません。コンテキストと限界の明示使用環境、バージョン、チーム規模などの背景と、アプローチの限界を明確にすることで、批判を先回りできます。防御力の低い表現: 「この方法でデータベース処理が30%速くなる」防御力の高い表現: 「XXデータベース14.5、16GBメモリ環境、約500万レコードのデータセットで、私のケースでは処理時間が約30%改善。ただし、より大規模なデータでは異なる結果になる可能性があります」コンテキストには、技術的な環境だけでなく、組織的な制約も含めると良いでしょう。「チーム全員がXX言語に熟練していたため、学習コストを考慮してXXを選択した」といった説明は、技術選定の合理性を示す重要な要素です。限界を示す際は、具体的な条件を挙げるとより信頼性が増します。「1秒あたり100リクエスト以上の負荷では応答時間が悪化する」「100GB以上のデータセットでは別のアプローチが必要」など、明確な境界条件を示すことで、「これが全てではない」という謙虚さと「ここまではちゃんと考えている」という誠実さを同時に伝えられます。実体験と具体例の活用抽象的な主張より、実際に経験した具体的なケースを示すことで、反論されにくくなります。ただし、「事実」も一つの解釈に過ぎないことを忘れないでください。防御力の低い表現: 「マイクロサービスアーキテクチャは複雑すぎる」防御力の高い表現: 「私たちの10人チームでECサイトをマイクロサービス化した際、サービス間の整合性維持に予想以上の工数がかかりました。具体的には、注文処理と在庫管理の同期において、トランザクション境界の設計に苦労し、最終的に以下のアプローチをとりました...」実体験を語る際のポイントは「検証可能な詳細」です。「パフォーマンスが向上した」という漠然とした記述より、「レスポンスタイムが平均342msから118msに短縮された」という具体的な数値の方が説得力があります。失敗談も非常に価値があります。「最初にAというアプローチを試みたが、Bという問題に直面したため、最終的にCという解決策にたどり着いた」という試行錯誤のプロセスは、他のエンジニアが同じ失敗を避けるのに役立ちます。失敗を率直に共有することで、「完璧を装おうとしていない」という誠実さも伝わります。肯定的なものを中心に語る批判よりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。防御力の低い表現: 「YY言語は設計に一貫性がなく不適切だ」防御力の高い表現: 「XX言語の型安全性は、特に大規模プロジェクトで次のような恩恵をもたらしました...」他の技術やアプローチを批判する代わりに、自分の選んだ技術の利点を具体的に説明することで、不必要な論争を避けられます。「YYは悪い」という否定的なメッセージより、「XXの良さはこれだ」という肯定的なメッセージの方が、心理的な抵抗を生みません。特に効果的なのは、自分が以前使っていた技術から新しい技術に移行した体験を共有することです。「以前はYYを使っていましたが、XXに移行してからこのような点が改善されました」という形式なら、YYの利用者も反感を抱きにくいでしょう。ただし、セキュリティやパフォーマンスに重大な問題がある場合など、警告が必要な場合は例外です。そのような場合でも、「避けるべき」という否定的表現より、「代替案を検討すべき状況」という建設的な表現を心がけましょう。根拠と出典の明示主張の根拠や出典を明確に示すことで、記事の信頼性と防御力が高まります。特に数値的な主張、ベストプラクティスの推奨、技術の問題点指摘、将来予測には出典が重要です。防御力の低い表現: 「このアプローチは処理速度が20倍向上する」防御力の高い表現: 「XX社の2024年1月の技術レポート（参考リンク）によれば、このアプローチでは平均20倍の処理速度向上が報告されています」出典は、公式ドキュメント、ピアレビューされた論文、広く信頼されているブログやカンファレンス発表などが理想的です。引用する際は、公開日も含めると時間的コンテキストが明確になります。出典がない場合は、自分の検証方法と結果を詳細に記述し、再現可能性を担保しましょう。「私は以下の環境でAとBの方法を各100回実行し、平均実行時間を比較しました。使用したベンチマークコードはこちらです...」という形で、検証プロセスを透明にすることで、読者自身が結果を確認できるようにします。特に重要なのは、相関と因果を混同しないことです。「XXを導入した後にパフォーマンスが向上した」と書くより、「XXを導入したことで、具体的にこのような理由からパフォーマンスが向上した」と因果関係を明確にする方が誠実です。防御力の高い構成テクニック批判を先取りする構成防御力の高い記事は、想定される批判や誤解を先取りして対応します：導入部で限定条件を明示する: 記事の冒頭で適用範囲を明確にしましょう。「このアプローチはスタートアップの小規模チームに適しています」「エンタープライズ環境での大規模データ処理を想定しています」など、読者が自分の状況に当てはまるかどうかを判断できるようにします。「よくある誤解」セクションを設ける: 技術的な選択や手法には、しばしば同じ誤解が繰り返されます。「XXは遅い」「YYはスケーリングできない」といった一般的な誤解に対して、データや実例に基づいた反論を準備しておくことで、コメント欄での同じ議論の繰り返しを避けられます。複数の代替案を併記する: 自分の推奨する方法だけでなく、代替アプローチも説明し、それぞれの長所と短所、適した状況を比較すると、公平で包括的な印象を与えます。「私たちはAを選択しましたが、以下のような状況ではBやCも有効な選択肢になります」という形式は、読者の多様なニーズに応える懐の深さを示します。構成例：問題の定義と重要性解決策を選ぶ際の考慮事項検討した代替案とそれぞれの長所・短所最終的に選んだアプローチとその理由実装の詳細と得られた結果よくある誤解と回答適用限界と将来の発展可能性異なる立場への配慮読者は様々な立場や専門性を持っています。フロントエンド開発者、バックエンド開発者、マネージャーなど、異なる役割からの見方も示すことで、幅広い共感を得られます。技術的選択を説明する際は、技術的メリットだけでなく、ビジネス的な影響や開発者体験など、複数の視点から評価することが重要です。例えば：開発者視点：「このアプローチは学習曲線がやや急ですが、一度習得すると生産性が向上します」運用視点：「デプロイの複雑さは増しますが、個別コンポーネントの更新が容易になります」ビジネス視点：「開発初期のコストは高くなりますが、長期的なメンテナンスコストが削減されます」特に効果的なのは、自分と異なる立場の人の懸念を認識し、それに対応することです。「フロントエンド開発者にとっては、このAPIの複雑さは課題かもしれませんが、以下のようなアプローチでシンプルなインターフェースを提供できます...」というように、異なる立場の読者が感じるかもしれない反論を先回りして対応すると、包括的な印象を与えられます。見出しと結論の工夫見出しは記事の骨格であり、読者が最初に目を通す部分です。見出しは主張ではなくトピックを示すようにすることで、中立的で探求的な印象を与えられます。防御力の低い見出し: 「モノリシックアーキテクチャは時代遅れ」防御力の高い見出し: 「モノリシックアーキテクチャとマイクロサービスの比較」見出しの階層構造も重要です。論理的に整理された見出し構造は、内容の理解を助け、「この著者は論理的に考えている」という信頼感を生み出します。また、見出しだけを読んでも記事の全体像が把握できるように設計すると、読者は自分に必要な部分を効率的に見つけられます。結論部分は特に注意が必要です。結論は余地を残すことで防御力が高まります。防御力の低い結論: 「すべての企業はマイクロサービスに移行すべきです」防御力の高い結論: 「私たちのケースではマイクロサービスへの移行が効果的でしたが、システムの複雑さやチーム状況によっては、モノリシックアーキテクチャも有効な選択肢です」結論では、自分の経験から得られた洞察を共有しつつも、読者自身が判断するための視点を提供するアプローチが効果的です。「私の経験からの重要な教訓は〜ですが、あなたの状況によっては以下の点を考慮すると良いでしょう」という形式は、押し付けがましくなく、かつ価値ある指針を提供できます。批判への対応と心構え「事実」と「解釈」の違いを理解する「事実だから否定していい」は最大の勘違いです。事実は解釈の一側面に過ぎず、あなたの視点も相手の視点も等しく重要です。例えば、「このアプローチはメモリ使用量が多い」という事実に対して、「だからこのアプローチは悪い」という解釈と「これは豊富なメモリを活用して処理速度を向上させる戦略だ」という解釈は、同じ事実から生まれる異なる視点です。批判的なコメントの多くは、こうした解釈の違いから生じています。対応のポイントは、事実と解釈を分離することです。「ご指摘の通り、メモリ使用量は増加します。私たちの状況ではメモリよりも処理速度が優先事項でしたが、メモリ制約が厳しい環境では別のアプローチが適しているでしょう」というように、事実を認めつつ、解釈の違いを尊重する姿勢が建設的な対話につながります。建設的なフィードバックを活かすすべての批判が悪意あるわけではありません。改善につながるフィードバックは感謝して受け入れましょう。礼儀を持って書かれた文章には礼儀を持って返しましょう。建設的フィードバックの見分け方：具体的な点を指摘している代替案や改善案を提示している敬意ある言葉遣いで表現されている個人ではなく内容に焦点を当てているこのようなフィードバックには、まず感謝の意を表し、その後で内容に対応するのが効果的です。「貴重なご指摘ありがとうございます。確かにその点は考慮すべきでした」という謝意から始めることで、対話の基盤を築けます。特に重要なのは、フィードバックが記事の改善につながった場合、その貢献を明示的に認めることです。「読者のAさんからのフィードバックを基に、この部分を更新しました」といった形で貢献を認めると、コミュニティ全体の協力的な雰囲気を促進できます。過剰な期待を持たない過剰な期待が否定の感情を生み出します。すべての人があなたの記事を理解し賛同することを期待せず、「100点満点の記事」ではなく「誰かの役に立つ記事」を目指しましょう。技術分野では特に、「正しさ」に対する執着が強い傾向があります。しかし、多くの技術的選択は、絶対的な正誤ではなく、特定の状況やニーズに対する適合性の問題です。自分の提案が「最適解」ではなく「一つの有効なアプローチ」であることを心に留めておくと、批判に対して感情的になりにくくなります。実際の数字として考えると：あなたの記事が1000人に読まれた場合、990人が何も言わず、9人が「参考になった」と言い、1人が批判することは珍しくありません。その1人の批判だけに注目すると、不当に否定的な印象を持ってしまいます。「批判は注目されやすいが、大多数の満足した読者は声を上げない」という非対称性を意識しましょう。明らかな失礼への対応馬鹿にされたら戦いしか残されていない場合もありますが、感情的にならず以下のような対応が効果的です：丁寧かつ簡潔に応答する: 「お気持ちは理解しましたが、もう少し建設的な形でご意見いただけると嬉しいです」というように、感情的に反応せず、対話の質を上げることを促します。コミュニティルール違反は適切に報告する: 明らかな罵倒や人格攻撃などは、多くのプラットフォームのコミュニティガイドラインに違反します。そのような場合は、反応せずに適切な報告手段を利用しましょう。非公開の場で対話を試みる: 「詳しいご意見をお聞かせいただけると助かります。DMでご連絡いただけませんか？」と提案することで、公開の場での感情的な応酬を避けられます。必要に応じてブロック機能を使用する: 継続的な嫌がらせや明らかな荒らし行為に対しては、自己防衛のためにブロック機能を利用することも正当な選択です。重要なのは、少数の攻撃的コメントに大量のエネルギーを消費しないことです。批判者の中には、あなたを感情的にさせること自体が目的の人もいます。そのような人に貴重な時間と精神的エネルギーを奪われることは、あなたの読者にとっても損失です。「防御」とは時に「攻撃に対して反撃する」ことではなく、「攻撃の影響を最小限に抑える」ことを意味します。最も強力な防御は、時に無反応であることを覚えておきましょう。執筆前の準備と実践自分のバイアスを認識する執筆前に「私はこの技術についてどんな思い込みを持っているか」と自問し、自分のバイアスを認識しましょう。技術的バイアスの例：- 特定の言語やフレームワークへの愛着- 特定のアーキテクチャパターンへの傾倒- 最新技術への過度な期待- レガシーシステムへの不当な否定役割バイアスの例：- バックエンド開発者としてのパフォーマンス重視- フロントエンド開発者としてのUX重視- インフラエンジニアとしての安定性重視- マネージャーとしてのプロジェクト進行スピード重視自分のバイアスを認識することは、それを否定することではなく、むしろそれを適切に開示し、他の視点も尊重する姿勢を示すことです。「私はパフォーマンス重視のバックエンドエンジニアとして見ていますが、フロントエンド開発者にとっては別の優先事項があるでしょう」というように、自分の視点を自覚的に提示することで、読者も自分の立場との違いを理解しやすくなります。執筆前の自己対話以下の質問に自分で答えることで、記事の焦点と防御力が高まります：この記事で伝えたい最も重要なことは何か？中心となるメッセージを明確にし、それを支える論点を整理します。一つの記事で伝えようとする内容が多すぎると、焦点がぼやけて批判を受けやすくなります。想定読者は誰で、どんな前提知識を持っているか？読者層を具体的にイメージし、その知識レベルに合わせた説明の詳しさを調整します。初心者向け記事なのに前提知識を要求しすぎたり、逆に熟練者向けなのに基本的すぎる説明をすると、「的外れ」という批判を受けやすくなります。どんな反論が予想され、それにどう対応するか？想定される主な反論をリストアップし、それぞれに対する回答を準備します。特に重要な反論は、記事本文で先回りして対応することも検討します。この内容の確信度はどの程度か？自分の主張にどの程度の確信を持っているかを評価し、その確信度を文章の調子に反映させます。高い確信がある部分は断言的に、確信が低い部分は探索的な表現にすることで、「間違いではないが、確信も持てない」という微妙な領域も適切に表現できます。信頼できる人のレビュー可能であれば、公開前に信頼できる人に読んでもらいましょう。彼らが感じた違和感は、他の読者も同様に感じる可能性があります。効果的なレビュー依頼のコツ：- 具体的な質問を準備する（「全体的にどう？」ではなく「この部分の説明は明確か？」など）- 批判的なフィードバックを歓迎する姿勢を示す- 技術的に詳しい人だけでなく、想定読者に近い知識レベルの人にも見てもらう- 十分な時間的余裕を持ってレビューを依頼するレビューで指摘された問題は、公開後に読者から指摘される可能性が高い部分です。この段階で修正しておくことで、公開後の批判を大幅に減らせます。学び続ける姿勢を示す「今後さらに調査したい」「まだ理解しきれていない部分がある」と認めることは、弱さではなく誠実さです。学び続ける姿勢を示すことで、「絶対に正しい」という固い主張を避けられます。専門家であることと、全てを知っていることは別です。特にIT分野では技術の変化が早く、常に学び続ける姿勢が重要です。「この記事執筆時点ではXXが最新でしたが、その後の発展により状況が変わっている可能性があります」というような但し書きは、記事の「賞味期限」を明示する役割も果たします。記事の最後に「今後の展望」や「さらなる調査ポイント」を設けることで、その話題に対する継続的な関心と探求姿勢を示せます。これは読者に「完結した知識」ではなく「進行中の探求」として内容を捉えてもらうのに役立ちます。おわりにそういうわけで、長々と話してきましたが、結局のところ完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しいのです。ある日突然空を飛ぶ象が現れたら、それはそれで困ってしまいますけどね。不思議なことに、私たちは「正しさ」というものにやたらとこだわる生き物なのですが、太陽の光が当たる角度によって、同じ景色でも全く違って見えることがあるように、「事実」というものも見る角度によって姿を変えるものなのです。そう考えると、一つの角度からしか見ていない私たちが、絶対の正しさを主張するというのは、少し滑稽なことかもしれません。それでも、あなたの見た景色、あなたの体験した不思議な出来事は、誰かにとっての道しるべになる可能性があるのです。あなたが迷った場所で、誰かが道に迷わないように。あなたが発見した小さな喜びを、誰かも同じように発見できるように。スイッチ！作者:チップ・ハース,ダン・ハース早川書房Amazon","isoDate":"2025-04-15T01:12:47.000Z","dateMiliSeconds":1744679567000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"エンジニアブログは技術的であるべきで登壇は衒学的であると思う理由","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150","contentSnippet":"はじめにあなたは最後に技術的な記事を読んだとき、何を求めていただろうか？この二つの問いに対する答えは、おそらく大きく異なるのではないだろうか。記事を読むとき、私は再現可能な手順、明確なコード例、具体的な問題解決の道筋を期待する。一方、技術発表を聞くとき、新たな視点やアイデア、そして時に「なるほど、そういう考え方があるのか」という気づきを求めている。技術を共有する手段として、ブログを書き、カンファレンスで登壇する。一見すると同じ「知識共有」という行為に見えるが、この二つは根本的に異なる体験を生み出している。ブログは時間に縛られず、読者が自分のペースで情報を咀嚼できる。一方、登壇は限られた時間の中で、話者の熱量や会場の空気感とともに知識が伝わる。この違いは偶然ではなく、それぞれのメディアには、最適な伝え方があると私は考えている。本稿では、私個人の経験から、エンジニアブログが技術的であるべき理由と、登壇が（ある意味で）衒学的(げんがくてき)である方が効果的である可能性について考察していく。もちろん、これはあくまで一つの視点に過ぎない。技術共有の形は人それぞれであり、正解は一つではないだろう。はじめにエンジニアブログが技術的であるべき理由参照性と再現性の重要性長期的な価値実装の痕跡としての価値集合知の形成と技術の民主化未来の自分への投資思考プロセスの可視化登壇が衒学的であっても良い理由衒学的とは何か「見せかけの深さ」が生む魅力とモチベーション「わかった気にさせる」テクニックと一過性の特性ステータスシンボルとしての衒学記憶に残るメンタルモデルの構築異分野からの知見取り込みの触媒衒学的アプローチの価値と限界まとめエンジニアブログが技術的であるべき理由技術ブログの書き方はこちらでお願いします。syu-m-5151.hatenablog.com参照性と再現性の重要性エンジニアブログの重要な特徴は、読者がいつでも立ち返ることができる参照点となることです。コードの実装例、設定手順、トラブルシューティングの方法など、技術的な内容は「再現できる」ことが最も重要です。技術的であるということは、単に難しい言葉を使うことではなく、読者が同じ結果を得られるように明確で具体的な手順を提供することです。例えば、クラウドでサーバーレスアプリケーションを構築する方法を説明するブログ記事では、使用するサービス、必要な設定、コード例、発生しうる問題とその解決策など、実践的で具体的な情報が求められます。長期的な価値技術的なブログ記事は、時間が経過しても価値を保ちます。もちろんテクノロジーは進化しますが、基本的な概念や問題解決のアプローチは長く参照されることがあります。「どのようにして特定の問題を解決したか」という記録は、数年後の同様の問題に直面したエンジニアにとって貴重な資料となります。例えば、5年前に書かれたコンテナ技術のネットワーク問題のデバッグ方法に関する記事は、現在でも参考になることが多いです。具体的な実装の痕跡は、技術の進化に関わらず価値を持ち続けるのです。実装の痕跡としての価値技術的なブログ記事の価値は、「実際にやってみた痕跡」が残ることです。抽象的な概念や理論ではなく、「この実装でこの問題に直面し、このように解決した」という具体的な記録は、他のエンジニアにとって何物にも代えがたい財産となります。コードスニペット、設定ファイル、エラーメッセージとその対処法などは、まさに泥臭いエンジニアリングの証であり、読者が同じ問題に直面したときの救いの手となります。理論や概念を語るのは簡単ですが、実際の実装の痕跡を残すことこそ、技術ブログの本質的な価値と言えるでしょう。ブログの目的は、実際に同じ道を歩んでいる人の助けになることだからです。集合知の形成と技術の民主化技術的なブログ記事は、個人の経験を超えた「集合知」の形成に貢献します。特に大企業や専門家だけが持っていた知識が、個人のブログを通じて広く共有されることで、技術の民主化が進みます。オープンソースの精神と同様に、技術的なブログは知識のバリアを取り払い、誰もが高度な技術にアクセスできる環境を作り出します。例えば、以前は高価な書籍や専門的なトレーニングでしか学べなかった最先端の技術が、今では個人のブログを通じて無料で学べるようになっています。この知識の解放こそが、技術革新のスピードを加速させる原動力となっています。未来の自分への投資技術ブログを書くことは、未来の自分への最高の投資でもあります。今日困難を乗り越えた方法を記録しておくことは、数ヶ月後、数年後に同じ問題に直面したときの自分自身へのギフトとなります。「あれ、この問題以前にも解決したはずだが、どうやったんだっけ？」という状況は、エンジニアなら誰もが経験するものです。自分のブログは、検索エンジンよりも信頼できる個人的な知識ベースとなり、問題解決の時間を大幅に短縮してくれます。さらに、記録する行為そのものが理解を深め、知識を定着させるため、学習効率も向上します。思考プロセスの可視化優れた技術ブログは、単に「何を」実装したかだけでなく、「なぜそうしたのか」「他にどんな選択肢を検討したのか」という思考プロセスも含みます。この思考の軌跡を残すことで、技術選択の背後にある意思決定の流れが明らかになり、読者はより深い文脈で技術を理解できます。例えば、「Aという技術とBという技術を比較検討した結果、こういう理由でAを選んだ」という記述は、単にAの使い方を説明するよりも価値があります。なぜなら、読者は自分の状況に照らし合わせて意思決定できるようになるからです。思考プロセスの共有は、テクニックだけでなく技術的判断力も養う助けとなります。登壇が衒学的であっても良い理由衒学的とは何かまず「衒学的(げんがくてき)」という言葉について整理しておきましょう。衒学的とは、本質的な理解が伴わないにもかかわらず、学識があるように見せかけ、それを誇示するような様子を指します。つまり、実際には深い知識や経験がなくても、難解な専門用語や引用を多用し、表面的に「賢そうに見せる」テクニックと言えるでしょう。登壇において、この「賢そうに見せる」という要素が、皮肉にも効果的である理由を考えていきます。また、これらは外部登壇を指し社内のプレゼンテーションとは別物ですので御容赦下さい。「見せかけの深さ」が生む魅力とモチベーション登壇の場では、実は技術的な詳細よりも「語り方」や「見せ方」が重要になることが多いのではないかと私は感じています。難解な概念や用語を織り交ぜ、「これは単なる技術ではなく、哲学なのだ」と語ることで、聴衆に「深い知見を得た」という錯覚を与えることができます。例えば、マイクロサービスアーキテクチャの実装という話題でも、具体的な実装方法よりも「組織設計との整合性」「分散システムの哲学的背景」などと語れば、特に具体的な内容がなくても「深い話を聞いた」という満足感を聴衆に与えることができるのです。私個人の考えでは、登壇の一つの重要な目的は、聴衆を「やる気にさせること」であり、具体的な方法論よりも「そういうアプローチもあるのか！」という気づきと挑戦意欲を引き出すことにあります。もちろん、これは私の一意見であり、登壇の目的は発表者それぞれが自由に決めるものです。聴衆が実際に行動を起こす可能性を高めるために解決策の提示が効果的であれば、それも取り入れるべきでしょう。しかし実装の苦労や具体的な失敗談よりも、抽象的な概念を語る方が「賢そう」に見えるという側面があるのも、一つの観察です。登壇スタイルは千差万別で、どれが正解というものではありません。「わかった気にさせる」テクニックと一過性の特性登壇は一過性のメディアです。登壇資料が公開される可能性が高いとはいえ、その場で聞くことと読むことでは体験や雰囲気が大きく異なります。実際には聴衆のほとんどは具体的な技術内容を覚えて帰ることはできないことが多いでしょう。それよりも「あの人は賢そうだった」「深い話だった気がする」という印象だけが残ることが少なくありません。私の経験では、登壇の短い時間内で、全ての文脈やトレードオフを理解してもらい、「なぜこういう判断をしたのか」を完全に伝えることはほぼ不可能です。実際の開発においては数週間から数ヶ月かけて検討したことを、わずか30分や1時間で説明するには限界があります。それぞれの登壇者が、この制約の中でベストだと思う方法を選択していると思います。この特性を踏まえると、実装の詳細や技術的な苦労よりも、引用や専門用語、抽象的な概念を散りばめることで「わかった気にさせる」アプローチが生まれるのも理解できます。私の考えでは、登壇の目的の一つは、人を分かった気にさせてやる気を引き出すことにあります。聴衆は具体的に何を学んだかを説明できなくても、「深い話を聞いた」という満足感と「自分も挑戦してみよう」というモチベーションを得ることができるかもしれません。もちろん、別の目的や価値観を持って登壇に臨む人もいて、それも素晴らしいことだと思います。もちろん、聴衆のやる気を引き出すために具体的な解決策を提示することが効果的であれば、それも積極的に取り入れるべきでしょう。しかし多くの場合、登壇者にとっても、抽象的な概念を語る方が準備も楽で「賢そうに見える」という都合の良さがあります。ステータスシンボルとしての衒学衒学的な登壇は、皮肉にもコミュニティ内での一種のステータスシンボルとなっています。「実装の詳細を語る人」より「大きな概念や哲学を語る人」の方が尊敬されるという暗黙の序列が形成されているのです。技術カンファレンスで最も拍手を浴びるのは、具体的な実装方法を丁寧に説明した発表ではなく、抽象的な概念を難解な用語で彩った発表であることが多いのは、この現象の表れと言えるでしょう。エンジニアであれば誰しも「コードを書く人」より「アーキテクトやコンサルタント」のように見られたいという欲求があり、衒学的な登壇はそれを満たす手段となっています。記憶に残るメンタルモデルの構築例えば、分散システムの説明で「ビザンチン将軍問題」や「CAP定理」といった概念を取り上げることは、単なる実装テクニックの説明よりも聴衆の理解と記憶に残りやすいものです。これらの抽象的なモデルは「問題のやり方」ではなく「問題の捉え方」や「考え方」を提供し、聴衆が様々な状況で応用できる思考ツールとなります。衒学的に思えるこうした抽象化は、表面的な知識の誇示ではなく、実は技術の本質をより効果的に伝えるための有効な手段となり得るのです。特に登壇という限られた時間の中では、具体的な細部よりも「考え方」を伝えることの方が、長期的な価値を生み出す可能性が高いと思います。異分野からの知見取り込みの触媒衒学的なアプローチの興味深い側面として、それが異なる専門分野からの知見を技術の文脈に取り入れる触媒になることがあります。哲学、経済学、心理学、生物学などの概念を技術的課題と結びつけることで、技術コミュニティに新しい視点がもたらされるのです。例えば、システム設計において「アンチフラジャイル」（ナシーム・タレブの概念）や「レジリエンス工学」といった他分野からの概念を導入することで、従来のエンジニアリングの枠を超えた発想が生まれます。一見すると衒学的に見えるこうした「知の越境」は、実は技術の進化において重要な役割を果たしています。異分野の知見を適切に取り入れる衒学的アプローチは、単なる見せかけではなく、技術コミュニティに真の価値をもたらし得るものです。特に複雑な問題に対して、単一分野の知見だけでは不十分な場合、こうした学際的な視点は革新的な解決策を生み出す源泉となり得ます。衒学的アプローチの価値と限界「具体」と「抽象」は物事の捉え方や表現の仕方において相対的な関係性を持ちます。登壇における衒学的アプローチは、多くの場合、抽象度を高めた表現を用いることで成り立っています。抽象的な表現は、個別の事例を超えた共通点や法則性を見出し、多くの状況に適用できる知見を提供できるという利点があります。具体的な表現は直観的でわかりやすく、個々の事例や実装を明確に伝えますが、抽象的な表現は多くの事象に共通する本質や性質を簡潔にまとめることができます。聴衆によって「しっくりくる表現」は異なり、抽象的な概念が腑に落ちる人もいれば、具体例から理解を深める人もいます。衒学的と思われる表現であっても、それが聴衆の一部にとって心に響くものであれば、それは価値あるコミュニケーションと言えるのではないでしょうか。具体と抽象を行き来する思考は、問題解決やコミュニケーション能力を高める上でも重要です。登壇者が衒学的に見える抽象的表現を用いつつも、適切なタイミングで具体例に降りてくる「往復」ができれば、より効果的な知識共有が可能になると思います。以上のような考察は、あくまで個人的な観察と意見です。技術コミュニティには様々な価値観があり、登壇のスタイルも多様であるべきだと思います。優れたエンジニアでも、登壇の場では衒学的になることを求められ、それに応えることでキャリアを築いていく側面があるように感じます。私の見解としては、実装の詳細や技術的な苦労話はブログという形式で書き残しておき、登壇では適度に抽象度を上げた概念を語るという使い分けは、それぞれのメディアの特性を活かした一つのアプローチかもしれません。ブログであれば、読者は自分のペースで何度も読み返し、理解を深めることができます。一方、登壇では限られた時間で複雑な文脈を伝えることは難しく、聴衆の注意を引きつつ主要なメッセージだけを印象づける技術が必要になるケースが多いと感じています。しかし、登壇が衒学的すぎることにも明らかな危険性があります。実体のない難解な言葉だけで埋め尽くされた発表は、短期的には印象的に見えても、長期的には聴衆の信頼を失います。「この人は話が上手いだけで、実際には何も伝えていない」と見抜かれれば、せっかくの登壇も台無しではないでしょうか。また、あまりに現実から乖離した抽象論ばかりでは、聴衆が実際の業務に持ち帰れる価値が少なく、最終的な目的である「やる気にさせる」ことにも失敗してしまうかもしれません。私なりに考える理想的な登壇とは、衒学的アプローチを適度に取り入れつつも、聴衆が明日から使える具体的なヒントや考え方をしっかりと提供するものです。「難解に思えるけれど、よく考えると実践的な知恵がある」という絶妙なバランスこそが、価値ある登壇の鍵かもしれませんが、これはあくまで一つの視点であり、様々な登壇スタイルがあって然るべきだと思います。エンジニアが技術的スキルに加えて、抽象的な概念を効果的に伝えるスキルを磨くことの価値は、人それぞれの考え方によると思います。重要なのは単なる見せかけではなく、本質的な価値を状況や相手に応じて適切に伝えるための表現技術ではないかと考えています。まとめエンジニアブログは具体的で技術的であることで長期的な参照価値を持ち、誰かの実際の問題解決に貢献します。一方、登壇は適度に衒学的なアプローチを取りながらも、聴衆に「深い話を聞いた」という満足感を与え、「自分も挑戦してみよう」というモチベーションを引き出すという役割があるように思います。もちろん、これはあくまで一つの見方であり、登壇やブログの形は多様であってよいと思います。「中身のない衒学」ではなく「知見を効果的に伝える技術」を身につけるべきだと考えています。限られた登壇時間と聴衆の記憶容量を考えると、物事を単純化し印象づける技術には価値がありますが、それが空虚なものであれば、長期的には信頼を失うことになると感じています。他の方は異なる価値観を持っているかもしれませんし、それも尊重されるべきです。個人的に大切だと思うのは、ブログでは誠実に技術を伝え、実際に同じ道を歩む人の助けになる一方で、登壇では効果的な伝え方を工夫しながらも本質的な価値を提供し、聴衆のやる気を引き出す、というそれぞれのメディアの特性を理解して使い分けることではないでしょうか。そして何より、「賢そうに見せる」ことと「本当に賢いこと」の違いを自分自身がしっかりと理解しておくことが重要だと思います。結局のところ、優れた技術共有とは、表面的な知識の誇示ではなく、本質的な価値をいかに効果的に伝えるかというバランスの問題なのかもしれません。メディアの特性を理解し、それぞれに合った形で自分の知見を共有できれば、技術コミュニティ全体がより豊かになっていくのではないでしょうか。これらはあくまで個人の経験と観察に基づく意見であり、みなさんがそれぞれのスタイルや価値観で技術共有を行うことを応援しています。","isoDate":"2025-04-07T09:11:50.000Z","dateMiliSeconds":1744017110000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AI時代に必要なシェルの基本知識とシェル芸への入門","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754","contentSnippet":"はじめに生成AIの急速な発展により、様々なAIアシスタントが日常的にシェルコマンドを提案してくれるようになりました。また、最新のAI統合ツールは、ユーザーの自然言語指示からコマンドを生成し、場合によっては自動的に実行することさえあります。このような環境では、AIが提案または実行するシェルコマンドを正確に理解し、安全に活用するための知識が不可欠となっています。「コマンドプロンプトやLinuxなんて難しそう」「プログラミングは専門家の領域」と思っている方こそ、この記事をお読みください。AIツールを使う現代では、専門知識がなくても基本を知っておくことで安全性が大きく変わります。本記事では、生成AIが提案するシェルコマンドを適切に評価し、安全に活用するために必要なシェルの基本知識と「シェル芸」と呼ばれる技術について詳しく解説します。難しい専門用語は極力避け、初心者の方でも理解できるよう丁寧に説明していきます。AIが生成したコードを盲目的に実行することのリスクを避けつつ、その強力な機能を最大限に活用するための実践的な知識を身につけていただくことを目指しています。b.ueda.tech普通に無料でダウンロードできるのでLinux標準教科書もオススメです。linuc.orgこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめに生成AIとシェルコマンドの関係シェルの基本概念代表的なシェルシェルの重要な機能1. I/O（入出力）2. パイプ3. リダイレクト4. フィルタ処理5. 内部展開6. 制御構文条件分岐（if文）case文（パターンマッチング）for ループwhile ループuntil ループ（条件が真になるまで繰り返す）関数定義と呼び出しその他の制御構文と技法AIが提案するシェルコマンドを理解するAIが生成するシェルコマンドの特徴ワンライナーの理解と解読ワンライナーの特徴生成AIが提案するワンライナーの例ワンライナーを解読する方法ワンライナーを複数行スクリプトに変換するコマンドを分解して理解する方法危険なコマンドの見分け方注意すべきコマンドとオプション安全に検証する方法安全な実行環境の構築と活用実用的なシェル芸とAIの活用例ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整AIからの提案を検証して実行する例テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価AIと連携したデータ前処理の例環境変数とエイリアスの理解環境変数の確認と活用AIが提案するエイリアスを安全に設定ジョブ制御と長時間実行コマンド長時間実行コマンドの制御実行中コマンドの管理ワンライナーの安全性評価と活用法ワンライナーの安全性評価チェックリストワンライナーを安全に変換する方法AIが提案するワンライナーを効果的に活用するコツワンライナー活用のベストプラクティスまとめ生成AIとシェルコマンドの関係生成AIはシェルコマンドの提案において非常に優れた能力を持っています。複雑な操作を1行のコマンドで実現したり、複数のツールを組み合わせて効率的なデータ処理を行ったりするシェルコマンドを即座に提案できます。しかし、この便利さの一方で、次のような課題も生じています。理解なき実行のリスク: AIが提案するコマンドを理解せずに実行すると、意図しないファイル削除やセキュリティリスクを引き起こす可能性があります環境依存の問題: AIは特定の環境を前提としたコマンドを提案することがあり、異なる環境で実行すると期待した結果が得られないことがあります権限の問題: 管理者権限が必要なコマンドを適切な検証なしに実行すると、システムに重大な影響を及ぼす可能性があります自動実行の危険性: GitHub Copilot CLIなどのツールがコマンドを自動生成し実行する場合、確認の機会なくリスクのあるコマンドが実行される可能性がありますこれらの課題に対処するには、シェルの基本を理解し、AIが提案するコマンドを正確に評価できる能力が必要です。シェルの基本概念シェルとは、オペレーティングシステム（OS）のカーネルと対話するためのインターフェースです。ユーザーがコマンドを入力すると、シェルはそれを解釈し、OSに対して適切な指示を出します。豆知識: シェルという名前は「殻」を意味し、OSの核心部分（カーネル）を覆う層として機能することに由来しています。［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】作者:武内 覚技術評論社Amazon代表的なシェルBash (Bourne Again SHell): Linux/Unixの標準シェルZsh (Z Shell): Bashの機能を拡張したシェル、macOSのデフォルトシェルPowerShell: Windowsで使用されるシェルFish: ユーザーフレンドリーな機能を持つシェル生成AIは異なるシェル環境向けのコマンドを提案することがあるため、自分の環境に合ったコマンドを理解し選択する必要があります。シェルの重要な機能AIが提案するコマンドを理解するには、以下のシェルの基本機能を把握することが重要です。1. I/O（入出力）Linuxの入出力は主に3つのストリームで管理されています。標準入力（stdin）: ユーザーからのキーボード入力（ファイルディスクリプタ 0）標準出力（stdout）: 通常の出力結果（ファイルディスクリプタ 1）標準エラー出力（stderr）: エラーメッセージ（ファイルディスクリプタ 2）AIが複雑な入出力リダイレクトを含むコマンドを提案した場合、これらの概念を理解していないと意図しない動作を引き起こす可能性があります。2. パイプパイプ（|記号）を使うと、あるコマンドの出力を次のコマンドの入力として渡すことができます。AIは複数のコマンドをパイプでつないだ複雑なワンライナーを好んで提案することがあります。例：# AIが提案するような複雑なパイプラインfind . -type f -name \"*.log\" | grep \"ERROR\" | awk '{print $1, $2}' | sort | uniq -cこのようなコマンドを理解するには、各部分の役割を個別に把握する必要があります。3. リダイレクトシェルではコマンドの出力を任意のファイルに書き出したり、コマンドへの入力を任意のファイルから行ったりできます。例：# 出力のリダイレクトls -l \u003e file_list.txt  # 上書きls -l \u003e\u003e file_list.txt  # 追記# 入力のリダイレクトsort \u003c unsorted.txt# エラー出力のリダイレクトcommand 2\u003e error.log# 標準出力とエラー出力を同じファイルへcommand \u003e output.log 2\u003e\u00261AIが提案するコマンドにリダイレクトが含まれる場合、既存ファイルの上書きなど、意図しない結果につながる可能性があるため注意が必要です。4. フィルタ処理生成AIは多くの場合、複数のフィルタコマンドを組み合わせた処理を提案します。代表的なフィルタコマンドとその役割を理解しておくことが重要です。grep: テキスト検索（正規表現可）sed: ストリームエディタ（テキスト置換など）awk: テキスト処理言語（列指向の処理に強い）sort/uniq: 行のソートと重複排除cut/paste: 列の切り出しと結合head/tail: 先頭/末尾の行を表示AIが提案する複雑なパイプラインは、これらのコマンドを組み合わせたものであることが多いため、各コマンドの役割を理解していれば全体の意図も把握しやすくなります。5. 内部展開シェルは入力されたコマンドを実行する前に、様々な展開処理を行います。AIが提案するコマンドに含まれる特殊な構文を理解するには、これらの展開処理の知識が必要です。変数展開: $VAR や ${VAR} で変数の値に置き換えるコマンド置換: `command` や $(command) でコマンドの実行結果に置き換える算術展開: $((expression)) で数式の計算結果に置き換えるブレース展開: {a,b,c} や {1..5} でパターンを展開するパス名展開（グロビング）: *, ?, [abc] などのワイルドカードを使ったファイル名の展開AIが提案するコマンドには、これらの展開を利用した簡潔な表現が含まれていることが多いです。6. 制御構文シェルスクリプト内での処理の流れを制御するための構文です。AIはしばしば複雑な条件分岐やループを含むシェルスクリプトを提案します。これらの構文を理解できないと、AIが提案するスクリプトの意図や潜在的なリスクを見逃す可能性があります。条件分岐（if文）# 基本構文if [ 条件 ]; then    # 条件が真の場合の処理elif [ 別の条件 ]; then    # 別の条件が真の場合の処理else    # どの条件も満たさない場合の処理fi# 数値比較の例if [ $num -eq 10 ]; then    echo \"numは10です\"elif [ $num -gt 10 ]; then    echo \"numは10より大きいです\"else    echo \"numは10より小さいです\"fi# ファイル・ディレクトリのテストif [ -f \"$file\" ]; then    echo \"$fileは通常ファイルです\"elif [ -d \"$file\" ]; then    echo \"$fileはディレクトリです\"elif [ ! -e \"$file\" ]; then    echo \"$fileは存在しません\"fi# 文字列比較if [ \"$str1\" = \"$str2\" ]; then    echo \"二つの文字列は同じです\"fiif [ -z \"$var\" ]; then    echo \"変数は空です\"fi主な条件テスト演算子：- 数値比較: -eq(等しい), -ne(等しくない), -lt(より小さい), -le(以下), -gt(より大きい), -ge(以上)- ファイルテスト: -e(存在する), -f(通常ファイル), -d(ディレクトリ), -r(読み取り可能), -w(書き込み可能), -x(実行可能)- 文字列テスト: =(等しい), !=(等しくない), -z(空), -n(非空)高度な条件テスト（[[ ]]構文）：# 拡張条件テストif [[ \"$file\" == *.txt ]]; then    echo \"テキストファイルです\"fiif [[ \"$str\" =~ ^[0-9]+$ ]]; then    echo \"数値のみの文字列です\"fi# 論理演算子if [[ $num -gt 5 \u0026\u0026 $num -lt 10 ]]; then    echo \"numは5より大きく10未満です\"fiif [[ $opt == \"a\" || $opt == \"b\" ]]; then    echo \"オプションはaまたはbです\"ficase文（パターンマッチング）# 基本構文case $variable in    pattern1)        # pattern1にマッチした場合の処理        ;;    pattern2|pattern3)        # pattern2またはpattern3にマッチした場合の処理        ;;    *)        # どのパターンにもマッチしない場合の処理（デフォルト）        ;;esac# 実用例case $action in    start|begin)        echo \"サービスを開始します\"        service_start        ;;    stop|end)        echo \"サービスを停止します\"        service_stop        ;;    restart)        echo \"サービスを再起動します\"        service_restart        ;;    *)        echo \"使用法: $0 {start|stop|restart}\"        exit 1        ;;esacfor ループ# 基本形（リスト指定）for item in item1 item2 item3; do    echo \"処理: $item\"done# 範囲指定for i in {1..10}; do    echo \"数: $i\"done# ステップ付き範囲指定for i in {1..10..2}; do    echo \"奇数: $i\"  # 1,3,5,7,9done# コマンド出力をループfor file in $(find . -name \"*.txt\"); do    echo \"ファイル: $file\"done# ワイルドカード展開for file in *.log; do    echo \"ログファイル: $file\"done# C言語風の構文for ((i=0; i\u003c5; i++)); do    echo \"カウント: $i\"donewhile ループ# 基本構文while [ 条件 ]; do    # 条件が真の間、繰り返し実行される処理done# カウンタ変数による繰り返しcount=1while [ $count -le 5 ]; do    echo \"カウント: $count\"    count=$((count + 1))done# ファイル内容を1行ずつ処理while read line; do    echo \"Line: $line\"done \u003c input.txt# コマンド結果をチェックするループwhile ping -c 1 example.com \u003e /dev/null; do    echo \"サーバーは応答しています\"    sleep 5doneuntil ループ（条件が真になるまで繰り返す）# 基本構文until [ 条件 ]; do    # 条件が偽の間、繰り返し実行される処理done# 例: サービスが起動するまで待機until service_is_running; do    echo \"サービス起動を待機中...\"    sleep 2doneecho \"サービスが起動しました\"関数定義と呼び出し# 基本的な関数定義function greet {    echo \"Hello, World!\"}# 別の構文（function キーワードなし）backup_file() {    cp \"$1\" \"$1.bak\"    echo \"Backed up $1 to $1.bak\"}# 引数を受け取る関数print_args() {    echo \"第1引数: $1\"    echo \"第2引数: $2\"    echo \"すべての引数: $@\"    echo \"引数の数: $#\"}# 戻り値を返す関数is_even() {    if (( $1 % 2 == 0 )); then        return 0  # 成功（真）    else        return 1  # 失敗（偽）    fi}# 関数の呼び出しgreetbackup_file \"important.txt\"print_args \"hello\" \"world\"# 戻り値のチェックif is_even 4; then    echo \"4は偶数です\"fiその他の制御構文と技法# コマンドの成功/失敗に基づく条件実行command1 \u0026\u0026 command2  # command1が成功した場合のみcommand2を実行command1 || command2  # command1が失敗した場合のみcommand2を実行# 例grep \"pattern\" file.txt \u0026\u0026 echo \"パターンが見つかりました\"grep \"pattern\" file.txt || echo \"パターンが見つかりませんでした\"# サブシェル（グループ化）(cd /tmp \u0026\u0026 ls -la)  # 現在のディレクトリを変更せずにコマンドを実行# 現在のシェルでのグループ化{ echo \"開始\"; command1; command2; echo \"終了\"; }# エラーハンドリングset -e  # エラーが発生したらスクリプトを終了trap 'echo \"エラーが発生しました\"; exit 1' ERR  # エラー発生時の処理を指定# デバッグモードset -x  # 実行されるコマンドを表示AIが生成するシェルスクリプトには、これらの制御構文が組み合わされて使用されることが多いです。特に注意すべき点は：条件判定の確認: 条件テストが意図したとおりに動作するか確認するループの終了条件: 無限ループになっていないか確認するエラーハンドリング: エラー発生時に適切に処理されるか確認する変数の展開: 変数が適切に展開されて使用されているか確認するAIが提案するスクリプトの制御構文を理解することで、そのスクリプトが何をしようとしているのか、そして潜在的なリスクがあるかどうかを判断できるようになります。AIが提案するシェルコマンドを理解する生成AIは非常に効率的なシェルコマンドを提案できますが、それを理解し安全に実行するにはいくつかのステップが必要です。特に生成AIは複雑な処理を1行で完結させる「ワンライナー」を好んで提案する傾向があります。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社AmazonAIが生成するシェルコマンドの特徴複雑なワンライナー: 複数の処理を1行で実行するコマンド高度なオプションの使用: 一般的ではない特殊なオプションの利用複数のツールの組み合わせ: grep, sed, awk, findなど複数のツールを組み合わせた処理正規表現の多用: 複雑なパターンマッチングを使用したテキスト処理環境依存の記述: 特定の環境を前提としたコマンドリソース集約的な処理: システムリソースを大量に消費する可能性のある処理ワンライナーの理解と解読生成AIは複数のコマンドを組み合わせた「ワンライナー」を頻繁に提案します。ワンライナーとは、複数の処理を1行のコマンドで完結させる技法で、効率的ですが理解が難しい場合があります。ワンライナーの特徴複数コマンドの連結: パイプ（|）やセミコロン（;）で複数のコマンドを連結制御構文の圧縮: if文やループをセミコロンで区切り1行に記述サブシェルの多用: $(command) や `command` でコマンド出力を埋め込みリダイレクトの組み合わせ: 入出力リダイレクトを複雑に組み合わせる特殊な演算子: \u0026\u0026（AND）、||（OR）、{}（グループ化）などの使用生成AIが提案するワンライナーの例# ログファイルからエラーを抽出して集計するワンライナーfind /var/log -name \"*.log\" -mtime -7 | xargs grep -l \"ERROR\" | xargs cat | grep -o \"ERROR: [^ ]*\" | sort | uniq -c | sort -nr | head -10# ディレクトリ内の大きなファイルを検索して移動するワンライナーfind . -type f -size +100M -exec du -h {} \\; | sort -hr | head -10 | awk '{print $2}' | xargs -I{} mv {} /backups/# 複数ファイルの文字列を一括置換するワンライナーgrep -l \"oldtext\" *.txt | xargs sed -i 's/oldtext/newtext/g'# 条件分岐を含むワンライナーfor file in *.log; do [ -s \"$file\" ] \u0026\u0026 echo \"$file is not empty\" || echo \"$file is empty\"; done# サブシェルと変数展開を使ったワンライナーfor i in {1..5}; do mkdir -p project_$(date +%Y%m%d)_$i/{src,docs,tests}; doneワンライナーを解読する方法セミコロンで分割: セミコロン（;）で区切られた部分を別々のコマンドとして考える   # 元のワンライナー   cd /tmp; mkdir test; cd test; touch file.txt; echo \"done\"      # 分解したコマンド   cd /tmp   mkdir test   cd test   touch file.txt   echo \"done\"パイプライン分析: パイプ（|）ごとにデータの流れを追跡する   # パイプラインの追跡   find . -name \"*.log\" | grep \"ERROR\" | awk '{print $1}' | sort | uniq -c      # ステップ1: logファイルの一覧を生成   # ステップ2: ERRORを含む行をフィルタリング   # ステップ3: 各行の最初のフィールドを抽出   # ステップ4: 結果をソート   # ステップ5: 重複を数えて集計制御構造の識別: for、if、whileなどの制御構造を識別して展開する   # 元のワンライナー   for file in *.txt; do grep \"pattern\" \"$file\" \u0026\u0026 echo \"$file contains pattern\"; done      # 展開した形   for file in *.txt   do       if grep \"pattern\" \"$file\"       then           echo \"$file contains pattern\"       fi   doneエコーデバッグ: 実行せずに echo でコマンドを表示する   # 危険そうなワンライナー   find . -name \"*.tmp\" -delete      # エコーデバッグバージョン   find . -name \"*.tmp\" -print部分実行: ワンライナーの一部だけを実行して結果を確認   # 完全なワンライナー   find . -name \"*.log\" | xargs grep \"ERROR\" | awk '{print $1,$2}' | sort \u003e errors.txt      # 部分実行   find . -name \"*.log\" | head  # まず対象ファイルを確認   find . -name \"*.log\" | xargs grep \"ERROR\" | head  # エラー行を確認ワンライナーを複数行スクリプトに変換するAIが提案する複雑なワンライナーは、理解しやすい複数行スクリプトに変換すると安全性が向上します。# 元のワンライナーfind /var/log -name \"*.log\" -mtime -7 | xargs grep -l \"ERROR\" | xargs cat | grep -o \"ERROR: [^ ]*\" | sort | uniq -c | sort -nr | head -10# 複数行スクリプトに変換#!/bin/bash# 最近7日間のログファイルを見つけるlog_files=$(find /var/log -name \"*.log\" -mtime -7)# エラーを含むファイルだけを抽出error_files=$(grep -l \"ERROR\" $log_files)# エラーメッセージを抽出して集計cat $error_files |     grep -o \"ERROR: [^ ]*\" |     sort |     uniq -c |     sort -nr |     head -10コマンドを分解して理解する方法AIが提案する複雑なコマンドを理解するための効果的なアプローチ：パイプでセグメント化: パイプ（|）ごとにコマンドを分割して考える   # 元のコマンド   find . -name \"*.log\" | grep \"ERROR\" | awk '{print $1}' | sort | uniq -c      # 分解して考える   find . -name \"*.log\"     # ステップ1: logファイルを見つける   grep \"ERROR\"             # ステップ2: ERRORを含む行を抽出   awk '{print $1}'         # ステップ3: 各行の最初のフィールドを取得   sort                     # ステップ4: 結果をソート   uniq -c                  # ステップ5: 重複をカウント部分的な実行: コマンドの一部だけを実行して結果を確認   # 段階的に実行して結果を確認   find . -name \"*.log\" | head  # まず対象ファイルを確認   find . -name \"*.log\" | grep \"ERROR\" | head  # 次にエラー行を確認マニュアルの確認: 不明なオプションは man や --help で調査   man find   # findコマンドのマニュアルを表示   grep --help  # grepのヘルプを表示テスト環境での実行: 実際のシステムやデータに影響を与えないテスト環境で試す危険なコマンドの見分け方AIが提案するコマンドの中には、システムに重大な影響を与える可能性のあるものもあります。そのようなコマンドを見分けるポイント：注意すべきコマンドとオプションファイル削除系   rm -rf  # 再帰的強制削除（特に /* や / を含む場合は危険）   find ... -delete  # 見つかったファイルを削除ファイル書き換え系   \u003e file  # ファイルの内容を上書き   sed -i  # ファイルを直接編集   dd      # ブロックレベルでのデータコピー（特にofオプションが危険）システム関連   shutdown, reboot  # システムの停止や再起動   chmod -R 777 /  # 危険な権限変更   mkfs  # ファイルシステムのフォーマットネットワーク関連   iptables -F  # ファイアウォールルールの削除   ssh-keygen -R  # 既知のホスト情報の削除安全に検証する方法実行前の確認コマンドの各部分が何をするのか理解する特に -f, -r, --force などの強制オプションに注意ワイルドカード (*, ?) の展開範囲を確認安全なオプションの利用   # 本当に削除する前に確認   rm -i file  # 対話的に確認      # 実際の変更前にシミュレーション   find . -name \"*.tmp\" -print  # -deleteの代わりに-printで確認   rsync --dry-run src/ dest/  # 実際のコピーなしでシミュレーションエコーやリダイレクト先の変更   # 危険なコマンドの代わりに同等の安全なコマンドで確認   echo \"rm -rf /\" # 実行せずに表示      # リダイレクト先を変更   command \u003e /tmp/test.out  # 重要なファイルではなくテスト用ファイルに出力実行前のバックアップ   # 重要なファイルのバックアップ   cp -a important_file important_file.bak安全な実行環境の構築と活用これらのコマンドの違いが分からない場合は、システム環境を破壊してしまう可能性があるため、VM（仮想マシン）やDocker（コンテナ技術）、リモートホストなどの隔離環境を使用しましょう。生成AIが提案するシェルコマンドを実行する際には、潜在的なリスクを軽減するために隔離された安全な環境を利用することが推奨されます。特に未知のコマンドや複雑なワンライナー（1行で記述された複合コマンド）を試す場合は、これらの環境を活用することでメインシステムへの悪影響を最小限に抑えることができます。実用的なシェル芸とAIの活用例AIが提案するシェルコマンドを理解し、自分のニーズに合わせて調整することで、日常の作業を効率化できます。ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整# AIが提案した複雑なファイル名変更コマンドfind . -type f -name \"log_*.txt\" -exec bash -c 'mv \"$1\" \"${1/log_/archive_}\"' _ {} \\;# より理解しやすく調整したバージョン# まず対象を確認find . -type f -name \"log_*.txt\" -print# 安全に実行for file in log_*.txt; do  echo \"Renaming $file to ${file/log_/archive_}\"  mv \"$file\" \"${file/log_/archive_}\"doneAIからの提案を検証して実行する例# AI提案: ディレクトリ内の全HTMLファイルでテキスト置換find . -type f -name \"*.html\" -exec sed -i 's/oldCompany/newCompany/g' {} \\;# 検証方法# 1. まず対象ファイルを確認find . -type f -name \"*.html\" | wc -l  # 対象ファイル数の確認# 2. 一部のファイルで試すfind . -type f -name \"*.html\" | head -1 | xargs grep \"oldCompany\"  # 置換前の確認find . -type f -name \"*.html\" | head -1 | xargs sed 's/oldCompany/newCompany/g'  # 置換シミュレーション# 3. バックアップしてから実行find . -type f -name \"*.html\" -exec cp {} {}.bak \\;  # バックアップ作成find . -type f -name \"*.html\" -exec sed -i 's/oldCompany/newCompany/g' {} \\;  # 実行テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価# AI提案: 複雑なログ解析コマンドcat access.log | grep -o '\"GET [^\"]*\"' | sed 's/\"GET \\(.*\\)\"/\\1/g' | sort | uniq -c | sort -nr | head -10# 検証と理解# 1. 段階的に実行cat access.log | head -5  # まずログの形式を確認cat access.log | grep -o '\"GET [^\"]*\"' | head -5  # GETリクエストの抽出確認cat access.log | grep -o '\"GET [^\"]*\"' | sed 's/\"GET \\(.*\\)\"/\\1/g' | head -5  # パスの抽出確認# 2. 最終結果の解釈# このコマンドは「アクセス数の多いパスTOP10」を表示しているAIと連携したデータ前処理の例# AIにデータを渡す前の前処理# 1. 個人情報をマスクcat data.csv | sed 's/\\([0-9]\\{3\\}\\)[0-9]\\{4\\}\\([0-9]\\{4\\}\\)/\\1-XXXX-\\2/g' \u003e masked_data.csv# 2. 必要な列だけを抽出cat masked_data.csv | awk -F, '{print $1,$3,$5}' OFS=, \u003e processed_data.csv# 3. AIに送るデータのサンプルを確認head -10 processed_data.csv環境変数とエイリアスの理解AIが提案するコマンドには、環境変数やエイリアスを利用したものもあります。これらを正しく理解することで、コマンドの意図や潜在的な問題を把握できます。環境変数の確認と活用# AIが提案する環境変数を使ったコマンドcd $HOME/projects \u0026\u0026 find . -name \"*.py\" | xargs grep \"TODO\"# 検証方法echo $HOME  # HOME変数の値を確認ls -la $HOME/projects  # プロジェクトディレクトリの存在確認AIが提案するエイリアスを安全に設定# AI提案: 便利なエイリアスalias ll='ls -la'alias findgrep='find . -type f -exec grep --color=auto -l \"$1\" {} \\;'# 検証と調整# 関数として定義し直す（引数の扱いが明確）findgrep() {  find . -type f -exec grep --color=auto -l \"$1\" {} \\;}# 使い方の確認type findgrep  # 関数定義を確認findgrep \"search term\"  # 実行テストジョブ制御と長時間実行コマンドAIはしばしば長時間実行する可能性のあるコマンドを提案します。このようなコマンドを実行する際のジョブ制御を理解しておくことが重要です。長時間実行コマンドの制御# AI提案: 大量ファイルの圧縮find /var/log -type f -name \"*.log\" | xargs gzip# より安全な実行方法# バックグラウンド実行してログを残すfind /var/log -type f -name \"*.log\" | xargs gzip \u003e compression.log 2\u003e\u00261 \u0026echo $! \u003e compression.pid  # プロセスIDを保存# 実行状況の確認ps -p $(cat compression.pid)tail -f compression.log実行中コマンドの管理# 実行中のコマンドの一時停止と再開Ctrl+Z  # 一時停止bg      # バックグラウンドで再開fg      # フォアグラウンドで再開# ジョブの一覧と管理jobs    # 現在のジョブ一覧kill %1  # ジョブ番号1を終了# ログアウト後も実行を継続nohup command \u0026  # ログアウト後も実行継続screen           # 仮想端末での実行tmux             # ターミナルマルチプレクサでの実行ワンライナーの安全性評価と活用法生成AIが提案するワンライナーを安全に活用するためのポイントです。ワンライナーの安全性評価チェックリストワンライナーを実行する前に以下の点をチェックすると安全性が向上します。また、これらが通っているからといって必ず安全というわけではない。破壊的コマンドの有無rm, mv, dd, \u003e (上書きリダイレクト)などのデータを破壊する可能性のあるコマンドが含まれているか例: rm -rf, find ... -delete, sed -i などは特に注意システム全体への影響/, /etc, /bin などの重要なシステムディレクトリに対する操作があるかchmod -R, chown -R などの再帰的な権限変更が含まれているかリソース消費find / など広範囲を検索する処理が含まれているか深い再帰処理や大量のファイル処理による負荷の可能性はあるか特権要求sudo や su などの特権昇格が含まれているか実行に特別な権限が必要なコマンドが含まれているかバックドア・不審なコードcurl | bash のようなインターネットからのスクリプト実行が含まれていないか暗号化されたコードや理解できない難読化された部分が含まれていないかワンライナーを安全に変換する方法# 危険なワンライナーfind / -name \"*.bak\" -delete# より安全な代替案# 1. プレビューモード: 削除せずに表示のみfind / -name \"*.bak\" -print# 2. 対話モード: 一つずつ確認find / -name \"*.bak\" -exec rm -i {} \\;# 3. 特定ディレクトリに限定find ~/projects -name \"*.bak\" -delete# 4. スクリプトに変換して段階的に実行#!/bin/bashecho \"次のファイルを削除します:\"find / -name \"*.bak\" -printread -p \"続行しますか？ (y/n) \" answerif [ \"$answer\" = \"y\" ]; then    find / -name \"*.bak\" -deletefiAIが提案するワンライナーを効果的に活用するコツ理解してから実行: 必ず各部分の意味を理解してから実行する段階的な検証: まず無害なオプションで実行し、結果を確認してから本来の処理を実行コメント付きスクリプトへの変換: 複雑なワンライナーはコメント付きの複数行スクリプトに変換変数の活用: ハードコードされたパスや値を変数に置き換えて柔軟性を高める環境に合わせた調整: 自分の環境に合わせてコマンドを調整するワンライナー活用のベストプラクティススクリプト化して再利用: 有用なワンライナーはスクリプトファイルに保存して再利用エイリアスとして登録: 頻繁に使うワンライナーはエイリアスとして登録   alias finderrors='find . -name \"*.log\" | xargs grep -l \"ERROR\"'関数化: 引数を受け取れるようにしてカスタマイズ性を高める   find_errors() {       find . -name \"*.$1\" | xargs grep -l \"$2\"   }   # 使用例: find_errors log ERRORバージョン管理: 重要なワンライナーやスクリプトはGitなどで管理ドキュメント化: 複雑なワンライナーは使い方や前提条件をドキュメント化まとめ生成AIがシェルコマンドを提案する時代において、以下のポイントを押さえておくことが重要です。理解してから実行: AIが提案するコマンドを盲目的に実行せず、各部分の意味を理解してから実行する段階的な検証: 複雑なコマンドは部分的に実行して、期待通りの動作をするか確認する危険なコマンドの見極め: システムに重大な影響を与える可能性のあるコマンドを識別できるようにする適切な調整: AIの提案を自分の環境や要件に合わせて調整する能力を身につけるバックアップの習慣: 重要なデータは常にバックアップしてから操作するワンライナーの分解理解: 複雑なワンライナーは各部分に分解して理解するスクリプト化の検討: 複雑なコマンドはスクリプトに変換して読みやすく、再利用可能にするこれらの知識とアプローチを身につけることで、生成AIが提案するシェルコマンドを安全かつ効果的に活用し、作業効率を大幅に向上させることができます。AI時代のシェルコマンド活用は、理解に基づいた適切な判断が鍵となります。生成AIとシェルの組み合わせは非常に強力なツールですが、その力を適切に扱うには基本的な理解が欠かせません。この記事が、皆さんがAIと安全に協働するための一助となれば幸いです。入門 モダンLinux ―オンプレミスからクラウドまで、幅広い知識を会得する作者:Michael Hausenblasオーム社Amazonより詳しく知りたい人はLinuxシステムプログラミング作者:Robert Love,ロバート ラブオライリージャパンAmazon狂人はこちらでお願いします。Linuxプログラミングインタフェース作者:Michael KerriskオライリージャパンAmazon","isoDate":"2025-04-03T23:57:54.000Z","dateMiliSeconds":1743724674000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"3年目までに身につけたい技術ブログの書き方","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420","contentSnippet":"はじめにあなたは日々、何かを見ている。そう、コードを。エラーを。ドキュメントを。解決策を。そして、それは誰も見ていないものかもしれない。あるいは、多くの人が同じものを見ているのに、誰も記録に残していないのかもしれない。「自分なんてまだ1年目、2年目。経験が浅いから書くことなんてない」そんな思いを抱いていませんか？ しかし、その思い込みは真実ではありません。むしろ、経験の浅さこそが、あなたにしか書けない貴重な視点を生み出します。初めて学ぶ時の困惑、理解するまでの試行錯誤、そして「あ、わかった！」という喜び—これらの生々しい体験は、あなたがまさに今感じているからこそ書ける宝物なのです。「専門家でもないのにブログなんて書けない」「自分の書いたものなんて誰も読まないだろう」という思いも、単なる幻想です。誰もが最初から専門家ではなかった。今あなたが参考にしている記事を書いた人も、最初は不安を抱えながらキーボードに向かったはずです。このブログを書いている私もです。ネット上には膨大な情報があふれていますが、だからこそ、あなたの視点、あなたの言葉、あなたの経験を通して伝えられる情報には価値があります。なぜなら、あなたの記事を必要としている人は、まさにあなたと同じ疑問や課題を持っている人だからです。技術ブログは、完璧な知識や完成された思考を示すためのものではありません。それは思考の過程を記録するものです。完璧を目指すあまり書けなくなるよりも、不完全でも自分の観察と気づきを残していくことに価値があります。自分が躓いたその瞬間こそ、同じ場所で立ち止まっている誰かにとっての地図になる。あなたが苦労して辿り着いた解決策は、未来の誰かの貴重な時間を節約するだけでなく、新たな発見への扉を開くきっかけになるかもしれません。この記事では、技術ブログの種類とその書き方、特に新人エンジニアが取り組みやすいパターンについて解説します。ブログを書く意義、どのようなブログを書けばよいのか、どう書き始めればよいのか、批判されたときにはどうすればよいのかを知ることで、あなたの歩んできた道は他のエンジニアにとって価値ある情報源となり、同時にあなた自身の成長を加速させる強力なツールとなるでしょう。「でも、文章を書くのが苦手で…」「何を書けばいいか分からなくて…」と思っているあなたも、この記事を読み終わる頃には、最初の記事を書くためのアイデアとやる気を手に入れているはずです。さあ、あなたの知識や経験を世界と共有する旅を、一緒に始めましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめにブログ執筆がもたらす価値思考を整理する鏡知識の共有経済への参加思考の足跡としてのブログ技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記2. バグハント記事3. 環境構築ガイド4. 学んだ教訓記事5. プログラミング言語の乗り換え記録6. システム開発の舞台裏7. 技術トレンドの考察8. 技術の性能比較と検証書き始めるための実践ガイド始めやすいブログパターンの選択日常からネタを発掘する技術読者を惹きつける記事構成読みやすさを高める実践テクニック心地よい技術コミュニケーションのために読み手の感情を大切にする好きなものを中心に語る個人の経験として共有する主観的な表現を心がけるポジティブな内容を中心に批判を柔らかく伝える工夫背景情報を丁寧に説明するもし反発を受けたときの心構え人気記事には批判も付きもの反応せずに見守る勇気を持つコメントの背景を想像してみる誤解には丁寧な補足を時間の流れを味方にするブログ公開の場の選択技術特化型プラットフォーム汎用ブログプラットフォーム自前のブログプラットフォーム選びのアドバイス継続のための現実的なアプローチ小さなハードルから始める自分のための記録として書く「十分に良い」の基準を持つ終わりに質の良い火種を作る本気(マジ)の話ブログ執筆がもたらす価値技術ブログを書く行為には、表面的には見えない多くの価値があります。思考を整理する鏡「説明できることは理解している証拠だ」という言葉があります。コードを書くだけではわからなかった理解の穴が、他者に説明しようとする瞬間に見えてきます。ブログ執筆は自分の思考をクリアにし、知識の定着を促す強力なツールです。ラバーダック・デバッギングがコードの理解を深めるように、ブログはあなたの思考を整理します。知識の共有経済への参加オープンソースのコードを共有するように、あなたの解決策や洞察も共有価値があります。あなたが30分かけて解決した問題は、記事を通じて何百人もの時間を節約するかもしれません。それは単なる善意ではなく、テクノロジー業界の発展に寄与する行為です。思考の足跡としてのブログ定期的に書かれたブログは、あなたの専門性と成長の記録となります。それは履歴書やポートフォリオ以上に、あなたの思考プロセスと問題解決能力を示す生きた証拠になります。自然と「個人ブランド」が形成され、思わぬ機会につながることもあるでしょう。技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記新人に特におすすめ新しい技術やツールを学んだ過程を記録するブログです。チュートリアルの穴を埋めたり、つまずいたポイントの解決策を共有したりします。書き方のポイント:学習の目的と背景を明確につまずいたポイントと解決法を詳細に公式ドキュメントには書かれていない気づきを強調スクリーンショットやコードスニペットで手順を明確に構成例:学習の動機（なぜこの技術を学ぼうと思ったか）前提知識と環境学習プロセス（つまずいたポイントを含む）得られた気づきと学び次のステップ2. バグハント記事特定のバグや問題を発見し、追跡し、最終的に修正するまでの旅を共有するブログです。書き方のポイント:問題の症状と影響を具体的に調査プロセスを時系列で詳細に（ミステリー小説のように、叙述トリックを使ってもよいですがほどほどに⋯）フレームグラフ、ログ、診断データなどの「証拠」を提示どのような思考プロセスで原因に辿り着いたかを解説最終的な解決策と学んだ教訓構成例:問題の概要（何が起きたか）調査の開始（最初の仮説）探索と証拠収集誤った道と行き止まり（失敗も正直に）原因の特定と理解解決策と検証学んだ教訓と予防策3. 環境構築ガイド開発環境や特定のツールのセットアップ方法を解説するブログです。書き方のポイント:対象読者（初心者か上級者か）を明確に前提条件と必要なツールを明示手順をステップバイステップで説明トラブルシューティングの情報を含める何のためにこの設定をするのかの理由も説明構成例:目的と概要前提条件と必要なものインストール手順（ステップバイステップ）設定と最適化動作確認の方法よくあるトラブルとその解決法4. 学んだ教訓記事プロジェクトや技術的課題から得た教訓や気づきを共有するブログです。書き方のポイント:率直かつ謙虚なトーンで具体的な状況と文脈を提供失敗や間違った判断からの学びを強調他のエンジニアに適用できる一般的な教訓を抽出時系列に沿った「日記的」な構成も有効構成例:状況と背景直面した課題取った行動と判断結果と振り返り学んだ教訓次回への活かし方5. プログラミング言語の乗り換え記録既存のプロジェクトを新しいプログラミング言語やフレームワークで作り直した経験を共有するブログです。書き方のポイント:言語やフレームワークを変更した理由を分かりやすく説明古い言語と新しい言語の違いと比較移行作業で苦労した点とその解決方法処理速度や保守のしやすさの比較結果言語の乗り換えから学んだこと構成例:現状と移行の動機技術選定と比較検討移行戦略と計画実装の詳細と課題成果と比較（ビフォー・アフター）学んだ教訓と今後の展望6. システム開発の舞台裏システムや機能をどのように考え、設計し、作り上げたかを詳しく説明するブログです。書き方のポイント:システムの目的と必要な機能を明確に設計で迷った点や判断した理由を説明全体の構造を図や図解でわかりやすく重要なコードの部分とその役割の解説ぶつかった壁とその乗り越え方今後の改善点や拡張できる部分構成例:プロジェクトの背景と目標要件と制約条件設計の選択肢と検討プロセス選んだアーキテクチャとその理由実装の重要ポイント課題と解決策結果と評価7. 技術トレンドの考察IT業界の流行りや新しい技術の動きについて、自分なりの意見や分析を述べるブログです。書き方のポイント:堅固な論拠と証拠で意見を裏付ける単なる批判ではなく、建設的な視点を提供自分の経験に基づいた具体例を含める複数の視点を考慮し、バランスの取れた議論を展開明確な結論と、読者が検討すべきポイントを提示構成例:トレンドの概要と背景現在の状況分析メリットとデメリット実務への影響と適用性自分の見解と予測実践的なアドバイス8. 技術の性能比較と検証異なる技術や方法の速度や効率を実際に測って比較し、その結果を共有するブログです。書き方のポイント:テスト方法と環境を詳細に記述公平で再現可能なベンチマーク手法を使用データを明確に視覚化（グラフ・表）結果の解釈と実用的な意味を説明限界と注意点も正直に伝える読者が検証できるようコードや手順を共有構成例:テストの目的と背景検証環境とセットアップテスト方法と条件結果の提示と分析発見と考察実用的な示唆と推奨事項書き始めるための実践ガイド始めやすいブログパターンの選択新人エンジニアが最初に挑戦しやすいのは、自分の直接体験に基づいた記事です。特に以下のパターンは、書きやすく読者にも価値を提供しやすい傾向があります。学習ログ＆チュートリアル体験記 - 公式ドキュメントには書かれていない「実際にやってみたらどうだったか」の記録は、後続の学習者にとって貴重な情報源になります。また、英語のチュートリアルを日本語でやってみるだけでも大きな価値があります。環境構築ガイド - 一度苦労して設定した開発環境の手順は、記録しておくだけで大きな価値があります。読者や半年後の自分も、同じ苦労をせずに済むでしょう。バグハント記録 - 解決に時間がかかった問題は、その過程を含めて記録する価値があります。デバッグの思考プロセスこそが、技術的な洞察を含んでいます。学びの教訓 - 「〜だと思っていたけど、実際は違った」という気づきは、技術記事として非常に価値があります。誤解やミスコンセプションを正す内容は、多くの人の時間を節約します。日常からネタを発掘する技術記事のアイデアは日々の業務や学習の中に隠れています。以下の視点で日常を観察してみましょう。学習過程での「なぜ？」、理解するのに時間がかかった概念や、直感に反する仕様は、記事になりやすいトピックです。繰り返し説明していること、チーム内で何度も同じ説明をしている内容は、記事化する価値が高いでしょう。検索しても満足な答えが見つからなかった問題、そのような問題を解決できたなら、あなたと同じ検索をする誰かのために記録を残しましょう。「あれ？」と思った瞬間、予想通りに動かなかったコード、意外な挙動を示したツール、これらの「あれ？」の瞬間は、貴重な記事の種です。このような日常の発見からブログネタを見つける考え方は、ジェームス・W・ヤングの名著『アイデアのつくり方』に私の考え方は近いです。ヤングによれば、アイデアとは既存の要素の新しい組み合わせであり、その才能は事物の関連性を見つけ出す力に依存しています。ヤングが提唱する5段階のアイデア創出プロセスは、技術ブログ執筆にも応用できます。資料を収集する - 特定のテーマに関する専門知識と、幅広い一般知識の両方を集める資料を噛み砕く - 集めた情報を様々な角度から検討し、関係性を探る問題を放棄する - 一度意識的な思考から離れ、無意識に働かせるアイデアが訪れる - 何気ない日常の瞬間（シャワー中やトイレなど）に閃きが生まれるアイデアを現実に連れ出す - 閃いたアイデアを忍耐強く形にするあなたの「あれ？」という瞬間は、ヤングの創造プロセスの一部として考えることができます。まず資料収集の段階で日々の開発や、読書、学習から知識を蓄え（第1段階）、それらの情報を頭の中で検討し関連付けようとし（第2段階）、一度問題から離れて無意識に働かせ（第3段階）、そして「あれ？」という気づきや閃きが訪れるのです（第4段階）。この瞬間を逃さず記録し、丁寧に育てて記事として形にしていく作業が最終段階（第5段階）となります。日々の疑問や発見を意識的に記録する習慣をつけることで、ヤングのプロセスを体現し、貴重なブログの種を蓄積できるでしょう。「ブログが書けない」と悩んでいるほとんどの人は、この5段階のプロセスのどこかが欠如していることがほとんどです。そして、どの段階が欠如しているかによって、対応方法が大きく変わります。資料収集が不足している人には、まずは情報のインプットを増やすことが重要です。技術書を読む、オンラインコースを受講する、技術カンファレンスの動画を見るなど、様々な方法で知識の幅を広げましょう。また、特定の技術だけでなく、隣接分野や全く異なる分野の知識も取り入れることで、独自の組み合わせが生まれやすくなります。情報の噛み砕きが不足している人には、学んだことをノートにまとめる、同僚に説明する、図解してみるなどの方法がおすすめです。具体化したり抽象化したりするのもおすすめです。情報を受動的に受け取るだけでなく、自分の言葉で咀嚼し直すことで、新たな気づきが生まれやすくなります。リラックスの時間が不足している人には、意識的に「何も考えない時間」を作ることが大切です。常に問題解決モードでは、無意識の働きが活かせません。散歩する、お風呂に浸かる、瞑想するなど、頭を空っぽにできる時間を日常に取り入れましょう。閃きを見逃している人には、スマートフォンのメモアプリやノートを常に持ち歩き、思いついたことをすぐに記録する習慣をつけることをおすすめします。閃きは突然訪れ、すぐに消えてしまうものです。「あとで覚えておこう」と思っても、ほとんどの場合は忘れてしまいます。書ききれない人には、「まずは15分だけ書く」という小さなハードルから始めることをおすすめします。完璧な記事を目指すのではなく、とにかく書き始めること。編集や推敲は後からでも可能ですが、書かれていない文章は編集のしようがありません。また、締め切りを設定したり、書き始める時間と場所を決めておくなど、環境を整えることも効果的です。あなたがブログを書けない理由がどの段階にあるのかを特定することで、より効果的な対策を講じることができるでしょう。アイデアのつくり方作者:ジェームス W.ヤングCCCメディアハウスAmazon読者を惹きつける記事構成技術ブログも、読者が最後まで読みたくなる構成が重要です。以下のような流れを意識すると、読みやすい記事になります。問題提起 - なぜこの記事を書いたのか、読者にとってどんな価値があるのかを明確にします。最初の段落で「この記事を読むことで解決できる問題」を具体的に示すことで、読者の興味を引きつけましょう。「〜に悩んでいませんか？」「〜をもっと効率的にしたいと思いませんか？」といった形で読者の課題に共感を示すと効果的です。ただし、単なるクリックベイト的な見出しや過度な約束は避け、記事の内容と一致した誠実な問題提起を心がけましょう。コンテキスト - あなたの環境や前提条件を説明し、読者が自分の状況と比較できるようにします。「私がこの問題に取り組んだ時の状況はこうでした」と具体的に共有することで、読者は自分のケースとの類似点や相違点を理解できます。使用した技術のバージョン、ハードウェア環境、チームの規模、プロジェクトの背景など、関連する情報を提供しましょう。これにより、読者は記事の内容が自分にとって適用可能かどうかを判断できます。コンテキストが明確であればあるほど、読者は安心して読み進められます。探求の旅 - 単なる解決策ではなく、そこに至るまでの思考プロセスを共有することで、読者は深い理解を得られます。最初に考えたアプローチ、試した方法、直面した課題、そしてなぜ最終的な解決策にたどり着いたのかを時系列で説明しましょう。失敗したアプローチも含めて正直に共有することで、記事の信頼性が高まり、読者も同じ失敗を避けられます。「最初はAという方法を試みましたが、Bという問題に直面したため、Cというアプローチに切り替えました」といった形で、あなたの試行錯誤のストーリーを語ることで、記事に人間味と深みが加わります。発見と学び - 技術的な発見だけでなく、アプローチ方法についての洞察も含めましょう。「この経験から学んだ最も重要なことは〜です」と明確に示すことで、読者は記事の本質的な価値を理解できます。コードやシステムの改善点だけでなく、問題解決プロセス、チーム協力、技術選定の基準など、より広い文脈での学びを共有すると、記事の応用範囲が広がります。特に、「意外だったのは〜」「常識と違ったのは〜」といった予想外の発見は強調する価値があります。こうした「目から鱗」の瞬間は、読者にとって最も記憶に残る部分となるでしょう。次のステップ - 読者が更に探求できるように、参考資料や発展的な内容へのリンクを提供します。「もっと詳しく知りたい方はこちらの資料がおすすめです」「次のステップとして〜を検討するとよいでしょう」といった形で、読者の学習旅行の次の目的地を示唆しましょう。また、未解決の課題や将来の展望についても正直に触れることで、読者との対話を促すことができます。「現在はまだ〜という課題が残っていますが、今後は〜のアプローチを試してみる予定です」といった形で、完璧な解決策だけでなく、進行中の探究であることを示すと、より現実的で共感を得られる記事になります。読みやすさを高める実践テクニック技術的な内容を伝える際、読みやすさは極めて重要です。以下のテクニックを活用して、読者が最後まで読み進められる記事を目指しましょう。最初の3行で読者を掴む - 記事の冒頭3行は、読者が「続きを読むか」を決める重要な部分です。問題提起や具体的な価値を示し、興味を引く導入を心がけましょう。「この記事を読むと〜ができるようになります」「あなたも経験したことがあるかもしれませんが、〜という問題は実は〜で解決できます」といった書き出しが効果的です。ただし、注意点として、技術ブログでは大言壮語や過度な主張（「これが唯一の正しい方法だ」「これさえ知れば全てが解決する」など）は避けるべきです。断定的な表現は炎上リスクを高め、読者の信頼を損なう恐れがあります。「私の経験では」「この特定の状況では」といった限定的な表現を使い、バランスを保ちましょう。見出しを上手に使う - 大見出しと小見出しで内容を整理し、ざっと見ただけでも内容がつかめる構造にします。見出しは「目次」としての役割を持ち、読者が求める情報に素早くアクセスするための道標となります。見出しには具体的な内容や得られるメリットを含めると、さらに効果的です。例えば「実装方法」よりも「3ステップで実装できるシンプルな方法」の方が読者の興味を引きます。また、見出しの階層構造は3段階程度に抑え、整理された印象を与えましょう。長い文章は小分けに - 長い文章が続くと読者は疲れます。適度に区切って、読者が「ここまで読めた」と小さな達成感を得られるようにします。段落は1つの考えにつき1つにし、3〜5行程度を目安にするとよいでしょう。また、読みやすさを高めるために、箇条書きや番号付きリストを活用して情報を整理しましょう。さらに、重要なポイントには太字や斜体などの強調を適切に使い、視覚的なメリハリをつけることで、スキャンしやすくなります。ただし、強調の使いすぎは逆効果なので、本当に重要な部分だけに留めるのがコツです。コードと説明文のバランス - 長すぎるプログラムコードは避け、重要な部分だけを取り出して、それに説明を加えましょう。コードブロックの前には「何をするコードなのか」、後には「なぜそのように実装したのか」「どのような効果があるのか」を説明すると理解が深まります。また、複雑なコードは徐々に構築していく形で示すと良いでしょう。初めに基本形を示し、段階的に機能を追加していくアプローチは、特に初心者にとって理解しやすい方法です。コメントを適切に挿入することも効果的ですが、コード自体が説明的であることを心がけましょう。具体例と全体像を交互に - 具体的なコード例と、そこから学べる一般的な教訓を交互に示すことで、理解が深まります。「木を見て森も見る」アプローチで、読者は個別の実装詳細と、それがどのように大きな概念に適合するかを同時に理解できます。例えば、特定のパターンの実装例を示した後、「このパターンが特に有効なのは〜のような状況です」と一般化すると、読者は自分の状況への応用がしやすくなります。逆に、原則や概念を先に説明してから具体例で補強する方法も効果的です。両方のアプローチを記事内で使い分けると、多様な学習スタイルの読者に対応できます。視覚的要素を活用する - 複雑な概念や関係性は、文章だけでなく図やダイアグラム、スクリーンショットで説明すると理解が格段に向上します。特に、システムアーキテクチャやデータフロー、アルゴリズムの流れなどは視覚化が効果的です。図は装飾ではなく情報を伝える手段として使い、適切なキャプションを付けることで文脈を明確にしましょう。また、長い記事では適度に図を挿入することで、読者に視覚的な休息も提供できます。図の作成には専門的なツールは必ずしも必要なく、シンプルな図であれば手書きスケッチをスキャンしたものでも十分に価値があります。読者の知識レベルを想定する - 対象とする読者層の知識レベルを想定し、それに合わせた説明の詳しさを調整しましょう。初心者向けの記事では基本概念から丁寧に説明し、上級者向けには深い技術的洞察や最適化のポイントに焦点を当てます。どちらの場合も、前提知識を記事の冒頭で明確にしておくと、読者は自分に適した内容かどうかを判断できます。「この記事はXYZの基本を理解している方を対象としています」といった一文を入れるだけでも効果的です。また、専門用語を使う場合は、初出時に簡単な説明を加えるか、リンクで参照先を示すと親切です。余韻を残す結びで読者の思考を広げる - 優れた技術ブログは、単に情報を伝えるだけでなく、読後に読者の思考を広げるものです。結びのパートでは、説明した技術の将来性や発展の可能性、異なる文脈での応用例などに軽く触れておくと、読者は記事を閉じた後も考え続けるきっかけとなります。「この技術は〜の領域でも応用できるかもしれません」「今回紹介した手法をさらに発展させると、どのような可能性が開けるでしょうか」といった問いかけは、読者の創造性を刺激し、自分なりの解釈や発展を考える余韻をもたらします。また、「私自身はこの技術と出会って、〜という視点が変わりました」のような個人的な洞察や、技術の社会的意義に触れることで、読者に新たな気づきや内省の機会を提供できます。心地よい技術コミュニケーションのために技術ブログを書くとき、単に知識を共有するだけでなく、読み手がどう感じるかに気を配ることも大切です。思慮深いコミュニケーションは、あなたのメッセージをより効果的に伝え、建設的な対話を生み出します。以下の考え方を意識することで、知識共有の質を高め、不要な論争を避けることができるでしょう。読み手の感情を大切にする書いた内容が誰かを傷つけていないか考えてみましょう。「この書き方だと、誰かが自分を批判されていると感じるかも」と想像することが大切です。例えば、ある技術について「この方法は時代遅れだ」と書くより、「私の用途ではこの新しい方法がうまく機能しました」と表現する方が、読み手の心を開いたままにします。技術選択は多くの場合、状況やニーズに依存するものであり、一概に優劣をつけられないことを認識しましょう。好きなものを中心に語るあなたが好きな技術や方法について熱く語りましょう。何かを批判するよりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。「Aは問題だらけだがBは素晴らしい」ではなく、「Bのここが素晴らしい」と伝えるだけで十分です。英語圏でよく使われる「not for me」（これは私には合わない）という表現は、技術ブログでも有効です。これは「悪い」というわけではなく、単に「私の状況や好みには合わない」という意味を含んでいるからです。個人の経験として共有する「すべてのエンジニアは〜すべきだ」「この業界では〜が常識だ」といった広い主語での断言は避けましょう。代わりに「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。それでも強引に批判してくる人はいます。そういう人はそもそもめちゃくちゃに批判したくてその構成が目の前に存在しているからめちゃくちゃに言ってくるのですが、日本語をちゃんと読めない人を相手にする必要はありません。あなたの経験を共有する権利は誰にも奪われないのです。主観的な表現を心がける「これは正しい方法だ」「あれは間違っている」という価値判断ではなく、「私はこの方法が好きです」「私の場合はこちらの方法が合っていました」という表現にすることで、異なる意見の人も受け入れやすくなります。私たちはみな異なる状況で働いており、一つの正解があるわけではないことを認識しましょう。特に技術の世界では、同じ問題に対しても多様なアプローチが存在することを尊重することが重要です。ポジティブな内容を中心に問題点や不満よりも、解決策や学びを中心に書きましょう。ネガティブな内容は同様にネガティブな反応を呼びがちです。「〜が使いにくい」より「こうすると〜がもっと使いやすくなりました」という表現の方が、建設的な対話につながります。あなたが困難を乗り越えた経験は、その過程で学んだことと共に共有することで、より価値のある情報になります。批判を柔らかく伝える工夫どうしても批判的な内容を書く必要があるときは、批判の対象をぼかしたり、自分の失敗談を交えたりすることで、攻撃的に見えるのを避けられます。「私も以前は〜と思っていましたが、実際にやってみると〜だとわかりました」といった表現なら、相手の反感を買いにくくなります。また、批判する際も建設的な代替案を提示することで、単なる不満ではなく有益なフィードバックとして受け取られやすくなります。背景情報を丁寧に説明する「これはこういう状況での話です」「私はこういう前提で考えています」と背景を明確にすることで、誤解を防げます。普通に人と喋っている時は省略するかもしれない文脈の紹介も技術ブログを書く時には必要です。誤読する余地を可能な限り減らします。特に技術的な主張をするときは、あなたの環境や条件を明示することで、「それは特定の状況下での話だね」と理解してもらいやすくなります。使用しているハードウェア、ソフトウェアのバージョン、チームの規模、プロジェクトの性質など、具体的な情報を提供することで、読者はあなたの経験を適切に文脈化できます。もし反発を受けたときの心構えどれだけ配慮して書いても、時には予想外の反応を受けることがあります。インターネット上での議論は時に感情的になりがちです。正直なところ、批判されたときの最初の感情は「なんでこんなこと言われなきゃいけないんだ」という怒りや落胆でしょう。そんな感情は自然なものですし、一時的に落ち込んだり、イラっとしたりするのも当然です。でも、そんなときに役立つ考え方をいくつか紹介します。人気記事には批判も付きもの多くの人に読まれるブログには、様々な価値観を持つ人が訪れます。あなたの意図とは関係なく、一定数の批判的なコメントが寄せられるのは自然なことです。人気の証と考えて、あまり気にしすぎないようにしましょう。実際、最も影響力のある技術記事でさえ、必ず反対意見や批判があります。これは多様な視点が存在することの健全な証でもあります。反応せずに見守る勇気を持つ批判的なコメントを見ると、すぐに反論したくなるものです。正直に言えば、「このバカ！ちゃんと記事を読め！」と思うこともあるでしょう。そんな感情を持つのは自然なことです。しかし、インターネット上での議論は感情的になりやすく、さらなる誤解を生むことも。多くの場合、反応しないことが最も賢明な選択です。キーボードから離れて深呼吸し、「本当に返信する価値があるか」を冷静に考えてみましょう。時間が経てば自然と収まることが多いものです。たまには筆を折って、「今日はもうネットを見ない日」を作るのも立派な対処法です。コメントの背景を想像してみる批判的なコメントを残す人の他の発言を見てみると、多くの場合、その人自身の傾向が見えてきます。常に批判的なコメントを残している人もいれば、特定のトピックに強い感情を持っている人もいます。「これはその人の反応パターンなのだ」と理解すれば、個人的な攻撃と受け取らずに済みます。時には「この人、今日はどうしたんだろう？仕事で嫌なことでもあったのかな？」と想像してみるのも手です。多くの批判的コメントは、あなたの記事そのものよりも、コメントした人のその日の気分や状況から生まれていることもあるのです。批判的なコメントをパブリックな場に書く人のほとんどは想像力が欠如しているのでその言葉で他人が傷つくということをほとんど何も考えていないです。実際に会うと優しかったりもします。でも、親切にスルーすることが、時には最大の優しさかもしれません。誤解には丁寧な補足を明らかな誤解に基づいた批判が多い場合は、記事に追記や修正を加えるのが効果的です。「追記：いくつかコメントをいただき、この点が誤解を招いているようなので補足します」といった形で、丁寧に説明すると良いでしょう。個別のコメントに反論するよりも、記事自体を改善する方が建設的です。これは読者全体にとっても価値があり、あなた自身の成長にもつながります。時間の流れを味方にするインターネット上の話題は移り変わりが早いものです。今日の論争も、明日には忘れられていることがほとんどです。一時的な批判に過度に反応するよりも、次の記事作成に前向きに取り組む方が、長期的には実りある選択となるでしょう。実際に「nwiizoさんの記事は役に立ちました」と声をかけられることはあっても、「お前の記事はクソだぞ」と直接言ってくる人は珍しいものです(私もそれぐらい強烈な論を発したいものです)。批判は匿名の場で、称賛は直接あなたに届くという不思議な法則があります。そして、真っ当な批判からは学び、感情的な批判は「私はそれだけの反応を引き出せるだけの影響力を持っているんだ」と前向きに捉える余裕を持ちましょう。ブログ公開の場の選択ブログを書く場所の選択は、思っているより重要な決断です。それぞれの場には一長一短があり、あなたの目的によって最適な選択肢は異なります。技術特化型プラットフォーム技術者向けのプラットフォームは、すでに技術に興味のある読者が集まっているという利点があります。初めから技術的な話題を求めている読者にリーチしやすく、専門的な議論が生まれやすい環境です。一方で、プラットフォームのルールやコミュニティの雰囲気に合わせる必要があり、自由度はやや制限されます。また、特定の技術コミュニティでは賛否両論が起きやすいトピックもあります。汎用ブログプラットフォームより幅広い読者層にアクセスできる汎用プラットフォームは、技術と非技術の境界領域の話題に適しています。テクニカルな内容を非エンジニアに伝えたい場合や、キャリアや働き方など、技術に付随する話題を扱いたい場合に向いています。ただし、深く技術的な内容は響く読者が少なく、反応が薄くなる可能性もあります。自前のブログ自分のドメインで運用するブログは、完全な自由度とブランディングの利点があります。長期的に見れば最も資産価値が高く、あなたのキャリアと共に育てていけるものになります。しかし、読者を集めるための工夫や継続的なメンテナンスが必要で、特に始めたばかりの頃は「誰も読んでいない」という状況に直面することも。SEO対策やSNSでの拡散など、追加の努力が求められます。プラットフォーム選びのアドバイス最初は低いハードルで始められる技術特化型プラットフォームでスタートし、書く習慣が身についてきたら自前のブログも並行して運用するというアプローチが現実的です。どのプラットフォームを選ぶにしても、コンテンツの所有権やエクスポート機能について確認しておくことをお勧めします。いつか別の場所に移行したいと思ったとき、あなたの資産を持ち出せるかどうかは重要な要素です。継続のための現実的なアプローチ技術ブログを一度書くことは難しくない。難しいのは書き続けることだ。以下は実践的な継続のコツだ。小さなハードルから始めるブログ執筆を習慣化するには、負荷を最小限に抑えることが重要です。月1回、あるいは四半期に1回といった現実的な頻度設定から始めましょう。15分でも執筆時間を確保できれば、少しずつ文章は成長していきます。無理な目標設定はモチベーションを消耗させるだけです。自分のための記録として書く「誰も読まないかもしれない」という恐れは、「自分のための記録」という視点で克服できます。将来の自分が参照するための記録として書けば、読者がゼロでも価値があります。実際、多くの技術ブログは、書き手自身が後日参照することで最大の価値を発揮します。「十分に良い」の基準を持つ完璧主義はブログ執筆の最大の敵です。「もっと調査が必要」「もっと洗練された文章にしたい」という思いは尽きませんが、公開されない記事に価値はありません。80%の完成度で公開する勇気を持ちましょう。改善はいつでもできます。このブログも80％ぐらいの完成度で公開してます(本当に)。終わりに技術の世界では、私たちは常に何かの「初心者」であり続けます。むしろ「初心者」であるべきです。新しい言語、新しいフレームワーク、新しいパラダイム—学びに終わりはありません。ベテランエンジニアでさえ、新技術の前では「初心者」に戻るのです。だからこそ、どの経験レベルの視点も価値があります。思い出してみてください。あなたが最初にプログラミングを学んだ時の興奮を。新しいフレームワークに触れた時の発見の喜びを。バグを解決した時の達成感を。これらはすべて、記録する価値のある体験です。そして、どの瞬間においても、あなたの「今」の視点は誰かにとって貴重な道標になります。完璧なブログではなく、あなたの観察と経験を率直に記録したブログこそが、同じ道を歩む誰かの力になるのです。いま書き始めることで、あなたは単なる技術の消費者から、コミュニティに貢献する創造者へと変わることができます。ブログは、知識の完成形を示すものではなく、思考の過程を記録するものです。あなたの躓きと発見の記録が、誰かの旅路を照らす灯になるでしょう。そして、その灯は時間が経っても消えることなく、未来の誰かを導き続けます。書くことで得られるのは、他者への貢献だけではありません。自分自身の思考を整理し、知識を定着させ、キャリアを形作っていく力にもなります。数年後、あなたが書いた記事の蓄積を振り返った時、そこには自分の成長の軌跡が鮮明に記録されているでしょう。継続のコツは「完璧を目指さない」ことです。まずは短く、1回15分でも書ける小さなテーマから始めましょう。また、定期的に書く習慣をつけるために、特定の曜日や時間帯を決めておくと効果的です。そして何より、自分自身が「書いていて楽しい」と感じられるトピックを選ぶことが長続きの秘訣です。技術ブログの世界では、読者からのフィードバックが得られることも大きな魅力です。あなたの記事に寄せられたコメントや質問から、新たな気づきを得ることもあるでしょう。それは、一人では辿り着けなかった視点や解決策との出会いかもしれません。今日から始めてみませんか？ 最初は小さな記事でいいのです。今週解決した問題について、新しく学んだツールの使い方、チームでの取り組みから得た気づき、読んだ技術書の要点と感想、あなたのチームが採用している開発プロセス、先輩から学んだテクニックなど、あなたの日常には書くべき価値のあるトピックがきっと溢れています。あなたの最初の記事は、誰かの最初の一歩を助ける光となるかもしれません。そして、書き続けることで、あなた自身も技術の世界でより深く、より遠くまで進んでいけるでしょう。書き始めることに価値があります。あなただけの観察眼で捉えた技術の風景を、今日から記録してみませんか。その一歩が、あなたのキャリアと技術コミュニティの未来を、より豊かなものにするはずです。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—これが、技術ブログの本当の姿だと思っています。さあ、あなたの最初の記事を、今週ぐらいに書いてみませんか？プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon質の良い火種を作る技術ブログを書く目的の一つに「発信力を高めたい」「影響力のある記事を書きたい」というものがあるでしょう。しかし、「バズらせよう」と意気込むほど空回りする行為はありません。バズる記事とは、戦略的に作られるものではなく、適切な「火種」が適切なタイミングで適切な場所に置かれたときに自然発生するものです。結局のところ、あなたが準備できるのは質の高い「火種」だけであり、それが燃え広がるかどうかは環境次第なのです。業界の動向、読者の関心事、時事的な話題、さらには投稿のタイミングや共有されるコミュニティの特性など、あなたがコントロールできない無数の要素が絡み合って「バズる」という現象は生まれます。同じ質の記事でも、ある日には大きな反響を呼び、別の日には静かに過ぎ去ることもあるのです。バズる記事の共通点は、特定のコミュニティの「今」の関心事に、新しい視点や価値ある情報を提供していることです。技術界隈で議論されている問題に、あなたならではの経験や洞察を加えることで、思わぬ反響を得ることがあります。重要なのは、炎上を狙った挑発的な内容ではなく、真摯に問題と向き合い、建設的な意見を提供することです。最も価値あるブログ記事は、実はバズを追いかけずに書かれたものです。「自分が本当に伝えたいこと」「自分が解決するのに苦労した問題」について誠実に書いた記事こそ、長期的に多くの人の役に立ち続けます。そして皮肉なことに、そういった記事が数年後に「古典的名記事」として再評価され、改めて大きな反響を呼ぶことも少なくありません。バズを目的とした記事は一過性の注目を集めても、すぐに忘れられます。一方、誠実に書かれた記事は、検索エンジンを通じて長期間にわたり、その問題で悩む人々に届き続けます。一時的な注目より、長期的な価値を持つ記事を書くことに焦点を当てましょう。そして覚えておいてください—あなたの役割は質の高い火種を用意することだけで、それがどう広がるかは、時に予測不能な「環境」が決めるものなのです。本気(マジ)の話これは本気で言っているのですが今回は流石にめちゃくちゃに良いブログだと思うので欲しいものリストを公開します。www.amazon.jp","isoDate":"2025-03-30T18:44:20.000Z","dateMiliSeconds":1743360260000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rust製MCPライブラリのサンプルコードから学ぶ活用法","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800","contentSnippet":"はじめに前回の「Rust製MCPライブラリの内部実装を徹底解析」では、Model Context Protocol (MCP) のRust SDKの内部実装について詳しく解説しました。今回は、その続編として、examples/ディレクトリに含まれるサンプルコードを詳しく見ていきます。github.comMCPを実際のプロジェクトで活用するためには、抽象的な実装だけでなく、具体的な使用例を理解することが重要です。このブログでは、クライアント実装、サーバー実装、マクロの使用例を通じて、MCPの実践的な活用方法を学び、実際に自分で実装できるようになることを目指します。概念が分からない人や自分の他のブログを読みたいくない人はこちらのドキュメントを一読してから読んでほしいです。modelcontextprotocol.ioexamples/の全体構造MCPのRust SDKには豊富なサンプルが含まれています。examples/ディレクトリは以下のような構成になっています。examples/├── clients/        # クライアント実装例├── servers/        # サーバー実装例├── transport/      # トランスポート実装例├── rig-integration/ # Rigフレームワークとの統合例├── wasi/           # WebAssembly実装例└── README.md       # サンプルの概要それぞれのディレクトリには、特定のユースケースに焦点を当てたサンプルコードが含まれています。これらのサンプルは、MCPの様々な機能や統合シナリオを理解するのに役立ちます。クライアント実装例examples/clients/ディレクトリには、MCPクライアントの様々な実装例が含まれています。これらの例を通じて、異なるシナリオでのMCPクライアントの使い方を学びましょう。基本的なクライアント実装: std_io.rs最も基本的なクライアント実装例はstd_io.rsです。このサンプルは標準入出力を使用してMCPサーバーと通信します。use anyhow::Result;use rmcp::{model::CallToolRequestParam, service::ServiceExt, transport::TokioChildProcess};use tokio::process::Command;use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -\u003e Result\u003c()\u003e {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!(\"info,{}=debug\", env!(\"CARGO_CRATE_NAME\")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();        // 子プロセスとしてMCPサーバーを起動し、サービスを作成    let service = ()        .serve(TokioChildProcess::new(            Command::new(\"uvx\").arg(\"mcp-server-git\"),        )?)        .await?;    // サーバー情報の取得    let server_info = service.peer_info();    tracing::info!(\"Connected to server: {server_info:#?}\");    // 利用可能なツールの一覧取得    let tools = service.list_tools(Default::default()).await?;    tracing::info!(\"Available tools: {tools:#?}\");    // ツールの呼び出し    let tool_result = service        .call_tool(CallToolRequestParam {            name: \"git_status\".into(),            arguments: serde_json::json!({ \"repo_path\": \".\" }).as_object().cloned(),        })        .await?;    tracing::info!(\"Tool result: {tool_result:#?}\");        // クライアントの終了    service.cancel().await?;    Ok(())}この例での主要な要素を解説します。#[tokio::main]マクロ: Rustの非同期ランタイムを初期化し、非同期コードを実行できるようにします。TokioChildProcess: 子プロセスとしてMCPサーバーを起動するためのトランスポート実装です。この例では「uvx mcp-server-git」コマンドを実行しています。serveメソッド: トランスポートを使ってサービスを初期化するメソッドです。RustのServiceExtトレイトが提供する拡張機能です。call_toolメソッド: 特定のツールを呼び出すメソッドです。CallToolRequestParam構造体を使ってツール名と引数を指定します。SSEトランスポートの使用: sse.rs次に、Server-Sent Events (SSE) トランスポートを使用する例を見てみましょう。これはWebアプリケーションとMCPを統合する際に特に有用です。use anyhow::Result;use rmcp::model::{ClientCapabilities, ClientInfo, Implementation};use rmcp::{ServiceExt, model::CallToolRequestParam, transport::SseTransport};use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -\u003e Result\u003c()\u003e {    // ロギングの初期化（省略）...    // SSEトランスポートの作成と接続    let transport = SseTransport::start(\"http://localhost:8000/sse\").await?;        // クライアント情報の定義    let client_info = ClientInfo {        protocol_version: Default::default(),        capabilities: ClientCapabilities::default(),        client_info: Implementation {            name: \"test sse client\".to_string(),            version: \"0.0.1\".to_string(),        },    };        // クライアントの作成    let client = client_info.serve(transport).await?;    // サーバー情報の取得    let server_info = client.peer_info();    tracing::info!(\"Connected to server: {server_info:#?}\");    // ツール一覧の取得（省略）...    // ツールの呼び出し（省略）...        // クライアントの終了    client.cancel().await?;    Ok(())}このサンプルの特徴的な点は：SseTransport: HTTP経由でMCPサーバーと通信するためのトランスポート実装です。長時間接続を維持し、サーバーからのイベントを受信します。ClientInfo: クライアントに関する情報をサーバーに提供する構造体です。名前やバージョン、プロトコル互換性などの情報が含まれます。複数クライアントの管理: collection.rs複数のMCPクライアントを効率的に管理する例も含まれています。use std::collections::HashMap;use anyhow::Result;use rmcp::service::ServiceExt;use rmcp::{model::CallToolRequestParam, transport::TokioChildProcess};use tokio::process::Command;#[tokio::main]async fn main() -\u003e Result\u003c()\u003e {    // ログ初期化は省略...    // 複数クライアントの作成    let mut client_list = HashMap::new();    for idx in 0..10 {        let service = ()            .into_dyn()            .serve(TokioChildProcess::new(                Command::new(\"uvx\").arg(\"mcp-server-git\"),            )?)            .await?;        client_list.insert(idx, service);    }    // 各クライアントの使用    for (_, service) in client_list.iter() {        // サーバー情報の取得        let _server_info = service.peer_info();        // ツール一覧の取得        let _tools = service.list_tools(Default::default()).await?;        // ツールの呼び出し        let _tool_result = service            .call_tool(CallToolRequestParam {                name: \"git_status\".into(),                arguments: serde_json::json!({ \"repo_path\": \".\" }).as_object().cloned(),            })            .await?;    }        // クライアントのクリーンアップ    for (_, service) in client_list {        service.cancel().await?;    }    Ok(())}この例では、複数のMCPクライアントを作成し、それぞれに対して操作を実行しています。実際のアプリケーションでは、異なるサーバーに接続する複数のクライアントを管理する場合に役立ちます。サーバー実装例examples/servers/ディレクトリには、様々なMCPサーバー実装例が含まれています。ここでは、基本的なサーバー実装と、Webフレームワークとの統合例を見ていきます。基本的なサーバー実装: std_io.rs最もシンプルなサーバー実装はstd_io.rsです。このサンプルは、標準入出力を使用してクライアントとやり取りする基本的なMCPサーバーを実装しています。use anyhow::Result;use common::counter::Counter;use rmcp::{ServiceExt, transport::stdio};use tracing_subscriber::{self, EnvFilter};mod common;#[tokio::main]async fn main() -\u003e Result\u003c()\u003e {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()))        .with_writer(std::io::stderr)        .with_ansi(false)        .init();    tracing::info!(\"Starting MCP server\");    // Counterサービスを作成し、標準入出力トランスポートで提供    let service = Counter::new().serve(stdio()).await?;    // クライアントからの要求を待機    service.waiting().await?;    Ok(())}このサンプルはシンプルですが、重要な要素がいくつか含まれています。Counter型: これはカウンターサービスを提供するサーバーハンドラの実装です。stdio(): 標準入出力をトランスポートとして使用するための関数です。waiting()メソッド: サーバーがクライアントからの要求を待機するためのメソッドです。次に、Counter型の実装を見てみましょう：use std::sync::Arc;use rmcp::{    Error as McpError, RoleServer, ServerHandler, const_string, model::*, schemars,    service::RequestContext, tool,};use tokio::sync::Mutex;#[derive(Clone)]pub struct Counter {    counter: Arc\u003cMutex\u003ci32\u003e\u003e,}#[tool(tool_box)]impl Counter {    pub fn new() -\u003e Self {        Self {            counter: Arc::new(Mutex::new(0)),        }    }    #[tool(description = \"Increment the counter by 1\")]    async fn increment(\u0026self) -\u003e Result\u003cCallToolResult, McpError\u003e {        let mut counter = self.counter.lock().await;        *counter += 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = \"Decrement the counter by 1\")]    async fn decrement(\u0026self) -\u003e Result\u003cCallToolResult, McpError\u003e {        let mut counter = self.counter.lock().await;        *counter -= 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = \"Get the current counter value\")]    async fn get_value(\u0026self) -\u003e Result\u003cCallToolResult, McpError\u003e {        let counter = self.counter.lock().await;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }}#[tool(tool_box)]impl ServerHandler for Counter {    fn get_info(\u0026self) -\u003e ServerInfo {        ServerInfo {            protocol_version: ProtocolVersion::V_2024_11_05,            capabilities: ServerCapabilities::builder()                .enable_tools()                .build(),            server_info: Implementation::from_build_env(),            instructions: Some(\"This server provides a counter tool...\".to_string()),        }    }        // その他の実装は省略...}このCounter実装の重要な点：#[tool(tool_box)]マクロ: これは、メソッドを自動的にMCPツールとして登録するマクロです。これにより、ボイラープレートコードが大幅に削減されます。#[tool(description = \"...\")]マクロ: 各メソッドにツールの説明を追加します。この情報はクライアントに公開され、ツールの使用方法を理解するのに役立ちます。Arc\u003cMutex\u003ci32\u003e\u003e: スレッド間で安全にカウンター値を共有するためのラッパーです。これは、Rustの並行性プリミティブの典型的な使用例です。Axumフレームワークとの統合: axum.rsより高度な例として、Axum WebフレームワークとMCPサーバーを統合した例を見てみましょう。use rmcp::transport::sse_server::SseServer;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};mod common;use common::counter::Counter;const BIND_ADDRESS: \u0026str = \"127.0.0.1:8000\";#[tokio::main]async fn main() -\u003e anyhow::Result\u003c()\u003e {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| \"debug\".to_string().into()),        )        .with(tracing_subscriber::fmt::layer())        .init();    // SSEサーバーの起動とカウンターサービスの設定    let ct = SseServer::serve(BIND_ADDRESS.parse()?)        .await?        .with_service(Counter::new);    // Ctrl+Cで終了するまで待機    tokio::signal::ctrl_c().await?;    ct.cancel();    Ok(())}このサンプルの特徴的な点：SseServer::serve: AxumフレームワークをベースにしたSSEサーバーを起動する関数です。これにより、ブラウザからMCPサーバーにアクセスできるようになります。with_service: サービスファクトリを指定するメソッドです。この例ではCounter::new関数をファクトリとして使用しています。tokio::signal::ctrl_c().await?: Ctrl+Cシグナルを受け取るまで待機します。これにより、サーバーはバックグラウンドで動作し続けます。Webフレームワーク統合のポイントWebフレームワーク（Axum、Actix Webなど）とMCPを統合する際のポイント：適切なトランスポート（SSEなど）を選択するセッション管理を適切に行うエラーハンドリングを丁寧に実装するサーバーのライフサイクルを適切に管理するマクロ使用例examples/macros/ディレクトリには、MCPマクロを使用してツールを簡単に定義する例が含まれています。これらのマクロは、ボイラープレートコードを大幅に削減し、MCPサーバーの実装を容易にします。計算機ツールの実装calculator.rsは、#[tool]マクロを使用して計算機ツールを実装する例です。use mcp_core::handler::{ToolError, ToolHandler};use mcp_macros::tool;#[tool(    name = \"calculator\",    description = \"Perform basic arithmetic operations\",    params(        x = \"First number in the calculation\",        y = \"Second number in the calculation\",        operation = \"The operation to perform (add, subtract, multiply, divide)\"    ))]async fn calculator(x: i32, y: i32, operation: String) -\u003e Result\u003ci32, ToolError\u003e {    match operation.as_str() {        \"add\" =\u003e Ok(x + y),        \"subtract\" =\u003e Ok(x - y),        \"multiply\" =\u003e Ok(x * y),        \"divide\" =\u003e {            if y == 0 {                Err(ToolError::ExecutionError(\"Division by zero\".into()))            } else {                Ok(x / y)            }        }        _ =\u003e Err(ToolError::InvalidParameters(format!(            \"Unknown operation: {}\",            operation        ))),    }}#[tokio::main]async fn main() -\u003e std::result::Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {    // ツールのインスタンスを作成    let calculator = Calculator;    // ツール情報の出力    println!(\"Tool name: {}\", calculator.name());    println!(\"Tool description: {}\", calculator.description());    println!(\"Tool schema: {}\", calculator.schema());    // サンプル入力でツールをテスト    let input = serde_json::json!({        \"x\": 5,        \"y\": 3,        \"operation\": \"multiply\"    });    let result = calculator.call(input).await?;    println!(\"Result: {}\", result);    Ok(())}このサンプルの素晴らしい点：宣言的なツール定義: #[tool]マクロを使うことで、通常の関数にメタデータを追加するだけでMCPツールを定義できます。パラメータドキュメント: params(x = \"First number...\")のように、パラメータの説明をマクロ内で定義できます。これにより、自己文書化されたAPIが作成されます。型安全: 関数の引数型（i32, Stringなど）を利用して型安全なパラメータを定義します。Rustのコンパイラが型チェックを行うため、型関連のバグを防ぐことができます。マクロの活用術マクロを効果的に使用するためのポイント：適切な名前と説明を提供して、ツールの目的を明確にするパラメータに詳細な説明を追加して、ユーザーが正しい値を入力できるようにする複雑なパラメータには構造体を使用し、#[tool(aggr)]アノテーションで集約するエラーハンドリングを丁寧に行い、具体的なエラーメッセージを提供するトランスポート実装例examples/transport/ディレクトリには、様々なトランスポート実装例が含まれています。トランスポートは、MCPクライアントとサーバーの通信方法を定義します。TCPトランスポートtcp.rsは、TCP接続を使用してMCPメッセージを送受信する例です。use common::calculator::Calculator;use rmcp::{serve_client, serve_server};mod common;#[tokio::main]async fn main() -\u003e anyhow::Result\u003c()\u003e {    tokio::spawn(server());    client().await?;    Ok(())}async fn server() -\u003e anyhow::Result\u003c()\u003e {    let tcp_listener = tokio::net::TcpListener::bind(\"127.0.0.1:8001\").await?;    while let Ok((stream, _)) = tcp_listener.accept().await {        tokio::spawn(async move {            let server = serve_server(Calculator, stream).await?;            server.waiting().await?;            anyhow::Ok(())        });    }    Ok(())}async fn client() -\u003e anyhow::Result\u003c()\u003e {    let stream = tokio::net::TcpSocket::new_v4()?        .connect(\"127.0.0.1:8001\".parse()?)        .await?;    let client = serve_client((), stream).await?;    let tools = client.peer().list_tools(Default::default()).await?;    println!(\"{:?}\", tools);    Ok(())}このサンプルでは：非同期I/O: tokioの非同期I/O機能を使用して、ブロッキングせずに複数の接続を処理します。serve_serverとserve_client: これらは便利なヘルパー関数で、トランスポートをサーバーまたはクライアントとして設定します。並行接続処理: tokio::spawnを使って各接続を別々のタスクで処理し、サーバーのスケーラビリティを確保しています。WebSocketトランスポートwebsocket.rsは、WebSocket接続を使用したMCPトランスポートの例です。async fn http_client(uri: \u0026str) -\u003e anyhow::Result\u003cRunningService\u003cRoleClient, ()\u003e\u003e {    let (stream, response) = tokio_tungstenite::connect_async(uri).await?;    if response.status() != tungstenite::http::StatusCode::SWITCHING_PROTOCOLS {        return Err(anyhow::anyhow!(\"failed to upgrade connection\"));    }    let transport = WebsocketTransport::new_client(stream);    let client = ().serve(transport).await?;    Ok(client)}async fn start_server() -\u003e anyhow::Result\u003c()\u003e {    let tcp_listener = tokio::net::TcpListener::bind(\"127.0.0.1:8001\").await?;    tokio::spawn(async move {        while let Ok((stream, addr)) = tcp_listener.accept().await {            tracing::info!(\"accepted connection from: {}\", addr);            tokio::spawn(async move {                let ws_stream = tokio_tungstenite::accept_async(stream).await?;                let transport = WebsocketTransport::new_server(ws_stream);                let server = Calculator.serve(transport).await?;                server.waiting().await?;                Ok::\u003c(), anyhow::Error\u003e(())            });        }    });    Ok(())}このサンプルでは：WebSocketプロトコル: HTTPからWebSocketにアップグレードする処理が含まれています。カスタムトランスポート実装: WebsocketTransportとしてカスタムトランスポートが実装されています。接続管理: 接続の確立からサーバー待機までの一連のフローが示されています。トランスポート選択のポイント適切なトランスポートを選択するためのポイント：用途に合わせて選択する:標準入出力（stdio）: コマンドラインツールや子プロセスSSE: Webブラウザとのリアルタイム通信TCP: ネットワーク上のサービス間通信WebSocket: 双方向リアルタイム通信Unix Socket: 同一マシン上のプロセス間通信セキュリティを考慮する: 公開ネットワークで使用する場合はTLSなどの暗号化を検討パフォーマンスを考慮する: 大量のデータや頻繁な通信がある場合は効率的なトランスポートを選択応用パターンとベストプラクティスMCPを実装する際の応用パターンとベストプラクティスをいくつか紹介します。エラーハンドリング具体的なエラーメッセージ: クライアントが問題を理解できるよう、具体的なエラーメッセージを提供します。   Err(ToolError::InvalidParameters(format!(       \"Unknown operation: {}. Supported operations are: add, subtract, multiply, divide\",       operation   )))エラー変換: 低レベルエラーを適切なMCPエラーに変換します。   async fn read_file(\u0026self, path: String) -\u003e Result\u003cCallToolResult, McpError\u003e {       let content = tokio::fs::read_to_string(path)           .await           .map_err(|e| McpError::tool_execution_error(               \"file_read_error\",               Some(serde_json::json!({ \"error\": e.to_string() }))           ))?;              Ok(CallToolResult::success(vec![Content::text(content)]))   }非同期処理適切なタスク管理: 長時間実行される処理は別タスクに分離し、クライアントをブロックしないようにします。   #[tool(description = \"Run a long process\")]   async fn run_long_process(\u0026self) -\u003e Result\u003cCallToolResult, McpError\u003e {       // 別タスクでバックグラウンド処理を開始       let task_id = self.start_background_task().await?;              // タスクIDを即座に返す       Ok(CallToolResult::success(vec![Content::text(format!(           \"Task started with ID: {}\", task_id       ))]))   }      // 別のツールでタスク状態を確認できるようにする   #[tool(description = \"Check task status\")]   async fn check_task_status(\u0026self, #[tool(param)] task_id: String) -\u003e Result\u003cCallToolResult, McpError\u003e {       // ...   }タイムアウト管理: 長時間の操作にはタイムアウトを設定します。   let result = tokio::time::timeout(       Duration::from_secs(30),       some_long_operation()   ).await.map_err(|_| McpError::tool_execution_error(       \"operation_timeout\",       Some(serde_json::json!({\"message\": \"Operation timed out after 30 seconds\"}))   ))??;リソース管理共有状態の適切な管理: Arc\u003cMutex\u003cT\u003e\u003eやArc\u003cRwLock\u003cT\u003e\u003eを使用して、スレッド間で状態を安全に共有します。リソースのクリーンアップ: Dropトレイトを実装して、リソースが確実に解放されるようにします。コネクション管理: クライアント接続を適切に管理し、リソースリークを防ぎます。実際の使用例：LLMとの統合MCPはLLM（大規模言語モデル）に外部ツールへのアクセスを提供するために設計されています。ここでは、LLMとMCPの統合例を見てみましょう。examples/rig-integration/ディレクトリには、Rigフレームワーク（LLMアプリケーションフレームワーク）とMCPの統合例が含まれています。// MCPツールをRigのツールとして適応させるアダプタpub struct McpToolAdaptor {    tool: McpTool,    server: ServerSink,}impl RigTool for McpToolAdaptor {    fn name(\u0026self) -\u003e String {        self.tool.name.to_string()    }    fn definition(        \u0026self,        _prompt: String,    ) -\u003e std::pin::Pin\u003cBox\u003cdyn Future\u003cOutput = rig::completion::ToolDefinition\u003e + Send + Sync + '_\u003e\u003e    {        Box::pin(std::future::ready(rig::completion::ToolDefinition {            name: self.name(),            description: self.tool.description.to_string(),            parameters: self.tool.schema_as_json_value(),        }))    }    fn call(        \u0026self,        args: String,    ) -\u003e std::pin::Pin\u003c        Box\u003cdyn Future\u003cOutput = Result\u003cString, rig::tool::ToolError\u003e\u003e + Send + Sync + '_\u003e,    \u003e {        let server = self.server.clone();        Box::pin(async move {            let call_mcp_tool_result = server                .call_tool(CallToolRequestParam {                    name: self.tool.name.clone(),                    arguments: serde_json::from_str(\u0026args)                        .map_err(rig::tool::ToolError::JsonError)?,                })                .await                .map_err(|e| rig::tool::ToolError::ToolCallError(Box::new(e)))?;            Ok(convert_mcp_call_tool_result_to_string(call_mcp_tool_result))        })    }}このアダプタは、MCPツールをRigフレームワークのツールとして使用できるようにします。これにより、LLMとMCPサーバーをシームレスに統合することができます。WASI (WebAssembly System Interface) 対応examples/wasi/ディレクトリには、WebAssemblyでMCPサーバーを実装する例が含まれています。これにより、ブラウザやエッジコンピューティング環境でMCPサーバーを実行できます。// wasi/src/lib.rsstruct TokioCliRunner;impl wasi::exports::cli::run::Guest for TokioCliRunner {    fn run() -\u003e Result\u003c(), ()\u003e {        let rt = tokio::runtime::Builder::new_current_thread()            .enable_all()            .build()            .unwrap();        rt.block_on(async move {            tracing_subscriber::fmt()                .with_env_filter(                    EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()),                )                .with_writer(std::io::stderr)                .with_ansi(false)                .init();            let server = calculator::Calculator.serve(wasi_io()).await.unwrap();            server.waiting().await.unwrap();        });        Ok(())    }}wasi::cli::command::export!(TokioCliRunner);WASI環境でMCPサーバーを実行することで、セキュリティやポータビリティが向上し、より多くの環境でMCPを活用できるようになります。まとめMCPのRust SDKには、様々なユースケースに対応するための豊富なサンプルコードが含まれています。これらのサンプルを理解し、実際に試すことで、MCPを活用したアプリケーションの開発スキルを向上させることができます。この記事でカバーした主なポイント：クライアント実装: 基本的なクライアント、SSEトランスポートの使用、複数クライアントの管理サーバー実装: 基本的なサーバー、ツールボックスとマクロの活用、Webフレームワークとの統合トランスポート実装: TCP、WebSocket、Unix Socketなどの様々なトランスポート応用パターン: エラーハンドリング、非同期処理、リソース管理のベストプラクティスLLM統合: Rigフレームワークを使ったLLMとMCPの統合例MCPはまだ比較的新しいプロトコルですが、AIとツールの統合に関する標準化に大きな可能性を秘めています。Rustの強力な型システムと安全性の恩恵を受けながら、MCPの機能を最大限に活用しましょう。生成AIについて興味があればこちらも読んでみてもらいたいです。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon","isoDate":"2025-03-28T04:28:00.000Z","dateMiliSeconds":1743136080000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rust製MCPライブラリの内部実装を徹底解析","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602","contentSnippet":"はじめに最近注目を集めているModel Context Protocol（MCP）は、大規模言語モデル（LLM）に外部ツールやサービスへのアクセス能力を提供するための標準プロトコルです。中でも公式が提供しているRust SDKはあまり注目されていませんが、私自身が必要としているためこのドキュメントを作成します。github.com以前は自前で実装していましたが、公式SDKが公開されたことでそちらを検討するのが良いと考えました。私の実装と比較してかなり洗練されている点が多く、多くの学びを得ることができました。syu-m-5151.hatenablog.comこの記事では、MCP Rust SDKの内部実装を深掘りし、どのようにRustの強力な型システムと非同期プログラミングモデルが活用されているかを解説します。コードの詳細な分析を通して、Rustの優れた設計パターンや実装テクニックを学びましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれるのもありがたいです。MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月27日 現在)。ちなみに今後MCPがどうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioSDKの全体構成 - 明確な関心の分離MCP Rust SDKは、複数のクレートに明確に分離されており、それぞれが特定の責任を担っています。rust-sdk/├── crates/│   ├── mcp-core/      # プロトコルの基本型とインターフェース│   ├── mcp-client/    # クライアント実装│   ├── mcp-server/    # サーバー実装│   └── mcp-macros/    # ツール実装を簡素化するマクロ└── examples/    ├── clients/       # クライアント使用例    ├── servers/       # サーバー実装例    └── macros/        # マクロ使用例この設計はRustエコシステムでよく見られる「関心の分離」パターンに従っています。各クレートがひとつの責任を持ち、依存関係も明確です。こうすることで、メンテナンス性と再利用性が大幅に向上します。特に注目すべきは、コア型定義とプロトコル実装をmcp-coreに分離している点です。これにより、クライアントとサーバーが共通の型定義を使いながら、それぞれ独立して実装・進化できる柔軟性を確保しています。mcp-core: 堅牢な基盤となる型定義mcp-coreクレートは、MCPプロトコルの心臓部とも言える基本型とインターフェースを提供しています。ここでの実装がSDK全体の品質を大きく左右します。JSON-RPCメッセージの巧妙な実装MCPはJSON-RPCプロトコルをベースにしていますが、その実装が非常に興味深いものになっています#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]#[serde(untagged, try_from = \"JsonRpcRaw\")]pub enum JsonRpcMessage {    Request(JsonRpcRequest),    Response(JsonRpcResponse),    Notification(JsonRpcNotification),    Error(JsonRpcError),    Nil, // used to respond to notifications}#[derive(Debug, Serialize, Deserialize)]struct JsonRpcRaw {    jsonrpc: String,    #[serde(skip_serializing_if = \"Option::is_none\")]    id: Option\u003cu64\u003e,    #[serde(skip_serializing_if = \"Option::is_none\")]    method: Option\u003cString\u003e,    #[serde(skip_serializing_if = \"Option::is_none\")]    params: Option\u003cValue\u003e,    #[serde(skip_serializing_if = \"Option::is_none\")]    result: Option\u003cValue\u003e,    #[serde(skip_serializing_if = \"Option::is_none\")]    error: Option\u003cErrorData\u003e,}impl TryFrom\u003cJsonRpcRaw\u003e for JsonRpcMessage {    type Error = String;    fn try_from(raw: JsonRpcRaw) -\u003e Result\u003cSelf, \u003cSelf as TryFrom\u003cJsonRpcRaw\u003e\u003e::Error\u003e {        // If it has an error field, it's an error response        if raw.error.is_some() {            return Ok(JsonRpcMessage::Error(JsonRpcError {                jsonrpc: raw.jsonrpc,                id: raw.id,                error: raw.error.unwrap(),            }));        }        // If it has a result field, it's a response        if raw.result.is_some() {            return Ok(JsonRpcMessage::Response(JsonRpcResponse {                jsonrpc: raw.jsonrpc,                id: raw.id,                result: raw.result,                error: None,            }));        }        // If we have a method, it's either a notification or request        if let Some(method) = raw.method {            if raw.id.is_none() {                return Ok(JsonRpcMessage::Notification(JsonRpcNotification {                    jsonrpc: raw.jsonrpc,                    method,                    params: raw.params,                }));            }            return Ok(JsonRpcMessage::Request(JsonRpcRequest {                jsonrpc: raw.jsonrpc,                id: raw.id,                method,                params: raw.params,            }));        }        // If we have no method and no result/error, it's a nil response        if raw.id.is_none() \u0026\u0026 raw.result.is_none() \u0026\u0026 raw.error.is_none() {            return Ok(JsonRpcMessage::Nil);        }        // If we get here, something is wrong with the message        Err(format!(            \"Invalid JSON-RPC message format: id={:?}, method={:?}, result={:?}, error={:?}\",            raw.id, raw.method, raw.result, raw.error        ))    }}この実装の素晴らしい点は3つあります。#[serde(untagged)]アノテーションの活用：JSONデータの構造に基づいて適切な列挙型バリアントに自動的にデシリアライズします。これにより、外部向けのJSONはシンプルな形式を維持できます。try_from = \"JsonRpcRaw\"による変換の分離：複雑な変換ロジックを別の型に委譲し、コードの見通しを良くしています。これはRustの型システムを活用した優れたパターンです。段階的な判断ロジック：各メッセージタイプの判定条件を明確にし、順番に評価することで複雑な条件分岐を読みやすく実装しています。これらの工夫により、複雑なJSON-RPCプロトコルの処理を堅牢かつ読みやすいコードで実現しています。特に注目すべきは、Rustの型システムを最大限に活用し、コンパイル時の型チェックでバグを防ぐ設計になっている点です。豊かなコンテンツ型システムMCPはさまざまなコンテンツ型（テキスト、画像、リソースなど）をサポートしています。その実装も非常に洗練されています。#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]#[serde(tag = \"type\", rename_all = \"camelCase\")]pub enum Content {    Text(TextContent),    Image(ImageContent),    Resource(EmbeddedResource),}impl Content {    pub fn text\u003cS: Into\u003cString\u003e\u003e(text: S) -\u003e Self {        Content::Text(TextContent {            text: text.into(),            annotations: None,        })    }    pub fn image\u003cS: Into\u003cString\u003e, T: Into\u003cString\u003e\u003e(data: S, mime_type: T) -\u003e Self {        Content::Image(ImageContent {            data: data.into(),            mime_type: mime_type.into(),            annotations: None,        })    }    pub fn resource(resource: ResourceContents) -\u003e Self {        Content::Resource(EmbeddedResource {            resource,            annotations: None,        })    }    // その他のメソッド...}この実装には、使いやすさと型安全性を両立する工夫がいくつもあります。タグ付き列挙型の活用：#[serde(tag = \"type\")]は、JSONに「type」フィールドを追加し、その値に基づいて適切な型にデシリアライズします。これはJSONとRustの型を自然にマッピングする優れた方法です。ファクトリメソッド：text(), image(), resource()などのメソッドは、わかりやすい方法でコンテンツを作成できるようにしています。これは、制約を守りながら簡潔にオブジェクトを作成するのに役立ちます。ジェネリックな引数：S: Into\u003cString\u003eのようなトレイト境界を使うことで、文字列リテラル、String、\u0026strなど、さまざまな文字列型を引数として受け入れることができます。これは使い勝手を大幅に向上させます。この設計は、使いやすいAPIと堅牢な内部実装のバランスが見事です。とりわけ、列挙型とそのバリアントを活用してドメインの概念を表現する点はRustらしいアプローチと言えるでしょう。mcp-client: 柔軟なトランスポートと抽象化mcp-clientクレートは、MCPサーバーとの通信を担当します。特に注目すべきは、トランスポート層の抽象化です。トランスポートの抽象化MCPサーバーとの通信には複数の方法（標準入出力、HTTP、WebSocketなど）が考えられます。このSDKはそれらを抽象化するための優れた設計を採用しています。/// A message that can be sent through the transport#[derive(Debug)]pub struct TransportMessage {    /// The JSON-RPC message to send    pub message: JsonRpcMessage,    /// Channel to receive the response on (None for notifications)    pub response_tx: Option\u003coneshot::Sender\u003cResult\u003cJsonRpcMessage, Error\u003e\u003e\u003e,}/// A generic asynchronous transport trait with channel-based communication#[async_trait]pub trait Transport {    type Handle: TransportHandle;    /// Start the transport and establish the underlying connection.    /// Returns the transport handle for sending messages.    async fn start(\u0026self) -\u003e Result\u003cSelf::Handle, Error\u003e;    /// Close the transport and free any resources.    async fn close(\u0026self) -\u003e Result\u003c(), Error\u003e;}#[async_trait]pub trait TransportHandle: Send + Sync + Clone + 'static {    async fn send(\u0026self, message: JsonRpcMessage) -\u003e Result\u003cJsonRpcMessage, Error\u003e;}この抽象化にはいくつもの巧妙な工夫があります。関連型（associated type）の活用：type Handle: TransportHandleという関連型を使うことで、トランスポートとそのハンドルを型レベルで紐づけています。これにより、異なるトランスポート実装が異なるハンドル型を持つことができます。非同期トレイト：#[async_trait]マクロを使って、非同期メソッドをトレイトに含められるようにしています。これは標準のRustでは直接サポートされていない機能です。分離された開始と通信：startメソッドで接続を確立し、その結果として得られるハンドルを使って通信するという2段階のパターンを採用しています。これにより、接続のライフサイクルとメッセージ送受信を明確に分離できます。このような抽象化により、新しいトランスポート実装を追加するのが容易になりますし、クライアント側のコードはトランスポートの詳細を気にせず書けるようになります。StdioTransportの実装標準入出力を使ったトランスポート実装も見てみましょう：pub struct StdioTransport {    command: String,    args: Vec\u003cString\u003e,    env: HashMap\u003cString, String\u003e,}impl StdioTransport {    pub fn new\u003cS: Into\u003cString\u003e\u003e(        command: S,        args: Vec\u003cString\u003e,        env: HashMap\u003cString, String\u003e,    ) -\u003e Self {        Self {            command: command.into(),            args,            env,        }    }    async fn spawn_process(\u0026self) -\u003e Result\u003c(Child, ChildStdin, ChildStdout, ChildStderr), Error\u003e {        let mut command = Command::new(\u0026self.command);        command            .envs(\u0026self.env)            .args(\u0026self.args)            .stdin(std::process::Stdio::piped())            .stdout(std::process::Stdio::piped())            .stderr(std::process::Stdio::piped())            .kill_on_drop(true);        // Set process group only on Unix systems        #[cfg(unix)]        command.process_group(0); // don't inherit signal handling from parent process        // Hide console window on Windows        #[cfg(windows)]        command.creation_flags(0x08000000); // CREATE_NO_WINDOW flag        let mut process = command            .spawn()            .map_err(|e| Error::StdioProcessError(e.to_string()))?;        let stdin = process            .stdin            .take()            .ok_or_else(|| Error::StdioProcessError(\"Failed to get stdin\".into()))?;        let stdout = process            .stdout            .take()            .ok_or_else(|| Error::StdioProcessError(\"Failed to get stdout\".into()))?;        let stderr = process            .stderr            .take()            .ok_or_else(|| Error::StdioProcessError(\"Failed to get stderr\".into()))?;        Ok((process, stdin, stdout, stderr))    }}この実装の素晴らしい点を見てみましょう：プラットフォーム固有の最適化：#[cfg(unix)]と#[cfg(windows)]を使って、各OSに最適な設定を行っています。これはRustの条件付きコンパイルの機能をうまく活用した例です。リソース管理：kill_on_drop(true)を使って、オブジェクトが破棄された時に子プロセスも確実に終了するよう保証しています。これはリソースリークを防ぐための重要な安全策です。エラーハンドリング：ok_or_elseのような関数を使って、エラーケースを明確に処理しています。これにより、どのような状況でもプログラムが予測可能な動作をするようになります。この実装は、複雑な子プロセス操作を安全かつ効率的に行うための優れた例です。特に、クロスプラットフォームな動作を保証するための配慮が随所に見られます。クライアント本体の実装最後に、クライアント本体の実装を見てみましょう：pub struct McpClient\u003cS\u003ewhere    S: Service\u003cJsonRpcMessage, Response = JsonRpcMessage\u003e + Clone + Send + Sync + 'static,    S::Error: Into\u003cError\u003e,    S::Future: Send,{    service: Mutex\u003cS\u003e,    next_id: AtomicU64,    server_capabilities: Option\u003cServerCapabilities\u003e,    server_info: Option\u003cImplementation\u003e,}impl\u003cS\u003e McpClient\u003cS\u003ewhere    S: Service\u003cJsonRpcMessage, Response = JsonRpcMessage\u003e + Clone + Send + Sync + 'static,    S::Error: Into\u003cError\u003e,    S::Future: Send,{    pub fn new(service: S) -\u003e Self {        Self {            service: Mutex::new(service),            next_id: AtomicU64::new(1),            server_capabilities: None,            server_info: None,        }    }    /// Send a JSON-RPC request and check we don't get an error response.    async fn send_request\u003cR\u003e(\u0026self, method: \u0026str, params: Value) -\u003e Result\u003cR, Error\u003e    where        R: for\u003c'de\u003e Deserialize\u003c'de\u003e,    {        let mut service = self.service.lock().await;        service.ready().await.map_err(|_| Error::NotReady)?;        let id = self.next_id.fetch_add(1, Ordering::SeqCst);        let request = JsonRpcMessage::Request(JsonRpcRequest {            jsonrpc: \"2.0\".to_string(),            id: Some(id),            method: method.to_string(),            params: Some(params.clone()),        });        let response_msg = service            .call(request)            .await            .map_err(|e| Error::McpServerError {                server: self                    .server_info                    .as_ref()                    .map(|s| s.name.clone())                    .unwrap_or(\"\".to_string()),                method: method.to_string(),                // we don't need include params because it can be really large                source: Box::new(e.into()),            })?;        // ... レスポンス処理 ...    }}この実装には、Rustの現代的な非同期プログラミング技術が凝縮されています。Tower Serviceの活用：低レベルのトランスポート詳細を抽象化するために、Tower crateのServiceトレイトを使用しています。これはミドルウェアの組み合わせや機能拡張を容易にします。ジェネリックな戻り値型：send_request\u003cR\u003eのようなジェネリック関数を使って、様々な型のレスポンスを受け取れるようにしています。これはクライアントAPIを使いやすくする工夫です。スレッドセーフなカウンター：AtomicU64を使って、スレッドセーフなID生成を実現しています。これは並行処理を安全に行うための基本的なテクニックです。非同期排他制御：Mutex\u003cS\u003eを使って、非同期コンテキストでのサービスアクセスを管理しています。tokio::sync::Mutexはブロッキングせずに排他制御を行える優れたプリミティブです。これらの機能を組み合わせることで、堅牢で効率的、かつ使いやすいクライアントAPIを実現しています。特にTowerのサービス抽象化を活用することで、将来的な拡張性も確保されています。mcp-server: モジュラーなサーバー設計mcp-serverクレートは、MCPサーバーをRustで実装するためのフレームワークを提供しています。ここでもいくつか興味深い実装が見られます。ByteTransportの実装#[pin_project]pub struct ByteTransport\u003cR, W\u003e {    // Reader is a BufReader on the underlying stream (stdin or similar) buffering    // the underlying data across poll calls, we clear one line (\\n) during each    // iteration of poll_next from this buffer    #[pin]    reader: BufReader\u003cR\u003e,    #[pin]    writer: W,}impl\u003cR, W\u003e ByteTransport\u003cR, W\u003ewhere    R: AsyncRead,    W: AsyncWrite,{    pub fn new(reader: R, writer: W) -\u003e Self {        Self {            // Default BufReader capacity is 8 * 1024, increase this to 2MB to the file size limit            // allows the buffer to have the capacity to read very large calls            reader: BufReader::with_capacity(2 * 1024 * 1024, reader),            writer,        }    }}impl\u003cR, W\u003e Stream for ByteTransport\u003cR, W\u003ewhere    R: AsyncRead + Unpin,    W: AsyncWrite + Unpin,{    type Item = Result\u003cJsonRpcMessage, TransportError\u003e;    fn poll_next(self: Pin\u003c\u0026mut Self\u003e, cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cOption\u003cSelf::Item\u003e\u003e {        // Poll実装...    }}この実装には、Rustの非同期I/Oに関する高度な知識が詰まっています。巨大なバッファサイズ：デフォルトの8KBではなく2MBという大きなバッファを使用し、大量のデータを効率的に処理できるようにしています。これは実際のユースケースに基づく現実的な最適化でしょう。pin-projectの活用：非同期処理でピン留めが必要なフィールドを持つ構造体を安全に扱うために、pin-projectクレートを使用しています。これは非同期Rustの複雑な問題を解決するための定石です。Streamトレイトの実装：Streamトレイトを実装することで、メッセージを非同期ストリームとして扱えるようにしています。これは非同期処理パターンとの自然な統合を可能にします。このようなトランスポート実装により、サーバーは効率的に大量のメッセージを処理できるようになります。また、バッファ管理や非同期I/Oの複雑さは抽象化されるため、上位層のコードはビジネスロジックに集中できます。優れたRouterトレイトMCPサーバーの中核となるのがRouterトレイトです。pub trait Router: Send + Sync + 'static {    fn name(\u0026self) -\u003e String;    fn instructions(\u0026self) -\u003e String;    fn capabilities(\u0026self) -\u003e ServerCapabilities;    fn list_tools(\u0026self) -\u003e Vec\u003cmcp_core::tool::Tool\u003e;    fn call_tool(        \u0026self,        tool_name: \u0026str,        arguments: Value,    ) -\u003e Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cVec\u003cContent\u003e, ToolError\u003e\u003e + Send + 'static\u003e\u003e;    fn list_resources(\u0026self) -\u003e Vec\u003cmcp_core::resource::Resource\u003e;    fn read_resource(        \u0026self,        uri: \u0026str,    ) -\u003e Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cString, ResourceError\u003e\u003e + Send + 'static\u003e\u003e;    fn list_prompts(\u0026self) -\u003e Vec\u003cPrompt\u003e;    fn get_prompt(\u0026self, prompt_name: \u0026str) -\u003e PromptFuture;    // 以下はデフォルト実装を持つヘルパーメソッド    fn create_response(\u0026self, id: Option\u003cu64\u003e) -\u003e JsonRpcResponse { ... }    fn handle_initialize(\u0026self, req: JsonRpcRequest) -\u003e impl Future\u003cOutput = Result\u003cJsonRpcResponse, RouterError\u003e\u003e + Send { ... }    // その他のハンドラメソッド...}この設計の素晴らしさは以下の点にあります。最小限の実装要件：ユーザーが実装すべきメソッドは基本的な機能に限られており、複雑なプロトコル処理はデフォルト実装として提供されています。これにより、ルーターの実装がシンプルになり、ドメインロジックに集中できます。Futureを返すメソッド：ツール呼び出しなどの処理は非同期で行われるケースが多いため、Pin\u003cBox\u003cdyn Future\u003c...\u003e\u003e\u003eを返すメソッドになっています。これにより、実装者は任意の非同期処理を行う自由を持ちます。明確なトレイト境界：Send + Sync + 'staticという境界により、マルチスレッド環境での使用を安全に行えるようになっています。これは実際のサーバー環境では不可欠な制約です。この設計は、「使いやすさ」と「柔軟性」のバランスがとれた素晴らしい例です。初心者でも簡単に基本的なルーターを実装できますが、高度なユースケースに対応する拡張性も備えています。RouterServiceの実装pub struct RouterService\u003cT\u003e(pub T);impl\u003cT\u003e Service\u003cJsonRpcRequest\u003e for RouterService\u003cT\u003ewhere    T: Router + Clone + Send + Sync + 'static,{    type Response = JsonRpcResponse;    type Error = BoxError;    type Future = Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cSelf::Response, Self::Error\u003e\u003e + Send\u003e\u003e;    fn poll_ready(\u0026mut self, _cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cResult\u003c(), Self::Error\u003e\u003e {        Poll::Ready(Ok(()))    }    fn call(\u0026mut self, req: JsonRpcRequest) -\u003e Self::Future {        let this = self.0.clone();        Box::pin(async move {            let result = match req.method.as_str() {                \"initialize\" =\u003e this.handle_initialize(req).await,                \"tools/list\" =\u003e this.handle_tools_list(req).await,                \"tools/call\" =\u003e this.handle_tools_call(req).await,                \"resources/list\" =\u003e this.handle_resources_list(req).await,                \"resources/read\" =\u003e this.handle_resources_read(req).await,                \"prompts/list\" =\u003e this.handle_prompts_list(req).await,                \"prompts/get\" =\u003e this.handle_prompts_get(req).await,                _ =\u003e {                    let mut response = this.create_response(req.id);                    response.error = Some(RouterError::MethodNotFound(req.method).into());                    Ok(response)                }            };            result.map_err(BoxError::from)        })    }}この実装は、デザインパターンの「アダプターパターン」を思わせる優れた例です。シンプルなラッパー型：RouterService\u003cT\u003e(pub T)というシンプルな新型でRouterトレイトをTowerのServiceトレイトに適応させています。これは非常にエレガントなアプローチです。メソッドディスパッチ：リクエストのmethod文字列に基づいて適切なハンドラメソッドに処理をディスパッチしています。これはルーティングのための直感的で効率的な実装です。Clone要件：非同期クロージャ内でルーターを使用するためにCloneトレイト境界を要求しています。これにより、所有権の問題を簡単に解決できます。このようなラッパー型とディスパッチロジックにより、開発者はRouterトレイトの実装に集中でき、ServiceやTowerのような低レベルの詳細を気にする必要がなくなります。これは抽象化の良い例です。mcp-macros: 宣言的ツール定義の魔法最後に、mcp-macrosクレートの中核である#[tool]マクロを見てみましょう：#[proc_macro_attribute]pub fn tool(args: TokenStream, input: TokenStream) -\u003e TokenStream {    let args = parse_macro_input!(args as MacroArgs);    let input_fn = parse_macro_input!(input as ItemFn);    // Extract function details    let fn_name = \u0026input_fn.sig.ident;    let fn_name_str = fn_name.to_string();    // Generate PascalCase struct name from the function name    let struct_name = format_ident!(\"{}\", { fn_name_str.to_case(Case::Pascal) });    // Use provided name or function name as default    let tool_name = args.name.unwrap_or(fn_name_str);    let tool_description = args.description.unwrap_or_default();    // パラメータの抽出処理...    // 実装の生成    let params_struct_name = format_ident!(\"{}Parameters\", struct_name);    let expanded = quote! {        #[derive(serde::Deserialize, schemars::JsonSchema)]        struct #params_struct_name {            #(#param_defs,)*        }        #input_fn        #[derive(Default)]        struct #struct_name;        #[async_trait::async_trait]        impl mcp_core::handler::ToolHandler for #struct_name {            fn name(\u0026self) -\u003e \u0026'static str {                #tool_name            }            fn description(\u0026self) -\u003e \u0026'static str {                #tool_description            }            fn schema(\u0026self) -\u003e serde_json::Value {                mcp_core::handler::generate_schema::\u003c#params_struct_name\u003e()                    .expect(\"Failed to generate schema\")            }            async fn call(\u0026self, params: serde_json::Value) -\u003e Result\u003cserde_json::Value, mcp_core::handler::ToolError\u003e {                let params: #params_struct_name = serde_json::from_value(params)                    .map_err(|e| mcp_core::handler::ToolError::InvalidParameters(e.to_string()))?;                // Extract parameters and call the function                let result = #fn_name(#(params.#param_names,)*).await                    .map_err(|e| mcp_core::handler::ToolError::ExecutionError(e.to_string()))?;                Ok(serde_json::to_value(result).expect(\"should serialize\"))            }        }    };    TokenStream::from(expanded)}このマクロは、Rustの宣言的プログラミングの可能性を示す素晴らしい例です。関数からのメタデータ抽出：関数の名前や引数リストを解析して、ツールの基本情報を自動的に取得します。パラメータ構造体の自動生成：関数の引数リストから自動的にパラメータ構造体を生成し、serdeとschemarsのデリバティブを適用してJSON対応にします。ツールハンドラの自動実装：抽出した情報を元に、ToolHandlerトレイトを自動的に実装します。これにより、開発者はツールのビジネスロジックだけに集中できます。このマクロを使うと、以下のように簡潔なコードでツールを定義できます。#[tool(    name = \"calculator\",    description = \"Perform basic arithmetic operations\",    params(        x = \"First number in the calculation\",        y = \"Second number in the calculation\",        operation = \"The operation to perform (add, subtract, multiply, divide)\"    ))]async fn calculator(x: i32, y: i32, operation: String) -\u003e Result\u003ci32, ToolError\u003e {    match operation.as_str() {        \"add\" =\u003e Ok(x + y),        \"subtract\" =\u003e Ok(x - y),        \"multiply\" =\u003e Ok(x * y),        \"divide\" =\u003e {            if y == 0 {                Err(ToolError::ExecutionError(\"Division by zero\".into()))            } else {                Ok(x / y)            }        }        _ =\u003e Err(ToolError::InvalidParameters(format!(            \"Unknown operation: {}\",            operation        ))),    }}通常なら数十行のボイラープレートコードが必要なところを、このマクロによって数行のアノテーションだけで実現できています。これは開発者体験を大幅に向上させる素晴らしい例です。Webフレームワークとの統合MCPはしばしばWebアプリケーションと統合されます。そのための優れた実装例を見てみましょう：async fn sse_handler(State(app): State\u003cApp\u003e) -\u003e Sse\u003cimpl Stream\u003cItem = Result\u003cEvent, io::Error\u003e\u003e\u003e {    // it's 4KB    const BUFFER_SIZE: usize = 1 \u003c\u003c 12;    let session = session_id();    tracing::debug!(%session, \"sse connection\");    let (c2s_read, c2s_write) = tokio::io::simplex(BUFFER_SIZE);    let (s2c_read, s2c_write) = tokio::io::simplex(BUFFER_SIZE);    app.txs        .write()        .await        .insert(session.clone(), Arc::new(Mutex::new(c2s_write)));    {        let session = session.clone();        tokio::spawn(async move {            let router = RouterService(counter::CounterRouter::new());            let server = Server::new(router);            let bytes_transport = ByteTransport::new(c2s_read, s2c_write);            let _result = server                .run(bytes_transport)                .await                .inspect_err(|e| tracing::error!(?e, \"server run error\"));            app.txs.write().await.remove(\u0026session);        });    }    let stream = futures::stream::once(futures::future::ok(        Event::default()            .event(\"endpoint\")            .data(format!(\"?sessionId={session}\")),    ))    .chain(        FramedRead::new(s2c_read, common::jsonrpc_frame_codec::JsonRpcFrameCodec)            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))            .and_then(move |bytes| match std::str::from_utf8(\u0026bytes) {                Ok(message) =\u003e futures::future::ok(Event::default().event(\"message\").data(message)),                Err(e) =\u003e futures::future::err(io::Error::new(io::ErrorKind::InvalidData, e)),            }),    );    Sse::new(stream)}この実装は、Webアプリケーションとバックエンドサービスを統合する優れた例です。単方向チャネルの活用：tokio::io::simplexを使って、クライアントからサーバーへの通信とサーバーからクライアントへの通信を分離しています。これは各方向の流れを独立して最適化できるようにします。バックグラウンドタスク：MCPサーバーをtokio::spawnを使ってバックグラウンドタスクとして実行しています。これによりWebハンドラーは応答を待つことなく、すぐにSSEストリームを返すことができます。SSEストリームの構築：futures::stream::onceと.chain()を組み合わせて、初期メッセージと継続的なメッセージストリームを連結しています。これはストリーミングAPIの標準的なパターンです。この実装パターンは、MCPサーバーをWebアプリケーションに統合する効果的な方法を示しています。特に注目すべきは、非同期処理とストリーミングを効果的に組み合わせている点です。SDKの設計思想分析このSDKの実装から、いくつかの重要な設計思想が読み取れます。堅牢性と型安全性への徹底したこだわりこのSDKは、Rustの型システムを徹底的に活用して堅牢性を確保しています。トレイト境界（Send + Sync + 'staticなど）の明示的な指定ジェネリックパラメータを使ったAPI設計Result型による包括的なエラーハンドリングasync/awaitとFutureの適切な組み合わせこれらの特徴は、SDKの開発者がRustの強みをよく理解し、それを活かそうとしていることを示しています。特に、コンパイル時に多くのエラーを捕捉できるように設計されており、実行時の予期せぬ動作を最小限に抑える工夫が随所に見られます。拡張性と将来性を考えた設計SDKは将来の拡張を見据えた柔軟な設計になっています。トランスポート層の抽象化サービス層の分離とミドルウェアのサポートプラグイン可能なツール定義このような設計により、MCPプロトコル自体が進化しても、SDKを大きく書き換えることなく対応できるでしょう。また、ユーザーが独自の機能を追加するための拡張ポイントが多く用意されています。開発者体験の重視SDKは、使いやすさにも重点を置いています。マクロによるボイラープレートコードの削減直感的なビルダースタイルAPI豊富なデフォルト実装これらの機能は、SDKを使う開発者の負担を軽減し、本質的なビジネスロジックに集中できるようにするための工夫です。特に#[tool]マクロは、開発者体験を大幅に向上させる優れた例です。パフォーマンスへの配慮実装には、パフォーマンスを考慮した数々の工夫が見られます。大きなバッファサイズ（2MB）の使用非同期I/Oの全面採用ロックの最小化と効率的な並行処理これらの最適化は、MCPが大量のデータや複雑なコンテキストを扱うAIユースケースを想定していることを示唆しています。優れた実装パターンのまとめこのSDKから学べる優れたRust実装パターンをまとめましょう。1. 関心の明確な分離SDKは複数のクレートに分かれており、各クレートが明確な責任を持っています。これは保守性と再利用性を高める優れた設計原則です。2. トランスポート抽象化異なる通信方法（Stdio、SSEなど）を統一的なインターフェースで扱うための抽象化は、拡張性と柔軟性の高いコードを書くための良い例です。3. Tower ServiceパターンTowerのサービス抽象化を活用して、ミドルウェアの組み合わせやサービス合成を容易にする設計は、現代的なRustサーバー実装のベストプラクティスです。4. プロシージャルマクロの効果的な活用ボイラープレートコードを削減し、宣言的なスタイルでコードを書けるようにするマクロの活用は、開発者体験を向上させる優れた方法です。5. 非同期プログラミングのベストプラクティスPin、Box\u003cdyn Future\u003e、async_traitなどを適切に組み合わせた非同期処理の実装は、Rustの非同期プログラミングの洗練されたパターンを示しています。おわりにMCP Rust SDKの内部実装を深掘りすることで、Rustの強力な型システムと非同期プログラミングモデルを最大限に活用した素晴らしい設計パターンを学ぶことができました。このSDKは、「型安全性」「拡張性」「使いやすさ」「パフォーマンス」のバランスが優れており、大規模なRustアプリケーションを設計する際の参考になります。特に、トランスポート抽象化、サービス指向設計、プロシージャルマクロの活用は、他のRustプロジェクトでも応用できる価値のある実践例です。MCPプロトコルの実装を検討している方はもちろん、Rustでの堅牢なライブラリ設計に興味がある方にとっても、このSDKのコードベースは探求する価値のある宝庫と言えるでしょう。次回のブログではサンプルを見ながら実際に色々動かしてみたいと思います。syu-m-5151.hatenablog.com","isoDate":"2025-03-27T03:16:02.000Z","dateMiliSeconds":1743045362000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\r- 公式URL: https://forkwell.connpass.com/event/348104/\r\r🗣️ 関連スライド\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\r- Platform Engineeringは自由のめまい\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇してきました。　#信頼性向上_findy","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737","contentSnippet":"はじめにこんにちは、スリーシェイクのnwiizoです。2025年3月21日に開催されたFindyさん主催のイベントで登壇してきました。findy.connpass.comイベント概要このイベントは、SLI/SLOの導入と運用に焦点を当てたライトニングトーク形式のセッションでした。サービス品質を高めるためのSLI/SLOですが、組織内での運用がうまくいってないケースや導入タイミングに悩まれている方も多いのが現状です。本イベントではSLI/SLOについて向き合っていらっしゃる4名の皆様に、導入までの取り組みや運用上の課題とその解決策を共有していただきます。参加者にとって今後システムの信頼性向上に取り組んでいくための知識やヒントを得られるイベントになることを目指します。私を含めた4名のスピーカーによる多角的なアプローチで、SLI/SLOに関する実践的な知見が共有されました。とても良い会だったと思います。私の発表内容資料 speakerdeck.com👻本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇します。こちら、資料になります。https://t.co/XtbFX2EOSH#信頼性向上_findy— nwiizo (@nwiizo) 2025年3月21日   発表の背景と位置づけこのイベントの準備にあたり、他の登壇者の方々の過去の発表や知見を事前に確認し、全体として何が語られるのかを予想してみました。技術的な実装方法や指標設計については他の方々が深く掘り下げられると考え、あえて私は「個人や組織への適用」という補完的な視点に焦点を当てることにしました。技術的な側面は重要ですが、実際にSLI/SLOが組織に定着するかどうかは、エンジニアリング以外の部分に大きく依存します。そこで今回は「技術をどう実装するか」ではなく「個人や組織をどう変革するか」という視点からSLI/SLOの旅を語ることにしました。発表の核心：三つの壁私の発表ではSLI/SLO導入における「三つの壁」に焦点を当てました1. 既存の習慣や方法からの変更を伴う壁「変化への抵抗」は克服すべき障害ではなく、理解し対話すべき自然な反応です。特に以下の4つの抵抗パターンを理解することが重要です。惰性による抵抗：「今のやり方で問題ない」労力による抵抗：「新しい方法を学ぶコストが高い」感情による抵抗：「自分の立場が脅かされる」心理的反発：変化に対する本能的な抵抗これらの抵抗に対して「北風」（強制）ではなく「太陽」（共感と対話）のアプローチが効果的です。2. 多くのステークホルダーとの協力が不可欠という壁SLI/SLOは技術だけの問題ではなく、むしろ組織の問題です。表向きは「全員で信頼性を高めましょう」という掛け声のもとで始まりますが、裏では様々な力学が働いています。部門間の隠れた対立構造：エンジニアリングは信頼性を重視し、プロダクトは新機能を優先し、経営層はコスト効率を求める。この三すくみの構造がSLI/SLO導入の最大の障壁になります。「会議では言えない本音」の存在：公式の場では皆が納得したように見えても、実際には「またエンジニアの自己満足では？」「数値のために本質を見失っている」といった潜在的な不信感が残ります。非公式なネットワークの重要性：公式のプロセスや説明会より、信頼関係のある個人間の非公式な対話の方が効果的なことが多いです。ランチタイムや1on1の場で地道に信頼関係を築く必要があります。技術と事業の懸け橋となる人材の重要性：各部門の言語を話せるクロスファンクショナルな理解者（技術と事業の両方を理解できる人）が不可欠です。このような架け橋となる存在を味方につけることが成功への近道になります。結局のところ、最も有効な戦略は「自分の専門領域を超えて相手の文脈で語る」ことです。技術者は事業KPIの言葉で、事業側は技術的制約の言葉で対話する努力が必要です。これが「信頼性は会話である」という言葉の本当の意味なのです。3. 目に見える成果が出るまでに時間がかかるという壁SLI/SLOの導入は短期決戦ではなく長期的な取り組みです。導入初期は一時的な作業量増加と基盤構築が先行本当の価値は6-12ヶ月後から現れることが多い「完璧なSLO」より「継続的に改善されるSLO」が重要長期的取り組みのためには、小さな成功の積み重ねと組織的なコミットメントが欠かせません。実務上の重要なポイントは、初期段階で期待値を適切に設定することです。多くの組織では「すぐに効果が出る」という期待から、半年程度で「効果がない」と判断されることがあります。これを防ぐには、短期的な小さな成功（例：アラート削減による疲労軽減）と長期的な大きな成功（例：システム安定性向上によるビジネス成長）の両方を明確に提示しておくことが重要です。発表を終えて今回のイベントでは、他の登壇者の方々もそれぞれの視点から素晴らしい発表をされていました。BASEのtandenさんがアラート品質の改善について、シンプルフォームの守屋さんが開発組織全体でのSLI/SLO実装について、ユーザベースの安藤さんがSREとCTOの両視点からのSLI/SLO活用について語られました。私は意図的に「組織文化と変革マネジメント」という視点から補完的に話すことで、イベント全体として技術から組織まで幅広い視点でSLI/SLOについて学べる場になったのではないかと思います。特に印象的だったのは、どの発表も「数値や指標そのものより、それを活用して何を実現するか」という本質的な部分を大切にしていたことです。形式的なSLI/SLO導入ではなく、真に組織とサービスの価値を高めるための取り組みとして捉えられていたのが印象的でした。まとめSLI/SLOの導入は一朝一夕にはいきません。それは旅のように、ゴールや完璧を目指すのではなく、継続的な前進が大切です。今日から始められることとしては：- 小さく始めて徐々に拡大する- まずは一つのサービスから- 既存の課題から出発するそして成功のための心構えとして：- 完璧よりも継続を重視する- 技術も情熱もどちらも大切- 信頼性は会話/対話から生まれるSLI/SLOの導入は技術的チャレンジであると同時に組織的チャレンジです。小さな一歩から始めて、組織全体で信頼性文化を育んでいきましょう。なお、SLI/SLOの基本概念から実践的な導入方法までを体系的に学ぶには、以下の書籍を必ず一読していただきたいと思います。組織への適用を考える前に、まずはこの本で基礎をしっかり固めることをお勧めします。www.oreilly.co.jpこれらのポイントを心に留めながら、組織にSLI/SLOを適用する旅を続けていきましょう。おわりにまた、他の登壇者の皆さんの発表資料も大変参考になりましたので、ぜひご覧ください。BASEの@tac_tandenさんによる「SLI/SLOの設定を進めるその前に、アラート品質の改善に取り組んだ話」では、SLI/SLO導入の前段階としてのアラート品質向上について詳しく解説されています。SREピラミットの下には常にモニタリングがあり自分の経験からも何よりも重要だと思っています。 speakerdeck.comシンプルフォームの守屋邦昭さんによる「開発組織全体で意識するSLI/SLOを実装している話」では、組織全体でのSLI/SLO実装について具体的な事例が紹介されています。 speakerdeck.comユーザベースの安藤裕紀さんによる「SREとしてSLI/SLOをどう普及してきたか、CTOとしてSLI/SLOをどう活用しているか」では、SRE視点とCTO視点の両面からSLI/SLOの活用方法が解説されています。個人的には俯瞰度合いが好きです。www.docswell.com最後までお読みいただき、ありがとうございました！","isoDate":"2025-03-21T11:47:37.000Z","dateMiliSeconds":1742557657000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\r\r\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」🎵🧭 というタイトルで登壇しました！\r\r🔍 イベント詳細:\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\r- 公式URL: https://findy.connpass.com/event/345990/\r\r📚 さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！😲\r「Kubernetesで実践する Platform Engineering - FL#88」🐳⚙️\r興味がある方はぜひ参加してください！👨‍💻👩‍💻\r👉 https://forkwell.connpass.com/event/348104/\r\rお見逃しなく！🗓️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIといっしょ: 動作するきれいなコードを生成AIとつくる","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025","contentSnippet":"※こちらは社内で発表したものを外部で登壇できるように修正したものです。はじめに2021年にGitHub Copilotが発表され、2022年に一般利用可能になって以来、生成AIはソフトウェア開発の世界に急速に浸透してきました。「動作するきれいなコード」はソフトウェア開発の理想とされてきましたが、生成AIの登場によってこの理想に到達する道筋が大きく変化しています。本記事では、テスト駆動開発の原典である『テスト駆動開発』の基本理念を踏まえ、生成AIとの協業によって「動作するきれいなコード」を実現する方法について考察します。「動作するきれいなコード」とは何かt-wada氏がSeleniumConf Tokyo 2019での基調講演で引用したように、テスト駆動開発のゴールは「動作するきれいなコード（Clean code that works）」です。Kent Beckによるテスト駆動開発の書籍の冒頭には、次のような一節があります。 speakerdeck.com「動作するきれいなコード」。Ron Jeffriesのこの簡潔な言葉が、テスト駆動開発（TDD）のゴールだ。動作するきれいなコードはあらゆる意味で価値がある「動作する」と「きれい」の2つの要素に分解すると、ソフトウェア開発においては以下の4つの象限が考えられます：きれいで動作する（理想）きれいだが動作しない（机上の空論）きたないが動作する（現実の妥協）きたなくて動作しない（最悪の状態）Kent Beckは、この目標に対して、天才的なプログラマならすぐに到達できるかもしれないが、一般のプログラマはすぐには書けないと述べています。そこで彼は分割統治法を提案し、まず「動作する」ことを優先し、その後「きれい」にすることを推奨しています。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon生成AIとテスト駆動開発の融合ソフトウェア開発における三種の神器t-wada氏の講演では、ソフトウェア開発において欠かせない三つの技術的な柱（三種の神器）が紹介されています。これらは生成AIと協働する際にも極めて重要な基盤となります。1. バージョン管理（Version Control）バージョン管理は、人間の記憶力の限界を補うために生まれました。バージョン管理システムは：いつ、誰が、どのような変更をしたかを記録異なるバージョン間の差分を可視化複数の開発者が同時に作業することを可能に過去の状態に簡単に戻れる安全網を提供生成AIとの協働においても、AIが生成したコードを適切に管理し、問題が生じた場合に以前の状態に戻れるようにするためにバージョン管理は不可欠です。2. テスティング（Testing）テスティングは人間の把握力の限界を補います。システムが複雑化するにつれ、変更が他の部分に与える影響を人間が完全に把握することは困難になります。テスティングにより：コードが予期通りに動作することを自動的に検証変更によるリグレッションを早期に発見設計の問題点を可視化リファクタリングの安全網を提供生成AIとの協業では、この安全網がさらに重要となります。AIが生成したコードが本当に要件を満たしているかを客観的に評価するためのテストは不可欠です。3. 自動化（Automation）自動化は人間の忍耐力の限界を補います。自動化により：繰り返し作業を機械に任せることで人間のエラーを減少開発プロセスの一貫性と再現性を確保開発速度の向上と時間の節約継続的インテグレーション・継続的デリバリ（CI/CD）を実現特に重要なのは、自動化がソフトウェア開発におけるガードレールとしての役割を果たすことです。AIが生成したコードの品質、セキュリティ、パフォーマンスを自動的に検証することで、AIの「創造性」と「安全性」のバランスを取ることができます。三種の神器は、「あれば便利」という加点法ではなく、「なければ危険」という減点法の世界です。生成AI時代においても、これらの基盤があってこそ、安全かつ効率的な開発が可能になります。AIとの協業進化段階AIによる開発支援は、自動車の自動運転レベルに似た段階を経て進化しています：レベル0：AI支援なし - 従来の手動開発レベル1：AI支援（Chat） - LLMによる情報提供のみレベル2：AI支援（補完＋Chat） - GitHub Copilotなどの部分的補完レベル3：Agent（人間が支援） - AIが主に作業し、人間が確認・修正レベル4：Agent（人間の支援なし） - AIが自律的に開発レベル5：業務の完全自動化 - 要求からプロセス全体を自動生成2025年の開発環境は、主にレベル3〜4の間で推移しており、「副操縦士（Copilot）」から「操縦士（Pilot）」へと主役が交代しつつあります。生成AIの強みと限界生成AIの特性は以下のようにまとめられます：強み:膨大なコードパターンとベストプラクティスの学習自然言語からコードを生成する能力環境情報を参照し、実行結果から学習して修正する能力圧倒的な速度でのコード生成・実行・修正多言語・多フレームワークへの対応多様な実装アプローチの提案能力限界:ビジネスロジックやドメイン知識の理解が浅いコンテキストの保持と長期的な一貫性の維持が苦手複雑なコンパイラ制約がある言語での実装に課題「テストを無理に通そうとする」傾向参照の明示的な解決が苦手特にCLINEなどの環境統合型エージェントは、実行と修正のサイクルを驚くべき速度で回すことができ、「どんなエキスパートでも勝てないレベル」に達しつつあります。AIツールを使いこなすためには、「コンテキストを記述する能力」「ドメインを記述する能力」「AIの性能に対する直感」といった新しいスキルセットが求められます。zenn.devドライバー席を譲った後の新しい役割開発者が主導権（ドライバー席）をAIに譲った後、どのような新しい役割を担うべきでしょうか。助手席のナビゲーター最も有望なポジションは「助手席」です：AIに対して適切な指示と方向性を提供する生成された成果物の品質と整合性を評価するAIの能力を最大限に引き出すプロンプトエンジニアリングを行う後部座席への後退リスク一方で、単に「後部座席」に座り、AIの決定に従うだけの受動的な立場になるリスクも存在します：AIが示した選択肢から選ぶだけの存在に専門的理解が浅くなり、本質的な問題解決能力が衰える「運試し」と「結果責任」だけが残される状態 speakerdeck.comこの比喩はとても好きなので、将来的には「お前は後部座席に座るなよ」とか言いそうです。レッドボックスの内に対処する生成AIの発展に伴い、小説「BEATLESS」で描かれた「人類未到産物（レッドボックス）」の概念が現実味を帯びてきています。「超高度AIが生み出した、今の人類には理解できない超高度技術によってつくられた産物。「レッドボックス」という名称には、観測者から遠ざかる光が赤方偏移により赤から黒（赤外領域）へと変わるように、人類が必死に追いすがらなければいずれ遠ざかりブラックボックスになってしまうという意味が込められている。」現在のAIコーディングでも、AIが生成した複雑なコードや設計に対して、人間が「理解できない」状態に陥るリスクが現実化しつつあります。それらには以下のような対策が考えられます。意図的な単純化 - AIに「人間が理解できるようなシンプルな実装」を明示的に要求する解説の要求 - 実装だけでなく、その設計思想や動作原理の解説を求める段階的な理解 - 複雑な実装を小さな部分に分解して理解するテストによる挙動の可視化 - 振る舞いを詳細なテストで定義することで、ブラックボックス化を防ぐ継続的な学習 - AIが使用する最新の技術やパターンを人間側も学び続ける speakerdeck.comAIの能力が人間の理解を超えた「レッドボックス」となっても、その内部を理解するための努力を怠らないことが、「助手席」の位置を維持するために不可欠です。技術が人間から遠ざかっていくのを防ぐために、テスト駆動開発のような体系的なアプローチが重要な役割を果たします。ＢＥＡＴＬＥＳＳ 上 (角川文庫)作者:長谷 敏司KADOKAWAAmazonバイブス労働とAIコーディングバイブスコーディングとは何かAndrej Karpathy（OpenAI共同創業者）が提唱した\"vibe coding\"という概念が注目を集めています。「新しい種類のコーディングがあって、私はこれを\"vibe coding\"と呼んでいます。そこでは完全に\"vibe（雰囲気、直感）\"に身を任せ、指数関数的成長を歓迎し、コードそのものが存在していることさえ忘れてしまいます。」— Andrej Karpathyこのバイブスコーディングは、以下の特徴を持っています：自力で成果物を作り込まない - AIに指示を出すことに集中ノールックマージ - AIの提案を直感的に受け入れるエラー解決のアウトソース - 問題発生時にAIに解決を依頼理詰めな部分はAIに任せる - 人間は直感と判断に集中Andrej Karpathyが提唱する「バイブスコーディング」の考え方を適度に取り入れることで、生成AIとの協業をより効果的にできます。直感を大切に - AIとの対話では、時に論理的思考よりも直感が良い結果を生むことがある反復の高速化 - AIがエラー修正や実装変更を高速で行える特性を活かし、試行錯誤のサイクルを加速余分な労力の削減 - 自明な実装や定型コードの作成はAIに任せ、本質的な部分に集中創造的提案の受け入れ - AIが提案する予想外のアプローチに対してオープンな姿勢を持つただし、バイブスに任せすぎることなく、テストという客観的基準を常に維持することで、「ノリ」と「品質」の両立を図ります。特に、重要な意思決定やアーキテクチャに関わる部分では、専門知識に基づく判断を優先しましょう。learning.oreilly.comblog.lai.soバイブス労働の広がりバイブスコーディングの概念は、プログラミングの領域を超えて様々な知識労働にも応用できる「バイブス労働」という新たなパラダイムを生み出しています。バイブス労働では、AIを活用して直感的かつ効率的に成果を生み出す働き方が可能になります。バイブス労働の特徴には以下のようなものがあります：プロンプトクラフティング - AIに適切な指示を出すスキルが新たな専門性として価値を持つ創造的監督 - 細部の実装よりも、全体の方向性や品質の判断に人間の能力を集中させる反復と共進化 - 人間とAIが互いにフィードバックを与え合いながら成果物を進化させていくメタ認知の重要性 - 自分の思考プロセスを客観視し、AIとの協業に最適な役割分担を模索するバイブス労働の時代においては、「コードを書く」「文章を作成する」といった直接的な生産活動よりも、「何を作るべきか」「どのような価値を提供するか」という本質的な問いに答えることにより多くの時間とエネルギーを費やすことが可能になります。これにより、人間の創造性と直感が最大限に発揮される新しい働き方が実現するでしょう。生成AIとのテスト駆動開発の実践テスト駆動開発（TDD）の基本サイクル「Red-Green-Refactoring」を生成AIと組み合わせると、以下のようなアプローチが考えられます：t-wada.hatenablog.jpRed: AIを活用したテスト設計生成AIはこのステップで：ユーザーストーリーや仕様から、テストケースを提案自然言語からテストコードを生成人間が見落としがちなエッジケースを発見様々なテスト方法を提示人間は機能要件を明確に定義し、AIが提案するテストケースが要件を正確に反映しているか評価します。Green: AIによる実装の高速化生成AIはここで：失敗するテストを満たす実装コードを生成複数の実装アプローチを提案素早いプロトタイピングを実現テスト失敗時のデバッグを支援テストという明確な基準があるため、AIの出力の正確性を客観的に評価できます。Kent Beckの原則通り、まずはテストを通過することを優先し、きれいさは次のステップで追求します。Refactoring: AIと共にコードをきれいにするこのステップでは、生成AIは：コードの問題点や改善点を指摘し、リファクタリング案を提示適切なデザインパターンを提案命名、構造、コメントなどの品質向上策を提案パフォーマンス最適化を提案テストが引き続き成功することを確認しながら、コードの品質を向上させます。AIはコードの「きれいさ」に関する豊富な知識を持っていますが、プロジェクト固有の規約やアーキテクチャの理解には限界があるため、人間による最終確認が不可欠です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon人間の役割の根本的な変化：「望ましい状態」の設計者へ生成AIとの協働を通じて、私たちの仕事の本質が根本的に変わりつつあることを実感しています。これまで人間は「どうやって実現するか」という実行プロセスに多くの時間を費やしてきましたが、今後は「どうあるべきか」という理想状態の定義に集中することになるでしょう。現在と理想の継続的な調整日々の開発で感じるのは、人間が担うべき役割が「現在の状態を正確に把握し、望ましい状態を明確に宣言する」ことに収斂していく感覚です。生成AIは、この両者の差分を自律的に検知し、継続的に調整を行ってくれます。まるで優秀なアシスタントが、私たちの意図を汲み取り、現実と理想のギャップを埋め続けてくれるかのようです。意図の翻訳者としての新たな専門性この変化の中で、人間の新たな専門性は「AIに適切な仕事を持ってくること」になります。現実世界の複雑な文脈、ビジネス要求、制約条件をAIが理解できる形で翻訳し、伝達する能力が求められます。AIは実装を担い、人間は意図と方向性を示す—この役割分担により、より高度な価値創造が可能になっています。バイブスと直感の背後にある判断プロセス興味深いことに、AIが生成したアウトプットを評価する際、私たちは「これは良い」「これは違う」という直感的な判断を瞬時に下しています。この一見感覚的な判断の背後では、実は脳内で理想状態と現状を高速で照合しているのです。この体験は時に、ギャンブルのような興奮を伴います。AIが次々と提案を生成し、理想的な解決策が現れた時の喜びは、まるで大当たりを引いたような高揚感があります。しかし決定的に違うのは、適切な評価基準があれば必ず理想に到達できるという点です。問題設定力と評価基準の設計この新しいパラダイムで人間に求められるのは、「問題設定力」と「評価基準の設計力」です。何を解決すべきか、どのような状態が理想的なのか、そしてその達成度をどう測定するのか—これらの判断には、倫理観、美意識、長期的視野といった、数値化困難な人間固有の価値観が不可欠です。例えば、新しいプロダクト開発において、エンジニアは細かな実装から解放され、「ユーザーにとって本当に価値のある体験とは何か」という本質的な問いに集中できるようになります。新たな責任：賢明な意図の設計しかし、この変化は同時に重大な責任も生みます。AIが強力になればなるほど、人間が設定する「望ましい状態」の定義が社会に与える影響は計り知れません。偏った価値観や短絡的な目標設定は、AIの力によって増幅され、意図しない結果を招く可能性があります。だからこそ、多様な視点を取り入れ、長期的な影響を慎重に検討する「賢明な意図の設計」が、これからの時代の最も重要な人間の仕事となるでしょう。私たちは単なる実行者から、理想の設計者へと進化しているのです。バンディット問題の理論とアルゴリズム (機械学習プロフェッショナルシリーズ)作者:本多淳也,中村篤祥講談社Amazon直感的判断の背後にある無意識の照合プロセスバイブスコーディングで「なんかこのコード良さげ」と感じる瞬間、それは単なる感覚ではありません。実は私たちの脳が「理想的な状態に到達した」と無意識に判定している瞬間なのです。逆に「ここの実装はしっくりこないな」と感じるのは、頭の中で「期待している姿と実際の姿にズレがある」と検出している証拠でしょう。この生成→確認→判断→再生成…というシンプルな繰り返しは、人間の脳の報酬系を強く刺激します。理想的な結果が出た時の満足感、期待外れだった時の「もう一度」という衝動—これらの感情的な起伏が、開発プロセスに独特の中毒性をもたらしているのかもしれません。新たな役割への変貌の自覚「理想の状態を定義し、現実との差を埋める方向性を示す」という新しい役割が、今や私自身の働き方の中核になってきました。かつては実装の詳細に没頭していた自分が、いつの間にか「どうあるべきかを示し、AIと共に理想に近づけていく調整役」になっている—この変化に気づいた時、まるで別の職業に転職したような感覚を覚えます。品質を保証する仕組みの重要性ソフトウェア開発において、「あるべき姿を定義し維持するための検証の仕組み」は欠かせません。テストはコードの正しさを、継続的インテグレーションは全体の一貫性を、本番環境の監視システムは実際の動作を検証します。これらは人間の意図と実際のシステムの振る舞いの間に一貫性を保つ自動化された仕組みといえるでしょう。生成AIの時代においては、AIの創造性と自由度が高まるほど、これらの検証の仕組みはさらに重要になります。AIが生み出す無限の可能性の中から、本当に価値のあるものを選び取るための基準と検証プロセスこそが、人間が設計すべき最も重要な要素なのです。生成AIとTDDの相性の良さ生成AIとテスト駆動開発には、以下のような相性の良さがあります：明確な評価基準 - テストがAIの出力の正確性を評価する客観的基準となる繰り返しのフィードバック - 小さなサイクルによる継続的改善がAIとの協業に適している段階的な複雑性の増加 - 単純から複雑へ進むアプローチがAIの能力を引き出す品質保証の自動化 - テストによる安全網でAIコードの品質を保証責任の分担 - 人間がテストで要件を明確にし、AIが実装を担当という自然な役割分担人間の尺度のリファクタリング - AIが生成した複雑なコードを、TDDを通じて人間が理解・保守しやすい形に整理できるプログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ作者:フェリエンヌ・ヘルマンス,水野貴明,水野いずみ秀和システムAmazon効果的な生成AI活用のためのプラクティス1. テスト優先の指示AIに実装を依頼する前にテストを先に書くよう指示することで、テスト駆動の流れを維持します。テストを通じて機能要件を明確に定義し、AIがその要件を正確に理解することを促します。2. 段階的な複雑性の増加単純なテストケースから始め、徐々に複雑なケースを追加していくアプローチがAIとの協業に効果的です。AIが問題を段階的に理解し、複雑性を徐々に取り入れることができます。3. リファクタリングの明示的な依頼具体的なリファクタリングの観点（命名の改善、重複の排除、可読性向上など）を指定すると良い結果が得られます。焦点を絞ることでAIはより的確な改善提案ができます。4. 小さなサイクルの維持小さな機能単位でテスト→実装→リファクタリングのサイクルを回すことで、問題発生時の影響範囲を限定し、修正を容易にします。短いサイクルは、AIにとっても理解しやすく、効率的な協業を促進します。5. 三種の神器を活用したAI協業ワークフローバージョン管理:- AIが生成したコードを適切にコミットし、変更履歴を明確に残す- AIの提案ごとにブランチを作成して比較検討- 問題発生時に以前の状態に容易に戻れるよう準備テスティング:- 先にテストコードを作成し、明確な目標を設定- テストと実装の両方を継続的に改善- テストカバレッジをモニタリングして品質保証自動化:- CIパイプラインでAIコードの品質を自動検証- 静的解析とセキュリティスキャンでAIの盲点をカバー- 自動化されたガードレールで意図しない問題を防止三種の神器は、AIとの協業における品質と安全性を保証する基盤となります。6. 私が生成AIの時代にRustを選択する理由プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonテスト駆動開発は効果的ですが、テストだけではすべての不具合を検出できないという限界があります。特に生成AI時代において、型システムによる形式検証を提供するRustのような言語を選択することで、AIとの協業をより確実なものにできます。Rustの型システムは「軽量な形式検証」として機能し、テストでは捉えきれない問題を発見します。所有権と借用チェッカーによるメモリ安全性の数学的保証、代数的データ型による未定義状態の排除、トレイト境界によるコードの整合性の静的検証など、多くの利点があります。現時点では、生成AIがRustコードを一発でコンパイル通過させることは難しく、私の経験上も何度か修正が必要になることが多いです。しかし、これは欠点というよりも、Rustのコンパイラが持つ厳格なチェック機能が「ガードレール」として働いている証拠と言えるでしょう。AIが生成したコードでもコンパイラが厳密な検証を行うことで、多くの潜在的な問題が実行前に排除されます。Rustの型システムとテスト駆動開発は相互補完的な関係にあります。型システムがコード全体の整合性と安全性を保証し、テストがビジネスロジックの正確さを検証します。このような組み合わせにより、AIが生成したコードの品質担保と不具合検出の両面をカバーできます。テストだけでは見つけられない並行処理やメモリの問題も、Rustのコンパイラが捕捉してくれるのです。生成AI時代において、言語自体が提供する安全性保証は、人間のレビュー負担を軽減し、AIとの効率的な協業を実現します。コンパイラが通過するまでに何度か調整が必要でも、その過程自体がコードの品質向上に貢献していることを忘れてはなりません。ＲｕｓｔによるＷｅｂアプリケーション開発　設計からリリース・運用まで (ＫＳ情報科学専門書)作者:豊田優貴,松本健太郎,吉川哲史講談社Amazonおわりに生成AIとテスト駆動開発を組み合わせることで、「動作するきれいなコード」を効率的に実現できる可能性が広がっています。AIの創造性と生産性、人間の判断力と創造性を組み合わせるための鍵は、テスト駆動開発の原則と三種の神器という堅固な基盤です。t-wada氏の言葉を借りれば、「テスト駆動開発は、設計のひらめきが正しい瞬間に訪れることを保証するものではない。しかし、自信を与えてくれるテストときちんと手入れされたコードは、ひらめきへの備えであり、いざひらめいたときに、それを具現化するための備えでもある」のです。t-wada.hatenablog.jp生成AIはこの「備え」をより強固にする強力なパートナーとなります。AIとの協業においても、テスト駆動開発の原則を守りながら、AIの能力を最大限に活用することで、より良いソフトウェア開発が実現できるでしょう。","isoDate":"2025-03-19T11:10:25.000Z","dateMiliSeconds":1742382625000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"uvでbrowser_useを使用した環境構築したり比べたりするけど責任は取れない。","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957","contentSnippet":"はじめに三寒四温（さんかんしおん）というような天気が続いています。これは「三日寒くて四日温かい」という意味で、冬から春への移行期によく見られる気温の周期的な変動を表す言葉です。寒暖の差が激しいこの季節、AIに関しての情報収集よりみなさんが暖かい格好して体調崩さないほうが大切です。とはいえ、技術ブログなので技術的なことも書いていきます。今回はPythonのAI用ブラウザである「browser_use」ライブラリを使用して、AnthropicのClaude 3.5 SonnetとOpenAIのGPT-4oの情報収集能力を実際のコードとログで比較します。github.com実際になにかに使う場合にはドキュメントを読んで下さい。このブログはそのようなことに耐えられるように作られてはいません。docs.browser-use.com環境構築まず、uvを使って環境を構築します。uvはPythonの高速パッケージマネージャーで、依存関係の解決と仮想環境の構築が効率的に行えます。# 仮想環境を作成uv venv# 仮想環境を有効化（macOS/Linux）source .venv/bin/activate# 必要なライブラリをインストールuv pip install langchain-anthropic langchain-openai browser-use実装コードAnthropicのClaudeを使用するコード（3shake_ceo_anthropic.py）:import asynciofrom browser_use import Agentfrom langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model_name=\"claude-3-5-sonnet-latest\")task = \"株式会社スリーシェイクのCEOのXアカウントを教えて下さい\"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())OpenAIのGPT-4oを使用するコード（3shake_ceo_openai.py）:import asynciofrom browser_use import Agentfrom langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\"gpt-4o\")task = \"株式会社スリーシェイクのCEOのXアカウントを教えて下さい\"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())実行結果(uv run xx.py)Claude 3.5 Sonnet（Anthropic）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - Starting fresh with empty pageINFO     [agent] 🧠 Memory: Starting the task to find X (Twitter) account of 株式会社スリーシェイク's CEO. Step 1/100.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク company information on GoogleINFO     [agent] 🛠️  Action 1/1: {\"search_google\":{\"query\":\"株式会社スリーシェイク CEO Twitter X\"}}INFO     [controller] 🔍  Searched for \"株式会社スリーシェイク CEO Twitter X\" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Found search results showing the CEO's X accountINFO     [agent] 🧠 Memory: Found that the CEO of スリーシェイク is 吉田拓真 (Takuma Yoshida) and his X account is @taqqma_ikachan. Step 2/100.INFO     [agent] 🎯 Next goal: Visit the CEO's X profile to confirm informationINFO     [agent] 🛠️  Action 1/1: {\"click_element\":{\"index\":19}}INFO     [controller] 🖱️  Clicked button with index 19: 吉田 拓真 / スリーシェイク (@taqqma_ikachan) / XINFO     [agent] 📍 Step 3INFO     [agent] 👍 Eval: Success - I have confirmed that this is indeed the X account of the CEO of スリーシェイクINFO     [agent] 🧠 Memory: Found and confirmed that 吉田拓真 (Yoshida Takuma) is the CEO of スリーシェイク and his X account is @taqqma_ikachan. His profile confirms he is the 代表取締役社長 (CEO) of スリーシェイク.INFO     [agent] 🎯 Next goal: Task completed - provide the answerINFO     [agent] 🛠️  Action 1/1: {\"done\":{\"text\":\"株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。\",\"success\":true}}INFO     [agent] 📄 Result: 株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。INFO     [agent] ✅ Task completedINFO     [agent] ✅ SuccessfullyGPT-4o（OpenAI）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - The page is empty and there's no previous context to evaluate.INFO     [agent] 🧠 Memory: Need to find the X account of 株式会社スリーシェイク's CEO.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク CEO Twitter account on Google.INFO     [agent] 🛠️  Action 1/1: {\"search_google\":{\"query\":\"株式会社スリーシェイク CEO Twitter account\"}}INFO     [controller] 🔍  Searched for \"株式会社スリーシェイク CEO Twitter account\" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Google search is displaying links related to the CEO of 株式会社スリーシェイク and their X account.INFO     [agent] 🧠 Memory: Searching for 株式会社スリーシェイク CEO's Twitter account. Found potential link at index 26.INFO     [agent] 🎯 Next goal: Check the link at index 26 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {\"click_element\":{\"index\":26}}INFO     [controller] 🖱️  Clicked button with index 26: 株式会社スリーシェイク (@3shake_Inc) / XINFO     [agent] 📍 Step 3INFO     [agent] ⚠ Eval: Failed - The page requires login to access the X account information.INFO     [agent] 🧠 Memory: Currently on the login page of X; unable to access 株式会社スリーシェイク's CEO account information directly without logging in.INFO     [agent] 🎯 Next goal: Search again for 株式会社スリーシェイク's CEO X account from another source.INFO     [agent] 🛠️  Action 1/1: {\"search_google\":{\"query\":\"株式会社スリーシェイク CEO X account\"}}INFO     [controller] 🔍  Searched for \"株式会社スリーシェイク CEO X account\" in GoogleINFO     [agent] 📍 Step 4INFO     [agent] 👍 Eval: Success - Found a link that likely refers to the CEO's X account.INFO     [agent] 🧠 Memory: Trying to access 株式会社スリーシェイク CEO's X account via the link available at index 25.INFO     [agent] 🎯 Next goal: Click on the link at index 25 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {\"click_element\":{\"index\":25}}INFO     [controller] 🖱️  Clicked button with index 25: 内村一行/3-Shake (@KAZUYUKIUCHIMU) / XINFO     [agent] 📍 Step 5INFO     [agent] 👍 Eval: Success - Reached the login page for the user's X account.INFO     [agent] 🧠 Memory: Identified the CEO's Twitter handle as @KAZUYUKIUCHIMU, but login is required to access more information.INFO     [agent] 🎯 Next goal: Provide the CEO's X account and complete the task.INFO     [agent] 🛠️  Action 1/1: {\"done\":{\"text\":\"The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.\",\"success\":true}}INFO     [agent] 📄 Result: The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.INFO     [agent] ✅ Task completedINFO     [agent] ✅ Successfullyコードとログの詳細分析browser_useの動作browser_useライブラリは、AIモデルをWebブラウジングと組み合わせて情報検索を行うエージェントを作成します。このライブラリはログを詳細に記録しており、AIの意思決定プロセスを追跡できます：🚀 Starting task: タスクの開始📍 Step N: 各ステップの開始🤷 Eval: ページの状態評価🧠 Memory: AIのタスク理解と記憶🎯 Next goal: 次の目標設定🛠️ Action: 実行するアクション📄 Result: 最終結果モデル間の違い1. 検索クエリの違いClaude: 株式会社スリーシェイク CEO Twitter XGPT-4o: 株式会社スリーシェイク CEO Twitter accountこの微妙な違いが、初期の検索結果に影響しました。2. 問題解決アプローチの違いGPT-4oは会社の公式アカウント（@3shake_Inc）をまず確認しようとしましたが、ログイン要求に遭遇して別の戦略に切り替えました。一方、Claudeは直接CEOのアカウントを検索してアクセスしました。3. 情報確認の徹底度Claudeはプロフィールにアクセスして「代表取締役社長」の肩書きを確認しましたが、GPT-4oは内村一行氏（実際は取締役）をCEOと誤認したままでした。技術的考察browser_useの利点詳細なログ: browser_useは各ステップを詳細にログに記録するため、AIの判断プロセスを追跡できます。シンプルなAPI: わずか数行のコードでAIエージェントを作成でき、異なるモデルの比較テストが容易です。多様なモデルサポート: browser_useは複数のAIモデルをサポートしており、異なるモデル間の比較が容易です。docs.browser-use.com改善ポイントログから以下の改善点が考えられます：1.検索クエリの最適化# より精度の高いクエリを指定task = \"株式会社スリーシェイク 吉田拓真 CEO Xアカウント\"2. 複数情報源からの検証agent = Agent(    task=task,    llm=llm,    verify_sources=True,  # 複数ソースでの検証を促す（仮想的なパラメータ）)3. エラー時の代替戦略# ログイン画面に遭遇した場合の対処を明示的に指示agent = Agent(    task=task,    llm=llm,    login_strategy=\"search_alternative\",  # ログイン要求時の戦略)実務への応用AIエージェントを活用する際は、以下の点に注意すると良いでしょう：1. 正確なプロンプトの設計# より具体的なタスク指定task = \"株式会社スリーシェイクの代表取締役社長/CEOの公式Xアカウントを会社の公式情報から特定してください\"2. 複数モデルでの検証# 複数モデルの結果を比較results = {}for model_name in [\"claude-3-5-sonnet-latest\", \"gpt-4o\"]:    agent = create_agent_for_model(model_name)    results[model_name] = await agent.run()# 結果の一致度を確認compare_results(results)3. 結果の人間によるレビュー:特に重要な意思決定には、AIの判断をそのまま信頼するのではなく、人間による最終チェックを行うプロセスを組み込むことが重要です。結果に責任が取れるような仕組みにはまだなっていなさそうです。テスト的になにかのチェックを行わせるというのは必要かと思いました。まとめ今回の実験では、特別なプロンプトエンジニアリングやチューニングを一切行わず、同じコードで二つのモデルを実行した結果を比較しました。思いつきで雑に実行しただけなのに、興味深い違いが出てきたのは面白いポイントです。Claudeは正確にCEOを特定した一方、GPT-4oは取締役を誤ってCEOと判断しました。この結果は、AIエージェントがまだ完璧ではなく、特に重要な情報収集には複数の検証プロセスを設けることの重要性を示しています。今後も気軽に試せるツールとして、browser_useとuvの組み合わせは便利そうです。特に複雑な設定や調整をしなくても、こうした比較実験が簡単にできるのが魅力的です。docs.browser-use.com注：コード例は概念的なものであり、実際のbrowser_use APIとは異なる場合があります。詳細は公式ドキュメントを参照してください。","isoDate":"2025-03-19T04:19:57.000Z","dateMiliSeconds":1742357997000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\r\rイベント名:  Developers Summit 2025\r\r公式URL: https://event.shoeisha.jp/devsumi/20250213\r\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\r\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\r\r公式URL: https://platformengineering.connpass.com/event/342670/\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\r\rイベント名: SRE Kaigi 2025\r\r公式URL: https://2025.srekaigi.net/\r\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\r\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\r\rイベント名: Cloud Native Days Winter 2024\r\r公式URL:https://event.cloudnativedays.jp/cndw2024/\r\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREの前に","link":"https://speakerdeck.com/nwiizo/srenoqian-ni","contentSnippet":"2024年11月06日(水) 18:00～19:00の予定に遅刻してしまい、大変申し訳ございませんでした。お詫びとして、当初非公開予定であった資料を公開させていただきます。元々、公開する予定ではなかったので補足が足りない部分などあると思いますのでご容赦下さい。\r\rブログなどで補足情報出すかもなので気になればフォローしてください\r- https://syu-m-5151.hatenablog.com/\r- https://x.com/nwiizo\r\r\rSREの前に - 運用の原理と方法論\r公式URL: https://talent.supporterz.jp/events/2ed2656a-13ab-409c-a1d9-df8383be25fd/","isoDate":"2024-11-06T05:00:00.000Z","dateMiliSeconds":1730869200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2024年版 運用者たちのLLM","link":"https://speakerdeck.com/nwiizo/2024nian-ban-yun-yong-zhe-tatinollm","contentSnippet":"Cloud Operator Days 2024 クロージングイベント\rhttps://cloudopsdays.com/closing/\r\rとても、端的に言うと「プロンプトエンジニアリングをしよう」って話。\rこの発表資料は、LLM（大規模言語モデル）によるIT運用の可能性と課題を探っています。AIOpsの概念を基に、LLMがインシデント対応、ドキュメンテーション、コード分析などの運用タスクをどのように改善できるかを説明しています。同時に、LLMの「幻覚」や不完全性といった課題も指摘し、適切な利用方法やプロンプトエンジニアリングの重要性を強調しています。\r\r登壇時ブログ\rhttps://syu-m-5151.hatenablog.com/entry/2024/09/06/154607","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineering と SRE の門 ","link":"https://speakerdeck.com/nwiizo/platform-engineering-to-sre-nomen","contentSnippet":"Platform Engineering とSREの門 というタイトルで登壇しました。入門のタイポではありません。\r\rイベント名: Platform Engineering Kaigi 2024\rイベントURL:https://www.cnia.io/pek2024/\r\r登壇ブログ:『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024\rhttps://syu-m-5151.hatenablog.com/entry/2024/07/09/215147","isoDate":"2024-07-09T04:00:00.000Z","dateMiliSeconds":1720497600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"運用者の各領域で向き合うLLM","link":"https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm","contentSnippet":"運用者の各領域で向き合うLLM というタイトルで登壇しました。\r\rイベント名: Cloud Operator Days Tokyo 2024 \rイベントURL:https://cloudopsdays.com/","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"可観測性ガイダンス","link":"https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu","contentSnippet":"可観測性ガイダンスというタイトルで登壇してきました。\r\rイベント名: オブザーバビリティ再入門 - 大切さと高め方を知ろう！\rイベントURL: https://mackerelio.connpass.com/event/316449/\r\r\r# ブログでいくつかの可観測性に関する書籍のまとめを投稿しました。\r5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文\rhttps://syu-m-5151.hatenablog.com/entry/2024/04/16/180511\r\rもう一度読むObservability Engineering\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/06/090014\r\r盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/10/121047","isoDate":"2024-06-04T04:00:00.000Z","dateMiliSeconds":1717473600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"書を捨てよ、現場へ出よう","link":"https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you","contentSnippet":"書を捨てよ、現場へ出よう このSRE本がすごい！2024年 LT版というタイトルで登壇してきました。\r\rSREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜\rhttps://findy.connpass.com/event/311323/\r\r元ブログはこちら\r\rこのSRE本がすごい！2024年版\rhttps://syu-m-5151.hatenablog.com/entry/2024/01/26/165255\r\r登壇ブログはこちら\r\r『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","isoDate":"2024-03-12T04:00:00.000Z","dateMiliSeconds":1710216000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"走馬灯のIaCは考えておいて","link":"https://speakerdeck.com/nwiizo/zou-ma-deng-noiachakao-eteoite","contentSnippet":"走馬灯のIaCは考えておいてというタイトルで登壇してきました\r\r技術的負債に向き合う Online Conference\rhttps://findy.connpass.com/event/297813/\r\r走馬灯のセトリは考えておいての短編はどれも面白いのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015282/\r\r登壇ブログ |『走馬灯のIaCは考えておいて』というタイトルで登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","isoDate":"2023-11-21T05:00:00.000Z","dateMiliSeconds":1700542800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとPlatform Engineerの交差点","link":"https://speakerdeck.com/nwiizo/sretoplatform-engineernojiao-chai-dian","contentSnippet":"Platform Engineering Meetup #5 #PFEM\rhttps://platformengineering.connpass.com/event/295048/ \r\rSREとPlatform Engineerの交差点: 2つの領域の交差と組織への適用 というタイトルで登壇します。\r\r登壇ブログ |『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました\rhttps://syu-m-5151.hatenablog.com/entry/2023/10/05/233555\r\rグレイラットの殺人 ワシントン・ポーが面白かったのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015569/","isoDate":"2023-10-05T04:00:00.000Z","dateMiliSeconds":1696478400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREからPlatform Engineerへの拡大","link":"https://speakerdeck.com/nwiizo/srekaraplatform-engineerhenokuo-da","contentSnippet":"SREからPlatform Engineerへの拡大 というタイトルで登壇してきました\r\rCloud Operator Days Tokyo 2023 運用の新時代　〜Effortless Operation〜\rhttps://cloudopsdays.com/\r\rクラウドインフラ運用技術者のための年次イベント「Cloud Operator Days Tokyo 2023」の見所を紹介\rhttps://cloud.watch.impress.co.jp/docs/news/1518302.html\r\rSREからPlatform Engineerへの拡大 というタイトルで登壇しました - じゃあ、おうちで学べる  https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412 \r\r登壇しかないので20分しかないのでｷﾞｭｯとしてしまいました。","isoDate":"2023-08-09T04:00:00.000Z","dateMiliSeconds":1691553600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"nwiizo"},"buildId":"2SXCzZd6bN-as7WP5p_Se","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>