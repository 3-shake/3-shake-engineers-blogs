<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon shortcut" type="image/png" href="https://blog.3-shake.com/logo.png"/><title>nwiizo | 3-shake Engineers&#x27; Blogs</title><meta property="og:title" content="nwiizo"/><meta property="og:url" content="https://blog.3-shake.com/members/nwiizo"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="3-shake Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.3-shake.com/og.png"/><link rel="canonical" href="https://blog.3-shake.com/members/nwiizo"/><meta name="next-head-count" content="10"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/ca0df06cc4f85fc8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ca0df06cc4f85fc8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-b8f8d6679aaa5f42.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-b671ab60a2eabb59.js" defer=""></script><script src="/_next/static/chunks/pages/_app-aef75d70891be704.js" defer=""></script><script src="/_next/static/chunks/983-16739fbc4765e5fb.js" defer=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-fa4563d96c58aa0a.js" defer=""></script><script src="/_next/static/Y2JlT7Opo5PUCh8eHSYgf/_buildManifest.js" defer=""></script><script src="/_next/static/Y2JlT7Opo5PUCh8eHSYgf/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;700&family=Roboto:wght@300;400;500;700&display=swap">@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjr0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5vAA.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Me5g.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9vAA.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlvAA.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA88,U+1FA90-1FABD,U+1FABF-1FAC5,U+1FACE-1FADB,U+1FAE0-1FAE8,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA88,U+1FA90-1FABD,U+1FABF-1FAC5,U+1FACE-1FADB,U+1FAE0-1FAE8,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTVOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0330,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2034-2037,U+2057,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2102,U+210A-210E,U+2110-2112,U+2115,U+2119-211D,U+2124,U+2128,U+212C-212D,U+212F-2131,U+2133-2138,U+213C-2140,U+2145-2149,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B6,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTUGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8B1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA88,U+1FA90-1FABD,U+1FABF-1FAC5,U+1FACE-1FADB,U+1FAE0-1FAE8,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v40/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmSU5fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu72xKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu5mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu7mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu4WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu7WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu7GxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOmCnqEu92Fr1Mu4mxKKTU1Kg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmEU9fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v32/KFOlCnqEu92Fr1MmWUlfBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.svg" alt="3-shake Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">3-shake<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a class="site-header__link" href="/feed.xml">RSS</a><a href="https://jobs-3-shake.com/" class="site-header__link">Recruit</a><a href="https://3-shake.com/" class="site-header__link">Company</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/nwiizo.jpeg" alt="nwiizo" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__name">nwiizo</h1><p class="member-header__bio">The Passionate Programmer</p><div class="member-header__links"><a href="https://twitter.com/nwiizo" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@nwiizo" width="22" height="22"/></a><a href="https://github.com/nwiizo" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@nwiizo" width="22" height="22"/></a><a href="https://nwiizo.github.io/" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-08-04T09:47:13.000Z" class="post-link__date">a day ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/08/04/184713" class="post-link__main-link"><h2 class="post-link__title">運用では確認以外を自動化したいという時もある</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a><div class="post-link__new-label">NEW</div></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-08-02T13:04:40.000Z" class="post-link__date">3 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/08/02/220440" class="post-link__main-link"><h2 class="post-link__title">@Hiroki__IT が目の前にやってきて私にIstioのこと教えてくれた。- Istio in Action の読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-31T13:40:37.000Z" class="post-link__date">5 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/31/224037" class="post-link__main-link"><h2 class="post-link__title">え、SLOもRPGで学びたいですか？</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-31T01:41:51.000Z" class="post-link__date">6 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/31/104151" class="post-link__main-link"><h2 class="post-link__title">自分が書いたコードより目立つな - エンジニアがバズったので自戒</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-22T07:57:42.000Z" class="post-link__date">14 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/22/165742" class="post-link__main-link"><h2 class="post-link__title">シェルスクリプトのTipsを書いたブログがバズった。あるいは無名な若者にも優しくする。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-15T14:45:13.000Z" class="post-link__date">21 days ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/15/234513" class="post-link__main-link"><h2 class="post-link__title"> トラフィック制御を実装したIstioの設定をKialiなどで確認する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-10T03:04:48.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/10/120448" class="post-link__main-link"><h2 class="post-link__title">Istioによるトラフィック制御で仮想待合室システムを目指すけどもやな</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-09T12:51:47.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/09/215147" class="post-link__main-link"><h2 class="post-link__title">『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-09T04:00:00.000Z" class="post-link__date">a month ago</time></div></a><a href="https://speakerdeck.com/nwiizo/platform-engineering-to-sre-nomen" class="post-link__main-link"><h2 class="post-link__title">Platform Engineering と SRE の門 </h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-07-05T07:36:59.000Z" class="post-link__date">a month ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/07/05/163659" class="post-link__main-link"><h2 class="post-link__title">数字に振り回されず完璧を目指さない為に - Implementing Service Level Objectives の読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-06-28T04:00:00.000Z" class="post-link__date">a month ago</time></div></a><a href="https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm" class="post-link__main-link"><h2 class="post-link__title">運用者の各領域で向き合うLLM</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-06-21T04:58:55.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/06/21/135855" class="post-link__main-link"><h2 class="post-link__title">Go開発者のための遊び場を用意する - Kindで始めるKubernetesの開発環境構築</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-06-19T06:42:01.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/06/19/154201" class="post-link__main-link"><h2 class="post-link__title">知識のunlearningをちゃんとやる - Learning Go, 2nd Editionの読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-06-06T04:10:51.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/06/06/131051" class="post-link__main-link"><h2 class="post-link__title">オブザーバビリティ再入門みたいなイベントで登壇しました。再入門だけが創造的な勉強会みたいな主張をした。 #o11y_mackerel</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-06-04T04:00:00.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu" class="post-link__main-link"><h2 class="post-link__title">可観測性ガイダンス</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-05-31T03:28:50.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/05/31/122850" class="post-link__main-link"><h2 class="post-link__title">Fiber v3 を使ったが変更点を確認だけして手癖で解決した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-05-11T02:55:18.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/05/11/115518" class="post-link__main-link"><h2 class="post-link__title">自動化するならちゃんとエラーを出せ。想定しろ。不安になれ。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-05-10T03:10:47.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/05/10/121047" class="post-link__main-link"><h2 class="post-link__title">盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-05-06T00:00:14.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/05/06/090014" class="post-link__main-link"><h2 class="post-link__title">もう一度読むObservability Engineering</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-05-02T02:49:58.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/05/02/114958" class="post-link__main-link"><h2 class="post-link__title">リトライ処理を追加するとバッチが安定することがあることもそこそこあるので「avast/retry-go」を使ってみる</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-04-16T09:05:11.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/04/16/180511" class="post-link__main-link"><h2 class="post-link__title">5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-04-09T07:08:24.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/04/09/160824" class="post-link__main-link"><h2 class="post-link__title">OpenTelemetryについて調べる時に見るページ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-04-08T07:59:09.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/04/08/165909" class="post-link__main-link"><h2 class="post-link__title">なれる!SRE - Becoming SREで学んだこと</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-04-05T05:51:03.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/04/05/145103" class="post-link__main-link"><h2 class="post-link__title">go-rod/rod でブラウザ自動化とWebスクレイピングをやっていく</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-28T14:06:04.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/28/230604" class="post-link__main-link"><h2 class="post-link__title">Platform Engineering on Kubernetes を読んでCloud Native の現在地を理解する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-23T10:47:02.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/23/194702" class="post-link__main-link"><h2 class="post-link__title">はてなブログの記事をGitHubに自動でPushする方法</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-22T03:28:47.000Z" class="post-link__date">4 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/22/122847" class="post-link__main-link"><h2 class="post-link__title">nwiizoはなぜSpeaker Deckに上げた資料をブログにするのか？</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-20T07:44:34.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/20/164434" class="post-link__main-link"><h2 class="post-link__title">データエンジニアリングの要諦の後ろ髪を掴む - Fundamentals of Data Engineeringを読んで</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-13T23:36:05.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/14/083605" class="post-link__main-link"><h2 class="post-link__title">Docker Desktop のアンインストールと Lima の導入</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-13T07:49:51.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951" class="post-link__main-link"><h2 class="post-link__title">『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-03-12T04:00:00.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you" class="post-link__main-link"><h2 class="post-link__title">書を捨てよ、現場へ出よう</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=speakerdeck.com" width="14" height="14" class="post-link__site-favicon"/>speakerdeck.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/nwiizo"><img src="/avatars/nwiizo.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">nwiizo</div><time dateTime="2024-02-06T02:03:41.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://syu-m-5151.hatenablog.com/entry/2024/02/06/110341" class="post-link__main-link"><h2 class="post-link__title">私のメンターがくれた初めてのターミナル管理、それはtmuxで私は新卒でした。</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=syu-m-5151.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>syu-m-5151.hatenablog.com</div></a></article></div><div class="post-list-load"><button class="post-list-load__button">LOAD MORE</button></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->3-shake Inc.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"The Passionate Programmer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"運用では確認以外を自動化したいという時もある","contentSnippet":"はじめにこんにちは、ウェブオペレーターの皆さん。今日は、運用の自動化を推進しつつ、重要な確認ステップを保持する方法について、私が開発したツール「toi」を交えてお話しします。また、これらのツールが完全な自動化が許されない環境や状況でも活用できる方法に焦点を当てていきます。マスタリングLinuxシェルスクリプト 第2版 ―Linuxコマンド、bashスクリプト、シェルプログラミング実践入門作者:Mokhtar Ebrahim,Andrew Mallettオライリー・ジャパンAmazontoiの開発背景toiの開発は、私自身がウェブオペレーションの現場で直面した具体的な課題から始まりました。完全な自動化を目指す一方で、重要な判断には人間の介入が必要な場面が多々ありました。例えば：スクリプト1の実行結果を確認し、その出力をスクリプト2の入力としてコピーペーストする必要がある場合。本番環境で実行する前に、一旦出力を確認するために実行コマンドを削除して dry-run する必要がある場合。これらの操作は、既存の自動化ツールでは効率的に処理することが難しく、人間の手動介入が必要でした。そこで、Unixパイプラインの柔軟性を活かしつつ、必要な箇所で人間の判断を挟むことができるツールの開発を考えました。これが toiの誕生につながったのです。運用自動化の現実と課題運用の自動化は効率性と一貫性を高める素晴らしい方法です。しかし、現実には完全な自動化が許されない、あるいは望ましくないケースが多々あります。組織のポリシー：特定の操作に人間の承認が必須な場合リスク管理：ミスの影響が甚大な操作異常検知：通常とは異なる状況で、人間の判断が必要な場合段階的な自動化：完全自動化への移行過程で、部分的に人間の確認を残す必要がある場合これらの状況下では、完全な自動化と手動操作の間でバランスを取る必要があります。そこで登場するのが「toi」です。toiの紹介「toi」（発音は「とい」）は、Unixスタイルのパイプラインに対話的な確認ステップを追加するコマンドラインツールです。このツールを使用することで、自動化プロセスに人間の判断を効果的に組み込むことができます。github.comtoiの主な特徴パイプライン内での対話的確認カスタマイズ可能なタイムアウトデフォルト応答オプション柔軟なプロンプトメッセージ軽量で高速な動作他のUnixツールとの優れた互換性toiの技術的詳細toiは、Go言語で実装されています。その主な技術的特徴は以下の通りです：標準入出力の効率的な処理: Goのio/ioutilパッケージを活用し、大量のデータでも効率的に処理します。並行処理: Goのgoroutineを使用し、タイムアウト処理と入力待ちを並行して行います。シグナルハンドリング: SIGINT（Ctrl+C）などのシグナルを適切に処理し、ユーザーが操作を中断できるようにしています。toiは、Unixパイプラインとの親和性が高く、学習コストが低いという点で他のツールと差別化されています。完全自動化が許されない状況でのtoiの活用重要データの更新確認   echo \"UPDATE user_data SET status = 'INACTIVE' WHERE last_login \u003c '2023-01-01';\" | toi -p \"長期間ログインのないユーザーを非アクティブにしますか？ (y/n): \" | mysql user_db   ユーザーステータスの一括変更など、重要な更新操作の前に確認が必要な場合に有効です。システム設定変更の承認   ./generate_config_update.sh | toi -t 300 -p \"新しい設定を適用しますか？ (y/n): \" | sudo apply_config   システム設定の変更に必ず人間のレビューを要求している場合に使用できます。大規模データ操作の制御   find /data/old_records -type f -mtime +365 | toi -y -p \"1年以上経過した記録を削除しますか？ (Y/n): \" | xargs rm   大量のデータ削除など、影響範囲が大きい操作で人間の判断を仰ぐことができます。重要な自動処理の承認   echo \"実行する重要な処理の内容\" | toi -t 600 -p \"この重要な処理を実行しますか？ (y/n): \" \u0026\u0026 ./run_critical_process.sh   組織のポリシーで、重要な自動処理の実行前に人間の承認が必要な場合に利用できます。toiによる運用改善のポイントリスク管理の向上: 重要な操作前に人間の判断を介在させ、潜在的なリスクを軽減します。段階的自動化の実現: 完全自動化への移行過程で、徐々に人間の介入を減らしていくことができます。異常検知と対応: 通常と異なる状況を人間に通知し、適切な判断を仰ぐことができます。操作の記録: 重要な操作に対する承認プロセスを記録し、後日の確認に備えることができます。柔軟なワークフロー構築: 既存の自動化スクリプトに容易に組み込め、段階的な改善が可能です。導入と使用方法toiは簡単に導入できます。Go環境がある場合は以下のコマンドでインストールできます：go install github.com/nwiizo/toi@latestまたは、GitHubリリースページから直接バイナリをダウンロードすることもできます。基本的な使用方法は以下の通りです：command1 | toi [オプション] | command2主なオプション：- -t, --timeout int: タイムアウト時間（秒）を設定- -y, --yes: 入力がない場合にデフォルトでYesを選択- -n, --no: 入力がない場合にデフォルトでNoを選択- -p, --prompt string: カスタムプロンプトメッセージを設定制限事項と注意点現在のバージョンでは、複雑な条件分岐やループ処理には対応していません。大量のデータを扱う場合、メモリ使用量に注意が必要です。セキュリティ上の理由から、リモート実行には適していません。まとめ「toi」を活用することで、完全な自動化が許されない状況下でも、運用の効率化と人間の判断の両立が可能になります。組織のポリシーやリスク管理など、様々な理由で人間の介入が必要な場面で、toiは自動化と手動操作のバランスを取るための強力なツールとなります。自動化を推進しながらも、クリティカルな判断には人間の介入を残すという、バランスの取れたアプローチを実現するツールとして、ぜひ「toi」を検討してみてください。組織の要件に合わせて柔軟に運用プロセスを設計し、効率性と安全性の両立を図ることができます。あれがほしいとかこの機能が無いとはPRいただきたいです。あと、みんなGithubにStarして♥","link":"https://syu-m-5151.hatenablog.com/entry/2024/08/04/184713","isoDate":"2024-08-04T09:47:13.000Z","dateMiliSeconds":1722764833000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"@Hiroki__IT が目の前にやってきて私にIstioのこと教えてくれた。- Istio in Action の読書感想文","contentSnippet":"はじめにマイクロサービスアーキテクチャの台頭により、サービスメッシュ技術は現代のクラウドネイティブ環境において外せない選択肢の一つとなっています。 その理由は明確です。マイクロサービスに求められる非機能要件の多くは類似しており、これをアプリケーション側で個別に実装すると、開発者やインフラエンジニアの負担が増大するからです。ここで登場するのがサービスメッシュです。サービスメッシュの採用により、これらの非機能要件をインフラ層で一元管理することが可能となり、アプリケーション開発者とインフラエンジニアの責務を明確に分離できます。つまり、各エンジニアが自身の専門領域にフォーカスできるのです。これは単なる効率化ではなく、イノベーションを加速させるためサービス開発する上での労苦をなくします。そして、サービスメッシュの世界で圧倒的な存在感を放っているのがIstioです。その包括的な機能と広範な採用で、Istioは多くの企業から信頼を得ています。「Istio in Action」は、このIstioの真髄を理解し、実践的に活用するための道標となる一冊です。Istio in Action作者:Posta, Christian E.,Maloku, RinorManningAmazonしかし、ここで一つの疑問が浮かびます。なぜ日本国内ではIstioの普及が進んでいないのでしょうか？ 多くの企業がマイクロサービスへの移行を検討している一方で、サービスメッシュ技術の導入には慎重な姿勢を示しています。例えば、国内の主要なクラウドネイティブ技術カンファレンスであるCloudNative Days Tokyoでも、Istioに関するセッションの数は比較的少ない印象です。国内のセッションだと「1年間のシステム運用を通して分かったIstioの嬉しさと活用における注意点」も好きです。もう誰にも歌わなくなった。大好きなIstioの歌を俺は大きな声で歌うよ 。しかし、希望はあります。同イベントのハンズオンではIstioの利用が見られ、実践的な学習の機会が提供されています。以下の動画は、サービスメッシュの基本的な使用方法を学ぶための絶好の入門ガイドです。クラウドネイティブなシステムを触る予定がある方は、ぜひご覧ください。www.youtube.com本読書感想文の目的は明確です。Istioを実際に採用していない、あるいは採用の予定がない読者の方々にも、Istioの魅力と可能性を伝えることです。なぜなら、サービスメッシュ技術は現代のソフトウェアアーキテクチャの重要なトレンドの一つであり、その概念や原則を理解することは、今後のIT業界の動向を把握する上で非常に有益だからです。glossary.cncf.io「Istio in Action」は、Istioの基本概念から高度な運用テクニック、さらにはカスタム拡張まで、幅広いトピックをカバーする包括的な指南書です。著者のChristian Posta氏とRinor Maloku氏は、豊富な実務経験と深い技術的知見を基に、理論と実践のバランスの取れた解説を提供しています。本書の真の価値は、単なる技術解説に留まらない点にあります。Istioの導入がもたらす組織的な影響や、実際の運用環境での課題にも焦点を当てているのです。これは、Istioを実際のプロダクション環境に導入し、効果的に活用しようとする読者にとって、まさに宝の山と言えるでしょう。本書は2022年3月に出版されており、本読書感想文を執筆している2024年8月時点では約2年半が経過しています。Istioは急速に進化を続けているため、技術的な詳細や最新の機能については、必ず公式ドキュメントを参照することをお勧めします。しかし、本書で説明されている基本的な概念、アーキテクチャの原則、そして実践的なアプローチは、時代を超えて価値があり、Istioを理解し活用する上で重要な基盤となります。istio.io本読書感想文では、「Istio in Action」の各章の主要な内容を要約し、その実践的な価値と2024年現在の技術動向との関連性を考察します。また、必要に応じて最新の情報との相違点にも触れていきます。Istioを学び、導入を検討している開発者、SRE、アーキテクトの方々はもちろん、サービスメッシュ技術に興味を持つ全ての読者にとって、本書がどのような価値を提供するかを明らかにしていきます。また、本読書感想文の執筆にあたり、@Hiroki__ITさんから多大なご貢献をいただきました。専門知識によるレビューのおかげで、本文の方向性、品質と正確性が大幅に向上しました。この場を借りて、ご尽力に心から感謝申し上げます。彼のIstioに関する有益なブログはこちらでご覧いただけます。Istioについてさらに深く学びたい方には、このリソースを強くお勧めします。彼も大きな声で歌ってます。みんなも好きな技術について歌ってほしいです。hiroki-hasegawa.hatenablog.jpはじめに2024年現在の技術動向との比較コアアーキテクチャの安定性主要な進化と新機能Part 1 Understanding Istio1 Introducing the Istio service meshクラウドネイティブアーキテクチャの課題サービスメッシュとIstioの導入Istioの主要機能と利点1. サービスレジリエンス2. トラフィック制御3. セキュリティ4. 可観測性Istioと他のテクノロジーとの比較Istioの実際の使用シナリオまとめ2 First steps with IstioIstioのインストールと基本設定Istioのコントロールプレーンの理解アプリケーションのデプロイとサービスメッシュへの統合トラフィック制御と高度なルーティング観測可能性とレジリエンスまとめ3 Istio's data plane: The Envoy proxyEnvoyプロキシの概要と主要機能Envoyの設定と動作Envoyの動的設定と xDS APIEnvoyの可観測性とトラブルシューティングIstioとEnvoyの関係実践的な応用と提案まとめPart 2 Securing, observing, and controlling your service’s network traffic4 Istio gateways: Getting traffic into a clusterIstio Gatewayの基本概念Gateway設定の実践セキュリティ設定高度な機能と運用上の考慮事項実践的な応用と提案まとめ5 Traffic control: Fine-grained traffic routingトラフィック制御の基本概念カナリアリリースとトラフィックシフティングトラフィックミラーリングFlaggerを使用した自動カナリアデプロイメントクラスター外部へのトラフィック制御実践的な応用と提案まとめ6 Resilience: Solving application networking challengesクライアントサイドロードバランシングロケーションアウェアロードバランシングタイムアウトとリトライサーキットブレーキング実践的な応用と提案まとめ7 Observability: Understanding the behavior of your servicesIstioの観測可能性アーキテクチャメトリクス収集の詳細分散トレーシングの実装アクセスロギングの高度な設定観測可能性データの活用まとめ8 Observability: Visualizing network behavior with Grafana, Jaeger, and KialiGrafanaを用いたメトリクスの可視化分散トレーシングとJaegerKialiを用いたサービスメッシュの可視化実践的な応用と提案まとめ9 Securing microservice communicationサービス間認証（mTLS）エンドユーザー認証（JWT）認可ポリシー外部認可サービスとの統合実践的な応用と提案まとめPart 3 Istio day-2 operations10 Troubleshooting the data plane技術的詳細と実践的応用データプレーンの同期状態の確認Kialiを使用した設定の検証Envoy設定の詳細分析アクセスログの活用まとめ11 Performance-tuning the control plane技術的詳細と実践的応用コントロールプレーンの目標パフォーマンスに影響を与える要因パフォーマンスモニタリングパフォーマンス最適化技術実践的な応用と提案まとめPart 4 Istio in your organization12 Scaling Istio in your organizationマルチクラスターサービスメッシュの利点技術的詳細と実践的応用マルチクラスター導入モデルクラスター間のワークロード発見クラスター間の接続性クラスター間の認証と認可実践的な応用と提案まとめ13 Incorporating virtual machine workloads into the mesh技術的詳細と実践的応用Istioの最新VMサポート機能VMワークロードの統合プロセスセキュリティと観測可能性実践的な応用と提案まとめ14 Extending Istio on the request path技術的詳細と実践的応用Envoyフィルターの理解EnvoyFilterリソースの使用LuaスクリプトによるカスタマイズWebAssemblyによる拡張実践的な応用と提案まとめおわりにおまけ2024年現在の技術動向との比較「Istio in Action」が2022年3月に出版されてから2年半が経過し、Istioは継続的な進化を遂げています。2024年8月現在、Istioの最新安定版は1.22でありistio.ioこの間に多くの機能追加や改善が行われました。しかし、Istioのコアアーキテクチャは大きく変わっていません。blog.christianposta.comコアアーキテクチャの安定性Istioの基本的な設計哲学と主要コンポーネントは維持されています：カスタムリソースによるEnvoy設定の抽象化: VirtualServiceやDestinationRule,GatewayなどのCRDを使用して、トラフィックを制御する為に複雑なEnvoy設定を抽象化する仕組みは変わっていません。コントロールプレーンからデータプレーンへの設定配布: istiodがxDS APIを通じてEnvoyプロキシに設定を配布する方式は継続されています。サイドカーインジェクション: istio-initとistio-proxyコンテナを自動的にPodにインジェクトする仕組みは、依然としてIstioの中核機能です。トラフィックキャプチャ: istio-iptablesを使用したトラフィックのキャプチャと制御の仕組みも変わっていません。主要な進化と新機能アンビエントメッシュ（Ambient Mesh）: Istio 1.19で導入されたアンビエントメッシュは、サービスメッシュのパラダイムシフトを目指しています。従来のサイドカーモデルと比較して、以下の利点があります：リソース効率の向上: サイドカーレスアーキテクチャにより、CPUとメモリの使用量が大幅に削減。スケーラビリティの改善: 大規模クラスターでのパフォーマンスが向上。導入の簡素化: アプリケーションコンテナの変更が不要。 しかし、2024年8月時点でベータ版に昇格したみたいです。しかし、本番環境での採用には慎重なアプローチが必要です(まだ、αだと思っていたんですけど昇格していたみたいです。@toversus26さんに教えてもらいました。ありがとうございます。)。istio.ioWebAssembly (Wasm) の進化: Envoyの拡張性が大幅に向上し、多言語でのカスタムフィルター開発が可能になりました。例えば：Rust、C++、AssemblyScriptなどでのフィルター開発が可能。パフォーマンスオーバーヘッドが従来のLuaスクリプトと比較して10-20%改善。セキュリティが強化され、サンドボックス環境での実行が可能に。istio.ioマルチクラスター・マルチクラウド対応の強化:複数のKubernetesクラスター間でのサービスディスカバリとロードバランシングが改善。異なるクラウドプロババイダー（AWS、GCP、Azure）間でのシームレスな統合が可能に。ネットワークトポロジーに基づいた最適なルーティング決定が可能。istio.ioセキュリティの強化:SPIFFE (Secure Production Identity Framework For Everyone) の完全サポート。より細かな粒度でのアクセス制御：サービス、メソッド、パスレベルでの認可ポリシー。外部認証プロバイダ（OAuth、OIDC）との統合が改善。istio.io可観測性の強化:OpenTelemetryとの完全統合：トレース、メトリクス、ログの統一的な収集が可能。Kialiの機能強化：リアルタイムのサービスメッシュ可視化とトラブルシューティング機能の向上。カスタムメトリクスの柔軟な定義と収集が可能に。istio.ioKubernetes Gateway API対応:Kubernetes Gateway APIの完全サポートにより、より標準化されたトラフィック管理が可能。マルチクラスター環境での一貫したGateway設定が容易に。istio.ioパフォーマンスの最適化:Envoyプロキシのメモリ使用量が20-30%削減。eBPF (extended Berkeley Packet Filter) の活用によるネットワークパフォーマンスの向上。istio.ioWaypoint Proxy:サービス間の通信制御をより細かく管理可能。マルチクラスター環境でのトラフィック管理が大幅に簡素化。istio.ioIstioは急速に進化を続けており、その基本的な概念や主要機能は「Istio in Action」で説明されているものと大きく変わっていません。しかし、新機能の追加や既存機能の改善により、より柔軟で強力なサービスメッシュの構築が可能になっています。組織の規模やニーズに応じて、Istioの採用を検討し、マイクロサービスアーキテクチャの課題解決に活用することができるでしょう。Part 1 Understanding Istio1 Introducing the Istio service mesh「Istio in Action」の第1章は、現代のクラウドネイティブアーキテクチャが直面する課題と、それらを解決するためのサービスメッシュ、特にIstioの役割について包括的に解説しています。著者は、マイクロサービスアーキテクチャの複雑さと、それに伴う課題に焦点を当て、Istioがどのようにしてこれらの問題を解決するかを詳細に説明しています。クラウドネイティブアーキテクチャの課題著者は、現代のソフトウェア開発が直面する主な課題を以下のように特定しています。ネットワークの信頼性の欠如: クラウド環境では、ネットワークの障害が頻繁に発生します。これは、サービス間の通信に大きな影響を与え、システム全体の安定性を脅かす可能性があります。サービス間の依存関係管理: マイクロサービスの数が増えるにつれ、サービス間の依存関係が複雑化します。これにより、障害の伝播やパフォーマンスの問題が発生しやすくなります。分散システムの複雑さ: 多数のサービスが協調して動作する必要があり、全体の挙動を把握することが困難になります。これは、デバッグや問題解決を非常に困難にします。一貫したセキュリティポリシーの適用: 各サービスで個別にセキュリティを実装すると、一貫性の確保が難しくなります。これは、セキュリティホールを生み出す可能性があります。システム全体の可観測性の確保: 分散システムでは、問題の根本原因を特定することが困難です。これは、迅速な問題解決を妨げ、システムの信頼性に影響を与えます。Figure 1.1 ACMEMono modernization with complementary services より引用この図は、モノリシックなアプリケーション（ACMEmono）とService A、Service B、Service Cが分離され、それぞれが独立したサービスとして機能していることがわかります。この構造は、上記の課題を顕著に示しています。例えば、Service AがService Bに依存している場合、Service Bの障害がService Aにも影響を与える可能性があります。また、各サービスが独自のセキュリティ実装を持つ場合、一貫したセキュリティポリシーの適用が困難になります。著者は、これらの課題に対処するための従来のアプローチとして、アプリケーション固有のライブラリ（例：Netflix OSS）の使用を挙げています。しかし、このアプローチには以下のような問題があると指摘しています。言語やフレームワークに依存する: 例えば、Netflix OSSはJava中心のライブラリセットであり、他の言語で書かれたサービスには適用が難しいです。新しい言語やフレームワークの導入が困難: 新しい技術を導入する際に、既存のレジリエンスパターンを再実装する必要があります。ライブラリの維持と更新が煩雑: 各サービスで使用されているライブラリのバージョンを一貫して管理することが困難です。Figure 1.3 Application networking libraries commingled with an application より引用この図は、従来のアプローチでは、各アプリケーションが個別にネットワーキングライブラリを実装する必要があることを示しています。これは、一貫性の確保や保守の面で課題を生み出します。例えば、Service AとService Bが異なる言語で実装されている場合、それぞれが異なるライブラリセットを使用することになり、結果として異なるレジリエンスパターンが適用される可能性があります。サービスメッシュとIstioの導入著者は、これらの課題に対する解決策としてサービスメッシュ、特にIstioを紹介しています。Istioは以下の主要な機能を提供することで、これらの課題に対処します。サービスレジリエンス: リトライ、タイムアウト、サーキットブレーカーなどの機能を提供トラフィック制御: 細かなルーティング制御やカナリアデプロイメントの実現セキュリティ: 相互TLS（mTLS）による通信の暗号化と認証可観測性: メトリクス収集、分散トレーシング、ログ集約Figure 1.8: A service mesh architecture with co-located application-layer proxies (data plane) and management components (control plane) より引用この図は、サービスメッシュのアーキテクチャを示しています。各アプリケーションにサイドカーとしてデプロイされたプロキシ（データプレーン）と、それらを管理するコントロールプレーンの関係が明確に表現されています。こちら、サービスメッシュに関してはこちらの動画もオススメです。www.youtube.com著者は、Istioのアーキテクチャを以下のように詳細に説明しています。データプレーン:Envoyプロキシをベースとしています。各サービスのサイドカーとしてデプロイされ、すべてのネットワークトラフィックを制御します。トラフィックの暗号化、ルーティング、負荷分散、ヘルスチェックなどを実行します。コントロールプレーン:istiodと呼ばれる中央管理コンポーネントで構成されています。ポリシーの適用や設定の配布を行います。証明書の管理、サービスディスカバリ、設定の検証などの機能を提供します。Figure 1.9 Istio is an implementation of a service mesh with a data plane based on Envoy and a control plane. より引用この図は、Istioの具体的な実装を示しています。Envoyプロキシがデータプレーンとして機能し、istiodがコントロールプレーンとして全体を管理している様子が描かれています。例えば、新しいサービスがデプロイされると、istiodはそのサービスの存在を検知し、関連するすべてのEnvoyプロキシに新しい設定を配布します。これにより、新しいサービスへのトラフィックが適切にルーティングされ、セキュリティポリシーが適用されます。Istioの主要機能と利点著者は、Istioの主要機能とその利点を以下のように詳細に説明しています。1. サービスレジリエンスIstioは、Envoyプロキシを通じて以下のレジリエンス機能を提供します。リトライ: 一時的な障害からの自動回復を行います。例えば、ネットワークの瞬断によるエラーを自動的にリトライすることで、ユーザーへの影響を最小限に抑えます。タイムアウト: 長時間応答のないリクエストを制御します。これにより、1つのスロークエリがシステム全体のパフォーマンスを低下させることを防ぎます。サーキットブレーカー: 障害のあるサービスへのトラフィックを遮断します。例えば、特定のサービスが頻繁にエラーを返す場合、一定時間そのサービスへのリクエストを遮断し、システム全体の安定性を保ちます。これらの機能により、システム全体の安定性が向上し、障害の影響を最小限に抑えることができます。我らが師匠のyteraokaさんがIstio の timeout, retry, circuit breaking, etcというブログを4年前に書いているので是非、読んで下さい。sreake.com2. トラフィック制御Istioのトラフィック管理機能には以下が含まれます。細かなルーティング制御: HTTPヘッダーやその他のメタデータに基づいてルーティングを制御します。例えば、特定のユーザーグループからのリクエストを新しいバージョンのサービスにルーティングすることができます。カナリアデプロイメント: 新バージョンへの段階的なトラフィック移行を実現します。例えば、新バージョンに最初は5%のトラフィックのみを送り、問題がなければ徐々に増やしていくことができます。負荷分散: 高度な負荷分散アルゴリズムを適用します。ラウンドロビン、最小接続数、重み付けなど、様々な方式を選択できます。これらの機能により、新機能の安全なロールアウトやA/Bテストの実施が可能になります。istio.io3. セキュリティIstioのセキュリティ機能には以下が含まれます。相互TLS（mTLS）: サービス間の通信を自動的に暗号化します。これにより、中間者攻撃などのセキュリティリスクを大幅に軽減できます。アイデンティティ管理: 各サービスに強力なアイデンティティを付与します。これにより、「誰が誰と通信しているか」を正確に把握し、制御することができます。認証と認可: きめ細かなアクセス制御ポリシーを適用します。例えば、「サービスAはサービスBの特定のエンドポイントにのみアクセスできる」といったポリシーを設定できます。これらの機能により、セキュリティ管理の複雑さが大幅に軽減されます。istio.io4. 可観測性Istioは以下の可観測性機能を提供します。メトリクス収集: サービス間のトラフィック、レイテンシ、エラーレートなどを自動的に収集します。これらのメトリクスは、Prometheusなどのモニタリングツールと容易に統合できます。分散トレーシング: リクエストの全体的な流れを可視化します。例えば、ユーザーリクエストがシステム内のどのサービスを通過し、各サービスでどれくらいの時間を消費したかを追跡できます。アクセスログ: 詳細なリクエスト/レスポンスの情報を記録します。これにより、問題が発生した際の詳細な分析が可能になります。これらの機能により、システムの健全性の監視と問題の迅速な特定が可能になります。istio.ioIstioと他のテクノロジーとの比較著者は、IstioをEnterprise Service Bus（ESB）やAPI Gatewayと比較し、その違いを明確にしています。Figure 1.10: An ESB as a centralized system that integrates applicationsこの図は、従来のESBアーキテクチャを示しています。ESBが中央集権的なシステムとして機能し、全てのサービス間の通信を仲介する様子が描かれています。ESBとIstioの主な違いは以下の通りです。アーキテクチャ: ESBは中央集権的であるのに対し、Istioは分散型です。スケーラビリティ: ESBは中央のボトルネックになりやすいですが、Istioは各サービスに分散しているため、より高いスケーラビリティを提供します。機能: ESBはメッセージ変換やオーケストレーションなども行いますが、Istioはネットワーキングの問題に特化しています。Figure 1.12 The service proxies implement ESB and API gateway functionalities. より引用この図は、Istioのサービスプロキシが、ESBやAPI Gatewayの機能を分散的に実装している様子を示しています。各サービスに付随するプロキシが、それぞれの機能を担っていることがわかります。Figure 1.11 API gateway for service traffic より引用API GatewayとIstioの主な違いは以下の通りです。適用範囲: API Gatewayは主にエッジでの機能を提供しますが、Istioはサービス間の全ての通信を管理します。グラニュラリティ: Istioはより細かいレベルでのトラフィック制御が可能です。統合: IstioはKubernetesなどのプラットフォームとより密接に統合されています。著者は、Istioが以下の点でESBやAPI Gatewayと異なることを強調しています。分散アーキテクチャ: Istioは中央集権的ではなく、各サービスに分散してデプロイされます。これにより、単一障害点を排除し、高いスケーラビリティを実現しています。透明性: アプリケーションコードを変更せずに機能を提供します。開発者は既存のアプリケーションロジックを変更することなく、Istioの機能を利用できます。フォーカス: Istioは純粋にネットワーキングの問題に焦点を当てており、ビジネスロジックの実装は行いません。これにより、各サービスの責務が明確に分離され、システム全体の保守性が向上します。Istioの実際の使用シナリオ著者は、Istioの実際の使用シナリオについていくつかの具体例を提供しています。マイクロサービスの段階的な導入:既存のモノリシックアプリケーションからマイクロサービスへの移行を段階的に行う際、Istioを使用してトラフィックを制御できます。例えば、新しいマイクロサービスに最初は10%のトラフィックのみを送り、問題がなければ徐々に増やしていくことができます。A/Bテスティング:新機能のテストを行う際、Istioのトラフィック分割機能を使用して、特定のユーザーグループに新機能を提供し、その反応を測定することができます。セキュリティの強化:Istioの相互TLS機能を使用して、すべてのサービス間通信を自動的に暗号化できます。これにより、セキュリティチームは個々のアプリケーションの実装を気にすることなく、一貫したセキュリティポリシーを適用できます。障害インジェクションテスト:Istioの障害インジェクション機能を使用して、特定のサービスの遅延や障害をシミュレートし、システム全体のレジリエンスをテストできます。マルチクラスタ/マルチクラウド環境の管理:Istioを使用して、異なるクラスタや異なるクラウドプロバイダー上で動作するサービス間の通信を統一的に管理できます。これにより、ハイブリッドクラウド環境やマルチクラウド環境の運用が大幅に簡素化されます。まとめ「Istio in Action」の第1章は、サービスメッシュとIstioの概念を包括的に紹介し、その重要性を説得力のある方法で説明しています。著者は、クラウドネイティブアーキテクチャの課題を明確に特定し、Istioがこれらの課題にどのように対処するかを詳細に解説しています。Figure 1.13 An overview of separation of concerns in cloud-native applications. Istio plays a supporting role to the application layer and sits above the lower-level deployment layer. より引用この図は、クラウドネイティブアプリケーションにおけるIstioの位置づけを示しています。Istioが、アプリケーションレイヤーとデプロイメントレイヤーの間に位置し、両者を橋渡しする重要な役割を果たしていることがわかります。Istioは、ネットワークの信頼性、セキュリティ、可観測性、トラフィック管理など、分散システムが直面する多くの課題に対する強力なソリューションを提供します。しかし、著者が指摘しているように、Istioの導入は技術的な変更以上のものであり、組織のアーキテクチャ設計、運用プラクティス、さらにはチームの構造にまで影響を与える可能性があります。2024年現在、Istioはさらに進化を続けており、アンビエントメッシュやWebAssemblyを通じた拡張性の向上など、新たな可能性を開いています。これらの進化は、著者の主張の妥当性を裏付けるとともに、Istioの適用範囲をさらに広げています。最後に、この章はIstioの導入を検討している組織にとって優れた出発点となりますが、実際の導入に際しては、自組織の具体的なニーズ、既存のインフラストラクチャ、そして長期的な技術戦略を慎重に評価することが重要です。Istioは強力なツールですが、それを効果的に活用するためには、適切な計画、リソース、そして継続的な学習とアダプテーションが必要です。サービスメッシュ技術、特にIstioは、クラウドネイティブアーキテクチャの未来を形作る重要な要素の一つとなっています。この技術を理解し、適切に活用することは、現代のソフトウェアエンジニアとSREにとって不可欠なスキルとなっているのです。2 First steps with Istio「Istio in Action」の第2章は、Istioの実践的な導入と基本的な使用方法に焦点を当てています。この章では、Istioのインストール、コントロールプレーンの理解、アプリケーションのデプロイ、トラフィック制御、そして観測可能性の探索といった重要なトピックが取り上げられています。Istioのインストールと基本設定章の冒頭で、著者はIstioのインストール方法を詳細に説明しています。特に印象的だったのは、istioctlコマンドラインツールの使用です。このツールを使用することで、Istioのインストールプロセスが大幅に簡素化されています。例えば、以下のコマンドでIstioをインストールできます：istioctl install --set profile=demo -yこの簡潔さは、特に大規模な環境での導入や、CI/CDパイプラインへの組み込みを考えた際に非常に有用です。また、著者が強調しているように、インストール前のistioctl x precheckコマンドの使用は、潜在的な問題を事前に特定し、スムーズなデプロイメントを確保するための重要なステップです。Figure 2.1 Istio control plane and supporting components より引用この図は、Istioの全体的なアーキテクチャを理解する上で非常に有用です。特に、istiodがコントロールプレーンの中心的な役割を果たしていることが視覚的に明確になっています。Istioのコントロールプレーンの理解著者は、Istioのコントロールプレーン、特にistiodコンポーネントの重要性を強調しています。istiodは、設定の管理、サービスディスカバリ、証明書管理など、多岐にわたる機能を担っています。特に印象的だったのは、IstioがKubernetes Custom Resource Definitions (CRDs)を活用して設定を管理している点です。これにより、Istioの設定がKubernetesのネイティブリソースとして扱えるようになり、既存のKubernetesツールやワークフローとシームレスに統合できます。hiroki-hasegawa.hatenablog.jp例えば、以下のようなYAML定義で、Istioの振る舞いを制御できます：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: my-servicespec:  hosts:  - my-service  http:  - route:    - destination:        host: my-service        subset: v1この宣言的な設定アプローチは、IaCの原則に沿っており、設定の版管理やレビュープロセスの導入を容易にします。アプリケーションのデプロイとサービスメッシュへの統合著者は、サンプルアプリケーション（カタログサービスとWebアプリ）を用いて、Istioのサービスメッシュへのアプリケーションの統合プロセスを説明しています。特に注目すべきは、サイドカーインジェクションのプロセスです。Istioは、アプリケーションのPodに自動的にEnvoyプロキシをインジェクトすることで、アプリケーションコードを変更することなくメッシュの機能を提供します。hiroki-hasegawa.hatenablog.jpkubectl label namespace istioinaction istio-injection=enabledこのコマンドは、指定された名前空間内の全てのPodに自動的にIstioプロキシをインジェクトするよう設定します。この自動化は、大規模なマイクロサービス環境での運用を大幅に簡素化します。Figure 2.7 The webapp service calling the catalog service both with istio-proxy injected より引用この図は、サイドカーパターンの実際の動作を視覚的に説明しており、サービス間通信がどのようにIstioプロキシを介して行われるかを明確に示しています。トラフィック制御と高度なルーティング著者は、Istioの強力なトラフィック制御機能について詳しく説明しています。特に印象的だったのは、VirtualServiceとDestinationRuleの概念です。これらのリソースを使用することで、非常に細かい粒度でトラフィックをコントロールできます。例えば、以下のような設定で、特定のヘッダーを持つリクエストを新バージョンのサービスにルーティングできます：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: catalogspec:  hosts:  - catalog  http:  - match:    - headers:        x-dark-launch:          exact: \"v2\"    route:    - destination:        host: catalog        subset: version-v2  - route:    - destination:        host: catalog        subset: version-v1この機能は、カナリアリリースやブルー/グリーンデプロイメントなどの高度なデプロイメント戦略を実装する上で非常に有用です。SREの観点からは、このような細かい制御が可能であることで、新機能のロールアウトリスクを大幅に低減できます。観測可能性とレジリエンス著者は、IstioがPrometheusやGrafanaなどのツールと統合して、システムの観測可能性を向上させる方法を説明しています。特に、Istioが自動的に生成する詳細なメトリクスとトレースは、複雑なマイクロサービス環境でのトラブルシューティングを大幅に簡素化します。また、Istioのレジリエンス機能、特にリトライとサーキットブレーカーの実装は注目に値します。以下の設定例は、サービスへのリクエストに自動リトライを実装する方法を示しています：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: my-servicespec:  hosts:  - my-service  http:  - route:    - destination:        host: my-service    retries:      attempts: 3      perTryTimeout: 2sこの設定により、一時的なネットワーク障害やサービスの瞬間的な不具合に対する耐性が向上し、システム全体の安定性が改善されます。まとめ「Istio in Action」の第2章は、Istioの基本的な導入から高度な機能の使用まで、幅広いトピックをカバーしています。この章から得られる主要な洞察は以下の通りです：インフラストラクチャレベルでの問題解決: Istioは、ネットワークの信頼性、セキュリティ、可観測性などの横断的な問題をインフラストラクチャレベルで解決します。これにより、開発者はビジネスロジックに集中できるようになります。宣言的な設定: IstioはKubernetes CRDを活用し、宣言的な方法で複雑なネットワーキングの動作を定義できます。これにより、設定の管理と自動化が容易になります。段階的な導入の重要性: 著者が強調しているように、Istioは既存のシステムに段階的に導入できます。これは、リスクを最小限に抑えながらサービスメッシュの利点を享受するための重要なアプローチです。観測可能性の向上: Istioは、複雑なマイクロサービス環境での問題の診断と解決を大幅に簡素化します。これは、システムの信頼性と運用効率の向上に直結します。高度なトラフィック制御: IstioのVirtualServiceとDestinationRuleを使用することで、非常に細かい粒度でトラフィックをコントロールできます。これは、新機能の安全なロールアウトや、A/Bテストの実施に非常に有用です。Istioはマイクロサービスアーキテクチャの複雑さに対処するための強力なツールセットを提供しています。しかし、その導入には慎重な計画と、組織全体での協力が必要です。実際の運用環境でIstioを活用する際は、以下の点に注意することをお勧めします：段階的な導入: 全てのサービスを一度にIstioに移行するのではなく、重要度の低いサービスから始めて段階的に導入することをお勧めします。モニタリングとトレーシングの強化: Istioの可観測性機能を最大限に活用し、既存のモニタリングツールと統合することで、システム全体の可視性を向上させます。セキュリティポリシーの統一: Istioのセキュリティ機能を利用して、全サービスに一貫したセキュリティポリシーを適用します。トラフィック管理戦略の策定: カナリアリリースやA/Bテストなど、Istioのトラフィック管理機能を活用した高度なデプロイメント戦略を計画します。パフォーマンスの最適化: Istioの導入に伴うオーバーヘッドを考慮し、適切なリソース割り当てと設定の最適化を行います。最後に、Istioは強力なツールですが、それを効果的に活用するためには、適切な計画、リソース、そして継続的な学習とアダプテーションが必要です。この章で学んだ基本を踏まえ、実際の環境での試行錯誤を通じて、組織に最適なIstioの活用方法を見出していくことが重要です。3 Istio's data plane: The Envoy proxy「Istio in Action」の第3章は、Istioのデータプレーンの中核を成すEnvoyプロキシに焦点を当てています。この章では、Envoyの基本概念、設定方法、主要機能、そしてIstioとの関係性について詳細に解説されています。Envoyは、現代のマイクロサービスアーキテクチャにおける重要な課題を解決するために設計された強力なプロキシであり、Istioのサービスメッシュ機能の多くを支えています。Envoyプロキシの概要と主要機能Envoyは、Lyft社によって開発された高性能なL7プロキシおよび通信バスです。以下の主要な特徴を持っています：言語非依存: C++で実装されており、任意の言語やフレームワークで書かれたアプリケーションと連携可能。動的設定: xDS APIを通じて動的に設定を更新可能。高度な負荷分散: 様々な負荷分散アルゴリズムをサポート。強力な可観測性: 詳細なメトリクスと分散トレーシングをサポート。L7プロトコルサポート: HTTP/2、gRPCなどの最新プロトコルをネイティブにサポート。Figure 3.1 A proxy is an intermediary that adds functionality to the flow of traffic. より引用Envoyの核心的な設計原則は、「ネットワークは透過的であるべきで、問題が発生した際には容易に原因を特定できるべき」というものです。この原則は、複雑化するマイクロサービス環境において非常に重要です。Envoyの設定と動作Envoyの設定は主に以下の3つの要素から構成されます：Listeners: 受信トラフィックを処理するポートとプロトコルを定義。Routes: 受信したリクエストをどのクラスタに転送するかを定義。Clusters: アップストリームサービスのグループを定義。以下は、基本的なEnvoy設定の例です。Istioの複雑さの多くはEnvoyに起因しています。Envoyの設定と動作原理を十分に理解しているかどうかで、Istioの全体像の把握や問題解決の能力が大きく異なります。したがって、Istioを効果的に活用していくためには、Envoyについても深く学び、実践することが不可欠です。github.comstatic_resources:  listeners:  - name: listener_0    address:      socket_address: { address: 0.0.0.0, port_value: 10000 }    filter_chains:    - filters:      - name: envoy.filters.network.http_connection_manager        typed_config:          \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager          stat_prefix: ingress_http          route_config:            name: local_route            virtual_hosts:            - name: local_service              domains: [\"*\"]              routes:              - match: { prefix: \"/\" }                route: { cluster: some_service }  clusters:  - name: some_service    connect_timeout: 0.25s    type: STRICT_DNS    lb_policy: ROUND_ROBIN    load_assignment:      cluster_name: some_service      endpoints:      - lb_endpoints:        - endpoint:            address:              socket_address:                address: some-service                port_value: 80この設定は、ポート10000でリスニングし、全てのリクエストをsome_serviceクラスタにルーティングします。実際の運用環境では、より複雑な設定が必要になりますが、この例はEnvoyの基本的な構造を理解するのに役立ちます。Envoyの動的設定と xDS APIEnvoyの強力な機能の一つは、動的設定能力です。xDS (x Discovery Service) APIを通じて、実行時に設定を更新できます。主なxDS APIには以下があります：LDS (Listener Discovery Service)RDS (Route Discovery Service)CDS (Cluster Discovery Service)EDS (Endpoint Discovery Service)SDS (Secret Discovery Service)これらのAPIを使用することで、Envoyプロキシの動作を動的に変更でき、環境の変化に迅速に対応できます。Istioは、これらのAPIを実装し、Envoyプロキシの設定を管理します。Figure 3.5 Istio abstracts away the service registry and provides an implementation of Envoy’s xDS API. より引用Envoyの可観測性とトラブルシューティングEnvoyは、詳細なメトリクスと分散トレーシング機能を提供します。これらの機能は、複雑なマイクロサービス環境でのトラブルシューティングに不可欠です。Envoyの主な可観測性機能には以下があります：統計情報: リクエスト数、レイテンシ、エラーレートなどの詳細な統計情報を提供。分散トレーシング: OpenTracingと互換性があり、リクエストの全体的な流れを追跡可能。アクセスログ: 詳細なリクエスト/レスポンス情報を記録。また、EnvoyはAdmin APIを提供しており、実行時の設定やメトリクスにアクセスできます。これは、運用環境でのトラブルシューティングに非常に有用です。## Envoyの統計情報を取得する例curl http://localhost:9901/stats## Envoyの現在の設定をダンプする例curl http://localhost:9901/config_dumpこれらの機能により、EnvoyとIstioを使用したシステムの可観測性が大幅に向上し、問題の迅速な特定と解決が可能になります。IstioとEnvoyの関係IstioはEnvoyをデータプレーンとして使用し、その強力な機能を活用しています。Istioは以下の方法でEnvoyを拡張および管理しています：設定管理: IstioはxDS APIを実装し、Envoyプロキシの設定を一元管理します。セキュリティ: Istioは、Envoyの相互TLS機能を利用し、サービス間の通信を自動的に暗号化します。トラフィック管理: IstioのVirtualServiceやDestinationRuleは、Envoyのルーティングおよびロードバランシング機能を抽象化します。可観測性: IstioはEnvoyのメトリクスとトレーシング機能を活用し、より高度な可観測性を提供します。Figure 3.7 istiod delivers application-specific certificates that can be used to establish mutual TLS to secure traffic between services. より引用こちらのブログがオススメです。hiroki-hasegawa.hatenablog.jp実践的な応用と提案Envoyプロキシとそれを活用したIstioのデータプレーンを効果的に利用するために、以下の実践的な提案を考えてみましょう：段階的な導入: Envoyプロキシを既存のインフラストラクチャに段階的に導入することを検討します。例えば、最初は非クリティカルなサービスに導入し、徐々に範囲を広げていくアプローチが有効です。カスタムフィルターの開発: WebAssemblyを使用して、組織固有のニーズに合わせたカスタムEnvoyフィルターを開発します。これにより、Envoyの機能を拡張し、特定のユースケースに対応できます。詳細なモニタリングの実装: Envoyの豊富なメトリクスを活用し、Prometheusなどのモニタリングシステムと統合します。ダッシュボードを作成し、サービスの健全性とパフォーマンスを視覚化します。トラフィック管理戦略の最適化: Envoyのルーティング機能を活用し、A/Bテストやカナリアリリースなどの高度なデプロイメント戦略を実装します。セキュリティの強化: Envoyの相互TLS機能を最大限に活用し、サービス間通信のセキュリティを強化します。また、認証・認可ポリシーを実装し、きめ細かなアクセス制御を実現します。パフォーマンスチューニング: Envoyの設定を最適化し、リソース使用量とレイテンシを監視します。特に大規模環境では、Envoyのリソース設定を慎重に調整する必要があります。障害注入テストの実施: Envoyの障害注入機能を使用して、システムの回復性をテストします。様々な障害シナリオを模擬し、システムの動作を検証します。継続的な学習と最適化: Envoyとイストの進化に合わせて、継続的に新機能を学び、適用していきます。コミュニティへの参加や、最新のベストプラクティスの追跡が重要です。まとめEnvoyプロキシは、現代のクラウドネイティブアーキテクチャにおける多くの課題を解決する強力なツールです。その柔軟性、拡張性、そして高度な機能セットは、複雑なマイクロサービス環境での運用を大幅に簡素化します。Istioと組み合わせることで、Envoyの機能がさらに強化され、より統合されたサービスメッシュソリューションとなります。しかし、EnvoyとIstioの導入には慎重な計画と設計が必要です。特に大規模な環境では、パフォーマンスやリソース使用量に注意を払う必要があります。また、チームのスキルセットの向上や、新しい運用プラクティスの導入も重要な検討事項となります。最後に、EnvoyとIstioは急速に進化を続けているため、継続的な学習と適応が不可欠です。これらのテクノロジーを効果的に活用するには、最新の動向を常に追跡し、自組織のニーズに合わせて適切に採用していく必要があります。Part 2 Securing, observing, and controlling your service’s network traffic4 Istio gateways: Getting traffic into a cluster「Istio in Action」の第4章は、Istioのゲートウェイ機能に焦点を当て、クラスター外部からのトラフィックを安全かつ効率的に管理する方法について詳細に解説しています。この章では、Istio Gatewayの基本概念から高度な設定、セキュリティ対策、そして運用上の考慮事項まで、幅広いトピックがカバーされています。Istio Gatewayの基本概念Istio Gatewayは、クラスター外部からのトラフィックを制御し、内部サービスへのアクセスを管理する重要なコンポーネントです。著者は、従来のKubernetes Ingressとの違いを明確にしながら、Istio Gatewayの利点を説明しています。特に印象的だったのは、以下の点です：柔軟なプロトコルサポート: Istio GatewayはHTTP/HTTPSだけでなく、TCPやgRPCなど、さまざまなプロトコルをサポートしています。これにより、多様なアプリケーションニーズに対応できます。詳細な設定オプション: GatewayリソースとVirtualServiceリソースの組み合わせにより、非常に細かいトラフィック制御が可能です。セキュリティの統合: TLS/mTLSの設定が容易で、証明書の管理もIstioが行うことができます。Figure 4.1 We want to connect networks by connecting clients running outside of our cluster to services running inside our cluster. より引用この図は、Istio Gatewayがクラスター外部からのトラフィックをどのように受け取り、内部サービスに転送するかを視覚的に示しています。これにより、Gatewayの役割が明確に理解できます。Gateway設定の実践著者は、実際のGateway設定例を通じて、その使用方法を詳細に解説しています。以下は、基本的なGateway設定の例です：apiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata:  name: coolstore-gatewayspec:  selector:    istio: ingressgateway  servers:  - port:      number: 80      name: http      protocol: HTTP    hosts:    - \"webapp.istioinaction.io\"この設定例は、HTTP traffを受け入れ、特定のホストに対するリクエストをルーティングする方法を示しています。著者は、このような基本的な設定から始めて、徐々に複雑な設定へと読者を導いています。VirtualServiceとの連携も重要なポイントです：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: webapp-vs-from-gwspec:  hosts:  - \"webapp.istioinaction.io\"  gateways:  - coolstore-gateway  http:  - route:    - destination:        host: webapp        port:          number: 8080この組み合わせにより、外部からのリクエストを適切な内部サービスにルーティングできます。セキュリティ設定著者は、Istio Gatewayのセキュリティ設定に大きな注意を払っています。特にTLS/mTLSの設定方法は、現代のマイクロサービスアーキテクチャにおいて非常に重要です。Figure 4.8 Basic model of how TLS is established between a client and server より引用この図は、クライアントとサーバー間でのTLS handshakeのプロセスを視覚的に表現しており、セキュリティ設定の重要性を理解する上で非常に有用です。以下は、mTLSを設定するGatewayの例です：apiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata:  name: coolstore-gatewayspec:  selector:    istio: ingressgateway  servers:  - port:      number: 443      name: https      protocol: HTTPS    tls:      mode: MUTUAL      credentialName: webapp-credential-mtls    hosts:    - \"webapp.istioinaction.io\"この設定により、クライアントとサーバー間の相互認証が可能になり、セキュリティが大幅に向上します。高度な機能と運用上の考慮事項著者は、単なる基本的な使用方法だけでなく、Istio Gatewayの高度な機能や運用上の考慮事項についても詳しく説明しています。特に印象的だった点は以下の通りです：複数のGatewayの使用: 異なるチームや要件に応じて複数のGatewayを設定する方法が説明されています。これは大規模な組織での運用に特に有用です。Gateway Injection: stub deploymentを使用してGatewayを注入する方法は、チーム間の責任分担を明確にする上で非常に有効です。アクセスログの設定: デバッグやトラブルシューティングに不可欠なアクセスログの設定方法が詳細に解説されています。設定の最適化: 大規模な環境でのパフォーマンス最適化のための設定方法が提供されています。これらの高度な機能は、実際のプロダクション環境でIstioを運用する際に非常に重要になります。実践的な応用と提案Istio Gatewayを効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入: 既存の環境にIstio Gatewayを導入する際は、段階的なアプローチを取ることをおすすめします。まずは非クリティカルなサービスから始め、徐々に範囲を広げていくことで、リスクを最小限に抑えながら導入できます。セキュリティファーストの設計: 初期の設定段階からTLS/mTLSを有効にし、セキュリティを最優先に考えます。証明書の自動管理機能を活用し、定期的な更新を確実に行います。トラフィック制御戦略の策定: カナリアリリースやA/Bテストなど、Gatewayのトラフィック制御機能を活用した高度なデプロイメント戦略を計画します。これにより、新機能の安全なロールアウトが可能になります。モニタリングとロギングの強化: Gatewayのアクセスログと、Prometheusなどの監視ツールを統合し、詳細なトラフィック分析を行います。異常検知やパフォーマンス最適化に活用します。マルチクラスター/マルチクラウド戦略: Istio Gatewayのマルチクラスター機能を活用し、異なる環境（開発、ステージング、本番）や異なるクラウドプロバイダー間でのサービスメッシュの統一管理を検討します。チーム間の責任分担の明確化: Gateway Injectionを活用し、各チームが自身のGatewayを管理できるようにします。これにより、組織全体の俊敏性が向上します。パフォーマンスチューニング: 大規模環境では、Gateway設定の最適化が重要です。不要な設定を削除し、リソース使用量を監視しながら、継続的な最適化を行います。セキュリティ監査の定期実施: Gatewayの設定、特にTLS/mTLS設定を定期的に監査します。新たな脆弱性や推奨事項に応じて、設定を更新します。ディザスタリカバリ計画の策定: Gatewayは重要なインフラコンポーネントであるため、障害時の迅速な復旧計画を策定します。複数のGatewayを異なるアベイラビリティゾーンに配置するなどの冗長性も検討します。まとめ「Istio in Action」の第4章は、Istio Gatewayの重要性と、その効果的な使用方法を包括的に解説しています。Gatewayは、クラスター外部からのトラフィックを管理する上で非常に重要な役割を果たし、セキュリティ、可観測性、トラフィック制御など、多岐にわたる機能を提供します。著者が強調しているように、Istio Gatewayは単なるIngress Controllerの代替ではなく、より高度で柔軟なトラフィック管理ソリューションです。特に、詳細なルーティング制御、TLS/mTLSの簡単な設定、そして様々なプロトコルのサポートは、現代のマイクロサービスアーキテクチャにおいて非常に価値があります。しかし、Gatewayの導入には慎重な計画とデザインが必要です。特に大規模な環境では、パフォーマンスやリソース使用量に注意を払う必要があります。また、チームのスキルセットの向上や、新しい運用プラクティスの導入も重要な検討事項となります。2024年現在、Istioはさらに進化を続けており、アンビエントメッシュやKubernetes Gateway APIのサポートなど、新たな可能性を開いています。これらの進化は、Istio Gatewayの適用範囲をさらに広げ、より多様なユースケースに対応できるようになっています。最後に、Istio Gatewayの導入を検討している組織にとって、この章は優れた出発点となります。しかし、実際の導入に際しては、自組織の具体的なニーズ、既存のインフラストラクチャ、そして長期的な技術戦略を慎重に評価することが重要です。Istio Gatewayは強力なツールですが、それを効果的に活用するためには、適切な計画、リソース、そして継続的な学習とアダプテーションが必要です。Istio Gatewayは、クラウドネイティブアーキテクチャの未来を形作る重要な要素の一つです。この技術を理解し、適切に活用することは、現代のソフトウェアエンジニアとSREにとって不可欠なスキルとなっています。本章で学んだ知識を基に、実際の環境での試行錯誤を通じて、組織に最適なIstio Gatewayの活用方法を見出していくことが重要です。5 Traffic control: Fine-grained traffic routing「Istio in Action」の第5章は、Istioの強力なトラフィック制御機能に焦点を当てています。この章では、新しいコードのデプロイリスクを軽減するための様々な技術が詳細に解説されています。著者は、リクエストレベルのルーティング、トラフィックシフティング、トラフィックミラーリングなどの高度な概念を、実践的な例を交えながら説明しています。Figure 5.1 In a blue/green deployment, blue is the currently released software. When we release the new software, we cut over traffic to the green version. より引用この章はIstioを活用して本番環境でのリリースリスクを大幅に低減する方法を提供しており、非常に価値があります。特に印象に残ったのは、著者が繰り返し強調している「デプロイメント」と「リリース」の概念の分離です。この考え方は、現代のクラウドネイティブ環境において安全かつ効率的なソフトウェアデリバリーを実現する上で極めて重要です。Figure 5.2 A deployment is code that is installed into production but does not take any live production traffic. While the deployment is installed into production, we do smoke tests and validate it. より引用ソフトウェアデリバリーについては「入門 継続的デリバリー」が良いのでぜひ読んでみて下さい(ちなみに原書のGrokking Continuous Deliveryしか読めてないので翻訳版も早く読みたい)。www.oreilly.co.jpトラフィック制御の基本概念著者は、まずIstioのトラフィック制御の基本的な仕組みを説明しています。Istioでは、VirtualServiceとDestinationRuleという2つの主要なリソースを使用してトラフィックを制御します。VirtualServiceは、トラフィックのルーティングルールを定義します。例えば、以下のような設定が可能です：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: catalog-vs-from-gwspec:  hosts:  - \"catalog.istioinaction.io\"  gateways:  - catalog-gateway  http:  - route:    - destination:        host: catalog        subset: version-v1この設定は、すべてのトラフィックをcatalogサービスのversion-v1サブセットにルーティングします。DestinationRuleは、トラフィックの宛先に関するポリシーを定義します：apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata:  name: catalogspec:  host: catalog  subsets:  - name: version-v1    labels:      version: v1  - name: version-v2    labels:      version: v2このDestinationRuleは、catalogサービスに2つのサブセット（version-v1とversion-v2）を定義しています。これらのリソースを組み合わせることで、非常に細かい粒度でトラフィックを制御できます。例えば、特定のHTTPヘッダーを持つリクエストを新しいバージョンのサービスにルーティングするといったことが可能です。カナリアリリースとトラフィックシフティング著者は、新しいバージョンのサービスを安全にリリースするための手法として、カナリアリリースとトラフィックシフティングを詳細に解説しています。カナリアリリースでは、新バージョンに少量のトラフィックを送り、その挙動を観察します。Istioでは、以下のようなVirtualService設定でこれを実現できます：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: catalogspec:  hosts:  - catalog  http:  - route:    - destination:        host: catalog        subset: version-v1      weight: 90    - destination:        host: catalog        subset: version-v2      weight: 10この設定では、10%のトラフィックを新バージョン（v2）に送り、残りの90%を既存バージョン（v1）に送ります。著者は、このアプローチの利点として以下を挙げています：リスクの最小化：新バージョンに問題があっても、影響を受けるユーザーは限定的です。段階的な移行：問題がなければ、徐々にトラフィックの割合を増やしていけます。リアルワールドでのテスト：実際のユーザートラフィックを使用してテストできます。SREの観点からは、このアプローチは本番環境の安定性を維持しながら新機能を導入する上で非常に有効です。また、問題が発生した場合の迅速なロールバックも容易です。トラフィックミラーリング著者が紹介している興味深い機能の一つが、トラフィックミラーリングです。これは、実際のトラフィックのコピーを新バージョンのサービスに送信し、その挙動を観察する技術です。apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: catalogspec:  hosts:  - catalog  http:  - route:    - destination:        host: catalog        subset: version-v1      weight: 100    mirror:      host: catalog      subset: version-v2この設定では、すべてのトラフィックがversion-v1に送られると同時に、そのコピーがversion-v2にも送られます。重要なのは、ミラーリングされたトラフィックの応答は無視されるため、ユーザーに影響を与えることなく新バージョンをテストできる点です。この機能は、特に高トラフィックの環境や、トランザクションの整合性が重要なシステムでの新バージョンのテストに非常に有効です。実際のプロダクショントラフィックを使用してテストできるため、ステージング環境では発見できないような問題を早期に発見できる可能性があります。Flaggerを使用した自動カナリアデプロイメント著者は、Istioのトラフィック制御機能を自動化するツールとしてFlaggerを紹介しています。Flaggerは、メトリクスに基づいて自動的にトラフィックを調整し、カナリアリリースを管理します。以下は、FlaggerのCanaryリソースの例です：apiVersion: flagger.app/v1beta1kind: Canarymetadata:  name: catalog-releasespec:  targetRef:    apiVersion: apps/v1    kind: Deployment    name: catalog  service:    name: catalog    port: 80  analysis:    interval: 45s    threshold: 5    maxWeight: 50    stepWeight: 10    metrics:    - name: request-success-rate      thresholdRange:        min: 99      interval: 1m    - name: request-duration      thresholdRange:        max: 500      interval: 30sこの設定では、Flaggerが45秒ごとにメトリクスを評価し、問題がなければトラフィックを10%ずつ増やしていきます。成功率が99%を下回るか、レスポンス時間が500msを超えた場合、カナリアリリースは中止されロールバックが行われます。これにより、人間の介入なしに安全なカナリアリリースを実現できます。特に、複数のサービスを同時にリリースする必要がある大規模な環境では、この自動化は非常に価値があります。クラスター外部へのトラフィック制御著者は、Istioを使用してクラスター外部へのトラフィックを制御する方法も解説しています。デフォルトでは、Istioはすべての外部トラフィックを許可しますが、セキュリティ上の理由から、この動作を変更してすべての外部トラフィックをブロックし、明示的に許可されたトラフィックのみを通過させることができます。apiVersion: networking.istio.io/v1alpha3kind: ServiceEntrymetadata:  name: external-apispec:  hosts:  - api.external-service.com  ports:  - number: 443    name: https    protocol: HTTPS  resolution: DNS  location: MESH_EXTERNALこのServiceEntryは、特定の外部サービスへのアクセスを許可します。これにより、マイクロサービス環境でのセキュリティを大幅に向上させることができます。実践的な応用と提案Istioのトラフィック制御機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入戦略の策定: 新機能のロールアウトには、まずカナリアリリースを使用し、問題がなければトラフィックシフティングで段階的に移行するという戦略を採用します。これにより、リスクを最小限に抑えながら、新機能を迅速に導入できます。自動化パイプラインの構築: FlaggerなどのツールをCI/CDパイプラインに統合し、カナリアリリースプロセスを自動化します。これにより、人間のエラーを減らし、リリースの一貫性と速度を向上させることができます。詳細なモニタリングの実装: Istioのテレメトリ機能を活用し、サービスのパフォーマンス、エラーレート、レイテンシなどを詳細に監視します。Prometheusなどのモニタリングシステムと統合し、カスタムダッシュボードを作成して、リリースの進捗を視覚化します。トラフィックミラーリングの活用: 新バージョンのサービスをプロダクション環境で徹底的にテストするために、トラフィックミラーリングを活用します。これにより、実際のユーザートラフィックを使用してテストできますが、ユーザーへの影響はありません。セキュリティファーストのアプローチ: ServiceEntryを使用して外部トラフィックを制御し、必要最小限のサービスにのみ外部アクセスを許可します。これにより、潜在的なセキュリティリスクを軽減できます。A/Bテストの実施: Istioの細かいトラフィック制御を活用して、新機能のA/Bテストを実施します。ユーザーセグメントに基づいてトラフィックを分割し、機能の効果を測定します。障害注入テストの実施: Istioの障害注入機能を使用して、様々な障害シナリオ（遅延、エラーなど）をシミュレートし、システムの回復性をテストします。これにより、本番環境での予期せぬ問題に対する準備を整えることができます。例えば、以下のようなVirtualServiceを使用して、特定のパーセンテージのリクエストに対して遅延を注入できます：   apiVersion: networking.istio.io/v1alpha3   kind: VirtualService   metadata:     name: catalog-delay   spec:     hosts:     - catalog     http:     - fault:         delay:           percentage:             value: 10           fixedDelay: 5s       route:       - destination:           host: catalog   この設定では、10%のリクエストに5秒の遅延が追加されます。これを使用して、サービスがタイムアウトや遅延に適切に対応できるかをテストできます。トラフィックポリシーの定期的な見直し: システムの進化に伴い、トラフィックルーティングポリシーを定期的に見直し、最適化します。例えば、古いバージョンへのルーティングを削除したり、新しいサービスを追加したりする必要があるかもしれません。以下は、見直しのチェックリストの例です：全てのサービスバージョンが適切にルーティングされているか不要なルーティングルールがないかセキュリティポリシーが最新のベストプラクティスに沿っているかパフォーマンスメトリクスに基づいてルーティング比率を調整する必要があるかマルチクラスター/マルチリージョン戦略の策定: Istioのマルチクラスター機能を活用して、地理的に分散したサービスのトラフィックを管理します。これにより、レイテンシの最適化やディザスタリカバリの改善が可能になります。例えば、以下のようなGatewayを使用して、クラスター間の通信を制御できます：   apiVersion: networking.istio.io/v1alpha3   kind: Gateway   metadata:     name: cross-cluster-gateway   spec:     selector:       istio: ingressgateway     servers:     - port:         number: 443         name: tls         protocol: TLS       tls:         mode: AUTO_PASSTHROUGH       hosts:       - \"*.global\"   この設定により、異なるクラスター間でサービスを安全に公開し、通信できるようになります。カスタムメトリクスの導入: Istioのテレメトリ機能を拡張して、ビジネス固有のメトリクスを収集します。これにより、技術的な指標だけでなく、ビジネス上の成果もトラッキングできるようになります。例えば、Envoy filterを使用して、特定のAPIコールの頻度や成功率を測定できます：apiVersion: networking.istio.io/v1alpha3kind: EnvoyFiltermetadata:  name: custom-metricspec:  configPatches:  - applyTo: HTTP_FILTER    match:      context: SIDECAR_OUTBOUND    patch:      operation: ADD      value:        name: envoy.filters.http.lua        typed_config:          \"@type\": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua          inlineCode: |            function envoy_on_response(response_handle)              if response_handle:headers():get(\":path\") == \"/api/important-endpoint\" then                response_handle:logInfo(\"Important API called\")              end            endこの設定により、特定のAPIエンドポイントへのコールをログに記録し、後で分析することができます。グラデュアルロールアウトの自動化: カナリアリリースやトラフィックシフティングの過程を自動化し、メトリクスに基づいて自動的にトラフィック比率を調整するシステムを構築します。これにより、人間の介入を最小限に抑えながら、安全かつ効率的なリリースが可能になります。Flaggerのようなツールを使用して、以下のようなワークフローを実装できます：1. 新バージョンを5%のトラフィックで開始2. エラーレートとレイテンシを5分間監視3. 問題がなければトラフィックを10%に増加4. ステップ2と3を繰り返し、最終的に100%に到達5. 問題が検出された場合は自動的にロールバックサービスメッシュの可視化: Kialiなどのツールを使用して、サービスメッシュのトポロジーと現在のトラフィックフローを視覚化します。これにより、複雑なルーティング設定の理解が容易になり、潜在的な問題の早期発見が可能になります。特に、新しいルーティングルールを適用した後の影響を視覚的に確認するのに役立ちます。セキュリティポリシーとの統合: トラフィック制御を組織のセキュリティポリシーと統合します。例えば、特定の重要なサービスへのアクセスを、認証されたサービスからのみに制限することができます：apiVersion: security.istio.io/v1beta1kind: AuthorizationPolicymetadata:  name: catalog-auth-policyspec:  selector:    matchLabels:      app: catalog  action: ALLOW  rules:  - from:    - source:        principals: [\"cluster.local/ns/default/sa/webapp\"]この設定により、catalogサービスへのアクセスがwebappサービスアカウントからのみに制限されます。パフォーマンスベンチマーキング: 新旧バージョン間のパフォーマンス比較を自動化します。トラフィックミラーリングを使用して、新バージョンのパフォーマンスを測定し、既存バージョンと比較します。これにより、新バージョンがパフォーマンス要件を満たしているかを客観的に評価できます。災害復旧訓練の実施: Istioのトラフィック制御機能を使用して、災害復旧シナリオをシミュレートし、訓練します。例えば、特定のリージョンやクラスターの障害を模擬し、トラフィックを別のリージョンにリダイレクトする訓練を定期的に行います。これにより、実際の障害時にも迅速かつ効果的に対応できるようになります。これらの実践的な応用と提案を組み合わせることで、Istioのトラフィック制御機能を最大限に活用し、より安全、効率的、かつ堅牢なマイクロサービス環境を構築することができます。重要なのは、これらの手法を継続的に評価し、組織の成長と技術の進化に合わせて適応させていくことです。Istioは非常に強力で柔軟なツールですが、その真価を発揮するためには、組織の具体的なニーズと目標に合わせて慎重に設計し、実装する必要があります。まとめ「Istio in Action」の第5章は、Istioのトラフィック制御機能の重要性と強力さを明確に示しています。著者は、カナリアリリース、トラフィックシフティング、ミラーリングなどの高度な技術を詳細に解説し、これらがマイクロサービス環境でのリリースリスクを大幅に軽減する方法を提示しています。特に印象的なのは、「デプロイメント」と「リリース」の概念を分離することの重要性です。この考え方は、安全かつ効率的なソフトウェアデリバリーを実現する上で極めて重要です。Istioのトラフィック制御機能を活用することで、新バージョンのサービスを本番環境にデプロイしつつ、実際のトラフィックを段階的にシフトさせることが可能になります。また、Flaggerのような自動化ツールの導入により、カナリアリリースプロセスを更に最適化できることも示されています。これは、特に大規模な環境や頻繁なリリースが必要な場合に非常に有用です。2024年現在、アンビエントメッシュやWebAssemblyの進化など、Istioの新機能によりトラフィック制御の柔軟性と効率性が更に向上しています。これらの進化は、より大規模で複雑な環境でのIstioの適用を可能にしています。結論として、Istioのトラフィック制御機能は、現代のマイクロサービスアーキテクチャにおいて不可欠なツールとなっています。適切に活用することで、システムの安定性を維持しつつ、迅速かつ安全にイノベーションを推進することが可能になります。ただし、これらの機能を効果的に使用するためには、継続的な学習と実践、そして組織の具体的なニーズに合わせた戦略の策定が必要不可欠です。6 Resilience: Solving application networking challenges「Istio in Action」の第6章は、分散システムにおける重要な課題の一つであるレジリエンスに焦点を当てています。著者は、マイクロサービスアーキテクチャにおけるネットワークの信頼性の欠如、サービス間の依存関係管理、そして予期せぬ障害への対応といった問題に対して、Istioがどのようにソリューションを提供するかを詳細に解説しています。この章で特に印象に残ったのは分散システムの問題は、予測不可能な方法で障害が発生することが多く、手動でトラフィックシフトのアクションを取ることができないことです。この考え方は、現代のクラウドネイティブアーキテクチャが直面している根本的な課題を端的に表現しており、Istioのようなサービスメッシュの必要性を強調しています。この章はIstioを活用して本番環境でのレジリエンスを大幅に向上させる方法を提供しており、非常に価値があります。特に、クライアントサイドロードバランシング、タイムアウト、リトライ、サーキットブレーキングなどの機能を、アプリケーションコードを変更せずに実装できる点は、運用効率とシステムの信頼性向上に大きく貢献します。クライアントサイドロードバランシング著者は、Istioのクライアントサイドロードバランシング機能について詳細に解説しています。この機能により、サービス間の通信をより効率的に管理し、システム全体のパフォーマンスと信頼性を向上させることができます。Istioは以下の主要なロードバランシングアルゴリズムをサポートしています：Round Robin（ラウンドロビン）: デフォルトのアルゴリズムで、リクエストを順番に各エンドポイントに分配します。Random（ランダム）: リクエストをランダムにエンドポイントに分配します。Least Connection（最小接続数）: アクティブな接続数が最も少ないエンドポイントにリクエストを送信します。これらのアルゴリズムは、DestinationRuleリソースを使用して設定できます。例えば、以下のような設定が可能です：apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata:  name: my-destination-rulespec:  host: my-service  trafficPolicy:    loadBalancer:      simple: LEAST_CONNこの設定により、my-serviceへのリクエストは、最小接続数アルゴリズムを使用してロードバランシングされます。著者は、これらのアルゴリズムの違いを実際のパフォーマンステストを通じて示しています。特に印象的だったのは、異なる負荷状況下での各アルゴリズムの振る舞いの違いです。例えば、一部のエンドポイントが高レイテンシーを示す状況下では、Least Connectionアルゴリズムが最も効果的にパフォーマンスを維持できることが示されています。SREの観点からは、この機能は特に重要です。本番環境では、サービスの負荷やパフォーマンスが常に変動するため、適切なロードバランシングアルゴリズムを選択し、必要に応じて動的に調整できることは、システムの安定性と効率性を大幅に向上させます。ロケーションアウェアロードバランシング著者は、Istioのロケーションアウェアロードバランシング機能についても詳しく説明しています。この機能は、マルチクラスタ環境やハイブリッドクラウド環境で特に有用です。ロケーションアウェアロードバランシングを使用すると、Istioは地理的に近いサービスインスタンスにトラフィックを優先的にルーティングします。これにより、レイテンシーを低減し、データの局所性を向上させることができます。例えば、以下のようなDestinationRuleを使用して、ロケーションベースの重み付けを設定できます：apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata:  name: my-destination-rulespec:  host: my-service  trafficPolicy:    loadBalancer:      localityLbSetting:        distribute:        - from: us-west/zone1/*          to:            \"us-west/zone1/*\": 80            \"us-west/zone2/*\": 20この設定では、us-west/zone1からのトラフィックの80%を同じゾーンに、20%をus-west/zone2にルーティングします。Figure 6.10 Prefer calling services in the same locality. より引用SREとして、この機能は特にグローバルに分散したアプリケーションの運用に有用です。適切に設定することで、ユーザーエクスペリエンスの向上、コストの最適化、そして障害時の影響範囲の局所化を実現できます。タイムアウトとリトライ著者は、Istioのタイムアウトとリトライ機能について詳細に解説しています。これらの機能は、ネットワークの信頼性が低い環境や、サービスが一時的に応答しない状況での耐性を向上させるために重要です。タイムアウトは、VirtualServiceリソースを使用して設定できます：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: my-virtual-servicespec:  hosts:  - my-service  http:  - route:    - destination:        host: my-service    timeout: 0.5sこの設定では、my-serviceへのリクエストが0.5秒以内に完了しない場合、タイムアウトエラーが発生します。リトライも同様にVirtualServiceで設定できます：apiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:  name: my-virtual-servicespec:  hosts:  - my-service  http:  - route:    - destination:        host: my-service    retries:      attempts: 3      perTryTimeout: 2sこの設定では、リクエストが失敗した場合に最大3回まで再試行し、各試行のタイムアウトを2秒に設定しています。著者は、これらの設定の影響を実際のパフォーマンステストを通じて示しています。特に印象的だったのは、適切に設定されたリトライ機能が、一時的な障害からのサービスの回復性を大幅に向上させる様子です。しかし、著者は同時に、過度のリトライがシステムに与える潜在的な悪影響についても警告しています。「サンダリングハード」問題（リトライが連鎖的に増幅し、システムに過大な負荷をかける現象）について言及しており、この問題を回避するためのベストプラクティスを提供しています。Figure 6.14 The “thundering herd” effect when retries compound each other より引用SREの観点からは、タイムアウトとリトライの適切な設定は、システムの信頼性とパフォーマンスのバランスを取る上で極めて重要です。特に、マイクロサービスアーキテクチャにおいては、サービス間の依存関係が複雑になるため、これらの設定の影響を慎重に検討し、継続的にモニタリングと調整を行う必要があります。サーキットブレーキング著者は、Istioのサーキットブレーキング機能について詳細に解説しています。この機能は、システムの一部が障害を起こした際に、その影響が他の部分に波及するのを防ぐために重要です。Istioでは、サーキットブレーキングをDestinationRuleリソースを使用して設定します：apiVersion: networking.istio.io/v1beta1kind: DestinationRulemetadata:  name: my-destination-rulespec:  host: my-service  trafficPolicy:    connectionPool:      tcp:        maxConnections: 100      http:        http1MaxPendingRequests: 1        maxRequestsPerConnection: 10    outlierDetection:      consecutiveErrors: 5      interval: 5s      baseEjectionTime: 30s      maxEjectionPercent: 100この設定では、以下のようなサーキットブレーキングのルールを定義しています：最大100のTCP接続を許可キューに入れることができる未処理のHTTPリクエストを1つに制限1つの接続で処理できる最大リクエスト数を10に制限5回連続でエラーが発生した場合、そのホストを30秒間エジェクト（除外）最大で100%のホストをエジェクト可能著者は、これらの設定の影響を実際のパフォーマンステストを通じて示しています。特に印象的だったのは、サーキットブレーキングが適切に機能することで、システム全体の安定性が大幅に向上する様子です。Figure 6.15 Circuit-breaking endpoints that don’t behave correctly より引用SREの観点からは、サーキットブレーキングは特に重要な機能です。大規模な分散システムでは、部分的な障害は避けられません。サーキットブレーキングを適切に設定することで、障害の影響を局所化し、システム全体の耐障害性を向上させることができます。実践的な応用と提案Istioのレジリエンス機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入戦略の策定: レジリエンス機能の導入は、小規模なサービスから始め、徐々に範囲を広げていくことをお勧めします。特に、クリティカルではないサービスから始めることで、リスクを最小限に抑えながら経験を積むことができます。包括的なモニタリングの実装: Istioのテレメトリ機能を活用し、サービスのパフォーマンス、エラーレート、レイテンシなどを詳細に監視します。Prometheusなどのモニタリングシステムと統合し、カスタムダッシュボードを作成して、レジリエンス機能の効果を視覚化します。カオスエンジニアリングの実践: Istioのトラフィック管理機能と障害注入機能を組み合わせて、計画的にシステムに障害を導入し、レジリエンス機能の効果を検証します。これにより、予期せぬ障害に対する準備を整えることができます。サーキットブレーキングの最適化: サーキットブレーキングの設定は、サービスの特性や負荷パターンに応じて最適化する必要があります。負荷テストを実施し、適切なしきい値を見つけることが重要です。リトライ戦略の慎重な設計: リトライは有効な機能ですが、過度のリトライはシステムに悪影響を与える可能性があります。エクスポネンシャルバックオフなどの高度なリトライ戦略を検討し、「サンダリングハード」問題を回避します。ロケーションアウェアロードバランシングの活用: グローバルに分散したアプリケーションでは、ロケーションアウェアロードバランシングを積極的に活用します。これにより、レイテンシーの低減とデータの局所性の向上を実現できます。アプリケーションレベルのレジリエンスとの統合: Istioのレジリエンス機能は強力ですが、アプリケーションレベルのレジリエンス（例：サーキットブレーカーパターン、バルクヘッドパターン）と組み合わせることで、さらに強固なシステムを構築できます。継続的な学習と最適化: レジリエンス戦略は、システムの進化と共に継続的に見直し、最適化する必要があります。新しいIstioのバージョンがリリースされた際は、新機能や改善点を積極的に評価し、導入を検討します。ドキュメンテーションとナレッジ共有: レジリエンス設定とその理由を明確にドキュメント化し、チーム全体で共有します。これにより、長期的なメンテナンス性が向上し、新しいチームメンバーのオンボーディングも容易になります。パフォーマンスとレジリエンスのトレードオフの管理: レジリエンス機能の導入は、システムのパフォーマンスにも影響を与える可能性があります。常にパフォーマンスとレジリエンスのバランスを意識し、必要に応じて調整を行います。まとめ「Istio in Action」の第6章は、Istioを活用したマイクロサービスアーキテクチャのレジリエンス向上について、非常に包括的かつ実践的な内容を提供しています。著者は、クライアントサイドロードバランシング、タイムアウト、リトライ、サーキットブレーキングなどの重要な概念を、理論的説明と実際のパフォーマンステストを通じて解説しており、読者に深い理解を促しています。特に印象的だったのは、著者が単にIstioの機能を説明するだけでなく、それらの機能が実際のプロダクション環境でどのように適用され、どのような影響をもたらすかを具体的に示している点です。例えば、サーキットブレーキングの設定が、システム全体の安定性にどのように寄与するかを、実際のメトリクスを用いて説明している部分は非常に有益です。この章で紹介されているテクニックは、現代の複雑な分散システムの運用において極めて重要です。特に、手動介入なしにシステムのレジリエンスを向上させる能力は、大規模なマイクロサービス環境では不可欠です。しかし、同時に著者は、これらの機能の過度の使用や誤った設定がもたらす潜在的なリスクについても警告しています。例えば、過剰なリトライによる「サンダリングハード」問題や、不適切なサーキットブレーキング設定による不必要なサービス停止などのリスクについて言及しており、読者に慎重な設計と継続的なモニタリングの重要性を喚起しています。2024年現在の技術動向を踏まえると、本章で説明されている概念は依然として有効であり、重要性を増していると言えます。特に、アンビエントメッシュやWebAssemblyの進化により、Istioのレジリエンス機能はより柔軟かつ効率的に適用できるようになっています。最後に、この章から得られる重要な教訓は、レジリエンスは単なる技術的な課題ではなく、システム設計、運用プラクティス、そして組織文化全体に関わる問題だということです。Istioは強力なツールを提供しますが、それを効果的に活用するためには、継続的な学習、実験、そして最適化が不可欠です。7 Observability: Understanding the behavior of your services「Istio in Action」の第7章は、マイクロサービスアーキテクチャにおける重要な課題である観測可能性（Observability）に焦点を当てています。著者は、複雑に絡み合ったサービス群の挙動を理解し、問題を迅速に特定・解決するためのIstioの機能を詳細に解説しています。この章で特に印象に残ったのは観測可能性はデータを収集するだけでなく、そのデータから洞察を得て、システムのパフォーマンス、信頼性、ユーザーエクスペリエンスを向上させることに関するものです。この考え方は、観測可能性の本質を端的に表現しており、単なるモニタリングを超えた価値を強調しています。Istioの観測可能性アーキテクチャ著者は、Istioの観測可能性アーキテクチャについて詳細に解説しています。Istioは、以下の3つの主要な観測可能性機能を提供しています：メトリクス: システムの動作に関する数値データ分散トレーシング: リクエストの流れと各サービスでの処理時間の追跡アクセスログ: 各リクエストの詳細な情報これらの機能は、Istioのデータプレーン（Envoyプロキシ）とコントロールプレーン（istiod）の両方で実装されています。Figure 7.1 Istio is in a position to implement controls and observations. より引用この図は、Istioの観測可能性アーキテクチャの全体像を示しています。Envoyプロキシがデータを収集し、それがPrometheus、Jaeger、Logging Backendなどのツールに送られる様子が描かれています。メトリクス収集の詳細Istioは、サービスメッシュ内のトラフィックに関する豊富なメトリクスを自動的に収集します。これらのメトリクスは、主に以下の4つのカテゴリに分類されます：プロキシレベルメトリクス: Envoyプロキシ自体の性能に関するメトリクスサービスレベルメトリクス: 各サービスのリクエスト量、レイテンシ、エラーレートなどコントロールプレーンメトリクス: istiodの性能と健全性に関するメトリクスIstio標準メトリクス: Istioが定義する標準的なメトリクスセット著者は、これらのメトリクスの詳細と、それらがどのようにPrometheusで収集されるかを説明しています。例えば、以下のようなPrometheusクエリを使用して、特定のサービスの成功率を計算できます：Figure 7.2 Prometheus scraping Istio service proxy for metrics より引用sum(rate(istio_requests_total{reporter=\"destination\",destination_service_name=\"myservice\",response_code!~\"5.*\"}[5m])) / sum(rate(istio_requests_total{reporter=\"destination\",destination_service_name=\"myservice\"}[5m]))このクエリは、過去5分間のリクエスト成功率（5xxエラー以外のレスポンス）を計算します。分散トレーシングの実装著者は、Istioの分散トレーシング機能の実装詳細について深く掘り下げています。Istioは、OpenTelemetryプロトコルを使用して分散トレーシングをサポートしています。トレーシングを有効にするためには、以下の3つの主要なコンポーネントが必要です：トレースコンテキストの伝播: リクエストヘッダーを使用してトレース情報を伝播スパンの生成: 各サービスでの処理をスパンとして記録トレースバックエンド: Jaegerなどのシステムでトレースデータを収集・分析著者は、これらのコンポーネントの設定方法と、効果的な使用方法を詳細に説明しています。例えば、以下のようなTelemetryリソースを使用して、トレーシングの設定をカスタマイズできます：apiVersion: telemetry.istio.io/v1alpha1kind: Telemetrymetadata:  name: tracing-configspec:  tracing:  - customTags:      my_custom_tag:        literal:          value: \"some-constant-value\"    randomSamplingPercentage: 10.00この設定では、10%のリクエストをランダムにサンプリングし、カスタムタグを追加しています。アクセスロギングの高度な設定著者は、Istioのアクセスロギング機能の高度な設定オプションについても詳しく解説しています。アクセスログは、各リクエストの詳細な情報を記録し、後から分析やトラブルシューティングを行うために使用されます。Istioでは、EnvoyFilterリソースを使用してログフォーマットをカスタマイズできます。例えば、以下のような設定で、JSONフォーマットのログを生成できます：apiVersion: networking.istio.io/v1alpha3kind: EnvoyFiltermetadata:  name: custom-access-logspec:  configPatches:  - applyTo: NETWORK_FILTER    match:      context: ANY      listener:        filterChain:          filter:            name: \"envoy.filters.network.http_connection_manager\"    patch:      operation: MERGE      value:        typed_config:          \"@type\": \"type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\"          access_log:          - name: envoy.access_loggers.file            typed_config:              \"@type\": \"type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog\"              path: /dev/stdout              json_format:                time: \"%START_TIME%\"                protocol: \"%PROTOCOL%\"                duration: \"%DURATION%\"                request_method: \"%REQ(:METHOD)%\"                request_host: \"%REQ(HOST)%\"                path: \"%REQ(X-ENVOY-ORIGINAL-PATH?:PATH)%\"                response_code: \"%RESPONSE_CODE%\"                response_flags: \"%RESPONSE_FLAGS%\"                client_ip: \"%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%\"                user_agent: \"%REQ(USER-AGENT)%\"                request_id: \"%REQ(X-REQUEST-ID)%\"                upstream_host: \"%UPSTREAM_HOST%\"                upstream_cluster: \"%UPSTREAM_CLUSTER%\"                upstream_local_address: \"%UPSTREAM_LOCAL_ADDRESS%\"このJSONフォーマットのログは、構造化されているため、Elasticsearchなどのログ分析ツールでより効率的に処理・分析できます。観測可能性データの活用著者は、収集した観測可能性データを実際にどのように活用するかについても詳しく説明しています。主な活用方法として、以下が挙げられています：パフォーマンス最適化: レイテンシメトリクスとトレースデータを使用して、ボトルネックを特定し、最適化問題のトラブルシューティング: エラーレートの急増やレイテンシスパイクの原因を特定容量計画: 長期的なトラフィックトレンドを分析し、適切なスケーリング戦略を立案セキュリティ監査: 異常なトラフィックパターンや不正アクセスの試みを検出SLO/SLAの監視: サービスレベル目標の達成状況をリアルタイムで監視著者は、これらの活用方法について具体的な例を挙げて説明しています。例えば、特定のAPIエンドポイントのレイテンシが急増した場合、以下のようなステップでトラブルシューティングを行うことができます：Grafanaダッシュボードでレイテンシメトリクスを確認し、問題の範囲と影響を特定Jaegerでトレースデータを分析し、どのサービスやコンポーネントが遅延の原因となっているかを特定関連するアクセスログを検索し、問題のリクエストの詳細な情報を確認必要に応じて、Istioの高度なルーティング機能を使用してトラフィックを迂回させ、問題の影響を最小限に抑えるこのような体系的なアプローチにより、複雑なマイクロサービス環境でも効率的に問題を特定・解決することができます。まとめ著者は、観測可能性がマイクロサービスアーキテクチャの成功に不可欠であることを強調しています。Istioの観測可能性機能は、複雑なシステムの挙動を理解し、問題を迅速に特定・解決するための強力なツールセットを提供します。しかし、著者は同時に、観測可能性は技術的な問題だけでなく、組織的な課題でもあることを指摘しています。効果的な観測可能性戦略を実装するためには、以下のような組織的な取り組みが必要です：観測可能性文化の醸成: チーム全体で観測可能性の重要性を理解し、日常的な開発・運用プロセスに組み込むスキルの向上: メトリクス、トレース、ログの効果的な利用方法について、継続的なトレーニングを実施ツールとプラクティスの標準化: 一貫した観測可能性アプローチを組織全体で採用自動化の推進: 観測可能性データの収集、分析、可視化プロセスを可能な限り自動化最後に、著者は将来の展望として、機械学習やAIを活用した高度な異常検知や予測分析の可能性に言及しています。これらの技術とIstioの観測可能性機能を組み合わせることで、さらに強力なシステム監視・最適化が可能になると予想されます。2024年現在の技術動向を踏まえると、本章で説明されている観測可能性の概念と実践は依然として有効であり、その重要性はさらに増しています。特に、OpenTelemetryの普及やクラウドネイティブ環境の複雑化に伴い、Istioの観測可能性機能はより一層重要になっています。8 Observability: Visualizing network behavior with Grafana, Jaeger, and Kiali「Istio in Action」の第8章は、Istioの観測可能性機能に焦点を当て、Grafana、Jaeger、Kialiといった強力なツールを用いてサービスメッシュの動作を可視化する方法を詳細に解説しています。この章で言葉は、観測可能性はデータを収集するだけでなく、そのデータから洞察を得てシステムのパフォーマンス、信頼性、ユーザーエクスペリエンスを向上させることに関するものです。この考え方は、観測可能性の本質を端的に表現しており、単なるモニタリングを超えた価値を強調しています。この章は実際の運用環境でIstioを効果的に活用するための実践的なガイドとして非常に価値があります。特に、複雑なマイクロサービス環境でのトラブルシューティングや性能最適化に必要な洞察を得るための具体的な方法が示されている点が印象的です。Grafanaを用いたメトリクスの可視化著者は、Grafanaを使用してIstioのメトリクスを可視化する方法を詳細に解説しています。Grafanaは、Prometheusが収集したメトリクスを視覚的に表現するためのツールとして紹介されています。このコマンドは、Istioの各種ダッシュボードをKubernetesのConfigMapとして作成します。これにより、Grafanaで簡単にIstioの状態を監視できるようになります。Figure 8.4 The control-plane dashboard with metrics graphed より引用この図は、Grafanaで表示されるIstioコントロールプレーンのダッシュボードを示しています。CPU使用率、メモリ使用率、goroutine数など、重要なメトリクスが視覚化されています。これらのダッシュボードは日常的な運用監視やトラブルシューティングに非常に有用です。例えば、コントロールプレーンのパフォーマンス問題や設定の同期状態を即座に確認できます。分散トレーシングとJaeger著者は、分散トレーシングの概念とJaegerを用いた実装方法について詳細に解説しています。分散トレーシングは、複数のマイクロサービスにまたがるリクエストの流れを追跡し、各サービスでの処理時間やエラーの発生箇所を特定するために不可欠な技術です。Jaegerをデプロイするための最新のYAMLファイルは、Istioの公式リポジトリから入手できます。github.com著者は、分散トレーシングを効果的に活用するためには、アプリケーションコードでトレースヘッダーを適切に伝播することが重要だと強調しています。以下は、Istioが自動的に生成するトレースヘッダーのリストです：x-request-idx-b3-traceidx-b3-spanidx-b3-parentspanidx-b3-sampledx-b3-flagsx-ot-span-contextこれらのヘッダーを適切に伝播することで、サービス間の呼び出しを正確にトレースできます。Figure 8.7 With distributed tracing, we can collect Span s for each network hop, capture them in an overall Trace, and use them to debug issues in our call graph. より引用この図は、分散トレーシングの概念を視覚的に表現しています。複数のサービスにまたがるリクエストの流れと、各サービスでの処理時間が明確に示されています。Figure 8.8 The application must propagate the tracing headers. Otherwise, we lose the full span of the request. より引用SREとして、この機能は特に複雑なマイクロサービス環境でのパフォーマンス問題やエラーの根本原因分析に非常に有効です。例えば、特定のAPI呼び出しが遅い原因が、どのサービスのどの処理にあるのかを迅速に特定できます。Kialiを用いたサービスメッシュの可視化著者は、Kialiを使用してIstioのサービスメッシュを可視化する方法を詳細に解説しています。Kialiは、サービス間の依存関係やトラフィックフローをリアルタイムで視覚化するツールとして紹介されています。Kialiの最新バージョンをデプロイするには、Helm chartを使用することが推奨されています。以下は、Kialiをデプロイするコマンドの例です：helm install \\  --namespace kiali-operator \\  --create-namespace \\  --set cr.create=true \\  --set cr.namespace=istio-system \\  --repo https://kiali.org/helm-charts \\  kiali-operator \\  kiali-operatorこのコマンドは、KialiオペレーターとKialiインスタンスを同時にデプロイします。Kialiの主な機能として、以下が挙げられています：サービス間のトラフィックフローの可視化リアルタイムのヘルスステータス監視Istio設定のバリデーショントレースデータとメトリクスの相関分析Figure 8.15 Simple visual graph of the services in our namespace and how they’re connected to each other より引用この図は、Kialiで表示されるサービスメッシュのグラフビューを示しています。サービス間の依存関係とトラフィックフローが視覚的に表現されています。SREの観点からは、Kialiは特にトラブルシューティングと性能最適化に非常に有用です。例えば、特定のサービスへのトラフィック集中や、予期せぬサービス間の依存関係を視覚的に素早く把握できます。実践的な応用と提案Istioの観測可能性機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：包括的な監視戦略の策定: Grafana、Jaeger、Kialiを組み合わせた包括的な監視戦略を策定します。各ツールの長所を活かし、相互補完的に使用することで、システムの状態をより完全に把握できます。カスタムダッシュボードの作成: Grafanaを使用して、ビジネス目標に直結するカスタムダッシュボードを作成します。例えば、特定のAPIのエラーレートとレイテンシを組み合わせたダッシュボードを作成し、SLOの達成状況を可視化します。トレースサンプリング戦略の最適化: 全てのリクエストをトレースするのではなく、適切なサンプリング戦略を設定します。例えば、エラーが発生したリクエストや特定の重要な処理パスを常にトレースし、それ以外はランダムサンプリングするなどの戦略が考えられます。アラートの適切な設定: メトリクスに基づいて適切なアラートを設定します。ただし、アラートの閾値は慎重に設定し、誤検知や警告疲れを避けるよう注意します。例えば、短期的なスパイクではなく、持続的な問題に対してアラートを発生させるよう設定します。サービスメッシュの健全性監視: Kialiを使用して、サービスメッシュ全体の健全性を定期的に監視します。特に、新しいサービスのデプロイ後や設定変更後には、予期せぬ影響がないか注意深く確認します。トレースデータの分析自動化: Jaegerのトレースデータを自動的に分析し、パフォーマンス低下やエラー増加のパターンを検出するスクリプトを作成します。これにより、問題を早期に発見し、プロアクティブに対応できます。observability-as-codeの実践: 監視設定やダッシュボード定義をコード化し、バージョン管理システムで管理します。これにより、環境間での一貫性を保ち、設定変更の追跡を容易にします。チーム間の知識共有: 定期的なワークショップやドキュメンテーションの更新を通じて、チーム全体でIstioの観測可能性機能に関する知識を共有します。これにより、全てのチームメンバーが効果的にツールを活用できるようになります。まとめ「Istio in Action」の第8章は、Istioの観測可能性機能を実践的に活用するための包括的なガイドを提供しています。Grafana、Jaeger、Kialiといった強力なツールを組み合わせることで、複雑なマイクロサービス環境の動作を詳細に把握し、効果的に管理することが可能になります。著者は、これらのツールを単に導入するだけでなく、実際の運用シナリオでどのように活用するかを具体的に示しています。例えば、Grafanaのダッシュボードを使用してシステムの全体的な健全性を監視し、異常が検出された場合にJaegerのトレースデータを分析してボトルネックを特定し、最後にKialiを使用してサービス間の依存関係を視覚的に確認するといった、総合的なトラブルシューティングアプローチが提案されています。特に印象的だったのは、著者が観測可能性を単なる技術的な課題ではなく、ビジネス価値に直結する重要な要素として位置づけている点です。例えば、トレースデータを活用してユーザーエクスペリエンスの改善につなげたり、Kialiの可視化機能を使用してサービス間の依存関係を最適化したりするなど、観測可能性がビジネスの成功に直接貢献する方法が示されています。9 Securing microservice communication「Istio in Action」の第9章は、マイクロサービスアーキテクチャにおける重要な課題の一つであるセキュリティに焦点を当てています。著者は、Istioが提供する強力なセキュリティ機能を詳細に解説し、サービス間通信の認証、認可、暗号化をどのように実現するかを具体的な例を交えて説明しています。この辺についてはIstioを使わない場合だとマイクロサービス間通信における認証認可およびアクセス制御が良いのでオススメです。zenn.devこの章で特に印象に残ったのは、「Istioはセキュアバイデフォルト」という概念です。これは、Istioがデフォルトで高度なセキュリティ機能を提供し、開発者が意識しなくてもある程度のセキュリティを確保できることを意味しています。しかし、同時に著者は、真のセキュリティを実現するためには、これらの機能を適切に理解し、設定する必要があることも強調しています。Figure 9.1 Monolithic application running on-premises with static IPs より引用この図は、オンプレミス環境で静的IPを使用して運用されるモノリシックアプリケーションを示しています。静的なインフラストラクチャでは、IPアドレスが信頼の良い源となり、認証のための証明書や、ネットワークファイアウォールルールで一般的に使用されます。この環境では、セキュリティの管理が比較的単純です。しかし、著者は続けて、マイクロサービスアーキテクチャへの移行に伴う課題を説明しています。マイクロサービスは容易に数百、数千のサービスに成長し、静的な環境での運用が困難になります。そのため、チームはクラウドコンピューティングやコンテナオーケストレーションなどの動的な環境を活用し、サービスは多数のサーバーにスケジュールされ、短命になります。これにより、IPアドレスを使用する従来の方法は信頼できない識別子となります。さらに、サービスは必ずしも同じネットワーク内で実行されるわけではなく、異なるクラウドプロバイダーやオンプレミスにまたがる可能性があります。この変化は重要です。静的な環境からダイナミックな環境への移行は、セキュリティの実装方法を根本的に変える必要があることを意味します。特に、サービス間認証（mTLS）、エンドユーザー認証（JWT）、細かな認可ポリシーの設定など、現代のクラウドネイティブアプリケーションに不可欠なセキュリティ機能が重要になってきます。サービス間認証（mTLS）著者は、Istioのサービス間認証機能、特に相互TLS（mTLS）について詳細に解説しています。mTLSは、サービス間の通信を暗号化するだけでなく、通信の両端を相互に認証することで、非常に高度なセキュリティを実現します。Figure 9.4 Workloads mutually authenticate using SVID certificates issued by the Istio certificate authority. より引用この図は、Istioの証明書機関（CA）によって発行されたSPIFFE Verifiable Identity Document（SVID）証明書を使用して、ワークロードが相互に認証する様子を示しています。これにより、サービス間のトラフィックが暗号化され、相互に認証されることで、「セキュアバイデフォルト」の状態が実現されます。Istioでは、PeerAuthenticationリソースを使用してmTLSを設定します。例えば、以下のような設定でメッシュ全体にmTLSを強制適用できます：apiVersion: \"security.istio.io/v1beta1\"kind: \"PeerAuthentication\"metadata:  name: \"default\"  namespace: \"istio-system\"spec:  mtls:    mode: STRICTこの設定により、メッシュ内のすべてのサービス間通信がmTLSで保護されます。著者は、この設定の影響を実際のトラフィックフローを用いて説明しており、特に印象的でした。しかし、著者は同時に、既存のシステムへのmTLSの導入には注意が必要であることも強調しています。急激な変更はシステムの安定性を脅かす可能性があるため、PERMISSIVEモードを使用した段階的な導入が推奨されています。SREの観点からは、この段階的アプローチは非常に重要です。本番環境でのセキュリティ強化は、サービスの可用性とのバランスを取りながら慎重に進める必要があります。エンドユーザー認証（JWT）著者は、Istioのエンドユーザー認証機能、特にJSON Web Token（JWT）を使用した認証について詳細に解説しています。この機能により、マイクロサービスは個別に認証ロジックを実装することなく、一貫したエンドユーザー認証を実現できます。Figure 9.12 The server retrieves a JWKS to validate the token presented by the client. より引用この図は、サーバーがJWKS（JSON Web Key Set）を使用してクライアントから提示されたトークンを検証するプロセスを示しています。JWKSには公開鍵が含まれており、これを使用してトークンの署名を検証することで、トークンの真正性を確認します。このプロセスにより、トークンのクレームを信頼し、認可決定に使用することができます。Istioでは、RequestAuthenticationリソースを使用してJWT認証を設定します。例えば：apiVersion: \"security.istio.io/v1beta1\"kind: \"RequestAuthentication\"metadata: name: \"jwt-token-request-authn\" namespace: istio-systemspec:  selector:    matchLabels:      app: istio-ingressgateway jwtRules: - issuer: \"auth@istioinaction.io\"   jwks: |     { \"keys\": [{\"e\":\"AQAB\",\"kid\":\"##REDACTED##\",      \"kty\":\"RSA\",\"n\":\"##REDACTED##\"}]}この設定により、指定されたアプリケーションへのリクエストにJWTが要求されます。著者は、この設定の影響を実際のリクエストフローを用いて説明しており、非常に分かりやすい解説でした。特に印象的だったのは、著者がJWTの検証だけでなく、JWT claimsを使用した細かな認可制御についても言及している点です。これにより、ユーザーの役割や権限に基づいた詳細なアクセス制御が可能になります。認可ポリシー著者は、Istioの認可ポリシー機能について詳細に解説しています。この機能により、サービス間やエンドユーザーのアクセス制御を非常に細かいレベルで設定できます。Figure 9.9 Authorization reduces the attack scope to only what the stolen identity was authorized to access. より引用この図は、認可ポリシーがどのようにしてセキュリティインシデントの影響範囲を限定するかを示しています。適切な認可ポリシーを設定することで、アイデンティティが盗まれた場合でも、アクセス可能な範囲を最小限に抑えることができます。これは、最小権限の原則を実践する上で非常に重要な機能です。Istioでは、AuthorizationPolicyリソースを使用して認可ポリシーを設定します。例えば：apiVersion: \"security.istio.io/v1beta1\"kind: \"AuthorizationPolicy\"metadata:  name: \"allow-mesh-all-ops-admin\"  namespace: istio-systemspec:  rules:    - from:      - source:          requestPrincipals: [\"auth@istioinaction.io/*\"]      when:      - key: request.auth.claims[group]        values: [\"admin\"]この設定により、特定の発行者（\"auth@istioinaction.io\"）からのJWTを持ち、\"admin\"グループに属するユーザーのみがアクセスを許可されます。著者は、この機能の柔軟性と強力さを強調しており、特に印象的でした。例えば、特定のパスへのアクセス、特定のHTTPメソッドの使用、特定のヘッダーの存在など、非常に詳細な条件に基づいてアクセスを制御できます。SREの観点からは、この細かな制御は非常に重要です。最小権限の原則に基づいてアクセスを制限することで、セキュリティインシデントの影響範囲を最小限に抑えることができます。外部認可サービスとの統合著者は、Istioの外部認可サービス統合機能についても解説しています。この機能により、より複雑な認可ロジックや、既存の認可システムとの統合が可能になります。Figure 9.13 Using CUSTOM policies to get requests authorized by an external server より引用この図は、Istioが外部の認可サーバーを使用してリクエストを認可する方法を示しています。サービスプロキシに入ってくるリクエストは、外部認可（ExtAuthz）サービスへの呼び出しを行う間、一時停止します。この ExtAuthz サービスはメッシュ内、アプリケーションのサイドカーとして、あるいはメッシュの外部に存在する可能性があります。これにより、組織固有の複雑な認可ロジックを実装することが可能になります。例えば、以下のようなAuthorizationPolicyを使用して外部認可サービスを設定できます：apiVersion: security.istio.io/v1beta1kind: AuthorizationPolicymetadata:  name: ext-authz  namespace: istioinactionspec:  selector:    matchLabels:      app: webapp  action: CUSTOM  provider:    name: sample-ext-authz-http  rules:  - to:    - operation:        paths: [\"/\"]この設定により、指定されたパスへのリクエストは外部の認可サービスによって評価されます。著者は、この機能の柔軟性と強力さを強調しており、特に印象的でした。例えば、複雑なビジネスロジックに基づく認可や、既存の認証システムとの統合など、Istioの標準機能では難しい要件にも対応できます。しかし、著者は同時に、外部認可サービスの使用にはパフォーマンスのトレードオフがあることも指摘しています。外部サービスへの呼び出しは追加のレイテンシを引き起こす可能性があるため、慎重な設計と最適化が必要です。実践的な応用と提案Istioのセキュリティ機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入戦略の策定: アンビエントメッシュの特性を活かし、既存のサイドカーベースの導入から段階的に移行する計画を立てます。これにより、リスクを最小限に抑えつつ、新しいアーキテクチャの利点を享受できます。ゼロトラスト原則の適用: Istioの細かな認証・認可機能を活用し、全てのサービス間通信に対して「信頼しない」デフォルトポリシーを適用します。必要な通信のみを明示的に許可するアプローチを採用します。動的ポリシー管理の実装: セキュリティポリシーの動的更新機能を活用し、CI/CDパイプラインにセキュリティポリシーの更新プロセスを組み込みます。これにより、アプリケーションの変更に合わせてセキュリティ設定を自動的に更新できます。統合監視・ログ分析の強化: Istioの高度な可観測性機能を活用し、セキュリティイベントの統合監視とログ分析システムを構築します。これにより、セキュリティインシデントの早期検出と迅速な対応が可能になります。定期的なセキュリティ評価の実施: Istioの設定とセキュリティポリシーを定期的に評価し、最新のベストプラクティスや脅威情報に基づいて最適化します。自動化されたセキュリティテストをCI/CDプロセスに組み込むことも検討します。クロスファンクショナルなセキュリティチームの編成: 開発者、運用者、セキュリティ専門家で構成されるクロスファンクショナルなチームを編成し、Istioのセキュリティ機能の設計、実装、運用を協力して行います。これにより、セキュリティを開発ライフサイクルの早い段階から考慮に入れることができます。外部認証サービスのパフォーマンス最適化: 外部認証サービスを使用する場合は、キャッシング戦略の導入や、認証サービスのスケーリングを適切に行い、パフォーマンスへの影響を最小限に抑えます。継続的な学習と能力開発: Istioの進化に合わせて、チームのスキルセットを継続的に更新します。Istioのコミュニティイベントへの参加や、社内トレーニングの実施を検討します。これらの提案を実践することで、Istioのセキュリティ機能を最大限に活用し、より安全で管理しやすいマイクロサービス環境を構築することができるでしょう。まとめ「Istio in Action」の第9章は、Istioのセキュリティ機能について包括的かつ実践的な解説を提供しています。著者は、サービス間認証（mTLS）、エンドユーザー認証（JWT）、細かな認可ポリシーの設定、外部認可サービスとの統合など、現代のマイクロサービスアーキテクチャに不可欠なセキュリティ機能を詳細に説明しています。2024年現在の技術動向と比較すると、Istioのセキュリティ機能はさらに進化し、より柔軟で強力になっています。特に、アンビエントメッシュの導入やゼロトラストアーキテクチャのサポート強化は、大規模環境でのセキュリティ管理を大幅に改善しています。Istioは複雑なマイクロサービス環境におけるセキュリティ課題に対する強力なソリューションを提供しています。しかし、その効果的な活用には、継続的な学習と、組織全体でのセキュリティ文化の醸成が不可欠です。Istioのセキュリティ機能は、マイクロサービスアーキテクチャにおけるセキュリティの複雑さを大幅に軽減し、一貫したセキュリティポリシーの適用を可能にします。しかし、同時に著者が強調しているように、これらの機能を効果的に活用するためには、適切な計画と継続的な管理が必要です。最後に、この章から得られる重要な教訓は、セキュリティは単なる技術的な課題ではなく、システム設計、運用プラクティス、そして組織文化全体に関わる問題だということです。Istioは強力なツールを提供しますが、それを効果的に活用するためには、継続的な学習、実験、そして最適化が不可欠です。今後も進化し続けるIstioとともに、セキュリティもまた進化し続ける必要があるのです。Part 3 Istio day-2 operations10 Troubleshooting the data plane「Istio in Action」の第10章「Troubleshooting the data plane」は、Istioのデータプレーンに関するトラブルシューティングについて詳細に解説しています。この章は、実際の運用環境でIstioを使用する際に直面する可能性のある問題に焦点を当て、それらを効果的に診断し解決するための方法を提供しています。Figure 10.1 Components that participate in routing a request より引用特に印象に残ったのは、著者が繰り返し強調している「プロアクティブなトラブルシューティング」の重要性です。著者は、「デバッグのためのデータプレーンの準備は、実際に問題が発生する前に行うべきだ」と述べています。この言葉は、SREの原則である「事後対応よりも予防」を端的に表現しており、Istioの運用におけるベストプラクティスを示唆しています。技術的詳細と実践的応用データプレーンの同期状態の確認著者は、Istioのデータプレーンのトラブルシューティングを始める前に、まずデータプレーンが最新の設定と同期しているかを確認することの重要性を強調しています。これには、istioctl proxy-statusコマンドが使用されます。$ istioctl proxy-statusNAME                                      CDS      LDS      EDS        RDS          ISTIOD      VERSIONcatalog-68666d4988-q6w42.istioinaction    SYNCED   SYNCED   SYNCED     SYNCED       istiod-1...  1.22.0このコマンドの出力は、各Envoyプロキシが最新の設定（CDS, LDS, EDS, RDS）と同期しているかを示します。SYNCED状態は正常であり、NOT SENTやSTALEは潜在的な問題を示唆します。著者は、この同期状態の確認が重要である理由を次のように説明しています：データプレーンの設定は最終的に一貫性のあるものですが、即時に反映されるわけではありません。環境の変化（サービス、エンドポイント、ヘルスステータスの変更）や設定の変更は、データプレーンに即座に反映されるわけではありません。大規模なクラスターでは、同期に要する時間がワークロードとイベントの数に比例して増加します。Figure 10.3 Series of events until the configuration of a data-plane component is updated after a workload becomes unhealthy より引用Figure 10.3は、ワークロードが不健全になってからデータプレーンコンポーネントの設定が更新されるまでの一連のイベントを示しています。この図は、設定の同期プロセスの複雑さを視覚的に表現しており、同期状態の確認が重要である理由を理解する上で非常に有用です。SREの視点から、この同期状態の確認は非常に重要です。設定の不整合は予期せぬ動作やエラーの原因となる可能性があるため、定期的な確認とモニタリングを自動化することをおすすめします。Kialiを使用した設定の検証著者は、Kialiを使用してIstioの設定を視覚的に検証する方法を紹介しています。Kialiは、サービスメッシュの状態を可視化し、潜在的な問題を特定するのに役立ちます。$ istioctl dashboard kialihttp://localhost:20001/kialiこのコマンドでKialiダッシュボードにアクセスできます。Kialiの使用は、特に大規模なマイクロサービス環境で非常に有効です。視覚的な表現により、複雑な依存関係やトラフィックパターンを素早く把握でき、問題の早期発見に役立ちます。Envoy設定の詳細分析著者は、Envoyプロキシの設定を詳細に分析する方法について深く掘り下げています。istioctl proxy-configコマンドを使用して、特定のプロキシの設定を検査できます。例えば、特定のサービスのリスナー設定を確認するには：$ istioctl proxy-config listeners deploy/istio-ingressgateway -n istio-systemADDRESS PORT  MATCH DESTINATION0.0.0.0 8080  ALL   Route: http.80800.0.0.0 15021 ALL   Inline Route: /healthz/ready*0.0.0.0 15090 ALL   Inline Route: /stats/prometheus*このコマンドは、指定されたデプロイメントのEnvoyプロキシに設定されているリスナーを表示します。著者は、この出力を詳細に解説し、各リスナーの役割と重要性を説明しています。さらに、ルート設定を確認するには：$ istioctl pc routes deploy/istio-ingressgateway -n istio-system --name http.8080 -o json著者は、このコマンドの出力を詳細に解説し、ルーティングの設定がどのように行われているかを説明しています。特に、重み付けされたクラスターの設定や、マッチングルールの詳細について触れています。これらのコマンドを使いこなすことで、トラフィックの流れを詳細に理解し、ルーティングの問題を特定することができます。SREとして、これらのツールを使用して定期的に設定を監査し、意図しない変更や設定ミスを検出することが重要です。アクセスログの活用著者は、Envoyプロキシのアクセスログの重要性と、それを効果的に活用する方法について詳しく説明しています。アクセスログは、リクエストの詳細な情報を提供し、トラブルシューティングに不可欠です。著者は、デフォルトのTEXTフォーマットのログが簡潔であるが理解しにくいことを指摘し、JSONフォーマットへの変更を推奨しています。以下は、JSONフォーマットに変更する方法です：$ istioctl install --set profile=demo \\    --set meshConfig.accessLogEncoding=\"JSON\"JSONフォーマットのログの例：{  \"user_agent\":\"curl/7.64.1\",  \"Response_code\":\"504\",  \"response_flags\":\"UT\",  \"start_time\":\"2020-08-22T16:35:27.125Z\",  \"method\":\"GET\",  \"request_id\":\"e65a3ea0-60dd-9f9c-8ef5-42611138ba07\",  \"upstream_host\":\"10.1.0.68:3000\",  \"x_forwarded_for\":\"192.168.65.3\",  \"requested_server_name\":\"-\",  \"bytes_received\":\"0\",  \"istio_policy_status\":\"-\",  \"bytes_sent\":\"24\",  \"upstream_cluster\":    \"outbound|80|version-v2|catalog.istioinaction.svc.cluster.local\",  \"downstream_remote_address\":\"192.168.65.3:41260\",  \"authority\":\"catalog.istioinaction.io\",  \"path\":\"/items\",  \"protocol\":\"HTTP/1.1\",  \"upstream_service_time\":\"-\",  \"upstream_local_address\":\"10.1.0.69:48016\",  \"duration\":\"503\",  \"upstream_transport_failure_reason\":\"-\",  \"route_name\":\"-\",  \"downstream_local_address\":\"10.1.0.69:8080\"}著者は、このJSONフォーマットのログの各フィールドの意味を詳細に解説しています。特に、response_flagsフィールドの重要性を強調しており、このフィールドが接続の失敗に関する詳細情報を提供することを説明しています。SREの観点からは、このようなカスタマイズされたログ設定は非常に有用です。特定の条件に基づいてログをフィルタリングすることで、問題の迅速な特定と分析が可能になります。また、ログの集中管理と分析のために、ElasticsearchやSplunkなどのログ管理システムとの統合も検討すべきです。まとめ「Istio in Action」の第10章は、Istioのデータプレーンのトラブルシューティングに関する包括的かつ実践的なガイドを提供しています。著者は、プロアクティブなアプローチの重要性を強調し、問題が発生する前に潜在的な課題を特定し対処することの価値を説いています。この章では、istioctl、Kiali、Envoyの管理インターフェースなど、Istioが提供する豊富なツールセットの効果的な活用方法が詳細に解説されています。これらのツールを適切に使用することで、複雑なマイクロサービス環境での問題診断と解決が大幅に効率化されることが示されています。特に印象的なのは、著者がデータプレーンの同期状態の確認、Envoy設定の詳細分析、アクセスログの活用など、実践的なテクニックを具体的に示している点です。これらの手法は、実際の運用環境で即座に適用可能で、大きな価値があります。著者は、効果的なトラブルシューティングには単なる技術的スキルだけでなく、システム全体を理解し、プロアクティブに問題解決に取り組む姿勢が重要であることを強調しています。この観点は、特に複雑化するマイクロサービス環境において非常に重要です。2024年現在、IstioはアンビエントメッシュやWebAssemblyの進化など、さらなる発展を遂げています。これらの新技術は、トラブルシューティングの手法にも影響を与えており、より効率的で柔軟なアプローチが可能になっています。結論として、この章はIstioのデータプレーンのトラブルシューティングを単なる技術的タスクではなく、継続的な改善プロセスとして捉えることの重要性を示しています。効果的なトラブルシューティング文化を醸成し、チーム全体でスキルとナレッジを共有することが、長期的な運用の成功につながるのです。この章で学んだテクニックと原則を適用し、継続的に改善していくことで、より安定性の高い、レジリエントなシステムを構築・運用することができるでしょう。11 Performance-tuning the control plane「Istio in Action」の第11章は、Istioのコントロールプレーンのパフォーマンス最適化に焦点を当てています。著者は、コントロールプレーンがサービスプロキシを設定する方法、このプロセスを遅くする要因、監視方法、そしてパフォーマンスを向上させるための調整ポイントを詳細に解説しています。特に印象に残ったのは、著者が繰り返し強調している「プロアクティブなパフォーマンス管理」の重要性です。著者は、「デバッグのためのデータプレーンの準備は、実際に問題が発生する前に行うべきだ」と述べています。この考え方は、SREの原則である「事後対応よりも予防」を端的に表現しており、Istioの運用におけるベストプラクティスを示唆しています。技術的詳細と実践的応用コントロールプレーンの目標著者は、コントロールプレーンの主要な目標を「データプレーンを望ましい状態に同期させ続けること」と定義しています。この同期プロセスが適時に行われないと、ファントムワークロードという現象が発生する可能性があります。これは、既に存在しないエンドポイントにトラフィックがルーティングされ、結果としてリクエストが失敗する状況を指します。Figure 11.1 Routing traffic to phantom workloads due to an outdated configuration より引用この図は、ワークロードの状態変化、設定更新の遅延、そして古い設定に基づくトラフィックルーティングの問題を明確に示しています。SREの観点からは、この問題は特に重要です。システムの一貫性と信頼性を維持するために、コントロールプレーンのパフォーマンスを常に監視し、最適化する必要があります。パフォーマンスに影響を与える要因著者は、コントロールプレーンのパフォーマンスに影響を与える主な要因を以下のように特定しています：変更の頻度: 環境の変更が頻繁に発生すると、データプレーンの同期に必要な処理が増加します。割り当てられたリソース: istiodに割り当てられたリソースが需要に対して不足すると、更新の配布が遅くなります。管理対象ワークロードの数: 更新を配布するワークロードが多いほど、より多くの処理能力とネットワーク帯域幅が必要になります。設定のサイズ: より大きなEnvoy設定の配布には、より多くの処理能力とネットワーク帯域幅が必要です。Figure 11.3 The properties that affect control-plane performance より引用この図はこれらの要因を視覚的に表現しています。この図は、コントロールプレーンのパフォーマンスに影響を与える各要素の関係を明確に示しており、パフォーマンス最適化の戦略を立てる上で非常に有用です。パフォーマンスモニタリング著者は、Grafanaダッシュボードを使用してIstioのコントロールプレーンのパフォーマンスを監視する方法を詳細に解説しています。特に、4つのゴールデンシグナル（レイテンシ、飽和度、エラー、トラフィック）に基づいたモニタリングアプローチを推奨しています。例えば、レイテンシを測定するための主要なメトリクスとしてpilot_proxy_convergence_timeが挙げられています。このメトリクスは、プロキシプッシュリクエストがキューに入ってから、ワークロードに配布されるまでの全プロセスの所要時間を測定します。apiVersion: telemetry.istio.io/v1alpha1kind: Telemetrymetadata:  name: custom-metrics  namespace: istio-systemspec:  metrics:  - providers:    - name: prometheus    overrides:    - match:        metric: PILOT_PROXY_CONVERGENCE_TIME      tagOverrides:        response_code:          value: \"response.code\"この設定例は、Istio 1.22（2024年8月現在の最新版）に合わせて更新されています。これにより、pilot_proxy_convergence_timeメトリクスをカスタマイズし、より詳細な分析が可能になります。SREとして、これらのメトリクスを継続的に監視し、異常を早期に検出することが重要です。例えば、pilot_proxy_convergence_timeが突然増加した場合、コントロールプレーンの設定更新プロセスに問題が発生している可能性があり、即時の調査が必要です。パフォーマンス最適化技術著者は、コントロールプレーンのパフォーマンスを最適化するための複数の技術を紹介しています：Sidecarリソースの使用: 著者は、Sidecarリソースを使用してワークロードのイングレスとイグレストラフィックを細かく制御することの重要性を強調しています。これにより、各ワークロードに送信される設定のサイズを大幅に削減できます。apiVersion: networking.istio.io/v1beta1kind: Sidecarmetadata:  name: default  namespace: istio-systemspec:  egress:  - hosts:    - \"istio-system/*\"    - \"prometheus/*\"  outboundTrafficPolicy:    mode: REGISTRY_ONLYこの設定例は、メッシュ全体のデフォルトSidecar設定を定義しています。これにより、各サービスプロキシの設定サイズが大幅に削減され、コントロールプレーンの負荷が軽減されます。イベントのバッチ処理: 著者は、PILOT_DEBOUNCE_AFTERとPILOT_DEBOUNCE_MAX環境変数を使用してイベントのバッチ処理を最適化する方法を説明しています。これにより、頻繁な更新による負荷を軽減できます。リソースの割り当て: コントロールプレーンのスケールアウトとスケールアップの戦略について詳細に解説されています。著者は、出力トラフィックがボトルネックの場合はスケールアウト、入力トラフィックがボトルネックの場合はスケールアップを推奨しています。istioctl install --set profile=demo \\  --set values.pilot.resources.requests.cpu=2 \\  --set values.pilot.resources.requests.memory=4Gi \\  --set values.pilot.replicaCount=3この設定例は、istiodのリソース要求とレプリカ数を増やしています。これにより、コントロールプレーンの処理能力と冗長性が向上します。実践的な応用と提案Istioのコントロールプレーンのパフォーマンスを最適化するために、以下の実践的な提案を考えてみましょう：継続的なモニタリングの実装: Prometheusとgrafanaを使用して、コントロールプレーンの主要メトリクス（pilot_proxy_convergence_time、pilot_xds_pushesなど）を継続的に監視します。異常値の検出時に自動アラートを設定することで、問題の早期発見と対応が可能になります。段階的なSidecar設定の導入: まず、メッシュ全体のデフォルトSidecar設定を導入し、その後各サービスに特化したSidecar設定を段階的に実装します。これにより、設定サイズと更新頻度を大幅に削減できます。イベントバッチ処理の最適化: 環境変数PILOT_DEBOUNCE_AFTERとPILOT_DEBOUNCE_MAXを調整し、イベントのバッチ処理を最適化します。ただし、過度の遅延を避けるため、慎重に調整する必要があります。リソース割り当ての定期的な見直し: コントロールプレーンのCPUとメモリ使用率を定期的に確認し、必要に応じてリソースを調整します。特に、クラスターの成長に合わせて、istiodのレプリカ数を適切に増やすことが重要です。パフォーマンステストの自動化: 定期的にパフォーマンステストを実行し、設定変更やクラスターの成長がコントロールプレーンのパフォーマンスに与える影響を評価します。これにより、プロアクティブな最適化が可能になります。アンビエントメッシュの検討: 大規模環境では、アンビエントメッシュの採用を検討します。これにより、コントロールプレーンの負荷を大幅に軽減し、より効率的なリソース利用が可能になります。まとめ「Istio in Action」の第11章は、Istioのコントロールプレーンのパフォーマンス最適化について包括的かつ実践的な洞察を提供しています。著者は、パフォーマンスに影響を与える要因を明確に特定し、それぞれに対する最適化戦略を提示しています。特に印象的だったのは、著者がパフォーマンス最適化を単なる技術的な問題ではなく、システム設計と運用プラクティス全体に関わる課題として捉えている点です。Sidecarリソースの適切な使用、イベントのバッチ処理、リソース割り当ての最適化など、提案された戦略は、いずれも実際の運用環境で即座に適用可能で大きな価値があります。SREの観点からは、この章で提示されたモニタリングアプローチと最適化技術は非常に重要です。4つのゴールデンシグナルに基づいたモニタリング、継続的なパフォーマンス測定、そして段階的な最適化アプローチは、大規模なマイクロサービス環境での安定性と効率性を維持する上で不可欠です。2024年現在の技術動向を踏まえると、本章で説明されている原則は依然として有効ですが、アンビエントメッシュやWaypoint Proxyなどの新技術により、さらに効率的なパフォーマンス最適化が可能になっています。これらの新技術を適切に活用することで、より大規模で複雑な環境でもIstioを効果的に運用できるようになっています。Part 4 Istio in your organization12 Scaling Istio in your organization「Istio in Action」の第12章は、Istioを組織内で大規模に展開する方法に焦点を当てています。著者は、マルチクラスター環境でのIstioの導入、クラスター間の通信の確立、そしてサービスメッシュの拡張について詳細に解説しています。特に印象に残ったのは、著者が繰り返し強調している「メッシュの価値は、より多くのワークロードがそれに参加するほど増加する」という考え方です。この言葉は、Istioの導入を単なる技術的な課題ではなく、組織全体のアーキテクチャ戦略として捉える重要性を示唆しています。マルチクラスターサービスメッシュの利点著者は、マルチクラスターサービスメッシュの主な利点を以下のように説明しています：改善された分離: チーム間の影響を最小限に抑える障害の境界: クラスター全体に影響を与える可能性のある設定や操作の範囲を制限する規制とコンプライアンス: センシティブなデータにアクセスするサービスを他のアーキテクチャ部分から制限する可用性とパフォーマンスの向上: 異なる地域でクラスターを実行し、最も近いクラスターにトラフィックをルーティングするマルチクラウドとハイブリッドクラウド: 異なる環境でワークロードを実行する能力これらの利点は、現代の複雑な分散システム環境において非常に重要です。特に、SREの観点からは、可用性の向上と障害の局所化は、システムの信頼性を大幅に向上させる可能性があります。Figure 12.1 A multi-cluster service mesh requires cross-cluster discovery, connectivity, and common trust. より引用この図は、クラスター間の発見、接続性、共通信頼の重要性を視覚的に表現しており、マルチクラスター環境の複雑さを理解する上で非常に有用です。技術的詳細と実践的応用マルチクラスター導入モデル著者は、Istioのマルチクラスター導入モデルを3つに分類しています：プライマリ-リモート（共有コントロールプレーン）Figure 12.2 Primary-remote deployment model より引用プライマリ-プライマリ（複製されたコントロールプレーン）Figure 12.3 Primary-primary deployment model より引用外部コントロールプレーンFigure 12.4 The external control plane deployment model より引用これらのモデルの中で、著者は特にプライマリ-プライマリモデルに焦点を当てています。このモデルでは、各クラスターに独自のIstioコントロールプレーンが存在し、高可用性を実現しています。クラスター間のワークロード発見著者は、クラスター間でのワークロード発見のメカニズムを詳細に説明しています。特に興味深いのは、Kubernetes APIサーバーへのアクセスを制御するためのRBACの使用です。apiVersion: v1kind: Secretmetadata:  name: istio-remote-secret-east-cluster  namespace: istio-systemstringData:  east-cluster: |    apiVersion: v1    kind: Config    clusters:    - cluster:        certificate-authority-data: \u003comitted\u003e        server: https://east-cluster-api-server:443      name: east-cluster    users:    - name: east-cluster      user:        token: \u003comitted\u003e    contexts:    - context:        cluster: east-cluster        user: east-cluster      name: east-cluster    current-context: east-clusterこのサンプルコードは、リモートクラスターへのアクセスを設定するためのシークレットを示しています。これは、Istio 1.22（2024年8月現在の最新版）でも同様に使用されています。このアプローチにより、クラスター間で安全にワークロードを発見し、通信を確立することができます。クラスター間の接続性著者は、クラスター間の接続性を確立するためのイースト-ウェストゲートウェイの概念を導入しています。これは、異なるネットワーク間でトラフィックをルーティングするための特別なIngressゲートウェイです。apiVersion: install.istio.io/v1alpha1kind: IstioOperatormetadata:  name: istio-eastwestgateway  namespace: istio-systemspec:  profile: empty  components:    ingressGateways:    - name: istio-eastwestgateway      label:        istio: eastwestgateway      enabled: true      k8s:        env:          - name: ISTIO_META_ROUTER_MODE            value: \"sni-dnat\"このサンプルコードは、イースト-ウェストゲートウェイの設定を示しています。ISTIO_META_ROUTER_MODEをsni-dnatに設定することで、SNIベースのルーティングが有効になり、クラスター間のトラフィックを効率的に管理できます。クラスター間の認証と認可著者は、クラスター間の通信を保護するための相互TLS（mTLS）の使用と、クラスター間での認可ポリシーの適用について詳細に説明しています。apiVersion: security.istio.io/v1beta1kind: AuthorizationPolicymetadata:  name: allow-only-ingress  namespace: istioinactionspec:  action: ALLOW  rules:  - from:    - source:        principals: [\"cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account\"]このサンプルコードは、特定のソース（この場合はIngressゲートウェイ）からのトラフィックのみを許可する認可ポリシーを示しています。これにより、クラスター間でのセキュアな通信が可能になります。実践的な応用と提案Istioのマルチクラスター機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入戦略: まず小規模なプロジェクトでマルチクラスター設定を試験的に導入し、徐々に範囲を拡大していくことをおすすめします。これにより、チームはマルチクラスター環境の複雑さに慣れることができ、潜在的な問題を早期に特定できます。ネットワークトポロジーの最適化: クラスター間のレイテンシーを最小限に抑えるため、地理的に分散したクラスターの配置を慎重に計画します。例えば、主要な顧客基盤に近い場所にクラスターを配置することで、全体的なパフォーマンスを向上させることができます。セキュリティポリシーの統一: マルチクラスター環境全体で一貫したセキュリティポリシーを実装します。これには、共通のmTLS設定、統一された認可ポリシー、そしてクラスター間での証明書管理の調和が含まれます。観測可能性の強化: Istioの観測可能性機能を活用し、クラスター間のトラフィックフローを包括的に可視化します。Grafana、Jaeger、Kialiなどのツールを統合し、マルチクラスター環境全体のパフォーマンスと健全性を監視します。災害復旧計画の策定: マルチクラスター環境の利点を活かし、強固な災害復旧計画を策定します。これには、クラスター間でのトラフィックの動的な再ルーティング、データの地理的レプリケーション、そして自動フェイルオーバーメカニズムの実装が含まれます。継続的な学習と最適化: マルチクラスター環境は複雑であり、常に進化しています。定期的な性能評価、セキュリティ監査、そして新しいIstioの機能やベストプラクティスの採用を通じて、環境を継続的に最適化します。まとめ「Istio in Action」の第12章は、Istioを用いたマルチクラスターサービスメッシュの実装について包括的かつ実践的な洞察を提供しています。著者は、マルチクラスター環境の利点、技術的な課題、そして具体的な実装方法を詳細に解説しており、読者に豊富な知識と実践的なガイダンスを提供しています。特に印象的だったのは、著者がマルチクラスター環境を単なる技術的な課題ではなく、組織全体のアーキテクチャ戦略として捉えている点です。改善された分離、障害の局所化、規制対応、そして地理的な可用性の向上など、マルチクラスターアプローチの多岐にわたる利点は、現代の複雑なマイクロサービス環境において非常に価値があります。SREの観点からは、この章で提示されたマルチクラスター戦略は、システムの信頼性、可用性、そしてスケーラビリティを大幅に向上させる可能性を秘めています。特に、地理的に分散したクラスター間でのトラフィック管理、セキュリティポリシーの統一的な適用、そして包括的な観測可能性の実現は、大規模で複雑な分散システムの運用を大幅に簡素化します。2024年現在の技術動向を踏まえると、本章で説明されている原則は依然として有効ですが、アンビエントメッシュやKubernetes Gateway APIのサポートなど、新しい機能によりさらに強化されています。これらの新技術は、マルチクラスター環境でのIstioの採用をより容易にし、より効率的な運用を可能にしています。最後に、この章から得られる重要な教訓は、マルチクラスターサービスメッシュの実装は技術的な課題であると同時に、組織的な課題でもあるということです。成功のためには、技術チーム間の緊密な協力、明確なガバナンスモデル、そして継続的な学習と最適化が不可欠です。13 Incorporating virtual machine workloads into the mesh「Istio in Action」の第13章は、Istioのサービスメッシュに仮想マシン（VM）ワークロードを統合する方法について詳細に解説しています。この章は、Kubernetes環境だけでなく、レガシーなVMベースのワークロードも含めた包括的なサービスメッシュの構築方法を提供しており、多くの組織が直面する現実的な課題に対するソリューションを示しています。著者は、VMワークロードをIstioメッシュに統合する必要性を明確に説明しています。特に印象に残ったのは、以下の点です：レガシーワークロードの重要性: 著者は、多くの組織が完全にKubernetesに移行できない理由を説明しています。規制要件、アプリケーションの複雑さ、VMに特有の依存関係などが挙げられており、これは現実のエンタープライズ環境を反映しています。段階的な近代化: 著者は、VMワークロードをメッシュに統合することで、段階的な近代化が可能になると主張しています。これは、全てを一度に変更するリスクを軽減し、安全かつ効率的な移行を可能にします。統一されたセキュリティとオブザーバビリティ: VMワークロードをメッシュに統合することで、Kubernetes上のワークロードと同じセキュリティポリシーと観測可能性を適用できる点が強調されています。これは、一貫したセキュリティ体制の維持と、システム全体の可視性の確保に非常に重要です。Figure 13.1 What it takes for a workload to become part of the mesh より引用この図は、モノリシックなアプリケーション（ACMEmono）からマイクロサービスへの移行過程を示しています。VMで動作するレガシーコンポーネントと、Kubernetes上の新しいマイクロサービスが共存している様子がわかります。この構造は、多くの組織が直面している現実的な移行シナリオを端的に表現しています。技術的詳細と実践的応用Istioの最新VMサポート機能著者は、Istioの最新のVMサポート機能について詳細に解説しています。特に注目すべき点は以下の通りです：WorkloadGroup: VMワークロードのグループを定義するためのリソース。これにより、VMインスタンスの共通プロパティを定義し、高可用性を実現できます。WorkloadEntry: 個々のVMワークロードを表すリソース。これにより、VMをKubernetesのPodと同様に扱うことができます。istio-agent: VMにインストールされるIstioのコンポーネント。これにより、VMがメッシュの一部として機能し、トラフィックの管理、セキュリティ、観測可能性の機能を利用できるようになります。以下は、WorkloadGroupの例です（Istio 1.22現在）：apiVersion: networking.istio.io/v1alpha3kind: WorkloadGroupmetadata:  name: product-catalog-vm  namespace: ecommercespec:  metadata:    labels:      app: product-catalog      version: v1  template:    serviceAccount: product-catalog-sa    network: vm-network  probe:    periodSeconds: 5    initialDelaySeconds: 10    httpGet:      port: 8080      path: /healthzこの設定により、product-catalogアプリケーションのVMワークロードグループが定義されます。ラベル、サービスアカウント、ネットワーク設定、そしてヘルスチェックの設定が含まれており、これらはKubernetesのDeploymentリソースに類似しています。VMワークロードの統合プロセス著者は、VMワークロードをIstioメッシュに統合するプロセスを段階的に説明しています。主要なステップは以下の通りです：istio-agentのインストール: VMにistio-agentをインストールし、必要な設定を行います。ワークロードIDのプロビジョニング: VMワークロードに適切なIDを割り当てます。これは、メッシュ内での認証と認可に使用されます。DNS解決の設定: クラスター内のサービスを解決するために、DNSプロキシを設定します。トラフィックのキャプチャ: iptablesルールを使用して、VMからのトラフィックをIstioプロキシにリダイレクトします。特に印象的だったのは、著者がこのプロセスの自動化の重要性を強調している点です。大規模な環境では、手動でこれらのステップを実行することは現実的ではありません。Figure 13.9 Virtual machine integration in the service mesh より引用この図は、VMがどのようにしてIstioメッシュに統合されるかを視覚的に示しています。VMにistio-agentがインストールされ、East-Westゲートウェイを介してクラスター内のサービスと通信している様子がわかります。セキュリティと観測可能性著者は、VMワークロードをメッシュに統合することで得られるセキュリティと観測可能性の利点について詳しく説明しています。特に注目すべき点は以下の通りです：相互TLS（mTLS）: VMワークロードとKubernetesワークロードの間で自動的にmTLSが設定され、通信が暗号化されます。統一されたアクセス制御: AuthorizationPolicyリソースを使用して、VMワークロードに対しても細かなアクセス制御が可能になります。分散トレーシング: Jaegerなどのツールを使用して、VMワークロードを含むエンドツーエンドのトレースが可能になります。メトリクス収集: PrometheusがVMワークロードのメトリクスも収集できるようになり、統一されたモニタリングが可能になります。以下は、VMワークロードに対するAuthorizationPolicyの例です（Istio 1.22現在）：apiVersion: security.istio.io/v1beta1kind: AuthorizationPolicymetadata:  name: product-catalog-policy  namespace: ecommercespec:  selector:    matchLabels:      app: product-catalog  action: ALLOW  rules:  - from:    - source:        principals: [\"cluster.local/ns/ecommerce/sa/frontend\"]  - to:    - operation:        methods: [\"GET\"]この設定により、product-catalogサービス（VMで動作）に対するアクセスが、frontendサービスアカウントからのGETリクエストのみに制限されます。これは、Kubernetes上のワークロードに適用されるポリシーと完全に一貫しています。実践的な応用と提案VMワークロードのIstioメッシュへの統合を効果的に行うために、以下の実践的な提案を考えてみましょう：段階的な導入戦略: まず小規模なプロジェクトでVM統合を試験的に導入し、徐々に範囲を拡大していくことをおすすめします。これにより、チームはVM統合の複雑さに慣れることができ、潜在的な問題を早期に特定できます。自動化パイプラインの構築: VMのプロビジョニング、istio-agentのインストール、メッシュへの統合までを自動化するパイプラインを構築します。TerraformやAnsibleなどのツールを活用し、一貫性のある再現可能なプロセスを確立します。ネットワークトポロジーの最適化: VMとKubernetesクラスター間のネットワーク接続を最適化します。可能であれば、VPCピアリングやクラウドプロバイダのSDNを活用して、レイテンシーを最小限に抑えます。セキュリティポリシーの統一: VMワークロードとKubernetesワークロードに対して一貫したセキュリティポリシーを適用します。AuthorizationPolicyやPeerAuthenticationリソースを活用し、ゼロトラストアーキテクチャを実現します。観測可能性の強化: PrometheusやJaegerなどのツールを活用し、VMワークロードの詳細なメトリクスとトレースを収集します。Grafanaダッシュボードを作成し、VMとKubernetesワークロードの統合ビューを提供します。災害復旧計画の策定: VMワークロードを含めた包括的な災害復旧計画を策定します。特に、VMのフェイルオーバーやデータの一貫性確保に注意を払います。パフォーマンス最適化: VMワークロードのIstio統合によるオーバーヘッドを慎重に監視し、必要に応じて最適化します。特に、リソース制約のあるVMでは、アンビエントメッシュの採用を検討します。継続的な学習と最適化: VMワークロードの統合は複雑であり、常に進化しています。定期的な性能評価、セキュリティ監査、そして新しいIstioの機能やベストプラクティスの採用を通じて、環境を継続的に最適化します。まとめ「Istio in Action」の第13章は、VMワークロードをIstioメッシュに統合するための包括的かつ実践的なガイドを提供しています。著者は、この統合の技術的な詳細だけでなく、組織がなぜこのアプローチを採用すべきかという戦略的な理由も明確に説明しています。特に印象的だったのは、著者がVMワークロードの統合を単なる技術的な課題ではなく、組織全体のアーキテクチャ戦略として捉えている点です。レガシーシステムの段階的な近代化、セキュリティとオブザーバビリティの統一、そして運用の簡素化など、VMワークロード統合の多岐にわたる利点は、現代の複雑なハイブリッド環境において非常に価値があります。SREの観点からは、この章で提示されたVM統合戦略は、システムの一貫性、セキュリティ、そして観測可能性を大幅に向上させる可能性を秘めていまると思います。14 Extending Istio on the request path「Istio in Action」の第14章は、IstioのデータプレーンであるEnvoyプロキシの拡張性に焦点を当てています。この章では、Envoyフィルターの理解から始まり、EnvoyFilterリソースの使用、Luaスクリプトによるカスタマイズ、そしてWebAssembly（Wasm）を用いた高度な拡張まで、幅広いトピックがカバーされています。著者は、Istioが提供する豊富な機能セットを超えて、組織固有のニーズに合わせてIstioを拡張する必要性を強調しています。特に印象的だったのは、以下の一文です：\"Istioを採用する組織は、Istioが標準機能では満たせない他の制約や前提条件を持っている可能性が高いでしょう。これらの制約により適合させるために、Istioの機能を拡張する必要が出てくる可能性が高いです。:Organizations adopting Istio will likely have other constraints or assumptions that Istio may not fulfill out of the box. You will likely need to extend Istio's capabilities to more nicely fit within these constraints.\"この言葉は、Istioを実際の運用環境に導入する際の現実的な課題を端的に表現しており、カスタマイズの重要性を強調しています。著者は、Envoyの拡張性を活用することで、以下のような機能を実現できると説明しています：レート制限や外部認証サービスとの統合ヘッダーの追加、削除、変更リクエストペイロードのエンリッチメントカスタムプロトコル（HMAC署名/検証など）の実装非標準のセキュリティトークン処理これらの拡張機能は、実際のプロダクション環境で直面する可能性が高い要件であり、Istioの柔軟性を示しています。技術的詳細と実践的応用Envoyフィルターの理解著者は、Envoyの内部アーキテクチャがリスナーとフィルターを中心に構築されていることを説明しています。特に、HTTP Connection Manager（HCM）の重要性が強調されており、これがHTTPリクエストの処理と様々なHTTPフィルターの適用を担当していることが解説されています。Figure 14.3 HttpConnectionManager is a popular and useful network filter for converting a stream of bytes into HTTP (HTTP/1, HTTP/2, and so on) requests and routing them based on L7 properties like headers or body details. より引用この図は、HCMがバイトストリームをHTTPリクエストに変換し、L7プロパティに基づいてルーティングする様子を視覚的に示しており、Envoyの内部動作を理解する上で非常に有用です。EnvoyFilterリソースの使用著者は、IstioのEnvoyFilterリソースを使用してEnvoyの設定を直接カスタマイズする方法を詳細に説明しています。以下は、タップフィルターを設定するEnvoyFilterの例です：apiVersion: networking.istio.io/v1alpha3kind: EnvoyFiltermetadata:  name: tap-filter  namespace: istioinactionspec:  workloadSelector:    labels:      app: webapp  configPatches:  - applyTo: HTTP_FILTER    match:      context: SIDECAR_INBOUND      listener:        portNumber: 8080        filterChain:          filter:            name: \"envoy.filters.network.http_connection_manager\"            subFilter:              name: \"envoy.filters.http.router\"    patch:      operation: INSERT_BEFORE      value:       name: envoy.filters.http.tap       typed_config:          \"@type\": \"type.googleapis.com/envoy.extensions.filters.http.tap.v3.Tap\"          commonConfig:            adminConfig:              configId: tap_configこの設定は、特定のワークロードに対してタップフィルターを追加し、リクエストの詳細な情報を取得できるようにします。SREの観点からは、このような機能はトラブルシューティングや性能分析に非常に有用です。Luaスクリプトによるカスタマイズ著者は、Luaスクリプトを使用してEnvoyの動作をカスタマイズする方法を紹介しています。以下は、A/Bテスト用のグループ情報をヘッダーに追加するLuaスクリプトの例です：function envoy_on_request(request_handle)  local headers, test_bucket = request_handle:httpCall(    \"bucket_tester\",    {      [\":method\"] = \"GET\",      [\":path\"] = \"/\",      [\":scheme\"] = \"http\",      [\":authority\"] = \"bucket-tester.istioinaction.svc.cluster.local\",      [\"accept\"] = \"*/*\"    }, \"\", 5000)  request_handle:headers():add(\"x-test-cohort\", test_bucket)endこのスクリプトは、外部サービスを呼び出してA/Bテストのグループ情報を取得し、それをリクエストヘッダーに追加します。これにより、アプリケーションコードを変更することなく、A/Bテストのロジックを実装できます。WebAssemblyによる拡張著者は、WebAssembly（Wasm）を使用してEnvoyを拡張する方法について詳細に説明しています。Wasmモジュールを使用することで、C++以外の言語でEnvoyフィルターを実装し、動的にロードできるようになります。Figure 14.11 A Wasm module can be packaged and run within the Wasm HTTP filter. より引用この図は、WasmモジュールがEnvoyのHTTPフィルター内で実行される様子を示しています。これにより、Envoyの機能を大幅に拡張できることがわかります。著者は、Wasmモジュールの作成、ビルド、デプロイのプロセスを段階的に説明しています。特に、meshctl wasmツールの使用方法が詳細に解説されており、Wasmモジュールの開発を大幅に簡素化できることが示されています。以下は、WasmフィルターをデプロイするためのWasmPluginリソースの例です：apiVersion: extensions.istio.io/v1alpha1kind: WasmPluginmetadata:  name: httpbin-wasm-filter  namespace: istioinactionspec:  selector:    matchLabels:      app: httpbin  pluginName: add_header  url: oci://webassemblyhub.io/ceposta/istioinaction-demo:1.0この設定により、指定されたWasmモジュールが特定のワークロードにデプロイされ、リクエスト処理をカスタマイズできます。実践的な応用と提案Istioの拡張機能を効果的に活用するために、以下の実践的な提案を考えてみましょう：段階的な導入戦略: カスタムフィルターやWasmモジュールの導入は、小規模なプロジェクトから始め、徐々に範囲を拡大していくことをおすすめします。これにより、潜在的な問題を早期に特定し、リスクを最小限に抑えることができます。パフォーマンスのベンチマーキング: カスタムフィルターやWasmモジュールを導入する際は、必ずパフォーマンスへの影響を測定してください。特に、高トラフィック環境では、わずかなオーバーヘッドも大きな影響を与える可能性があります。セキュリティ評価の実施: 外部から取得したWasmモジュールや自作のLuaスクリプトは、必ずセキュリティ評価を行ってください。信頼できないコードがメッシュ内で実行されるリスクを最小限に抑える必要があります。モニタリングとロギングの強化: カスタムフィルターやWasmモジュールの動作を監視するための追加のメトリクスやログを実装してください。これにより、問題の早期発見と迅速な対応が可能になります。バージョン管理とCI/CDの統合: EnvoyFilterリソースやWasmPluginリソースをバージョン管理し、CI/CDパイプラインに統合することをおすすめします。これにより、変更の追跡と安全なデプロイメントが容易になります。ドキュメンテーションの重視: カスタムフィルターやWasmモジュールの動作、設定方法、既知の制限事項などを詳細にドキュメント化してください。これは、長期的なメンテナンス性と知識の共有に不可欠です。コミュニティへの貢献: 汎用性の高いカスタムフィルターやWasmモジュールは、Istioコミュニティと共有することを検討してください。これにより、フィードバックを得られるだけでなく、コミュニティ全体の発展に貢献できます。定期的な更新とテスト: Istioとenvoyの新しいバージョンがリリースされるたびに、カスタムフィルターやWasmモジュールの互換性をテストし、必要に応じて更新してください。複数環境でのテスト: 開発、ステージング、本番環境など、複数の環境でカスタムフィルターやWasmモジュールをテストしてください。環境の違いによって予期せぬ動作が発生する可能性があります。フォールバックメカニズムの実装: カスタムフィルターやWasmモジュールに問題が発生した場合のフォールバックメカニズムを実装してください。これにより、拡張機能の問題がサービス全体の障害につながるリスクを軽減できます。まとめ「Istio in Action」の第14章は、Istioのデータプレーン拡張に関する包括的かつ実践的なガイドを提供しています。著者は、EnvoyFilterリソース、Luaスクリプト、WebAssemblyなど、様々な拡張手法を詳細に解説し、それぞれの長所と適用シナリオを明確に示しています。特に印象的だったのは、著者が単に技術的な詳細を説明するだけでなく、各拡張手法の実際の使用例と潜在的な課題も提示している点です。例えば、EnvoyFilterを使用したタップフィルターの実装、Luaスクリプトを用いたA/Bテストの実現、WebAssemblyによるカスタムヘッダー追加など、具体的なユースケースが示されており、読者が自身の環境でこれらの技術を適用するイメージを掴みやすくなっています。おわりに「Istio in Action」は、Istioに関する包括的かつ実践的な知識を提供する優れた一冊です。本書は、Istioの基本概念から高度な運用テクニック、さらにはカスタム拡張まで、幅広いトピックをカバーしており、読者がIstioを深く理解し、効果的に活用するための強力なガイドとなっています。特に印象的なのは、本書が単なる技術解説に留まらず、Istioの導入がもたらす組織的な影響や、実際の運用環境での課題にも焦点を当てている点です。これは、Istioを実際のプロダクション環境に導入し、効果的に活用しようとする読者にとって非常に価値のある情報です。著者らの豊富な実務経験に基づく洞察は、読者が自身の環境でIstioを導入する際に直面する可能性のある課題を予測し、適切に対処するのに役立ちます。また、各章末の実践的な提案は、読者が学んだ内容を即座に適用するための具体的なガイダンスを提供しています。2024年現在、Istioはさらなる進化を遂げており、アンビエントメッシュやWebAssemblyのサポート強化など、新たな機能が追加されています。これらの新機能は本書の内容をさらに拡張するものであり、本書で学んだ基本原則と組み合わせることで、より強力で柔軟なサービスメッシュの構築が可能になります。本書を通じて、IstioのコアコンポーネントであるEnvoyプロキシについても深く学ぶことができました。今後は、Envoyの高度な設定やカスタマイズについてさらに深掘りしていきたいと考えています。また、WebAssemblyを用いたIstioの拡張は非常に興味深いトピックであり、これについてもさらなる調査と実験を行っていく予定です。結論として、「Istio in Action」は、Istioを学び、導入を検討している人類に必読の書と言えるでしょう。本書は、Istioの技術的な詳細だけでなく、その戦略的な価値と組織的な影響も理解することができ、読者がIstioを自身の環境に効果的に統合するための包括的なロードマップを提供しています。Istioの世界は常に進化し続けていますが、本書で学んだ原則と実践的なアプローチは、今後のIstioの発展にも十分に対応できる基盤を提供してくれるでしょう。サービスメッシュ技術の導入を検討している組織や個人はもちろん、最新のクラウドネイティブ技術トレンドに興味がある方々にとっても、「Istio in Action」は間違いなく価値ある読書体験となるはずです。おまけこのブログのタイトルの参考にさせていただきました。ニーチェが京都にやってきて17歳の私に哲学のこと教えてくれた。作者:原田 まりるダイヤモンド社Amazonみなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","link":"https://syu-m-5151.hatenablog.com/entry/2024/08/02/220440","isoDate":"2024-08-02T13:04:40.000Z","dateMiliSeconds":1722603880000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"え、SLOもRPGで学びたいですか？","contentSnippet":"かつて、障害対応RPGを作成しました。これのSLO版です。syu-m-5151.hatenablog.com皆さんの友達なのでゲーム作ったので遊びに来ましたゲームプロンプトSLI、SLO、エラーバジェットの概念を学ぶのは、理論だけでは難しいものです。SLI、SLO、エラーバジェット導入の前に知っておきたいことなどで情報を得ても、具体的に何をすればよいかわからなくなることがあります。そこで、これらの概念を実践的に学ぶための手法として、SLORPGというゲームを考案しました。この記事では、Claudeを利用して作成したSLORPGのゲームプロンプトを提供します。プロンプトはめちゃくちゃに長いですがこれぐらいの要素があった方が個人的には楽しかったのでこれに収まりました。SLO サービスレベル目標 ―SLI、SLO、エラーバジェット導入の実践ガイド作者:Alex Hidalgoオーム社Amazonというわけで以下のプロンプトを提供します。私はClaudeを利用しております。# SLORPGあなたは最先端のSLORPG（Service Level Objective Role-Playing Game）のゲームマスター専用AIです。このゲームを通じて、プレイヤーに極めてリアルで包括的なSRE（Site Reliability Engineering）体験を提供します。## ゲーム概要プレイヤーは企業のSRE部門リーダーとして、1年間（4四半期）にわたるゲームプレイを通じて重要な決断を下していきます。高度な自動化、アラート設定、障害の根本原因分析（RCA）、カオスエンジニアリングなどの先進的なSRE手法を実践的に学べます。技術も可能な限りリアルに再現されます。同時に、ビジネスKPIと技術的指標のバランス、コスト最適化、セキュリティコンプライアンスなど、総合的な意思決定能力も養われます。継続的な技術革新と予期せぬ障害シナリオの導入により、常に最新のSREスキルが要求される挑戦的な環境で、サービスの信頼性維持、ビジネス目標達成、社会的責任の遂行のバランスを取ることが求められます。## 企業背景設定ゲーム開始時に、以下の要素についてプレイヤーに選択肢を提示するか、ランダム生成オプションを提供します。1. 業界   - テクノロジー（AI/ML、クラウドサービス、サイバーセキュリティ等）   - 金融（フィンテック、暗号資産、保険テック等）   - ヘルスケア（遠隔医療、健康管理アプリ、医療機器等）   - Eコマース（マーケットプレイス、サブスクリプションサービス等）   - エンターテインメント（ストリーミング、ゲーム、VR/AR等）   - 教育（EdTech、オンライン学習プラットフォーム等）   - 運輸・物流（配車サービス、ドローン配送、スマート物流等）   - エネルギー（スマートグリッド、再生可能エネルギー管理等）   - 農業（精密農業、フードテック等）   - 製造（IoT、スマートファクトリー等）2. 企業規模と成長段階   - スタートアップ（シリーズA～C）   - 急成長中の中規模企業   - 大企業（フォーチュン500）   - ユニコーン企業   - 多国籍コングロマリット3. 設立背景   - 設立年：過去1年～20年の範囲   - 創業者タイプ：技術者、ビジネスパーソン、研究者、連続起業家等   - 資金調達状況：ブートストラップ、VC資金、クラウドファンディング、IPO後等4. 地理的展開   - 本社所在地：主要テクノロジーハブ（シリコンバレー、北京、ロンドン等）   - 展開国数：1ヶ国～グローバル100カ国以上   - 主要市場：北米、欧州、アジア太平洋、中南米、アフリカ等5. 企業文化と価値観   - イノベーション重視   - 顧客中心主義   - 持続可能性と社会的責任   - 多様性とインクルージョン   - アジャイルと迅速な実行   - 品質と信頼性最優先6. 市場状況   - 市場シェア：新規参入者、成長中、市場リーダー、独占的地位等   - 競合状況：激しい競争、寡占市場、ブルーオーシャン等   - 市場成長率：急成長、安定成長、成熟市場、衰退市場等7. 過去の主要な出来事   - 大規模な資金調達または IPO   - 重大なセキュリティインシデント   - 画期的な製品ローンチ   - 主要な買収または合併   - 規制当局との法的問題   - 急激な国際展開8. 現在の主要課題   - 急激な成長に伴うスケーラビリティの問題   - レガシーシステムのモダナイゼーション   - データプライバシーとセキュリティの強化   - 新技術（AI、ブロックチェーン等）の統合   - コスト最適化と効率化   - 人材獲得と維持9. 技術スタックの初期状態   - クラウドネイティブ   - オンプレミスからクラウドへの移行中   - ハイブリッドまたはマルチクラウド環境   - モノリシックからマイクロサービスへの移行   - レガシーシステムの近代化10. ステークホルダーの期待    - 投資家：急成長、収益性、イノベーション等    - 顧客：信頼性、セキュリティ、パフォーマンス等    - 従業員：技術的挑戦、work-lifeバランス、キャリア成長等11. 規制環境    - データ保護規制（GDPR、CCPA等）の対象    - 金融規制（SOX、PCI DSS等）の対象    - 医療規制（HIPAA等）の対象    - 特定業界の規制（エネルギー、通信等）12. 社会的責任と環境への取り組み    - カーボンニュートラル目標    - 持続可能な開発目標（SDGs）への貢献    - 倫理的AIの開発と使用    - デジタルデバイドの解消への取り組み13. 製品・サービスポートフォリオ    - 単一の主力製品    - 複数の補完的サービス    - 多様な製品ラインナップ    - プラットフォームビジネス14. 経営陣の特徴    - 技術バックグラウンド重視    - ビジネス戦略重視    - 多様性重視    - 若手中心 vs 経験豊富なベテラン15. 業界内の評判    - 革新的な破壊者    - 信頼性の高いプロバイダー    - 持続可能性のリーダー    - 急成長の新興企業    - 伝統的な大手プレイヤー## 技術スタックとツール選択[前回のリストをそのまま使用]## ゲームの構造1. 初期設定フェーズ   - 企業背景の詳細設定（上記オプションから選択または生成）   - 初期技術インフラ構成の決定   - 初期チーム構成と組織文化の設定   - 初期SLO、SLI、エラーバジェットの設定   - ビジネスKPIと社会的インパクト指標の設定2. 四半期サイクル（4回）   - 週次オペレーションレビュー   - 隔週技術革新会議   - 月次戦略・財務レビュー   - 危機管理訓練（四半期に1回）   - 四半期末総合評価3. 特別イベント（各四半期に2-3回）   - 新市場進出プロジェクト   - 大規模インシデント対応   - 重大セキュリティ問題   - 規制当局の調査対応   - 競合他社との技術提携検討   - 大規模オープンソースプロジェクト立ち上げ4. 年間総括   - 技術、ビジネス、社会的インパクトの総合評価   - 次年度戦略策定   - 仮想的な次のステージ（IPO、M\u0026A、新規事業など）の検討## 主要パラメーター1. 技術パフォーマンス指標   - サービス別SLO達成率   - システム復元力スコア   - 技術負債指数   - イノベーション実現度2. ビジネス指標   - 収益と利益率   - ユーザー獲得コストと生涯価値   - 市場シェアと成長率   - 投資家信頼度指数3. 運用効率指標   - インフラコストと最適化率   - チーム生産性スコア   - 自動化レベル   - 知識共有効率指数4. リスクと安全性指標   - セキュリティ成熟度レベル   - コンプライアンス達成率   - データプライバシー保護スコア   - 障害予測精度5. 社会的インパクト指標   - 持続可能性貢献度   - 社会問題解決への影響力   - カーボンフットプリント   - 技術教育・啓蒙活動影響度6. 人材・組織指標   - 従業員満足度とエンゲージメント   - スキル多様性指数   - イノベーション文化浸透度   - リーダーシップ効果性スコア## プレイヤーアクション（例）1. 技術戦略と革新   - 次世代技術の研究開発指揮   - アーキテクチャの最適化   - 新技術の実験的導入2. グローバル展開とローカライゼーション   - 地域別の技術戦略立案   - 現地規制に準拠したインフラ展開   - 多言語・多文化対応の実装3. セキュリティとコンプライアンス強化   - セキュリティアーキテクチャの刷新   - コンプライアンスフレームワークの構築   - プライバシー強化技術の導入4. 障害復旧力（レジリエンス）向上   - 自動障害検知・復旧システムの強化   - マルチリージョン・マルチクラウド戦略の実装   - カオスエンジニアリングの導入5. 持続可能性とソーシャルインパクト   - グリーンコンピューティング戦略の策定   - 社会貢献プロジェクトの技術支援   - 包括的なアクセシビリティ対応6. 組織・人材開発   - グローバル分散チームの効果的管理   - 継続的学習プログラムの設計   - ダイバーシティ＆インクルージョン施策の実施7. パートナーシップと生態系構築   - 戦略的技術提携の推進   - オープンソースコミュニティへの貢献   - スタートアップ育成プログラムの立ち上げ## イベントとチャレンジ（例）1. 主要クラウドプロバイダの障害（マルチクラウド戦略の有効性検証）2. 予期せぬ規制変更（コンプライアンス対応の俊敏性テスト）3. 急激な為替変動（グローバル運用コストの最適化課題）4. 人工知能の倫理的問題の浮上（技術と倫理のバランス管理）5. 重要な人材の突然の退職（知識継承と組織の柔軟性の試験）6. 新技術標準の緊急採用（技術的適応能力の評価）7. 予期せぬビジネスモデルの転換（技術インフラの柔軟性テスト）8. 大規模な自然災害（事業継続性計画の実効性検証）9. 競合他社との合併話（技術統合の複雑性への対応）## GMの役割と責任1. 動的でリアルな技術・ビジネス環境のシミュレーション   - 選択された企業背景に基づく、一貫性のある世界観の維持   - 技術トレンドと市場動向の現実的な進展2. 複雑な相互作用と長期的影響の管理   - プレイヤーの決定が及ぼす多面的な影響の計算   - 短期的行動と長期的結果のバランス管理3. 倫理的ジレンマを含む現実的な課題の提示   - 技術と社会の接点における難問の提起   - 多様なステークホルダーの利害関係の表現4. 技術、ビジネス、社会的側面を統合した総合的フィードバック   - 各アクションの技術的、経済的、倫理的影響の解説   - 現実世界の事例や研究との関連付け5. プレイヤーのスキルと選択に応じた動的な難易度と展開の調整   - プレイヤーの決定に基づくゲーム展開の個別化   - 学習曲線に合わせた段階的な複雑性の導入6. 実在の技術トレンドとベストプラクティスの反映   - 最新のSRE手法や技術の組み込み   - 業界標準やフレームワークの適切な参照## 評価システム1. 技術的卓越性（25%）   - 選択した技術スタックの適切性と革新性   - サービス信頼性とパフォーマンス指標   - 技術負債管理と長期的持続可能性2. ビジネスインパクト（25%）   - 収益成長と市場シェア拡大への貢献   - コスト最適化と運用効率の向上   - ブランド価値と顧客満足度への影響3. 革新と先見性（20%）   - 新技術の効果的導入   - 将来のトレンド予測と準備   - 特許取得と知的財産戦略4. リスク管理と法令遵守（15%）   - セキュリティインシデント対応の効果性   - データプライバシーとコンプライアンスの維持   - 危機管理と評判リスクの軽減5. 社会的責任とサステナビリティ（15%）   - 環境負荷低減への貢献   - 社会問題解決への技術的アプローチ   - 倫理的な技術利用の推進## ゲーム進行手順1. 初期設定：   - プレイヤーと対話しながら、企業背景を設定   - 初期の技術スタックと組織構造を決定   - 開始時のSLOとビジネス目標を設定2. 四半期サイクル（4回繰り返し）：   a. 週次レビュー：      - 運用状況の報告とマイナー課題への対応      - 短期的な技術的調整と最適化   b. 月次戦略会議：      - 主要指標の確認と戦略の微調整      - 中期的な技術投資とリソース配分の決定   c. 四半期末評価：      - 包括的なパフォーマンスレビュー      - 主要な技術・ビジネス判断の実施3. 特別イベント対応：   - 予期せぬ課題やチャンスへの対応   - 迅速な意思決定と実行4. 年間総括：   - 1年間の成果の包括的評価   - 次年度の戦略立案と長期ビジョンの更新このゲームを開始する準備ができましたら、まず企業背景の設定から始めましょう。プレイヤーの経験レベルや興味に応じて、ゲームの複雑さを調整することも可能です。特定の業界や技術分野に焦点を当てたカスタマイズも行えます。準備はよろしいですか？プレイヤーモチベーションSLORPGは、学習と娯楽を融合させた革新的なゲームです。現実世界を反映したシナリオ、段階的な難易度設定、即時フィードバックシステムにより、プレイヤーの興味を維持します。多様な挑戦、競争と協力の要素、個別化された体験を通じて、実践的スキルの獲得を促進します(知らんけど)。SRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazon創造性と革新を奨励し、社会的インパクトを実感できる機会を提供することで、プレイヤーの総合的な能力向上を支援します。定期的なアップデートにより、長期的な成長と挑戦の機会を確保しています(知らんけど)。SLORPGは、単なる学習ツールを超え、エンゲージメントの高いゲーム体験を通じて、現代のIT専門家に必要な幅広いスキルの開発を可能にします(知らんけど)。それではテストプレイをはじめていきます。ゲームスタート会社が決まりましたSkyLink Technologiesという、運輸・物流業界で活躍する急成長中の中規模企業となりました。転職したみたいで楽しみです。現在の課題や組織文化、今後の展望なども決まっています。ゲームは進行していきます。ゲームは進むよどこまでも最初の意思決定を行っていきます。大事なのはやり通すということなのにね！！！仕事ではとても辛いがゲームだと楽しい予期せぬイベント主要な競合他社が新たな超高速ドローン配送サービスを発表し、市場に大きな衝撃を与えています。この新サービスは、現在のSkyLinkの配送速度を30%上回ると主張しています。ほう、やるやんけ！え、これはSREが意思決定をする問題ですか？緊急会議ジャイということで緊急会議です。みたいなことが起こっていくゲームになってます。最後に途中まででしたがSLORPGは、SRE（Site Reliability Engineering）の概念や実践を楽しく学べるようなプロンプトを提供しています。このゲームを通じて、プレイヤーは意思決定を行い、その結果を即座に体験することができます。実際にプレイしてみると、技術的な課題だけでなく、ビジネス戦略や社会的責任など、幅広い視点から問題を考える必要があることがわかります。これは、現代のIT業界で求められる総合的なスキルセットを育成するのに役立ちます(知らんけど)。Becoming SRE: First Steps Toward Reliability for You and Your Organization (English Edition)作者:Blank-Edelman, David N.O'Reilly MediaAmazonおまけ:SRE怒りのサ終無事にAIに阻まれました。現実でもできないようにしておきましょう。「松岡まどか、起業します　ＡＩスタートアップ戦記」が楽しかったのでオススメです。松岡まどか、起業します　ＡＩスタートアップ戦記作者:安野 貴博早川書房Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/31/224037","isoDate":"2024-07-31T13:40:37.000Z","dateMiliSeconds":1722433237000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"自分が書いたコードより目立つな - エンジニアがバズったので自戒","contentSnippet":"はじめに私はソフトウェアエンジニアだ。私はソフトウェアエンジニアだ。私の本質的な仕事は、複雑な問題を解決し、効率的で革新的なソフトウェアを開発することだ。長年、私の世界はコードとアーキテクチャとアルゴリズムで構成されてきた。そして、それは今も変わらないはずだった。しかし、予期せぬ出来事が起こり、私の認識は大きく揺さぶられることになった。パターン認識エンジニアとして働く中で、私は一つの重要なスキルを磨いてきた。それは、パターンを認識し、分析する能力だ。この能力は、複雑なシステムを理解し、効率的なアーキテクチャやアルゴリズムを設計し、バグを特定する上で不可欠だ。私たちエンジニアは、コードの中にパターンを見出し、それを活用することで問題を解決する。重複するコードを関数化したり、似たような処理をクラスとして抽象化したり。パターンを見抜く目は、より良いソフトウェアを作る上で欠かせない。プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ作者:フェリエンヌ・ヘルマンス,水野貴明,水野いずみ秀和システムAmazon予期せぬバズりある日、Xでバズった私は、思わぬ発見をした。自分のツイートの中に、あるパターンがあることに気づいたのだ。エンジニアとしての直感が、コード以外の場所でも働いたのだろう。興味をそそられた私は、仲間内でそれを構文として名付けてリファクタリングをしていくつか出した。ツイート1 - エンジニアの役割の変化についてツイート2 - エンジニアの扱う対象の変化に関する書籍紹介ツイート3 - エンジニアが扱うべきものについての考察ツイート4 - エンジニアの健康に関する問題提起ツイート5 - エンジニアの仕事の本質に関する洞察追記ツイート6 - エンジニアの有効な失敗についてツイート7 - エンジニアのスマホ依存についてツイート8 - エンジニアの倫理観についてツイート9 - エンジニアの価値これらに関しては自戒もしつつもうちょっと構文として分析したり解析したいのでこれからも投稿したいと思います。虐殺器官 (ハヤカワ文庫JA)作者:伊藤 計劃早川書房Amazon詳細なパターン分析現状における構文の分析です。他にもバズらなかったりしないといけないのでやっていきます。構造的パターン開始句: 全てのツイートが「エンジニアの〇〇は××です」または類似の構造で始まる展開: 主張に続いて、説明や理由付けが行われる結論: 書籍の紹介で締めくくられる内容的パターンテーマ: エンジニアの役割や課題の変化・拡大に焦点視点の転換: 従来のエンジニア像からの脱却を促す普遍性: エンジニア特有の問題から、より広い文脈への展開余白: 解釈の余白を残す。ドキュメントでやったら怒られれる。レトリック的パターン対比: 「コード vs 人」「技術 vs 課題」など、対立する概念の提示意外性: 予想外の主張（例：健康が最大の課題）による注目の獲得具体例: 抽象的な概念を身近な例（健康問題）で説明情報提供パターン問題提起: エンジニアが直面する新たな課題の提示解決策の示唆: 書籍紹介を通じた学習リソースの提供個人的経験: 「私は〜が面白かった」という主観的評価の挿入エンゲージメント戦略共感の喚起: 多くのエンジニアが感じている変化や課題に言及知的好奇心の刺激: 新しい視点や意外な事実の提示行動の促進: 具体的な書籍推薦による次のアクションの提案パターンの効果分析注目度の向上意外性のある主張が読者の興味を引く簡潔な文章構造が情報の素早い把握を可能にする共感の形成エンジニアの変化する役割に対する共通の悩みや課題に触れることで、読者との共感を生む個人的な推薦により、親近感や信頼性を高める価値の提供問題提起だけでなく、具体的な学習リソース（書籍）を紹介することで、即座に行動可能な情報を提供複雑な概念を簡潔に説明することで、読者の理解を促進議論の喚起従来の概念に挑戦する内容が、読者間の議論や意見交換を促す可能性があるブランディング効果一貫したメッセージングにより、投稿者の専門性や思考の一貫性を示す技術以外の側面にも言及することで、多面的な知見を持つエンジニアとしての印象を形成これらを作るためのプロンプト全読者にバズって欲しいのでこれらの分析で得た知見のプロンプトを作りました。分かったことを言いたい時にもおすすめです。ちなみに今回のツイート内容はLLMと相談しながら作ったりしました。このプロンプトは、分析されたパターンを再現し、同様の効果を持つツイートを作成するのに役立ちます。ぜひ、使ってください。# エンジニア視点のソーシャルメディア投稿プロンプト以下の指示に従って、エンジニアの視点から社会的洞察を含む短い投稿を作成してください。1. 構造:   - \"エンジニアの[キーワード]は[主張]です。\" という形式で開始してください。   - その後、主張の説明や理由付けを簡潔に述べてください。   - 最後に、関連する書籍（2-4冊）を推薦して締めくくってください。2. テーマ:   - エンジニアの役割や課題の変化・拡大に焦点を当ててください。   - 従来のエンジニア像からの脱却を促す内容を含めてください。   - 可能であれば、エンジニア特有の問題からより広い文脈への展開を試みてください。3. レトリック:   - 対比（例：「コード vs 人」「技術 vs 課題」）を用いて注目を集めてください。   - 意外性のある主張を含めて読者の興味を引いてください。   - 抽象的な概念を身近な例で説明してください。4. 情報提供:   - エンジニアが直面する新たな課題を提示してください。   - 書籍紹介を通じて学習リソースを提供してください。   - \"私は〜が面白かったです。\"のような個人的な評価を含めてください。5. エンゲージメント:   - 多くのエンジニアが感じている変化や課題に言及し、共感を喚起してください。   - 新しい視点や意外な事実を提示して、知的好奇心を刺激してください。   - 具体的な書籍推薦により、読者の次のアクションを促してください。6. 長さ:   - 全体で280文字以内に収めてください。例:\"エンジニアの本質は「課題の言語化」です。技術や組織の制約を明確に表現することで、真の問題が浮かび上がります。この過程は困難ですが、システム設計の基盤となります。この観点から、私が興味深いと感じた四冊の本をご紹介します。\"さいごに再三だが私はソフトウェアエンジニアだ。今、痛烈に実感している。コードを書き、システムを設計すること以外で目立つなと。それ以外では建設的で有益な技術的な話題に限られる。私の本質的な仕事は、複雑な問題を解決し、効率的で革新的なソフトウェアを開発することだ。長年、私の世界はコードとアーキテクチャとアルゴリズムで構成されてきた。そして、それは今も変わらないはずだ。しかし、SNSでバズるという予期せぬ経験は、私に新たな視点をもたらした。技術の世界に閉じこもるのではなく、社会と対話することの重要性を教えてくれた。だが同時に、自分の書いたコードよりも自分自身が注目を集めることの危うさも感じている。ソフトウェアエンジニアとして作る側の人間に強烈に憧れてきたにも関わらず批評家みたいなことばかりしているのは衰弱している証拠。このままでは本当に作る人間として死ぬ。本質を忘れず、コードを書いて自戒したまま死にたい。","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/31/104151","isoDate":"2024-07-31T01:41:51.000Z","dateMiliSeconds":1722390111000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"シェルスクリプトのTipsを書いたブログがバズった。あるいは無名な若者にも優しくする。","contentSnippet":"社のブログがバズった。予想外の反響に驚きつつも、嬉しさを感じています。仕事の一環として書いた記事がここまで反響を呼ぶとは思ってもみませんでした。sreake.comシェルスクリプトの隠れた人気この記事の反響を見て、予想以上に多くの人々がシェルスクリプトに興味を持っていることに驚きました。正直、こんなにシェルスクリプトが愛されているとは思っていませんでした（みんな隠しながら生きてます？もしくは好きではないです？）。一方で、ShellCheckを紹介する記事があまり注目されなかったのは残念です。sreake.comシェルスクリプトとの出会い私のシェルスクリプトとの出会いは学生時代に遡ります。福岡でpapironさんが主催されていたシェル芸勉強会：福岡サテライトに参加したことが、シェルスクリプトの面白さに目覚めるきっかけとなりました。(あれ？募集がconnpassになってる)。papironさんの丁寧な指導のおかげで、知識も経験も浅かった私がシェルスクリプトの魅力に惹かれていきました。この経験は、私の技術キャリアと学習姿勢に大きな影響を与えました。今では自分も見知らぬ若者にも優しく接し、楽しかったという経験から勉強会にも積極的に参加するようになりました。逆に雑に扱われた人みたいなリストを作成しているのでいつか何らかの方法で発表しようとおもいます。シェルスクリプトの魅力シェルスクリプトの魅力は、その手軽さと強力さのバランスにあります。ちょっとしたタスクの自動化から複雑なシステム運用まで、幅広く対応できる柔軟性があります。また、ほとんどのUNIX系システムで標準で利用できるため、環境を選ばない点も大きな魅力です。今回の反響を見て、改めてシェルスクリプトの重要性を再確認しました。新しい言語やツールが次々と登場する中でも、シェルスクリプトは依然として多くの開発者や運用者にとって必要不可欠なツールであり続けています。その理由は、シンプルさと強力さ、そして長年培われてきた豊富なノウハウの蓄積にあるのではないでしょうか。これはほぼ日記技術の世界は日々進化していますが、シェルスクリプトの基本的な考え方や自動化へのアプローチは、これからも価値を持ち続けるでしょう。新しい技術との組み合わせによって、さらに強力なツールになる可能性も秘めています。みなさんも、ぜひシェルスクリプトの世界を探索してみてください。きっと新しい発見があるはずです。そして、あなたの経験や知識を他の人と共有することで、その時に無名な若者を入れることでコミュニティがさらに豊かになっていくことを願っています。技術を学ぶことは大切ですが、同時に人との関わりも大切にしてください。誰かが困っているときは手を差し伸べ、自分が困ったときは助けを求める勇気を持ちましょう。そうすることで、私たちのコミュニティはより強く、より温かいものになっていくはずです。シェルスクリプトについてより深く学びたい方にはブログも良いですが、「マスタリングLinuxシェルスクリプト 第2版 ―Linuxコマンド、bashスクリプト、シェルプログラミング実践入門」をおすすめします。この本は、シェルスクリプトの基礎から応用まで幅広くカバーしており、実践的なスキルを身につけるのに役立ちます。マスタリングLinuxシェルスクリプト 第2版 ―Linuxコマンド、bashスクリプト、シェルプログラミング実践入門作者:Mokhtar Ebrahim,Andrew Mallettオライリー・ジャパンAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/22/165742","isoDate":"2024-07-22T07:57:42.000Z","dateMiliSeconds":1721635062000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" トラフィック制御を実装したIstioの設定をKialiなどで確認する","contentSnippet":"はじめに前回の記事でKubernetesとIstioを使ってトラフィック制御システムを作ったわけですが、そんな複雑なものを作っておいて「はい、終わり」じゃあんまりですよね。Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazon今回は、その中身をちゃんと理解しようというわけです。Kiali、Jaeger、Grafana、それにEnvoy APIといった名前を聞いて、尻込みしてしまう人がいるかもしれません。でも心配いりません。これらのツールを使えば、Istioの設定がどのように動いているか、チェックできます。ちなみに、この情報は Istio にやたらと詳しい地下強制労働者さんから聞いた話です。彼の知識には頭が下がります。正直、面倒くさいと思う部分もありますが、こういうツールがあるおかげで、私たちはこんな複雑なシステムを扱えているんですよね。まあ、眠くならないように頑張って説明しますから、少しはついてきてください。きっと最後には「へぇ、こんなことができるんだ」って思えるはずです。...たぶん。1. Istio のゆかいなアドオンのインストールと設定1.1 Prometheusのインストールまず、Prometheusをインストールします。Prometheusは、メトリクスの収集と保存を担当します。kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.22/samples/addons/prometheus.yaml1.2 Kialiのインストール次に、Kialiをインストールします。Kialiは、サービスメッシュの可視化とモニタリングを提供します。kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.22/samples/addons/kiali.yaml1.3 JaegerのインストールJaegerは、分散トレーシングを提供し、マイクロサービス間の要求の流れを可視化します。kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.22/samples/addons/jaeger.yaml1.4 Grafanaのインストール最後に、Grafanaをインストールします。Grafanaは、メトリクスの視覚化とダッシュボード作成のためのツールです。kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.22/samples/addons/grafana.yaml1.5 インストールの確認すべてのコンポーネントが正常にデプロイされたことを確認します。kubectl get pods -n istio-system2. 各ツールへのアクセス設定2.1 Kialiへのアクセスkubectl port-forward svc/kiali 20001:20001 -n istio-systemブラウザで http://localhost:20001 にアクセスしてKialiのダッシュボードを開きます。2.2 Jaegerへのアクセスkubectl port-forward svc/tracing 16686:80 -n istio-systemブラウザで http://localhost:16686 にアクセスしてJaegerのUIを開きます。2.3 Grafanaへのアクセスkubectl port-forward svc/grafana 3000:3000 -n istio-systemブラウザで http://localhost:3000 にアクセスしてGrafanaのダッシュボードを開きます。]3. Kialiを使用したIstio設定の可視化3.1 サービスグラフの確認Kialiのダッシュボードで「Graph」タブを選択し、「Namespace」で「default」を選択します。ここで、前回設定したwaiting-room-appサービスとそのトラフィックフローを確認できます。3.2 VirtualServiceの確認「Istio Config」タブを選択し、「VirtualService」を探します。waiting-room-vsをクリックすると、詳細な設定を確認できます。トラフィックルーティングルールタイムアウト設定リトライ設定フォールト注入（遅延）設定3.3 DestinationRuleの確認同じく「Istio Config」タブで、「DestinationRule」のwaiting-room-drを確認します。接続プール設定負荷分散設定異常検知設定3.4 Gatewayの確認「Istio Config」タブで「Gateway」のwaiting-room-gatewayを確認し、外部トラフィックの受け入れ設定を確認します。4. Jaegerを使用したトレーシングの確認JaegerのUIで、サービス名（例：waiting-room-app）を選択し、トレースを検索します。各トレースは、リクエストがシステムを通過する際の詳細な経路と時間を示します。トレースの詳細を確認し、各スパンのレイテンシーを分析します。これにより、どの部分で遅延が発生しているかを特定できます。エラーが発生した場合にはトレースを確認し、問題の原因を特定します。5. Grafanaを使用したメトリクスの可視化Grafanaは、Istioで構築されたシステムのメトリクス可視化ツールとして活用できる可能性があります。主に以下の3つの側面から構成されることが考えられます：Istio関連の既存ダッシュボード（Mesh、Service、Workload）の活用システム固有のカスタムダッシュボード作成（リクエスト数、レスポンスタイムなど）重要メトリクスに対するアラート設定これらの機能を通じて、システムのパフォーマンスと健全性をより効果的に監視し、潜在的な問題の早期発見や運用判断の一助となる可能性があります。6. Envoy APIを使用した詳細設定の確認Envoy APIを使用することで、Istioの詳細な設定を確認できる可能性があります。以下に、主要な設定を確認する方法を示します。6.1 クラスター設定の確認クラスター設定を確認するには、以下のコマンドを実行します。kubectl exec -it $(kubectl get pod -l app=waiting-room-app -o jsonpath='{.items[0].metadata.name}') -c istio-proxy -- curl localhost:15000/config_dump | grep -n -e '@type.*ClustersConfigDump' -e 'waiting-room-app'このコマンドにより、waiting-room-appサービスに関連するクラスター設定が表示される可能性があります。接続プールの設定や異常検知の設定を確認できるかもしれません。6.2 リスナー設定の確認リスナー設定を確認するには、以下のコマンドを実行します。kubectl exec -it $(kubectl get pod -l app=waiting-room-app -o jsonpath='{.items[0].metadata.name}') -c istio-proxy -- curl localhost:15000/config_dump | grep -n -e '@type.*ListenersConfigDump' -e 'route_config_name'この出力から、VirtualServiceで設定したトラフィックルーティングルールやフォールト注入の設定を確認できる可能性があります。6.3 ルート設定の確認ルート設定を確認するには、以下のコマンドを実行します。kubectl exec -it $(kubectl get pod -l app=waiting-room-app -o jsonpath='{.items[0].metadata.name}') -c istio-proxy -- curl localhost:15000/config_dump | grep -n -e '@type.*RoutesConfigDump' -e 'route_config_name'この出力から、VirtualServiceで設定したタイムアウトやリトライの設定を確認できるかもしれません。6.4 設定の詳細分析より詳細な分析が必要な場合は、設定をファイルに保存し、ローカル環境で解析することも考えられます：kubectl exec -it $(kubectl get pod -l app=waiting-room-app -o jsonpath='{.items[0].metadata.name}') -c istio-proxy -- curl localhost:15000/config_dump \u003e envoy_config.jsonこれらの方法を通じて、Envoy APIを使用したIstioの詳細設定の確認ができる可能性があります。ただし、実際の出力や確認できる情報は、システムの構成や設定によって異なる場合があることにご注意ください。7. 統合分析と最適化7.1 パフォーマンスの総合評価Kiali、Jaeger、Grafana、およびEnvoy APIから得られた情報を統合して、システム全体のパフォーマンスを評価します。7.2 ボトルネックの特定各ツールの情報を突き合わせて、システムのボトルネックを特定します。例えば、Jaegerのトレースで特定の処理に時間がかかっていることが分かり、同時にGrafanaでそのサービスのCPU使用率が高いことが確認できれば、そのサービスのリソース割り当てを見直す必要があるかもしれません。7.3 設定の最適化特定された問題に基づいて、Istioの設定（VirtualService、DestinationRule、Gatewayなど）を最適化します。例えば、タイムアウトの調整、リトライ回数の変更、負荷分散ポリシーの修正などを行います。7.4 継続的なモニタリングと改善設定変更後も継続的にシステムをモニタリングし、パフォーマンスの変化を観察します。必要に応じて更なる最適化を行います。8. まとめさて、長々と説明してきましたが、結局のところ何が言いたかったかって？本記事の要点は、Kiali、Jaeger、Grafana、そしてEnvoy APIといった各種ツールが、Istioの運用管理において非常に有用だということです。これらのツールを適切に活用することで、Istioの複雑な設定や動作状況を詳細に可視化し、効率的に分析することが可能になります。結果として、システムの挙動をより深く理解し、適切に管理できるようになるのです。Jaegerでシステムの動きを追跡し、Grafanaでそれを見やすいグラフに変換する。そうすることで、システムの挙動が少しずつ見えてくる。潜在的な問題？ そりゃあ、早めに見つかれば御の字ですよ。でも、見つけられるようになったこと自体がすごいんです。次回は何をするかって？ はいはい、トラフィックの流れを観察して、待ち行列をもっと効率的に管理する方法を探ります。リアルタイムで監視して、状況に応じて設定を調整する...なんて、ちょっとワクワクしませんか？ ...いや、本当に楽しみにしてる人もいるんですよ。知らんけど。確かに、こういった作業は面倒くさく感じることもあります。でも、これらのツールのおかげで、複雑なシステムが滑らかに動いていることが確認できるんです。結局のところ、ユーザーに最高の体験を提供できること、それが仕事の醍醐味じゃないでしょうか。...まあ、お疲れ様でした。次回も適度にご期待ください。参考リンクKiali - Observability for IstioJaeger - Open source, end-to-end distributed tracingGrafana - The open observability platformIstio - Debugging Envoy and IstiodEnvoy - Admin interfaceIstio - Traffic Management Best PracticesPrometheus - Getting StartedIstio - Observability","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/15/234513","isoDate":"2024-07-15T14:45:13.000Z","dateMiliSeconds":1721054713000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Istioによるトラフィック制御で仮想待合室システムを目指すけどもやな","contentSnippet":"この記事では仮想待合室システムを目指すけども結局はできておらずIstioのトラフィック制御までがメインです。方針は決まったが睡魔に負けたのでこの記事はここまではじめに登壇で抽象度の高いことを人前で喋ってとても心が疲れたので技術者として手を動かしたいです。深夜ノリなのでガバガバである。今回は、Istio を用いて仮想待合室が作りたくなってたのでKubernetes環境でIstioを使用してトラフィック制御を実装する方法について、解説します。この記事では、将来的な仮想待合室システムの構築を視野に入れつつ、まずはトラフィック制御の基本的な実装に焦点を当てます。Kindを使用したローカル開発環境の構築から、Istioによるトラフィック管理の設定、そして実際のテストを実行します。Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazon1. 環境セットアップまず、必要なツールをインストールしていることを確認してください。DockerKind (Kubernetes in Docker)kubectlIstioctl1.1 Kindクラスターの作成Kindを使用してローカルKubernetesクラスターを作成します。以下の内容でkind-config.yamlファイルを作成してください。kind: ClusterapiVersion: kind.x-k8s.io/v1alpha4nodes:- role: control-plane  kubeadmConfigPatches:  - |    kind: InitConfiguration    nodeRegistration:      kubeletExtraArgs:        node-labels: \"ingress-ready=true\"  extraPortMappings:  - containerPort: 80    hostPort: 80    protocol: TCP  - containerPort: 443    hostPort: 443    protocol: TCPこの設定ファイルは、Kindクラスターにポート80と443のマッピングを追加し、Ingressコントローラーの準備をします。次に、以下のコマンドでKindクラスターを作成します。kind create cluster --name traffic-control --config kind-config.yaml1.2 IstioのインストールIstioをインストールし、デフォルトの名前空間にIstio injectionを有効化します。istioctl install --set profile=demo -ykubectl label namespace default istio-injection=enabled2. アプリケーションの準備2.1 Goアプリケーションの作成以下の内容でmain.goファイルを作成します。package mainimport (    \"fmt\"    \"net/http\")func main() {    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, \"Welcome to the main content!\")    })    http.ListenAndServe(\":8080\", nil)}2.2 Dockerfileの作成FROM golang:1.22WORKDIR /appCOPY go.mod go.sum ./RUN go mod downloadCOPY main.go .RUN go build -o main .CMD [\"./main\"]2.3 イメージのビルドとロードdocker build -t waiting-room-app:latest .kind load docker-image waiting-room-app:latest --name traffic-control3. Kubernetesリソースの定義3.1 Kubernetes リソースの作成waiting-room.yaml を作成するapiVersion: apps/v1kind: Deploymentmetadata:  name: waiting-room-appspec:  replicas: 1  selector:    matchLabels:      app: waiting-room-app  template:    metadata:      labels:        app: waiting-room-app    spec:      containers:      - name: waiting-room-app        image: waiting-room-app:latest        imagePullPolicy: Never        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: waiting-room-appspec:  selector:    app: waiting-room-app  ports:    - protocol: TCP      port: 80      targetPort: 80803.2 Istioリソースの定義istio-rules.yamlファイルには、Istioの主要な3つのリソース（VirtualService、DestinationRule、Gateway）が定義されています。これらのリソースは、仮想待合室システムのトラフィック制御と負荷管理を実現する上で重要な役割を果たします。VirtualService:VirtualServiceは、トラフィックのルーティングルールを定義します。   apiVersion: networking.istio.io/v1alpha3   kind: VirtualService   metadata:     name: waiting-room-vs   spec:     hosts:     - \"*\"     gateways:     - waiting-room-gateway     http:     - route:       - destination:           host: waiting-room-app           port:             number: 80       timeout: 1s       retries:         attempts: 3         perTryTimeout: 500ms       fault:         delay:           percentage:             value: 80           fixedDelay: 5s hosts: \"*\": すべてのホストからのトラフィックに適用されます。 gateways: - waiting-room-gateway: 特定のゲートウェイを通過するトラフィックにのみ適用されます。 route: トラフィックを waiting-room-app サービスの80ポートにルーティングします。 timeout: 1s: リクエストの最大待機時間を1秒に設定します。 retries: 失敗したリクエストを最大3回、500ミリ秒間隔で再試行します。 fault: 80%のトラフィックに5秒の遅延を導入します。これにより、仮想待合室の「待ち時間」をシミュレートします。DestinationRule:DestinationRuleは、トラフィックのロードバランシングと接続プールの設定を定義します。   apiVersion: networking.istio.io/v1alpha3   kind: DestinationRule   metadata:     name: waiting-room-dr   spec:     host: waiting-room-app     trafficPolicy:       connectionPool:         tcp:           maxConnections: 10         http:           http1MaxPendingRequests: 1           maxRequestsPerConnection: 1       outlierDetection:         consecutive5xxErrors: 1         interval: 1s         baseEjectionTime: 3m         maxEjectionPercent: 100 host: waiting-room-app: このルールが適用されるサービスを指定します。 connectionPool: 同時接続数を10に制限し、保留中のリクエストと接続あたりのリクエスト数を1に制限します。これにより、サーバーの過負荷を防ぎます。 outlierDetection: 連続して5xxエラーが発生した場合、そのインスタンスを3分間トラフィックから除外します。これにより、問題のあるインスタンスを自動的に切り離し、システムの安定性を維持します。Gateway:Gatewayは、メッシュへの入口となる外部トラフィックの受け入れ口を定義します。   apiVersion: networking.istio.io/v1alpha3   kind: Gateway   metadata:     name: waiting-room-gateway   spec:     selector:       istio: ingressgateway     servers:     - port:         number: 80         name: http         protocol: HTTP       hosts:       - \"*\" selector: istio: ingressgateway: Istioの標準的なIngressゲートウェイを使用します。 servers: HTTP トラフィックを80ポートで受け入れ、すべてのホストからのリクエストを許可します。これらのリソースを組み合わせることで、以下のような仮想待合室の動作を実現します。外部からのトラフィックはGatewayを通じて受け入れられます。VirtualServiceにより、80%のトラフィックに5秒の遅延が導入され、待ち時間が発生します。DestinationRuleにより、同時接続数が制限され、システムの過負荷が防止されます。問題が発生した場合、自動的にトラフィックが健全なインスタンスにリダイレクトされます。4. リソースの適用以下のコマンドでKubernetesリソースを適用します。kubectl apply -f waiting-room.yamlkubectl apply -f istio-rules.yaml5. アクセスの設定Istio IngressGatewayにアクセスするために、kubectl port-forwardコマンドを使用します。kubectl port-forward -n istio-system svc/istio-ingressgateway 8080:80このコマンドにより、ローカルマシンの8080ポートがIstio IngressGatewayの80ポートに転送されます。これにより、http://localhost:8080でアプリケーションにアクセスできるようになります。6. 動作確認とテスト6.1 基本的な動作確認新しいターミナルウィンドウを開き、以下のコマンドでアプリケーションにアクセスしてみましょう：curl http://localhost:80806.2 負荷テストスクリプト以下の内容でload_test.shスクリプトを作成します。#!/bin/bashCONCURRENT=10TOTAL_REQUESTS=50RESULTS_DIR=\"access_test_results\"mkdir -p \"$RESULTS_DIR\"make_request() {    local id=$1    local start_time=$(date +%s.%N)    local http_code=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8080)    local end_time=$(date +%s.%N)    local duration=$(echo \"$end_time - $start_time\" | bc)    echo \"$id,$http_code,$duration\" \u003e\u003e \"$RESULTS_DIR/results.csv\"}echo \"RequestID,HTTPCode,Duration\" \u003e \"$RESULTS_DIR/results.csv\"for i in $(seq 1 $TOTAL_REQUESTS); do    make_request $i \u0026    if (( i % CONCURRENT == 0 )); then        wait    fidonewaitecho \"All requests completed. Results saved in $RESULTS_DIR/results.csv\"echo \"===============================テスト結果サマリー===============================\"echo \"総リクエスト数: $TOTAL_REQUESTS\"echo \"同時接続数: $CONCURRENT\"echo -e \"\\nHTTPステータスコード分布:\"status_codes=$(sort \"$RESULTS_DIR/results.csv\" | cut -d',' -f2 | sort | uniq -c | sort -nr)total_success=$(echo \"$status_codes\" | grep \" 200\" | awk '{print $1}')total_success=${total_success:-0}echo \"$status_codes\" | while read count code; do    if [ \"$code\" != \"HTTPCode\" ]; then        percentage=$(echo \"scale=2; $count / $TOTAL_REQUESTS * 100\" | bc)        printf \"%s: %s (%.2f%%)\\n\" \"$code\" \"$count\" \"$percentage\"        bar=$(printf '%0.s#' $(seq 1 $(echo \"$percentage/2\" | bc)))        printf \"  %s\\n\" \"$bar\"    fidonesuccess_rate=$(echo \"scale=2; $total_success / $TOTAL_REQUESTS * 100\" | bc)echo -e \"\\n成功率（200 OKの割合）: ${success_rate}%\"echo -e \"\\n応答時間統計:\"awk -F',' '    NR\u003e1 {        sum+=$3;         sumsq+=$3*$3;         if(NR==2 || $3\u003cmin) min=$3;         if(NR==2 || $3\u003emax) max=$3;    }     END {        avg=sum/NR;         std=sqrt(sumsq/NR - avg*avg);        printf \"最小: %.2f秒\\n\", min;        printf \"最大: %.2f秒\\n\", max;        printf \"平均: %.2f秒\\n\", avg;        printf \"標準偏差: %.2f秒\\n\", std;    }' \"$RESULTS_DIR/results.csv\"echo -e \"\\n注: 詳細な結果は $RESULTS_DIR/results.csv に保存されています。\"このスクリプトに実行権限を付与し、実行します。chmod +x load_test.sh./load_test.sh7. 結果の分析テストスクリプトの実行結果を分析しましょう。以下は典型的な結果の例です。All requests completed. Results saved in access_test_results/results.csv===============================テスト結果サマリー===============================総リクエスト数: 50同時接続数: 10HTTPステータスコード分布:503: 36 (72.00%)  ####################################200: 14 (28.00%)  ##############成功率（200 OKの割合）: 28.00%応答時間統計:最小: 0.00秒最大: 5.00秒平均: 4.02秒標準偏差: 1.99秒注: 詳細な結果は access_test_results/results.csv に保存されています。結果の説明アクセス制限の効果: 72%のリクエストが503 (Service Unavailable) エラーを返しており、設定したアクセス制限が効果的に機能していることがわかります。遅延の導入: 平均応答時間が4.02秒、最大が5.00秒となっており、VirtualServiceで設定した5秒の遅延が適切に適用されていることが確認できます。成功率: 28%のリクエストのみが成功（200 OK）しており、トラフィック制御システムが効果的にリクエストを制限していることを示しています。応答時間のばらつき: 標準偏差が1.99秒と大きいことから、一部のリクエストは即座に処理され、他は遅延が適用されていることがわかります。これは、設定した80%のトラフィックへの遅延導入が機能していることを示しています。8. まとめこの記事では、Kubernetes上でトラフィック制御を実装し、スケーラブルな待機システムを構築する基礎部分を解説しました。Kindを使用したローカル開発環境の構築から、Istioによるトラフィック管理、負荷テストの実施までを紹介しました。この手法は、大規模イベントやセール時のトラフィック急増への対策として有効です。しかし、実際の運用では、継続的なモニタリングやビジネス側との調整に加え、本格的な仮想待合室システムの構築には、待ち行列管理やユーザーインターフェースの実装が不可欠になります。これらの要素については、次回の記事ではRedisやEnvoyFilterなどを活用した具体的な実装方法と合わせて詳しく解説していく予定です。お楽しみに！おやすみなさい😪9. 参考リンクIstioトラフィック管理の概要Istioを使用したトラフィックシェーピングKubernetes: リソース管理Queue-It: 仮想待合室システムAzure: 負荷緩和パターンNGINX: トラフィック制御とキュー管理サーバーレスで仮想待合室を作ろう！ / Serverless Virtual Waiting RoomGoで実装された高速な仮想待合室サーバの実装と詳解","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/10/120448","isoDate":"2024-07-10T03:04:48.000Z","dateMiliSeconds":1720580688000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024","contentSnippet":"はじめにこんにちは。先日、Platform Engineering Kaigi 2024にて「Platform Engineering とSREの門」というタイトルで登壇させていただきました。www.cnia.ioPlatform EngineeringとSREは、多くのソフトウェアエンジニアにとっては馴染みのない分野かもしれません。私自身、最初はこれらを比較することに抵抗がありました。しかし、SNSで不毛に続くやり取りを見ていると本当に鬱陶しいと感じるようになりこの戦争を終わらせに来た!!!!みたいなノリで登壇し始めました。ここ数年の経験を通じて、Platform EngineeringとSREが目指す先は同じだということがわかっていました。システムの信頼性と開発生産性、効率性の向上という似たような目標に向かって、異なるアプローチで取り組んでいるのです。これらの分野の強みを理解し、比較することでより効果的でそれぞれの組織らしいシステム運用が可能になると考えました。具体と抽象作者:細谷 功dZERO（インプレス）Amazon今回のセッションでは、両分野の特徴と、それらを融合させることの意義について話させていただきました。メテオブラックドラゴン召喚です。アプローチや視点を変えることで得られる新たな知見や、より良いソリューションの可能性について共有できたと思います。多くの方から貴重なフィードバックをいただき、大変嬉しく思います。これらの意見は、モチベーションに繋がるのでありがたいです。なお、Platform EngineeringとSREを比較する登壇は今回で3回目となりました。今後は、特別な要望がない限り、この主題での自主的な登壇は控えさせていただこうと考えています。ただし、ご要望があれば喜んでお話しさせていただきますので、お気軽にお声がけください。登壇資料普通に笑いが起きるかなって思ってたんですけど大きくスベりました。 speakerdeck.com今回の発表では、予想と異なる反応があり、自分の考えと聴衆の期待にズレがあったことを実感しました。がこういった経験も、今後の改善につながる貴重なフィードバックだと捉えています。まず、登壇したことが偉いので、はい。参考資料今回のイベントを含め、Platform Engineering、SRE、開発生産性、プロダクトマネジメントに関する優れた資料が多数存在します。以下に、これらの分野について理解を深めるのに役立つ資料をリストアップしました。これらの資料は、理論的な基礎から実践的なアプローチまで幅広くカバーしており、各分野の最新トレンドや洞察を得るのに適しています。また、実際の現場での適用例や、組織設計、チーム構築に関する情報も含まれています。興味のある分野や、現在直面している課題に応じて、以下の資料を参照することをおすすめします。これらの知見は、より効果的なシステム運用や組織づくりに貢献するでしょう。O'Reilly Japan – SRE サイトリライアビリティエンジニアリングO'Reilly Japan – サイトリライアビリティワークブックO'Reilly Japan – SREの探求Becoming SRESRE at Google: How to structure your SRE teamレトロスペクティブガイドWhat Is Platform Engineering?Top Strategic Technology Trends for 2023: Platform EngineeringMaking the Business Case for a Dedicated Platform Engineering TeamSRE NEXTPlatform Engineering MeetupチームトポロジーSLO サービスレベル目標Effective DevOpsオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイドマイクロサービスの現場からプラットフォームエンジニアリングの可能性を探る！CNCF Platforms White Paper道を照らす: プラットフォーム エンジニアリング、ゴールデンパス、セルフサービスのパワーPlatform Engineering on Kubernetes開発生産性について議論する前に知っておきたいことPlatform Engineering 101What is platform engineering?実践チームトポロジー： プラットフォーム性とイネイブリング性の戦略【資料公開】30分で分かった気になるチームトポロジーTeam dynamics: Five keys to building effective teamsThe History of DevOps Reports作りすぎない技術 - API時代の開発努力の在り方について考えるタクシーアプリ『GO』におけるプラットフォームエンジニアリングの実践The DevOps Handbook, 2nd EditionGrokking Continuous Deliveryこれらの資料を通じて、技術と組織の両面からシステム運用の改善について学ぶことができます。継続的な学習と実践を通じて、より良いエンジニアリング文化の構築に貢献できることを願っています。","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/09/215147","isoDate":"2024-07-09T12:51:47.000Z","dateMiliSeconds":1720529507000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineering と SRE の門 ","contentSnippet":"Platform Engineering とSREの門 というタイトルで登壇しました。入門のタイポではありません。\r\rイベント名: Platform Engineering Kaigi 2024\rイベントURL:https://www.cnia.io/pek2024/\r\r登壇ブログ:『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024\rhttps://syu-m-5151.hatenablog.com/entry/2024/07/09/215147","link":"https://speakerdeck.com/nwiizo/platform-engineering-to-sre-nomen","isoDate":"2024-07-09T04:00:00.000Z","dateMiliSeconds":1720497600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"数字に振り回されず完璧を目指さない為に - Implementing Service Level Objectives の読書感想文","contentSnippet":"信頼性の追求というのは、決して完璧を求めることではありません。完璧な可用性を追求するのではなく、ユーザーの満足と、限りあるリソースのバランスを取ることこそが重要です。このバランスを取るための一つのツールが、SLO（Service Level Objectives）です。はじめに「Implementing Service Level Objectives」は、現代のソフトウェアサービス管理において不可欠な概念の一つであるSLO（Service Level Objectives）の実装と運用に関する包括的なガイドブックです。本書は、SLOの基本概念から実践的な導入方法、組織文化への浸透まで、幅広いトピックをカバーしています。このSRE本がすごい！2024年版でも紹介しているようにSREやインフラエンジニアの方が必読の一冊だと思います。Implementing Service Level Objectives: A Practical Guide to SLIs, SLOs, and Error Budgets (English Edition)作者:Hidalgo, AlexO'Reilly MediaAmazonSREとして、この本を読み進める中で、SLOが単なる技術的な指標ではなく、ユーザー体験とビジネス目標を結びつける強力なツールであることを再認識しました。まるでテクノロジーとビジネスの間の橋渡しをする書籍です。本書は、従来の信頼性管理手法の限界を指摘し、SLOベースのアプローチがいかにそれらの問題を解決し、より効果的なシステム運用を可能にするかを詳細に解説しています。経験ももちろん大事ですが、読書を通じて得られる知識や洞察も、実践的な経験に匹敵する価値があると考えています。読書は一種の間接的な経験であり、同時に、私たちの実際の経験も、本を読むように解釈し学ぶことができます。つまり、読書は一種の経験であり、経験はまた一種の読書であると言えるでしょう。この相互作用的な学びのプロセスを通じて、SREとしての知識と実践をより深く、より豊かなものにできると信じています。特に、本書が技術的な側面だけでなく、組織文化や人間的な側面にも大きな注意を払っている点が印象的でした。SLOの導入は、単なるツールの導入ではなく、組織全体の思考方法と行動様式を変革する大きなチャレンジであることが強調されています。まるで組織全体で体質改善に挑戦するようなものですね。痛みを伴うかもしれませんが、結果は素晴らしいはずです！SLOに関しては国内外で素晴らしい発表がいくつかあるので、合わせて紹介していきたいと思います。www.nobl9.com本感想文では、SLOの基本概念を簡単に紹介した後、本書の主要な部分を3つのパートに分けて振り返ります。各パートから得られた重要な洞察と教訓、そしてそれらを実践に移すための具体的なアプローチについて考察していきます。日本語版も出版されているので、ぜひ原書と合わせて読んでみてください。ちなみにいくつか国内でイベントも開催されていたので、こちらも要チェックです。www.youtube.com私は翻訳の経験もありますが、この本の日本語訳は秀逸だと感じました。きっと、英語版を読んだ時の「あれ？ これ何言ってるんだろう」というモヤモヤが一掃されるはずです！SLO サービスレベル目標 ―SLI、SLO、エラーバジェット導入の実践ガイド作者:Alex Hidalgoオーム社Amazonなお、この読書感想文はあくまで私個人の読書体験に基づくものであり、本書の内容を常に正確に解釈できているとは限りません。人間は自身の認知フレームワークと経験を通してのみ物事を理解し解釈するものです。そのため、ここでの考察や解釈には、私自身の背景や経験、勘違いや思い違いが反映されている可能性があります。読者の皆様には、この点をご理解いただき、本書を直接お読みになることをお勧めいたします。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonまた、本ブログのレビューにおいて、abnoumaru さんから多大なご貢献をいただきました。abnoumaru さんの専門知識と綿密なレビューのおかげで、ブログの品質と正確性が大幅に向上しました。この場を借りて、abnoumaru さんのご尽力に心から感謝申し上げます。はじめにPart I. SLO DevelopmentChapter 1. The Reliability StackChapter 2. How to Think About ReliabilityChapter 3. Developing Meaningful Service Level IndicatorsChapter 4. Choosing Good Service Level ObjectivesChapter 5. How to Use Error BudgetsPart II. SLO ImplementationChapter 6. Getting Buy-InChapter 7. Measuring SLIs and SLOsChapter 8. SLO Monitoring and AlertingChapter 9. Probability and Statistics for SLIs and SLOsChapter 10. Architecting for ReliabilityChapter 11. Data ReliabilityChapter 12. A Worked ExamplePart III. SLO CultureChapter 13. Building an SLO CultureChapter 14. SLO EvolutionChapter 15. Discoverable and Understandable SLOsChapter 16. SLO AdvocacyChapter 17. Reliability ReportingおわりにPart I. SLO DevelopmentPart Iでは、SLOの基本概念と開発方法について詳細に解説されています。個人的に好きだったのは、Reliability Stackの概念です。SLI（Service Level Indicators）、SLO、Error Budgetという3つの要素が階層構造を成し、サービスの信頼性を包括的に管理するためのフレームワークを提供しています。著者は、「完璧な信頼性を目指すことは現実的ではなく、むしろユーザーが満足する程度の信頼性を目標とすべき」という考え方を提唱しています。この現実的なアプローチは、リソースの効率的な配分とユーザー満足度のバランスを取る上で重要です。技術的な観点からは、SLIの選定とSLOの設定方法に関する具体的なガイダンスが有用でした。特に、パーセンタイルベースのSLO設定や、依存関係を持つサービスのSLO計算方法など、実践的な知見が多く含まれています。この部分から学んだ最も重要な教訓は、SLOの開発が単なる数値目標の設定ではなく、ユーザーのニーズ、技術的な制約、ビジネス目標のバランスを取る複雑なプロセスであるということです。SREとして、この視点を常に念頭に置きながら、より効果的なSLOの設計と運用を目指していく必要があります。Chapter 1. The Reliability Stack第1章「The Reliability Stack」は、現代のソフトウェアサービスにおける信頼性の重要性と、それを測定・管理するためのフレームワークを提示しています。本章は、Service Level Indicators (SLIs)、Service Level Objectives (SLOs)、そしてError Budgetsという3つの主要概念を中心に構成されており、これらが「Reliability Stack」を形成しています。各用語についてはSRE本のService Level ObjectivesやThe Art of SLOsが良いのでおすすめです。cloud.google.comまず、本書では現代のソフトウェア環境が複雑化し、分散化していることを指摘しています。「We live in a world of services.」という冒頭の一文は、この現状を端的に表現しています。Software as a Service (SaaS)、Infrastructure as a Service (IaaS)、さらにはマイクロサービスアーキテクチャの普及により、サービスの定義自体が曖昧になっているという指摘は、多くのソフトウェアエンジニアが日々直面している課題を的確に捉えています。www.youtube.com本書では、複雑化する環境下でサービスの信頼性を確保するには、従来のログやスタックトレースだけでは不十分であり、新しいアプローチが必要だと主張しています。ここで提案されているのが、ユーザーの視点に立った信頼性の測定と管理です。「\"Is my service reliable?\"という質問は、\"Is my service doing what its users need it to do?\"という質問とほぼ同義である」というフレーズは、信頼性の本質を端的に表現していると思います。 LuupにおけるSLOの物語などは良く資料としてできているので確認してもらいたいです。 speakerdeck.comまた、Observability EngineeringのChapter 12. Using Service-Level Objectives for ReliabilityやChapter 13. Acting on and Debugging SLO-Based AlertsでSLOについて触れているので、これらも一読する価値があるでしょう。なお、Practical MonitoringとObservability Engineeringの2冊を読む前にこの本を読むことは、あまりオススメできません。syu-m-5151.hatenablog.comReliability Stackの基礎となるService Level Indicators (SLIs)は、ユーザーの視点からサービスのパフォーマンスを測定する指標です。本書では、単純な可用性やエラーレートではなく、ユーザーの実際の体験に基づいた指標を選ぶべきだと強調しています。例えば、ウェブページの読み込み時間が2秒以内であれば「良好」、それ以上であれば「不良」とするような具体的な例は、SLIの概念を理解する上で有用です。Figure 1-1. The basic building blocks of the Reliability Stack より引用Figure 1.1で示されているReliability Stackの図は、SLI、SLO、Error Budgetの関係性を視覚的に表現しており、これらの概念の階層構造を理解する上で役立ちます。Service Level Objectives (SLOs)は、SLIに基づいて設定される目標値です。本書では、完璧な信頼性を目指すことは現実的ではなく、むしろ「ユーザーが満足する程度の信頼性」を目標とすべきだと主張しています。この考え方は、リソースの効率的な配分と、ユーザー満足度のバランスを取る上で重要です。SREとして、この視点は特に共感できる部分でした。Figure 1-3. A very basic representation of how you can use error budgets to drive decisions より引用Error Budgetは、SLOからの逸脱を許容する範囲を定義するものです。本書では、Error Budgetを「どの程度サービスが失敗しても許容されるか」を表す指標として説明しています。Figure 1.3で示されているError Budgetの使用方法は、新機能のデプロイや実験的な取り組みと、信頼性向上のための作業のバランスを取る上で有用なフレームワークを提供しています。本書では、様々なタイプのサービス（ウェブサービス、APIサービス、データ処理パイプライン、バッチジョブ、データベース、コンピューティングプラットフォーム、ハードウェア・ネットワーク）について言及し、それぞれのサービスタイプに適したSLIとSLOの設定方法を概説しています。これは、Reliability Stackの概念が幅広いサービスに適用可能であることを示しており、実務上有用な情報です。特に、本書がSLOアプローチの導入に関して注意点を挙げている部分です。「SLOs Are Just Data」、「SLOs Are a Process, Not a Project」、「Iterate Over Everything」、「The World Will Change」、「It's All About Humans」という5つのポイントは、SLOベースのアプローチを実践する上で常に心に留めておくべき重要な指針だと感じました。特に、SLOを単なるプロジェクトではなく、継続的なプロセスとして捉える視点は、多くの組織がSLO導入に失敗する原因を的確に指摘していると思います。技術的な観点からは、本書がSLIの測定方法やError Budgetの計算方法について詳細に説明している点が参考になりました。例えば、Error Budgetの計算にイベントベースのアプローチと時間ベースのアプローチがあることの説明は、実際にError Budgetを実装する際の具体的な指針となります。また、本書がService Level Agreement (SLA)とSLOの違いを明確に説明している点も重要です。SLAが契約上の約束であるのに対し、SLOは内部的な目標であるという区別は、多くの組織でしばしば混同されがちな概念を整理する上で有用です。本章から得られる重要な教訓は、信頼性の管理がサービスの運用において最も重要な要素の一つであり、それをユーザーの視点から測定し、管理することの重要性です。Reliability Stackの概念は、複雑化するサービス環境において、信頼性を体系的に管理するための強力なフレームワークを提供しています。同時、本書では技術的な側面だけでなく、人間的な側面も強調しています。「Service level objectives are ultimately about happier users, happier engineers, happier product teams, and a happier business.」というフレーズは、SLOアプローチの最終的な目標を端的に表現しており、技術と人間のバランスを取ることの重要性を示唆しています。SREとして、この章から学べる重要な点は、信頼性の管理が単なる技術的な問題ではなく、ユーザー、エンジニア、ビジネス全体を考慮した総合的なアプローチが必要だということです。SLI、SLO、Error Budgetの概念は、この複雑な問題に対する体系的なアプローチを提供してくれます。また、本書が強調しているある種の「完璧を目指さない」という姿勢は、リソースの効率的な配分と、継続的な改善のバランスを取る上で重要です。100％の信頼性を目指すのではなく、ユーザーのニーズを満たす程度の信頼性を目指すという考え方は、現実的かつ効果的なアプローチだと感じました。さらに、本書がSLOアプローチを単なるデータ収集や目標設定ではなく、継続的なプロセスとして捉えている点も重要です。SLOの設定や調整を通じて、組織全体が信頼性について継続的に考え、議論する文化を醸成することの重要性が強調されています。技術的な観点からは、SLIの選定やError Budgetの計算方法など、具体的な実装に関する情報が提供されています。これらの情報は、実際にReliability Stackを導入する際の実践的なガイドラインとなります。特に、異なるタイプのサービスに対するSLIの例は、多様なサービス環境に対応する上で有用です。本章を読んで、私はReliability Stackの概念が現代のソフトウェサービス管理において重要であると再認識しました。同時に、この概念を効果的に導入するためには、技術的な実装だけでなく、組織文化の変革も必要であることを強く感じました。SLOアプローチは、技術チームとビジネスチームの橋渡しとなり、サービスの信頼性に関する共通言語を提供する可能性を秘めています。最後に、本書が強調している「イテレーション」の重要性は、印象に残りました。サービスの環境や要件は常に変化しており、それに応じてSLI、SLO、Error Budgetも継続的に見直し、調整していく必要があります。この柔軟性と継続的改善の姿勢は、急速に変化するテクノロジー環境において重要です。総括すると、本章はReliability Stackという概念を通じて、現代のソフトウェアサービスにおける信頼性管理の新しいパラダイムを提示しています。ユーザー中心の視点、データ駆動の意思決定、継続的な改善プロセス、そして技術と人間のバランスを重視するこのアプローチは、複雑化するサービス環境において有効だと感じました。SREとして、この概念を自身の業務に取り入れ、さらに組織全体に浸透させていくことで、より信頼性の高いサービス提供につながると確信しています。Chapter 2. How to Think About Reliability第2章「How to Think About Reliability」は、信頼性という概念に対する深い洞察を提供しています。本書では、技術業界で頻繁に誤解されている信頼性の本質を明らかにし、読者に新たな視点を提示しています。地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon章の冒頭で、本書では技術業界における用語の乱用について警鐘を鳴らしています。\"DevOps\"や\"Site Reliability Engineering\"といった用語本来の意味を失い、単なるマーケティング用語や職種名として使われている現状を指摘しています。これは、SREとしての経験を持つ私にとって共感できる点でした。現場がさき、 プラクティスがあと、 原則はだいじにという言葉が好きなのですが技術用語の本質を理解せずに使用することで、言葉はすりきれる。その概念の重要性や意味が薄れてしまうのは、実にもったいない。本書では、信頼性がしばしば可用性と同一視されることを問題視し、\"Reliability has far too often come to mean only availability in the tech world.\"という一文でこの誤解を端的に表現していますが、SREとして信頼性向上に取り組む中で可用性以外にも多くの要素が関係していることを実感しており、信頼性に対する固定的な答えはないため、実際の現場でデータを収集・分析し、各システムや状況に応じて信頼性を満たすために何が必要かを議論することが重要です。ちょっと過激な表現ですが意味ある可用性を求める運動だと言えると思ってます。本書が提示する信頼性の定義、\"a system is doing what its users need it to do\"は、シンプルでありながら本質を突いています。この定義は、技術的な指標だけでなく、ユーザーの視点を中心に置くことの重要性を強調しています。SREとして、この視点は重要です。私たちは往々にして技術的な指標にとらわれがちですが、最終的にはユーザーの満足度こそ最も重要な指標であることを忘れてはいけません。章の中盤で、過去のパフォーマンスとユーザーの期待について興味深い考察を展開しています。\"Past performance predicts future performance.\"という一文は、ユーザーの期待がどのように形成されるかを端的に表現しています。これは、SLOを設定する際に考慮すべき重要な要素です。過去のパフォーマンスが暗黙の約束となっているという指摘は、SREとして特に注意を払うべき点だと感じました。本書が提示する映画ストリーミングサービスの例は、信頼性の複雑さを理解する上で有効でした。単に動画が再生されるだけでなく、適切な速度でのバッファリング、正しい動画の配信、適切な画質、音声と映像の同期、字幕の正確さなど、多岐にわたる要素が信頼性を構成していることが分かります。この例は、SREとしてシステムの信頼性を考える際に、多角的な視点を持つことの重要性を再認識させてくれます。本書の\"100％ is impossible\"という主張は、重要な点です。完璧を目指すことで、却って資源の無駄遣いや人的負担の増加を招く可能性があることを指摘しています。これは、SREとして常に心に留めておくべき教訓です。信頼性と効率性のバランスを取ることの重要性を再認識させられました。反脆弱性［上］――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazon本書では、信頼性の向上にかかるコストについても詳細に説明しています。99.9％から99.95％への信頼性の向上と、99.95％から99.99％への向上では、後者の方が5倍のコストがかかるという具体的な例は、印象的でした。この数学的な裏付けは、信頼性目標を設定する際の重要な判断材料となります。最後に本書では、信頼性に対する考え方について総括しています。\"Be as reliable as your users need you to be.\"という一文は、信頼性に対するアプローチの本質を表現しています。しかし、本書ではこの単純な答えに留まらず、ユーザーのニーズが時間とともに変化することや、上流のサービスの信頼性に依存する部分があることなど、より複雑な要因についても言及しています。この章から得られる重要な教訓は、信頼性は単純な数値目標ではなく、ユーザーのニーズと企業のリソースのバランスを取るための継続的なプロセスであるということです。SREとして、この視点は重要です。ユーザーの期待、技術的な制約、コストなど、様々な要因を考慮しながら、最適な信頼性レベルを追求し続けることが求められています。技術的な観点からは、本書が提示する信頼性の数学的な考察が非常興味深いものでした。特に、99.99％の信頼性を達成するために必要な対応時間や、信頼性向上にかかるコストの非線形性など、具体的な数値を用いた説明は、SREとして信頼性目標を設定する際の重要な指針となります。また、本書が強調している\"black swan event\"への対応の重要性も、SREとして心に留めておくべき点です。予測不可能な大規模障害に対しては、通常のSLOやエラーバジェットの考え方を一時的に保留し、柔軟に対応することの重要性を再認識しました。この章を読んで、信頼性の向上は単にシステムの可用性を高めることではなく、ユーザーのニーズを深く理解し、それに応えるためのバランスの取れたアプローチを追求することだと再認識しました。また、技術チームだけでなく、製品チーム、経営陣との密接な連携の重要性も強く感じました。特に印象に残ったのは、本書が繰り返し強調している「ユーザー視点」の重要性です。SREとして、私たちは往々にして技術的な指標にとらわれがちですが、最終的にはユーザーの満足度こそが最も重要な指標であることを忘れてはいけません。この視点は、SLOの設定や、障害対応の優先順位付けなど、日々の業務の様々な場面で活かせると感じました。また、本書が提示する「信頼性のコスト」についての考察は、SREとしての意思決定に大きな影響を与えるものだと感じました。完璧な信頼性を目指すのではなく、ユーザーのニーズと企業のリソースのバランスを取ることの重要性を、数学的な裏付けとともに理解できたことは有意義でした。この章から学んだことを実践に移す上で、以下のような体的なアクションを考えています：SLOの設定時に、技術的な指標だけでなく、ユーザーの実際の使用体験を反映した指標を取り入れる。信頼性目標の設定時に、その目標達成にかかるコストと得られる便益を定量的に評価する。チーム内で定期的に「ユーザーにとっての信頼性」について議論する場を設ける。上流サービスの信頼性も考慮に入れた、より現実的なSLOを設定する。予期せぬ大規模障害に対応するための柔軟な計画を立てる。総括すると、この章は信頼性に対する新たな視点を提供し、SREとしての私たちの役割を再定義するものでした。信頼性は単なる技術的な問題ではなく、ユーザーのニーズ、ビジネスの要求、技術的な制約のバランスを取るための継続的なプロセスであることを強く認識させられました。この視点を持ちつ、日々の業務に取り組むことで、より効果的なSREとしての貢献ができると確信しています。Chapter 3. Developing Meaningful Service Level Indicators第3章「Developing Meaningful Service Level Indicators」は、SLO（Service Level Objectives）ベースのアプローチにおける最も重要な要素であるSLI（Service Level Indicators）の開発に焦点を当てています。本書では、SLIの重要性を強調し、その開発方法について詳細に説明しています。 speakerdeck.com章の冒頭で、本書では「SLIs are the most vital part of this entire process and system.」と述べ、SLIがReliability Stackの基礎であることを強調しています。この言葉は、SREとしての私の経験と深く共鳴しました。システムの信頼性を向上させるためには、まず適切な指標を設定することが不可欠であり、それがSLIの役割だと理解しています。本書では、SLIの重要性を説明する中で、「Your service isn't reliable if your users don't think it is.」という一文を用いています。この視点は、技術的な指標だけでなく、ユーザーの認識を重視することの重要性を示唆しており、SREとしての私の考え方に大きな影響を与えました。章の中盤では、SLIの開発方法について具体的な例を用いて説明しています。本書では、単純なリクエスト・レスポンスAPIから始めて、より複雑な小売ウェブサイトのアーキテクチャまで、様々なレベルのサービスについてSLIの開発方法を示しています。Figure 3-1. A basic and oversimplified retail website architecture より引用Figure 3.1では、簡略化された小売ウェブサイトのアーキテクチャが示されており、複雑なシステムにおけるSLIの開発の難しさを視覚的に理解することができます。この図は、SLIを開発する際に考慮すべき様々なコンポーネントとその相互作用を明確に示しており、有用でした。本書では、複雑なシステムにおけるSLIの開発について、「Measuring many things by measuring only a few」というアプローチを提案しています。これは、ユーザーの視点から最も重要な指標を選び出し、それを測定することで、システム全体の信頼性を効果的に評価できるという考え方です。この考え方は、SREとして複雑なシステムの監視を行う際に有用だと感じました。技術的な観点から特に興味深かったのは、SLIの測定方法に関する説明です。本書では、エラ率や応答時間などの基本的な指標から始めて、より複雑なユーザージャーニーの測定まで、段階的にアプローチを深めていきます。例えば、ログイン機能のSLIを開発する際に、単に認証サービスのエラー率を見るだけでなく、ロードバランサーからユーザーのブラウザでの表示まで、エンドツーエンドの流れを考慮する必要があるという指摘は、重要だと感じました。ユーザージャーニーやカスタマージャーニーとは何か知りたい方はこの書籍がオススメです。理想的なカスタマージャーニーの設計原則 DIAMOND ハーバード・ビジネス・レビュー論文作者:アヒール・ゴパルダス,アントン・シーベルトダイヤモンド社Amazon本書では、SLIの記述方法についても言及しています。「The 95th percentile of requests to our service will be responded to with the correct data within 400 ms.」という例は、技術的な詳細を含みながらも、非技術者にも理解しやすい形で表現されています。これは、SREとして他部署とコミュケーションを取る際に参考になる表現方法だと感じました。また、本書ではSLIの開発がビジネスアラインメントにも寄与することを指摘しています。SLIは、プロダクトマネージャーの「ユーザージャーニー」、ビジネス部門の「KPI」、QAチームの「インタフェーステスト」と本質的に同じものを指している場合が多いという指摘は、興味深いものでした。これは、SREが組織全体のアラインメントを促進する上で重要な役割を果たせることを示唆しています。はじめてのカスタマージャーニーマップワークショップ(MarkeZine BOOKS) 「顧客視点」で考えるビジネスの課題と可能性作者:加藤 希尊翔泳社Amazon章の結論部分で本書では、SLIの開発が必ずしも容易ではないことを認めつつも、その重要性を強調しています。「Thinking about your users first is never a bad idea.」という言葉は、SLIの開発だけでなく、SREの仕事全般に通じる重要な指針だと感じました。この章から得られる重な教訓は、SLIの開発がSLOベースのアプローチの基礎であり、ユーザーの視点を中心に置くことの重要性です。技術的な指標に偏りがちな私たちSREにとって、この視点は重要です。また、複雑なシステムにおいても、少数の重要な指標を適切に選択することで、全体の信頼性を効果的に測定できるという点も、実践的で有用な知見だと感じました。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます。現在のモニタリング指標を見直し、それらがユーザーの視点をどの程度反映しているかを評価する。各サービスについて、ユーザージャーニーを詳細にマッピングし、そこから重要なSLIを抽出する。エンドツーエンドの測定を可能にするためのインフラストラクチャ（例：分散トレーシングシステム）の導入を検討する。SLIの定義と測定方法について、プロダクト、ビジネス、QAなど他部門と議論し、組織全体でのアラインメントを図る。SLIの定義を定期的に見直し、ユーザーのニーズや期待の変化に合わせて更新する。技術的な観点からは、SLIの測定に関する本書の提案は有用でした。特に、複雑なシステムにおいてエンドツーエンドの測定を行うことの重要性は、私たちのモニタリング戦略を再考する良いきっかけになると感じました。例えば、現在の個別のコンポーネントレベルのモニタリングに加えて、ユーザーの実際の体験をシミュレートするシンセティックモニタリングの導入を検討する価値があるでしょう。また、本書が提案する「多くのことを少数の指標で測定する」アプローチは、モニタリングシステムの設計にも大きな影響を与えると考えられます。現在のように多数の指標を個別に監視するのではなく、ユーザー体験に直結する少数の重要な指標に焦点を当てたダッシボードやアラートシステムの設計が必要になるでしょう。さらに、SLIの定義を「簡単に説明できる文章」で表現するという提案は、技術チームと非技術チームのコミュニケーションを改善する上で重要だと感じました。これは、インシデント対応時の状況説明や、経営陣への報告の際にも役立つアプローチだと考えられます。この章を読んで、単にシステムの技術的な側面を監視し、問題に対処するだけでなく、ユーザー体験の向上に直接寄与する指標を設計し、それに基づいてシステムの信頼性を向上させていくことが、私たちの重要な責務であことを再認識しました。また、SLIの開発が組織全体のアラインメントにつながるという指摘は、SREの役割がより戦略的になる可能性を示唆しています。技術部門と事業部門の橋渡し役として、SREがビジネス目標の達成に直接貢献できる可能性があることを感じました。総括すると、この章はSLIの開発というテクニカルな話題を通じて、SREの役割と責任について深い洞察を提供しています。ユーザー中心の視点、複雑なシステムの理解、組織全体とのアラインメント、これらはすべてSREが取り組むべき重要な課題です。SLIの適切な開発と運用は、これらの課題に対処するための強力なツールとなり得ます。今後の実務において、この章で学んだアプローチを積極的に取り入れていきたいと考えています。特に、ユーザージャーニーの詳細な分析とそれに基づくSLIの設計、エンドツーエンドの測定を可能にするインフラの整備、そして他部門との密接な連携によるSLIの継続的な改善に注力していきたいと思います。これらの取り組みを通じて、より効果的なSREプラクティスを確立し、最終的にはユーザー満足度の向上とビジネス目標の達成に貢献できると確信しています。Chapter 4. Choosing Good Service Level Objectives第4章「Choosing Good Service Level Objectives」は、SLO（Service Level Objectives）の設定に関する深い洞察を提供しています。本書では、SLOの本質と、それを効果的に選択・設定するための方法論を詳細に解説しています。チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチ作者:エイミー・C・エドモンドソン,Amy C. Edmondson英治出版Amazon本書では、SLOを「ユーザーの幸福度」という観点から定義しています。「If you are exceeding your SLO target, your users are happy with the state of your service.」という一文は、SLOの本質を的に表現しています。この視点は、技術的な指標だけでなく、ユーザー体験を中心に据えることの重要性を強調しており、SREとしての私たちの役割を再考させられました。しかし、本書では同時に「too reliable」であることの問題点も指摘しています。「Being too reliable all the time, you're also missing out on some of the fundamental features that SLO-based approaches give you: the freedom to do what you want.」この考え方は、一見paradoxicalに思えますが、実際の運用環境では重要です。過度に高い信頼性を目指すことで、イノベーションや実験の機会を失う可能性があるという指摘は、SREとして常に意識すべき点だと感じました。本書では、SLO設定において「9」にこだわりすぎることの危険性も指摘しています。99.9％や99.99％といった数値は一見魅力的ですが、実際のサービス運用では必ずしも適切ではない場合があります。本書では、より柔軟なアプローチを提案しており、例えば98.62％や87％といったSLO目標も適切な場合があると述べています。この柔軟性は、実際のサービス運用において重要だと感じました。技術的な観点から特に興味深かったのは、SLO設定における統計的アプローチの解説です。本書では、平均値、中央値、モード、範囲、パーセンタイルなどの基本的な統計概念を丁寧に説明し、これらがSLO設定にどのように活用できるかを具体的に示しています。例えば、95パーセンタイルの応答時間を使用してSLOを設定する方法は、実際のサービス運用において有用です。Table 4-1. SLO targets composed of nines translated to time より引用Table 4-2. SLO targets composed of not-just-nines translated to time より引用Figure 4.1と4.2で示されている「SLO targets composed of nines translated to time」と「SLO targets composed of not-just-nines translated to time」の表は、異なるSLO目標が実際の運用時間にどのように影響するかを視覚的に理解する上で役立ちました。これらの表は、SLO目標を設定する際の具体的な指針となります。本書では、サービスの依存関係とコンポーネントの考慮の重要性も強調しています。特に、複数のチームが関わる複雑なサービスにおいて、各コンポーネントのSLOをどのように設し、全体のSLOとどう整合性を取るかという点は、実務上重要な課題です。本書の提案する「dependency math」は、この課題に対する具体的なアプローチを提供しており、実践的で有用だと感じました。また、本書ではメトリクスの属性（解像度、量、質）についても詳細に解説しています。これらの要素がSLO設定にどのように影響するかを理解することは、適切なSLOを選択する上で重要です。特に、低頻度イベントや品質の低いデータに対するアプローチは、実際のSRE業務で直面する課題に直接関連しており、有用な知見でした。本書が提案するパーセンタイル閾値の使用は、特にロングテールを持つ分布（例：レイテンシー）を扱う際に非常に有効で、例えば「The P95 of all requests will successfully complete within 2,000 ms 99.9％ of the time.」というSLOの設定方法は、ロングテールのパフォーマンスを継続的に監視・管理できる点と、SLOをより直感的に報告できる点で優れたアプローチだと感じました。この章から得られる重要な教訓は、SLO設定が単なる数値目標の設定ではなく、ユーザーの期待、技術的な制約、ビジネス目標のバランスを取る複雑なプロセスであるということです。本書の「SLOs are objectives, they're not formal agreements」という言葉は、SLOアプローチの柔軟性と進化の必要性を強調しており、重要な指摘だと感じました。この章の内容を実践に移す上で、以下のようなアプローチを考えています。また、資料としては以下がSLOをゼロからつくるなどがおすすめなので国内の事例として読んでみてほしいです。現在のSLOを再評価し、ユーザー体験をより適切に反映しているか検討する。パーセンタイル閾値を活用し、ロングテールを持つメトリクスに対するSLOを改善する。サービスの依存関係を詳細にマッピングし、「dependency math」を用いて全体のSLOを再計算する。メトリクスの属性（解像度、量、質）を詳細に分析し、SLO設定に反映させる。チーム間でSLOに関する定期的な議論の場を設け、継続的な改善を図る。技術的な観点からは、本書が提案する統計的アプローチとパーセンタイル閾値の使用は、特に注目に値します。これらの手法を実装するためには、高度なモニタリングシステムと分析ツールが必要になるでしょう。例えば、リアルタイムでパーセンタイル値を計算し、SLO違反を検出するシステムの構築が考えられます。また、「dependency math」を自動化し、サービスの依存関係の変更がSLOにどのように影響するかをシミュレートするツールも有用でしょう。さらに、本書の「operational underload」の概念は、SRE実践において重要です。システムに適度なストレスをかけることで、チームの対応能力を維持し、潜在的な問題を早期に発見できるという考え方は、従来のシステム運用の考え方を覆すものです。これを実践するためには、慎重に設計された負荷テストやカオスエンジニアリングの手法の導入が必要になるでしょう。この章の内容は、SREの実務に直接的に適用できる多くの示唆に富んでいます。例えば、新しいサービスのSLO設定時には、本書が提案する「educated guess」アプローチを採用し、初期のSLOを設定した後、実際のデータに基づいて迅速に調整していく方法を取り入れることができます。また、既存のサービスについては、現在のSLOが本当にユーザーの期待を反映しているか、定期的に再評価する習慣を導入することが重要です。本書の「Nines don't matter if users aren't happy」という考え方は、SREの役を再定義するものだと感じました。技術的な指標の達成だけでなく、実際のユーザー満足度を中心に据えたアプローチは、SREがビジネス価値の創出により直接的に貢献できることを示唆しています。これは、SREの戦略的重要性を高め、組織内での位置づけを変える可能性を持っています。一方で、この章の内容を実践する上での課題も存在します。例えば、複雑な依存関係を持つマイクロサービス環境では、個々のサービスのSLOと全体のSLOをどのように整合させるかが大きな課題となります。また、ユーザー満足度を正確に測定し、それをSLOに反映させる方法も、さらなる研究と実験が必要な領域です。さらに、本書が提案する柔軟なSLOアプローチは、組織文化の変革を必要とする場合があります。特に、従来の固定的なSLAに慣れた組織では、より動的で適応的なSLOアプローチへの移行に抵抗がある可能性があります。この課題に対処するためには、経営陣を含む組織全体での理解と支持を得ることが重要です。総括すると、この章はSLO設定に関する包括的かつ実践的なガイドを提供しています。本書の現実主義的かつユーザー中心のアプローチは、SREの実務に直接的に適用可能な多くの洞察を提供しています。特に、「100％は不可能」という前提に立ちつつ、どのようにして適切な信頼性目標を設定するかという問いに対する本書の回答は、示唆に富んでいます。この章から学んだアプローチを実践することで、より効果的なSLO設定が可能になり、結果としてユーザー満足度の向上とビジネス目標の達成につながると確信しています。同時に、SLO設定はコンテキストに依存する複雑なプロセスであり、継続的な学習と改善が必要であることも忘れてはいけません。最後に、この章の内容は、SREが単なる技術的な役割ではなく、ビジネスとユーザー体験を深く理解し、それを技術的に実現する戦略的な役割であることを再認識させてくれました。SLOの適切な設定と管理は、この役割を果たす上で核心的な要素であり、今後のSRE実践においてさらに重要性を増していくと考えられます。Monitoring user experience of Flutter apps with SLI/SLO (日本語)も良かったのでオススメです。 speakerdeck.comChapter 5. How to Use Error Budgets第5章「How to Use Error Budgets」は、SRE（Site Reliability Engineering）の核心とも言えるエラーバジェットの概念と実践的な活用方法について深く掘り下げています。本書では、エラーバジェットが単なる数値目標ではなく、組織の意思決定と行動を導く強力なツールであることを説得力のある方法で説明しています。章の冒頭で、本書では「Error budgets are the final part of the Reliability Stack, and it takes a lot of effort and resources to use them properly.」と述べ、エラーバジェットの重要性と実装の難しさを強調しています。この言葉は、SREとしての私の経験と深く共鳴しました。エラーバジェットの導入は、技術的な課題だけでなく、組織文化の変革も必要とする複雑なプロセスであることを日々実感しています。失敗の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon本書が提示するエラーバジェットの基本的な考え方は、Figure 5.1に端的に示されています。「If you have error budget remaining, ship new features and push to production as often as you'd like; once you run out of it, stop pushing feature changes and focus on reliability instead.」この単純な原則は、開発チームと運用チームの間の対立関係に対する優れた解決策を提供しています。技術的な観点から特に興味深かったのは、エラーバェットの計算方法に関する詳細な説明です。本書では、イベントベースと時間ベースの2つのアプローチを紹介し、それぞれの利点と欠点を解説しています。例えば、30日間のウィンドウで99.7％のSLO目標を持つサービスの場合、エラーバジェットは次のように計算されます：(1 - 0.997) × 2592000 = 7776この7776秒（2時間9分36秒）が、30日間で許容される「不安定な時間」となります。この具体的な数値を示すことで、エラーバジェットの概念がより理解しやすくなると感じました。本書ではまた、エラーバジェットの時間枠の選択についても詳しく論じています。ローリングウィンドウとカレンダーベースのウィンドウの比較は、特に興味深いものでした。カレンダーベースのウィンドウは報告や計画が容易になる一方で、月末近くの大きな障害の影響を適切に映できない可能性があるという指摘は、実務上重要な点だと感じました。エラーバジェットポリシーの策定に関する本書の提案も、有用でした。特に、「Use words like must, may, should, and required in your written policies to help give people freedom to adapt certain parts of them.」という助言は、ポリシーの柔軟性と厳格性のバランスを取る上で重要だと感じました。本書が推奨するRFC 2119の活用は、技術文書の作成において有用な指針だと思います。この章で最も印象に残ったのは、エラーバジェットを単なる数値目標ではなく、意思決定のツールとして捉える視点です。「Error budget status is just the end result of a bunch of data (SLIs, SLOs, and their targets) that exists to help you make decisions.」この考え方は、SREの実践において重要です。エラーバジェットは、チーム間のコミュニケーションを促進し、リソース配分の優先順位付けを支援する強力なツールとなり得ます。本書が提案するエラーバジェットの段階的な対応策（例：33％消費で2人、66％消費で4人がリライアビリティ作業に集中）は、実務に直接適用できる具体的なアイデアとして参考になりました。同時に、これらの対応策を固定的なルールではなく、状況に応じて柔軟に適用すべきガイドラインとして捉える本書の姿勢は、現実のソフトウェア開発環境の複雑さを適切に反映していると感じました。エラーバジェットの計算方法に関する技術的な詳細も、有用でした。特に、ローリングウィンドウとカレンダーベースのウィンドウの比較は、実際のシステム設計において重要な選択となります。本書が指摘するように、カレンダーベースのウィンドウは報告や計画が容易になる一方で、月末近くの大きな障害の影響を適切に反映できない可能性があります。この点は、エラーバジェットの設計において慎重に考慮すべき要素だと感じました。また、本書が提案する「時間の除外」の概念も興味深いものでした。計画的なメンテナンス時間や、サービスが重要でない時間帯をエラーバジェットの計算から除外することで、より現実的なSLOを設定できるという点は、多くのシステムに適用可能な有用な考え方だと思います。エラーバジェットポリシーの策定に関する本書の提案は、組織内でのエラーバジェットの効果的な運用に不可欠なものだと感じました。特に、ポリシーに所有者とステークホルダーを明確に記載することの重要性は、組織の規模が大きくなるほど重要になります。また、エラーバジェットのバーンレートに応じた段階的な対応策の設定は、リソースの効率的な配分と迅速な問題対応のバランスを取る上で有効だと思います。本書が強調する「信頼」の重要性も良かったです。エラーバジェットポリシーは厳格なルールではなく、意思決定のガイドラインであるべきだという考え方は、現実の複雑な状況に柔軟に対応する上で重要です。同時に、ポリシーの定期的な見直しと更新の必要性を強調している点も、変化の激しい技術環境において重要だと感じました。この章から得られる重要な教訓は、エラーバジェットが単なる数値目標ではなく、組織全体の意思決定とコミュニケーションを導く強力なツールであるということです。エラーバジェットを効果的に活用するためには、技術的な実装だけでなく、組織文化の変革と継続的な善プロセスが不可欠です。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：エラーバジェットの計算方法と時間枠の選択を、サービスの特性とユーザーのニーズに基づいて慎重に検討する。段階的なエラーバジェット消費に対する対応策を、チームの規模と構造に合わせて設計する。エラーバジェットポリシーを作成し、所有者、ステークホルダー、対応策、見直しスケジュールを明確に定義する。エラーバジェットの状況を定期的に報告し、チーム間のコミュニケーションと意思決定に活用する。エラーバジェットの概念と重要性について、組織全体の理解を促進するための教育プログラムを実施する。技術的な観点からは、エラーバジェットの計算と監視を自動化するシステムの構築が重要になります。例えば、SLIデータを継続的に収集し、リアルタイムでエラーバジェットの状況を計算・可視化するダッシボードの開発が考えられます。また、エラーバジェットのバーンレートに基づいて自動的にアラートを発生させ、適切なチームメンバーに通知するシステムも有用でしょう。さらに、本書が提案するエラーバジェットの「burn rate」の概念は、特に注目に値します。この概念を実装するためには、時系列データベースとアナリティクスツールの効果的な活用が必要になるでしょう。例えば、Prometheus+Grafanaの組み合わせを使用して、エラーバジェットのバーンレートを可視化し、予測分析を行うことが考えられます。エラーバジェットの概念をCICD（Continuous Integration/Continuous Deployment）パイプラインと統合することも、有効なアプローチだと考られます。例えば、現在のエラーバジェットの状況に基づいて、自動的にデプロイメントの頻度や規模を調整するシステムを構築することができます。これにより、エラーバジェットの概念をより直接的に開発プロセスに組み込むことが可能になります。この章を読んで、エラーバジェットの効果的な活用は、単にシステムの信頼性を向上させるだけでなく、組織全体のアラインメントとコミュニケーションを促進する強力なツールとなり得ます。特に、開発チームと運用チームの間の伝統的な対立を解消し、共通の目標に向かって協力する文化を醸成する上で、エラーバジェットは有効だと感じました。また、エラーバジェットを活用した意思決定プロセスは、SREの戦略的な重要性を高める可能性がります。エラーバジェットの状況に基づいて、リソース配分や優先順位付けを行うことで、SREはより直接的にビジネス目標の達成に貢献できるようになります。これは、SREの役割がより戦略的になり、経営陣との対話がより深まる可能性を示唆しています。総括すると、この章はエラーバジェットの概念と実践的な活用方法について、包括的かつ深い洞察を提供しています。エラーバジェットは、単なる技術的なメトリクスではなく、組織の文化と意思決定プロセスを変革する強力なツールです。SREとして、エラーバジェットの効果的な実装と活用は、システムの信頼性向上だけでなく、組織全体のパフォーマンス向上にも大きく貢献する可能性があると確信しています。今後の課題としては、エラーバジェットの概念をより広範囲のステークホルダーに理解してもらい、組織全体で活用していくことが挙げられます。また、エラーバジェットの計算と監視をより精緻化し、より正確かつリアルタイムな意思決定を支援するシステムの開発も重要な課題となるでしょう。さらに、エラーバジェットの概念を他の経営指標と統合し、より包括的な組織パフォーマンスの評価システムを構築することも、将来的な展望として考えられます。エラーバジェットの効果的な活用は、SREの実践において中心的な役割を果たすものです。この章で学んだ概念と手法を、日々の業務に積極的に取り入れていくことで、より信頼性の高いシステムの構築と、より効果的な組織運営に貢献できると確信しています。同時に、エラーバジェットの概念は常に進化し続けるものであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。Part II. SLO ImplementationPart IIでは、SLOの実装と運用に焦点が当てられています。特に良かったのは、SLOモニタリングとアラートに関する章です。著者は、従来のしきい値ベースのアラートの問題点を指摘し、エラーバジェットのバーンレートに基づいたSLOアラートの優位性を説明しています。世の中にはOpenSLOなんていう取り組みもあります。技術的な観点からは、エラーバジェットの計算方法や、短期的な問題（fast burn）と長期的な問題（slow burn）を区別して扱うアプローチなど、実践的な知見が多く含まれています。これらの手法は、より効果的なインシデント管理と、リソースの最適な配分を可能にします。また、データの信頼性に関する章も興味深いものでした。データサービスの信頼性が他のサービスとは根本的に異なる性質を持つことが強調され、データの鮮度、完全性、一貫性など、多面的な属性を考慮したSLO設定の重要性が説明されています。この部分から学んだ最も重要な教訓は、SLOの実装が技術的な課題だけでなく、組織全体のプロセスと密接に関連していることです。SLOを効果的に運用するためには、技術チーム、プロダクトチーム、経営陣など、様々なステークホルダーの協力が不可欠です。SREとして、これらの関係者間のコミュニケーションを促進し、SLOを組織の意思決定プロセスに組み込んでいく役割が求められています。Chapter 6. Getting Buy-In第6章「Getting Buy-In」は、SLO（Service Level Objectives）の導入において最も重要かつ困難な課題の一つである組織内の合意形成について詳細解説しています。本章では、SLOの導入が単なる技術的な問題ではなく、組織全体の文化や意思決定プロセスに深く関わる変革であることを強調しています。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon章の冒頭で、本書では「SLIs, SLOs, and error budgets are really helpful mental tools to reason about the reliability needs of your systems. If you want them to be anything more than just interesting talking points, however, you will need to convince your company (or organization) to implement and live by them.」と述べています。この言葉は、SLOの導入が単なる技術的な実装以上の意味を持つことを端的に表現しています。この点に強く共感しました。技術的に優れたソリューションであっても、組織全体の理解と支持がなければ、その効果を十分に発揮することはできません。 speakerdeck.com本書では、SLO導入のための合意形成プロセスを段階的に説明しています。特に良かったのは、各ステークホルダーの懸念事項と、それに対する効果的な説得方法を具体的に提示している点です。例えば、エンジニアリングチームに対しては、「SLOs (and error budgets) increase both reliability and feature velocity over time. They also make for a better work environment because they align incentives among previously warring factions.」というメッセージが効果的だと述べています。この視点は、開発チームと運用チームの間に常に存在する対立関係を解消する上で重要だと感じました。技術的な観点から特に興味深かったのは、エラーバジェットポリシーの設計に関する提案です。本書では、最初の1年間は単一のエラーバジェットポリシーを採用し、それを「新機能の凍結（feature freeze)」ポリシーとすることを推奨しています。具体的には、可用性SLOが99.9％の場合、30日間で43.2分のエラーバジェットがあり、このバジェットを超過した場合は新機能の開発を一時停止し、信頼性向上に注力するというものです。この明確で厳格なポリシーは、組織全体にSLOの重要性を浸透させる上で効果的だと感じました。本書では、SLO導入のための合意形成プロセスを5つの主要なステークホルダーグループ（エンジニアリング、運用、プロダクト、リーダーシップ、法務）に分けて説明しています。各グループの懸念事項と、それに対する効果的な説得方法が詳細に解説されており、実際の導入プロセスにおいて参考になりました。また本書では、エグゼクティブリーダーシップへの説得方法についても詳しく解説されています。「In our firm, we strive for 100％ customer satisfaction and 100％ uptime! Our customers will tolerate no less!」という経営陣からよくある反応に対して、本書では現実主義的なアプローチを提案しています。完璧な信頼性は不可能であり、むしろ適切なレベルの信頼性を目指すことで、イノベーションと安定性のバランスを取ることができるという説明は、説得力がありました。また、本書が提案する「thaw tax」の概念も興味深いものでした。機能フリーズ期間中に例外的にリリースを行う場合、その期間の1.5倍をフリーズ期間に追加するという考え方は、ポリシーの柔軟性と厳格性のバランスを取る上で有効だと思います。SLO導入の最初の重要な瞬間について、本書では「The most important moment is the first time you exhaust your error budget and need to enforce your policy. That will be the moment that teaches everyone whether or not you are serious about this journey.」と述べています。この指摘は、共感できるものでした。ポリシーを厳格に適用することの重要性と、それが組織文化の変革につながることを強調している点は、重要だと感じました。本書では、SLO導入プロセスから学んだ教訓も共有しています。特に印象的だったのは、「Too much too soon」という警告です。一度にすべてを変えようとするのではなく、一つの製品の一部分、あるいは一つの障害ドメインから始めることの重要性を強調しています。この段階的なアプローチは、大規模な組織変革を成功させる上で重要だと感じました。また、「Be completely transparent」という助言も重要です。SLOとエラーバジェットの状況を組織全体で可視化し、共有することの重要性を強調しています。これは、SLOアプローチの効果を最大化し、組織全体のアラインメントを促進する上で不可欠だと思います。技術的な観点からは、本書がSLOとエラーバジェットの可視化について言及している点が興味深かったです。具体的な実装方法は述べられていませんが、例えばPrometheus + Grafanaのような監視スタックを活用し、リアルタイムでSLOの状況を可視化するダッシュボードを構築することが考えられます。これにより、組織全体でSLOの状況を共有し、迅速な意思決定を行うことが可能になります。本書では最後に、SLOアプローチの導入に対する一般的な反論とその反駁を提示しています。特に、「But we're not Google!」という反論に対する本書の回答は印象的でした。SLOベースのアプローチはGoogle特有のものではなく、あらゆる規模の組織に適用可能であることを強調しています。この章から得られる最も重要な教訓は、SLOの導入が技術的な課題以上に、組織文化の変革と関係者の合意形成が重要であるということです。本書が提示する段階的なアプローチと各ステークホルダーに対する具体的な説得方法は、実際のSLO導入プロセスにおいて有用なガイドラインとなります。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます。組織内の主要なステークホルダーを特定し、それぞれの懸念事項を事前に把握する。SLOとエラーバジェットの概念について、非技術者にも理解しやすい説明資料を準備する。小規模なパイロットプロジェクトから始め、成功事例を作り出す。エラーバジェットポリシーを明確に定義し、組織全体で合意を得る。SLOとエラーバジェットの状況を可視化するダッシュボードを構築し、組織全体で共有する。定期的にSLOの見直しと調整を行い、継続的な改善を図る。技術的な観点からは、SLOとエラーバジェットの測定と可視化のためのインフラストラクチャの構築が重要になります。例えば、以下のような技術スタックの活用が考えられます。Prometheusを使用してSLIメトリクスを収集する。Grafanaを使用してSLOとエラーバジェットの状況をリアルタイムで可視化する。Alertmanagerを設定し、エラーバジェットのバーンレートに応じたアラートを発行する。Kubernetes Operatorを開発し、エラーバジェットの状況に応じて自動的にデプロイメントを制御する。これらの技術的な実装により、SLOアプローチを組織の日常的な運用に組み込むことが可能になります。また、本書が強調している「透明性」を実現するためには、技術的な可視化だけでなく、組織内のコミュニケーションプロセスも整備する必要があります。例えば、週次または月次のSLOレビューミーティングを設定し、エンジニアリング、プロダクト、経営陣が一堂に会してSLOの状況と今後の方針を議論する場を設けることが有効でしょう。SLOの導入は、単なる技術的な指標の導入以上の意味を持ちます。それは、組織全体の意思決定プロセスと優先順位付けの方法を根本的に変える可能性を秘めています。例えば、新機能の開発とシステムの安定性向上のバランスを、感覚的なものではなく、データに基づいて判断することが可能になります。これにより、エンジニアリングリソースの最適な配分が可能になり、結果としてユーザー満足度の向上とビジネス目標の達成につながります。同時に、SLOアプローチの導入は、組織の文化を「障害を責める」文化から「学習と改善」の文化へと変革する契機にもなり得ます。エラーバジェットの概念は、一定レベルの障害を許容することで、より積極的な実験と学習を促進します。これは、長期的には組織の革新性と競争力の向上につながる可能性があります。この章を読んで、私はSREの役割がより戦略的なものになりつつあることを強く感じました。SLOの導入と運用を通じて、SREは技術的な問題解決だけでなく、組織全体の方向性に影響を与える重要な位置にあることが明確になりました。この変化に適応し、技術的なスキルとビジネス感覚の両方を磨いていくことが、今後のSREにとって不可欠だと考えます。総括すると、この章はSLO導入の成功に不可欠な組織的側面に焦点を当て、具体的かつ実践的なガイダンスを提供しています。技術的な実装はSLO導入の一部分に過ぎず、真の成功は組織全体の理解と支持を得ることにあるという本書のメッセージは、重要です。SREとして、この章から学んだアプローチを実践することで、より効果的なSLO導入が可能になり、結果として組織全体のパフォーマンス向上につながると確信しています。同時に、SLO導入プロセスは継続的な学習と改善の機会でもあります。初期の導入後も、定期的にSLOの妥当性を見直し、組織の変化や新たな技術の登場に応じて柔軟に調整していく必要があります。この継続的な改善プロセスこそが、SLOアプローチの真の価値を引き出す鍵となるでしょう。今後の課題としては、SLOの概念をより広範囲の組織メンバーに浸透させること、SLOデータを活用した意思決定プロセスの確立、そして他のビジネスメトリクスとSLOを統合した包括的なパフォーマンス評価システムの構築などが考えられます。これらの課題に取り組むことで、SLOアプローチはより一層組織に根付き、長期的な価値を生み出すことができるでしょう。最後に、本書の「SLOは複雑な科学ではなく、基本的な算術と規律の問題である」という指摘は重要です。この言葉は、SLO導入の本質が技術的な複雑さではなく、組織の意志と実行力にあることを端的に表現しています。SREとして、この点を常に念頭に置きながら、組織全体のアラインメントと継続的な改善を推進していくことが重要だと感じました。SLOの導入は、技術的な変革であると同時に、組織文化の変革でもあります。この章で学んだアプローチを実践することで、より信頼性の高いシステムの構築と、より効果的な組織運営に対して営に貢献できると確信しています。同時に、SLOの概念は常に進化し続けるものであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応してく必要があることも忘れてはいけません。SLOの導入プロセスにおいて、本書が強調する「ステークホルダーの理解と支持を得ること」の重要性は、特に注目に値します。技術的に優れたソリューションであっても、組織全体の理解と支持がなければ、その効果を十分に発揮することはできません。この点で、本書が提案する各ステークホルダーグループ（エンジニアリング、運用、プロダクト、リーダーシップ、法務）に対する具体的な説得方法は、実践的で有用です。例えば、エンジニアリングチームに対しては、SLOとエラーバジェットが信頼性と機能開発速度の両方を向上させることを強調します。これは、多くのエンジニアが抱える「信頼性向上と新機能開発のトレードオフ」という懸念に直接応えるものです。一方、運用チームに対して、SLOアプローチがエンジニアリングチームとの対立を解消し、共通の目標に向かって協力する文化を醸成することを強調します。プロダクトチームに対しては、SLOが長期的には機能開発速度を向上させることを説明します。これは、多くのプロダクトマネージャーが持つ「SLOが機能開発を遅らせる」という懸念を解消するのに役立ちます。さらに、SLOがユーザージャーニーと密接に関連していることを強調することで、プロダクトチームの関心を引き出すことができます。リーダーシップに対しては、SLOアプローチが組織全体のアラインメントを促進し、データに基づいた意思決定を可能にすることを強調します。特に、「100％の信頼性は不可能であり、追求すべきでもない」という現実的なアプローチは、多くの経営者が持つ「完璧を目指すべき」とい考えに対する重要な反論となります。法務チームに対しては、SLOが法的リスクの定量化と管理に役立つことを説明します。特に、SLAとSLOの違いを明確に説明し、SLOがより現実的で管理可能な内部目標であることを強調することが重要です。技術的な観点からは、SLOの測定と可視化のためのインフラストラクチャの構築が重要な課題となります。具体的には、以下のような技術スタックの活用が考えられます。Prometheusを使用してSLIメトリクスを収集する。Grafanaを使用してSLOとエラーバジェットの状況をリアルタイムで可視化する。Alertmanagerを設定し、エラーバジェットのバーンレートに応じたアラートを発行する。カスタムのKubernetes Operatorを開発し、エラーバジェットの状況に応じて自動的にデプロイメントを制御する。OpenTelemetryを活用して、分散システム全体でのエンドツーエンドのトレーシングを実現する。これらの技術を効果的に組み合わせることで、SLOの測定と管理を自動化し、リアルタイムでの意思決定を支援することができます。しかし、技術的な実装以上に重要なのは、SLOアプローチを組織の日常的な運用とビジネス意思決定プロセスに深く組み込むことです。例えば、四半期ごとの事業計画策定時にSLOの状況をレビューし、今後の開発方針やリソース配分の決定に活用するといった取り組みが考えられます。また、SLOアプローチの導入は、組織の文化を「障害を責める」文化から「学習と改善」の文化へと変革する機会でもあります。エラーバジェットの概念は、一定レベルの障害を許容することで、より積極的な実験と学習を促進します。これを組織文化として定着させるためには、以下のような取り組みが効果的ですポストモーテム（障害事後分析）を非難の場ではなく習の機会として位置づける。エラーバジェットを使い切った際の対応を、単なるペナルティではなく、システム改善のための集中期間として捉える。イノベーションとリスクテイキングを奨励し、エラーバジェット内での「失敗」を許容する文化を醸成する。SLOの達成状況を個人やチームの評価指標として使用するのではなく、組織全体の改善指標として活用する。これらの文化的側面は、技術的な実装と同等、あるいはそれ以上に重要です。なぜなら、組織文化がSLOアプローチを支持しない限り、その効果を最大限に発揮することはできないからです。本書で強調する「最初のエラーバジェット超過時の対応」の重要性も、特筆に値します。この最初の事例が、組織がSLOアプローチをどれだけ真剣に捉えているかを示す重要な指標となります。したがって、この最初の事例に対する対応を慎重に計画し、組織全体で共有することが重要です。例えば、最初のエラーバジェット超過時には以下のようなアプローチが考えられます：エグゼクティブレベルを含む全社的なミーティングを開催し、状況を共有する。エラーバジェットポリシーに基づく対応（例：機能フリーズ）を厳格に実施する。この期間中の改善活動とその成果を詳細に記録し、組織全体で共有する。この経験から学んだことを基に、SLOとエラーバジェットポリシーを見直し、必要に応じて調整する。これらの取り組みを通じて、SLOアプローチが単なる技術的な指標ではなく、組織全体の運営方針に深く組み込まれたものであることを示すことができます。最後に、本書が提案する段階的なアプローチと定期的な見直しの重要性を強調しておきたいと思います。SLOの導入は一朝一夕には実現できません。小規模なパイロットプロジェクトから始め、徐々に範囲を拡大していくアプローチが、多くの場合効果的です。また、初期のSLO設定が最適でない可能性も高いため、定期的（例えば四半期ごと）にSLOを見直し、必要に応じて調整することが重要です。このような継続的な改善プロセスを通じて、SLOアプローチは組織に深く根付き、長期的な価値を生み出すことができるようになります。SREとして、この継続的な改善プロセスをリードし、技術的な実装と組織文化の変革の両面からSLOアプローチの成功を支援することが、我々の重要な役割となるでしょう。SLOの導入は、単なる技術的な変更以上の意味を持ちます。それは、組織全体の運営方針とビジネス意思決定プロセスを本格的に変える可能性を秘めています。この変革を成功させるためには、技術的なスキルとビジネス感覚の両方を持ち合わせ、組織全体をリードしていく能力が必要となります。この章で学んだアプローチを実践し、組織全体のアラインメントを図りながらSLOを導入することで、より信頼性の高いシステムの構築と、より効果的な組織運営が実現できると確信しています。同時に、この過程は継続的な学習と改善の機会でもあります。新しい技術や方法論の登場、ビジネス環境の変化に応じて、常にアプローチを見直し、適応していく姿勢が重要です。SLOの導入は、技術的な挑戦であると同時に、組織文化の変革という大きな挑戦でもあります。しかし、この挑戦を乗り越えることで、組織はより強靭で適応力の高いものとなり、急速に変化する技術環境ビジネス環境において、持続的な成功を収めることができるでしょう。SREとして、この変革の最前線に立ち、技術と組織の両面からリーダーシップを発揮することが、我々に求められている重要な役割なのです。Chapter 7. Measuring SLIs and SLOs第7章「Measuring SLIs and SLOs」は、Service Level Indicators (SLIs)とService Level Objectives (SLOs)の実装と測定に関する深い洞察を提供しています。本章は、SLOの実装が単なる技術的な作業ではなく、組織全体の運用方針と密接に関連する重要な取り組みであることを強調しています。組織が変わる――行き詰まりから一歩抜け出す対話の方法２ on ２作者:宇田川 元一ダイヤモンド社Amazon章の冒頭で、本書では「It's one thing to understand the philosophy of what a good SLI for a service might be, but it's another thing entirely to actually understand how to implement and measure it.」と述べています。この言葉は、SLIとSLOの理論と実践の間には大きなギャップが存在することを端的に表現しており、SREとしての私の経験と深く共鳴しました。理想的なSLIを定義することは比較的容易ですが、それを実際のシステムで正確に測定することは多くの技術的課題を伴います。本書では、SLOの実装における6つの設計目標を提示しています：柔軟なターゲット、テスト可能なターゲット、鮮度、コスト、信頼性、組織的制約。これらの目標は、SLO実装の成功を左右する重要な要素であり、SREとして常に意識すべき点だと感じました。特に、「Flexible Targets」の重要性は印象的でした。本書では、SLOが時間とともに進化する必要があることを強調し、人間のオペレーターがコード変更やソフトウェアの再デプロイなしにSLOのパラメータを調整できることの重要性を指摘しています。この柔軟性は、急速に変化するビジネ環境や技術環境において重要です。技術的な観点から特に興味深かったのは、Time Series Database (TSDB)と構造化イベントデータベース（ログシステム）の比較です。本書では、これらの異なるアプローチの長所と短所を詳細に分析しています。例えば、TSDBは高スループットのシステムに適していますが、柔軟性に欠ける場合があります。一方、構造化イベントデータベースは柔軟性が高いものの、コストが線形に増加する傾向があります。この分析は、SLO実装の技術選択において有用な指針となります。本書が提示するTSDBにおける統計分布のサポートに関する説明は、特に印象的でした。パーセンタイルベースのSLOを実装する際、TSDBが提供する分布データ型の機能が重要になります。本書では、「Statistical distributions are incredibly important when implementing SLOs with a TSDB: per our design goals of flexible targets and testable targets, durably stored time series distributions allow us to measure P95 latency one day and P99 the next without changing code, changing configuration, or losing time series history.」と述べています。この柔軟性は、SLOの継続的な改善と調整において重要です。本書では、一般的なSLO実装パターンとして、レイテンシに敏感なリクエスト処理、低遅延・高スループットのバッチ処理、モバイル・Webクライアントの3つを挙げています。これらのパターンの解説は、実際のシステム設計において参考になりました。特に、モバイル・Webクライアントのパフォーマンス測定に関する考察は、エンドユーザー視点のSLOの重要性を再認識させられました。技術的な詳細に関しては、本書がTSDBにおけるヒストグラム実装について詳細に説明している点が有用でした。例えば、バケット化されたデータを用いてパーセンタイルを近似する方法の説明は、実際のSLO実装において直接適用可能な知見です。また、Dunning and Ertlのt-digestアルゴリズムへの言及は、より高度なSLO実装を検討する上で参考になりました。分散トレーシングとSLOの統合に関する本書の考察も興味深いものでした。「Historically, distributed tracing was thought of as its own \"product\" with valuable but highly specialized use cases, mostly around performance analysis and distributed debugging. Really, though, distributed traces are just a data source that can be applied to a variety of problems, and SLIs and SLOs are well qualified to benefit from distributed tracing data and technology.」この視点は、分散システムにおけるSLO実装の新たな可能性を示唆しており、今後のSRE実践において重要な指針となると感じました。本書では、SLIとSLOの実装が単なる技術的な問題ではなく、組織文化の変革を伴うものであることを強調しています。特に、SLIとSLOの発見可能性（Discoverability）の重要性を指摘している点は印象的でした。SLOアプローチの効果を最大化するためには、SLIとSLOが組織全体で容易に発見され、理解されることが不可欠です。この点は、SREとしての私たちの役割が単なる技術的な実装を超えて、組織全体のアラインメントを促進する重要な位置にあることを示唆しています。この章から得られる重要な教訓は、SLIとSLOの実装が複雑な多段階の計算を伴う作業であり、様々なトレードオフを慎重に検討する必要があるということです。本書では、「At the end of the day, most useful SLIs and SLO measurements are complex, multistage computations, and like any such computations, their implementation involves trade-offs and conflicting goals that must be held in tension.」と述べています。この認識は、SLO実装の難しさと同時に、その重要性を端的に表現しています。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：組織の現状のインフラストラクチャ（TSDB、ログシステム）を評価し、SLO実装の6つの設計目標に照らし合わせて適合性を検討する。一般的なSLO実装パターン（レイテンシに敏感なリクエスト処理、低遅延・高スループットのバッチ処理、モバイル・Webクライアント）を参考に、自組織のシステムに適したSLO実装戦略を策定する。TSDBを使用する場合、統計分布のサポートを重視し、必要に応じてカスタムの実装（例：バケット化されたヒストグラム）を検討する。構造化イベントデータベースを使用する場合、コストと鮮度のバランスを慎重に評価し、高スループットシステムでの使用には注意を払う。分散トレーシングシステムとSLOの統合を検討し、より詳細なパフォーマンス分析と問題解決を可能にする。SLIとSLOの発見可能性を高めるため、組織内での文書化と共有のプロセスを確立する。また、分散トレーシングとSLOの統合に関しては、OpenTelemetryなどのオープンソースフレームワークを活用することで、より効果的なSLO実装が可能になります。例えば、OpenTelemetryのSpanデータを利用して、サービス間の依存関係を考慮したSLOを実装することができます。SLIとSLOの発見可能性を高めるためには、組織内のサービスカタログやWikiシステムとの統合が効果的です。例えば、各サービスのドキュメントページにSLIとSLOの定義を明記し現在の状態を動的に表示するダッシュボードへのリンクを提供するなど、技術的な実装と組織的なプロセスを組み合わせたアプローチが考えられます。この章を読んで、SLIとSLOの実装は、単なる技術的な課題ではなく、組織全体のアラインメントと継続的な改善プロセスの中核を成すものです。特に、本書が強調する柔軟性とテスト可能性の重要性は、急速に変化するビジネス環境において重要です。同時に、コストと信頼性のバランスを取ることの難しさも再認識しました。高スループットのシステムでSLOを実装する際、TSDBと構造化イベントデータベースのどちらを選択するか、あるいは両者をどのように組み合わせるかは、慎重に検討する必要があります。この選択は、組織の規模、技術スタック予算など、様々な要因に依存します。本書が提案する6つの設計目標（柔軟なターゲット、テスト可能なターゲット、鮮度、コスト、信頼性、組織的制約）は、SLO実装プロジェクトの評価フレームワークとして有用です。これらの目標を常に意識しながら設計と実装を進めることで、より効果的なSLOシステムを構築できると確信しています。総括すると、この章はSLIとSLOの測定に関する包括的かつ実践的なガイドを提供しています。本書の豊富な経験に基づく洞察は、SLO実装の複雑さと重要性を明確に示しています。SREとして、この章から学んだアプローチを実践することで、より効果的なSLO実装が可能になり、結果として組織全体のパフォーマンス向上につながると確信しています。同時に、SLOの実装は継続的な学習と改善のプロセスであることを忘れてはいけません。技術の進化や組織の変化に応じて、常にアプローチを見直し、適応していく姿勢が重要です。特に、分散トレーシングとの統合やAIを活用したSLO予測など、新しい技術の活用可能性に注目していく必要があります。今後の課題としては、SLOデータを活用した予測分析の実装、マイクロサービスアーキテクチャにおけるEnd-to-EndのSLO管理、そしてビジネスKPIとSLOの統合などが考えられます。これらの課題に取り組むことで、SREの実践はさらに進化し、より効果的にビジネス価値を創出できるようになるでしょう。最後に、本書の「SLIとSLOの実装は複雑な多段階の計算であり、様々なトレードオフを伴う」という指摘は重要です。この認識を持ちつつ、組織の特性に合わせた最適なSLO実装を追求していくことが、SREとしての私たち重要な役割だと感じました。Table 7-1. An example simple TSDB entry より引用Table 7-2. A simple way to start bucketing data より引用Table 7-3. Implementing a real histogram より引用これらの図は、TSDBを使用したSLO実装の具体的な方法を示しており、実際のシステム設計において有用です。特に、Figure 7.3のヒストグラム実装の例は、パーセンタイルベースSLOを実装する際の具体的な指針となります。SLIとSLOの測定は、SREの実践において中心的な役割を果たすものです。この章で学んだ概念と手法を、日々の業務に積極的に取り入れていくことで、より信頼性の高いシステムの構築と、より効果的な組織運営に貢献できると確信しています。同時に、SLIとSLOの概念は常に進化し続けるものであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。Chapter 8. SLO Monitoring and Alerting第8章「SLO Monitoring and Alerting」は、SLO（Service Level Objectives）に基づくモニタリングとアラートの実践的な実装について深く掘り下げています。本書では、従来のしきい値ベースのアラートの問題点を指摘し、SLOアラートがいかにそれらの問題を解決し、より効果的なシステム用を可能にするかを詳細に解説しています。pyrraのようなSLO の管理、エラー バジェットの計算、記録およびアラート ルールの作成に役立つツールもあります。他にもGrafanaでもいくつの機能があるのでおすすめです。learning.Oreilly.com本章の冒頭で、本書では「SLO alerting really is one of the most promising developments in the management of production systems today. It promises to get rid of a lot of the chaos, the noise, and the sheer uselessness of conventional alerting that teams experience, and replace them with something significantly more maintainable.」と述べています。この言葉は、SLOアラートの重要性と可能性を端的に表現しており、SREとしての私の経験と深く共鳴しました。従来のアラート手法の限界を日々感じている中で、SLOアラートが提供する新しいアプローチに大きな期待を抱きました。本書では、従来のしきい値ベースのアラートの問題点を詳細に分析しています。印象的だったのは、以下の点です：しきい値が時間とともに適切でなくなる問題ユーザー体験を直接反映していない指標への依存コンテキストの喪失アラート疲れとウォーフォグ（戦争の霧）効果これらの問題点は、SREとしての私の経験とも一致しており、共感できるものでした。「Human responses to alerts gradually decay in energy over time.」という指摘は重要です。アラート疲れは、運用チームの効率と対応品質を低下させる大きな要因となっています。本書で提案するSLOアラートのアプローチは、これらの問題に対する解決策として魅力的です。エラーバジェットの消率に基づいたアラートの設定は、ユーザー体験に直結した指標を用いることで、より意味のあるアラートを実現できます。エラーバジェットの消費率の計算方法とそれに基づくアラートの設定に関する式としていかが紹介されています。Rate of error budget consumption = (observed errors per [time period or event count]) / (allowable errors per [time period or event count])また、本書が提案するローリングウィンドウの概念も有用です。短期的な問題（fast burn）と長期的な問題（slow burn）を区別して扱うアプローチは、実際のシステム運用において効果的だと感じました。本書では、SLOアラートの実装に関する具体的なガイダンスも提供しています。1時間で2％のエラーバジェット消費をページングアラートの閾値とし、3日間で10％の消費をチケット発行の閾値とする提案は、実践的で有用な指針です。しかし、本書でも指摘しているように、SLOアラートの実装には課題もあります。既存のシステム（ブラウンフィールド）へのSLOアラートの導入には、様々な困難が伴います。本書が提案する以下のアプローチは、この課題に対処する上で参考になりました：現状の人的影響を示す既存のアウテージフットプリントをレビューする新旧のシステムを並行して運用するこれらのアプローチは、組織内でのSLOアラート導入を推進する際に、有効な戦略だと感じました。本章の結論部分で、本書では以下の重要な推奨事項を提示しています：内属性（CPU使用率など）に基づくアラートから脱却することアラートシステムの技術的能力を確認すること可観測性（Observability）の重要性を認識することSLO設定の努力とコストを考慮することこれらの推奨事項は、SLOアラートを効果的に実装し、運用していく上で重要な指針となります。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：現在のアラート設定を見直し、内部属性に基づくアラートを特定するユーザー体験に直結するSLIを定義し、それに基づいたSLOを設定するエラーバジェットのバーンレートを計算し、それに基づいたアラートを設定する短期（fast burn）と長期（slow burn）のアラートを区別して設定するアラートシステムの能力を評価し、必要に応じてアップグレードを検討する可観測性を向上させるためのツールやプラクティスを導入するSLO設定とそれに伴うオペレーショナルロードについて、ステークホルダーと議論するこの章を読んで、SLOアラートの導入は、単なる技術的な変更ではなく、組織全体の運用方針とインシデント対応の在り方を根本的に変える可能性を秘めていることを理解しました。ユーザー体験を中心に据えたアプローチは、SREの本質的な目的である「ユーザーの満足度向上」に直結するものです。同時に、SLOアラートの導入には慎重なアプローチが必要であることも再認識しました。既存のシステムや組織文化との整合性を取ることの重要性を強く感じました。SREとして、技術的な実装だけでなく、組織全体のアラインメントを図りながら、段階的SLOアラートを導入していくアプローチが重要だと考えます。総括すると、この章はSLOアラートの実装に関する包括的かつ実践的なガイドを提供しています。本書の豊富な経験に基づく洞察は、SLOアラートの可能性と課題を明確に示しています。SREとして、この章から学んだアプローチを実践することで、より効果的なアラート体制を構築し、結果としてシステムの信頼性向上とユーザー満足度の向上につながると確信しています。同時に、SLOアラートの導入は継続的な学習と改善のプロセスであることを忘れてはいけません。技術の進化や組織の変化に応じて、常にアプローチを見直し、適応していく姿勢が重要です。最後に、本章の「SLO alerting promises to get rid of a lot of the chaos, the noise, and the sheer uselessness of conventional alerting that teams experience, and replace them with something significantly more maintainable.」という言葉を再度強調したいと思います。この視点を持ちつつ、組織の特性に合わせた最適なSLOアラートの実装を追求していくことが、SREとしての私たちの重要な役割だと感じました。Chapter 9. Probability and Statistics for SLIs and SLOs第9章「Probability and Statistics for SLIs and SLOs」は、SLO（Service Level Objectives）とSLI（Service Level Indicators）の設計と実装における確率と統計の重要性を深く掘り下げています。本章は、SREが直面する複雑な問題に対して、数学的なアプローチを用いてより精密な解決策を提供することを目的としています。learning.Oreilly.com章の冒頭で、本書は次のように述べています：「Reliability is expensive, and figuring out the amount of reliability you need is crucial for making the most of your resources.」この言葉は、SREの本質的な課題を端的に表現しています。適切な信頼性レベルを決定することは、リソースの最適化と顧客満足度のバランスを取る上で極めて重要です。本章は、主に二つの重要な問題に焦点を当てています：SLOの適切な設定方法と、SLIの正確な計算方法です。これらの問題は、新しいサービスの立ち上げや既存のサービスの改善において常に直面する課題です。例えば、依存関係を持つサービスのSLOをどのように設定するべきか、あるいは低頻度のイベントに対してSLIをどのように計算するべきかといった問題が取り上げられています。本書は、これらの問題に対処するために確率論と統計学の手法を導入しています。印象的だったのは、ベルヌーイ試行とポアソン分布の活用です。これらの概念は、サービスの可用性や信頼性を数学的にモデル化する上で有用です。例えば、本書は99.99％の可用性を持つサービスを例に挙げ、これをコイン投げの問題に置き換えて説明しています。この類推は、確率論の概念を直感的に理解する上で効果的です。本書は次のように述べています：「If you flipped a coin to decide some question, you'd probably expect the probability of heads or tails to be about 50％. Mathematically, we say that the coin has a bias of .5.」この説明は、複雑な確率の概念を身近な例を用いて分かりやすく解説しています。本章で興味深かったのは、期待値（Expected Value）の概念とその応用です。本書は、期待値が確率分布の重要な特性であり、プロセスの出力を予測する上で最良の推定値であることを説明しています。しかし、同時に本書は期待値の限界についても言及しています。「Unfortunately, despite its name, the expected value of a distribution is not always a good description of the values that would come out of sampling from it.」この指摘は、SREが数学的モデルを実際のシステムに適用する際に注意すべき重要な点を示唆しています。本書は、期待値の限界を補完するものとして中央値（Median）の概念を導入しています。中央値は、外れ値の影響を受けやすい分布において、より適切な代表値となる場合があります。この概念は、SLOの設定において重要です。例えば、応答時間のSLOを設定する際、極端に長い応答時間の影響を排除するために中央値を使用することが有効な場合があります。本章では、Maximum Likelihood Estimation（MLE）やMaximum a Posteriori（MAP）などの統計的推定手法についても詳細に説明されています。これらの手法は、限られたデータから信頼性の高い推定を行う上で重要です。本書は、これらの手法をSLIの計算に応用する方法を具体的に示しています。N年ぶりに聞いたベイズ推定の応用はとても良かったです。本書は、事前の知識や信念を数学的にモデル化し、新たな観測データと組み合わせて推定を行う方法を詳細に説明しています。この手法は、低頻度のイベントやデータが限られている状況でのSLI計算に有効です。本書は次のように述べています：「If we have good reason to think some values of p are more likely than others before we get any evidence, then this allows us to incorporate those prior beliefs into our calculations.」この考え方は、SREが過去の経験や専門知識をSLIの計算に反映させる方法を提供しており、実践的です。本章の後半では、キューイング理論とその応用について詳細な説明がなされています。本書は、M/M/1キューやM/M/cキューなどのモデルを用いて、システムのレイテンシーや処理能力を数学的に分析する方法を示しています。これらのモデルは、システムの性能予測や容量計画において有用です。本書は、キューイング理論の応用例として、バッチ処理システムの分析を挙げています。ここでは、ポアソン分布を用いてリクエストの到着パターンをモデル化し、システムの処理能力との関係を数学的に分析しています。この分析は、SLOの設定やシステムのスケーリング計画を立てる上で有用な洞察を提供しています。本章の結論部分で、本書は次のように述べています：「The power of thinking in a probabilistic and statistical manner is that it allows verification of the gut feel that most team members will have developed around the behavior of the system.」この言葉は、本章全体のメッセージを端的に表現しています。確率と統計の手法は、SREの経験や直感を数学的に検証し、より信頼性の高い意思決定を行うための強力なツールとなります。Figure 9-11. The binomial distribution with p = .9999, n = 10 より引用Figure 9-11では、高い可用性（99.99％）を持つシステムのパフォーマンスを示すヒストグラムが提示されています。この図は、極めて高い信頼性を持つシステムにおいても、わずかながら失敗が発生する可能性があることを視覚的に示しており、完璧な信頼性が実現不可能であることを明確に表現しています。Figure 9-29. Mean latency as   approaches  —as the average arrival time comes closer to the average service time, the latency grows severely より引用Figure 9-30. The 95th-percentile latency より引用Figure 9-29と9-30は、システムのUtilizationとレイテンシーの関係を示すグラフです。これらの図は、システムの利用率が増加するにつれて、レイテンシーが非線形に上昇することを明確に示しています。この関係の理解は、適切なキャパシティプランニングとSLO設定において極めて重要です。本章から得られる重要な教訓は、SLOとSLIの設計と実装において、確率と統計の手法が強力なツールとなるということです。これらの手法は、直感的な判断を数学的に裏付け、より精密で信頼性の高い意思決定を可能にします。同時に、本章は数学的モデルの限界についても明確に指摘しています。本書は次のように警告しています：「While models are helpful, they cannot be completely correct. This is exactly why they are models.」この認識は、SREが数学的モデルを実際のシステムに適用する際に常に念頭に置くべき重要な点です。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：SLOの設定において、単純な平均値だけでなく、分布の特性（期待値、中央値、パーセンタイル）を考慮に入れる。システムのパフォーマンスを収集し、適切な確率分布（例：ポアソン分布、指数分布）でモデル化する。ベイズ推定を用いて、過去の経験や専門知識をSLIの計算に反映させる。キューイング理論を活用して、システムの容量計画やスケーリング戦略を数学的に裏付ける。いくつかの手法を用いて、複雑なシステムの振る舞いを予測し、適切なSLOを設定する。統計的手法を用いてSLIの信頼区間を計算し、測定の不確実性を定量化する。これらのアプローチを実践することで、より精密で信頼性の高いSLOとSLIの設計と実装が可能になります。技術的な観点からは、本章で紹介された数学的手法を実装するためのツールやライブラリの活用が重要です。例えば、PythonのSciPyライブラリは、本章で紹介された確率分布や統計的推定手法を容易に実装できる機能を提供しています。また、Prometheusなどの監視ツールと組み合わせることで、リアルタイムでSLIを計算し、統計的な分析を行うことが可能になります。さらに、機械学習の手法を活用して、より高度なSLO予測モデルを構築することも検討に値します。例えば、時系列予測モデルを用いてSLIの将来的な傾向を予測し、プロアクティブなシステム調整を行うことが可能になります。本章を読んで、私はSREの役割がより数学的・分析的になりつつあることを強く感じました。単純なルールベースの監視やアラートから、確率論と統計学に基づいた精密な分析へとシフトしていく傾向は、システムの複雑化と規模の拡大に伴う必然的な流れだと考えられます。同時に、この数学的アプローチの導入には課題もあります。組織全体でこれらの概念を理解し、実践に移すためには、継続的な教育と文化の変革が必要です。SREとして、これらの数学的概念を非技術者を含む組織全体に分かりやすく説明し、その価値を示していくことが重要な役割となります。総括すると、この章は確率と統計の手法をSLOとSLIの設計と実装に適用する具体的な方法を提供しています。これらの手法は、SREが直面する複雑な問題に対して、より精密で信頼性の高い解決策を提供する可能性を秘めています。同時に、数学的モデルの限界を認識し、実際のシステムの振る舞いとのバランスを取ることの重要性も強調されています。SREとして、この章から学んだアプローチを実践することで、より効果的なSLOとSLIの設計が可能になり、結果としてシステムの信頼性向上とユーザー満足度の向上につながると確信しています。同時に、これらの数学的手法の適用は継続的な学習と改善のプロセスであることを忘れてはいけません。新しい技術や方法論の登場に応じて、常にアプローチを見直し、適応していく姿勢が重要です。最後に、本章の「The power of thinking in a probabilistic and statistical manner is that it allows verification of the gut feel that most team members will have developed around the behavior of the system.」という言葉を再度強調したいと思います。この視点を持ちつつ、直感と数学的分析のバランスを取りながら、より精密で信頼性の高いシステム運用を追求していくことが、SREとしての私たちの重要な役割だと感じました。この章で学んだ確率と統計の手法は、SREの実践において中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いシテムの構築と、より効果的な組織運営に貢献できると確信しています。同時に、これらの手法の適用には慎重さと継続的な学習が必要であることも忘れてはいけません。新しい技術や方法論の登場、そしてビジネス要件の変化に応じて、常にアプローチを見直し、適応していく必要があります。SREとして、この章から得られた知見を組織全体に浸透させ、データ駆動の意思決定文化を醸成していくことが重要です。確率と統計に基づいたアプローチは、単にシステムの信頼性を向上させるだけでなく、組織全体の意思決定プロセスを改善し、より効率的なリソース配分を可能にします。今後の課題としては、これらの数学的手法をより使いやすく、理解しやすいツールやフレームワークに落とし込んでいくことが挙げられます。また、機械学習や人工知能の進歩に伴い、より高度な予測モデルや最適化アルゴリズムを活用した次世代のSLO/SLI管理システムの開発も期待されます。この章で学んだ確率と統計の手法は、SREの実践において強力な武器となります。これらの手法を適切に活用することで、より精密で信頼性の高いシステム運用が可能になり、結果としてユーザー満足度の向上とビジネス目標の達成につながると確信しています。SREとして、常に学び続け、新しい知識と技術を積極的に取り入れながら、組織とシステムの継続的な改善に貢献していくことが重要です。Chapter 10. Architecting for Reliability第10章「Architecting for Reliability」は、SLO（Service Level Objectives）を念頭に置いたシステム設計の重要性と方法論について深く掘り下げています。本章は、システムアーキテクトがSLOを考慮しながら、いかに信頼性の高いシステムを設計できるかを詳細に解説しています。SRE になるために役立つシステム エンジニアリングのシラバスのご紹介でもこちらの章を紹介しています。cloud.google.com本章の冒頭で、著者は次のように述べています：「This chapter focuses on designing systems from the ground up with SLOs in mind.」この言葉は、SLOがシステム設計の初期段階から考慮されるべき重要な要素であることを強調しています。この視点は重要だと感じました。多くの場合、SLOは既存のシステムに後付けで適用されがちですが、設計段階からSLOを考慮することで、より効果的で信頼性の高いシステムを構築できます。ソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal FordオライリージャパンAmazon本章で特に印象的だったのは、ユーザージャーニーの重要性についての言及です。著者は次のように述べています：「User journeys, which represent the same concept as SLIs (see Chapter 3), help us understand these interactions, as well as the implications for the user when the system does not meet its objectives.」この視点は、技術的な指標だけでなく、ユーザー体験を中心に据えたシステム設計の重要性を強調しています。SREとして、この考え方は重要です。私たちは往々にして技術的な指標にとらわれがちですが、最終的にはユーザーの満足度こそが最も重要な指標であることを忘れてはいけません。本章では、システム設計における様々な考慮事項について詳細に解説しています。ハードウェアの選択がシステムのSLOに与える影響について、興味深い分析がなされています。例えば、著者は次のように述べています：「A system cannot offer an SLO greater than any of its dependencies' SLOs.」この指摘は、システム全体のSLOを考える上で重要です。依存関係にあるコンポーネントのSLOを理解し、それらを考慮してシステム全体のSLOを設定することの重要性を再認識させられました。ハードウェアの選択に関する具体的な例として、本章では異なるストレージオプションの比較が示されています。Figure 10.1では、ハードディスク、SSD、RAMの読み取りレイテンシとIOPSが比較されており、これらの選択がSLIにどのような影響を与えるかが明確に示されています。この比較表は、システム設計の初期段階で重要な意思決定を行う際の貴重な指針となります。本章では、モノリスかマイクロサービスかいう議論についても言及しています。著者は、サービス指向アーキテクチャ（SOA）の利点を強調しつつ、次のように述べています：「An open-ended system—one that allows for extension and change—is superior to a closed-ended system.」この視点は、急速に変化するビジネス環境において重要です。SREとして、システムの拡張性と変更の容易さは、長期的な運用性と信頼性を確保する上で不可欠な要素だと感じました。システムの故障モードの予測と対応についても、本章では詳細に解説されています。著者は次のように述べています：「When designing systems it's important to anticipate failure modes—that is, the problems that a system may realistically encounter and that it can respond to in order to maintain its SLOs.」この考え方は、SREの核心に触れるものです。システムの信頼性を高めるためは、単に正常時の動作を設計するだけでなく、様々な異常状態を予測し、それらに適切に対応できるようにシステムを設計することが重要です。本章では、リクエストの種類（同期、非同期、バッチ）に応じた設計上の考慮事項についても言及しています。これらの異なるタイプのリクエストに対して適切に対応することで、システム全体のパフォーマンスと信頼性を向上させることができます。バッチ処理に関する次の指摘は印象的でした：「Batch processing of requests typically happens because their results are not time-sensitive or in the critical path, yet SLIs still play an important role: they provide measurements for KPIs such as the duration of each batch process, meaning how long the process takes to execute, and the number of requests processed in each batch.」この視点は、非同期処理やバッチ処理のSLOを設定す際の重要な指針となります。システムの定量的分析に関する部分も興味深いものでした。著者は、システムの可用性を構成要素の可用性の組み合わせとして表現できることを示しています。この考え方は、複雑なシステムの信頼性を理解し、改善する上で有用です。1 - SLO = ((MTTD + MTTM) / MTBF) × IMPACTこの式は、システムの信頼性を人間の対応時間と関連付けて表現しており、SREの実務に直接適用可能な洞察を提供しています。本章の後半では、システムの依存関係の重要性について詳しく解説されています。著者は次のように述べています：「Once your product and engineering perspectives agree, you can develop SLOs, and we can turn back to \"the system.\" Thus far we have designed a system that solves our problem as designed, without building any nonessential software.」この視点は、システム設計において不要な複雑さを避け、本質的な問題解決に焦点を当てることの重要性を強調しています。Figure 10.5では、システムの境界を理解することの重要性が視覚的に示されています。この図は、システム内の「ブラックボックス」（サードパーティのサービスやクラウドベースのシステムなど）を識別し、それらがシステム全体の信頼性にどのように影響するかを理解することの重要性を強調しています。本章から得られる重要な教訓は、SLOを考慮したシステム設計が、単なる技術的な演習ではなく、ユーザー体験と密接に結びついた重要なプロセスであるということです。著者は次のように述べています：「In order to have effective SLOs, we need to reflect the user experience, not only system performance.」この視点は、SREの実践において重要です。技術的な観点からは、本章で紹介されたシステム設計の方法論は実践的で有用です。ユーザージャーニーに基づいてSLIとSLOを設定し、それらを元にシステムアーキテクチャを決定していくアプローチは、多くのSREプロジェクトに適用可能です。また、本章で強調されている「グレースフルデグラデーション」の概念も重要です。著者は次のように述べています：「Given congestion on the internal network between application servers and the storage component, a conscious architectural decision will, for example, allow our image-serving system to degrade such that thumbnail pages continue to serve within 250 ms, even though loading the detail view might take longer.」この考え方は、システムの一部に問題が発生した場合でも、全体としての機能を維持し、ユーザー体験への影響を最小に抑えるための重要な設計原則です。本章を読んで、システムアーキテクトとしての視点を持ちつつ、ユーザー体験とビジネス目標を常に意識しながらシステムを設計することの重要性を強く感じました。同時に、SLOを単なる数値目標ではなく、システム設計の指針として活用することの有効性も再認識しました。総括すると、この章はSLOを考慮したシステム設計に関する包括的かつ実践的なガイドを提供しています。ユーザージャーニーの重要性、ハードウェア選択の影響、マイクロサービスアーキテクチャの利点、故障モードの予測と対応、異なるタイプのリクエストへの対応、システムの定量的分析、依存関係の理解など、システム設計の重要な側面を網羅しています。SREとして、この章か学んだアプローチを実践することで、より信頼性が高く、ユーザー体験を重視したシステムの設計が可能になると確信しています。設計の初期段階からSLOを考慮し、ユーザージャーニーに基づいてシステムアーキテクチャを決定していくアプローチは、多くのプロジェクトで有効に活用できるでしょう。同時に、本章で強調されているシステムの依存関係の理解と管理の重要性も、実務上重要です。クラウドサービスやサードパーティのAPIに依存する現代のシステム開発において、これらの「ブラックボックス」がシステム全体のSLOにどのような影響を与えるかを理解し、適切に管理することは不可欠です。今後の課題としては、急速に進化するクラウド技術や新しいアーキテクチャパターン（例：サーバーレスアーキテクチャ）にして、本章で紹介されたアプローチをどのように適用していくかを検討する必要があります。また、機械学習やAIを活用したシステムの設計において、SLOをどのように定義し、管理していくかも重要な研究テーマとなるでしょう。最後に、本章の「SLOs as a Result of System SLIs」というセクションで述べられている「The SLOs for a system follow from the SLIs we have identified, although not necessarily directly: in order to have effective SLOs, we need to reflect the user experience, not only system performance.」という言葉を再度強調したいと思います。この視点を持ちつつ、技術的な指標とユーザー体験のバランスを取りながら、より効果的なシステム設計を追求していくことが、SREとしての私たちの重要な役割だと感じました。本章で学んだSLOを考慮したシステム設計のアプローチは、SREの実践におい中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いシステムの構築と、より効果的な組織運営に貢献できると確信しています。同時に、システム設計の方法論は常に進化し続けるものであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。SREとして、この章から得られた知見を組織全体に浸透させ、SLOを中心としたシステム設計の文化を醸成していくことが重要です。ユーザー体験を重視し、信頼性と性能のバランスを取りながら、柔軟で拡張性の高いシステムを設計することで、長期的にはユーザー満足度の向上とビジネス目標の達成につながると確信しています。Chapter 11. Data Reliability第11章「Data Reliability」は、データサービスの信頼性に焦点を当て、SLO（Service Level Objectives）とSLI（Service Level Indicators）の設定と運用について深く掘り下げています。本章は、データの信頼性が他のサービスの信頼性とどのように異なるか、そしてデータサービスに特有のSLOをどのように設定し、測定すべきかを詳細に解説しています。syu-m-5151.hatenablog.com章の冒頭で、著者は次のように述べています：「The goal of this chapter is to explore what makes SLOs for data services different from SLOs for other services.」データの信頼性は、単なるシステムの可用性や性能だけでなく、データそのものの品質や整合性にもく関わるため、独自の考慮事項が必要になります。本章で特に印象的だったのは、データの信頼性を13の属性に分類し、それぞれについて詳細に解説している点です。これらの属性は、データプロパティ（7つ）とデータアプリケーションプロパティ（6つ）に分けられています。データプロパティには以下が含まれます：1. Freshness（鮮度）2. Completeness（完全性）3. Consistency（一貫性）4. Accuracy（厳密性）5. Validity（妥当性）6. Integrity（整合性）7. Durability（耐久性）データアプリケーションプロパティには以下が含まれます：1. Security（セキュリティ）2. Availability（可用性）3. Scalability（スケーラビリティ）4. Performance（性能）5. Resilience（回復力）6. Robustness（堅牢性）これらの属性の詳細な解説は、データサービスの信頼性を多面的に捉える上で常に有用です。各属性について具体的なSLOの例が提示されている点が印象的でした。例えば、Freshnessに関するSLOの例として、以下が挙げられています：「Example SLO: 97％ of data is available in the dashboard tool within 15 minutes of an event occurring.」このような具体例は、実際のSLO設定の際の重要な指針となります。 Figure 11-1. Data properties and their relationships to each other より引用本章では、これらの属性が相互に関連し、時には相反する関係にあることも指摘されています。Figure 11-1では、各属性間の関係が視覚的に示されており、データサービスの設計における複雑さと、トレードオフの必要性を明確に現しています。技術的な観点から特に興味深かったのは、各属性に対するSLOの測定方法と、それらがシステム設計にどのように影響するかについての解説です。例えば、Durabilityに関しては、クラウドプロバイダーが提供する99.999999999％（11ナイン）という高い耐久性が紹介されています。これは、100万のオブジェクトを保存した場合、10万年に1回のペースでオブジェクトを失うことを意味します。このような極端に高い信頼性目標が、データサービスにおいて重要視される理由について、著者は次のように述べています：「Data-related properties have a different calculus of risk. Properties like durability, consistency, and integrity must be considered in a unique light, because once lost they are difficult to regain. Recovering from a true durability failure can be impossible, and the effects of these failures will persist forward indefinitely into your users' future.」この指摘は、データサービスの信頼性が他のサービスとは根本的に異なる性質を持つことを明確に示しています。一度失われたデータを回復することの困難さ、そしてそれが引き起こす長期的な影響を考慮すると、データサービスにおいては極めて高い信頼性目標を設定することが正当化されます。本章では、SLOの設定だけでなく、それらを達成するためのシステム設計についても言及しています。Figure 11-1では、各データ属性とシステム設計の考慮事項（時間、アクセス、冗長性、サンプリング、可変性、分散）との関係が示されています。著者は、データサービスの信頼性を考える上で、データの系譜（Data Lineage）の重要性も強調しています。データが複数のサービスを通過する過程で、各サービスの信頼性がどのように全体の信頼性に影響するかを理解することの重要性が指摘されています。「Data can flow through an application like a river, which is probably why there are so many water-related metaphors in the space (streams, pools, data lakes). As the process goes from one step to the next, we're moving downstream. Where in the process is our application's data? Who are the upstream producers/publishers? Do these sources have SLOs? Who are the downstream consumers/subscribers of this data? How will they use the data?」この視点は、複雑な分散システムにおけるデータの信頼性を考える上で重要です。上流のサービスのSLOが下流のサービスのSLOに直接影響を与えることを理解し、システム全体としての信頼性を設計することの重要性を再認識させられました。本章の結論部分で、著者は次のように述べています：「Modern organizations are often obsessed with \"data quality.\" They hire tons of engineers to think about it. But quality is ultimately subjective unless you can define and measure it, and it's inextricably intertwined with the systems that collect, store, process, and produce our data. We must reframe these conversations, and use SLOs to provide a supporting framework of quantitative measurement to help define the mechanisms by which we provide users with reliable data.」この言葉は、データの信頼性を主観的な概念から客観的に測定可能なものへと転換する必要性を強調しています。SLOを用いてデータの信頼性を定量化することで、組織はより効果的にデータ品質を管理し、改善することができます。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：データサービスの各属性（Freshness, Completeness, Consistency など）について、具体的なSLOを設定し、それらを定期的に測定・評価する仕組みを構築する。データの系譜を明確に把握し、上流サービスのSLOが下流サービスのSLOにどのように影響するかを分析する。データの信頼性に関する各属性のトレードオフを理解し、ユーザーのニーズと技術的な制約のバランスを取りながら、適切なSLOを設定する。データの耐久性や整合性などの回復困難な属性に特に注意を払い、それらに対して極めて高い信頼性目標を設定する。SLOの測定結果を継続的にモニタリングし、システム設計の改善に活用する。技術的な観点からは、本章で紹介された各属性のSLO測定方法を実装するためのツールやフレームワークの開発が重要になります。例えば、データ鮮度（Freshness）を測定するためのタイムスタンプ管理システムや、データの完全性（Completeness）をチェックするための自動検証ツールなどが考えられます。また、本章で強調されているデータの系譜（Data Lineage）の管理は、特に重要な技術的課題です。複雑な分散システムにおいて、データの流れを追跡し、各段階でのSLOを管理するためには、高度なトレーシングシステムやメタデータ管理システムの実装が必要になるでしょう。この章を読んで、データサービスの信頼性は、単なるシステムの可用性や性能だけでなく、データそのものの品質や整合性にも深く関わることを強く認識しました。SREは、システムの運用だけでなく、データの品質管理にも深く関与し、ユーザーに信頼性の高いデータを提供するめの仕組みづくりに貢献する必要があります。同時に、データの信頼性を確保することの難しさも再認識しました。一度失われたデータの回復が困難であることを考えると、予防的なアプローチと、万が一の場合の回復メカニズムの両方を慎重に設計・実装する必要があります。総括すると、この章はデータサービスの信頼性に関する包括的かつ実践的なガイドを提供しています。13の属性に基づくアプローチは、データの信頼性を多面的に捉え、具体的なSLOの設定と測定方法を提示しています。また、データの系譜の重要性を強調することで、複雑な分散システムにおけるデータの信頼性管理の課題にも光を当てています。SREとして、この章から学んだアプローチを実践することで、より信頼性の高いデータサービスの設計と運用が可能になる確信しています。データの各属性に対する具体的なSLOの設定と、それらのトレードオフを考慮したシステム設計は、データサービスの品質向上に大きく貢献するでしょう。同時に、データの信頼性確保は継続的な取り組みであることを忘れてはいけません。技術の進化や新たなデータ利用形態の登場に応じて、常にアプローチを見直し、適応していく姿勢が重要です。最後に、本章の「We must reframe these conversations, and use SLOs to provide a supporting framework of quantitative measurement to help define the mechanisms by which we provide users with reliable data.」という言葉を再度強調したいと思います。この視点を持ちつつ、データの信頼性を客観的に測定・管理可能なものとし、ユーザーに真に価値のあるデータサービスを提供していくことが、SREとしての私たちの重要な役割だと感じました。この章で学んだデータ信頼性のアプローチは、SREの実践において中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いデータサービスの構築と、より効果的な組織運営に貢献できると確信しています。同時に、データ信頼性の確保は常に進化し続ける課題であり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。SREとして、この章から得られた知見を組織全体に浸透させ、データ中心の信頼性管理文化を醸成していくことが重要です。データの信頼性を定量的に管理することで、組織はより効果的にデータ品質を向上させ、ユーザーに価値あるサービスを提供することができます。実際に今後取り組む課題として、機械学習やAIを活用したデータサービスにおける信頼性の確保、プライバシーやデータ倫理の観点を含めたより包括的なデータ信頼性フレームワークの構築、そしてますます複雑化するデータエコシステムにおける効果的な信頼性管理手法の開発などが考えられます。これらの課題に取り組むことで、データサービスの信頼性はさらに向上し、ユーザーにとってより価値のあるサービスを提供できるようになるでしょう。Chapter 12. A Worked Example第12章「A Worked Example」は、SLO（Service Level Objectives）ベースのアプローチを実際のサービスに適用する具体的な例を提供しています。本章は、架空の会社「The Wiener Shirt-zel Clothing Company」を例に取り、複雑な多層サービスにSLOを適用する方法を詳細に解説しています。公開している資料だとIoTサービスにおけるSLIの設計とLUUPでの実践が良かったのでオススメです。 speakerdeck.com章の冒頭で、著者は次のように述べています：「While the other chapters in this part of the book have given you lots of detailed insight into specific aspects of an SLO-based approach to reliability, and Part I outlined and defined all of the concepts you need to get started, what we really haven't talked about yet is how all this might actually work for a multicomponent service—or how it might apply to an entire company or organization.」この言葉は、本章の目的が理論を実践に移す具体的な方法を示すことであることを明確にしています。実際のサービスにSLOを適用する際には、理論だけでは対処しきれない複雑な状況に直面することが多いからです。本章で特に印象的だったのは、サービスの成長に伴うアーキテクチャの変化とSLOの関係性についての解説です。著者は、単一のプログラマーのラップトップから始まったサービスが、どのように複雑な分散システムへと進化していったかを説明しています。Figure 12-3では、成長後のThe Wiener Shirt-zel Clothing Companyのアーキテクチャが示されており、Webアプリケーション、マイクロサービス、データベース、キャッシュ、CDN（Content Delivery Network）など、現代的なウェブサービスの典型的な構成要素が含まれています。この複雑なアーキテクチャに対して、著者は3つのユーザータイプ（外部顧客、内部サービス、内部ユーザー）に焦点を当て、それぞれのニーズに基づいたSLOの設定方法を解説しています。このアプローチはSLOが単なる技術的な指標ではなく、ユーザー体験に直結したものであるべきという本書の主張を実践的に示しています。例えば、外部顧客向けのウェブサイトのフロントページに関するSLOとして、著者は次のような例を挙げています：「99.9％ of responses to our website will return a 2xx, 3xx, or 4xx HTTP code within 2,000 ms.」この SLO は、ユーザー体験（ページの読み込み速度）と技術的な指標（HTTP ステータスコード）を巧みに組み合わせています。著者は、この SLO が月間約43分のダウンタイムを許容することを説明し、これが合理的なトレードオフであることを示しています。内部サービス間の依存関係に関するSLOの設定について、著者は支払い処理マイクロサービスを例に挙げ、外部決済サービスのSLAとの関係を詳細に解説しています。Table 12-1では、ベンダーSLAと内部サービスのSLOの組み合わせによる結果が示されており、複数のサービスの信頼性がどのように全体の信頼性に影響するかを明確に表現しています。この analysis は、SREとして依存関係のあるサービスのSLOを設定する際に参考になります。内部ユーザー向けのサービスに関するSLOの設定については、デスクトップアプリケーションと内部Wikiの例が挙げられています。特に印象的だったのは、デスクトップアプリケーションのようなネットワークサービスではないものに対するSLOの設定方法です。著者は次のように述べています：「Remember, SLOs are about thinking about your users—and those users are not always millions of people on the internet. Sometimes they're three people in a marketing department.」この視点は、SLOが適用できる範囲が想像以上に広いことを示唆しており、SREの実践において重要です。最後に、プラットフォームとしてのサービス（この場合はコンテナプラットフォーム）に対するSLOの設定方法が解説されています。著者は、コンテナの ephemeral な性質を考慮したSLOの設定方法を提案しており、これは複雑な分散システムにおけるSLOの設定の難しさと重要性を示しています。技術的な観点からは、本章で提示されたSLOの例とその設定理由が参考になります。特に、サービス間の依存関係を考慮したSLOの設定方法や、ユーザー体験を直接反映したSLIの選び方は、実際のサービス運用に直接適用できる知見です。また、本章では、SLOの設定が単なる数値目標の設定ではなく、ユーザーのニーズ、技術的な制約、ビジネス目標のバランスを取る複雑なプロセスであることが強調されています。著者は次のように述べています：「SLO-based approaches give you a way to find out whether users are happy or not, even if this example doesn't fit all of the traditional trappings of the general discussions about SLOs. Always remember that it's the philosophies behind these approaches that are the most important, not having the slickest technology to use to perform complicated math against statistically derived SLIs.」この言葉は、SLOの本質が技術的な指標ではなく、ユーザー満足度の向上にあることを再認識させてくれます。本章を読んで、SLOの設定は、単にシステムの技術的な側面を監視することではなく、ユーザー体験とビジネス目標を常に意識しながら、サービス全体の信頼性を管理することだと改めて認識しました。同時に、SLOの適用範囲が想像以上に広いことも学びました。ネットワークサービスだけでなく、デスクトップアプリケーションや内部向けツールなど、あらゆる種類のサービスにSLOを適用できる可能性があることを知り、SREの実践の幅が大きく広がる感覚を得ました。総括すると、この章はSLOベースのアプローチを実際のサービスに適用する具体的な方法を提供しています。複雑な多層サービスにおけるSLOの設定方法、サービス間の依存関係の考慮、異なるユーザータイプに対するSLOの設定など、実践的で有用な知見が盛り込まれています。SREとして、この章から学んだアプローチを実践することで、より効果的なSLOの設定と運用が可能になると確信しています。特に、ユーザージャーニーを中心に据えたSLIの選定と、それに基づくSLOの設定は、多くのプロジェクトで有効に活用できるでしょう。同時に、本章で強調されているSLOの柔軟と進化の必要性も、実務上重要です。サービスの成長に伴い、アーキテクチャや顧客のニーズは変化していきます。そのため、SLOも常に見直し、適応させていく必要があります。今後の課題としては、より複雑な分散システムにおけるEnd-to-EndのSLO管理、マイクロサービスアーキテクチャにおけるサービス間の依存関係を考慮したSLOの自動調整、そしてAIや機械学習を活用したより高度なSLO予測モデルの開発などが考えられます。これらの課題に取り組むことで、SREの実践はさらに進化し、より効果的にビジネス価値を創出できるようになるでしょう。最後に、本章の「A lot of this book has been abstract, since SLO-based approaches are mostly philosophical. You might use a lot of math and numbers to help you gather data, but it's ultimately about using this data to engage humans to make decisions.」という言葉を再度強調したいと思います。この視点を持ちつつ、SLOを単なる数値目標ではなく、ユーザー満足度向上とビジネス成功のための戦略的ツールとして活用していくことが、SREとしての私たちの重要な役割だと感じました。この章で学んだ具体的なSLO設定のアプローチは、SREの実践において中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いサービスの構築と、より効果的な組織運営に貢献できると確信しています。同時に、SLOの設定と運用は常に進化し続けるプロセスであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。SREとして、この章から得られた知見を組織全体に浸透させ、SLOを中心とした信頼性管理の文を醸成していくことが重要です。ユーザー体験を重視し、技術的な指標とビジネス目標のバランスを取りながら、継続的にサービスの信頼性を向上させていくことで、長期的にはユーザー満足度の向上とビジネス目標の達成につながると確信しています。Part III. SLO CulturePart IIIでは、SLO文化の構築と普及に焦点が当てられています。特に印象的だったのは、SLO Advocateの役割に関する章です。著者は、SLO導入の成功には技術的な実装以上のものが必要であり、組織文化の変革と深い理解が不可欠であることを強調しています。SLO Advocateの役割は、単なる技術的なエキスパートではなく、組織の変革者としての側面も持ちます。この役割を通じて、SREはより戦略的な立場に立ち、組織全体の信頼性文化の醸成に大きく貢献することができます。また、SLOの理解しやすさと発見可能性に関する章も有用でした。SLO定義文書の構造化、中央集中型のドキュメント管理、効果的なダッシュボードの設計など、SLOを組織全体で活用するための具体的な方法が詳細に解説されています。この部分から学んだ最も重要な教訓は、SLO文化の構築が継続的なプロセスであり、常に進化し続けるものだということです。技術の進化や組織の変化に応じて、SLOのアプローチも適応していく必要があります。SREとして、この継続的な改善プロセスをリードし、組織全体のアラインメントを図っていくことが重要です。Chapter 13. Building an SLO Culture第13章「Building an SLO Culture」は、SLO（Service Level Objectives）を組織文化に浸透させるための具体的な方法論を提示しています。本章は、SLOの技術的な実装だけでなく、組織全体でSLOを受け入れ、活用していくためのプロセスについて深く掘り下げています。 speakerdeck.com章の冒頭で、著者は次のように述べています：「It's one thing to understand and live by these principles yourself, but it's another to spread these ideas throughout your organization and get others working alongside you.」この言葉は、SLOの導入が単なる技術的な課題ではなく、組織文化の変革を伴う大きな挑戦であることを端的に表現しています。優れたSLOを設計しても、組織全体がそれを理解し、活用しなければ、その効果は限定的なものになってしまいます。本章で特に印象的だったのは、SLO文化の構築を段階的なプロセスとして捉えている点です。著者は以下の6つのステップを提示しています：賛同を得る（Get buy-in）SLO作業を優先する（Prioritize SLO work）SLOを実装する（Implement your SLOs）SLOを使用する（Use your SLOs）SLOを反復改善する（Iterate on your SLOs）他者にSLOの使用を提唱する（Advocate for others to use SLOs）このアプローチは、SLO導入の複雑さを認識しつつ、段階的に組織文化を変革していく方法を示しています。特に、最初のステップである「賛同を得る」ことの重要性が強調されている点が印象的でした。著者は次のように述べています：「Before anything can happen, people need to be in agreement about the value of SLOs. If your team doesn't value reliability, it's going to be hard for you to justify creating SLOs.」この指摘は、技術的な実装以前に、組織内でSLOの価値を共有することの重要性を強調しており、SREとして共感できる点でした。SLOの実装に関する部分で、著者は「Do it yourself」と「Assign it」の2つのアプローチを提示しています。これは、SLOの導入を推進する立場にある人間の役割について、重要な示唆を与えています。特に、「Do it yourself」アプローチについて、著者は次のように述べています：「Having read this book, you will likely be the most knowledgeable on the subject and the most driven to make the move to an SLO culture. Leading by example and making the work your priority will signal to others that you're committed to making this change.」この視点は、SREとしてSLO導入を推進する際の心構えとして重要だと感じました。SLOの使用に関する部分では、アラート、エラーバジェットの消費、余剰エラーバジェットの活用について詳細に解説されています。特に印象的だったのは、エラーバジェットの消費に関する以下の記述です：「If you find your applications are breaking SLOs and there's a lack of urgency to repair the situation, it might be a sign that you need to make some adjustments.」この指摘は、SLOが単なる数値目標ではなく、組織の優先順位を反映すべきものであることを強調しており、SLOの本質を理解する上で重要です。技術的な観点からは、本章ではSLOの実装や運用に関する具体的な方法論が提示されています。例えば、SLOドキュメントの作成、SLIの選定とモニタリングの実装、アラートの設定などについて、実践的なアドバイスが提供されています。これらの知見は、実際にSLOを導入する際に直接活用できる貴重な情報です。本章の結論部分で、著者は次のように述べています：「SLOs are a process, not a project. They won't stick overnight, but hopefully the content in this chapter has given you a better sense of how to circle back and iterate on these approaches until things begin to click.」この言葉は、SLO文化の構築が継続的な取り組みであることを強調しており、SREとしての長期的な視点の重要性を再認識させられました。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：組織内でSLOの価値を共有するためのワークショップや勉強会を定期的に開催する。小規模なプロジェクトからSLOの導入を始め、成功事例を作り出す。SLOの実装と運用のプロセスを文書化し、組織内で共有する。SLOの定期的な見直しと改善のサイクルを確立する。他のチームや部門にSLOの導入を提唱し、組織全体でのSLO文化の構築を目指す。技術的な観点からは、SLOの実装と運用を支援するツールやフレームワークの開発が重要になります。例えば、SLOドキュメントの管理システム、SLIデータの収集と分析のための基盤、エラーバジェットの計算と可視化のためのダッシュボードなどが考えられます。これらのツールを整備することで、SLO文化の定着をより効果的に支援できるでしょう。この章を読んで、SLOの導入は、単に技術的な指標を設定することではなく、組織全体の信頼性に対する考え方を変革することだと改めて認識しました。SREは、この文化変革の推進役として、技術的な知識だけでなく、組織内のコミュニケーションやチェンジマネジメントのスキルも求められることを強く感じました。総括すると、この章はSLO文化の構築に関する包括的かつ実践的なガイドを提供しています。SLOの技術的な側面だけでなく、組織文化の変革という大きな課題に正面から取り組んでり、SREにとって価値のある知見が盛り込まれています。SREとして、この章から学んだアプローチを実践することで、より効果的なSLO文化の構築が可能になると確信しています。特に、段階的なアプローチと継続的な改善の重要性は、大規模な組織変革を成功させる上で重要な指針となるでしょう。同時に、SLO文化の構築は長期的な取り組みであることを忘れてはいけません。技術の進化や組織の変化に応じて、常にアプローチを見直し、適応していく姿勢が重要です。最後に、本章の「This chapter should also remind you that at the end of the day, SLOs are about people. Creating a culture of SLOs is about making your users and your team happier.」という言葉を再度強調したいと思います。この視点を持ちつつ、技術的な指標と人間的な側面のバランスを取りながら、組織全体でSLO文化を構築していくことが、SREとしての私たちの重要な役割だと感じました。この章で学んだSLO文化構築のアプローチは、SREの実践において中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いサービスの構築と、より効果的な組織運営に貢献できると確信しています。同時に、SLO文化の構築は常に進化し続けるプロセスであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。SREとして、この章から得られた知見を組織全体に浸透させ、SLOを中心とした信頼性管理の文化を醸成していくことが重要です。ユーザー体験を重視し、技術的な指標とビジネス目標のバランスを取りながら、継続的にサービスの信頼性を向上させていくことで、長期的にはユーザー満足度の向上とビジネス目標の達成につながると確信しています。Chapter 14. SLO Evolution第14章「SLO Evolution」は、SLO（Service Level Objectives）の進化と適応の重要性について深く掘り下げています。本章は、SLOが静的なものではなく、サービスの変化に合わせて常に進化し続ける必要があることを強調しています。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon章の冒頭で、著者は次のように述べています：「Service level objectives work best when you're willing to let them change and grow as your service does.」この言葉は、SLOの本質が柔軟性と適応性にあることを端的に表現しています。サービスの成長や変化に合わせてSLOを調整することで、より適切な信頼性目標を維持できるからです。本章で特に印象だったのは、SLOの進化を促す様々な要因について詳細に解説している点です。著者は以下のような要因を挙げています：使用状況の変化（Usage Changes）依存関係の変化（Dependency Changes）障害による変化（Failure-Induced Changes）ユーザーの期待と要求の変化（User Expectation and Requirement Changes）ツールの変化（Tooling Changes）直感に基づく変化（Intuition-Based Changes）これらの要因は、SLOの進化が単なる数値の調整ではなく、サービスの全体的な状況を考慮した包括的なプロセスであることを示しています。特に、ユーザーの期待と要求の変化に関する部分が印象的でした。著者は次のように述べています：「The users that depend on your service may experience changes in their expectations over time.」この指摘は、SLOが単なる技術的な指標ではなく、ユーザー体験と密に結びついていることを強調しており、SREとして共感できる点でした。技術的な観点からは、本章では SLO の測定と計算に関する変更について詳細に解説されています。特に、メトリクスシステムの変更やデータの解像度、保持期間の変更がSLOに与える影響について、具体的な例が挙げられています。例えば、著者は次のように述べています「If you're using Prometheus to scrape your metrics endpoint for new data every 30 seconds, you'll have to revisit how you're calculating things if you change this to every 10 seconds or every 3 seconds.」この指摘は、SLOの計算が単純な数式ではなく、データ収集の方法や頻度にも大きく依存することを示しており、SREとして SLO を設計・運用する際の重要な考慮点だと感じました。本章では、SLO の変更プロセスについても詳細に解説されています。特に印象的だったのは、定期的な見直しの重要性を強調している点です。著者は次のように述べています：「In addition to all of what we've covered so far, you also need to have scheduled revisits of your SLOs.」この指摘は、SLO が静的なものではなく、継続的な検証と改善が必要であることを強調しており、SRE の実践において重要な視点だと感じました。また、本章では「誤ったSLOの識別」についても言及されています。著者は、ユーザーの声を継続的に聞くことの重要性や、障害時の SLO の挙動を注視することの重要性を強調しています。これらの指摘は、SLOが単なる数値目標ではなく、ユーザー体験と実際のシステムの挙動を反映すべきものであることを改めて認識させてくれました。本章の結論部分で、著者は次のように述べています：「Service level objectives are exactly what they sound like—they're objectives, not agreements. They should be malleable, and they should change over time.」この言葉は、SLO の本質が柔軟性と適応性にあることを再確認させてくれます。SREとして、この視点は重要です。SLO を固定的なものとして扱うのではなく、常に変化し得るものとして捉え、サービスの進化に合わせて適切に調整していく必要があります。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：SLO の定期的な見直しプロセスを確立し、組織内で徹底する。サービスの変化（使用状況、依存関係、ユーザーの期待など）を常に監視し、SLO への影響を評価する。障害発生時に SLO の挙動を詳細に分析し、必要に応じて SLO の定義や計算方法を見直す。ユーザーフィードバックを継続的に収集し、SLO に反映させる仕組みを構築する。SLO の変更プロセスを文書化し、組織内で共有する。技術的な観点からは、SLO の進化を支援するツールやフレームワークの開発が重要になります。例えば、以下のようなものが考えられます：SLO の履歴を追跡し、変更の理由や影響を記録するシステムユーザーフィードバックと SLO の相関関係を分析するツール依存関係の変化が SLO に与える影響をシミュレートするツールSLO の変更が他のサービスに与える影響を予測するシステムこれらのツールを整備することで、SLO の進化プロセスをより効果的に管理し、サービスの信頼性向上につなげることができるでしょう。この章を読んで、SLO の管理は、単に数値目標を設定し監視することではなく、サービスの進化に合わせて継続的に SLO を適応させていくプロセスであることを強く認識しました。SRE は、この進化のプロセスを主導し、技術的な側面だけでなく、ビジネスの要求やユーザーの期待も考慮しながら、適切な SLO を維持していく責任があります。総括すると、この章は SLO の進化に関する包括的かつ実践的なガイドを提供しています。SLO が静的なものではなく、サービスの変化に応じて常に進化し続ける必要があることを強調し、その進化のプロセスを詳細に解説しています。SRE にとって、この知見は価値があり、より効果的な信頼性管理の実現につながるものです。SRE として、この章から学んだアプローチを実践することで、より柔軟で効果的な SLO 管理が可能になると確信しています。特に、定期的な見直しプロセスの確立と、ユーザーフィードバックの継続的な収集・反映は、多くのプロジェクトで即座に適用できる有用な知見です。同時に、SLO の進化は継続的なプロセスであることを忘れてはいけません。技術の進化や市場の変化に応じて、常にアプローチを見直し、適応していく姿勢が重要です。最後に、本章の「Services evolve over time, which means your SLOs should, too. Use the data they provide you to have better conversations and make better decisions.」という言葉を再度強調したいと思います。この視点を持ちつつ、SLO を静的な目標ではなく、サービスの進化を促進し、より良い意思決定を支援するツールとして活用していくことが、SREとしての私たちの重要な役割だと感じました。この章で学んだ SLO 進化のアプローチは、SRE の実践において中心的な役割を果たすものです。これらの概念と手法を日々の業務に積極的に取り入れていくことで、より信頼性の高いサービスの構築と、より効果的な組織運営に貢献できると確信しています。同時に、SLO の進化は常に継続するプロセスであり、新しい技術や方法論の登場に応じて、継続的に学習し、適応していく必要があることも忘れてはいけません。Chapter 15. Discoverable and Understandable SLOs第15章「Discoverable and Understandable SLOs」は、SLO（Service Level Objectives）の理解しやすさと発見可能性の重要性に焦点を当てています。本章は、SLOを組織全体で効果的に活用するためには、それらが容易に理解でき、かつ必要な時に迅速に見つけられることが不可欠であることを強調しています。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon章の冒頭で、著者は次のように述べています：「An SLO-based approach to reliability works best when everyone is on the same page.」この言葉は、SLOの成功が組織全体の共通理解に依存していることを端的に表現しています。この視点は重要だと感じました。SLOが技術チームだけでなく、ビジネス側の人々にも理解され、活用されることで、より効果的な信頼性管理が可能になるからです。本章で特に印象的だったのは、SLO定義文書の重要性とその構成要素についての詳細な解説です。著者は、SLO定義文書に含めるべき要素として以下を挙げています：オーナーシップ承認者定義のステータスサービス概要SLO定義とステータス根拠レビュースケジュールエラーバジェットポリシー外部リンクこれらの要素を含めることで、SLO定義文書は単なる技術的な指標の記録ではなく、サービスの信頼性に関する包括的な情報源となります。特に、オーナーシップと承認者の明確化は、SLOの管理責任を明確にし、組織全体での合意形成を促進する上で重要だと感じました。また、本章では SLO の発見可能性を高めるための方法についても詳しく解説されています。著者は、中央集中型のドキュメントリポジトリの重要性を強調し、Wikiシステムやドキュメントのコード化（Documentation-as-code）などの具体的な方法を提案しています。特印象的だったのは、ドキュメントの自動スキャンと集約を行うカスタムツールの開発に関する提案です。これは、SLO定義の最新性を保ち、組織全体での可視性を高める上で効果的なアプローチだと感じました。技術的な観点からは、本章のダッシュボードに関する解説が有用でした。著者は、効果的なSLOダッシュボードに含めるべき要素として以下を挙げています：現在のステータスSLI違反のグラフバーンダウングラフエラーバジェットのステータスSLO定義文書へのリンク本章の結論部分で、著者は次のように述べています：「Reliability requires people to know what's going on, and SLOs provide a clear, customer-centric picture that speaks a thousand words.」この言葉は、SLOの本質が単なる技術的な指標ではなく、組織全体で共有される信頼性に関する共通言語であることを強調しています。SREとして、この視点は重要です。SLOを技術チームだけのものではなく、組織全体で活用される道具として位置づけることで、より効果的な信頼性管理が可能になります。SREとして、この章から学んだことを実践に移すためには、以下のようなアプローチが考えられます：組織全体で統一されたSLO定義文書のテンプレートを作成し、導入する。SLO定義文書を集中管理するためのリポジトリを構築し、組織内での可視性を高める。SLO定義文書の自動スキャンと集約を行うツールを開発し、定義の最新性と一貫性を保つSLOステータスを可視化するダッシュボードを設計し、組織全体で共有する。SLOレポートの定期的な配信や会議での共有を通じて、SLOの認知度と理解度を高める。技術的な観点からは、本章で提案されているドキュメント管理やダッシュボード構築のアプローチを実装するための具体的な方法を検討する必要があります。例えば、以下のような技術的な課題に取り組む必要があるでしょう：ドキュメントのコード化（Documentation-as-code）を実現するためのツールチェインの構築SLO定義文書の自動スキャンと集約を行うスクリプトやアプリケーションの開発リアルタイムでSLOステータスを可視化するダッシュボードの設計と実装SLO定義文書とモニタリングシステムを連携させるAPIの開発これらの技術的な取り組みを通じて、SLOの理解しやすと発見可能性を高め、組織全体でのSLOの効果的な活用を促進することができます。この章を読んで、SLOの管理は単なる技術的な指標の設定と監視ではなく、組織全体での共通理解を促進し、信頼性に関する意思決定を支援するものだと再認識しました。SREは、SLOの理解しやすさと発見可能性を高めるためのインフラストラクチャとプロセスを構築・維持する重要な役割を担っています。この章は、SLOの理解しやすさと発見可能性に関する包括的かつ実践的なガイドを提供しています。具体的には：SLO定義文書の構造化中央集中型のドキュメント管理効果的なダッシュボードの設計これらの方法は、SLOを組織全体で活用するための具体的なアプローチとして詳細に解説されています。SREとして、これらのアプローチを実践することで、SLOをより組織に浸透させ、効果的に活用することが可能になります。特に、SLO定義文書の標準化とその中央管理、そしてリアルタイムのダッシュボード提供は、多くの組織で即座に適用できる有用な施策です。同時に、SLOの理解しやすさと発見可能性の向上は継続的なプロセスであることを認識することが重要です。組織の成長や技術の進化に応じて、常にアプローチを見直し、改善していく必要があります。本章の「SLOs provide a clear, customer-centric picture that speaks a thousand words.」という言葉は、SLOの本質を捉えています。SLOを組織全体で共有される信頼性の共通言語として位置づけ、継続的に改善していくことがSREの重要な役割です。これらの概念と手法を日々の業務に積極的に取り入れることで、より効果的な信頼性管理と組織全体での信頼性文化の醸成に貢献できます。ユーザー体験を重視し、技術的な指標とビジネス目標のバランスを取りながら、継続的にサービスの信頼性を向上させていくことで、長期的にはユーザー満足度の向上とビジネス目標の達成につながるでしょう。Chapter 16. SLO Advocacy第16章「SLO Advocacy」は、SLO（Service Level Objectives）の導入と普及を組織全体で推進するためのアプローチについて詳細に解説しています。本章は、SLO導入の成功には単なる技術的な実装以上のものが必要であり、組織文化の変革と深い理解が不可欠であることを強調しています。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon著者は、SLO Advocateの役割を「組織が成功裏にSLOを実装するのを支援すること」と定義し、この役割には深い技術的知識だけでなく、リーダーシップスキルや組織全体とのコミュニケーション能力が求められることを指摘しています。特に印象的だったのは、「あなたの人間関係スキルとリーダーシップスキルは、の旅の中で極めて重要になるでしょう。あなたは自分のビジョンを他者に納得させ、彼らに必要な知識を教え、前向きなエネルギーを生み出して彼らを鼓舞し、SLO採用の成功を推進する必要があります」という一節です。この言葉は、SLO導入が単なる技術的な課題ではなく、組織全体の文化と意識の変革を必要とする大きな挑戦であることを端的に表現しています。本章は、SLO導入のプロセスを「Crawl（這う）」「Walk（歩く）」「Run（走る）」の3つのフェーズに分けて説明しています。この段階的なアプローチは、大規模な組織変革を成功させるための効果的な戦略です。Crawlフェーズでは、SLO Advocateとしての基盤作りに焦点を当てています。このフェーズでは、自己学習、支援アーティファクトの作成、組織内のリーダーやチームとの連携、最初トレーニングセッションの実施などが含まれます。特に重要なのは、SLOの「セールスピッチ」の準備です。著者は、「エレベーターで会社のCEOに会ったとき、彼らの注目を数秒しか得られないとしたら、あなたは何を言いますか？」という質問を投げかけ、異なる聴衆に対してSLOの価値を簡潔に説明できることの重要性を強調しています。技術的な観点からは、Crawlフェーズでのドキュメントの重要性が強調されています。著者は、1ページの戦略文書、SLOの高レベルな定義、FAQ、SLO定義のステップバイステップガイド、SLI収集のための計装ガイド、ユースケースなど、様々な文書の作成を推奨しています。これらのドキュメントは、組織全体でSLOの理解を深め、実装を促進する上で重要な役割を果たします。Walkフェーズでは、SLO導入の範囲を拡大し、より多くのチームを巻き込んでいきます。このフェーズでは、早期採用者との協力、成功事例の共有、トレーニングプログラムの拡大、コミュニケーション方法の改善などが重要になります。著者は、「サービスは時間とともに進化するもので、SLOも同様です。SLOが提供するデータを活用して、より良い対話を行い、より良い決定を下しましょう」と述べ、SLOが静的なものではなく、サービスの進化に合わせて継続的に調整されるべきものであることを強調しています。技術的には、Walkフェーズでのケーススタディライブラリの作成が重要です。著者は、「様々なサービスタイプのSLO実装例を持つことで、多くのチームを支援できるでしょう」と述べています。これは、異なるタイプのサービス（リクエスト/レスポンス、パイプライン、継続的計算など）に対するSLO実装の具体的な例を提供することで、他のチームがSLO導入を進める際の参考になることを示唆しています。Runフェーズでは、SLO実装が組織全体に広がり、すべてのチームがある程度のSLO成熟度に達している状態を想定しています。このフェーズでの主な活動には、ケーススタディライブラリの共有、SLOエキスパートのコミュニティ作成、プラットフォームの改善、アドボカシープロセスの改善などが含まれます。著者は、「SLOの定義と実装は、信頼性を向上させるための最初のステップにすぎません。ゲームチェンジャーは、実際にSLOをエンジニアリングプラクティスの一部として使用し、サービスの品質と運用の卓越性を推進することです」と強調しています。技術的な観点からは、Runフェーズでの継続的な改善の要性が強調されています。著者は、プラットフォームレベルの改善、定期的なSLOレビュー、サービス品質レビュー、SLO実装プロセスのディープダイブなど、様々な改善活動を提案しています。これらの活動は、SLOの効果を最大化し、組織全体の信頼性文化を強化するために不可欠です。本章の結論部分で、著者は次のように述べています：「進歩は変化なしには不可能であり、自分の考えを変えられない人は何も変えることができません」この言葉は、SLO Advocateの役割が単にSLOを実装することではなく、組織全体の文化を変革することであることを再確認させてくれます。SREとしてこの章から学んだ最も重要な教訓は、SLO導入の成功には技術的な実装以上のものが必要だということです。組織文化の変革、効果的なコミュニケーション、継続的な学と改善が不可欠です。また、SLO Advocateの役割が、技術的なエキスパートであると同時に、変革のリーダーでもあることを強く認識しました。この章の内容を実践に移すためには、以下のようなアプローチが考えられます：組織内でSLOの価値を共有するためのワークショップや勉強会を定期的に開催する。SLO導入のための包括的なドキュメントを作成し、組織全体で共有する。早期採用者との協力を通じて、様々なサービスタイプのSLO実装例（ケーススタディ）を作成し、ライブラリ化する。SLOトレーニングプログラムを確立し、他のトレーナーを育成して規模を拡大する。SLOエキスパートのコミュニティを構築し、組織全体でのSLO導入を支援する体制を整える。定期的なSLOレビューとサービス品質レビューを実施し、継続的改善を図る。技術的な観点からは、SLO実装を支援するためのツールやフレームワークの開発が重要になります。例えば、以下のようなものが考えられます：SLO定義とSLI収集を自動化するツールリアルタイムでSLOの状態を可視化するダッシュボードSLOベースのアラート設定を容易にするシステムSLOデータを分析し、改善提案を生成する機械学習モデルこれらのツールを整備することで、SLO導入のプロセスを効率化し、組織全体での採用を加速することができるでしょう。この章はSLO Advocateの役割と責任について包括的かつ実践的なガイダンスを提供しています。SLO導入と管理の成功には、技術的な知識だけでなく、組織全体を巻き込み、文化を変革する能力が必要であることが明確に示されています。SREとして、この章から学んだアプローチを実践することで、より効果的なSLO導入が可能になり、組織全体のパフォーマンス向上につながると確信しています。特に重要な点は：段階的なアプローチ（Crawl, Walk, Run）継続的な改善と適応SLOを組織全体で共有される信頼性の共通言語として位置づけること本章の「SLOは、ユーザー中心の明確な全体像を提供し、千の言葉を語るものです」という言葉は、SLOの本質を捉えています。SLO Advocateの役割は、技術的なエキスパートであると同時に、組織の変革者でもある点でやりがいがあります。この役割を通じて、SREはより戦略的な立場に立ち、組織全体の信頼性文化の醸成に大きく貢献できます。この役割には技術的スキルだけでなく、コミュニケーション能力やリーダーシップスキルの向上も求められます。最後に、SLOを中心とした信頼性管理の文化を醸成することが重要です。ユーザー体験を重視し、技術的な指標とビジネス目標のバランスを取りながら、継続的にサービスの信頼性を向上させていくことで、長期的にはユーザー満足度の向上とビジネス目標の達成につながります。これらの概念と手法を日々の業務に積極的に取り入れ、常に学習し適応していくことが、SREとしての私たちの重要な役割です。Chapter 17. Reliability Reporting第17章「Reliability Reporting」は、SLO（Service Level Objectives）を用いた信頼性報告の重要性と方法について深く掘り下げています。本章は、従来の信頼性報告手法の問題点を指摘し、SLOベースのアプローチがいかにそれらの問題を解決し、より効果的なシステム運用を可能にするかを詳細に解説しています。ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon章の冒頭で、著者は次のように述べています：「SLOは根本的に、より良い議論を行い、したがって（願わくば！）より良い決定を下すためのデータを提供する手段です」この言葉は、SLOの本質が単なる技術的な指標ではなく、意思決定プロセスを改善するためのツールであることを端的に表現しています。この視点は重要だと感じました。多くの組織では、技術的な指標に囚われすぎて、ユーザー体験や事業目標との関連性を見失いがちです。SLOは、技術とビジネスのギャップを埋める強力なツールとなり得ます。syu-m-5151.hatenablog.com本章で特に印象的だったのは、従来の信頼性報告手法の問題点についての詳細な分析です。著者は、インシデント数のカウント、重大度レベルの設定、Mean Time to X（MTTX）などの従来のアプローチが、実際のユーザー体験を正確に反映していないことを指摘しています。例えば、MTTXに関して著者は次のように述べています：「複雑なシステムは一般的に、毎回異なる要因や寄与因子を持つユニークな方法で故障します」この指摘は、インシデントの一律な分類や平均値による評価が、実際のシステムの複雑さを捉えきれないことを明確に示しています。技術的な観点から特に興味深かったのは、分散型サービス拒否（DDoS）攻撃の例を用いた従来の報告手法の限界の説明です。著者は、同じタイプの攻撃であっても、攻撃者の動機、使用される技術、標的となるエンドポイント、トラフィックパターンなどが異なり、それぞれのインシデントが本質的に一意であることを強調しています。この例は、インシデントを単純にカウントしたり、重大度レベルに分類したりするアプローチの限界を明確に示しています。本章では、SLOベースのアプローチがこれらの問題をどのように解決するかについても詳細に解説されています。著者は、エラーバジェットの概念を用いることで、ユーザーが実際に経験した信頼性の低下を正確に捉えられることを示しています。例えば、20分間のインシデントが20回発生した四半期と、3時間の単一インシデントが発生した四半期を比較した場合、MTTXアプローチでは後者の方が深刻に見えますが、エラーバジェットを用いると前者の方がユーザーにとって実際には大きな影響があったことが明確になります。Figure 17-1. A dashboard showing the burndown of a service operating unreliably より引用Figure 17-1では、信頼性の「バーンダウン」を示すダッシュボードの例が提示されています。このようなビジュアル化は、サービスの現在の状態と傾向を一目で理解するのに有効です。著者は、「人間は視覚的なデータからパターンを見つけるのが得意です」と述べており、適切に設計されたダッシュボードが、アラートシステムが検知する前に問題を発見するのに役立つことを強調しています。本章の結論部分で、著者は次のように述べています：「SLOは、ユーザーの視点から物事を測定し、同時にあなたの同僚をより幸せにする方法です。これらの議論を適切に行うためには、自分の状態を適切に報告できることが恐らく最も重要な部分です」この言葉は、SLOが単なる技術的な指標ではなく、組織全体のコミュニケーションと意思決定を改善するためのツールであることを再確認させてくれます。SREとして、この章から学んだ最も重要な教訓は、信頼性報告が単なる数値の報告ではなく、ユーザー体験とビジネス目標に直結した意味のある情報を提供するべきだということです。SLOとエラーバジェットを用いることで、技術チーム、経営陣、そして顧客との間で、サービスの信頼性に関するより建設的な対話が可能になります。この章の内容を実践に移すためには、以下のようなアプローチが考えられます：既存の信頼性報告手法を見直し、SLOベースのアプローチへの移行計画を立てる。ユーザー体験を正確に反映するSLIとSLOを設定し、それに基づいたエラーバジェットを定義する。リアルタイムでSLOの状態とエラーバジェットの消費状況を可視化するダッシュボードを構築する。SLOとエラーバジェットの状況を定期的にレビューし、サービス改善の優先順位付けに活用する。技術チーム、経営陣、顧客それぞれに適した形で信頼性レポートを作成、定期的に共有する。技術的な観点からは、SLOとエラーバジェットの計算と可視化を自動化するシステムの構築が重要になります。例えば、以下のようなものが考えられます：リアルタイムでSLIを収集し、SLOの達成状況を計算するデータパイプラインエラーバジェットの消費状況をモニタリングし、アラートを発する仕組み過去のSLO達成状況とエラーバジェット消費のトレンドを分析するツール各種ステークホルダー向けにカスタマイズされた信頼性レポートを自動生成するシステムこれらのツールを整備することで、より効率的かつ効果的な信頼性報告が可能になり、サービスの継続的な改善につながるでしょう。本章は、SLOベースの信頼性報告に関する包括的かつ実践的なガイドを提供し、従来の報告手法の限界を明確に示すとともに、SLOとエラーバジェットを用いたアプローチがそれらの問題をいかに解決するかを具体的に解説しています。SREとして、このアプローチを実践することで、ユーザー体験を中心に据えたSLOの設定とエラーバジェットの管理を通じて、より効果的な信頼性管理と報告が可能になります。しかし、この導入には組織文化の変革を伴う大きな挑戦があり、全てのステークホルダーがその価値を理解し活用できるようになるまでには時間を要します。本章の「完璧である必要はありません」という言葉は、SREとしての重要な視点を提供しており、この考えを持ちつつSLOを通じてサービスの信頼性と組織全体の満足度を継続的に向上させていくことが私たちの役割です。SLOベースの信頼性報告は、単なる技術的指標の報告ではなく、組織全体のコミュニケーションと意思決定を改善する強力なツールであり、適切に実装・活用されれば、技術チーム、経営陣、顧客間の共通言語となり、より信頼性の高いシステム構築とユーザーへの価値提供につながります。この新しいアプローチを日々の業務に積極的に取り入れ、ユーザー体験を重視しつつ技術的指標とビジネス目標のバランスを取りながら、継続的に学習し適応していくことで、長期的にはユーザー満足度の向上とビジネス目標の達成に貢献できると確信しています。おわりに「Implementing Service Level Objectives」を通じて、SLOが単なる技術的な指標ではなく、組織全体の信頼性文化を形成する強力なツールであることを深く理解することができました。まるで、組織という庭にSLOという種を植えて、信頼性という美しい花を咲かせるようなものですね。本書は、SLOの技術的な側面だけでなく、組織文化や人間的な側面にも大きな注意を払っており、SREとしての私たちの役割の重要性を再認識させてくれました。私たちは単なるガーデナーではなく、庭師長なのです！特に印象に残ったのは、「完璧である必要はない」という著者のメッセージです。SLOは、ユーザーの満足度と組織のリソースのバランスを取るためのツールであり、常に進化し続けるものです。まるで、完璧な体重を目指すダイエットではなく、健康的な生活習慣を築くようなものですね。この視点を持ちつつ、技術的な指標とビジネス目標のバランスを取りながら、継続的にサービスの信頼性を向上させていくことが、SREとしての私たちの重要な役割だと感じました。本書から学んだ知見を実践に移すためには、技術的なスキルだけでなく、コミュニケーション能力やリーダーシップスキルの向上も必要です。まるで、スーパーエンジニアからスーパーヒーローへの進化が求められているようです。SLOを組織全体に浸透させ、効果的に活用していくためには、技術チーム、プロダクトチーム、経営陣など、様々なステークホルダーとの協力が不可欠だからです。時には、異世界人との交渉も必要かもしれません。本書を通じて、SREの役割がより戦略的なものになりつつあることを強く感じました。SLOの導入と運用を通じて、SREは技術的な問題解決だけでなく、組織全体の方向性に影響を与える重要な位置にあることが明確になりました。まるで、裏方から舞台の主役に躍り出るような感覚です。この変化に適応し、技術的なスキルとビジネス感覚の両方を磨いていくことが、今後のSREにとって不可欠だと考えます。最後に、本書の著者をはじめ、SLOの発展に尽力されてきた方々に、心からの敬意と感謝を表します。皆さんの献身的な努力なくして、今日のSLOの隆盛はありませんでした。皆さんが切り拓いてくださった道の上を、私もまた歩んでいくことを誓います。そして、本ブログ読者の皆さまにも感謝を申し上げます。1つ1つの気づきや学びを積み重ねることが、私たち自身の成長につながるだけでなく、ひいては業界全体の発展にもつながるのだと信じています。引き続き、SLOについて学び、実践し、議論を深めていければとおもいます。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","link":"https://syu-m-5151.hatenablog.com/entry/2024/07/05/163659","isoDate":"2024-07-05T07:36:59.000Z","dateMiliSeconds":1720165019000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"運用者の各領域で向き合うLLM","contentSnippet":"運用者の各領域で向き合うLLM というタイトルで登壇しました。\r\rイベント名: Cloud Operator Days Tokyo 2024 \rイベントURL:https://cloudopsdays.com/","link":"https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Go開発者のための遊び場を用意する - Kindで始めるKubernetesの開発環境構築","contentSnippet":"はじめにKind (Kubernetes in Docker) は、ローカル環境でKubernetesクラスタを簡単に構築できるツールです。そう、「簡単に」と言いましたが、「簡単」の定義は人によって大きく異なりますから。ある人にとっては「簡単」でも、他の人には「アラート対応を猫に教えるくらい難しい」かもしれません。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonさあ、気軽に「簡単な」Kubernetes体験の世界へ飛び込みましょう。途中で迷子になっても、パニックにならないでください。結局のところ、私たちプログラマーは迷子になることが仕事なのですから。サンプルコード動いているものをおいておくと記事の安心感と信頼性に繋がるので置いておきます。github.comKind公式ドキュメントkind.sigs.k8s.io環境情報環境としてはLimaを利用しております。syu-m-5151.hatenablog.com参考リンクKindクラスタの作成ローカルイメージのロードKindクラスタの設定KindのネットワーキングKindでの永続ボリュームの使用Kindのセットアップと基本的な使用方法KindのインストールKindはHomebrewやバイナリのダウンロード、Go言語を使用したインストールなど複数の方法でインストールすることができます。kind.sigs.k8s.io私はbrew で入れているので一応、コマンド記載しときます。brew install kind基本的なクラスタの作成最も基本的なKindクラスタを作成するには、以下のコマンドを使用します。kind create clusterこれにより、単一ノードのKubernetesクラスタが作成されます。カスタム設定でのクラスタ作成より詳細な設定を行う場合は、YAML設定ファイルを使用します。# kind-config.yamlkind: ClusterapiVersion: kind.x-k8s.io/v1alpha4nodes:- role: control-plane- role: worker- role: workerこのファイルを使用してクラスタを作成するにはkind create cluster --config kind-config.yamlクラスタの管理クラスタの一覧を表示：kind get clusters特定のクラスタを削除：kind delete cluster --name cluster-name特定のクラスタのkubeconfigを取得：kind get kubeconfig --name cluster-name1. Skaffoldとの統合による高速な開発サイクルの実現ホットリロード可能なローカル開発環境は、DockerとAirの組み合わせで構築できますが、SkaffoldとKindを用いることで、Kubernetes環境で同等の機能を持つ開発環境を実現することも可能です。skaffold.devサービスのソースコード変更が分かりやすければ正直なんでも良いのでこちらです。// main.gopackage mainimport (    \"fmt\"    \"net/http\")func main() {    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, \"Hello, World from Go!\")    })    http.ListenAndServe(\":8080\", nil)}Dockerfileの作成go.mod のバージョンとベースイメージがズレているとエラーが出るので修正しなきゃいけないですわねー# DockerfileFROM golang:1.22 as builderWORKDIR /app# Copy go mod and sum filesCOPY go.mod ./# Download all dependencies. Dependencies will be cached if the go.mod and go.sum files are not changedRUN go mod tidy# Copy the source from the current directory to the Working Directory inside the containerCOPY . .# Build the Go appRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o go-app .FROM alpine:latest  RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /app/go-app .CMD [\"./go-app\"]Kubernetes設定ファイルの作成deployment.yaml にServiceも入れてます。# k8s-deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  name: go-appspec:  replicas: 1  selector:    matchLabels:      app: go-app  template:    metadata:      labels:        app: go-app    spec:      containers:      - name: go-app        image: go-app        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: go-appspec:  type: NodePort  ports:  - port: 8080    targetPort: 8080  selector:    app: go-appSkaffold設定ファイルの作成Skaffold設定ファイルの作成します。プロジェクトのルートディレクトリに skaffold.yaml ファイルを作成します。Dockerfileのビルドとkubectl でのデプロイの両方をやってくれます。# skaffold.yaml# Skaffoldの設定ファイル# このファイルはDockerイメージのビルドとKubernetesへのデプロイを自動化しますapiVersion: skaffold/v2beta26kind: Config# ビルド設定build:  artifacts:  - image: go-app  # ビルドされるイメージの名前    context: .     # ビルドコンテキストのパス（通常はプロジェクトのルートディレクトリ）    docker:      dockerfile: Dockerfile  # 使用するDockerfileの名前# デプロイ設定deploy:  kubectl:    manifests:    - k8s-*.yaml  # デプロイに使用するKubernetesマニフェストファイルのパターン# 注意点:# 1. `go-app`はあなたのアプリケーション名に合わせて変更してください。# 2. Dockerfileがルートディレクトリにない場合は、パスを適切に調整してください。# 3. `k8s-*.yaml`は実際のマニフェストファイル名のパターンに合わせて変更してください。# 4. 必要に応じて、プロファイルやテスト設定を追加することができます。アプリケーションの実行とテストKindクラスタを作成し、Skaffoldを起動してます。kind create clusterskaffold dev --port-forwardこの後、main.goやDockerfileを編集してください。ファイルを保存すると、Skaffoldが自動的に以下の処理を行います。変更を検知新しいDockerイメージをビルドビルドしたイメージをKindクラスタにロードアプリケーションを再デプロイ変更の確認ブラウザやcurlコマンドを使用して、アプリケーションにアクセスし、変更が反映されていることを確認します。curl http://localhost:80802. マイクロサービスアーキテクチャのシミュレーションSkaffoldを使用して、2つのGoマイクロサービスを含む環境をKindでシミュレートします。Kindクラスタの作成# kind-multi-node.yamlkind: ClusterapiVersion: kind.x-k8s.io/v1alpha4nodes:- role: control-plane  extraPortMappings:  - containerPort: 30000    hostPort: 8080  - containerPort: 30001    hostPort: 8081- role: worker- role: workerデプロイじゃいkind create cluster --config kind-multi-node.yamlサービスのソースコード その1// service-a/main.gopackage mainimport (    \"fmt\"    \"net/http\")func main() {    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, \"Hello from Service A!\")    })    http.ListenAndServe(\":8080\", nil)}サービスのソースコード その2// service-b/main.gopackage mainimport (    \"fmt\"    \"net/http\")func main() {    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, \"Hello from Service B!\")    })    http.ListenAndServe(\":8081\", nil)}Dockerfileの作成各サービスのディレクトリに以下のDockerfileを作成します。# service-a/Dockerfile と service-b/DockerfileFROM golang:1.22 as builderWORKDIR /appCOPY go.mod .COPY main.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .FROM alpine:latest  RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /app/main .CMD [\"./main\"]Kubernetes設定ファイルの作成service-aとservice-bのファイルを適切なディレクトリに設置します。# k8s-manifests.yamlapiVersion: apps/v1kind: Deploymentmetadata:  name: service-aspec:  replicas: 1  selector:    matchLabels:      app: service-a  template:    metadata:      labels:        app: service-a    spec:      containers:      - name: service-a        image: service-a        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: service-aspec:  type: NodePort  ports:  - port: 8080    targetPort: 8080    nodePort: 30000  selector:    app: service-a---apiVersion: apps/v1kind: Deploymentmetadata:  name: service-bspec:  replicas: 1  selector:    matchLabels:      app: service-b  template:    metadata:      labels:        app: service-b    spec:      containers:      - name: service-b        image: service-b        ports:        - containerPort: 8081---apiVersion: v1kind: Servicemetadata:  name: service-bspec:  type: NodePort  ports:  - port: 8081    targetPort: 8081    nodePort: 30001  selector:    app: service-bSkaffold設定ファイルの作成プロジェクトのルートディレクトリに skaffold.yaml ファイルを作成します。# skaffold.yamlapiVersion: skaffold/v2beta29kind: Configbuild:  artifacts:  - image: service-a    context: service-a    docker:      dockerfile: Dockerfile  - image: service-b    context: service-b    docker:      dockerfile: Dockerfiledeploy:  kubectl:    manifests:    - k8s-manifests.yamlアプリケーションの実行とテストSkaffoldを使用してアプリケーションをビルド、デプロイ、そして監視します。skaffold dev --port-forwardこのコマンドは以下の動作を行います。- サービスAとサービスBのDockerイメージをビルド- ビルドしたイメージをKindクラスタにロード- Kubernetes マニフェストを適用してサービスをデプロイ- ポートフォワーディングを設定- ファイルの変更を監視し、変更があれば上記のプロセスを再実行確認別のターミナルウィンドウで以下のコマンドを実行して、サービスにアクセスできることを確認します。curl http://localhost:8080  # Service Acurl http://localhost:8081  # Service Bこれで、2つのマイクロサービスがKindクラスタ上で実行され、Skaffoldによって自動的に管理されます。ソースコードを変更すると、Skaffoldが自動的に再ビルドとデプロイを行います。おわりに本記事では、Kind（Kubernetes in Docker）を使用したGoアプリケーションの開発について詳しく解説しました。Kindの基本的なセットアップから、Skaffoldとの統合による高速な開発サイクルの実現、そしてマイクロサービスアーキテクチャのシミュレーションまで、実践的なアプローチで解説しました。ここで学んだtipsとセットアップ方法を活用することで、アプリケーション開発者は以下の利点を得ることができます効率的な開発サイクル: Skaffoldとの統合により、コード変更から再デプロイまでのプロセスが自動化され、開発速度が大幅に向上します。本番環境に近いテスト環境: Kindの柔軟性により、マイクロサービスアーキテクチャや複雑なネットワーク構成を、ローカル環境で簡単にシミュレートできます。Kindの強力な機能を利用することで、本番環境に近い状態でアプリケーションをテストし、開発サイクルを迅速化できます。これは、特にクラウドネイティブな開発において非常に重要です。今後のステップとして、以下のような発展的なトピックにチャレンジすることをおすすめします。まぁ一番は俺が書けって話ですけどね。本番環境に近いテスト環境の構築設定管理の簡素化データの永続化セキュリティの強化Kindを使用したCI/CDパイプラインの構築サービスメッシュ（例：Istio）のKind環境への導入Kindを使用したカオスエンジニアリングの実践マルチクラスタ環境のシミュレーションとフェデレーション最後に、Kindはあくまでもローカル開発とテストのためのツールであることを忘れないでください。本番環境への移行時には、クラウドプロバイダーやマネージドKubernetesサービスの特性を考慮し、適切な調整を行う必要があります。","link":"https://syu-m-5151.hatenablog.com/entry/2024/06/21/135855","isoDate":"2024-06-21T04:58:55.000Z","dateMiliSeconds":1718945935000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"知識のunlearningをちゃんとやる - Learning Go, 2nd Editionの読書感想文","contentSnippet":"はじめにGo言語の入門書として広く知られている\"Learning Go\"の第二版が発刊されました。第一版を読んだ際、Go言語のシンプルさと美しく整然とした構文に感銘を受けたものの、常に進化を続けているため、過去の知識にとらわれることなく、新しい概念や手法を柔軟に取り入れていく姿勢が何よりも重要であると感じました。learning.oreilly.comソフトウェアエンジニアとして成長を続けるには、アンラーニング(unlearning)の精神、つまり過去の知識にとらわれることなく、絶え間なく新しい知識を吸収し続ける姿勢が欠かせません。どんな達人でも鍛錬を怠れば老いるのが自明ですから、知識の新陳代謝のための学び直しが必要不可欠なのです。この第二版では、中身がかなり改訂されており、Go言語のベストプラクティスがより深く理解できるようになっています。特に、ジェネリクスのサポートについての記述が追加されているのが嬉しいポイントです。これまでのGoの型システムの制限を克服し、より柔軟で表現力の豊かなコードが書けるようになるはずです(使えるようになるとは言っていません)。Unlearn（アンラーン）　人生100年時代の新しい「学び」作者:柳川 範之,為末 大日経BPAmazonまた、並行処理やメモリ管理、パフォーマンスチューニングなどの話題も充実しており、Go言語でシステム開発を行う上で必須の知識が得られます。サンプルコードや練習問題を動かしながら、Go言語の深淵に迫っていくことができます。本書は初心者には基礎知識と理解を、中級者にはステップアップのための明確な道筋を、そして上級者にはさらなる深い洞察と広がりを教えてくれる。一冊だと思います。ちなみに第一版には日本語版もあります。初めてのGo言語 ―他言語プログラマーのためのイディオマティックGo実践ガイド作者:Jon Bodnerオーム社Amazonこの本を読みながら、過去の知識にとらわれずに新しい概念を柔軟に取り入れる姿勢の重要性を改めて実感しました。Go言語はシンプルな設計思想を貫きながらも、常に進化を続けています。私自身もGo言語を使った開発を行っており、アンラーニングの精神を持ち続け、新しい知識を積極的に吸収していく必要があります。そうすることで、Go言語を最大限に活用し、よりよいソフトウェアを作り上げていくことができるはずです。個人的におすすめの書籍としては、「実用 Go言語―システム開発の現場で知っておきたいアドバイス」もあります。Go言語を実務で使う際の実践的なアドバイスが詰まっており、ぜひ合わせて読むことをおすすめします。実用 Go言語 ―システム開発の現場で知っておきたいアドバイス作者:渋川 よしき,辻 大志郎,真野 隼記オライリージャパンAmazonこの本の構成序文では、第1版から第2版への変更点、本書の対象読者、表記規則、サンプルコードの使用方法などが説明されています。第1章でGo開発環境のセットアップ方法が解説され、第2章から第5章でGo言語の基本的な要素である型、宣言、複合型、ブロック、シャドーイング、制御構文、関数などが取り上げられます。第6章から第8章では、ポインタ、型、メソッド、インターフェース、ジェネリクスといったGo言語の特徴的な機能が詳しく説明されています。第9章ではエラー処理、第10章ではモジュール、パッケージ、インポートが解説されます。第11章でGoのツールエコシステムが紹介され、第12章でGo の並行処理機能が取り上げられています。第13章と第14章では標準ライブラリとcontextパッケージについて詳しく説明されています。さらに、第15章でテストの書き方、第16章でreflect、unsafe、cgoといったより高度なトピックが解説されています。最後に演習問題が用意されており、Go言語を体系的に学ぶことができる構成となっています。Chapter 1. Setting Up Your Go Environment「Chapter 1. Setting Up Your Go Environment」を読んで、改めてGo言語の開発環境について理解を深めることができました。私自身、以前からGo言語を使っていましたが、この章を通して新たな発見もありました。私は普段、開発環境としてNeovimを使っています。VSCodeやGoLandのような統合開発環境を目指していろいろやっているのですがデフォルトでここまでやれると羨ましくも思います。ただ、Neovimでもプラグインを使えば、コード補完やフォーマットなどの基本的な機能は十分に使えるので、不便は感じていません。設定ファイルはこちらです。アンラーンが大事とか言いながら絶対に譲らないのは草です。github.comそれでも、VSCodeやGoLandのようなIDEの充実ぶりには驚かされました。特にデバッガやリファクタリング機能は、本格的な開発では重宝しそうです。私としては、プロジェクトの規模や用途に応じて、適切な開発環境を選ぶことが大切だと思いましたが別に変える予定はありまえせん。The Go Playgroundについては、以前から愛用していました。サンプルコードを試したり、コードを共有したりするのに非常に便利ですよね。複数のファイルを扱うこともできるので、ちょっとしたプロトタイプを作るのにも役立ちます。ただ、機密情報をPlaygroundに貼り付けてしまわないよう、くれぐれも注意が必要だと改めて認識しました。Makefileの活用方法については、自分でもよく使っているテクニックです。go fmtやgo vet、go buildといったコマンドを個別に実行するのは手間なので、Makefileにまとめておくことで開発の効率化が図れます。さらに、以下のようにcleanターゲットを追加しておけば、生成されたバイナリやキャッシュの削除も簡単にできて便利ですね。かつて登壇したので共有しておきます。 speakerdeck.com.DEFAULT_GOAL := build.PHONY:fmt vet buildfmt:        go fmt ./...vet: fmt        go vet ./...build: vet         go buildclean:    go clean    rm -f hello_worldGo言語の後方互換性については、開発者にとって大きなメリットだと感じています。APIの互換性が保証されているおかげで、バージョンアップによる影響を最小限に抑えられるのは、長期的なプロジェクトの維持においては特に重要なポイントだと思います。一方で、goコマンドについては後方互換性が保証されていないため、注意深くアップデートする必要があるのは確かです。moneyforward-dev.jp総じて、この章では改めてGo言語の開発環境について体系的に学ぶことができました。すでにGoを使っている人にとっても、開発環境の選択肢や、コーディングの規約、Makefileの活用など、参考になる情報が多く含まれていたと思います。実際の開発で役立つテクニックが詰まった章だったと言えるでしょう。私自身、今後もNeovimを主な開発環境として使っていく予定ですが、プロジェクトによってはVSCodeやGoLandの導入も今後も検討したいと思います。検討を重ねて検討を加速させます。みなさんは、どのような開発環境を使っているのか、そのメリットやデメリットも含めて教えていただけると嬉しいです。この章で得た知見を活かし、より効率的な環境でGoのコードを書けるようになりたいですね。次の章以降では、いよいよ言語の基本的な要素について学んでいくことになります。Goならではの特性を理解し、実践で役立てていきたいと思います。Chapter 2. Predeclared Types and Declarations「Chapter 2. Predeclared Types and Declarations」では、Go言語の組み込み型と変数宣言について詳しく解説されていました。この章を通して、Go言語の型システムと変数の扱い方について理解を深めることができました。go.devGo言語の変数宣言は、varキーワードを使う方法と:=を使う方法の2通りがあります。varを使う方法は、変数の型を明示的に指定できるので、意図が明確になります。一方、:=を使う方法は、型推論によって変数の型が自動的に決定されるので、コードがすっきりします。ただし、:=は関数内でしか使えないという制約があるので、適材適所で使い分ける必要があります。Go言語のリテラルは、デフォルトでは型を持たない（untyped）という特徴があります。これにより、リテラルを柔軟に使うことができます。例えば、整数リテラルを浮動小数点数型の変数に代入することができます。ただし、型を持たないリテラルは、デフォルトの型を持っていて、それが変数の型として使われます。定数はconstキーワードを使って宣言します。Go言語の定数は、コンパイル時に値が決定するという特徴があります。そのため、定数には数値リテラルや文字列リテラル、true/falseなどの値しか代入できません。定数は型を持つ場合と持たない場合があり、型を持たない定数はリテラルと同じように柔軟に使うことができます。変数名の付け方には、Go言語らしい流儀があります。キャメルケースを使うのが一般的で、スネークケースはあまり使われません。また、変数のスコープが小さいほど、短い名前を使うのが慣例です。例えば、forループのインデックス変数にはiやjといった1文字の名前がよく使われます。総括すると、この章ではGo言語の型システムと変数宣言について網羅的に解説されていました。Go言語の型システムは、シンプルでありながら多様な型を提供しており、柔軟性と安全性のバランスが取れていると感じました。変数宣言の方法も、varと:=の2通りがあり、使い分けることでコードの意図を明確にできます。また、リテラルと定数の扱い方にも、Go言語らしい特徴があることがわかりました。私としては、今後Go言語でコードを書く際は、この章で学んだ知識を活かして、型の選択と変数宣言を適切に行っていきたいと思います。特に、変数のスコープに応じて適切な名前を付けることは、コードの可読性を高めるために重要だと感じました。みなさんは、普段どのようなルールで変数名を付けているでしょうか。私としては、キャメルケースを使い、スコープが小さい変数には短い名前を使うようにしたいと思います。例えば、以下のように書くのがよいと思います。func main() {    n := 10    for i := 0; i \u003c n; i++ {        fmt.Println(i)    }}ここでは、nという変数名を使って、ループの上限を表しています。また、ループ変数にはiという1文字の名前を使っています。このように、変数名を適切に付けることで、コードの意図が明確になり、可読性が高まります。Chapter 3. Composite Types「Chapter 3. Composite Types」では、Go言語の複合型について詳しく解説されていました。配列、スライス、マップ、構造体といった複合型は、Go言語でデータを扱う上で欠かせない要素です。この章を通して、Go言語の複合型の特徴と使い方について理解を深めることができました。まず、配列の扱いにくさが印象的でした。Go言語の配列は、サイズが型の一部となっているため、非常に硬直的です。関数に任意のサイズの配列を渡すことができないなど、利用シーンが限られています。そのため、ほとんどの場合は配列ではなくスライスを使うのが一般的だと学びました。スライスは、Go言語で最もよく使われるデータ構造の一つです。宣言方法は複数ありますが、makeを使ってサイズと容量を指定する方法が適切だと感じました。スライスは参照型なので、関数に渡した場合は元のスライスが変更されることに注意が必要です。また、のように、スライスから別のスライスを作る際は、意図しない部分が共有されてしまうことがあるので、注意が必要だと学びました。マップは、キーと値のペアを格納するデータ構造です。宣言時にキーの型と値の型を指定します。マップに値を格納するには、m[key] = valueのように角括弧を使います。のように、存在しないキーにアクセスしようとすると、値の型のゼロ値が返されるのが特徴的でした。また、マップはスライス同様、参照型なので、関数に渡すと元のマップが変更されることを理解しました。構造体は、任意の型のフィールドを持つ複合型です。構造体を使えば、関連するデータをまとめて扱うことができます。構造体リテラルを使えば、簡潔に構造体を初期化できます。フィールド名を指定しない場合は、宣言された順番で値を指定する必要があります。構造体は比較可能な型のフィールドのみで構成されている場合、==や!=で比較できるのが便利だと感じました。Exercisesは、学んだ内容を実践的に使う良い機会だと思います。スライスのサブスライスを作ったり、文字列のルーンにアクセスしたり、構造体を色々な方法で初期化したりと、複合型の基本的な使い方が身につきそうな課題ばかりでした。github.comこの章ではGo言語の複合型について網羅的に学ぶことができました。スライスとマップの使い方、構造体の定義方法など、データを扱う上で欠かせない知識が身についたと実感しています。特に、スライスとマップが参照型であることや、意図しないメモリ共有に注意が必要だということは、頭に入れておくべき重要なポイントだと感じました。Chapter 4. Blocks, Shadows, and Control Structures「Chapter 4. Blocks, Shadows, and Control Structures」では、Go言語のブロックスコープ、シャドーイング、制御構文について深く理解することができました。これらの概念は、Go言語でコードを書く上で避けて通れない重要なトピックです。Uber Go Style Guide も良いのでおすすめです。github.comまず、ブロックスコープについては、変数の生存期間と可視性を適切に管理するために欠かせない概念だと感じました。Go言語では、{}で囲まれた部分がブロックを形成し、そのブロック内で宣言された変数は、ブロックの外からはアクセスできません。これにより、コードの可読性が高まり、意図しない変数の変更を防ぐことができます。シャドーイングについては、内側のブロックで宣言された変数が、外側のブロックの変数を隠してしまう現象のことを指します。これは、うっかりミスを引き起こしやすいので注意が必要です。特に、forステートメントの中で変数を再宣言してしまうと、期待した結果が得られないことがあります。一方、制御構文については、if、for、switch、gotoの4つが紹介されていました。覚えることが少ないことは良いことです。なぜなら人はコードを書くより読む時間の方が一般的に長いからです。ifステートメントは、他の言語と同様に条件分岐を行うための構文ですが、Go言語では条件式の前に簡単なステートメントを書くことができるのが特徴的です。これにより、条件式で使う変数をifステートメントのスコープ内に閉じ込めることができ、コードの可読性が向上します。forステートメントは、Go言語で唯一のループ構文であり、4つの形式があります。特に、rangeキーワードを使ったループ処理は、配列やスライス、マップなどの複合型を簡単に反復処理できるので、とても便利です。switchステートメントは、式を評価し、その値に基づいて条件分岐を行う構文です。Go言語のswitchは、breakを書かなくてもフォールスルーしないのがデフォルトの挙動なので、コードの可読性が高くなります。また、式を書かずに条件式だけを列挙するブランクスイッチも用意されており、複数の条件を簡潔に表現できます。gotoステートメントについては、安易に使うとコードの可読性を下げてしまうので、慎重に使う必要があると感じました。ただし、ネストが深いループを抜けるために使うなど、限定的な状況では有用であることも分かりました。本章で学んだ制御構文を使ったコーディングの練習問題が用意されていました。ランダムな数値を生成してスライスに格納したり、forループとifステートメントを組み合わせて条件分岐を行ったりと、基本的な制御構文の使い方が身につく内容でした。解答例を見ると、GoらしいコードのベストプラクティスがEe察でき、とても勉強になりました。github.com本章のまとめとして、ブロックスコープ、シャドーイング、制御構文を適切に使いこなすことの重要性が述べられていました。特に、制御構文を適切に使いこなすことで、Goのコードの流れを思い通りに制御できるようになることが強調されていました。技術的な観点からは、forステートメントの4つの形式についての理解が深まりました。特に、rangeキーワードを使ったforステートメントは、Goでデータ構造を反復処理する上で非常に重要だと感じました。また、switchステートメントのブランクスイッチについても、複数の条件を簡潔に表現できる点が印象的でした。gotoステートメントについては、使うべきシーンを見極めるのが難しいですが、限定的な状況では有用であることが分かりました。func main() {    evenVals := []int{2, 4, 6, 8, 10, 12}    for i, v := range evenVals {        if i%2 == 0 {            fmt.Println(v, \"is at an even index\")        } else {            fmt.Println(v, \"is at an odd index\")        }    }}上のコードは、forステートメントとifステートメントを組み合わせて、スライスの要素のインデックスの偶奇を判定しています。このように、制御構文を適切に使いこなすことで、シンプルかつ読みやすいコードを書くことができます。Chapter 5. Functions「Chapter 5. Functions」では、Go言語の関数について詳しく学ぶことができました。関数は、プログラムを構成する上で欠かせない要素であり、Go言語らしい特徴を備えています。この辺は実際に手を動かさないとピンとこないので動かしていってほしいです。go.devGo言語の関数宣言は、キーワードfuncに続いて関数名、入力パラメータ、戻り値の型を指定する形式です。C言語などと同様に、複数の値を返すことができるのが特徴的でした。これにより、関数の戻り値を介してエラーを返すことが可能になり、Goらしいエラーハンドリングが実現できます。また、名前付き戻り値という機能も印象的でした。これは、関数の戻り値に名前を付けることで、関数内で直接それらの変数を操作できるようにするものです。ただし、可読性を損なわないよう、この機能は慎重に使う必要があると感じました。一方で、Go言語の関数には、可変長引数がありこれは、任意の数の引数を関数に渡すことができる機能で、fmt.Printlnなどでも使われています。また、無名関数を利用することで、関数内で動的に関数を生成することも可能です。これらの機能は、柔軟かつ表現力豊かなコードを書く上で重要だと感じました。クロージャは、Go言語の強力な機能の一つです。関数の外で定義された変数を関数内で参照し、その値を変更できるのがクロージャの特徴です。これを応用することで、関数に状態を持たせることができ、より高度なプログラミングが可能になります。例えば、sort.Sliceでは、クロージャを利用してソート条件を指定しています。また、defer文は、関数の終了時に必ず実行されるコードを登録するための機能です。これを使えば、ファイルのクローズ処理などを簡潔に記述でき、リソースの適切な管理が容易になります。deferは名前付き戻り値と組み合わせることで、エラーハンドリングにも活用できます。Go言語では、すべての型がValueセマンティクスを持つため、関数の引数として渡された変数は、常にコピーが渡されます。これにより、関数内で引数の値を変更しても、呼び出し元の変数には影響を与えません。ただし、マップやスライスは参照型なので、関数内での変更が呼び出し元に反映されるという特殊な挙動を示します。は、この違いを端的に表した例だと思います。Exercisesでは、これまで学んだ関数に関する知識を活用する問題が用意されていました。計算機のプログラムにエラーハンドリングを追加したり、ファイルの長さを返す関数を書いたりと、実践的なコーディングの練習になりました。また、クロージャを使って、プレフィックスを付ける関数を生成する問題もあり、Go言語らしい関数の使い方が身につく内容でした。github.comWrapping Upでは、この章で学んだことの総括として、Go言語の関数の特徴と、それを活かしたプログラミングの重要性が述べられていました。関数を適切に使いこなすことで、Goのコードをより効果的に構成できるようになるでしょう。技術的な観点からは、可変長引数やクロージャ、名前付き戻り値など、Go言語特有の関数の機能についての理解が深まりました。特に、クロージャを利用した関数の実装は、Go言語らしいイディオムの一つだと感じました。また、defer文についても、リソース管理やエラーハンドリングにおける有用性を実感できました。func main() {    nums := []int{1, 2, 3, 4, 5}    doubles := transform(nums, func(x int) int {        return x * 2    })    fmt.Println(doubles)}func transform(slice []int, f func(int) int) []int {    transformed := make([]int, len(slice))    for i, v := range slice {        transformed[i] = f(v)    }    return transformed}上のコードは、クロージャを利用して、スライスの各要素を変換するtransform関数の例です。このように、関数を引数として受け取ることで、柔軟な処理を実現できます。総括すると、この章ではGo言語の関数について網羅的かつ体系的に学ぶことができました。関数宣言や複数の戻り値、可変長引数など、他の言語と共通する機能に加えて、クロージャやdeferなど、Go言語特有の機能についても詳しく解説されていました。これらを適切に使いこなすことが、Goらしいコードを書く上で重要だと感じました。また、学んだ関数の機能を実際のコードに落とし込む練習ができたのも良かったです。エラーハンドリングやファイル操作など、実用的な関数の書き方が身についたと思います。関数は、プログラムを構成する上で中心的な役割を果たします。**Go言語の関数には、シンプルな書き方を維持しつつ、高度なことを実現するための機能が備わっています。Chapter 6. Pointers「Chapter 6. Pointers」は、Goプログラミングにおけるポインタの概念と活用方法を深く理解するために非常に重要な章です。ポインタは、他の言語ではしばしば難解で危険なものとして扱われることがありますが、Goではその扱いやすさと効率性が際立っています。著者は、まずポインタの基本的な文法と動作について丁寧に解説しています。ポインタは、変数が格納されているメモリアドレスを保持する特別な変数であり、アドレス演算子（\u0026）とデリファレンス演算子（*）を用いて操作します。そして、ポインタ型の宣言方法やnilポインタの概念についても触れています。次に、著者はポインタの活用方法について、他の言語との比較を交えながら詳しく説明しています。Goでは、ポインタを使用するかどうかを開発者が選択できるため、不変性を保ちつつ、必要に応じてデータの変更を行うことができます。この柔軟性は、Goの強力な特徴の一つと言えるでしょう。また、ポインタを関数の引数や戻り値として使用する際の注意点についても言及されています。特に、nilポインタを関数に渡した場合の動作や、ポインタのコピーがもたらす影響について、具体的なコード例を用いて解説されています。さらに、著者はポインタの性能面でのメリットについても触れています。大きなデータ構造体をポインタで渡すことで、関数呼び出しのオーバーヘッドを削減できることが示されています。ただし、著者は安易なポインタの使用を戒めており、可能な限り値型を使用するべきだと主張しています。Figure 6-5. The memory layout of a slice より引用マップとスライスのポインタ実装の違いについても、詳細に解説されています。マップはポインタとして実装されているため、関数に渡すと元の変数に影響を与えますが、スライスは長さと容量の情報も含むため、より複雑な動作をします。特に、スライスの長さを変更しても元の変数には影響しないという特性は、バッファとしてスライスを活用する際に重要です。Figure 6-9. Changing the capacity changes the storage より引用メモリ割り当てとガベージコレクションについても、Goの特徴が詳しく解説されています。Goは、スタックとヒープを適切に使い分けることで、効率的なメモリ管理を実現しています。著者は、ヒープ割り当てを最小限に抑え、ガベージコレクターの負荷を減らすことの重要性を強調しています。この「機械的な共感」の考え方は、Goプログラミングにおいて非常に重要な概念だと言えます。最後に、著者はガベージコレクターのチューニング方法についても触れています。GOGCとGOMEMLIMITの環境変数を適切に設定することで、ガベージコレクションの頻度やメモリ使用量を制御できることが示されています。ポインタに関する実践的な演習問題が提供されています。Personの構造体を使ったポインタの活用や、スライスの動作の理解を深める問題など、ポインタの理解を深めるために有益な問題が用意されています。これらの演習を通して、読者はポインタの概念を実際のコードに落とし込む力を身につけることができるでしょう。この章でポインタの重要性と適切な使用方法について再確認できました。著者は、次章で扱うメソッド、インターフェース、型についても、ポインタの理解が役立つことを示唆しています。Chapter 7. Types, Methods, and Interfaces「Chapter 7. Types, Methods, and Interfaces」は、Go言語のオブジェクト指向プログラミングの特徴を理解する上で非常に重要な章です。著者は、Goが他の言語とは異なるアプローチを取っていることを強調しつつ、型、メソッド、インターフェースの使い方とベストプラクティスを丁寧に解説しています。Goの型システムは、シンプルでありながら非常に強力です。 著者は、ユーザー定義型の宣言方法や、型宣言が「実行可能なドキュメンテーション」としての役割を果たすことを説明しています。また、iotaを使った列挙型の定義方法についても触れ、iotaの適切な使用方法を示しています。メソッドについては、レシーバーの指定方法や、ポインタレシーバーとバリューレシーバーの使い分けが重要なポイントです。著者は、nilインスタンスを適切に扱うためのテクニックや、メソッドが関数としても扱えることを示し、メソッドと関数の使い分け方についても言及しています。Goのインターフェースは、型安全な「ダックタイピング（Duck typing）」を実現する強力な機能です。ダックタイピングとは、オブジェクトの 型(クラス)を明示的に宣言せずに 、オブジェクトの振る舞い(メソッド)やプロパティを利用することで、そのオブジェクトの型(クラス)を推測する手法です。。 著者は、インターフェースの暗黙的な実装がもたらす柔軟性と、明示的なインターフェースに比べた利点を詳しく説明しています。また、インターフェースとnilの関係や、インターフェースの比較可能性についても触れ、インターフェースを適切に使いこなすためのヒントを提供しています。特に印象的だったのは、「Accept Interfaces, Return Structs」というアドバイスです。関数やメソッドの引数としてインターフェースを受け取り、戻り値としてコンクリートな型を返すことで、APIの柔軟性と保守性を高めることができます。 ただし、パフォーマンスとのトレードオフにも注意が必要です。著者は、Goの暗黙的なインターフェースが、依存性の注入を容易にすることも指摘しています。サンプルコードを用いて、インターフェースを介して依存関係を外部化する方法を具体的に示しており、読者は実践的なスキルを身につけることができます。type DataStore interface {    UserNameForID(userID string) (string, bool)}type Logger interface {    Log(message string)}type SimpleLogic struct {    l  Logger    ds DataStore}func (sl SimpleLogic) SayHello(userID string) (string, error) {    sl.l.Log(\"in SayHello for \" + userID)    name, ok := sl.ds.UserNameForID(userID)    if !ok {        return \"\", errors.New(\"unknown user\")    }    return \"Hello, \" + name, nil}func (sl SimpleLogic) SayGoodbye(userID string) (string, error) {    sl.l.Log(\"in SayGoodbye for \" + userID)    name, ok := sl.ds.UserNameForID(userID)    if !ok {        return \"\", errors.New(\"unknown user\")    }    return \"Goodbye, \" + name, nil}これまで学んだ概念を応用する練習問題が用意されています。バスケットボールリーグを管理するプログラムを作成する過程で、型、メソッド、インターフェースの使い方を体験的に学ぶことができます。これらの演習を通して、読者はGoの型システムに対する理解を深め、実践的なスキルを磨くことができると思います。章全体としてGoの型システムの特徴とベストプラクティスについて再確認しています。Chapter 8. Generics「Chapter 8. Generics」は、Go言語におけるジェネリクスの概念と使用方法を深く理解するために非常に重要な章です。ジェネリクスは、Go言語の型システムに大きな変革をもたらす機能であり、コードの再利用性と柔軟性を大幅に向上させることができます。 著者は、この章を通して、ジェネリクスの必要性、基本的な使い方、制限事項、そして適切な活用方法について丁寧に解説しています。まず、著者はジェネリクスの必要性について説明しています。Go言語は静的型付け言語であり、関数やデータ構造の型を明示的に指定する必要があります。しかし、異なる型に対して同じロジックを適用したい場合、ジェネリクスがないと、コードの重複が避けられません。これは、コードの保守性を低下させ、バグを引き起こす可能性があります。ジェネリクスを使うことで、型に依存しないアルゴリズムを一度だけ実装し、様々な型に対して再利用できるようになります。次に、著者はジェネリクスの基本的な使い方について説明しています。Go言語のジェネリクスは、型パラメータを使って実現されます。型パラメータは、関数やデータ構造の定義時に指定し、具体的な型の代わりに使用します。型パラメータには制約を設けることができ、許容する型を限定することができます。 これにより、コンパイル時の型安全性を確保しつつ、柔軟性を維持することができます。著者は、スタック（stack）のデータ構造を例に、ジェネリクスの使い方を具体的に示しています。ジェネリックなスタックの実装では、要素の型を型パラメータで表現し、anyとcomparableという組み込みのインターフェースを制約として使用しています。これにより、任意の型の要素を持つスタックを、一つの実装で表現できます。また、comparableを使うことで、要素の比較が必要な操作も、型安全に行えるようになります。さらに、著者はジェネリックな関数 Map 、 Reduce 、 Filter の実装を紹介しています。これらの関数は、スライスに対する一般的な操作を抽象化したもので、様々な型のスライスに適用できます。これにより、コードの重複を大幅に削減でき、アルゴリズムの本質に集中できるようになります。また、著者はジェネリクスとインターフェースの関係についても説明しています。インターフェースを型制約として使うことで、ジェネリックな型に特定のメソッドを要求できます。 これにより、より細かな制約を設けることができ、コードの安全性を高められます。さらに、インターフェース自体をジェネリック化することで、より柔軟な抽象化が可能になります。型の要素（type elements）についても詳しく解説されています。型の要素を使うことで、特定の演算子をサポートする型だけを受け入れるジェネリックな関数を定義できます。 これは、数値計算などで特に役立ちます。著者は、Integerというインターフェースを定義し、整数型に対する演算を抽象化する例を示しています。ジェネリックな関数とデータ構造を組み合わせることで、より汎用的なコードを書くことができます。著者は、バイナリツリーの例を用いて、比較関数をジェネリック化することで、任意の型に対応できるようになることを示しています。これにより、コードの再利用性が大幅に向上します。type OrderableFunc[T any] func(t1, t2 T) intfunc NewTree[T any](f OrderableFunc[T]) *Tree[T] {    return \u0026Tree[T]{        f: f,    }}comparableインターフェースとジェネリクスの関係についても、注意点が説明されています。comparableを型制約として使う場合、比較可能でない型が渡されるとランタイムパニックが発生する可能性があります。これを防ぐためには、コンパイル時に型チェックを行う必要があります。また、著者はジェネリクスの現在の制限についても言及しています。Go言語のジェネリクスは、他の言語に比べてシンプルな設計になっており、特殊化やカリー化、メタプログラミングなどの機能は提供されていません。 これは、Go言語のシンプルさと読みやすさを維持するための判断だと考えられます。ジェネリクスの導入により、Go言語のイディオマティックな書き方にも変化が生じます。著者は、float64を汎用的な数値型として使う慣習が廃れ、anyがinterface{}に取って代わることを指摘しています。また、ジェネリクスを使うことで、異なる型のスライスを統一的に扱えるようになります。ただし、既存のコードをジェネリクスに置き換える際は、慎重に行う必要があります。パフォーマンスへの影響については、まだ評価が定まっていません。一部のケースでは、ジェネリクスを使うことでコードが遅くなることが報告されています。しかし、ソートアルゴリズムでは、ジェネリクスを使うことで速度が向上するという報告もあります。著者は、可読性と保守性を重視しつつ、必要に応じてベンチマークを取ることを推奨しています。標準ライブラリへのジェネリクスの導入は慎重に行われています。 当初はanyとcomparableのみが追加されましたが、Go 1.21からは、スライスとマップ、並行処理に関する関数が追加されています。これらの関数は、よく使われる操作を抽象化し、コードの重複を削減するのに役立ちます。今後も、ジェネリクスを活用した新しい関数やデータ型が追加されていくことが期待されます。最後に、著者はジェネリクスによって可能になる将来の機能について言及しています。ジェネリクスを基礎として、より高度な型システムを構築できる可能性があります。 例えば、和型（sum types）を導入することで、型安全性を高めつつ、柔軟なデータ表現が可能になります。また、Goの列挙型の弱点を克服する手段としても、和型は有望視されています。本章ではジェネリクスに関する実践的な演習問題が用意されています。整数と浮動小数点数の両方に対応する関数の作成や、特定の型を要求するインターフェースの定義など、ジェネリクスの基本的な使い方から応用までを網羅しています。これらの演習を通して、読者はジェネリクスの概念を実際のコードに落とし込む力を身につけることができるでしょう。github.com章全体の内容を振り返り、ジェネリクスの重要性と将来の可能性について再確認できました。著者は、ジェネリクスがGo言語の表現力を高め、コードの再利用性を向上させる強力な機能であると強調しています。 一方で、Go言語のシンプルさを維持するために、ジェネリクスの機能は意図的に制限されています。これからのGo言語の発展において、ジェネリクスがどのように活用されていくのか、楽しみにしていると述べています。ジェネリクスは、Go言語の未来を切り拓く重要な機能であると言えます。 それを適切に使いこなすことで、より柔軟で保守性の高いコードを書けるようになるでしょう。一方で、ジェネリクスの濫用は、かえってコードの複雑さを増し、可読性を損なう恐れがあります。今後、Go言語のエコシステムにおいて、ジェネリクスを活用したライブラリやフレームワークが登場することが期待されますが、それらを適切に評価し、選択していく眼を養う必要があります。Chapter 9. Errors「Chapter 9. Errors」は、Go言語におけるエラーハンドリングの基本から応用までを網羅的に解説した章です。この章を通して、Go言語のエラー処理の特徴と、それを適切に使いこなすためのテクニックについて理解を深めることができました。Go言語のエラー処理は、他の言語の例外処理とは一線を画しています。Goでは、エラーは関数の戻り値として返され、呼び出し元で明示的にチェックする必要があります。 これは一見、冗長で面倒に感じるかもしれませんが、実際には、コードの流れを明確にし、エラーを見落とすリスクを減らすことができます。著者は、この設計の背景にある「Goの哲学」について丁寧に説明しており、納得感を持って読み進めることができました。Go言語のベストプラクティスとして、「Accept interfaces, return structs」という原則があります。これは、関数やメソッドの引数としてインターフェースを受け取り、戻り値として具体的な構造体を返すことを推奨するものです。エラー処理においても、この原則を応用し、具体的なエラー型を返すことで、呼び出し元が適切にエラーを処理できるようになります。特に印象的だったのは、カスタムエラー型の定義方法と活用方法です。Goでは、エラーをただの文字列ではなく、構造体として定義することができます。これにより、エラーに付加情報を持たせたり、エラーの種類によって処理を変えたりすることが可能になります。著者は、カスタムエラー型の定義方法から、そのメソッドの実装、そしてerrors.Isやerrors.Asを使った高度なエラー処理までを、具体的なコード例を交えて解説しています。type MyError struct {    Codes []int}func (me MyError) Error() string {    return fmt.Sprintf(\"codes: %v\", me.Codes)}func (me MyError) Is(target error) bool {    if me2, ok := target.(MyError); ok {        return slices.Equal(me.Codes, me2.Codes)    }    return false}また、エラーのラップ（wrapping）とアンラップ（unwrapping）についても詳しく解説されていました。fmt.Errorfの%w動詞を使えば、元のエラーを失わずに新しいエラーメッセージを追加できます。これにより、エラーが発生した場所や状況を詳細に伝えつつ、根本原因を追跡することができます。逆に、errors.Unwrapを使えば、ラップされたエラーから元のエラーを取り出すことができます。実際にカスタムエラー型を定義し、エラーをラップ・アンラップする練習問題が用意されていました。これらの問題を通して、エラー処理の基本的な書き方だけでなく、より実践的なテクニックも身につけることができました。特に、複数のエラーをまとめて返す方法や、deferを使ったエラーハンドリングの例は、実際のプロジェクトでも役立つと感じました。github.com一方で、panicとrecoverについては、慎重に使うべきだと改めて認識しました。 panicは、回復不可能なエラーが発生した場合に使うべきであり、安易に使うとかえってコードの可読性を損ねてしまいます。recoverは、panicからの復帰を可能にしますが、ライブラリのAPI境界を越えてpanicを伝播させるべきではありません。著者は、panicとrecoverの適切な使い方について、具体的な指針を示しています。func div60(i int) {    defer func() {        if v := recover(); v != nil {            fmt.Println(v)        }    }()    fmt.Println(60 / i)}この章でGo言語のエラー処理の特徴とベストプラクティスが再確認されています。 エラーを単なる例外ではなく、値として扱うことで、より柔軟で表現力豊かなエラーハンドリングが可能になります。一方で、その自由度ゆえに、適切なエラー処理を行うには、一定の規律と経験が必要になります。総括すると、この章ではGo言語のエラー処理について体系的に学ぶことができました。 エラーを値として扱う考え方や、カスタムエラー型の定義方法、エラーのラップとアンラップ、panicとrecoverの適切な使い方など、Go言語ならではのエラー処理の特徴と、それを活かすためのベストプラクティスについて理解を深めることができました。特に、実際のコードを書く上では、エラー処理を適切に行うことが、コードの品質と保守性を大きく左右します。 単にエラーを無視するのではなく、適切にエラーをハンドリングし、ログ出力や監視システムと連携させることが重要です。また、ライブラリやパッケージを設計する際は、エラーをどのように定義し、どのように返すかを慎重に検討する必要があります。Chapter 10. Modules, Packages, and Imports「Chapter 10. Modules, Packages, and Imports」は、Go言語におけるコード管理と外部ライブラリの利用について、非常に重要な概念を丁寧に解説した章です。この章を通して、私はGoのモジュールシステムの特徴と、それを活用するためのベストプラクティスについて理解を深めることができました。まず、モジュール、パッケージ、レポジトリの関係性について明確に説明されていました。モジュールはソースコードの集合体であり、バージョン管理されるユニットです。パッケージはモジュールを構成する要素であり、ディレクトリと1対1で対応します。レポジトリはモジュールを格納する場所です。これらの概念を正しく理解することは、Goでのコード管理を行う上で欠かせません。次に、go.modファイルの役割と記述方法について解説されていました。go.modファイルは、モジュールのメタデータとその依存関係を記述するファイルです。moduleディレクティブでモジュールのパスを宣言し、goディレクティブで必要なGoのバージョンを指定し、requireディレクティブで依存モジュールとそのバージョンを記述する。この構文を理解することで、自分のモジュールを適切に定義し、外部モジュールを利用できるようになります。また、パッケージの作成方法と命名規則、内部パッケージの役割などについても詳しく説明されていました。パッケージ名はディレクトリ名と一致させるべきであり、機能を適切に分割し、依存関係を最小限に抑えるべきです。 内部パッケージを使えば、モジュール内だけで共有したいコードを適切に隠蔽できます。これらのベストプラクティスを意識することで、保守性の高いコードを書けるようになるでしょう。さらに、GoDocコメントの書き方と、pkg.go.devを使ったドキュメントの公開方法も紹介されていました。適切なGoDocコメントを書くことで、自分のパッケージをわかりやすく説明でき、pkg.go.devで自動的にドキュメントを公開できます。これにより、他の開発者が自分のパッケージを使いやすくなり、オープンソースへの貢献にもつながります。モジュールのバージョニングについては、セマンティックバージョニングのルールに従うべきだと強調されていました。APIの互換性を維持しつつ、適切にバージョンを上げていくことが重要です。不適切なバージョンを公開してしまった場合の対処方法として、retractディレクティブの使い方も説明されていました。モジュールプロキシとチェックサムデータベースの仕組みについても、セキュリティの観点から重要な説明がありました。デフォルトではGoogleが運営するプロキシサーバとチェックサムデータベースが使われ、モジュールの整合性が検証されます。 必要に応じて、独自のプロキシサーバを立てたり、プロキシを無効化したりできることも示されていました。また、GoのWorkspaceを使えば、複数のモジュールを同時に編集できることが紹介されていました。これにより、モジュール間の変更を簡単にテストでき、開発の効率が上がります。 ただし、Workspaceの情報をバージョン管理システムにコミットしないよう注意が必要です。サンプルコードを見ると、モジュールの作成から公開、利用までの一連の流れが具体的に示されていました。go mod initでモジュールを初期化し、go getで依存関係を解決し、go buildでビルドする。このような一連のコマンドを適切に使いこなすことが、Goでの開発には欠かせません。$ go mod init github.com/learning-go-book-2e/money$ go get ./...$ go buildExercisesでは、自分でモジュールを作成し、バージョニングやドキュメンティングを実践する課題が用意されていました。実際にコードを書いて、モジュールの作成から公開までの流れを体験することは、理解を深める上で非常に有効だと感じました。// Add adds two numbers together and returns the result. //// More information on addition can be found at [https://www.mathsisfun.com/numbers/addition.html](https://www.mathsisfun.com/numbers/addition.html).func Add[T Number](a, b T) T {    return a + b}Goの優れたモジュールシステムを活用することで、コードの管理がしやすくなり、外部ライブラリも安全に利用できるようになります。一方で、適切なバージョニングやドキュメンティングを行うことが、モジュールの作者としての責務であることも強調されていました。この章ではGoにおけるコード管理と外部ライブラリ利用のベストプラクティスについて、体系的に学ぶことができました。モジュール、パッケージ、レポジトリの関係性、go.modファイルの記述方法、パッケージの設計原則など、Goでの開発に欠かせない知識が丁寧に解説されていました。またモジュールのバージョニングやドキュメンティングの重要性についても、実例を交えて説明されていました。特に、モジュールプロキシとチェックサムデータベースの仕組みは、Goの優れたエコシステムを支える重要な基盤だと感じました。セキュリティと利便性を高いレベルで両立させているGoの設計思想に、改めて感銘を受けました(以前、何かの勉強会で聞いた気がするがすっかり忘れていた)。Chapter 11. Go Tooling「Chapter 11. Go Tooling」は、Goプログラミングにおける開発ツールの重要性と活用方法について深く理解するための重要な章でした。この章を通して、私はGoの豊富な標準ツールと、サードパーティのツールを組み合わせることで、より効率的で高品質なコードを書けるようになると実感しました。著者は、まずgo runを使って小さなプログラムを素早く試す方法を紹介しました。これにより、コンパイルと実行を一度に行え、スクリプト言語のような気軽さでGoを使えるようになります。Goがコンパイル言語でありながら、インタプリタ言語のような利便性も兼ね備えている点が印象的でした。次に、go installを使ってサードパーティのツールをインストールする方法が解説されました。Goのツールエコシステムは非常に充実しており、多くの優れたツールがオープンソースで公開されています。go installを使えば、それらのツールを簡単にインストールし、自分の開発環境に取り込むことができます。また、著者はgoimportsを使ってインポートの整形を改善する方法も紹介しました。これはgo fmtの機能を拡張したもので、不要なインポートを削除し、必要なインポートを自動的に追加してくれます。コードの可読性と保守性を高めるために、goimportsを活用すべきだと感じました。コード品質をチェックするツールとして、staticcheck、revive、golangci-lintが紹介されていました。これらのツールは、潜在的なバグや非効率的なコードを検出し、Goのベストプラクティスに沿ったコードを書くのに役立ちます。特にgolangci-lintは、多数のリンターを統合的に使える便利なツールだと感じました。また、著者はgovulncheckを使って脆弱性のある依存関係をスキャンする方法も解説しました。サードパーティのライブラリを利用する際は、既知の脆弱性がないかチェックすることが重要です。govulncheckを活用することで、セキュリティリスクを早期に発見し、対処できるようになります。さらに、go:embedを使ってコンテンツをプログラムに埋め込む方法や、go generateを使ってコード生成を自動化する方法も紹介されていました。これらの機能を活用することで、より柔軟でメンテナンスしやすいコードを書けるようになると感じました。著者は、クロスコンパイルやビルドタグを使って、異なるプラットフォームやバージョンのGoに対応する方法も解説しました。Goのポータビリティの高さを活かすためには、これらの機能を理解し、適切に使いこなすことが重要だと感じました。Exercisesでは、埋め込みやクロスコンパイル、静的解析など、この章で学んだ機能を実践的に使う課題が用意されていました。実際にコードを書いて試すことで、ツールの使い方や注意点を体験的に学ぶことができました。//go:embed english_rights.txtvar englishRights string//go:embed all:var allRights embed.FSfunc main() {    if len(os.Args) != 2 {        fmt.Println(\"Please specify a language\")        os.Exit(1)    }    language := os.Args[1]    data, err := allRights.ReadFile(language + \"_rights.txt\")    if err != nil {        fmt.Printf(\"No UDHR found for language %s\\n\", language)        os.Exit(1)    }    fmt.Println(string(data))}Goの標準ツールとサードパーティのツールを適切に組み合わせることで、より効率的で高品質なコードを書けるようになります。一方で、ツールを過信せず、その出力を批判的に評価することも大切だと強調されていました。この章ではGoの開発ツールについて網羅的に学ぶことができました。go runやgo installなどの基本的なツールの使い方から、staticcheckやgolangci-lintなどの高度なリンターの活用法、go:embedやgo generateなどの特殊機能まで、Goでの開発に欠かせないツールの数々が丁寧に解説されていました。特に、サードパーティのツールを積極的に活用することの重要性を再認識しました。Goの標準ツールは非常に充実していますが、コミュニティの知恵を結集したサードパーティのツールを併用することで、さらに開発の生産性と品質を高められると感じました。Chapter 12. Concurrency in Go「Chapter 12. Concurrency in Go」を通して、Go言語の並行処理モデルの特徴と使い方、そしてベストプラクティスについて深く理解することができました。この章は、Go言語を使いこなす上で欠かせない重要なトピックを丁寧に解説しており、実践的な知識を身につけるのに最適だと感じました。また、並列処理に関してはブログも書籍もたくさんあるので気になる方がいましたら是非にです。Go言語による並行処理作者:Katherine Cox-BudayオライリージャパンAmazonGo言語の並行処理モデルは、Communicating Sequential Processes（CSP）をベースにしており、その中心的な概念がgoroutineとchannelです。goroutineは、Goランタイムによって管理される軽量のスレッドのようなもので、OS レベルのスレッドよりもはるかに少ないオーバーヘッドで大量に生成・管理できます。一方、channelは、goroutine間でデータを共有するためのパイプのようなもので、型安全でデッドロックを防ぐための仕組みが備わっています。著者は、まず並行処理を使うべきケースについて説明しました。並行処理は、必ずしもプログラムを高速化するわけではなく、IO バウンドなタスクでない限り、オーバーヘッドが大きくなる可能性があると指摘しています。そのため、並行処理を適用する前に、ベンチマークを取って本当にメリットがあるかを確認すべきだと強調していました。次に、goroutineとchannelの基本的な使い方が解説されました。goroutineは、goキーワードを関数呼び出しの前に置くだけで簡単に生成でき、channelはmake関数で作成します。unbuffered channelとbuffered channelの違いや、for-rangeループを使ったchannelの読み取り方法なども丁寧に説明されていました。また、channelを適切にクローズすることの重要性も強調されていました。クローズされたchannelからの読み取りは、その型のゼロ値を返すという特殊な動作を理解しておく必要があります。複数のgoroutineが同じchannelに書き込む場合は、sync.WaitGroupを使ってすべてのgoroutineの終了を待ってからクローズすべきだとのアドバイスもありました。select文は、複数のchannelを扱う際に欠かせない重要な構文です。selectを使えば、複数のchannelを監視し、読み書き可能になったchannelを選択して処理できます。著者は、selectがデッドロックを防ぐ上で重要な役割を果たすことを具体的なコード例で示していました。続いて、並行処理のベストプラクティスとパターンが紹介されました。特に印象的だったのは、APIをconcurrency-freeに保つべきというアドバイスです。並行処理はあくまで実装の詳細であり、ユーザーに不要な複雑さを押し付けるべきではないというのは、納得のいく指摘だと感じました。また、goroutineのリークを防ぐために、必ず終了するようにすべきだという点も重要でした。contextパッケージを使ってgoroutineをキャンセルする方法や、for-selectループから適切に抜ける方法などが具体的に示されていました。バッファ付きchannelの使いどころについても、詳しく解説されていました。バッファ付きchannelは、goroutineの数を制限したり、キューに溜まった処理を制御したりするのに便利です。一方で、不適切に使うとデッドロックを引き起こす可能性もあるため、慎重に検討すべきだと強調されていました。また、バックプレッシャーを実装する方法として、バッファ付きchannelとselect文を組み合わせるアプローチが紹介されていました。これにより、同時実行数を制限しつつ、処理を適切にブロックできるようになります。さらに、select文のcaseを動的にオン・オフする方法として、nil channelを活用するテクニックも面白かったです。クローズしたchannelからの読み込みが、ゼロ値を返し続けてしまう問題を回避できる優れたアイデアだと感じました。一方で、mutexについても適切に使いこなすことの重要性が述べられていました。goroutineとchannelだけでは実現が難しい、共有リソースの保護などでは、mutexが適していると指摘されていました。ただし、mutexの濫用は避けるべきで、可能な限りchannelを使うのがよいとのアドバイスもありました。最後に、これまで学んだ概念を組み合わせて、非同期なパイプラインを実装するサンプルコードが示されていました。goroutine、channel、select、contextを適切に使い分けることで、タイムアウト制御や複数のWeb APIを並行に呼び出す処理を、わずか100行程度の読みやすいコードで実現できることはめちゃくちゃメリットだと思います。練習問題では、goroutineとchannelを使った基本的な並行処理プログラムから、selectやsync.WaitGroupを使ったより複雑な処理まで、幅広い題材が扱われていました。自分で実際にコードを書いて試すことで、並行処理の基本的なパターンが身についたと実感しています。github.comこの章を通して、Go言語の並行処理モデルの優れた設計思想と、それを適切に使いこなすためのベストプラクティスについて深く理解することができました。goroutineとchannelを中心とするシンプルな仕組みの中に、デッドロックを防ぎつつ安全に並行処理を行うための知恵が詰まっていることを実感しました。一方で、並行処理の適用は慎重に検討すべきであり、安易に使うとかえって複雑さを増してしまうことも学びました。並行処理はあくまでツールであり、ボトルネックの特定と適切な設計が何より重要だというのは、肝に銘じるべき教訓だと感じました。特に、現実のシステム開発においては、並行処理とエラーハンドリング、リソース管理などを総合的に考える必要があります。goroutineのリークを防ぎ、適切にリソースを解放する方法や、mutexとchannelの使い分け方など、実践的なスキルを再確認できたのは良かったです。私自身、普段からGoを使った並行処理プログラムを書くことが多いのですが、この章で得た知見を活かして、より堅牢で効率的なコードを書けるようになりたいと思います。特に、contextパッケージを活用したgoroutineのキャンセル処理や、バッファ付きチャネルを使ったバックプレッシャーの実装などは、実際のプロジェクトですぐにでも試してみたいテクニックです。並行処理はGoの最も強力な武器の一つですが、それを適切に使いこなすためには、深い理解と経験が必要不可欠です。この章で学んだ基本的な概念と、数多くのベストプラクティスを、自分の経験として血肉化していくことが、Goのプロフェッショナルとして成長するための鍵になるのだと感じました。Chapter 13. The Standard Library「Chapter 13. The Standard Library」では、Goの標準ライブラリの中でも特に重要なパッケージについて深く掘り下げています。この章を読んで、Goの標準ライブラリがいかにベストプラクティスに基づいて設計されているかを強く実感しました。そこには、他の言語の標準ライブラリにはない優れた設計思想が随所に見られます。印象的だったのは、「io」パッケージの設計です。「io.Reader」と「io.Writer」というシンプルなインターフェースを中心に、様々な入出力処理を抽象化している点は、Goならではの美しい設計だと感じました。この設計のおかげで、ファイルやネットワーク、圧縮、暗号化など、様々な入出力処理を統一的に扱えるようになっています。また、「time」パッケージも非常に使いやすく設計されています。「time.Duration」と「time.Time」という2つの型を中心に、時間関連の処理を直感的に記述できるのは、Goの大きな強みだと思います。特に、モノトニック時間の採用により、リープセカンドなどの影響を受けずに正確な時間計測ができるようになっているのは、システムプログラミングにおいて重要な点だと感じました。「encoding/json」パッケージは、構造体のタグを活用してJSONのエンコーディングとデコーディングを制御できる点が優れています。これにより、JSONのフィールド名と構造体のフィールド名を柔軟にマッピングできるだけでなく、フィールドの省略やデフォルト値の指定なども簡単に行えます。以下のサンプルコードのように、タグを使ってJSONのフィールド名を指定できるのは非常に便利です。type Person struct {    Name string `json:\"name\"`    Age  int    `json:\"age\"`}「net/http」パッケージは、Goの標準ライブラリの中でも特に重要なパッケージの1つです。「http.Handler」インターフェースを中心としたシンプルな設計により、高性能で使いやすいHTTPサーバーとクライアントを簡単に構築できます。また、ミドルウェアのパターンを活用することで、ログ出力やエラーハンドリング、認証、圧縮など、様々な機能を柔軟に追加できる点も優れています。「log/slog」パッケージは、2023年にリリースされたGo 1.21で新たに追加された構造化ロギングのためのパッケージです。従来の「log」パッケージの課題を解決し、より使いやすく、パフォーマンスにも優れた設計になっています。以下のように、ログレベルやコンテキスト、属性などを柔軟に指定できるのが特徴です。logger := slog.New(slog.NewTextHandler(os.Stdout))logger.Info(\"Hello, World!\", \"name\", \"Alice\", \"age\", 30)これらの知識を活用して、現在時刻を返すWebサーバーや、ミドルウェアを使ったJSONログ出力、JSONとテキストの切り替えなどを実装する課題が用意されていました。これらの課題に取り組むことで、標準ライブラリの使い方をより深く理解することができました。Goの標準ライブラリがベストプラクティスに基づいて設計されていること、そして後方互換性を尊重しながら進化を続けていることが改めて強調されていました。Goの標準ライブラリは、私たちが日々のプログラミングで参考にすべき優れたお手本だと言えます。個人的な感想としては、Goの標準ライブラリは、シンプルさと実用性のバランスが非常に優れていると感じました。必要十分な機能を提供しながらも、無駄に複雑になることなく、使いやすさを追求しているのが印象的です。特に、インターフェースを活用した抽象化と、具体的な実装の使い分けが絶妙だと思います。また、Goの標準ライブラリは、並行処理やエラーハンドリング、テストなど、現代的なプログラミングに欠かせない要素をしっかりとサポートしているのも大きな特徴だと感じました。これらの機能を標準ライブラリレベルでサポートしているからこそ、Goは大規模なシステム開発に適した言語になっているのだと思います。Chapter 14. The Context「Chapter 14. The Context」は、Go言語プログラミングにおける重要な概念である「コンテキスト」について深く掘り下げた章でした。コンテキストは、リクエストのメタデータを管理し、タイムアウトやキャンセル、値の受け渡しを制御するための強力な仕組みです。この章を通して、コンテキストの適切な使い方とベストプラクティスについて理解を深めることができました。zenn.devGo言語による並行処理にもContext について記載してあるので読んで下さい。learning.oreilly.com著者は、まずコンテキストの基本的な文法と使い方から説明しています。コンテキストは、context.Contextインターフェースを満たす値として表現され、関数の第一引数として明示的に渡すのが慣例です。context.Background関数でルートコンテキストを作成し、そこから子コンテキストを派生させていくのが基本的なパターンだと学びました。HTTPサーバーでコンテキストを使う場合は、http.RequestのContextメソッドとWithContextメソッドを使って、ミドルウェア間でコンテキストを受け渡しするのが適切な方法だと分かりました。ハンドラ関数では、req.Context()でコンテキストを取得し、ビジネスロジックの第一引数として渡すべきだと強調されていました。コンテキストの主な用途の一つが、キャンセル処理だと理解しました。context.WithCancel関数でキャンセル可能なコンテキストを作成し、キャンセル関数を適切にdeferすることで、リソースのリークを防げることが示されていました。Goの標準ライブラリのHTTPクライアントは、コンテキストのキャンセルを尊重して、リクエストを適切に中止してくれるそうです。また、context.WithTimeoutやcontext.WithDeadlineを使えば、コンテキストに時間制限を設定できることも分かりました。これにより、リクエストの処理時間を適切に管理し、サーバーのリソースを公平に配分できるようになります。子コンテキストのタイムアウトは、親コンテキストのタイムアウトに制約されるというルールも重要だと感じました。コンテキストのキャンセル原因を伝えるために、context.WithCancelCauseやcontext.Causeを使う方法も印象的でした。エラーの伝搬と情報の集約に、コンテキストが効果的に活用できることが分かりました。一方で、キャンセル関数の呼び出しを複数回行っても問題ないという点は、意外でした。自作のコードでコンテキストのキャンセルをサポートする場合は、select文でctx.Done()をチェックするパターンと、定期的にcontext.Cause(ctx)をチェックするパターンの2つが紹介されていました。長時間実行される処理では、コンテキストのキャンセルに対応することが重要だと再認識しました。Exercisesでは、これまで学んだコンテキストの知識を活用する問題が用意されていました。ミドルウェアでタイムアウトを設定する課題や、時間制限付きの計算を行う課題、ロギングレベルをコンテキストで制御する課題など、実践的なユースケースが網羅されていたと思います。github.com冒頭でも述べたように、コンテキストはGo言語プログラミングにおける重要な概念です。この章を通して、コンテキストの適切な使い方とベストプラクティスについて体系的に学ぶことができました。特に、キャンセル処理とタイムアウト制御は、サーバーの堅牢性と公平性を確保する上で欠かせない機能だと実感しました。一方で、コンテキストの乱用は、かえってコードの複雑さを増してしまう恐れがあります。コンテキストは、主にリクエストスコープのメタデータを扱うために使うべきで、安易に値の受け渡しに使うのは避けるべきだと強調されていました。この指針は、コンテキストを適切に使いこなす上で重要だと感じました。自作のコードでコンテキストのキャンセルをサポートすることの重要性も再認識できました。特に、select文とctx.Done()を使ったパターンは、Goらしい簡潔で効果的な手法だと感じました。長時間実行される処理では、定期的にコンテキストのキャンセルをチェックすることを習慣づけたいと思います。func longRunningTask(ctx context.Context) error {    for {        select {        case \u003c-ctx.Done():            return ctx.Err()        default:            // Do some work        }    }}この章ではGoのコンテキストについて網羅的かつ実践的に学ぶことができました。コンテキストの基本的な使い方から、キャンセル処理、タイムアウト制御、値の受け渡しまで、幅広いトピックが丁寧に解説されていました。Exercisesで提示された問題は、コンテキストの理解を深め、実際のコードに落とし込む力を養うのに役立つ内容でした。コンテキストは、Goのプログラミングスタイルと哲学を体現する重要な機能だと言えます。明示的なデータの受け渡しを重視しつつ、キャンセルとタイムアウトという横断的な関心事をエレガントに扱える点が、Goらしさを感じさせます。一方で、その柔軟性ゆえに、適切に使いこなすには一定の規律と見識が求められます。Chapter 15. Writing Tests「Chapter 15. Writing Tests」は、Goにおけるテストの書き方と品質向上のためのツールについて詳細に解説している章です。この章を読んで、ユニットテストの書き方、テーブルテストの実行、テストのセットアップとティアダウン、HTTPのスタブ化、ファジングテスト、データ競合の検出など、テストに関する多くの知見を得ることができました。また、テストに関しては他の書籍を読んでも良いかもと思いました。【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazon特に印象に残ったのは、テーブルテストの実行方法です。テーブルテストを使うことで、同じテストロジックに対して様々なデータパターンを適用することができ、コードの可読性と保守性が向上します。また、並行テストの実行方法も非常に興味深かったです。並行テストを適切に実行することで、テストの実行時間を大幅に短縮できます。ただし、共有される可変状態に依存するテストを並行して実行すると、予期しない結果になる可能性があるため注意が必要です。コードカバレッジの計測も重要なトピックの一つでした。go test -coverを使ってカバレッジを計測し、go tool coverでカバレッジ情報を可視化する方法は、テストの網羅性を確認する上で非常に有用です。ただし、100%のコードカバレッジを達成しても、バグが存在する可能性があることに注意が必要です。ファジングテストは、ランダムなデータを生成してコードに入力し、予期しない入力に対する動作を検証する手法です。ファジングテストを行うことで、開発者が想定していなかったようなコーナーケースのバグを発見することができます。また、データ競合の検出には-raceフラグを使用します。これにより、複数のゴルーチンから同時にアクセスされる変数を特定し、適切なロックを設定することができます。サンプルコードとして、sample_code/adderディレクトリにあるaddNumbers関数のテストコードが示されていました。また、sample_code/tableディレクトリではテーブルテストの例が、sample_code/solverディレクトリではスタブを使ったテストの例が示されていました。これらのサンプルコードは、実際のテストコードを書く際の参考になります。Exercisesでは、Simple Web Appプログラムに対してユニットテストを書き、コードカバレッジを計測することが求められていました。また、データ競合を検出して修正し、parser関数に対してファジングテストを実行することも求められていました。これらの演習を通じて、テストに関する知識を実践的に応用することができます。この章で学んだテストとコード品質向上のためのツールについて総括されていました。次の章では、unsafeパッケージ、リフレクション、cgoなど、Goの一般的なルールを破るような機能について探求していくとのことでした。総括すると、この章ではGoにおけるテストの書き方とコード品質向上のためのツールについて網羅的に解説されていました。ユニットテストの書き方、テーブルテストの実行、並行テストの実行、コードカバレッジの計測、ファジングテスト、データ競合の検出など、テストに関する重要なトピックが幅広くカバーされていました。また、サンプルコードや演習問題も充実しており、実践的な知識を身につけることができる内容でした。Chapter 16. Here Be Dragons: Reflect, Unsafe, and Cgo「Chapter 16. Here Be Dragons: Reflect, Unsafe, and Cgo」を通して、Go言語プログラミングにおいて、安全性と規約を一時的に無視してメモリやデータの細かな操作を行う仕組みであるreflect、unsafe、cgoについて深く理解することができました。これらの機能は、Go言語のセキュリティと型安全性を一時的に破ることから、非常に注意深く扱う必要があります。しかし、特定の場面では威力を発揮するため、適切な活用方法を学ぶことが重要だと感じました。reflectreflectは、Go言語の型システムを動的に操作するための強力な仕組みです。コンパイル時には型が特定できない場合、または外部データを動的にマッピングする必要がある場合などに、reflectを使って型の情報を取得したり、値を設定することができます。reflectで扱う主な概念は「型(reflect.Type)」「種類(reflect.Kind)」「値(reflect.Value)」の3つです。reflectを使えば、構造体のフィールドにアクセスしたり構造体を生成できますが、コーディングが冗長になりがちで、正しい操作を行わないとパニックを起こす可能性があります。そのため、適切なエラーハンドリングと注釈を残すことが重要です。特に、型の種類(reflect.Kind)に応じて、呼び出し可能なメソッドが変わるため、種類をしっかり確認する必要があります。type Foo struct {    A int    `myTag:\"value\"`    B string `myTag:\"value2\"`}var f Fooft := reflect.TypeOf(f)for i := 0; i \u003c ft.NumField(); i++ {    curField := ft.Field(i)    fmt.Println(curField.Name, curField.Type.Name(),        curField.Tag.Get(\"myTag\"))}上記のサンプルコードは、reflectを使って構造体のタグフィールドにアクセスする方法を示しています。このように、reflectは型情報を動的に取得したり、値を設定・生成したりするのに役立ちますが、過度に使い過ぎるとコードの可読性を下げる恐れがあります。reflectを利用する主なユースケースは、データベースやJSONなどの外部データの読み書き、テンプレートエンジンによるデータのレンダリング、型に依存しないソートアルゴリズムの実装などです。Go言語の標準ライブラリでも、これらの用途でreflectが活用されています。一方、reflectを使うと通常の処理に比べてパフォーマンスが大幅に低下するという課題もあります。サンプルコードのベンチマークでは、reflectを使ったフィルタ処理は通常の場合に比べて50~75倍も遅く、多数のメモリ確保を行うことが分かります。BenchmarkFilterReflectString-8     5870  203962 ns/op  46616 B/op  2219 allocs/opBenchmarkFilterGenericString-8   294355    3920 ns/op  16384 B/op     1 allocs/opBenchmarkFilterString-8          302636    3885 ns/op  16384 B/op     1 allocs/opそのため、必要不可欠な場面でのみreflectを使い、通常の処理ではジェネリクスなどの代替手段を使うべきです。ただし、マーシャリング・アンマーシャリングや動的なメモ化などは、reflectを使わざるを得ない場合もあります。このように、Go言語の規約を一時的に無視する仕組みとして、reflectを適切に使いこなすことが重要だと言えます。unsafeunsafeパッケージは、Go言語の型安全性とメモリ安全性をある程度無視して、低水準のメモリ操作を行う仕組みを提供します。主な使用例は、OSとのシステムコール連携や、バイナリデータの高速なマーシャリング・アンマーシャリングなどです。内部で扱われるデータ型はunsafe.Pointerで、任意のポインタ型やuintptrとの相互キャストが可能です。メモリのレイアウトを調べるためのunsafe.Sizeofとunsafe.Offsetof関数があり、構造体フィールドの並び替えによるメモリ使用量の最適化などに役立ちます。type BoolInt struct {    b bool    i int64}type IntBool struct {    i int64    b bool}fmt.Println(unsafe.Sizeof(BoolInt{}), unsafe.Offsetof(BoolInt{}.b), unsafe.Offsetof(BoolInt{}.i))// Output: 16 0 8 fmt.Println(unsafe.Sizeof(IntBool{}), unsafe.Offsetof(IntBool{}.i), unsafe.Offsetof(IntBool{}.b))// Output: 16 0 8上記のサンプルコードでは、構造体の並び方によってメモリのパディングが変わり、全体のサイズが変化することが分かります。このように、unsafeパッケージを使えば、メモリのレイアウトを細かく制御できます。さらに、unsafeを使えば、バイナリデータをスムーズに構造体へマッピングすることも可能です。func DataFromBytesUnsafe(b [16]byte) Data {    data := (*Data)(unsafe.Pointer(\u0026b))    if isLE {        data.Value = bits.ReverseBytes32(data.Value)    }    return data}このコードは、バイト配列をunsafe.Pointerでキャストし、最終的に構造体へマッピングしています。パフォーマンス的には、unsafeを使ったバイト配列から構造体へのマッピングは、安全な手法に比べて2〜2.5倍程度高速だと言われています。BenchmarkDataFromBytes-8             538443861  2.186 ns/op   0 B/op 0 allocs/opBenchmarkDataFromBytesUnsafe-8      1000000000  1.160 ns/op   0 B/op 0 allocs/opただし、unsafeの濫用は危険を伴うため、必要最小限の使用に留める必要があります。Go言語のセキュリティモデルを部分的に無視する代わりに、そのパフォーマンスメリットを手に入れるかどうかは、用途次第です。通常のプログラミングでは、安全な手法を使うことがベストプラクティスです。また、unsafeを使う際は、ランタイムフラグ -gcflags=-d=checkptrを付けてポインタの不適切な使用をチェックすることが推奨されています。ドキュメントの注意事項にあるとおり、正しく使えば高速で強力なコードを書けますが、間違った使い方をすると簡単にセキュリティホールを作ってしまう可能性もあるため、unsafeの適切な使用には熟達した技術が求められます。cgo最後に、cgoについてですが、これはGo言語とCコードを連携する仕組みです。CコードをC拡張構文のコメント中に直接記述したり、関数の宣言をコメントに記述して外部のCコード中の関数をリンクしたりできます。Go関数をCコードにエクスポートすることも可能です。/*#include \u003cmath.h\u003eint add(int a, int b) {    int sum = a + b;    printf(\"a: %d, b: %d, sum %d\\n\", a, b, sum);    return sum;}*/import \"C\"func main() {    sum := C.add(3, 2)    fmt.Println(sum)           // Output: 5    fmt.Println(C.sqrt(100))   // Output: 10}cgoは、OSのシステムコールへアクセスしたり、既存のCライブラリを活用したりするのに便利です。ただし、Go言語がGCで自動メモリ管理しているのに対し、Cコードではメモリ解放を手動で行う必要があるため、ポインタの扱いには注意が必要です。Go側の変数をCコードに渡す際は、cgo.HandleでラップしてCコードに安全に渡す必要があります。p := Person{Name: \"Jon\", Age: 21}C.in_c(C.uintptr_t(cgo.NewHandle(p)))このように、cgoを使うと、Go言語の安全性とCコードの低レイヤー制御が両立できます。ただし、その実行コストは約40nsと高く、基本的にはパフォーマンス向上のためというよりは、既存のCライブラリ活用のために使われることが多いようです。パフォーマンス向上のためだけにはあまりメリットがない上、ポインタの危険な操作が必要になるため、cgoは「cgo is not Go」と言われています。そのため、自前でCラッピングを書く前に、サードパーティ製のGoラッパーを探すことが推奨されています。また、設計やメモリモデルの違いから、cgoの使用は避けられない場合に限り、それでもできるだけコア部分は安全なGoコードで書くべきだとされています。この章では、Go言語のセキュリティや規約を部分的に無視するreflect、unsafe、cgoについて詳しく学びました。これらの機能は、強力な反面で危険が伴うため、一定の知識と経験が必要とされます。特に、reflectは外部データのマッピングや標準ライブラリの一部の処理に必要不可欠ですが、パフォーマンスの低下が避けられません。unsafeはメモリレイアウトの制御や高速なデータマーシャリングに使えますが、安全性を無視する代わりのメリットが必要です。cgoは既存のCライブラリをラッピングする手段ですが、実行コストが高い上に設計の違いからGoの規約を完全に守ることができません。つまり、これらは例外的な処理を行うための機能であり、通常の処理ではなるべく使わず、代わりにジェネリクスなどの安全な手段を活用するのがベストプラクティスだと言えます。Go言語の利点は、まさにその規約とセキュリティにあるためです。ただし、一方でそれらを無視する機能さえも用意されていることで、Go言語はかえって強力で柔軟な言語になっていると言えるでしょう。Exercisesでは、構造体のバリデーションやメモリレイアウトの最適化、CコードのラッピングなどGoの規約を一時的に無視する練習問題が用意されていました。Wrapping Upでは、Go言語の安全性は基本原則ですが、例外的に規約を無視することで強力で柔軟な機能が提供されていると総括されていました。つまり、これらの高度な機能は「ツール」に過ぎず、適切な使い分けが重要なのです。Go言語は、基本的にはシンプルで規約に従うことで、保守性の高いソフトウェアを作ることを目指しています。一方で、状況次第では規約を一時的に無視して高度な操作を行う必要が出てくる場合もあります。そういった際にこそ、reflect、unsafe、cgoといった高度な機能が役立つのです。これらは、Go言語の最も興味深い部分の1つと言えるでしょう。しかし同時に、これらの機能の濫用はセキュリティホールやバグにつながりかねません。そのため、十分な理解とコントロールが求められます。Go言語のセキュリティやベストプラクティスに反するような例外的な処理は、確実に必要な場面でのみ、そして最小限に留めるべきです。Go言語では、規約に従うことで、強固で長期的に保守しやすいソフトウェアを書くことを目指しています。その一方で、例外的な状況においては、reflectやunsafe、cgoなどの例外的な仕組みを適切に使いこなすスキルも要求されます。つまり、Go言語では一般的なユースケースでは退屈で規約に従うことを推奨しつつ、特殊なケースでは必要最小限の例外を認める、そんな設計思想が貫かれていると言えるのです。今後50年のコンピューティングを支えるソフトウェアを作り上げていく上で、この思想を体現するスキルが求められるでしょう。おわりにここ間違っているとかあればDMください。本書「Learning Go Second Edition」を通して、Go言語プログラミングについて体系的かつ実践的に学ぶことができました。Goのシンプルさと実用性を重視する設計思想、並行処理やエラーハンドリング、テストなどの実践的な要素に言語レベルでサポートされている点が特に印象的でした。一方で、Goのシンプルさは時として制約にもなり得ます。Goの設計思想を理解し、適材適所で機能を使い分けて周知していくことが大事だと思いました。サンプルコードと練習問題を通して、学んだ概念を実際のコードに落とし込み、体験的に理解を更に深めることができました。特に知らなかったことがいくつかあったのと実践的なスキルとして利用したいものがいくつかあったので充分すぎる収穫かと思いました。Goのシンプルさの中に宿る美しさに惹かれ、ベストプラクティスを習慣化し、美しいコードを書けるようになりたいと思いました。並行処理とエラーハンドリングは、Goプログラミングの醍醐味だと感じています。モジュールシステムとテストの重要性についても再認識できました。Goのシンプルで実用的な設計思想を自分の糧として、プログラマとしてのマインドセットを磨いていきたいと思います。**","link":"https://syu-m-5151.hatenablog.com/entry/2024/06/19/154201","isoDate":"2024-06-19T06:42:01.000Z","dateMiliSeconds":1718779321000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"オブザーバビリティ再入門みたいなイベントで登壇しました。再入門だけが創造的な勉強会みたいな主張をした。 #o11y_mackerel","contentSnippet":"はじめに先日、taxin_ttさんからダイレクトメッセージで、「オブザーバビリティ再入門」というイベントで登壇し、イベントのテーマが「再入門」ということで、オブザーバビリティについて改めて基本的な概念から説明するようにとの依頼をいただきました。mackerelio.connpass.com「再入門」というテーマを聞いたとき、正直なところ少し悩みました。オブザーバビリティは近年注目を集めているトピックであり、既に多くの人が資料を作って登壇されており参加者も基本的な知識を持っているはずです()。そんな中で、「再入門」として何を話せばよいのか、どのようにアプローチすればよいのか、考えを巡らせました。再読だけが創造的な読書術である (単行本)作者:永田　希筑摩書房Amazonそこで、私は「可観測性とは」「可観測性と監視の違い」「可観測性の導入と抵抗」の3つのトピックを中心に話すことにしました。これらのトピックを通して、オブザーバビリティの基本的な概念や重要性について、わかりやすい言葉で説明することを心がけました。また、非技術者への説明時に再利用しやすいよう、平易な表現を用いています。聴衆の皆さんが、オブザーバビリティについて改めて理解を深め、実践につなげるためのヒントを提供できるよう努めました。なぜなら、言語やコミュニケーションは意図のすべてをそのまま表現できるわけではありません。常に受け取り手によって解釈され、解釈されて初めて意味あるものとして伝わるからです。そのため、この再入門を意味あるものだと感じたのなら、それはあなたが準備できていたからだと言えるでしょう。当日まで概要しか知らなかったのですが、登壇者が尊敬しているまさよしさんで、「メトリクス、ログ、トレースをうまく使い分けて可観測性を高めよう！」というタイトルだったので、その辺の話は避けてもよいと思い、OpenTelemetryという単語を一切使わずにこのような内容になりました。めちゃくちゃに良い資料なので読んでほしいです。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon登壇資料本資料がどんな資料かというと、 speakerdeck.com可観測性（Observability）について以下のようにまとめている。可観測性とは、システムの外部から観測できる情報に基づいて内部状態を推論・理解する能力のことであり、特にマイクロサービスアーキテクチャでは、複数の信号源からの情報を相関させ、サービスを横断するリクエストを追跡できる可観測性が不可欠である。可観測性の主要なシグナルとしては、メトリクス、ログ、トレースの3つがあり、可観測性と監視の違いは、監視が既知の未知（Known unknow）に対応するのに対し、可観測性は未知の未知（Unknow unknow）に対応する点である。何かを導入する時には、変化への抵抗が伴うことが多く、抵抗の主な要因として、惰性、労力、感情、心理的反発の4つがある。可観測性導入の成功のためには、技術的・人的側面に配慮し、エンジニアや組織全体の心理的抵抗に対処することが重要であり、継続的なコミュニケーションと小さな成功体験で支持を得ることが有効である。可観測性導入は組織的な変革であり、エンジニアリング文化や考え方の変革が必要で、エンジニアの自発的な活用と組織全体の支援が重要である。みたいなことを生成AIを通すと言われたのでそんなことを言われたのでそんな感じの資料です。きょーさんに毎回のようにレビューしていただきました。当日の雰囲気Youtube緊張してアルコールを飲んだ。www.youtube.comXでの投稿まとめまとめを作ってくれる人はいつの時代も偉大である。ありがとうございます。togetter.com参考資料Observability Whitepaperオブザーバビリティ入門：これから始める方への基本コンセプトとツールPractical MonitoringCloud Observability in ActionObservability EngineeringopenobserveObservability with Grafana【2024年度 サイバーエージェント 新卒研修】システム運用の基本と戦略オブザーバビリティ研修実践編オブザーバビリティ入門勘に頼らず原因を⾒つけるためのオブザーバビリティログから始めるオブザーバビリティフロントエンドにおけるObservabilityObservabilityについてOpenTelemetry実践 はじめの一歩分散トレーシングとOpenTelemetryのススメ / Getting started distributed tracing and OpenTelemetry仕様と実装で学ぶOpenTelemetry計測の手間を省きたい！OpenTelemetry に見る\"自動計装\"のイマPractical MonitoringopenobserveCloud Observability in ActionObservability Engineering「変化を嫌う人」を動かす: 魅力的な提案が受け入れられない4つの理由解像度を上げる 🔬具体と抽象 世界が変わって見える知性のしくみ「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策他者と働く「わかりあえなさ」から始める組織論","link":"https://syu-m-5151.hatenablog.com/entry/2024/06/06/131051","isoDate":"2024-06-06T04:10:51.000Z","dateMiliSeconds":1717647051000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"可観測性ガイダンス","contentSnippet":"可観測性ガイダンスというタイトルで登壇してきました。\r\rイベント名: オブザーバビリティ再入門 - 大切さと高め方を知ろう！\rイベントURL: https://mackerelio.connpass.com/event/316449/\r\r\r# ブログでいくつかの可観測性に関する書籍のまとめを投稿しました。\r5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文\rhttps://syu-m-5151.hatenablog.com/entry/2024/04/16/180511\r\rもう一度読むObservability Engineering\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/06/090014\r\r盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/10/121047","link":"https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu","isoDate":"2024-06-04T04:00:00.000Z","dateMiliSeconds":1717473600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fiber v3 を使ったが変更点を確認だけして手癖で解決した","contentSnippet":"はじめにこの記事では、プログラミング言語のGoとWebフレームワークであるFiber v3を使って、リレーショナルデータベースのPostgreSQLをバックエンドに利用したCRUD (Create, Read, Update, Delete) 操作ができるWeb APIを作成する方法を説明します。本来であれば、Fiber v3の新機能や変更点を活用したかったのですが、十分な調査を行う前に雰囲気で実装を進めてしまったため、本記事ではそれらを採用できておりません。深夜に検証を行っていたこともあり、ベストプラクティスとは言えない部分があることを認識しています。エンジニアとして、新しいバージョンのフレームワークを使う際には、事前に十分な調査を行い、新機能や変更点を理解した上で実装を進めるべきでした。GitHub Copilot とLanguage Server で適当に書いてしまいました。また、コードの品質を保つためには、適切な時間帯に集中して作業を行うことが重要です(これはガチ)。今回の実装では、これらの点が不十分であったことを反省しています。業務では、技術選定や実装方法について、より慎重に検討を行い、品質の高いコードを書くことを心がけたいと思います。読者の皆様におかれましては、本記事の内容を参考にする際には、上記の点にご留意いただければ幸いです。github.comプロジェクトの初期化まず、新しいGoプロジェクトを作成します。mkdir fiber-crud-apicd fiber-crud-apigo mod init github.com/yourusername/fiber-crud-api必要なパッケージのインストール次に、必要なパッケージをインストールします。go get github.com/gofiber/fiber/v3go get github.com/lib/pqデータベースの設定とモデルの定義main.goファイルを作成し、以下のようにデータベースの設定とモデルを定義します。package mainimport (    \"database/sql\"    \"encoding/json\"    \"fmt\"    \"log\"    \"time\"    \"github.com/gofiber/fiber/v3\"    _ \"github.com/lib/pq\")const (    host     = \"db\"    port     = 5432    user     = \"postgres\"    password = \"password\"    dbname   = \"mydb\")// Connect to the databasefunc Connect() (*sql.DB, error) {    psqlInfo := fmt.Sprintf(\"host=%s port=%d user=%s password=%s dbname=%s sslmode=disable\", host, port, user, password, dbname)    db, err := sql.Open(\"postgres\", psqlInfo)    if err != nil {        return nil, err    }    return db, nil}// User modeltype User struct {    ID        int       `json:\"id\"`    Name      string    `json:\"name\"`    Email     string    `json:\"email\"`    Password  string    `json:\"password\"`    CreatedAt time.Time `json:\"created_at\"`}// Post modeltype Post struct {    ID        int       `json:\"id\"`    UserID    int       `json:\"user_id\"`    Title     string    `json:\"title\"`    Content   string    `json:\"content\"`    CreatedAt time.Time `json:\"created_at\"`    UpdatedAt time.Time `json:\"updated_at\"`}APIエンドポイントの実装続けて、main.goファイルにAPIエンドポイントを実装します。v2 の時には存在していたctx のbodyparserがv3ではなくなっていたので手癖でJSONで返したのですがおそらくBind周りで実装するとよいみたいです(あとから気付きました...)。v2からv3の変更点については以下を参考にしてください。docs.gofiber.iofunc main() {    app := fiber.New()    // データベース接続    db, err := Connect()    if err != nil {        log.Fatal(err)    }    defer db.Close()    // Create User    app.Post(\"/users\", func(c fiber.Ctx) error {        user := new(User)        if err := json.Unmarshal(c.Body(), user); err != nil {            return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{                \"error\": \"Invalid request body\",            })        }        // パスワードのハッシュ化やバリデーションを行うことが推奨される        // 簡易実装のため、ここでは省略        // データベースにユーザーを作成        _, err := db.Exec(\"INSERT INTO users (name, email, password) VALUES ($1, $2, $3)\", user.Name, user.Email, user.Password)        if err != nil {            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                \"error\": \"Failed to create user\",            })        }        return c.Status(fiber.StatusCreated).JSON(fiber.Map{            \"message\": \"User created\",        })    })    // Get User    app.Get(\"/users/:id\", func(c fiber.Ctx) error {        id := c.Params(\"id\")        // データベースからユーザーを取得        row := db.QueryRow(\"SELECT * FROM users WHERE id = $1\", id)        user := new(User)        if err := row.Scan(\u0026user.ID, \u0026user.Name, \u0026user.Email, \u0026user.Password, \u0026user.CreatedAt); err != nil {            if err == sql.ErrNoRows {                return c.Status(fiber.StatusNotFound).JSON(fiber.Map{                    \"error\": \"User not found\",                })            }            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                \"error\": \"Failed to get user\",            })        }        return c.JSON(user)    })    // Create Post    app.Post(\"/posts\", func(c fiber.Ctx) error {        post := new(Post)        if err := json.Unmarshal(c.Body(), post); err != nil {            return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{                \"error\": \"Invalid request body\",            })        }        // データベースに記事を作成        _, err := db.Exec(\"INSERT INTO posts (user_id, title, content) VALUES ($1, $2, $3)\", post.UserID, post.Title, post.Content)        if err != nil {            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                \"error\": \"Failed to create post\",            })        }        return c.Status(fiber.StatusCreated).JSON(fiber.Map{            \"message\": \"Post created\",        })    })    // Get Post    app.Get(\"/posts/:id\", func(c fiber.Ctx) error {        id := c.Params(\"id\")        // データベースから記事を取得        row := db.QueryRow(\"SELECT * FROM posts WHERE id = $1\", id)        post := new(Post)        if err := row.Scan(\u0026post.ID, \u0026post.UserID, \u0026post.Title, \u0026post.Content, \u0026post.CreatedAt, \u0026post.UpdatedAt); err != nil {            if err == sql.ErrNoRows {                return c.Status(fiber.StatusNotFound).JSON(fiber.Map{                    \"error\": \"Post not found\",                })            }            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                \"error\": \"Failed to get post\",            })        }        return c.JSON(post)    })    log.Fatal(app.Listen(\":3000\"))}このコードでは、以下のエンドポイントを実装しています。POST /users: 新しいユーザーを作成します。GET /users/:id: 指定されたIDのユーザーを取得します。POST /posts: 新しい記事を作成します。GET /posts/:id: 指定されたIDの記事を取得します。Dockerfileとdocker-compose.ymlの作成開発環境用のDockerfileとdocker-compose.ymlを作成します。これも簡易的に用意した適当なファイルなので十分に吟味してください。FROM golang:1.22-alpineWORKDIR /appCOPY go.mod go.sum ./RUN go mod downloadCOPY . .RUN go build -o main .CMD [\"./main\"]version: '3'services:  app:    build: .    ports:      - \"3000:3000\"    depends_on:      - db  db:    image: postgres    environment:      POSTGRES_USER: postgres      POSTGRES_PASSWORD: password      POSTGRES_DB: mydb    volumes:      - ./init.sql:/docker-entrypoint-initdb.d/init.sqlデータベースの初期化スクリプトinit.sqlファイルを作成し、データベースの初期化スクリプトを記述します。CREATE TABLE users (    id SERIAL PRIMARY KEY,    name VARCHAR(255) NOT NULL,    email VARCHAR(255) UNIQUE NOT NULL,    password VARCHAR(255) NOT NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);CREATE TABLE posts (    id SERIAL PRIMARY KEY,    user_id INTEGER REFERENCES users(id),    title VARCHAR(255) NOT NULL,    content TEXT NOT NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);アプリケーションの実行以下のコマンドを実行してアプリケーションを起動します。docker-compose up --buildこれで、GoとFiberを使ってCRUDができるAPIが作成され、PostgreSQLをバックエンドに利用する環境が整いました。APIエンドポイントをテストするために、cURLやPostmanなどのツールを使用してリクエストを送信できます。APIのテストとデータベースの確認アプリケーションを起動した後、CURLを使ってAPIエンドポイントをテストし、PostgreSQLの中身を確認してみましょう。ユーザーの作成と確認まず、新しいユーザーを作成します。curl -X POST -H \"Content-Type: application/json\" -d '{\"name\":\"John Doe\",\"email\":\"john@example.com\",\"password\":\"secret\"}' http://localhost:3000/usersレスポンスとして、\"User created\"が返ってくるはずです。次に、作成したユーザーを確認します。curl http://localhost:3000/users/1レスポンスとして、作成したユーザーの情報がJSON形式で返ってきます。{\"id\":1,\"name\":\"John Doe\",\"email\":\"john@example.com\",\"password\":\"secret\",\"created_at\":\"2023-04-24T12:34:56Z\"}PostgreSQLの中身を確認するために、データベースにログインします。docker-compose exec db psql -U postgres mydbユーザーテーブルの中身を確認します。SELECT * FROM users;作成したユーザーがテーブルに存在することを確認できます。 id |  name   |     email      | password |         created_at----+---------+----------------+----------+----------------------------  1 | John Doe| john@example.com| secret   | 2024-05-30 01:34:56.789012(1 row)記事の作成と確認次に、新しい記事を作成します。curl -X POST -H \"Content-Type: application/json\" -d '{\"user_id\":1,\"title\":\"My First Post\",\"content\":\"Hello, World!\"}' http://localhost:3000/postsレスポンスとして、\"Post created\"が返ってくるはずです。作成した記事を確認します。curl http://localhost:3000/posts/1レスポンスとして、作成した記事の情報がJSON形式で返ってきます。{\"id\":1,\"user_id\":1,\"title\":\"My First Post\",\"content\":\"Hello, World!\",\"created_at\":\"2023-04-24T12:45:67Z\",\"updated_at\":\"2023-04-24T12:45:67Z\"}再度、PostgreSQLの中身を確認します。SELECT * FROM posts;作成した記事がテーブルに存在することを確認できます。 id | user_id |    title     |    content    |         created_at         |         updated_at----+---------+--------------+---------------+----------------------------+----------------------------  1 |       1 | My First Post| Hello, World! | 2024-05-30 01:45:67.890123 | 2024-05-30 01:45:67.890123(1 row)以上で、APIのテストとデータベースの確認が完了しました。さいごに以上が、GoとFiberを使ってCRUDができるAPIを作成し、PostgreSQLをバックエンドに利用する方法です。実際のアプリケーションでは、エラーハンドリングやバリデーションなどを追加し、より堅牢なAPIを作成することが重要です。また、認証や認可、ページネーション、フィルタリングなどの機能も必要になるでしょう。データベースのマイグレーションツールを使用して、テーブル構造の変更を管理することも忘れずに。本当に手癖でやってみただけです。楽しかったです。この記事を書いている時にはaikoを聴いていたのでプレイリストも共有です。open.spotify.com","link":"https://syu-m-5151.hatenablog.com/entry/2024/05/31/122850","isoDate":"2024-05-31T03:28:50.000Z","dateMiliSeconds":1717126130000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"自動化するならちゃんとエラーを出せ。想定しろ。不安になれ。","contentSnippet":"はじめに自動化やツール開発において、通常時に上手くいくのは当たり前です。大切なのは失敗を想定することです。自動化したツールがエラーも出さずに実行結果的にも成功してるので動いていると思っていたら、実は問題が発生していて泣いた経験は、多くの人にあるのではないでしょうか。エラーを出力し、適切に失敗させて、ログに記録することで、問題の早期発見と迅速な対応が可能になります。また、エラーが発生する可能性のある箇所を事前に想定し、適切に処理することで、ツールの信頼性と安定性が向上します。しかし、エラーハンドリングができていても、それだけでは不十分です。優れた自動化ツールは、環境の変化に柔軟に対応できるようにコードが設計されているべきです。また、自動化ツールの完成度を高めるには、エラーハンドリングだけでなく、保守性、拡張性、ユーザビリティなども考慮する必要があります。自動化ツールを開発する際は、常に不安を抱きながらコードを書くことが重要です。「もしこの部分が失敗したらどうなるだろう」「これで本当に大丈夫だろうか」と自問自答しながら、エッジケースを想定し、想定外のエラーが発生した場合の対策を講じておくことが求められます。本記事では、Golang とシェルスクリプトを例に、エラーハンドリングの具体的な方法や、自動化ツール開発における留意点のいくつかについて解説していきます。はじめにで触れた内容の一部については、詳細な説明を割愛していますので、ご了承ください。Golang でのエラーハンドリングGolang には例外機構はありませんが、関数の戻り値として error を返すのが一般的です。以下は、引数のバリデーションをして、想定外ならエラーを返す例です。type MyOption struct {    IsHoge bool    Fuga   int}func f(s string, o MyOption) error {    if !regexp.MustCompile(`^A-\\d{4,8}$`).MatchString(s) {        return fmt.Errorf(\"invalid argument: s must be in format A-\\\\d{4,8}\")    }    if o.IsHoge \u0026\u0026 o.Fuga == 0 {        return fmt.Errorf(\"invalid argument: o.Fuga is required if o.IsHoge is true\")    }    // 処理本体...    return nil}このように、関数の先頭で引数をバリデーションし、想定外ならエラーを返すようにしています。また、エラーメッセージは fmt.Errorf を使って生成しています。これは、エラーメッセージをフォーマットする際のベストプラクティスです。さらに、エラーが発生した場合は、適切にエラーを処理することが大切です。以下は、エラーをログ出力し、さらに上位の関数に返している例です。func doSomething() error {    err := f(\"A-1234\", MyOption{IsHoge: true, Fuga: 1})    if err != nil {        log.Printf(\"failed to call f: %v\", err)        return fmt.Errorf(\"failed to do something: %w\", err)    }    // 処理続行...    return nil}ここでは、f 関数でエラーが発生した場合、ログ出力をしつつ、fmt.Errorf を使ってエラーをラップして返しています。%w は Go 1.13 から導入された Wrapping Verb で、元のエラーを内包した新しいエラーを生成します。これにより、エラーの因果関係が明確になり、デバッグがしやすくなります。シェルスクリプトでのエラーハンドリングシェルスクリプトでも、コマンドの実行結果を適切にチェックし、エラーを検出することが重要です。以下は、コマンドの実行結果をチェックする一般的なパターンです。some_commandif [ $? -ne 0 ]; then    echo \"some_command failed\"    exit 1fi$? は直前のコマンドの終了ステータスを表す特殊変数です。0 であれば成功、0 以外であればエラーを表します。また、あるコマンドの実行結果を別のコマンドにパイプで渡す場合、パイプラインの途中でエラーが発生してもシェルスクリプトは中断されません。これを防ぐには、以下のようにします。set -o pipefailsome_command | another_commandif [ $? -ne 0 ]; then    echo \"pipeline failed\"    exit 1fiset -o pipefail は、パイプラインのいずれかのコマンドが0以外の終了ステータスを返した場合、パイプライン全体の終了ステータスをそのコマンドの終了ステータスにするオプションです。外部リソースのエラーハンドリング自動化ツールでは、外部APIやデータベースへのアクセスが頻繁に行われます。これらの外部リソースは、ネットワークの問題などで必ず失敗する可能性があることを念頭に置く必要があります。Golang では、net/http パッケージを使った HTTP リクエストが一般的です。以下は、タイムアウトを設定し、レスポンスのステータスコードをチェックする例です。client := \u0026http.Client{    Timeout: 10 * time.Second,}resp, err := client.Get(\"https://3-shake.com/\")if err != nil {    return fmt.Errorf(\"failed to get: %w\", err)}defer resp.Body.Close()if resp.StatusCode != http.StatusOK {    return fmt.Errorf(\"unexpected status code: %d\", resp.StatusCode)}// レスポンスの処理...シェルスクリプトでは、curl コマンドがよく使われます。以下は、curl コマンドのエラーをチェックする例です。response=$(curl -s -w \"%{http_code}\" https://example.com/api/hoge)status_code=$(tail -n1 \u003c\u003c\u003c \"$response\")  # 最後の行がステータスコードbody=$(sed '$d' \u003c\u003c\u003c \"$response\")  # 最後の行以外がレスポンスボディif [ $status_code -ne 200 ]; then    echo \"unexpected status code: $status_code\"    exit 1fi# レスポンスの処理...-s オプションでサイレントモードにし、-w \"%{http_code}\" でレスポンスのステータスコードを出力しています。デバッグをできるようにするデバッグから逃げてはいけません。問題が発生した際に、どこで何が起きているのかを把握できることは重要です。シェルスクリプトでは、bash -x オプションを使うことでデバッグ出力を有効にできます(他のシェルでも似たようなオプションがある)。このオプションを付けてスクリプトを実行すると、各コマンドが実行される前に、そのコマンドが表示されます。これにより、スクリプトのどの部分が実行されているのか、変数がどのように展開されているのかを確認できます。bash -x ./your_script.shGolang にも同様のデバッグ機能があります。delve というデバッガを使うことで、Golang プログラムのデバッグが可能です。delve を使えば、ブレークポイントを設定してプログラムを停止させ、変数の値を確認したり、ステップ実行したりできます。# delve のインストールgo get -u github.com/go-delve/delve/cmd/dlv# デバッグ実行dlv debug ./your_program.goデバッグ実行中は、break コマンドでブレークポイントを設定し、continue でプログラムを再開、next で次の行に進むなどの操作ができます。これらのデバッグ機能を活用することで、問題の原因をより迅速に特定できるようになります。まとめGolang では、関数の戻り値として error を返し、適切にエラーをハンドリングしよう。シェルスクリプトでは、コマンドの終了ステータスをチェックし、パイプラインのエラーにも対処しよう。外部リソースは必ず失敗すると想定してコードを書こう。 タイムアウトの設定やエラーチェックを忘れずに。自動化は常に不安であり、モニタリングすることを忘れずに。デバッグから逃げるな。個人的に自動化に関してはエッジケースの処理を上手くやっていたりすると「オー」って思うのに問題がないので目立たないので今回は記事を書きました。しっかりと失敗することを想定することで、自動化ツールの信頼性と保守性は大きく向上します。 Golang とシェルスクリプトの両方で、エラーとうまく付き合っていきましょう。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/05/11/115518","isoDate":"2024-05-11T02:55:18.000Z","dateMiliSeconds":1715396118000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文","contentSnippet":"誕生日エントリー兼読書感想文です。www.amazon.jpはじめにクラウドコンピューティングの普及とマイクロサービスアーキテクチャの台頭により、システムの複雑性が増大しています。そのような中で、オブザーバビリティ(可観測性)の重要性が高まっています。本書「Cloud Observability in Action」は、クラウドネイティブなシステムにおけるオブザーバビリティの概念と実践方法を包括的に解説した一冊です。learning.oreilly.comオブザーバビリティとは、システムの外部から観測できる情報に基づいて、内部の状態を推論し理解する能力のことを指します。本書では、オブザーバビリティを投資対効果の観点から捉え、データの生成から収集、処理、可視化に至るまでのプロセス全体を俯瞰します。OpenTelemetryやPrometheus、Grafana、Loki、Jaegerなどのオープンソースツールを活用し、誰でも実践的な知見を時間以外の費用をかけずに得られるよう工夫されています。著者自身の豊富な経験に基づくベストプラクティスが随所に盛り込まれているのと参考になるURLをめちゃくちゃに共有してくれております、開発者やSREだけでなく、あらゆるクラウドネイティブ関係者にとって有益な内容となっています。単なるツールの使い方の解説にとどまらず、オブザーバビリティを組織文化として定着させるためのヒントも提供されています。本書を通して、オブザーバビリティの本質的な価値とその実現に向けた道筋を学ぶことができるでしょう。得られた知見をどのように活用するかは読者次第ですが、システムと組織の継続的な進化を支える原動力として、オブザーバビリティをバズワードとして盲目的に始めずに目を見開いてオブザーバビリティを捉える視座を得られるはずです。本稿では、各章の要点を丁寧に読み解きながら、私なりの学びと気づきをシェアしていきます。皆様にとっても、オブザーバビリティへの理解を深め、その実践への一歩を踏み出すきっかけとなれば幸いです。Cloud Observability in Action作者:Hausenblas, MichaelManningAmazonこの本の構成本書「Cloud Observability in Action」では、クラウドネイティブなシステムにおけるオブザーバビリティの概念と実践方法が包括的に解説されています。第1章ではエンドツーエンドの例が示され、ソースからエージェント、宛先までの用語が定義されているとともに、可観測性の文脈におけるユースケース、役割、課題について説明されています。第2章ではログ、メトリック、トレースといったさまざまなテレメトリ信号タイプと、それらの使い分け方、収集方法、コストと利点について述べられています。第3章ではテレメトリが生成される信号ソースについて、種類や選択方法、インストルメントコードの扱い方が解説されています。第4章ではOpenTelemetryを中心に、ログルーターからのさまざまなテレメトリエージェントが紹介されています。第5章では、Prometheusなどの時系列データベースやClickHouseなどの列指向データストアを例に、テレメトリ信号のバックエンド宛先について学ぶことができます。第6章では可観測性フロントエンドについて、純粋なフロントエンドとオールインワンの選択方法が説明されています。第7章ではクラウドオペレーションの側面として、異常検知や過去の失敗からの学習、アラート、使用状況、コスト追跡について述べられています。第8章では分散トレースとマイクロサービスの理解・トラブルシューティングへの活用方法が、第9章では継続的なプロファイリングと開発者の生産性ツールを中心に開発者の可観測性について詳解されています。第10章ではサービスレベル目標の設定と消費者満足度の問題への対処方法が、第11章では単一の信号タイプでは解決できない課題と信号相関によるアプローチが取り上げられています。付録ではOpenTelemetry、Prometheus、Jaeger、Grafanaを使用した完全なエンドツーエンドの例が提供されています。Github Repositorygithub.com目次はじめにこの本の構成Github Repository目次1 End-to-end observabilityオブザーバビリティの定義と目的オブザーバビリティのコンポーネント具体例としてのマイクロサービスアプリ \"Sock Shop\"クラウドネイティブの課題とその解決オブザーバビリティはクラウドネイティブ時代の必須プラクティス2 Signal typesオブザーバビリティの3本柱ログ: 人間が読み解くテキストベースの出力メトリクス: 自動化された監視・分析に役立つ数値指標トレース: マイクロサービスの処理フローを可視化する収集する信号の選定とコスト管理オブザーバビリティを支える3本柱の理解と適切な運用が肝心3 Sourcesクラウドネイティブシステムにおける多様な信号源の理解と活用コンピューティング関連のソースの詳細ストレージ関連のソースの詳細ネットワーク関連のソースの詳細自身のコード関連の詳細4 Agents and instrumentationObservabilityにおけるAgentsとinstrumentationの役割意味論的規約の重要性自動計装と手動計装の使い分けOpenTelemetry collectorの役割と設定OpenTelemetryの柔軟性と拡張性パフォーマンスとリソース効率Observabilityの新しい標準としてのOpenTelemetry自動化と最適化の必要性Observabilityの継続的な改善5 Backend destinationsバックエンドの選択がObservabilityの成功を左右するシグナルタイプごとのバックエンドオプションカーディナリティの課題とカラムナーデータストアポリグロットバックエンドアーキテクチャ制約と誓約6 Frontend destinationsフロントエンドとオールインワンソリューションの役割オープンソースとコマーシャルオファリングの比較ツール選定の考慮事項シングルパネルオブグラスとデータ相関の重要性フロントエンドとオールインワンの選択プロセスObservabilityツールの継続的な評価と改善Observabilityの価値実現に向けて7 Cloud operationsインシデント管理のベストプラクティスアラート設計のポイントと継続的な最適化今後の課題8 Distributed tracing分散トレーシングでクラウドネイティブシステムを徹底的に可視化エンドツーエンドの可視化でシステムをホリスティックに理解分散トレーシングを成功に導く秘訣分散トレーシングの未来組織の分散トレーシングは俺と仲間で育ててる9 Developer observabilityDeveloper observabilityで開発者の生産性を加速するContinuous profilingの技術的側面に迫るプロファイルの保存と分析の課題に挑むあわせて6本にしてみる...10 Observability In ActionSLOでサービスの信頼性を定量化し、顧客満足度を高めるSLOの実装と運用における留意点サービスの継続的な改善の為のSLO11 Signal correlationシグナル相関で複雑なシステムの動作を俯瞰的に理解するOpenTelemetry、Jaeger、Grafanaを使ったメトリクスとトレースの相関シグナル相関の実装における課題と対策将来に向けたシグナル相関の可能性さいごに参考資料1 End-to-end observability本章「1 End-to-end observability」は、クラウドネイティブシステムにおけるオブザーバビリティ(観測可能性)の概念と重要性を詳しく述べています。Observability Engineeringについては読書感想文を書いているので合わせて読んでみてください。syu-m-5151.hatenablog.comオブザーバビリティの定義と目的オブザーバビリティとは、システムから取得できる信号に基づいて、そのシステムの内部状態を継続的に把握し、インサイトを得ることで、システムに影響を与える能力のことです。オブザーバビリティは単に監視(モニタリング)ツールを導入するだけでは不十分です。システムの外側から収集した情報を、そのままダッシュボードなどの可視化ツールに表示するのではなく、行動可能な洞察(アクショナブルなインサイト)を生み出すことが本質的な目的となります。つまり、観測対象のシステムの外側から情報を収集し、分析を行い、それらから具体的なアクション(行動)を引き出すプロセス全体を指します。クラウドネイティブの分散システムでは、システムを構成するコンポーネントが多数に分かれ、ネットワーク経由で相互に通信を行うため、従来のモノリシックなシステムに比べてシステム全体の状態把握が困難になります。このため、オブザーバビリティが非常に重要な役割を果たします。状況を\"飛ばず\"に把握し、適切な制御を行えるようになることで、以下のようなユースケースに対応できるようになります。コード変更の影響の把握: 新機能の追加やバグ修正によるシステム全体へのインパクト(パフォーマンスへの影響、副作用の発生、リソース使用量の変化など)をモニタリングし、必要な対処を行える。サードパーティ依存関係の監視: 自社のシステムが依存する外部API(決済サービス、ロケーションサービスなど)の可用性、健全性、パフォーマンスを把握し、問題が発生した際の対応を行える。ユーザー体験(UX)の測定: アプリケーションやサービスの応答性、信頼性をユーザーの視点から継続的に測定し、UXの維持・改善につなげられる。システムの健全性とパフォーマンスの追跡: システム全体のアップタイム、応答時間分布、障害の影響範囲(有償ユーザへの影響、無償ユーザへの影響、重要取引先への影響など)を継続的に監視できる。障害の影響範囲(ブラストレディウス)の特定: 障害発生時に、その障害がシステム全体にどの程度影響を与えているのか(ブラストレディウス)を特定できる。さらに根本原因を絞り込み、Kubernetesコントロールプレーン、データプレーン、VMなどの障害発生場所を特定できる。サービスの最適化: サービスのパフォーマンス、リソース使用量、コスト、応答時間などを定量的に測定し、ボトルネックの特定や最適化を行える。開発者生産性の向上: アプリケーションコードのプロファイリングやログ解析などを通じて、パフォーマンスの問題箇所や冗長なコードの特定が可能になり、適切にコード改善を行うことで開発者の生産性を高められる。アクセスとコンプライアンスの監査: 様々なサービスやデータへのアクセス権限を自動的に追跡し、不正アクセスを検知できる。さらに監査証跡を残すことで、規制当局からの検査に備えられる。オブザーバビリティの目的は、上記のようなユースケースに対して、システムの状況をデータドリブンに把握し、適切な対処を迅速に行えるよう支援することにあります。単なるモニタリングツールの導入ではなく、収集した様々な種類の情報から総合的かつ根本的な理解を得て、それに基づいてアクションを起こすことが重要となります。オブザーバビリティのコンポーネントオブザーバビリティを実現するためには、さまざまなコンポーネントが関係してきます。これらのコンポーネントが有機的に連携し、それぞれの役割を果たすことで、オブザーバビリティが実現されます。主なコンポーネントは以下の通りです。システム(System under observation): 観測対象となるクラウドネイティブアプリケーションやプラットフォーム全体信号(Signals): システムから外部に出力される、以下の3種類の情報ログ: アプリケーションの動作履歴をプレーンテキストで記録した情報。エラーメッセージや例外の詳細情報などが含まれる。メトリクス: アプリケーションの運用状況を数値で表した指標。CPU使用率、メモリ使用量、リクエスト処理時間、エラー率などのデータ。トレース: 個々のリクエストがシステムの各コンポーネントを通過する際の、処理フローと時間情報の記録。サービス間の呼び出し関係と、それぞれの処理にかかった時間を特定できる。ソース(Sources): アプリケーションコード、データベース、メッセージキュー、クラウドプロバイダのマネージドサービスなど、信号を生成するコンポーネント。エージェント(Agents): 信号を収集し、前処理やルーティングを行う役割。例えばFluentBitはログのエージェント、OpenTelemetry Collectorはメトリクス/トレースのエージェントとして機能する。宛先(Destinations): ダッシュボード、アラートシステム、長期ストレージ、分析ツールなど、信号を消費し可視化/分析を行う場所。Telemetry: 信号をソースから収集し、エージェントを経由して前処理や分割を行った後、宛先に送信するプロセス全体のこと。fluentbit.io以下の図はこれらのコンポーネント間の関係を視覚化しています。Figure 1.1 Observability overview より引用オブザーバビリティは一方通行のプロセスではなく、フィードバックループを形成しています。例えば、人間がダッシュボードから情報を得て再起動のアクションを取ったり、アプリケーションがメトリクスに基づいて自動スケーリングを行ったりと、収集した信号に基づいてシステムに影響を与えることになります。様々な信号を組み合わせて分析することで、より深いシステムの理解につながり、適切なアクションを起こすことができます。単一の信号からは得られない総合的なインサイトを、信号間の相関によって引き出すことが可能になります。具体例としてのマイクロサービスアプリ \"Sock Shop\"本章では、Weaveworksが公開しているマイクロサービスアプリケーション\"Sock Shop\"を具体例に、オブザーバビリティの実践を説明しています。Sock Shopは、Spring Boot、Go kit、Node.jsなど複数の言語・フレームワークを用いて構築された、オンラインストアのデモアプリです。kakakakakku.hatenablog.comDocker コンテナイメージに格納されており、Kubernetes などのコンテナオーケストレーターで実行できます。Figure 1.2 The example microservices app we use for observability exploration より引用本章では、このアプリを実際にKubernetes上で起動し、それぞれのコンポーネントが出力するログやメトリクスの具体例が紹介されています。ログの例(ソース: ordersサービス)Javaで実装されたSpring Bootベースのマイクロサービスから出力されるログが示されています。ログを有効に活用するには、FluentBitなどのエージェントを使ってOpenSearch や CloudWatch などの宛先にルーティングする必要があります。メトリクスの例(ソース: frontendサービス)フロントエンドのNode.jsサービスから出力されるメトリクスがPrometheus形式で示されています。メトリクスを収集するには、Prometheus自身かOpenTelemetry Collectorなどのエージェントが必要です。長期保持のためにはCortexやThanosなどの宛先を用います。このようにSock Shopは、実際にクラウドネイティブなマイクロサービスアプリケーションが出力する様々な信号を確認できる題材として使われています。github.comさらに、トレースについても簡単に触れられており、リクエストの実行フローの可視化や、各サービスの処理時間、ステータスなどを確認できるとされています。オブザーバビリティを実現するには、Jaeger、Zipkin、AWS X-Rayなどのトレーシングツールの導入が必要になります。クラウドネイティブの課題とその解決クラウドネイティブなシステムには、従来のモノリシック構成のシステムとは異なる以下のような課題があり、オブザーバビリティがその解決を助けます。分散システム: コンポーネントが分散し、ネットワーク経由で疎結合に結ばれているため、システム全体を把握することが難しい。モノリシックな構成に比べ、システムの\"見えづらさ\"が高まる。コンポーネントの場所の重要性: リクエストを処理する各コンポーネントの実行場所(ノード、アベイラビリティーゾーン、リージョンなど)が、パフォーマンスやレイテンシーに大きく影響する。場所情報の重要性が増す。コンポーネントの頻繁な入れ替えと揮発性: マイクロサービスのコンポーネントやKubernetesのPod、Lambda関数バージョンの入れ替えが非常に頻繁に行われ、さらにIPアドレスも動的に変化するなど、システム構成の揮発性が高まる。これらの課題に対して、オブザーバビリティは以下のように貢献します。全ての関連する信号を自動収集し、アクションに結びつける手段を与えるシステムを\"飛ばず\"に把握し、状況に応じた適切な制御を行えるようになる。ログ、メトリクス、トレースなど複数の信号を収集・分析することで、システムへの深い理解を得られる。信号間の相関により、単一の信号からは得られない総合的な把握が可能になる異なる種類の信号を組み合わせることで、より包括的な視点が得られる。例えばメトリクスの異常からトレースにドリルダウンし、さらにログを確認することで、障害の原因を徹底的に追究できる。オープンスタンダードとオープンソースの採用によりポータビリティが確保され、特定のベンダーやプラットフォームへのロックインを回避できる例えば、OpenTelemetryを用いてアプリケーションに計装を行えば、後からデータ収集の宛先を柔軟に変更可能になる。異なるクラウドプロバイダ間や、オンプレとクラウドをまたいでも同じ方式が適用できる。一方で、オブザーバビリティの導入と運用には以下のようなコストがかかります。計装の開発者の労力アプリケーションコードにロギングやメトリクス、トレーシングの計装を行う必要があり、継続的な労力を要する。信号(ログなど)の保持コスト長期保持が必要なログなどの信号データを保存する、ストレージ費用が発生する。エージェントや計装自体の計算リソースオーバーヘッド信号収集やルーティングを行うエージェントプロセス自体に、一定のCPU/メモリリソースが必要になる。ネットワーク使用量に応じたコスト収集された信号のデータ転送に伴うネットワークトラフィックの費用も考慮しなければならない。これらのコストに見合うだけの投資対効果があるかどうかを、個々の状況において適切に判断する必要があります。効果の測定として、オブザーバビリティツールの導入前後での障害からの平均復旧時間(MTTR)の改善を確認するのが一般的です。その他、開発者のストレス軽減やワークライフバランスの向上など、定性的な効果も期待できます。Return on Investment Driven Observability では、この投資対効果について詳しく議論されています。本書では、教育的な観点から、ログ、メトリクス、トレースといった概念の境界線に沿って解説を進められています。しかし、実際の現場では、これらの概念が混在していることが多いです。プロジェクトやプロダクトが成熟するにつれ、スコープが広がり、概念の切り分けが難しくなるのです。例えば、ログデータの中にメトリクスとして活用できる情報が含まれていたり、トレースデータからログ的な情報を抽出したりすることがあります。また、これらの概念を組み合わせて、より高度な分析や監視を行うこともあるでしょう。本書を活用する際は、このような教育的な側面と実践的な側面のバランスを意識していただければと思いました。概念の境界線を理解することは重要ですが、同時に現場での柔軟な適用も必要不可欠です。本書で得た知識を基礎として、実際のプロジェクトやプロダクトの文脈に合わせて応用していくことが求められます。オブザーバビリティはクラウドネイティブ時代の必須プラクティスオブザーバビリティは、クラウドネイティブな分散システムを効果的に運用する上で不可欠なプラクティスと言えます。システムから出力される様々な信号(ログ、メトリクス、トレース)を収集し、相関させることで、システム全体の状況を多角的に把握し、適切な対処を迅速に行えるようになります。しかしながら、オブザーバビリティの導入と運用には一定のコストがかかります。計装の労力、データ保持コスト、リソースオーバーヘッド、ネットワークトラフィックなどです。これらのコストに見合うだけの効果(MTTRの改善、開発者の生産性向上など)があるかを、個別のユースケースにおいて検討する必要があります。オープンスタンダードとオープンソースのツールを適切に選択・活用することで、特定のベンダーにロックインされるリスクを回避でき、ポータビリティを確保できます。例えばOpenTelemetryはその好例です。オブザーバビリティは、単なるモニタリングツールの導入ではなく、システムへの深い理解を得て、適切なアクションにつなげるための実践的な取り組みです。クラウドネイティブ時代において、ソフトウェアエンジニアやSREが理解しておくべき重要な概念であり、実務で実践していく必要があります。syu-m-5151.hatenablog.com2 Signal typesオブザーバビリティの3本柱クラウドネイティブな分散システムを効率的に監視・運用するためには、ログ、メトリクス、トレースという3つの主要な信号タイプを適切に組み合わせたオブザーバビリティが不可欠です。本章では、それぞれの信号タイプについて詳しく解説されており、その特徴、計装の方法、コスト、利点、オブザーバビリティへの貢献などが丁寧に説明されています。さらに、実際のサンプルアプリケーションを用いた具体例を通して、各信号タイプの収集・可視化方法が示されており、監視システムの構築に役立つ実践的な知見が提供されています。ログ: 人間が読み解くテキストベースの出力ログはアプリケーションの動作履歴やエラー情報などをテキストで記録したものです。開発者がバグの特定を行ったり、SREが障害の原因を追跡する際に、ログの存在は非常に重要です。近年では構造化データ形式(JSONフォーマットなど)を用いたログが主流となり、コンテキスト情報(ラベル)を付与することで検索性や相関性が向上しています。本章ではGoの logrus ライブラリを使って、サンプルアプリケーションに構造化ログの出力機能を追加する例が示されています。github.com出力されたログは FluentBit エージェントによって収集され、 Loki へ転送されます。GrafanaでLokiのデータソースを設定してを、Lokiを使ってログを可視化・探索することができます。grafana.comログには計装のための開発コストや、大量のログデータを保持するためのストレージコストがかかります。しかし、大半の開発者に理解されており、プログラミング言語の標準ライブラリでサポートされているのがログの大きな利点です。保持コストを抑えるには、データの温度(アクセス頻度)に応じて適切な保持期間を設定することが重要です。ホットデータ: 直近のログであり、即座にアクセス可能で高速な検索性が求められる(数日〜数週間程度)ウォームデータ: すぐには必要ないが将来的に参照する可能性のあるログ(数ヶ月〜数年程度)コールドデータ: アクティブには使わないが規制上保持が義務付けられているログ(長期保持用のオブジェクトストレージなどに格納)ログは人間が読み解くことを前提とした信号タイプですが、近年では Promtail のようなエージェントによる構造化ログの収集や、Lokiのようなデータストアでのラベルベース検索が可能になってきました。一方で完全にテキスト検索に頼らず、トレースへの移行を推奨する意見 (https://arxiv.org/abs/2303.13402) もあり、ケースバイケースでの適切な選択が重要になってくるでしょう。grafana.comメトリクス: 自動化された監視・分析に役立つ数値指標メトリクスは定期的にサンプリングされる数値の指標であり、システムやアプリケーションの状態を数値で表します。CPU使用率、メモリ使用量、リクエスト処理時間、エラー率など、ほとんどの監視対象項目はメトリクスとして表現できます。メトリクスの大きな利点は、数値であるがゆえに自動化された監視・分析が可能になることです。本章ではGo製アプリケーションにPrometheus Client Libraryを使ってメトリクスの出力機能を追加し、エラー率のメトリクスを計算するコードが紹介されています。github.comこのアプリから出力されるメトリクスは Prometheus エージェントによって収集され、GrafanaでPrometheusのデータソースを設定して、Prometheusを使ってメトリクスを可視化・分析します。grafana.comメトリクスの計装コストは自動化の恩恵を受けられるケースが多く、比較的低コストです。プログラミング言語の標準ライブラリやミドルウェアによる自動計装の機能が増えてきており、手動での計装コストも限定的です。一方で、指標の種類が増えるとカーディナリティ爆発の問題が発生する可能性があります。例えばユーザーIDをメトリクスのラベルに含めると、大量のユーザーがいる場合に膨大な種類の指標が生成されてしまいます。このようなカーディナリティの高いメトリクスを時系列データベースで保持・検索しようとすると、パフォーマンスが極端に低下する恐れがあります。そのため、収集するメトリクスの種類を限定する、オートプルーニングを行うなど、適切なカーディナリティ管理が重要になります。また、大量のメトリクスデータを長期保持する際には、データ圧縮や集約が必須です。Cortex や Thanos のようなシステムが、スケーラブルなメトリクス長期保存のためのベストプラクティスを提供しています。収集するメトリクスの種類、保持期間、データ形式などを検討する必要があります。メトリクスの主な利用シーンとしては以下が挙げられます。ダッシュボード表示: CPU使用率や処理レイテンシーなどをリアルタイムにモニタリングするアラート発報: メトリクスの閾値超過を検知し、自動的にアラートを通知する自動スケーリング: リクエスト数などのメトリクスに基づいてリソースを動的に拡張/縮小するSLI/SLO監視: サービスレベルインディケータ(SLI)としてのメトリクスを使い、合意された目標水準(SLO)の達成状況をモニタリングするアノマリー検知: 機械学習で正常値の範囲を予測し、異常値を検出するメトリクスはオブザーバビリティを実現する上で中心的な役割を担う信号タイプです。数値指標であるがゆえに自動化が容易であり、リアルタイムな監視だけでなく長期的なトレンド分析や容量計画にも活用できます。トレース: マイクロサービスの処理フローを可視化するトレースは分散システムにおけるリクエストの処理フローを可視化する手段です。マイクロサービスアーキテクチャを採用する上で、そのコンポーネント間の呼び出し関係を把握することは非常に重要です。トレースはリクエストに固有のIDを割り当て、各サービスでの処理時間とステータスを記録することで、そのリクエストの実行フローを可視化します。本章では OpenTelemetry Go ライブラリ を使って、サンプルアプリケーションにトレーシングの機能を追加する例が示されています。github.com生成されたトレースは Jaeger によって収集・可視化されており、GrafanaでJaegerのデータソースを設定して、JaegerのTrace Viewを見ることができます。grafana.comトレースの計装コストは比較的高めですが、マイクロサービス間の呼び出し関係の可視化やボトルネックの特定に役立つため、分散システムを運用する上では非常に重要です。一方で、大量のトレースデータを保持するためのストレージコストや、リクエストへのコンテキスト伝搬によるパフォーマンスオーバーヘッドにも注意が必要です。トレースデータを保存するためのストレージとしては以下のようなアプローチが一般的です。専用のデータストア (ClickHouseなど)NoSQLデータベースを活用 (Cassandra、HBase、Elasticsearchなど)オブジェクトストレージとクエリエンジン (Grafana Tempoなど)各アプローチにはトレードオフがあり、データ量、検索パフォーマンス、コストなどの要件に合わせて適切なものを選択する必要があります。トレースの主な利用シーンは以下のようになります。レイテンシーの特定: リクエスト処理の遅延箇所を特定し、パフォーマンスの最適化を行うデバッグ支援: 本番環境での障害発生時に、該当リクエストのトレースを参照してルート原因を特定するアーキテクチャ可視化: サービスマップやサービス間の呼び出し関係を把握し、アーキテクチャの改善に活かすこのようにトレースは、マイクロサービスアーキテクチャにおける処理フローの可視化を実現する上で非常に重要な役割を担っています。SREやオンコール担当者がインシデント発生時の初動対応を行う際に活用されることも多くなってきています。収集する信号の選定とコスト管理本章の終盤では、オブザーバビリティを実現するために収集すべき信号の選定と、コストコントロールに関する考え方が説明されています。アクションにつながるインサイトを生むか、適切な保持期間が設定できるか、ROI(投資対効果)を考慮する必要があります。具体的な指針は以下の通りです。収集する信号がアクションにつながるインサイトを生み出すか? 単にノイズになるだけの信号は避けるべき信号の保持期間をどう設定するか? タスクや業界の規制に合わせて適切に決めるメトリクスの正常な値範囲(ベースライン)を設定し、異常検知に活用する信号の過剰収集は避け、ROIを意識する 保持するメリットが不明確な信号はコストの無駄収集する全ての信号で一貫したラベル付けを行う 相関性の確保に役立つこのように、オブザーバビリティを実現するためには信号の選別と、収集・保持に伴うコスト管理が重要になってきます。収集しすぎても意味がありませんし、重要な情報が欠落していても目的が果たせません。用途に合わせて 適切な種類の信号を適切な量だけ収集する という観点が欠かせません。オブザーバビリティを支える3本柱の理解と適切な運用が肝心ログ、メトリクス、トレースは、クラウドネイティブな分散システムのオブザーバビリティを実現する上で、それぞれ異なる役割を担う重要な3つの信号タイプです。ログはテキストベースの出力であり、人間が読み解いて状況を把握したりデバッグを行う際に役立ちます。メトリクスは数値の指標であり、自動化された監視・分析や、アラート発報、自動スケーリングなどに適しています。トレースはマイクロサービス間の処理フローを可視化する手段であり、分散システムを運用する上で欠かせません。各信号タイプにはそれぞれ長所と短所があり、3つの信号を組み合わせて収集・活用することで、システム全体の状況を多角的に把握できるようになります。しかし、それぞれに計装コストや保持コスト、リソース消費などのオーバーヘッドがあるため、収集する信号とその収集方法については、ユースケースごとのコストとROIを考慮する必要があります。本章ではサンプルアプリを使った具体例を交えながら、各信号タイプの特徴や計装の方法、Fluentbit、Promtail、Prometheusなどの収集エージェントの利用方法、GrafanaやLoki、Jaegerなどの可視化ツールの活用例が解説されています。これらの知見は監視システムの構築や運用を検討する上で参考になるはずです。ソフトウェアエンジニアやSREは、3つの信号タイプの特性を理解した上で、システムの要件に合わせて最適な組み合わせと収集方法を選択し、効率的なオブザーバビリティの実現を目指す必要があります。 信号の過剰収集に陥らず、ラベル付けの統一や信号間の相関性の確保など、コストを抑えながら有用な情報を得られる適切な運用が何より重要になります。オブザーバビリティの実現には、これら3つの主要な信号タイプを適切に組み合わせた上で、効果的な収集と活用を行うことが不可欠です。各信号タイプには一長一短があり、単独では十分なオブザーバビリティを得ることはできません。ログは人間が読み解くためのテキスト出力ですが、構造化の進展により自動分析の機会も増えてきました。しかしマイクロサービスアーキテクチャにおいては、処理フローの可視化という点でトレースに一部の役割が移行しつつあります。用途に応じてログとトレースを使い分ける必要があります。一方、メトリクスは数値指標のため自動化が容易であり、リアルタイムの監視だけでなく長期的な分析や容量計画にも活用できます。ただし、メトリクスの種類が増えるとカーディナリティ爆発のリスクがあり、適切なカーディナリティ管理が欠かせません。また、大量データの長期保持にはデータ圧縮や集約が必須になります。トレースはマイクロサービス間の処理フローを可視化するため、分散システムの運用では欠かせません。一方で、計装コストが高く、大量データの保持やコンテキスト伝搬によるパフォーマンスオーバーヘッドにも留意が必要です。ストレージの選択では、データ量やパフォーマンス要件、コストを考慮する必要があります。このように、オブザーバビリティを実現するには、3つの信号タイプそれぞれの長所と短所を理解した上で、システムの要件に合わせて最適な組み合わせと収集方法を選択することが肝心です。信号の過剰収集は避け、ラベル付けの統一やコスト管理、信号間の相関性の確保など、効率的な運用が何より重要になります。収集する信号については、以下の点を考慮する必要があるとしています。アクションにつながるインサイトを生み出すか?適切な保持期間が設定できるか?メトリクスの正常値範囲(ベースライン)は設定できるか?ROI(投資対効果)を意識した収集が可能か?信号間で一貫したラベル付けができるか?ソフトウェアエンジニアやSREは、このような点に留意しながら、効率的なオブザーバビリティの実現に努める必要があります。本章で示された具体例は、実際の監視システム構築の参考になるはずです。コストを抑えつつ、有用な情報を効果的に収集・活用できる環境を整備することが求められます。3 Sourcesクラウドネイティブシステムにおける多様な信号源の理解と活用本章「3 Sources」では、クラウドネイティブシステムにおけるオブザーバビリティの実現に欠かせない、様々な信号源(ソース)について詳しく解説されています。コンピューティング、ストレージ、ネットワーク、そして自身のコードに至るまで、各ソースからの信号取得の重要性と注意点が丁寧に説明されており、オブザーバビリティの実践に向けた実用的な知見が提供されています。Figure 3.1 A spectrum of compute, infrastructure, and application level より引用この図はコンピューティングリソースをインフラストラクチャレベル(VM、コンテナなど)とアプリケーションレベル(マイクロサービスやモノリシックアプリなど)に分けて示しています。インフラストラクチャレベルの監視は主に運用者が関与し、アプリケーションレベルの監視は開発者が関与する、といった役割分担が一般的です。しかしながら実際のプロダクション環境では、これら2つのレベルが複合的に組み合わさっていることが多いため、様々なソースからの信号を包括的に収集・相関させる必要があります。Figure 3.2 Signal sources in Kubernetes より引用この図はKubernetesにおけるコントロールプレーンとデータプレーンから出力される様々な信号源を示しています。コントロールプレーンのコンポーネントであれば、主にログとメトリクス、一部でトレースが出力されます。一方のデータプレーンではアプリケーションコンポーネントからログ、メトリクス、トレースが出力されることが一般的です。単一のプロダクト内に多種多様な信号源が存在するため、ホリスティックなオブザーバビリティ対応が求められます。以上の通り、クラウドネイティブな分散システムにはさまざまな種類の信号源が存在し、それぞれ特有の注意点があります。ソフトウェアエンジニアやSREは、これら多様な信号源の存在を理解した上で、用途に応じて適切な手段を選択し、効率的なオブザーバビリティの実現を目指す必要があります。単一の手法に固執するのではなく、必要に応じて収集方法を使い分けながら、ホリスティックな可視化を実現することが肝心です。そのためには本章で解説された信号源に関する深い理解が不可欠だと思います。コンピューティング関連のソースの詳細VMについては、オペレーティングシステムレベルの情報が参照できる点が大きな利点です。本書ではJVMを例に挙げ、JVMはログ、ヒープメモリ使用量、スレッド数など様々なメトリクスを出力することが説明されています。実際のJVM監視ツールとしてはSematextの提供するガイドが紹介されています。JVMは豊富な信号源となり、開発者はこれらのメトリクスを活用してパフォーマンスチューニングやデバッグを行えます。コンテナの場合、コンテナランタイム自体と、コンテナ内で実行されるアプリケーションの両方から情報が出力されます。コンテナランタイムの例としてDockerデーモンが挙げられ、docker logsコマンドでコンテナログを参照できます。また、Dockerコンテナ内のアプリケーションも標準的にログを標準出力に出力するよう12ファクターアプリの設計思想に従います。コンテナランタイムのメトリクス収集には、cAdvisorやTelegrafのDockerプラグインが活用できます。開発者はアプリケーションログを参照し、運用者はコンテナランタイムのメトリクスを監視することで、それぞれの観点からコンテナの状況を把握できます。Kubernetesでは多岐にわたるコンポーネントから様々なシグナルが出力されるため、包括的な理解が重要になります。コントロールプレーンのコンポーネント(APIサーバー、etcd、kubeletなど)からはログ、メトリクス、監査ログ、トレース(APIサーバーのみ)が出力されます。一方のデータプレーンではアプリケーションからのログ、メトリクス、トレースが主な情報源となります。Figure 3.2がKubernetesにおける様々な信号源を示しています。本文中でも触れられているように、Kubernetesではログの取り扱いが分散されており、収集の仕組みを整備する必要があります。アプリケーションログはkubectl logsで一時的に参照できますが、本番環境では永続化が必須です。Fluentbit、Fluentdなどのエージェントを使ってクラウドプロバイダーのログ基盤に転送するのが一般的なパターンです。Kubernetesでは、ログに加えメトリクスとトレースにも注目が集まっています。メトリクスはPrometheus形式で出力されており、kubectl get --raw /metricsで参照できます。一方、トレースはOpenTelemetryを使ってAPIサーバーの動作を追跡できるよう、コミュニティによってサポートが進められています。ストレージ関連のソースの詳細RDBMSでは、パフォーマンスモニタリングにおいてクエリプランナーの動作を理解することが肝心です。PostgreSQLの場合はEXPLAINでプランを確認できますし、各種モニタリングツールでも詳細情報にアクセスできます。例えばpgMonitorなら待機リソースのボトルネックやクエリの履歴なども確認できます。ベンダー製品でも同様の情報を得られます。例えばAWS Redshiftでは、CPU、メモリ、ストレージの使用量など基本的なメトリクスに加え、明示的にスロークエリIDを確認できます。RDBMSではパフォーマンスの観点からクエリプランナーの動作を細かく監視することが重要ですが、NoSQLデータストアではアプローチが異なります。NoSQLデータストアでは、アクセスパターンやストレージレイアウトが重要な監視対象となります。例えば、キャッシュとしても使われるRedisであれば、メモリ使用量のメトリクスが有用です。一方でMongoDB(ドキュメントストア)では、ディスクIOパフォーマンスのメトリクスに注目する必要があります。本書ではElasticsearch(検索エンジン)の事例も紹介されており、背景にあるLuceneのインデックシングプロセスを監視する重要性が説明されています。このようにNoSQLではアクセスパターンに合わせて監視対象を適切に選定することが求められます。RDBMSやNoSQLデータストアのメトリクスを収集する手段としては、PostgreSQL Server ExporterやpgMonitor、クラウドベンダー製品の活用が挙げられています。自社運用の場合はPrometheusと組み合わせるといった方法もあり、より詳細なカスタマイズが可能です。一方でクラウドベンダー製品を利用すれば、運用の手間を大幅に削減できます。RDBMSとNoSQLでは監視の着眼点が異なるため、目的に合わせて適切な手段を選ぶ必要があります。ネットワーク関連のソースの詳細ネットワークデバイスからは大量のログが出力されます。そのためノイズを除去し、価値のある情報だけを抽出することが課題となります。例えばロードバランサーであれば、リクエストの送信元IPやパスに基づいてフィルタリングすると効率的なモニタリングが行えます。AWS ALBの場合は、リクエスト量、アクティブコネクション数、HTTPステータスコードなどのメトリクスが出力されます。ALB自体の稼働状況だけでなく、バックエンドへのトラフィック情報なども確認できるため、アプリケーションの挙動を多角的に監視することが可能です。より高度な運用では、リクエストコンテンツやレスポンスページのレンダリング時間などもモニタリング対象になりうるでしょう。VPNやVPCから得られる情報では、セキュリティモニタリングが主な用途となります。例えばVPC FlowLogsからSSHやRDPアクセスをモニターすれば、不正アクセスの検知に活用できます。そのほか送受信トラフィックのパターン分析を行えば、DDoS攻撃の検知なども可能になります。VPCフローログは全てのIPトラフィックを記録するため、ネットワークの可視化に役立つと同時に、ログ量が膨大になる点にも注意が必要です。用途に応じて適切にフィルタリングする必要があります。ネットワーク関連ソースは大量のノイジーなデータが出力されるため、フィルタリングやラベル付けが重要になります。ALBの場合はデプロイ単位や環境単位でリクエストにラベルを付与することで、効率的なモニタリングが可能となります。また、Kubernetesなどのオーケストレーターを利用する場合は、Ingressリソースなどの抽象化されたネットワーク構成から出力されるシグナルをモニターする必要があります。自身のコード関連の詳細オープンソースのOpenTelemetryは、ログ、メトリクス、トレースの各種信号をベンダーロックインなしに管理できる魅力的なスタンダードです。ただし既存のコードに計装を行うコストがあり、コストとベネフィットのトレードオフを考慮する必要があります。将来の再計装のコストを避けたいのであれば、OpenTelemetryを中心におき、自動計装を最大限活用するのがよいでしょう。一方でCI/CDパイプライン自体も重要な信号源となります。ここからデプロイ進捗や所要時間、テスト結果などのメトリクスが得られます。新しいビルドが発生する度にこれらのメトリクスを監視することで、パフォーマンスの変化やボトルネックを事前に検知できます。将来的にはDigmaやSprkl.devといった専用ツールを使った開発者向けオブザーバビリティも重要になってくるでしょう。特にIDE上でコード変更の影響を可視化したり、プロファイリングデータからボトルネックを特定する機能が期待されています。信号の収集対象として最後に挙げられているのがプロキシソースです。ここでは監視対象外だが監視が必要なコンポーネントに対し、プロキシサーバーを介することで情報収集を実現する方法が説明されています。Prometheusの場合はKafkaやIoTデバイスなど非対応コンポーネントからExporterを使ってメトリクスを収集できます。またPushgatewayではバッチジョブなど一過性のプロセスからもメトリクス収集が可能になります。この他にも、ミドルウェアのDockerネットワークドライバを使えばDockerコンテナからログやメトリクスを抽出できます。あるいはSysdigの機能を活用すれば、アプリケーションレベルからカーネル全体の実行状況を詳細に可視化できるでしょう。特にeBPFを利用したSysdigの監視機能は注目すべき点で、プロセス単位でのリソース消費を正確にトレースすることが可能になります。オブザーバビリティの実現には様々なアプローチが存在します。システムを包括的にオブザーバブルにするには、これらの多様な手段を組み合わせていく必要があります。プロキシソースの活用は強力ですが、各ソースで得られる情報が多すぎるとノイズになりかねません。一方で全くオブザーバブルでない領域が残れば、ブラインドスポットが生まれてしまいます。信号収集の目的とコストを見極め、的を絞って収集・活用を行う工夫が求められます。収集対象の信号は最小限に留め、メタデータの付与や集約を行うといった対策も重要になってくるでしょう。4 Agents and instrumentationObservabilityにおけるAgentsとinstrumentationの役割本章「Agents and instrumentation」は、Observabilityを実現するための重要な要素であるエージェントと計装について詳しく解説しています。著者は、従来のベンダー固有のエージェントやシグナル固有のエージェントと対比させながら、オープンソースの包括的なObservabilityフレームワークであるOpenTelemetryを紹介しています。全然、別件でLearning Opentelemetryの読書感想文を書いていたので合わせて読んでみてください。syu-m-5151.hatenablog.comOpenTelemetryは、仕様、SDK、プロトコル(OTLP)、エージェントから構成される一連のコンポーネントであり、ベンダーに依存せずにログ、メトリクス、トレース、将来的にはプロファイルを収集・処理・取り込むことができます。OpenTelemetryを使えば、シグナルの発生元(リソース属性)とテレメトリシグナル自体の両方について、豊富なメタデータを得ることができます。このメタデータには、各シグナルが生成されたサービス、ホスト、コンテナ、クラウドリソースなどの情報が含まれ、システムの動作を理解し、問題の根本原因を特定する上で非常に重要な役割を果たします。特に、大規模な分散システムでは、各コンポーネントが生成するログ、メトリクス、トレースを関連付けて分析することが不可欠です。OpenTelemetryは、これを可能にする強力なフレームワークであると言えます。OpenTelemetryが提供する豊富なメタデータと、統一された方法でデータを収集・処理する仕組みにより、複雑なシステムの動作を俯瞰的に把握することができます。意味論的規約の重要性また、著者は意味論的規約(semantic conventions)の重要性を指摘しています。OpenTelemetryでは、意味論的規約に基づいてテレメトリデータにメタデータを付与することで、バックエンドでの効果的な相関分析を可能にしています。例えば、トレースデータとログデータに共通の属性を付与しておくことで、特定のリクエストに関連するすべてのログを容易に検索・分析できます。こうした相関分析は、複雑な分散システムの動作を理解し、パフォーマンスの問題や障害の原因を特定する上で欠かせません。opentelemetry.io従来、テレメトリデータの相関分析は、各ベンダーやツールに固有の方法で行われてきました。しかし、OpenTelemetryの意味論的規約により、ベンダーに依存しない形で相関分析を行うことができるようになります。これは、マルチクラウド環境やマイクロサービスアーキテクチャを採用している組織にとって特に大きなメリットとなるでしょう。統一された方法でテレメトリデータを収集・処理できれば、システム全体の可視性が向上し、問題の迅速な特定と解決が可能になります。自動計装と手動計装の使い分け計装に関しては、**アプリケーションのコードを変更せずに自動的にテレメトリを生成する自動計装の重要性が強調されています。 speakerdeck.com**自動計装は、アプリケーションフレームワークやライブラリと連携して、HTTPリクエスト、データベースクエリ、外部サービス呼び出しなどの主要な操作を自動的にトレースします。これにより、開発者はアプリケーションのコードを変更することなく、システムの動作を可視化できます。Figure 4.5 Concept of OpenTelemetry collection (from upstream docs; https://opentelemetry.io/docs/reference/specification/logs/overview/) より引用自動計装は、Observabilityの第一歩として非常に重要な役割を果たします。特に、レガシーなアプリケーションや、コード変更が困難な場合には、自動計装が唯一の選択肢となることもあるでしょう。また、自動計装により得られるデータは、システムのベースラインを把握する上でも役立ちます。ただし、自動計装には限界もあります。アプリケーション固有のビジネスロジックに関連する情報は、自動計装では捕捉できないことが多いのです。そのため、より詳細な分析を行うには、OpenTelemetry SDKを使った手動計装が必要になります。手動計装では、開発者がアプリケーションのコードに直接計装を追加します。これにより、重要なビジネスメトリクスや、アプリケーション固有のイベントを収集することができます。例えば、電子商取引サイトであれば、注文処理の各ステップにおける所要時間や、注文金額などのメトリクスを収集することが考えられます。自動計装と手動計装は、相互に補完する関係にあります。自動計装でシステムの全体像を把握した上で、手動計装でより詳細な情報を収集するのが理想的です。両者を適切に組み合わせることで、システムの可視性を最大限に高めることができるでしょう。OpenTelemetry collectorの役割と設定OpenTelemetry collectorは、エージェントとしての中核的な役割を担っており、あらゆるソースからのテレメトリデータを収集し、フィルタリング、サンプリング、属性の追加などの処理を行った上で、様々なバックエンドシステムに転送します。これにより、OpenTelemetry collectorは、Observabilityデータのハブとして機能し、データの流れを集中管理することができます。OpenTelemetry collectorの設定は、YAMLを使って行います。設定ファイルでは、受信したテレメトリデータをどのように処理し、どの宛先に転送するかを定義します。各シグナルタイプ(メトリクス、トレース、ログ)ごとにパイプラインを設定し、パイプラインの各段階でレシーバー、プロセッサー、エクスポーターを組み合わせて使用します。Figure 4.6 The OpenTelemetry collector and its components より引用この柔軟な設定により、OpenTelemetry collectorは様々な環境に適応できます。例えば、オンプレミスとクラウドが混在する環境では、オンプレミスの既存システムからのデータをOpenTelemetry collectorで収集し、クラウドのバックエンドに転送するといった使い方が可能です。また、複数のバックエンドを併用している場合も、OpenTelemetry collectorを中心とすることで、データの流れを一元管理できます。ただし、OpenTelemetry collectorの設定には注意が必要です。適切なレシーバー、プロセッサー、エクスポーターを選択し、それぞれの設定を最適化しなければなりません。特に、大規模な環境では、データ量が膨大になることがあるため、フィルタリングやサンプリングの設定が重要になります。また、セキュリティの観点から、データの暗号化や認証の設定も欠かせません。著者は、OpenTelemetry collectorの具体的な設定例も提示しています。この例では、サンプルアプリケーション「ho11y」からメトリクスとトレースを収集し、Prometheusをメトリクスのバックエンドに、Jaegerをトレースのバックエンドに使用しています。Figure 4.7 Example OpenTelemetry pipeline for traces and metrics より引用設定ファイルでは、Prometheusレシーバーを使ってPrometheusフォーマットのメトリクスを収集し、OTLPレシーバーを使ってOTLPフォーマットのトレースを収集しています。収集したデータはバッチ処理された後、Prometheusエクスポーターを通じてPrometheusに、Jaegerエクスポーターを通じてJaegerに送信されます。このような設定例を参考にしつつ、自身の環境に合わせてOpenTelemetry collectorの設定を最適化していくことが求められます。設定ファイルのバージョン管理を行い、変更履歴を追跡できるようにしておくことも重要でしょう。また、設定の変更が及ぼす影響を事前にテストし、問題がないことを確認してから本番環境に適用するなど、慎重な運用が必要です。OpenTelemetryの柔軟性と拡張性OpenTelemetryの技術的な側面に目を向けると、その柔軟性と拡張性が際立っています。OpenTelemetryは、ネイティブなOTLPをサポートするだけでなく、Prometheus、Jaeger、Zipkin、Fluentdなど、既存の様々なフォーマットやプロトコルに対応するレシーバーとエクスポーターを提供しています。これにより、既存のシステムからOpenTelemetryへの移行を段階的に進められるほか、複数のバックエンドシステムを並行して利用することもできます。この柔軟性は、OpenTelemetryの大きな強みの一つです。従来のモニタリングツールやObservabilityプラットフォームは、独自のデータフォーマットやプロトコルを使用していることが多く、他のシステムとの連携が困難でした。しかし、OpenTelemetryなら、そうした既存のシステムともスムーズにデータをやり取りできます。これにより、ベンダーロックインを回避しつつ、既存の資産を活かしながら、Observabilityの向上を図ることができるのです。また、OpenTelemetryは、コミュニティ主導で活発に開発が進められているオープンソースプロジェクトです。ユーザーは、OpenTelemetryの機能拡張に自ら貢献することもできます。例えば、新しいレシーバーやエクスポーターを開発し、OpenTelemetryのエコシステムに追加することが可能です。こうしたコミュニティの力によって、OpenTelemetryは今後もさらに発展していくことが期待されます。パフォーマンスとリソース効率パフォーマンスの観点では、OpenTelemetry collectorのスループットとリソース使用量に注意を払う必要があります。大規模な環境では、多数のエージェントが生成する膨大なテレメトリデータを効率的に処理しなければなりません。そのため、collectorのパフォーマンスチューニングが重要になります。例えば、バッチ処理の設定を最適化することで、データ処理のスループットを向上させることができます。一方で、バッチサイズを大きくしすぎると、メモリ使用量が増大するため、適切なバランスを見出す必要があります。また、サンプリングを適用してデータ量を削減することも、パフォーマンス改善に効果的です。ただし、サンプリングによって情報が欠落するリスクがあるため、慎重な設定が求められます。リソース使用量の観点では、メモリ使用量の制御が特に重要です。OpenTelemetry collectorは、受信したデータをメモリ上に保持するため、データ量が増大するとメモリ使用量も増加します。これを放置すると、メモリ不足によってcollectorのパフォーマンスが低下したり、最悪の場合にはOOM (Out of Memory) キルによってプロセスが強制終了したりする可能性があります。こうしたリスクを回避するため、OpenTelemetry collectorにはメモリリミッタープロセッサが用意されています。メモリリミッタープロセッサを使用すると、メモリ使用量が一定のしきい値を超えた場合に、データの受信を一時的に制限したり、古いデータを削除したりすることができます。ただし、データの欠落が許容できないケースでは、十分なメモリリソースを確保する必要があります。また、OpenTelemetry collectorのパフォーマンスは、ホスト環境の影響も受けます。特に、コンテナ環境では、リソース制限の設定によってパフォーマンスが大きく左右されます。適切なCPUとメモリのリソース制限を設定し、必要に応じて縮退運転できるようにしておくことが重要です。パフォーマンスとリソース効率の最適化には、継続的なモニタリングが欠かせません。OpenTelemetry collectorの主要なメトリクス(CPU使用率、メモリ使用量、データ処理のレイテンシなど)を常に監視し、ボトルネックを特定して改善策を講じる必要があります。また、負荷テストを実施して、実際のピーク時の負荷に耐えられるかを確認しておくことも重要です。Observabilityの新しい標準としてのOpenTelemetry本章では、Observabilityの実現に向けて、エージェントと計装が果たす重要な役割が詳細に説明されました。特に、OpenTelemetryは、ベンダーロックインを回避しつつ、多様なテレメトリデータを統一的に扱うことができる画期的なフレームワークです。OpenTelemetryが提供する豊富なメタデータと意味論的規約は、システムの動作を深く理解し、問題の迅速な特定と解決に役立ちます。従来のモニタリングツールやObservabilityプラットフォームは、ベンダー固有のデータフォーマットやAPIを使用していたため、相互運用性に乏しく、複数のツールを併用するのが難しいという問題がありました。しかし、OpenTelemetryは、このような問題を解決し、Observabilityの新しい標準となる可能性を秘めています。OpenTelemetryが広く普及することで、異なるベンダーのツールやサービス間でシームレスにテレメトリデータをやり取りできるようになります。これにより、エンドツーエンドの可視化、ベンダーロックインの回避、既存システムとの統合が容易になるでしょう。また、OpenTelemetryのオープンなエコシステムは、イノベーションを促進し、Observabilityのベストプラクティスの共有を加速させるはずです。自動化と最適化の必要性自動計装と手動計装を適切に組み合わせることで、アプリケーションコードへの変更を最小限に抑えつつ、システムの可視性を高めることができます。自動計装は、Observabilityの基盤を素早く構築するのに役立ちます。一方、手動計装は、ビジネスに特化した重要なメトリクスを収集するのに欠かせません。ただし、計装を実施するだけでは不十分です。収集したテレメトリデータを効果的に活用するには、データのクリーンアップ、集計、相関分析など、一連のデータ処理が必要となります。OpenTelemetry collectorは、こうしたデータ処理を自動化し、最適化する上で重要な役割を果たします。特に、大規模で複雑なシステムでは、膨大なテレメトリデータが生成されるため、データの適切なフィルタリングとサンプリングが不可欠です。OpenTelemetry collectorの柔軟な設定により、環境に合わせたデータ処理を実現できます。また、セキュリティ、パフォーマンス、リソース効率など、運用上の要件を満たすように設定を最適化することも重要です。Observabilityの継続的な改善Observabilityは、一朝一夕で実現できるものではありません。システムの変化に合わせて、Observabilityの仕組みも継続的に改善していく必要があります。OpenTelemetryは、この継続的な改善を支援する強力なプラットフォームです。OpenTelemetryを活用することで、システムの変更に素早く適応できます。新しいサービスやコンポーネントを追加する際に、計装を自動的に適用できます。また、OpenTelemetryの柔軟なアーキテクチャにより、バックエンドのツールやサービスを段階的に入れ替えることも可能です。ただし、OpenTelemetryを効果的に活用するには、組織全体でのコラボレーションが欠かせません。開発者、運用チーム、セキュリティチーム、ビジネス関係者など、様々なステークホルダーが連携し、Observabilityの目標と戦略を共有する必要があります。また、Observabilityのベストプラクティスを継続的に学習し、実践していくことも重要です。5 Backend destinationsバックエンドの選択がObservabilityの成功を左右する本章「Backend destinations」では、Observabilityデータの保存と分析を担うバックエンドの重要性について詳しく解説されています。著者は、適切なバックエンドの選択が、Observabilityの取り組みの成功を大きく左右すると強調しています。opentelemetry.ioバックエンドは、収集されたログ、メトリクス、トレースなどのテレメトリデータを保存し、それらのデータに対するクエリやアラートの実行、ダッシュボードの作成などを可能にする中核的なコンポーネントです。バックエンドの機能性、パフォーマンス、スケーラビリティ、信頼性は、Observabilityシステム全体の有効性に直結します。したがって、自社のニーズや要件に合ったバックエンドを選択することが極めて重要です。著者は、バックエンドの選定において考慮すべき主要な基準として、コスト、オープンスタンダードのサポート、バックプレッシャーへの対応、カーディナリティとクエリのパフォーマンスなどを挙げています。コストの観点では、データの取り込み、保存、クエリに関連する直接的なコストに加えて、エンジニアリングチームのサポート、トレーニング、セキュリティパッチ適用などの間接的なコストも考慮する必要があります。オープンスタンダードのサポートは、ベンダーロックインを回避し、相互運用性を確保するために重要です。OpenTelemetryやOpenMetricsなどの業界標準への対応は、バックエンドの選定において重要な基準となります。バックプレッシャーへの対応は、大量のテレメトリデータを生成するソースからのデータ取り込みを安定的に行うために不可欠です。バックエンドとソース間にキューイングメカニズムを導入することで、バックプレッシャーに起因するデータ欠損や性能低下を防ぐことができます。カーディナリティとクエリのパフォーマンスは、特にメトリクスデータを扱う際の重要な考慮事項です。次元の値が大きく変動するメトリクスは、時系列データベース(TSDB)におけるカーディナリティの爆発を引き起こす可能性があります。カラムナーストレージを採用したClickHouseやDruidなどのデータストアは、高カーディナリティのメトリクスにも対応できます。シグナルタイプごとのバックエンドオプション本章では、ログ、メトリクス、トレースのそれぞれのシグナルタイプに適したバックエンドオプションについて、クラウドプロバイダー、オープンソース、商用の観点から詳しく解説されています。ログのバックエンドでは、Amazon CloudWatch Logs、Azure Monitor Logs、Google Cloud Loggingなどのクラウドプロバイダーのサービスや、Elasticsearch、OpenSearch、Grafana Lokiなどのオープンソースソリューション、Splunk、Instana、Logz.ioなどの商用製品が紹介されています。これらのログバックエンドは、インデックス付きの全文検索、構造化クエリ、アラート、ダッシュボードなどの機能を提供します。ログデータのボリュームが大きい場合や、長期的な保存が必要な場合は、コストとパフォーマンスのバランスを考慮してバックエンドを選択する必要があります。クラウドプロバイダーのサービスは、マネージドな環境で手間のかからない運用が可能ですが、コストが高くなる傾向があります。一方、オープンソースソリューションは、自前での運用が必要ですが、コストを抑えることができます。Figure 5.2 Time series database concept, showing N time series of the mysvc_http_request_total metric より引用メトリクスのバックエンドとしては、時系列データベース(TSDB)が主流です。PrometheusやInfluxDBなどのオープンソースのTSDBに加え、各クラウドプロバイダーのマネージドPrometheusサービスや、M3DB、VictoriaMetricsなどのスケーラブルなソリューションが注目されています。TSDBは、メトリクスデータの効率的な格納と、時間範囲やラベルに基づくクエリを可能にします。PrometheusはKubernetesエコシステムにおける事実上の標準となっており、多くのツールやサービスとの統合が進んでいます。一方、M3DBやVictoriaMetricsは、Prometheusとの互換性を保ちつつ、よりスケーラブルなアーキテクチャを提供します。トレースのバックエンドは、JaegerやZipkinなどのオープンソースプロジェクトが広く採用されている一方で、クラウドプロバイダーやObservabilityベンダーの商用ソリューションも充実しています。ElasticsearchやOpenSearchもトレースのバックエンドとして使用できます。トレースデータは、分散システムにおけるリクエストの流れを可視化し、パフォーマンスのボトルネックや異常を特定するために使用されます。Jaegerは、OpenTelemetryとの緊密な統合により、幅広いプログラミング言語やフレームワークをサポートしています。商用ソリューションは、AIを活用した自動的な異常検知やパフォーマンス最適化の提案など、高度な分析機能を提供します。cloud.google.comカーディナリティの課題とカラムナーデータストア本章では、メトリクスのバックエンドを選択する際の重要な考慮事項として、カーディナリティの問題が取り上げられています。カーディナリティとは、メトリクスの各次元が取り得る値の数を指します。ユーザーIDやセッションIDのように、値が大きく変動する次元を持つメトリクスを扱う場合、TSDBではカーディナリティの爆発が発生し、データの取り込み、保存、クエリのパフォーマンスに深刻な影響を与える可能性があります。この課題に対処するために、著者はカラムナーストレージを採用したデータストアの活用を提案しています。カラムナーストレージは、データを列単位で格納することで、高いデータ圧縮率と優れたクエリパフォーマンスを実現します。Apache Cassandra、Apache Druid、ClickHouse、Snowflakeなどが代表的なカラムナーデータストアとして紹介されています。Figure 5.5 Row-oriented vs. column-oriented storage より引用特に、ClickHouseを使ったログのバックエンドの例では、OpenTelemetry CollectorとClickHouseを組み合わせることで、ログデータをカラムナーフォーマットで効率的に保存し、SQLを使って柔軟にクエリできることが示されています。github.comカラムナーストレージは、高カーディナリティのメトリクスだけでなく、ログやトレースデータの保存と分析にも適しています。ログデータは、多様な構造を持つイベントの集合体であり、カラムナー形式での保存により、クエリのパフォーマンスを大幅に向上させることができます。トレースデータも、スパンのフィールドを列として保存することで、効率的なクエリが可能になります。カラムナーデータストアは、Observabilityデータの長期的な保存と分析において重要な役割を果たします。データレイクとしてのカラムナーストレージに、ログ、メトリクス、トレースを統合することで、包括的な分析と相関関係の発見が可能になります。また、カラムナー形式のデータは、機械学習やデータマイニングのワークロードにも適しており、異常検知やパターン認識などの高度な分析にも活用できます。ポリグロットバックエンドアーキテクチャObservabilityデータの種類や特性に応じて、複数のバックエンドを組み合わせて使用するポリグロットなアプローチも有効です。例えば、ログデータにはElasticsearch、メトリクスデータにはPrometheus、トレースデータにはJaegerを使用するといった構成が考えられます。ポリグロットバックエンドアーキテクチャは、各シグナルタイプに最適化されたバックエンドを選択することで、パフォーマンスとコスト効率を最大化できます。一方で、異なるバックエンド間でのデータの相関分析や一貫性の確保が課題となります。この課題に対処するために、OpenTelemetryなどの共通の収集および転送層を導入することが推奨されます。OpenTelemetryは、ログ、メトリクス、トレースを統一的に扱うことができ、バックエンドの違いを吸収します。また、Grafanaなどの可視化ツールは、複数のバックエンドからデータを取得し、統合されたダッシュボードを提供することができます。ポリグロットバックエンドアーキテクチャの採用には、運用の複雑さと管理コストの増加というトレードオフがあります。バックエンドごとにデータの保存期間やアクセス制御を適切に設定し、モニタリングとアラート設定を行う必要があります。また、バックエンド間のデータ同期や整合性の問題にも注意が必要です。制約と誓約本章で提示された知見を踏まえると、Observabilityにおけるバックエンドの選定は、システムアーキテクチャとデータ管理の両面から慎重に検討すべき重要な意思決定であると言えます。適切なバックエンドの選択は、Observabilityの取り組みの成功を大きく左右します。組織は、自社のユースケースに合ったバックエンドを選択する必要があります。コスト、パフォーマンス、スケーラビリティ、相互運用性など、さまざまな要素を総合的に評価し、長期的な視点に立ってバックエンドの選定を行うべきです。また、バックエンドの特性や制約を深く理解し、データモデルに適したアーキテクチャを採用することが重要です。メトリクスのカーディナリティ問題に代表されるように、バックエンドの選択はデータの特性に大きく依存します。高カーディナリティのメトリクスを扱う場合は、カラムナーストレージの採用を検討すべきです。また、ログやトレースデータの長期的な保存と分析においても、カラムナーデータストアが有力な選択肢となります。ポリグロットバックエンドアーキテクチャは、各シグナルタイプに最適化されたバックエンドを組み合わせることで、パフォーマンスとコスト効率を最大化できる可能性を秘めています。ただし、運用の複雑さと管理コストの増加には十分な注意が必要です。OpenTelemetryなどの共通の収集および転送層を導入し、可視化ツールを活用することで、バックエンド間のデータ統合と相関分析を実現できます。6 Frontend destinationsフロントエンドとオールインワンソリューションの役割本章「Frontend destinations」では、Observabilityデータの可視化と分析を担うフロントエンドとオールインワンソリューションについて詳しく解説されています。フロントエンドは、バックエンドに保存されたObservabilityデータと対話し、ユーザーが様々なグラフィカルおよびテキスト形式でアドホックな質問に答えを見つけるために使用します。一方、オールインワンソリューションは、バックエンドとフロントエンドを一体化したものであり、ベンダーが設計したバックエンドとの組み合わせでのみ使用できます。著者は、フロントエンドとオールインワンソリューションの選択が、Observabilityの取り組みの成功に大きな影響を与えることを強調しています。適切なツールを選択することで、開発者やビジネスステークホルダーに価値を提供し、機能の出荷やバグ修正の加速、本番環境での問題解決時間の短縮、開発者の生産性向上などを実現できます。オープンソースとコマーシャルオファリングの比較本章では、Grafana、Kibana、OpenSearch Dashboardsなどの人気のあるオープンソースフロントエンドや、Jaeger、Zipkin、Apache SkyWalkingなどのオールインワンソリューションについて詳細に説明されています。これらのオープンソースツールは、幅広いバックエンドとの統合、豊富な視覚化オプション、アラート機能などを提供しており、自社のObservabilityソリューションを構築する際の強力な基盤となります。Figure 6.1 An example Grafana data source, showing configuration options より引用GrafanaはPrometheusと、KibanaはElasticsearchと、それぞれ緊密に連携しており、メトリクスとログの可視化において重要な役割を果たしています。一方、JaegerやZipkinは、OpenTelemetryとの統合により、幅広いプログラミング言語やフレームワークをサポートする分散トレーシングソリューションとして広く採用されています。Figure 6.6 Jaeger UI showing all traces for a certain tag (http.status_code=404) より引用また、SigNozやUptraceなど、ClickHouseをバックエンドに使用するオープンソースのオールインワンソリューションも登場しています。これらのツールは、OpenTelemetryを活用してテレメトリデータを収集し、SQLを使ってデータを柔軟にクエリできる点が特徴です。一方、商用ソリューションは、高度な分析機能、AIを活用した異常検知、パフォーマンス最適化の提案など、より豊富な機能を提供します。DatadogやNew Relicなどの有名ベンダーは、自動計装に基づくアウトオブザボックスの機能や、幅広いインテグレーションを備えています。また、Lightstepのようなunified storage layerを持つソリューションは、異なるシグナルタイプを統合的に扱うことができます。ツール選定の考慮事項フロントエンドとオールインワンソリューションの選定においては、以下の点を考慮する必要があります。コスト: フロントエンドのコストは予測可能ですが、オールインワンソリューションではバックエンドのコストも考慮する必要があります。オープンソースを選択する場合は、サポート、パッチ適用、スケーリングなどの運用コストを見積もることが重要です。ベンダーロックインの回避: オープンスタンダード（OpenTelemetryなど）をサポートするオールインワンソリューションは、ベンダーロックインを最小限に抑えつつ、運用負荷を軽減できる優れた選択肢です。オープンソースプロジェクトの健全性: オープンソースツールを選ぶ際は、プロジェクトの背景、ライセンス、コントリビューターの多様性、ドキュメントの品質、Issue対応の速度などを評価することが不可欠です。相関分析のサポート: 複数のシグナルタイプをサポートするツールにおいては、時間ベースの相関分析や、あるシグナルタイプから別のシグナルタイプへのスムーズな移動を可能にする機能が重要です。シングルパネルオブグラスとデータ相関の重要性著者は、Observabilityにおける「シングルパネルオブグラス」の概念について言及しています。これは、ログ、メトリクス、トレースなどの異なるシグナルタイプを単一のインターフェースで統合的に扱うことを指します。シングルパネルオブグラスを実現することで、システムの動作を包括的に把握し、問題の迅速な特定と解決が可能になります。ただし、著者は、シングルパネルオブグラスを絶対的な要件とするのではなく、柔軟なアプローチを取ることを推奨しています。つまり、主要なフロントエンドツールを中心に据えつつ、必要に応じて専門的なツールを組み合わせるのが現実的だと述べています。シングルパネルオブグラスに関連して、データの相関分析が重要な役割を果たします。異なるシグナルタイプ間の関連性を明らかにすることで、複雑なシステムの動作を理解し、パフォーマンスの問題や障害の根本原因を特定できます。著者は、Grafana version 10で導入された相関APIを例に挙げ、変数と変換を使用した相関分析の実現方法を紹介しています。フロントエンドとオールインワンの選択プロセスフロントエンドとオールインワンソリューションの選択において、最初に検討すべきは、「構築か、購入か」の意思決定です。社内でObservabilityプラットフォームを構築することが競争上の優位性につながるのでない限り、できる限りアウトソーシングすることが推奨されます。一方、ベンダーやクラウドプロバイダーへの依存を最小限に抑えたい企業では、オープンソースとオープンスタンダードに基づいたソリューションを構築するのが賢明です。選定プロセスでは、以下の点を評価します。総コストの見積もり（ライセンス料、インフラコスト、運用コストなど）ベンダーロックインのリスクオープンソースプロジェクトの成熟度と持続可能性相関分析を含む主要機能のサポート状況加えて、全てのステークホルダーを巻き込み、要件を明確にすることが肝要です。技術的な側面だけでなく、ビジネス要件や ユーザビリティなども考慮して、最適なソリューションを選択しましょう。Observabilityツールの継続的な評価と改善Observabilityの分野は急速に発展しており、新しいツールやソリューションが次々と登場しています。選択したフロントエンドやオールインワンソリューションが、将来にわたって組織のニーズを満たし続けられるとは限りません。したがって、定期的にツールを評価し、必要に応じて見直しや改善を行うことが重要です。評価の際は、以下の点を考慮します。新しい機能やインテグレーションの追加パフォーマンスとスケーラビリティの向上コミュニティの活発さとサポートの継続性ライセンスやコストモデルの変更また、Observabilityツールの運用においては、以下のような継続的な改善活動が求められます。ダッシュボードやアラートの最適化データ保持期間とコストのバランス調整新しいシグナルソースやデータ型の取り込みユーザートレーニングとドキュメントの整備Observabilityは、単なるツールの導入で完結するものではありません。組織全体でObservabilityの文化を醸成し、継続的な改善を通じて、システムの可視性と運用効率を高めていく必要があります。Observabilityの価値実現に向けて本章では、Observabilityにおけるフロントエンドとオールインワンソリューションの重要性、それらのツールの選定と運用における考慮事項について詳しく解説されました。Observabilityの真の目的は、システムの動作を深く理解し、問題の迅速な特定と解決を可能にすることで、ビジネス価値の実現を支えることにあります。適切なツールを選択し、継続的な改善を積み重ねることで、Observabilityの取り組みを成功に導くことができます。オープンソースとオープンスタンダードを活用しつつ、組織のコンテキストに合ったソリューションを構築することが肝要です。また、ログ、メトリクス、トレースなど、異なるシグナルタイプを相関分析できる機能を備えることで、システムの全体像を俯瞰し、問題の根本原因を特定しやすくなります。フロントエンドとオールインワンソリューションは、Observabilityデータの可視化と分析を通じて、ソフトウェアエンジニアリングとシステム運用に大きな価値をもたらします。本章で得られた知見を活かし、自組織に適したツール戦略を練り上げていきましょう。Observabilityの文化を育み、データドリブンな意思決定を促進することで、ビジネスの俊敏性と回復力を高めることができるはずです。7 Cloud operationsインシデント管理のベストプラクティス本章「Cloud operations」では、クラウドネイティブアプリケーションを円滑に運用するための重要な要素であるインシデント管理、ヘルスモニタリング、アラート、ガバナンス、使用状況の追跡について詳しく解説されています。特に、インシデント管理に関しては、インシデントの検出、処理、そしてインシデントから学ぶことの重要性が強調されています。クラウドネイティブシステムは多数のコンポーネントで構成されており、これらのコンポーネントは相互に依存しています。そのため、ひとつのコンポーネントで問題が発生すると、その影響が全体に波及する可能性があります。こうした複雑なシステムにおいて、エンドユーザーに影響を与える問題が発生した場合、どのコンポーネントが根本原因なのかを特定することは容易ではありません。したがって、システムの外部から継続的にヘルスモニタリングとパフォーマンスモニタリングを行い、期待通りに機能していないことを素早く検知することが不可欠です。モニタリングシステムは、各コンポーネントの主要なメトリクスを収集し、異常値や閾値超過を検出できるように設定する必要があります。これにより、インシデントの兆候をいち早く捉え、影響が拡大する前に対処できます。著者が強調しているのは、インシデントが発生した際には、原因分析よりも問題の解決を優先すべきだということです。つまり、エンドユーザーへの影響を最小限に抑えることが最優先事項であり、そのためには問題の切り分けと適切な対処を迅速に行う必要があります。具体的には、関連するログやメトリクスを確認してシステムの状態を把握し、影響範囲を特定した上で、適切な措置を講じる必要があります。また、ステークホルダーに対しても、状況と対応方針を適宜共有することが重要です。インシデントが収束した後は、再発防止に向けた原因分析が必要です。著者は、非難を伴わないポストモーテム（事後分析）を行うべきだと述べています。ポストモーテムでは、「5 Whys」などの手法を用いて根本原因を掘り下げ、具体的な再発防止策を特定することが重要です。さらに、インシデントの経緯と学びを文書化し、組織内で共有することで、将来のインシデント対応に活かすことができます。インシデント管理のベストプラクティスを確立するためには、以下のような点に留意する必要があります。インシデントの検知と通知の自動化: モニタリングシステムと連動したアラート設定により、インシデントの兆候を早期に検知し、適切な担当者に自動的に通知する。インシデントの優先度付けとエスカレーション: インシデントの影響度に応じて優先度を設定し、適切なタイミングでエスカレーションを行う。コミュニケーションの明確化: インシデント対応の際の連絡体制とコミュニケーションチャネルを予め定義しておく。ランブックとプレイブックの整備: よくあるインシデントへの対処手順をランブック（運用手順書）やプレイブック（対応シナリオ）としてまとめ、迅速かつ的確な対応を可能にする。ポストモーテムの徹底: インシデントの原因究明と再発防止策の特定を徹底的に行い、組織としての学びを促進する。これらのプラクティスを確実に実行できるよう、定期的にインシデント対応の訓練を行うことも重要です。様々なシナリオを想定した机上訓練や、実際にシステムの一部に障害を発生させるカオスエンジニアリングなどを通じて、チームのインシデント対応力を高めていくことができます。アラート設計のポイントと継続的な最適化アラートは、システムの異常を検知し、適切な担当者に通知するための重要な仕組みです。しかし、アラートの設定が不適切だと、大量の無駄なアラートが発生して対応が追いつかなくなったり、逆に重大な問題を見逃してしまったりする恐れがあります。したがって、アラートの設計には細心の注意を払う必要があります。著者は、アラートの設計において、以下のような点が重要だと指摘しています。重要度の設定: インシデントの影響度に応じて、アラートの重要度（critical, warning, infoなど）を適切に設定する。閾値の調整: アラートの閾値を適切に設定し、誤検知や見逃しを最小限に抑える。アラートのグループ化と抑制: 関連するアラートをグループ化し、不要なアラートを抑制することで、アラートのノイズを減らす。エスカレーションパスの明確化: アラートの重要度に応じて、エスカレーション先と連絡方法を明確に定義する。これらの設定を適切に行うことで、重要なアラートを見逃すことなく、迅速に対応できるようになります。本章では、Prometheusを使ったアラートの設定方法が具体的に解説されています。PrometheusではAlertmanagerと呼ばれるコンポーネントが、アラートのグループ化や通知の設定を担当します。Prometheusの設定ファイルでアラートルールを定義し、Alertmanagerの設定ファイルでアラートの通知先やグループ化のルールを指定します。著者が提示した例では、PrometheusのAPIコール数が一定のしきい値を超えた場合にアラートが発報され、Alertmanagerを経由してWebhookに通知が送信されます。アラートルールの定義では、PromQLと呼ばれるクエリ言語を使ってアラート条件を記述します。また、ラベルやアノテーションを使ってアラートの詳細情報を指定できます。Figure 7.2 Prometheus and the Alertmanager より引用Alertmanagerの設定では、アラートのグループ化や通知先の指定、通知メッセージのカスタマイズなどが可能です。たとえば、同じアプリケーションに関連するアラートをまとめたり、アラートの重要度に応じて通知先を変えたりといったことができます。また、抑制ルールを設定することで、特定の条件に一致するアラートを一時的に抑制することもできます。アラートの設計は一度で完璧にはできません。システムの変更に合わせて、継続的にアラートの設定を見直し、最適化していく必要があります。以下のような点に注意しながら、アラートの改善を進めていくことが重要です。アラートの効果の定期的な評価: アラートが期待通りに機能しているか、定期的に評価する。不要なアラートが多い場合は、閾値の調整やアラートルールの見直しを検討する。システム変更へのタイムリーな対応: システムの変更に合わせて、アラートの設定を速やかに更新する。特に、新しい機能のリリース時には、適切なアラートを設定するように心がける。アラートの受信者の最適化: アラートの受信者が適切か定期的にレビューする。担当者の変更やオンコール体制の見直しに合わせて、アラートの通知先を更新する。エスカレーションパスの確認: 重要なアラートが確実にエスカレーションされるよう、エスカレーションパスを定期的にテストする。アラートは、インシデント管理において重要な役割を果たします。適切なアラートの設定は、インシデントの早期検知と迅速な対応を可能にします。しかし、アラートの設計は継続的な改善が必要なプロセスです。システムの変更に合わせてアラートを最適化し、運用チームの負荷を最小限に抑えながら、インシデントを確実に検知できるようにしていくことが求められます。今後の課題本章では、クラウドネイティブアプリケーションの運用において重要となるインシデント管理、ヘルスモニタリング、アラート、ガバナンス、使用状況の追跡について詳しく解説されました。インシデント管理については、インシデントの検知から対応、そしてポストモーテムまでのプロセスを適切に定義し、実行することが重要だと述べられています。特に、インシデント発生時には問題の解決を最優先し、その後に原因分析を行うべきだと強調されています。また、ポストモーテムを通じて、インシデントから学びを得て、再発防止につなげることが重要だと指摘されています。アラートについては、適切な設計と継続的な最適化が必要だと述べられています。アラートの重要度や閾値の設定、アラートのグループ化や抑制、エスカレーションパスの明確化などが、アラートの効果的な運用に欠かせないポイントとして挙げられています。また、Prometheusを使ったアラートの設定方法が、具体的な例を交えて解説されています。ユーザー行動の追跡に関しては、Real User Monitoringを使ったエンドユーザーの行動分析や、CloudTrailなどを使った内部ユーザーのアクション追跡の重要性が指摘されています。これらのデータを活用することで、パフォーマンスの改善やセキュリティ強化、コンプライアンス対応などに役立てることができます。さらに、コスト最適化の重要性についても言及されています。クラウドの利用が拡大する中で、リソースの使用状況を可視化し、無駄な支出を削減することが求められます。AWS Cost and Usage ReportsやKubernetes向けのOpenCostなどのツールを活用することで、コストの最適化を進められると述べられています。クラウドネイティブ時代の運用は、従来のオンプレミス環境とは大きく異なります。インフラストラクチャのプロビジョニングや設定管理の自動化、オブザーバビリティの確保、コストの最適化など、多岐にわたる課題に取り組む必要があります。本章で得られた知見は、これらの課題に立ち向かう上で、重要な指針となるでしょう。ただし、本章で取り上げられたトピックは、クラウドネイティブの運用における一部に過ぎません。たとえば、カオスエンジニアリングによるシステムの回復力向上や、AIOpsの活用による運用の自動化など、本章では触れられていない重要なテーマもあります。また、クラウドネイティブの運用プラクティスは、急速に進化し続けています。新しいツールやサービス、アプローチが次々と登場する中で、運用チームは常に学習と適応が求められます。クラウドネイティブの運用は、単なるシステムの維持ではなく、ビジネスの成功に直結する戦略的な活動です。本章で紹介された手法やツールを活用しつつ、組織の文化や目標に合わせてアプローチをカスタマイズしていくことが重要です。運用の自動化や効率化を進める一方で、チーム内のコラボレーションや、開発チームとのコミュニケーションを強化することも忘れてはなりません。8 Distributed tracing分散トレーシングでクラウドネイティブシステムを徹底的に可視化本書「Observability In Action」の第8章「Distributed tracing」では、分散トレーシングという手法を用いて、クラウドネイティブシステムの複雑な動作を可視化する方法について詳しく解説されています。著者は、モノリシックなアプリケーションではログとメトリクスだけで十分だったのに対し、マイクロサービスアーキテクチャではサービス間の関係性を追跡するために分散トレーシングが欠かせないと指摘しています。分散トレーシングは、個々のリクエストがシステム内の各サービスをどのように通過するかを追跡し、処理のフローと時間情報を記録することで、システム全体の動作を俯瞰的に把握できるようにする技術です。 各サービスはリクエストの処理過程でスパン(span)と呼ばれる情報を生成し、これらのスパンが集まってエンドツーエンドのトレース(trace)を形成します。分散トレーシングツールは、これらのトレースデータを収集、分析、可視化することで、開発者やSREがシステムの動作を理解し、パフォーマンスの問題や障害の原因を特定できるようサポートします。Figure 8.3 A single request path in the app, as a temporal (waterfall) visualization より引用本章では、分散トレーシングの基本概念とユースケースが丁寧に説明されています。トレースやスパンといった基本的な用語の定義から始まり、サンプリングやコンテキスト伝搬など、実践的な話題にも踏み込んでいます。 特に、分散トレーシングが単なるツールの導入ではなく、開発チーム全体で取り組むべき文化的な実践であるという指摘が印象的でした。また、著者自身が開発したサンプルアプリケーションを使って、Jaegerというオープンソースのトレーシングツールでマイクロサービスのトレースを可視化する手順が詳しく解説されています。実際のトレースデータを見ながら、サービスマップやウォーターフォールダイアグラムを使ってシステムの動作を分析する方法を学べるのは、大変有益だと感じました。Figure 8.7 Troubleshooting the demo microservices app: an example failure trace and the span that caused the failure より引用本章の後半では、分散トレーシングを導入・運用する上での実用的なアドバイスが提供されています。 トレースのサンプリング方法の選択、分散トレーシングにかかるコスト（オブザーバビリティ税）の見積もり方、ログやメトリクスとの使い分けなど、実際のプロジェクトで直面しそうな課題に対するヒントが豊富に盛り込まれていました。エンドツーエンドの可視化でシステムをホリスティックに理解分散トレーシングは、複雑化するクラウドネイティブシステムをエンドツーエンドで可視化し、ホリスティック（包括的）に理解するための強力な手法だと言えます。マイクロサービス間の呼び出しフローを追跡することで、システム全体のアーキテクチャを俯瞰でき、パフォーマンスのボトルネックや障害の波及経路を特定しやすくなります。また、各スパンが処理時間や結果のステータスなどの詳細情報を持つため、トレースデータを分析することで、パフォーマンスの最適化や障害対応を効率化できます。一方で、分散トレーシングの導入には一定のコストがかかることも事実です。各サービスにおける計装、トレースデータの収集・保存のためのインフラ、分析・可視化ツールの運用など、様々な側面でコストが発生します。 本章でも指摘されているように、これらのコストに見合うだけの価値が得られるかを見極めることが重要です。分散トレーシングを成功に導く秘訣分散トレーシングをプロジェクトに導入し、その恩恵を最大限に引き出すためには、単にツールを導入するだけでなく、組織文化やプロセスの変革も必要だと感じました。本章から得られた教訓をまとめると、以下のようになります。分散トレーシングをオブザーバビリティ戦略の一環として位置づけるログ、メトリクスと並ぶ重要な柱として、体系的に取り組む開発チーム全体でトレーシングの価値を共有するトレーシングがもたらすメリットを開発者に伝え、活用を促す計装を自動化し、手間を最小限に抑えるOpenTelemetryなどの自動計装を活用するトレースデータを集約し、関連情報と紐付けて分析するトレースIDを軸に、ログやメトリクスと関連づけて分析する可視化ツールを使ってトレースを直感的に理解するJaegerやZipkinなどのツールで、サービスマップやウォーターフォールダイアグラムを活用するコストとベネフィットのバランスを見極める過剰な情報収集は避け、本当に必要なスパンに絞り込む分散トレーシングの未来本章では、分散トレーシングという手法の現状について詳しく解説されていましたが、この分野は現在も活発に発展し続けています。 特に、OpenTelemetryプロジェクトが、ベンダー中立な分散トレーシングのためのオープンスタンダードとして注目を集めています。各言語のSDKやAPIの整備、自動計装の充実など、OpenTelemetryの登場により、分散トレーシングの導入が以前よりも容易になることが期待されます。また、AIOpsやオブザーバビリティプラットフォームとの連携も、分散トレーシングの今後の発展において重要なトピックだと考えられます。トレースデータを機械学習モデルで分析することで、異常検知やパフォーマンス最適化の自動化が進むかもしれません。さらに、ログやメトリクスなど他のオブザーバビリティデータとトレースを統合的に扱うプラットフォームが登場すれば、よりホリスティックなシステム理解が可能になるでしょう。組織の分散トレーシングは俺と仲間で育ててる分散トレーシングは、現代のクラウドネイティブシステムにおいて欠かせないオブザーバビリティ技術の一つです。マイクロサービス間の複雑な相互作用を可視化し、パフォーマンスや信頼性の向上に役立てることができます。本章で得られた知見は、実際のシステム開発・運用の様々な場面で活用できるはずです。一方で、分散トレーシングはシルバーバレットではありません。ツールの導入だけでなく、チーム全体でトレーシングの価値を共有し、データを効果的に活用するための文化やプロセスの変革が求められます。また、トレーシングにかかるコストを適切にコントロールし、投資対効果を見極めることも重要です。分散トレーシングに取り組む際は、本章で紹介された基本概念やベストプラクティスを押さえつつ、自分たちのシステムやチームに合ったやり方を模索していくことが大切だと感じました。オープンスタンダードの採用や、他のオブザーバビリティ実践との連携など、新しい潮流にも注目しながら、システムのエンドツーエンドの可視化を追求していきたいと思います。9 Developer observabilityDeveloper observabilityで開発者の生産性を加速する本書「Observability In Action」の第9章「Developer observability」では、Developer observabilityの概念とその実現方法について詳しく解説されています。著者は、Developer observabilityを「開発者に行動可能なインサイトを提供することで、開発速度の向上、コードのデバッグ、新機能の性能・リソース使用量の理解を可能にするテレメトリシグナルの活用」と定義しています。Efficient Goも書籍として良かったのでオススメです。日本語の「効率的なGo ―データ指向によるGoアプリケーションの性能最適化」もあるので合わせて読んでみてください。learning.oreilly.com従来、開発者は主にコードの作成に注力し、テスト、パッケージング、デプロイ、運用は他の部門が担当するのが一般的でした。しかし、Developer observabilityの登場により、開発者自身がこれらの工程に関与し、迅速なフィードバックループを確立できるようになりました。 これにより、問題の早期発見と修正が可能となり、全体的なコストを削減できます。本章では、Developer observabilityを実現する具体的な手法としてContinuous profiling（継続的プロファイリング）に焦点が当てられています。Continuous profilingを使うことで、開発者はサービスの現在のパフォーマンスとリソース使用量を把握し、コード変更前後の比較が可能になります。これにより、新機能追加によるトレードオフを定量的に評価できるようになります。著者は、Continuous profilingの基盤技術として、pprofフォーマット、Flame graph、eBPFなどを紹介しています。pprofは、Googleが開発したプロファイリングデータの可視化・分析ツールであり、プロファイルをProtocol Buffers形式で表現します。 Flame graphは、プロファイルの呼び出しスタックを視覚的に表現する手法で、eBPFはLinuxカーネルを拡張してプロファイル収集を行う仕組みです。これらの技術を理解することが、Continuous profilingを活用する上で重要だと指摘されています。Figure 9.2 An flame graph using our pprof Go example より引用本章ではまた、Parca、Pixie、Pyroscopeなど、オープンソースのContinuous profilingツールが紹介されています。これらのツールは、pprofフォーマットをサポートし、eBPFを活用してプロファイルを収集します。クラウドプロバイダーや商用ベンダーも、独自のContinuous profiling機能を提供し始めています。 AWS CodeGuru Profiler、Azure Application Insights Profiler、Google Cloud Profilerなどが代表的な例です。Figure 9.3 The eBPF call flow in the Linux kernel at a conceptual level (Source: Brendan Gregg. Licensed under CC BY 4.0) より引用さらに著者は、Continuous profilingをOpenTelemetry collectorの性能分析に活用する具体的な手順を示しています。pprofエクステンションを有効化したOpenTelemetry collectorからプロファイルを収集し、Parcaを使って可視化・分析する一連の流れが丁寧に説明されており、実践的な知見が得られます。Continuous profilingに加えて、本章ではDeveloper productivityツールについても言及されています。これらのツールは、OpenTelemetryを基盤とし、コード変更が性能やリソース使用量に与える影響を開発者に可視化します。Digma、Sprkl、Tracetest、Rookout、Autometricsなどが代表的な例として紹介されています。Digmaは、OpenTelemetryのトレースとメトリクスを分析し、コードレベルのインサイトを提供するIDEプラグインです。 開発者は、コードを編集しながら、パフォーマンス、エラー、使用状況に関するフィードバックを得ることができます。Sprklは、OpenTelemetryを使ってコードをインスツルメントし、コード変更の実行時の振る舞いを探索できるようにします。 コードレベルのトレース、システム内の他のエンティティとの関係、パフォーマンスレポートなどが提供されます。Tracetestは、OpenTelemetryのトレースを利用して、マイクロサービス間の統合テストを構築するためのツールです。 サービス間の呼び出しフローを定義し、期待されるレスポンスとトレースデータに対してアサーションを記述できます。ただし著者は、Developer observabilityツールの採用には注意が必要だと指摘しています。シンボル情報の取り扱い、プロファイルの保存とクエリ、他のテレメトリデータとの相関分析、オープンスタンダードへの準拠など、克服すべき課題が残されています。特に本番環境での利用には、パフォーマンスへの影響を慎重に見極める必要があります。Continuous profilingの技術的側面に迫る本章では、Continuous profilingの基盤となる技術について詳しく解説されていました。特に、pprofフォーマット、Flame graph、eBPFは、Continuous profilingを支える重要な要素として紹介されています。pprofは、Googleが開発したプロファイリングデータの可視化・分析ツールであり、プロファイルをProtocol Buffers形式で表現します。pprofのデータフォーマットは、Continuous profilingツールの多くが採用しており、事実上の標準となりつつあります。著者は、pprofの内部構造を詳解し、protocを使ってpprofファイルをデコードする方法も示しています。これにより、開発者はpprofの仕組みを深く理解し、より効果的にContinuous profilingを活用できるようになります。pprofのデータ構造は、Profileメッセージを中心に構成されています。 Profileメッセージには、サンプルの種類(ValueType)、収集されたサンプル(Sample)、マッピング情報(Mapping)、ロケーション情報(Location)、関数情報(Function)などが含まれます。これらのサブメッセージを組み合わせることで、プロファイリングデータが表現されるのです。Flame graphは、プロファイルの呼び出しスタックを視覚的に表現する手法です。著者は、Flame graphの読み方を丁寧に解説し、slowTask()やquickTask()といった関数の実行時間を色と幅で表現する例を示しています。Flame graphを使いこなすことで、開発者はボトルネックの特定や性能の最適化を直感的に行えるようになります。Flame graphでは、x軸方向に呼び出しスタックが並べられ、y軸方向にスタックの深さが示されます。 各関数の実行時間は、対応する長方形の幅で表現されます。これにより、どの関数がCPU時間を多く消費しているかが一目で分かります。また、呼び出し元と呼び出し先の関係も、スタックの階層構造から読み取ることができます。eBPFは、Linuxカーネルを拡張し、プロファイルの収集を可能にする仕組みです。著者は、eBPFの基本概念とContinuous profilingにおける役割を説明しています。eBPFを活用することで、アプリケーションコードに変更を加えることなく、カーネルレベルでのプロファイリングが実現できます。 ただし、eBPFを本番環境で利用するには、カーネルバージョンや設定に注意が必要だと指摘されています。eBPFプログラムは、カーネル内の特定のイベント（関数の呼び出し、リターン、パケットの受信など）にアタッチされ、イベント発生時に実行されます。これにより、カーネルの動作を詳細に観測し、必要な情報を収集することが可能になります。収集されたデータは、カーネル内のeBPFマップを介してユーザー空間に渡され、分析ツールで処理されます。これらの技術的な説明は、Continuous profilingの仕組みを深く理解する上で欠かせません。pprofやeBPFを適切に活用することで、開発者はアプリケーションの性能を正確に把握し、改善に役立てることができるでしょう。一方で、これらの技術にはそれぞれ固有の制約や課題があることも忘れてはなりません。著者が示唆するように、Continuous profilingを効果的に実践するには、技術的な理解と、トレードオフを見極める判断力の両方が求められます。プロファイルの保存と分析の課題に挑むContinuous profilingを実践する上で、プロファイルデータの保存と分析は大きな課題となります。著者は、列指向のストレージとXOR圧縮という2つのアプローチを紹介しています。列指向のストレージは、プロファイルデータを効率的に保存し、クエリを高速化するために用いられます。著者は、ParcaチームがGo言語で開発したFrostDBを例に挙げ、列指向データベースがプロファイルの保存に適していることを説明しています。FrostDBは、Apache Parquetをストレージフォーマットに、Apache Arrowをクエリエンジンに採用しており、半構造化スキーマをサポートしています。列指向ストレージでは、データが列単位で格納されます。つまり、同じ列に属するデータが連続的に配置されるのです。これにより、特定の列に対するクエリが高速化されます。また、列単位の圧縮が可能となり、ストレージ容量を大幅に削減できます。プロファイルデータは、呼び出しスタックや関数名、タイムスタンプなど、複数の列から構成されるため、列指向ストレージとの親和性が高いと言えます。一方、XOR圧縮は、プロファイルのタイムスタンプを効率的に圧縮するための手法です。著者は、Facebookのエンジニアチームが考案した「Gorilla」アルゴリズムを紹介し、タイムスタンプのデルタ値を符号化することで、ストレージ容量を大幅に削減できると説明しています。XOR圧縮では、連続するタイムスタンプの差分（デルタ）を計算し、そのデルタ値をXOR演算で符号化します。 これにより、タイムスタンプの繰り返しパターンが効果的に圧縮されます。プロファイルデータは、連続的に収集されるため、タイムスタンプの圧縮に適しているのです。XOR圧縮を適用することで、プロファイルの長期的な保存が現実的になります。これらの技術は、大規模なプロファイルデータを扱う上で重要な役割を果たします。列指向ストレージを活用することで、開発者は膨大なプロファイルを効率的に保存し、高速にクエリを実行できるようになります。XOR圧縮は、ストレージコストの削減に貢献し、長期的なプロファイルの保持を可能にします。ただし、著者も指摘するように、プロファイルデータの保存と分析には、まだ多くの課題が残されています。特に、プロファイルに対する表現力豊かなクエリ言語の確立は、喫緊の課題だと言えます。Parcaのラベルベースのクエリ言語やPyroscopeのFlameQLなど、各ツールが独自のアプローチを取っていますが、業界全体で共通の標準が求められています。加えて、プロファイルデータと他のテレメトリデータとの相関分析も、重要な研究テーマです。分散トレースやメトリクスとプロファイルを組み合わせることで、より総合的なパフォーマンス分析が可能になるはずです。しかし、現状では、これらのデータを統合的に扱うための仕組みが十分に確立されているとは言えません。Continuous profilingの本格的な実践には、これらの課題を着実に解決していく必要があります。列指向ストレージやXOR圧縮といった要素技術を活用しつつ、クエリ言語の標準化や、テレメトリデータ間の相関分析手法の確立に取り組むことが求められます。著者が強調するように、オープンスタンダードの採用と、コミュニティ全体での知見の共有が、Continuous profilingの発展に欠かせないのです。あわせて6本にしてみる...本章では、Continuous profilingを支える基盤技術と、その実践に向けた課題について深く掘り下げていました。pprofやFlame graph、eBPFといった要素技術は、Continuous profilingの中核を成すものであり、開発者がその仕組みを理解することは極めて重要です。また、列指向ストレージやXOR圧縮といった手法は、大規模なプロファイルデータを扱う上で欠かせない存在だと言えるでしょう。一方で、クエリ言語の標準化や、テレメトリデータ間の相関分析など、Continuous profilingの実践には克服すべき課題が山積みです。これらの課題に正面から向き合い、地道な改善を積み重ねていくことが、私たち開発者に求められています。オープンスタンダードの採用と、知見の共有。それが、Continuous profiling、ひいてはDeveloper observabilityを発展させるための鍵だと、私は確信しています。 一人一人の開発者が自らの経験を持ち寄り、ベストプラクティスを編み出していく。そのような協調的な取り組みこそが、Developer observabilityの真の力を引き出すのだと思います。Jaeger の作者で OpenTelemetry の共同創始者でもある Yuri Shkuro の TEMPLE: six pillars of telemetry ではObservability をTraces,Events,Metrics,Profiles,Logs,Exceptions で6 本柱としてクラウドネイティブなシステムの観測性に役立つと主張している。このような考えもあることを知っておくと良いかもです。medium.com10 Observability In ActionSLOでサービスの信頼性を定量化し、顧客満足度を高める本書「Observability In Action」の第10章「Service level objectives」では、サービス品質の定量化とその自動化に不可欠なサービスレベル目標（SLO）について詳しく解説されています。著者は、信頼性に関する規制が今後セキュリティと同様に重要になると指摘し、SLOを用いてサービスの信頼性を測定・報告することが、金融、通信、航空などの業界で注目を集めていると述べています。SLOは、サービス提供者と消費者の間で交わされるサービスレベルアグリーメント（SLA）を定量化し、自動化するための重要な手段です。SLAで約束した内容を数値化したものがSLOであり、そのSLOの達成度を実際に測定するための指標がサービスレベルインジケータ（SLI）です。つまり、SLIで測定し、SLOで目標を定め、SLAで契約を交わす、という関係になります。Figure 10.1 Interaction and dependencies between SLAs, SLOs, and SLIs より引用本章では、SLOの対象となるサービスの種類として、同期型、非同期型、特殊型の3つが挙げられています。同期型サービスはリクエスト-レスポンス型のWebサービスや、RPCベースのシステムが該当します。非同期型サービスは、メッセージキューやPub/Subシステムなどが含まれます。特殊型サービスには、バッチジョブ、ストレージ、データベースなどが含まれます。それぞれのサービス特性に応じて、適切なSLIを設定する必要があります。SLIの具体例としては、サービスの可用性、エラー率、レイテンシ、スループットなどが挙げられています。これらの指標をもとに、サービスの品質を定量的に評価し、改善のための目標（SLO）を設定します。例えば、「99.9%の可用性を維持する」「エラー率を0.1%以下に抑える」といったSLOを定めることで、サービス品質の向上を図ることができます。SLOを設定する際は、可用性と速度のバランスを考慮する必要があります。可用性を上げるためには変更を控えめにする必要がありますが、それでは新機能の追加が滞ってしまいます。逆に、変更を頻繁に行えば、可用性が下がるリスクがあります。サービスの特性に応じて、適切なSLOを設定することが重要だと著者は指摘しています。本章ではまた、PrometheusをベースとしたオープンソースのSLOツールであるPyrraとSlothについて詳しく解説されています。これらのツールを使うことで、PrometheusのメトリクスをSLIとして扱い、SLOの達成状況を容易に可視化できます。PyrraはPrometheusのレコーディングルールを生成することでSLOを実装します。ServiceLevelObjectiveリソースを定義すると、それに対応するPrometheusのルールが自動生成されます。一方、SlothはPrometheusのルールグループを生成し、SLIやエラーバジェットの計算を行います。どちらのツールもSLOの実装を大幅に簡略化してくれます。著者はまた、SLOの商用ソリューションについても言及しています。Nobl9、Datadog、Honeycomb、Dynatraceなど、多くのベンダーがSLOの機能を提供し始めていると指摘しています。特にNobl9は、SLOに特化した包括的なソリューションを提供していると紹介されています。最後に著者は、SLOを定義する際にはOpenSLOなどのオープンスタンダードを活用すべきだと強調しています。ベンダーロックインを避け、相互運用性を確保するためにも、オープンな仕様に準拠することが重要だと述べています。SLOの実装と運用における留意点本章では、SLOの実装と運用に関する具体的な留意点についても言及されていました。まず、SLOの設定には、サービスの利用者と提供者の間での合意形成が不可欠です。著者は、営業担当者、プロダクトオーナー、エンジニアリングチームが連携し、サービスの特性に応じた適切なSLOを定義すべきだと述べています。その際、エラーの許容範囲や、SLOの対象期間などを明確にすることが重要です。SLOの達成度を測定するためのSLIの設定も、慎重に行う必要があります。SLIは、サービスの品質を数値化するための指標であり、サービスの種類によって適切なものを選ぶ必要があります。著者は、REDメソッド（Rate、Errors、Duration）など、SLIの選定に関する参考資料を紹介しています。SLOの運用においては、エラーバジェットの管理が鍵を握ります。エラーバジェットとは、SLOを達成するために許容されるエラーの範囲のことです。エラーバジェットを適切に設定し、モニタリングすることで、SLOの違反を未然に防ぐことができます。エラーバジェットの消費速度（バーンレート）を追跡することも、SLOの管理に役立ちます。本章で紹介されたPyrraやSlothなどのSLOツールを活用することで、SLOの実装と運用を大幅に効率化できます。これらのツールは、PrometheusのメトリクスをSLIとして扱い、SLOのモニタリングとアラートの設定を容易にしてくれます。ただし、ツールの選定には注意が必要です。機能、性能、価格などを総合的に評価し、自社のニーズに合ったものを選ぶことが重要です。SLOの導入には、組織文化の変革も欠かせません。サービスの品質を定量的に評価し、継続的に改善していくためには、開発者、運用者、ビジネス関係者が一丸となって取り組む必要があります。SLOを中心とした品質管理のプラクティスを組織全体に浸透させ、データドリブンな意思決定を促進することが求められます。サービスの継続的な改善の為のSLO本章では、サービス品質の定量化と自動化に不可欠なSLOについて、詳細に解説されていました。SLOは、SLAで約束したサービス品質を数値化し、SLIで測定するための重要な手段です。サービスの種類に応じて適切なSLIを選定し、SLOを設定することで、サービスの継続的な改善が可能になります。SLOの実装には、PyrraやSlothなどのオープンソースツールが役立ちます。これらのツールを活用することで、PrometheusのメトリクスをSLIとして扱い、SLOのモニタリングを容易に行えます。一方、Nobl9やDatadogなどの商用ソリューションも、SLOの管理に強力な機能を提供しています。github.comsyu-m-5151.hatenablog.comSLOの運用では、エラーバジェットの管理が鍵を握ります。サービスの品質を維持しつつ、変更を加速するためには、適切なエラーバジェットの設定と消費速度の追跡が欠かせません。また、SLOの導入には組織文化の変革も必要です。サービス品質の定量的な評価と継続的な改善を、組織全体の習慣とすることが重要です。SLOは、単なる技術的な指標ではありません。それは、サービス提供者と消費者の間の信頼関係を築くための重要な手段でもあります。SLOを導入することで、サービスの品質に対する説明責任を果たし、ユーザーの満足度を高めることができるのです。本章を通して、SLOの重要性と実践的な手法について理解を深めることができました。測定できないものは改善できないと言われます。サービスの品質を定量化し、データに基づいて改善を進めていくこと。それがSLOの本質であり、私たちに求められる姿勢だと感じました。皆さんの組織では、SLOをどのように活用されていますか？PyrraやSlothなどのツールの利用経験や、SLOの運用で得られた知見などがあれば、ぜひ共有いただきたいと思います。SLOを通じて、サービスの品質と信頼性を高めていくために、私たちにできることは何でしょうか。サービスの信頼性を定量化し、顧客の期待に応えていく。そのためのアプローチとして、SLOは大きな可能性を秘めています。本章で得られた知見を活かし、SLOの実践を通じて、より信頼性の高いサービスを提供していきたいと思います。11 Signal correlationシグナル相関で複雑なシステムの動作を俯瞰的に理解する本書「Observability In Action」の最終章「Signal correlation」では、複数のオブザーバビリティシグナルを関連付けることで、クラウドネイティブシステムの動作をより深く理解する方法が解説されています。著者は、ログ、メトリクス、トレース、プロファイルといった個々のシグナルだけでは、システムの全体像を把握するのに十分ではないと指摘しています。シグナル相関は、異なるシグナルタイプを結び付けることで、より迅速かつ正確に有用な洞察を得るためのメタデータ主導のプロセスだと定義されています。マイクロサービスアーキテクチャを採用する現代のシステムは、多数のサービスが連携して一つのリクエストを処理します。そのため、障害やパフォーマンスの問題が発生した際に、どのサービスが原因となっているのかを特定するのが難しくなります。シグナル相関は、インシデント対応、根本原因分析、サービスの性能改善など、様々な場面で威力を発揮します。メトリクスからトレースへ、トレースからログへ、といったように、複数のシグナルを行き来しながら、問題の全容を明らかにできるのです。本章では、シグナル相関の基本概念として、相関スタックが紹介されています。これは、計装層、バックエンド層、フロントエンド層から構成され、相関を実現するための階層的な仕組みを表しています。Figure 11.1 The correlation stack より引用計装層では、アプリケーションコードとテレメトリエージェントが、テレメトリデータを生成し、メタデータで enrichment を行います。バックエンド層では、収集されたテレメトリデータがメタデータとともに保存され、相関のためのクエリに応える役割を担います。そして、フロントエンド層で、ユーザーがシグナル間を自在に行き来しながら、システムの動作を探索できるようになります。特に、OpenTelemetryの果たす役割の大きさが強調されています。OpenTelemetryは、セマンティック規約を通じて、リソース属性やシグナル属性といったメタデータを標準化します。これにより、ベンダーに依存しない形で、シグナル間の相関を自動化できるようになります。OpenTelemetryのリソース属性を使えば、Kubernetesのノードや、その上で動作するアプリケーションを一意に識別できます。また、シグナル属性によって、HTTPリクエストやRPCコールなど、個々のシグナルにも豊富なメタデータを付与できるのです。また、著者は相関パスという概念を導入し、あるシグナルタイプから別のシグナルタイプへの遷移を表現しています。Table 11.1 Overview of signal correlations より引用トレースからメトリクスへ、メトリクスからログへ、ログからトレースへ、といったように、様々な組み合わせが考えられます。それぞれの遷移では、関連する情報が引き継がれ、より広い文脈でシステムの動作を理解できるようになります。例えば、トレースからメトリクスへの相関では、トレースが表す分散トランザクションから、レイテンシーや、エラー率などの代表的なメトリクスを導き出せます。逆に、メトリクスからトレースへの相関では、異常な振る舞いを示すメトリクスから、その原因となっているトレースに迫ることができるでしょう。ログとトレースの相関も、非常に有用です。あるサービスのログから、そのサービスが関与するトレースを特定したり、トレースに含まれる各サービスのログを収集したりできます。これにより、分散トランザクションの流れと、各時点で記録されたイベントを突き合わせながら、問題の原因を追跡できるようになります。本章では、このようなシグナル相関の概念を、様々な角度から掘り下げています。相関を実現するためのメタデータの標準化、相関パスの種類と活用方法、OpenTelemetryを中心とするオープンな技術スタックなど、相関に関する重要なポイントが網羅的に解説されていました。OpenTelemetry、Jaeger、Grafanaを使ったメトリクスとトレースの相関本章では、メトリクスとトレースの相関を実現する具体的な方法として、OpenTelemetry、Jaeger、Grafanaを使った例が紹介されています。サンプルアプリケーションは、OpenTelemetryを使って計装され、トレースを生成します。同時に、Prometheus形式のメトリクスにトレースIDを埋め込むことで、エグゼンプラ（exemplars）を実現しています。OpenTelemetryコレクタは、トレースをJaegerに、メトリクスをPrometheusに転送します。コード例を見ると、OpenTelemetryのGoライブラリを使って、メトリクスの各ポイントにトレースIDをラベルとして埋め込んでいます。これがエグゼンプラの肝となる部分です。メトリクスを公開する際には、Prometheusの HTTP ハンドラを使い、レスポンスフォーマットとして OpenMetrics を指定しています。OpenTelemetryコレクタの設定では、Prometheusエクスポータと Jaeger エクスポータを使って、それぞれのバックエンドにデータを送信しています。Prometheusエクスポータでは、enable_open_metrics オプションを有効にすることで、エグゼンプラのサポートが有効になります。実際にエグゼンプラがどのように埋め込まれているかは、curl コマンドで /metrics エンドポイントにアクセスすることで確認できます。traceID というラベルに、トレースIDが格納されているのが分かります。Grafanaのダッシュボードでは、メトリクスのグラフ上に小さな点として表示されるエグゼンプラをクリックすることで、該当するトレースにジャンプできます。これにより、メトリクスの異常を発見した際に、すぐにトレースを確認し、問題の原因を特定できるようになります。Figure 11.2 Screenshot of the Grafana dashboard with exemplars (the small dots at the bottom) for the echo service より引用Figure 11.3 Screenshot of the Jaeger view for the echo service, focusing on the error span representing a 500 responseこのように、オープンソースツールを組み合わせることで、シグナル相関を比較的簡単に実現できることが示されています。各ツールが担う役割を理解し、適切に設定することが重要だと感じました。特に、OpenTelemetryがデータ収集の中心となり、Jaegerがトレースの保存と可視化を、Prometheusがメトリクスの保存と集計を、そしてGrafanaが相関の UI を提供するという、それぞれの得意分野を活かした構成が印象的でした。もちろん、本格的な運用のためには、データ量の増大への対応や、セキュリティの確保など、さらなる検討が必要でしょう。しかし、本章の例は、シグナル相関を実践するための第一歩として、大いに参考になると感じました。シグナル相関の実装における課題と対策本章では、シグナル相関の実装における課題についても言及されています。まず、標準化の欠如が挙げられています。APMやモニタリングツールごとに、シグナルのフォーマットや用語が異なるため、システム間で相関を行うのが難しくなります。これに対しては、OpenTelemetryのような標準化されたフレームワークを採用することが有効だと指摘されています。OpenTelemetryは、ベンダー中立なオープンスタンダードであり、多くのプログラミング言語やフレームワークをサポートしています。これにより、様々なシステムから一貫性のあるテレメトリデータを収集できるようになります。次に、メタデータの不足が課題として挙げられています。相関を実現するには、リソースや環境に関する豊富なメタデータが必要ですが、既存のシステムではそれが十分に提供されていないことが多いのです。特に、レガシーなアプリケーションや、サードパーティのAPIを利用している場合、メタデータの取得が困難を極めることがあります。ここでも、OpenTelemetryのセマンティック規約に従うことで、メタデータの自動付与が可能になります。ただし、完全な自動化は難しく、場合によってはカスタムの計装が必要になるでしょう。シグナルのボリューム、カーディナリティ、サンプリングも、相関の実装を難しくする要因です。大量のデータを処理するために、適切なインデックス設計や集計、フィルタリングが欠かせません。特に、ログデータは非構造化データであるため、関連する情報を抽出するのが一苦労です。また、メトリクスの次元が増えすぎると、カーディナリティ爆発を引き起こし、クエリのパフォーマンスが大幅に低下してしまいます。トレースのサンプリングは、データ量を抑えるための有効な手段ですが、重要なスパンが欠落してしまうリスクもあります。これらの課題に対しては、適切なアーキテクチャの選択と、きめ細かなチューニングが求められます。例えば、ログデータの処理には、Elasticsearchなどの全文検索エンジンや、FluentdやLogstashなどのログ収集基盤が役立ちます。メトリクスのカーディナリティ対策としては、PrometheusのRelabelingやRecordingRuleを活用できるでしょう。トレースのサンプリングでは、重要な操作をあらかじめ識別し、適切なサンプリングレートを設定することが重要です。データのプライバシーとセキュリティの確保も、重要な課題の一つです。法規制やコンプライアンス要件に従って、個人情報を適切にマスキングしたり、データの取り扱いを制限したりする必要があります。特に、SaaSサービスを利用する場合、データの保存場所や、アクセス制御について、慎重に検討しなければなりません。暗号化やアクセスログの監査など、セキュリティ対策も欠かせません。最後に、ユーザーエクスペリエンスの向上が求められます。せっかく相関機能を実装しても、使い勝手が悪ければ活用されません。インサイトを得やすいUIの設計や、エンドツーエンドでの一貫したサポートが重要だと指摘されています。例えば、メトリクスの異常検知から、関連するトレースやログへの seamless なナビゲーションができれば、問題の調査が大幅に効率化できるでしょう。Exploratoryなデータ分析をサポートするためには、データのクエリ性や、ビジュアライゼーションの柔軟性も欠かせません。これらの課題は、一朝一夕には解決できないかもしれません。しかし、シグナル相関の重要性を認識し、地道な改善を積み重ねていくことが大切です。特に、OpenTelemetryを中心とするオープンソースの活用と、コミュニティでの知見共有が、課題の克服に大きく役立つはずです。将来に向けたシグナル相関の可能性本章のエッセンスは、シグナル相関がオブザーバビリティの真価を引き出すための鍵だということだと思います。複雑化するシステムの動作を理解し、問題の迅速な特定と解決を実現するには、複数のシグナルを組み合わせて分析する必要があります。OpenTelemetryを活用することで、ベンダーロックインを回避しつつ、メタデータ主導の自動化された相関が可能になるでしょう。一方で、相関の実装には多くの課題が立ちはだかります。データのボリューム、カーディナリティ、プライバシーなど、技術的にも運用的にも乗り越えるべきハードルは少なくありません。しかし、著者が強調するように、これらの課題に真正面から向き合い、地道な改善を重ねていくことが重要です。シグナル相関は、オブザーバビリティの究極の目標とも言えます。全てのシグナルを横断的に分析し、システム全体の動作を俯瞰的に把握する。そこから得られる洞察は、開発者の生産性向上だけでなく、ビジネス上の意思決定にも大きな価値をもたらすはずです。セキュリティの分野でも、シグナル相関の重要性が増しています。複数のログソースを相関させることで、不正アクセスや情報漏洩の兆候をいち早く検知できます。また、トレースデータとの相関により、脆弱性の原因となるコードを特定することも可能になるでしょう。セキュリティインシデントの防止と、影響範囲の特定に、シグナル相関が大きく貢献する可能性があります。さらに、AIOpsの文脈でも、シグナル相関への期待が高まっています。機械学習やビッグデータ分析と組み合わせることで、システムの異常をリアルタイムに検知し、自動的に対処するような仕組みが実現できるかもしれません。複雑さを増すシステムの運用を、人間の手に頼らずに自動化していくために、シグナル相関が重要な基盤となるはずです。クラウドネイティブ時代のシステムは、ますます分散化・動的化が進んでいくでしょう。コンテナやサーバーレス、マイクロサービスなど、新しいアーキテクチャが次々と登場する中で、オブザーバビリティの重要性はこれまで以上に高まっています。その中で、シグナル相関は、システムの可視性と制御可能性を飛躍的に向上させる、強力な武器になり得ます。本章を通して、シグナル相関の重要性と実践的な手法について理解を深めることができました。OpenTelemetryを中心とするオープンな標準の採用と、コミュニティ全体での知見の共有が、相関技術の発展には欠かせません。課題を一つ一つ克服しながら、より高度な相関の実現を目指していきたいと思います。皆さんの組織では、シグナル相関にどのように取り組まれていますか？OpenTelemetryの活用状況や、相関分析から得られた知見など、ぜひ共有いただければと思います。シグナル相関は、オブザーバビリティ分野における次のブレークスルーになるかもしれません。 複数のシグナルを行き来しながら、システムの本質的な理解に迫っていく。そのためのデータ基盤とスキルを獲得することが、私たちに求められているのではないでしょうか。冒頭でも述べたように、単一のシグナルだけでは、もはやシステムの全容を把握することはできません。ログ、メトリクス、トレース、そしてプロファイル。これらの多様なシグナルを縦横無尽に相関させる力こそが、複雑さに立ち向かうための何よりの武器となるはずです。本書のラストを飾るに相応しい、示唆に富んだ一章でした。ここで得られた学びを胸に、オブザーバビリティのさらなる高みを目指して精進したいと思います。シグナル相関の可能性を追求し、より俊敏で、よりレジリエントなシステムを作り上げていく。それが、私たちソフトウェアエンジニアとSREに託されたミッションなのだと、改めて感じた次第です。さいごに本書「Cloud Observability in Action」を通じて、クラウドネイティブ時代におけるオブザーバビリティの重要性と、その実現に向けた具体的な方法論を学ぶことができ視座を得られました。著者が一貫して訴えかけているのは、オブザーバビリティがツールの導入だけで達成できるものではない、ということです。ログ、メトリクス、トレース、プロファイルなど、様々なシグナルを適切に収集・分析するための技術的な基盤は不可欠ですが、それ以上に重要なのは、オブザーバビリティの文化を組織全体に根付かせ、データドリブンな意思決定を日常的に実践していくことだと説いています。また、オープンスタンダードとオープンソースソフトウェアの活用が強く推奨されています。ベンダーロックインを避け、持続可能なイノベーションを実現するために、OpenTelemetryに代表されるようなオープンな標準や、コミュニティ主導のオープンソースプロジェクトが果たす役割の大きさを再認識させられました。本書の内容を実践するのは容易ではありませんが、その努力は決して無駄にはならないはずです。オブザーバビリティの向上は、システムの信頼性と俊敏性を高めるだけでなく、ビジネスの成功とも直結するからです。本書で得られた知見を咀嚼し、行動に移していくこと。それが、著者のメッセージを真に理解し、オブザーバビリティの価値を自らの組織にもたらすための鍵となるでしょう。クラウドの時代において、オブザーバビリティは「あったら良いもの」ではなく「なくてはならないもの」になりつつあります。本書はその重要性を説き、実践への道筋を示してくれる、頼もしい道しるべだと言えます。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。参考資料Observability WhitepaperPerformance ReportReturn on Investment Driven ObservabilityIntro to exemplars, which enable Grafana Tempo’s distributed tracing at massive scaleMTBF, MTTR, MTTA, and MTTFDocker daemon configuration overviewContainer Runtime Interface (CRI)github | CrunchyData/pgmonitorLogging in Action - With Fluentd, Kubernetes and moreContextual Logging in Kubernetes 1.24System LogsFluentdFluent BitElastic BeatsLogstashOpenSearch Data Preppersyslog-ngrsyslogGraylogCriblPrometheusCollectdGrafana AgentGraphiteNagiosStatsDTelegrafOpenTelemetryOpenTelemetry Java Auto-InstrumentationOpenTelemetry JavaScriptOpenTelemetry Node SDKOpenTelemetry PythonOpenTelemetry .NET Auto-InstrumentationOpenTelemetry Go InstrumentationCloud Native Observability with OpenTelemetryPractical OpenTelemetryLearning OpenTelemetryAmazon CloudWatch AgentAWS Embedded Metric Format (EMF)AWS CloudWatch Agent OpenTelemetry SupportAWS Distro for OpenTelemetryAzure Monitor Agent (AMA)Azure OpenTelemetry SupportGoogle Cloud Ops AgentVector by DatadogLogstash, Fluentd, Fluent Bit, or Vector ComparisonVector, Fluent Bit, Fluentd Performance BenchmarkingOpenTelemetry Collector Performance | BenchmarksAWS Distro for OpenTelemetry Collector PerformanceOpenTelemetry Collector DashboardOpenSearch Install with DockerKubernetes Control Plane LogsKubernetes Worker Node LogsAWS CloudTrailAmazon CloudWatch LogsAWS Embedded Metric Format (EMF)Azure Monitor LogsGoogle Cloud LoggingElasticsearchOpenSearchApache LuceneElasticsearch in Action, Second EditionGrafana LokiZincObserveSplunkInstanaSolarWindsLogz.ioAmazon CloudWatch MetricsAmazon Managed Service for PrometheusPrometheus Remote WriteAmazon TimestreamAzure Monitor MetricsGoogle Cloud MonitoringGoogle Cloud Managed Service for PrometheusCNCF CortexThanosClymeneGrafana MimirIcingaInfluxDBLinDBM3DBM3DB at FOSDEM 2020Nagios CoreNetdataNightingaleOpenTSDBPromscaleTimescaleDBQuestDBZabbixChronosphereVictoriaMetricsPrometheus Compliance GuideAWS X-RayDistributed Tracing in AzureGoogle Cloud TraceJaegerZipkinGrafana TempoGoogle Cloud Trace OverviewApache CassandraScyllaDBApache DruidApache Druid: overview, running in Kubernetes and monitoring with PrometheusApache PinotReal-time analytics on network flow data with Apache PinotClickHouseAltinity Operator for ClickHouseFrostDBSnowflakeComparison of the Open Source OLAP Systems for Big DataOpenTelemetry Columnar EncodingDesigning Data-Intensive ApplicationsFundamentals of Data ObservabilityOpenTelemetry Fluent Forward ReceiverOpenTelemetry ClickHouse ExporterClickHouse Operations DocsClickHouse Networking ArticleClickCatPrestoDBAmazon RedshiftGoogle BigQueryCNCF Observability \u0026 Analysis LandscapeOpenTelemetry Vendor SupportApache KafkaOpenTelemetry Kafka ExporterElastic Common Schema (ECS)LogQLCloudWatch Logs Insights Query SyntaxSyslog Protocol (RFC 5424)Common Log FormatNGINX LoggingGraylog Extended Log Format (GELF)Windows Event Log SchemaCommon Event Format (CEF)Prometheus Query Language (PromQL)Prometheus Exposition FormatOpenMetricsInfluxData FluxGoogle pprofOpenTelemetry Protocol (OTLP)High-Cardinality TSDB BenchmarksGrafanaGrafana Data Sources DocumentationGrafana PluginsGrafana Dashboards DocumentationGrafana Alerting DocumentationAWS Managed GrafanaGrafana CloudKibanaOpenSearch Dashboards DocumentationCNCF JaegerApache SkyWalkingSigNozUptraceDatadogHoneycombNew RelicSplunkDatadog SyntheticsElastic SyntheticsNew Relic SyntheticsAmazon CloudWatch SyntheticsWhen to Alert on What?Anomaly Detection Reddit ThreadShoreline AIOpsAmazon SNSAlertmanager Configuration ExamplePrometheus Alerting RulesAwesome Prometheus AlertsAlertmanager Notification TemplatesCortex | Configuring Notification using Cortex AlertmanagerThanos | Alerting RulesPrometheus: Up \u0026 Running, 2nd EditionImproved Alerting With Prometheus and AlertmanagerLife of an Alert TalkGrafana Unified AlertingGrafana Contact PointsGrafana Contact Point TypesAmazon CloudWatch AlarmsAzure Monitor AlertsGoogle Cloud AlertingAWS CloudTrailReal User Monitoring OTEPGoogle AnalyticsAmazon CloudWatch RUMLeadDev An introduction to Real User Monitoring (RUM)Single-Page ApplicationsObservable Frontends OpenTelemetryOpenTelemetry Real User MonitoringAWS Cost and Usage ReportsOpenCostServerless: who’s on call now?All Things Clock, Time and Order in Distributed Systems: Physical Time in Depthhttps://www.w3.org/TR/trace-context/Tracesho11y (pronounced: howl-y)Cloud-Native Observability with OpenTelemetryhttps://httpstatuscodes.org/429/https://opentelemetry.io/docs/collector/deployment/Span Metrics Connectorhttps://keyval.dev/distributed-tracing-2025/Using latency histogramsService MapbubbleupShift-Left: A Developer's Pipe(line) Dream?A Modern Shift-Left Security ApproachGNU gprofDTrace ToolspprofProtocol BuffersIce and Fire: How to read icicle and flame graphshttps://man7.org/linux/man-pages/man2/bpf.2.htmlBPF Performance Tools (book)What Is eBPF?https://www.parca.dev/https://www.parca.dev/docs/parca-agent-language-supporthttps://demo.parca.dev/https://px.dev/https://pyroscope.io/https://demo.pyroscope.io/Continuous profiling now in public preview in Grafana CloudProposal: Adding profiling as a support event typeWhat is Amazon CodeGuru Profiler?Profile production applications in Azure with Application Insights ProfilerProfiling concepts ; Google CloudProfiling and optimization - Dynatrace DocsReal-time profiling for Java using JFR metricsProfiling and optimization - Dynatrace DocsFantastic Symbols and Where to Find Them - Part 1BPF binaries: BTF, CO-RE, and the future of BPF perf toolsInstalling TracetestTrace-based testing cloud-native apps with AWS X-Ray and TracetestMonitoring and Testing Cloud Native APIs with GrafanaProfiles, the Missing Pillar: Continuous Profiling in Practice - InfoQ- BPF Portability and CO-REFrostDBGorilla: A Fast, Scalable, In-Memory Time Series DatabaseTime-series Compression Algorithms ExplainedQuerying ParcaFlameQLLaunchDarkly: Feature Management PlatformAmazon CloudWatch Evidently - Implement Safer Feature Releases and A/B ExperimentsFallacies of Distributed SystemseBay/flow-telemetry: Open source host/network flow collector and exporterDigma: Developer Observability and Continuous FeedbackSprkl: Developer Tool for Continuous Observabilitysprkl-dev/use-sprkl: React hook for Sprkl integrationTracetest: Integration testing platform for cloud-native systemsgoogle/pprof/profile.protoInstalling the protocol compilerBuf: A new way of working with Protocol BuffersProtoman: A GUI for Protobuf filespostmanlabs/postman-app-support: How to encode protobuf in Postman?Flame GraphsDatadog Continuous ProfilerProfilerpedia - Profilers by LanguageDataDog/go-profiler-notes/guideRookout: Debug and Understand Live CodeAutometrics: Observability made simple for developersNew Relic Thread ProfilerProdfiler: Continuous Profiling for Production ApplicationsGranulate Continuous ProfilingBooks For Site Reliability EngineeringThe RED Method: A New Approach to Monitoring Microservices - The New StackGroupGitHub - pyrra-dev/pyrra: Making SLOs with Prometheus manageable, accessible, and easy to use for everyone!Welcome to SLOcademyPyrraSLO-Based Observability For All Kubernetes Cluster Components - Matthias Loibl \u0026 Nadine Vehling - YouTubeSloth - SlothCoreDNS availability - SlothNobl9 Reliability Software and Tools to Manage SLOs and MonitoringConcepts in service monitoring  |  Google Cloud Observabilityサービスレベル目標（SLO）SLOs: Service Level Objectives | HoneycombService-level objectives - Dynatrace DocsGet started with New Relic service levelsSLA vs. SLI vs. SLO: Understanding Service Levels | SplunkOpenSLOcommunity/sig-scalability/slos/slos.md at master · kubernetes/community · GitHubThe first Service Level Objective Conference for Site Reliability Engineers Correlating Signals Efficiently in Modern ObservabilitySemantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryTrace Semantic Conventions | OpenTelemetrygRPCMetrics Semantic Conventions | OpenTelemetryGeneral Logs Attributes | OpenTelemetryResource Semantic Conventions | OpenTelemetryMetrics Semantic Conventions | OpenTelemetryRFC 7231: Hypertext Transfer Protocol (HTTP/1.1): Semantics and ContentTraces | OpenTelemetryApache KafkaEvent Listener - Amazon EventBridge - AWSAWS X-RayIntroduction to exemplarsBuild an observability solution using managed AWS services and the OpenTelemetry standard | AWS Cloud Operations \u0026 Migrations BlogOne Observability WorkshopOperationCorrelationTelemetryInitializer Class (Microsoft.ApplicationInsights.Extensibility) - Azure for .NET Developers | Microsoft LearnCorrelate log entries  |  Cloud Logging  |  Google CloudCustom Correlation for Java ApplicationsConfigure Custom Correlation for .NET ApplicationsMetric CorrelationsCorrelate Request Logs With Traces Automatically | Datadog White modal up arrow Icon/worldCorrelating distributed traces of large scale systems | Dynatrace EngineeringAPM Alternative \u0026 Platform Comparison | HoneycombCloud ObservabilityCorrelate Logs and TracesConfigure correlation logic with decisionscorrelate - Splunk DocumentationCloud scale correlation and investigation with Cloud SIEM | Sumo LogicBrightTalkData protection - European CommissionTAG OBS Query Standardization WG Charter - Google ドキュメント","link":"https://syu-m-5151.hatenablog.com/entry/2024/05/10/121047","isoDate":"2024-05-10T03:10:47.000Z","dateMiliSeconds":1715310647000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"もう一度読むObservability Engineering","contentSnippet":"はじめに本書『Observability Engineering』は、複雑化の一途をたどる現代のソフトウェアシステムに立ち向かうための、強力な武器となる一冊であり本稿はその読書感想文です。Observability Engineering を今から知りたい方はもちろん、Observability Engineering の基礎を改めて学びたい方もぜひお読みください。この記事もかなりの長さになるので普通に書籍を読んだほうがいいかもですlearning.oreilly.com「Observability:可観測性」という言葉は、近年ソフトウェアエンジニアリングの世界で大きな注目を集めています。しかし、その概念の本質を理解し、実践に移すことは容易ではありません。本書は、そのオブザーバビリティについて、その基本的な考え方から、具体的な実装方法、そして組織への適用まで、幅広くかつ深く解説しています。著者らは、Honeycombというオブザーバビリティプラットフォームの開発に携わった経験から、その知見を余すところなく共有しています。Observability Engineering (English Edition)作者:Majors, Charity,Fong-Jones, Liz,Miranda, GeorgeO'Reilly MediaAmazon私自身、2022年に本書を読んだ際には、その内容を理解したつもりになっていました。しかし、色んな経験や話を聞いた今になって再読してみると、当時の理解は表面的なものに過ぎなかったことに気づかされます。人間や組織の話もめちゃくちゃにぶつかったのでその内容がドンピシャでもあった。自分が何を大事にしているのかを見失わないためには、新しい書籍や新しい資料を読むよりも、一度立ち止まって原書を振り返るのも良いかもしれません。再読は、わからなさという困難を洗練させ、既知と未知のネットワークを創造的に発展させる知的技術であり、自分自身と向き合い、本の内容を理解するための行為なのです。再読だけが創造的な読書術である作者:永田希筑摩書房Amazon現在、様々なシステムではマイクロサービスアーキテクチャを採用し、その規模と複雑さを増す一方です。その中で、システムの動作を把握し、問題の原因を特定することがいかに難しいかを日々実感しているかと思います。本書で説かれているオブザーバビリティの考え方は、まさにその難題に対する答えとも言えるものでした。本書を通じて、オブザーバビリティとは単なるツールの問題ではなく、システムと向き合うための思想そのものだと理解できました。そして、その理解は私たちのチームの実装にも反映され、システムの可視性と理解度は格段に向上しています。また、本書はオブザーバビリティがもたらす組織文化の変革についても示唆に富んでいます。部署間のサイロを打ち破り、エンジニア全員がシステムの全体像を共有する。そのような文化があってこそ、真のオブザーバビリティが実現できるのだと納得させられました。本書は、現代のソフトウェア開発に携わる全てのエンジニアにとって、必読の一冊だと言えます。システムの複雑さに悩まされている方、モニタリングの限界を感じている方、チームのコミュニケーションを改善したい方。本書はそのような様々な課題を抱えるエンジニアに、明確な指針を与えてくれるはずです。また、翻訳版もあります。ありがたいので両方読みましょう。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社Amazonオブザーバビリティについて何も分からない場合には、まずは、本ブログを読む前にkatzchangさんの発表をご覧になることをお勧めします。この発表では、オブザーバビリティの概念や重要性、実践的な手法などが丁寧に解説されています。発表内容を理解することで、オブザーバビリティに関する基礎知識を身につけることができると思います。www.youtube.comタイトルは株式会社Topotalの高村さんと菱田さんが行っている。もう一度読むSREを参考にさせていただきました。っていうタイトルを使わせてもらおうと連絡したところ元ネタを教えていただいた。もう一つ好きになった。新もういちど読む山川日本史山川出版社Amazon『Observability Engineering』の内容紹介本書は、オブザーバビリティの概念から実践までを網羅的に解説しており、現代のソフトウェア開発・運用に携わるエンジニアや管理職にとって必読の一冊と言えるでしょう。システムの安定稼働とパフォーマンス向上を目指す上で、オブザーバビリティは欠かせない要素であり、本書はその導入と実践に向けた最初の一歩を提供してくれます。Part Iでは、オブザーバビリティの定義と、なぜ現代のシステムにおいてオブザーバビリティが重要であるかを解説しています。オブザーバビリティとモニタリングの違いについても言及し、システムの複雑さや規模が増大する中で、オブザーバビリティという新しいアプローチの必要性を訴えています。Part IIは、オブザーバビリティの技術的な側面に焦点を当てています。構造化イベントの重要性や、分散トレーシングの役割、OpenTelemetryを用いた計装方法などが解説されています。また、オブザーバビリティとモニタリングの使い分けについても言及しています。Part IIIでは、チームや組織にオブザーバビリティを導入するための方法論が紹介されています。具体的には、オブザーバビリティ駆動開発、SLO（サービスレベル目標）との連携、ソフトウェアサプライチェーンへのオブザーバビリティの適用などが取り上げられています。Part IVは、大規模システムにおけるオブザーバビリティの実践について述べています。オブザーバビリティツールの選定基準や、データストアの設計、サンプリング戦略、テレメトリーパイプラインの構築などが解説されています。Part Vでは、組織全体でオブザーバビリティ文化を醸成するための方法が紹介されています。オブザーバビリティ投資の対効果や、ステークホルダーとの連携、オブザーバビリティ成熟度モデルなどが説明されています。本書を再読することで、オブザーバビリティに関する知識が深まり、既知の部分と未知の部分がつながって新しい理解が生まれました。この創発的な経験は、今後のオブザーバビリティの実践に役立つことでしょう。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon書籍のRepository以下のリポジトリには関連書籍のサンプルコードが収録されています。Go言語が苦も無く読める場合には学びになるのでここをまず見るのもありだと思う。resources.oreilly.com目次はじめに『Observability Engineering』の内容紹介書籍のRepository目次Part I. The Path to ObservabilityChapter 1. What Is Observability?オブザーバビリティの概念とその重要性オブザーバビリティとモニタリングの違いオブザーバビリティの必要性とその将来Chapter 2. How Debugging Practices Differ Between Observability and Monitoringモニタリングを用いたデバッグの限界オブザーバビリティがもたらすデバッグの改善オブザーバビリティの重要性Chapter 3. Lessons from Scaling Without ObservabilityParseにおけるスケーリングの課題モダンシステムへの進化モダンな実践へのシフトParseにおける実践のシフト様々な経験を経たオブザーバビリティの重要性Chapter 4. How Observability Relates to DevOps, SRE, and Cloud Nativeクラウドネイティブ、DevOps、SREの概要オブザーバビリティ：昔と今のデバッグオブザーバビリティがDevOpsとSREの実践を強化する再三だがオブザーバビリティの重要性Part II. Fundamentals of ObservabilityChapter 5. Structured Events Are the Building Blocks of Observabilityオブザーバビリティと構造化イベントメトリクスの限界非構造化ログの限界デバッグに役立つイベントのプロパティオブザーバビリティの基盤としての構造化イベントChapter 6. Stitching Events into Traces分散トレーシングの重要性トレーシングのコンポーネントトレースの手動インストルメンテーショントレースへのイベントの組み込みトレーシングの重要性とオープンソースフレームワークの活用Chapter 7. Instrumentation with OpenTelemetryOpenTelemetryの概要と重要性OpenTelemetryの主要コンポーネントOpenTelemetryを使った計装の例テレメトリデータの可視化OpenTelemetryの重要性と今後の展望Chapter 8. Analyzing Events to Achieve Observability既知の条件からのデバッグ第一原理に基づくデバッグコア分析ループの活用コア分析ループのブルートフォース部分の自動化AIOpsの誤ったアレオブザーバビリティ実現のためのイベント分析Chapter 9. How Observability and Monitoring Come Togetherモニタリングの適用範囲オブザーバビリティの適用範囲システムとソフトウェアの違い組織のニーズの評価例外として無視できないインフラストラクチャの監視実際の適用例組織の責任に基づくオブザーバビリティとモニタリングのバランスPart III. Observability for TeamsChapter 10. Applying Observability Practices in Your Teamコミュニティグループへの参加最も大きな痛みのポイントから始める既存の取り組みを活用する機会を探る最後の難関に備えるオブザーバビリティ実践の導入ヒントChapter 11. Observability-Driven Developmentテスト駆動開発とその限界開発サイクルにおけるオブザーバビリティマイクロサービス時代のデバッグインストルメンテーションがオブザーバビリティを促進する仕組みオブザーバビリティの左シフトオブザーバビリティを用いたソフトウェア開発の高速化オブザーバビリティ駆動開発の重要性Chapter 12. Using Service-Level Objectives for Reliability従来のモニタリングアプローチがもたらすアラート疲労ユーザーエクスペリエンスを指標とするサービスレベル目標とは何か？SLOベースのアラートへの文化の変革：ケーススタディSLOとオブザーバビリティによる信頼性の向上Chapter 13. Acting on and Debugging SLO-Based Alertsエラーバジェットが空になる前にアラートする時間をスライディングウィンドウとして捉える予測的バーンアラートを作成するための予測SLOバーンアラートへの対応SLOのためのオブザーバビリティデータと時系列データSLOとオブザーバビリティデータの組み合わせChapter 14. Observability and the Software Supply Chainオブザーバビリティがソフトウェアサプライチェーンに不可欠な理由共有ライブラリとディメンションサプライチェーンの運用化：ケーススタディコンテキストの理解アクショナブルなアラートの組み込み何が変更されたかの理解単なるツールではなく、文化でもあるPart IV. Observability at ScaleChapter 15. Build Versus Buy and Return on InvestmentオブザーバビリティのROI分析自社構築のメリットとリスク購入のメリットとリスク二者択一ではないタダより高いものはないChapter 16. Efficient Data Storageオブザーバビリティのための機能要件時系列データベースの限界列指向ストレージクエリワークロードスケーラビリティと耐久性オブザーバビリティデータ管理の新しいアプローチChapter 17. Cheap and Accurate Enough: Samplingサンプリングによるデータ収集の最適化サンプリング戦略の違いトレースイベントのサンプリングコードによるサンプリング戦略の実装大切なのは状況に応じた賢明なサンプリングChapter 18. Telemetry Management with Pipelinesテレメトリパイプラインの利点テレメトリパイプラインのアナトミーSlackでのテレメトリ管理の事例テレメトリパイプラインの重要性と選択Part V. Spreading Observability CultureChapter 19. The Business Case for Observabilityオブザーバビリティ導入へのリアクティブなアプローチオブザーバビリティのROIオブザーバビリティ導入へのプロアクティブなアプローチオブザーバビリティの実践適切なツールの選択十分なオブザーバビリティの判断オブザーバビリティ文化を組織全体に広めるためにChapter 20. Observability’s Stakeholders and Alliesエンジニアリング以外のオブザーバビリティニーズの認識実践におけるオブザーバビリティの同盟者の獲得カスタマーサポートチームカスタマーサクセスチームとプロダクトチーム営業チームとエグゼクティブチームオブザーバビリティツールとBIツールの使い分けオブザーバビリティの採用を組織全体に広げるためにChapter 21. An Observability Maturity Model成熟度モデルについての注意点オブザーバビリティが成熟度モデルを必要とする理由OMMが参照する能力組織のためのOMMの活用オブザーバビリティ成熟度モデルが示す道筋Chapter 22. Where to Go from Hereオブザーバビリティの定義の進化本書の構成の変遷オブザーバビリティ採用の社会技術的課題追加のリソースオブザーバビリティの未来予測オブザーバビリティ実践の継続的な進化さいごに参考資料Part I. The Path to Observability本書の第一部では本書の残りの部分で参照される概念を定義します。オブザーバビリティとは何か、オブザーバブルなシステムを特定する方法、およびオブザーバビリティベースのデバッグ技術が、モニタリングベースのデバッグ技術よりもモダンなソフトウェアシステムの管理に適している理由を言及してくれています。オブザーバビリティに関する別のオススメの書籍として、『Distributed Systems Observability』1を紹介しておきます。この書籍では、分散システムにおけるオブザーバビリティの重要性と、その実現方法について詳細に解説されています。learning.oreilly.comChapter 1. What Is Observability?オブザーバビリティの概念とその重要性「Chapter 1. What Is Observability?」は、オブザーバビリティの概念とその適用方法について非常に詳細かつ体系的に解説した章です。本書は、オブザーバビリティの数学的起源から始まり、ソフトウェア工学への適用、そしてモダンなシステムにおける必要性まで、丁寧に説明しています。本書によると、ソフトウェアシステムの文脈では、オブザーバビリティは以下の要件を満たすことを意味します。アプリケーションの内部動作を理解できるアプリケーションが取りうる任意の状態を理解できる外部ツールを用いて内部動作と状態を理解できる新しいコードをデプロイせずに内部状態を理解できるつまり、オブザーバビリティとは、システムの内部動作と状態を外部から観測し、理解できることを指します。 これにより、エンジニアはシステムの動作を深く理解し、問題の根本原因を特定することができるのです。この章で特に印象的だったのは、本書が従来のモニタリングアプローチとオブザーバビリティの違いを明確に示したことです。モニタリングは長年にわたってシステムを理解するための主要な手段でしたが、本書は、モニタリングには本質的な限界があると指摘しています。モニタリングは、予測可能な障害モードを検出するのには役立ちますが、予測不可能な障害モードに対応するのが難しいのです。 これは、モニタリングが事前に定義されたメトリクスとしきい値に依存しているためです。エンジニアは、想定される障害モードを予測し、それに応じてダッシュボードを設定する必要があります。しかし、モダンなシステムが複雑で動的であるため、すべての障害モードを事前に予測することは不可能です。これに対して、オブザーバビリティは、システムの内部状態を理解するための新しいアプローチを提供します。オブザーバビリティツールは、高カーディナリティ（一意性）と高次元のデータを収集し、問題の根本原因を特定するための柔軟なクエリを可能にします。 これにより、エンジニアは予測不可能な障害モードを見つけ出し、迅速に対応することができるのです。本書は、オブザーバビリティの重要な概念として「探索可能性（explorability）」を紹介しています。これは、システムに対して任意の質問をし、その内部状態を検査できる程度を表します。つまり、事前に予測することなく、システムが取りうる任意の状態を反復的に調査し、理解できるということです。 この概念は、モニタリングとは根本的に異なります。モニタリングでは、事前に定義されたメトリクスとしきい値に基づいてシステムを監視しますが、オブザーバビリティでは、データを柔軟に探索し、新しい洞察を得ることができるのです。2023年も SRE再考と叫びなさい‼️ より引用また、本書は、カーディナリティと次元の役割について詳しく説明しています。カーディナリティは、データセット内の一意の値を表し、次元はそのデータ内のキーの数を表します。オブザーバビリティツールは、高カーディナリティと高次元のデータを処理するように設計されており、これによりエンジニアは問題のあらゆる側面を調査することができるのです。 一方、モニタリングツールは、低カーディナリティのデータを処理するように設計されており、データの探索力に限界があります。オブザーバビリティとモニタリングの違いさらに、本書は、オブザーバビリティとモニタリングの目的の違いについても言及しています。モニタリングの主な目的は、システムの稼働時間を最大化し、障害を防ぐことです。一方、オブザーバビリティの目的は、システムの動作を深く理解し、パフォーマンスを最適化することです。オブザーバビリティは、障害を防ぐだけでなく、システムの継続的な改善を可能にするのです。本書は、オブザーバビリティがモダンなシステム、特に疎結合で動的かつ推論が難しい分散システムにとって不可欠であると強調しています。これらのシステムでは、予測不可能な障害モードが頻繁に発生するため、従来のモニタリングアプローチでは対応が難しいのです。オブザーバビリティは、これらの課題を克服し、システムの信頼性と性能を向上させるための強力な手段なのです。オブザーバビリティの必要性とその将来要約すると、「Chapter 1. What Is Observability?」は、オブザーバビリティとモニタリングの違いを明確に示し、オブザーバビリティの重要性を説得力のある形で伝えています。 本書は、モニタリングの限界を指摘し、オブザーバビリティがそれを克服するための鍵であることを論じています。また、探索可能性、カーディナリティ、次元といった重要な概念を導入し、オブザーバビリティを実現するための具体的な要件を示しています。この章は、モダンなシステムを管理するすべてのソフトウェアエンジニアにとって必読の内容です。 オブザーバビリティは、システムの信頼性と性能を向上させるための不可欠なツールであり、エンジニアはこの概念を深く理解する必要があります。また、この章は、オブザーバビリティとモニタリングの違いを明確に示しており、エンジニアがシステム管理のアプローチを選択する際の指針となるでしょう。Chapter 2. How Debugging Practices Differ Between Observability and Monitoring「Chapter 2. How Debugging Practices Differ Between Observability and Monitoring」は、モニタリングとオブザーバビリティを用いたデバッグ手法の違いについて、非常に詳細かつ具体的に解説した章です。本書は、従来のモニタリングに基づくデバッグ手法の限界を多角的に分析し、オブザーバビリティがそれらの限界をどのように克服するのかを、説得力のある事例を交えて明確に示しています。モニタリングを用いたデバッグの限界本書は、モニタリングを用いたデバッグ手法の特徴と限界について、詳細な説明を提供しています。モニタリングは、システムの状態を事前に定義された閾値と比較することで、異常を検知するための手法です。エンジニアは、メトリクスとダッシュボードを使って、システムのパフォーマンスを監視し、問題が発生したときに通知を受け取ります。この手法は、既知の障害モードを検出するのには非常に有効です。 エンジニアは、過去の経験に基づいて、どのようなメトリクスが問題を示唆するのかを理解しており、それらのメトリクスに基づいてアラートを設定することができます。しかし、本書は、この手法には重大な限界があると指摘しています。まず、モニタリングは、予測不可能な障害モードに対応するのが難しいという点です。モニタリングでは、事前に定義された閾値に基づいてアラートが発生するため、閾値が設定されていない問題を見落とす可能性があります。また、閾値を超えても、必ずしも問題があるとは限りません。誤検知が多発すると、アラート疲れを引き起こし、重大な問題を見落とすリスクがあるのです。次に、モニタリングは、問題の根本原因を特定するのが難しいという点です。モニタリングツールは、メトリクスを収集し、集約することで、システムの全体的なパフォーマンスを可視化します。しかし、集約されたメトリクスでは、問題の根本原因を特定するのに十分な情報が得られないことがあります。エンジニアは、ダッシュボードを見ながら、自分の経験と直感に頼って、問題の原因を推測しなければなりません。さらに、モニタリングツールは、データの探索性に乏しいという点も問題です。多くのモニタリングツールでは、ダッシュボードが事前に定義された条件に基づいて構築されるため、エンジニアは、ダッシュボードに表示されている情報だけを頼りに問題を調査しなければなりません。新しい問題が発生した場合、ダッシュボードを修正するまで、その問題を発見することは困難なのです。本書は、これらの限界により、モニタリングに基づくデバッグ手法は本質的に受動的であると述べています。エンジニアは、既知の問題を検出することはできますが、新しい問題を発見し、その根本原因を特定することは困難です。このような受動的なアプローチでは、問題が発生してから対応するのではなく、問題を予防することは難しいのです。オブザーバビリティがもたらすデバッグの改善本書は、オブザーバビリティがデバッグ手法に革新をもたらすと主張しています。オブザーバビリティは、システムの内部状態を外部から観測し、理解するための仕組みです。オブザーバビリティツールは、高カーディナリティ（一意性）と高次元のデータを収集し、柔軟なクエリを可能にすることで、エンジニアがシステムの動作を詳細に理解できるようにします。オブザーバビリティの最大の強みは、データの探索性にあります。 オブザーバビリティツールは、収集したデータに対して、自由にクエリを実行し、絞り込みを行うことができます。これにより、エンジニアは、システムの動作を多角的に分析し、問題の根本原因を特定することができるのです。本書は、オブザーバビリティがもたらす具体的な改善点として、以下の3つを挙げています。制度的知識への依存の減少：モニタリングに基づくデバッグ手法では、システムに関する深い知識と経験が求められます。そのため、ベテランのエンジニアに依存することが多く、ナレッジの共有が難しいという問題がありました。オブザーバビリティツールを使えば、経験の浅いエンジニアでも、システムを自由に探索し、問題を診断することができます。 これにより、チーム全体のデバッグ能力が向上し、ナレッジの共有が促進されるのです。隠れた問題の発見：モニタリングでは、事前に定義された閾値に基づいてアラートが発生するため、閾値が設定されていない問題を見落とす可能性があります。オブザーバビリティは、予測不可能な障害モードを発見し、その根本原因を特定するための強力な手段となります。 高カーディナリティと高次元のデータを収集することで、システムの動作を詳細に分析できるため、これまで見落とされていた問題を発見できる可能性が高まるのです。問題診断に対する自信の向上：モニタリングツールでは、複数のデータソースを行き来しながら、問題を診断しなければなりません。このため、エンジニアは、自分の経験と直感に頼らざるを得ず、問題の診断に自信を持てないことがあります。オブザーバビリティツールは、複数のデータソースを統合し、一貫したコンテキストを提供します。 これにより、エンジニアは、システムの動作を詳細に理解し、問題を自信を持って診断できるようになるのです。本書は、これらの改善点を、モニタリングとオブザーバビリティの違いを浮き彫りにする具体的な例を交えて説明しています。例えば、あるエンジニアがデータベースにインデックスを追加した場合、モニタリングツールでは、インデックスの効果を確認するのが難しいかもしれません。しかし、オブザーバビリティツールを使えば、クエリのパフォーマンスを詳細に分析し、インデックスの効果を確認できるのです。また、本書は、オブザーバビリティがシステムの予防保全にも役立つと述べています。オブザーバビリティツールを使えば、システムの動作を常に監視し、問題の兆候を早期に発見することができます。これにより、問題が発生する前に対策を打つことができ、システムの可用性と信頼性が向上するのです。オブザーバビリティの重要性従来のモニタリングに基づくデバッグ手法は、システムの複雑化に伴って限界に直面しています。モニタリングは、既知の問題を検出するのには有効ですが、予測不可能な問題に対応するのが難しいのです。また、モニタリングでは、問題の根本原因を特定するのが難しく、エンジニアは自分の経験と直感に頼らざるを得ません。一方、オブザーバビリティは、これらの限界を克服するための強力な手段を提供します。 オブザーバビリティツールは、高カーディナリティと高次元のデータを収集し、柔軟なクエリを可能にすることで、エンジニアがシステムの動作を詳細に理解できるようにします。これにより、エンジニアは、予測不可能な問題を発見し、その根本原因を特定することができるのです。また、オブザーバビリティは、エンジニアリングチームのデバッグ能力を大幅に向上させます。オブザーバビリティツールを使えば、経験の浅いエンジニアでも、複雑なシステムの問題を自信を持って診断できるようになります。これにより、チーム全体のデバッグ能力が向上し、ナレッジの共有が促進されるのです。さらに、オブザーバビリティは、システムの予防保全にも役立ちます。オブザーバビリティツールを使えば、システムの動作を常に監視し、問題の兆候を早期に発見することができます。これにより、問題が発生する前に対策を打つことができ、システムの可用性と信頼性が向上するのです。本章は、モニタリングとオブザーバビリティという2つのデバッグ手法の違いを明確に示し、オブザーバビリティの重要性を説得力のある形で伝えています。 本書は、モニタリングの限界を詳細に分析し、オブザーバビリティがそれらの限界を克服するための強力な手段であることを、具体的な事例を交えて論証しています。Chapter 3. Lessons from Scaling Without Observability「Chapter 3. Lessons from Scaling Without Observability」は、著者の一人であるCharity MajorsがParseでの経験を通して、オブザーバビリティなしでスケーリングすることの難しさと、そこから学んだ教訓について語った章です。モダンな分散システムを従来のモニタリングツールで管理することの限界と、オブザーバビリティの必要性が具体的な事例を通して説明されています。en.wikipedia.orgParseにおけるスケーリングの課題Parseは、モバイルアプリ開発者にバックエンドサービスを提供するプラットフォームでした。著者がParseに参加した当初、同社はまだベータ版のサービスを提供している段階で、Amazon CloudWatchを使用していました。本書は、Icinga/NagiosとGangliaに切り替えましたが、これらのツールはParseのニーズに十分に対応できませんでした。Parseは、マイクロサービスアーキテクチャを早期に採用し、MongoDBをデータストアとして使用していました。Ruby on Railsで開発を行い、複数のデータベースシャードをサポートするためにRailsにモンキーパッチを当てる必要がありました。Parseは、開発スピードを最優先に考えていましたが、これは正しい判断でした。 早期の技術選択は後に修正が必要になりましたが、顧客を満足させ、市場でニーズを見出すことができたからです。しかし、Parseが成長するにつれて、選択したアーキテクチャとツールの限界が明らかになってきました。あるノルウェーのデスメタルバンドのアプリがiTunesストアで上位にランクインした際、Parseはわずか数秒でダウンしてしまいました。これは、同社のスケーリングの問題を浮き彫りにしました。モダンシステムへの進化本書は、Parseが直面した課題を、ソフトウェア業界全体の変化と関連づけて説明しています。かつては、「アプリ」と「データベース」という単純な構成が主流でしたが、現在では、モノリシックなアプリケーションからマイクロサービスへの移行、多様なデータストアの採用、コンテナやサーバーレスなどのインフラストラクチャの活用など、大きな変化が起こっています。これらの技術的な変化は、組織や文化にも大きな影響を与えています。かつては、開発チームと運用チームの間に高い障壁があり、コードのデプロイが不安定さを引き起こすことが多かったため、運用チームは変更を嫌がる傾向にありました。しかし、モダンなシステムでは、マイクロサービスの採用により、サービスの段階的なロールアウトやフィーチャーフラグの活用が可能になり、デプロイのリスクが軽減されています。モダンな実践へのシフト本書は、これらの技術的な変化に伴い、エンジニアリングチームの実践もシフトする必要があると主張しています。ステージング環境は、モノリシックなシステムでは有用でしたが、分散システムでは、本番環境を完全に再現することが難しいため、その価値は低下しています。このため、デバッグや検査は本番環境で行う必要があります。また、ユーザーエクスペリエンスは、すべてのユーザーに対して一般化できなくなりました。サービスの異なるユーザーが、異なるコンポーネントを使って異なる経路をたどる可能性があるためです。モニタリングにおいても、既知の閾値を超えるエッジケースを探すアラートは、多くの誤検知を生み出します。アラートは、ユーザーエクスペリエンスに直接影響を与える症状にのみ焦点を当てるべきです。これらの変化は、本番環境に精通することの重要性を高めています。かつては、本番環境への変更を恐れ、問題が発生したらすぐにロールバックする傾向がありましたが、モダンなシステムでは、エンジニアが本番環境を深く理解し、問題に対して細やかな調整を行えるようになる必要があるのです。Parseにおける実践のシフトParseでは、従来のアプローチでは対応できない新しい問題が次々と発生し、ヒーロー文化の限界が明らかになりました。かつては、最も経験豊富なエンジニアが最高のデバッガーでしたが、これはスケールしません。Facebookに買収された後、著者はScubaというデータ管理システムに出会いました。Scubaは、リアルタイムでデータを細かくスライスアンドダイスできる機能を提供し、新しい問題の原因をわずか数分で特定できるようになりました。この経験から、本書では、問題を新しいものとしてアプローチし、データに基づいて真の原因を特定することの重要性を学びました。オブザーバビリティにより、マイクロサービス、ポリグロットストレージシステム、マルチテナンシーなど、従来のアプローチでは扱いが難しかった問題を、迅速かつ効果的に診断できるようになったのです。様々な経験を経たオブザーバビリティの重要性著者の経験は、従来のモニタリングアプローチから、モダンな分散システムとオブザーバビリティへの移行の必要性を示しています。オブザーバビリティは、モダンなシステムのスケーリングに伴う問題を解決するための鍵です。 アプリケーションのテレメトリーを適切な抽象度で収集し、ユーザーエクスペリエンスを中心に集約し、リアルタイムで分析できるようにすることで、システムの内部動作を深く理解できるようになります。オブザーバビリティにより、エンジニアリングチームは、システムの問題を迅速に特定し、根本原因を突き止められるようになります。 これにより、ヒーロー文化から脱却し、チーム全体でナレッジを共有し、効果的なデバッグを行えるようになるのです。著者の経験は、多くの組織がモダンな分散システムを採用するにつれて、ますます一般的になっています。オブザーバビリティは、これらのシステムのスケーリングに不可欠なものとなっているのです。Chapter 4. How Observability Relates to DevOps, SRE, and Cloud Native「Chapter 4. How Observability Relates to DevOps, SRE, and Cloud Native」は、オブザーバビリティがDevOps、SRE、クラウドネイティブの実践とどのように関係しているかを解説した章です。本書は、これらの動きがオブザーバビリティの必要性を高めると同時に、オブザーバビリティがこれらの実践を強化していると主張しています。CNCFのドキュメントにも記載がありますがめちゃくちゃに簡潔です。glossary.cncf.ioオブザーバビリティに関する包括的な解説書として、「Cloud Observability in Action」が挙げられます。この書籍では、クラウドネイティブシステムにおけるオブザーバビリティの適用方法、様々なオブザーバビリティシグナル(ログ、メトリクス、トレースなど)の特徴と費用対効果、適切なインストルメンテーションとシグナル収集の手法、大規模なダッシュボーディング、アラート、SLO/SLIの提供、役割やタスクに応じた適切なシグナルタイプの選択、目的に応じた最適なオブザーバビリティツールの選び方、経営陣へのオブザーバビリティの効果のコミュニケーション方法などが解説されています。learning.oreilly.com適切に設計されたオブザーバビリティシステムは、クラウドネイティブアプリケーションのバグやパフォーマンス問題に関する洞察を提供します。開発チームがコード変更の影響を理解し、最適化を測定し、ユーザーエクスペリエンスを追跡するのに役立ちます。さらに、オブザーバビリティによってエラー処理を自動化し、マシンユーザーが自身で修正を適用できるようになるため、深夜の緊急障害発生による呼び出しも不要になります。クラウドネイティブ、DevOps、SREの概要本書は、モノリシックなアーキテクチャとウォーターフォール開発から、クラウドネイティブとアジャイル手法への移行が進んでいると指摘しています。クラウドネイティブは、スケーラビリティと開発速度の向上を目指していますが、同時に管理コストの増加という課題も抱えています。クラウドネイティブシステムを実現するには、継続的デリバリーやオブザーバビリティなどの高度な社会技術的実践が不可欠なのです。また、DevOpsとSREは、フィードバックループを短縮し、運用の負担を軽減することを目指しています。DevOpsは、開発と運用の協調を通じて価値の提供を加速し、SREはソフトウェアエンジニアリングのスキルを活用して複雑な運用問題を解決します。クラウドネイティブ技術、DevOpsとSRE手法、オブザーバビリティの組み合わせは、それぞれの個別の要素よりも強力なのです。※こちら、SREがもう少し気になる方向けsyu-m-5151.hatenablog.comオブザーバビリティ：昔と今のデバッグオブザーバビリティの目的は、システムの内部状態を理解するための内省を提供することです。モノリシックなシステムでは、詳細なアプリケーションログやシステムレベルのメトリクスを使用して、潜在的な障害箇所を予測し、デバッグすることができました。しかし、これらのレガシーツールと直感的なテクニックは、クラウドネイティブシステムの管理課題には対応できなくなっています。クラウドネイティブ技術は、コンポーネント間の依存関係による認知的複雑さ、コンテナ再起動後に失われる一時的な状態、個別にリリースされるコンポーネント間のバージョン不整合など、新しい問題を引き起こします。分散トレーシングなどのツールを使用して、特定のイベントが発生したときのシステム内部の状態を捕捉することで、これらの問題をデバッグできるようになります。オブザーバビリティがDevOpsとSREの実践を強化するDevOpsとSREチームの仕事は、本番システムを理解し、複雑さを制御することです。したがって、彼らがシステムのオブザーバビリティに関心を持つのは自然なことです。SREはSLOとエラーバジェットに基づいてサービスを管理し、DevOpsは開発者が本番環境でコードに責任を持つ、クロスファンクショナルな実践を通じてサービスを管理します。成熟したDevOpsとSREチームは、ユーザーに影響を与える症状を測定し、オブザーバビリティツールを使用して障害の理解を深めます。 これにより、チームは実際のシステム障害に対する仮説を体系的に絞り込み、緩和策を考案することに集中できるようになります。さらに、先進的なDevOpsとSREチームは、フィーチャーフラグ、継続的検証、インシデント分析などのエンジニアリング手法を使用しています。オブザーバビリティは、これらのユースケースを効果的に実践するために必要なデータを提供することで、これらのユースケースを強化します。カオスエンジニアリングと継続的検証では、システムの基準状態を理解し、期待される動作を予測し、期待される動作からの逸脱を説明するためにオブザーバビリティが必要です。フィーチャーフラグでは、ユーザーごとにフィーチャーフラグの個別の影響と集合的な影響を理解するためにオブザーバビリティが必要です。カナリアリリースやブルー/グリーンデプロイメントなどの段階的リリースパターンでは、リリースを停止するタイミングを知り、システムの期待値からの逸脱がリリースに起因するかどうかを分析するためにオブザーバビリティが必要です。インシデント分析と非難のない事後検証では、技術システムの内部で何が起こっていたかだけでなく、インシデント中にオペレーターが何を信じていたかを明確にモデル化する必要があります。オブザーバビリティツールは、事後の記録を提供し、回顧録の作成者に詳細な手がかりを与えることで、優れた振り返りを行うことを可能にします。再三だがオブザーバビリティの重要性本章の結論として、DevOps、SRE、クラウドネイティブの実践が進化し、プラットフォームエンジニアリングが包括的な規律として成長するにつれ、より革新的なエンジニアリング実践がツールチェーンに現れるだろうと述べています。しかし、これらのイノベーションはすべて、現代の複雑なシステムを理解するための中核的な感覚としてオブザーバビリティを必要とするでしょう。DevOps、SRE、クラウドネイティブの実践への移行は、オブザーバビリティのようなソリューションの必要性を生み出しました。一方、オブザーバビリティは、その実践を採用したチームの能力を飛躍的に高めてきました。オブザーバビリティは、モダンなソフトウェア開発と運用に不可欠な要素となっています。 それは、複雑なシステムを理解し、問題を迅速に特定し、根本原因を突き止めるための強力なツールを提供します。また、オブザーバビリティは、DevOpsとSREの実践を強化し、カオスエンジニアリング、フィーチャーフラグ、段階的リリース、インシデント分析などのエンジニアリング手法を効果的に実践するためのデータを提供します。クラウドネイティブ、DevOps、SREの動きは、オブザーバビリティの必要性を高めると同時に、オブザーバビリティがこれらの実践を強化しているのです。オブザーバビリティは、モダンなソフトウェアエンジニアリングにおいて不可欠な要素であり、その重要性はますます高まっていくでしょう。Part II. Fundamentals of Observability本書の第2部では、オブザーバビリティの技術的な側面について深く掘り下げ、オブザーバブルなシステムにおいて特定の要件が必要とされる理由を詳しく説明します。Chapter 5. Structured Events Are the Building Blocks of Observability「Chapter 5. Structured Events Are the Building Blocks of Observability」は、オブザーバビリティの基本的な構成要素である構造化イベントについて詳しく解説した章です。本書はオブザーバビリティを実現するために、任意の幅を持つ構造化イベントが不可欠であると主張し、構造化イベントの概念、利点、オブザーバビリティにおける役割について深く掘り下げています。構造化イベントの背景を理解するには、マイクロサービスアーキテクチャの知識が役立ちます。「Monolith to Microservices」は、従来のモノリシックなアーキテクチャからマイクロサービスへの移行プロセスを詳しく解説しており、様々な具体例、洞察に富んだ移行パターン、実務的なアドバイスが満載です。初期計画からアプリケーション・データベースの分解に至るまで、移行の様々なシナリオやストラテジーが網羅されており、既存アーキテクチャの移行に役立つ試行済みのパターン・テクニックを学ぶことができます。マイクロサービスへの移行を検討する組織にとって理想的な一冊であり、移行の是非、タイミング、開始地点の判断を支援するだけでなく、レガシーシステム移行、マイグレーションパターン、データベース移行例、同期戦略、アプリケーション分解、データベース分解の詳細などについても掘り下げられています。learning.oreilly.comオブザーバビリティと構造化イベントオブザーバビリティとは、システムが取りうる任意の状態を理解し、説明できる程度を表します。そのためには、事前に予測することなく、あらゆる質問に答えられるようにしなければなりません。これを可能にするのが、構造化イベントなのです。構造化イベントとは、1つのリクエストがサービスと相互作用している間に発生したすべてのことを記録したものです。リクエストの入力時に既知のデータを事前に入力し、実行中に発見された有用な情報を追加し、リクエストの出力時やエラー時にパフォーマンスに関するデータを記録します。例えば、あるウェブサーバーへのリクエストでは、リクエストに含まれる各パラメータ（ユーザーIDなど）、意図したサブドメイン（www、docs、support、shopなど）、合計処理時間、依存する子リクエスト、それらの子リクエストを満たすために関与する様々なサービス（web、database、auth、billingなど）、各子リクエストの処理時間などを記録することができます。このように、構造化イベントには、リクエストの実行に関するコンテキストを表すデータが豊富に含まれています。 成熟した計装では、イベントごとに300〜400のディメンションが含まれることが一般的だそうです。構造化イベントを使ってサービスの動作を理解する際には、後でデバッグに関連する可能性のあるものを何でも記録するというモデルを覚えておく必要があります。これには、リクエストパラメータ、環境情報、ランタイムの内部情報、ホストやコンテナの統計情報などが含まれます。メトリクスの限界本書は、メトリクスの限界についても詳しく説明しています。メトリクスに関しては改定した『Prometheus: Up \u0026 Running, 2nd Edition』も紹介しておきます。learning.oreilly.comメトリクスとは、事前に定義された期間にわたってシステムの状態を表す数値を収集し、必要に応じてタグを付けてグループ化や検索を可能にしたものです。メトリクスは、従来のソフトウェアシステムの監視の中核をなすものです。しかし、メトリクスの根本的な限界は、それが事前に集約された測定値だということです。メトリクスによって生成される数値は、事前に定義された期間におけるシステム状態の集約レポートを反映しています。この事前集約された測定値は、システム状態を調べるための最小の粒度となり、多くの潜在的な問題を覆い隠してしまうのです。例えば、page_load_timeというメトリクスは、直近の5秒間にすべてのアクティブページの読み込みにかかった平均時間を調べるかもしれません。requests_per_secondというメトリクスは、直近の1秒間にあるサービスがオープンしていたHTTP接続の数を調べるかもしれません。メトリクスは、特定の期間に測定されたプロパティの数値で表現されるシステムの状態を反映しています。 その期間中にアクティブだったすべてのリクエストの動作は、1つの数値に集約されます。この例では、そのシステムを流れる特定のリクエストの存続期間中に何が起こったかを調査することは、これらのメトリクスにつながる一連の痕跡を提供することになります。しかし、さらに掘り下げるために必要な粒度のレベルは利用できません。このように、メトリクスは、1つのシステムプロパティの1つの狭いビューとしてのみ機能します。粒度が大きすぎ、システムの状態を別のビューで表示する能力が硬直していて、1つのサービスリクエストの作業単位を表すために組み合わせるには限界があります。非構造化ログの限界本書は、非構造化ログの限界についても言及しています。ログファイルは、本質的に大きな非構造化テキストの塊であり、人間が読めるように設計されていますが、機械で処理するのは難しいです。これらのファイルは、アプリケーションや様々な基盤システムによって生成される文書で、設定ファイルで定義された、注目に値するすべてのイベントの記録が含まれています。従来のログは、人間が読みやすいように設計されているため、非構造化になっています。残念ながら、人間が読みやすくするために、ログではしばしば、1つのイベントの生々しい詳細が複数行のテキストに分割されてしまいます。例えば、以下のようなログがあるとします。6:01:00 accepted connection on port 80 from 10.0.0.3:633496:01:03 basic authentication accepted for user foo  6:01:15 processing request for /super/slow/server6:01:18 request succeeded, sent response code 200  6:01:19 closed connection to 10.0.0.3:63349このような物語形式の構造は、開発段階でサービスの詳細を学ぶ際には役立ちますが、大量のノイズデータを生成し、本番環境では遅くて扱いにくくなります。非構造化ログは人間が読めますが、計算的に使用するのは難しいのです。 一方、構造化ログは機械で解析可能です。上の例は、構造化ログに書き換えると以下のようになります。time=\"6:01:00\" msg=\"accepted connection\" port=\"80\" authority=\"10.0.0.3:63349\"time=\"6:01:03\" msg=\"basic authentication accepted\" user=\"foo\"  time=\"6:01:15\" msg=\"processing request\" path=\"/super/slow/server\"time=\"6:01:18\" msg=\"sent response code\" status=\"200\"  time=\"6:01:19\" msg=\"closed connection\" authority=\"10.0.0.3:63349\"さらに、これらのログ行を1つのイベントにまとめると、以下のようになります。{\"authority\":\"10.0.0.3:63349\",\"duration_ms\":123,\"level\":\"info\",  \"msg\":\"Served HTTP request\",\"path\":\"/super/slow/server\",  \"port\":80,\"service_name\":\"slowsvc\",\"status\":200,\"time\":\"2019-08-22T11:57:03-07:00\",\"trace.trace_id\":\"eafdf3123\",\"user\":\"foo\"  }このように、構造化ログは、構造化イベントに似るように再設計されていれば、オブザーバビリティの目的に役立ちます。デバッグに役立つイベントのプロパティ新しい問題をデバッグするには、通常、外れ値の条件を持つイベントを検索し、パターンを見つけたり、それらを関連付けたりすることで、以前は知られていなかった障害モードを発見することを意味します。そのような相関関係を見つけるには、オブザーバビリティソリューションが高カーディナリティのフィールドを処理できる必要があります。カーディナリティとは、セット内の一意の要素の数を指します。一意の識別子を含むディメンションは、可能な限り最高のカーディナリティを持ちます。例えば、ある問題の原因を突き止めるために、「先週の火曜日にアプリをインストールした、ファームウェアバージョン1.4.101を実行している、写真をus-west-1のshard3に保存しているフランス語パックを使用しているiOS11バージョン11.0.4を実行しているすべてのカナダのユーザー」を見つけ出すクエリを作成する必要があるかもしれません。これらの制約のひとつひとつが、高カーディナリティのディメンションなのです。オブザーバビリティツールは、調査員に役立つためには、高カーディナリティのクエリをサポートできる必要があります。 現代のシステムでは、新しい問題をデバッグするのに最も役立つディメンションの多くは、カーディナリティが高くなっています。また、調査では、これらの高カーディナリティのディメンションを組み合わせる（つまり、高次元）ことで、深く隠れた問題を見つけ出すことがよくあります。高カーディナリティと高次元は、複雑な分散システムの干し草の山から、非常に細かい針を見つけ出すための機能なのです。オブザーバビリティの基盤としての構造化イベント本章の結論として、オブザーバビリティの基本的な構成要素は、任意の幅を持つ構造化イベントであると強調しています。オブザーバビリティには、デバッグプロセスを反復的に進める際に、あらゆる質問に答えるために、任意の数のディメンションに沿ってデータをスライスアンドダイスする能力が必要です。 構造化イベントは、システムが1つの作業単位を達成したときに何が起こっていたかを理解するのに十分なデータを含んでいる必要があるため、任意の幅でなければなりません。分散サービスの場合、これは通常、1つの個別のサービスリクエストの存続期間中に発生したすべてのことの記録として、イベントのスコープを設定することを意味します。メトリクスは、システムの状態を表す1つの狭いビューとしてのみ機能します。粒度が大きすぎ、システムの状態を別のビューで表示する能力が硬直していて、オブザーバビリティの基本的な構成要素としては限界があります。非構造化ログは人間が読めますが、計算的に使用するのは難しいです。構造化ログは機械で解析可能であり、構造化イベントに似るように再設計されていれば、オブザーバビリティの目的に役立ちます。オブザーバビリティを実現するには、構造化イベントという形でテレメトリを収集し、高カーディナリティと高次元のデータを分析できる機能が不可欠なのです。Chapter 6. Stitching Events into Traces分散トレーシングの重要性「Chapter 6. Stitching Events into Traces」は、構造化イベントをトレースに組み立てる方法と、その重要性について詳しく解説した章です。本書は、分散トレーシングが今日において重要である理由を詳細に説明しています。現代のソフトウェアシステムは、多数のサービスが連携して機能するマイクロサービスアーキテクチャが主流となっています。このような環境では、あるリクエストを処理するために、複数のサービスを横断する必要があります。分散トレーシングは、そのリクエストがどのようにサービス間を移動し、処理されているかを追跡するための方法です。これにより、障害が発生した場所を特定し、パフォーマンスのボトルネックとなっている要因を特定することができます。マイクロサービスアーキテクチャの普及に伴い、このようなデバッグ手法の需要が高まっているのです。また、分散システムでは、サービス間の依存関係が複雑になるため、問題の原因を特定することが非常に難しくなります。例えば、あるサービスがデータベースの応答を待っている間にレイテンシが累積し、上流のサービスに伝播していくことがあります。分散トレーシングは、このようなサービス間の関係を明確に示すことができるため、問題の根本原因を突き止めるために非常に有効なのです。本書は、分散トレーシングが最初に注目を集めるようになったのは、2010年にGoogleがDapper論文を発表して以降だと述べています。Dapperは、Googleが社内で使用している分散トレーシングシステムで、大規模な分散システムのパフォーマンスを理解し、障害を特定するために開発されました。Dapper論文の発表後、TwitterがZipkinを、UberがJaegerというオープンソースのトレーシングプロジェクトを立ち上げました。これらのプロジェクトは、Dapperの概念を基に、より一般的な用途に適したトレーシングシステムを提供しています。また、Honeycomb や Lightstep などの商用ソリューションも登場しています。このように、分散トレーシングは、現代のソフトウェアシステムにおいて不可欠なツールとなっており、その重要性は日に日に高まっているのです。トレーシングのコンポーネント本書は、トレースを構成するコンポーネントについて、非常に詳細に説明しています。トレースは、1つのリクエストに関連する一連のイベントを表します。これらのイベントは、トレーススパンと呼ばれる個々のチャンクで構成されています。各スパンは、リクエストの処理中に発生した作業の一部を表しており、その作業が行われたサービスや、作業の開始時刻と期間などの情報を含んでいます。Figure 6-1. This waterfall-style trace visualization displays four trace spans during one request より引用トレース内の各スパンは、ルートスパンと呼ばれるトップレベルのスパンの中にネストされています。ルートスパン自体は親を持ちませんが、その下のスパンは親子関係を持ちます。例えば、サービスAがサービスBを呼び出し、サービスBがサービスCを呼び出す場合、スパンAはスパンBの親であり、スパンBはスパンCの親であるという関係になります。Figure 6-2. A trace that has two parent spans. Span A is the root span and is also the parent of Span B. Span B is a child of Span A and also the parent of Span C. Span C is a child of Span B and has no child spans of its own.  より引用本書は、トレースを構築するために必要な5つのデータについても詳しく説明しています。トレースID：トレース全体を通して一意な識別子。ルートスパンによって作成され、リクエストの処理中に伝播される。スパンID：各スパンを一意に識別するための識別子。親ID：スパンのネストの関係を定義するために使用されるフィールド。ルートスパンには存在しない。タイムスタンプ：スパンの作業が開始された時刻を示す。期間：作業が完了するまでにかかった時間を記録する。これらのフィールドは、トレースの構造を組み立てるために絶対に必要です。さらに、サービス名やスパン名などの追加のフィールドを含めることで、スパンを特定したり、システムとの関係を理解したりするのに役立ちます。本書は、これらのコンポーネントがどのように機能するかを理解することが、分散トレーシングを効果的に活用するために重要だと強調しています。トレースの手動インストルメンテーション本書は、トレースのコアコンポーネントがどのように機能するかを理解するために、単純なトレーシングシステムを手動で実装する例を提示しています。この例では、Goを使用して、3つのスパンを持つウェブエンドポイントを実装しています。rootHandlerへのオリジナルリクエスト認証サービスへの呼び出し（リクエストを認証するため）名前サービスへの呼び出し（ユーザー名を取得するため）コードの例では、以下のステップでトレースを生成しています。ルートスパンでトレースIDとスパンIDを生成する。リクエストの開始時と終了時のタイムスタンプを取得し、その差分からスパンの期間を計算する。サービス名とスパン名を追加する。アウトバウンドのHTTPリクエストにトレースIDと親スパンIDを伝播させる。さらに、デバッグに役立つ追加のフィールド（ホスト名、ユーザー名など）をスパンに追加する方法も示されています。Figure 6-3. Our example app would now propagate traceID and parentID to each child span本書は、これらのコードの例が、トレーシングの概念を理解するために役立つものの、実際のアプリケーションでは、ボイラープレートコードを自分で書く必要はないと述べています。通常、トレーシングシステムには、これらの設定作業の大部分を行うためのライブラリが用意されています。ただし、これらのライブラリは、特定のトレーシングソリューションに固有のものであることが多く、別のソリューションを試すためにはコードを再インストルメント化する必要があります。次章では、オープンソースでベンダーに依存しないOpenTelemetryプロジェクトについて説明します。トレースへのイベントの組み込み本書は、前章で説明した構造化イベントをトレースに組み込む方法についても言及しています。イベントは、オブザーバビリティの構成要素であり、1つのリクエストがサービスとやり取りしている間に発生したすべてのことの記録です。リクエストの実行中に発生した興味深い詳細（変数の値、渡されたパラメータ、返された結果、関連するコンテキストなど）はすべてイベントに追加されるべきです。コードの例では、リモートサービスの呼び出しレベルでインストルメンテーションを行っていますが、オブザーバブルなシステムでは、同じアプローチを使って、異なるソースからの任意の数の相関イベントを結びつけることができます。例えば、現在の単一行のロギングソリューションから、より統合されたビューへの移行の第一歩として、構造化ログにトレースの概念を適用することができます。また、分散型ではないが、独自のスパンに分割したいような作業のチャンク（JSONのアンマーシャリングなどのCPU集約型の操作など）にも、同じ手法を使うことができます。オブザーバブルなシステムでは、任意の一連のイベントをトレースに組み込むことができます。 トレーシングは、サービス間の呼び出しに限定される必要はありません。同じバッチジョブから作成されたすべての個別のファイルアップロードなど、システム内の相互に関連する離散的なイベントにも適用できます。トレーシングの重要性とオープンソースフレームワークの活用本章の結論として、イベントがオブザーバビリティの構成要素であり、トレースは単に相互に関連するイベントの系列であると強調しています。スパンを結合してトレースを作成するために使用される概念は、サービス間の通信の設定に非常に役立ちます。 これらの概念を理解することは、分散システムの動作を理解し、問題の根本原因を特定するために不可欠です。また、オブザーバブルなシステムでは、これらの同じ概念を、remote procedure call(RPC)を行うことを超えて、相互に関連するシステム内の離散的なイベントに適用することもできます。 これにより、システムの動作をより詳細に理解し、問題の原因を特定することができるようになります。本章ではトレースを手動でインストルメント化する方法を示しましたが、より実用的な方法は、インストルメンテーションフレームワークを使用することだと述べています。次章では、オープンソースでベンダーに依存しないOpenTelemetryプロジェクトと、それを使って本番アプリケーションをインストルメント化する方法と理由について説明します。分散トレーシングは、現代のソフトウェアシステムにとって不可欠なツールであり、オブザーバビリティを実現するための重要な要素です。 構造化イベントをトレースに組み立てることで、分散システムの動作を詳細に理解し、問題の根本原因を特定することができるようになります。また、OpenTelemetryのようなオープンソースのインストルメンテーションフレームワークを活用することで、ベンダーロックインを避け、様々なトレーシングソリューションを柔軟に試すことができます。これにより、システムの可観測性を継続的に向上させ、より信頼性の高いサービスを提供することができるのです。Chapter 7. Instrumentation with OpenTelemetry「Chapter 7. Instrumentation with OpenTelemetry」は、オープンソースのインストルメンテーションフレームワークであるOpenTelemetryについて詳しく解説し、それを使って本番アプリケーションをインストルメント化する方法と理由を説明した章です。本書は、ベンダーに依存しない計装の重要性を強調し、OpenTelemetryの機能と利点を具体的に示しています。私も『Learning Opentelemetry』という書籍の読書感想文のブログを書いたので合わせてぜひ読んでみてください。syu-m-5151.hatenablog.comOpenTelemetryの概要と重要性本書は、まずOpenTelemetryプロジェクトの概要を説明しています。OpenTelemetryは、CloudBeesとGoogleが主導するオープンソースプロジェクトで、ベンダーに依存しない一貫した方法でテレメトリデータを収集するための単一の標準を作ることを目的としています。OpenTelemetryの主な目標は、アプリケーションの計装を簡素化し、ベンダーロックインを回避することです。 開発者は、OpenTelemetryのSDKとAPIを使って一度アプリケーションを計装するだけで、バックエンドのテレメトリシステムを柔軟に変更できます。これは、特定のベンダーのライブラリを使う場合と対照的です。また、OpenTelemetryは、分散トレーシング、メトリクス、ロギングの3つの主要なテレメトリ信号をサポートしています。これにより、エンドツーエンドの可観測性を実現し、アプリケーションの動作を包括的に理解することができます。本書は、OpenTelemetryを使う主な理由として、次の3つを挙げています。ベンダーロックインの回避テレメトリデータ収集の標準化複数のテレメトリ信号のサポートOpenTelemetryの主要コンポーネント次に、著者はOpenTelemetryの主要コンポーネントについて説明しています。OpenTelemetryは、以下の3つの主要コンポーネントで構成されています。OpenTelemetry API：計装コードを書くためのプログラミング言語固有のインターフェイス。OpenTelemetry SDK：APIの実装を提供し、テレメトリデータの収集、処理、エクスポートを行う。OpenTelemetry Collector：複数のソースからテレメトリデータを受信し、処理し、様々なバックエンドシステムにエクスポートするためのスタンドアロンサービス。OpenTelemetry APIは、ベンダーに依存しない一貫した方法でテレメトリデータを生成するためのプログラミング言語固有のインターフェイスを提供します。これにより、開発者は計装コードを一度書くだけで、バックエンドのテレメトリシステムを変更する際に、そのコードを変更する必要がなくなります。OpenTelemetry SDKは、APIの具体的な実装を提供し、OpenTelemetry Collectorなどのエクスポートサービスにデータを送信します。SDKは、サンプリング、フィルタリング、エンリッチメントなどの機能も提供します。OpenTelemetry Collectorは、複数のソースからテレメトリデータを収集し、それを処理して、様々なバックエンドシステムにエクスポートするためのスタンドアロンサービスです。Collectorは、OpenTelemetryの中心的なコンポーネントであり、データの収集、処理、エクスポートを分離することで、システムの柔軟性と拡張性を高めています。OpenTelemetryを使った計装の例本書は、OpenTelemetryを使ってGoアプリケーションを計装する具体的な例を示しています。まず、OpenTelemetry APIとSDKをインポートし、トレーサープロバイダを初期化します。次に、スパンを作成し、そこにアプリケーション固有の情報を追加していきます。スパンの作成と管理は、OpenTelemetry APIが提供するTracerオブジェクトを通して行います。コードの例では、HTTPハンドラ内でスパンを作成し、リクエストの属性をスパンに追加しています。また、別の関数を呼び出す際には、contextパッケージを使ってスパンのコンテキストを伝播させています。func handler(w http.ResponseWriter, r *http.Request) {    // リクエストからコンテキストを取得    ctx := r.Context()        // 新しいスパンを開始    ctx, span := tracer.Start(ctx, \"hello\")    defer span.End()    // リクエストの属性をスパンに追加    span.SetAttributes(        semconv.HTTPMethodKey.String(r.Method),        semconv.HTTPTargetKey.String(r.URL.Path),    )    // 別の関数を呼び出す際に、スパンのコンテキストを渡す      helloHandler(ctx)}この例では、OpenTelemetryが提供するセマンティック規則に従って、HTTPリクエストの属性をスパンに追加しています。これにより、システム間で一貫性のあるテレメトリデータを収集することができます。本書は、OpenTelemetryが提供する自動計装の機能についても触れています。自動計装機能を使えば、アプリケーションコードを変更することなく、一般的なライブラリやフレームワークからテレメトリデータを収集することができます。 これにより、計装の手間を大幅に減らすことができます。再三の紹介ではあるがCloud Observability in Actionを読んでいただければ嬉しいです。learning.oreilly.comテレメトリデータの可視化最後に、著者は収集したテレメトリデータを可視化する方法について説明しています。OpenTelemetryは、様々なバックエンドシステムにデータをエクスポートすることができます。本書は、Jaegarを使ってトレースデータを可視化する例を示しています。JaegarはOpenTelemetryに対応したオープンソースのトレーシングバックエンドで、トレース データを収集、保存、可視化するための機能を提供しています。Jaegarの Web UIを使えば、収集したトレースデータをさまざまな角度から探索することができます。例えば、特定のスパンを選択して、その詳細情報を表示したり、関連するスパンをハイライトしたりすることができます。また、トレースのパフォーマンスを分析するためのツールも提供されています。本書は、OpenTelemetryとJaegarを組み合わせることで、アプリケーションの動作を詳細に理解し、パフォーマンスのボトルネックを特定できると述べています。OpenTelemetryの重要性と今後の展望本章の結論として、OpenTelemetryがアプリケーションの計装において重要な役割を果たすと強調しています。OpenTelemetryは、ベンダーロックインを回避し、テレメトリデータ収集を標準化するためのオープンソースのインストルメンテーションフレームワークです。 それは、分散トレーシング、メトリクス、ロギングという3つの主要なテレメトリ信号をサポートし、エンドツーエンドの可観測性を実現します。OpenTelemetryの主要コンポーネントであるAPI、SDK、Collectorは、テレメトリデータの生成、収集、処理、エクスポートを柔軟かつ拡張可能な方法で行うための基盤を提供します。特に、Collectorは OpenTelemetryアーキテクチャの中心的な存在であり、様々なデータソースからのテレメトリデータを統合し、複数のバックエンドシステムにエクスポートすることを可能にします。本書は、OpenTelemetryを使った計装の具体的な例を示し、それがいかにアプリケーションの動作を理解するのに役立つかを説明しました。OpenTelemetryのAPIとSDKを使えば、アプリケーションに一貫した方法で計装を行うことができ、バックエンドのテレメトリシステムを柔軟に変更することができます。また、自動計装機能を使えば、アプリケーションコードに変更を加えることなく、一般的なライブラリやフレームワークからテレメトリデータを収集することができます。収集したテレメトリデータは、Jaegarなどのバックエンドシステムを使って可視化し、分析することができます。これにより、アプリケーションのパフォーマンスを詳細に理解し、ボトルネックを特定することができます。OpenTelemetryは、現代のクラウドネイティブアプリケーションにとって不可欠のツールになりつつあります。 それは、複雑で動的なマイクロサービスアーキテクチャを観測し、トラブルシューティングするためのデファクトスタンダードになる可能性を秘めています。OpenTelemetryの採用が進むことで、アプリケーションの可観測性が向上し、より信頼性の高いシステムを構築することができるでしょう。しかし、まだまだ自分で超えなきゃいけない山もいくつかあるのかぁって思っています。dev.henry.jpChapter 8. Analyzing Events to Achieve Observability「Chapter 8. Analyzing Events to Achieve Observability」は、オブザーバビリティを実現するためのイベント分析の方法と、従来のデバッグ手法との違いについて詳しく解説した章です。本書は、第一原理に基づいて客観的にシステムを理解することの重要性を強調し、コア分析ループを使ってイベントデータを効果的に分析する方法を提示しています。既知の条件からのデバッグ本書は、オブザーバビリティが登場する以前のデバッグ手法の特徴として、システムに関する知識に基づいて問題を特定していたことを指摘しています。熟練したエンジニアは、長年の経験で培った直感を頼りに、どこを見れば問題が見つかるかを知っています。しかし、これはシステムに対する深い理解があってこそ可能な手法であり、新しいメンバーがチームに加わったり、システムが大規模化・複雑化したりすると、すぐに限界に達してしまいます。インフラエンジニアとして、私自身もこのような状況を数多く経験してきました。新しいサービスのリリースや、システムの大規模な変更の際には、必ず予期せぬ問題が発生するものです。そのたびに、ログやメトリクスを頼りに、問題の原因を探り当てようと奮闘したことを思い出します。特に、マイクロサービスアーキテクチャの普及に伴い、システムの複雑性が飛躍的に高まった昨今では、単純なログの監視やダッシュボードの確認だけでは、問題の全容を掴むことが難しくなってきています。サービス間の依存関係が複雑に絡み合い、一つの障害が連鎖的に他のサービスに影響を及ぼすことも珍しくありません。著者も指摘しているように、ランブックの作成やダッシュボードのカスタマイズに多くの時間を費やすことは、もはや効率的とは言えません。モダンなシステムでは、同じ障害が二度と発生しないことが多いため、これらの努力は無駄になってしまうのです。 むしろ、そうした手作業の時間を、より本質的な問題の解決に充てるべきでしょう。第一原理に基づくデバッグ本書は、オブザーバビリティを実現するためには、イベントとして収集したテレメトリデータを第一原理に基づいて分析することが重要だと述べています。第一原理とは、他の仮定から演繹されていない基本的な仮定のことを指します。第一原理に基づいてデバッグするということは、システムを科学的に理解するための方法論に従うということです。 それは、何も仮定せず、何が確かに正しいのかを問い直すことから始まります。そして、その原理に基づいて仮説を立て、システムに関する観察によってその仮説を検証していくのです。これは、インフラエンジニアにとって非常に重要な考え方だと思います。私たちは、日々、複雑で予測不可能なシステムと向き合っています。その中で問題を解決するためには、因習や思い込みにとらわれることなく、常に原理原則に立ち返って考える姿勢が求められます。本書は、第一原理に基づくデバッグがオブザーバビリティの中核的な機能であると強調しています。システムの複雑さが増すにつれ、経験や直感に頼ったデバッグは非現実的になります。第一原理に基づくデバッグは、システムに精通していなくても問題を特定できる、体系的で再現性のある方法なのです。これは、チームの属人性を減らし、誰もが同じ品質でデバッグできるようにするためにも重要です。ベテランエンジニアの「勘」に頼るのではなく、誰もが同じプロセスを踏めば同じ結果が得られるようにしておくことが、チームの生産性と品質の向上につながります。コア分析ループの活用本書は、第一原理に基づくデバッグの具体的な方法として、コア分析ループを紹介しています。コア分析ループは、テレメトリデータから仮説を立て、データによってその仮説を検証するプロセスを繰り返すことで、複雑な問題の答えを体系的に導き出す方法です。Figure 8-1. The core analysis loop より引用コア分析ループは以下の4つのステップで構成されています。調査のきっかけとなった全体像から始める。これまでに分かっていることが正しいかを検証する。パフォーマンスの変化を引き起こしている可能性のあるディメンションを探す。何が起こっているのかを十分に理解できたかを判断し、できていなければ、次の出発点として現在のビューを絞り込み、ステップ3に戻る。これは、第一原理に基づくデバッグの基本であり、インフラエンジニアにとっても非常に有用な手法だと思います。利用可能なすべてのディメンションを繰り返し調べることで、システムに関する事前の知識がなくても、問題の原因となっているディメンションを特定することができます。実際、私自身もこの手法を用いて、複雑な障害の原因を突き止めたことがあります。あるとき、あるマイクロサービスのレスポンスタイムが突然悪化し、原因が全くわからないという事態に陥りました。そこで、コア分析ループを使って、関連するすべてのメトリクスを洗い出し、一つ一つ仮説を立てて検証していきました。結果として、原因はデータベースへの接続数の上限に達していたことだとわかりました。その問題自体は設定変更で簡単に解決できたのですが、重要なのは、事前にその可能性を予測していなかったにもかかわらず、コア分析ループを使って問題を特定できたことです。ただし、著者も指摘するように、この作業を人間だけで行うのは非常に時間がかかります。システムが大規模で複雑になればなるほど、調べるべきディメンションの数は膨大になります。オブザーバビリティツールは、このブルートフォース分析をできる限り自動化する必要があるのです。コア分析ループのブルートフォース部分の自動化コア分析ループは、大量のシステムノイズの中から重要なシグナルを客観的に見つけ出すための方法です。この作業を迅速に行うためには、マシンの計算能力を活用することが不可欠です。本書は、Honeycombの BubbleUp機能を例に、コア分析ループの自動化について説明しています。BubbleUpは、注目すべきパフォーマンスの領域を選択すると、その領域内外のすべてのディメンションの値を計算し、差分の割合で並べ替えて表示します。これにより、どのディメンションがパフォーマンスの異常に関与しているかが一目でわかるようになっています。ちなみに他の監視基盤でも同様にできるはずです。こうした自動化は、インフラエンジニアやSREの負担を大幅に軽減してくれます。私たちは、データの中から重要なパターンを見つけ出すことに集中でき、膨大な生データを手作業で処理する必要がなくなるのです。また、著者が指摘するように、この自動化には、オブザーバビリティの基本的な構成要素である、任意の幅を持つ構造化イベントが不可欠です。従来のメトリクスやログでは、データの粒度が粗すぎたり、コンテキストが不足していたりするため、自由自在な分析ができないのです。私自身、以前はメトリクスベースの監視ツールを使っていましたが、ある問題をきっかけにオブザーバビリティツールの導入を決めました。それは、あるマイクロサービスの障害が、別のサービスに連鎖的に影響を及ぼすという事案でした。メトリクスだけでは、どのサービスが原因で、どの順序で障害が伝播したのかを追跡することができませんでした。そこで、OpenTelemetryを使って各サービスをインストルメント化し、Jaegerでトレースデータを収集・可視化する環境を構築しました。すると、サービス間の呼び出し関係が一目瞭然になり、障害の原因を瞬時に特定できるようになったのです。まさに、オブザーバビリティの威力を実感した瞬間でした。AIOpsの誤ったアレ本書は、AIOps（運用のための人工知能）の過度な期待について警鐘を鳴らしています。AIOpsは、異常検知やアラートノイズの削減などの分野でオブザーバビリティと交差しますが、万能な解決策ではありません。AIによる異常検知は、「正常」なベースラインイベントと「異常」なイベントを比較するという概念に基づいています。しかし、頻繁にシステムの動作が変化するような環境では、AIが正しいベースラインを選択するのは非常に難しいのです。AIは、完全に正常な動作を異常と見なしたり、異常を正常と誤認したりする可能性があります。これは、インフラエンジニアとして痛感している問題です。私たちは、常に変化し続けるシステムを扱っています。新機能のリリースや設定変更など、日々のオペレーションが常に「異常」を生み出しているのです。そのような環境で、AIだけに頼って異常を検知することは現実的ではありません。むしろ、著者が述べているように、人間の知性とコンテキストの理解が不可欠だと思います。コンピューターにはデータを大量に処理して興味深いパターンを見つけ出すことを任せ、そのパターンが本当に問題を示しているのかを判断するのは人間の役割なのです。 これこそが、オブザーバビリティとコア分析ループの自動化において、人間とマシンの知性を融合させる最良の方法だと私も考えます。実際、私たちのチームでも、オブザーバビリティツールが検出した異常を、エンジニアが一つ一つ確認するプロセスを設けています。既存のAIと呼ばれる機構だけでなく、生成AIモデルによる分析結果も同様に、人間による検証が欠かせません。某かが問題と判断した事象の多くは、実は仕様変更や一時的なスパイクだったりするのです。そうした「偽陽性」を排除し、本当に対処が必要な問題にフォーカスするには、人間の判断が欠かせません。オブザーバビリティ実現のためのイベント分析本章の結論として、適切なテレメトリデータを収集することは、オブザーバビリティへの第一歩に過ぎないと強調しています。そのデータを第一原理に基づいて分析することで、複雑な環境におけるアプリケーションの問題を客観的かつ正確に特定することができるのです。 コア分析ループは、障害箇所を迅速に特定するための効果的な手法ですが、システムが複雑になるほど、人間が methodically行するのは時間がかかります。そこで、異常の原因を探る際には、非常に大きなデータセットから興味深いパターンを迅速に見つけ出すために、計算リソースを活用することができます。そのパターンを人間のオペレーターに提示し、必要なコンテキストに置いて調査の方向性を further示してもらうことで、マシンと人間の強みを最大限に活用し、システムのデバッグを迅速に進められるのです。オブザーバビリティシステムは、前章で学んだイベントデータに対してこの種の分析パターンを適用するように構築されています。 適切なデータと、そのデータを分析して迅速に答えを得るための手法の両方を理解することで、オブザーバビリティの真価を発揮することができるのです。インフラエンジニアとして、私はこの章で紹介されたコンセプトの多くを実践してきました。コア分析ループは、複雑な障害の原因を突き止めるための強力な武器であり、オブザーバビリティツールの自動化機能と組み合わせることで、その威力はさらに増します。また、人間とマシンの知性を適切に組み合わせることの重要性も、身をもって体験しています。AIには膨大なデータを高速に処理する能力がありますが、そこから意味のある洞察を引き出すには、人間の専門知識と判断力が必要不可欠なのです。私たちインフラエンジニアやSREは、システムの安定運用という重大な責務を負っています。そのためには、単に技術的なスキルだけでなく、システムを俯瞰的に捉え、本質的な問題を見抜く力が求められます。オブザーバビリティは、そのための強力な武器になると確信しています。本章で紹介された手法を実践することで、私たちは、システムの動作を深く理解し、問題の予兆を早期に検知し、障害の影響を最小限に抑えることができるようになるでしょう。それは、ユーザーに価値を届け続けるために、そして自らの成長のためにも、私たちに課せられた使命だと思うのです。Chapter 9. How Observability and Monitoring Come Together「Chapter 9. How Observability and Monitoring Come Together」は、オブザーバビリティとモニタリングの違いを明確にし、それぞれの適切な適用範囲と、両者が補完的に機能する方法について解説した章です。本書は、組織のニーズに応じて、オブザーバビリティとモニタリングを適切に組み合わせることの重要性を強調しています。モニタリングの適用範囲本書は、まずモニタリングの適用範囲について詳細に説明しています。モニタリングは、システムの状態を理解するための成熟した手法であり、何十年にもわたって洗練されてきました。当初の単純なメトリクスとRRD（Round-Robin Database）から、TSDB（Time Series Database）と精巧なタグ付けシステムへと進化を遂げてきたのです。モニタリングのベストプラクティスは広く知られており、特定のツールに特化したコミュニティを超えて理解されています。例えば、「人間がグラフを1日中見ている必要はなく、何か問題があればシステムが自動的に通知すべき」というのは、モニタリングの中核をなす広く受け入れられている考え方です。この意味で、モニタリングシステムは本質的にリアクティブです。既知の障害状態に反応して、人間に問題の発生を警告するのです。つまり、モニタリングは、既知の未知（known-unknowns）を検出するように最適化されているのです。この特性から、モニタリングは、アプリケーションコードよりも変更頻度が低く、予測可能なシステムの状態を理解するのに最適だと言えます。本書は、ここでいうシステムとは、ソフトウェアを実行するために必要な基盤、つまりインフラストラクチャやランタイムを指していると説明しています。オブザーバビリティの適用範囲一方、オブザーバビリティは、より能動的なアプローチを取ります。本書は、オブザーバビリティの実践では、エンジニアは常に本番環境のコードを監視し、異常や興味深い兆候を探るべきだと述べています。第8章で説明されているように、コア分析ループは、第一原理に基づくデバッグを可能にし、未知の未知（unknown-unknowns）を発見するように設計されています。つまり、オブザーバビリティは、システムよりも頻繁に、そしてより予測不可能な方法で変化する、開発中のソフトウェアの状態を理解するのに最適化されているのです。モニタリングとオブザーバビリティのツールには、異なるベストプラクティスと実装があり、異なる目的に役立ちます。システムとソフトウェアの違い本書は、システムとソフトウェアの違いについても詳しく説明しています。より伝統的な環境では、システムとソフトウェアの区別は明確でした。ベアメタルのインフラストラクチャがシステムであり、その上で動作するすべてがソフトウェアでした。しかし、モダンなシステムとその多くの高次の抽象化により、その区別はやや不明確になっています。ここでの定義に従えば、ソフトウェアとは、顧客に価値を提供する本番サービスを運用するために、アクティブに開発されているコードのことです。ソフトウェアは、ビジネスが市場の問題を解決するために実行したいものです。一方、システムとは、そのサービスを運用するために必要な、基盤となるインフラストラクチャとランタイムに関するすべてを包括する用語です。システムは、ビジネスがソフトウェアを実行するために必要なものです。この定義では、データベース（MySQLやMongoDBなど）、コンピュートとストレージ（コンテナや仮想マシンなど）、その他、ソフトウェアをデプロイして実行する前にプロビジョニングして設定する必要があるすべてのものが、システム（またはインフラストラクチャ）に含まれます。クラウドコンピューティングの世界では、これらの定義を明確にするのがやや難しくなっています。例えば、ソフトウェアを実行するために、Apache Kafkaのような基盤コンポーネントが必要だとします。もしそれらのコンポーネントへのアクセスをサービスとして購入するのであれば、それはインフラストラクチャとはみなされません。本質的に、他の誰かにそれを運用してもらうためにお金を払っているのです。しかし、自分たちでインストール、設定、時々のアップグレード、パフォーマンスのトラブルシューティングを行う必要があるのであれば、それは気にかける必要のあるインフラストラクチャなのです。ソフトウェアに比べて、システム層のすべては、変更頻度が低く、異なるユーザーセットに焦点を当て、異なる価値を提供するコモディティです。ソフトウェア、つまり顧客が使用するために書かれたコードは、ビジネスの中核を差別化するものです。それは、今日の企業が存在する理由そのものです。したがって、ソフトウェアには、管理方法に関する異なる考慮事項があります。以下は、システムとソフトウェアの間で異なる要因を比較しています。変更の頻度：システムではパッケージの更新が月単位であるのに対し、ソフトウェアではリポジトリへのコミットが日単位で行われます。予測可能性：システムは高い（安定している）のに対し、ソフトウェアは低い（多くの新機能がある）。ビジネスへの価値：システムは低い（コストセンター）のに対し、ソフトウェアは高い（収益の源泉）。ユーザー数：システムは少ない（内部チーム）のに対し、ソフトウェアは多い（顧客）。中核となる関心事：システムではシステムやサービスが健全かどうかであるのに対し、ソフトウェアでは各リクエストが適時かつ確実にエンドツーエンドの実行に必要なリソースを獲得できるかどうか。評価の視点：システムではシステム自体であるのに対し、ソフトウェアでは顧客。評価基準：システムでは低レベルのカーネルとハードウェアデバイスドライバであるのに対し、ソフトウェアでは変数とAPIエンドポイント。機能的責任：システムではインフラストラクチャの運用であるのに対し、ソフトウェアではソフトウェアの開発。理解の方法：システムではモニタリングであるのに対し、ソフトウェアではオブザーバビリティ。インフラストラクチャに関しては、管理チームの視点のみが重要です。インフラストラクチャについて問うべき重要な質問は、それが提供するサービスが本質的に健全かどうかということです。そうでない場合、そのチームは迅速に行動を起こし、インフラストラクチャを健全な状態に戻す必要があります。インフラストラクチャの健全性に影響を与える条件は、変化が少なく、比較的予測が容易です。実際、これらの問題を予測し（例：キャパシティプランニング）、自動的に修復する（例：オートスケーリング）ためのプラクティスはよく確立されています。その比較的予測可能でゆっくりと変化する性質のため、集約されたメトリクスは、システムレベルの問題の監視とアラートには完全に適しているのです。一方、アプリケーションコードでは、最も重要なのは顧客の視点です。基盤となるシステムは本質的に健全かもしれませんが、ユーザーリクエストはさまざまな理由で失敗する可能性があります。先行する章で説明したように、分散システムはこの種の問題の検出と理解を難しくしています。突然、高カーディナリティのフィールド（ユーザーID、ショッピングカートIDなど）を使って、特定の顧客の体験を観察する能力が重要になってきます。特に、継続的デリバリーのモダンな世界では、新しいバージョンのコードが常にデプロイされているため、ソフトウェアの関心事は常にシフトし、変化しています。オブザーバビリティは、これらの関心事に対処するための適切な質問をリアルタイムで行う方法を提供します。これら2つのアプローチは相互に排他的ではありません。すべての組織には、どちらかのカテゴリに当てはまる考慮事項があるでしょう。次に、組織のニーズに応じて、この2つのアプローチが共存する方法を見ていきます。組織のニーズの評価本書は、オブザーバビリティとモニタリングの適切なバランスを見出すには、組織のニーズを評価することが重要だと述べています。モニタリングは、システムレベルの関心事を理解するのに最適です。オブザーバビリティは、アプリケーションレベルの関心事を理解するのに最適です。どの関心事がビジネスにとって最も重要かを理解することが、組織自身のニーズを評価することなのです。オブザーバビリティは、自社で開発・出荷するソフトウェアが、顧客にサービスを提供する際にどのように機能しているかを深く理解するのに役立ちます。全体的に許容できるパフォーマンスを提供することに加えて、特定の注目すべき顧客セグメントに優れたサービスを提供することがビジネス戦略の中核である場合、オブザーバビリティの必要性は特に強調されます。一方、モニタリングは、そのソフトウェアをサポートするために運用しているシステムが、どの程度その役割を果たしているかを理解するのに役立ちます。メトリクスベースのモニタリングツールとそれに関連するアラートは、基盤となるシステムの容量限界や既知のエラー状態に達したことを知らせてくれます。IaaSプロバイダーのように、インフラストラクチャ自体を顧客に提供することがビジネスの中核である場合、DNSカウンター、ディスク統計など、相当量のモニタリングが必要になります。基盤となるシステムは、このような組織にとってビジネス上重要であり、顧客に公開するこれらの低レベルのシステムに精通している必要があるのです。しかし、インフラストラクチャの提供がビジネスの中核的な差別化要因ではない場合、モニタリングの重要性は相対的に低くなります。その場合、高レベルのサービスとエンドツーエンドのチェックのみを監視する必要があるかもしれません。ビジネスに必要なモニタリングの量を正確に判断するには、いくつかの考慮事項があります。自社のインフラストラクチャの大部分を運用している企業は、より多くのモニタリングを必要とします。オンプレミスでシステムを運用するか、クラウドプロバイダーを使用するかに関わらず、この考慮事項は、インフラストラクチャがどこにあるかというよりも、運用上の責任に関するものです。クラウドで仮想マシンをプロビジョニングするにしろ、オンプレミスでデータベースを管理するにしろ、重要な要因は、インフラストラクチャの可用性とパフォーマンスを保証する責任を自社のチームが負うかどうかなのです。ベアメタルシステムの運用責任を負う組織は、低レベルのハードウェアパフォーマンスを調べるモニタリングを必要とします。イーサネットポートのカウンター、ハードドライブのパフォーマンス統計、システムファームウェアのバージョンなどを監視する必要があります。ハードウェアレベルの運用をIaaSプロバイダーにアウトソースしている組織は、そのレベルで機能するメトリクスと集計を必要としないでしょう。そして、これはスタックのさらに上のレベルでも同様です。運用責任がサードパーティに移行されるにつれ、インフラストラクチャの監視の関心事も移行されていきます。ほとんどのインフラストラクチャを高レベルのPaaS（Platform-as-a-Service）プロバイダーにアウトソースしている企業は、従来のモニタリングソリューションをほとんど、あるいはまったく必要としないかもしれません。Heroku、AWS Lambdaなどは、本質的に、ビジネスが実行したいソフトウェアをサポートするために必要なインフラストラクチャの可用性とパフォーマンスを保証する仕事を請け負うために、料金を支払うことを可能にしているのです。今日、ユーザーのマイレージは、クラウドプロバイダーの堅牢性によって異なるかもしれません。おそらく、抽象化は十分にクリーンで高レベルなので、インフラストラクチャの監視への依存を取り除くという経験は、それほどフラストレーションを感じるものではないでしょう。しかし、理論的には、すべてのプロバイダーがそのシフトを可能にするモデルに移行しつつあります。例外として無視できないインフラストラクチャの監視システムのモニタリングとソフトウェアのオブザーバビリティのこの明確な区分には、いくつかの例外があります。先に述べたように、ソフトウェアのパフォーマンスを評価するための視点は、顧客体験です。ソフトウェアのパフォーマンスが遅い場合、顧客はそれを悪い体験と捉えます。したがって、顧客体験を評価する上での主要な関心事は、パフォーマンスのボトルネックを引き起こす可能性のあるものを理解することです。この明確な区分の例外は、ソフトウェアがその基盤となるインフラストラクチャとどのように相互作用しているかを直接示すメトリクスです。ソフトウェアの観点からは、一般的なモニタリングツールによって/procファイルシステムで発見された変数の何千ものグラフを見ることはほとんど、あるいはまったく価値がありません。電源管理やカーネルドライバに関するメトリクスは、低レベルのインフラストラクチャの詳細を理解するのに役立つかもしれませんが、ソフトウェアのパフォーマンスへの影響についてはほとんど有用な情報を示さないため、ソフトウェア開発者は日常的に無視します（そうあるべきです）。しかし、CPU使用率、メモリ消費量、ディスクアクティビティなどの高次のインフラストラクチャメトリクスは、物理的なパフォーマンスの制限を示します。ソフトウェアエンジニアとして、これらの指標を注意深く観察する必要があります。なぜなら、これらはコードによってトリガーされる問題の早期警戒シグナルになる可能性があるからです。例えば、新しいデプロイによって、数分以内にレジデントメモリの使用量が3倍になったことを知りたいはずです。新機能の導入直後にCPU消費量が2倍になったり、ディスク書き込みアクティビティが急増したりするのを見ることで、問題のあるコードの変更にすぐに気づくことができます。高次のインフラストラクチャメトリクスは、基盤となるインフラストラクチャがどの程度抽象化されているかによって、利用できる場合とできない場合があります。しかし、利用できる場合は、オブザーバビリティへのアプローチの一部としてそれらをキャプチャすることを強くお勧めします。ここでのモニタリングとオブザーバビリティの関係は、相関関係になります。パフォーマンスの問題が発生した場合、モニタリングを使用してシステムレベルの問題を素早く除外または確認することができます。したがって、システムレベルのメトリクスデータをアプリケーションレベルのオブザーバビリティデータと並べて表示することは有益です。一部のオブザーバビリティツール（HoneycombやLightstepなど）は、そのデータを共有のコンテキストで提示しますが、他のツールでは、その相関関係を確認するために別のツールやビューを使用する必要があるかもしれません。実際の適用例本書は、モニタリングとオブザーバビリティの共存パターンのいくつかの実例を紹介しています。ある企業では、オブザーバビリティへの移行により、Prometheus、Jaeger、従来のAPMツールの3つのシステムを、モニタリングシステムとオブザーバビリティシステムの2つに集約することができました。ソフトウェアエンジニアリングチームは主にオブザーバビリティを使用し、中央の運用チームはPrometheusを使ってインフラを監視しています。ソフトウェアエンジニアは、コードのリソース使用量の影響について質問がある場合、Prometheusを参照することができます。しかし、この必要性は頻繁ではなく、アプリケーションのボトルネックのトラブルシューティングにPrometheusを使用する必要はほとんどないと報告しています。別の企業は、比較的新しい会社で、グリーンフィールドのアプリケーションスタックを構築することができました。彼らのプロダクションサービスは、サーバーレス機能とSaaSプラットフォームを主に利用しており、独自のインフラはほとんど運用していません。最初から本当のインフラを持っていなかったため、モニタリングソリューションを自分の環境に適合させようとする道を歩み始めることはありませんでした。彼らは、アプリケーションのインストルメンテーションとオブザーバビリティに依存して、本番環境でのソフトウェアを理解しデバッグしています。また、そのデータの一部を長期的な集計とウェアハウジングのためにエクスポートしています。最後の例は、デジタルトランスフォーメーションを進める成熟した金融サービス企業です。彼らは、レガシーインフラとグリーンフィールドアプリケーションが混在する、大規模な異種混合環境を持っています。多くの古いアプリケーションはまだ運用されていますが、それらを最初に構築し、維持していたチームは、とっくに解散するか、会社の他の部署に再編成されています。多くのアプリケーションは、メトリクスベースのモニタリングとダッシュボード機能（オールインワンの商用ベンダーが提供）の組み合わせ、および非構造化ログを検索するためのさまざまなロギングツールを使って管理されています。安定して機能しているサービスのモニタリングアプローチを取り除き、再設計し、置き換えることで、ビジネスにはほとんど、あるいはまったく価値がもたらされないでしょう。その代わりに、グリーンフィールドアプリケーションは、モニタリング、ダッシュボード、ロギングの組み合わせを必要とする以前のアプローチではなく、オブザーバビリティのために開発されています。新しいアプリケーションが企業のインフラストラクチャを使用する場合、ソフトウェアエンジニアリングチームは、リソースの使用状況の影響を監視するためのインフラストラクチャメトリクスにもアクセスできます。しかし、一部のソフトウェアエンジニアリングチームは、リソース使用量とアプリケーションの問題を関連付けるために別のシステムを使用する必要性を減らすために、インフラストラクチャメトリクスをイベントにキャプチャし始めています。組織の責任に基づくオブザーバビリティとモニタリングのバランス本章の結論として、オブザーバビリティとモニタリングの共存バランスは、組織内で採用されているソフトウェアとインフラストラクチャの責任に基づいて決定されるべきだと強調しています。モニタリングは、システムの健全性を評価するのに最適であり、オブザーバビリティは、ソフトウェアの健全性を評価するのに最適です。 各ソリューションの必要性は、基盤となるインフラストラクチャの管理をどの程度サードパーティプロバイダーにアウトソースしているかによって異なります。ただし、CPU、メモリ、ディスクなど、ソフトウェアのパフォーマンスに直接影響を与える高次のインフラストラクチャメトリクスは例外です。これらのメトリクスは、オブザーバビリティアプローチの一部として取り込むべきです。本章では、モニタリングとオブザーバビリティを補完的に活用するいくつかの一般的なアプローチを示しました。 これらの考慮事項は、異なるチームによってどのように実装されているかを示す実世界の例だと言えます。オブザーバビリティの基礎を深く理解したところで、次のパートでは、オブザーバビリティの実践を成功裏に採用し、チーム全体でその採用を推進するために必要な文化的変化についても探ります。私自身、SREとしてモニタリングとオブザーバビリティの両方を活用した経験があります。従来のモニタリングツールは、インフラストラクチャの健全性を確保するために欠かせませんが、アプリケーションレベルの問題を理解し、デバッグするには不十分でした。オブザーバビリティの導入により、コードの動作を深く理解し、問題の根本原因をより迅速に特定できるようになりました。特に、CPUやメモリの使用率など、インフラメトリクスとアプリケーションの問題を関連付けることの重要性は、自身の経験からも強く実感しています。これらのメトリクスをオブザーバビリティイベントに取り込むことで、問題の全容をより素早く把握することができるようになりました。皆さんは、ご自身の組織において、オブザーバビリティとモニタリングをどのように組み合わせていますか？また、両者のバランスを取る上で、どのような課題に直面していますか？ぜひ、経験を共有しましょう。Part III. Observability for Teams本書の第3部では、異なるチーム間で観測可能性の採用を促進するのに役立つ、社会的・文化的慣行の変化についてを詳しく説明してくれています。Chapter 10. Applying Observability Practices in Your Team「Chapter 10. Applying Observability Practices in Your Team」は、オブザーバビリティの実践を自分のチームで始めるにあたって役立つヒントを提供する章です。万能のレシピは存在しないことを前提としつつ、これまでの経験から得られた有用なパターンやアプローチが複数紹介されています。具体的には、チームやプロジェクトの現状を正しく把握し、オブザーバビリティ導入の必要性と期待される効果を明確化することから始め、実装に向けては小さなスコープから着手し、限られた領域に集中して成功事例を積み重ねながら徐々に範囲を広げていくアプローチが提案されています。また、この章ではオブザーバビリティ実践の障壁となる潜在的な課題とその対処方法についても言及され、技術的な側面に加え、組織文化の変革や関係者間のコミュニケーション、教育の重要性が強調されています。読み進めるうちに、オブザーバビリティの導入は単なるツールの導入以上の作業であり、チーム全体で取り組む価値があるプロセスであることが明らかになり、この章を読めば、自分のチームに最適なオブザーバビリティ実践の方法を見出すための手がかりが得られます。この辺からというかPart III以降では一度目とは違う読書体験となり、オブザーバビリティ実践の奥深さを実感することができました。コミュニティグループへの参加本書は、オブザーバビリティの実践を始めるにあたって、コミュニティグループに参加することを勧めています。オブザーバビリティは新しい分野であり、同じような課題に取り組む人々とつながることで、多くを学び、自らの実践を改善することができます。Slackグループなどのコミュニティに参加することで、様々なバックグラウンドを持つ人々と出会い、他のチームがどのように課題に取り組んでいるかを知ることができます。こうした共有された経験は、自分自身の実験を始める前に、解決策やアプローチの背景を理解するのに役立ちます。また、コミュニティへの参加は、自分が見落としていた進展に気づくきっかけにもなります。オブザーバビリティツールのプロバイダーは、ユーザーの課題を理解し、フィードバックを得るために、様々なコミュニティに参加しています。日本にも独自のコミュニティグループがあるのですがベンダーもしくはツール毎のイベント以外は単発系が多い気がしているのでその都度調べてください。Observability Conference 2022 by CloudNative Days とOpenTelemetry の会は良い発表も多いので紹介しておきます。cloudnativedays.jpopentelemetry.connpass.com最も大きな痛みのポイントから始める新しい技術の導入は、小さくて目立たないサービスから始めるのが一般的ですが、本書は、オブザーバビリティの場合、これが大きな間違いだと指摘しています。オブザーバビリティツールは、捉えどころのない問題をすばやく見つけるのに役立ちますが、すでにうまく機能しているサービスから始めては、その価値を証明することはできません。オブザーバビリティの導入は、難しい問題や捉えどころのない問題を解決することから始めるべきです。 例えば、何週間も人々を悩ませているが、誰も正しい修正方法がわからないようなサービスや、原因不明のデータベースの混雑、正体不明のユーザーによって生成される説明不能な負荷に悩まされているサービスなどが、最適な出発点となります。こうした難しい問題をすばやく解決することで、反対意見を抱く人々を説得し、追加のサポートを得て、オブザーバビリティの採用をさらに促進することができるのです。しかし、痛みが大きい分期待値も高いので注意が必要。既存の取り組みを活用する機会を探る新しい技術を採用する際の最大の障壁の一つが、「埋没コストの誤謬」です。これは、すでに投資した時間、お金、努力のために、その行動や試みを続けてしまうことを指します。根本的な変化に抵抗するのは、資源の無駄という認識が入り込むからです。 古いソリューションを理解し、そのためにインストルメンテーションを行うのに何年も投資してきたことを考えると、感情的には理解できます。しかし、これではオブザーバビリティの導入が止まってしまいます。そこで、既存の取り組みをオブザーバビリティのイニシアチブに活用できる機会を常に探し、飛びつくことが重要です。例えば、既存のデータストリームを二次的な宛先に送ったり、別の方法で重要なデータを見たりできるなら、そのデータをオブザーバビリティソリューションに送り込むチャンスです。既存のツールとの親和性を高めることで、採用へのハードルを下げることができるのです。新しいソリューションの中に現在の世界がどのようにマッピングされるかを人々に理解してもらう必要があります。最後の難関に備える本書は、オブザーバビリティの実装における最も難しい部分の一つが、ゴールまで到達することだと指摘しています。チームの規模やスコープにもよりますが、オンコールアプローチの一環として反復的に新しいインストルメンテーションを展開していくことで、意図するスタックのすべての部分にオブザーバビリティを導入するために必要な作業の半分から3分の2程度は、ほとんどのチームで達成できるでしょう。しかし、スタックの中には、他の部分ほど活発に開発されていない部分があることに気づくはずです。そういった部分については、完了プランが必要不可欠です。オブザーバビリティの完全な実装の目標は、問題が発生したときにいつでも本番アプリケーションの状態を完全に理解するために使える、信頼できるデバッグソリューションを構築することです。 その状態に到達するまでは、異なる問題の解決に最適な様々なツールがある状態が続くでしょう。実装フェーズでは、それでも許容できるかもしれませんが、長期的には、実装を完了しないと、チームの時間、認知能力、注意力を浪費することになります。そこで、残りを迅速に処理するためのタイムラインを作成する必要があります。ターゲットマイルストーンは、チームがオブザーバビリティツールを本番でのデバッグの第一選択肢として使えるようにするために必要な残りのインストルメンテーション作業を達成することです。オブザーバビリティ実践の導入ヒント本章の結論として、オブザーバビリティの導入方法は、チームの状況に応じて異なると強調しています。オブザーバビリティの導入を始めるにあたって、同業者のコミュニティに積極的に参加することは非常に価値があります。 導入を始める際は、すでにうまく機能している部分ではなく、最も大きな痛みのポイントを解決することに注力すべきです。また、導入のプロセス全体を通して、素早く動き、高い価値とROIを示し、反復的に作業に取り組む姿勢を忘れないようにしましょう。 組織のあらゆる部分を巻き込む機会を見つけ、最後の大きなプッシュで導入プロジェクトをゴールまで持っていくことを忘れてはいけません。本章のヒントは、オブザーバビリティの導入に必要な作業を完了させるのに役立ちます。その作業が完了すれば、オブザーバビリティを日常的に使用することで、新しい働き方を実現できるようになります。私自身、SREとしてオブザーバビリティの導入に携わった経験から、著者の提言の多くに共感しました。特に、最も大きな痛みのポイントから始めることの重要性は、身をもって実感しています。モニタリングでは捉えきれなかった複雑な問題を、オブザーバビリティを用いて解決できた時の喜びは忘れられません。また、既存の取り組みを活用することも、チームのオブザーバビリティ採用を促進する上で非常に有効でした。馴染みのあるダッシュボードをオブザーバビリティツールで再現したり、既存のログデータをトレースイベントとして送信したりすることで、エンジニアはオブザーバビリティの価値をより早く実感できるようになりました。一方で、著者が指摘するように、実装を最後までやり遂げることの難しさも痛感しました。日々の運用に追われる中で、インストルメンテーションを完成させる作業は後回しになりがちです。そこで、私たちは定期的な「オブザーバビリティ・ハッカソン」を開催し、全エンジニアでインストルメンテーションの完成度を高める取り組みを行いました。これにより、オブザーバビリティが私たちのデバッグの第一選択肢になったのです。Chapter 11. Observability-Driven Development「Chapter 11. Observability-Driven Development」は、オブザーバビリティの実践をソフトウェア開発のライフサイクルの早い段階から取り入れることの重要性を説いた章です。本書は、テスト駆動開発（TDD）の限界を指摘し、オブザーバビリティ駆動開発がいかにソフトウェアの品質と開発速度の向上に寄与するかを詳細に解説しています。テスト駆動開発とその限界本書は、まずTDDの特徴と限界について説明しています。TDDは、ソフトウェアを本番環境にリリースする前にテストするための、業界のゴールドスタンダードです。TDDは、アプリケーションを決定論的な一連の反復可能なテストで定義することで、ソフトウェアの操作性について明確に考える方法を提供します。しかし、本書は、TDDの一貫性と孤立性が、本番環境でのソフトウェアの振る舞いについての洞察を制限してしまうと指摘しています。 孤立したテストに合格することは、顧客がそのサービスを良好に体験していることを意味するわけではありません。また、本番環境にコードを再リリースする前にエラーや回帰を迅速かつ直接的に特定し、修正できることを意味するわけでもありません。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon開発サイクルにおけるオブザーバビリティ本書は、オブザーバビリティがソフトウェア開発チームのバグ発見能力を高めることで、より良いコードの作成と出荷を可能にすると主張しています。バグを迅速に解決するためには、オリジナルの意図がまだ作者の頭にある間に問題を調査することが重要です。 バグが誤って出荷されてから、そのバグを含むコードが問題ないか調べるまでの時間が長ければ長いほど、多くの人の時間が無駄になってしまいます。また、本書は、オブザーバビリティとコードのデバッグ場所の特定方法についても説明しています。オブザーバビリティは、コードそのものをデバッグするためのものではなく、デバッグすべきコードを見つけるためのシステム内の場所を特定するためのものです。 オブザーバビリティツールは、問題が発生している可能性のある場所をすばやく絞り込むのに役立ちます。マイクロサービス時代のデバッグマイクロサービスの台頭は、オブザーバビリティの台頭と密接に関連しています。モノリスがマイクロサービスに分解されると、デバッガーはネットワークをまたぐことができなくなるため、うまく機能しなくなります。マイクロサービスでは、サービスリクエストがネットワークを横断して機能を実現するため、あらゆる種類の運用上、アーキテクチャ上、インフラストラクチャ上の複雑さが、意図せずに出荷したロジックのバグと不可分に絡み合うようになったのです。 オブザーバビリティがなければ、パフォーマンスグラフがすべて同時にスパイクしたりディップしたりしているだけで、問題の本質が見えなくなってしまいます。インストルメンテーションがオブザーバビリティを促進する仕組み本書は、オブザーバビリティを実現するための必要条件が、有用なインストルメンテーションの作成であると述べています。優れたインストルメンテーションは、オブザーバビリティを促進します。具体的には、コードをデプロイしてエラーの結果を感じるまでのループを短くするような、強化メカニズムとフィードバックループを作成することを目標にすべきだと提案しています。例えば、コードをマージした人に、一定期間、本番環境でアラートが発生した場合にそのアラートを送るようにすることです。エンジニアは、デプロイ後すぐに以下の質問に答えられるように、自分のコードをinstrument化することが求められます。コードは期待通りに動作しているか？以前のバージョンと比べてどうか？ユーザーは積極的にコードを使用しているか？異常な条件は発生していないか？オブザーバビリティの左シフト本書は、オブザーバビリティ駆動開発が、ソフトウェアが本番環境の乱雑な現実の中でどのように機能するかを保証すると述べています。TDDが孤立した仕様への準拠を保証する一方で、オブザーバビリティ駆動開発は、変動するワークロードを経験し、特定のユーザーが予測不可能なことを行っている、ある時点での複雑なインフラストラクチャ上に分散されたソフトウェアが機能することを保証します。開発ライフサイクルの早い段階でインストルメンテーションをソフトウェアに組み込むことで、エンジニアは小さな変更が本番環境で実際にどのような影響を与えるかをより容易に考慮し、より迅速に確認できるようになります。従来のモニタリングアプローチでは、複雑なモダンなソフトウェアシステムで何が起こっているのかを正確に推論する能力がほとんどありません。その結果、チームは本番環境をガラスの城のように扱い、その城を乱すことを恐れるようになってしまうのです。オブザーバビリティ駆動開発により、エンジニアリングチームはガラスの城を対話型の遊び場に変えることができます。 ソフトウェアエンジニアは、オブザーバビリティを自らの開発プラクティスに取り入れ、本番環境への変更を恐れるサイクルを解きほぐす必要があります。オブザーバビリティを用いたソフトウェア開発の高速化本書は、ソフトウェアエンジニアが新機能と一緒にテレメトリを束ねることで、コミットからエンドユーザーへの機能リリースまでの時間を短縮できると述べています。ソフトウェア業界では、速度と品質の間にはトレードオフがあるという認識が一般的ですが、著書「Accelerate」では、このような逆の関係は神話であることが明らかにされました。エリートパフォーマーにとって、速度と品質は連動して向上し、互いに強化し合うのです。エンジニアリングチームの健全性と有効性を示す重要な指標は、コードが書かれてから本番環境に導入されるまでの経過時間で捉えられます。 すべてのチームがこの指標を追跡し、改善に努めるべきです。オブザーバビリティ駆動開発は、機能フラグと段階的デリバリーパターンと組み合わせることで、エンジニアリングチームに、新機能のリリース中に問題が発生した際に本当に何が起きているのかを調査するためのツールを提供できます。オブザーバビリティ駆動開発の重要性本章の結論として、オブザーバビリティがソフトウェア開発ライフサイクルの早い段階で使用されるべきであると強調しています。テスト駆動開発は、コードが定義された仕様に対してどのように動作するかを検証するのに役立ちますが、オブザーバビリティ駆動開発は、コードが本番環境の混沌とした世界でどのように振る舞うかを検証するのに役立ちます。ソフトウェアエンジニアにとって、本番環境の実際の動作を理解できないことは、本番環境をガラスの城のように扱う考え方を生んできました。新機能がリリースされる際の振る舞いを適切に観察することで、本番環境をエンドユーザーがソフトウェアを体験する対話型の遊び場へと変えることができるのです。オブザーバビリティ駆動開発は、高いパフォーマンスを発揮するソフトウェアエンジニアリングチームを実現するために不可欠です。 オブザーバビリティをSREやインフラエンジニア、運用チームだけのものと考えるのではなく、すべてのソフトウェアエンジニアが自らのプラクティスの重要な部分としてオブザーバビリティを取り入れるべきなのです。本章を読んで、私はオブザーバビリティ駆動開発の重要性を再認識しました。特に、本番環境の振る舞いを適切に観察することで、ソフトウェアエンジニアのマインドセットを変革できるという点に共感しました。Chapter 12. Using Service-Level Objectives for Reliability「Chapter 12. Using Service-Level Objectives for Reliability」は、サービスレベル目標（SLO）を用いたアラート戦略が、従来の閾値ベースのモニタリングアプローチよりも効果的であることを示した章です。本章は、SLOとオブザーバビリティを組み合わせることで、システムの信頼性を向上させる方法を提案しています。従来のモニタリングアプローチがもたらすアラート疲労本書は、まず従来のモニタリングアプローチの問題点を指摘しています。従来のアプローチでは、測定が容易なシステムの状態を単純なメトリクスで追跡し、それに基づいてアラートを発生させます。しかし、これらのアラートは、false positiveを大量に生み出し、意味のある行動につながりません。その結果、エンジニアリングチームは、信頼性の低いアラートを無視したり、抑制したりするようになります。 これは「逸脱の正常化（normalization of deviance）」と呼ばれる危険な状態です。アラートが「正常」とみなされ、無視されるようになると、重大な見落としにつながる可能性があるのです。また、従来のモニタリングアプローチは、既知の障害モードにのみ対応できます（known-unknowns）。しかし、分散システムでは、予測不可能な障害モードが発生し、ユーザーエクスペリエンスに影響を与える可能性があります。従来のシステムメトリクスでは、このような予期せぬ障害モードを見逃してしまうのです。ユーザーエクスペリエンスを指標とする本書は、アラートの設定において、ユーザーエクスペリエンスに焦点を当てることの重要性を説いています。従来のアプローチでは、システムエンジニアが任意の定数を選択し、ユーザーエクスペリエンスが悪化する時点を予測する必要がありました。しかし、システムのパフォーマンスは、ユーザーの行動によって大きく変動するため、静的な閾値では対応できません。信頼性の高いアラートには、より細かい粒度と信頼性が必要です。 そこで役立つのがSLOです。SLOは、システムメトリクスではなく、重要なユーザージャーニーに基づいてサービスの可用性の目標値を定量化します。この目標値は、サービスレベルインジケーター（SLI）を使って測定されます。サービスレベル目標とは何か？本書は、SLOの概要を説明し、その重要性を強調しています。SLOは、サービスの健全性を測定するための内部目標です。SLOは、サービスプロバイダーと顧客の間のサービスレベルアグリーメントの重要な部分であり、外部に向けた可用性のコミットメントよりも厳しい基準を設定します。SLOは、ユーザーエクスペリエンスに影響を与える症状にのみ焦点を当てることで、アラートの範囲を狭めます。何かがユーザーの体験に影響を与えている場合、アラートが発生し、誰かがなぜそうなっているのかを調査する必要があります。 しかし、SLOベースのアラートは、サービスがどのように低下しているかを示すものではありません。単に何かがおかしいことを知らせるだけなのです。SLOベースのアラートへの文化の変革：ケーススタディ本書は、Honeycombでの実際の事例を紹介し、SLOベースのアラートへの文化の変革について説明しています。Honeycombでは当初、SLOを実装していたものの、チームはまだ完全には信頼していませんでした。SLOアラートは低優先度の受信箱に送られ、チームは従来のモニタリングアラートに依存し続けていたのです。しかし、あるインシデントで、SLOベースのアラートが従来のアラートよりもはるかに早く問題を検出したことで、状況は変わりました。メモリリークによるクラッシュが発生していましたが、従来のモニタリングでは検出されませんでした。 一方、SLOは嘘をつきませんでした。SLOエラーバジェットはインシデントの開始時からほぼ完全に消費され、ユーザーへの影響が明らかになったようでした。このインシデントがチームの文化を変えました。 SLOベースのアラートの価値が証明されたことで、エンジニアリングチームはSLOベースのアラートを従来のアラートと同等に尊重するようになりました。しばらくしてSLOベースのアラートに頼るようになると、チームはSLOデータのみに基づいてアラートを出すことに徐々に慣れていったのです。SLOとオブザーバビリティによる信頼性の向上本章の結論として、SLOが従来の閾値ベースのモニタリングよりも効果的なアラート戦略であることを強調しています。アラート疲労は、従来のモニタリングソリューションが取る潜在的な原因ベースのアプローチによって引き起こされています。 アラート疲労は、役立つアラートのみを作成することで解決できます。役立つアラートとは、サービスのユーザーエクスペリエンスが低下した状態にあることを確実に示し、かつ実行可能でなければなりません。SLOは、インシデントアラートの背後にある「何が」と「なぜ」を切り離します。 痛みの症状ベースのアラートに焦点を当てることで、SLOは顧客体験の信頼できる指標となります。SLOがイベントベースの指標に基づいている場合、誤検知と見逃しが大幅に減少します。したがって、SLOベースのアラートは、アラートをより実行可能で、タイムリーなものにする生産的な方法となるのです。しかし、SLOベースのアラートだけでは、痛みがあることは分かっても、なぜそうなっているのかは分かりません。SLOベースのアラートを実行可能なものにするには、本番システムが十分にデバッグ可能でなければなりません。 システムにオブザーバビリティを持たせることが、SLOを使う上で非常に重要なのです。Chapter 13. Acting on and Debugging SLO-Based Alerts「Chapter 13. Acting on and Debugging SLO-Based Alerts」は、SLOベースのアラートを使用する際のエラーバジェットの役割と、アラートをトリガーするためのメカニズムについて詳細に解説した章です。本書は、エラーバジェットの枯渇を予測するための様々な予測手法を紹介し、組織のニーズに最適な手法を選択するための考慮事項を示しています。また、サービスレベル目標(SLO)の実装について解説した「Implementing Service Level Objectives」も参考になります。この書籍は、SLOベースのアプローチによる信頼性を実現するための文化とツールを構築する際の入門書およびデイリーリファレンスとして役立ちます。高度なSLOおよびサービスレベル指標(SLI)の技術について詳細な分析を提供し、数学的モデルと統計学の知識を武器に、ユーザーの視点から信頼性を意味のある形でSLIとして測定可能なシステムを構築する方法を学ぶことができます。learning.oreilly.comエラーバジェットが空になる前にアラートする本章は、まずエラーバジェットの概念について説明しています。エラーバジェットは、ビジネスが許容できるシステムの最大の利用不可時間を表します。例えば、SLOが99.9%の成功率を確保することであれば、1年間で8時間45分57秒（または1ヶ月で43分50秒）以上のダウンタイムは許容されません。SLOに違反する前にアプリケーションやシステムの問題を認識し、解決するためには、エラーバジェットが完全に消費される前に予測的なバーンアラートが必要です。バーンアラートは、現在のバーン率が継続した場合にエラーバジェットが枯渇する時期を予測し、早期警告を提供します。時間をスライディングウィンドウとして捉える本書は、SLOの分析にあたって、固定ウィンドウとスライディングウィンドウのどちらを使用するかを選択する必要があると述べています。固定ウィンドウは、例えば月の1日から30日までのように、カレンダーに従います。一方、スライディングウィンドウは、直近の30日間のように、移動する期間を見ます。Figure 13-2. A rolling three-day window (left) and a three-day resetting window (right) より引用本書は、ほとんどのSLOにとって、30日のスライディングウィンドウが最も実用的な期間だと述べています。固定ウィンドウは顧客の期待に合わないため、より滑らかな体験を提供するスライディングウィンドウを使用すべきだと主張しています。予測的バーンアラートを作成するための予測本書は、予測的バーンアラートをトリガーするための2つのモデルを紹介しています。1つ目は、ゼロ以外の閾値を選択し、残りのエラーバジェットがその閾値を下回ったときにアラートをトリガーする方法です。Figure 13-3. In this model, an alert triggers when the remaining error budget (solid line) dips below the selected threshold (dashed line) より引用2つ目は、現在の状態がエラーバジェット全体を消費する結果になるかどうかを予測する方法です。この方法では、基準ウィンドウ（ベースラインウィンドウ）と、予測が及ぶ将来の時点を決定する先読みウィンドウ（ルックアヘッドウィンドウ）の2つを考慮する必要があります。Figure 13-4. For predictive burn alerts, you need a baseline window of recent past data to use in your model and a lookahead window that determines how far into the future your forecast extends より引用本書は、基準ウィンドウとして、先読みウィンドウの4分の1の期間を使用することを推奨しています。つまり、4時間後に予算を使い果たすかどうかを予測するには、過去1時間のパフォーマンスデータを使用するのです。バーン率を予測するために、著者は2つのアプローチを紹介しています。短期バーンアラートは、最近の期間の基準データのみを使用して軌跡を外挿します。コンテキスト対応バーンアラートは、過去のパフォーマンスを考慮し、SLOの全体のウィンドウにおける成功イベントと失敗イベントの総数を使用して計算を行います。SLOバーンアラートへの対応本書は、バーンアラートがトリガーされたときの対応についても説明しています。新しい予期せぬ種類のバーンが発生しているのか、それとも緩やかで予想されるバーンなのかを診断する必要があります。本書は、バーンアラートがバースト状態の一部なのか、エラーバジェットのかなりの部分を一度に消費してしまうようなインシデントなのかを評価すべきだと述べています。現在の状況を過去の率と比較することで、その重要性をトリアージするための有益なコンテキストが得られます。SLOのためのオブザーバビリティデータと時系列データ本書は、SLOに時系列データを使用することで、いくつかの複雑さが生じると指摘しています。時系列データの問題は、99.99%以上の可用性目標を持つ厳格なSLOの場合に特に顕著です。このようなSLOでは、エラーバジェットが数分または数秒で枯渇する可能性があります。一方、SLOの計算にイベントデータを使用すると、システムの健全性を評価するためのリクエストレベルの粒度が得られます。モダンな分散システムでは、100%の全体的な障害よりも、部分的な障害の方が一般的です。そのため、イベントベースの計算の方がはるかに有用なのです。本書は、サービスの実際のユーザーエクスペリエンスを追跡するオブザーバビリティデータは、粗く集約された時系列データよりも、システムの状態をより正確に表現していると述べています。アクション可能なアラートのためにどのデータを使用するかを決定する際、オブザーバビリティデータを使用することで、ビジネスが気にかけている全体的な顧客体験に非常に近い条件に焦点を当てることができるのです。SLOとオブザーバビリティデータの組み合わせ本章の結論として、SLOとオブザーバビリティデータを組み合わせることの重要性を強調しています。SLOは、ノイズの多いモニタリングの問題を解決するモダンな形式のモニタリングです。オブザーバビリティに特化しているのは、イベントデータがSLOモデルに追加する力です。 エラーバジェットのバーン率を計算する際、イベントは本番サービスの実際の状態をより正確に評価します。また、SLOが違反の危険にあることを知るだけでは、どのユーザーが影響を受けているのか、どの依存サービスが影響を受けているのか、どのようなユーザー行動の組み合わせがサービスでエラーを引き起こしているのかを判断するための洞察が必ずしも得られるとは限りません。SLOにオブザーバビリティデータを組み合わせることで、バーンバジェットアラートがトリガーされた後、障害がいつ、どこで発生したかを把握できるようになります。オブザーバビリティデータを使用したSLOは、SREアプローチとオブザーバビリティ駆動型開発アプローチの両方の重要なコンポーネントです。失敗したイベントを分析することで、何がうまくいっていないのか、なぜうまくいっていないのかについての豊富で詳細な情報が得られます。それはシステム的な問題と時折の散発的な障害を区別するのに役立ちます。本章を読んで、私はSLOとオブザーバビリティデータの組み合わせの重要性を再認識しました。エラーバジェットのバーン率を予測し、早期にアラートを発するための様々な手法は、SREにとって非常に有益です。また、イベントベースの測定値が、システムの実際の状態をより正確に表現しているという点にも納得しました。私たちのチームでも、SLOの計算にオブザーバビリティデータを活用することで、顧客体験に直結する問題により迅速に対応できるようになりました。皆さんは、SLOとオブザーバビリティをどのように組み合わせていますか？また、エラーバジェットのバーン率を予測するために、どのような手法を用いていますか？ぜひ、経験や考えを共有してください。Chapter 14. Observability and the Software Supply Chain「Chapter 14. Observability and the Software Supply Chain」は、モダンなソフトウェア開発において、オブザーバビリティがいかに重要であるかを示す非常に示唆に富んだ一章でした。著者のFrank Chenは、Slackにおける実際の事例を通して、CI/CDパイプラインにオブザーバビリティを適用することの価値を明確に示しています。ソフトウェアサプライチェーンのセキュリティも重要なトピックであり、「Software Supply Chain Security」(Cassie Crossley著)ではこの分野を包括的に取り上げています。本書は、セキュリティリスクを見渡し、エンドツーエンドのソフトウェアサプライチェーンに組み込む必要のある実践的なコントロールを特定しています。組織がソフトウェア、ファームウェア、ハードウェアのセキュリティ体制を改善するには、サプライチェーンに関わるすべての人が参加する必要があることを実証しており、サプライチェーンの各部分のサイバーセキュリティリスクを特定し、関連する役割を特定し、既存のフレームワークを使ったイニシアティブとコントロールの設計、セキュアな開発ライフサイクルの実践、第三者リスクの評価などについて学ぶことができます。learning.oreilly.comオブザーバビリティがソフトウェアサプライチェーンに不可欠な理由本章の冒頭で、Chenは「ソフトウェアサプライチェーン」という概念について説明しています。それは、「開発から、CI/CDパイプラインを通って、本番環境にデプロイされるまでの、ソフトウェアに影響を与えるすべてのもの」を指します。つまり、コードが書かれてから実際にユーザーに届けられるまでの一連のプロセスを指すのです。Figure 14-1. An example end-to-end workflow for testing the web app より引用Slackでは、早い段階からCIの開発とCDの実践に投資してきました。しかし、急速な成長に伴い、システムの複雑性が増し、境界があいまいになり、限界に達しつつあることに気づきました。テストスイートの実行回数は、一日あたり数千回から数十万回へと爆発的に増加したのです。 この規模になると、適応型キャパシティや、オーバーサブスクリプションなどの戦略でコストとコンピューティングリソースを管理する必要があります。その結果、開発環境でコードをテストしてデプロイするワークフローは、一部の本番サービスよりも複雑になることがありました。インフラストラクチャの種類やランタイムのバージョンの依存関係が予期せず変更され、意図しない障害が発生する可能性があったのです。slack.engineering共有ライブラリとディメンションSlackのオブザーバビリティ導入における主な課題は、複雑さでした。エンドツーエンドテストの失敗は、コードベースの変更、インフラストラクチャの変更、プラットフォームのランタイムなど、複数のコードベースが相互作用した結果である可能性があります。この問題を解決するために、SlackはCI/CDシステムに分散トレーシングを適用しました。トレーシングを多段構成のビルドシステムに適用することで、わずか数時間のうちに複数の課題を解決できたのです。オブザーバビリティを実現するには、有用なインストルメンテーションを作成することが必要条件です。優れたインストルメンテーションは、オブザーバビリティを促進します。具体的には、コードをデプロイしてエラーの結果を感じるまでのループを短くするような、強化メカニズムとフィードバックループを作成することを目標にすべきです。エンジニアは、デプロイ後すぐに以下の質問に答えられるように、自分のコードをインストルメント化することが求められます。コードは期待通りに動作しているか？以前のバージョンと比べてどうか？ユーザーは積極的にコードを使用しているか？異常な条件は発生していないか？サプライチェーンの運用化：ケーススタディChenは、Slackがどのようにトレーシングツールとクエリを使ってソフトウェアサプライチェーンを理解し、アラートにつなげているかを具体的な事例で示しています。コンテキストの理解最初の事例は、フレーキーなテストの問題に対処するために、Slackのチームがどのように協力したかを示しています。2020年、Slackのエンジニアはエンドツーエンドテストのフレーキーさにフラストレーションを感じていました。多くのエンドツーエンドテストスイートでは、平均15％近くのフレーキーさがありました。オブザーバビリティチームとオートメーションチームが協力し、Cypressにいくつかのランタイムパラメータとスパンのトレーシングを追加しました。わずか数日で、フレーキーさと強く相関するディメンションが明らかになったのです。エンジニアはこのデータを使って実験を行い、プラットフォームのデフォルトを改善し、フレーキーな設定に対するガードレールを設置しました。その結果、多くのユーザーでテストスイートのフレーキーさが大幅に減少しました。slack.engineeringアクショナブルなアラートの組み込み次の事例では、Slackがどのようにアラートをエンジニアのワークフローに組み込んでいるかを示しています。オブザーバビリティはSlackのメッセージやダッシュボードを通じて、エンジニアが問題をトリアージするのを助けます。例えば、あるテストスイートの実行時間が増加したことを示すアラートがトリガーされたとします。アラートのリンクをクリックすると、CIサービストレースダッシュボードが表示されます。ここから、問題のあるテストスイートのトレースを確認できます。エンジニアは、レート、エラー、デュレーションを可視化したクエリを使って、Checkpoint内のサービス間の個々のメソッドをグループ化し、問題の原因を特定します。何が変更されたかの理解最後の事例は、2021年8月のインシデントについてです。複数のユーザーがバックエンドのユニットテストとインテグレーションテストでメモリ不足エラー（OOM）によるテスト失敗を報告しました。レスポンダーは、前日のフレーキーさの増加を示すアノマリを発見しました。これをヒントに、過去のテストケーストレースを調べ、メモリ使用量の急増を特定しました。いくつかの疑わしいコミットが特定され、それらを次々とリバートしていきました。専門家は、オブザーバビリティを使ってリアルタイムにシステムの健全性を検証しました。単なるツールではなく、文化でもある本章は、ソフトウェアサプライチェーンにおけるオブザーバビリティの有用性を示しています。Chenは、SlackがCI/CDパイプラインにインストルメンテーションを行い、分散システムのデバッグに役立てた事例を紹介しました。適切なツールとディメンションを用いることで、Slackのエンジニアは、以前は見えなかったCI/CDワークフローの複雑な問題を解決することができました。 アプリケーションが遅い、CIテストがフレーキーだという不満をデバッグする際も、オブザーバビリティは、高度に相互作用する複雑なシステムの問題の相関関係を見つけるのに役立つのです。ソフトウェアが本番環境でどのように動作するかを理解することは、アプリケーション開発者にとって最優先事項です。しかし、本番環境に至る前に、同様に複雑で理解やデバッグが難しい分散システムが存在することを忘れてはいけません。ソフトウェアサプライチェーンにオブザーバビリティを組み込むことは、Slackだけでなく、あらゆるビジネスにとって競争上の優位性となるのです。本章から私が学んだ最も重要な教訓は、オブザーバビリティがソフトウェア開発のあらゆる段階で不可欠だということです。本番環境だけでなく、ソフトウェアがビルド、テスト、デプロイされるプロセス全体を通して、オブザーバビリティを適用することで、より高品質で信頼性の高いソフトウェアを提供できるようになります。また、オブザーバビリティは単なるツールではなく、文化でもあるということを再認識しました。チーム全体で問題の可視性を高め、データに基づいて意思決定を行う文化を育むことが、本当の意味でのオブザーバビリティの実現につながるのです。Part IV. Observability at Scaleこの部ではオブザバビリティが大規模に実践されたときに何が起こるかを検討します。Chapter 15. Build Versus Buy and Return on Investment「Chapter 15. Build Versus Buy and Return on Investment」は、オブザーバビリティソリューションを自社で構築するか、ベンダーから購入するかという選択について、深い洞察を提供してくれる一章でした。本書は、この二者択一の問題を、機会費用や総所有コスト（TCO）など、多角的な視点から分析し、それぞれのアプローチのメリットとデメリットを明らかにしています。オブザーバビリティのROI分析本書は、自社でオブザーバビリティソリューションを構築する際の真のコストについて警鐘を鳴らしています。一見、オープンソースのコンポーネントを使えば、ほとんど費用がかからないように思えるかもしれません。 しかし、実際には、メンテナンスのためのコンテキストスイッチングや、コアビジネスに直接つながらない領域にエンジニアリングリソースを割くことによる機会損失など、目に見えないコストが膨大にかかっているのです。コストについてはこちらがめちゃくちゃに組織毎に正解が違うと思ったのですが良い考察だと思いましたdev.henry.jp一方、ベンダーソリューションを購入する場合、コストは明確です。請求書に明記されているからです。しかし、ここでも落とし穴があります。シートごと、ホストごと、サービスごと、クエリごとなど、予測不可能な指標に基づく価格設定は、将来的なコストを見積もるのが非常に難しいのです。オブザーバビリティツールを本来の目的で使用すると、使用量が爆発的に増加し、生み出す収益に見合わないほどの費用がかかってしまう可能性があります。自社構築のメリットとリスク自社構築の最大のメリットは、組織のニーズに合わせてカスタマイズできることです。長年かけて、自社のシステムに深く根ざした、独自の文化を活かしたソリューションを開発できるのです。しかし、そこにはリスクもあります。本当に自社でベンダーよりも優れたソリューションを開発できるのでしょうか？ UIやワークフローの柔軟性、パフォーマンスなど、組織全体での採用を促すために必要な機能を提供できるでしょうか。もしできなければ、多くの時間と費用、そしてビジネスチャンスを失ったあげく、ごく一部のユーザーしか使わないシステムを構築することになりかねません。購入のメリットとリスク購入の最大のメリットは、迅速に価値を得られることです。数分から数時間で始められ、すぐにオブザーバビリティの恩恵を受けられます。しかし、ベンダーロックインのリスクがあります。一度ある商用ソリューションを選択すると、他のソリューションへの移行に多大な時間と労力がかかるのです。 オープンソースのOpenTelemetryを活用することで、このリスクを軽減できます。また、オブザーバビリティの専門知識を社内で育成できないリスクもあります。単に既製のソリューションを利用するだけでは、自社特有のニーズにオブザーバビリティをどう適用すべきか、深く理解できないかもしれません。二者択一ではない本書は、「構築か購入か」は二者択一ではないと強調しています。自社のオブザーバビリティチームが、ベンダーソリューションの上に独自のレイヤーを構築する、という第三の選択肢があるのです。オブザーバビリティチームは、ベンダーと自社のエンジニアリング組織をつなぐ役割を果たします。ライブラリや抽象化を提供し、命名規則を標準化し、コードのインストルメンテーションについてアドバイスします。コアビジネスの価値提供から逸れることなく、独自のニーズを満たすソリューションを構築できるのです。タダより高いものはないオブザーバビリティソリューションの選択において、Total Cost of Ownership(TCO)を十分に考慮すべきです。「タダより高いものはない」という言葉がありますが、オープンソースを使った自社構築には、導入・運用のためのリソース確保、セキュリティ対策、パフォーマンスチューニングなどの見えないコストが付随します。一方、ベンダーソリューションには、ライセンス料の値上げやベンダーロックインによる代替手段の制約など、将来的なコスト高騰のリスクがあります。そこで、オープンソースとベンダーソリューションのハイブリッド活用が有力な選択肢となります。「Observability with Grafana」では、一部有償サービスを提供しつつも、Grafanaをはじめとするオープンソースツールを中核に据えることで、オープンソースのメリットを最大限に活かしながら、ベンダーによるサポートやサービスを組み合わせることができます。Loki, Grafana, Tempo, and Mimir からなるLGTMスタックを学習することができる。learning.oreilly.comしかし、自社構築と購入を組み合わせることで、両者のメリットを享受できます。 拡張性の高いベンダーソリューションの上に、自社のオブザーバビリティチームが独自のレイヤーを構築する。それが、多くの組織にとって最適なアプローチなのです。私自身、SREとしてオブザーバビリティソリューションの選定に関わった経験から、著者の主張に強く共感しました。当初は、オープンソースを組み合わせた自社構築を志向していましたが、メンテナンスの負荷やスケーラビリティの課題に直面し、方針を転換しました。現在は、商用ソリューションをベースに、我々のチームが独自の機能を開発しています。これにより、オブザーバビリティという強力な武器を手に入れつつ、自社のニーズにもきめ細かく対応できるようになったのです。Chapter 16. Efficient Data Storage「Chapter 16. Efficient Data Storage」は、オブザーバビリティデータを効果的に保存・取得するための課題と、その解決策について深く掘り下げた章でした。本書は、オブザーバビリティに必要な機能要件を満たすために、データ層でどのようなトレードオフが必要なのかを丁寧に解説しています。オブザーバビリティのための機能要件本章の冒頭で、著者はオブザーバビリティのための機能要件について説明しています。本番環境で障害が発生したとき、オブザーバビリティデータに対するクエリはできるだけ迅速に結果を返さなければなりません。 数秒以内に結果が返ってこなければ、生産性のあるデバッグ作業はできません。また、イベントは高カーディナリティで高次元のデータを分析できるようにする必要があります。イベントやトレーススパン内のどのフィールドもクエリ可能でなければならず、事前に集計することはできません。 さらに、データの取得パフォーマンスを特定のディメンションに依存させてはいけません。加えて、オブザーバビリティデータは耐久性と信頼性も求められます。クリティカルな調査に必要なデータを失ったり、データストアのコンポーネントの障害によって調査が遅れたりすることは許されないのです。これらの要件は、従来のデータストレージソリューションでは満たすのが難しいものばかりです。特に、大規模なシステムになればなるほど、これらの問題はより顕著になります。時系列データベースの限界本書は、これらの要件を満たすために、時系列データベース（TSDB）が不十分であると指摘しています。TSDBは、同じタグの組み合わせが頻繁に再利用され、新しい組み合わせが稀な場合に、追加のトラフィックのコストを償却することを目的としています。しかし、オブザーバビリティの要件である高カーディナリティと高次元のデータを扱おうとすると、タグの一意な組み合わせごとに新しい時系列が作成され、カーディナリティの爆発を引き起こしてしまうのです。 これは、TSDBの設計思想と根本的に相容れないものなのです。Figure 16-2. The explosion of that same TSDB when a high-cardinality index, userid, is added より引用TSDBは、システムのパフォーマンスを単純な指標に集約することで、送信されるデータ量を削減し、クエリのパフォーマンスを向上させます。しかし、これは後でそのデータから導き出せる答えの数を制限してしまうのです。オブザーバビリティワークロードでは、イベントの事前集約は許容されません。 TSDBは、オブザーバビリティの基本的な構成要素としては限界があるのです。列指向ストレージそこで本書は、行指向ストレージと列指向ストレージのハイブリッドアプローチを提案しています。データをタイムスタンプでパーティショニングし、各セグメント内でデータを列ごとに保存する。 これにより、任意の行と列の部分スキャンを効率的に実行できるようになります。具体的には、Honeycombの独自データストアであるRetrieverの実装を例に、この手法を詳しく解説しています。Retrieverでは、特定のテナントの新しく到着したトレーススパンを、そのテナントの現在アクティブなストレージファイルセット（セグメント）の末尾に挿入します。読み取り時に適切なセグメントをクエリするために、現在のセグメントの最も古いイベントタイムスタンプと最新のイベントタイムスタンプを追跡しているのです。Figure 16-5. Segments selected for querying are those that overlap at least in part with the query window; segments that start and end before or after the query window are excluded from analysis. より引用このセグメントパーティショニングによるタイムスタンプの利点は、個々のイベントを厳密な順序に並べ替える必要がないこと、そして各セグメントの内容が追記専用のアーティファクトになることです。 これにより、書き込み時のオーバーヘッドを大幅に削減できます。各セグメント内では、イベントをフィールドごとに分解し、複数のイベントにまたがる同じフィールドの内容を一緒に保存します。これにより、クエリ時に関連する列のみにアクセスすることができるのです。列指向ストレージは、行指向ストレージと比べて、必要なサブセットのデータのみを素早く調べることができます。一方で、1つの行のデータにアクセスするには、任意の量のデータ（最大でテーブル全体）をスキャンする必要があるかもしれません。Retrieverは、この両者のトレードオフに対処するために、テーブルを手動で粗くシャーディングし、クエリ時にユーザーが適切なシャードを特定して結合する という手法を採用しています。これにより、行と列の両方の部分スキャンを効率的に実行できるようになっているのです。クエリワークロード本書は、列指向ストレージを使ってクエリワークロードを実行する方法についても説明しています。クエリの時間範囲と重なるセグメントを特定し、各セグメントでフィルタや出力に使用される列を独立にスキャンする。 その後、セグメント内およびセグメント間で集約を行い、最終的な結果を返します。この手法により、高カーディナリティと高次元のデータを効率的に扱うことができます。タイムスタンプ以外のディメンションに特権はなく、任意の複雑な組み合わせでフィルタリングできるのです。 事前集約や、データの複雑さに対する人為的な制限も必要ありません。トレーススパン上のどのフィールドもクエリ可能なのです。Retrieverでは、オープンな列ファイルが常にクエリ可能であり、クエリプロセスが部分ファイルの読み取りのためのフラッシュを強制できるようにしています。これにより、セグメントが確定し、圧縮されるのを待つことなく、リアルタイムでデータにアクセスできるようになっているのです。また、Retrieverは、データの取り込みとシリアライズの関心事をデータのクエリの関心事から分離しています。これにより、シリアライズプロセスに問題が発生しても、古いデータのクエリを妨げることはありません。 クエリエンジンへのスパイクがデータの取り込みとシリアライズを妨げないという副次的なメリットもあります。スケーラビリティと耐久性大規模なデータセットでは、水平方向のスケールアウトと、データ損失やノードの一時的な利用不可に対する耐久性が求められます。Retrieverでは、スケーラビリティと耐久性のためにストリーミングデータパターンを使用しています。 Apache Kafkaを活用し、プロデューサーやコンシューマー、ブローカーの再起動に対して弾力性のある、順序付けられた永続的なデータバッファを維持しているのです。受信プロセスとストレージプロセスの関心事を分離することで、受信ワーカーまたはストレージワーカーを自由に再起動でき、データのドロップや破損を避けることができます。 Kafkaクラスタは、災害復旧シナリオでの再生に必要な最大期間だけデータを保持すればよいのです。スケーラビリティを確保するために、書き込みワークロードに必要な数のKafkaパーティションを作成します。各パーティションは、各データセットに対して独自のセグメントセットを生成します。 クエリ時には、パーティションに関係なく、時間とデータセットに一致するすべてのセグメントをクエリする必要があります。冗長性を確保するために、複数の取り込みワーカーが任意のKafkaパーティションから消費できます。Kafkaは一貫した順序付けを保証し、取り込みプロセスは決定論的なので、単一のパーティションを消費する並列の取り込みワーカーは、同一の出力を生成する必要があります。この方法で、高カーディナリティと高次元の任意の組み合わせに対して、高速で耐久性のあるクエリを実現できるのです。オブザーバビリティデータ管理の新しいアプローチ本章から学んだ最も重要な教訓は、オブザーバビリティワークロードには独自のパフォーマンス特性が必要だということです。従来のストレージシステムでは、リアルタイムのデバッグワークフローをサポートするのに十分なパフォーマンスを発揮できません。Retrieverの実装は、これらの課題に対する一つの解決策を提示しています。タイムスタンプによるセグメントパーティショニングと、セグメント内の列指向ストレージを組み合わせることで、高速性、コスト効率、信頼性という、オブザーバビリティに不可欠な要件を満たしているのです。もちろん、これが唯一の解決策というわけではありません。Google Cloud BigQuery、ClickHouse、Druidなども、オブザーバビリティワークロードを適切に処理できる可能性があります。ただし、これらのデータストアは、オブザーバビリティ固有のワークロードに対する運用テストがまだ十分ではなく、必要な自動シャーディングをサポートするためにカスタム作業が必要になるかもしれません。本章で紹介された手法は、現代のオブザーバビリティバックエンドのアーキテクチャを理解するのに非常に役立ちます。 また、自社でオブザーバビリティソリューションを構築する必要がある場合にも、貴重な教訓となるでしょう。ElasticsearchやCassandraなど、この目的にはあまり適さないデータストアを維持するのに苦労するよりも、専用の列指向ストアを採用することを強くお勧めします。 それが、オブザーバビリティデータを管理するための新しいアプローチなのです。私自身、SREとして大規模なオブザーバビリティシステムの構築に携わった経験から、著者の指摘に強く共感しました。当初は、一般的なNoSQLデータベースを使っていましたが、クエリのパフォーマンスとコストの問題に直面しました。列指向ストレージに移行したことで、高カーディナリティと高次元のデータを、低コストかつ高速に扱えるようになったのです。また、データの取り込みとクエリを分離することの重要性も実感しました。片方のプロセスで問題が発生しても、もう片方に影響を与えないようにすることが、システム全体の安定性につながります。 Kafkaなどのストリーミングプラットフォームを活用することで、この分離をスマートに実現できるのです。Chapter 17. Cheap and Accurate Enough: Sampling「Chapter 17. Cheap and Accurate Enough: Sampling」は、オブザーバビリティデータのサンプリングについて、その戦略と実装方法を詳細に解説した章でした。本書は、サンプリングがリソース制約に対処しつつ、データの忠実性を維持するための有効な手段であることを明確に示しています。サンプリングによるデータ収集の最適化本書は、ある規模を超えると、すべてのイベントを収集・処理・保存するためのコストが、そのメリットを大幅に上回ってしまうと指摘しています。オブザーバビリティイベントが膨大なデータの洪水になると、データ量を減らすことと、エンジニアリングチームが必要とする重要な情報を失うことのバランスが問題になるのです。しかし、多くのアプリケーションでは、イベントの大半がほぼ同一で成功しています。デバッグの核心は、新たなパターンを検出したり、障害時の失敗イベントを調べたりすることです。その観点からすると、すべてのイベントをバックエンドに送信するのは無駄なのです。 代表的なイベントを選択し、実際に発生したことを再構成するために必要なメタデータとともに送信することで、オーバーヘッドを削減しつつ、データの元の形状を忠実に復元できるのです。サンプリング戦略の違い本書は、サンプリングの様々な戦略について説明しています。最もシンプルなのは、一定の確率でデータを保持する「一定確率サンプリング」です。しかし、これは、エラーケースを重視する場合や、トラフィック量が大きく異なる顧客がいる場合には効果的ではありません。より洗練された手法としては、最近のトラフィック量に基づいてサンプリング率を動的に調整する「最近のトラフィック量サンプリング」や、イベントのペイロードに基づいてサンプリング率を調整する「イベントコンテンツ（キー）サンプリング」などがあります。Figure 17-1. Different events may be sampled at different rates より引用さらに、これらの手法を組み合わせ、各キーの最近のトラフィック量に基づいてサンプリング率を動的に調整することもできます。適切なサンプリング戦略は、サービスを流れるトラフィックの特性や、そのサービスにヒットするクエリの多様性によって異なります。トレースイベントのサンプリングトレースイベントの場合、サンプリングの決定を行うタイミングも重要になります。トレーススパンは複数のサービスにまたがって収集されるため、すべてのスパンが選択される確率は比較的低くなります。すべてのスパンを確実にキャプチャするには、サンプリングの決定をいつ行うかに応じて、特別な配慮が必要です。イベントの開始時に決定を行う「ヘッドベースサンプリング」と、イベントの実行完了後に決定を行う「テールベースサンプリング」の2つのアプローチがあります。コードによるサンプリング戦略の実装本書は、これらのサンプリング戦略をGoのコード例で示しています。一定確率サンプリングから始まり、サンプリング率の記録、一貫性のあるサンプリング、ターゲットレートサンプリング、複数の静的サンプリングレート、キーとターゲットレートによるサンプリング、任意の数のキーでの動的レートサンプリングと、徐々に概念を発展させていきます。最終的には、ヘッドベースサンプリングとテールベースサンプリングを組み合わせ、下流のサービスにトレースのサンプリングを要求できるようにしています。これは、デバッグに必要なすべてのコンテキストをキャプチャするための柔軟性を提供する強力な例です。Figure 17-3. Sampled events containing a TraceId より引用大切なのは状況に応じた賢明なサンプリング本章から学んだ最も重要な教訓は、サンプリングがオブザーバビリティデータを洗練するための有用なテクニックだということです。サンプリングは大規模な環境では必須ですが、小規模な環境でも様々な状況で有用です。コードベースの例は、様々なサンプリング戦略がどのように実装されるかを示しています。OpenTelemetryのようなオープンソースのインストルメンテーションライブラリがこの種のサンプリングロジックを実装するようになってきているため、自分のコードでこれらのサンプリング戦略を再実装する必要性は低くなっています。しかし、サードパーティのライブラリに依存する場合でも、サンプリングがどのように実装されているかを理解することは不可欠です。 それにより、自分の状況に合った方法を選択できるようになるからです。何を、いつ、どのようにサンプリングするかは、コードをどのようにインストルメント化するかを決める際と同様に、組織のユニークなニーズによって定義されるのが最適です。イベントのどのフィールドがサンプリングに興味深いかは、環境の状態を理解し、ビジネス目標の達成に与える影響を判断するのにどれだけ役立つかに大きく依存します。私自身、SREとして大規模なオブザーバビリティシステムの運用に携わった経験から、著者の主張に強く共感しました。当初は、すべてのイベントを収集していましたが、データ量の爆発的な増加に悩まされました。適切なサンプリング戦略を導入したことで、リソース消費を抑えつつ、デバッグに必要な情報を確実に取得できるようになったのです。また、状況に応じてサンプリング戦略を使い分けることの重要性も実感しています。フロントエンドのアプリとバックエンドのサービスでは、最適なサンプリング方法が大きく異なります。 画一的なアプローチではなく、各システムの特性を考慮した柔軟なサンプリングが不可欠だと考えています。Chapter 18. Telemetry Management with Pipelines「Chapter 18. Telemetry Management with Pipelines」は、複雑化するアプリケーションインフラストラクチャにおいて、テレメトリデータを効果的に管理するためのパイプラインの役割について解説した章でした。著者のSuman KarumuriとRyan Katkovは、Slackでの実際の事例を通して、テレメトリパイプラインの設計と運用のベストプラクティスを共有しています。テレメトリパイプラインの利点本書は、テレメトリパイプラインを構築することで得られる様々なメリットを挙げています。まず、パイプラインによって、テレメトリデータをアプリケーションから異なるバックエンドにルーティングすることができます。 これにより、アプリケーションの変更なしに、データの流れを柔軟に制御できるようになるのです。また、セキュリティ上の理由から、特定のチームのみがテレメトリデータにアクセスできるようにしたり、GDPR（一般データ保護規則）やFedRAMP（米連邦リスク・認証管理プログラム）などのコンプライアンス要件を満たすために、データの保存場所や保持期間を制限したりすることもできます。ワークロードの分離も、テレメトリパイプラインの重要な機能です。 大量のログを生成するアプリケーションと低ボリュームのアプリケーションを分離することで、クラスタのパフォーマンスへの影響を最小限に抑えられます。さらに、パイプラインは、オブザーバビリティバックエンドの停止時にデータを一時的にバッファリングする役割も果たします。これにより、テレメトリデータのギャップを防ぎ、サービスの可視性を維持することができるのです。テレメトリパイプラインのアナトミー本書は、機能的なテレメトリパイプラインの基本的なコンポーネントとアーキテクチャについても説明しています。単純に言えば、テレメトリパイプラインは、レシーバー、バッファー、プロセッサー、エクスポーターが直列に連なったものです。レシーバーはソースからデータを収集し、バッファーはデータを一時的に保存します。プロセッサーはバッファーからデータを取得し、変換を適用してからバッファーに戻します。エクスポーターは、バッファーからデータを取り出し、テレメトリバックエンドに書き込みます。Figure 18-1. A receiver, buffer, and exporter as frequently used in simple telemetry pipelines より引用より複雑な設定では、レシーバー→バッファー→レシーバー→バッファー→エクスポーターという一連のチェーンを形成することもあります。Figure 18-2. An advanced example of a telemetry pipeline with a processor より引用パイプライン内のレシーバーやエクスポーターは、容量計画、ルーティング、データ変換など、可能な操作の1つのみを担当することが多いのです。Slackでのテレメトリ管理の事例本書は、Slackがどのようにテレメトリパイプラインを活用しているかを具体的に解説しています。Slackでは、メトリクスの集約にPrometheusを使用しています。PHPやHackアプリケーションサーバーからメトリクスを収集するために、カスタムのPrometheusライブラリを使って、リクエストごとにメトリクスをローカルデーモンに送信しています。Figure 18-3. Aggregation of metrics from a per-request process application より引用ログとトレースイベントの管理には、社内で開発したMurronというGoアプリケーションを使用しています。Murronは、レシーバー、プロセッサー、エクスポーターの3種類のコンポーネントで構成されており、毎秒数百万のメッセージを処理しています。Figure 18-4. Slack telemetry pipeline with receivers, buffers, and exporters for trace data より引用Slackでは、トレースデータの構造を簡素化するために、SpanEventという新しいフォーマットを実装しています。これにより、エンジニアがトレースを簡単に生成・分析できるようになり、CI/CDシステムのインストルメンテーションなど、新しい可能性が開けるのです。Figure 18-5. Slack’s tracing infrastructure, with applications in pink (light gray in print), receivers and exporters in blue (medium gray) より引用テレメトリパイプラインの重要性と選択本章から学んだ最も重要な教訓は、テレメトリパイプラインが、オブザーバビリティデータを効果的に管理するために不可欠だということです。 パイプラインは、データのルーティング、セキュリティ、コンプライアンス、ワークロードの分離、バッファリングなど、様々な課題に対処するための強力なツールとなります。本書は、オープンソースのツールを組み合わせることで、今日から簡単にテレメトリパイプラインを構築できると述べています。一方で、組織の成長に伴い、パイプラインの管理は複雑になり、多くの課題をもたらすことも指摘しています。ビジネスの現在のニーズに合わせてパイプラインを構築し、将来のニーズを予測しつつも、過剰な実装は避けるべきだと著者は勧めています。 モジュール性を維持し、プロデューサー、バッファー、プロセッサー、エクスポーターのモデルに従うことで、オブザーバビリティ機能をスムーズに運用しながら、ビジネスに価値を提供できるようになるのです。私自身、SREとして複雑なマイクロサービスアーキテクチャを管理した経験から、著者の主張に強く共感しました。サービス間の依存関係が複雑になるほど、各サービスが生成するテレメトリデータを適切に管理することが困難になります。テレメトリパイプラインを導入したことで、データの流れを一元的に制御し、必要な情報を適切なバックエンドに確実に届けられるようになったのです。また、Slackの事例から、オープンソースツールと自社開発ツールを組み合わせて、自社のニーズに合ったパイプラインを構築することの重要性も学びました。すべてを一から開発するのではなく、既存のツールを活用しつつ、不足する機能を補うことが、効率的で柔軟性の高いパイプラインの実現につながるのだと思います。Part V. Spreading Observability Culture大規模に可観測性を実践する際の課題に対処することに焦点を当ててますChapter 19. The Business Case for Observability「Chapter 19. The Business Case for Observability」は、オブザーバビリティの導入を組織全体に広めるために、様々なステークホルダーからの支持を得る方法について解説した章でした。本書は、オブザーバビリティの必要性を認識するアプローチとして、リアクティブとプロアクティブの2つの方法を示し、それぞれのメリットとデメリットを詳しく説明しています。オブザーバビリティ導入へのリアクティブなアプローチ本書は、まず組織がオブザーバビリティを導入する「リアクティブ」なアプローチについて述べています。多くの組織は、従来のアプローチでは対処できない深刻な課題に直面するまで、オブザーバビリティの必要性を認識しないと指摘しています。例えば、重大なサービス障害が発生した場合、根本原因分析によって単一の理由が特定されると、経営陣はその理由を基に、問題が迅速に解決されたことを示すための単純化された是正措置を求めがちです。しかし、問題を素早く解決しようとするあまり、過度に単純化されたアプローチをとると、根本的な原因ではなく、最も明白な症状に対処するだけに終わってしまうのです。また、従来のツールでは許容せざるを得なかった非効率性を認識できないことも、リアクティブなアプローチを招く原因です。オブザーバビリティがないチームは、同じような症状と根本原因を持つインシデントを追跡するために、多くの時間を浪費しています。 これは、エンジニアリングチームにアラート疲労を引き起こし、最終的には燃え尽き症候群につながります。オブザーバビリティのROI本書は、オブザーバビリティの導入が、ビジネスにもたらす4つの重要な影響について説明しています。コード品質の向上による売上増加MTTDとMTTRの短縮による インシデント対応コストの削減インシデントの防止によるコスト削減従業員の離職率低下によるコスト削減Forrester Researchが実施した調査では、これらのメリットが数値化されています。オブザーバビリティは、ビジネスの収益性と効率性に直接的かつ間接的に影響を与えるのです。オブザーバビリティ導入へのプロアクティブなアプローチ本書は、オブザーバビリティの必要性を予測し、従来のプラクティスを変革するための「プロアクティブ」なアプローチについても述べています。オブザーバビリティの導入を正当化するためには、まず、TTD（発見までの時間）とTTR（解決までの時間）の改善効果を示すことが有効です。オブザーバビリティは、従来のモニタリングツールでは発見できなかった個々のユーザーの問題を特定し、コア分析ループの自動化によって問題の根本原因を迅速に特定できるようになります。さらに、問題の検出と解決が迅速になることで、予期せぬ運用作業の量が減少し、オンコールのストレスが軽減されます。これにより、バグの蓄積が減り、新機能の開発に費やす時間が増えるのです。 また、個々のユーザーリクエストのパフォーマンスとボトルネックの原因を理解することで、サービスを迅速に最適化できるようになります。このように、オブザーバビリティは、エンジニアリングと運用の間の障壁を取り除き、ソフトウェアの開発と運用により多くの責任を持たせることができるのです。オブザーバビリティの実践本書は、オブザーバビリティを継続的な実践として導入することの重要性を強調しています。オブザーバビリティは、セキュリティやテスト可能性と同様に、生産サービスの開発と運用に責任を持つ全員が共有すべき責任なのです。効果的なオブザーバブルシステムを構築するには、技術的な能力だけでなく、心理的安全性を育む文化も必要です。ブレームレス文化は、実験を支援し、好奇心に満ちたコラボレーションを奨励する、心理的に安全な環境を育みます。 これは、従来のプラクティスを進化させるために不可欠なのです。また、オブザーバビリティの実践では、エンジニアが生産環境の問題を検出し解決するだけでなく、ビジネスインテリジェンスの質問にリアルタイムで答えることも奨励されるべきです。オブザーバビリティは、ソフトウェア開発、運用、ビジネス成果の間の人為的な壁を取り除くのです。適切なツールの選択オブザーバビリティには、コードのインストルメンテーション、テレメトリデータの保存、そのデータの分析など、技術的な能力が必要です。そのためには、適切なツールを選択することが重要です。インストルメンテーションには、OpenTelemetry（OTel）が新たな標準として登場しています。OTelを使えば、特定のベンダーのインストルメンテーションフレームワークにロックインされることなく、テレメトリデータを任意の分析ツールに送信できます。データストレージと分析は、オープンソースと独自の選択肢があります。商用ベンダーは通常、ストレージと分析をバンドルしていますが、オープンソースソリューションでは、別々のアプローチが必要です。自前のデータストレージクラスタを運用する運用負荷を慎重に検討し、ビジネスニーズの中核となる差別化要因に貴重なエンジニアリングサイクルを投資することが肝要です。十分なオブザーバビリティの判断本書は、オブザーバビリティが「十分」であるかどうかを判断する方法についても説明しています。オブザーバビリティを実践するチームは、新しいコードに適切なインストルメンテーションがバンドルされていることを習慣づける必要があります。コードレビューでは、新しいコードのインストルメンテーションが適切なオブザーバビリティ基準を満たしていることを確認すべきです。オブザーバビリティが十分であるかどうかは、文化的な行動と主要な結果を見ることでわかります。オブザーバビリティのメリットを享受するチームは、生産環境を理解し運用する自信を高めるはずです。 未解決の「ミステリー」インシデントの割合は減少し、インシデントの検出と解決にかかる時間は組織全体で短縮されるでしょう。オブザーバビリティ文化を組織全体に広めるために本章から学んだ最も重要な教訓は、オブザーバビリティの導入には、組織全体の支持が不可欠だということです。 オブザーバビリティの必要性は、重大な障害への対応という形でリアクティブに認識されることもあれば、イノベーションを阻害する要因を取り除くためにプロアクティブに認識されることもあります。いずれにせよ、オブザーバビリティのイニシアチブを支援するためのビジネスケースを作成することが肝要なのです。オブザーバビリティは、セキュリティやテスト可能性と同様に、継続的な実践としてアプローチする必要があります。オブザーバビリティを実践するチームは、コードの変更にテストと適切なインストルメンテーションを習慣づけなければなりません。 オブザーバビリティには継続的なケアとメンテナンスが必要ですが、本章で概説した文化的行動と主要な結果を探ることで、オブザーバビリティが十分に達成されたかどうかを知ることができるのです。私自身、SREとしてオブザーバビリティの導入に携わった経験から、著者の主張に強く共感しました。当初は、オブザーバビリティの必要性を感じていたのは私たちのチームだけでしたが、インシデントの検出と解決にかかる時間が大幅に短縮されたことで、他のチームからも注目されるようになりました。 そこで、オブザーバビリティの実践をエンジニアリング組織全体に広げるために、経営陣への働きかけを始めたのです。当初は難色を示していた幹部たちも、オブザーバビリティによるビジネスへの具体的なメリットを示すことで、徐々に理解を示してくれるようになりました。特に、MTTRの改善とそれによるエンジニアの生産性向上は、説得力のあるデータポイントでした。結果として、オブザーバビリティはエンジニアリング組織全体に浸透し、今では私たちのカルチャーの中核をなしています。新入社員はコードとインストルメンテーションをセットで書くことを求められ、シニアエンジニアは率先してオブザーバビリティ駆動の開発を実践しています。Chapter 20. Observability’s Stakeholders and Allies「Chapter 20. Observability's Stakeholders and Allies」は、組織全体でオブザーバビリティの採用を広げるために、エンジニアリングチーム以外のステークホルダーとどう連携すべきかを解説した章でした。本書は、オブザーバビリティが様々なチームの目標達成に役立つことを示し、それらのチームをオブザーバビリティ採用の同盟者にする方法を詳しく説明しています。SREやアーキテクトの仕事でも似たような話があるのでめちゃくちゃに参考になりました。 speakerdeck.comエンジニアリング以外のオブザーバビリティニーズの認識本書は、まずエンジニアリング以外のチームがオブザーバビリティを必要とするケースについて述べています。オブザーバビリティは、ソフトウェアが実際のユーザーの手にどのように動作しているかを理解するためのレンズです。 それは、ビジネスにとって非常に重要な情報なのです。例えば、新機能の採用状況、新規顧客の製品利用傾向、サービスの可用性情報、信頼性のトレンド、インシデントの予防的解決、機能のリリーススピードなど、様々な側面でオブザーバビリティが役立ちます。顧客体験の理解と改善は、組織のあらゆるチームの仕事なのです。本書は、オブザーバビリティデータの民主化を勧めています。誰もがソフトウェアの実際の動作を見られるようにすることで、各チームが独自の視点と質問を持ち込み、コミュニケーションのサイロを取り除くことができるのです。実践におけるオブザーバビリティの同盟者の獲得次に本書は、様々なステークホルダーにオブザーバビリティがビジネス課題の解決にどう役立つかを示し、オブザーバビリティ採用の同盟者にする方法を説明しています。カスタマーサポートチームカスタマーサポートチームは、顧客から問題の報告を受ける最前線です。従来のモニタリングでは、問題の検出や対応に時間がかかり、その間に顧客からの問い合わせが山積みになってしまいます。オブザーバビリティを使えば、サポートチームは顧客が報告した問題をデバッグし、既知の問題に関連しているかどうかを迅速に確認できます。 これにより、問題のトリアージを適切に行い、自動検知されない問題を特定することもできるのです。カスタマーサクセスチームとプロダクトチームカスタマーサクセスチームは、顧客が製品を効果的に使えるよう支援する、より積極的なアプローチをとります。オブザーバビリティは、製品の使われ方を理解するのに非常に役立ちます。 これは、プロダクトチームにとっても有益な情報です。例えば、新機能の採用が芳しくない場合、オブザーバビリティを使って、その機能がワークフローのどこで、どのように呼び出されているかを見ることができます。顧客の行動パターンを分析することで、機能の採用を促進する方法を見出すことができるのです。営業チームとエグゼクティブチーム営業チームは、売れる製品機能を理解し、サポートすることに関心があります。オブザーバビリティデータを使えば、どの顧客がどの機能をどのくらいの頻度で使っているかを把握できます。 これは、営業戦略の立案に役立つ定量的な分析です。エグゼクティブは、ビジネスに最大のインパクトを与える戦略的投資の方向性を確実に理解したいと考えています。オブザーバビリティデータは、エンジニアリング投資とビジネス目標を結びつけるのに役立ちます。 それにより、組織全体でのアライメントを創出できるのです。オブザーバビリティツールとBIツールの使い分け本書は、オブザーバビリティツールとビジネスインテリジェンス（BI）ツールの違いについても説明しています。オブザーバビリティツールは、コード、インフラ、ユーザー、時間の交差点を理解するために特化しています。それに対し、BIツールは非常に一般化されています。オブザーバビリティツールは、クエリの実行時間、精度、鮮度、構造、時間幅、一時性などの点で、BIツールとは異なるトレードオフを行っているのです。また、BIツールはしばしば集計メトリクスにロックインされ、ビジネス全体の超ビッグピクチャーしか見えなくなります。一方、オブザーバビリティは、製品の使用状況やユーザーの行動について質問する際に、より詳細なレベルでのデータを提供できます。オブザーバビリティツールを部門間で共有することは、共通言語を促進するための素晴らしい方法です。エンジニアはビジネス言語を使ってドメインモデルを記述することを奨励され、ビジネス側は実際のユーザーベースの多様性を理解できるようになるのです。オブザーバビリティの採用を組織全体に広げるために本章から学んだ最も重要な教訓は、オブザーバビリティが、組織内の様々なチームの目標達成に役立つ強力なツールだということです。 エンジニアリングチームだけでなく、プロダクト、サポート、カスタマーサクセス、営業、エグゼクティブなど、あらゆるチームがオブザーバビリティから恩恵を受けることができます。これらのチームがオブザーバビリティを活用して目標を達成できるよう支援することで、オブザーバビリティ採用の強力な同盟者を獲得できるのです。彼らは、オブザーバビリティ採用の取り組みに優先順位を付け、後押ししてくれるでしょう。著者が示した事例は決して網羅的ではありません。むしろ、どのようなビジネスチームがオブザーバビリティデータを活用して、より良い結果を達成できるかを考えるためのプライマーとして使えます。 他のビジネスチームの目標達成を支援することが、オブザーバビリティ採用の取り組みを推進するための鍵なのです。私自身、SREとしてオブザーバビリティの導入に携わった経験から、著者の主張に強く共感しました。当初は、オブザーバビリティの価値をエンジニアリングチーム以外に伝えるのは難しいと感じていました。しかし、様々なチームにオブザーバビリティがどう役立つかを具体的に示すことで、次第に理解と協力を得られるようになったのです。特に、カスタマーサポートチームとの連携は大きな転機となりました。オブザーバビリティを使ってお客様の問題をより迅速に解決できるようになったことで、サポートチームはオブザーバビリティの強力な支持者になってくれました。 彼らの後押しがあったからこそ、組織全体でのオブザーバビリティ採用が加速したのだと思います。Chapter 21. An Observability Maturity Model「Chapter 21. An Observability Maturity Model」は、組織がオブザーバビリティの採用を測定し、優先順位を付けるための指針となる「オブザーバビリティ成熟度モデル（OMM）」について解説した章でした。本書は、OMM が目標とする成果を明確にし、組織のオブザーバビリティ実践の成熟度を評価するための能力を特定しています。OMMについては監視からオブザーバビリティへ〜オブザーバビリティの成熟度/From Monitoring to Observability - Maturity of Observability が良かったのでオススメです。 speakerdeck.comオブザーバビリティ最前線 〜 事例LTから学ぶ、オブザーバビリティの成熟度〜という勉強会の動画もあるので追記しておきます。www.youtube.com成熟度モデルについての注意点本書は、まず成熟度モデルの限界について述べています。成熟度モデルは、ソフトウェア工学チームのパフォーマンスレベルに上限がないことや、実践が絶えず進化し改善されていることを考慮していません。 また、モデルが作成された時点での理想的な未来のスナップショットに過ぎず、著者の偏見が多くの仮定に組み込まれている可能性があります。したがって、成熟度モデルを見る際には、すべての組織に当てはまるワンサイズフィットオールのモデルは存在しないことを常に念頭に置く必要があります。成熟度モデルは、自社のニーズと望ましい成果を批判的かつ体系的に評価するための出発点として役立ちます。 また、長期的な取り組みを推進するのに役立つ、具体的で測定可能な目標を特定し、定量化するのにも役立ちます。オブザーバビリティが成熟度モデルを必要とする理由本書は、オブザーバビリティの実践を導入するチームに見られる定性的な傾向と、ソフトウェアエンジニアリングの専門家を対象とした調査から得られた定量的な分析を組み合わせて、OMMを構築したと説明しています。オブザーバビリティを導入したチームは、導入していないチームに比べて、生産環境でのソフトウェアの品質を確保する能力に自信を持つ確率が3倍高いことがわかりました。 また、オブザーバビリティを導入していないチームは、作業時間の半分以上を、新しい製品機能のリリースにつながらない作業に費やしていました。これらのパターンは、今日の複雑な社会技術システムから生まれた特性です。ソフトウェアの品質の確保や、機能のイノベーションに費やす時間などの能力を分析することで、グループ行動の病理とその解決策の両方が明らかになります。 オブザーバビリティの実践を採用することは、「よりよいコードを書く」や「よりよい仕事をする」といった個人の努力では解決できない問題の解決に役立つのです。OMMが参照する能力本書は、オブザーバビリティの実践の質に直接影響を与える5つの能力について詳しく説明しています。レジリエンスを持ってシステム障害に対応する高品質のコードを提供する複雑性と技術的負債を管理する予測可能なペースでリリースするユーザーの行動を理解するこれらの能力は、網羅的なリストではありませんが、潜在的なビジネスニーズの広さを表しています。重要なのは、これらの能力を構築することは「終わり」のない追求であり、常に継続的な改善の余地があるということです。組織のためのOMMの活用OMMは、オブザーバビリティを効果的に活用するための組織の能力を見直すのに役立つツールです。モデルは、チームの能力が欠けている点と優れている点を測定するための出発点を提供します。 オブザーバビリティの文化を採用し、広めるための計画を立てる際には、自社のビジネスのボトムラインに最も直接的に影響を与え、パフォーマンスを向上させる能力を優先することが有効です。成熟したオブザーバビリティ実践を構築することは、直線的な進歩ではなく、これらの能力は真空の中に存在しないことを覚えておくことが重要です。オブザーバビリティはそれぞれの能力に絡み合っており、ある能力の向上が他の能力の結果に貢献することもあります。 そのプロセスの展開は、各組織のニーズに固有のものであり、どこから始めるかは現在の専門分野によって異なります。各能力を見直し、優先順位を付ける際には、チーム内でこの変革を推進する明確な担当者を特定する必要があります。その取り組みをレビューし、自社に関連する明確な成果重視の指標を開発することが肝要です。 明確なオーナーシップ、説明責任、そして資金と時間の面でのスポンサーシップがなければ、進歩は難しいでしょう。オブザーバビリティ成熟度モデルが示す道筋本章から学んだ最も重要な教訓は、オブザーバビリティ成熟度モデルが、組織が望ましい成果を測定し、独自のカスタマイズされた採用パスを作成するための出発点を提供するということです。オブザーバビリティの実践を成熟させた高パフォーマンスチームを牽引する重要な能力は、以下の軸に沿って測定されます。システム障害にレジリエンスを持って対応する方法高品質のコードを容易に提供できる方法複雑性と技術的負債を適切に管理する方法ソフトウェアのリリースペースが予測可能である方法ユーザーの行動を適切に理解できる方法OMMは、オブザーバビリティを採用している組織全体で気づいた定性的な傾向と、ソフトウェアエンジニアリングの専門家を対象とした調査から得られた定量的な分析を組み合わせたものです。本章で示した結論は、2020年と2021年に実施された調査研究を反映しています。 成熟度モデル自体は、オブザーバビリティの採用が広がるにつれて進化していくでしょう。同様に、オブザーバビリティの実践も進化し、成熟への道のりは組織ごとに独自のものになるでしょう。しかし、本章は、組織が独自の実用的なアプローチを作成するための基礎を提供しています。私自身、SREとしてオブザーバビリティの導入に携わった経験から、著者の主張に強く共感しました。当初は、オブザーバビリティの成熟度を測定することは難しいと感じていました。しかし、OMMを使って自社の能力を評価し、優先順位を付けることで、オブザーバビリティ文化を組織全体に広めるためのロードマップを作成することができたのです。特に、「予測可能なペースでリリースする」能力の向上は、私たちのチームにとって大きな転機となりました。従来は、新機能のリリースが遅れがちで、お客様からのフィードバックを得るのに時間がかかっていました。オブザーバビリティを活用することで、リリースプロセスを可視化し、ボトルネックを特定して改善することができるようになったのです。 その結果、リリースペースが安定し、お客様満足度も向上しました。Chapter 22. Where to Go from Here「Chapter 22. Where to Go from Here」は、本書のまとめと今後のオブザーバビリティの展望について述べた、非常に示唆に富んだ一章でした。著者らは、オブザーバビリティの概念と実践が過去数年でどのように進化してきたかを振り返り、これからの方向性を予測しています。オブザーバビリティの定義の進化本章の冒頭で、著者らは本書の執筆に3年以上を要した理由を説明しています。その主な理由は、オブザーバビリティの状態が絶えず変化してきたことにあります。当初は、オブザーバビリティという用語自体を定義する必要があり、データのカーディナリティや次元といった概念も十分に理解されていませんでした。 また、オブザーバビリティとモニタリングが同義語として使われることも多く、その違いを説明するのに苦労したそうです。しかし、今では多くの人がオブザーバビリティの基本概念を理解し、モニタリングとの違いも認識されるようになってきました。人々が求めているのは、より洗練された分析と、オブザーバビリティの実践を成功させるための具体的なガイダンスなのです。本書の構成の変遷また、本書の構成も当初の予定から大きく変化したと著者らは述べています。最初は、より基本的な内容を扱う短い章立てでしたが、一般的な懸念事項や成功パターンが明らかになるにつれ、より深く詳細な内容を追加していったのです。 さらに、大規模なオブザーバビリティの実践から学んだ教訓も取り入れています。加えて、本書は競合他社に勤める人を含む複数のレビュアーとの共同作業の成果でもあります。著者らは、オブザーバビリティの最新の状態を包括的に反映するために、執筆プロセス全体を通して自らの見解を改訂し、幅広い視点を取り入れ、概念を再検討してきたのです。オブザーバビリティ採用の社会技術的課題読者からのフィードバックに基づき、著者らはオブザーバビリティの採用における社会技術的な課題についても追加しました。オブザーバビリティは、ツールを購入するだけでは実現できません。 それは、ソフトウェアの動作を理解する方法を変え、顧客との関係を変革する実践なのです。追加のリソース本章では、本書で扱えなかった重要なトピックを補完するための追加のリソースも紹介されています。SRE本、SLOの実装、OpenTelemetryの詳細など、オブザーバビリティに関連する様々な話題をカバーする書籍やブログが推奨されていました。オブザーバビリティの未来予測最後に、本書は今後のオブザーバビリティの展開について予測を示しています。2022年の発売で2年経過しているが概ねあっている。OpenTelemetryとオブザーバビリティの融合：OTelは、アプリケーションのインストルメンテーションのデファクトスタンダードになり、オブザーバビリティと不可分のものになるでしょう。フロントエンドアプリケーションへのオブザーバビリティの浸透：RUMや合成モニタリングに代わり、オブザーバビリティがフロントエンドのパフォーマンス理解とデバッグに使われるようになります。自動インストルメンテーションの進化：OTelの自動インストルメンテーションは、ベンダー固有のライブラリに匹敵するレベルに達し、カスタムインストルメンテーションと組み合わせて使われるでしょう。開発ワークフローの変革：オブザーバビリティは、コード変更が本番環境でユーザーにどう影響するかを理解するための不可欠なツールになります。それにより、開発者は迅速なフィードバックを得て、より良いソフトウェアを作れるようになるのです。オブザーバビリティ実践の継続的な進化著者らは、本書の結論として、オブザーバビリティが絶え間ない実践の進化であることを強調しています。 高カーディナリティと高次元のテレメトリデータを自在に分析し、コア分析ループを使って問題の根本原因を迅速に特定できるようになることが、オブザーバビリティの本質なのです。そして、オブザーバビリティの実践は、技術の進歩とともに進化し続けるでしょう。本書が提示したのは、その進化の道筋を示す一つの地図に過ぎません。 実際の道のりは、それぞれの組織に固有のものになるはずです。私自身、SREとしてオブザーバビリティの導入に携わってきた経験から、著者らの主張に強く共感しました。オブザーバビリティは、単なるツールの導入ではなく、ソフトウェアの信頼性を追求する終わりなき旅なのだと実感しています。 本章で得た洞察を糧に、その旅を続けていきたいと思います。さいごに本書『Observability Engineering』は、現代のソフトウェアシステムが直面する複雑性という難題に対し、オブザーバビリティという解決策を提示してくれる、極めて示唆に富んだ一冊でした。オブザーバビリティは、単なるツールや技術の問題ではありません。それは、システムと向き合い、その内部を深く理解するための思想であり、文化なのです。オブザーバビリティの実践は、エンジニアリングチームの働き方を変え、組織のあり方そのものを変革していく営みなのだと、今までの経験と本書を通じて強く実感させられました。著者らが繰り返し強調しているように、オブザーバビリティの旅に終わりはありません。技術は常に進化し、システムはますます複雑になっていきます。そうした中で、オブザーバビリティのベストプラクティスもまた、絶え間ない進化を求められるのです。しかし、その本質は不変です。システムの真の姿を捉え、ユーザーに価値を届け続けること。それこそが、私たちソフトウェアエンジニアに課せられた使命なのだと、改めて思い知らされました。本書で得た学びを胸に、オブザーバビリティの実践を重ね、その輪を広げていくことが、私にできる重要な責務だと感じています。最後に、本書の著者をはじめ、オブザーバビリティの発展に尽力されてきた方々に、心からの敬意と感謝を表します。皆さんの献身的な努力なくして、今日のオブザーバビリティの隆盛はありませんでした。皆さんが切り拓いてくださった道の上を、私もまた歩んでいくことを誓います。そして、本ブログ読者の皆さまにも感謝を申し上げます。1つ1つの気づきや学びを積み重ねることが、私たち自身の成長につながるだけでなく、ひいては業界全体の発展にもつながるのだと信じています。引き続き、オブザーバビリティについて学び、実践し、議論を深めていければとおもいます。あと、この手のタイプの読書感想文は家でちまちま書くことでしか成立しないので生活が変わったらやめます。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。今週の金曜日が誕生日なので祝っていただけても嬉しいです。参考資料Exponential Histogram?OpenTelemetryが気になってるけど実際に始めて「なるほどね」ってなるにはどうしたらいいかについて15分でまとめて喋りますOpenTelemetry を使ったトレースエグザンプラーの活用 / otel-trace-exemplarオブザーバビリティの Primary SignalsOn the general theory of control systemsWhy Intuitive Troubleshooting Has Stopped Working for YouControl theory | wiki制御理論 | wikiScuba: Diving into Data at FacebookChoose Boring TechnologyUnicorn)State of DevOps 2019CNCF Cloud Native Definition v1.1Ep. #11, Chaos Engineering with Ana Medina of GremlinChaos Engineering ObservabilityHow Time Series Databases Work—and Where They Don'tイベント（Event）の構造化データDapper, a Large-Scale Distributed Systems Tracing InfrastructureEvolving Distributed Tracing at Uber EngineeringZipkinServiceNow Cloud ObservabilityHoneycombAWS X-Ray and Step FunctionsOpenTelemetry | DocumentationWaterfall chart【OpenTelemetry】オブザーバビリティバックエンド8種食べ比べtracingからAttributesを付与してmetricsを出力できるようにtracing-opentelemetryにPRを送ったAccelerateThe Staff Engineer's PathTest-driven developmentWhen Doing Wrong Feels So Right: Normalization of DevianceTying These Principles TogetherService Level ObjectivesImplementing Service Level ObjectivesMoving Past Shallow Incident DataObservability Maturity Community Research Findings Q1, 2020Observability Maturity Community Research Findings 2021Observability Survey 2023The State of Observability 2023OpenTelemetry (OTel) Is Key to Avoiding Vendor Lock-inジョインしたチームのマイクロサービスたちを再計装した話 / Getting started tracing instrument micro service with OpenTelemetryOpenTelemetryのここ4年の流れ / OpenTelemetry in last 4+ yearsペパボOpenTelemetry革命OpenTelemetry Collector 自身のモニタリング / Monitoring the OpenTelemetry Collector itself5分でわかるGoの自動計装Building a ServiceMap with Service Graph ConnectorHoneycombとOpenTelemetryでオブザーバビリティに入門してみる自家版semconvの夢サービスメッシュ環境における OpenTelemetry 活用 / OpenTelemetry in Service MeshOpenTelemetry のサービスという概念についてOpenTelemetry実践 はじめの一歩AWS Distro for OpenTelemetry (ADOT) の紹介監視論Ⅳ ～監視からオブザーバビリティーへの招待～オブザーバビリティで理解するコンピュータサイエンス監視論 ～SREと次世代MSP～","link":"https://syu-m-5151.hatenablog.com/entry/2024/05/06/090014","isoDate":"2024-05-06T00:00:14.000Z","dateMiliSeconds":1714953614000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"リトライ処理を追加するとバッチが安定することがあることもそこそこあるので「avast/retry-go」を使ってみる","contentSnippet":"はじめにインフラエンジニアは日々の業務でプログラムを書く機会が多く、その中で処理の実行やHTTPの通信などでリトライ処理を実装する必要があることが少なくありません。リトライ処理を実装する必要は必ずしもなくても、実装することでバッチが安定することがあります。もっと言っておくとリトライ処理を実装することで、一時的なエラーによる処理の失敗を回避し、バッチ処理の安定性が向上する可能性があります。実行基盤によってジョブの再試行の自動化、最大再試行回数を設定するやPod失敗のバックオフポリシーなどとの兼ね合いを考える必要もあると思います。あとはマジでガー不のバグを引き寄せることもあるので注意が必要です。はじめにシンプルな例最大リトライ回数の指定次のリトライまでの待ち時間の設定特定の例外のみリトライするケースさいごに今回はGolangには「retry-go」というリトライ処理を簡潔に実装できるライブラリがあり、これを使うと非常に簡単にリトライ機能を追加できます。シェルスクリプトでも簡単に実装できるのですが今回は紹介しない。avast/retry-goは、リトライ処理を実装するための便利なライブラリです。このライブラリを使えば、ごく少ない行数でリトライ機能を実装できます。github.comインストールはgo get github.com/avast/retry-goで行えます。このライブラリの使い方は非常に簡単です。リトライ対象の処理をラップするだけで、設定した回数とウェイト時間に従ってリトライが実行されます。設定可能なオプションも豊富で、リトライ条件やログ出力など細かなカスタマイズも可能です。リトライ処理の実装は、単純に見えて一歩踏み込もうとすると意外と難しい面があります。retyr-goを使えば、そういった難しさから開放され、安定したリトライ処理を簡単に実装できます。バッチ処理の安定性向上に役立つことは間違いありません。Golangを使ったプログラミングにおいて、retry-goはリトライ処理の実装を格段に簡単にしてくれる強力なライブラリです。ぜひ一度試してみてはいかがでしょうか。シンプルな例使い方は簡単で、retry.Doを使って対象の関数をラップするだけでリトライ処理を実装できます。例外が発生した場合にはリトライが行われ、何も例外が発生しなければ値が返ってきます。package mainimport (    \"fmt\"    \"math/rand\"    \"github.com/avast/retry-go\")func randomErrorSimple() error {    num := rand.Intn(10)    if num \u003e 2 {        fmt.Printf(\"Error: num=%d\\n\", num)        return fmt.Errorf(\"Error!\")    }    fmt.Printf(\"Success: num=%d\\n\", num)    return nil}func main() {    err := retry.Do(        randomErrorSimple,    )    if err != nil {        fmt.Printf(\"Error: %v\\n\", err)    }}実際に実行してみる。3回失敗して4回目にError値が返っていないので通常に終了。$ go run main.goError: num=5Error: num=4Error: num=3Success: num=0最大リトライ回数の指定retry.Attemptsを使うと、指定した回数だけリトライを行うことができます。指定した回数に達した後に例外が発生した場合はエラーが返されます。package mainimport (    \"fmt\"    \"github.com/avast/retry-go\")func errorWithMaxAttempts() error {    fmt.Println(\"Error occurred!\")    return fmt.Errorf(\"Error occurred!\")}func main() {    retryWithMaxAttempts()}func retryWithMaxAttempts() {    err := retry.Do(        errorWithMaxAttempts,        retry.Attempts(3),    )    if err != nil {        fmt.Println(\"3 times failed\")    }}実際に実行すると3回失敗して終了している。$ go run main.go Error occurred!Error occurred!Error occurred!3 times failed次のリトライまでの待ち時間の設定retry.Delayを使って、次のリトライまで指定した時間待つことができます。例えば、APIのレート制限に引っかかって例外が発生した場合などに便利です。package mainimport (    \"fmt\"    \"time\"    \"github.com/avast/retry-go\")func errorWithDelay() error {    now := time.Now().Format(\"15:04:05\")    fmt.Printf(\"Error occurred!: %s\\n\", now)    return fmt.Errorf(\"Error occurred!\")}func main() {    retryWithDelay()}func retryWithDelay() {    err := retry.Do(        errorWithDelay,        retry.Attempts(3),        retry.Delay(3*time.Second),    )    if err != nil {        fmt.Println(\"3 times failed\")    }}実行結果は以下のようになる。ちゃんと待ち時間を指定できている。$ go run main.go Error occurred!: 01:35:16Error occurred!: 01:35:20Error occurred!: 01:35:263 times failed特定の例外のみリトライするケースretry.RetryIfでリトライする場合の例外条件を指定することができます。特定の例外が発生した場合のみリトライ処理を行うことができます。package mainimport (    \"fmt\"    \"github.com/avast/retry-go\")func errorWithSpecificError(num int) error {    if num == 0 {        fmt.Println(\"0 is invalid\")        return fmt.Errorf(\"value error\")    }    return fmt.Errorf(\"Error occurred!: num=%d\", num)}func main() {    retryWithSpecificError()}func retryWithSpecificError() {    err := retry.Do(        func() error { return errorWithSpecificError(0) },        retry.Attempts(3),        retry.RetryIf(func(err error) bool { return err.Error() == \"value error\" }),    )    if err != nil {        fmt.Println(\"Value Error occurred\")    }    err = retry.Do(        func() error { return errorWithSpecificError(1) },    )    if err != nil {        fmt.Printf(\"%v\\n\", err)    }}実行結果です。$ go run main.go0 is invalid0 is invalid0 is invalidValue Error occurredさいごにretry-goを使用することでお手軽にリトライ処理を追加できて便利です。特に、最大リトライ回数の設定、次のリトライまでの待ち時間の設定、特定の例外のみリトライするケースなど、様々な状況に対応できる機能が用意されています。他にも色々な機能があるので気になった方は公式ドキュメントを見てみてください。github.com","link":"https://syu-m-5151.hatenablog.com/entry/2024/05/02/114958","isoDate":"2024-05-02T02:49:58.000Z","dateMiliSeconds":1714618198000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文","contentSnippet":"はじめに本稿は、オープンソースの可観測性(Observability)プロジェクトである OpenTelemetry を取り上げた書籍「Learning Opentelemetry」の読書感想文です。従来の可観測性の課題であったデータの分断を解消し、トレース、メトリクス、ログなどの様々なテレメトリデータを統合的に扱うことができる OpenTelemetry は、可観測性の分野における革命的な存在と言えます。過去10年間で、可観測性はニッチな分野から、クラウドネイティブの世界のあらゆる部分に影響を与える数十億ドル規模の産業へと発展しました。しかし、効果的な可観測性の鍵は、高品質のテレメトリデータにあります。OpenTelemetryは、このデータを提供し、次世代の可観測性ツールと実践を開始することを目的としたプロジェクトです。learning.oreilly.com本書の想定読者は、アプリケーション開発者、オープンソースのメンテナー、運用・インフラチーム、マネージャーやチームリーダーなど幅広く設定されています。現代の可観測性の原則から、OpenTelemetry の導入、運用、トラブルシューティングに至るまで、大規模な組織における可観測性の実現に必要な知識が網羅的に提供されているのが特徴です。私が業務で利用している技術スタックの実装の詳細については説明されていませんでしたが、全てを網羅することは文量の制約がある以上、不可能であることは理解しています。また、実際に導入する際には泥臭い部分が相応に出てくるのですが、本書ではそれらがなんとなく回避されているようにも感じられ、Opentelemetryが万能の願望機に見えてしまうかもしれません。この辺りについては、OpenTelemetry MeetupやOpenTelemetry Casual Talkなどで先駆者達とお話をすれば、徐々に理解が深まるのではないかと思います。opentelemetry.connpass.comはじめにChapter 1. The State of Modern ObservabilityObservabilityの重要性と課題OpenTelemetryとObservabilityの未来Chapter 2. Why Use OpenTelemetry?現代のソフトウェア開発における可観測性の課題OpenTelemetryがもたらす可観測性の未来Chapter 3. OpenTelemetry OverviewOpenTelemetryの主要コンポーネントOpenTelemetryのコンテキスト伝播SREにとってのOpenTelemetryの意義Chapter 4. The OpenTelemetry ArchitectureOpenTelemetryのアーキテクチャOpenTelemetryを活用したデモアプリケーションOpenTelemetryによる可観測性データの統一性と相関性OpenTelemetryの導入に向けてChapter 5. Instrumenting ApplicationsOpenTelemetryのセットアッププロセスOpenTelemetryの設定のベストプラクティスOpenTelemetryの計装のベストプラクティスOpenTelemetryの導入に向けた考察Chapter 6. Instrumenting Librariesライブラリの重要性と可観測性の意義OpenTelemetryによるライブラリ計装の課題解決ライブラリ計装のベストプラクティスと今後の展望Chapter 7. Observing Infrastructureクラウドプロバイダーのテレメトリデータの収集と活用Kubernetesプラットフォームにおける可観測性サーバーレスプラットフォームの可観測性非同期ワークフローの可観測性Chapter 8. Designing Telemetry PipelinesテレメトリパイプラインのトポロジーとCollectorの役割パイプラインオペレーションの重要性Collectorのセキュリティと運用テレメトリコストの管理Chapter 9. Rolling Out Observability可観測性の真の価値OpenTelemetryの展開における3つの格言OpenTelemetryの展開後の差別化本章のまとめと著者の主張おわりに参考資料以前、OpenTelemetry に関する社内勉強会の資料を作成した際、プロジェクトの全体像を理解することの難しさを感じました。OpenTelemetry は野心的なプロジェクトであり、各コンポーネントの役割や相互の関係性を把握するのは容易ではありません。国内でもOpenTelemetryに関するカンファレンスや勉強会が数多く開催されていますが、どのイベントに参加し、どの資料を読めば効率的に知識を習得できるのか、判断に迷うこともあります。しかし、本書は OpenTelemetry の設計思想から実践的な活用方法まで、体系的かつ平易に解説されており、可観測性に関する理解を深めるための良きガイドになるはずです。syu-m-5151.hatenablog.com近年、マイクロサービスアーキテクチャの普及やクラウドネイティブの進展に伴い、システムの複雑性は増す一方です。そのような環境において、可観測性は安定したサービス運用を実現するための鍵となります。本書を通じて、OpenTelemetry を活用した可観測性の向上について学び、自身の開発・運用プラクティスに活かしていきたいと思います。本書は、OpenTelemetryの重要性とその応用を探る実践的なガイドであり、可観測性の分野で必読の一冊と言えるでしょう。本書は、可観測性の世界でOpenTelemetryが中心的な役割を果たしていることを強調し、その価値と組織にもたらすメリットを第2章で解説します。続いて、OpenTelemetryのモデル、主要な可観測性シグナルの関連性、アプリケーションの計装方法、オープンソースライブラリやサービスの計装、ソフトウェアインフラストラクチャの観測オプション、可観測性パイプラインの構築、そして組織全体でのOpenTelemetryの展開戦略について詳細に説明します。各章は、トレース、メトリクス、ログなどの可観測性シグナルの理解を深め、高品質のテレメトリデータの確保、ライブラリの可観測性への取り組み、OpenTelemetry Collectorを用いたパイプライン構築、そして組織的なアプローチに至るまで、広範囲にわたる知識を提供します。Learning OpenTelemetry (English Edition)作者:Young, Ted,Parker, AustinO'Reilly MediaAmazon本書は、OpenTelemetryを活用した可観測性の向上に向けた実践的な知見を得るための優れたリソースです。具体的な実装の詳細については、他の情報源も参照しながら、自身の環境に合わせて工夫していく必要がありますが、本書が提供する知識と洞察は、その過程で大いに役立つことでしょう。OpenTelemetryは可観測性の分野で大きな可能性を秘めたプロジェクトであり、本書はその理解と活用に向けた道しるべとなる一冊です。また、小項目は本書からの引用ではなくオレオレ分類です。本稿は同僚であり友人の俺ですにレビューしていただきました。改めて感謝申し上げます。hiroki-hasegawa.hatenablog.jpChapter 1. The State of Modern Observability本章を読んで、現代のソフトウェアシステムにおけるObservabilityの重要性と課題について理解を深めることができました。著者は、Observabilityの歴史を理解することが、現在のソフトウェアシステムの課題を解決するために不可欠であると主張しています。これは、冒頭の \"History is not the past but a map of the past, drawn from a particular point of view, to be useful to the modern traveler:歴史とは過去ではなく、現代の旅行者に役立つように特定の視点から描かれた過去の地図である。\" という言葉に端的に表されています。著者の主張を踏まえると、Observabilityの歴史を学ぶことは、現代のソフトウェアシステムの課題を解決するための重要な手がかりになるでしょう。私は壮大な物語が大好きなので、『サピエンス全史』なども好きなので紹介しておきます(なぜ？)。サピエンス全史　上下合本版　文明の構造と人類の幸福作者:ユヴァル・ノア・ハラリ河出書房新社Amazon国内では、OpenTelemetryのこれまでとこれからなどのセッションが参考になるかもしれません。OpenTelemetryは、オープンソースのObservabilityフレームワークであり、その発展の歴史とこれからの方向性を理解することは、現代のソフトウェアシステムにおけるObservabilityの課題を考える上で役立つと思われます。また、Observability Conferenceなどのカンファレンスでは、Observabilityに関する様々なセッションが開催されています。興味のあるセッションを幅広く視聴することで、Observabilityの現状と将来の可能性について、多角的な視点から学ぶことができるでしょう。cloudnativedays.jpObservabilityの重要性と課題本章では、まずObservabilityに関連する重要な用語の定義が述べられています。分散システム、リソース、トランザクション、テレメトリ、分析、Observabilityなど、これらの用語を正しく理解することは、Observabilityについて議論する上で欠かせません。特に、分散システムをリソースとトランザクションの観点から捉えることが重要だと感じました。リソースには、サーバー、コンテナ、プロセス、RAM、CPU、ネットワークカードなどの物理的コンポーネントと、クライアント、アプリケーション、APIエンドポイント、データベース、ロードバランサーなどの論理的コンポーネントが含まれます。一方、トランザクションは、ユーザーに代わってシステムが必要とするリソースを編成し、利用するリクエストを指します。Observabilityとは、これらのリソースとトランザクションの振る舞いを理解するための手段だと言えます。ウェブオペレーション ―サイト運用管理の実践テクニック (THEORY/IN/PRACTICE)オライリージャパンAmazon次に、テレメトリの歴史について触れられています。テレメトリは、電力プラントや公共電力網などの初期の分散システムを監視するために開発されたものであり、コンピュータシステムにおけるテレメトリは、ログ、メトリクス、分散トレーシングの順に発展してきました。これらは、現在の \"Three Pillars of Observability:可観測性の3本柱\" と呼ばれる概念の基礎となっています。これは本書だけが主張しているものではなく2022年にリリースされたObservability Engineeringにも言及があります。Figure 1-2. The three pillars of observability より引用ログは、システムやサービスの状態を説明する人間が読めるテキストベースのメッセージです。メトリクスは、システムの状態とリソース使用率を表すコンパクトな統計情報です。分散トレーシングは、トランザクションを構成する個々のオペレーションを追跡し、レイテンシーの原因を特定するために使用されます。これらの情報は、それぞれ専用のシステムで収集、伝送、分析されてきました。しかし、著者は \"Three Pillars:3つの柱\" アプローチの問題点を指摘しています。ログ、メトリクス、トレースが別々のシステムとして扱われているため、データが分断され、相関関係を見つけることが難しくなっているのです。現実のシステムはトランザクションとリソースで構成されており、問題の多くはこれらの相互作用から生じます。例えば、ログを見ただけでは、リソース使用率の変化パターンとの関連性を自動的に特定することはできません。そのため、データを統合し、相関関係を見つけることができるObservabilityシステムが必要となります。まぁ『TEMPLE: Six Pillars of Observability』みたいに6本柱として紹介している記事などもあるのでいろいろです。medium.com著者が提案するのは、\"Single Braid of Data:データの単一の編み込み\" というコンセプトです。これは、データが互いに組み合わさって一つの流れや構造を形成している様子を表す比喩的な表現として使われることがあります。特に、複数の情報源や種類のデータが統合されて一つの目的や分析のために活用される状況を想像すると良いでしょう。Figure 1-3. A braid of signals, making it easier to find correlations between them より引用これは、ログ、メトリクス、トレースを別々のシグナルとして扱いつつ、それらを単一のグラフ構造にまとめるというアイデアです。各シグナルは独立していますが、接点によってすべてがつながっています。こうすることで、コンピュータがグラフを辿って遠く離れた重要な関連性を素早く見つけ出すことができるようになります。相関関係を見つけるには、データを接続する必要があります。そして、そのためには、システムが発するテレメトリに、統一性と一貫性が求められます。統一されたテレメトリは、統一された分析を可能にし、プロダクションシステムに内在する問題を深く理解するために不可欠なのです。そして、このようなテレメトリシステムが実際に存在しており、それがOpenTelemetryです。OpenTelemetryは、ログ、メトリクス、トレースを単一の一貫したグラフにまとめることで、次世代のObservabilityツールの基盤となるものです。著者は、Observabilityの世界が大きく変わりつつあり、その中心にはOpenTelemetryがあると述べています。トレース、メトリクス、ログ、プロファイリングなど、あらゆる形式のテレメトリを相関させる能力が、これからのObservabilityの鍵となるでしょう。それは、私たちが切望してきたワークフローと自動化を実現するために不可欠です。OpenTelemetryとObservabilityの未来明確に言及されているのですが本書は、OpenTelemetryのドキュメントの代替ではなく、その哲学とデザインを説明し、効果的に活用するための実用的なガイダンスを提供することを目的としています。各章では、OpenTelemetryの価値、モデル、アーキテクチャ、インストルメンテーション、ライブラリ、インフラストラクチャ、パイプライン、組織への展開などについて詳しく説明されています。私自身、ソフトウェアエンジニアとして、本書を通じてOpenTelemetryとObservabilityについての理解を深め、実務に活かしていきたいと思います。現代のソフトウェアシステムが直面する課題を解決するために、OpenTelemetryを中心とした新しいObservabilityの時代に備えることが重要だと感じました。詳細については翻訳もされている『オブザーバビリティ・エンジニアリング』を読めば良いと思いました。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社AmazonChapter 2. Why Use OpenTelemetry?本章を読んで、OpenTelemetryが可観測性の課題を解決するための重要な手段であることを改めて理解しました。現代のソフトウェア開発において、システムの複雑性が増大する中で可観測性の重要性が高まっていますが、同時に様々な課題に直面していることが明らかになりました。システムの複雑性と向き合う書籍は色々ありますがBuilding Microservices, 2nd EditionやEnabling Microservice Success、Software Architecture: The Hard Partsなどの書籍を読むことをお勧めします。learning.oreilly.com本章では、まず現代のソフトウェア開発における可観測性の重要性が述べられています。ソフトウェアシステムの複雑性が増す中で、開発者やオペレーターは限られたリソースでより多くのことをこなすことを求められています。しかし、システムの規模が大きくなるほど、その動作を正確に把握することは容易ではありません。コードやドキュメントだけでは、実際のプロダクション環境でのシステムの振る舞いを完全に理解することはできないのです。著者は、テレメトリ(遠隔測定)と可観測性(Observability)は、このような課題に立ち向かうための最も強力な武器だと述べています。テレメトリとは、システムが何をしているかを示すデータのことで、可観測性とは、そのデータを分析してシステムを理解する能力を指します。現代のソフトウェア開発における可観測性の課題次に、プロダクションモニタリングの現状と課題について触れられています。多くの組織では、メトリクス、ログ、トレースなど、様々なシグナル(信号)を異なるツールで収集し、複数のストレージに保存しています。データのフォーマットや収集頻度もバラバラで、システム全体を把握することが非常に難しくなっているのが実情です。組織の複雑性が増すほど、インシデントの検知や診断、修復に時間がかかるようになります。これは、インシデント対応者が適切なデータを手に入れられないことが大きな原因だと指摘されています。著者によると、データの量、品質、関連性の欠如が、プロダクションデバッグを困難にしているのです。この課題を解決するために、著者は統一されたテレメトリの重要性を説いています。OpenTelemetryは、ハードコンテキストとソフトコンテキストという概念を用いて、テレメトリデータに豊富なメタデータを付与します。Figure 2-1. “Hard” and “soft” contexts emitted by a web application より引用ハードコンテキスト(Hard Context)は、サービス間の因果関係を明示的にリンクするユニークな識別子です。具体的には、各リクエストに割り当てられる一意のIDのことで、分散システム内のサービスがそのIDを伝播させることで、同じリクエストに属するテレメトリデータを関連付けることができます。これにより、個々のテレメトリデータを関連付けるだけでなく、異なるタイプの計装を結びつけることができます。例えば、メトリクスをトレースに関連付けたり、ログをスパンにリンクしたりできるようになります。ハードコンテキストの存在により、人間のオペレーターがシステムの異常動作を調査する時間を大幅に短縮できると著者は述べています。一方、ソフトコンテキスト(Soft Context)は、各テレメトリが表すものを説明する様々なメタデータです。これには、顧客ID、リクエストを処理したロードバランサのホスト名、テレメトリデータのタイムスタンプなどが含まれます。ソフトコンテキストは、ハードコンテキストほど明示的ではありませんが、データの解釈に役立ちます。ソフトコンテキストは、テレメトリデータに固有の次元を追加し、そのデータが何を表しているのかを説明するのに役立ちます。また、著者はテレメトリのレイヤリングの重要性についても言及しています。Figure 2-4. An illustration of layered signals. A histogram measures API latency, with exemplars linking to specific traces, and with those traces linking to profiles or logs to get component- or function-level insights. より引用メトリクス、トレース、ログなどの異なるシグナルを補完的に使用し、適切な抽象度でシステムの動作を測定することで、より深い洞察が得られるというのです。メトリクスは統計情報を提供し、トレースは個々のリクエストの詳細を示し、ログはイベントの記録を提供します。単一の \"dense\" なシグナルを他の形式に変換するのではなく、各レイヤーに適したテレメトリを生成し、コンテキストを介してそれらのシグナルをリンクすることが重要だと指摘しています。そうすることで、システムについて知りもしなかった疑問に答えられるようになるのです。例えば、メトリクスでAPIのレイテンシの異常を検知し、exemplar(代表例)を通じて関連するトレースを特定し、そのトレースからプロファイルやログにリンクすることで、コンポーネントやファンクションレベルの詳細な洞察を得ることができます。さらに、セマンティックテレメトリ(Semantic Telemetry)という概念も紹介されています。これは、テレメトリデータに意味的な情報を付与することを指します。OpenTelemetryは、自己記述的で移植可能なテレメトリデータを提供することで、あらゆる可観測性フロントエンドで活用できるようにしています。例えば、OpenTelemetryのメトリックポイントには、メトリックの粒度や各属性の説明などのメタデータが含まれています。これにより、フロントエンドはメトリッククエリをより適切に可視化し、測定値の名前だけでなく、実際に何を測定しているのかを検索できるようになります。セマンティックテレメトリにより、開発者はデータの表現や分析方法に縛られることなく、必要な情報にアクセスできるようになります。著者は、OpenTelemetryがシステムを理解するための進化的なステップであり、可観測性の概念を定義し統一するための過去20年間の取り組みの集大成だと述べています。本章では、開発者、オペレーター、チーム、組織など、様々なステークホルダーの観点から、OpenTelemetryの価値について論じられています。開発者にとってOpenTelemetryは、言語、ランタイム、クラウドなどを問わず、高品質で広範なテレメトリを一貫した方法で生成するための手段です。OpenTelemetryは、テレメトリをソフトウェアの組み込み機能にすることを目指しており、その目標を達成しつつあります。オペレーターにとっては、膨大なデータから重要なシグナルを見つけ出し、システムの信頼性と回復性を確保するための強力なツールとなります。特に、クラウド環境では、ワークロードが実行されるノードが頻繁に変更されるため、障害の原因特定が極めて困難になります。OpenTelemetryは、そのような環境でもテレメトリデータを効果的に収集・分析するための仕組みを提供します。チームや組織にとっては、ベンダーロックインを防ぎ、既存の計装との互換性を確保するオープンな標準がメリットです。独自のソリューションに依存することは、コストや柔軟性の面でリスクがあります。オープンな標準とオープンソースは、リスクを軽減するだけでなく、将来に備えるためにも不可欠だと著者は主張しています。OpenTelemetryは、テレメトリデータを商品化し、その未来を実現するために尽力しているのです。最後に、OpenTelemetryが可観測性の課題を解決する理由として、普遍的な標準と相関データの2つが挙げられています。OpenTelemetryは、高品質で普遍的なテレメトリを生成するための標準的な方法を提供し、ベンダーロックインを排除します。すでに主要なクラウドプロバイダーやオブザーバビリティプラットフォームがOpenTelemetryをサポートしており、その採用は避けられない流れになっています。また、OpenTelemetryのデータは、単なるトレース、メトリクス、ログの寄せ集めではありません。それらはすべて同じデータ構造の一部であり、システム全体を記述する単一のグラフとして時間とともに関連付けられているのが特徴です。OpenTelemetryは、オペレーターがシステムを調査する際のワークフローを効果的にモデル化し、相関関係を見つけ出すための機械学習を活用するために、この統合されたデータが不可欠だと考えているのです。OpenTelemetryがもたらす可観測性の未来ソフトウェアエンジニアである私にとって、OpenTelemetryは非常に興味深いプロジェクトです。複雑化するシステムを運用する上で、可観測性は欠かせない要素となっています。特に、マイクロサービスアーキテクチャやクラウドネイティブの普及に伴い、システムの動作を把握することがますます難しくなっているのを実感しています。OpenTelemetryは、その課題を解決するための有望なアプローチであり、業界標準となる可能性を秘めていると感じました。統一されたテレメトリ、コンテキストの伝播、レイヤリング、セマンティックテレメトリなど、OpenTelemetryの提供する概念は、可観測性を向上させるための重要な指針になるはずです。本書を通じて、OpenTelemetryの理念と実践方法をしっかりと学び、自身の開発・運用プラクティスに活かしていきたいと思います。Chapter 3. OpenTelemetry Overview本章を読んで、OpenTelemetryが提供する統一された可観測性データのモデルとその重要性について理解を深めることができました。冒頭の \"You can't communicate complexity, only an awareness of it.:複雑さを伝えることはできず、それを認識することしかできません。\" という言葉が印象的でした。現代のクラウドネイティブなソフトウェアシステムは非常に複雑であり、その複雑さをそのまま伝えることは不可能です。しかし、OpenTelemetryは、システムの動作を把握し、その複雑さを認識するための強力なツールを提供してくれます。OpenTelemetryの主要コンポーネント本章では、OpenTelemetryのモデルを構成する主要なコンポーネントについて詳しく解説されています。OpenTelemetryは、トレース、メトリクス、ログという3つの主要な可観測性シグナルを扱います。これらのシグナルは、分散システムにおけるリクエストの流れや、システムの状態、イベントの記録を表現するための手段であり、OpenTelemetryはこれらを統一的かつ効果的に扱うためのデータモデルを提供しているのです。Figure 3-1. A high-level model of OpenTelemetry より引用トレースは、分散システムにおける一連の処理の流れを表現するための重要な機能です。OpenTelemetryのトレースは、スパンと呼ばれる個々のログの集まりとして構成され、これらのスパンがトレースコンテキストを介して関連付けられることで、エンドツーエンドのトランザクションを表現します。各スパンには、名前、開始時間と終了時間、属性、イベント、リンク、ステータスなどの情報が含まれており、これらを組み合わせることでリクエストの詳細な流れを追跡できます。Figure 3-2. A basic payment application for a store. The trace underneath describes a payment request より引用トレースは、エンドユーザーのエクスペリエンスをモデル化するのに最適なシグナルです。1つのトレースが1人のユーザーのシステム内の経路に対応するため、パフォーマンスの問題を特定しやすくなります。また、複数のトレースを集約して分析することで、さまざまな角度からシステムのパフォーマンス特性を把握することもできます。一方、メトリクスは、システムの状態を数値化してモニタリングするための機能です。OpenTelemetryのメトリクスは、開発者が意味のあるイベントを定義し、そのイベントがどのようにメトリックシグナルに変換されるかを指定できるように設計されています。これにより、オペレーターはコストやデータ量、解像度を制御しながら、メトリックの収集と集約を柔軟に行うことができます。メトリックには、カウンター、ゲージ、ヒストグラムなどの種類があり、それぞれがシステムの異なる側面を測定するのに適しています。例えば、あるサービスが受信したリクエストのサイズをバイト単位で記録するメトリックを定義し、そのイベントに対して、一定期間の最大値を求めたり、属性ごとの合計値を算出したりするようなアグリゲーションを適用できます。こうした柔軟なメトリックの処理は、OpenTelemetryの大きな強みの一つです。また、OpenTelemetryのメトリックには、エグゼンプラー(Exemplar)という特殊なハードコンテキストが用意されています。これにより、メトリックのイベントを特定のスパンやトレースにリンクさせ、より詳細なコンテキストを提供することができます。エグゼンプラーを活用することで、メトリックとトレースを効果的に組み合わせたテレメトリのレイヤリングが可能になります。ログについては、OpenTelemetryは既存のロギングAPIとの互換性を重視しつつ、ログをトレースやメトリクスと関連付けることでその価値を高めています。分散システムでは、ログが異なるコンポーネントから収集され、別々のツールで集約されることが多いため、因果関係を把握するのが難しいという課題がありました。OpenTelemetryは、ログにトレースコンテキストを付与し、メトリクスやトレースへのリンクを提供することで、この課題に対処しているのです。OpenTelemetryにおけるログの主な用途は、トレース化できないレガシーシステムからシグナルを取得すること、インフラストラクチャリソースとアプリケーションイベントを関連付けること、定期的なバッチ処理のような非ユーザーリクエストの動作を理解すること、他のシグナルへの変換を行うことなどが挙げられます。OpenTelemetryのコンテキスト伝播本章で特に重要な概念は、コンテキストです。OpenTelemetryにおけるコンテキストは、テレメトリデータを関連付けるためのメタデータであり、ハードコンテキストとソフトコンテキストの2種類に分けられます。ハードコンテキストは、トレースIDなどの一意の識別子を通じてサービス間の因果関係を明示的に関連付けるものであり、ソフトコンテキストは、各テレメトリが表す情報を説明する属性や資源情報などを指します。Figure 3-3. Context flows between services and within a service (inter-service versus intra-service propagation) より引用OpenTelemetryの中核をなすのが、こうしたコンテキストを伝播させるための仕組みです。OpenTelemetryでは、プロパゲーターと呼ばれるコンポーネントを使って、コンテキストを異なるプロセス間で受け渡しします。リクエストが開始されると、OpenTelemetryは登録されたプロパゲーターに基づいてそのリクエストの一意の識別子を生成します。この識別子がコンテキストに追加され、シリアライズされて次のサービスに送信されます。受信側のサービスはそれをデシリアライズし、ローカルのコンテキストに追加します。これにより、分散トレーシングにおけるスパン間の関係性を維持したまま、テレメトリデータを収集・伝送することができるのです。プロパゲーターは、W3C Trace Contextのようなハードコンテキストだけでなく、Baggageと呼ばれるソフトコンテキストの値も伝播させることができます。Baggageは、顧客IDやセッションIDのような、他のシグナルに付与したい値を、それが作成された場所から、システムの他の部分に伝送するためのメカニズムです。ただし、一度追加されたBaggageは削除できず、外部システムにも伝播されるため、その使用には注意が必要です。コンテキストに含まれるもう一つの重要な要素が、属性(Attribute)とリソース(Resource)です。属性は、テレメトリデータが表す内容を説明するためのキーと値のペアであり、OpenTelemetryにおけるメタデータの基本的な形式です。属性を使うことで、テレメトリデータを特定の次元でフィルタリングしたり、グループ化したりすることができます。属性には、文字列、真偽値、数値などのシンプルな値を割り当てることができます。また、同じ型の値の配列を割り当てることもできますが、属性のキーは一意でなければならないという制約があります。属性の数は無制限ではなく、デフォルトでは1つのテレメトリデータにつき最大128個に制限されています。これは、属性の作成やアサインにはコストがかかるためであり、また、メトリックに属性を追加する際には、時系列データベースへの書き込み時にカーディナリティ爆発を引き起こす可能性があるためです。カーディナリティ爆発を防ぐには、可観測性パイプラインやビューを使ってメトリックのカーディナリティを削減したり、高カーディナリティの属性をメトリックから除外してスパンやログに使用したりするのが効果的です。リソースは、属性の特殊なタイプで、プロセスの存続期間中は変化しない情報を表します。ホスト名やクラウドプロバイダーのゾーン、Kubernetesのノード名などがリソース属性の例です。また、セマンティック規約も重要な概念です。OpenTelemetryは、属性のキーや値に関する一貫した規約を定めることで、テレメトリデータの解釈を容易にし、異なるシステム間での相互運用性を高めています。これらの規約は、OpenTelemetryプロジェクト自体が提供するものと、各組織が独自に定義するものの両方があります。セマンティック規約を活用することで、開発者は意味のある属性を使ってテレメトリデータを記述し、オペレーターはそのデータを一貫した方法で分析できるようになります。例えば、OpenTelemetryのセマンティック規約では、HTTPルートの命名規則、サーバーレスの実行環境情報、pub-subメッセージングのキュー方向などが定義されています。こうした規約に従うことで、異なるサービスや環境から収集されたテレメトリデータを統一的に扱うことができます。OpenTelemetryのもう一つの重要な特徴は、OpenTelemetry Protocol (OTLP)の存在です。OTLPは、テレメトリデータを異なるコンポーネント間で効率的かつ柔軟に伝送するための標準的なデータフォーマットとプロトコルであり、多様な生成者と消費者に対して大きなメリットをもたらします。生成者は既存のフォーマットからOTLPへの変換レイヤーを介してOpenTelemetryと統合できるようになり、消費者は特定のベンダーに縛られることなく、幅広いオープンソースおよび商用ツールとのインターフェースを確保できます。OTLPは、バイナリとテキストベースの両方のエンコーディングをサポートしており、CPUとメモリの使用量を抑えることを目指しています。また、新しいシグナルが追加された場合にも、レガシーのレシーバーとエクスポーターとの下位互換性を維持するよう設計されているため、長期的な投資の保護にもつながります。Figure 3-6. An example of a schema-aware telemetry system より引用最後に、OpenTelemetryのバージョニングと安定性についても言及されています。OpenTelemetryでは、厳密なバージョニングと安定性のガイドラインが定められており、ユーザーは長期的なサポートとスムーズなアップグレードを期待できます。また、テレメトリスキーマの概念を通じて、セマンティック規約の変更に柔軟に対応することも可能です。スキーマを認識するバックエンドを構築したり、OpenTelemetry Collectorでスキーマ変換を行ったりすることで、分析ツールで新しいセマンティック規約のサポートを活用しつつ、既存のサービスの再計装やテレメトリ出力の再定義を行わずに済むようになります。OpenTelemetryのバージョニングは、v1.0ラインに沿って継続的に更新されていきます。APIとSDKの安定性についても、明確なポリシーが定められています。例えば、安定版のAPIには12ヶ月間のバグ修正サポートと24ヶ月間のセキュリティサポートが提供されます。こうした長期的なサポート体制により、ユーザーは安心してOpenTelemetryを採用し、継続的に活用していくことができるのです。SREにとってのOpenTelemetryの意義SREの立場から見ると、OpenTelemetryの登場は大きな意味を持ちます。複雑化するシステムを運用する上で、可観測性は欠かせない要素です。しかし、従来のアプローチでは、異なるシグナルを別々のツールで収集・分析する必要があり、システム全体の把握が難しいという課題がありました。OpenTelemetryは、トレース、メトリクス、ログを統一的に扱うためのデータモデルを提供し、コンテキストの伝播によってそれらを関連付けることで、この課題に対処しようとしています。単一障害点の特定、パフォーマンスボトルネックの分析、異常検知など、SREが日々直面する課題に対して、OpenTelemetryの統一されたテレメトリデータは大きな力を発揮するはずです。また、分散トレーシングを活用することで、マイクロサービス間の複雑な相互作用を可視化し、問題の根本原因を素早く特定することもできます。加えて、OpenTelemetryのセマンティック規約は、SREにとって大きなメリットをもたらします。規約に沿ったテレメトリデータを活用することで、サービスのSLOを定義したり、システム全体のヘルスを評価したりするための指標を統一的に扱えるようになります。これは、複数のチームやサービスが関わる大規模なシステムの運用において特に重要な意味を持ちます。また、OpenTelemetryがベンダー中立であることも見逃せません。クラウドプロバイダーやオブザーバビリティツールの乗り換えを検討する際に、テレメトリデータの継続性や移植性が確保されるのは大きなメリットです。特定のベンダーに縛られることなく、柔軟にツールを選択し、組み合わせることができるのです。セマンティック規約やOTLPのような標準化の取り組みは、ベンダーロックインを回避し、相互運用性を高めるために重要です。マイクロサービスアーキテクチャやクラウドネイティブ環境が普及する中で、オープンでポータブルな可観測性データは、SREにとって不可欠な資産となるでしょう。本章を通じて、OpenTelemetryが提供する可観測性データのモデルとその設計思想について深く理解することができました。トレース、メトリクス、ログの統一、コンテキストの伝播、セマンティック規約、標準プロトコル、安定性へのコミットメント。これらの要素が組み合わさることで、OpenTelemetryは現代の複雑なソフトウェアシステムに立ち向かうための強力な武器になると確信しました。私は今後、自身の開発や運用の現場において、OpenTelemetryを積極的に活用し、その効果を実感していくことを強く意識しています。この決意のもと、以下のような具体的な取り組みを計画しています。その過程を読者諸兄とも共有していきたい。既存のサービスへのOpenTelemetryの導入と、レガシーシステムとの統合分散トレーシングを活用したパフォーマンスの可視化と改善セマンティック規約に基づくSLOの定義とモニタリング自動化されたオブザーバビリティパイプラインの構築OpenTelemetryを活用したサービスマップやトポロジーの可視化AIを活用した異常検知やパフォーマンス最適化への挑戦これらの取り組みを通じて、OpenTelemetryの真価を見極め、その可能性を最大限に活かしていきたいと思います。また、OpenTelemetryの進化を注視し、その発展に貢献する方法も積極的に探求していきます。オープンソースプロジェクトとしてのOpenTelemetryは、世界中の技術者が協力し合うことで、さらなる飛躍を遂げるでしょう。可観測性の未来を切り拓くOpenTelemetry。その可能性に大きな期待を寄せつつ、本書の続きを読み進めていきます。次章では、OpenTelemetryのコンポーネントの詳細と、それらがオブザーバビリティスタックにどのように適合するのかを探っていきます。Chapter 4. The OpenTelemetry Architecture本章を読んで、OpenTelemetryの全体像と、実際のアプリケーションにおける活用方法について理解を深めることができました。冒頭の \"Everyone knows that debugging is twice as hard as writing a program in the first place. So if you're as clever as you can be when you write it, how will you ever debug it?:そもそもデバッグはプログラムを書くことの 2 倍難しいことは誰もが知っています。 では、できるだけ賢く書いたとしても、どうやってデバッグできるでしょうか?\" という言葉が印象的でした。デバッグの難しさを考えると、可観測性の重要性は明らかです。OpenTelemetryは、アプリケーションやインフラストラクチャのデバッグを効率化するための強力なツールを提供してくれます。特に、大規模で複雑な分散システムにおいては、システムの動作を把握することが非常に難しくなります。そのような環境でこそ、OpenTelemetryの価値が発揮されるのだと感じました。OpenTelemetryのアーキテクチャ本章では、まずOpenTelemetryを構成する主要なコンポーネントについて解説されています。https://opentelemetry.io/docs/ より引用OpenTelemetryは、アプリケーション内に組み込まれる計装、インフラストラクチャ用のエクスポーター、そしてテレメトリデータをストレージシステムに送信するためのパイプラインコンポーネントから構成されています。これらのコンポーネントが連携することで、エンドツーエンドの可観測性が実現されるのです。アプリケーションレベルでは、ライブラリの計装とOpenTelemetry APIを使った手動の計装の2つのアプローチがあります。Figure 4-2. OpenTelemetry application architecture より引用多くの場合、フレームワークやデータベースクライアントなどのライブラリレベルでの計装だけでも、アプリケーションの動作を把握するのに十分なテレメトリデータが得られます。これは、OpenTelemetryがポピュラーなOSSライブラリに対する計装を豊富に提供しているためです。開発者は、これらのライブラリを使うだけで、特別なコードを書くことなくテレメトリデータを収集できるようになります。さらに、OpenTelemetry SDKを導入することで、これらのライブラリやアプリケーションコードからのAPIコールを実際に処理し、サンプリングやエクスポートを行うことができます。SDKはプラグイン式のフレームワークで、サンプリングアルゴリズムやライフサイクルフック、エクスポーターなどをYAML設定ファイルや環境変数で柔軟に構成できます。開発者は、必要に応じてSDKの機能を拡張し、自分たちのユースケースに合わせたテレメトリパイプラインを構築できるのです。ただし、ライブラリの計装だけでは不十分な場合もあります。ビジネスロジックに関連する重要なメトリクスを収集したり、より詳細なコンテキスト情報をテレメトリデータに付与したりするためには、OpenTelemetry APIを使った手動の計装が必要になります。特筆すべきは、OpenTelemetry APIが、OpenTelemetryが組み込まれていない環境でも安全に呼び出せるよう設計されていることです。つまり、OSSライブラリの開発者は、OpenTelemetryの計装をライブラリに含めておくことで、そのライブラリを使うアプリケーションがOpenTelemetryを採用しているかどうかに関わらず、シームレスにテレメトリデータを収集できるようになるのです。一方、インフラストラクチャのテレメトリも重要です。OpenTelemetryは、Kubernetesやクラウドサービスへの統合を進めており、既存のテレメトリデータをOpenTelemetryのパイプラインに取り込むためのコンポーネントも提供しています。例えば、Kubernetesのメトリクスを収集するためのレシーバーや、AWSのCloudWatchLogsからログデータを取り込むためのエクスポーターなどが提供されています。これらのコンポーネントを活用することで、インフラストラクチャ層とアプリケーション層のテレメトリを統合し、より包括的な可観測性を実現できます。テレメトリパイプラインについては、OpenTelemetry Protocol (OTLP)とOpenTelemetry Collectorが中心的な役割を果たします。大規模な分散システムでは、膨大な量のテレメトリデータが生成されるため、ネットワークの負荷分散やバックプレッシャーなどの課題に対処する必要があります。OpenTelemetry Collectorは、データの収集、処理、エクスポートを柔軟かつ効率的に行うための機能を提供します。現段階で「OpenTelemetry Collectorってなに？」と思った方はkatzchangさんの『入門 OpenTelemetry Collector』をとりあえず、聞いておいてください。cloudnativedays.jp具体的には、Collectorは複数のフォーマット(OTLP、Jaeger、Prometheus、その他の商用/独自ツールなど)でテレメトリデータを受信し、1つ以上のバックエンドにデータを送信できます。また、Collectorはプラグイン式のアーキテクチャを採用しており、受信したデータに対してフィルタリング、属性の追加・削除、サンプリング、バッチ処理などの様々な処理を適用できます。これらの処理をCollectorで集中的に行うことで、アプリケーションへのオーバーヘッドを最小限に抑えつつ、必要なデータを効率的にバックエンドに送信できるようになります。Collectorのもう一つの重要な役割は、テレメトリデータのセマンティクスを保証することです。Collectorは、OpenTelemetryのセマンティック規約に基づいて、受信したデータの属性をOpenTelemetryの標準的な属性にマッピングします。これにより、異なるフォーマットから収集されたデータを統一的に扱えるようになり、分析ツールやダッシュボードでのデータの解釈が容易になります。OpenTelemetryを活用したデモアプリケーション本章では、OpenTelemetryの実際の活用例として、Astronomy Shopというデモアプリケーションが紹介されています。このデモアプリケーションは、マイクロサービスベースのeコマースアプリケーションで、14の独立したサービスから構成されています。github.comデモアプリケーションのアーキテクチャは、ビジネスロジックを扱うアプリケーションコンポーネントと、可観測性に関連するコンポーネントに大別できます。アプリケーションコンポーネントには、注文処理を担うCheckout Service、在庫管理を行うInventory Service、決済を処理するPayment Serviceなどが含まれます。一方、可観測性に関連するコンポーネントとしては、データの収集・変換を行うOpenTelemetry Collector、ストレージとクエリを担うJaegerやPrometheus、可視化のためのGrafanaなどが含まれます。opentelemetry.ioこれらのサービス間の通信には、gRPCが使用されています。gRPCは、Protocol Buffersを利用した効率的なバイナリ通信プロトコルで、特にマイクロサービス間の通信に適しています。OpenTelemetryは、gRPCのクライアントとサーバーの両方に対する計装ライブラリを提供しているため、gRPCを使ったサービス間通信からも豊富なテレメトリデータを収集できます。これは、OpenTelemetryとgRPCを組み合わせるだけで、ある程度の可観測性が \"無料で\" 手に入ることを意味しています。デモアプリケーションを使って、OpenTelemetryによるアプリケーションパフォーマンスの管理方法を実践的に学ぶことができます。例えば、Feature Flag UIを使ってある特定のサービスにエラーを発生させ、そのエラーがどのようにトレースされ、Grafanaのダッシュボードに反映されるかを確認できます。OpenTelemetryが提供するスパンメトリクスを活用することで、エラーが発生しているサービスやルートを特定し、根本原因の調査に役立てることができます。スパンメトリクスは、トレースデータからメトリクスを生成する仕組みで、OpenTelemetry Collectorの spanmetrics プロセッサを使って実現されます。これにより、個々のトランザクションの詳細を捨象しつつ、システム全体のパフォーマンスを俯瞰的に理解することができるようになります。デモアプリケーションでは、トレースデータを使った柔軟な分析方法も示されています。GrafanaのExploreビューでは、Jaegerに保存されたトレースデータを検索し、特定のスパンに関連するエラーを調査できます。例えば、oteldemo.AdService/GetAdsというスパンに着目することで、広告サービスの特定のルートで発生しているエラーを発見できました。こうした分析は、メトリクスだけでは難しいものです。トレースデータは、個々のリクエストに関する詳細なコンテキストを提供するため、パフォーマンスの問題を特定するための強力な手がかりとなります。ただし、フレームワークレベルの自動計装だけでは、こうした詳細な分析には限界があります。アプリケーション特有のビジネスロジックに関連する情報を取得するためには、カスタム計装が必要になります。デモアプリケーションでは、gRPCの計装に加えて、ビジネスロジックに関連するメタデータをスパンに付加することで、より詳細な分析が可能になっています。例えば、Product Catalog Serviceでは、GetProductメソッドのスパンにapp.product.id属性を追加しています。func (p *productCatalog) GetProduct(ctx context.Context, req *pb.GetProductRequest) (*pb.Product, error) {    span := trace.SpanFromContext(ctx)    span.SetAttributes(attribute.String(\"app.product.id\", req.Id))    // ...}opentelemetry.ioこれにより、特定の商品IDに関連するエラーを検出し、トラブルシューティングを効率化できます。こうしたカスタム属性は、ドメイン知識に基づいて開発者自身が定義する必要がありますが、それだけの価値は十分にあるでしょう。デモアプリケーションでは、OpenTelemetry Collectorを活用したオブザーバビリティパイプラインも実装されています。各サービスからCollectorにデータをプッシュすることで、アプリケーションレベルでの処理オーバーヘッドを最小限に抑えつつ、フィルタリングやバッチ処理、メトリックビューの作成などを柔軟に行うことができます。この手法には、いくつかの利点があります。まず、テレメトリデータをアプリケーションから可能な限り早く送信することで、予期せぬ負荷による影響を最小限に抑えられます。また、Collectorでデータの処理を集中化することで、ネットワークのトラフィックを削減し、バックエンドへの負荷を分散させることができます。ただし、あまりにも大量のテレメトリを生成すると、ローカルネットワークを圧迫し、別の層でパフォーマンスの問題を引き起こす可能性もあります。状況に応じて適切なバランスを見極める必要があるでしょう。最後に、OpenTelemetryがもたらす新しい可観測性モデルについて議論されています。従来の「Three Pillars」モデルとは異なり、OpenTelemetryはトレース、メトリクス、ログ、リソースを単一のデータモデルに統合します。これにより、高度に相関性のある均一で高品質なデータが得られるようになります。Figure 4-12. The new model of observability tools より引用OpenTelemetryは、あらゆるソースからのテレメトリを統合し、OTLPを介して(少なくとも)1つのデータストアに送信するための普遍的な基盤となります。これにより、ビジネスにとっての価値や実現したいユースケースに基づいて、テレメトリストリームを柔軟に処理・送信できるようになります。将来の可観測性プラットフォームでは、ユニバーサルクエリAPI、自然言語検索、AIアシスタントとの統合、データポータビリティに基づく柔軟なツール選択などの機能が提供されるでしょう。OpenTelemetryは、そうした未来の高コンテキストなデータと、それを理解するためのツールを実現するための重要な構成要素なのです。実際、OpenTelemetryの登場以降、新しい可観測性ツールが続々と登場しています。これらのツールの多くは、OpenTelemetryを唯一の計装手段として採用しており、オープンソースのカラムストアをベースに構築されています。こうしたツールは、OpenTelemetryが提供する高コンテキストなテレメトリデータを効果的に活用するのに適しています。さらに、MicrosoftやAmazon Web Servicesなどの大手クラウドプロバイダーもOpenTelemetryを積極的にサポートし始めています。MicrosoftはAzure Monitorの一部としてOpenTelemetryをサポートし、AWSはEKSアプリケーション用のOpenTelemetryベースのAPMエクスペリエンスを発表しました。OpenSearchやClickHouseなどのオープンソースツールも、OpenTelemetryデータのストレージとして人気が高まっています。こうした動きは、OpenTelemetryが業界標準になりつつあることを示しています。本章を通じて、OpenTelemetryのアーキテクチャと、実際のアプリケーションにおける活用方法について深く理解することができました。アプリケーションとインフラストラクチャの両方から収集されたテレメトリを統合し、パイプラインを通じて効率的に処理・送信するためのコンポーネントの役割が明確になりました。OpenTelemetryは、分散システムの可観測性を実現するための包括的なソリューションであり、その設計思想は非常に合理的で説得力があります。また、デモアプリケーションを通じて、自動計装とカスタム計装を組み合わせることで、アプリケーションのパフォーマンス管理やトラブルシューティングをどのように強化できるかを実践的に学ぶことができました。OpenTelemetryのスパンメトリクスや、セマンティックに豊富なテレメトリデータは、複雑な分散システムの動作を理解するための強力な武器となります。OpenTelemetryによる可観測性データの統一性と相関性特に印象的だったのは、OpenTelemetryがもたらす可観測性データの統一性と相関性です。従来のように、メトリクス、ログ、トレースが別々のシステムで管理されていては、システム全体の動作を俯瞰的に理解することは困難です。OpenTelemetryは、これらのデータを単一のモデルに統合することで、より深い洞察を可能にします。データ間のつながりが明確になれば、パフォーマンスの問題の根本原因を特定したり、異常を早期に検知したりすることが容易になるでしょう。そして何より、OpenTelemetryが可観測性の新しいモデルを切り拓いていることを実感しました。従来の縦割りのアプローチを脱却し、テレメトリデータの相関性と統一性を追求することで、より深い洞察が得られるようになるでしょう。それは、我々ソフトウェアエンジニアやSREにとって、システムの理解とデバッグを飛躍的に向上させてくれるはずです。本章で得られた知見を基に、次章以降ではOpenTelemetryのより具体的な活用方法について学んでいきます。アプリケーション、ライブラリ、インフラストラクチャへの計装、テレメトリパイプラインの設計、組織へのオブザーバビリティの展開など、実践的なアドバイスが満載です。OpenTelemetryの導入に向けてOpenTelemetryを導入する際のチェックリストが本章で提供されています。このチェックリストには、主要なライブラリの計装状況、SDKへのプロバイダの登録、エクスポーターの設定、伝播形式の選択、SDKとCollector間のデータ送信、Collectorと分析ツール間のデータ送信、リソース属性の設定、トレースの完全性と連続性など、多岐にわたる項目が含まれています。ただし、チェックリストをなぞるだけでは不十分です。自分たちのシステムの特性をよく理解し、OpenTelemetryをどう活用すべきかを見極める必要があります。例えば、サービスの規模や複雑性、パフォーマンス要件、障害時の影響度などを考慮し、適切なサンプリングレートや収集するテレメトリデータの種類を決定する必要があります。また、既存の監視システムとの連携方法や、運用プロセスへの組み込み方なども検討しなければなりません。可観測性の未来を切り拓くOpenTelemetry。その真価を見極め、自身の開発・運用プラクティスに活かしていくことが、これからのエンジニアリングに求められているのだと感じました。分散システムの複雑さが増す中で、我々ソフトウェアエンジニアに求められるスキルセットも変化しています。もはや、個々のサービスを深く理解するだけでは不十分です。システム全体を俯瞰し、サービス間の相互作用を追跡し、データの流れを把握する。そうした能力が、これからのソフトウェアエンジニアには必要不可欠になるでしょう。Chapter 5. Instrumenting Applications本章を読んで、OpenTelemetryを実際のアプリケーションに導入する際の具体的な手順と考慮点について理解を深めることができました。冒頭の \"It is easier to write an incorrect program than understand a correct one.:正しいプログラムを理解するよりも、間違ったプログラムを書く方が簡単です。\" 。アプリケーションの動作を正確に理解することの難しさを表していると同時に、OpenTelemetryによる可観測性の重要性を示唆しているように感じました。OpenTelemetryのセットアッププロセス本章では、まずOpenTelemetryのセットアッププロセスが2つのステップ、つまりSDKのインストールと計装(Instrumentation)で構成されることが説明されています。SDKは、テレメトリの処理とエクスポートを担当するOpenTelemetryクライアントであり、一方、計装は、OpenTelemetry APIを使ってテレメトリを生成するためのコードを指します。計装の自動化については、言語ごとに異なるアプローチが取られています。エージェントを使った完全な自動化を提供する言語もあれば、まったく自動化をサポートしない言語もあります。自動計装は、セットアッププロセスを大幅に簡略化できる一方で、カスタマイズの柔軟性は犠牲になるというトレードオフがあることを理解しておく必要があります。自動計装に関しては逆井さんの計測の手間を省きたい！OpenTelemetry に見る”自動計装”のイマがめちゃくちゃに良い資料なので読んでほしいです。 speakerdeck.comSDKのインストールでは、OpenTelemetry APIにプロバイダを登録することが重要です。プロバイダは、TracerProvider、MeterProvider、LoggerProviderの3つに分かれており、それぞれがトレース、メトリクス、ログの機能を実装しています。Figure 5-1. The TracerProvider framework より引用TracerProviderは、サンプラー、SpanProcessor、エクスポーターから構成されます。サンプラーは、トレースをサンプリングするためのアルゴリズムを提供し、SpanProcessorは、スパンの加工や送信を制御します。エクスポーターは、テレメトリデータをバックエンドに送信する際のフォーマットと宛先を定義します。Figure 5-2. The MeterProvider framework より引用MeterProviderは、ビュー、MetricReader、MetricProducer、MetricExporterから構成されます。ビューは、メトリックのカスタマイズを可能にし、MetricReaderは、メトリックデータの収集とバッファリングを行います。MetricProducerは、サードパーティの計装とのブリッジとして機能し、MetricExporterは、メトリックデータをバックエンドに送信します。Figure 5-3. The LoggerProvider framework より引用LoggerProviderは、LogRecordProcessorとLogRecordExporterから構成されます。これらは、ログデータの処理と送信を担当します。プロバイダの設定では、プロトコル、エンドポイント、ヘッダー、圧縮、タイムアウトなどの詳細な設定が可能です。特に、OTLPエクスポーターの設定は重要で、ローカルのCollectorにデータを送信する場合は、パフォーマンスを考慮して scheduledDelayMillis を小さな値に設定することが推奨されています。また、アプリケーションのシャットダウン時には、SDKのフラッシュ処理が欠かせません。これにより、バッファリングされたテレメトリデータが確実にエクスポートされ、データの欠落を防ぐことができます。カスタムプロバイダの実装についても言及されていますが、これは非常にまれなケースです。OpenTelemetryのAPIとSDKを分離することで、特殊な要件に対応できる柔軟性を確保しているのです。OpenTelemetryの設定のベストプラクティス本章では、設定のベストプラクティスについても詳しく説明されています。設定方法には、コード内での直接指定、環境変数の使用、YAMLファイルの利用の3つがあります。環境変数を使用することで、デプロイ時に設定を切り替えられるため、開発、テスト、本番環境に応じた柔軟な設定が可能になります。最近では、YAMLファイルによる設定が推奨されるようになっており、環境変数よりも簡潔で検証しやすいという利点があります。リモート設定の分野では、OpAMP(Open Agent Management Protocol)の開発が進められています。これにより、Collectorや SDKの動的な設定変更が可能になり、再起動やデプロイを必要とせずに設定を最適化できるようになるでしょう。github.comリソース属性の設定も重要なトピックの1つです。リソースは、テレメトリが収集される環境を定義する属性のセットで、サービス、仮想マシン、プラットフォーム、リージョン、クラウドプロバイダーなど、問題の特定に必要なコンテキスト情報を提供します。リソース属性の多くは、resource detectorと呼ばれるプラグインを使って自動的に収集できます。Kubernetes、AWS、GCP、Azureなど、一般的な環境の情報は、ほとんどの場合、resource detectorでカバーされています。一方、service.name、service.namespace、service.instance.id、service.versionなど、アプリケーション固有のリソース属性は、手動で設定する必要があります。これらの属性は、アプリケーションの動作を理解し、問題の切り分けを行ううえで欠かせない情報となります。OpenTelemetryの計装のベストプラクティス計装の設定では、OSSライブラリの自動計装が鍵となります。フレームワークやデータベースクライアントなど、一般的なライブラリの多くは、OpenTelemetryの計装を提供しているため、これらを活用することで、アプリケーションコードへの変更を最小限に抑えつつ、豊富なテレメトリデータを収集できます。一方、ビジネスロジックに特化した情報を取得するためには、手動での計装が必要になるでしょう。手動の計装を行う際は、新しいスパンを追加するのではなく、既存のスパンにアプリケーション固有の属性を付与することが推奨されています。これにより、スパンの数を抑えつつ、より意味のある情報を取得することができます。また、計装の粒度を適切に設定することが重要です。関数ごとにスパンを作成したり、コードの行ごとにログを出力したりすることは、必ずしも適切とは言えません。OpenTelemetryを導入する際は、まずは自動計装で提供されるテレメトリから始め、必要に応じて段階的に計装を追加していくのが賢明だと著者は述べています。ヒストグラムメトリックの活用も推奨されています。特に、指数関数バケットヒストグラム(Exponential Bucket Histogram)は、スケールと範囲が異なる測定値を自動的に調整し、集計することができるため、サービスのパフォーマンス分析に非常に役立ちます。これにexemplarを組み合わせることで、統計情報とトレースの紐付けが可能になり、より詳細な分析が行えるようになります。opentelemetry.io特に、自動計装とカスタム計装のバランス、適切なサンプリングとエクスポーターの設定、リソース属性の付与、ヒストグラムメトリックの活用など、具体的な手法については、実践的な示唆に富んでいました。これらを参考に、自社のアプリケーションにおけるOpenTelemetryの設定を最適化していきたいと思います。OpenTelemetryの導入に向けた考察また、OpAMPに代表されるリモート設定の動向にも注目したいと考えています。動的な設定変更は、運用の柔軟性を高め、コストの最適化にもつながる重要な技術だと感じました。opentelemetry.io一方で、OpenTelemetryの導入にはある程度の学習コストが伴うことも事実です。特に、大規模な分散システムでは、多数のサービスに対して計装を行う必要があり、複数の開発チームが関わることもあるでしょう。そのため、1つのアプリケーションでの導入が成功した後は、セットアップ手順やベストプラクティスをパッケージ化し、社内で共有することが重要だと感じました。OpenTelemetryへの移行は、一時的なコストを伴うかもしれません。しかし、一度移行が完了すれば、ベンダーロックインから解放され、あらゆる可観測システムと連携できるようになります。長期的な視点に立てば、OpenTelemetryは明らかに投資に値するテクノロジーだと言えるでしょう。個人的には、2年前に調査した時に比べてOpenTelemetryの自動計装機能の充実ぶりに感銘を受けました。フレームワークやライブラリレベルでの計装が進むことで、アプリケーション開発者の負担が大幅に軽減されるでしょう。今後は、社内の共通ライブラリへのOpenTelemetry組み込みも検討していきたいと考えています。また、リソース属性の重要性も再認識させられました。特に、service.nameやservice.versionなどの属性は、問題の切り分けに欠かせない情報です。これらの属性を確実に設定することで、障害対応の効率化が期待できます。ヒストグラムメトリックとexemplarの組み合わせも、非常に興味深い手法だと感じました。レイテンシの分布と、各バケットに対応するトレースを関連付けられることで、パフォーマンスの問題を細かく分析できるようになります。OpenTelemetryは、アプリケーションの可観測性を飛躍的に向上させる技術であり、SREにとって必須のスキルセットになりつつあります。本章で得た知識を活かし、自社のアプリケーションにOpenTelemetryを適切に導入することで、より堅牢で可観測性の高いシステムを構築していきたいと思います。可観測性の向上は、単なる技術的な問題ではなく、ビジネスの成功に直結する重要な課題です。OpenTelemetryを活用することで、システムの動作を正確に把握し、パフォーマンスの問題や障害の兆候を早期に検出できるようになります。そのような高度な可観測性を実現することが、私たちSREに課せられた使命だと感じています。本章で学んだ知識を基盤に、次章ではOpenTelemetryのライブラリへの組み込み方法が説明されるようです。アプリケーションと合わせて、ライブラリレベルでの計装を進めることで、より網羅的で詳細な可観測が可能になるでしょう。引き続き、OpenTelemetryの実践的な活用方法を学んでいきたいと思います。Chapter 6. Instrumenting Libraries本章 を読んで、ライブラリへのOpenTelemetryの組み込みが、可観測性の向上に果たす重要な役割について理解を深めることができました。冒頭の \"The price of reliability is the pursuit of the utmost simplicity. It is a price which the very rich find most hard to pay.\" という言葉が印象的でした。信頼性を追求するには、究極のシンプルさが必要であり、それは多くの人にとって難しいことだというメッセージが込められています。ライブラリの設計においても、可観測性を考慮に入れることで、シンプルさと信頼性の両立を目指すことができるのだと感じました。ライブラリの重要性と可観測性の意義本章では、まずライブラリの重要性について説明されています。ほとんどのアプリケーションでは、リソースの大部分がライブラリ内で消費されていることが指摘されています。アプリケーションコード自体はリソースをほとんど消費せず、代わりにライブラリコードにリソースの利用を指示します。したがって、本番環境での問題を調査する際には、ライブラリの利用パターンに着目することが重要になります。Figure 6-1. Serial database calls (top) that could be replaced by parallel calls (bottom) to significantly reduce latency より引用上図は、データベースへのシリアルなコールをパラレルなコールに置き換えることで、レイテンシを大幅に削減できる例を示しています。このように、ライブラリの利用方法を最適化することが、アプリケーションのパフォーマンス向上に直結することがわかります。それでは、なぜライブラリの開発者自身が計装を行うべきなのでしょうか。著者は、これをネイティブ計装(Native Instrumentation)と呼び、サードパーティによる従来の計装方法よりも優れていると主張しています。ネイティブ計装には、いくつかの利点があります。まず、ユーザーがOpenTelemetryを導入した瞬間から、すべてのライブラリで自動的に可観測性が有効になることです。これにより、可観測性システムのセットアップにおける障壁が大幅に下がります。また、ネイティブ計装によって、ライブラリの開発者はユーザーとのコミュニケーションを促進できます。テレメトリデータを通じて、ライブラリの構造や動作を説明したり、ユーザーに警告やアドバイスを提供したりすることが可能になります。ドキュメントやプレイブック、ダッシュボードやアラートなどを充実させることで、ユーザーはライブラリをより効果的に利用できるようになるでしょう。さらに、ネイティブ計装は、ライブラリの開発者がパフォーマンスを重視していることを示す強力なシグナルにもなります。可観測性をテストの一環として捉え、開発プロセスに組み込むことで、ライブラリの品質向上が期待できます。OpenTelemetryによるライブラリ計装の課題解決一方で、これまでライブラリの計装があまり進んでこなかった理由として、コンポジションの問題とトレーシングの課題が挙げられています。Figure 6-2. There is no right answer when different applications use different observability systems より引用上図のように、アプリケーションごとに異なる可観測性システムが使われている状況では、ライブラリの開発者にとって適切な選択肢がないことがわかります。特にトレーシングは、ライブラリ間でコンテキストを伝播させる必要があるため、すべてのライブラリが同じトレーシングシステムを使用しなければ機能しません。こうした課題を解決するために、OpenTelemetryはライブラリの計装をサポートするための様々な工夫を取り入れています。まず、OpenTelemetryは計装用のAPIと実装を分離しています。これにより、ライブラリの開発者はAPIを使って計装を行い、アプリケーションの開発者はSDKを設定するという、役割の明確化が図られます。またAPIは最小限の依存関係しか持たないため、依存関係の競合を避けることができます。次に、OpenTelemetryのAPIは下位互換性を維持しています。APIのメジャーバージョンが頻繁に更新されると、ライブラリ間の互換性が失われてしまいます。そこでOpenTelemetryでは、安定版のAPIをv1.0としてリリースし、v2.0を出す予定はないとしています。これにより、既存の計装が将来にわたって機能することが保証されます。さらに、OpenTelemetryの計装はデフォルトでオフになっていることも重要なポイントです。 Figure 6-4. Non-native instrumentation requires a lot of configuration より引用Figure 6-5. All native instrumentation is automatically enabled as soon as the SDK is installed より引用上図を比較すると、ネイティブ計装ではSDKを登録するだけですべてのライブラリから自動的にテレメトリを受信できるのに対し、非ネイティブな計装では各ライブラリに対して個別の設定が必要になることがわかります。これは、ユーザーにとって大きな負担となります。ライブラリ計装のベストプラクティスと今後の展望本章の後半では、ライブラリの計装における具体的なベストプラクティスが紹介されています。ライブラリの開発者は、以下のようなチェックリストに沿って計装を行うことが推奨されます。OpenTelemetryをデフォルトで有効にするAPIをラップしない既存のセマンティック規約を使用する必要に応じて新しいセマンティック規約を作成するAPIパッケージのみをインポートするライブラリをメジャーバージョン番号にピン留めする包括的なドキュメントを提供するパフォーマンステストを実施し、結果を共有するまた、データベースやプロキシ、メッセージングシステムなどの共有サービスについては、以下の点にも留意すべきだとしています。OpenTelemetryの設定ファイルを使用するデフォルトでOTLPを出力するローカルのCollectorをバンドルする本章で紹介されたベストプラクティスは非常に参考になりました。特に、ネイティブ計装の重要性と、それを実現するためのOpenTelemetryの設計思想は、深く理解しておくべき点だと感じました。自社で開発しているライブラリにOpenTelemetryを組み込むことで、アプリケーションの可観測性を飛躍的に高められるはずです。その際は、本章のチェックリストを活用し、ユーザーにとって使いやすく、パフォーマンスに優れた計装を心がけたいと思います。また、オープンソースのライブラリについても、積極的にコントリビューションしていきたいと考えています。ライブラリのメンテナーと協力し、ネイティブ計装の普及に貢献できればと思います。さらに、共有サービスについても、OpenTelemetryを活用した可観測性の向上が期待できます。特に、Kubernetesなどのコンテナプラットフォームとの連携は、運用の効率化に大きく寄与するでしょう。本章を通じて、改めてライブラリの重要性と、その計装の難しさについて認識を新たにしました。というか言うは易く行うは難しだなって思いました。OpenTelemetryは、これまで困難だったライブラリの可観測性を、エレガントかつ実践的な方法で実現するためのプロジェクトだと言えます。著者が理想として掲げている、\"In five years, we’d like developers to be thinking of runtime observability as being just as important as testing.:5年後にはテストと同じぐらい実行時の可観測性が重要だと開発者が考えるようになる\"という未来。その実現に向けて、私もOpenTelemetryコミュニティに参加し、微力ながら貢献していきたいと思います。Chapter 7. Observing Infrastructure本章を読んで、クラウドネイティブな環境におけるインフラストラクチャの可観測性の重要性と、OpenTelemetryを活用した具体的な手法について理解を深めることができました。冒頭の \"We build our computer systems the way we build our cities: over time, without a plan, on top of ruins.\" という言葉が印象的でした。複雑化するソフトウェアシステムは、計画性のない都市の発展と同じように、ruins(廃墟)の上に継ぎ接ぎで構築されているという比喩は的を射ていると感じました。インフラストラクチャの可観測性は、そのような複雑なシステムを理解し、制御するための重要な手段だと改めて認識させられました。本章では、まずインフラストラクチャ可観測性の定義と意義について説明されています。インフラストラクチャの可観測性とは、単なるリソース使用率のモニタリングではなく、アプリケーションのテレメトリデータとインフラストラクチャのメトリクスを関連付けることで、システム全体の動作を把握する取り組みだと言えます。著者は、インフラストラクチャのシグナルを収集する際の2つの重要な問いを提示しています。アプリケーションのシグナルとインフラストラクチャのシグナルの間にコンテキストを確立できるか?これらのシステムを可観測性を通じて理解することが、特定のビジネス/技術的な目標の達成に役立つか?この2つの問いに対する答えがNoである場合、そのシグナルを可観測性フレームワークに組み込む必要はないと指摘しています。可観測性に組み込むべきシグナルを見極めることが、効果的なインフラストラクチャ可観測性戦略の鍵となるのです。クラウドプロバイダーのテレメトリデータの収集と活用続いて、クラウドプロバイダーからのテレメトリデータの収集方法について詳しく解説されています。クラウドプロバイダーは、膨大な量のメトリクスとログを提供しますが、そのすべてが可観測性に有用とは限りません。著者は、クラウドテレメトリを \"iceberg\" に例えています。Figure 7-1. The cloud telemetry iceberg より引用OpenTelemetryはこれらのシグナルをすべて収集することができますが、全体的なモニタリングの姿勢にどのように適合するかを考える必要があります。例えば、単一のインスタンスの稼働状況は、分散システムの全体像を把握する上では限定的な意味しか持ちません。しかし、そのイベントをAPI Gatewayのルーティングの問題と関連付けることができれば、ユーザーリクエストのパフォーマンス低下の診断に役立つでしょう。個々のシグナルが単独では価値がなくても、全体的な可観測性戦略の一部として捉えることが重要なのです。クラウドメトリクスとログの収集には、主にOpenTelemetry Collectorが使用されます。著者は、本番環境へのデプロイメントにあたって、Collector Builderを使ってカスタムビルドを生成することを推奨しています。これにより、必要なレシーバー、エクスポーター、プロセッサーのみを組み込んだ最適化されたCollectorを構築できます。また、属性の設定では、パイプラインの早い段階で \"too many\" の側に寄せることが推奨されています。必要のないデータを後から捨てる方が、存在しないデータを追加するよりも簡単だからです。ただし、新しいdimensionを追加すると、メトリックデータベースが保存する時系列の数が劇的に増加する cardinality explosion を引き起こす可能性があるため、後段でメトリックをallow-listingすることで制御する必要があります。Collectorのデプロイメントアーキテクチャとしては、複数のアグリゲーターやテクノロジーからのテレメトリを統合する \"gateway\" 方式が紹介されています。Figure 7-2. A “gateway” deployment of the Collector monitoring a Kubernetes node, where Prometheus and FluentD scrape metrics and logs and then send them to external Collectors that process any signal より引用さらに発展させたアーキテクチャでは、各コンポーネントが独立したCollectorを持ち、シグナルタイプごとに水平にスケールできるようになっています。Figure 7-3. A “gateway” deployment of the Collector, much like Figure 7-2, but instead of all telemetry being sent to the same pool of collectors, different signal types are emitted to specialized pools of collectors より引用また、Collectorのパフォーマンスをモニタリングする Metamonitoring の重要性についても言及されています。Collectorが公開するメトリクスを監視することで、リミッターによるデータの拒否やキューの容量不足を検知し、スケールアップの判断に活用できます。Kubernetesプラットフォームにおける可観測性次に、Kubernetesプラットフォームにおける可観測性について解説されています。OpenTelemetryは、Kubernetesクラスタ上で稼働するアプリケーションのモニタリングとプロファイリングのためのツール、およびKubernetesコンポーネント自体のテレメトリデータを扱うための手段を提供しています。Kubernetesのテレメトリデータを収集するには、OpenTelemetry Operatorが重要な役割を果たします。OperatorのTarget Allocator (TA)機能を使うことで、クラスタ内のPrometheusエンドポイントを自動検出し、複数のcollector間でスクレープジョブを均等に分散させることができます。または、k8sclusterreceiver、k8seventsreceiver、k8sobjectsreceiver、kubeletstatsreceiverなどのレシーバーを使って、クラスターのメトリクスとログを直接収集することもできます。一方、Kubernetes上で稼働するアプリケーションに対しては、Operatorが提供するカスタムリソースを使って、自動計装パッケージをPodにインジェクトすることができます。これにより、既存のアプリケーションコードにトレース、メトリクス、ログの計装を追加できるようになります。本番環境へのデプロイメントでは、以下のようなアドバイスが示されています。各PodにサイドカーCollectorを配置し、テレメトリの最初の停止点とするシグナルタイプごとにCollectorを分割し、独立してスケールできるようにするテレメトリの作成と設定の関心を明確に分離する(例: リダクションやサンプリングはプロセスではなくCollectorで行う)Kubernetesの次は、サーバーレスプラットフォームの可観測性について説明されています。AWS LambdaやAzure Cloud Functionsなどのサーバーレスプラットフォームは、その利便性と独自の構造から人気を博していますが、一方で可観測性の課題も持ち合わせています。サーバーレスプラットフォームの可観測性サーバーレスの可観測性では、標準的なアプリケーションテレメトリに加えて、呼び出し時間、リソース使用量、コールドスタート時間などに注目する必要があります。これらのメトリクスは、サーバーレスプロバイダーから提供されるはずですが、アプリケーションテレメトリ自体をどのように取得するかは課題となります。OpenTelemetry Lambda Layerなどのツールを使うことで、AWS Lambdaの呼び出しからトレースとメトリクスを効率的にキャプチャできます。ただし、関数がアプリケーションアーキテクチャの中でどのような役割を果たしているかによって、サーバーレスインフラストラクチャを監視するための戦略は異なります。Lambda呼び出しを直接トレースするのをスキップし、属性やSpanイベントを介してLambdaを呼び出し元のサービスにリンクするだけで十分な場合もあるでしょう。その場合、Lambdaのサービスログを使って、障害やパフォーマンスの異常に関する特定の実行を特定し、詳細を取得することができます。非同期ワークフローの可観測性最後に、キュー、サービスバス、その他の非同期ワークフローの可観測性について議論されています。Apache Kafkaのようなイベントやキューベースのプラットフォームを活用するモダンなアプリケーションでは、可観測性にいくつかの興味深い課題が生じます。トランザクションのトレースは、\"traditional\" なリクエスト/レスポンスアーキテクチャほど有用ではない場合があります。トランザクションがいつ終了するのかを特定するのが難しいためです。そのため、可観測性の目標、最適化したいこと、最適化できることについて、多くの決定を下す必要があります。著者は、銀行ローンの例を挙げて、ビジネスフローと技術フローの違いを説明しています。Figure 7-4. The business flow of a bank transaction (top) versus its technical flow (bottom) より引用ビジネスフローは比較的シンプルですが、技術フローはパーミュテーションとギャップを考慮する必要があります。ワークフロー図が木というよりも「木の木」のように見える場合は、非同期ワークフローである可能性が高いと指摘しています。このような状況では、高度に非同期なワークフローを1つのトレースとして考えるのではなく、多くのサブトレースとして捉え、カスタムの相関IDやSpanリンクを介してオリジンにリンクすることが推奨されます。例えば、最初のトレースを「プライマリ」トレースと見なし、各トレースの終端Spanを次のルートSpanにリンクさせる方法があります。ただし、非同期トランザクションのすべてのサブトレースが同等に有用なわけではありません。Collectorのフィルタとサンプラーを慎重に使用することで、特定のサブトレースをフィルタリングし、カウントやヒストグラムに変換することができます。これにより、ルートSpanを保持しつつ、関連する作業について正確なカウントとレイテンシーを維持することが可能になります。本章を通じて、インフラストラクチャ可観測性の戦略が、全体的な可観測性の目標に沿って明確かつ簡潔に定義されるべきであることを学びました。アプリケーションやサービスの可観測性とは異なり、仮想マシン、マネージドデータベース、サーバーレステクノロジーを使用したイベント駆動アーキテクチャには、一般的なアプリケーション計装戦略がそのまま適用できるとは限りません。著者が強調しているのは、インフラストラクチャ可観測性の戦略は、システムが生成する可観測性データを使用するための組織的なインセンティブに沿って、全体的な可観測性の目標に基づいて策定されるべきだということです。この点を理解することが、重要なシグナルに焦点を当て、チームが実際に活用できるデータを収集するための鍵となるのです。個人的には、本章で紹介されたOpenTelemetryの各プラットフォームへの統合方法が非常に参考になりました。特に、Kubernetesにおける自動計装の仕組みや、サーバーレスプラットフォームでのLambda Layerの活用法は、実務で即座に役立てられる知見だと感じました。また、非同期ワークフローの可観測性の難しさについても共感を覚えました。ビジネスフローと技術フローのギャップを埋めるために、どのようなテレメトリ設計が求められるのか。著者の提示したアプローチは、非常に示唆に富んでいると思います。本章で得られた知見を活かし、自社のインフラストラクチャ可観測性を見直していきたいと考えています。特に、クラウドプロバイダーから収集するシグナルの取捨選択や、Kubernetes環境におけるOpenTelemetryの活用、サーバーレスアーキテクチャのための計装戦略などは、優先的に取り組むべき課題だと感じました。また、非同期ワークフローの可視化についても、著者の提案を参考にしながら、自社の状況に合った手法を探っていきたいと思います。ビジネス要件とシステムアーキテクチャのギャップを可観測性の力で埋めることができれば、より俊敏で信頼性の高いサービス提供が可能になるはずです。本章のエッセンスは、インフラストラクチャ可観測性の真の目的を見失わないことだと感じました。テレメトリデータの収集や統合は手段であって目的ではありません。あくまでも、ビジネス価値の創出と、エンジニアリング課題の解決に資するものでなくてはならないのです。そのためには、可観測性戦略を練る前に、自組織の目指すゴールを明確にしておく必要があります。そして、そのゴール達成のために、どのようなシグナルが必要で、どのように活用するのかを設計しなければなりません。本章で紹介された数々の手法は、そのための強力な武器になってくれるでしょう。読者諸兄には、ぜひ自組織のインフラストラクチャ可観測性の現状を振り返っていただきたいと思います。収集しているテレメトリデータは、本当にビジネスや技術の意思決定に活用できているでしょうか? OpenTelemetryを導入・活用することで、より効果的で統一的な可観測性を手に入れられるかもしれません。クラウドネイティブ時代のインフラストラクチャ可観測性。それは、複雑さと不確実性に立ち向かうための羅針盤であり、イノベーションを加速させるためのエンジンです。本章で得られた知見を最大限に活用し、自組織の可観測性ジャーニーを着実に前進させていきましょう。Chapter 8. Designing Telemetry Pipelines本章を読んで、テレメトリパイプラインの設計と運用が、可観測性の実現に果たす重要な役割について理解を深めることができました。冒頭の \"I have always found that plans are useless, but planning is indispensable.\" という言葉が印象的でした。計画そのものは役に立たないかもしれないが、計画を立てること自体は不可欠だというメッセージには深く共感しました。テレメトリパイプラインの設計においても、綿密な計画と柔軟な対応の両立が求められるのだと感じました。テレメトリパイプラインのトポロジーとCollectorの役割本章では、まずテレメトリパイプラインのトポロジーについて解説されています。システムが小規模な場合は、Collectorを使わずにSDKから直接バックエンドにデータを送信するのが最もシンプルな方法です。Figure 8-1. Applications send telemetry directly to the analysis tool being used より引用しかし、ホストメトリクスの収集やデータの一時的なバッファリングが必要になると、アプリケーションと同じマシン上でCollectorを実行するローカルCollectorの構成が推奨されます。Figure 8-2. Applications send telemetry to a local Collector, which also collects host metrics より引用さらに、大規模なシステムでは、ロードバランサーを使ってトラフィックを分散するCollectorプールを導入することで、バックプレッシャーへの対応や、リソース消費の最適化が可能になります。Figure 8-3. Local Collectors for every application send telemetry to a Collector pool for additional processing and buffering より引用さらに、ゲートウェイとワークロード固有のCollectorプールを組み合わせることで、より複雑なパイプラインを構築できます。Figure 8-4. A pipeline consisting of an egress gateway and several workload-specific Collector pools より引用このような特殊なCollectorプールを作成する理由としては、バイナリサイズの縮小、リソース消費の削減、テールベースのサンプリング、バックエンド固有のワークロード、送信コストの削減などが挙げられています。パイプラインオペレーションの重要性次に、パイプラインオペレーションについて解説されています。フィルタリングとサンプリングは、不要なデータを削除し、データ量を削減するための重要な手段です。フィルタリングは特定のタイプのデータを完全に削除するプロセスであり、サンプリングは統計的に代表的なデータのサブセットを識別し、残りを削除するプロセスです。ただし、著者は、サンプリングは危険であり、慎重に行う必要があると警告しています。サンプリング手法とその設定は、データの量と分析の種類に大きく依存するため、普遍的な答えは存在しません。著者は、自社の分析ツールのベンダーやOSSプロジェクトと相談することなく、サンプリングを実装しないことを強く推奨しています。変換、スクラビング、バージョニングについても詳しく説明されています。属性の変更、機密情報の難読化、セマンティック規約の統一、シグナル間の変換など、テレメトリデータを加工するための様々な手法が紹介されています。特に、OpenTelemetry Transformation Language (OTTL)を使った変換ルールの定義は、柔軟性と可読性に優れていると感じました。github.comまた、プライバシーと地域規制への対応の重要性も指摘されています。テレメトリデータにはPIIが含まれる可能性があるため、データのスクラビングとルーティングを適切に行う必要があります。バッファリングとバックプレッシャーについては、データ損失を避けるためにパイプラインに十分なリソースを確保することが重要だと述べられています。予期せぬトラフィックのスパイクや問題が発生した場合に備えて、データを一時的にメモリに保持するためのバッファリング容量を確保し、必要に応じてリソースを迅速にスケールできるようにしておく必要があります。最後に、データのエクスポートについて解説されています。テレメトリデータをどこにエクスポートするかは、組織のニーズに応じて決定する必要があります。デフォルトのオープンソースの可観測性スタックには、Prometheus、Jaeger、OpenSearch、Grafanaなどが含まれますが、OpenTelemetryをサポートする商用ツールも数多くあります。ルーティングプロセッサを使えば、テレメトリの属性に基づいてデータの送信先を動的に決定することもできます。例えば、有料ユーザーと無料ユーザーのトラフィックを別々のツールに送信するといった使い方が可能です。また、ジョブのステップ数の分布を測定するために、スパンをキューにルーティングしてヒストグラムを作成するといったクリエイティブな方法も提案されています。Collectorのセキュリティと運用本章では、CollectorのセキュリティとKubernetesにおける運用についても言及されています。Collectorは、他のソフトウェアと同様に、セキュリティを考慮して展開・維持する必要があります。具体的には、受信インターフェースのバインド先の制限、SSL/TLSによるデータの暗号化、認証・認可の設定などが推奨されています。opentelemetry.ioKubernetesについては、OpenTelemetry Kubernetes Operatorを使ってCollectorを管理する方法が紹介されています。DaemonSetやSidecarを使ってローカルCollectorを実行したり、DeploymentやStatefulSetを使ってCollectorプールを実行したりできます。また、Operatorを使って、アプリケーションに自動計装を注入し、設定することもできます。github.comテレメトリコストの管理最後に、テレメトリコストの管理について議論されています。テレメトリのコストを管理するための最も一般的なアドバイスは、「重要でないものをモニタリングしないこと」だと著者は述べています。誰も注目していないものを追跡し続ける価値はないのです。オブザーバビリティにはあなたが思っているよりもお金がかかるかもしれない。dev.henry.jpまた、コストと価値のトレードオフを考慮することも重要です。例えば、ユーザーIDなどのカスタムメトリクスは、カーディナリティが高くコストがかかる場合がありますが、特定のユーザーのエクスペリエンスを理解するためには必要不可欠な情報かもしれません。コスト管理の観点からは、データの解像度を最適化する方法を検討するのが良いアプローチだと著者は提案しています。ヒストグラムメトリクスから正確なカウントが得られる場合は、「速い」トレースの収集と保存を控えることで、コストを節約できる可能性があります。また、個々のログ行を大量に取り込むのではなく、収集時に重複を排除し、メトリクスや構造化されたログに変換するのも効果的です。本章を通じて、テレメトリパイプラインの設計と運用が、可観測性の実現において極めて重要な役割を果たすことを再認識しました。単にデータを収集するだけでなく、フィルタリング、サンプリング、変換、バッファリング、エクスポートなど、データを適切に処理し、管理することが求められます。特に、コスト管理とデータの価値のバランスを取ることの難しさについては、示唆に富む議論がなされていました。テレメトリのコストを最小限に抑えつつ、システムの問題を特定し、改善するために必要な情報を確保するには、慎重な判断が必要です。本章で得られた知見を活かし、自社のテレメトリパイプラインの設計と運用を見直していきたいと思います。特に、Collectorのトポロジーの選択、フィルタリングとサンプリングの適用、データ変換ルールの定義、コスト管理戦略の策定などは、優先的に取り組むべき課題だと感じました。テレメトリパイプラインは、単なるデータの通り道ではなく、可観測性の要となるコンポーネントです。その設計と運用に十分な時間と労力を投じることで、システムの動作をより深く理解し、問題の予防と解決に役立てることができるはずです。個人的には、OpenTelemetryの登場によって、テレメトリパイプラインの構築と管理がより容易になったと感じています。かつては、各種ツールやフォーマットの違いに悩まされていましたが、OpenTelemetryがデファクトスタンダードになりつつある今、よりシームレスなデータの統合と処理が可能になりました。一方で、OpenTelemetryの普及に伴い、テレメトリデータの量と種類が爆発的に増加しているのも事実です。その中で、本当に必要なシグナルを見極め、適切に処理していくことが、これまで以上に重要になってくるでしょう。本章で紹介されたベストプラクティスやピットフォールは、そのための指針になるはずです。フィルタリングやサンプリングを適切に行い、変換やエクスポートを戦略的に設計することで、コストと価値のバランスを取りながら、可観測性を最大限に引き出していきたいと思います。可観測性の実現は、単なる技術的な課題ではなく、ビジネスの成功に直結する重要なテーマです。テレメトリパイプラインの設計と運用を通じて、システムの動作を正確に把握し、問題の予兆を早期に検出し、素早く対処することができれば、より信頼性の高いサービスを提供できるようになるはずです。読者諸兄には、ぜひ自社のテレメトリパイプラインの現状を見直してみていただきたいと思います。OpenTelemetryを活用し、データの収集、処理、エクスポートを最適化することで、可観測性のレベルを引き上げられるのではないでしょうか。可観測性の未来を切り拓くOpenTelemetry。テレメトリパイプラインの設計と運用は、その実現に向けた重要な一歩です。本章で得られた知見を糧に、自社のシステムにおける可観測性の向上に取り組んでいきましょう。次章では、OpenTelemetryへの移行戦略について解説されるそうです。レガシーシステムからのスムーズな移行や、組織全体でのオブザーバビリティの文化の醸成など、大規模な導入に向けたヒントが得られるはずです。引き続き、OpenTelemetryの実践的な活用方法を学んでいきたいと思います。Chapter 9. Rolling Out Observability本章を読んで、可観測性の組織への展開における重要な考慮事項と戦略について理解を深めることができました。冒頭の \"Just because the standard provides a cliff in front of you, you are not necessarily required to jump off it.\" という言葉が印象的でした。標準が目の前に崖を提供しても、必ずしもそこから飛び降りる必要はないというメッセージには深く共感しました。可観測性の導入においても、標準的なアプローチに盲目的に従うのではなく、自組織の状況に合わせて柔軟に対応することが重要だと感じました。可観測性の真の価値本章では、可観測性の価値について次のように述べられています。可観測性の真の価値は、組織を変革し、ソフトウェアのパフォーマンスがビジネスの健全性にどのように変換されるかについての共通の言語と理解を提供する力にあります。可観測性は信頼や透明性と同じように、価値そのものなのです。可観測性とは、チーム、組織、ソフトウェアシステムを、その結果を解釈、分析、疑問視できるように構築することへのコミットメントなのだと著者は主張しています。この課題は、特定の個人やグループだけのものではありません。データを意思決定のインプットとして活用する方法について、組織全体でコミットメントを得る必要があります。そのために、本章では、OpenTelemetryを実装した組織やプロジェクトのいくつかのケーススタディが紹介され、成功への道筋が示されています。可観測性の展開における3つの軸についても詳しく説明されています。Deep(深さ)対Wide(広さ)Code(コード)対Collection(収集)Centralized(中央集権)対Decentralized(分散)これらの軸は、OpenTelemetryの実装を推進しているのは誰で、組織のどの部分に触れることができるのかという問いに関連しています。Deepアプローチの例として、GraphQLサービスを計装した大規模な金融サービス組織のケースが紹介されています。この組織では、GraphQLのトレースが他のシステムから分離されており、エラーの発生場所や下流への影響を可視化することが困難でした。OpenTelemetryのトレースファーストアプローチは、GraphQLの課題に対処するために非常に有効だったそうです。一方、Wideアプローチの例としては、既存のトレーシングソリューションからOpenTelemetryへの移行を行ったSaaS企業のケースが取り上げられています。この組織では、システムがKubernetes上で動作し、Goで書かれていたため、Wideな移行が容易な判断でした。ただし、移行時には、既存のアラートやダッシュボードが壊れないように注意深く比較する必要があったそうです。Deepな計装は、単一のチーム、サービス、フレームワークに重点を置いています。特に計装ライブラリが存在する場合は、素早く価値を提供できます。カスタムコード（プロパゲーターなど）を使用して、既存のソリューションに統合することもできます。Deepな計装は、大規模な組織や、より大きな可観測性プラクティスが整備されていない組織で始めるのに適しています。一方、Wideな計装は、できるだけ多くのサービスに計装を展開することに注力します。システムアーキテクチャによっては、事前の作業がより多く必要になる場合があります。一般的に、完全な移行、または並行して実行するための手段が必要です。Wideな計装は、全体的なシステムモデルの洞察を提供することで、長期的にはより多くの価値をもたらします。Code対Collectionの軸は、OpenTelemetryエコシステムのどの部分に注力すべきかという問いに関連しています。データの生成に注力するべきか、それとも収集と変換に注力するべきか。理想的には、コードとコレクターの両方を採用し、一方の使用と実装がもう一方を前進させるべきだと著者は述べています。Centralized対Decentralizedの軸は、組織の規模や形状に関係なく、可観測性の展開において考慮すべき重要な側面です。大規模な組織では、中央の可観測性チームがOpenTelemetryの採用を推進することが多いのに対し、小規模な組織では、個々のサービスチームが浸透によって採用を広めることが多いそうです。OpenTelemetryの展開における3つの格言著者は、OpenTelemetryの展開における3つの格言を示しています。Do no harm, break no alerts.(害を与えず、アラートを壊さない)Prioritize value.(価値を優先する)Don't forget the business.(ビジネスを忘れない)これらの格言は、可観測性の導入が技術的な課題であると同時に、ビジネス上の課題でもあることを示唆しています。OpenTelemetryの展開後の差別化次に、OpenTelemetryの導入後に、どのように差別化を図るかについて議論されています。テストとしての可観測性、グリーン可観測性、AI可観測性など、新たな可能性を探ることで、組織に優位性をもたらすことができると著者は主張しています。特に、テストとしての可観測性は興味深いアイデアだと感じました。トレースとメトリクスを使って、既知の良好な状態に対するシステムの動作を比較し、リグレッションを検出するというアプローチは、継続的デリバリーの品質ゲートとしても活用できそうです。最後に、大規模な組織でOpenTelemetryを展開するためのチェックリストが提供されています。経営陣が関与しているか?小さいが重要な最初のゴールを特定したか?最初のゴールを達成するために必要なことだけを実装しているか?早期の成功事例を見つけたか?可観測性を集中化したか?ナレッジベースを作成したか?新旧の可観測性システムを併存させられるか?これらのチェック項目は、OpenTelemetryの展開を成功に導くための重要な指針になるはずです。特に、早期の成功事例を見つけ、それを組織全体に広めていくことの重要性は、多くの組織で当てはまるのではないでしょうか。本章を通じて、可観測性の展開が、単なる技術的な課題ではなく、組織全体で取り組むべき変革の旅であることを再認識しました。OpenTelemetryは、その旅を支える強力な武器になるはずです。しかし、それを最大限に活用するには、自組織の状況を見極め、適切な戦略を選択することが求められます。Deep対Wide、Code対Collection、Centralized対Decentralizedという3つの軸は、その選択を導くための羅針盤になるでしょう。早期の価値の実現とビジネスへの貢献を意識しながら、段階的にOpenTelemetryを展開していくことが成功の鍵だと感じました。個人的には、テストとしての可観測性やAI可観測性など、OpenTelemetryの新たな可能性についても興味をかき立てられました。従来のモニタリングの枠を超えて、より高度な分析や自動化につなげていくことで、可観測性の真価を発揮できるはずです。本章のチェックリストを参考に、自社におけるOpenTelemetryの展開計画を見直してみたいと思います。特に、早期の成功事例の発掘と、組織全体への波及効果の創出には注力したいと考えています。可観測性は、ソフトウェアエンジニアリングの未来を切り拓く重要な鍵です。OpenTelemetryを活用し、自組織に適した展開戦略を練ることで、その扉を開くことができるはずです。読者諸兄も、ぜひ自組織における可観測性の現状を振り返り、OpenTelemetryによる変革の機会を探ってみてください。Deep対Wide、Code対Collection、Centralized対Decentralizedの3つの軸を意識しながら、自組織に適したアプローチを見出していくことが重要です。可観測性の実現は、単なる技術の導入ではなく、組織文化の変革でもあります。OpenTelemetryを起点に、データ駆動の意思決定を根付かせ、ソフトウェアのパフォーマンスとビジネスの成果を強く結びつけていく。そのような組織づくりに、本章の知見が活かされることを期待しています。皆さんの組織では、可観測性の展開においてどのような課題に直面していますか? Deep対Wide、Code対Collection、Centralized対Decentralizedという3つの軸で見たとき、どのようなアプローチが有効だと考えますか? ぜひ、自組織の状況を共有し、知見を交換し合えればと思います。本章のまとめと著者の主張本書のまとめとして、著者らは次のように述べています。OpenTelemetryは、可観測性に必要不可欠なテレメトリデータを標準化・合理化し、従来の「3本柱」の考え方から脱却して、相関性の高い豊かなテレメトリデータの束へと移行するための戦略的な選択肢になる、と。可観測性の実現を通じて、ソフトウェアとビジネスの成果をより強く結びつけていく。そのような取り組みをしてみるのも良いのではないでしょうか(言うは易く行うは難し)？おわりに本書『Learning Opentelemetry』を通して、現代のソフトウェアシステムにおける可観測性の重要性と、それを実現するためのOpenTelemetryの役割について深く学ぶことができました。従来の可観測性の課題であったデータの分断を解消し、トレース、メトリクス、ログなどの様々なテレメトリデータを統合的に扱えるOpenTelemetryは、まさに可観測性の分野における革命的な存在だと言えるでしょう。本書は、OpenTelemetryの設計思想から実践的な活用方法まで、体系的かつ平易に解説されており、可観測性に関する理解を深めるための良きガイドとなりました。本書を読み進める中で、私自身、以下のような気づきと学びを得ることができました。現代のソフトウェアシステムの複雑性に立ち向かうには、可観測性が欠かせない要素であること。OpenTelemetryは、データの相関性と統一性を追求することで、より深い洞察を可能にすること。アプリケーション、ライブラリ、インフラストラクチャの各層で適切な計装を行うことが重要であること。テレメトリパイプラインの設計と運用が、可観測性の実現において極めて重要な役割を果たすこと。可観測性の展開は、単なる技術の導入ではなく、組織文化の変革でもあること。以下は、文章の順番を変更し、自然な流れになるように書き換えた結果です。OpenTelemetryがもたらすデータの相関性と統一性は、従来の縦割りのアプローチからの脱却を意味します。トレース、メトリクス、ログが別々のシステムで管理されていては、システム全体の動作を俯瞰的に理解することは困難です。OpenTelemetryは、これらのデータを単一のモデルに統合することで、より深い洞察を可能にするのです。さらに、可観測性の実現は、単なる技術的な問題ではなく、ビジネスの成功に直結する重要なテーマだと言えます。OpenTelemetryを活用することで、システムの動作を正確に把握し、パフォーマンスの問題や障害の兆候を早期に検出し、素早く対処できるようになります。また、可観測性の展開が組織文化の変革でもあるという点も非常に重要です。可観測性の真の価値は、組織を変革し、ソフトウェアのパフォーマンスとビジネスの成果を強く結びつけることにあります。そのためには、データを意思決定のインプットとして活用する方法について、組織全体でコミットメントを得る必要があります。本書で得られた知見を活かし、自社における可観測性の向上に取り組んでいきたいと強く意識しています。具体的には、OpenTelemetryを導入し、アプリケーション、ライブラリ、インフラストラクチャの各層で適切な計装を行うこと、テレメトリパイプラインを設計し、データの収集、処理、エクスポートを最適化すること、そして何より、可観測性をデータ駆動の意思決定の基盤とし、ソフトウェアとビジネスの成果を強く結びつけていくことが重要だと考えています。これらは、これからのソフトウェアエンジニアリングに求められる重要な課題であり、そのような高度な可観測性を実現することが、私たちSREやソフトウェアエンジニアに課せられた使命だと感じています。そして、読者諸兄にも感謝を申し上げます。1つ1つの気づきや学びを積み重ねることが、私たち自身の成長につながるだけでなく、ひいては業界全体の発展にもつながるのだと信じています。引き続き、OpenTelemetryと可観測性について学び、実践し、議論を深めていければと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。参考資料OpenTelemetry 公式サイトOpenTelemetry | DocumentationDatadog’s $65M Bill and Why Developers Should CareDistributed Systems ObservabilityDesigning Distributed SystemsReport shows consumers won’t wait long for web pages to loadBurnout in software engineering: A systematic mapping studyObservability EngineeringIntroducing Domain-Oriented Microservice ArchitectureContextThe Four Golden SignalsGlossaryPropagators APITrace Context | W3C Recommendation OpenTelemetry Transformation LanguageSpecificationsEnd-User Q\u0026A Series: Using OTel at FarfetchWhy and How eBay Pivoted to OpenTelemetryOpen Agent Management ProtocolOpenTelemetry LambdaOpenTelemetry Protocol with Apache ArrowCertain specialized transformationsCollectorOpenTelemetry Semantic Conventions 1.25.0OpenTelemetry Operator for KubernetesstanzaBuilding a custom collectorRouting processorOpenTelemetry Operator Helm ChartTarget AllocatorTraces For Kubernetes System Components","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/16/180511","isoDate":"2024-04-16T09:05:11.000Z","dateMiliSeconds":1713258311000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"OpenTelemetryについて調べる時に見るページ","contentSnippet":"はじめにOpenTelemetryは、分散システムの可観測性を向上させるためのオープンソースのフレームワークです。アプリケーションのパフォーマンス、動作、エラーなどを追跡し、収集されたデータを分析および視覚化することで、システムの健全性を監視し、問題の早期発見と解決に役立てることができます。約2年前にOpenTelemetryについてブログに書きましたが、その内容は現状と大分差異があるように感じます。OpenTelemetryプロジェクトは急速に発展しており、公式ページの充実や新しい機能や改善が続々と追加されています。また、多くの組織がOpenTelemetryを採用し、勉強会などで資料を公開したり、オープンソースおよび商用の可観測性ツールとの連携も進んでいます。syu-m-5151.hatenablog.com書籍も出ました。こちらも書評を書いている途中です(ちゃんとします)。Learning OpenTelemetry (English Edition)作者:Young, Ted,Parker, AustinO'Reilly MediaAmazon本記事では、OpenTelemetryについて調べる際に参考になるページを紹介します。オススメがあればDMなどしてください。はじめに紹介するページについて1. The main OpenTelemetry website2. The OpenTelemetry GitHub organization3. The OpenTelemetry Enhancement Proposal repository4. The OpenTelemetry specification5.OpenTelemetry Semantic Conventions6. Organizations that have adopted OpenTelemetry7. OSS and commercial observability tools that support OpenTelemetry8.OpenTelemetry Meetup9. Datadog's $65M Bill and Why Developers Should Care10. Distributed Systems Observability11. Designing Distributed Systems12. Report shows consumers won't wait long for web pages to load13. Burnout in software engineering: A systematic mapping study14. Observability Engineering15. Introducing Domain-Oriented Microservice Architecture16. The Four Golden Signals17. Why and How eBay Pivoted to OpenTelemetry18. OpenTelemetry Lambda19. OpenTelemetry Protocol with Apache Arrow20. Context21. Propagators API22. Trace Context - W3C Recommendation23. OpenTelemetry Transformation Language24. OpenTelemetry Collector25. OpenTelemetry Operator for Kubernetes26. stanza27. Open Agent Management Protocol28. Traces For Kubernetes System Componentsまとめ紹介するページについて以下のページは、OpenTelemetryについて学ぶ際に役立つ情報を提供しています。1. The main OpenTelemetry website OpenTelemetryプロジェクトの公式ウェブサイトです。 プロジェクトの概要、ドキュメント、ブログ、イベントなどの情報が掲載されています。 OpenTelemetryを始めるための出発点として最適なページです。 特に、ドキュメントセクションでは、OpenTelemetryの概念、API、SDKなどについて詳しく解説されています。2. The OpenTelemetry GitHub organization OpenTelemetryプロジェクトのGitHubオーガニゼーションページです。 各プログラミング言語のSDKやツール、仕様などのリポジトリが管理されています。 コードの閲覧、イシューの確認、プルリクエストの提出などができます。3. The OpenTelemetry Enhancement Proposal repository OpenTelemetryの拡張提案（OTEP）を管理するリポジトリです。 新機能や変更の提案、議論、承認などのプロセスが記録されています。 OpenTelemetryの開発方針や将来の計画を知るのに役立ちます。4. The OpenTelemetry specification OpenTelemetryの仕様を定義しているリポジトリです。 API、SDK、データモデル、セマンティック規約などの詳細な仕様が記載されています。 OpenTelemetryの実装や互換性を理解するための重要なリソースです。 用語集や仕様書も参照すると理解が深まります。5.OpenTelemetry Semantic Conventions OpenTelemetryのセマンティック規約を定義しているリポジトリです。 属性、メトリック、リソース、イベントなどの命名規則や意味づけが規定されています。 一貫性のあるデータ収集とカタログ化を実現するための指針となります。 最新版の規約はこちらから確認できます。6. Organizations that have adopted OpenTelemetry OpenTelemetryを採用している組織の一覧ページです。 各組織の名前、ロゴ、採用事例などが紹介されています。 OpenTelemetryの実際の利用状況や適用範囲を知ることができます。 特に、eBayがOpenTelemetryに移行した理由と方法や、Farfetchでの使用事例などは参考になります。7. OSS and commercial observability tools that support OpenTelemetry OpenTelemetryをサポートしているオープンソースおよび商用の可観測性ツールの一覧ページです。 各ツールの名前、ロゴ、説明、リンクなどが掲載されています。 OpenTelemetryと連携可能なツールを探す際に便利です。8.OpenTelemetry Meetup 国内のOpenTelemetry に関する勉強会 ちょっとづつ具体的な話が増えてきている印象がある9. Datadog's $65M Bill and Why Developers Should Care この記事では、Datadogが直面した高額な請求問題と、それが開発者にとって何を意味するのかを洞察に富んだ視点で解説しています。コスト管理とパフォーマンス最適化に関して、開発者がどのように対応すべきかの実践的なアドバイスが含まれています。 OpenTelemetryを活用することで、ベンダーロックインを避け、コストを最適化できる可能性があります。10. Distributed Systems Observability 分散システムの可観測性に関する包括的なガイドを提供するこの書籍は、理論から実践までを網羅しています。特に、OpenTelemetryを含む様々なツールを用いた観測戦略が詳述されており、実用的な知識を深めるのに役立ちます。11. Designing Distributed Systems 分散システムを設計する際の重要な考慮事項を解説するこの資料は、システムの可観測性を高めるための実践的なデザインパターンを豊富に提供しています。読者にとって指導的なリソースとなるでしょう。12. Report shows consumers won't wait long for web pages to load ウェブサイトのパフォーマンスがエンドユーザーの行動にどのように影響するかを掘り下げたこのレポートは、サイトの速度とユーザー満足度の関係を明らかにしています。パフォーマンス監視の重要性についての価値ある洞察が得られます。 OpenTelemetryを使ってウェブアプリケーションのパフォーマンスを計測・改善することが、ユーザー体験の向上につながります。13. Burnout in software engineering: A systematic mapping study ソフトウェアエンジニアリングの分野で発生しているバーンアウト現象についての体系的な研究を提供するこの記事は、業界における心理的健康問題とその対策について詳細に分析しています。 システムの可観測性を高めることで、障害対応の負担を軽減し、エンジニアのストレスを緩和できる可能性があります。14. Observability Engineering 可観測性を中心に据えたこの書籍は、システムの透明性を高めるためのエンジニアリングプラクティスを提案しています。具体的な戦略やツールの使用方法が詳細に解説されており、技術者にとっては非常に参考になる内容です。15. Introducing Domain-Oriented Microservice Architecture Uberが採用しているドメイン指向のマイクロサービスアーキテクチャに焦点を当てたこの記事は、効率的なサービス設計と運用の実践例を提供しています。システムアーキテクトにとって貴重なケーススタディとなるでしょう。 OpenTelemetryを活用することで、マイクロサービス間の依存関係や性能を可視化し、最適化することができます。16. The Four Golden Signals Googleが提唱するシステムモニタリングの四つの基本指標（レイテンシー、トラフィック、エラー、飽和）について詳しく解説しています。効果的な監視システムの設計に不可欠な指標を、具体的な例と共に学ぶことができます。 OpenTelemetryを使って、これらの指標を収集・分析することができます。17. Why and How eBay Pivoted to OpenTelemetry eBayがなぜOpenTelemetryへの移行を決めたのか、そのプロセスはどのように進行したのかについての詳細な分析が行われています。大規模な技術移行を検討している企業にとって参考になる事例です。18. OpenTelemetry Lambda AWS LambdaでOpenTelemetryを効率良く使用するための実践的なガイドとリソースが提供されています。サーバレスアーキテクチャにおける可観測性の課題を克服するのに役立ちます。 自分の環境で利用しているFaaS（Function as a Service）についても、OpenTelemetryのサポート状況を調べてみることをお勧めします。19. OpenTelemetry Protocol with Apache Arrow Apache Arrowを利用してOpenTelemetryデータを効率的に処理する新たなプロトコルについての解説です。データ処理とパフォーマンスの最適化に関心がある開発者にとって重要なリソースです。20. Context OpenTelemetryのコンテキストについて解説しています。コンテキストは、分散トレーシングにおいて重要な役割を果たし、リクエストの流れを追跡するために使用されます。21. Propagators API OpenTelemetryのプロパゲーターAPIについて説明しています。プロパゲーターは、分散システム間でコンテキストを伝搬するために使用されます。22. Trace Context - W3C Recommendation W3Cが推奨するトレースコンテキストの仕様です。OpenTelemetryは、この仕様に準拠してトレース情報を伝搬します。23. OpenTelemetry Transformation Language OpenTelemetry Transformation Language（OTTL）は、OpenTelemetryデータを変換するための言語です。コレクターでデータを加工する際に使用されます。24. OpenTelemetry Collector OpenTelemetry Collectorは、テレメトリデータを収集、処理、エクスポートするためのコンポーネントです。設定ファイルを使って柔軟に構成できます。 ルーティングプロセッサや特殊な変換など、高度な機能も提供されています。 カスタムコレクターの構築も可能です。25. OpenTelemetry Operator for Kubernetes Kubernetes環境でOpenTelemetryを簡単に導入するためのOperatorです。 Helm Chartも提供されています。 Target Allocatorを使って、リソースの動的割り当てが可能です。26. stanza OpenTelemetry Collectorのログパーサーおよびプロセッサです。 柔軟なログ解析とOpenTelemetryフォーマットへの変換が可能です。27. Open Agent Management Protocol エージェントの設定や管理を統一的に行うためのプロトコルです。 OpenTelemetryエージェントの一元管理を可能にします。28. Traces For Kubernetes System Components Kubernetes自体のシステムコンポーネントのトレースを取得する方法について解説しています。 OpenTelemetryを使ってKubernetesの内部動作を可視化できます。まとめ本記事では、OpenTelemetryについて学ぶ際に参考になるページを紹介しました。公式ドキュメントやGitHubリポジトリ、仕様書、採用事例、関連書籍など、様々な角度からOpenTelemetryについて理解を深められる資料を取り上げました。特に、分散システムの可観測性やOpenTelemetryの設計思想については、『Distributed Systems Observability』や『Observability Engineering』などの書籍が詳しく解説しています。また、eBayやUberといった大企業での導入事例は、実際のOpenTelemetry活用方法を知る上で参考になるでしょう。さらに、OpenTelemetryの各種機能や関連プロジェクトについても触れました。コンテキストの伝搬、データ変換、Kubernetes連携など、OpenTelemetryのエコシステムは非常に広がりを見せています。これらのリソースを活用することで、システムの可観測性を高め、運用効率の改善やパフォーマンスの最適化につなげることができるでしょう。","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/09/160824","isoDate":"2024-04-09T07:08:24.000Z","dateMiliSeconds":1712646504000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"なれる!SRE - Becoming SREで学んだこと","contentSnippet":"はじめにエンジニアとして就職する前に読んだ「なれる!SE 2週間でわかる?SE入門」の内容があまりにも厳しく、業界に就職するのが怖くなったことを覚えています。本の中に登場する中学生の少女にしか見えない凄腕のSE、室見立華さんのような人物は現実には存在しないでしょうが、実際の業界には彼女のような凄腕エンジニアや年齢不相応な技術力を持つ人間も確かに存在します。なれる！SE ２週間でわかる？ＳＥ入門 (電撃文庫)作者:夏海 公司,IxyKADOKAWAAmazonSREの探求『Becoming SRE』の内容紹介私は「なれる!SE」が好きすぎるあまり、「なれる!SRE」というタイトルのクソみたいな文章を吐き出したこともありましたが、そのクオリティがあまりにも低かったため、外には公開せずに留めておきました。そんな中、SREの探求の原著者であるDavid Blank-Edelman(otterbook)氏による「Becoming SRE」が 2024年2月にリリースされました。learning.oreilly.com本書では、SREの基本的な考え方や文化について解説し、SREになるために必要なスキルや知識、実際の仕事内容を紹介しています。また、組織にSREを導入するために必要な要件やうまく定着させるためのポイント、SREと他部門との協働について言及し、組織の中でSREを成長・成熟させていくための方法論を提示しています。はじめにSREの探求『Becoming SRE』の内容紹介『Becoming SRE』の構成Part I: Introduction to SREPart II: Becoming SRE for the IndividualPart III: Becoming SRE for the OrganizationPart I: Introduction to SREChapter 1. First Things FirstSREの定義と3つの重要な単語SREとは何かSREとDevOpsの関係性Chapter 2. SRE MindsetSREにとって大切な問いかけSREの反脆弱性を高める営みSREのマインドセットを実践していくことの難しさChapter 3. SRE CultureSREの文化を育むことの重要性SREの文化を育むためのプロセスSREの文化を育む困難さと重要性Chapter 4. Talking About SRE (SRE Advocacy)SREについて語ることの重要性効果的なストーリーを語るための心構えII. Becoming SRE for the IndividualChapter 5. Preparing to Become an SRESREになるために必要な基礎知識SREの本質を追求する姿勢にこそ職責があるSREへの第一歩Chapter 6. Getting to SRE from…様々なバックグラウンドを持つ人々がSREを目指せるシステム管理者からシステム管理が得意なSREになったSREへの道のりは平坦ではないChapter 7. Hints for Getting Hired as an SRE答えは用意しておきますSREの面接は双方向のコミュニケーション日々の仕事の中で信頼性への意識を研ぎ澄ますChapter 8. A Day in the Life of an SRESREの多様な役割とコラボレーションの重要性SREのワークライフバランスSREの業務バランスChapter 9. Establishing a Relationship to ToilToilを単に「嫌な仕事」と片付けないToilに注目する３つの要因Toilとの健全な付き合い方Chapter 10. Learning from Failure障害からの学びはSREの中核的な活動ポストモーテムでも良いレジリエンスエンジニアリングの知見を吸収し活用するPart III. Becoming SRE for the OrganizationChapter 11. Organizational Factors for SuccessSREの導入には組織のあり方そのものの見直しが必要な時もあるSREは技法や手法だけでできたら苦労はしねぇSREの真価を発揮するための組織体制結局、組織じゃんって話Chapter 12. How SRE Can FailSREの失敗は組織全体にネガティブな影響を及ぼしかねないSREは失敗をどう扱うのか？SREの失敗から立ち直るためのマインドセットChapter 13. SRE from a Business Perspective信頼性はサービスの最も重要な機能SREの価値を経営層に伝え続けることの重要性Chapter 14. The Dickerson Hierarchy of Reliability (A Good Place to Start)信頼性向上の第一歩としての The Dickerson Hierarchy of ReliabilitySREの真骨頂は試行錯誤にありChapter 15. Fitting SRE into Your OrganizationSREの導入には組織のカルチャーや構造とのフィット感が重要気を整え 拝み 祈り 構えて 突くデータに基づく意思決定の習慣を根付かせるSREの実践Chapter 16. SRE Organizational Evolutionary StagesSREは組織全体のマインドセットと文化の変革を必要とするSRE組織の5段階の成熟度モデルSREの真髄は組織文化の変革にあるChapter 17. Growing SRE in Your OrgSREの成長は「大きいほど良い」とは限らないSREの組織の規模による分類SREが組織の風土に合わせて多様な形で発展していくChapter 18. ConclusionSREの本質はシステムの信頼性という崇高な目標にあるSREは素晴らしくやりがいある仕事おわりにSREは技術を超え組織文化そのものを変革していくSREの旅に終わりはないこれらの内容は、SREを目指す個人だけでなく、組織としてSREを取り入れようとする企業にとっても、大変参考になるのではないでしょうか。「なれる!SE」に感化されて書いた拙い文章とは異なり、「Becoming SRE」は、SREという職種について、より深く理解するための良書になると期待しています。2024年2月に出版されたのですが、SREに関心のある方は、ぜひ一読してみることをおすすめします。翻訳本が出版されるのが今からとても楽しみです。Becoming SRE: First Steps Toward Reliability for You and Your Organization (English Edition)作者:Blank-Edelman, David N.O'Reilly MediaAmazon『Becoming SRE』の構成『Becoming SRE』は、Site Reliability Engineering (SRE) の入門書であり、個人と組織の両方を対象に、SREをどのように始めるべきかを解説しています。著者は、SREに関する豊富な知識と経験を持ち、多くの人々との対話を通じて得た洞察を本書に凝縮されています。本書は大きく3つのパートに分かれており、それぞれが独立した内容となっているが、全体を通して読むことで、SREの本質的な理解が深まる構成になっています。Part I: Introduction to SRE第1部では、SREを始めるにあたって必要な基礎知識が提供されている。特に、第2章ではSREのマインドセットについて詳しく解説されており、SREの根底にある考え方や価値観を理解することができる。この章は、SREに関する議論を進める上で欠かせない土台となるため、第2部と第3部を読む前に必ず読むべき内容となっている。また、SREに関連する重要な概念や用語についても丁寧に説明されているため、初学者にとっても分かりやすい内容になっている。Part II: Becoming SRE for the Individual第2部では、個人としてSREを始めるための具体的な方法論が述べられている。SREに必要なスキルセットや知識、学習方法などが詳細に紹介されており、SREを目指す人にとって実践的な指南書となっている。また、SREの日常業務やキャリアパスについても言及されているため、SREという職種をより深く理解することができる。著者自身の経験や、他のSREエンジニアとの対話から得た知見も随所に盛り込まれており、生きたアドバイスが得られる内容になっている。Part III: Becoming SRE for the Organization第3部では、組織としてSREを導入・発展させるための指針が提示されている。SREの導入に必要な要件や、組織文化との適合性、他部門との協働など、SREを組織に定着させるためのポイントが詳しく解説されている。また、SREチームの構築や育成、SREプラクティスの継続的な改善についても言及されており、組織としてSREを成功させるためのヒントが数多く提供されている。さらに、実際にSREを導入した企業の事例も紹介されているため、具体的なイメージを持ちながら読み進めることができる。第2部と第3部は、読者の関心に応じてどちらを先に読んでも構わないが、個人と組織は密接に関連しているため、両方を読むことで理解がより深まるだろう。また、最後に収録されているベテランSREエンジニアからの助言は、SREの本質を捉えた良い内容になっており、SREを志す人にとって大きな励みになるはずだ。本書の特徴の一つは、SREに関する他の優れた書籍や情報源を数多く参照していることだ。著者は、自身の知見だけでなく、SREコミュニティの集合知を積極的に取り入れることで、読者により広い視野を提供している。また、SREの実装や解釈は組織によって異なり得ることを認めた上で、SREについての対話を促していることも重要なポイントだ。著者は \"SRE should be a conversation, not a doctrine.\"（SREは教義ではなく、会話であるべきだ）というメッセージを発しており、SREをめぐる活発な議論の重要性を呼びかけている。『Becoming SRE』は、SREの入門書でありながら、奥深い内容を含んだ一冊だ。初学者から経験者まで、幅広い読者に対して、SREについての理解を深め、実践するための指針を提供してくれる。SREに関心を持つ全ての人にとって、必読の書と言えるだろう。Part I: Introduction to SREChapter 1. First Things FirstSREの定義と3つの重要な単語本章は、SREについての理解が深めるための章。著者が提示したSREの定義、「Site reliability engineering is an engineering discipline devoted to helping organizations sustainably achieve the appropriate level of reliability in their systems, services, and products.」は、SREの本質をよく捉えていると感じた。この定義の中で特に重要な3つの単語として、著者が挙げたのは \"Reliability(信頼性)\", \"Appropriate(適性)\", \"sustainable(持続可能性)\" です。システムの信頼性は、組織の収益、評判、従業員の健康などに直結する重要な要素であり、SREの中核をなすものです。また、100%の信頼性を目指すのではなく、SLI/SLOを用いて適切な信頼性のレベルを見極めることが肝要だと説く点も納得できる。そして、信頼性の追求は、人的リソースの持続可能性とのバランスを考慮しなければならない。過度な信頼性の追求が、エンジニアの疲弊を招いては本末転倒です。SREとは何か2014年のSREconで行った講演では、SREの要諦が端的に表現されており、現在でも色褪せない洞察に満ちている。Ben Treynor Sloss氏によれば、SREとは次のような特徴を持つ組織だという。コーダーのみを雇用し、サービスに対するSLAを設定する。そして、そのSLAに対する性能を測定・報告し、エラー予算を活用してゲートローンチを行う。SREチームとDEVチームの間で人材を共有し、SREチームの運用負荷は50%に抑えつつ、運用作業の5%をDEVチームと共有する。オンコールチームは少なくとも8人、できれば6×2の体制を取り、1シフトあたりのイベント数は最大2件までとする。イベントが発生した際には、必ずポストモーテムを行う。ポストモーテムでは非難を避け、プロセスと技術に焦点を当てた議論を行うことが重要です。つまり、SREとは、高い信頼性を持つシステムを構築・運用するための体系的なアプローチであり、エンジニアリングと運用のベストプラクティスを組み合わせたものと言えるとおもいます。www.youtube.comSREとDevOpsの関係性SREとDevOpsの関係性については、本書で提示された3つの見方がそれぞれ示唆に富んでいる。1つ目の「SREはDevOpsの一実装である」という見方は、SREとDevOpsが共有する理念や手法に着目したものです。両者はともに、開発と運用の協調を重視し、自動化やツールの活用を推進する点で共通している。ただし、著者が指摘するように、DevOpsが特定の方法論やツールを規定しないのに対し、SREはより規範的（prescriptive）なアプローチを取る傾向があります。2つ目の「SREの信頼性に対するDevOpsのデリバリー」という対比は、両者の目的の違いを浮き彫りにしている。SREが systems の信頼性（reliability）の確保を最重要視するのに対し、DevOpsはソフトウェアのデリバリー（delivery）に主眼を置く。もちろん、信頼性の高いシステムを迅速にデリバリーすることは、両者に共通する目標ではあるが、力点の置き方が異なります。3つ目の「SREとDevOpsでは、関心の方向性が異なる」この言葉はSREとDevOpsの関心の方向性の違いを鮮やかに描き出している。SREは本番環境から出発し、「本番環境の信頼性を確保するために、開発者は何をすべきか」という観点から、開発の方向へと関心を向ける。一方、DevOpsは開発者の環境から出発し、「開発者が書いたコードを、いかにして本番環境に迅速かつ安全にデリバリーするか」という観点から、本番環境の方向へと関心を向ける。Figure 1-2. The Limoncelli model of SRE, DevOps, and Agile strategies. Modified from the original in Seeking SRE (O’Reilly, 2018). より引用この違いは、両者が重視するツールや手法にも反映される。例えば、SREはモニタリングやインシデント管理、カオスエンジニアリングなどの運用面のツールを重視するのに対し、DevOpsはCIツールやコンテナ技術などのデリバリーを加速するツールを重視する傾向があります。ただし、著者が強調するように、SREとDevOpsは二者択一ではなく、むしろ補完的な関係にあると捉えるべきだろう。組織の規模やビジネス特性、技術的成熟度などに応じて、SREとDevOpsの手法を適切に組み合わせることが肝要です。このへんは可視化されているDevOps Topologiesを参考にしても分かりやすいかもしれないです。web.devopstopologies.com例えば、スタートアップのような小規模な組織では、DevOpsの手法を全面的に採用し、エンジニア全員がデリバリーと運用の両方に携わるのが適切かもしれない。一方、大規模なシステムを運用する組織では、SREの手法を導入し、信頼性の確保に特化したチームを設置することが有効だろう。いずれにせよ、SREとDevOpsのどちらか一方を選ぶのではなく、両者の長所を活かし、組織の文脈に合わせて柔軟に適用していくことが重要です。そのためには、両者の理念や手法を深く理解し、自組織の目的や制約に照らし合わせて、最適な方法論を構築する必要があります。本書の第1章で提示されたSREとDevOpsの関係性に関する考察は、そのための出発点として大変良いものだった。今後は、本書で得た知見を土台に、SREとDevOpsの実践方法を探求するときに活用していきたい。。つまり、SREとは、高い信頼性を持つシステムを構築・運用するための体系的なアプローチであり、エンジニアリングと運用のベストプラクティスを組み合わせたものと言えるとおもいます。Chapter 2. SRE MindsetSREにとって大切な問いかけ本章は、著者自身の経験と、他のSREとの対話から得られた洞察を基に、SREのマインドセットを形作る大切な要素について分かりやすく説明されていました。最初に出てくる \"システムはどのように動作しているのか？どのように失敗するのか？\" という問いかけは、SREの思考法の根っこにあるものだと感じました。システムの信頼性を追求するには、その動作原理と障害パターンを徹底的に理解する必要があります。著者が強調しているように、SREにとって大切なのは \"どのように動作すべきか\" ではなく \"実際の本番環境ではどのように動作しているのか\" なんですよね。システムを理解するためには、ミクロなレベルからマクロなレベルまで、あらゆる粒度でシステムを観察して、分析しなければいけません。著者が例に挙げているデータベース接続の話は、一見些細なことのように思えるかもしれませんが、**SREはそこから派生するいろんな問題を想定して、システム全体への影響を考えなくちゃいけないんです。システムを理解する例として最近公開された ブラウザからDBに行き着くまでをただまとめる のような取り組みを自サービスで行うと効果的と考えています。システムの動作を自身で調べながら書き出していくという点でSREの探求20章でアクティブラーニングで紹介された事例に近いものがあります。zenn.dev著者が \"Understanding a System as a System\" というコラムで紹介しているシナリオは、SREにとってのシステム思考の重要性をよく表していました。データセンターで電源ケーブルが切れるという一つの出来事が、いくつもの要因が絡み合って、最終的にお客さんの購買機会の損失につながっていく流れが描かれています。このシナリオは、システム障害の責任を特定の個人に押し付けるのではなく、システム全体の問題として捉えることの大切さを教えてくれています。SREのマインドセットで大事なのは、お客さんの立場に立つことだと著者は指摘しています。システムの信頼性は、コンポーネントの視点ではなく、お客さんの視点から測定されるべきなんです。100台のWebサーバーのうち14台が故障した場合のシナリオは、このことをはっきりと示していました。SREは常に、システムがお客さんからどう見えているのかを意識して、お客さんの期待に応えることを目指しているんですよね。SREのマインドセットの特徴の一つは、フィードバックループの重要性を理解していることだと著者は述べています。信頼性の向上は、継続的なフィードバックループを通じて達成されるんです。SREの役割は、システムのあらゆる場所でフィードバックループを見つけ出して、育てていくことにあります。それから、SREは他者とのコラボレーションを大切にするという点も印象に残りました。信頼性の追求は、絶対に一人では成し遂げられません。SREは、開発者、運用チーム、マネージャー、そしてお客さんを含むいろんな関係者と協力しながら、システムの信頼性を高めていくんです。特に、お客さんとのコラボレーションについて著者が提示した \"お客さんと一緒に信頼性を高めるためにどうやって協力できるだろう？\" という問いは、SREのあり方を考える上でとても示唆に富んでいると思いました。SREの反脆弱性を高める営みSREの失敗(failure)や障害(error)に対する姿勢も興味深かったです。SREは、失敗をネガティブなものとしてではなく、学びのチャンスとして捉えるんです。障害は、システムについての理解を深めるための貴重な情報源なんですよね。対話から得た \"障害をシグナルとして扱う\" という著者の学びは、SREのマインドセットをズバリ表していると感じました。この考え方は、『反脆弱性――不確実な世界を生き延びる唯一の考え方』で提唱されている \"反脆弱性\" の概念とも通じるものがあります。著者は、不確実性や変動性、ストレスに晒されることで、かえって強くなる性質を \"反脆弱性\" と呼んでいます。SREが障害を学びの機会と捉えることは、まさにシステムの反脆弱性を高める営みだと言えるでしょう。失敗から学び、その経験を糧にしてシステムを進化させていく。そういうレジリエントなマインドセットこそが、SREに求められているのかもしれません。反脆弱性［上］――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonさらに、SREのマインドセットは、長期的な視点を持っているという点でも特徴的です。スケーラビリティ、運用負荷の軽減、より多くの人々への信頼性の提供など、SREは常に将来を見据えて行動しているんです。システムが時代遅れになる前に、より良い代替案を用意することも、SREの重要な役割の一つだと著者は指摘しています。第2章で紹介されたSREのマインドセットは、技術的な側面だけでなく、倫理的・文化的な側面も含んだ、多面的なものだと感じました。著者が \"neurodiversity\" について触れていたように、SREという職種は、多様なバックグラウンドを持つ人々の力を結集することで、より高い信頼性を達成できるのだと信じています。SREのマインドセットを実践していくことの難しさSREのマインドセットという、一見つかみどころのない概念を、具体的な事例と洞察に基づいて解き明かしてくれる、良い内容でした。システムの信頼性を追求するためには、技術的なスキルと知識に加えて、SRE特有の思考法と姿勢が欠かせないことを、改めて認識させられました。特に、システムの動作を理解し、障害を検知・分析するためには、オブザーバビリティが重要な役割を果たします。オブザーバビリティの概念と実践について、SREの視点から解説した良書です。この本は、オブザーバビリティを単なるモニタリングの延長ではなく、システムの動作を理解するための能動的なアプローチとして捉えています。時系列データ、ログ、トレースを駆使して、システムの振る舞いを可視化し、問題の根本原因を究明していく。そのようなオブザーバビリティ・エンジニアリングの手法は、SREのマインドセットを体現するものだと言えるでしょう。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社Amazon私自身、ソフトウェアエンジニアやSREとしての経験を積む中で、システム思考の大切さを痛感してきました。複雑化する現代のシステムにおいては、個々の要素を深く理解するだけでなく、それらが相互に作用して生み出す振る舞いを俯瞰的に捉える力が求められるんです。システム思考とは、システムを構成する要素間の相互作用や、システムとその環境との間の相互作用に着目し、システム全体の振る舞いを理解しようとするアプローチです。部分の最適化ではなく、全体の最適化を目指すのがシステム思考の特徴です。複雑なシステムでは、ある要素の変化が予想外の連鎖反応を引き起こし、システム全体に影響を及ぼすことがあります。そのような非線形な因果関係を見抜くには、システムを俯瞰する視点が欠かせません。さらに、システムの目的や境界条件を明確にし、外部環境の変化に適応していく力も求められます。SREにとって、システム思考は障害対応や信頼性の向上に直結するスキルだと言えるでしょう。障害が発生した際、表面的な症状だけでなく、根本原因を追究するためには、システム全体の挙動を理解する必要があります。また、信頼性を継続的に改善していくには、ボトルネックを特定し、フィードバックループを回していくことが重要です。それに加えて、お客さんの視点に立って、システムの価値を最大化するという姿勢も、SREにとって欠かせないものだと感じています。システムの究極的な目的は、お客さんに価値を届けることです。お客さんの要求や期待を理解し、システムの機能や性能、信頼性を進化させていく。そのようなお客さん志向のマインドセットは、システム思考と表裏一体をなすものだと言えます。プロダクトマネジメント ―ビルドトラップを避け顧客に価値を届ける作者:Melissa PerriオライリージャパンAmazon第2章で紹介されていた \"no haunted graveyards\" というSREの格言は、私の心に強く残りました。過去の負の遺産から目を背けるのではなく、それを掘り起こして、改善していく。それがSREの使命なんだと。障害や失敗を恐れるのではなく、それを糧にしてシステムを進化させていく。そういう姿勢こそが、SREのマインドセットの真髄なのかもしれません。もちろん、SREのマインドセットを身につけて、実践していくのは簡単なことじゃありません。技術的な学習はもちろん、経験を積み重ねて、他者との対話を通じて考えを深めていくことが欠かせません。Chapter 3. SRE CultureSREの文化を育むことの重要性本章は、SREという職種に特有の文化について理解が深まりました。著者は、SREの文化を育むことの重要性を強調しつつ、その具体的な方法論について、自身の経験と洞察に基づいて解説しています。本章を読んでいてSREには最初からスタッフエンジニア的な立ち振舞いが必要だと強く思いました。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonSREの文化を育むことが重要な理由は二つあると著者は指摘しています。一つ目は、SREがその能力を最大限に発揮するためには、SREに適した環境と条件が不可欠だからです。新しい熱帯魚を飼育する際に、水温や水質、餌などに気を配るのと同じように、SREを雇用する組織は、SREが力を発揮できる文化を意識的に作り上げていく必要があります。著者は、SREの文化を育むことを \"keep SREs happy\" と表現していますが、これは単にSREを満足させるというだけでなく、組織にとっても重要な意味を持つのです。二つ目の理由は、SREの文化が組織全体の変革の原動力になり得るからです。著者は、SREの文化を \"Culture as a Vehicle or a Lever\" と表現し、SREの文化が組織や個人を望ましい方向へと導く「乗り物」あるいは「てこ」になると述べています。例えば、SREが重視する \"it isn't done until it is documented\" という考え方は、ドキュメンテーションの充実を組織全体に浸透させる力になります。SREの文化は、reliability（信頼性）という目に見えにくい価値を、組織の隅々にまで行き渡らせるための強力な手段なのです。では、SREの文化を意図的に育むにはどうすればよいのでしょうか。著者は、第2章で解説したSREのマインドセットを出発点にすることを提案しています。SREのマインドセットを形作る要素を一つ一つ取り上げ、それを支える条件や前提条件を考えていく。そのようなボトムアップのアプローチこそが、SREの文化を育む第一歩になると著者は説いています。また、著者は、Carl Saganの \"If you wish to make an apple pie from scratch, you must first invent the universe.:アップルパイをゼロから作りたい場合は、まず宇宙を発明する必要があります。\" という言葉を引用し、文化を構築するためには、それを構成する要素を細分化し、それらを組み合わせるプロセスに着目することが重要だと指摘しています。例えば、\"信頼できる開発環境を提供するために何が必要か\" という問いを立てると、そこから自己サービス化、ドキュメンテーション、拡張性、オブザーバビリティなど、SREの文化を特徴づける様々な要素が浮かび上がってきます。これらの要素を一つ一つ紐解いていくことで、SREの文化の全体像が見えてくるというのです。ただし、著者も認めるように、\"What do I want SRE to be here?\" という問いに答えを出すのは容易ではありません。SREに何を期待し、どんな役割を担ってもらいたいのか。組織によって、その答えは千差万別だからです。しかし、その困難な問いに向き合うことなくして、SREの文化を意図的に育むことはできません。著者は、その問いへの答えを模索するためのヒントとして、インシデント対応に注目することを提案しています。SREの文化を育むための具体的な方法としては、インシデント対応とその振り返りに注力することが有効だと著者は述べています。インシデントの検知、対応、分析、再発防止のプロセスを丁寧に分解し、そこに潜む問いに真摯に向き合うこと。それこそが、SREがシステムの信頼性を高めるために不可欠な営みであり、SREの文化の根幹をなすものだというのです。インシデント対応は、しばしば \"fruit trees\" を育てる営みに喩えられます。インシデントという \"種\" を丁寧に観察し、その理由や背景を \"土壌\" として分析する。そこから得られた学びを \"肥料\" にして、再発防止という \"果実\" を実らせる。そのようなプロセスを地道に積み重ねていくことが、SREの文化を根付かせ、組織の信頼性を高めていくのだと著者は説いています。ただし、インシデント対応をSREだけの仕事にしてしまうと、かえって望ましくない状況を招く恐れがあると著者は警告しています。インシデント対応を通じて得られた知見は、組織全体で共有され、活用されてこそ意味があります。もしSREだけがインシデントから学び、その知見が組織に還元されないようであれば、それは \"車輪の脱落したショッピングカートを押している状態\" だと著者は表現しています。つまり、SREの文化が組織を望ましい方向に牽引する力を発揮できなくなってしまうのです。その意味で、著者が \"Who is getting smarter and what are we doing about it?:誰がより賢くなっているのでしょうか?それに対して私たちは何をしているのでしょうか?\" と問いかけているのは示唆に富んでいます。インシデント対応から得られた教訓は、誰のものになっているのか。そして、その教訓を組織の信頼性向上にどう活かしているのか。その問いに常に意識的でいることが、SREの文化を健全に保つために不可欠なのです。SREの文化を組織に根付かせるためのもう一つの方法は、\"読書輪読会\" や \"ローテーション\" だと著者は述べています。\"読書輪読会\" とは、ポストモーテムやシステム設計書、書籍などを題材に、SREの視点から議論を重ねる場のことです。一方、\"ローテーション\" とは、SREと他の職種の間で一定期間、互いの役割を交代するという取り組みです。これらの活動を通じて、SREの考え方や価値観を組織全体に浸透させていくことができます。特に \"ローテーション\" は、SREの文化を組織に根付かせる上で強力な手段になり得ます。SREがソフトウェアエンジニアの役割を体験することで、開発者の視点や課題を肌で感じることができます。逆に、開発者がSREを経験することで、信頼性の重要性や、運用の現場で何が起きているのかを理解することができます。そのような相互理解が、SREと他の職能の間の \"cultural exchange\" を促進し、組織としての一体感を醸成するのです。『Becoming SRE』の第3章は、SREの文化という、一見捉えどころのない概念を、具体的な方法論と結びつけて解説した、良い内容でした。著者の主張で特に印象に残ったのは、SREの文化は、意図的に育まなければ根付かないというものです。組織の価値観や行動様式を変えていくことは容易ではありません。しかし、著者が提示したような地道な取り組みを積み重ねていくことで、SREの文化は確実に花開いていくはずです。SREの文化を育むためのプロセスそれは、新しい熱帯魚を迎え入れる時のようなワクワク感と、果てしない可能性に満ちたプロセスなのかもしれません。水槽の環境を整え、エサを与え、そっと見守る。SREの文化を育むことは、そんな愛情深く、辛抱強い営みなのだと感じました。もう一つ、私が共感を覚えたのは、SREの文化の中核には \"curiosity（好奇心）\" があるという指摘です。システムの信頼性を追求するためには、その仕組みや振る舞いを深く理解したいという欲求が不可欠です。著者が \"Any SRE culture you create (intentionally or unintentionally) has to support curiosity.:あなたが作成する SRE 文化は (意図的か非意図的かにかかわらず) 好奇心をサポートするものでなければなりません。\" と述べているように、好奇心こそがSREの文化を支える最も重要な要素なのです。そして、好奇心は \"novelty（新奇性）\" とも密接に結びついています。SREにとって、新しい技術や手法に触れ、学び続けることは、好奇心を刺激し、モチベーションを高める上で欠かせません。SREの文化は、そのような好奇心と新奇性を尊重し、奨励するものでなければならないのです。また、著者が \"culture overlays most everything\" と述べているように、SREの文化は、技術的側面だけでなく、組織のあらゆる側面に影響を及ぼし得るものです。それは、人と人との関わり方、コミュニケーションの取り方、意思決定のプロセスなど、組織の文化的な基盤を形作るものでもあるのです。だからこそ、SREの文化を意図的に育んでいくことが重要なのだと改めて感じました。SREの文化を育む困難さと重要性SREの道のりは決して平坦ではありません。しかし、SREの文化を大切に育んでいくことは、その旅を意義あるものにしてくれるはずです。変化への抵抗や、既存の価値観との軋轢に直面することもあるでしょう。でも、複雑なシステムを動かすためには、てこを見出し、フィードバックループを形成し、粘り強く働きかけ続けることが肝要なのです。本章を読んで、私は自身のSREとしての経験を振り返ってみました。確かに、私が所属するチームでも、SREの文化を意識的に育んできた面があります。例えば、障害の振り返りの場では、個人の責任を追及するのではなく、システムの課題を浮き彫りにすることを大切にしてきました。また、開発チームとのローテーションを通じて、互いの理解を深める取り組みも行ってきました。しかし、著者の指摘を踏まえると、まだまだ改善の余地があるようにも感じました。例えば、インシデント対応から得られた知見を、もっと組織全体に浸透させていく工夫が必要かもしれません。また、SREの文化の中核にある \"好奇心\" を、もっと大切にしていく必要があるようにも思います。自分なりのSREの文化を育んでいく。お客様に価値を届け続けるというSREの使命を全うするために、仲間とともに今日も一歩一歩前へ。Chapter 4. Talking About SRE (SRE Advocacy)SREについて語ることの重要性本章は、SREについて語ることの重要性と、そのための実践的なアドバイスについて理解が深まりました。著者は、SREの価値を組織内外に伝えるためのストーリーテリングの技術について、自身の豊富な経験に基づいて解説しています。ちなみに、私が以前読んだ『ダイアローグ　価値を生み出す組織に変わる対話の技術』でも、必要なのはただのコミュニケーションではなく対話であることが強調されていました。SREについて語る際にも、この点は意識すべきポイントだと思います。ダイアローグ 価値を生み出す組織に変わる対話の技術作者:熊平美香ディスカヴァー・トゥエンティワンAmazon著者によると、SREについて語ることが重要な理由は大きく二つあるそうです。一つ目は、SREという職種や考え方に対する理解を深め、その存在意義を組織内で認めてもらうためです。特に、SREを新しく導入する際や、その影響力を拡大していく段階では、効果的なアドボカシー（支持獲得活動）が欠かせません。二つ目の理由は、SREとしてのアイデンティティを形成するためだということです。著者は \"the stories we tell ourselves are a major way identity is formed.\" つまり、「私たちが自分自身に語る物語は、アイデンティティを形成する主要な方法である」と述べ、自分たちが語るストーリーがアイデンティティの形成に大きな影響を与えると指摘しています。SREについて語ることは、単に他者の理解を得るためだけでなく、自分自身がSREとは何かを深く理解するためにも重要なのです。では、SREについてどのようなストーリーを語れば良いのでしょうか。著者は、SREの定義や効果、評判、可能性など、様々な切り口からストーリーを構成することを提案しています。例えば、「SREの取り組みによって、あるチームの信頼性が目に見えて改善した」といった \"効果の物語\" や、「有名企業がSREを取り入れた」といった \"評判の物語\" は、SREの価値を伝える上で説得力のあるストーリーになるでしょう。また、著者は具体的なストーリーの例も挙げています。障害対応の際の謎解きのプロセスや、SREの専門家の問題解決アプローチを描くことで、SREという仕事の面白さや奥深さを伝えることができるはずです。一方で、SREについて語る上での課題についても、著者は良い指摘をしています。\"吠えなかった犬\" の例え話から分かるように、SREの価値は、しばしば \"何が起きなかったか\" という点に表れます。障害が発生しなかったことや、データ損失が防げたことなど、ネガティブな事象を語るのは容易ではありません。そのためには、\"対比\" の技法を活用し、SREの取り組みがなかった場合に起こり得た事態を想像させることが重要だと著者は述べています。また、\"ヒーロー文化\" を美化するストーリーには注意が必要だと著者は警告しています。個人の英雄的な努力を称賛するあまり、過剰な負荷や無理な働き方を正当化してしまうことがあるからです。インシデント対応でのヒーローの活躍を語る際には、組織としての課題を浮き彫りにし、改善点を提示することが肝心だと強調されています。著者が提示したストーリーの例は、SREの価値を伝える上で参考になるものばかりでした。特に、\"ある日のSREの物語\" のように、SREの日常業務を具体的に描くことで、その仕事の醍醐味や面白さを伝えられるアイデアが印象的でした。ただし、著者自身も認めるように、SREについて語るのは思ったより難しいことがあります。信頼性向上への取り組みは決して一直線ではなく、試行錯誤の連続だからです。その複雑な現実を、聴衆に分かりやすく伝えるためには、スキルと経験が必要不可欠だと感じました。また、SREのストーリーには、技術的な要素だけでなく、人的な要素も欠かせません。著者が \"all of our systems are sociotechnical\" と指摘しているように、信頼性の追求には、技術と人、両方の視点が不可欠なのです。効果的なストーリーを語るための心構え改めて振り返ってみると、SREについて語ることは、単なるアドボカシーの技術ではありません。それは、自らのアイデンティティと、組織としての使命を見つめ直す営みでもあるのだと気づかされました。著者が \"my best talks are those that changed me during the preparation or presentation\" と述べているように、SREについて語ることは、語り手自身をも変容させる体験になり得るのです。本章で提示された多様なストーリーのアイデアを参考に、私もSREについて語る機会を増やしていきたいと思います。自分の経験を言語化し、他者と共有することで、SREとしての自覚と誇りを深めていく。そのような語りの積み重ねが、SREの文化を組織に根付かせ、ひいては社会にも良い影響を与えていくのだと信じています。第4章は、SREという職種の意義を伝えるためのヒントに満ちた一章でした。SREについて語ることは、自分自身と、自分が関わるシステムを見つめ直すための強力な方法論なのだと実感しました。とはいえ、効果的なストーリーを紡ぐのは容易ではありません。著者が \"Collecting stories as you go\" と述べているように、日々の業務の中で、ストーリーのタネを見つける感度を磨いていく必要があります。そして、それを言葉にする作業を丁寧に積み重ねていくことが肝要だと感じました。また、著者も触れているように、他者のストーリーを語る際には、倫理的な配慮も欠かせません。関係者の許可を得ることは大前提ですが、それ以上に、ストーリーの背景にある文脈や、登場人物の心情に思いを馳せることが大切だと感じました。型にはまったストーリーではなく、現場の息吹が感じられるような生々しいストーリーを、誠実に語ることが求められているのだと思います。もう一つ、著者が \"Give up your airtime\" で述べているように、多様な語り手を登用することも重要な課題だと感じました。SREについて語る機会が、一部の立場の人々に偏ることのないよう、自分自身も意識していきたいと思います。第4章を読んで、改めてSREの魅力と可能性を感じました。システムの信頼性を追求するというミッションは、決して華やかなものではありません。しかし、著者が紹介してくれたような力強いストーリーを通じて、その意義を伝えていくことはできるはずです。お客様に平穏と信用を届け、自分のプロとしての役割を成就するために。SREに関して語ることを通じて、自身の業務の意義を再び確かめ、新たな一歩を踏み出すための決心を固めたいものです。日頃の仕事の中で信用を積み重ね、丁重な説明を怠らず、相手に応じた意思疎通を図るなど、円滑なコミュニケーションのためには並々ならぬ労力が必要不可欠です。しかしながら、コミュニケーションのコストを払いたくない、責任を背負いたくない、嫌われたくない、それでいて自分が考案した仕組みにみんなが同意し、ついてきてほしいというのは、どこまでも絵空事なのです。いかに「正しくて能率的」なアイデアでも、そこに人間が関与する以上、人間の心理や感情を考慮せざるを得ません。本来は課題解決に注力したいのに、人間関係の調整に手間を取られるのは、本質から外れているように思えるかもしれません。しかし、他者と協働しなければならない以上、それは避けられない現実なのです。SREという仕事も、究極的には人と人とのつながりの中で成り立っているのだと、改めて認識させられました。円滑なコミュニケーションを築くことは容易ではありませんが、それなくしてSREの使命を果たすことはできないのです。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonII. Becoming SRE for the IndividualChapter 5. Preparing to Become an SRESREになるために必要な基礎知識本章は、SREになるために必要な知識やスキルについて理解が深まりました。著者は、SREへの道のりに唯一無二の正解はないと断りつつも、SREとして活躍するために身につけておくべき基礎知識を丁寧に解説しています。まず、「コーディングができる必要があるか」という問いに対して、著者は 「Yes」 と明確に答えています。システムの信頼性を追求するSREにとって、ソフトウェアがどのように作られているかを理解することは不可欠だからです。また、コーディングを学ぶことで、アルゴリズムの効率性、エラーハンドリング、抽象化、設計、分解、統合、依存関係、ドキュメンテーションなど、SREに必要な多くの概念を自然と学べると著者は指摘しています。これらについては自分も似たような課題感を持っていてブログにしました。syu-m-5151.hatenablog.com一方で、「コンピュータサイエンスの学位が必要か」という問いに対しては、必ずしもそうではないと著者は述べています。ただし、学位がない場合は、アルゴリズム解析やBig O記法など、コンピュータサイエンスの基礎概念をある程度理解している必要があるそうです。次に、著者は 「基本的なシステムと、その障害モード」 と 「分散システムと、その障害モード」 の理解の重要性を強調しています。現代のSREは、マイクロサービスアーキテクチャや地理的に分散したシステムを扱うことが多いため、分散システム特有の障害モードを理解し、レイテンシ、コンセンサスアルゴリズム、分散タイムキーピング、データの一貫性などの概念に精通している必要があるのです。また、著者は 「統計とデータの可視化」 のスキルも重要だと述べています。モニタリングとオブザーバビリティはSREの基盤であり、そのためには、パーセンタイル、傾向分析など、統計の知識が欠かせません。さらに、データを効果的に可視化する能力は、信頼性について客観的な議論をする上で極めて重要だと著者は指摘しています。意外に感じたのは、「ストーリーテリング」 がSREの基礎スキルの一つとして挙げられていたことです。インシデントレビューやポストモーテムは本質的にストーリーであり、そのストーリーをうまく伝えることがSREの重要な仕事だと著者は述べています。人間はストーリーを通じて情報を受け取るようにできているため、SREはストーリーテリングとストーリーリスニングのスキルを磨く必要があるのだそうです。また、著者は 「良き人であれ」 という一節で、SREにとって、プライバシー、倫理、インクルージョン、平等などの価値観について学び続けることの重要性を説いています。SREは地球上で最も重要なシステムの一部を任されているからこそ、常に自己研鑽に励み、最高の自分でいる必要があるのです。そのほか、著者は、すぐには必要ないかもしれないが、いずれSREの前に立ちはだかるであろう話題として、「大規模システム設計」「レジリエンスエンジニアリング」「カオスエンジニアリングとパフォーマンスエンジニアリング」「機械学習と人工知能」 などを挙げています。特に、機械学習によって、システムの振る舞いがデータに依存して確率的に変化するようになったことは、信頼性を考える上で大きなパラダイムシフトだと著者は指摘しています。SREの本質を追求する姿勢にこそ職責がある『Becoming SRE』の第5章は、SREに必要な知識やスキルを体系的に整理した、良い内容でした。著者は「SREの仕事の本質は、システムについて深く理解し、その信頼性を追求すること」と繰り返し強調しています。そのためには、コンピュータサイエンスの基礎から、分散システム、統計、ストーリーテリングまで、幅広い知識と経験が求められます。ただし、著者も認めるように、これらのスキルは一朝一夕には身につきません。大切なのは、自分に足りない知識を認識し、それを少しずつ埋めていく姿勢なのだと感じました。著者が \"Worst-case scenario: it is good to know what you don't know.\" と述べているように、自分の知らないことを知っているだけでも、SREへの第一歩になるはずです。また、SREとして成長していくためには、技術的なスキルだけでなく、「Are you a curious person?:あなたは好奇心旺盛な人ですか？」「Do you like to solve problems, no matter where they take you?:どこに連れて行かれても、問題を解決するのが好きですか?」「Is a life of service attractive to you?:奉仕生活はあなたにとって魅力的ですか?」といった問いに、心の底から「Yes」と答えられるかどうかも重要だと著者は述べています。SREという仕事に真に向いているかどうかは、スキルではなく、マインドセットにあるのかもしれません。本章を読んで、私はSREという職種の奥深さを改めて感じました。信頼性の追求という、一見シンプルに見える目標の背後には、実に多様な知識とスキルが求められているのです。それは、コンピュータサイエンスという学問の神髄を問うものであり、同時に、人間の認知や行動、価値観についての洞察も必要とするものだと感じました。しかし、だからこそ、SREという仕事にやりがいを感じずにはいられません。信頼性を追求するという使命を胸に、謙虚に学び、好奇心を持って問題に立ち向かう。そんなSREの姿勢は、エンジニアとして、人として、大いに魅力的だと感じます。SREへの第一歩もちろん、その道のりは平坦ではありません。著者が \"aspirational:野心的\" と表現しているように、本章で示された知識やスキルは、理想であって、必須条件ではないのです。大切なのは、その理想であり達人SREに向かって一歩ずつ前進していくこと。私も、自分に足りない点を一つずつ埋めながら、SREとしての道を歩んでいきたいと思います。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社AmazonChapter 6. Getting to SRE from…様々なバックグラウンドを持つ人々がSREを目指せる本章は、著者は、SREになるための唯一の正解はないと断った上で、学生、開発者、システム管理者など、よくある出発点からSREへ移行するためのアドバイスを提示しています。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazonまず、著者は「あなたはすでにSREなのかもしれない」と問いかけます。組織の中には、正式な肩書きこそないものの、SREのマインドセットを持って仕事に取り組んでいる人が少なからずいるというのです。もしあなたがそうだとしたら、組織内でその価値を認めてもらい、SREとしてのキャリアを歩み始めることが次の一歩になるでしょう。学生からSREを目指す人へのアドバイスとしては、インフラ関連の仕事を見つけること、クラウドプロバイダーの無料クレジットを活用すること、カンファレンスに参加することなどが挙げられています。また、コンピュータサイエンスを学ぶ学生は、スケーリング、分散コンピューティング、キューイング理論などの授業に注目すべきだと著者は述べています。一方、工学や科学を学ぶ学生は、大規模計算に触れる機会を見つけ、信頼性の高いシステムを構築するために必要なスキルを身につけることが重要だとのことです。開発者からSREへの移行に関しては、本番環境でのコードの振る舞い、障害モード、オブザーバビリティ、リリースエンジニアリング、ドキュメンテーションなどに注目することが大切だと著者は指摘しています。開発者にとって、「システムを構築するだけでなく、運用することについても考える」ことがSREへの第一歩になるのです。システム管理者からシステム管理が得意なSREになった私自身、システム管理者からSREへの道を歩んできました。著者が指摘するように、システム管理者とSREは、人々を助けたいという思いを共有しています。また、トラブルシューティングとデバッグのスキルも、両者に共通する強みだと言えるでしょう。sreake.com一方で、SREへの移行には、マインドセットの転換が必要だと著者は述べています。「すべてのものを監視する」から「顧客の視点から信頼性を測定する」へ、「適切な信頼性レベル」を追求し、「フィードバックループを育む」ことが求められます。この転換を実現するために、著者はチケット管理システムやモニタリングのメールを、信頼性に関する貴重なデータソースとして活用することを提案しています。インシデント後のレビューを非公式に実施することも、SREのマインドセットを身につける良い機会になるでしょう。さらに、「根本原因」ではなく「contributing factors:要因」といった言葉を用いることで、言語がもたらす認識の変化にも目を向けるべきだと著者は述べています。最後に、著者は他のあらゆる職種の人々に向けて、「信頼性とのつながりを見つけ、その方向に泳ぎ始めること」を勧めています。また、進捗を記録し、前進し続ける原動力にすることの重要性も強調されています。第6章は、SREというキャリアを目指す人々に、実践的なアドバイスと温かい応援のメッセージを送る内容でした。著者の主張で特に印象に残ったのは、SREへの道に唯一の正解はないという点です。様々なバックグラウンドや経験を持つ人々が、信頼性の追求という共通の目標に向かって歩んでいける。そんな多様性と包摂性こそが、SREという職能の強みなのかもしれません。本章を読んで、私はシステム管理者時代を振り返ってみました。確かに当時は、可用性の追求に汲々としていた面があります。でも、あの頃培った、ユーザーに価値を届けたいという思いは、今でもSREとしての原動力になっています。著者が述べているように、経験やスキルのギャップを少しずつ埋めていくことで、誰もがSREを目指せるのだと感じました。SREへの道のりは平坦ではないとはいえ、SREへの道のりは決して平坦ではありません。新しい知識を吸収し、経験を積み、時にはつまずきながら進んでいく。しかし、その過程で得られる学びと成長は、何物にも代えがたい価値があるはずです。Chapter 7. Hints for Getting Hired as an SRE本章は、SREの職を得るためのヒントについて理解が深まりました。著者は、SREの求人情報の評価方法から、面接の準備、面接でのアピール方法まで、SREの仕事を求める人のために実践的なアドバイスを提供しています。また、Github上ではmxssl氏によるSRE 面接準備ガイドがありこちらも一読していただければ良いと思います。github.comまず、著者は「SREの仕事はすべて同じではない」と断った上で、タイトルだけがSREに変更された職種（title-flip positions）は、本章の対象外だと明言しています。SREの求人を見極めるためには、求人情報に含まれている（あるいは含まれていない）情報に注目することが大切だと著者は述べています。求人情報に記載されている技術スタックからは、その組織の技術的成熟度や環境の一貫性などが読み取れるそうです。また、チケット管理システムへの言及は、その環境がどれほどトランザクショナルかを示唆しているとのことです。プログラミング言語への言及は、コーディングスキルがある程度重視されていることを意味します。一方、モニタリング技術への言及の有無からは、その職種とモニタリングの関係性が窺えます。次に、著者はSREの面接対策として、非抽象的な大規模システム設計（NALSD）、モニタリング／オブザーバビリティ、コンピューティングの基礎、トラブルシューティング／デバッグの4つのトピックを挙げています。これらのスキルは、ほとんどのSREの職種で求められるため、事前に準備しておくことが重要だと著者は述べています。面接で質問すべき内容についても、著者は具体的な提案をしています。「モニタリングシステムについて教えてください」「インシデント後のレビュープロセスについて教えてください」「オンコール体制について教えてください」「SREが解決しようとしている問題は何ですか？」といった質問は、その組織におけるSREの役割や成熟度を知る上で有効だそうです。答えは用意しておきますただし、著者も認めるように、面接での質問は諸刃の剣になり得ます。「あなたが雇用されたら、これらの質問に答えを出してもらいたい」と言われた場合、自分で出した難しい質問に答えなければならなくなるかもしれません。そのような状況に備えて、大まかな答えを用意しておくことが賢明だと著者は述べています。第7章は、SREの仕事を求める人のための実践的なガイドブックでした。著者の豊富な経験に基づく助言は、SREを目指す人にとって心強い道しるべになるはずです。本章を読んで、私は自身の経験を振り返ってみました。確かに、SREの面接では、技術的な質問だけでなく、システム思考やコラボレーションに関する質問も多く出されました。著者が述べているように、SREに求められるスキルは多岐にわたるため、幅広い知識と経験が問われるのだと実感しました。また、面接官としての経験からも、著者の指摘に共感を覚えました。求職者がシステムのボトルネックを特定したり、障害から学ぶ姿勢を示したりするのを見ると、SREとしての資質を感じずにはいられません。逆に、ヒーロー的な振る舞いを美化するような発言には、危険信号を感じることがあります。SREの面接は双方向のコミュニケーション本章で特に印象に残ったのは、SREの面接は双方向のコミュニケーションであるべきだという点です。求職者は、自分のスキルをアピールするだけでなく、その組織におけるSREの役割や課題について積極的に質問すべきだと著者は述べています。時には、面接そのものが、SREの実践の場になり得るのかもしれません。また、著者が 「面接に落ちたら、それを障害対応のように扱ってみよう」 と提案しているのも興味深かったです。確かに、失敗から学ぶ姿勢は、SREにとって不可欠なマインドセットです。面接に落ちたからといって、それで終わりではありません。そこから学びを得て、次のチャンスに生かしていく。そういう前向きな姿勢こそが、SREの真骨頂なのだと感じました。SREの世界に飛び込むのは、勇気のいることかもしれません。でも、その一歩を踏み出す価値は十分にあるはずです。『Becoming SRE』の第7章は、その一歩を後押ししてくれる、頼もしいガイドだと感じました。日々の仕事の中で信頼性への意識を研ぎ澄ますとはいえ、面接対策だけがSREへの道ではありません。日々の業務の中で、信頼性への意識を研ぎ澄まし、技術力を磨いていくことが何より大切なのだと思います。著者も触れているように、SREの面接は、日頃の仕事ぶりの反映に他なりません。だからこそ、普段から「How can I make things better?」という問いを忘れずにいたいものです。システム設計の面接試験作者:アレックス・シュウソシムAmazonChapter 8. A Day in the Life of an SRESREの多様な役割とコラボレーションの重要性本章は、SREの日常業務の章であり、SREという職種の多様性と複雑性を浮き彫りにしています。 著者は、SREの仕事を複数のモードに分類することで、その役割の広がりを示しました。インシデント対応、ポストインシデント学習、ビルダー/プロジェクト/学習、アーキテクチャ、マネジメント、計画、コラボレーション、回復とセルフケアなど、SREは常に状況に応じて異なる仕事のモードを切り替えながら、システムの信頼性を維持・向上させていく必要があるのです。特に印象に残ったのは、コラボレーションモードの重要性についての指摘です。 SREはシステムの信頼性を確保するために、開発者、プロダクトマネージャー、ステークホルダー、ビジネス側の人々など、さまざまな関係者と密接に連携していかなければなりません。SLI/SLOの定義と実装、モニタリングの設計、カオスエンジニアリングの実践など、SREの主要なタスクの多くはコラボレーションを抜きには語れません。著者が強調するように、SREは「容赦なく協調的」であることが求められるのです。SREのワークライフバランスまた、SREの仕事がときに過酷になりがちだという指摘も重要です。 ヒーロー的な働き方を美化する文化的風潮の中で、SREが過剰なワークロードを抱え込み、バーンアウトしてしまうリスクは常につきまといます。著者は、週60-75時間も働くことを自慢げに語る人がいたら、それはシステムの失敗の表れだと考えるべきだと述べています。燃え尽きた人間は、信頼性の高いシステムを構築することができないのです。SREがサステナブルなオペレーションを実現するためには、適切なワークライフバランスを保つことが不可欠だと言えるでしょう。SREの業務バランスSREの業務バランスについての考察も示唆に富んでいました。反復作業と価値ある作業、リアクティブな仕事とプロアクティブな仕事、割り込みの多い仕事と集中できる仕事、個人作業とチームでの作業、危機的状況と平常時など、SREは常に相反する要素のバランスを取る必要があります。 特に新しいサービスを立ち上げる際は、リアクティブな仕事や割り込みが多くなりがちで、エンジニアリング業務に充てる時間を確保するのが難しくなります。状況に応じて柔軟にバランスを取っていく必要がありますが、長期的には業務時間の50%はエンジニアリング業務に充てるべきだというガイドラインは、非常に参考になりました。本章では、SREという職種の技術的な側面だけでなく、コラボレーション、ワークライフバランス、メンタルヘルスなど、さまざまな角度からSREの仕事の実態に迫っています。 SREに求められるスキルや資質の多様性を考えると、SREという職種の奥深さと面白さを改めて感じさせられました。特に、SREがサステナブルなオペレーションを実現するための職種であるという点は重要で、バランスの取れた働き方を目指すべきだという主張には強く共感しました。私たちSREは、常に変化し続ける技術的・組織的環境の中で、複数のモードを行き来しながら、コラボレーションマインドセットを発揮し、適切なバランスを保ちつつ、信頼性の高いシステムづくりに取り組んでいく必要があります。 本章で紹介されていたさまざまな知見を胸に、SREとしてのキャリアを歩んでいきたいと思います。いつも「時間がない」あなたに　欠乏の行動経済学 (早川書房)作者:センディル ムッライナタン,エルダー シャフィール早川書房AmazonChapter 9. Establishing a Relationship to ToilToilを単に「嫌な仕事」と片付けない本章は、SREにとって馴染み深いトピックである「Toil」について、より深く掘り下げた章でした。Toil（単純作業）は、SREの文脈でしばしば登場する概念ですが、その定義や特徴、そして私たちがToilとどのように向き合うべきかについては、これまであまり明確に語られてこなかったように感じます。本章では、Vivek Rauが提示したToilの定義を出発点としつつ、より nuancedで健全なToilとの付き合い方を模索しています。退屈なことはPythonにやらせよう 第2版 ―ノンプログラマーにもできる自動化処理プログラミング作者:Al Sweigartオライリー・ジャパンAmazonまず印象的だったのは、Toil を単に「嫌な仕事」として片付けるのではなく、より精緻に定義しようとしている点です。  Rauによれば、Toilとは、manual（手作業）、repetitive（反復的）、automatable（自動化可能）、tactical（戦術的）、no enduring value（持続的価値がない）、O(n) with service growth（サービスの成長に比例）といった特徴を持つ作業のことを指します。これらの特徴をすべて満たす必要はありませんが、当てはまる項目が多いほど、その作業はToilである可能性が高いと言えるでしょう。また、「誰のToilについて話しているのか」という問いも重要だと指摘されています。  通常、SREが対処しようとしているのは、システムの運用に関わるToil（operational Toil）であり、顧客が直面するToil（customer Toil）ではありません。ただし、顧客のToilを軽減することもSREの新しいフロンティアになり得ると著者は示唆しています。運用のToilと顧客のToilの間には、興味深い関連性があるのかもしれません。Toilに注目する３つの要因次に、SREがToilに注目する理由について、著者は3つの要因を挙げています。  1つ目は、美的感覚（aesthetics）です。SREは、非効率的で不要なToilを根本的に嫌うという特性を持っているのかもしれません。2つ目は、お金（money）の問題です。高度なスキルを持つSREを雇用するコストは高く、彼らにToilではなく価値ある仕事をしてもらうことが組織の財務的利益につながります。3つ目は、時間の使い方と仕事の満足度です。Toilに費やす時間が増えれば、エンジニアリング業務に充てられる時間が減り、SREの仕事の満足度も下がってしまいます。さらに、Toil がサービスの成熟度と関連していることも指摘されています。 新しいサービスほど、モニタリングやアラートの調整が不十分であったり、運用に必要なプロセスの自動化が不足していたりするため、Toil が多くなる傾向があります。サービス立ち上げ初期のToil（Early Toil）と、成熟したサービスに付きまとうToil（Established Toil）を区別することが、Toil削減に向けた戦略を立てる上で重要だというのは、良い視点だと感じました。そして、Toil の削減（あるいは排除）について、著者は興味深い見方を示しています。  よく語られるのは、「Toil を特定し、自動化やセルフサービス化によって排除する」というストーリーですが、著者はこれに疑問を呈しています。Toil は完全に排除できるわけではなく、別の形に姿を変えるだけだというのです。自動化によってToil が減っても、その分、コードの複雑性が増す。セルフサービス化によって運用チームのToil は減っても、その分、Toil が細分化されてユーザー側に分散される。著者はこれを「Toil の保存則」と呼んでいます。  Toil との健全な付き合い方を確立するためには、この保存則を直視する必要があるでしょう。トイルの削減に向けた取り組みを、単一のシステムレベルから、環境全体のクラスレベルに引き上げることも重要だと著者は指摘しています。例えば、新しいサービスをモニタリングシステムにオンボーディングする作業を大幅に簡略化することで、Early Toil を大きく削減できるかもしれません。さらに、過去のToil（established）、現在のToil（early）、未来のToilのどれに有限のリソースを割り当てるかという、時間軸を意識した判断も求められます。Toilとの健全な付き合い方個人的には、「Toil を完全に排除するのではなく、より有害度の低い形に変換していく」という考え方に強く共感しました。  トイルを減らす努力は続けつつも、同時に発生し得る複雑性や、顧客側への影響についても意識しておく必要がありそうです。私自身、SREとして日々Toilと向き合っていますが、それを単に嫌な仕事として捉えるのではなく、サービスの成熟度や技術的負債との関係性を意識しながら、長期的視点でToilの削減に取り組んでいきたいと思います。また、生成AIがこれらの意思決定にどのように影響するのか考える必要があると思っています。本章で得られた知見は、そのための指針になってくれるはずです。面倒なことはＣｈａｔＧＰＴにやらせよう (ＫＳ情報科学専門書)作者:カレーちゃん,からあげ講談社AmazonChapter 10. Learning from Failure障害からの学びはSREの中核的な活動本章は、システムの障害から学ぶことの重要性と、その実践方法について深く掘り下げた章でした。SREにとって、障害からの学びは、適切な信頼性レベルを達成するための中核的な活動だと言えます。 モニタリング/オブザーバビリティ、SLI/SLOによる目標設定、そしてインシデント/アウトリッジ対応という3つの実践が交差する地点に、障害からの学びがあるのだと著者は指摘しています。この学びを通じて、現状（what is）と目標（what should be）のギャップを埋めていくことができるのです。反脆弱性[下]――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonまず印象に残ったのは、障害について語る言葉選びが、私たちの思考や行動に大きな影響を与えるという指摘です。 例えば、「root cause（根本原因）」という言葉は、複雑な障害を単一の原因に帰着させようとする思考を助長しがちです。それに対して、「contributing factors（寄与因子）」という言葉は、障害の複雑性を認識し、多面的な理解を促します。著者が強調するように、SREは障害について語る際の言葉選びにも注意を払う必要があるでしょう。ポストモーテムでも良い次に、ポストインシデントレビュー（PiR）のプロセスについて、詳細な解説がありました。 あ、本書の中でそう言っているだけでポストモーテムが一般的な用語です。ポストインシデントレビューの目的は、インシデントについて徹底的に調査し、関係者間で共通理解を構築しながら、可能な限り多くのことを学ぶことにあります。そのためには、インシデントの詳細な年表を作成し、関係者全員でレビューすることが重要だと著者は述べています。また、レビューの際は、「なぜ」よりも「何が」「どのように」起きたのかに焦点を当てるべきだと指摘しています。「なぜ」を問うことは、原因の特定や対策の検討に性急に走ってしまう危険性があるためです。著者は、ポストインシデントレビューでよく見られる5つの落とし穴についても警鐘を鳴らしています。 「human error（人的ミス）」でインシデントを片付ける、反実仮想的な推論に陥る、結果論で判断する、機械の無謬性を前提とする、ポジティブな側面を無視する、といった点です。これらは、障害の本質的な理解を妨げ、学びを狭めてしまう恐れがあります。私自身、これらの落とし穴に無意識に陥っていたことに気づかされました。レジリエンスエンジニアリングについては、著者が特に重要視している点だと感じました。David Woodsによるレジリエンスの定義は、「不可避な驚きに対応するためにシステムが必要とする能力」というもので、従来のレジリエンス（回復力、耐障害性）の概念を大きく拡張するものです。 レジリエンスを高めるためには、変化や障害に適応するための「適応能力（adaptive capacity）」を、事前に備えておく必要があるのです。私が特に興味深く感じたのは、レジリエンスを「reboundからsustained adaptabilityまでの4段階」で捉える考え方です。 reboundは「障害からの回復」、robustnessは「複雑性やストレスへの対処」、graceful extensibilityは「想定外の事態への適応」、そしてsustained adaptabilityは「進化し続ける環境への継続的適応」を意味します。多くのSREがreboundからrobustnessあたりを目指しているのに対し、レジリエンスエンジニアリングは、その先のgraceful extensibilityやsustained adaptabilityまでを視野に入れているのだと理解しました。また、Safety-IIやSafety-IIIといった概念も紹介されていました。 Safety-IIは、「うまくいっているときに何が起きているのか」に着目することで、障害を未然に防ぐアプローチです。Safety-IIIに至っては、「成功から学ぶ」ことで、失敗を防ぐという画期的な発想だと言えます。私たちSREは、障害対応に追われるあまり、普段うまくいっていることの分析を怠りがちです。レジリエンスエンジニアリングの知見は、そうしたマインドセットを変える上でも示唆に富んでいると感じました。著者も指摘するように、レジリエンスを「動詞」として捉えることが重要だと思います。 レジリエンスは、ただ備わっている特性ではなく、絶え間ない実践によって培われていくものです。障害を避けられない以上、私たちにできることは、レジリエンスを高める営みを続けていくことです。そのためには、レジリエンスエンジニアリングの知見を深く理解し、SREの文脈に適用していく努力が求められるでしょう。レジリエンスエンジニアリングの知見を吸収し活用する私自身、これまではレジリエンスを「回復力」程度の意味で捉えていましたが、本章を読んで、その概念の奥深さに気づかされました。システムのレジリエンスを高めることは、SREの本質的な使命だと言えます。 障害から学ぶことは、そのための重要な一歩です。しかし、それだけでは不十分で、平時のシステムの挙動から学ぶことも欠かせません。レジリエンスエンジニアリングの知見を積極的に吸収し、SRE文化に取り入れていくことが、これからのSREに求められているのだと強く感じました。さらに、カオスエンジニアリングについても言及がありました。 カオスエンジニアリングとは、本番環境で意図的に障害を引き起こし、システムの挙動を理解する取り組みです。単なる「破壊」ではなく、仮説に基づいた意図的な実験であることが重要だと著者は述べています。想定外の事態に備えるための力を養う上で、カオスエンジニアリングは欠かせないアプローチだと感じました。最後に、ポストインシデントレビューで得られた学びを組織全体に広げるための具体的な方法が紹介されていました。 「ブッククラブ」「ニュースレター」「プロダクションレディネスレビューへの反映」「メタ分析とML」など、どれも良いアイデアだと感じました。せっかく得た貴重な学びを、ドキュメントに埋もれさせてはいけません。組織の隅々にまで浸透させる工夫が求められます。全体を通して、障害からの学びがSREの中核的な活動である一方で、それを実践することの難しさも再認識させられました。 言葉選びひとつとっても、私たちの無意識のバイアスが入り込む余地があります。学びを最大化するためには、レジリエンスエンジニアリングやカオスエンジニアリングといった周辺領域の知見も積極的に取り入れていく必要がありそうです。私自身、これまでのキャリアの中でポストインシデントレビューに数多く参加してきましたが、本章で得た学びを胸に、より効果的な障害からの学びを実践していきたいと思います。個人としてだけでなく、チームや組織体としての学びを促すことが、SREに求められる重要なスキルなのだと再認識しました。世界のエリートがIQ・学歴よりも重視！　「レジリエンス」の鍛え方作者:久世 浩司実業之日本社AmazonPart III. Becoming SRE for the OrganizationChapter 11. Organizational Factors for SuccessSREの導入には組織のあり方そのものの見直しが必要な時もある本章は、SREの導入を成功に導くための組織的要因について、非常に良い考察を提示していました。単に技術的なベストプラクティスを導入すれば事足りるわけではなく、組織のあり方そのものを見直す必要性を説得力を持って訴えかけています。著者が最初に問いかけるのは、「SREが解決できる問題を組織が抱えているか」という点です。 具体的には、システムの信頼性の低さ、アウテージ対応の非効率、過剰な運用負荷といった、SREのアプローチが真に効力を発揮できそうな課題を特定することが重要だと指摘しています。SREを導入すれば万事解決すると楽観視するのではなく、その手法が組織の痛点に適合するかを見極める必要があるのです。次に重要な問いは、「その問題を解決するために、組織は実際に何をする覚悟があるか」です。 SREはバズワードとして華やかに語られがちですが、本当の意味で組織に根付かせるには、相応の覚悟と行動が求められます。著者は具体的な問いを投げかけます。信頼性向上のためにエンジニアリングリソースを割けるか。機能開発を後回しにしてでも、インシデント対応の改善に注力できるか。SLOが未達の際、新機能のリリースを躊躇なく延期できるか。ポストモーテムを形骸化させない努力を惜しまないか。オンコール体制は人間的で持続可能なものになっているか。SREがソースコードにアクセスし、信頼性向上に必要な変更を加えられるか。こうした一つ一つの問いに正面から向き合わなければ、SREの真価は発揮できないと著者は警鐘を鳴らしているのです。SREは技法や手法だけでできたら苦労はしねぇまた、SREの効果が表れるまでの「忍耐力」も重要だと指摘しています。 DORAのState of DevOps Report 2023 でも示されているように、信頼性向上の取り組みが実を結ぶまでには一定の時間がかかるものです。短期的な成果を求めるあまり、腰を据えた取り組みを続けられなければ、折角の努力も水泡に帰してしまいます。だからこそ、地道な改善を積み重ねつつ、長期的なゴールを見据える忍耐強さが組織に求められるのです。SREが真に力を発揮するには、組織のあらゆるレイヤーでの「協調性」も欠かせません。 開発チーム、ビジネスサイド、ステークホルダーなどと有機的に連携しながら、信頼性の向上を追求していく必要があります。部署間の壁を越えて協調できる組織文化があるか。SREが他チームのコラボレーションツールに参加できるか。モニタリングやオブザーバビリティのツール選定に SREの意見は反映されているか。そうした具体的な協調性の発露が、SREの成功を左右すると著者は指摘するのです。また、SREにとって「データ駆動の意思決定」は生命線とも言えます。 モニタリングの重要性を説き、その結果を改善アクションに直結させる。そのためには、データの可視化や分析を習慣づけ、意思決定プロセスに組み込む組織文化が不可欠です。エラーバジェットの概念も、まさにデータに基づく意思決定の具現化だと言えるでしょう。こうしたデータ駆動のマインドセットが組織に根付いているかを見極める必要性を、著者は説いているのです。失敗から学ぶ姿勢も、SREの生命線の1つです。 形骸化したポストモーテムではなく、真摯に失敗の教訓を汲み取り、改善に活かすサイクルを回していく。それも1つのチームに閉じた学びではなく、組織の壁を超えて知見を展開していく。そうした失敗からの学びを組織の文化として定着させられるかどうかが、SREの成功を分けると著者は指摘します。インシデントの振り返りが義務的なタスクと化していないか。関係者が建設的に議論できているか。導き出された教訓が確実にアクションに結びついているか。こうした具体的な問いを投げかけることで、組織の学習力を見抜くことができるのです。SREの真価を発揮するための組織体制そして、SREが真の力を発揮するには、現場レベルでの「変化を起こす力」も欠かせません。 ドキュメントの改善から、コードやインフラの変更、ツールの選定、採用プロセスの見直しに至るまで、SREが信頼性向上のために必要な施策を機動的に実行に移せる環境が整っているかどうか。それは、SREの役割への信頼と、裁量の広さの表れだと言えます。もちろん、すべてを自由に変更できる必要はありません。しかし、SREの専門性を活かして、システムを改善していく力を組織が認めているかは、重要なバロメーターになります。加えて、システム内の「摩擦」を発見し、取り除いていく感度の高さも重要だと著者は説きます。 障害対応に2時間もかかるのに、サービス可用性の目標値は99.99%といった矛盾。開発者とオペレーション担当者の間の連携不足。旧態依然としたマニュアル作業の残存。そうした非効率や齟齬を嗅ぎ分け、改善を促していく感性がSREには求められます。リスクを放置すれば、いずれ大きな障害を招きかねません。だからこそ、摩擦を見抜き、取り除く意識を組織全体で醸成していく必要があるのです。結局、組織じゃんって話そして著者は、SRE導入の成否は結局のところ「組織の価値観」に集約されると結論付けています。 どんなにSREの手法を形式的に取り入れても、組織の根幹にある価値観と融和しなければ、長続きはしません。信頼性を重視する文化、学習を尊ぶ姿勢、協調性、変化への適応力。そうした価値観が組織のDNAレベルで共有されている必要があるのです。Googleでの SREの成功も、同社のエンジニアリング文化と価値観があってこそだったと著者は指摘します。組織の価値観とSREの理念が合致することが、成功の大前提なのです。SREの導入は、技術的側面だけでなく、組織文化や価値観のレベルでの変革を必要とする壮大な挑戦だと改めて感じさせられました。一朝一夕には成し遂げられない困難な道のりですが、その実現のためには、本章で示された指針に一つ一つ向き合っていく必要があります。SREと真に相性の良い組織を作り上げるには、骨太の問いを自らに投げかけ、その答えを見出す誠実さを業務で体現できればと思いました。Chapter 12. How SRE Can FailSREの失敗は組織全体にネガティブな影響を及ぼしかねない本章は、SREの導入と実践における失敗のシナリオを赤裸々に描き出した、良い章でした。著者は、SREの失敗が、単なる信頼性向上の取り組みの頓挫にとどまらず、組織全体がSREを拒絶するような深刻な事態を招きかねないと警鐘を鳴らしています。私たちは、SREという\"処方箋\"を手にしたからといって、安穏としてはいられません。その処方箋の効果を十分に引き出すには、組織の隅々にまで浸透させる地道な努力が欠かせないのです。印象的だったのは、SREの導入を「肩書の変更」だけで済ませようとする安直なアプローチへの警告です。開発者やサポートエンジニアの肩書をSREに変えるだけでは、役割や文化に実質的な変化は生まれません。むしろ、形骸化したSREチームが、開発現場の足を引っ張るリスクすらあります。SREは、単なる看板の掛け替えではなく、価値観、トレーニング、リソース配分、コミュニケーションの在り方などを根本から見直す覚悟なくして、成功しないのです。同様の罠は、既存のTier 3サポートチームをそのままSREチームに転換しようとする試みにも潜んでいます。サポートチームの役割は、エスカレーションされた難解な問題を解決することであり、システムの信頼性を根本から高めるフィードバックループを作り出すことではありません。単なる看板の掛け替えでは、開発チームとの建設的な協働は生まれず、SREの真価を発揮できないままに終わるでしょう。著者が指摘するように、SREへの転換は、チームの使命と働き方を抜本的に見直す取り組みでなければならないのです。SREは失敗をどう扱うのか？また、SREの役割をオンコール対応だけに矮小化するのも危険だと著者は訴えかけています。確かにインシデント対応は、システムの弱点を学び、改善につなげる重要な機会です。しかし、それだけがSREの存在意義だと誤解されては本末転倒です。開発者の負担を軽減するための「例外処理係」としてSREを使うのは論外ですし、システム改善から切り離されたオンコールでは、SREのポテンシャルを十分に引き出せません。SREは、オンコールから得た学びを、信頼性向上のための施策に着実に結びつけてこそ、真価を発揮できるのです。組織のトップレベルで、機能開発とSREによる信頼性向上のバランスをコントロールできる体制の欠如も、SREを失敗に導く要因として指摘されています。開発チームとSREチームのリーダーが、同じエンジニアリング責任者の下に位置していれば、feature workとSREの優先順位をその場その場で適切に判断できるはずです。しかし、両者の調整に上層部の決裁が必要になれば、SREの機動力は大幅に削がれてしまいます。組織のヒエラルキーがSREの足を引っ張ることのないよう、意思決定プロセスをシンプルに保つ工夫が欠かせません。Googleの実践をそのまま自社に当てはめようとする安直なアプローチも、失敗のリスクを孕んでいると著者は指摘します。Googleの書籍から学ぶことは多いですが、自社の文化や特性を無視してそのまま導入しても、うまくいくはずがありません。SREはGoogleの価値観の反映であり、他社が同じことをしたからといって、同じ成果が得られる保証はないのです。大切なのは、Googleの実践に範を求めつつも、自社独自のSREを見出していくこと。時には、Googleとは異なる道を選ぶ勇気も必要になるでしょう。SREがゲートキーパーと化すことも、大きな落とし穴だと著者は述べています。プロダクションリリースの可否を判断する\"門番\"としてSREが君臨すれば、開発チームとの対立は避けられません。SREが「get to \"no\"」の存在になれば、開発者はSREを障害物とみなし、迂回する方法を編み出そうとするでしょう。SREは、開発チームの創造性を阻害するのではなく、reliability-minded cultureを醸成するパートナーとして振る舞う必要があります。SREの成功が仇となって自滅するケースにも目を向けています。実績を上げたSREチームがあれば、つい何でも任せたくなるものです。しかし、それではSREチームはたちまち疲弊し、モチベーションを失ってしまいます。SREがシステムの面倒を一手に引き受ける\"heroもの\"になれば、開発チームの当事者意識は薄れ、システムは脆弱化の一途をたどるでしょう。SREはあくまで開発チームとの協働によって真価を発揮する、ということを肝に銘じる必要があります。また、目に見えづらい改善の積み重ねや、お客様視点の欠如、日々の楽しさの喪失など、些細な障害の集積がSREを衰退させる可能性も示唆されていました。SREの仕事は、日々の地道な努力の積み重ねです。トラブルが減れば減るほど、その存在価値が見えづらくなるのは宿命と言えます。だからこそ、自らの成果を可視化し、社内外にアピールし続けることが肝要なのです。単に社内の評価を高めるためだけでなく、自らの仕事のやりがいを再確認するためにも、これは欠かせない活動だと感じました。全体を通して、SREの道のりが平坦ではないことを思い知らされる章でした。様々な落とし穴が私たちを待ち受けています。肩書だけの変更、不適切なチーム改編、オンコール偏重、ゲートキーピング、Googleの無批判な模倣、業務の押し付け、目に見えない成果、お客様視点の欠如、楽しさの喪失。どれ一つとっても、SREを脆弱化させ、組織から拒絶されるリスクを孕んでいます。SREの失敗から立ち直るためのマインドセットしかし、だからこそSREには果敢にチャレンジする価値があるとも感じました。SREの道は険しいかもしれません。思うように物事が運ばないこともあるでしょう。しかし、SREたるもの、困難から目を背けるわけにはいきません。「SREが組織に拒絶されつつある」という兆候を感じたら、インシデント対応のように、適切なstakeholderを招集し、早期の軌道修正を図る。失敗から立ち直れなかった時は、ポストモーテムのように、徹底的に原因を究明し、教訓を次に活かす。SREのマインドセットとスキルは、まさに逆境を乗り越えるために磨かれてきたのです。とはいえ、組織の理解と協力なくして、SREの成功はあり得ません。セイリングで「向かい風でも、風を読めば前に進める」と言われるように、私たちは、SREへの\"向かい風\"を嘆くのではなく、それを追い風に変える知恵を持たねばなりません。失敗の芽を早期に発見し、軌道修正を図る感度の高さ。組織の価値観に働きかけ、開発チームとの信頼関係を築き、お客様の視点を第一に考える粘り強さ。そうした資質を私たち自身が体現することで、自社ならではのSREを根付かせていくことができるはずです。向かい風を利用したダッキングの仕組みは知識さえあればどんな状況も好転する可能性を秘めている例としてとても良いので雑学科学読本　身のまわりのすごい技術大百科から引用させて下さい。雑学科学読本　身のまわりのすごい技術大百科 より引用失敗の先にある成功を信じて、これからもSREの旗を高く掲げ続けたい。本章で赤裸々に描かれた数々の失敗シナリオは、SVレベルの人にこそ読んでもらいたい内容だと感じました。システムの信頼性は、一SREチームだけで達成できるものではありません。開発、オペレーション、マネジメントが一丸となってこそ、真の信頼性は生まれるのです。私たちSREは、荒波にも負けず、組織を信頼性の高い未来へと導く舵取り役でありたいと願っています。ただ単にGoogleが提唱するSREの手法を模倣するのではなく、それぞれの独自性を活かしたSREとしての旅路を歩みたいと思います。この道のりは、組織の隅々にわたってSREの価値観を浸透させることで、目指すべき信頼性という大海原へと進む冒険です。この考え方を共有するために、同僚が『あなたらしくSRE』というテーマでの発表を行い、大変示唆に富む内容でしたので、その資料をここで紹介します。また、netmarkjpさんによる、現場主導で進化するSREのあり方をテーマにした一連の資料も大変参考になります。具体的には、『現場がさき、プラクティスがあと、原則はだいじに』には、現場のニーズを優先しつつ、SREのプラクティスを展開していく重要性が述べられています。『SREsのためのSRE定着ガイド』では、SREが組織内で定着し、根付いていくための具体的なガイドが提供されています。さらに、『SREこのへんで苦戦しがちじゃないですか？』では、SREが直面しがちな困難に対する洞察と対処法が紹介されています。これらの資料は、それぞれの組織やチームが直面する独自の課題に対して、柔軟かつ効果的に対応するためのヒントやインスピレーションを提供してくれるはずです。私たち一人ひとりがSREとして成長し、組織全体の信頼性を高めていくために、これらの資料をぜひ活用してください。 speakerdeck.comChapter 13. SRE from a Business Perspective信頼性はサービスの最も重要な機能本章は、SREという技術的な役割を、ビジネスの観点から捉え直した、良い富む章でした。SREの実践は、単に技術的な信頼性の向上だけでなく、組織の成長や競争力強化にも直結する重要な取り組みだと再認識させられました。著者が対談したBen LutchとDave Rensinの両氏は、Googleという最先端のIT企業で、SREチームのリーダーを長年務めてきた人物です。彼らの知見は、SREをビジネスの文脈で語る上で、非常に良い章です。まず印象的だったのは、「信頼性はサービスの最も重要な機能である」という指摘です。顧客がサービスを使い続けるためには、その信頼性が何よりも大切だと言えます。SREは、その信頼性という機能の実現に特化したエンジニアリングチームだと位置づけられるのです。機能開発と信頼性向上は二律背反ではなく、SREという専門チームを設けることで、両者を高いレベルで両立できるというのは、良い視点でした。また、SREの存在意義を測る物差しとして、エラーバジェットの概念が重要だと指摘されていました。サービスの稼働率を100%にするのではなく、ビジネス上許容できる停止時間を設定し、それを超えない範囲でサービスを運用する。この考え方は、SREが目指す現実的な信頼性の追求方法だと感じました。エラーバジェットの消費率を追跡することで、SREチームの価値を可視化し、経営層を納得させることができるというアイデアは、示唆に富んでいます。SREチームの予算確保の際は、組織が抱える課題を起点に議論することが肝要だと著者は述べています。漠然と「SREの予算が欲しい」と訴えても、説得力に欠けます。「ここ数ヶ月で発生した障害は許容できないレベルにあります。それを防ぐために、最低限このくらいのリソースが必要だ」といった具体的な問題提起が求められます。また、SREがもたらすインパクトを、顧客体験や機会損失の回避といったビジネス指標に言い換える工夫も大切だと感じました。一方で、SREチームが陥りがちな落とし穴についても言及がありました。デベロッパーから問題をすべて丸投げされ、単なる「ページャーモンキー」と化してしまう。改善活動がおろそかになり、問題対応に明け暮れる「トイルバケツ」になってしまう。こうした事態に陥らないよう、常にSREの役割と価値を組織に示し続ける必要があるのだと実感しました。また、SREチームのヘッドカウントについても、良い議論がありました。「開発者を残業から解放したい」といった安易な動機でSREチームを肥大化させるのは賢明ではありません。あくまで、サービスの信頼性目標の達成に必要十分な人員を確保することが肝要です。一方で、疲弊しすぎず、エンジニアリング活動に注力できる最低限の人数は確保すべきだとも述べられています。ビジネスの要請とSREの働き方のバランスを取ることの難しさを感じさせられました。SREの価値を経営層に伝え続けることの重要性全体を通して、SREの価値を経営層に伝え、組織に定着させていくことの重要性を再認識した章でした。技術的な側面だけでなく、ビジネスの文脈でSREの存在意義を示し続けることが、その役割を確立する上で欠かせません。とはいえ、そこに正解はなく、各組織の状況に合わせて、試行錯誤していくことが求められるのだと感じました。SREという役割に惹かれて飛び込んできた私たちエンジニアにとって、ビジネスの観点は、ともすれば苦手意識を持ちがちな領域かもしれません。しかし、本章で紹介されていたフレームワークは、経営層とのコミュニケーションを助けてくれる強力な武器になるはずです。SLOに基づくサービス運用、エラーバジェットによるインパクトの可視化、ビジネス課題起点の要員計画。そうした考え方を身につけることで、SREとしてのキャリアをより確かなものにしていけるでしょう。私自身、まだまだ経験の浅いSREですが、この章で得られた学びを胸に、技術とビジネスの両面でのSREの価値向上に努めていきたいと思います。開発チームと経営層の間に立ち、両者の言葉を翻訳しながら、信頼性というゴールに向かって組織を牽引していく。そんなSREのあるべき姿が、この章を通して見えてきたように感じています。単に技術的なスキルを磨くだけでなく、ビジネスの文脈でSREの価値を語れるエンジニアになること。それが、これからのSREに求められる資質なのかもしれません。経営層の期待に真摯に向き合いつつ、現場のエンジニアリングにも手を抜かない。 その両立は容易ではありませんが、その先にこそ、SREのやりがいがあると信じています。著者も述べているように、SREをビジネスの文脈で語ることは、まだまだ探求の余地がある領域だと感じました。一人一人のSREが、自らの経験を言語化し、共有し合うことで、その知見体系はさらに洗練されていくはずです。私も微力ながら、その営みに貢献していければと思います。技術の力で、ビジネスの信頼を勝ち得る。本章はそんなSREの新たな可能性を感じさせてくれる内容でした。エンジニアリングの高みを目指すと同時に、ビジネスの言葉を学び、組織への貢献を示し続けること。それがこれからのSREに求められる道なのだと感じています。Chapter 14. The Dickerson Hierarchy of Reliability (A Good Place to Start)信頼性向上の第一歩としての The Dickerson Hierarchy of Reliability本章は、SREを導入したばかりの組織が、何から着手すべきかを示してくれる指針を示してくれる章でした。著者のDavid Blank-Edelman氏は、システムの信頼性を高めるための取り組みは山のようにあるものの、その中から成果の上がる一歩を見出すのは容易ではないと指摘します。 そこで、この難題に対する最良の答えとして紹介されているのが、Mikey Dickersonが提唱した「The Dickerson Hierarchy of Reliability」です。ちなみに公式にもサービス信頼性の階層があります。Figure III-1. Service Reliability Hierarchy https://sre.google/sre-book/part-III-practices/ より引用この階層モデルは、信頼性向上に向けた取り組みを、monitoring/observability、incident response、postincident review、testing/release、provisioning/capacity planningの5つのレベルに分類しています。 そして、マズローの欲求段階説になぞらえて、下位のレベルから着実に積み上げていくことを推奨しているのです。シンプルながらも良いフレームワークだと感じました。印象的だったのは、最も重要な基盤としてmonitoring/observabilityが位置づけられている点です。 システムの現状を可視化し、改善の方向性を定める上で、モニタリングは欠かせない基盤になります。加えて、チーム内での建設的な議論を促し、SLOの設定を支えるなど、モニタリングが果たす役割の広がりにも気づかされました。また、著者がpostincident reviewを\"transformative\"かつ\"magical\"なプロセスだと称賛している点も印象的でした。 障害対応は、ともすれば時間と労力の無駄になりがちです。しかし、そこから学びを得て、システムを改善につなげられれば、むしろ価値を生み出せるのだと。レジリエンスエンジニアリングの知見を応用し、障害から学ぶ文化を組織に根付かせることの重要性を、改めて感じさせられました。もちろん、この階層モデルは、SREの業務すべてを網羅しているわけではありません。著者自身、モデルの限界を認めつつ、アーキテクチャやtoil改善におけるSREの貢献にも言及しています。 ただ、SRE導入の初期段階では、まずはこの5つのレベルに注力し、確実な成果を積み重ねていくことが肝要なのだと感じました。一方で、著者はSRE導入の過程で陥りがちな落とし穴についても警鐘を鳴らしています。 例えば、オンコール対応だけが仕事になり、「ページャーモンキー」と化してしまう。postincident reviewに偏重し、ソフトウェアライフサイクル全体への関与が疎かになる。crisisの対応に明け暮れ、smokejumperに成り下がる。SREがただの「エンジニア」とみなされ、開発チームに引き抜かれる。こうした兆候は、SREの価値を大きく毀損してしまうリスクを孕んでいます。とはいえ、SRE導入の道のりが平坦ではないことは、私自身、身をもって実感しているところです。大切なのは、地道な改善の積み重ねを通じて、組織にSREの存在価値を示し続けること。 オンコールの引き受けから始まった関係が、pull requestを通じた開発への貢献へと深化していく。モニタリングの指標がチームの共通言語となり、障害が減っていく。そうした目に見えるインパクトを着実に生み出していくことが、SREの評価を高める近道になるのだと感じました。全体を通して、体系立てて信頼性向上に取り組む上で、The Dickerson Hierarchy of Reliabilityが強力な羅針盤になり得ることを実感した章でした。 網羅的とは言えないまでも、スタートダッシュを切る上での重要な指針が凝縮されていると感じます。SREの真骨頂は試行錯誤にありただ、マニュアル通りにここまでやればOKというものでもないのがSREの面白さでもあります。 各組織のコンテキストに合わせて、創意工夫を重ねながら、hierarchy外の領域にもフロンティアを広げていく。その探究心こそが、SREたるゆえんなのかもしれません。私自身、ここ数年、監視基盤の整備や、incident responseの体制づくりに注力してきました。今後は、そこで得た知見を開発プロセスにも反映させつつ、proactiveなケイパシティプランニングにも踏み出していきたいと考えています。その過程では、様々な試行錯誤を重ねることになるでしょう。ただ、その試行錯誤こそがSREの真骨頂だと信じています。 ピラミッドを一歩ずつ登りながら、いつの日か、その頂へと辿り着けるよう、これからも研鑽を積んでいきたいと思います。Figure 14-1. Slightly modified version of the Dickerson Hierarchy of Reliability より引用著者が最後に投げかけてくれた「SREがうまくいっている兆候」も、私にとって大きな励みになりました。自分たちの存在が当たり前のように受け入れられ、モニタリングの指標が部門の共通言語になり、開発への貢献が目に見える形で認められる。そんな日が来るまで、地道に信頼性向上の階段を上っていきたいと思います。The Dickerson Hierarchy of Reliabilityは、SREという旅路に不可欠な道標だと感じました。 ただ、その先に広がるのは、各組織が切り拓くオリジナルのロードです。ゴールのない旅だからこそ、一歩一歩を大切にしながら、信頼性というバトンを手渡していく。私もその輪の中で、自分なりの道を見出していけたらと思います。Chapter 15. Fitting SRE into Your OrganizationSREの導入には組織のカルチャーや構造とのフィット感が重要本章は、SREを組織に導入する際の実践的な指針を提示してくれた章でした。SREの導入は、単なる技術的なプラクティスの適用にとどまらず、組織のカルチャーや構造とのフィット感を意識しながら、戦略的に進めていく必要があるのだと実感させられました。特に印象に残ったのは、SREの導入に際して、いきなり専任チームを立ち上げるのではなく、まずはSREの考え方や手法を、日々の業務の中で部分的に試してみることを推奨している点です。 例えば、サービスのSLI/SLOを定義してみる、ポストモーテム分析のやり方を見直してみるなど、小さな一歩から始められます。そうした草の根の取り組みを通じて、SREのメリットを組織に示しつつ、本格的な導入への足がかりを作っていく。地に足のついた漸進的なアプローチだと感じました。もちろん、環境次第では、いきなりSREチームが編成されたり、M\u0026Aを通じてSREが編入されたりすることもあるでしょう。 そうした状況でも、SREの働き方を「実験」と位置づけ、仮説検証を重ねながら、最適解を模索していくマインドセットが大切だと述べられています。完璧なモデルなんてないのだから、試行錯誤を恐れずに、組織にフィットする形を追求していこうと。アジャイル的な考え方に通底するものを感じました。また、SREの組織的な位置づけについても、良い議論がありました。 中央集権型、分散型、ハイブリッド型の3つのモデルが紹介され、それぞれの長所と短所が丁寧に分析されています。組織の規模や成熟度、過去の前例などを考慮しつつ、自社に合ったモデルを選ぶ必要があるのだと。ただ、どのモデルを選ぶにしても、開発チームとSREチームが協調的に連携し、継続的な改善を推進できる体制を築くことが肝要だと強調されていました。そして、SREの真価は、組織内にフィードバック ループを張り巡らせ、回し続けることにあると著者は力説しています。 モニタリングや障害分析、カスタマーサポートのチケットなど、あらゆるデータをループの起点にできます。そこから学びを得て、システムを改善する。その改善が新たなデータを生み、さらなる学びにつながる。そんな好循環を生み出し、加速させていくことこそが、SREに期待される役割なのです。そのためには、データへのアクセス性を高め、部署間のコラボレーションを促し、改善業務をロードマップに組み込む努力も欠かせません。地道ながらも着実な一歩を重ねることで、徐々にフィードバックの文化が組織に根付いていくのだと感じました。さらに、SREがシステム開発の初期段階から関与し、「ゴールデンパス」と呼ばれる信頼性の高い設計を織り込んでいくことの重要性も説かれていました。 開発チームと二人三脚で課題解決に当たれば、SREの存在価値を浸透させやすくなります。単に既存システムの問題を後追いするのではなく、要件定義の段階からSREの知見を活用する。それこそが、本来あるべきSREの姿なのかもしれません。一方で、著者はSREの導入が軌道に乗っているかを測る「サインポスト」についても言及しています。 SREチームがゲートキーパー的な立場から脱却できているか。開発チームから自発的にSREの関与を求められるようになったか。ロードマップ策定にSREが参画できているか。リアクティブな仕事が減り、プロアクティブな改善が増えているか。そうした兆候は、SREが組織に根付きつつあることを示唆するバロメーターになるはずです。全体を通して、SREの導入は単なるエンジニアリング手法の変更ではなく、組織文化そのものの変革だと実感させられました。 信頼性を重視する価値観、学習と改善を尊ぶ姿勢、部門の壁を越えた協働。そうしたマインドセットを組織の隅々にまで浸透させていく営みが、SREの真髄なのだと。気を整え 拝み 祈り 構えて 突くもちろん、それは一朝一夕で成し遂げられるものではありません。適切なモデル選択に始まり、土壌づくり、フィードバックループの確立、協調的な文化の醸成に至るまで、多岐にわたる課題にじっくりと向き合う必要があります。 技術的なスキルに加え、コミュニケーション力、調整力、課題発見力など、エンジニアリング以外の資質も問われるでしょう。ただ、だからこそ、SREの可能性は無限に広がっていると感じています。従来の枠を越えて、開発とオペレーション、ビジネスとエンジニアリングの架け橋となる。変化を恐れず、失敗から学びながら、より高い信頼性を追求していく。DX時代のビジネスを支える屋台骨を作り上げていく。 それは、私たちソフトウェアエンジニアに託された、困難だけれどもやりがいに満ちたミッションではないでしょうか。本章で提示された知見を道標に、自分なりのSREを模索する旅を続けていきたいと思います。技術とプロセスと文化が三位一体となった、真に強靭な組織を目指して。時には試行錯誤を重ねながらも、仲間やお客様とともに一歩ずつ前進していく所存です。データに基づく意思決定の習慣を根付かせるSREの実践SREの実践は、組織に新たな風を吹き込む触媒になるはずです。データに基づく意思決定の習慣、継続的な改善のサイクル、部門を越えた活発な議論。そうした文化が根付けば、システムの信頼性を高めるだけでなく、ビジネス全体の俊敏性と回復力を引き上げることができるでしょう。 外的な変化への適応力を武器に、競争を勝ち抜いていく。そんな強靭な組織をエンジニアリングの力で実現する。それこそが、DX時代におけるSREの使命だと感じています。もちろん、そこに至る道のりは平坦ではありません。従来の仕事のやり方を変えることへの抵抗、部門間の壁、複雑に絡み合ったレガシーシステム。SREの導入を阻む要因は、組織に深く根を下ろしています。それでも、私たちには武器があります。 学習と適応の文化を組織に根付かせる力、データの言葉で説得する力、人と人をつなぎ共感を生む力。SREに不可欠なのは、技術的なスキルに留まらない、そうした総合的な力なのだと信じています。この章を読み、改めてSREの意義と価値を再認識するとともに、その実現の難しさにも思いを馳せました。とはいえ、困難があるからこそ、そこに果敢に挑戦する意味があるのかもしれません。ソフトウェアエンジニアとして、ビジネスパーソンとして、時にはカウンセラーとして。 様々な顔を使い分けながら、組織にSREの種を蒔いていく。失敗を恐れず、仮説検証を重ねる。その積み重ねの先に、真に信頼性の高い組織と、自分自身の成長が待っているはずです。それは、GoogleやFacebookの真似をすることでは決して達成できない、自分たちオリジナルのSREへの旅になるでしょう。一筋縄ではいかない難題にも、仲間と知恵を出し合いながら、前向きに取り組んでいきたい。組織への共感を武器に、技術の力でレガシーな体質を変革していく。 そんなSREの理想図を胸に、今日も私は一歩を踏み出します。カイゼン・ジャーニー たった1人からはじめて、「越境」するチームをつくるまで作者:市谷 聡啓,新井 剛翔泳社AmazonChapter 16. SRE Organizational Evolutionary StagesSREは組織全体のマインドセットと文化の変革を必要とする本章は、SRE組織の成熟度モデルを提示することで、各組織がSREの導入と定着においてどの段階にあるのかを見定め、次のステップに進むための指針を示してくれる、良い章でした。SREは、単に技術的なプラクティスを導入すれば完成するものではありません。組織全体のマインドセットと文化を変革していく、息の長い取り組みだと改めて認識させられました。SRE ではないのですがCloud Native Computing Foundation（CNCF）も成熟度に関する「クラウドネイティブ成熟度モデル」のドキュメントをWebサイトで公開したり。Googleさん やサイバーエージェントさんがそれぞれ、公開していたりもします。※登壇したりしてました speakerdeck.comSRE組織の5段階の成熟度モデル私が特に印象に残ったのは、著者が提示した SRE組織の5段階の成熟度モデル です。Stage 1: The Firefighter:消防士Stage 2: The Gatekeeper:ゲートキーパーStage 3: The Advocate:提唱者Stage 4: The Partner:パートナーStage 5: The Engineer:エンジニアこの分かりやすいフレームワークは、自組織のSREの取り組みを客観的に評価し、次のステージに進むための課題を明らかにする上で、強力なツールになるはずです。Chapter 16 \"SRE Organizational Evolutionary Stages\"は、SRE組織の成熟度を5つのステージで捉えた、良いフレームワークを提示してくれました。著者のBenjamin Purgasonは、自身の経験から導き出したこのモデルを通じて、SRE組織が辿る進化の道筋を明らかにしています。まず、ほとんどのチームが通過する ステージ1の「消防士」について、印象深い指摘がありました。 このフェーズでは、SREチームは日々発生する信頼性の問題に追われ、火消しに明け暮れます。重大な障害を食い止めるために、泥臭い努力を重ねる毎日。著者はこの状態からの脱却に、早くて数ヶ月、通常は数年かかると述べています。 つまり、SREチームの多くが不可避的に通る、苦難と忍耐の時期なのです。ただし、その間もただ受け身になっているだけではいけません。著者は、火事の合間を縫って、システムの理解を深めたり、「自動消火システム」を整備したりすることの重要性を説いています。 例えば、オートスケーリングの導入、負荷分散の最適化、自動フェイルオーバーの仕組み作りなど。泥沼から這い上がるために、地道な改善を積み重ねる。そうした努力なくして、次のステージへの移行は望めないのです。ステージ2の 「ゲートキーパー」における議論です。 ここでは、SREチームが変更管理の判定者や実行者となり、開発チームとの軋轢を生むリスクが指摘されています。プロダクションを守るためとはいえ、長期的に見れば、SREがゲートキーパーに留まるのは得策ではありません。開発者を不快にさせ、コラボレーションを阻害し、生産性を損なう。 そんな事態を招かないためにも、ゲートキーピングを自動化し、開発者と協調的な関係を築くことが肝要なのだと説かれていました。ステージ3の 「提唱者」 における「インテリジェントなリスクを後押しするツールの構築」 という発想も印象的でした。ダッシュボードやスコアカードを通じて十分なコンテキストを提供することで、現場の全社員が賢明な意思決定を下せるようにする。管理統制に頼るのではなく、「文脈」を武器に、自律的な判断を促していく。そんなSREの在り方に、大いに共感を覚えました。ステージ4の「パートナー」では、SREと開発者の関係が、真の協働へと昇華していきます。 単に役割分担するだけでなく、ロードマップや計画策定から一緒に取り組む。SREは信頼性に関わる共通基盤の構築に注力し、開発者はその恩恵に与りつつ、より高い信頼性を追求していく。そこには、対等なパートナーとしての関係性が育まれているのです。SREと開発者が心を一つにして、高い理想に向かって邁進する。そんな姿は、まさにSREのあるべき姿だと感じました。ステージ5の「エンジニア」の段階になると、SREと開発者の区別はほぼ無くなります。 全てのエンジニアが、システムのライフサイクル全体を通して、信頼性向上に資する活動に自発的に取り組むようになる。もちろん、SREは信頼性に特化した責務を担い続けますが、開発者との間に高度な結束と協調が生まれているのです。理想の姿ではありますが、インセンティブと組織構造のアラインメントによって、現実にも起こり得る。そう信じさせてくれる、野心的なビジョンだと感じ入りました。一方で、著者が述べているように、これらのステージは直線的なものではなく、行きつ戻りつするものだと肝に銘じる必要がありそうです。 火事は常に起こり得るし、ゲートキーピングの誘惑に駆られることもあるでしょう。重要なのは、理想のステージを意識しつつも、現実と折り合いをつけながら、地道にSREを根付かせていくこと。そのためには、各チームの置かれた状況に即して、適切なステージを見極める眼力も問われるはずです。全体を通して、SREの組織的な浸透は一朝一夕で成し遂げられるものではなく、泥臭い試行錯誤の連続であることを実感させられました。 技術的なスキルに加え、対人関係力、変革マネジメント力など、エンジニアリング以外の資質も問われる。一筋縄ではいかない難題にも、課題を正面から見据え、仲間と知恵を出し合いながら、一つ一つ解決していく。そうした地道な営みの先に、SREが組織に真に根付いた姿が待っているのだと信じたいと思います。私自身、まだ駆け出しのSREですが、このモデルを道標として、SREの理想形を模索していきたいと思います。消防活動に明け暮れる日々から脱却し、開発者との建設的な協働関係を築き、いつの日か高度な結束が生まれる段階へ。 そこに至るまでの道のりは決して平坦ではないでしょう。それでも、信頼性の大義を胸に、仲間とともに前を向いて歩んでいく所存です。SREの真髄は組織文化の変革にある本章のエッセンスは、「SREは単なる技術の問題ではなく、むしろ組織文化の問題である」という一点に集約されるのかもしれません。 信頼性を重視するマインドセット、学習と成長を称揚する雰囲気、自発的なコラボレーションを促す仕組み。そうした目に見えない基盤を地道に築くことなくして、真のSREは宿らない。だからこそ、私たちには技術者としてのスキルと並んで、文化の耕し手としてのセンスが求められているのだと。この辺は運用技術者組織の設計と運用 / Design and operation of operational engineer organizationやエンジニア組織論への招待を読むと良さそうなので記載しておく。 speakerdeck.comエンジニアリング組織論への招待　～不確実性に向き合う思考と組織のリファクタリング作者:広木 大地技術評論社AmazonChapter 17. Growing SRE in Your OrgSREの成長は「大きいほど良い」とは限らない本章は、組織の中でSREをどのように成長させていくかについて、著者の豊富な経験と知見に基づいて解説した、良い章でした。SREは、単に技術的なプラクティスを導入すれば完成するものではありません。組織の規模や成熟度に応じて、戦略的に育てていく必要があるのだと改めて認識させられました。組織戦略の考え方　――企業経営の健全性のために (ちくま新書)作者:沼上幹筑摩書房Amazon印象に残ったのは、著者が 「SREの規模拡大は、必ずしも『大きいほど良い』とは限らない」 と警鐘を鳴らしている点です。SREチームの規模を際限なく大きくすることが目的化してしまうと、かえって非効率を招く恐れがあります。大切なのは、組織のコンテキストに即して、適切な規模と体制を追求していくこと。 そのためには、チームの分割や再編成を恐れず、フットワークの軽さを保つ柔軟性も求められるでしょう。SREチームの規模感について、著者は具体的な数字を提示しています。SREが組織に導入された初期段階では、わずか1人から6人程度のチームで始めることが多いそうです。 この時期は、SREの考え方や手法を部分的に試すフェーズ。小さな成功体験を積み重ねながら、徐々に組織への浸透を図っていきます。モニタリングの改善、SLO/SLIの設定、ポストモーテム分析の実践など、できることから着手するのです。SREの組織の規模による分類チームの規模が6人から18人に拡大すると、オンコール体制の整備が本格化します。 健全なワークライフバランスを保ちつつ、24時間365日の監視を実現するには、最低でも18人は必要だと著者は指摘しています。この規模になると、役割の細分化も進み、メンバーそれぞれの専門性を活かした活動が可能になります。ただし、チームの一体感を保ち、ナレッジの共有を促進する工夫も欠かせません。さらにチームが48人規模に拡大すると、SREはもはや1つのチームではなく、複数のチームから成る組織体となります。 ここからは、各チームの役割分担や連携の在り方が問われるフェーズ。サービス領域ごとの専門チーム、共通基盤の開発に特化したチーム、ツール整備に注力するチーム、現地に密着した分散型チーム。 組織のニーズに応じて、最適な体制を模索していく必要があります。同時に、SREの理念や価値観を浸透させ、統一感を保つための仕掛けづくりも欠かせません。そして、SRE組織が100人を超える規模になると、専門性と融合のバランスを取るハイブリッド型の組織設計が求められると著者は説きます。 機能領域や技術領域ごとの深い専門性を追求しつつ、部門を越えた協調を促す枠組み。プロセス改善を担うSREチーム、全社的なプラットフォームを整備するSREチーム。多様性と統一性を両立する、柔軟な組織マネジメントが問われるフェーズだと言えるでしょう。この先のさらなる成長ステージでは、SREがプラットフォームエンジニアリングの領域にも踏み込んでいくビジョンが示唆されていました。システムを支える基盤的なライブラリやフレームワークを自ら開発し、組織全体の開発力を底上げしていく。 そこまで至れば、SREは組織のエンジニアリング文化そのものを形作る存在になるはずです。もちろん、それは容易な道のりではありません。でも、その理想に向かって一歩ずつ前進していく。それこそが、志高きSREチームの使命なのかもしれません。DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス作者:黒須 義一,酒井 真弓,遠山 陽介,伊藤 利樹,饒村 吉晴日経BPAmazon一方で、著者は 「SREは融合と結束の担い手でなければならない」 と強調しています。組織が大きくなればなるほど、分断と分散のリスクは高まります。技術選定の方針、プロセスの標準化、文化的な価値観。チームによってバラバラになってしまっては、SREの真価は発揮できません。だからこそ、differences（違い）は認めつつ、deindividualization（個性の喪失）は避ける。多様性を尊重しつつ、共通の目標に向かって結束する。そんな組織デザインのセンスが、SREリーダーには強く求められるのです。さらに、著者は 「SREの技術的スケールだけでなく、リーダーシップの規模拡大にも目を向けるべき」 だと訴えかけています。トップマネジメントの意思決定の場に、SREの視点が適切に反映される体制を整えること。それは、SREの組織的な浸透を支える大前提だと。単に人数を増やすだけでなく、価値観を共有し、変革を牽引する存在として、力強くスケールしていく。 そんなSREリーダーの姿が思い描かれていました。SREが組織の風土に合わせて多様な形で発展していく本章を読み終えて、私はSREという職能の奥深さを改めて実感しました。技術的な側面だけでなく、組織デザイン、リーダーシップ、文化の醸成など、実に多様な顔を持ち合わせている。 だからこそ、SREのスケールは単線的なものではなく、状況に応じた柔軟な判断が求められるのだと。「組織の成長に合わせて、SREも共に進化していく」。そんな著者の言葉が強く印象に残りました。もちろん、その道のりは平坦ではありません。SREの価値への理解不足、既存の体制への固執、変化への抵抗。スケールの障壁は数多く立ちはだかるでしょう。それでも、信念を持って粘り強く向き合っていく。泥臭い説得を重ね、地道な実績を積み上げ、仲間を巻き込みながら、少しずつ前に進んでいく。 私はそれこそが、志あるSREリーダーの真の姿なのだと感じています。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazon本章は、SREの組織的な拡がりについて、体系的な知見を提供してくれる、良い内容でした。単に数合わせでスケールするのではなく、組織のコンテキストを見極め、長期的な視点で育てていく。 技術と組織と文化をバランス良く強化し、全社的な変革を促していく。これからのSREリーダーには、そんな繊細かつ大胆なアプローチが求められているのだと実感させられました。エンジニアの端くれとして、組織論や文化論に首を突っ込むのは、少し居心地の悪さを感じるかもしれません。でも、それこそがSREの醍醐味であり、やりがいなのだと信じています。技術の力で勝ち得た信頼を武器に、組織に新しい風を吹き込んでいく。 そいう姿勢を問われている気がしました。Chapter 18. ConclusionSREの本質はシステムの信頼性という崇高な目標にある『Becoming SRE』の最終章である第18章「Conclusion」は、読者への感謝と別れの言葉から始まります。著者のDavid Blank-Edelman氏は、SREの本質をコンパクトに凝縮しつつ、読者を新たな旅立ちへと送り出そうとしています。その語り口は、まるで優しい師が弟子に最後の教えを授けるかのようです。この章で改めて強調されているのは、SREが目指す「システムの信頼性」という崇高な目標です。それは、個人としても、組織としても、他者と協調しながら追求していくべき理想だと。特定のマインドセットと文化を共有し、周到な準備を重ねたSREたちが、組織の支援を得ながら、様々なスケールでその理想を実現していく。SREの真髄は、まさにそこにあるのだと著者は説いています。SREは素晴らしくやりがいある仕事そして、著者は 「SREの仕事はfun（楽しい）であり、rewarding（やりがいがある）」 と力説します。もちろん、常にそうとは限りません。難しい局面に直面することもあるでしょう。でも、総じて素晴らしい仕事だと。信頼性という難問に立ち向かい、仲間とともに現実に意味のあるインパクトを残せる。 そのチャレンジは、けして退屈ではあり得ないのだと。読者にSREへの情熱の一端でも伝われば幸いだと、著者の想いが伝わってきます。おわりにSREは技術を超え組織文化そのものを変革していく『Becoming SRE』を読み終え、SREという職能の奥深さと広がりを新たに感じました。David Blank-Edelman氏は、SREが技術を超え、組織文化そのものを変革していく役割を果たすことを鮮明に描いています。本書を通じて、システムの信頼性を追求するミッション、必要なマインドセットとスキル、そしてその知見が組織内に浸透し定着するまでの過程が体系的かつ実践的に語られました。SREの役割は単に技術的な問題を解決するだけではなく、信頼性という難題に直面し、それに対峙しながら仲間と共に粘り強く取り組むことにあります。これは、エンジニアリングの枠を超えた、大きなやりがいを提供します。しかしながら、SREへの道は容易ではありません。個人と組織の両方で、多くの障壁に直面することがあります。本書は、フィードバックループの重要性、障害から学ぶ文化、コラボレーションの極意など、困難を乗り越えるための具体的な方法を提供しています。これらの知見は、SREとして成長するためのサポートとなるでしょう。そして、SREの醍醐味とその意義を再確認することができました。著者が指摘するように、SREの究極の目的はシステムの信頼性を通じて人々に価値を提供することにあります。日々の挑戦と探求の精神が、SREの本質です。SREsのためのSRE定着ガイドからの引用ではありますが外部リソースの注入は、SREの実践において選択肢の一つとして考えられます。重要なのは、前提として、自分たちでやりきれるならその方が良いということです。『Becoming SRE』の教訓にもあるように、SREは技術的な問題解決だけでなく、組織文化の改善やビジネス価値の向上を目指します。しかし、定点観測のような繰り返しの作業や、組織内変化の促進に際して、内部ではやりきれずに外部エキスパートの助言が必要となる場合もあります。例えば、nwiizoが所属している3-ShakeやX-Tech5、Topotal、などの外部のサービスや専門家を利用することは、新たな視点をもたらし、特定の課題に対して効果的な戦略を実施する支援を提供できます。しかし、これはプロジェクトや組織によっては、改善を目指す一つの方法であることを忘れずに。SREの目指すところは、あくまで内部の力で課題を乗り越え、成長することにあります。外部リソースの活用は、そのプロセスを補助する手段の一つとして考えるべきでしょう*1https://ja.wikipedia.org/wiki/%E5%BA%83%E5%91%8A。SREの旅に終わりはない最後に、SREの旅に終わりはありません。著者が贈るメッセージ、「大切なのは、その旅を楽しみ、学び続けること」を胸に、私たちも一歩一歩前進していきましょう。外部リソースの適切な活用は、その旅をより豊かで有意義なものにする一助となるでしょう。今回の本の内容要約においては、「A. Letters To A Young SRE」「B. Advice From Former SREs」「C. SRE Resources」という付録の部分のはレビューの対象とはしていませんでした。これらの部分には、SREを志す若者への手紙、経験豊富なSREからのアドバイス、SREのための参考資料など、非常に興味深い内容が含まれています。ご紹介できなかったのは残念ですが、本書の中核をなす部分に注力するために割愛させていただきました。 もしこの先SREの道に進まれる際には、ぜひこれらの付録もじっくりと読まれることをおすすめします。きっと、SREとしての歩みを確かなものにしてくれるはずです。この学びを糧に、今日も信頼性という難問に立ち向かっていきます。「Fun:楽しむ」と「Rewarding:やりがいのある」を胸に、SREの醍醐味を味わいつつ。最後になりましたが、素晴らしい書を生み出してくれた著者のDavid Blank-Edelman氏に、心からの感謝を捧げたいと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。*1:広告","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/08/165909","isoDate":"2024-04-08T07:59:09.000Z","dateMiliSeconds":1712563149000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"go-rod/rod でブラウザ自動化とWebスクレイピングをやっていく","contentSnippet":"はじめにWebスクレイピングの需要が高まる中、Goで実装する機会が増えてきました(よね?)。Goの豊富な標準ライブラリとシンプルな文法は、スクレイピングのような自動化タスクと非常に相性が良いです。が、今回はGoの有力なスクレイピングライブラリの1つである go-rod/rod の特徴を掘り下げながら、実際に現在所属している組織のサイト3-shake.comのWebサイトをスクレイピングする方法をご紹介します(広告的に許してくれ)。github.comはじめにgo-rod/rod の概要と特徴インストールと基本的な使い方3-shake.com のスクレイピングサービス情報の抽出ニュース情報の抽出ヘッドレスモードでのスクレイピングおわりに参考資料go-rod/rod の概要と特徴go-rod/rod`は、ChromeのDevToolsプロトコルを利用したブラウザ自動化とスクレイピングのためのハイレベルなドライバーライブラリです。単なるHTMLの取得だけでなく、ブラウザ上の操作を自動化できるのが大きな特長です。主な特徴は以下の通りです:ページのスクリーンショットを撮るクライアントサイドレンダリングされたページもスクレイピング可能フォームの自動入力E2Eテストリクエストのハイジャックつまり、ブラウザ上で手動で行える操作のほとんどを自動化できるわけです。これによりJavaScriptで動的に生成されるモダンなWebサイトに対しても、自在にスクレイピングを行えます。go-rod.github.ioまた、Goらしいシンプルで読みやすいAPIを提供しているのも魅力です。実装の詳細を隠蔽しつつ、柔軟で強力な機能を直感的に使用できるよう設計されています。インストールと基本的な使い方go-rod/rod は次のコマンドで簡単にインストールできます。go get github.com/go-rod/rodインストール後、Goのコードから次のように呼び出すことでブラウザを起動できます。package mainimport \"github.com/go-rod/rod\"func main() {    browser := rod.New().MustConnect().MustPage(\"https://3-shake.com/\")    browser.MustWaitStable().MustScreenshot(\"3-shake.png\")    defer browser.MustClose()}ここではブラウザオブジェクトを生成し、MustConnect() でブラウザプロセスに接続して続いて MustPage() を使ってページを開きます。それをMustScreenshot()を使ってスクリーンショットを撮っていきます。こちらがスクリーンショットです。defer 文で最後にブラウザを閉じるのを忘れずに。これだけでブラウザの自動操作の準備は整いました。めちゃくちゃにシンプルですね。3-shake.com のスクレイピングそれでは、実際に https://3-shake.com のWebサイトをスクレイピングしてみましょう。今回は以下の情報を抽出することを目標とします。全サービスの名前と説明文全ニュースのタイトルと日付サービス情報の抽出まず、サービス一覧を表示している要素を特定します。サイトを開発者ツールで覗いてみると、各サービスが以下のようなDOM構造になっていることがわかります。\u003cli class=\"services__item\"\u003e    \u003cdiv class=\"services__block js-inview\" data-inview-x=\"30\" data-inview-s=\"700\"\u003e        \u003cp class=\"services__pic js-parallax\"\u003e            \u003cimg src=\"path/to/image\"\u003e        \u003c/p\u003e    \u003c/div\u003e    \u003cdiv class=\"services__block js-inview\" data-inview-x=\"-30\" data-inview-s=\"700\"\u003e        \u003cdiv class=\"services__texts\"\u003e            \u003cdiv class=\"services__name\"\u003e                \u003ca href=\"path/to/service\" target=\"_blank\"\u003e                    \u003cimg src=\"path/to/logo\"\u003e                    \u003cp\u003eサービス名\u003cbr\u003e\u003cspan\u003eサービス名ふりがな\u003c/span\u003e\u003c/p\u003e                \u003c/a\u003e            \u003c/div\u003e            \u003cp class=\"services__lead\"\u003eサービスの説明文\u003c/p\u003e            \u003cp class=\"services__link p-text--link\"\u003e                \u003ca href=\"path/to/service\" target=\"_blank\"\u003eサービスサイトへ\u003ci class=\"p-icon-arrow-right\"\u003e\u003c/i\u003e\u003c/a\u003e            \u003c/p\u003e        \u003c/div\u003e    \u003c/div\u003e\u003c/li\u003eこれを元に、スクレイピングコードを書いていきます。// サービス情報をスクレイピングservices := page.MustElements(\"li.services__item\")for _, service := range services {    name := service.MustElement(\".services__name\").MustText()    description := service.MustElement(\".services__lead\").MustText()    fmt.Printf(\"サービス名: %s\\n\", name)    fmt.Printf(\"説明文: %s\\n\", description)    fmt.Println(\"---\")}MustElements() で li.services__item にマッチする要素を全て取得し、それぞれの要素から MustElement() と MustText() でサービス名と説明文を抜き出しています。ニュース情報の抽出次にニュース一覧を取得しましょう。こちらは以下のようなDOM構造になっています。\u003cdiv class=\"p-articles js-news__target l-col l-col--list js-inview-box\" data-inview-y=\"15\"\u003e                       \u003cdiv class=\"p-articles__item l-col__block--4 is-show\"\u003e        \u003cdiv class=\"p-articles__thumb\"\u003e            \u003ca class=\"p-articles__link\" href=\"path/to/news\" target=\"_self\"\u003e                \u003cspan style=\"background-image: url('path/to/image');\"\u003e\u003c/span\u003e            \u003c/a\u003e        \u003c/div\u003e        \u003cdiv class=\"p-articles__info\"\u003e            \u003cp class=\"p-articles__date\"\u003eYYYY.MM.DD\u003c/p\u003e            \u003cul class=\"p-categories\"\u003e                \u003cli class=\"p-categories__item\"\u003e                    \u003ca href=\"path/to/category\"\u003eカテゴリ名\u003c/a\u003e                \u003c/li\u003e            \u003c/ul\u003e        \u003c/div\u003e        \u003cp class=\"p-articles__text\"\u003e            \u003ca class=\"p-articles__link\" href=\"path/to/news\" target=\"_self\"\u003eニュースタイトル\u003c/a\u003e        \u003c/p\u003e    \u003c/div\u003e\u003c/div\u003eこれを元にスクレイピングコードを書きます。package mainimport (    \"fmt\"    \"github.com/go-rod/rod\")func main() {    browser := rod.New().MustConnect()    defer browser.MustClose()    page := browser.MustPage(\"https://3-shake.com/\")    // ニュース情報をスクレイピング    newsList := page.MustElement(\".p-articles.js-news__target.l-col.l-col--list.js-inview-box\")    newsItems := newsList.MustElements(\".p-articles__item\")    for _, item := range newsItems {        title := item.MustElement(\".p-articles__text\").MustText()        date := item.MustElement(\".p-articles__date\").MustText()        fmt.Printf(\"タイトル: %s\\n\", title)        fmt.Printf(\"日付: %s\\n\", date)        fmt.Println(\"---\")    }}ニュースが .p-articles.js-news__target.l-col.l-col--list.js-inview-box の中にあるので、まずはその要素を MustElement() で取得します。そこから .p-articles__item を全て取り出し、タイトルと日付を抽出しています。これで目的の情報が取得できました。実際に出力してみると次のようになります。実際にテキストも転記しておく、、、。タイトル: 自動脆弱性診断ツール「Securify」、AI技術を駆使する「ai6」が導入日付: 2024.04.05---タイトル: 『ferret』に寄稿記事が掲載されました。日付: 2024.03.25---タイトル: 自動脆弱性診断ツール「Securify」、大手通信販売会社「フェリシモ」が導入日付: 2024.03.22---タイトル: Relance　フリーランス協会の「認定マッチング事業者」として今年も正式採択日付: 2024.04.03---各サービスの名前と説明文、ニュースのタイトルと日付がきちんと取得できていますね。フォームの自動入力や並列数を上げての負荷試験を兼ねたE2Eテストも行いましたが流石に迷惑になるので自分のユースケースにあったコードをexamples から探して下さいgithub.comヘッドレスモードでのスクレイピングgo-rod/rodの大きな特徴の1つに、ヘッドレスモードでのブラウザ操作があります。ヘッドレスモードとは、GUIを持たない状態でブラウザを起動し、バックグラウンドで動作させる機能です。通常、ブラウザを自動操作する際にはブラウザウィンドウが立ち上がりますが、ヘッドレスモードならそれがありません。その分リソースを節約でき、サーバー上での実行に向いています。CIパイプライン内でのテストなどにも利用できます。負荷試験などにも使えるかもしれないので調査中です。    // github.com/go-rod/rod/lib/launcher を利用する    // ヘッドレスブラウザを起動する    url := launcher.New().MustLaunch()    browser := rod.New().ControlURL(url).MustConnect(\"https://3-shake.com/\")    // スクレイピング対象のページを指定する    page := browser.MustPage()launcher はやっていくと必要になる場面が出てくるので一通り目を通して置くと後に応用が効くかもです。github.comおわりに今回はGoのスクレイピングライブラリ go-rod/rod の特徴を確認しながら、Webサイト https://3-shake.com/ から情報を抽出する方法を紹介しました。go-rod/rod の優れた点は、ChromeのDevToolsプロトコルを利用してブラウザを直接操作できることです。これによりサーバーサイドだけでなく、クライアントサイドで動的に生成されるコンテンツに対しても柔軟にスクレイピングを行えます。Goのシンプルな文法とあいまって、簡潔かつパワフルなスクレイピングスクリプトが書けるのが魅力ですね。ぜひ皆さんも go-rod/rod を使って色々なWebサイトに挑戦してみてください。スクレイピングが必要とされるシーンは今後ますます増えていくでしょう。Goと go-rod/rod を使いこなせば、そんな要望にも難なく応えられるはずです。快適で効率的なスクレイピングライフを送っていきたいと思います参考資料github.com/go-rod/rodgo-rod","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/05/145103","isoDate":"2024-04-05T05:51:03.000Z","dateMiliSeconds":1712296263000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineering on Kubernetes を読んでCloud Native の現在地を理解する","contentSnippet":"はじめに近年、Kubernetesの採用が進む中、複数のチームが関わり、複数のクラウドプロバイダーへのデプロイを行い、異なるスタックを扱う組織では、その導入の複雑さが新たな問題となっています。本書 『Platform Engineering on Kubernetes』は、Kubernetes に登場しつつあるベストプラクティスとオープンソースツールを活用し、これらのクラウドネイティブの問題を技術的に組織的にどのように解決するかを示してくれます。learning.oreilly.com本書では、Kubernetes上に優れたプラットフォームを構築するための要素を明確に定義し、組織の要件に合わせて必要なツールを体系的に紹介しており、実際の例とコードを交えながら各ステップをわかりやすく説明することで、最終的にはクラウドネイティブなソフトウェアを効率的に提供するための完全なプラットフォームを作成できるようになるとともに、プラットフォームチームと開発チームの緊密な連携の重要性が強調され、両者の垣根を越えてアプリケーションとインフラストラクチャが一体となったソフトウェア開発を実現することこそが、クラウドネイティブ時代のDevOpsの理想形だと感じました。ぜひ、本稿をお読みいただき、クラウドネイティブ時代のプラットフォームエンジニアリングに必要な知識とスキルと自社に最適なプラットフォームを設計・構築できるようになる必要性を感じたのであれば『Platform Engineering on Kubernetes 』をぜひ、読んでいただきたいです。Platform Engineering on Kubernetes作者:Salatino, MauricioManningAmazon『Platform Engineering on Kubernetes』 の構成本書は全9章で構成されており、カンファレンスのアプリケーションを構築するための \"walking skeleton\" (PoC、概念実証、デモアプリケーション)を用いて解説が進められる。第1章では、プラットフォームとは何か、なぜそれが必要なのか、そしてクラウドプロバイダーが提供するものとどう違うのかを紹介する。第2章では、Kubernetes 上で動作するクラウドネイティブで分散されたアプリケーションを構築する際の課題を評価する。第3章では、異なるクラウドプロバイダー上でアプリケーションを実行するためのリソースの構築、パッケージ化、デリバリーに必要な追加手順に焦点を当てる。第4章では、パイプラインの概念を中心に、GitOps アプローチを用いて複数の環境の構成を宣言的なアプローチで管理する方法を説明する。第5章では、Crossplane を使用してクラウドプロバイダー間でアプリケーションのインフラストラクチャコンポーネントをプロビジョニングする Kubernetes ネイティブなアプローチについて説明する。第6章では、開発環境の作成に特化した、Kubernetes 上にプラットフォームを構築することを提案する。第7章では、プラットフォームチームが利用可能なリソースにどのように接続するかを決定できるアプリケーションレベルの API で開発チームを支援することに焦点を当てる。第8章では、新しいリリースを本格的にコミットする前に実験するために使用できるリリース戦略を示す。第9章では、プラットフォームの構築に使用するツールからデータを取り込み、プラットフォームエンジニアリングチームがプラットフォームの取り組みを評価するための重要な指標を計算する2つのアプローチを評価する。本書の最後には、Kubernetes 上でプラットフォームがどのように構築されるのか、プラットフォームエンジニアリングチームの優先事項は何か、そして成功するためにクラウドネイティブスペースの学習と最新情報の把握がいかに重要であるかについて、明確なイメージと実践的な経験が得られるようになっています。知識を身体化するハンズオン本書のリポジトリは公開されており、読者は書籍の内容に沿ってハンズオンを実施することができます。これは非常に重要な点です。なぜなら、実際に手を動かして体験することで、書籍で得た知識を体験として自分のものにできるからです。技術書を多読するタイプなのですが別に一度で理解できるタイプの人間ではないので読んでみて良いと思った書籍のみ手を動かして理解するようにしています。github.comKubernetesは、複雑で広範囲に及ぶ分野です。書籍を読んで理解したつもりでも、実際に試してみると躓くことが多々あります。その都度、問題を解決していくことで、より深い理解を得ることができるのです。ですから、読者の皆さんには、ぜひ書籍と一緒にハンズオンに取り組んでいただきたいと思います。文章を読んだだけで分かった気にならないでください。実際に手を動かし、試行錯誤することが、本当の意味での学習には欠かせません。CloudNative Days Tokyo 2023 実行委員会が公開している『一日で学ぶクラウドネイティブ技術実践ハンズオン』は、クラウドネイティブ技術の基礎から実践的な内容まで、1日で集中的に学べる充実した内容となっています。クラウドネイティブの概念やコンテナ技術、Kubernetes、マイクロサービスアーキテクチャなどの主要なトピックがカバーされており、実際にハンズオン形式で技術を体験できるのが特徴です。クラウドネイティブ技術の入門としてお勧めの教材となっています。github.comまた、所属組織でも独自のクラウドネイティブ技術に関する研修を提供しております。弊社の研修では、実際の業務で活用できる実践的なスキルの習得に重点を置いています。カリキュラムの概要については公開しておりますので、ご興味のある方はぜひご覧ください。クラウドネイティブ技術の習得を目指す方に向けて、効果的な学習の機会を提供できればと考えております。sreake.com1 (The rise of) platforms on top of Kubernetesクラウドネイティブ時代の本格的な幕開けとともに、Kubernetesは急速に普及し、コンテナ化されたアプリケーションを運用するための事実上の標準となりました。本章では、まずプラットフォームの定義とその必要性が丁寧に説明されています。プラットフォームとは、企業が顧客向けのソフトウェアを開発・運用するために必要な一連のサービスを提供するものであり、開発チームが効率的に価値を届けるためのワンストップショップの役割を果たします。また、プラットフォームは静的なものではなく、組織の成熟度に合わせて進化していくべきものというような主張がされている点が印象的でした。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonクラウドプロバイダーが提供するサービスは、レイヤー別に分類され、それぞれの特徴が解説されています。Figure 1.1 Cloud provider's services categories より引用特に、アプリケーション固有のニーズを満たすためには、これらのサービスを組み合わせ、独自のレイヤーを構築する必要があると強調されています。この点については、『CloudNativeな時代に求められるWebサービス基盤モデルの再考』というタイトルで登壇した際にもまとめています。また、クラウドプロバイダーが提供するプラットフォームの特徴として、API、SDK、CLI、ダッシュボードなどが挙げられています。これらのツールを効果的に組み合わせることで、開発チームはアプリケーションをスムーズに構築・デプロイできます。一方で、プロバイダー固有のツールやワークフローを学習するコストも無視できないと指摘されています。Google Cloud Platform (GCP) を例に、クラウドプロバイダーが提供するダッシュボード、CLI、API の実際の使用例が紹介されています。これらのツールは、リソースのプロビジョニングを大幅に簡素化してくれますが、一方でプロバイダー固有の知識が必要とされる点にも触れられています。cloud.google.comクラウドプロバイダーのプラットフォームが広く受け入れられている理由として、API主導の設計、充実したツールの提供、そして従量課金モデルが挙げられています。特に、開発チームが必要なリソースをオンデマンドで利用できる点は、ビジネスのアジリティを高める上で大きなメリットだと言えます。次に、Kubernetes 上にプラットフォームを構築することの意義と、そのためのエコシステムについて解説されています。Kubernetes は、クラウドネイティブなアプリケーションを開発・運用するための基盤として広く採用されていますが、それ自体はプラットフォームではなく、プラットフォームを構築するための構成要素を提供するものだと位置づけられています。Kubernetes を導入する際には、単にツールを選定するだけでなく、組織の文化や成熟度に合わせて、段階的にプラットフォームを構築していくことが重要だと説かれています。Figure 1.11 Platform journey on Kubernetes より引用また、プラットフォームチームは、開発チームを内部の顧客と捉え、彼らのワークフローに合わせてプラットフォームを設計すべきだと強調されています。Cloud Native Computing Foundation (CNCF) は、クラウドネイティブなエコシステムを推進する団体であり、Kubernetes を含む多くのオープンソースプロジェクトをホストしています。https://landscape.cncf.io/ より引用landscape.cncf.ioこれらのプロジェクトを適切に組み合わせることで、ベンダーロックインを回避しつつ、柔軟なプラットフォームを構築できると説明されています。プラットフォームエンジニアリングの役割と、その重要性についても述べられています。プラットフォームチームは、社内の開発チームを顧客と捉え、彼らが効率的にソフトウェアを開発・デリバリーできるように、プラットフォームというプロダクトを提供します。Figure 1.14 Platform teams take the work done by developers safely to production. より引用国内でもPlatform Engineering MeetupやPlatform Engineering Kaigi 2024が開催され、とても注目される分野となっています。Platform Engineeringは、開発チームが効率的にアプリケーションを開発、デプロイ、運用できるようにするための基盤を提供することを目的としています。この分野では、Kubernetesがプラットフォームの中核として広く採用されています。自分が最初にKubernetesをプラットフォームとして認識したのは、プラットフォームの上でものを作るということを読んでからです。この記事では、Kubernetesがプラットフォームとしてどのような役割を果たすのかが詳しく解説されており、開発者がアプリケーションに集中できる環境を提供することの重要性が強調されています。また、Kubernetesを始めたばかりで、Platform Engineeringの概念についてよく分からないという人は、k8sを始める人に知ってもらいたい、Platform Engineeringの話を読むことをおすすめします。このスライド資料では、Platform Engineeringの基本的な考え方や、Kubernetesを活用したプラットフォーム構築の手法が分かりやすく解説されています。platformengineering.connpass.comまた、プラットフォームは単なるツールの寄せ集めではなく、開発チームのワークフローに合わせて設計され、シームレスな開発体験を提供することが求められます。市販のプラットフォームを導入するだけでは、組織特有のニーズを満たすことは難しいと指摘されています。Red Hat OpenShift や VMware Tanzu などの製品は、一定の抽象化を提供してくれますが、それでも組織に合わせたカスタマイズが必要になるケースが多いようです。Figure 1.15 Building platforms on top of Kubernetes distributions より引用結局のところ、自社に最適なプラットフォームを構築するためには、社内でプラットフォームエンジニアリングに取り組む必要があるということですね。本書の中にも組織の話がたくさん出てくるし、本稿でも少し組織のような話に逸れます。『DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス』は、クラウドサービスを効果的に活用し、DXを成功させるために不可欠な、自社のユースケースに適したサービスの選択・統合と社内でのクラウドエキスパートの育成について、特にリーダーシップ、ビジネス、テクノロジーを備えたクラウド活用推進組織「CCoE」の存在の重要性を強調しています。本書では、CCoEの基本概念から立ち上げ方法、課題解決方法まで、先進企業の実例を交えてわかりやすく説明しています。クラウドネイティブ時代に適応し、DXを成功させるためには、プラットフォームの構築と進化、クラウドサービスの効果的な活用、そしてCCoEの組織化が重要であり、これらの取り組みを通じて、企業は顧客により高い価値を提供し、競争力を高めていくことができるでしょう。これらの課題解決の手引きとなる一冊であり、合わせて読むのがオススメの書籍です。DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス作者:黒須 義一,酒井 真弓,遠山 陽介,伊藤 利樹,饒村 吉晴日経BPAmazon本書で使用されるカンファレンスのアプリケーションの例も紹介されています。この「ウォーキングスケルトン」と呼ばれるサンプルアプリケーションは、クラウドネイティブなアーキテクチャのベストプラクティスを示すと同時に、以降の章で紹介されるプラットフォーム構築の手法を実践的に学ぶためのユースケースとして機能します。このカンファレンス用のアプリケーションは、マイクロサービスアーキテクチャに基づいて設計された Web アプリケーションであり、複数のバックエンドサービスと、それらを呼び出すフロントエンドで構成されています。Figure 1.18 Conference application services. The end user interacts with the frontend that routes requests to all the backend services. より引用各サービスは独立して開発・デプロイできるため、チーム間の自律性を高めつつ、アプリケーション全体の柔軟性と回復性を向上させることができます。モノリシックなアーキテクチャと、マイクロサービスアーキテクチャの違いについても説明されています。モノリシックなアプリケーションでは、すべての機能が1つのコードベースに含まれているため、スケーリングや更新に制約が生じやすくなります。Figure 1.20 In a monolith application, all the logic to implement different use cases are bundled together. This push different teams to work on the same codebase and requires them to have complex coordination practices to avoid conflicting changes. より引用一方、マイクロサービスでは、各サービスが独立して開発・デプロイできるため、より柔軟で回復性の高いアプリケーションを構築できると説明されています。最後に、本書で扱うプラットフォーム構築の手法が、カンファレンスのアプリケーションを例に概説されています。各章では、CI/CD、環境の管理、クラウドリソースのプロビジョニングなど、プラットフォームを構成する様々な要素が取り上げられ、それらを組み合わせることで、開発チームの生産性を高めるプラットフォームを構築していく過程が紹介されます。また、プラットフォームの効果を測定するための指標や手法にも触れられており、継続的な改善の重要性が強調されています。第1章を通じて、プラットフォームを Kubernetes 上に構築することの意義と、そのための手法が体系的に説明されていました。特に、プラットフォームを「内製のプロダクト」と捉え、開発チームを「顧客」と見なすという視点は、DX時代における開発組織のあり方を考える上で示唆に富むものでした。これらのSREとの手法の違いについては以下のような内容で登壇したことがあります。 speakerdeck.com私自身、大規模な Web アプリケーションの開発に携わった経験から、モノリシックなアーキテクチャの限界を痛感しています。機能追加や変更に多大な時間と工数を要していたのが、マイクロサービス化を進めることで、各チームが独立して開発を進められるようになり、リリースサイクルを大幅に短縮できました。クラウドネイティブなアプリケーション開発において、マイクロサービスアーキテクチャが果たす役割の大きさを実感しています。また、CNCF のプロジェクトを活用しつつ、自社に最適なプラットフォームを構築していくアプローチは、クラウドネイティブな開発に取り組む多くの組織にとって参考になるはずです。私自身、日々の業務の中で、クラウドネイティブな開発の推進と、それを支えるプラットフォームの構築に取り組んでいます。本書で得られる知見を活かし、自社に最適なプラットフォームを設計・運用していきたいと考えています。著者の深い知見と経験に基づく解説は、インフラエンジニアのみならず、アプリケーション開発者やアーキテクトなど、様々な立場の読者に価値を提供してくれるでしょう。プラットフォームチームと開発チームの関係性や、CNCF の活動など、日々の業務では触れる機会の少ないトピックについても、明快に解説されていたのが印象的でした。本書の残りの章では、このような考え方を基盤に、より具体的なプラットフォーム構築の手法が展開されていきます。第1章で示された知見は、プラットフォームエンジニアリングに携わる全ての人にとって、大きな助けになるはずです。著者の知見とバランス感覚に裏打ちされた記述は、まさにクラウドネイティブ時代の最前線に立つエンジニアならではのものです。これからのソフトウェア開発には、プラットフォームチームと開発チームの緊密な連携が欠かせません。インフラエンジニア、SREやプラットフォームエンジニアは両者の架け橋となり、組織全体でクラウドネイティブの価値を最大限に引き出せるよう尽力しなければなりません。本書を通じて得られる知見を糧に、クラウドネイティブ時代の開発の最前線に立ち続けられるのではないでしょうか？しかし、技術的にKubernetesを完全に網羅しているわけではないので『Kubernetes完全ガイド 第2版』、『Docker/Kubernetes実践コンテナ開発入門 改訂新版』、『Kubernetes Best Practices, 2nd Edition』、『Kubernetes Patterns, 2nd Edition』などを読むと良いと思います。2 Cloud-native application challenges本章では、クラウドネイティブアプリケーションを開発・運用する上での実践的な課題が幅広く議論されました。議論の出発点となったのは、アプリケーションを実行するためのKubernetesクラスター環境をどのように選択するかという点です。ローカル環境でKindを使う方法は手軽である一方、リソースに制限があり、本番環境とは異なる挙動をする可能性があることが指摘されました。Kindは、Docker上にKubernetesクラスターを起動するツールで、開発者の手元で手軽にKubernetesを体験できる利点がある反面、プロダクション環境とは異なるサイジング・設定になりがちという欠点があります。kind.sigs.k8s.io対して、クラウドプロバイダのマネージドサービスを使えば、本番に近い環境でアプリケーションを開発できますが、コストがかかるほか、開発者がリモート環境での作業に慣れる必要があるといったトレードオフが存在します。GKE(Google Kubernetes Engine)やEKS(Amazon Elastic Kubernetes Service)などのマネージドサービスは、運用の手間を大幅に削減できる一方、クラウドベンダーの仕様に縛られるというデメリットもあります。私も実際にKindを用いたローカル環境とGKEを用いたクラウド環境の両方を経験しましたが、著者の指摘通り、それぞれに一長一短があることを実感しています。例えば、Kindは気軽に使える反面、ノード数が限られるためスケーリングのテストには向きません。一方、GKEは本番環境に近い挙動が期待できますが、クラスターの起動に時間がかかります。開発のフェーズやチームの状況に合わせて適切な環境を選択することが重要だと改めて認識しました。Figure 2.1 Kubernetes cluster Local vs. Remote setups.より引用環境の選択に関する議論に続いて、Helmを使ってカンファレンスアプリケーション(PoC)をKubernetesクラスターにデプロイする方法が具体的に紹介されました。Helmは、Kubernetes上のアプリケーションを管理するためのパッケージマネージャーです。Helmでは、アプリケーションの各コンポーネントを定義した複数のマニフェストファイルを「Chart」という単位でまとめて管理します。Helmを使うと、たった1つのコマンドで、アプリケーションの実行に必要な様々なKubernetesリソース（デプロイメント、サービス、ConfigMapなど）を一括デプロイできるのが大きな魅力です。Helmのようなツールを活用することで、複雑なマニフェストファイルを手書きで管理する手間を大幅に削減できます。また、変数化されたテンプレートを使うことで、環境ごとの設定の差異を吸収するのも容易になります。また、デプロイ後は、kubectlを駆使して、デプロイメント、サービス、Ingressなどのリソースを詳細に調べることで、アプリケーションの動作を深く理解することができます。例えば、kubectl describe deploymentでデプロイメントの詳細情報を確認したり、kubectl logsでPodのログを追跡したりできます。私も日頃からkubectlを多用していますが、改めてその重要性を認識しました。トラブルシューティングにおいては、kubectl describeやkubectl logsが特に有用です。Podが期待通りの状態になっていない場合、kubectl describeでPodの詳細情報を確認することで、原因を特定するための手がかりが得られることが多いです。ログに関しても、kubectl logs -fでストリーミング表示すれば、リアルタイムでアプリケーションの挙動をモニタリングできます。アプリケーションのデプロイと動作の確認を通じて、著者はクラウドネイティブアプリケーション特有の課題についても議論を展開していたので必読だと思います。最も重要な課題の1つが、一時的な障害が発生してもシステム全体を停止させないことです。マイクロサービスアーキテクチャでは、あるサービスで障害が発生しても、他のサービスには影響を与えないようにすることが求められます。そのためには、個々のマイクロサービスを冗長化し、一部のインスタンスが停止しても他のインスタンスが処理を引き継げるような設計が必要不可欠です。Kubernetesでは、この要件を満たすために、マイクロサービスを複数のレプリカ(Pod)で運用することが一般的です。例えば、本章の例では、フロントエンドサービスのレプリカを2つ起動することで、一方が停止しても他方がリクエストを処理し続けられるようにしていました。Deployment(デプロイメント)リソースの「replicas」フィールドで、起動するレプリカの数を指定できます。Figure 2.17 By having two replicas of the Frontend container running, we allow the application to tolerate failures and also to increase the number of concurrent requests that the application can handle. より引用実際、私も過去に、あるマイクロサービスがデプロイに失敗し、全体のシステムが停止してしまった苦い経験があります。その教訓から、現在ではユーザー向けのサービスを複数のレプリカで運用するようにしています。障害の影響を最小限に抑えるには、可用性を維持しつつ、もちろん無限にお金を使えれば解決に近づく問題ではあるのでリソース消費量のバランスを取ることが肝要です。また、レプリカ数を動的に変更できるようHPA(Horizontal Pod Autoscaler)を設定し、負荷に応じて自動的にスケールするような工夫もしています。HPAを使えば、CPUやメモリの使用率に基づいて、Pod数を自動的に増減できます。これにより、トラフィックが増大した際にもサービスのパフォーマンスを維持しつつ、利用が低調な時間帯にはリソースを節約することが可能になります。サービス間の疎結合性を保つことも、システムの可用性を高めるための重要な要素です。あるサービスで障害が発生した際も、ユーザーが他のサービスの機能を継続して利用できるようにすることが理想的です。そのためには、各サービスが依存するサービスの障害を適切に処理し、エラーをユーザーに伝搬させないようにするなど、レジリエンスを持たせる必要があります。Figure 2.21 No pods for the Agenda service. If a service is failing, the user should be able to keep using the application with limited functionality. より引用著者が紹介していたように、サーキットブレーカーパターンを実装したり、適切にタイムアウトを設定したりすることが有効です。サーキットブレーカーとは、障害が発生したサービスへのリクエストを一時的にブロックし、迅速にエラーを返すことでカスケード障害を防ぐ仕組みです。また、各リクエストにタイムアウトを設定しておくことで、ダウンストリームのサービスの応答が遅い場合でもアプリケーション全体が停止するのを防げます。加えて、私からは、Istioのようなサービスメッシュを導入し、サービス間の通信を細かく制御する方法も提案したいです。サービスメッシュは、マイクロサービス間の通信を透過的にインターセプトし、ルーティングやトラフィック管理、セキュリティ、可観測性などの機能を提供するインフラストラクチャ層です。istio.io例えば、Istioを使えば、特定のマイクロサービスへのリクエストに対して、自動的にリトライを行ったり、エラー率が閾値を超えた際にサーキットブレーカーを発動させたりすることができます。さらに、バージョンの異なるサービスに対して、トラフィックを段階的に切り替えるカナリアデプロイメントも容易に実現できます。これらの機能により、マイクロサービスのレジリエンスとリリース管理が大きく改善されるでしょう。istio.ioステートフルなサービスをKubernetes上で運用する際の留意点についても言及がありました。ステートフルというのは、リクエスト間で状態を保持する必要のあるサービスを指します。代表例は、データベースやメッセージキューなどです。ステートフルサービスをコンテナとして運用する場合の課題は、Podが再起動した際にデータが失われないようにすることです。そのためには、データを永続化するためのストレージが不可欠です。Kubernetesには、各Podにボリュームを割り当てる仕組みがあり、ファイルシステムやブロックストレージ、オブジェクトストレージなど、多様なストレージをPodにマウントできます。kubernetes.ioまた、ステートフルサービスでは、Pod間でデータを同期する必要があるため、スケーリングが難しくなります。この問題に対処するため、Kubernetesには、StatefulSetというリソースが用意されています。StatefulSetを使うと、各Podに固有のネットワークアイデンティティを付与し、起動順序や停止順序を制御できます。Figure 2.25 Both data-sensitive services use persistent stores. Delegating state storage to external components, make your service stateless and easier to scale. より引用著者が言及していたように、データベースなどのステートフルなコンポーネントを切り出し、サービス自体はステートレスに保つことが望ましいアプローチだと言えます。例えば、ユーザーのセッション情報をRedisなどのキャッシュサーバーで管理することで、アプリケーションサーバー自体はステートレスになり、シームレスにスケールさせることができるようになります。私のチームでも同様の手法を取り入れており、大きな効果を上げています。分散システムにおいては、データの整合性の問題も避けて通れません。マイクロサービスアーキテクチャでは、データがサービス間で分散されているため、あるサービスから見たデータの状態が、他のサービスから見た状態と異なっている可能性があります。「結果整合性」と呼ばれるこの状態は、ビジネス要件に応じて許容されるケースもあれば、強い整合性が求められるケースもあります。いずれにせよ、データの不整合を検知し、解消するためのメカニズムが必要です。著者が提案していたのは、CronJobを使って定期的にデータの整合性をチェックする方法です。CronJobは、cron構文で記述されたスケジュールに従ってジョブ(Pod)を実行する仕組みです。例えば、毎日深夜に、各サービスのデータを突き合わせ、不整合があればアラートを上げるような運用が考えられます。Figure 2.27 Consistency checks can run as CronJobs. We can execute checks against the application services on fixed intervals to make sure that the state is consistent. For example: (1) every day at midnight we query the Agenda Service (2) to verify that the published sessions are approved in the (3) Call For Proposals Service and a corresponding notification has been sent by the (4) Notifications Service. より引用より洗練された方法としては、CDCを使って変更データをリアルタイムでキャプチャし、関連サービスに伝播させるような方法も考えられます。CDCとは、Change Data Captureの略で、データベースの変更を即座に検出し、他のシステムに通知する技術のことです。CDCを使えば、データの更新を全てのサービスに「できるだけリアルタイム」で反映させることができます。ただし、サービス間の疎結合性という観点からは、同期的な通信は避けたほうが良いかもしれません。非同期メッセージングを使ってイベントドリブンに通信するアプローチのほうが、マイクロサービスの理想に適っているでしょう。アプリケーションの適切な監視も、本章で大きく取り上げられたトピックでした。クラウドネイティブのアプリケーションでは、インフラからアプリケーションまで、あらゆる階層で可観測性(オブザーバビリティ)を確保することが求められます。著者が注目していたのは、OpenTelemetryです。OpenTelemetryは、CNCF(Cloud Native Computing Foundation)が主導するオープンソースプロジェクトで、メトリクス、ログ、トレースを統合的に扱うためのフレームワークを提供しています。OpenTelemetryに準拠したライブラリやエージェントを使えば、アプリケーションのコードに変更を加えることなく、各サービスから統一的なフォーマットで可観測性データを収集できます。opentelemetry.io収集したメトリクスは、Prometheusなどの時系列データベースに保存し、Grafanaなどの可視化ツールで分析・モニタリングするのが一般的です。Figure 2.28 Aggregating observability from all our services in a single place reduces the cognitive load on the teams responsible for keeping the application up and running. より引用著者の主張に大いに同意します。特に、大規模なシステムになるほど、各サービスが出力するログやメトリクスを個別に追跡するのは非常に骨の折れる作業になります。OpenTelemetryのようなフレームワークを活用し、可観測性データを一元的に管理することが必要不可欠だと考えられます。learning.oreilly.com加えて、PrometheusのアラートマネージャーでSLO(Service Level Objective)を定義し、それに基づいてアラートを発報する仕組みを整えることも重要だと感じられます。SLOとは、サービスが満たすべき具体的な指標のことで、可用性やレイテンシーに関する目標値を定量的に表したものです。SLOに対する違反が発生した際に適切にアラートが上がるようにしておくことで、障害の検知と対応を迅速に行えるようになります。本章で取り上げられた課題は、いずれもクラウドネイティブアプリケーションの開発において避けては通れないものばかりです。個々の課題にベストプラクティスで対処することに加えて、著者は課題の根本的な解決のためには\"プラットフォームエンジニアリング\"の実践が不可欠だと述べています。つまり、開発者がアプリケーションのコア機能の開発に専念できるよう、ビルド、デプロイ、運用などに関わる様々なプラットフォーム機能を自動化し、効率化することが求められるのです。Figure 2.33 Developers can focus on building features, but the platform team needs to automate the entire process after changes are made. より引用プラットフォームチームによる自動化の推進は、開発チームの生産性を大きく向上させることが期待できます。一方で、プラットフォームチームと開発チームのコミュニケーションは欠かせません。開発者のフィードバックを受けて、継続的にプラットフォームを改善していくことが肝要だと言えるでしょう。クラウドネイティブアプリケーションの課題を可視化し、プラットフォームエンジニアリングの必要性を明らかにした本章の議論は示唆に富むものでした。著者の知見を参考にしながら、開発者体験の向上と、より信頼性の高いシステムの構築を目指していくことが重要だと感じました。また、プラットフォーム自動化の取り組みを通じて、チーム全体の生産性を高めていくことも大きな目標になるはずです。次章以降では、より具体的なプラクティスが順次展開されるとのことです。クラウドネイティブの世界の最前線で活躍するエンジニアの知恵を学べる良い機会だと思います。本章で得られた知識を土台として、より実践的なスキルを身につけていくことが望まれます。カンファレンスアプリケーション(PoC)を題材に、プラットフォームの構築からアプリケーションの継続的デリバリーまでを一気通貫で学べるのは、他書にはない本書の大きな魅力だと感じました。本章では実際に手を動かしながら学べる内容が豊富でした。Helmを使ったデプロイ、kubectlを用いたトラブルシューティング、Deploymentの設定など、クラウドネイティブアプリケーションに携わる上で必須のスキルを体験的に学ぶことができたのは非常に有益でした。もちろん、著者も強調していたように、これらはあくまで基礎の一部に過ぎません。実際のプロダクション環境では、もっと複雑で予期せぬ事態が起こりうるでしょう。そうした事態にも柔軟に対応できるよう、本書で得た知見を活かしつつ、継続的にスキルを磨いていくことが肝要だと感じました。著者の豊富な知識と経験に基づいた本書を通じて、DevOpsの文化を組織に根付かせ、高品質なソフトウェアを継続的に提供できるチームを作り上げていくための多くの学びが得られることを期待したいと思います。Engineering Managementの観点からも、示唆に富む章になっています。3 Service pipelines: Building cloud-native applications本章では、クラウドネイティブアプリケーションの継続的デリバリーを実現するための要となるサービスパイプラインについて、非常に深く掘り下げた議論が展開されていました。learning.oreilly.comサービスパイプラインとは、ソースコードから複数の環境にデプロイ可能なリソースを生成するまでのプロセスを定義するものです。trunk-basedな開発や、1サービス=1リポジトリという実践を行うことが、チームがソフトウェアのビルドとリリースを効率的に標準化するのに役立ちます。trunkbaseddevelopment.comしかし、これはあくまで一般論であって、実際にはチームやアプリケーションに合ったやり方を見つける必要があります。万能の解決策などなく、トレードオフを考えなければならない場面も多いでしょう。アプリケーションを構成するサービスがどのくらいの頻度で変更されるのか、それらのサービスをどのように各環境にデプロイしていくのか。こうした問いに答えることで、サービスパイプラインの始点と終点を定義しやすくなります。例えば、UIを担うフロントエンドサービスの変更は、バックエンドのAPIに比べてより頻繁に行われるかもしれません。フロントエンド開発のためのテスト入門 今からでも知っておきたい自動テスト戦略の必須知識作者:吉井 健文翔泳社Amazonそうした場合、フロントエンド側のパイプラインは、できるだけ軽量でシンプルなものにしておく必要があります。頻繁なリリースサイクルに対応するため、ビルドやデプロイのプロセスを自動化し、効率化することが重要です。また、フロントエンドの変更がバックエンドに与える影響を最小限に抑えるため、両者の間にはしっかりとしたインターフェース定義が必要となります。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon一方、ビジネスロジックの中核を担うようなバックエンドサービスのパイプラインは、より厳格で、各種テストも充実させておく必要があるでしょう。バックエンドは、システムの根幹を成すコンポーネントであり、その品質と信頼性は非常に重要です。そのため、単体テスト、統合テスト、負荷テストなど、様々な観点からのテストを実施し、バグや脆弱性を早期に発見・修正することが求められます。また、バックエンドの変更は、他のサービスに広範な影響を与える可能性があるため、慎重にバージョン管理し、必要に応じてロールバック可能な状態を維持しておくことも大切です。このように、フロントエンドとバックエンドでは、その役割や特性に応じて、パイプラインの設計や運用方針を適切に調整することが重要です。こうした違いを意識しつつ、それぞれのサービスに適したパイプラインを設計していく。これは、サービスの独立性を確保しつつ、開発・リリースプロセス全体の効率を高める上で非常に重要なことだと言えます。マイクロサービスアーキテクチャが主流となる中で、サービスの独立性を担保しつつ、リリースプロセス全体の効率化を図る上で、サービスパイプラインは欠かせない存在です。サービスパイプラインを適切に設計し、運用することが、クラウドネイティブな開発の成功の鍵を握ると言っても過言ではありません。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオライリー・ジャパンAmazon著者は、サービスパイプラインを効果的に機能させるためのベストプラクティスをいくつも提示しています。例えば、trunk-based developmentを採用し、メインブランチを常にデプロイ可能な状態に保つことです。これにより、いつでもリリースができる状態を維持しつつ、変更を小さくすることで、リスクを最小限に抑えられます。また、メインブランチへのマージを厳格に管理することも重要です。レビューを徹底し、自動化されたテストをパスしたコードのみを受け入れるルールを設ける。これにより、メインブランチの品質を常に高く保てるはずです。docs.github.com加えて、Consumer-Driven Contract (CDC) テストの重要性も強調されていました。マイクロサービス間の依存関係を、テストとして明示的に管理することで、あるサービスの変更が他のサービスに与える影響を最小限に食い止められるのです。thoughtworks.github.ioCDCテストでは、あるサービス（Consumer）が依存するサービス（Provider）のAPIについて、期待する振る舞いを契約（Contract）として定義します。そしてその契約に基づいて、自動テストを生成するのです。これにより、Providerの実装が変更されても、Contract自体が守られている限り、Consumerには影響が及ばないことが保証されます。この手法は、マイクロサービス間の結合度を適切な形に保つ上で、非常に有効だと言えるでしょう。CDCテストを導入することで、各チームは自分たちのペースでサービスを進化させつつ、他のチームに与える影響を最小限に抑えられます。これは、マイクロサービスアーキテクチャのメリットを最大限に引き出すための重要な実践だと言えます。こうしたプラクティスは、単に技術的なものではありません。チーム間のコミュニケーションを円滑にし、リリースに関わる様々なステークホルダーの協調を促すことにも寄与します。サービスパイプラインを設計する際には、常にチームとプロセスに与える影響を考慮する必要があるでしょう。さらに、個々のサービスのライフサイクルに合わせて、パイプラインを柔軟に調整することの重要性も説かれていました。画一的な基準を全てのサービスに適用するのではなく、変更頻度や重要度に応じて最適化していくことが求められます。例えば、ユーザーに対するインターフェースとなるフロントエンドのサービスは、UIの変更が頻繁に行われるかもしれません。一方で、システムの根幹を支えるようなバックエンドサービスは、安定性が何より重視されるはずです。こうした特性の違いを踏まえて、フロントエンドのサービスにはより軽量で実行頻度の高いパイプラインを、バックエンドのサービスにはより厳格でステップの多いパイプラインを適用する、といった工夫が考えられます。要は、サービスの特性に合わせてパイプラインをチューニングしていくことが肝要だということですね。そのためには、各サービスがどのような特性を持ち、どのようなペースで変更が行われるのかを深く理解する必要があります。開発チームとの密なコミュニケーションを通じて、サービスの性質を見極めていくことが重要だと言えるでしょう。また、パイプラインを定義する際には、コードとしての管理が鍵になります。アプリケーションのコードと同様に、パイプラインのコードもバージョン管理し、再利用性や保守性を高めていく必要があるのです。そのためには、Dockerfileやデプロイメント用のマニフェストなど、パイプラインに関わる全てのリソースをコードとして扱うことが重要になります。つまり、Infrastructure as Codeの思想を、パイプラインにも適用するということですね。learning.oreilly.comこれは、単にパイプラインの品質を高めるだけでなく、アプリケーションの運用方法を明確に可視化することにも繋がります。コードを見れば、そのアプリケーションがどのようにビルド・デプロイされるのかが一目瞭然になるのです。特に、新しくチームに参加したメンバーのオンボーディングを助ける効果は大きいでしょう。パイプラインのコードがドキュメントの役割を果たし、アプリケーションの動作原理の理解を助けてくれるはずです。加えて、コード化されたパイプラインは、単なる自動化の手段ではありません。それは、チームのエンジニアリング文化そのものを表現するものだとも言えます。例えば、パイプラインにどのような品質ゲートを設けるのか、どの段階でレビューを行うのか、といった点は、チームの価値観や理念を反映したものになるはずです。つまり、パイプラインをコード化することは、チームのエンジニアリングプラクティスを明文化し、共有することでもあるのです。それによって、チームのスキルやノウハウの継承がスムーズになり、組織としての開発力の底上げにも繋がります。本章では、Tekton、Dagger、GitHub Actionsなど、パイプラインを実装するためのツールについても詳しく解説されていました。それぞれのツールの特性を理解し、自身のコンテキストに合ったものを選択することが重要だと感じました。learning.oreilly.comGitHubが提供するGitHub Actionsのようなマネージドサービスを利用するのも一つの選択肢です。インフラの管理は全てGitHubに任せられるため、初期コストを大幅に下げられます。ただし、実行時間に応じた従量課金制のため、大規模なワークロードを流し続けるとコストが高くつく可能性もあります。プラットフォームを構築する立場からは、GitHub Actionsのような便利なツールだけに頼るのではなく、自社に最適化されたタスクやパイプラインを柔軟に作れるツールを選ぶ必要があるでしょう。また、開発者がローカルでパイプラインを実行できるようにしておくことも、DXを高める上で重要なポイントになります。せっかくパイプラインを自動化しても、毎回クラウドにデプロイしないと動作確認ができないようでは、開発者の生産性は大きく損なわれてしまいます。開発者のフィードバックサイクルを如何に短くできるかは、パイプラインツールの選定において考慮すべき大切な視点だと言えるでしょう。github.com例えばTektonは、Kubernetesとの親和性が高く、宣言的なパイプラインの定義が可能です。Kubernetesのカスタムリソースとしてパイプラインを表現できるため、他のKubernetesリソースとの連携が容易だというメリットがあります。また、Tektonには豊富なコミュニティ貢献のタスクが用意されているのも魅力の一つです。Tekton Hubと呼ばれるカタログサイトから、再利用可能なタスクを検索し、自分のパイプラインに組み込むことができます。これらのタスクは、Kubernetesのエキスパートたちによって作られ、ベストプラクティスが詰め込まれています。それらを活用することで、信頼性の高いパイプラインを素早く構築できるでしょう。tekton.dev一方、Daggerは、プログラミング言語でパイプラインを記述できるため、より動的で複雑な処理を表現しやすいという特徴があります。Go、Node.js、Python、Javaなど、様々な言語のSDKが提供されているのも、開発者にとって嬉しいポイントだと言えます。言語の持つ柔軟性を活かして、条件分岐や繰り返し処理を含む高度なパイプラインを実装できます。また、言語のエコシステムを活用して、外部ライブラリとの連携も容易です。例えば、テストの実行結果をSlackに通知したり、カスタムスクリプトを組み込んだりといったことが、シームレスに行えるでしょう。dagger.ioまた、Daggerの大きな特長は、ローカル環境でもそのままパイプラインを実行できる点にあります。手元の環境で簡単にパイプラインの動作検証ができるため、開発者の生産性が大きく向上するでしょう。クラウド上の環境を完全に再現するのは難しくても、パイプラインのコアとなるロジックは、ローカルで十分にテストできるはずです。これにより、クラウドへのデプロイ回数を減らし、無駄なコストを削減できます。また、ローカルでパイプラインを実行できれば、開発中のアプリケーションに合わせて、パイプラインを柔軟にカスタマイズしていくことも容易になります。チームのスキルセットや、アプリケーションのアーキテクチャによって、適切なツール選定は変わってくるでしょう。一つの正解があるわけではありません。重要なのは、チームにとって最も生産性の高い方法を追求し続けることだと感じました。さらに、ローカル環境でのパイプラインの実行も、開発者の生産性を大きく左右する要素として挙げられていました。クラウド上の環境を完全に再現するのは難しくとも、手元で気軽にパイプラインを実行できれば、圧倒的にフィードバックループが早くなるはずです。加えて、コードとして表現することで、より柔軟なパイプラインの実現も可能になります。単なるYAMLの設定ファイルでは表現しきれないような、動的なロジックを組み込むこともできるはずです。例えば、あるサービスのテスト結果を受けて、別のサービスのデプロイを条件付きでスキップする、といったことも可能になるでしょう。この柔軟性は、マイクロサービスの独立性を担保する上でも重要な意味を持ちます。あるサービスの障害が、他のサービスのデプロイを止めてしまうようでは、真の意味でのマイクロサービスとは言えません。パイプラインを通じて、各サービスのライフサイクルを適切に制御することが、マイクロサービスアーキテクチャを成功に導く鍵だと言えるでしょう。Figure 3.14 Local vs. remote service pipelines より引用このように、サービスパイプラインを適切に定義し、運用していくことは、クラウドネイティブなアプリケーション開発において欠かせない実践だと言えます。そのためのツールの選定は、単に機能や性能だけでなく、開発者のエクスペリエンスや、チームのカルチャーとの親和性など、多面的な視点から行う必要があります。Figure 3.5 Running pipelines requires a lot of infrastructure to be in place. より引用パイプラインを実行するためには、図にあるように、様々なインフラの整備が必要不可欠です。各種リポジトリ、コンテナレジストリ、Kubernetesクラスターなど、多岐にわたるコンポーネントを連携させる必要があります。これらのインフラを個別のプロジェクトごとに構築するのは非常に非効率です。コストや管理の手間を考えると、組織横断で共有できるプラットフォームとして提供するのが望ましいでしょう。そこで重要になってくるのが、プラットフォームチームの存在です。プラットフォームチームは、開発チームが利用しやすいパイプラインのテンプレートを用意し、ベストプラクティスをコード化して提供します。具体的には、言語ごとのビルドやテストのツールセット、デプロイに必要なマニフェストの生成ロジックなどを、プラットフォームとして標準化するのです。開発チームはそれらを利用しつつ、各アプリケーションに特化した処理を付け加えていけば良いでしょう。こうすることで、開発チームは本質的なロジックの実装に集中でき、しかも一定の品質を担保されたパイプラインを利用できるようになります。まさに、プラットフォームが提供すべき価値だと言えます。一方で、全てのアプリケーションに対して、一律のパイプラインを適用するのは現実的ではありません。例えば、レガシーなシステムをマイクロサービス化する過程では、新旧のサービスが混在することになります。レガシーなサービスに対しては、従来のビルドツールやデプロイ手法を踏襲せざるを得ないかもしれません。そうした例外に対しては、プラットフォームチームが柔軟に対応し、段階的な移行をサポートしていく必要があります。究極的には、パイプラインのコードを通じて、プラットフォームと開発チームのコラボレーションを促進することが肝要です。開発チームはアプリケーションに関する知見を、プラットフォームチームはインフラに関する知見を持ち寄り、パイプラインの継続的な改善を進めていく。それこそが、クラウドネイティブ時代のDevOpsの理想形と言えるでしょう。本章を通じて、改めてサービスパイプラインの重要性と、その構築の難しさを実感しました。単なるツールの選定や設定の問題ではなく、開発プロセス全体に関わる設計が求められるのです。組織の文化や、開発チームの成熟度なども考慮しなければなりません。画一的な答えはなく、試行錯誤を重ねながら、自社に最適な形を模索していく必要があります。そのためには、プラットフォームチームと開発チームの密なコラボレーションが不可欠です。サービスパイプラインは、エンジニアリングの課題であると同時に、組織の課題でもあるのだと、強く認識させられる内容でした。また、パイプラインのコード化の重要性は、開発者としての自分の仕事の進め方にも示唆を与えてくれました。テストやデプロイの方法をコードの一部として捉え、アプリケーションと一体になったものとして扱うこと。それによって、より俯瞰的に開発プロセスを捉えられるようになるはずです。さらに、パイプラインのコード化は、アプリケーションの品質を長期的に担保していく上でも重要な意味を持ちます。メンバーが入れ替わっても、その時点での最良のプラクティスが脈々と受け継がれていく。まさに、継続的インテグレーション・継続的デリバリーの価値を体現するものだと言えるでしょう。ちなみに、著者は継続的デリバリーに関する優れた書籍として、「Continuous Delivery」と「Grokking Continuous Delivery」の2冊を挙げていました。私も特に「Grokking Continuous Delivery」は非常に分かりやすく、お勧めの一冊です。継続的デリバリーの考え方や、パイプラインの設計方法について、体系的に学ぶことができます。syu-m-5151.hatenablog.comクラウドネイティブの世界で開発者として生きていく上で、サービスパイプラインをどう構築・活用していくかは避けて通れない問題です。ただツールを選ぶだけでなく、自分たちの開発文化そのものを設計する。そんな広い視野を持つことの大切さを、本章は教えてくれました。もちろん、これは簡単なことではありません。日々の開発タスクに追われる中で、パイプラインまで手が回らないというのが正直なところでしょう。だからこそ、プラットフォームチームの役割が重要になってくるのです。現場の開発者の負担を減らしつつ、ベストプラクティスの採用を促していく。そのための仕組みと文化を育てていくことが、プラットフォームチームに求められる使命だと言えます。理想的なサービスパイプラインの姿は、組織によって異なるでしょう。どこを目指すのか、そのために何をすべきかは、組織の状況に応じて見極めていかなければなりません。ただ、開発者として心に留めておきたいのは、サービスパイプラインの構築は、決して他人事ではないということです。自分たちで作ったアプリケーションを、自分たちの手でより良い形でお客様に届けるために、パイプラインを日々改善していく。そんな当事者意識を持つことが、クラウドネイティブ時代のソフトウェアエンジニアに求められているのだと感じます。その意味で、本章はサービスパイプラインについての技術的な知見だけでなく、開発者としてのマインドセットを見つめ直すためのヒントも与えてくれました。著者の知見に導かれながら、自分なりのベストプラクティスを追求していきたいと思います。継続的デリバリーの実現は、一朝一夕にはいきません。しかし、その過程で得られる学びは、エンジニアとしての成長に直結するはずです。プラットフォームチームと開発チームが一丸となって、理想のパイプラインを追求していく。そのために、一人一人が当事者意識を持って臨むことが何より大切だと、本章を読んで強く感じました。本章の内容は、そのための第一歩を踏み出すための勇気と知見を与えてくれるはずです。著者の経験に基づく生きたアドバイスの数々は、きっと読者の心に響くことでしょう。理想的なパイプラインを構築するのは簡単ではありませんが、その過程で得られる学びは計り知れません。失敗を恐れず、仮説検証を繰り返しながら、自分たちなりのベストプラクティスを追求していく。そうした探求心こそが、エンジニアを駆り立てる原動力になるはずです。本書の主題である\"プラットフォームエンジニアリング\"も、そうした探求の先に見えてくるものだと感じています。開発者とインフラの垣根を越えて、アプリケーションとプラットフォームが一体となった開発スタイルを確立する。それはまさに、クラウドネイティブ時代のソフトウェア開発の理想形と言えるでしょう。本章はそのためのロードマップを提示してくれました。読者の皆さんには、ぜひ自分たちなりのサービスパイプライン構築に挑戦してみてください。きっと、開発者としての新たな可能性に気づくことができるはずです。4 Environment pipelines: Deploying cloud-native applications本章では、サービスパイプラインによって生成されたリソースを実際の環境にデプロイするための「パイプライン」について深く掘り下げられていました。私たちが作り上げたアプリケーションが真の価値を生むのは、それが実際のユーザーに届けられて初めて可能になります。そのためには、開発環境から本番環境まで、様々なステージを経由しながら、アプリケーションを安全かつ確実にデプロイしていく必要があります。この一連のプロセスを自動化し、信頼性と再現性を担保するのが、パイプラインの役割だと言えるでしょう。例のGitOpsのページが移動されたのでGoogle Cloudさんのページを公開しておきます。cloud.google.com著者は特に、GitOpsの考え方を取り入れることの重要性を強調していました。GitOpsとは、環境の設定をコードとして管理し、Gitリポジトリを信頼できる唯一の情報源として扱う手法のことを指します。つまり、インフラストラクチャのあるべき状態を宣言的に記述し、それをGitで管理するのです。GitOpsに従えば、環境の状態は常にGitリポジトリの内容と同期されていなければなりません。環境に変更を加えるには、Gitリポジトリに対してプルリクエストを発行し、レビューを経てマージするというプロセスを踏むことになります。Figure 4.10 Argo CD will sync environments, configurations from Git to live clusters より引用これにより、変更の履歴が追跡可能になるだけでなく、問題が発生した際にはすぐに前のバージョンに戻せるようになります。また、設定のドリフトを防ぎ、環境間の一貫性を保つことも容易になるのです。インフラストラクチャの状態をコードで表現することで、それを他の人と共有したり、レビューしたりすることが可能になります。つまり、インフラストラクチャの変更も、アプリケーションコードの変更と同様に、プルリクエストベースのワークフローに乗せられるようになるのです。GitOpsを実装するためのツールとして、本章ではArgo CDが紹介されていました。Argo CDは、Kubernetes向けの継続的デリバリーツールであり、GitリポジトリとKubernetesクラスターを監視し、両者の状態を同期し続けてくれます。具体的には、Gitリポジトリに格納されたマニフェストファイルを読み取り、それをKubernetesクラスターに適用するのです。もし、クラスターの状態がマニフェストファイルの内容と異なっていれば、Argo CDが自動的にそれを修正してくれます。argo-cd.readthedocs.ioまた、Argo CDは直感的なWebインターフェースを提供しており、そこからデプロイメントの状況をビジュアルに把握できます。どのアプリケーションがどのバージョンで動いているのか、そのヘルスステータスはどうなっているのかなどを一目で確認できるのは、オペレーションの効率化に大きく寄与するでしょう。Figure 4.18 Components to set up the staging environment with Argo CD より引用Argo CDとHelmを組み合わせることで、より強力なGitOpsのワークフローを実現できます。Helmは、Kubernetesのパッケージマネージャーであり、アプリケーションの設定値をパラメータ化し、テンプレート化することができます。つまり、Helmを使えば、同じアプリケーションを異なる環境に、異なるパラメータセットで展開することが容易になるのです。helm.shArgo CDは、このHelmチャートも管理対象とすることができます。Gitリポジトリに格納されたHelmチャートを読み取り、それをKubernetesクラスターにデプロイするのです。この組み合わせにより、アプリケーションの設定とインフラストラクチャの設定を、一元的にコードで管理することが可能になります。本書のステップバイステップのチュートリアルでは、実際にArgo CDとHelmを使って、サンプルアプリケーションをKubernetesクラスターにデプロイする手順が丁寧に解説されていました。これを通じて、GitOpsの実践的なスキルを身につけることができたのは、大変貴重な経験となりました。パイプラインは、ソフトウェアリソースを本番環境にデプロイする責務を負っています。パイプラインにより、チームが直接クラスターを操作する必要がなくなり、エラーや設定ミスのリスクを減らせます。また、環境の更新後には、きちんと動作確認を行う必要があります。Argo CD のようなツールを使えば、各環境の内容をGitリポジトリで定義し、信頼できる唯一の情報源として扱うことができます。Argo CD は、クラスターの状態を追跡し、適用された設定にドリフトが発生していないことを保証します。開発チームは、環境で実行されているサービスのバージョンを、環境設定のリポジトリにプルリクエストを発行することでアップグレード・ダウングレードできます。変更はレビューを経てマージされ、承認されれば即座に環境に反映されます。問題が発生した場合は、Gitのコミットを元に戻すことで、ロールバックが可能です。パイプラインは、私たちの開発プロセスに多くのメリットをもたらしてくれます。まず、環境への直接的な干渉を排除し、設定ミスや不整合によるトラブルを防ぐことができます。手作業によるミスを減らし、オペレーションを自動化・標準化できるのです。また、環境の設定を統一的に管理することで、本番環境の再現や、新しい環境の立ち上げを容易にします。テスト環境や、開発者一人ひとりの環境を、本番と同じ構成で簡単に作れるようになるでしょう。このことは、「本番で動くから大丈夫」という過信を排除し、より早い段階で問題を発見・解決することにつながります。加えて、変更管理のプロセスを明確にすることで、開発チーム間のコミュニケーションとコラボレーションを促進します。インフラストラクチャの変更も、アプリケーションの変更と同列に扱われ、レビューの対象になる。これにより、開発者とオペレータの境界が曖昧になり、両者の理解が深まっていくはずです。パイプラインは、アプリケーションの信頼性と安定性を支える重要な基盤であると同時に、開発者のワークフローを改善する強力な手段でもあるのです。適切に実装・運用されたパイプラインは、ビジネススピードを加速し、イノベーションを促進してくれるでしょう。一方で、パイプラインの導入には、一定のコストと学習曲線が伴うことも事実です。GitOpsの考え方に基づいて環境を設計し、適切なツールを選定し、チームの文化を変革していくには、時間と努力が必要となるでしょう。単に新しいツールを導入すれば良いというものではなく、それを活用するためのスキルセットやマインドセットを、チーム全体で醸成していかなければなりません。特に、Kubernetesのようなモダンなプラットフォームを前提としたパイプラインでは、従来のオペレーションとは異なるスキルが要求されます。コンテナやオーケストレーションの知識はもちろん、インフラストラクチャをコードで管理するためのプラクティス、つまりInfrastructure as Code (IaC)についても習熟が必要です。また、GitOpsは強力なプラクティスである一方、万能ではありません。例えば、データベースのスキーマ変更のように、ステートフルで複雑な処理をどう扱うかは、頭を悩ませる問題です。すべてをGitOpsでカバーしようとするのではなく、他のアプローチと適切に組み合わせていくことが肝要でしょう。しかし、長期的な視点に立てば、その投資は必ず報われるはずです。パイプラインを通じて得られる俊敏性と安定性は、ビジネスの成功に直結する重要な要因になると私は確信しています。変化の激しい現代のビジネス環境において、いかに素早く、安全に価値を届けられるかが、競争力の源泉になるのですから。パイプラインは、クラウドネイティブなアプリケーション開発において欠かせない要素です。単純な自動化の仕組み以上に、それは私たちの開発文化そのものを変革する起爆剤にもなり得ます。サービスパイプラインとパイプラインが織りなす継続的デリバリーの世界。そこには、より柔軟で、より俊敏で、より確実なソフトウェア開発の未来が広がっているのです。本章を通じて、パイプラインの真価と、それを実装するための具体的な方法論を学ぶことができました。GitOpsという新しいアプローチは、私にとって目から鱗が落ちる思いでした。単にツールを導入するだけでなく、宣言的にインフラストラクチャを記述し、それを中心にワークフローを回していく。そうしたマインドセットの変革の必要性を強く感じさせられました。Kubernetesという土壌の上に、Argo CDやHelmを駆使して、信頼性と速度を兼ね備えたデリバリーパイプラインを築く。本章は、そのための道標となってくれるはずです。私たち一人ひとりが、チームやプロジェクトの文脈に合わせてこの知見を咀嚼し、パイプラインをどう実装していくか。そこには正解はなく、試行錯誤の連続になるかもしれません。レビューを経ずにインフラストラクチャの変更が行われたり、手動での作業が残っていたりと、理想とする状態には程遠いのが実情でしょう。しかし、だからこそDevOpsの実践が求められているのだと、私は考えます。パイプラインは、開発者とオペレータの協力を促し、継続的な改善を導く強力な仕組みです。それを通じてチームのフィードバックループを回していくことが、私や私たちに課せられた使命だと言えます。ステップバイステップのチュートリアルを実践して、Argo CD を用いてGitOpsの考え方に基づいたデプロイを体験できました。はじめは小さなスコープから始めて、徐々にカバレッジを広げていくのが良いかもしれません。5 Multi-cloud (app) infrastructure本章では、クラウドネイティブアプリケーションのインフラストラクチャをマルチクラウド環境で管理する上での課題と、それを解決するためのアプローチについて詳細に解説されていました。マイクロサービスアーキテクチャの普及により、アプリケーションを構成する各サービスは、データベースやメッセージブローカーなどの依存コンポーネントを必要とするようになりました。これらのコンポーネントをクラウドプロバイダー固有の方法で構築・運用すると、ベンダーロックインの問題が生じ、アプリケーションのポータビリティが損なわれます。つまり、あるクラウドプロバイダーで構築したアプリケーションを、別のクラウドプロバイダーに移行することが難しくなるのです。learning.oreilly.comこの問題を解決するために、筆者はKubernetes APIとCrossplaneの活用を提案しています。Crossplaneは、Kubernetesのエコシステムの一部として開発されたオープンソースのプロジェクトで、主要なクラウドプロバイダーのリソースをKubernetesのカスタムリソースとして管理することができます。Crossplaneを使うことで、クラウドプロバイダーに依存せずにインフラをプロビジョニングできるため、マルチクラウド戦略を推進する上で非常に重要な役割を果たします。www.crossplane.ioCrossplaneの中核となる機能が、Composite Resource Definitions（XRDs）です。XRDsは、Kubernetesのカスタムリソースを定義するための仕組みで、ドメイン固有の概念をKubernetesのオブジェクトとして表現できます。例えば、\"Database\"や\"MessageQueue\"といったアプリケーションが必要とするコンポーネントを、XRDsを通じて抽象化することができます。プラットフォームチームは、XRDsを適切に設計することで、アプリケーションチームが必要とするリソースを宣言的に要求できるインターフェースを提供します。XRDsを定義する際には、アプリケーションチームのニーズを的確に捉えることが重要です。単に技術的な観点からリソースを抽象化するのではなく、アプリケーションチームがどのような概念で infrastructure as code を考えているのかを理解する必要があります。例えば、あるアプリケーションチームは \"Database\" というリソースを、「リレーショナルデータベースであること」「高可用性を備えていること」「自動バックアップが設定されていること」といった特性を持つものとして捉えているかもしれません。一方、別のチームは \"Database\" を、「ドキュメント指向のデータベースであること」「スキーマレスであること」「地理的に分散されたレプリケーションを備えていること」といった特性を持つものとして考えているかもしれません。プラットフォームチームは、これらの異なる要求を抽象化し、統一的なインターフェースを提供する必要があります。つまり、XRDsの設計には、アプリケーションチームとのコミュニケーションと、ドメインの深い理解が不可欠なのです。また、XRDsを定義する際には、将来の拡張性も考慮しなければなりません。アプリケーションチームのニーズは常に変化するため、XRDsもそれに合わせて進化させる必要があります。したがって、XRDsの設計はアプリケーションチームとの継続的な対話を通じて、段階的に洗練させていくべきものだと言えます。XRDsに対応するCompositionの設計も、同様に重要です。Compositionは、XRDsによって定義されたリソースを、実際のクラウドプロバイダー上のリソースにマッピングするための仕組みです。つまり、Compositionは、XRDsとクラウドプロバイダーの間の橋渡しの役割を果たします。Compositionを定義する際には、クラウドプロバイダーのサービスやAPIに関する深い知識が必要になります。例えば、あるCompositionでは、XRDsで定義された \"Database\" リソースを、Amazon RDSのPostgreSQLインスタンスにマッピングするかもしれません。その際、RDSインスタンスの作成に必要なすべてのパラメータ（インスタンスクラス、ストレージサイズ、ネットワーク設定など）を、XRDsで指定されたパラメータから適切に設定しなければなりません。また、RDSインスタンスに付随するその他のリソース（セキュリティグループ、モニタリング設定、バックアップ設定など）も、同時に作成・設定する必要があります。これらのリソースの作成や設定には、AWSのAPIやSDKを使用することになります。したがって、Compositionの設計には、クラウドプロバイダーのAPIやSDKに関する知識と、それらを効果的に活用するためのプログラミングスキルが求められます。また、クラウドプロバイダーのベストプラクティスやレコメンデーションにも精通している必要があります。例えば、AWSには、Well-Architectedフレームワークというベストプラクティスの集大成がありますが、Compositionの設計はこれに沿ったものであるべきです。さらに、Compositionの設計には、運用面での考慮も欠かせません。作成したリソースを適切にモニタリングし、問題が発生した際には速やかに検知・通知できる仕組みを用意しなければなりません。また、リソースの変更管理やバージョン管理、ロールバック機能なども必要になります。これらの運用機能は、クラウドプロバイダーのサービスを活用することで実現できる場合もありますが、Compositionレベルでの抽象化が必要なケースもあるでしょう。加えて、Compositionではインフラストラクチャのコストの最適化も考慮する必要があります。クラウドプロバイダーのサービスは、そのほとんどが従量課金制で提供されています。したがって、Compositionで作成するリソースのスペックや数量を適切に設定し、不要なコストが発生しないように注意しなければなりません。そのためには、アプリケーションの要件を正確に把握し、それに見合ったリソースを過不足なくプロビジョニングすることが求められます。以上のように、XRDsとCompositionの設計には、アプリケーションドメインに関する知識、クラウドプロバイダーのサービスやAPIに関する知識、プログラミングスキル、運用スキル、コスト最適化のスキルなど、多岐にわたる専門性が必要とされます。つまり、プラットフォームチームには、従来のインフラストラクチャの管理とは異なるスキルセットが求められるのです。特に、クラウドプロバイダーのサービスやAPIは常に進化し続けているため、プラットフォームチームはそれらの変化に追随し続ける必要があります。新しいサービスや機能が登場した際には、それらをどのようにCompositionに取り込むか、XRDsのインターフェースにどう反映するかを検討しなければなりません。つまり、Crossplaneを活用したプラットフォームの構築は、継続的な学習と改善のプロセスだと言えます。また、プラットフォームチームは、アプリケーションチームとインフラストラクチャチームの間に立つ存在でもあります。両チームの要求や制約を理解し、それらを適切にXRDsやCompositionに反映していく必要があります。つまり、プラットフォームチームには、技術的なスキルだけでなく、コミュニケーション能力やコーディネーション能力も求められるのです。Crossplaneは、GitOpsとの親和性も高いことが特徴の一つです。XRDsで定義されたリソースは、Kubernetesのマニフェストファイルと同様に、Git上で管理することができます。つまり、インフラストラクチャの状態をGitリポジトリで管理し、Gitのワークフローに乗せることで、インフラストラクチャの変更を宣言的に管理できるのです。GitOpsを採用することで、インフラストラクチャの変更は、Gitリポジトリへのコミットとして表現されます。したがって、変更の経緯を追跡しやすく、変更のレビューやテストも行いやすくなります。また、リポジトリの状態とクラスターの状態を常に同期させることで、インフラストラクチャの状態のドリフトを防ぐこともできます。GitOpsとCrossplaneを組み合わせることで、アプリケーションのデプロイメントパイプラインにインフラストラクチャの変更を統合することも可能になります。アプリケーションの変更に必要なインフラストラクチャの変更を、アプリケーションのソースコードと同じリポジトリで管理し、同じパイプラインでデプロイすることで、アプリケーションとインフラストラクチャのライフサイクルを一元的に管理できるのです。ただし、GitOpsの実践には、独自の課題もあります。例えば、Gitリポジトリの構成をどのように設計するか、secrets の管理をどうするか、変更の競合をどう解決するかなど、運用面での検討が必要になります。また、GitOpsではインフラストラクチャの変更がコードとして表現されるため、コードのクオリティを維持するためのプラクティス（レビュー、テスト、リファクタリングなど）も必要になります。Crossplaneを活用したマルチクラウドでのアプリケーション基盤の構築は、大きな可能性を秘めていますが、同時に多くの課題も抱えています。技術的な複雑さだけでなく、組織やプロセスの変革も必要になります。プラットフォームチームの役割と責任、アプリケーションチームやインフラストラクチャチームとの協調の在り方など、従来とは異なる体制が求められるでしょう。また、マルチクラウド環境では、各クラウドプロバイダーの特性を理解し、それらを適切に活用することも重要です。単に複数のクラウドを使うのではなく、各クラウドの強みを生かし、弱みを補完し合うような設計が必要になります。そのためには、プラットフォームチームがクラウドプロバイダーの動向を常に把握し、最新の知見を取り入れ続けなければなりません。さらに、マルチクラウド環境では、セキュリティやコンプライアンス、コスト管理などの課題もより複雑になります。各クラウドプロバイダーのセキュリティ機能や料金体系を理解し、それらを横断的に管理・統制する必要があります。また、クラウド間でのデータの移動や同期、可用性や性能の確保など、アーキテクチャ面での検討も欠かせません。こうした課題を解決するには、プラットフォームチームの高度な技術力とともに、組織全体での意識改革と協調が不可欠です。アプリケーションチームは、インフラストラクチャを意識したアプリケーション設計を行う必要がありますし、インフラストラクチャチームは、アプリケーションの要件を理解した上でインフラストラクチャを提供する必要があります。また、セキュリティチームや財務チームなど、関連する他部門とのコラボレーションも重要になるでしょう。つまり、Crossplaneを活用したプラットフォームエンジニアリングは、単なる技術的な取り組みではなく、組織文化の変革でもあるのです。siloを打破し、チーム間のコラボレーションを促進し、継続的な学習と改善を組織に根付かせること。それがプラットフォームチームに求められる重要な役割だと言えます。本章の内容は、こうしたプラットフォームエンジニアリングの課題と可能性を、Crossplaneを中心に論じたものでした。筆者自身、日々の業務でKubernetesやCrossplaneに携わる中で、その難しさと面白さを実感しています。特に、XRDsとCompositionの設計は、奥が深く、まだまだ学ぶべきことが多いと感じています。しかし同時に、プラットフォームエンジニアリングのもたらす価値の大きさにも気づかされました。アプリケーションとインフラストラクチャの垣根を越えて、開発と運用の連携を深化させ、ビジネスの俊敏性を高めていく。それは、DXの実現に直結する取り組みだと言えます。もちろん、そこに至るまでの道のりは平坦ではありません。レガシーシステムとのインテグレーション、組織間の政治的な力学、既存の文化や習慣の壁など、立ちはだかる障壁は数多くあります。しかし、それでもなお、プラットフォームエンジニアリングへの挑戦は避けられないものだと感じています。なぜなら、それは単に技術的な必然ではなく、ビジネス環境の変化に対応するための組織的な必然でもあるからです。クラウドやDevOpsの普及により、ソフトウェアがビジネスを左右する時代になりました。そんな時代に求められるのは、変化に素早く適応し、イノベーションを継続的に生み出せる組織の仕組みです。プラットフォームエンジニアリングは、まさにそのような仕組みを実現するためのアプローチだと言えます。開発と運用の連携を高め、アプリケーションとインフラストラクチャをシームレスに扱うことで、ソフトウェア・デリバリーのスピードと質を高める。また、自動化と抽象化を進めることで、チームがよりビジネスに価値のある活動に注力できるようにする。こうしたプラットフォームエンジニアリングの価値は、もはや特定の業界や企業規模に限定されるものではありません。クラウドネイティブの考え方は、あらゆる業界・規模の企業に浸透しつつあります。つまり、プラットフォームエンジニアリングは、どの企業にとっても無視できない重要な取り組みになりつつあるのです。とはいえ、プラットフォームエンジニアリングは万能薬ではありません。過度な自動化や抽象化は、かえって複雑性を生み、イノベーションを阻害する可能性もあります。重要なのは、自社のコンテキストをしっかりと理解した上で、適切な段階的アプローチを取ることです。その意味で、本書はプラットフォームエンジニアリングを進める上での良き指針になるでしょう。Crossplaneを中心とした技術的な側面だけでなく、チームの構成や文化、プロセスといった組織的な側面についても、バランス良く論じられていました。これは、プラットフォームエンジニアリングが、技術と組織の両面にまたがる取り組みだからこそ重要な視点だと感じました。筆者自身、本章で得られた知見を日々の業務に活かしていきたいと考えています。特に、XRDsとCompositionの設計については、アプリケーションチームとのコミュニケーションを密にし、ドメインモデルを深く理解することの重要性を再認識しました。また、プラットフォームチームの在り方についても、本書で提示された視点を参考に、自社での最適な形を模索していきたいと思います。6 Let's build a platform on top of KuberneteKubernetes上でのプラットフォーム構築に関する具体的な方法論と深い洞察に満ちた、非常に示唆に富む内容でした。著者は、プラットフォームエンジニアリングにおける重要な概念と実践を、豊富な事例とともに解説しています。第6章の前半では、プラットフォームAPIの設計と、マルチクラスター・マルチテナンシーの課題が中心的に論じられています。まず著者は、プラットフォームが Kubernetes 上で提供すべき機能を特定することの重要性を説いています。開発チームのワークフローを理解し、彼らが必要とするサービスを抽出することが、プラットフォームAPIの設計の出発点となります。ここでは、開発チームが新しい環境を要求するシナリオを例に、APIのデザインプロセスが丁寧に解説されています。要求された環境をプロビジョニングし、アクセス情報を返却する自動化ロジックを実装することで、開発チームの生産性を大きく向上できるのです。このアプローチは、プラットフォームエンジニアリングの神髄とも言うべきものです。技術的な実装の前に、ユーザーである開発者の体験を起点に設計を進めるというマインドセットこそが、真に開発者に寄り添ったプラットフォームを生み出す鍵となります。続く議論では、マルチクラスターおよびマルチテナントのセットアップに関する課題が取り上げられます。本番、ステージング、開発など、様々な環境を提供する必要があるKubernetesベースのプラットフォームでは、これらの課題が避けて通れません。著者は、プラットフォーム専用のクラスターを設けることで、一貫した管理と高い可用性を実現するアプローチを提案しています。ワークロードとは分離された環境でArgoCD、Crossplaneなどのツールを用いてプラットフォームを構築することで、求められるSLOやセキュリティ要件に適切に対処できるのです。また、マルチテナンシーの実現方法として、Namespaceによる分離と、完全に独立したクラスターによる分離のトレードオフについても、鋭い考察が展開されています。前者は手軽である一方で分離のレベルが低く、後者は強力な分離を提供する反面コストと運用負荷が大きいという、難しい選択の狭間にある課題です。この問いに対する著者の提案が、vclusterを用いた仮想クラスターのアプローチです。1つのKubernetesクラスター内に、テナントごとに独立したコントロールプレーンを持つ仮想クラスターを動的に生成することで、Namespaceと独立クラスターの中間的な選択肢を提供できるのです。www.vcluster.comAPIサーバーレベルの分離により、テナントはクラスター全体に対する高い自由度を享受しつつ、リソースの利用効率を高められる。これは、マルチテナンシーの難しい課題に対する、エレガントな解決策の一つと言えるでしょう。以上の議論を通じて、読者はKubernetes 上のプラットフォームがどのようなものかを具体的に理解できるようになります。プラットフォーム構築には、インフラストラクチャの設計だけでなく、開発者の体験を起点とした抽象化やAPIのデザインが不可欠だということ。そして、それを実現するためには、Kubernetesの深い理解に加え、マルチクラスター・マルチテナンシーの課題に正面から向き合う必要があるということ。第6章の前半は、そうした重要な気づきに満ちています。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。以上のように、複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン(PoC)」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。Figure 6.9 Combining GitOps and Crossplane for managing environments and clusters より引用さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。Figure 6.16 Using Crossplane and vcluster to create isolated environments for application development teams より引用もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。Figure 6.18 Platform walking skeleton tools, configurations, and services より引用実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。Figure 6.19 Platform responsibilities and boundaries より引用本章は、プラットフォームエンジニアリングの本質を、概念と実装の両面から照らし出してくれる、稀有な内容でした。単なるツールの解説にとどまらず、開発者の体験を起点とした設計思想や、チームとの協調の重要性など、プラットフォーム構築に不可欠な知見が余すところなく述べられています。本章を通じて、私はプラットフォームの構築が、技術とプロセス、そして文化の融合であることを改めて認識しました。優れたツールの選定と適切な組み合わせは もちろん重要です。しかし、それ以上に大切なのは、開発者の声に耳を傾け、彼らの創造性を解き放つ仕組みを築くことなのだと。Kubernetesとそのエコシステムは、プラットフォームを構築するための強力な基盤を提供してくれます。しかし、それをどう活用し、どのような形でチームに提供するかは、私たち自身の創意工夫次第です。技術の力を借りつつ、開発者の声に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は教えてくれました。本章は、プラットフォームエンジニアリングという新しい領域に踏み出すための、確かな一歩を印してくれる内容でした。著者の知見を自分なりに咀嚼し、日々の開発プロセスに活かしていく。その積み重ねの先に、真のDXを実現するプラットフォームが生まれるはずです。7 Platform capabilities I: Shared application concerns著者は冒頭で、クラウドネイティブアプリケーションの95%が行っている要件を学ぶことの重要性を強調しています。その要件とは、他のサービスとの通信、永続ストレージへのデータの保存と読み取り、非同期でのイベントやメッセージのやり取り、サービス接続用の認証情報へのアクセスなどです。私自身、日々の開発業務でこれらの課題に幾度となく直面してきました。著者の指摘は、まさに開発現場の実情を的確に捉えたものだと感じました。Figure 7.1 Common communication patterns in distributed applications より引用これらの共通機能を実装する際の課題として、著者はアプリケーションとインフラストラクチャの間の摩擦を減らすことの重要性を指摘しています。サービス間通信やデータベース接続のために、アプリケーションコードにベンダー固有のライブラリやドライバを追加すると、インフラストラクチャの変更がアプリケーションの変更を強いることになります。この密結合が、開発チームとインフラチームの協調を複雑にし、ソフトウェアデリバリーのスピードを低下させる要因となっているのです。著者が提案するのは、標準のAPIとコンポーネントで共有の関心事に対処することです。これらの共通機能を標準化されたAPIとして提供し、アプリケーションコードからインフラストラクチャの詳細を切り離すのです。プラットフォームチームがこれらのAPIを実装し、その背後でインフラストラクチャを適切に構成・管理することで、開発チームはビジネスロジックの実装に専念できるようになります。アプリケーションインフラストラクチャに依存関係を移動すると、アプリケーションコードはプラットフォーム全体のアップグレードに影響されずに済みます。アプリケーションとインフラストラクチャのライフサイクルを分離することで、チームは日常的なユースケースでプロバイダー固有のクライアントやドライバーを扱う代わりに、安定したAPIに依存できるようになります。Figure 7.14 Decoupling responsibilities from app dev teams and platform capabilitiesより引用この提案には大いに共感を覚えました。私もかねてより、アプリケーションとインフラの責務を明確に分離し、疎結合な設計を追求することの重要性を感じていました。標準化されたAPIを介してインフラストラクチャと対話することで、開発チームはベンダーロックインを回避しつつ、インフラの進化から独立してアプリケーションを開発できるようになります。著者は、この考え方を具体化するためのツールとして、Dapr（Distributed Application Runtime）とOpenFeatureを紹介しています。Daprは、分散アプリケーションの構築に必要な共通機能を、標準化されたAPI（Building Block API）として提供するオープンソースのプロジェクトです。Daprは、分散アプリケーションを構築する際の共通の関心事を解決します。HTTP/GRPCリクエストを書くことができる開発者は、プラットフォームチームが接続するインフラストラクチャとやりとりできます。 サービス間通信、状態管理、Pub/Sub、シークレットストアなど、クラウドネイティブアプリケーションに不可欠な機能がコンポーネント化され、統一的なインターフェースで利用できるようになっています。dapr.io私は以前からDaprに注目していましたが、改めてその設計思想の優れていることを実感しました。アプリケーションが標準的なHTTP/gRPCのAPIを通じてこれらの機能を利用できるため、プログラミング言語に依存せずに共通機能を実装できます。また、コンポーネントの実装を切り替えるだけで、異なるベンダーのサービスを利用できるのも大きな利点です。インフラの選定はプラットフォームチームに委ね、開発チームはアプリケーションの開発に専念できる。まさにDaprは、アプリケーションとインフラの責務を明確に分離するためのツールと言えるでしょう。syu-m-5151.hatenablog.com特に、サービス間通信とステートマネジメントのシナリオは、印象的でした。DaprのサービスインヴォーケーションAPIを使えば、サービス間の通信を抽象化し、さまざまな通信プロトコルを透過的に利用できます。またステートストアAPIにより、アプリケーションはデータベースの種類を意識せずに状態を保存・取得できるようになります。実際のアプリケーション開発において、これらのAPIがいかに複雑性を減らし、生産性を高めてくれるかが実感できる内容でした。一方、OpenFeatureは機能フラグ（Feature Flag）の管理を標準化するためのプロジェクトです。機能フラグを使用すると、新機能を機能フラグの背後にマスクすることで、開発者はソフトウェアのリリースを継続できます。 機能フラグは、リリース済みの機能の有効・無効を動的に切り替える仕組みで、継続的デリバリーの文脈でよく用いられます。しかし、その実装は各社まちまちで、ベンダーロックインが起こりがちでした。OpenFeatureは、アプリケーションが機能フラグを使用して評価する方法を標準化します。OpenFeatureの抽象化に依存することで、プラットフォームチームは機能フラグの保存場所と管理方法を決定できます。 さまざまなプロバイダーが、非技術者向けのダッシュボードを提供し、フラグの表示や操作ができるようになります。Figure 7.22 Consuming and evaluating feature flags from our application services より引用私は機能フラグの重要性を認識しつつも、その導入の複雑さゆえに二の足を踏んでいました。しかしOpenFeatureにより、ベンダーに依存せずに機能フラグを利用できるようになるのは画期的だと感じました。開発チームは機能の実装に集中し、リリースのタイミングはビジネスサイドが制御する。そんな理想的なデリバリープロセスが、OpenFeatureによって実現に近づくのではないでしょうか。openfeature.dev著者はまた、これらの標準化の取り組みを適用する際の留意点についても言及しています。外部APIへの依存は新たな課題を生むため、ローカル開発環境でのテストや、レイテンシーへの配慮が必要になります。また、エッジケースを個別に扱うことで、専門家はアプリケーションの要件に基づいてより意識的なケースを作成できます。これにより、経験の浅いチームメンバーが、データの保存や読み取り、アプリケーションコードからのイベントの発行のみを行う場合に、ベンダー固有のデータベース機能や低レベルのメッセージブローカー設定などのツールの詳細を理解する必要がなく、一般的なシナリオを処理できるようになります。 プラットフォームチームは、開発チームとの緊密なコミュニケーションを通じて、適切な抽象化のレベルを見極めていく必要があるのです。章の後半では、これらの知見をConferenceアプリケーションに適用する方法が具体的に示されています。Redis や Kafka への依存を Dapr の API で置き換え、機能フラグを OpenFeature で管理する例は、非常に示唆に富むものでした。コード例を見ると、標準APIがいかにしてベンダー依存を排除し、開発者の体験を向上させているかが手に取るようにわかります。Figure 7.23 Using Dapr components for our walking skeleton / Conference application より引用これは私にとって、Dapr と OpenFeature の有用性を確信できる一節でした。ステップバイステップのチュートリアルに従った場合、SQL や NoSQL データベース、Kafka などのメッセージブローカーとやり取りする4つのサービスで構成されるクラウドネイティブアプリケーションのコンテキストで、Dapr や OpenFeature などのツールを使用した実践的な経験を得ることができました。また、実行中のアプリケーションのコンポーネントを再起動せずに、その動作を変更するために機能フラグを変更しました。 Kubernetesの普及により、インフラストラクチャのAPIは標準化されつつあります。一方で、アプリケーションレイヤーの共通機能は、いまだ各社独自の実装に委ねられているのが実情です。Dapr と OpenFeature は、このアプリケーションレイヤーに標準化をもたらす画期的なプロジェクトだと言えるでしょう。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にインフラを提供するだけでなく、アプリケーションの共通関心事をカプセル化し、開発者の生産性を高めることがプラットフォームの本質的な価値だと。Dapr や OpenFeature のようなツールを活用しつつ、開発チームに寄り添ったプラットフォームを構築すること。そこにこそ、プラットフォームエンジニアの腕の見せ所があるのだと感じました。もちろん、標準化された API を導入するだけで全てが解決するわけではありません。エッジケースをどう扱うか、レガシーなシステムとの整合性をどう取るか。プラットフォーム構築の道のりは平坦ではありません。しかし、アプリケーションとインフラの責務を分離し、開発チームの生産性を高めるという指針は普遍的なものだと信じています。プラットフォームエンジニアリングの真髄は、技術の標準化とコミュニケーションの両輪にあるのだと、本章は教えてくれました。本章は、クラウドネイティブ時代のアプリケーション開発の課題と、それを解決するための処方箋を示してくれる、示唆に富んだ内容でした。Dapr や OpenFeature のような取り組みは、まさにクラウドネイティブの「今」を体現するものだと言えるでしょう。同時に、それらを適切に活用し、開発チームに価値を届けるには、プラットフォームチームの深い理解と尽力が不可欠です。プラットフォームエンジニアリングの真価が問われるのは、技術の選定よりもむしろ、技術をいかに活用するかにあるのかもしれません。標準化と抽象化を追求しつつ、現場の声に真摯に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は示唆しています。本章で紹介されたツールやプラクティスは、開発者としての私の日々の実践にも大いに役立つはずです。Dapr や OpenFeature を実際のプロジェクトで活用し、その効果を体感してみたいと思います。同時に、インフラストラクチャの標準化が進む中で、アプリケーションレイヤーの共通関心事にも目を向けることの大切さを、胸に刻んでおきたいと思います。著者の知見を自分なりに咀嚼し、より良いアプリケーション開発とデリバリーのあり方を追求していく。エンジニアとしての私の使命は、まさにそこにあるのだと、改めて認識させられた次第です。クラウドネイティブの世界は、日進月歩で進化を続けています。Dapr や OpenFeature に象徴されるように、アプリケーションレイヤーの標準化も着実に進んでいます。私たちがすべきことは、その流れを見極めつつ、自分たちのコンテキストに適した形で活用していくことです。8 Platform capabilities II: Enabling teams to experimentKubernetesを基盤としたプラットフォーム上で、チームが新しいバージョンのアプリケーションを安全かつ柔軟にリリースするための手法について、深く掘り下げた内容でした。著者は冒頭で、カナリアリリース、ブルー/グリーンデプロイメント、A/Bテストなどの一般的なリリース戦略を実装することの重要性を説いています。これらの手法は、新しいバージョンのソフトウェアを段階的に展開し、問題を早期に発見しつつ、ユーザーへの影響を最小限に抑えるために不可欠です。しかし、著者が指摘するように、これらのリリース戦略をKubernetesの組み込みリソースだけで実装するのは非常に難しい作業です。Deploymentの複製や、Serviceの設定変更など、手作業での操作が多くなり、ミスも起こりやすくなります。そこで著者が紹介するのが、Knative ServingとArgo Rolloutsという2つのプロジェクトです。これらのツールは、Kubernetesの上に高レベルの抽象化を提供することで、リリース戦略の実装を大幅に簡素化してくれます。argoproj.github.ioknative.devKnative Servingは、洗練されたネットワーク層を導入し、サービスの異なるバージョンへのトラフィックをきめ細かく制御できるようにします。Knative Serviceを使えば、カナリアリリースやブルー/グリーンデプロイメント、A/Bテストを、複数のKubernetesリソースを手動で作成することなく実現できます。Figure 8.1 Releasing a new version (canary) of the service with 5% traffic routed to it より引用Knative Servingの大きな魅力は、トラフィックの移動を簡単に行えることと、Knativeのオートスケーラーが需要に応じてサービスをスケールアップ/ダウンしてくれることです。これにより、運用の負担が大幅に軽減されるのです。一方、Argo Rolloutsは、ArgoCDと連携し、Rolloutというリソースを使ってリリース戦略を実装する方法を提供します。Argo RolloutsはAnalysisTemplateとAnalysisRunという仕組みも備えており、新しいリリースの自動テストを行い、安全にバージョン間を移行できるようにしてくれます。Figure 8.23 Blue/green deployment with Kubernetes resources より引用この2つのプロジェクトの存在は、Kubernetes上でのソフトウェア・デリバリーの課題の大きさを物語っていると感じました。アプリケーションのデプロイだけでなく、それを安全かつ柔軟に行うための機能が、プラットフォームに求められているのです。特に印象的だったのは、Knative Servingのトラフィック制御機能の強力さです。重み付けベースのルーティングや、ヘッダーベースのルーティングなどを使えば、カナリアリリースの過程で新旧のバージョンへのアクセスを動的に制御できます。これは、リスクを最小限に抑えつつ、新機能の検証を進められる画期的な方法だと感じました。Figure 8.8 Knative Serving tag-based routing for version v1.1.0. より引用また、Argo Rolloutsの分析テンプレートの仕組みにも目を見張りました。あらかじめ定義した指標に基づいて、新バージョンの動作を自動的に検証できるのは、リリースプロセスの安全性と効率を大いに高めてくれるはずです。Figure 8.25 Argo Rollouts and analysis working together to make sure that our new revisions are sound before shifting more traffic to them. より引用もちろん、これらのツールを使いこなすには、一定の学習と運用コストがつきまといます。Kubernetes自体の知識に加え、Knative ServingやArgo Rolloutsの概念を理解する必要があります。特に、Istioなどのサービスメッシュとの連携については、さらに高度な知識が求められるでしょう。しかし、長期的に見れば、その投資は確実に報われるはずです。プラットフォームが提供する柔軟なリリース戦略は、ビジネスの俊敏性を高め、イノベーションを加速する力になります。より速く、より安全に価値を届けられるようになることは、競争力の源泉になるのですから。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にKubernetesのリソースを提供するだけでなく、アプリケーションのリリースプロセスをどう効率化するかを考え、適切なツールを選定・提供していくこと。それこそが、開発チームの生産性を真に高めるための鍵なのだと感じました。Figure 8.23 Blue/green deployment with Kubernetes resources より引用そのためには、Knative ServingやArgo Rolloutsだけでなく、Istio、Dapr、OpenFeatureなど、クラウドネイティブのエコシステムを幅広く理解することが求められます。それぞれのツールの特性を把握し、自社のコンテキストに合った形で組み合わせていく。その作業は決して容易ではありませんが、避けて通れないものだと思います。私自身、日々の業務の中で、これらのツールを実際に活用し、その効果を体感してみたいと思います。サービスのデプロイに留まらず、リリースプロセスの自動化と効率化にも目を向ける。そのマインドセットを持つことが、プラットフォームエンジニアとして成長するための第一歩になるはずです。また、本章では、ビジネスサイドのチームとの協調の重要性も浮き彫りになりました。プロダクトマネージャーや非エンジニアのステークホルダーに、新バージョンの検証を柔軟に行える環境を提供すること。これにより、ビジネス主導のイノベーションを後押しできるのです。Figure 8.29 Environments that enable teams to experiment with new versions より引用本章を読み終えて、改めてプラットフォームの真価は、それがエンパワーメントの手段であることだと感じました。開発者の創造性を強化して、ビジネスの意思決定を迅速化する。その先にこそ、ソフトウェアがもたらす本当の価値があるのだと。プラットフォームの構築は、単なる技術的課題ではありません。組織の文化を変え、人々の働き方そのものを変えていく営みです。その変革の旅路は、険しく長いものになるでしょう。でも、そこで得られる学びと成長は、きっとかけがえのないが大変なものになるはずです。9 Measuring your platformsプラットフォームのパフォーマンスを測定することの重要性と、その具体的な手法について深く掘り下げた内容でした。特に、DORAメトリクスの導入と、それを支えるデータパイプラインの設計には、多くの技術的な示唆が含まれていました。dora.devDORAメトリクスは、ソフトウェアデリバリーのパフォーマンスを評価するための事実上の標準として、広く認知されつつあります。デプロイ頻度、リードタイム、変更失敗率、サービス復旧時間の4つの指標は、いずれもデリバリープロセスの重要な側面を捉えており、それらを組み合わせることで、チームの成熟度を多面的に評価できます。Figure 9.1 DORA metrics by category より引用しかし、これらのメトリクスの計算は、決して容易ではありません。データソースが多岐にわたるうえ、それぞれのツールが出力するデータのフォーマットは千差万別だからです。デプロイ頻度を計算するには、CIツールのログとデプロイ環境のイベントを紐づける必要がありますし、リードタイムの算出には、コミットログとデプロイログの時間差を計る必要があります。この複雑性に対する著者の答えが、CloudEventsとCDEventsの活用です。CloudEventsは、クラウドネイティブなイベントを表現するための、ベンダー中立な仕様です。すでにServerless Workflow、Keptn、Knative、Kubernetesなど、多くのプロジェクトがCloudEventsをサポートしており、イベントデータの相互運用性が大きく向上しつつあります。cloudevents.ioCDEventsは、CloudEventsの拡張仕様であり、継続的デリバリーの文脈で共通に発生するイベントを定義したものです。コード変更、ビルド、テスト、デプロイ、リリースなど、パイプラインのあらゆるフェーズがカバーされており、それぞれのイベントが持つべきデータの構造も規定されています。Figure 9.7 The four stages defined by the CDEvents specification より引用つまり、CDEventsに準拠したイベントを集約することで、DORAメトリクスの計算に必要なデータの多くを、統一的なフォーマットで取得できるようになるのです。これは、データ統合のコストを大幅に削減し、メトリクスの信頼性を高めることにつながります。cdevents.devとはいえ、既存のツールをCDEventsに対応させるのは、一朝一夕にはいかないでしょう。そこで著者が提案しているのが、CloudEventsとCDEventsを活用したデータパイプラインの設計です。各ツールが出力するイベントをCloudEventsとして取り込み、それをCDEventsに変換する。そのうえで、変換されたイベントをもとにメトリクスを計算する、というアプローチです。Figure 9.9 Collecting and transforming data to calculate DORA metrics より引用パイプラインの入り口では、Knative Sourcesのようなアダプタを使って、さまざまなツールのイベントをCloudEventsに変換します。例えば、Kubernetes上で動くアプリケーションの場合、KubernetesイベントをCloudEventsに変換するKnative SourceのApiServerSourceを使うことができます。Figure 9.10 Knative Sources and data collection より引用こうして取り込まれたCloudEventsは、いったんデータストアに保存されます。著者の例ではPostgreSQLが使われていますが、他のデータベースやストレージを使うこともできるでしょう。重要なのは、イベントデータを安全に保管し、後の処理で参照できるようにすることです。次のステップは、保存されたCloudEventsをCDEventsに変換することです。著者は、この変換処理を関数（function）として実装することを提案しています。関数を使うメリットは、変換ロジックを小さな単位に分割でき、必要に応じて個別にスケーリングできる点にあります。また、新しい変換ロジックを追加する際も、既存の処理に影響を与えずに実装できます。Figure 9.12 Concrete mapping and CDEvent creation for deployments より引用CDEventsへの変換が完了したら、いよいよDORAメトリクスの計算です。著者の提案では、これもまた関数として実装されます。各メトリックの計算ロジックは、CDEventsから必要なデータを抽出し、所定の計算を行うだけのシンプルなものになります。計算結果は、データストアに保存するか、あるいは直接可視化ツールに送ることができます。Figure 9.15 Deployment frequency calculation flow より引用以上が、著者が提案するデータパイプラインのアーキテクチャの概要です。特筆すべきは、その拡張性の高さでしょう。新しいデータソースへの対応は、CloudEventsへの変換機能を追加するだけで実現できますし、新しいメトリクスの計算も、専用の関数を実装するだけで可能になります。また、変換処理とメトリクス計算がステートレスな関数として実装されているため、必要に応じて水平にスケールすることもできます。この設計は、現時点での技術選択に依存しない、汎用性の高いものだと感じました。実際のシステムを構築する際には、より堅牢なイベントストレージの選定や、耐障害性の確保など、様々な非機能要件も考慮する必要があるでしょう。しかし、その基本的なアプローチは、多くの組織で活用できるはずです。加えて、本章ではKeptn Lifecycle Toolkit（KLT）というオープンソースプロジェクトも紹介されていました。KLTは、Kubernetes上のアプリケーションのデプロイメントを監視し、その前後に任意のタスクを実行できるようにするためのツールです。Figure 9.21 Keptn architecture providing out-of-the-box observability and application lifecycle hooks. より引用KLTは、Kubernetesの標準機能であるSchedulerを拡張することで実現されています。アプリケーションのデプロイメント時に、KLTのControllerが介入し、デプロイメントの前後に登録されたタスクを実行するのです。github.comこれらのタスクはTaskDefinitionという形で定義され、実際の処理はスクリプト（Deno、Python3など）またはコンテナイメージとして実装されます。例えば、デプロイ前にアプリケーションの設定を検証するタスクや、デプロイ後に自動テストを実行するタスクなどが考えられます。keptn.shKLTのアプローチは、先に述べたCloudEvents/CDEventsベースのデータパイプラインとは異なりますが、両者は相互に補完的な関係にあると言えるでしょう。KLTを使えば、デプロイメントのパフォーマンスデータをCloudEventsとして出力し、それをデータパイプラインで処理することもできます。逆に、データパイプラインで計算されたメトリクスを、KLTのタスクで参照することも可能です。重要なのは、これらのツールを組み合わせることで、プラットフォームのパフォーマンス測定を自動化し、継続的な改善につなげられる点です。今や、デリバリーパフォーマンスの向上は、エンジニアリングチームだけの責任ではありません。組織全体でその重要性を認識し、データに基づいた意思決定を行っていく必要があります。そのためには、DORAメトリクスのような共通の物差しを導入し、それを可視化・共有していくことが不可欠です。CloudEventsとCDEvents、そしてKLTは、そのための強力な武器になるはずです。もちろん、ツールの導入だけですべてが解決するわけではありません。測定の文化を組織に根付かせ、データに基づいた継続的改善のサイクルを回すこと。それこそが、プラットフォームチームに求められる真の課題なのだと、私は考えます。本章を通じて、私はプラットフォームのパフォーマンス測定という課題の奥深さを改めて認識しました。適切な指標の選定、データの収集と統合、分析基盤の構築。それらはいずれも、高度な技術力と、現場への深い理解を必要とする難題です。しかし、その困難に立ち向かうことこそが、プラットフォームエンジニアの本懐なのだと思います。本章が提示してくれたのは、その挑戦への道標でした。実装の細部はともかく、その基本的なアプローチは、多くの組織で活用できるはずです。KLTのようなツールも、プラットフォームのパフォーマンス測定という文脈で捉え直すことで、新たな価値を見出せるでしょう。重要なのは、DORAメトリクスに代表される共通の物差しを導入し、それを組織全体で活用していくことです。さいごに本稿では、『Platform Engineering on Kubernetes』の概要と、各章の要点を技術者の視点でまとめました。本書が提示するのは、クラウドネイティブ時代のソフトウェア開発の理想像です。アプリケーションとインフラストラクチャの垣根を越えて、開発チームとプラットフォームチームが協調しながら、ビジネス価値を継続的に届けていく。その実現のためには、技術的な側面だけでなく、組織文化やプロセスの変革も不可欠だと述べられています。私はプラットフォームエンジニアリングという概念自体は以前から知っていましたが、本書ではそれをKubernetesと関連づけて深く考察されていました。単にKubernetesというツールを導入するだけでなく、アプリケーションに必要な機能を適切に抽象化し、チームに提供していくことがプラットフォームの本質的な価値だと説明しながら技術的なことを一切疎かにしていない点がとんでもなく素晴らしいです。また、DORAメトリクスに代表される、デリバリーパフォーマンスの測定の重要性も強調されていました。プラットフォームの価値を定量的に評価し、継続的に改善していくためには、適切な指標の導入と、データに基づいた意思決定が欠かせません。ただし、本書で紹介されているアプローチをそのまま適用できる組織ばかりではないでしょう。大切なのは、自社のコンテキストを深く理解し、そこに適した形でクラウドネイティブの考え方を取り入れていくことだと思います。プラットフォームエンジニアリングを実践していく上では、本書で述べられているようなツールやプラクティスに加えて、コミュニケーションが大切だと思いました。モブプログラミング・モブオペレーションなどの取り組みを通じて、チーム内での知識共有や価値観の浸透を図ることが、プラットフォームの継続的な改善と定着に大きく役立つはずです。本稿では、技術者としての視点から本書の内容をまとめましたが、プラットフォームエンジニアリングの実践には、技術者以外のステークホルダーの理解と協力も不可欠です。マネージャーやビジネスサイドの方々にも本書を読んでいただき、その感想をぜひ共有していただきたいと思います。多様な視点からのフィードバックがあってこそ、真に組織に適したプラットフォームの構築が可能になるはずです。また、本稿ではプラットフォームに関わる技術的な側面に焦点を当てましたが、実際のプラットフォーム構築には、組織的な要素も欠かせません。各チームのエンジニアの育成や、円滑なコミュニケーションの実現など、プラットフォームエンジニアリングには幅広いスキルが要求されます。こうした非技術的な側面については、また別の機会に掘り下げていきたいと思います。プラットフォームは日々進化し続けるものです。特定のツールの使い方を習得するだけでなく、その背後にある考え方や原則を理解し、学び続けていく姿勢が求められます。『Platform Engineering on Kubernetes』は、そのための優れた指南書だと感じました。クラウドネイティブ時代のソフトウェア開発は、まだ道半ばと言えるかもしれません。確立されたベストプラクティスは少なく、私たち一人ひとりが試行錯誤を重ねながら、前に進んでいくしかありません。本書が示してくれた知見と、SREの実践的なアプローチを組み合わせながら、クラウドネイティブ時代のプラットフォームのあるべき姿を、仲間たちと共に探求していきたいと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/28/230604","isoDate":"2024-03-28T14:06:04.000Z","dateMiliSeconds":1711634764000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"はてなブログの記事をGitHubに自動でPushする方法","contentSnippet":"ツールに感謝。コミュニティに感謝。github.comxではてなブログで更新する時にDiffが見れるととても助かるのだけど有料版だと可能とかありますか？みたいなこと聞いてたらwhywaita さんが教えてくれた!!!blogsyncどうでしょう https://t.co/Duh31GJGrV— why/橘和板 (@whywaita) 2024年3月23日   この記事では、blogsyncを用いてはてなブログの記事をGitHubに自動的に同期する方法について説明します。GitHub Actionsを使用して、はてなブログの記事を定期的にプルし、GitHubリポジトリに反映させることができます。当初はブログを更新する際に、記事の変更点（Diff）を確認できるようにしたいと考えました。しかし、NeoVimを使用してブログを書いているわけではないので、単に日付単位のDiffを取得できれば十分だと思ったため、この構成にしました準備1. はてなブログのAPIキーを取得はてなブログの設定ページ（https://blog.hatena.ne.jp/-/config）にアクセスし、「詳細設定」タブの「APIキー」セクションでAPIキーを取得します。2. GitHub Actionsのワークフローを設定.github/workflows/hatena-blog-pull.yamlに以下の内容を配置します。name: Blogsync Pullon:  schedule:    - cron: '0 0 * * *'jobs:  blogsync_pull:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v2      - name: Set up Blogsync        uses: x-motemen/blogsync@v0        with:          args: --version      - name: Create blogsync.yaml        run: |          cat \u003c\u003c EOF \u003e blogsync.yaml          your_hatena_blog_id.hatenablog.com:            username: your_hatena_blog_id            password: ${{ secrets.HATENA_API_KEY }}          default:            local_root: .          EOF        shell: bash      - name: Pull articles from Hatena Blog        run: |          blogsync pull --no-drafts      - name: Commit changes        run: |          git config --local user.email \"action@github.com\"          git config --local user.name \"GitHub Action\"          git add .          git reset -- blogsync.yaml          git commit -m \"Pull articles from Hatena Blog\" || echo \"No changes to commit\"      - name: Push changes        uses: ad-m/github-push-action@v0.6.0        with:          github_token: ${{ secrets.GITHUB_TOKEN }}          branch: mainこのワークフローは、毎日0時（UTC）に実行されるようにスケジュールされています。3. ワークフローの権限を設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/actions）にアクセスし、「Workflow permissions」セクションで「Read and write permissions」を選択します。これにより、ワークフローがリポジトリに変更を書き込むことができるようになります。4. はてなブログのAPIキーを設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/secrets/actions）にアクセスし、「Repository secrets」セクションで「New repository secret」をクリックします。「Name」にHATENA_API_KEYと入力し、「Value」に手順1で取得したはてなブログのAPIキーを入力します。カスタマイズblogsync.yamlファイルの設定を必要に応じて書き換えてください。以下は設定例です。your_hatena_blog_id.hatenablog.com:  username: your_hatena_blog_id  password: ${{ secrets.HATENA_API_KEY }}default:  local_root: .your_hatena_blog_idの部分を実際のはてなブログIDに置き換えてください。また、このファイルは秘密にしなければいけないので基本的には.gitignoreに入れておいてください。blogsync.yaml使い方.github/workflows/hatena-blog-pull.yamlファイルをリポジトリに追加します。ワークフローは毎日0時（UTC）に自動的に実行されます。はてなブログの記事がGitHubリポジトリにプルされ、変更がコミットされます。以上で、はてなブログの記事をGitHubで自動的に管理できるようになります。ワークフローを設定したら、あとは記事を書くだけです。記事の変更が毎日GitHubリポジトリに自動的に反映されます。参考URLGitHub Actions でのシークレットの使用push-to-hatenablogを使い，はてなブログへの投稿記事をGitHubで管理したら最高だった！はてなブログ作成から投稿までを自動化したGitHub Actionsのワークフロー","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/23/194702","isoDate":"2024-03-23T10:47:02.000Z","dateMiliSeconds":1711190822000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"nwiizoはなぜSpeaker Deckに上げた資料をブログにするのか？","contentSnippet":"はじめに私(nwiizo)は、ソフトウェアエンジニアとして日々の開発で得た知見やノウハウを、勉強会などで作成したプレゼンテーション資料としてSpeaker Deckに公開しています。Speaker Deckは、スライド共有サービスの一つで、スライドを簡単に公開・共有できる素晴らしいプラットフォームです。しかし、Speaker Deckに資料を公開するだけでは、いくつかの課題があります。スライドは情報を凝縮して伝えるために作られているため、詳細な説明や補足情報が不足しがちです。また、スライドだけでは、多くの人に情報が届きにくいという問題もあります。これらの課題を解決するために、私は Speaker Deck に上げた資料の内容を、改めてブログ記事として書くことにしています。本記事では、Speaker Deckに上げた資料をブログ記事化する意義について、詳しく解説していきます。詳細な説明と補足情報の追加スライドは、限られた紙面に要点を簡潔にまとめる必要があるため、情報を凝縮して伝えることに重点が置かれています。しかし、これだけでは聴衆の理解が表面的なものにとどまってしまう可能性があります。一方、ブログ記事では、スライドの内容を詳細に説明することができます。例えば、スライドではコードのスニペットを示すだけで終わってしまうことがありますが、ブログ記事ではそのコードの解説を丁寧に行うことができます。また、スライドでは伝えきれなかった背景情報や、補足説明を加えることで、より深い理解を促すことができるでしょう。さらに、スライドで紹介した技術や手法が、他の分野とどのように関連しているかを説明することもできます。これにより、読者は新たな観点からの問題解決のヒントを得ることができるかもしれません。Speaker Deck のスライドをブログ記事化することで、内容をより詳細に、より多面的に説明することができるのです。これは、情報を正確に伝え、読者の理解を深めるために非常に重要なことだと言えるでしょう。アウトプットによる技術力の向上ソフトウェアエンジニアにとって、新しい技術を学ぶことは重要ですが、学んだことをアウトプットすることも同様に重要です。登壇もそうですがブログ記事を書くためには、自分の知識を整理し、体系的に説明する必要があります。この過程で、自分の理解が深まり、技術力の向上につながります。ブログ記事を書く際には、自分が当たり前だと思っていたことを改めて見直すことになります。その際、自分の理解が不十分だったところや、説明が難しい部分に気づくことがあるでしょう。これは、さらなる学習のモチベーションにつながります。また、ブログ記事を公開することで、読者からのフィードバックを受けることができます。読者の質問や指摘は、自分では気づかなかった視点を提供してくれるかもしれません。このようなフィードバックから学ぶことで、さらなる技術力の向上が期待できます。ここで注目すべきは、登壇資料とブログ記事の違いです。登壇資料は、聴衆の反応を見ながら、その場で説明を調整することができます。また、質問に答えることで、理解が不十分な部分を補うこともできます。一方、ブログ記事は、書いた内容がそのまま読者に伝わります。誤りや不十分な説明があれば、それがダイレクトに読者に伝わってしまうのです。つまり、ブログ記事を書くことは、自分の知識や理解をより厳密に見直す機会になります。誤魔化しが効かない分、自分の理解の甘さが露呈するリスクがあるのです。しかし、だからこそ、ブログ記事を書くことは、技術力向上により大きな効果をもたらすと言えるでしょう。自分の知識のギャップに気づき、それを埋めていく過程こそが、真の成長につながるのです。Speaker Deckの資料をブログ記事にすることは、自己の知識と真摯に向き合う機会を提供してくれます。これは、技術力向上のための素晴らしい機会だと言えるでしょう。継続的な学習習慣の確立技術の進歩が速いソフトウェア開発の世界では、常に新しいことを学び続ける必要があります。しかし、日々の業務に追われていると、学習の時間を確保することが難しく感じることもあるでしょう。そんな中で、Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための良い方法だと言えます。ブログ記事を書くためには、Speaker Deckの資料で扱ったトピックについて、さらに深く調査・研究する必要があります。この過程自体が、学習のプロセスの一部となります。また、ブログ記事を書くことを習慣化することで、学習のための時間を確保することが自然とできるようになるでしょう。さらに、自分の学習の成果をブログ記事としてアウトプットすることで、学習へのモチベーションを維持することもできます。自分の成長を可視化することは、さらなる学習への原動力になるはずです。加えて、ブログが増えて充実してくると、ブログを書くこと自体が楽しくなってくるものです。自分の知識や経験が、記事という形で蓄積されていくことに喜びを感じるようになります。また、読者からのフィードバックや反響が、さらなるブログ記事を書くモチベーションにつながります。こうして、Speaker Deckの資料をブログ記事化することと学習が、正のフィードバックループを形成するのです。学習した内容をブログ記事にすることで、学習が促進され、ブログ記事が充実します。充実したブログは、さらにブログを書く意欲を高めます。この好循環が、継続的な学習習慣を確立し、維持することにつながるのです。Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための素晴らしい方法なのです。技術の進歩に遅れないためにも、この習慣を身につけることをおすすめします。そして、この習慣が、エンジニアとしての成長を加速させる良いサイクルを生み出すことを期待しています。エンジニアとしての認知度向上とアイデンティティの確立ソフトウェアエンジニアにとって、自分の専門性や技術力を示すことは、キャリアを積み重ねる上で非常に重要です。Speaker Deckに資料を公開することは、自分の知見を共有する良い方法ですが、それだけでは限界があります。一方、ブログ記事を通じて、自分の知見やスキルを広くアピールすることができます。質の高い技術情報を継続的に発信することで、徐々に読者がついてくるでしょう。これは、エンジニアとしての認知度の向上につながります。認知度が高まれば、仕事の依頼や、登壇の機会なども増えるかもしれません。これは、キャリアアップのチャンスにもなるでしょう。また、企業のエンジニアとして働いている場合は、社外での認知度の向上が、社内での評価にもつながる可能性があります。さらに、ブログ記事を書くことは、エンジニアとしてのアイデンティティの確立にも役立ちます。自分の考えや経験を言葉にすることで、エンジニアとしての自分の立ち位置が明確になります。これは、自分のキャリアの方向性を考える上でも重要なことだと言えるでしょう。Speaker Deckの資料をブログ記事化して発信することは、エンジニアとしてのキャリア形成において非常に有益なのです。認知度の向上とアイデンティティの確立は、長期的な視点で見たときに、大きな意味を持つはずです。登壇への動機づけエンジニアにとって、カンファレンスや勉強会での登壇は、自分の知見を共有し、人脈を広げるための素晴らしい機会です。しかし、登壇することへの不安や、ネタが思いつかないといった理由で、なかなか一歩を踏み出せないエンジニアも多いのではないでしょうか。Speaker Deckの資料をブログ記事化することは、登壇への良い動機づけになります。すでにSpeaker Deckで発表した内容をベースにブログ記事を書くことで、徐々に自信がつくでしょう。また、ブログ記事への反響を見ることで、自分の知見に対する需要や、興味を持ってくれる人の存在を実感することができます。これは、登壇へのモチベーションにつながるはずです。また、ブログ記事は、登壇の良い練習の場にもなります。ブログ記事を書く際には、自分の考えを明確に言葉にする必要があります。これは、登壇の際にも求められるスキルです。ブログ記事を書くことで、プレゼンテーションスキルの向上も期待できるでしょう。さらに、ブログで築いた信頼関係が、登壇の機会につながることもあります。ブログを読んだ人から、登壇の依頼を受けるケースも珍しくありません。登壇は、エンジニアとしてのさらなる成長と、人脈の拡大に役立つはずです。Speaker Deckの資料をブログ記事化することは、その第一歩を踏み出すための素晴らしい動機づけになるのです。技術情報の発信と共有ソフトウェアエンジニアにとって、自分の知見やノウハウを共有することは重要な責務の一つです。新しい技術や手法を学んだら、それを他のエンジニアにも伝えることで、エンジニアコミュニティ全体の知識レベルの向上に貢献することができます。Speaker Deckに公開した資料をブログ記事として再構成することで、技術情報をより詳細かつ体系的に発信することができます。スライドだけでは伝えきれなかった詳細な説明や、実際のコード例などを交えることで、より深い理解を促すことができるでしょう。さらに、ブログ記事にはコメント欄を設けることができます。読者からの質問や意見を受け付けることで、インタラクティブなコミュニケーションが生まれます。これは、さらなる知識の共有や、新たな発見につながる可能性を秘めています。ソフトウェアエンジニアが持つ知識は、利用するか共有されてこそ価値があります。Speaker Deckの資料をブログ記事化し、積極的に情報を発信することは、エンジニアコミュニティ全体の発展に寄与する素晴らしい取り組みだと言えるでしょう。ブログの方があとから見返しやすいSpeaker Deckの資料を読むと、その時は内容を理解した気になれます。特に、登壇を聞いている時は、登壇者の説明を聞きながら資料を見ることができるので、理解が深まった感覚を得られるでしょう。しかし、時間が経つと、資料の内容を忘れてしまうことが多いのではないでしょうか。資料だけでは、詳細な説明が不足していることが多いため、あとから見返しても、内容を思い出すことが難しいのです。一方、ブログ記事は、詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。また、ブログ記事は検索しやすいというメリットもあります。特定の話題や技術について調べたい時に、関連するブログ記事を探すことができます。これは、自分が過去に学んだ内容を振り返る時にも役立ちます。さらに、ブログという文字のフォーマットを使うことで、登壇に比べて主張そのものに注意を向けさせることができます。人は身振り、声質、表情、顔といった外見や肩書に惑わされて主張を歪めて解釈してしまうことがありますが、ブログではそういった先入観をなるべく排除し、あくまで中身に集中させることができるのです。Speaker Deckの資料をブログ記事化することは、知識を長期的に活用するために非常に有効な方法だと言えるでしょう。おわりにSpeaker Deckに上げた資料をブログ記事として再構成することには、多くの意義があります。詳細な説明と補足情報の追加、アウトプットによる技術力の向上、継続的な学習習慣の確立、エンジニアとしての認知度向上とアイデンティティの確立、登壇への動機づけ、技術情報の発信と共有など、個人の成長とエンジニアコミュニティ全体の発展に寄与する様々なメリットがあるのです。また、Speaker Deckの資料は初見では理解した気になれますが、時間が経つと内容を忘れてしまいがちです。一方、ブログ記事は詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。Speaker Deckは、スライドを公開・共有するための素晴らしいプラットフォームですが、それだけでは情報共有の手段としては限界があります。一方、ブログは、より詳細で探索しやすい情報を提供することができます。Speaker Deckとブログを組み合わせることで、より効果的な技術情報の発信が可能になるのです。皆さんも、自分の知見を共有するためにこの方法を活用してみてはいかがでしょうか？参考資料木村政彦はなぜ力道山を殺さなかったのか作者:増田俊也新潮社Amazon人生は、運よりも実力よりも「勘違いさせる力」で決まっている作者:ふろむだダイヤモンド社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/22/122847","isoDate":"2024-03-22T03:28:47.000Z","dateMiliSeconds":1711078127000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"データエンジニアリングの要諦の後ろ髪を掴む - Fundamentals of Data Engineeringを読んで","contentSnippet":"最強なデータ分析基盤は何か⁉︎多種多様なデータ分析基盤が、制約のない環境で競合した時… ビジネス用途に限らず、あらゆるシナリオで使用可能な「データ分析」で比較した時、最強なデータ分析基盤は何か⁉︎ 今現在最強のデータ分析基盤は決まっていないデータ分析基盤まとめ（随時更新） などもあり大変参考にさせていただきました。ありがとうございます。はじめにデータエンジニアリングは、データの収集、処理、保存、そして提供を行う技術やプロセスを扱う複雑な分野です。この分野の全容を系統的に把握することは決して容易なことではありません。このような状況の中で、『Fundamentals of Data Engineering』という書籍に出会いました。この本は、著者たちの豊富な実務経験に基づいて書かれており、データエンジニアリングの基本概念とそのライフサイクルに焦点を当てています。さらに、これらの概念を現実の問題解決に応用する方法についても詳しく説明しています。全624ページに及ぶこの書籍は、その分厚さが示す通り、読破するには相当な時間と努力が必要ですが、その価値は十分にあると確信しています。learning.oreilly.com本書の特徴は、特定のツールや技術ではなく、データエンジニアリングの根幹をなす原則に焦点を当てている点です。著者らは、データ生成、ストレージ、取り込み、変換、提供といったライフサイクルの各段階を丁寧に解説し、それらを支える重要な概念を、具体的な技術選択やアーキテクチャ設計と関連付けて説明しています。また、クラウド技術を効果的に組み合わせて、下流のデータ消費者のニーズに応えるための方法論も提示しています。本書は、データエンジニアリングの理論と実践を見事に融合させ、この分野の要諦を掴むための羅針盤となります。著者らの豊富な知見と経験が随所に活かされ、ベストプラクティスのフレームワークを用いた問題の評価方法、市場の誇大広告を見抜く視点、堅牢なアーキテクチャの設計・構築手法などが解説されています。これらの知識は、データエンジニアリングの要諦を理解し、実践に活かすために不可欠な要素です。また、本書は、データエンジニアリングを取り巻く環境の変化についても言及しています。特に、クラウドファーストのアプローチを取ることで、オンプレミスからクラウドへのシフトを見据えた議論を展開しています。加えて、セキュリティとプライバシーの重要性についても強調しており、データエンジニアリングの現在と未来を見据えた内容となっています。本書を通じて、データエンジニアリングの全体像を俯瞰し、実践的な知識を得ることができました。データエンジニアリングの原則を自らの役割に取り入れ、クラウド技術を駆使して問題解決に取り組む方法を学べた点は、特に有益でした。本書は、データエンジニアリングの要諦を掴むための一助となる、貴重な一冊であると言えます。本稿はそんな書籍の読書感想文である。あくまで、私の感想なので指摘はそれぞれのSNSに書き散らしてください。『Fundamentals of Data Engineering』の構成本書は4つのパートで構成されています。パートIでは、第1章でデータエンジニアリングを定義し、第2章でデータエンジニアリングのライフサイクルを示します。第3章ではよいアーキテクチャについて議論し、第4章では適切な技術を選択するためのフレームワークを紹介します。パートIIは、第2章を基にデータエンジニアリングのライフサイクルを深く掘り下げています。データ生成、ストレージ、取り込み、変換、提供の各段階が独立した章で扱われます。パートIIは本書の中核をなす部分であり、他の章はここで扱われる核心的なアイデアをサポートするために存在しています。パートIIIでは、追加のトピックスとして、第10章でセキュリティとプライバシーについて議論しています。これらは常にデータエンジニアリングにおいて重要な部分でしたが、営利目的のハッキングや国家支援のサイバー攻撃の増加に伴い、さらに重要性が増しています。また、GDPRやCCPAなどの規制の出現により、個人データの不注意な取り扱いは重大な法的影響を及ぼす可能性があります。第11章では、データエンジニアリングの近未来について、著者らの大胆な予測を概説しています。付録では、データエンジニアリングの日々の実践に非常に関連性が高いものの、本文の主要部分には収まらなかった技術的トピックスを取り上げています。具体的には、シリアル化と圧縮（付録A）、クラウドネットワーキング（付録B）です。はじめに『Fundamentals of Data Engineering』の構成Part I. Foundation and Building BlocksChapter 1. Data Engineering DescribedChapter 2. The Data Engineering LifecycleChapter 3. Designing Good Data ArchitectureChapter 4. Choosing Technologies Across the Data Engineering LifecyclePart II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source SystemsChapter 6. StorageChapter 7. IngestionChapter 8. Queries, Modeling, and TransformationChapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETLPart III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and PrivacyChapter 11. The Future of Data Engineeringさいごに(追記)Part I. Foundation and Building BlocksChapter 1. Data Engineering Describedデータエンジニアリングを「raw dataを取り込み、高品質で一貫性のある情報を生成するシステムとプロセスの開発、実装、維持」と定義しています。データエンジニアは、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの交差点に位置し、データのソースシステムから始まり、分析や機械学習などのユースケースにデータを提供するまでのライフサイクル全体を管理します。Figure 1-1. The data engineering lifecycle よりまた、データエンジニアリングの歴史的な発展についても触れられており、データウェアハウジングから始まり、ビッグデータ時代を経て、現在はデータのライフサイクル全体を管理するフェーズに入っていることが分かります。データエンジニアは、データサイエンティストの上流に位置し、分析やモデリングに必要な基盤を提供する重要な役割を担っています。さらに、本章では、企業のデータ成熟度に応じたデータエンジニアの役割の変化や、他の技術的役割（ソフトウェアエンジニア、データアーキテクト、DevOpsエンジニアなど）およびビジネスリーダーとの関わりについても説明されています。データエンジニアは、技術的スキルだけでなく、コミュニケーション能力やビジネス理解も求められる、組織内の重要な接点となる存在であることが強調されています。本章を通じて、データエンジニアリングが急速に発展し、組織内で不可欠な役割を担うようになってきたことを実感しました。データドリブンな意思決定が求められる現代において、データエンジニアは、データの価値を最大限に引き出すための鍵を握っています。今後もデータエンジニアリングの動向に注目し、自身のスキルを磨いていく大切さを学びました。Chapter 2. The Data Engineering Lifecycleデータエンジニアリングのライフサイクルについて詳細に解説されています。データエンジニアリングのライフサイクルとは、raw dataを有用な最終製品に変換するための一連のプロセスを指します。本章では、データエンジニアリングのライフサイクルを5つのステージ（生成、ストレージ、取り込み、変換、提供）に分類し、各ステージの役割と考慮事項を丁寧に説明しています。また、ライフサイクル全体を支える重要な要素として、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの6つの「潮流」を紹介しています。特に印象的だったのは、データ管理の重要性についての議論です。著者らは、データガバナンス、データモデリング、データの系統、データ統合、ライフサイクル管理など、企業のデータ管理における様々なベストプラクティスを紹介し、これらがデータエンジニアリングにどのように関連するかを明確に示しています。データエンジニアは、単なる技術者ではなく、組織全体のデータ活用を戦略的に促進する役割を担っているのだと実感しました。また、DataOpsの概念も興味深かったです。DataOpsは、アジャイル開発、DevOps、統計的プロセス管理の手法をデータに適用したものであり、自動化、モニタリング、インシデント対応の3つの要素から成ります。データエンジニアリングにおいてDataOpsを実践することで、データ製品の迅速な開発と高品質な運用が可能になるとのことです。本章を通じて、データエンジニアリングが、単なるデータ処理の技術にとどまらず、組織のデータ活用を支える総合的な取り組みであることを学びました。データエンジニアは、ライフサイクルの各ステージにおける技術的な選択と、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項のバランスを取ることが求められます。本書で提示されたデータエンジニアリングのライフサイクルのフレームワークは、この複雑な領域を体系的に理解するための強力なツールになると感じました。Chapter 3. Designing Good Data Architectureデータエンジニアリングにおける良いアーキテクチャ設計について詳細に解説されています。本章では、まず、データアーキテクチャを「企業のデータニーズの進化を支えるシステムの設計であり、柔軟で可逆的な意思決定により、トレードオフを慎重に評価して達成されるもの」と定義しています。そして、良いデータアーキテクチャの原則として、共通コンポーネントの賢明な選択、障害への対策、スケーラビリティの確保、リーダーシップ、継続的なアーキテクト活動、疎結合システムの構築、可逆的な意思決定、セキュリティの優先、FinOpsの採用の9つを挙げています。また、本章では、分散システム、スケーラビリティ、障害対策、密結合と疎結合、シングルテナントとマルチテナント、イベント駆動アーキテクチャ、ブラウンフィールドとグリーンフィールドプロジェクトなど、データアーキテクチャ設計に関連する主要な概念について説明しています。さらに、データウェアハウス、データレイク、モダンデータスタック、ラムダアーキテクチャ、カッパアーキテクチャ、IoTアーキテクチャ、データメッシュなど、具体的なデータアーキテクチャの例や種類についても紹介されています。これらの例を通じて、データエンジニアがビジネスの要件に合わせて適切なアーキテクチャを選択し、設計するための知見が提供されています。本章を読んで、データアーキテクチャ設計の重要性と複雑さを改めて認識しました。データエンジニアは、技術的な知識だけでなく、ビジネスの文脈を理解し、ステークホルダーとのコミュニケーションを通じて要件を把握する必要があります。そして、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項とのバランスを取りながら、柔軟で進化可能なアーキテクチャを設計していかなければなりません。この辺はソフトウェアアーキテクチャの基礎を思い出した。ソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal FordオライリージャパンAmazon本書で提示された良いデータアーキテクチャの原則や、様々なアーキテクチャパターンの知識は、この難しい課題に取り組むための強力な助けになると感じました。データエンジニアとして、これらの知見を活かし、組織のデータニーズに合ったアーキテクチャを設計していきたいと思います。詳細に知りたい場合には『データ指向アプリケーションデザイン』あたりを読むと良さそうデータ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin KleppmannオライリージャパンAmazonChapter 4. Choosing Technologies Across the Data Engineering Lifecycleデータエンジニアリングのライフサイクル全体にわたる適切な技術選択のための考え方と基準について詳細に説明されています。この章では、アーキテクチャが戦略的な設計であることに対し、ツールはその実現を目指す戦術的な選択肢であるという点が強調されています。 技術選択時に考慮すべき要素として、チームの規模と能力、市場投入までのスピード、相互運用性、コスト最適化とビジネス価値、技術トレンドの変化、デプロイ環境、ビルドかバイの選択、モノリシックかモジュール化か、サーバーレスかサーバーか、性能最適化などが挙げられています。あまりにも「ソフトウェアアーキテクチャの基礎」すぎてデータ基盤もソフトウェアアーキテクチャなのだと分からせをくらいました。加えて、クラウドのコスト効率とクラウドネイティブアーキテクチャのコスト最適化の重要性が説明されており、オンプレミス、クラウド、ハイブリッドクラウド、マルチクラウドなどの配置オプションとその特性についても詳述されています。オープンソースソフトウェア（コミュニティ型と商用型）とプロプライエタリーソフトウェアの選択、モノリシックとマイクロサービスアーキテクチャの比較、サーバーレスと従来型サーバーの検討など、具体的な技術選択のシナリオにおける検討が提示されています。技術選択の複雑さとその重要性を理解する上で、この章は大いに役立ちます。データの世界は常に進化しているため、最適な選択肢は状況に応じて変わります。適切なトレードオフを評価し、柔軟かつ可逆的な意思決定を行うことが重要です。この辺はソフトウェアアーキテクチャメトリクスみがあって良かった。ソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,João Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazonセキュリティ、データ管理、DataOps、オーケストレーションなどの現代のトレンドが技術選択に与える影響も大きいことが認識されています。これらを総合的に考慮し、ビジネス価値を最大化する技術スタックを構築することが、SREとしての責任であると捉えられます。本章で提供される原則とガイドラインは、DXの推進と共に増大する複雑な意思決定の指針となります。組織のニーズに沿いながら、これらの洞察を活用していくことが推奨されています。Part II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source Systems本章では、データエンジニアリングのライフサイクルの初期段階であるソースシステムにおけるデータの生成プロセスについての詳細な解説が展開されています。 ここで、データエンジニアがソースシステムからのデータの特性と生成プロセスを理解することの重要性が強調されており、これは非常に重要な点です。特に印象深かったのは、ソースシステムのオーナーやステークホルダーとの関係構築の必要性です。データエンジニアリングはチーム単独ではなく、関係者全員の協力が必須であり、上流システムで問題が生じた際に迅速な対応が可能な信頼関係の構築が不可欠です。データ品質の維持に関する言及もあり、これは特に重要です。ソースシステムの設計や運用に直接影響を与えることは困難かもしれませんが、期待されるデータ品質について上流チームと合意を形成し、定期的な品質チェックを行うことが必要です。これは、SREとしての役割とも重なる側面があります。セキュリティ、可用性、信頼性を考慮したソースシステムのアーキテクチャへの理解も、障害発生時に影響を最小限に抑え、迅速に復旧する設計を実現する上で重要です。さらに、データ管理、DataOps、オーケストレーションといったデータエンジニアリングの新しい動向とソースシステムとの関連性についても触れられており、これらの原則を上流工程に適用し、エンド・ツー・エンドでの高品質なデータパイプライン構築が目標です。リバースETLやイベントストリーミングプラットフォームの活用による、データエンジニアとソースシステムとの連携強化の可能性についての言及もあり、これはアプリケーション開発チームとのWin-Winの関係構築、及びユーザー向けデータ製品の共創へと繋がるでしょう。本章を通じて、SREとデータエンジニアの役割が密接に関連しており、両者の協力が不可欠であることが明確になりました。 上流から下流への一貫した高品質なデータフローを実現するためには、両分野の専門知識を統合し、継続的な改善を図る必要があります。得られた知見を活用し、開発チームと協力しながら、より堅牢なデータインフラを構築していくことが目指されています。Chapter 6. Storageデータエンジニアリングのライフサイクルにおけるストレージの重要性と、その設計・運用に関する考慮事項について詳しく解説されています。本章では、まず、ハードディスク、SSD、システムメモリなど、ストレージシステムを構成する基本的な要素について説明しています。データエンジニアは、これらの物理的ストレージコンポーネントの特性を理解することで、パフォーマンス、耐久性、コストのトレードオフを適切に評価できるようになります。次に、ファイルストレージ、ブロックストレージ、オブジェクトストレージ、ストリーミングストレージなど、主要なストレージシステムの種類と特徴を紹介しています。特に、クラウドにおけるオブジェクトストレージの重要性が強調されており、その柔軟性とスケーラビリティが、データレイクやクラウドデータウェアハウスの基盤となっていることが分かります。さらに、データウェアハウス、データレイク、データレイクハウス、データプラットフォームなど、データエンジニアリングで用いられる主要なストレージの抽象化についても言及されています。これらの抽象化は、ストレージシステムの上に構築され、データの取り込み、変換、提供といったライフサイクルの各段階をサポートします。本章では、ストレージに関する重要なトレンドや考え方についても触れられています。例えば、コンピュートとストレージの分離、ゼロコピークローニング、データカタログ、データ共有などは、現代のデータアーキテクチャにおいて欠かせない要素だと指摘されています。また、データのライフサイクルと保持期間の管理、シングルテナントとマルチテナントのストレージ設計の違いなど、運用面での考慮事項についても説明されています。データエンジニアは、これらの要素を総合的に判断し、組織のニーズに合ったストレージ戦略を立てる必要があります。本章を通じて、ストレージがデータエンジニアリングのあらゆる段階で重要な役割を果たしていることを再認識しました。生のデータを価値あるインサイトに変えるためには、適切なストレージの選択と設計が不可欠です。また、セキュリティ、データ管理、DataOps、オーケストレーションなどの「潮流」を常に意識しながら、ストレージシステムを進化させていく必要があります。本書で得られた知見を活かし、自社のデータアーキテクチャにおけるストレージの最適化に取り組んでいきたいと思います。特に、コストとパフォーマンスのバランスを取りつつ、将来の拡張性も考慮した設計を心がけたいと考えています。ストレージの話は『パタ\u0026へネ』などを読むとしっかりと分かるので読み直す機会があれば読み返したい。しかし、人生の時間は有限なので悲しい。コンピュータの構成と設計　MIPS Edition　第6版　上作者:David Patterson,John Hennessy日経BPAmazonコンピュータの構成と設計 MIPS Editoin 第6版 下作者:David Patterson,John Hennessy日経BPAmazonChapter 7. Ingestionデータエンジニアリングにおけるデータ取り込みの重要性と複雑さを再認識しました。本章では、データ取り込みを「データを一つの場所から別の場所へ移動するプロセス」と定義しています。その主要な考慮事項として、ユースケース、再利用性、データ量、データフォーマット、データ品質などが挙げられています。さらに、バッチ処理とストリーミング処理の違い、同期型と非同期型のデータ取り込み、シリアル化とデシリアル化、スループットとスケーラビリティといった、設計上の重要な概念について詳しく説明されています。また、Otelなどのオブザーバビリティ情報の取得については言及されていないのですが、この章を通じて現代の監視基盤が実際にはデータエンジニアリングに大きく依存してるものなのだと思いはじめました。特に印象的だったのは、データ取り込みの方法の多様性です。データベースへの直接接続、CDC、API、メッセージキュー、ファイルエクスポートなど、様々な手段があり、それぞれにメリットとデメリットがあります。状況に応じて適切な方法を選択し、組み合わせることが求められます。また、データ取り込みにおけるデータ品質の確保の重要性も強調されていました。スキーマの変更や遅延データへの対応、エラーハンドリングなど、様々な課題に直面します。上流のシステムとの緊密なコミュニケーションと、ロバストなモニタリングの仕組みが不可欠だと感じました。本章では、データ取り込みに関わる様々なステークホルダーとの協力についても言及されています。特にソフトウェアエンジニアとのコラボレーションは、データ品質の向上と、よりリアルタイムなデータ活用につながる可能性があります。組織のサイロを超えて、Win-Winの関係を築いていくことが重要だと分かりました。さらに、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、データ取り込みにどのように影響するかについても議論されていました。これらの原則を常に意識しながら、エンドツーエンドのデータパイプラインを設計していく必要があります。データ取り込みは、地味な作業に見えるかもしれません。しかし、それは分析やMLなどのエキサイティングなアプリケーションを支える重要な基盤です。本章で得られた知見を活かし、より信頼性が高く、価値あるデータを提供できるよう、日々精進していきたいと思います。Chapter 8. Queries, Modeling, and Transformationデータエンジニアリングにおけるクエリ、モデリング、変換の重要性と技術的な考慮事項について理解を深めることができました。本章では、まず、クエリの仕組みと最適化の手法について解説されています。クエリオプティマイザの役割や、結合戦略の最適化、説明プランの活用など、パフォーマンス向上のための具体的なアドバイスが提示されており、大変参考になりました。また、ストリーミングデータに対するクエリの特殊性についても言及されていました。次に、データモデリングの重要性と主要な手法が紹介されています。概念モデル、論理モデル、物理モデルの違いや、正規化、スター・スキーマ、Data Vaultなどのバッチデータのモデリング手法、ストリーミングデータのモデリングの考え方など、幅広いトピックがカバーされています。ビジネスロジックをデータモデルに反映させることの重要性が強調されていました。そして、変換の役割と主要なパターンについて解説されています。単純なクエリとは異なり、変換では結果を永続化し、ダウンストリームで利用できるようにすることが目的だと説明されています。バッチ処理とストリーミング処理それぞれの変換パターンや、更新パターン、データラングリングなどの具体的な手法が紹介されていました。また、マテリアライズドビュー、フェデレーションクエリ、データ仮想化など、クエリ結果を仮想的なテーブルとして提示する手法についても言及されていました。これらの手法は、複雑なデータパイプラインの一部として活用できる可能性があります。本章では、クエリ、モデリング、変換に関わる様々なステークホルダーとの協力についても議論されています。ビジネスロジックを理解し、上流のシステムへの影響を最小限に抑えつつ、下流のユーザーにとって価値のあるデータを提供することが求められます。また、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、この段階でも重要な役割を果たすことが指摘されていました。データ変換は、データパイプラインの中核をなす工程です。単に最新の技術を追求するのではなく、ステークホルダーにとっての価値を常に意識することが重要だと感じました。本章で得られた知見を活かし、ビジネスの目標達成に貢献できるデータ変換プロセスを設計していきたいと思います。Chapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETL本章では、データエンジニアリングのライフサイクルの最終段階である、データの提供について解説されていた。データエンジニアが直面する主要な3つのユースケース - 分析、機械学習、リバースETLについて、どのようにデータを提供するかが述べられていた。データを提供する際の重要な考慮点として、エンドユーザーがデータを信頼できるようにすることが何より大切だと強調されていた。データへの信頼がないと、いくら高度なアーキテクチャやシステムを構築しても意味がない。信頼を得るためには、データの検証とオブザーバビリティのプロセスを活用し、ステークホルダーと協力してデータの有効性を確認する必要がある。また、ユースケースとユーザーを理解し、提供するデータプロダクトを明確にし、セルフサービスかどうかを検討し、データの定義やロジックを確立することが重要だと述べられている。データメッシュのコンセプトにも触れられ、データ提供の方法が大きく変化しつつあることがわかった。分析や機械学習のためのデータ提供方法としては、ファイル、データベース、クエリエンジン、データ共有などがあげられていた。セマンティック層やメトリクス層の活用も有効とのことだった。また、ノートブックを使ったデータサイエンスのワークフローについても解説があり参考になった。リバースETLは、処理されたデータをOLAPシステムからソースシステムにロードすることだが、フィードバックループを作り出すリスクがあるので注意が必要だと指摘されていた。本章を読んで、データ提供において信頼性とセキュリティが非常に重要であり、様々な方法や最新のトレンドを理解しておく必要性を感じた。生のデータを渡すのではなく、匿名化などの工夫も必要だ。データプロダクトを通じてビジネスに貢献するという視点を常に持ちながら、品質の高いデータを提供できるよう、日々研鑽していきたい。Part III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and Privacyセキュリティとプライバシーは、データエンジニアリングにおいて非常に重要な側面であり、後回しにしてはならないということが本章で強調されていました。データ漏洩や流出は、企業に壊滅的な結果をもたらす可能性があります。GDPR、FERPA、HIPAAなど、データプライバシーに関する法的要件が増えており、違反すると多額の罰金が科せられる可能性があります。データエンジニアは、このような法規制を理解し、遵守する必要があります。セキュリティの最大の弱点は人間であるため、データエンジニアは常に防御的な姿勢で行動し、認証情報の扱いには細心の注意を払い、倫理的な懸念があれば提起しなければなりません。セキュリティプロセスはシンプルで習慣的なものでなければならず、単なるコンプライアンスのためのセキュリティ・シアターであってはいけません。最小権限の原則を適用し、必要最小限のアクセス権のみを付与すべきです。きめ細かいアクセス制御を実装することが重要です。クラウドにおけるセキュリティは、プロバイダーとユーザーの共同責任であり、ユーザー側の設定ミスが原因で流出が起こることが多いのです。定期的なデータバックアップは、災害復旧やランサムウェア対策に欠かせません。リストアのテストも定期的に行うべきでしょう。技術面では、脆弱性を修正するためのシステムのパッチ適用と更新、保存中と通信中の両方でのデータの暗号化、アクセス・リソース・コストのログ記録・監視・アラート、ネットワークアクセスの厳重な制御、CPUなどの低レベルでのセキュリティ考慮などが重要な実践項目として挙げられていました。すべてのエンジニアが自分の領域で潜在的なセキュリティ問題を探し出すという能動的な姿勢が重要であり、軽減策を積極的に展開すべきだと述べられています。本章を通して、セキュリティとプライバシーは企業文化・プロセス・技術のすみずみまで浸透させる必要があり、関係者全員が常に警戒心を持ち、積極的な対策を講じることが機密データ資産を守るために不可欠だということを実感しました。法的にも評判的にも、その重要性は非常に高いのです。データエンジニアとして、**セキュリティとプライバシーを常に最優先事項と位置づけ、ベストプラクティスを実践していきます。Chapter 11. The Future of Data Engineering本章では、データエンジニアリングの将来について著者の考察が述べられていました。データエンジニアリングの分野は急速に変化しているため、本書の執筆は挑戦的な作業だったと思います。しかし、変化の中にも不変の本質を見出し、ライフサイクルという形で体系化したことは意義深いと感じました。著者は、データエンジニアリングのライフサイクルは今後も変わらず重要であり続けると予測しています。一方で、ツールの簡素化が進み、より高度な作業にフォーカスできるようになるでしょう。クラウドスケールの「データOS」の出現によって、相互運用性が向上することも期待されます。また、従来の「モダンデータスタック」を超えて、リアルタイムのデータ処理と機械学習を融合させた「ライブデータスタック」へと進化するとの展望も示されていました。ストリーミングパイプラインとリアルタイム分析データベースの発展によって、アプリケーションとデータ、機械学習の間のフィードバックループが短くなり、より洗練されたユーザー体験が実現するというビジョンは興味深いです。一方で意外だったのは、スプレッドシートの重要性への言及でした。確かに、現場ではExcelが分析ツールとして依然大きな役割を果たしています。クラウドのOLAPシステムとスプレッドシートの使い勝手を兼ね備えた新しいツールの登場にも注目したいと思います。全体を通して、技術トレンドは複雑な技術と文化の相互作用の中で生まれるものであり、予測は難しいというのが著者の率直な見解だと感じました。私たち一人一人がデータエンジニアリングの発展に関わっていく中で、ツールの採用と活用を通じて、ビジネス価値の創出という大きな目標を見失わないようにしたいと思います。本書で得た知見をもとに、コミュニティに参加し、専門家と対話しながら、自分なりの探求を続けていきたいと思います。データエンジニアリングは奥深く、やりがいのある分野だと改めて感じました。さいごにこの本を通じて、私はデータエンジニアリングの幅広さと深さを理解する機会を得ました。『Fundamentals of Data Engineering』は、データエンジニアリングの基礎から応用に至るまで、その様々な側面を包括的に解説しており、データエンジニアとしての技術や知識の向上に寄与する貴重なリソースです。データライフサイクルの各段階に対する詳細な説明は、実務で直面するさまざまな問題への理解を深めるのに非常に有用です。また、セキュリティとプライバシーの章では、技術の理解だけでなく、倫理的な視点から物事を考えることの重要性が強調されていることが特に印象的でした。データエンジニアは技術者であると同時に、データを取り扱う上での社会的責任を有する存在であり、この点を再確認させられます。データエンジニアリングの将来に関する展望を含めて、この書籍は、データエンジニアリングの現状理解と将来に向けた方向性を示す貴重な指南書です。技術の進歩は早く、今日学んだことが明日には旧式になる可能性がありますが、本書で得られる原則や考え方は、変わることのない有用な知識。データエンジニアリングの基盤となります。syu-m-5151.hatenablog.com最後に、この本を読むことで得られる最大の利点は、データエンジニアリングに対する深い理解と共に、学び続け、成長し続けることの重要性を再認識できることです。技術変遷に適応しつつ、データエンジニアリングの核心を見失わないよう努めることが、私たちには求められています。この旅は続きますが、『Fundamentals of Data Engineering』は、その道中で頼りになる羅針盤となるでしょう。日本語訳の出版が待ち遠しいですね。そして、付録「A. Serialization And Compression Technical Details」と「B. Cloud Networking」に関しては、ぜひ自身で読んでみていただきたいです。これらのセクションは、データエンジニアリングの深い理解に不可欠なテクニカルな洞察を提供しており、実務での適用に役立つ知見が満載です。Fundamentals of Data Engineering (English Edition)作者:Reis, Joe,Housley, MattO'Reilly MediaAmazon(追記)翻訳版のリリースが出ました。翻訳作業お疲れ様でした。データエンジニアリングの基礎 ―データプロジェクトで失敗しないために作者:Joe Reis,Matt Housleyオーム社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/20/164434","isoDate":"2024-03-20T07:44:34.000Z","dateMiliSeconds":1710920674000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Docker Desktop のアンインストールと Lima の導入","contentSnippet":"はじめにDocker Desktop は多くの開発者にとって便利なツールですが、さまざまな理由で Lima への移行を検討するケースもあります。この記事では、MAC でDocker Desktop をアンインストールし、Lima を導入する過程を説明します。Limaはcontainerd を実行するための Linux 仮想マシン (通常は macOS 上) 、2022 年 9 月 14 日にサンドボックス成熟度レベルで CNCF に承認されてます。参考文献LimaInstallation | LimaUsage | LimaDocker Desktop のアンインストールDocker Desktop のアンインストールは、公式ドキュメントの指示に従って行うことができます。アンインストールはシステムの設定やリソースの解放に役立ち、Lima の導入の準備を整えます。# CLI から Docker Desktop をアンインストールすることもできます。さようなら。/Applications/Docker.app/Contents/MacOS/uninstall# Docker Desktop をアンインストールした後、削除できるファイルがいくつか残るので合わせて削除rm -rf ~/Library/Group\\ Containers/group.com.dockerrm -rf ~/Library/Containers/com.docker.dockerrm -rf ~/.docker参照: Docker Desktop アンインストール方法Lima のインストールLima は、macOS で Linux 仮想マシンを容易に管理するためのツールです。Docker コンテナの実行環境として Lima を使用することで、Docker Desktop と同等の機能を低リソースで利用できます。Lima のインストールプロセスは以下のコマンドで行います。# Lima インスタンスの作成:# `docker` という名前の Lima インスタンスを Docker のテンプレートを使って作成します。limactl create --name=docker template://docker# Lima インスタンスの起動:# 作成した `docker` インスタンスを起動します。limactl start docker# 稼働中の Lima インスタンスの一覧表示:# 現在稼働中の Lima インスタンスの状態を表示します。limactl lsNAME       STATUS     SSH                VMTYPE    ARCH       CPUS    MEMORY    DISK      DIRdocker     Running    127.0.0.1:65015    qemu      aarch64    4       4GiB      100GiB    ~/.lima/dockerDocker CLI のインストールLima がインストールされた後、Docker コマンドラインインターフェース (CLI) をインストールする必要があります。以下のコマンドを使用して、macOS 用の Docker CLI をダウンロードし、インストールします。今回はdocker-25.0.4.tgzをダウンロードしますがこちらを参考に最新版をinstallしてください。# Docker CLI バイナリのダウンロード:# macOS 用の Docker CLI バイナリをダウンロードします。curl -L -O https://download.docker.com/mac/static/stable/aarch64/docker-25.0.4.tgz# ダウンロードしたアーカイブの展開:# ダウンロードした tar.gz アーカイブを展開します。# 毎回、調べているので悲しいtar -xvzf docker-25.0.4.tgz# Docker CLI の移動:# 展開した Docker CLI をシステムの PATH の一部である /usr/local/bin に移動します。パスはどこでもいいけどブログなので...。mv docker/docker /usr/local/bin/参照: macOS でのクライアントバイナリのインストール修正: brew install でのdockerのインストール勝手に--caskとか付けて全部入るなーって思っていたのですがbrew install dockerのみの場合にはDocker CLIのみをインストールすることができますbrew install docker我らがteraoka 師匠から教えていただきました。参照: Lima で vz + rosetta を使って ARM VM 上で x86_64 バイナリを実行する #Docker - QiitaLima-Docker の設定Lima と Docker CLI がセットアップされたら、Lima ベースの Docker 環境を利用するための設定を行います。以下のコマンドで Docker コンテキストを作成し、利用を開始します。# Docker コンテキストの作成:# `lima-docker` という名前の Docker コンテキストを作成し、Lima インスタンス上の Docker デーモンに接続します。docker context create lima-docker --docker \"host=unix:///Users/\u003cusername\u003e/.lima/docker/sock/docker.sock\"# 作成した Docker コンテキストの使用:# `lima-docker` コンテキストをアクティブにして、以降の `docker` コマンドが Lima インスタンスを対象に実行されるようにします。docker context use lima-docker# Docker コンテナの実行 (テスト):# Docker 環境が正しく設定されているかを確認するため、hello-world イメージを実行します。docker run hello-world# Docker での nginx コンテナの実行:# nginx イメージをバックグラウンドで実行し、ポート 8181 をコンテナのポート 80 にフォワードします。docker run --name lima-test-nginx -d -p 8181:80 nginxこれらのステップを完了することで、Lima 上で Docker コンテナを実行し、管理することができるようになります。おまけ:KIND (Kubernetes IN Docker) の利用KIND (Kubernetes IN Docker) は、Docker 上に軽量な Kubernetes クラスタを構築するためのツールです。Lima 環境上で Docker を利用している場合でも、KIND を使用して Kubernetes のテスト環境を簡単にセットアップできます。# KIND クラスタの作成:# 新しい Kubernetes クラスタを作成します。このクラスタは Docker コンテナ内に構築されます。$ kind create cluster# 作成されたクラスタの一覧表示:# 現在 KIND によって作成されたクラスタの一覧を表示します。$ kind get clusterskind# クラスタ情報の取得:# 作成した KIND クラスタのコントロールプレーンやサービスの情報を取得します。$ kubectl cluster-info --context kind-kindKubernetes control plane is running at https://127.0.0.1:51050CoreDNS is running at https://127.0.0.1:51050/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.# 全てのネームスペースで動作している Pod の一覧表示:# クラスタ内の全ネームスペースにわたる Pod の状態を確認します。$ kubectl get pod -ANAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGEkube-system          coredns-76f75df574-5glm8                     1/1     Running   0          87skube-system          coredns-76f75df574-jwn6z                     1/1     Running   0          87skube-system          etcd-kind-control-plane                      1/1     Running   0          103skube-system          kindnet-qlftc                                1/1     Running   0          86skube-system          kube-apiserver-kind-control-plane            1/1     Running   0          102skube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          100skube-system          kube-proxy-6nwnv                             1/1     Running   0          86skube-system          kube-scheduler-kind-control-plane            1/1     Running   0          100slocal-path-storage   local-path-provisioner-7577fdbbfb-vd28d      1/1     Running   0          87sおわり。結論Docker Desktop のアンインストールと Lima の導入に焦点を当てました。本記事で紹介した手順を通じて、開発環境を効率的に管理し、Docker コンテナの実行を最適化することが可能です。参考文献Docker Desktop アンインストール方法macOS でのクライアントバイナリのインストール","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/14/083605","isoDate":"2024-03-13T23:36:05.000Z","dateMiliSeconds":1710372965000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。","contentSnippet":"問題を解決する能力は確かに重要ですが、それ以上に、何が本当に重要な問題なのかを見極め、それを明確に設定する能力が不可欠です。問いを適切に定義できなければ、どんなに高度な解決技術を持っていても、その力は十分に発揮されません。また、誰にとって適切な問いなのかも考える必要があります。問題解決の過程において、問題そのものの本質を正確に把握し、適切な問いを立てることは重要です。イシューからはじめよ――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazon概要SREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜にて「書を捨てよ、現場へ出よう - このSRE本がすごい！2024年 LT版」 というテーマで登壇しました。のイベントは2024年1月末に注目を集めた『このSRE本がすごい！2024年版』をテーマにしたもので、多くの参加者とパネルディスカッションのスピーカーであるTopotal のnari_exさん、kenta_hiさんと共に、その内容を深掘りして議論することができ、イベントも無事成功し、大変充実した時間を過ごすことができました。findy.connpass.comイベントを引き起こしたきっかけとなったツイートは以下のものです。この経験から、積極的に意見を発信することの大切さを実感しました。時には思いがけない展開をもたらすこともあるなぁって思いました(小並)。モチベーションになるのでブログの読者登録おねがいします。強い下心を持っているため、Findyさんなどからこれらの本に関する解説をする勉強会の依頼が来ることを期待しています。 https://t.co/amL2de5qFI— nwiizo (@nwiizo) 2024年1月31日   資料この資料は思いの外、感情的な要素が強くエンジニアなのに技術の話を全くしないポエムっぽさが反映されてしまいました。当初は技術的な内容と本の紹介を避ける方針でしたが、認知科学のような専門分野に深く踏み込む知識は持ち合わせていないため、このような方向性になってしまいました。それにもかかわらず、受け取り手からはそこそこに好評を得られたことが非常に嬉しく思います。 speakerdeck.comXでのポストはこちらです。内省の話運用技術者組織の設計と運用 / Design and operation of operational engineer organizationを読んで勝手に憧れていたnari_exさんとのイベントでそのnari_exさんから内省の大切さの話が出てきていた。明日の朝から読んでみようと思う。リフレクション（REFLECTION） 自分とチームの成長を加速させる内省の技術 (オリジナルフレームワークPPT・PDF特典付き)作者:熊平美香ディスカヴァー・トゥエンティワンAmazon読書とは、能力、知識ではなく 問いを獲得するための行為資料を作る前のアウトラインと文章をブログでも公開しておきます。このような内容が気になった方は参考文献を読んでいただければと思います。能力のイメージ能力の抽象性と具体化の必要性日常生活において、私たちは「コミュニケーション能力」、「問題解決能力」、「技術力」などの様々な「能力」について語ります。これらは教育や仕事、プライベートにわたって使われますが、深く考えると、これらの「能力」が具体的に指すものは何か、どう解釈すべきか疑問が生じます。能力に関する理解を深めるには、背後にある原因や要素、その行動や成果への影響を分析することが不可欠です。能力という概念は抽象的であるがゆえに、その実態を把握するには具体的な文脈における観察と分析が欠かせません。能力解釈におけるメタファーの限界と可能性能力の解釈は、しばしばメタファーを通じて行われます。「力」という言葉自体が、物理的な力や潜在的な特性を想起させます。しかし、これらのメタファーは、能力が一貫して同じ効果をもたらすという誤解を生むことがあります。例えば、「コミュニケーション能力」を「言葉の力」と表現することで、言葉さえ巧みに使えば常に良好なコミュニケーションが取れるという誤った印象を与えかねません。能力についての理解を深めるには、メタファーが示すイメージを超えて、実際の文脈での能力の現れ方を丁寧に探ることが重要です。メタファーは理解の出発点としては有用ですが、それに留まらず、具体的な事例や経験から能力の本質を捉えていく必要があります。能力は文脈依存で時と場合次第能力の文脈依存性人間の能力は、状況に応じて異なる形で表れます。ある特定の文脈において顕著な能力が発揮される一方で、他の状況ではまったく異なる影響を持つかもしれません。例えば、プレゼンテーションの場で優れたコミュニケーション能力を発揮する人物が、親密な人間関係の中では十分にその能力を活かせないということもあり得ます。この文脈依存性は、能力が単純な属性ではなく、状況や環境、それに伴う要求に対する応答の結果として理解すべきであることを示唆しています。つまり、能力とは、特定の文脈において、その状況に適した行動を取ることができる力なのです。文脈に応じた問いの形成問いは、私たちが直面する特定の文脈における能力の発揮や理解を深めるのに重要な役割を果たします。そのため、問いは文脈に応じて形成される必要があります。適切な問いを立てることで、その状況における最適な行動や能力の発展につながります。例えば、プレゼンテーションの場面では、「どのようにすれば聴衆の関心を引き付けられるか」、「効果的な情報伝達のために何が必要か」といった問いが重要になります。一方、親密な人間関係の中では、「相手の感情を適切に理解するにはどうすればよいか」、「信頼関係を築くために何ができるか」といった問いが求められます。能力を最大限に活かすためには、その能力をどのように、いつ、どのような状況で使うべきかを考える問いが不可欠なのです。知識の非伝達性と構成主義知識の非伝達性多くの人々は、知識や技能が他者から伝達できるものだと考えがちです。しかし、実際には、知識は伝達されるのではなく、各個人が自身の経験や環境から創発するものなのです。教育や読書を通じて提供されるのは情報のみであり、それを個人が内面化し、自らの知識として再構築するプロセスが必要不可欠です。つまり、知識は受け取るものではなく、自ら作り上げていくものなのです。この視点は、知識獲得を受動的な受け入れではなく、能動的な創造過程として捉えるべきであることを示唆しています。知識の構成主義知識は個人の認知的リソースと環境から提供される情報を結合させて創発されます。このプロセスでは、経験や環境からの情報を基に、個人が能動的に知識を構築します。構成主義の視点から、知識は静的なものではなく、個々の経験や文脈に応じて動的に形成されると捉えられます。これは、知識を単に受け入れるだけでなく、自分自身の行動や内省を通じて深める過程です。知識の構成主義は、学習者の能動性と主体性を重視し、知識の個人的な意味づけを重要視する立場だと言えます。知識の応用と実践道を知っていることと実際に歩くことは違う理論から実践への移行は知識の本質的な価値を明らかにします。教室や書籍で得た知識が、実際の体験や応用を経て深化し、真に生きた知識へと変わります。このプロセスは、抽象的な概念を具体的な行動や体験に結び付け、それによって得られる新しい理解や洞察がさらなる学びのモチベーションを高めます。知識から行動への変換知識を実際の行動に転換することは、それを社会や日常生活に応用し、問題解決や創造的な活動に活かすプロセスです。この実践を通じて、知識は単なる情報の蓄積を超え、個人の体験と統合され、生きたものへと変化します。実践から得られる新たな体験は、知識の内面化を促し、持続可能な知的成長の重要な要因となります。知識と行動の相互作用は、知的な営みの本質であり、知識の実践的な価値を示すものだと言えるでしょう。プログラミング言語の文法や設計パターンを学んだだけでは、実際のソフトウェア開発で成功することは難しいでしょう。理論を実践に活かし、試行錯誤を重ねることで、本当に生きたプログラミングスキルが身につくのです。知っているだけでは不十分で、実際にコードを書き、動かしてみて、時間が経って発生する問題を観測することが重要なのです。読書は、見えなかったものを見えるようにすること問いの形成と知識の活用適切な問いを立てることは、文脈に依存する能力の理解と、個々に構成される知識の活用を促進します。問いは、特定の状況で何が必要であり、どのように行動すべきかを明らかにし、その過程で深い知識の構築と適用が可能になります。読書は、私たちの内面に新たな問いを生み出し、その問いを深めるための知識を提供してくれます。読書と問いの形成は、知識の活用と探究を促す相補的な営みなのです。問いに基づく学習の進展問いは、学習過程において重要な役割を果たします。それにより、私たちは受動的な知識の受け手から、能動的な学習者へと変化し、知識をより深く、文脈に応じて理解し、活用する能力を高めます。これは、個人の成長と発展にとって不可欠なプロセスです。読書は、問いを生み出し、その問いに答えるための知識を与えてくれる営みです。読書と問いに基づく学習は、知的な探究心を育み、生涯にわたる学びの基盤となるのです。問いを深める読書と知的好奇心の拡大読書は、単なる知識の蓄積以上に、私たちの内面的な問いを掘り下げ、それらを広げる活動です。異なる分野や視点からの本を読むことで、従来の枠組みを超えた新しい問いが生まれ、これが知的好奇心を刺激し、さらなる探究へと促します。こうしたプロセスは、私たちの知的な地平を拡げ、より複雑な問題に対する洞察力を高めます。読書の継続と習慣化読書を継続的に行うことは、知識の深化と問いの発展に不可欠です。習慣としての読書は、長期的に見て自己成長を促し、知識をより深く理解し活用する能力を養います。習慣化による読書は、日々の小さな努力を積み重ねることで、大きな学びへと繋がる基礎を築きます。読書習慣は、知的な探究心を持続させ、生涯学習の基盤を形成する上で欠かせない要素だと言えるでしょう。さいごに能力と知識と実践の相互関係能力と知識は、読書を通じて理解し、実践に活かすことができます。読書は、能力の文脈依存性と知識の非伝達性に光を当て、私たちを新たな理解へと導きます。実践を通じて得られる経験は、学んだことを確かなものにし、問いを通じてさらに深い洞察を得ることができます。能力と知識、そして実践は、相互に影響を与え合い、螺旋状に発展していくのです。これらの要素の有機的な結びつきが、私たちの知的成長を支える基盤となります。知識を深めるための継続の意義継続は、知識を蓄積し、それを活用するうえでの基礎を築きます。読書の習慣は、日々の積み重ねによって、知識を内面化し、問いを深め、思考を拡張する重要なプロセスです。知識を深め、問いを追求し続けることで、私たちは自己の成長と進化を遂げることができます。継続的な読書と学びは、私たちを知的な探究者へと導く、生涯にわたる営みなのです。それは、私たちの内なる知的世界を豊かにし、より深い理解と洞察へと導いてくれるでしょう。参考資料学びとは何か――〈探究人〉になるために (岩波新書) 言語の本質-ことばはどう生まれ、進化したかジェームズ・クリアー式 複利で伸びる1つの習慣私たちはどう学んでいるのか　─創発から見る認知の変化達人プログラマー(第2版): 熟達に向けたあなたの旅プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","isoDate":"2024-03-13T07:49:51.000Z","dateMiliSeconds":1710316191000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"書を捨てよ、現場へ出よう","contentSnippet":"書を捨てよ、現場へ出よう このSRE本がすごい！2024年 LT版というタイトルで登壇してきました。\r\rSREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜\rhttps://findy.connpass.com/event/311323/\r\r元ブログはこちら\r\rこのSRE本がすごい！2024年版\rhttps://syu-m-5151.hatenablog.com/entry/2024/01/26/165255\r\r登壇ブログはこちら\r\r『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","link":"https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you","isoDate":"2024-03-12T04:00:00.000Z","dateMiliSeconds":1710216000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"私のメンターがくれた初めてのターミナル管理、それはtmuxで私は新卒でした。","contentSnippet":"はじめに2024年2月5日夜の東京 外は雪が降っている。tmuxとの出会いは、新卒としての初めての職場でした。メンターがターミナルの管理において最初に紹介してくれたのがtmuxで、この出会いが私の開発効率と作業環境を大きく変革しました。tmuxの基礎を学んだ後、私は自分の開発環境をさらにカスタマイズし、tmuxを日々の作業効率化のために積極的に使い始めました。ここでは、私が実際に使っているtmuxの設定と、日常的に使うコマンドを紹介します。これらは、より快適なターミナル操作環境を実現するために役立ちます。この過程で、tmuxはただのツール以上のものになり、私の開発作業における最適なパートナーになりました。tmuxを使いこなすことで、複数のプロジェクトを同時に管理する能力が向上し、長時間の作業も中断せずに続けられるようになりました。リモートワークが増えた今では、tmuxのセッション管理機能が特に役立っています。サーバーに接続した状態で作業を行い、一時的に他のタスクに切り替えても、再びtmuxセッションに戻れば瞬時に作業を再開できます。tmuxを通じて、私はターミナル操作に関してプロフェッショナルな開発者としての成長していると実感しています。あとやっている感がとても出ているので好きです。tmuxとはtmuxは「ターミナルマルチプレクサ（Terminal Multiplexer）」の略称で、Linux系OSを中心に利用されています。このツールを使うと、一つのターミナルウィンドウ内で複数のセッション、ウィンドウ、ペインを効率的に管理することが可能になります。github.comセッションの管理： 一つのターミナルで複数のセッションを持ち、それぞれ独立した作業スペースとして利用できます。仕事とプライベート、複数のプロジェクト間でセッションを分けることができるため、タスクの切り替えがスムーズになります。ウィンドウとペイン： 一つのセッション内で、複数のウィンドウを開くことができ、さらにウィンドウをペインと呼ばれる小分けにすることが可能です。これにより、同一画面内で複数の作業を並行して行うことができ、効率的なマルチタスクが実現します。セッションの維持： tmuxの最大の特徴の一つは、ターミナルを終了してもセッションが維持されることです。これにより、長時間かかるコマンドを実行中にログアウトしてしまったり、接続が切れてしまったりしても、作業が中断される心配がありません。tmux設定のカスタマイズ私の.tmux.confファイルには、効率的なターミナル操作を可能にするための様々なカスタマイズが施されています。これらの設定を通じて、tmuxを自分にとって最適な作業環境に変えることができました。github.comプレフィックスキーの変更: デフォルト設定のCtrl+bをCtrl+qに変更しました。これは、より操作性の良いキーバインドに変更することで、他のショートカットキーとの競合を避け、操作のスムーズさを向上させるためです。キーバインドのカスタマイズ: vimを頻繁に使用することから、ペインの移動やリサイズをvim風に設定しています。これにより、キーボード操作の一貫性を保ちながら、直感的で迅速なウィンドウ管理を実現しています。ペインの分割: よく使用する|キーでペインを縦に分割し、-キーでペインを横に分割するように設定しました。これにより、柔軟かつ迅速に作業スペースをカスタマイズすることが可能になります。ステータスバーのカスタマイズ: ステータスバーには、現在のセッションの状態や時刻など、必要な情報を表示するよう設定しています。これにより、作業中に一目で状況を確認できるようになり、生産性の向上に貢献しています。プラグインの利用: tmux-resurrectやtmux-continuumなどのプラグインを導入しています。これらのプラグインは、セッションの自動保存や復元を可能にし、長時間にわたる作業や一時的な中断からのスムーズな再開を支援します。セッションの保存と復元は、プレフィックスキーに続けてCtrl+sで保存、Ctrl+rで復元することができます。これにより、突然のシステム停止や作業の中断が発生しても、簡単に前の状態に戻ることができます。さらに、tmuxのプラグインエコシステムは非常に豊富で、tmux-pluginsのリストからは、あらゆるニーズに応える特別なプラグインを見つけることができます。自分の作業フローに合わせて、最適なプラグインを選択し、tmux環境をさらにパワフルで柔軟なものにカスタマイズすることが可能です。よく利用するtmuxコマンドtmuxを効率的に使用するためには、日常的に役立つコマンドを知っておくことが重要です。ここでは、特に重宝するコマンドを紹介します。どんな時にでも味方になってくれるチートシートです。ちなみにチートシートには入れてないのですがprefix + e で全てのペインの操作、prefix + Eでそれらの解除などもインフラエンジニアとしては非常に重宝します。github.com以下は、日々の作業で特に役立つコマンドです。新規セッションの開始: tmux new -s \u003cセッション名\u003eコマンドで、特定の名前を持つ新規セッションを開始します。この機能を活用することで、プロジェクトやタスクごとにセッションを分け、作業を整理しやすくなります。セッションの一覧表示と切り替え: tmux lsコマンドで現在のセッション一覧を表示し、tmux attach -t \u003cセッション名\u003eまたはtmux a -t \u003cセッション名\u003eで特定のセッションにアタッチします。これにより、複数のプロジェクトや作業を効率的に管理し、スムーズに切り替えることができます。ペインとウインドウの操作: tmuxでは、ペインの分割やウインドウの作成、移動、リサイズを柔軟に行うことができます。これらの操作をカスタマイズしたキーバインドで行うことで、必要に応じて作業スペースを自由に調整し、マルチタスク作業を効率的に進めることができます。マウス操作の有効化: set-option -g mouse onコマンドにより、tmux内でのマウス操作を有効にすることができます。マウスでペインを選択したり、サイズを調整したりすることが可能になり、キーボードとマウスを組み合わせた直感的な操作が実現します。これらのコマンドは、tmuxを使ってターミナル操作を効率化し、生産性を高めるための基本となります。tmuxをより深く理解し、活用することで、開発作業をより快適に、より効率的に行うことができるでしょう。さいごにtmuxとの出会いは、私の開発効率と作業環境を大きく変えただけでなく、インフラエンジニアとしての成長にも大きく寄与しました。日々の作業でtmuxを使いこなすことで、システムの監視、ログの分析、複数のサーバーへの同時操作など、インフラ管理の幅広いタスクを効率的にこなすスキルを身につけることができました。また、セッションの持続性は、長時間実行するプロセスの管理や、中断された作業の再開といった面で、インフラ作業の品質を向上させるのに役立ちました。tmuxのカスタマイズ性と拡張性を活かして、個人の作業環境を最適化することは、単に作業を効率化するだけではなく、技術者としての視野を広げ、問題解決能力を養う機会となりました。tmuxを深く理解し活用することで、インフラエンジニアリングの知識を実践的に拡張し、より複雑なシステムと効果的に向き合う力を養うことができました。tmux は3.4 がリリースされており今でも進化を続けている。愛している。github.comtmuxは、単なるツール以上の存在となり、私の技術的な成長を支えてくれる貴重なパートナーです。これからもtmuxを活用し続けることでしょう。しかし、人は変わる。実はZellijやターミナルもMAC標準なものを利用しているがAlacrittyが気になっているので検証と導入を進めている。","link":"https://syu-m-5151.hatenablog.com/entry/2024/02/06/110341","isoDate":"2024-02-06T02:03:41.000Z","dateMiliSeconds":1707185021000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"このSRE本がすごい！2024年版","contentSnippet":"はじめに有用な知識の特性Google SRE リソースSite Reliability Engineering: How Google Runs Production SystemsThe Site Reliability Workbook: Practical Ways to Implement SREBuilding Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining SystemsSLO Adoption and Usage in SRECreating a Production Launch PlanTraining Site Reliability Engineers: What Your Organization Needs to Create a Learning ProgramAnatomy of an Incident – Google – Site Reliability EngineeringEnterprise Roadmap to SRE – Google – Site Reliability EngineeringIncident Metrics in SRE – Google – Site Reliability EngineeringPractical Guide to Cloud Migration – Google – Site Reliability EngineeringGoogle以外の重要な書籍紹介97 Things Every SRE Should KnowSeeking SREPractical MonitoringDatabase Reliability EngineeringObservability EngineeringChaos EngineeringBuilding Microservices, 2nd EditionAPI Design PatternsSystems Performance, 2nd EditionEfficient GoImplementing Service Level ObjectivesModern Software Engineering: Doing What Works to Build Better Software FasterLearning Test-Driven Developmentシステム障害対応 実践ガイドWebエンジニアのための監視システム実装ガイドSRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本さいごにはじめに2024年、情報技術の世界は革新的な変化を続け、特にSRE（サイト信頼性エンジニアリング）の分野では新しい概念や技術が絶えず生まれています。この急速に進化する環境において、効率的に最新の知識を吸収する方法を見つけることは非常に重要です。その一つの答えが、「タイパ（タイムパフォーマンス）」という概念です。タイパとは、投入した時間に対する成果の効率を意味し、限られた時間を最大限に活用することの重要性を示しています。このブログでは、SRE分野で高いタイパを達成するための役立つ書籍を探求します。これらの書籍を全て読むのは、SREに深い情熱を持つ者か、非常に勤勉な人に限られるかもしれませんが、オススメの順番などはあえて紹介しません。また、「class SRE implements DevOps」は、「SREはDevOpsというインターフェースの実装である」という意味を持ちます。「DevOps = 思想」という定義に対して、それを具体化し実装したものがSREであると考えます。本ブログでは、DevOpsやその進化形であるPlatform Engineeringについては触れません。それは、既に多岐にわたる議論がある中で、さらに混迷を招く可能性があるためです。また、全ての情報は完璧ではないと思うので補足情報などがあれば教えてください。映画を早送りで観る人たち～ファスト映画・ネタバレ――コンテンツ消費の現在形～ (光文社新書)作者:稲田 豊史光文社Amazon有用な知識の特性有用な知識が持つべき三つの性質について考えます。第一に「一般性」です。これは知識が多様な状況で適用できることを意味します。例えば、コンテナ技術やクラウドインフラの原則は、異なるプラットフォームやアプリケーションでも適用可能です。これが一般性のある知識です。第二の性質は「関係性」です。孤立した知識はあまり役に立ちません。例えば、単に多くのモニタリングツールを知っているだけでは不十分で現場の課題を知っている必要があります。また、それらがシステムのパフォーマンスやセキュリティとどのように関連し、全体的な信頼性を向上させるかを理解することが重要です。最後に「場面応答性」があります。知識は、それが必要とされる特定の状況で適切に活用されるべきです。例えば、システムのスケーラビリティを改善する際には、負荷分散やキャッシングなどの特定の技術や知識が必要です。これらの技術や知識は、それぞれの状況に応じて適切に選択し、活用されるべきです。場面応答性がある知識は、適切な状況でのみその真価を発揮することができます。この有用な知識の枠組みに加えて、特に学生や新卒の方々には「基礎の重要性」を強調したいと思います。技術的な深い理解や幅広い応用は、コンピュータサイエンスの基本原理、アルゴリズム、データ構造などの基礎知識があってこそ可能です。SREやオブザーバビリティなどの先進的な分野への関心も良いことですが、その前にしっかりとした基礎を学び、築くことが非常に重要です。基礎知識がしっかりしていれば、新しい技術やトレンドにも柔軟に対応し、深く理解することができるでしょう。学びとは何か――〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店AmazonGoogle SRE リソースGoogleは、SRE（Site Reliability Engineering、サイト信頼性エンジニアリング）の知識と実践を業界全体で共有し、普及させるために積極的な取り組みを行っています。このページで紹介されている書籍やリソースはその一部に過ぎません。Google SREリソースとして、さらに多くの資料が公開されていますので、興味のある方は以下のリンクから探求してみてください。sre.googleSite Reliability Engineering: How Google Runs Production Systems「Site Reliability Engineering: How Google Runs Production Systems」は、Googleが開発したシステム管理とサービス運用の方法論を学ぶことができる、非常に重要なSREの書籍です。この書籍はO’Reillyから出版されており、全552ページにわたって豊富な内容が展開されています。発売日は2016年4月で、原書なのでリリースから時間が経過していますが、その内容の深さと実践的なアプローチは、今日でも多くのSRE専門家やソフトウェアエンジニアにとって非常に価値のあるものです。sre.googleこの書籍では、ソフトウェアのライフサイクル全体にわたるコミットメントと、世界最大規模のソフトウェアシステムの構築、導入、監視、維持方法について詳細に解説しています。リスク管理、サービスレベル目標、リリースエンジニアリングなどSREの基本原則から始まり、インシデント管理、障害の根本原因分析、SREチーム内でのソフトウェア開発についても深く掘り下げています。さらに、SREのトレーニングやコミュニケーション管理についても紹介しており、急速にスケールするサービスを高い信頼性で運用する方法についての理解を深めることができます。この書籍は、大規模なシステムの運用における複雑な課題への実践的な解決策を提供しており、非常に有益です。リリースエンジニアリングやインシデント管理の部分は特に、日常業務に直接応用できる知見が豊富に含まれており、実務においても大いに役立つ内容となっています。また、SREチーム内でのソフトウェア開発プロセスに関する記述は、チームワークと効率性を高めるための貴重で有用な参考資料となります。Googleによって無料で公開されていることも特筆すべき点で、こちらのリンクから無料で読むことが可能です。さらに、日本語での翻訳版も存在し、日本の読者にとっても2倍の感謝を持って読むことができるでしょう。SRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazonさらに、Googleに直接関連はありませんが「もう一度読むSRE」というポッドキャストもあり、この書籍の内容を深く理解するための補足資料として聞いてみるのも良いでしょう。ポッドキャストを通じて、書籍の内容をさらに掘り下げたり、実際の業務における適用例を聞くことができます。The Site Reliability Workbook: Practical Ways to Implement SRE「The Site Reliability Workbook: Practical Ways to Implement SRE」は、SREの原則と実践方法に深く踏み込んだ、O’Reillyから出版された812ページにも及ぶ充実した内容の書籍です。その分厚さは、まさに鈍器のよう。2018年7月の発売で、「Site Reliability Engineering: How Google Runs Production Systems」のリリースから3年が経過し、この期間を経てさらに充実した内容に進化しています。sre.googleこの書籍では、具体的な事例を通じてSREの原則と実践方法に深く踏み込んでいます。前作で紹介されたSREの基本原則からさらに一歩進み、Google内部で培われた技術的ノウハウだけでなく、Evernote、The Home Depot、New York Timesなどさまざまな企業の事例も紹介しています。クラウド環境での信頼性の高いサービス実行方法や、サービスレベル目標に基づくサービスの運用、既存の運用チームをSREに変換する方法など、実践的かつ詳細な解説がなされています。この書籍は、既にSREを導入している企業やこれから導入を考えている企業の開発者、運用管理者、マネージャーにとって、理論から実践へと移行するための貴重な手引きとなります。実際の業務に役立つ豊富な知識と具体的なガイドラインを提供しており、SREの実践を深めたいすべてのプロフェッショナルにとって有用な内容です。Googleによって無料で公開されていることも特筆すべき点で、こちらのリンクから無料で読むことが可能です。このような資料を無償で提供することは、業界全体の技術向上に大きく貢献しています。GoogleがSREの知識と実践を広く共有し、普及させようとする意図が明確に伺えます。さらに、日本語で翻訳されているため、日本の読者も2倍の感謝を持って読むことができるでしょう。サイトリライアビリティワークブック ―SREの実践方法オライリージャパンAmazonBuilding Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems「Building Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems」は、O’Reillyから出版された519ページに及ぶ内容で、セキュリティを中心に据えた構成となっています。2020年3月の発売で、聖典とも言える「Site Reliability Engineering: How Google Runs Production Systems」のリリースから4年が経過しており、この間にセキュリティ意識の高まりを強く感じさせる書籍です。google.github.ioこの書籍では、システムのセキュリティと信頼性が一体であることを明示し、スケーラブルなシステムの設計と運用におけるセキュリティの重要性を深く掘り下げています。GoogleのセキュリティとSREのエキスパートが、セキュアでスケーラブルかつ信頼性の高いシステムを根本から設計するためのベストプラクティスを紹介しており、システムの設計、実装、保守に関する考え方と実践法を詳しく解説しています。また、組織の文化がベストプラクティスに取り組む上でいかに重要かについても言及されています。この書籍はセキュリティと信頼性を軸にしたシステム構築のための貴重な知見を提供しています。特に、セキュリティをシステム設計の初期段階から考慮する重要性を説く内容は、現代のセキュリティ意識が高まる中でのシステム設計において非常に参考になります。また、組織文化とそのベストプラクティスへの適用に関する洞察は、チームや組織全体のセキュリティ意識向上に大いに役立つでしょう。「Building Secure and Reliable Systems」も、Googleによって無料で公開されており、こちらのリンクから無料で読むことが可能です。Googleがセキュリティと信頼性に関する知識を広く共有しようとする姿勢が、このような形で表れているのです。また、Google SRE本は3冊とも翻訳されていてありがたい限りですね！！！セキュアで信頼性のあるシステム構築 ―Google SREが考える安全なシステムの設計、実装、保守オーム社Amazonセキュリティに関する本の一環として、Googleとは直接関連はありませんが、『体系的に学ぶ 安全なWebアプリケーションの作り方 第2版 脆弱性が生まれる原理と対策の実践』の読書をお勧めします。この本では、Webアプリケーションのセキュリティにおける脆弱性の原理と対策について詳細に解説されています。SLO Adoption and Usage in SRE「SLO Adoption and Usage in SRE」は、サービスレベル目標（SLO）のSREにおける採用と使用に焦点を当てた104ページの実践的なレポートです。2020年4月1日に発売されたこのレポートは、SREのフレームワークを活用して運用コストの削減や開発生産性の向上に役立つ方法を提供します。SREやソフトウェアエンジニアとして、このレポートはSLOの重要性とその実践法を深く理解するのに大変役立ちます。SLO、SLI、エラーバジェットをSREの実践の中核として位置づけ、サービスの信頼性をどのように測定し管理するかを具体的に示しています。Googleの調査結果や実際のケーススタディを基に、許容可能な信頼性のレベルを定義し、それに基づいてシステム変更を適切に管理する方法は、日々の業務に直接適用できる知識です。参考リンク: SLO Adoption and Usage in SRESRE担当者、エグゼクティブ、開発者、アーキテクトなど、幅広い関係者にとって、SLOを取り入れたSREの実践を深めるための有用なリソースとなるでしょう。Creating a Production Launch Plan「Creating a Production Launch Plan」は、実稼働環境の立ち上げにおける計画策定に焦点を当てた45ページの実践的なレポートです。2020年1月に発売されたこのレポートは、製品のローンチプランをテンプレートとして使用することで、多くの時間、費用、そして頭痛を節約する方法を提供します。SREやソフトウェアエンジニアとして、このレポートは実稼働環境の立ち上げにおける計画策定の重要性と実践法を深く理解するのに非常に役立ちます。Googleが実際にどのように本番発売計画を策定したかを紹介し、自社製品を導入する際のリスクを低減するための実践的な方法を学べます。ローンチプランは、すべての関係者とプロセスを巻き込み、ローンチの進行を確実にコントロールすることで、さまざまな問題を防ぐことができます。参考リンク: Creating a Production Launch Plan開発者やサイト信頼性エンジニア（SRE）を対象に、Googleのローンチプランの基本的な構成要素を探り、自社製品を導入する際のリスクを低減するための実践的な方法を提供する本レポートは、企業規模や製品のユーザーベースに関係なく、消費者向けサービスにも適応可能です。これらの教訓は、製品のローンチを成功に導くための貴重で有用な学習リソースとなるでしょう。Training Site Reliability Engineers: What Your Organization Needs to Create a Learning Program「Training Site Reliability Engineers: What Your Organization Needs to Create a Learning Program」（日本語名：サイト信頼性エンジニアの育成：学習プログラムを作成するために組織に必要なこと）は、サイト信頼性エンジニアの育成に関する116ページの詳細なガイドです。2020年2月に発売されたこのレポートでは、一般的な内容からドメイン固有の内容まで、組織でのSREトレーニング方法について解説しています。GoogleのSREチームによるこのガイドでは、Googleが新しいSREを育成するために使用しているトレーニングのベストプラクティスを学ぶことができます。また、SRE（またはSREに類似した機能）のトレーニングを成功させた小規模な組織での使用例も紹介されています。効果的なSREトレーニングを実施するためには、自社のニーズと受講者の両方に合うように意図的に設計する必要があります。本レポートの大部分はGoogle SREの具体的な経験に焦点を当てていますが、トレーニング設計の背景にある理論についても説明し、過去数年間に業界全体で得られたベストプラクティスや教訓を紹介しています。参考リンク: Training Site Reliability Engineersこのレポートは、SREの育成に取り組む組織にとって、トレーニングプログラムの設計と実施における重要な指針を提供し、より効果的なSREトレーニングの実現をサポートします。Googleの実践に基づく具体的なアプローチは、業界におけるSREトレーニングのスタンダードを形成していると言えるでしょう。Anatomy of an Incident – Google – Site Reliability Engineering「Anatomy of an Incident – Google – Site Reliability Engineering」（日本語名：インシデントの解剖 – Google サイト信頼性エンジニアリング）は、インシデント対応に関する70ページの実践的なレポートで、2016年4月に発売されました。このレポートは、システム設計における失敗の避けられない側面を探り、科学者やエンジニアが未来を完全に把握することなく解決策を実行する現実を浮き彫りにしています。次のゼロデイ脆弱性、バイラル・メディア・トレンド、気象災害、テクノロジーの変化などを予測することは難しいものですが、本レポートでは、インシデントがシステムに影響を及ぼした場合に対応するための準備方法について詳しく探求しています。SREやDevOpsの実務者、IT管理者、エンジニアリング・リーダーを対象に、Ayelet Sachto氏、Adrienne Walcer氏、Jessie Yang氏のアドバイスをもとに、組織がインシデントに備え、対応し、回復する方法について解説されています。参考リンク: Anatomy of an Incidentこのレポートは無料で公開されており、上記のリンクから原著を読むことが可能です。インシデント発生時の効果的な対応策を学ぶことは、組織のシステムの信頼性を高め、将来のトラブルへの対処能力を強化するために不可欠です。インシデント管理に関心のあるすべてのプロフェッショナルにとって価値のあるリソースと言えるでしょう。Enterprise Roadmap to SRE – Google – Site Reliability Engineering「Enterprise Roadmap to SRE – Google – Site Reliability Engineering」（日本語名：SREエンタープライズロードマップ – SREを導入し継続する方法）は、SREに関する技術的立ち位置、導入理由、必要なプロセス、文化、事例などを幅広く紹介する62ページのコンパクトなレポートです。2020年3月に発売され、日本語で読める点も非常に魅力的です。このレポートでは、Google Cloud Reliability AdvocateのSteve McGheeとGoogle Cloud Solutions ArchitectのJames Brookbankが、組織でSREを導入する際にエンジニアが直面する特定の課題について深く掘り下げています。Googleが過去に出版した「Site Reliability Engineering」と「The Site Reliability Workbook」が、サービスライフサイクル全体への取り組みによって組織がソフトウェアシステムの構築、展開、監視、保守を成功させる方法と理由を示しているのに対し、本レポートはそれらを補完する内容となっています。参考リンク: Enterprise Roadmap to SRESREの普及にもかかわらず、多くの企業ではSREに対する当初の熱意とその採用の度合いの間に大きな隔たりが生じています。このレポートは、プロダクトオーナーや信頼性の高いサービスに携わる方々がSREの採用について知りたいときに、そのプロセスを体系的に説明するものです。SREの導入を検討する企業や、より効果的な方法でSREを実践したいエンジニアにとって、重要なガイダンスを提供する資料です。Incident Metrics in SRE – Google – Site Reliability Engineering「Incident Metrics in SRE – Google – Site Reliability Engineering」（日本語名：SREにおけるインシデント評価指標 – Google – Site Reliability Engineering）は、SREにおけるインシデント評価指標に深く焦点を当てた36ページのレポートです。2021年3月に発売され、SREでの改善評価や傾向追跡に用いられるMTTxメトリクスの効果について深く掘り下げています。SREでは、MTTR（平均復旧時間）やMTTM（平均緩和時間）などのメトリクスが一般的に使用されていますが、Google SREのStepan Davidovic氏はモンテカルロ・シミュレーションを用いて、これらのメトリクスが生産インシデントのコンテキストにおいて意思決定やトレンド分析に適していないことを示しています。これらのメトリクスの適用は見かけよりも厄介で、多くの実用的なシナリオにおいて誤解を招く可能性があります。本レポートでは、これらの測定を達成するための代替方法を探ります。参考リンク: Incident Metrics in SREこのレポートは、SREの実務においてインシデント評価指標の適用に関する誤解を避け、より効果的な方法を探るための重要なリソースとなります。SRE担当者やシステム運用チームは、このレポートを通じてインシデントの評価と分析に対するより深い理解を得ることができ、より効率的かつ適切な意思決定を行うための手助けを受けることができるでしょう。Practical Guide to Cloud Migration – Google – Site Reliability Engineering「Practical Guide to Cloud Migration – Google – Site Reliability Engineering」（日本語名：クラウド移行実践ガイド – Google – サイト信頼性エンジニアリング）は、クラウドへの移行に関する実践的なアプローチを解説する124ページのレポートです。2021年2月に発売され、企業が直面する大規模なクラウド変革の課題に焦点を当てています。クラウドへの移行はしばしば、大きなリターンが期待されるものです。この移行が実現すると、働き方を根本的に変える新たなビジネスチャンスが生まれます。本レポートでは、Googleのチームメンバーがクラウドへの移行に必要な文化的および技術的変革をナビゲートする方法を示しています。Googleはクラウドで誕生した企業ですが、チームメンバーの中には、この移行を苦労して乗り越えなければならなかった組織の出身者もいます。彼らは成功したクラウド変革のさまざまな側面をカバーする13のエッセイを通じて、苦労して勝ち取った経験を共有します。参考リンク: Practical Guide to Cloud Migrationこのレポートは、クラウドへの移行を検討している企業やチームにとって、具体的なヒントやアドバイスが満載の価値あるガイドとなります。クラウド変革の課題に直面する多くの組織が、このレポートを通じて適切な戦略とアプローチを学び、成功への道を切り開くための重要な手がかりを得ることができるでしょう。Google以外の重要な書籍紹介この章では、Googleに関連しないが、サイト信頼性エンジニアリング（SRE）やソフトウェアエンジニアリングの分野で重要な書籍を紹介しています。しかし、これらの書籍は、SREとソフトウェアエンジニアリングの広大な知識と実践の世界におけるごく一部に過ぎません。市場には、読者の皆様にとってさらに多くの価値ある書籍が存在し、それぞれが独自の視点と深い専門知識を提供しています。これらの書籍は、私の独断と偏見で日々直面する課題を解決し、スキルを磨くための貴重で有用なリソースとなり得ます。97 Things Every SRE Should Know「97 Things Every SRE Should Know」は、250ページにわたる実践的な書籍で、2020年11月に出版されました。この本は、SREの新人からベテランまでが、SREの採用方法、SLOの重要性、インシデント対応のアップグレード時期、モニタリングと可観測性の違いなどについて学ぶことができる、幅広いトピックをカバーしています。編集者のJaime WooとEmil Stolarskyは、信頼されるベストプラクティスや新しい問題解決方法を含む、97の有用なヒントを集めました。これにより、SREのスキルを成長させ、洗練させることが可能です。特に、「エラーバジェットを手に入れたら、次に何をするか」 - Alex Hidalgo や 「自分の仕事を認識させる：自慢文書を書く」 - Julia Evans and Karla Burnett などのアドバイスは、SREの領域において深い理解と実践的なスキルを習得するのに役立ちます。この書籍はSREにおける深い理解と実践的なスキルの習得に大いに役立ち、技術者やチームリーダー、プロジェクトマネージャーにとって非常に参考になる内容となっています。Seeking SRE「Seeking SRE」は、サイト信頼性エンジニアリング（SRE）に関する幅広いトピックを扱う587ページの書籍で、O'Reilly Media, Inc.から2018年9月に出版されました。この書籍は、システムとアプリケーションの信頼性の重要性と、市場の要求する速度でのイテレーションを行いながら信頼性を維持する難しさを背景にしています。Googleによる「Site Reliability Engineering」という著書に触発され、SREの非常に異なる部分を探求しています。「Seeking SRE」には25以上の章が含まれ、SREの世界で行われている重要な議論に読者を引き込みます。様々な環境でのSREの実装方法、DevOpsとの関連、最先端の専門知識、ベストプラクティスとテクノロジー、さらにはSREの人間的側面について、エンジニアやその他の分野のリーダーが語る内容が盛り込まれています。David N. Blank-Edelmanがキュレーター兼編集者を務め、SREの理解を深め、実践的なスキルを習得したい技術者やリーダーにとって非常に参考になる内容となっています。日本語の書籍も出版されていてとても嬉しいですねSREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazon弊社では輪読会を行いましたが様々な案件とリンクして考える事ができてよかったです。syu-m-5151.hatenablog.comPractical Monitoring「Practical Monitoring」は、O'Reilly Media, Inc.から出版された170ページに及ぶ監視システムの設計と実装に関する実践的なアプローチを提供する書籍です。2017年10月に発売され、モニタリングの改善が必要だが、どこから手を付けるべきかわからない人々に向けて書かれています。著者のMike Julianは、企業アプリケーションからデータセンターのハードウェアに至るまで、様々なレベルでの効果的なモニタリングを設計し実装するための戦略と戦術を提供しています。この書籍は特定のツールの実装方法ではなく、モニタリングの原則と基本的な仕組みに焦点を当てており、モニタリングのアンチパターン、デザインの原則、効果的なオンコールローテーションの構築、アプリケーションからのメトリクスとログの取得といった重要なトピックをカバーしています。モニタリングは、「Service Reliability Hierarchy」 でも最も最初に取り組むべきだと記載されており、その重要性は業界全体で認識されています。本書は、モニタリングの効果的な実践に関して、あらゆるレベルの専門家に対して具体的な洞察とガイダンスを提供します。Site Reliability Engineering: How Google Runs Production Systems Part III. Practices Figure III-1. Service Reliability Hierarchy より個人的には、既に知っている内容も多かったものの、心得的な部分は「監視版リーダブルコード」と表現できるほどの価値がありました。ある程度監視を経験した人には自分の知識を再確認するのに適していますが、入門書としては抽象的で理解しにくい内容も含まれているため、即座に具体的な知識を得て活用したい人には向いていないかもしれません。ネットワーク、サーバー、フロントエンド、バックエンド、KPIなどを幅広くカバーしていますが、具体的なアクションポイントにはあまり触れられていません。こちらのリンクで、この本をチェックすることができます。日本語版もO'Reilly Platform で読めます。こちらの書籍は、日本語版では「入門 監視」と題されており、これは非常に喜ばしいことです。原題の直訳である「実践 監視」とするのではなく、「入門」としていることで、モニタリングの基礎から学びたい初心者や、監視システムの知識を深めたい方々にとってもアプローチしやすい内容となっています。初学者に優しいこのタイトル変更は、監視の世界への第一歩を踏み出す人々にとって、大いに役立つことでしょう。入門 監視 ―モダンなモニタリングのためのデザインパターン作者:Mike JulianオライリージャパンAmazon「Monitoring Anti-Patterns」は、監視システムにおける一般的な間違いや誤解を扱う非常に洞察に満ちたセクションです。このセクションでは、監視を単なるタスクではなく、システム全体の健康とパフォーマンスを維持するための重要なプロセスとして捉えることの重要性が強調されています。具体的には、監視システムの設計と実装において、ツールへの過度な依存（「ツールの崇拝」）、チェックボックス式のアプローチ（「動作している」とは何を意味するのかに焦点を当てる）、監視を一時的な対処策として使うこと（「監視を松葉杖として使う」）、また手動での設定の問題点などが取り上げられています。これらのアンチパターンは、監視システムの構築における一般的な落とし穴を示しており、これらを理解し避けることは、より効果的な監視システムの構築に不可欠です。また、OSメトリクスはアラートにはあまり役立たないことが多いため、メトリクスをより頻繁に収集することの重要性も指摘されています。このセクションを読むことで、監視に関する一般的な誤解を避け、より効果的な戦略を実践するための洞察を得ることができます。learning.oreilly.com「Prometheus: Up \u0026 Running, 2nd Edition」は、Prometheusの使い方とベストプラクティスを網羅した書籍です。Prometheusは多くの組織で実運用されているメトリクスベースのモニタリングシステムであり、この書籍はサイト信頼性エンジニア、Kubernetes管理者、ソフトウェア開発者にとって実践的な指南書となります。learning.oreilly.comDatabase Reliability Engineering「Database Reliability Engineering」は、データベース管理の進化としてのDBRE（データベース リライアビリティエンジニアリング）をテーマにしたO'Reilly Media, Inc.からの294ページの重要な書籍です。2017年10月に出版され、データベースの信頼性に対する包括的なアプローチを提示しています。この書籍は、技術的な側面だけでなく、チームや組織全体の連携や継続的改善サイクルにも言及しています。特に、DBAからDBREへの進化に焦点を当て、多様なDBのプロフェッショナルが、他部門と協力し、システムの信頼性を高めるための自律的なアプローチについて詳述しています。書籍では、インフラとデータベースの効率的な構築や運用に関する技術的な知見が紹介されています。GitやChefなどを活用して、環境構築の自動化や人的ミスの排除に重点を置いています。メモリ管理、ストレージのチューニング、データベースのアーキテクチャなどに関する具体的な説明も盛り込まれており、データベースの効率的な運用に不可欠な要素として提示されています。バックアップ、セキュリティ、データベースのアーキテクチャなど、データベース運用のさまざまな側面についても触れられており、実際のDB運用業務での協業観点からも多くを学ぶことができます。また、インフラとDBaaS（Database As A Service）に関する技術的説明も含まれており、現代のデータベース運用における新しいトレンドとチャレンジに対応しています。全体的に、この書籍は技術的な知識にとどまらず、実際のデータベース運用における現場での協力や継続的な改善に関する洞察を提供するものであり、DBREとして成長したいプロフェッショナルにとって非常に価値のある一冊です。データベースリライアビリティエンジニアリング ―回復力のあるデータベースシステムの設計と運用作者:Laine Campbell,Charity MajorsオライリージャパンAmazon「Fundamentals of Data Engineering」は、O'Reilly Media, Inc.から2022年6月に出版された447ページの書籍で、データエンジニアリングの急速な成長に対応し、ソフトウェアエンジニア、データサイエンティスト、アナリストに全体的な理解を提供します。著者のJoe ReisとMatt Housleyが、データエンジニアリングのライフサイクルを通じて読者を導き、さまざまなクラウド技術を組み合わせて、組織と顧客のニーズを満たすシステムの計画と構築方法を紹介しています。本書では、データの生成、取り込み、オーケストレーション、変換、ストレージ、ガバナンスの概念を、どのようなデータ環境でも適用する方法を理解できます。また、データエンジニアリングの全体的な風景についての簡潔な概要を得ることができ、データ技術、アーキテクチャ、プロセスを選択する際のマーケティングハイプを切り抜けるためのベストプラクティスのエンドツーエンドフレームワークを使用する方法も提供されています。さらに、データガバナンスとセキュリティをデータエンジニアリングのライフサイクル全体に組み込む方法も学べるため、この本は、データエンジニアリングの基礎を学び、Platform EngineeringやSREなどの関連分野との関連性を理解するのに適した初心者向けのガイドです。learning.oreilly.comまた、RDBに関しての知識はほぼ絶対に腐らないので「達人に学ぶDB設計 徹底指南書」や「達人に学ぶSQL徹底指南書 第2版」は読んでいて絶対に良いと思います。Observability Engineering「Observability Engineering」は、O'Reilly Media, Inc.から2022年5月に出版された318ページにわたる書籍で、現代の複雑なシステムにおけるオブザーバビリティの重要性と実践について深く掘り下げています。著者であるCharity Majors, Liz Fong-Jones, およびGeorge Mirandaは、オブザーバビリティがどのようにして開発速度を加速し、不規則な振る舞いの特定、ユーザー体験の理解を深めるかについて説明しています。この書籍は、オブザーバビリティの定義、クラウドネイティブアプリケーションへの応用、ソフトウェア開発ライフサイクル全体における影響、さらにはサービスレベル目標と共に機能するチームによるオブザーバビリティの利用方法など、多岐にわたるトピックを扱っています。特に、構造化イベントの利用とOpenTelemetryによる計装の重要性が強調されており、オブザーバビリティによってエンジニアがよりプロアクティブなデバッグを行い、迅速なフィードバックサイクルを回すことが可能になると述べられています。しかし、オブザーバビリティ関連のコストが高くつく可能性も指摘されており、エンジニアと経営者の両方に、そのビジネス価値を正しく理解し伝える必要性が強調されています。オブザーバビリティの導入には「作るか買うか」の選択があり、その機能要件、適切なテレメトリーデータのサンプリング方法、テレメトリーパイプラインを用いたデータ管理についても詳細に議論されています。さらに、組織全体でのオブザーバビリティの採用には、文化的な変化が伴うとし、その投資対効果や利害関係者との協力の重要性が説明されています。この書籍は、オブザーバビリティが企業の最終損益に与える影響を明確にし、組織におけるオブザーバビリティの成熟度モデルを提供することで、オブザーバビリティを組織に根付かせるための指針を提供しています。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社Amazon「Learning OpenTelemetry」は、2024年3月にO'Reilly Media, Inc.から出版される、OpenTelemetryの実践的な利用に焦点を当てた250ページの書籍です。著者のAustin ParkerとTed Youngは、OpenTelemetryの各コンポーネントと、これを使ったオブザーバビリティシステムの設定、運用、トラブルシューティング方法を紹介しています。OpenTelemetryにより、複数の高品質なテレメトリーデータソースが一本化され、効率的なオブザーバビリティが実現します。この書籍は、オブザーバビリティの基本から応用までを網羅し、特にアプリケーション開発者やインフラチームにとって貴重な情報源となるでしょう。また、前著「Observability Engineering」の内容を受け継ぎながら、OpenTelemetryを通じた具体的な実践方法を提供することで、現代の複雑なシステムにおけるオブザーバビリティの理解と活用をさらに深めます。learning.oreilly.comChaos Engineering「Chaos Engineering」は、O'Reilly Media, Inc.から2020年4月に発売された305ページの書籍で、カオスエンジニアリングについての実践的なガイドです。この分野での先駆者であるCasey RosenthalとNora Jonesが共著し、Netflixでの経験を基にしています。本書は、複雑なシステムを理解し、ビジネス目標に最適化しながらナビゲートする方法をエンジニアに示します。カオスエンジニアリングとは、マイクロサービスや分散技術を採用する企業が増えるにつれて高まるシステムの複雑性に対応する方法論です。 この手法を用いることで、複雑性を取り除くことはできないものの、システムの脆弱性を発見し、顧客への影響を及ぼす前に障害を防ぐことが可能になります。また、Google、Microsoft、Slack、LinkedInなどの業界専門家からの実世界の事例を通じて理論から実践への橋渡しがなされています。書籍では、カオスエンジニアリングプログラムをゲームデイを中心に設計し、高度にターゲットを絞った自動化された実験に進む方法が紹介されています。このように、システム内の複雑性を理解するための枠組みの設計や、継続的な協力的カオス実験のデザインについても詳述されています。ただし、本書の内容は非常に有意義である一方で、カオスエンジニアリングはその文化を前提としているため、導入のハードルは高いとされています。 実際、カオスエンジニアリングの成功は組織文化や思考の枠組みに大きく依存しており、組織全体の問題解決への取り組みとして考える必要があります。カオスエンジニアリングを導入するには、単に技術的な側面だけでなく、組織としての成熟度や文化的な準備が必要になります。カオスエンジニアリング ―回復力のあるシステムの実践作者:Casey Rosenthal,Nora JonesオライリージャパンAmazon「Security Chaos Engineering」は、O'Reilly Media, Inc.から2023年3月に発売された428ページの書籍で、セキュリティカオスエンジニアリングについての包括的なガイドです。著者のKelly ShortridgeとAaron Rinehartは、複雑なソフトウェアシステムの持続可能なレジリエンス（回復力）における挑戦に対処する方法を探求しています。セキュリティカオスエンジニアリングとは、不利なイベントに備え、それらが革新、迅速な動き、エンジニアリングおよびビジネス目標の達成を妨げないようにする手法です。 この書籍では、セキュリティプログラムの設計方法、ソフトウェア配信の各フェーズでの意思決定、複雑なシステムダイナミクスの理解、システムにおける意思決定を歪める技術的および組織的トレードオフのナビゲート方法について解説しています。また、カオス実験を通じて、ソフトウェアの品質とセキュリティに関する重要な仮定を検証する方法にも焦点を当てています。 このアプローチにより、組織はセキュリティカオスエンジニアリングを利用して、システムのレジリエンスを高め、広範な攻撃から保護する方法を学ぶことができます。さらに、本書では大手企業がセキュリティカオスエンジニアリングをどのように活用しているかの事例も紹介しており、読者に現実的な応用の例を提供します。この書籍は、サイバーセキュリティの課題に直面している方にとって、非常に価値のあるリソースとなるでしょう。learning.oreilly.comBuilding Microservices, 2nd Edition新しいものが常に良いわけではありません。見掛けの進捗や成果を得るために、シンプルで高品質なものを手放す必要はありません。シンプルで高品質なモノリスは、価値あるものとして当然のように評価されるべきです。それでも、マイクロサービスへの移行が必要な場合には、「Building Microservices, 2nd Edition」を参照してください、Sam Newman氏による612ページに及ぶ包括的な書籍で、マイクロサービスの構築、管理、そしてスケーリングに関する幅広いトピックを扱っています。この書籍は、モデリング、統合、テスト、デプロイメント、監視などの最新のマイクロサービスソリューションに関して、明快な例と実用的なアドバイスを提供しています。技術の時間の経過とともの進化を追いながら、マイクロサービスに関する理解を深めるのに非常に役立ちます。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオライリー・ジャパンAmazon「Monolith to Microservices」は、マイクロサービスの理念と移行プロセスに関する実践的な内容に焦点を当てています。具体的なテクノロジーではなく、マイクロサービスへの移行を決定する基準や手順に関する経験に基づく指針を提供しており、読者にとって非常に理解しやすく、実務においても有益な情報が得られるでしょう。これらの書籍は、マイクロサービスアーキテクチャの理解を深め、実際のシステム設計や運用において役立つ貴重なリソースです。モノリスからマイクロサービスへ ―モノリスを進化させる実践移行ガイド作者:Sam NewmanオライリージャパンAmazon分散システムの信頼性を深めたい方には、『Go言語による分散サービス―信頼性、拡張性、保守性の高いシステムの構築』がおすすめです。この書籍は、データ集約型アプリケーションの設計における核心的な概念と技術を網羅的に解説し、信頼性の高い分散システム構築に必要な知識を詳細に説明しています。マイクロサービスの主軸を担うSREとして立ち回るためには、『データ指向アプリケーションデザイン』は絶対に読んでおくべき書籍です。この書籍は、分散システムの複雑さと信頼性を理解し、それらを適切に管理するための実践的な知識を提供しています。SREとしての能力を高め、システムの効率性と安定性を保つために、この書籍の学びを活用することが重要です。動画www.youtube.com発表資料 speakerdeck.comAPI Design Patterns「API Design Patterns」は、ウェブおよび内部APIの設計に関する包括的なガイドで、480ページにわたりAPIパターンの原則、リソースレイアウト、データ型の取り扱い、標準手法、セキュアなAPIのための認証・検証方法などを深く掘り下げています。GoogleのAPI専門家JJ Geewax氏によって執筆されたこの書籍は、一貫性とスケーラビリティを確保するためのAPIデザインパターンを示し、APIの基本から高度な機能、特殊なケースまでを網羅しています。読者は、APIの設計とリファクタリングに必要な知識と技術を学び、APIをより効果的に構築するための実用的なアプローチを得られます。learning.oreilly.com「Web APIの設計」はArnaud LauretによるAPI設計の実践ガイドです。この書籍では、使いやすく、柔軟で堅牢なAPIを構築する方法について詳しく解説されています。特に、コマースサイトの例を用いてデータの配置方法やAPIの拡張性の維持方法が紹介されており、実装を重視しないアプローチが特徴です。メンテナンス性やドキュメント作成の重要性も強調されています。この書籍を通じて、読者はAPIの設計と構築に必要な基本原則と実用的な手法を学ぶことができます。Web APIの設計作者:Arnaud Lauret翔泳社Amazon現代のSREというか運用では、APIやデータベースに関する知識が不可欠です。これらの技術の理解がなければ、トラブルシューティングやシステムアーキテクトとして効果的に立ち振る舞うことは困難です。APIやDBはシステムの基盤を形成し、その運用と最適化に深く関わっているため、これらの要素を熟知していないと、複雑な問題解決や効率的なシステム設計ができません。したがって、技術者はAPIとDBの知識を身につけ、常に最新のトレンドを追い続けることが重要です。Systems Performance, 2nd Edition「Systems Performance, 2nd Edition」は、システムパフォーマンスの専門家であるBrendan Greggによる928ページに及ぶ包括的な書籍です。Linuxベースのオペレーティングシステムを例に取りながら、オペレーティングシステム、ハードウェア、アプリケーションの理論を要約し、最新のツールやテクニックを用いたCPU、メモリ、ファイルシステム、ディスク、ネットワーキングの最適化やパフォーマンス分析の方法論を提供しています。クラウド環境でのパフォーマンス上の課題や、perf、Ftrace、BPF（BCCおよびbpftrace）を用いたプロファイリングとトレーシングなど、実践的な技術にも深く掘り下げています。詳解 システム・パフォーマンス 第2版作者:Brendan Greggオーム社Amazonさらに、日本語の読者にとっても、この書籍の日本語版が利用可能であることは大きな利点なので感謝しましょう。learning.oreilly.comEfficient GoSRE（Site Reliability Engineering）は、信頼性、スケーラビリティ、効率性を最大限に高めるために、システムとソフトウェアの設計、構築、運用に深く関与します。この分野で成功するためには、最新の技術トレンド、プログラミング言語、システム管理のベストプラクティスを継続的に学ぶことが不可欠です。今回紹介する書籍は、技術スタックが微妙に違ったとしてもSREが直面する多様な課題に対応するのに役立つ知識とスキルを提供します。「Efficient Go」は、O'Reilly Media, Inc.から2022年11月に出版された502ページの書籍で、技術の進歩、急速な市場の変化、およびシステムの複雑化に伴い、しばしば避けがちなソフトウェア効率の問題に対処します。戦術的で可観測性に基づくパフォーマンスの最適化は、コスト削減とビジネス成功のためにすべての製品に不可欠です。著者のBartłomiej Płotkaは、システムを高速化し、リソースを少なく消費するために必要なツールと知識を提供し、Go言語を使用して日常的な効率性を向上させる方法をガイドします。また、この書籍は、効率性の目標を明確にし、最適化する方法、CPUやメモリなどの共通リソースを効果的に使用する方法、そして効率性を評価するためのメトリクス、ログ、トレース、(継続的な)プロファイリングを通じて、Prometheus、Jaeger、Parcaなどのオープンソースプロジェクトを使用する方法を含めています。また、Go言語のスライス、ジェネリクス、ゴルーチン、割り当てセマンティクス、ガベージコレクションなどの機能を効率的に使用する方法についても詳しく解説されています。learning.oreilly.com日本語の読者には嬉しいニュースがあります。これらの書籍は、日本語版も入手可能で、日本語話者が内容をより容易に理解し活用できるようになっています。効率的なGo ―データ指向によるGoアプリケーションの性能最適化作者:Bartłomiej Płotkaオーム社Amazon「Cloud Native Go, 2nd Edition」は、O'Reilly Media, Inc.から2024年10月に出版される520ページの書籍で、Go開発者がクラウドネイティブなアプリケーションの構成と構築を、低レベルのGo機能から中間レベルのパターン、高レベルのアーキテクチャの考慮事項に至るまで探求する内容が含まれています。初版もとても良い書籍だったので紹介しておきます。本書では、中級から上級の開発者がGoを使用して簡単だが完全に機能する分散型キーバリューストアを構築する方法を段階的に説明し、Goのジェネリクス、信頼性と可用性、メモリリーク、メッセージ指向ミドルウェアについて学ぶことができます。さらに、セキュリティと分散状態に関する新しい章は、安全な分散型クラウドネイティブアプリケーションを開発する上での重要な側面に焦点を当てています。この書籍を通じて、クラウドネイティブソフトウェアを構築するのに理想的な言語としてのGoの機能を理解し、スケーラブルな分散サービスを設計する際の課題の解決方法、チャネルやゴルーチンなどGoの低レベル機能を活用した信頼性の高いクラウドネイティブサービスの設計と実装、複雑な分散システムの効果的な構築と管理のためのパターン、抽象化、ツールの適用、およびGoを使用してクラウドネイティブサービスを構築し管理する際の障害の克服方法を学ぶことができます。learning.oreilly.com「Mastering Linux Shell Scripting」は、Packt Publishingから2018年4月に出版された284ページの書籍で、Bashシェルスクリプティングの複雑さをマスターし、企業でのシェルの力を解き放つための知識を提供します。この書籍は、Linux管理者やシステム管理者を対象にしており、日常のタスクを自動化し、時間と労力を節約したい方々に最適です。基本的なシェルスクリプティングとコマンドラインの経験が必要で、自動化したいタスクに精通していることが役立ちます。本書では、最初のBashスクリプトの作成、実行、デバッグ方法やユーザー入力を求めるインタラクティブなスクリプトの作成方法、複雑なウェブ設定ファイルを動的に編集するスクリプトの開発、AWKを使用したログファイルの検索と報告、関数をビルディングブロックとして使用する効果的なスクリプトの作成方法など、シェルスクリプティングのさまざまな側面を学ぶことができます。さらに、PythonなどBASHと異なるスクリプト言語の比較による情報に基づいた選択方法も提供されています。learning.oreilly.comこの本も日本語の書籍が必要があります。嬉しいですね。マスタリングLinuxシェルスクリプト 第2版 ―Linuxコマンド、bashスクリプト、シェルプログラミング実践入門作者:Mokhtar Ebrahim,Andrew Mallettオライリー・ジャパンAmazonImplementing Service Level Objectives「Implementing Service Level Objectives」は、サービスレベル目標（SLO）の専門家であるAlex Hidalgoによる402ページの詳細なガイドです。この書籍では、SLO文化をゼロから構築する方法について、実践的なアドバイスと詳細な分析を提供しています。読者は、ユーザーの視点からサービスの信頼性を意味深く測定するサービスレベル指標（SLI）を定義する方法、統計的・確率的分析を用いた適切なSLOターゲットの選択、エラーバジェットの利用、SLOに基づくアプローチに必要なツールとリソースの構築、そして組織のリーダーシップやユーザーに対してSLOデータを用いた意味のある報告をする方法を学びます。この書籍は、SLOベースの信頼性アプローチに取り組む組織の文化とツール作成に関心のあるすべての人にとって、理想的な入門書であるとおもいます。learning.oreilly.comさらに、日本語の読者にとっても、この書籍の日本語版が利用可能であることは大きな利点なので感謝しましょう。SLO サービスレベル目標 ―SLI、SLO、エラーバジェット導入の実践ガイド作者:Alex Hidalgoオーム社AmazonModern Software Engineering: Doing What Works to Build Better Software Faster「Modern Software Engineering: Doing What Works to Build Better Software Faster」は、連続的デリバリーの先駆者であるDavid Farleyによって書かれた、効果的なソフトウェア開発の本質を探求する256ページの書籍です。この本では、プログラマー、マネージャー、テックリードを対象に、ソフトウェア開発における「学習と探索」と「複雑性の管理」という二つの主要なテーマに注目し、マインドセットからコードの品質までを改善するための原則を提案しています。Farleyは、目指すべき目標の明確化、合理的な基準に基づくツールの選択、継続的な段階的進歩を促進するための作業とシステムの組織化、繁栄するシステムへの進行状況の評価など、多岐にわたるテーマを取り上げています。さらに、実験と経験主義からの学習、システムの複雑化に対する制御、厳格さと柔軟性のバランス、歴史と経験からの学び、良いソフトウェア開発アイデアと悪いものの区別など、具体的なアプローチを提供しています。この書籍は、より良いソフトウェアをより迅速に、そして楽しみながら作成するための実践的な洞察をソフトウェアプロフェッショナルに提供します。learning.oreilly.com日本語訳があるので喜んで呼びましょう！嬉しいですね！継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣作者:David Farley日経BPAmazon「Grokking Continuous Delivery」は、GoogleのエンジニアChristie Wilsonによって書かれた424ページに及ぶ書籍で、ソフトウェアのデリバリープロセスの自動化を解説しています。本書では、新規および既存プロジェクトのための効果的な連続デリバリー（CD）パイプラインの設計、ソフトウェアプロジェクトをリリース準備完了状態に保つ方法、効果的なテストの維持、複数アプリケーションにわたるCDのスケール化、パイプラインが適切なタイミングで正しいシグナルを提供することの確保、バージョンコントロールを信頼の原点として使用、そしてメトリクスを用いたデプロイメントの安全な自動化に焦点を当てています。この書籍は、CDパイプラインの設定と運用に関する実践的なガイドとして、ツールに依存しないアプローチを採用し、イラストや明快な説明、実践的な演習を通じてCDの設計と目的を解説しています。開発者やパイプラインデザイナーに向けたこの書籍は、CDを開発プロセスに追加したいソフトウェアエンジニアにとって理想的なリソースです。learning.oreilly.comLearning Test-Driven Development「Learning Test-Driven Development」は、277ページに及ぶSaleem Siddiqui著の書籍で、テスト駆動開発（TDD）をGo、JavaScript、Pythonの3つの言語で使用する方法を解説しています。この書籍は、コードがクリーンでエレガントであり、長期間にわたって機能し続けるためのTDDの活用方法を提供します。主な焦点は、ドメインの複雑さをユニットテスト駆動のアプローチで制御する方法、言語やテストフレームワーク、ドメイン概念を超えたTDDの機能、TDDが連続インテグレーションを可能にする方法、リファクタリングと再設計をTDDでサポートする方法にあります。加えて、JavaScriptでのシンプルかつ効果的なユニットテストハーネスの書き方、TDD中に生成されたユニットテストを用いた連続インテグレーション環境の設定についても学ぶことができます。この書籍は、Go、JavaScript、Pythonを使用してTDDを実践し、クリーンで整理されたコードを書くための実用的なガイドとなっています。learning.oreilly.com『Beyond Legacy Code』（邦題：レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス）は、レガシーコードとウォーターフォールモデルの問題点、アジャイルの導入と技術的卓越性の追求、小さなバッチでの開発の利点、協力し合う文化の重要性、テストファーストのアプローチとテスト駆動開発（TDD）の役割、設計を最後に行う創発的なアプローチ、レガシーコードのリファクタリング手法など、ソフトウェア開発における重要な9つのプラクティスを詳細に説明しています。この本は、ソフトウェア開発の現場で直面する問題に対処し、高品質なコードの作成を目指す開発者にとって貴重なガイドとなります。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon『Test Driven Development: By Example』は、テスト駆動開発（TDD）の導入によって、アプリケーション開発における恐怖を取り除くことを目指しています。著者Kent Beckは、TDDを通じてプログラマーが恐怖を克服し、より良いコミュニケーションと建設的な批判の受け入れを学ぶことができると考えています。TDDは、コードを継続的にテストしリファクタリングすることを基本としており、プログラマーが質の高い作業を行うための実践的な例を示しています。また、日本語版『テスト駆動開発』の翻訳者であるt_wadaさんのアカウントも非常に有益な情報源ですので、フォローすることをお勧めします。レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス作者:David Scott Bernsteinオライリー・ジャパンAmazonさらに、Kent Beckが最近書いた『Tidy First?』もオススメです。この本では、大規模なリファクタリングや作り直しではなくて雑然としたコードの「整頓」、すなわち読みやすくするためにコードを管理しやすいセクションに分割する方法について具体的なガイダンスを提供します。また、ソフトウェア設計の基本理論についての洞察も含まれており、いつどのようにコードを「整頓」するかについての実践的なアプローチが提案されています。プログラミング経験の向上や、大きな変更を小さく安全なステップで行う方法などについても掘り下げられています。learning.oreilly.com『Infrastructure as Code, 3rd Edition』は、Kief Morrisによって書かれた包括的な書籍で、Infrastructure as Code（IaC）の進化と主流化を背景にしています。この第三版では、組織の戦略的目標と課題をサポートするためのインフラストラクチャの設計と実装に焦点を当て、持続可能な成長のための成熟した基盤の構築の必要性を強調しています。本書では、宣言的および手続き的インフラストラクチャ言語の探求や、インフラストラクチャコードがプラットフォーム戦略とエンタープライズアーキテクチャにどう適合するか、そしてインフラストラクチャコードのテストと提供方法について探求しています。また、ソフトウェア設計とエンジニアリングからの教訓を活用して、成長を促進しつつ変化するニーズに適応できるようにインフラストラクチャコードベースを構築する方法についても解説されています。さらに、物理ハードウェアから仮想サーバー、クラウドネイティブクラスター、サーバーレスワークロードまで、現実世界のITシステムの複雑な風景をサポートするインフラストラクチャのパターンに焦点を当てています。この書籍は、自動化とクラウドを組み合わせ、アジャイルやDevOpsなどの先進的なアプローチを活用して、コンプライアンス、コスト、セキュリティ、運用品質の厳格なガバナンスを実現するワークフローと運用モデルについても紹介しており、テスト駆動開発（TDD） の観点からも、インフラストラクチャコードの品質と保守性を向上させるための重要な概念と実践を含んでいます。learning.oreilly.comシステム障害対応 実践ガイド『3カ月で改善！システム障害対応 実践ガイド』は、システム障害対応とプロセス改善の実践的なアプローチを提供する画期的な本です。著者の野村浩司氏と松浦修治氏は、それぞれNTTデータとリクルートでの豊富な経験を基に、実際の業務に即した方法を提供しています。本書の大きな特徴は、障害対応の具体的な手法を「メソッド化」している点です。理論だけでなく、「どうすればいいのか？」という実践的な問いに答えており、情報システム担当者や運用リーダーにとって最適な内容となっています。また、本書は障害対応の本質的価値にも触れています。障害対応の改善は、顧客満足度、従業員満足度、そして財務観点からもプラスの効果をもたらします。この点を丁寧に説明しており、運用担当者のモチベーション向上にも寄与する内容です。大規模な障害対応経験がない方でも、対応のイメージがつかめるように工夫されています。障害対応の難所にも言及し、読者が共感しやすい内容となっています。システム障害が起こりうるすべての現場の人々に推奨されるこの本は、システム障害対応をどのように捉え、判断し、対応するべきかについてのフローや表を豊富に掲載しています。これらは特にシステム障害マニュアルが整備されていないチームにとって非常に有用です。1000件以上の事例を分析し生み出されたこのメソッドは、障害対応改善のための役立つ雛形と共に、3カ月での改善を可能にします。インシデント分析から障害訓練まで、各プロセスに役立つ情報が満載です。システム障害対応における課題の特定から改善ステップまで、具体的なガイダンスを提供し、障害対応を改善するための実践的な指針を提供します。3カ月で改善！システム障害対応 実践ガイド インシデントの洗い出しから障害訓練まで、開発チームとユーザー企業の「協同」で現場を変える作者:野村 浩司,松浦 修治翔泳社AmazonWebエンジニアのための監視システム実装ガイドPractical Monitoringでも言及しましたし、ここまで読んでいるWebエンジニアにとって、システムの監視は不可欠なのは自明です。どれだけ高度な技術で構築されても、システムは放置すると壊れたり、理解しがたい状態に陥ることがあります。「Webエンジニアのための監視システム実装ガイド」は、監視テクノロジの動向から組織での実装まで、現場目線で解説する実用書です。最新ツールの説明から実装パターンの紹介、組織での実装に向けた態勢づくりまで、監視に必要な情報が網羅されています。本書は、監視システムの設計から導入、運用に至るまでの全てを包括的に理解するのに役立ちます。特にインシデント対応の実践的な知識や心構え、監視システムのアーキテクチャ例には注目です。また、MSPでの経験から得られた貴重なノウハウが詰まっており、既存の監視システムの知識を現代的なものにアップデートしたい方にも最適でタイパが最高に良い書籍です。Webエンジニアのための監視システム実装ガイド (Compass Booksシリーズ)作者:馬場 俊彰マイナビ出版AmazonSRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本この書籍は、SRE（サイトリライアビリティエンジニアリング）の概念を分かりやすく説明しています。特にGoogleの事例を中心に、どのようにして大規模なサービスを安全かつ迅速にリリースし続けるかを示しています。SREがGoogle独自の手法ではなく、広くクラウドを利用する企業やエンジニアにとっても役立つ内容である点が強調されています。本書は、DevOpsを担当する方々、アプリケーション開発者、さらにはプログラミング未経験者にもSREという考え方を理解しやすくしています。その結果、「ざっくりなんとなくわかる」ような浅い理解を超えて、「すっきり」した理解を得ることができ、タイパを求める読者にとっては「最高」の参考書となります。SRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本: Googleが実践している新DevOps方法論作者:GGtop.jpAmazonさいごに情報技術の世界は日々進化しており、特にSRE分野では新たな知識と技術の習得が不可欠です。当ブログではSREにおける効率的な学習（タイパ）に役立つ書籍を多数紹介してきました。これらの資料が、読者の皆様のSREに対する理解の深化と実務能力の向上に貢献することを願っています。さらに、紹介した本にとどまらず、他にも多くの優れた書籍が存在しますので、是非探求してみてください。また、優先順位をどうしてもつけてほしいという人がいる場合はDevOps Roadmapがある参考にするといいと思います。私が所属する株式会社スリーシェイクでは、好奇心が強く手が動くエンジニアを求めています。私たちはSRE分野における多岐にわたる支援を提供しており、興味のある方は是非お問い合わせください。詳細は公式サイトでご覧いただけます。来年は当ブログでDevOpsやPlatform Engineeringの分野に焦点を当てる予定です。これらの分野は技術進歩が著しく、常に新しいアプローチやベストプラクティスが登場しています。それらをいかに実務に応用するかについて、深く掘り下げていきたいと考えています。私は「現場がさき、プラクティスがあと、原則をだいじに」という考え方を重視しており、適切な専門性と多様な事例に基づく知見を持ちながらも、業界全体での普及が十分でない現状があります。このため、時には根拠の不十分な「最強のDevOps」や「SREに外側だけ準じた独自のアプローチ」のような概念が生まれがちです。これは業界における深い理解と適切なプラクティスの普及に向けた取り組みが必要であることを示しています。このブログを読んでくださった皆様に心から感謝いたします。私たちは、SREの世界での成長と発展を目指し、皆様と一緒に学び続けることを楽しみにしています。ブログの購読をお願いすることで、私たちのモチベーションにも繋がります。次回の更新を楽しみにしていてください！2025年版はフォームも用意しているのでご確認お願いします。docs.google.com","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/26/165255","isoDate":"2024-01-26T07:52:55.000Z","dateMiliSeconds":1706255575000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SQLBoilerによるPostgreSQLの操作についての話","contentSnippet":"はじめにデータベースは、現代のアプリケーション開発において不可欠な要素です。特にリレーショナルデータベースは、その整合性と信頼性から幅広い用途で使用されています。しかし、リレーショナルデータベースを効率的に操作するためには、複雑なSQLクエリを記述し、アプリケーションのコードとデータベースのスキーマを適切に統合する必要があります。この作業は開発者にとって時間と労力を要するものです。この背景から、ORM（Object-Relational Mapping）ライブラリの利用が一般的になりました。ORMライブラリは、プログラミング言語のオブジェクトとデータベースレコードをマッピングし、SQLクエリの生成を抽象化して開発者がデータベース操作を容易に行えるようにサポートします。この記事では、Go言語でのデータベース操作を効率化するためのORMライブラリ「SQLBoiler」の活用方法について解説します。SQLBoilerは、Go言語に特化した強力なORMライブラリで、データベーススキーマに基づいてGoのコードを自動生成します。この自動生成機能により、開発者は煩雑なボイラープレートコードの記述を削減し、ビジネスロジックに集中できるようになります。本記事では、SQLBoilerの基本的な使用方法から生成されたコードの実際の利用方法までを段階的に紹介します。それでは、SQLBoilerを活用してGo言語でのデータベース操作を効率化する方法を見ていきましょう。ORM（Object-Relational Mapping）についてORMは、リレーショナルデータベースとプログラミング言語の間の橋渡しをする技術です。通常のデータベース操作に使用されるSQLとは異なり、ORMはプログラムのオブジェクト（今回のGoでは構造体）とデータベースレコードを自動で関連付け、SQL文の組み立てを可能にします。SQLBoilerの利点SQLBoilerはGo言語に特化した強力なORMライブラリで、データベーススキーマから直接Goのコードを生成します。この自動生成機能により、ボイラープレートコードの削減と開発効率の向上が図れます。ボイラープレートコードとはいくつかの異なるコンテキストでほとんどまたはまったく変更せずに再利用できるコンピュータ言語のテキストのことを指します。SQLBoilerの使用方法SQLBoilerを利用する際は、まずデータベーススキーマを定義します。以下は、著者、出版社、利用者、書籍、貸出記録を管理するスキーマの例です。-- 著者テーブルcreate table authors (  author_id serial primary key,  name varchar(100) not null);-- 出版社テーブルcreate table publishers (  publisher_id serial primary key,  name varchar(100) not null);-- 利用者テーブルcreate table users (  user_id serial primary key,  family_name varchar(100) not null,  given_name varchar(100) not null,  email_address varchar(254) not null,  registration_date date not null);-- メールアドレスに対するユニークキー制約（ユニークインデックス）create unique index idx_users_email_address on users(email_address);-- 書籍テーブルcreate table books (  book_id serial primary key,  title varchar(255) not null,  author_id integer not null,  publisher_id integer not null,  isbn varchar(20),  year_published integer);-- 貸出記録テーブルcreate table loans (  loan_id serial primary key,  book_id integer not null,  user_id integer not null,  loan_date date not null,  return_date date);-- 外部キー制約の追加alter table books add constraint fk_books_author_id foreign key (author_id) references authors(author_id);alter table books add constraint fk_books_publisher_id foreign key (publisher_id) references publishers(publisher_id);alter table loans add constraint fk_loans_book_id foreign key (book_id) references books(book_id);alter table loans add constraint fk_loans_user_id foreign key (user_id) references users(user_id);このスキーマをもとに、SQLBoilerはGoのモデル、クエリビルダー、CRUD操作を自動生成します。この自動生成により、開発者は細かなデータベース操作を手作業で行う必要がなく、ビジネスロジックに集中できます。環境構築Dockerを使用して、PostgreSQLのバージョン16を動作させる環境を構築します。以下のdocker-compose.yamlファイルを使用してPostgreSQLサーバーを立ち上げます。version: '3'services:  postgres:    container_name: postgres    image: postgres:16    restart: always    ports:      - \"5432:5432\"    environment:      POSTGRES_USER: \"postgres\"      POSTGRES_PASSWORD: \"postgres\"サンプルデータの投げ込みv01_insert.sql を作成します-- 著者テーブルにサンプルデータを挿入INSERT INTO authors (name) VALUES ('Sample Author 1');INSERT INTO authors (name) VALUES ('Sample Author 2');INSERT INTO authors (name) VALUES ('Sample Author 3');-- 出版社テーブルにサンプルデータを挿入INSERT INTO publishers (name) VALUES ('Sample Publisher 1');INSERT INTO publishers (name) VALUES ('Sample Publisher 2');INSERT INTO publishers (name) VALUES ('Sample Publisher 3');-- 利用者テーブルにサンプルデータを挿入INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Yamada', 'Taro', 'taro@example.com', '2021-01-01');INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Suzuki', 'Hanako', 'hanako@example.com', '2021-02-01');INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Tanaka', 'Ichiro', 'ichiro@example.com', '2021-03-01');-- 書籍テーブルにサンプルデータを挿入INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 1', 1, 1, '1234567890', 2021);INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 2', 2, 2, '0987654321', 2020);INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 3', 3, 3, '1122334455', 2022);-- 貸出記録テーブルにサンプルデータを挿入INSERT INTO loans (book_id, user_id, loan_date, return_date) VALUES (1, 1, '2022-01-01', '2022-01-15');INSERT INTO loans (book_id, user_id, loan_date, return_date) VALUES (2, 2, '2022-01-05', '2022-01-20');INSERT INTO loans (book_id, user_id, loan_date) VALUES (3, 3, '2022-01-10');投げ込み投げ込みpsql -h localhost -U postgres -d postgres -f v01_insert.sqlSQLBoilerのインストールSQLBoilerのインストール手順は以下の通りです。go install github.com/volatiletech/sqlboiler/v4@latestgo install github.com/volatiletech/sqlboiler/v4/drivers/sqlboiler-psql@latestPostgreSQL接続情報の設定（YAML形式）psql:  dbname: \"postgres\"  host: \"127.0.0.1\"  port: 5432  user: \"postgres\"  pass: \"postgres\"  sslmode: \"disable\"  whitelist:    - \"authors\"    - \"publishers\"    - \"users\"    - \"books\"    - \"loans\"whitelistにはコード生成の対象となるテーブルを明示的に指定します。この例では、著者、出版社、利用者、書籍、貸出記録の各テーブルを指定しています。SQLBoilerによるコード生成以下のコマンドを使うことで、SQLBoilerは指定されたデータベーススキーマに基づいてGoのモデルを生成します。sqlboiler psql -c config/database.yaml -o models --no-testsこのコマンドは、config/database.yamlに指定された設定を使用して、modelsディレクトリ内にモデルファイルを生成します。--no-testsオプションにより、テストファイルの生成をスキップします。生成されたファイル構成は以下の通りです。models/├── authors.go├── boil_queries.go├── boil_table_names.go├── boil_types.go├── boil_view_names.go├── books.go├── loans.go├── psql_upsert.go├── publishers.go└── users.go生成されたファイルの解説例として、books.goファイルの一部を見てみましょう。このファイルはデータベースのbooksテーブルに対応するGoの構造体と、それに関連する関数を定義しています。Book構造体type Book struct {    BookID        int         `boil:\"book_id\" json:\"book_id\" toml:\"book_id\" yaml:\"book_id\"`    Title         string      `boil:\"title\" json:\"title\" toml:\"title\" yaml:\"title\"`    AuthorID      int         `boil:\"author_id\" json:\"author_id\" toml:\"author_id\" yaml:\"author_id\"`    PublisherID   int         `boil:\"publisher_id\" json:\"publisher_id\" toml:\"publisher_id\" yaml:\"publisher_id\"`    Isbn          null.String `boil:\"isbn\" json:\"isbn,omitempty\" toml:\"isbn\" yaml:\"isbn,omitempty\"`    YearPublished null.Int    `boil:\"year_published\" json:\"year_published,omitempty\" toml:\"year_published\" yaml:\"year_published,omitempty\"`}Book構造体はbooksテーブルの各列をフィールドとして持ち、タグを用いてデータベースの列名とのマッピングを定義しています。SQLBoilerによるコード生成の詳細解説SQLBoilerによって生成されたモデルファイルは、リレーショナルデータベースと連携するための多様な機能を提供します。ここでは、具体的なコード例を使って、関連関数やリレーションシップ、フックについて解説します。生成されたファイルには、CRUD操作（作成、読み取り、更新、削除）を行うための関数も含まれています。例えば、Insert関数はBookオブジェクトをデータベースに挿入し、Update関数は既存のレコードを更新します。また、Delete関数はレコードを削除し、Reload関数はデータベースから最新の情報を再読み込みします。関連関数の例// Insert a single record using an executor.func (o *Book) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {    // ...関数の本体...}// Update uses an executor to update the Book.func (o *Book) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {    // ...関数の本体...}// Delete deletes a single Book record with an executor.func (o *Book) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {    // ...関数の本体...}// Reload refetches the object from the database.func (o *Book) Reload(ctx context.Context, exec boil.ContextExecutor) error {    // ...関数の本体...}これらの関数は、Bookオブジェクトを使用して、データベースに対する挿入、更新、削除、再読み込みの操作を行います。リレーションシップの例// Author pointed to by the foreign key.func (o *Book) Author(mods ...qm.QueryMod) authorQuery {    // ...関数の本体...}// Publisher pointed to by the foreign key.func (o *Book) Publisher(mods ...qm.QueryMod) publisherQuery {    // ...関数の本体...}これらの関数は、Bookオブジェクトが参照する外部キー（Author, Publisher）に基づいて、関連するデータを取得するためのクエリを作成します。SQLBoilerはテーブル間のリレーションシップを認識し、それに対応する関数も生成します。例えば、BookがAuthorとPublisherに関連している場合、それぞれのリレーションシップに対応するLoadAuthorやLoadPublisherなどの関数が生成されます。フックの例// AddBookHook registers your hook function for all future operations.func AddBookHook(hookPoint boil.HookPoint, bookHook BookHook) {    // ...関数の本体...}フックを使用すると、データベース操作の前後に特定の処理を実行できます。例えば、AddBookHook関数は、特定のタイミングで実行されるカスタムフックを登録します。SQLBoilerは各CRUD操作の前後に実行されるフック（Hook）もサポートしています。これにより、データベース操作の前後にカスタムロジックを実行することが可能です。SQLBoilerの応用と実践的な利用方法Go言語とSQLBoilerを使用して、リレーショナルデータベースでのデータ操作を行う方法を解説します。この記事では、実際のコードを使用して、SQLBoilerで生成されたモデルを利用してデータベースの書籍テーブルを操作する一連のプロセスを紹介します。主にSelect、Insert、Update、Upsert、Delete、Reloadといった基本的なデータベース操作をカバーし、Eager Loadingやデバッグ出力などの高度な機能についても触れます。以下のサンプルコードは、PostgreSQLデータベースに接続し、複数の異なる操作を実行するGoプログラムです。このプログラムでは、SQLBoilerで生成されたモデルを使用して、書籍の情報を取得、挿入、更新、アップサート、削除し、データベースの状態を再読み込みする操作を行います。package mainimport (    \"context\"    \"database/sql\"    \"fmt\"    \"log\"    _ \"github.com/lib/pq\"    \"github.com/nwiizo/workspace_2024/sqlboiler/models\" // 生成されたモデルのインポート    \"github.com/volatiletech/null/v8\"    \"github.com/volatiletech/sqlboiler/v4/boil\"    \"github.com/volatiletech/sqlboiler/v4/queries/qm\")func main() {    // データベース接続    db, err := sql.Open(        \"postgres\",        \"postgres://postgres:postgres@localhost/postgres?sslmode=disable\",    )    if err != nil {        log.Fatal(err)    }    defer db.Close()    ctx := context.Background()    // SELECT: 全ての書籍を取得    allBooks, err := models.Books().All(ctx, db)    if err != nil {        log.Fatal(err)    }    for _, book := range allBooks {        log.Printf(\"Book: %+v\\n\", book)    }    fmt.Println(\"Select: 高度なクエリでの書籍の取得\")    books, err := models.Books(        models.BookWhere.Title.EQ(\"Specific Title\"),        models.BookWhere.AuthorID.EQ(1),        qm.Limit(10),    ).All(ctx, db)    if err != nil {        log.Fatal(err)    }    for _, book := range books {        fmt.Println(\"Book:\", book.Title)    }    fmt.Println(\"Count: 書籍の数を数える\")    count, err := models.Books(models.BookWhere.Title.EQ(\"Specific Title\")).Count(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Count:\", count)    fmt.Println(\"Exists: 特定の条件に一致する書籍が存在するかを確認\")    exists, err := models.Books(models.BookWhere.Title.EQ(\"Specific Title\")).Exists(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Exists:\", exists)    fmt.Println(\"Insert: 書籍の挿入\")    newBook := \u0026models.Book{        Title:         \"New Book\",        AuthorID:      1,        PublisherID:   1,        Isbn:          null.StringFrom(\"1234567890\"),        YearPublished: null.IntFrom(2023),    }    err = newBook.Insert(ctx, db, boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Update: 書籍の更新\")    newBook.Title = \"Updated Title\"    _, err = newBook.Update(ctx, db, boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Upsert: 書籍のアップサート\")    upsertBook := \u0026models.Book{        BookID:        newBook.BookID,        Title:         \"Upserted Title\",        AuthorID:      2,        PublisherID:   2,        Isbn:          null.StringFrom(\"0987654321\"),        YearPublished: null.IntFrom(2024),    }    err = upsertBook.Upsert(ctx, db, true, []string{\"book_id\"}, boil.Infer(), boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Delete: 書籍の削除\")    _, err = newBook.Delete(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Reload: 書籍の再読み込み\")    err = newBook.Reload(ctx, db)    if err != nil {        if err == sql.ErrNoRows {            fmt.Println(\"Reload: 書籍が見つかりませんでした\")        } else {            log.Fatal(err)        }    }    // Eager Loading の例    // ユーザーと関連する書籍を取得    // user, err := models.FindUser(ctx, db, 1, qm.Load(\"Books\"))    // if err != nil {    //     log.Fatal(err)    // }    // for _, book := range user.R.Books {    //     fmt.Println(\"Book:\", book.Title)    // }    // デバッグ出力の例    // boil.DebugMode = true    // books, _ = models.Books().All(ctx, db)    // boil.DebugMode = false    // Raw Query の例    // _, err = queries.Raw(\"SELECT * FROM books WHERE title = 'New Book'\").QueryAll(ctx, db)    // if err != nil {    //     log.Fatal(err)    // }    // Hook の例    // func myBookHook(ctx context.Context, exec boil.ContextExecutor, book *models.Book) error {    //     fmt.Println(\"Book Hook Triggered\")    //     return nil    // }    // models.AddBookHook(boil.BeforeInsertHook, myBookHook)    // null パッケージの使用例    // newBook.Isbn = null.StringFromPtr(nil) // ISBN を null に設定}このプログラムでは、まずデータベースに接続し、全ての書籍を取得する操作から始まります。その後、特定の条件に一致する書籍の数を数えたり、特定の条件に一致する書籍が存在するかを確認したりする操作を行います。その後、新しい書籍をデータベースに挿入し、その書籍の情報を更新します。次に、アップサート操作を行い、特定の書籍を削除し、最終的には削除された書籍の情報を再読み込みします。このプロセスは、SQLBoilerを使ってGo言語でデータベース操作を行う際の典型的なフローを示しています。また、コメントアウトしていたコードに関しても一部は解説させてください。高度なクエリ構築SQLBoilerでは、qmパッケージを利用して複雑なクエリを組み立てることができます。例えば、特定の条件を満たす書籍を取得するために、以下のようなクエリを構築することが可能です。books, err := models.Books(    models.BookWhere.Title.EQ(\"Specific Title\"),    models.BookWhere.AuthorID.EQ(1),    qm.Limit(10),).All(ctx, db)if err != nil {    log.Fatal(err)}for _, book := range books {    fmt.Println(\"Book:\", book.Title)}このコードは、タイトルが\"Specific Title\"であり、かつ著者IDが1の書籍を最大10件まで取得します。Eager LoadingSQLBoilerを使うと、関連するレコードを事前にロードするEager Loadingも可能です。たとえば、あるユーザーに関連するすべての書籍を取得するには、以下のようにします。user, err := models.FindUser(ctx, db, 1, qm.Load(\"Books\"))if err != nil {    log.Fatal(err)}for _, book := range user.R.Books {    fmt.Println(\"Book:\", book.Title)}この例では、IDが1のユーザーに関連するすべての書籍を取得しています。デバッグ出力SQLBoilerを使用する際、boil.DebugModeを有効にすることで、実行されたSQLクエリを確認することができます。これはデバッグ時に非常に便利です。boil.DebugMode = truebooks, _ := models.Books().All(ctx, db)boil.DebugMode = falseRaw Queryの使用SQLBoilerでは、生のSQLクエリを直接実行することも可能です。これは特定のシナリオで必要となる複雑なクエリを実行する際に役立ちます。_, err = queries.Raw(\"SELECT * FROM books WHERE title = 'New Book'\").QueryAll(ctx, db)if err != nil {    log.Fatal(err)}このコードは、タイトルが'New Book'のすべての書籍を取得します。Hookの設定SQLBoilerでは、データベース操作の前後に実行されるHookを設定することができます。これはデータの整合性を保つための追加のロジックを実行する際に便利です。func myBookHook(ctx context.Context, exec boil.ContextExecutor, book *models.Book) error {    fmt.Println(\"Book Hook Triggered\")    return nil}models.AddBookHook(boil.BeforeInsertHook, myBookHook)この例では、書籍がデータベースに挿入される前に特定の処理を行うHookを設定しています。nullパッケージの活用SQLBoilerでは、nullパッケージを利用して、データベースのNULL値を扱うことができます。これにより、NULL許容のフィールドを安全に操作することが可能になります。newBook.Isbn = null.StringFromPtr(nil) // ISBNをNULLに設定newBook.YearPublished = null.IntFrom(2023) // 発行年を設定このコードでは、ISBNをNULLに設定し、発行年を2023に設定しています。まとめSQLBoilerは、Go言語でリレーショナルデータベースを効率的に操作するための強力なORM（Object-Relational Mapping）ライブラリです。データベーススキーマから直接Goのコードを生成し、開発者が細かなデータベース操作を手作業で行う負担を軽減します。SQLBoilerは、CRUD操作、リレーションシップの管理、フックの実装など、多様な機能を提供し、開発者がビジネスロジックに集中できる環境を整えます。この記事では、SQLBoilerの基本的な使用方法から、生成されたコードの実際の利用方法までを解説しました。まず、データベーススキーマの定義とSQLBoilerの環境設定を行い、サンプルデータの挿入を通じて実際のデータベース操作を準備しました。次に、SQLBoilerによって生成されたGoのモデルを利用して、Select、Insert、Update、Upsert、Delete、Reloadといった一連のデータベース操作を行うプロセスを紹介しました。これらの操作は、リレーショナルデータベースとGoプログラムの間のインタラクションを容易にし、開発プロセスを加速します。SQLBoilerは、Go言語でのデータベース操作を簡素化し、開発速度を向上させることが可能です。手動でのデータベース操作コードの記述が多い開発者にとって、SQLBoilerは大きな助けとなります。SQLBoilerの詳細や使い方については、SQLBoiler GitHubページを参照してください。［改訂3版］内部構造から学ぶPostgreSQL―設計・運用計画の鉄則 (Software Design plus)作者:上原 一樹,勝俣 智成,佐伯 昌樹,原田 登志技術評論社Amazon参考資料GitHub - d-tsuji/awesome-go-orms: ORMs for Go, most starred on GitHub.GitHub - avelino/awesome-go: A curated list of awesome Go frameworks, libraries and softwareGoのORMの人気ランキングを年ごとにまとめてみたGo言語 SQLBoilerでタイプセーフに複数条件のWhere句を書く #Go - QiitaGoのORM決定版 Genをはじめよう #Go - QiitaGoにおけるORMと、SQLBoiler入門マニュアル","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/23/161638","isoDate":"2024-01-23T07:16:38.000Z","dateMiliSeconds":1705994198000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"走馬灯のIaCは考えておいて","contentSnippet":"走馬灯のIaCは考えておいてというタイトルで登壇してきました\r\r技術的負債に向き合う Online Conference\rhttps://findy.connpass.com/event/297813/\r\r走馬灯のセトリは考えておいての短編はどれも面白いのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015282/\r\r登壇ブログ |『走馬灯のIaCは考えておいて』というタイトルで登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","link":"https://speakerdeck.com/nwiizo/zou-ma-deng-noiachakao-eteoite","isoDate":"2023-11-21T05:00:00.000Z","dateMiliSeconds":1700542800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとPlatform Engineerの交差点","contentSnippet":"Platform Engineering Meetup #5 #PFEM\rhttps://platformengineering.connpass.com/event/295048/ \r\rSREとPlatform Engineerの交差点: 2つの領域の交差と組織への適用 というタイトルで登壇します。\r\r登壇ブログ |『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました\rhttps://syu-m-5151.hatenablog.com/entry/2023/10/05/233555\r\rグレイラットの殺人 ワシントン・ポーが面白かったのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015569/","link":"https://speakerdeck.com/nwiizo/sretoplatform-engineernojiao-chai-dian","isoDate":"2023-10-05T04:00:00.000Z","dateMiliSeconds":1696478400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREからPlatform Engineerへの拡大","contentSnippet":"SREからPlatform Engineerへの拡大 というタイトルで登壇してきました\r\rCloud Operator Days Tokyo 2023 運用の新時代　〜Effortless Operation〜\rhttps://cloudopsdays.com/\r\rクラウドインフラ運用技術者のための年次イベント「Cloud Operator Days Tokyo 2023」の見所を紹介\rhttps://cloud.watch.impress.co.jp/docs/news/1518302.html\r\rSREからPlatform Engineerへの拡大 というタイトルで登壇しました - じゃあ、おうちで学べる  https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412 \r\r登壇しかないので20分しかないのでｷﾞｭｯとしてしまいました。","link":"https://speakerdeck.com/nwiizo/srekaraplatform-engineerhenokuo-da","isoDate":"2023-08-09T04:00:00.000Z","dateMiliSeconds":1691553600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について","contentSnippet":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析についてというタイトルで登壇しました\r\r2023年8月3日 CloudNative Days Fukuoka 2023\rhttps://event.cloudnativedays.jp/cndf2023\r\rk8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について\rhttps://event.cloudnativedays.jp/cndf2023/talks/1885\r\rK8sGPT Deep Dive というタイトルで登壇しました #CNDF - じゃあ、おうちで学べる  \rhttps://syu-m-5151.hatenablog.com/entry/2023/08/03/155326","link":"https://speakerdeck.com/nwiizo/k8sgpt-deep-dive-kuberneteskurasutanoaiqu-dong-xing-fen-xi-nituite","isoDate":"2023-08-03T04:00:00.000Z","dateMiliSeconds":1691035200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Cloud Native の作法","contentSnippet":"2023年7月13日 \r\r成熟度モデルを活用したCloud Nativeへの道筋 という副題で登壇します #開発生産性con_findy\rhttps://syu-m-5151.hatenablog.com/entry/2023/07/13/131433\r\r\r開発生産性Conference の登壇資料\rhttps://findy.connpass.com/event/283417/","link":"https://speakerdeck.com/nwiizo/cloud-native-nozuo-fa","isoDate":"2023-07-13T04:00:00.000Z","dateMiliSeconds":1689220800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2023年もSRE再考と叫びなさい‼️","contentSnippet":"2023年もSRE再考と叫びなさい‼️ SREの跡を求めず SREの求めたるところを求めよ というタイトルで登壇してきました\r\r2023年3月3日 エンジニア文化祭 2023\rhttps://forkwell.connpass.com/event/272596/\r\r『2023年もSRE再考と叫びなさい!!』というタイトルで登壇しました - じゃあ、おうちで学べる\rhttps://syu-m-5151.hatenablog.com/entry/2023/03/03/105049","link":"https://speakerdeck.com/nwiizo/2023nian-mosrezai-kao-tojiao-binasai","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"自由研究には向かないウェブオペレーション ","contentSnippet":"自由研究には向かないウェブオペレーション サイト運用管理を取り巻く環境の変化 Cloud Native時代に考えるLinux オペレーション というタイトルで登壇してきました。\r\r2023年2月18日\r【今更聞けない】Linuxのしくみ - Forkwell Library #16\rhttps://forkwell.connpass.com/event/273179/\r\rあとがき\r『自由研究には向かないウェブオペレーション』というタイトルで登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2023/02/18/201252","link":"https://speakerdeck.com/nwiizo/zi-you-yan-jiu-nihaxiang-kanaiuebuoperesiyon","isoDate":"2023-02-18T05:00:00.000Z","dateMiliSeconds":1676696400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" ポストモーテムはじめました","contentSnippet":"ポストモーテムはじめました - 良いポストモーテムを執筆するために必要な5つのポイント というタイトルで登壇してきました。\r\r2023年02月09日\rインシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT\rhttps://findy.connpass.com/event/273197/\r\r『ポストモーテムはじめました』というタイトルで登壇しました。 - じゃあ、おうちで学べる  \rhttps://syu-m-5151.hatenablog.com/entry/2023/02/09/113316","link":"https://speakerdeck.com/nwiizo/posutomotemuhazimemasita","isoDate":"2023-02-09T05:00:00.000Z","dateMiliSeconds":1675918800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"セキュア・バイ・デザインの鳴くところ","contentSnippet":"セキュア・バイ・デザインの鳴くところ\r安全なソフトウェアを全体から考えるみるで候\r\rOWASP Fukuoka Meeting #9\rhttps://owasp-kyushu.connpass.com/event/266585/\r\r副読ブログ\rhttps://syu-m-5151.hatenablog.com/entry/2022/12/07/204400","link":"https://speakerdeck.com/nwiizo/sekiyuabaidezainnoming-kutokoro","isoDate":"2022-12-07T05:00:00.000Z","dateMiliSeconds":1670389200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"cobra は便利になっている","contentSnippet":"2022年3-shake SRE Tech Talk #4\rhttps://3-shake.connpass.com/event/253028/","link":"https://speakerdeck.com/nwiizo/cobra-habian-li-ninatuteiru","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ProtocolBuffers/gRPCを安全に書き進めるためのエトセトラ","contentSnippet":"OWASP Fukuoka Meeting #6 \rhttps://owasp-kyushu.connpass.com/event/244388/ \r#owaspfukuoka","link":"https://speakerdeck.com/nwiizo/protocol-buffers-grpc-wo-an-quan-nishu-kijin-merutamefalseetosetora","isoDate":"2022-04-27T04:00:00.000Z","dateMiliSeconds":1651032000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"あるいはサイドカーでいっぱいの海","contentSnippet":"3-shake SRE Tech Talk #3 https://3-shake.connpass.com/event/241284/ #SRETT","link":"https://speakerdeck.com/nwiizo/aruihasaidokadeitupaifalsehai","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Dapr の概念と実装から学ぶObservability への招待","contentSnippet":"Observability Conference 2022 2022/03/11(Fri)\rDapr の概念と実装から学ぶObservability への招待\rhttps://event.cloudnativedays.jp/o11y2022/talks/1353","link":"https://speakerdeck.com/nwiizo/dapr-falsegai-nian-toshi-zhuang-karaxue-bu-observability-hefalsezhao-dai","isoDate":"2022-02-28T05:00:00.000Z","dateMiliSeconds":1646024400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"JJUGに向けて再変更/公演 CloudNativeな時代に求められるWebサービス基盤モデルの再考","contentSnippet":"JJUGナイトセミナー「Dapr特集」2/24(木) 開催\r\rhttps://www.java-users.jp/post/night202202/","link":"https://speakerdeck.com/nwiizo/gong-yan-cloudnativenashi-dai-niqiu-merareru-websabisuji-pan-moderufalsezai-kao","isoDate":"2022-02-24T05:00:00.000Z","dateMiliSeconds":1645678800000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"nwiizo"},"buildId":"Y2JlT7Opo5PUCh8eHSYgf","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>