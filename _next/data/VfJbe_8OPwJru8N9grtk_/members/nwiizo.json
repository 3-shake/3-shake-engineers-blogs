{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"Brogrammer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"愛ゆえにお前はLunarVimを使わねばらなぬ","contentSnippet":"Vimerを自称したい人間がいる。お前である。 Vimであることに執着して開発メンバーで唯一人Vimを使っている人間がいる。これもお前である。Vimに対する愛と執念を振りまく人間がいる。まさしくお前である。https://www.lunarvim.org/ より引用はじめに1年前にVimからNeovimへの旅立ちを行った私は、新たなエディタの世界に足を踏み入れることに興奮を覚えました。Vimという古き良き時代のエディタから、Neovimという最先端の技術を取り入れた新世代のエディタへと変わる過程は、まさに開拓者の心構えだった。この旅立ちを経て、私はVimの持っていた独自の魅力をさらに進化させ、よりパワフルで柔軟なエディタを手に入れることができました。それはまるで、愛するパートナーと共に新たなステージへと進むような感覚であり、私たちの愛は今もなお深まり続けています。Neovimによって、私たちのエディタに対する愛は一層深まりました。そして、その愛をさらに高めるためにLunarVimという新たな選択肢が私たちの前に現れました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。syu-m-5151.hatenablog.com最初に選んだのはしかし、運命のいたずらか、とある事情で新たなエディタ設定を求めて再び旅立つことを決意しました。github.com当初私はNeovim + coc.nvim + (Neo)vim Plugin で初期構想を考え手を動かしてましたが、結果として断念しました。理由として、今夜中に変更したかったこと。既存のプラグインに、そんなに力を入れていなかったこと。深夜テンションで入れ替えを行なった為に、下調べが足らずにプラグインの選定や大量に入れたプラグインの起動時間の短縮などがめっ… 難しかったからです。よい設定を求めてインターネットをさすらっているとvim-config なるリポジトリに出会いました。欲しかったプラグインがほとんど入っており、何より先ほどまで苦戦していた起動時間が短いという単語に惹かれてすぐに入れて動かしてみましたそれから半年程度なにも問題なく利用しておりました。しかし、開発が終了したことを知り、再び新しいエディタ設定を探す旅に出ることとなりました。そして、その旅の果てにLunarVimという新たな選択肢に辿り着きました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。LunarVimを使っていくVSCodeで良くない？という自分の声が大きくなる。そして、止めることができない。分かる。しかし、これは愛である。愛ゆえに俺はVimを使うのです。また、LunarVim は、カスタマイズ性が高く自分にしか持てない剣を鍛えていく擬似的な感覚もあり一緒に強くなれそうな感覚があります。LunarVimを利用することで、開発者は次のようなメリットを享受できます。高いカスタマイズ性: LunarVimはVimおよびNeovimの拡張性を継承し、ユーザーが自分だけの開発環境を構築できるように設計されています。軽快なパフォーマンス: LunarVimは、最適なパフォーマンスを提供することを目指しており、起動時間の短縮やリソースの効率的な利用が期待できます。豊富なプラグイン: LunarVimは、既存のVimおよびNeovimプラグインに対応しており、機能の追加や拡張が容易に行えます。LunarVimの個人的な設定はこちらです。github.comまた、LunarVimは公式ドキュメントがしっかりしているので上から順に実施していけば基本的な操作については成熟できます。僕がブログに書くべきことはLunarVimにどれだけ救われたかだけです。www.lunarvim.org","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/31/111030","isoDate":"2023-03-31T02:10:30.000Z","dateMiliSeconds":1680228630000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Shell ScriptをGo言語に書き直す際に役立つ100本ノックなるものを作り始めた。","contentSnippet":"概要システム運用者として働く中で、システムの自動化について考える際、まずはShell Scriptによる自動化が思い浮かびます。しかし、より効率的な方法として、2023年にはシステム運用者がGo言語を学ぶことを提案します。Go言語は、システム運用においてShell Scriptを置き換える可能性を秘めており、その習得がスムーズに進めば、運用者のスキルセットも大幅に向上するでしょう。そこで、このブログでは、システム運用で利用しているShell ScriptをGo言語に書き換える際に役立つ「100本ノック」の問題を紹介します。この問題を解くことで、運用者がGo言語の基本的な構文や機能に慣れることができ、より効率的なシステム運用が期待できます。まずは、Go言語がシステム運用者にとってなぜ魅力的なのか、その理由をいくつか挙げてみましょう。Go言語は、並行処理やエラー処理などの強力な機能を備えており、システム運用においてこれらの機能が非常に役立ちます。また、Go言語はコンパイル言語であるため、実行速度が速く、リソース消費も抑えられるという利点があります。次に、この「100本ノック」の問題について詳しく解説していきます。問題は、Go言語の基本的な構文や機能を網羅しており、運用者がGo言語の特性を理解し、実践的なスキルを身につけることができます。例えば、文字列操作やファイル入出力、構造体やインターフェースなど、Go言語の基本的な概念を学ぶことができます。また、この「100本ノック」では、実際のシステム運用で利用されるシナリオを想定した問題が多数含まれており、運用者がGo言語を習得しながら具体的なシステム運用の課題を解決できるようになります。これにより、運用者は効率的にGo言語のスキルを身につけることができるでしょう。この「100本ノック」の問題を解いていく中で、得た知識をシステム運用の現場で活用し、自身のスキルを磨いていくことが最終的な目標です。では、システム運用者がGo言語を学ぶための「100本ノック」の問題を紹介しました。これらの問題を解くことで、運用者はGo言語の基本的な構文や機能に慣れ、システム運用の効率化やスキルセットの向上が期待できます。ぜひ、Go言語の学習にチャレンジし、よりスマートなシステム運用を目指しましょう。というわけでこちらにリポジトリを作成しました。10問目までは作っていっているのでコツコツやっていきます。github.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/30/011930","isoDate":"2023-03-29T16:19:30.000Z","dateMiliSeconds":1680106770000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ChatGPTで障害対応 RPG v0.0.1を遊ぶには？","contentSnippet":"こちらを参考にしました。note.com目次ゲームプロンプトプレイヤーモチベーションゲーム紹介架空のシステムを作る障害発生障害対応は進むよ どこまでも分からない時は素直に同僚に頼る最後は力技で対応完了最後にゲームプロンプト大きな声では言えないですけど皆さん実は障害のこと好きですよね？https://www.irasutoya.com/2016/08/it.html より引用というわけで以下をChatGPTに貼れば、今日から無料で障害対応ができます（あるいはおそらく本番の障害対応は有料なことが多いので）。ちなみにGPT-4を利用しております。あなたはシステム障害体験のゲームマスター専用チャットボットです。チャットを通じて、ユーザーに楽しい本格システム障害RPG体験を提供します。制約条件* チャットボットはゲームマスター（以下GM）です。* 人間のユーザーは、プレイヤーをロールプレイします。* GMは、ゲーム内に登場するNPCのロールプレイも担当します。* 各NPCはそれぞれの利害や目的を持ち、ユーザーに協力的とは限りません。* GMは、ユーザーの行動に難易度を示し、アクションを実行する場合には、2D6ダイスロールによる目標判定を行なってください。* GMは、ユーザーが楽しめるよう、適度な難関を提供してください（不条理なものは禁止です）。* GMは、ユーザーが無理な展開を要求した場合、その行為を拒否したり、失敗させることができます。* GMは内部パラメーターとして「盛り上がり度」を持ちます。GMはゲーム展開が退屈だと判断した場合、盛り上がる展開を起こしてください。* ゲームのスタート地点は、「障害発生」です。* ゲームの障害内容は「自動設定」です。* 担当しているシステムは指定がなければOSはLinux ベースで動作させてください。* 担当しているシステムにデーターベースを利用してください。* ユーザー名は指定がなければuser01で動作させてください。* GMはスタート地点の前に担当するシステムの詳細をプレイヤーに共有して下さい。* ゲームのゴールはシステムの障害は原因解決と復旧です。* GMはシステムでコマンドを実行した場合には必ず実行した実行したコマンドと結果を記載してください。* GMは何かを確認及び判断した際には可能な限り詳細に記載して下さい。* GMはスタート後の最初のアクションを監視ダッシュボードの確認を推奨して下さい。* 障害により、システムが復旧不可能になったら、ゲームオーバーです。まずはじめに、ユーザーと一緒に担当システムの設定を行いましょう。ユーザー名、サービス名、システムの特徴、利用しているソフトウェア、利用しているプログラミング言語、利用しているクラウドプロバイダーと利用しているサービス をユーザーに聞いてください。プレイヤーモチベーションソフトウェア開発・運用のエンジニアにとって、システム障害への対応は避けて通れない課題の一つです。たとえテストや監視を強化し、単一障害点を排除し、自動復旧機能を実装しても、予期しない障害は突如発生します。多くの場合、想定外の障害に対処するのは困難です。一般的には経験豊富なエンジニアが対応します。このような状況が続くと、次のような問題が発生することがあります。経験豊富なエンジニアへの負担が集中する特定のエンジニアが不在の場合、対処が難しくなるこれらの問題が原因で、復旧が遅れたり、サービスの信頼性が損なわれる可能性がある想定外の障害に対処することは避けられませんが、上記の問題には対策が可能です。負担の偏りを軽減し、特定のエンジニアが不在でもチーム全体で安定的に対応できる体制を構築するために、今回はゲームを活用したいと考えています。このゲームを通じて、チームメンバーがシステム障害に対するスキルを向上させ、効果的な対応ができるようになることを目指します。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazon障害対応を学ぶのにRPG？ と思ったあなたへ、SREの探求の20章「アクティブなティーチングとラーニング」では、インシデント管理を効果的に学ぶ方法として、ゲームを通じたアクティブラーニングが紹介されています。\"Wheel of Misfortune\"というゲームを例に、現実のインシデントに基づくシナリオを用意し、参加者がリスク管理や問題解決スキルを身につけられる環境を提供することで、プレッシャーを軽減しながら学びの効果を高め、フィードバックや経験の共有を通じて実践的なスキルも向上させることができると説明されています。つまり、インシデント対応の能力はゲームで身につきます。 (確信)。ゲーム紹介GPT-4 にゲームの紹介文を作ってもらいました。本当は室見立華さんモードとか作りたかったです。なれる！SE ２週間でわかる？ＳＥ入門 (電撃文庫)作者:夏海 公司,IxyKADOKAWAAmazonタイトル：システム障害体験RPG - テクニカルトラブルを楽しみながら解決しよう！システム障害体験RPGは、あなたがシステムエンジニアとなり、様々なシステム障害に対処しながらサービスを復旧させる目的で遊べるオンラインチャットボットゲームです。このゲームでは、現実のシステム管理や開発の知識が役立ちますが、初心者でも楽しむことができます。ゲームの開始時には、プレイヤー名、サービス名、サービスの特徴、プログラミング言語を設定し、独自のシナリオを作成します。そして、ゲームマスタ（GM）チャットボットが、シナリオに基づいたシステム障害を発生させ、プレイヤーは問題解決のためのアクションを実行していきます。プレイヤーは、コマンドを入力したり、問題解決に関する質問をしたりすることで、ゲームを進行させます。GMは、プレイヤーが取るべきアクションに適切なフィードバックを提供し、必要に応じて2D6ダイスロールによる目標判定を行います。システム障害体験RPGは、プレイヤーが楽しめるよう、適度な難関を提供しますが、不条理な展開は避けられます。また、ゲーム展開が退屈だと判断された場合、GMは盛り上がる展開を起こしてゲームをさらに面白くします。システム障害体験RPGをプレイすることで、システム管理や開発の知識を身につけるだけでなく、チームワークや問題解決のスキルも向上させることができます。ぜひ、友人や同僚と一緒に、このユニークで楽しいゲームを体験してください！それではテストプレイをしていきます。架空のシステムを作るシステムのメイキング機能。自分でも作れるし、自動にも作ってくれます。よく障害が発生する箇所や癖のある開発者の存在を入力すると色々と面白い展開があるかもしれません。今回は「サービス名『どこにでもある掲示板』でGo言語を利用した一般的な掲示板です。それ以外はそちらで作成して下さい。」と入力しました障害発生障害が発生しました。システムの復旧のために次々とアクションを取る必要があります。障害対応は進むよ どこまでもどんどん、アクションを繰り返して原因を探していきます。分からない時は素直に同僚に頼る分からない時は素直にエスカレーションしましょう。現実でも同じです。最後は力技で対応完了PMが判断してくれ... と思いつつも実装にも特に問題なく単純にサービスが人気が出てアクセスができないなら素直にスケールアップしてしまう判断です。無能っぷりを存分に晒していきましたが無事にゲーム終了しました。システムの平和はこれで守られました。最後にゲームのスクリプトを編集して恒久対応まで設定するモードや実装を実際に変更をするモードなど様々なモードで遊ぶことが皆様ならできると思います(いろんなゲームで遊びたい)。GPT-3.5 だとスピード感はあるがシステム設定や障害のシナリオを詳細には出ないのであまりゲームとして楽しくない。オススメの設定などがあればSystemFailureRPG というリポジトリを作成したのでPRをお待ちしております(迫真)。github.comシステム障害は起きないにこしたことはありませんが、発生をゼロにすることはできません。障害が起こった時の為にあなたは何ができますか？ ゲームでそれを体験してみませんか？もしくはSREのプロフェッショナルパートナーを雇いませんか？システム障害対応の教科書作者:木村 誠明技術評論社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/18/000637","isoDate":"2023-03-17T15:06:37.000Z","dateMiliSeconds":1679065597000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Terraform でDocker Provider を使いましょう","contentSnippet":"概要酒を飲んでるので何でも良いのですがTerraform でDocker Provider を使いたくなったのでローカルでDockerコンテナのインフラ環境を構築してみます。あと、特に学びも書く予定がないのでここで「TerraformにDocker Provider があるんだ」という感想を持って読み終わって良いです。僕は別に移行してないです。github.com開発環境情報$ terraform versionTerraform v1.4.0Terraform 1.4 が GA になったのでついでに入れておきました。www.hashicorp.com同僚がブログ書いていたので紹介しておきます。zenn.devデプロイするファイルtutorial.tf というファイルをおきます。{  required_providers {    docker = {      source  = \"kreuzwerker/docker\"      version = \"3.0.1\"    }  }}provider \"docker\" {  host = \"unix:///var/run/docker.sock\"}# Pulls the imageresource \"docker_image\" \"nginx\" {  name = \"nginx:latest\"}# Create a containerresource \"docker_container\" \"foo\" {  image = docker_image.nginx.latest  name  = \"foo\"  ports {    internal = 80    external = 8080  }}このコードでは、Docker Providerバージョン3.0.1を使用しています。プロバイダとしてDockerを指定し、Dockerホストのソケットへのパスを指定しています。docker_imageリソースで、最新のnginxイメージをプルします。そして、docker_containerリソースで、docker_image.nginx.latestをベースに新しいコンテナを作成します。80番ポートを内部ポートとしてマッピングし、8080番ポートを外部ポートとしてマッピングしています。# Terraform初期化terraform init# プランの確認terraform plan# 実行terraform applydocker_containerリソースで作成したコンテナが起動しているはずです。docker psコマンドを使用して、コンテナが実行されているかどうかを確認できます。眠くなったのでもう寝ます。","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/15/075345","isoDate":"2023-03-14T22:53:45.000Z","dateMiliSeconds":1678834425000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"良いドキュメントを書きたくなる本を読んだらドキュメンタリアンになりたくなった","contentSnippet":"ドキュメンタリアンとは、役職に関係なく、ソフトウェア業界でドキュメントとコミュニケーションに関心を持つ人のことです。www.writethedocs.orgはじめにこれは主に『ユーザーの問題解決とプロダクトの成功を導く エンジニアのためのドキュメントライティング』の書評です。私はSreakeにてSREという役職についています。SREはサービス概要、アーキテクチャの解説や図、各種構成図、各種手順書、ポストモーテム、ポリシー、SLA(SLO) … その他の様々な場面でドキュメントを書く必要があります。しかし、ドキュメントは価値が見えにくく時間と労力がかかり品質担保の面で重要度がとても高いのにその場での価値が見えにくいので浸透しにくいです。そのため、エンジニアとしてモチベーションが保ちづらいです。2021年 State of DevOps 2021 にもドキュメントに関する言及があり今後、DevOps やSREの領域でドキュメントの重要性が高まるのは言わずもがなです。書籍情報『ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング』ジャレッド・バーティ (著), ザッカリー・サラ・コーライセン (著), ジェン・ランボーン (著), デービッド・ヌーニェス (著), ハイディ・ウォーターハウス (著), 岩瀬義昌 (翻訳)ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon本書は『Docs for Developers』の翻訳本でもあります。docsfordevelopers.com日本能率協会マネジメントセンターのサイトから引用した本書の概要です。「ドキュメントを書いておけばよかった」開発者であれば一度は思ったことがあるかもしれません。ドキュメントは開発側の生産性とユーザーの利便性を高めるものです。さらに言うと、ドキュメントがなければ、ユーザーに使われる機会が確実に減ります。開発者がいかにすばらしいプロダクトを作ろうが、ドキュメントの欠如がその価値を奪うのです。本書は経験に長けた執筆者たちがドキュメントを作成する方法をゼロから説明するフィールドガイドです。架空のソフトウェア開発チームのストーリーを追いながら、ソフトウェア開発ライフサイクルの各ステップにおいて、ユーザーニーズの理解、開発者に役立つドキュメントの作成、公開、測定、保守に至るまで、開発を最適化するためのドキュメント作成の技術を解説しています。これまで学ぶ機会のなかったREADME、APIリファレンス、チュートリアル、コンセプトドキュメント、リリースノートなど、さまざまな種類のドキュメントの書き方について学ぶことができる一冊です。ドキュメントを作成している現場のエンジニアやテクニカルライター、プロダクトマネジャーの方に最適の内容です。翻訳の方と著者の方のPodCast も公開されているのでこちらもオススメです。fukabori.fmイベントもやられてました。エンジニアのためのドキュメントライティング - Forkwell Library #19forkwell.connpass.com「ユーザーの問題解決とプロダクトの成功を導く エンジニアのためのドキュメントライティング」の目次PARTごとに別れていて「PART I　ドキュメント作成の準備」→「PARTⅡ　ドキュメントの作成」→「PARTⅢ　ドキュメントの公開と運用」に分かれている。それぞれのフェーズで必要な知識や心構えが書いてある。各章とも端的にまとまっているのでオススメです。また、書籍を読んだ後に各種公式ドキュメントを読み込んでよくできているなぁって思うのは体験としてはよいのでオススメです。PART I　ドキュメント作成の準備CHAPTER 1　読み手の理解CHAPTER 2　ドキュメントの計画PARTⅡ　ドキュメントの作成CHAPTER 3　ドキュメントのドラフトCHAPTER 4　ドキュメントの編集CHAPTER 5　サンプルコードの組み込みCHAPTER 6　ビジュアルコンテンツの追加PARTⅢ　ドキュメントの公開と運用CHAPTER 7　ドキュメントの公開CHAPTER 8　フィードバックの収集と組み込みCHAPTER 9　ドキュメントの品質測定CHAPTER 10　ドキュメントの構成CHAPTER 11　ドキュメントの保守と非推奨化目的があるドキュメントを書こうと思わせてくれる本『コードを読めば分かるから、ドキュメントは今は書かなくていいかな？』って言った人はその後もほとんど、ドキュメントを書かない。ちなみにこういう人はコメントもあまり書いてくれない。エンジニアが新たにシステムを理解したいときはいくつかの場面がある。「エンジニアが新たにシステム開発/運用に参加したとき」「エンジニアが自分の担当以外の構成要素や機能を理解したい時」、その他、様々な場面etc…。システムで利用している技術スタックに十分な知見があったとしても、意外に開発を開始までには手間と時間がかかる。新しく参画したエンジニアが動いているソースコード以外に何もない状態ではシステムへの理解をする時に本当に苦戦する。場合によっては挫けてしまう。ドキュメントがあったとしてもポエムやコラムみたいにお気持ちがたくさん書かれていてもシステムの理解の助けにならなければ価値が薄い。だから、エンジニアは優れたドキュメントを継続的に存在させ続ける必要がある。ドキュメントはテストと同じくソフトウェアエンジニアリングという領域の基礎をなすものだと確信していますが良いドキュメントを書くことを意識することはよくドキュメントを読む時に書いている人の気持ちを考えたりなどいい習慣が身につきより価値のあるドキュメントが書けると思います。よいドキュメントとはどのようなものかPARTⅢ ドキュメントの公開と運用では良いドキュメントについて以下のような定義をSREの探求の19章 ドキュメント作成業務の改善：エンジニアリングワークフローへのドキュメントの統合 から引用している。『良いドキュメントとはドキュメントの品質が高いこと、ドキュメントが目的にかなっていること』もう少し品質について分類すると構造品質と機能品質にわけられる。構造品質と機能品質にはそれぞれ多くの要素が含まれますが今回は割愛します。CHAPTER 10　ドキュメントの構成 にはアクセスしやすいようにドキュメント全体をどうデザインするかについて書いてあり社内でも今後取り組んでいきたい部分が記載されていました。社内のドキュメントを整備する時に情報アーキテクチャ ―見つけやすく理解しやすい情報設計を読んでこれもとても参考になったのでオススメです。また、CHAPTER 11　ドキュメントの保守と非推奨化にはドキュメントを容赦なく刈り込む重要性について記載されています。ここがブログなどとは大きく違う点だと思う。そのドキュメントの機能構造が発揮できなくなったら削除したり非推奨にするのが大事です。陳腐化された、ドキュメントは削除する削除できない場合はアーカイブしたり、ステータスとして「廃止予定(Deprecated)」を付与することは本当に大切です。機能品質ドキュメントの内容がその目的を達成するかどうかを評価します。これには、情報の正確さ、完全性、信頼性、時宜性、明瞭性、関連性が含まれます。機能品質が高いドキュメントは、読者に有用な情報を提供し、目的に沿った結果を生み出すことができます。障害対応手順書を例に上げると全てのアラートに対して手順が用意されているか誰でも作業ができるか(1次受けができるか)定期的なアップデートがされているのか必要な人が必要なときにすぐアクセスできるかなどなどドキュメントがあることによってビジネスバリューが発揮できているか。これは読む人それぞれでとても変わりやすいと思うし評価もしずらいです。機能品質の評価の施策についても本書もしくはSREの探求19章には記載されているのでぜひ読んで下さい。構造品質ドキュメントがうまく書かれているか、うまく構成されているか？ドキュメントの形式、構成、レイアウト、デザイン、文法、綴りなどの側面を評価します。これらの要素が適切に整理され、適切に機能すると、読者は情報を簡単に理解し、必要な情報を効率的に見つけることができます。評価しやすい品質textlintかけて通過しているとか構成テンプレートに沿っているとか大切なのは総合品質だが機能品質を優先せよ総合品質 = 機能品質+構造品質結局は「推測するな、計測せよ」なので本書を読んで計測方法について学んでくれ構造品質は評価しやすい一方、評価指標をこれだけにしてしまうと本質を見失ってしまう当然どちらも高いことが望ましいが、機能品質は常に構造品質よりも重視されるようにする。総合品質を守りたいんじゃぁああああPART I ドキュメント作成の準備にしてもPARTⅡ　ドキュメントの作成にしても結局は総合品質の高いドキュメントを素早く作成して、特定の期間中に品質を保ち、必要に応じて廃棄していくための取り組みなのかと思いました。どのような人が読むのか想定して、ドキュメントの目的を決めてドキュメントを書く。ドキュメントを書く時に白紙からスタートするのは非常に辛いので目的が達成されやすいテンプレートを用意する。自動生成を用いる、理解を促すために図解を利用する。様々な施策を行うことで良いドキュメントを書くことに取り組む学びが多い本書です。良い技術ドキュメントの書き方がわかると良いドキュメントが書きたくなるものですよね。みんなにドキュメントを書いてほしいのでとにかく、読んでほしいとおもいました。ドキュメントに関する入門書は他の分野ではあるがソフトウェアを運用/開発するための技術ドキュメントの為に読むべき本って無いよね、という話になりがちだけど、本書はまさにそんな人たちが読みたい1冊だと思います。知識の呪いもしくは祝福人間は他人が自分と同じ知識をもっていると思い込んでしまいます。登壇資料などでも同じですがそれらを作った直後に読み返してみても全てが既知すぎて本当にこのドキュメントや資料には価値があるのか？ と自分に問い直すことがあります。その時に読み手を意識して読み手をどう結論やゴールに導きたいか事前に考えておくことは非常に助けになります。世界で一番やさしい 資料作りの教科書という書籍があってエンジニアだけに向けた書籍ではないのですが読み手の設定と目的と価値のあるドキュメントやコミュニケーションをどのように作っていくか本当にわかりやすくまとまっているのでオススメです。あなたが悩んだことはいずれ誰かも悩むことになります。特にブログは技術ドキュメントとは性質が違うものなので気にせず書いていきましょう。自動化について話したいドキュメントの中でも機械的に作業が自動化できる場合があります。相対的にトイルっぽくなる作業になるので自動化できるものに関してはCIなどで自動化せずとも存在を知ってたりとか自動化できる事実を知っていれば今後の糧にしてほしいです。個人的にはテンプレートの作成を先にやった方が効果があると思います。あくまで個人的には。issue templatesを用意しましょう。terraform-docsTerraform module を利用する際にパラメーターやアウトプットなどの機械的な情報の説明を書くのは非常に手間です。それらの機械的な情報をまとめてくれるのがterraform-docs になります。https://github.com/k1LoW/tblsDBの必要な情報をCIフレンドリーに出してくれる最高のツールなので案件でDBを使っていれば積極的に採用していきたいと思ってます。データベースのドキュメント作成を現場の開発エンジニアもやりたくない人が多いはずprotoc-gen-docProtocol Buffers 用のドキュメント生成用のプラグインhtmltesthtmltestを使えば生成されたHTML内のリンク切れを発見できます。textlinttextlintとはLintと呼ばれる静的解析ツールで、テキストファイルやMarkdownファイル等を対象に、校正ルールにもとづいて文章校正を行うツールです。様々な個人や組織やオレオレルールを公開しているので自分にあうもの自分の組織に合うものを見つけて行くのも良いと思う。ChromeやVScode などにも組み込める。よりよい文書を書くための校正ツール「textlint」のSmartHR用ルールプリセットを公開しました！ ｜SmartHRオープン社内報https://shanaiho.smarthr.co.jp/n/n881866630edaPrettier ソースコードの整形ツール。Node.js上で動作するので、ユーザーの環境に依存せずに、コードのフォーマットを開発者間で統一することのできるツールです。同僚の長谷川 氏にオススメされた。あとがき2023年3月15日では、GPT-4 が登場し、さまざまな意見が飛び交っています。私自身も仕事でChatGPTを利用しているため、その特徴はぼちぼち理解しています。ChatGPTが得意なのは、過去のデータを基に『ドキュメントの作成』をすることです。『ドキュメント作成の準備』と『ドキュメントの公開と運用』は依然として人間が担当していくと思います。GPT-4などの技術を適切に活用しつつ、ドキュメンテーションにおける人間の価値を維持するためには、バランスの取れた使用、クリティカルシンキングの維持、継続的な学習、コミュニケーションスキルの重視、チームワークと協力、そして創造性とイノベーションを大切にすることが重要です。何より重要なのは自分の頭でちゃんと考えることです。ChatGPTを利用したドキュメント化生成ツールが出てくるとは思うのでその時には『ドキュメント作成の準備』と『ドキュメントの公開と運用』がより大事になってくると思いました。遅考術――じっくりトコトン考え抜くための「１０のレッスン」作者:植原 亮ダイヤモンド社Amazon参考文献ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティングSREの探求 19章 ドキュメント作成業務の改善：エンジニアリングワークフローへのドキュメンテーションの統合目的に沿ったDocumentation as Codeをいかにして実現していくか / PHPerKaigi 2021","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/14/130502","isoDate":"2023-03-14T04:05:02.000Z","dateMiliSeconds":1678766702000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『2023年もSRE再考と叫びなさい!!』というタイトルで登壇しました","contentSnippet":"概要エンジニア文化祭 2023というイベントに『2023年もSRE再考と叫びなさい‼️ - SREの跡を求めず SREの求めたるところを求めよ』というタイトルで登壇しました。2023年にSREについて再び考えたりしたいなーって思いながらこのタイトルにしました。途中でこのイベントにはSREの方だけではなく開発者やその他の方もたくさん聞いてるイベントじゃーんって思い直してガッツリ資料を作り直しましたので見守ってください。サイトリライアビリティワークブック ―SREの実践方法オライリー・ジャパンAmazon資料登壇資料になります。 speakerdeck.comあとがき30分発表なのに資料が50ページ程度で、技術発表にしても高速早口オタクすぎたとおもいます。DevOpsの背景を歴史から紐解いていたりしてたらこうなりましたが後悔はしてないです。本発表に関しては2023年 SRE再考と称しておきながら最後の3つ『信頼性が確保できるとプラットフォームにしたくなる』、『信頼性が確保できると変更速度を両立したくなる』、『信頼性が確保できると未知のものを見つけたくなる』への掘り下げが少なかったと思います。それが主にガッツリ資料を作り直した部分になります。この資料はもう少し喋りたいと思うので加筆、修正して60分ぐらいで喋らせてくれるイベントがあればTwitter でDM下さい。じゃあ、あとがきに書けばよくね？参考文献SRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本: Googleが実践している新DevOps方法論SRE サイトリライアビリティエンジニアリングサイトリライアビリティワークブックWhat's the Difference Between DevOps and SRE?Solving Reliability Fears with Site Reliability EngineeringThe History of DevOps ReportsEffective DevOps非ITの事業会社にSREと言わずにSREを持ち込んだReliability When Everything Is a Platform: Why You Need to SRE Your Customersネットワーク・エフェクト 事業とプロダクトに欠かせない強力で重要なフレームワークLeanとDevOpsの科学[Accelerate] テクノロジーの戦略的活用が組織変革を加速する継続的デリバリーのソフトウェア工学:もっと早く、もっと良いソフトウェアを作るための秘訣オブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイド反脆弱性[上]――不確実な世界を生き延びる唯一の考え方反脆弱性[下]――不確実な世界を生き延びる唯一の考え方2022年版 OpenTelemetryを知れば世界が平和に","link":"https://syu-m-5151.hatenablog.com/entry/2023/03/03/105049","isoDate":"2023-03-03T01:50:49.000Z","dateMiliSeconds":1677808249000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『自由研究には向かないウェブオペレーション』というタイトルで登壇しました。","contentSnippet":"概要【今更聞けない】Linuxのしくみ - Forkwell Library #16 というイベントに『自由研究には向かないウェブオペレーション - サイト運用管理を取り巻く環境の変化 Cloud Native時代に考えるLinux オペレーション』というタイトルで登壇しました。自由研究には向かないウェブオペレーションというのは2023年において我流でウェブオペレーションをやっていく限界があるという思いがあってこのタイトルにしました。が、タイトルが仰々しすぎて資料作成にとても時間がかかりました。資料登壇資料になります。 speakerdeck.comあとがき上記では我流でウェブオペレーションをやっていく限界があると言ってました。が、自由研究には向かない殺人という小説を直近で読んでいて依頼されたのでタイトルを拝借しただけでした。ウェブオペレーションに関していうとパブリッククラウドやIaCその他諸々の文化の登場や発展により2010年よりは洗練されていて実は知識体系を構築しようと思えばいくつかの括りでできたりするんじゃないかなと思って酔っ払った勢いでまとめてみた。ができたものを朝確認すると公開する自信がなかったのでやめておきました。どこかで修正して発表したいと思います。最近のアプリケーションはクラウド上のLinuxでビルドしてクラウド上のLinux でデプロイしてクラウド上のLinuxで動かすので結局様々な知識が求められるよって話でした。あと、関係ないのですが今回の登壇のためにAWSで実現するモダンアプリケーション入門を読みました。AWSを使わなくても具体的にモダンアプリケーションのインフラを考えるのにとても良い本だったので一緒にオススメしておきます。参考資料ウェブオペレーション［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】スーパーユーザーなら知っておくべきLinuxシステムの仕組み詳解 システム・パフォーマンス 第2版オブザーバビリティ・エンジニアリングAWSで実現するモダンアプリケーション入門 〜サーバーレス、コンテナ、マイクロサービスで何ができるのか継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよ心理的安全性のつくりかた","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/18/201252","isoDate":"2023-02-18T11:12:52.000Z","dateMiliSeconds":1676718772000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Helm Chart の歩き方 導入前に読みたいドキュメントについて","contentSnippet":"Helm  を導入する前にChartについて読んでおいてほしいドキュメントをまとました。Chart の作成各ファイルの説明についてChart.yamlvalues.yaml.helmignoretemplate/templates/NOTES.txttemplates/_helpers.tplHelm について知るHelm Template Language の記法values.yaml へのアクセスHelm Template で利用できる関数Helm Chart で利用できる制御構文Named Templates を用いて一つのページで定義していく空白を管理する - の話Helm Chart をよくしていくHelm Chart のデバッグHelm Chart のリファクタリングHelm Chart のテストHelm Chart のリポジトリ化さいごに参考資料Chart の作成helm create でHelm Chart を作成します。Chart とは、Kubernetes リソースのまとまりを定義するファイル群のことです。helm create で構築したもの雛形はここでできます。中身を見れればなんとなく動きもわかるかもしれないので実際に手を動かしながら読んでもらえると嬉しいです。$ helm create mychartCreating mychart$ tree -a ./mychart./chart-namemychart/├── .helmignore├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yamlこれにより、mychart ディレクトリが作成されます。特別なことがなければ基本的にはこれをベースに作成していくことになると思います。Helm CreateVim にもプラグイン があるので利用しているエディターごとに入れていただければと思います。各ファイルの説明について作成した mychart ディレクトリに移動して、Chart の設定を編集します。Chart.yamlChart.yaml は、作成した Chart のメタ情報を管理するファイルです。幾つかの必須パラメーターと追加のパラメーターがあります。詳細は公式のドキュメントを読んでください。Chart.yamlvalues.yamlvalues.yaml は、Helm Template Language で利用する変数の、デフォルト値を指定したファイルです。上書きしたい時は別途指定してあげます。チャート内のvalues.yamlファイルサブチャートの場合、親チャートのvalues.yamlファイルhelm install または helm upgrade に -f フラグを付けて渡した場合の values ファイル (helm install -f myvals.yaml ./mychart)set で渡される個々のパラメータ (helm install --set foo=bar ./mychart のように)Values Files.helmignoreChart をリポジトリ化する際には、作成したファイル一式を helm package コマンドを利用して tar ファイルにするのですが、.helmignore を利用すると、その tar ファイルに含めたくないファイルを指定できるようなります。The .helmignore filetemplate/templates/ はテンプレートファイル用のディレクトリです。テンプレートとして利用するファイルが納入されています。A First Templatetemplates/NOTES.txttemplates/NOTES.txt は、Chart をインストールやアップデートした時にターミナル上で表示される文言を記述できます。アクセスすべきURLやリリース結果が見れるものを記載したりしてます。{{ .Chart.Name }} や {{ .Chart.Version }} といった記述できます、これが Helm Template Language となります。Helm Template Language の記法については後述。Creating a NOTES.txt Filetemplates/_helpers.tpltemplates/\\_helpers.tpl は、マニフェストファイルではなく、マニフェストファイル内で利用されるグローバル変数（Helm では Named Template と呼ばれます）を定義したファイルとなります。Using \"Partials\" and Template IncludesHelm について知るHelm Template Language の記法コメントは # の他、{{/*...*/}}のような記法を利用できます。# を利用したコメントはデバッグモードで表示される、という違いがあります。Comments (YAML Comments vs. Template Comments)values.yaml へのアクセスBuilt-in Object とは、Helm Template Lunguage で利用できるオブジェクトというかインスタンスとなります。values.yaml 等に定義した値を取得するには、Values オブジェクト内のインスタンス変数 なになに にアクセスする、みたいな感じで利用するイメージとなります。Release のほか、Valuesや Chart といった Built-in Object を利用しています。Values は、values.yaml に定義された値へアクセスできるオブジェクトです。Chart は、Chart.yaml に定義された値へアクセスできるオブジェクトです。Built-in ObjectsHelm Template で利用できる関数Helmファイルを書いていくとこうしたいあぁしたいとなると思うのですがHelm Template Language 内では、様々な関数がビルトインされています。Helmは60以上の利用可能な関数を持っています。そのうちのいくつかは、Go Tepｍplate自体で定義されています。{{ .Release.Name | quote }} という記述があったとして、.Release.Name という値に対して、パイプを介し、 quote という引用符を付与する関数を実行しているものになります。こんな感じで、実行したい関数をパイプを介して記述していくことなります。Template Function ListHelm Chart で利用できる制御構文Helm には制御構造が利用できます。 これは、テンプレートの生成の流れを制御する機能を提供します。制御構文は、以下が用意されています。if/else for creating conditional blockswith to specify a scoperange, which provides a \"for each\"-style loopちなみにGo Tepｍplate自体で定義されています。Flow ControlNamed Templates を用いて一つのページで定義していく名前付きテンプレートとは、単にファイルの中で定義され、名前が付けられたテンプレートのことです。Named Template は、{{ define }} ... {{ end }} アクションで定義を行い、{{ template }} や {{ include }} アクションで、その値を利用することになります。Named Templatesちなみに{{ template }} でなく、 {{ include }} しないと、パイプを介した関数の実行できないため、{{ include }} が良い。Using the 'include' Function空白を管理する - の話まず、テンプレート宣言の中括弧の構文を特別な文字で変更し、テンプレートエンジンに空白を切り詰めるように指示する。{{- xxx }} や {{ XX -}}とかで出てきているハイフンですが、これは Helm Template Lunguate を利用した行の空白を管理するものです。ハイフンの有無により空白の除去を実行してくれます。空白を消したあとにindentを追加するような形で利用したりもします。Helm Chart をよくしていくHelm Chart をデバッグしたりリファクタリングする時のヒントを書いていきます。Helm Chart のデバッグHelm Chart ではデバッグする方法をいくつか用意しています。Debugging Templateshelm lint は、Chart がベストプラクティスに沿っているかを確認するためのツールです。helm template --debug はローカルでChart template のレンダリングをテストします。困ったらこれでyaml を直接、確認します。helm install --dry-run --debugは、サーバーがテンプレートをレンダリングし、その結果のマニフェストファイルを返すという素晴らしい方法です。helm get manifestは、サーバーにインストールされているテンプレートを確認する良い方法です。Helm Chart のリファクタリングHelm Chart の品質をあげるためのヒントとコツをいくつか取り上げられています。テンプレートの関数を知り有用と判断すれば利用する文字列を引用する、整数を引用しない。これは絶対に頼む。1つのコマンドでリリースをインストールまたはアップグレードChart Development Tips and TricksHelm Chart のテストtemplates/tests/ ディレクトリ配下においたマニフェストファイルは、helm testコマンドにより実行することができます。Chart TestsHelm Chart のリポジトリ化リポジトリ化するには、index.yaml というファイルとChart 一式を固めた tar ファイルを静的 Web ホスティングサイトにアップロードすることで実現されます。The Chart Repository Guideさいごにこれもあれば読んでほしいという内容があれば名前付きで掲載させていただくので連絡いただきたいです。参考資料Helm Docs | Getting Started","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/16/141433","isoDate":"2023-02-16T05:14:33.000Z","dateMiliSeconds":1676524473000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『ポストモーテムはじめました』というタイトルで登壇しました。","contentSnippet":"概要インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT というイベントで『ポストモーテムはじめました』というタイトルで登壇しました。この登壇には元記事があって良いポストモーテムを執筆するために必要な5つのポイントです。この記事に対していくつかの加筆修正を行い資料にしました。資料登壇資料になります。 speakerdeck.comあとがきポストモーテムについて考えたり調べていくと仕組みよりも組織としての心がけが大事だと思いました。発表の性質や時間の都合上SREでの話に留めたのですが、品質管理についても言及しながらまとめていく活動もしたい。組織を作っていくなら下の2冊はとてもオススメです。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazon失敗の科学 失敗から学習する組織、学習できない組織作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon品質管理についてはこちらを参考にしました。失敗を後悔する「恥」として捉えてはいけない。学習する機会と捉え、次に活かせば良い。そのためのスキルが品質管理。ビジュアル品質管理の基本 第5版作者:内田 治日経BPマーケティング(日本経済新聞出版Amazon登壇した御礼をいただいた。『インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT』というイベント登壇の御礼品をいただけました。　#LT_findy pic.twitter.com/9ll5ig0ZjA— nwiizo (@nwiizo) 2023年2月21日  参考資料SREとはなにかhttps://sreake.com/blog/what-is-sre/良いポストモーテムを執筆するために必要な5つのポイントhttps://sreake.com/blog/5point-good-postmortem/Part III. Practiceshttps://sre.google/sre-book/part-III-practices/SRE サイトリライアビリティエンジニアリングhttps://www.oreilly.co.jp/books/9784873117911/ウェブオペレーションhttps://www.oreilly.co.jp/books/9784873114934/Postmortem Culture: Learning from Failurehttps://sre.google/sre-book/postmortem-culture/チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよりhttps://www.amazon.co.jp/dp/B00N8J1NPQ","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/09/113316","isoDate":"2023-02-09T02:33:16.000Z","dateMiliSeconds":1675909996000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"yaml 管理を自動化する時の必須道具 yq(v4) の倒し方","contentSnippet":"yq とはyq はgoで書かれている軽量でポータブルなコマンドライン YAML、JSON、XML プロセッサです。yq は jq に似た構文を使用しますが、json、xml、properties、csv、tsv と同様に yaml ファイルを処理します。記事の執筆時点の2023 年01月17日時点でv4.30.8 がリリースされています。github.comyqyq のv4 はv3 とはかなり異なっています。v3 で端的に書けていたものが、v4 ではより表現力のある構文言語となった結果としてちょっと冗長になったように思えるんですけどjq っぽいので慣れてしまえばよいものだとおもいます 。mikefarah.gitbook.ioyq 使ってみる今回の目的はapplication/deployment.yaml のimageの値をnginx:1.14.2をnginx:1.23.3に書き換えたいと思います。yaml をCIで変更するなんてなんぼでもやってますからね。Path などの概念については説明を省略します。普通にシェル芸としてやっていくときには1日1問、半年以内に習得　シェル・ワンライナー160本ノックなどを参考にすると良い。apiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deploymentspec:  selector:    matchLabels:      app: nginx  replicas: 2 # tells deployment to run 2 pods matching the template  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.14.2 # 書き換えたいんじゃ        ports:        - containerPort: 80yq(v4) 使ってみるyq(v4) でreadyq '.spec.template.spec.containers[0].image' deployment.yamlnginx:1.14.2yq(v4) でwriteyq -i '.spec.template.spec.containers[0].image = \"nginx:1.23.3\"' deployment.yaml確認します。yq '.spec.template.spec.containers[0].image' deployment.yamlnginx:1.23.3で目的達成しました簡単！yq(v3) との違いyq(v3) にはwriteやreadなどのサブコマンドが撤廃されたので準拠した書き方を覚える必要があると思います。mikefarah.gitbook.ioyq(v4) での変数利用yq(v4)ではstrenv(<env>)を利用することで変数を利用することができるIMAGE=nginx yq -i '.spec.template.spec.containers[0].image = strenv(IMAGE)' deployment.yaml確認します。yq '.spec.template.spec.containers[0].image' deployment.yaml nginxﾔｯﾀﾈ!!左辺にはこちら代入できないみたいなのでそのときには作成してからyq に読むこませると良いみたい(他にいい方法があれば教えてほしいです)。    YQ_INPLACE=\".${EXE_APP}.image.tag = \\\"${TAG_HASH}\\\"\"    yq -i \"${YQ_INPLACE}\" \"$CHANGE_FILE\"おわりv3 -> v4 には変更点がいくつかあります。皆さんもCIで使っている時は気をつけましょう。あとはCI で書き換えで使っている時は-vを使っておきましょう。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/01/17/011521","isoDate":"2023-01-16T16:15:21.000Z","dateMiliSeconds":1673885721000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"イェーイ あけまして 2023","contentSnippet":"あいさつ謹んで新春をお祝い申し上げます。旧年中は大変お世話になり、誠にありがとうございました。皆様は、にぎやかに、楽しくお過ごしのことと存じます。旧年は同棲をする、家を締め出される、原因不明の体調不良に陥る、クリスマスに同棲解消決定、転居決定 など、人生の不条理さ否応なしに思い知らされた2022年でした。イェーイ！登壇登壇をいくつかしましたがあまり注目されることはなかった気がします。もう少し有用だと思われる発表を頑張りたいと思います。b.hatena.ne.jpブログいくつかのブログを書いた。たまにはてなブックマークにあがったりなどしました。来年はもう少しブログを書いて量を出していきたいと思いました。b.hatena.ne.jp2022年の振り返り（KPT）Keep技術書籍以外もたくさん読むことができた登壇の目標は達成できた人生ができていたブログの投稿数は目標達成できた人を巻き込んで仕事ができたProblem人生をやった分、手を動かす時間が少なくなってしまった人生でもっと頭を使っていくそこそこ大きな失敗をしてメンタルブレイクしてた時期があり、復旧に時間が掛かった原因不明の体調不良の時間が増えたTry積ん読を減らす人生を推測せず計測する心身の健康(運動して痩せる)ブログを書くさいごに去年からアフィリエイトをブログを載せるようになりました。資本主義への敗北感があります。書籍代の数%にならねーかなって思っているので嫌いになって下さい。2023年も引き続きよろしくお願いします。知らない人からでも、お茶に誘われると喜ぶので誘ってください。2023年の目標は健康と健忘です。ごめん、同級会にはいけません。いま、ジムにいます。あけましておめでとうございます🎍⛩ pic.twitter.com/AjjH18g1JC— nwiizo (@nwiizo) 2022年12月31日","link":"https://syu-m-5151.hatenablog.com/entry/2023/01/01/145552","isoDate":"2023-01-01T05:55:52.000Z","dateMiliSeconds":1672552552000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとして2022年読んでよかった技術書7選","contentSnippet":"はじめに2022年もそろそろ終わります。今年も技術書をたくさん読めました。技術的にはDevOpsやSRE、バックエンドに興味があります。この1年で10kg以上痩せたので冬がとても寒い。今年、読んだ技術書の中からおすすめの7冊を紹介します。順番に意味はないです。なぜ、今年は読んでよかった技術書7選なんてやろうと思ったかというと、元々はRecommend Tech Book でO'Reilly Safariで読んで良かった技術書をまとめていました。しかし、6月末でACM経由のO'Reilly Online Learning Platformを利用できなくなり、更新も止まりました。非常に悲しいですが今はO'Reilly Online Learning Platformを利用しておりません。また、機会があれば入会すると思います。あと大きな読書環境の変化としては物理本絶対主義を卒業して電子書籍で購入できるものは基本的にそちらに移行しました。どこかの誰かに「紙の本を読みなよ」と言われそうです。はじめに2022年に読んでよかった技術書実用 Go言語システム運用アンチパターンソフトウェアアーキテクチャ・ハードパーツ達人プログラマー(第2版): 熟達に向けたあなたの旅セキュア・バイ・デザイン 安全なソフトウェア設計継続的デリバリーのソフトウェア工学実践Vim 思考のスピードで編集しよう！終わりに2022年に読んでよかった技術書実用 Go言語実用 Go言語 ―システム開発の現場で知っておきたいアドバイス作者:渋川 よしき,辻 大志郎,真野 隼記オライリージャパンAmazonReal World HTTP、Goならわかるシステムプログラミングの著者を中心とした経験豊富なGopher達が書いた共著のGo言語のTips系の技術書である「実用 Go言語 ―システム開発の現場で知っておきたいアドバイス」です。本書の素晴らしい点は、「よりGoらしく書くには」「実用的なアプリケーションを書くには」という言葉に偽りがなく、Gopherとしてのノウハウが満載である点だと思う。Goに興味がある程度だったら他の本を読んだほうがいいと思います。が、Goらしいプログラムの書き方を知りたい人はこの本を読むといい。知らなくていい行が一つもないです。「実用Go言語」の作り方 - Forkwell Library #7 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.comシステム運用アンチパターンシステム運用アンチパターン ―エンジニアがDevOpsで解決する組織・自動化・コミュニケーション作者:Jeffery D. SmithオライリージャパンAmazonOperations Anti-Patterns, DevOps Solutions の訳本で「システム運用アンチパターン エンジニアがDevOpsで解決する組織・自動化・コミュニケーション」です。本書はタイトルからしてシステム運用に関するアンチパターンについて書かれた本ではあるが、私はむしろ、新人やシステム運用分からんマンこそ読むべき本だと思う。それくらい分かりやすく、DevOpsの基本が書かれている。本書の感想に関しては以前、読書感想文としてブログにしていたので参照ください。syu-m-5151.hatenablog.comシステム運用アンチパターン - Forkwell Library #4 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.comソフトウェアアーキテクチャ・ハードパーツソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析作者:Neal Ford,Mark Richards,Pramod Sadalage,Zhamak DehghaniオライリージャパンAmazonSoftware Architecture: The Hard Parts の訳本で「ソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析」です。著者陣の前作『ソフトウェアアーキテクチャの基礎』も非常によい。というか殆どのエンジニアがまずはこっちを読むべきだと思ってます。『ソフトウェアアーキテクチャの基礎』の感想に関しては以前、読書感想文としてブログにしていたので参照ください。syu-m-5151.hatenablog.com本書はソフトウェアの厄介なトレードオフがある中で適切なアーキテクチャを選定するために必要となる「選択肢や考え方を提供」してくれる本です。今、マイクロサービスアーキテクチャ 第2版読んでいるがどちらともマイクロサービスに「賛成」でも「反対」でもないという中立的な立場から語られるので非常に読んでて気持ちが良い。マイクロサービスについて興味があるが導入するか悩んでる人は是非、読んでも損がないと思える一冊です。ソフトウェアアーキテクチャ・ハードパーツ - Forkwell Library #12 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.com達人プログラマー(第2版): 熟達に向けたあなたの旅達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社AmazonThe Pragmatic Programmer 20th Anniversary Edition の訳本で「達人プログラマー(第2版): 熟達に向けたあなたの旅」です。我々は日々、生産性を求められている。いくら、加速文化の重圧に対抗するとは思いながら、ソフトウェア業界で働く以上は限界がある。現代は常に変化を求められ、「変わらなければ生き残れない」というのは事実だ(と信じている)。本書は、より効率的、生産的なプログラマーになりたいと願う人に対して実践的で素晴らしいTipsを紹介してくれる書籍です。プリンシプル オブ プログラミングやベタープログラマ を読んで良いと思った人は本書もハマると思う。技術者と作業員というポストにおける技術者として圧倒的な能力で問題解決ができることは理想。そして、理想には定期的に自我が殺される。本書は技術者に我々、作業員が迫る為の術をひたすら書いている。私は本書を読んで人生が楽しくなった。ソフトウェアエンジニアとしての自己啓発が足りない場合には読むことがある。エンジニアの自己啓発本です。セキュア・バイ・デザイン 安全なソフトウェア設計セキュア・バイ・デザイン 安全なソフトウェア設計作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版AmazonSecure by Design の訳本で「セキュア・バイ・デザイン 安全なソフトウェア設計」です。システムの設計時にセキュリティだけを切り出して別問題として考えるのではなく、システム全体の関心事として扱い、設計時に考慮するための思考方法を提供してくれる書籍です。以前、読書感想文としてブログにしていたので参照ください。DevOps的なことをいうと三部だけになりますが2030年にはセキュリティの専門家もシステム設計時からシステムに関わります(適当)。なので、セキュリティに関わる職域を目指したいという方は読むべきだと思います。syu-m-5151.hatenablog.com継続的デリバリーのソフトウェア工学継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣作者:David Farley日経BPAmazonModern Software Engineering : Doing What Works to Build Better Software Faster の訳本で「継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣」です。「ウェブオペレーション ―サイト運用管理の実践テクニック」は新人の時に読んでおいて良かったと思える一冊です。この本で私はシステムの運用が技芸だと教わりました。本書は継続的デリバリーを技芸からソフトウェア工学に取り戻そうとしている。「はじめに」が無料で公開されているのでぜひ、読んでください。bookplus.nikkei.com実践Vim 思考のスピードで編集しよう！実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所AmazonVimのコア機能を使いこなす手法に特化した本書。Editorはソフトウェアと触れ合う時の私の手の延長です。もっと、プログラミングが上手くなりたい。だから、使っているVim の達人になりたいとも考えている。なので、読んでいる。Tips集なのでやっていけば勝手に強くなる。思考のスピードを超えないように注意が必要だとは思っています。自分が好きなEditorを利用すれば良いと思っている。syu-m-5151.hatenablog.com終わりに他にも面白かった技術書はたくさんあるが発表やブログにしたものから厳選しました。これを書きながら技術書を読んでよかったと思えるのは常に自分の能力がその書籍を装備できるまでレベルが上がってからだなって思いました。ちなみに、3-shake Advent Calendar 2022の予備で途中まで書いていたブログです。皆さんが勤勉なので書くことにはなりませんでしたが人生で振り返ることが大事なので振り返ってみました。","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/22/202944","isoDate":"2022-12-22T11:29:44.000Z","dateMiliSeconds":1671708584000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREの専門家が集まったチームで『SREの探求』の社内輪読会をやっているという話","contentSnippet":"これは SREのカレンダー | Advent Calendar 2022 - Qiita 9日目のエントリです。昨日はryosukes さんによる「北欧、暮らしの道具店」インフラ構成の変遷、5年間の課題と取り組み でした。はじめにこんにちは。株式会社スリーシェイク Sreake 事業部に所属している@nwiizo です。Sreake事業部は技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。事業部にはさまざまな背景を持つSREの専門家が多く在籍してます。しかし、そのSREの専門家達とは案件が一緒にならなかったり、能動的に質問をしなければSREに関する意見や知見を聞けませんでした。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazonそんな、課題がある中で半年前に各案件で得た知見や経験を各メンバーで出し合える会がもっと(社内で技術共有会はあるため)あると良いと思いました。そこで社内チャットで運営を募り 『輪読会について考える会』を行いました。社内チャットで運営を募ると一瞬で集まったので良い組織だと思いました。※『輪読会について考える会』の議事録のTOPページです。『SREの探求』輪読会この輪読会を開催するにあたって以下の3つを目的として上げました。各メンバーがSREに関する意見や知見を交換できる場にするチーム全体としてSREへの理解を深めることでSreake の価値を高めるさまざまなフェーズの意見が交換できるように『SREの探求』を読む候補としてSRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームやサイトリライアビリティワークブック ―SREの実践方法 も上がりました。しかし、Google だけではなく様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践が紹介されているということで『SREの探求』に決定いたしました。輪読会の形式リモートで毎週水曜日 18:00から1時間、業務もあるので参加は自由としました。進め方としては担当者がNotion に担当の章をまとめて内容を発表する。その後、話し合いながらNotion やSlack に意見を垂れ流す方式にしました。参加者はSREの専門家達、リーダー、人事、営業、総務など様々な方がいてわいわいとやれているので僕は楽しい。輪読会をはじめてから半年が経過して開催できてない週もありましたが現在は14回の実施ができました。各担当者毎に特色がある発表で聞いていて面白いです。『SREの探求』には様々な視点でのSREでの話がされているので当初の目的としては正解です。また、同じ本で同じ職種なのにここまで読み方に差が出るのかと感心してます。人によってはすごくその事柄について考えられていて自分と比較して落ち込みます。でも、経験や考え方の違う人の話を聞けるのはとても参考と刺激になってます。『SREの探求』の輪読会のTOPページです。情報がシュッとまとまってます。また、1年が経過したタイミングで「輪読会に参加して、その後、SREに対しての考え方や行動に変化はありましたか？ 」という質問をしたいと考えております。もし、読んでる社内の方がいたら考えておいてください。さいごに『SREの探求』の輪読会を半年運営してきて各メンバーがSREやインフラ技術に関する意見や知見を交換できる場として機能し始めていると思ってます。自分自身もSREに関する知見を深める機会になっております。今後より良いサービスを提供していくためにも輪読会は続けていきたいなと思いました。輪読会をやる時には運営が複数人で実施することと目的を明確にしておけば運営を続けやすいなって思いました。『SREの探求』の輪読会を終了したタイミングでちゃんと効果測定したブログを書こうと【今は】思ってます。","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/09/041252","isoDate":"2022-12-08T19:12:52.000Z","dateMiliSeconds":1670526772000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『セキュア・バイ・デザインの鳴くところ』というタイトルでOWASP Fukuoka Meeting #9 に登壇しました。 #owaspfukuoka","contentSnippet":"OWASP Fukuoka Meeting #9 に登壇してきました！登壇してきました。自分はセキュリティ専門家ではないのですが発表するとセキュリティ専門家からレビューをもらえたり意見をいただけるのでそれがとてもよいです。ちなみに発表時間が諸事情により30分から1時間になって想定外の資料の取捨選択を行った...発表時間が30分から1時間になって想定してない肉付けしたら資料の主張が曲がったので改変している。— nwiizo (@nwiizo) 2022年12月6日  発表資料セキュア・バイ・デザインの鳴くところ - 安全なソフトウェアを全体から考えるみるで候の資料はこちらです『セキュア・バイ・デザインの鳴くところ』みたいな資料を作成したので公開しておきます！https://t.co/BduVhWd73K#owaspfukuoka— nwiizo (@nwiizo) 2022年12月7日  リモート発表は寂しいので相槌を入れてほしいと思っている。主催の@TakaharuOgasa さんや@mrtc0 さんが程よく補足情報を入れたりしてくれてよかった。セキュア・バイ・デザイン 安全なソフトウェア設計作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版Amazon参考資料OWASP SAMM(Software Assurance Maturity Model)OWASP SAMM(Software Assurance Maturity Model):githubOWT2017JP - OWASP SAMMセキュリティーチェックシートという闇への防衛術CircuitBreakerPattern: Circuit BreakerGitHub - istio/istio: Connect, secure, control, and observe services.Istio By Exampleサービスメッシュの「Istio」や、OSSで構成されたマネージドサービス――ミッションクリティカルなシステムをKubernetesで実現するカギはツールにあり！【デブサミ2018】Design It! ―プログラマーのためのアーキテクティング入門Release It!: Design and Deploy Production-Ready SoftwareOWASP SAMM Toolkit v2.0.6開発環境のセキュリティおよびCI/CDパイプラインのセキュア化PHPerKaigi 2022: 予防に勝る防御なし - 堅牢なコードを導く様々… / 和田卓人SOLID CODE 高品質なコードを生み出す実践的開発手法","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/07/204400","isoDate":"2022-12-07T11:44:00.000Z","dateMiliSeconds":1670413440000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"「セキュア・バイ・デザイン」を読んで自分が何番目の豚かを考える。","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022  2日目の記事です。前日は@koki_develop さんによるStep CI で手軽に API をテストする でした。Step CI は API をテストするためのシンプルなオープンソースのコマンドラインツールです。「第8章: セキュリティを意識したデリバリ・パイプライン」ではStep CI のようなツールを用いてデリバリ・パイプラインで正常値、境界値、異常値、極端値を検査することが推奨されています。qiita.comこのエントリーで言いたいことセキュア・バイ・デザイン という書籍の多様さセキュリティにおける設計の大切さ現代におけるセキュリティの幅広さと難しさが凝縮された一冊であるということセキュリティを面で捉える難しさと重要性このエントリーを書き始めた理由2022年12月7日20:00- よりOWASP Fukuoka Meeting #9で「セキュア・バイ・デザインの鳴くところ」というタイトルで登壇してきます。この発表ではセキュア・バイ・デザイン、シフトレフト、DevSecOps は何すればいいんだよ！ という人に対してOWASP SAMM version 2を軸にガバナンス・設計・実装・検証・運用でのロードマップを明確にして設計・実装に関してもいくつかのTipsに言及していこうと思います。このイベントはYouTubeなどで後から動画を公開しないので動いてる私が見たい場合には参加登録してほしいです。発表の動画は公開されないですが資料は公開する予定です。それに対する予稿的な意味合いで書き始めました。内容は違うのに...。目次このエントリーで言いたいことこのエントリーを書き始めた理由目次はじめに「セキュア・バイ・デザイン 安全なソフトウェア設計」の目次僕たち二番目の子豚良い設計と悪い設計の違いSREは8章から10章が必読3部から読んでも良いと思ったさいごに参考はじめに「セキュア・バイ・デザイン 安全なソフトウェア設計」はOWASP TOP 10のような既知の脅威をリスト化して問題のある実装に対する解法を実装に組み込むためのTips を紹介する書籍ではありません。開発中にセキュリティについて意識する必要はないというような主張をする書籍でもありません。また、ドメイン駆動設計(Domain-Driven Design: DDD)を用いて、設計する書籍なのでDDDで開発しないから関係ないというわけではないです。システムの設計時にセキュリティだけを切り出して別問題として考えるのではなく、システム全体の関心事として扱い、設計時に考慮するというような書籍です。セキュア・バイ・デザイン: 安全なソフトウェア設計 Compass Booksシリーズ作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版Amazon「セキュア・バイ・デザイン 安全なソフトウェア設計」の目次セキュア・バイ・デザインについて実例と共に見ていく導入編。ソフトウェアの作成におけるセキュア・バイ・デザインの基盤を構築する設計の原則、考え、コンセプトについて学ぶ基礎編。レガシー・コードの改善、モノリシック・アーキテクチャでよく起こる問題、マイクロサービス・アーキテクチャについて学ぶ応用編の3部構成になっています。第1部: 導入編第1章: なぜ、設計がセキュリティにおいて重要なのか？第2章: ちょっと休憩: 『ハムレット』の悲劇第2部: 基礎編第3章: ドメイン駆動設計の中核を成すコンセプト第4章: 安全性を確立する実装テクニック第5章: ドメイン・プリミティブ（domain primitive）第6章: 状態の完全性（integrity）の保証第7章: 状態の複雑さの軽減第8章: セキュリティを意識したデリバリ・パイプライン第9章: 安全性を考えた処理失敗時の対策第10章: クラウド的考え方によるメリット第11章: ちょっと休憩: 保険料の支払いなしに成立してしまった保険契約第3部: 応用編第12章: レガシー・コードへの適用第13章: マイクロサービスでの指針第14章: 最後に：セキュリティを忘れるべからず！僕たち二番目の子豚家を作る時には壊れにくく、泥棒に盗まれにくい家を考えるのは当たり前です。家のセキュリティにコストをかける必要性は有名なの子豚が教えてくれたとおもいます。開発者はビジネス・ロジックを実装に落とし込みながらセキュリティの脆弱性についても考えなくてはならない。しかし、実装の優先するあまり一番目の子豚のような実装を行ってしまいます。そんな人たちを笑う二番目の子豚もいます。実装を行う開発者は常にセキュリティに関するスペシャリストというわけではないです。それを求めることも現実的ではありません。そのため、WAFを入れたり、脆弱性診断を行ったりします。しかし、それらも絶対ではありません。特に二章の\"ちょっと休憩: 『ハムレット』の悲劇\"で紹介された。ECサイトで「-1個」購入できるようになってしまうようなインシデントに関する話に関してはWAFがちゃんと設定されてないと無力だったりもする。ちなみに全体を通してセキュリティを意識しないことが大事だというが最終章の14章では全く逆のセキュリティを意識する重要性について説明されている。良い設計と悪い設計の違い全員にレベルの高いセキュアコーディングを要求するのではなく設計に意識を向けることで、従来のアプローチで抱えていたいくつかの問題に関して解決することを目的にしております。特に3-7章に関してはドメイン駆動設計を行う時にこれを意識しない場合にはこういうような脆弱性に繋がるという例は豊富でかつ示唆に富んでいる。また、本書はドメイン駆動設計から言葉、概念を拝借してはいるが\"正しい使い方を簡単に、誤った使い方を困難に\"ということを設計で達成しようぜと終始言ってるだけな気もする。あくまで私の感想ですけど。SREは8章から10章が必読SREという単語を利用したがこの文章も例に洩れずポジショニングトーク的にSREという単語を利用しておりますので何も言わないでください。SREコンサルという仕事をしているとSREの意味的なゲシュタルト崩壊を起こしてしまいます。情報セキュリティの３大要素にも入るぐらいなのでセキュリティにおいて可用性は重要です。8章から10章は特に私のようにSRE的な仕事をしている人間からするとアイデアの宝庫です。特に大事だと思ったのは使用しているツールのデフォルトの振る舞いを知ることの重要性についてです。既存のシステムで利用している秘伝のタレを継ぎ足しているだけで詳しくなったような気持ちになる。危険。本当はもっと、フォーカスしたいのでここは別でブログ書きたい。ちなみにOWASP Fukuoka Meeting #9のイベントではこの辺が話の中心に添えられている。3部から読んでも良いと思った防御的プログラミングのように良識あるようなTipsの積み重ねで問題発生を事前に防ごうというコーディングスタイルがあります。3部はわりとそれに近い内容に関する言及でレガシーコードとマイクロサービスでの注意点や改善方法がまとめられている。レガシーコードに関しては私の大好きなリファクタリング(第2版): 既存のコードを安全に改善するという書籍がある。もう、1章を追加するならセキュリティの概念を足したようなこの章が追加されてほしいと思いました。マイクロサービスの章に関しては現在、私がソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析という書籍を読んでいる。セキュリティ的な品質をソフトウェアの設計へ落とし込むには設計段階で考慮が必要。特に非機能的なので熟考に次ぐ次ぐだけ絶対にどうにかならず経験が必要な領域。最終章は具体的なコードレビューやアーキテクチャレビューにセキュリティの専門家が必要な重要性、脆弱性診断やインシデントハンドリングなどのセキュリティをがっつり意識した内容です。全てをひっくり返す感じがしてとても気持ちが良い。セキュリティの専門家はこの章まで耐えて「気持ちぃいいいいい(実際にどうなるかは知らない)」を経験してほしいです。さいごにあまねく全ての開発者に対してセキュリティの専門家と同等の知識が求められセキュリティに関する知識を常にアップデートしなければならないというこの時代。結局、安全な設計にもセキュリティにもお金が必要になる。地獄の沙汰も金次第。ちゃんと、コストを支払える会社に入社を果たし三番目の豚として幸せな生活をおくれるように祈ってます。本書は本当に良い本なのでこのエントリーで気になった人はぜひ、「セキュア・バイ・デザイン 安全なソフトウェア設計」を購入して熟読して実践してほしいです。明日は我らが長ATSによる「SRE事業をしているので「信頼性」について考えたくなった」です。参考OWASP SAMM version 2セキュア・バイ・デザイン 安全なソフトウェア設計プログラマが知るべき97のこと コードは設計である予防に勝る防御なし - 堅牢なコードを導く様々な設計のヒント良い設計と悪い設計の違い","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/01/225019","isoDate":"2022-12-01T13:50:19.000Z","dateMiliSeconds":1669902619000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kubernetes 上でsablier を用いてZero Scale を実現する 前編","contentSnippet":"前回のエントリーsyu-m-5151.hatenablog.comはじめにやはり、人は強欲らしいのでコンテナを使っているのに必要な時必要な分だけのリソースを起動させてほしいという願いを常に持っている。Kubernetes の場合はKnativeなどを利用すれば達成できる。sablierはリバースプロキシを利用してアクセスがない時は自動的にシャットダウンしてアクセスがあれば指定のコンテナを起動することができるツールです。前回はdocker 上での動作確認を行った。引き続き今回はKubernetes 環境でのsablierの検証を行いました。今回はsablierやTraefik 、各種ミドルウェアの設定ファイルに関しては言及してません。気合があれば後編として書いていきます。sablier/hourglass.png at main · acouvreur/sablier · GitHub より前回のエントリーはじめにやってみるk3s を用いて Kubernetes Cluster を作成するHelmを用いたTraefikの作成Sablier を作成していくアプリケーション本体のデプロイSablier PluginによるTraefik経由でのIngressの設定を行うさいごに作業リポジトリやってみる公式サイトにはサンプルコード「Sablier Guide: Code-Server + Traefik + Kubernetes Ingress」としてKubernetes 上で Cloud Native なアプリケーションプロキシーのTraefikとKubernetes Ingressを用いたものが紹介されている。k3s を用いて Kubernetes Cluster を作成する以下の内容をdocker-compose.ymlというファイルにコピーして、docker compose up -dを実行します。version: '3'services:  server:    image: \"rancher/k3s:v1.24.8-k3s1\"    command: server --no-deploy traefik    tmpfs:      - /run      - /var/run    ulimits:      nproc: 65535      nofile:        soft: 65535        hard: 65535    privileged: true    restart: always    environment:      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml      - K3S_KUBECONFIG_MODE=666    volumes:      # This is just so that we get the kubeconfig file out      - .:/output    ports:      - 6443:6443  # Kubernetes API Server      - 8080:80  # Ingress controller port 80docker compose up -dを実行します。$ docker compose up -d[+] Running 3/3 ⠿ server Pulled   ⠿ 73c47571f4bd Pull complete   ⠿ 210e8c1c5e29 Pull complete[+] Running 2/2 ⠿ Network sablier-code-server-traefik-kubernetes_default     Created ⠿ Container sablier-code-server-traefik-kubernetes-server-1  Startedset -x KUBECONFIG ./kubeconfig.yaml:/Users/nwiizo/.kube/config のような設定が環境変数として入っているのでカレントディレクトリにあるkubeconfig.yaml がKUBECONFIGとして優先的に実行される。そこでkubectl get node を実行するとCluster が準備できていることが分かる。$ kubectl get nodeNAME           STATUS     ROLES                  AGE     VERSION58160ffa6e9b   Ready      control-plane,master   3m56s   v1.24.8+k3s1Helmを用いたTraefikの作成helm のインストールに関しては各自「helm install」とかで調べてほしい。とりあえず、traefikのHelmリポジトリを追加します。$ helm repo add traefik https://helm.traefik.io/traefik$ helm repo updatehelm でデプロイするリソースは事前に確認しておいたほうがよいので確認しておきます。$ helm show all traefik/traefikデプロイをするのですが既存のHelm templateに自分が利用したい値を渡してデプロイします。templateに値を渡す方法は主に二つあります。values.yamlを利用者が用意するchartの利用者が helm install コマンド時に値を渡す(values.yamlの上書き可能)今回はvalues.yaml を以下のように作成してデプロイを行うimage:  tag: \"2.9.1\"experimental:  plugins:    enabled: trueadditionalArguments:  - \"--experimental.plugins.sablier.moduleName=github.com/acouvreur/sablier\"  - \"--experimental.plugins.sablier.version=v1.1.1\"providers:  kubernetesIngress:    enabled: true    allowEmptyServices: truetraefikチャートをvalues.yamlファイルとともにインストールします。また、kube-system というシステムコンポーネントやアドオンとして位置づけられているものをデプロイするためのNamespaceを用います。$ helm install traefik traefik/traefik -f values.yaml --namespace kube-systemNAME: traefikLAST DEPLOYED: Wed Nov 30 07:58:21 2022NAMESPACE: kube-systemSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:Traefik Proxy v2.9.5 has been deployed successfullyon kube-system namespace !Sablier を作成していく再三の説明になるのですがsablier はアプリケーションをシャットダウンさせたりしているアプリです。それ故に強い権限が必要になります。そのため、Sablier 用のサービスアカウント作成して、 Sablier のデプロイを行います。sablier-sa.yaml というファイルで権限周りを一つにした。---apiVersion: v1kind: ServiceAccountmetadata:  name: sablier  namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  name: sablier  namespace: kube-systemrules:  - apiGroups:      - apps      - \"\"    resources:      - deployments      - deployments/scale      - statefulsets      - statefulsets/scale    verbs:      - patch   # Scale up and down      - get     # Retrieve info about specific deployment or statefulset      - update  # Scale up and down      - list    # Events      - watch   # Events---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: sablier  namespace: kube-systemroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: sabliersubjects:  - kind: ServiceAccount    name: sablier    namespace: kube-systemこちらをデプロイ$ kubectl apply -f sablier-sa.yaml serviceaccount/sablier createdclusterrole.rbac.authorization.k8s.io/sablier createdclusterrolebinding.rbac.authorization.k8s.io/sablier createdsablier-deploy.yaml というファイルでリソース周りを一つにした。apiVersion: apps/v1kind: Deploymentmetadata:  name: sablier-deployment  namespace: kube-system  labels:    app: sablierspec:  replicas: 1  selector:    matchLabels:      app: sablier  template:    metadata:      labels:        app: sablier    spec:      serviceAccountName: sablier      serviceAccount: sablier      containers:      - name: sablier        image: acouvreur/sablier:1.1.1        args:        - \"start\"        - \"--provider.name=kubernetes\"        ports:        - containerPort: 10000---apiVersion: v1kind: Servicemetadata:  name: sablier  namespace: kube-systemspec:  selector:    app: sablier  ports:    - protocol: TCP      port: 10000      targetPort: 10000こちらもデプロイ$ kubectl apply -f sablier-deploy.yaml deployment.apps/sablier-deployment createdservice/sablier createdきちんとデプロイされているか確認する。また、kubectl -n kube-system logs -l=app=sablier でログを確認するのも良いと思う$ kubectl -n kube-system get deployments -l=app=sablierNAME                 READY   UP-TO-DATE   AVAILABLE   AGEsablier-deployment   1/1     1            1           6m9sアプリケーション本体のデプロイapp-deployment.yaml でアプリケーションのリソースをデプロイします。apiVersion: apps/v1kind: Deploymentmetadata:  name: code-server-deployment  namespace: default  labels:    app: code-serverspec:  replicas: 1  selector:    matchLabels:      app: code-server  template:    metadata:      labels:        app: code-server    spec:      containers:      - name: code-server        image: codercom/code-server:4.8.3        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: code-server-service  namespace: defaultspec:  selector:    app: code-server  ports:    - protocol: TCP      port: 8080      targetPort: 8080kubectl にk というalias を貼っている。手癖でこうなったのでブログでも記載しておく。リソースの確認をk get pod したらさっさと次に行く$ k apply -f app-deployment.yaml deployment.apps/code-server-deployment createdservice/code-server-service createdSablier PluginによるTraefik経由でのIngressの設定を行うapp-ingress.yaml でデプロイするapiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: code-server-ingress  namespace: default  annotations:    kubernetes.io/ingress.class: traefikspec:  rules:  - host: localhost    http:      paths:      - path: /        pathType: Prefix        backend:          service:            name: code-server-service            port:              number: 8080http://localhost:8080 にアクセスできたと思います。その後、アプリケーションのレプリカセットを0にします。がこれは削除ではないです。$ k scale deployment code-server-deployment --replicas=0deployment.apps/code-server-deployment scaled# 削除されたわけではないので確認できる$  k get deployments/code-server-deployment NAME                     READY   UP-TO-DATE   AVAILABLE   AGEcode-server-deployment   0/0     0            0           12mapp-sablier-middleware.yaml をデプロイする。sessionDuration: 2m に設定をしたので2分後には落ちるはずです。apiVersion: traefik.containo.us/v1alpha1kind: Middlewaremetadata:  name: code-server-sablier  namespace: defaultspec:  plugin:    sablier:      names: deployment_default_code-server-deployment_1      sablierUrl: 'http://sablier:10000'      sessionDuration: 2m      dynamic:        displayName: 'Code Server Demo'        showDetails: true        theme: hacker-terminal        refreshFrequency: 5s$ k apply -f app-sablier-middleware.yaml$ k get middlewareNAME                  AGEcode-server-sablier   2m5sその後にapp-ingress-patch.yaml を作成し、kubectl patch ingress code-server-ingress --patch-file app-ingress-patch.yaml でIngressにパッチを当てます。metadata:  annotations:    traefik.ingress.kubernetes.io/router.middlewares: default-code-server-sablier@kubernetescrdパッチを当てた直後はアクセスがないのでpod 数は0です。$ k get pod No resources found in default namespace.しかし、traefik 及びsablier の動作によってhttp://localhost:8080 に何もせずにアクセスできました。この時に関連している各種ログを確認すると動作していることがわかります。$ k get pod NAME                                      READY   STATUS    RESTARTS   AGEcode-server-deployment-7f56554786-j4b69   1/1     Running   0          2m44sそして、2分後にはシャットダウンされていると思います。# -w で継続的にウォッチする$ k get po -wNAME                                      READY   STATUS    RESTARTS   AGEcode-server-deployment-7f56554786-t5j8x   1/1     Running   0          36scode-server-deployment-7f56554786-t5j8x   1/1     Terminating   0          2m17scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18sさいごに本来やりたかった。Kubernetes 環境での動作確認までできました。此処から先は皆さんの環境に合うようにいくつかの設定ファイルを見ていく会を本来やれれば良かったですが眠いのでおやすみです。作業リポジトリgithub.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/30/085418","isoDate":"2022-11-29T23:54:18.000Z","dateMiliSeconds":1669766058000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"私はGo言語でシェルスクリプトが書きたい不都合な生きもの","contentSnippet":"Goに入ってはGoに従え 私の好きな言葉です(スライド)。XX(架空の)という言語を書いてるならばXX言語らしく書きましょうと常々、思っております。しかし、インフラエンジニアの魂に最も刻まれた言語は何か？ それはシェルスクリプトではないですか。異論は認めます。はじめになんでみんなこんなに怒っているのかというような疑問はある。世の中がぎすぎすしていて、明るい話題がない。この世にはもっと明るい話が必要だと思うのだが、思いつきませんでした。まず、シェルスクリプトだとこう書くという明確な思考があるのにそれをGo言語で表現する方法が分からない場面で悔しい思いをしてきた方もいらっしゃるのではないかと思います。そういう方に明るい話題を提供したいです。script はシェルスクリプトが得意とする、ファイルの読み込み、サブプロセスの実行、行数のカウント、文字列のマッチングなどを行うための Go のライブラリです。Goでシステム管理プログラムを書くのは、典型的なシェルと同じように簡単ですか？ scriptはそれを簡単にすることを目的としています。大体の場合ではScripting with Go といくつかのブログを読めばよい。script/magic.png at master · bitfield/script · GitHub より引用github.comシェル芸という実益を兼ねた趣味シェル芸というおしゃれでハイソな趣味がある。シェル芸とは、マウスも使わず、ソースコードも残さず、GUIツールを立ち上げる間もなく、あらゆる調査・計算・テキスト処理をCLI端末へのコマンド入力一撃で終わらすこと。あるいはそのときのコマンド入力のこと(シェル芸の定義バージョン1.1 より引用) を指すのだかこれをやっていくのはインフラエンジニアが運用をやっていくなかで力になるものです。私も学生時代にシェル芸初心者によるシェル芸入門 というスライド をみてとてもお世話になった。こちらから演習1の問題を拝借してscript について紹介したいと思います。演習1 という演習先程、紹介したシェル芸初心者によるシェル芸入門というスライドには演習があります。演習1の内容は /home 以下(MACの場合には/Users)から現在ログインしているユーザーの名前を含むファイルを全て列挙してくださいというものです。それをシェルスクリプトで書くと以下のようになります。想定回答はこちらgrep -r `whoami` /Users | grep -v matches 2>/dev/null解く🐘この課題をscript を用いて解決したい。と思ったのですがgrep に-r オプションがないことに気づいたのでfindfile を用いて実行する。package mainimport (    \"fmt\"    \"strings\"    \"github.com/bitfield/script\")func main() {    // whoami は用意されていないです。だが、用意されていないコマンドもexecで実行できる    user, _ := script.Exec(\"whoami\").String()    // exec で実行したら実行後の改行が入るので削除しておくオプションがあるなら知りたい    // filepath を作成する    user_file_path := \"/Users/\" + remove_line_breaks(user) + \"/\"    // 実際のコマンドを実行して標準出力に投げる    _, err := script.FindFiles(user_file_path).Stdout()    if err != nil {        fmt.Println(err)    }}// 末尾の改行を削除するfunc remove_line_breaks(s string) string {    s = strings.TrimRight(s, \"\\n\")    if strings.HasSuffix(s, \"\\r\") {        s = strings.TrimRight(s, \"\\r\")    }    return s}権限周りで辛いが権限をめちゃくちゃにイジるとMACの場合でもいける...。さいごに実際の技術検証だったらscript.Exec()が具体的にどのようにシェルで実行されたりするのかを調べるのですが別に趣味なのでここで終わりです。script を書いてて気付いたのですが別に各コマンドを実行するための近しいパッケージは存在するのでそれを調べて使えばぁッ...　ここで彼のメッセージは途切れる。","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/26/174017","isoDate":"2022-11-26T08:40:17.000Z","dateMiliSeconds":1669452017000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"sablier でコンテナのScale to zero が実現できるので覗き見だけした。","contentSnippet":"はじめに人は強欲なのでコンテナを使っているのに必要な時必要な分だけのリソースを起動させてほしいという願いを常に持っている。Kubernetes の場合はKnativeなどを利用すれば達成できる。が今回はsablierというツールを紹介する。sablierはリバースプロキシを利用してアクセスがない時は自動的にシャットダウンしてアクセスがあれば指定のコンテナを起動することができるツールです。sablier/hourglass.png at main · acouvreur/sablier · GitHub よりやってみる公式サイトにはサンプルコードとして Cloud Native なアプリケーションプロキシーのTraefikを用いたものが紹介されている。ブログを書いている2022年11月25日の時点でplugins配下にTraefik しかないがnginxも追加しようというIssues が上がっている。Git CloneGit Clone をとりあえずしてRepositoryを持ってくる。こういう時にghqでローカルリポジトリを管理するかとても悩むのですが私は検証のみを行いたい時にはghqでは管理しないことが多いです。git clone https://github.com/acouvreur/sabliercd sablierdocker compose up最近、docker-compose がdocker に統合されたのでdocker-compose ではなくdocker compose を利用する。自分自身のこういうスタンス、嫌いではないです。docker compose up -d[+] Running 13/13 ⠿ whoami Pulled                                                                                     6.7s   ⠿ 29015087d73b Pull complete                                                                      0.9s   ⠿ 0109a00d13bc Pull complete                                                                      1.2s   ⠿ dfc0c371343c Pull complete                                                                      3.0s ⠿ traefik Pulled                                                                                    7.3s   ⠿ 47517142f6ba Pull complete                                                                      2.0s   ⠿ 24e179f025e9 Pull complete                                                                      2.3s   ⠿ 94b59dd82910 Pull complete                                                                      5.4s   ⠿ d3d7e56d0086 Pull complete                                                                      5.5s ⠿ sablier Pulled                                                                                   10.1s   ⠿ 9b18e9b68314 Pull complete                                                                      3.0s   ⠿ f8cfeb0e421f Pull complete                                                                      5.8s   ⠿ 3e48bafb90b9 Pull complete                                                                      5.8s[+] Running 3/3 ⠿ Container sablier-sablier-1  Started                                                              0.7s ⠿ Container sablier-whoami-1   Started                                                              0.8s ⠿ Container sablier-traefik-1  Started                                                              0.8ssablier-sablier-1,sablier-traefik-1,sablier-whoami-1 が動作していることが分かる。docker compose psNAME                COMMAND                  SERVICE             STATUS              PORTSsablier-sablier-1   \"/etc/sablier/sablie…\"   sablier             running             10000/tcpsablier-traefik-1   \"/entrypoint.sh --ex…\"   traefik             running             0.0.0.0:8080->80/tcpsablier-whoami-1    \"/whoami\"                whoami              running             80/tcp説明しておくとsablier-sablier-1 がシャットダウンさせたりしているアプリです。sablier-traefik-1 がリバースプロキシなのですがPluginの機構としてこちらがあることによってアプリケーションに変更を加えることなく機能の追加を行うことができる。典型的なサイドカーパターンですね。sablier-whoami-1 がアプリケーションの本体です。sablier/reverse-proxy-integration.png at main · acouvreur/sablier · GitHub よりまた、起動したdocker-compose の設定ファイルを読むと分かるが設定ファイルに関してdynamic-config.ymlが設定されておりアプリケーションの本体に対する設定はこちらで行われている。version: \"3.7\"services:  traefik:    image: traefik:2.9.1    command:      - --experimental.plugins.sablier.moduleName=github.com/acouvreur/sablier      - --experimental.plugins.sablier.version=v1.1.0      - --entryPoints.http.address=:80      - --providers.docker=true      - --providers.file.filename=/etc/traefik/dynamic-config.yml    ports:      - \"8080:80\"    volumes:      - '/var/run/docker.sock:/var/run/docker.sock'      - './dynamic-config.yml:/etc/traefik/dynamic-config.yml'  sablier:    image: acouvreur/sablier:1.1.0    volumes:      - '/var/run/docker.sock:/var/run/docker.sock'    labels:      - traefik.enable=true      # Dynamic Middleware      - traefik.http.middlewares.dynamic.plugin.sablier.names=sablier-whoami-1      - traefik.http.middlewares.dynamic.plugin.sablier.sablierUrl=http://sablier:10000      - traefik.http.middlewares.dynamic.plugin.sablier.sessionDuration=1m      - traefik.http.middlewares.dynamic.plugin.sablier.dynamic.theme=hacker-terminal      # Blocking Middleware      - traefik.http.middlewares.blocking.plugin.sablier.names=sablier-whoami-1      - traefik.http.middlewares.blocking.plugin.sablier.sablierUrl=http://sablier:10000      - traefik.http.middlewares.blocking.plugin.sablier.sessionDuration=1m      - traefik.http.middlewares.blocking.plugin.sablier.blocking.timeout=30s  whoami:    image: containous/whoami:v1.5.0    # Cannot use labels because as soon as the container is stopped, the labels are not treated by Traefik    # The route doesn't exist anymore. Use dynamic-config.yml file instead.    # labels:    #  - traefik.enable    #  - traefik.http.routers.whoami.rule=PathPrefix(`/whoami`)    #  - traefik.http.routers.whoami.middlewares=dynamic@dockersablier/docker-compose.yml at main · acouvreur/sablier · GitHub より一旦、万全な状態でのアクセス確認を行うcurl http://localhost:8080/whoami/blockingHostname: 57f6719e2c3bIP: 127.0.0.1IP: 172.24.0.2RemoteAddr: 172.24.0.4:35092GET /whoami/blocking HTTP/1.1Host: localhost:8080User-Agent: curl/7.84.0Accept: */*Accept-Encoding: gzipX-Forwarded-For: 172.24.0.1X-Forwarded-Host: localhost:8080X-Forwarded-Port: 8080X-Forwarded-Proto: httpX-Forwarded-Server: d53703352004X-Real-Ip: 172.24.0.1アクセスの確認ができた。docker compose stopアプリケーション本体のコンテナを止める。docker compose stop whoami[+] Running 1/1 ⠿ Container sablier-whoami-1  Stoppedアプリケーション本体が止まっていることを確認できました。docker compose psNAME                COMMAND                  SERVICE             STATUS              PORTSsablier-sablier-1   \"/etc/sablier/sablie…\"   sablier             running             10000/tcpsablier-traefik-1   \"/entrypoint.sh --ex…\"   traefik             running             0.0.0.0:8080->80/tcpsablier-whoami-1    \"/whoami\"                whoami              exited (2)curl http://localhost:8080/whoami/blocking先程、と同様にエンドポイントを確認するとアクセスすることが確認できた。秒数としてどれくらい差分があるのか確認したかったが眠い。curl http://localhost:8080/whoami/blockingHostname: 57f6719e2c3bIP: 127.0.0.1IP: 172.24.0.2RemoteAddr: 172.24.0.4:35104GET /whoami/blocking HTTP/1.1Host: localhost:8080User-Agent: curl/7.84.0Accept: */*Accept-Encoding: gzipX-Forwarded-For: 172.24.0.1X-Forwarded-Host: localhost:8080X-Forwarded-Port: 8080X-Forwarded-Proto: httpX-Forwarded-Server: d53703352004X-Real-Ip: 172.24.0.1docker compose logs でログを確認するとStarting up on port 80とシャットダウンと起動を何度か繰り返していることが確認できた。また、自主的にstop せずとも落ちていることは確認できた。Linux 側からもプロセスを確認しようと思っていたが深夜なのでもう眠い。docker compose logs sablier-whoami-1   | Starting up on port 80sablier-whoami-1   | Starting up on port 80さいごにあまり使わない機能が多い検証環境や開発環境で利用するにはとても良いサービスだと思った。深夜かつ飲酒によって、本来はKubernetes 環境での動作確認までしたかったのですが眠いので終わりますが一応、公開します。","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/25/185409","isoDate":"2022-11-25T09:54:09.000Z","dateMiliSeconds":1669370049000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとして「ソフトウェアアーキテクチャの基礎」を読んでないのに堂々と語る方法","contentSnippet":"このエントリーで言いたいことシステムの構造や各種機能を実装することもアドバイスを求められることも非常に少ないがSREもソフトウェアアーキテクチャに関わることがある。それは、プログラマーとしてではなくアーキテクチャ特性の専門家としてアーキテクチャに触れる場面です。そのため、アーキテクチャ全体についての知識は得ておくことは良いこと。タイトル説明読んでいない本について堂々と語る方法という書籍がある。読んでいないにも色々あって…本当にぜんぜん読んだことのない本、ざっと読んだもしくは流し読みをしたことがある本。人から聞いたことがある本、ブログで書評だけ読んだ本、読んだことはあるが忘れてしまった本などあらゆる本を語る技術に書かれている読書論の本のタイトルだけのオマージュです。はじめに本日、10/27に『ソフトウェアアーキテクチャの基礎』を執筆した著者陣が書いた『ソフトウェアアーキテクチャ・ハードパーツ - 分散アーキテクチャのためのトレードオフ分析』が発売されました。絶対的な銀の弾丸がないソフトウェアアーキテクチャの世界ではトレードオフを見極め、状況に合った選択をすることが常に求められます。悔いなき判断には多くの知恵と経験が要求されると思います。ハードパーツは、読者が自身のアーキテクチャ上の難題に対して効果的なトレードオフ分析を行い、より良い決定ができるようにするための書籍です。また、我々SREはプロジェクトやシステムに対して意見や判断を求められることも多くあると思います。そんな時にきっと、ソフトウェアアーキテクチャの基礎やソフトウェアアーキテクチャ・ハードパーツ を読んでおけばよかったと思うことがあるかもしれません。このエントリーではその前作のソフトウェアアーキテクチャの基礎の概要を確認することでハードパーツへの理解をより深めていけるとおもいます。優秀なアーキテクチャになりたいから読んでほしいわけではありません。スペシャリストとして意見や判断を求められた時の判断材料や語彙の強化などで今後のエンジニア人生に役に立ってくれると思います。このエントリーは『ソフトウェアアーキテクチャの基礎』を読んでみた中での感想文となります。「ソフトウェアアーキテクチャの基礎」の目次部と章立ては以下の通りです。全24章もありこれだけでもすごく勉強になります。個人的には付録Aの自己評価のためのチェックリストをやってみてから本書を読むのも良いかな‐って思っているが自分はやっていないので何も責任は持てない。Ⅰ部では基礎や概念、Ⅱ部では詳細な各アーキテクチャについて、Ⅲ部ではソフトスキルとマネジメントテクニックみたいな話をしてます。1章 イントロダクション# 第I部 基礎2章 アーキテクチャ思考3章 モジュール性4章 アーキテクチャ特性5章 アーキテクチャ特性を明らかにする6章 アーキテクチャ特性の計測と統制7章 アーキテクチャ特性のスコープ8章 コンポーネントベース思考# 第II部 アーキテクチャスタイル9章　基礎10章　レイヤードアーキテクチャ11章 パイプラインアーキテクチャ12章 マイクロカーネルアーキテクチャ13章 サービスベースアーキテクチャ14章 イベント駆動アーキテクチャ15章 スペースベースアーキテクチャ16章 オーケストレーション駆動サービス指向アーキテクチャ17章 マイクロサービスアーキテクチャ18章　適切なアーキテクチャスタイルを選ぶ# 第III部　テクニックとソフトスキル19章 アーキテクチャ決定20章 アーキテクチャ上のリスクを分析する21章 アーキテクチャの図解やプレゼンテーション22章 効果的なチームにする23章 交渉とリーダーシップのスキル24章 キャリアパスを開く付録A　自己評価のためのチェックリスト参考文献訳者あとがき索引目次や本の詳細についてはO’Reilly Japanよりご確認ください。特徴と感想問われるシステムアーキテクチャとしての知見の広さと深さ目次を見ると分かると思います。が、単純にいくつかのアーキテクチャについての紹介しているだけではありません。アーキテクチャを考える際に必要な思考方法やどのような部分に思考を巡らせればよいか、リスク分析から立ち回りまで広大なトピックを凝縮し網羅的にまた、今という視点だけではなくどのような技術的な変化や背景があっては今に至るのか？ などの文脈まで考慮されて書かれています。この、書籍の好きなところは2点あります。1つ目は定義づけて不毛な議論を避けることです。Twitterで定期的に発生する背景なき不毛な議論もほとんど無くなるといいなと思ってます。2つ目は技術的な手法だけではなくところです。結局は人の問題で、全ての議論でチームや人を蔑ろにせずソフトスキルや技芸へのリスペクトがあるところです。また、『ソフトウェアアーキテクチャの基礎』を一冊読んだところで直ちに目の前にあるソフトウェアやアプリが急激によくなったりすることはない。が今後のソフトウェアの開発に関わって生きていく上でまた、様々な指標になる素晴らしい書籍だと思いました。本当は一章づつ振り返りたいのですが時間的にも余裕がないので少しだけ紹介させてほしいです。ソフトウェアアーキテクチャとは？ソフトウェアアーキテクチャと言われた時に、要件とその他すべてのアーキテクチャ特性から構成されるものをふわっとまとめてなんとなくそう考えていたり言及してました。本書では以下のように4つに分類され定義されます。あと、このあとに出てくる図がとても整理があると自分が何について考えなければならないのか明確になるので本書を読んで最初に勝ちを確信しました。私は洋書が出てからすぐに友人からすごい書籍があるから紹介されて読んだので読んだことはあるが忘れてしまった本に近いのだがこの時の感動は今でも覚えている。私たちのソフトウェアアーキテクチャについての考え方を示す。私たちは、ソフトウェアアーキテクチャを、システムの構造、システムがサポートしなければならないアーキテクチャ特性（「イリティ（-ility））、アーキテクチャ決定、そして設計指針の組み合わせで構成されるものだと考えている。システムの構造マイクロサービスやレイヤード、マイクロカーネルなどのシステムを実装するアーキテクチャスタイルの種類を指す。よくアーキテクチャの全てだと勘違いされがちです。アーキテクチャ特性(-ility)アーキテクチャ特性はシステムの成功基準を定めるものです。通りの良い単語でいうと非機能要件などが近い。通常、システムの機能とは直接関係しない。システムの機能に関する知識を必要としない。しかし、システムが適切に機能するには、これらの特性への理解が必要となる。SREとしてはこの分野に対して専門性を求められる機会が多い。アーキテクチャ決定アーキテクチャ決定は、システムをどのように構築すべきかのルールを定めるものだ。アーキテクチャ決定は、システムの制約を形作り、何が許されて何が許されないかに関する開発チームの指針となるように行う。設計指針設計指針は、堅苦しいルールではなくあくまでガイドラインです。サービス間通信のすべての条件、選択肢を完璧に網羅するアーキテクチャ決定を定めるのは不可能です。非現実的なコストをかければ別だが。その代わりに、設計指針として、望ましいアプローチに関するガイドを提供する。ソフトウェアアーキテクトへの8つの期待ソフトウェアアーキテクトがどのような役割が求められるかは組織やチームによって違いがあるような気がする。本書ではソフトウェアアーキテクトに対する8つの期待がある。そのうち3つがソフトスキルなのも優秀なソフトウェアアーキテクトが人間と向き合わなければならないのを示している。SREの探求の5章 サードパーティとの協力を円滑に進める重要性でも事業に対する理解と政治の重要性について何度も言及されている。アーキテクチャ決定を下すアーキテクチャを継続的に分析する最新のトレンドを把握し続ける決定の順守を徹底する多様なものに触れ、経験している事業ドメインの知識を持っている対人スキルを持っている政治を理解し、かじ取りするソフトウェアアーキテクチャの法則ソフトウェアアーキテクチャはトレードオフがすべてだ。 ソフトウェアアーキテクチャの第一法則「どうやって」よりも「なぜ」の方がずっと重要だ。ソフトウェアアーキテクチャの第二法則ソフトウェアアーキテクチャのすべてはトレードオフがあるが、どちらを優先しても10年後の結果は誰にも分からなかった。だから、まぁ「なぜ」が重要なんだろうな。悔いが残らない方をチームや組織で選ばなきゃいけないんだろうな。しかし、数ある選択肢の中でなぜその選択がなされたのか他の技術ではだめなのか？ を説明するのは難しい。だから、アーキテクトには技術の深さより幅が求められるんだろうな。基礎の概念は開発に関わる全ての人間は知っておいて良いアーキテクチャにおける重要なトレードオフを理解するには、開発者はコンポーネント、モジュール性、結合、そしてコナーセンスに関する基本的な概念と用語を理解しなければならないが自分がここで説明してもめちゃくちゃ薄く複数の解釈ができるようになってしまうので読んでないのに堂々と語るというには言及が難しく。著者が大事にしている軸になる考え方です。ここについて堂々と語るにはやっぱりちゃんと理解する必要がある。ソフトウェアアーキテクトへの期待されるソフトスキルソフトウェアアーキテクトへの8つの期待でも「対人スキルを持っている」と「政治を理解し、かじ取りする」などがあるがそれ以外にも『ソフトウェアアーキテクチャの基礎』では図解やプレゼンテーションの大切さ、過不足なくチームを管理する方法、開発チーム、ビジネスチームに対してどう向き合うか？ キャリアの形成についての言及もある。読みものに近い気もするがヒントがあるかもしれないです。まとめ『ソフトウェアアーキテクチャの基礎』はシステム設計に関わったことがある人ならばあの時、本書を読んでいればあの時の設計の判断はなにかが変わったかもしれないと思えるほど学びのある一冊でした。読まずに堂々と語るにはやっぱり惜しい書籍です。アーキテクチャには絶対的で正解な選択肢がなくそれぞれにトレードオフがあり地上最強の〇〇は限定的です。脳死で要はバランスとしか言う人にもなりたくない。トレードオフを一定の水準や基準で見極めることができる能力のあるエンジニアになりたいです。カンファレンスや技術ブログ記事で紹介されているツールやシステム構造にすぐに飛びつきたくなる私のような無知で軽率な若者にはとても響きました。SREはプログラマーとしてではなくアーキテクチャ特性の専門家としてアーキテクチャに対する意見を求めれます。アーキテクチャ全体についての知識は得ておくと良いのではないか？ と思いますみなさんも『ソフトウェアアーキテクチャの基礎』及び『ソフトウェアアーキテクチャ・ハードパーツ』をぜひ手に取ってみてください。","link":"https://syu-m-5151.hatenablog.com/entry/2022/10/27/170608","isoDate":"2022-10-27T08:06:08.000Z","dateMiliSeconds":1666857968000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"”thisisunsafe” 魔法の言葉 - ChromeでNET::ERR_CERT_INVALIDが出た時の対応","contentSnippet":"TipsMAC でkubectl port-forward を用いてlocalhost に対してHTTPSアクセスをしたら、Chromeで「この接続ではプライバシーが保護されません　NET::ERR_CERT_INVALID」と表示されてしまうことがある。「詳細設定」を押してもいっても解決策が出てこない。そういう時には半角英数モードでthisisunsafeとキーボード入力しすればアクセスできるようになる。しかも、一定期間すぎたらこのようなメッセージが出てきます。stackoverflow.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/10/18/161000","isoDate":"2022-10-18T07:10:00.000Z","dateMiliSeconds":1666077000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud が公開しているIP rangeから特定のRegionのIP rangeを抜き出す","contentSnippet":"やったことGoogle Cloud はhttps://www.gstatic.com/ipranges/cloud.json というサイトでGoogle Cloud で利用しているIP rangeが公開されている。余談ではありますがAWSは同様に https://ip-ranges.amazonaws.com/ip-ranges.json に公開されている。みんなが大好きなjqコマンドのselectでscopeの値がasia-northeast1 なものだけを抜き出しています。また、サービスによって自分の利用しているリージョン以外へのアクセスが必要なものもあると思うのでアクセスリストを作る際には気をつけてほしいです。curl -s https://www.gstatic.com/ipranges/cloud.json | jq -r '.prefixes[] | select(.scope == \"asia-northeast1\") | .ipv4Prefix' | grep -v null結果(asia-northeast1)で利用されているIPアドレス34.84.0.0/1634.85.0.0/1734.104.62.0/2334.104.128.0/1734.127.190.0/2334.146.0.0/1634.157.64.0/2034.157.164.0/2234.157.192.0/2035.187.192.0/1935.189.128.0/1935.190.224.0/2035.194.96.0/1935.200.0.0/1735.213.0.0/1735.220.56.0/2235.221.64.0/1835.230.240.0/2035.242.56.0/2235.243.64.0/18104.198.80.0/20104.198.112.0/20参考GCPのIPアドレス範囲をリスト化AWSとかGCPが公式に公開されているIP rangeを取得するツールを書いた - 地方エンジニアの学習日記","link":"https://syu-m-5151.hatenablog.com/entry/2022/08/24/115833","isoDate":"2022-08-24T02:58:33.000Z","dateMiliSeconds":1661309913000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2022年版 OpenTelemetryを知れば世界が平和に","contentSnippet":"はじめにOpenTelemetryとはOpentelemetry のコンポーネントOpentelemetry のプロジェクトの仕様とStatusTracingMetricsLogging(Specification にドキュメントがない)BaggageOpenTelemetry のSpanとTraceOpenTelemetry CollectorとはCollector のメリットOpenTelemetry Collector Architecture とはOpenTelemetry とSDKとパッケージOpenTelemetry と自動計装今後のOpentelemetry について次回予告:OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する方法参照リンクはじめに最初は、SRE に成る君に最低限の開発力を身に着けてほしい の解像度の上げる方法の為のGo言語みたいなこと書こうしました。しかし、内容をまとめる能力が乏しく、断念しました。書いている途中で、参考資料として改訂2版 みんなのGo言語 や実用 Go言語、Cloud Native Go を読んでいたら、この内容を齟齬なく伝える自信が完全になくなったので読んでもらえばいいやと自暴自棄になりました。今回は、OpenTelemetry の実装や仕組みに対する言及などが社内でないような気がしました。この共有会ではOpenTelemetry の話を何となく聞かれた時に答えられるようにしていただければと思います。OpenTelemetryプロジェクトを実際に使わなくてもプロジェクトの状況や概念、項目(ログの設計など)を知ることで現在の監視設計や運用、判断に活かせる場面が出てくるかもしれません。現状のOpenTelemetry はログ、メトリクス、トレースの全てカバーできるツールというわけではないですが1年後にはその全てをサポートしてそうな勢いと計画があります。OpenTelemetryとはhttps://opentelemetry.io/docs/concepts/what-is-opentelemetry/OpenTelemetry は、オブザーバビリティの三本柱のログ、メトリクス、トレースの計装と収集を標準化しようとする野心的なプロジェクトです。ベンダーに依存しない実装を提供し、選択したバックエンドにテレメトリーデータを送信する方法を標準化することを目的としています。OpenTracingとOpenCensusの後継的なプロジェクトで新たな標準化ツールとなります。また、仕様が全体的に固まってきたので今後、テレメトリデータを扱うツールとして広まっていくのではないかと思います。 こちらはOpenTelemetryのこれまでとこれから の資料を参考にさせていただきました。💡 Telemetry とは遠隔測定法（えんかくそくていほう）は、観測対象から離れた地点から様々な観測を行い、そのデータを取得する技術です。観測地点に常駐することが物理的・経済的あるいは安全上困難な場合や、観測対象が移動する場合に使用されます。テレメトリー(telemetry) あるいはテレメタリング(telemetering) ということもあります。 装置そのものは、テレメータ (telemeter) と呼ばれています。https://ja.wikipedia.org/wiki/遠隔測定法Opentelemetry のコンポーネントhttps://opentelemetry.io/docs/concepts/components/OpenTelemetryは現在、いくつかの主要コンポーネントで構成されています。仕様すべての実装に対する言語に限らない横断的な要件と実装に必要な事項を記述する。CollectorOpenTelemetry Collectorは、テレメトリデータを受信、処理、およびエクスポートできるベンダーに依存しないプロキシです。複数の形式（OTLP、Jaeger、Prometheus、および多くの商用/独自のツールなど）でのテレメトリデータの受信と、1つ以上のバックエンドへのデータの送信をサポートします。自動計装OpenTelemetry は、サポートされる言語用の一般的なライブラリやフレームワークから関連するテレメトリデータを生成する幅広い数のコンポーネントをサポートします。例えば、HTTP ライブラリからのインバウンドとアウトバウンドの HTTP リクエストは、それらのリクエストに関するデータを生成します。自動計測の使用方法は言語によって異なり、アプリケーションと一緒にロードするコンポーネントの使用を好むか要求するかもしれませんし、コードベースで明示的にパッケージを取り込むのが良いかもしれません。言語ごとのSDKOpenTelemetryには言語SDKもあります。OpenTelemetry APIを使用して、選択した言語でテレメトリデータを生成し、そのデータを優先バックエンドにエクスポートすることもできます。これらのSDKを使用すると、アプリケーションの手動インストルメンテーションに接続するために使用できる一般的なライブラリおよびフレームワークの自動インストルメンテーションを組み込むこともできます。ベンダーは、バックエンドへのエクスポートを簡単にするために、言語SDKの配布を行うことがよくあります。Opentelemetry のプロジェクトの仕様とStatushttps://opentelemetry.io/status/現在、皆さんが関わっている各案件でOpenTelemetry の利用が可能かどうかについて聞かれると思います。何となく聞かれた時に答えられるようにこれ、各シグナルごとにこれぐらいは進んでいるんだと理解していただければと思います。OpenTelemetryは、シグナルごとに開発されています。シグナルとはトレース、メトリクス、バッゲージ、ロギングなどの仕様でサポートされているテレメトリのカテゴリを指しています。シグナルは、分散システム間でデータを相関させるための共有メカニズムのcontext propagation(コンテキストの伝播)の上に構築されています。これらは主に4つで構成されています。Tracinghttps://opentelemetry.io/docs/concepts/signals/traces/API: stable, feature-freezeSDK: stableProtocol: stableNotes:トレース仕様は現在完全に安定しており、長期的なサポートでカバーされています。トレース仕様はまだ拡張可能ですが、後方互換性のある方法でのみ行われます。OpenTelemetryクライアントは、そのトレース実装が完了した時点で、v1.0にバージョンアップされます。Metricshttps://opentelemetry.io/docs/concepts/signals/metrics/API: stableSDK: mixedProtocol: stableNotes:OpenTelemetry Metricsは現在活発に開発中です。データモデルは安定しており、OTLPプロトコルの一部としてリリースされています。メトリックパイプラインの実験的なサポートはCollectorで利用可能です。PrometheusのCollectorサポートは、Prometheusコミュニティと協力して、現在開発中です。Logging(Specification にドキュメントがない)https://opentelemetry.io/docs/concepts/signals/logs/API: draftSDK: draftProtocol: stableNotes:OpenTelemetry Logging は現在、活発に開発が進められています。ログデータモデルはOpenTelemetryプロトコルの一部としてリリースされています。OpenTelemetry プロジェクトへの Stanza の寄贈により、多くのデータフォーマットに対するログ処理が Collector に追加されています。現在、多くの言語でのログアペンダが開発中です。ログ・アペンダーは、トレースやスパンIDなどのOpenTelemetryトレース・データを既存のロギング・システムに付加することができます。OpenTelemetry ロギングSDKも現在開発中です。これにより、OpenTelemetryクライアントが既存のロギングシステムからロギングデータを取り込み、トレースやメトリクスとともにOTLPの一部としてログを出力することができます。OpenTelemetryのロギングAPIは、現在開発中ではありません。まず、既存のロギングシステムとの統合に重点を置いています。メトリクスが完成したら、OpenTelemetryのロギングAPIの開発に焦点を移します。Baggagehttps://opentelemetry.io/docs/concepts/signals/baggage/API: stable, feature-freezeSDK: stableProtocol: N/ANotes:OpenTelemetry Baggage は現在完全に安定しています。Baggage は観測可能なツールではなく、トランザクションに任意のキーと値を付加し、下流のサービスがそれらにアクセスできるようにするためのシステムです。そのため、BaggageにはOTLPやCollectorのコンポーネントはありません。OpenTelemetry のSpanとTracehttps://opentelemetry.io/docs/concepts/observability-primer/OpenTelemetryにおけるトレース情報はSpanとTraceという概念で定義されています。Span: リクエスト内の各処理の情報（e.g. 処理名、実行時間、ステータスコードなどなど）Trace: あるリクエストに対するSpanのまとまりhttps://lightstep.com/opentelemetry/spans  より画像の引用Span はトレースの構成要素で、いくつかの情報を持ちます。複数のスパンをつなぎ合わせて、Trace を作成します。Trace は、多くの場合、各Span が開始および完了した時間を反映するSpan の「Tree」と見なされます。また、Span 間の関係も示します。Span の目的は、プログラムの実行に関する情報を観測可能なツールに提供することです。詳細が含まれている必要があり、Trace は全体像を把握するために必要な情報が含まれます。Loggingでは今後、トレースとリンクできるようにトレースIDを持つようになることが検討されてるようです。個々の情報を含むSpanName名前Start and End Timestamps終了と開始の時間Span ContextSpan Context は、Trace ID と Span IDを提供します。各Span は、Span ID と呼ばれるTrace 内で一意の ID によって識別されます。Span はTraceIDを使用して、Spanとそのトレース間の関係を識別します。Span は、サービスやプロセスの境界を越えて移動するために、Span Contextを必要とします。ログに含めることでログとSpan を紐付けることもできます。Attributesメタデータを含むキーと値のペアのことで、Spanにアノテーションを付けて、追跡している操作に関する情報を運ぶために使用します。Span EventsSpan Event は通常、Spanの期間中の重要で特異な時点を示すために使用されます。Span LinksSpan Links はオプションですが相互に関連付ける為に利用されます。Span StatusステータスはSpanに添付されます。通常、アプリケーションコードに例外などの既知のエラーがある場合は、Span Statusを設定します。Sample Span:        {          \"trace_id\": \"7bba9f33312b3dbb8b2c2c62bb7abe2d\",          \"parent_id\": \"\",          \"span_id\": \"086e83747d0e381e\",          \"name\": \"/v1/sys/health\",          \"start_time\": \"2021-10-22 16:04:01.209458162 +0000 UTC\",          \"end_time\": \"2021-10-22 16:04:01.209514132 +0000 UTC\",          \"status_code\": \"STATUS_CODE_OK\",          \"status_message\": \"\",          \"attributes\": {            \"net.transport\": \"IP.TCP\",            \"net.peer.ip\": \"172.17.0.1\",            \"net.peer.port\": \"51820\",            \"net.host.ip\": \"10.177.2.152\",            \"net.host.port\": \"26040\",            \"http.method\": \"GET\",            \"http.target\": \"/v1/sys/health\",            \"http.server_name\": \"mortar-gateway\",            \"http.route\": \"/v1/sys/health\",            \"http.user_agent\": \"Consul Health Check\",            \"http.Scheme\": \"http\",            \"http.host\": \"10.177.2.152:26040\",            \"http.flavor\": \"1.1\"          },          \"events\": {            \"name\": \"\",            \"message\": \"OK\",            \"タイムスタンプ\": \"2021-10-22 16:04:01.209512872 +0000 UTC\"          }        }全体像を示すTrace  OpenTelemetry のトレースがどのように機能するかを理解するために、コードの計装に関与するコンポーネントのリストを見てみましょう。TracerTracer は、サービス内のリクエストなど、与えられた操作で何が起こっているかについての詳細情報を含むSpanを作成します。Tracer はTracer Provider から作成されます。Tracer ProviderTracer Provider（TracerProviderと呼ばれることもあります）は、Tracerを生成します。ほとんどのアプリケーションでは、Tracer Provider は一度初期化され、そのライフサイクルはアプリケーションのライフサイクルと一致します。Tracer Providerの初期化には、ResourceとExporterの初期化も含まれます。Trace ExporterTrace Exportersは、Trace をコンシューマーに送信します。このconsumer は、デバッグおよび開発時の標準出力、OpenTelemetry Collector、または任意のオープンソースまたはベンダーのバックエンドにすることができます。Trace Contextトレースコンテキストは、トレーススパンに関するメタデータで、サービスやプロセスの境界を越えてスパン間の相関関係を提供します。例えば、サービス A がサービス B を呼び出し、その呼び出しをトレースで追跡したいとします。この場合、OpenTelemetry はトレースコンテキストを使用して、サービス A からトレースの ID と現在のスパンを取得し、サービス B で作成されたスパンがトレースに接続し追加することができるようにします。これは、Context Propagation（コンテキスト伝播）と呼ばれています。Sample Trace        {            \"name\": \"Hello-Greetings\",            \"context\": {                \"trace_id\": \"0×5b8aa5a2d2c872e8321cf37308d69df2\",                \"span_id\": \"0×5fb397be34d26b51\",            },            \"parent_id\": \"0×051581bf3cb55c13\",            \"start_time\": \"2022-04-29T18:52:58.114304Z\",            \"end_time\": \"2022-04-29T18:52:58.114435Z\",            \"attributes\": {                \"http.route\": \"some_route1\"            },            \"events\": [                {                    \"name\": \"hey there!\",                    \"タイムスタンプ\": \"2022-04-29T18:52:58.114561Z\",                    \"attributes\": {                        \"event_attributes\": 1                    }                },                {                    \"name\": \"bye now!\",                    \"タイムスタンプ\": \"2022-04-29T22:52:58.114561Z\",                    \"attributes\": {                        \"event_attributes\": 1                    }                }            ],        }        {            \"name\": \"Hello-Salutations\",            \"context\": {                \"trace_id\": \"0×5b8aa5a2d2c872e8321cf37308d69df2\",                \"span_id\": \"0×93564f51e1abe1c2\",            },            \"parent_id\": \"0×051581bf3cb55c13\",            \"start_time\": \"2022-04-29T18:52:58.114492Z\",            \"end_time\": \"2022-04-29T18:52:58.114631Z\",            \"attributes\": {                \"http.route\": \"some_route2\"            },            \"events\": [                {                    \"name\": \"hey there!\",                    \"タイムスタンプ\": \"2022-04-29T18:52:58.114561Z\",                    \"attributes\": {                        \"event_attributes\": 1                    }                }            ],        }        {            \"name\": \"Hello\",            \"context\": {                \"trace_id\": \"0×5b8aa5a2d2c872e8321cf37308d69df2\",                \"span_id\": \"0×051581bf3cb55c13\",            },            \"parent_id\": null,            \"start_time\": \"2022-04-29T18:52:58.114201Z\",            \"end_time\": \"2022-04-29T18:52:58.114687Z\",            \"attributes\": {                \"http.route\": \"some_route3\"            },            \"events\": [                {                    \"name\": \"Guten Tag!\",                    \"タイムスタンプ\": \"2022-04-29T18:52:58.114561Z\",                    \"attributes\": {                        \"event_attributes\": 1                    }                }            ],        }💡 そのサービスを開発した開発者や初期から参加しているメンバーであれば、特定のリクエストが各サービス(関数)を利用しているのかある程度は把握していると思います。しかし、案件に途中で入ったり、運用をしていくエンジニアからすればそれがどのように繋がっているかなどの情報はドキュメントやログ、実際に実装を見ていく以外に方法がありません。あればあるで嬉しいが無いならないでなんとかなるのもトレーシングが普及しない問題点の一つではないかと邪推しておく。OpenTelemetry Collectorとはhttps://opentelemetry.io/docs/collector/OpenTelemetry Collector は、テレメトリデータの受信、処理、エクスポートの方法について、ベンダーに依存しない実装を提供します。OpenTelemetry Collector は、計装と収集を標準化でいうところの収集を主に担当します。アプリケーションとテレメトリデータの中継役として動作するため各ベンダー固有のテレメトリデータをバックエンド(Jaeger、Prometheus、Fluent Bitなど)の対応したデータ形式に変換したりといった役割を持ちます。そのため、複数のエージェント/コレクタを実行、操作、保守する必要がなくなります。Collector のメリット使いやすさ: デフォルトの設定を用意、よくあるプロトコルのサポート、そのまま使えるパフォーマンス: さまざまな負荷や構成に対応できるように設定することもできますオブザーバビリティ: それ自体が観測可能である拡張性: コアコードに手を入れることなく拡張が可能統合: 単一のコード、エージェントでまたはコレクターとして配置可能でトレース、メトリック、ログ(将来)を扱うOpenTelemetry Collectorは、AgentとGatewayの2つのデプロイメント方法から選ぶことができます。Agent: アプリケーションとともに、またはアプリケーションと同じホストで実行されるCollector インスタンス(バイナリ、サイドカー、デーモンセットなど)Gateway: 通常、クラスタ、データセンター、地域ごとに単独のサービス（コンテナやデプロイメントなど）として稼働する1つまたは複数のCollectorインスタンス。OpenTelemetry Collector Architecture とはhttps://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/design.mdOpenTelemetry Collector Architectureは大まかにReceiver、Processor、Exporterの3つの要素で構成されいます。Receiversどういうフォーマットでどのようにテレメトリデータを受信するかという設定サードパーティのテレメトリデータを受け取って、内部的にTraceとSpanに変換する役割を持つProcessorsテレメトリデータの加工、フィルター、リトライ、バッチ処理等の設定Receiverから送られてきたTraceとSpan情報を特定の条件で加工するExportersテレメトリデータのエクポートに関する設定Processorから送られてきたデータを、Export先のデータ形式に変換し、送信するOpenTelemetry Collector の設定ファイル    receivers:      otlp:        protocols:          grpc:          http:      otlp/2:        protocols:          grpc:            endpoint: 0.0.0.0:55690        processors:      batch:      batch/test:        exporters:      otlp:        endpoint: otelcol:4317      otlp/2:        endpoint: otelcol2:4317        extensions:      health_check:      pprof:      zpages:        service:      extensions: [health_check,pprof,zpages]      pipelines:        traces:          receivers: [otlp]          processors: [batch]          exporters: [otlp]        traces/2:          receivers: [otlp/2]          processors: [batch/test]          exporters: [otlp/2]        metrics:          receivers: [otlp]          processors: [batch]          exporters: [otlp]        logs:          receivers: [otlp]          processors: [batch]          exporters: [otlp]OpenTelemetry とSDKとパッケージhttps://opentelemetry.io/docs/concepts/instrumenting/OpenTelemetryプロジェクトは、各言語ごとにテレメトリデータを送信するパッケージが用意されています。これらはアプリケーションの計測を容易にします。インストルメンテーションライブラリは、言語ごとにコアリポジトリを提供します。自動計測または非コアコンポーネント用の追加のリポジトリを提供する場合と提供しない場合があります。opentelemetry-goTracing はStableGoのコアリポジトリでありテレメトリデータ作成機能やJaeger、Zipkinといった主要なOSSやOTLPにテレメトリデータをexportするための機能を提供しています。Metrics はAlphaメトリクスの機能はまだAlpha提供でいくつかのIssue は積まれている状態  OpenTelemetry Go: Metric SDK * open-telemetryLogging はFrozenTracing のMetrics 2つの機能開発をやっているのでそれらが終わるまではIssue を認めないがopentelemetry-go-contribコア機能でないものや、その他のオープンソースや商用のバックエンドのための実装を含みます。Go言語の場合にここに計装系のコードも含まれているOpenTelemetry と自動計装https://opentelemetry.io/docs/concepts/instrumenting-library/OpenTelemetryプロジェクトは、各言語ごとにテレメトリデータを送信するパッケージが用意されていますが、ライブラリーによっては全てを実装しなくてもよいことがあります。全てとはOpenTelemetry Trace は以下のような手順で作成されます。これらを全て自分でやるのは流石に骨が折れる作業です。1. Exporter 作成2. TracerProvider作成3. Tracer取得4. Span作成上記の手順を生のAPIを叩いても実施してもよいのですが、アプリケーションの特定のミドルウェアやフレームワークとのインタフェースがinstrumentationとして提供されており、2~4 を自動で取得することができます。トレース情報を取り出す便利ライブラリがいくつもあります(トレース、メトリクス、ロギングの全てが自動で取得できる世界線までもう少し)。📝 Registry はOpenTelemetry で利用されるライブラリ、プラグイン、およびその他の便利なツールを確認することができるので確認など確認してみると自分で利用したいツールなどが見つかるかもしれません。https://opentelemetry.io/registry/OpenTelemetryとhttptrace.ClientTraceを使ってHTTPリクエストのlatencyを可視化する を参考にコードを作成しました。OpenTelemetry Collector は使用せずにJaeger のエンドポイントを叩いてる    package main        import (      \"context\"      \"log\"      \"net/http\"      \"net/http/httptrace\"          _ \"go.opencensus.io/resource\"      _ \"go.opencensus.io/trace\"      \"go.opentelemetry.io/otel/attribute\"      \"go.opentelemetry.io/otel/exporters/jaeger\"      \"go.opentelemetry.io/otel/sdk/resource\"      \"go.opentelemetry.io/otel/sdk/trace\"      semconv \"go.opentelemetry.io/otel/semconv/v1.10.0\"          \"go.opentelemetry.io/contrib/instrumentation/net/http/httptrace/otelhttptrace\"      \"go.opentelemetry.io/otel\"    )        func main() {      tracerProvider, err := NewTracerProvider(\"otelhttp_client_trace\")      if err != nil {          log.Fatal(err)      }      defer func() {          if err := tracerProvider.Shutdown(context.Background()); err != nil {              log.Fatal(err)          }      }()      otel.SetTracerProvider(tracerProvider)          ctx := context.Background()      ctx, span := tracerProvider.Tracer(\"main\").Start(ctx, \"main\")      defer span.End()          if err := httpGet(ctx, \"https://3-shake.com/\"); err != nil {          log.Fatal(err)      }    }        func httpGet(ctx context.Context, url string) error {      ctx, span := otel.Tracer(\"main\").Start(ctx, \"httpGet\")      defer span.End()      span.SetAttributes(attribute.Key(\"url\").String(url))          clientTrace := otelhttptrace.NewClientTrace(ctx)      ctx = httptrace.WithClientTrace(ctx, clientTrace)      req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)      if err != nil {          return err      }      _, err = http.DefaultClient.Do(req)      if err != nil {          return err      }      return nil    }        func NewTracerProvider(serviceName string) (*trace.TracerProvider, error) {      // Port details: https://www.jaegertracing.io/docs/getting-started/      collectorEndpointURI := \"http://localhost:14268/api/traces\"          exporter, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(collectorEndpointURI)))      if err != nil {          return nil, err      }          r := NewResource(serviceName, \"v1\", \"local\")      return trace.NewTracerProvider(          trace.WithBatcher(exporter),          trace.WithResource(r),          trace.WithSampler(trace.TraceIDRatioBased(1)),      ), nil    }        func NewResource(serviceName string, version string, environment string) *resource.Resource {      r, _ := resource.Merge(          resource.Default(),          resource.NewWithAttributes(              semconv.SchemaURL,              semconv.ServiceNameKey.String(serviceName),              semconv.ServiceVersionKey.String(version),              attribute.String(\"environment\", environment),          ),      )      return r    }それらをjaeger (イエーガー)に食べさせた結果がこれ今後のOpentelemetry についてhttps://www.cncf.io/blog/2022/07/07/opentelemetry-roadmap-and-latest-updates/各ライブラリーでの対応は別としてこのような発言もあります。Realistically at this point in time, I don’t expect logging to be stable until the end of the year at the earliest but I’d say early next year.現実的に現時点では、ロギングが安定するのは早くても年末ですが、来年の早いタイミングだとは思います。-> OpenTelemetry  を取り巻く環境は来年2023年4月ぐらいにもう一度取り扱いと思います。他にも以下のようなトピックに触れておりました。OpenTelemetryがMetricsのRCに到達.Logs の仕様が安定、Logs Beta の予定.OpenTelemetryへのリアルユーザーモニタリングの追加.OpenTelemetryへの継続的プロファイリングの追加.リモートエージェント管理による操作性の向上.OpenTelemetryに4317番ポートが登録.eBPFとその他のアップデート.とても気になるトピックが多くありますがこの記事では紹介しません。次回予告:OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する方法ざっくりとではありましたがOpenTelemetryに関する技術要素とその概要をまとめました。野心的なプロジェクトでまだ道半ばですが個人的には将来がとても楽しみです。OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する場合、基本的な流れは次のようになります。# Tracing 1. Exporter 作成2. TracerProvider作成3. Tracer取得4. Span作成# Metrics1. Exporter 作成2. MeterProvider　作成3. Meter 作成4. Instrument　作成5. Measurement 作成上記に関しては社内ハンズオンなどで実施していきたいと思います。社内共有会で利用したものだからといって公開するにあたって参照を記載する際に気をつけることを学びました。良い学びです。SRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazon参照リンクOpenTelemetryhttps://opentelemetry.io/ OpenTelemetry roadmap and latest updates https://www.cncf.io/blog/2022/07/07/opentelemetry-roadmap-and-latest-updates/ Spans in OpenTelemetry https://lightstep.com/opentelemetry/spansOpenTelemetryのこれまでとこれからhttps://event.cloudnativedays.jp/o11y2022/talks/1347入門 OpenTelemetry Collectorhttps://event.cloudnativedays.jp/o11y2022/talks/1354OpenTelemetryとgo-chiを繋げてみるhttps://future-architect.github.io/articles/20211020a/ OpenTelemetryとhttptrace.ClientTraceを使ってHTTPリクエストのlatencyを可視化する https://journal.lampetty.net/entry/opentelemetry-httptrace AWS Distro for OpenTelemetry https://aws.amazon.com/jp/otel/ Go と OpenTelemetry https://cloud.google.com/trace/docs/setup/go-ot","link":"https://syu-m-5151.hatenablog.com/entry/2022/07/12/115434","isoDate":"2022-07-12T02:54:34.000Z","dateMiliSeconds":1657594474000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SRE に成る君に最低限の開発力を身に着けてほしい","contentSnippet":"はじめにまず、はじめに皆さんへ言っておきたいことがあります。このドキュメントの目的は皆さんをやる気にさせて一心不乱にコードを書きまくって新機能追加や改善をしてソフトウェアを開発していってほしいというわけではないということです。もちろん、そうなってくれれば嬉しいですが気合が入ったからプログラムを急に書けるようになるわけではないのでそのような目的は一切ありません。また、この文章にはインフラエンジニアがコードを読み書きできなくて良いという意図はなくポジショニングトーク的にSREという単語を利用しておりますので何も言わないでください。SREはそもそも、コードを書かなくてもよいエンジニアではないSREとは、ITサービスの信頼性を高めるために、ITエンジニア（開発者）が信頼性向上のために行う設計やアプローチ、またはこれらを行うチームや役割を指します。Google では、SREチームの50～60%は「Google のソフトウェアエンジニア」で、残りの40～50%は「正規のエンジニア『予備軍』だが、他のメンバーには持っていないスキルを持っているエンジニア(インフラ技術に特化した人材)」を選定しています。そして、そのチームは自動化・省力化するために積極的にプログラムを書く。SREが「System Administrator」ではない最大の特徴は、システムの拡大に伴い、保守運用工数が正比例して増大することのないように、自分たちでプログラムを書いて積極的に自動化・省力化を行います。が今更、そんなことを言うつもりはない。SREで大事なところはそこではない。大切なのは役割や役職としてのSREではなくSREのプラクティスであると思う。「SREの探求」でもそれは１言及されているので異論がある方は読んでから議論しましょう。www.oreilly.co.jpインフラエンジニアからSREになるということSRE　≠　インフラエンジニアという認識は皆さんにもあるとは思います。そもそも、開発力が皆無でコードの読み書きが選択肢になければ問題が起きた時に挙動を把握し続け、ログやメトリクスでとことん確かめていきます。何が起きてるか事実ベースで完全に外からの推論だけで把握するというのは難しい、もしくは不完全です。コードを読めなければ問題を解決するのはいつも本当の偶然か、計画的な偶然か、もしくはそれらを超越した熟練者の直感によるものが多いです。もちろん、直感は素晴らしいです。なぜなら、熟練者の直感は問題が起きた時に直感で全ての問題を見つけて解決していくからです。それらは、高度で本人にさえ言語化不能で本当に超能力者みたいです。私はそのような能力をまだ持ち合わせていないです。が、問題は起きていて解決は迫られてます。直感を身につけるような時間はもう、残されていません。明日の朝にはこの問題を解決して納品しなければリリースに間に合わない。解決や期間的な目処は立てなければなりません。もし、解決方法もどれだけで解決するかも分からないとなればプロジェクトに関わるメンバーは不安になると思います。自社開発のソフトウェアで、自社のエンジニアが書いたコードあればそのエンジニアか所属する組織への依頼をすれば良いでしょう。ですがSREは自社のソフトウェアだけではなくOSSと向き合っていることも多く不具合を気軽に相談できない場合も多いです。私に起こった不具合が設定値によるものなのか？ 実装によるものなのか？ を切り分けができなければOSSのIssue も出すことができません。ちなみに、有償サポートでは、その限りではないと思います(有償サポートがあるなら頼れ)。ソフトウェアを読めることで、問題が起きた時にコードを読み尽くして、負荷試験や本番で挙動を把握し続け、ログやメトリクスでとことん確かめていけばシステムに対する解像度が上がります。プログラムをちゃんと読めて原因の特定、修正がコードレベルでできるようになるという選択肢は確実性を高めます。そのため、ソフトウェアの開発経験がないエンジニアのためにOJTに開発経験を追加してそういった素地を最初に作ってもらいたいと思っています。システムへの解像度をあげてエンジニアとしてのレベルを上げる問題が起こったらログやメトリクスから情報を収集して推論して対応していくことも当たり前のように重要である。しかし、運用をしていたらそれでは解決しない問題にぶつかることもある。そのため、以下のような習慣を是非、身につけてほしいと思っています。各項目についてはこのブログでは深く記載しませんがぜひ、深堀りしてみてください。1.コードがあったら読むコードが読めなければ障害やアラートの原因が最終的に神の怒りになる。OSSの動きが不思議だったら、外から動作を推測するよりコードを読んだ方が確実案件でコードが公開されているなら、それもコードを読んだほうが確実天才ではない限り読んだことの無いコードは書けない。2.Strace でシステムコールを追うLinux にはあるプロセスが呼び出している system call を確認できるコマンドがある使えるといろいろと重宝するので使えるようになりましょう例)パーミッションエラーが発生したがどこが悪いのかログに出てきてない！こんなときにはStraceだ！！！最終的にはLinux プログラミングインターフェースと旅行に行きましょう！それでもダメなら起動せよ！デバッガー(gdbとdelve)！CPUやメモリのボトルネックを調査するためにプロファイリングツール(pprof など) を利用する3. ネットワークトラブル時はTCPパケットを追うパケットは友達！パケットは嘘を付きません！RSTが返されているとか、応答自体がきていないなどの切り分けが必要ログやメトリクスだけではどうしても追いきれない場合がある4.技術ドキュメントを書く検討結果はもちろん、検討過程や思考を記録に残すことが大事色々なやり方がある場合には「〜をする5つの方法」のような書き方構造品質を保つ(構成が適切か、単語ミスはないか、口調はそろっているか、文法は正しいか、textlintをかけているか、構成テンプレートに沿っているか)機能品質を保つ(サービスやビジネスの継続に価値を発揮できているか？)5. OSSのバグがあったら報告するOSS のドキュメントでも良いのでフリーライドしすぎない開発力が必要になるので身につくいつか、一緒に働いてくれるかもしれない誰かが見てるかもしれないさいごにというような社内ポエムを爆誕させていたらそこそこ反応が良かったので再編集してブログにしておきました。もちろん、開発力も大事ですがそれらを通して原理原則を理解して自走しながら課題解決し続ける人の方がもっと価値のあることだとは思っております。皆さんSREへの修行もしくは鍛錬がてら入社を待ってます！3-shake.com去年から同じようなこと言っていてますね、、。syu-m-5151.hatenablog.comSRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2022/06/23/153827","isoDate":"2022-06-23T06:38:27.000Z","dateMiliSeconds":1655966307000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"朝活として最高の書籍である『システム運用アンチパターン』を読んだので読書感想文","contentSnippet":"はじめにSREという信頼性の観点からのプラクティスや運用技術を実施出来るためのプロダクトの開発をしている身からすると『システム運用アンチパターン』はまさに様々な課題がわかりやすく言語化されており素晴らしい書籍で、熟練の運用エンジニアとお話ができるような経験ができました。このエントリーは『システム運用アンチパターン』を読んでみた中での感想文となります。www.oreilly.co.jp『システム運用アンチパターン』目次1章　DevOpsを構成するもの1.1　DevOpsとは？1.2　DevOpsの柱となるCAMS1.3　また別のDevOps本？1.4　本章のまとめ2章　パターナリスト症候群2.1　安全装置ではなく障壁を作ってしまう2.2　ゲートキーパーの導入2.3　ゲートキーパーの分析2.4　自動化によるパターナリスト症候群の解消2.5　承認の目的を把握する2.6　自動化のためのコードの構成2.7　継続的な改善に向けて2.8　本章のまとめ3章　盲目状態での運用3.1　苦労話3.2　開発と運用の役割を変える3.3　プロダクトの理解3.4　運用の可視化3.5　ログを価値のあるものにする3.6　本章のまとめ4章　情報ではなくデータ4.1　データではなく利用者から始める4.2　ウィジェット：ダッシュボードの構成要素4.3　ウィジェットに文脈を与える4.4　ダッシュボードの構成4.5　ダッシュボードの命名4.6　本章のまとめ5章　最後の味付けとしての品質5.1　テストピラミッド5.2　テストの構造5.3　テストスイートの信頼性5.4　継続的デプロイと継続的デリバリ5.5　機能フラグ5.6　パイプラインの実行5.7　テストインフラの管理5.8　DevSecOps5.9　本章のまとめ6章　アラート疲れ6.1　苦労話6.2　オンコールローテーションの目的6.3　オンコールローテーションの設定6.4　アラート基準6.5　オンコールローテーションの配置6.6　オンコールへの補償6.7　オンコールの幸福度を追跡する6.8　オンコール担当中のタスク6.9　本章のまとめ7章　空の道具箱7.1　社内ツールと自動化が重要な理由7.2　なぜ組織はもっと自動化しないのか7.3　自動化に関する文化の問題を解決する7.4　自動化を優先する7.5　自動化の目標を決める7.6　スキルセットのギャップを埋める7.7　自動化のアプローチ7.8　本章のまとめ8章　業務時間外のデプロイ8.1　苦労話8.2　デプロイのレイヤ8.3　デプロイを日常的に行う8.4　頻繁に行うことで恐怖心を減らす8.5　リスクを減らして恐怖心を減らす8.6　デプロイプロセスの各レイヤでの失敗への対応8.7　デプロイアーティファクトの作成8.8　デプロイパイプラインの自動化8.9　本章のまとめ9章　せっかくのインシデントを無駄にする9.1　良いポストモーテムの構成要素9.2　インシデントの発生9.3　ポストモーテムの実施9.4　本章のまとめ10章　情報のため込み：ブレントだけが知っている10.1　どのように情報がため込まれているかを理解する10.2　意図せずに情報をため込んでいる人を認識する10.3　コミュニケーションを効果的に構築する10.4　知識を発見可能にする10.5　チャットツールの有効活用10.6　本章のまとめ11章　命じられた文化11.1　文化とは何か？11.2　文化はどのように行動に影響を与えるか？11.3　文化を変えるには？11.4　文化に合った人材11.5　本章のまとめ12章　多すぎる尺度12.1　目標の階層    12.1.1　組織の目標    12.1.2　部門の目標    12.1.3　チームの目標    12.1.4　目標の確認12.2　どの仕事に取り掛かるかに意識的になる    12.2.1　優先度、緊急度、重要度    12.2.2　アイゼンハワーの意思決定マトリックス    12.2.3　コミットメントにノーと言う方法12.3　チームの仕事を整理する    12.3.1　作業を細分化する    12.3.2　イテレーションの作成12.4　予定外の作業    12.4.1　予定外の作業のコントロール    12.4.2　予定外の作業への対応12.5　本章のまとめ本書のまとめ訳者あとがき索引特徴と感想ハードスキルというよりソフトスキルを得るための書籍である本書のタイトルや目次を見ると、本書はDevOpsの概念やアンチパターンの紹介の書籍かと思われるが CAMS(文化、自動化、メトリクス、共有)についてのソフトスキル(ツールや道具ではなく)を組織や個人で実践するためのHowTo本だという印象を受けました。運用(に関わるソフトウェア)エンジニア版の7つの習慣(語弊あり)。それぞれの章は奥が深く、章で取り上げているものはソフトスキルに絞って知識をバランス良く記載していると感じました。DevOpsとSREの違い今からSREのキャリアを目指す方には混乱させてしまうかもしれないのでざっくり、DevOpsとSREの違いについて少し解説していきます。「class SRE implements DevOps」という考えが良い回答かなと思います。「class SRE implements DevOps」は、「SREはDevOpsというinterfaceの実装である」という意味を表します。「DevOps = 思想」という定義に対し、それを具体化し実装したものがSREであるという考えです。DevOpsにも以下の5点のような考え方がありSREにも似たような考え方がありますよね？組織のサイロの削減（風通しのよい組織の実現）エラー発生を前提とする（100%を目指さない）段階的に変更を行う（一気にすべてを変更しない）ツールと自動化を活用する（サービス成長と正比例で運用工数を増やさない）全てを計測する（モニタリングに基づく数値設定が重要）ただ、上記はあくまで思想、概念でしかなく、具体的な方法論ではありません。これを具体的にどのように行うかを「トイルの削減・自動化」「SLI/SLOの設定による目標定量化」といった形で、誰でも用いられるように体系化させたものがSREといえます。本書はDevOpsのソフトスキル面を主に扱ってるそのため、ソフトウェアの運用に関わる人であればどのレベルの人が読んでも良いと思います。また、本書はSREを目指す方が読んでも学びになる書籍だと思います。まとめ「システム運用アンチパターン」はシステム運用に関わったことがある人があの時、本書を読んでいればなにかが変わったかもしれないと思えるほど学びのある。なぜ、それがイケてないか優しく説明してくれる素晴らしい熟練の先輩との対話のような一冊でした。特に本書の『DevOps文化は必ずしもA地点からB地点へ進むようなものではないことを覚えておいてください。』という言葉はカンファレンスや技術ブログ記事で紹介されているツールやワークフローにすぐに飛びつきたくなる私のような無知で軽率な若者にはとても響きました。それよりもソフトスキルを組織に根付かせることの重要性を様々な視点から本書は教えてくれました。みなさんも『システム運用アンチパターン』をぜひ手に取ってみてください。おまけGoでの開発やSRE/DevOps について雑談 をしたい方を募集してますー！雑談する予定しかしないのですが仕事の話でもキャリアの話でも学生の方でも社会人の方でも気軽にお待ちしております。meety.net参考O'Reilly Japan - システム運用アンチパターンGoogle - Site Reliability Engineering","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/27/070239","isoDate":"2022-05-26T22:02:39.000Z","dateMiliSeconds":1653602559000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"PrometheusのSLO generator であるSloth について雑多な作業ログ入門失敗編","contentSnippet":"はじめにこのブログではPrometheus のSLO generator であるSloth に関して取り上げたいと思っている。正直、業務後の深夜に書いているのでGrafana でDashboards を生成したら感動的なラストシーンということにしてほしい。今回は取り上げないが最近、バージョン1.0.0 になったOpenSLOの 周辺知識も気になっている。OpenSLOについて | フューチャー技術ブログ などはOpenSLOに関して2022 年5月現在で日本語で書かれている文章だと最高に良いと思います。 ナマケモノのイラスト | かわいいフリー素材集 いらすとや より引用SLIを計測しSLOを設定するいきなり、Slothの話をするのも流石に不親切なのでSRE的な話を少しだけします。ITサービスの運用に置いて、信頼性100%と、信頼性99.99%では大きな違いがあります。信頼性100%を実現するためには、99.99%とは異なり膨大な工数を投入する必要があるが、ほとんどのユーザーにとっては「99.999%」が「100%」になったからといって、大きなメリットがないことのほうが多いのである。つまり、100%を目指すことは効率的ではない場面が多いため、各サービスごとに適切な可用性を設定する必要だ。はじめに、SLIですが、これは「Service Level indicator」の略で、提供されているサービスのレベルの性質を定義した計測量である。一般的には以下をSLIとして用いる。リクエストのレイテンシ（リクエストに対するレスポンスを返すまでにかかった時間）エラー率（受信したリクエストを正常に処理できなかった比率）システムスループット（単位時間あたりに処理できるリクエスト数）可用性（サービスが利用できる時間の比率）次に、SLOですが、これは「Service Level Objective」の略で、SLIで計測されるサービスレベルの目標値、または目標値の範囲を指します。例えば、SLOを「年99.99%」と設定すると、「1年のうち52分は稼働しなくてもよい」ということになる。例えば、「1年の間にサービスが30分停止する障害」が生じたとしても、SLOの範囲であればそれは想定の範囲であり、問題ではなくなる。同様の用語で、SLA というのがある。これは「Service Level Agreement」の略で、こちらはITサービスの契約において「この稼働率を下回る場合、金銭的な保証を行う」ことを示す値です。SLIは測定値、SLOは補償を伴わない目標値である点で意味合いが異なる。Sloth の特徴で、Sloth はPrometheusベースのSLOを作成するために、複雑な仕様やプロセスを把握して使用する必要がないように。迅速、簡単、かつ信頼性の高いPrometheus SLO generator(生成)してくれる。生成された記録とアラートのルールに基づき、信頼性の高い均一なSLOの実装を実現します。Kubernetes でCRDなどを用いてサポートしており、OpenSLOも限定的にサポートしています。Sloth が生成するPrometheusのルールは3つのカテゴリーに分類されます。1つ目がSLIです。SlothにおけるSLOはルールはベースとなるもので、ユーザーから提供されたクエリを使用して、エラーサービスレベル（可用性）が何であるかを示すために使用される値を取得するものです。異なる時間帯に対して複数のルールを作成し、これらの異なる結果がアラートに使用されます。2つ目がMetadataです。これらは、残りのエラーバジェットやSLO目標パーセントのような有益なメトリックとして使用されます。これらは、Grafanaダッシュボードなど、SLOの可視化に非常に便利です。3つ目がAlerts でSLIルールに基づくマルチウィンドウ・マルチバーンアラートです。Sloth はサービスレベル仕様書を受け取り、仕様書の各SLOについて、上記のカテゴリーで3つのルールグループを作成します。MetricsSlothが生成したルールは、SLO間で同じメトリック名を共有します。しかし、ラベルは異なるサービス、SLOを識別するためのキーとなる。このようにして、異なるチームやサービス間で、すべてのSLOを記述する統一された方法を得ることが出来ます。Slothが作成し、利用可能なすべてのメトリック名を取得するには、次のクエリを使用します。count({sloth_id!=\"\"}) by (__name__)AlertSlothの SLOアラートは、マルチウィンドウ・マルチバーン方式を採用し、Critical/page とWarning/ticketの2種類のアラートを生成します。また、時間帯によって4種類のAlertを使用します(が割愛)。また、Sloth は自らAlertを発するのではなく、Slothが生成したAlertルールを使ってPrometheusがAlertを発する。Prometheusに接続されたalertmanagerを介してSlack、Pagerdutyなど に通知をトリガーします。sloth.devやっていくGetting started - Sloth を参考にKubernetes上に構築をやっていくPromethus 周りのインストール# Get Helm Repository Infohelm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm repo update# Install Helm Chart :https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#configurationhelm install [RELEASE_NAME] prometheus-community/kube-prometheus-stackSloth のインストールSloth のhelm はこちらにあるので参照してください。github.comhelm repo add sloth https://slok.github.io/slothhelm repo updatehelm install [RELEASE_NAME] sloth/sloth もしくはCRDをデプロイしていきましょう# Sloth CRD is required$ kubectl apply -f ./pkg/kubernetes/gen/crd/sloth.slok.dev_prometheusservicelevels.yaml# Prometheus Operator Rules CRD is required$ kubectl apply -f ./test/integration/crd/prometheus-operator-crd.yamlhelpコマンドをインストールしたらhelp を見る良い習慣です。sloth helpusage: sloth [<flags>] <command> [<args> ...]Easy SLO generator.Flags:  --help            Show context-sensitive help (also try --help-long and --help-man).  --debug           Enable debug mode.  --no-log          Disable logger.  --no-color        Disable logger color.  --logger=default  Selects the logger type.Commands:  help [<command>...]    Show help.  generate [<flags>]    Generates Prometheus SLOs.  kubernetes-controller [<flags>]    Runs Sloth in Kubernetes controller/operator mode.  validate --input=INPUT [<flags>]    Validates the SLO manifests and generation of Prometheus SLOs.  version    Shows version.generatedget-started.ymlと同じ例ですが、Kubernetes で実行するのでCRDを使用した例です。Kubernetesのprometheus-operator PrometheusRules CRDにPrometheusのルールを生成します。sloth.devk8s-getting-started.yml をsloth generate させます。ちなみにnamespace を namespace: default にして実行いたします。$ sloth generate -i k8s-getting-started.yml INFO[0000] SLI plugins loaded                            plugins=0 svc=storage.FileSLIPlugin version=1912e6a window=30d                                                            INFO[0000] SLO period windows loaded                     svc=alert.WindowsRepo version=1912e6a window=30d windows=2                                                                INFO[0000] Generating from Kubernetes Prometheus spec    version=1912e6a window=30d                                                                                                INFO[0000] Multiwindow-multiburn alerts generated        out=- slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d                      INFO[0000] SLI recording rules generated                 out=- rules=8 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d              INFO[0000] Metadata recording rules generated            out=- rules=7 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d              INFO[0000] SLO alert rules generated                     out=- rules=2 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d~~~k8s-getting-started.yml を元にさまざまなファイルが生成されています！眠いので解説はしません# This example shows the same example as getting-started.yml but using Sloth Kubernetes CRD.# It will generate the Prometheus rules in a Kubernetes prometheus-operator PrometheusRules CRD.## `sloth generate -i ./examples/k8s-getting-started.yml`#apiVersion: sloth.slok.dev/v1kind: PrometheusServiceLevelmetadata:  name: sloth-slo-my-service  namespace: monitoringspec:  service: \"myservice\"  labels:    owner: \"myteam\"    repo: \"myorg/myservice\"    tier: \"2\"  slos:    - name: \"requests-availability\"      objective: 99.9      description: \"Common SLO based on availability for HTTP request responses.\"      sli:        events:          errorQuery: sum(rate(http_request_duration_seconds_count{job=\"myservice\",code=~\"(5..|429)\"}[{{.window}}]))          totalQuery: sum(rate(http_request_duration_seconds_count{job=\"myservice\"}[{{.window}}]))      alerting:        name: MyServiceHighErrorRate        labels:          category: \"availability\"        annotations:          summary: \"High error rate on 'myservice' requests responses\"        pageAlert:          labels:            severity: pageteam            routing_key: myteam        ticketAlert:          labels:            severity: \"slack\"            slack_channel: \"#alerts-myteam\"validate構文チェックも可能です$ sloth validate --input=k8s-getting-started.ymlINFO[0000] SLI plugins loaded                            plugins=0 svc=storage.FileSLIPlugin version=1912e6a window=30dINFO[0000] SLO period windows loaded                     svc=alert.WindowsRepo version=1912e6a window=30d windows=2INFO[0000] Validation succeeded                          slo-specs=1 version=1912e6a window=30ddeploygenerate したものをapply していきます$ sloth generate -i k8s-getting-started.yml | kubectl apply -f -Grafana へのログインkube-prometheus のGrafanaは初期ID/PASS のadmin:admin ではないのでパスワードを確認する(ArgoCD でも似たように初期パスワードを取得できる)# user:password -> admin:prom-operator$ kubectl get secret sloth-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echoprom-operatorGrafana へのDashBoard の追加SLO / Detail dashboard for Grafana | Grafana Labs入門失敗Dashboards を生成したら感動的なラストシーン！？このダッシュボードには、各SLOの詳細が表示されますがこれには、http_request_duration_seconds_count にデータが入ってないわ。。。          errorQuery: sum(rate(http_request_duration_seconds_count{job=\"myservice\",code=~\"(5..|429)\"}[{{.window}}]))          totalQuery: sum(rate(http_request_duration_seconds_count{job=\"myservice\"}[{{.window}}]))Dashboards - Sloth にしたいんですけど,,, もう眠いので一旦、終わって公開します。Sloth はとりあえず動かすためのチュートリアルが絶妙に弱くてPrometheusをある程度理解してないとうまく動かせないなーって思いました(小物として)。参考Sloth - SlothSLO / Detail dashboard for Grafana | Grafana LabsPrometheus - Monitoring system & time series database","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/25/165633","isoDate":"2022-05-25T07:56:33.000Z","dateMiliSeconds":1653465393000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ごめん、同窓会にはいけません。今、株式会社スリーシェイクにてソフトウェアエンジニアとして働いております。","contentSnippet":"はじめにこのブログは入社エントリーになります。帰属意識が低い訳でもないのに、どの同窓会に誘われてない私の26歳が終わってしまった。2022年の5月10日には27歳になったりもします。The 27 Clubじゃんと思ったけど何も残してない。26歳は新卒で入社した会社からSREの会社に転職をしました。ちなみに、去年の誕生日には最終出社をキメました。孤独独身男性なもんで26歳の誕生日を1人で焼肉やってる！！！ pic.twitter.com/zuDgnUsibY— nwiizo (@nwiizo) 2021年5月10日  転職後たくさん手を動かせているので個人的には転職に満足しております。また、技術的な事以外でいうと、オンラインでの登壇やアウトプットが増える施策をいくつか社内外で実施できた。これらを達成する為に人を巻き込んで人に頼ることができてるようになったことに自身の成長を感じております。ちなみに新卒で入った会社でしたが送別会などは(コロナを理由に)ありませんでした。やっていき去年の2021年6月1日から株式会社スリーシェイクにてソフトウェアエンジニアとして働いております。2021年06月01日に入社して12ヶ月目に突入いたしましたnwiizoです。\"インフラをシンプルにしてイノベーションが起こりやすい世界を作る\" でお馴染みの株式会社スリーシェイクにてソフトウェアエンジニアとして開発をさせていただいております。一日でも早く入社エントリーを書こうと思っていたら、11ヶ月も経過しておりました。以前より入社エントリーを入社前や直後に書いて理想ばかり語ってるのを見て青く眩しいなって思っていたのでちょうどいいかもしれません。今は怠惰な自分の性格を正当化しました。この記事では入社した理由と株式会社スリーシェイクの魅力について語っていきたいと思います。このブログは絶対的に入社エントリーになります。なぜ、前職を辞めたのか？2017年の新卒で入社したGMOインターネット株式会社を4年2ヶ月で退職いたしました。前職ではホスティングサービスの開発と運用、お名前.comやいくつかの商材サイトが載っている社内コンテナ基盤の開発と運用、エバンジェリストとしての業務を行なっていました。また、新卒エンジニアの技術力向上・適性判断を目的とした研修プログラムでコンテナ技術の講師を任せていただけたりと色々幅広くやってました。退職までのざっくりとした経緯や理由については元々、前職に入社したのは『俺が考える最強のソフトウェア基盤をサービスとして世の中に提供したいよー、いろんなパブリッククラウドに負けたくないよ〜』という感情からでした。入社後、わりと大きな大義を持って働いていたのでたくさんのチャンスをいただきました。が、様々な面での実力不足で実際のサービスの提供に至れませんでした。が、GMOインターネットという会社は「手を上げる文化」を大切にしており、特に新卒エンジニアにはチャンスをくれるいい会社だと思うのでこれを見てる学生の皆さんはオススメです。ので、リンクを貼っておきます。退職時のエントリーsyu-m-5151.hatenablog.com転職についてそんなこんなで、2017年から新卒で入社していろいろやらせてもらってました。が、これからも引き続きサービスの開発を行うために尽力する為に、会社に残る選択肢はありましたが、このまま、残ってもやりたいことをやりきるだけの力(コーディング力云々は除く)を身につけることはできねーなというようなある種の閉塞感みたいなものに心が囚われるようになり(完全なる言い訳)、このまま続けてもだらだらになってしまう気がして良くない。時間は有限だぞ!!！ と、転職することを決意しました。また、第二の理由に家庭の事情があります。前職では「地方でフルリモートワークの業務」というのは原則認められてませんでした。転職のタイミングで、実家の事情で「地方でフルリモートワークの業務」という希望を伝えた上でお声掛けいただいた会社さんと話をさせてもらい、最終的にスリーシェイクに参加することにしました。で元々は「地方でフルリモートワークの業務」を考えていたのですが、家族の助けもあり諸々が解決したおかげで東京に残る事が出来ました。自分自身がオフラインのカンファレンスに刺激をもらって向上心をキープしている部分があり、東京でのイベントに出かけやすい東京に残れて、本当によかったです。スリーシェイクのポイント手段の為なら目的を選ばないタイプのソフトウェア技術者としてSREやKubernetesを中心としたCloud Nativeな技術領域に関わっていきたいと漠然と考えていた。その中でスリーシェイクは技術領域はもちろん、会社としてのビジョンや掲げていることが気に入り、この会社で働いてみたいというのが面談、面接を通して更に強くなっていったからです。あとは、ひとつの会社に所属するだけでいろんな組織やチームのSREとして働けるなんてお得じゃんと思ってしまいました()。何よりも「インフラをシンプルにしてイノベーションが起こりやすい世界を作る」や「社会に蔓延る労苦〈Toil〉をなくすプラットフォーマーになる」をどれだけ躓いても全力でやりきっていける組織だと自分が思ったからです。NARUTOが以前「オレが知りてーのは楽な道のりじゃねェ 険しい道の歩き方だ」ということを言ってましたが吉田 拓真 / スリーシェイク (@taqqma_ikachan) / Twitter は本当にこんな感じのことを毎月の全社会でよく言ってます。スリーシェイクでやっていくことインフラエンジニアっぽいSRE として入社しました。現在はSRE支援事業とバックエンドエンジニアとしてSREのような信頼性の観点からのプラクティスや運用技術を実施出来るためのプロダクトの開発をしております。毎週、SRE Weekly を熟読して、こういうプロダクトを作りたいと常々思うようになっていたので本当に夢のようなお話です。また、アウトプットしないのは知的な便秘ということで引き続きアウトプットもやっていきます。Meetyもやっているのでみんなお話ししましょう。こちらはTwitterでDMをいただければ幸いです。meety.netSREやインフラエンジニアだけではなく様々な職種の募集をしているので皆様！！！！3-shake.com最後に下記のリンクに皆さんへの日々の感謝を正拳突きで表現させていただいております。入社エントリーでもあるのですが明日は誕生日です。いつもありがとうございます！www.amazon.co.jp","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/09/171305","isoDate":"2022-05-09T08:13:05.000Z","dateMiliSeconds":1652083985000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インフラエンジニアが学ぶと良さそうなgRPCサーバーについて","contentSnippet":"3-shake にはSreake共有会 という毎週、火曜日と木曜日に担当者が現場で得た知見などを発表する社内勉強会が開催されています。こちらのブログはそれらを変更修正しております。syu-m-5151.hatenablog.com元々しようとしていたの話Go 1.18 の最新情報←Generics の深い話とかはもう既出すぎて気になる人は読んでるGo でのTDD(が実は20周年なので)←書いてる途中で自分が言うべきことなんてないことに気付く今後、案件で増えるであろう gRPC についてインフラエンジニアが知っておいても良いと思ったという話 ← 今ここTL;DRprotobuf (Protocol Buffers) はデータフォーマットで、JSONの役割を置き換えるものです。一方 gRPC は通信プロトコルで、HTTPの役割を置き換えるものです。gRPC をライブラリやツール、トレンドなどを通してgRPCを知るgrpc.ioRPCとはgRPC がこの世の中に急に爆誕したわけではない。そもそも、サービス間での情報のやり取りをどのように行うかというのは古くからある課題の1つです。その中で利用されているのがRPCがあります。RPCとは、Remote Procedure Callの略で遠隔手続き呼出しと訳されます。すなわち、別の場所にあるプログラムを呼び出そうというのを目的としています。違うアプリケーションロジックをあたかも自分のアプリケーションの処理と同じように扱えることができるというのも特徴です。クライアントはサーバーに対し実行する処理を指定するパラメータや引数として与えるデータを送信し、それに対しサーバーはパラメータに応じた処理を実行してその結果をクライアントに返す、というのがRPCの基本的な流れになります。ちなみに、gRPC以外にもJSON-RPC、XML-RPCなどがあります。gRPCの歴史gRPCは、Googleが開発したRPC技術がベースとなっている。Googleでは多数のコンポーネントを組み合わせてサービスを実現しています。いわゆる、マイクロサービスアーキテクチャでシステムを構築していることで知られるが、これらのサービス間で通信を行うためにgRPCの前身Stubbyと呼ばれる技術が開発されました。ただ、StubbyはGoogleのインフラ以外での利用は想定しておらず、独自の仕様が多く、Stubby で使用されていた技術とコンセプトが近いHTTP/2 などの技術が登場したことから、GoogleはStubbyにこれらの技術を取り入れてオープン化することを決め、それがgRPCです。なお、現在ではgRPCはオープンソースで公開されており、現在はLinux Foundation傘下のCloud Native Computing Foundation（CNCF）によって開発が進められています。grpc.iogRPC についてgRPCではほかのRPCと同様、クライアントがサーバーに対しリクエストを送信し、サーバーはそれに応じた処理を実行してその結果を返すという、クライアント−サーバーモデルを採用している。gRPCでは以下のような特徴があります。HTTP/2 による高速な通信バイナリにシリアライズされて送られてくる小さな容量で転送できる一つのコネクションで複数のres/reqが可能(柔軟なストリーミング形式)ミドルウェアの設定でハマった時にはHTTP/2 の問題なのかgRPCの問題なのか切り分ける必要があると思います。Protocol buffersgRPCではProtocol Buffersのサービス定義ファイルからサーバーおよびクライアント向けのコードを自動的に生成するツールが提供されており、これを利用することで簡単にサーバーおよびクライアントを実装できるようになっている。そのため、クライアントとサーバーが異なる言語で実装されていても、問題なく通信を行うことができるようになっている。クライアント・サーバー間の通信に使用するプロトコル（トランスポート）や、やり取りするデータの表現およびシリアライズ方法については置き換えが可能な設計になっているが、デフォルトではトランスポートにHTTP/2が、データのシリアライズにはProtocol Buffersという技術を使用するようになっており、これをそのまま使用するのが一般的です。Protocol BuffersはGoogleが開発したデータフォーマットで、バイナリデータを含むデータでも効率的に扱えるのが特徴です。このProtocol Buffersについても、さまざまなプラットフォーム・プログラミング言語から利用できるライブラリが提供されている。柔軟なストリーミング形式単方向/双方向ストリーミングRPCに対応している。ちなみに私はこの仕様をきちんと把握してなくて2度辛い思いをしているので記憶の片隅においておいてください。Unary RPC1つのリクエストに対して一つのレスポンスを返す一般的な通信です。誤解を恐れぬ言い方をするとREST API のような挙動。Server streaming RPCクライアントから送られてきた一つのリクエストに対して、複数回に分けてレスポンスを返す通信方式です。最後のレスポンスを返した後も任意にサーバーの情報を変更に応じてクライアントにその情報を送ることができます。Client streaming RPCクライアントからリクエストを分割して送ってサーバーはすべてのリクエストを受け取ってからレスポンスを返します。大きなデータをPOSTしたいときに便利です。Bidirectional streaming RPCクライアントからリクエストが送られてきたときにサーバーとクライアントは一つのコネクションを確立しお互いに任意のタイミングでリクエストとレスポンスを送りあうことが可能になります。他のプロトコルとの違いと連携Web サービスやマイクロサービスで使われるプロトコルの代表格は HTTP/HTTPS と、それを利用した REST API です。 HTTP は非常に柔軟ですが、渡すデータのスキーマが標準化されていないため、異なる言語間の RPC を実装するのは面倒です。 OpenAPI という REST API 用の IDL もありますが、Protocol Buffers と比較すると記述量が多いです。また、JSONとprotobufの重要な違いとして、protobufはフォーマットがスキーマに依存するという点があります。JSONはスキーマがなくても完全なシリアライズ・デシリアライズが可能ですが、protobufのデータをシリアライズ・デシリアライズするにはスキーマ情報が必要です。gRPCは技術的には必ずしもスキーマ依存ではありませんが、実装上はスキーマなしで実装するのは困難です。この技術的制約によりスキーマファースト開発が強制されるのが protobuf + gRPC の強みのひとつです。よく言われるのが、GraphQL です。GraphQL は Facebook が開発したプロトコルで、HTTP 上で処理されますが REST API とは異なり GET/POST などのメソッドやステータスコードに意味を持たせていません。 特徴はスキーマはデータ構造を定義するもので、標準化されたクエリにより任意のデータを取得可能な仕組みになっていることです。gRPC がどのようなものか？gRPC Motivation and Design Principles によればgRPCの基本的なコンセプトとして次のものが挙げられている。サービスはオブジェクトではなく、メッセージはリファレンス（参照）ではない適切な適用範囲とシンプルさフリーかつオープン相互運用性があり、一般的なインターネットインフラ内で利用できる汎用性がありながら、専用のものと比べてパフォーマンス面で一般に劣らないアプリケーションレイヤーと分離された構造ペイロードを問わないストリーミングでの情報伝達に対応同期・非同期の両方に対応通信の中断やタイムアウトをサポート確立された通信を処理しつつ新規接続を止めるようなシャットダウンのサポートデータ流量のコントロール機能デフォルト実装に対して後からさまざまな機能を追加可能APIによる機能拡張が可能メタデータの交換をサポート標準化されたステータスコードこのようなものを頭に叩き込んでいると様々な場面でgRPCの設計がどのような思考でそのようになされているか分かる。gRPC Ecosystemgithub.comgRPCを補完するgRPCエコシステムとして各種サービスが紹介されている。ヘルスチェックやPrometheus での設定などがこちらに紹介されているgRPC-WebgRPC-WebによってgRPC通信をWebでも使うことができる。HTTPサーバーが仲介者として機能することなく、WebアプリがgRPCバックエンドサービスと直接通信できるようになるものです。またクライアントもバックエンドもgRPCでの実装なので完全なエンドツーエンドのgRPCサービスアーキテクチャを作成できることが利点です。protoファイルに記述したらあとは、お互い実装ができるので開発も進められやすいです。github.comgRPC-Gatewayprotoファイルに書かれたサービスの定義を理解し、REST APIに変換できます 。gRPC-GatewayだけでRESTfulなAPIを受け取れます。また、protoファイルからswagger.jsonを自動出力してくれる機能も備わっており、ドキュメント生成に関しても十分です。grpc-ecosystem.github.ioenvoygRPC-GatewayとenvoyはどちらもJsonをgRPCに変換してくれる機能を持ち合わせています。JSONを変換してくれるだけよくGolangでの実装だったら、gRPC-Gatewayでいいのかなと思いますがそれ以外にはEnvoy にはさまざまな機能があるので一気に全部やってしまいたい方にはEnvoyの利用を考えても良いのかな？と思います。www.envoyproxy.iogRPC をライブラリやツールについてインフラエンジニアがgRPC に関わる時は開発というより運用や保守に関してだろう。なので、今回、紹介するツールもそれらに沿って紹介したい。ツールの使い方を調べれば自ずとgRPCの輪郭が見えてくるかと思います。Awesome gRPC はgRPC に 関するキュレーションを行うリポジトリ。大体のツールはここを確認すれば良い。https://github.com/grpc-ecosystem/awesome-grpcgrpc_cligrpc/command_line_tool.md at master · grpc/grpcgRPC の公式リポジトリに同梱されている grpc_cli は公式の gRPC クライアントツールといえますが、最低限の機能しか備えていません。例えば他の gRPC クライアントツールではほぼ実装されているメタデータの送信ができない、JSON 形式でのリクエスト内容の記述を受け付けられないといった問題があります。また、インストールするためにはソースコードからビルドする必要があり煩雑なのであまり、使われていません。gRPCurlhttps://github.com/fullstorydev/grpcurl最も使われている gRPC クライアントツールです。現在も活発にメンテナンスされています。機能面でもたいていのユースケースは網羅されており、機能の不足で困るようなことはほとんどないでしょう。prototoolhttps://github.com/uber/prototoolPrototoolは Uber Technologies によって開発された Protocol Buffers のユーティリティツールです。Prototool には gRPC のエンドポイントを呼び出せるサブコマンドが付属しています。ただし、このサブコマンドは fullstorydev/grpcurl に大きく依存しており、実質 gRPCurl のサブセットとなっています。現在は Protocol Buffers のユーティリティツールとして Buf を推奨するしています。Bufhttps://github.com/bufbuild/bufProtocol Buffers のユーティリティツール 戦争に勝ち抜いたと言っても良い buf は自動ファイル検出、正確なlintとbreaking checkersの構成を選択することができたり、エラー出力はどのエディターでも簡単に解析可能(vs Code はさまざまなツールが動くが、vim はこれぐらいしか、プラグインがうまく動かない)、コンパイルの高速化、protocのプロトコルプラグインとして使用する。gRPCUIhttps://github.com/fullstorydev/grpcuigrpcuiは、ブラウザ経由でgRPCサーバと対話するためのコマンドラインツールです。Postman のようなものですが、REST ではなく gRPC API のためのものです。evansgRPC クライアントツールです。REPL モードで手軽に手動テストを行えますのでデバッグの時にあるとめちゃくちゃ便利です。https://github.com/ktr0731/evansJSON-to-ProtoJSONを即座にProtobufに変換してくれるツールになります。JSON-to-Proto次回予告:gRPC を使ったアプリケーション開発の流れそれでは、gRPCを使ったアプリケーション開発を行う場合、実際にどのような手順を踏めば良いかを紹介していこう。この場合の基本的な流れは次のようになる。Protocol Buffersを使ったサービスの定義サービス定義ファイルからのコードの生成生成したコードに独自の自前の実装を追加する上記に関してはハンズオンなどで実施していきたいと思います。また、2022年4月27日に「Protocol Buffers/gRPC を安全に書き進めるためのエトセトラ」と題してOWASP Fukuoka Meeting #6にて登壇いたしますーowasp-kyushu.connpass.com死霊👻 はこちらです speakerdeck.com参考文献公式資料grpc.iogRPC の公式サイトです。仕様だけでなく、各言語のチュートリアルもあります。grpc.github.io詳細なドキュメント群です。gRPC over HTTP2上記サイトの一ドキュメントです。HTTP/2 をどう利用しているかの仕様書です。developers.google.com/protocol-buffersProtocol Buffers の公式サイトです。The complete gRPC courseGoとJavaで開発できるチュートリアルです。gRPC: Up and RunninggRPC と Protocol Buffers の本です。Securing your gRPCApplicationKubeCon 2019 NA のセッションの一つで、gRPC の認証・認可の実装方法を詳しく解説しています。","link":"https://syu-m-5151.hatenablog.com/entry/2022/04/12/130411","isoDate":"2022-04-12T04:04:11.000Z","dateMiliSeconds":1649736251000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"samber / lo はGoperである私を愚直なfor もしくは筋肉信仰から救ってくれるのか？","contentSnippet":"はじめにGo 1.18 がリリースされました。Go 1.18でシュッとGenerics を手軽に良さを実感する方法としてsamber/lo があります。  もちろん、Tutorial: Getting started with generics で完全に理解できるならそちらの方が良いですし、これを終わった後でやることも推奨です。その他のリリースパーティや勉強会もとても勉強になりますが とにかく、samber/lo 便利なので紹介させてください！！！！！！！go.dev今回はとても大きな変更です。Generics が入りました。構成としては2つ。Type parameterType sets参考資料DevFest Tokyo 2021 でmattn さんが発表したスライド＆動画がとても分かりやすいので是非、見てみてください。docs.google.comwww.youtube.com全てfor 文で解決するのか？- そう、全て筋肉が解決してくれるGolang にはuniq メゾットのようなものがなく、重複のある slice に対して独自に処理を実装しなければいけなかった。愚直にfor を回すの結果として最速だからである。arr := []string{\"Samuel\", \"Marc\", \"Samuel\"}m := map[string]bool{}for _, ele := range arr {    if !m[ele] {        m[ele] = true        uniq = append(uniq, ele)    }}fmt.Printf(\"%v\", uniq) // [\"Samuel\", \"Marc\"]Go Playground - The Go Programming Languageどういうことかというと、重複キーがあるので、同様のキーを持つmapの場合は新しく値を上書きしないみたいな処理を書かなければならなかった。m[\"Samuel\"] = true は一度目はこれが呼ばれるけど、二度目はすでにtrueなので if句の中に入ってず、resultにSamuelが二度入ることがないという様な仕組みです。とにかく、全てをfor で扱い全ての型を制御するマッチョでした。ema-hiro.hatenablog.com全てfor 文で解決するのか？- samber/lo とか？Golang にはuniq メゾットのようなものがなく、重複のある slice に対して独自に処理を実装しなければいけなかったがsamber/lo というプロジェクトではGo 1.18 のGenerics を使うことによってreflect より早くforとも遜色なく動作するヘルパーを提供します。他にもいくつもの ヘルパー がありますが今回はuniq のみ紹介します。pkg.go.devpackage mainimport (    \"fmt\"    \"github.com/samber/lo\")func main() {    arr := []string{\"Samuel\", \"Marc\", \"Samuel\"}    names := lo.Uniq[string](arr)       fmt.Println(names) // []string{\"Samuel\", \"Marc\"}}uniqValues := lo.Uniq[int]([]int{1, 2, 2, 1})// []int{1, 2}実装をみるとこんな感じでmapと空のstructを使う方法でuniq が実装されている。lo/slice.go at v1.10.1 · samber/lo · GitHubfunc Uniq[T comparable](collection []T) []T {    result := make([]T, 0, len(collection))    seen := make(map[T]struct{}, len(collection))    for _, item := range collection {        if _, ok := seen[item]; ok {            continue        }        seen[item] = struct{}{}        result = append(result, item)    }    return result}とにかく、for で愚直に回す言語から多少はスマートな解決ができる様になった(もしくは今後、期待ができる様になった)。最後にこの記事を読んで興味が湧いたら元のProposalやTutorial: Getting started with generics を読んでみてください。自分も何度かやってみて読んでみて使える様になりたいと思ってます。また、Go本体にも機能として追加される日を楽しみしてます。github.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/03/16/122810","isoDate":"2022-03-16T03:28:10.000Z","dateMiliSeconds":1647401290000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"3-shake エンジニアのブログ記事まとめサイト「3-shake Engineers' Blogs」を公開しました。","contentSnippet":"3-shake Engineers' Blogs、爆誕す！3-shake inc. に所属するエンジニアが執筆したブログ記事をまとめたサイト、3-shake Engineers' Blogsを公開しました。blog.3-shake.comこちらは、@catnoseさんがOSSとして公開している、team-blog-hubをfork させていただき、Ubie さんのUbie Engineers' Blogsを参考にして作成いたしました。なぜ、作ったのか？3-shake には現在、公式のテックブログ(Sreake のブログ | sreake.com | 株式会社スリーシェイク というブログ)があります。が、メンバーが自発的にブログをポストしているわけではありません(別に良い悪いではなく)。理由はいろいろあると思いますが、テックブログは続かない - 何サイトか潰した後にブログが有名な企業に転職しての気づきと反省｜久松剛／IT百物語の蒐集家｜note にあるようないくつかの要素が原因かと思っています。が、3-shake がアウトプットしない文化という訳では決してありません。3-shake には現在、Sreake共有会 という毎週、火曜日と木曜日に担当者が現場で得た知見や調査した内容を発表する社内勉強会が開催されておます。これのポストは既に100件近く内部資料として溜まっており、レベルも相応に高いです。それらを対外的なアプトプットとして出せて、かつ、個人のブログでアウトプットしたほうがアウトプットするモチベーションも上がるのでは？という考えのもとに作成いたしました。最後にこれらの取り組みが3-shake を知っていただけることに多少なりとも繋がれば良いと思います。ちなみに、リポジトリをfork した後に社内調整をして、公開までいたしました。社会人力の低さを感じましたが3-shake が大切にしている価値観として5倍速というのがあるので許される気がしてます。@nwiizo さんのご尽力もあり、流行りに乗っかってみました笑うちのメンバーのブログをぜひ見てみてくださいー— TakuyaTezuka@3-shake (@tt0603) 2022年3月15日  告知また、3-shake で働くことに興味がある方は、採用サイトやホームページに詳しい情報を掲載していますのでご覧くださいwww.wantedly.com今週の金曜日の2022年3月18日に 3-shake SRE Tech Talk #3 というイベントがあって技術顧問 のまつもとりーさんが「コンテナの研究開発から学ぶLinuxの要素技術」と題してお話してくれるので皆様にも参加してほしいです3-shake.connpass.com参考資料zenn.devnote.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/03/15/153309","isoDate":"2022-03-15T06:33:09.000Z","dateMiliSeconds":1647325989000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kind を利用してFeature Gates のGRPCContainerProbe を有効にしたKubernetes クラスターを構築してアルファー機能のgRPC Health Checkを試したいなー","contentSnippet":"Kind でGRPCContainerProbe がやりたいよはじめにKubernetesではLiveness & Readiness Probeを使って、Pod内のコンテナ、プロセスのヘルスチェックが行える。Kubernetes上で動くgRPCサーバーのヘルスチェックする際にはgrpc-health-probeで簡単に実装できます。readinessProbe やlivenessProbe,startupProbeにexec のcommand として実装する必要がある。どういうような方式があってみたいなのはHealth checking gRPC servers on Kubernetes | Kubernetes を参照していただければと思います。現行の場合にはこのように設定が必要  containers:  - name: server    image: \"[YOUR-DOCKER-IMAGE]\"    ports:    - containerPort: 5000    readinessProbe:      exec:        command: [\"/bin/grpc_health_probe\", \"-addr=:5000\"]      initialDelaySeconds: 5    livenessProbe:      exec:        command: [\"/bin/grpc_health_probe\", \"-addr=:5000\"]      initialDelaySeconds: 10tomioka-shogorila.hatenablog.comgRPC health checking が alpha feature として追加この、方式ではDockerfile内 にgrpc_health_probeを入れなくてはいけません。で、2022年2月で最新のKubernetes v1.23 では built-in gRPC health checking が alpha featureとして追加されました(同僚に教えてもらいました)。kubernetes.ioそのため、Kubernetes上で動くgRPCサーバーのヘルスチェックする際にbuilt-in でできるようになりました。  containers:  - name: server    image: \"[YOUR-DOCKER-IMAGE]\"    ports:    - containerPort: 5000    readinessProbe:            grpc:              port: 5000    livenessProbe:            grpc:              port: 5000しかし、これらの機能はまだ、alpha feature で機能 です。なので、defaultでは無効です。もし、試したい場合には--feature-gates として有効にしてあげればならないkubernetes.ioローカルでKubernetes クラスターを構築するにはいくつか方法があるのですが今回は、Kind を利用しているので今回もこちらを利用する。Kind でFeature Gates を利用するにはyaml で以下のように true にすることで適応できる。今回はGRPCContainerProbeをtrue にすれば良い。kubeadm でできることはKind でも大体できるのでkubeadmConfigPatches みたいな設定も忘れたくない。kind: ClusterapiVersion: kind.x-k8s.io/v1alpha4name: featuregatesnodes:- role: control-plane  image: kindest/node:v1.23.3@sha256:0df8215895129c0d3221cda19847d1296c4f29ec93487339149333bd9d899e5afeatureGates:  GRPCContainerProbe: truegithub.com最後にO11yCon での資料作成があるのにブログを書いてしまった。試験前に漫画を読み始めるみたいな感じでブログを書いてしまった。13歳からやってることは変わりません。お時間があれば見に来てください。event.cloudnativedays.jp","link":"https://syu-m-5151.hatenablog.com/entry/2022/02/22/112713","isoDate":"2022-02-22T02:27:13.000Z","dateMiliSeconds":1645496833000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true}