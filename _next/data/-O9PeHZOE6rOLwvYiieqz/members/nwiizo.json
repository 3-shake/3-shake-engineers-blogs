{"pageProps":{"member":{"id":"nwiizo","name":"nwiizo","role":"Software Developer","bio":"The Passionate Programmer","avatarSrc":"/avatars/nwiizo.jpeg","sources":["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],"includeUrlRegex":"","twitterUsername":"nwiizo","githubUsername":"nwiizo","websiteUrl":"https://nwiizo.github.io/"},"postItems":[{"title":"OpenTelemetryについて調べる時に見るページ","contentSnippet":"はじめにOpenTelemetryは、分散システムの可観測性を向上させるためのオープンソースのフレームワークです。アプリケーションのパフォーマンス、動作、エラーなどを追跡し、収集されたデータを分析および視覚化することで、システムの健全性を監視し、問題の早期発見と解決に役立てることができます。約2年前にOpenTelemetryについてブログに書きましたが、その内容は現状と大分差異があるように感じます。OpenTelemetryプロジェクトは急速に発展しており、公式ページの充実や新しい機能や改善が続々と追加されています。また、多くの組織がOpenTelemetryを採用し、勉強会などで資料を公開したり、オープンソースおよび商用の可観測性ツールとの連携も進んでいます。syu-m-5151.hatenablog.com書籍も出ました。こちらも書評を書いている途中です(ちゃんとします)。Learning OpenTelemetry (English Edition)作者:Young, Ted,Parker, AustinO'Reilly MediaAmazon本記事では、OpenTelemetryについて調べる際に参考になるページを紹介します。オススメがあればDMなどしてください。はじめに紹介するページについて1. The main OpenTelemetry website2. The OpenTelemetry GitHub organization3. The OpenTelemetry Enhancement Proposal repository4. The OpenTelemetry specification5.OpenTelemetry Semantic Conventions6. Organizations that have adopted OpenTelemetry7. OSS and commercial observability tools that support OpenTelemetry紹介するページについて以下のページは、OpenTelemetryについて学ぶ際に役立つ情報を提供しています。1. The main OpenTelemetry website OpenTelemetryプロジェクトの公式ウェブサイトです。 プロジェクトの概要、ドキュメント、ブログ、イベントなどの情報が掲載されています。 OpenTelemetryを始めるための出発点として最適なページです。2. The OpenTelemetry GitHub organization OpenTelemetryプロジェクトのGitHubオーガニゼーションページです。 各プログラミング言語のSDKやツール、仕様などのリポジトリが管理されています。 コードの閲覧、イシューの確認、プルリクエストの提出などができます。3. The OpenTelemetry Enhancement Proposal repository OpenTelemetryの拡張提案（OTEP）を管理するリポジトリです。 新機能や変更の提案、議論、承認などのプロセスが記録されています。 OpenTelemetryの開発方針や将来の計画を知るのに役立ちます。4. The OpenTelemetry specification OpenTelemetryの仕様を定義しているリポジトリです。 API、SDK、データモデル、セマンティック規約などの詳細な仕様が記載されています。 OpenTelemetryの実装や互換性を理解するための重要なリソースです。5.OpenTelemetry Semantic Conventions OpenTelemetryのセマンティック規約を定義しているリポジトリです。 属性、メトリック、リソース、イベントなどの命名規則や意味づけが規定されています。 一貫性のあるデータ収集とカタログ化を実現するための指針となります。6. Organizations that have adopted OpenTelemetry OpenTelemetryを採用している組織の一覧ページです。 各組織の名前、ロゴ、採用事例などが紹介されています。 OpenTelemetryの実際の利用状況や適用範囲を知ることができます。7. OSS and commercial observability tools that support OpenTelemetry OpenTelemetryをサポートしているオープンソースおよび商用の可観測性ツールの一覧ページです。 各ツールの名前、ロゴ、説明、リンクなどが掲載されています。 OpenTelemetryと連携可能なツールを探す際に便利です。","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/09/160824","isoDate":"2024-04-09T07:08:24.000Z","dateMiliSeconds":1712646504000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"なれる!SRE - Becoming SREで学んだこと","contentSnippet":"はじめにエンジニアとして就職する前に読んだ「なれる!SE 2週間でわかる?SE入門」の内容があまりにも厳しく、業界に就職するのが怖くなったことを覚えています。本の中に登場する中学生の少女にしか見えない凄腕のSE、室見立華さんのような人物は現実には存在しないでしょうが、実際の業界には彼女のような凄腕エンジニアや年齢不相応な技術力を持つ人間も確かに存在します。なれる！SE ２週間でわかる？ＳＥ入門 (電撃文庫)作者:夏海 公司,IxyKADOKAWAAmazon私は「なれる!SE」が好きすぎるあまり、「なれる!SRE」というタイトルのクソみたいな文章を吐き出したこともありましたが、そのクオリティがあまりにも低かったため、外には公開せずに留めておきました。そんな中、SREの探求の原著者であるDavid Blank-Edelman(otterbook)氏による「Becoming SRE」が 2024年2月にリリースされました。learning.oreilly.com本書では、SREの基本的な考え方や文化について解説し、SREになるために必要なスキルや知識、実際の仕事内容を紹介しています。また、組織にSREを導入するために必要な要件やうまく定着させるためのポイント、SREと他部門との協働について言及し、組織の中でSREを成長・成熟させていくための方法論を提示しています。はじめに『Becoming SRE』の構成Part I: Introduction to SREPart II: Becoming SRE for the IndividualPart III: Becoming SRE for the OrganizationPart I: Introduction to SREChapter 1. First Things FirstChapter 2. SRE MindsetChapter 3. SRE CultureChapter 4. Talking About SRE (SRE Advocacy)II. Becoming SRE for the IndividualChapter 5. Preparing to Become an SREChapter 6. Getting to SRE from…Chapter 7. Hints for Getting Hired as an SREChapter 8. A Day in the Life of an SREChapter 9. Establishing a Relationship to ToilChapter 10. Learning from FailurePart III. Becoming SRE for the OrganizationChapter 11. Organizational Factors for SuccessChapter 12. How SRE Can FailChapter 13. SRE from a Business PerspectiveChapter 14. The Dickerson Hierarchy of Reliability (A Good Place to Start)Chapter 15. Fitting SRE into Your OrganizationChapter 16. SRE Organizational Evolutionary StagesChapter 17. Growing SRE in Your OrgChapter 18. Conclusionおわりにこれらの内容は、SREを目指す個人だけでなく、組織としてSREを取り入れようとする企業にとっても、大変参考になるのではないでしょうか。「なれる!SE」に感化されて書いた拙い文章とは異なり、「Becoming SRE」は、SREという職種について、より深く理解するための良書になると期待しています。2024年2月に出版されたのですが、SREに関心のある方は、ぜひ一読してみることをおすすめします。翻訳本が出版されるのが今からとても楽しみです。Becoming SRE: First Steps Toward Reliability for You and Your Organization (English Edition)作者:Blank-Edelman, David N.O'Reilly MediaAmazon『Becoming SRE』の構成『Becoming SRE』は、Site Reliability Engineering (SRE) の入門書であり、個人と組織の両方を対象に、SREをどのように始めるべきかを解説しています。著者は、SREに関する豊富な知識と経験を持ち、多くの人々との対話を通じて得た洞察を本書に凝縮されています。本書は大きく3つのパートに分かれており、それぞれが独立した内容となっているが、全体を通して読むことで、SREの本質的な理解が深まる構成になっています。Part I: Introduction to SRE第1部では、SREを始めるにあたって必要な基礎知識が提供されている。特に、第2章ではSREのマインドセットについて詳しく解説されており、SREの根底にある考え方や価値観を理解することができる。この章は、SREに関する議論を進める上で欠かせない土台となるため、第2部と第3部を読む前に必ず読むべき内容となっている。また、SREに関連する重要な概念や用語についても丁寧に説明されているため、初学者にとっても分かりやすい内容になっている。Part II: Becoming SRE for the Individual第2部では、個人としてSREを始めるための具体的な方法論が述べられている。SREに必要なスキルセットや知識、学習方法などが詳細に紹介されており、SREを目指す人にとって実践的な指南書となっている。また、SREの日常業務やキャリアパスについても言及されているため、SREという職種をより深く理解することができる。著者自身の経験や、他のSREエンジニアとの対話から得た知見も随所に盛り込まれており、生きたアドバイスが得られる内容になっている。Part III: Becoming SRE for the Organization第3部では、組織としてSREを導入・発展させるための指針が提示されている。SREの導入に必要な要件や、組織文化との適合性、他部門との協働など、SREを組織に定着させるためのポイントが詳しく解説されている。また、SREチームの構築や育成、SREプラクティスの継続的な改善についても言及されており、組織としてSREを成功させるためのヒントが数多く提供されている。さらに、実際にSREを導入した企業の事例も紹介されているため、具体的なイメージを持ちながら読み進めることができる。第2部と第3部は、読者の関心に応じてどちらを先に読んでも構わないが、個人と組織は密接に関連しているため、両方を読むことで理解がより深まるだろう。また、最後に収録されているベテランSREエンジニアからの助言は、SREの本質を捉えた良い内容になっており、SREを志す人にとって大きな励みになるはずだ。本書の特徴の一つは、SREに関する他の優れた書籍や情報源を数多く参照していることだ。著者は、自身の知見だけでなく、SREコミュニティの集合知を積極的に取り入れることで、読者により広い視野を提供している。また、SREの実装や解釈は組織によって異なり得ることを認めた上で、SREについての対話を促していることも重要なポイントだ。著者は \"SRE should be a conversation, not a doctrine.\"（SREは教義ではなく、会話であるべきだ）というメッセージを発しており、SREをめぐる活発な議論の重要性を呼びかけている。『Becoming SRE』は、SREの入門書でありながら、奥深い内容を含んだ一冊だ。初学者から経験者まで、幅広い読者に対して、SREについての理解を深め、実践するための指針を提供してくれる。SREに関心を持つ全ての人にとって、必読の書と言えるだろう。Part I: Introduction to SREChapter 1. First Things First本章は、SREについての理解が深めるための章。著者が提示したSREの定義、「Site reliability engineering is an engineering discipline devoted to helping organizations sustainably achieve the appropriate level of reliability in their systems, services, and products.」は、SREの本質をよく捉えていると感じた。この定義の中で特に重要な3つの単語として、著者が挙げたのは \"Reliability(信頼性)\", \"Appropriate(適性)\", \"sustainable(持続可能性)\" です。システムの信頼性は、組織の収益、評判、従業員の健康などに直結する重要な要素であり、SREの中核をなすものです。また、100%の信頼性を目指すのではなく、SLI/SLOを用いて適切な信頼性のレベルを見極めることが肝要だと説く点も納得できる。そして、信頼性の追求は、人的リソースの持続可能性とのバランスを考慮しなければならない。過度な信頼性の追求が、エンジニアの疲弊を招いては本末転倒です。2014年のSREconで行った講演では、SREの要諦が端的に表現されており、現在でも色褪せない洞察に満ちている。Ben Treynor Sloss氏によれば、SREとは次のような特徴を持つ組織だという。コーダーのみを雇用し、サービスに対するSLAを設定する。そして、そのSLAに対する性能を測定・報告し、エラー予算を活用してゲートローンチを行う。SREチームとDEVチームの間で人材を共有し、SREチームの運用負荷は50%に抑えつつ、運用作業の5%をDEVチームと共有する。オンコールチームは少なくとも8人、できれば6×2の体制を取り、1シフトあたりのイベント数は最大2件までとする。イベントが発生した際には、必ずポストモーテムを行う。ポストモーテムでは非難を避け、プロセスと技術に焦点を当てた議論を行うことが重要です。つまり、SREとは、高い信頼性を持つシステムを構築・運用するための体系的なアプローチであり、エンジニアリングと運用のベストプラクティスを組み合わせたものと言えるとおもいます。www.youtube.comSREとDevOpsの関係性については、本書で提示された3つの見方がそれぞれ示唆に富んでいる。1つ目の「SREはDevOpsの一実装である」という見方は、SREとDevOpsが共有する理念や手法に着目したものです。両者はともに、開発と運用の協調を重視し、自動化やツールの活用を推進する点で共通している。ただし、著者が指摘するように、DevOpsが特定の方法論やツールを規定しないのに対し、SREはより規範的（prescriptive）なアプローチを取る傾向があります。2つ目の「SREの信頼性に対するDevOpsのデリバリー」という対比は、両者の目的の違いを浮き彫りにしている。SREが systems の信頼性（reliability）の確保を最重要視するのに対し、DevOpsはソフトウェアのデリバリー（delivery）に主眼を置く。もちろん、信頼性の高いシステムを迅速にデリバリーすることは、両者に共通する目標ではあるが、力点の置き方が異なります。3つ目の「SREとDevOpsでは、関心の方向性が異なる」この言葉はSREとDevOpsの関心の方向性の違いを鮮やかに描き出している。SREは本番環境から出発し、「本番環境の信頼性を確保するために、開発者は何をすべきか」という観点から、開発の方向へと関心を向ける。一方、DevOpsは開発者の環境から出発し、「開発者が書いたコードを、いかにして本番環境に迅速かつ安全にデリバリーするか」という観点から、本番環境の方向へと関心を向ける。Figure 1-2. The Limoncelli model of SRE, DevOps, and Agile strategies. Modified from the original in Seeking SRE (O’Reilly, 2018). より引用この違いは、両者が重視するツールや手法にも反映される。例えば、SREはモニタリングやインシデント管理、カオスエンジニアリングなどの運用面のツールを重視するのに対し、DevOpsはCIツールやコンテナ技術などのデリバリーを加速するツールを重視する傾向があります。ただし、著者が強調するように、SREとDevOpsは二者択一ではなく、むしろ補完的な関係にあると捉えるべきだろう。組織の規模やビジネス特性、技術的成熟度などに応じて、SREとDevOpsの手法を適切に組み合わせることが肝要です。このへんは可視化されているDevOps Topologiesを参考にしても分かりやすいかもしれないです。web.devopstopologies.com例えば、スタートアップのような小規模な組織では、DevOpsの手法を全面的に採用し、エンジニア全員がデリバリーと運用の両方に携わるのが適切かもしれない。一方、大規模なシステムを運用する組織では、SREの手法を導入し、信頼性の確保に特化したチームを設置することが有効だろう。いずれにせよ、SREとDevOpsのどちらか一方を選ぶのではなく、両者の長所を活かし、組織の文脈に合わせて柔軟に適用していくことが重要です。そのためには、両者の理念や手法を深く理解し、自組織の目的や制約に照らし合わせて、最適な方法論を構築する必要があります。本書の第1章で提示されたSREとDevOpsの関係性に関する考察は、そのための出発点として大変良いものだった。今後は、本書で得た知見を土台に、SREとDevOpsの実践方法を探求するときに活用していきたい。。つまり、SREとは、高い信頼性を持つシステムを構築・運用するための体系的なアプローチであり、エンジニアリングと運用のベストプラクティスを組み合わせたものと言えるとおもいます。Chapter 2. SRE Mindset本章は、著者自身の経験と、他のSREとの対話から得られた洞察を基に、SREのマインドセットを形作る大切な要素について分かりやすく説明されていました。最初に出てくる \"システムはどのように動作しているのか？どのように失敗するのか？\" という問いかけは、SREの思考法の根っこにあるものだと感じました。システムの信頼性を追求するには、その動作原理と障害パターンを徹底的に理解する必要があります。著者が強調しているように、SREにとって大切なのは \"どのように動作すべきか\" ではなく \"実際の本番環境ではどのように動作しているのか\" なんですよね。システムを理解するためには、ミクロなレベルからマクロなレベルまで、あらゆる粒度でシステムを観察して、分析しなければいけません。著者が例に挙げているデータベース接続の話は、一見些細なことのように思えるかもしれませんが、**SREはそこから派生するいろんな問題を想定して、システム全体への影響を考えなくちゃいけないんです。システムを理解する例として最近公開された ブラウザからDBに行き着くまでをただまとめる のような取り組みを自サービスで行うと効果的と考えています。システムの動作を自身で調べながら書き出していくという点でSREの探求20章でアクティブラーニングで紹介された事例に近いものがあります。zenn.dev著者が \"Understanding a System as a System\" というコラムで紹介しているシナリオは、SREにとってのシステム思考の重要性をよく表していました。データセンターで電源ケーブルが切れるという一つの出来事が、いくつもの要因が絡み合って、最終的にお客さんの購買機会の損失につながっていく流れが描かれています。このシナリオは、システム障害の責任を特定の個人に押し付けるのではなく、システム全体の問題として捉えることの大切さを教えてくれています。SREのマインドセットで大事なのは、お客さんの立場に立つことだと著者は指摘しています。システムの信頼性は、コンポーネントの視点ではなく、お客さんの視点から測定されるべきなんです。100台のWebサーバーのうち14台が故障した場合のシナリオは、このことをはっきりと示していました。SREは常に、システムがお客さんからどう見えているのかを意識して、お客さんの期待に応えることを目指しているんですよね。SREのマインドセットの特徴の一つは、フィードバックループの重要性を理解していることだと著者は述べています。信頼性の向上は、継続的なフィードバックループを通じて達成されるんです。SREの役割は、システムのあらゆる場所でフィードバックループを見つけ出して、育てていくことにあります。それから、SREは他者とのコラボレーションを大切にするという点も印象に残りました。信頼性の追求は、絶対に一人では成し遂げられません。SREは、開発者、運用チーム、マネージャー、そしてお客さんを含むいろんな関係者と協力しながら、システムの信頼性を高めていくんです。特に、お客さんとのコラボレーションについて著者が提示した \"お客さんと一緒に信頼性を高めるためにどうやって協力できるだろう？\" という問いは、SREのあり方を考える上でとても示唆に富んでいると思いました。SREの失敗(failure)や障害(error)に対する姿勢も興味深かったです。SREは、失敗をネガティブなものとしてではなく、学びのチャンスとして捉えるんです。障害は、システムについての理解を深めるための貴重な情報源なんですよね。対話から得た \"障害をシグナルとして扱う\" という著者の学びは、SREのマインドセットをズバリ表していると感じました。この考え方は、『反脆弱性――不確実な世界を生き延びる唯一の考え方』で提唱されている \"反脆弱性\" の概念とも通じるものがあります。著者は、不確実性や変動性、ストレスに晒されることで、かえって強くなる性質を \"反脆弱性\" と呼んでいます。SREが障害を学びの機会と捉えることは、まさにシステムの反脆弱性を高める営みだと言えるでしょう。失敗から学び、その経験を糧にしてシステムを進化させていく。そういうレジリエントなマインドセットこそが、SREに求められているのかもしれません。反脆弱性［上］――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonさらに、SREのマインドセットは、長期的な視点を持っているという点でも特徴的です。スケーラビリティ、運用負荷の軽減、より多くの人々への信頼性の提供など、SREは常に将来を見据えて行動しているんです。システムが時代遅れになる前に、より良い代替案を用意することも、SREの重要な役割の一つだと著者は指摘しています。第2章で紹介されたSREのマインドセットは、技術的な側面だけでなく、倫理的・文化的な側面も含んだ、多面的なものだと感じました。著者が \"neurodiversity\" について触れていたように、SREという職種は、多様なバックグラウンドを持つ人々の力を結集することで、より高い信頼性を達成できるのだと信じています。SREのマインドセットという、一見つかみどころのない概念を、具体的な事例と洞察に基づいて解き明かしてくれる、良い内容でした。システムの信頼性を追求するためには、技術的なスキルと知識に加えて、SRE特有の思考法と姿勢が欠かせないことを、改めて認識させられました。特に、システムの動作を理解し、障害を検知・分析するためには、オブザーバビリティが重要な役割を果たします。オブザーバビリティの概念と実践について、SREの視点から解説した良書です。この本は、オブザーバビリティを単なるモニタリングの延長ではなく、システムの動作を理解するための能動的なアプローチとして捉えています。時系列データ、ログ、トレースを駆使して、システムの振る舞いを可視化し、問題の根本原因を究明していく。そのようなオブザーバビリティ・エンジニアリングの手法は、SREのマインドセットを体現するものだと言えるでしょう。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社Amazon私自身、ソフトウェアエンジニアやSREとしての経験を積む中で、システム思考の大切さを痛感してきました。複雑化する現代のシステムにおいては、個々の要素を深く理解するだけでなく、それらが相互に作用して生み出す振る舞いを俯瞰的に捉える力が求められるんです。システム思考とは、システムを構成する要素間の相互作用や、システムとその環境との間の相互作用に着目し、システム全体の振る舞いを理解しようとするアプローチです。部分の最適化ではなく、全体の最適化を目指すのがシステム思考の特徴です。複雑なシステムでは、ある要素の変化が予想外の連鎖反応を引き起こし、システム全体に影響を及ぼすことがあります。そのような非線形な因果関係を見抜くには、システムを俯瞰する視点が欠かせません。さらに、システムの目的や境界条件を明確にし、外部環境の変化に適応していく力も求められます。SREにとって、システム思考は障害対応や信頼性の向上に直結するスキルだと言えるでしょう。障害が発生した際、表面的な症状だけでなく、根本原因を追究するためには、システム全体の挙動を理解する必要があります。また、信頼性を継続的に改善していくには、ボトルネックを特定し、フィードバックループを回していくことが重要です。それに加えて、お客さんの視点に立って、システムの価値を最大化するという姿勢も、SREにとって欠かせないものだと感じています。システムの究極的な目的は、お客さんに価値を届けることです。お客さんの要求や期待を理解し、システムの機能や性能、信頼性を進化させていく。そのようなお客さん志向のマインドセットは、システム思考と表裏一体をなすものだと言えます。プロダクトマネジメント ―ビルドトラップを避け顧客に価値を届ける作者:Melissa PerriオライリージャパンAmazon第2章で紹介されていた \"no haunted graveyards\" というSREの格言は、私の心に強く残りました。過去の負の遺産から目を背けるのではなく、それを掘り起こして、改善していく。それがSREの使命なんだと。障害や失敗を恐れるのではなく、それを糧にしてシステムを進化させていく。そういう姿勢こそが、SREのマインドセットの真髄なのかもしれません。もちろん、SREのマインドセットを身につけて、実践していくのは簡単なことじゃありません。技術的な学習はもちろん、経験を積み重ねて、他者との対話を通じて考えを深めていくことが欠かせません。Chapter 3. SRE Culture本章は、SREという職種に特有の文化について理解が深まりました。著者は、SREの文化を育むことの重要性を強調しつつ、その具体的な方法論について、自身の経験と洞察に基づいて解説しています。本章を読んでいてSREには最初からスタッフエンジニア的な立ち振舞いが必要だと強く思いました。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonSREの文化を育むことが重要な理由は二つあると著者は指摘しています。一つ目は、SREがその能力を最大限に発揮するためには、SREに適した環境と条件が不可欠だからです。新しい熱帯魚を飼育する際に、水温や水質、餌などに気を配るのと同じように、SREを雇用する組織は、SREが力を発揮できる文化を意識的に作り上げていく必要があります。著者は、SREの文化を育むことを \"keep SREs happy\" と表現していますが、これは単にSREを満足させるというだけでなく、組織にとっても重要な意味を持つのです。二つ目の理由は、SREの文化が組織全体の変革の原動力になり得るからです。著者は、SREの文化を \"Culture as a Vehicle or a Lever\" と表現し、SREの文化が組織や個人を望ましい方向へと導く「乗り物」あるいは「てこ」になると述べています。例えば、SREが重視する \"it isn't done until it is documented\" という考え方は、ドキュメンテーションの充実を組織全体に浸透させる力になります。SREの文化は、reliability（信頼性）という目に見えにくい価値を、組織の隅々にまで行き渡らせるための強力な手段なのです。では、SREの文化を意図的に育むにはどうすればよいのでしょうか。著者は、第2章で解説したSREのマインドセットを出発点にすることを提案しています。SREのマインドセットを形作る要素を一つ一つ取り上げ、それを支える条件や前提条件を考えていく。そのようなボトムアップのアプローチこそが、SREの文化を育む第一歩になると著者は説いています。また、著者は、Carl Saganの \"If you wish to make an apple pie from scratch, you must first invent the universe.:アップルパイをゼロから作りたい場合は、まず宇宙を発明する必要があります。\" という言葉を引用し、文化を構築するためには、それを構成する要素を細分化し、それらを組み合わせるプロセスに着目することが重要だと指摘しています。例えば、\"信頼できる開発環境を提供するために何が必要か\" という問いを立てると、そこから自己サービス化、ドキュメンテーション、拡張性、オブザーバビリティなど、SREの文化を特徴づける様々な要素が浮かび上がってきます。これらの要素を一つ一つ紐解いていくことで、SREの文化の全体像が見えてくるというのです。ただし、著者も認めるように、\"What do I want SRE to be here?\" という問いに答えを出すのは容易ではありません。SREに何を期待し、どんな役割を担ってもらいたいのか。組織によって、その答えは千差万別だからです。しかし、その困難な問いに向き合うことなくして、SREの文化を意図的に育むことはできません。著者は、その問いへの答えを模索するためのヒントとして、インシデント対応に注目することを提案しています。SREの文化を育むための具体的な方法としては、インシデント対応とその振り返りに注力することが有効だと著者は述べています。インシデントの検知、対応、分析、再発防止のプロセスを丁寧に分解し、そこに潜む問いに真摯に向き合うこと。それこそが、SREがシステムの信頼性を高めるために不可欠な営みであり、SREの文化の根幹をなすものだというのです。インシデント対応は、しばしば \"fruit trees\" を育てる営みに喩えられます。インシデントという \"種\" を丁寧に観察し、その理由や背景を \"土壌\" として分析する。そこから得られた学びを \"肥料\" にして、再発防止という \"果実\" を実らせる。そのようなプロセスを地道に積み重ねていくことが、SREの文化を根付かせ、組織の信頼性を高めていくのだと著者は説いています。ただし、インシデント対応をSREだけの仕事にしてしまうと、かえって望ましくない状況を招く恐れがあると著者は警告しています。インシデント対応を通じて得られた知見は、組織全体で共有され、活用されてこそ意味があります。もしSREだけがインシデントから学び、その知見が組織に還元されないようであれば、それは \"車輪の脱落したショッピングカートを押している状態\" だと著者は表現しています。つまり、SREの文化が組織を望ましい方向に牽引する力を発揮できなくなってしまうのです。その意味で、著者が \"Who is getting smarter and what are we doing about it?:誰がより賢くなっているのでしょうか?それに対して私たちは何をしているのでしょうか?\" と問いかけているのは示唆に富んでいます。インシデント対応から得られた教訓は、誰のものになっているのか。そして、その教訓を組織の信頼性向上にどう活かしているのか。その問いに常に意識的でいることが、SREの文化を健全に保つために不可欠なのです。SREの文化を組織に根付かせるためのもう一つの方法は、\"読書輪読会\" や \"ローテーション\" だと著者は述べています。\"読書輪読会\" とは、ポストモーテムやシステム設計書、書籍などを題材に、SREの視点から議論を重ねる場のことです。一方、\"ローテーション\" とは、SREと他の職種の間で一定期間、互いの役割を交代するという取り組みです。これらの活動を通じて、SREの考え方や価値観を組織全体に浸透させていくことができます。特に \"ローテーション\" は、SREの文化を組織に根付かせる上で強力な手段になり得ます。SREがソフトウェアエンジニアの役割を体験することで、開発者の視点や課題を肌で感じることができます。逆に、開発者がSREを経験することで、信頼性の重要性や、運用の現場で何が起きているのかを理解することができます。そのような相互理解が、SREと他の職能の間の \"cultural exchange\" を促進し、組織としての一体感を醸成するのです。『Becoming SRE』の第3章は、SREの文化という、一見捉えどころのない概念を、具体的な方法論と結びつけて解説した、良い内容でした。著者の主張で特に印象に残ったのは、SREの文化は、意図的に育まなければ根付かないというものです。組織の価値観や行動様式を変えていくことは容易ではありません。しかし、著者が提示したような地道な取り組みを積み重ねていくことで、SREの文化は確実に花開いていくはずです。それは、新しい熱帯魚を迎え入れる時のようなワクワク感と、果てしない可能性に満ちたプロセスなのかもしれません。水槽の環境を整え、エサを与え、そっと見守る。SREの文化を育むことは、そんな愛情深く、辛抱強い営みなのだと感じました。もう一つ、私が共感を覚えたのは、SREの文化の中核には \"curiosity（好奇心）\" があるという指摘です。システムの信頼性を追求するためには、その仕組みや振る舞いを深く理解したいという欲求が不可欠です。著者が \"Any SRE culture you create (intentionally or unintentionally) has to support curiosity.:あなたが作成する SRE 文化は (意図的か非意図的かにかかわらず) 好奇心をサポートするものでなければなりません。\" と述べているように、好奇心こそがSREの文化を支える最も重要な要素なのです。そして、好奇心は \"novelty（新奇性）\" とも密接に結びついています。SREにとって、新しい技術や手法に触れ、学び続けることは、好奇心を刺激し、モチベーションを高める上で欠かせません。SREの文化は、そのような好奇心と新奇性を尊重し、奨励するものでなければならないのです。また、著者が \"culture overlays most everything\" と述べているように、SREの文化は、技術的側面だけでなく、組織のあらゆる側面に影響を及ぼし得るものです。それは、人と人との関わり方、コミュニケーションの取り方、意思決定のプロセスなど、組織の文化的な基盤を形作るものでもあるのです。だからこそ、SREの文化を意図的に育んでいくことが重要なのだと改めて感じました。SREの道のりは決して平坦ではありません。しかし、SREの文化を大切に育んでいくことは、その旅を意義あるものにしてくれるはずです。変化への抵抗や、既存の価値観との軋轢に直面することもあるでしょう。でも、複雑なシステムを動かすためには、てこを見出し、フィードバックループを形成し、粘り強く働きかけ続けることが肝要なのです。本章を読んで、私は自身のSREとしての経験を振り返ってみました。確かに、私が所属するチームでも、SREの文化を意識的に育んできた面があります。例えば、障害の振り返りの場では、個人の責任を追及するのではなく、システムの課題を浮き彫りにすることを大切にしてきました。また、開発チームとのローテーションを通じて、互いの理解を深める取り組みも行ってきました。しかし、著者の指摘を踏まえると、まだまだ改善の余地があるようにも感じました。例えば、インシデント対応から得られた知見を、もっと組織全体に浸透させていく工夫が必要かもしれません。また、SREの文化の中核にある \"好奇心\" を、もっと大切にしていく必要があるようにも思います。自分なりのSREの文化を育んでいく。お客様に価値を届け続けるというSREの使命を全うするために、仲間とともに今日も一歩一歩前へ。Chapter 4. Talking About SRE (SRE Advocacy)本章は、SREについて語ることの重要性と、そのための実践的なアドバイスについて理解が深まりました。著者は、SREの価値を組織内外に伝えるためのストーリーテリングの技術について、自身の豊富な経験に基づいて解説しています。ちなみに、私が以前読んだ『ダイアローグ　価値を生み出す組織に変わる対話の技術』でも、必要なのはただのコミュニケーションではなく対話であることが強調されていました。SREについて語る際にも、この点は意識すべきポイントだと思います。ダイアローグ 価値を生み出す組織に変わる対話の技術作者:熊平美香ディスカヴァー・トゥエンティワンAmazon著者によると、SREについて語ることが重要な理由は大きく二つあるそうです。一つ目は、SREという職種や考え方に対する理解を深め、その存在意義を組織内で認めてもらうためです。特に、SREを新しく導入する際や、その影響力を拡大していく段階では、効果的なアドボカシー（支持獲得活動）が欠かせません。二つ目の理由は、SREとしてのアイデンティティを形成するためだということです。著者は \"the stories we tell ourselves are a major way identity is formed.\" つまり、「私たちが自分自身に語る物語は、アイデンティティを形成する主要な方法である」と述べ、自分たちが語るストーリーがアイデンティティの形成に大きな影響を与えると指摘しています。SREについて語ることは、単に他者の理解を得るためだけでなく、自分自身がSREとは何かを深く理解するためにも重要なのです。では、SREについてどのようなストーリーを語れば良いのでしょうか。著者は、SREの定義や効果、評判、可能性など、様々な切り口からストーリーを構成することを提案しています。例えば、「SREの取り組みによって、あるチームの信頼性が目に見えて改善した」といった \"効果の物語\" や、「有名企業がSREを取り入れた」といった \"評判の物語\" は、SREの価値を伝える上で説得力のあるストーリーになるでしょう。また、著者は具体的なストーリーの例も挙げています。障害対応の際の謎解きのプロセスや、SREの専門家の問題解決アプローチを描くことで、SREという仕事の面白さや奥深さを伝えることができるはずです。一方で、SREについて語る上での課題についても、著者は良い指摘をしています。\"吠えなかった犬\" の例え話から分かるように、SREの価値は、しばしば \"何が起きなかったか\" という点に表れます。障害が発生しなかったことや、データ損失が防げたことなど、ネガティブな事象を語るのは容易ではありません。そのためには、\"対比\" の技法を活用し、SREの取り組みがなかった場合に起こり得た事態を想像させることが重要だと著者は述べています。また、\"ヒーロー文化\" を美化するストーリーには注意が必要だと著者は警告しています。個人の英雄的な努力を称賛するあまり、過剰な負荷や無理な働き方を正当化してしまうことがあるからです。インシデント対応でのヒーローの活躍を語る際には、組織としての課題を浮き彫りにし、改善点を提示することが肝心だと強調されています。著者が提示したストーリーの例は、SREの価値を伝える上で参考になるものばかりでした。特に、\"ある日のSREの物語\" のように、SREの日常業務を具体的に描くことで、その仕事の醍醐味や面白さを伝えられるアイデアが印象的でした。ただし、著者自身も認めるように、SREについて語るのは思ったより難しいことがあります。信頼性向上への取り組みは決して一直線ではなく、試行錯誤の連続だからです。その複雑な現実を、聴衆に分かりやすく伝えるためには、スキルと経験が必要不可欠だと感じました。また、SREのストーリーには、技術的な要素だけでなく、人的な要素も欠かせません。著者が \"all of our systems are sociotechnical\" と指摘しているように、信頼性の追求には、技術と人、両方の視点が不可欠なのです。改めて振り返ってみると、SREについて語ることは、単なるアドボカシーの技術ではありません。それは、自らのアイデンティティと、組織としての使命を見つめ直す営みでもあるのだと気づかされました。著者が \"my best talks are those that changed me during the preparation or presentation\" と述べているように、SREについて語ることは、語り手自身をも変容させる体験になり得るのです。本章で提示された多様なストーリーのアイデアを参考に、私もSREについて語る機会を増やしていきたいと思います。自分の経験を言語化し、他者と共有することで、SREとしての自覚と誇りを深めていく。そのような語りの積み重ねが、SREの文化を組織に根付かせ、ひいては社会にも良い影響を与えていくのだと信じています。第4章は、SREという職種の意義を伝えるためのヒントに満ちた一章でした。SREについて語ることは、自分自身と、自分が関わるシステムを見つめ直すための強力な方法論なのだと実感しました。とはいえ、効果的なストーリーを紡ぐのは容易ではありません。著者が \"Collecting stories as you go\" と述べているように、日々の業務の中で、ストーリーのタネを見つける感度を磨いていく必要があります。そして、それを言葉にする作業を丁寧に積み重ねていくことが肝要だと感じました。また、著者も触れているように、他者のストーリーを語る際には、倫理的な配慮も欠かせません。関係者の許可を得ることは大前提ですが、それ以上に、ストーリーの背景にある文脈や、登場人物の心情に思いを馳せることが大切だと感じました。型にはまったストーリーではなく、現場の息吹が感じられるような生々しいストーリーを、誠実に語ることが求められているのだと思います。もう一つ、著者が \"Give up your airtime\" で述べているように、多様な語り手を登用することも重要な課題だと感じました。SREについて語る機会が、一部の立場の人々に偏ることのないよう、自分自身も意識していきたいと思います。第4章を読んで、改めてSREの魅力と可能性を感じました。システムの信頼性を追求するというミッションは、決して華やかなものではありません。しかし、著者が紹介してくれたような力強いストーリーを通じて、その意義を伝えていくことはできるはずです。お客様に平穏と信用を届け、自分のプロとしての役割を成就するために。SREに関して語ることを通じて、自身の業務の意義を再び確かめ、新たな一歩を踏み出すための決心を固めたいものです。日頃の仕事の中で信用を積み重ね、丁重な説明を怠らず、相手に応じた意思疎通を図るなど、円滑なコミュニケーションのためには並々ならぬ労力が必要不可欠です。しかしながら、コミュニケーションのコストを払いたくない、責任を背負いたくない、嫌われたくない、それでいて自分が考案した仕組みにみんなが同意し、ついてきてほしいというのは、どこまでも絵空事なのです。いかに「正しくて能率的」なアイデアでも、そこに人間が関与する以上、人間の心理や感情を考慮せざるを得ません。本来は課題解決に注力したいのに、人間関係の調整に手間を取られるのは、本質から外れているように思えるかもしれません。しかし、他者と協働しなければならない以上、それは避けられない現実なのです。SREという仕事も、究極的には人と人とのつながりの中で成り立っているのだと、改めて認識させられました。円滑なコミュニケーションを築くことは容易ではありませんが、それなくしてSREの使命を果たすことはできないのです。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonII. Becoming SRE for the IndividualChapter 5. Preparing to Become an SRE本章は、SREになるために必要な知識やスキルについて理解が深まりました。著者は、SREへの道のりに唯一無二の正解はないと断りつつも、SREとして活躍するために身につけておくべき基礎知識を丁寧に解説しています。まず、「コーディングができる必要があるか」という問いに対して、著者は 「Yes」 と明確に答えています。システムの信頼性を追求するSREにとって、ソフトウェアがどのように作られているかを理解することは不可欠だからです。また、コーディングを学ぶことで、アルゴリズムの効率性、エラーハンドリング、抽象化、設計、分解、統合、依存関係、ドキュメンテーションなど、SREに必要な多くの概念を自然と学べると著者は指摘しています。これらについては自分も似たような課題感を持っていてブログにしました。syu-m-5151.hatenablog.com一方で、「コンピュータサイエンスの学位が必要か」という問いに対しては、必ずしもそうではないと著者は述べています。ただし、学位がない場合は、アルゴリズム解析やBig O記法など、コンピュータサイエンスの基礎概念をある程度理解している必要があるそうです。次に、著者は 「基本的なシステムと、その障害モード」 と 「分散システムと、その障害モード」 の理解の重要性を強調しています。現代のSREは、マイクロサービスアーキテクチャや地理的に分散したシステムを扱うことが多いため、分散システム特有の障害モードを理解し、レイテンシ、コンセンサスアルゴリズム、分散タイムキーピング、データの一貫性などの概念に精通している必要があるのです。また、著者は 「統計とデータの可視化」 のスキルも重要だと述べています。モニタリングとオブザーバビリティはSREの基盤であり、そのためには、パーセンタイル、傾向分析など、統計の知識が欠かせません。さらに、データを効果的に可視化する能力は、信頼性について客観的な議論をする上で極めて重要だと著者は指摘しています。意外に感じたのは、「ストーリーテリング」 がSREの基礎スキルの一つとして挙げられていたことです。インシデントレビューやポストモーテムは本質的にストーリーであり、そのストーリーをうまく伝えることがSREの重要な仕事だと著者は述べています。人間はストーリーを通じて情報を受け取るようにできているため、SREはストーリーテリングとストーリーリスニングのスキルを磨く必要があるのだそうです。また、著者は 「良き人であれ」 という一節で、SREにとって、プライバシー、倫理、インクルージョン、平等などの価値観について学び続けることの重要性を説いています。SREは地球上で最も重要なシステムの一部を任されているからこそ、常に自己研鑽に励み、最高の自分でいる必要があるのです。そのほか、著者は、すぐには必要ないかもしれないが、いずれSREの前に立ちはだかるであろう話題として、「大規模システム設計」「レジリエンスエンジニアリング」「カオスエンジニアリングとパフォーマンスエンジニアリング」「機械学習と人工知能」 などを挙げています。特に、機械学習によって、システムの振る舞いがデータに依存して確率的に変化するようになったことは、信頼性を考える上で大きなパラダイムシフトだと著者は指摘しています。『Becoming SRE』の第5章は、SREに必要な知識やスキルを体系的に整理した、良い内容でした。著者は「SREの仕事の本質は、システムについて深く理解し、その信頼性を追求すること」と繰り返し強調しています。そのためには、コンピュータサイエンスの基礎から、分散システム、統計、ストーリーテリングまで、幅広い知識と経験が求められます。ただし、著者も認めるように、これらのスキルは一朝一夕には身につきません。大切なのは、自分に足りない知識を認識し、それを少しずつ埋めていく姿勢なのだと感じました。著者が \"Worst-case scenario: it is good to know what you don't know.\" と述べているように、自分の知らないことを知っているだけでも、SREへの第一歩になるはずです。また、SREとして成長していくためには、技術的なスキルだけでなく、「Are you a curious person?:あなたは好奇心旺盛な人ですか？」「Do you like to solve problems, no matter where they take you?:どこに連れて行かれても、問題を解決するのが好きですか?」「Is a life of service attractive to you?:奉仕生活はあなたにとって魅力的ですか?」といった問いに、心の底から「Yes」と答えられるかどうかも重要だと著者は述べています。SREという仕事に真に向いているかどうかは、スキルではなく、マインドセットにあるのかもしれません。本章を読んで、私はSREという職種の奥深さを改めて感じました。信頼性の追求という、一見シンプルに見える目標の背後には、実に多様な知識とスキルが求められているのです。それは、コンピュータサイエンスという学問の神髄を問うものであり、同時に、人間の認知や行動、価値観についての洞察も必要とするものだと感じました。しかし、だからこそ、SREという仕事にやりがいを感じずにはいられません。信頼性を追求するという使命を胸に、謙虚に学び、好奇心を持って問題に立ち向かう。そんなSREの姿勢は、エンジニアとして、人として、大いに魅力的だと感じます。もちろん、その道のりは平坦ではありません。著者が \"aspirational:野心的\" と表現しているように、本章で示された知識やスキルは、理想であって、必須条件ではないのです。大切なのは、その理想であり達人SREに向かって一歩ずつ前進していくこと。私も、自分に足りない点を一つずつ埋めながら、SREとしての道を歩んでいきたいと思います。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社AmazonChapter 6. Getting to SRE from…本章は、著者は、SREになるための唯一の正解はないと断った上で、学生、開発者、システム管理者など、よくある出発点からSREへ移行するためのアドバイスを提示しています。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazonまず、著者は「あなたはすでにSREなのかもしれない」と問いかけます。組織の中には、正式な肩書きこそないものの、SREのマインドセットを持って仕事に取り組んでいる人が少なからずいるというのです。もしあなたがそうだとしたら、組織内でその価値を認めてもらい、SREとしてのキャリアを歩み始めることが次の一歩になるでしょう。学生からSREを目指す人へのアドバイスとしては、インフラ関連の仕事を見つけること、クラウドプロバイダーの無料クレジットを活用すること、カンファレンスに参加することなどが挙げられています。また、コンピュータサイエンスを学ぶ学生は、スケーリング、分散コンピューティング、キューイング理論などの授業に注目すべきだと著者は述べています。一方、工学や科学を学ぶ学生は、大規模計算に触れる機会を見つけ、信頼性の高いシステムを構築するために必要なスキルを身につけることが重要だとのことです。開発者からSREへの移行に関しては、本番環境でのコードの振る舞い、障害モード、オブザーバビリティ、リリースエンジニアリング、ドキュメンテーションなどに注目することが大切だと著者は指摘しています。開発者にとって、「システムを構築するだけでなく、運用することについても考える」ことがSREへの第一歩になるのです。私自身、システム管理者からSREへの道を歩んできました。著者が指摘するように、システム管理者とSREは、人々を助けたいという思いを共有しています。また、トラブルシューティングとデバッグのスキルも、両者に共通する強みだと言えるでしょう。sreake.com一方で、SREへの移行には、マインドセットの転換が必要だと著者は述べています。「すべてのものを監視する」から「顧客の視点から信頼性を測定する」へ、「適切な信頼性レベル」を追求し、「フィードバックループを育む」ことが求められます。この転換を実現するために、著者はチケット管理システムやモニタリングのメールを、信頼性に関する貴重なデータソースとして活用することを提案しています。インシデント後のレビューを非公式に実施することも、SREのマインドセットを身につける良い機会になるでしょう。さらに、「根本原因」ではなく「contributing factors」といった言葉を用いることで、言語がもたらす認識の変化にも目を向けるべきだと著者は述べています。最後に、著者は他のあらゆる職種の人々に向けて、「信頼性とのつながりを見つけ、その方向に泳ぎ始めること」を勧めています。また、進捗を記録し、前進し続ける原動力にすることの重要性も強調されています。第6章は、SREというキャリアを目指す人々に、実践的なアドバイスと温かい応援のメッセージを送る内容でした。著者の主張で特に印象に残ったのは、SREへの道に唯一の正解はないという点です。様々なバックグラウンドや経験を持つ人々が、信頼性の追求という共通の目標に向かって歩んでいける。そんな多様性と包摂性こそが、SREという職能の強みなのかもしれません。本章を読んで、私はシステム管理者時代を振り返ってみました。確かに当時は、可用性の追求に汲々としていた面があります。でも、あの頃培った、ユーザーに価値を届けたいという思いは、今でもSREとしての原動力になっています。著者が述べているように、経験やスキルのギャップを少しずつ埋めていくことで、誰もがSREを目指せるのだと感じました。とはいえ、SREへの道のりは決して平坦ではありません。新しい知識を吸収し、経験を積み、時にはつまずきながら進んでいく。しかし、その過程で得られる学びと成長は、何物にも代えがたい価値があるはずです。Chapter 7. Hints for Getting Hired as an SRE本章は、SREの職を得るためのヒントについて理解が深まりました。著者は、SREの求人情報の評価方法から、面接の準備、面接でのアピール方法まで、SREの仕事を求める人のために実践的なアドバイスを提供しています。また、Github上ではmxssl氏によるSRE 面接準備ガイドがありこちらも一読していただければ良いと思います。github.comまず、著者は「SREの仕事はすべて同じではない」と断った上で、タイトルだけがSREに変更された職種（title-flip positions）は、本章の対象外だと明言しています。SREの求人を見極めるためには、求人情報に含まれている（あるいは含まれていない）情報に注目することが大切だと著者は述べています。求人情報に記載されている技術スタックからは、その組織の技術的成熟度や環境の一貫性などが読み取れるそうです。また、チケット管理システムへの言及は、その環境がどれほどトランザクショナルかを示唆しているとのことです。プログラミング言語への言及は、コーディングスキルがある程度重視されていることを意味します。一方、モニタリング技術への言及の有無からは、その職種とモニタリングの関係性が窺えます。次に、著者はSREの面接対策として、非抽象的な大規模システム設計（NALSD）、モニタリング／オブザーバビリティ、コンピューティングの基礎、トラブルシューティング／デバッグの4つのトピックを挙げています。これらのスキルは、ほとんどのSREの職種で求められるため、事前に準備しておくことが重要だと著者は述べています。面接で質問すべき内容についても、著者は具体的な提案をしています。「モニタリングシステムについて教えてください」「インシデント後のレビュープロセスについて教えてください」「オンコール体制について教えてください」「SREが解決しようとしている問題は何ですか？」といった質問は、その組織におけるSREの役割や成熟度を知る上で有効だそうです。ただし、著者も認めるように、面接での質問は諸刃の剣になり得ます。「あなたが雇用されたら、これらの質問に答えを出してもらいたい」と言われた場合、自分で出した難しい質問に答えなければならなくなるかもしれません。そのような状況に備えて、大まかな答えを用意しておくことが賢明だと著者は述べています。第7章は、SREの仕事を求める人のための実践的なガイドブックでした。著者の豊富な経験に基づく助言は、SREを目指す人にとって心強い道しるべになるはずです。本章を読んで、私は自身の経験を振り返ってみました。確かに、SREの面接では、技術的な質問だけでなく、システム思考やコラボレーションに関する質問も多く出されました。著者が述べているように、SREに求められるスキルは多岐にわたるため、幅広い知識と経験が問われるのだと実感しました。また、面接官としての経験からも、著者の指摘に共感を覚えました。求職者がシステムのボトルネックを特定したり、障害から学ぶ姿勢を示したりするのを見ると、SREとしての資質を感じずにはいられません。逆に、ヒーロー的な振る舞いを美化するような発言には、危険信号を感じることがあります。本章で特に印象に残ったのは、SREの面接は双方向のコミュニケーションであるべきだという点です。求職者は、自分のスキルをアピールするだけでなく、その組織におけるSREの役割や課題について積極的に質問すべきだと著者は述べています。時には、面接そのものが、SREの実践の場になり得るのかもしれません。また、著者が 「面接に落ちたら、それを障害対応のように扱ってみよう」 と提案しているのも興味深かったです。確かに、失敗から学ぶ姿勢は、SREにとって不可欠なマインドセットです。面接に落ちたからといって、それで終わりではありません。そこから学びを得て、次のチャンスに生かしていく。そういう前向きな姿勢こそが、SREの真骨頂なのだと感じました。SREの世界に飛び込むのは、勇気のいることかもしれません。でも、その一歩を踏み出す価値は十分にあるはずです。『Becoming SRE』の第7章は、その一歩を後押ししてくれる、頼もしいガイドだと感じました。とはいえ、面接対策だけがSREへの道ではありません。日々の業務の中で、信頼性への意識を研ぎ澄まし、技術力を磨いていくことが何より大切なのだと思います。著者も触れているように、SREの面接は、日頃の仕事ぶりの反映に他なりません。だからこそ、普段から「How can I make things better?」という問いを忘れずにいたいものです。システム設計の面接試験作者:アレックス・シュウソシムAmazonChapter 8. A Day in the Life of an SRE本章は、SREの日常業務の章であり、SREという職種の多様性と複雑性を浮き彫りにしています。 著者は、SREの仕事を複数のモードに分類することで、その役割の広がりを示しました。インシデント対応、ポストインシデント学習、ビルダー/プロジェクト/学習、アーキテクチャ、マネジメント、計画、コラボレーション、回復とセルフケアなど、SREは常に状況に応じて異なる仕事のモードを切り替えながら、システムの信頼性を維持・向上させていく必要があるのです。特に印象に残ったのは、コラボレーションモードの重要性についての指摘です。 SREはシステムの信頼性を確保するために、開発者、プロダクトマネージャー、ステークホルダー、ビジネス側の人々など、さまざまな関係者と密接に連携していかなければなりません。SLI/SLOの定義と実装、モニタリングの設計、カオスエンジニアリングの実践など、SREの主要なタスクの多くはコラボレーションを抜きには語れません。著者が強調するように、SREは「容赦なく協調的」であることが求められるのです。また、SREの仕事がときに過酷になりがちだという指摘も重要です。 ヒーロー的な働き方を美化する文化的風潮の中で、SREが過剰なワークロードを抱え込み、バーンアウトしてしまうリスクは常につきまといます。著者は、週60-75時間も働くことを自慢げに語る人がいたら、それはシステムの失敗の表れだと考えるべきだと述べています。燃え尽きた人間は、信頼性の高いシステムを構築することができないのです。SREがサステナブルなオペレーションを実現するためには、適切なワークライフバランスを保つことが不可欠だと言えるでしょう。SREの業務バランスについての考察も示唆に富んでいました。反復作業と価値ある作業、リアクティブな仕事とプロアクティブな仕事、割り込みの多い仕事と集中できる仕事、個人作業とチームでの作業、危機的状況と平常時など、SREは常に相反する要素のバランスを取る必要があります。 特に新しいサービスを立ち上げる際は、リアクティブな仕事や割り込みが多くなりがちで、エンジニアリング業務に充てる時間を確保するのが難しくなります。状況に応じて柔軟にバランスを取っていく必要がありますが、長期的には業務時間の50%はエンジニアリング業務に充てるべきだというガイドラインは、非常に参考になりました。本章では、SREという職種の技術的な側面だけでなく、コラボレーション、ワークライフバランス、メンタルヘルスなど、さまざまな角度からSREの仕事の実態に迫っています。 SREに求められるスキルや資質の多様性を考えると、SREという職種の奥深さと面白さを改めて感じさせられました。特に、SREがサステナブルなオペレーションを実現するための職種であるという点は重要で、バランスの取れた働き方を目指すべきだという主張には強く共感しました。私たちSREは、常に変化し続ける技術的・組織的環境の中で、複数のモードを行き来しながら、コラボレーションマインドセットを発揮し、適切なバランスを保ちつつ、信頼性の高いシステムづくりに取り組んでいく必要があります。 本章で紹介されていたさまざまな知見を胸に、SREとしてのキャリアを歩んでいきたいと思います。いつも「時間がない」あなたに　欠乏の行動経済学 (早川書房)作者:センディル ムッライナタン,エルダー シャフィール早川書房AmazonChapter 9. Establishing a Relationship to Toil本章は、SREにとって馴染み深いトピックである「Toil」について、より深く掘り下げた章でした。Toil（単純作業）は、SREの文脈でしばしば登場する概念ですが、その定義や特徴、そして私たちがToilとどのように向き合うべきかについては、これまであまり明確に語られてこなかったように感じます。本章では、Vivek Rauが提示したToilの定義を出発点としつつ、より nuancedで健全なToilとの付き合い方を模索しています。退屈なことはPythonにやらせよう 第2版 ―ノンプログラマーにもできる自動化処理プログラミング作者:Al Sweigartオライリー・ジャパンAmazonまず印象的だったのは、Toil を単に「嫌な仕事」として片付けるのではなく、より精緻に定義しようとしている点です。  Rauによれば、Toilとは、manual（手作業）、repetitive（反復的）、automatable（自動化可能）、tactical（戦術的）、no enduring value（持続的価値がない）、O(n) with service growth（サービスの成長に比例）といった特徴を持つ作業のことを指します。これらの特徴をすべて満たす必要はありませんが、当てはまる項目が多いほど、その作業はToilである可能性が高いと言えるでしょう。また、「誰のToilについて話しているのか」という問いも重要だと指摘されています。  通常、SREが対処しようとしているのは、システムの運用に関わるToil（operational Toil）であり、顧客が直面するToil（customer Toil）ではありません。ただし、顧客のToilを軽減することもSREの新しいフロンティアになり得ると著者は示唆しています。運用のToilと顧客のToilの間には、興味深い関連性があるのかもしれません。次に、SREがToilに注目する理由について、著者は3つの要因を挙げています。  1つ目は、美的感覚（aesthetics）です。SREは、非効率的で不要なToilを根本的に嫌うという特性を持っているのかもしれません。2つ目は、お金（money）の問題です。高度なスキルを持つSREを雇用するコストは高く、彼らにToilではなく価値ある仕事をしてもらうことが組織の財務的利益につながります。3つ目は、時間の使い方と仕事の満足度です。Toilに費やす時間が増えれば、エンジニアリング業務に充てられる時間が減り、SREの仕事の満足度も下がってしまいます。さらに、Toil がサービスの成熟度と関連していることも指摘されています。 新しいサービスほど、モニタリングやアラートの調整が不十分であったり、運用に必要なプロセスの自動化が不足していたりするため、Toil が多くなる傾向があります。サービス立ち上げ初期のToil（Early Toil）と、成熟したサービスに付きまとうToil（Established Toil）を区別することが、Toil削減に向けた戦略を立てる上で重要だというのは、良い視点だと感じました。そして、Toil の削減（あるいは排除）について、著者は興味深い見方を示しています。  よく語られるのは、「Toil を特定し、自動化やセルフサービス化によって排除する」というストーリーですが、著者はこれに疑問を呈しています。Toil は完全に排除できるわけではなく、別の形に姿を変えるだけだというのです。自動化によってToil が減っても、その分、コードの複雑性が増す。セルフサービス化によって運用チームのToil は減っても、その分、Toil が細分化されてユーザー側に分散される。著者はこれを「Toil の保存則」と呼んでいます。  Toil との健全な付き合い方を確立するためには、この保存則を直視する必要があるでしょう。トイルの削減に向けた取り組みを、単一のシステムレベルから、環境全体のクラスレベルに引き上げることも重要だと著者は指摘しています。例えば、新しいサービスをモニタリングシステムにオンボーディングする作業を大幅に簡略化することで、Early Toil を大きく削減できるかもしれません。さらに、過去のToil（established）、現在のToil（early）、未来のToilのどれに有限のリソースを割り当てるかという、時間軸を意識した判断も求められます。個人的には、「Toil を完全に排除するのではなく、より有害度の低い形に変換していく」という考え方に強く共感しました。  トイルを減らす努力は続けつつも、同時に発生し得る複雑性や、顧客側への影響についても意識しておく必要がありそうです。私自身、SREとして日々Toilと向き合っていますが、それを単に嫌な仕事として捉えるのではなく、サービスの成熟度や技術的負債との関係性を意識しながら、長期的視点でToilの削減に取り組んでいきたいと思います。また、生成AIがこれらの意思決定にどのように影響するのか考える必要があると思っています。本章で得られた知見は、そのための指針になってくれるはずです。面倒なことはＣｈａｔＧＰＴにやらせよう (ＫＳ情報科学専門書)作者:カレーちゃん,からあげ講談社AmazonChapter 10. Learning from Failure本章は、システムの障害から学ぶことの重要性と、その実践方法について深く掘り下げた章でした。SREにとって、障害からの学びは、適切な信頼性レベルを達成するための中核的な活動だと言えます。 モニタリング/オブザーバビリティ、SLI/SLOによる目標設定、そしてインシデント/アウトリッジ対応という3つの実践が交差する地点に、障害からの学びがあるのだと著者は指摘しています。この学びを通じて、現状（what is）と目標（what should be）のギャップを埋めていくことができるのです。反脆弱性[下]――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonまず印象に残ったのは、障害について語る言葉選びが、私たちの思考や行動に大きな影響を与えるという指摘です。 例えば、「root cause（根本原因）」という言葉は、複雑な障害を単一の原因に帰着させようとする思考を助長しがちです。それに対して、「contributing factors（寄与因子）」という言葉は、障害の複雑性を認識し、多面的な理解を促します。著者が強調するように、SREは障害について語る際の言葉選びにも注意を払う必要があるでしょう。次に、ポストインシデントレビュー（PiR）のプロセスについて、詳細な解説がありました。 あ、本書の中でそう言っているだけでポストモーテムが一般的な用語です。ポストインシデントレビューの目的は、インシデントについて徹底的に調査し、関係者間で共通理解を構築しながら、可能な限り多くのことを学ぶことにあります。そのためには、インシデントの詳細な年表を作成し、関係者全員でレビューすることが重要だと著者は述べています。また、レビューの際は、「なぜ」よりも「何が」「どのように」起きたのかに焦点を当てるべきだと指摘しています。「なぜ」を問うことは、原因の特定や対策の検討に性急に走ってしまう危険性があるためです。著者は、ポストインシデントレビューでよく見られる5つの落とし穴についても警鐘を鳴らしています。 「human error（人的ミス）」でインシデントを片付ける、反実仮想的な推論に陥る、結果論で判断する、機械の無謬性を前提とする、ポジティブな側面を無視する、といった点です。これらは、障害の本質的な理解を妨げ、学びを狭めてしまう恐れがあります。私自身、これらの落とし穴に無意識に陥っていたことに気づかされました。レジリエンスエンジニアリングについては、著者が特に重要視している点だと感じました。David Woodsによるレジリエンスの定義は、「不可避な驚きに対応するためにシステムが必要とする能力」というもので、従来のレジリエンス（回復力、耐障害性）の概念を大きく拡張するものです。 レジリエンスを高めるためには、変化や障害に適応するための「適応能力（adaptive capacity）」を、事前に備えておく必要があるのです。私が特に興味深く感じたのは、レジリエンスを「reboundからsustained adaptabilityまでの4段階」で捉える考え方です。 reboundは「障害からの回復」、robustnessは「複雑性やストレスへの対処」、graceful extensibilityは「想定外の事態への適応」、そしてsustained adaptabilityは「進化し続ける環境への継続的適応」を意味します。多くのSREがreboundからrobustnessあたりを目指しているのに対し、レジリエンスエンジニアリングは、その先のgraceful extensibilityやsustained adaptabilityまでを視野に入れているのだと理解しました。また、Safety-IIやSafety-IIIといった概念も紹介されていました。 Safety-IIは、「うまくいっているときに何が起きているのか」に着目することで、障害を未然に防ぐアプローチです。Safety-IIIに至っては、「成功から学ぶ」ことで、失敗を防ぐという画期的な発想だと言えます。私たちSREは、障害対応に追われるあまり、普段うまくいっていることの分析を怠りがちです。レジリエンスエンジニアリングの知見は、そうしたマインドセットを変える上でも示唆に富んでいると感じました。著者も指摘するように、レジリエンスを「動詞」として捉えることが重要だと思います。 レジリエンスは、ただ備わっている特性ではなく、絶え間ない実践によって培われていくものです。障害を避けられない以上、私たちにできることは、レジリエンスを高める営みを続けていくことです。そのためには、レジリエンスエンジニアリングの知見を深く理解し、SREの文脈に適用していく努力が求められるでしょう。私自身、これまではレジリエンスを「回復力」程度の意味で捉えていましたが、本章を読んで、その概念の奥深さに気づかされました。システムのレジリエンスを高めることは、SREの本質的な使命だと言えます。 障害から学ぶことは、そのための重要な一歩です。しかし、それだけでは不十分で、平時のシステムの挙動から学ぶことも欠かせません。レジリエンスエンジニアリングの知見を積極的に吸収し、SRE文化に取り入れていくことが、これからのSREに求められているのだと強く感じました。さらに、カオスエンジニアリングについても言及がありました。 カオスエンジニアリングとは、本番環境で意図的に障害を引き起こし、システムの挙動を理解する取り組みです。単なる「破壊」ではなく、仮説に基づいた意図的な実験であることが重要だと著者は述べています。想定外の事態に備えるための力を養う上で、カオスエンジニアリングは欠かせないアプローチだと感じました。最後に、ポストインシデントレビューで得られた学びを組織全体に広げるための具体的な方法が紹介されていました。 「ブッククラブ」「ニュースレター」「プロダクションレディネスレビューへの反映」「メタ分析とML」など、どれも良いアイデアだと感じました。せっかく得た貴重な学びを、ドキュメントに埋もれさせてはいけません。組織の隅々にまで浸透させる工夫が求められます。全体を通して、障害からの学びがSREの中核的な活動である一方で、それを実践することの難しさも再認識させられました。 言葉選びひとつとっても、私たちの無意識のバイアスが入り込む余地があります。学びを最大化するためには、レジリエンスエンジニアリングやカオスエンジニアリングといった周辺領域の知見も積極的に取り入れていく必要がありそうです。私自身、これまでのキャリアの中でポストインシデントレビューに数多く参加してきましたが、本章で得た学びを胸に、より効果的な障害からの学びを実践していきたいと思います。個人としてだけでなく、チームや組織体としての学びを促すことが、SREに求められる重要なスキルなのだと再認識しました。世界のエリートがIQ・学歴よりも重視！　「レジリエンス」の鍛え方作者:久世 浩司実業之日本社AmazonPart III. Becoming SRE for the OrganizationChapter 11. Organizational Factors for Success本章は、SREの導入を成功に導くための組織的要因について、非常に良い考察を提示していました。単に技術的なベストプラクティスを導入すれば事足りるわけではなく、組織のあり方そのものを見直す必要性を説得力を持って訴えかけています。著者が最初に問いかけるのは、「SREが解決できる問題を組織が抱えているか」という点です。 具体的には、システムの信頼性の低さ、アウテージ対応の非効率、過剰な運用負荷といった、SREのアプローチが真に効力を発揮できそうな課題を特定することが重要だと指摘しています。SREを導入すれば万事解決すると楽観視するのではなく、その手法が組織の痛点に適合するかを見極める必要があるのです。次に重要な問いは、「その問題を解決するために、組織は実際に何をする覚悟があるか」です。 SREはバズワードとして華やかに語られがちですが、本当の意味で組織に根付かせるには、相応の覚悟と行動が求められます。著者は具体的な問いを投げかけます。信頼性向上のためにエンジニアリングリソースを割けるか。機能開発を後回しにしてでも、インシデント対応の改善に注力できるか。SLOが未達の際、新機能のリリースを躊躇なく延期できるか。ポストモーテムを形骸化させない努力を惜しまないか。オンコール体制は人間的で持続可能なものになっているか。SREがソースコードにアクセスし、信頼性向上に必要な変更を加えられるか。こうした一つ一つの問いに正面から向き合わなければ、SREの真価は発揮できないと著者は警鐘を鳴らしているのです。また、SREの効果が表れるまでの「忍耐力」も重要だと指摘しています。 DORAのState of DevOps Report 2023 でも示されているように、信頼性向上の取り組みが実を結ぶまでには一定の時間がかかるものです。短期的な成果を求めるあまり、腰を据えた取り組みを続けられなければ、折角の努力も水泡に帰してしまいます。だからこそ、地道な改善を積み重ねつつ、長期的なゴールを見据える忍耐強さが組織に求められるのです。SREが真に力を発揮するには、組織のあらゆるレイヤーでの「協調性」も欠かせません。 開発チーム、ビジネスサイド、ステークホルダーなどと有機的に連携しながら、信頼性の向上を追求していく必要があります。部署間の壁を越えて協調できる組織文化があるか。SREが他チームのコラボレーションツールに参加できるか。モニタリングやオブザーバビリティのツール選定に SREの意見は反映されているか。そうした具体的な協調性の発露が、SREの成功を左右すると著者は指摘するのです。また、SREにとって「データ駆動の意思決定」は生命線とも言えます。 モニタリングの重要性を説き、その結果を改善アクションに直結させる。そのためには、データの可視化や分析を習慣づけ、意思決定プロセスに組み込む組織文化が不可欠です。エラーバジェットの概念も、まさにデータに基づく意思決定の具現化だと言えるでしょう。こうしたデータ駆動のマインドセットが組織に根付いているかを見極める必要性を、著者は説いているのです。失敗から学ぶ姿勢も、SREの生命線の1つです。 形骸化したポストモーテムではなく、真摯に失敗の教訓を汲み取り、改善に活かすサイクルを回していく。それも1つのチームに閉じた学びではなく、組織の壁を超えて知見を展開していく。そうした失敗からの学びを組織の文化として定着させられるかどうかが、SREの成功を分けると著者は指摘します。インシデントの振り返りが義務的なタスクと化していないか。関係者が建設的に議論できているか。導き出された教訓が確実にアクションに結びついているか。こうした具体的な問いを投げかけることで、組織の学習力を見抜くことができるのです。そして、SREが真の力を発揮するには、現場レベルでの「変化を起こす力」も欠かせません。 ドキュメントの改善から、コードやインフラの変更、ツールの選定、採用プロセスの見直しに至るまで、SREが信頼性向上のために必要な施策を機動的に実行に移せる環境が整っているかどうか。それは、SREの役割への信頼と、裁量の広さの表れだと言えます。もちろん、すべてを自由に変更できる必要はありません。しかし、SREの専門性を活かして、システムを改善していく力を組織が認めているかは、重要なバロメーターになります。加えて、システム内の「摩擦」を発見し、取り除いていく感度の高さも重要だと著者は説きます。 障害対応に2時間もかかるのに、サービス可用性の目標値は99.99%といった矛盾。開発者とオペレーション担当者の間の連携不足。旧態依然としたマニュアル作業の残存。そうした非効率や齟齬を嗅ぎ分け、改善を促していく感性がSREには求められます。リスクを放置すれば、いずれ大きな障害を招きかねません。だからこそ、摩擦を見抜き、取り除く意識を組織全体で醸成していく必要があるのです。そして著者は、SRE導入の成否は結局のところ「組織の価値観」に集約されると結論付けています。 どんなにSREの手法を形式的に取り入れても、組織の根幹にある価値観と融和しなければ、長続きはしません。信頼性を重視する文化、学習を尊ぶ姿勢、協調性、変化への適応力。そうした価値観が組織のDNAレベルで共有されている必要があるのです。Googleでの SREの成功も、同社のエンジニアリング文化と価値観があってこそだったと著者は指摘します。組織の価値観とSREの理念が合致することが、成功の大前提なのです。SREの導入は、技術的側面だけでなく、組織文化や価値観のレベルでの変革を必要とする壮大な挑戦だと改めて感じさせられました。一朝一夕には成し遂げられない困難な道のりですが、その実現のためには、本章で示された指針に一つ一つ向き合っていく必要があります。SREと真に相性の良い組織を作り上げるには、骨太の問いを自らに投げかけ、その答えを見出す誠実さを業務で体現できればと思いました。Chapter 12. How SRE Can Fail本章は、SREの導入と実践における失敗のシナリオを赤裸々に描き出した、良い章でした。著者は、SREの失敗が、単なる信頼性向上の取り組みの頓挫にとどまらず、組織全体がSREを拒絶するような深刻な事態を招きかねないと警鐘を鳴らしています。私たちは、SREという\"処方箋\"を手にしたからといって、安穏としてはいられません。その処方箋の効果を十分に引き出すには、組織の隅々にまで浸透させる地道な努力が欠かせないのです。印象的だったのは、SREの導入を「肩書の変更」だけで済ませようとする安直なアプローチへの警告です。開発者やサポートエンジニアの肩書をSREに変えるだけでは、役割や文化に実質的な変化は生まれません。むしろ、形骸化したSREチームが、開発現場の足を引っ張るリスクすらあります。SREは、単なる看板の掛け替えではなく、価値観、トレーニング、リソース配分、コミュニケーションの在り方などを根本から見直す覚悟なくして、成功しないのです。同様の罠は、既存のTier 3サポートチームをそのままSREチームに転換しようとする試みにも潜んでいます。サポートチームの役割は、エスカレーションされた難解な問題を解決することであり、システムの信頼性を根本から高めるフィードバックループを作り出すことではありません。単なる看板の掛け替えでは、開発チームとの建設的な協働は生まれず、SREの真価を発揮できないままに終わるでしょう。著者が指摘するように、SREへの転換は、チームの使命と働き方を抜本的に見直す取り組みでなければならないのです。また、SREの役割をオンコール対応だけに矮小化するのも危険だと著者は訴えかけています。確かにインシデント対応は、システムの弱点を学び、改善につなげる重要な機会です。しかし、それだけがSREの存在意義だと誤解されては本末転倒です。開発者の負担を軽減するための「例外処理係」としてSREを使うのは論外ですし、システム改善から切り離されたオンコールでは、SREのポテンシャルを十分に引き出せません。SREは、オンコールから得た学びを、信頼性向上のための施策に着実に結びつけてこそ、真価を発揮できるのです。組織のトップレベルで、機能開発とSREによる信頼性向上のバランスをコントロールできる体制の欠如も、SREを失敗に導く要因として指摘されています。開発チームとSREチームのリーダーが、同じエンジニアリング責任者の下に位置していれば、feature workとSREの優先順位をその場その場で適切に判断できるはずです。しかし、両者の調整に上層部の決裁が必要になれば、SREの機動力は大幅に削がれてしまいます。組織のヒエラルキーがSREの足を引っ張ることのないよう、意思決定プロセスをシンプルに保つ工夫が欠かせません。Googleの実践をそのまま自社に当てはめようとする安直なアプローチも、失敗のリスクを孕んでいると著者は指摘します。Googleの書籍から学ぶことは多いですが、自社の文化や特性を無視してそのまま導入しても、うまくいくはずがありません。SREはGoogleの価値観の反映であり、他社が同じことをしたからといって、同じ成果が得られる保証はないのです。大切なのは、Googleの実践に範を求めつつも、自社独自のSREを見出していくこと。時には、Googleとは異なる道を選ぶ勇気も必要になるでしょう。SREがゲートキーパーと化すことも、大きな落とし穴だと著者は述べています。プロダクションリリースの可否を判断する\"門番\"としてSREが君臨すれば、開発チームとの対立は避けられません。SREが「get to \"no\"」の存在になれば、開発者はSREを障害物とみなし、迂回する方法を編み出そうとするでしょう。SREは、開発チームの創造性を阻害するのではなく、reliability-minded cultureを醸成するパートナーとして振る舞う必要があります。SREの成功が仇となって自滅するケースにも目を向けています。実績を上げたSREチームがあれば、つい何でも任せたくなるものです。しかし、それではSREチームはたちまち疲弊し、モチベーションを失ってしまいます。SREがシステムの面倒を一手に引き受ける\"heroもの\"になれば、開発チームの当事者意識は薄れ、システムは脆弱化の一途をたどるでしょう。SREはあくまで開発チームとの協働によって真価を発揮する、ということを肝に銘じる必要があります。また、目に見えづらい改善の積み重ねや、お客様視点の欠如、日々の楽しさの喪失など、些細な障害の集積がSREを衰退させる可能性も示唆されていました。SREの仕事は、日々の地道な努力の積み重ねです。トラブルが減れば減るほど、その存在価値が見えづらくなるのは宿命と言えます。だからこそ、自らの成果を可視化し、社内外にアピールし続けることが肝要なのです。単に社内の評価を高めるためだけでなく、自らの仕事のやりがいを再確認するためにも、これは欠かせない活動だと感じました。全体を通して、SREの道のりが平坦ではないことを思い知らされる章でした。様々な落とし穴が私たちを待ち受けています。肩書だけの変更、不適切なチーム改編、オンコール偏重、ゲートキーピング、Googleの無批判な模倣、業務の押し付け、目に見えない成果、お客様視点の欠如、楽しさの喪失。どれ一つとっても、SREを脆弱化させ、組織から拒絶されるリスクを孕んでいます。しかし、だからこそSREには果敢にチャレンジする価値があるとも感じました。SREの道は険しいかもしれません。思うように物事が運ばないこともあるでしょう。しかし、SREたるもの、困難から目を背けるわけにはいきません。「SREが組織に拒絶されつつある」という兆候を感じたら、インシデント対応のように、適切なstakeholderを招集し、早期の軌道修正を図る。失敗から立ち直れなかった時は、ポストモーテムのように、徹底的に原因を究明し、教訓を次に活かす。SREのマインドセットとスキルは、まさに逆境を乗り越えるために磨かれてきたのです。とはいえ、組織の理解と協力なくして、SREの成功はあり得ません。セイリングで「向かい風でも、風を読めば前に進める」と言われるように、私たちは、SREへの\"向かい風\"を嘆くのではなく、それを追い風に変える知恵を持たねばなりません。失敗の芽を早期に発見し、軌道修正を図る感度の高さ。組織の価値観に働きかけ、開発チームとの信頼関係を築き、お客様の視点を第一に考える粘り強さ。そうした資質を私たち自身が体現することで、自社ならではのSREを根付かせていくことができるはずです。向かい風を利用したダッキングの仕組みは知識さえあればどんな状況も好転する可能性を秘めている例としてとても良いので雑学科学読本　身のまわりのすごい技術大百科から引用させて下さい。雑学科学読本　身のまわりのすごい技術大百科 より引用失敗の先にある成功を信じて、これからもSREの旗を高く掲げ続けたい。本章で赤裸々に描かれた数々の失敗シナリオは、SVレベルの人にこそ読んでもらいたい内容だと感じました。システムの信頼性は、一SREチームだけで達成できるものではありません。開発、オペレーション、マネジメントが一丸となってこそ、真の信頼性は生まれるのです。私たちSREは、荒波にも負けず、組織を信頼性の高い未来へと導く舵取り役でありたいと願っています。ただ単にGoogleが提唱するSREの手法を模倣するのではなく、それぞれの独自性を活かしたSREとしての旅路を歩みたいと思います。この道のりは、組織の隅々にわたってSREの価値観を浸透させることで、目指すべき信頼性という大海原へと進む冒険です。この考え方を共有するために、同僚が『あなたらしくSRE』というテーマでの発表を行い、大変示唆に富む内容でしたので、その資料をここで紹介します。また、netmarkjpさんによる、現場主導で進化するSREのあり方をテーマにした一連の資料も大変参考になります。具体的には、『現場がさき、プラクティスがあと、原則はだいじに』には、現場のニーズを優先しつつ、SREのプラクティスを展開していく重要性が述べられています。『SREsのためのSRE定着ガイド』では、SREが組織内で定着し、根付いていくための具体的なガイドが提供されています。さらに、『SREこのへんで苦戦しがちじゃないですか？』では、SREが直面しがちな困難に対する洞察と対処法が紹介されています。これらの資料は、それぞれの組織やチームが直面する独自の課題に対して、柔軟かつ効果的に対応するためのヒントやインスピレーションを提供してくれるはずです。私たち一人ひとりがSREとして成長し、組織全体の信頼性を高めていくために、これらの資料をぜひ活用してください。 speakerdeck.comChapter 13. SRE from a Business Perspective本章は、SREという技術的な役割を、ビジネスの観点から捉え直した、良い富む章でした。SREの実践は、単に技術的な信頼性の向上だけでなく、組織の成長や競争力強化にも直結する重要な取り組みだと再認識させられました。著者が対談したBen LutchとDave Rensinの両氏は、Googleという最先端のIT企業で、SREチームのリーダーを長年務めてきた人物です。彼らの知見は、SREをビジネスの文脈で語る上で、非常に良い章です。まず印象的だったのは、「信頼性はサービスの最も重要な機能である」という指摘です。顧客がサービスを使い続けるためには、その信頼性が何よりも大切だと言えます。SREは、その信頼性という機能の実現に特化したエンジニアリングチームだと位置づけられるのです。機能開発と信頼性向上は二律背反ではなく、SREという専門チームを設けることで、両者を高いレベルで両立できるというのは、良い視点でした。また、SREの存在意義を測る物差しとして、エラーバジェットの概念が重要だと指摘されていました。サービスの稼働率を100%にするのではなく、ビジネス上許容できる停止時間を設定し、それを超えない範囲でサービスを運用する。この考え方は、SREが目指す現実的な信頼性の追求方法だと感じました。エラーバジェットの消費率を追跡することで、SREチームの価値を可視化し、経営層を納得させることができるというアイデアは、示唆に富んでいます。SREチームの予算確保の際は、組織が抱える課題を起点に議論することが肝要だと著者は述べています。漠然と「SREの予算が欲しい」と訴えても、説得力に欠けます。「ここ数ヶ月で発生した障害は許容できないレベルにあります。それを防ぐために、最低限このくらいのリソースが必要だ」といった具体的な問題提起が求められます。また、SREがもたらすインパクトを、顧客体験や機会損失の回避といったビジネス指標に言い換える工夫も大切だと感じました。一方で、SREチームが陥りがちな落とし穴についても言及がありました。デベロッパーから問題をすべて丸投げされ、単なる「ページャーモンキー」と化してしまう。改善活動がおろそかになり、問題対応に明け暮れる「トイルバケツ」になってしまう。こうした事態に陥らないよう、常にSREの役割と価値を組織に示し続ける必要があるのだと実感しました。また、SREチームのヘッドカウントについても、良い議論がありました。「開発者を残業から解放したい」といった安易な動機でSREチームを肥大化させるのは賢明ではありません。あくまで、サービスの信頼性目標の達成に必要十分な人員を確保することが肝要です。一方で、疲弊しすぎず、エンジニアリング活動に注力できる最低限の人数は確保すべきだとも述べられています。ビジネスの要請とSREの働き方のバランスを取ることの難しさを感じさせられました。全体を通して、SREの価値を経営層に伝え、組織に定着させていくことの重要性を再認識した章でした。技術的な側面だけでなく、ビジネスの文脈でSREの存在意義を示し続けることが、その役割を確立する上で欠かせません。とはいえ、そこに正解はなく、各組織の状況に合わせて、試行錯誤していくことが求められるのだと感じました。SREという役割に惹かれて飛び込んできた私たちエンジニアにとって、ビジネスの観点は、ともすれば苦手意識を持ちがちな領域かもしれません。しかし、本章で紹介されていたフレームワークは、経営層とのコミュニケーションを助けてくれる強力な武器になるはずです。SLOに基づくサービス運用、エラーバジェットによるインパクトの可視化、ビジネス課題起点の要員計画。そうした考え方を身につけることで、SREとしてのキャリアをより確かなものにしていけるでしょう。私自身、まだまだ経験の浅いSREですが、この章で得られた学びを胸に、技術とビジネスの両面でのSREの価値向上に努めていきたいと思います。開発チームと経営層の間に立ち、両者の言葉を翻訳しながら、信頼性というゴールに向かって組織を牽引していく。そんなSREのあるべき姿が、この章を通して見えてきたように感じています。単に技術的なスキルを磨くだけでなく、ビジネスの文脈でSREの価値を語れるエンジニアになること。それが、これからのSREに求められる資質なのかもしれません。経営層の期待に真摯に向き合いつつ、現場のエンジニアリングにも手を抜かない。 その両立は容易ではありませんが、その先にこそ、SREのやりがいがあると信じています。著者も述べているように、SREをビジネスの文脈で語ることは、まだまだ探求の余地がある領域だと感じました。一人一人のSREが、自らの経験を言語化し、共有し合うことで、その知見体系はさらに洗練されていくはずです。私も微力ながら、その営みに貢献していければと思います。技術の力で、ビジネスの信頼を勝ち得る。本章はそんなSREの新たな可能性を感じさせてくれる内容でした。エンジニアリングの高みを目指すと同時に、ビジネスの言葉を学び、組織への貢献を示し続けること。それがこれからのSREに求められる道なのだと感じています。Chapter 14. The Dickerson Hierarchy of Reliability (A Good Place to Start)本章は、SREを導入したばかりの組織が、何から着手すべきかを示してくれる指針を示してくれる章でした。著者のDavid Blank-Edelman氏は、システムの信頼性を高めるための取り組みは山のようにあるものの、その中から成果の上がる一歩を見出すのは容易ではないと指摘します。 そこで、この難題に対する最良の答えとして紹介されているのが、Mikey Dickersonが提唱した「The Dickerson Hierarchy of Reliability」です。ちなみに公式にもサービス信頼性の階層があります。Figure III-1. Service Reliability Hierarchy https://sre.google/sre-book/part-III-practices/ より引用この階層モデルは、信頼性向上に向けた取り組みを、monitoring/observability、incident response、postincident review、testing/release、provisioning/capacity planningの5つのレベルに分類しています。 そして、マズローの欲求段階説になぞらえて、下位のレベルから着実に積み上げていくことを推奨しているのです。シンプルながらも良いフレームワークだと感じました。印象的だったのは、最も重要な基盤としてmonitoring/observabilityが位置づけられている点です。 システムの現状を可視化し、改善の方向性を定める上で、モニタリングは欠かせない基盤になります。加えて、チーム内での建設的な議論を促し、SLOの設定を支えるなど、モニタリングが果たす役割の広がりにも気づかされました。また、著者がpostincident reviewを\"transformative\"かつ\"magical\"なプロセスだと称賛している点も印象的でした。 障害対応は、ともすれば時間と労力の無駄になりがちです。しかし、そこから学びを得て、システムを改善につなげられれば、むしろ価値を生み出せるのだと。レジリエンスエンジニアリングの知見を応用し、障害から学ぶ文化を組織に根付かせることの重要性を、改めて感じさせられました。もちろん、この階層モデルは、SREの業務すべてを網羅しているわけではありません。著者自身、モデルの限界を認めつつ、アーキテクチャやtoil改善におけるSREの貢献にも言及しています。 ただ、SRE導入の初期段階では、まずはこの5つのレベルに注力し、確実な成果を積み重ねていくことが肝要なのだと感じました。一方で、著者はSRE導入の過程で陥りがちな落とし穴についても警鐘を鳴らしています。 例えば、オンコール対応だけが仕事になり、「ページャーモンキー」と化してしまう。postincident reviewに偏重し、ソフトウェアライフサイクル全体への関与が疎かになる。crisisの対応に明け暮れ、smokejumperに成り下がる。SREがただの「エンジニア」とみなされ、開発チームに引き抜かれる。こうした兆候は、SREの価値を大きく毀損してしまうリスクを孕んでいます。とはいえ、SRE導入の道のりが平坦ではないことは、私自身、身をもって実感しているところです。大切なのは、地道な改善の積み重ねを通じて、組織にSREの存在価値を示し続けること。 オンコールの引き受けから始まった関係が、pull requestを通じた開発への貢献へと深化していく。モニタリングの指標がチームの共通言語となり、障害が減っていく。そうした目に見えるインパクトを着実に生み出していくことが、SREの評価を高める近道になるのだと感じました。全体を通して、体系立てて信頼性向上に取り組む上で、The Dickerson Hierarchy of Reliabilityが強力な羅針盤になり得ることを実感した章でした。 網羅的とは言えないまでも、スタートダッシュを切る上での重要な指針が凝縮されていると感じます。ただ、マニュアル通りにここまでやればOKというものでもないのがSREの面白さでもあります。 各組織のコンテキストに合わせて、創意工夫を重ねながら、hierarchy外の領域にもフロンティアを広げていく。その探究心こそが、SREたるゆえんなのかもしれません。私自身、ここ数年、監視基盤の整備や、incident responseの体制づくりに注力してきました。今後は、そこで得た知見を開発プロセスにも反映させつつ、proactiveなケイパシティプランニングにも踏み出していきたいと考えています。その過程では、様々な試行錯誤を重ねることになるでしょう。ただ、その試行錯誤こそがSREの真骨頂だと信じています。 ピラミッドを一歩ずつ登りながら、いつの日か、その頂へと辿り着けるよう、これからも研鑽を積んでいきたいと思います。Figure 14-1. Slightly modified version of the Dickerson Hierarchy of Reliability より引用著者が最後に投げかけてくれた「SREがうまくいっている兆候」も、私にとって大きな励みになりました。自分たちの存在が当たり前のように受け入れられ、モニタリングの指標が部門の共通言語になり、開発への貢献が目に見える形で認められる。そんな日が来るまで、地道に信頼性向上の階段を上っていきたいと思います。The Dickerson Hierarchy of Reliabilityは、SREという旅路に不可欠な道標だと感じました。 ただ、その先に広がるのは、各組織が切り拓くオリジナルのロードです。ゴールのない旅だからこそ、一歩一歩を大切にしながら、信頼性というバトンを手渡していく。私もその輪の中で、自分なりの道を見出していけたらと思います。Chapter 15. Fitting SRE into Your Organization本章は、SREを組織に導入する際の実践的な指針を提示してくれた章でした。SREの導入は、単なる技術的なプラクティスの適用にとどまらず、組織のカルチャーや構造とのフィット感を意識しながら、戦略的に進めていく必要があるのだと実感させられました。特に印象に残ったのは、SREの導入に際して、いきなり専任チームを立ち上げるのではなく、まずはSREの考え方や手法を、日々の業務の中で部分的に試してみることを推奨している点です。 例えば、サービスのSLI/SLOを定義してみる、ポストモーテム分析のやり方を見直してみるなど、小さな一歩から始められます。そうした草の根の取り組みを通じて、SREのメリットを組織に示しつつ、本格的な導入への足がかりを作っていく。地に足のついた漸進的なアプローチだと感じました。もちろん、環境次第では、いきなりSREチームが編成されたり、M&Aを通じてSREが編入されたりすることもあるでしょう。 そうした状況でも、SREの働き方を「実験」と位置づけ、仮説検証を重ねながら、最適解を模索していくマインドセットが大切だと述べられています。完璧なモデルなんてないのだから、試行錯誤を恐れずに、組織にフィットする形を追求していこうと。アジャイル的な考え方に通底するものを感じました。また、SREの組織的な位置づけについても、良い議論がありました。 中央集権型、分散型、ハイブリッド型の3つのモデルが紹介され、それぞれの長所と短所が丁寧に分析されています。組織の規模や成熟度、過去の前例などを考慮しつつ、自社に合ったモデルを選ぶ必要があるのだと。ただ、どのモデルを選ぶにしても、開発チームとSREチームが協調的に連携し、継続的な改善を推進できる体制を築くことが肝要だと強調されていました。そして、SREの真価は、組織内にフィードバック ループを張り巡らせ、回し続けることにあると著者は力説しています。 モニタリングや障害分析、カスタマーサポートのチケットなど、あらゆるデータをループの起点にできます。そこから学びを得て、システムを改善する。その改善が新たなデータを生み、さらなる学びにつながる。そんな好循環を生み出し、加速させていくことこそが、SREに期待される役割なのです。そのためには、データへのアクセス性を高め、部署間のコラボレーションを促し、改善業務をロードマップに組み込む努力も欠かせません。地道ながらも着実な一歩を重ねることで、徐々にフィードバックの文化が組織に根付いていくのだと感じました。さらに、SREがシステム開発の初期段階から関与し、「ゴールデンパス」と呼ばれる信頼性の高い設計を織り込んでいくことの重要性も説かれていました。 開発チームと二人三脚で課題解決に当たれば、SREの存在価値を浸透させやすくなります。単に既存システムの問題を後追いするのではなく、要件定義の段階からSREの知見を活用する。それこそが、本来あるべきSREの姿なのかもしれません。一方で、著者はSREの導入が軌道に乗っているかを測る「サインポスト」についても言及しています。 SREチームがゲートキーパー的な立場から脱却できているか。開発チームから自発的にSREの関与を求められるようになったか。ロードマップ策定にSREが参画できているか。リアクティブな仕事が減り、プロアクティブな改善が増えているか。そうした兆候は、SREが組織に根付きつつあることを示唆するバロメーターになるはずです。全体を通して、SREの導入は単なるエンジニアリング手法の変更ではなく、組織文化そのものの変革だと実感させられました。 信頼性を重視する価値観、学習と改善を尊ぶ姿勢、部門の壁を越えた協働。そうしたマインドセットを組織の隅々にまで浸透させていく営みが、SREの真髄なのだと。もちろん、それは一朝一夕で成し遂げられるものではありません。適切なモデル選択に始まり、土壌づくり、フィードバックループの確立、協調的な文化の醸成に至るまで、多岐にわたる課題にじっくりと向き合う必要があります。 技術的なスキルに加え、コミュニケーション力、調整力、課題発見力など、エンジニアリング以外の資質も問われるでしょう。ただ、だからこそ、SREの可能性は無限に広がっていると感じています。従来の枠を越えて、開発とオペレーション、ビジネスとエンジニアリングの架け橋となる。変化を恐れず、失敗から学びながら、より高い信頼性を追求していく。DX時代のビジネスを支える屋台骨を作り上げていく。 それは、私たちソフトウェアエンジニアに託された、困難だけれどもやりがいに満ちたミッションではないでしょうか。本章で提示された知見を道標に、自分なりのSREを模索する旅を続けていきたいと思います。技術とプロセスと文化が三位一体となった、真に強靭な組織を目指して。時には試行錯誤を重ねながらも、仲間やお客様とともに一歩ずつ前進していく所存です。SREの実践は、組織に新たな風を吹き込む触媒になるはずです。データに基づく意思決定の習慣、継続的な改善のサイクル、部門を越えた活発な議論。そうした文化が根付けば、システムの信頼性を高めるだけでなく、ビジネス全体の俊敏性と回復力を引き上げることができるでしょう。 外的な変化への適応力を武器に、競争を勝ち抜いていく。そんな強靭な組織をエンジニアリングの力で実現する。それこそが、DX時代におけるSREの使命だと感じています。もちろん、そこに至る道のりは平坦ではありません。従来の仕事のやり方を変えることへの抵抗、部門間の壁、複雑に絡み合ったレガシーシステム。SREの導入を阻む要因は、組織に深く根を下ろしています。それでも、私たちには武器があります。 学習と適応の文化を組織に根付かせる力、データの言葉で説得する力、人と人をつなぎ共感を生む力。SREに不可欠なのは、技術的なスキルに留まらない、そうした総合的な力なのだと信じています。この章を読み、改めてSREの意義と価値を再認識するとともに、その実現の難しさにも思いを馳せました。とはいえ、困難があるからこそ、そこに果敢に挑戦する意味があるのかもしれません。ソフトウェアエンジニアとして、ビジネスパーソンとして、時にはカウンセラーとして。 様々な顔を使い分けながら、組織にSREの種を蒔いていく。失敗を恐れず、仮説検証を重ねる。その積み重ねの先に、真に信頼性の高い組織と、自分自身の成長が待っているはずです。それは、GoogleやFacebookの真似をすることでは決して達成できない、自分たちオリジナルのSREへの旅になるでしょう。一筋縄ではいかない難題にも、仲間と知恵を出し合いながら、前向きに取り組んでいきたい。組織への共感を武器に、技術の力でレガシーな体質を変革していく。 そんなSREの理想図を胸に、今日も私は一歩を踏み出します。カイゼン・ジャーニー たった1人からはじめて、「越境」するチームをつくるまで作者:市谷 聡啓,新井 剛翔泳社AmazonChapter 16. SRE Organizational Evolutionary Stages本章は、SRE組織の成熟度モデルを提示することで、各組織がSREの導入と定着においてどの段階にあるのかを見定め、次のステップに進むための指針を示してくれる、良い章でした。SREは、単に技術的なプラクティスを導入すれば完成するものではありません。組織全体のマインドセットと文化を変革していく、息の長い取り組みだと改めて認識させられました。SRE ではないのですがCloud Native Computing Foundation（CNCF）も成熟度に関する「クラウドネイティブ成熟度モデル」のドキュメントをWebサイトで公開したり。Googleさん やサイバーエージェントさんがそれぞれ、公開していたりもします。※登壇したりしてました speakerdeck.com私が特に印象に残ったのは、著者が提示した SRE組織の5段階の成熟度モデル です。Stage 1: The Firefighter:消防士Stage 2: The Gatekeeper:ゲートキーパーStage 3: The Advocate:提唱者Stage 4: The Partner:パートナーStage 5: The Engineer:エンジニアこの分かりやすいフレームワークは、自組織のSREの取り組みを客観的に評価し、次のステージに進むための課題を明らかにする上で、強力なツールになるはずです。Chapter 16 \"SRE Organizational Evolutionary Stages\"は、SRE組織の成熟度を5つのステージで捉えた、良いフレームワークを提示してくれました。著者のBenjamin Purgasonは、自身の経験から導き出したこのモデルを通じて、SRE組織が辿る進化の道筋を明らかにしています。まず、ほとんどのチームが通過する ステージ1の「消防士」について、印象深い指摘がありました。 このフェーズでは、SREチームは日々発生する信頼性の問題に追われ、火消しに明け暮れます。重大な障害を食い止めるために、泥臭い努力を重ねる毎日。著者はこの状態からの脱却に、早くて数ヶ月、通常は数年かかると述べています。 つまり、SREチームの多くが不可避的に通る、苦難と忍耐の時期なのです。ただし、その間もただ受け身になっているだけではいけません。著者は、火事の合間を縫って、システムの理解を深めたり、「自動消火システム」を整備したりすることの重要性を説いています。 例えば、オートスケーリングの導入、負荷分散の最適化、自動フェイルオーバーの仕組み作りなど。泥沼から這い上がるために、地道な改善を積み重ねる。そうした努力なくして、次のステージへの移行は望めないのです。ステージ2の 「ゲートキーパー」における議論です。 ここでは、SREチームが変更管理の判定者や実行者となり、開発チームとの軋轢を生むリスクが指摘されています。プロダクションを守るためとはいえ、長期的に見れば、SREがゲートキーパーに留まるのは得策ではありません。開発者を不快にさせ、コラボレーションを阻害し、生産性を損なう。 そんな事態を招かないためにも、ゲートキーピングを自動化し、開発者と協調的な関係を築くことが肝要なのだと説かれていました。ステージ3の 「提唱者」 における「インテリジェントなリスクを後押しするツールの構築」 という発想も印象的でした。ダッシュボードやスコアカードを通じて十分なコンテキストを提供することで、現場の全社員が賢明な意思決定を下せるようにする。管理統制に頼るのではなく、「文脈」を武器に、自律的な判断を促していく。そんなSREの在り方に、大いに共感を覚えました。ステージ4の「パートナー」では、SREと開発者の関係が、真の協働へと昇華していきます。 単に役割分担するだけでなく、ロードマップや計画策定から一緒に取り組む。SREは信頼性に関わる共通基盤の構築に注力し、開発者はその恩恵に与りつつ、より高い信頼性を追求していく。そこには、対等なパートナーとしての関係性が育まれているのです。SREと開発者が心を一つにして、高い理想に向かって邁進する。そんな姿は、まさにSREのあるべき姿だと感じました。ステージ5の「エンジニア」の段階になると、SREと開発者の区別はほぼ無くなります。 全てのエンジニアが、システムのライフサイクル全体を通して、信頼性向上に資する活動に自発的に取り組むようになる。もちろん、SREは信頼性に特化した責務を担い続けますが、開発者との間に高度な結束と協調が生まれているのです。理想の姿ではありますが、インセンティブと組織構造のアラインメントによって、現実にも起こり得る。そう信じさせてくれる、野心的なビジョンだと感じ入りました。一方で、著者が述べているように、これらのステージは直線的なものではなく、行きつ戻りつするものだと肝に銘じる必要がありそうです。 火事は常に起こり得るし、ゲートキーピングの誘惑に駆られることもあるでしょう。重要なのは、理想のステージを意識しつつも、現実と折り合いをつけながら、地道にSREを根付かせていくこと。そのためには、各チームの置かれた状況に即して、適切なステージを見極める眼力も問われるはずです。全体を通して、SREの組織的な浸透は一朝一夕で成し遂げられるものではなく、泥臭い試行錯誤の連続であることを実感させられました。 技術的なスキルに加え、対人関係力、変革マネジメント力など、エンジニアリング以外の資質も問われる。一筋縄ではいかない難題にも、課題を正面から見据え、仲間と知恵を出し合いながら、一つ一つ解決していく。そうした地道な営みの先に、SREが組織に真に根付いた姿が待っているのだと信じたいと思います。私自身、まだ駆け出しのSREですが、このモデルを道標として、SREの理想形を模索していきたいと思います。消防活動に明け暮れる日々から脱却し、開発者との建設的な協働関係を築き、いつの日か高度な結束が生まれる段階へ。 そこに至るまでの道のりは決して平坦ではないでしょう。それでも、信頼性の大義を胸に、仲間とともに前を向いて歩んでいく所存です。本章のエッセンスは、「SREは単なる技術の問題ではなく、むしろ組織文化の問題である」という一点に集約されるのかもしれません。 信頼性を重視するマインドセット、学習と成長を称揚する雰囲気、自発的なコラボレーションを促す仕組み。そうした目に見えない基盤を地道に築くことなくして、真のSREは宿らない。だからこそ、私たちには技術者としてのスキルと並んで、文化の耕し手としてのセンスが求められているのだと。この辺は運用技術者組織の設計と運用 / Design and operation of operational engineer organizationやエンジニア組織論への招待を読むと良さそうなので記載しておく。 speakerdeck.comエンジニアリング組織論への招待　～不確実性に向き合う思考と組織のリファクタリング作者:広木 大地技術評論社AmazonChapter 17. Growing SRE in Your Org本章は、組織の中でSREをどのように成長させていくかについて、著者の豊富な経験と知見に基づいて解説した、良い章でした。SREは、単に技術的なプラクティスを導入すれば完成するものではありません。組織の規模や成熟度に応じて、戦略的に育てていく必要があるのだと改めて認識させられました。組織戦略の考え方　――企業経営の健全性のために (ちくま新書)作者:沼上幹筑摩書房Amazon印象に残ったのは、著者が 「SREの規模拡大は、必ずしも『大きいほど良い』とは限らない」 と警鐘を鳴らしている点です。SREチームの規模を際限なく大きくすることが目的化してしまうと、かえって非効率を招く恐れがあります。大切なのは、組織のコンテキストに即して、適切な規模と体制を追求していくこと。 そのためには、チームの分割や再編成を恐れず、フットワークの軽さを保つ柔軟性も求められるでしょう。SREチームの規模感について、著者は具体的な数字を提示しています。SREが組織に導入された初期段階では、わずか1人から6人程度のチームで始めることが多いそうです。 この時期は、SREの考え方や手法を部分的に試すフェーズ。小さな成功体験を積み重ねながら、徐々に組織への浸透を図っていきます。モニタリングの改善、SLO/SLIの設定、ポストモーテム分析の実践など、できることから着手するのです。チームの規模が6人から18人に拡大すると、オンコール体制の整備が本格化します。 健全なワークライフバランスを保ちつつ、24時間365日の監視を実現するには、最低でも18人は必要だと著者は指摘しています。この規模になると、役割の細分化も進み、メンバーそれぞれの専門性を活かした活動が可能になります。ただし、チームの一体感を保ち、ナレッジの共有を促進する工夫も欠かせません。さらにチームが48人規模に拡大すると、SREはもはや1つのチームではなく、複数のチームから成る組織体となります。 ここからは、各チームの役割分担や連携の在り方が問われるフェーズ。サービス領域ごとの専門チーム、共通基盤の開発に特化したチーム、ツール整備に注力するチーム、現地に密着した分散型チーム。 組織のニーズに応じて、最適な体制を模索していく必要があります。同時に、SREの理念や価値観を浸透させ、統一感を保つための仕掛けづくりも欠かせません。そして、SRE組織が100人を超える規模になると、専門性と融合のバランスを取るハイブリッド型の組織設計が求められると著者は説きます。 機能領域や技術領域ごとの深い専門性を追求しつつ、部門を越えた協調を促す枠組み。プロセス改善を担うSREチーム、全社的なプラットフォームを整備するSREチーム。多様性と統一性を両立する、柔軟な組織マネジメントが問われるフェーズだと言えるでしょう。この先のさらなる成長ステージでは、SREがプラットフォームエンジニアリングの領域にも踏み込んでいくビジョンが示唆されていました。システムを支える基盤的なライブラリやフレームワークを自ら開発し、組織全体の開発力を底上げしていく。 そこまで至れば、SREは組織のエンジニアリング文化そのものを形作る存在になるはずです。もちろん、それは容易な道のりではありません。でも、その理想に向かって一歩ずつ前進していく。それこそが、志高きSREチームの使命なのかもしれません。DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス作者:黒須 義一,酒井 真弓,遠山 陽介,伊藤 利樹,饒村 吉晴日経BPAmazon一方で、著者は 「SREは融合と結束の担い手でなければならない」 と強調しています。組織が大きくなればなるほど、分断と分散のリスクは高まります。技術選定の方針、プロセスの標準化、文化的な価値観。チームによってバラバラになってしまっては、SREの真価は発揮できません。だからこそ、differences（違い）は認めつつ、deindividualization（個性の喪失）は避ける。多様性を尊重しつつ、共通の目標に向かって結束する。そんな組織デザインのセンスが、SREリーダーには強く求められるのです。さらに、著者は 「SREの技術的スケールだけでなく、リーダーシップの規模拡大にも目を向けるべき」 だと訴えかけています。トップマネジメントの意思決定の場に、SREの視点が適切に反映される体制を整えること。それは、SREの組織的な浸透を支える大前提だと。単に人数を増やすだけでなく、価値観を共有し、変革を牽引する存在として、力強くスケールしていく。 そんなSREリーダーの姿が思い描かれていました。本章を読み終えて、私はSREという職能の奥深さを改めて実感しました。技術的な側面だけでなく、組織デザイン、リーダーシップ、文化の醸成など、実に多様な顔を持ち合わせている。 だからこそ、SREのスケールは単線的なものではなく、状況に応じた柔軟な判断が求められるのだと。「組織の成長に合わせて、SREも共に進化していく」。そんな著者の言葉が強く印象に残りました。もちろん、その道のりは平坦ではありません。SREの価値への理解不足、既存の体制への固執、変化への抵抗。スケールの障壁は数多く立ちはだかるでしょう。それでも、信念を持って粘り強く向き合っていく。泥臭い説得を重ね、地道な実績を積み上げ、仲間を巻き込みながら、少しずつ前に進んでいく。 私はそれこそが、志あるSREリーダーの真の姿なのだと感じています。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazon本章は、SREの組織的な拡がりについて、体系的な知見を提供してくれる、良い内容でした。単に数合わせでスケールするのではなく、組織のコンテキストを見極め、長期的な視点で育てていく。 技術と組織と文化をバランス良く強化し、全社的な変革を促していく。これからのSREリーダーには、そんな繊細かつ大胆なアプローチが求められているのだと実感させられました。エンジニアの端くれとして、組織論や文化論に首を突っ込むのは、少し居心地の悪さを感じるかもしれません。でも、それこそがSREの醍醐味であり、やりがいなのだと信じています。技術の力で勝ち得た信頼を武器に、組織に新しい風を吹き込んでいく。 そいう姿勢を問われている気がしました。Chapter 18. Conclusion『Becoming SRE』の最終章である第18章「Conclusion」は、読者への感謝と別れの言葉から始まります。著者のDavid Blank-Edelman氏は、SREの本質をコンパクトに凝縮しつつ、読者を新たな旅立ちへと送り出そうとしています。その語り口は、まるで優しい師が弟子に最後の教えを授けるかのようです。この章で改めて強調されているのは、SREが目指す「システムの信頼性」という崇高な目標です。それは、個人としても、組織としても、他者と協調しながら追求していくべき理想だと。特定のマインドセットと文化を共有し、周到な準備を重ねたSREたちが、組織の支援を得ながら、様々なスケールでその理想を実現していく。SREの真髄は、まさにそこにあるのだと著者は説いています。そして、著者は 「SREの仕事はfun（楽しい）であり、rewarding（やりがいがある）」 と力説します。もちろん、常にそうとは限りません。難しい局面に直面することもあるでしょう。でも、総じて素晴らしい仕事だと。信頼性という難問に立ち向かい、仲間とともに現実に意味のあるインパクトを残せる。 そのチャレンジは、けして退屈ではあり得ないのだと。読者にSREへの情熱の一端でも伝われば幸いだと、著者の想いが伝わってきます。おわりに『Becoming SRE』を読み終え、SREという職能の奥深さと広がりを新たに感じました。David Blank-Edelman氏は、SREが技術を超え、組織文化そのものを変革していく役割を果たすことを鮮明に描いています。本書を通じて、システムの信頼性を追求するミッション、必要なマインドセットとスキル、そしてその知見が組織内に浸透し定着するまでの過程が体系的かつ実践的に語られました。SREの役割は単に技術的な問題を解決するだけではなく、信頼性という難題に直面し、それに対峙しながら仲間と共に粘り強く取り組むことにあります。これは、エンジニアリングの枠を超えた、大きなやりがいを提供します。しかしながら、SREへの道は容易ではありません。個人と組織の両方で、多くの障壁に直面することがあります。本書は、フィードバックループの重要性、障害から学ぶ文化、コラボレーションの極意など、困難を乗り越えるための具体的な方法を提供しています。これらの知見は、SREとして成長するためのサポートとなるでしょう。そして、SREの醍醐味とその意義を再確認することができました。著者が指摘するように、SREの究極の目的はシステムの信頼性を通じて人々に価値を提供することにあります。日々の挑戦と探求の精神が、SREの本質です。SREsのためのSRE定着ガイドからの引用ではありますが外部リソースの注入は、SREの実践において選択肢の一つとして考えられます。重要なのは、前提として、自分たちでやりきれるならその方が良いということです。『Becoming SRE』の教訓にもあるように、SREは技術的な問題解決だけでなく、組織文化の改善やビジネス価値の向上を目指します。しかし、定点観測のような繰り返しの作業や、組織内変化の促進に際して、内部ではやりきれずに外部エキスパートの助言が必要となる場合もあります。例えば、nwiizoが所属している3-ShakeやX-Tech5、Topotal、などの外部のサービスや専門家を利用することは、新たな視点をもたらし、特定の課題に対して効果的な戦略を実施する支援を提供できます。しかし、これはプロジェクトや組織によっては、改善を目指す一つの方法であることを忘れずに。SREの目指すところは、あくまで内部の力で課題を乗り越え、成長することにあります。外部リソースの活用は、そのプロセスを補助する手段の一つとして考えるべきでしょう*1https://ja.wikipedia.org/wiki/%E5%BA%83%E5%91%8A。最後に、SREの旅に終わりはありません。著者が贈るメッセージ、「大切なのは、その旅を楽しみ、学び続けること」を胸に、私たちも一歩一歩前進していきましょう。外部リソースの適切な活用は、その旅をより豊かで有意義なものにする一助となるでしょう。今回の本の内容要約においては、「A. Letters To A Young SRE」「B. Advice From Former SREs」「C. SRE Resources」という付録の部分のはレビューの対象とはしていませんでした。これらの部分には、SREを志す若者への手紙、経験豊富なSREからのアドバイス、SREのための参考資料など、非常に興味深い内容が含まれています。ご紹介できなかったのは残念ですが、本書の中核をなす部分に注力するために割愛させていただきました。 もしこの先SREの道に進まれる際には、ぜひこれらの付録もじっくりと読まれることをおすすめします。きっと、SREとしての歩みを確かなものにしてくれるはずです。この学びを糧に、今日も信頼性という難問に立ち向かっていきます。「Fun:楽しむ」と「Rewarding:やりがいのある」を胸に、SREの醍醐味を味わいつつ。最後になりましたが、素晴らしい書を生み出してくれた著者のDavid Blank-Edelman氏に、心からの感謝を捧げたいと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。*1:広告","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/08/165909","isoDate":"2024-04-08T07:59:09.000Z","dateMiliSeconds":1712563149000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"go-rod/rod でブラウザ自動化とWebスクレイピングをやっていく","contentSnippet":"はじめにWebスクレイピングの需要が高まる中、Goで実装する機会が増えてきました(よね?)。Goの豊富な標準ライブラリとシンプルな文法は、スクレイピングのような自動化タスクと非常に相性が良いです。が、今回はGoの有力なスクレイピングライブラリの1つである go-rod/rod の特徴を掘り下げながら、実際に現在所属している組織のサイト3-shake.comのWebサイトをスクレイピングする方法をご紹介します(広告的に許してくれ)。github.comgo-rod/rod の概要と特徴go-rod/rod`は、ChromeのDevToolsプロトコルを利用したブラウザ自動化とスクレイピングのためのハイレベルなドライバーライブラリです。単なるHTMLの取得だけでなく、ブラウザ上の操作を自動化できるのが大きな特長です。主な特徴は以下の通りです:ページのスクリーンショットを撮るクライアントサイドレンダリングされたページもスクレイピング可能フォームの自動入力E2Eテストリクエストのハイジャックつまり、ブラウザ上で手動で行える操作のほとんどを自動化できるわけです。これによりJavaScriptで動的に生成されるモダンなWebサイトに対しても、自在にスクレイピングを行えます。go-rod.github.ioまた、Goらしいシンプルで読みやすいAPIを提供しているのも魅力です。実装の詳細を隠蔽しつつ、柔軟で強力な機能を直感的に使用できるよう設計されています。インストールと基本的な使い方go-rod/rod は次のコマンドで簡単にインストールできます。go get github.com/go-rod/rodインストール後、Goのコードから次のように呼び出すことでブラウザを起動できます。package mainimport \"github.com/go-rod/rod\"func main() {    browser := rod.New().MustConnect().MustPage(\"https://3-shake.com/\")    browser.MustWaitStable().MustScreenshot(\"3-shake.png\")    defer browser.MustClose()}ここではブラウザオブジェクトを生成し、MustConnect() でブラウザプロセスに接続して続いて MustPage() を使ってページを開きます。それをMustScreenshot()を使ってスクリーンショットを撮っていきます。こちらがスクリーンショットです。defer 文で最後にブラウザを閉じるのを忘れずに。これだけでブラウザの自動操作の準備は整いました。めちゃくちゃにシンプルですね。3-shake.com のスクレイピングそれでは、実際に https://3-shake.com のWebサイトをスクレイピングしてみましょう。今回は以下の情報を抽出することを目標とします。全サービスの名前と説明文全ニュースのタイトルと日付サービス情報の抽出まず、サービス一覧を表示している要素を特定します。サイトを開発者ツールで覗いてみると、各サービスが以下のようなDOM構造になっていることがわかります。<li class=\"services__item\">    <div class=\"services__block js-inview\" data-inview-x=\"30\" data-inview-s=\"700\">        <p class=\"services__pic js-parallax\">            <img src=\"path/to/image\">        </p>    </div>    <div class=\"services__block js-inview\" data-inview-x=\"-30\" data-inview-s=\"700\">        <div class=\"services__texts\">            <div class=\"services__name\">                <a href=\"path/to/service\" target=\"_blank\">                    <img src=\"path/to/logo\">                    <p>サービス名<br><span>サービス名ふりがな</span></p>                </a>            </div>            <p class=\"services__lead\">サービスの説明文</p>            <p class=\"services__link p-text--link\">                <a href=\"path/to/service\" target=\"_blank\">サービスサイトへ<i class=\"p-icon-arrow-right\"></i></a>            </p>        </div>    </div></li>これを元に、スクレイピングコードを書いていきます。// サービス情報をスクレイピングservices := page.MustElements(\"li.services__item\")for _, service := range services {    name := service.MustElement(\".services__name\").MustText()    description := service.MustElement(\".services__lead\").MustText()    fmt.Printf(\"サービス名: %s\\n\", name)    fmt.Printf(\"説明文: %s\\n\", description)    fmt.Println(\"---\")}MustElements() で li.services__item にマッチする要素を全て取得し、それぞれの要素から MustElement() と MustText() でサービス名と説明文を抜き出しています。ニュース情報の抽出次にニュース一覧を取得しましょう。こちらは以下のようなDOM構造になっています。<div class=\"p-articles js-news__target l-col l-col--list js-inview-box\" data-inview-y=\"15\">                       <div class=\"p-articles__item l-col__block--4 is-show\">        <div class=\"p-articles__thumb\">            <a class=\"p-articles__link\" href=\"path/to/news\" target=\"_self\">                <span style=\"background-image: url('path/to/image');\"></span>            </a>        </div>        <div class=\"p-articles__info\">            <p class=\"p-articles__date\">YYYY.MM.DD</p>            <ul class=\"p-categories\">                <li class=\"p-categories__item\">                    <a href=\"path/to/category\">カテゴリ名</a>                </li>            </ul>        </div>        <p class=\"p-articles__text\">            <a class=\"p-articles__link\" href=\"path/to/news\" target=\"_self\">ニュースタイトル</a>        </p>    </div></div>これを元にスクレイピングコードを書きます。package mainimport (    \"fmt\"    \"github.com/go-rod/rod\")func main() {    browser := rod.New().MustConnect()    defer browser.MustClose()    page := browser.MustPage(\"https://3-shake.com/\")    // ニュース情報をスクレイピング    newsList := page.MustElement(\".p-articles.js-news__target.l-col.l-col--list.js-inview-box\")    newsItems := newsList.MustElements(\".p-articles__item\")    for _, item := range newsItems {        title := item.MustElement(\".p-articles__text\").MustText()        date := item.MustElement(\".p-articles__date\").MustText()        fmt.Printf(\"タイトル: %s\\n\", title)        fmt.Printf(\"日付: %s\\n\", date)        fmt.Println(\"---\")    }}ニュースが .p-articles.js-news__target.l-col.l-col--list.js-inview-box の中にあるので、まずはその要素を MustElement() で取得します。そこから .p-articles__item を全て取り出し、タイトルと日付を抽出しています。これで目的の情報が取得できました。実際に出力してみると次のようになります。実際にテキストも転記しておく、、、。タイトル: 自動脆弱性診断ツール「Securify」、AI技術を駆使する「ai6」が導入日付: 2024.04.05---タイトル: 『ferret』に寄稿記事が掲載されました。日付: 2024.03.25---タイトル: 自動脆弱性診断ツール「Securify」、大手通信販売会社「フェリシモ」が導入日付: 2024.03.22---タイトル: Relance　フリーランス協会の「認定マッチング事業者」として今年も正式採択日付: 2024.04.03---各サービスの名前と説明文、ニュースのタイトルと日付がきちんと取得できていますね。フォームの自動入力や並列数を上げての負荷試験を兼ねたE2Eテストも行いましたが流石に迷惑になるので自分のユースケースにあったコードをexamples から探して下さいgithub.comヘッドレスモードでのスクレイピングgo-rod/rodの大きな特徴の1つに、ヘッドレスモードでのブラウザ操作があります。ヘッドレスモードとは、GUIを持たない状態でブラウザを起動し、バックグラウンドで動作させる機能です。通常、ブラウザを自動操作する際にはブラウザウィンドウが立ち上がりますが、ヘッドレスモードならそれがありません。その分リソースを節約でき、サーバー上での実行に向いています。CIパイプライン内でのテストなどにも利用できます。負荷試験などにも使えるかもしれないので調査中です。    // github.com/go-rod/rod/lib/launcher を利用する    // ヘッドレスブラウザを起動する    url := launcher.New().MustLaunch()    browser := rod.New().ControlURL(url).MustConnect(\"https://3-shake.com/\")    // スクレイピング対象のページを指定する    page := browser.MustPage()launcher はやっていくと必要になる場面が出てくるので一通り目を通して置くと後に応用が効くかもです。github.comおわりに今回はGoのスクレイピングライブラリ go-rod/rod の特徴を確認しながら、Webサイト https://3-shake.com/ から情報を抽出する方法を紹介しました。go-rod/rod の優れた点は、ChromeのDevToolsプロトコルを利用してブラウザを直接操作できることです。これによりサーバーサイドだけでなく、クライアントサイドで動的に生成されるコンテンツに対しても柔軟にスクレイピングを行えます。Goのシンプルな文法とあいまって、簡潔かつパワフルなスクレイピングスクリプトが書けるのが魅力ですね。ぜひ皆さんも go-rod/rod を使って色々なWebサイトに挑戦してみてください。スクレイピングが必要とされるシーンは今後ますます増えていくでしょう。Goと go-rod/rod を使いこなせば、そんな要望にも難なく応えられるはずです。快適で効率的なスクレイピングライフを送っていきたいと思います参考資料github.com/go-rod/rodgo-rod","link":"https://syu-m-5151.hatenablog.com/entry/2024/04/05/145103","isoDate":"2024-04-05T05:51:03.000Z","dateMiliSeconds":1712296263000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Platform Engineering on Kubernetes を読んでCloud Native の現在地を理解する","contentSnippet":"はじめに近年、Kubernetesの採用が進む中、複数のチームが関わり、複数のクラウドプロバイダーへのデプロイを行い、異なるスタックを扱う組織では、その導入の複雑さが新たな問題となっています。本書 『Platform Engineering on Kubernetes』は、Kubernetes に登場しつつあるベストプラクティスとオープンソースツールを活用し、これらのクラウドネイティブの問題を技術的に組織的にどのように解決するかを示してくれます。learning.oreilly.com本書では、Kubernetes上に優れたプラットフォームを構築するための要素を明確に定義し、組織の要件に合わせて必要なツールを体系的に紹介しており、実際の例とコードを交えながら各ステップをわかりやすく説明することで、最終的にはクラウドネイティブなソフトウェアを効率的に提供するための完全なプラットフォームを作成できるようになるとともに、プラットフォームチームと開発チームの緊密な連携の重要性が強調され、両者の垣根を越えてアプリケーションとインフラストラクチャが一体となったソフトウェア開発を実現することこそが、クラウドネイティブ時代のDevOpsの理想形だと感じました。ぜひ、本稿をお読みいただき、クラウドネイティブ時代のプラットフォームエンジニアリングに必要な知識とスキルと自社に最適なプラットフォームを設計・構築できるようになる必要性を感じたのであれば『Platform Engineering on Kubernetes 』をぜひ、読んでいただきたいです。Platform Engineering on Kubernetes作者:Salatino, MauricioManningAmazon『Platform Engineering on Kubernetes』 の構成本書は全9章で構成されており、カンファレンスのアプリケーションを構築するための \"walking skeleton\" (PoC、概念実証、デモアプリケーション)を用いて解説が進められる。第1章では、プラットフォームとは何か、なぜそれが必要なのか、そしてクラウドプロバイダーが提供するものとどう違うのかを紹介する。第2章では、Kubernetes 上で動作するクラウドネイティブで分散されたアプリケーションを構築する際の課題を評価する。第3章では、異なるクラウドプロバイダー上でアプリケーションを実行するためのリソースの構築、パッケージ化、デリバリーに必要な追加手順に焦点を当てる。第4章では、パイプラインの概念を中心に、GitOps アプローチを用いて複数の環境の構成を宣言的なアプローチで管理する方法を説明する。第5章では、Crossplane を使用してクラウドプロバイダー間でアプリケーションのインフラストラクチャコンポーネントをプロビジョニングする Kubernetes ネイティブなアプローチについて説明する。第6章では、開発環境の作成に特化した、Kubernetes 上にプラットフォームを構築することを提案する。第7章では、プラットフォームチームが利用可能なリソースにどのように接続するかを決定できるアプリケーションレベルの API で開発チームを支援することに焦点を当てる。第8章では、新しいリリースを本格的にコミットする前に実験するために使用できるリリース戦略を示す。第9章では、プラットフォームの構築に使用するツールからデータを取り込み、プラットフォームエンジニアリングチームがプラットフォームの取り組みを評価するための重要な指標を計算する2つのアプローチを評価する。本書の最後には、Kubernetes 上でプラットフォームがどのように構築されるのか、プラットフォームエンジニアリングチームの優先事項は何か、そして成功するためにクラウドネイティブスペースの学習と最新情報の把握がいかに重要であるかについて、明確なイメージと実践的な経験が得られるようになっています。知識を身体化するハンズオン本書のリポジトリは公開されており、読者は書籍の内容に沿ってハンズオンを実施することができます。これは非常に重要な点です。なぜなら、実際に手を動かして体験することで、書籍で得た知識を体験として自分のものにできるからです。技術書を多読するタイプなのですが別に一度で理解できるタイプの人間ではないので読んでみて良いと思った書籍のみ手を動かして理解するようにしています。github.comKubernetesは、複雑で広範囲に及ぶ分野です。書籍を読んで理解したつもりでも、実際に試してみると躓くことが多々あります。その都度、問題を解決していくことで、より深い理解を得ることができるのです。ですから、読者の皆さんには、ぜひ書籍と一緒にハンズオンに取り組んでいただきたいと思います。文章を読んだだけで分かった気にならないでください。実際に手を動かし、試行錯誤することが、本当の意味での学習には欠かせません。CloudNative Days Tokyo 2023 実行委員会が公開している『一日で学ぶクラウドネイティブ技術実践ハンズオン』は、クラウドネイティブ技術の基礎から実践的な内容まで、1日で集中的に学べる充実した内容となっています。クラウドネイティブの概念やコンテナ技術、Kubernetes、マイクロサービスアーキテクチャなどの主要なトピックがカバーされており、実際にハンズオン形式で技術を体験できるのが特徴です。クラウドネイティブ技術の入門としてお勧めの教材となっています。github.comまた、所属組織でも独自のクラウドネイティブ技術に関する研修を提供しております。弊社の研修では、実際の業務で活用できる実践的なスキルの習得に重点を置いています。カリキュラムの概要については公開しておりますので、ご興味のある方はぜひご覧ください。クラウドネイティブ技術の習得を目指す方に向けて、効果的な学習の機会を提供できればと考えております。sreake.com1 (The rise of) platforms on top of Kubernetesクラウドネイティブ時代の本格的な幕開けとともに、Kubernetesは急速に普及し、コンテナ化されたアプリケーションを運用するための事実上の標準となりました。本章では、まずプラットフォームの定義とその必要性が丁寧に説明されています。プラットフォームとは、企業が顧客向けのソフトウェアを開発・運用するために必要な一連のサービスを提供するものであり、開発チームが効率的に価値を届けるためのワンストップショップの役割を果たします。また、プラットフォームは静的なものではなく、組織の成熟度に合わせて進化していくべきものというような主張がされている点が印象的でした。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonクラウドプロバイダーが提供するサービスは、レイヤー別に分類され、それぞれの特徴が解説されています。Figure 1.1 Cloud provider's services categories より引用特に、アプリケーション固有のニーズを満たすためには、これらのサービスを組み合わせ、独自のレイヤーを構築する必要があると強調されています。この点については、『CloudNativeな時代に求められるWebサービス基盤モデルの再考』というタイトルで登壇した際にもまとめています。また、クラウドプロバイダーが提供するプラットフォームの特徴として、API、SDK、CLI、ダッシュボードなどが挙げられています。これらのツールを効果的に組み合わせることで、開発チームはアプリケーションをスムーズに構築・デプロイできます。一方で、プロバイダー固有のツールやワークフローを学習するコストも無視できないと指摘されています。Google Cloud Platform (GCP) を例に、クラウドプロバイダーが提供するダッシュボード、CLI、API の実際の使用例が紹介されています。これらのツールは、リソースのプロビジョニングを大幅に簡素化してくれますが、一方でプロバイダー固有の知識が必要とされる点にも触れられています。cloud.google.comクラウドプロバイダーのプラットフォームが広く受け入れられている理由として、API主導の設計、充実したツールの提供、そして従量課金モデルが挙げられています。特に、開発チームが必要なリソースをオンデマンドで利用できる点は、ビジネスのアジリティを高める上で大きなメリットだと言えます。次に、Kubernetes 上にプラットフォームを構築することの意義と、そのためのエコシステムについて解説されています。Kubernetes は、クラウドネイティブなアプリケーションを開発・運用するための基盤として広く採用されていますが、それ自体はプラットフォームではなく、プラットフォームを構築するための構成要素を提供するものだと位置づけられています。Kubernetes を導入する際には、単にツールを選定するだけでなく、組織の文化や成熟度に合わせて、段階的にプラットフォームを構築していくことが重要だと説かれています。Figure 1.11 Platform journey on Kubernetes より引用また、プラットフォームチームは、開発チームを内部の顧客と捉え、彼らのワークフローに合わせてプラットフォームを設計すべきだと強調されています。Cloud Native Computing Foundation (CNCF) は、クラウドネイティブなエコシステムを推進する団体であり、Kubernetes を含む多くのオープンソースプロジェクトをホストしています。https://landscape.cncf.io/ より引用landscape.cncf.ioこれらのプロジェクトを適切に組み合わせることで、ベンダーロックインを回避しつつ、柔軟なプラットフォームを構築できると説明されています。プラットフォームエンジニアリングの役割と、その重要性についても述べられています。プラットフォームチームは、社内の開発チームを顧客と捉え、彼らが効率的にソフトウェアを開発・デリバリーできるように、プラットフォームというプロダクトを提供します。Figure 1.14 Platform teams take the work done by developers safely to production. より引用国内でもPlatform Engineering MeetupやPlatform Engineering Kaigi 2024が開催され、とても注目される分野となっています。Platform Engineeringは、開発チームが効率的にアプリケーションを開発、デプロイ、運用できるようにするための基盤を提供することを目的としています。この分野では、Kubernetesがプラットフォームの中核として広く採用されています。自分が最初にKubernetesをプラットフォームとして認識したのは、プラットフォームの上でものを作るということを読んでからです。この記事では、Kubernetesがプラットフォームとしてどのような役割を果たすのかが詳しく解説されており、開発者がアプリケーションに集中できる環境を提供することの重要性が強調されています。また、Kubernetesを始めたばかりで、Platform Engineeringの概念についてよく分からないという人は、k8sを始める人に知ってもらいたい、Platform Engineeringの話を読むことをおすすめします。このスライド資料では、Platform Engineeringの基本的な考え方や、Kubernetesを活用したプラットフォーム構築の手法が分かりやすく解説されています。platformengineering.connpass.comまた、プラットフォームは単なるツールの寄せ集めではなく、開発チームのワークフローに合わせて設計され、シームレスな開発体験を提供することが求められます。市販のプラットフォームを導入するだけでは、組織特有のニーズを満たすことは難しいと指摘されています。Red Hat OpenShift や VMware Tanzu などの製品は、一定の抽象化を提供してくれますが、それでも組織に合わせたカスタマイズが必要になるケースが多いようです。Figure 1.15 Building platforms on top of Kubernetes distributions より引用結局のところ、自社に最適なプラットフォームを構築するためには、社内でプラットフォームエンジニアリングに取り組む必要があるということですね。本書の中にも組織の話がたくさん出てくるし、本稿でも少し組織のような話に逸れます。『DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス』は、クラウドサービスを効果的に活用し、DXを成功させるために不可欠な、自社のユースケースに適したサービスの選択・統合と社内でのクラウドエキスパートの育成について、特にリーダーシップ、ビジネス、テクノロジーを備えたクラウド活用推進組織「CCoE」の存在の重要性を強調しています。本書では、CCoEの基本概念から立ち上げ方法、課題解決方法まで、先進企業の実例を交えてわかりやすく説明しています。クラウドネイティブ時代に適応し、DXを成功させるためには、プラットフォームの構築と進化、クラウドサービスの効果的な活用、そしてCCoEの組織化が重要であり、これらの取り組みを通じて、企業は顧客により高い価値を提供し、競争力を高めていくことができるでしょう。これらの課題解決の手引きとなる一冊であり、合わせて読むのがオススメの書籍です。DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス作者:黒須 義一,酒井 真弓,遠山 陽介,伊藤 利樹,饒村 吉晴日経BPAmazon本書で使用されるカンファレンスのアプリケーションの例も紹介されています。この「ウォーキングスケルトン」と呼ばれるサンプルアプリケーションは、クラウドネイティブなアーキテクチャのベストプラクティスを示すと同時に、以降の章で紹介されるプラットフォーム構築の手法を実践的に学ぶためのユースケースとして機能します。このカンファレンス用のアプリケーションは、マイクロサービスアーキテクチャに基づいて設計された Web アプリケーションであり、複数のバックエンドサービスと、それらを呼び出すフロントエンドで構成されています。Figure 1.18 Conference application services. The end user interacts with the frontend that routes requests to all the backend services. より引用各サービスは独立して開発・デプロイできるため、チーム間の自律性を高めつつ、アプリケーション全体の柔軟性と回復性を向上させることができます。モノリシックなアーキテクチャと、マイクロサービスアーキテクチャの違いについても説明されています。モノリシックなアプリケーションでは、すべての機能が1つのコードベースに含まれているため、スケーリングや更新に制約が生じやすくなります。Figure 1.20 In a monolith application, all the logic to implement different use cases are bundled together. This push different teams to work on the same codebase and requires them to have complex coordination practices to avoid conflicting changes. より引用一方、マイクロサービスでは、各サービスが独立して開発・デプロイできるため、より柔軟で回復性の高いアプリケーションを構築できると説明されています。最後に、本書で扱うプラットフォーム構築の手法が、カンファレンスのアプリケーションを例に概説されています。各章では、CI/CD、環境の管理、クラウドリソースのプロビジョニングなど、プラットフォームを構成する様々な要素が取り上げられ、それらを組み合わせることで、開発チームの生産性を高めるプラットフォームを構築していく過程が紹介されます。また、プラットフォームの効果を測定するための指標や手法にも触れられており、継続的な改善の重要性が強調されています。第1章を通じて、プラットフォームを Kubernetes 上に構築することの意義と、そのための手法が体系的に説明されていました。特に、プラットフォームを「内製のプロダクト」と捉え、開発チームを「顧客」と見なすという視点は、DX時代における開発組織のあり方を考える上で示唆に富むものでした。これらのSREとの手法の違いについては以下のような内容で登壇したことがあります。 speakerdeck.com私自身、大規模な Web アプリケーションの開発に携わった経験から、モノリシックなアーキテクチャの限界を痛感しています。機能追加や変更に多大な時間と工数を要していたのが、マイクロサービス化を進めることで、各チームが独立して開発を進められるようになり、リリースサイクルを大幅に短縮できました。クラウドネイティブなアプリケーション開発において、マイクロサービスアーキテクチャが果たす役割の大きさを実感しています。また、CNCF のプロジェクトを活用しつつ、自社に最適なプラットフォームを構築していくアプローチは、クラウドネイティブな開発に取り組む多くの組織にとって参考になるはずです。私自身、日々の業務の中で、クラウドネイティブな開発の推進と、それを支えるプラットフォームの構築に取り組んでいます。本書で得られる知見を活かし、自社に最適なプラットフォームを設計・運用していきたいと考えています。著者の深い知見と経験に基づく解説は、インフラエンジニアのみならず、アプリケーション開発者やアーキテクトなど、様々な立場の読者に価値を提供してくれるでしょう。プラットフォームチームと開発チームの関係性や、CNCF の活動など、日々の業務では触れる機会の少ないトピックについても、明快に解説されていたのが印象的でした。本書の残りの章では、このような考え方を基盤に、より具体的なプラットフォーム構築の手法が展開されていきます。第1章で示された知見は、プラットフォームエンジニアリングに携わる全ての人にとって、大きな助けになるはずです。著者の知見とバランス感覚に裏打ちされた記述は、まさにクラウドネイティブ時代の最前線に立つエンジニアならではのものです。これからのソフトウェア開発には、プラットフォームチームと開発チームの緊密な連携が欠かせません。インフラエンジニア、SREやプラットフォームエンジニアは両者の架け橋となり、組織全体でクラウドネイティブの価値を最大限に引き出せるよう尽力しなければなりません。本書を通じて得られる知見を糧に、クラウドネイティブ時代の開発の最前線に立ち続けられるのではないでしょうか？しかし、技術的にKubernetesを完全に網羅しているわけではないので『Kubernetes完全ガイド 第2版』、『Docker/Kubernetes実践コンテナ開発入門 改訂新版』、『Kubernetes Best Practices, 2nd Edition』、『Kubernetes Patterns, 2nd Edition』などを読むと良いと思います。2 Cloud-native application challenges本章では、クラウドネイティブアプリケーションを開発・運用する上での実践的な課題が幅広く議論されました。議論の出発点となったのは、アプリケーションを実行するためのKubernetesクラスター環境をどのように選択するかという点です。ローカル環境でKindを使う方法は手軽である一方、リソースに制限があり、本番環境とは異なる挙動をする可能性があることが指摘されました。Kindは、Docker上にKubernetesクラスターを起動するツールで、開発者の手元で手軽にKubernetesを体験できる利点がある反面、プロダクション環境とは異なるサイジング・設定になりがちという欠点があります。kind.sigs.k8s.io対して、クラウドプロバイダのマネージドサービスを使えば、本番に近い環境でアプリケーションを開発できますが、コストがかかるほか、開発者がリモート環境での作業に慣れる必要があるといったトレードオフが存在します。GKE(Google Kubernetes Engine)やEKS(Amazon Elastic Kubernetes Service)などのマネージドサービスは、運用の手間を大幅に削減できる一方、クラウドベンダーの仕様に縛られるというデメリットもあります。私も実際にKindを用いたローカル環境とGKEを用いたクラウド環境の両方を経験しましたが、著者の指摘通り、それぞれに一長一短があることを実感しています。例えば、Kindは気軽に使える反面、ノード数が限られるためスケーリングのテストには向きません。一方、GKEは本番環境に近い挙動が期待できますが、クラスターの起動に時間がかかります。開発のフェーズやチームの状況に合わせて適切な環境を選択することが重要だと改めて認識しました。Figure 2.1 Kubernetes cluster Local vs. Remote setups.より引用環境の選択に関する議論に続いて、Helmを使ってカンファレンスアプリケーション(PoC)をKubernetesクラスターにデプロイする方法が具体的に紹介されました。Helmは、Kubernetes上のアプリケーションを管理するためのパッケージマネージャーです。Helmでは、アプリケーションの各コンポーネントを定義した複数のマニフェストファイルを「Chart」という単位でまとめて管理します。Helmを使うと、たった1つのコマンドで、アプリケーションの実行に必要な様々なKubernetesリソース（デプロイメント、サービス、ConfigMapなど）を一括デプロイできるのが大きな魅力です。Helmのようなツールを活用することで、複雑なマニフェストファイルを手書きで管理する手間を大幅に削減できます。また、変数化されたテンプレートを使うことで、環境ごとの設定の差異を吸収するのも容易になります。また、デプロイ後は、kubectlを駆使して、デプロイメント、サービス、Ingressなどのリソースを詳細に調べることで、アプリケーションの動作を深く理解することができます。例えば、kubectl describe deploymentでデプロイメントの詳細情報を確認したり、kubectl logsでPodのログを追跡したりできます。私も日頃からkubectlを多用していますが、改めてその重要性を認識しました。トラブルシューティングにおいては、kubectl describeやkubectl logsが特に有用です。Podが期待通りの状態になっていない場合、kubectl describeでPodの詳細情報を確認することで、原因を特定するための手がかりが得られることが多いです。ログに関しても、kubectl logs -fでストリーミング表示すれば、リアルタイムでアプリケーションの挙動をモニタリングできます。アプリケーションのデプロイと動作の確認を通じて、著者はクラウドネイティブアプリケーション特有の課題についても議論を展開していたので必読だと思います。最も重要な課題の1つが、一時的な障害が発生してもシステム全体を停止させないことです。マイクロサービスアーキテクチャでは、あるサービスで障害が発生しても、他のサービスには影響を与えないようにすることが求められます。そのためには、個々のマイクロサービスを冗長化し、一部のインスタンスが停止しても他のインスタンスが処理を引き継げるような設計が必要不可欠です。Kubernetesでは、この要件を満たすために、マイクロサービスを複数のレプリカ(Pod)で運用することが一般的です。例えば、本章の例では、フロントエンドサービスのレプリカを2つ起動することで、一方が停止しても他方がリクエストを処理し続けられるようにしていました。Deployment(デプロイメント)リソースの「replicas」フィールドで、起動するレプリカの数を指定できます。Figure 2.17 By having two replicas of the Frontend container running, we allow the application to tolerate failures and also to increase the number of concurrent requests that the application can handle. より引用実際、私も過去に、あるマイクロサービスがデプロイに失敗し、全体のシステムが停止してしまった苦い経験があります。その教訓から、現在ではユーザー向けのサービスを複数のレプリカで運用するようにしています。障害の影響を最小限に抑えるには、可用性を維持しつつ、もちろん無限にお金を使えれば解決に近づく問題ではあるのでリソース消費量のバランスを取ることが肝要です。また、レプリカ数を動的に変更できるようHPA(Horizontal Pod Autoscaler)を設定し、負荷に応じて自動的にスケールするような工夫もしています。HPAを使えば、CPUやメモリの使用率に基づいて、Pod数を自動的に増減できます。これにより、トラフィックが増大した際にもサービスのパフォーマンスを維持しつつ、利用が低調な時間帯にはリソースを節約することが可能になります。サービス間の疎結合性を保つことも、システムの可用性を高めるための重要な要素です。あるサービスで障害が発生した際も、ユーザーが他のサービスの機能を継続して利用できるようにすることが理想的です。そのためには、各サービスが依存するサービスの障害を適切に処理し、エラーをユーザーに伝搬させないようにするなど、レジリエンスを持たせる必要があります。Figure 2.21 No pods for the Agenda service. If a service is failing, the user should be able to keep using the application with limited functionality. より引用著者が紹介していたように、サーキットブレーカーパターンを実装したり、適切にタイムアウトを設定したりすることが有効です。サーキットブレーカーとは、障害が発生したサービスへのリクエストを一時的にブロックし、迅速にエラーを返すことでカスケード障害を防ぐ仕組みです。また、各リクエストにタイムアウトを設定しておくことで、ダウンストリームのサービスの応答が遅い場合でもアプリケーション全体が停止するのを防げます。加えて、私からは、Istioのようなサービスメッシュを導入し、サービス間の通信を細かく制御する方法も提案したいです。サービスメッシュは、マイクロサービス間の通信を透過的にインターセプトし、ルーティングやトラフィック管理、セキュリティ、可観測性などの機能を提供するインフラストラクチャ層です。istio.io例えば、Istioを使えば、特定のマイクロサービスへのリクエストに対して、自動的にリトライを行ったり、エラー率が閾値を超えた際にサーキットブレーカーを発動させたりすることができます。さらに、バージョンの異なるサービスに対して、トラフィックを段階的に切り替えるカナリアデプロイメントも容易に実現できます。これらの機能により、マイクロサービスのレジリエンスとリリース管理が大きく改善されるでしょう。istio.ioステートフルなサービスをKubernetes上で運用する際の留意点についても言及がありました。ステートフルというのは、リクエスト間で状態を保持する必要のあるサービスを指します。代表例は、データベースやメッセージキューなどです。ステートフルサービスをコンテナとして運用する場合の課題は、Podが再起動した際にデータが失われないようにすることです。そのためには、データを永続化するためのストレージが不可欠です。Kubernetesには、各Podにボリュームを割り当てる仕組みがあり、ファイルシステムやブロックストレージ、オブジェクトストレージなど、多様なストレージをPodにマウントできます。kubernetes.ioまた、ステートフルサービスでは、Pod間でデータを同期する必要があるため、スケーリングが難しくなります。この問題に対処するため、Kubernetesには、StatefulSetというリソースが用意されています。StatefulSetを使うと、各Podに固有のネットワークアイデンティティを付与し、起動順序や停止順序を制御できます。Figure 2.25 Both data-sensitive services use persistent stores. Delegating state storage to external components, make your service stateless and easier to scale. より引用著者が言及していたように、データベースなどのステートフルなコンポーネントを切り出し、サービス自体はステートレスに保つことが望ましいアプローチだと言えます。例えば、ユーザーのセッション情報をRedisなどのキャッシュサーバーで管理することで、アプリケーションサーバー自体はステートレスになり、シームレスにスケールさせることができるようになります。私のチームでも同様の手法を取り入れており、大きな効果を上げています。分散システムにおいては、データの整合性の問題も避けて通れません。マイクロサービスアーキテクチャでは、データがサービス間で分散されているため、あるサービスから見たデータの状態が、他のサービスから見た状態と異なっている可能性があります。「結果整合性」と呼ばれるこの状態は、ビジネス要件に応じて許容されるケースもあれば、強い整合性が求められるケースもあります。いずれにせよ、データの不整合を検知し、解消するためのメカニズムが必要です。著者が提案していたのは、CronJobを使って定期的にデータの整合性をチェックする方法です。CronJobは、cron構文で記述されたスケジュールに従ってジョブ(Pod)を実行する仕組みです。例えば、毎日深夜に、各サービスのデータを突き合わせ、不整合があればアラートを上げるような運用が考えられます。Figure 2.27 Consistency checks can run as CronJobs. We can execute checks against the application services on fixed intervals to make sure that the state is consistent. For example: (1) every day at midnight we query the Agenda Service (2) to verify that the published sessions are approved in the (3) Call For Proposals Service and a corresponding notification has been sent by the (4) Notifications Service. より引用より洗練された方法としては、CDCを使って変更データをリアルタイムでキャプチャし、関連サービスに伝播させるような方法も考えられます。CDCとは、Change Data Captureの略で、データベースの変更を即座に検出し、他のシステムに通知する技術のことです。CDCを使えば、データの更新を全てのサービスに「できるだけリアルタイム」で反映させることができます。ただし、サービス間の疎結合性という観点からは、同期的な通信は避けたほうが良いかもしれません。非同期メッセージングを使ってイベントドリブンに通信するアプローチのほうが、マイクロサービスの理想に適っているでしょう。アプリケーションの適切な監視も、本章で大きく取り上げられたトピックでした。クラウドネイティブのアプリケーションでは、インフラからアプリケーションまで、あらゆる階層で可観測性(オブザーバビリティ)を確保することが求められます。著者が注目していたのは、OpenTelemetryです。OpenTelemetryは、CNCF(Cloud Native Computing Foundation)が主導するオープンソースプロジェクトで、メトリクス、ログ、トレースを統合的に扱うためのフレームワークを提供しています。OpenTelemetryに準拠したライブラリやエージェントを使えば、アプリケーションのコードに変更を加えることなく、各サービスから統一的なフォーマットで可観測性データを収集できます。opentelemetry.io収集したメトリクスは、Prometheusなどの時系列データベースに保存し、Grafanaなどの可視化ツールで分析・モニタリングするのが一般的です。Figure 2.28 Aggregating observability from all our services in a single place reduces the cognitive load on the teams responsible for keeping the application up and running. より引用著者の主張に大いに同意します。特に、大規模なシステムになるほど、各サービスが出力するログやメトリクスを個別に追跡するのは非常に骨の折れる作業になります。OpenTelemetryのようなフレームワークを活用し、可観測性データを一元的に管理することが必要不可欠だと考えられます。learning.oreilly.com加えて、PrometheusのアラートマネージャーでSLO(Service Level Objective)を定義し、それに基づいてアラートを発報する仕組みを整えることも重要だと感じられます。SLOとは、サービスが満たすべき具体的な指標のことで、可用性やレイテンシーに関する目標値を定量的に表したものです。SLOに対する違反が発生した際に適切にアラートが上がるようにしておくことで、障害の検知と対応を迅速に行えるようになります。本章で取り上げられた課題は、いずれもクラウドネイティブアプリケーションの開発において避けては通れないものばかりです。個々の課題にベストプラクティスで対処することに加えて、著者は課題の根本的な解決のためには\"プラットフォームエンジニアリング\"の実践が不可欠だと述べています。つまり、開発者がアプリケーションのコア機能の開発に専念できるよう、ビルド、デプロイ、運用などに関わる様々なプラットフォーム機能を自動化し、効率化することが求められるのです。Figure 2.33 Developers can focus on building features, but the platform team needs to automate the entire process after changes are made. より引用プラットフォームチームによる自動化の推進は、開発チームの生産性を大きく向上させることが期待できます。一方で、プラットフォームチームと開発チームのコミュニケーションは欠かせません。開発者のフィードバックを受けて、継続的にプラットフォームを改善していくことが肝要だと言えるでしょう。クラウドネイティブアプリケーションの課題を可視化し、プラットフォームエンジニアリングの必要性を明らかにした本章の議論は示唆に富むものでした。著者の知見を参考にしながら、開発者体験の向上と、より信頼性の高いシステムの構築を目指していくことが重要だと感じました。また、プラットフォーム自動化の取り組みを通じて、チーム全体の生産性を高めていくことも大きな目標になるはずです。次章以降では、より具体的なプラクティスが順次展開されるとのことです。クラウドネイティブの世界の最前線で活躍するエンジニアの知恵を学べる良い機会だと思います。本章で得られた知識を土台として、より実践的なスキルを身につけていくことが望まれます。カンファレンスアプリケーション(PoC)を題材に、プラットフォームの構築からアプリケーションの継続的デリバリーまでを一気通貫で学べるのは、他書にはない本書の大きな魅力だと感じました。本章では実際に手を動かしながら学べる内容が豊富でした。Helmを使ったデプロイ、kubectlを用いたトラブルシューティング、Deploymentの設定など、クラウドネイティブアプリケーションに携わる上で必須のスキルを体験的に学ぶことができたのは非常に有益でした。もちろん、著者も強調していたように、これらはあくまで基礎の一部に過ぎません。実際のプロダクション環境では、もっと複雑で予期せぬ事態が起こりうるでしょう。そうした事態にも柔軟に対応できるよう、本書で得た知見を活かしつつ、継続的にスキルを磨いていくことが肝要だと感じました。著者の豊富な知識と経験に基づいた本書を通じて、DevOpsの文化を組織に根付かせ、高品質なソフトウェアを継続的に提供できるチームを作り上げていくための多くの学びが得られることを期待したいと思います。Engineering Managementの観点からも、示唆に富む章になっています。3 Service pipelines: Building cloud-native applications本章では、クラウドネイティブアプリケーションの継続的デリバリーを実現するための要となるサービスパイプラインについて、非常に深く掘り下げた議論が展開されていました。learning.oreilly.comサービスパイプラインとは、ソースコードから複数の環境にデプロイ可能なリソースを生成するまでのプロセスを定義するものです。trunk-basedな開発や、1サービス=1リポジトリという実践を行うことが、チームがソフトウェアのビルドとリリースを効率的に標準化するのに役立ちます。trunkbaseddevelopment.comしかし、これはあくまで一般論であって、実際にはチームやアプリケーションに合ったやり方を見つける必要があります。万能の解決策などなく、トレードオフを考えなければならない場面も多いでしょう。アプリケーションを構成するサービスがどのくらいの頻度で変更されるのか、それらのサービスをどのように各環境にデプロイしていくのか。こうした問いに答えることで、サービスパイプラインの始点と終点を定義しやすくなります。例えば、UIを担うフロントエンドサービスの変更は、バックエンドのAPIに比べてより頻繁に行われるかもしれません。フロントエンド開発のためのテスト入門 今からでも知っておきたい自動テスト戦略の必須知識作者:吉井 健文翔泳社Amazonそうした場合、フロントエンド側のパイプラインは、できるだけ軽量でシンプルなものにしておく必要があります。頻繁なリリースサイクルに対応するため、ビルドやデプロイのプロセスを自動化し、効率化することが重要です。また、フロントエンドの変更がバックエンドに与える影響を最小限に抑えるため、両者の間にはしっかりとしたインターフェース定義が必要となります。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon一方、ビジネスロジックの中核を担うようなバックエンドサービスのパイプラインは、より厳格で、各種テストも充実させておく必要があるでしょう。バックエンドは、システムの根幹を成すコンポーネントであり、その品質と信頼性は非常に重要です。そのため、単体テスト、統合テスト、負荷テストなど、様々な観点からのテストを実施し、バグや脆弱性を早期に発見・修正することが求められます。また、バックエンドの変更は、他のサービスに広範な影響を与える可能性があるため、慎重にバージョン管理し、必要に応じてロールバック可能な状態を維持しておくことも大切です。このように、フロントエンドとバックエンドでは、その役割や特性に応じて、パイプラインの設計や運用方針を適切に調整することが重要です。こうした違いを意識しつつ、それぞれのサービスに適したパイプラインを設計していく。これは、サービスの独立性を確保しつつ、開発・リリースプロセス全体の効率を高める上で非常に重要なことだと言えます。マイクロサービスアーキテクチャが主流となる中で、サービスの独立性を担保しつつ、リリースプロセス全体の効率化を図る上で、サービスパイプラインは欠かせない存在です。サービスパイプラインを適切に設計し、運用することが、クラウドネイティブな開発の成功の鍵を握ると言っても過言ではありません。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオライリー・ジャパンAmazon著者は、サービスパイプラインを効果的に機能させるためのベストプラクティスをいくつも提示しています。例えば、trunk-based developmentを採用し、メインブランチを常にデプロイ可能な状態に保つことです。これにより、いつでもリリースができる状態を維持しつつ、変更を小さくすることで、リスクを最小限に抑えられます。また、メインブランチへのマージを厳格に管理することも重要です。レビューを徹底し、自動化されたテストをパスしたコードのみを受け入れるルールを設ける。これにより、メインブランチの品質を常に高く保てるはずです。docs.github.com加えて、Consumer-Driven Contract (CDC) テストの重要性も強調されていました。マイクロサービス間の依存関係を、テストとして明示的に管理することで、あるサービスの変更が他のサービスに与える影響を最小限に食い止められるのです。thoughtworks.github.ioCDCテストでは、あるサービス（Consumer）が依存するサービス（Provider）のAPIについて、期待する振る舞いを契約（Contract）として定義します。そしてその契約に基づいて、自動テストを生成するのです。これにより、Providerの実装が変更されても、Contract自体が守られている限り、Consumerには影響が及ばないことが保証されます。この手法は、マイクロサービス間の結合度を適切な形に保つ上で、非常に有効だと言えるでしょう。CDCテストを導入することで、各チームは自分たちのペースでサービスを進化させつつ、他のチームに与える影響を最小限に抑えられます。これは、マイクロサービスアーキテクチャのメリットを最大限に引き出すための重要な実践だと言えます。こうしたプラクティスは、単に技術的なものではありません。チーム間のコミュニケーションを円滑にし、リリースに関わる様々なステークホルダーの協調を促すことにも寄与します。サービスパイプラインを設計する際には、常にチームとプロセスに与える影響を考慮する必要があるでしょう。さらに、個々のサービスのライフサイクルに合わせて、パイプラインを柔軟に調整することの重要性も説かれていました。画一的な基準を全てのサービスに適用するのではなく、変更頻度や重要度に応じて最適化していくことが求められます。例えば、ユーザーに対するインターフェースとなるフロントエンドのサービスは、UIの変更が頻繁に行われるかもしれません。一方で、システムの根幹を支えるようなバックエンドサービスは、安定性が何より重視されるはずです。こうした特性の違いを踏まえて、フロントエンドのサービスにはより軽量で実行頻度の高いパイプラインを、バックエンドのサービスにはより厳格でステップの多いパイプラインを適用する、といった工夫が考えられます。要は、サービスの特性に合わせてパイプラインをチューニングしていくことが肝要だということですね。そのためには、各サービスがどのような特性を持ち、どのようなペースで変更が行われるのかを深く理解する必要があります。開発チームとの密なコミュニケーションを通じて、サービスの性質を見極めていくことが重要だと言えるでしょう。また、パイプラインを定義する際には、コードとしての管理が鍵になります。アプリケーションのコードと同様に、パイプラインのコードもバージョン管理し、再利用性や保守性を高めていく必要があるのです。そのためには、Dockerfileやデプロイメント用のマニフェストなど、パイプラインに関わる全てのリソースをコードとして扱うことが重要になります。つまり、Infrastructure as Codeの思想を、パイプラインにも適用するということですね。learning.oreilly.comこれは、単にパイプラインの品質を高めるだけでなく、アプリケーションの運用方法を明確に可視化することにも繋がります。コードを見れば、そのアプリケーションがどのようにビルド・デプロイされるのかが一目瞭然になるのです。特に、新しくチームに参加したメンバーのオンボーディングを助ける効果は大きいでしょう。パイプラインのコードがドキュメントの役割を果たし、アプリケーションの動作原理の理解を助けてくれるはずです。加えて、コード化されたパイプラインは、単なる自動化の手段ではありません。それは、チームのエンジニアリング文化そのものを表現するものだとも言えます。例えば、パイプラインにどのような品質ゲートを設けるのか、どの段階でレビューを行うのか、といった点は、チームの価値観や理念を反映したものになるはずです。つまり、パイプラインをコード化することは、チームのエンジニアリングプラクティスを明文化し、共有することでもあるのです。それによって、チームのスキルやノウハウの継承がスムーズになり、組織としての開発力の底上げにも繋がります。本章では、Tekton、Dagger、GitHub Actionsなど、パイプラインを実装するためのツールについても詳しく解説されていました。それぞれのツールの特性を理解し、自身のコンテキストに合ったものを選択することが重要だと感じました。learning.oreilly.comGitHubが提供するGitHub Actionsのようなマネージドサービスを利用するのも一つの選択肢です。インフラの管理は全てGitHubに任せられるため、初期コストを大幅に下げられます。ただし、実行時間に応じた従量課金制のため、大規模なワークロードを流し続けるとコストが高くつく可能性もあります。プラットフォームを構築する立場からは、GitHub Actionsのような便利なツールだけに頼るのではなく、自社に最適化されたタスクやパイプラインを柔軟に作れるツールを選ぶ必要があるでしょう。また、開発者がローカルでパイプラインを実行できるようにしておくことも、DXを高める上で重要なポイントになります。せっかくパイプラインを自動化しても、毎回クラウドにデプロイしないと動作確認ができないようでは、開発者の生産性は大きく損なわれてしまいます。開発者のフィードバックサイクルを如何に短くできるかは、パイプラインツールの選定において考慮すべき大切な視点だと言えるでしょう。github.com例えばTektonは、Kubernetesとの親和性が高く、宣言的なパイプラインの定義が可能です。Kubernetesのカスタムリソースとしてパイプラインを表現できるため、他のKubernetesリソースとの連携が容易だというメリットがあります。また、Tektonには豊富なコミュニティ貢献のタスクが用意されているのも魅力の一つです。Tekton Hubと呼ばれるカタログサイトから、再利用可能なタスクを検索し、自分のパイプラインに組み込むことができます。これらのタスクは、Kubernetesのエキスパートたちによって作られ、ベストプラクティスが詰め込まれています。それらを活用することで、信頼性の高いパイプラインを素早く構築できるでしょう。tekton.dev一方、Daggerは、プログラミング言語でパイプラインを記述できるため、より動的で複雑な処理を表現しやすいという特徴があります。Go、Node.js、Python、Javaなど、様々な言語のSDKが提供されているのも、開発者にとって嬉しいポイントだと言えます。言語の持つ柔軟性を活かして、条件分岐や繰り返し処理を含む高度なパイプラインを実装できます。また、言語のエコシステムを活用して、外部ライブラリとの連携も容易です。例えば、テストの実行結果をSlackに通知したり、カスタムスクリプトを組み込んだりといったことが、シームレスに行えるでしょう。dagger.ioまた、Daggerの大きな特長は、ローカル環境でもそのままパイプラインを実行できる点にあります。手元の環境で簡単にパイプラインの動作検証ができるため、開発者の生産性が大きく向上するでしょう。クラウド上の環境を完全に再現するのは難しくても、パイプラインのコアとなるロジックは、ローカルで十分にテストできるはずです。これにより、クラウドへのデプロイ回数を減らし、無駄なコストを削減できます。また、ローカルでパイプラインを実行できれば、開発中のアプリケーションに合わせて、パイプラインを柔軟にカスタマイズしていくことも容易になります。チームのスキルセットや、アプリケーションのアーキテクチャによって、適切なツール選定は変わってくるでしょう。一つの正解があるわけではありません。重要なのは、チームにとって最も生産性の高い方法を追求し続けることだと感じました。さらに、ローカル環境でのパイプラインの実行も、開発者の生産性を大きく左右する要素として挙げられていました。クラウド上の環境を完全に再現するのは難しくとも、手元で気軽にパイプラインを実行できれば、圧倒的にフィードバックループが早くなるはずです。加えて、コードとして表現することで、より柔軟なパイプラインの実現も可能になります。単なるYAMLの設定ファイルでは表現しきれないような、動的なロジックを組み込むこともできるはずです。例えば、あるサービスのテスト結果を受けて、別のサービスのデプロイを条件付きでスキップする、といったことも可能になるでしょう。この柔軟性は、マイクロサービスの独立性を担保する上でも重要な意味を持ちます。あるサービスの障害が、他のサービスのデプロイを止めてしまうようでは、真の意味でのマイクロサービスとは言えません。パイプラインを通じて、各サービスのライフサイクルを適切に制御することが、マイクロサービスアーキテクチャを成功に導く鍵だと言えるでしょう。Figure 3.14 Local vs. remote service pipelines より引用このように、サービスパイプラインを適切に定義し、運用していくことは、クラウドネイティブなアプリケーション開発において欠かせない実践だと言えます。そのためのツールの選定は、単に機能や性能だけでなく、開発者のエクスペリエンスや、チームのカルチャーとの親和性など、多面的な視点から行う必要があります。Figure 3.5 Running pipelines requires a lot of infrastructure to be in place. より引用パイプラインを実行するためには、図にあるように、様々なインフラの整備が必要不可欠です。各種リポジトリ、コンテナレジストリ、Kubernetesクラスターなど、多岐にわたるコンポーネントを連携させる必要があります。これらのインフラを個別のプロジェクトごとに構築するのは非常に非効率です。コストや管理の手間を考えると、組織横断で共有できるプラットフォームとして提供するのが望ましいでしょう。そこで重要になってくるのが、プラットフォームチームの存在です。プラットフォームチームは、開発チームが利用しやすいパイプラインのテンプレートを用意し、ベストプラクティスをコード化して提供します。具体的には、言語ごとのビルドやテストのツールセット、デプロイに必要なマニフェストの生成ロジックなどを、プラットフォームとして標準化するのです。開発チームはそれらを利用しつつ、各アプリケーションに特化した処理を付け加えていけば良いでしょう。こうすることで、開発チームは本質的なロジックの実装に集中でき、しかも一定の品質を担保されたパイプラインを利用できるようになります。まさに、プラットフォームが提供すべき価値だと言えます。一方で、全てのアプリケーションに対して、一律のパイプラインを適用するのは現実的ではありません。例えば、レガシーなシステムをマイクロサービス化する過程では、新旧のサービスが混在することになります。レガシーなサービスに対しては、従来のビルドツールやデプロイ手法を踏襲せざるを得ないかもしれません。そうした例外に対しては、プラットフォームチームが柔軟に対応し、段階的な移行をサポートしていく必要があります。究極的には、パイプラインのコードを通じて、プラットフォームと開発チームのコラボレーションを促進することが肝要です。開発チームはアプリケーションに関する知見を、プラットフォームチームはインフラに関する知見を持ち寄り、パイプラインの継続的な改善を進めていく。それこそが、クラウドネイティブ時代のDevOpsの理想形と言えるでしょう。本章を通じて、改めてサービスパイプラインの重要性と、その構築の難しさを実感しました。単なるツールの選定や設定の問題ではなく、開発プロセス全体に関わる設計が求められるのです。組織の文化や、開発チームの成熟度なども考慮しなければなりません。画一的な答えはなく、試行錯誤を重ねながら、自社に最適な形を模索していく必要があります。そのためには、プラットフォームチームと開発チームの密なコラボレーションが不可欠です。サービスパイプラインは、エンジニアリングの課題であると同時に、組織の課題でもあるのだと、強く認識させられる内容でした。また、パイプラインのコード化の重要性は、開発者としての自分の仕事の進め方にも示唆を与えてくれました。テストやデプロイの方法をコードの一部として捉え、アプリケーションと一体になったものとして扱うこと。それによって、より俯瞰的に開発プロセスを捉えられるようになるはずです。さらに、パイプラインのコード化は、アプリケーションの品質を長期的に担保していく上でも重要な意味を持ちます。メンバーが入れ替わっても、その時点での最良のプラクティスが脈々と受け継がれていく。まさに、継続的インテグレーション・継続的デリバリーの価値を体現するものだと言えるでしょう。ちなみに、著者は継続的デリバリーに関する優れた書籍として、「Continuous Delivery」と「Grokking Continuous Delivery」の2冊を挙げていました。私も特に「Grokking Continuous Delivery」は非常に分かりやすく、お勧めの一冊です。継続的デリバリーの考え方や、パイプラインの設計方法について、体系的に学ぶことができます。syu-m-5151.hatenablog.comクラウドネイティブの世界で開発者として生きていく上で、サービスパイプラインをどう構築・活用していくかは避けて通れない問題です。ただツールを選ぶだけでなく、自分たちの開発文化そのものを設計する。そんな広い視野を持つことの大切さを、本章は教えてくれました。もちろん、これは簡単なことではありません。日々の開発タスクに追われる中で、パイプラインまで手が回らないというのが正直なところでしょう。だからこそ、プラットフォームチームの役割が重要になってくるのです。現場の開発者の負担を減らしつつ、ベストプラクティスの採用を促していく。そのための仕組みと文化を育てていくことが、プラットフォームチームに求められる使命だと言えます。理想的なサービスパイプラインの姿は、組織によって異なるでしょう。どこを目指すのか、そのために何をすべきかは、組織の状況に応じて見極めていかなければなりません。ただ、開発者として心に留めておきたいのは、サービスパイプラインの構築は、決して他人事ではないということです。自分たちで作ったアプリケーションを、自分たちの手でより良い形でお客様に届けるために、パイプラインを日々改善していく。そんな当事者意識を持つことが、クラウドネイティブ時代のソフトウェアエンジニアに求められているのだと感じます。その意味で、本章はサービスパイプラインについての技術的な知見だけでなく、開発者としてのマインドセットを見つめ直すためのヒントも与えてくれました。著者の知見に導かれながら、自分なりのベストプラクティスを追求していきたいと思います。継続的デリバリーの実現は、一朝一夕にはいきません。しかし、その過程で得られる学びは、エンジニアとしての成長に直結するはずです。プラットフォームチームと開発チームが一丸となって、理想のパイプラインを追求していく。そのために、一人一人が当事者意識を持って臨むことが何より大切だと、本章を読んで強く感じました。本章の内容は、そのための第一歩を踏み出すための勇気と知見を与えてくれるはずです。著者の経験に基づく生きたアドバイスの数々は、きっと読者の心に響くことでしょう。理想的なパイプラインを構築するのは簡単ではありませんが、その過程で得られる学びは計り知れません。失敗を恐れず、仮説検証を繰り返しながら、自分たちなりのベストプラクティスを追求していく。そうした探求心こそが、エンジニアを駆り立てる原動力になるはずです。本書の主題である\"プラットフォームエンジニアリング\"も、そうした探求の先に見えてくるものだと感じています。開発者とインフラの垣根を越えて、アプリケーションとプラットフォームが一体となった開発スタイルを確立する。それはまさに、クラウドネイティブ時代のソフトウェア開発の理想形と言えるでしょう。本章はそのためのロードマップを提示してくれました。読者の皆さんには、ぜひ自分たちなりのサービスパイプライン構築に挑戦してみてください。きっと、開発者としての新たな可能性に気づくことができるはずです。4 Environment pipelines: Deploying cloud-native applications本章では、サービスパイプラインによって生成されたリソースを実際の環境にデプロイするための「パイプライン」について深く掘り下げられていました。私たちが作り上げたアプリケーションが真の価値を生むのは、それが実際のユーザーに届けられて初めて可能になります。そのためには、開発環境から本番環境まで、様々なステージを経由しながら、アプリケーションを安全かつ確実にデプロイしていく必要があります。この一連のプロセスを自動化し、信頼性と再現性を担保するのが、パイプラインの役割だと言えるでしょう。例のGitOpsのページが移動されたのでGoogle Cloudさんのページを公開しておきます。cloud.google.com著者は特に、GitOpsの考え方を取り入れることの重要性を強調していました。GitOpsとは、環境の設定をコードとして管理し、Gitリポジトリを信頼できる唯一の情報源として扱う手法のことを指します。つまり、インフラストラクチャのあるべき状態を宣言的に記述し、それをGitで管理するのです。GitOpsに従えば、環境の状態は常にGitリポジトリの内容と同期されていなければなりません。環境に変更を加えるには、Gitリポジトリに対してプルリクエストを発行し、レビューを経てマージするというプロセスを踏むことになります。Figure 4.10 Argo CD will sync environments, configurations from Git to live clusters より引用これにより、変更の履歴が追跡可能になるだけでなく、問題が発生した際にはすぐに前のバージョンに戻せるようになります。また、設定のドリフトを防ぎ、環境間の一貫性を保つことも容易になるのです。インフラストラクチャの状態をコードで表現することで、それを他の人と共有したり、レビューしたりすることが可能になります。つまり、インフラストラクチャの変更も、アプリケーションコードの変更と同様に、プルリクエストベースのワークフローに乗せられるようになるのです。GitOpsを実装するためのツールとして、本章ではArgo CDが紹介されていました。Argo CDは、Kubernetes向けの継続的デリバリーツールであり、GitリポジトリとKubernetesクラスターを監視し、両者の状態を同期し続けてくれます。具体的には、Gitリポジトリに格納されたマニフェストファイルを読み取り、それをKubernetesクラスターに適用するのです。もし、クラスターの状態がマニフェストファイルの内容と異なっていれば、Argo CDが自動的にそれを修正してくれます。argo-cd.readthedocs.ioまた、Argo CDは直感的なWebインターフェースを提供しており、そこからデプロイメントの状況をビジュアルに把握できます。どのアプリケーションがどのバージョンで動いているのか、そのヘルスステータスはどうなっているのかなどを一目で確認できるのは、オペレーションの効率化に大きく寄与するでしょう。Figure 4.18 Components to set up the staging environment with Argo CD より引用Argo CDとHelmを組み合わせることで、より強力なGitOpsのワークフローを実現できます。Helmは、Kubernetesのパッケージマネージャーであり、アプリケーションの設定値をパラメータ化し、テンプレート化することができます。つまり、Helmを使えば、同じアプリケーションを異なる環境に、異なるパラメータセットで展開することが容易になるのです。helm.shArgo CDは、このHelmチャートも管理対象とすることができます。Gitリポジトリに格納されたHelmチャートを読み取り、それをKubernetesクラスターにデプロイするのです。この組み合わせにより、アプリケーションの設定とインフラストラクチャの設定を、一元的にコードで管理することが可能になります。本書のステップバイステップのチュートリアルでは、実際にArgo CDとHelmを使って、サンプルアプリケーションをKubernetesクラスターにデプロイする手順が丁寧に解説されていました。これを通じて、GitOpsの実践的なスキルを身につけることができたのは、大変貴重な経験となりました。パイプラインは、ソフトウェアリソースを本番環境にデプロイする責務を負っています。パイプラインにより、チームが直接クラスターを操作する必要がなくなり、エラーや設定ミスのリスクを減らせます。また、環境の更新後には、きちんと動作確認を行う必要があります。Argo CD のようなツールを使えば、各環境の内容をGitリポジトリで定義し、信頼できる唯一の情報源として扱うことができます。Argo CD は、クラスターの状態を追跡し、適用された設定にドリフトが発生していないことを保証します。開発チームは、環境で実行されているサービスのバージョンを、環境設定のリポジトリにプルリクエストを発行することでアップグレード・ダウングレードできます。変更はレビューを経てマージされ、承認されれば即座に環境に反映されます。問題が発生した場合は、Gitのコミットを元に戻すことで、ロールバックが可能です。パイプラインは、私たちの開発プロセスに多くのメリットをもたらしてくれます。まず、環境への直接的な干渉を排除し、設定ミスや不整合によるトラブルを防ぐことができます。手作業によるミスを減らし、オペレーションを自動化・標準化できるのです。また、環境の設定を統一的に管理することで、本番環境の再現や、新しい環境の立ち上げを容易にします。テスト環境や、開発者一人ひとりの環境を、本番と同じ構成で簡単に作れるようになるでしょう。このことは、「本番で動くから大丈夫」という過信を排除し、より早い段階で問題を発見・解決することにつながります。加えて、変更管理のプロセスを明確にすることで、開発チーム間のコミュニケーションとコラボレーションを促進します。インフラストラクチャの変更も、アプリケーションの変更と同列に扱われ、レビューの対象になる。これにより、開発者とオペレータの境界が曖昧になり、両者の理解が深まっていくはずです。パイプラインは、アプリケーションの信頼性と安定性を支える重要な基盤であると同時に、開発者のワークフローを改善する強力な手段でもあるのです。適切に実装・運用されたパイプラインは、ビジネススピードを加速し、イノベーションを促進してくれるでしょう。一方で、パイプラインの導入には、一定のコストと学習曲線が伴うことも事実です。GitOpsの考え方に基づいて環境を設計し、適切なツールを選定し、チームの文化を変革していくには、時間と努力が必要となるでしょう。単に新しいツールを導入すれば良いというものではなく、それを活用するためのスキルセットやマインドセットを、チーム全体で醸成していかなければなりません。特に、Kubernetesのようなモダンなプラットフォームを前提としたパイプラインでは、従来のオペレーションとは異なるスキルが要求されます。コンテナやオーケストレーションの知識はもちろん、インフラストラクチャをコードで管理するためのプラクティス、つまりInfrastructure as Code (IaC)についても習熟が必要です。また、GitOpsは強力なプラクティスである一方、万能ではありません。例えば、データベースのスキーマ変更のように、ステートフルで複雑な処理をどう扱うかは、頭を悩ませる問題です。すべてをGitOpsでカバーしようとするのではなく、他のアプローチと適切に組み合わせていくことが肝要でしょう。しかし、長期的な視点に立てば、その投資は必ず報われるはずです。パイプラインを通じて得られる俊敏性と安定性は、ビジネスの成功に直結する重要な要因になると私は確信しています。変化の激しい現代のビジネス環境において、いかに素早く、安全に価値を届けられるかが、競争力の源泉になるのですから。パイプラインは、クラウドネイティブなアプリケーション開発において欠かせない要素です。単純な自動化の仕組み以上に、それは私たちの開発文化そのものを変革する起爆剤にもなり得ます。サービスパイプラインとパイプラインが織りなす継続的デリバリーの世界。そこには、より柔軟で、より俊敏で、より確実なソフトウェア開発の未来が広がっているのです。本章を通じて、パイプラインの真価と、それを実装するための具体的な方法論を学ぶことができました。GitOpsという新しいアプローチは、私にとって目から鱗が落ちる思いでした。単にツールを導入するだけでなく、宣言的にインフラストラクチャを記述し、それを中心にワークフローを回していく。そうしたマインドセットの変革の必要性を強く感じさせられました。Kubernetesという土壌の上に、Argo CDやHelmを駆使して、信頼性と速度を兼ね備えたデリバリーパイプラインを築く。本章は、そのための道標となってくれるはずです。私たち一人ひとりが、チームやプロジェクトの文脈に合わせてこの知見を咀嚼し、パイプラインをどう実装していくか。そこには正解はなく、試行錯誤の連続になるかもしれません。レビューを経ずにインフラストラクチャの変更が行われたり、手動での作業が残っていたりと、理想とする状態には程遠いのが実情でしょう。しかし、だからこそDevOpsの実践が求められているのだと、私は考えます。パイプラインは、開発者とオペレータの協力を促し、継続的な改善を導く強力な仕組みです。それを通じてチームのフィードバックループを回していくことが、私や私たちに課せられた使命だと言えます。ステップバイステップのチュートリアルを実践して、Argo CD を用いてGitOpsの考え方に基づいたデプロイを体験できました。はじめは小さなスコープから始めて、徐々にカバレッジを広げていくのが良いかもしれません。5 Multi-cloud (app) infrastructure本章では、クラウドネイティブアプリケーションのインフラストラクチャをマルチクラウド環境で管理する上での課題と、それを解決するためのアプローチについて詳細に解説されていました。マイクロサービスアーキテクチャの普及により、アプリケーションを構成する各サービスは、データベースやメッセージブローカーなどの依存コンポーネントを必要とするようになりました。これらのコンポーネントをクラウドプロバイダー固有の方法で構築・運用すると、ベンダーロックインの問題が生じ、アプリケーションのポータビリティが損なわれます。つまり、あるクラウドプロバイダーで構築したアプリケーションを、別のクラウドプロバイダーに移行することが難しくなるのです。learning.oreilly.comこの問題を解決するために、筆者はKubernetes APIとCrossplaneの活用を提案しています。Crossplaneは、Kubernetesのエコシステムの一部として開発されたオープンソースのプロジェクトで、主要なクラウドプロバイダーのリソースをKubernetesのカスタムリソースとして管理することができます。Crossplaneを使うことで、クラウドプロバイダーに依存せずにインフラをプロビジョニングできるため、マルチクラウド戦略を推進する上で非常に重要な役割を果たします。www.crossplane.ioCrossplaneの中核となる機能が、Composite Resource Definitions（XRDs）です。XRDsは、Kubernetesのカスタムリソースを定義するための仕組みで、ドメイン固有の概念をKubernetesのオブジェクトとして表現できます。例えば、\"Database\"や\"MessageQueue\"といったアプリケーションが必要とするコンポーネントを、XRDsを通じて抽象化することができます。プラットフォームチームは、XRDsを適切に設計することで、アプリケーションチームが必要とするリソースを宣言的に要求できるインターフェースを提供します。XRDsを定義する際には、アプリケーションチームのニーズを的確に捉えることが重要です。単に技術的な観点からリソースを抽象化するのではなく、アプリケーションチームがどのような概念で infrastructure as code を考えているのかを理解する必要があります。例えば、あるアプリケーションチームは \"Database\" というリソースを、「リレーショナルデータベースであること」「高可用性を備えていること」「自動バックアップが設定されていること」といった特性を持つものとして捉えているかもしれません。一方、別のチームは \"Database\" を、「ドキュメント指向のデータベースであること」「スキーマレスであること」「地理的に分散されたレプリケーションを備えていること」といった特性を持つものとして考えているかもしれません。プラットフォームチームは、これらの異なる要求を抽象化し、統一的なインターフェースを提供する必要があります。つまり、XRDsの設計には、アプリケーションチームとのコミュニケーションと、ドメインの深い理解が不可欠なのです。また、XRDsを定義する際には、将来の拡張性も考慮しなければなりません。アプリケーションチームのニーズは常に変化するため、XRDsもそれに合わせて進化させる必要があります。したがって、XRDsの設計はアプリケーションチームとの継続的な対話を通じて、段階的に洗練させていくべきものだと言えます。XRDsに対応するCompositionの設計も、同様に重要です。Compositionは、XRDsによって定義されたリソースを、実際のクラウドプロバイダー上のリソースにマッピングするための仕組みです。つまり、Compositionは、XRDsとクラウドプロバイダーの間の橋渡しの役割を果たします。Compositionを定義する際には、クラウドプロバイダーのサービスやAPIに関する深い知識が必要になります。例えば、あるCompositionでは、XRDsで定義された \"Database\" リソースを、Amazon RDSのPostgreSQLインスタンスにマッピングするかもしれません。その際、RDSインスタンスの作成に必要なすべてのパラメータ（インスタンスクラス、ストレージサイズ、ネットワーク設定など）を、XRDsで指定されたパラメータから適切に設定しなければなりません。また、RDSインスタンスに付随するその他のリソース（セキュリティグループ、モニタリング設定、バックアップ設定など）も、同時に作成・設定する必要があります。これらのリソースの作成や設定には、AWSのAPIやSDKを使用することになります。したがって、Compositionの設計には、クラウドプロバイダーのAPIやSDKに関する知識と、それらを効果的に活用するためのプログラミングスキルが求められます。また、クラウドプロバイダーのベストプラクティスやレコメンデーションにも精通している必要があります。例えば、AWSには、Well-Architectedフレームワークというベストプラクティスの集大成がありますが、Compositionの設計はこれに沿ったものであるべきです。さらに、Compositionの設計には、運用面での考慮も欠かせません。作成したリソースを適切にモニタリングし、問題が発生した際には速やかに検知・通知できる仕組みを用意しなければなりません。また、リソースの変更管理やバージョン管理、ロールバック機能なども必要になります。これらの運用機能は、クラウドプロバイダーのサービスを活用することで実現できる場合もありますが、Compositionレベルでの抽象化が必要なケースもあるでしょう。加えて、Compositionではインフラストラクチャのコストの最適化も考慮する必要があります。クラウドプロバイダーのサービスは、そのほとんどが従量課金制で提供されています。したがって、Compositionで作成するリソースのスペックや数量を適切に設定し、不要なコストが発生しないように注意しなければなりません。そのためには、アプリケーションの要件を正確に把握し、それに見合ったリソースを過不足なくプロビジョニングすることが求められます。以上のように、XRDsとCompositionの設計には、アプリケーションドメインに関する知識、クラウドプロバイダーのサービスやAPIに関する知識、プログラミングスキル、運用スキル、コスト最適化のスキルなど、多岐にわたる専門性が必要とされます。つまり、プラットフォームチームには、従来のインフラストラクチャの管理とは異なるスキルセットが求められるのです。特に、クラウドプロバイダーのサービスやAPIは常に進化し続けているため、プラットフォームチームはそれらの変化に追随し続ける必要があります。新しいサービスや機能が登場した際には、それらをどのようにCompositionに取り込むか、XRDsのインターフェースにどう反映するかを検討しなければなりません。つまり、Crossplaneを活用したプラットフォームの構築は、継続的な学習と改善のプロセスだと言えます。また、プラットフォームチームは、アプリケーションチームとインフラストラクチャチームの間に立つ存在でもあります。両チームの要求や制約を理解し、それらを適切にXRDsやCompositionに反映していく必要があります。つまり、プラットフォームチームには、技術的なスキルだけでなく、コミュニケーション能力やコーディネーション能力も求められるのです。Crossplaneは、GitOpsとの親和性も高いことが特徴の一つです。XRDsで定義されたリソースは、Kubernetesのマニフェストファイルと同様に、Git上で管理することができます。つまり、インフラストラクチャの状態をGitリポジトリで管理し、Gitのワークフローに乗せることで、インフラストラクチャの変更を宣言的に管理できるのです。GitOpsを採用することで、インフラストラクチャの変更は、Gitリポジトリへのコミットとして表現されます。したがって、変更の経緯を追跡しやすく、変更のレビューやテストも行いやすくなります。また、リポジトリの状態とクラスターの状態を常に同期させることで、インフラストラクチャの状態のドリフトを防ぐこともできます。GitOpsとCrossplaneを組み合わせることで、アプリケーションのデプロイメントパイプラインにインフラストラクチャの変更を統合することも可能になります。アプリケーションの変更に必要なインフラストラクチャの変更を、アプリケーションのソースコードと同じリポジトリで管理し、同じパイプラインでデプロイすることで、アプリケーションとインフラストラクチャのライフサイクルを一元的に管理できるのです。ただし、GitOpsの実践には、独自の課題もあります。例えば、Gitリポジトリの構成をどのように設計するか、secrets の管理をどうするか、変更の競合をどう解決するかなど、運用面での検討が必要になります。また、GitOpsではインフラストラクチャの変更がコードとして表現されるため、コードのクオリティを維持するためのプラクティス（レビュー、テスト、リファクタリングなど）も必要になります。Crossplaneを活用したマルチクラウドでのアプリケーション基盤の構築は、大きな可能性を秘めていますが、同時に多くの課題も抱えています。技術的な複雑さだけでなく、組織やプロセスの変革も必要になります。プラットフォームチームの役割と責任、アプリケーションチームやインフラストラクチャチームとの協調の在り方など、従来とは異なる体制が求められるでしょう。また、マルチクラウド環境では、各クラウドプロバイダーの特性を理解し、それらを適切に活用することも重要です。単に複数のクラウドを使うのではなく、各クラウドの強みを生かし、弱みを補完し合うような設計が必要になります。そのためには、プラットフォームチームがクラウドプロバイダーの動向を常に把握し、最新の知見を取り入れ続けなければなりません。さらに、マルチクラウド環境では、セキュリティやコンプライアンス、コスト管理などの課題もより複雑になります。各クラウドプロバイダーのセキュリティ機能や料金体系を理解し、それらを横断的に管理・統制する必要があります。また、クラウド間でのデータの移動や同期、可用性や性能の確保など、アーキテクチャ面での検討も欠かせません。こうした課題を解決するには、プラットフォームチームの高度な技術力とともに、組織全体での意識改革と協調が不可欠です。アプリケーションチームは、インフラストラクチャを意識したアプリケーション設計を行う必要がありますし、インフラストラクチャチームは、アプリケーションの要件を理解した上でインフラストラクチャを提供する必要があります。また、セキュリティチームや財務チームなど、関連する他部門とのコラボレーションも重要になるでしょう。つまり、Crossplaneを活用したプラットフォームエンジニアリングは、単なる技術的な取り組みではなく、組織文化の変革でもあるのです。siloを打破し、チーム間のコラボレーションを促進し、継続的な学習と改善を組織に根付かせること。それがプラットフォームチームに求められる重要な役割だと言えます。本章の内容は、こうしたプラットフォームエンジニアリングの課題と可能性を、Crossplaneを中心に論じたものでした。筆者自身、日々の業務でKubernetesやCrossplaneに携わる中で、その難しさと面白さを実感しています。特に、XRDsとCompositionの設計は、奥が深く、まだまだ学ぶべきことが多いと感じています。しかし同時に、プラットフォームエンジニアリングのもたらす価値の大きさにも気づかされました。アプリケーションとインフラストラクチャの垣根を越えて、開発と運用の連携を深化させ、ビジネスの俊敏性を高めていく。それは、DXの実現に直結する取り組みだと言えます。もちろん、そこに至るまでの道のりは平坦ではありません。レガシーシステムとのインテグレーション、組織間の政治的な力学、既存の文化や習慣の壁など、立ちはだかる障壁は数多くあります。しかし、それでもなお、プラットフォームエンジニアリングへの挑戦は避けられないものだと感じています。なぜなら、それは単に技術的な必然ではなく、ビジネス環境の変化に対応するための組織的な必然でもあるからです。クラウドやDevOpsの普及により、ソフトウェアがビジネスを左右する時代になりました。そんな時代に求められるのは、変化に素早く適応し、イノベーションを継続的に生み出せる組織の仕組みです。プラットフォームエンジニアリングは、まさにそのような仕組みを実現するためのアプローチだと言えます。開発と運用の連携を高め、アプリケーションとインフラストラクチャをシームレスに扱うことで、ソフトウェア・デリバリーのスピードと質を高める。また、自動化と抽象化を進めることで、チームがよりビジネスに価値のある活動に注力できるようにする。こうしたプラットフォームエンジニアリングの価値は、もはや特定の業界や企業規模に限定されるものではありません。クラウドネイティブの考え方は、あらゆる業界・規模の企業に浸透しつつあります。つまり、プラットフォームエンジニアリングは、どの企業にとっても無視できない重要な取り組みになりつつあるのです。とはいえ、プラットフォームエンジニアリングは万能薬ではありません。過度な自動化や抽象化は、かえって複雑性を生み、イノベーションを阻害する可能性もあります。重要なのは、自社のコンテキストをしっかりと理解した上で、適切な段階的アプローチを取ることです。その意味で、本書はプラットフォームエンジニアリングを進める上での良き指針になるでしょう。Crossplaneを中心とした技術的な側面だけでなく、チームの構成や文化、プロセスといった組織的な側面についても、バランス良く論じられていました。これは、プラットフォームエンジニアリングが、技術と組織の両面にまたがる取り組みだからこそ重要な視点だと感じました。筆者自身、本章で得られた知見を日々の業務に活かしていきたいと考えています。特に、XRDsとCompositionの設計については、アプリケーションチームとのコミュニケーションを密にし、ドメインモデルを深く理解することの重要性を再認識しました。また、プラットフォームチームの在り方についても、本書で提示された視点を参考に、自社での最適な形を模索していきたいと思います。6 Let's build a platform on top of KuberneteKubernetes上でのプラットフォーム構築に関する具体的な方法論と深い洞察に満ちた、非常に示唆に富む内容でした。著者は、プラットフォームエンジニアリングにおける重要な概念と実践を、豊富な事例とともに解説しています。第6章の前半では、プラットフォームAPIの設計と、マルチクラスター・マルチテナンシーの課題が中心的に論じられています。まず著者は、プラットフォームが Kubernetes 上で提供すべき機能を特定することの重要性を説いています。開発チームのワークフローを理解し、彼らが必要とするサービスを抽出することが、プラットフォームAPIの設計の出発点となります。ここでは、開発チームが新しい環境を要求するシナリオを例に、APIのデザインプロセスが丁寧に解説されています。要求された環境をプロビジョニングし、アクセス情報を返却する自動化ロジックを実装することで、開発チームの生産性を大きく向上できるのです。このアプローチは、プラットフォームエンジニアリングの神髄とも言うべきものです。技術的な実装の前に、ユーザーである開発者の体験を起点に設計を進めるというマインドセットこそが、真に開発者に寄り添ったプラットフォームを生み出す鍵となります。続く議論では、マルチクラスターおよびマルチテナントのセットアップに関する課題が取り上げられます。本番、ステージング、開発など、様々な環境を提供する必要があるKubernetesベースのプラットフォームでは、これらの課題が避けて通れません。著者は、プラットフォーム専用のクラスターを設けることで、一貫した管理と高い可用性を実現するアプローチを提案しています。ワークロードとは分離された環境でArgoCD、Crossplaneなどのツールを用いてプラットフォームを構築することで、求められるSLOやセキュリティ要件に適切に対処できるのです。また、マルチテナンシーの実現方法として、Namespaceによる分離と、完全に独立したクラスターによる分離のトレードオフについても、鋭い考察が展開されています。前者は手軽である一方で分離のレベルが低く、後者は強力な分離を提供する反面コストと運用負荷が大きいという、難しい選択の狭間にある課題です。この問いに対する著者の提案が、vclusterを用いた仮想クラスターのアプローチです。1つのKubernetesクラスター内に、テナントごとに独立したコントロールプレーンを持つ仮想クラスターを動的に生成することで、Namespaceと独立クラスターの中間的な選択肢を提供できるのです。www.vcluster.comAPIサーバーレベルの分離により、テナントはクラスター全体に対する高い自由度を享受しつつ、リソースの利用効率を高められる。これは、マルチテナンシーの難しい課題に対する、エレガントな解決策の一つと言えるでしょう。以上の議論を通じて、読者はKubernetes 上のプラットフォームがどのようなものかを具体的に理解できるようになります。プラットフォーム構築には、インフラストラクチャの設計だけでなく、開発者の体験を起点とした抽象化やAPIのデザインが不可欠だということ。そして、それを実現するためには、Kubernetesの深い理解に加え、マルチクラスター・マルチテナンシーの課題に正面から向き合う必要があるということ。第6章の前半は、そうした重要な気づきに満ちています。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。以上のように、複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン(PoC)」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。Figure 6.9 Combining GitOps and Crossplane for managing environments and clusters より引用さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。Figure 6.16 Using Crossplane and vcluster to create isolated environments for application development teams より引用もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。Figure 6.18 Platform walking skeleton tools, configurations, and services より引用実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。Figure 6.19 Platform responsibilities and boundaries より引用本章は、プラットフォームエンジニアリングの本質を、概念と実装の両面から照らし出してくれる、稀有な内容でした。単なるツールの解説にとどまらず、開発者の体験を起点とした設計思想や、チームとの協調の重要性など、プラットフォーム構築に不可欠な知見が余すところなく述べられています。本章を通じて、私はプラットフォームの構築が、技術とプロセス、そして文化の融合であることを改めて認識しました。優れたツールの選定と適切な組み合わせは もちろん重要です。しかし、それ以上に大切なのは、開発者の声に耳を傾け、彼らの創造性を解き放つ仕組みを築くことなのだと。Kubernetesとそのエコシステムは、プラットフォームを構築するための強力な基盤を提供してくれます。しかし、それをどう活用し、どのような形でチームに提供するかは、私たち自身の創意工夫次第です。技術の力を借りつつ、開発者の声に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は教えてくれました。本章は、プラットフォームエンジニアリングという新しい領域に踏み出すための、確かな一歩を印してくれる内容でした。著者の知見を自分なりに咀嚼し、日々の開発プロセスに活かしていく。その積み重ねの先に、真のDXを実現するプラットフォームが生まれるはずです。7 Platform capabilities I: Shared application concerns著者は冒頭で、クラウドネイティブアプリケーションの95%が行っている要件を学ぶことの重要性を強調しています。その要件とは、他のサービスとの通信、永続ストレージへのデータの保存と読み取り、非同期でのイベントやメッセージのやり取り、サービス接続用の認証情報へのアクセスなどです。私自身、日々の開発業務でこれらの課題に幾度となく直面してきました。著者の指摘は、まさに開発現場の実情を的確に捉えたものだと感じました。Figure 7.1 Common communication patterns in distributed applications より引用これらの共通機能を実装する際の課題として、著者はアプリケーションとインフラストラクチャの間の摩擦を減らすことの重要性を指摘しています。サービス間通信やデータベース接続のために、アプリケーションコードにベンダー固有のライブラリやドライバを追加すると、インフラストラクチャの変更がアプリケーションの変更を強いることになります。この密結合が、開発チームとインフラチームの協調を複雑にし、ソフトウェアデリバリーのスピードを低下させる要因となっているのです。著者が提案するのは、標準のAPIとコンポーネントで共有の関心事に対処することです。これらの共通機能を標準化されたAPIとして提供し、アプリケーションコードからインフラストラクチャの詳細を切り離すのです。プラットフォームチームがこれらのAPIを実装し、その背後でインフラストラクチャを適切に構成・管理することで、開発チームはビジネスロジックの実装に専念できるようになります。アプリケーションインフラストラクチャに依存関係を移動すると、アプリケーションコードはプラットフォーム全体のアップグレードに影響されずに済みます。アプリケーションとインフラストラクチャのライフサイクルを分離することで、チームは日常的なユースケースでプロバイダー固有のクライアントやドライバーを扱う代わりに、安定したAPIに依存できるようになります。Figure 7.14 Decoupling responsibilities from app dev teams and platform capabilitiesより引用この提案には大いに共感を覚えました。私もかねてより、アプリケーションとインフラの責務を明確に分離し、疎結合な設計を追求することの重要性を感じていました。標準化されたAPIを介してインフラストラクチャと対話することで、開発チームはベンダーロックインを回避しつつ、インフラの進化から独立してアプリケーションを開発できるようになります。著者は、この考え方を具体化するためのツールとして、Dapr（Distributed Application Runtime）とOpenFeatureを紹介しています。Daprは、分散アプリケーションの構築に必要な共通機能を、標準化されたAPI（Building Block API）として提供するオープンソースのプロジェクトです。Daprは、分散アプリケーションを構築する際の共通の関心事を解決します。HTTP/GRPCリクエストを書くことができる開発者は、プラットフォームチームが接続するインフラストラクチャとやりとりできます。 サービス間通信、状態管理、Pub/Sub、シークレットストアなど、クラウドネイティブアプリケーションに不可欠な機能がコンポーネント化され、統一的なインターフェースで利用できるようになっています。dapr.io私は以前からDaprに注目していましたが、改めてその設計思想の優れていることを実感しました。アプリケーションが標準的なHTTP/gRPCのAPIを通じてこれらの機能を利用できるため、プログラミング言語に依存せずに共通機能を実装できます。また、コンポーネントの実装を切り替えるだけで、異なるベンダーのサービスを利用できるのも大きな利点です。インフラの選定はプラットフォームチームに委ね、開発チームはアプリケーションの開発に専念できる。まさにDaprは、アプリケーションとインフラの責務を明確に分離するためのツールと言えるでしょう。syu-m-5151.hatenablog.com特に、サービス間通信とステートマネジメントのシナリオは、印象的でした。DaprのサービスインヴォーケーションAPIを使えば、サービス間の通信を抽象化し、さまざまな通信プロトコルを透過的に利用できます。またステートストアAPIにより、アプリケーションはデータベースの種類を意識せずに状態を保存・取得できるようになります。実際のアプリケーション開発において、これらのAPIがいかに複雑性を減らし、生産性を高めてくれるかが実感できる内容でした。一方、OpenFeatureは機能フラグ（Feature Flag）の管理を標準化するためのプロジェクトです。機能フラグを使用すると、新機能を機能フラグの背後にマスクすることで、開発者はソフトウェアのリリースを継続できます。 機能フラグは、リリース済みの機能の有効・無効を動的に切り替える仕組みで、継続的デリバリーの文脈でよく用いられます。しかし、その実装は各社まちまちで、ベンダーロックインが起こりがちでした。OpenFeatureは、アプリケーションが機能フラグを使用して評価する方法を標準化します。OpenFeatureの抽象化に依存することで、プラットフォームチームは機能フラグの保存場所と管理方法を決定できます。 さまざまなプロバイダーが、非技術者向けのダッシュボードを提供し、フラグの表示や操作ができるようになります。Figure 7.22 Consuming and evaluating feature flags from our application services より引用私は機能フラグの重要性を認識しつつも、その導入の複雑さゆえに二の足を踏んでいました。しかしOpenFeatureにより、ベンダーに依存せずに機能フラグを利用できるようになるのは画期的だと感じました。開発チームは機能の実装に集中し、リリースのタイミングはビジネスサイドが制御する。そんな理想的なデリバリープロセスが、OpenFeatureによって実現に近づくのではないでしょうか。openfeature.dev著者はまた、これらの標準化の取り組みを適用する際の留意点についても言及しています。外部APIへの依存は新たな課題を生むため、ローカル開発環境でのテストや、レイテンシーへの配慮が必要になります。また、エッジケースを個別に扱うことで、専門家はアプリケーションの要件に基づいてより意識的なケースを作成できます。これにより、経験の浅いチームメンバーが、データの保存や読み取り、アプリケーションコードからのイベントの発行のみを行う場合に、ベンダー固有のデータベース機能や低レベルのメッセージブローカー設定などのツールの詳細を理解する必要がなく、一般的なシナリオを処理できるようになります。 プラットフォームチームは、開発チームとの緊密なコミュニケーションを通じて、適切な抽象化のレベルを見極めていく必要があるのです。章の後半では、これらの知見をConferenceアプリケーションに適用する方法が具体的に示されています。Redis や Kafka への依存を Dapr の API で置き換え、機能フラグを OpenFeature で管理する例は、非常に示唆に富むものでした。コード例を見ると、標準APIがいかにしてベンダー依存を排除し、開発者の体験を向上させているかが手に取るようにわかります。Figure 7.23 Using Dapr components for our walking skeleton / Conference application より引用これは私にとって、Dapr と OpenFeature の有用性を確信できる一節でした。ステップバイステップのチュートリアルに従った場合、SQL や NoSQL データベース、Kafka などのメッセージブローカーとやり取りする4つのサービスで構成されるクラウドネイティブアプリケーションのコンテキストで、Dapr や OpenFeature などのツールを使用した実践的な経験を得ることができました。また、実行中のアプリケーションのコンポーネントを再起動せずに、その動作を変更するために機能フラグを変更しました。 Kubernetesの普及により、インフラストラクチャのAPIは標準化されつつあります。一方で、アプリケーションレイヤーの共通機能は、いまだ各社独自の実装に委ねられているのが実情です。Dapr と OpenFeature は、このアプリケーションレイヤーに標準化をもたらす画期的なプロジェクトだと言えるでしょう。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にインフラを提供するだけでなく、アプリケーションの共通関心事をカプセル化し、開発者の生産性を高めることがプラットフォームの本質的な価値だと。Dapr や OpenFeature のようなツールを活用しつつ、開発チームに寄り添ったプラットフォームを構築すること。そこにこそ、プラットフォームエンジニアの腕の見せ所があるのだと感じました。もちろん、標準化された API を導入するだけで全てが解決するわけではありません。エッジケースをどう扱うか、レガシーなシステムとの整合性をどう取るか。プラットフォーム構築の道のりは平坦ではありません。しかし、アプリケーションとインフラの責務を分離し、開発チームの生産性を高めるという指針は普遍的なものだと信じています。プラットフォームエンジニアリングの真髄は、技術の標準化とコミュニケーションの両輪にあるのだと、本章は教えてくれました。本章は、クラウドネイティブ時代のアプリケーション開発の課題と、それを解決するための処方箋を示してくれる、示唆に富んだ内容でした。Dapr や OpenFeature のような取り組みは、まさにクラウドネイティブの「今」を体現するものだと言えるでしょう。同時に、それらを適切に活用し、開発チームに価値を届けるには、プラットフォームチームの深い理解と尽力が不可欠です。プラットフォームエンジニアリングの真価が問われるのは、技術の選定よりもむしろ、技術をいかに活用するかにあるのかもしれません。標準化と抽象化を追求しつつ、現場の声に真摯に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は示唆しています。本章で紹介されたツールやプラクティスは、開発者としての私の日々の実践にも大いに役立つはずです。Dapr や OpenFeature を実際のプロジェクトで活用し、その効果を体感してみたいと思います。同時に、インフラストラクチャの標準化が進む中で、アプリケーションレイヤーの共通関心事にも目を向けることの大切さを、胸に刻んでおきたいと思います。著者の知見を自分なりに咀嚼し、より良いアプリケーション開発とデリバリーのあり方を追求していく。エンジニアとしての私の使命は、まさにそこにあるのだと、改めて認識させられた次第です。クラウドネイティブの世界は、日進月歩で進化を続けています。Dapr や OpenFeature に象徴されるように、アプリケーションレイヤーの標準化も着実に進んでいます。私たちがすべきことは、その流れを見極めつつ、自分たちのコンテキストに適した形で活用していくことです。8 Platform capabilities II: Enabling teams to experimentKubernetesを基盤としたプラットフォーム上で、チームが新しいバージョンのアプリケーションを安全かつ柔軟にリリースするための手法について、深く掘り下げた内容でした。著者は冒頭で、カナリアリリース、ブルー/グリーンデプロイメント、A/Bテストなどの一般的なリリース戦略を実装することの重要性を説いています。これらの手法は、新しいバージョンのソフトウェアを段階的に展開し、問題を早期に発見しつつ、ユーザーへの影響を最小限に抑えるために不可欠です。しかし、著者が指摘するように、これらのリリース戦略をKubernetesの組み込みリソースだけで実装するのは非常に難しい作業です。Deploymentの複製や、Serviceの設定変更など、手作業での操作が多くなり、ミスも起こりやすくなります。そこで著者が紹介するのが、Knative ServingとArgo Rolloutsという2つのプロジェクトです。これらのツールは、Kubernetesの上に高レベルの抽象化を提供することで、リリース戦略の実装を大幅に簡素化してくれます。argoproj.github.ioknative.devKnative Servingは、洗練されたネットワーク層を導入し、サービスの異なるバージョンへのトラフィックをきめ細かく制御できるようにします。Knative Serviceを使えば、カナリアリリースやブルー/グリーンデプロイメント、A/Bテストを、複数のKubernetesリソースを手動で作成することなく実現できます。Figure 8.1 Releasing a new version (canary) of the service with 5% traffic routed to it より引用Knative Servingの大きな魅力は、トラフィックの移動を簡単に行えることと、Knativeのオートスケーラーが需要に応じてサービスをスケールアップ/ダウンしてくれることです。これにより、運用の負担が大幅に軽減されるのです。一方、Argo Rolloutsは、ArgoCDと連携し、Rolloutというリソースを使ってリリース戦略を実装する方法を提供します。Argo RolloutsはAnalysisTemplateとAnalysisRunという仕組みも備えており、新しいリリースの自動テストを行い、安全にバージョン間を移行できるようにしてくれます。Figure 8.23 Blue/green deployment with Kubernetes resources より引用この2つのプロジェクトの存在は、Kubernetes上でのソフトウェア・デリバリーの課題の大きさを物語っていると感じました。アプリケーションのデプロイだけでなく、それを安全かつ柔軟に行うための機能が、プラットフォームに求められているのです。特に印象的だったのは、Knative Servingのトラフィック制御機能の強力さです。重み付けベースのルーティングや、ヘッダーベースのルーティングなどを使えば、カナリアリリースの過程で新旧のバージョンへのアクセスを動的に制御できます。これは、リスクを最小限に抑えつつ、新機能の検証を進められる画期的な方法だと感じました。Figure 8.8 Knative Serving tag-based routing for version v1.1.0. より引用また、Argo Rolloutsの分析テンプレートの仕組みにも目を見張りました。あらかじめ定義した指標に基づいて、新バージョンの動作を自動的に検証できるのは、リリースプロセスの安全性と効率を大いに高めてくれるはずです。Figure 8.25 Argo Rollouts and analysis working together to make sure that our new revisions are sound before shifting more traffic to them. より引用もちろん、これらのツールを使いこなすには、一定の学習と運用コストがつきまといます。Kubernetes自体の知識に加え、Knative ServingやArgo Rolloutsの概念を理解する必要があります。特に、Istioなどのサービスメッシュとの連携については、さらに高度な知識が求められるでしょう。しかし、長期的に見れば、その投資は確実に報われるはずです。プラットフォームが提供する柔軟なリリース戦略は、ビジネスの俊敏性を高め、イノベーションを加速する力になります。より速く、より安全に価値を届けられるようになることは、競争力の源泉になるのですから。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にKubernetesのリソースを提供するだけでなく、アプリケーションのリリースプロセスをどう効率化するかを考え、適切なツールを選定・提供していくこと。それこそが、開発チームの生産性を真に高めるための鍵なのだと感じました。Figure 8.23 Blue/green deployment with Kubernetes resources より引用そのためには、Knative ServingやArgo Rolloutsだけでなく、Istio、Dapr、OpenFeatureなど、クラウドネイティブのエコシステムを幅広く理解することが求められます。それぞれのツールの特性を把握し、自社のコンテキストに合った形で組み合わせていく。その作業は決して容易ではありませんが、避けて通れないものだと思います。私自身、日々の業務の中で、これらのツールを実際に活用し、その効果を体感してみたいと思います。サービスのデプロイに留まらず、リリースプロセスの自動化と効率化にも目を向ける。そのマインドセットを持つことが、プラットフォームエンジニアとして成長するための第一歩になるはずです。また、本章では、ビジネスサイドのチームとの協調の重要性も浮き彫りになりました。プロダクトマネージャーや非エンジニアのステークホルダーに、新バージョンの検証を柔軟に行える環境を提供すること。これにより、ビジネス主導のイノベーションを後押しできるのです。Figure 8.29 Environments that enable teams to experiment with new versions より引用本章を読み終えて、改めてプラットフォームの真価は、それがエンパワーメントの手段であることだと感じました。開発者の創造性を強化して、ビジネスの意思決定を迅速化する。その先にこそ、ソフトウェアがもたらす本当の価値があるのだと。プラットフォームの構築は、単なる技術的課題ではありません。組織の文化を変え、人々の働き方そのものを変えていく営みです。その変革の旅路は、険しく長いものになるでしょう。でも、そこで得られる学びと成長は、きっとかけがえのないが大変なものになるはずです。9 Measuring your platformsプラットフォームのパフォーマンスを測定することの重要性と、その具体的な手法について深く掘り下げた内容でした。特に、DORAメトリクスの導入と、それを支えるデータパイプラインの設計には、多くの技術的な示唆が含まれていました。dora.devDORAメトリクスは、ソフトウェアデリバリーのパフォーマンスを評価するための事実上の標準として、広く認知されつつあります。デプロイ頻度、リードタイム、変更失敗率、サービス復旧時間の4つの指標は、いずれもデリバリープロセスの重要な側面を捉えており、それらを組み合わせることで、チームの成熟度を多面的に評価できます。Figure 9.1 DORA metrics by category より引用しかし、これらのメトリクスの計算は、決して容易ではありません。データソースが多岐にわたるうえ、それぞれのツールが出力するデータのフォーマットは千差万別だからです。デプロイ頻度を計算するには、CIツールのログとデプロイ環境のイベントを紐づける必要がありますし、リードタイムの算出には、コミットログとデプロイログの時間差を計る必要があります。この複雑性に対する著者の答えが、CloudEventsとCDEventsの活用です。CloudEventsは、クラウドネイティブなイベントを表現するための、ベンダー中立な仕様です。すでにServerless Workflow、Keptn、Knative、Kubernetesなど、多くのプロジェクトがCloudEventsをサポートしており、イベントデータの相互運用性が大きく向上しつつあります。cloudevents.ioCDEventsは、CloudEventsの拡張仕様であり、継続的デリバリーの文脈で共通に発生するイベントを定義したものです。コード変更、ビルド、テスト、デプロイ、リリースなど、パイプラインのあらゆるフェーズがカバーされており、それぞれのイベントが持つべきデータの構造も規定されています。Figure 9.7 The four stages defined by the CDEvents specification より引用つまり、CDEventsに準拠したイベントを集約することで、DORAメトリクスの計算に必要なデータの多くを、統一的なフォーマットで取得できるようになるのです。これは、データ統合のコストを大幅に削減し、メトリクスの信頼性を高めることにつながります。cdevents.devとはいえ、既存のツールをCDEventsに対応させるのは、一朝一夕にはいかないでしょう。そこで著者が提案しているのが、CloudEventsとCDEventsを活用したデータパイプラインの設計です。各ツールが出力するイベントをCloudEventsとして取り込み、それをCDEventsに変換する。そのうえで、変換されたイベントをもとにメトリクスを計算する、というアプローチです。Figure 9.9 Collecting and transforming data to calculate DORA metrics より引用パイプラインの入り口では、Knative Sourcesのようなアダプタを使って、さまざまなツールのイベントをCloudEventsに変換します。例えば、Kubernetes上で動くアプリケーションの場合、KubernetesイベントをCloudEventsに変換するKnative SourceのApiServerSourceを使うことができます。Figure 9.10 Knative Sources and data collection より引用こうして取り込まれたCloudEventsは、いったんデータストアに保存されます。著者の例ではPostgreSQLが使われていますが、他のデータベースやストレージを使うこともできるでしょう。重要なのは、イベントデータを安全に保管し、後の処理で参照できるようにすることです。次のステップは、保存されたCloudEventsをCDEventsに変換することです。著者は、この変換処理を関数（function）として実装することを提案しています。関数を使うメリットは、変換ロジックを小さな単位に分割でき、必要に応じて個別にスケーリングできる点にあります。また、新しい変換ロジックを追加する際も、既存の処理に影響を与えずに実装できます。Figure 9.12 Concrete mapping and CDEvent creation for deployments より引用CDEventsへの変換が完了したら、いよいよDORAメトリクスの計算です。著者の提案では、これもまた関数として実装されます。各メトリックの計算ロジックは、CDEventsから必要なデータを抽出し、所定の計算を行うだけのシンプルなものになります。計算結果は、データストアに保存するか、あるいは直接可視化ツールに送ることができます。Figure 9.15 Deployment frequency calculation flow より引用以上が、著者が提案するデータパイプラインのアーキテクチャの概要です。特筆すべきは、その拡張性の高さでしょう。新しいデータソースへの対応は、CloudEventsへの変換機能を追加するだけで実現できますし、新しいメトリクスの計算も、専用の関数を実装するだけで可能になります。また、変換処理とメトリクス計算がステートレスな関数として実装されているため、必要に応じて水平にスケールすることもできます。この設計は、現時点での技術選択に依存しない、汎用性の高いものだと感じました。実際のシステムを構築する際には、より堅牢なイベントストレージの選定や、耐障害性の確保など、様々な非機能要件も考慮する必要があるでしょう。しかし、その基本的なアプローチは、多くの組織で活用できるはずです。加えて、本章ではKeptn Lifecycle Toolkit（KLT）というオープンソースプロジェクトも紹介されていました。KLTは、Kubernetes上のアプリケーションのデプロイメントを監視し、その前後に任意のタスクを実行できるようにするためのツールです。Figure 9.21 Keptn architecture providing out-of-the-box observability and application lifecycle hooks. より引用KLTは、Kubernetesの標準機能であるSchedulerを拡張することで実現されています。アプリケーションのデプロイメント時に、KLTのControllerが介入し、デプロイメントの前後に登録されたタスクを実行するのです。github.comこれらのタスクはTaskDefinitionという形で定義され、実際の処理はスクリプト（Deno、Python3など）またはコンテナイメージとして実装されます。例えば、デプロイ前にアプリケーションの設定を検証するタスクや、デプロイ後に自動テストを実行するタスクなどが考えられます。keptn.shKLTのアプローチは、先に述べたCloudEvents/CDEventsベースのデータパイプラインとは異なりますが、両者は相互に補完的な関係にあると言えるでしょう。KLTを使えば、デプロイメントのパフォーマンスデータをCloudEventsとして出力し、それをデータパイプラインで処理することもできます。逆に、データパイプラインで計算されたメトリクスを、KLTのタスクで参照することも可能です。重要なのは、これらのツールを組み合わせることで、プラットフォームのパフォーマンス測定を自動化し、継続的な改善につなげられる点です。今や、デリバリーパフォーマンスの向上は、エンジニアリングチームだけの責任ではありません。組織全体でその重要性を認識し、データに基づいた意思決定を行っていく必要があります。そのためには、DORAメトリクスのような共通の物差しを導入し、それを可視化・共有していくことが不可欠です。CloudEventsとCDEvents、そしてKLTは、そのための強力な武器になるはずです。もちろん、ツールの導入だけですべてが解決するわけではありません。測定の文化を組織に根付かせ、データに基づいた継続的改善のサイクルを回すこと。それこそが、プラットフォームチームに求められる真の課題なのだと、私は考えます。本章を通じて、私はプラットフォームのパフォーマンス測定という課題の奥深さを改めて認識しました。適切な指標の選定、データの収集と統合、分析基盤の構築。それらはいずれも、高度な技術力と、現場への深い理解を必要とする難題です。しかし、その困難に立ち向かうことこそが、プラットフォームエンジニアの本懐なのだと思います。本章が提示してくれたのは、その挑戦への道標でした。実装の細部はともかく、その基本的なアプローチは、多くの組織で活用できるはずです。KLTのようなツールも、プラットフォームのパフォーマンス測定という文脈で捉え直すことで、新たな価値を見出せるでしょう。重要なのは、DORAメトリクスに代表される共通の物差しを導入し、それを組織全体で活用していくことです。さいごに本稿では、『Platform Engineering on Kubernetes』の概要と、各章の要点を技術者の視点でまとめました。本書が提示するのは、クラウドネイティブ時代のソフトウェア開発の理想像です。アプリケーションとインフラストラクチャの垣根を越えて、開発チームとプラットフォームチームが協調しながら、ビジネス価値を継続的に届けていく。その実現のためには、技術的な側面だけでなく、組織文化やプロセスの変革も不可欠だと述べられています。私はプラットフォームエンジニアリングという概念自体は以前から知っていましたが、本書ではそれをKubernetesと関連づけて深く考察されていました。単にKubernetesというツールを導入するだけでなく、アプリケーションに必要な機能を適切に抽象化し、チームに提供していくことがプラットフォームの本質的な価値だと説明しながら技術的なことを一切疎かにしていない点がとんでもなく素晴らしいです。また、DORAメトリクスに代表される、デリバリーパフォーマンスの測定の重要性も強調されていました。プラットフォームの価値を定量的に評価し、継続的に改善していくためには、適切な指標の導入と、データに基づいた意思決定が欠かせません。ただし、本書で紹介されているアプローチをそのまま適用できる組織ばかりではないでしょう。大切なのは、自社のコンテキストを深く理解し、そこに適した形でクラウドネイティブの考え方を取り入れていくことだと思います。プラットフォームエンジニアリングを実践していく上では、本書で述べられているようなツールやプラクティスに加えて、コミュニケーションが大切だと思いました。モブプログラミング・モブオペレーションなどの取り組みを通じて、チーム内での知識共有や価値観の浸透を図ることが、プラットフォームの継続的な改善と定着に大きく役立つはずです。本稿では、技術者としての視点から本書の内容をまとめましたが、プラットフォームエンジニアリングの実践には、技術者以外のステークホルダーの理解と協力も不可欠です。マネージャーやビジネスサイドの方々にも本書を読んでいただき、その感想をぜひ共有していただきたいと思います。多様な視点からのフィードバックがあってこそ、真に組織に適したプラットフォームの構築が可能になるはずです。また、本稿ではプラットフォームに関わる技術的な側面に焦点を当てましたが、実際のプラットフォーム構築には、組織的な要素も欠かせません。各チームのエンジニアの育成や、円滑なコミュニケーションの実現など、プラットフォームエンジニアリングには幅広いスキルが要求されます。こうした非技術的な側面については、また別の機会に掘り下げていきたいと思います。プラットフォームは日々進化し続けるものです。特定のツールの使い方を習得するだけでなく、その背後にある考え方や原則を理解し、学び続けていく姿勢が求められます。『Platform Engineering on Kubernetes』は、そのための優れた指南書だと感じました。クラウドネイティブ時代のソフトウェア開発は、まだ道半ばと言えるかもしれません。確立されたベストプラクティスは少なく、私たち一人ひとりが試行錯誤を重ねながら、前に進んでいくしかありません。本書が示してくれた知見と、SREの実践的なアプローチを組み合わせながら、クラウドネイティブ時代のプラットフォームのあるべき姿を、仲間たちと共に探求していきたいと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/28/230604","isoDate":"2024-03-28T14:06:04.000Z","dateMiliSeconds":1711634764000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"はてなブログの記事をGitHubに自動でPushする方法","contentSnippet":"ツールに感謝。コミュニティに感謝。github.comxではてなブログで更新する時にDiffが見れるととても助かるのだけど有料版だと可能とかありますか？みたいなこと聞いてたらwhywaita さんが教えてくれた!!!blogsyncどうでしょう https://t.co/Duh31GJGrV— why/橘和板 (@whywaita) 2024年3月23日   この記事では、blogsyncを用いてはてなブログの記事をGitHubに自動的に同期する方法について説明します。GitHub Actionsを使用して、はてなブログの記事を定期的にプルし、GitHubリポジトリに反映させることができます。当初はブログを更新する際に、記事の変更点（Diff）を確認できるようにしたいと考えました。しかし、NeoVimを使用してブログを書いているわけではないので、単に日付単位のDiffを取得できれば十分だと思ったため、この構成にしました準備1. はてなブログのAPIキーを取得はてなブログの設定ページ（https://blog.hatena.ne.jp/-/config）にアクセスし、「詳細設定」タブの「APIキー」セクションでAPIキーを取得します。2. GitHub Actionsのワークフローを設定.github/workflows/hatena-blog-pull.yamlに以下の内容を配置します。name: Blogsync Pullon:  schedule:    - cron: '0 0 * * *'jobs:  blogsync_pull:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v2      - name: Set up Blogsync        uses: x-motemen/blogsync@v0        with:          args: --version      - name: Create blogsync.yaml        run: |          cat << EOF > blogsync.yaml          your_hatena_blog_id.hatenablog.com:            username: your_hatena_blog_id            password: ${{ secrets.HATENA_API_KEY }}          default:            local_root: .          EOF        shell: bash      - name: Pull articles from Hatena Blog        run: |          blogsync pull --no-drafts      - name: Commit changes        run: |          git config --local user.email \"action@github.com\"          git config --local user.name \"GitHub Action\"          git add .          git reset -- blogsync.yaml          git commit -m \"Pull articles from Hatena Blog\" || echo \"No changes to commit\"      - name: Push changes        uses: ad-m/github-push-action@v0.6.0        with:          github_token: ${{ secrets.GITHUB_TOKEN }}          branch: mainこのワークフローは、毎日0時（UTC）に実行されるようにスケジュールされています。3. ワークフローの権限を設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/actions）にアクセスし、「Workflow permissions」セクションで「Read and write permissions」を選択します。これにより、ワークフローがリポジトリに変更を書き込むことができるようになります。4. はてなブログのAPIキーを設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/secrets/actions）にアクセスし、「Repository secrets」セクションで「New repository secret」をクリックします。「Name」にHATENA_API_KEYと入力し、「Value」に手順1で取得したはてなブログのAPIキーを入力します。カスタマイズblogsync.yamlファイルの設定を必要に応じて書き換えてください。以下は設定例です。your_hatena_blog_id.hatenablog.com:  username: your_hatena_blog_id  password: ${{ secrets.HATENA_API_KEY }}default:  local_root: .your_hatena_blog_idの部分を実際のはてなブログIDに置き換えてください。また、このファイルは秘密にしなければいけないので基本的には.gitignoreに入れておいてください。blogsync.yaml使い方.github/workflows/hatena-blog-pull.yamlファイルをリポジトリに追加します。ワークフローは毎日0時（UTC）に自動的に実行されます。はてなブログの記事がGitHubリポジトリにプルされ、変更がコミットされます。以上で、はてなブログの記事をGitHubで自動的に管理できるようになります。ワークフローを設定したら、あとは記事を書くだけです。記事の変更が毎日GitHubリポジトリに自動的に反映されます。参考URLGitHub Actions でのシークレットの使用push-to-hatenablogを使い，はてなブログへの投稿記事をGitHubで管理したら最高だった！はてなブログ作成から投稿までを自動化したGitHub Actionsのワークフロー","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/23/194702","isoDate":"2024-03-23T10:47:02.000Z","dateMiliSeconds":1711190822000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"nwiizoはなぜSpeaker Deckに上げた資料をブログにするのか？","contentSnippet":"はじめに私(nwiizo)は、ソフトウェアエンジニアとして日々の開発で得た知見やノウハウを、勉強会などで作成したプレゼンテーション資料としてSpeaker Deckに公開しています。Speaker Deckは、スライド共有サービスの一つで、スライドを簡単に公開・共有できる素晴らしいプラットフォームです。しかし、Speaker Deckに資料を公開するだけでは、いくつかの課題があります。スライドは情報を凝縮して伝えるために作られているため、詳細な説明や補足情報が不足しがちです。また、スライドだけでは、多くの人に情報が届きにくいという問題もあります。これらの課題を解決するために、私は Speaker Deck に上げた資料の内容を、改めてブログ記事として書くことにしています。本記事では、Speaker Deckに上げた資料をブログ記事化する意義について、詳しく解説していきます。詳細な説明と補足情報の追加スライドは、限られた紙面に要点を簡潔にまとめる必要があるため、情報を凝縮して伝えることに重点が置かれています。しかし、これだけでは聴衆の理解が表面的なものにとどまってしまう可能性があります。一方、ブログ記事では、スライドの内容を詳細に説明することができます。例えば、スライドではコードのスニペットを示すだけで終わってしまうことがありますが、ブログ記事ではそのコードの解説を丁寧に行うことができます。また、スライドでは伝えきれなかった背景情報や、補足説明を加えることで、より深い理解を促すことができるでしょう。さらに、スライドで紹介した技術や手法が、他の分野とどのように関連しているかを説明することもできます。これにより、読者は新たな観点からの問題解決のヒントを得ることができるかもしれません。Speaker Deck のスライドをブログ記事化することで、内容をより詳細に、より多面的に説明することができるのです。これは、情報を正確に伝え、読者の理解を深めるために非常に重要なことだと言えるでしょう。アウトプットによる技術力の向上ソフトウェアエンジニアにとって、新しい技術を学ぶことは重要ですが、学んだことをアウトプットすることも同様に重要です。登壇もそうですがブログ記事を書くためには、自分の知識を整理し、体系的に説明する必要があります。この過程で、自分の理解が深まり、技術力の向上につながります。ブログ記事を書く際には、自分が当たり前だと思っていたことを改めて見直すことになります。その際、自分の理解が不十分だったところや、説明が難しい部分に気づくことがあるでしょう。これは、さらなる学習のモチベーションにつながります。また、ブログ記事を公開することで、読者からのフィードバックを受けることができます。読者の質問や指摘は、自分では気づかなかった視点を提供してくれるかもしれません。このようなフィードバックから学ぶことで、さらなる技術力の向上が期待できます。ここで注目すべきは、登壇資料とブログ記事の違いです。登壇資料は、聴衆の反応を見ながら、その場で説明を調整することができます。また、質問に答えることで、理解が不十分な部分を補うこともできます。一方、ブログ記事は、書いた内容がそのまま読者に伝わります。誤りや不十分な説明があれば、それがダイレクトに読者に伝わってしまうのです。つまり、ブログ記事を書くことは、自分の知識や理解をより厳密に見直す機会になります。誤魔化しが効かない分、自分の理解の甘さが露呈するリスクがあるのです。しかし、だからこそ、ブログ記事を書くことは、技術力向上により大きな効果をもたらすと言えるでしょう。自分の知識のギャップに気づき、それを埋めていく過程こそが、真の成長につながるのです。Speaker Deckの資料をブログ記事にすることは、自己の知識と真摯に向き合う機会を提供してくれます。これは、技術力向上のための素晴らしい機会だと言えるでしょう。継続的な学習習慣の確立技術の進歩が速いソフトウェア開発の世界では、常に新しいことを学び続ける必要があります。しかし、日々の業務に追われていると、学習の時間を確保することが難しく感じることもあるでしょう。そんな中で、Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための良い方法だと言えます。ブログ記事を書くためには、Speaker Deckの資料で扱ったトピックについて、さらに深く調査・研究する必要があります。この過程自体が、学習のプロセスの一部となります。また、ブログ記事を書くことを習慣化することで、学習のための時間を確保することが自然とできるようになるでしょう。さらに、自分の学習の成果をブログ記事としてアウトプットすることで、学習へのモチベーションを維持することもできます。自分の成長を可視化することは、さらなる学習への原動力になるはずです。加えて、ブログが増えて充実してくると、ブログを書くこと自体が楽しくなってくるものです。自分の知識や経験が、記事という形で蓄積されていくことに喜びを感じるようになります。また、読者からのフィードバックや反響が、さらなるブログ記事を書くモチベーションにつながります。こうして、Speaker Deckの資料をブログ記事化することと学習が、正のフィードバックループを形成するのです。学習した内容をブログ記事にすることで、学習が促進され、ブログ記事が充実します。充実したブログは、さらにブログを書く意欲を高めます。この好循環が、継続的な学習習慣を確立し、維持することにつながるのです。Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための素晴らしい方法なのです。技術の進歩に遅れないためにも、この習慣を身につけることをおすすめします。そして、この習慣が、エンジニアとしての成長を加速させる良いサイクルを生み出すことを期待しています。エンジニアとしての認知度向上とアイデンティティの確立ソフトウェアエンジニアにとって、自分の専門性や技術力を示すことは、キャリアを積み重ねる上で非常に重要です。Speaker Deckに資料を公開することは、自分の知見を共有する良い方法ですが、それだけでは限界があります。一方、ブログ記事を通じて、自分の知見やスキルを広くアピールすることができます。質の高い技術情報を継続的に発信することで、徐々に読者がついてくるでしょう。これは、エンジニアとしての認知度の向上につながります。認知度が高まれば、仕事の依頼や、登壇の機会なども増えるかもしれません。これは、キャリアアップのチャンスにもなるでしょう。また、企業のエンジニアとして働いている場合は、社外での認知度の向上が、社内での評価にもつながる可能性があります。さらに、ブログ記事を書くことは、エンジニアとしてのアイデンティティの確立にも役立ちます。自分の考えや経験を言葉にすることで、エンジニアとしての自分の立ち位置が明確になります。これは、自分のキャリアの方向性を考える上でも重要なことだと言えるでしょう。Speaker Deckの資料をブログ記事化して発信することは、エンジニアとしてのキャリア形成において非常に有益なのです。認知度の向上とアイデンティティの確立は、長期的な視点で見たときに、大きな意味を持つはずです。登壇への動機づけエンジニアにとって、カンファレンスや勉強会での登壇は、自分の知見を共有し、人脈を広げるための素晴らしい機会です。しかし、登壇することへの不安や、ネタが思いつかないといった理由で、なかなか一歩を踏み出せないエンジニアも多いのではないでしょうか。Speaker Deckの資料をブログ記事化することは、登壇への良い動機づけになります。すでにSpeaker Deckで発表した内容をベースにブログ記事を書くことで、徐々に自信がつくでしょう。また、ブログ記事への反響を見ることで、自分の知見に対する需要や、興味を持ってくれる人の存在を実感することができます。これは、登壇へのモチベーションにつながるはずです。また、ブログ記事は、登壇の良い練習の場にもなります。ブログ記事を書く際には、自分の考えを明確に言葉にする必要があります。これは、登壇の際にも求められるスキルです。ブログ記事を書くことで、プレゼンテーションスキルの向上も期待できるでしょう。さらに、ブログで築いた信頼関係が、登壇の機会につながることもあります。ブログを読んだ人から、登壇の依頼を受けるケースも珍しくありません。登壇は、エンジニアとしてのさらなる成長と、人脈の拡大に役立つはずです。Speaker Deckの資料をブログ記事化することは、その第一歩を踏み出すための素晴らしい動機づけになるのです。技術情報の発信と共有ソフトウェアエンジニアにとって、自分の知見やノウハウを共有することは重要な責務の一つです。新しい技術や手法を学んだら、それを他のエンジニアにも伝えることで、エンジニアコミュニティ全体の知識レベルの向上に貢献することができます。Speaker Deckに公開した資料をブログ記事として再構成することで、技術情報をより詳細かつ体系的に発信することができます。スライドだけでは伝えきれなかった詳細な説明や、実際のコード例などを交えることで、より深い理解を促すことができるでしょう。さらに、ブログ記事にはコメント欄を設けることができます。読者からの質問や意見を受け付けることで、インタラクティブなコミュニケーションが生まれます。これは、さらなる知識の共有や、新たな発見につながる可能性を秘めています。ソフトウェアエンジニアが持つ知識は、利用するか共有されてこそ価値があります。Speaker Deckの資料をブログ記事化し、積極的に情報を発信することは、エンジニアコミュニティ全体の発展に寄与する素晴らしい取り組みだと言えるでしょう。ブログの方があとから見返しやすいSpeaker Deckの資料を読むと、その時は内容を理解した気になれます。特に、登壇を聞いている時は、登壇者の説明を聞きながら資料を見ることができるので、理解が深まった感覚を得られるでしょう。しかし、時間が経つと、資料の内容を忘れてしまうことが多いのではないでしょうか。資料だけでは、詳細な説明が不足していることが多いため、あとから見返しても、内容を思い出すことが難しいのです。一方、ブログ記事は、詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。また、ブログ記事は検索しやすいというメリットもあります。特定の話題や技術について調べたい時に、関連するブログ記事を探すことができます。これは、自分が過去に学んだ内容を振り返る時にも役立ちます。さらに、ブログという文字のフォーマットを使うことで、登壇に比べて主張そのものに注意を向けさせることができます。人は身振り、声質、表情、顔といった外見や肩書に惑わされて主張を歪めて解釈してしまうことがありますが、ブログではそういった先入観をなるべく排除し、あくまで中身に集中させることができるのです。Speaker Deckの資料をブログ記事化することは、知識を長期的に活用するために非常に有効な方法だと言えるでしょう。おわりにSpeaker Deckに上げた資料をブログ記事として再構成することには、多くの意義があります。詳細な説明と補足情報の追加、アウトプットによる技術力の向上、継続的な学習習慣の確立、エンジニアとしての認知度向上とアイデンティティの確立、登壇への動機づけ、技術情報の発信と共有など、個人の成長とエンジニアコミュニティ全体の発展に寄与する様々なメリットがあるのです。また、Speaker Deckの資料は初見では理解した気になれますが、時間が経つと内容を忘れてしまいがちです。一方、ブログ記事は詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。Speaker Deckは、スライドを公開・共有するための素晴らしいプラットフォームですが、それだけでは情報共有の手段としては限界があります。一方、ブログは、より詳細で探索しやすい情報を提供することができます。Speaker Deckとブログを組み合わせることで、より効果的な技術情報の発信が可能になるのです。皆さんも、自分の知見を共有するためにこの方法を活用してみてはいかがでしょうか？参考資料木村政彦はなぜ力道山を殺さなかったのか作者:増田俊也新潮社Amazon人生は、運よりも実力よりも「勘違いさせる力」で決まっている作者:ふろむだダイヤモンド社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/22/122847","isoDate":"2024-03-22T03:28:47.000Z","dateMiliSeconds":1711078127000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"データエンジニアリングの要諦の後ろ髪を掴む - Fundamentals of Data Engineeringを読んで","contentSnippet":"最強なデータ分析基盤は何か⁉︎多種多様なデータ分析基盤が、制約のない環境で競合した時… ビジネス用途に限らず、あらゆるシナリオで使用可能な「データ分析」で比較した時、最強なデータ分析基盤は何か⁉︎ 今現在最強のデータ分析基盤は決まっていないデータ分析基盤まとめ（随時更新） などもあり大変参考にさせていただきました。ありがとうございます。はじめにデータエンジニアリングは、データの収集、処理、保存、そして提供を行う技術やプロセスを扱う複雑な分野です。この分野の全容を系統的に把握することは決して容易なことではありません。このような状況の中で、『Fundamentals of Data Engineering』という書籍に出会いました。この本は、著者たちの豊富な実務経験に基づいて書かれており、データエンジニアリングの基本概念とそのライフサイクルに焦点を当てています。さらに、これらの概念を現実の問題解決に応用する方法についても詳しく説明しています。全624ページに及ぶこの書籍は、その分厚さが示す通り、読破するには相当な時間と努力が必要ですが、その価値は十分にあると確信しています。learning.oreilly.com本書の特徴は、特定のツールや技術ではなく、データエンジニアリングの根幹をなす原則に焦点を当てている点です。著者らは、データ生成、ストレージ、取り込み、変換、提供といったライフサイクルの各段階を丁寧に解説し、それらを支える重要な概念を、具体的な技術選択やアーキテクチャ設計と関連付けて説明しています。また、クラウド技術を効果的に組み合わせて、下流のデータ消費者のニーズに応えるための方法論も提示しています。本書は、データエンジニアリングの理論と実践を見事に融合させ、この分野の要諦を掴むための羅針盤となります。著者らの豊富な知見と経験が随所に活かされ、ベストプラクティスのフレームワークを用いた問題の評価方法、市場の誇大広告を見抜く視点、堅牢なアーキテクチャの設計・構築手法などが解説されています。これらの知識は、データエンジニアリングの要諦を理解し、実践に活かすために不可欠な要素です。また、本書は、データエンジニアリングを取り巻く環境の変化についても言及しています。特に、クラウドファーストのアプローチを取ることで、オンプレミスからクラウドへのシフトを見据えた議論を展開しています。加えて、セキュリティとプライバシーの重要性についても強調しており、データエンジニアリングの現在と未来を見据えた内容となっています。本書を通じて、データエンジニアリングの全体像を俯瞰し、実践的な知識を得ることができました。データエンジニアリングの原則を自らの役割に取り入れ、クラウド技術を駆使して問題解決に取り組む方法を学べた点は、特に有益でした。本書は、データエンジニアリングの要諦を掴むための一助となる、貴重な一冊であると言えます。本稿はそんな書籍の読書感想文である。あくまで、私の感想なので指摘はそれぞれのSNSに書き散らしてください。『Fundamentals of Data Engineering』の構成本書は4つのパートで構成されています。パートIでは、第1章でデータエンジニアリングを定義し、第2章でデータエンジニアリングのライフサイクルを示します。第3章ではよいアーキテクチャについて議論し、第4章では適切な技術を選択するためのフレームワークを紹介します。パートIIは、第2章を基にデータエンジニアリングのライフサイクルを深く掘り下げています。データ生成、ストレージ、取り込み、変換、提供の各段階が独立した章で扱われます。パートIIは本書の中核をなす部分であり、他の章はここで扱われる核心的なアイデアをサポートするために存在しています。パートIIIでは、追加のトピックスとして、第10章でセキュリティとプライバシーについて議論しています。これらは常にデータエンジニアリングにおいて重要な部分でしたが、営利目的のハッキングや国家支援のサイバー攻撃の増加に伴い、さらに重要性が増しています。また、GDPRやCCPAなどの規制の出現により、個人データの不注意な取り扱いは重大な法的影響を及ぼす可能性があります。第11章では、データエンジニアリングの近未来について、著者らの大胆な予測を概説しています。付録では、データエンジニアリングの日々の実践に非常に関連性が高いものの、本文の主要部分には収まらなかった技術的トピックスを取り上げています。具体的には、シリアル化と圧縮（付録A）、クラウドネットワーキング（付録B）です。はじめに『Fundamentals of Data Engineering』の構成Part I. Foundation and Building BlocksChapter 1. Data Engineering DescribedChapter 2. The Data Engineering LifecycleChapter 3. Designing Good Data ArchitectureChapter 4. Choosing Technologies Across the Data Engineering LifecyclePart II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source SystemsChapter 6. StorageChapter 7. IngestionChapter 8. Queries, Modeling, and TransformationChapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETLPart III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and PrivacyChapter 11. The Future of Data Engineeringさいごに(追記)Part I. Foundation and Building BlocksChapter 1. Data Engineering Describedデータエンジニアリングを「raw dataを取り込み、高品質で一貫性のある情報を生成するシステムとプロセスの開発、実装、維持」と定義しています。データエンジニアは、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの交差点に位置し、データのソースシステムから始まり、分析や機械学習などのユースケースにデータを提供するまでのライフサイクル全体を管理します。Figure 1-1. The data engineering lifecycle よりまた、データエンジニアリングの歴史的な発展についても触れられており、データウェアハウジングから始まり、ビッグデータ時代を経て、現在はデータのライフサイクル全体を管理するフェーズに入っていることが分かります。データエンジニアは、データサイエンティストの上流に位置し、分析やモデリングに必要な基盤を提供する重要な役割を担っています。さらに、本章では、企業のデータ成熟度に応じたデータエンジニアの役割の変化や、他の技術的役割（ソフトウェアエンジニア、データアーキテクト、DevOpsエンジニアなど）およびビジネスリーダーとの関わりについても説明されています。データエンジニアは、技術的スキルだけでなく、コミュニケーション能力やビジネス理解も求められる、組織内の重要な接点となる存在であることが強調されています。本章を通じて、データエンジニアリングが急速に発展し、組織内で不可欠な役割を担うようになってきたことを実感しました。データドリブンな意思決定が求められる現代において、データエンジニアは、データの価値を最大限に引き出すための鍵を握っています。今後もデータエンジニアリングの動向に注目し、自身のスキルを磨いていく大切さを学びました。Chapter 2. The Data Engineering Lifecycleデータエンジニアリングのライフサイクルについて詳細に解説されています。データエンジニアリングのライフサイクルとは、raw dataを有用な最終製品に変換するための一連のプロセスを指します。本章では、データエンジニアリングのライフサイクルを5つのステージ（生成、ストレージ、取り込み、変換、提供）に分類し、各ステージの役割と考慮事項を丁寧に説明しています。また、ライフサイクル全体を支える重要な要素として、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの6つの「潮流」を紹介しています。特に印象的だったのは、データ管理の重要性についての議論です。著者らは、データガバナンス、データモデリング、データの系統、データ統合、ライフサイクル管理など、企業のデータ管理における様々なベストプラクティスを紹介し、これらがデータエンジニアリングにどのように関連するかを明確に示しています。データエンジニアは、単なる技術者ではなく、組織全体のデータ活用を戦略的に促進する役割を担っているのだと実感しました。また、DataOpsの概念も興味深かったです。DataOpsは、アジャイル開発、DevOps、統計的プロセス管理の手法をデータに適用したものであり、自動化、モニタリング、インシデント対応の3つの要素から成ります。データエンジニアリングにおいてDataOpsを実践することで、データ製品の迅速な開発と高品質な運用が可能になるとのことです。本章を通じて、データエンジニアリングが、単なるデータ処理の技術にとどまらず、組織のデータ活用を支える総合的な取り組みであることを学びました。データエンジニアは、ライフサイクルの各ステージにおける技術的な選択と、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項のバランスを取ることが求められます。本書で提示されたデータエンジニアリングのライフサイクルのフレームワークは、この複雑な領域を体系的に理解するための強力なツールになると感じました。Chapter 3. Designing Good Data Architectureデータエンジニアリングにおける良いアーキテクチャ設計について詳細に解説されています。本章では、まず、データアーキテクチャを「企業のデータニーズの進化を支えるシステムの設計であり、柔軟で可逆的な意思決定により、トレードオフを慎重に評価して達成されるもの」と定義しています。そして、良いデータアーキテクチャの原則として、共通コンポーネントの賢明な選択、障害への対策、スケーラビリティの確保、リーダーシップ、継続的なアーキテクト活動、疎結合システムの構築、可逆的な意思決定、セキュリティの優先、FinOpsの採用の9つを挙げています。また、本章では、分散システム、スケーラビリティ、障害対策、密結合と疎結合、シングルテナントとマルチテナント、イベント駆動アーキテクチャ、ブラウンフィールドとグリーンフィールドプロジェクトなど、データアーキテクチャ設計に関連する主要な概念について説明しています。さらに、データウェアハウス、データレイク、モダンデータスタック、ラムダアーキテクチャ、カッパアーキテクチャ、IoTアーキテクチャ、データメッシュなど、具体的なデータアーキテクチャの例や種類についても紹介されています。これらの例を通じて、データエンジニアがビジネスの要件に合わせて適切なアーキテクチャを選択し、設計するための知見が提供されています。本章を読んで、データアーキテクチャ設計の重要性と複雑さを改めて認識しました。データエンジニアは、技術的な知識だけでなく、ビジネスの文脈を理解し、ステークホルダーとのコミュニケーションを通じて要件を把握する必要があります。そして、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項とのバランスを取りながら、柔軟で進化可能なアーキテクチャを設計していかなければなりません。この辺はソフトウェアアーキテクチャの基礎を思い出した。ソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal FordオライリージャパンAmazon本書で提示された良いデータアーキテクチャの原則や、様々なアーキテクチャパターンの知識は、この難しい課題に取り組むための強力な助けになると感じました。データエンジニアとして、これらの知見を活かし、組織のデータニーズに合ったアーキテクチャを設計していきたいと思います。詳細に知りたい場合には『データ指向アプリケーションデザイン』あたりを読むと良さそうデータ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin KleppmannオライリージャパンAmazonChapter 4. Choosing Technologies Across the Data Engineering Lifecycleデータエンジニアリングのライフサイクル全体にわたる適切な技術選択のための考え方と基準について詳細に説明されています。この章では、アーキテクチャが戦略的な設計であることに対し、ツールはその実現を目指す戦術的な選択肢であるという点が強調されています。 技術選択時に考慮すべき要素として、チームの規模と能力、市場投入までのスピード、相互運用性、コスト最適化とビジネス価値、技術トレンドの変化、デプロイ環境、ビルドかバイの選択、モノリシックかモジュール化か、サーバーレスかサーバーか、性能最適化などが挙げられています。あまりにも「ソフトウェアアーキテクチャの基礎」すぎてデータ基盤もソフトウェアアーキテクチャなのだと分からせをくらいました。加えて、クラウドのコスト効率とクラウドネイティブアーキテクチャのコスト最適化の重要性が説明されており、オンプレミス、クラウド、ハイブリッドクラウド、マルチクラウドなどの配置オプションとその特性についても詳述されています。オープンソースソフトウェア（コミュニティ型と商用型）とプロプライエタリーソフトウェアの選択、モノリシックとマイクロサービスアーキテクチャの比較、サーバーレスと従来型サーバーの検討など、具体的な技術選択のシナリオにおける検討が提示されています。技術選択の複雑さとその重要性を理解する上で、この章は大いに役立ちます。データの世界は常に進化しているため、最適な選択肢は状況に応じて変わります。適切なトレードオフを評価し、柔軟かつ可逆的な意思決定を行うことが重要です。この辺はソフトウェアアーキテクチャメトリクスみがあって良かった。ソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,João Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazonセキュリティ、データ管理、DataOps、オーケストレーションなどの現代のトレンドが技術選択に与える影響も大きいことが認識されています。これらを総合的に考慮し、ビジネス価値を最大化する技術スタックを構築することが、SREとしての責任であると捉えられます。本章で提供される原則とガイドラインは、DXの推進と共に増大する複雑な意思決定の指針となります。組織のニーズに沿いながら、これらの洞察を活用していくことが推奨されています。Part II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source Systems本章では、データエンジニアリングのライフサイクルの初期段階であるソースシステムにおけるデータの生成プロセスについての詳細な解説が展開されています。 ここで、データエンジニアがソースシステムからのデータの特性と生成プロセスを理解することの重要性が強調されており、これは非常に重要な点です。特に印象深かったのは、ソースシステムのオーナーやステークホルダーとの関係構築の必要性です。データエンジニアリングはチーム単独ではなく、関係者全員の協力が必須であり、上流システムで問題が生じた際に迅速な対応が可能な信頼関係の構築が不可欠です。データ品質の維持に関する言及もあり、これは特に重要です。ソースシステムの設計や運用に直接影響を与えることは困難かもしれませんが、期待されるデータ品質について上流チームと合意を形成し、定期的な品質チェックを行うことが必要です。これは、SREとしての役割とも重なる側面があります。セキュリティ、可用性、信頼性を考慮したソースシステムのアーキテクチャへの理解も、障害発生時に影響を最小限に抑え、迅速に復旧する設計を実現する上で重要です。さらに、データ管理、DataOps、オーケストレーションといったデータエンジニアリングの新しい動向とソースシステムとの関連性についても触れられており、これらの原則を上流工程に適用し、エンド・ツー・エンドでの高品質なデータパイプライン構築が目標です。リバースETLやイベントストリーミングプラットフォームの活用による、データエンジニアとソースシステムとの連携強化の可能性についての言及もあり、これはアプリケーション開発チームとのWin-Winの関係構築、及びユーザー向けデータ製品の共創へと繋がるでしょう。本章を通じて、SREとデータエンジニアの役割が密接に関連しており、両者の協力が不可欠であることが明確になりました。 上流から下流への一貫した高品質なデータフローを実現するためには、両分野の専門知識を統合し、継続的な改善を図る必要があります。得られた知見を活用し、開発チームと協力しながら、より堅牢なデータインフラを構築していくことが目指されています。Chapter 6. Storageデータエンジニアリングのライフサイクルにおけるストレージの重要性と、その設計・運用に関する考慮事項について詳しく解説されています。本章では、まず、ハードディスク、SSD、システムメモリなど、ストレージシステムを構成する基本的な要素について説明しています。データエンジニアは、これらの物理的ストレージコンポーネントの特性を理解することで、パフォーマンス、耐久性、コストのトレードオフを適切に評価できるようになります。次に、ファイルストレージ、ブロックストレージ、オブジェクトストレージ、ストリーミングストレージなど、主要なストレージシステムの種類と特徴を紹介しています。特に、クラウドにおけるオブジェクトストレージの重要性が強調されており、その柔軟性とスケーラビリティが、データレイクやクラウドデータウェアハウスの基盤となっていることが分かります。さらに、データウェアハウス、データレイク、データレイクハウス、データプラットフォームなど、データエンジニアリングで用いられる主要なストレージの抽象化についても言及されています。これらの抽象化は、ストレージシステムの上に構築され、データの取り込み、変換、提供といったライフサイクルの各段階をサポートします。本章では、ストレージに関する重要なトレンドや考え方についても触れられています。例えば、コンピュートとストレージの分離、ゼロコピークローニング、データカタログ、データ共有などは、現代のデータアーキテクチャにおいて欠かせない要素だと指摘されています。また、データのライフサイクルと保持期間の管理、シングルテナントとマルチテナントのストレージ設計の違いなど、運用面での考慮事項についても説明されています。データエンジニアは、これらの要素を総合的に判断し、組織のニーズに合ったストレージ戦略を立てる必要があります。本章を通じて、ストレージがデータエンジニアリングのあらゆる段階で重要な役割を果たしていることを再認識しました。生のデータを価値あるインサイトに変えるためには、適切なストレージの選択と設計が不可欠です。また、セキュリティ、データ管理、DataOps、オーケストレーションなどの「潮流」を常に意識しながら、ストレージシステムを進化させていく必要があります。本書で得られた知見を活かし、自社のデータアーキテクチャにおけるストレージの最適化に取り組んでいきたいと思います。特に、コストとパフォーマンスのバランスを取りつつ、将来の拡張性も考慮した設計を心がけたいと考えています。ストレージの話は『パタ&へネ』などを読むとしっかりと分かるので読み直す機会があれば読み返したい。しかし、人生の時間は有限なので悲しい。コンピュータの構成と設計　MIPS Edition　第6版　上作者:David Patterson,John Hennessy日経BPAmazonコンピュータの構成と設計 MIPS Editoin 第6版 下作者:David Patterson,John Hennessy日経BPAmazonChapter 7. Ingestionデータエンジニアリングにおけるデータ取り込みの重要性と複雑さを再認識しました。本章では、データ取り込みを「データを一つの場所から別の場所へ移動するプロセス」と定義しています。その主要な考慮事項として、ユースケース、再利用性、データ量、データフォーマット、データ品質などが挙げられています。さらに、バッチ処理とストリーミング処理の違い、同期型と非同期型のデータ取り込み、シリアル化とデシリアル化、スループットとスケーラビリティといった、設計上の重要な概念について詳しく説明されています。また、Otelなどのオブザーバビリティ情報の取得については言及されていないのですが、この章を通じて現代の監視基盤が実際にはデータエンジニアリングに大きく依存してるものなのだと思いはじめました。特に印象的だったのは、データ取り込みの方法の多様性です。データベースへの直接接続、CDC、API、メッセージキュー、ファイルエクスポートなど、様々な手段があり、それぞれにメリットとデメリットがあります。状況に応じて適切な方法を選択し、組み合わせることが求められます。また、データ取り込みにおけるデータ品質の確保の重要性も強調されていました。スキーマの変更や遅延データへの対応、エラーハンドリングなど、様々な課題に直面します。上流のシステムとの緊密なコミュニケーションと、ロバストなモニタリングの仕組みが不可欠だと感じました。本章では、データ取り込みに関わる様々なステークホルダーとの協力についても言及されています。特にソフトウェアエンジニアとのコラボレーションは、データ品質の向上と、よりリアルタイムなデータ活用につながる可能性があります。組織のサイロを超えて、Win-Winの関係を築いていくことが重要だと分かりました。さらに、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、データ取り込みにどのように影響するかについても議論されていました。これらの原則を常に意識しながら、エンドツーエンドのデータパイプラインを設計していく必要があります。データ取り込みは、地味な作業に見えるかもしれません。しかし、それは分析やMLなどのエキサイティングなアプリケーションを支える重要な基盤です。本章で得られた知見を活かし、より信頼性が高く、価値あるデータを提供できるよう、日々精進していきたいと思います。Chapter 8. Queries, Modeling, and Transformationデータエンジニアリングにおけるクエリ、モデリング、変換の重要性と技術的な考慮事項について理解を深めることができました。本章では、まず、クエリの仕組みと最適化の手法について解説されています。クエリオプティマイザの役割や、結合戦略の最適化、説明プランの活用など、パフォーマンス向上のための具体的なアドバイスが提示されており、大変参考になりました。また、ストリーミングデータに対するクエリの特殊性についても言及されていました。次に、データモデリングの重要性と主要な手法が紹介されています。概念モデル、論理モデル、物理モデルの違いや、正規化、スター・スキーマ、Data Vaultなどのバッチデータのモデリング手法、ストリーミングデータのモデリングの考え方など、幅広いトピックがカバーされています。ビジネスロジックをデータモデルに反映させることの重要性が強調されていました。そして、変換の役割と主要なパターンについて解説されています。単純なクエリとは異なり、変換では結果を永続化し、ダウンストリームで利用できるようにすることが目的だと説明されています。バッチ処理とストリーミング処理それぞれの変換パターンや、更新パターン、データラングリングなどの具体的な手法が紹介されていました。また、マテリアライズドビュー、フェデレーションクエリ、データ仮想化など、クエリ結果を仮想的なテーブルとして提示する手法についても言及されていました。これらの手法は、複雑なデータパイプラインの一部として活用できる可能性があります。本章では、クエリ、モデリング、変換に関わる様々なステークホルダーとの協力についても議論されています。ビジネスロジックを理解し、上流のシステムへの影響を最小限に抑えつつ、下流のユーザーにとって価値のあるデータを提供することが求められます。また、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、この段階でも重要な役割を果たすことが指摘されていました。データ変換は、データパイプラインの中核をなす工程です。単に最新の技術を追求するのではなく、ステークホルダーにとっての価値を常に意識することが重要だと感じました。本章で得られた知見を活かし、ビジネスの目標達成に貢献できるデータ変換プロセスを設計していきたいと思います。Chapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETL本章では、データエンジニアリングのライフサイクルの最終段階である、データの提供について解説されていた。データエンジニアが直面する主要な3つのユースケース - 分析、機械学習、リバースETLについて、どのようにデータを提供するかが述べられていた。データを提供する際の重要な考慮点として、エンドユーザーがデータを信頼できるようにすることが何より大切だと強調されていた。データへの信頼がないと、いくら高度なアーキテクチャやシステムを構築しても意味がない。信頼を得るためには、データの検証とオブザーバビリティのプロセスを活用し、ステークホルダーと協力してデータの有効性を確認する必要がある。また、ユースケースとユーザーを理解し、提供するデータプロダクトを明確にし、セルフサービスかどうかを検討し、データの定義やロジックを確立することが重要だと述べられている。データメッシュのコンセプトにも触れられ、データ提供の方法が大きく変化しつつあることがわかった。分析や機械学習のためのデータ提供方法としては、ファイル、データベース、クエリエンジン、データ共有などがあげられていた。セマンティック層やメトリクス層の活用も有効とのことだった。また、ノートブックを使ったデータサイエンスのワークフローについても解説があり参考になった。リバースETLは、処理されたデータをOLAPシステムからソースシステムにロードすることだが、フィードバックループを作り出すリスクがあるので注意が必要だと指摘されていた。本章を読んで、データ提供において信頼性とセキュリティが非常に重要であり、様々な方法や最新のトレンドを理解しておく必要性を感じた。生のデータを渡すのではなく、匿名化などの工夫も必要だ。データプロダクトを通じてビジネスに貢献するという視点を常に持ちながら、品質の高いデータを提供できるよう、日々研鑽していきたい。Part III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and Privacyセキュリティとプライバシーは、データエンジニアリングにおいて非常に重要な側面であり、後回しにしてはならないということが本章で強調されていました。データ漏洩や流出は、企業に壊滅的な結果をもたらす可能性があります。GDPR、FERPA、HIPAAなど、データプライバシーに関する法的要件が増えており、違反すると多額の罰金が科せられる可能性があります。データエンジニアは、このような法規制を理解し、遵守する必要があります。セキュリティの最大の弱点は人間であるため、データエンジニアは常に防御的な姿勢で行動し、認証情報の扱いには細心の注意を払い、倫理的な懸念があれば提起しなければなりません。セキュリティプロセスはシンプルで習慣的なものでなければならず、単なるコンプライアンスのためのセキュリティ・シアターであってはいけません。最小権限の原則を適用し、必要最小限のアクセス権のみを付与すべきです。きめ細かいアクセス制御を実装することが重要です。クラウドにおけるセキュリティは、プロバイダーとユーザーの共同責任であり、ユーザー側の設定ミスが原因で流出が起こることが多いのです。定期的なデータバックアップは、災害復旧やランサムウェア対策に欠かせません。リストアのテストも定期的に行うべきでしょう。技術面では、脆弱性を修正するためのシステムのパッチ適用と更新、保存中と通信中の両方でのデータの暗号化、アクセス・リソース・コストのログ記録・監視・アラート、ネットワークアクセスの厳重な制御、CPUなどの低レベルでのセキュリティ考慮などが重要な実践項目として挙げられていました。すべてのエンジニアが自分の領域で潜在的なセキュリティ問題を探し出すという能動的な姿勢が重要であり、軽減策を積極的に展開すべきだと述べられています。本章を通して、セキュリティとプライバシーは企業文化・プロセス・技術のすみずみまで浸透させる必要があり、関係者全員が常に警戒心を持ち、積極的な対策を講じることが機密データ資産を守るために不可欠だということを実感しました。法的にも評判的にも、その重要性は非常に高いのです。データエンジニアとして、**セキュリティとプライバシーを常に最優先事項と位置づけ、ベストプラクティスを実践していきます。Chapter 11. The Future of Data Engineering本章では、データエンジニアリングの将来について著者の考察が述べられていました。データエンジニアリングの分野は急速に変化しているため、本書の執筆は挑戦的な作業だったと思います。しかし、変化の中にも不変の本質を見出し、ライフサイクルという形で体系化したことは意義深いと感じました。著者は、データエンジニアリングのライフサイクルは今後も変わらず重要であり続けると予測しています。一方で、ツールの簡素化が進み、より高度な作業にフォーカスできるようになるでしょう。クラウドスケールの「データOS」の出現によって、相互運用性が向上することも期待されます。また、従来の「モダンデータスタック」を超えて、リアルタイムのデータ処理と機械学習を融合させた「ライブデータスタック」へと進化するとの展望も示されていました。ストリーミングパイプラインとリアルタイム分析データベースの発展によって、アプリケーションとデータ、機械学習の間のフィードバックループが短くなり、より洗練されたユーザー体験が実現するというビジョンは興味深いです。一方で意外だったのは、スプレッドシートの重要性への言及でした。確かに、現場ではExcelが分析ツールとして依然大きな役割を果たしています。クラウドのOLAPシステムとスプレッドシートの使い勝手を兼ね備えた新しいツールの登場にも注目したいと思います。全体を通して、技術トレンドは複雑な技術と文化の相互作用の中で生まれるものであり、予測は難しいというのが著者の率直な見解だと感じました。私たち一人一人がデータエンジニアリングの発展に関わっていく中で、ツールの採用と活用を通じて、ビジネス価値の創出という大きな目標を見失わないようにしたいと思います。本書で得た知見をもとに、コミュニティに参加し、専門家と対話しながら、自分なりの探求を続けていきたいと思います。データエンジニアリングは奥深く、やりがいのある分野だと改めて感じました。さいごにこの本を通じて、私はデータエンジニアリングの幅広さと深さを理解する機会を得ました。『Fundamentals of Data Engineering』は、データエンジニアリングの基礎から応用に至るまで、その様々な側面を包括的に解説しており、データエンジニアとしての技術や知識の向上に寄与する貴重なリソースです。データライフサイクルの各段階に対する詳細な説明は、実務で直面するさまざまな問題への理解を深めるのに非常に有用です。また、セキュリティとプライバシーの章では、技術の理解だけでなく、倫理的な視点から物事を考えることの重要性が強調されていることが特に印象的でした。データエンジニアは技術者であると同時に、データを取り扱う上での社会的責任を有する存在であり、この点を再確認させられます。データエンジニアリングの将来に関する展望を含めて、この書籍は、データエンジニアリングの現状理解と将来に向けた方向性を示す貴重な指南書です。技術の進歩は早く、今日学んだことが明日には旧式になる可能性がありますが、本書で得られる原則や考え方は、変わることのない有用な知識。データエンジニアリングの基盤となります。syu-m-5151.hatenablog.com最後に、この本を読むことで得られる最大の利点は、データエンジニアリングに対する深い理解と共に、学び続け、成長し続けることの重要性を再認識できることです。技術変遷に適応しつつ、データエンジニアリングの核心を見失わないよう努めることが、私たちには求められています。この旅は続きますが、『Fundamentals of Data Engineering』は、その道中で頼りになる羅針盤となるでしょう。日本語訳の出版が待ち遠しいですね。そして、付録「A. Serialization And Compression Technical Details」と「B. Cloud Networking」に関しては、ぜひ自身で読んでみていただきたいです。これらのセクションは、データエンジニアリングの深い理解に不可欠なテクニカルな洞察を提供しており、実務での適用に役立つ知見が満載です。Fundamentals of Data Engineering (English Edition)作者:Reis, Joe,Housley, MattO'Reilly MediaAmazon(追記)翻訳版のリリースが出ました。翻訳作業お疲れ様でした。データエンジニアリングの基礎 ―データプロジェクトで失敗しないために作者:Joe Reis,Matt Housleyオーム社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/20/164434","isoDate":"2024-03-20T07:44:34.000Z","dateMiliSeconds":1710920674000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Docker Desktop のアンインストールと Lima の導入","contentSnippet":"はじめにDocker Desktop は多くの開発者にとって便利なツールですが、さまざまな理由で Lima への移行を検討するケースもあります。この記事では、MAC でDocker Desktop をアンインストールし、Lima を導入する過程を説明します。Limaはcontainerd を実行するための Linux 仮想マシン (通常は macOS 上) 、2022 年 9 月 14 日にサンドボックス成熟度レベルで CNCF に承認されてます。参考文献LimaInstallation | LimaUsage | LimaDocker Desktop のアンインストールDocker Desktop のアンインストールは、公式ドキュメントの指示に従って行うことができます。アンインストールはシステムの設定やリソースの解放に役立ち、Lima の導入の準備を整えます。# CLI から Docker Desktop をアンインストールすることもできます。さようなら。/Applications/Docker.app/Contents/MacOS/uninstall# Docker Desktop をアンインストールした後、削除できるファイルがいくつか残るので合わせて削除rm -rf ~/Library/Group\\ Containers/group.com.dockerrm -rf ~/Library/Containers/com.docker.dockerrm -rf ~/.docker参照: Docker Desktop アンインストール方法Lima のインストールLima は、macOS で Linux 仮想マシンを容易に管理するためのツールです。Docker コンテナの実行環境として Lima を使用することで、Docker Desktop と同等の機能を低リソースで利用できます。Lima のインストールプロセスは以下のコマンドで行います。# Lima インスタンスの作成:# `docker` という名前の Lima インスタンスを Docker のテンプレートを使って作成します。limactl create --name=docker template://docker# Lima インスタンスの起動:# 作成した `docker` インスタンスを起動します。limactl start docker# 稼働中の Lima インスタンスの一覧表示:# 現在稼働中の Lima インスタンスの状態を表示します。limactl lsNAME       STATUS     SSH                VMTYPE    ARCH       CPUS    MEMORY    DISK      DIRdocker     Running    127.0.0.1:65015    qemu      aarch64    4       4GiB      100GiB    ~/.lima/dockerDocker CLI のインストールLima がインストールされた後、Docker コマンドラインインターフェース (CLI) をインストールする必要があります。以下のコマンドを使用して、macOS 用の Docker CLI をダウンロードし、インストールします。今回はdocker-25.0.4.tgzをダウンロードしますがこちらを参考に最新版をinstallしてください。# Docker CLI バイナリのダウンロード:# macOS 用の Docker CLI バイナリをダウンロードします。curl -L -O https://download.docker.com/mac/static/stable/aarch64/docker-25.0.4.tgz# ダウンロードしたアーカイブの展開:# ダウンロードした tar.gz アーカイブを展開します。# 毎回、調べているので悲しいtar -xvzf docker-25.0.4.tgz# Docker CLI の移動:# 展開した Docker CLI をシステムの PATH の一部である /usr/local/bin に移動します。パスはどこでもいいけどブログなので...。mv docker/docker /usr/local/bin/参照: macOS でのクライアントバイナリのインストール修正: brew install でのdockerのインストール勝手に--caskとか付けて全部入るなーって思っていたのですがbrew install dockerのみの場合にはDocker CLIのみをインストールすることができますbrew install docker我らがteraoka 師匠から教えていただきました。参照: Lima で vz + rosetta を使って ARM VM 上で x86_64 バイナリを実行する #Docker - QiitaLima-Docker の設定Lima と Docker CLI がセットアップされたら、Lima ベースの Docker 環境を利用するための設定を行います。以下のコマンドで Docker コンテキストを作成し、利用を開始します。# Docker コンテキストの作成:# `lima-docker` という名前の Docker コンテキストを作成し、Lima インスタンス上の Docker デーモンに接続します。docker context create lima-docker --docker \"host=unix:///Users/<username>/.lima/docker/sock/docker.sock\"# 作成した Docker コンテキストの使用:# `lima-docker` コンテキストをアクティブにして、以降の `docker` コマンドが Lima インスタンスを対象に実行されるようにします。docker context use lima-docker# Docker コンテナの実行 (テスト):# Docker 環境が正しく設定されているかを確認するため、hello-world イメージを実行します。docker run hello-world# Docker での nginx コンテナの実行:# nginx イメージをバックグラウンドで実行し、ポート 8181 をコンテナのポート 80 にフォワードします。docker run --name lima-test-nginx -d -p 8181:80 nginxこれらのステップを完了することで、Lima 上で Docker コンテナを実行し、管理することができるようになります。おまけ:KIND (Kubernetes IN Docker) の利用KIND (Kubernetes IN Docker) は、Docker 上に軽量な Kubernetes クラスタを構築するためのツールです。Lima 環境上で Docker を利用している場合でも、KIND を使用して Kubernetes のテスト環境を簡単にセットアップできます。# KIND クラスタの作成:# 新しい Kubernetes クラスタを作成します。このクラスタは Docker コンテナ内に構築されます。$ kind create cluster# 作成されたクラスタの一覧表示:# 現在 KIND によって作成されたクラスタの一覧を表示します。$ kind get clusterskind# クラスタ情報の取得:# 作成した KIND クラスタのコントロールプレーンやサービスの情報を取得します。$ kubectl cluster-info --context kind-kindKubernetes control plane is running at https://127.0.0.1:51050CoreDNS is running at https://127.0.0.1:51050/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.# 全てのネームスペースで動作している Pod の一覧表示:# クラスタ内の全ネームスペースにわたる Pod の状態を確認します。$ kubectl get pod -ANAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGEkube-system          coredns-76f75df574-5glm8                     1/1     Running   0          87skube-system          coredns-76f75df574-jwn6z                     1/1     Running   0          87skube-system          etcd-kind-control-plane                      1/1     Running   0          103skube-system          kindnet-qlftc                                1/1     Running   0          86skube-system          kube-apiserver-kind-control-plane            1/1     Running   0          102skube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          100skube-system          kube-proxy-6nwnv                             1/1     Running   0          86skube-system          kube-scheduler-kind-control-plane            1/1     Running   0          100slocal-path-storage   local-path-provisioner-7577fdbbfb-vd28d      1/1     Running   0          87sおわり。結論Docker Desktop のアンインストールと Lima の導入に焦点を当てました。本記事で紹介した手順を通じて、開発環境を効率的に管理し、Docker コンテナの実行を最適化することが可能です。参考文献Docker Desktop アンインストール方法macOS でのクライアントバイナリのインストール","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/14/083605","isoDate":"2024-03-13T23:36:05.000Z","dateMiliSeconds":1710372965000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。","contentSnippet":"問題を解決する能力は確かに重要ですが、それ以上に、何が本当に重要な問題なのかを見極め、それを明確に設定する能力が不可欠です。問いを適切に定義できなければ、どんなに高度な解決技術を持っていても、その力は十分に発揮されません。また、誰にとって適切な問いなのかも考える必要があります。問題解決の過程において、問題そのものの本質を正確に把握し、適切な問いを立てることは重要です。イシューからはじめよ――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazon概要SREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜にて「書を捨てよ、現場へ出よう - このSRE本がすごい！2024年 LT版」 というテーマで登壇しました。のイベントは2024年1月末に注目を集めた『このSRE本がすごい！2024年版』をテーマにしたもので、多くの参加者とパネルディスカッションのスピーカーであるTopotal のnari_exさん、kenta_hiさんと共に、その内容を深掘りして議論することができ、イベントも無事成功し、大変充実した時間を過ごすことができました。findy.connpass.comイベントを引き起こしたきっかけとなったツイートは以下のものです。この経験から、積極的に意見を発信することの大切さを実感しました。時には思いがけない展開をもたらすこともあるなぁって思いました(小並)。モチベーションになるのでブログの読者登録おねがいします。強い下心を持っているため、Findyさんなどからこれらの本に関する解説をする勉強会の依頼が来ることを期待しています。 https://t.co/amL2de5qFI— nwiizo (@nwiizo) 2024年1月31日   資料この資料は思いの外、感情的な要素が強くエンジニアなのに技術の話を全くしないポエムっぽさが反映されてしまいました。当初は技術的な内容と本の紹介を避ける方針でしたが、認知科学のような専門分野に深く踏み込む知識は持ち合わせていないため、このような方向性になってしまいました。それにもかかわらず、受け取り手からはそこそこに好評を得られたことが非常に嬉しく思います。 speakerdeck.comXでのポストはこちらです。内省の話運用技術者組織の設計と運用 / Design and operation of operational engineer organizationを読んで勝手に憧れていたnari_exさんとのイベントでそのnari_exさんから内省の大切さの話が出てきていた。明日の朝から読んでみようと思う。リフレクション（REFLECTION） 自分とチームの成長を加速させる内省の技術 (オリジナルフレームワークPPT・PDF特典付き)作者:熊平美香ディスカヴァー・トゥエンティワンAmazon読書とは、能力、知識ではなく 問いを獲得するための行為資料を作る前のアウトラインと文章をブログでも公開しておきます。このような内容が気になった方は参考文献を読んでいただければと思います。能力のイメージ能力の抽象性と具体化の必要性日常生活において、私たちは「コミュニケーション能力」、「問題解決能力」、「技術力」などの様々な「能力」について語ります。これらは教育や仕事、プライベートにわたって使われますが、深く考えると、これらの「能力」が具体的に指すものは何か、どう解釈すべきか疑問が生じます。能力に関する理解を深めるには、背後にある原因や要素、その行動や成果への影響を分析することが不可欠です。能力という概念は抽象的であるがゆえに、その実態を把握するには具体的な文脈における観察と分析が欠かせません。能力解釈におけるメタファーの限界と可能性能力の解釈は、しばしばメタファーを通じて行われます。「力」という言葉自体が、物理的な力や潜在的な特性を想起させます。しかし、これらのメタファーは、能力が一貫して同じ効果をもたらすという誤解を生むことがあります。例えば、「コミュニケーション能力」を「言葉の力」と表現することで、言葉さえ巧みに使えば常に良好なコミュニケーションが取れるという誤った印象を与えかねません。能力についての理解を深めるには、メタファーが示すイメージを超えて、実際の文脈での能力の現れ方を丁寧に探ることが重要です。メタファーは理解の出発点としては有用ですが、それに留まらず、具体的な事例や経験から能力の本質を捉えていく必要があります。能力は文脈依存で時と場合次第能力の文脈依存性人間の能力は、状況に応じて異なる形で表れます。ある特定の文脈において顕著な能力が発揮される一方で、他の状況ではまったく異なる影響を持つかもしれません。例えば、プレゼンテーションの場で優れたコミュニケーション能力を発揮する人物が、親密な人間関係の中では十分にその能力を活かせないということもあり得ます。この文脈依存性は、能力が単純な属性ではなく、状況や環境、それに伴う要求に対する応答の結果として理解すべきであることを示唆しています。つまり、能力とは、特定の文脈において、その状況に適した行動を取ることができる力なのです。文脈に応じた問いの形成問いは、私たちが直面する特定の文脈における能力の発揮や理解を深めるのに重要な役割を果たします。そのため、問いは文脈に応じて形成される必要があります。適切な問いを立てることで、その状況における最適な行動や能力の発展につながります。例えば、プレゼンテーションの場面では、「どのようにすれば聴衆の関心を引き付けられるか」、「効果的な情報伝達のために何が必要か」といった問いが重要になります。一方、親密な人間関係の中では、「相手の感情を適切に理解するにはどうすればよいか」、「信頼関係を築くために何ができるか」といった問いが求められます。能力を最大限に活かすためには、その能力をどのように、いつ、どのような状況で使うべきかを考える問いが不可欠なのです。知識の非伝達性と構成主義知識の非伝達性多くの人々は、知識や技能が他者から伝達できるものだと考えがちです。しかし、実際には、知識は伝達されるのではなく、各個人が自身の経験や環境から創発するものなのです。教育や読書を通じて提供されるのは情報のみであり、それを個人が内面化し、自らの知識として再構築するプロセスが必要不可欠です。つまり、知識は受け取るものではなく、自ら作り上げていくものなのです。この視点は、知識獲得を受動的な受け入れではなく、能動的な創造過程として捉えるべきであることを示唆しています。知識の構成主義知識は個人の認知的リソースと環境から提供される情報を結合させて創発されます。このプロセスでは、経験や環境からの情報を基に、個人が能動的に知識を構築します。構成主義の視点から、知識は静的なものではなく、個々の経験や文脈に応じて動的に形成されると捉えられます。これは、知識を単に受け入れるだけでなく、自分自身の行動や内省を通じて深める過程です。知識の構成主義は、学習者の能動性と主体性を重視し、知識の個人的な意味づけを重要視する立場だと言えます。知識の応用と実践道を知っていることと実際に歩くことは違う理論から実践への移行は知識の本質的な価値を明らかにします。教室や書籍で得た知識が、実際の体験や応用を経て深化し、真に生きた知識へと変わります。このプロセスは、抽象的な概念を具体的な行動や体験に結び付け、それによって得られる新しい理解や洞察がさらなる学びのモチベーションを高めます。知識から行動への変換知識を実際の行動に転換することは、それを社会や日常生活に応用し、問題解決や創造的な活動に活かすプロセスです。この実践を通じて、知識は単なる情報の蓄積を超え、個人の体験と統合され、生きたものへと変化します。実践から得られる新たな体験は、知識の内面化を促し、持続可能な知的成長の重要な要因となります。知識と行動の相互作用は、知的な営みの本質であり、知識の実践的な価値を示すものだと言えるでしょう。プログラミング言語の文法や設計パターンを学んだだけでは、実際のソフトウェア開発で成功することは難しいでしょう。理論を実践に活かし、試行錯誤を重ねることで、本当に生きたプログラミングスキルが身につくのです。知っているだけでは不十分で、実際にコードを書き、動かしてみて、時間が経って発生する問題を観測することが重要なのです。読書は、見えなかったものを見えるようにすること問いの形成と知識の活用適切な問いを立てることは、文脈に依存する能力の理解と、個々に構成される知識の活用を促進します。問いは、特定の状況で何が必要であり、どのように行動すべきかを明らかにし、その過程で深い知識の構築と適用が可能になります。読書は、私たちの内面に新たな問いを生み出し、その問いを深めるための知識を提供してくれます。読書と問いの形成は、知識の活用と探究を促す相補的な営みなのです。問いに基づく学習の進展問いは、学習過程において重要な役割を果たします。それにより、私たちは受動的な知識の受け手から、能動的な学習者へと変化し、知識をより深く、文脈に応じて理解し、活用する能力を高めます。これは、個人の成長と発展にとって不可欠なプロセスです。読書は、問いを生み出し、その問いに答えるための知識を与えてくれる営みです。読書と問いに基づく学習は、知的な探究心を育み、生涯にわたる学びの基盤となるのです。問いを深める読書と知的好奇心の拡大読書は、単なる知識の蓄積以上に、私たちの内面的な問いを掘り下げ、それらを広げる活動です。異なる分野や視点からの本を読むことで、従来の枠組みを超えた新しい問いが生まれ、これが知的好奇心を刺激し、さらなる探究へと促します。こうしたプロセスは、私たちの知的な地平を拡げ、より複雑な問題に対する洞察力を高めます。読書の継続と習慣化読書を継続的に行うことは、知識の深化と問いの発展に不可欠です。習慣としての読書は、長期的に見て自己成長を促し、知識をより深く理解し活用する能力を養います。習慣化による読書は、日々の小さな努力を積み重ねることで、大きな学びへと繋がる基礎を築きます。読書習慣は、知的な探究心を持続させ、生涯学習の基盤を形成する上で欠かせない要素だと言えるでしょう。さいごに能力と知識と実践の相互関係能力と知識は、読書を通じて理解し、実践に活かすことができます。読書は、能力の文脈依存性と知識の非伝達性に光を当て、私たちを新たな理解へと導きます。実践を通じて得られる経験は、学んだことを確かなものにし、問いを通じてさらに深い洞察を得ることができます。能力と知識、そして実践は、相互に影響を与え合い、螺旋状に発展していくのです。これらの要素の有機的な結びつきが、私たちの知的成長を支える基盤となります。知識を深めるための継続の意義継続は、知識を蓄積し、それを活用するうえでの基礎を築きます。読書の習慣は、日々の積み重ねによって、知識を内面化し、問いを深め、思考を拡張する重要なプロセスです。知識を深め、問いを追求し続けることで、私たちは自己の成長と進化を遂げることができます。継続的な読書と学びは、私たちを知的な探究者へと導く、生涯にわたる営みなのです。それは、私たちの内なる知的世界を豊かにし、より深い理解と洞察へと導いてくれるでしょう。参考資料学びとは何か――〈探究人〉になるために (岩波新書) 言語の本質-ことばはどう生まれ、進化したかジェームズ・クリアー式 複利で伸びる1つの習慣私たちはどう学んでいるのか　─創発から見る認知の変化達人プログラマー(第2版): 熟達に向けたあなたの旅プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ","link":"https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","isoDate":"2024-03-13T07:49:51.000Z","dateMiliSeconds":1710316191000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"書を捨てよ、現場へ出よう","contentSnippet":"書を捨てよ、現場へ出よう このSRE本がすごい！2024年 LT版というタイトルで登壇してきました。\r\rSREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜\rhttps://findy.connpass.com/event/311323/\r\r元ブログはこちら\r\rこのSRE本がすごい！2024年版\rhttps://syu-m-5151.hatenablog.com/entry/2024/01/26/165255\r\r登壇ブログはこちら\r\r『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","link":"https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you","isoDate":"2024-03-12T04:00:00.000Z","dateMiliSeconds":1710216000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"私のメンターがくれた初めてのターミナル管理、それはtmuxで私は新卒でした。","contentSnippet":"はじめに2024年2月5日夜の東京 外は雪が降っている。tmuxとの出会いは、新卒としての初めての職場でした。メンターがターミナルの管理において最初に紹介してくれたのがtmuxで、この出会いが私の開発効率と作業環境を大きく変革しました。tmuxの基礎を学んだ後、私は自分の開発環境をさらにカスタマイズし、tmuxを日々の作業効率化のために積極的に使い始めました。ここでは、私が実際に使っているtmuxの設定と、日常的に使うコマンドを紹介します。これらは、より快適なターミナル操作環境を実現するために役立ちます。この過程で、tmuxはただのツール以上のものになり、私の開発作業における最適なパートナーになりました。tmuxを使いこなすことで、複数のプロジェクトを同時に管理する能力が向上し、長時間の作業も中断せずに続けられるようになりました。リモートワークが増えた今では、tmuxのセッション管理機能が特に役立っています。サーバーに接続した状態で作業を行い、一時的に他のタスクに切り替えても、再びtmuxセッションに戻れば瞬時に作業を再開できます。tmuxを通じて、私はターミナル操作に関してプロフェッショナルな開発者としての成長していると実感しています。あとやっている感がとても出ているので好きです。tmuxとはtmuxは「ターミナルマルチプレクサ（Terminal Multiplexer）」の略称で、Linux系OSを中心に利用されています。このツールを使うと、一つのターミナルウィンドウ内で複数のセッション、ウィンドウ、ペインを効率的に管理することが可能になります。github.comセッションの管理： 一つのターミナルで複数のセッションを持ち、それぞれ独立した作業スペースとして利用できます。仕事とプライベート、複数のプロジェクト間でセッションを分けることができるため、タスクの切り替えがスムーズになります。ウィンドウとペイン： 一つのセッション内で、複数のウィンドウを開くことができ、さらにウィンドウをペインと呼ばれる小分けにすることが可能です。これにより、同一画面内で複数の作業を並行して行うことができ、効率的なマルチタスクが実現します。セッションの維持： tmuxの最大の特徴の一つは、ターミナルを終了してもセッションが維持されることです。これにより、長時間かかるコマンドを実行中にログアウトしてしまったり、接続が切れてしまったりしても、作業が中断される心配がありません。tmux設定のカスタマイズ私の.tmux.confファイルには、効率的なターミナル操作を可能にするための様々なカスタマイズが施されています。これらの設定を通じて、tmuxを自分にとって最適な作業環境に変えることができました。github.comプレフィックスキーの変更: デフォルト設定のCtrl+bをCtrl+qに変更しました。これは、より操作性の良いキーバインドに変更することで、他のショートカットキーとの競合を避け、操作のスムーズさを向上させるためです。キーバインドのカスタマイズ: vimを頻繁に使用することから、ペインの移動やリサイズをvim風に設定しています。これにより、キーボード操作の一貫性を保ちながら、直感的で迅速なウィンドウ管理を実現しています。ペインの分割: よく使用する|キーでペインを縦に分割し、-キーでペインを横に分割するように設定しました。これにより、柔軟かつ迅速に作業スペースをカスタマイズすることが可能になります。ステータスバーのカスタマイズ: ステータスバーには、現在のセッションの状態や時刻など、必要な情報を表示するよう設定しています。これにより、作業中に一目で状況を確認できるようになり、生産性の向上に貢献しています。プラグインの利用: tmux-resurrectやtmux-continuumなどのプラグインを導入しています。これらのプラグインは、セッションの自動保存や復元を可能にし、長時間にわたる作業や一時的な中断からのスムーズな再開を支援します。セッションの保存と復元は、プレフィックスキーに続けてCtrl+sで保存、Ctrl+rで復元することができます。これにより、突然のシステム停止や作業の中断が発生しても、簡単に前の状態に戻ることができます。さらに、tmuxのプラグインエコシステムは非常に豊富で、tmux-pluginsのリストからは、あらゆるニーズに応える特別なプラグインを見つけることができます。自分の作業フローに合わせて、最適なプラグインを選択し、tmux環境をさらにパワフルで柔軟なものにカスタマイズすることが可能です。よく利用するtmuxコマンドtmuxを効率的に使用するためには、日常的に役立つコマンドを知っておくことが重要です。ここでは、特に重宝するコマンドを紹介します。どんな時にでも味方になってくれるチートシートです。ちなみにチートシートには入れてないのですがprefix + e で全てのペインの操作、prefix + Eでそれらの解除などもインフラエンジニアとしては非常に重宝します。github.com以下は、日々の作業で特に役立つコマンドです。新規セッションの開始: tmux new -s <セッション名>コマンドで、特定の名前を持つ新規セッションを開始します。この機能を活用することで、プロジェクトやタスクごとにセッションを分け、作業を整理しやすくなります。セッションの一覧表示と切り替え: tmux lsコマンドで現在のセッション一覧を表示し、tmux attach -t <セッション名>またはtmux a -t <セッション名>で特定のセッションにアタッチします。これにより、複数のプロジェクトや作業を効率的に管理し、スムーズに切り替えることができます。ペインとウインドウの操作: tmuxでは、ペインの分割やウインドウの作成、移動、リサイズを柔軟に行うことができます。これらの操作をカスタマイズしたキーバインドで行うことで、必要に応じて作業スペースを自由に調整し、マルチタスク作業を効率的に進めることができます。マウス操作の有効化: set-option -g mouse onコマンドにより、tmux内でのマウス操作を有効にすることができます。マウスでペインを選択したり、サイズを調整したりすることが可能になり、キーボードとマウスを組み合わせた直感的な操作が実現します。これらのコマンドは、tmuxを使ってターミナル操作を効率化し、生産性を高めるための基本となります。tmuxをより深く理解し、活用することで、開発作業をより快適に、より効率的に行うことができるでしょう。さいごにtmuxとの出会いは、私の開発効率と作業環境を大きく変えただけでなく、インフラエンジニアとしての成長にも大きく寄与しました。日々の作業でtmuxを使いこなすことで、システムの監視、ログの分析、複数のサーバーへの同時操作など、インフラ管理の幅広いタスクを効率的にこなすスキルを身につけることができました。また、セッションの持続性は、長時間実行するプロセスの管理や、中断された作業の再開といった面で、インフラ作業の品質を向上させるのに役立ちました。tmuxのカスタマイズ性と拡張性を活かして、個人の作業環境を最適化することは、単に作業を効率化するだけではなく、技術者としての視野を広げ、問題解決能力を養う機会となりました。tmuxを深く理解し活用することで、インフラエンジニアリングの知識を実践的に拡張し、より複雑なシステムと効果的に向き合う力を養うことができました。tmux は3.4 がリリースされており今でも進化を続けている。愛している。github.comtmuxは、単なるツール以上の存在となり、私の技術的な成長を支えてくれる貴重なパートナーです。これからもtmuxを活用し続けることでしょう。しかし、人は変わる。実はZellijやターミナルもMAC標準なものを利用しているがAlacrittyが気になっているので検証と導入を進めている。","link":"https://syu-m-5151.hatenablog.com/entry/2024/02/06/110341","isoDate":"2024-02-06T02:03:41.000Z","dateMiliSeconds":1707185021000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"このSRE本がすごい！2024年版","contentSnippet":"はじめに有用な知識の特性Google SRE リソースSite Reliability Engineering: How Google Runs Production SystemsThe Site Reliability Workbook: Practical Ways to Implement SREBuilding Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining SystemsSLO Adoption and Usage in SRECreating a Production Launch PlanTraining Site Reliability Engineers: What Your Organization Needs to Create a Learning ProgramAnatomy of an Incident – Google – Site Reliability EngineeringEnterprise Roadmap to SRE – Google – Site Reliability EngineeringIncident Metrics in SRE – Google – Site Reliability EngineeringPractical Guide to Cloud Migration – Google – Site Reliability EngineeringGoogle以外の重要な書籍紹介97 Things Every SRE Should KnowSeeking SREPractical MonitoringDatabase Reliability EngineeringObservability EngineeringChaos EngineeringBuilding Microservices, 2nd EditionAPI Design PatternsSystems Performance, 2nd EditionEfficient GoImplementing Service Level ObjectivesModern Software Engineering: Doing What Works to Build Better Software FasterLearning Test-Driven Developmentシステム障害対応 実践ガイドWebエンジニアのための監視システム実装ガイドSRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本さいごにはじめに2024年、情報技術の世界は革新的な変化を続け、特にSRE（サイト信頼性エンジニアリング）の分野では新しい概念や技術が絶えず生まれています。この急速に進化する環境において、効率的に最新の知識を吸収する方法を見つけることは非常に重要です。その一つの答えが、「タイパ（タイムパフォーマンス）」という概念です。タイパとは、投入した時間に対する成果の効率を意味し、限られた時間を最大限に活用することの重要性を示しています。このブログでは、SRE分野で高いタイパを達成するための役立つ書籍を探求します。これらの書籍を全て読むのは、SREに深い情熱を持つ者か、非常に勤勉な人に限られるかもしれませんが、オススメの順番などはあえて紹介しません。また、「class SRE implements DevOps」は、「SREはDevOpsというインターフェースの実装である」という意味を持ちます。「DevOps = 思想」という定義に対して、それを具体化し実装したものがSREであると考えます。本ブログでは、DevOpsやその進化形であるPlatform Engineeringについては触れません。それは、既に多岐にわたる議論がある中で、さらに混迷を招く可能性があるためです。また、全ての情報は完璧ではないと思うので補足情報などがあれば教えてください。映画を早送りで観る人たち～ファスト映画・ネタバレ――コンテンツ消費の現在形～ (光文社新書)作者:稲田 豊史光文社Amazon有用な知識の特性有用な知識が持つべき三つの性質について考えます。第一に「一般性」です。これは知識が多様な状況で適用できることを意味します。例えば、コンテナ技術やクラウドインフラの原則は、異なるプラットフォームやアプリケーションでも適用可能です。これが一般性のある知識です。第二の性質は「関係性」です。孤立した知識はあまり役に立ちません。例えば、単に多くのモニタリングツールを知っているだけでは不十分で現場の課題を知っている必要があります。また、それらがシステムのパフォーマンスやセキュリティとどのように関連し、全体的な信頼性を向上させるかを理解することが重要です。最後に「場面応答性」があります。知識は、それが必要とされる特定の状況で適切に活用されるべきです。例えば、システムのスケーラビリティを改善する際には、負荷分散やキャッシングなどの特定の技術や知識が必要です。これらの技術や知識は、それぞれの状況に応じて適切に選択し、活用されるべきです。場面応答性がある知識は、適切な状況でのみその真価を発揮することができます。この有用な知識の枠組みに加えて、特に学生や新卒の方々には「基礎の重要性」を強調したいと思います。技術的な深い理解や幅広い応用は、コンピュータサイエンスの基本原理、アルゴリズム、データ構造などの基礎知識があってこそ可能です。SREやオブザーバビリティなどの先進的な分野への関心も良いことですが、その前にしっかりとした基礎を学び、築くことが非常に重要です。基礎知識がしっかりしていれば、新しい技術やトレンドにも柔軟に対応し、深く理解することができるでしょう。学びとは何か――〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店AmazonGoogle SRE リソースGoogleは、SRE（Site Reliability Engineering、サイト信頼性エンジニアリング）の知識と実践を業界全体で共有し、普及させるために積極的な取り組みを行っています。このページで紹介されている書籍やリソースはその一部に過ぎません。Google SREリソースとして、さらに多くの資料が公開されていますので、興味のある方は以下のリンクから探求してみてください。sre.googleSite Reliability Engineering: How Google Runs Production Systems「Site Reliability Engineering: How Google Runs Production Systems」は、Googleが開発したシステム管理とサービス運用の方法論を学ぶことができる、非常に重要なSREの書籍です。この書籍はO’Reillyから出版されており、全552ページにわたって豊富な内容が展開されています。発売日は2016年4月で、原書なのでリリースから時間が経過していますが、その内容の深さと実践的なアプローチは、今日でも多くのSRE専門家やソフトウェアエンジニアにとって非常に価値のあるものです。sre.googleこの書籍では、ソフトウェアのライフサイクル全体にわたるコミットメントと、世界最大規模のソフトウェアシステムの構築、導入、監視、維持方法について詳細に解説しています。リスク管理、サービスレベル目標、リリースエンジニアリングなどSREの基本原則から始まり、インシデント管理、障害の根本原因分析、SREチーム内でのソフトウェア開発についても深く掘り下げています。さらに、SREのトレーニングやコミュニケーション管理についても紹介しており、急速にスケールするサービスを高い信頼性で運用する方法についての理解を深めることができます。この書籍は、大規模なシステムの運用における複雑な課題への実践的な解決策を提供しており、非常に有益です。リリースエンジニアリングやインシデント管理の部分は特に、日常業務に直接応用できる知見が豊富に含まれており、実務においても大いに役立つ内容となっています。また、SREチーム内でのソフトウェア開発プロセスに関する記述は、チームワークと効率性を高めるための貴重で有用な参考資料となります。Googleによって無料で公開されていることも特筆すべき点で、こちらのリンクから無料で読むことが可能です。さらに、日本語での翻訳版も存在し、日本の読者にとっても2倍の感謝を持って読むことができるでしょう。SRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazonさらに、Googleに直接関連はありませんが「もう一度読むSRE」というポッドキャストもあり、この書籍の内容を深く理解するための補足資料として聞いてみるのも良いでしょう。ポッドキャストを通じて、書籍の内容をさらに掘り下げたり、実際の業務における適用例を聞くことができます。The Site Reliability Workbook: Practical Ways to Implement SRE「The Site Reliability Workbook: Practical Ways to Implement SRE」は、SREの原則と実践方法に深く踏み込んだ、O’Reillyから出版された812ページにも及ぶ充実した内容の書籍です。その分厚さは、まさに鈍器のよう。2018年7月の発売で、「Site Reliability Engineering: How Google Runs Production Systems」のリリースから3年が経過し、この期間を経てさらに充実した内容に進化しています。sre.googleこの書籍では、具体的な事例を通じてSREの原則と実践方法に深く踏み込んでいます。前作で紹介されたSREの基本原則からさらに一歩進み、Google内部で培われた技術的ノウハウだけでなく、Evernote、The Home Depot、New York Timesなどさまざまな企業の事例も紹介しています。クラウド環境での信頼性の高いサービス実行方法や、サービスレベル目標に基づくサービスの運用、既存の運用チームをSREに変換する方法など、実践的かつ詳細な解説がなされています。この書籍は、既にSREを導入している企業やこれから導入を考えている企業の開発者、運用管理者、マネージャーにとって、理論から実践へと移行するための貴重な手引きとなります。実際の業務に役立つ豊富な知識と具体的なガイドラインを提供しており、SREの実践を深めたいすべてのプロフェッショナルにとって有用な内容です。Googleによって無料で公開されていることも特筆すべき点で、こちらのリンクから無料で読むことが可能です。このような資料を無償で提供することは、業界全体の技術向上に大きく貢献しています。GoogleがSREの知識と実践を広く共有し、普及させようとする意図が明確に伺えます。さらに、日本語で翻訳されているため、日本の読者も2倍の感謝を持って読むことができるでしょう。サイトリライアビリティワークブック ―SREの実践方法オライリージャパンAmazonBuilding Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems「Building Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems」は、O’Reillyから出版された519ページに及ぶ内容で、セキュリティを中心に据えた構成となっています。2020年3月の発売で、聖典とも言える「Site Reliability Engineering: How Google Runs Production Systems」のリリースから4年が経過しており、この間にセキュリティ意識の高まりを強く感じさせる書籍です。google.github.ioこの書籍では、システムのセキュリティと信頼性が一体であることを明示し、スケーラブルなシステムの設計と運用におけるセキュリティの重要性を深く掘り下げています。GoogleのセキュリティとSREのエキスパートが、セキュアでスケーラブルかつ信頼性の高いシステムを根本から設計するためのベストプラクティスを紹介しており、システムの設計、実装、保守に関する考え方と実践法を詳しく解説しています。また、組織の文化がベストプラクティスに取り組む上でいかに重要かについても言及されています。この書籍はセキュリティと信頼性を軸にしたシステム構築のための貴重な知見を提供しています。特に、セキュリティをシステム設計の初期段階から考慮する重要性を説く内容は、現代のセキュリティ意識が高まる中でのシステム設計において非常に参考になります。また、組織文化とそのベストプラクティスへの適用に関する洞察は、チームや組織全体のセキュリティ意識向上に大いに役立つでしょう。「Building Secure and Reliable Systems」も、Googleによって無料で公開されており、こちらのリンクから無料で読むことが可能です。Googleがセキュリティと信頼性に関する知識を広く共有しようとする姿勢が、このような形で表れているのです。また、Google SRE本は3冊とも翻訳されていてありがたい限りですね！！！セキュアで信頼性のあるシステム構築 ―Google SREが考える安全なシステムの設計、実装、保守オーム社Amazonセキュリティに関する本の一環として、Googleとは直接関連はありませんが、『体系的に学ぶ 安全なWebアプリケーションの作り方 第2版 脆弱性が生まれる原理と対策の実践』の読書をお勧めします。この本では、Webアプリケーションのセキュリティにおける脆弱性の原理と対策について詳細に解説されています。SLO Adoption and Usage in SRE「SLO Adoption and Usage in SRE」は、サービスレベル目標（SLO）のSREにおける採用と使用に焦点を当てた104ページの実践的なレポートです。2020年4月1日に発売されたこのレポートは、SREのフレームワークを活用して運用コストの削減や開発生産性の向上に役立つ方法を提供します。SREやソフトウェアエンジニアとして、このレポートはSLOの重要性とその実践法を深く理解するのに大変役立ちます。SLO、SLI、エラーバジェットをSREの実践の中核として位置づけ、サービスの信頼性をどのように測定し管理するかを具体的に示しています。Googleの調査結果や実際のケーススタディを基に、許容可能な信頼性のレベルを定義し、それに基づいてシステム変更を適切に管理する方法は、日々の業務に直接適用できる知識です。参考リンク: SLO Adoption and Usage in SRESRE担当者、エグゼクティブ、開発者、アーキテクトなど、幅広い関係者にとって、SLOを取り入れたSREの実践を深めるための有用なリソースとなるでしょう。Creating a Production Launch Plan「Creating a Production Launch Plan」は、実稼働環境の立ち上げにおける計画策定に焦点を当てた45ページの実践的なレポートです。2020年1月に発売されたこのレポートは、製品のローンチプランをテンプレートとして使用することで、多くの時間、費用、そして頭痛を節約する方法を提供します。SREやソフトウェアエンジニアとして、このレポートは実稼働環境の立ち上げにおける計画策定の重要性と実践法を深く理解するのに非常に役立ちます。Googleが実際にどのように本番発売計画を策定したかを紹介し、自社製品を導入する際のリスクを低減するための実践的な方法を学べます。ローンチプランは、すべての関係者とプロセスを巻き込み、ローンチの進行を確実にコントロールすることで、さまざまな問題を防ぐことができます。参考リンク: Creating a Production Launch Plan開発者やサイト信頼性エンジニア（SRE）を対象に、Googleのローンチプランの基本的な構成要素を探り、自社製品を導入する際のリスクを低減するための実践的な方法を提供する本レポートは、企業規模や製品のユーザーベースに関係なく、消費者向けサービスにも適応可能です。これらの教訓は、製品のローンチを成功に導くための貴重で有用な学習リソースとなるでしょう。Training Site Reliability Engineers: What Your Organization Needs to Create a Learning Program「Training Site Reliability Engineers: What Your Organization Needs to Create a Learning Program」（日本語名：サイト信頼性エンジニアの育成：学習プログラムを作成するために組織に必要なこと）は、サイト信頼性エンジニアの育成に関する116ページの詳細なガイドです。2020年2月に発売されたこのレポートでは、一般的な内容からドメイン固有の内容まで、組織でのSREトレーニング方法について解説しています。GoogleのSREチームによるこのガイドでは、Googleが新しいSREを育成するために使用しているトレーニングのベストプラクティスを学ぶことができます。また、SRE（またはSREに類似した機能）のトレーニングを成功させた小規模な組織での使用例も紹介されています。効果的なSREトレーニングを実施するためには、自社のニーズと受講者の両方に合うように意図的に設計する必要があります。本レポートの大部分はGoogle SREの具体的な経験に焦点を当てていますが、トレーニング設計の背景にある理論についても説明し、過去数年間に業界全体で得られたベストプラクティスや教訓を紹介しています。参考リンク: Training Site Reliability Engineersこのレポートは、SREの育成に取り組む組織にとって、トレーニングプログラムの設計と実施における重要な指針を提供し、より効果的なSREトレーニングの実現をサポートします。Googleの実践に基づく具体的なアプローチは、業界におけるSREトレーニングのスタンダードを形成していると言えるでしょう。Anatomy of an Incident – Google – Site Reliability Engineering「Anatomy of an Incident – Google – Site Reliability Engineering」（日本語名：インシデントの解剖 – Google サイト信頼性エンジニアリング）は、インシデント対応に関する70ページの実践的なレポートで、2016年4月に発売されました。このレポートは、システム設計における失敗の避けられない側面を探り、科学者やエンジニアが未来を完全に把握することなく解決策を実行する現実を浮き彫りにしています。次のゼロデイ脆弱性、バイラル・メディア・トレンド、気象災害、テクノロジーの変化などを予測することは難しいものですが、本レポートでは、インシデントがシステムに影響を及ぼした場合に対応するための準備方法について詳しく探求しています。SREやDevOpsの実務者、IT管理者、エンジニアリング・リーダーを対象に、Ayelet Sachto氏、Adrienne Walcer氏、Jessie Yang氏のアドバイスをもとに、組織がインシデントに備え、対応し、回復する方法について解説されています。参考リンク: Anatomy of an Incidentこのレポートは無料で公開されており、上記のリンクから原著を読むことが可能です。インシデント発生時の効果的な対応策を学ぶことは、組織のシステムの信頼性を高め、将来のトラブルへの対処能力を強化するために不可欠です。インシデント管理に関心のあるすべてのプロフェッショナルにとって価値のあるリソースと言えるでしょう。Enterprise Roadmap to SRE – Google – Site Reliability Engineering「Enterprise Roadmap to SRE – Google – Site Reliability Engineering」（日本語名：SREエンタープライズロードマップ – SREを導入し継続する方法）は、SREに関する技術的立ち位置、導入理由、必要なプロセス、文化、事例などを幅広く紹介する62ページのコンパクトなレポートです。2020年3月に発売され、日本語で読める点も非常に魅力的です。このレポートでは、Google Cloud Reliability AdvocateのSteve McGheeとGoogle Cloud Solutions ArchitectのJames Brookbankが、組織でSREを導入する際にエンジニアが直面する特定の課題について深く掘り下げています。Googleが過去に出版した「Site Reliability Engineering」と「The Site Reliability Workbook」が、サービスライフサイクル全体への取り組みによって組織がソフトウェアシステムの構築、展開、監視、保守を成功させる方法と理由を示しているのに対し、本レポートはそれらを補完する内容となっています。参考リンク: Enterprise Roadmap to SRESREの普及にもかかわらず、多くの企業ではSREに対する当初の熱意とその採用の度合いの間に大きな隔たりが生じています。このレポートは、プロダクトオーナーや信頼性の高いサービスに携わる方々がSREの採用について知りたいときに、そのプロセスを体系的に説明するものです。SREの導入を検討する企業や、より効果的な方法でSREを実践したいエンジニアにとって、重要なガイダンスを提供する資料です。Incident Metrics in SRE – Google – Site Reliability Engineering「Incident Metrics in SRE – Google – Site Reliability Engineering」（日本語名：SREにおけるインシデント評価指標 – Google – Site Reliability Engineering）は、SREにおけるインシデント評価指標に深く焦点を当てた36ページのレポートです。2021年3月に発売され、SREでの改善評価や傾向追跡に用いられるMTTxメトリクスの効果について深く掘り下げています。SREでは、MTTR（平均復旧時間）やMTTM（平均緩和時間）などのメトリクスが一般的に使用されていますが、Google SREのStepan Davidovic氏はモンテカルロ・シミュレーションを用いて、これらのメトリクスが生産インシデントのコンテキストにおいて意思決定やトレンド分析に適していないことを示しています。これらのメトリクスの適用は見かけよりも厄介で、多くの実用的なシナリオにおいて誤解を招く可能性があります。本レポートでは、これらの測定を達成するための代替方法を探ります。参考リンク: Incident Metrics in SREこのレポートは、SREの実務においてインシデント評価指標の適用に関する誤解を避け、より効果的な方法を探るための重要なリソースとなります。SRE担当者やシステム運用チームは、このレポートを通じてインシデントの評価と分析に対するより深い理解を得ることができ、より効率的かつ適切な意思決定を行うための手助けを受けることができるでしょう。Practical Guide to Cloud Migration – Google – Site Reliability Engineering「Practical Guide to Cloud Migration – Google – Site Reliability Engineering」（日本語名：クラウド移行実践ガイド – Google – サイト信頼性エンジニアリング）は、クラウドへの移行に関する実践的なアプローチを解説する124ページのレポートです。2021年2月に発売され、企業が直面する大規模なクラウド変革の課題に焦点を当てています。クラウドへの移行はしばしば、大きなリターンが期待されるものです。この移行が実現すると、働き方を根本的に変える新たなビジネスチャンスが生まれます。本レポートでは、Googleのチームメンバーがクラウドへの移行に必要な文化的および技術的変革をナビゲートする方法を示しています。Googleはクラウドで誕生した企業ですが、チームメンバーの中には、この移行を苦労して乗り越えなければならなかった組織の出身者もいます。彼らは成功したクラウド変革のさまざまな側面をカバーする13のエッセイを通じて、苦労して勝ち取った経験を共有します。参考リンク: Practical Guide to Cloud Migrationこのレポートは、クラウドへの移行を検討している企業やチームにとって、具体的なヒントやアドバイスが満載の価値あるガイドとなります。クラウド変革の課題に直面する多くの組織が、このレポートを通じて適切な戦略とアプローチを学び、成功への道を切り開くための重要な手がかりを得ることができるでしょう。Google以外の重要な書籍紹介この章では、Googleに関連しないが、サイト信頼性エンジニアリング（SRE）やソフトウェアエンジニアリングの分野で重要な書籍を紹介しています。しかし、これらの書籍は、SREとソフトウェアエンジニアリングの広大な知識と実践の世界におけるごく一部に過ぎません。市場には、読者の皆様にとってさらに多くの価値ある書籍が存在し、それぞれが独自の視点と深い専門知識を提供しています。これらの書籍は、私の独断と偏見で日々直面する課題を解決し、スキルを磨くための貴重で有用なリソースとなり得ます。97 Things Every SRE Should Know「97 Things Every SRE Should Know」は、250ページにわたる実践的な書籍で、2020年11月に出版されました。この本は、SREの新人からベテランまでが、SREの採用方法、SLOの重要性、インシデント対応のアップグレード時期、モニタリングと可観測性の違いなどについて学ぶことができる、幅広いトピックをカバーしています。編集者のJaime WooとEmil Stolarskyは、信頼されるベストプラクティスや新しい問題解決方法を含む、97の有用なヒントを集めました。これにより、SREのスキルを成長させ、洗練させることが可能です。特に、「エラーバジェットを手に入れたら、次に何をするか」 - Alex Hidalgo や 「自分の仕事を認識させる：自慢文書を書く」 - Julia Evans and Karla Burnett などのアドバイスは、SREの領域において深い理解と実践的なスキルを習得するのに役立ちます。この書籍はSREにおける深い理解と実践的なスキルの習得に大いに役立ち、技術者やチームリーダー、プロジェクトマネージャーにとって非常に参考になる内容となっています。Seeking SRE「Seeking SRE」は、サイト信頼性エンジニアリング（SRE）に関する幅広いトピックを扱う587ページの書籍で、O'Reilly Media, Inc.から2018年9月に出版されました。この書籍は、システムとアプリケーションの信頼性の重要性と、市場の要求する速度でのイテレーションを行いながら信頼性を維持する難しさを背景にしています。Googleによる「Site Reliability Engineering」という著書に触発され、SREの非常に異なる部分を探求しています。「Seeking SRE」には25以上の章が含まれ、SREの世界で行われている重要な議論に読者を引き込みます。様々な環境でのSREの実装方法、DevOpsとの関連、最先端の専門知識、ベストプラクティスとテクノロジー、さらにはSREの人間的側面について、エンジニアやその他の分野のリーダーが語る内容が盛り込まれています。David N. Blank-Edelmanがキュレーター兼編集者を務め、SREの理解を深め、実践的なスキルを習得したい技術者やリーダーにとって非常に参考になる内容となっています。日本語の書籍も出版されていてとても嬉しいですねSREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazon弊社では輪読会を行いましたが様々な案件とリンクして考える事ができてよかったです。syu-m-5151.hatenablog.comPractical Monitoring「Practical Monitoring」は、O'Reilly Media, Inc.から出版された170ページに及ぶ監視システムの設計と実装に関する実践的なアプローチを提供する書籍です。2017年10月に発売され、モニタリングの改善が必要だが、どこから手を付けるべきかわからない人々に向けて書かれています。著者のMike Julianは、企業アプリケーションからデータセンターのハードウェアに至るまで、様々なレベルでの効果的なモニタリングを設計し実装するための戦略と戦術を提供しています。この書籍は特定のツールの実装方法ではなく、モニタリングの原則と基本的な仕組みに焦点を当てており、モニタリングのアンチパターン、デザインの原則、効果的なオンコールローテーションの構築、アプリケーションからのメトリクスとログの取得といった重要なトピックをカバーしています。モニタリングは、「Service Reliability Hierarchy」 でも最も最初に取り組むべきだと記載されており、その重要性は業界全体で認識されています。本書は、モニタリングの効果的な実践に関して、あらゆるレベルの専門家に対して具体的な洞察とガイダンスを提供します。Site Reliability Engineering: How Google Runs Production Systems Part III. Practices Figure III-1. Service Reliability Hierarchy より個人的には、既に知っている内容も多かったものの、心得的な部分は「監視版リーダブルコード」と表現できるほどの価値がありました。ある程度監視を経験した人には自分の知識を再確認するのに適していますが、入門書としては抽象的で理解しにくい内容も含まれているため、即座に具体的な知識を得て活用したい人には向いていないかもしれません。ネットワーク、サーバー、フロントエンド、バックエンド、KPIなどを幅広くカバーしていますが、具体的なアクションポイントにはあまり触れられていません。こちらのリンクで、この本をチェックすることができます。日本語版もO'Reilly Platform で読めます。こちらの書籍は、日本語版では「入門 監視」と題されており、これは非常に喜ばしいことです。原題の直訳である「実践 監視」とするのではなく、「入門」としていることで、モニタリングの基礎から学びたい初心者や、監視システムの知識を深めたい方々にとってもアプローチしやすい内容となっています。初学者に優しいこのタイトル変更は、監視の世界への第一歩を踏み出す人々にとって、大いに役立つことでしょう。入門 監視 ―モダンなモニタリングのためのデザインパターン作者:Mike JulianオライリージャパンAmazon「Monitoring Anti-Patterns」は、監視システムにおける一般的な間違いや誤解を扱う非常に洞察に満ちたセクションです。このセクションでは、監視を単なるタスクではなく、システム全体の健康とパフォーマンスを維持するための重要なプロセスとして捉えることの重要性が強調されています。具体的には、監視システムの設計と実装において、ツールへの過度な依存（「ツールの崇拝」）、チェックボックス式のアプローチ（「動作している」とは何を意味するのかに焦点を当てる）、監視を一時的な対処策として使うこと（「監視を松葉杖として使う」）、また手動での設定の問題点などが取り上げられています。これらのアンチパターンは、監視システムの構築における一般的な落とし穴を示しており、これらを理解し避けることは、より効果的な監視システムの構築に不可欠です。また、OSメトリクスはアラートにはあまり役立たないことが多いため、メトリクスをより頻繁に収集することの重要性も指摘されています。このセクションを読むことで、監視に関する一般的な誤解を避け、より効果的な戦略を実践するための洞察を得ることができます。learning.oreilly.com「Prometheus: Up & Running, 2nd Edition」は、Prometheusの使い方とベストプラクティスを網羅した書籍です。Prometheusは多くの組織で実運用されているメトリクスベースのモニタリングシステムであり、この書籍はサイト信頼性エンジニア、Kubernetes管理者、ソフトウェア開発者にとって実践的な指南書となります。learning.oreilly.comDatabase Reliability Engineering「Database Reliability Engineering」は、データベース管理の進化としてのDBRE（データベース リライアビリティエンジニアリング）をテーマにしたO'Reilly Media, Inc.からの294ページの重要な書籍です。2017年10月に出版され、データベースの信頼性に対する包括的なアプローチを提示しています。この書籍は、技術的な側面だけでなく、チームや組織全体の連携や継続的改善サイクルにも言及しています。特に、DBAからDBREへの進化に焦点を当て、多様なDBのプロフェッショナルが、他部門と協力し、システムの信頼性を高めるための自律的なアプローチについて詳述しています。書籍では、インフラとデータベースの効率的な構築や運用に関する技術的な知見が紹介されています。GitやChefなどを活用して、環境構築の自動化や人的ミスの排除に重点を置いています。メモリ管理、ストレージのチューニング、データベースのアーキテクチャなどに関する具体的な説明も盛り込まれており、データベースの効率的な運用に不可欠な要素として提示されています。バックアップ、セキュリティ、データベースのアーキテクチャなど、データベース運用のさまざまな側面についても触れられており、実際のDB運用業務での協業観点からも多くを学ぶことができます。また、インフラとDBaaS（Database As A Service）に関する技術的説明も含まれており、現代のデータベース運用における新しいトレンドとチャレンジに対応しています。全体的に、この書籍は技術的な知識にとどまらず、実際のデータベース運用における現場での協力や継続的な改善に関する洞察を提供するものであり、DBREとして成長したいプロフェッショナルにとって非常に価値のある一冊です。データベースリライアビリティエンジニアリング ―回復力のあるデータベースシステムの設計と運用作者:Laine Campbell,Charity MajorsオライリージャパンAmazon「Fundamentals of Data Engineering」は、O'Reilly Media, Inc.から2022年6月に出版された447ページの書籍で、データエンジニアリングの急速な成長に対応し、ソフトウェアエンジニア、データサイエンティスト、アナリストに全体的な理解を提供します。著者のJoe ReisとMatt Housleyが、データエンジニアリングのライフサイクルを通じて読者を導き、さまざまなクラウド技術を組み合わせて、組織と顧客のニーズを満たすシステムの計画と構築方法を紹介しています。本書では、データの生成、取り込み、オーケストレーション、変換、ストレージ、ガバナンスの概念を、どのようなデータ環境でも適用する方法を理解できます。また、データエンジニアリングの全体的な風景についての簡潔な概要を得ることができ、データ技術、アーキテクチャ、プロセスを選択する際のマーケティングハイプを切り抜けるためのベストプラクティスのエンドツーエンドフレームワークを使用する方法も提供されています。さらに、データガバナンスとセキュリティをデータエンジニアリングのライフサイクル全体に組み込む方法も学べるため、この本は、データエンジニアリングの基礎を学び、Platform EngineeringやSREなどの関連分野との関連性を理解するのに適した初心者向けのガイドです。learning.oreilly.comまた、RDBに関しての知識はほぼ絶対に腐らないので「達人に学ぶDB設計 徹底指南書」や「達人に学ぶSQL徹底指南書 第2版」は読んでいて絶対に良いと思います。Observability Engineering「Observability Engineering」は、O'Reilly Media, Inc.から2022年5月に出版された318ページにわたる書籍で、現代の複雑なシステムにおけるオブザーバビリティの重要性と実践について深く掘り下げています。著者であるCharity Majors, Liz Fong-Jones, およびGeorge Mirandaは、オブザーバビリティがどのようにして開発速度を加速し、不規則な振る舞いの特定、ユーザー体験の理解を深めるかについて説明しています。この書籍は、オブザーバビリティの定義、クラウドネイティブアプリケーションへの応用、ソフトウェア開発ライフサイクル全体における影響、さらにはサービスレベル目標と共に機能するチームによるオブザーバビリティの利用方法など、多岐にわたるトピックを扱っています。特に、構造化イベントの利用とOpenTelemetryによる計装の重要性が強調されており、オブザーバビリティによってエンジニアがよりプロアクティブなデバッグを行い、迅速なフィードバックサイクルを回すことが可能になると述べられています。しかし、オブザーバビリティ関連のコストが高くつく可能性も指摘されており、エンジニアと経営者の両方に、そのビジネス価値を正しく理解し伝える必要性が強調されています。オブザーバビリティの導入には「作るか買うか」の選択があり、その機能要件、適切なテレメトリーデータのサンプリング方法、テレメトリーパイプラインを用いたデータ管理についても詳細に議論されています。さらに、組織全体でのオブザーバビリティの採用には、文化的な変化が伴うとし、その投資対効果や利害関係者との協力の重要性が説明されています。この書籍は、オブザーバビリティが企業の最終損益に与える影響を明確にし、組織におけるオブザーバビリティの成熟度モデルを提供することで、オブザーバビリティを組織に根付かせるための指針を提供しています。オブザーバビリティ・エンジニアリング作者:Charity Majors,Liz Fong-Jones,George Mirandaオーム社Amazon「Learning OpenTelemetry」は、2024年3月にO'Reilly Media, Inc.から出版される、OpenTelemetryの実践的な利用に焦点を当てた250ページの書籍です。著者のAustin ParkerとTed Youngは、OpenTelemetryの各コンポーネントと、これを使ったオブザーバビリティシステムの設定、運用、トラブルシューティング方法を紹介しています。OpenTelemetryにより、複数の高品質なテレメトリーデータソースが一本化され、効率的なオブザーバビリティが実現します。この書籍は、オブザーバビリティの基本から応用までを網羅し、特にアプリケーション開発者やインフラチームにとって貴重な情報源となるでしょう。また、前著「Observability Engineering」の内容を受け継ぎながら、OpenTelemetryを通じた具体的な実践方法を提供することで、現代の複雑なシステムにおけるオブザーバビリティの理解と活用をさらに深めます。learning.oreilly.comChaos Engineering「Chaos Engineering」は、O'Reilly Media, Inc.から2020年4月に発売された305ページの書籍で、カオスエンジニアリングについての実践的なガイドです。この分野での先駆者であるCasey RosenthalとNora Jonesが共著し、Netflixでの経験を基にしています。本書は、複雑なシステムを理解し、ビジネス目標に最適化しながらナビゲートする方法をエンジニアに示します。カオスエンジニアリングとは、マイクロサービスや分散技術を採用する企業が増えるにつれて高まるシステムの複雑性に対応する方法論です。 この手法を用いることで、複雑性を取り除くことはできないものの、システムの脆弱性を発見し、顧客への影響を及ぼす前に障害を防ぐことが可能になります。また、Google、Microsoft、Slack、LinkedInなどの業界専門家からの実世界の事例を通じて理論から実践への橋渡しがなされています。書籍では、カオスエンジニアリングプログラムをゲームデイを中心に設計し、高度にターゲットを絞った自動化された実験に進む方法が紹介されています。このように、システム内の複雑性を理解するための枠組みの設計や、継続的な協力的カオス実験のデザインについても詳述されています。ただし、本書の内容は非常に有意義である一方で、カオスエンジニアリングはその文化を前提としているため、導入のハードルは高いとされています。 実際、カオスエンジニアリングの成功は組織文化や思考の枠組みに大きく依存しており、組織全体の問題解決への取り組みとして考える必要があります。カオスエンジニアリングを導入するには、単に技術的な側面だけでなく、組織としての成熟度や文化的な準備が必要になります。カオスエンジニアリング ―回復力のあるシステムの実践作者:Casey Rosenthal,Nora JonesオライリージャパンAmazon「Security Chaos Engineering」は、O'Reilly Media, Inc.から2023年3月に発売された428ページの書籍で、セキュリティカオスエンジニアリングについての包括的なガイドです。著者のKelly ShortridgeとAaron Rinehartは、複雑なソフトウェアシステムの持続可能なレジリエンス（回復力）における挑戦に対処する方法を探求しています。セキュリティカオスエンジニアリングとは、不利なイベントに備え、それらが革新、迅速な動き、エンジニアリングおよびビジネス目標の達成を妨げないようにする手法です。 この書籍では、セキュリティプログラムの設計方法、ソフトウェア配信の各フェーズでの意思決定、複雑なシステムダイナミクスの理解、システムにおける意思決定を歪める技術的および組織的トレードオフのナビゲート方法について解説しています。また、カオス実験を通じて、ソフトウェアの品質とセキュリティに関する重要な仮定を検証する方法にも焦点を当てています。 このアプローチにより、組織はセキュリティカオスエンジニアリングを利用して、システムのレジリエンスを高め、広範な攻撃から保護する方法を学ぶことができます。さらに、本書では大手企業がセキュリティカオスエンジニアリングをどのように活用しているかの事例も紹介しており、読者に現実的な応用の例を提供します。この書籍は、サイバーセキュリティの課題に直面している方にとって、非常に価値のあるリソースとなるでしょう。learning.oreilly.comBuilding Microservices, 2nd Edition新しいものが常に良いわけではありません。見掛けの進捗や成果を得るために、シンプルで高品質なものを手放す必要はありません。シンプルで高品質なモノリスは、価値あるものとして当然のように評価されるべきです。それでも、マイクロサービスへの移行が必要な場合には、「Building Microservices, 2nd Edition」を参照してください、Sam Newman氏による612ページに及ぶ包括的な書籍で、マイクロサービスの構築、管理、そしてスケーリングに関する幅広いトピックを扱っています。この書籍は、モデリング、統合、テスト、デプロイメント、監視などの最新のマイクロサービスソリューションに関して、明快な例と実用的なアドバイスを提供しています。技術の時間の経過とともの進化を追いながら、マイクロサービスに関する理解を深めるのに非常に役立ちます。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオライリー・ジャパンAmazon「Monolith to Microservices」は、マイクロサービスの理念と移行プロセスに関する実践的な内容に焦点を当てています。具体的なテクノロジーではなく、マイクロサービスへの移行を決定する基準や手順に関する経験に基づく指針を提供しており、読者にとって非常に理解しやすく、実務においても有益な情報が得られるでしょう。これらの書籍は、マイクロサービスアーキテクチャの理解を深め、実際のシステム設計や運用において役立つ貴重なリソースです。モノリスからマイクロサービスへ ―モノリスを進化させる実践移行ガイド作者:Sam NewmanオライリージャパンAmazon分散システムの信頼性を深めたい方には、『Go言語による分散サービス―信頼性、拡張性、保守性の高いシステムの構築』がおすすめです。この書籍は、データ集約型アプリケーションの設計における核心的な概念と技術を網羅的に解説し、信頼性の高い分散システム構築に必要な知識を詳細に説明しています。マイクロサービスの主軸を担うSREとして立ち回るためには、『データ指向アプリケーションデザイン』は絶対に読んでおくべき書籍です。この書籍は、分散システムの複雑さと信頼性を理解し、それらを適切に管理するための実践的な知識を提供しています。SREとしての能力を高め、システムの効率性と安定性を保つために、この書籍の学びを活用することが重要です。動画www.youtube.com発表資料 speakerdeck.comAPI Design Patterns「API Design Patterns」は、ウェブおよび内部APIの設計に関する包括的なガイドで、480ページにわたりAPIパターンの原則、リソースレイアウト、データ型の取り扱い、標準手法、セキュアなAPIのための認証・検証方法などを深く掘り下げています。GoogleのAPI専門家JJ Geewax氏によって執筆されたこの書籍は、一貫性とスケーラビリティを確保するためのAPIデザインパターンを示し、APIの基本から高度な機能、特殊なケースまでを網羅しています。読者は、APIの設計とリファクタリングに必要な知識と技術を学び、APIをより効果的に構築するための実用的なアプローチを得られます。learning.oreilly.com「Web APIの設計」はArnaud LauretによるAPI設計の実践ガイドです。この書籍では、使いやすく、柔軟で堅牢なAPIを構築する方法について詳しく解説されています。特に、コマースサイトの例を用いてデータの配置方法やAPIの拡張性の維持方法が紹介されており、実装を重視しないアプローチが特徴です。メンテナンス性やドキュメント作成の重要性も強調されています。この書籍を通じて、読者はAPIの設計と構築に必要な基本原則と実用的な手法を学ぶことができます。Web APIの設計作者:Arnaud Lauret翔泳社Amazon現代のSREというか運用では、APIやデータベースに関する知識が不可欠です。これらの技術の理解がなければ、トラブルシューティングやシステムアーキテクトとして効果的に立ち振る舞うことは困難です。APIやDBはシステムの基盤を形成し、その運用と最適化に深く関わっているため、これらの要素を熟知していないと、複雑な問題解決や効率的なシステム設計ができません。したがって、技術者はAPIとDBの知識を身につけ、常に最新のトレンドを追い続けることが重要です。Systems Performance, 2nd Edition「Systems Performance, 2nd Edition」は、システムパフォーマンスの専門家であるBrendan Greggによる928ページに及ぶ包括的な書籍です。Linuxベースのオペレーティングシステムを例に取りながら、オペレーティングシステム、ハードウェア、アプリケーションの理論を要約し、最新のツールやテクニックを用いたCPU、メモリ、ファイルシステム、ディスク、ネットワーキングの最適化やパフォーマンス分析の方法論を提供しています。クラウド環境でのパフォーマンス上の課題や、perf、Ftrace、BPF（BCCおよびbpftrace）を用いたプロファイリングとトレーシングなど、実践的な技術にも深く掘り下げています。詳解 システム・パフォーマンス 第2版作者:Brendan Greggオーム社Amazonさらに、日本語の読者にとっても、この書籍の日本語版が利用可能であることは大きな利点なので感謝しましょう。learning.oreilly.comEfficient GoSRE（Site Reliability Engineering）は、信頼性、スケーラビリティ、効率性を最大限に高めるために、システムとソフトウェアの設計、構築、運用に深く関与します。この分野で成功するためには、最新の技術トレンド、プログラミング言語、システム管理のベストプラクティスを継続的に学ぶことが不可欠です。今回紹介する書籍は、技術スタックが微妙に違ったとしてもSREが直面する多様な課題に対応するのに役立つ知識とスキルを提供します。「Efficient Go」は、O'Reilly Media, Inc.から2022年11月に出版された502ページの書籍で、技術の進歩、急速な市場の変化、およびシステムの複雑化に伴い、しばしば避けがちなソフトウェア効率の問題に対処します。戦術的で可観測性に基づくパフォーマンスの最適化は、コスト削減とビジネス成功のためにすべての製品に不可欠です。著者のBartłomiej Płotkaは、システムを高速化し、リソースを少なく消費するために必要なツールと知識を提供し、Go言語を使用して日常的な効率性を向上させる方法をガイドします。また、この書籍は、効率性の目標を明確にし、最適化する方法、CPUやメモリなどの共通リソースを効果的に使用する方法、そして効率性を評価するためのメトリクス、ログ、トレース、(継続的な)プロファイリングを通じて、Prometheus、Jaeger、Parcaなどのオープンソースプロジェクトを使用する方法を含めています。また、Go言語のスライス、ジェネリクス、ゴルーチン、割り当てセマンティクス、ガベージコレクションなどの機能を効率的に使用する方法についても詳しく解説されています。learning.oreilly.com日本語の読者には嬉しいニュースがあります。これらの書籍は、日本語版も入手可能で、日本語話者が内容をより容易に理解し活用できるようになっています。効率的なGo ―データ指向によるGoアプリケーションの性能最適化作者:Bartłomiej Płotkaオーム社Amazon「Cloud Native Go, 2nd Edition」は、O'Reilly Media, Inc.から2024年10月に出版される520ページの書籍で、Go開発者がクラウドネイティブなアプリケーションの構成と構築を、低レベルのGo機能から中間レベルのパターン、高レベルのアーキテクチャの考慮事項に至るまで探求する内容が含まれています。初版もとても良い書籍だったので紹介しておきます。本書では、中級から上級の開発者がGoを使用して簡単だが完全に機能する分散型キーバリューストアを構築する方法を段階的に説明し、Goのジェネリクス、信頼性と可用性、メモリリーク、メッセージ指向ミドルウェアについて学ぶことができます。さらに、セキュリティと分散状態に関する新しい章は、安全な分散型クラウドネイティブアプリケーションを開発する上での重要な側面に焦点を当てています。この書籍を通じて、クラウドネイティブソフトウェアを構築するのに理想的な言語としてのGoの機能を理解し、スケーラブルな分散サービスを設計する際の課題の解決方法、チャネルやゴルーチンなどGoの低レベル機能を活用した信頼性の高いクラウドネイティブサービスの設計と実装、複雑な分散システムの効果的な構築と管理のためのパターン、抽象化、ツールの適用、およびGoを使用してクラウドネイティブサービスを構築し管理する際の障害の克服方法を学ぶことができます。learning.oreilly.com「Mastering Linux Shell Scripting」は、Packt Publishingから2018年4月に出版された284ページの書籍で、Bashシェルスクリプティングの複雑さをマスターし、企業でのシェルの力を解き放つための知識を提供します。この書籍は、Linux管理者やシステム管理者を対象にしており、日常のタスクを自動化し、時間と労力を節約したい方々に最適です。基本的なシェルスクリプティングとコマンドラインの経験が必要で、自動化したいタスクに精通していることが役立ちます。本書では、最初のBashスクリプトの作成、実行、デバッグ方法やユーザー入力を求めるインタラクティブなスクリプトの作成方法、複雑なウェブ設定ファイルを動的に編集するスクリプトの開発、AWKを使用したログファイルの検索と報告、関数をビルディングブロックとして使用する効果的なスクリプトの作成方法など、シェルスクリプティングのさまざまな側面を学ぶことができます。さらに、PythonなどBASHと異なるスクリプト言語の比較による情報に基づいた選択方法も提供されています。learning.oreilly.comこの本も日本語の書籍が必要があります。嬉しいですね。マスタリングLinuxシェルスクリプト 第2版 ―Linuxコマンド、bashスクリプト、シェルプログラミング実践入門作者:Mokhtar Ebrahim,Andrew Mallettオライリー・ジャパンAmazonImplementing Service Level Objectives「Implementing Service Level Objectives」は、サービスレベル目標（SLO）の専門家であるAlex Hidalgoによる402ページの詳細なガイドです。この書籍では、SLO文化をゼロから構築する方法について、実践的なアドバイスと詳細な分析を提供しています。読者は、ユーザーの視点からサービスの信頼性を意味深く測定するサービスレベル指標（SLI）を定義する方法、統計的・確率的分析を用いた適切なSLOターゲットの選択、エラーバジェットの利用、SLOに基づくアプローチに必要なツールとリソースの構築、そして組織のリーダーシップやユーザーに対してSLOデータを用いた意味のある報告をする方法を学びます。この書籍は、SLOベースの信頼性アプローチに取り組む組織の文化とツール作成に関心のあるすべての人にとって、理想的な入門書であるとおもいます。learning.oreilly.comさらに、日本語の読者にとっても、この書籍の日本語版が利用可能であることは大きな利点なので感謝しましょう。SLO サービスレベル目標 ―SLI、SLO、エラーバジェット導入の実践ガイド作者:Alex Hidalgoオーム社AmazonModern Software Engineering: Doing What Works to Build Better Software Faster「Modern Software Engineering: Doing What Works to Build Better Software Faster」は、連続的デリバリーの先駆者であるDavid Farleyによって書かれた、効果的なソフトウェア開発の本質を探求する256ページの書籍です。この本では、プログラマー、マネージャー、テックリードを対象に、ソフトウェア開発における「学習と探索」と「複雑性の管理」という二つの主要なテーマに注目し、マインドセットからコードの品質までを改善するための原則を提案しています。Farleyは、目指すべき目標の明確化、合理的な基準に基づくツールの選択、継続的な段階的進歩を促進するための作業とシステムの組織化、繁栄するシステムへの進行状況の評価など、多岐にわたるテーマを取り上げています。さらに、実験と経験主義からの学習、システムの複雑化に対する制御、厳格さと柔軟性のバランス、歴史と経験からの学び、良いソフトウェア開発アイデアと悪いものの区別など、具体的なアプローチを提供しています。この書籍は、より良いソフトウェアをより迅速に、そして楽しみながら作成するための実践的な洞察をソフトウェアプロフェッショナルに提供します。learning.oreilly.com日本語訳があるので喜んで呼びましょう！嬉しいですね！継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣作者:David Farley日経BPAmazon「Grokking Continuous Delivery」は、GoogleのエンジニアChristie Wilsonによって書かれた424ページに及ぶ書籍で、ソフトウェアのデリバリープロセスの自動化を解説しています。本書では、新規および既存プロジェクトのための効果的な連続デリバリー（CD）パイプラインの設計、ソフトウェアプロジェクトをリリース準備完了状態に保つ方法、効果的なテストの維持、複数アプリケーションにわたるCDのスケール化、パイプラインが適切なタイミングで正しいシグナルを提供することの確保、バージョンコントロールを信頼の原点として使用、そしてメトリクスを用いたデプロイメントの安全な自動化に焦点を当てています。この書籍は、CDパイプラインの設定と運用に関する実践的なガイドとして、ツールに依存しないアプローチを採用し、イラストや明快な説明、実践的な演習を通じてCDの設計と目的を解説しています。開発者やパイプラインデザイナーに向けたこの書籍は、CDを開発プロセスに追加したいソフトウェアエンジニアにとって理想的なリソースです。learning.oreilly.comLearning Test-Driven Development「Learning Test-Driven Development」は、277ページに及ぶSaleem Siddiqui著の書籍で、テスト駆動開発（TDD）をGo、JavaScript、Pythonの3つの言語で使用する方法を解説しています。この書籍は、コードがクリーンでエレガントであり、長期間にわたって機能し続けるためのTDDの活用方法を提供します。主な焦点は、ドメインの複雑さをユニットテスト駆動のアプローチで制御する方法、言語やテストフレームワーク、ドメイン概念を超えたTDDの機能、TDDが連続インテグレーションを可能にする方法、リファクタリングと再設計をTDDでサポートする方法にあります。加えて、JavaScriptでのシンプルかつ効果的なユニットテストハーネスの書き方、TDD中に生成されたユニットテストを用いた連続インテグレーション環境の設定についても学ぶことができます。この書籍は、Go、JavaScript、Pythonを使用してTDDを実践し、クリーンで整理されたコードを書くための実用的なガイドとなっています。learning.oreilly.com『Beyond Legacy Code』（邦題：レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス）は、レガシーコードとウォーターフォールモデルの問題点、アジャイルの導入と技術的卓越性の追求、小さなバッチでの開発の利点、協力し合う文化の重要性、テストファーストのアプローチとテスト駆動開発（TDD）の役割、設計を最後に行う創発的なアプローチ、レガシーコードのリファクタリング手法など、ソフトウェア開発における重要な9つのプラクティスを詳細に説明しています。この本は、ソフトウェア開発の現場で直面する問題に対処し、高品質なコードの作成を目指す開発者にとって貴重なガイドとなります。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon『Test Driven Development: By Example』は、テスト駆動開発（TDD）の導入によって、アプリケーション開発における恐怖を取り除くことを目指しています。著者Kent Beckは、TDDを通じてプログラマーが恐怖を克服し、より良いコミュニケーションと建設的な批判の受け入れを学ぶことができると考えています。TDDは、コードを継続的にテストしリファクタリングすることを基本としており、プログラマーが質の高い作業を行うための実践的な例を示しています。また、日本語版『テスト駆動開発』の翻訳者であるt_wadaさんのアカウントも非常に有益な情報源ですので、フォローすることをお勧めします。レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス作者:David Scott Bernsteinオライリー・ジャパンAmazonさらに、Kent Beckが最近書いた『Tidy First?』もオススメです。この本では、大規模なリファクタリングや作り直しではなくて雑然としたコードの「整頓」、すなわち読みやすくするためにコードを管理しやすいセクションに分割する方法について具体的なガイダンスを提供します。また、ソフトウェア設計の基本理論についての洞察も含まれており、いつどのようにコードを「整頓」するかについての実践的なアプローチが提案されています。プログラミング経験の向上や、大きな変更を小さく安全なステップで行う方法などについても掘り下げられています。learning.oreilly.com『Infrastructure as Code, 3rd Edition』は、Kief Morrisによって書かれた包括的な書籍で、Infrastructure as Code（IaC）の進化と主流化を背景にしています。この第三版では、組織の戦略的目標と課題をサポートするためのインフラストラクチャの設計と実装に焦点を当て、持続可能な成長のための成熟した基盤の構築の必要性を強調しています。本書では、宣言的および手続き的インフラストラクチャ言語の探求や、インフラストラクチャコードがプラットフォーム戦略とエンタープライズアーキテクチャにどう適合するか、そしてインフラストラクチャコードのテストと提供方法について探求しています。また、ソフトウェア設計とエンジニアリングからの教訓を活用して、成長を促進しつつ変化するニーズに適応できるようにインフラストラクチャコードベースを構築する方法についても解説されています。さらに、物理ハードウェアから仮想サーバー、クラウドネイティブクラスター、サーバーレスワークロードまで、現実世界のITシステムの複雑な風景をサポートするインフラストラクチャのパターンに焦点を当てています。この書籍は、自動化とクラウドを組み合わせ、アジャイルやDevOpsなどの先進的なアプローチを活用して、コンプライアンス、コスト、セキュリティ、運用品質の厳格なガバナンスを実現するワークフローと運用モデルについても紹介しており、テスト駆動開発（TDD） の観点からも、インフラストラクチャコードの品質と保守性を向上させるための重要な概念と実践を含んでいます。learning.oreilly.comシステム障害対応 実践ガイド『3カ月で改善！システム障害対応 実践ガイド』は、システム障害対応とプロセス改善の実践的なアプローチを提供する画期的な本です。著者の野村浩司氏と松浦修治氏は、それぞれNTTデータとリクルートでの豊富な経験を基に、実際の業務に即した方法を提供しています。本書の大きな特徴は、障害対応の具体的な手法を「メソッド化」している点です。理論だけでなく、「どうすればいいのか？」という実践的な問いに答えており、情報システム担当者や運用リーダーにとって最適な内容となっています。また、本書は障害対応の本質的価値にも触れています。障害対応の改善は、顧客満足度、従業員満足度、そして財務観点からもプラスの効果をもたらします。この点を丁寧に説明しており、運用担当者のモチベーション向上にも寄与する内容です。大規模な障害対応経験がない方でも、対応のイメージがつかめるように工夫されています。障害対応の難所にも言及し、読者が共感しやすい内容となっています。システム障害が起こりうるすべての現場の人々に推奨されるこの本は、システム障害対応をどのように捉え、判断し、対応するべきかについてのフローや表を豊富に掲載しています。これらは特にシステム障害マニュアルが整備されていないチームにとって非常に有用です。1000件以上の事例を分析し生み出されたこのメソッドは、障害対応改善のための役立つ雛形と共に、3カ月での改善を可能にします。インシデント分析から障害訓練まで、各プロセスに役立つ情報が満載です。システム障害対応における課題の特定から改善ステップまで、具体的なガイダンスを提供し、障害対応を改善するための実践的な指針を提供します。3カ月で改善！システム障害対応 実践ガイド インシデントの洗い出しから障害訓練まで、開発チームとユーザー企業の「協同」で現場を変える作者:野村 浩司,松浦 修治翔泳社AmazonWebエンジニアのための監視システム実装ガイドPractical Monitoringでも言及しましたし、ここまで読んでいるWebエンジニアにとって、システムの監視は不可欠なのは自明です。どれだけ高度な技術で構築されても、システムは放置すると壊れたり、理解しがたい状態に陥ることがあります。「Webエンジニアのための監視システム実装ガイド」は、監視テクノロジの動向から組織での実装まで、現場目線で解説する実用書です。最新ツールの説明から実装パターンの紹介、組織での実装に向けた態勢づくりまで、監視に必要な情報が網羅されています。本書は、監視システムの設計から導入、運用に至るまでの全てを包括的に理解するのに役立ちます。特にインシデント対応の実践的な知識や心構え、監視システムのアーキテクチャ例には注目です。また、MSPでの経験から得られた貴重なノウハウが詰まっており、既存の監視システムの知識を現代的なものにアップデートしたい方にも最適でタイパが最高に良い書籍です。Webエンジニアのための監視システム実装ガイド (Compass Booksシリーズ)作者:馬場 俊彰マイナビ出版AmazonSRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本この書籍は、SRE（サイトリライアビリティエンジニアリング）の概念を分かりやすく説明しています。特にGoogleの事例を中心に、どのようにして大規模なサービスを安全かつ迅速にリリースし続けるかを示しています。SREがGoogle独自の手法ではなく、広くクラウドを利用する企業やエンジニアにとっても役立つ内容である点が強調されています。本書は、DevOpsを担当する方々、アプリケーション開発者、さらにはプログラミング未経験者にもSREという考え方を理解しやすくしています。その結果、「ざっくりなんとなくわかる」ような浅い理解を超えて、「すっきり」した理解を得ることができ、タイパを求める読者にとっては「最高」の参考書となります。SRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本: Googleが実践している新DevOps方法論作者:GGtop.jpAmazonさいごに情報技術の世界は日々進化しており、特にSRE分野では新たな知識と技術の習得が不可欠です。当ブログではSREにおける効率的な学習（タイパ）に役立つ書籍を多数紹介してきました。これらの資料が、読者の皆様のSREに対する理解の深化と実務能力の向上に貢献することを願っています。さらに、紹介した本にとどまらず、他にも多くの優れた書籍が存在しますので、是非探求してみてください。また、優先順位をどうしてもつけてほしいという人がいる場合はDevOps Roadmapがある参考にするといいと思います。私が所属する株式会社スリーシェイクでは、好奇心が強く手が動くエンジニアを求めています。私たちはSRE分野における多岐にわたる支援を提供しており、興味のある方は是非お問い合わせください。詳細は公式サイトでご覧いただけます。来年は当ブログでDevOpsやPlatform Engineeringの分野に焦点を当てる予定です。これらの分野は技術進歩が著しく、常に新しいアプローチやベストプラクティスが登場しています。それらをいかに実務に応用するかについて、深く掘り下げていきたいと考えています。私は「現場がさき、プラクティスがあと、原則をだいじに」という考え方を重視しており、適切な専門性と多様な事例に基づく知見を持ちながらも、業界全体での普及が十分でない現状があります。このため、時には根拠の不十分な「最強のDevOps」や「SREに外側だけ準じた独自のアプローチ」のような概念が生まれがちです。これは業界における深い理解と適切なプラクティスの普及に向けた取り組みが必要であることを示しています。このブログを読んでくださった皆様に心から感謝いたします。私たちは、SREの世界での成長と発展を目指し、皆様と一緒に学び続けることを楽しみにしています。ブログの購読をお願いすることで、私たちのモチベーションにも繋がります。次回の更新を楽しみにしていてください！2025年版はフォームも用意しているのでご確認お願いします。docs.google.com","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/26/165255","isoDate":"2024-01-26T07:52:55.000Z","dateMiliSeconds":1706255575000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SQLBoilerによるPostgreSQLの操作についての話","contentSnippet":"はじめにデータベースは、現代のアプリケーション開発において不可欠な要素です。特にリレーショナルデータベースは、その整合性と信頼性から幅広い用途で使用されています。しかし、リレーショナルデータベースを効率的に操作するためには、複雑なSQLクエリを記述し、アプリケーションのコードとデータベースのスキーマを適切に統合する必要があります。この作業は開発者にとって時間と労力を要するものです。この背景から、ORM（Object-Relational Mapping）ライブラリの利用が一般的になりました。ORMライブラリは、プログラミング言語のオブジェクトとデータベースレコードをマッピングし、SQLクエリの生成を抽象化して開発者がデータベース操作を容易に行えるようにサポートします。この記事では、Go言語でのデータベース操作を効率化するためのORMライブラリ「SQLBoiler」の活用方法について解説します。SQLBoilerは、Go言語に特化した強力なORMライブラリで、データベーススキーマに基づいてGoのコードを自動生成します。この自動生成機能により、開発者は煩雑なボイラープレートコードの記述を削減し、ビジネスロジックに集中できるようになります。本記事では、SQLBoilerの基本的な使用方法から生成されたコードの実際の利用方法までを段階的に紹介します。それでは、SQLBoilerを活用してGo言語でのデータベース操作を効率化する方法を見ていきましょう。ORM（Object-Relational Mapping）についてORMは、リレーショナルデータベースとプログラミング言語の間の橋渡しをする技術です。通常のデータベース操作に使用されるSQLとは異なり、ORMはプログラムのオブジェクト（今回のGoでは構造体）とデータベースレコードを自動で関連付け、SQL文の組み立てを可能にします。SQLBoilerの利点SQLBoilerはGo言語に特化した強力なORMライブラリで、データベーススキーマから直接Goのコードを生成します。この自動生成機能により、ボイラープレートコードの削減と開発効率の向上が図れます。ボイラープレートコードとはいくつかの異なるコンテキストでほとんどまたはまったく変更せずに再利用できるコンピュータ言語のテキストのことを指します。SQLBoilerの使用方法SQLBoilerを利用する際は、まずデータベーススキーマを定義します。以下は、著者、出版社、利用者、書籍、貸出記録を管理するスキーマの例です。-- 著者テーブルcreate table authors (  author_id serial primary key,  name varchar(100) not null);-- 出版社テーブルcreate table publishers (  publisher_id serial primary key,  name varchar(100) not null);-- 利用者テーブルcreate table users (  user_id serial primary key,  family_name varchar(100) not null,  given_name varchar(100) not null,  email_address varchar(254) not null,  registration_date date not null);-- メールアドレスに対するユニークキー制約（ユニークインデックス）create unique index idx_users_email_address on users(email_address);-- 書籍テーブルcreate table books (  book_id serial primary key,  title varchar(255) not null,  author_id integer not null,  publisher_id integer not null,  isbn varchar(20),  year_published integer);-- 貸出記録テーブルcreate table loans (  loan_id serial primary key,  book_id integer not null,  user_id integer not null,  loan_date date not null,  return_date date);-- 外部キー制約の追加alter table books add constraint fk_books_author_id foreign key (author_id) references authors(author_id);alter table books add constraint fk_books_publisher_id foreign key (publisher_id) references publishers(publisher_id);alter table loans add constraint fk_loans_book_id foreign key (book_id) references books(book_id);alter table loans add constraint fk_loans_user_id foreign key (user_id) references users(user_id);このスキーマをもとに、SQLBoilerはGoのモデル、クエリビルダー、CRUD操作を自動生成します。この自動生成により、開発者は細かなデータベース操作を手作業で行う必要がなく、ビジネスロジックに集中できます。環境構築Dockerを使用して、PostgreSQLのバージョン16を動作させる環境を構築します。以下のdocker-compose.yamlファイルを使用してPostgreSQLサーバーを立ち上げます。version: '3'services:  postgres:    container_name: postgres    image: postgres:16    restart: always    ports:      - \"5432:5432\"    environment:      POSTGRES_USER: \"postgres\"      POSTGRES_PASSWORD: \"postgres\"サンプルデータの投げ込みv01_insert.sql を作成します-- 著者テーブルにサンプルデータを挿入INSERT INTO authors (name) VALUES ('Sample Author 1');INSERT INTO authors (name) VALUES ('Sample Author 2');INSERT INTO authors (name) VALUES ('Sample Author 3');-- 出版社テーブルにサンプルデータを挿入INSERT INTO publishers (name) VALUES ('Sample Publisher 1');INSERT INTO publishers (name) VALUES ('Sample Publisher 2');INSERT INTO publishers (name) VALUES ('Sample Publisher 3');-- 利用者テーブルにサンプルデータを挿入INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Yamada', 'Taro', 'taro@example.com', '2021-01-01');INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Suzuki', 'Hanako', 'hanako@example.com', '2021-02-01');INSERT INTO users (family_name, given_name, email_address, registration_date) VALUES ('Tanaka', 'Ichiro', 'ichiro@example.com', '2021-03-01');-- 書籍テーブルにサンプルデータを挿入INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 1', 1, 1, '1234567890', 2021);INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 2', 2, 2, '0987654321', 2020);INSERT INTO books (title, author_id, publisher_id, isbn, year_published) VALUES ('Sample Book 3', 3, 3, '1122334455', 2022);-- 貸出記録テーブルにサンプルデータを挿入INSERT INTO loans (book_id, user_id, loan_date, return_date) VALUES (1, 1, '2022-01-01', '2022-01-15');INSERT INTO loans (book_id, user_id, loan_date, return_date) VALUES (2, 2, '2022-01-05', '2022-01-20');INSERT INTO loans (book_id, user_id, loan_date) VALUES (3, 3, '2022-01-10');投げ込み投げ込みpsql -h localhost -U postgres -d postgres -f v01_insert.sqlSQLBoilerのインストールSQLBoilerのインストール手順は以下の通りです。go install github.com/volatiletech/sqlboiler/v4@latestgo install github.com/volatiletech/sqlboiler/v4/drivers/sqlboiler-psql@latestPostgreSQL接続情報の設定（YAML形式）psql:  dbname: \"postgres\"  host: \"127.0.0.1\"  port: 5432  user: \"postgres\"  pass: \"postgres\"  sslmode: \"disable\"  whitelist:    - \"authors\"    - \"publishers\"    - \"users\"    - \"books\"    - \"loans\"whitelistにはコード生成の対象となるテーブルを明示的に指定します。この例では、著者、出版社、利用者、書籍、貸出記録の各テーブルを指定しています。SQLBoilerによるコード生成以下のコマンドを使うことで、SQLBoilerは指定されたデータベーススキーマに基づいてGoのモデルを生成します。sqlboiler psql -c config/database.yaml -o models --no-testsこのコマンドは、config/database.yamlに指定された設定を使用して、modelsディレクトリ内にモデルファイルを生成します。--no-testsオプションにより、テストファイルの生成をスキップします。生成されたファイル構成は以下の通りです。models/├── authors.go├── boil_queries.go├── boil_table_names.go├── boil_types.go├── boil_view_names.go├── books.go├── loans.go├── psql_upsert.go├── publishers.go└── users.go生成されたファイルの解説例として、books.goファイルの一部を見てみましょう。このファイルはデータベースのbooksテーブルに対応するGoの構造体と、それに関連する関数を定義しています。Book構造体type Book struct {    BookID        int         `boil:\"book_id\" json:\"book_id\" toml:\"book_id\" yaml:\"book_id\"`    Title         string      `boil:\"title\" json:\"title\" toml:\"title\" yaml:\"title\"`    AuthorID      int         `boil:\"author_id\" json:\"author_id\" toml:\"author_id\" yaml:\"author_id\"`    PublisherID   int         `boil:\"publisher_id\" json:\"publisher_id\" toml:\"publisher_id\" yaml:\"publisher_id\"`    Isbn          null.String `boil:\"isbn\" json:\"isbn,omitempty\" toml:\"isbn\" yaml:\"isbn,omitempty\"`    YearPublished null.Int    `boil:\"year_published\" json:\"year_published,omitempty\" toml:\"year_published\" yaml:\"year_published,omitempty\"`}Book構造体はbooksテーブルの各列をフィールドとして持ち、タグを用いてデータベースの列名とのマッピングを定義しています。SQLBoilerによるコード生成の詳細解説SQLBoilerによって生成されたモデルファイルは、リレーショナルデータベースと連携するための多様な機能を提供します。ここでは、具体的なコード例を使って、関連関数やリレーションシップ、フックについて解説します。生成されたファイルには、CRUD操作（作成、読み取り、更新、削除）を行うための関数も含まれています。例えば、Insert関数はBookオブジェクトをデータベースに挿入し、Update関数は既存のレコードを更新します。また、Delete関数はレコードを削除し、Reload関数はデータベースから最新の情報を再読み込みします。関連関数の例// Insert a single record using an executor.func (o *Book) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {    // ...関数の本体...}// Update uses an executor to update the Book.func (o *Book) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {    // ...関数の本体...}// Delete deletes a single Book record with an executor.func (o *Book) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {    // ...関数の本体...}// Reload refetches the object from the database.func (o *Book) Reload(ctx context.Context, exec boil.ContextExecutor) error {    // ...関数の本体...}これらの関数は、Bookオブジェクトを使用して、データベースに対する挿入、更新、削除、再読み込みの操作を行います。リレーションシップの例// Author pointed to by the foreign key.func (o *Book) Author(mods ...qm.QueryMod) authorQuery {    // ...関数の本体...}// Publisher pointed to by the foreign key.func (o *Book) Publisher(mods ...qm.QueryMod) publisherQuery {    // ...関数の本体...}これらの関数は、Bookオブジェクトが参照する外部キー（Author, Publisher）に基づいて、関連するデータを取得するためのクエリを作成します。SQLBoilerはテーブル間のリレーションシップを認識し、それに対応する関数も生成します。例えば、BookがAuthorとPublisherに関連している場合、それぞれのリレーションシップに対応するLoadAuthorやLoadPublisherなどの関数が生成されます。フックの例// AddBookHook registers your hook function for all future operations.func AddBookHook(hookPoint boil.HookPoint, bookHook BookHook) {    // ...関数の本体...}フックを使用すると、データベース操作の前後に特定の処理を実行できます。例えば、AddBookHook関数は、特定のタイミングで実行されるカスタムフックを登録します。SQLBoilerは各CRUD操作の前後に実行されるフック（Hook）もサポートしています。これにより、データベース操作の前後にカスタムロジックを実行することが可能です。SQLBoilerの応用と実践的な利用方法Go言語とSQLBoilerを使用して、リレーショナルデータベースでのデータ操作を行う方法を解説します。この記事では、実際のコードを使用して、SQLBoilerで生成されたモデルを利用してデータベースの書籍テーブルを操作する一連のプロセスを紹介します。主にSelect、Insert、Update、Upsert、Delete、Reloadといった基本的なデータベース操作をカバーし、Eager Loadingやデバッグ出力などの高度な機能についても触れます。以下のサンプルコードは、PostgreSQLデータベースに接続し、複数の異なる操作を実行するGoプログラムです。このプログラムでは、SQLBoilerで生成されたモデルを使用して、書籍の情報を取得、挿入、更新、アップサート、削除し、データベースの状態を再読み込みする操作を行います。package mainimport (    \"context\"    \"database/sql\"    \"fmt\"    \"log\"    _ \"github.com/lib/pq\"    \"github.com/nwiizo/workspace_2024/sqlboiler/models\" // 生成されたモデルのインポート    \"github.com/volatiletech/null/v8\"    \"github.com/volatiletech/sqlboiler/v4/boil\"    \"github.com/volatiletech/sqlboiler/v4/queries/qm\")func main() {    // データベース接続    db, err := sql.Open(        \"postgres\",        \"postgres://postgres:postgres@localhost/postgres?sslmode=disable\",    )    if err != nil {        log.Fatal(err)    }    defer db.Close()    ctx := context.Background()    // SELECT: 全ての書籍を取得    allBooks, err := models.Books().All(ctx, db)    if err != nil {        log.Fatal(err)    }    for _, book := range allBooks {        log.Printf(\"Book: %+v\\n\", book)    }    fmt.Println(\"Select: 高度なクエリでの書籍の取得\")    books, err := models.Books(        models.BookWhere.Title.EQ(\"Specific Title\"),        models.BookWhere.AuthorID.EQ(1),        qm.Limit(10),    ).All(ctx, db)    if err != nil {        log.Fatal(err)    }    for _, book := range books {        fmt.Println(\"Book:\", book.Title)    }    fmt.Println(\"Count: 書籍の数を数える\")    count, err := models.Books(models.BookWhere.Title.EQ(\"Specific Title\")).Count(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Count:\", count)    fmt.Println(\"Exists: 特定の条件に一致する書籍が存在するかを確認\")    exists, err := models.Books(models.BookWhere.Title.EQ(\"Specific Title\")).Exists(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Exists:\", exists)    fmt.Println(\"Insert: 書籍の挿入\")    newBook := &models.Book{        Title:         \"New Book\",        AuthorID:      1,        PublisherID:   1,        Isbn:          null.StringFrom(\"1234567890\"),        YearPublished: null.IntFrom(2023),    }    err = newBook.Insert(ctx, db, boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Update: 書籍の更新\")    newBook.Title = \"Updated Title\"    _, err = newBook.Update(ctx, db, boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Upsert: 書籍のアップサート\")    upsertBook := &models.Book{        BookID:        newBook.BookID,        Title:         \"Upserted Title\",        AuthorID:      2,        PublisherID:   2,        Isbn:          null.StringFrom(\"0987654321\"),        YearPublished: null.IntFrom(2024),    }    err = upsertBook.Upsert(ctx, db, true, []string{\"book_id\"}, boil.Infer(), boil.Infer())    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Delete: 書籍の削除\")    _, err = newBook.Delete(ctx, db)    if err != nil {        log.Fatal(err)    }    fmt.Println(\"Reload: 書籍の再読み込み\")    err = newBook.Reload(ctx, db)    if err != nil {        if err == sql.ErrNoRows {            fmt.Println(\"Reload: 書籍が見つかりませんでした\")        } else {            log.Fatal(err)        }    }    // Eager Loading の例    // ユーザーと関連する書籍を取得    // user, err := models.FindUser(ctx, db, 1, qm.Load(\"Books\"))    // if err != nil {    //     log.Fatal(err)    // }    // for _, book := range user.R.Books {    //     fmt.Println(\"Book:\", book.Title)    // }    // デバッグ出力の例    // boil.DebugMode = true    // books, _ = models.Books().All(ctx, db)    // boil.DebugMode = false    // Raw Query の例    // _, err = queries.Raw(\"SELECT * FROM books WHERE title = 'New Book'\").QueryAll(ctx, db)    // if err != nil {    //     log.Fatal(err)    // }    // Hook の例    // func myBookHook(ctx context.Context, exec boil.ContextExecutor, book *models.Book) error {    //     fmt.Println(\"Book Hook Triggered\")    //     return nil    // }    // models.AddBookHook(boil.BeforeInsertHook, myBookHook)    // null パッケージの使用例    // newBook.Isbn = null.StringFromPtr(nil) // ISBN を null に設定}このプログラムでは、まずデータベースに接続し、全ての書籍を取得する操作から始まります。その後、特定の条件に一致する書籍の数を数えたり、特定の条件に一致する書籍が存在するかを確認したりする操作を行います。その後、新しい書籍をデータベースに挿入し、その書籍の情報を更新します。次に、アップサート操作を行い、特定の書籍を削除し、最終的には削除された書籍の情報を再読み込みします。このプロセスは、SQLBoilerを使ってGo言語でデータベース操作を行う際の典型的なフローを示しています。また、コメントアウトしていたコードに関しても一部は解説させてください。高度なクエリ構築SQLBoilerでは、qmパッケージを利用して複雑なクエリを組み立てることができます。例えば、特定の条件を満たす書籍を取得するために、以下のようなクエリを構築することが可能です。books, err := models.Books(    models.BookWhere.Title.EQ(\"Specific Title\"),    models.BookWhere.AuthorID.EQ(1),    qm.Limit(10),).All(ctx, db)if err != nil {    log.Fatal(err)}for _, book := range books {    fmt.Println(\"Book:\", book.Title)}このコードは、タイトルが\"Specific Title\"であり、かつ著者IDが1の書籍を最大10件まで取得します。Eager LoadingSQLBoilerを使うと、関連するレコードを事前にロードするEager Loadingも可能です。たとえば、あるユーザーに関連するすべての書籍を取得するには、以下のようにします。user, err := models.FindUser(ctx, db, 1, qm.Load(\"Books\"))if err != nil {    log.Fatal(err)}for _, book := range user.R.Books {    fmt.Println(\"Book:\", book.Title)}この例では、IDが1のユーザーに関連するすべての書籍を取得しています。デバッグ出力SQLBoilerを使用する際、boil.DebugModeを有効にすることで、実行されたSQLクエリを確認することができます。これはデバッグ時に非常に便利です。boil.DebugMode = truebooks, _ := models.Books().All(ctx, db)boil.DebugMode = falseRaw Queryの使用SQLBoilerでは、生のSQLクエリを直接実行することも可能です。これは特定のシナリオで必要となる複雑なクエリを実行する際に役立ちます。_, err = queries.Raw(\"SELECT * FROM books WHERE title = 'New Book'\").QueryAll(ctx, db)if err != nil {    log.Fatal(err)}このコードは、タイトルが'New Book'のすべての書籍を取得します。Hookの設定SQLBoilerでは、データベース操作の前後に実行されるHookを設定することができます。これはデータの整合性を保つための追加のロジックを実行する際に便利です。func myBookHook(ctx context.Context, exec boil.ContextExecutor, book *models.Book) error {    fmt.Println(\"Book Hook Triggered\")    return nil}models.AddBookHook(boil.BeforeInsertHook, myBookHook)この例では、書籍がデータベースに挿入される前に特定の処理を行うHookを設定しています。nullパッケージの活用SQLBoilerでは、nullパッケージを利用して、データベースのNULL値を扱うことができます。これにより、NULL許容のフィールドを安全に操作することが可能になります。newBook.Isbn = null.StringFromPtr(nil) // ISBNをNULLに設定newBook.YearPublished = null.IntFrom(2023) // 発行年を設定このコードでは、ISBNをNULLに設定し、発行年を2023に設定しています。まとめSQLBoilerは、Go言語でリレーショナルデータベースを効率的に操作するための強力なORM（Object-Relational Mapping）ライブラリです。データベーススキーマから直接Goのコードを生成し、開発者が細かなデータベース操作を手作業で行う負担を軽減します。SQLBoilerは、CRUD操作、リレーションシップの管理、フックの実装など、多様な機能を提供し、開発者がビジネスロジックに集中できる環境を整えます。この記事では、SQLBoilerの基本的な使用方法から、生成されたコードの実際の利用方法までを解説しました。まず、データベーススキーマの定義とSQLBoilerの環境設定を行い、サンプルデータの挿入を通じて実際のデータベース操作を準備しました。次に、SQLBoilerによって生成されたGoのモデルを利用して、Select、Insert、Update、Upsert、Delete、Reloadといった一連のデータベース操作を行うプロセスを紹介しました。これらの操作は、リレーショナルデータベースとGoプログラムの間のインタラクションを容易にし、開発プロセスを加速します。SQLBoilerは、Go言語でのデータベース操作を簡素化し、開発速度を向上させることが可能です。手動でのデータベース操作コードの記述が多い開発者にとって、SQLBoilerは大きな助けとなります。SQLBoilerの詳細や使い方については、SQLBoiler GitHubページを参照してください。［改訂3版］内部構造から学ぶPostgreSQL―設計・運用計画の鉄則 (Software Design plus)作者:上原 一樹,勝俣 智成,佐伯 昌樹,原田 登志技術評論社Amazon参考資料GitHub - d-tsuji/awesome-go-orms: ORMs for Go, most starred on GitHub.GitHub - avelino/awesome-go: A curated list of awesome Go frameworks, libraries and softwareGoのORMの人気ランキングを年ごとにまとめてみたGo言語 SQLBoilerでタイプセーフに複数条件のWhere句を書く #Go - QiitaGoのORM決定版 Genをはじめよう #Go - QiitaGoにおけるORMと、SQLBoiler入門マニュアル","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/23/161638","isoDate":"2024-01-23T07:16:38.000Z","dateMiliSeconds":1705994198000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"PostgreSQLのsqldefによるDBスキーマ管理で遊んだ。 ","contentSnippet":"はじめにこの記事では、データベーススキーママイグレーションツールであるsqldefで遊んだので使用方法とその特徴について解説します。sqldefはRidgepoleに触発されて開発されたツールで、データベースのスキーマ変更を容易に行えるように設計されています。github.com1. sqldefとはsqldefは「The easiest idempotent MySQL/PostgreSQL/SQLite3/SQL Server schema management by SQL」と謳われるDBスキーマ変更管理ツールです。GitHub上で公開されており（sqldef GitHubリポジトリ）、MySQL、PostgreSQL、SQLite3、SQL Serverに対応しています。このツールを使用することで、CREATE TABLE文を書くだけで対象テーブルの比較とALTER TABLE文の生成・実行が可能になります。sqldefは、データベースの現在のスキーマとユーザーが提供するCREATE TABLE文を比較し、必要な変更を自動的に検出します。このプロセスにより、データベースの変更をより簡単かつ迅速に行うことができます。また、sqldefはidempotent（冪等性）を持つため、同じ変更を何度適用しても、結果として得られるスキーマは同じになります。これにより、データベースの変更管理がより安全かつ予測可能になります。このツールは特に、開発環境やテスト環境での迅速な変更適用や、本番環境への安全な変更のロールアウトに非常に有用です。2. sqldefの利点従来のスキーママイグレーションツールではCREATE TABLE文とALTER TABLE文を二重管理する必要がありましたが、sqldefを使用すると新規作成DDL文のみを管理するだけで済むため、DBA（データベース管理者）および開発者の作業負担が大幅に軽減されます。また、CI/CDパイプラインにも簡単に組み込むことができるため、デプロイメントプロセスの自動化と整合性の向上が期待できます。2.1 sqldefの最大の利点は、そのシンプルさと効率性従来のツールでは、データベースの初期状態を構築するためのCREATE TABLE文と、既存のデータベースを変更するためのALTER TABLE文の両方を管理する必要がありました。しかし、sqldefを使えば、CREATE TABLE文のみを管理すれば十分で、ALTER TABLE文は自動的に生成されます。これにより、変更の管理が簡略化され、DBAと開発者の双方の作業負担が大幅に減少します。2.2 CI/CDパイプラインへの組み込みさらに、sqldefはCI/CDパイプラインとの統合が容易で、これによりデプロイメントプロセスの自動化が可能になります。データベースの変更をコードレビューとテストのプロセスに組み込むことで、変更の品質を向上させ、本番環境への変更のロールアウトをより安全に行うことができます。このように、sqldefは開発チームの生産性を高め、データベースの整合性を維持するための強力なツールです。3. やってみる実際にsqldefを使用するためには、適切な環境構築が不可欠です。このセクションでは、Dockerを活用してPostgreSQLサーバーをセットアップし、sqldefをダウンロードして設定する手順を具体的に説明します。その後、具体的なスキーマ定義を作成し、それをデータベースに適用してみます。3.1 環境構築Dockerを使用して、PostgreSQLのバージョン16を動作させる環境を構築します。以下のdocker-compose.yamlファイルを使用してPostgreSQLサーバーを立ち上げます。version: '3'services:  postgres:    container_name: postgres    image: postgres:16    restart: always    ports:      - \"5432:5432\"    environment:      POSTGRES_USER: \"postgres\"      POSTGRES_PASSWORD: \"postgres\"3.2 sqldefのダウンロードと設定sqldefの実行可能バイナリをGitHubからダウンロードし、設定します。これにより、任意のプラットフォームでsqldefを利用することが可能になります。curl -LO https://github.com/sqldef/sqldef/releases/download/v0.16.15/psqldef_darwin_amd64.zipunzip psqldef_darwin_amd64.ziprm psqldef_darwin_amd64.zip./psqldef --versionリリース情報はこちらから適切なアーキテクチャを選んでください。tarコマンドのオプションは覚えられず忘れているのでzipファイルを選びました。github.com3.3 スキーマの適用v01_library.sqlファイルを用意し、図書館システムの基本的なテーブルを作成します。このスクリプトでは、PostgreSQLのserial型を使用して主キーの自動インクリメントを行い、外部キー制約を設定しています。これにより、データベースの整合性が保たれ、アプリケーションの安定性が向上します。ただし、sqldefを用いたスキーマの適用は効率的ですが、特に外部キー制約に関連する場合には注意が必要です。外部キー制約はデータベースの整合性を保つために重要な役割を果たしますが、これらの制約を含むテーブルの変更を管理する際には、特定の課題が生じることがあります。今回のケースでは、これらの課題を避けるための工夫を取り入れながら、スキーマを適用していきます。-- 著者テーブルcreate table authors (  author_id serial primary key,  name varchar(100) not null);-- 出版社テーブルcreate table publishers (  publisher_id serial primary key,  name varchar(100) not null);-- 利用者テーブルcreate table users (  user_id serial primary key,  user_name varchar(100) not null,  email_address varchar(100),  registration_date date not null);-- 書籍テーブルcreate table books (  book_id serial primary key,  title varchar(255) not null,  author_id integer not null,  publisher_id integer not null,  isbn varchar(20),  year_published integer);-- 貸出記録テーブルcreate table loans (  loan_id serial primary key,  book_id integer not null,  user_id integer not null,  loan_date date not null,  return_date date);-- 外部キー制約の追加alter table books add constraint fk_books_author_id foreign key (author_id) references authors(author_id);alter table books add constraint fk_books_publisher_id foreign key (publisher_id) references publishers(publisher_id);alter table loans add constraint fk_loans_book_id foreign key (book_id) references books(book_id);alter table loans add constraint fk_loans_user_id foreign key (user_id) references users(user_id);これを psqldef で以下のように適用します。PGPASSWORD=postgres ./psqldef -h localhost -p 5432 -U postgres postgres < v01_library.sql3.4 スキーマの変更ユーザーテーブル（users）の構造を変更するための新しいDDLスクリプトを作成し、sqldefを使用して適用します。この変更には、列の追加、列の型変更、NOT NULL制約の追加が含まれ、データベースの設計を現代的な要件に合わせることができます。-- v02_library.sqlcreate table users (  user_id serial primary key,  family_name varchar(100) not null,  given_name varchar(100) not null,  email_address varchar(254) not null,  registration_date date not null);これを psqldef で以下のように適用します。PGPASSWORD=postgres ./psqldef -h localhost -p 5432 -U postgres postgres < v02_library.sql-- Apply --ALTER TABLE \"public\".\"users\" ADD COLUMN \"family_name\" varchar(100) NOT NULL;ALTER TABLE \"public\".\"users\" ADD COLUMN \"given_name\" varchar(100) NOT NULL;ALTER TABLE \"public\".\"users\" ALTER COLUMN \"email_address\" TYPE varchar(254);ALTER TABLE \"public\".\"users\" ALTER COLUMN \"email_address\" SET NOT NULL;-- Skipped: DROP TABLE \"public\".\"authors\";-- Skipped: DROP TABLE \"public\".\"books\";-- Skipped: DROP TABLE \"public\".\"loans\";-- Skipped: DROP TABLE \"public\".\"publishers\";ALTER TABLE \"public\".\"users\" DROP COLUMN \"user_name\";3.5 ユニークキー制約の追加最後に、ユーザーテーブルにユニークキー制約を追加するためのDDLスクリプトを適用します。ユニークキー制約を追加することで、メールアドレスの重複を防ぎ、データの一意性を保証することができます。-- v03_library.sql-- ユーザーテーブルの作成create table users (  user_id serial primary key,  family_name varchar(100) not null,  given_name varchar(100) not null,  email_address varchar(254) not null,  registration_date date not null);-- メールアドレスに対するユニークキー制約（ユニークインデックス）create unique index idx_users_email_address on users(email_address);これを psqldef で以下のように適用します。PGPASSWORD=postgres ./psqldef -h localhost -p 5432 -U postgres postgres < v03_library.sql-- Apply ---- メールアドレスに対するユニークキー制約（ユニークインデックス）create unique index idx_users_email_address on users(email_address);-- Skipped: DROP TABLE \"public\".\"authors\";-- Skipped: DROP TABLE \"public\".\"books\";-- Skipped: DROP TABLE \"public\".\"loans\";-- Skipped: DROP TABLE \"public\".\"publishers\";4. 結論sqldefは、データベーススキーマの変更を簡単かつ効率的に行うことができる強力なツールです。特に、継続的インテグレーション/継続的デリバリー（CI/CD）パイプラインの一部としてスキーマ変更の自動化を行う際に非常に有効であり、開発プロセスの加速とデータベース整合性の向上に大きく寄与します。ただし、すべてのケースに適用可能なわけではなく、その特性と限界点を十分理解することが重要です。今回は実験的に使用してみた結果、このようなツールの有用性を実感しました。また、実際に運用経験のある方々の貴重なフィードバックが参考文献に掲載されていますので、より深い洞察を得るためにも、ぜひ参考にしていただくと良いでしょう。プログラマのためのSQL 第4版 すべてを知り尽くしたいあなたに作者:Joe Celko翔泳社Amazon5.参考文献sqldefDocker Compose overviewpostgres | Docker Official ImageGo製マイグレーションツールまとめsqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントDBスキーマ変更管理ツール sqldef を試してみたsqldefへのSQL Server対応のコントリビュート 〜OSS活動を通して紐解くDBマイグレーションツールの実装〜ミラティブのサーバサイドをGo + Clean Architectureに再設計した話マイグレーションツールをsqldefに移行した話","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/22/124414","isoDate":"2024-01-22T03:44:14.000Z","dateMiliSeconds":1705895054000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"アヒルに話かけると仕事をしてくれるが責任まではとってくれない","contentSnippet":"正直に言えば、責任も取ってほしい。k0kubunさんのAIにプログラミング作業を奪われているに対する感想です。はじめに現代のソフトウェア開発は、生成AIの急速な進化によって前例のない大規模な変革を経験しています。かつては時間と労力を要していた複雑な作業が、生成AIの導入により効率的かつ迅速に行えるようになりました。特に、DevOpsやSREの分野での生成AIの利用は注目に値します。自動化されたプロセスにより、開発サイクルが加速し、ソフトウェアの品質と信頼性が向上しました。その結果、継続的インテグレーションやデリバリーのプロセスが効率化され、開発チームは新しい機能の実装やバグ修正に迅速に対応できるようになりました。この技術革新は、ユーザーだけでなく、開発者自身の作業プロセスにも大きな変化をもたらしており、良い影響を与えることが期待されます。本稿では、自動コード生成の利点と課題、開発者の責任、そして最終的には人間中心の設計と開発の重要性について探求します。自動コード生成と開発者への影響自動コード生成の分野では、生成AIは開発者の作業を劇的に簡素化し、プログラミングの高速化と精度向上を実現しています。この技術の進歩により、開発者はルーチン作業から解放され、より複雑で創造的な問題に集中できるようになりました。生成AIによる自動コード生成は、開発者が新しいアイデアやソリューションを迅速に試すことを可能にし、従来の開発手法とは異なる新しいアプローチを提供しています。ただし、このような革新的な進歩には新たなリスクも伴い、セキュリティやプライバシー、倫理的な課題に対応する必要があります。開発者はこれらの新たな課題に適切に対処するために、生成AIの活用を慎重に管理し、適切に調整する必要があります。アヒルに話かけると仕事は終わる「ラバーダック・デバッグ」というテクニックは、問題をゴム製のアヒルに説明することで解決策を見つける効果的な方法です。同様に、生成AIと対話することは、仕事を効率的に終えるためのアプローチとなります。ソフトウェア開発において、生成AIは開発者の負担を大幅に軽減し、ルーチン作業から複雑なタスク処理までをサポートします。この進化により、開発者は日常の作業から一歩離れ、より戦略的で創造的な活動に集中できるようになります。その結果、プロジェクトの進捗が加速し、開発サイクルが短縮されることが可能になります。Happy Trees アヒル お風呂用おもちゃ 大型 バスダック スクイークゴム アヒル ベビーシャワー 7インチHappy Trees MauLaikaAmazon生成AIを活用した創造的な問題解決の促進自動コード生成を含む生成AIの技術は、開発者を日常の作業から解放し、より複雑で創造的な問題解決に集中させます。生成AIによるバグ検出やパフォーマンス最適化機能は、ソフトウェアの信頼性と効率性を飛躍的に向上させています。これらの技術の進歩は、開発プロセスの速度向上だけでなく、ソフトウェアの全体的な品質向上と持続的な改善ももたらしています。生成AIは、開発者が直面する課題に新たな解決策を提供し、イノベーションの可能性を広げています。働きたくないイタチと言葉がわかるロボット 人工知能から考える「人と言葉」作者:川添愛朝日出版社Amazonアヒルは仕事をしてくれるが責任はとれない生成AIはソフトウェア開発に多くの利点を提供しますが、その適用範囲と機能には限界があります。生成AIはプロジェクトの特定の側面を助ける強力なツールとして機能しますが、最終的な製品の品質、セキュリティ、倫理的な問題解決は開発者の裁量と判断に委ねられています。例えば、生成AIは基本的なコード生成や一般的な問題の検出に優れた能力を発揮しますが、複難なシステムアーキテクチャの設計や新しい種類のセキュリティリスクに対処するためには、開発者の深い技術知識と経験が必要です。開発者の役割と責任したがって、開発者は生成AIの提案を批判的に評価し、プロジェクトのニーズに応じて適切な調整や改善を行う責任があります。生成AIは開発プロセスを支援し、効率化を促進できますが、最終的な製品の品質と機能性の確保は開発者の責任です。開発者は、生成AIによって提供されるソリューションの品質を確保し、プロジェクトの目標達成に向けて責任を持つことが求められます。また、生成AIの活用に伴う潜在的なリスクを理解し、適切に管理することも重要です。このようにして、生成AIと人間の開発者は協力しながら、高品質で安全なソフトウェアを創造できます。人間中心の設計と開発生成AIの技術進歩は、ソフトウェア開発のプロセスを変革していますが、この変革の中心には常にユーザー（社内外問わず）が存在します。人間中心の設計と開発は、技術が人間のニーズ、価値、行動に基づいて開発されるべきだという理念に根ざしています。このアプローチは、生成AIを含む技術が、ユーザーや開発者のエクスペリエンスを向上させ、よりアクセスしやすく、開発しやすく、使いやすい製品を生み出すことを目指しています。人間中心の設計では、開発初期段階からユーザーフィードバックを組み込み、継続的なテストと改善を通じて、ユーザーの実際の使用状況を反映したソリューションを提供します。開発者は、ユーザーの視点を理解し、その視点を設計と開発のプロセスに統合することで、より人間中心のアプローチを取り入れることができます。これには、多様なユーザーグループとの協力、ユーザビリティテストの実施、アクセシビリティガイドラインの遵守が含まれます。このようにして、開発者は生成AIの潜在的な利点を最大限に活用しながら、技術が人間のニーズに適応することを保証できます。同じ開発者に対しても良い行動を示すことが重要であり、互いに刺激し合い、共に成長することで、全体の業界の水準を引き上げることに寄与します。人間の仕事として最後に残るものソフトウェア開発において生成AIの役割が拡大している現在、人間中心の設計と開発の原則は、開発者が直面する責任と課題に新たな次元を加えています。技術の進歩は、単に作業の自動化や効率化を超え、開発者に対して、ユーザーの深い理解と共感を基にした意思決定を行うことを要求しています。このコンテキストでは、倫理的な判断、戦略的思考、そして人間の感情と経験を理解する能力が、人間の仕事として最後に残る核心的な要素となります。開発者は、生成AIを活用することで得られる多大な利益を享受しつつも、最終的な製品がユーザーの実生活において意味のある価値を提供することを確実にする責任を負います。このためには、技術の知識と同様に、人間と社会に関する深い洞察が必要です。生成AIの進歩によって開発者の役割が変化しても、最終的な目標は変わりません。それは、人間の生活を豊かにし、より良い未来を形成することです。したがって、人間中心の設計と開発の精神は、ソフトウェア開発における人間の仕事の未来を形作る基盤となります。このようにして、生成AIと人間の開発者は、高品質で、使いやすく、全ての人にとって有益なソフトウェアを共に創出していくことができます。プロフェッショナリズムの重要性プロフェッショナリズムは、技術の進歩と人間中心の設計の精神を融合させる上で不可欠な要素です。生成AIのような強力なツールを活用する際、開発者は単に技術的なスキルを超えた行動規範を持つ必要があります。プロフェッショナルとして、不十分な対応や適切ではない言い訳に直面した際には、我々はしばしば失望と不満を感じます。このため、開発者は常に高い倫理基準を維持し、ユーザーのニーズと安全を最優先する責任があります。問題に直面した場合、待つのではなく、積極的に解決策を探し、適切な対応を行うことが求められます。このプロフェッショナリズムは、生成AIの倫理的使用、人間中心の設計原則、そして最終的にはソフトウェアの品質とユーザー体験の向上に寄与します。開発者としてのプロ意識を維持することは、技術の可能性を最大限に引き出し、同時に潜在的なリスクを適切に管理する上で不可欠です。また、プロフェッショナリズムは、開発者が生成AIを含むあらゆるツールを使って良質なソフトウェアを生み出すための基盤を形成します。さらに、プロフェッショナリズムは、チーム内外での信頼と尊敬を築く上でも重要です。開発者が高いプロ意識を示すことで、チームメンバー間の協力が促され、プロジェクトの成功に向けた効果的なコミュニケーションと協働が可能になります。また、組織外の利害関係者やエンドユーザーに対しても、開発者の行動は組織の信頼性と評判を高めることに直接影響します。最終的に、プロフェッショナリズムの重要性は、技術的なスキルだけでなく、倫理的、人間的な価値を尊重し、それらを実務に統合することで、より良いソフトウェア製品とサービスを提供することにあります。生成AIの時代においても、開発者のプロ意識は、革新的で持続可能なソリューションの創出と、社会全体の利益に対する貢献の核心をなすものです。www.nhk.jp","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/19/202246","isoDate":"2024-01-19T11:22:46.000Z","dateMiliSeconds":1705663366000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"達人と呼ばれる技術力を持ったソフトウェアエンジニアになりたくて","contentSnippet":"zyさんの「技術力が高い」という幻覚を読んでの感想。sizu.me技術力とは私の経験でも、技術力は単なる専門知識や技術の習得を超えた、もっと包括的で深い概念です。実用日本語表現辞典において「技術力」とは、「手段や手法を用いて物事を成し遂げる能力」と定義されています。この定義は、技術を単に適用することではなく、それを利用して広範囲な目標を達成する、特に問題解決能力を含む幅広い能力を示唆しています。言い換えれば、技術力は具体的な技術的スキルだけではなく、それらを応用し、実際の課題に対して実効性のある解決策を生み出す能力を意味します。これには、新しい技術を学び、既存の技術を創造的に応用することも含まれます。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon技術力への信頼とその重要性私が考えるに、高い技術力は複雑な技術の使用能力だけに限らず、他者からの信頼と依頼を獲得する能力にも反映されます。人々が「あの人に任せたい」「あの人に相談したい」と感じる時、それは技術的な能力だけではなく、人間性やコミュニケーション能力が高いことを示します。こうした能力は、チームワークやプロジェクトの成功に不可欠です。技術力を持つ人は、単にタスクをこなすだけでなく、チームメンバーと効果的に協力し、プロジェクトの目標に貢献します。「技術力が高い」「技術力が低い」という一般的な評価はしばしば狭い視野に基づいています。真の技術力の評価は、直接的な事業貢献やコミュニケーション能力を超えた、より幅広い能力に基づくべきです。これは、個々のポジションや視点によって異なり、難解なコードを書く能力だけでなく、既存のコードを効率的に活用し、迅速に顧客に価値を提供できる能力も含まれます。技術力は、新しい課題に対応する柔軟性と、既存のソリューションを改善する創造性を併せ持つことです。このように、高い技術力は、技術的なスキルに加えて、人間性、信頼性、問題解決能力、コミュニケーション能力などの多面的な資質が組み合わさったものです。これにより、他者から頼りにされ、尊敬されるエンジニアとなることが可能です。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazonソフトウェアエンジニアの役割ソフトウェアエンジニアは、一人で全てを行う天才ハッカーや家で働きもせずに自称ソフトウェアエンジニアを名乗っている場合を除いて、技術を活用して問題を解決し、新しい価値を創造する重要な役割を担っています。彼らは技術的な問題に直面するだけでなく、企業の一員としてのプロフェッショナルな責任も持ちます。これには、会社の目標達成、業務の効率化、社内外の関係構築など、より広範な責務が含まれます。社内で問題が発生した際、彼らは解決策の策定と推進における主導的な役割を果たし、問題点の指摘にとどまらず、修正パッチの提供など具体的かつ建設的な貢献を行います。この積極的で前向きなアプローチは、問題の根本的な解決につながり、ソフトウェアの品質向上や優れたソリューションの提供に貢献します。総じて、ソフトウェアエンジニアとしての技術力と、企業の一員としてのプロフェッショナルな貢献は、それぞれが重要な役割を果たします。彼らは技術的なスキルと共に、組織内での協力と責任感を兼ね備えていることが求められます。サラリーマン金太郎 第1巻作者:本宮 ひろ志サード・ラインAmazonまとめ私が若い頃、私は寡黙で不器用だが技術に深く向き合う、達人と呼ばれるソフトウェアエンジニアの存在を信じていました。しかし、時が経つにつれて、「技術力が高い」という言葉が単に技術的なスキルの高さだけを意味するのではないことを理解しました。この言葉には、問題解決能力、信頼性、コミュニケーション能力など、多面的な資質が含まれています。たとえそれが誤解や幻想に基づいていたとしても、持ちうる技術力を活かして他者を支援し、互いにリスペクトを持つことが、ソフトウェアエンジニアとしての成長への道であると気づきました。このような姿勢が、周囲から達人として認識されるための重要な要素となっています。イシューからはじめよ――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazonあとは、「技術力が高い」という幻覚を読んでたらそーだいさんのソフトウェアエンジニアと技術力を思い出した。読み返してもとても良かったので合わせて紹介しておきたいです。 speakerdeck.com私、もしくは私たちが技術力と呼んでいるナニカについての話でした。追記したこと後日このブログを読み返してみると、僕にとって、あの日ハッカーに憧れた自分が、「ハッカーの呪縛」から解き放たれるまで 的な意味合いもあったのだと思います。ただの思いつきかもしれませんが、技術分野でトップに立てなかった自分に対する、ある種の弁解や自己正当化の意味もあるのかもしれません。もしかしたらこれから私が歩む道によっては別の意味を持ってくるのか？ハッカーと画家 コンピュータ時代の創造者たち作者:ポール グレアムオーム社Amazonハッカーになろう (How To Become A Hacker）ハッカーと画家 ---Hackers and Painters---","link":"https://syu-m-5151.hatenablog.com/entry/2024/01/10/132326","isoDate":"2024-01-10T04:23:26.000Z","dateMiliSeconds":1704860606000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"技術書やブログ、登壇資料の参考文献は読んだ方がいい","contentSnippet":"はじめに今年、わたしは女性との同棲を解消した。その過程で、円形脱毛症にも胃潰瘍にもなった。まるで自分の身体から生気が抜け落ちるような感覚に何度も襲われた。そして、人生でこれまでにないほど体重が増えるという、加齢を言い訳にしたような出来事が頻発した。彼女との生活でトーストの耳を食べるのをやめていたがそれも食べるように戻した。年末のこの時期は、振り返ったり新しいことを始めたくなるものです。しかしそんなことは全て横に置いておいて今日は、「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というテーマについて、深掘りしてみたいと思います。技術の世界は日々進化し、新しい情報を取り入れることは不可欠ですが、新しい技術や理論の背後にある基礎知識や歴史にも目を向けることも同じかそれ以上に大事ではないでしょうか？参考文献の役割技術書やブログ、登壇資料には、文字やページの数や時間の制限があるため、著者や発表者は主要なポイントに焦点を当てて情報を伝えます。しかしこれらの表面に現れる情報だけでは、トピックの全貌を把握するのは難しいです。そこで重要になるのが、参考文献の役割です。これらは、トピックに関するより詳細な情報、歴史的背景、異なる視点やアプローチを提供し、より深い理解を促します。特に、複雑な技術や理論を扱う際には、参考文献が理解の鍵となります。ブログや登壇資料の表面だけを読んで分かったと思うのは容易いですが、実際の理解は表面的なものに過ぎないことが多いのです。認知科学者スティーブン・スローマンとフィリップ・ファーンバックの著書「知ってるつもり 無知の科学」では、人間の知性の限界と錯覚について詳しく論じられています。この本は、私たちが持つ「知識の錯覚」について解説しています。多くの人が、あるトピックについて理解していると自信を持っているが、実際にはその理解は浅いことが多いのです。これは、私たちの認知システムが複雑な情報を簡略化し、限られた情報から全体を理解したと錯覚する傾向があるためです。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazonまた、エンジンコミュニティではダニング＝クルーガー効果という現象としても有名で、人々は自分の知識や能力を過大評価する傾向があります。これは特に、自分の知識が不足している分野で顕著に現れます。この効果は、単なる自信過剰にとどまらず、誤った情報や決定に基づく行動を引き起こすリスクを含んでいます。togetter.comこのようなわかったフリした認識の歪みを避けるためにも、参考文献を活用して自分の理解を深め、多角的な視点を持つことが重要です。参考文献は、知識の錯覚やダニング＝クルーガー効果に陥りがちな私たちの認識を補完し、より深い理解を促すためのものになり得ます。文献選びのポイント文献を選ぶ際には、その情報源の信頼性や、著者の専門性を評価することが大切です。現在の自分の知識レベルや興味のある領域に合った文献を選ぶことも重要です。一つのトピックについて、異なる角度から書かれた文献を読むことで、よりバランスの取れた理解が得られます。年末年始の休暇は、新しい知識を身につけるための絶好の機会です。選んだ文献をじっくりと読むことで、より学びを充実させることができます。文献選びに関しては、必ずしも難解なものを選ぶ必要はありません。例えば、参考文献に載ってる書籍の入門書を読むことは、知識の更新や基礎を再確認するためにも有効です。O'Reillyなどの専門書のサブスクリプションサービスを利用することで、「え、この本読むのに3000円か」と逡巡せずに幅広い分野の知識を得るための良い方法となります。最後にこのブログを通じて伝えたいのは、単に「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というアドバイスではなく、むしろ「技術書やブログ、登壇資料の参考文献は読んでほしい」という切なる願いです。学びの過程で急ぎすぎず、じっくりと時間をかけて考えることは本当に大切です。表面的な理解に留まらず、深く内容を吟味し、背景や著者の意図を理解することで、真の学びが得られます。参考文献を読む際には、それらが提供する多様な視点や深い知識を活用し、幸せの分母を増やすような豊かな理解を目指すことが重要です。ゆっくりと考えることで、新しい発見や洞察が生まれ、学びの経験がより深いものになります。私たちは共に学び、共に成長することができます。皆さん、良いお年をお迎えください。新しい年にも、学びの喜びを共有し、一緒に成長していくことを心から楽しみにしています。そして、みなさんにも心から「参考文献をしっかりと読むこと」を勧めます。それによって、より深い知識と理解を得ることができ、幸せの分母を増やすための一歩となるでしょう。遅考術――じっくりトコトン考え抜くための「１０のレッスン」作者:植原 亮ダイヤモンド社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/31/221026","isoDate":"2023-12-31T13:10:26.000Z","dateMiliSeconds":1704028226000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"WIP: 2023年 俺が愛した本たち 非技術書編","contentSnippet":"この記事は、3-shake Advent Calendar 2023 21日目のエントリ記事です。はじめにプログラマー脳エンジニアのためのドキュメントライティング達人プログラマー 第2版スタッフエンジニアプロジェクト ヘイルメアリーサーキット・スイッチャー可燃物大規模言語モデルは新たな知性か？ブラジャーで天下をとった男さいごにはじめに2023年が終わろうとしています。年の瀬になると、いつも一年を振り返ることが私の習慣です。技術書に続いて、今年はさまざまな非技術書にも手を伸ばしました。小説や歴史、哲学、芸術の本など、多くのジャンルの本を読むことで、心が豊かになったと感じています。これらの本は、技術的なことだけではなく、人生について深く考えるきっかけをくれました。異なる文化や、普段とは違う視点の物語に触れることで、新しい考え方を学びました。これらの本が、私の考えを広げ、日々の生活に新しい刺激を与えてくれました。技術書と一緒に、これらの本も私のエンジニアとしての知識を形成する大切な部分になりました。2023年は、技術だけでなく、人生の学びにも終わりがないことを感じた一年でした。非技術書から得たことは、技術書から学んだことと相まって、私の理解を深めてくれました。読書を通じて得たこれらの経験は、来年もまた新しい発見への旅に私を連れて行ってくれるでしょう。そして、来年もまた、本とともに充実した一年になることを楽しみにしています。プログラマー脳『プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ』は、プログラミングのスキル向上に認知科学の手法を応用した、画期的な書籍です。この本は、プログラマーがプログラムを読み書きする際に経験する認知的プロセスを深く掘り下げ、熟達したプログラマーと初心者の違いを明確に示しています。著者は、具体的なプログラミング技法や設計手法の直接的な説明を超え、認知のメカニズムを理解し活用することにより、プログラミングの学習と実践の改善を目指しています。プログラマー脳 プログラマーになるための認知科学に基づくアプローチノーブランド品Amazon本書の強みは、抽象的な概念を具体的な実例や演習を交えて解説することで、読者が新しいアイデアを自然に理解し、実践的な知識として身につけるのを助ける点にあります。また、プログラミングに関連する認知科学的な概念を、実際のプログラミングの状況にどのように適用するかについて、具体的かつ実用的なアドバイスを提供しています。こうしたアプローチは、読者がプログラミングに関する洞察を深め、より効率的かつ効果的に技術を習得する手助けをします。この本で特に興味深いのは、「意味波」という概念です。これは、新しい概念や技術を学ぶ過程で、抽象から具象、そして再び抽象へと進むプロセスを指します。このプロセスは、学習者が情報を受け取るだけでなく、それを自分の既存の知識や経験と結びつけ、より高い次元の理解へと昇華させるのに役立ちます。このアプローチは、新しい技術やアイデアを単に学ぶのではなく、それらを既存の知識構造に組み込んで深い理解を得ることに重点を置いています。他にも面白い概念や考え方が多いので、ぜひ読んでみてください。本書は、プログラミングにおける認知的側面を深く掘り下げることで、新しい学習法やスキル向上のアプローチを提供します。これにより、プログラミングのスキルを深め、熟達したプログラマーになるための貴重な知識と洞察を提供しています。『プログラマー脳』を読んで面白いと感じた方は、『言語の本質-ことばはどう生まれ、進化したか』も読んでみてください。『言語の本質-ことばはどう生まれ、進化したか』は、言語の起源と進化に焦点を当てた別の注目すべき書籍です。この本は、言語が人間にとってどのように重要なコミュニケーションツールとして発展してきたのかを探求しています。特に、オノマトペやアブダクション推論という人間特有の学びの力に焦点を置き、言語の進化と子どもの言語習得を通じて人間の根源に迫ります。著者は、言語の起源と進化に関する深い知見を提供し、言語が単なるコミュニケーションツール以上のものであること、すなわち、私たちの認知と感情、文化に深く根差した現象であることを明らかにします。言語の本質　ことばはどう生まれ、進化したか (中公新書)作者:今井むつみ,秋田喜美中央公論新社Amazon本書は、言語の抽象性や体系性、さらには言語がどのようにして複雑なシステムへと発展してきたのかを解明しています。これらのトピックを通じて、読者は言語の複雑な構造と機能、そして人間の認知プロセスとの関連を理解することができます。この本は、言語学、認知科学、心理学に興味を持つ読者にとって、知識の深化と洞察の拡大に貢献するでしょう。それぞれ異なる領域において人間の認知能力と学習の本質に深く切り込んでいる『プログラマー脳』と『言語の本質』に加えて、『進化心理学から考えるホモサピエンス 一万年変化しない価値観』も非常に興味深い本です。『プログラマー脳』では、プログラミングの習得と実践に認知科学を適用し、『言語の本質』は言語の起源と進化を探求することで人間の認知プロセスを解析しています。これらの本は、それぞれの分野において新たな洞察を提供し、読者の理解とスキルの向上に貢献します。進化心理学から考えるホモサピエンス　一万年変化しない価値観作者:アラン・S・ミラーパンローリング株式会社Amazon『進化心理学から考えるホモサピエンス 一万年変化しない価値観』は、進化心理学の観点から、人間の行動や価値観がどのように進化してきたかを探る一冊です。この本は、私たちの行動や意思決定に影響を与える進化的適応について深く掘り下げ、現代の社会や文化における人間の行動パターンを進化心理学的視点から分析します。この並びで本書を紹介するのは、伊藤計劃の『虐殺器官』が『言語学、進化心理学SFの傑作である』ためで、この本は人生を変えるぐらい面白い本だったからです。また、『ゆる言語学ラジオ』も聞いており、とても良かったのでおすすめです。www.youtube.comエンジニアのためのドキュメントライティングDocs for Developers: An Engineer’s Field Guide to Technical Writingの翻訳本です。書いた書評のブログ記事では、この本が良いドキュメントの特徴を架空の開発チームのストーリーを通して教えることで、読者にドキュメンタリアンとしての情熱を呼び起こすと評価されています。syu-m-5151.hatenablog.com原著は読んでないです。やっててよかったO'Reillyサブスクは原著版のみあります。learning.oreilly.comまた、技術ドキュメントではないいですが『三行で撃つ 〈善く、生きる〉ための文章塾』もおすすめです。この本は読者に向けた独特なアプローチで、文章技術の向上を目指す実用書です。作家の近藤康太郎氏によるこの本は、ただのテクニック本にとどまらず、書くという行為を通じて自己の実存を考えさせられる思想書としての側面も持ち合わせています。文章テクニックだけでなく、企画の立て方、時間・自己管理術、インプットの方法、思考の深め方に至るまで幅広くカバーし、リリカルな思想とロジカルな技術を融合させています。また、他人の目で空を見ず、自分だけの言葉で書くことの重要性や、「説明しない技術」を身に付けることの必要性を強調し、読者が自然に感情を動かされる文章を書くための技術を教えてくれます。文章を通じて善く生きるための深い洞察を提供する、稀有な一冊です。技術ドキュメントとの差異が分かるので理科系の作文技術や数学文章作法などと一緒に読むと自分がその時に書くべき文章がわかってくる。www.youtube.com同著者の近藤康太郎の『百冊で耕す 〈自由に、なる〉ための読書術』は、読む行為を通じて自己を見つめ、新しい自己を発見するための思想書としても機能します。速読や遅読、批判的読書や没入的読書など、対立する読書法を探求し、それらを融合させることで多面的な読書体験を提案しています。近藤氏は、「本は百冊あればいい」と述べ、読者に自分にとってのカノン(聖典)100冊を選び、深く読み込むことで、知識を内面化し、己の一部にする方法を説いています。本書は、読書のご利益を探求し、勉強、孤独、愛、幸せ、生きることについての疑問を掘り下げ、読むことで自分が変わり、他者や世界を愛する新たな自分を発見する旅を提案しています。達人プログラマー 第2版『達人プログラマー ―熟達に向けたあなたの旅― 第2版』は、David ThomasとAndrew Huntによる名著で、ソフトウェア開発者がより効率的かつ生産的になるための実践的アプローチを提供する一冊です。本書は特に今年読んだわけではないものの、非常に多く引用して、活用している価値のある本としてあげておきます。プログラマーとしての技術面だけでなく、問題解決の姿勢やプロフェッショナリズムについても深く掘り下げています。例えば、「猫がソースコードを食べちゃった」というセクションでは、責任を持つ重要性を強調し、「石のスープとゆでガエル」では、プロジェクト進行の重要なポイントを示唆します。また、「伝達しよう！」のセクションでは、効果的なコミュニケーションの重要性を説いています。また、プロジェクトマネジメントやチームワーク、プロフェッショナルとしての姿勢に関する深い洞察を提供し、エンジニアとしてのキャリアを積む上での貴重な指針となります。本書はあまりに網羅的な内容のため、各セクションに関連する本での補完が必要だと思います。しかし、特に技術系のポエム記事に触れたことがある読者には、この一冊を深く読み込むことを強くお勧めします。『達人プログラマー』は、プログラマーだけでなく、あらゆるソフトウェア開発に関わる全ての人にとって、読む価値のある一冊です。『SOFT SKILLS ソフトウェア開発者の人生マニュアル 第 2 版』も同様にオススメですがこちらの方がバラエティに富んでいるのでちょっとエンジニアリング以外のコラムも読みたい方はこちらの方がオススメです。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonスタッフエンジニア『スタッフエンジニア　マネジメントを超えるリーダーシップ』はWill Larsonによる本で、エンジニアリングキャリアのシニアレベル以上を目指す人にとって重要な指針を提供する一冊です。Will Larsonは、EM（エンジニアリングマネージャー）としてのチームのつくりかた、VPやDirectorとしての組織のつくりかたに関する洞察を提供する『An Elegant Puzzle』の著者でもあります。本書の洋書版を読む気力がなかった私にとって、翻訳本の出版はありがたいことでした。また、LarsonのHow to invest in technical infrastructureという記事も、共通基盤への投資方法について記述しており、非常に参考になるためオススメです。さて、本の内容に戻りますと、第1章ではスタッフエンジニアの役割とその意味を深く掘り下げ、技術力だけでなく組織内での影響力とリーダーシップの重要性を強調しています。これらの役割をどのように達成し、キャリアを前進させるかについて詳細に説明しており、特に印象的なのは、「スタッフエンジニアになれば自分の仕事を自分で管理でき、誰もがあなたに従い、あなたの望むことをするようになると考えたら大間違いだ」という言葉です。これはスタッフエンジニアの役割に関する一般的な誤解を解き明かしています。さらに、シニアエンジニアからスタッフプラスエンジニアへの進化を探る第3章、転職の決断を考慮する第4章、そして現役スタッフエンジニアのインタビューを通じて彼らの日常と役割の変化を深く掘り下げる第5章が続きます。全体を通して、この本は技術的なキャリアパスにおいてマネジメントの道を選ばないエンジニアにとって、必読の書です。各章は、スタッフエンジニアとしての役割を深く理解し、実現するための具体的な手法を提供しています。この本は、私のような経験豊富なエンジニアにとっても新たな学びとなり、これからのキャリアにおいて大いに参考になります。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonプロジェクト ヘイルメアリーTBDサーキット・スイッチャーTBD可燃物TBD大規模言語モデルは新たな知性か？TBDブラジャーで天下をとった男TBDさいごにこの年、多くの非技術書に没頭することで、私は内面的な成長と感情の豊かさを体験しました。各々の書籍が示した独特の感性や深い感動は、私の人間性を拡げ、心を満たしてくれました。皆さんからの心に残る作品の推薦も、来年の読書リストに追加し、楽しみにしています。読書はただの趣味にとどまらず、私たちの感情や人格を育て、深める重要な行為です。来年も、私と一緒に、心の成長と感動の旅に出ましょう。2024年も感動に満ちた読書の時を過ごし、新しい自分を見つけ、心の成長を遂げる一年となりますように。","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/21/165021","isoDate":"2023-12-21T07:50:21.000Z","dateMiliSeconds":1703145021000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2023年 俺が愛した本たち 技術書編","contentSnippet":"この記事は、3-shake Advent Calendar 2023 2日目のエントリ記事です。はじめに2023年がそろそろ幕を閉じようとしています。年末に差し掛かると、時間が流れる水のように止まらないことを感じながら、過ぎ去った一年を振り返るのは、私にとって欠かせない習慣です。この一年も、技術書の海に身を投じて、多くの本に心を奪われ、狂気のような積読を重ねました。積めば技術力が向上すると信じている。現代科学では解明できない電波が(諸説あり)積み上がった本からは出ていてこれらが私の知識の山となりました。が、来年はこの山を一歩一歩登り、購入する本の数を読む本の数に下回らせることを心に誓います。2023年は、特に技術の世界で学びは終わりがないことを実感した年でした。読書を通じて得た知識と経験は、来年もまた新たな知識の旅へと私を導くでしょう。昨年の読んだ本syu-m-5151.hatenablog.comはじめに有用情報2023年に読んでよかった技術書サイトリライアビリティワークブックSoftware Requirements Essentialsシステム障害対応 実践ガイドコンテナセキュリティTerraform: Up and Running, 3rd EditionEfficient GoKubernetes Best Practices, 2nd Editionルールズ・オブ・プログラミングさいごに有用情報昨年惜しまれつつ終了したACM会員特典、O'Reilly Online Learningの読み放題サブスクが、2023年に復活しました！これは大きなニュースですね。新しい年間料金は＄174と少々お高くなってしまいましたが、通常の＄499と比較するとかなりの節約です。ちなみに、私は5月に＄499でこのサブスクを手に入れました。興味がある方は、ACM登録ページより登録が可能です。ACM Professional Membership（年間＄99）にACM Skills Bundle Add-On（追加＄75）を組み合わせることで、O'Reilly Online Learning、Skillsoft Percipioのeラーニング、PluralsightのIT技術学習プラットフォームといった3つの学習コンテンツのサブスクを登録できます。2023年に読んでよかった技術書2023年は、読書から得た知識をソフトウェアエンジニアとしての実務経験に結びつけ、いくつかのイベントで登壇する機会に恵まれました。これらの登壇では、本で学んだ理論やアイデアを実際の業務に応用し、それらを共有することで得られた知見が非常に貴重なものでした。今後も、この経験を活かして、より多くの人々と知識を共有し、相互に学び合う機会を創出していきたいと考えています。また、2023年に私が特に愛読した本を紹介し、読書を通じたさらなる知見の共有を図っていく予定です。これらの本が、皆さんの技術的な成長や新しい洞察を得るための一助となれば幸いです。speakerdeck.comサイトリライアビリティワークブック『サイトリライアビリティワークブック ―SREの実践方法』は、『SRE サイトリライアビリティエンジニアリング』の実践編として、SRE（サイトリライアビリティエンジニアリング）を組織やプロジェクトに導入する際に必要な具体的な方法や手順を詳しく解説した本です。Google内部での技術的ノウハウに加え、Evernote、The Home Depot、New York Timesなど、様々な企業での事例を紹介しています。本書は、クラウド環境など制御できない環境での信頼性の高いサービスの実行方法、サービスレベル目標に基づくサービスの作成・監視・運用、運用チームをSREに変換する方法、新規開発や既存サービスにおけるSREの始め方などをカバーしています。また、SREとDevOpsの関係性についても詳しく触れています。この本は、前作『SRE サイトリライアビリティエンジニアリング』と対になる本であり、前作が原理と哲学を紹介するのに対し、本書はそれらの原理の適用方法に焦点を当てています。また、Googleだけでなく、さまざまな企業でのSREプラクティスについても解説しています。本書は前作と比較して内容が身近で読みやすく、SREの理解をさらに深めることができます。基本的な用語や他社の事例が分かりやすく説明されており、SREの実践に関して具体的かつ実用的な内容が盛り込まれています。さらに、分散システムの信頼性に関する知識を深めたい方には、『Go言語による分散サービス―信頼性、拡張性、保守性の高いシステムの構築』がおすすめです。この本は『Distributed Services with Go』の翻訳版であり、2022年8月に発売されました。また、『Designing Data-Intensive Applications』も非常に役立ちここ数年で最も読んでよかった技術書の一冊です。この本はデータ集約型アプリケーションの設計における核心的な概念と技術を網羅的に解説し、信頼性の高い分散システム構築に必要な知識が詳細に説明されています。時間を巻き戻して本を読む順番を選べるなら、もっと早く手に取りたかったと感じています。翻訳版である『データ指向アプリケーションデザイン』も知っておくと有益です。関連するイベントの詳細はこちらで確認できます。イベントは既に終了していますが、本の内容を深く理解し、専門家から新しい視点や知見を得る絶好の機会です。このイベントに参加することで、読書体験がより充実したものになることは間違いありません。動画www.youtube.com発表資料 speakerdeck.comちょっと脱線してしまいましたが総じて、『サイトリライアビリティワークブック ―SREの実践方法』は、SREを導入し、SREの考え方をプロダクト開発に導入しようとしている人にとって有益な情報が豊富に含まれています。サイトリライアビリティワークブック ―SREの実践方法オライリージャパンAmazon英語版を読みたい方のために、Googleが無料で公開しているリンクは以下です。sre.googleSoftware Requirements Essentials「私は過去 10 年間でベストセラーになった要件エンジニアリングの本 10 冊を読んだことがあります。この 1 冊には、それらの 10 冊を合わせたものよりも有益な情報が簡潔に記載されています。」--Mike Cohn, author of User Stories Applied and co-founder, Scrum Allianceこの表現が過剰ではないことがわかる一冊である。はやく読みたかった本つながりで。『Software Requirements Essentials: Core Practices for Successful Business Analysis』は、要件開発と管理における20のコアプラクティスを紹介する重要な本です。著者のKarl WiegersとCandase Hokansonは、伝統的なプロジェクトからアジャイルプロジェクトまで、あらゆるアプリケーションドメインにおいて、優れた価値を提供する可能性が最も高いプラクティスに焦点を当てています。これらのコアプラクティスは、チームがビジネス問題を理解し、適切な参加者を巻き込み、より良い解決策を明確にし、コミュニケーションを改善し、最も価値のある機能を適切な順序で実装し、変化と成長に適応するのに役立ちます。これもサブスクで読めるのでおすすめです。ソフトウェア要求 第3版 を読むほど時間がないのであればおすすめです。learning.oreilly.comソフトウェア要求 第3版 の本も読めます(原書)。やっててよかったO'Reillyサブスクlearning.oreilly.comこの本はソフトウェア要求 第3版を簡潔で焦点を絞った内容であり、「どのように」するかについての実用的な詳細がほどよく含まれているため、すべてのプロジェクト参加者におすすめできます。本書を使用することで、チーム全体が重要な概念、用語、技術、理論について共通の理解を築き、プロジェクトごとにより効果的に協力できます。主な内容には、問題の明確化、ビジネス目標の定義、ソリューションの境界設定、利害関係者と意思決定者の特定、ユーザータスク、イベント、応答の調査、データの概念と関係の評価、品質属性の取り扱い、要件の分析、モデリング、優先順位付け、要件の明確かつ整理された方法での記述、要件のレビュー、テスト、変更管理などが含まれています。Software Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon本当に良い内容だったのですが自分が本として言及するには深すぎる内容だったのでざっくり雰囲気を知りたい人はこちらのブログを確認してほしいです。agnozingdays.hatenablog.comシステム障害対応 実践ガイド『3カ月で改善！システム障害対応 実践ガイド』は、システム障害対応とプロセス改善の実践的なアプローチを提供する画期的な本です。著者の野村浩司氏と松浦修治氏は、それぞれNTTデータとリクルートでの豊富な経験を基に、実際の業務に即した方法を提供しています。本書の大きな特徴は、障害対応の具体的な手法を「メソッド化」している点です。理論だけでなく、「どうすればいいのか？」という実践的な問いに答えており、情報システム担当者や運用リーダーにとって最適な内容となっています。また、本書は障害対応の本質的価値にも触れています。障害対応の改善は、顧客満足度、従業員満足度、そして財務観点からもプラスの効果をもたらします。この点を丁寧に説明しており、運用担当者のモチベーション向上にも寄与する内容です。大規模な障害対応経験がない方でも、対応のイメージがつかめるように工夫されています。障害対応の難所にも言及し、読者が共感しやすい内容となっています。システム障害が起こりうるすべての現場の人々に推奨されるこの本は、システム障害対応をどのように捉え、判断し、対応するべきかについてのフローや表を豊富に掲載しています。これらは特にシステム障害マニュアルが整備されていないチームにとって非常に有用です。1000件以上の事例を分析し生み出されたこのメソッドは、障害対応改善のための役立つ雛形と共に、3カ月での改善を可能にします。インシデント分析から障害訓練まで、各プロセスに役立つ情報が満載です。システム障害対応における課題の特定から改善ステップまで、具体的なガイダンスを提供し、障害対応を改善するための実践的な指針を提供します。3カ月で改善！システム障害対応 実践ガイド インシデントの洗い出しから障害訓練まで、開発チームとユーザー企業の「協同」で現場を変える作者:野村 浩司,松浦 修治翔泳社Amazonまた、SREの観点からいうと『Implementing Service Level Objectives』は、SLO文化をゼロから構築するための具体的なガイダンスを提供する貴重な本です。著者のAlex Hidalgoは、ユーザーの視点からサービスの信頼性を測定するSLIの定義、SLO目標の選択と統計的分析、エラーバジェットの利用方法など、SLOベースのアプローチに必要なツールとリソースの構築について詳しく説明しています。このガイドは、SLOデータを活用して経営陣やユーザーに意味のあるレポートを作成する方法を含め、SLOの実装に関わる全てのステークホルダーにとって非常に価値ある本なので読んでほしいです。この分野では「Webエンジニアのための監視システム実装ガイド」、「運用設計の教科書 ~現場で困らないITサービスマネジメントの実践ノウハウ」などもとてもおもしろかったのでおすすめです。learning.oreilly.com国内でもIncident Responseの勉強会があったり、Awesome Incident Responseなどがあるので一読して見るのがよいかなって思いました。incident-response.connpass.comコンテナセキュリティ『コンテナセキュリティ：コンテナ化されたアプリケーションを保護する要素技術』は、Liz Riceによる原著『Container Security: Fundamental Technology Concepts that Protect Containerized Applications』の翻訳版で、コンテナセキュリティに関する深い理解を提供してくれる本です。www.youtube.comこの本は、コンテナへの攻撃経路、Linuxの構造、コンテナの堅牢化、設定ミスによるセキュリティ侵害のリスク、コンテナイメージビルドのベストプラクティスなど、コンテナセキュリティに関する要素技術を幅広くカバーしています。開発者、運用者、セキュリティ専門家にとって、コンテナセキュリティの理解を深めるための優れた本であり、翻訳を担当しました。コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術作者:Liz Rice,株式会社スリーシェイク　監修,水元 恭平　訳,生賀 一輝　訳,戸澤 涼　訳,元内 柊也　訳インプレスAmazon一方で、同様の本もリリースされております。『基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策』は、森田浩平著による、コンテナセキュリティの基本から応用までを解説した本です。Dockerの普及に伴い、コンテナ技術が広く使用されていますが、そのセキュリティ面についての理解が不十分な点が多々あります。この本は、コンテナ利用時のセキュリティ上の問題を防ぎ、安全に活用するための基本的なガイダンスを提供します。コンテナ型仮想化の概要、コンテナの主要な攻撃ルート、堅牢なコンテナイメージの作り方、セキュアなコンテナ環境の構築など、実践的な内容が盛り込まれています。ちなみにContainer Security Book というこれから Linux コンテナのセキュリティを学びたい人のための文書を公開しているのでこちらを最初に読んでみるのが良いかと思います。基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策 (Software Design plusシリーズ)作者:森田 浩平技術評論社Amazonこれらの本は、コンテナセキュリティに関心が高いエンジニアにとって、理論と実践のバランスを持ち、現代のコンテナ環境で必要とされる重要な知識とスキルを提供します。コンテナ技術のセキュリティ面に関する包括的な理解を深めるために、有益です。ちなみに『Docker: Up & Running, 3rd Edition』が2023年にリリースされました。コンテナ技術に関するめちゃくちゃ有用な本です。この最新版は、Sean KaneとKarl Matthiasによって、Dockerの登場から約10年間の大きな変化に対応して大幅に更新されています。知識の新陳代謝のためにもぜひ、読んでみてください。この本では、DockerやLinuxコンテナがクラウドサービスやKubernetesとどのように統合されるか、OCIイメージの構築、Linuxコンテナのデプロイと管理、依存関係管理やアプリケーションのデプロイワークフローの単純化、本番環境でのLinuxコンテナのデプロイとテストの実用的なテクニックなど、広範囲にわたるトピックが取り上げられています。BuildKit、マルチアーキテクチャイメージサポート、ルートレスコンテナなど、新機能の追加カバレッジもあります。learning.oreilly.comTerraform: Up and Running, 3rd Edition『Terraform: Up and Running, 3rd Edition』は、Terraformについての優れた入門書です。とりあえず、何も考えずにTerraform を書くなら読んでほしいです。本書は、Terraformを使用して、様々なクラウドや仮想化プラットフォームでインフラをコードとして定義、立ち上げ、管理する方法を示しています。著者Yevgeniy (Jim) Brikmanは、Terraformのシンプルで宣言的なプログラミング言語を通じて、インフラを数コマンドでデプロイおよび管理する方法を示すコード例を提供しています。この第3版は、Terraform 1.0に対応するために大幅に拡張され、最新の情報が追加されています。Terraformの基本から、大量のトラフィックをサポートし、大規模な開発チームを運営できるフルスタックの実行まで、システム管理者、DevOpsエンジニア、初心者開発者が素早く学べる内容になっています。本書の最大の特徴は、ただコードをコピー＆ペーストするのではなく、読者自身に実際に作業を行わせることを強く推奨している点です。実際に手を動かして学ぶことが、Terraformの理解を深める最善の方法だと著者は語っています。また、gitやdockerなど、本書で使用されるすべての技術について、読者が日常業務で別のツールを使用している場合でもついていけるようにミニチュートリアルが用意されています。さらに、本書は、IaC（Infrastructure as Code）とDevOpsの実践、Terraform、パブリッククラウド、バージョンコントロールの統合、プロビジョニングツールを通じてインフラを作成・デプロイする効果について、基本から細かなニュアンスまでをわかりやすく説明しています。実際にコードを書いてテストする経験は、初心者にとって非常に価値のある学びの機会となります。Infrastructure as Code の3版もEarly Releaseされています(翻訳されて...)。learning.oreilly.comTerraformは進化し続けており、最新機能は絶えず追加されています。例えばTerraform v1.6のtestが追加されますが本書では一切触れられておりません。そのため、最新のリリースや動向に注意を払い続けることが重要です。また、HashiCorpがTerraformを含む自社製品のライセンスをオープンソースから変更したこともあり、今後もその動向に注目する必要があるでしょう。Terraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名総じて、TerraformやIaCを学び、理解し、実践したい人にとって、非常におすすめの入門 本です。翻訳本が2023年11月21日に出ましたね。幸せです。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy Brikmanオーム社AmazonEfficient Go『Efficient Go: Data-Driven Performance Optimization』は、計測方法や目的設定から方法から始まり、様々なレベルでの効率を最適化する方法、CPUやメモリなどの一般的なリソースを効果的に使用する技術、Prometheus、Jaeger、Parcaなどのオープンソースプロジェクトを通じてメトリクス、ログ、トレーシング、（連続的な）プロファイリングによる効率評価方法、go test、pprof、benchstat、k6などのツールを使用して信頼性のあるマイクロおよびマクロベンチマークを作成する技術に至るまで、幅広い内容が網羅されています。また、Goの機能であるスライス、ジェネリクス、ゴルーチン、割り当てセマンティクス、ガベージコレクションなどを効率的に使用する方法についても解説されており、記事として散見されるものがまとめて読めることと自体に勝ちがある。加えて最適化の限界を超えると、得るものと失うものが等しくなるみたないマインドセットの部分も含めてとても価値があるのでGoやシステムの最適化を目指す方には必読の内容かと思います。Efficient Go: Data-Driven Performance Optimization作者:Plotka, BartlomiejOreilly & Associates IncAmazonKubernetes Best Practices, 2nd Edition『Kubernetes Best Practices, 2nd Edition』は、Kubernetesを活用してアプリケーションを構築するプロセスに焦点を当てた実践的なガイドです。著者たちは、分散システム、エンタープライズアプリケーション開発、オープンソース分野での豊富な経験を活かし、最新のKubernetesの機能や新しいツールに関する知見を提供しています。この本は、Kubernetesの基本概念に精通しているが、最新のベストプラクティスに迅速に対応したい開発者やアーキテクトに最適です。また、既にある程度の知識を持っている方にとって、知識を更新し、新たな視点を得るためのデトックスにも役立ちます。入門書を読みたいならKubernetes: Up and Running, 3rd Editionを読めばよいとおもいます。最新のKubernetesの機能、新しいツール、および廃止された機能についてカバーされており、意外と知らなかったり古くなっている知識があったので知識のデトックスにもオススメです。一方で、『Kubernetes Patterns, 2nd Edition』は、クラウドネイティブアプリケーションの設計と実装におけるパターンと原則に重点を置いています。著者のBilgin IbryamとRoland Hussは、再利用可能なパターンとKubernetesに特化した解決策を提供し、具体的なコード例を通じてこれらのパターンを実演します。読者は、コンテナベースのクラウドネイティブアプリケーションの構築と運用に関する基本原則や、より複雑なトピックを含む様々なパターンを学ぶことができます。個人的にはKubernetes Best Practices, 2nd Editionは良識ある大人が寄ってきてKubernetesについて手取り足取り教えてくれる本。learning.oreilly.comKubernetes Patterns, 2nd Edition はKubernetes について知りたいって言ったら勢いよくオタクが寄ってきてその全てを教えて去っていく本。learning.oreilly.com総じて、『Kubernetes Best Practices』はKubernetesの進んだ使い方やベストプラクティスに焦点を当てており、『Kubernetes Patterns』はKubernetesを用いたアプリケーション設計における具体的なパターンと原則に重点を置いています。どちらの本も、Kubernetesの利用を最大限に活かしたいと考える技術者にとって読んで損のない二冊だと思います。ルールズ・オブ・プログラミング『ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール』は、大ヒットゲーム『Ghost of Tsushima』の開発現場で培われた、ゲーム制作スタジオSucker Punch Productionsの共同創設者であるChris Zimmermanによる、すべてのプログラマーにとって必読のプログラミング哲学です。この本では、プログラミングに関する21の本質的なルールが紹介されており、単純化とバランスの取り方、バグの扱い、命名の重要性、一般化のプロセス、最適化のタイミング、コードレビューの価値、失敗の回避、実行されないコードの対応、複雑性の管理など、プログラミングにおける幅広いトピックにわたる洞察が提供されています。C++で書かれたコード例を用いながらも、C++の知識がない読者でも理解できるよう配慮されており、PythonやJavaScriptプログラマー向けのC++コード読解法も掲載されています。この本は、入門書では決してないですがトレードオフを意識したことがある全てのプログラマーにとってプログラミングの日々の課題を解決し、優れたコードを書くための実践的なガイドとして推奨されます。あと、この本はWIP: 2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるでも紹介した『プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ』の後に読んだのでそれらの制約やルールは人間の脳や認識の制約によって成り立っているものだなって思いました。ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール作者:Chris Zimmermanオーム社Amazonこちらは、『ルールズ・オブ・プログラミング』を2倍楽しむための1つのルール というイベントの動画があるのでぜひご覧いただきたいです。www.youtube.com『Good Code, Bad Code』は、Googleのテックリードである著者が、高品質なコードを書くための「コーディングの4つのゴール」と「品質6つの柱」を提案しています。この本は、コードの読みやすさ、誤用の防止、モジュール化、再利用性、テストのしやすさなど、日々の開発業務で直面する課題に対して、具体的で実践的なアドバイスを提供しています。著者の経験に基づいたアプローチは、プログラミングにおける理想論ではなく、現実的で実用的な解決策を提示しています。この本は、コードの品質を高めるための具体的な手法として「コーディングの4つのゴール」と「品質6つの柱」を提示しています。「コーディングの4つのゴール」には、1) 正しく動くこと、2) 正しく動作し続けること、3) 要件の変更に対応しやすいこと、4) 車輪の再発明をしないこと、が含まれます。これらのゴールは、コードの堅牢性と信頼性を保ちながら、変化に柔軟に対応できることを重視しています。また、「コード品質の6つの柱」は、1) 読みやすさ、2) 想定外の事態をなくす、3) 誤用しにくいコードを書く、4) モジュール化、5) 再利用・汎用化のしやすさ、6) テストのしやすさと適切なテスト、に焦点を当てています。これらは、コードを効果的かつ効率的に管理するための基本的な要素であり、エンジニアが日々の開発業務で直面する課題を解決するための実践的なアドバイスを提供しています。Good Code, Bad Code ～持続可能な開発のためのソフトウェアエンジニア的思考作者:TomLong,秋勇紀,高田新山,山本大祐秀和システムAmazonあと、忘れてほしくないのが我らがKent Beck先生の『Tidy First?』（日本語訳：まずは整理整頓）です。この実践的ガイドでは、エクストリーム・プログラミングの創始者でありソフトウェアパターンの先駆者である著者が、コードを読みやすく整理する「タイディング（Tidying）」の適切なタイミングと場所を提案しており、大きな関数や複雑なシステムを小さなステップで安全に改善する方法、ソフトウェア設計の理論的な側面と実践的なスキルの融合など、人間関係の観点からのソフトウェア設計を深く掘り下げています。この本は、単にコードを綺麗にするテクニックを教えるだけでなく、ソフトウェアの品質を向上させ、開発プロセスを効果的かつ効率的にするための全体的な視野を提供してくれます。技術コンサルティングを行う上で、この本を参考にする機会が多く、多くのプロジェクトでその洞察とアプローチが非常に役立ちました。learning.oreilly.comこれらの本に本当に優劣とかないですが同系統の書籍なので一緒に紹介させていただきました。さいごに今年一年を通して読み漁った数々の技術書は、私にとって新たな知識の扉を開く鍵となりました。それぞれの本が持つ独自の視点や深い洞察は、技術者としての私の視野を広げ、思考を豊かにしてくれました。皆さんからのおすすめの本も、来年の読書リストに加えて楽しみにしています。読書は単なる趣味ではなく、私たちの知識を形成し、成長させる重要な行為です。皆さんも、来年は私と一緒に、新たな知識の探求に挑戦してみませんか？ それでは、2024年も充実した読書ライフをお過ごし下さい。読書を通じて、皆さんが新しい自分を発見し、さらなる成長を遂げる一年となりますように。","link":"https://syu-m-5151.hatenablog.com/entry/2023/12/02/141455","isoDate":"2023-12-02T05:14:55.000Z","dateMiliSeconds":1701494095000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"走馬灯のIaCは考えておいて","contentSnippet":"走馬灯のIaCは考えておいてというタイトルで登壇してきました\r\r技術的負債に向き合う Online Conference\rhttps://findy.connpass.com/event/297813/\r\r走馬灯のセトリは考えておいての短編はどれも面白いのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015282/\r\r登壇ブログ |『走馬灯のIaCは考えておいて』というタイトルで登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","link":"https://speakerdeck.com/nwiizo/zou-ma-deng-noiachakao-eteoite","isoDate":"2023-11-21T05:00:00.000Z","dateMiliSeconds":1700542800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『走馬灯のIaCは考えておいて』というタイトルで登壇しました。","contentSnippet":"概要2023年11月23日、私は技術的負債に向き合う Online Conference 」にて「走馬灯のIaCは考えておいて - Infrastructure as Codeの導入において技術的負債を考える」というテーマで登壇しました。このセッションでは、Infrastructure as Code（IaC）の実践方法と、技術的負債に対処する際の考慮点について深掘りしました。資料かなり概念系の資料になっているので実践編の登壇の登壇したいので誰か招待してくれ！！！この辺を先に整理しておかないと先の進化的アーキテクチャやA Philosophy of Software Designの話ができないので前提条件をまとめておきました。 speakerdeck.com技術的負債というメタファー に対する違和感私は、技術的な負債についての一般的な表現に違和感を感じています。この点で、まつもとりーさんも技術的負債という表現に対して抵抗を感じていたようです。M年N回目なんですけど、技術的負債という言語化にはずっと抵抗がありまして.......困ったな— まつもとりー / Ryosuke Matsumoto (@matsumotory) 2023年11月21日  この言葉の「負債」という部分が、技術的な問題の本質や性質を正確に捉えていないと感じたため、私は「技術的な腐敗と発酵」という言葉に置き換えることにしました。この新しいメタファーは、技術的問題が時間の経過とともに変化し、時には複雑化や悪化するプロセスをより的確に表現しています。例えば、「腐敗」は、問題が放置されることでシステムの健全性が低下する様子を示し、「発酵」は、初めは小さな問題が時間とともに変化し、場合によっては新たな価値を生み出す可能性があることを意味します。この観点から、私は自身のプレゼンテーションや議論の中で、技術的な問題を扱う際にこれらの言葉を使用しました。普通に元ネタがあります。メタファーとしての発酵 (Make: Japan Books)作者:Sandor Ellix KatzオライリージャパンAmazon実生活の発酵と腐敗の違い実生活における「発酵」と「腐敗」はどちらも微生物の作用による物質の変化プロセスであり、人間にとっての利益に基づいて定義されます。発酵は、生物の作用によって物質が変化し、人間にとって有益なものに変わるプロセスを指し、ヨーグルト、チーズ、醤油などが例として挙げられます。一方、腐敗は同じく微生物の作用による物質の変化ですが、不快な臭いや有害な物質が発生し、人間にとって有害とされるプロセスを指します。この考え方は、インフラの世界にも当てはまります。時間の経過とともに技術が進化し、新しい技術が古い技術に取って代わることが多い中で、長く使用され信頼性が高まった「枯れた技術」は発酵に、時代遅れとなりリスクを引き起こす技術は腐敗に例えられます。これにより、古い技術を見直し、必要に応じて新しい技術に移行するかの判断が容易になり、インフラの健全性と持続可能性を保つ上で重要な役割を果たします。発酵と腐敗・熟成の違いって何？負債と言わないことが負債と向き合うこと「負債と言わないことが負債と向き合うこと」という素晴らしい発表があった。メタファーの限界と実際の技術的課題への取り組みの重要性を改めて感じました。この発表は、言葉だけでなく、根本的な問題解決に焦点を当てることの大切さを示しています。私は向き合わずに逃げたので...。確かに、メタファーは理解を深めるための一つの手段ですが、それにとどまらず、具体的な問題や課題に目を向け、解決策を見つけて実行することが不可欠です。この点において、私は自分の業務、特にSRE（Site Reliability Engineering）の領域において「トイル」という用語が使われていることに気づきました(これも状況を整理するためのメタファーではある)。「トイル」とは、SREのコンテキストで使われる用語で、繰り返し行われる、自動化されていない、戦略的価値の低い作業を指します。この用語を用いることで、SREは単に作業を行うのではなく、その作業がなぜ存在し、どのように改善できるかを考えるように促されます。このような言葉の使い方は、メタファーを超えて、実際の作業の性質や価値を正確に捉え、それに基づいて改善策を模索する手助けとなります。最終的には、このような言葉の使い方が、より効果的で生産的な仕事に取り組むことができます。言葉は単なるコミュニケーションの道具ではなく、私たちの思考や行動に影響を与える強力なツールです。そのため、技術的な課題に取り組む際には、適切な用語を選び、それを戦略的に活用することが重要です。sreake.com speakerdeck.com何が技術的負債に変わるのか技術的負債という言葉のメタファーとしての強さ。技術的負債に向き合う幾つかのヒントをいくつかいただいたので気になった人はぜひ、読んでみてほしい。junkyard.song.mu決定版・ゲームの神様 横井軍平のことばが気になったのでAmazonで調べたところ2023年11月21日現在では20000円だった。ソフトウェアの内部品質に生じる様々な問題は組織設計にその原因があることも多い良い内容だったので感想書く speakerdeck.com異なる思想で書かれたコードの統一に動く -Terraformの場合-良い内容だったので感想書く speakerdeck.com技術的負債が生まれる背景を理解して，アーリーからレイター向けの根本的なアプローチを考える良い内容だったので感想書く speakerdeck.com参考資料Infrastructure as CodeInfrastructure as Code 再考Infrastructure as Codeのこれまでとこれから/Infra Study Meetup #1わたしたちにIaCはまだ早かったのかもしれないThe History of DevOps ReportsEffective DevOpsLeanとDevOpsの科学[Accelerate] テクノロジーの戦略的活用が組織変革を加速する継続的デリバリーのソフトウェア工学:もっと早く、もっと良いソフトウェアを作るための秘訣メタファーとしての発酵Hashicorp DeveloperChef InfraAnsible - Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain.aws-cdk - The AWS Cloud Development Kit is a framework for defining cloud infrastructure in codePulumi - Infrastructure as Code in any programming language.dapr - Dapr is a portable, event-driven, runtime for building distributed applications across cloud and edge.dagger - Application Delivery as Code that Runs AnywhereInfrastructure as Code, 3rd EditionPlatform Engineering MeetupBackstage - Backstage is an open platform for building developer portalsbackstage.ioWhat is platform engineering?DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティスウェブオペレーション―サイト運用管理の実践テクニック","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","isoDate":"2023-11-21T04:21:44.000Z","dateMiliSeconds":1700540504000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文","contentSnippet":"はじめに前回の続きで第四部のV. Delivering Infrastructure (インフラストラクチャの提供)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第五部 目次V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)この章では、スタック定義、サーバー設定、モジュール、ライブラリ、テスト、設定、ユーティリティなど、さまざまな種類のコードが含まれる可能性があります。これらのコードをプロジェクト間およびリポジトリ内でどのように整理するか、またインフラストラクチャコードとアプリケーションコードを一緒に管理するべきか、分けるべきかという問題が提起されています。これには、複数部分からなるエステートのコードをどのように整理するかという課題も含まれます。Organizing Projects and Repositoriesこのセクションでは、プロジェクトがシステムの個別のコンポーネントを構築するために使用されるコードの集まりであると説明されています。プロジェクトやそのコンポーネントがどれだけ含むべきかについての硬いルールはありません。プロジェクト間の依存関係と境界は、プロジェクトコードの整理方法に明確に反映されるべきです。コンウェイの法則によれば、組織の構造とそれが構築するシステムの間には直接的な関係があります。チーム構造とシステムの所有権、およびそれらのシステムを定義するコードの不整合は、摩擦と非効率を生み出します。One Repository, or Many?複数のプロジェクトを持つ場合、それらを単一のリポジトリに入れるべきか、複数のリポジトリに分散させるべきかという問題があります。コードを同じリポジトリに保持すると、バージョン管理やブランチ化が一緒に行えるため、いくつかのプロジェクト統合およびデリバリー戦略を簡素化します。One Repository for Everythingすべてのコードを単一のリポジトリで管理する戦略は、ビルド時のプロジェクト統合パターンでうまく機能します。この戦略では、リポジトリ内のすべてのプロジェクトを一緒にビルドしますが、アプリケーションパッケージ、インフラストラクチャスタック、サーバーイメージなど、複数の成果物を生み出すことがあります。Figure 18-1. Building all projects in a repository togetherA Separate Repository for Each Project (Microrepo)各プロジェクトごとに別のリポジトリを持つ戦略は、プロジェクト間のクリーンな分離を保証します。特に、各プロジェクトを別々にビルドしてテストするパイプラインを持つ場合に効果的です。Multiple Repositories with Multiple Projects一つのリポジトリですべてを管理する極端な戦略と、各プロジェクトごとに別のリポジトリを持つ極端な戦略の間で、多くの組織は複数のリポジトリを持ち、複数のプロジェクトを含む方法を採用しています。Organizing Different Types of Code異なるタイプのコードを整理する戦略を持つことは、コードベースを維持可能にするのに役立ちます。例えば、スタックのプロジェクトレイアウトは、インフラストラクチャスタックコード、テストコード、設定ファイル、デリバリー設定などを含む可能性があります。Delivering Infrastructure and Applicationsアプリケーションとインフラストラクチャのコードを一緒に管理するか、別々にするかという選択は、組織の構造と所有権の分割に依存します。アプリケーションチームがインフラストラクチャに関する責任を持つ場合、コードを分けることは認知的な障壁を生み出す可能性があります。システムのインフラストラクチャのアーキテクチャ、品質、および管理をコードベースから導くという概念を持っています。したがって、コードベースはビジネス要件とシステムアーキテクチャに応じて構築され、管理される必要があります。それはまた、チームが効果的であるためのエンジニアリング原則と実践をサポートする必要があります。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)インフラストラクチャコードのデリバリーについての章では、ソフトウェアのデリバリーライフサイクルが重要なコンセプトとして強調されています。しかし、インフラストラクチャのデリバリーは、しばしば異なるタイプのプロセスに従います。例えば、本番環境でテストされないハードウェアの変更が一般的です。しかし、コードを使ってインフラストラクチャを定義することで、より包括的なプロセスで変更を管理する機会が生まれます。例えば、サーバーのRAMを変更するような手動で構築されたシステムへの変更を開発環境で複製することは、ばかげているように思えるかもしれません。しかし、コードで実装された変更は、パイプラインを通じて本番環境へ簡単に展開することができます。Delivering Infrastructure Codeパイプラインのメタファーは、インフラストラクチャコードの変更が開発者から本番インスタンスへ進む方法を説明しています。このデリバリープロセスに必要なアクティビティは、コードベースの整理方法に影響を与えます。Figure 19-1. Infrastructure code project delivery phasesBuilding an Infrastructure Projectインフラストラクチャプロジェクトのビルドは、コードを使用するための準備を行います。これには、ライブラリの取得、ビルド時の設定の解決、コードのコンパイルまたは変換、テストの実行、ツールが適用するためのフォーマットでコードを準備することなどが含まれます。Packaging Infrastructure Code as an Artifact一部のツールでは、「コードの使用準備」は特定のフォーマットのパッケージファイルにファイルを組み立てることを意味します。これは、Ruby（gems）、JavaScript（NPM）、Python（pipインストーラーを使用するPythonパッケージ）などの一般的なプログラミング言語で一般的なプロセスです。Using a Repository to Deliver Infrastructure Codeチームはソースコードリポジトリを使用して、インフラストラクチャソースコードの変更を保存し、管理します。多くのチームは、環境やインスタンスにデリバリーする準備ができたコードを保存するために、別のリポジトリを使用します。Figure 19-2. Build stage publishes code to the delivery repositoryIntegrating Projects「Organizing Projects and Repositories」で述べたように、コードベース内のプロジェクト間には通常、依存関係があります。次に、互いに依存するプロジェクトの異なるバージョンをいつ、どのように組み合わせるかという問題があります。Pattern: Build-Time Project Integrationビルド時のプロジェクト統合パターンは、複数のプロジェクトをまたいでビルドアクティビティを実行します。これには、それらの依存関係を統合し、プロジェクト間のコードバージョンを設定することが含まれます。Pattern: Delivery-Time Project Integrationデリバリー時のプロジェクト統合パターンは、それぞれのプロジェクトを個別にビルドおよびテストした後で組み合わせます。このアプローチでは、ビルド時の統合よりも後の段階でコードのバージョンを統合します。Pattern: Apply-Time Project Integration適用時のプロジェクト統合は、複数のプロジェクトを別々にデリバリーステージを進めることを含みます。プロジェクトのコードに変更が加えられたとき、パイプラインはそのプロジェクトの更新されたコードをそのプロジェクトのデリバリーパスの各環境に適用します。Using Scripts to Wrap Infrastructure Tools多くのチームは、インフラストラクチャツールをオーケストレーションし、実行するためにカスタムスクリプトを作成します。これには、Make、Rake、Gradleなどのソフトウェアビルドツールを使用する場合や、Bash、Python、PowerShellでスクリプトを書く場合があります。多くの場合、このサポートコードはインフラストラクチャを定義するコードと同じくらい、またはそれ以上に複雑になり、チームはそのデバッグと維持に多くの時間を費やすことになります。確実で信頼性の高いインフラストラクチャコードのデリバリープロセスを作成することは、4つの主要なメトリクスに対して良好なパフォーマンスを達成するための鍵です。あなたのデリバリーシステムは、システムへの変更を迅速かつ信頼性高くデリバリーすることの実際の実装です。Only build packages once. を参考にしてください。20. Team Workflows (チームワークフロー)IaCを利用することによる作業方法の根本的な変化に焦点を当てています。従来のアプローチとは異なり、仮想サーバーやネットワーク構成の変更をコマンド入力やライブ設定の直接編集ではなく、コードの記述と自動化システムによる適用を通じて行います。これは新しいツールやスキルの習得を超えた変化であり、インフラストラクチャを設計、構築、管理する全ての人々の働き方に影響を与えます。Figure 20-1. A classic mapping of a dedicated team to each part of a workflowThe People信頼できる自動化ITシステムでは、人々が重要な役割を果たします。コード変更を本番システムに反映させるためには、テスト結果のレビューやボタンの操作以外に、人の手は必要ありませんが、システムの継続的な構築、修正、適応、改善には人間が不可欠です。Who Writes Infrastructure Code?組織によってインフラストラクチャコードを誰が書くかという問いに対する答えは異なります。伝統的なプロセスとチーム構造を維持しようとする組織では、インフラストラクチャを構築（およびサポート）するチームがインフラストラクチャ・アズ・コードのツールを使用して作業を最適化します。また、多くの組織ではアプリケーションチームが自分たちのアプリケーションに必要なインフラストラクチャを定義しています。Applying Code to Infrastructureインフラストラクチャへのコード適用に関する一般的なワークフローは、共有ソースリポジトリ内のコードから始まります。チームメンバーは最新バージョンのコードを自分の作業環境にプルし、編集した後、ソースリポジトリにプッシュして新しいバージョンのコードを様々な環境に適用します。Applying Code from Your Local Workstationローカルワークステーションからインフラストラクチャコードを適用することは、他の誰も使用していないインフラストラクチャのテストインスタンスに対しては有用です。しかし、ローカル作業環境からツールを実行すると、共有インフラストラクチャインスタンスに問題を引き起こす可能性があります。Applying Code from a Centralized Serviceインフラストラクチャコードをインスタンスに適用するために、中央集権的なサービスを使用できます。このサービスはソースコードリポジトリまたはアーティファクトリポジトリからコードをプルし、インフラストラクチャに適用します。Personal Infrastructure Instances理想的には、共有リポジトリにプッシュする前にコード変更をテストできる方法があります。これにより、変更が期待通りの動作をするかどうかを確認でき、パイプラインがオンラインテストステージまでコードを実行するのを待つよりも高速です。Source Code Branches in Workflowsソースリポジトリのブランチは、コードベースの異なるコピー（ブランチ）で作業を行い、準備ができたら統合する際に役立ちます。Martin Fowlerの記事「Patterns for Managing Source Code Branches」には、チームのワークフローの一部としてブランチを使用する様々な戦略やパターンが説明されています。Preventing Configuration Drift設定のドリフトを防ぐために、ワークフローにおいていくつかの対策を講じることができます。これには、自動化の遅れを最小限に抑える、アドホックな適用を避ける、コードを継続的に適用する、不変のインフラストラクチャを使用するなどが含まれます。Governance in a Pipeline-based Workflowパイプラインベースのワークフローにおけるガバナンスでは、責任の再配置、左へのシフト、インフラストラクチャ・アズ・コードのガバナンスを持つ例示プロセスなどが議論されます。インフラストラクチャをコードとして定義する組織では、人々は日々のルーチン活動やゲートキーパーとしての作業に費やす時間が減り、システム自体の改善能力を向上させるためにより多くの時間を費やすことになるはずです。彼らの努力は、ソフトウェアのデプロイおよび運用パフォーマンスの4つの指標に反映されます。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)Chapter 21: Safely Changing Infrastructure21. Safely Changing Infrastructure本章では、インフラの迅速かつ頻繁な変更の重要性に焦点を当てています。私のSREとしての経験では、速さと安定性は相補的な要素であることが多くのプロジェクトで証明されています。特に、インフラストラクチャー・アズ・コード(IaC)の実践において、このアプローチは効率と品質を大幅に向上させることができます。変更の頻度を上げることで、小さな問題を迅速に検出し、修正することが可能になります。Reduce the Scope of Change小さな変更の範囲を制限することは、リスクの軽減に寄与します。私の経験からも、小さな変更ほど管理が容易であり、予期せぬ問題への対応も迅速になるということが証明されています。このアプローチは、大規模な変更を小分けにして取り組むことで、変更の複雑性とリスクを管理するのに有効です。Figure 21-2. Plan to split out multiple stacksSmall Changes小さな変更を積極的に行うことの利点は、私のプロジェクト経験で明らかです。バッチサイズを小さくすることで、リスクを最小限に抑え、より迅速なフィードバックを得ることが可能になります。これは特に複雑なシステムにおいて、問題の特定と修正を容易にします。小さな変更は、大きなリリースの複雑さを減らし、より継続的なデリバリーを可能にします。Example of Refactoringリファクタリングの例は、コードベースを改善し、将来の変更を容易にするための重要な手段です。実際、私の経験では、リファクタリングはしばしば次のステップへの道を開くための重要なプロセスであり、これによりコードの保守性と拡張性が向上します。リファクタリングは、既存の機能を維持しつつ、コードの構造を改善することで、新しい機能の追加や将来的な変更を容易にします。Pushing Incomplete Changes to Production不完全な変更を本番環境に押し出すことは、段階的なデプロイメントの一環として重要です。この戦略は、変更の影響を小さく保ちながらも、継続的な進化を促進します。特に、リリース前のテスト段階でのフィードバックを得るために役立ちます。Parallel Instances並行インスタンスの概念は、本番環境でのリスクを軽減する上で非常に効果的です。これにより、新しい変更を既存のシステムと並行してテストし、徐々に本番環境に移行することが可能になります。これは、特に大規模なシステムや重要な機能の更新において、ダウンタイムを避けるための重要な戦略です。Backward Compatible Transformations後方互換性を持つ変更は、サービスの中断を防ぎつつ進化を遂げるための鍵です。このアプローチにより、既存の機能を維持しつつ、新しい機能や改善を段階的に導入することができます。これは、システムの安定性を保ちながらも、進歩と成長を促すために非常に効果的です。Feature Toggles機能トグルは、新旧の機能を柔軟に管理できる強力なツールです。これにより、新しい機能を段階的に導入し、必要に応じて迅速に変更を反映することができます。段階的なデプロイメントやA/Bテストにおいてこの技術は特に有効で、リスクを最小限に抑えつつ、ユーザーの反応を評価することができます。Changing Live Infrastructureライブインフラの変更は、サービスの中断を最小限に抑えながらインフラを最新の状態に保つために不可欠です。このセクションでは、インフラストラクチャーの更新がサービスの連続性に与える影響を最小限に抑えるための技術と戦略が紹介されています。Infrastructure Surgeryインフラの手術は、既存のインフラを修正しつつサービスを維持するための洗練された方法です。これにより、サービスの中断を最小限に抑えながら、重要なインフラの変更や改善を行うことができます。このアプローチは、特にデータ損失のリスクを最小限に抑えたい場合や、既存のシステムを段階的に改善したい場合に有効です。Expand and Contract拡張と収縮のパターンは、インフラの柔軟性を最大限に活用する素晴らしい方法です。このアプローチは、リソースの効率的な利用とスケーラビリティの向上に寄与します。特にクラウド環境において、この手法を利用することで、リソースの迅速な拡張と収縮が可能になり、需要の変動に応じたスケーリングが実現できます。Zero Downtime Changesダウンタイムのない変更は、ユーザーエクスペリエンスを維持しつつ、システムのアップデートを行う上で非常に重要です。これにより、サービスの中断を防ぎつつ、新しい機能や修正を順次適用することができます。この手法は、特にユーザーへの影響を最小限に抑えたい場合に有効です。Continuity継続性は、変更管理における中心的な考え方です。エラーを防ぐことによる継続性、速やかな回復による継続性、継続的な災害復旧、カオスエンジニアリング、そして失敗計画は、システムの安定性と耐久性を確保するために重要な要素です。これらのアプローチは、リスクを軽減し、システムの回復力を高めるのに役立ちます。Continuity by Preventing Errorsエラーを予防することによる継続性は、事前の計画と迅速な回復のバランスを取ることが重要です。このアプローチにより、システムの安定性を維持しながら、予期せぬ問題に迅速に対応することが可能になります。エラーの予防と迅速な修正は、特に大規模なシステムにおいて、サービスの連続性と信頼性を確保するために不可欠です。Continuity by Fast Recovery速やかな回復による継続性は、現代のインフラにおいて不可欠な要素です。システムの迅速な回復は、特に予期せぬ障害やエラーが発生した場合に、サービスの中断を最小限に抑えるために重要です。これは、特にビジネスクリティカルなアプリケーションやサービスにおいて、信頼性と利用可能性を確保するための鍵となります。Continuous Disaster Recovery継続的な災害復旧は、システムの耐障害性を高め、ビジネスの継続性を保証するために不可欠です。このアプローチは、システムの変更に関連するリスクを管理し、不測の事態が発生した場合に迅速に対応できるようにすることが重要です。私の経験では、継続的な災害復旧の計画と実施は、組織の全体的なリスク管理戦略の核心部分を形成します。これにより、システムが予期せぬ障害にも迅速に対応し、サービスの継続性を維持できるようになります。システムのバックアップと復旧プロセスを定期的にテストし、改善することで、災害発生時のリカバリー時間を短縮し、ビジネスへの影響を最小限に抑えることが可能です。Chaos Engineeringカオスエンジニアリングは、システムの弱点を明らかにし、それらを改善するための実践的なアプローチです。この手法は、システムの耐障害性を試験し、実際の環境での挙動を理解するのに非常に有効です。私のキャリアの中で、カオスエンジニアリングはシステムの弱点を早期に特定し、それに対処する機会を提供する重要なツールとなっています。意図的に障害を引き起こすことで、システムの回復力をテストし、実際の災害時に備えることができます。このようなプラクティスにより、システムの安定性と信頼性が向上し、ユーザー体験の質が保たれます。Planning for Failure失敗計画は、システムの回復力を高めるために重要です。失敗を計画することは、システムの弱点を特定し、それらに対応するための戦略を立てることを意味します。私が経験したプロジェクトでは、様々な失敗シナリオを想定し、それぞれに対する回復計画を策定することが、システムの全体的な堅牢性を高める上で非常に重要でした。失敗計画は、リスクの評価と緩和策の策定を通じて、システムの安全性と効率性を保証します。また、失敗に迅速かつ効果的に対応するための準備とプロセスを確立することで、ビジネスの中断を最小限に抑えることができます。Data Continuity in a Changing Systemデータの連続性は、変更のあるシステムにおいて最も重要な側面の一つです。私の経験では、データの安全性と一貫性を維持することは、サービスの品質と顧客信頼の基盤となります。Lockロック機能は、特定のリソースを変更から保護する効果的な方法です。しかし、自動化と手動の介入のバランスを見極めることが重要です。過度に手動の介入に依存することはリスクを高める可能性があります。Segregateデータを他のシステムコンポーネントから分離することにより、より柔軟かつ安全に変更を行うことが可能になります。このアプローチは、データを中心としたアーキテクチャ設計において特に有効です。Replicateデータの複製は、可用性と耐障害性の向上に寄与します。分散型データベースのようなシステムでは、データの複製が自動化されることが多く、このプロセスはデータの保護に不可欠です。Reloadデータの再ロードやバックアップは、データ損失を防ぐ上で基本的です。バックアップと復元のプロセスを自動化することで、データの信頼性とアクセス性が大幅に向上します。Mixing Data Continuity Approachesデータの継続性を確保する最善の方法は、分離、複製、再ロードの組み合わせです。この複合的なアプローチにより、データの安全性とアクセス性の両方を最大化できます。データの継続性は、単一の手法に依存するのではなく、複数の手法をバランスよく組み合わせることで、最も効果的に実現されます。この章の締めくくりでは、インフラ変更におけるデータの継続性の重要性が強調されています。クラウド時代におけるインフラ管理の進化に伴い、速度と品質のバランスを取りながらも、データの安全性を維持することの重要性が明確にされています。データはビジネスの中心にあり、その連続性と安全性を確保することが、サービスの品質と顧客信頼を維持するための鍵であることが再確認されます。総括 Infrastructure as Code, 2nd Edition の読書感想文『Infrastructure as Code, 2nd Edition』は、現代のITインフラストラクチャ管理の進化に対応するための重要なガイドです。この書籍は、インフラストラクチャをコードとして扱うことの重要性と、それを実現するための具体的な方法を体系的に説明しています。第一部では、インフラストラクチャをコードとして管理する基本原則に焦点を当て、クラウド時代のダイナミクスを解説しています。特に、変更の速度を利用してリスクを減らし、品質を向上させる新しいマインドセットの必要性が強調されています。第二部では、インフラストラクチャスタックの構築と管理に関して詳述し、スタックの構築、環境の設定、および継続的なテストと提供の重要性について論じています。ここでは、インフラストラクチャの自動化におけるスタックの重要性を明確にし、技術的な洞察と実践的な指針を提供します。第三部は、サーバーと他のアプリケーションランタイムプラットフォームとの作業に注目し、アプリケーションランタイム、サーバーのコード化、サーバーへの変更管理などを取り上げています。この部分は、アプリケーション主導のインフラストラクチャ戦略を通じて、現代の動的インフラを使用してアプリケーションランタイム環境を構築する方法に重点を置いています。第四部では、インフラストラクチャの設計に関して、小さく単純な部品の使用、モジュラリティ、コンポーネント設計のルール、モジュール化、およびスタックコンポーネントの設計パターンとアンチパターンについて論じています。このセクションは、効率的で持続可能なインフラストラクチャを設計するための具体的な方法とベストプラクティスを提供します。第五部では、インフラストラクチャコードの整理、提供、チームワークフロー、およびインフラストラクチャの安全な変更に焦点を当てています。インフラストラクチャコードの整理と管理、デリバリープロセス、プロジェクトの統合、および安全な変更の方法に関する洞察が提供されています。全体として、この書籍は、インフラストラクチャとしてのコードの採用と適用において、技術者や専門家に重要な洞察と価値ある情報を提供し、インフラストラクチャ管理の現代的なアプローチを実現するための実践的なガイドとなっています。その詳細な解説と実用的なアドバイスは、この分野で働く専門家にとって非常に役立つものです。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/161320","isoDate":"2023-11-16T07:13:20.000Z","dateMiliSeconds":1700118800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文","contentSnippet":"はじめに前回の続きで第四部のIV. Designing Infrastructure (インフラストラクチャの設計)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com次回の記事* Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第四部 目次IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)Designing for Modularityモジュラリティの設計は、システムの変更を安全かつ容易にすることを目的としています。これは、ソフトウェア開発経験においても非常に重要です。モジュール式の設計は変更管理を簡素化し、技術的負債の蓄積を防ぐ効果があります。インフラコードにおいても、このアプローチは同様に有効であり、システムの成長に伴う複雑さとリスクを管理するための鍵となります。コンポーネントをより小さく、単純に保つことで、システム全体の品質と反応性が向上します。Characteristics of Well-Designed Components良く設計されたコンポーネントは、低い結合度と高い凝集度を持ちます。これは、各コンポーネントが独立して機能し、他の部分に影響を及ぼすことなく変更可能であることを意味します。これらの特徴はシステムの長期的な安定性とメンテナンスの容易さに大きく貢献します。低結合度は、一部の変更が全体のシステムに広範な影響を与えるリスクを最小限に抑え、高凝集度は、コンポーネントがその機能に集中し、より効率的に動作することを可能にします。Rules for Designing Componentsコンポーネントの設計におけるルールには、重複の排除や単一責任原則などが含まれます。これらはコードの可読性と保守性を高め、変更を容易にします。重複の排除は、同じ機能やデータの複数のコピーを避けることで、変更時の労力を減らし、エラーの可能性を下げます。一方、単一責任原則は、各コンポーネントが一つの機能または責任を持つべきであるという原則です。これにより、システムはより整理され、理解しやすくなります。Use Testing to Drive Design Decisionsテスト駆動設計は、インフラコードの品質を向上させます。テストは、コードの継続的な改善を促進し、設計の効率化に寄与します。テスト可能なコードは、自然とより良い設計に導かれます。テストを重視することで、コードの変更が容易になり、新しい機能の追加や既存機能の改善がスムーズに行えるようになります。また、自動化されたテストは、システムの信頼性を確保し、デプロイメントプロセスを加速します。Modularizing Infrastructureインフラのモジュラー化は、システムの柔軟性とスケールアップを促進します。構成要素を効果的に分割することで、変更が容易になり、システムの拡張がスムーズに行えます。このアプローチは、インフラストラクチャの管理と運用においても有効であり、特に大規模なシステムでは、異なる部分を個別に更新、拡張、または縮小できる柔軟性が重要です。モジュール化されたインフラストラクチャは、変更のスピードを高め、システムの全体的な効率を改善します。Stack Components Versus Stacks as Componentsスタックコンポーネントとしてのスタックは、独立性を提供し、変更を容易にします。分離されたスタックは変更管理とスケーラビリティにおいて重要な役割を果たします。スタックとしてのコンポーネントは、システムの一部として独立してデプロイおよび管理することができ、これにより大規模な変更や障害が他の部分に波及するリスクを最小限に抑えます。Figure 15-1. Shared code module used by two stacks より引用Using a Server in a Stackスタック内でサーバーを使用することは、設定変更の容易さを提供します。これにより、運用上の柔軟性が高まります。サーバーをスタックの一部として扱うことで、サーバーの設定やソフトウェアの更新が簡単になり、システム全体のメンテナンスが容易になります。また、サーバーの迅速な追加や削除が可能となり、システムのスケーラビリティが向上します。Drawing Boundaries Between Componentsコンポーネント間の境界を適切に設定することは、システムの成長と変更を管理する上で重要です。これはシステムの安定性と拡張性を支えます。境界線を引くことで、システムの異なる部分を明確に区分し、それぞれが独立して機能し、互いに干渉しないようにします。これにより、システムの一部を変更しても、他の部分に予期しない影響を与えるリスクが減少します。Align Boundaries with Natural Change Patterns変更パターンに合わせた境界線は、システムの自然な進化を促進します。これにより、継続的な改善が可能になります。システムの異なる部分がどのように変化し、成長するかを理解することで、それらの部分を適切に区分することができます。これは、変更の管理を容易にし、システム全体の効率を高めます。Align Boundaries with Component Life Cyclesコンポーネントのライフサイクルに合わせた境界線は、管理の簡素化をもたらします。特定のコンポーネントの更新や交換が容易になります。例えば、頻繁に更新が必要なコンポーネントと、長期間安定して運用されるコンポーネントを区別することで、各コンポーネントをより効果的に管理することが可能になります。Align Boundaries with Organizational Structures組織構造に合わせた境界線の設定は、チーム間のコラボレーションを促進し、システムの全体的な一貫性を向上させます。Conwayの法則によれば、システムの設計はしばしばその開発を行う組織の構造を反映します。例えば、開発と運用が別々のチームによって行われる場合、それぞれのチームはシステムの異なる部分を管理することになり、結果としてシステム全体が分断されがちです。これを避けるためには、チームの組織構造をシステムのアーキテクチャに合わせて調整することが有効です。これにより、各チームは自分たちの責任範囲内で効率的に作業を進めることができ、全体としてのシステムの一貫性と効率が向上します。Create Boundaries That Support Resilience回復力を支持する境界線の設定は、システムの耐障害性と回復力を強化します。これは、特定のコンポーネントやサービスが障害に遭遇した場合に、システム全体が影響を受けるリスクを最小限に抑えることを意味します。例えば、システムの一部が故障した場合に、他の部分が正常に機能し続けるように設計することです。これにより、障害発生時にもシステムの主要な機能が維持され、迅速な回復が可能になります。また、このような設計は、障害発生時の影響範囲（ブラストラジアス）を小さくすることも目的としています。Create Boundaries That Support Scalingスケーリングを支持する境界線の設定は、システムの拡張性を高めることを目指します。これにより、需要の増大や減少に応じてシステムのリソースを柔軟に調整することが可能になります。例えば、特定のサービスやコンポーネントの利用が増加した場合に、追加のリソースを割り当てることで対応することができます。また、リソースの利用が減少した場合には、不要なリソースを削減してコストを節約することも可能です。このように、スケーリングを支持する境界線を設定することで、システムは変動する需要に柔軟に対応し、最適なパフォーマンスを維持することができます。Align Boundaries to Security and Governance Concernsセキュリティとガバナンスの懸念に合わせて境界線を設定することは、システムのセキュリティを強化し、規制遵守を容易にします。これは、異なるセキュリティ要件を持つシステムの部分に対して適切な保護措置を施すことを意味します。例えば、金融情報や個人データを扱う部分には、より厳格なセキュリティ対策が必要です。セキュリティとガバナンスに基づいて境界線を設定することにより、これらの要件を満たすための管理が容易になり、システム全体のセキュリティが向上します。この章は、インフラストラクチャをコードとして定義する際の、より小さな部分への分割の重要性を強調しています。分割されたコンポーネントは、変更、スケーリング、回復力の向上に寄与し、システム全体の運用効率を高めます。また、組織構造、セキュリティ、ガバナンスの観点から適切に境界線を設定することで、システムはより安全で管理しやすい状態になります。16. Building Stacks From Components (コンポーネントからスタックを構築する)Infrastructure Languages for Stack Componentsインフラストラクチャ言語の選択は、スタックコンポーネントの設計と実装において非常に重要です。宣言型言語は、その明確な構造と予測可能性により、特に大規模なシステムの設計において有効です。一方、命令型言語は、より動的で柔軟なシステムの構築に適しています。個人的な感覚では宣言型言語はインフラストラクチャの基本的な構造を定義するのに適しており、命令型言語はより複雑なロジックや条件分岐が必要な場面で役立ちます。Reuse Declarative Code with Modules宣言型コードのモジュール化による再利用は、システムの整合性を高め、変更の管理を容易にします。私は、モジュールを利用して共通の機能を効率的に管理し、コードベースの複雑さを減らすことができると感じています。宣言型言語で書かれたモジュールは、その明確さと一貫性により、特に大規模なプロジェクトや多くの開発者が関与する環境において有効です。Dynamically Create Stack Elements with Librariesライブラリを利用した動的なスタック要素の作成は、システムの設計における柔軟性を大幅に向上させます。命令型言語を用いることで、条件に応じたリソースの動的な生成や複雑なロジックの実装が可能になり、システムのカスタマイズが容易になります。これは、特に要件が頻繁に変更されるプロジェクトや、特定の条件に基づいて異なる動作をさせる必要があるシステムにおいて有用です。Patterns for Stack Componentsスタックコンポーネントを設計する際には、適切なパターンの選択が重要です。これにより、システムの一貫性、再利用性、そして将来の拡張性が向上します。良い設計パターンを採用することで、システム全体の品質を高めることができます。Pattern: Facade Moduleファサードモジュールは、複雑なリソースをよりシンプルに扱えるようにすることで、開発者の負担を軽減します。これは、複数のプロジェクトやチーム間で共通のリソースや設定を共有する際に特に有効で、一貫性のあるアプローチを提供します。ファサードモジュールを使用することで、開発者はより高度なタスクに集中でき、基盤となる複雑な詳細について心配する必要がなくなります。Antipattern: Obfuscation Moduleオブフスケーションモジュールは、実際には価値を追加せず、むしろシステムの複雑さを増加させるものです。このようなモジュールは、コードの可読性を低下させ、保守や拡張を困難にします。開発者がモジュールの背後にあるロジックを理解するのが難しくなり、結果として効率性が損なわれます。Antipattern: Unshared Module共有されていないモジュールは、その再利用性が低く、開発プロセスにおける効率性に欠けます。モジュール化の主な目的は、コードの再利用を促進することにありますが、この目的が達成されていない場合、モジュールの価値は大幅に低下します。このようなモジュールは、システム全体の一貫性を損なう可能性があります。Pattern: Bundle Moduleバンドルモジュールは、関連する複数のリソースを単一のインターフェースで管理することを可能にします。これにより、システムの一貫性と管理の容易さが向上します。特に、異なるリソースが密接に連携して動作する必要がある場合に有効で、開発者はより高度なタスクに集中できるようになります。Antipattern: Spaghetti Moduleスパゲッティモジュールは、パラメータに応じて大きく異なる結果を生み出すような複雑な設定が特徴です。これらのモジュールは、多くの動的な部分を含むため、実装が雑然として理解しにくくなりがちです。このようなモジュールはメンテナンスが困難で、変更を加える際には他の部分に予期せぬ影響を与えやすいことが分かっています。重要なのは、モジュールが単一の明確な目的を持ち、必要な機能だけを提供することです。複雑さを避けるためには、モジュールをより小さく、シンプルに保つことが重要です。Pattern: Infrastructure Domain Entityインフラストラクチャのドメインエンティティは、複数の低レベルのリソースを組み合わせて、より高度なスタックコンポーネントを実装するパターンです。このパターンは、特定のアプリケーションやサービスに必要なインフラストラクチャの全体像を捉え、その要件に基づいてリソースを動的に構築します。このアプローチは特に大規模で複雑な環境において効果的で、異なる要件に応じて柔軟にインフラストラクチャを構築できるようにします。しかし、これを実装するには、インフラストラクチャ自体をドメインとして捉え、その上で適切な設計を行う必要があります。Building an Abstraction Layer抽象化レイヤーを構築することで、より低レベルのリソースへの直接的なアクセスを抽象化し、より高レベルのタスクに集中できるようにします。これは、特に複数のチームが関わる大規模なプロジェクトにおいて有用です。抽象化レイヤーを使用することで、開発者はインフラストラクチャの詳細を気にせずに、アプリケーションの開発やビジネスロジックに集中できます。しかし、抽象化には適度なレベルが必要であり、過度な抽象化はシステムの理解を難しくし、問題の診断や解決を複雑化することもあります。第16章では、コンポーネントからスタックを構築する方法とその利点について説明されていますが、同時に、抽象化のレイヤーやコンポーネントのライブラリがもたらす複雑さに注意する必要があるとも指摘しています。システムの規模や複雑さに応じて、これらの構造を適切に使用することが重要です。適切な抽象化レベルの選択は、システムの効率をあげることにつながります。17. Using Stacks As Components (スタックをコンポーネントとして使用する)17. Using Stacks As ComponentsDiscovering Dependencies Across Stacksスタック間の依存関係の発見は、インフラストラクチャの複雑な環境において、異なるスタック間の統合を容易にするために重要です。依存関係を発見する方法を選ぶ際には、システムの拡張性、メンテナンスの容易さ、そして再利用性のバランスを考慮することが必要です。スタック間の依存関係を効果的に管理することは、システム全体の効率を向上させることに繋がります。Pattern: Resource Matchingリソースマッチングパターンは、名前、タグ、または他の識別特性を使用して、必要なリソースを発見する方法です。このパターンは、特に大規模なプロジェクトや、異なるチームや環境間での統合において有効です。実際、私が過去に関わったプロジェクトでは、リソースマッチングを使用することで、複数の環境やチーム間でのリソースの共有が容易になりました。Figure 17-1. Resource matching for discovering dependencies より引用Pattern: Stack Data Lookupスタックデータルックアップパターンは、提供側スタックが管理するデータ構造に基づいて、必要なリソースを見つける方法です。このアプローチは、全てのインフラストラクチャが同じツールを使用して管理されている場合に特に効果的です。スタックデータルックアップは、依存関係を明確にし、統合を容易にするために役立ちます。Pattern: Integration Registry Lookup統合レジストリルックアップパターンは、両方のスタックが一つのレジストリを使用して値を保存し、それを読み取る方法です。これは、異なるツールを使用している複数のチーム間の統合に非常に適しています。私自身も、異なる技術スタックを持つチーム間での統合にこのパターンを利用したことがあり、その柔軟性と効率性に非常に満足しています。Dependency Injection依存性の注入は、スタック定義から依存性の発見を分離することで、スタックの再利用性と柔軟性を向上させるテクニックです。このアプローチにより、異なるプロバイダー実装を容易に切り替えることが可能になり、より包括的に統合されたシステムのテストが容易になります。依存性の注入を使用することで、スタックをよりモジュラー化し、システムの各部分を独立して開発し、テストすることが可能になります。スタックをコンポーネントとして使用することは、システムの変更を容易にし、品質を向上させる効果的な方法です。このアプローチの成功は、スタックを適切に設計し、サイズを適切に保ち、スタック間の緩い結合を維持することに依存しています。スタックをコンポーネントとしてうまく利用することで、システム全体の可用性と拡張性が大幅に向上し、チームの生産性が向上しました。まとめインフラストラクチャをコードとして扱う際のベストプラクティス、効果的な設計パターン、および一般的なアンチパターンに焦点を当てています。この部分は、インフラストラクチャのモジュラリティの重要性を強調し、スタックのデザインパターンとアンチパターンを紹介します。依存関係の管理に関する方法論や依存性の注入の利点も説明されており、全体として、インフラストラクチャを効果的に設計し、管理するための重要な原則と方法論を提供しています。これらのガイドラインは、インフラストラクチャをコードとして扱う際に直面する一般的な課題に対する解決策を提示し、システムの効率性、拡張性、および信頼性を高めるための具体的な指針を提供しています。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/143554","isoDate":"2023-11-16T05:35:54.000Z","dateMiliSeconds":1700112954000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文","contentSnippet":"はじめに前回の続きで第二部のIII. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com 次回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第三部 目次III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes(アプリケーションランタイム)アプリケーションランタイムの章では、システムの3層モデルの一部として「インフラストラクチャシステムの部品」でアプリケーションランタイムを導入しています。ここでは、インフラ層からリソースを組み合わせて、アプリケーションをデプロイできるランタイムプラットフォームを提供する方法に焦点を当てています。アプリケーションランタイムは、インフラ管理ツールを使用して定義および作成されたインフラストラクチャスタックで構成されています。これは、どの言語や実行スタックで実行されるか、サーバー、コンテナ、またはFaaSサーバーレスコードにパッケージ化してデプロイされるかなど、それを使用するアプリケーションの理解から始まります。本章は、アプリケーションに対するランタイムプラットフォームとしてのインフラリソースの構成方法に焦点を当て、後の章でこれらのリソースをコードとして定義および管理する方法について詳しく説明しています。Figure 10-1. The application layer composed of infrastructure stacks より引用Cloud Native and Application-Driven Infrastructureクラウドネイティブとアプリケーション主導のインフラに関するこのセクションは、現代インフラのダイナミックな性質を最大限に活用するソフトウェア設計に重点を置いています。Herokuの12ファクターメソドロジーやKubernetesエコシステムとの関連性は、現代のアプリケーション開発の重要性を強調しています。このアプローチは、特に大規模なシステムの再構築や運用において、私の経験と一致しています。クラウドネイティブは、可変性と拡張性を重視したアプローチであり、これが現代のソフトウェア開発の標準となっています。Application Runtime Targetsアプリケーションランタイムターゲットを選定する際には、アプリケーションポートフォリオのランタイム要件を分析し、それに合わせたランタイムソリューションを設計することが重要です。これは、特に異なる技術スタックを持つ複数のプロジェクトを管理する場合に非常に役立ちます。ランタイムターゲットの選択は、アプリケーションのパフォーマンスと効率に大きく影響します。例えば、サーバーレス環境やコンテナベースの環境では、従来のサーバーベースのランタイムとは異なるアプローチが必要です。Deployable Parts of an Applicationアプリケーションのデプロイ可能な部分を理解することは、効率的なアプリケーションデプロイメント戦略を策定する上で重要です。実行可能ファイル、サーバー設定、データ構造などを適切に管理することは、私の経験上、運用の効率化に直結します。デプロイメントの自動化は、特に大規模なアプリケーションにおいて、時間とリソースの節約につながります。Deployment Packagesデプロイメントパッケージのセクションは、異なるランタイム環境に適したパッケージ形式の理解を深めます。これは、適切なツールとプロセスを選択する上でのガイドとなります。デプロイメントパッケージは、アプリケーションの構成とデプロイメントを標準化し、異なる環境間での一貫性を保証します。Deploying Applications to Serversサーバーへのアプリケーションデプロイメントに関しては、物理的または仮想的なサーバーを利用する従来のアプローチに焦点を当てています。これは、インフラの柔軟性とアプリケーションのニーズのバランスをとる上で重要な考慮点です。サーバーベースのデプロイメントは、特にレガシーシステムや特定のセキュリティ要件を持つアプリケーションにおいて、依然として重要な役割を果たします。Packaging Applications in Containersコンテナでのアプリケーションパッケージングについては、依存関係をアプリケーションパッケージに取り込むことの利点と課題を詳述しています。コンテナ化の進展は、アプリケーションのデプロイメントと運用の柔軟性を大きく向上させています。コンテナは、異なる環境間でのアプリケーションの実行を標準化し、デプロイメントプロセスを単純化します。Deploying Applications to Server Clustersサーバークラスターへのアプリケーションデプロイメントは、スケーラビリティと冗長性を確保するための重要な手法です。私の経験でも、効果的なクラスターマネジメントはシステムの可用性を大幅に向上させることができます。サーバークラスターは、負荷分散や障害耐性の向上に寄与します。Deploying Applications to Application Clustersアプリケーションクラスターへのデプロイメントは、ホストサーバー間でのアプリケーションインスタンスの分散に注目しています。これは、特に大規模なアプリケーションにおいて、リソースの効率的な利用とスケーラビリティの向上を実現します。クラスター内の異なるサーバーで異なるアプリケーションを実行することにより、リソースの最適化と柔軟な運用が可能になります。Packages for Deploying Applications to Clustersクラスターへのアプリケーションデプロイメントに必要なパッケージに関するセクションでは、複雑なインフラストラクチャ上で複数のプロセスとコンポーネントをデプロイする方法について説明しています。このアプローチは、現代の大規模アプリケーションの運用に不可欠です。クラスターベースのデプロイメントは、アプリケーションのスケールアップとスケールダウンを効率的に管理するための鍵となります。Deploying FaaS Serverless ApplicationsFaaS（Function as a Service）サーバーレスアプリケーションのデプロイメントは、サーバーやコンテナの詳細を抽象化し、インフラの複雑さから開発者を解放します。これは、迅速な開発とデプロイメントを可能にし、特にイベント駆動型アプリケーションやマイクロサービスアーキテクチャに適しています。サーバーレスは、リソースの使用に基づいた課金モデルを提供し、コスト効率を向上させます。Application Dataアプリケーションデータに関して、特にデータ構造の変更やデータの継続性の確保の重要性に焦点を当てています。これは、データベースの設計と運用における私の経験と一致し、データの変更と管理がシステムの信頼性と拡張性に大きく寄与することを示しています。Data Schemas and Structuresデータスキーマと構造のセクションでは、構造化されたデータストレージと非構造化、またはスキーマレスなデータストレージの違いを説明しています。スキーマ移行ツールの使用は、私の経験では、データベースのバージョン管理と変更の追跡に非常に有効であることが分かりました。Cloud Native Application Storage Infrastructureクラウドネイティブアプリケーションストレージインフラストラクチャは、動的に割り当てられるストレージリソースに重点を置いています。これは、拡張性とリソースの最適化におけるクラウドネイティブのアプローチの利点を反映しています。Application Connectivityアプリケーションの接続性に関するセクションでは、インバウンドとアウトバウンドの接続要件と、これらをインフラストラクチャスタックの一部として定義する方法について説明しています。これは、ネットワーク設計とセキュリティを考慮したアプリケーション開発に不可欠な要素です。Service Discoveryサービスディスカバリーに関しては、動的なインフラストラクチャでのサービスの発見方法として、DNS、リソースタグ、構成レジストリなどを含む様々なメカニズムに焦点を当てています。これは、マイクロサービスアーキテクチャや大規模な分散システムにおいて、サービス間の連携と通信のための重要な概念です。最後に、この章の結論では、インフラストラクチャの目的は有用なアプリケーションとサービスを実行することであると強調しています。アプリケーション主導のインフラストラクチャアプローチは、アプリケーションのランタイム要件に焦点を当て、アプリケーションの実行に必要なスタック、サーバー、クラスターなどの中間層構造を設計するのに役立ちます。「アプリケーション主導のインフラストラクチャ戦略では、現代的な動的インフラを使用してアプリケーションランタイム環境を構築します。(原文: An application-driven infrastructure strategy involves building application runtime environments for applications using modern, dynamic infrastructure.)」は、現代のインフラストラクチャ設計の核心をついており、私自身の経験でも、動的で柔軟なインフラストラクチャの設計と実装が、効率的で拡張性のあるシステムの構築に不可欠であることを強く感じています。アプリケーションのニーズに応じてインフラを適応させることが、現代のソフトウェア開発と運用の鍵となっています。11. Building Servers As Code (サーバーをコードとして構築する)「サーバーをコードとして構築する」章では、サーバーの設定を自動化する方法としてインフラストラクチャとしてのコードが最初に登場したことについて説明しています。システム管理者は、シェル、バッチ、Perlスクリプトを書いてサーバーを設定し、CFEngineはサーバー上のパッケージのインストールと設定ファイルの管理に対して、宣言型で冪等なDSLの使用を先駆けました。そして、PuppetやChefがこれに続きました。これらのツールは、物理サーバーやVMwareを使用した仮想マシン、後にはクラウドインスタンスなど、既存のサーバーから始めることを前提としています。現在では、サーバーがインフラスタックの一部であるか、コンテナクラスターの下層の詳細であるかに焦点を当てています。しかし、サーバーはほとんどのアプリケーションランタイム環境において依然として不可欠な部分です。この章では、サーバーの構成内容（設定する必要があるもの）とサーバーのライフサイクル（設定活動が行われるタイミング）から始まり、サーバー設定コードとツールに関する視点に移ります。この章の中心的な内容は、サーバーインスタンスの作成方法、サーバーを事前に構築して複数の一貫性のあるインスタンスを作成する方法、およびサーバーライフサイクル全体にわたるサーバー設定の適用方法に関する異なる方法を見ています。サーバーのライフサイクルをいくつかの遷移フェーズに分けて考えることが役立つ場合があります。サーバーの基本的なライフサイクルには、サーバーインスタンスの作成と設定、既存のサーバーインスタンスの変更、サーバーインスタンスの破棄という3つの遷移フェーズがあります。Figure 11-1. The basic server life cycle より引用What’s on a Serverサーバーに存在するものを理解することは、システムの安定性と効率を高める上で重要です。サーバー上のソフトウェア、設定、データの区別は、特に自動化されたインフラ管理において、適切なツールの選択と利用に不可欠です。私の経験からも、これらの要素を適切に管理することがシステムの安定稼働に直接影響を与えます。Where Things Come Fromサーバーの要素がどこから来るかを理解することは、サーバー構築と運用の複雑さを浮き彫りにします。OSのインストール、OSパッケージリポジトリ、言語やフレームワークのパッケージなど、多様な要素の組み合わせがサーバーのセットアップにおいて重要です。私の経験では、これらの要素を適切に組み合わせることが、効率的で堅牢なサーバーインフラの構築に不可欠であることが明らかです。Server Configuration Codeサーバー設定コードのセクションは、自動化されたサーバー設定のためのツールとアプローチを詳述しています。Ansible、Chef、Puppetなどのツールは、サーバー設定の自動化において非常に重要な役割を果たし、私の経験からもこれらのツールの有効性を実感しています。Server Configuration Code Modulesサーバー設定コードモジュールについてのこの部分は、コードの組織化とモジュール化の重要性を強調しています。実際のプロジェクトでは、これらの原則がサーバー設定の複雑さを管理するために不可欠です。コードのモジュール化は、メンテナンスの容易さと拡張性を提供します。Designing Server Configuration Code Modulesサーバー設定コードモジュールの設計についてのセクションは、単一の関心事に焦点を当てたモジュールの重要性を説明しています。これは、効率的なインフラストラクチャ管理に必要なベストプラクティスです。私の経験でも、関心の分離を行うことで、より管理しやすく、エラーの少ないインフラを構築できることが実証されています。Versioning and Promoting Server Codeサーバーコードのバージョニングと昇格に関するこの部分は、サーバー設定の変更を管理するための戦略を提供します。コードのバージョン管理は、安定したインフラストラクチャ環境の維持において重要です。バージョン管理を通じて、安定性と再現性を保証することができます。Server Rolesサーバーの役割に関するセクションは、特定の設定モジュール群をサーバーに適用する方法を示しています。これは、サーバー設定の柔軟性と適用性を高めるための有効な手法です。役割に基づくモジュール管理は、特に大規模な環境において、サーバーの設定と運用を簡素化します。Testing Server Codeサーバーコードのテストに関するこの部分は、インフラストラクチャコードのテスト戦略を提供し、品質保証において重要な役割を果たします。私の経験では、テストはインフラストラクチャの信頼性と整合性を保証するための鍵です。Progressively Testing Server Codeサーバーコードの段階的なテストについてのセクションは、テスト戦略を効果的に組み立てる方法を示しています。これは、インフラストラクチャの信頼性を高めるために不可欠です。段階的なテストは、コードの整合性を保ちながら、継続的に品質を向上させることができます。What to Test with Server Codeサーバーコードで何をテストするかについてのこのセクションは、テストの焦点と目的を明確にします。これは、サーバー設定の精度と効率を保証するために重要です。テストを通じて、異なる環境や条件下でのサーバーの挙動を確認し、予期せぬ問題の早期発見と修正を行うことができます。How to Test Server Codeサーバーコードをどのようにテストするかに関するセクションは、効果的なテスト方法とツールを提供します。InspecやServerspecなどのツールは、サーバーの状態を検証し、期待される動作を保証するために役立ちます。実際のテストプロセスは、特定の条件下でサーバーの設定と動作を確認し、必要に応じて調整を行うことを目的としています。Creating a New Server Instance新しいサーバーインスタンスを作成する際には、物理サーバーや仮想マシンの選択、OSのインストール、初期設定の適用が含まれます。これは、効率的で再現性の高いサーバー環境を構築するために重要です。私の経験では、新しいサーバーインスタンスの作成は、システムの拡張性と柔軟性に大きく寄与します。Hand-Building a New Server Instance手作業で新しいサーバーインスタンスを構築する方法は、特に小規模な環境や実験的な目的に適しています。しかし、大規模な運用環境においては、この方法は非効率的でエラーが発生しやすいため、自動化されたプロセスに置き換えることが望ましいです。Using a Script to Create a Serverサーバー作成のためのスクリプト使用に関して、このセクションはサーバー作成プロセスの自動化の重要性を強調しています。コマンドラインツールやAPIを利用するスクリプトを作成することで、サーバーの設定が一貫性を持ち、透明性が向上します。私の経験では、このようなスクリプトを活用することで、サーバーのデプロイメントプロセスの効率化とエラーの削減が可能です。Using a Stack Management Tool to Create a Serverスタック管理ツールを使用したサーバー作成に関するこの部分では、サーバーを他のインフラリソースと一緒に定義する利点を説明しています。Terraformなどのツールを使用することで、サーバーインスタンスの作成や更新が簡素化されます。私の経験上、スタックツールの使用は、インフラリソースの統合と管理を効率的に行うのに役立ちます。Configuring the Platform to Automatically Create Serversプラットフォームを設定して自動的にサーバーを作成するこのセクションは、オートスケーリングやオートリカバリーのような機能を利用する方法を示しています。これは、負荷の増加に応じたサーバーの追加や障害発生時のサーバーインスタンスの交換といった、動的な環境において特に重要です。Using a Networked Provisioning Tool to Build a Serverネットワークプロビジョニングツールを使用してサーバーを構築するこの部分では、ハードウェアサーバーの動的なプロビジョニングプロセスについて説明しています。PXEブートなどの手法を利用して物理サーバーをリモートで起動し、OSインストールや設定を行うプロセスは、特に物理的なインフラを管理する際に有効です。Prebuilding Servers事前にサーバーを構築するこのセクションでは、サーバーの内容を事前に準備する複数の方法を提供しています。これにより、サーバーの構築プロセスを高速化し、複数の一貫性のあるサーバーインスタンスを容易に作成できます。実際に、事前に構築されたサーバーイメージを使用することで、デプロイメントの時間と労力を大幅に削減できることを経験しています。Hot-Cloning a Server実行中のサーバーをホットクローニングするこの部分では、クローニングを行う際の利便性とリスクについて説明しています。特に、本番環境のサーバーをクローニングする際には、意図しない影響を避けるために注意が必要です。Using a Server Snapshotサーバースナップショットの使用に関するこのセクションでは、ライブサーバーからスナップショットを取得し、そのスナップショットを使用して新しいサーバーを作成する方法を提供しています。これは、特に大規模な環境において、サーバーの一貫性を保つための有効な方法です。Creating a Clean Server Imageクリーンなサーバーイメージを作成するこの部分では、複数の一貫性のあるサーバーインスタンスを作成するための基盤となるイメージを作成するプロセスを説明しています。これは、サーバーのデプロイメントを標準化し、品質を保つために非常に重要です。Configuring a New Server Instance新しいサーバーインスタンスの設定に関するこのセクションでは、サーバーの作成とプロビジョニングプロセスの最後の部分である自動化されたサーバー設定コードの適用について説明しています。このプロセスは、新しいサーバーを作成する際の構成を決定する上で重要な要素です。最後に、この章はサーバーの作成とプロビジョニングに関する様々な側面をカバーしています。サーバーに含まれる要素にはソフトウェア、設定、データがあり、これらは通常、サーバーイメージとサーバー設定ツールを使用して追加されるパッケージと設定から構成されます。サーバーを作成するためには、コマンドラインツールを使用するかUIを使用することができますが、コード駆動のプロセスを使用することが好ましいです。今日では、カスタムスクリプトを作成することは少なく、スタック管理ツールを使用することが一般的です。サーバーを構築するためのさまざまなアプローチについて説明していますが、通常、サーバーイメージを構築することをお勧めします。12. Managing Changes To Servers (サーバーへの変更の管理)この章は、サーバーとそのインフラに対する変更を管理するための多様なアプローチとパターンを探求しています。この章を読んで、サーバーの変更管理における自動化の重要性が強く印象に残りました。特に、変更を例外的なイベントではなく、日常的なルーチンとして取り扱うことの重要性が強調されている点に共感しました。私自身の経験からも、一貫性のある自動化された変更プロセスは、システムの安定性と信頼性を大きく向上させると確信しています。また、この章で提案されている様々なパターン、特に「継続的な設定同期」と「不変のサーバー」というパターンは、サーバー運用の効率を高める上で非常に有効です。サーバーの設定を定期的に同期することで、予期せぬ変更や誤差を早期に検出し、対処することが可能になります。また、不変のサーバーの概念は、変更によるリスクを減らす効果的な手法として、私のプロジェクトでも積極的に採用しています。サーバー設定コードをどのように適用するかに関しても、プッシュとプルの2つのパターンを詳しく説明しています。これらのパターンの選択は、サーバーのライフサイクルイベントに合わせて行う必要があり、特定の状況や要件に基づいて適切なアプローチを選択することが重要です。サーバーの他のライフサイクルイベント、例えばサーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などについても、有益な洞察を提供しています。特に、サーバーの回復プロセスは、クラウドインフラストラクチャの信頼性の限界に対処するために不可欠です。総じて、サーバーのライフサイクル管理における現代的なアプローチを包括的に提示しており、サーバーの設定と変更プロセスを最適化するための貴重なリソースとなっています。Change Management Patterns: When to Apply Changesサーバーの変更管理パターンは、変更を適用するタイミングを決定するための重要なガイドラインを提供します。変更が必要となった場合にそれを例外的なイベントとして扱うのではなく、ルーチンとして組み込むことで、システムの一貫性とポリシーへの準拠を確保できます。これは、私が経験したシステムの自動化における重要な一歩です。Antipattern: Apply On Changeこのアンチパターンは、特定の変更を適用するためにのみ設定コードを使用することを示しています。変更を例外として扱うことは、システムの不整合とエラーの原因となることが多いです。これは、私の経験でも、効率的なシステム管理において避けるべき方法です。Pattern: Continuous Configuration Synchronization継続的な設定同期は、変更があるかどうかに関わらず、定期的に設定コードを適用することを意味します。これにより、サーバーの設定の一貫性が保たれ、予期せぬ違いを早期に検出できます。これは、私のSREとしての実践において、サーバー運用の効率を大幅に向上させた方法です。Pattern: Immutable Server不変のサーバーとは、設定が変更されないサーバーインスタンスを意味します。変更を配信するために、変更された設定で新しいサーバーインスタンスを作成し、既存のサーバーを置き換えます。これは、特に安定性と整合性が重要な環境で有効な手法です。How to Apply Server Configuration Codeサーバー設定コードの適用方法に関するこのセクションは、サーバーに変更を適用するためのパターンを検討します。サーバーの新規構築、既存インスタンスの更新、サーバーイメージの構築において、これらのパターンは不可欠です。Pattern: Push Server Configurationプッシュサーバー設定パターンでは、新しいサーバーインスタンスの外部からサーバーに接続してコードを実行し、適用します。これは、サーバーインスタンスへのタイムリーな設定更新が必要な場合に特に有効です。Pattern: Pull Server Configurationプルサーバー設定パターンでは、サーバーインスタンス自体で実行されるプロセスが設定コードをダウンロードして適用します。これは、サーバーインスタンスが入ってくる接続を受け入れる必要がないため、攻撃面を減らすのに役立ちます。Other Server Life Cycle Eventsサーバーの他のライフサイクルイベントに関するこのセクションでは、サーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などを検討します。これらは、サーバーの管理と運用において、特に重要なフェーズです。Stopping and Restarting a Server Instanceサーバーインスタンスの停止と再起動に関するこのセクションは、特定の目的のためにサーバーを一時的に停止または再起動する方法を示しています。これは、コスト削減やメンテナンスのために、しばしば実践されます。Figure 12-1. Server life cycle—stopping and restarting より引用Replacing a Server Instanceサーバーインスタンスの置換に関するこの部分は、新しいサーバーインスタンスを作成し、古いインスタンスと交換するプロセスを説明しています。これは、特に自動スケーリングや自動回復を利用する環境で役立つアプローチです。Recovering a Failed Server失敗したサーバーの回復についてのこのセクションでは、サーバーインスタンスが失敗した場合の回復プロセスについて説明しています。これは、クラウドインフラストラクチャの信頼性が常に保証されるわけではないため、特に重要です。この章は、サーバーのライフサイクルにおける核心的なイベントを網羅しています。サーバーの作成と変更に関するアプローチの多くは、サーバーイメージをカスタマイズし、それを使用して複数のサーバーインスタンスを作成または更新することに依存しています。13. Server Images As Code (サーバーイメージをコードとして扱う)サーバーイメージの自動化された構築と維持に関する包括的なガイドを提供しています。この章を読む中で、サーバーイメージの構築と管理を自動化することの重要性が強調されてました。特に、サーバーイメージのライフサイクルを通じて、一貫性と品質の確保に焦点を当てることが重要であると感じました。サーバーイメージの構築プロセスは、オンラインとオフラインの二つのアプローチが存在し、各々の利点と制約について詳しく解説されています。私の経験上、オフラインのイメージ構築は迅速で、特定のシナリオでは非常に有効ですが、より複雑な設定を必要とすることがあります。また、サーバーイメージの異なる起源、例えばベンダー提供のストックイメージやゼロからの構築、そしてそのコンテンツの出所に関する議論は、セキュリティとパフォーマンスのバランスを取る上で非常に有益です。セキュリティに関する考慮事項は、特に重要であり、サーバーイメージの構築プロセスにおいて常に優先されるべきです。サーバーイメージのバージョニングと更新の管理は、章の中でも特に興味深い部分でした。これにより、サーバーイメージが最新のセキュリティパッチや設定で常に最新の状態を保つための効率的な方法が提供されます。私の経験では、サーバーイメージの定期的な更新は、インフラの安定性と運用の効率を大幅に向上させることができます。さらに、サーバーイメージをパイプラインを通じてテストおよび配信することに関するセクションは、インフラストラクチャの自動化とCI/CDの実践において非常に重要な概念を提供します。パイプラインを使用することで、サーバーイメージの構築、テスト、配布が容易かつ効率的になります。この章全体を通して、サーバーイメージを効率的に管理し、継続的に改善するための強固な基盤が提示されています。これは、現代のインフラストラクチャ管理において不可欠なリソースであり、その実践は技術的な洞察とともに、ビジネスの効率性とセキュリティを高める重要な手段となります。Figure 13-1. Server image life cycle より引用Building a Server Imageサーバーイメージの構築に関するセクションでは、カスタムサーバーイメージの作成プロセスの重要性とその利点について深く掘り下げられています。このプロセスを通じて、組織固有の要件やセキュリティ基準に合致したイメージを作成することの価値が明らかにされました。このセクションは、自動化されたイメージ作成のアプローチが、サーバーのデプロイメントをより迅速かつ安全にする方法を示しています。実際に、カスタマイズされたイメージを使用することで、セキュリティやパフォーマンスの最適化が可能になると私は経験しています。Why Build a Server Image?サーバーイメージを構築する理由についてのセクションは、特に啓発的でした。組織のガバナンス、セキュリティの強化、パフォーマンスの最適化など、カスタムイメージを構築するための具体的な理由が挙げられています。これらの要因は、私が直面する日常の課題と密接に関連しており、カスタムサーバーイメージを活用することの価値を再確認させてくれました。How to Build a Server Imageサーバーイメージの構築方法に関する部分は、理論的かつ実践的なアプローチを提供しており、非常に役立ちました。オンラインとオフラインの両方のイメージ構築方法が詳細に説明されており、これは技術的な選択肢を検討する際に重要なガイドラインとなります。Tools for Building Server Imagesこのセクションでは、サーバーイメージを構築するためのツールとサービスが詳述されています。Packerのようなツールの利用が、イメージ構築プロセスを効率化する上でいかに重要かが強調されているのを見て、私の現在のワークフローに対する洞察を得ることができました。Online Image Building Processオンラインでのイメージ構築プロセスについてのセクションは、イメージを作成する実際の手順を明確に説明しています。このプロセスに関する詳細な説明は、実務での応用を容易にし、サーバーイメージの構築方法の理解を深めました。Offline Image Building Processオフラインイメージ構築プロセスに関する説明は、オンラインプロセスとの比較を通じて、異なるアプローチの利点と制約を理解するのに役立ちました。オフラインでのイメージ構築方法は、特定の状況下での効率性を考慮する上で重要です。Origin Content for a Server Imageサーバーイメージの起源コンテンツに関するセクションは、イメージ構築の基礎となる要素についての理解を深めるのに役立ちました。ストックイメージからの構築、スクラッチからの構築、そしてサーバーイメージとそのコンテンツの由来に関する議論は、イメージ構築プロセスの基礎を形成します。Building from a Stock Server Imageストックサーバーイメージからの構築に関するセクションは、既存のイメージをカスタマイズする方法とその利点を解説しています。このアプローチは、特にセキュリティやパフォーマンスの最適化を目指す際に重要です。Building a Server Image from Scratchゼロからサーバーイメージを構築するプロセスに関する詳細は、完全にカスタマイズされたイメージを作成するための重要なガイドラインを提供しています。これは、特定の高度な要件を持つ組織にとって特に有益です。Provenance of a Server Image and its Contentサーバーイメージとそのコンテンツの出所に関するセクションは、セキュリティと信頼性の側面を考慮する上で特に重要です。サードパーティからのコンテンツを使用する際の潜在的なリスクを理解し、適切なチェックを実施することが強調されています。Changing a Server Imageサーバーイメージの変更に関するセクションは、イメージの維持と更新のプロセスに光を当てています。定期的なリフレッシュとバージョニングの重要性に関する洞察は、効率的で安全なインフラストラクチャ管理のために不可欠です。Reheating or Baking a Fresh Imageイメージの再加熱または新たなイメージの焼き直しに関するセクションは、サーバーイメージの更新方法に関する具体的な選択肢を提示しています。どちらのアプローチもそれぞれのメリットがあり、状況に応じて適切な方法を選択することが重要です。Versioning a Server Imageサーバーイメージのバージョニングに関する議論は、イメージの追跡と管理の重要性を強調しています。バージョニングは、イメージの透明性と一貫性を保つ上で不可欠な要素です。Updating Server Instances When an Image Changesイメージが変更された場合のサーバーインスタンスの更新についてのセクションは、イメージを基に作成されたインスタンスの一貫Updating Server Instances When an Image Changes「イメージが変更されたときのサーバーインスタンスの更新」に関するセクションは、サーバーイメージの更新とサーバーインスタンスの同期に関する洞察を提供しました。この部分では、新しいサーバーイメージを作成した後のサーバーインスタンスの管理方法について考察しています。サーバーインスタンスを即座に更新するか、自然に時間が経過するまで待つかという選択は、システムの整合性と運用の効率の両方に影響を及ぼします。私の経験では、定期的なサーバーインスタンスの更新は、セキュリティとパフォーマンスの観点から重要です。また、適切なバージョン管理と更新ポリシーは、サーバー環境の一貫性を保ち、予期せぬ問題を回避するために不可欠です。Providing and Using a Server Image Across Teams「チーム間でのサーバーイメージの提供と使用」は、サーバーイメージを異なるチーム間で共有する際のベストプラクティスに焦点を当てています。このセクションは、サーバーイメージを中央チームが作成し、他のチームが使用する場合のダイナミクスを明確に説明しています。イメージのバージョン管理と共有に関する洞察は、大規模な組織における効果的なインフラ管理に特に関連しています。私が以前関わったプロジェクトでは、チーム間でサーバーイメージを共有することで、作業の重複を防ぎ、一貫性を保つことができました。Handling Major Changes to an Image「イメージの大きな変更を扱う」セクションは、サーバーイメージに対する大規模な変更を適切に管理する方法に関する重要な洞察を提供しています。このセクションでは、大きな変更をセマンティックバージョニングを使用して管理することの重要性が強調されています。私の経験では、サーバーイメージに大きな変更を加える際には、特に慎重なテストと段階的な導入が重要です。これにより、変更による影響を最小限に抑え、システムの安定性を保つことができます。Using a Pipeline to Test and Deliver a Server Image「サーバーイメージをテストおよび配信するためのパイプラインの使用」セクションは、サーバーイメージのライフサイクルを自動化し、品質を確保するための強力なアプローチを提供しています。パイプラインを通じてサーバーイメージを構築、テスト、配信することは、継続的な改善と効率化のための鍵です。私の経験では、CI/CDパイプラインを使用することで、サーバーイメージの作成と更新が格段に効率的になり、システムの全体的な信頼性が向上します。Using Multiple Server Images「複数のサーバーイメージの使用」セクションは、異なる環境や用途に合わせて複数のサーバーイメージを維持する必要性を説明しています。異なるプラットフォーム、オペレーティングシステム、ハードウェアアーキテクチャに対応するためのサーバーイメージの管理は、特に複雑なインフラストラクチャを持つ組織において重要です。私の経験では、特定の役割や要件に合わせてサーバーイメージを最適化することで、運用の効率を大幅に向上させることが可能です。サーバーイメージの管理に関するこの章の総括として、サーバーイメージをコードとして扱うことの利点が明確に示されています。自動化されたプロセスを通じてサーバーイメージを維持し、定期的に更新することで、インフラストラクチャの効率性とセキュリティが大きく向上することが示されています。14. Building Clusters As Code (クラスターをコードとして構築する)この章は、クラスターをコードとして構築する方法について詳しく解説しています。ソフトウェアエンジニアリングの経験から、このアプローチの強みは、システムの柔軟性と再現性にあります。KubernetesやAWS ECSなどの例が挙げられ、クラスター管理の複雑さを隠蔽しながらも、コードを介して制御可能であることが強調されています。Figure 14-1. An application cluster creates a layer between infrastructure resources and the applications running on them より引用Application Cluster Solutionsアプリケーションクラスターのソリューションに関しては、クラウドベースのサービスとオンプレミスのソリューション間の選択肢を詳細に検討しています。私の経験では、クラウドサービスは迅速な展開と低い初期コストを提供しますが、長期的にはカスタマイズの柔軟性とコントロールの観点で限界があります。一方で、オンプレミスソリューションは初期設定が複雑であり、維持管理のコストが高くなる可能性がありますが、長期的にはより制御可能で安定しています。Cluster as a Serviceクラウドプラットフォームが提供するCluster as a Service は、設定や管理の簡素化を可能にします。しかし、クラウド固有のサービスに依存することのリスクも伴います。この点は、多くのプロジェクトで検討すべき重要なトレードオフです。Packaged Cluster Distributionパッケージ化されたクラスター配布は、よりカスタマイズ可能で、組織固有のニーズに合わせた設定が可能です。Kubernetesのようなオープンソースソリューションの利用は、柔軟性をもたらしますが、メンテナンスとサポートにおいて自組織のリソースを要求します。Stack Topologies for Application Clustersアプリケーションクラスターのスタックトポロジーについては、モノリシックなスタックと分散型スタックの両方が詳述されています。私の観点からは、モノリシックなアプローチは小規模なプロジェクトや初期段階でのプロトタイピングに適しています。しかし、規模が大きくなると、スタックを分割し、各機能を別々に管理することで、より効率的な運用と拡張性が得られます。特に大規模なシステムでは、分散型のアプローチがシステムの複雑さを管理しやすくします。Monolithic Stack Using Cluster as a Serviceモノリシック・スタックを使用する場合、初期段階では管理が簡単ですが、規模が大きくなるにつれて、複雑さとリスクが増大します。このアンチパターンは、特に大規模なシステムでの問題につながり得ます。Monolithic Stack for a Packaged Cluster Solutionパッケージ化されたクラスター・ソリューションにおけるモノリシック・スタックは、より管理が複雑ですが、カスタマイズの自由度が高いです。インフラのスタックとアプリケーションのクラスターが別々に管理される点は、運用において重要な考慮事項です。Pipeline for a Monolithic Application Cluster Stackモノリシック・アプリケーション・クラスター・スタックのパイプラインは、インフラとアプリケーションの両方に影響を及ぼします。この一元管理は、変更の際に大きな影響を及ぼす可能性があります。Example of Multiple Stacks for a Clusterクラスターのための複数スタックの例は、変更の影響を局所化し、リスクを分散させるのに役立ちます。スタックを分割することで、より効率的かつ安全に変更を行うことができます。Sharing Strategies for Application Clustersアプリケーションクラスターの共有戦略に関するセクションは、特に多様な環境やニーズを持つ組織にとって重要です。一つの大きなクラスターをすべての用途に使用するのではなく、目的やチームごとにクラスターを分割することで、セキュリティ、パフォーマンス、および管理の観点から優れた結果を得ることができます。私の経験上、チームやプロジェクトごとに専用のクラスターを用意することは、リソースの効率的な利用とセキュリティリスクの軽減に繋がります。また、ガバナンスやコンプライアンスの要件に基づいてクラスターを分割することは、特に規制の厳しい業界での運用において重要です。One Big Cluster for Everything全てを一つの大きなクラスターで管理するアプローチは、シンプルさと効率の面で魅力的ですが、変更管理の複雑さやリスクの集中が懸念されます。Separate Clusters for Delivery Stages異なるデリバリー段階ごとに別々のクラスターを用意する戦略は、リスクの分散と環境間の独立性を提供します。これにより、特定の環境に特化した最適化が可能になります。Clusters for Governanceガバナンスのためのクラスターは、特定のコンプライアンス要件を持つアプリケーションに対して、より厳格な環境を提供することができます。これにより、セキュリティとパフォーマンスの向上が期待できます。Clusters for Teamsチームごとのクラスターは、チームの特定のニーズに合わせたカスタマイズを可能にします。これは、チームの生産性を向上させると同時に、システムの全体的な効率を高めることができます。Service Meshサービスメッシュは、アプリケーション間の通信を効率化し、複雑な分散システムにおける管理を容易にします。これにより、開発者はアプリケーションのロジックに集中でき、インフラストラクチャの詳細から解放されます。Infrastructure for FaaS ServerlessFaaS Serverlessのインフラストラクチャは、従来のアプリケーション・ホスティングとは異なり、イベント駆動のコード実行をサポートします。これにより、負荷が不規則なワークロードに対して、高い効率性とスケーラビリティが得られます。この章の総括として、クラスターをコードとして構築するアプローチは、アプリケーションをサポートするためのインフラストラクチャを効率的に管理するための強力な方法です。個々の技術や戦略の選択は、組織の特定のニーズに基づいて行われるべきです。まとめサーバーとその他のアプリケーションランタイムプラットフォームの扱いに焦点を当てています。このセクションは、現代のインフラストラクチャ管理における重要なトピックを深く掘り下げており、Infrastructure as Code (IaC) の実践において不可欠な洞察を提供しています。特に、アプリケーションクラスターの構築、スタックトポロジーの設計、そしてクラスター共有戦略の選択に関する章は、システムのスケーラビリティと耐障害性を高める方法論を提示しています。これらの章では、クラウドサービスとオンプレミスソリューションの利点と欠点が比較され、プロジェクトの要件に応じた適切な選択を行うための洞察が提供されています。本書は、インフラストラクチャをコードとして扱うことの重要性を強調し、変更管理、セキュリティ、およびコンプライアンスを効率的に運用するための具体的な手法を提供しています。また、サービスメッシュやサーバーレスアーキテクチャなどの先進的なトピックにも言及し、読者がこれらの技術を理解し、適切に活用するためのガイダンスを提供しています。全体を通して、この部分は、インフラストラクチャの自動化とオーケストレーションに関する実用的なアプローチを強調しており、読者がより堅牢で効率的なシステムを構築するための知識を深めるのに役立ちます。結果として、サーバーとアプリケーションランタイムプラットフォームの管理において、より戦略的で洗練されたアプローチを採用するための基盤を築くことができます。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/124030","isoDate":"2023-11-16T03:40:30.000Z","dateMiliSeconds":1700106030000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文","contentSnippet":"はじめに前回の続きで第二部のWorking With Infrastructure Stacks (インフラストラクチャスタックとの作業)という部の読書感想文になります。まず、Stackってなんやねんと思うと思います。僕も思っています。前回の記事syu-m-5151.hatenablog.com次回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第二部 目次II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)この章はインフラストラクチャスタックをコードとして構築する方法に焦点を当てています。Figure 5-1. An infrastructure stack is a collection of infrastructure elements managed as a group より引用What Is an Infrastructure Stack?インフラストラクチャスタックは、インフラリソースを単位として定義、プロビジョニングし、更新する集合体であり、スタック管理ツールによって一括で管理されます。スタック管理ツールには、HashiCorp Terraform, AWS CloudFormation, Azure Resource Manager, Google Cloud Deployment Manager, Pulumi などがあります。AnsibleやChefなどの内部を上手に操作するツールはこれらには含まれません。そして、このStack管理ツールは私は現実ではほぼ使いません。Infrastructure as Codeのこれまでとこれから、わたしたちにIaCはまだ早かったのかもしれないなどでもStackツールって表現しているようなことはありませんだからといって本書の価値が下がるということは一切ありません。Stack Codeスタックコードはスタックの構造を記述するソースコードであり、インフラプラットフォームから提供されるリソースやサービスを宣言的に記述します。スタックコードは、インフラストラクチャの各要素をどのようにコード化するかを明確にし、変更が行われる際には、このコードに基づいてインスタンスが更新されます。Stack Instanceスタックインスタンスは、特定のスタックコードに基づいてプロビジョニングされたインフラリソースの具体的な実体です。インフラストラクチャの状態がコードで明確に定義されることにより、再現性と整合性を保つことが可能です。Configuring Servers in a Stackサーバー設定はインフラコードベースの重要な部分であり、コンテナベースやサーバーレスアーキテクチャではないシステムにおいて特に多くのコードが必要になります。Direct Infrastructure Management Languages & Abstraction-Level Infrastructure Languages直接インフラ管理言語は、インフラストラクチャプラットフォームが提供するリソースに直接対応し、抽象化レベルのインフラ言語は、基盤となるプラットフォームが提供するリソースに直接対応していないエンティティを定義します。たとえば、PaaSプラットフォームやパッケージ化されたクラスターは、より高い抽象レベルでリソースを管理する能力を提供します。Patterns and Antipatterns for Structuring Stacksインフラストラクチャスタックの構造化において取るべき適切なアプローチと避けるべき間違ったアプローチについて説明しています。Antipattern: Monolithic Stack (アンチパターン: モノリシックスタック)モノリシックスタックは、多くの要素を含む過大なインフラストラクチャスタックで、その管理が困難です。これはシステムの拡大とともに発生しやすく、一つのプロジェクトに新しい要素を単純に追加することで成長します。しかし、その結果、スタックのプロビジョニングや更新に時間がかかりすぎたり、変更時のリスクが高まるなどの問題が生じます。Pattern: Application Group Stack (パターン: アプリケーショングループスタック)アプリケーショングループスタックは、関連する複数のアプリケーションまたはサービスのインフラストラクチャをグループ化して管理します。これにより、システム内の複数のアプリケーションを単一の単位として扱い、管理を簡素化できます。しかし、アプリケーションごとの変更のリズムが異なる場合、不必要なオーバーヘッドやリスクを招く可能性があります。Pattern: Service Stack (パターン: サービススタック)サービススタックでは、デプロイ可能な各アプリケーションコンポーネントのインフラストラクチャを個別のスタックで管理します。これにより、サービスごとの変更を独立して行えるため、変更管理のリスクが局限され、チームがそれぞれのソフトウェアに関連するインフラストラクチャを所有することが容易になります。Pattern: Micro Stack (パターン: マイクロスタック)マイクロスタックでは、単一サービスのインフラストラクチャを複数のスタックに分割します。これにより、サービスの異なる部分が異なるレートで変更されたり、管理が別々に簡単になるなど、さらなる柔軟性と管理のしやすさを提供します。ただし、スタックの数が増えることで生じる追加の複雑性を管理する新たな課題もあります。これらのパターンとアンチパターンは、スタックのサイズと構造をどのように決定するかについての考慮点を提供し、スタックの管理とスケーラビリティのバランスを最適化する方法を示しています。この章では、インフラストラクチャの自動化におけるスタックの重要性と管理方法を明確にし、スタックの構築と管理に関する技術的な洞察と実践的な指針を提供します。6. Building Environments With Stacks (スタックで環境を構築する)インフラストラクチャスタックを用いて環境を構築する方法について詳しく説明されています。この章は、ソフトウェア開発と運用の現場で経験した実践的な課題と、それを解決するためのインフラコード化の知見を踏まえ、環境構築の理論と手法を提供します。Figure 6-1. ShopSpinner delivery environmentsより引用What Environments Are All About環境は特定の目的に沿って組織されたソフトウェアとインフラリソースの集合体であり、例えばテストフェーズをサポートするため、または地理的な地域でサービスを提供するために使用されます。スタックまたはスタックのセットは、これらのインフラリソースのコレクションを定義し、管理する手段であり、環境を実装するために使用されます。\"An environment is a collection of software and infrastructure resources organized around a particular purpose, such as to support a testing phase, or to provide service in a geographical region.\" (環境とは、テストフェーズをサポートしたり、地理的な地域でサービスを提供したりするなど、特定の目的の周りに組織されたソフトウェアとインフラリソースの集合体です。)Patterns for Building Environments環境を構築するためのパターンでは、環境とスタックの実装方法についてのアンチパターンとパターンが説明されています。Antipattern: Multiple-Environment Stack (アンチパターン: 複数環境スタック)複数環境スタックは、単一のスタックインスタンスとして複数の環境のインフラストラクチャを定義し、管理するものです。これは、新しいスタックツールを学習している際に直感的に行われがちな構造ですが、コード内のミスや依存関係の予期せぬ発生により、インスタンス内の全てが影響を受けるリスクがあります。Antipattern: Copy-Paste Environments (アンチパターン: コピペ環境)コピペ環境アンチパターンは、各インフラストラクチャスタックインスタンスに対して別々のスタックソースコードプロジェクトを使用するものです。これにより、コードの重複や一貫性の欠如が生じ、環境間での構成のズレによるテストやデプロイメントプロセスの信頼性が低下する可能性があります。Pattern: Reusable Stack (パターン: 再利用可能スタック)再利用可能スタックは、複数のスタックインスタンスを生成するために使用されるインフラソースコードプロジェクトです。これにより、スタックコードに加えた変更を一つのインスタンスでテストし、その後同じコードバージョンを使用して複数の追加インスタンスを作成または更新することができます。この章は、インフラストラクチャスタックを使用して環境を効果的に実装するための戦略と、それに伴う潜在的な問題を特定し、解決する方法を提供します。インフラストラクチャスタックを活用した環境構築は、ソフトウェアのリリースプロセスのサポートや、地理的な分散によるスケーラビリティと耐障害性の向上に貢献します。7. Configuring Stack Instances (スタックインスタンスの設定)再利用可能なインフラスタックを複数の環境で効率的に運用するための構成管理について議論しています。この章では、インフラスタックのカスタマイズが必要なシナリオを想定し、環境ごとのユニークな設定をどのように実現するかを検討しています。Figure 7-1. Using the same code with different parameter values for each environment より引用Using Stack Parameters to Create Unique Identifiersスタックコードにパラメータを渡すことで、同一プロジェクトから生成される複数のスタックインスタンスがIDの衝突を避けられるよう、一意性の確保を目指しています。このアプローチは、インフラストラクチャのコード化の原則「全てを再現可能にする」を実現する上で重要な役割を果たします。\"Consistency across environments is one of the main drivers of Infrastructure as Code.\" (環境間の一貫性は、インフラストラクチャのコード化の主要な推進力の一つです。)Patterns for Configuring Stacksスタック構成に関するパターンでは、スタックツールに構成値を効果的に渡すための複数のアンチパターンとパターンが提示されています。Antipattern: Manual Stack Parameters (アンチパターン: 手動スタックパラメータ)手動でパラメータを入力する方法は、簡便ですが、誤入力のリスクがあり、チーム内での構成値の一貫性を担保するのが難しいです。Pattern: Stack Environment Variables (パターン: スタック環境変数)スタックツールが使用するパラメータ値を環境変数として設定することは、実行前のセットアップを容易にし、またパラメータの可視性を向上させますが、その管理は別の機構に依存します。Pattern: Scripted Parameters (パターン: スクリプト化されたパラメータ)パラメータ値をスクリプトに埋め込むことで、環境ごとの一貫性を保証することができ、手動入力時の問題を避けられます。しかし、シークレット情報の扱いには注意が必要です。Pattern: Stack Configuration Files (パターン: スタック構成ファイル)パラメータファイルを用いることで、環境ごとにカスタマイズされた構成をバージョン管理することができます。これは、構成の監査と変更管理において非常に有効なアプローチです。Pattern: Wrapper Stack (パターン: ラッパースタック)ラッパースタックを用いることで、スタックコードの共有を促進し、変更を段階的に配布することができますが、この方法は追加の複雑さをもたらす可能性があります。Pattern: Pipeline Stack Parameters (パターン: パイプラインスタックパラメータ)パイプラインツールを活用してスタックコードを環境に適用する場合、パイプラインの構成にパラメータ値を定義することで、一貫性を保ちつつ効率的に構成を管理できます。Pattern: Stack Parameter Registry (パターン: スタックパラメータレジストリ)中央のレジストリにパラメータ値を格納することで、スタックのインスタンス構成情報を一元管理し、システム全体の設定変更に対する可視性と監査性を向上させます。スタックの再利用は、一貫性のある構成管理を実現する上で重要です。異なるスタックインスタンスが大幅に異なる場合には、それぞれを異なるスタックとして定義することが推奨されます。この章を通じて、スタックパラメータの管理と適用のアプローチが多様であることが明らかになりました。特にセキュリティに関する配慮が必要な部分では、最初から安全な取り扱いを心がける必要があると強調されています。システムやチームの成熟度に応じて適切な構成管理のアプローチを選択することが重要だと感じます。環境やチーム間での一貫性を保ちつつ、セキュリティを確保するための実践的なアドバイスを得ることができました。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)継続的なテストとデリバリーはインフラストラクチャコードの品質を維持し、信頼性を高めるための不可欠な実践です。アジャイルの原則に沿い、小さな変更を頻繁にテストし、即座にフィードバックを得ることで、品質を段階的に向上させていくことが強調されています。このプラクティスは、開発者が直面する潜在的な問題を早期に特定し、修正することを可能にし、最終的にはより安定したインフラストラクチャの配信につながります。長期的には、このアプローチはリリースプロセスの効率化と、エラー発生時の迅速な対応を促進します。Why Continuously Test Infrastructure Code?継続的なテストは、インフラストラクチャを一貫して信頼できる状態に保つために不可欠です。インフラストラクチャが変化し続ける環境では、変更の配信を効果的に行う上で重要なテスト自動化のスイートを構築することが求められます。このプロセスは、開発から運用に至るまでのライフサイクル全体を通じてインフラストラクチャの品質を確保し、継続的な改善を促進するための基盤となります。テストの自動化は、未来の変更に対しても柔軟に対応できる堅牢なインフラを構築する上で、決定的な役割を果たします。What Continuous Testing Means継続的なテストは、品質をコードライティングプロセスに組み込むことで、問題を早期に発見し解決することを意味します。このアプローチは、開発者がコードを書く際にリアルタイムでフィードバックを得られるようにし、問題の迅速な特定と修正を可能にします。この即時性は、システム開発における迅速なイテレーションと改善を実現し、技術的負債の蓄積を避けることを目指します。What Should We Test with Infrastructure?インフラストラクチャのテストは、機能性だけでなく、セキュリティやコンプライアンス、パフォーマンスなど、幅広いリスクの管理を包括します。CDプロセスでは、これらのリスクをリリース前にテストし、潜在的な問題を事前に特定し修正することで、プロダクション環境へのリスクを最小限に抑えることを目指します。Challenges with Testing Infrastructure Codeインフラストラクチャコードのテストにはいくつかの課題があり、これらはしばしばデリバリーの速度と品質に影響を与えます。デクララティブなコードのテストが低価値であること、テストプロセスが遅いこと、そして依存関係による複雑さがそれらです。Challenge: Tests for Declarative Code Often Have Low Valueデクララティブなコードのテストは冗長な場合が多く、実際のリスクの特定や管理にはあまり寄与しません。テストはリスクを管理するためのものであり、単なるコードの繰り返しではないため、デクララティブなコードに対しては、より高いレベルのリスク分析とそれに基づいたテスト戦略が求められます。Challenge: Testing Infrastructure Code Is Slowインフラストラクチャコードのテストはプラットフォーム上でのインスタンスのプロビジョニングを必要とするため、遅延が生じる傾向があります。テストプロセスの速度を向上させるためには、小さなコンポーネントに分割し、依存関係を最小限に抑えることが重要です。Challenge: Dependencies Complicate Testing Infrastructure依存関係はインフラテストの複雑さを増大させます。モックやテストダブルなどを使用して依存関係をシミュレートすることで、テストの実施をより実用的かつ迅速にすることが可能です。Progressive Testing段階的なテストは、初期のシンプルなテストから始めて徐々に統合の範囲を広げる戦略です。テストピラミッドは、より低レベルのテストを多くし、高レベルの統合テストは少なくするべきだと提唱し、スイスチーズモデルは、複数のテストレイヤーが組み合わさることで、単一レイヤーの穴を補完することを示します。これらのモデルは、リスクを管理するために、どのステージでどのテストを行うべきかを考える上で役立ちます。Figure 8-1. Scope versus speed of progressive testing より引用Infrastructure Delivery PipelinesCDパイプラインは、プログレッシブテストとデリバリーを組み合わせたもので、自動化により一貫性を保ちます。パイプラインの各ステージは特定のトリガーやアクティビティを持ち、適切なスコープとプラットフォーム要素を備えています。パイプラインの構築には、適切なソフトウェアまたはサービスが必要ですが、これによってインフラストラクチャの変更が効率的に、かつ一貫して配信されることが保証されます。Testing in Productionプロダクションでのテストは、他の環境では再現できないリアルな条件下でのリスクを検証する機会を提供します。プロダクション環境には再現できない要素が多く存在し、これらを通じてリアルタイムでのリスク管理を実施することができます。プロダクションでのテストに伴うリスクを管理するためには、監視、可視性の向上、ゼロダウンタイムデプロイメント、プログレッシブデプロイメント、データ管理、カオスエンジニアリングなどの戦略が不可欠です。インフラストラクチャのテストは、その構築と運用の基盤です。この章ではインフラストラクチャのテストに関する一般的な課題とアプローチについて説明しましたが、テストとQAはインフラストラクチャアズコードの成功に不可欠なため、これらの分野に関するさらなる知識を深めることが推奨されます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)9. Testing Infrastructure Stacksこの章の焦点は、インフラストラクチャスタックのテストにあります。現代のソフトウェア開発では、インフラストラクチャのコードもアプリケーションのコードと同様に継続的にテストされるべきであるという考え方が強調されています。これはSREの実践においても極めて重要で、システムの安定性と効率性を保つためには、テストの自動化と継続的な改善が不可欠です。Example Infrastructureここでは、具体的なインフラストラクチャの例としてShopSpinnerのケースが紹介されます。この例を通して、リアルなインフラストラクチャの構築と管理の課題を理解することができ、特に再利用可能なスタックの概念が実際のプロジェクト管理においてどのように役立つかが明らかになります。The Example StackShopSpinnerのスタックの具体的な構成を示すセクションです。ここでの重要なポイントは、効率的なリソース管理とスタックのモジュール化の重要性です。これらの概念は、大規模なシステムにおいてコードの再利用性とメンテナンス性を高めるために重要です。Pipeline for the Example Stackこのセクションでは、ShopSpinnerのインフラストラクチャスタックに対するパイプラインの設計について説明されています。パイプラインの構成は、継続的インテグレーション（CI）と継続的デリバリー（CD） の実践に欠かせない要素であり、効率的な開発プロセスを実現するためのキーです。Figure 9-1. Simplified example pipeline for a stack より引用Offline Testing Stages for Stacksオフラインテストは、インフラストラクチャスタックの開発段階において、コードの品質を確保するために非常に重要です。この段階では、ネットワーク接続や実際のリソースへのアクセスなしにテストを行います。Syntax Checkingシンタックスチェックは、最も基本的ながらも重要なテストの一つです。このプロセスは、コード内のタイポや文法の誤りを迅速に特定し、より大きな問題が発生する前に修正する機会を提供します。Offline Static Code Analysis静的コード分析は、より高度なエラー検出やコーディングスタイルの改善に役立ちます。これにより、コードの品質とセキュリティが大幅に向上します。Static Code Analysis with APIAPIを用いた静的コード分析は、特定のインフラストラクチャプラットフォームに対するコードの適合性をテストするために重要です。これにより、実際の環境へのデプロイ前に潜在的な問題を特定できます。Testing with a Mock APIモックAPIを使用するテストは、実際のAPIとの統合前に、コードが期待通りに機能するかどうかを検証するのに役立ちます。これは、特に大規模なシステムでの統合テストにおいて重要です。Online Testing Stages for Stacksオンラインテストは、実際のインフラストラクチャや外部サービスとの統合を伴うテストです。これにより、オフラインテストでは捉えきれない実際の環境での動作を確認できます。Preview: Seeing What Changes Will Be Made変更のプレビューは、実際にコードを適用する前に、どのような変更が行われるかを確認するプロセスです。これは、特にインフラストラクチャの変更に伴うリスクを軽減するために重要です。Verification: Making Assertions About Infrastructure Resourcesインフラストラクチャリソースに関するアサーションの作成は、スタックが正しく設定されていることを検証するための手段です。これにより、システムの整合性とパフォーマンスを保証できます。Outcomes: Proving Infrastructure Works Correctlyインフラストラクチャが正しく機能していることを証明するためのテストは、最終的なユーザーエクスペリエンスに直接関連するため、非常に重要です。これにより、実際の環境でのインフラストラクチャの振る舞いを確認できます。Using Test Fixtures to Handle Dependenciesテストフィクスチャを使用して依存関係を処理する方法は、テストプロセスの複雑さを軽減し、より継続的かつ効率的なテスト環境を構築するための効果的なアプローチです。Test Doubles for Upstream Dependencies上流依存関係に対するテストダブルは、実際の依存関係なしでスタックをテストするための仮想的な環境を提供します。これは、開発プロセスの柔軟性を大幅に高めます。Test Fixtures for Downstream Dependencies下流依存関係に対するテストフィクスチャは、他のスタックが利用するリソースを提供するスタックのテストに役立ちます。これにより、インフラストラクチャ間の統合テストの精度が向上します。Refactor Components So They Can Be Isolatedコンポーネントをリファクタリングして単独でテストできるようにすることは、コードの品質と保守性を向上させるために重要です。これにより、システム全体の堅牢性が向上します。Life Cycle Patterns for Test Instances of Stacksスタックのテストインスタンスのライフサイクルパターンは、テスト環境の管理と最適化に関する洞察を提供します。これにより、リソースの使用効率とテストプロセスの効率が向上します。Pattern: Persistent Test Stack持続的テストスタックパターンは、安定したテスト環境を提供するが、時間が経つにつれて問題が発生する可能性があります。継続的なメンテナンスと監視が必要です。Pattern: Ephemeral Test Stackこのセクションは、エフェメラルテストスタックのパターンに焦点を当て、テストのたびに新しいインスタンスを作成して破棄する方法を提案します。このアプローチは、クリーンな環境を保証し、過去のテストからの\"クラッター\"（不要なデータや設定）による影響を排除します。私の経験から言うと、この方法は、特に頻繁に変更されるコードベースにおいて、信頼性と一貫性のあるテスト結果を提供するのに非常に有効です。しかし、新しい環境を都度設定するための時間コストは考慮する必要があります。特に、大規模なインフラストラクチャの場合、セットアップに時間がかかり、フィードバックループを遅くする可能性があります。Antipattern: Dual Persistent and Ephemeral Stack Stagesここで取り上げられているのは、永続的スタックとエフェメラルスタックの両方を組み合わせたアンチパターンです。この方法は、理論上は早急なフィードバックと堅牢なテスト環境の両方を提供するはずですが、実際には両方のアプローチの欠点を引き受けることになります。例えば、永続的スタックのインスタンスが\"ウェッジ状態\"（変更によって不安定な状態）になると、エフェメラルスタックステージがその安全網となる可能性があります。しかし、これはリソースの二重消費を招くだけでなく、結局のところ、チームは永続的スタックの問題を解決するために時間を費やさなければならない場合があります。Pattern: Periodic Stack Rebuild定期的なスタック再構築のパターンは、永続的なテストスタックを定期的に再構築することで、リソースの使用量の蓄積や、更新プロセスの信頼性の低下を防ぐことを目的としています。このアプローチは、特にメモリやストレージがテストの実行に伴い徐々に消費される場合に効果的です。ただし、これは根本的な問題を覆い隠す一時的な解決策であり、問題の本質的な解決には至らないことに注意が必要です。Pattern: Continuous Stack Reset連続スタックリセットのパターンは、各テストステージの完了後にスタックインスタンスを自動的に破棄し再構築することで、常にクリーンな状態を保つことを目指しています。この方法は、テスト実行のたびに一から環境を構築する時間を節約できる一方で、背後で発生する問題を見落とすリスクがあります。例えば、バックグラウンドでのインスタンス破棄が失敗した場合、次回のテスト実行時に問題が顕在化する可能性があります。Test Orchestrationテストオーケストレーションに関しては、テストフィクスチャの作成、テストデータのロード、テストスタックインスタンスのライフサイクル管理、テストツールへのパラメータ提供、テストツールの実行、テスト結果の統合、テストインスタンス、フィクスチャ、データのクリーンアップなど、多岐にわたる活動が含まれます。このセクションは、これらの複雑なプロセスを効率的に管理するための実践的なガイダンスを提供しています。Support Local Testingローカルテストのサポートは、開発者が共有パイプラインや環境にコードをプッシュする前に自分でテストを実行できるようにすることを目的としています。これは、特にクラウドベースのインフラストラクチャで働く開発者にとっては不可欠です。ローカルでのテストは、より迅速なフィードバックを可能にし、開発プロセスの効率を大幅に向上させることができます。Avoid Tight Coupling with Pipeline Toolsパイプラインツールとの密接な結合を避けることは、テストオーケストレーションの柔軟性と再利用性を保つ上で非常に重要です。パイプラインツールにテストを強く結びつけると、テストのセットアップや実行をパイプライン外で行う際に困難が生じることがあります。テストオーケストレーションを独立したスクリプトまたはツールで実装することは、パイプラインオーケストレーションとテストオーケストレーションの関心を適切に分離するのに役立ちます。Test Orchestration Toolsテストオーケストレーションツールに関しては、多くのチームがカスタムスクリプトを書いてテストをオーケストレーションしています。これらのスクリプトは、Bashスクリプト、バッチファイル、Ruby、Pythonなど、さまざまな言語で記述されることがあります。しかし、特定のワークフローに特化して設計されたツール（例：Test Kitchen、Molecule）も存在しますが、自分のニーズに合わせて設定するのは難しいことがあります。この章全体を通して、インフラストラクチャスタックのテストに関する包括的な概観と、その実践的な実装について深く掘り下げられています。スタックコードのテストにはまだ十分に成熟したツールや実践が存在しない中、この章は、現在利用可能なツールやカスタムスクリプティングを活用して、これらの課題にどのように対処するかを示唆しています。これは、インフラストラクチャのテストプロセスに取り組む上での貴重な洞察を提供するものであり、非常に有用です。さいごに現代のソフトウェア開発と運用の中核となる要素、すなわちインフラストラクチャスタックの管理と運用について深く探究しています。このセクションは、インフラストラクチャコードの設計、開発、テスト、デプロイメントの各フェーズにおけるベストプラクティスと戦略を詳細に説明しており、現代のIT環境における効率性、スケーラビリティ、信頼性の実現に必要な知識とツールを提供します。特に注目すべきは、インフラストラクチャとアプリケーションの間の相互依存性の管理と、自動化されたテストプロセスの重要性に焦点を当てた点です。これらのトピックは、DevOps文化の中心であり、迅速かつ効率的なソフトウェアデリバリーを可能にする基盤となっています。また、パイプラインの設計とオーケストレーションのセクションは、コードの変更が生産環境にどのように流れるか、そしてそのプロセスをどのように最適化し、安全に保つかについての洞察を提供しています。この部分は、持続可能なインフラストラクチャ管理のための戦略的アプローチを明らかにし、リスクを最小限に抑えつつ高いパフォーマンスを実現する方法を提案しています。セクション全体を通して、可読性、再利用性、モジュール性の観点からインフラストラクチャコードを設計することの重要性が強調されています。コードの品質と管理性を高めることは、時間の経過と共にシステムのメンテナンスと進化を容易にします。また、セキュリティとコンプライアンスの考慮は、現代のインフラストラクチャスタックの設計と運用において不可欠な要素です。最終的に、このセクションは、インフラストラクチャスタックの管理における複雑性と挑戦に対処するための網羅的で実践的なガイドを提供しており、読者にとって非常に価値のあるリソースであると言えます。この知識を活用することで、ITプロフェッショナルはより強固で効率的なシステムを構築し、ビジネスの成長と変化に迅速に対応できるようになるでしょう。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/16/015354","isoDate":"2023-11-15T16:53:54.000Z","dateMiliSeconds":1700067234000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文","contentSnippet":"はじめに2016年、初版の『Infrastructure as Code』がリリースされ、クラウド技術の運用における新たな標準をぶち立てました。公式サイトもここに置いておきます。infrastructure-as-code.com初版の2017年に日本語版がリリースされました。mizzy.orgそれから4年後、待望の『Infrastructure as Code, 2nd Edition』が登場した。この新版は、サブタイトルを「Managing Servers in the Cloud」から「Dynamic Systems for the Cloud Age」へと変更し、クラウド技術の進化と共に変わるシステム管理のダイナミクスに焦点を当てている。さらに、360ページから427ページへと内容が拡張され、より包括的な情報と洞察が提供されている。残念ながら、『Infrastructure as Code, 2nd Edition』の日本語版は現在提供されていませんがこの本はクラウドインフラストラクチャの管理に関して重要な洞察と知識を提供しており、その内容は多くの専門家や技術者にとって非常に価値があります。Infrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon『Infrastructure as Code』の第二版では、かつて新しい概念として導入されたインフラストラクチャとしてのコードが、今や世界中の企業、銀行や伝統的な組織を含めてクラウドへの移行が進む中で、開発チームが大規模なインフラコードベースの構築において不可欠なものとなっています。この改訂版は、DevOpsチームによって開発された原則、実践、パターンを活用し、クラウド時代に適したインフラの管理方法を明らかにしています。システム管理者、インフラエンジニア、ソフトウェア開発者たちに、クラウドと自動化技術を用いて、容易に、安全に、迅速に、かつ責任を持って変更を加える方法を教えます。また、コードとして全てを定義し、小さく疎結合な部品を組み合わせてシステムを構築する技術も伝えます。ただし、日本語版のリリースがなされぬままに、次の第三版が出版される可能性があります。これはそういった悲しみの読書感想文でもあります。また、このブログはずっと。次回の記事syu-m-5151.hatenablog.com目次I. Foundations (基礎)1. What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)   - インフラストラクチャをコードで管理する概念とその重要性について説明します。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)   - クラウドインフラストラクチャ管理の基本原則を掘り下げます。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)   - 現代のインフラストラクチャプラットフォームの種類と特徴について論じます。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)   - インフラストラクチャ要素をコードとして定義する実践方法に焦点を当てます。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードの提供)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。I. Foundations (基礎)What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)この章は、現代のITインフラストラクチャの管理における根本的なシフトを示唆しています。クラウドとインフラストラクチャの自動化技術は、より迅速かつ信頼性の高い価値提供を可能にする一方で、管理するべきものの複雑さと多様性を増大させています。このジレンマは、組織がデジタル化するにつれて特に重要になってきています。「デジタル」という言葉は、ソフトウェアシステムが組織の活動に不可欠であることを意味します。これは私自身のソフトウェアエンジニアおよびSREとしての経験にも共鳴します。変更管理プロセスを厳格化することで混乱を防ごうとする試みは、しばしばクラウド技術の利点を損なうものです。「クラウドと自動化技術を利用して、変更を容易に、安全に、迅速に、そして責任を持って行うことができる」というこの本の前提は、特に重要です。この利点は、自動化ツールやクラウドプラットフォームというツールそのものからではなく、これらの技術の使い方に依存しています。印象的なのは、インフラストラクチャとしてのコード（IaC）が、ソフトウェア開発からの実践に基づいたインフラストラクチャの自動化へのアプローチであるという点です。これは、システムのプロビジョニングと変更およびその設定を一貫して、繰り返し可能なルーチンとして扱います。コードの変更を行い、それらの変更をシステムに自動的にテストし適用します。この章はまた、クラウド時代のインフラストラクチャへのアプローチが、速度と品質の間の偽のジレンマを排除する方法を説明しています。速度を品質向上の手段として利用し、品質を高速なデリバリーの可能性として利用します。また、このような言及が出てくるのもソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとして定着しているこの本ならではだなって思いました。t-wada.hatenablog.jp「クラウド時代のインフラストラクチャを管理するためには、クラウド時代のマインドセットが必要」というメッセージは、私の経験と完全に一致します。クラウド時代では、変更の速度を利用してリスクを減らし、品質を向上させる新しい考え方が求められます。このアプローチは、根本的なアプローチの変更と変更とリスクに対する新しい考え方を必要とします。\"A fundamental truth of the Cloud Age is: Stablity comes from making changes.\"（クラウド時代の基本的な真理は：変更から安定性が生まれる）は、インフラストラクチャの管理における直感に反すると思いますが2023年の現在ではとても納得することが出来ます。未パッチのシステムは安定しているのではなく、脆弱であり、発見した問題をすぐに修正できない場合、システムは安定していないという考え方です。最後に、インフラストラクチャとしてのコードの3つのコアプラクティス：すべてをコードとして定義する、進行中のすべての作業を継続的にテストし提供する、そして、独立して変更できる小さくシンプルな部品を構築する、これらはインフラストラクチャの管理における新しい標準を示しています。似たようなプラクティスはソフトウェア開発でももちろん存在していてソフトウェア開発のプラクティスをインフラ管理に持ち込める強みのようなものを強く感じました。レガシーコードからの脱却 ―ソフトウェアの寿命を延ばし価値を高める9つのプラクティス作者:David Scott BernsteinオライリージャパンAmazonこの章を読んで、クラウド時代におけるインフラストラクチャ管理の新しい考え方とアプローチについての理解が深まりました。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)この章は、クラウド時代のインフラストラクチャ設計と実装における基本原則を提示し、それらがどのように従来の「鉄の時代」のインフラストラクチャと異なるかを示しています。クラウド時代はコンピューティングリソースを物理的なハードウェアから切り離し、これらが仮想的な構成物として変更や破棄が可能になります。「鉄の時代」とCloud Native を語っている書籍があり一章だけでも面白いの読んでほしいです。Kubernetesで実践するクラウドネイティブDevOps作者:John Arundel,Justin DomingusオライリージャパンAmazon原則: Assume Systems Are Unreliable (システムが信頼できないと仮定する)クラウドスケールのインフラストラクチャでは、信頼性のあるハードウェアを使用しても障害は発生します。この原則は、根底のリソースが変化したときにも中断なくサービスを提供するための設計を必要とします。重要性と実装の方法この原則の重要性は、特にクラウド環境で顕著になります。クラウドでは、物理的なサーバーやネットワーク機器に依存しない仮想化されたリソースを使用します。これらのリソースは柔軟でスケーラブルですが、未知だったりコントロール外の障害の可能性も含まれています。したがって、システムの設計において、予期しないエラーに対処する機能を組み込むことが重要です。障害を前提とした設計では、冗長性の構築、フォールトトレラントなアーキテクチャの採用、自動回復機構の組み込みなどが行われます。例えば、データの自動バックアップ、複数の地域にまたがるサービスのデプロイ、障害発生時にトラフィックを自動的に切り替えるロードバランシングなどがこれに該当します。総合的なアプローチシステムの信頼性を高めるためには、ハードウェアとソフトウェアの両方の側面を考慮した総合的なアプローチが必要です。これには、適切なハードウェアの選択、ログやメトリクスの取り扱い、ソフトウェアの品質保証、セキュリティ対策、そして継続的なメンテナンスとアップデートが含まれます。「システムが信頼できないと仮定する」という原則は、特にクラウドベースのインフラストラクチャにおいて重要です。この原則に従うことで、システムはより堅牢で回復力があり、最終的にはユーザーに対してより信頼性の高いサービスを提供することができます。このアプローチを採用することで、企業は技術的な障害によるリスクを最小限に抑え、ビジネスの継続性を確保することができるのです。参考リンクAWSの公式ドキュメント - AWS Well-Architected FrameworkAWSが提供するこのフレームワークは、信頼性の高いクラウドアプリケーションの設計に関するベストプラクティスを示しています。Google Cloudのドキュメント - Google Cloud Architecture FrameworkGoogle Cloudでの信頼性の高いシステム設計に関する包括的なガイドです。『Site Reliability Engineering』GoogleのSREチームによって書かれたこの本は、大規模なシステムの信頼性を保つための実践的なアプローチを紹介しています。『継続的デリバリー　信頼できるソフトウエアリリースのためのビルド・テスト・デプロイメントの自動化』本書は、本番環境にデプロイされるソフトウェアの設計において考慮すべき点、特に継続的デリバリーをどのように実践するかに重点を置いています。原則: Make Everything Reproducible (全てを再現可能にする)システムの回復性を高める一つの方法は、その部品を容易かつ信頼性高く再構築できるようにすることです。これによりテスト環境を本番環境と一致させたり、負荷の高い時に需要に応じてインスタンスを追加することが容易になります。でも、実際には様々な理由から完全に一致させることは難しいので機能を制限したりコスト削減の為にkube-downscalerやInstance Schedulerなどを入れるようにしましょう。実際の経験から、この原則を守るためのキーポイントは、構成管理とバージョン管理の徹底です。例えば、私が取り組んだプロジェクトでは、全てのサーバー設定や依存関係をコードで管理し、Gitなどのバージョン管理システムを使用しました。これにより、ある特定のバージョンのコードベースから環境を正確に再現できるようになります。また、自動化されたデプロイメントパイプラインを設置することで、一貫性のあるデプロイメントプロセスを確保しました。これは、予期しない問題が生じた場合に、迅速に対応できるようにするために重要です。さらに、継続的インテグレーション（CI）を活用することも大切です。CIツールを使用することで、コードの変更が他の部分に悪影響を及ぼさないかどうかを常に確認できます。例えば、新しい機能を追加する際には、既存のシステムに影響がないかを自動テストで確認します。これにより、安定した本番環境を保ちながら迅速に開発を進めることができます。最後に、ドキュメントの重要性を忘れてはなりません。システムの各部分がどのように機能し、どのように相互作用するかを明確に文書化することで、新しいメンバーやチーム外の人がシステムを理解しやすくなります。これにより、効率的なコラボレーションと問題解決が促進されます。落とし穴: Snowflake Systems (特殊なシステムの罠)スノーフレークシステムは再構築が困難なシステムのインスタンス、または本来似ているべき環境が理解できない方法で異なる環境を指します。これらのシステムはリスクを生み、管理するチームの時間を浪費します。特殊な設定やカスタムの依存関係が原因で、システムが一意的になりすぎることがあります。これは、将来のスケーラビリティやメンテナンス、アップグレードの際に問題を引き起こします。また、これらのシステムは新しいチームメンバーにとって理解しにくく、エラーの原因となる可能性が高まります。原則: Create Disposable Things (廃棄可能なものを作る)ダイナミックなインフラストラクチャに対処するためのシステムを構築することは重要ですが、システム自体がダイナミックであることも重要です。部品を柔軟に追加、削除、開始、停止、変更、移動できるようにすることが重要です。この原則の鍵は、自動化とスケーラビリティです。インフラストラクチャのコード化（Infrastructure as Code: IaC）を採用することで、システムの部品を簡単に作成し、廃棄することができます。また、コンテナ技術やサーバーレスアーキテクチャを利用することで、リソースを効率的に管理し、必要に応じて柔軟にスケールアップまたはスケールダウンできます。これにより、システムのメンテナンスやアップデートを簡単に行い、変更に迅速に対応できるようになります。原則: Minimize Variation (変動を最小限にする)システムが成長するにつれて、理解、変更、修正が難しくなります。多くの異なる種類の部品があるほど、作業は複雑になります。したがって、システムを管理しやすくするためには、異なる種類の部品を少なくすることが有用です。私の経験では、使用する技術やツールの数を最小限に抑えることで、システムの理解と管理が大幅に容易になりました。例えば、異なるプロジェクトやチーム間で同じ技術スタックやツールを使用することで、知識の共有が容易になり、新しいメンバーのトレーニングもスムーズに進みました。Configuration Drift (設定の変動)設定の変動は、かつて同一だったシステムが時間の経過とともに異なるようになることを指します。手動での変更や、一部のインスタンスにのみ自動化ツールを使用して行うアドホックな変更が原因で発生することがあります。この問題を解決するために、私は以前のプロジェクトで、全ての設定変更を中央で管理し、自動化ツールを用いて全インスタンスに一貫して適用する方法を採用しました。これにより、設定の一貫性が保たれ、予期しない問題の発生を防ぐことができました。Configuration Drift: How It Happens, Top Sources + How to Stop It for Good原則: Ensure That You Can Repeat Any Process (任意のプロセスを繰り返せるようにする)再現性の原則に基づき、インフラストラクチャに対して行うあらゆる操作を繰り返せるようにする必要があります。スクリプトや設定管理ツールを使用して行動を繰り返す方が、手動で行うよりも簡単です。実際、私は自動化ツールやスクリプトを利用して、インフラストラクチャの構築、設定、デプロイを繰り返し可能にしました。これにより、新しい環境を迅速かつ一貫して構築でき、エラーの発生率を低減しました。また、これらのプロセスを文書化し、全チームメンバーが理解しやすい形で共有することで、作業の効率化と知識の共有を実現しました。SREにおけるトイルの判断と切り分け方IT Infrastructure Automation: A Beginner’s Guideこの章を読んで、クラウド時代のインフラストラクチャの原則が、伝統的なインフラストラクチャとどのように異なるか、そしてこれらの原則がどのようにクラウドプラットフォームの性質を最大限に活用する鍵となるかを理解しました。クラウドプラットフォームにおける変更の容易さを抵抗するのではなく、品質と信頼性を得るためにそれを利用することの重要性が強調されています。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)この章では、クラウドインフラストラクチャの複雑さを解体し、その構成要素を理解しやすく分類しています。ここで提示されたモデルは、特定の技術やツールに依存することなく、概念やアプローチを議論するための文脈を作り出しています。これは非常に有益で、私たちが使用するテクノロジースタックやプラットフォームに関係なく、議論を関連性のあるものに保つために役立ちます。インフラストラクチャシステムの部品 (The Parts of an Infrastructure System)モダンなクラウドインフラストラクチャは、アプリケーション、アプリケーションランタイム、インフラストラクチャプラットフォームの3つの主要な層で構成されています。この分類は、インフラストラクチャの複雑な世界を整理し、各層がどのように組織全体の機能提供に寄与しているかを明確にします。私の経験では、この3層モデルを理解し、適切に管理することが、効率的なシステム運用に不可欠です。特にアプリケーション層の性能と信頼性を保証するためには、アプリケーションランタイムとインフラストラクチャプラットフォームの調和が必要です。例えば、あるプロジェクトでは、コンテナ化されたアプリケーションをクラウド上で稼働させるために、Kubernetesを使用しました。これにより、アプリケーションランタイムの管理が容易になり、インフラストラクチャプラットフォームのリソースを効率的に利用することができました。また、これらの層を適切に管理することで、全体のシステムメンテナンスやアップグレードもスムーズに行えるようになりました。しかし、すべてのプロジェクトで当てはまるわけではないです。他のプロジェクトには他の要件や制約がありそれぞれに違う正解があると思います。Figure 3-1. Layers of system elements より引用\"Applications and services provide capabilities to your organization and its users. Everything else in this model exists to enable this layer.\" (アプリケーションとサービスは、あなたの組織とそのユーザーに機能を提供します。このモデルの他のすべては、この層を可能にするために存在します。)はアプリケーション層が最終的な目標であり、アプリケーションランタイムとインフラストラクチャプラットフォームがその実現のための手段であることを示しています。これは、インフラストラクチャをただのサポート機能ではなく、組織の目的達成に不可欠な要素として位置づけている点で示唆に富んでいます。インフラストラクチャプラットフォーム (Infrastructure Platforms)このセクションは、インフラストラクチャとしてのコード実践において、ダイナミックなインフラストラクチャプラットフォームがいかに中心的な役割を担っているかを強調しています。クラウド技術は物理ハードウェアからの解放をもたらし、APIを通じた資源の管理を可能にしました。一部をクラウドベースのインフラストラクチャプラットフォームを活用することで、システムの柔軟性と拡張性が大幅に向上しました。例えば、AWSのサービスを使用して、サーバーレスアーキテクチャを構築しました。これにより、物理的なハードウェアの制約から解放され、APIを介してリソースを効率的に管理することができるようになりました。このアプローチは、システムの拡張性を高めるだけでなく、運用コストの削減にも寄与することがあります。\"Virtualization decoupled systems from the hardware they ran on, and cloud added APIs to manage those virtualized resources.\" (仮想化はシステムを実行しているハードウェアから切り離し、クラウドはこれらの仮想化されたリソースを管理するAPIを追加しました。)は仮想化とクラウドがどのようにしてインフラストラクチャの運用を変革したかを端的に表しています。APIによる管理は、リソースの柔軟な扱いを可能にし、インフラストラクチャの変更や拡張を以前に比べて格段に簡単にしました。インフラストラクチャリソース (Infrastructure Resources)インフラストラクチャリソースは、現代のITシステムの根幹を成す重要な要素です。計算、ストレージ、ネットワークのこれら3つの基本リソースは、システムの性能や拡張性を決定づける要因となります。仮想マシン、コンテナインスタンス、データベースインスタンスなどの形態で利用されるこれらのリソースは、クラウドインフラストラクチャにおいて特に重要です。これらを適切に管理し、最適化することで、システムの効率性、柔軟性、信頼性を高めることができます。\"The line between a primitive and a composite resource is arbitrary, as is the line between a composite infrastructure resource and an application runtime service.\" (プリミティブリソースとコンポジットリソースの間、またコンポジットインフラストラクチャリソースとアプリケーションランタイムサービスの間の線引きは任意です。)は、インフラストラクチャリソースのカテゴライズが一定の基準に基づいているわけではなく、使用する文脈や目的に応じて変わることがあるという点を浮き彫りにしています。重要なのは、これらのリソースをどのようにして有効に組み合わせ、運用するかということであり、そのためには柔軟性が必要です。全体を通して、この章はクラウドインフラストラクチャの理解を深め、それぞれの要素がどのように相互作用して機能するのかを示す貴重な洞察を提供しています。これらの知識は、インフラストラクチャとしてのコードを実践する上で、私たちが直面する課題への取り組み方や、利用可能な技術を選択する際の指針となります。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)インフラストラクチャをコードとして定義する理由 (Why You Should Define Your Infrastructure as Code)インフラエンジニアとして、インフラストラクチャをコードとして定義することの価値を語るのは、自明の理だと感じます。しかし、このアプローチは私たちの仕事を根本的に変えました。初めて自動化スクリプトを書いたとき、それは単なる作業の簡略化ではなく、再利用可能性、一貫性、透明性をもたらしました。これは組織のアジリティを高め、変更を迅速かつ確実に行う能力を提供する秘密の要因となります。これらの価値は、インフラストラクチャの変更が頻繁であろうとなかろうと、品質を向上させるために速度を活用することにあります。コードとして定義できるもの (What You Can Define as Code)過去にはプラットフォームのウェブベースのユーザーインターフェイスを使用したり、CLIを駆使してインフラストラクチャを手動でプロビジョニングすることが一般的でした。しかし、インフラストラクチャをコード化することで、過去のプロジェクトで見た、可視性の高い変更管理と迅速な展開の実現が可能となりました。これは、経験上も正しく技術的な変更が頻繁に発生する環境で特に重要です。インフラストラクチャをコードとして定義することは、変更の自動化、文書化されたプロセス、およびエラーの減少に大きく貢献します。また、様々な現場ではIaCを通じて運用効率の向上、設定の一貫性、そしてセキュリティの強化を実現しています。IaCはリスクを軽減し、復元力の高いシステムを構築するための重要な手段となっています。さらに、チームの生産性の向上とスケールアップの際の柔軟性も、IaCの利用によって可能となっています。インフラストラクチャコーディング言語 (Infrastructure Coding Languages)スクリプト言語やDSLの使用から、一般的なプログラミング言語を使用したインフラストラクチャのツールへの移行は、運用の柔軟性を飛躍的に向上させました。以前に取り組んだプロジェクトでは、Terraformのような宣言的言語を使用してインフラストラクチャを定義し、それがもたらすシンプルさと明確さに驚かされました。このようなツールにより、インフラストラクチャのコードが従来のプログラミングコードと同様に「リアルなコード」として扱われるようになりました。インフラストラクチャをコードとして定義するための実装原則 (Implementation Principles for Defining Infrastructure as Code)宣言的と命令的コードを混在させることなく、インフラストラクチャコードを「リアルな」コードとして扱うことは、私たちのコードベースをクリーンに保つために不可欠です。参加した多くのプロジェクトでは、技術的負債を積極的に管理し、コードの品質を維持するために、コードレビュー、ペアプログラミング、自動テストなどの慣行を取り入れていました。これらは、インフラストラクチャコードの維持可能性を確保するために重要な実践です。この章は、システムをコードとしてどのように定義するか、その方法とその背後にある理由を詳細に説明しています。インフラストラクチャを定義するための適切な言語を選択することは、効果的なインフラストラクチャを構築する上での重要な課題です。私の経験では、この課題はまだ解決されていませんが、本書を通じて、このテーマが再び現れ、私たち全員が最善の方法を発見するための考察を深めることを期待しています。まとめ『Infrastructure as Code』の初めの4章は、クラウド時代のインフラストラクチャ管理の新しいパラダイムを解き明かしています。第1章では、変更を効率的に、安全に、かつ迅速に行うためのインフラストラクチャとしてのコード（IaC）の基礎を設定します。第2章では、システムの不確実性を前提とし、再現性、廃棄可能性、変動の最小化といったクラウド時代のインフラストラクチャ設計の原則に深く潜ります。第3章は、インフラストラクチャプラットフォームとそのリソースがどのようにアプリケーションランタイム層の構築に寄与するかを具体的に説明し、計算、ストレージ、ネットワークという基本リソースを掘り下げます。そして第4章は、これらのリソースをシンプルで独立して変更可能な部品に分けることの重要性を強調し、チームワークフローとインフラストラクチャの安全な変更方法について具体的なガイダンスを提供します。これらの章は、IaCの実践における基本的な理解を構築し、次のセクション「II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)」でのより具体的なスタック構築への取り組みへと説明してくれます。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/15/134317","isoDate":"2023-11-15T04:43:17.000Z","dateMiliSeconds":1700023397000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Terraformの条件分岐にうってつけの日","contentSnippet":"Infrastructure as Codeの概念とTerraformの役割Infrastructure as Code (IaC) は、現代のインフラ管理の根幹を成すものです。IaCがどんなものか様々な言論があると思いますが、ここではソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとIaC 本に準拠しておきます。IaCによる自動化、バージョン管理、テスト、そして継続的インテグレーションなどのプラクティスは、システム管理の世界に革命をもたらしました。ちなみに個人的には各々のプラクティスを一つずつ実践しない度にIaCの価値は一つずつ確実に下がっていくものだと確信してます。ですが、各々にコストがかかるものなので各プラクティスをどこまで実践するかは非常に難しい問題だとも同時に思います。その中で周知の事実だとは思いますがTerraformは、これらのプラクティスを宣言的なインフラストラクチャの管理、定義、および構成に応用することで、効率性と柔軟性の高いインフラストラクチャ管理を可能にします。このツールは、設計から実装までの過程を劇的に変える可能性を秘めています。Infrastructure as Codeの概念とTerraformの役割に関する参考リンクInfrastructure as Code - AWSInfrastructure as Code - Google CloudIntroduction to Terraform - HashiCorpInfrastructure as Codeの原則とTerraformInfrastructure as Codeの原則には、以下のような要素が含まれます​​:簡単に再現できるシステム: Terraformを使用することで、インフラストラクチャをコードとして定義し、簡単に再現可能なシステムを構築できます。使い捨てにできるシステム: サーバーなどのリソースを一時的なものとして扱い、必要に応じて簡単に生成・破棄できます。統一的なシステム: 全てのインフラストラクチャのコンポーネントを統一的な方法で管理します。反復できるプロセス: 同じ設定を繰り返し適用することで、一貫性と信頼性を保ちます。これらの原則に基づいて、Terraformは以下のような機能を提供します:リソースの自動生成と管理: Terraformを使用すると、インフラストラクチャのリソースを自動的に生成・管理できます。宣言的なインフラの構築: Terraformを通じて、インフラストラクチャの状態を宣言的に定義し、計画的かつ一貫性のある方法でインフラを構築・更新します。バージョン管理のサポート: Terraformの設定ファイルはバージョン管理システムで管理でき、変更履歴を追跡できます。モジュールと再利用可能なコンポーネント: Terraformではモジュールを使って、コードの再利用性を高めます。なのでそれ以外のプラクティスに関しては別のソリューションで実現してあげる必要があります。Terraformの条件分岐のテクニックと利用場面もう少し能書きを垂れるかなって思ったんですけどもう飽きたので普通にテクニックや使い方の話をしていきます。Terraformは基本的に宣言的なインフラ定義ツールですが、宣言的だけでは現実の複雑な要求を満たすのが難しい場合があります。そのため、Terraformは手続き型プログラミングに近い柔軟性も提供します。条件分岐やループなど、より具体的な制御が必要な場面で役立つ機能を組み込んで、効率的かつ柔軟なインフラ管理を実現しています。それでは、これらのテクニックや利用場面について、具体的な例を交えて詳しく見ていきましょう。ループ (countとfor_each)ループは、同じタイプのリソースを複数回作成する際に便利です。countやfor_eachを使用して、コードの重複を避けながら、効率的にリソースを管理できます。利用場面A: 異なる環境に同一種類のリソースを複数作成resource \"aws_instance\" \"dev_servers\" {  count         = 5  instance_type = \"t2.micro\"  # その他の設定}利用場面B: 複数のユーザーにIAMロールを割り当てresource \"aws_iam_user\" \"users\" {  for_each = toset([\"alice\", \"bob\", \"charlie\"])  name     = each.value  # その他の設定}条件分岐 (countを使用)条件分岐を使用すると、環境やパラメータに基づいてリソースの作成を制御できます。これにより、開発環境と本番環境などで異なるリソース設定を実現できます。利用場面A: 本番環境でのみデータベースのインスタンスを作成resource \"aws_db_instance\" \"prod_db\" {  count = var.is_production ? 1 : 0  # データベースの設定}利用場面B: 開発環境ではリソースを作成せず、本番環境でのみ特定のリソース（例: S3バケット）を作成したい場合。resource \"aws_s3_bucket\" \"prod_bucket\" {  count  = var.env == \"prod\" ? 1 : 0  bucket = \"my-production-bucket\"  acl    = \"private\"}ここではvar.env変数がprod（本番環境）の場合にのみS3バケットを作成します利用場面C: 特定の機能フラグ（例: 監視機能の有効化）がオンの場合にのみ、関連リソース（例: CloudWatchアラーム）をデプロイしたい。resource \"aws_cloudwatch_metric_alarm\" \"example_alarm\" {  count               = var.enable_monitoring ? 1 : 0  alarm_name          = \"High-CPU-Utilization\"  comparison_operator = \"GreaterThanThreshold\"  evaluation_periods  = \"2\"  threshold           = \"80\"  # その他の設定}この例では、var.enable_monitoringがtrueの場合にのみCloudWatchアラームを作成します。ゼロダウンタイムデプロイメント (create_before_destroyを使用)ゼロダウンタイムデプロイメントは、システムやアプリケーションの更新時にサービスを停止することなく、新しいバージョンへの移行を行う手法です。Terraformにおけるゼロダウンタイムデプロイメントでは、create_before_destroyライフサイクル設定を使用して、新しいリソースを古いリソースを削除する前に作成します。これにより、サービスが継続的に稼働しつつ、背後で安全にリソースの更新や交換が行われます。利用場面A: アプリケーションの更新時に新旧インスタンスの平滑な切り替えresource \"aws_instance\" \"app_server\" {  ami           = \"ami-newversion\"  instance_type = \"t2.micro\"  lifecycle {    create_before_destroy = true  }  # その他の設定}このコードは、新しいAMIでEC2インスタンスを作成します。create_before_destroyがtrueに設定されているため、新しいインスタンスが完全に起動し、運用準備が整うまで旧インスタンスは削除されません。これにより、アプリケーションの更新中もサービスが継続して提供されます。利用場面B: インフラのリファクタリング時に既存リソースの無停止更新resource \"aws_s3_bucket\" \"storage\" {  bucket = \"my-new-bucket-name\"  lifecycle {    create_before_destroy = true  }  # その他の設定}この設定では、新しいS3バケットが作成される際、既存のバケットは新しいバケットの設定が完了し、利用可能になるまで保持されます。これにより、データの移行やバケットの設定変更が行われる際にも、サービスの中断を回避できます。ゼロダウンタイムデプロイメントの限界ゼロダウンタイムデプロイメントは最高だと思った皆様、悲報です。ゼロダウンタイムデプロイメントを行う際にcreate_before_destroyを使用すると、いくつかの問題点があります。特に、オートスケーリングポリシーを使うと、デプロイメントごとに自動スケーリンググループ（ASG）のサイズが最小サイズに戻ることが問題です。これは、デプロイメント時にサーバー数が本来の数より少なくなる可能性があるためです。解決策として、カスタムスクリプトを使用してAWS APIでデプロイメント前のインスタンス数を取得する方法があります。しかし、より重要なのは、複雑なタスクにはネイティブな解決策を使用することが望ましいということです。たとえば、AWSではinstance refreshというオートスケーリンググループ用のネイティブソリューションが提供されており、これはAWSによって完全に管理され、エラー処理も適切です。ただし、このプロセスは時に遅いことが欠点です。一般的には、instance refreshのようなネイティブなデプロイメントオプションを使うことが推奨されています。なので、Providerの実装次第という部分もあると思います。Lifecycle をちゃんとやっていると、柔軟性と安全性が格段に向上するlifecycle引数は、リソースの作成と破棄に関するカスタムルールを作成することで、Terraform操作の流れを制御します。これにより、特定のリソースの変更やインフラへの影響を防ぎつつ、リソースニーズに基づいて潜在的なダウンタイムを最小限に抑えることができます​​。prevent_destroy: このオプションは、特定のリソースの削除を防ぐために使用されます。例えば、ある属性の変更によりリソースの置換が必要になりダウンタイムが発生する可能性がある場合、prevent_destroyを使ってリソースの削除を防ぐことができます​​。create_before_destroy: この属性を使用すると、古いリソースを破棄する前に新しいリソースを作成できます。これにより、リソースの置換によるダウンタイムを避けることが可能です。create_before_destroyがない場合、Terraformはまずインスタンスを破棄し、その後再作成しますが、これによりダウンタイムが発生する可能性があります​​。ignore_changes: Terraformのワークフロー外で行われた変更を無視するために使用されます。例えば、AWS CLIで行われた変更をignore_changesを使ってTerraformの操作に影響しないようにすることができますlifecycleの学びの意義は、インフラ管理の柔軟性と安全性を高めることにあります。異なるlifecycleオプションを使用することで、意図しないリソースの削除を防いだり、インフラの再作成時のダウンタイムを最小限に抑えたり、外部からの変更をTerraformのプランに影響させないようにすることができます。これにより、Terraformを使ったインフラの管理がより安全かつ効率的になります。結論とかこれらの使い方はもちろんのこと原則を理解しながら活用することで、インフラストラクチャの管理において幸せな世界観を目指していきましょう。『Terraform: Up & Running』の日本語版第3版のリリースを心から祝福してます。この本は、Terraformの基本から応用までを幅広くカバーし、多くの開発者やシステム管理者にとってよても良い本となることでしょう。手元においておいて本当に損がない書籍かと思います。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy Brikmanオーム社Amazon参考資料Count: Repeating ResourcesFor Each: Repeating a Module Multiple TimesConditional ExpressionsResource Lifecycle: create_before_destroyManage resource lifecycleTerraform by HashiCorpIntroduction to TerraformZero Downtime Updates with TerraformTerraformチュートリアル - HashiCorp LearnTerraform Best Practices余談Ansible やDockerではどのようにループや条件分岐を実現しているかAnsibleでは組み込まれている機能で実現できますがDockerでは、ループや条件分岐は通常、Dockerfile内では直接実現できません。しかし、Docker Composeやスクリプトを使用して間接的にこれらを処理することができます。Kubernetesでも、ループや条件分岐はマニフェストファイル（YAML）内で直接的にはサポートされていませんが、Helmチャートのようなテンプレートエンジンを使用することで、これらの動作を実現できます。Helmは条件分岐や変数の代入などを可能にするテンプレート機能を提供しているのでそれぞれ紹介します。ループloopキーワードを使用して繰り返しタスクを実行します。- name: パッケージのインストール  yum:    name: \"{{ item }}\"    state: present  loop:    - httpd    - memcachedAnsible Loopsこの例では、.Values.services内の各サービスに対してループを行い、それぞれのnameとportを出力しています。{{- range .Values.services }}- name: {{ .name }}  port: {{ .port }}{{- end }}HelmチャートのテンプレートDocker Composeでのループと条件分岐Docker Composeでは直接的なループや条件分岐のサポートはありませんが、環境変数を利用して擬似的にこれらを実現できます。services:  web:    image: \"webapp:${WEBAPP_TAG}\"    environment:      - DEBUG=${DEBUG_MODE}この例では、WEBAPP_TAGとDEBUG_MODE環境変数を使用しています。条件分岐ステートメントを使用して、特定の条件に基づいてタスクを実行します。- name: 開発環境でのみ実行するタスク  command: echo \"これは開発環境用のタスクです\"  when: env == 'development'- name: 本番環境でのみ実行するタスク  command: echo \"これは本番環境用のタスクです\"  when: env == 'production'Ansible Conditionals{{- if .Values.debug }}environment: \"development\"{{- else }}environment: \"production\"{{- end }}ここでは、.Values.debugの値に基づいて環境を設定しています。debugがtrueならdevelopment、そうでなければproductionが選択されます。Helmのテンプレート関数この節では、Ansible、Docker、そしてKubernetesにおけるループと条件分岐の実装方法を比較しました。これらのツールはそれぞれに独自のアプローチを持っており、その違いを理解することで、適切なツール選択や実装戦略を行う上での参考になります。また、異なるツールでどのように同じ問題を解決しているかを知ることは、より深い技術的理解や柔軟な対応能力を身につけるために重要です。","link":"https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603","isoDate":"2023-11-14T06:46:03.000Z","dateMiliSeconds":1699944363000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました","contentSnippet":"概要資料参考文献概要Platform Engineering Meetup #5 で SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用 というテーマで登壇をしました。SREからPlatform Engineerへの拡大のセルフリバイバルになります。このブログでは、参考資料を見るために利用してください。気が向いたら続き書く資料 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?What Team Structure is Right for DevOps to Flourish?Making the Business Case for a Dedicated Platform Engineering TeamCNCF Platforms White PaperSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsTop Strategic Technology Trends for 2023: Platform Engineering道を照らす: プラットフォーム エンジニアリング、ゴールデンパス、セルフサービスのパワーオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイドネットワーク・エフェクト　事業とプロダクトに欠かせない強力で重要なフレームワークINSPIRED 熱狂させる製品を生み出すプロダクトマネジメント","link":"https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555","isoDate":"2023-10-05T14:35:55.000Z","dateMiliSeconds":1696516555000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとPlatform Engineerの交差点","contentSnippet":"Platform Engineering Meetup #5 #PFEM\rhttps://platformengineering.connpass.com/event/295048/ \r\rSREとPlatform Engineerの交差点: 2つの領域の交差と組織への適用 というタイトルで登壇します。\r\r登壇ブログ |『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました\rhttps://syu-m-5151.hatenablog.com/entry/2023/10/05/233555\r\rグレイラットの殺人 ワシントン・ポーが面白かったのでオススメです。\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015569/","link":"https://speakerdeck.com/nwiizo/sretoplatform-engineernojiao-chai-dian","isoDate":"2023-10-05T04:00:00.000Z","dateMiliSeconds":1696478400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Open InterpreterのDockerfile を書いたのでTipsとか","contentSnippet":"Dockerfile のベストプラクティスを考える機会はありますが皆さんの意見も聞きたい。今回は噂の便利ツール、Open Interpreterのような外部コマンドをどんどん実行して環境を作り変えるようなタイプのツールの場合にはDockerはとても有用です。そのようなツールを利用する時のDockerfile について考えていきます。リポジトリは以下になります。github.comGitHub Actionsとの連携GitHub Actionsは、CI/CD（継続的インテグレーションと継続的デリバリー）をGithub 上に簡単に実装できるツールです。今回は、trivy.ymlとdocker-publishを利用することで、セキュリティのスキャンとDockerイメージの自動公開が可能です。github.comtrivy.ymlの利用trivy.ymlは、Trivyという脆弱性スキャナーをGitHub Actionsで動かすための設定ファイルです。この設定を利用することで、Dockerイメージに存在するセキュリティの脆弱性を自動で検出できます。docker-publishの追加docker-publishは、DockerイメージをDocker Hubや他のレジストリに自動で公開するためのGitHub Actionsのワークフローです。これにより、新しいバージョンのOpen Interpreterがリリースされた際に、手動でイメージをビルド・プッシュする手間が省けます。Renovate.jsonの利用renovate.jsonは、依存関係を自動で更新する設定ファイルですが、これを使うとOpen Interpreterが依存しているライブラリやパッケージが新しくなったときに、自動でプルリクエストが作られるんです。そうすることで、いつも最新の状態を保てるわけですから、セキュリティリスクも減らせます。さらに、Pythonのパッケージも自動で更新したい場合は、requirements.txtを使って設定しておくと便利です。これにより、Pythonの依存パッケージも最新の状態を維持できるようになります。github.comDockerfileを書く際の注意点私は以下のようなDockerfileを書きましたその際に以下のようなポイントを意識して書いたので参考にしてください。github.com軽量なベースイメージの使用不必要なパッケージを含まない軽量なベースイメージを使用することで、ビルド時間とイメージサイズを削減できます。FROM python:3.11キャッシュの最適化RUNコマンドを効率的に配置することで、Dockerキャッシュを最適化できます。RUN apt-get update && \\  apt-get upgrade -y && \\  apt-get install -y --no-install-recommends git && \\  rm -rf /var/lib/apt/lists/*不必要なパッケージの削除--no-install-recommendsオプションを使用して、不必要なパッケージをインストールしないようにします。  apt-get install -y --no-install-recommends git && \\作業ディレクトリの設定WORKDIRを設定することで、その後のコマンドの実行ディレクトリを明示的に指定できます。WORKDIR /root機密情報はコンテナイメージに絶対に埋め込まない社内で有識者へ投げたら機密情報をビルドイメージに追加することを指摘されたので運用時の手癖やミスで何処かのレイヤーに不用意に埋め込まないようにしたgithub.comまとめDockerでOpen Interpreterを運用する際には他にもいろいろ考えるべきことがあると思うので皆さんと議論したいのでIssue待ってます。","link":"https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920","isoDate":"2023-09-19T15:29:20.000Z","dateMiliSeconds":1695137360000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"まずPR-AgentをPromptとします。","contentSnippet":"「ツールよりもプロンプトのほうが、隙間がなくて効率的なのでは？」... ああ、面倒なブログになるな、とおれは直感した。はじめに近年、プルリクエスト（PR）の管理が開発フローにおいてますます重要な位置を占めるようになっています。ただし、PRをより良く作る作業は往々にして煩雑で手間がかかりがちです。その解決策として、Codium AIによって開発されたPR-Agentが脚光を浴びています。このAIソフトウェアは、OpenAIのGPT-4技術を基盤にしており、単にOpenAIのAPIキーを設定するだけで、既存のCI/CDパイプラインに簡単にインテグレーションできます。github.comPR-Agentの主な機能PR-Agentは、様々なPR関連作業を自動化するための多機能なオープンソースプロジェクトです。具体的には、以下のような機能群を提供しています。/describe: タイトル、種類、要約、コードの詳細説明、およびラベルを自動で作成するためのPR（プルリクエスト）説明自動生成機能。/review: PRの主題、種類、関連テスト、セキュリティ問題、評価スコア、その他のフィードバックを調整可能に提供する自動レビュー機能。/ask ...: PRに関するフリーテキスト質問に回答する質問応答機能。/improve: PRを改善するためのコミット可能なコード提案を行うコード改善提案機能。/update_changelog: PRの変更内容に基づき、CHANGELOG.mdファイルを自動で更新する更新履歴自動更新機能。PR-AgentはOpenAIのAPIキーを設定するだけでCI環境に簡単に組み込め、開発者が効率的なPR作成と管理を行えるよう支援します。このツールはGPT-4を用いて高精度なソースコード解析とレビューを自動で行い、開発者が重要なポイントに集中できるようにします。さらに、「PR Compression Strategy」と呼ばれる独自のアルゴリズムによって、大規模なPRでも重要なファイルと主要な言語のコードブロックに焦点を当てた効率的なレビューが可能です。それ以外にもさまざまな設定により、PR-AgentはPR作成とレビューのプロセスを自動化し、効率化する強力なツールであり、大規模プロジェクトにおいてもスムーズかつ効率的なレビュープロセスを実現します。これらをどのように動作させればよいのかはUsage guideを読んでみてください。PR-Agent のPromptPR Compression Strategyにより、送信するファイルの戦略が定められています。その設定に加えて、pr-agent/pr_agent/settings/ ディレクトリには、TOML形式でプルリクエスト（PR）のレビュープロンプトのテンプレートが含まれています。具体的には、pr_review_promptはpr_reviewer_prompts.toml ファイルに定義されており、これがPRのレビュープロセスにおける基本的な指示とフォーマットを規定しています。この構成により、PRレビューが一貫性を持ち、効率的に行えるよう設計されています。pr_reviewer_prompts.toml 解説pr_reviewer_prompts.tomlは、Pull Request（PR）レビューに関する設定と指示を定義する設定ファイルです。この設定ファイルは、PRレビューを自動化する際に利用されます。pr_review_prompt セクションsystemこの設定は、レビュワーがどのような役割を果たすべきかを定義しています。具体的なPR Diffの入力例も提供され、新しく追加されたコード（+で始まる行）に焦点を当てるよう指示されています。system=\"You are PR-Reviewer, a language model designed to review git pull requests. ...\"num_code_suggestionsコード提案が必要な場合、その数や重要度についての指示がこの部分に記載されています。{%- if num_code_suggestions > 0 %}- Provide up to {{ num_code_suggestions }} code suggestions. ...{%- endif %}extra_instructionsパラメータで、追加的な指示や設定を行うために使用されます。この項目は主に以下のような用途で利用されることが多いです。{%- if extra_instructions %}Extra instructions from the user:{{ extra_instructions }}{% endif %}YAMLスキーマこの部分で、PRレビュワーが出力するレビュー結果のYAMLフォーマットが定義されています。Main theme, PR summary, Type of PR, etc.これらは、PRに関する基本情報を整理するためのフィールドです。Main theme:  type: string  description: a short explanation of the PRScore, Relevant tests added, Insights from user's answer, etc.これらのフィールドは、PRに関する詳細な評価やテスト情報、ユーザーからのフィードバックに基づく評価を行います。Score:  type: int  description: Rate this PR on a scale of 0-100 ...General suggestions, Code feedback, Security concernsこれらのフィールドは、具体的なコード提案やセキュリティ上の懸念など、PRのコードに関する詳細なフィードバックを提供します。General suggestions:  type: string  description: General suggestions and feedback for the contributors ...user セクションこのセクションは、PR作成者から提供される情報（タイトル、ブランチ、説明文など）を取り込む場所です。user=\"PR Info:Title: '{{title}}'Branch: '{{branch}}'Description: '{{description}}' ...\"この設定ファイルによって、PRレビューのプロセスが自動化され、一貫性を持つようになります。特定のプロジェクトやチームに特有の要件に応じて、これらの設定はカスタマイズ可能です。まとめpr_reviewer_prompts.tomlといった設定ファイルを読んで全体としてPRのフォーマットに忠実にプロンプトを作成していったのがわかりました。参考にしていきたいと思います。github.com参考PR-Agent を使って Pull Request をAIレビューしてみた。（日本語対応もしてみた）GitHub - Codium-ai/pr-agent: 🚀CodiumAI PR-Agent: An AI-Powered 🤖 Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! 💻🔍","link":"https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227","isoDate":"2023-09-06T07:52:27.000Z","dateMiliSeconds":1693986747000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ChatGPT: SREがCustom instructions機能を利用する","contentSnippet":"はじめに最近、ChatGPTからCustom instructions機能がリリースされました。Custom instructionsとは、ChatGPTの応答方法をより詳細に制御するカスタム命令を設定することができる機能です。ChatGPTの利用者にとって非常に便利な機能です。この機能により、ユーザーは特定の応答スタイルやフォーマットを要求することができるようになりました。これは、特定の業界や専門分野での使用など多岐にわたる用途に適応できるため、非常に有用です。めちゃくちゃ端的にかつ語弊を恐れずにいうと毎回、prompt を入力しなくてよくなるやつです。以前、公開したプロンプトに関するブログsyu-m-5151.hatenablog.comOpenAI CEOのSam Altman氏も、Custom instructionsのポストをしていましたので参考にしてみても良いかもしれません。damn i love custom instructions pic.twitter.com/su0BlttJF7— Sam Altman (@sama) 2023年7月22日  その上で私が利用してるものを公開します。What would you like ChatGPT to know about you to provide better responses?I'm a software developer and primarily use Golang. Depending on the application, I also utilize Shell Script, Terraform, and Ansible.I am a software developer and I like Cloud Native technologies such as Docker and Kubernetes.I like to develop, operate, and optimize systems.Technical advisor for several other companies.Please use Japanese.How would you like ChatGPT to respond?You are an AI programming assistant.Your response should be informative and logical.First, think STEP-BY-STEP, then describe your plan for what to build.Then output the code in a single code block.Keep your answers objective and concise, and use Markdown formatting.Be sure to include the name of the programming language at the start of the Markdown code block.Avoid enclosing your entire response in a triple backtick.また、 respondに信頼性に関する言及を求めていたのですが有益な情報が得られないので削除しておきました。まとめCustom instructions機能は、ChatGPTの応答をより細かく制御する強力なツールです。これにより、ユーザーは特定のニーズに合わせてモデルを調整することができ、より多様で効果的な結果を得ることが可能になります。この機能の導入により、ChatGPTはさらに多岐にわたる分野での応用が期待されます。この書籍はChatGPTによって達成された科学的な貢献や重要性を理解することができるのでオススメです。ChatGPTの頭の中 (ハヤカワ新書)作者:スティーヴン ウルフラム早川書房Amazonおすすめ記事honeshabri.hatenablog.com","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/22/204327","isoDate":"2023-08-22T11:43:27.000Z","dateMiliSeconds":1692704607000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREからPlatform Engineerへの拡大 というタイトルで登壇しました","contentSnippet":"概要Cloud Operator Days Tokyo 2023 で SREからPlatform Engineerへの拡大 というテーマでの登壇を果たしました。オンデマンド配信なのでいずれ見れるようになると思います。今回のサブタイトルは【運用の新時代】とし、それにちなんでメインタイトルを考えました。資料の作成過程で、話したい内容がどんどんと増えてきてしまい、20分という限られた時間での発表が一番の課題となりました。内容の整理に際して、具体と抽象 ―世界が変わって見える知性のしくみ という本を参照し、大変役立ちました。具体と抽象作者:細谷 功dZERO（インプレス）Amazon資料このブログでは、Cloud Operator Days Tokyo 2023での登壇内容をまとめております。資料作成時に参照したさまざまな参考情報も掲載していますので、読者の皆様が別途情報を探す手間を省けるよう心掛けました。ぜひ、本ブログをご活用ください。文字多くて分かりにくいのは分かってます。脳内整理はできているのですが資料を読みやすくすると20分に何も収まらず...。 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングあなたらしくSREO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?Top Strategic Technology Trends for 2023: Platform EngineeringMaking the Business Case for a Dedicated Platform Engineering TeamSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイド","link":"https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412","isoDate":"2023-08-10T06:04:12.000Z","dateMiliSeconds":1691647452000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREからPlatform Engineerへの拡大","contentSnippet":"SREからPlatform Engineerへの拡大 というタイトルで登壇してきました\r\rCloud Operator Days Tokyo 2023 運用の新時代　〜Effortless Operation〜\rhttps://cloudopsdays.com/\r\rクラウドインフラ運用技術者のための年次イベント「Cloud Operator Days Tokyo 2023」の見所を紹介\rhttps://cloud.watch.impress.co.jp/docs/news/1518302.html\r\rSREからPlatform Engineerへの拡大 というタイトルで登壇しました - じゃあ、おうちで学べる  https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412 \r\r登壇しかないので20分しかないのでｷﾞｭｯとしてしまいました。","link":"https://speakerdeck.com/nwiizo/srekaraplatform-engineerhenokuo-da","isoDate":"2023-08-09T04:00:00.000Z","dateMiliSeconds":1691553600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について","contentSnippet":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析についてというタイトルで登壇しました\r\r2023年8月3日 CloudNative Days Fukuoka 2023\rhttps://event.cloudnativedays.jp/cndf2023\r\rk8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について\rhttps://event.cloudnativedays.jp/cndf2023/talks/1885\r\rK8sGPT Deep Dive というタイトルで登壇しました #CNDF - じゃあ、おうちで学べる  \rhttps://syu-m-5151.hatenablog.com/entry/2023/08/03/155326","link":"https://speakerdeck.com/nwiizo/k8sgpt-deep-dive-kuberneteskurasutanoaiqu-dong-xing-fen-xi-nituite","isoDate":"2023-08-03T04:00:00.000Z","dateMiliSeconds":1691035200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Cloud Native の作法","contentSnippet":"2023年7月13日 \r\r成熟度モデルを活用したCloud Nativeへの道筋 という副題で登壇します #開発生産性con_findy\rhttps://syu-m-5151.hatenablog.com/entry/2023/07/13/131433\r\r\r開発生産性Conference の登壇資料\rhttps://findy.connpass.com/event/283417/","link":"https://speakerdeck.com/nwiizo/cloud-native-nozuo-fa","isoDate":"2023-07-13T04:00:00.000Z","dateMiliSeconds":1689220800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2023年もSRE再考と叫びなさい‼️","contentSnippet":"2023年もSRE再考と叫びなさい‼️ SREの跡を求めず SREの求めたるところを求めよ というタイトルで登壇してきました\r\r2023年3月3日 エンジニア文化祭 2023\rhttps://forkwell.connpass.com/event/272596/\r\r『2023年もSRE再考と叫びなさい!!』というタイトルで登壇しました - じゃあ、おうちで学べる\rhttps://syu-m-5151.hatenablog.com/entry/2023/03/03/105049","link":"https://speakerdeck.com/nwiizo/2023nian-mosrezai-kao-tojiao-binasai","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"自由研究には向かないウェブオペレーション ","contentSnippet":"自由研究には向かないウェブオペレーション サイト運用管理を取り巻く環境の変化 Cloud Native時代に考えるLinux オペレーション というタイトルで登壇してきました。\r\r2023年2月18日\r【今更聞けない】Linuxのしくみ - Forkwell Library #16\rhttps://forkwell.connpass.com/event/273179/\r\rあとがき\r『自由研究には向かないウェブオペレーション』というタイトルで登壇しました。\rhttps://syu-m-5151.hatenablog.com/entry/2023/02/18/201252","link":"https://speakerdeck.com/nwiizo/zi-you-yan-jiu-nihaxiang-kanaiuebuoperesiyon","isoDate":"2023-02-18T05:00:00.000Z","dateMiliSeconds":1676696400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" ポストモーテムはじめました","contentSnippet":"ポストモーテムはじめました - 良いポストモーテムを執筆するために必要な5つのポイント というタイトルで登壇してきました。\r\r2023年02月09日\rインシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT\rhttps://findy.connpass.com/event/273197/\r\r『ポストモーテムはじめました』というタイトルで登壇しました。 - じゃあ、おうちで学べる  \rhttps://syu-m-5151.hatenablog.com/entry/2023/02/09/113316","link":"https://speakerdeck.com/nwiizo/posutomotemuhazimemasita","isoDate":"2023-02-09T05:00:00.000Z","dateMiliSeconds":1675918800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"セキュア・バイ・デザインの鳴くところ","contentSnippet":"セキュア・バイ・デザインの鳴くところ\r安全なソフトウェアを全体から考えるみるで候\r\rOWASP Fukuoka Meeting #9\rhttps://owasp-kyushu.connpass.com/event/266585/\r\r副読ブログ\rhttps://syu-m-5151.hatenablog.com/entry/2022/12/07/204400","link":"https://speakerdeck.com/nwiizo/sekiyuabaidezainnoming-kutokoro","isoDate":"2022-12-07T05:00:00.000Z","dateMiliSeconds":1670389200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"cobra は便利になっている","contentSnippet":"2022年3-shake SRE Tech Talk #4\rhttps://3-shake.connpass.com/event/253028/","link":"https://speakerdeck.com/nwiizo/cobra-habian-li-ninatuteiru","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ProtocolBuffers/gRPCを安全に書き進めるためのエトセトラ","contentSnippet":"OWASP Fukuoka Meeting #6 \rhttps://owasp-kyushu.connpass.com/event/244388/ \r#owaspfukuoka","link":"https://speakerdeck.com/nwiizo/protocol-buffers-grpc-wo-an-quan-nishu-kijin-merutamefalseetosetora","isoDate":"2022-04-27T04:00:00.000Z","dateMiliSeconds":1651032000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"あるいはサイドカーでいっぱいの海","contentSnippet":"3-shake SRE Tech Talk #3 https://3-shake.connpass.com/event/241284/ #SRETT","link":"https://speakerdeck.com/nwiizo/aruihasaidokadeitupaifalsehai","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Observability Conference 2022 に登壇しました","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Dapr の概念と実装から学ぶObservability への招待","contentSnippet":"Observability Conference 2022 2022/03/11(Fri)\rDapr の概念と実装から学ぶObservability への招待\rhttps://event.cloudnativedays.jp/o11y2022/talks/1353","link":"https://speakerdeck.com/nwiizo/dapr-falsegai-nian-toshi-zhuang-karaxue-bu-observability-hefalsezhao-dai","isoDate":"2022-02-28T05:00:00.000Z","dateMiliSeconds":1646024400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"JJUGに向けて再変更/公演 CloudNativeな時代に求められるWebサービス基盤モデルの再考","contentSnippet":"JJUGナイトセミナー「Dapr特集」2/24(木) 開催\r\rhttps://www.java-users.jp/post/night202202/","link":"https://speakerdeck.com/nwiizo/gong-yan-cloudnativenashi-dai-niqiu-merareru-websabisuji-pan-moderufalsezai-kao","isoDate":"2022-02-24T05:00:00.000Z","dateMiliSeconds":1645678800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"CloudNativeな時代に求められるWebサービス基盤モデルの再考","contentSnippet":"Developers Summit 2022\rhttps://event.shoeisha.jp/devsumi/20220217\r\rhttps://event.shoeisha.jp/devsumi/20220217/session/3648/\r\r今週、ずっと体調が悪く昨日、PCR検査受けたが陰性\r後ほど、修正して再度、上げます。","link":"https://speakerdeck.com/nwiizo/cloudnativenashi-dai-niqiu-merareru-websabisuji-pan-moderufalsezai-kao","isoDate":"2022-02-17T05:00:00.000Z","dateMiliSeconds":1645074000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インフラエンジニアが学んだGo言語での並行処理失敗パターン","contentSnippet":"2021/11/16 Infra Study 2nd #7「SREと組織」にて発表\rhttps://forkwell.connpass.com/event/228038/","link":"https://speakerdeck.com/nwiizo/inhuraenziniagaxue-nda-goyan-yu-defalsebing-xing-chu-li-shi-bai-patan","isoDate":"2021-11-16T05:00:00.000Z","dateMiliSeconds":1637038800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREの車窓から","contentSnippet":"GeekGig #1 〜Goと私の一年〜\rhttps://showcase-gig.connpass.com/event/217914/","link":"https://speakerdeck.com/nwiizo/srefalseche-chuang-kara","isoDate":"2021-08-11T04:00:00.000Z","dateMiliSeconds":1628654400000,"authorName":"nwiizo","authorId":"nwiizo"}]},"__N_SSG":true}