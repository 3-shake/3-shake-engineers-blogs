<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sat, 06 Apr 2024 18:30:36 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[go-rod/rod でブラウザ自動化とWebスクレイピングをやっていく]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/04/05/145103</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/04/05/145103</guid>
            <pubDate>Fri, 05 Apr 2024 05:51:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめにWebスクレイピングの需要が高まる中、Goで実装する機会が増えてきました(よね?)。Goの豊富な標準ライブラリとシンプルな文法は、スクレイピングのような自動化タスクと非常に相性が良いです。が、今回はGoの有力なスクレイピングライブラリの1つである go-rod/rod の特徴を掘り下げながら、実際に現在所属している組織のサイト3-shake.comのWebサイトをスクレイピングする方法をご紹介します(広告的に許してくれ)。github.comgo-rod/rod の概要と特徴go-rod/rod`は、ChromeのDevToolsプロトコルを利用したブラウザ自動化とスクレイピングのためのハイレベルなドライバーライブラリです。単なるHTMLの取得だけでなく、ブラウザ上の操作を自動化できるのが大きな特長です。主な特徴は以下の通りです:ページのスクリーンショットを撮るクライアントサイドレンダリングされたページもスクレイピング可能フォームの自動入力E2Eテストリクエストのハイジャックつまり、ブラウザ上で手動で行える操作のほとんどを自動化できるわけです。これによりJavaScriptで動的に生成されるモダンなWebサイトに対しても、自在にスクレイピングを行えます。go-rod.github.ioまた、Goらしいシンプルで読みやすいAPIを提供しているのも魅力です。実装の詳細を隠蔽しつつ、柔軟で強力な機能を直感的に使用できるよう設計されています。インストールと基本的な使い方go-rod/rod は次のコマンドで簡単にインストールできます。go get github.com/go-rod/rodインストール後、Goのコードから次のように呼び出すことでブラウザを起動できます。package mainimport "github.com/go-rod/rod"func main() {    browser := rod.New().MustConnect().MustPage("https://3-shake.com/")    browser.MustWaitStable().MustScreenshot("3-shake.png")    defer browser.MustClose()}ここではブラウザオブジェクトを生成し、MustConnect() でブラウザプロセスに接続して続いて MustPage() を使ってページを開きます。それをMustScreenshot()を使ってスクリーンショットを撮っていきます。こちらがスクリーンショットです。defer 文で最後にブラウザを閉じるのを忘れずに。これだけでブラウザの自動操作の準備は整いました。めちゃくちゃにシンプルですね。3-shake.com のスクレイピングそれでは、実際に https://3-shake.com のWebサイトをスクレイピングしてみましょう。今回は以下の情報を抽出することを目標とします。全サービスの名前と説明文全ニュースのタイトルと日付サービス情報の抽出まず、サービス一覧を表示している要素を特定します。サイトを開発者ツールで覗いてみると、各サービスが以下のようなDOM構造になっていることがわかります。<li class="services__item">    <div class="services__block js-inview" data-inview-x="30" data-inview-s="700">        <p class="services__pic js-parallax">            <img src="path/to/image">        </p>    </div>    <div class="services__block js-inview" data-inview-x="-30" data-inview-s="700">        <div class="services__texts">            <div class="services__name">                <a href="path/to/service" target="_blank">                    <img src="path/to/logo">                    <p>サービス名<br><span>サービス名ふりがな</span></p>                </a>            </div>            <p class="services__lead">サービスの説明文</p>            <p class="services__link p-text--link">                <a href="path/to/service" target="_blank">サービスサイトへ<i class="p-icon-arrow-right"></i></a>            </p>        </div>    </div></li>これを元に、スクレイピングコードを書いていきます。// サービス情報をスクレイピングservices := page.MustElements("li.services__item")for _, service := range services {    name := service.MustElement(".services__name").MustText()    description := service.MustElement(".services__lead").MustText()    fmt.Printf("サービス名: %s\n", name)    fmt.Printf("説明文: %s\n", description)    fmt.Println("---")}MustElements() で li.services__item にマッチする要素を全て取得し、それぞれの要素から MustElement() と MustText() でサービス名と説明文を抜き出しています。ニュース情報の抽出次にニュース一覧を取得しましょう。こちらは以下のようなDOM構造になっています。<div class="p-articles js-news__target l-col l-col--list js-inview-box" data-inview-y="15">                       <div class="p-articles__item l-col__block--4 is-show">        <div class="p-articles__thumb">            <a class="p-articles__link" href="path/to/news" target="_self">                <span style="background-image: url('path/to/image');"></span>            </a>        </div>        <div class="p-articles__info">            <p class="p-articles__date">YYYY.MM.DD</p>            <ul class="p-categories">                <li class="p-categories__item">                    <a href="path/to/category">カテゴリ名</a>                </li>            </ul>        </div>        <p class="p-articles__text">            <a class="p-articles__link" href="path/to/news" target="_self">ニュースタイトル</a>        </p>    </div></div>これを元にスクレイピングコードを書きます。package mainimport (    "fmt"    "github.com/go-rod/rod")func main() {    browser := rod.New().MustConnect()    defer browser.MustClose()    page := browser.MustPage("https://3-shake.com/")    // ニュース情報をスクレイピング    newsList := page.MustElement(".p-articles.js-news__target.l-col.l-col--list.js-inview-box")    newsItems := newsList.MustElements(".p-articles__item")    for _, item := range newsItems {        title := item.MustElement(".p-articles__text").MustText()        date := item.MustElement(".p-articles__date").MustText()        fmt.Printf("タイトル: %s\n", title)        fmt.Printf("日付: %s\n", date)        fmt.Println("---")    }}ニュースが .p-articles.js-news__target.l-col.l-col--list.js-inview-box の中にあるので、まずはその要素を MustElement() で取得します。そこから .p-articles__item を全て取り出し、タイトルと日付を抽出しています。これで目的の情報が取得できました。実際に出力してみると次のようになります。実際にテキストも転記しておく、、、。タイトル: 自動脆弱性診断ツール「Securify」、AI技術を駆使する「ai6」が導入日付: 2024.04.05---タイトル: 『ferret』に寄稿記事が掲載されました。日付: 2024.03.25---タイトル: 自動脆弱性診断ツール「Securify」、大手通信販売会社「フェリシモ」が導入日付: 2024.03.22---タイトル: Relance　フリーランス協会の「認定マッチング事業者」として今年も正式採択日付: 2024.04.03---各サービスの名前と説明文、ニュースのタイトルと日付がきちんと取得できていますね。ヘッドレスモードでのスクレイピングgo-rod/rodの大きな特徴の1つに、ヘッドレスモードでのブラウザ操作があります。ヘッドレスモードとは、GUIを持たない状態でブラウザを起動し、バックグラウンドで動作させる機能です。通常、ブラウザを自動操作する際にはブラウザウィンドウが立ち上がりますが、ヘッドレスモードならそれがありません。その分リソースを節約でき、サーバー上での実行に向いています。CIパイプライン内でのテストなどにも利用できます。負荷試験などにも使えるかもしれないので調査中です。    // github.com/go-rod/rod/lib/launcher を利用する    // ヘッドレスブラウザを起動する    url := launcher.New().MustLaunch()    browser := rod.New().ControlURL(url).MustConnect("https://3-shake.com/")    // スクレイピング対象のページを指定する    page := browser.MustPage()おわりに今回はGoのスクレイピングライブラリ go-rod/rod の特徴を確認しながら、Webサイト https://3-shake.com/ から情報を抽出する方法を紹介しました。go-rod/rod の優れた点は、ChromeのDevToolsプロトコルを利用してブラウザを直接操作できることです。これによりサーバーサイドだけでなく、クライアントサイドで動的に生成されるコンテンツに対しても柔軟にスクレイピングを行えます。Goのシンプルな文法とあいまって、簡潔かつパワフルなスクレイピングスクリプトが書けるのが魅力ですね。ぜひ皆さんも go-rod/rod を使って色々なWebサイトに挑戦してみてください。スクレイピングが必要とされるシーンは今後ますます増えていくでしょう。Goと go-rod/rod を使いこなせば、そんな要望にも難なく応えられるはずです。快適で効率的なスクレイピングライフを送っていきたいと思います参考資料github.com/go-rod/rodgo-rod]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIアプリケーション開発入門ハンズオン]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/04/05/122853</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/04/05/122853</guid>
            <pubDate>Fri, 05 Apr 2024 03:28:53 GMT</pubDate>
            <content:encoded><![CDATA[genai-users.connpass.comこの記事は、日本生成AIユーザ会 #1 生成AIアプリケーション開発入門ハンズオンの資料です。↓アーカイブ動画はこちらyoutu.be自己紹介小渕 周（こぶち しゅう）2023年12月株式会社スリーシェイクに入社Sreake事業部 エンジニア生成AIアプリケーション開発に従事sreake.com発表内容Python + LangChain + OpenAIで簡単なサンプルコードを実行しながら生成AIアプリケーション開発についてご説明していきます。プロンプトエンジニアリングについても学べる内容となっています。最後に少しRAGアプリも紹介します。使用するソースコードhttps://github.com/shu-kob/langchain-sample-appPythonを使う理由LangChainライブラリがJavaScript(TypeScript)版より情報が多いOpenAIを使う理由情報が多いからPython + LangChain + OpenAIの組み合わせの情報が最も多いPython設定python3 --versionPython 3.11.4Python 3.11系を使ってください。Python 3.12系だと、ライブラリの関係で、最後の「chainlit_chat_db.py」が実行できないかもしれません。OpenAI API設定https://platform.openai.com/API KeysでSECRET KEYを取得無料枠APIはアカウント開設してから3ヶ月間、$5.00 分利用可能それ以降は課金する必要あり別でアカウント作っても、SMS認証に使う電話番号が同じであれば無料枠はもらえない模様$5.00から課金可能ChatGPTの有料プランとは異なるので注意以下のエラーが出たら課金する必要ありopenai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}課金して数分すればエラーが出ず正常実行できるようにAPI Keyを環境変数に設定export OPENAI_API_KEY=sk-***********************************他のLLMGeminiGoogle CloudのVertex AIで利用可能Claude 3上位 ← Opus、Sonnet、Haiku → 下位AWSのAmazon BedrockでOpus（最上位モデル）利用可能Google CloudではSonnet（中位モデル）利用可能OpusはComing SoonOpenAI APIを使ったプログラミング無料枠でも利用可能なgpt-3.5-turboを使用python3 -m pip install openai==1.16.1openai_chat_completions.pyimport osfrom openai import OpenAIclient = OpenAI(  # This is the default and can be omitted  api_key=os.environ.get("OPENAI_API_KEY"),)chat_completion = client.chat.completions.create(  model="gpt-3.5-turbo",  messages=[    {"role": "system", "content": "私は優秀なソフトウェアエンジニアです。"},    {"role": "user", "content": "kubernetesについて説明してください。"}  ])print(chat_completion.choices[0].message.content)実行python3 openai_chat_completions.pyKubernetes（クーバーネティス）は、コンテナ化されたアプリケーションを管理するためのオープンソースのコンテナオーケストレーションツールです。Kubernetesは、複数のコンテナを効率的かつ柔軟に管理することができ、アプリケーションのデプロイメント、スケーリング、バージョン管理、ネットワーキングなどを自動化します。Kubernetesは、クラウド上やオンプレミスの環境など、さまざまな環境で使用でき、高い信頼性、拡張性、セキュリティを提供します。また、リソースの効率的な管理や障害時の自己修復機能も持っています。Kubernetesは、コンテナ化されたアプリケーションの展開や管理を容易にするための多くの機能やリソースを提供しており、クラウドネイティブなアプリケーションの開発や運用において非常に重要な役割を果たしていますLangChainLLMの差分を吸収するライブラリPython版がメインで開発は先行情報が多い追従して、JavaScript(TypeScript)版が出るWebフロントエンドと開発言語を合わせられるLangChain以外のLLMライブラリはLlamaなどこちらもPython版とJavaScript版python3 -m pip install langchain==0.1.14python3 -m pip install langchain-openai==0.1.1langchain_chat.pyfrom langchain_openai import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagechat = ChatOpenAI(  model="gpt-3.5-turbo",)result = chat.invoke(  [    SystemMessage(content="私は優秀なソフトウェアエンジニアです。"),    HumanMessage(content="LangChainについて説明してください。"),  ])print(result.content)実行python3 langchain_chat.pyLangChainは、ブロックチェーン技術を活用して言語学習者とネイティブスピーカーをつなぐプラットフォームです。言語学習者は、LangChainを通じてネイティブスピーカーとリアルタイムでコミュニケーションを取りながら、言語スキルを向上させることができます。ネイティブスピーカーは、言語学習者に言語を教えることで収入を得ることができます。ブロックチェーン技術によって、安全かつ透明な支払いシステムが提供され、利用者同士の信頼関係を築くことができます。LangChainは、言語学習をより効果的かつ楽しくする革新的なプラットフォームとして注目されています。ハルシネーションが発生実行前にブロックチェーンの質問はしていないし、会話履歴は取得・使用していないGPT-4でもハルシネーションLangChainは、AIを活用した言語翻訳プラットフォームです。ブロックチェーン技術を導入することで、翻訳者は自分の作業を通じて報酬を得ることができます。また、LangChainは独自のトークン経済を持っており、翻訳作業の報酬やサービスの利用料金にそのトークンが使用されます。LangChainの特徴は、AI技術を活用して高精度な自動翻訳を可能にしている点です。また、ブロックチェーンを活用して翻訳者とクライアント間の取引を透明化し、安全性と信頼性を確保しています。さらに、LangChainはコミュニティ主導型のプラットフォームであり、ユーザーがサービスの改善や発展に直接貢献できることも大きな特徴です。ただし、上記内容はLangChainについて一般的に説明したものであり、特定のLangChainとは異なる場合があります。具体的な情報は各LangChainの公式情報をご確認ください。ChainlitPythonで稼動するLLMフレームワークすぐにリッチなUIを使えるカスタマイズは限定される自由にUI開発するならStreamitを使えば良いpython3 -m pip install chainlit==1.0.500https://docs.chainlit.io/integrations/langchain を少し修正chainlit_app.pyfrom langchain_openai import ChatOpenAIfrom langchain.prompts import ChatPromptTemplatefrom langchain.schema import StrOutputParserfrom langchain.schema.runnable import Runnablefrom langchain.schema.runnable.config import RunnableConfigimport chainlit as cl@cl.on_chat_startasync def on_chat_start():    model = ChatOpenAI(model="gpt-3.5-turbo", streaming=True)    prompt = ChatPromptTemplate.from_messages(        [            (                "system",                "あなたはとても優秀なソフトウェアエンジニアです。",            ),            ("human", "{question}"),        ]    )    runnable = prompt | model | StrOutputParser()    cl.user_session.set("runnable", runnable)    await cl.Message(content="こんにちは。私はAIです。質問をしてください。").send()@cl.on_messageasync def on_message(message: cl.Message):    runnable = cl.user_session.get("runnable")  # type: Runnable    msg = cl.Message(content="")    async for chunk in runnable.astream(        {"question": message.content},        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),    ):        await msg.stream_token(chunk)    await msg.send()起動方法chainlit run chainlit_app.py -w-w をつけると、ソースの更新が即時反映以下をChainlitのUIから実行プロンプトエンジニアリングプロンプトの工夫システム開発しなくても、LLMデフォルトのUI上でプロンプトを工夫して欲しい結果を得られるChatGPTのUIでもプロンプトを登録可能左下のプロフィール > ChatGPTをカスタマイズする役割を与えるあなたは〇〇の専門家です。あなたはIT営業です。生成AIを企業のお客様にわかりやすく解説してください。生成AIとは、人工知能の一種で、データから新しい情報やコンテンツを生成することができる技術です。例えば、文章や画像、音声など、さまざまな形式のデータを入力として与えると、生成AIはそのデータを分析し、それらに似た新しいデータを作成することができます。企業が生成AIを活用することで、以下のようなメリットが得られます：1. 新しい商品やサービスの開発：生成AIを使って市場のトレンドや消費者のニーズを分析し、新しい商品やサービスのアイデアを生み出すことができます。2. マーケティング戦略の強化：生成AIを使って効果的な広告コピーを作成したり、ターゲットとなる顧客に最適なコンテンツを提供することができます。3. プロセスの効率化：生成AIを活用して、自動で文章を生成したり、画像を加工したりすることで、業務プロセスを効率化し、作業効率を向上させることができます。生成AIは、ビジネスのさまざまな分野で活用されており、企業の競争力を強化するための強力なツールとなっています。文字数指定〇〇について200文字以内で教えてください。AWSについて200文字以内で教えてください。AWS（Amazon Web Services）は、Amazonが提供するクラウドコンピューティングサービスのことです。AWSを利用することで、サーバー、ストレージ、データベースなどのインフラストラクチャをクラウド上で提供し、スケーラビリティや柔軟性を実現します。多くのサービスが用意されており、企業や個人が必要なサービスを選択して利用することができます。AWSは世界中で広く利用されており、安定性やセキュリティ面でも信頼性が高いです。箇条書き〇〇について箇条書きしてください。良いプレゼンに必要なことを箇条書きで答えてください。・ 明確な目的を持つ・ 聴衆に合わせた内容とレベルを選定する・ わかりやすい構成と論理展開・ 魅力的なビジュアル要素の使用・ 適切な言葉遣いとトーン・ 質疑応答に備えた準備・ タイムマネジメントを考慮したスピーチ時間の管理・ 自信を持ってプレゼンする簡単な回答を得る〇〇について小学5年生にもわかるような文章で教えてください。公定歩合について小学5年生にもわかるような文章で教えてください。公定歩合とは、日本銀行が決める金利のことです。これは、お金を借りたり貸したりするときに使われる金利の基準です。公定歩合が高いと、お金を借りるのがちょっと高くなってしまいます。逆に、公定歩合が低いと、お金を借りるのが安くなります。公定歩合は、経済や物価などに関係していて、政府や日本銀行が調整しています。手順を書かせる賞味期限の近い食材を含め、今あるもので料理を作る、という想定冷蔵庫に、キャベツ、豚肉、豆腐、味噌があります。これらの食材で作れる料理を教えてください。また、調理の手順を箇条書きで書いてください。キャベツと豚肉の味噌炒めを作ることができます。以下に調理手順を箇条書きで示します。材料:- キャベツ- 豚肉- 味噌- 豆腐（オプション）調理手順:1. キャベツを千切りにします。2. 豚肉を食べやすい大きさに切ります。3. フライパンに少量の油を熱し、豚肉を炒めます。4. 豚肉に火が通ったら、キャベツを加えてさらに炒めます。5. キャベツがしんなりとしたら、味噌を加えて全体を混ぜます。6. ソースが全体になじんだら完成です。7. 豆腐を加えてさらに煮込むと、豆腐も味を含んで美味しくなります。是非お試しください！ハッシュタグで条件を指定メール作成や翻訳など、テンプレート化しておくと便利# 役割:あなたはITコンサルタントです。# 目的:生成AIを用いたシステム開発を見込み客に提案# 条件:・開発期間は2ヶ月・予算は1,000万円・見込み客は生成AIシステム開発は初めて＃ 指示:以上の条件をもとに事業企画書をA4用紙1枚分で出してください。事業企画書プロジェクト概要プロジェクト名: 生成AIを活用したシステム開発プロジェクト目的: 見込み客の業務効率向上と競争力強化開発期間: 2ヶ月予算: 1,000万円背景見込み客は生成AIシステム開発に初めて取り組む生成AIの活用により業務プロセスの自動化や品質向上が期待される提案内容要件定義および設計フェーズ要件ヒアリングとシステム設計の作成開発方針の決定と進行管理計画の策定開発フェーズ生成AIモデルの構築と学習システムの開発とテスト導入および運用フェーズシステムの導入支援とトレーニング運用保守体制の構築とサポート体制の整備期待効果業務効率の向上と品質の向上競争力の強化と市場シェアの拡大結言生成AIを活用したシステム開発は見込み客にとって未知の領域かもしれませんが、弊社の豊富な経験と専門知識により、成功への道筋を示すことができます。ご検討いただければ幸いです。プロンプトエンジニアリングガイドPrompt Engineering Guide – Nextra基本的知識から様々な応用手法まで紹介LangChainで実装できる手法も存在RAG speakerdeck.comライブラリをインストールpython3 -m pip install pymupdf-1.24.1python3 -m pip install spacy==3.7.4python3 -m spacy download ja_core_news_smpython3 -m pip install tiktoken==0.6.0python3 -m pip install chromadb==0.4.24python3 -m pip install langchain-community==0.0.31prepare_db.pyPDFの内容をベクトル化してChroma DBに格納from langchain.document_loaders import PyMuPDFLoaderfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import SpacyTextSplitterfrom langchain.vectorstores import Chromaloader = PyMuPDFLoader("./sample.pdf")documents = loader.load()text_splitter = SpacyTextSplitter(  chunk_size=300,  pipeline="ja_core_news_sm")splitted_documents = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings(  model="text-embedding-ada-002")database = Chroma(  persist_directory="./.data",  embedding_function=embeddings)database.add_documents(  splitted_documents,)print("データベースの作成が完了しました。")PDFをベクトル化してDBに格納python3 prepare_db.pyDBに格納したPDFの内容について質問可能なChainlitアプリimport chainlit as clfrom langchain_openai import ChatOpenAI, OpenAIEmbeddingsfrom langchain.prompts import PromptTemplatefrom langchain.schema import HumanMessagefrom langchain_community.vectorstores import Chromaembeddings = OpenAIEmbeddings(  model="text-embedding-ada-002")chat = ChatOpenAI(model="gpt-3.5-turbo")prompt = PromptTemplate(template="""文章を元に質問に答えてください。文章:{document}質問: {query}""", input_variables=["document", "query"])database = Chroma(  persist_directory="./.data",  embedding_function=embeddings)@cl.on_chat_startasync def on_caht_start():  await cl.Message(content="準備ができました！メッセージを入力してください！").send()@cl.on_messageasync def on_message(input_message: cl.Message):  print("入力されたメッセージ: " + input_message.content)  documents = database.similarity_search(input_message.content)  documents_string = ""  for document in documents:    documents_string += f"""  -------------------------  {document.page_content}  """  result = chat([    HumanMessage(content=prompt.format(document=documents_string, query=input_message.content))  ])  await cl.Message(content=result.content).send()Chainlitアプリを実行し、PDFの内容について質問可能chainlit run chainlit_chat_db.py -w PDFはオライリージャパン「詳解Terraform」を格納してある。www.oreilly.co.jpTerraformで再利用可能なモジュールを作成するためのコツを教えてください。再利用可能なTerraformモジュールを作成するためのコツは、以下の点に注意することです。小さなモジュールを作成する: 1つのモジュールに複数の機能やリソースを詰め込まず、1つの機能やリソースに焦点を当てた小さなモジュールを作成することで、再利用性が高くなります。組み合わせ可能なモジュールを作成する: モジュール同士が疎結合であり、組み合わせて利用することが容易な設計を心がけることで、柔軟性が向上します。テスト可能なモジュールを作成する: モジュールごとに適切なテストを実施し、品質を担保することが重要です。テストが容易に実施できるようなモジュールを作成することがポイントです。バージョン管理されたモジュールを使用する: モジュールのバージョン管理を行い、変更やアップデートが容易に行えるようにすることが大切です。これらのポイントに留意しながら、Terraformモジュールを設計・作成することで、効果的な再利用可能性を実現できます。オライリー本をEbookで購入して、PDFをRAGに入れていけば便利そう詳解Terraformのベクトル化でEmbeddingモデルにかかった料金は$0.06参考文献LangChain完全入門　生成AIアプリケーション開発がはかどる大規模言語モデルの操り方作者:田村 悠インプレスAmazonChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社Amazon10倍速で成果が出る！ChatGPTスゴ技大全作者:武井 一巳翔泳社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md</link>
            <guid>https://nnaka2992.hatenablog.com/entry/zatu/20240323_pgunconf.md</guid>
            <pubDate>Sun, 31 Mar 2024 14:30:29 GMT</pubDate>
            <content:encoded><![CDATA[PGUnconf #46 でPostgreSQL の開発するときにまず何からすればいいかを聞いてきた概要2024年3月23日に第46回 PostgreSQLアンカンファレンス@東京が開催されました。PostgreSQLアンカンファレンスは日本PostgreSQLユーザー会が主催するイベントでPostgreSQLユーザーはもちろん、PostgreSQLのコントリンビューターやコミッターも参加しているイベントです。その中でPostgreSQL メジャーコントリビューターであり、コミッターでもある@masahiko_sawadaさんが、PGConn 2024でMAKING POSTGRESQL HACKING MORE INCLUSIVEというセッションでPostgreSQLコミュニティーがどうすればより初心者にオープンになれるか？ という内容でディスカッションするそうです。そこに向けてアイデアはあるか？ 困ってることはないか？ という相談？ をされていました。経験豊富な方々は実践的な案を出していましたが、私はPostgreSQLにコードコントリビュートしたいけど何からすればいいのか分らないという状態だったのでこの機会に相談してみました。自分のレベル感Cはすこし読める。すこし書けるPostgreSQLのソースコードはsimple_query_execの関数をひととおり読んで、なんとなくどこで何しているか分かるPostgreSQLのメーリングリストはとりあえず入った何が分からなかったのか？そもそもPostgreSQLはメーリングリストとパッチの文化なのでGitHub/Labなどになれた身からするとよく分からないです。またGitHubで管理されているOSSでは良くあるgood first issueのようなものも存在しないため、新規参入者には難しいと感じていました。なにからすればいいのか？PGUnconfでは以下のようなアドバイスを受けました。チュートリアルをなぞってドキュメント通りに動かないものを修正する初心者向けコンテンツへの追記は初心者にしか出来ないので、是非おねがいしたいとのことでした既存のパッチで放置されているもの(Headでビルドできないようなもの)をアップデートするメーリングリストのディスカッションを眺めてネタを探す新規機能を試してバグをさがし、修正するCommitFestに参加するまとめ1のネタを探してみつつ、PostgreSQL17のリリースが近いので4に取りくんでみようと思います。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[新しくなった Workload Identity Federation for GKE を試してみる]]></title>
            <link>https://zenn.dev/yokoo_an209/articles/new-workload-identity-federation-for-gke</link>
            <guid>https://zenn.dev/yokoo_an209/articles/new-workload-identity-federation-for-gke</guid>
            <pubDate>Sun, 31 Mar 2024 12:32:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめにGKE の Workload Identity 連携（Workload Identity Federation for GKE）がアップデートされたということで、早速試してみました。https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity#configure-workloads なにが変わったのかこれまで、GKE で Workload Identity 連携を使う場合、Google Cloud の Service Account（以降：GSA） を Kubernetes の ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform / GKE で実現する ExternalSecretOperator テンプレート]]></title>
            <link>https://zenn.dev/yokoo_an209/articles/external-secret-operator</link>
            <guid>https://zenn.dev/yokoo_an209/articles/external-secret-operator</guid>
            <pubDate>Sun, 31 Mar 2024 06:11:06 GMT</pubDate>
            <content:encoded><![CDATA[はじめにGKEのSecretの管理に External Secret Operator を利用することがありました。備忘も兼ねて、周辺知識も補足しながら、今後の使い回しのできるようにTerraform / GKEでのExternal Secret Operatorのテンプレートを作成しました。【前提】Cluster : GKE Autopilot 1.27GKEのWorkload Identityは有効化されているマニフェスト管理helm : helmfileIaC : Terraform今回は、Service Account キーの使用ではなく、W...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQuery の Object テーブルと Gemini-pro-vision リモートモデルを使って pdf を要約してみる]]></title>
            <link>https://zenn.dev/satohjohn/articles/0cc45efca800e3</link>
            <guid>https://zenn.dev/satohjohn/articles/0cc45efca800e3</guid>
            <pubDate>Sat, 30 Mar 2024 17:44:21 GMT</pubDate>
            <content:encoded><![CDATA[概要pdf などの非構造化データを GCS に配置した際に BQ で分析するってどうすんねんというところをやってみる流れとしては以下を実施するpdf などを gcs に配置するBigQuery Connection の作成する必要な権限付与を行うBQ で Object テーブルを作成するBQ でリモートモデルを作成するObject テーブルを使って pdf の要約をする 必要なことBigQuery Connection API の有効化 手順 pdf などを GCS に配置するここは何も考えないで GCS に pdf を配置する例えば、今回...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIアプリケーションにおけるRAGとデータベースの役割]]></title>
            <link>https://speakerdeck.com/shukob/sheng-cheng-aiahurikesiyonniokeruragtotetahesunoyi-ge</link>
            <guid>https://speakerdeck.com/shukob/sheng-cheng-aiahurikesiyonniokeruragtotetahesunoyi-ge</guid>
            <pubDate>Fri, 29 Mar 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://3-shake.connpass.com/event/311868/3-SHAKE SRETTにて、生成AIのデータベースやストレージに関連した部分を発表。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2024-03-29 SRETT9 Cloud SQLの可用性について]]></title>
            <link>https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing</link>
            <guid>https://speakerdeck.com/masasuzu/2024-03-29-srett9-cloudsqlnoke-yong-xing</guid>
            <pubDate>Fri, 29 Mar 2024 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[社内ChatBot (h1-slack-bot)にClaude 3を追加した話(+α)]]></title>
            <link>https://sreake.com/blog/chatgpt-slack-integration-claude-3/</link>
            <guid>https://sreake.com/blog/chatgpt-slack-integration-claude-3/</guid>
            <pubDate>Fri, 29 Mar 2024 02:50:00 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 この記事では、Anthro […]The post 社内ChatBot (h1-slack-bot)にClaude 3を追加した話(+α) first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Platform Engineering on Kubernetes を読んでCloud Native の現在地を理解する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/28/230604</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/28/230604</guid>
            <pubDate>Thu, 28 Mar 2024 14:06:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに近年、Kubernetesの採用が進む中、複数のチームが関わり、複数のクラウドプロバイダーへのデプロイを行い、異なるスタックを扱う組織では、その導入の複雑さが新たな問題となっています。本書 『Platform Engineering on Kubernetes』は、Kubernetes に登場しつつあるベストプラクティスとオープンソースツールを活用し、これらのクラウドネイティブの問題を技術的に組織的にどのように解決するかを示してくれます。learning.oreilly.com本書では、Kubernetes上に優れたプラットフォームを構築するための要素を明確に定義し、組織の要件に合わせて必要なツールを体系的に紹介しており、実際の例とコードを交えながら各ステップをわかりやすく説明することで、最終的にはクラウドネイティブなソフトウェアを効率的に提供するための完全なプラットフォームを作成できるようになるとともに、プラットフォームチームと開発チームの緊密な連携の重要性が強調され、両者の垣根を越えてアプリケーションとインフラストラクチャが一体となったソフトウェア開発を実現することこそが、クラウドネイティブ時代のDevOpsの理想形だと感じました。ぜひ、本稿をお読みいただき、クラウドネイティブ時代のプラットフォームエンジニアリングに必要な知識とスキルと自社に最適なプラットフォームを設計・構築できるようになる必要性を感じたのであれば『Platform Engineering on Kubernetes 』をぜひ、読んでいただきたいです。Platform Engineering on Kubernetes作者:Salatino, MauricioManningAmazon『Platform Engineering on Kubernetes』 の構成本書は全9章で構成されており、カンファレンスのアプリケーションを構築するための "walking skeleton" (PoC、概念実証、デモアプリケーション)を用いて解説が進められる。第1章では、プラットフォームとは何か、なぜそれが必要なのか、そしてクラウドプロバイダーが提供するものとどう違うのかを紹介する。第2章では、Kubernetes 上で動作するクラウドネイティブで分散されたアプリケーションを構築する際の課題を評価する。第3章では、異なるクラウドプロバイダー上でアプリケーションを実行するためのリソースの構築、パッケージ化、デリバリーに必要な追加手順に焦点を当てる。第4章では、パイプラインの概念を中心に、GitOps アプローチを用いて複数の環境の構成を宣言的なアプローチで管理する方法を説明する。第5章では、Crossplane を使用してクラウドプロバイダー間でアプリケーションのインフラストラクチャコンポーネントをプロビジョニングする Kubernetes ネイティブなアプローチについて説明する。第6章では、開発環境の作成に特化した、Kubernetes 上にプラットフォームを構築することを提案する。第7章では、プラットフォームチームが利用可能なリソースにどのように接続するかを決定できるアプリケーションレベルの API で開発チームを支援することに焦点を当てる。第8章では、新しいリリースを本格的にコミットする前に実験するために使用できるリリース戦略を示す。第9章では、プラットフォームの構築に使用するツールからデータを取り込み、プラットフォームエンジニアリングチームがプラットフォームの取り組みを評価するための重要な指標を計算する2つのアプローチを評価する。本書の最後には、Kubernetes 上でプラットフォームがどのように構築されるのか、プラットフォームエンジニアリングチームの優先事項は何か、そして成功するためにクラウドネイティブスペースの学習と最新情報の把握がいかに重要であるかについて、明確なイメージと実践的な経験が得られるようになっています。知識を身体化するハンズオン本書のリポジトリは公開されており、読者は書籍の内容に沿ってハンズオンを実施することができます。これは非常に重要な点です。なぜなら、実際に手を動かして体験することで、書籍で得た知識を体験として自分のものにできるからです。技術書を多読するタイプなのですが別に一度で理解できるタイプの人間ではないので読んでみて良いと思った書籍のみ手を動かして理解するようにしています。github.comKubernetesは、複雑で広範囲に及ぶ分野です。書籍を読んで理解したつもりでも、実際に試してみると躓くことが多々あります。その都度、問題を解決していくことで、より深い理解を得ることができるのです。ですから、読者の皆さんには、ぜひ書籍と一緒にハンズオンに取り組んでいただきたいと思います。文章を読んだだけで分かった気にならないでください。実際に手を動かし、試行錯誤することが、本当の意味での学習には欠かせません。CloudNative Days Tokyo 2023 実行委員会が公開している『一日で学ぶクラウドネイティブ技術実践ハンズオン』は、クラウドネイティブ技術の基礎から実践的な内容まで、1日で集中的に学べる充実した内容となっています。クラウドネイティブの概念やコンテナ技術、Kubernetes、マイクロサービスアーキテクチャなどの主要なトピックがカバーされており、実際にハンズオン形式で技術を体験できるのが特徴です。クラウドネイティブ技術の入門としてお勧めの教材となっています。github.comまた、所属組織でも独自のクラウドネイティブ技術に関する研修を提供しております。弊社の研修では、実際の業務で活用できる実践的なスキルの習得に重点を置いています。カリキュラムの概要については公開しておりますので、ご興味のある方はぜひご覧ください。クラウドネイティブ技術の習得を目指す方に向けて、効果的な学習の機会を提供できればと考えております。sreake.com1 (The rise of) platforms on top of Kubernetesクラウドネイティブ時代の本格的な幕開けとともに、Kubernetesは急速に普及し、コンテナ化されたアプリケーションを運用するための事実上の標準となりました。本章では、まずプラットフォームの定義とその必要性が丁寧に説明されています。プラットフォームとは、企業が顧客向けのソフトウェアを開発・運用するために必要な一連のサービスを提供するものであり、開発チームが効率的に価値を届けるためのワンストップショップの役割を果たします。また、プラットフォームは静的なものではなく、組織の成熟度に合わせて進化していくべきものというような主張がされている点が印象的でした。チームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonクラウドプロバイダーが提供するサービスは、レイヤー別に分類され、それぞれの特徴が解説されています。Figure 1.1 Cloud provider's services categories より引用特に、アプリケーション固有のニーズを満たすためには、これらのサービスを組み合わせ、独自のレイヤーを構築する必要があると強調されています。この点については、『CloudNativeな時代に求められるWebサービス基盤モデルの再考』というタイトルで登壇した際にもまとめています。また、クラウドプロバイダーが提供するプラットフォームの特徴として、API、SDK、CLI、ダッシュボードなどが挙げられています。これらのツールを効果的に組み合わせることで、開発チームはアプリケーションをスムーズに構築・デプロイできます。一方で、プロバイダー固有のツールやワークフローを学習するコストも無視できないと指摘されています。Google Cloud Platform (GCP) を例に、クラウドプロバイダーが提供するダッシュボード、CLI、API の実際の使用例が紹介されています。これらのツールは、リソースのプロビジョニングを大幅に簡素化してくれますが、一方でプロバイダー固有の知識が必要とされる点にも触れられています。cloud.google.comクラウドプロバイダーのプラットフォームが広く受け入れられている理由として、API主導の設計、充実したツールの提供、そして従量課金モデルが挙げられています。特に、開発チームが必要なリソースをオンデマンドで利用できる点は、ビジネスのアジリティを高める上で大きなメリットだと言えます。次に、Kubernetes 上にプラットフォームを構築することの意義と、そのためのエコシステムについて解説されています。Kubernetes は、クラウドネイティブなアプリケーションを開発・運用するための基盤として広く採用されていますが、それ自体はプラットフォームではなく、プラットフォームを構築するための構成要素を提供するものだと位置づけられています。Kubernetes を導入する際には、単にツールを選定するだけでなく、組織の文化や成熟度に合わせて、段階的にプラットフォームを構築していくことが重要だと説かれています。Figure 1.11 Platform journey on Kubernetes より引用また、プラットフォームチームは、開発チームを内部の顧客と捉え、彼らのワークフローに合わせてプラットフォームを設計すべきだと強調されています。Cloud Native Computing Foundation (CNCF) は、クラウドネイティブなエコシステムを推進する団体であり、Kubernetes を含む多くのオープンソースプロジェクトをホストしています。https://landscape.cncf.io/ より引用landscape.cncf.ioこれらのプロジェクトを適切に組み合わせることで、ベンダーロックインを回避しつつ、柔軟なプラットフォームを構築できると説明されています。プラットフォームエンジニアリングの役割と、その重要性についても述べられています。プラットフォームチームは、社内の開発チームを顧客と捉え、彼らが効率的にソフトウェアを開発・デリバリーできるように、プラットフォームというプロダクトを提供します。Figure 1.14 Platform teams take the work done by developers safely to production. より引用国内でもPlatform Engineering MeetupやPlatform Engineering Kaigi 2024が開催され、とても注目される分野となっています。Platform Engineeringは、開発チームが効率的にアプリケーションを開発、デプロイ、運用できるようにするための基盤を提供することを目的としています。この分野では、Kubernetesがプラットフォームの中核として広く採用されています。自分が最初にKubernetesをプラットフォームとして認識したのは、プラットフォームの上でものを作るということを読んでからです。この記事では、Kubernetesがプラットフォームとしてどのような役割を果たすのかが詳しく解説されており、開発者がアプリケーションに集中できる環境を提供することの重要性が強調されています。また、Kubernetesを始めたばかりで、Platform Engineeringの概念についてよく分からないという人は、k8sを始める人に知ってもらいたい、Platform Engineeringの話を読むことをおすすめします。このスライド資料では、Platform Engineeringの基本的な考え方や、Kubernetesを活用したプラットフォーム構築の手法が分かりやすく解説されています。platformengineering.connpass.comまた、プラットフォームは単なるツールの寄せ集めではなく、開発チームのワークフローに合わせて設計され、シームレスな開発体験を提供することが求められます。市販のプラットフォームを導入するだけでは、組織特有のニーズを満たすことは難しいと指摘されています。Red Hat OpenShift や VMware Tanzu などの製品は、一定の抽象化を提供してくれますが、それでも組織に合わせたカスタマイズが必要になるケースが多いようです。Figure 1.15 Building platforms on top of Kubernetes distributions より引用結局のところ、自社に最適なプラットフォームを構築するためには、社内でプラットフォームエンジニアリングに取り組む必要があるということですね。本書の中にも組織の話がたくさん出てくるし、本稿でも少し組織のような話に逸れます。『DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス』は、クラウドサービスを効果的に活用し、DXを成功させるために不可欠な、自社のユースケースに適したサービスの選択・統合と社内でのクラウドエキスパートの育成について、特にリーダーシップ、ビジネス、テクノロジーを備えたクラウド活用推進組織「CCoE」の存在の重要性を強調しています。本書では、CCoEの基本概念から立ち上げ方法、課題解決方法まで、先進企業の実例を交えてわかりやすく説明しています。クラウドネイティブ時代に適応し、DXを成功させるためには、プラットフォームの構築と進化、クラウドサービスの効果的な活用、そしてCCoEの組織化が重要であり、これらの取り組みを通じて、企業は顧客により高い価値を提供し、競争力を高めていくことができるでしょう。これらの課題解決の手引きとなる一冊であり、合わせて読むのがオススメの書籍です。DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティス作者:黒須 義一,酒井 真弓,遠山 陽介,伊藤 利樹,饒村 吉晴日経BPAmazon本書で使用されるカンファレンスのアプリケーションの例も紹介されています。この「ウォーキングスケルトン」と呼ばれるサンプルアプリケーションは、クラウドネイティブなアーキテクチャのベストプラクティスを示すと同時に、以降の章で紹介されるプラットフォーム構築の手法を実践的に学ぶためのユースケースとして機能します。このカンファレンス用のアプリケーションは、マイクロサービスアーキテクチャに基づいて設計された Web アプリケーションであり、複数のバックエンドサービスと、それらを呼び出すフロントエンドで構成されています。Figure 1.18 Conference application services. The end user interacts with the frontend that routes requests to all the backend services. より引用各サービスは独立して開発・デプロイできるため、チーム間の自律性を高めつつ、アプリケーション全体の柔軟性と回復性を向上させることができます。モノリシックなアーキテクチャと、マイクロサービスアーキテクチャの違いについても説明されています。モノリシックなアプリケーションでは、すべての機能が1つのコードベースに含まれているため、スケーリングや更新に制約が生じやすくなります。Figure 1.20 In a monolith application, all the logic to implement different use cases are bundled together. This push different teams to work on the same codebase and requires them to have complex coordination practices to avoid conflicting changes. より引用一方、マイクロサービスでは、各サービスが独立して開発・デプロイできるため、より柔軟で回復性の高いアプリケーションを構築できると説明されています。最後に、本書で扱うプラットフォーム構築の手法が、カンファレンスのアプリケーションを例に概説されています。各章では、CI/CD、環境の管理、クラウドリソースのプロビジョニングなど、プラットフォームを構成する様々な要素が取り上げられ、それらを組み合わせることで、開発チームの生産性を高めるプラットフォームを構築していく過程が紹介されます。また、プラットフォームの効果を測定するための指標や手法にも触れられており、継続的な改善の重要性が強調されています。第1章を通じて、プラットフォームを Kubernetes 上に構築することの意義と、そのための手法が体系的に説明されていました。特に、プラットフォームを「内製のプロダクト」と捉え、開発チームを「顧客」と見なすという視点は、DX時代における開発組織のあり方を考える上で示唆に富むものでした。これらのSREとの手法の違いについては以下のような内容で登壇したことがあります。 speakerdeck.com私自身、大規模な Web アプリケーションの開発に携わった経験から、モノリシックなアーキテクチャの限界を痛感しています。機能追加や変更に多大な時間と工数を要していたのが、マイクロサービス化を進めることで、各チームが独立して開発を進められるようになり、リリースサイクルを大幅に短縮できました。クラウドネイティブなアプリケーション開発において、マイクロサービスアーキテクチャが果たす役割の大きさを実感しています。また、CNCF のプロジェクトを活用しつつ、自社に最適なプラットフォームを構築していくアプローチは、クラウドネイティブな開発に取り組む多くの組織にとって参考になるはずです。私自身、日々の業務の中で、クラウドネイティブな開発の推進と、それを支えるプラットフォームの構築に取り組んでいます。本書で得られる知見を活かし、自社に最適なプラットフォームを設計・運用していきたいと考えています。著者の深い知見と経験に基づく解説は、インフラエンジニアのみならず、アプリケーション開発者やアーキテクトなど、様々な立場の読者に価値を提供してくれるでしょう。プラットフォームチームと開発チームの関係性や、CNCF の活動など、日々の業務では触れる機会の少ないトピックについても、明快に解説されていたのが印象的でした。本書の残りの章では、このような考え方を基盤に、より具体的なプラットフォーム構築の手法が展開されていきます。第1章で示された知見は、プラットフォームエンジニアリングに携わる全ての人にとって、大きな助けになるはずです。著者の知見とバランス感覚に裏打ちされた記述は、まさにクラウドネイティブ時代の最前線に立つエンジニアならではのものです。これからのソフトウェア開発には、プラットフォームチームと開発チームの緊密な連携が欠かせません。インフラエンジニア、SREやプラットフォームエンジニアは両者の架け橋となり、組織全体でクラウドネイティブの価値を最大限に引き出せるよう尽力しなければなりません。本書を通じて得られる知見を糧に、クラウドネイティブ時代の開発の最前線に立ち続けられるのではないでしょうか？しかし、技術的にKubernetesを完全に網羅しているわけではないので『Kubernetes完全ガイド 第2版』、『Docker/Kubernetes実践コンテナ開発入門 改訂新版』、『Kubernetes Best Practices, 2nd Edition』、『Kubernetes Patterns, 2nd Edition』などを読むと良いと思います。2 Cloud-native application challenges本章では、クラウドネイティブアプリケーションを開発・運用する上での実践的な課題が幅広く議論されました。議論の出発点となったのは、アプリケーションを実行するためのKubernetesクラスター環境をどのように選択するかという点です。ローカル環境でKindを使う方法は手軽である一方、リソースに制限があり、本番環境とは異なる挙動をする可能性があることが指摘されました。Kindは、Docker上にKubernetesクラスターを起動するツールで、開発者の手元で手軽にKubernetesを体験できる利点がある反面、プロダクション環境とは異なるサイジング・設定になりがちという欠点があります。kind.sigs.k8s.io対して、クラウドプロバイダのマネージドサービスを使えば、本番に近い環境でアプリケーションを開発できますが、コストがかかるほか、開発者がリモート環境での作業に慣れる必要があるといったトレードオフが存在します。GKE(Google Kubernetes Engine)やEKS(Amazon Elastic Kubernetes Service)などのマネージドサービスは、運用の手間を大幅に削減できる一方、クラウドベンダーの仕様に縛られるというデメリットもあります。私も実際にKindを用いたローカル環境とGKEを用いたクラウド環境の両方を経験しましたが、著者の指摘通り、それぞれに一長一短があることを実感しています。例えば、Kindは気軽に使える反面、ノード数が限られるためスケーリングのテストには向きません。一方、GKEは本番環境に近い挙動が期待できますが、クラスターの起動に時間がかかります。開発のフェーズやチームの状況に合わせて適切な環境を選択することが重要だと改めて認識しました。Figure 2.1 Kubernetes cluster Local vs. Remote setups.より引用環境の選択に関する議論に続いて、Helmを使ってカンファレンスアプリケーション(PoC)をKubernetesクラスターにデプロイする方法が具体的に紹介されました。Helmは、Kubernetes上のアプリケーションを管理するためのパッケージマネージャーです。Helmでは、アプリケーションの各コンポーネントを定義した複数のマニフェストファイルを「Chart」という単位でまとめて管理します。Helmを使うと、たった1つのコマンドで、アプリケーションの実行に必要な様々なKubernetesリソース（デプロイメント、サービス、ConfigMapなど）を一括デプロイできるのが大きな魅力です。Helmのようなツールを活用することで、複雑なマニフェストファイルを手書きで管理する手間を大幅に削減できます。また、変数化されたテンプレートを使うことで、環境ごとの設定の差異を吸収するのも容易になります。また、デプロイ後は、kubectlを駆使して、デプロイメント、サービス、Ingressなどのリソースを詳細に調べることで、アプリケーションの動作を深く理解することができます。例えば、kubectl describe deploymentでデプロイメントの詳細情報を確認したり、kubectl logsでPodのログを追跡したりできます。私も日頃からkubectlを多用していますが、改めてその重要性を認識しました。トラブルシューティングにおいては、kubectl describeやkubectl logsが特に有用です。Podが期待通りの状態になっていない場合、kubectl describeでPodの詳細情報を確認することで、原因を特定するための手がかりが得られることが多いです。ログに関しても、kubectl logs -fでストリーミング表示すれば、リアルタイムでアプリケーションの挙動をモニタリングできます。アプリケーションのデプロイと動作の確認を通じて、著者はクラウドネイティブアプリケーション特有の課題についても議論を展開していたので必読だと思います。最も重要な課題の1つが、一時的な障害が発生してもシステム全体を停止させないことです。マイクロサービスアーキテクチャでは、あるサービスで障害が発生しても、他のサービスには影響を与えないようにすることが求められます。そのためには、個々のマイクロサービスを冗長化し、一部のインスタンスが停止しても他のインスタンスが処理を引き継げるような設計が必要不可欠です。Kubernetesでは、この要件を満たすために、マイクロサービスを複数のレプリカ(Pod)で運用することが一般的です。例えば、本章の例では、フロントエンドサービスのレプリカを2つ起動することで、一方が停止しても他方がリクエストを処理し続けられるようにしていました。Deployment(デプロイメント)リソースの「replicas」フィールドで、起動するレプリカの数を指定できます。Figure 2.17 By having two replicas of the Frontend container running, we allow the application to tolerate failures and also to increase the number of concurrent requests that the application can handle. より引用実際、私も過去に、あるマイクロサービスがデプロイに失敗し、全体のシステムが停止してしまった苦い経験があります。その教訓から、現在ではユーザー向けのサービスを複数のレプリカで運用するようにしています。障害の影響を最小限に抑えるには、可用性を維持しつつ、もちろん無限にお金を使えれば解決に近づく問題ではあるのでリソース消費量のバランスを取ることが肝要です。また、レプリカ数を動的に変更できるようHPA(Horizontal Pod Autoscaler)を設定し、負荷に応じて自動的にスケールするような工夫もしています。HPAを使えば、CPUやメモリの使用率に基づいて、Pod数を自動的に増減できます。これにより、トラフィックが増大した際にもサービスのパフォーマンスを維持しつつ、利用が低調な時間帯にはリソースを節約することが可能になります。サービス間の疎結合性を保つことも、システムの可用性を高めるための重要な要素です。あるサービスで障害が発生した際も、ユーザーが他のサービスの機能を継続して利用できるようにすることが理想的です。そのためには、各サービスが依存するサービスの障害を適切に処理し、エラーをユーザーに伝搬させないようにするなど、レジリエンスを持たせる必要があります。Figure 2.21 No pods for the Agenda service. If a service is failing, the user should be able to keep using the application with limited functionality. より引用著者が紹介していたように、サーキットブレーカーパターンを実装したり、適切にタイムアウトを設定したりすることが有効です。サーキットブレーカーとは、障害が発生したサービスへのリクエストを一時的にブロックし、迅速にエラーを返すことでカスケード障害を防ぐ仕組みです。また、各リクエストにタイムアウトを設定しておくことで、ダウンストリームのサービスの応答が遅い場合でもアプリケーション全体が停止するのを防げます。加えて、私からは、Istioのようなサービスメッシュを導入し、サービス間の通信を細かく制御する方法も提案したいです。サービスメッシュは、マイクロサービス間の通信を透過的にインターセプトし、ルーティングやトラフィック管理、セキュリティ、可観測性などの機能を提供するインフラストラクチャ層です。istio.io例えば、Istioを使えば、特定のマイクロサービスへのリクエストに対して、自動的にリトライを行ったり、エラー率が閾値を超えた際にサーキットブレーカーを発動させたりすることができます。さらに、バージョンの異なるサービスに対して、トラフィックを段階的に切り替えるカナリアデプロイメントも容易に実現できます。これらの機能により、マイクロサービスのレジリエンスとリリース管理が大きく改善されるでしょう。istio.ioステートフルなサービスをKubernetes上で運用する際の留意点についても言及がありました。ステートフルというのは、リクエスト間で状態を保持する必要のあるサービスを指します。代表例は、データベースやメッセージキューなどです。ステートフルサービスをコンテナとして運用する場合の課題は、Podが再起動した際にデータが失われないようにすることです。そのためには、データを永続化するためのストレージが不可欠です。Kubernetesには、各Podにボリュームを割り当てる仕組みがあり、ファイルシステムやブロックストレージ、オブジェクトストレージなど、多様なストレージをPodにマウントできます。kubernetes.ioまた、ステートフルサービスでは、Pod間でデータを同期する必要があるため、スケーリングが難しくなります。この問題に対処するため、Kubernetesには、StatefulSetというリソースが用意されています。StatefulSetを使うと、各Podに固有のネットワークアイデンティティを付与し、起動順序や停止順序を制御できます。Figure 2.25 Both data-sensitive services use persistent stores. Delegating state storage to external components, make your service stateless and easier to scale. より引用著者が言及していたように、データベースなどのステートフルなコンポーネントを切り出し、サービス自体はステートレスに保つことが望ましいアプローチだと言えます。例えば、ユーザーのセッション情報をRedisなどのキャッシュサーバーで管理することで、アプリケーションサーバー自体はステートレスになり、シームレスにスケールさせることができるようになります。私のチームでも同様の手法を取り入れており、大きな効果を上げています。分散システムにおいては、データの整合性の問題も避けて通れません。マイクロサービスアーキテクチャでは、データがサービス間で分散されているため、あるサービスから見たデータの状態が、他のサービスから見た状態と異なっている可能性があります。「結果整合性」と呼ばれるこの状態は、ビジネス要件に応じて許容されるケースもあれば、強い整合性が求められるケースもあります。いずれにせよ、データの不整合を検知し、解消するためのメカニズムが必要です。著者が提案していたのは、CronJobを使って定期的にデータの整合性をチェックする方法です。CronJobは、cron構文で記述されたスケジュールに従ってジョブ(Pod)を実行する仕組みです。例えば、毎日深夜に、各サービスのデータを突き合わせ、不整合があればアラートを上げるような運用が考えられます。Figure 2.27 Consistency checks can run as CronJobs. We can execute checks against the application services on fixed intervals to make sure that the state is consistent. For example: (1) every day at midnight we query the Agenda Service (2) to verify that the published sessions are approved in the (3) Call For Proposals Service and a corresponding notification has been sent by the (4) Notifications Service. より引用より洗練された方法としては、CDCを使って変更データをリアルタイムでキャプチャし、関連サービスに伝播させるような方法も考えられます。CDCとは、Change Data Captureの略で、データベースの変更を即座に検出し、他のシステムに通知する技術のことです。CDCを使えば、データの更新を全てのサービスに「できるだけリアルタイム」で反映させることができます。ただし、サービス間の疎結合性という観点からは、同期的な通信は避けたほうが良いかもしれません。非同期メッセージングを使ってイベントドリブンに通信するアプローチのほうが、マイクロサービスの理想に適っているでしょう。アプリケーションの適切な監視も、本章で大きく取り上げられたトピックでした。クラウドネイティブのアプリケーションでは、インフラからアプリケーションまで、あらゆる階層で可観測性(オブザーバビリティ)を確保することが求められます。著者が注目していたのは、OpenTelemetryです。OpenTelemetryは、CNCF(Cloud Native Computing Foundation)が主導するオープンソースプロジェクトで、メトリクス、ログ、トレースを統合的に扱うためのフレームワークを提供しています。OpenTelemetryに準拠したライブラリやエージェントを使えば、アプリケーションのコードに変更を加えることなく、各サービスから統一的なフォーマットで可観測性データを収集できます。opentelemetry.io収集したメトリクスは、Prometheusなどの時系列データベースに保存し、Grafanaなどの可視化ツールで分析・モニタリングするのが一般的です。Figure 2.28 Aggregating observability from all our services in a single place reduces the cognitive load on the teams responsible for keeping the application up and running. より引用著者の主張に大いに同意します。特に、大規模なシステムになるほど、各サービスが出力するログやメトリクスを個別に追跡するのは非常に骨の折れる作業になります。OpenTelemetryのようなフレームワークを活用し、可観測性データを一元的に管理することが必要不可欠だと考えられます。learning.oreilly.com加えて、PrometheusのアラートマネージャーでSLO(Service Level Objective)を定義し、それに基づいてアラートを発報する仕組みを整えることも重要だと感じられます。SLOとは、サービスが満たすべき具体的な指標のことで、可用性やレイテンシーに関する目標値を定量的に表したものです。SLOに対する違反が発生した際に適切にアラートが上がるようにしておくことで、障害の検知と対応を迅速に行えるようになります。本章で取り上げられた課題は、いずれもクラウドネイティブアプリケーションの開発において避けては通れないものばかりです。個々の課題にベストプラクティスで対処することに加えて、著者は課題の根本的な解決のためには"プラットフォームエンジニアリング"の実践が不可欠だと述べています。つまり、開発者がアプリケーションのコア機能の開発に専念できるよう、ビルド、デプロイ、運用などに関わる様々なプラットフォーム機能を自動化し、効率化することが求められるのです。Figure 2.33 Developers can focus on building features, but the platform team needs to automate the entire process after changes are made. より引用プラットフォームチームによる自動化の推進は、開発チームの生産性を大きく向上させることが期待できます。一方で、プラットフォームチームと開発チームのコミュニケーションは欠かせません。開発者のフィードバックを受けて、継続的にプラットフォームを改善していくことが肝要だと言えるでしょう。クラウドネイティブアプリケーションの課題を可視化し、プラットフォームエンジニアリングの必要性を明らかにした本章の議論は示唆に富むものでした。著者の知見を参考にしながら、開発者体験の向上と、より信頼性の高いシステムの構築を目指していくことが重要だと感じました。また、プラットフォーム自動化の取り組みを通じて、チーム全体の生産性を高めていくことも大きな目標になるはずです。次章以降では、より具体的なプラクティスが順次展開されるとのことです。クラウドネイティブの世界の最前線で活躍するエンジニアの知恵を学べる良い機会だと思います。本章で得られた知識を土台として、より実践的なスキルを身につけていくことが望まれます。カンファレンスアプリケーション(PoC)を題材に、プラットフォームの構築からアプリケーションの継続的デリバリーまでを一気通貫で学べるのは、他書にはない本書の大きな魅力だと感じました。本章では実際に手を動かしながら学べる内容が豊富でした。Helmを使ったデプロイ、kubectlを用いたトラブルシューティング、Deploymentの設定など、クラウドネイティブアプリケーションに携わる上で必須のスキルを体験的に学ぶことができたのは非常に有益でした。もちろん、著者も強調していたように、これらはあくまで基礎の一部に過ぎません。実際のプロダクション環境では、もっと複雑で予期せぬ事態が起こりうるでしょう。そうした事態にも柔軟に対応できるよう、本書で得た知見を活かしつつ、継続的にスキルを磨いていくことが肝要だと感じました。著者の豊富な知識と経験に基づいた本書を通じて、DevOpsの文化を組織に根付かせ、高品質なソフトウェアを継続的に提供できるチームを作り上げていくための多くの学びが得られることを期待したいと思います。Engineering Managementの観点からも、示唆に富む章になっています。3 Service pipelines: Building cloud-native applications本章では、クラウドネイティブアプリケーションの継続的デリバリーを実現するための要となるサービスパイプラインについて、非常に深く掘り下げた議論が展開されていました。learning.oreilly.comサービスパイプラインとは、ソースコードから複数の環境にデプロイ可能なリソースを生成するまでのプロセスを定義するものです。trunk-basedな開発や、1サービス=1リポジトリという実践を行うことが、チームがソフトウェアのビルドとリリースを効率的に標準化するのに役立ちます。trunkbaseddevelopment.comしかし、これはあくまで一般論であって、実際にはチームやアプリケーションに合ったやり方を見つける必要があります。万能の解決策などなく、トレードオフを考えなければならない場面も多いでしょう。アプリケーションを構成するサービスがどのくらいの頻度で変更されるのか、それらのサービスをどのように各環境にデプロイしていくのか。こうした問いに答えることで、サービスパイプラインの始点と終点を定義しやすくなります。例えば、UIを担うフロントエンドサービスの変更は、バックエンドのAPIに比べてより頻繁に行われるかもしれません。フロントエンド開発のためのテスト入門 今からでも知っておきたい自動テスト戦略の必須知識作者:吉井 健文翔泳社Amazonそうした場合、フロントエンド側のパイプラインは、できるだけ軽量でシンプルなものにしておく必要があります。頻繁なリリースサイクルに対応するため、ビルドやデプロイのプロセスを自動化し、効率化することが重要です。また、フロントエンドの変更がバックエンドに与える影響を最小限に抑えるため、両者の間にはしっかりとしたインターフェース定義が必要となります。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon一方、ビジネスロジックの中核を担うようなバックエンドサービスのパイプラインは、より厳格で、各種テストも充実させておく必要があるでしょう。バックエンドは、システムの根幹を成すコンポーネントであり、その品質と信頼性は非常に重要です。そのため、単体テスト、統合テスト、負荷テストなど、様々な観点からのテストを実施し、バグや脆弱性を早期に発見・修正することが求められます。また、バックエンドの変更は、他のサービスに広範な影響を与える可能性があるため、慎重にバージョン管理し、必要に応じてロールバック可能な状態を維持しておくことも大切です。このように、フロントエンドとバックエンドでは、その役割や特性に応じて、パイプラインの設計や運用方針を適切に調整することが重要です。こうした違いを意識しつつ、それぞれのサービスに適したパイプラインを設計していく。これは、サービスの独立性を確保しつつ、開発・リリースプロセス全体の効率を高める上で非常に重要なことだと言えます。マイクロサービスアーキテクチャが主流となる中で、サービスの独立性を担保しつつ、リリースプロセス全体の効率化を図る上で、サービスパイプラインは欠かせない存在です。サービスパイプラインを適切に設計し、運用することが、クラウドネイティブな開発の成功の鍵を握ると言っても過言ではありません。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオライリー・ジャパンAmazon著者は、サービスパイプラインを効果的に機能させるためのベストプラクティスをいくつも提示しています。例えば、trunk-based developmentを採用し、メインブランチを常にデプロイ可能な状態に保つことです。これにより、いつでもリリースができる状態を維持しつつ、変更を小さくすることで、リスクを最小限に抑えられます。また、メインブランチへのマージを厳格に管理することも重要です。レビューを徹底し、自動化されたテストをパスしたコードのみを受け入れるルールを設ける。これにより、メインブランチの品質を常に高く保てるはずです。docs.github.com加えて、Consumer-Driven Contract (CDC) テストの重要性も強調されていました。マイクロサービス間の依存関係を、テストとして明示的に管理することで、あるサービスの変更が他のサービスに与える影響を最小限に食い止められるのです。thoughtworks.github.ioCDCテストでは、あるサービス（Consumer）が依存するサービス（Provider）のAPIについて、期待する振る舞いを契約（Contract）として定義します。そしてその契約に基づいて、自動テストを生成するのです。これにより、Providerの実装が変更されても、Contract自体が守られている限り、Consumerには影響が及ばないことが保証されます。この手法は、マイクロサービス間の結合度を適切な形に保つ上で、非常に有効だと言えるでしょう。CDCテストを導入することで、各チームは自分たちのペースでサービスを進化させつつ、他のチームに与える影響を最小限に抑えられます。これは、マイクロサービスアーキテクチャのメリットを最大限に引き出すための重要な実践だと言えます。こうしたプラクティスは、単に技術的なものではありません。チーム間のコミュニケーションを円滑にし、リリースに関わる様々なステークホルダーの協調を促すことにも寄与します。サービスパイプラインを設計する際には、常にチームとプロセスに与える影響を考慮する必要があるでしょう。さらに、個々のサービスのライフサイクルに合わせて、パイプラインを柔軟に調整することの重要性も説かれていました。画一的な基準を全てのサービスに適用するのではなく、変更頻度や重要度に応じて最適化していくことが求められます。例えば、ユーザーに対するインターフェースとなるフロントエンドのサービスは、UIの変更が頻繁に行われるかもしれません。一方で、システムの根幹を支えるようなバックエンドサービスは、安定性が何より重視されるはずです。こうした特性の違いを踏まえて、フロントエンドのサービスにはより軽量で実行頻度の高いパイプラインを、バックエンドのサービスにはより厳格でステップの多いパイプラインを適用する、といった工夫が考えられます。要は、サービスの特性に合わせてパイプラインをチューニングしていくことが肝要だということですね。そのためには、各サービスがどのような特性を持ち、どのようなペースで変更が行われるのかを深く理解する必要があります。開発チームとの密なコミュニケーションを通じて、サービスの性質を見極めていくことが重要だと言えるでしょう。また、パイプラインを定義する際には、コードとしての管理が鍵になります。アプリケーションのコードと同様に、パイプラインのコードもバージョン管理し、再利用性や保守性を高めていく必要があるのです。そのためには、Dockerfileやデプロイメント用のマニフェストなど、パイプラインに関わる全てのリソースをコードとして扱うことが重要になります。つまり、Infrastructure as Codeの思想を、パイプラインにも適用するということですね。learning.oreilly.comこれは、単にパイプラインの品質を高めるだけでなく、アプリケーションの運用方法を明確に可視化することにも繋がります。コードを見れば、そのアプリケーションがどのようにビルド・デプロイされるのかが一目瞭然になるのです。特に、新しくチームに参加したメンバーのオンボーディングを助ける効果は大きいでしょう。パイプラインのコードがドキュメントの役割を果たし、アプリケーションの動作原理の理解を助けてくれるはずです。加えて、コード化されたパイプラインは、単なる自動化の手段ではありません。それは、チームのエンジニアリング文化そのものを表現するものだとも言えます。例えば、パイプラインにどのような品質ゲートを設けるのか、どの段階でレビューを行うのか、といった点は、チームの価値観や理念を反映したものになるはずです。つまり、パイプラインをコード化することは、チームのエンジニアリングプラクティスを明文化し、共有することでもあるのです。それによって、チームのスキルやノウハウの継承がスムーズになり、組織としての開発力の底上げにも繋がります。本章では、Tekton、Dagger、GitHub Actionsなど、パイプラインを実装するためのツールについても詳しく解説されていました。それぞれのツールの特性を理解し、自身のコンテキストに合ったものを選択することが重要だと感じました。learning.oreilly.comGitHubが提供するGitHub Actionsのようなマネージドサービスを利用するのも一つの選択肢です。インフラの管理は全てGitHubに任せられるため、初期コストを大幅に下げられます。ただし、実行時間に応じた従量課金制のため、大規模なワークロードを流し続けるとコストが高くつく可能性もあります。プラットフォームを構築する立場からは、GitHub Actionsのような便利なツールだけに頼るのではなく、自社に最適化されたタスクやパイプラインを柔軟に作れるツールを選ぶ必要があるでしょう。また、開発者がローカルでパイプラインを実行できるようにしておくことも、DXを高める上で重要なポイントになります。せっかくパイプラインを自動化しても、毎回クラウドにデプロイしないと動作確認ができないようでは、開発者の生産性は大きく損なわれてしまいます。開発者のフィードバックサイクルを如何に短くできるかは、パイプラインツールの選定において考慮すべき大切な視点だと言えるでしょう。github.com例えばTektonは、Kubernetesとの親和性が高く、宣言的なパイプラインの定義が可能です。Kubernetesのカスタムリソースとしてパイプラインを表現できるため、他のKubernetesリソースとの連携が容易だというメリットがあります。また、Tektonには豊富なコミュニティ貢献のタスクが用意されているのも魅力の一つです。Tekton Hubと呼ばれるカタログサイトから、再利用可能なタスクを検索し、自分のパイプラインに組み込むことができます。これらのタスクは、Kubernetesのエキスパートたちによって作られ、ベストプラクティスが詰め込まれています。それらを活用することで、信頼性の高いパイプラインを素早く構築できるでしょう。tekton.dev一方、Daggerは、プログラミング言語でパイプラインを記述できるため、より動的で複雑な処理を表現しやすいという特徴があります。Go、Node.js、Python、Javaなど、様々な言語のSDKが提供されているのも、開発者にとって嬉しいポイントだと言えます。言語の持つ柔軟性を活かして、条件分岐や繰り返し処理を含む高度なパイプラインを実装できます。また、言語のエコシステムを活用して、外部ライブラリとの連携も容易です。例えば、テストの実行結果をSlackに通知したり、カスタムスクリプトを組み込んだりといったことが、シームレスに行えるでしょう。dagger.ioまた、Daggerの大きな特長は、ローカル環境でもそのままパイプラインを実行できる点にあります。手元の環境で簡単にパイプラインの動作検証ができるため、開発者の生産性が大きく向上するでしょう。クラウド上の環境を完全に再現するのは難しくても、パイプラインのコアとなるロジックは、ローカルで十分にテストできるはずです。これにより、クラウドへのデプロイ回数を減らし、無駄なコストを削減できます。また、ローカルでパイプラインを実行できれば、開発中のアプリケーションに合わせて、パイプラインを柔軟にカスタマイズしていくことも容易になります。チームのスキルセットや、アプリケーションのアーキテクチャによって、適切なツール選定は変わってくるでしょう。一つの正解があるわけではありません。重要なのは、チームにとって最も生産性の高い方法を追求し続けることだと感じました。さらに、ローカル環境でのパイプラインの実行も、開発者の生産性を大きく左右する要素として挙げられていました。クラウド上の環境を完全に再現するのは難しくとも、手元で気軽にパイプラインを実行できれば、圧倒的にフィードバックループが早くなるはずです。加えて、コードとして表現することで、より柔軟なパイプラインの実現も可能になります。単なるYAMLの設定ファイルでは表現しきれないような、動的なロジックを組み込むこともできるはずです。例えば、あるサービスのテスト結果を受けて、別のサービスのデプロイを条件付きでスキップする、といったことも可能になるでしょう。この柔軟性は、マイクロサービスの独立性を担保する上でも重要な意味を持ちます。あるサービスの障害が、他のサービスのデプロイを止めてしまうようでは、真の意味でのマイクロサービスとは言えません。パイプラインを通じて、各サービスのライフサイクルを適切に制御することが、マイクロサービスアーキテクチャを成功に導く鍵だと言えるでしょう。Figure 3.14 Local vs. remote service pipelines より引用このように、サービスパイプラインを適切に定義し、運用していくことは、クラウドネイティブなアプリケーション開発において欠かせない実践だと言えます。そのためのツールの選定は、単に機能や性能だけでなく、開発者のエクスペリエンスや、チームのカルチャーとの親和性など、多面的な視点から行う必要があります。Figure 3.5 Running pipelines requires a lot of infrastructure to be in place. より引用パイプラインを実行するためには、図にあるように、様々なインフラの整備が必要不可欠です。各種リポジトリ、コンテナレジストリ、Kubernetesクラスターなど、多岐にわたるコンポーネントを連携させる必要があります。これらのインフラを個別のプロジェクトごとに構築するのは非常に非効率です。コストや管理の手間を考えると、組織横断で共有できるプラットフォームとして提供するのが望ましいでしょう。そこで重要になってくるのが、プラットフォームチームの存在です。プラットフォームチームは、開発チームが利用しやすいパイプラインのテンプレートを用意し、ベストプラクティスをコード化して提供します。具体的には、言語ごとのビルドやテストのツールセット、デプロイに必要なマニフェストの生成ロジックなどを、プラットフォームとして標準化するのです。開発チームはそれらを利用しつつ、各アプリケーションに特化した処理を付け加えていけば良いでしょう。こうすることで、開発チームは本質的なロジックの実装に集中でき、しかも一定の品質を担保されたパイプラインを利用できるようになります。まさに、プラットフォームが提供すべき価値だと言えます。一方で、全てのアプリケーションに対して、一律のパイプラインを適用するのは現実的ではありません。例えば、レガシーなシステムをマイクロサービス化する過程では、新旧のサービスが混在することになります。レガシーなサービスに対しては、従来のビルドツールやデプロイ手法を踏襲せざるを得ないかもしれません。そうした例外に対しては、プラットフォームチームが柔軟に対応し、段階的な移行をサポートしていく必要があります。究極的には、パイプラインのコードを通じて、プラットフォームと開発チームのコラボレーションを促進することが肝要です。開発チームはアプリケーションに関する知見を、プラットフォームチームはインフラに関する知見を持ち寄り、パイプラインの継続的な改善を進めていく。それこそが、クラウドネイティブ時代のDevOpsの理想形と言えるでしょう。本章を通じて、改めてサービスパイプラインの重要性と、その構築の難しさを実感しました。単なるツールの選定や設定の問題ではなく、開発プロセス全体に関わる設計が求められるのです。組織の文化や、開発チームの成熟度なども考慮しなければなりません。画一的な答えはなく、試行錯誤を重ねながら、自社に最適な形を模索していく必要があります。そのためには、プラットフォームチームと開発チームの密なコラボレーションが不可欠です。サービスパイプラインは、エンジニアリングの課題であると同時に、組織の課題でもあるのだと、強く認識させられる内容でした。また、パイプラインのコード化の重要性は、開発者としての自分の仕事の進め方にも示唆を与えてくれました。テストやデプロイの方法をコードの一部として捉え、アプリケーションと一体になったものとして扱うこと。それによって、より俯瞰的に開発プロセスを捉えられるようになるはずです。さらに、パイプラインのコード化は、アプリケーションの品質を長期的に担保していく上でも重要な意味を持ちます。メンバーが入れ替わっても、その時点での最良のプラクティスが脈々と受け継がれていく。まさに、継続的インテグレーション・継続的デリバリーの価値を体現するものだと言えるでしょう。ちなみに、著者は継続的デリバリーに関する優れた書籍として、「Continuous Delivery」と「Grokking Continuous Delivery」の2冊を挙げていました。私も特に「Grokking Continuous Delivery」は非常に分かりやすく、お勧めの一冊です。継続的デリバリーの考え方や、パイプラインの設計方法について、体系的に学ぶことができます。syu-m-5151.hatenablog.comクラウドネイティブの世界で開発者として生きていく上で、サービスパイプラインをどう構築・活用していくかは避けて通れない問題です。ただツールを選ぶだけでなく、自分たちの開発文化そのものを設計する。そんな広い視野を持つことの大切さを、本章は教えてくれました。もちろん、これは簡単なことではありません。日々の開発タスクに追われる中で、パイプラインまで手が回らないというのが正直なところでしょう。だからこそ、プラットフォームチームの役割が重要になってくるのです。現場の開発者の負担を減らしつつ、ベストプラクティスの採用を促していく。そのための仕組みと文化を育てていくことが、プラットフォームチームに求められる使命だと言えます。理想的なサービスパイプラインの姿は、組織によって異なるでしょう。どこを目指すのか、そのために何をすべきかは、組織の状況に応じて見極めていかなければなりません。ただ、開発者として心に留めておきたいのは、サービスパイプラインの構築は、決して他人事ではないということです。自分たちで作ったアプリケーションを、自分たちの手でより良い形でお客様に届けるために、パイプラインを日々改善していく。そんな当事者意識を持つことが、クラウドネイティブ時代のソフトウェアエンジニアに求められているのだと感じます。その意味で、本章はサービスパイプラインについての技術的な知見だけでなく、開発者としてのマインドセットを見つめ直すためのヒントも与えてくれました。著者の知見に導かれながら、自分なりのベストプラクティスを追求していきたいと思います。継続的デリバリーの実現は、一朝一夕にはいきません。しかし、その過程で得られる学びは、エンジニアとしての成長に直結するはずです。プラットフォームチームと開発チームが一丸となって、理想のパイプラインを追求していく。そのために、一人一人が当事者意識を持って臨むことが何より大切だと、本章を読んで強く感じました。本章の内容は、そのための第一歩を踏み出すための勇気と知見を与えてくれるはずです。著者の経験に基づく生きたアドバイスの数々は、きっと読者の心に響くことでしょう。理想的なパイプラインを構築するのは簡単ではありませんが、その過程で得られる学びは計り知れません。失敗を恐れず、仮説検証を繰り返しながら、自分たちなりのベストプラクティスを追求していく。そうした探求心こそが、エンジニアを駆り立てる原動力になるはずです。本書の主題である"プラットフォームエンジニアリング"も、そうした探求の先に見えてくるものだと感じています。開発者とインフラの垣根を越えて、アプリケーションとプラットフォームが一体となった開発スタイルを確立する。それはまさに、クラウドネイティブ時代のソフトウェア開発の理想形と言えるでしょう。本章はそのためのロードマップを提示してくれました。読者の皆さんには、ぜひ自分たちなりのサービスパイプライン構築に挑戦してみてください。きっと、開発者としての新たな可能性に気づくことができるはずです。4 Environment pipelines: Deploying cloud-native applications本章では、サービスパイプラインによって生成されたリソースを実際の環境にデプロイするための「パイプライン」について深く掘り下げられていました。私たちが作り上げたアプリケーションが真の価値を生むのは、それが実際のユーザーに届けられて初めて可能になります。そのためには、開発環境から本番環境まで、様々なステージを経由しながら、アプリケーションを安全かつ確実にデプロイしていく必要があります。この一連のプロセスを自動化し、信頼性と再現性を担保するのが、パイプラインの役割だと言えるでしょう。例のGitOpsのページが移動されたのでGoogle Cloudさんのページを公開しておきます。cloud.google.com著者は特に、GitOpsの考え方を取り入れることの重要性を強調していました。GitOpsとは、環境の設定をコードとして管理し、Gitリポジトリを信頼できる唯一の情報源として扱う手法のことを指します。つまり、インフラストラクチャのあるべき状態を宣言的に記述し、それをGitで管理するのです。GitOpsに従えば、環境の状態は常にGitリポジトリの内容と同期されていなければなりません。環境に変更を加えるには、Gitリポジトリに対してプルリクエストを発行し、レビューを経てマージするというプロセスを踏むことになります。Figure 4.10 Argo CD will sync environments, configurations from Git to live clusters より引用これにより、変更の履歴が追跡可能になるだけでなく、問題が発生した際にはすぐに前のバージョンに戻せるようになります。また、設定のドリフトを防ぎ、環境間の一貫性を保つことも容易になるのです。インフラストラクチャの状態をコードで表現することで、それを他の人と共有したり、レビューしたりすることが可能になります。つまり、インフラストラクチャの変更も、アプリケーションコードの変更と同様に、プルリクエストベースのワークフローに乗せられるようになるのです。GitOpsを実装するためのツールとして、本章ではArgo CDが紹介されていました。Argo CDは、Kubernetes向けの継続的デリバリーツールであり、GitリポジトリとKubernetesクラスターを監視し、両者の状態を同期し続けてくれます。具体的には、Gitリポジトリに格納されたマニフェストファイルを読み取り、それをKubernetesクラスターに適用するのです。もし、クラスターの状態がマニフェストファイルの内容と異なっていれば、Argo CDが自動的にそれを修正してくれます。argo-cd.readthedocs.ioまた、Argo CDは直感的なWebインターフェースを提供しており、そこからデプロイメントの状況をビジュアルに把握できます。どのアプリケーションがどのバージョンで動いているのか、そのヘルスステータスはどうなっているのかなどを一目で確認できるのは、オペレーションの効率化に大きく寄与するでしょう。Figure 4.18 Components to set up the staging environment with Argo CD より引用Argo CDとHelmを組み合わせることで、より強力なGitOpsのワークフローを実現できます。Helmは、Kubernetesのパッケージマネージャーであり、アプリケーションの設定値をパラメータ化し、テンプレート化することができます。つまり、Helmを使えば、同じアプリケーションを異なる環境に、異なるパラメータセットで展開することが容易になるのです。helm.shArgo CDは、このHelmチャートも管理対象とすることができます。Gitリポジトリに格納されたHelmチャートを読み取り、それをKubernetesクラスターにデプロイするのです。この組み合わせにより、アプリケーションの設定とインフラストラクチャの設定を、一元的にコードで管理することが可能になります。本書のステップバイステップのチュートリアルでは、実際にArgo CDとHelmを使って、サンプルアプリケーションをKubernetesクラスターにデプロイする手順が丁寧に解説されていました。これを通じて、GitOpsの実践的なスキルを身につけることができたのは、大変貴重な経験となりました。パイプラインは、ソフトウェアリソースを本番環境にデプロイする責務を負っています。パイプラインにより、チームが直接クラスターを操作する必要がなくなり、エラーや設定ミスのリスクを減らせます。また、環境の更新後には、きちんと動作確認を行う必要があります。Argo CD のようなツールを使えば、各環境の内容をGitリポジトリで定義し、信頼できる唯一の情報源として扱うことができます。Argo CD は、クラスターの状態を追跡し、適用された設定にドリフトが発生していないことを保証します。開発チームは、環境で実行されているサービスのバージョンを、環境設定のリポジトリにプルリクエストを発行することでアップグレード・ダウングレードできます。変更はレビューを経てマージされ、承認されれば即座に環境に反映されます。問題が発生した場合は、Gitのコミットを元に戻すことで、ロールバックが可能です。パイプラインは、私たちの開発プロセスに多くのメリットをもたらしてくれます。まず、環境への直接的な干渉を排除し、設定ミスや不整合によるトラブルを防ぐことができます。手作業によるミスを減らし、オペレーションを自動化・標準化できるのです。また、環境の設定を統一的に管理することで、本番環境の再現や、新しい環境の立ち上げを容易にします。テスト環境や、開発者一人ひとりの環境を、本番と同じ構成で簡単に作れるようになるでしょう。このことは、「本番で動くから大丈夫」という過信を排除し、より早い段階で問題を発見・解決することにつながります。加えて、変更管理のプロセスを明確にすることで、開発チーム間のコミュニケーションとコラボレーションを促進します。インフラストラクチャの変更も、アプリケーションの変更と同列に扱われ、レビューの対象になる。これにより、開発者とオペレータの境界が曖昧になり、両者の理解が深まっていくはずです。パイプラインは、アプリケーションの信頼性と安定性を支える重要な基盤であると同時に、開発者のワークフローを改善する強力な手段でもあるのです。適切に実装・運用されたパイプラインは、ビジネススピードを加速し、イノベーションを促進してくれるでしょう。一方で、パイプラインの導入には、一定のコストと学習曲線が伴うことも事実です。GitOpsの考え方に基づいて環境を設計し、適切なツールを選定し、チームの文化を変革していくには、時間と努力が必要となるでしょう。単に新しいツールを導入すれば良いというものではなく、それを活用するためのスキルセットやマインドセットを、チーム全体で醸成していかなければなりません。特に、Kubernetesのようなモダンなプラットフォームを前提としたパイプラインでは、従来のオペレーションとは異なるスキルが要求されます。コンテナやオーケストレーションの知識はもちろん、インフラストラクチャをコードで管理するためのプラクティス、つまりInfrastructure as Code (IaC)についても習熟が必要です。また、GitOpsは強力なプラクティスである一方、万能ではありません。例えば、データベースのスキーマ変更のように、ステートフルで複雑な処理をどう扱うかは、頭を悩ませる問題です。すべてをGitOpsでカバーしようとするのではなく、他のアプローチと適切に組み合わせていくことが肝要でしょう。しかし、長期的な視点に立てば、その投資は必ず報われるはずです。パイプラインを通じて得られる俊敏性と安定性は、ビジネスの成功に直結する重要な要因になると私は確信しています。変化の激しい現代のビジネス環境において、いかに素早く、安全に価値を届けられるかが、競争力の源泉になるのですから。パイプラインは、クラウドネイティブなアプリケーション開発において欠かせない要素です。単純な自動化の仕組み以上に、それは私たちの開発文化そのものを変革する起爆剤にもなり得ます。サービスパイプラインとパイプラインが織りなす継続的デリバリーの世界。そこには、より柔軟で、より俊敏で、より確実なソフトウェア開発の未来が広がっているのです。本章を通じて、パイプラインの真価と、それを実装するための具体的な方法論を学ぶことができました。GitOpsという新しいアプローチは、私にとって目から鱗が落ちる思いでした。単にツールを導入するだけでなく、宣言的にインフラストラクチャを記述し、それを中心にワークフローを回していく。そうしたマインドセットの変革の必要性を強く感じさせられました。Kubernetesという土壌の上に、Argo CDやHelmを駆使して、信頼性と速度を兼ね備えたデリバリーパイプラインを築く。本章は、そのための道標となってくれるはずです。私たち一人ひとりが、チームやプロジェクトの文脈に合わせてこの知見を咀嚼し、パイプラインをどう実装していくか。そこには正解はなく、試行錯誤の連続になるかもしれません。レビューを経ずにインフラストラクチャの変更が行われたり、手動での作業が残っていたりと、理想とする状態には程遠いのが実情でしょう。しかし、だからこそDevOpsの実践が求められているのだと、私は考えます。パイプラインは、開発者とオペレータの協力を促し、継続的な改善を導く強力な仕組みです。それを通じてチームのフィードバックループを回していくことが、私や私たちに課せられた使命だと言えます。ステップバイステップのチュートリアルを実践して、Argo CD を用いてGitOpsの考え方に基づいたデプロイを体験できました。はじめは小さなスコープから始めて、徐々にカバレッジを広げていくのが良いかもしれません。5 Multi-cloud (app) infrastructure本章では、クラウドネイティブアプリケーションのインフラストラクチャをマルチクラウド環境で管理する上での課題と、それを解決するためのアプローチについて詳細に解説されていました。マイクロサービスアーキテクチャの普及により、アプリケーションを構成する各サービスは、データベースやメッセージブローカーなどの依存コンポーネントを必要とするようになりました。これらのコンポーネントをクラウドプロバイダー固有の方法で構築・運用すると、ベンダーロックインの問題が生じ、アプリケーションのポータビリティが損なわれます。つまり、あるクラウドプロバイダーで構築したアプリケーションを、別のクラウドプロバイダーに移行することが難しくなるのです。learning.oreilly.comこの問題を解決するために、筆者はKubernetes APIとCrossplaneの活用を提案しています。Crossplaneは、Kubernetesのエコシステムの一部として開発されたオープンソースのプロジェクトで、主要なクラウドプロバイダーのリソースをKubernetesのカスタムリソースとして管理することができます。Crossplaneを使うことで、クラウドプロバイダーに依存せずにインフラをプロビジョニングできるため、マルチクラウド戦略を推進する上で非常に重要な役割を果たします。www.crossplane.ioCrossplaneの中核となる機能が、Composite Resource Definitions（XRDs）です。XRDsは、Kubernetesのカスタムリソースを定義するための仕組みで、ドメイン固有の概念をKubernetesのオブジェクトとして表現できます。例えば、"Database"や"MessageQueue"といったアプリケーションが必要とするコンポーネントを、XRDsを通じて抽象化することができます。プラットフォームチームは、XRDsを適切に設計することで、アプリケーションチームが必要とするリソースを宣言的に要求できるインターフェースを提供します。XRDsを定義する際には、アプリケーションチームのニーズを的確に捉えることが重要です。単に技術的な観点からリソースを抽象化するのではなく、アプリケーションチームがどのような概念で infrastructure as code を考えているのかを理解する必要があります。例えば、あるアプリケーションチームは "Database" というリソースを、「リレーショナルデータベースであること」「高可用性を備えていること」「自動バックアップが設定されていること」といった特性を持つものとして捉えているかもしれません。一方、別のチームは "Database" を、「ドキュメント指向のデータベースであること」「スキーマレスであること」「地理的に分散されたレプリケーションを備えていること」といった特性を持つものとして考えているかもしれません。プラットフォームチームは、これらの異なる要求を抽象化し、統一的なインターフェースを提供する必要があります。つまり、XRDsの設計には、アプリケーションチームとのコミュニケーションと、ドメインの深い理解が不可欠なのです。また、XRDsを定義する際には、将来の拡張性も考慮しなければなりません。アプリケーションチームのニーズは常に変化するため、XRDsもそれに合わせて進化させる必要があります。したがって、XRDsの設計はアプリケーションチームとの継続的な対話を通じて、段階的に洗練させていくべきものだと言えます。XRDsに対応するCompositionの設計も、同様に重要です。Compositionは、XRDsによって定義されたリソースを、実際のクラウドプロバイダー上のリソースにマッピングするための仕組みです。つまり、Compositionは、XRDsとクラウドプロバイダーの間の橋渡しの役割を果たします。Compositionを定義する際には、クラウドプロバイダーのサービスやAPIに関する深い知識が必要になります。例えば、あるCompositionでは、XRDsで定義された "Database" リソースを、Amazon RDSのPostgreSQLインスタンスにマッピングするかもしれません。その際、RDSインスタンスの作成に必要なすべてのパラメータ（インスタンスクラス、ストレージサイズ、ネットワーク設定など）を、XRDsで指定されたパラメータから適切に設定しなければなりません。また、RDSインスタンスに付随するその他のリソース（セキュリティグループ、モニタリング設定、バックアップ設定など）も、同時に作成・設定する必要があります。これらのリソースの作成や設定には、AWSのAPIやSDKを使用することになります。したがって、Compositionの設計には、クラウドプロバイダーのAPIやSDKに関する知識と、それらを効果的に活用するためのプログラミングスキルが求められます。また、クラウドプロバイダーのベストプラクティスやレコメンデーションにも精通している必要があります。例えば、AWSには、Well-Architectedフレームワークというベストプラクティスの集大成がありますが、Compositionの設計はこれに沿ったものであるべきです。さらに、Compositionの設計には、運用面での考慮も欠かせません。作成したリソースを適切にモニタリングし、問題が発生した際には速やかに検知・通知できる仕組みを用意しなければなりません。また、リソースの変更管理やバージョン管理、ロールバック機能なども必要になります。これらの運用機能は、クラウドプロバイダーのサービスを活用することで実現できる場合もありますが、Compositionレベルでの抽象化が必要なケースもあるでしょう。加えて、Compositionではインフラストラクチャのコストの最適化も考慮する必要があります。クラウドプロバイダーのサービスは、そのほとんどが従量課金制で提供されています。したがって、Compositionで作成するリソースのスペックや数量を適切に設定し、不要なコストが発生しないように注意しなければなりません。そのためには、アプリケーションの要件を正確に把握し、それに見合ったリソースを過不足なくプロビジョニングすることが求められます。以上のように、XRDsとCompositionの設計には、アプリケーションドメインに関する知識、クラウドプロバイダーのサービスやAPIに関する知識、プログラミングスキル、運用スキル、コスト最適化のスキルなど、多岐にわたる専門性が必要とされます。つまり、プラットフォームチームには、従来のインフラストラクチャの管理とは異なるスキルセットが求められるのです。特に、クラウドプロバイダーのサービスやAPIは常に進化し続けているため、プラットフォームチームはそれらの変化に追随し続ける必要があります。新しいサービスや機能が登場した際には、それらをどのようにCompositionに取り込むか、XRDsのインターフェースにどう反映するかを検討しなければなりません。つまり、Crossplaneを活用したプラットフォームの構築は、継続的な学習と改善のプロセスだと言えます。また、プラットフォームチームは、アプリケーションチームとインフラストラクチャチームの間に立つ存在でもあります。両チームの要求や制約を理解し、それらを適切にXRDsやCompositionに反映していく必要があります。つまり、プラットフォームチームには、技術的なスキルだけでなく、コミュニケーション能力やコーディネーション能力も求められるのです。Crossplaneは、GitOpsとの親和性も高いことが特徴の一つです。XRDsで定義されたリソースは、Kubernetesのマニフェストファイルと同様に、Git上で管理することができます。つまり、インフラストラクチャの状態をGitリポジトリで管理し、Gitのワークフローに乗せることで、インフラストラクチャの変更を宣言的に管理できるのです。GitOpsを採用することで、インフラストラクチャの変更は、Gitリポジトリへのコミットとして表現されます。したがって、変更の経緯を追跡しやすく、変更のレビューやテストも行いやすくなります。また、リポジトリの状態とクラスターの状態を常に同期させることで、インフラストラクチャの状態のドリフトを防ぐこともできます。GitOpsとCrossplaneを組み合わせることで、アプリケーションのデプロイメントパイプラインにインフラストラクチャの変更を統合することも可能になります。アプリケーションの変更に必要なインフラストラクチャの変更を、アプリケーションのソースコードと同じリポジトリで管理し、同じパイプラインでデプロイすることで、アプリケーションとインフラストラクチャのライフサイクルを一元的に管理できるのです。ただし、GitOpsの実践には、独自の課題もあります。例えば、Gitリポジトリの構成をどのように設計するか、secrets の管理をどうするか、変更の競合をどう解決するかなど、運用面での検討が必要になります。また、GitOpsではインフラストラクチャの変更がコードとして表現されるため、コードのクオリティを維持するためのプラクティス（レビュー、テスト、リファクタリングなど）も必要になります。Crossplaneを活用したマルチクラウドでのアプリケーション基盤の構築は、大きな可能性を秘めていますが、同時に多くの課題も抱えています。技術的な複雑さだけでなく、組織やプロセスの変革も必要になります。プラットフォームチームの役割と責任、アプリケーションチームやインフラストラクチャチームとの協調の在り方など、従来とは異なる体制が求められるでしょう。また、マルチクラウド環境では、各クラウドプロバイダーの特性を理解し、それらを適切に活用することも重要です。単に複数のクラウドを使うのではなく、各クラウドの強みを生かし、弱みを補完し合うような設計が必要になります。そのためには、プラットフォームチームがクラウドプロバイダーの動向を常に把握し、最新の知見を取り入れ続けなければなりません。さらに、マルチクラウド環境では、セキュリティやコンプライアンス、コスト管理などの課題もより複雑になります。各クラウドプロバイダーのセキュリティ機能や料金体系を理解し、それらを横断的に管理・統制する必要があります。また、クラウド間でのデータの移動や同期、可用性や性能の確保など、アーキテクチャ面での検討も欠かせません。こうした課題を解決するには、プラットフォームチームの高度な技術力とともに、組織全体での意識改革と協調が不可欠です。アプリケーションチームは、インフラストラクチャを意識したアプリケーション設計を行う必要がありますし、インフラストラクチャチームは、アプリケーションの要件を理解した上でインフラストラクチャを提供する必要があります。また、セキュリティチームや財務チームなど、関連する他部門とのコラボレーションも重要になるでしょう。つまり、Crossplaneを活用したプラットフォームエンジニアリングは、単なる技術的な取り組みではなく、組織文化の変革でもあるのです。siloを打破し、チーム間のコラボレーションを促進し、継続的な学習と改善を組織に根付かせること。それがプラットフォームチームに求められる重要な役割だと言えます。本章の内容は、こうしたプラットフォームエンジニアリングの課題と可能性を、Crossplaneを中心に論じたものでした。筆者自身、日々の業務でKubernetesやCrossplaneに携わる中で、その難しさと面白さを実感しています。特に、XRDsとCompositionの設計は、奥が深く、まだまだ学ぶべきことが多いと感じています。しかし同時に、プラットフォームエンジニアリングのもたらす価値の大きさにも気づかされました。アプリケーションとインフラストラクチャの垣根を越えて、開発と運用の連携を深化させ、ビジネスの俊敏性を高めていく。それは、DXの実現に直結する取り組みだと言えます。もちろん、そこに至るまでの道のりは平坦ではありません。レガシーシステムとのインテグレーション、組織間の政治的な力学、既存の文化や習慣の壁など、立ちはだかる障壁は数多くあります。しかし、それでもなお、プラットフォームエンジニアリングへの挑戦は避けられないものだと感じています。なぜなら、それは単に技術的な必然ではなく、ビジネス環境の変化に対応するための組織的な必然でもあるからです。クラウドやDevOpsの普及により、ソフトウェアがビジネスを左右する時代になりました。そんな時代に求められるのは、変化に素早く適応し、イノベーションを継続的に生み出せる組織の仕組みです。プラットフォームエンジニアリングは、まさにそのような仕組みを実現するためのアプローチだと言えます。開発と運用の連携を高め、アプリケーションとインフラストラクチャをシームレスに扱うことで、ソフトウェア・デリバリーのスピードと質を高める。また、自動化と抽象化を進めることで、チームがよりビジネスに価値のある活動に注力できるようにする。こうしたプラットフォームエンジニアリングの価値は、もはや特定の業界や企業規模に限定されるものではありません。クラウドネイティブの考え方は、あらゆる業界・規模の企業に浸透しつつあります。つまり、プラットフォームエンジニアリングは、どの企業にとっても無視できない重要な取り組みになりつつあるのです。とはいえ、プラットフォームエンジニアリングは万能薬ではありません。過度な自動化や抽象化は、かえって複雑性を生み、イノベーションを阻害する可能性もあります。重要なのは、自社のコンテキストをしっかりと理解した上で、適切な段階的アプローチを取ることです。その意味で、本書はプラットフォームエンジニアリングを進める上での良き指針になるでしょう。Crossplaneを中心とした技術的な側面だけでなく、チームの構成や文化、プロセスといった組織的な側面についても、バランス良く論じられていました。これは、プラットフォームエンジニアリングが、技術と組織の両面にまたがる取り組みだからこそ重要な視点だと感じました。筆者自身、本章で得られた知見を日々の業務に活かしていきたいと考えています。特に、XRDsとCompositionの設計については、アプリケーションチームとのコミュニケーションを密にし、ドメインモデルを深く理解することの重要性を再認識しました。また、プラットフォームチームの在り方についても、本書で提示された視点を参考に、自社での最適な形を模索していきたいと思います。6 Let's build a platform on top of KuberneteKubernetes上でのプラットフォーム構築に関する具体的な方法論と深い洞察に満ちた、非常に示唆に富む内容でした。著者は、プラットフォームエンジニアリングにおける重要な概念と実践を、豊富な事例とともに解説しています。第6章の前半では、プラットフォームAPIの設計と、マルチクラスター・マルチテナンシーの課題が中心的に論じられています。まず著者は、プラットフォームが Kubernetes 上で提供すべき機能を特定することの重要性を説いています。開発チームのワークフローを理解し、彼らが必要とするサービスを抽出することが、プラットフォームAPIの設計の出発点となります。ここでは、開発チームが新しい環境を要求するシナリオを例に、APIのデザインプロセスが丁寧に解説されています。要求された環境をプロビジョニングし、アクセス情報を返却する自動化ロジックを実装することで、開発チームの生産性を大きく向上できるのです。このアプローチは、プラットフォームエンジニアリングの神髄とも言うべきものです。技術的な実装の前に、ユーザーである開発者の体験を起点に設計を進めるというマインドセットこそが、真に開発者に寄り添ったプラットフォームを生み出す鍵となります。続く議論では、マルチクラスターおよびマルチテナントのセットアップに関する課題が取り上げられます。本番、ステージング、開発など、様々な環境を提供する必要があるKubernetesベースのプラットフォームでは、これらの課題が避けて通れません。著者は、プラットフォーム専用のクラスターを設けることで、一貫した管理と高い可用性を実現するアプローチを提案しています。ワークロードとは分離された環境でArgoCD、Crossplaneなどのツールを用いてプラットフォームを構築することで、求められるSLOやセキュリティ要件に適切に対処できるのです。また、マルチテナンシーの実現方法として、Namespaceによる分離と、完全に独立したクラスターによる分離のトレードオフについても、鋭い考察が展開されています。前者は手軽である一方で分離のレベルが低く、後者は強力な分離を提供する反面コストと運用負荷が大きいという、難しい選択の狭間にある課題です。この問いに対する著者の提案が、vclusterを用いた仮想クラスターのアプローチです。1つのKubernetesクラスター内に、テナントごとに独立したコントロールプレーンを持つ仮想クラスターを動的に生成することで、Namespaceと独立クラスターの中間的な選択肢を提供できるのです。www.vcluster.comAPIサーバーレベルの分離により、テナントはクラスター全体に対する高い自由度を享受しつつ、リソースの利用効率を高められる。これは、マルチテナンシーの難しい課題に対する、エレガントな解決策の一つと言えるでしょう。以上の議論を通じて、読者はKubernetes 上のプラットフォームがどのようなものかを具体的に理解できるようになります。プラットフォーム構築には、インフラストラクチャの設計だけでなく、開発者の体験を起点とした抽象化やAPIのデザインが不可欠だということ。そして、それを実現するためには、Kubernetesの深い理解に加え、マルチクラスター・マルチテナンシーの課題に正面から向き合う必要があるということ。第6章の前半は、そうした重要な気づきに満ちています。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。以上のように、複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。第6章の後半では、これらの知見を実践的なコードとともに示した「ウォーキングスケルトン(PoC)」の例が紹介されています。ここで著者が強調するのは、Kubernetes 上にプラットフォームを構築することは、さまざまな要件を持つチームにサービスを提供するために、さまざまなツールを組み合わせる必要がある複雑なタスクだということです。Crossplane、ArgoCD、vclusterなど、多岐にわたるツールへの理解が求められます。しかし同時に、プラットフォームはビジネス アプリケーションとしてのソフトウェア プロジェクトでもあります。主要なユーザーが誰になるかを理解することから始め、明確な API を定義することが、プラットフォームを構築する上で何を優先すべきかを決める鍵となります。技術的な側面だけでなく、開発者の体験を起点とした設計が肝要なのです。ウォーキングスケルトンの例では、Crossplaneを用いて Environment という Custom Resource を定義し、それをKubernetesのAPIサーバーに適用するだけで、開発者はシンプルなYAMLを書くだけで必要な環境を要求できるようになります。このアプローチは、宣言的インフラストラクチャの理想を見事に体現していると言えるでしょう。コードとインフラの融合により、環境のプロビジョニングがアプリケーションデプロイメントと同じ土俵で扱えるようになるのです。Figure 6.9 Combining GitOps and Crossplane for managing environments and clusters より引用さらに、vclusterとCrossplaneを組み合わせることで、動的にテナント固有の仮想クラスターを生成する例も印象的でした。これにより、クラウド ネイティブへの移行を加速するために何を構築できるかを社内チームに示すことができます。開発者は、自分専用のKubernetes環境を手に入れつつ、プラットフォームの管理というオーバーヘッドからは開放されるという、まさにDXとインフラ効率化の両立を実現する理想的なアプローチです。Figure 6.16 Using Crossplane and vcluster to create isolated environments for application development teams より引用もちろん、実際のプラットフォームではより多くの要素を考慮する必要があります。とはいえ、Crossplane、ArgoCD、vclusterなどのツールを活用することで、プラットフォーム レベルでクラウド ネイティブのベスト プラクティスを促進できることは間違いありません。ただし、ここで著者が強調しているのは、既存のツールを適切に組み合わせることの重要性です。カスタム ツールや、クラウド ネイティブ リソースの複雑な構成をプロビジョニングおよび維持する独自の方法を作成するのは避けるべきだと述べています。可能な限り、既存のツールやプラクティスを活用し、シンプルさを保つことが肝要なのです。Figure 6.18 Platform walking skeleton tools, configurations, and services より引用実際、本書のステップバイステップのチュートリアルに従うことで、Crossplane などのツールを使用して、vclusterオンデマンド開発環境をプロビジョニングする実践的な経験を得ることができます。また、本格的な Kubernetes API サーバーを操作したくない、または操作できないチームのために、簡素化された API も提供されています。これにより、開発チームの認知負荷を軽減しつつ、プラットフォームの恩恵を享受できるようになるのです。複数の Kubernetes クラスターの管理とテナントの分離への対処が、プラットフォーム チームの主要な課題であることを認識しつつ、適切なツールを選定し、シンプルさを保ちながら開発者の体験を向上させていくこと。それこそが、プラットフォームの成功を左右する鍵なのだと、ここからは読み取れます。Figure 6.19 Platform responsibilities and boundaries より引用本章は、プラットフォームエンジニアリングの本質を、概念と実装の両面から照らし出してくれる、稀有な内容でした。単なるツールの解説にとどまらず、開発者の体験を起点とした設計思想や、チームとの協調の重要性など、プラットフォーム構築に不可欠な知見が余すところなく述べられています。本章を通じて、私はプラットフォームの構築が、技術とプロセス、そして文化の融合であることを改めて認識しました。優れたツールの選定と適切な組み合わせは もちろん重要です。しかし、それ以上に大切なのは、開発者の声に耳を傾け、彼らの創造性を解き放つ仕組みを築くことなのだと。Kubernetesとそのエコシステムは、プラットフォームを構築するための強力な基盤を提供してくれます。しかし、それをどう活用し、どのような形でチームに提供するかは、私たち自身の創意工夫次第です。技術の力を借りつつ、開発者の声に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は教えてくれました。本章は、プラットフォームエンジニアリングという新しい領域に踏み出すための、確かな一歩を印してくれる内容でした。著者の知見を自分なりに咀嚼し、日々の開発プロセスに活かしていく。その積み重ねの先に、真のDXを実現するプラットフォームが生まれるはずです。7 Platform capabilities I: Shared application concerns著者は冒頭で、クラウドネイティブアプリケーションの95%が行っている要件を学ぶことの重要性を強調しています。その要件とは、他のサービスとの通信、永続ストレージへのデータの保存と読み取り、非同期でのイベントやメッセージのやり取り、サービス接続用の認証情報へのアクセスなどです。私自身、日々の開発業務でこれらの課題に幾度となく直面してきました。著者の指摘は、まさに開発現場の実情を的確に捉えたものだと感じました。Figure 7.1 Common communication patterns in distributed applications より引用これらの共通機能を実装する際の課題として、著者はアプリケーションとインフラストラクチャの間の摩擦を減らすことの重要性を指摘しています。サービス間通信やデータベース接続のために、アプリケーションコードにベンダー固有のライブラリやドライバを追加すると、インフラストラクチャの変更がアプリケーションの変更を強いることになります。この密結合が、開発チームとインフラチームの協調を複雑にし、ソフトウェアデリバリーのスピードを低下させる要因となっているのです。著者が提案するのは、標準のAPIとコンポーネントで共有の関心事に対処することです。これらの共通機能を標準化されたAPIとして提供し、アプリケーションコードからインフラストラクチャの詳細を切り離すのです。プラットフォームチームがこれらのAPIを実装し、その背後でインフラストラクチャを適切に構成・管理することで、開発チームはビジネスロジックの実装に専念できるようになります。アプリケーションインフラストラクチャに依存関係を移動すると、アプリケーションコードはプラットフォーム全体のアップグレードに影響されずに済みます。アプリケーションとインフラストラクチャのライフサイクルを分離することで、チームは日常的なユースケースでプロバイダー固有のクライアントやドライバーを扱う代わりに、安定したAPIに依存できるようになります。Figure 7.14 Decoupling responsibilities from app dev teams and platform capabilitiesより引用この提案には大いに共感を覚えました。私もかねてより、アプリケーションとインフラの責務を明確に分離し、疎結合な設計を追求することの重要性を感じていました。標準化されたAPIを介してインフラストラクチャと対話することで、開発チームはベンダーロックインを回避しつつ、インフラの進化から独立してアプリケーションを開発できるようになります。著者は、この考え方を具体化するためのツールとして、Dapr（Distributed Application Runtime）とOpenFeatureを紹介しています。Daprは、分散アプリケーションの構築に必要な共通機能を、標準化されたAPI（Building Block API）として提供するオープンソースのプロジェクトです。Daprは、分散アプリケーションを構築する際の共通の関心事を解決します。HTTP/GRPCリクエストを書くことができる開発者は、プラットフォームチームが接続するインフラストラクチャとやりとりできます。 サービス間通信、状態管理、Pub/Sub、シークレットストアなど、クラウドネイティブアプリケーションに不可欠な機能がコンポーネント化され、統一的なインターフェースで利用できるようになっています。dapr.io私は以前からDaprに注目していましたが、改めてその設計思想の優れていることを実感しました。アプリケーションが標準的なHTTP/gRPCのAPIを通じてこれらの機能を利用できるため、プログラミング言語に依存せずに共通機能を実装できます。また、コンポーネントの実装を切り替えるだけで、異なるベンダーのサービスを利用できるのも大きな利点です。インフラの選定はプラットフォームチームに委ね、開発チームはアプリケーションの開発に専念できる。まさにDaprは、アプリケーションとインフラの責務を明確に分離するためのツールと言えるでしょう。syu-m-5151.hatenablog.com特に、サービス間通信とステートマネジメントのシナリオは、印象的でした。DaprのサービスインヴォーケーションAPIを使えば、サービス間の通信を抽象化し、さまざまな通信プロトコルを透過的に利用できます。またステートストアAPIにより、アプリケーションはデータベースの種類を意識せずに状態を保存・取得できるようになります。実際のアプリケーション開発において、これらのAPIがいかに複雑性を減らし、生産性を高めてくれるかが実感できる内容でした。一方、OpenFeatureは機能フラグ（Feature Flag）の管理を標準化するためのプロジェクトです。機能フラグを使用すると、新機能を機能フラグの背後にマスクすることで、開発者はソフトウェアのリリースを継続できます。 機能フラグは、リリース済みの機能の有効・無効を動的に切り替える仕組みで、継続的デリバリーの文脈でよく用いられます。しかし、その実装は各社まちまちで、ベンダーロックインが起こりがちでした。OpenFeatureは、アプリケーションが機能フラグを使用して評価する方法を標準化します。OpenFeatureの抽象化に依存することで、プラットフォームチームは機能フラグの保存場所と管理方法を決定できます。 さまざまなプロバイダーが、非技術者向けのダッシュボードを提供し、フラグの表示や操作ができるようになります。Figure 7.22 Consuming and evaluating feature flags from our application services より引用私は機能フラグの重要性を認識しつつも、その導入の複雑さゆえに二の足を踏んでいました。しかしOpenFeatureにより、ベンダーに依存せずに機能フラグを利用できるようになるのは画期的だと感じました。開発チームは機能の実装に集中し、リリースのタイミングはビジネスサイドが制御する。そんな理想的なデリバリープロセスが、OpenFeatureによって実現に近づくのではないでしょうか。openfeature.dev著者はまた、これらの標準化の取り組みを適用する際の留意点についても言及しています。外部APIへの依存は新たな課題を生むため、ローカル開発環境でのテストや、レイテンシーへの配慮が必要になります。また、エッジケースを個別に扱うことで、専門家はアプリケーションの要件に基づいてより意識的なケースを作成できます。これにより、経験の浅いチームメンバーが、データの保存や読み取り、アプリケーションコードからのイベントの発行のみを行う場合に、ベンダー固有のデータベース機能や低レベルのメッセージブローカー設定などのツールの詳細を理解する必要がなく、一般的なシナリオを処理できるようになります。 プラットフォームチームは、開発チームとの緊密なコミュニケーションを通じて、適切な抽象化のレベルを見極めていく必要があるのです。章の後半では、これらの知見をConferenceアプリケーションに適用する方法が具体的に示されています。Redis や Kafka への依存を Dapr の API で置き換え、機能フラグを OpenFeature で管理する例は、非常に示唆に富むものでした。コード例を見ると、標準APIがいかにしてベンダー依存を排除し、開発者の体験を向上させているかが手に取るようにわかります。Figure 7.23 Using Dapr components for our walking skeleton / Conference application より引用これは私にとって、Dapr と OpenFeature の有用性を確信できる一節でした。ステップバイステップのチュートリアルに従った場合、SQL や NoSQL データベース、Kafka などのメッセージブローカーとやり取りする4つのサービスで構成されるクラウドネイティブアプリケーションのコンテキストで、Dapr や OpenFeature などのツールを使用した実践的な経験を得ることができました。また、実行中のアプリケーションのコンポーネントを再起動せずに、その動作を変更するために機能フラグを変更しました。 Kubernetesの普及により、インフラストラクチャのAPIは標準化されつつあります。一方で、アプリケーションレイヤーの共通機能は、いまだ各社独自の実装に委ねられているのが実情です。Dapr と OpenFeature は、このアプリケーションレイヤーに標準化をもたらす画期的なプロジェクトだと言えるでしょう。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にインフラを提供するだけでなく、アプリケーションの共通関心事をカプセル化し、開発者の生産性を高めることがプラットフォームの本質的な価値だと。Dapr や OpenFeature のようなツールを活用しつつ、開発チームに寄り添ったプラットフォームを構築すること。そこにこそ、プラットフォームエンジニアの腕の見せ所があるのだと感じました。もちろん、標準化された API を導入するだけで全てが解決するわけではありません。エッジケースをどう扱うか、レガシーなシステムとの整合性をどう取るか。プラットフォーム構築の道のりは平坦ではありません。しかし、アプリケーションとインフラの責務を分離し、開発チームの生産性を高めるという指針は普遍的なものだと信じています。プラットフォームエンジニアリングの真髄は、技術の標準化とコミュニケーションの両輪にあるのだと、本章は教えてくれました。本章は、クラウドネイティブ時代のアプリケーション開発の課題と、それを解決するための処方箋を示してくれる、示唆に富んだ内容でした。Dapr や OpenFeature のような取り組みは、まさにクラウドネイティブの「今」を体現するものだと言えるでしょう。同時に、それらを適切に活用し、開発チームに価値を届けるには、プラットフォームチームの深い理解と尽力が不可欠です。プラットフォームエンジニアリングの真価が問われるのは、技術の選定よりもむしろ、技術をいかに活用するかにあるのかもしれません。標準化と抽象化を追求しつつ、現場の声に真摯に耳を傾ける。そのバランス感覚こそが、優れたプラットフォームを生み出す鍵なのだと、本章は示唆しています。本章で紹介されたツールやプラクティスは、開発者としての私の日々の実践にも大いに役立つはずです。Dapr や OpenFeature を実際のプロジェクトで活用し、その効果を体感してみたいと思います。同時に、インフラストラクチャの標準化が進む中で、アプリケーションレイヤーの共通関心事にも目を向けることの大切さを、胸に刻んでおきたいと思います。著者の知見を自分なりに咀嚼し、より良いアプリケーション開発とデリバリーのあり方を追求していく。エンジニアとしての私の使命は、まさにそこにあるのだと、改めて認識させられた次第です。クラウドネイティブの世界は、日進月歩で進化を続けています。Dapr や OpenFeature に象徴されるように、アプリケーションレイヤーの標準化も着実に進んでいます。私たちがすべきことは、その流れを見極めつつ、自分たちのコンテキストに適した形で活用していくことです。8 Platform capabilities II: Enabling teams to experimentKubernetesを基盤としたプラットフォーム上で、チームが新しいバージョンのアプリケーションを安全かつ柔軟にリリースするための手法について、深く掘り下げた内容でした。著者は冒頭で、カナリアリリース、ブルー/グリーンデプロイメント、A/Bテストなどの一般的なリリース戦略を実装することの重要性を説いています。これらの手法は、新しいバージョンのソフトウェアを段階的に展開し、問題を早期に発見しつつ、ユーザーへの影響を最小限に抑えるために不可欠です。しかし、著者が指摘するように、これらのリリース戦略をKubernetesの組み込みリソースだけで実装するのは非常に難しい作業です。Deploymentの複製や、Serviceの設定変更など、手作業での操作が多くなり、ミスも起こりやすくなります。そこで著者が紹介するのが、Knative ServingとArgo Rolloutsという2つのプロジェクトです。これらのツールは、Kubernetesの上に高レベルの抽象化を提供することで、リリース戦略の実装を大幅に簡素化してくれます。argoproj.github.ioknative.devKnative Servingは、洗練されたネットワーク層を導入し、サービスの異なるバージョンへのトラフィックをきめ細かく制御できるようにします。Knative Serviceを使えば、カナリアリリースやブルー/グリーンデプロイメント、A/Bテストを、複数のKubernetesリソースを手動で作成することなく実現できます。Figure 8.1 Releasing a new version (canary) of the service with 5% traffic routed to it より引用Knative Servingの大きな魅力は、トラフィックの移動を簡単に行えることと、Knativeのオートスケーラーが需要に応じてサービスをスケールアップ/ダウンしてくれることです。これにより、運用の負担が大幅に軽減されるのです。一方、Argo Rolloutsは、ArgoCDと連携し、Rolloutというリソースを使ってリリース戦略を実装する方法を提供します。Argo RolloutsはAnalysisTemplateとAnalysisRunという仕組みも備えており、新しいリリースの自動テストを行い、安全にバージョン間を移行できるようにしてくれます。Figure 8.23 Blue/green deployment with Kubernetes resources より引用この2つのプロジェクトの存在は、Kubernetes上でのソフトウェア・デリバリーの課題の大きさを物語っていると感じました。アプリケーションのデプロイだけでなく、それを安全かつ柔軟に行うための機能が、プラットフォームに求められているのです。特に印象的だったのは、Knative Servingのトラフィック制御機能の強力さです。重み付けベースのルーティングや、ヘッダーベースのルーティングなどを使えば、カナリアリリースの過程で新旧のバージョンへのアクセスを動的に制御できます。これは、リスクを最小限に抑えつつ、新機能の検証を進められる画期的な方法だと感じました。Figure 8.8 Knative Serving tag-based routing for version v1.1.0. より引用また、Argo Rolloutsの分析テンプレートの仕組みにも目を見張りました。あらかじめ定義した指標に基づいて、新バージョンの動作を自動的に検証できるのは、リリースプロセスの安全性と効率を大いに高めてくれるはずです。Figure 8.25 Argo Rollouts and analysis working together to make sure that our new revisions are sound before shifting more traffic to them. より引用もちろん、これらのツールを使いこなすには、一定の学習と運用コストがつきまといます。Kubernetes自体の知識に加え、Knative ServingやArgo Rolloutsの概念を理解する必要があります。特に、Istioなどのサービスメッシュとの連携については、さらに高度な知識が求められるでしょう。しかし、長期的に見れば、その投資は確実に報われるはずです。プラットフォームが提供する柔軟なリリース戦略は、ビジネスの俊敏性を高め、イノベーションを加速する力になります。より速く、より安全に価値を届けられるようになることは、競争力の源泉になるのですから。本章を通じて、私はプラットフォームチームの役割の重要性を改めて認識しました。単にKubernetesのリソースを提供するだけでなく、アプリケーションのリリースプロセスをどう効率化するかを考え、適切なツールを選定・提供していくこと。それこそが、開発チームの生産性を真に高めるための鍵なのだと感じました。Figure 8.23 Blue/green deployment with Kubernetes resources より引用そのためには、Knative ServingやArgo Rolloutsだけでなく、Istio、Dapr、OpenFeatureなど、クラウドネイティブのエコシステムを幅広く理解することが求められます。それぞれのツールの特性を把握し、自社のコンテキストに合った形で組み合わせていく。その作業は決して容易ではありませんが、避けて通れないものだと思います。私自身、日々の業務の中で、これらのツールを実際に活用し、その効果を体感してみたいと思います。サービスのデプロイに留まらず、リリースプロセスの自動化と効率化にも目を向ける。そのマインドセットを持つことが、プラットフォームエンジニアとして成長するための第一歩になるはずです。また、本章では、ビジネスサイドのチームとの協調の重要性も浮き彫りになりました。プロダクトマネージャーや非エンジニアのステークホルダーに、新バージョンの検証を柔軟に行える環境を提供すること。これにより、ビジネス主導のイノベーションを後押しできるのです。Figure 8.29 Environments that enable teams to experiment with new versions より引用本章を読み終えて、改めてプラットフォームの真価は、それがエンパワーメントの手段であることだと感じました。開発者の創造性を強化して、ビジネスの意思決定を迅速化する。その先にこそ、ソフトウェアがもたらす本当の価値があるのだと。プラットフォームの構築は、単なる技術的課題ではありません。組織の文化を変え、人々の働き方そのものを変えていく営みです。その変革の旅路は、険しく長いものになるでしょう。でも、そこで得られる学びと成長は、きっとかけがえのないが大変なものになるはずです。9 Measuring your platformsプラットフォームのパフォーマンスを測定することの重要性と、その具体的な手法について深く掘り下げた内容でした。特に、DORAメトリクスの導入と、それを支えるデータパイプラインの設計には、多くの技術的な示唆が含まれていました。dora.devDORAメトリクスは、ソフトウェアデリバリーのパフォーマンスを評価するための事実上の標準として、広く認知されつつあります。デプロイ頻度、リードタイム、変更失敗率、サービス復旧時間の4つの指標は、いずれもデリバリープロセスの重要な側面を捉えており、それらを組み合わせることで、チームの成熟度を多面的に評価できます。Figure 9.1 DORA metrics by category より引用しかし、これらのメトリクスの計算は、決して容易ではありません。データソースが多岐にわたるうえ、それぞれのツールが出力するデータのフォーマットは千差万別だからです。デプロイ頻度を計算するには、CIツールのログとデプロイ環境のイベントを紐づける必要がありますし、リードタイムの算出には、コミットログとデプロイログの時間差を計る必要があります。この複雑性に対する著者の答えが、CloudEventsとCDEventsの活用です。CloudEventsは、クラウドネイティブなイベントを表現するための、ベンダー中立な仕様です。すでにServerless Workflow、Keptn、Knative、Kubernetesなど、多くのプロジェクトがCloudEventsをサポートしており、イベントデータの相互運用性が大きく向上しつつあります。cloudevents.ioCDEventsは、CloudEventsの拡張仕様であり、継続的デリバリーの文脈で共通に発生するイベントを定義したものです。コード変更、ビルド、テスト、デプロイ、リリースなど、パイプラインのあらゆるフェーズがカバーされており、それぞれのイベントが持つべきデータの構造も規定されています。Figure 9.7 The four stages defined by the CDEvents specification より引用つまり、CDEventsに準拠したイベントを集約することで、DORAメトリクスの計算に必要なデータの多くを、統一的なフォーマットで取得できるようになるのです。これは、データ統合のコストを大幅に削減し、メトリクスの信頼性を高めることにつながります。cdevents.devとはいえ、既存のツールをCDEventsに対応させるのは、一朝一夕にはいかないでしょう。そこで著者が提案しているのが、CloudEventsとCDEventsを活用したデータパイプラインの設計です。各ツールが出力するイベントをCloudEventsとして取り込み、それをCDEventsに変換する。そのうえで、変換されたイベントをもとにメトリクスを計算する、というアプローチです。Figure 9.9 Collecting and transforming data to calculate DORA metrics より引用パイプラインの入り口では、Knative Sourcesのようなアダプタを使って、さまざまなツールのイベントをCloudEventsに変換します。例えば、Kubernetes上で動くアプリケーションの場合、KubernetesイベントをCloudEventsに変換するKnative SourceのApiServerSourceを使うことができます。Figure 9.10 Knative Sources and data collection より引用こうして取り込まれたCloudEventsは、いったんデータストアに保存されます。著者の例ではPostgreSQLが使われていますが、他のデータベースやストレージを使うこともできるでしょう。重要なのは、イベントデータを安全に保管し、後の処理で参照できるようにすることです。次のステップは、保存されたCloudEventsをCDEventsに変換することです。著者は、この変換処理を関数（function）として実装することを提案しています。関数を使うメリットは、変換ロジックを小さな単位に分割でき、必要に応じて個別にスケーリングできる点にあります。また、新しい変換ロジックを追加する際も、既存の処理に影響を与えずに実装できます。Figure 9.12 Concrete mapping and CDEvent creation for deployments より引用CDEventsへの変換が完了したら、いよいよDORAメトリクスの計算です。著者の提案では、これもまた関数として実装されます。各メトリックの計算ロジックは、CDEventsから必要なデータを抽出し、所定の計算を行うだけのシンプルなものになります。計算結果は、データストアに保存するか、あるいは直接可視化ツールに送ることができます。Figure 9.15 Deployment frequency calculation flow より引用以上が、著者が提案するデータパイプラインのアーキテクチャの概要です。特筆すべきは、その拡張性の高さでしょう。新しいデータソースへの対応は、CloudEventsへの変換機能を追加するだけで実現できますし、新しいメトリクスの計算も、専用の関数を実装するだけで可能になります。また、変換処理とメトリクス計算がステートレスな関数として実装されているため、必要に応じて水平にスケールすることもできます。この設計は、現時点での技術選択に依存しない、汎用性の高いものだと感じました。実際のシステムを構築する際には、より堅牢なイベントストレージの選定や、耐障害性の確保など、様々な非機能要件も考慮する必要があるでしょう。しかし、その基本的なアプローチは、多くの組織で活用できるはずです。加えて、本章ではKeptn Lifecycle Toolkit（KLT）というオープンソースプロジェクトも紹介されていました。KLTは、Kubernetes上のアプリケーションのデプロイメントを監視し、その前後に任意のタスクを実行できるようにするためのツールです。Figure 9.21 Keptn architecture providing out-of-the-box observability and application lifecycle hooks. より引用KLTは、Kubernetesの標準機能であるSchedulerを拡張することで実現されています。アプリケーションのデプロイメント時に、KLTのControllerが介入し、デプロイメントの前後に登録されたタスクを実行するのです。github.comこれらのタスクはTaskDefinitionという形で定義され、実際の処理はスクリプト（Deno、Python3など）またはコンテナイメージとして実装されます。例えば、デプロイ前にアプリケーションの設定を検証するタスクや、デプロイ後に自動テストを実行するタスクなどが考えられます。keptn.shKLTのアプローチは、先に述べたCloudEvents/CDEventsベースのデータパイプラインとは異なりますが、両者は相互に補完的な関係にあると言えるでしょう。KLTを使えば、デプロイメントのパフォーマンスデータをCloudEventsとして出力し、それをデータパイプラインで処理することもできます。逆に、データパイプラインで計算されたメトリクスを、KLTのタスクで参照することも可能です。重要なのは、これらのツールを組み合わせることで、プラットフォームのパフォーマンス測定を自動化し、継続的な改善につなげられる点です。今や、デリバリーパフォーマンスの向上は、エンジニアリングチームだけの責任ではありません。組織全体でその重要性を認識し、データに基づいた意思決定を行っていく必要があります。そのためには、DORAメトリクスのような共通の物差しを導入し、それを可視化・共有していくことが不可欠です。CloudEventsとCDEvents、そしてKLTは、そのための強力な武器になるはずです。もちろん、ツールの導入だけですべてが解決するわけではありません。測定の文化を組織に根付かせ、データに基づいた継続的改善のサイクルを回すこと。それこそが、プラットフォームチームに求められる真の課題なのだと、私は考えます。本章を通じて、私はプラットフォームのパフォーマンス測定という課題の奥深さを改めて認識しました。適切な指標の選定、データの収集と統合、分析基盤の構築。それらはいずれも、高度な技術力と、現場への深い理解を必要とする難題です。しかし、その困難に立ち向かうことこそが、プラットフォームエンジニアの本懐なのだと思います。本章が提示してくれたのは、その挑戦への道標でした。実装の細部はともかく、その基本的なアプローチは、多くの組織で活用できるはずです。KLTのようなツールも、プラットフォームのパフォーマンス測定という文脈で捉え直すことで、新たな価値を見出せるでしょう。重要なのは、DORAメトリクスに代表される共通の物差しを導入し、それを組織全体で活用していくことです。さいごに本稿では、『Platform Engineering on Kubernetes』の概要と、各章の要点を技術者の視点でまとめました。本書が提示するのは、クラウドネイティブ時代のソフトウェア開発の理想像です。アプリケーションとインフラストラクチャの垣根を越えて、開発チームとプラットフォームチームが協調しながら、ビジネス価値を継続的に届けていく。その実現のためには、技術的な側面だけでなく、組織文化やプロセスの変革も不可欠だと述べられています。私はプラットフォームエンジニアリングという概念自体は以前から知っていましたが、本書ではそれをKubernetesと関連づけて深く考察されていました。単にKubernetesというツールを導入するだけでなく、アプリケーションに必要な機能を適切に抽象化し、チームに提供していくことがプラットフォームの本質的な価値だと説明しながら技術的なことを一切疎かにしていない点がとんでもなく素晴らしいです。また、DORAメトリクスに代表される、デリバリーパフォーマンスの測定の重要性も強調されていました。プラットフォームの価値を定量的に評価し、継続的に改善していくためには、適切な指標の導入と、データに基づいた意思決定が欠かせません。ただし、本書で紹介されているアプローチをそのまま適用できる組織ばかりではないでしょう。大切なのは、自社のコンテキストを深く理解し、そこに適した形でクラウドネイティブの考え方を取り入れていくことだと思います。プラットフォームエンジニアリングを実践していく上では、本書で述べられているようなツールやプラクティスに加えて、コミュニケーションが大切だと思いました。モブプログラミング・モブオペレーションなどの取り組みを通じて、チーム内での知識共有や価値観の浸透を図ることが、プラットフォームの継続的な改善と定着に大きく役立つはずです。本稿では、技術者としての視点から本書の内容をまとめましたが、プラットフォームエンジニアリングの実践には、技術者以外のステークホルダーの理解と協力も不可欠です。マネージャーやビジネスサイドの方々にも本書を読んでいただき、その感想をぜひ共有していただきたいと思います。多様な視点からのフィードバックがあってこそ、真に組織に適したプラットフォームの構築が可能になるはずです。また、本稿ではプラットフォームに関わる技術的な側面に焦点を当てましたが、実際のプラットフォーム構築には、組織的な要素も欠かせません。各チームのエンジニアの育成や、円滑なコミュニケーションの実現など、プラットフォームエンジニアリングには幅広いスキルが要求されます。こうした非技術的な側面については、また別の機会に掘り下げていきたいと思います。プラットフォームは日々進化し続けるものです。特定のツールの使い方を習得するだけでなく、その背後にある考え方や原則を理解し、学び続けていく姿勢が求められます。『Platform Engineering on Kubernetes』は、そのための優れた指南書だと感じました。クラウドネイティブ時代のソフトウェア開発は、まだ道半ばと言えるかもしれません。確立されたベストプラクティスは少なく、私たち一人ひとりが試行錯誤を重ねながら、前に進んでいくしかありません。本書が示してくれた知見と、SREの実践的なアプローチを組み合わせながら、クラウドネイティブ時代のプラットフォームのあるべき姿を、仲間たちと共に探求していきたいと思います。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS EKSのNetwork Policyの動作と実装を確認してみる]]></title>
            <link>https://zenn.dev/satoken/articles/eks-network-policy</link>
            <guid>https://zenn.dev/satoken/articles/eks-network-policy</guid>
            <pubDate>Sat, 23 Mar 2024 15:00:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2023年の9月にAWS EKSのCNIがNetwork Policyをサポートしました。ここで興味深いのが、Network Policyの実装にeBPFを使用していることです。今回は環境を構築して動作を確認しつつ、コントローラとeBPFの実装を見てみます。https://aws.amazon.com/jp/blogs/news/amazon-vpc-cni-now-supports-kubernetes-network-policies/ 環境構築と動作確認環境構築のためにAWSのblogに書かれているyamlファイルとeksctlでクラスタを作りました。c...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[はてなブログの記事をGitHubに自動でPushする方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/23/194702</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/23/194702</guid>
            <pubDate>Sat, 23 Mar 2024 10:47:02 GMT</pubDate>
            <content:encoded><![CDATA[ツールに感謝。コミュニティに感謝。github.comxではてなブログで更新する時にDiffが見れるととても助かるのだけど有料版だと可能とかありますか？みたいなこと聞いてたらwhywaita さんが教えてくれた!!!blogsyncどうでしょう https://t.co/Duh31GJGrV— why/橘和板 (@whywaita) 2024年3月23日   この記事では、blogsyncを用いてはてなブログの記事をGitHubに自動的に同期する方法について説明します。GitHub Actionsを使用して、はてなブログの記事を定期的にプルし、GitHubリポジトリに反映させることができます。当初はブログを更新する際に、記事の変更点（Diff）を確認できるようにしたいと考えました。しかし、NeoVimを使用してブログを書いているわけではないので、単に日付単位のDiffを取得できれば十分だと思ったため、この構成にしました準備1. はてなブログのAPIキーを取得はてなブログの設定ページ（https://blog.hatena.ne.jp/-/config）にアクセスし、「詳細設定」タブの「APIキー」セクションでAPIキーを取得します。2. GitHub Actionsのワークフローを設定.github/workflows/hatena-blog-pull.yamlに以下の内容を配置します。name: Blogsync Pullon:  schedule:    - cron: '0 0 * * *'jobs:  blogsync_pull:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v2      - name: Set up Blogsync        uses: x-motemen/blogsync@v0        with:          args: --version      - name: Create blogsync.yaml        run: |          cat << EOF > blogsync.yaml          your_hatena_blog_id.hatenablog.com:            username: your_hatena_blog_id            password: ${{ secrets.HATENA_API_KEY }}          default:            local_root: .          EOF        shell: bash      - name: Pull articles from Hatena Blog        run: |          blogsync pull --no-drafts      - name: Commit changes        run: |          git config --local user.email "action@github.com"          git config --local user.name "GitHub Action"          git add .          git reset -- blogsync.yaml          git commit -m "Pull articles from Hatena Blog" || echo "No changes to commit"      - name: Push changes        uses: ad-m/github-push-action@v0.6.0        with:          github_token: ${{ secrets.GITHUB_TOKEN }}          branch: mainこのワークフローは、毎日0時（UTC）に実行されるようにスケジュールされています。3. ワークフローの権限を設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/actions）にアクセスし、「Workflow permissions」セクションで「Read and write permissions」を選択します。これにより、ワークフローがリポジトリに変更を書き込むことができるようになります。4. はてなブログのAPIキーを設定GitHub リポジトリの設定ページ（https://github.com/ユーザー名/リポジトリ名/settings/secrets/actions）にアクセスし、「Repository secrets」セクションで「New repository secret」をクリックします。「Name」にHATENA_API_KEYと入力し、「Value」に手順1で取得したはてなブログのAPIキーを入力します。カスタマイズblogsync.yamlファイルの設定を必要に応じて書き換えてください。以下は設定例です。your_hatena_blog_id.hatenablog.com:  username: your_hatena_blog_id  password: ${{ secrets.HATENA_API_KEY }}default:  local_root: .your_hatena_blog_idの部分を実際のはてなブログIDに置き換えてください。また、このファイルは秘密にしなければいけないので基本的には.gitignoreに入れておいてください。blogsync.yaml使い方.github/workflows/hatena-blog-pull.yamlファイルをリポジトリに追加します。ワークフローは毎日0時（UTC）に自動的に実行されます。はてなブログの記事がGitHubリポジトリにプルされ、変更がコミットされます。以上で、はてなブログの記事をGitHubで自動的に管理できるようになります。ワークフローを設定したら、あとは記事を書くだけです。記事の変更が毎日GitHubリポジトリに自動的に反映されます。参考URLGitHub Actions でのシークレットの使用push-to-hatenablogを使い，はてなブログへの投稿記事をGitHubで管理したら最高だった！はてなブログ作成から投稿までを自動化したGitHub Actionsのワークフロー]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ビットコイン・ブロックチェーン入門]]></title>
            <link>https://speakerdeck.com/shukob/hitutokoinhurotukutienru-men</link>
            <guid>https://speakerdeck.com/shukob/hitutokoinhurotukutienru-men</guid>
            <pubDate>Fri, 22 Mar 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[初学者の方向けにビットコイン・ブロックチェーン技術の全体像をお話ししました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nwiizoはなぜSpeaker Deckに上げた資料をブログにするのか？]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/22/122847</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/22/122847</guid>
            <pubDate>Fri, 22 Mar 2024 03:28:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめに私(nwiizo)は、ソフトウェアエンジニアとして日々の開発で得た知見やノウハウを、勉強会などで作成したプレゼンテーション資料としてSpeaker Deckに公開しています。Speaker Deckは、スライド共有サービスの一つで、スライドを簡単に公開・共有できる素晴らしいプラットフォームです。しかし、Speaker Deckに資料を公開するだけでは、いくつかの課題があります。スライドは情報を凝縮して伝えるために作られているため、詳細な説明や補足情報が不足しがちです。また、スライドだけでは、多くの人に情報が届きにくいという問題もあります。これらの課題を解決するために、私は Speaker Deck に上げた資料の内容を、改めてブログ記事として書くことにしています。本記事では、Speaker Deckに上げた資料をブログ記事化する意義について、詳しく解説していきます。詳細な説明と補足情報の追加スライドは、限られた紙面に要点を簡潔にまとめる必要があるため、情報を凝縮して伝えることに重点が置かれています。しかし、これだけでは聴衆の理解が表面的なものにとどまってしまう可能性があります。一方、ブログ記事では、スライドの内容を詳細に説明することができます。例えば、スライドではコードのスニペットを示すだけで終わってしまうことがありますが、ブログ記事ではそのコードの解説を丁寧に行うことができます。また、スライドでは伝えきれなかった背景情報や、補足説明を加えることで、より深い理解を促すことができるでしょう。さらに、スライドで紹介した技術や手法が、他の分野とどのように関連しているかを説明することもできます。これにより、読者は新たな観点からの問題解決のヒントを得ることができるかもしれません。Speaker Deck のスライドをブログ記事化することで、内容をより詳細に、より多面的に説明することができるのです。これは、情報を正確に伝え、読者の理解を深めるために非常に重要なことだと言えるでしょう。アウトプットによる技術力の向上ソフトウェアエンジニアにとって、新しい技術を学ぶことは重要ですが、学んだことをアウトプットすることも同様に重要です。登壇もそうですがブログ記事を書くためには、自分の知識を整理し、体系的に説明する必要があります。この過程で、自分の理解が深まり、技術力の向上につながります。ブログ記事を書く際には、自分が当たり前だと思っていたことを改めて見直すことになります。その際、自分の理解が不十分だったところや、説明が難しい部分に気づくことがあるでしょう。これは、さらなる学習のモチベーションにつながります。また、ブログ記事を公開することで、読者からのフィードバックを受けることができます。読者の質問や指摘は、自分では気づかなかった視点を提供してくれるかもしれません。このようなフィードバックから学ぶことで、さらなる技術力の向上が期待できます。ここで注目すべきは、登壇資料とブログ記事の違いです。登壇資料は、聴衆の反応を見ながら、その場で説明を調整することができます。また、質問に答えることで、理解が不十分な部分を補うこともできます。一方、ブログ記事は、書いた内容がそのまま読者に伝わります。誤りや不十分な説明があれば、それがダイレクトに読者に伝わってしまうのです。つまり、ブログ記事を書くことは、自分の知識や理解をより厳密に見直す機会になります。誤魔化しが効かない分、自分の理解の甘さが露呈するリスクがあるのです。しかし、だからこそ、ブログ記事を書くことは、技術力向上により大きな効果をもたらすと言えるでしょう。自分の知識のギャップに気づき、それを埋めていく過程こそが、真の成長につながるのです。Speaker Deckの資料をブログ記事にすることは、自己の知識と真摯に向き合う機会を提供してくれます。これは、技術力向上のための素晴らしい機会だと言えるでしょう。継続的な学習習慣の確立技術の進歩が速いソフトウェア開発の世界では、常に新しいことを学び続ける必要があります。しかし、日々の業務に追われていると、学習の時間を確保することが難しく感じることもあるでしょう。そんな中で、Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための良い方法だと言えます。ブログ記事を書くためには、Speaker Deckの資料で扱ったトピックについて、さらに深く調査・研究する必要があります。この過程自体が、学習のプロセスの一部となります。また、ブログ記事を書くことを習慣化することで、学習のための時間を確保することが自然とできるようになるでしょう。さらに、自分の学習の成果をブログ記事としてアウトプットすることで、学習へのモチベーションを維持することもできます。自分の成長を可視化することは、さらなる学習への原動力になるはずです。加えて、ブログが増えて充実してくると、ブログを書くこと自体が楽しくなってくるものです。自分の知識や経験が、記事という形で蓄積されていくことに喜びを感じるようになります。また、読者からのフィードバックや反響が、さらなるブログ記事を書くモチベーションにつながります。こうして、Speaker Deckの資料をブログ記事化することと学習が、正のフィードバックループを形成するのです。学習した内容をブログ記事にすることで、学習が促進され、ブログ記事が充実します。充実したブログは、さらにブログを書く意欲を高めます。この好循環が、継続的な学習習慣を確立し、維持することにつながるのです。Speaker Deckの資料をブログ記事化することは、継続的な学習習慣を確立するための素晴らしい方法なのです。技術の進歩に遅れないためにも、この習慣を身につけることをおすすめします。そして、この習慣が、エンジニアとしての成長を加速させる良いサイクルを生み出すことを期待しています。エンジニアとしての認知度向上とアイデンティティの確立ソフトウェアエンジニアにとって、自分の専門性や技術力を示すことは、キャリアを積み重ねる上で非常に重要です。Speaker Deckに資料を公開することは、自分の知見を共有する良い方法ですが、それだけでは限界があります。一方、ブログ記事を通じて、自分の知見やスキルを広くアピールすることができます。質の高い技術情報を継続的に発信することで、徐々に読者がついてくるでしょう。これは、エンジニアとしての認知度の向上につながります。認知度が高まれば、仕事の依頼や、登壇の機会なども増えるかもしれません。これは、キャリアアップのチャンスにもなるでしょう。また、企業のエンジニアとして働いている場合は、社外での認知度の向上が、社内での評価にもつながる可能性があります。さらに、ブログ記事を書くことは、エンジニアとしてのアイデンティティの確立にも役立ちます。自分の考えや経験を言葉にすることで、エンジニアとしての自分の立ち位置が明確になります。これは、自分のキャリアの方向性を考える上でも重要なことだと言えるでしょう。Speaker Deckの資料をブログ記事化して発信することは、エンジニアとしてのキャリア形成において非常に有益なのです。認知度の向上とアイデンティティの確立は、長期的な視点で見たときに、大きな意味を持つはずです。登壇への動機づけエンジニアにとって、カンファレンスや勉強会での登壇は、自分の知見を共有し、人脈を広げるための素晴らしい機会です。しかし、登壇することへの不安や、ネタが思いつかないといった理由で、なかなか一歩を踏み出せないエンジニアも多いのではないでしょうか。Speaker Deckの資料をブログ記事化することは、登壇への良い動機づけになります。すでにSpeaker Deckで発表した内容をベースにブログ記事を書くことで、徐々に自信がつくでしょう。また、ブログ記事への反響を見ることで、自分の知見に対する需要や、興味を持ってくれる人の存在を実感することができます。これは、登壇へのモチベーションにつながるはずです。また、ブログ記事は、登壇の良い練習の場にもなります。ブログ記事を書く際には、自分の考えを明確に言葉にする必要があります。これは、登壇の際にも求められるスキルです。ブログ記事を書くことで、プレゼンテーションスキルの向上も期待できるでしょう。さらに、ブログで築いた信頼関係が、登壇の機会につながることもあります。ブログを読んだ人から、登壇の依頼を受けるケースも珍しくありません。登壇は、エンジニアとしてのさらなる成長と、人脈の拡大に役立つはずです。Speaker Deckの資料をブログ記事化することは、その第一歩を踏み出すための素晴らしい動機づけになるのです。技術情報の発信と共有ソフトウェアエンジニアにとって、自分の知見やノウハウを共有することは重要な責務の一つです。新しい技術や手法を学んだら、それを他のエンジニアにも伝えることで、エンジニアコミュニティ全体の知識レベルの向上に貢献することができます。Speaker Deckに公開した資料をブログ記事として再構成することで、技術情報をより詳細かつ体系的に発信することができます。スライドだけでは伝えきれなかった詳細な説明や、実際のコード例などを交えることで、より深い理解を促すことができるでしょう。さらに、ブログ記事にはコメント欄を設けることができます。読者からの質問や意見を受け付けることで、インタラクティブなコミュニケーションが生まれます。これは、さらなる知識の共有や、新たな発見につながる可能性を秘めています。ソフトウェアエンジニアが持つ知識は、利用するか共有されてこそ価値があります。Speaker Deckの資料をブログ記事化し、積極的に情報を発信することは、エンジニアコミュニティ全体の発展に寄与する素晴らしい取り組みだと言えるでしょう。ブログの方があとから見返しやすいSpeaker Deckの資料を読むと、その時は内容を理解した気になれます。特に、登壇を聞いている時は、登壇者の説明を聞きながら資料を見ることができるので、理解が深まった感覚を得られるでしょう。しかし、時間が経つと、資料の内容を忘れてしまうことが多いのではないでしょうか。資料だけでは、詳細な説明が不足していることが多いため、あとから見返しても、内容を思い出すことが難しいのです。一方、ブログ記事は、詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。また、ブログ記事は検索しやすいというメリットもあります。特定の話題や技術について調べたい時に、関連するブログ記事を探すことができます。これは、自分が過去に学んだ内容を振り返る時にも役立ちます。さらに、ブログという文字のフォーマットを使うことで、登壇に比べて主張そのものに注意を向けさせることができます。人は身振り、声質、表情、顔といった外見や肩書に惑わされて主張を歪めて解釈してしまうことがありますが、ブログではそういった先入観をなるべく排除し、あくまで中身に集中させることができるのです。Speaker Deckの資料をブログ記事化することは、知識を長期的に活用するために非常に有効な方法だと言えるでしょう。おわりにSpeaker Deckに上げた資料をブログ記事として再構成することには、多くの意義があります。詳細な説明と補足情報の追加、アウトプットによる技術力の向上、継続的な学習習慣の確立、エンジニアとしての認知度向上とアイデンティティの確立、登壇への動機づけ、技術情報の発信と共有など、個人の成長とエンジニアコミュニティ全体の発展に寄与する様々なメリットがあるのです。また、Speaker Deckの資料は初見では理解した気になれますが、時間が経つと内容を忘れてしまいがちです。一方、ブログ記事は詳細な説明と補足情報が含まれているため、あとから見返した時にも内容を理解しやすいという利点があります。つまり、Speaker Deckの資料だけでは一時的な理解にとどまってしまいますが、ブログ記事であれば、長期的な理解と知識の定着に役立つのです。Speaker Deckは、スライドを公開・共有するための素晴らしいプラットフォームですが、それだけでは情報共有の手段としては限界があります。一方、ブログは、より詳細で探索しやすい情報を提供することができます。Speaker Deckとブログを組み合わせることで、より効果的な技術情報の発信が可能になるのです。皆さんも、自分の知見を共有するためにこの方法を活用してみてはいかがでしょうか？参考資料木村政彦はなぜ力道山を殺さなかったのか作者:増田俊也新潮社Amazon人生は、運よりも実力よりも「勘違いさせる力」で決まっている作者:ふろむだダイヤモンド社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[新人SREが0から始めるGKE上でのArgoCDによるWordPressデプロイ]]></title>
            <link>https://sreake.com/blog/deploy-wordpress-with-argocd-on-gke/</link>
            <guid>https://sreake.com/blog/deploy-wordpress-with-argocd-on-gke/</guid>
            <pubDate>Thu, 21 Mar 2024 23:34:40 GMT</pubDate>
            <content:encoded><![CDATA[はじめに はじめまして。Sreake事業部インターン生の高島です。2023年10月から長期インターン生としてKubernetes関連技術の習得とSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解 […]The post 新人SREが0から始めるGKE上でのArgoCDによるWordPressデプロイ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[データエンジニアリングの要諦の後ろ髪を掴む - Fundamentals of Data Engineeringを読んで]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/20/164434</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/20/164434</guid>
            <pubDate>Wed, 20 Mar 2024 07:44:34 GMT</pubDate>
            <content:encoded><![CDATA[最強なデータ分析基盤は何か⁉︎多種多様なデータ分析基盤が、制約のない環境で競合した時… ビジネス用途に限らず、あらゆるシナリオで使用可能な「データ分析」で比較した時、最強なデータ分析基盤は何か⁉︎ 今現在最強のデータ分析基盤は決まっていないデータ分析基盤まとめ（随時更新） などもあり大変参考にさせていただきました。ありがとうございます。はじめにデータエンジニアリングは、データの収集、処理、保存、そして提供を行う技術やプロセスを扱う複雑な分野です。この分野の全容を系統的に把握することは決して容易なことではありません。このような状況の中で、『Fundamentals of Data Engineering』という書籍に出会いました。この本は、著者たちの豊富な実務経験に基づいて書かれており、データエンジニアリングの基本概念とそのライフサイクルに焦点を当てています。さらに、これらの概念を現実の問題解決に応用する方法についても詳しく説明しています。全624ページに及ぶこの書籍は、その分厚さが示す通り、読破するには相当な時間と努力が必要ですが、その価値は十分にあると確信しています。learning.oreilly.com本書の特徴は、特定のツールや技術ではなく、データエンジニアリングの根幹をなす原則に焦点を当てている点です。著者らは、データ生成、ストレージ、取り込み、変換、提供といったライフサイクルの各段階を丁寧に解説し、それらを支える重要な概念を、具体的な技術選択やアーキテクチャ設計と関連付けて説明しています。また、クラウド技術を効果的に組み合わせて、下流のデータ消費者のニーズに応えるための方法論も提示しています。本書は、データエンジニアリングの理論と実践を見事に融合させ、この分野の要諦を掴むための羅針盤となります。著者らの豊富な知見と経験が随所に活かされ、ベストプラクティスのフレームワークを用いた問題の評価方法、市場の誇大広告を見抜く視点、堅牢なアーキテクチャの設計・構築手法などが解説されています。これらの知識は、データエンジニアリングの要諦を理解し、実践に活かすために不可欠な要素です。また、本書は、データエンジニアリングを取り巻く環境の変化についても言及しています。特に、クラウドファーストのアプローチを取ることで、オンプレミスからクラウドへのシフトを見据えた議論を展開しています。加えて、セキュリティとプライバシーの重要性についても強調しており、データエンジニアリングの現在と未来を見据えた内容となっています。本書を通じて、データエンジニアリングの全体像を俯瞰し、実践的な知識を得ることができました。データエンジニアリングの原則を自らの役割に取り入れ、クラウド技術を駆使して問題解決に取り組む方法を学べた点は、特に有益でした。本書は、データエンジニアリングの要諦を掴むための一助となる、貴重な一冊であると言えます。本稿はそんな書籍の読書感想文である。あくまで、私の感想なので指摘はそれぞれのSNSに書き散らしてください。『Fundamentals of Data Engineering』の構成本書は4つのパートで構成されています。パートIでは、第1章でデータエンジニアリングを定義し、第2章でデータエンジニアリングのライフサイクルを示します。第3章ではよいアーキテクチャについて議論し、第4章では適切な技術を選択するためのフレームワークを紹介します。パートIIは、第2章を基にデータエンジニアリングのライフサイクルを深く掘り下げています。データ生成、ストレージ、取り込み、変換、提供の各段階が独立した章で扱われます。パートIIは本書の中核をなす部分であり、他の章はここで扱われる核心的なアイデアをサポートするために存在しています。パートIIIでは、追加のトピックスとして、第10章でセキュリティとプライバシーについて議論しています。これらは常にデータエンジニアリングにおいて重要な部分でしたが、営利目的のハッキングや国家支援のサイバー攻撃の増加に伴い、さらに重要性が増しています。また、GDPRやCCPAなどの規制の出現により、個人データの不注意な取り扱いは重大な法的影響を及ぼす可能性があります。第11章では、データエンジニアリングの近未来について、著者らの大胆な予測を概説しています。付録では、データエンジニアリングの日々の実践に非常に関連性が高いものの、本文の主要部分には収まらなかった技術的トピックスを取り上げています。具体的には、シリアル化と圧縮（付録A）、クラウドネットワーキング（付録B）です。はじめに『Fundamentals of Data Engineering』の構成Part I. Foundation and Building BlocksChapter 1. Data Engineering DescribedChapter 2. The Data Engineering LifecycleChapter 3. Designing Good Data ArchitectureChapter 4. Choosing Technologies Across the Data Engineering LifecyclePart II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source SystemsChapter 6. StorageChapter 7. IngestionChapter 8. Queries, Modeling, and TransformationChapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETLPart III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and PrivacyChapter 11. The Future of Data Engineeringさいごに(追記)Part I. Foundation and Building BlocksChapter 1. Data Engineering Describedデータエンジニアリングを「raw dataを取り込み、高品質で一貫性のある情報を生成するシステムとプロセスの開発、実装、維持」と定義しています。データエンジニアは、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの交差点に位置し、データのソースシステムから始まり、分析や機械学習などのユースケースにデータを提供するまでのライフサイクル全体を管理します。Figure 1-1. The data engineering lifecycle よりまた、データエンジニアリングの歴史的な発展についても触れられており、データウェアハウジングから始まり、ビッグデータ時代を経て、現在はデータのライフサイクル全体を管理するフェーズに入っていることが分かります。データエンジニアは、データサイエンティストの上流に位置し、分析やモデリングに必要な基盤を提供する重要な役割を担っています。さらに、本章では、企業のデータ成熟度に応じたデータエンジニアの役割の変化や、他の技術的役割（ソフトウェアエンジニア、データアーキテクト、DevOpsエンジニアなど）およびビジネスリーダーとの関わりについても説明されています。データエンジニアは、技術的スキルだけでなく、コミュニケーション能力やビジネス理解も求められる、組織内の重要な接点となる存在であることが強調されています。本章を通じて、データエンジニアリングが急速に発展し、組織内で不可欠な役割を担うようになってきたことを実感しました。データドリブンな意思決定が求められる現代において、データエンジニアは、データの価値を最大限に引き出すための鍵を握っています。今後もデータエンジニアリングの動向に注目し、自身のスキルを磨いていく大切さを学びました。Chapter 2. The Data Engineering Lifecycleデータエンジニアリングのライフサイクルについて詳細に解説されています。データエンジニアリングのライフサイクルとは、raw dataを有用な最終製品に変換するための一連のプロセスを指します。本章では、データエンジニアリングのライフサイクルを5つのステージ（生成、ストレージ、取り込み、変換、提供）に分類し、各ステージの役割と考慮事項を丁寧に説明しています。また、ライフサイクル全体を支える重要な要素として、セキュリティ、データ管理、DataOps、データアーキテクチャ、オーケストレーション、ソフトウェアエンジニアリングの6つの「潮流」を紹介しています。特に印象的だったのは、データ管理の重要性についての議論です。著者らは、データガバナンス、データモデリング、データの系統、データ統合、ライフサイクル管理など、企業のデータ管理における様々なベストプラクティスを紹介し、これらがデータエンジニアリングにどのように関連するかを明確に示しています。データエンジニアは、単なる技術者ではなく、組織全体のデータ活用を戦略的に促進する役割を担っているのだと実感しました。また、DataOpsの概念も興味深かったです。DataOpsは、アジャイル開発、DevOps、統計的プロセス管理の手法をデータに適用したものであり、自動化、モニタリング、インシデント対応の3つの要素から成ります。データエンジニアリングにおいてDataOpsを実践することで、データ製品の迅速な開発と高品質な運用が可能になるとのことです。本章を通じて、データエンジニアリングが、単なるデータ処理の技術にとどまらず、組織のデータ活用を支える総合的な取り組みであることを学びました。データエンジニアは、ライフサイクルの各ステージにおける技術的な選択と、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項のバランスを取ることが求められます。本書で提示されたデータエンジニアリングのライフサイクルのフレームワークは、この複雑な領域を体系的に理解するための強力なツールになると感じました。Chapter 3. Designing Good Data Architectureデータエンジニアリングにおける良いアーキテクチャ設計について詳細に解説されています。本章では、まず、データアーキテクチャを「企業のデータニーズの進化を支えるシステムの設計であり、柔軟で可逆的な意思決定により、トレードオフを慎重に評価して達成されるもの」と定義しています。そして、良いデータアーキテクチャの原則として、共通コンポーネントの賢明な選択、障害への対策、スケーラビリティの確保、リーダーシップ、継続的なアーキテクト活動、疎結合システムの構築、可逆的な意思決定、セキュリティの優先、FinOpsの採用の9つを挙げています。また、本章では、分散システム、スケーラビリティ、障害対策、密結合と疎結合、シングルテナントとマルチテナント、イベント駆動アーキテクチャ、ブラウンフィールドとグリーンフィールドプロジェクトなど、データアーキテクチャ設計に関連する主要な概念について説明しています。さらに、データウェアハウス、データレイク、モダンデータスタック、ラムダアーキテクチャ、カッパアーキテクチャ、IoTアーキテクチャ、データメッシュなど、具体的なデータアーキテクチャの例や種類についても紹介されています。これらの例を通じて、データエンジニアがビジネスの要件に合わせて適切なアーキテクチャを選択し、設計するための知見が提供されています。本章を読んで、データアーキテクチャ設計の重要性と複雑さを改めて認識しました。データエンジニアは、技術的な知識だけでなく、ビジネスの文脈を理解し、ステークホルダーとのコミュニケーションを通じて要件を把握する必要があります。そして、セキュリティ、データ管理、アーキテクチャなどの戦略的な考慮事項とのバランスを取りながら、柔軟で進化可能なアーキテクチャを設計していかなければなりません。この辺はソフトウェアアーキテクチャの基礎を思い出した。ソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal FordオライリージャパンAmazon本書で提示された良いデータアーキテクチャの原則や、様々なアーキテクチャパターンの知識は、この難しい課題に取り組むための強力な助けになると感じました。データエンジニアとして、これらの知見を活かし、組織のデータニーズに合ったアーキテクチャを設計していきたいと思います。詳細に知りたい場合には『データ指向アプリケーションデザイン』あたりを読むと良さそうデータ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin KleppmannオライリージャパンAmazonChapter 4. Choosing Technologies Across the Data Engineering Lifecycleデータエンジニアリングのライフサイクル全体にわたる適切な技術選択のための考え方と基準について詳細に説明されています。この章では、アーキテクチャが戦略的な設計であることに対し、ツールはその実現を目指す戦術的な選択肢であるという点が強調されています。 技術選択時に考慮すべき要素として、チームの規模と能力、市場投入までのスピード、相互運用性、コスト最適化とビジネス価値、技術トレンドの変化、デプロイ環境、ビルドかバイの選択、モノリシックかモジュール化か、サーバーレスかサーバーか、性能最適化などが挙げられています。あまりにも「ソフトウェアアーキテクチャの基礎」すぎてデータ基盤もソフトウェアアーキテクチャなのだと分からせをくらいました。加えて、クラウドのコスト効率とクラウドネイティブアーキテクチャのコスト最適化の重要性が説明されており、オンプレミス、クラウド、ハイブリッドクラウド、マルチクラウドなどの配置オプションとその特性についても詳述されています。オープンソースソフトウェア（コミュニティ型と商用型）とプロプライエタリーソフトウェアの選択、モノリシックとマイクロサービスアーキテクチャの比較、サーバーレスと従来型サーバーの検討など、具体的な技術選択のシナリオにおける検討が提示されています。技術選択の複雑さとその重要性を理解する上で、この章は大いに役立ちます。データの世界は常に進化しているため、最適な選択肢は状況に応じて変わります。適切なトレードオフを評価し、柔軟かつ可逆的な意思決定を行うことが重要です。この辺はソフトウェアアーキテクチャメトリクスみがあって良かった。ソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,João Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazonセキュリティ、データ管理、DataOps、オーケストレーションなどの現代のトレンドが技術選択に与える影響も大きいことが認識されています。これらを総合的に考慮し、ビジネス価値を最大化する技術スタックを構築することが、SREとしての責任であると捉えられます。本章で提供される原則とガイドラインは、DXの推進と共に増大する複雑な意思決定の指針となります。組織のニーズに沿いながら、これらの洞察を活用していくことが推奨されています。Part II. The Data Engineering Lifecycle in DepthChapter 5. Data Generation in Source Systems本章では、データエンジニアリングのライフサイクルの初期段階であるソースシステムにおけるデータの生成プロセスについての詳細な解説が展開されています。 ここで、データエンジニアがソースシステムからのデータの特性と生成プロセスを理解することの重要性が強調されており、これは非常に重要な点です。特に印象深かったのは、ソースシステムのオーナーやステークホルダーとの関係構築の必要性です。データエンジニアリングはチーム単独ではなく、関係者全員の協力が必須であり、上流システムで問題が生じた際に迅速な対応が可能な信頼関係の構築が不可欠です。データ品質の維持に関する言及もあり、これは特に重要です。ソースシステムの設計や運用に直接影響を与えることは困難かもしれませんが、期待されるデータ品質について上流チームと合意を形成し、定期的な品質チェックを行うことが必要です。これは、SREとしての役割とも重なる側面があります。セキュリティ、可用性、信頼性を考慮したソースシステムのアーキテクチャへの理解も、障害発生時に影響を最小限に抑え、迅速に復旧する設計を実現する上で重要です。さらに、データ管理、DataOps、オーケストレーションといったデータエンジニアリングの新しい動向とソースシステムとの関連性についても触れられており、これらの原則を上流工程に適用し、エンド・ツー・エンドでの高品質なデータパイプライン構築が目標です。リバースETLやイベントストリーミングプラットフォームの活用による、データエンジニアとソースシステムとの連携強化の可能性についての言及もあり、これはアプリケーション開発チームとのWin-Winの関係構築、及びユーザー向けデータ製品の共創へと繋がるでしょう。本章を通じて、SREとデータエンジニアの役割が密接に関連しており、両者の協力が不可欠であることが明確になりました。 上流から下流への一貫した高品質なデータフローを実現するためには、両分野の専門知識を統合し、継続的な改善を図る必要があります。得られた知見を活用し、開発チームと協力しながら、より堅牢なデータインフラを構築していくことが目指されています。Chapter 6. Storageデータエンジニアリングのライフサイクルにおけるストレージの重要性と、その設計・運用に関する考慮事項について詳しく解説されています。本章では、まず、ハードディスク、SSD、システムメモリなど、ストレージシステムを構成する基本的な要素について説明しています。データエンジニアは、これらの物理的ストレージコンポーネントの特性を理解することで、パフォーマンス、耐久性、コストのトレードオフを適切に評価できるようになります。次に、ファイルストレージ、ブロックストレージ、オブジェクトストレージ、ストリーミングストレージなど、主要なストレージシステムの種類と特徴を紹介しています。特に、クラウドにおけるオブジェクトストレージの重要性が強調されており、その柔軟性とスケーラビリティが、データレイクやクラウドデータウェアハウスの基盤となっていることが分かります。さらに、データウェアハウス、データレイク、データレイクハウス、データプラットフォームなど、データエンジニアリングで用いられる主要なストレージの抽象化についても言及されています。これらの抽象化は、ストレージシステムの上に構築され、データの取り込み、変換、提供といったライフサイクルの各段階をサポートします。本章では、ストレージに関する重要なトレンドや考え方についても触れられています。例えば、コンピュートとストレージの分離、ゼロコピークローニング、データカタログ、データ共有などは、現代のデータアーキテクチャにおいて欠かせない要素だと指摘されています。また、データのライフサイクルと保持期間の管理、シングルテナントとマルチテナントのストレージ設計の違いなど、運用面での考慮事項についても説明されています。データエンジニアは、これらの要素を総合的に判断し、組織のニーズに合ったストレージ戦略を立てる必要があります。本章を通じて、ストレージがデータエンジニアリングのあらゆる段階で重要な役割を果たしていることを再認識しました。生のデータを価値あるインサイトに変えるためには、適切なストレージの選択と設計が不可欠です。また、セキュリティ、データ管理、DataOps、オーケストレーションなどの「潮流」を常に意識しながら、ストレージシステムを進化させていく必要があります。本書で得られた知見を活かし、自社のデータアーキテクチャにおけるストレージの最適化に取り組んでいきたいと思います。特に、コストとパフォーマンスのバランスを取りつつ、将来の拡張性も考慮した設計を心がけたいと考えています。ストレージの話は『パタ&へネ』などを読むとしっかりと分かるので読み直す機会があれば読み返したい。しかし、人生の時間は有限なので悲しい。コンピュータの構成と設計　MIPS Edition　第6版　上作者:David Patterson,John Hennessy日経BPAmazonコンピュータの構成と設計 MIPS Editoin 第6版 下作者:David Patterson,John Hennessy日経BPAmazonChapter 7. Ingestionデータエンジニアリングにおけるデータ取り込みの重要性と複雑さを再認識しました。本章では、データ取り込みを「データを一つの場所から別の場所へ移動するプロセス」と定義しています。その主要な考慮事項として、ユースケース、再利用性、データ量、データフォーマット、データ品質などが挙げられています。さらに、バッチ処理とストリーミング処理の違い、同期型と非同期型のデータ取り込み、シリアル化とデシリアル化、スループットとスケーラビリティといった、設計上の重要な概念について詳しく説明されています。また、Otelなどのオブザーバビリティ情報の取得については言及されていないのですが、この章を通じて現代の監視基盤が実際にはデータエンジニアリングに大きく依存してるものなのだと思いはじめました。特に印象的だったのは、データ取り込みの方法の多様性です。データベースへの直接接続、CDC、API、メッセージキュー、ファイルエクスポートなど、様々な手段があり、それぞれにメリットとデメリットがあります。状況に応じて適切な方法を選択し、組み合わせることが求められます。また、データ取り込みにおけるデータ品質の確保の重要性も強調されていました。スキーマの変更や遅延データへの対応、エラーハンドリングなど、様々な課題に直面します。上流のシステムとの緊密なコミュニケーションと、ロバストなモニタリングの仕組みが不可欠だと感じました。本章では、データ取り込みに関わる様々なステークホルダーとの協力についても言及されています。特にソフトウェアエンジニアとのコラボレーションは、データ品質の向上と、よりリアルタイムなデータ活用につながる可能性があります。組織のサイロを超えて、Win-Winの関係を築いていくことが重要だと分かりました。さらに、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、データ取り込みにどのように影響するかについても議論されていました。これらの原則を常に意識しながら、エンドツーエンドのデータパイプラインを設計していく必要があります。データ取り込みは、地味な作業に見えるかもしれません。しかし、それは分析やMLなどのエキサイティングなアプリケーションを支える重要な基盤です。本章で得られた知見を活かし、より信頼性が高く、価値あるデータを提供できるよう、日々精進していきたいと思います。Chapter 8. Queries, Modeling, and Transformationデータエンジニアリングにおけるクエリ、モデリング、変換の重要性と技術的な考慮事項について理解を深めることができました。本章では、まず、クエリの仕組みと最適化の手法について解説されています。クエリオプティマイザの役割や、結合戦略の最適化、説明プランの活用など、パフォーマンス向上のための具体的なアドバイスが提示されており、大変参考になりました。また、ストリーミングデータに対するクエリの特殊性についても言及されていました。次に、データモデリングの重要性と主要な手法が紹介されています。概念モデル、論理モデル、物理モデルの違いや、正規化、スター・スキーマ、Data Vaultなどのバッチデータのモデリング手法、ストリーミングデータのモデリングの考え方など、幅広いトピックがカバーされています。ビジネスロジックをデータモデルに反映させることの重要性が強調されていました。そして、変換の役割と主要なパターンについて解説されています。単純なクエリとは異なり、変換では結果を永続化し、ダウンストリームで利用できるようにすることが目的だと説明されています。バッチ処理とストリーミング処理それぞれの変換パターンや、更新パターン、データラングリングなどの具体的な手法が紹介されていました。また、マテリアライズドビュー、フェデレーションクエリ、データ仮想化など、クエリ結果を仮想的なテーブルとして提示する手法についても言及されていました。これらの手法は、複雑なデータパイプラインの一部として活用できる可能性があります。本章では、クエリ、モデリング、変換に関わる様々なステークホルダーとの協力についても議論されています。ビジネスロジックを理解し、上流のシステムへの影響を最小限に抑えつつ、下流のユーザーにとって価値のあるデータを提供することが求められます。また、セキュリティ、データ管理、DataOps、オーケストレーション、ソフトウェアエンジニアリングといった「潮流」が、この段階でも重要な役割を果たすことが指摘されていました。データ変換は、データパイプラインの中核をなす工程です。単に最新の技術を追求するのではなく、ステークホルダーにとっての価値を常に意識することが重要だと感じました。本章で得られた知見を活かし、ビジネスの目標達成に貢献できるデータ変換プロセスを設計していきたいと思います。Chapter 9. Serving Data for Analytics, Machine Learning, and Reverse ETL本章では、データエンジニアリングのライフサイクルの最終段階である、データの提供について解説されていた。データエンジニアが直面する主要な3つのユースケース - 分析、機械学習、リバースETLについて、どのようにデータを提供するかが述べられていた。データを提供する際の重要な考慮点として、エンドユーザーがデータを信頼できるようにすることが何より大切だと強調されていた。データへの信頼がないと、いくら高度なアーキテクチャやシステムを構築しても意味がない。信頼を得るためには、データの検証とオブザーバビリティのプロセスを活用し、ステークホルダーと協力してデータの有効性を確認する必要がある。また、ユースケースとユーザーを理解し、提供するデータプロダクトを明確にし、セルフサービスかどうかを検討し、データの定義やロジックを確立することが重要だと述べられている。データメッシュのコンセプトにも触れられ、データ提供の方法が大きく変化しつつあることがわかった。分析や機械学習のためのデータ提供方法としては、ファイル、データベース、クエリエンジン、データ共有などがあげられていた。セマンティック層やメトリクス層の活用も有効とのことだった。また、ノートブックを使ったデータサイエンスのワークフローについても解説があり参考になった。リバースETLは、処理されたデータをOLAPシステムからソースシステムにロードすることだが、フィードバックループを作り出すリスクがあるので注意が必要だと指摘されていた。本章を読んで、データ提供において信頼性とセキュリティが非常に重要であり、様々な方法や最新のトレンドを理解しておく必要性を感じた。生のデータを渡すのではなく、匿名化などの工夫も必要だ。データプロダクトを通じてビジネスに貢献するという視点を常に持ちながら、品質の高いデータを提供できるよう、日々研鑽していきたい。Part III. Security, Privacy, and the Future of Data EngineeringChapter 10. Security and Privacyセキュリティとプライバシーは、データエンジニアリングにおいて非常に重要な側面であり、後回しにしてはならないということが本章で強調されていました。データ漏洩や流出は、企業に壊滅的な結果をもたらす可能性があります。GDPR、FERPA、HIPAAなど、データプライバシーに関する法的要件が増えており、違反すると多額の罰金が科せられる可能性があります。データエンジニアは、このような法規制を理解し、遵守する必要があります。セキュリティの最大の弱点は人間であるため、データエンジニアは常に防御的な姿勢で行動し、認証情報の扱いには細心の注意を払い、倫理的な懸念があれば提起しなければなりません。セキュリティプロセスはシンプルで習慣的なものでなければならず、単なるコンプライアンスのためのセキュリティ・シアターであってはいけません。最小権限の原則を適用し、必要最小限のアクセス権のみを付与すべきです。きめ細かいアクセス制御を実装することが重要です。クラウドにおけるセキュリティは、プロバイダーとユーザーの共同責任であり、ユーザー側の設定ミスが原因で流出が起こることが多いのです。定期的なデータバックアップは、災害復旧やランサムウェア対策に欠かせません。リストアのテストも定期的に行うべきでしょう。技術面では、脆弱性を修正するためのシステムのパッチ適用と更新、保存中と通信中の両方でのデータの暗号化、アクセス・リソース・コストのログ記録・監視・アラート、ネットワークアクセスの厳重な制御、CPUなどの低レベルでのセキュリティ考慮などが重要な実践項目として挙げられていました。すべてのエンジニアが自分の領域で潜在的なセキュリティ問題を探し出すという能動的な姿勢が重要であり、軽減策を積極的に展開すべきだと述べられています。本章を通して、セキュリティとプライバシーは企業文化・プロセス・技術のすみずみまで浸透させる必要があり、関係者全員が常に警戒心を持ち、積極的な対策を講じることが機密データ資産を守るために不可欠だということを実感しました。法的にも評判的にも、その重要性は非常に高いのです。データエンジニアとして、**セキュリティとプライバシーを常に最優先事項と位置づけ、ベストプラクティスを実践していきます。Chapter 11. The Future of Data Engineering本章では、データエンジニアリングの将来について著者の考察が述べられていました。データエンジニアリングの分野は急速に変化しているため、本書の執筆は挑戦的な作業だったと思います。しかし、変化の中にも不変の本質を見出し、ライフサイクルという形で体系化したことは意義深いと感じました。著者は、データエンジニアリングのライフサイクルは今後も変わらず重要であり続けると予測しています。一方で、ツールの簡素化が進み、より高度な作業にフォーカスできるようになるでしょう。クラウドスケールの「データOS」の出現によって、相互運用性が向上することも期待されます。また、従来の「モダンデータスタック」を超えて、リアルタイムのデータ処理と機械学習を融合させた「ライブデータスタック」へと進化するとの展望も示されていました。ストリーミングパイプラインとリアルタイム分析データベースの発展によって、アプリケーションとデータ、機械学習の間のフィードバックループが短くなり、より洗練されたユーザー体験が実現するというビジョンは興味深いです。一方で意外だったのは、スプレッドシートの重要性への言及でした。確かに、現場ではExcelが分析ツールとして依然大きな役割を果たしています。クラウドのOLAPシステムとスプレッドシートの使い勝手を兼ね備えた新しいツールの登場にも注目したいと思います。全体を通して、技術トレンドは複雑な技術と文化の相互作用の中で生まれるものであり、予測は難しいというのが著者の率直な見解だと感じました。私たち一人一人がデータエンジニアリングの発展に関わっていく中で、ツールの採用と活用を通じて、ビジネス価値の創出という大きな目標を見失わないようにしたいと思います。本書で得た知見をもとに、コミュニティに参加し、専門家と対話しながら、自分なりの探求を続けていきたいと思います。データエンジニアリングは奥深く、やりがいのある分野だと改めて感じました。さいごにこの本を通じて、私はデータエンジニアリングの幅広さと深さを理解する機会を得ました。『Fundamentals of Data Engineering』は、データエンジニアリングの基礎から応用に至るまで、その様々な側面を包括的に解説しており、データエンジニアとしての技術や知識の向上に寄与する貴重なリソースです。データライフサイクルの各段階に対する詳細な説明は、実務で直面するさまざまな問題への理解を深めるのに非常に有用です。また、セキュリティとプライバシーの章では、技術の理解だけでなく、倫理的な視点から物事を考えることの重要性が強調されていることが特に印象的でした。データエンジニアは技術者であると同時に、データを取り扱う上での社会的責任を有する存在であり、この点を再確認させられます。データエンジニアリングの将来に関する展望を含めて、この書籍は、データエンジニアリングの現状理解と将来に向けた方向性を示す貴重な指南書です。技術の進歩は早く、今日学んだことが明日には旧式になる可能性がありますが、本書で得られる原則や考え方は、変わることのない有用な知識。データエンジニアリングの基盤となります。syu-m-5151.hatenablog.com最後に、この本を読むことで得られる最大の利点は、データエンジニアリングに対する深い理解と共に、学び続け、成長し続けることの重要性を再認識できることです。技術変遷に適応しつつ、データエンジニアリングの核心を見失わないよう努めることが、私たちには求められています。この旅は続きますが、『Fundamentals of Data Engineering』は、その道中で頼りになる羅針盤となるでしょう。日本語訳の出版が待ち遠しいですね。そして、付録「A. Serialization And Compression Technical Details」と「B. Cloud Networking」に関しては、ぜひ自身で読んでみていただきたいです。これらのセクションは、データエンジニアリングの深い理解に不可欠なテクニカルな洞察を提供しており、実務での適用に役立つ知見が満載です。Fundamentals of Data Engineering (English Edition)作者:Reis, Joe,Housley, MattO'Reilly MediaAmazon(追記)翻訳版のリリースが出ました。翻訳作業お疲れ様でした。データエンジニアリングの基礎 ―データプロジェクトで失敗しないために作者:Joe Reis,Matt Housleyオーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ECSのタグ付け認可とアカウント単位のオプトアウトの廃止]]></title>
            <link>https://blog.masasuzu.net/entry/2024/03/20/121151</link>
            <guid>https://blog.masasuzu.net/entry/2024/03/20/121151</guid>
            <pubDate>Wed, 20 Mar 2024 03:11:51 GMT</pubDate>
            <content:encoded><![CDATA[ECSのタグ付け認可とはアカウント単位のオプトアウトの廃止確認影響がある例対応まとめ関連リソースECSのタグ付け認可とはECS関連のリソース作成時にリソースタグを付けることができます。その際 ecs:tagResource の権限が必要となります。なお、リソースタグを設定しないECSリソース作成の際は権限不要です。この権限の有無のチェックをタグ付け認可と言います。具体的にECSリソースの作成のアクションは以下の通りです。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTaskタグ付け認可の仕組みは2023年4月18日に導入されました。しかしながら従来からECSリソースを作成する際にタグ付けしていたAWSアカウントに関しては影響があるため、アカウントレベルでタグ付け認可の機能を無効(オプトアウト)することができました。つまりアカウントレベルで無効にしていれば ecs:tagResource の権限がなくてもタグ付けをすることが可能でした。しかしながらアカウント単位のオプトアウト設定は2024年3月9日に廃止されます。アカウント単位のオプトアウトの廃止タグ付け認可におけるタイムラインは以下のとおりです2023年4月18日 タグ付け認可の導入とアカウント単位での有効化設定の導入2024年2月9日- 2月28日 新規アカウントおよび影響を受けないアカウントに関してデフォルトでタグ付け認可の有効化が行われる2024年2月29日 アカウント単位で有効にしている場合、無効に変更できなくなる2024年3月29日 すべてのアカウントでタグ付け認可が有効になり、アカウント単位での設定が不可能になる現時点(2024/03/20)であまり時間がありません。現在タグ付け認可に影響あるAWSアカウントに関しては、Personal Health Dashboadに以下のような通知が来ているはずです。▼ElasticContainerService security notification (クリックで展開)▼English follows Japanese | 英語のメッセージは日本語の後にございますお客様のアカウントにて過去 1 年以内に ecs:TagResource の許可無しに ECS リソースの作成時にタグを付けていることが判明したため、ご連絡差し上げます。Amazon ECS は、2023 年 4 月 18 日にリソース作成のタグ付け認証を導入しました [1]。新規および既存のお客様は、ECS Console または API の ECS アカウント設定ページを使用して、この新機能の使用をオプトインする必要があります。このセキュリティ制御により、ECS リソースの作成時にタグをつけることをユーザーに拒否または許可できます。2024 年 3 月 29 日以降もお客様の IAM プリンシパルが新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーを更新して ecs:TagResource アクションを明示的に許可することを強くお勧めします。2024 年 2 月 9 日以降、AWS コンソール の ECS アカウント設定ページにて tagResourceAuthorization アカウント設定を明示的に off に設定していないすべてのお客様のアカウントは、自動的にこの設定にオプトインされました。お客様の AWS アカウントは一時的に許可リストに載せているため、2024 年 3 月 29 日まではタグリソース認証の off の動作が継続されます。2024 年 3 月 8 日、現在オプトインしているアカウントが tagResourceAuthorization をオプトアウトする機能を削除し、タグをサポートするすべての ECS リソースの作成に際して ecs:TagResource IAM 権限の使用を強制するようにしました。最終的に 2024 年 3 月 29 日をもってお客様のアカウントを許可リストから削除し、tagResourceAuthorization を有効化します。呼び出し元のプリンシパルの IAM ポリシーに ecs:TagResource アクションを含めずにタグをつけて ECS リソースを作成しようとすると、「AccessDenied」メッセージが表示されます。この変更は CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, および RegisterTaskDefinition の API に影響を及ぼします。ecs:TagResource を使用しない拒否レスポンスの例以下は、ecs:CreateCluster アクションを付与している IAM ポリシーの一部です。ecs:TagResource アクションは含まれていません。tagResourceAuthorization アカウント設定がオンの場合、リクエスト例では以下の AccessDenied 例外が返されます。# IAM ポリシー“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# クラスター作成のリクエストaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# タグ付けの拒否されたレスポンスAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource action必要なアクション:IAM プリンシパルが 2024 年 3 月 29 日以降も新しく作成された ECS リソースに引き続きタグを適用できるように、IAM ポリシーに次のステートメントを追加することを強くお勧めします。すべての ECS リソースの作成時にタグ付けを許可以下の説明に従って ecs:TagResource アクションを追加すると、ECS リソースの作成中にタグ付けが可能になります [2]。“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]単一の ECS リソースタイプ (ECS クラスタ) の作成時にタグ付けを許可条件ステートメント ecs:CreateAction を使用すると、タグ付けを特定の ECS API に制限できます。以下の例では、ECS CreateCluster API でのみタグ付けへのアクセスを許可します。タグ付きの ECS RunTask API へのリクエストは、拒否判定になります [2]。“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]タイムライン:2024 年 2 月 9 日（完了）- タグ付け認証はデフォルトで on になっています。これには、ホワイトリストに登録されているアカウントは含まれません。tagResourceAuthorization アカウント設定の on/off を切り替えることも可能であり、ポリシーへの準拠をテストいただけます。2024 年 3 月 8 日 - タグ付け認証を on にすると、off にすることはできなくなります。この日まではアカウント設定を切り替えることができますので、その間に IAM ポリシーをテストすることをお勧めします。2024 年 3 月 29 日 - すべての AWS アカウントでタグ付け認証が有効になります。アカウントレベルの設定は使用されなくなり、AWS コンソールの ECS アカウント設定ページから削除されます。ご質問やご不明点等ございましたら、AWS サポート [3] までお問い合わせください。[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support---We are contacting you because we identified that your account has tagged ECS resources upon creation, within the past year, without the ecs:TagResource permission. Amazon ECS introduced tagging authorization for resource creation on April 18, 2023 [1]. New and existing customers must opt-in to use this new feature by using the ECS Account Settings page in the ECS Console or API. This security control allows users to deny or allow tagging ECS resources when they are created. We strongly recommend you update your IAM policies to explicitly allow the ecs:TagResource action so that your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024.From February 9, 2024, all customer accounts which have not explicitly set the tagResourceAuthorization account setting to “off” in the ECS Account Settings page in the AWS Console were automatically opted into the setting. We have temporarily allow-listed your AWS account so you will continue to have the “off” behavior for tagResourceAuthorization until March 29, 2024.On March 8, 2024, we removed the ability for currently opted-in accounts to opt-out of tagging authorization and enforced the creation of all ECS resources that support tags to use the ecs:TagResource IAM permission.Finally on March 29, 2024, we will remove your account from the allow-list and activate tagResourceAuthorization. You will experience an "AccessDenied" message if you attempt to create tagged ECS resources without including the ecs:TagResource action in the IAM policy of the calling principal. This change will affect the following APIs: CreateCapacityProvider, CreateCluster, CreateService, CreateTaskSet, RegisterContainerInstance, RunTask, StartTask, and RegisterTaskDefinition.Example Deny Response without ecs:TagResourceThe following is part of an IAM policy that is granting the ecs:CreateCluster Action. It does not include the ecs:TagResource Action. When tagResourceAuthorization Account setting is on, the example request would return the AccessDeniedException below.# IAM Policy“Statement”: [{“Sid”: “AllowCreateCluster”,“Effect”: “Allow”,“Action”: [“ecs:CreateCluster”],“Resource”: “*”}]# Create Cluster Requestaws ecs create-cluster --cluster-name MyCluster --tags key=key1,value=value1# Tagging Denied ResponseAn error occurred (AccessDeniedException) when calling the CreateCluster operation:User: is not authorized to perform: ecs:TagResource on resource: cluster/MyCluster because no identity-based policy allows the ecs:TagResource actionRequired Action:To ensure your IAM principals continue applying tags to newly created ECS resources on or after March 29, 2024, we strongly recommend adding the following statement(s) to your IAM policies:Allow Tagging during creation for all ECS ResourcesAdding the ecs:TagResource Action as described below would Allow tagging during ECS resource creation [2].“Statement”: [{“Sid”: “AllowTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”}]Allow Tagging during creation for single ECS Resource Type (ECS Cluster)Using the Conditional statement ecs:CreateAction allow you to limit the tagging to a specific ECS API. The example below grants access to tagging only on the ECS create-cluster API. A request to the ECS API run-task with tags would result in a Deny decision [2].“Statement”: [{“Sid”: “AllowClusterTagging”,“Effect”: “Allow”,“Action”: [“ecs:TagResource”],“Resource”: “*”,“Condition”: {“StringEquals”: {“ecs:CreateAction” : “CreateCluster”}}}]Timeline:February 9, 2024 (Completed) - Tagging Authorization is “on” by default. This excludes your account which is allowlisted. The tagResourceAuthorization account setting can be turned on/off to help test your policy compliance.March 8, 2024 - Tagging Authorization can no longer be turned “off” once it is turned “on”. It is recommended that you test your IAM policies before this date while you are able to toggle the account setting.March 29, 2024 - Tagging Authorization will be turned on for all AWS accounts. The account level setting will no longer be used and will be removed from the ECS Account Settings page in the AWS Console.If you have any questions, please contact AWS Support [3].[1] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html#tag-resources-setting[2] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/supported-iam-actions-tagging.html[3] https://aws.amazon.com/support通知が来ているアカウントは29日までに対応する必要があります。確認aws ecs list-account-settings --effective-settings --name tagResourceAuthorization を実行すると以下のような表示になると思います。ここがonであれば、すでにアカウント単位で有効になってるので影響がありません。(ただし、タグ付きのリソースを新規作成する際には権限が足りないとエラーになる可能性はあります)ここがoffになっている場合、タグ付け認可が無効になってるので3月29日以降影響を受ける可能性があります。% aws ecs list-account-settings --effective-settings --name tagResourceAuthorization{    "settings": [        {            "name": "tagResourceAuthorization",            "value": "on",            "principalArn": "arn:aws:iam::xxxxxxxxxxxx:root"        }    ]}影響がある例ユースケースにもよりますが、タグ付け認可に関連する操作は以下のようなものが考えられるかと思いますインフラ担当者によるECSリソース構築開発担当者(またはCI/CD)によるECSサービスのデプロイ前者に関しては、PowerUser相当の強い権限を付与されていることが多くここが問題になることはほとんどど無いかとは思います。後者の特にCI/CDによるデプロイに問題となることがありえます。一般的に非人間ユーザで目的が明確であれば、最小権限の原則に則り、 ecs:TagResource が付与されていない可能性があります。トライアンドエラーで権限を付与した場合、過去にうまく動いたためそのままの権限で使い続けている可能性もあります。その場合影響がある可能性あります。デプロイ時のタスク定義登録の際、タスク定義内に従来なかったtagsの記述を新規追加した際にResgisterTaskDefinitionでエラーになるという事例を私は経験しました。タスク定義にtagsがないときはタグ付け認可は実行されないのでそのまま成功していたため、ecs:TagResource が必要なことに気づいていませんでした。エラーとしては以下のような記述になるので、タグ付け認可の機能の存在を知っていて冷静に読み解けば、ecs:TagResource が足りていないことに気づけると思います。An error occurred (AccessDeniedException) when calling the RegisterTaskDefinition operation: User: arn:aws:sts::xxxx:assumed-role/deploy-github-actions/GitHubActions is not authorized to perform: ecs:TagResource on resource: arn:aws:ecs:ap-northeast-1:xxxx:task-definition/ecs-service because no identity-based policy allows the ecs:TagResource action対応まずECSサービスを利用しているIAM RoleとIAM Policyを洗い出します。その上でそれらが以下のアクションを許可している場合、ecs:TagResource を追加してあげます。CreateCapacityProviderCreateClusterCreateServiceCreateTaskSetRegisterContainerInstanceRegisterTaskDefinitionRunTaskStartTask私の場合は、ECSサービスデプロイ用のポリシーに以下のStatementを追加しました。それぞれ適切な記述を足していただけたらと思います。この場合タスク定義を登録する際にタグ付け認可を通すような許可を追加しています。        {            "Action": "ecs:TagResource",            "Condition": {                "StringEquals": {                    "ecs:CreateAction": "RegisterTaskDefinition"                }            },            "Effect": "Allow",            "Resource": "arn:aws:ecs:ap-northeast-1:xxxxxx:task-definition/yyyyyyyyyyyyyyy",            "Sid": "RegisterTaskDefinitionWithTag"        },まとめタグ付け認可について説明しました。タグ付け認可は2024年3月29日に強制的に全アカウントで有効になります。時間が少ないですが、影響受ける可能性があるかどうかチェックしてハマらないようにしましょう。また、これまでタグ付けしてなかったリソースにタグ付けする際にタグ付け認可に引っかかる可能性があります。デプロイやリソース作成の際にnot authorized to perform: ecs:TagResource と言われたらこの記事を思い出していただけたらと思います。それでは良いECSライフを!関連リソースアカウント設定による Amazon ECS 機能へのアクセス - Amazon Elastic Container Service タグ付け認可リソース作成時にタグ付けするための許可を付与する - Amazon Elastic Container Service]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Skaffoldのスゴさを語る！]]></title>
            <link>https://zenn.dev/kojake_300/articles/11945f2047b22b</link>
            <guid>https://zenn.dev/kojake_300/articles/11945f2047b22b</guid>
            <pubDate>Mon, 18 Mar 2024 11:24:43 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、2024/3/15に登壇したJagu'e'r クラウドネイティブ分科会　俺の考える最強のCI/CDのリマスターになります。 k8sアプリケーション開発の悩み突然ですが皆さん、k8sでアプリを動かす時にこんな悩み、イライラはありませんか？k8sで検証する時には必ず通る道だと思います。効率よく検証するにはどうしたものか、、Skaffoldはそんな悩みを解決してくれます😄 Skaffoldとは？ 概要Skaffold[1]は、コンテナベース及びKubernetesアプリケーションの継続的開発(Continuous Development = CD)を容易...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tagpr で tag trigger の workflow が実行されなくてハマった話]]></title>
            <link>https://blog.1q77.com/2024/03/tagpr/</link>
            <guid>https://blog.1q77.com/2024/03/tagpr/</guid>
            <pubDate>Fri, 15 Mar 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[最近 tagpr という便利ツールの存在を知って試していたのですが、使い方が悪くてハマったのでメモ。 tagpr とは 作者さまの記事を参照ください。 リリース用のpu]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Helm chart を GitHub Container Registry に host する]]></title>
            <link>https://blog.1q77.com/2024/03/helm-push-to-ghcr/</link>
            <guid>https://blog.1q77.com/2024/03/helm-push-to-ghcr/</guid>
            <pubDate>Thu, 14 Mar 2024 15:13:39 GMT</pubDate>
            <content:encoded><![CDATA[背景 最近は書いたアプリを Kubernetes に deploy することも多い。 その際に helm で簡単に deploy できるようになっていると便利ということで Helm chart を Git に入れておいても良いのだけ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Docker Desktop のアンインストールと Lima の導入]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/14/083605</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/14/083605</guid>
            <pubDate>Wed, 13 Mar 2024 23:36:05 GMT</pubDate>
            <content:encoded><![CDATA[はじめにDocker Desktop は多くの開発者にとって便利なツールですが、さまざまな理由で Lima への移行を検討するケースもあります。この記事では、MAC でDocker Desktop をアンインストールし、Lima を導入する過程を説明します。Limaはcontainerd を実行するための Linux 仮想マシン (通常は macOS 上) 、2022 年 9 月 14 日にサンドボックス成熟度レベルで CNCF に承認されてます。参考文献LimaInstallation | LimaUsage | LimaDocker Desktop のアンインストールDocker Desktop のアンインストールは、公式ドキュメントの指示に従って行うことができます。アンインストールはシステムの設定やリソースの解放に役立ち、Lima の導入の準備を整えます。# CLI から Docker Desktop をアンインストールすることもできます。さようなら。/Applications/Docker.app/Contents/MacOS/uninstall# Docker Desktop をアンインストールした後、削除できるファイルがいくつか残るので合わせて削除rm -rf ~/Library/Group\ Containers/group.com.dockerrm -rf ~/Library/Containers/com.docker.dockerrm -rf ~/.docker参照: Docker Desktop アンインストール方法Lima のインストールLima は、macOS で Linux 仮想マシンを容易に管理するためのツールです。Docker コンテナの実行環境として Lima を使用することで、Docker Desktop と同等の機能を低リソースで利用できます。Lima のインストールプロセスは以下のコマンドで行います。# Lima インスタンスの作成:# `docker` という名前の Lima インスタンスを Docker のテンプレートを使って作成します。limactl create --name=docker template://docker# Lima インスタンスの起動:# 作成した `docker` インスタンスを起動します。limactl start docker# 稼働中の Lima インスタンスの一覧表示:# 現在稼働中の Lima インスタンスの状態を表示します。limactl lsNAME       STATUS     SSH                VMTYPE    ARCH       CPUS    MEMORY    DISK      DIRdocker     Running    127.0.0.1:65015    qemu      aarch64    4       4GiB      100GiB    ~/.lima/dockerDocker CLI のインストールLima がインストールされた後、Docker コマンドラインインターフェース (CLI) をインストールする必要があります。以下のコマンドを使用して、macOS 用の Docker CLI をダウンロードし、インストールします。今回はdocker-25.0.4.tgzをダウンロードしますがこちらを参考に最新版をinstallしてください。# Docker CLI バイナリのダウンロード:# macOS 用の Docker CLI バイナリをダウンロードします。curl -L -O https://download.docker.com/mac/static/stable/aarch64/docker-25.0.4.tgz# ダウンロードしたアーカイブの展開:# ダウンロードした tar.gz アーカイブを展開します。# 毎回、調べているので悲しいtar -xvzf docker-25.0.4.tgz# Docker CLI の移動:# 展開した Docker CLI をシステムの PATH の一部である /usr/local/bin に移動します。パスはどこでもいいけどブログなので...。mv docker/docker /usr/local/bin/参照: macOS でのクライアントバイナリのインストール修正: brew install でのdockerのインストール勝手に--caskとか付けて全部入るなーって思っていたのですがbrew install dockerのみの場合にはDocker CLIのみをインストールすることができますbrew install docker我らがteraoka 師匠から教えていただきました。参照: Lima で vz + rosetta を使って ARM VM 上で x86_64 バイナリを実行する #Docker - QiitaLima-Docker の設定Lima と Docker CLI がセットアップされたら、Lima ベースの Docker 環境を利用するための設定を行います。以下のコマンドで Docker コンテキストを作成し、利用を開始します。# Docker コンテキストの作成:# `lima-docker` という名前の Docker コンテキストを作成し、Lima インスタンス上の Docker デーモンに接続します。docker context create lima-docker --docker "host=unix:///Users/<username>/.lima/docker/sock/docker.sock"# 作成した Docker コンテキストの使用:# `lima-docker` コンテキストをアクティブにして、以降の `docker` コマンドが Lima インスタンスを対象に実行されるようにします。docker context use lima-docker# Docker コンテナの実行 (テスト):# Docker 環境が正しく設定されているかを確認するため、hello-world イメージを実行します。docker run hello-world# Docker での nginx コンテナの実行:# nginx イメージをバックグラウンドで実行し、ポート 8181 をコンテナのポート 80 にフォワードします。docker run --name lima-test-nginx -d -p 8181:80 nginxこれらのステップを完了することで、Lima 上で Docker コンテナを実行し、管理することができるようになります。おまけ:KIND (Kubernetes IN Docker) の利用KIND (Kubernetes IN Docker) は、Docker 上に軽量な Kubernetes クラスタを構築するためのツールです。Lima 環境上で Docker を利用している場合でも、KIND を使用して Kubernetes のテスト環境を簡単にセットアップできます。# KIND クラスタの作成:# 新しい Kubernetes クラスタを作成します。このクラスタは Docker コンテナ内に構築されます。$ kind create cluster# 作成されたクラスタの一覧表示:# 現在 KIND によって作成されたクラスタの一覧を表示します。$ kind get clusterskind# クラスタ情報の取得:# 作成した KIND クラスタのコントロールプレーンやサービスの情報を取得します。$ kubectl cluster-info --context kind-kindKubernetes control plane is running at https://127.0.0.1:51050CoreDNS is running at https://127.0.0.1:51050/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.# 全てのネームスペースで動作している Pod の一覧表示:# クラスタ内の全ネームスペースにわたる Pod の状態を確認します。$ kubectl get pod -ANAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGEkube-system          coredns-76f75df574-5glm8                     1/1     Running   0          87skube-system          coredns-76f75df574-jwn6z                     1/1     Running   0          87skube-system          etcd-kind-control-plane                      1/1     Running   0          103skube-system          kindnet-qlftc                                1/1     Running   0          86skube-system          kube-apiserver-kind-control-plane            1/1     Running   0          102skube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          100skube-system          kube-proxy-6nwnv                             1/1     Running   0          86skube-system          kube-scheduler-kind-control-plane            1/1     Running   0          100slocal-path-storage   local-path-provisioner-7577fdbbfb-vd28d      1/1     Running   0          87sおわり。結論Docker Desktop のアンインストールと Lima の導入に焦点を当てました。本記事で紹介した手順を通じて、開発環境を効率的に管理し、Docker コンテナの実行を最適化することが可能です。参考文献Docker Desktop アンインストール方法macOS でのクライアントバイナリのインストール]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951</guid>
            <pubDate>Wed, 13 Mar 2024 07:49:51 GMT</pubDate>
            <content:encoded><![CDATA[問題を解決する能力は確かに重要ですが、それ以上に、何が本当に重要な問題なのかを見極め、それを明確に設定する能力が不可欠です。問いを適切に定義できなければ、どんなに高度な解決技術を持っていても、その力は十分に発揮されません。また、誰にとって適切な問いなのかも考える必要があります。問題解決の過程において、問題そのものの本質を正確に把握し、適切な問いを立てることは重要です。イシューからはじめよ――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazon概要SREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜にて「書を捨てよ、現場へ出よう - このSRE本がすごい！2024年 LT版」 というテーマで登壇しました。のイベントは2024年1月末に注目を集めた『このSRE本がすごい！2024年版』をテーマにしたもので、多くの参加者とパネルディスカッションのスピーカーであるTopotal のnari_exさん、kenta_hiさんと共に、その内容を深掘りして議論することができ、イベントも無事成功し、大変充実した時間を過ごすことができました。findy.connpass.comイベントを引き起こしたきっかけとなったツイートは以下のものです。この経験から、積極的に意見を発信することの大切さを実感しました。時には思いがけない展開をもたらすこともあるなぁって思いました(小並)。モチベーションになるのでブログの読者登録おねがいします。強い下心を持っているため、Findyさんなどからこれらの本に関する解説をする勉強会の依頼が来ることを期待しています。 https://t.co/amL2de5qFI— nwiizo (@nwiizo) 2024年1月31日   資料この資料は思いの外、感情的な要素が強くエンジニアなのに技術の話を全くしないポエムっぽさが反映されてしまいました。当初は技術的な内容と本の紹介を避ける方針でしたが、認知科学のような専門分野に深く踏み込む知識は持ち合わせていないため、このような方向性になってしまいました。それにもかかわらず、受け取り手からはそこそこに好評を得られたことが非常に嬉しく思います。 speakerdeck.comXでのポストはこちらです。内省の話運用技術者組織の設計と運用 / Design and operation of operational engineer organizationを読んで勝手に憧れていたnari_exさんとのイベントでそのnari_exさんから内省の大切さの話が出てきていた。明日の朝から読んでみようと思う。リフレクション（REFLECTION） 自分とチームの成長を加速させる内省の技術 (オリジナルフレームワークPPT・PDF特典付き)作者:熊平美香ディスカヴァー・トゥエンティワンAmazon読書とは、能力、知識ではなく 問いを獲得するための行為資料を作る前のアウトラインと文章をブログでも公開しておきます。このような内容が気になった方は参考文献を読んでいただければと思います。能力のイメージ能力の抽象性と具体化の必要性日常生活において、私たちは「コミュニケーション能力」、「問題解決能力」、「技術力」などの様々な「能力」について語ります。これらは教育や仕事、プライベートにわたって使われますが、深く考えると、これらの「能力」が具体的に指すものは何か、どう解釈すべきか疑問が生じます。能力に関する理解を深めるには、背後にある原因や要素、その行動や成果への影響を分析することが不可欠です。能力という概念は抽象的であるがゆえに、その実態を把握するには具体的な文脈における観察と分析が欠かせません。能力解釈におけるメタファーの限界と可能性能力の解釈は、しばしばメタファーを通じて行われます。「力」という言葉自体が、物理的な力や潜在的な特性を想起させます。しかし、これらのメタファーは、能力が一貫して同じ効果をもたらすという誤解を生むことがあります。例えば、「コミュニケーション能力」を「言葉の力」と表現することで、言葉さえ巧みに使えば常に良好なコミュニケーションが取れるという誤った印象を与えかねません。能力についての理解を深めるには、メタファーが示すイメージを超えて、実際の文脈での能力の現れ方を丁寧に探ることが重要です。メタファーは理解の出発点としては有用ですが、それに留まらず、具体的な事例や経験から能力の本質を捉えていく必要があります。能力は文脈依存で時と場合次第能力の文脈依存性人間の能力は、状況に応じて異なる形で表れます。ある特定の文脈において顕著な能力が発揮される一方で、他の状況ではまったく異なる影響を持つかもしれません。例えば、プレゼンテーションの場で優れたコミュニケーション能力を発揮する人物が、親密な人間関係の中では十分にその能力を活かせないということもあり得ます。この文脈依存性は、能力が単純な属性ではなく、状況や環境、それに伴う要求に対する応答の結果として理解すべきであることを示唆しています。つまり、能力とは、特定の文脈において、その状況に適した行動を取ることができる力なのです。文脈に応じた問いの形成問いは、私たちが直面する特定の文脈における能力の発揮や理解を深めるのに重要な役割を果たします。そのため、問いは文脈に応じて形成される必要があります。適切な問いを立てることで、その状況における最適な行動や能力の発展につながります。例えば、プレゼンテーションの場面では、「どのようにすれば聴衆の関心を引き付けられるか」、「効果的な情報伝達のために何が必要か」といった問いが重要になります。一方、親密な人間関係の中では、「相手の感情を適切に理解するにはどうすればよいか」、「信頼関係を築くために何ができるか」といった問いが求められます。能力を最大限に活かすためには、その能力をどのように、いつ、どのような状況で使うべきかを考える問いが不可欠なのです。知識の非伝達性と構成主義知識の非伝達性多くの人々は、知識や技能が他者から伝達できるものだと考えがちです。しかし、実際には、知識は伝達されるのではなく、各個人が自身の経験や環境から創発するものなのです。教育や読書を通じて提供されるのは情報のみであり、それを個人が内面化し、自らの知識として再構築するプロセスが必要不可欠です。つまり、知識は受け取るものではなく、自ら作り上げていくものなのです。この視点は、知識獲得を受動的な受け入れではなく、能動的な創造過程として捉えるべきであることを示唆しています。知識の構成主義知識は個人の認知的リソースと環境から提供される情報を結合させて創発されます。このプロセスでは、経験や環境からの情報を基に、個人が能動的に知識を構築します。構成主義の視点から、知識は静的なものではなく、個々の経験や文脈に応じて動的に形成されると捉えられます。これは、知識を単に受け入れるだけでなく、自分自身の行動や内省を通じて深める過程です。知識の構成主義は、学習者の能動性と主体性を重視し、知識の個人的な意味づけを重要視する立場だと言えます。知識の応用と実践道を知っていることと実際に歩くことは違う理論から実践への移行は知識の本質的な価値を明らかにします。教室や書籍で得た知識が、実際の体験や応用を経て深化し、真に生きた知識へと変わります。このプロセスは、抽象的な概念を具体的な行動や体験に結び付け、それによって得られる新しい理解や洞察がさらなる学びのモチベーションを高めます。知識から行動への変換知識を実際の行動に転換することは、それを社会や日常生活に応用し、問題解決や創造的な活動に活かすプロセスです。この実践を通じて、知識は単なる情報の蓄積を超え、個人の体験と統合され、生きたものへと変化します。実践から得られる新たな体験は、知識の内面化を促し、持続可能な知的成長の重要な要因となります。知識と行動の相互作用は、知的な営みの本質であり、知識の実践的な価値を示すものだと言えるでしょう。プログラミング言語の文法や設計パターンを学んだだけでは、実際のソフトウェア開発で成功することは難しいでしょう。理論を実践に活かし、試行錯誤を重ねることで、本当に生きたプログラミングスキルが身につくのです。知っているだけでは不十分で、実際にコードを書き、動かしてみて、時間が経って発生する問題を観測することが重要なのです。読書は、見えなかったものを見えるようにすること問いの形成と知識の活用適切な問いを立てることは、文脈に依存する能力の理解と、個々に構成される知識の活用を促進します。問いは、特定の状況で何が必要であり、どのように行動すべきかを明らかにし、その過程で深い知識の構築と適用が可能になります。読書は、私たちの内面に新たな問いを生み出し、その問いを深めるための知識を提供してくれます。読書と問いの形成は、知識の活用と探究を促す相補的な営みなのです。問いに基づく学習の進展問いは、学習過程において重要な役割を果たします。それにより、私たちは受動的な知識の受け手から、能動的な学習者へと変化し、知識をより深く、文脈に応じて理解し、活用する能力を高めます。これは、個人の成長と発展にとって不可欠なプロセスです。読書は、問いを生み出し、その問いに答えるための知識を与えてくれる営みです。読書と問いに基づく学習は、知的な探究心を育み、生涯にわたる学びの基盤となるのです。問いを深める読書と知的好奇心の拡大読書は、単なる知識の蓄積以上に、私たちの内面的な問いを掘り下げ、それらを広げる活動です。異なる分野や視点からの本を読むことで、従来の枠組みを超えた新しい問いが生まれ、これが知的好奇心を刺激し、さらなる探究へと促します。こうしたプロセスは、私たちの知的な地平を拡げ、より複雑な問題に対する洞察力を高めます。読書の継続と習慣化読書を継続的に行うことは、知識の深化と問いの発展に不可欠です。習慣としての読書は、長期的に見て自己成長を促し、知識をより深く理解し活用する能力を養います。習慣化による読書は、日々の小さな努力を積み重ねることで、大きな学びへと繋がる基礎を築きます。読書習慣は、知的な探究心を持続させ、生涯学習の基盤を形成する上で欠かせない要素だと言えるでしょう。さいごに能力と知識と実践の相互関係能力と知識は、読書を通じて理解し、実践に活かすことができます。読書は、能力の文脈依存性と知識の非伝達性に光を当て、私たちを新たな理解へと導きます。実践を通じて得られる経験は、学んだことを確かなものにし、問いを通じてさらに深い洞察を得ることができます。能力と知識、そして実践は、相互に影響を与え合い、螺旋状に発展していくのです。これらの要素の有機的な結びつきが、私たちの知的成長を支える基盤となります。知識を深めるための継続の意義継続は、知識を蓄積し、それを活用するうえでの基礎を築きます。読書の習慣は、日々の積み重ねによって、知識を内面化し、問いを深め、思考を拡張する重要なプロセスです。知識を深め、問いを追求し続けることで、私たちは自己の成長と進化を遂げることができます。継続的な読書と学びは、私たちを知的な探究者へと導く、生涯にわたる営みなのです。それは、私たちの内なる知的世界を豊かにし、より深い理解と洞察へと導いてくれるでしょう。参考資料学びとは何か――〈探究人〉になるために (岩波新書) 言語の本質-ことばはどう生まれ、進化したかジェームズ・クリアー式 複利で伸びる1つの習慣私たちはどう学んでいるのか　─創発から見る認知の変化達人プログラマー(第2版): 熟達に向けたあなたの旅プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[書を捨てよ、現場へ出よう]]></title>
            <link>https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you</link>
            <guid>https://speakerdeck.com/nwiizo/shu-woshe-teyo-xian-chang-hechu-you</guid>
            <pubDate>Tue, 12 Mar 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[書を捨てよ、現場へ出よう このSRE本がすごい！2024年 LT版というタイトルで登壇してきました。SREたちの廊下〜あなたの現場での悩み、あの本にヒントがあるかも〜https://findy.connpass.com/event/311323/元ブログはこちらこのSRE本がすごい！2024年版https://syu-m-5151.hatenablog.com/entry/2024/01/26/165255登壇ブログはこちら『読書とは、能力、知識ではなく 問いを獲得するための行為』みたいな内容で登壇しました。https://syu-m-5151.hatenablog.com/entry/2024/03/13/164951]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Modern App Summit Tokyo'24 に登壇しました！ ~オススメのセッションを添えて~]]></title>
            <link>https://zenn.dev/yokoo_an209/articles/488f1aa442444f</link>
            <guid>https://zenn.dev/yokoo_an209/articles/488f1aa442444f</guid>
            <pubDate>Tue, 12 Mar 2024 00:13:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに3/1（金）に Google Cloud Modern App Summit Tokyo’24 が開催されましたhttps://cloudonair.withgoogle.com/events/modern-app-summit-24#私はスポンサーセッションのSpeakerとして参加しましたが、他のセッションもすごくおもしろいものが多かったのでゆる〜く内容も合わせてご紹介しますこの方の参加レポートがすごく良いのでぜひ！https://iret.media/94801 登壇内容私は、以下の内容で登壇しました。これだけ規模の大きいイベントに登壇するのは初め...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OSC(Open Source Conference) 2024 Online/Springでセミナー発表とTokyo/Springでブース出展]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/03/10/225747</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/03/10/225747</guid>
            <pubDate>Sun, 10 Mar 2024 13:57:47 GMT</pubDate>
            <content:encoded><![CDATA[2024年3月2日(土)、Open Source Conference 2024 Online/Spring でセミナー発表し、event.ospn.jp同年3月10日(日)、Open Source Conference 2024 Tokyo/Spring でブース出展しました。event.ospn.jpOnline/Springのセミナー（以下、オンラインセミナー）では、日本生成AIユーザ会として、生成AI入門というテーマで発表させていただきました。日本生成AIユーザ会のデビュー戦でした。これまで日本暗号通貨ユーザ会などでブロックチェーン関連の発表はたくさんしてきましたが、生成AIの発表は初めて。無事発表できてよかったです。 speakerdeck.comyoutu.beなお、オンラインセミナーでは日本暗号通貨ユーザ会の発表は今回しておりません。日本生成AIユーザ会と日本暗号通貨ユーザ会の2つの発表をやることはしんどいので、1つだけにしました。一方、3月10日OSC東京はブース展示会でした。会場は東京都立産業貿易センター台東館で、最寄りは浅草駅。天気もよく、浅草駅前の吾妻橋交差点から見える東京スカイツリーとアサヒビール本社屋上の金色のオブジェが綺麗に見えました！浅草からの風景↓金色のオブジェは聖火台の炎を表現していたのですね！今知りましたwwww.asahibeer.co.jpブース展示会では、日本生成AIユーザ会と日本暗号通貨ユーザ会の合同出展という形にしました。出展しております！#osc24tk#genai_users#ccstudy pic.twitter.com/O0vcEGWkd0— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月10日   ブースにはたくさんの方にきていただき、生成AI、暗号通貨(ブロックチェーン)ともに興味を持っていただけました。OSC東京の休憩で、坦々麺 一龍 浅草本店へ。昨年春の浅草でのOSC東京にてここで食べて美味しかったので、再来店。かなりの細麺、正方形の器になり、進化してました。美味しかった！#osc24tk#genai_users#ccstudy pic.twitter.com/wvscqgtHHj— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月10日   日本生成AIユーザ会と日本暗号通貨ユーザ会のブースに、リナックくんが遊びに来たで！#Linuc#リナックくん#osc24tk#genai_users#ccstudy pic.twitter.com/R9CLB7FG4g— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月10日   皆様お疲れ様でした！運営の皆様、出展させていただきありがとうございました。ブースに来ていただいた皆様ありがとうございました。これまでOSCのブース出展は、日本暗号通貨ユーザ会だけで行ってきましたが、今回、日本生成AIユーザ会でも出展することで新たな気付きもたくさん得られました。秋のOSC東京ではもっとブースをパワーアップして挑みたいと思います！日本暗号通貨ユーザ会は次回、3月22日(金)20:00〜「ビットコイン・ブロックチェーン入門」という講義形式(※)のオンライン勉強会を開催します。※講義形式というのは、ハンズオンや輪読ではないということです。発表者が説明して、質問を受け付けます。当てたりしませんので、ご安心をw！cryptocurrency.connpass.com日本生成AIユーザ会は次回、4月5日(金)20:00〜「生成AIアプリケーション開発入門ハンズオン」というハンズオン形式のオンライン勉強会を開催します。ハンズオンですが、難しくなく皆さんがついてこられて、かつ楽しい内容にします！genai-users.connpass.comどちらもぜひご参加ください！これからも両コミュニティをよろしくお願いいたしますm(._.)m]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 主催 Generative AI Summit Tokyo '24に参加]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/03/08/095543</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/03/08/095543</guid>
            <pubDate>Fri, 08 Mar 2024 00:55:43 GMT</pubDate>
            <content:encoded><![CDATA[2024年3月7日、GOOGLE CLOUD 主催 Generative AI Summit Tokyo '24 に参加しました！cloudonair.withgoogle.com株式会社スリーシェイクはスポンサーを務めておりました。基調講演を除き、観たセッションはXにてスレッドで軽く実況を書いています。Google Cloud Generative AI Summit「生成 AI 時代に Google Kubernetes Engine は何を解決してくれるのか」を聞きます！https://t.co/c0HW6f9xVP#gc_genai— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   Google Cloud Generative AI Summit「Chugai DX × GenAI の裏側 : 製薬業界の IT エンジニアが挑む次世代の業務最適化」https://t.co/fbqXCTorEq#gc_genai  #track1— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   弊社の発表！「SRE@scale: 生成 AI で実現するスリーシェイクが考える拡張性のある SRE の取り組み」https://t.co/lv5Rd15qLb#gc_genai #track4— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   Google Cloud Generative AI Summit Tokyo '24住友ゴム工業株式会社さん「製造業における生成 AI を使った業務効率化への取り組み」https://t.co/XGSFieexyF#gc_genai #track1— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   Google Cloud Generative AI Summit Tokyo '24株式会社トップゲートさん「文書管理の未来：Document AI と Vertex Search を利用した紙文書管理」https://t.co/SIHbwTcJPb#gc_genai #track3— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   Google Cloud Generative AI Summit Tokyo '24株式会社サテライトオフィスさん「2000 社導入、生成 AI 活用最前線　サテライト AI のご紹介」https://t.co/brrAlihedB#gc_genai #track3— Shu Kobuchi(こぶシュー) (@shu_kob) 2024年3月7日   全体を通しての感想は、キラーアプリはまだ出てきていないものの、早期に生成AIを触り始めた企業さんは、事例をどんどん作っていると言う印象でした。私も生成AIに携わるものとして、モチベーションが上がったので、日々の業務に邁進していきたいと思います！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[君たちはどう記事を管理しているか]]></title>
            <link>https://zenn.dev/yokoo_an209/articles/c0ccd3bd241ad6</link>
            <guid>https://zenn.dev/yokoo_an209/articles/c0ccd3bd241ad6</guid>
            <pubDate>Thu, 07 Mar 2024 13:49:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめにみなさんは良いなと思った記事や保存しておきたいなと思った記事をどのように溜めていますか？また、どのように引き出していますか？身近に「こんな資料・記事あったな、参考になると思うのでどうぞ 」で ｼｭﾂ と出してくる猛者エンジニアの方がいたりしますよね...ここでは、頭のストレージ容量が皆無な私が、そんなことできる人になりてぇなぁ〜と思いながら、考えた方法をご紹介します。ブラウザのブックマークや、Qiita・Zennに搭載のネイティブのストック機能、Slackの自分だけのチャンネルに貼る、様々な方法があると思います。もしくは、特に溜めていなく引き出したいときに思い出せ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI入門]]></title>
            <link>https://speakerdeck.com/shukob/sheng-cheng-airu-men</link>
            <guid>https://speakerdeck.com/shukob/sheng-cheng-airu-men</guid>
            <pubDate>Sat, 02 Mar 2024 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[今話題の生成AIについて簡単に技術概要をお話ししたのち、LangChain、プロンプトエンジニアリング、RAG（Retrieval Augmented Generation）、Embedding、グラウンディングなどを実装の手法などを紹介しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[酸いも甘いもある Shared VPC（共有VPC） ~ GKE をShared VPC で構築する際の苦悩~]]></title>
            <link>https://zenn.dev/yokoo_an209/articles/1818360b9c7821</link>
            <guid>https://zenn.dev/yokoo_an209/articles/1818360b9c7821</guid>
            <pubDate>Thu, 29 Feb 2024 07:23:09 GMT</pubDate>
            <content:encoded><![CDATA[このブログは、【Google Cloud】GDG Tokyo Monthly Online Tech Talksにて発表した内容を元にしています。登壇時の資料はこちらになります。https://speakerdeck.com/parupappa2929/suan-imogan-imoarushared-vpc-gong-you-vpc-gkewoshared-vpcdegou-zhu-suruji-noku-nao はじめにGoogle Cloud Shared VPC（共有VPC）はネットワークリソースの集中管理ができる一方で、リソース利用に関して制約があったり、エンプラ企業...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[迅速に叶える、GKE Autopilot によるユニバーサルモダンアーキテクチャの実践]]></title>
            <link>https://speakerdeck.com/parupappa2929/xun-su-nixie-eru-gke-autopilotniyoruyunibasarumodanakitekutiyanoshi-jian</link>
            <guid>https://speakerdeck.com/parupappa2929/xun-su-nixie-eru-gke-autopilotniyoruyunibasarumodanakitekutiyanoshi-jian</guid>
            <pubDate>Thu, 29 Feb 2024 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Modern App Summit Tokyo '24 にて登壇した内容です。https://cloudonair.withgoogle.com/events/modern-app-summit-24?talk=session-c1]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Astroでブログを作ってる]]></title>
            <link>https://abnoumaru.com/tech/2024-02-27-create-blog-from-astro-template/</link>
            <guid>https://abnoumaru.com/tech/2024-02-27-create-blog-from-astro-template/</guid>
            <pubDate>Tue, 27 Feb 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[AstroのBlog templateをベースに自分が欲しい機能を検討してブログ作ってる]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Azure Container Apps Jobs を Self-hosted GitHub Actions Runner として使う]]></title>
            <link>https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/</link>
            <guid>https://blog.1q77.com/2024/02/container-apps-jobs-self-hosted-github-actions-runner/</guid>
            <pubDate>Fri, 23 Feb 2024 10:05:41 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Actions の Self-hosted Runner を安く用意する方法を探していたところ、 Azure の Container Apps Jobs というのが便利に使えるらしいというのを見つけたので試してみる。 チュートリアル:Az]]></content:encoded>
        </item>
    </channel>
</rss>