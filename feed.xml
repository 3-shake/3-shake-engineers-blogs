<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 03 Apr 2025 11:34:50 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[GTC2025 参加記録　~Keynote~]]></title>
            <link>https://sreake.com/blog/gtc2025-keynote/</link>
            <guid>https://sreake.com/blog/gtc2025-keynote/</guid>
            <pubDate>Mon, 31 Mar 2025 00:26:08 GMT</pubDate>
            <content:encoded><![CDATA[3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Keyball 61にhome row modsを導入した]]></title>
            <link>https://blog.atusy.net/2025/03/31/home-row-mods/</link>
            <guid>https://blog.atusy.net/2025/03/31/home-row-mods/</guid>
            <pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[長らくキー配列についてはKeyball61のオレオレマッピングを語るの通りでしたが、加えてhome row modsを導入しました。home row modsは、ホームポジションのasdf（左）とjkl;（右）を押しっぱなしたときに（hold）、CtrlやShiftなどの修飾キーとして機能させる方法論です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[3年目までに身につけたい技術ブログの書き方]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</guid>
            <pubDate>Sun, 30 Mar 2025 18:44:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあなたは日々、何かを見ている。そう、コードを。エラーを。ドキュメントを。解決策を。そして、それは誰も見ていないものかもしれない。あるいは、多くの人が同じものを見ているのに、誰も記録に残していないのかもしれない。「自分なんてまだ1年目、2年目。経験が浅いから書くことなんてない」そんな思いを抱いていませんか？ しかし、その思い込みは真実ではありません。むしろ、経験の浅さこそが、あなたにしか書けない貴重な視点を生み出します。初めて学ぶ時の困惑、理解するまでの試行錯誤、そして「あ、わかった！」という喜び—これらの生々しい体験は、あなたがまさに今感じているからこそ書ける宝物なのです。「専門家でもないのにブログなんて書けない」「自分の書いたものなんて誰も読まないだろう」という思いも、単なる幻想です。誰もが最初から専門家ではなかった。今あなたが参考にしている記事を書いた人も、最初は不安を抱えながらキーボードに向かったはずです。このブログを書いている私もです。ネット上には膨大な情報があふれていますが、だからこそ、あなたの視点、あなたの言葉、あなたの経験を通して伝えられる情報には価値があります。なぜなら、あなたの記事を必要としている人は、まさにあなたと同じ疑問や課題を持っている人だからです。技術ブログは、完璧な知識や完成された思考を示すためのものではありません。それは思考の過程を記録するものです。完璧を目指すあまり書けなくなるよりも、不完全でも自分の観察と気づきを残していくことに価値があります。自分が躓いたその瞬間こそ、同じ場所で立ち止まっている誰かにとっての地図になる。あなたが苦労して辿り着いた解決策は、未来の誰かの貴重な時間を節約するだけでなく、新たな発見への扉を開くきっかけになるかもしれません。この記事では、技術ブログの種類とその書き方、特に新人エンジニアが取り組みやすいパターンについて解説します。ブログを書く意義、どのようなブログを書けばよいのか、どう書き始めればよいのか、批判されたときにはどうすればよいのかを知ることで、あなたの歩んできた道は他のエンジニアにとって価値ある情報源となり、同時にあなた自身の成長を加速させる強力なツールとなるでしょう。「でも、文章を書くのが苦手で…」「何を書けばいいか分からなくて…」と思っているあなたも、この記事を読み終わる頃には、最初の記事を書くためのアイデアとやる気を手に入れているはずです。さあ、あなたの知識や経験を世界と共有する旅を、一緒に始めましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめにブログ執筆がもたらす価値思考を整理する鏡知識の共有経済への参加思考の足跡としてのブログ技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記2. バグハント記事3. 環境構築ガイド4. 学んだ教訓記事5. プログラミング言語の乗り換え記録6. システム開発の舞台裏7. 技術トレンドの考察8. 技術の性能比較と検証書き始めるための実践ガイド始めやすいブログパターンの選択日常からネタを発掘する技術読者を惹きつける記事構成読みやすさを高める実践テクニック心地よい技術コミュニケーションのために読み手の感情を大切にする好きなものを中心に語る個人の経験として共有する主観的な表現を心がけるポジティブな内容を中心に批判を柔らかく伝える工夫背景情報を丁寧に説明するもし反発を受けたときの心構え人気記事には批判も付きもの反応せずに見守る勇気を持つコメントの背景を想像してみる誤解には丁寧な補足を時間の流れを味方にするブログ公開の場の選択技術特化型プラットフォーム汎用ブログプラットフォーム自前のブログプラットフォーム選びのアドバイス継続のための現実的なアプローチ小さなハードルから始める自分のための記録として書く「十分に良い」の基準を持つ終わりに本気(マジ)の話ブログ執筆がもたらす価値技術ブログを書く行為には、表面的には見えない多くの価値があります。思考を整理する鏡「説明できることは理解している証拠だ」という言葉があります。コードを書くだけではわからなかった理解の穴が、他者に説明しようとする瞬間に見えてきます。ブログ執筆は自分の思考をクリアにし、知識の定着を促す強力なツールです。ラバーダック・デバッギングがコードの理解を深めるように、ブログはあなたの思考を整理します。知識の共有経済への参加オープンソースのコードを共有するように、あなたの解決策や洞察も共有価値があります。あなたが30分かけて解決した問題は、記事を通じて何百人もの時間を節約するかもしれません。それは単なる善意ではなく、テクノロジー業界の発展に寄与する行為です。思考の足跡としてのブログ定期的に書かれたブログは、あなたの専門性と成長の記録となります。それは履歴書やポートフォリオ以上に、あなたの思考プロセスと問題解決能力を示す生きた証拠になります。自然と「個人ブランド」が形成され、思わぬ機会につながることもあるでしょう。技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記新人に特におすすめ新しい技術やツールを学んだ過程を記録するブログです。チュートリアルの穴を埋めたり、つまずいたポイントの解決策を共有したりします。書き方のポイント:学習の目的と背景を明確につまずいたポイントと解決法を詳細に公式ドキュメントには書かれていない気づきを強調スクリーンショットやコードスニペットで手順を明確に構成例:学習の動機（なぜこの技術を学ぼうと思ったか）前提知識と環境学習プロセス（つまずいたポイントを含む）得られた気づきと学び次のステップ2. バグハント記事特定のバグや問題を発見し、追跡し、最終的に修正するまでの旅を共有するブログです。書き方のポイント:問題の症状と影響を具体的に調査プロセスを時系列で詳細に（ミステリー小説のように、叙述トリックを使ってもよいですがほどほどに⋯）フレームグラフ、ログ、診断データなどの「証拠」を提示どのような思考プロセスで原因に辿り着いたかを解説最終的な解決策と学んだ教訓構成例:問題の概要（何が起きたか）調査の開始（最初の仮説）探索と証拠収集誤った道と行き止まり（失敗も正直に）原因の特定と理解解決策と検証学んだ教訓と予防策3. 環境構築ガイド開発環境や特定のツールのセットアップ方法を解説するブログです。書き方のポイント:対象読者（初心者か上級者か）を明確に前提条件と必要なツールを明示手順をステップバイステップで説明トラブルシューティングの情報を含める何のためにこの設定をするのかの理由も説明構成例:目的と概要前提条件と必要なものインストール手順（ステップバイステップ）設定と最適化動作確認の方法よくあるトラブルとその解決法4. 学んだ教訓記事プロジェクトや技術的課題から得た教訓や気づきを共有するブログです。書き方のポイント:率直かつ謙虚なトーンで具体的な状況と文脈を提供失敗や間違った判断からの学びを強調他のエンジニアに適用できる一般的な教訓を抽出時系列に沿った「日記的」な構成も有効構成例:状況と背景直面した課題取った行動と判断結果と振り返り学んだ教訓次回への活かし方5. プログラミング言語の乗り換え記録既存のプロジェクトを新しいプログラミング言語やフレームワークで作り直した経験を共有するブログです。書き方のポイント:言語やフレームワークを変更した理由を分かりやすく説明古い言語と新しい言語の違いと比較移行作業で苦労した点とその解決方法処理速度や保守のしやすさの比較結果言語の乗り換えから学んだこと構成例:現状と移行の動機技術選定と比較検討移行戦略と計画実装の詳細と課題成果と比較（ビフォー・アフター）学んだ教訓と今後の展望6. システム開発の舞台裏システムや機能をどのように考え、設計し、作り上げたかを詳しく説明するブログです。書き方のポイント:システムの目的と必要な機能を明確に設計で迷った点や判断した理由を説明全体の構造を図や図解でわかりやすく重要なコードの部分とその役割の解説ぶつかった壁とその乗り越え方今後の改善点や拡張できる部分構成例:プロジェクトの背景と目標要件と制約条件設計の選択肢と検討プロセス選んだアーキテクチャとその理由実装の重要ポイント課題と解決策結果と評価7. 技術トレンドの考察IT業界の流行りや新しい技術の動きについて、自分なりの意見や分析を述べるブログです。書き方のポイント:堅固な論拠と証拠で意見を裏付ける単なる批判ではなく、建設的な視点を提供自分の経験に基づいた具体例を含める複数の視点を考慮し、バランスの取れた議論を展開明確な結論と、読者が検討すべきポイントを提示構成例:トレンドの概要と背景現在の状況分析メリットとデメリット実務への影響と適用性自分の見解と予測実践的なアドバイス8. 技術の性能比較と検証異なる技術や方法の速度や効率を実際に測って比較し、その結果を共有するブログです。書き方のポイント:テスト方法と環境を詳細に記述公平で再現可能なベンチマーク手法を使用データを明確に視覚化（グラフ・表）結果の解釈と実用的な意味を説明限界と注意点も正直に伝える読者が検証できるようコードや手順を共有構成例:テストの目的と背景検証環境とセットアップテスト方法と条件結果の提示と分析発見と考察実用的な示唆と推奨事項書き始めるための実践ガイド始めやすいブログパターンの選択新人エンジニアが最初に挑戦しやすいのは、自分の直接体験に基づいた記事です。特に以下のパターンは、書きやすく読者にも価値を提供しやすい傾向があります。学習ログ＆チュートリアル体験記 - 公式ドキュメントには書かれていない「実際にやってみたらどうだったか」の記録は、後続の学習者にとって貴重な情報源になります。また、英語のチュートリアルを日本語でやってみるだけでも大きな価値があります。環境構築ガイド - 一度苦労して設定した開発環境の手順は、記録しておくだけで大きな価値があります。読者や半年後の自分も、同じ苦労をせずに済むでしょう。バグハント記録 - 解決に時間がかかった問題は、その過程を含めて記録する価値があります。デバッグの思考プロセスこそが、技術的な洞察を含んでいます。学びの教訓 - 「〜だと思っていたけど、実際は違った」という気づきは、技術記事として非常に価値があります。誤解やミスコンセプションを正す内容は、多くの人の時間を節約します。日常からネタを発掘する技術記事のアイデアは日々の業務や学習の中に隠れています。以下の視点で日常を観察してみましょう。学習過程での「なぜ？」、理解するのに時間がかかった概念や、直感に反する仕様は、記事になりやすいトピックです。繰り返し説明していること、チーム内で何度も同じ説明をしている内容は、記事化する価値が高いでしょう。検索しても満足な答えが見つからなかった問題、そのような問題を解決できたなら、あなたと同じ検索をする誰かのために記録を残しましょう。「あれ？」と思った瞬間、予想通りに動かなかったコード、意外な挙動を示したツール、これらの「あれ？」の瞬間は、貴重な記事の種です。このような日常の発見からブログネタを見つける考え方は、ジェームス・W・ヤングの名著『アイデアのつくり方』に私の考え方は近いです。ヤングによれば、アイデアとは既存の要素の新しい組み合わせであり、その才能は事物の関連性を見つけ出す力に依存しています。ヤングが提唱する5段階のアイデア創出プロセスは、技術ブログ執筆にも応用できます。資料を収集する - 特定のテーマに関する専門知識と、幅広い一般知識の両方を集める資料を噛み砕く - 集めた情報を様々な角度から検討し、関係性を探る問題を放棄する - 一度意識的な思考から離れ、無意識に働かせるアイデアが訪れる - 何気ない日常の瞬間（シャワー中やトイレなど）に閃きが生まれるアイデアを現実に連れ出す - 閃いたアイデアを忍耐強く形にするあなたの「あれ？」という瞬間は、ヤングの創造プロセスの一部として考えることができます。まず資料収集の段階で日々の開発や、読書、学習から知識を蓄え（第1段階）、それらの情報を頭の中で検討し関連付けようとし（第2段階）、一度問題から離れて無意識に働かせ（第3段階）、そして「あれ？」という気づきや閃きが訪れるのです（第4段階）。この瞬間を逃さず記録し、丁寧に育てて記事として形にしていく作業が最終段階（第5段階）となります。日々の疑問や発見を意識的に記録する習慣をつけることで、ヤングのプロセスを体現し、貴重なブログの種を蓄積できるでしょう。「ブログが書けない」と悩んでいるほとんどの人は、この5段階のプロセスのどこかが欠如していることがほとんどです。そして、どの段階が欠如しているかによって、対応方法が大きく変わります。資料収集が不足している人には、まずは情報のインプットを増やすことが重要です。技術書を読む、オンラインコースを受講する、技術カンファレンスの動画を見るなど、様々な方法で知識の幅を広げましょう。また、特定の技術だけでなく、隣接分野や全く異なる分野の知識も取り入れることで、独自の組み合わせが生まれやすくなります。情報の噛み砕きが不足している人には、学んだことをノートにまとめる、同僚に説明する、図解してみるなどの方法がおすすめです。具体化したり抽象化したりするのもおすすめです。情報を受動的に受け取るだけでなく、自分の言葉で咀嚼し直すことで、新たな気づきが生まれやすくなります。リラックスの時間が不足している人には、意識的に「何も考えない時間」を作ることが大切です。常に問題解決モードでは、無意識の働きが活かせません。散歩する、お風呂に浸かる、瞑想するなど、頭を空っぽにできる時間を日常に取り入れましょう。閃きを見逃している人には、スマートフォンのメモアプリやノートを常に持ち歩き、思いついたことをすぐに記録する習慣をつけることをおすすめします。閃きは突然訪れ、すぐに消えてしまうものです。「あとで覚えておこう」と思っても、ほとんどの場合は忘れてしまいます。書ききれない人には、「まずは15分だけ書く」という小さなハードルから始めることをおすすめします。完璧な記事を目指すのではなく、とにかく書き始めること。編集や推敲は後からでも可能ですが、書かれていない文章は編集のしようがありません。また、締め切りを設定したり、書き始める時間と場所を決めておくなど、環境を整えることも効果的です。あなたがブログを書けない理由がどの段階にあるのかを特定することで、より効果的な対策を講じることができるでしょう。アイデアのつくり方作者:ジェームス W.ヤングCCCメディアハウスAmazon読者を惹きつける記事構成技術ブログも、読者が最後まで読みたくなる構成が重要です。以下のような流れを意識すると、読みやすい記事になります。問題提起 - なぜこの記事を書いたのか、読者にとってどんな価値があるのかを明確にします。最初の段落で「この記事を読むことで解決できる問題」を具体的に示すことで、読者の興味を引きつけましょう。「〜に悩んでいませんか？」「〜をもっと効率的にしたいと思いませんか？」といった形で読者の課題に共感を示すと効果的です。ただし、単なるクリックベイト的な見出しや過度な約束は避け、記事の内容と一致した誠実な問題提起を心がけましょう。コンテキスト - あなたの環境や前提条件を説明し、読者が自分の状況と比較できるようにします。「私がこの問題に取り組んだ時の状況はこうでした」と具体的に共有することで、読者は自分のケースとの類似点や相違点を理解できます。使用した技術のバージョン、ハードウェア環境、チームの規模、プロジェクトの背景など、関連する情報を提供しましょう。これにより、読者は記事の内容が自分にとって適用可能かどうかを判断できます。コンテキストが明確であればあるほど、読者は安心して読み進められます。探求の旅 - 単なる解決策ではなく、そこに至るまでの思考プロセスを共有することで、読者は深い理解を得られます。最初に考えたアプローチ、試した方法、直面した課題、そしてなぜ最終的な解決策にたどり着いたのかを時系列で説明しましょう。失敗したアプローチも含めて正直に共有することで、記事の信頼性が高まり、読者も同じ失敗を避けられます。「最初はAという方法を試みましたが、Bという問題に直面したため、Cというアプローチに切り替えました」といった形で、あなたの試行錯誤のストーリーを語ることで、記事に人間味と深みが加わります。発見と学び - 技術的な発見だけでなく、アプローチ方法についての洞察も含めましょう。「この経験から学んだ最も重要なことは〜です」と明確に示すことで、読者は記事の本質的な価値を理解できます。コードやシステムの改善点だけでなく、問題解決プロセス、チーム協力、技術選定の基準など、より広い文脈での学びを共有すると、記事の応用範囲が広がります。特に、「意外だったのは〜」「常識と違ったのは〜」といった予想外の発見は強調する価値があります。こうした「目から鱗」の瞬間は、読者にとって最も記憶に残る部分となるでしょう。次のステップ - 読者が更に探求できるように、参考資料や発展的な内容へのリンクを提供します。「もっと詳しく知りたい方はこちらの資料がおすすめです」「次のステップとして〜を検討するとよいでしょう」といった形で、読者の学習旅行の次の目的地を示唆しましょう。また、未解決の課題や将来の展望についても正直に触れることで、読者との対話を促すことができます。「現在はまだ〜という課題が残っていますが、今後は〜のアプローチを試してみる予定です」といった形で、完璧な解決策だけでなく、進行中の探究であることを示すと、より現実的で共感を得られる記事になります。読みやすさを高める実践テクニック技術的な内容を伝える際、読みやすさは極めて重要です。以下のテクニックを活用して、読者が最後まで読み進められる記事を目指しましょう。最初の3行で読者を掴む - 記事の冒頭3行は、読者が「続きを読むか」を決める重要な部分です。問題提起や具体的な価値を示し、興味を引く導入を心がけましょう。「この記事を読むと〜ができるようになります」「あなたも経験したことがあるかもしれませんが、〜という問題は実は〜で解決できます」といった書き出しが効果的です。ただし、注意点として、技術ブログでは大言壮語や過度な主張（「これが唯一の正しい方法だ」「これさえ知れば全てが解決する」など）は避けるべきです。断定的な表現は炎上リスクを高め、読者の信頼を損なう恐れがあります。「私の経験では」「この特定の状況では」といった限定的な表現を使い、バランスを保ちましょう。見出しを上手に使う - 大見出しと小見出しで内容を整理し、ざっと見ただけでも内容がつかめる構造にします。見出しは「目次」としての役割を持ち、読者が求める情報に素早くアクセスするための道標となります。見出しには具体的な内容や得られるメリットを含めると、さらに効果的です。例えば「実装方法」よりも「3ステップで実装できるシンプルな方法」の方が読者の興味を引きます。また、見出しの階層構造は3段階程度に抑え、整理された印象を与えましょう。長い文章は小分けに - 長い文章が続くと読者は疲れます。適度に区切って、読者が「ここまで読めた」と小さな達成感を得られるようにします。段落は1つの考えにつき1つにし、3〜5行程度を目安にするとよいでしょう。また、読みやすさを高めるために、箇条書きや番号付きリストを活用して情報を整理しましょう。さらに、重要なポイントには太字や斜体などの強調を適切に使い、視覚的なメリハリをつけることで、スキャンしやすくなります。ただし、強調の使いすぎは逆効果なので、本当に重要な部分だけに留めるのがコツです。コードと説明文のバランス - 長すぎるプログラムコードは避け、重要な部分だけを取り出して、それに説明を加えましょう。コードブロックの前には「何をするコードなのか」、後には「なぜそのように実装したのか」「どのような効果があるのか」を説明すると理解が深まります。また、複雑なコードは徐々に構築していく形で示すと良いでしょう。初めに基本形を示し、段階的に機能を追加していくアプローチは、特に初心者にとって理解しやすい方法です。コメントを適切に挿入することも効果的ですが、コード自体が説明的であることを心がけましょう。具体例と全体像を交互に - 具体的なコード例と、そこから学べる一般的な教訓を交互に示すことで、理解が深まります。「木を見て森も見る」アプローチで、読者は個別の実装詳細と、それがどのように大きな概念に適合するかを同時に理解できます。例えば、特定のパターンの実装例を示した後、「このパターンが特に有効なのは〜のような状況です」と一般化すると、読者は自分の状況への応用がしやすくなります。逆に、原則や概念を先に説明してから具体例で補強する方法も効果的です。両方のアプローチを記事内で使い分けると、多様な学習スタイルの読者に対応できます。視覚的要素を活用する - 複雑な概念や関係性は、文章だけでなく図やダイアグラム、スクリーンショットで説明すると理解が格段に向上します。特に、システムアーキテクチャやデータフロー、アルゴリズムの流れなどは視覚化が効果的です。図は装飾ではなく情報を伝える手段として使い、適切なキャプションを付けることで文脈を明確にしましょう。また、長い記事では適度に図を挿入することで、読者に視覚的な休息も提供できます。図の作成には専門的なツールは必ずしも必要なく、シンプルな図であれば手書きスケッチをスキャンしたものでも十分に価値があります。読者の知識レベルを想定する - 対象とする読者層の知識レベルを想定し、それに合わせた説明の詳しさを調整しましょう。初心者向けの記事では基本概念から丁寧に説明し、上級者向けには深い技術的洞察や最適化のポイントに焦点を当てます。どちらの場合も、前提知識を記事の冒頭で明確にしておくと、読者は自分に適した内容かどうかを判断できます。「この記事はXYZの基本を理解している方を対象としています」といった一文を入れるだけでも効果的です。また、専門用語を使う場合は、初出時に簡単な説明を加えるか、リンクで参照先を示すと親切です。余韻を残す結びで読者の思考を広げる - 優れた技術ブログは、単に情報を伝えるだけでなく、読後に読者の思考を広げるものです。結びのパートでは、説明した技術の将来性や発展の可能性、異なる文脈での応用例などに軽く触れておくと、読者は記事を閉じた後も考え続けるきっかけとなります。「この技術は〜の領域でも応用できるかもしれません」「今回紹介した手法をさらに発展させると、どのような可能性が開けるでしょうか」といった問いかけは、読者の創造性を刺激し、自分なりの解釈や発展を考える余韻をもたらします。また、「私自身はこの技術と出会って、〜という視点が変わりました」のような個人的な洞察や、技術の社会的意義に触れることで、読者に新たな気づきや内省の機会を提供できます。心地よい技術コミュニケーションのために技術ブログを書くとき、単に知識を共有するだけでなく、読み手がどう感じるかに気を配ることも大切です。思慮深いコミュニケーションは、あなたのメッセージをより効果的に伝え、建設的な対話を生み出します。以下の考え方を意識することで、知識共有の質を高め、不要な論争を避けることができるでしょう。読み手の感情を大切にする書いた内容が誰かを傷つけていないか考えてみましょう。「この書き方だと、誰かが自分を批判されていると感じるかも」と想像することが大切です。例えば、ある技術について「この方法は時代遅れだ」と書くより、「私の用途ではこの新しい方法がうまく機能しました」と表現する方が、読み手の心を開いたままにします。技術選択は多くの場合、状況やニーズに依存するものであり、一概に優劣をつけられないことを認識しましょう。好きなものを中心に語るあなたが好きな技術や方法について熱く語りましょう。何かを批判するよりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。「Aは問題だらけだがBは素晴らしい」ではなく、「Bのここが素晴らしい」と伝えるだけで十分です。英語圏でよく使われる「not for me」（これは私には合わない）という表現は、技術ブログでも有効です。これは「悪い」というわけではなく、単に「私の状況や好みには合わない」という意味を含んでいるからです。個人の経験として共有する「すべてのエンジニアは〜すべきだ」「この業界では〜が常識だ」といった広い主語での断言は避けましょう。代わりに「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。それでも強引に批判してくる人はいます。そういう人はそもそもめちゃくちゃに批判したくてその構成が目の前に存在しているからめちゃくちゃに言ってくるのですが、日本語をちゃんと読めない人を相手にする必要はありません。あなたの経験を共有する権利は誰にも奪われないのです。主観的な表現を心がける「これは正しい方法だ」「あれは間違っている」という価値判断ではなく、「私はこの方法が好きです」「私の場合はこちらの方法が合っていました」という表現にすることで、異なる意見の人も受け入れやすくなります。私たちはみな異なる状況で働いており、一つの正解があるわけではないことを認識しましょう。特に技術の世界では、同じ問題に対しても多様なアプローチが存在することを尊重することが重要です。ポジティブな内容を中心に問題点や不満よりも、解決策や学びを中心に書きましょう。ネガティブな内容は同様にネガティブな反応を呼びがちです。「〜が使いにくい」より「こうすると〜がもっと使いやすくなりました」という表現の方が、建設的な対話につながります。あなたが困難を乗り越えた経験は、その過程で学んだことと共に共有することで、より価値のある情報になります。批判を柔らかく伝える工夫どうしても批判的な内容を書く必要があるときは、批判の対象をぼかしたり、自分の失敗談を交えたりすることで、攻撃的に見えるのを避けられます。「私も以前は〜と思っていましたが、実際にやってみると〜だとわかりました」といった表現なら、相手の反感を買いにくくなります。また、批判する際も建設的な代替案を提示することで、単なる不満ではなく有益なフィードバックとして受け取られやすくなります。背景情報を丁寧に説明する「これはこういう状況での話です」「私はこういう前提で考えています」と背景を明確にすることで、誤解を防げます。普通に人と喋っている時は省略するかもしれない文脈の紹介も技術ブログを書く時には必要です。誤読する余地を可能な限り減らします。特に技術的な主張をするときは、あなたの環境や条件を明示することで、「それは特定の状況下での話だね」と理解してもらいやすくなります。使用しているハードウェア、ソフトウェアのバージョン、チームの規模、プロジェクトの性質など、具体的な情報を提供することで、読者はあなたの経験を適切に文脈化できます。もし反発を受けたときの心構えどれだけ配慮して書いても、時には予想外の反応を受けることがあります。インターネット上での議論は時に感情的になりがちです。正直なところ、批判されたときの最初の感情は「なんでこんなこと言われなきゃいけないんだ」という怒りや落胆でしょう。そんな感情は自然なものですし、一時的に落ち込んだり、イラっとしたりするのも当然です。でも、そんなときに役立つ考え方をいくつか紹介します。人気記事には批判も付きもの多くの人に読まれるブログには、様々な価値観を持つ人が訪れます。あなたの意図とは関係なく、一定数の批判的なコメントが寄せられるのは自然なことです。人気の証と考えて、あまり気にしすぎないようにしましょう。実際、最も影響力のある技術記事でさえ、必ず反対意見や批判があります。これは多様な視点が存在することの健全な証でもあります。反応せずに見守る勇気を持つ批判的なコメントを見ると、すぐに反論したくなるものです。正直に言えば、「このバカ！ちゃんと記事を読め！」と思うこともあるでしょう。そんな感情を持つのは自然なことです。しかし、インターネット上での議論は感情的になりやすく、さらなる誤解を生むことも。多くの場合、反応しないことが最も賢明な選択です。キーボードから離れて深呼吸し、「本当に返信する価値があるか」を冷静に考えてみましょう。時間が経てば自然と収まることが多いものです。たまには筆を折って、「今日はもうネットを見ない日」を作るのも立派な対処法です。コメントの背景を想像してみる批判的なコメントを残す人の他の発言を見てみると、多くの場合、その人自身の傾向が見えてきます。常に批判的なコメントを残している人もいれば、特定のトピックに強い感情を持っている人もいます。「これはその人の反応パターンなのだ」と理解すれば、個人的な攻撃と受け取らずに済みます。時には「この人、今日はどうしたんだろう？仕事で嫌なことでもあったのかな？」と想像してみるのも手です。多くの批判的コメントは、あなたの記事そのものよりも、コメントした人のその日の気分や状況から生まれていることもあるのです。批判的なコメントをパブリックな場に書く人のほとんどは想像力が欠如しているのでその言葉で他人が傷つくということをほとんど何も考えていないです。実際に会うと優しかったりもします。でも、親切にスルーすることが、時には最大の優しさかもしれません。誤解には丁寧な補足を明らかな誤解に基づいた批判が多い場合は、記事に追記や修正を加えるのが効果的です。「追記：いくつかコメントをいただき、この点が誤解を招いているようなので補足します」といった形で、丁寧に説明すると良いでしょう。個別のコメントに反論するよりも、記事自体を改善する方が建設的です。これは読者全体にとっても価値があり、あなた自身の成長にもつながります。時間の流れを味方にするインターネット上の話題は移り変わりが早いものです。今日の論争も、明日には忘れられていることがほとんどです。一時的な批判に過度に反応するよりも、次の記事作成に前向きに取り組む方が、長期的には実りある選択となるでしょう。実際に「nwiizoさんの記事は役に立ちました」と声をかけられることはあっても、「お前の記事はクソだぞ」と直接言ってくる人は珍しいものです(私もそれぐらい強烈な論を発したいものです)。批判は匿名の場で、称賛は直接あなたに届くという不思議な法則があります。そして、真っ当な批判からは学び、感情的な批判は「私はそれだけの反応を引き出せるだけの影響力を持っているんだ」と前向きに捉える余裕を持ちましょう。ブログ公開の場の選択ブログを書く場所の選択は、思っているより重要な決断です。それぞれの場には一長一短があり、あなたの目的によって最適な選択肢は異なります。技術特化型プラットフォーム技術者向けのプラットフォームは、すでに技術に興味のある読者が集まっているという利点があります。初めから技術的な話題を求めている読者にリーチしやすく、専門的な議論が生まれやすい環境です。一方で、プラットフォームのルールやコミュニティの雰囲気に合わせる必要があり、自由度はやや制限されます。また、特定の技術コミュニティでは賛否両論が起きやすいトピックもあります。汎用ブログプラットフォームより幅広い読者層にアクセスできる汎用プラットフォームは、技術と非技術の境界領域の話題に適しています。テクニカルな内容を非エンジニアに伝えたい場合や、キャリアや働き方など、技術に付随する話題を扱いたい場合に向いています。ただし、深く技術的な内容は響く読者が少なく、反応が薄くなる可能性もあります。自前のブログ自分のドメインで運用するブログは、完全な自由度とブランディングの利点があります。長期的に見れば最も資産価値が高く、あなたのキャリアと共に育てていけるものになります。しかし、読者を集めるための工夫や継続的なメンテナンスが必要で、特に始めたばかりの頃は「誰も読んでいない」という状況に直面することも。SEO対策やSNSでの拡散など、追加の努力が求められます。プラットフォーム選びのアドバイス最初は低いハードルで始められる技術特化型プラットフォームでスタートし、書く習慣が身についてきたら自前のブログも並行して運用するというアプローチが現実的です。どのプラットフォームを選ぶにしても、コンテンツの所有権やエクスポート機能について確認しておくことをお勧めします。いつか別の場所に移行したいと思ったとき、あなたの資産を持ち出せるかどうかは重要な要素です。継続のための現実的なアプローチ技術ブログを一度書くことは難しくない。難しいのは書き続けることだ。以下は実践的な継続のコツだ。小さなハードルから始めるブログ執筆を習慣化するには、負荷を最小限に抑えることが重要です。月1回、あるいは四半期に1回といった現実的な頻度設定から始めましょう。15分でも執筆時間を確保できれば、少しずつ文章は成長していきます。無理な目標設定はモチベーションを消耗させるだけです。自分のための記録として書く「誰も読まないかもしれない」という恐れは、「自分のための記録」という視点で克服できます。将来の自分が参照するための記録として書けば、読者がゼロでも価値があります。実際、多くの技術ブログは、書き手自身が後日参照することで最大の価値を発揮します。「十分に良い」の基準を持つ完璧主義はブログ執筆の最大の敵です。「もっと調査が必要」「もっと洗練された文章にしたい」という思いは尽きませんが、公開されない記事に価値はありません。80%の完成度で公開する勇気を持ちましょう。改善はいつでもできます。このブログも80％ぐらいの完成度で公開してます(本当に)。終わりに技術の世界では、私たちは常に何かの「初心者」であり続けます。むしろ「初心者」であるべきです。新しい言語、新しいフレームワーク、新しいパラダイム—学びに終わりはありません。ベテランエンジニアでさえ、新技術の前では「初心者」に戻るのです。だからこそ、どの経験レベルの視点も価値があります。思い出してみてください。あなたが最初にプログラミングを学んだ時の興奮を。新しいフレームワークに触れた時の発見の喜びを。バグを解決した時の達成感を。これらはすべて、記録する価値のある体験です。そして、どの瞬間においても、あなたの「今」の視点は誰かにとって貴重な道標になります。完璧なブログではなく、あなたの観察と経験を率直に記録したブログこそが、同じ道を歩む誰かの力になるのです。いま書き始めることで、あなたは単なる技術の消費者から、コミュニティに貢献する創造者へと変わることができます。ブログは、知識の完成形を示すものではなく、思考の過程を記録するものです。あなたの躓きと発見の記録が、誰かの旅路を照らす灯になるでしょう。そして、その灯は時間が経っても消えることなく、未来の誰かを導き続けます。書くことで得られるのは、他者への貢献だけではありません。自分自身の思考を整理し、知識を定着させ、キャリアを形作っていく力にもなります。数年後、あなたが書いた記事の蓄積を振り返った時、そこには自分の成長の軌跡が鮮明に記録されているでしょう。継続のコツは「完璧を目指さない」ことです。まずは短く、1回15分でも書ける小さなテーマから始めましょう。また、定期的に書く習慣をつけるために、特定の曜日や時間帯を決めておくと効果的です。そして何より、自分自身が「書いていて楽しい」と感じられるトピックを選ぶことが長続きの秘訣です。技術ブログの世界では、読者からのフィードバックが得られることも大きな魅力です。あなたの記事に寄せられたコメントや質問から、新たな気づきを得ることもあるでしょう。それは、一人では辿り着けなかった視点や解決策との出会いかもしれません。今日から始めてみませんか？ 最初は小さな記事でいいのです。今週解決した問題について、新しく学んだツールの使い方、チームでの取り組みから得た気づき、読んだ技術書の要点と感想、あなたのチームが採用している開発プロセス、先輩から学んだテクニックなど、あなたの日常には書くべき価値のあるトピックがきっと溢れています。あなたの最初の記事は、誰かの最初の一歩を助ける光となるかもしれません。そして、書き続けることで、あなた自身も技術の世界でより深く、より遠くまで進んでいけるでしょう。書き始めることに価値があります。あなただけの観察眼で捉えた技術の風景を、今日から記録してみませんか。その一歩が、あなたのキャリアと技術コミュニティの未来を、より豊かなものにするはずです。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—これが、技術ブログの本当の姿だと思っています。さあ、あなたの最初の記事を、今週ぐらいに書いてみませんか？プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon本気(マジ)の話これは本気で言っているのですが今回は流石にめちゃくちゃに良いブログだと思うので欲しいものリストを公開します。www.amazon.jp]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[gopass を使ってパスワード共有を試す]]></title>
            <link>https://blog.1q77.com/2025/03/share-password-using-gopass/</link>
            <guid>https://blog.1q77.com/2025/03/share-password-using-gopass/</guid>
            <pubDate>Sat, 29 Mar 2025 00:57:32 GMT</pubDate>
            <content:encoded><![CDATA[gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fish 4のabbrはサブコマンドも展開できるぞ]]></title>
            <link>https://blog.atusy.net/2025/03/29/fish-4-abbr/</link>
            <guid>https://blog.atusy.net/2025/03/29/fish-4-abbr/</guid>
            <pubDate>Sat, 29 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishのabbr使ってますか？aliasの強化版といった感じで、短縮した入力をスペースやエンターと共に本来のコマンドに展開してくれる機能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリのサンプルコードから学ぶ活用法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</guid>
            <pubDate>Fri, 28 Mar 2025 04:28:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の「Rust製MCPライブラリの内部実装を徹底解析」では、Model Context Protocol (MCP) のRust SDKの内部実装について詳しく解説しました。今回は、その続編として、examples/ディレクトリに含まれるサンプルコードを詳しく見ていきます。github.comMCPを実際のプロジェクトで活用するためには、抽象的な実装だけでなく、具体的な使用例を理解することが重要です。このブログでは、クライアント実装、サーバー実装、マクロの使用例を通じて、MCPの実践的な活用方法を学び、実際に自分で実装できるようになることを目指します。概念が分からない人や自分の他のブログを読みたいくない人はこちらのドキュメントを一読してから読んでほしいです。modelcontextprotocol.ioexamples/の全体構造MCPのRust SDKには豊富なサンプルが含まれています。examples/ディレクトリは以下のような構成になっています。examples/├── clients/        # クライアント実装例├── servers/        # サーバー実装例├── transport/      # トランスポート実装例├── rig-integration/ # Rigフレームワークとの統合例├── wasi/           # WebAssembly実装例└── README.md       # サンプルの概要それぞれのディレクトリには、特定のユースケースに焦点を当てたサンプルコードが含まれています。これらのサンプルは、MCPの様々な機能や統合シナリオを理解するのに役立ちます。クライアント実装例examples/clients/ディレクトリには、MCPクライアントの様々な実装例が含まれています。これらの例を通じて、異なるシナリオでのMCPクライアントの使い方を学びましょう。基本的なクライアント実装: std_io.rs最も基本的なクライアント実装例はstd_io.rsです。このサンプルは標準入出力を使用してMCPサーバーと通信します。use anyhow::Result;use rmcp::{model::CallToolRequestParam, service::ServiceExt, transport::TokioChildProcess};use tokio::process::Command;use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("info,{}=debug", env!("CARGO_CRATE_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();        // 子プロセスとしてMCPサーバーを起動し、サービスを作成    let service = ()        .serve(TokioChildProcess::new(            Command::new("uvx").arg("mcp-server-git"),        )?)        .await?;    // サーバー情報の取得    let server_info = service.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // 利用可能なツールの一覧取得    let tools = service.list_tools(Default::default()).await?;    tracing::info!("Available tools: {tools:#?}");    // ツールの呼び出し    let tool_result = service        .call_tool(CallToolRequestParam {            name: "git_status".into(),            arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),        })        .await?;    tracing::info!("Tool result: {tool_result:#?}");        // クライアントの終了    service.cancel().await?;    Ok(())}この例での主要な要素を解説します。#[tokio::main]マクロ: Rustの非同期ランタイムを初期化し、非同期コードを実行できるようにします。TokioChildProcess: 子プロセスとしてMCPサーバーを起動するためのトランスポート実装です。この例では「uvx mcp-server-git」コマンドを実行しています。serveメソッド: トランスポートを使ってサービスを初期化するメソッドです。RustのServiceExtトレイトが提供する拡張機能です。call_toolメソッド: 特定のツールを呼び出すメソッドです。CallToolRequestParam構造体を使ってツール名と引数を指定します。SSEトランスポートの使用: sse.rs次に、Server-Sent Events (SSE) トランスポートを使用する例を見てみましょう。これはWebアプリケーションとMCPを統合する際に特に有用です。use anyhow::Result;use rmcp::model::{ClientCapabilities, ClientInfo, Implementation};use rmcp::{ServiceExt, model::CallToolRequestParam, transport::SseTransport};use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化（省略）...    // SSEトランスポートの作成と接続    let transport = SseTransport::start("http://localhost:8000/sse").await?;        // クライアント情報の定義    let client_info = ClientInfo {        protocol_version: Default::default(),        capabilities: ClientCapabilities::default(),        client_info: Implementation {            name: "test sse client".to_string(),            version: "0.0.1".to_string(),        },    };        // クライアントの作成    let client = client_info.serve(transport).await?;    // サーバー情報の取得    let server_info = client.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // ツール一覧の取得（省略）...    // ツールの呼び出し（省略）...        // クライアントの終了    client.cancel().await?;    Ok(())}このサンプルの特徴的な点は：SseTransport: HTTP経由でMCPサーバーと通信するためのトランスポート実装です。長時間接続を維持し、サーバーからのイベントを受信します。ClientInfo: クライアントに関する情報をサーバーに提供する構造体です。名前やバージョン、プロトコル互換性などの情報が含まれます。複数クライアントの管理: collection.rs複数のMCPクライアントを効率的に管理する例も含まれています。use std::collections::HashMap;use anyhow::Result;use rmcp::service::ServiceExt;use rmcp::{model::CallToolRequestParam, transport::TokioChildProcess};use tokio::process::Command;#[tokio::main]async fn main() -> Result<()> {    // ログ初期化は省略...    // 複数クライアントの作成    let mut client_list = HashMap::new();    for idx in 0..10 {        let service = ()            .into_dyn()            .serve(TokioChildProcess::new(                Command::new("uvx").arg("mcp-server-git"),            )?)            .await?;        client_list.insert(idx, service);    }    // 各クライアントの使用    for (_, service) in client_list.iter() {        // サーバー情報の取得        let _server_info = service.peer_info();        // ツール一覧の取得        let _tools = service.list_tools(Default::default()).await?;        // ツールの呼び出し        let _tool_result = service            .call_tool(CallToolRequestParam {                name: "git_status".into(),                arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),            })            .await?;    }        // クライアントのクリーンアップ    for (_, service) in client_list {        service.cancel().await?;    }    Ok(())}この例では、複数のMCPクライアントを作成し、それぞれに対して操作を実行しています。実際のアプリケーションでは、異なるサーバーに接続する複数のクライアントを管理する場合に役立ちます。サーバー実装例examples/servers/ディレクトリには、様々なMCPサーバー実装例が含まれています。ここでは、基本的なサーバー実装と、Webフレームワークとの統合例を見ていきます。基本的なサーバー実装: std_io.rs最もシンプルなサーバー実装はstd_io.rsです。このサンプルは、標準入出力を使用してクライアントとやり取りする基本的なMCPサーバーを実装しています。use anyhow::Result;use common::counter::Counter;use rmcp::{ServiceExt, transport::stdio};use tracing_subscriber::{self, EnvFilter};mod common;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()))        .with_writer(std::io::stderr)        .with_ansi(false)        .init();    tracing::info!("Starting MCP server");    // Counterサービスを作成し、標準入出力トランスポートで提供    let service = Counter::new().serve(stdio()).await?;    // クライアントからの要求を待機    service.waiting().await?;    Ok(())}このサンプルはシンプルですが、重要な要素がいくつか含まれています。Counter型: これはカウンターサービスを提供するサーバーハンドラの実装です。stdio(): 標準入出力をトランスポートとして使用するための関数です。waiting()メソッド: サーバーがクライアントからの要求を待機するためのメソッドです。次に、Counter型の実装を見てみましょう：use std::sync::Arc;use rmcp::{    Error as McpError, RoleServer, ServerHandler, const_string, model::*, schemars,    service::RequestContext, tool,};use tokio::sync::Mutex;#[derive(Clone)]pub struct Counter {    counter: Arc<Mutex<i32>>,}#[tool(tool_box)]impl Counter {    pub fn new() -> Self {        Self {            counter: Arc::new(Mutex::new(0)),        }    }    #[tool(description = "Increment the counter by 1")]    async fn increment(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter += 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Decrement the counter by 1")]    async fn decrement(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter -= 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Get the current counter value")]    async fn get_value(&self) -> Result<CallToolResult, McpError> {        let counter = self.counter.lock().await;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }}#[tool(tool_box)]impl ServerHandler for Counter {    fn get_info(&self) -> ServerInfo {        ServerInfo {            protocol_version: ProtocolVersion::V_2024_11_05,            capabilities: ServerCapabilities::builder()                .enable_tools()                .build(),            server_info: Implementation::from_build_env(),            instructions: Some("This server provides a counter tool...".to_string()),        }    }        // その他の実装は省略...}このCounter実装の重要な点：#[tool(tool_box)]マクロ: これは、メソッドを自動的にMCPツールとして登録するマクロです。これにより、ボイラープレートコードが大幅に削減されます。#[tool(description = "...")]マクロ: 各メソッドにツールの説明を追加します。この情報はクライアントに公開され、ツールの使用方法を理解するのに役立ちます。Arc<Mutex<i32>>: スレッド間で安全にカウンター値を共有するためのラッパーです。これは、Rustの並行性プリミティブの典型的な使用例です。Axumフレームワークとの統合: axum.rsより高度な例として、Axum WebフレームワークとMCPサーバーを統合した例を見てみましょう。use rmcp::transport::sse_server::SseServer;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};mod common;use common::counter::Counter;const BIND_ADDRESS: &str = "127.0.0.1:8000";#[tokio::main]async fn main() -> anyhow::Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| "debug".to_string().into()),        )        .with(tracing_subscriber::fmt::layer())        .init();    // SSEサーバーの起動とカウンターサービスの設定    let ct = SseServer::serve(BIND_ADDRESS.parse()?)        .await?        .with_service(Counter::new);    // Ctrl+Cで終了するまで待機    tokio::signal::ctrl_c().await?;    ct.cancel();    Ok(())}このサンプルの特徴的な点：SseServer::serve: AxumフレームワークをベースにしたSSEサーバーを起動する関数です。これにより、ブラウザからMCPサーバーにアクセスできるようになります。with_service: サービスファクトリを指定するメソッドです。この例ではCounter::new関数をファクトリとして使用しています。tokio::signal::ctrl_c().await?: Ctrl+Cシグナルを受け取るまで待機します。これにより、サーバーはバックグラウンドで動作し続けます。Webフレームワーク統合のポイントWebフレームワーク（Axum、Actix Webなど）とMCPを統合する際のポイント：適切なトランスポート（SSEなど）を選択するセッション管理を適切に行うエラーハンドリングを丁寧に実装するサーバーのライフサイクルを適切に管理するマクロ使用例examples/macros/ディレクトリには、MCPマクロを使用してツールを簡単に定義する例が含まれています。これらのマクロは、ボイラープレートコードを大幅に削減し、MCPサーバーの実装を容易にします。計算機ツールの実装calculator.rsは、#[tool]マクロを使用して計算機ツールを実装する例です。use mcp_core::handler::{ToolError, ToolHandler};use mcp_macros::tool;#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}#[tokio::main]async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {    // ツールのインスタンスを作成    let calculator = Calculator;    // ツール情報の出力    println!("Tool name: {}", calculator.name());    println!("Tool description: {}", calculator.description());    println!("Tool schema: {}", calculator.schema());    // サンプル入力でツールをテスト    let input = serde_json::json!({        "x": 5,        "y": 3,        "operation": "multiply"    });    let result = calculator.call(input).await?;    println!("Result: {}", result);    Ok(())}このサンプルの素晴らしい点：宣言的なツール定義: #[tool]マクロを使うことで、通常の関数にメタデータを追加するだけでMCPツールを定義できます。パラメータドキュメント: params(x = "First number...")のように、パラメータの説明をマクロ内で定義できます。これにより、自己文書化されたAPIが作成されます。型安全: 関数の引数型（i32, Stringなど）を利用して型安全なパラメータを定義します。Rustのコンパイラが型チェックを行うため、型関連のバグを防ぐことができます。マクロの活用術マクロを効果的に使用するためのポイント：適切な名前と説明を提供して、ツールの目的を明確にするパラメータに詳細な説明を追加して、ユーザーが正しい値を入力できるようにする複雑なパラメータには構造体を使用し、#[tool(aggr)]アノテーションで集約するエラーハンドリングを丁寧に行い、具体的なエラーメッセージを提供するトランスポート実装例examples/transport/ディレクトリには、様々なトランスポート実装例が含まれています。トランスポートは、MCPクライアントとサーバーの通信方法を定義します。TCPトランスポートtcp.rsは、TCP接続を使用してMCPメッセージを送受信する例です。use common::calculator::Calculator;use rmcp::{serve_client, serve_server};mod common;#[tokio::main]async fn main() -> anyhow::Result<()> {    tokio::spawn(server());    client().await?;    Ok(())}async fn server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    while let Ok((stream, _)) = tcp_listener.accept().await {        tokio::spawn(async move {            let server = serve_server(Calculator, stream).await?;            server.waiting().await?;            anyhow::Ok(())        });    }    Ok(())}async fn client() -> anyhow::Result<()> {    let stream = tokio::net::TcpSocket::new_v4()?        .connect("127.0.0.1:8001".parse()?)        .await?;    let client = serve_client((), stream).await?;    let tools = client.peer().list_tools(Default::default()).await?;    println!("{:?}", tools);    Ok(())}このサンプルでは：非同期I/O: tokioの非同期I/O機能を使用して、ブロッキングせずに複数の接続を処理します。serve_serverとserve_client: これらは便利なヘルパー関数で、トランスポートをサーバーまたはクライアントとして設定します。並行接続処理: tokio::spawnを使って各接続を別々のタスクで処理し、サーバーのスケーラビリティを確保しています。WebSocketトランスポートwebsocket.rsは、WebSocket接続を使用したMCPトランスポートの例です。async fn http_client(uri: &str) -> anyhow::Result<RunningService<RoleClient, ()>> {    let (stream, response) = tokio_tungstenite::connect_async(uri).await?;    if response.status() != tungstenite::http::StatusCode::SWITCHING_PROTOCOLS {        return Err(anyhow::anyhow!("failed to upgrade connection"));    }    let transport = WebsocketTransport::new_client(stream);    let client = ().serve(transport).await?;    Ok(client)}async fn start_server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    tokio::spawn(async move {        while let Ok((stream, addr)) = tcp_listener.accept().await {            tracing::info!("accepted connection from: {}", addr);            tokio::spawn(async move {                let ws_stream = tokio_tungstenite::accept_async(stream).await?;                let transport = WebsocketTransport::new_server(ws_stream);                let server = Calculator.serve(transport).await?;                server.waiting().await?;                Ok::<(), anyhow::Error>(())            });        }    });    Ok(())}このサンプルでは：WebSocketプロトコル: HTTPからWebSocketにアップグレードする処理が含まれています。カスタムトランスポート実装: WebsocketTransportとしてカスタムトランスポートが実装されています。接続管理: 接続の確立からサーバー待機までの一連のフローが示されています。トランスポート選択のポイント適切なトランスポートを選択するためのポイント：用途に合わせて選択する:標準入出力（stdio）: コマンドラインツールや子プロセスSSE: Webブラウザとのリアルタイム通信TCP: ネットワーク上のサービス間通信WebSocket: 双方向リアルタイム通信Unix Socket: 同一マシン上のプロセス間通信セキュリティを考慮する: 公開ネットワークで使用する場合はTLSなどの暗号化を検討パフォーマンスを考慮する: 大量のデータや頻繁な通信がある場合は効率的なトランスポートを選択応用パターンとベストプラクティスMCPを実装する際の応用パターンとベストプラクティスをいくつか紹介します。エラーハンドリング具体的なエラーメッセージ: クライアントが問題を理解できるよう、具体的なエラーメッセージを提供します。   Err(ToolError::InvalidParameters(format!(       "Unknown operation: {}. Supported operations are: add, subtract, multiply, divide",       operation   )))エラー変換: 低レベルエラーを適切なMCPエラーに変換します。   async fn read_file(&self, path: String) -> Result<CallToolResult, McpError> {       let content = tokio::fs::read_to_string(path)           .await           .map_err(|e| McpError::tool_execution_error(               "file_read_error",               Some(serde_json::json!({ "error": e.to_string() }))           ))?;              Ok(CallToolResult::success(vec![Content::text(content)]))   }非同期処理適切なタスク管理: 長時間実行される処理は別タスクに分離し、クライアントをブロックしないようにします。   #[tool(description = "Run a long process")]   async fn run_long_process(&self) -> Result<CallToolResult, McpError> {       // 別タスクでバックグラウンド処理を開始       let task_id = self.start_background_task().await?;              // タスクIDを即座に返す       Ok(CallToolResult::success(vec![Content::text(format!(           "Task started with ID: {}", task_id       ))]))   }      // 別のツールでタスク状態を確認できるようにする   #[tool(description = "Check task status")]   async fn check_task_status(&self, #[tool(param)] task_id: String) -> Result<CallToolResult, McpError> {       // ...   }タイムアウト管理: 長時間の操作にはタイムアウトを設定します。   let result = tokio::time::timeout(       Duration::from_secs(30),       some_long_operation()   ).await.map_err(|_| McpError::tool_execution_error(       "operation_timeout",       Some(serde_json::json!({"message": "Operation timed out after 30 seconds"}))   ))??;リソース管理共有状態の適切な管理: Arc<Mutex<T>>やArc<RwLock<T>>を使用して、スレッド間で状態を安全に共有します。リソースのクリーンアップ: Dropトレイトを実装して、リソースが確実に解放されるようにします。コネクション管理: クライアント接続を適切に管理し、リソースリークを防ぎます。実際の使用例：LLMとの統合MCPはLLM（大規模言語モデル）に外部ツールへのアクセスを提供するために設計されています。ここでは、LLMとMCPの統合例を見てみましょう。examples/rig-integration/ディレクトリには、Rigフレームワーク（LLMアプリケーションフレームワーク）とMCPの統合例が含まれています。// MCPツールをRigのツールとして適応させるアダプタpub struct McpToolAdaptor {    tool: McpTool,    server: ServerSink,}impl RigTool for McpToolAdaptor {    fn name(&self) -> String {        self.tool.name.to_string()    }    fn definition(        &self,        _prompt: String,    ) -> std::pin::Pin<Box<dyn Future<Output = rig::completion::ToolDefinition> + Send + Sync + '_>>    {        Box::pin(std::future::ready(rig::completion::ToolDefinition {            name: self.name(),            description: self.tool.description.to_string(),            parameters: self.tool.schema_as_json_value(),        }))    }    fn call(        &self,        args: String,    ) -> std::pin::Pin<        Box<dyn Future<Output = Result<String, rig::tool::ToolError>> + Send + Sync + '_>,    > {        let server = self.server.clone();        Box::pin(async move {            let call_mcp_tool_result = server                .call_tool(CallToolRequestParam {                    name: self.tool.name.clone(),                    arguments: serde_json::from_str(&args)                        .map_err(rig::tool::ToolError::JsonError)?,                })                .await                .map_err(|e| rig::tool::ToolError::ToolCallError(Box::new(e)))?;            Ok(convert_mcp_call_tool_result_to_string(call_mcp_tool_result))        })    }}このアダプタは、MCPツールをRigフレームワークのツールとして使用できるようにします。これにより、LLMとMCPサーバーをシームレスに統合することができます。WASI (WebAssembly System Interface) 対応examples/wasi/ディレクトリには、WebAssemblyでMCPサーバーを実装する例が含まれています。これにより、ブラウザやエッジコンピューティング環境でMCPサーバーを実行できます。// wasi/src/lib.rsstruct TokioCliRunner;impl wasi::exports::cli::run::Guest for TokioCliRunner {    fn run() -> Result<(), ()> {        let rt = tokio::runtime::Builder::new_current_thread()            .enable_all()            .build()            .unwrap();        rt.block_on(async move {            tracing_subscriber::fmt()                .with_env_filter(                    EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()),                )                .with_writer(std::io::stderr)                .with_ansi(false)                .init();            let server = calculator::Calculator.serve(wasi_io()).await.unwrap();            server.waiting().await.unwrap();        });        Ok(())    }}wasi::cli::command::export!(TokioCliRunner);WASI環境でMCPサーバーを実行することで、セキュリティやポータビリティが向上し、より多くの環境でMCPを活用できるようになります。まとめMCPのRust SDKには、様々なユースケースに対応するための豊富なサンプルコードが含まれています。これらのサンプルを理解し、実際に試すことで、MCPを活用したアプリケーションの開発スキルを向上させることができます。この記事でカバーした主なポイント：クライアント実装: 基本的なクライアント、SSEトランスポートの使用、複数クライアントの管理サーバー実装: 基本的なサーバー、ツールボックスとマクロの活用、Webフレームワークとの統合トランスポート実装: TCP、WebSocket、Unix Socketなどの様々なトランスポート応用パターン: エラーハンドリング、非同期処理、リソース管理のベストプラクティスLLM統合: Rigフレームワークを使ったLLMとMCPの統合例MCPはまだ比較的新しいプロトコルですが、AIとツールの統合に関する標準化に大きな可能性を秘めています。Rustの強力な型システムと安全性の恩恵を受けながら、MCPの機能を最大限に活用しましょう。生成AIについて興味があればこちらも読んでみてもらいたいです。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nvidia/cuda imageを使ってDockerコンテナでGPUを使用する]]></title>
            <link>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</link>
            <guid>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</guid>
            <pubDate>Thu, 27 Mar 2025 04:33:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリの内部実装を徹底解析]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</guid>
            <pubDate>Thu, 27 Mar 2025 03:16:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに最近注目を集めているModel Context Protocol（MCP）は、大規模言語モデル（LLM）に外部ツールやサービスへのアクセス能力を提供するための標準プロトコルです。中でも公式が提供しているRust SDKはあまり注目されていませんが、私自身が必要としているためこのドキュメントを作成します。github.com以前は自前で実装していましたが、公式SDKが公開されたことでそちらを検討するのが良いと考えました。私の実装と比較してかなり洗練されている点が多く、多くの学びを得ることができました。syu-m-5151.hatenablog.comこの記事では、MCP Rust SDKの内部実装を深掘りし、どのようにRustの強力な型システムと非同期プログラミングモデルが活用されているかを解説します。コードの詳細な分析を通して、Rustの優れた設計パターンや実装テクニックを学びましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれるのもありがたいです。MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月27日 現在)。ちなみに今後MCPがどうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioSDKの全体構成 - 明確な関心の分離MCP Rust SDKは、複数のクレートに明確に分離されており、それぞれが特定の責任を担っています。rust-sdk/├── crates/│   ├── mcp-core/      # プロトコルの基本型とインターフェース│   ├── mcp-client/    # クライアント実装│   ├── mcp-server/    # サーバー実装│   └── mcp-macros/    # ツール実装を簡素化するマクロ└── examples/    ├── clients/       # クライアント使用例    ├── servers/       # サーバー実装例    └── macros/        # マクロ使用例この設計はRustエコシステムでよく見られる「関心の分離」パターンに従っています。各クレートがひとつの責任を持ち、依存関係も明確です。こうすることで、メンテナンス性と再利用性が大幅に向上します。特に注目すべきは、コア型定義とプロトコル実装をmcp-coreに分離している点です。これにより、クライアントとサーバーが共通の型定義を使いながら、それぞれ独立して実装・進化できる柔軟性を確保しています。mcp-core: 堅牢な基盤となる型定義mcp-coreクレートは、MCPプロトコルの心臓部とも言える基本型とインターフェースを提供しています。ここでの実装がSDK全体の品質を大きく左右します。JSON-RPCメッセージの巧妙な実装MCPはJSON-RPCプロトコルをベースにしていますが、その実装が非常に興味深いものになっています#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]#[serde(untagged, try_from = "JsonRpcRaw")]pub enum JsonRpcMessage {    Request(JsonRpcRequest),    Response(JsonRpcResponse),    Notification(JsonRpcNotification),    Error(JsonRpcError),    Nil, // used to respond to notifications}#[derive(Debug, Serialize, Deserialize)]struct JsonRpcRaw {    jsonrpc: String,    #[serde(skip_serializing_if = "Option::is_none")]    id: Option<u64>,    #[serde(skip_serializing_if = "Option::is_none")]    method: Option<String>,    #[serde(skip_serializing_if = "Option::is_none")]    params: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    result: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    error: Option<ErrorData>,}impl TryFrom<JsonRpcRaw> for JsonRpcMessage {    type Error = String;    fn try_from(raw: JsonRpcRaw) -> Result<Self, <Self as TryFrom<JsonRpcRaw>>::Error> {        // If it has an error field, it's an error response        if raw.error.is_some() {            return Ok(JsonRpcMessage::Error(JsonRpcError {                jsonrpc: raw.jsonrpc,                id: raw.id,                error: raw.error.unwrap(),            }));        }        // If it has a result field, it's a response        if raw.result.is_some() {            return Ok(JsonRpcMessage::Response(JsonRpcResponse {                jsonrpc: raw.jsonrpc,                id: raw.id,                result: raw.result,                error: None,            }));        }        // If we have a method, it's either a notification or request        if let Some(method) = raw.method {            if raw.id.is_none() {                return Ok(JsonRpcMessage::Notification(JsonRpcNotification {                    jsonrpc: raw.jsonrpc,                    method,                    params: raw.params,                }));            }            return Ok(JsonRpcMessage::Request(JsonRpcRequest {                jsonrpc: raw.jsonrpc,                id: raw.id,                method,                params: raw.params,            }));        }        // If we have no method and no result/error, it's a nil response        if raw.id.is_none() && raw.result.is_none() && raw.error.is_none() {            return Ok(JsonRpcMessage::Nil);        }        // If we get here, something is wrong with the message        Err(format!(            "Invalid JSON-RPC message format: id={:?}, method={:?}, result={:?}, error={:?}",            raw.id, raw.method, raw.result, raw.error        ))    }}この実装の素晴らしい点は3つあります。#[serde(untagged)]アノテーションの活用：JSONデータの構造に基づいて適切な列挙型バリアントに自動的にデシリアライズします。これにより、外部向けのJSONはシンプルな形式を維持できます。try_from = "JsonRpcRaw"による変換の分離：複雑な変換ロジックを別の型に委譲し、コードの見通しを良くしています。これはRustの型システムを活用した優れたパターンです。段階的な判断ロジック：各メッセージタイプの判定条件を明確にし、順番に評価することで複雑な条件分岐を読みやすく実装しています。これらの工夫により、複雑なJSON-RPCプロトコルの処理を堅牢かつ読みやすいコードで実現しています。特に注目すべきは、Rustの型システムを最大限に活用し、コンパイル時の型チェックでバグを防ぐ設計になっている点です。豊かなコンテンツ型システムMCPはさまざまなコンテンツ型（テキスト、画像、リソースなど）をサポートしています。その実装も非常に洗練されています。#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]#[serde(tag = "type", rename_all = "camelCase")]pub enum Content {    Text(TextContent),    Image(ImageContent),    Resource(EmbeddedResource),}impl Content {    pub fn text<S: Into<String>>(text: S) -> Self {        Content::Text(TextContent {            text: text.into(),            annotations: None,        })    }    pub fn image<S: Into<String>, T: Into<String>>(data: S, mime_type: T) -> Self {        Content::Image(ImageContent {            data: data.into(),            mime_type: mime_type.into(),            annotations: None,        })    }    pub fn resource(resource: ResourceContents) -> Self {        Content::Resource(EmbeddedResource {            resource,            annotations: None,        })    }    // その他のメソッド...}この実装には、使いやすさと型安全性を両立する工夫がいくつもあります。タグ付き列挙型の活用：#[serde(tag = "type")]は、JSONに「type」フィールドを追加し、その値に基づいて適切な型にデシリアライズします。これはJSONとRustの型を自然にマッピングする優れた方法です。ファクトリメソッド：text(), image(), resource()などのメソッドは、わかりやすい方法でコンテンツを作成できるようにしています。これは、制約を守りながら簡潔にオブジェクトを作成するのに役立ちます。ジェネリックな引数：S: Into<String>のようなトレイト境界を使うことで、文字列リテラル、String、&strなど、さまざまな文字列型を引数として受け入れることができます。これは使い勝手を大幅に向上させます。この設計は、使いやすいAPIと堅牢な内部実装のバランスが見事です。とりわけ、列挙型とそのバリアントを活用してドメインの概念を表現する点はRustらしいアプローチと言えるでしょう。mcp-client: 柔軟なトランスポートと抽象化mcp-clientクレートは、MCPサーバーとの通信を担当します。特に注目すべきは、トランスポート層の抽象化です。トランスポートの抽象化MCPサーバーとの通信には複数の方法（標準入出力、HTTP、WebSocketなど）が考えられます。このSDKはそれらを抽象化するための優れた設計を採用しています。/// A message that can be sent through the transport#[derive(Debug)]pub struct TransportMessage {    /// The JSON-RPC message to send    pub message: JsonRpcMessage,    /// Channel to receive the response on (None for notifications)    pub response_tx: Option<oneshot::Sender<Result<JsonRpcMessage, Error>>>,}/// A generic asynchronous transport trait with channel-based communication#[async_trait]pub trait Transport {    type Handle: TransportHandle;    /// Start the transport and establish the underlying connection.    /// Returns the transport handle for sending messages.    async fn start(&self) -> Result<Self::Handle, Error>;    /// Close the transport and free any resources.    async fn close(&self) -> Result<(), Error>;}#[async_trait]pub trait TransportHandle: Send + Sync + Clone + 'static {    async fn send(&self, message: JsonRpcMessage) -> Result<JsonRpcMessage, Error>;}この抽象化にはいくつもの巧妙な工夫があります。関連型（associated type）の活用：type Handle: TransportHandleという関連型を使うことで、トランスポートとそのハンドルを型レベルで紐づけています。これにより、異なるトランスポート実装が異なるハンドル型を持つことができます。非同期トレイト：#[async_trait]マクロを使って、非同期メソッドをトレイトに含められるようにしています。これは標準のRustでは直接サポートされていない機能です。分離された開始と通信：startメソッドで接続を確立し、その結果として得られるハンドルを使って通信するという2段階のパターンを採用しています。これにより、接続のライフサイクルとメッセージ送受信を明確に分離できます。このような抽象化により、新しいトランスポート実装を追加するのが容易になりますし、クライアント側のコードはトランスポートの詳細を気にせず書けるようになります。StdioTransportの実装標準入出力を使ったトランスポート実装も見てみましょう：pub struct StdioTransport {    command: String,    args: Vec<String>,    env: HashMap<String, String>,}impl StdioTransport {    pub fn new<S: Into<String>>(        command: S,        args: Vec<String>,        env: HashMap<String, String>,    ) -> Self {        Self {            command: command.into(),            args,            env,        }    }    async fn spawn_process(&self) -> Result<(Child, ChildStdin, ChildStdout, ChildStderr), Error> {        let mut command = Command::new(&self.command);        command            .envs(&self.env)            .args(&self.args)            .stdin(std::process::Stdio::piped())            .stdout(std::process::Stdio::piped())            .stderr(std::process::Stdio::piped())            .kill_on_drop(true);        // Set process group only on Unix systems        #[cfg(unix)]        command.process_group(0); // don't inherit signal handling from parent process        // Hide console window on Windows        #[cfg(windows)]        command.creation_flags(0x08000000); // CREATE_NO_WINDOW flag        let mut process = command            .spawn()            .map_err(|e| Error::StdioProcessError(e.to_string()))?;        let stdin = process            .stdin            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdin".into()))?;        let stdout = process            .stdout            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdout".into()))?;        let stderr = process            .stderr            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stderr".into()))?;        Ok((process, stdin, stdout, stderr))    }}この実装の素晴らしい点を見てみましょう：プラットフォーム固有の最適化：#[cfg(unix)]と#[cfg(windows)]を使って、各OSに最適な設定を行っています。これはRustの条件付きコンパイルの機能をうまく活用した例です。リソース管理：kill_on_drop(true)を使って、オブジェクトが破棄された時に子プロセスも確実に終了するよう保証しています。これはリソースリークを防ぐための重要な安全策です。エラーハンドリング：ok_or_elseのような関数を使って、エラーケースを明確に処理しています。これにより、どのような状況でもプログラムが予測可能な動作をするようになります。この実装は、複雑な子プロセス操作を安全かつ効率的に行うための優れた例です。特に、クロスプラットフォームな動作を保証するための配慮が随所に見られます。クライアント本体の実装最後に、クライアント本体の実装を見てみましょう：pub struct McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    service: Mutex<S>,    next_id: AtomicU64,    server_capabilities: Option<ServerCapabilities>,    server_info: Option<Implementation>,}impl<S> McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    pub fn new(service: S) -> Self {        Self {            service: Mutex::new(service),            next_id: AtomicU64::new(1),            server_capabilities: None,            server_info: None,        }    }    /// Send a JSON-RPC request and check we don't get an error response.    async fn send_request<R>(&self, method: &str, params: Value) -> Result<R, Error>    where        R: for<'de> Deserialize<'de>,    {        let mut service = self.service.lock().await;        service.ready().await.map_err(|_| Error::NotReady)?;        let id = self.next_id.fetch_add(1, Ordering::SeqCst);        let request = JsonRpcMessage::Request(JsonRpcRequest {            jsonrpc: "2.0".to_string(),            id: Some(id),            method: method.to_string(),            params: Some(params.clone()),        });        let response_msg = service            .call(request)            .await            .map_err(|e| Error::McpServerError {                server: self                    .server_info                    .as_ref()                    .map(|s| s.name.clone())                    .unwrap_or("".to_string()),                method: method.to_string(),                // we don't need include params because it can be really large                source: Box::new(e.into()),            })?;        // ... レスポンス処理 ...    }}この実装には、Rustの現代的な非同期プログラミング技術が凝縮されています。Tower Serviceの活用：低レベルのトランスポート詳細を抽象化するために、Tower crateのServiceトレイトを使用しています。これはミドルウェアの組み合わせや機能拡張を容易にします。ジェネリックな戻り値型：send_request<R>のようなジェネリック関数を使って、様々な型のレスポンスを受け取れるようにしています。これはクライアントAPIを使いやすくする工夫です。スレッドセーフなカウンター：AtomicU64を使って、スレッドセーフなID生成を実現しています。これは並行処理を安全に行うための基本的なテクニックです。非同期排他制御：Mutex<S>を使って、非同期コンテキストでのサービスアクセスを管理しています。tokio::sync::Mutexはブロッキングせずに排他制御を行える優れたプリミティブです。これらの機能を組み合わせることで、堅牢で効率的、かつ使いやすいクライアントAPIを実現しています。特にTowerのサービス抽象化を活用することで、将来的な拡張性も確保されています。mcp-server: モジュラーなサーバー設計mcp-serverクレートは、MCPサーバーをRustで実装するためのフレームワークを提供しています。ここでもいくつか興味深い実装が見られます。ByteTransportの実装#[pin_project]pub struct ByteTransport<R, W> {    // Reader is a BufReader on the underlying stream (stdin or similar) buffering    // the underlying data across poll calls, we clear one line (\n) during each    // iteration of poll_next from this buffer    #[pin]    reader: BufReader<R>,    #[pin]    writer: W,}impl<R, W> ByteTransport<R, W>where    R: AsyncRead,    W: AsyncWrite,{    pub fn new(reader: R, writer: W) -> Self {        Self {            // Default BufReader capacity is 8 * 1024, increase this to 2MB to the file size limit            // allows the buffer to have the capacity to read very large calls            reader: BufReader::with_capacity(2 * 1024 * 1024, reader),            writer,        }    }}impl<R, W> Stream for ByteTransport<R, W>where    R: AsyncRead + Unpin,    W: AsyncWrite + Unpin,{    type Item = Result<JsonRpcMessage, TransportError>;    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {        // Poll実装...    }}この実装には、Rustの非同期I/Oに関する高度な知識が詰まっています。巨大なバッファサイズ：デフォルトの8KBではなく2MBという大きなバッファを使用し、大量のデータを効率的に処理できるようにしています。これは実際のユースケースに基づく現実的な最適化でしょう。pin-projectの活用：非同期処理でピン留めが必要なフィールドを持つ構造体を安全に扱うために、pin-projectクレートを使用しています。これは非同期Rustの複雑な問題を解決するための定石です。Streamトレイトの実装：Streamトレイトを実装することで、メッセージを非同期ストリームとして扱えるようにしています。これは非同期処理パターンとの自然な統合を可能にします。このようなトランスポート実装により、サーバーは効率的に大量のメッセージを処理できるようになります。また、バッファ管理や非同期I/Oの複雑さは抽象化されるため、上位層のコードはビジネスロジックに集中できます。優れたRouterトレイトMCPサーバーの中核となるのがRouterトレイトです。pub trait Router: Send + Sync + 'static {    fn name(&self) -> String;    fn instructions(&self) -> String;    fn capabilities(&self) -> ServerCapabilities;    fn list_tools(&self) -> Vec<mcp_core::tool::Tool>;    fn call_tool(        &self,        tool_name: &str,        arguments: Value,    ) -> Pin<Box<dyn Future<Output = Result<Vec<Content>, ToolError>> + Send + 'static>>;    fn list_resources(&self) -> Vec<mcp_core::resource::Resource>;    fn read_resource(        &self,        uri: &str,    ) -> Pin<Box<dyn Future<Output = Result<String, ResourceError>> + Send + 'static>>;    fn list_prompts(&self) -> Vec<Prompt>;    fn get_prompt(&self, prompt_name: &str) -> PromptFuture;    // 以下はデフォルト実装を持つヘルパーメソッド    fn create_response(&self, id: Option<u64>) -> JsonRpcResponse { ... }    fn handle_initialize(&self, req: JsonRpcRequest) -> impl Future<Output = Result<JsonRpcResponse, RouterError>> + Send { ... }    // その他のハンドラメソッド...}この設計の素晴らしさは以下の点にあります。最小限の実装要件：ユーザーが実装すべきメソッドは基本的な機能に限られており、複雑なプロトコル処理はデフォルト実装として提供されています。これにより、ルーターの実装がシンプルになり、ドメインロジックに集中できます。Futureを返すメソッド：ツール呼び出しなどの処理は非同期で行われるケースが多いため、Pin<Box<dyn Future<...>>>を返すメソッドになっています。これにより、実装者は任意の非同期処理を行う自由を持ちます。明確なトレイト境界：Send + Sync + 'staticという境界により、マルチスレッド環境での使用を安全に行えるようになっています。これは実際のサーバー環境では不可欠な制約です。この設計は、「使いやすさ」と「柔軟性」のバランスがとれた素晴らしい例です。初心者でも簡単に基本的なルーターを実装できますが、高度なユースケースに対応する拡張性も備えています。RouterServiceの実装pub struct RouterService<T>(pub T);impl<T> Service<JsonRpcRequest> for RouterService<T>where    T: Router + Clone + Send + Sync + 'static,{    type Response = JsonRpcResponse;    type Error = BoxError;    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {        Poll::Ready(Ok(()))    }    fn call(&mut self, req: JsonRpcRequest) -> Self::Future {        let this = self.0.clone();        Box::pin(async move {            let result = match req.method.as_str() {                "initialize" => this.handle_initialize(req).await,                "tools/list" => this.handle_tools_list(req).await,                "tools/call" => this.handle_tools_call(req).await,                "resources/list" => this.handle_resources_list(req).await,                "resources/read" => this.handle_resources_read(req).await,                "prompts/list" => this.handle_prompts_list(req).await,                "prompts/get" => this.handle_prompts_get(req).await,                _ => {                    let mut response = this.create_response(req.id);                    response.error = Some(RouterError::MethodNotFound(req.method).into());                    Ok(response)                }            };            result.map_err(BoxError::from)        })    }}この実装は、デザインパターンの「アダプターパターン」を思わせる優れた例です。シンプルなラッパー型：RouterService<T>(pub T)というシンプルな新型でRouterトレイトをTowerのServiceトレイトに適応させています。これは非常にエレガントなアプローチです。メソッドディスパッチ：リクエストのmethod文字列に基づいて適切なハンドラメソッドに処理をディスパッチしています。これはルーティングのための直感的で効率的な実装です。Clone要件：非同期クロージャ内でルーターを使用するためにCloneトレイト境界を要求しています。これにより、所有権の問題を簡単に解決できます。このようなラッパー型とディスパッチロジックにより、開発者はRouterトレイトの実装に集中でき、ServiceやTowerのような低レベルの詳細を気にする必要がなくなります。これは抽象化の良い例です。mcp-macros: 宣言的ツール定義の魔法最後に、mcp-macrosクレートの中核である#[tool]マクロを見てみましょう：#[proc_macro_attribute]pub fn tool(args: TokenStream, input: TokenStream) -> TokenStream {    let args = parse_macro_input!(args as MacroArgs);    let input_fn = parse_macro_input!(input as ItemFn);    // Extract function details    let fn_name = &input_fn.sig.ident;    let fn_name_str = fn_name.to_string();    // Generate PascalCase struct name from the function name    let struct_name = format_ident!("{}", { fn_name_str.to_case(Case::Pascal) });    // Use provided name or function name as default    let tool_name = args.name.unwrap_or(fn_name_str);    let tool_description = args.description.unwrap_or_default();    // パラメータの抽出処理...    // 実装の生成    let params_struct_name = format_ident!("{}Parameters", struct_name);    let expanded = quote! {        #[derive(serde::Deserialize, schemars::JsonSchema)]        struct #params_struct_name {            #(#param_defs,)*        }        #input_fn        #[derive(Default)]        struct #struct_name;        #[async_trait::async_trait]        impl mcp_core::handler::ToolHandler for #struct_name {            fn name(&self) -> &'static str {                #tool_name            }            fn description(&self) -> &'static str {                #tool_description            }            fn schema(&self) -> serde_json::Value {                mcp_core::handler::generate_schema::<#params_struct_name>()                    .expect("Failed to generate schema")            }            async fn call(&self, params: serde_json::Value) -> Result<serde_json::Value, mcp_core::handler::ToolError> {                let params: #params_struct_name = serde_json::from_value(params)                    .map_err(|e| mcp_core::handler::ToolError::InvalidParameters(e.to_string()))?;                // Extract parameters and call the function                let result = #fn_name(#(params.#param_names,)*).await                    .map_err(|e| mcp_core::handler::ToolError::ExecutionError(e.to_string()))?;                Ok(serde_json::to_value(result).expect("should serialize"))            }        }    };    TokenStream::from(expanded)}このマクロは、Rustの宣言的プログラミングの可能性を示す素晴らしい例です。関数からのメタデータ抽出：関数の名前や引数リストを解析して、ツールの基本情報を自動的に取得します。パラメータ構造体の自動生成：関数の引数リストから自動的にパラメータ構造体を生成し、serdeとschemarsのデリバティブを適用してJSON対応にします。ツールハンドラの自動実装：抽出した情報を元に、ToolHandlerトレイトを自動的に実装します。これにより、開発者はツールのビジネスロジックだけに集中できます。このマクロを使うと、以下のように簡潔なコードでツールを定義できます。#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}通常なら数十行のボイラープレートコードが必要なところを、このマクロによって数行のアノテーションだけで実現できています。これは開発者体験を大幅に向上させる素晴らしい例です。Webフレームワークとの統合MCPはしばしばWebアプリケーションと統合されます。そのための優れた実装例を見てみましょう：async fn sse_handler(State(app): State<App>) -> Sse<impl Stream<Item = Result<Event, io::Error>>> {    // it's 4KB    const BUFFER_SIZE: usize = 1 << 12;    let session = session_id();    tracing::debug!(%session, "sse connection");    let (c2s_read, c2s_write) = tokio::io::simplex(BUFFER_SIZE);    let (s2c_read, s2c_write) = tokio::io::simplex(BUFFER_SIZE);    app.txs        .write()        .await        .insert(session.clone(), Arc::new(Mutex::new(c2s_write)));    {        let session = session.clone();        tokio::spawn(async move {            let router = RouterService(counter::CounterRouter::new());            let server = Server::new(router);            let bytes_transport = ByteTransport::new(c2s_read, s2c_write);            let _result = server                .run(bytes_transport)                .await                .inspect_err(|e| tracing::error!(?e, "server run error"));            app.txs.write().await.remove(&session);        });    }    let stream = futures::stream::once(futures::future::ok(        Event::default()            .event("endpoint")            .data(format!("?sessionId={session}")),    ))    .chain(        FramedRead::new(s2c_read, common::jsonrpc_frame_codec::JsonRpcFrameCodec)            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))            .and_then(move |bytes| match std::str::from_utf8(&bytes) {                Ok(message) => futures::future::ok(Event::default().event("message").data(message)),                Err(e) => futures::future::err(io::Error::new(io::ErrorKind::InvalidData, e)),            }),    );    Sse::new(stream)}この実装は、Webアプリケーションとバックエンドサービスを統合する優れた例です。単方向チャネルの活用：tokio::io::simplexを使って、クライアントからサーバーへの通信とサーバーからクライアントへの通信を分離しています。これは各方向の流れを独立して最適化できるようにします。バックグラウンドタスク：MCPサーバーをtokio::spawnを使ってバックグラウンドタスクとして実行しています。これによりWebハンドラーは応答を待つことなく、すぐにSSEストリームを返すことができます。SSEストリームの構築：futures::stream::onceと.chain()を組み合わせて、初期メッセージと継続的なメッセージストリームを連結しています。これはストリーミングAPIの標準的なパターンです。この実装パターンは、MCPサーバーをWebアプリケーションに統合する効果的な方法を示しています。特に注目すべきは、非同期処理とストリーミングを効果的に組み合わせている点です。SDKの設計思想分析このSDKの実装から、いくつかの重要な設計思想が読み取れます。堅牢性と型安全性への徹底したこだわりこのSDKは、Rustの型システムを徹底的に活用して堅牢性を確保しています。トレイト境界（Send + Sync + 'staticなど）の明示的な指定ジェネリックパラメータを使ったAPI設計Result型による包括的なエラーハンドリングasync/awaitとFutureの適切な組み合わせこれらの特徴は、SDKの開発者がRustの強みをよく理解し、それを活かそうとしていることを示しています。特に、コンパイル時に多くのエラーを捕捉できるように設計されており、実行時の予期せぬ動作を最小限に抑える工夫が随所に見られます。拡張性と将来性を考えた設計SDKは将来の拡張を見据えた柔軟な設計になっています。トランスポート層の抽象化サービス層の分離とミドルウェアのサポートプラグイン可能なツール定義このような設計により、MCPプロトコル自体が進化しても、SDKを大きく書き換えることなく対応できるでしょう。また、ユーザーが独自の機能を追加するための拡張ポイントが多く用意されています。開発者体験の重視SDKは、使いやすさにも重点を置いています。マクロによるボイラープレートコードの削減直感的なビルダースタイルAPI豊富なデフォルト実装これらの機能は、SDKを使う開発者の負担を軽減し、本質的なビジネスロジックに集中できるようにするための工夫です。特に#[tool]マクロは、開発者体験を大幅に向上させる優れた例です。パフォーマンスへの配慮実装には、パフォーマンスを考慮した数々の工夫が見られます。大きなバッファサイズ（2MB）の使用非同期I/Oの全面採用ロックの最小化と効率的な並行処理これらの最適化は、MCPが大量のデータや複雑なコンテキストを扱うAIユースケースを想定していることを示唆しています。優れた実装パターンのまとめこのSDKから学べる優れたRust実装パターンをまとめましょう。1. 関心の明確な分離SDKは複数のクレートに分かれており、各クレートが明確な責任を持っています。これは保守性と再利用性を高める優れた設計原則です。2. トランスポート抽象化異なる通信方法（Stdio、SSEなど）を統一的なインターフェースで扱うための抽象化は、拡張性と柔軟性の高いコードを書くための良い例です。3. Tower ServiceパターンTowerのサービス抽象化を活用して、ミドルウェアの組み合わせやサービス合成を容易にする設計は、現代的なRustサーバー実装のベストプラクティスです。4. プロシージャルマクロの効果的な活用ボイラープレートコードを削減し、宣言的なスタイルでコードを書けるようにするマクロの活用は、開発者体験を向上させる優れた方法です。5. 非同期プログラミングのベストプラクティスPin、Box<dyn Future>、async_traitなどを適切に組み合わせた非同期処理の実装は、Rustの非同期プログラミングの洗練されたパターンを示しています。おわりにMCP Rust SDKの内部実装を深掘りすることで、Rustの強力な型システムと非同期プログラミングモデルを最大限に活用した素晴らしい設計パターンを学ぶことができました。このSDKは、「型安全性」「拡張性」「使いやすさ」「パフォーマンス」のバランスが優れており、大規模なRustアプリケーションを設計する際の参考になります。特に、トランスポート抽象化、サービス指向設計、プロシージャルマクロの活用は、他のRustプロジェクトでも応用できる価値のある実践例です。MCPプロトコルの実装を検討している方はもちろん、Rustでの堅牢なライブラリ設計に興味がある方にとっても、このSDKのコードベースは探求する価値のある宝庫と言えるでしょう。次回のブログではサンプルを見ながら実際に色々動かしてみたいと思います。syu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetesで実現できるPlatform Engineering の現在地]]></title>
            <link>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</link>
            <guid>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</guid>
            <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: Kubernetesで実践する Platform Engineering - FL#88- 公式URL: https://forkwell.connpass.com/event/348104/🗣️ 関連スライド- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite- Platform Engineeringは自由のめまい- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimのファジーファインダーtelescope.nvimでよく使っているpicker集]]></title>
            <link>https://blog.atusy.net/2025/03/25/nvim-telescope-pickers/</link>
            <guid>https://blog.atusy.net/2025/03/25/nvim-telescope-pickers/</guid>
            <pubDate>Tue, 25 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Vim駅伝2025-03-24の記事です。1日遅れで申し訳ありません。さて、telescope.nvimは言わずと知れたファジーファインダーと呼ばれるものです。ファジーファインダーとは、ファイルなどの候補一覧から、検索などで欲しいものを絞りこみ、開くなり消すなり任意のアクションを実行するためのツールです。たしかそんなようなことをShougoさんがvim-jp ラジオの#7か#8で語ってたはず。良い話いっぱいなので、聞いてみてください。【Vimプラグイン作者・Shougoさん登場！】エンジニアの楽園 vim-jp ラジオ #7【Shougoさんが考えるプラグインのあるべき姿】エンジニアの楽園 vim-jp ラジオ #8vim-jpではまたファジーファインダーかと叫ばれるくらいには作者が多く、vim-jpにいらっしゃる方の作品だけでもShougo/ddu.vim、vim-fall/fall.vim、hrsh7th/nvim-deckなどがあります。それくらいには求めるところがユーザーによって変わるということでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[論文紹介 ”A Survey on Large Language Model based Autonomous Agents”]]></title>
            <link>https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents</link>
            <guid>https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents</guid>
            <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/349197/この論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。本論文を読むことで、AIエージェントの概要を体系的に知ることができます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇してきました。　#信頼性向上_findy]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737</guid>
            <pubDate>Fri, 21 Mar 2025 11:47:37 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは、スリーシェイクのnwiizoです。2025年3月21日に開催されたFindyさん主催のイベントで登壇してきました。findy.connpass.comイベント概要このイベントは、SLI/SLOの導入と運用に焦点を当てたライトニングトーク形式のセッションでした。サービス品質を高めるためのSLI/SLOですが、組織内での運用がうまくいってないケースや導入タイミングに悩まれている方も多いのが現状です。本イベントではSLI/SLOについて向き合っていらっしゃる4名の皆様に、導入までの取り組みや運用上の課題とその解決策を共有していただきます。参加者にとって今後システムの信頼性向上に取り組んでいくための知識やヒントを得られるイベントになることを目指します。私を含めた4名のスピーカーによる多角的なアプローチで、SLI/SLOに関する実践的な知見が共有されました。とても良い会だったと思います。私の発表内容資料 speakerdeck.com👻本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇します。こちら、資料になります。https://t.co/XtbFX2EOSH#信頼性向上_findy— nwiizo (@nwiizo) 2025年3月21日   発表の背景と位置づけこのイベントの準備にあたり、他の登壇者の方々の過去の発表や知見を事前に確認し、全体として何が語られるのかを予想してみました。技術的な実装方法や指標設計については他の方々が深く掘り下げられると考え、あえて私は「個人や組織への適用」という補完的な視点に焦点を当てることにしました。技術的な側面は重要ですが、実際にSLI/SLOが組織に定着するかどうかは、エンジニアリング以外の部分に大きく依存します。そこで今回は「技術をどう実装するか」ではなく「個人や組織をどう変革するか」という視点からSLI/SLOの旅を語ることにしました。発表の核心：三つの壁私の発表ではSLI/SLO導入における「三つの壁」に焦点を当てました1. 既存の習慣や方法からの変更を伴う壁「変化への抵抗」は克服すべき障害ではなく、理解し対話すべき自然な反応です。特に以下の4つの抵抗パターンを理解することが重要です。惰性による抵抗：「今のやり方で問題ない」労力による抵抗：「新しい方法を学ぶコストが高い」感情による抵抗：「自分の立場が脅かされる」心理的反発：変化に対する本能的な抵抗これらの抵抗に対して「北風」（強制）ではなく「太陽」（共感と対話）のアプローチが効果的です。2. 多くのステークホルダーとの協力が不可欠という壁SLI/SLOは技術だけの問題ではなく、むしろ組織の問題です。表向きは「全員で信頼性を高めましょう」という掛け声のもとで始まりますが、裏では様々な力学が働いています。部門間の隠れた対立構造：エンジニアリングは信頼性を重視し、プロダクトは新機能を優先し、経営層はコスト効率を求める。この三すくみの構造がSLI/SLO導入の最大の障壁になります。「会議では言えない本音」の存在：公式の場では皆が納得したように見えても、実際には「またエンジニアの自己満足では？」「数値のために本質を見失っている」といった潜在的な不信感が残ります。非公式なネットワークの重要性：公式のプロセスや説明会より、信頼関係のある個人間の非公式な対話の方が効果的なことが多いです。ランチタイムや1on1の場で地道に信頼関係を築く必要があります。技術と事業の懸け橋となる人材の重要性：各部門の言語を話せるクロスファンクショナルな理解者（技術と事業の両方を理解できる人）が不可欠です。このような架け橋となる存在を味方につけることが成功への近道になります。結局のところ、最も有効な戦略は「自分の専門領域を超えて相手の文脈で語る」ことです。技術者は事業KPIの言葉で、事業側は技術的制約の言葉で対話する努力が必要です。これが「信頼性は会話である」という言葉の本当の意味なのです。3. 目に見える成果が出るまでに時間がかかるという壁SLI/SLOの導入は短期決戦ではなく長期的な取り組みです。導入初期は一時的な作業量増加と基盤構築が先行本当の価値は6-12ヶ月後から現れることが多い「完璧なSLO」より「継続的に改善されるSLO」が重要長期的取り組みのためには、小さな成功の積み重ねと組織的なコミットメントが欠かせません。実務上の重要なポイントは、初期段階で期待値を適切に設定することです。多くの組織では「すぐに効果が出る」という期待から、半年程度で「効果がない」と判断されることがあります。これを防ぐには、短期的な小さな成功（例：アラート削減による疲労軽減）と長期的な大きな成功（例：システム安定性向上によるビジネス成長）の両方を明確に提示しておくことが重要です。発表を終えて今回のイベントでは、他の登壇者の方々もそれぞれの視点から素晴らしい発表をされていました。BASEのtandenさんがアラート品質の改善について、シンプルフォームの守屋さんが開発組織全体でのSLI/SLO実装について、ユーザベースの安藤さんがSREとCTOの両視点からのSLI/SLO活用について語られました。私は意図的に「組織文化と変革マネジメント」という視点から補完的に話すことで、イベント全体として技術から組織まで幅広い視点でSLI/SLOについて学べる場になったのではないかと思います。特に印象的だったのは、どの発表も「数値や指標そのものより、それを活用して何を実現するか」という本質的な部分を大切にしていたことです。形式的なSLI/SLO導入ではなく、真に組織とサービスの価値を高めるための取り組みとして捉えられていたのが印象的でした。まとめSLI/SLOの導入は一朝一夕にはいきません。それは旅のように、ゴールや完璧を目指すのではなく、継続的な前進が大切です。今日から始められることとしては：- 小さく始めて徐々に拡大する- まずは一つのサービスから- 既存の課題から出発するそして成功のための心構えとして：- 完璧よりも継続を重視する- 技術も情熱もどちらも大切- 信頼性は会話/対話から生まれるSLI/SLOの導入は技術的チャレンジであると同時に組織的チャレンジです。小さな一歩から始めて、組織全体で信頼性文化を育んでいきましょう。なお、SLI/SLOの基本概念から実践的な導入方法までを体系的に学ぶには、以下の書籍を必ず一読していただきたいと思います。組織への適用を考える前に、まずはこの本で基礎をしっかり固めることをお勧めします。www.oreilly.co.jpこれらのポイントを心に留めながら、組織にSLI/SLOを適用する旅を続けていきましょう。おわりにまた、他の登壇者の皆さんの発表資料も大変参考になりましたので、ぜひご覧ください。BASEの@tac_tandenさんによる「SLI/SLOの設定を進めるその前に、アラート品質の改善に取り組んだ話」では、SLI/SLO導入の前段階としてのアラート品質向上について詳しく解説されています。SREピラミットの下には常にモニタリングがあり自分の経験からも何よりも重要だと思っています。 speakerdeck.comシンプルフォームの守屋邦昭さんによる「開発組織全体で意識するSLI/SLOを実装している話」では、組織全体でのSLI/SLO実装について具体的な事例が紹介されています。 speakerdeck.comユーザベースの安藤裕紀さんによる「SREとしてSLI/SLOをどう普及してきたか、CTOとしてSLI/SLOをどう活用しているか」では、SRE視点とCTO視点の両面からSLI/SLOの活用方法が解説されています。個人的には俯瞰度合いが好きです。www.docswell.com最後までお読みいただき、ありがとうございました！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishの補完をコマンドラインの内容に応じて変える]]></title>
            <link>https://blog.atusy.net/2025/03/21/fish-completion-considering-tokens/</link>
            <guid>https://blog.atusy.net/2025/03/21/fish-completion-considering-tokens/</guid>
            <pubDate>Fri, 21 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishで補完を定義するとき、コマンドに指定された引数によって補完候補を変えたいことがあります。たとえばメインコマンドの直後だったらサブコマンドを補完したい、--input-fileの後だったらファイル名を補完したいとかいうことありますよね。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SLI/SLO・ラプソディあるいは組織への適用の旅]]></title>
            <link>https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu</link>
            <guid>https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu</guid>
            <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～- 公式URL: https://findy.connpass.com/event/345990/📚 さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！😲「Kubernetesで実践する Platform Engineering - FL#88」🐳⚙️興味がある方はぜひ参加してください！👨‍💻👩‍💻👉 https://forkwell.connpass.com/event/348104/お見逃しなく！🗓️✨]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishの関数で関数外の変数を利用する]]></title>
            <link>https://blog.atusy.net/2025/03/20/use-outer-scope-vars-in-fish/</link>
            <guid>https://blog.atusy.net/2025/03/20/use-outer-scope-vars-in-fish/</guid>
            <pubDate>Thu, 20 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025-03-21時点で最新のFish 4.0.1のデフォルト挙動では、関数が外界のローカル変数を参照できません。ためしに、関数fの外で定義した変数のechoを試みてみると、何も表示されません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIといっしょ: 動作するきれいなコードを生成AIとつくる]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025</guid>
            <pubDate>Wed, 19 Mar 2025 11:10:25 GMT</pubDate>
            <content:encoded><![CDATA[※こちらは社内で発表したものを外部で登壇できるように修正したものです。はじめに2021年にGitHub Copilotが発表され、2022年に一般利用可能になって以来、生成AIはソフトウェア開発の世界に急速に浸透してきました。「動作するきれいなコード」はソフトウェア開発の理想とされてきましたが、生成AIの登場によってこの理想に到達する道筋が大きく変化しています。本記事では、テスト駆動開発の原典である『テスト駆動開発』の基本理念を踏まえ、生成AIとの協業によって「動作するきれいなコード」を実現する方法について考察します。「動作するきれいなコード」とは何かt-wada氏がSeleniumConf Tokyo 2019での基調講演で引用したように、テスト駆動開発のゴールは「動作するきれいなコード（Clean code that works）」です。Kent Beckによるテスト駆動開発の書籍の冒頭には、次のような一節があります。 speakerdeck.com「動作するきれいなコード」。Ron Jeffriesのこの簡潔な言葉が、テスト駆動開発（TDD）のゴールだ。動作するきれいなコードはあらゆる意味で価値がある「動作する」と「きれい」の2つの要素に分解すると、ソフトウェア開発においては以下の4つの象限が考えられます：きれいで動作する（理想）きれいだが動作しない（机上の空論）きたないが動作する（現実の妥協）きたなくて動作しない（最悪の状態）Kent Beckは、この目標に対して、天才的なプログラマならすぐに到達できるかもしれないが、一般のプログラマはすぐには書けないと述べています。そこで彼は分割統治法を提案し、まず「動作する」ことを優先し、その後「きれい」にすることを推奨しています。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon生成AIとテスト駆動開発の融合ソフトウェア開発における三種の神器t-wada氏の講演では、ソフトウェア開発において欠かせない三つの技術的な柱（三種の神器）が紹介されています。これらは生成AIと協働する際にも極めて重要な基盤となります。1. バージョン管理（Version Control）バージョン管理は、人間の記憶力の限界を補うために生まれました。バージョン管理システムは：いつ、誰が、どのような変更をしたかを記録異なるバージョン間の差分を可視化複数の開発者が同時に作業することを可能に過去の状態に簡単に戻れる安全網を提供生成AIとの協働においても、AIが生成したコードを適切に管理し、問題が生じた場合に以前の状態に戻れるようにするためにバージョン管理は不可欠です。2. テスティング（Testing）テスティングは人間の把握力の限界を補います。システムが複雑化するにつれ、変更が他の部分に与える影響を人間が完全に把握することは困難になります。テスティングにより：コードが予期通りに動作することを自動的に検証変更によるリグレッションを早期に発見設計の問題点を可視化リファクタリングの安全網を提供生成AIとの協業では、この安全網がさらに重要となります。AIが生成したコードが本当に要件を満たしているかを客観的に評価するためのテストは不可欠です。3. 自動化（Automation）自動化は人間の忍耐力の限界を補います。自動化により：繰り返し作業を機械に任せることで人間のエラーを減少開発プロセスの一貫性と再現性を確保開発速度の向上と時間の節約継続的インテグレーション・継続的デリバリ（CI/CD）を実現特に重要なのは、自動化がソフトウェア開発におけるガードレールとしての役割です。AIが生成したコードの品質、セキュリティ、パフォーマンスを自動的に検証することで、AIの「創造性」と「安全性」のバランスを取ることができます。三種の神器は、「あれば便利」という加点法ではなく、「なければ危険」という減点法の世界です。生成AI時代においても、これらの基盤があってこそ、安全かつ効率的な開発が可能になります。AIとの協業進化段階AIによる開発支援は、自動車の自動運転レベルに似た段階を経て進化しています：レベル0：AI支援なし - 従来の手動開発レベル1：AI支援（Chat） - LLMによる情報提供のみレベル2：AI支援（補完＋Chat） - GitHub Copilotなどの部分的補完レベル3：Agent（人間が支援） - AIが主に作業し、人間が確認・修正レベル4：Agent（人間の支援なし） - AIが自律的に開発レベル5：業務の完全自動化 - 要求からプロセス全体を自動生成2025年の開発環境は、主にレベル3〜4の間で推移しており、「副操縦士（Copilot）」から「操縦士（Pilot）」へと主役が交代しつつあります。生成AIの強みと限界生成AIの特性は以下のようにまとめられます：強み:膨大なコードパターンとベストプラクティスの学習自然言語からコードを生成する能力環境情報を参照し、実行結果から学習して修正する能力圧倒的な速度でのコード生成・実行・修正多言語・多フレームワークへの対応多様な実装アプローチの提案能力限界:ビジネスロジックやドメイン知識の理解が浅いコンテキストの保持と長期的な一貫性の維持が苦手複雑なコンパイラ制約がある言語での実装に課題「テストを無理に通そうとする」傾向参照の明示的な解決が苦手特にCLINEなどの環境統合型エージェントは、実行と修正のサイクルを驚くべき速度で回すことができ、「どんなエキスパートでも勝てないレベル」に達しつつあります。AIツールを使いこなすためには、「コンテキストを記述する能力」「ドメインを記述する能力」「AIの性能に対する直感」といった新しいスキルセットが求められます。zenn.devドライバー席を譲った後の新しい役割開発者が主導権（ドライバー席）をAIに譲った後、どのような新しい役割を担うべきでしょうか。助手席のナビゲーター最も有望なポジションは「助手席」です：AIに対して適切な指示と方向性を提供する生成された成果物の品質と整合性を評価するAIの能力を最大限に引き出すプロンプトエンジニアリングを行う後部座席への後退リスク一方で、単に「後部座席」に座り、AIの決定に従うだけの受動的な立場になるリスクも存在します：AIが示した選択肢から選ぶだけの存在に専門的理解が浅くなり、本質的な問題解決能力が衰える「運試し」と「結果責任」だけが残される状態 speakerdeck.comこの比喩はとても好きなので将来的には「お前は後部座席に座るなよ」とか言いそう。レッドボックスの内に対処する生成AIの発展に伴い、小説「BEATLESS」で描かれた「人類未到産物（レッドボックス）」の概念が現実味を帯びてきています。「超高度AIが生み出した、今の人類には理解できない超高度技術によってつくられた産物。「レッドボックス」という名称には、観測者から遠ざかる光が赤方偏移により赤から黒（赤外領域）へと変わるように、人類が必死に追いすがらなければいずれ遠ざかりブラックボックスになってしまうという意味が込められている。」現在のAIコーディングでも、AIが生成した複雑なコードや設計に対して、人間が「理解できない」状態に陥るリスクが現実化しつつあります。それらには以下のような対策が考えられます。意図的な単純化 - AIに「人間が理解できるようなシンプルな実装」を明示的に要求する解説の要求 - 実装だけでなく、その設計思想や動作原理の解説を求める段階的な理解 - 複雑な実装を小さな部分に分解して理解するテストによる挙動の可視化 - 振る舞いを詳細なテストで定義することで、ブラックボックス化を防ぐ継続的な学習 - AIが使用する最新の技術やパターンを人間側も学び続ける speakerdeck.comAIの能力が人間の理解を超えた「レッドボックス」となっても、その内部を理解するための努力を怠らないことが、「助手席」の位置を維持するために不可欠です。技術が人間から遠ざかっていくのを防ぐために、テスト駆動開発のような体系的なアプローチが重要な役割を果たします。ＢＥＡＴＬＥＳＳ 上 (角川文庫)作者:長谷 敏司KADOKAWAAmazonバイブス労働とAIコーディングバイブスコーディングとは何かAndrej Karpathy（OpenAI共同創業者）が提唱した"vibe coding"という概念が注目を集めています。「新しい種類のコーディングがあって、私はこれを"vibe coding"と呼んでいます。そこでは完全に"vibe（雰囲気、直感）"に身を任せ、指数関数的成長を歓迎し、コードそのものが存在していることさえ忘れてしまいます。」— Andrej Karpathyこのバイブスコーディングは、以下の特徴を持っています：自力で成果物を作り込まない - AIに指示を出すことに集中ノールックマージ - AIの提案を直感的に受け入れるエラー解決のアウトソース - 問題発生時にAIに解決を依頼理詰めな部分はAIに任せる - 人間は直感と判断に集中Andrej Karpathyが提唱する「バイブスコーディング」の考え方を適度に取り入れることで、生成AIとの協業をより効果的にできます。直感を大切に - AIとの対話では、時に論理的思考よりも直感が良い結果を生むことがある反復の高速化 - AIがエラー修正や実装変更を高速で行える特性を活かし、試行錯誤のサイクルを加速余分な労力の削減 - 自明な実装や定型コードの作成はAIに任せ、本質的な部分に集中創造的提案の受け入れ - AIが提案する予想外のアプローチに対してオープンな姿勢を持つただし、バイブスに任せすぎることなく、テストという客観的基準を常に維持することで、「ノリ」と「品質」の両立を図ります。特に、重要な意思決定やアーキテクチャに関わる部分では、専門知識に基づく判断を優先しましょう。blog.lai.soバイブス労働の広がりバイブスコーディングの概念は、プログラミングの領域を超えて様々な知識労働にも応用できる「バイブス労働」という新たなパラダイムを生み出しています。バイブス労働では、AIを活用して直感的かつ効率的に成果を生み出す働き方が可能になります。バイブス労働の特徴には以下のようなものがあります：プロンプトクラフティング - AIに適切な指示を出すスキルが新たな専門性として価値を持つ創造的監督 - 細部の実装よりも、全体の方向性や品質の判断に人間の能力を集中させる反復と共進化 - 人間とAIが互いにフィードバックを与え合いながら成果物を進化させていくメタ認知の重要性 - 自分の思考プロセスを客観視し、AIとの協業に最適な役割分担を模索するバイブス労働の時代においては、「コードを書く」「文章を作成する」といった直接的な生産活動よりも、「何を作るべきか」「どのような価値を提供するか」という本質的な問いに答えることにより多くの時間とエネルギーを費やすことが可能になります。これにより、人間の創造性と直感が最大限に発揮される新しい働き方が実現するでしょう。生成AIとのテスト駆動開発の実践テスト駆動開発（TDD）の基本サイクル「Red-Green-Refactoring」を生成AIと組み合わせると、以下のようなアプローチが考えられます：Red: AIを活用したテスト設計生成AIはこのステップで：ユーザーストーリーや仕様から、テストケースを提案自然言語からテストコードを生成人間が見落としがちなエッジケースを発見様々なテスト方法を提示人間は機能要件を明確に定義し、AIが提案するテストケースが要件を正確に反映しているか評価します。Green: AIによる実装の高速化生成AIはここで：失敗するテストを満たす実装コードを生成複数の実装アプローチを提案素早いプロトタイピングを実現テスト失敗時のデバッグを支援テストという明確な基準があるため、AIの出力の正確性を客観的に評価できます。Kent Beckの原則通り、まずはテストを通過することを優先し、きれいさは次のステップで追求します。Refactoring: AIと共にコードをきれいにするこのステップでは、生成AIは：コードの問題点や改善点を指摘し、リファクタリング案を提示適切なデザインパターンを提案命名、構造、コメントなどの品質向上策を提案パフォーマンス最適化を提案テストが引き続き成功することを確認しながら、コードの品質を向上させます。AIはコードの「きれいさ」に関する豊富な知識を持っていますが、プロジェクト固有の規約やアーキテクチャの理解には限界があるため、人間による最終確認が不可欠です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon生成AIとTDDの相性の良さ生成AIとテスト駆動開発には、以下のような相性の良さがあります：明確な評価基準 - テストがAIの出力の正確性を評価する客観的基準となる繰り返しのフィードバック - 小さなサイクルによる継続的改善がAIとの協業に適している段階的な複雑性の増加 - 単純から複雑へ進むアプローチがAIの能力を引き出す品質保証の自動化 - テストによる安全網でAIコードの品質を保証責任の分担 - 人間がテストで要件を明確にし、AIが実装を担当という自然な役割分担人間の尺度のリファクタリング - AIが生成した複雑なコードを、TDDを通じて人間が理解・保守しやすい形に整理できるプログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ作者:フェリエンヌ・ヘルマンス,水野貴明,水野いずみ秀和システムAmazon効果的な生成AI活用のためのプラクティス1. テスト優先の指示AIに実装を依頼する前にテストを先に書くよう指示することで、テスト駆動の流れを維持します。テストを通じて機能要件を明確に定義し、AIがその要件を正確に理解することを促します。2. 段階的な複雑性の増加単純なテストケースから始め、徐々に複雑なケースを追加していくアプローチがAIとの協業に効果的です。AIが問題を段階的に理解し、複雑性を徐々に取り入れることができます。3. リファクタリングの明示的な依頼具体的なリファクタリングの観点（命名の改善、重複の排除、可読性向上など）を指定すると良い結果が得られます。焦点を絞ることでAIはより的確な改善提案ができます。4. 小さなサイクルの維持小さな機能単位でテスト→実装→リファクタリングのサイクルを回すことで、問題発生時の影響範囲を限定し、修正を容易にします。短いサイクルは、AIにとっても理解しやすく、効率的な協業を促進します。5. 三種の神器を活用したAI協業ワークフローバージョン管理:AIが生成したコードを適切にコミットし、変更履歴を明確に残すAIの提案ごとにブランチを作成して比較検討問題発生時に以前の状態に容易に戻れるよう準備テスティング:先にテストコードを作成し、明確な目標を設定テストと実装の両方を継続的に改善テストカバレッジをモニタリングして品質保証自動化:CIパイプラインでAIコードの品質を自動検証静的解析とセキュリティスキャンでAIの盲点をカバー自動化されたガードレールで意図しない問題を防止三種の神器は、AIとの協業における品質と安全性を保証する基盤となります。6. 私が生成AIの時代にRustを選択する理由プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonテスト駆動開発は効果的ですが、テストだけではすべての不具合を検出できないという限界があります。特に生成AI時代において、型システムによる形式検証を提供するRustのような言語を選択することで、AIとの協業をより確実なものにできます。Rustの型システムは「軽量な形式検証」として機能し、テストでは捉えきれない問題を発見します。所有権と借用チェッカーによるメモリ安全性の数学的保証、代数的データ型による未定義状態の排除、トレイト境界によるコードの整合性の静的検証など、多くの利点があります。現時点では、生成AIがRustコードを一発でコンパイル通過させることは難しく、私の経験上も何度か修正が必要になることが多いです。しかし、これは欠点というよりも、Rustのコンパイラが持つ厳格なチェック機能が「ガードレール」として働いている証拠と言えるでしょう。AIが生成したコードでもコンパイラが厳密な検証を行うことで、多くの潜在的な問題が実行前に排除されます。Rustの型システムとテスト駆動開発は相互補完的な関係にあります。型システムがコード全体の整合性と安全性を保証し、テストがビジネスロジックの正確さを検証します。このような組み合わせにより、AIが生成したコードの品質担保と不具合検出の両面をカバーできます。テストだけでは見つけられない並行処理やメモリの問題も、Rustのコンパイラが捕捉してくれるのです。生成AI時代において、言語自体が提供する安全性保証は、人間のレビュー負担を軽減し、AIとの効率的な協業を実現します。コンパイラが通過するまでに何度か調整が必要でも、その過程自体がコードの品質向上に貢献していることを忘れてはなりません。ＲｕｓｔによるＷｅｂアプリケーション開発　設計からリリース・運用まで (ＫＳ情報科学専門書)作者:豊田優貴,松本健太郎,吉川哲史講談社Amazonおわりに生成AIとテスト駆動開発を組み合わせることで、「動作するきれいなコード」を効率的に実現できる可能性が広がっています。AIの創造性と生産性、人間の判断力と創造性を組み合わせるための鍵は、テスト駆動開発の原則と三種の神器という堅固な基盤です。t-wada氏の言葉を借りれば、「テスト駆動開発は、設計のひらめきが正しい瞬間に訪れることを保証するものではない。しかし、自信を与えてくれるテストときちんと手入れされたコードは、ひらめきへの備えであり、いざひらめいたときに、それを具現化するための備えでもある」のです。t-wada.hatenablog.jp生成AIはこの「備え」をより強固にする強力なパートナーとなります。AIとの協業においても、テスト駆動開発の原則を守りながら、AIの能力を最大限に活用することで、より良いソフトウェア開発が実現できるでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[uvでbrowser_useを使用した環境構築したり比べたりするけど責任は取れない。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957</guid>
            <pubDate>Wed, 19 Mar 2025 04:19:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめに三寒四温（さんかんしおん）というような天気が続いています。これは「三日寒くて四日温かい」という意味で、冬から春への移行期によく見られる気温の周期的な変動を表す言葉です。寒暖の差が激しいこの季節、AIに関しての情報収集よりみなさんが暖かい格好して体調崩さないほうが大切です。とはいえ、技術ブログなので技術的なことも書いていきます。今回はPythonのAI用ブラウザである「browser_use」ライブラリを使用して、AnthropicのClaude 3.5 SonnetとOpenAIのGPT-4oの情報収集能力を実際のコードとログで比較します。github.com実際になにかに使う場合にはドキュメントを読んで下さい。このブログはそのようなことに耐えられるように作られてはいません。docs.browser-use.com環境構築まず、uvを使って環境を構築します。uvはPythonの高速パッケージマネージャーで、依存関係の解決と仮想環境の構築が効率的に行えます。# 仮想環境を作成uv venv# 仮想環境を有効化（macOS/Linux）source .venv/bin/activate# 必要なライブラリをインストールuv pip install langchain-anthropic langchain-openai browser-use実装コードAnthropicのClaudeを使用するコード（3shake_ceo_anthropic.py）:import asynciofrom browser_use import Agentfrom langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model_name="claude-3-5-sonnet-latest")task = "株式会社スリーシェイクのCEOのXアカウントを教えて下さい"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())OpenAIのGPT-4oを使用するコード（3shake_ceo_openai.py）:import asynciofrom browser_use import Agentfrom langchain_openai import ChatOpenAIllm = ChatOpenAI(model="gpt-4o")task = "株式会社スリーシェイクのCEOのXアカウントを教えて下さい"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())実行結果(uv run xx.py)Claude 3.5 Sonnet（Anthropic）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - Starting fresh with empty pageINFO     [agent] 🧠 Memory: Starting the task to find X (Twitter) account of 株式会社スリーシェイク's CEO. Step 1/100.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク company information on GoogleINFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO Twitter X"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO Twitter X" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Found search results showing the CEO's X accountINFO     [agent] 🧠 Memory: Found that the CEO of スリーシェイク is 吉田拓真 (Takuma Yoshida) and his X account is @taqqma_ikachan. Step 2/100.INFO     [agent] 🎯 Next goal: Visit the CEO's X profile to confirm informationINFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":19}}INFO     [controller] 🖱️  Clicked button with index 19: 吉田 拓真 / スリーシェイク (@taqqma_ikachan) / XINFO     [agent] 📍 Step 3INFO     [agent] 👍 Eval: Success - I have confirmed that this is indeed the X account of the CEO of スリーシェイクINFO     [agent] 🧠 Memory: Found and confirmed that 吉田拓真 (Yoshida Takuma) is the CEO of スリーシェイク and his X account is @taqqma_ikachan. His profile confirms he is the 代表取締役社長 (CEO) of スリーシェイク.INFO     [agent] 🎯 Next goal: Task completed - provide the answerINFO     [agent] 🛠️  Action 1/1: {"done":{"text":"株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。","success":true}}INFO     [agent] 📄 Result: 株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。INFO     [agent] ✅ Task completedINFO     [agent] ✅ SuccessfullyGPT-4o（OpenAI）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - The page is empty and there's no previous context to evaluate.INFO     [agent] 🧠 Memory: Need to find the X account of 株式会社スリーシェイク's CEO.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク CEO Twitter account on Google.INFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO Twitter account"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO Twitter account" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Google search is displaying links related to the CEO of 株式会社スリーシェイク and their X account.INFO     [agent] 🧠 Memory: Searching for 株式会社スリーシェイク CEO's Twitter account. Found potential link at index 26.INFO     [agent] 🎯 Next goal: Check the link at index 26 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":26}}INFO     [controller] 🖱️  Clicked button with index 26: 株式会社スリーシェイク (@3shake_Inc) / XINFO     [agent] 📍 Step 3INFO     [agent] ⚠ Eval: Failed - The page requires login to access the X account information.INFO     [agent] 🧠 Memory: Currently on the login page of X; unable to access 株式会社スリーシェイク's CEO account information directly without logging in.INFO     [agent] 🎯 Next goal: Search again for 株式会社スリーシェイク's CEO X account from another source.INFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO X account"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO X account" in GoogleINFO     [agent] 📍 Step 4INFO     [agent] 👍 Eval: Success - Found a link that likely refers to the CEO's X account.INFO     [agent] 🧠 Memory: Trying to access 株式会社スリーシェイク CEO's X account via the link available at index 25.INFO     [agent] 🎯 Next goal: Click on the link at index 25 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":25}}INFO     [controller] 🖱️  Clicked button with index 25: 内村一行/3-Shake (@KAZUYUKIUCHIMU) / XINFO     [agent] 📍 Step 5INFO     [agent] 👍 Eval: Success - Reached the login page for the user's X account.INFO     [agent] 🧠 Memory: Identified the CEO's Twitter handle as @KAZUYUKIUCHIMU, but login is required to access more information.INFO     [agent] 🎯 Next goal: Provide the CEO's X account and complete the task.INFO     [agent] 🛠️  Action 1/1: {"done":{"text":"The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.","success":true}}INFO     [agent] 📄 Result: The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.INFO     [agent] ✅ Task completedINFO     [agent] ✅ Successfullyコードとログの詳細分析browser_useの動作browser_useライブラリは、AIモデルをWebブラウジングと組み合わせて情報検索を行うエージェントを作成します。このライブラリはログを詳細に記録しており、AIの意思決定プロセスを追跡できます：🚀 Starting task: タスクの開始📍 Step N: 各ステップの開始🤷 Eval: ページの状態評価🧠 Memory: AIのタスク理解と記憶🎯 Next goal: 次の目標設定🛠️ Action: 実行するアクション📄 Result: 最終結果モデル間の違い1. 検索クエリの違いClaude: 株式会社スリーシェイク CEO Twitter XGPT-4o: 株式会社スリーシェイク CEO Twitter accountこの微妙な違いが、初期の検索結果に影響しました。2. 問題解決アプローチの違いGPT-4oは会社の公式アカウント（@3shake_Inc）をまず確認しようとしましたが、ログイン要求に遭遇して別の戦略に切り替えました。一方、Claudeは直接CEOのアカウントを検索してアクセスしました。3. 情報確認の徹底度Claudeはプロフィールにアクセスして「代表取締役社長」の肩書きを確認しましたが、GPT-4oは内村一行氏（実際は取締役）をCEOと誤認したままでした。技術的考察browser_useの利点詳細なログ: browser_useは各ステップを詳細にログに記録するため、AIの判断プロセスを追跡できます。シンプルなAPI: わずか数行のコードでAIエージェントを作成でき、異なるモデルの比較テストが容易です。多様なモデルサポート: browser_useは複数のAIモデルをサポートしており、異なるモデル間の比較が容易です。docs.browser-use.com改善ポイントログから以下の改善点が考えられます：1.検索クエリの最適化# より精度の高いクエリを指定task = "株式会社スリーシェイク 吉田拓真 CEO Xアカウント"2. 複数情報源からの検証agent = Agent(    task=task,    llm=llm,    verify_sources=True,  # 複数ソースでの検証を促す（仮想的なパラメータ）)3. エラー時の代替戦略# ログイン画面に遭遇した場合の対処を明示的に指示agent = Agent(    task=task,    llm=llm,    login_strategy="search_alternative",  # ログイン要求時の戦略)実務への応用AIエージェントを活用する際は、以下の点に注意すると良いでしょう：1. 正確なプロンプトの設計# より具体的なタスク指定task = "株式会社スリーシェイクの代表取締役社長/CEOの公式Xアカウントを会社の公式情報から特定してください"2. 複数モデルでの検証# 複数モデルの結果を比較results = {}for model_name in ["claude-3-5-sonnet-latest", "gpt-4o"]:    agent = create_agent_for_model(model_name)    results[model_name] = await agent.run()# 結果の一致度を確認compare_results(results)3. 結果の人間によるレビュー:特に重要な意思決定には、AIの判断をそのまま信頼するのではなく、人間による最終チェックを行うプロセスを組み込むことが重要です。結果に責任が取れるような仕組みにはまだなっていなさそうです。テスト的になにかのチェックを行わせるというのは必要かと思いました。まとめ今回の実験では、特別なプロンプトエンジニアリングやチューニングを一切行わず、同じコードで二つのモデルを実行した結果を比較しました。思いつきで雑に実行しただけなのに、興味深い違いが出てきたのは面白いポイントです。Claudeは正確にCEOを特定した一方、GPT-4oは取締役を誤ってCEOと判断しました。この結果は、AIエージェントがまだ完璧ではなく、特に重要な情報収集には複数の検証プロセスを設けることの重要性を示しています。今後も気軽に試せるツールとして、browser_useとuvの組み合わせは便利そうです。特に複雑な設定や調整をしなくても、こうした比較実験が簡単にできるのが魅力的です。docs.browser-use.com注：コード例は概念的なものであり、実際のbrowser_use APIとは異なる場合があります。詳細は公式ドキュメントを参照してください。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rでトレースバックつきのエラーログをとる]]></title>
            <link>https://blog.atusy.net/2025/03/19/log-error-on-r/</link>
            <guid>https://blog.atusy.net/2025/03/19/log-error-on-r/</guid>
            <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[エラーログはエラーでユーザーに影響が発生した時に、何が起きたか記録する重要な情報源です。特にどこで問題が起きたか特定を容易にするトレースバックはログに欠かせません。ログをとらなくてもエラーは表示されるよと思いの方も、ログを使うとエラーの発生時刻は関連情報を同時に記録できるので、覚えていて損はないです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishで非同期処理を実装してみる]]></title>
            <link>https://blog.atusy.net/2025/03/16/fish-async/</link>
            <guid>https://blog.atusy.net/2025/03/16/fish-async/</guid>
            <pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishのプロンプトを自作していて、実行に時間がかかる場合に、非同期にプロンプトを更新できるか気になりました。軽く調べてみたところ、ユニバーサル変数を利用するといいよとのこと。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[外向けに話すときは相手のメリットを話そう]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2025/03/14/204148</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2025/03/14/204148</guid>
            <pubDate>Fri, 14 Mar 2025 11:41:48 GMT</pubDate>
            <content:encoded><![CDATA[お仕事をしているとチームや自分の周りで合意を取ったことを、相手にお願いしに行くことが多々あります。例えばピープルマネジメントのマネージャー層でxxというやり方を試していきたいと合意をとったものを、相手にお願いしに行くこと。例えば自分たちの担当範囲の決め事で、相手に協力をお願いしに行くこと。例えば自分たちのシステムと他システム間の決め事で、こちらの方針を相談しに行くこと。自分たちの決め事を相手に協力してもらうことはよくあります。方針を固めるまでにディスカッションを重ね、自分たちにどのようなメリットがあるかは詳細に話すでしょう。自分たちの考えやメリットも詳細に説明できるでしょう。では相手のメリットはどうでしょう？ 自分の考えやメリットの説明で終わってはいないでしょうか？相手のアクションが必要なとき、ポジションティブに動いてもらうには相手の動機が重要です。相手にメリット考えて貰うより、発案者から提案したほうが心象も良くなります。要は相手の立場を考えましょうの一側面です。相手と話すときは相手の立場を考えましょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ObservabilityCON on the Road Tokyo 2025 Recap]]></title>
            <link>https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/</link>
            <guid>https://sreake.com/blog/observabilitycon-on-the-road-tokyo-2025-recap/</guid>
            <pubDate>Fri, 14 Mar 2025 02:09:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部の岩﨑です。 2025年2月25日、ObservabilityCON on the Road Tokyo 2025 が東京ポートシティ竹芝で開催されました。初めての参加でしたが、Grafana […]The post ObservabilityCON on the Road Tokyo 2025 Recap first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[1～100までの整数が奇数かどうかを判定するプログラム.R]]></title>
            <link>https://blog.atusy.net/2025/03/14/is-odd-r/</link>
            <guid>https://blog.atusy.net/2025/03/14/is-odd-r/</guid>
            <pubDate>Fri, 14 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[【ゆる募】１～100までの整数が奇数かどうかを判定するプログラム大喜利を開催します☺　言語不問✨https://x.com/arith_rose/status/1899300131658510802とのことで、Rで書いてみましょう。模範解答……？ナニソレオイシイノ？]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[fish shellを実質的なデフォルトシェルにするbashrc]]></title>
            <link>https://blog.atusy.net/2025/03/13/drop-into-fish-from-bash/</link>
            <guid>https://blog.atusy.net/2025/03/13/drop-into-fish-from-bash/</guid>
            <pubDate>Thu, 13 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[fish shell、便利ですよね。デフォルトでもシンタックスハイライトや補完がよく効いてチューニングしなくてもそこそこ高速に起動するので日常使いしています。これまで chsh -s /usr/bin/fish してデフォルトシェルにfish shellを指定していましたが、Nixやhome-manager経由でfish shellを入れると特殊な場所にインストールされるため、chshできない問題に遭遇しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infrastructure Designing Injection ~ draw.ioに対して ~]]></title>
            <link>https://zenn.dev/akasan/articles/66d1fc03edde50</link>
            <guid>https://zenn.dev/akasan/articles/66d1fc03edde50</guid>
            <pubDate>Wed, 12 Mar 2025 14:38:56 GMT</pubDate>
            <content:encoded><![CDATA[Infrastructure Designing Injectionとは私が勝手に適当に思いついたものになります。業務の中で「Terraformで書いた構成をdraw.ioで図にしてくれると嬉しいよね」みたいなコメントがあり、その逆もできるんだろうなと思っていました。その時、もしdraw.ioの中に目には見えない情報を仕組んだら予期せぬ構成を作成させることができるのでは？と思い、それってInjectionだよねということで命名しました。Infrastructure Designing Injectionと書くと長いのでIDIと呼ばせてくださいw※ IDIというよりステガノ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovim Nightlyでターミナル内でプロンプト間をジャンプできるようになった（OSC133）]]></title>
            <link>https://blog.atusy.net/2025/03/12/nvim-osc133/</link>
            <guid>https://blog.atusy.net/2025/03/12/nvim-osc133/</guid>
            <pubDate>Wed, 12 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Vim駅伝2025-03-12の記事です。最近、NeovimがOSC 133に対応しました（https://github.com/neovim/neovim/pull/32736）。これにより、OSC 133に対応したシェルのユーザーであれば、[[ や ]] を使って、:terminal内のシェルプロンプト間をジャンプできるようになります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのTerraform職人が失職する機能が出てしまった……]]></title>
            <link>https://zenn.dev/nnaka2992/articles/intro_to_application_design_center</link>
            <guid>https://zenn.dev/nnaka2992/articles/intro_to_application_design_center</guid>
            <pubDate>Tue, 11 Mar 2025 00:30:01 GMT</pubDate>
            <content:encoded><![CDATA[Google CloudがApplication Design Centerという、構成図を書けばTerraformを書いて、デプロイまで行う機能をリリースしました。[1]https://cloud.google.com/application-design-center/docs/overviewどうやらGoogle CloudはTerraform職人を失職に追い込みたいようです。 Application Design Centerの概要アプリケーション デザイン センターは、Google Cloud アプリケーション インフラストラクチャの設計、共有、デプロイに役立ちます...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[tfmcp 🦀: A Rust-Implemented Tool to Operate Terraform from LLMs]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/10/091144</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/10/091144</guid>
            <pubDate>Mon, 10 Mar 2025 00:11:44 GMT</pubDate>
            <content:encoded><![CDATA[IntroductionHello! Today, I'd like to introduce a tool I recently developed called tfmcp. This tool allows you to operate Terraform from LLMs (Large Language Models) by utilizing the Model Context Protocol (MCP).github.comIf you like this project, please consider giving a Star to the GitHub repository to encourage development. Feedback is always welcome!What is MCP?Before diving in, let me briefly explain MCP (Model Context Protocol). For more detailed information, refer to the official documentation at modelcontextprotocol.io.Note: The image above is in Japanese but illustrates the MCP concept.MCP is a protocol that allows LLM clients like Cline or Cursor to connect with external services. Traditionally, LLMs could only "think" based on learned data, but with MCP, they gain the ability to "act" by connecting with external systems.MCP enables capabilities like:Editing files in NotionQuerying databasesChecking service statusEditing and operating local filesMCP is fundamentally a JSON-RPC-based protocol with three main components:Resources: Provide access to data (equivalent to REST API GET)Tools: Enable execution of actions (equivalent to REST API POST)Prompts: Guidance on how LLMs should use the servicetfmcp: Operating Terraform from LLMsNow, let me introduce tfmcp. It's a tool that utilizes MCP to enable operation of Terraform from LLMs (particularly Claude Desktop).Note: The image above is in Japanese but illustrates the tfmcp architecture.Main Features of tfmcpWith tfmcp, you can:Read and analyze Terraform configuration filesParse and explain Terraform plansApply Terraform configurationsManage Terraform stateCreate and modify configuration filesDemoHere's a demo of tfmcp working with Claude Desktop:In this demo, Claude operates a Terraform project through natural language commands.Installation and Setuptfmcp is written in Rust and can be easily installed using Cargo:cargo install tfmcpTo connect with Claude Desktop, find the path to the installed tfmcp executable and add it to Claude Desktop's configuration file:{     "mcpServers": {       "tfmcp": {         "command": "/path/to/your/tfmcp",         "args": ["mcp"],         "env": {           "HOME": "/Users/yourusername",           "PATH": "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin",           "TERRAFORM_DIR": "/path/to/your/terraform/project"      }    }  }}Technical Implementation in Rusttfmcp consists of these main components:tfmcp├── config      - Configuration management├── core        - Core logic├── mcp         - MCP protocol implementation├── shared      - Common utilities└── terraform   - Terraform integrationNote: The image above is in Japanese but illustrates the internal architecture of tfmcp.MCP Server ImplementationThe core of the MCP server is the McpHandler struct, which processes requests and executes appropriate Terraform commands:pub struct McpHandler<'a> {    tfmcp: &'a mut TfMcp,    initialized: bool,}impl<'a> McpHandler<'a> {    async fn handle_tools_call(        &mut self,        transport: &StdioTransport,        id: u64,        params_val: serde_json::Value,    ) -> anyhow::Result<()> {        let name = params_val            .get("name")            .and_then(|v| v.as_str())            .unwrap_or("");        match name {            "list_terraform_resources" => {                self.handle_list_terraform_resources(transport, id).await?;            }            "analyze_terraform" => {                self.handle_analyze_terraform(transport, id, &params_val).await?;            }            "get_terraform_plan" => {                self.handle_get_terraform_plan(transport, id).await?;            }            // Other tool handlers...        }        Ok(())    }}The MCP request/response flow:Note: The image above is in Japanese but illustrates the MCP request/response flow.Terraform ServiceThe Terraform service handles the actual integration with Terraform:pub struct TerraformService {    terraform_path: PathBuf,    project_directory: PathBuf,}impl TerraformService {    pub async fn apply(&self, auto_approve: bool) -> anyhow::Result<String> {        let mut args = vec!["apply", "-no-color"];        if auto_approve {            args.push("-auto-approve");        }        let output = Command::new(&self.terraform_path)            .args(&args)            .current_dir(&self.project_directory)            .output()?;        // Output processing        // ...    }        // Other methods for Terraform operations}JSON-RPC Implementationtfmcp uses Rust to implement the JSON-RPC 2.0 protocol:Note: The image above is in Japanese but illustrates the JSON-RPC implementation.The message types and transport are defined as follows:#[derive(Debug, Clone, Serialize, Deserialize)]#[serde(untagged)]pub enum Message {    Request {        #[serde(rename = "jsonrpc")]        jsonrpc: String,        #[serde(rename = "method")]        method: String,        #[serde(rename = "id")]        id: u64,        #[serde(rename = "params")]        #[serde(skip_serializing_if = "Option::is_none")]        params: Option<serde_json::Value>,    },    Notification { /* ... */ },    Response { /* ... */ },}#[async_trait]pub trait Transport: Send + Sync {    async fn send(&self, message: Message) -> Result<(), Error>;    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>>;    async fn close(&self) -> Result<(), Error>;}Security ConsiderationsWhen using MCP tools like tfmcp, be aware that:They can create, modify, and delete infrastructureThey have access to local files and potentially sensitive informationUntrusted MCP servers could pose security risksImplement these safety measures:Only install MCP servers from trusted sourcesGrant minimum required permissionsRun in sandboxed environments when possibleEnable audit loggingFilter sensitive informationConclusiontfmcp represents a step forward in integrating Terraform with LLMs. By leveraging the Model Context Protocol, it provides a natural language interface to infrastructure management, simplifying complex IaC (Infrastructure as Code) tasks.MCP itself acts as a bridge allowing AI models to safely access local resources and tools. The implementation is based on a simple JSON-RPC protocol, making it accessible for developers to create their own MCP servers for specific domains.The Rust implementation provides benefits like type safety, robust error handling, and efficient asynchronous processing, creating a reliable foundation for smooth interaction between AI and tools.Reference LinksModel Context Protocol Official DocumentationMCP GitHub RepositoryAnthropic's MCP Introduction Article]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MCPでLLMに行動させる - Terraformを例とした tfmcp の紹介]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057</guid>
            <pubDate>Sat, 08 Mar 2025 17:00:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは！今回は、私が最近開発した tfmcp というツールを紹介します。これは Terraform を LLM（大規模言語モデル）から操作できるようにするツールで、Model Context Protocol (MCP) を活用しています。github.comこのブログが良ければ読者になったり、GitHub リポジトリにStarをいただけると開発の励みになります。nwiizoをフォロワーしてくれるのもありがたいです。より良いツール開発のためのフィードバックもお待ちしています！MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月9日 現在)。TypeScript SDKPython SDKKotlin SDKJava SDKRust SDKしかし、MCP は標準的な JSON-RPC プロトコルをベースとしているため、任意のプログラミング言語で独自に実装することも可能です。本プロジェクト tfmcp では、Rust で実装しています。ちなみにJSON−RPCについて詳しく知りたい場合は「Real World HTTP 第3版」を読むととても勉強になるのでオススメです。Real World HTTP 第3版 ―歴史とコードに学ぶインターネットとウェブ技術作者:渋川 よしきオライリージャパンAmazon今後、どうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioJSON-RPC の基本MCP は JSON-RPC 2.0 仕様に基づいており、以下の3種類のメッセージ形式が使われます。リクエスト：クライアントからサーバーへの要求{     "jsonrpc": "2.0",     "id": 1,     "method": "tools/call",     "params": { /* パラメータ */ }}レスポンス：サーバーからクライアントへの応答{     "jsonrpc": "2.0",     "id": 1,     "result": { /* 結果オブジェクト */ }}エラー時：{     "jsonrpc": "2.0",     "id": 1,     "error": {       "code": -32700,       "message": "エラーメッセージ"  }}通知：レスポンスを必要としないサーバーからの一方的なメッセージ{     "jsonrpc": "2.0",     "method": "$/log",     "params": { /* パラメータ */ }}tfmcp: Terraform を LLM から操作するさて、本題の tfmcp の紹介に移ります。tfmcp は Model Context Protocol を活用して、LLM（特に Claude Desktop など）から Terraform の操作を可能にするツールです。tfmcp の主な機能tfmcp を使うと、以下のようなことが可能になります。Terraform 設定ファイルの読み取りプロジェクト内の .tf ファイルを解析し構造を理解Terraform プランの解析terraform plan の結果を解析して LLM に伝えるTerraform の適用設定をインフラに適用する terraform apply を実行状態管理Terraform の状態ファイルを管理・読み取り設定ファイルの作成・修正新しい Terraform 設定の作成や既存の設定の変更デモClaude Desktop と連携している tfmcp のデモを見てみましょう：このデモでは、Claude が自然言語で Terraform プロジェクトを操作し、分析、実行しています。インストール方法tfmcp は Rust で書かれており、Cargo を使って簡単にインストールできます。cargo install tfmcpソースからのインストールも可能です。# リポジトリをクローンgit clone https://github.com/nwiizo/tfmcpcd tfmcp# ビルドとインストールcargo install --path .Claude Desktop との連携方法Claude Desktop と tfmcp を連携するには、以下の手順を行います。まず、tfmcp をインストールします。bashcargo install tfmcpインストールされた tfmcp 実行ファイルのパスを見つけます。bashwhich tfmcpClaude Desktop の設定ファイルを開き、以下の設定を追加します。{     "mcpServers": {       "tfmcp": {         "command": "/path/to/your/tfmcp",  // 実際のパスに置き換えてください         "args": ["mcp"],         "env": {           "HOME": "/Users/yourusername",  // あなたのユーザー名に置き換えてください           "PATH": "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin",           "TERRAFORM_DIR": "/path/to/your/terraform/project"  // オプション：Terraformプロジェクトのパス      }    }  }}Claude Desktop を再起動し、tfmcp ツールを有効にします。もし Terraform プロジェクトが存在しない場合、tfmcp は自動的に ~/terraform に基本的なサンプルプロジェクトを作成します。使用例tfmcp の使い方や詳細なドキュメントは GitHub リポジトリの README で確認できます。以下のようなシナリオで特に役立ちます。Terraform 設定の説明と理解「このプロジェクトで使われている Terraform リソースを分析して」設定の検証とトラブルシューティング「この Terraform プロジェクトのエラーを見つけて修正して」インフラの計画と適用「このプランを実行するとどうなるか説明して」「この変更を適用して結果を報告して」設定の自動生成「S3バケットとIAMポリシーを作成する Terraform コードを書いて」セキュリティに関する考慮事項tfmcp を使用する際には、以下の点に注意が必要です。tfmcp は Terraform コマンドをユーザーに代わって実行するため、インフラの作成、変更、削除が可能です本番環境では、適切な IAM 権限やロール境界を使用することを検討してくださいAI によって生成された Terraform プランは、適用前に必ず確認してくださいTerraform の状態ファイルに含まれる機密情報が AI アシスタントからアクセス可能になる可能性がありますMCP自体のセキュリティリスク作っていて思ったんですけどMCPはLLMにローカル環境への強いアクセス権を付与するので、本質的にセキュリティ上の懸念があります。普通にもう狙ってきていると思いますのでむやみやたらにインストールするのはやめましょう。サードパーティMCPサーバーのリスク: 信頼できない「野良MCPサーバー」をインストールすると、マルウェアや情報漏洩のリスクが高まります。MCPサーバーはローカルファイルシステムや他のリソースへのアクセス権を持つため、悪意のあるコードを実行される可能性があります。権限の過剰付与: MCPサーバーが必要以上の権限を持つと、攻撃者がLLMとの対話を通じてシステムリソースに不正アクセスする可能性があります。データ漏洩のリスク: ローカルファイルやクレデンシャルなどの機密情報が、LLMとの対話を通じて外部に漏洩する可能性があります。プロンプトインジェクション攻撃: 悪意あるプロンプトを通じて、MCPサーバーに予期しない操作を実行させるリスクがあります。安全なMCP利用のための注意事項以下の対策を実施することで、MCPの安全な利用が多少、可能になります。それでも完璧ではないです。金払ってくれるなら作ってやるから連絡してくれ。信頼できるソースからのみMCPサーバーをインストール: 公式リポジトリや信頼できる開発者からのMCPサーバーのみを使用し、コードを確認してから実行してください。最小権限の原則を適用: MCPサーバーには必要最小限の権限のみを付与し、特に本番環境や機密データへのアクセスは制限してください。サンドボックス環境での実行: 可能であれば、MCPサーバーを隔離された環境で実行し、重要なシステムやデータへのアクセスを制限してください。監査ログの有効化: MCPサーバーを通じて実行されたすべてのコマンドや操作を記録し、不審な活動がないかを定期的に確認してください。機密情報のフィルタリング: LLMに送信される前に、APIキーやパスワードなどの機密情報を検出・削除するメカニズムを実装してください。定期的なセキュリティレビュー: MCPサーバーの設定やコードを定期的にレビューし、セキュリティの脆弱性がないかを確認してください。tfmcpを含むMCPサーバーは強力なツールですが、その力は適切に管理されなければリスクにもなり得ます。特に初めての利用時は、非本番環境でのテストから始め、リスクを理解した上で徐々に本番環境への導入を検討することをお勧めします。tfmcp の技術的詳細と実装tfmcp の内部実装について詳しく説明します。全体アーキテクチャtfmcp は大きく分けて以下のコンポーネントから構成されています。tfmcp├── config      - 設定管理├── core        - コアロジック├── mcp         - MCPプロトコル実装├── shared      - 共通ユーティリティ└── terraform   - Terraform連携主要コンポーネントの詳細1. MCP サーバー (src/mcp/)MCPサーバーは、LLMクライアント（Claude Desktopなど）との通信を処理する部分です。主に以下のファイルから構成されています。handler.rs: MCPリクエストの処理とレスポンスの生成stdio.rs: 標準入出力を使った通信の実装handler.rs の核となる部分は McpHandler 構造体で、リクエストに応じて適切なTerraformコマンドを実行します。pub struct McpHandler<'a> {    tfmcp: &'a mut TfMcp,    initialized: bool,}impl<'a> McpHandler<'a> {    // ...    async fn handle_tools_call(        &mut self,        transport: &StdioTransport,        id: u64,        params_val: serde_json::Value,    ) -> anyhow::Result<()> {        let name = params_val            .get("name")            .and_then(|v| v.as_str())            .unwrap_or("");        match name {            "list_terraform_resources" => {                self.handle_list_terraform_resources(transport, id).await?;         }            "analyze_terraform" => {                self.handle_analyze_terraform(transport, id, &params_val).await?;         }            "get_terraform_plan" => {                self.handle_get_terraform_plan(transport, id).await?;         }            // 他のツール処理...     }        Ok(()) }        // 各ツールの実装...}MCPのリクエスト/レスポンスフローを図示すると次のようになります。2. Terraform サービス (src/terraform/)Terraformとの実際の連携を担当するコンポーネントです。主に以下のファイルで構成されています。service.rs: Terraformコマンドの実行とその結果の解析model.rs: Terraformの設定やステート用のデータモデルTerraformService 構造体が主要なインターフェースを提供します。pub struct TerraformService {    terraform_path: PathBuf,  // terraform実行ファイルのパス    project_directory: PathBuf,  // Terraformプロジェクトのディレクトリ}impl TerraformService {    // 初期化    pub fn new(        terraform_path: PathBuf,        project_directory: PathBuf,    ) -> Result<Self, TerraformError> {        // ... 検証ロジック ... }    // プロジェクトディレクトリの変更    pub fn change_project_directory(        &mut self,        new_directory: PathBuf,    ) -> Result<(), TerraformError> {        // ... ディレクトリ変更ロジック ... }    // Terraformコマンドの実行    pub async fn apply(&self, auto_approve: bool) -> anyhow::Result<String> {        let mut args = vec!["apply", "-no-color"];        if auto_approve {            args.push("-auto-approve");     }        let output = Command::new(&self.terraform_path)            .args(&args)            .current_dir(&self.project_directory)            .output()?;        // ... 出力処理 ... }    // 設定ファイルの解析    pub async fn analyze_configurations(&self) -> anyhow::Result<TerraformAnalysis> {        // ... 解析ロジック ... }    // その他のメソッド...}3. コア (src/core/)TfMcp 構造体は、アプリケーションの中心的なコントローラーとして機能し、MCPハンドラーとTerraformサービスを橋渡しします。pub struct TfMcp {    config: Config,    terraform_service: TerraformService,}impl TfMcp {    pub fn new(config_path: Option<String>, project_dir: Option<String>) -> anyhow::Result<Self> {        // ... 初期化ロジック ... }    pub async fn launch_mcp(&mut self) -> anyhow::Result<()> {        // ... MCPサーバー起動ロジック ... }    // Terraformサービスへの橋渡し    pub async fn analyze_terraform(&mut self) -> anyhow::Result<()> {        let analysis = self.terraform_service.analyze_configurations().await?;        println!("{}", serde_json::to_string_pretty(&analysis)?);        Ok(()) }    // その他のメソッド...}4. 設定管理 (src/config/)アプリケーションの設定を管理します。設定ファイルからの読み込みと、デフォルト設定の提供を担当します。pub struct Config {    pub terraform: TerraformConfig,    pub mcp: McpConfig,}pub fn init_default() -> anyhow::Result<Config> {    // ... デフォルト設定ロジック ...}pub fn init_from_path(path: &str) -> anyhow::Result<Config> {    // ... 設定ファイル読み込みロジック ...}実装の特徴高速なパフォーマンス：Rust のエコシステムを活用した高速な処理自動セットアップ：必要に応じてサンプル Terraform プロジェクトを自動作成エラー処理：適切なエラーメッセージとロギングプロジェクトディレクトリの動的切り替え：実行中にプロジェクトディレクトリを変更可能Rust での JSON-RPC 2.0 実装tfmcp では Rust で JSON-RPC 2.0 を実装するために、標準的なアプローチを採用しています。以下は JSON-RPC メッセージの定義と処理の詳細な実装方法です。1. 依存パッケージの設定まず、Cargo.toml に必要な依存関係を定義します。[dependencies]serde = { version = "1.0", features = ["derive"] }serde_json = "1.0"anyhow = "1.0"thiserror = "1.0"tokio = { version = "1.0", features = ["full"] }futures = "0.3"async-trait = "0.1"2. メッセージ構造体とエラー型の定義use serde::{Deserialize, Serialize};use std::pin::Pin;use std::sync::{Arc, Mutex};use tokio::sync::broadcast;use futures::Stream;use async_trait::async_trait;// JSON-RPC エラーコード#[derive(Debug)]#[allow(dead_code)]pub enum JsonRpcErrorCode {    ParseError = -32700,    InvalidRequest = -32600,    MethodNotFound = -32601,    InvalidParams = -32602,    InternalError = -32603,    // カスタムエラーコード（-32000 から -32099 の範囲）    TerraformNotFound = -32000,    InvalidProjectDirectory = -32001,}// トランスポートエラー#[derive(thiserror::Error, Debug, Clone)]pub enum Error {    #[error("IO error: {0}")]    Io(String),        #[error("Serialization error: {0}")]    Serialization(String),        #[error("Other error: {0}")]    Other(String),}// JSON-RPC メッセージ#[derive(Debug, Clone, Serialize, Deserialize)]#[serde(untagged)]pub enum Message {    Request {        #[serde(rename = "jsonrpc")]        jsonrpc: String,        #[serde(rename = "method")]        method: String,        #[serde(rename = "id")]        id: u64,        #[serde(rename = "params")]        #[serde(skip_serializing_if = "Option::is_none")]        params: Option<serde_json::Value>, },    Notification {        #[serde(rename = "jsonrpc")]        jsonrpc: String,        #[serde(rename = "method")]        method: String,        #[serde(rename = "params")]        #[serde(skip_serializing_if = "Option::is_none")]        params: Option<serde_json::Value>, },    Response {        #[serde(rename = "jsonrpc")]        jsonrpc: String,        #[serde(rename = "id")]        id: u64,        #[serde(rename = "result")]        #[serde(skip_serializing_if = "Option::is_none")]        result: Option<serde_json::Value>,        #[serde(rename = "error")]        #[serde(skip_serializing_if = "Option::is_none")]        error: Option<serde_json::Value>, },}ここで重要なのは：#[serde(untagged)] アノテーションにより、3種類のメッセージタイプを同じ列挙型で表現#[serde(skip_serializing_if = "Option::is_none")] で null 値のフィールドを出力しない設定thiserror を使った明確なエラー型の定義3. トランスポートトレイトとその実装JSON-RPC メッセージの送受信を行うための抽象インターフェースとして、トランスポートトレイトを定義します。#[async_trait]pub trait Transport: Send + Sync {    // メッセージを送信する    async fn send(&self, message: Message) -> Result<(), Error>;        // メッセージストリームを受け取る    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>>;        // トランスポートを閉じる    async fn close(&self) -> Result<(), Error>;}標準入出力を使ったトランスポート実装例：pub struct StdioTransport {    stdout: Arc<Mutex<std::io::Stdout>>,    receiver: broadcast::Receiver<Result<Message, Error>>,}impl StdioTransport {    pub fn new() -> (Self, broadcast::Sender<Result<Message, Error>>) {        let (sender, receiver) = broadcast::channel(100);        let transport = Self {            stdout: Arc::new(Mutex::new(std::io::stdout())),            receiver,     };        // 標準入力からの読み取りをバックグラウンドで実行        let stdin = tokio::io::stdin();        let mut reader = tokio::io::BufReader::new(stdin);        let sender_clone = sender.clone();        tokio::spawn(async move {            let mut line = String::new();            loop {                line.clear();                match reader.read_line(&mut line).await {                    Ok(0) => break, // EOF                    Ok(_) => {                        // 空白を除去して解析の問題を回避                        let trimmed_line = line.trim();                        eprintln!("[DEBUG] Received JSON: {}", trimmed_line);                                                // JSON-RPC メッセージを解析                        let parsed = parse_json_message(trimmed_line);                        if sender_clone.send(parsed).is_err() {                            eprintln!("[ERROR] Failed to send parsed message to channel");                            break;                     }                 }                    Err(e) => {                        eprintln!("[ERROR] Error reading from stdin: {}", e);                        let _ = sender_clone.send(Err(Error::Io(                            format!("Error reading from stdin: {}", e))                        ));                        break;                 }             }         }     });        (transport, sender) }}#[async_trait]impl Transport for StdioTransport {    async fn send(&self, message: Message) -> Result<(), Error> {        let mut stdout = self.stdout.lock()            .map_err(|_| Error::Other("Failed to lock stdout".into()))?;        // メッセージを JSON 文字列に変換        let json = match serde_json::to_string(&message) {            Ok(s) => s,            Err(e) => return Err(Error::Serialization(                format!("JSON serialization error: {}", e)            )),     };        // デバッグログ用に送信するJSONを出力        let truncated_json = if json.len() > 500 {            format!("{}... (truncated)", &json[0..500])     } else {            json.clone()     };        eprintln!("[DEBUG] Sending JSON: {}", truncated_json);        // JSON 文字列を改行付きで出力し、フラッシュ        if let Err(e) = writeln!(stdout, "{}", json) {            return Err(Error::Io(format!("Failed to write to stdout: {}", e)));     }        if let Err(e) = stdout.flush() {            return Err(Error::Io(format!("Failed to flush stdout: {}", e)));     }        Ok(()) }    fn receive(&self) -> Pin<Box<dyn Stream<Item = Result<Message, Error>> + Send>> {        let rx = self.receiver.resubscribe();        Box::pin(futures::stream::unfold(rx, |mut rx| async move {            match rx.recv().await {                Ok(msg) => Some((msg, rx)),                Err(_) => None,         }     })) }    async fn close(&self) -> Result<(), Error> {        Ok(()) }}よりロバストなJSONパース処理の実装：// エラー対応の改善されたJSONメッセージパース関数fn parse_json_message(json_string: &str) -> Result<Message, Error> {    // 空入力のバリデーション    if json_string.is_empty() {        return Err(Error::Serialization("Empty JSON string".into())); }    // 一般的なJSON問題を修正    let mut processed_json = json_string.to_string();    // 問題のある空白文字を除去    processed_json = processed_json.replace(['\n', '\r', '\t'], " ");    // エスケープされていないバックスラッシュと引用符の処理    if processed_json.contains("\\\\") || processed_json.contains("\\\"") {        processed_json = processed_json            .replace("\\\\", "\\")            .replace("\\\"", "\""); }    // 修正された文字列で解析を試行    let parse_result = serde_json::from_str::<Message>(&processed_json);    match parse_result {        Ok(msg) => Ok(msg),        Err(e) => {            eprintln!("[ERROR] JSON parse error: {}. Input: {}", e, processed_json);            // 追加診断情報の提供            if let Ok(value) = serde_json::from_str::<serde_json::Value>(&processed_json) {                eprintln!("[DEBUG] JSON parsed as generic value: {:?}", value);         } else {                eprintln!("[ERROR] Could not parse JSON even as generic value");         }            Err(Error::Serialization(format!("JSON parse error: {}", e)))     } }}4. リクエスト処理とメソッドディスパッチMCP サーバー内でのリクエスト処理は、メソッド名に基づいてディスパッチ（振り分け）します。pub struct McpHandler<'a> {    tfmcp: &'a mut TfMcp,    initialized: bool,}impl<'a> McpHandler<'a> {    pub fn new(tfmcp: &'a mut TfMcp) -> Self {        Self {            tfmcp,            initialized: false,     } }    pub async fn launch_mcp(&mut self, transport: &StdioTransport) -> anyhow::Result<()> {        let mut stream = transport.receive();        logging::info("MCP stdio transport server started. Waiting for JSON messages on stdin...");                // メッセージループ        while let Some(msg_result) = stream.next().await {            match msg_result {                Ok(Message::Request { id, method, params, .. }) => {                    logging::debug(&format!(                        "Got Request: id={}, method={}, params={:?}",                        id, method, params                    ));                    // 初期化リクエストの特別処理                    if method == "initialize" {                        if let Err(err) = self.handle_initialize(transport, id).await {                            logging::error(&format!("Error handling initialize request: {}", err));                     }                        self.initialized = true;                        continue;                 }                    // 他のすべてのリクエストでは、初期化されていることを確認                    if !self.initialized {                        self.send_error_response(                            transport,                            id,                            JsonRpcErrorCode::InvalidRequest,                            "Server not initialized. Send 'initialize' request first.".to_string(),                        ).await?;                        continue;                 }                    // リクエスト処理の実行                    if let Err(err) = self.handle_request(transport, id, method, params).await {                        logging::error(&format!("Error handling request: {:?}", err));                        self.send_error_response(                            transport,                            id,                            JsonRpcErrorCode::InternalError,                            format!("Failed to handle request: {}", err),                        ).await?;                 }             }                Ok(Message::Notification { method, params, .. }) => {                    logging::debug(&format!("Got Notification: method={}, params={:?}", method, params));                    // 通知の処理（必要に応じて）             }                Ok(Message::Response { id, result, error, .. }) => {                    logging::debug(&format!(                        "Got Response: id={}, result={:?}, error={:?}",                        id, result, error                    ));                    // レスポンスの処理（必要に応じて）             }                Err(e) => {                    logging::error(&format!("Error receiving message: {:?}", e));             }         }     }        Ok(()) }    async fn handle_request(        &mut self,        transport: &StdioTransport,        id: u64,        method: String,        params: Option<serde_json::Value>,    ) -> anyhow::Result<()> {        match &*method {            "initialize" => self.handle_initialize(transport, id).await?,            "tools/list" => self.handle_tools_list(transport, id).await?,            "tools/call" => {                if let Some(params_val) = params {                    self.handle_tools_call(transport, id, params_val).await?;             }         }            "resources/list" => self.handle_resources_list(transport, id).await?,            "prompts/list" => self.handle_prompts_list(transport, id).await?,            _ => {                self.send_error_response(                    transport,                    id,                    JsonRpcErrorCode::MethodNotFound,                    format!("Method not found: {}", method),                ).await?;         }     }        Ok(()) }}5. レスポンス送信メソッド成功レスポンスとエラーレスポンスのヘルパーメソッド：impl<'a> McpHandler<'a> {    // テキストコンテンツを持つレスポンスを送信    async fn send_text_response(        &self,        transport: &StdioTransport,        id: u64,        text: &str,    ) -> anyhow::Result<()> {        logging::info(&format!("Sending text response for id {}", id));        // 適切に構造化されたテキストレスポンスを作成        let response = Message::Response {            jsonrpc: "2.0".to_string(),            id,            result: Some(json!({                "content": [{                    "type": "text",                    "text": text             }]         })),            error: None,     };        // レスポンスをログに記録（デバッグ用）        if let Ok(json_str) = serde_json::to_string_pretty(&response) {            logging::debug(&format!("Sending text response: {}", json_str));     }        // レスポンスを送信        match transport.send(response).await {            Ok(_) => {                logging::info("Text response sent successfully");                Ok(())         }            Err(e) => {                logging::error(&format!("Failed to send text response: {}", e));                Err(anyhow::anyhow!("Failed to send text response: {}", e))         }     } }    // エラーレスポンスを送信    async fn send_error_response(        &self,        transport: &StdioTransport,        id: u64,        code: JsonRpcErrorCode,        message: String,    ) -> anyhow::Result<()> {        logging::warn(&format!(            "Sending error response for id {}: {}",            id, message        ));        // 適切に構造化されたエラーレスポンスを作成        let response = Message::Response {            jsonrpc: "2.0".to_string(),            id,            result: None,            error: Some(json!({                "code": code as i32,                "message": message         })),     };        // レスポンスをログに記録（デバッグ用）        if let Ok(json_str) = serde_json::to_string_pretty(&response) {            logging::debug(&format!("Sending error response: {}", json_str));     }        // レスポンスを送信        match transport.send(response).await {            Ok(_) => {                logging::info("Error response sent successfully");                Ok(())         }            Err(e) => {                logging::error(&format!("Failed to send error response: {}", e));                Err(anyhow::anyhow!("Failed to send error response: {}", e))         }     } }}6. 具体的なメソッドハンドラの実装例例として、tools/list メソッドのハンドラ実装：async fn handle_tools_list(&self, transport: &StdioTransport, id: u64) -> anyhow::Result<()> {    // ツール一覧を含むJSONを取得    let tools_value: serde_json::Value = serde_json::from_str(TOOLS_JSON)        .expect("tools.json must be valid JSON");    // レスポンスを作成して送信    let response = Message::Response {        jsonrpc: "2.0".to_string(),        id,        result: Some(tools_value),        error: None, };    transport.send(response).await?;    Ok(())}ツール呼び出しハンドラの実装例：async fn handle_tools_call(    &mut self,    transport: &StdioTransport,    id: u64,    params_val: serde_json::Value,) -> anyhow::Result<()> {    let name = params_val        .get("name")        .and_then(|v| v.as_str())        .unwrap_or("");    logging::info(&format!("Handling tools/call for tool: {}", name));    match name {        "get_terraform_plan" => {            // Terraform プランを取得            match self.tfmcp.get_terraform_plan().await {                Ok(plan) => {                    // 結果のJSONを構築                    let result_json = json!({ "plan": plan });                    let obj_as_str = serde_json::to_string(&result_json)?;                                        // テキストレスポンスとして送信                    self.send_text_response(transport, id, &obj_as_str).await?;             }                Err(err) => {                    // エラーレスポンスを送信                    self.send_error_response(                        transport,                        id,                        JsonRpcErrorCode::InternalError,                        format!("Failed to get Terraform plan: {}", err),                    ).await?;             }         }     }        // 他のツールハンドラ...        _ => {            self.send_error_response(                transport,                id,                JsonRpcErrorCode::MethodNotFound,                format!("Tool not found: {}", name),            ).await?;     } }    Ok(())}これらのコードパターンにより、tfmcp は MCP プロトコルの JSON-RPC メッセージを効率的に処理し、Terraform コマンドの実行結果をクライアントに返すことができます。Rust の主要な利点としては以下が挙げられます。型安全性: serde による強力なシリアライズ/デシリアライズの型検証強力なエラーハンドリング: Result 型と thiserror によるエラー処理非同期処理: tokio と async/await による効率的な非同期I/Oトレイトベースの抽象化: Transport トレイトによる異なる通信方式のサポートメモリ安全性: ランタイムの安全性とパフォーマンスおわりにtfmcp は、Terraform と LLM の統合における最初の一歩です。MCP（Model Context Protocol）に関して色々説明してきましたが、すごく簡単に言うなら「LLMのためのAPIサーバー」です。この技術を活用することで、インフラストラクチャの管理に自然言語インターフェースをもたらし、複雑な IaC (Infrastructure as Code) の作業を簡素化することができます。Model Context Protocol は、AIモデルがローカル環境のリソースやツールに安全にアクセスするための架け橋となります。実装自体はシンプルなJSON-RPCベースのプロトコルなので、皆さんも自分の得意な分野や業務で使えるMCPサーバーを実装してみてください。AIとのコラボレーションの可能性が大きく広がるはずです。Rust による実装は、型安全性、堅牢なエラー処理、効率的な非同期処理など、多くの利点をもたらしています。特に通信プロトコルの実装において、これらの特性は重要な役割を果たし、AIとツールの間のやり取りをスムーズかつ確実に行うための信頼性の高い基盤となっています。とても楽しいです。また、こちらも応援お願いします。こちらCfPを書きました。皆様の応援が力になるので投票お願いします。生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について | CloudNative Days Summer 2025 https://t.co/vs2EfE2m41 #CNDS2025— nwiizo (@nwiizo) 2025年2月25日   あ、会社にも所属していて技術支援もやっているので興味があれば話をしましょうやー！sreake.com各種参考リンクModel Context Protocol 公式ドキュメントMCP メッセージフォーマットとトランスポート仕様MCP GitHub リポジトリMCP TypeScript SDKAnthropic の MCP 紹介記事Cline における MCP の解説記事MCPで広がるLLM　~Clineでの動作原理~]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Qiitaの自己紹介欄に何書く？　というポエム]]></title>
            <link>https://qiita.com/masaru-komiyama/items/781912e64e09d5ac8e90</link>
            <guid>https://qiita.com/masaru-komiyama/items/781912e64e09d5ac8e90</guid>
            <pubDate>Fri, 07 Mar 2025 13:22:22 GMT</pubDate>
            <content:encoded><![CDATA[はじめに皆様、こんばんは。カラーコードの覚え方 や、適当なプログラムを書いた共有に超初級編などと銘打つ記事 など、 ふと頭によぎった技術ネタや、興味が湧いた技術ネタなど、一貫性の無いネタを自由に…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[無限技術的負債 - Taming Your Dragon: Addressing Your Technical Debt の読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/07/133504</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/07/133504</guid>
            <pubDate>Fri, 07 Mar 2025 04:35:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「Taming Your Dragon: Addressing Your Technical Debt」を読み終えて、技術的負債という厄介な問題への理解が大きく深まりました。この本は2024年7月にO'Reillyから出版され、技術的負債というドラゴンの正体とその退治法について包括的に解説しています。多くのエンジニアにとって身近な「誰がこんなコードを書いたんだ！...あ、私か」という経験から始まり、技術的負債の本質と効果的な管理方法へと読者を導いてくれます。learning.oreilly.com私たちエンジニアは普段、「美しいコードを書く芸術家」か「とりあえず動けばOKの実務家」かという二択で自分を見がちです。しかし実際には、納期に追われて「まぁ動くからいっか」と書いたコードが、数ヶ月後に「誰だこんな恐ろしいものを作ったのは！」という悲鳴に変わる悪夢のループから抜け出せないことも多いのではないでしょうか。これこそが「技術的負債」という悪魔もしくはドラゴンの卵が孵化する瞬間です。平凡なプログラマー・nwiizoは、ある日、長年使われてきた古い社内システム「Ｃシステム」でごく普通のプログラム部品を追加しようとしたところ、突然画面にエラーメッセージが溢れ、システムが完全に動かなくなってしまいます。会社の先輩プログラマーたちから、この巨大で一体化した管理システムを操作する権限をもらいましたが、すでに修正すべき不具合リストには何百もの未解決問題が積み上がっている状態で、自分の問題が解決される順番はいつになるかわかりません。nwiizoはシステム停止の警告に悩まされながら待ち続けますが、調査するうちにこのシステムの内部構造が信じられないほど複雑に絡み合っていることに気づきます。プログラムの中には決まった数値をむやみに書き換える人、テスト用の環境で好き勝手に変更する人、コードの整理に奮闘する人、緊急の修正を求めて管理者に詰め寄る人など、様々な混乱が広がっていました。nwiizoは問題を見つけるための様々な道具を使いますが、なぜかシステムの根本からの改善は「前例がない」と許可されません。この状況から逃げ出そうとしても、このシステムの外側には、この古いシステムに頼って動いている無数の小さなサービスプログラムが広がっていました。まるで古い城の土台が崩れかけているのに、その上に次々と新しい部屋を増築しているような状態です。nwiizoは気づきます。今はまさに《技術的負債の時代》、すべてのコードが少しずつ劣化し、誰も全体を理解できない環境に自分はいるのだと。あなたも、きっと「誰がこんなコードを書いたんだ！」と頭を抱えながらチケットキューに並んだことがあるでしょう。あるいは数ヶ月前の自分が書いたハードコードされた値を見て「これ誰が書いたんだ？...あ、私か」と冷や汗をかいたことがあるはずです。安心してください、あなたやnwiizoだけではありません。私たちは皆、技術的負債というドラゴンの前で怯えているのです。技術的負債の起源と本質「技術的負債」という言葉は近年広く使われるようになりましたが、その明確な定義はなく、理解が曖昧なまま用いられることが多いのが現状です。Ward Cunningham氏が技術的負債の概念の生みの親と言われていますが、最初に"負債"という言葉を用いたのは1992年のOOPSLA '92 Experience Reportでした。「最初のバージョンをリリースすることは、ある意味で借金を背負うようなものです」興味深いことに、レポート全体を見てもdebt（負債）としか言及しておらず、technical（技術的）という言葉は付いていません。後に彼自身がWikiで解説しているように、このメタファーが生まれた背景は純粋に学術的なものではなく、職場でのコミュニケーションにおいて、金融ソフトウェアを開発していた彼が上司に説明するために使った「金融の例え話」だったのです。t_wadaさんによる翻訳記事でも詳しく解説されています。その後、いつ頃からか「技術的負債（Technical Debt）」という言葉が広まっていきましたが、いつ誰が最初に「技術的」を付け加えたのかは明確ではありません。Cunningham氏は技術的負債について次のように説明しています。「ソフトウェアを急いでリリースし、開発過程で様々な気づきを得ても、それらの学びをコードに反映しないケースは数多くあります。これは返済不要だと思って借金をするようなものです。たとえばクレジットカードの場合、そんなことを続けていれば、最終的には収入のすべてが利息の支払いに消え、実質的な購買力はゼロになってしまうでしょう」「負債というメタファーの本質は、その返済能力にあります。これをうまく活用できるかどうかは、問題を理解した時点でリファクタリングできるような、きちんと構造化されたコードを書けるかどうかにかかっているのです」技術的負債に抱く多くの人のイメージはネガティブなものですが、Cunningham氏の説明にはそのようなニュアンスはありません。彼はあくまで「リファクタリング可能な十分に設計されたコード」を前提に話しており、「不摂生により病気になってしまった」ようなネガティブな状況ではなく、「成長して身体に合わなくなった服や靴を替える」ような状況をイメージしていたのです。乱雑なコードは技術的負債なのか？『Clean Architecture』などのCleanシリーズでお馴染みのRobert C. Martin氏（通称ボブおじさん）は、技術的負債と単なる乱雑さを明確に区別しています。「乱雑さは技術的負債ではありません。乱雑さはただの乱雑さです。技術的負債は意識的な選択の結果であり、戦略的な理由から生じるものです。リスクはあっても将来的な価値があります。一方、乱雑なコードを作る決断は合理的ではなく、ただの怠慢と不注意から生じるものであり、将来的な価値はありません」Martin氏も、Ward Cunningham氏と同様に雑なコードには賛成しておらず、「技術的負債は戦略的に選択されるものであり、単なる乱雑さとは異なる」と強調しています。技術的負債の多角的理解Martin Fowler氏は技術的負債の四象限という概念を提唱し、「無鉄砲／慎重」と「意図的／不注意」という二つの軸で負債を分類しました。この四象限フレームワークは、技術的負債をより体系的に考えるための重要なツールです。例えば「慎重・意図的」な負債は、ビジネス価値を早期に提供するための意識的な選択である一方、「無鉄砲・不注意」な負債は単に悪い設計の結果として発生します。Fowler氏によれば、技術的負債の議論において重要なのは次の点です。「設計上の問題が負債に当たるかどうかを議論するよりも、負債というメタファーがその問題を考えたり議論したりする助けになるかどうかを考えるべきです。このメタファーの大きな利点は、技術者以外の人々にも理解されやすい点にあります」また、Fowler氏は別の記事TechnicalDebtでも技術的負債について考察し、次のような洞察を提供しています。「品質の低いコードは、驚くほど早く影響を及ぼします。緊急の機能追加が遅延するのです。技術的負債を蓄積したチームは、コード品質の向上に時間をかけたチームよりも、結果的に開発のペースが落ちてしまいます」これは技術的負債の重要な側面を示しています。負債の影響は将来の問題だけでなく、すぐに現在の開発速度にも影響を与えるのです。技術的負債は本質的に技術的問題というよりもトレードオフの意思決定問題です。負債のメタファーはソフトウェア開発の状況を非技術者にも説明しやすくする点で有用ですが、全ての状況に当てはまるわけではありません。金融の負債に対する理解は人によって異なり、ソフトウェア開発のすべての側面を金融の仕組みで説明することには限界があります。本書「Taming Your Dragon」では、技術的負債の本質、その影響、そして効果的な管理方法について詳しく解説されています。短期的な利益（機能の早期リリース）と長期的なコスト（保守性の低下）のバランスをどう取るべきか、組織全体でどのように技術的負債に取り組むべきかなど、実践的なアプローチが示されています。心の準備はいいですか？ nwiizoと同じように、コードの迷宮へと足を踏み入れる勇気を持ちましょう！Part I Exploring Technical Debt1. What Is Technical Debt?基本概念の再定義技術的負債は本質的に技術的問題ではなくトレードオフの意思決定問題です。Technopediaによれば「容易だが限定的な解決策を選択した際に発生する将来的な再作業のコスト」と定義されます。つまり、単なる「悪いコード」ではなく、短期的利益（機能追加や早期納品）と長期的コスト（保守性低下）の間の意識的選択の結果です。Taming Your Dragon: Addressing Your Technical Debt (English Edition)作者:Brown, Dr. Andrew RichardApressAmazon昨今のソフトウェア開発現場では、何か問題が発生すると「技術的負債のせいだ」と安易に結論づける風潮が見られます。しかし、この「技術的負債」という言葉が本来の意味から逸脱し、単なる言い訳や責任転嫁の道具になっていないでしょうか。すべての問題が技術的負債に起因するという考え方は、複雑な開発現場の実態を過度に単純化している可能性があります。実際には、プロジェクト管理の不備、要件定義の曖昧さ、あるいは単純な実装ミスなど、多様な要因が問題の背景に存在することが多いのです。技術的負債の玉ねぎモデル著者が提案する多層構造モデルは、技術的負債を複数の層で捉えます。Figure 1-1 The technical debt onion model より引用テクニカル層はコードやアーキテクチャの問題、トレードオフ層は個人の意思決定メカニズム、システム層は組織構造の影響、さらに経済学/ゲーム理論層と厄介な問題層（複雑で一義的解決策のない問題）があります。このモデルが示唆するのは、技術的負債を持続的に管理するには全ての層に取り組む必要があるということです。表面的な修正だけでは、時間の経過とともに元の状態に戻ってしまいます。技術的負債の分類法Fowlerの4象限（慎重/無謀 × 意図的/無意識的）は代表的な分類です。Figure 1-2 The technical debt quadrant より引用金利率による分類も実用的です。高金利負債は放置すると急速にコスト増大する領域、低金利負債は影響が限定的な領域、無金利負債は実質的な影響がない領域です。レベルによる分類では、アーキテクチャ負債（最もコストが高い）、コード負債、その他の負債に区分されます。SDLCステージによる分類はどの開発段階で負債が発生したかを示し、トレードオフの種類による分類は何と引き換えに負債を受け入れたかを明らかにします。負債管理の実践的アプローチ高金利負債から優先的に返済することが重要です。頻繁に変更される中核コンポーネントの負債を最優先すべきです。技術的負債の影響を経営層が理解できる言葉で表現することも効果的です。「このリファクタリングを後回しにすると保守コストが20%増加します」など、具体的な数字で示すと説得力が増します。がこのときにはやはり数字的な根拠が必要です。組織構造の影響を理解することも大切です。コンウェイの法則を認識し、部門横断的視点で負債を可視化する必要があります。継続的な管理プロセスを確立することも不可欠です。単発の対処ではなくシステムとしての改善が求められます。まとめ技術的負債を効果的に管理するには、技術者だけでなく、マネージャーやステークホルダーを含めた組織全体の協力が必要です。単一のモデルや手法に頼るのではなく、複数の視点を統合し状況に応じて適切なアプローチを選択できるアダプティブな姿勢が鍵となります。2. Why You Need to Address Technical Debt負債の二面性を理解する技術的負債は必ずしも「悪」ではないです。著者は金融負債との類似性を指摘し、適切に管理された技術的負債が組織に価値をもたらす場合もあると説明しています。家を購入するためのモーゲージのように、戦略的に活用すれば事業価値を生み出すことができるのです。しかし、「返済できない負債」「より良い代替手段がある場合」「間違った資金調達を選んだ場合」には問題が発生します。この金融アナロジーは非技術系の経営層にも理解しやすく、共通認識を築く上で役立つと感じました。『良い戦略、悪い戦略』は技術的負債の考え方と深く関連しています。ルメルトが説く「良い戦略」の本質—正確な診断、明確な指針、一貫した行動—は、技術的負債の管理にも直接応用できます。「良い負債」は明確な目的と返済計画を持つ戦略的選択であり、「悪い負債」は単なる近視眼的回避策です。ルメルトが強調する「選択の重要性」は、技術的リソースの配分や優先順位付けにおける難しい決断と共鳴します。技術的負債を単なる技術問題ではなく、組織の戦略的選択として捉える視点を提供する一冊です。良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon長期的影響の驚くべき事例著者が紹介する「スペースシャトルの設計が古代ローマの馬車の車輪幅に影響された」という事例は衝撃的でした。この例えは初期の技術的決定が予想をはるかに超えて長期間にわたり影響するという重要な教訓を伝えています。私自身も過去のプロジェクトで、初期データモデルの制約が何年も後の開発に影響し続ける状況を経験しました。アーキテクトとして、目前の問題解決だけでなく未来の開発者の自由度を考慮する責任があると再認識しました。企業競争力への致命的影響Netscape Navigatorの例は技術的負債の危険性を如実に示しています。80%の市場シェアを持ちながら、負債対処のための完全な書き直しで3年もの遅延が発生し、市場を失った事例は「技術的負債における破産宣告」として説得力があります。著者が経験したHMVでの事例も興味深く、プロジェクト工数の約1/3が技術的負債対応に費やされていた実態には驚かされました。特に設計段階ではなく「コーディング段階」で発見される予期せぬ負債が問題となり、短期的な回避策が長期的な負債増大につながるという悪循環が明確に説明されています。技術的負債がもたらす「六つの悪魔」著者が挙げる負債の影響は現場感覚に近く、共感できました：追加コスト - すべてのプロジェクトで負債対応のコストが発生開発テンポと納品の遅延 - 予定どおりの進行が困難になる予測可能性の低下 - 不明確な負債状況が見積もり精度を下げる非現実的なスケジュール - 「技術から遠い人ほど正確な数字を要求する一方で技術的負債に無頓着」という指摘は的確プロジェクト中止 - 負債返済コストが事業価値を上回り計画が頓挫負債のスパイラル - 遅延挽回のために更なる負債を生み出す悪循環特に負債の影響が線形ではなく、ある閾値を超えると急激に開発効率が低下するという点は実務経験とも合致し、説得力がありました。組織的問題としての技術的負債本章で最も重要な気づきは、技術的負債は技術的問題以上に組織的な問題であるという点です。HMVの事例から、意思決定プロセス、予算サイクル、部門間連携の重要性が浮き彫りになります。プロジェクトが遅れると意思決定者がリスクを取りがちになる心理的変化や、部門間のコミュニケーション不足がもたらすアーキテクチャの不整合など、組織的な要因が技術的負債を増大させる構造が明確に示されています。まとめこの章から得られた実践的な提言として、以下の点を自分のプロジェクトに取り入れたいと考えます。負債の可視化と測定による共通理解の促進継続的なリファクタリングを日常的な開発サイクルに組み込む文化の構築「良い負債」と「悪い負債」を区別する戦略的な負債管理組織全体の課題として取り組む組織的アプローチの採用「馬の尻幅」の影響が2000年続いたように、今日の技術的決定は将来に大きな影響を及ぼすという教訓は、アーキテクトとしての責任を再認識させる貴重な気づきでした。3. Why Has Technical Debt Proved So Resistant to Solutions?技術的負債への誤解多くの組織が技術的負債を単なる「技術的問題」として捉える誤解が本章の核心です。著者は「暗闇で鍵を失くした酔っ払いが街灯の下だけを探す」という例えを用いて、私たちが解決策を間違った場所で探していることを鋭く指摘しています。ソフトウェアアーキテクトとして、この指摘に強く共感します。日々の業務でチームが「このコードは技術的負債だから修正しよう」と議論するとき、多くの場合「悪いコード」を直すことだけに注力し、なぜそのコードが生まれたのか、背景にあるトレードオフの判断や組織的要因を見落としがちです。また過信効果（overconfidence effect）の指摘も的確です。技術的負債を金融負債のアナロジーで理解しているため、実際より理解していると錯覚し、深い探求を怠ることがあります。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazon技術的負債ライフサイクルの誤認著者が提示する技術的負債のライフサイクル図は非常に啓発的でした。Figure 3-1 Technical debt life cycle, starting from when it is created より引用一般的な理解（Figure 3-1）では、技術的負債の作成から始まるライフサイクルを想定していますが、これは不完全です。Figure 3-2 Technical debt life cycle, beginning with events that led to its creation より引用著者が示す完全なライフサイクル（Figure 3-2）では、組織構造の作成→プロジェクトの見積もり→プロジェクトの遅延といった前半部分が無視されていることが明らかになります。私自身の経験でも、技術的負債はコードが書かれるずっと前から、不適切な見積もりや無理なスケジュール、チーム間の不十分なコミュニケーションなどにより発生しています。にもかかわらず、多くの組織は「悪いコード」だけを見て、「なぜ開発者はこんなコードを書いたのか」と問い、真の原因を見逃しています。近因と究極因の区別著者の「近因（proximate cause）と究極因（ultimate cause）」の区別についての議論は大変示唆に富んでいます。事故調査の例を用いて、近因（心臓停止）と究極因（飲酒運転）を区別する重要性を説明していますが、これは技術的負債の分析にも当てはまります。究極因を追求することが技術的負債対策の本質だという指摘は核心を突いています。「5つのなぜ」テクニックを用いて深く掘り下げることで、表面的な「悪いコード」という近因を超え、組織構造や意思決定プロセスといった根本原因に到達できます。実務では、近因で分析を終わらせることが多いのは、責任の所在が明確になり、組織の自己反省を避けられるという「便利さ」があるためです。しかし、これでは同じ問題が繰り返し発生することになります。「重要だが緊急ではない」問題としての技術的負債アイゼンハワー大統領の「私には2種類の問題がある：緊急なものと重要なもの。緊急なものは重要ではなく、重要なものは決して緊急ではない」という言葉を引用した著者の分析は、技術的負債の優先順位付けの難しさを見事に表しています。技術的負債は典型的な「重要だが緊急ではない」問題です。著者の本の執筆（重要だが締め切りまで9ヶ月ある）と会議の資料作成（重要性は低いが数日後に必要）の比較は、緊急性が優先順位付けを支配する現実を示しています。私のチームでも、新機能開発やバグ修正などの「緊急」タスクが、リファクタリングやアーキテクチャ改善より常に優先されます。技術的負債が十分に蓄積されてシステムが機能不全になってようやく「緊急」問題となりますが、その時には対処コストが膨大になっています。成果が見えにくい技術的負債対策「誰も起こらなかった問題を修正したことに対して称賛されることはない」というネルソン・レペニングの言葉は、技術的負債対策の本質的な困難さを表しています。技術的負債削減の効果はすぐには現れず、多くの領域に分散するため、明確に債務削減プログラムに起因するものとして認識されにくいのです。また恩恵を受ける側も、そのメリットを認識せず、あるいは自分たちの努力の結果と捉える傾向があります。大規模リファクタリングプロジェクトを実施しても「何も変わっていない」と評価された経験は、多くの開発者が共感するでしょう。「問題が発生しなかった」ことを証明するのは非常に難しいのです。「銀の弾丸」が存在しない現実フレッド・ブルックスの「人月の神話」を引用した著者の指摘は的確です。技術的負債削減には「銀の弾丸」は存在せず、前払いの努力と投資が必要なのです。技術的負債の中心的な問いは「技術的負債を減らしたいですか？」ではなく「将来の技術的負債負担を減らすために今日何を犠牲にする準備がありますか？」という点にあります。この視点の転換は非常に重要です。現代のソフトウェア開発では、新フレームワークやAIなど「銀の弾丸」として喧伝される解決策が次々と現れる中で、地道な技術的負債対策は地味に見えがちです。しかし、真の改善には継続的な取り組みが不可欠なのです。技術的問題として捉えたい心理「We Desperately Want Technical Debt to Be a Technical Problem」というセクションは、私たちの心理を鋭く突いています。マネージャーや経営陣は技術的負債を技術的問題として捉えることで、「エキサイティングな」新規イニシアチブに集中できます。技術者も、現在のトレードオフ決定の一部として認めるよりも「後で対処する問題」として先送りしたいのです。この心理は痛いほど身に覚えがあります。ビジネス側は「スコープクリープを許可した決定」や「見積もりの甘さ」による影響を認めたくなく、技術者も「ビジネス側の圧力」を責任転嫁の理由にする傾向があります。技術的負債を組織全体の共同責任として捉え改善していく視点が必要だという著者の提言は、深く共感します。変化管理としての技術的負債対策技術的負債削減の取り組みが組織変革の一種であるという著者の指摘は非常に重要です。大きな改善を得るためには技術的負債が作られる原因に焦点を当てる必要があります。組織構造やトレードオフ決定のプロセス、プロジェクト見積もりの方法などに対処する必要があるのです。この視点は私のアプローチを変えました。技術的負債対策を単なる技術的改善ではなく組織変革として捉え、変化に対する抵抗を予測し対処する計画を立てることの重要性を認識しました。総括と実践への示唆本章から得た最も重要な教訓は、技術的負債を単なる技術的問題ではなく、組織的課題として捉える必要性です。技術的負債への効果的な対処には：技術的負債の真の性質と根本原因への理解を深める組織全体の問題として認識し、全体で取り組む変化管理の手法を取り入れ、抵抗に対処する成果を可能な限り可視化し、継続的な取り組みのモチベーションを維持するこれらの教訓を自分のプロジェクトに適用し、技術的負債に対するより効果的なアプローチを構築していきたいと思います。Part II Understanding the Technical Debt Problem4. The Broken Analogy問題理解におけるアナロジーの役割アナロジー（類推）は複雑な問題を理解する強力なツールです。著者はヨハネス・ケプラーの例を挙げ、惑星運動の法則発見までの道のりで、彼が熱、光、磁気力、渦巻く水流など様々なアナロジーを試し、検証し、限界を見極めていった過程を紹介しています。ケプラーの方法論で重要なのは、単一のアナロジーに固執せず、複数のアナロジーを「容赦なく検証」し、より良いものを見つけては前のものを捨てる姿勢です。著者はこれを技術的負債への我々のアプローチと対比し、「金融負債へのアナロジーの欠陥を容赦なく検証し、より良いアナロジーのために捨てているだろうか？」と問いかけています。著者は良いアナロジーには「親しみやすさ」と「代表性（正確さ）」のバランスが必要と指摘します。この観点から評価すると、技術的負債の金融負債アナロジーは「親しみやすいが正確性が低い」象限Aに位置します。ビジネス関係者の初期理解には役立つものの、誤解を招く恐れがあるのです。特に上記のアナロジーに関する議論と関連して、本書は抽象化によって本質を見抜き、具体例を通じて理解を深める方法を提供しています。ケプラーが様々なアナロジーを試し、捨て、より良いものを見つけていったプロセスは、まさに具体と抽象の間を行き来する思考法の実践例といえるでしょう。具体と抽象作者:細谷 功dZERO（インプレス）Amazon金融負債アナロジーの限界金融負債アナロジーがビジネス関係者の理解を助けた理由は、「財務」がビジネスの共通言語であることと、多くの人が個人的に金融負債を経験していることにあります。このアナロジーが正しく機能する側面として：- 返済が通常必要である- 時間とともにコストが増大する- その存在が他の活動を制限する- 高レベルの負債は深刻な負担となるしかし問題は、「私たちが正確性よりも理解のしやすさを優先した」ことにあります。著者はより正確な技術的負債の例えとして「特殊な車のローン」を提案しています。このローンでは借りた金額がわからず、返済時期も不明確で、金利も部分によって異なり、返済計画は外部イベントに左右され、さらに親族にはクレジットカードが無料配布されるという恐ろしいものです。代替アナロジー：肥満問題著者が提案する最初の代替アナロジーは「肥満問題」です。肥満は技術的負債と次の点で類似しています。直接的・間接的な影響：肥満は直接的（余分な体重による機械的ストレス）または間接的（ホルモンや代謝の変化）に影響します。技術的負債も同様に直接的（修正作業）または間接的（経済的に成り立たなくなるプロジェクト）に問題を引き起こします。自己強化的性質：極度の肥満は運動能力を低下させ、さらに肥満解消を困難にします。高レベルの技術的負債も同様に自己強化的になります。根本的な誤解：1970年代の肥満対策は脂肪摂取量の削減に焦点を当て、食品業界は脂肪を減らす代わりに糖分を増やした結果、肥満は増加しました。技術的負債も同様に、要因を技術的なものだけと考えると、特定の要因を監視する一方で他の要因を見逃すリスクがあります。肥満アナロジーからは「システムマッピング」という有用なツールも得られます。イギリス政府の肥満問題への「システムアトラス」アプローチは、技術的負債の異なる側面を地図化する際にも応用できるでしょう。その他の代替アナロジー環境汚染アナロジーは、「汚染を生み出す決定をする者とその恩恵を受ける者が同一である一方、その結果に苦しむ者は決定に関与していない」という重要な洞察をもたらします。技術的負債も同様に、負債を生み出す決定をする人は恩恵を受けますが、対処コストを負担するのは別の人々です。依存症アナロジーでは、著者は「技術的負債を増やす結果をもたらす行動への依存」を指摘します。例えば納期を守るために技術的負債を増やす決断を繰り返し、その悪影響を認識しながらも止められない状態です。摩擦アナロジーはフォン・クラウゼヴィッツの「戦争論」から取られています。クラウゼヴィッツは「戦争では全てが単純だが、単純なことが難しい」と述べ、戦場での摩擦を「無数の小さな困難の蓄積」と説明しました。技術的負債の影響も同様に、最も単純なタスクさえ困難にします。クラウゼヴィッツは摩擦は常に存在し完全に排除できないものだと指摘しつつ、最小化する努力を怠るべきではないと主張しました。この洞察は技術的負債管理にも当てはまります。複数アナロジーの実践的活用この章から得た最も重要な教訓は、単一のアナロジーに縛られず、複数の視点から技術的負債を理解する必要性です。技術的負債はその「玉ねぎモデル」が示すように多層的な問題であり、各層には異なるアナロジーが適しているのです。私の実務経験からも、ビジネス関係者との初期対話では金融アナロジーを使いつつ、より深い議論では段階的に他のアナロジーを導入することが効果的だと感じています。例えば：技術的負債を予算化する際には金融アナロジー負債の蓄積メカニズムを説明する際には依存症アナロジー開発プロセスへの影響を説明する際には摩擦アナロジー技術的負債のトレードオフを議論する際に異なるアナロジーを意識的に使い分けることで、より生産的な議論が可能になります。例えば「この機能を期限までに実装するために技術的負債を受け入れるか」という古典的なトレードオフを、単に「借金を増やすか」としてではなく、「システムを肥満させるか」「摩擦を増やすか」「汚染物質を放出するか」といった多様な視点から検討することで、より豊かな議論が可能になります。複数のアナロジーを使いこなせるアーキテクトは、技術チームとビジネス側の双方と効果的にコミュニケーションを取り、組織全体で技術的負債に対する共通理解を形成することができるでしょう。それこそが継続的な技術的負債管理への第一歩となります。5. Technical Debt As a Trade-Off Problem技術的負債と人間の意思決定メカニズム技術的負債は単なる技術問題ではなく、人間の意思決定メカニズムに根ざしたトレードオフ問題です。著者は技術的負債の「玉ねぎモデル」の第2層である「トレードオフ層」を詳細に分析し、特に「アフェクト・ヒューリスティック」と呼ばれる感情に基づく直感的判断の影響を掘り下げています。私たちの意思決定能力は進化の過程で発達したものです。祖先が直面していた環境では「速さ」「質の低い情報でも機能すること」「認知的負荷が低いこと」が重要でした。これにより私たちの意思決定の大部分は無意識下で行われるという重要な特性が生まれました。意識的な論理的思考はあまりにも遅く、情報処理に限界があるためです。カーネマンの「ファスト&スロー」は人間の思考を「システム1」（速い、直観的）と「システム2」（遅い、論理的）に分類しています。技術的負債の文脈では、即時の問題解決を優先するシステム1の思考が、長期的な技術的健全性より優先されがちです。時間や認知的制約から、多くの技術的決断は直感に頼ることになり、これが技術的負債の発生につながります。この人間の意思決定メカニズムを理解することが、技術的負債への効果的な対策に重要です。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonアフェクト・ヒューリスティックの重要性アフェクト・ヒューリスティックは、現在の感情的印象を利用して意思決定を導く心理的ショートカットです。私たちが「直感」や「腹の感覚」と呼ぶものの正体です。このヒューリスティックの重要な特性は①感情を用いること②「感覚」を通して行動を仲介すること③高速であること④変化に抵抗し経験を通してのみ変化すること⑤意識的評価が不可能であることです。私たちが論理的な決断をしていると思っていても、実際には感情的システムがすでに決断を下しており、理性はただそれを正当化しているに過ぎないのです。技術的負債の蓄積を促す意思決定の非対称性著者が提示する例は非常に示唆的です。プロダクトオーナーが技術的負債を増やす新機能を開発するかどうかを決断する場面で：機能開発を選択した場合の利益は「即時的」「確実」「具体的」「自分が経験する」「感情的」という特性を持ちます。これらは強い感情的印象を生み出し、アフェクト・ヒューリスティックに強く影響します。対照的に、技術的負債を避けることの利益は「将来的」「不確実」「無形」「他者が経験する」「理性的」という特性を持ちます。これらは感情にほとんど訴えず、理性的システムにのみ響きます。この非対称性によって、意思決定において技術的負債の側面がほとんど考慮されないという問題が生じます。これが技術的負債が過度に蓄積する構造的要因の一つであり、私自身のプロジェクト経験とも強く共鳴します。喫煙予防プログラムからの教訓喫煙予防プログラムの事例は技術的負債管理に重要な示唆を与えます。当初の論理的なメッセージは効果が限定的でしたが、タバコパッケージに喫煙の生々しい害を視覚的に表現するなど、感情に訴えかける戦略に転換して初めて成功しました。喫煙の利益と害の構造は技術的負債のトレードオフと全く同じです。この教訓から、技術的負債を避ける決断に影響を与えたいなら、論理よりも感情に訴えかける必要があると理解できます。精密さと価値の問題著者が導入する「精密さ」と「価値」の概念も重要です。音楽辞典の例を用いて、比較可能な状態では内容を重視し、比較できない状態では精密に評価できる表面的な属性に重きを置く傾向があると指摘しています。新機能や早期納品の利益は高い精密さをもって評価できますが、技術的負債の回避による利益は精密さを欠いています。このため、不確実で無形な技術的負債の重要性が過小評価されがちなのです。チャレンジャー宇宙船事故の例からも、精密に表現できない懸念が無視される危険性が理解できます。これは技術リーダーとして、技術的負債の影響をより具体的かつ精密に表現する工夫が必要だと強く感じさせる部分です。技術的負債管理のための実践的アプローチ著者が紹介する「ユリシーズ契約」は非常に実践的です。将来の自分を特定の状況下で拘束するための事前のコミットメントとして、例えばスプリント中に生じた技術的負債が閾値を超えた場合、次のスプリントに返済タスクを含めることを事前に約束する方法は、すぐに実践できそうです。「同時決定vs連続決定」の概念も興味深いです。複数の決定を同時に行うと、多様化バイアスにより健康的な選択肢（技術的負債の返済）を含める傾向があるという指摘は、スプリント計画の改善に応用できそうです。また、プロジェクトの状況がリスク選好に与える影響についての洞察も重要です。プロジェクトがスケジュール通りの場合はリスク回避的、遅延している場合はリスク追求的になるという傾向は、日々のプロジェクト管理で強く実感するところです。6. Technical Debt As a Systems Problemシステム思考による技術的負債の理解技術的負債は単なる技術的問題ではなく、組織的なシステム問題として捉えるべきです。第6章では、「玉ねぎモデル」の「システム層」に焦点を当て、組織内のシステム構造と個人の役割がどのように技術的負債の蓄積に寄与するかを分析しています。Figure 6-1 The technical debt onion model より引用著者はドネラ・メドウズの定義を引用し、システムを「一貫して組織化され相互接続されたパターンまたは構造で特徴的な一連の振る舞いを生み出す要素または部品の集合」と説明します。システムの振る舞いは外部要因よりも内部構造によって決定されるという点が重要です。ソフトウェア開発の文脈では、プロジェクトチームや組織構造自体もシステムとして捉える視点が必要です。ITシステムと社会システムの決定的な違いは、社会システム内のコンポーネント（個人）が「独自の目標を追求する能力」を持つことです。この違いはシステムの複雑性と予測不可能性を大幅に増大させます。企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon生物学の例から学ぶシステム的視点Y染色体と胎盤の関係という生物学的例は、目標が競合するシステムコンポーネントがどのように予期せぬ結果をもたらすかを説明しています。一夫多妻制と一夫一婦制のマウスの交配実験は、ソフトウェア開発に直接的な類推を持ちます。プロジェクト（胎児）は最も有利な状態で「生まれる」ことを望み、組織的リソースを最大限に得ようとします。一方で組織（母親）はシステムを維持し将来的な機能を提供し続けるために健全な状態を保とうとします。この拮抗する目標がバランスを崩すと技術的負債の過剰な蓄積につながるのです。「過剰と崩壊」のパターン著者は技術的負債問題の中心に「過剰と崩壊」というパターンがあると主張します。これは再生可能なリソースが持続可能なレベルを超えて利用され、回復不可能なほど枯渇する状態です。古代文明の崩壊や商業漁業における乱獲と同様のパターンがソフトウェア開発にも現れます。ソフトウェア開発における「過剰」とは、タスク完了率の持続不可能なレベルへの引き上げを意味します。プロジェクトが圧力を受けると、補助的活動（良質な要件作成、効果的なテスト、過度な技術的負債の回避など）が放棄されるか最小限に抑えられます。これにより一時的な見かけ上の進捗改善がありますが、長期的には効率の低下と「消火活動モード」と呼ばれる状態への転落を招きます。過剰と崩壊は特に危険です。なぜなら一度崩壊が始まると回復は非常に困難だからです。北海のタラ資源が崩壊すると漁業をすべて停止しても回復しないかもしれないように、プロジェクトが消火活動モードに陥ると、技術的負債の蓄積を止めても既存の負債が残存し回復を妨げるのです。役割による制約と技術的負債著者はシェイクスピアの「世界は舞台、人は皆役者」という言葉を引用し、私たちがソフトウェアプロジェクトにおいて独立した個人としてではなく「役割を演じる人」として意思決定を行うことを指摘します。個人は組織の長期的な利益に反すると認識していても、その役割に合致した決定を下すよう制約されることがあります。プロジェクトマネージャーは締め切りを守るプレッシャーから、長期的な技術的負債を増やす決断をせざるを得ないことがあります。同様に開発者も技術的負債を溜めることの長期的な影響を理解していても、スケジュールプレッシャーから短期的な解決策を選ばざるを得ません。特に重要なのは「基本的帰属の誤り」と呼ばれる認知バイアスです。私たちは他者の行動を彼らの状況や役割ではなく性格に帰属させがちですが、多くの場合、技術的負債を増やす決断は個人の性格ではなく、システム内の役割による制約によるものなのです。プロジェクト見積もりと技術的負債技術的負債の増加に大きく寄与する要因の一つはプロジェクトの過小評価です。著者は入札プロセスの構造がいかに過小評価を生み出すかを説明します。評価チームは可能な限り低い見積もりを望み、入札チームは競争に勝つために最低の入札を提出しようとします。この相互作用は不現実な見積もりを生み出し、プロジェクトの遅延と圧力の増加につながります。過小評価されたプロジェクトは二つの問題に直面します。一つはスケジュールの遅れであり、これは圧力と補助的活動の放棄を引き起こします。もう一つは「フィクション」の創造です。プロジェクト関係者の多くは見積もりが間違っていることを認識していますが、その事実を公に認めることを避けるため、フィクションが維持され、重要な問題が無視されることになるのです。政策抵抗と意図せぬ結果著者は「政策抵抗（policy resistance）」という概念を紹介します。これはシステム内のアクターがルールやポリシーを回避する方法を見つけたり、ポリシー変更によって意図された利益を無効にするような行動を取ることを指します。英国政府の「20%の追加見積もり」政策の例は示唆に富んでいます。この政策に対する抵抗は、まず元の見積もりが約20%削減されてから20%が追加され、結果として提出される見積もりは以前とほぼ同じになります。次に「20%の余裕がある」という誤った認識が生まれ、機能の追加（スコープクリープ）を促進し、結果としてプロジェクトはさらに予算超過と遅延に陥るのです。システム思考なしで導入される政策がいかに期待と反対の結果をもたらすかを示す重要な例です。技術的負債登録簿を確立・維持することが実際には技術的負債の減少ではなく増加につながる可能性があるという反直感的な発見も同様の原理によるものです。システム思考による技術的負債管理技術的負債に対するシステム思考を実践するために、著者はいくつかのアプローチを提案しています。組織構造の見直し：役割間の目標の対立を最小化し、組織全体の長期的目標と個人の目標を整合させる過小評価を避けるメカニズム：見積もりプロセスと入札/選択プロセスを分離し、より現実的な見積もりを促進する補助的活動の価値を可視化：リファクタリング、自動テスト、ドキュメンテーションなどの活動の価値を示すメトリクスを導入「過剰と崩壊」のサインを早期に検出：技術的負債の増加率、バグ発生率、機能実装時間などの指標を追跡この章から得られる最も重要な洞察は、技術的負債の蓄積を促進しているのは個人の意思決定ではなく組織システムの構造であるという理解です。短期的な生産性向上のために補助的活動を放棄すると、長期的には持続可能性の低下と崩壊を招きます。技術的負債管理は単なる技術的な問題解決ではなく、組織全体のシステム設計の問題として取り組むべきなのです。7. Technical Debt As an Economics Problem経済学的視点による新たな洞察技術的負債を経済学の視点から分析することで新たな洞察と解決策が得られるというのが本章の核心です。著者は「玉ねぎモデル」の「経済学またはゲーム理論の層」に焦点を当て、八つの経済学的問題を通して技術的負債の根本的要因を探っています。Figure 7-1 The technical debt onion model より引用経済学的視点を採用する三つの利点として、新鮮な視点による新たな洞察の獲得、1776年のアダム・スミス以来蓄積された膨大な経済学の知見の活用、そして上級ステークホルダーとの共通言語の確立が挙げられています。「経済学は共通の権威ある言語を提供する」という著者の主張に強く共感します。技術チームが「あの人が作業をサボったせいでバグが増えた」といった非難の応酬をしても生産的な解決には至りません。しかし「これはプリンシパル・エージェント問題の一例で情報の非対称性と利害の不一致から生じている」と分析すれば、冷静な議論と建設的な対策が可能になります。企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazonプリンシパル・エージェント問題プリンシパル・エージェント問題はエージェント（代理人）がプリンシパル（依頼者）の代わりに行動する際に生じる利害や優先事項の対立を指します。この問題が発生するには「利害の不一致」「情報の非対称性」「プリンシパルがエージェントに影響を与える手段の欠如」のうち少なくとも一つが存在する必要があります。技術的負債の文脈では「利害の不一致」と「情報の非対称性」が特に顕著です。負債のないコードを書くことはプリンシパル（ステークホルダー）にとって有益ですがエージェント（開発チーム）にとっては追加の労力を要します。また多くのステークホルダーやプロジェクトリーダーは技術スキルや経験が不足しているため情報の観察が困難です。複数のプリンシパルが存在する場合この問題はさらに複雑になります。マトリックス管理やビジネス部門、プロジェクトサポートとメンテナンスオペレーション、アーキテクチャチームなど複数のステークホルダーが関与するプロジェクトでは「集合行動問題」が発生します。解決策として「自分の作ったドッグフードを食べる」アプローチがあります。開発チームが通常のハイパーケア期間を超えて自分たちのコードをサポートし維持する責任を持つことで、利害の一致を促進できます。コモンズの悲劇コモンズの悲劇は限られた共有資源の過剰使用に関する概念です。共有地を利用する牧畜業者は新たな動物を追加すると個人はその動物からの利益をすべて享受する一方で、共有地へのダメージはすべての人に分散されます。そのため各牧畜業者が個別に合理的な選択をすると共有地は劣化または破壊されてしまいます。技術的な資産を「コモンズ」とみなすと、組織は同様のジレンマに直面します。各関係者は高品質で負債の少ない技術資産を重視しますが、負債を増やす行動から多くの価値を得ることもできます。例えばプロダクトオーナーがテスト削減の代償として追加機能を詰め込んだり、開発者がコードを再利用する代わりにコピー＆ペーストしたりする行為です。この問題に対する解決策の本質は、すべての技術的資産の明確な所有権を確立することです。また適切な組織文化と社会規範があると、個人は協力してより良い解決策を見つける傾向があります。外部性の問題外部性は一方の当事者が他方の当事者に対しコストや便益を押し付けることができる状況を指します。一般的な例は汚染です。自動車は健康被害というコストを都市住民に押し付けます。著者の元同僚のプロジェクトマネージャーの「それは私の問題じゃない！」という発言はまさに外部性を示しています。このマネージャーは他者に外部性を押し付けることができ、相手はそれを阻止する力がないことを示していました。著者はHMVでの製品を複数のジャンルで表示するプロジェクトを例に挙げます。重複テーブルを作成するという解決策はステークホルダーがプロジェクトチームに押し付けた外部性の例です。クリスマスコードフリーズ前にプロジェクトを完了できましたが、サポートチームに週次データ取り込みのための開発者の時間という継続的な外部コストが課されました。解決策は技術的資産の周囲でより良い財産権を定義し、外部性とは何かについての認識を高めることです。短期主義の影響短期主義は「将来への影響よりも現在の利益や利点だけを考慮する思考や計画の方法」です。外部性とは異なり、コストを課す者と負担する者が同じ当事者である点が特徴です。短期主義は技術的負債と特に関係が深いです。なぜなら負債の返済は常に将来のことであり、便益は通常現在のものだからです。技術的負債項目の返済のコスト便益タイムラインを示したグラフでは、短い期間ではコスト便益曲線が負のままであることが示されています。プロジェクトの期間が短い場合、負債を返済することはプロジェクトにとって価値がありません（組織全体の観点からは価値があるかもしれませんが）。短期主義への対策として、プロジェクトの意思決定者に彼らの視野を現在のプロジェクトを超えて拡大させること、技術的負債のトレードオフ決定を外部関係者ではなく従業員によって行うようにすること、アーキテクチャチームをより多く関与させることが提案されています。小さな決断の専制小さな決断の専制は「個別には小さく重要でない決断の集積が最適でも望ましくもない結果をもたらす現象」を指します。ニューヨーク州イサカの鉄道サービス撤退の例では、多くの乗客が便利な時だけ他の交通手段を選ぶ小さな決断を積み重ねた結果、鉄道は経済的に維持不可能になりました。この問題は特にコーディングに関連しています。開発者は毎回のコード作成や修正時に膨大な数の小さな決断を下します。それぞれの決断は小さなものですが、集合的には大きな意味を持ちます。理想的には重要な決断は階層的な意思決定レベルで行われるべきですが、作業中の実務者が一連の小さな一見無害な決断を行い、結果として重要な決断が事後的に蓄積されることがあります。解決策として、組織の技術アーキテクチャ能力を開発し保護すること、小さな決断の集積が意図しない重要な決断をもたらしていないかコードレビューで確認することが有効です。忍び寄る正常性忍び寄る正常性は「大きな変化や逸脱が小さな漸進的変化を通じて起こるため気づかれない現象」を指します。フォルクスワーゲンの排出ガススキャンダルはこの概念の例です。エンジニアのグループが排出ガス試験などの特定の状況下で排出量を減らすように車のソフトウェアに複数の小さな調整を加えました。ダイアン・ヴォーンはこれを「逸脱の正常化」と呼び、リスクを正当化するための根拠を徐々に調整して増大させることを指します。スペースシャトル・チャレンジャー号の事故もこの例です。技術的負債の文脈では、忍び寄る正常性は「緊急」の問題への対応時に徐々に導入される行動によって起こり得ます。緊急事態が過ぎた後もその行動は元に戻らず、新しい「正常」となります。解決策として「弱いシグナルに注意を払うこと」「不合理に楽観的になる衝動に抵抗すること」「システムオペレーターが安心して発言できること」「監視は終わりのないプロセスであることを認識すること」などが提案されています。アナーキーの代償アナーキーの代償は「システム内のエージェントの自己利益的行動によりシステムの効率がどれだけ低下するかを測定するもの」です。道路交通システムの例では、個々のエージェントが自分のルートを選択できる場合に平均移動時間が増加します。技術的負債に関しても、個人が技術的負債に影響する決断をする際、自分の利益を最大化しますが他者に「増加した移動時間」に相当する負債を残します。極端な場合、アナーキーの究極的な代償はシステムの崩壊です。解決策はアナーキーの代償が高い決断を集中化することです。コーディング標準、技術設計権限、コードレビューポリシーなどの集中的な方針も有効です。モラルハザードモラルハザードは「人々がリスクの全コストを負担しない場合、より多くのリスクを取る状況」を指します。エコノミストのポール・クルーグマンはこれを「ある人がリスクをどれだけ取るかを決定する一方で、物事が悪化した場合のコストを他の誰かが負担する状況」と説明しています。著者は保育所の例を挙げています。保育所は親の遅刻を減らすために罰金を導入しましたが、予想に反して遅刻は増加しました。以前は親は教師との「社会的契約」に基づき遅刻を避けていましたが、罰金システムの導入は社会的契約を取引的なものに置き換え、親はもはや罪悪感を感じることなく遅刻して罰金を支払うことを選んだのです。技術的負債の登録簿を作成すると技術的負債のレベルが減少するのではなく増加する可能性があるというのもモラルハザードの例です。登録簿の作成により負債の作成が正当化され、通常は対処されていたものが登録簿に記載されるようになります。解決策として、組織がソフトウェア開発プロセスの変更を行う前に、それらのプロセスが社会的契約にどの程度依存しているか考慮することが重要です。経済学的視点の活用著者は最後に経済学的問題の活用方法として三つの行動方針を提案しています。各問題に対して提案された解決策を試してみる議論と言語を経済学的なものに変える技術的負債や他のソフトウェア開発問題に対する解決策のためにさらに経済学的パズルを探求する経済学の言語を使用することで、ステークホルダーとの効果的なコミュニケーションが可能になるという点は特に重要です。「外部性」「プリンシパル・エージェント問題」「コモンズの悲劇」といった言葉を使うことで、問題の真の原因とどのように効果的で永続的な解決策を開発するかについての建設的な議論が促進されます。経済学の視点から技術的負債を理解することで、単なる技術的問題としてではなく、組織構造と意思決定プロセスの問題として捉え直す視点が得られるのです。8. Technical Debt As a Wicked Problem技術的負債の最深層技術的負債は単なる技術的問題ではなく、社会的複雑性に起因する「厄介な問題（wicked problem）」であるという視点が本章の中心テーマです。著者はこの「玉ねぎモデル」の最内層に焦点を当て、技術的負債問題が永続化する根本原因を探っています。Figure 8-1 The technical debt onion model より引用冒頭で引用されるジェラルド・ワインバーグの言葉「問題がどのように見えるか、何が問題か、他の人が何と言おうと、それは常に人間の問題である」は、技術的負債の本質を端的に表しています。技術的な問題に見えても、その根底には人間の問題があるのです。気候変動の例は示唆に富んでいます。40年以上認識されながらも効果的な解決に至っていない気候変動は、異なるステークホルダー間で見解が分かれ、単純な解決策が通用しない典型的な厄介な問題です。EU圏内の製造業への排出規制が却って全体の排出量増加につながった事例は、意図せぬ結果をもたらす介入の典型例として技術的負債対策にも重要な教訓を提供します。イシューからはじめよ［改訂版］――知的生産の「シンプルな本質」作者:安宅和人英治出版Amazon厄介な問題の8つの特性著者は厄介な問題と手なずけられた問題を対比しています。クロスワードパズルがどんなに難しくても十分な知識があれば解ける「手なずけられた問題」であるのに対し、技術的負債は「厄介な問題」に該当します。その特性として：問題は解決策を見つけた後でしか理解できない：技術的負債の原因がプロジェクト遅延なのか、誤ったトレードオフなのか、外部性の問題なのかは、解決策を試してみないと見えてこない循環性があります。ステークホルダーは根本的に異なる世界観を持つ：プロダクトオーナーは顧客からの急ぎの要求に重点を置く一方、開発者は技術的負債による制約に囲まれています。この異なる世界観が問題理解を複雑にします。問題の理解の仕方が試す解決策を決定する：各ステークホルダーの世界観によって問題の捉え方が異なり、それに基づいて異なる解決策を提案します。ビジネス側と技術側の分断がここから生じます。解決策は真か偽かではなく良いか悪いかで判断される：技術的負債の解決策に明確な「正解」はなく、各自の世界観に基づいた「より良い」解決策があるだけです。解決策がうまくいったかどうかの即時的で決定的なテストがない：解決策の結果は長期間にわたって現れ、初期には良くても後に悪影響が判明することがあります。あらゆる解決策は「一発勝負」である：厄介な問題への介入は取り返しのつかない結果をもたらすこともあります。厄介な問題は他の厄介な問題と相互に関連している：技術的負債は見積もりやプロジェクト遅延と密接に関連し、互いに循環的に影響し合います。いつ止めるべきかを知る方法がない：問題が十分に理解されているかの明確な基準がなく、多くの場合、時間や予算の制約で対応が中断されます。これらの特性は、技術的負債が単純な技術的修正では解決できない複雑な問題であることを示しています。社会的複雑性と組織的分断著者は「社会的複雑性」の概念を導入し、問題に関わるプレイヤーの数と多様性がさらなる複雑さを生み出すと指摘します。Jeff Conklinの等式「分断 = 厄介さ × 社会的複雑性」が示すように、厄介な問題と社会的複雑性の組み合わせが組織内の分断を引き起こします。単独で問題に取り組む場合、「問題を理解していない」ことは探求の過程として現れますが、複数のステークホルダーが関わると、「理解の欠如」が組織的分断として現れます。この分断を悪化させる要因として「過信効果」と「確証バイアス」が挙げられています。「デザインのジレンマ」として「あるべき姿」と「できること」の間の緊張関係も指摘されています。大規模な組織では「あるべき姿」を追求するグループ（マーケティング、営業など）と「できること」に焦点を当てるグループ（技術系部門）が分断され、互いに対立する文化的戦争が起きやすくなります。この分断の最も確実な指標は「非難」です。技術的負債問題が「統合的な視点」ではなく、互いに責任を押し付け合う「非難文化」として現れる様子が描写されています。解決へのアプローチ著者は厄介な問題への対処法として、「手なずけられた問題のコレクションとして扱う」アプローチの限界を指摘しています。技術的負債登録簿の作成と負債返済チームの設立は一時的な改善をもたらすかもしれませんが、問題は周囲に変形し、長期的な解決には至らない可能性があります。より効果的なアプローチは組織の分断問題に取り組むことです。著者は「共有理解」から「共有コミットメント」へと進む道筋を示しています。共有理解は全員が合意することではなく、互いの立場を十分に理解し、知的な対話ができる状態を指します。この分断への対処ツールとして「ダイアログマッピング」や「議論マッピング」の活用が提案されています。Rationaleなどの議論マッピングソフトウェアを使用して、複雑な問題に関する異なる視点を構造化することで、共有理解の構築を促進できます。技術的負債が単なる技術的問題ではなく、社会的複雑性を持つ厄介な問題であるという本章の視点は、問題の本質理解に大きく貢献します。8つの特性を通じて技術的負債の複雑さを体系的に整理し、問題解決の難しさの根源を「組織的分断」として特定している点は非常に示唆に富みます。特に重要なのは、技術的負債の「社会的複雑性」の側面です。技術的負債を効果的に管理するためには、単に技術的な解決策を見つけるだけでなく、組織全体の協力を促進する「共有理解」と「共有コミットメント」の構築が不可欠です。技術的負債を「人間の問題」として捉え直すことは、この厄介な問題への効果的なアプローチの第一歩となるのです。9. Common Technical Debt Anti-patterns循環するアンチパターンの理解技術的負債は単発的な意思決定ではなく、継続的な決断の連鎖によって蓄積されるという視点が本章の核心です。著者は技術的負債を増大させる10のアンチパターンを因果ループ図を用いて詳細に分析し、効果的な介入ポイントとレバレッジポイントを特定しています。冒頭で紹介される「There's a Hole in My Bucket」という童謡の例えは、技術的負債アンチパターンの循環的な性質を端的に表しています。バケツの穴を修理するという単純な問題が、相互接続した問題の連鎖に発展し、最終的には元の問題に戻るという循環性は、技術的負債問題の本質を示しています。特に重要なのは「後期介入のコスト」という概念です。技術的負債も早期に対処しなければ対処自体が困難になるという悪循環に陥ります。プロジェクトの緊急性を優先してテストコードを後回しにすると、技術的負債返済のためのリソースを確保すること自体が困難になる事例は、多くの開発者が経験していることでしょう。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon因果ループ図の力著者は技術的負債アンチパターンを可視化する手法として因果ループ図（Causal Loop Diagram: CLD）を紹介しています。CLDは変数と因果関係を矢印で表現し、「+」（正の関係）と「-」（負の関係）の記号でその影響を示します。アンチパターンの探索と可視化は三つの面で有益です。問題の理解を深める介入ポイントとレバレッジポイントを特定する異なるステークホルダー間の共通理解を促進する特に共通理解の構築は実務上極めて重要です。技術的負債に関する最大の課題は、ビジネス側と技術側の認識の乖離にあります。技術チームが危機感を持って訴える問題が、ビジネス側には「技術者の完璧主義」と誤解されることが多いからです。見積もり罠見積もり罠（Estimation Trap）は、見積もり誤差→プロジェクト遅延→短期目標への集中→技術的負債の増加→見積もり誤差という自己強化ループを形成します。特に注目すべきは「プロジェクト遅延→短期目標への集中」の接続です。プロジェクトが遅延すると人々の心理状態が「利益」から「損失」のマインドセットに切り替わります。これはプロスペクト理論が示すように、人のリスク志向を「リスク回避的」から「リスク追求的」に変え、非合理的行動を促進します。レバレッジポイントとしては、見積もり誤差の縮小、プロジェクト遅延時の再スケジューリング、技術的負債の後処理（ユリシーズ契約）などが挙げられています。特に「ユリシーズ契約」は、事前に自分の行動を縛る仕組みを導入する実践的手法として注目に値します。最後のレースの誘惑最後のレースの日（Last Race of the Day）は賭け事における現象から名付けられたアンチパターンです。競馬で大きく負けている状況では「確率は低いが全額取り戻せる可能性のある選択肢」が選ばれやすくなります。プロジェクトでも遅延状態ではチームのリスク志向が変化し、「すべての遅れを取り戻せる可能性は低いが魅力的な選択肢」を選んでしまいがちです。「新しいフレームワークで生産性が3倍になる」といった根拠の薄い見積もりに基づく決断が、結果的に状況をさらに悪化させる事例は少なくありません。道徳的信任効果道徳的信任効果（Moral Credential Effect）は過去に良い行いをした人が無意識のうちに「次は少し悪いことをしても良い」と思ってしまう心理です。技術的負債の文脈では「予期せぬ技術的負債への対処→チームの美徳意識→負債を作る資格があるという感覚→技術的負債の増加」という循環を形成します。リファクタリングスプリントの直後に「少しくらい負債を作っても良い」という雰囲気が蔓延する現象は、この効果の現れです。これを防ぐには技術的負債の管理を一時的なキャンペーンではなく継続的なプロセスとして位置付ける文化形成が必要です。割れ窓理論と学習性無力感割れ窓理論は環境の悪化が更なる悪化を招くという社会学的概念で、技術的負債の文脈では「すでに負債がある環境ではさらに負債を作っても構わない」という心理が働きます。「レガシーコードに新しいレガシーコードを追加しても問題ない」という考え方がその例です。一方学習性無力感はネガティブな体験の繰り返しによって無力感を学習してしまう心理です。バグ追跡システムに報告したバグが対応されないことを繰り返し経験すると「どうせ報告しても意味がない」とバグ報告をやめてしまいます。対策として「ズブロケンウインドウポリシー（Zero Broken Windows Policy）」の導入が効果的です。どんな小さな問題でも放置せず即座に対応するという方針は、技術チームの当事者意識を高め、負債の増加を抑制します。目標文化と社会的手抜き目標文化（Goal Culture）は過度に目標を強調することで逆効果を招くアンチパターンです。目標への過度な集中は行動変化（OKR代用効果、社会的手抜き）を引き起こし、結果的に目標達成に失敗します。社会的手抜き（Social Loafing）はグループ内では個人が単独の時より努力しなくなる傾向を指します。著者はこれを「怠惰」ではなく「リソース配分の問題」として捉えています。多くの開発者が過度な作業負荷の中で自身の作業を優先し、他者に恩恵をもたらす作業に労力を投じない選択をするのです。OKRと代用効果OKRと代用効果（OKRs and the Surrogation Effect）は指標への過度な集中による弊害を示しています。代用効果とは戦略的目標を表す指標が目標そのものに取って代わる現象で、グッドハートの法則「指標が目標になると指標としての価値を失う」として知られています。1904年の客船ゼネラル・スローカム号の火災事故は、最低重量基準を満たすため救命胴衣に鉄の棒を入れたことが逆に沈下を招いた事例で、「真の目的を見失い指標だけを満たそうとする」行為の危険性を示しています。ソフトウェア開発では「コードカバレッジ率」を指標として重視すると、テストの質ではなく量だけを追求する行動を促してしまう問題が起こります。技術的負債の文脈では代用効果は特に危険です。技術的負債の測定が難しいため「測定されない」部分が軽視される傾向があるからです。消火活動への転落消火活動への転落（Descent into Firefighting）はネルソン・レペニングの研究に基づくアンチパターンで、同じリソースを使いながら効率的なモードから非効率なモードへと転落するプロセスを示しています。作業を「補助的作業」と「不可欠な作業」に分けると、あるプロジェクトが遅延した場合、他のプロジェクトから人員を引き抜いて不可欠な作業を完了させることがあります。しかしその結果、次のプロジェクトでは補助的作業が不十分となり、更なる問題が発生するという連鎖が始まります。特定のポイントを超えると組織は「非効率な消火活動モード」に陥り、回復が極めて困難になります。テストチームが手動テストに追われ、自動テスト構築のための時間を確保できない状態などが典型例です。環境制約の問題限定環境（Limited Environments）アンチパターンは特に大規模組織で見られる問題です。十分なテスト環境が不足していると、プロジェクトは不適切な環境で作業を進めることを強いられます。これは開発・テストの非効率さ、バグの発見遅延、技術的負債の増加につながります。このアンチパターンの恐ろしさは、次のプロジェクトも同じサイクルを繰り返すことで、負のループが組織内に定着してしまう点です。レバレッジポイントとしては「利用可能な環境より多くのプロジェクトをスケジュールしない」「コンテナ化技術を導入して環境生成を容易にする」などが挙げられます。プロトタイプからの負債プロトタイプからの負債（Prototype into Debt）は多くのプロジェクトが陥る典型的なアンチパターンです。プロトタイプは本来「学習のため」に作られるもので技術的負債は高くても問題ありませんが、多くの場合プロトタイプが製品として使われてしまいます。これはプロジェクトがスケジュール圧力に晒されていたり、製品開発にかかる時間を過小評価していたりする場合に起こりやすくなります。フレデリック・ブルックスの「人月の神話」で言及されている「捨てる覚悟で作れ（Plan to throw one away）」という助言が適切なレバレッジポイントとなります。因果ループ図を活用した共通理解の構築著者が提案する因果ループ図を用いたワークショップは、技術的負債問題への効果的なアプローチです。これにより、技術チームとビジネスチームが共通理解を形成し、相互の協力関係を構築することができます。技術的負債管理において重要なのは「問題の根本原因を理解する」ことです。表面的な症状ではなく、組織的・心理的要因に踏み込んだ著者のアプローチは、技術的負債が単なる技術的問題ではなく、組織全体のシステム的な問題であることを浮き彫りにしています。10. Modeling Technical Debt with System Modeling Toolsシミュレーションで見える負債の動的性質技術的負債は静的な問題ではなく動的プロセスとして理解すべきというのが本章の核心です。著者は動的モデリングツールを用いたシミュレーションによって、技術的負債の蓄積とその影響を可視化する手法を紹介しています。ジョージ・ボックスの「すべてのモデルは間違っているが、一部は有用である」という言葉から始まるこの章は、正確な予測よりも理解の促進に重点を置いています。技術的負債の動的モデルを構築する目的は、①共有理解の構築②意思決定結果の探索③関係者のメンタルモデルの強化にあると説明されています。特に重要なのは「WYSIATI（What You See Is All There Is）」というダニエル・カーネマンの概念です。多くの組織で技術的負債が「目に見えない問題」として過小評価される現実があります。見えない問題は存在しないも同然であり、動的モデルはこの「見えないコスト」を具体的な形で示す強力なツールになります。Vensimを用いた技術的負債モデル著者はモデル構築ツールとしてVensimを紹介し、具体的なモデル構築とシミュレーション実行の手順を解説しています。技術的負債モデルの基本構造は「Work Remaining（残作業）」「Work Accomplished（完了した作業）」「Undiscovered Rework（未発見の手戻り）」という3つのストック（箱）と、それらを結ぶフロー（パイプライン）で構成されています。技術的負債を表現するために「fighting fires（消火活動）」というフローと「Technical Debt（技術的負債）」というストックが追加され、「スケジュール圧力」などの変数がこのフローに影響する仕組みになっています。シミュレーション結果から得られる洞察は非常に興味深いものです。特に「予定完了日を8か月から10か月に延長すると、実際の完了が15か月から12.5か月に短縮される」という一見反直感的な結果は印象的でした。この現象の原因は作業品質にあります。非現実的に短い納期は急速なスケジュール圧力の増加を招き、時間外労働の増加から疲労が生じます。これが品質低下と手戻りの増加、さらには生産性の低下をもたらすのです。実際のシミュレーションでは、品質が0.5の水準まで落ち込み、作業の約50%が誤りを含み手戻りが必要になるという恐ろしい状況が示されました。現在の利益と将来のコスト技術的負債のシミュレーションで最も示唆に富む部分は、「負債が現在と将来のプロジェクトに与える異なる影響」の可視化です。モデルでは技術的負債を増やす設定にすると、最初のプロジェクトは約10%短縮され費用も10%削減できます。しかし後続プロジェクトでは技術的負債が「摩擦」として作用し、作業の流れを妨げるため、完了までの時間とコストが大幅に増加します。この洞察はフォン・クラウゼヴィッツの「戦争論」における「摩擦」の概念に類似しています。十分な量の摩擦が蓄積すると、軍隊もソフトウェアチームも投入努力に関わらず何も達成できなくなるのです。シミュレーションでは技術的負債の蓄積によって3つ目のプロジェクトでは7百万ポンドのコスト超過が発生し、場合によってはプロジェクトが完了不能になることが示されました。著者は伝統的なプロジェクト管理の「鉄の三角形」（コスト・範囲・時間）を拡張する視点も提供しています。プロジェクトには少なくとも2つの追加次元「品質」と「技術的負債」があり、三角形に影響することなくこれらを調整できるという洞察は重要です。測定されるのは三角形の目に見える属性だけであり、技術的負債は測定されないため、「何が測定されるかが管理される」という原則に従うと、ほとんど管理されないことになります。社会的手抜きのモデル著者はもう一つのモデル「Social Loafing（社会的手抜き）」も紹介しています。このモデルでは要件・設計・コーディング・テストという開発パイプラインを通して作業がどのように流れるかシミュレーションします。各作業グループは「協力レベル」と「品質レベル」を調整できますが、上流グループが協力や品質を犠牲にして自分たちの作業を早く完了させると、下流グループの生産性が大きく低下する影響が示されています。このモデルから得られる教訓は、個々のグループが自分たちのゴールを最適化しようとする行動が、全体としての成果を損なう可能性があるということです。ウォーターフォール型の開発ではこの問題が顕著になりやすく、一方でアジャイルプロセスでは完了した作業への注目度が高く、個人が「社会的手抜き」に走るインセンティブが少ないと著者は指摘しています。シミュレーションの価値と実践的アプローチ本章を通じて著者が伝えようとしている最も重要なメッセージは「動的シミュレーションによって得られる反直感的な洞察の価値」です。例えば「納期延長が実はプロジェクト短縮につながる」「技術的負債が現在のプロジェクトには有益だが将来のプロジェクトには壊滅的」といった知見は、静的な分析だけでは得られません。動的シミュレーションの強みは「仮想実験場」として機能することです。実際のプロジェクトでは様々な条件を変えて実験することはほぼ不可能ですが、シミュレーションでは数分で多数のバリエーションを試すことができます。コントロールスライダーを調整するだけで、完了予定日・作業品質・技術的負債レベルの変更が、リワークの量・品質の変動・生産性などに与える影響をリアルタイムで観察できるのです。著者はモデル構築を純粋な技術プロセスではなく共有理解を構築するための協働活動として捉えることを強調しています。ビジネスアナリストがビジネスプロセスをマッピングするように、質問を投げかけ、組織・システム・プロセスの動作を理解し、小さなモデルを構築して徐々に機能を追加していくアプローチが推奨されています。特に重要なのは、モデルの動作と特性について事前に関係者の合意を得ることです。シミュレーションが予期せぬ結果や望ましくない結果を生み出した場合に、ステークホルダーがモデルの妥当性を否定したくなる可能性がありますが、事前に合意が得られていれば反論しにくくなります。シミュレーションの力と限界本章で紹介されたシミュレーション手法は、技術的負債の影響を「見える化」する強力なツールですが、いくつかの限界もあります。現実の組織では「2つ先のプロジェクト」よりも目先の納期が優先される状況が多く、将来コストの可視化だけでは意思決定に影響しない場合があります。また、モデルの妥当性検証にも課題があります。技術的負債のような長期的影響を持つ問題は検証サイクルが長く、「モデルが正しかった」と確認できるまでに年単位の時間がかかります。この間にモデルへの信頼が低下すると、継続的な活用が困難になります。とはいえ、シミュレーションモデルは技術的決断の「将来への影響を可視化する窓」として、組織の意思決定能力を向上させる強力なツールです。静的な図や文書だけでは伝えにくい技術的負債の長期的影響や反直感的な振る舞いをシミュレーションを通じて示すことで、組織内の共通理解構築に貢献します。技術的負債管理における動的シミュレーションの価値は、今後ますます高まるでしょう。「見えないコスト」を可視化し、長期的な視点を提供するこのアプローチは、短期的な利益にフォーカスしがちな現代の開発環境において、特に重要な役割を果たすと考えられます。Part III Tackling Technical Debt11. Safely Convincing Everyone変革の難しさと危険性技術的負債への対処には組織全体の協力が必要だが、変革を起こすことには危険が伴うというのが本章の核心です。著者はマキャベリの「新しい秩序を導入することほど危険で成功が不確かなものはない」という言葉から始め、「安全に」「説得する」「全員を」という三つの重要な視点を提供しています。本章の焦点は、技術的な解決策そのものではなく、その解決策を組織に受け入れてもらうための人間的、社会的側面にあります。セメルワイスという19世紀の医師の悲劇的な事例を通じて、いかに優れたアイデアであっても実装に失敗する可能性があることを示しています。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazonセメルワイスの教訓19世紀ウィーンの産科医イグナーツ・セメルワイスは、医師が解剖後に手を洗わずに出産を介助することが産褥熱の原因だと突き止めました。塩素化石灰溶液による手洗いを導入すると死亡率が90%減少するという驚異的な成果を上げたにもかかわらず、彼の発見は同僚医師たちに激しく拒絶されました。セメルワイスの理論は当時の主流だった「四体液の不均衡」という病気観と矛盾し、因果関係の説明も不十分でした。さらに医師が「紳士の手」が病気を運ぶという考えに憤慨したことなども障壁となりました。しかし最も致命的だったのは、彼が医学界の重要人物を敵に回してしまったことです。自分の発見を無視する同僚たちを「無責任な殺人者」と非難した結果、彼は精神病院に閉じ込められて死亡するという悲惨な末路をたどりました。この事例から新たなアイデアを導入する際の障壁は必ずしも合理的なものだけではないことがわかります。技術的に優れた解決策であっても、組織の既存パラダイムや人々のプライドと衝突すれば受け入れられないのです。視点の転換セメルワイスの事例から生まれた「セメルワイス反射」は、現在の信念や枠組みに矛盾する新しい証拠を拒絶する認知バイアスを指します。著者は、単にセメルワイスの同僚たちを非合理的だと非難するのではなく、自分をセメルワイスの同僚の立場に置いて考える重要性を強調しています。当時の視点からすれば、セメルワイスの提案した「死体粒子」という因果メカニズムは、科学的進歩ではなく魔術的・迷信的思考への回帰に見えたかもしれません。目に見えない微小なものが人間を殺すという考えは、当時は非合理的に思えたのです。この視点転換から著者は、セメルワイスがより効果的に同僚を説得するために取るべきだった六つの行動を提案しています。同僚を疎外しないこと、より良いコミュニケーションを図ること、「紳士医師」の感受性に配慮すること、支持者の連合を構築すること、好機を待つこと、そして異なるコミュニティに働きかけることです。これらの教訓は技術的負債への取り組みにも直接適用できます。例えば「同僚を疎外しない」というポイントは、現代の事故調査から学んだ「すべての関係者は安全に作業しようとしていた」「当時の視点から見れば全員の行動には理由があった」という前提に基づいています。技術的負債問題でも同様に、関係者を非難するのではなく、彼らがそのような決断をした背景を理解することが重要です。理解してから理解される著者はスティーブン・コヴィーの「7つの習慣」から「理解してから理解される」という原則を引用しています。技術的負債を減らすためには、それを生み出した意思決定プロセスを変える必要があり、関係者がなぜそのような決断をしたのかを深く理解することから始めるべきです。前述の事故調査の原則「当時の視点から見れば全員の行動には理由があった」に則り、技術的負債を生み出した意思決定者が当時のコンテキストで最善と思える選択をしたと考えるべきです。インタビューやワークショップでの時間の大部分は、非難ではなく関係者が直面していた状況と制約を理解することに費やすべきです。著者はさらに「外部性の問題」にも触れています。外部性とは一方の当事者が他方に一方的にコストを押し付けられる状況です。利益を得る側は外部性の継続を望み、それを正当化しようとします。一方でコスト負担側も「誰も自分たちを責められない」「複雑すぎて誰にも理解できない」状態に安住してしまう共依存関係に陥ることもあります。共通理解の構築著者はジェラルド・ワインバーグの「チームのすべてのメンバーが問題の共通理解を持つまで、あらゆる解決の試みは単なる無駄なエネルギーである」という言葉を引用し、技術的負債への取り組みにはワークショップを通じた共通理解の構築が不可欠だと強調しています。共有理解の構築は一人ずつ始めることが推奨されています。まず一対一の面談を通じて各関係者の視点を深く理解し、後のワークショップでの議論の基盤を作ります。個別のインタビューでは、大勢の前では言えない率直な意見も出やすくなります。収集した情報はMiroやLucidchartなどの視覚的コラボレーションツールに記録し、インタビューの過程で徐々に全体像を構築していきます。この共有可視化プロセスが「共有理解」から「共有コミットメント」への移行を助けます。共通理解の構築には「問題基盤情報システム(IBIS)」「対話マッピング」「議論マッピング」などのツールが有効です。これらは利害関係者間の異なる視点を構造化し、建設的な対話を促進します。組織の準備状況への配慮時には組織が変革の準備ができていないこともあります。その場合著者は「変化の段階的理論モデル」を参考に「前熟考段階」に対処することを提案しています。前熟考段階では個人や組織は変化について真剣に考えていません。彼らは現状を守ろうとし、変化のプレッシャーに防衛的になります。ここで強制的な変革を試みるとかえって逆効果となり、「バックファイア効果」（反証的証拠に直面すると既存の信念を強化する傾向）を引き起こす可能性があります。このような状況では大きな変革を強制するのではなく、限定的な戦術的改善にとどめ、将来の介入のための扉を開けておくことが賢明です。セメルワイスの反省点として、彼が同僚を疎外したことで今後の協力可能性を閉ざしてしまったことが挙げられています。安全に説得するためのチェックリスト著者は章の最後に「安全に全員を説得するためのチェックリスト」を提供しています。同僚を疎外していないか、コミュニケーションは明確で促進されているか、全員と関わっているか、個別にステークホルダーと関わっているか、支持者の連合を構築したか、現在は好機か、そして組織が変革の準備ができていない場合も扉を開けておいたかといった点を確認するものです。技術的負債への取り組みは技術的問題というよりも人間の問題です。変革を成功させるためには論理的な正しさだけでなく、感情面への配慮と組織文化の理解が不可欠です。セメルワイスの悲劇から学び、私たちは「安全に全員を説得する」という困難だが不可欠なステップを通じて、技術的負債という厄介な問題に効果的に対処することができるでしょう。技術的負債の問題提起時に非難の言葉を避け、当時の意思決定の文脈を理解し、一対一の対話から始め、視覚的なツールを活用して異なる視点を統合し、組織の準備状況を見極めるというアプローチは、日々の実践に取り入れるべき重要な教訓です。12. A Program to Address Technical Debt技術的負債対策の体系的アプローチ技術的負債に対処する難しさは技術的問題ではないにもかかわらず、責任が高度に技術的な人々に委ねられることが多いという著者の指摘は、問題の本質を見事に捉えています。この章では、技術的負債への対処方法から実際の介入プログラムの構築へと視点を移し、持続可能な取り組みのためのロードマップを提示しています。著者は技術的負債削減プログラムのフレームワークとして6つの主要ステップを提案しています。予備情報収集、問題理解のためのワークショップ、追加情報収集、ソリューション開発のためのワークショップ、パイロットソリューション、そして展開と安定化です。このフレームワークはコード修正などの技術的解決策に直接飛びつく前に、組織の理解と準備状況の評価に時間を割いている点が特徴的です。Figure 12-2 The technical debt reduction program framework より引用私の経験でも技術的アプローチだけでは持続的な改善は達成できないことを実感してきました。コード解析ツールとアーキテクチャ設計を導入したにもかかわらず、数ヶ月後には元の状態に逆戻りしてしまったプロジェクトで、組織の意思決定プロセスと開発文化に焦点を当て直した結果、持続的な改善を実現できました。【ITIL4公認】ITIL 4の基本 図解と実践作者:中 寛之日経BPAmazon準備状況の評価と問題理解予備情報収集ステップでは組織の変化への準備状況を評価することが最重要課題です。組織が準備不足の状態で技術的負債削減プログラムを開始することは逆効果となり、将来の改善機会を損なう可能性があります。また現状に至った理由を理解することで、問題の根本原因に対処できます。問題理解のためのワークショップでは「共有かつ集合的な理解」の構築を目指します。全てのステークホルダーを関与させることで異なる情報を集め、後のプロセスでの協力を確保します。ワークショップではグループを意図的に混合し、異なる分野の人々が代替的な視点を探求する機会を作ることも推奨されています。あるプロジェクトでは運用チームとプロダクト企画チームが同じグループになることで、「リリースの頻度を上げたい」と「システム安定性を確保したい」という相反する要望の矛盾が明らかになり、共通の解決策を模索するきっかけとなりました。解決策の開発と実装ソリューション開発のワークショップでは潜在的な解決策を探索し、最終的にパイロットとして試す解決策を特定します。この段階でも全てのステークホルダーを関与させることが不可欠です。技術チームだけで解決策を設計すると、実装段階で大きな抵抗に直面するリスクがあります。パイロットソリューションの段階では小規模な実験を通して解決策の有効性を検証します。「早期の成功をステークホルダーに報告すること」が特に重要です。技術的負債の削減は通常すぐに目に見える成果を生み出さないため、小さな成功を強調し可視化することが変革を推進する勢いを維持するのに役立ちます。あるクライアントでは技術的負債対策の効果を「開発速度インデックス」という指標で可視化し経営陣に定期報告しました。リファクタリング後の開発速度向上というデータが次のフェーズの予算確保に決定的な役割を果たしました。継続的な改善サイクル著者は技術的負債問題を「一度のサイクルで解決することはできない」と明言しています。技術的負債は「厄介な問題」であり、「解決するというよりむしろ管理する」べきものです。循環するフレームワークを提示し、技術的負債管理が継続的プロセスであることを示しています。一つのサイクルが完了すると問題の性質が変化するため、次のサイクルを開始する必要があります。本章は技術的負債管理を継続的サイクルとして捉える包括的なフレームワークを提示しています。特に重要なのは技術的負債が技術的な問題ではなく変更管理の問題であるという認識です。どんなに優れた技術的解決策も、組織の意思決定プロセスや文化が変わらなければ持続的な改善は実現できません。技術的負債管理は終わりのない旅です。完璧に負債のない状態を目指すのではなく、「管理可能でビジネス価値の創出を妨げない」レベルを維持することが現実的な目標となります。アーキテクトの役割は単に技術的解決策を設計するだけでなく、組織全体がこの永続的な旅を効果的に進められるよう導くことにあります。13. Preliminary Information Gathering遅延満足と組織文化技術的負債への対処は本質的に遅延満足（delayed gratification）の問題であるという洞察は、本章の重要な出発点です。「企業版マシュマロテスト」という概念を通じて、著者は技術的負債管理と組織の忍耐力の関係を描き出しています。「今すぐ一つのマシュマロ」か「後で二つのマシュマロ」かという選択は、開発現場では「今すぐリリースするために技術的負債を増やすか」「時間をかけて適切な実装をし長期的な保守性を確保するか」という決断に直結します。著者が指摘するように、この能力は個人だけでなく組織文化にも依存します。私の経験からも技術的負債管理に成功している組織は、異口同音に「我慢できる文化」を持っています。ある金融テクノロジー企業では経営陣が四半期ごとに「技術的健全性レビュー」を義務付け、短期的な機能開発と長期的な技術投資のバランスを取る仕組みを構築していました。これにより技術チームは「リリース延期」という難しい決断にビジネス側の理解を得やすくなりました。マシュマロテストは単なる比喩ではなく実際の診断ツールとして活用できます。著者が提案する質問を通じて組織の「遅延満足度」を測定し、現実的な改善計画を立てられることは大きな価値があります。ダイアローグ 価値を生み出す組織に変わる対話の技術作者:熊平美香ディスカヴァー・トゥエンティワンAmazon技術的負債の現状把握著者は技術的負債の現状を理解するための5つの質問に焦点を当てています。①技術的負債はどれくらいあるか ②どのように獲得されたか ③組織はどこで痛みを感じているか ④コード関連の技術的負債は何か ⑤アーキテクチャ関連の技術的負債は何か。これらの問いは技術的負債の量だけでなく質や原因まで掘り下げる包括的なアプローチを提供しています。技術的負債の量を測定する手段として著者は「技術的負債レジスター」の活用を提案しています。興味深いのはレジスターの存在だけでなく「更新されているか」も重要視している点です。レジスターが更新されていないという事実自体が組織の技術的負債に対する姿勢を物語っています。著者がシャーロック・ホームズの「吠えなかった犬」の例えを用いて情報の不在も重要なデータだと指摘するのは見事です。私の実務経験からもこの体系的な情報収集アプローチの価値は明らかです。技術的負債の量的測定に加え異なるステークホルダーから多角的に情報を収集することで初めて全体像が見えてきます。ある金融機関では統合的な「技術的負債ヒートマップ」を作成し、組織のどの部分がどのような負債に苦しんでいるかを可視化したことでリソース配分の適正化が実現しました。負債のタイプと消火活動文化著者は技術的負債をコード関連とアーキテクチャ関連に分類して調査することを推奨しています。特に「アーキテクチャ関連の負債が最も高価な技術的負債」であり、多くの場合プロジェクトの初期段階で作られるという指摘は重要です。予算や時間の制約が厳しい場合、アーキテクチャの妥協が行われやすく、長期的なコストが発生します。マイクロサービスアーキテクチャが普及した現代のソフトウェア開発においてもこの問題は顕著です。サービス境界の不適切な設計はシステム全体の複雑性を高め保守コストを増大させます。私の経験では技術的負債の優先順位付けにおいてアーキテクチャとコードの区別は極めて重要です。アーキテクチャの負債は放置すると影響範囲が指数関数的に広がる一方、コードレベルの負債は比較的局所的な影響にとどまります。「消火活動による負債蓄積」のセクションは組織行動の観点から技術的負債の蓄積メカニズムを解説しています。著者は消火活動を「以前に確立された計画や優先事項を無視して問題発生時に反応的修正的なアプローチを適用する管理タイプ」と定義します。消火活動文化の特徴として著者は「技術的負債の長期的影響に関する議論が異端視される」点を指摘しています。現場からの「将来の問題」への懸念が「今の問題を解決できなければ将来なんてない！」という短期的思考に押しつぶされてしまうのです。また「英雄的な消火活動者を過度に称賛する」文化が消火活動を永続化させる危険性も指摘されています。私の経験では「消火活動モード」への転落は予想以上に速く起こります。ある製造業のシステム開発では、最初の遅延発生から2週間でチーム全体が消火活動モードに陥り、テスト活動削減や設計文書の放棄といった悪循環が始まりました。消火活動からの脱却は極めて困難であり、「消火活動モードへの転落を防ぐ」予防策の重要性を痛感しました。効率的な介入点と変革への準備本章の後半で著者は組織の理解に基づく「前進方法の決定」に焦点を当てています。特に「レバレッジポイント」の探索は効率的な技術的負債管理において核心的な考え方です。これは小さな変更で大きな効果をもたらす可能性のある点を指し、効率的な改善の鍵となります。著者は「少なくとも2つの前進方法のアイデアを持って」ワークショップに臨むことを推奨しています。これはエンジニアリング的なアプローチだけでなく組織変革としての準備も必要だという認識を示しています。また「トレードオフの理解」「システムの理解」「潜在的なレバレッジポイントの理解」という段階的なアプローチも実践的です。私のアーキテクト実務においてもレバレッジポイントの特定は技術的負債管理の核心です。あるeコマースシステムでは「商品カタログサービス」がボトルネックとなっていることを特定し、集中的にリファクタリングすることで全体のパフォーマンスが劇的に向上しました。すべての負債に均等にリソースを配分するのではなく「最大の効果をもたらす負債」に集中することが重要です。著者は技術的負債対策プログラムを人々の変化への準備という観点からも考察しています。予備情報収集の段階で「技術的負債が管理された組織ではどのように違うか」を説明することが重要です。より予測可能で迅速なソフトウェア開発というビジョンを共有し、必要な規律や方針変更についても前もって議論しておくべきです。特に興味深いのはソフトウェアシミュレーションモデルの活用提案です。技術的負債の動的側面を探索するためのシミュレーションツールは抽象的な概念を具体的に示す強力な手段となります。個人にモデルを見せて実験させることで、組織の開発プロセスとの類似点や相違点について議論を促進できます。情報収集の重要性本章の核心は適切な情報収集が効果的な技術的負債管理プログラムの基盤だという点です。単なる「悪いコード」の列挙ではなく、組織文化や意思決定プロセスも含めた多角的な調査が不可欠となります。著者は本章の最後に予備情報収集の成果として「質問への回答」「インタビューノート」「初期的な発見事項」が期待されると述べています。ここからさらに組織の技術的負債特性やその原因、そして現在のレベルに関する「感覚」を発展させるべきだと強調しています。これは現代のDevOps文化における「継続的な改善」の概念とも整合します。私の経験では技術的負債管理を一時的なプロジェクトではなく継続的なプロセスとして位置づけることが成功の鍵です。あるSaaS企業では「リファクタリングフライデー」という慣行を導入し、毎週金曜日の半日を技術的負債の返済に充てることで負債が累積する前に対処する文化を構築しました。このような継続的な取り組みを支えるのが本章で説明されている予備情報収集のプロセスです。状況を正確に把握し効果的なレバレッジポイントを特定することで限られたリソースで最大の効果を得ることができます。技術的負債に関する深い理解なしには持続可能な対策は不可能なのです。「測定なくして管理なし」という原則は技術的負債管理にも当てはまります。技術的負債の効果的な管理には正確な現状把握が必須であり、多角的なデータ収集が必要です。組織の遅延満足能力を正直に評価し、技術的負債レジスターを整備し定期的に更新し、コード関連とアーキテクチャ関連の負債を区別して対処し、消火活動文化から脱却するための環境改善を行うというアプローチが有効です。予備情報収集が次の「問題理解ワークショップ」への準備であるという著者の指摘は重要です。情報収集は単独の活動ではなく組織全体の共通理解と行動変革への第一歩なのです。技術的負債管理は技術問題ではなく組織全体の問題だという認識が本章全体を通して強調されています。14. Workshop for Problem Understanding技術的負債への共通理解を構築するワークショップ技術的負債問題を組織全体で理解するためのワークショップは、技術的負債対策プログラムの核心部分です。著者は2日間のワークショップアジェンダを提示し、予備情報収集で得られた知見をもとに組織内の全関係者が技術的負債の本質とその原因を共通理解するためのプロセスを詳細に解説しています。このアジェンダは技術的負債の多層的な性質を反映した構成になっています。1日目は「イントロダクション」「トレードオフ決定の理解」「システム効果の理解」「アンチパターン」をカバーし、2日目は「経済学的視点からの負債」「厄介な問題・社会的複雑性・分断」「総合的な問題理解」へと進みます。この構成は技術的負債「玉ねぎモデル」の層構造と見事に対応しており、単に「コードが汚い」という表面的な理解から、徐々に深層の原因へと参加者の理解を導く流れになっています。私はこのアプローチに強く共感します。これまで多くの組織で技術的負債対策が失敗したのは、問題の本質的な理解なしに表面的な対処に終始したからです。まず、ちゃんと聴く。　コミュニケーションの質が変わる｢聴く｣と｢伝える｣の黄金比作者:櫻井将日本能率協会マネジメントセンターAmazonトレードオフ決定の理解「Understanding Trade-Off Decisions」セクションは特に印象的です。ここでは参加者がアフェクト・ヒューリスティックを用いて意思決定していることへの気づきを促し、技術的負債蓄積の心理学的要因に焦点を当てています。著者はChristopher Hseeの実験を再現する演習から始めることで、参加者の関心を引き理論的な説明へとスムーズに移行しています。この手法はワークショップ設計において非常に効果的です。参加者は自分自身の意思決定傾向を体験的に把握することで、理論の説明により深く共感できるようになります。私が以前ファシリテートしたワークショップでも同様のアプローチを試みました。参加者に複数の選択肢（技術負債を増やして納期を守るか、技術的健全性を保って納期をずらすか）を提示し実際に選択してもらった後で、意思決定パターンを分析したのです。この体験は多くの参加者にとって目からウロコの瞬間となりました。著者はタバコの健康警告メッセージの例も挙げ、技術的負債の問題を理性ではなく感情に訴えかける形で伝える重要性を説明しています。また「ユリシーズ契約」「同時決定vs連続決定」「プリモーテム技法」などの概念も紹介され、参加者がより効果的な意思決定を行うための具体的なツールを提供しています。システム思考とシミュレーション「Understanding Systems Effects」セクションでは、システムの内部構造が外部の影響よりもその行動パターンを決定づけるという重要な洞察を提供しています。著者はITシステムと社会的システムの決定的な違いとして「社会的システムの構成要素は独自の目標を持ち追求できる」点を強調しています。このセクションで紹介されるVensimモデルリーダーを使用した技術的負債シミュレーションモデルは、参加者に動的なシステム挙動を体験的に理解させる強力なツールです。「過剰と崩壊（overshoot and collapse）」のような一見予測困難なシステム行動パターンを視覚化することで、参加者は技術的負債の長期的影響をより直感的に把握できるようになります。私の経験からもこうしたシミュレーションの効果は絶大です。ある金融機関でのプロジェクトでは、技術的負債の蓄積が開発速度に与える影響をシミュレーションモデルで示しました。最初は順調に進むプロジェクトが負債の蓄積とともに徐々に減速し、最終的には機能停止する様子を可視化したことで、経営層が技術的負債対策の重要性を納得したのです。アンチパターンと因果ループ図「Anti-patterns」セクションでは技術的負債を増加させる行動パターンと因果ループ図（CLD）の概念が紹介されています。著者は参加者が自ら「推定トラップ」のCLDを構築する演習を提案しています。この体験型のアプローチは参加者が概念を自分のものとして内在化するのに役立ちます。私のアーキテクト経験でもCLDは複雑な組織的問題を説明するのに非常に有効でした。あるプロジェクトでは「テスト自動化の後回し→手動テスト負荷の増大→テスト自動化に使える時間の減少→さらなる手動テスト依存」という悪循環をCLDで可視化しました。これによりチームは問題の本質が単なる「リソース不足」ではなく「システム構造」にあることを理解し、解決策を見出すことができたのです。経済学的視点と厄介な問題「Technical Debt from an Economics PoV」セクションでは、経済学の概念を用いて技術的負債問題を考察します。著者はHMVでの経験談を通じて「それは私の問題じゃない！」という反応を「外部性」という経済学的概念で説明し、問題の本質が個人の性格ではなくシステム構造にあることを示しています。8つの経済学的問題（プリンシパル・エージェント問題、コモンズの悲劇、外部性、短期主義、小さな決断の専制、忍び寄る正常性、アナーキーの代償、モラルハザード）は技術的負債への新たな視点を提供します。「Wicked Problems, Social Complexity, and Fragmentation」セクションでは技術的負債問題の最も深い層に焦点を当てています。「デザインの二分法」の概念、つまり「あるべき姿」を追求するグループと「できること」に焦点を当てるグループが対立する構図は、多くの組織で見られる現象であり、技術的負債問題においてもビジネス側と技術側のこの対立が根本的な課題となっていることが多いのです。ワークショップの準備と実施「Putting It All Together」セクションでは、著者は「ワークショップが解決策モードに走るのを避ける」ことを強調しています。これは極めて重要なポイントです。問題解決に慣れた技術者はすぐに解決策を提案したがりますが、拙速な解決策は表面的な対処に終わりがちです。問題理解のフェーズで十分に時間をかけることが長期的には効率的なアプローチとなります。後半の「Workshop Preparation」セクションはワークショップの成功に不可欠な準備について詳細なガイダンスを提供しています。ワークショップへの準備に3〜10倍の時間をかけるべきだというアドバイスは現実的で経験に基づいたものだと感じます。また「一人ひとりが最初の30分間に発言する機会を作る」という具体的なテクニックは参加率を高めるための有効な戦略です。第14章のワークショップアプローチの最大の価値は、技術的負債問題を「知識」のレベルから「理解」のレベルへと深める点にあります。参加者は講義を聞くだけでなく、体験的な演習やグループディスカッションを通じて技術的負債の多層的な性質を内在化します。この共通理解が次の「追加情報収集」と「解決策開発」への強固な基盤となるのです。15. Additional Information Gathering and Sensemaking組織の政治的側面の理解第15章で最も印象的だったのは「政治的側面（Political Landscape）の理解」に重点を置いている点です。技術的負債は純粋に技術的な問題ではなく、組織的・政治的な側面を持つという認識は極めて重要です。著者が指摘するように「情報が欠けているように見える場合、実際には隠されていたり偽装されていたりする」ことが多々あります。著者のHMVでのエピソードは非常に示唆に富んでいます。テスターに二画面を与えることが「スクリーン羨望（screen envy）」という理由で拒否された話は、技術的な合理性と組織的な現実の乖離を見事に示しています。Javaデベロッパーに特別感を与えるために二画面を許可し、他のスタッフには認めないという決定は技術的には全く意味がありません。しかし組織の暗黙のヒエラルキーを維持するという政治的観点からは合理的だったのです。私の経験でも同様の状況に遭遇したことがあります。あるプロジェクトではアーキテクチャの重大な欠陥が明らかになったにもかかわらず修正案が拒否され続けました。後になって判明したのはその設計が特定の上級管理職のアイデアだったこと。その人物のプライドを守るために欠陥のあるアーキテクチャが維持されていたのです。こうした人間的要素は純粋に技術的なアプローチでは解決できません。著者の「マインドマップを作成して異なる派閥や彼らの目的、相互関係を把握する」というアドバイスは極めて実用的です。ただし著者が警告するように「共有または誰でもアクセスできる場所に置かないこと」は重要です。こうした政治的分析は誤解を招く恐れがあるため慎重に扱う必要があります。反脆弱性[上]――不確実な世界を生き延びる唯一の考え方作者:ナシーム・ニコラス・タレブダイヤモンド社Amazon情報収集とセンスメイキング「不足情報への対応」セクションでは、組織の政治的側面を理解した上で必要な情報を収集する方法について解説しています。私にとって最も共感できるのは「全ての不足情報を入手することは不可能だと認識すべき」という指摘です。ソフトウェア開発では完璧な情報を持つことは幻想にすぎません。著者の「WMD（大量破壊兵器）の証拠がすべて揃わなくても他国に侵攻するなら、技術的負債についてすべての情報がなくてもワークショップを進めてもよいはず」という皮肉交じりの発言は痛烈です。完璧な情報を待っていては何も始められません。得られる最善の情報で前進する勇気も必要なのです。「意味づけ：全てが意味するものは何か？」セクションは、集めた情報から構造と意味を見出すプロセスを扱っています。著者は様々な技法を紹介していますが、特に興味深いのは非正統的な方法への言及です。「退屈」を創造的なツールとして活用するという発想は新鮮です。問題について考えすぎて退屈になるまで考え、次に完全に忘れて違うことをする。そして睡眠をとった後に戻ってくると新たな洞察が得られるかもしれないというアプローチは、私も経験的に効果を実感しています。センスメイキングプロセスで特に価値があるのは「仮説を検証する」というアプローチです。仮説を立て裏付けるデータを収集するだけでなく、仮説が間違っていることを示す可能性のあるデータも意識的に探すという姿勢は、健全な批判的思考を促します。解決策の形成と検証「潜在的な解決策の形成」セクションでは、技術的負債対策の二つの主要なアプローチ「既存の負債の削減」と「新たな負債の作成回避」のバランスを強調しています。著者は短期的な成果を示すために既存の負債に対処することの重要性を認めつつも、長期的には負債作成プロセスそのものの変革が必要だと述べています。HMVのJukeboxプロジェクトの例はこの原則を完璧に示しています。C#で開発されたシステムをJavaで再実装することで既存の負債は解消されましたが、「IT部門を完全に含めずに戦略的イニシアティブを開始する」という根本原因は解決されなかったのです。結果として新たな負債が作られ続けました。「センスメイキング→潜在的解決策の形成→ステークホルダーフィードバック→リファイン」という反復的なプロセスは特に価値があります。このフィードバックループを通じてステークホルダーの賛同を得つつ解決策を洗練させるアプローチは、変革管理の基本原則に沿っています。私の経験では技術的負債対策プログラムが失敗する最大の理由はこの反復的プロセスの欠如です。多くの場合技術チームが「完璧な」解決策を考案し一方的に導入しようとしますが、ステークホルダーの関与なしでは抵抗に遭い挫折します。小さなフィードバックループを何度も回し、各ステークホルダーが「自分の提案が取り入れられた」と感じる機会を作ることが成功への鍵です。「動的シミュレーションモデル」セクションは、技術的負債の影響を可視化する強力なツールについて言及しています。私の経験では技術的負債の影響を客観的に示すことはステークホルダーの説得において最大の課題の一つです。シミュレーションモデルを通じて負債の蓄積がどのように開発速度の低下や品質問題に結びつくかを視覚的に示すことができれば説得力は格段に高まります。技術を超えた人間の問題この章を通じて最も強調されているのは、技術的負債が単なる技術的問題ではなく「人間の問題」だという点です。著者がジェラルド・ワインバーグの「常に人間の問題である」という言葉を引用しているように、技術的負債の背後には常に人間の決断や人間関係の力学があります。技術偏重のアプローチでは組織の政治的側面や人間の心理を無視してしまうため、効果的な解決は難しくなります。セメルワイスの悲劇的な例が示すように、科学的に正しいソリューションでも人間的な側面を無視すれば拒絶されるリスクがあるのです。私が技術的負債対策プログラムで最も重視するのはこの「人間中心」のアプローチです。技術的に最適な解決策より、組織文化や政治的現実に適合した実行可能な解決策を優先します。また変革の速度も重要です。急激な変化は抵抗を招くため、「ボイルドフロッグ」アプローチとも呼ばれる緩やかな変化が効果的であることが多いです。第15章は技術的負債対策プログラムにおける「問題理解」と「解決策開発」の間の重要なステップを詳細に解説しています。特に重要なのは、技術的負債を単なる技術問題としてではなく、組織的・政治的な問題として捉える視点です。「情報が隠されている可能性」「政治的力学の影響」「完璧な情報の入手不可能性」といった現実を認識したうえでの対応が必要になります。技術的負債対策の成功はアーキテクチャの適切さやコードの質だけでなく、組織の政治的現実への適応力にも大きく依存します。セメルワイスの悲劇を繰り返さないためにも、「それは安全にできるか？」という問いを常に念頭に置き、人間中心のアプローチを心がけることが不可欠です。16. Workshops for Solution Development解決策開発ワークショップの目的と構造第16章は技術的負債対策プログラムの重要な段階である解決策開発ワークショップに焦点を当てています。ワークショップの目的を明確にすることが最も重要であり、著者は「パイロットプロジェクト段階に持ち込める潜在的な解決策をもってワークショップを終えること」という明確な目標を設定しています。著者が提供する1日のワークショップアジェンダは「リキャップと更新」からスタートし、「第一の候補介入策の探索」「第二・第三の介入策の探索」「要約と次のステップ」へと続く論理的な流れになっています。特に「既存の負債への対処 vs 新たな負債の作成回避」というセクションは技術的負債管理の二つの主要アプローチのバランスを考慮する重要性を強調しています。PowerPointスライドデックの活用に関する著者の提案も実用的です。「自分のプレゼンテーションスタイルを反映するように各スライドを修正する」というアドバイスは単なるテンプレートの使用を超えた個人化の重要性を示しています。私が組織でワークショップを実施した経験からも十分な準備が成功の鍵であることを強く実感しています。物語思考　「やりたいこと」が見つからなくて悩む人のキャリア設計術 (幻冬舎単行本)作者:けんすう（古川健介）幻冬舎Amazon前回の理解を振り返る「リキャップと更新」セクションは前回のワークショップの成果と追加調査結果を共有するための重要なステップです。技術的負債の「玉ねぎモデル」の復習は特に重要であり、「技術的負債は技術的問題か？」という問いに対して全員が「No!」と答えるよう促すアプローチは核心的な理解を確認する効果的な方法です。前回のワークショップの結果と追加調査の発見を共有するセクションでは、著者は「ワークショップの方向性を形作る機会」としての側面を強調しています。これは単なる情報共有ではなく、議論を生産的な方向に導くための戦略的なステップです。重要あるいは実りの多い領域を強調し、他の領域にはあまり重点を置かないことでファシリテーターはワークショップの焦点を効果的に調整できます。私の経験でもこのような「方向付け」は極めて重要です。あるプロジェクトでは技術的負債の様々な側面を検討していましたが、全てを同等に扱うと議論が発散してしまいました。そこで特にビジネスインパクトの高いアーキテクチャの整合性に焦点を当てることで、具体的な改善策を効率的に策定することができました。候補介入策の探索と評価「最初の候補介入策の探索」セクションでは、最も有望な技術的負債管理介入策を深掘りします。候補介入策の選択にはドット投票法の使用が推奨されています。各参加者が一定数の投票権を持ち自分が優先したい項目に割り当てるこの手法は、直観的かつ民主的な優先順位付け方法です。ファシリテートされた議論では、介入策の明確な問題/介入ステートメントの作成から始めることが推奨されています。例えば「プロジェクトの過小評価はプロジェクトの遅延につながり技術的負債を生み出す。当組織はプロジェクト見積もりを技術的負債作成の要因でなくなるまで改善する」といった形式です。このような明確なステートメントが議論の焦点を絞り、具体的な行動計画の形成を促進します。解決策アプローチのアイデア生成には「1-2-4-All」とブレインストーミングを組み合わせる方法が提案されています。この手法は個人での思考からペアディスカッション、さらに4人グループでの議論へと段階的に拡大していくアプローチで、多様な視点を集めつつグループダイナミクスを効果的に活用できます。有用なワークショップ技法著者が提案する「有用なワークショップ技法」は実務者にとって貴重なツールキットです。「厄介な質問（Wicked Questions）」は対立する現実を両方とも認める質問を形成する手法です。例えば「技術的負債を減らしながら同時にベロシティをどう維持するか？」といった形式の質問は、矛盾するように見える目標間の創造的な緊張を生み出します。「TRIZ」（発明的問題解決の理論）は特に興味深い手法です。この手法では「最悪の結果を確実にする方法」を特定し、次に「現在行っている活動で最初のリストに似ているもの」を見つけ、最後にそれらの活動を停止する方法を考えます。「技術的負債でいっぱいのITシステムを確実に構築するには？」といった逆説的な問いかけは既存の思考パターンを破壊する効果があります。「チェスタートンのフェンス」は既存のセットアップの理由を完全に理解するまで変更を加えるべきではないという原則です。著者がスイスの製薬会社のシステム移行プロジェクトで経験した教訓（使われていないと思われたインターフェースを削除した結果、ヨーロッパ中の工場が停止した）は非常に印象的です。技術的負債対策においても、既存の「負債」が何らかの重要な目的を果たしている可能性を常に考慮する必要があります。フォローアップと成果の確保著者は「ワークショップの準備」「セッション後のフォローアップ」「アウトプット」といった実践的な側面も詳細に解説しています。特に「Peter Druckerの誤用を借りれば『測定されるものは管理される』。確実に誰かが特定された小さな改善策をフォローアップすることを参加者に知らせなさい」というアドバイスは重要です。ワークショップの成果として著者は「パイロットまたは承認を求めるための1〜3の介入策」「将来のワークショップのための候補介入策リスト」「ワークショップ参加者が実行できる小さな項目のリスト」などの具体的なアウトプットを挙げています。私の経験から最も価値があるのは「ワークショップ参加者が実行できる小さな項目のリスト」です。大規模な組織的変革は時間がかかりますが、小さな改善は即座に実施でき成功体験を積み重ねることができます。第16章で最も重要なメッセージは参加者に「主体性（agency）」を持たせることです。技術的負債は圧倒的で手に負えないように見えることが多く、無力感や諦めを生み出します。しかし著者が提案するワークショップアプローチは参加者が自分たちの裁量でできることに焦点を当て、具体的な行動計画を形成することで主体性を回復させるのです。17. Pilot Solutionsパイロットプロジェクトの危険性と留意点第17章は技術的負債対策プログラムの実験的な試行段階に焦点を当てています。パイロットプロジェクトの危険性への警告から始まり、著者はマキャベリの「新しいものを導入するほど危険で不確実なものはない…改革者は古い条件下で成功した全ての人々を敵に回すからだ」という言葉を引用し、変革の難しさを強調しています。最も印象に残るのは「自身の利益のために悲劇を利用しようとする人がいるのなら、自組織内の誰かがパイロットプロジェクトを自己利益のために利用しようとすることは間違いない」という警告です。これは実務経験からも強く共感できるポイントです。以前関わったプロジェクトでは技術的負債対策パイロットの結果が特定のチームの予算削減を正当化する「証拠」として利用されかけたことがありました。パイロットの位置づけについて著者はCynefinフレームワークを参照し、技術的負債問題が「複雑（COMPLEX）」な領域に位置することを示しています。このような領域では完全に制御された実験が不可能であり、介入自体が問題の性質を変えてしまうことも考慮すべきです。そのため「介入が状況を悪化させるよりも改善する可能性が高い」という程度の証明で十分だとする著者の実用的なアプローチは説得力があります。リーン・スタートアップ　ムダのない起業プロセスでイノベーションを生みだす作者:エリック リース日経BPAmazonデータを活用した解決策の検証著者はパイロットプロジェクトなしで技術的負債を管理できる二つの状況を検討しています。一つはソリューション開発ワークショップで参加者が自分たちの権限内でできると特定した小さな項目のみに対処する方法、もう一つは過去のプロジェクトデータを使用する方法です。過去プロジェクトのデータを使用した例として、遅延した二つのプロジェクトの技術的負債蓄積パターンの違いが示されています。正確に見積もられたプロジェクト（20%遅延）では技術的負債が全期間を通じて均等に蓄積されていましたが、不正確な見積りのプロジェクト（60%遅延）では当初の締め切りを過ぎた後に技術的負債の蓄積率が急激に上昇していました。これは単なる印象や主観ではなく実際のデータに基づく証拠であり、技術的負債の管理において「プロジェクト遅延防止」が重要な戦略であることを示しています。この分析アプローチは現代のソフトウェア開発環境でも直接応用可能です。ユリシーズ契約を用いた負債管理著者はパイロットプロジェクトの具体例として「ユリシーズ契約」の実装と評価を提案しています。ユリシーズ契約とは将来の特定条件下で自分自身を拘束するために自発的に締結する合意です。技術的負債の文脈では、戦術的なプロジェクト問題を解決するために技術的負債を作成することを許容しつつ、その負債を返済するための時間と資金を確保するメカニズムを提供します。著者が提案するユリシーズ契約の設計で考慮すべき点は「望ましい行動を奨励し望ましくない行動を抑制する」という原則に基づき、高い透明性、高コスト負債の回避、組織全体にとって有利な場合のみ負債を受け入れるといった望ましい行動を促進する仕組みが必要だと指摘しています。特に興味深いのは「負債のコストをどのように分担するか」についての考察です。全てのコストを組織が負担するとプロジェクトはあらゆるものを技術的負債登録簿に追加しようとする一方、全てのコストをプロジェクトが負担するとほとんどの技術的負債項目が隠されて透明性が失われるというジレンマが生じます。これは単純な技術的問題ではなく、組織的なインセンティブ設計の問題であることを示しています。実務的には私はこのようなユリシーズ契約を「技術的負債バジェット」という形で実装したことがあります。各プロジェクトには一定量の「負債クレジット」が割り当てられ、期限内に納品する必要がある場合に「借用」できる仕組みです。重要なのはこの「借用」が明示的に記録され、返済計画が事前に合意されることです。パイロットの実施と結果分析著者はパイロットプロジェクト選定の基準として「適時性」「協力的なチーム」「小規模」「緊急性が低い」「短期間」といった要素を挙げています。特に注目すべきは「プロジェクトが遅延した場合実験が忘れられるリスク」や「さらに悪いことにスケジュール遅延の責任転嫁に使われるリスク」という警告です。パイロットプロジェクト実施の際、著者は「プロジェクト自体ではなく介入による技術的負債蓄積の変化に関する情報収集」に焦点を当てるべきと強調しています。プロジェクト運営自体に巻き込まれないよう注意しつつ、プロジェクトチームが持つ洞察や価値観を活用することが推奨されています。結果分析においては「これは正しい方向への一歩だったか」「コストよりも大きな助けになったか」という二つの基本的な質問に答えることを目指すべきです。また報告書は「忙しく注意力散漫なステークホルダー」を念頭に置き、明確で簡潔なメッセージを含めることが重要です。「人は数字が好き」「人はストーリーも好き」という著者の指摘は組織でのコミュニケーション経験からも非常に的確です。本章の最も重要なメッセージは技術的負債管理が単なる技術的問題ではなく、組織全体のプロセスと文化に関わる変革だということです。著者が提案するユリシーズ契約や段階的なパイロットプロジェクトアプローチはこの複雑な変革をより管理可能な形で実施するための実用的な方法です。最終的には組織の文化や構造に適合した「型」を見つけることが成功への鍵となります。技術的負債という「厄介な問題」に対処するための万能解決策は存在しませんが、明示的な契約、データに基づく意思決定、小規模から始めて学習するという原則を取り入れることで、組織は自分たちに適した持続可能な技術的負債管理アプローチを見つけることができるでしょう。18. Rollout and Stabilization組織変革としての技術的負債管理第18章は技術的負債削減プログラムの最終段階、組織全体への展開と定着に焦点を当てています。技術的負債への対処は単なる技術問題ではなく、組織全体の変革を必要とする取り組みであることが強調されています。マキャベリの「新しい秩序を導入することほど困難で危険で成功が不確かなものはない」という言葉は、技術的負債への取り組みにも当てはまります。変革管理の難しさは単に既存の負債を技術的に解決することではなく、人々の働き方を変えることにあるのです。技術的負債の解消が困難である理由は多岐にわたります。多くの人は技術的負債を技術問題と誤解し、本質がトレードオフ問題であることを認識していません。また常に他の「緊急」事項が優先される状況や、華々しい成果を上げにくい地道な取り組みであることも組織的な推進力を弱めています。技術的負債の返済に多額の投資を行う組織でさえ、その成果を定着させるためのプロセス変革に失敗するケースが多いのです。コッターの8ステップ変革プロセス本章ではジョン・コッターの8ステップ変革プロセスに焦点を当てています。このモデルは実証済みで広く使われ、豊富な文献とリソースがあり、関連経験を持つ変革管理の専門家も多いことから選ばれています。コッターのモデルはコミュニケーションと関係者の同意獲得に重点を置いています。明確な8つのステップが用意されていること、シンプルな実装方法、ステークホルダーの参画への強い焦点、緊急性の感覚を創出する点が利点として挙げられています。変革の8ステップとその実践緊急性の確立は技術的負債への取り組みにおいて特に難しい課題です。アイゼンハワー大統領の区分で言えば、技術的負債は「重要だが緊急でない問題」に該当します。効果的な緊急性を確立するためには、技術的負債の組織へのコスト試算、負債が引き起こした具体的な事例を物語として伝えるアプローチ、異なるレベルの技術的負債が開発コストに与える影響を動的シミュレーションモデルで可視化する方法などが有効です。ただし誇張された緊急性を作り出すことは「組織変革疲労」を引き起こす危険があります。著者は絶え間ない変革状態にあった組織での経験から、BOHICA(「また来たぞ、身構えろ」の意)という現場エンジニアの諦めの姿勢について触れています。強力な指導連合の形成も重要です。変革を成功させるには「強力」で「指導」する「連合」が必要です。パワーは変革を実行するための十分な権限を持ち、指導力は組織全体を導く能力、連合は技術的負債問題に取り組む共通の目的を持った集団を意味します。ビジョンの創造とコミュニケーションでは、明確で魅力的で信頼できるビジョンが必要です。このビジョンがあまりに複雑だったり曖昧だったりして5分以内で相手に伝えられないようでは失敗の原因となります。技術者向けには「負債に縛られずに望まれる機能を最良の方法で実装できる」というビジョン、利害関係者には「予測可能性と約束通りの機能提供」というビジョンを伝えるなど、対象によって異なるメッセージが必要かもしれません。ビジョンに基づく行動の促進においては、組織構造や強力な抵抗勢力がもたらす障壁を取り除く必要があります。変革への最大の障壁は現状に既得権益を持つ人々の抵抗です。例えばスプリントから無理やり追加のストーリーを絞り出すプロダクトマネージャー、実現不可能と知りながら受注する営業チーム、遅延プロジェクトで品質より機能を優先するステークホルダー、火消し作業に終始し根本的な改善に取り組まない「ヒーロー」など様々なパターンがあります。短期的成果の創出と定着化も欠かせません。ステークホルダーは合理的な期間内に改善の兆候が見えなければ変革への道を継続することはできません。そのため技術的負債削減プログラムには早期の成果を示せる取り組みを含めるべきです。これらの改善に貢献したチームメンバーを称えることで他のメンバーにも変革への動機付けができます。新しいアプローチの制度化が最終目標です。早期の成果による信頼性の向上を活用し、技術的負債の蓄積につながるシステム構造や方針の変更を主張しましょう。技術的負債の文脈では見積りプロセスの改善など根本的な原因に対処する変更が多く該当します。変革の成功要因変革プロジェクトの成功に共通する重要な要素には、測定可能なステークホルダーの目標の定義、全関係者への効果的なコミュニケーション、効果的なトレーニングプログラムの作成、抵抗の監視と対処、進捗の監視と微調整があります。技術的負債の解消は技術だけの問題ではなく組織全体の変革を必要とすることをこの章は強調しています。コッターの8ステップモデルは効果的な変革管理の枠組みを提供していますが、重要なのは組織の文化や特性に合わせたアプローチをとることです。技術的負債は連続的な問題であり、一度解決すれば終わりというものではありません。持続可能な解決策の構築には組織全体の継続的な取り組みとスキル構築が求められています。19. Conclusion魔法のボタンは存在しない著者は魅力的な比喩で最終章を始めています。もし寿命を延ばすボタンや体重を減らすボタンがあれば誰もが迷わず押すでしょう。しかしそのようなボタンは存在せず、健康的な生活習慣や適切な運動プログラムの継続が唯一の道です。同様にソフトウェアシステムの寿命を延ばす魔法のボタンも存在しません。一部のベンダーは「魔法の解決策」を売り込もうとしますがそれは幻想にすぎません。技術的負債に対する現実的なアプローチは「頭蓋骨に穴をあける」ような原始的な対症療法ではなく、世界の捉え方自体を変えることから始まります。慢性的な頭痛を食事や生活習慣、予防薬の組み合わせで治療するように、技術的負債も根本的な原因理解と持続的な対策が必要なのです。この取り組みには努力と満足の遅延が必要ですが、確かな道筋は存在します。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon技術的負債の本質技術的負債の問題に立ち向かう際の最初の障壁は「負債」という類推自体の限界です。金融債務との類推は技術的でない利害関係者とのコミュニケーションに役立ちましたが、同時に誤解も生み出しました。この類推は技術的負債を主に「技術的な問題」と捉えさせますが、実際は「トレードオフの問題」なのです。新機能、早期デリバリー、直接コスト削減と引き換えに負債を抱え込む意思決定が本質的な課題です。トレードオフ決定は「affect heuristic（直感的判断）」に基づいて行われ、潜在意識で処理されるため歪みが生じやすく自覚することも困難です。本書を通じて学んだように、技術的負債はこの意思決定プロセスの歪みが組織システム内で増幅される結果なのです。技術的負債は単なる個人の意思決定の問題ではなく「システム問題」です。判断を行う個人は真空の中ではなく組織というシステムの中で意思決定を行います。彼らの役割とそれに伴う評価基準が負債に関する判断を歪めるのです。この問題が「厄介な問題（wicked problem）」であり、組織の社会的複雑性と相まって断片化したグループ間の対立を生み出すのです。技術的負債管理がもたらす恩恵こうした複雑な問題にもかかわらず、技術的負債を管理し高価なソフトウェアシステムの寿命を延ばすプログラムを構築することは可能です。技術的負債管理プログラムの構築が組織にもたらす三つの大きな恩恵を著者は強調しています。システムの寿命を50%以上延長することによる大幅なコスト削減。IT開発は既に組織予算の相当部分を占めており、人工知能など新技術の普及によってその割合は今後も増加することが予想されます。大規模なITプロジェクトによる混乱の減少。システム置き換えのような大規模プロジェクトはビジネスに大きな混乱をもたらしますが、技術的負債管理によりそうした必要性を減らすことができます。リスクの低減。ITおよびソフトウェアプロジェクトは本質的にリスクが高く、多くのプロジェクトが失敗します。機能しているシステムを技術的負債管理によって継続的に機能させ寿命を延ばすことは、組織にとってはるかにリスクの低い選択なのです。旅路への励まし著者は「技術的負債というドラゴンを飼いならす」ことが組織に大きな優位性をもたらすと結論づけています。そして読者への最後のメッセージとして「幸運」ではなく「勇気」を願っています。これは技術的負債との闘いが幸運頼みではなく、勇気を持って取り組むべき旅であることを示唆しています。技術的負債管理は単純な技術的解決や一時的な対策ではなく、組織の働き方、意思決定プロセス、評価システムにまで及ぶ包括的な変革です。それは困難な旅となりますが、組織の競争力、ソフトウェア資産の寿命、業務効率の向上に繋がる価値ある挑戦なのです。おわりにお疲れさまでした！長い旅路の末、ようやく技術的負債というドラゴンの本質が見えてきましたね。「単なる汚いコードでしょ？」と思っていた方は、それが実は「トレードオフの意思決定問題」「組織のシステム問題」「経済学的問題」そして「厄介な問題（wicked problem）」という複数の顔を持つ複雑な生き物だったことに気づかれたでしょう。私たちは皆、技術的負債という名の「マシュマロテスト」の前に立たされています。「今すぐひとつのマシュマロを食べるか、我慢して後で二つ食べるか」というあの有名な実験です。ソフトウェア開発の世界では「今すぐリリースして技術的負債を増やすか、時間をかけて正しく実装するか」という選択を迫られるわけです。もっとも、現実はそう単純ではありません。我慢して「正しく実装」したとしても、ビジネス要件の変更や技術の進化によって、約束の「二つ目のマシュマロ」が手に入らないこともあります。それでも、多くのプロジェクトは「締め切りが明日！」という時間の圧力の前に、リスクを考慮せずマシュマロを見るなり飛びつく3歳児のような選択をしがちです。「技術的負債を瞬時に返済できる魔法のボタン」を探し求めていた方には残念なお知らせがあります。最新のAI技術によってハードコードされた値の検出と修正は容易になりつつありますが、それでも技術的負債の全体を一瞬で解消するボタンはありません。チケットキューの山を一気に片付けるドラゴンボールでさえ、集めるのに時間と努力が必要なのです！あるのは地道なリファクタリングと品質管理という、継続的な改善活動だけです。でも、その「毎日続けること」こそが実は魔法なのかもしれません。無限病院 医院作者:韓 松早川書房Amazon最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。ドラゴンとの共存 - もうひとつのエピローグこの話の終わりに、もうひとつの物語を聞いてください。あれから3年が経ち、nwiizoの姿は大きく変わっていました。かつて彼を悩ませた「Cシステム」は、いまや彼が手なずけた技術的負債のドラゴンとなっていたのです。「どうしたんだ？また新機能の追加か？」nwiizoは画面の向こうのドラゴンに話しかけます。ドラゴンは小さく息を吐き、コード上に赤い警告を表示しました。「ありがとう、気づかなかった。この依存関係を追加したら循環参照になるところだった」nwiizoが最初にCシステムと対峙した日、彼はこのドラゴンを倒そうとしていました。「すべてを書き換えれば解決する」と、純粋すぎる情熱に燃えていたのです。しかし時間をかけて彼は大切な真実に気づきました。ドラゴンは倒すものではなく、共存するものだったのです。オフィスの壁には今、大きな「負債マップ」が掲げられています。技術的負債の「玉ねぎモデル」に基づき、技術層・トレードオフ層・システム層・経済学層・厄介な問題層という同心円が描かれています。チームメンバーはここに付箋を貼り、「高金利負債」には赤いマーカーで印をつけます。毎週金曜日の午後、彼らは「ドラゴンとのお茶会」と呼ばれるセッションを開きます。プロダクトオーナー、開発者、テスター、運用担当者が一堂に会し、今週作った負債と返済した負債について語り合うのです。「先週、納期を優先してユニットテストを省略したよね」とQAリードが言います。「うん、『ユリシーズ契約』に基づいて記録したよ。来週のスプリントで返済する約束をした」と開発者が答えます。nwiizoは微笑みながらこのやり取りを見ています。かつてはタブー視されていた「負債を作る決断」が、今は透明性を持って議論されているのです。彼の机の上には、「厄介な問題への挑み方」という本が開かれています。そこには彼の手書きのメモがあります。「技術的負債は複雑な問題だ。誰もが自分の視点から『解決策』を持っているが、誰も全体を見通せていない。重要なのは対話だ。異なる世界観を持つ人々が理解し合う場を作ること。」ある日、新入社員がnwiizoに尋ねました。「先輩、どうしてこんなに古いシステムを使っているんですか？最新のフレームワークで書き直せば、もっと効率的になると思いますが...」nwiizoはコーヒーを一口飲み、穏やかに答えました。「君はドラゴンを倒したいのかな？」新入社員は困惑した表情を浮かべます。「ドラゴンとは技術的負債のことだ。確かに彼は時に厄介で、時に怖い。でも実は私たちのプロジェクトの歴史そのものでもある。何年もの経験と学びが詰まった叡智だ。」nwiizoは立ち上がり、壁のチャートを指さしました。「見てごらん。私たちはすでに負債の70%を返済した。残りの30%は『低金利負債』か、あるいは返済コストが便益を上回る部分だ。完璧に負債ゼロのシステムを作ることが目標ではない。ビジネス価値を最大化しながら『管理可能な負債』を維持することが重要なんだ。」新入社員は考え込みます。「でも、いつか全部書き換える日は来るんですか？」「もちろん、その日は来るだろう。でも焦る必要はない。大切なのは毎日少しずつドラゴンと会話すること。負債を理解し、管理し、時には交渉することだ。それが本当の『ドラゴン使い』の仕事なんだよ。」その日の夕方、オフィスを出るnwiizoは、デスクの上のノートに次のスプリントの計画を書き残しました：「負債返済：20%、新機能：60%、実験：20%」ドラゴンは消えることはありませんでした。しかし今や、彼は恐れるべき敵ではなく、ともに歩むパートナーになっていたのです。時に手を焼かせるが、その炎は道を照らす光にもなる——そんな不思議な共存関係を築いたnwiizoの物語は、多くのエンジニアの心の支えとなったといいます。あなたのプロジェクトにも、きっとドラゴンは潜んでいるでしょう。それを倒そうとするのではなく、手なずけることを考えてみてはいかがでしょうか。最初の一歩は、ドラゴンの目を見て「こんにちは」と言うことから始まります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[StageCrewとは？マルチモーダルAIツールを触ってみた]]></title>
            <link>https://sreake.com/blog/research-multi-modal-tool-stagecrew/</link>
            <guid>https://sreake.com/blog/research-multi-modal-tool-stagecrew/</guid>
            <pubDate>Thu, 06 Mar 2025 11:13:20 GMT</pubDate>
            <content:encoded><![CDATA[StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLって定数を定義できるの?]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9</guid>
            <pubDate>Thu, 06 Mar 2025 10:53:04 GMT</pubDate>
            <content:encoded><![CDATA[whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...]]></content:encoded>
        </item>
    </channel>
</rss>