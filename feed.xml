<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 06 Mar 2025 22:34:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[StageCrewとは？マルチモーダルAIツールを触ってみた]]></title>
            <link>https://sreake.com/blog/research-multi-modal-tool-stagecrew/</link>
            <guid>https://sreake.com/blog/research-multi-modal-tool-stagecrew/</guid>
            <pubDate>Thu, 06 Mar 2025 11:13:20 GMT</pubDate>
            <content:encoded><![CDATA[StageCrew™️とは StageCrew™（https://stagecrew.ai/）は、システム監視やログ収集、トランザクションのトレースといった各種管理ツールに対するアクセスを自動化、インシデント発生時の対応 […]The post StageCrewとは？マルチモーダルAIツールを触ってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLって定数を定義できるの?]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/6d6bacc1a294b9</guid>
            <pubDate>Thu, 06 Mar 2025 10:53:04 GMT</pubDate>
            <content:encoded><![CDATA[whatLookMLで定数を定義する事ができるのか調べてみた個人ログ Q.LookMLって定数を定義できるの?A. できるLookMLも他のプログラミング言語と同じように定数を設定できる。 定数の定義とマニフェストファイル マニフェストファイルLookMLにおいて、定数はマニフェストファイルというファイルを作成することによって定義する事ができる。https://cloud.google.com/looker/docs/lookml-project-files?hl=ja#project_manifest_filesマニフェストファイルは、定数の定義以外にも...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[標準入出力テストを可視化するTUIツールの開発をした。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/04/160714</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/04/160714</guid>
            <pubDate>Tue, 04 Mar 2025 07:07:14 GMT</pubDate>
            <content:encoded><![CDATA[yamori demo gifはじめに「あー、もう！競プロでテストの為にSolverを分けるの、マジで面倒くさい！」これが私がYamoriを作ったきっかけです。正直に言いましょう。私は怠け者です。AtCoderで問題を解くたびに、問題ごとにSolverを分けて、いちいちmain.rsを書き換えて...という作業が本当に億劫でした。標準入力でサクッとテストできないものかと常々思っていたのです。「標準入力でサクッとテストできないかな」と思いながら、コピペして実行して、出力を目視で確認する日々。ある日、特に複雑な問題で間違えたとき、「あれ？どのテストケースで落ちたっけ？」と混乱し、絶望的な気分になりました。そんな「プログラマーの怠惰」から生まれたのがYamoriです。「ヤモリ」という名前は、元々YAMLでテスト定義を書こうと思ったからです。（まあ、実際には「山守」という意味で、テストが私のコードを守ってくれるという願いも込めていますが、カッコいい理由なんて後付けです）github.com「これでスッキリする！」という淡い期待競技プログラミングで使うRustのプログラムをテストするためだけに、Rustでテストツールを開発するという本末転倒な状況に、私は何の違和感も覚えませんでした。これぞ「釘を打つために、まず金槌を作るプログラマー」の鑑です。「単純な標準入出力のテストツールなんて、週末でサクッと作れるでしょ！」この甘い考えが、のちに何週間もの苦闘を招くとは思いもよりませんでした。ターミナルUIという沼「コマンドラインでテキスト出力するだけじゃつまらない。せっかくだから可視化もしたい！」この「せっかくだから」という言葉は、エンジニアの時間を無限に吸い取る魔法の呪文です。ratutuiというライブラリを見つけた瞬間、私は沼にハマりました。「タブがあって、色付きで、差分も表示できて、履歴も見れて...」気づけば、単純なテストツールのはずが、フルスクリーンのターミナルUIアプリケーションに進化していました。vim風のキーバインドを実装しながら「これ、競プロのテストに使うんだよね？」と自問自答する日々。言い訳のような機能たち最終的に、Yamoriには「競プロのテスト」という本来の目的を超えた様々な機能が実装されました：TOML/YAML形式のテスト定義（JSONじゃダメだったの？）履歴追跡機能（過去のテスト結果を見返す時間があるなら問題を解けよ）リリースモード切替（競プロでリリースビルド？本気？）カラフルな差分表示（赤と緑でお祭り気分）キーボードショートカット（vimmerの執着心）これらの機能を実装しながら、脳内では常に「ただテストするだけなのに...」というツッコミが再生され続けていました。しかし、完成したときの満足感は格別でした。最初のテストケースが緑色で「PASS」と表示されたとき、「こんなの作る時間があったら、もう10問解けてたな」と思いつつも、心のどこかでは「でも、これからはテストが楽になる！」という正当化が始まっていました。大切なものは ほしいものより先にきた結局のところ、Yamoriの開発は「標準入力でテストしたい」という単純な欲求から始まり、いつの間にか「立派なターミナルUIアプリ」へと成長しました。本当に必要だったのは単純なシェルスクリプトだったかもしれませんが、この回り道があったからこそ、Rustの理解も深まり、新しいライブラリにも触れられました。「効率的に競プロを解きたい」という目的からは大きく外れましたが、「プログラミングを楽しむ」という本質的な目的は達成できたのではないでしょうか。そして何より、次回のコンテストでテストケースを流し込むとき、「よっしゃYamori様様やな！」と密かに自己満足に浸れるのです。Yamoriを使ってみたいという変わり者の方は：cargo install yamoriで、この過剰なテストツールをインストールできます。あなたのターミナルをカラフルに彩るヤモリをぜひ体験してください！...そして私のように「本末転倒なツール開発」の罠に陥らないよう、ご注意を。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[技術的負債と立ち向かう前に知っておいてもいいこと]]></title>
            <link>https://sreake.com/blog/think-about-technical-debt/</link>
            <guid>https://sreake.com/blog/think-about-technical-debt/</guid>
            <pubDate>Mon, 03 Mar 2025 10:46:12 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは、nwiizoです。開発チームの会話の中で「これは技術的負債だから後で対処しよう」という言葉をよく耳にします。納期に追われるプロジェクトでは、この「後で」が永遠の「いつか」になりがちです。結果として多 […]The post 技術的負債と立ち向かう前に知っておいてもいいこと first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる]]></title>
            <link>https://sreake.com/blog/step-up-product-backlog-and-user-story-development/</link>
            <guid>https://sreake.com/blog/step-up-product-backlog-and-user-story-development/</guid>
            <pubDate>Mon, 03 Mar 2025 01:17:49 GMT</pubDate>
            <content:encoded><![CDATA[Sreake事業部アプリケーション開発チームの安本です。 現在、スクラムでアプリケーション開発の概念検証（Proof of Concept; PoC）を進めています。 本記事では、スクラム開発を行っているチーム向けに、私 […]The post ユーザーストーリーにこだわって、プロダクトバックログをスクラムチームが行う作業の唯一の情報源として成立させる first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[2025/02/28] #kubenews 今週のKubernetes + Cloud Native + その他ニュース]]></title>
            <link>https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228</link>
            <guid>https://zenn.dev/bells17/articles/k8s-cloud-native-and-other-20250228</guid>
            <pubDate>Fri, 28 Feb 2025 10:19:14 GMT</pubDate>
            <content:encoded><![CDATA[#kubenewsの2025年02月28日の回で話す、@bells17が最近気になったニュース記事をまとめたものです。自分が気になった今週のKubernetes + Cloud Native + その他なニュースをまるっとまとめておいて、その中から時間内に話せるものを話そうと思ってます。この記事自体はざっと読んで書いてるものが多いので、詳細はリンクとかで貼ってる記事の中を読んでもらった方が正確です。配信URL:https://www.youtube.com/live/e4qQt7sQ46Y 告知とかニュースっぽいもの コードを読んで理解するko buildhttps...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIエージェント元年@日本生成AIユーザ会]]></title>
            <link>https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui</link>
            <guid>https://speakerdeck.com/shukob/aiezientoyuan-nian-at-ri-ben-sheng-cheng-aiyuzahui</guid>
            <pubDate>Fri, 28 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/344332/2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。生成AIの概略を説明した後、AIエージェントの紹介をします。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimで使うCopilotのモデルをClaudeに変更する苦労話 - 技術ブログ未満の個人的体験談]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/27/184558</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/27/184558</guid>
            <pubDate>Thu, 27 Feb 2025 09:45:58 GMT</pubDate>
            <content:encoded><![CDATA[免責事項: この記事は個人的な発見と試行錯誤を記録したものであり、正式なドキュメントに基づく推奨設定ではありません。ここで紹介する方法を実際の環境に適用する際は、十分な検証と自己責任でお願いします。はじめにこんにちは、Neovimユーザーのnwiizoです。今回は、NeovimでCopilotを使う際にAIモデルをClaudeに変更しようとして遭遇した「ちょっとした冒険」について共有したいと思います。最近、mizchiさんの最高のブログを読んだ。zenn.devこの記事を読んで魂を揺さぶられた。だが、まだVSCodeには移行しない。Neovimを使い続けることを決意した。揺らいだ。しかし、Neovim環境でもCopilotのAIモデルを自由に変更できたほうが良いと思い、特にClaudeモデルを試してみることにした。やりたかったこと最近、GitHub Copilotが Claude-3.7-sonnetなどのAnthropicのモデルをサポートするようになり、コーディング支援にもっと高度なAIの力を借りたいと思いました。GitHubの公式ドキュメント「Copilot Chat の AI モデルを変更する」によると、Copilot ChatのデフォルトLLMを別のモデルに変更できるようになっています。私のNeovim環境ではyetone/avante.nvimを使用してCopilotとの対話を行っていたので、このプラグインの設定でモデルを変更しようとしました。syu-m-5151.hatenablog.com最初の試み（失敗）まず試したのは、avante.nvimの設定で直接モデルを指定する方法です：{    "yetone/avante.nvim",    event = "VeryLazy",    lazy = false,    version = false,    opts = {      provider = "copilot", -- copilotを使用      auto_suggestions_provider = "copilot",      copilot = {        endpoint = "https://api.githubcopilot.com",        model = "claude-3.7-sonnet", -- ここでClaudeモデルを指定        timeout = 30000,        temperature = 0,        max_tokens = 4096,      },      -- 以下省略...    },    -- 依存関係などの設定...}しかし、この設定を適用してもなぜか期待通りの動作をしませんでした。デバッグを試みましたが、avante.nvimの設定だけではモデルの変更がうまく反映されていないようでした。というかこのような設定はたぶんなくて⋯。解決策：CopilotChat.nvimの力を借りる調査を進めるうちに、面倒になってCopilotC-Nvim/CopilotChat.nvimというプラグインの設定も変更しようと思いました。このプラグインはCopilotのチャットインターフェースを提供するもので、モデル設定も直接サポートしています。試しに以下の設定を追加してみました：-- Copilotチャット用の設定{  "CopilotC-Nvim/CopilotChat.nvim",  event = { "VeryLazy" },  branch = "main",  dependencies = {    { "zbirenbaum/copilot.lua" },    { "nvim-lua/plenary.nvim" },  },  opts = {    model = "claude-3.7-sonnet", -- モデル名を指定    debug = true, -- デバッグを有効化  },}そして驚いたことに、この設定を追加した後、avante.nvim側でもClaudeモデルが使われるようになりました！どうやら、CopilotChat.nvimの設定がcopilot.luaの基本設定に影響を与え、それがavante.nvimにも「引きずられて」反映されたようです。【注意】これは技術ブログ未満の個人的な発見であり、正式なドキュメントに基づくものではありません。このような依存関係による予期せぬ影響は、本番環境では深刻な問題を引き起こす可能性があります。設定の影響範囲を十分理解せずに適用すれば、システム全体に致命的な影響を及ぼす可能性があることを肝に銘じてください。なぜこうなったのか？正確な理由は不明ですが、おそらく両方のプラグインが同じzbirenbaum/copilot.luaに依存しており、この共通の依存関係を通じて設定が共有されたのだと思われます。CopilotChat.nvimがより直接的にCopilot APIとの連携部分を制御しているため、そちらでの設定が優先されたのでしょう。教訓Neovimのプラグインエコシステムでは、依存関係の連鎖によって予想外の相互作用が発生することがあります。今回のケースでは幸いにも望んだ結果につながりましたが、これは完全に「技術ブログ未満」の個人的な発見に過ぎません。警告: このような依存関係の連鎖による予期せぬ相互作用は、本番環境では極めて危険です。プラグイン間の隠れた依存関係による設定の「引きずり」は、デバッグが困難な問題を引き起こし、最悪の場合、本番システムの停止や重大なセキュリティ問題につながる可能性があります。設定変更の影響範囲を完全に理解しないまま適用することは、言わば地雷原を歩くようなものであることを忘れないでください。他の方も同様の状況に遭遇した場合、両方のプラグインを併用する方法が一つの解決策になるかもしれません。最終的な設定結局、私の設定はavante.nvimとCopilotChat.nvimの両方を含む形になりました：-- avante.nvimの設定（一部省略）{    "yetone/avante.nvim",    -- 省略...    opts = {      provider = "copilot",      auto_suggestions_provider = "copilot",      copilot = {        endpoint = "https://api.githubcopilot.com",        model = "claude-3.7-sonnet",        -- 省略...      },    },    -- 省略...},-- CopilotChat.nvimの設定{  "CopilotC-Nvim/CopilotChat.nvim",  event = { "VeryLazy" },  branch = "main",  dependencies = {    { "zbirenbaum/copilot.lua" },    { "nvim-lua/plenary.nvim" },  },  opts = {    model = "claude-3.7-sonnet",    debug = true,  },},これでNeovimでのコーディング体験がClaudeの能力で強化され、より的確なコード提案や説明が得られるようになりました。Neovimの設定は時に「魔法」のように思えることもありますが、それも含めて楽しいハック体験の一部なのでしょう。注：この記事は2025年2月時点の情報に基づいています。Copilotの仕様やプラグインの動作は変更される可能性があります。参考リンクGitHub Copilot Chat の AI モデルを変更する方法yetone/avante.nvimCopilotC-Nvim/CopilotChat.nvimzbirenbaum/copilot.lua]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Model Armorによるプロンプトインジェクション対策]]></title>
            <link>https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/</link>
            <guid>https://sreake.com/blog/prompt-injection-protection-with-google-cloud-model-armor/</guid>
            <pubDate>Thu, 27 Feb 2025 02:14:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 昨年2024年は生成AIアプリケーションの開発が本格化し、RAG（Retrieval-Augmented Generation）が爆発的に流行した年でした。今年2025年はAIエージェントの年になると考えられて […]The post Google Cloud Model Armorによるプロンプトインジェクション対策 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代におけるMLOpsのTips]]></title>
            <link>https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips</link>
            <guid>https://speakerdeck.com/shukob/aishi-dai-niokerumlopsnotips</guid>
            <pubDate>Sat, 22 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://event.ospn.jp/osc2025-spring/session/2017030AI時代におけるMLOpsのTips 〜 MLOpsを加速させるOSS 〜オープンソースカンファレンス2025 Tokyo/SpringライトニングトークにてKubeflowの紹介などMLOpsの話をさせていただきました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIエージェント元年]]></title>
            <link>https://speakerdeck.com/shukob/aiezientoyuan-nian</link>
            <guid>https://speakerdeck.com/shukob/aiezientoyuan-nian</guid>
            <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/344292/2024年は生成AIが世の中に浸透した1年でしたが、2025年はAIエージェント元年と言われています。生成AIはチャットベースで受け身なものでしたが、AIエージェントは自律的にタスクを分解しこなすことができます。そのインパクトは計り知れません。生成AIの概略を説明した後、AIエージェントの紹介をします。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コンテナサプライチェーンセキュリティ]]></title>
            <link>https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei</link>
            <guid>https://speakerdeck.com/kyohmizu/kontenasapuraitiensekiyuritei</guid>
            <pubDate>Fri, 21 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[イベント登壇資料です。2025/02/21 #CNCJhttps://cncj-security.connpass.com/event/341812/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenClarityの裏側を知りたい]]></title>
            <link>https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8</link>
            <guid>https://speakerdeck.com/kojake_300/openclaritynoli-ce-wozhi-ritai-fe15f317-ff7b-4f9e-acd4-8d389e3ebed8</guid>
            <pubDate>Thu, 20 Feb 2025 05:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[🦀 Automating Rust Dependency Management - A Deep Dive into cargo-autodd]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/20/121157</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/20/121157</guid>
            <pubDate>Thu, 20 Feb 2025 03:11:57 GMT</pubDate>
            <content:encoded><![CDATA[📖 IntroductionWhen developing Rust projects, we frequently need to add new crates or remove unused ones. While Rust provides the cargo add command as a standard tool for managing dependencies from the command line:cargo add serde --features deriveHowever, cargo add requires manual execution and doesn't detect or remove unused dependencies. To further automate this dependency management process, I developed "cargo-autodd" 🚀.I developed "cargo-autodd", a CLI tool to automate dependency management in Rust. It analyzes use statements and extern crates to add required crates to Cargo.toml. Release planned this week with nvim support.https://t.co/ZNfOu4AxEd pic.twitter.com/Tsh0KzEiZV— nwiizo (@nwiizo) 2025年2月16日   🎯 What is cargo-autodd?cargo-autodd is a tool that automatically analyzes Rust source code to detect required dependencies and updates Cargo.toml accordingly.github.comKey features include:🔍 Analysis of use statements and extern crate declarations in source code🤖 Automatic detection of required crates⬆️ Addition of latest stable versions to Cargo.toml🗑️ Removal of unused crates⚡ Advanced analysis using rust-analyzer (optional)🛠️ Technical Details📊 Project Structure AnalysisThe analysis is centered around the DependencyManager struct, which has the following fields:struct DependencyManager {    project_root: PathBuf,  // Project root directory    cargo_toml: PathBuf,    // Path to Cargo.toml}🔄 Dependency Analysis ProcessThe analyze_dependencies method performs analysis in three stages:🚀 rust-analyzer Analysis (Priority)let output = Command::new("rust-analyzer")    .arg("analysis")    .arg("--workspace")    .current_dir(&self.project_root)    .output()?;📝 Regex Analysis (Fallback)let use_regex = Regex::new(r"use\s+([a-zA-Z_][a-zA-Z0-9_]*)(::|\s|;)")?;let extern_regex = Regex::new(r"extern\s+crate\s+([a-zA-Z_][a-zA-Z0-9_]*)")?;✅ Result Aggregation and VerificationRecords usage locations and feature flags for each detected crateExcludes standard library cratesEliminates duplicates📝 Cargo.toml Update MechanismThe update_cargo_toml method updates dependencies through the following steps:📖 Reading Current Dependencieslet content = fs::read_to_string(&self.cargo_toml)?;let mut doc = content.parse::<DocumentMut>()?;➕ Adding New Dependenciesfor (name, crate_ref) in crate_refs {    if !current_deps.contains(name) && !is_std_crate(name) {        self.add_dependency(&mut doc, crate_ref)?;    }}➖ Removing Unused DependenciesPreserves essential dependencies specified by is_essential_depfn is_essential_dep(name: &str) -> bool {    let essential_deps = [        "serde",        "tokio",        "anyhow",        "thiserror",        "async-trait",        "futures",    ];    essential_deps.contains(&name)}📈 Version Management DetailsVersion management is handled by the get_latest_version method with the following features:🌐 Fetching Latest Version from crates.io APIlet url = format!("https://crates.io/api/v1/crates/{}/versions", crate_name);🚫 Excluding Yanked Versionslet latest_version = response    .versions    .iter()    .find(|v| !v.yanked)?;🔢 Applying Semantic VersioningSpecifies only major and minor versionsAllows automatic patch version updatesOk(format!("^{}.{}.0", version.major, version.minor))📚 Best Practices and Usage Guidelines🔧 PreparationInstall rust-analyzer (recommended)Ensure project builds successfully🚀 Execution StepsRun cargo autodd in the project root directoryReview the changesPay special attention to version specificationsVerify dependency consistency with cargo check🔍 TroubleshootingFalls back to regex analysis if rust-analyzer is unavailableManually correct any falsely detected dependencies🔮 Future PlansFuture enhancements planned for cargo-autodd include:🔍 Enhanced AnalysisMacro expansion and dependency analysisMore accurate feature flag detectionConsideration of conditional compilation (cfg attributes)📦 Extended Dependency ManagementAutomatic management of dev-dependenciesEnhanced workspace supportAutomatic version conflict resolution💻 Improved Developer ExperienceEditor integration (e.g., VSCode extension)More detailed dependency graph visualizationCI automation options🎉 Conclusioncargo-autodd is a powerful tool for automating dependency management in Rust projects. Its strengths can be summarized in three key areas:⚡ Enhanced EfficiencyEliminates manual dependency management overheadMaintains project dependencies at latest necessary versionsImproves maintainability through automated version management🔒 Ensured SafetyAccurate dependency analysis using rust-analyzerProper handling of semantic versioningProtection of essential dependencies🎯 Improved Developer ExperienceSimple usage patternReduced maintenance time through automationClear visualization of project dependenciesThese features allow developers to focus more on essential coding tasks. As an open-source project, it continues to evolve through community feedback and contributions.cargo-autodd is expected to become an increasingly important tool as the Rust ecosystem matures. We hope it serves as an effective solution to the challenge of dependency management for many developers in the Rust community. 🚀日本語版:syu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rustの依存関係管理を自動化する - cargo-autoddの紹介]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/20/120339</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/20/120339</guid>
            <pubDate>Thu, 20 Feb 2025 03:03:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめにRustプロジェクトを開発していると、新しいクレートを追加したり不要なクレートを削除したりする作業は頻繁に発生します。現在、Rustにはcargo addというコマンドが標準で用意されており、コマンドラインから依存関係を追加することができます。cargo add serde --features deriveしかし、cargo addは手動での実行が必要で、また使用していない依存関係の検出や削除は行いません。この依存関係の管理をさらに自動化できないか？という思いから開発したのが「cargo-autodd」です。Rustで開発する際の面倒な依存関係管理を自動化するツール「cargo-autodd」を開発しました。ソースコード内のuse文やextern crate宣言を解析し、必要なクレートを自動でCargo.tomlに追加します。先ほど作ったのでバグや不具合があると思うのでPRお願いします。テストもない。https://t.co/ZNfOu4AxEd pic.twitter.com/RbQNyp0K8H— nwiizo (@nwiizo) 2025年2月16日   cargo-autoddとはcargo-autoddは、Rustのソースコードを解析して必要な依存関係を自動的に検出し、Cargo.tomlを更新するツールです。github.com主な特徴は以下の通りです：ソースコード内のuse文とextern crate宣言を解析必要なクレートを自動検出Cargo.tomlに最新の安定バージョンを追加未使用のクレートを削除rust-analyzerを活用した高度な解析（オプション）技術的な詳細プロジェクト構造の解析プロジェクトの解析はDependencyManager構造体を中心に行われます。この構造体は以下のようなフィールドを持ちます：struct DependencyManager {    project_root: PathBuf,  // プロジェクトのルートディレクトリ    cargo_toml: PathBuf,    // Cargo.tomlのパス}依存関係の解析プロセスanalyze_dependenciesメソッドは、以下の3段階で依存関係を解析します：rust-analyzerによる解析（優先）let output = Command::new("rust-analyzer")    .arg("analysis")    .arg("--workspace")    .current_dir(&self.project_root)    .output()?;正規表現による解析（フォールバック）let use_regex = Regex::new(r"use\s+([a-zA-Z_][a-zA-Z0-9_]*)(::|\s|;)")?;let extern_regex = Regex::new(r"extern\s+crate\s+([a-zA-Z_][a-zA-Z0-9_]*)")?;結果の集約と検証検出された各クレートに対して、使用箇所とフィーチャーフラグを記録標準ライブラリのクレートを除外重複を排除Cargo.tomlの更新メカニズムupdate_cargo_tomlメソッドは、以下の手順で依存関係を更新します：現在の依存関係の読み取りlet content = fs::read_to_string(&self.cargo_toml)?;let mut doc = content.parse::<DocumentMut>()?;新規依存関係の追加for (name, crate_ref) in crate_refs {    if !current_deps.contains(name) && !is_std_crate(name) {        self.add_dependency(&mut doc, crate_ref)?;    }}未使用依存関係の削除ただし、is_essential_depで指定された重要な依存関係は保持fn is_essential_dep(name: &str) -> bool {    let essential_deps = [        "serde",        "tokio",        "anyhow",        "thiserror",        "async-trait",        "futures",    ];    essential_deps.contains(&name)}バージョン管理の詳細バージョン管理はget_latest_versionメソッドで行われ、以下の特徴があります：crates.ioのAPIを使用した最新バージョンの取得let url = format!("https://crates.io/api/v1/crates/{}/versions", crate_name);Yank済みバージョンの除外let latest_version = response    .versions    .iter()    .find(|v| !v.yanked)?;セマンティックバージョニングの適用メジャーバージョンとマイナーバージョンのみを指定パッチバージョンは自動更新可能にOk(format!("^{}.{}.0", version.major, version.minor))ベストプラクティスと使用上の注意点事前準備rust-analyzerのインストール（推奨）プロジェクトのビルドが通っていることを確認実行手順プロジェクトのルートディレクトリでcargo autoddを実行変更内容を必ず確認特にバージョン指定に注意を払うcargo checkで依存関係の整合性を検証トラブルシューティングrust-analyzerが使用できない場合は正規表現による解析にフォールバック誤検出された依存関係は手動で修正今後の展望cargo-autoddの将来的な機能拡張として、以下を計画しています：解析機能の強化マクロの展開とその依存関係の解析より正確なフィーチャーフラグの自動検出条件付きコンパイル（cfg属性）の考慮依存関係管理の拡張開発依存関係（dev-dependencies）の自動管理ワークスペース対応の強化バージョン競合の自動解決開発者体験の向上エディターへの組み込み（VSCode拡張など）より詳細な依存関係グラフの可視化CIでの自動実行オプションまとめcargo-autoddは、Rustプロジェクトにおける依存関係管理の自動化を実現する強力なツールです。その特徴は以下の点にあります：効率性の向上手動での依存関係管理の煩わしさを解消プロジェクトの依存関係を常に最新かつ必要最小限に保持バージョン管理の自動化による保守性の向上安全性の確保rust-analyzerを活用した正確な依存関係の解析セマンティックバージョニングの適切な処理重要な依存関係の保護機能開発者体験の改善シンプルな使用方法自動化による作業時間の削減プロジェクトの依存関係の可視化これらの機能により、開発者はより本質的なコーディング作業に集中できるようになります。また、オープンソースプロジェクトとして公開されているため、コミュニティからのフィードバックや貢献を受け入れながら、さらなる機能改善を進めていく予定です。cargo-autoddは、Rustエコシステムの成熟に伴い、より重要なツールとなることが期待されます。依存関係管理の自動化という課題に対する一つの解決策として、多くの開発者の方々に活用していただければ幸いです。English Edition:syu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コードを読んで理解するko build]]></title>
            <link>https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build</link>
            <guid>https://speakerdeck.com/bells17/kotowodu-nteli-jie-suruko-build</guid>
            <pubDate>Wed, 19 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Jagu'e'r Cloud Native #17 ハイブリッド Meetup ~ 推しの CNCF プロジェクトを紹介するぜ LT ~ の登壇資料です。https://jaguer-cloud-native.connpass.com/event/342024/参考リンク・画像など引用元一覧https://ko.build/ https://github.com/ko-build/ko https://github.com/google/go-containerregistry https://github.com/sigstore/cosign https://github.com/opencontainers/image-spec https://github.com/cncf/sandbox/issues/17 https://github.com/ko-build/ko/issues/791 https://github.com/cncf/sandbox/issues/163 https://github.com/cncf/artwork/blob/main/projects/ko/stacked/color/ko-stacked-color.png https://github.com/cncf/artwork/blob/main/projects/ko/icon/color/ko-icon-color.png]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン]]></title>
            <link>https://sreake.com/blog/rank-among-top-contributors-to-cncf-projects-in-japan/</link>
            <guid>https://sreake.com/blog/rank-among-top-contributors-to-cncf-projects-in-japan/</guid>
            <pubDate>Tue, 18 Feb 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 CNCF（Cloud Native Computing Foundation）の公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア 早川大貴・長澤翼（以下早川・長澤）がCNCFプロジェクトでの貢献者TOP10にランクインしたことをお知らせします。The post CNCFの公式ブログ「Japan’s CNCF DevStats 2024」にて、スリーシェイク所属のエンジニア2名がCNCFプロジェクトでの貢献者TOP10にランクイン first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする]]></title>
            <link>https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/</link>
            <guid>https://sreake.com/blog/aws-sam-quick-deploy-with-github-actions/</guid>
            <pubDate>Sun, 16 Feb 2025 23:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは。スリーシェイクの小林です。 本日は AWS Serverless Application Model（以下、AWS SAM）と GitHub Actions を用いて サーバーレス API の作成からデプロイ […]The post AWS SAM と GitHub Actions で爆速でサーバーレス API をデプロイする first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[自分ばっかり大変と思ってるときは気をつけたほうがいい]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2025/02/16/140946</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2025/02/16/140946</guid>
            <pubDate>Sun, 16 Feb 2025 05:09:46 GMT</pubDate>
            <content:encoded><![CDATA[仕事をしていて数年ほどたつと自分はこんなに頑張ってるのに評価が低いと思うタイミングが来る。これは後々そんなことはなかったと気がつくものの、そのタイミングにいる間は不適当な評価を受けていると思いがちで、自尊心が肥大しがちである。自分ばっかり頑張っていると感じたときは、自分の仕事が本当に価値を生んでいるのかという観点に立ち返ったほうがいい。やらなくてもいい仕事に忙殺されていないか？ 楽してると思ってる人は本質的な仕事に集中しているのではないか？これはイシューからはじめよでいうところの犬の道に陥っている状態である。自分だけ大変と思っているときは、実際には価値を生み出していないにも限らず、仕事量によ達成感を成果と勘違いしていることが多い。自分ばっかり大変だ、となっているときは価値の低いことに時間を投入していないか見つめ直そうという自戒。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[runwasi の cgroup に関する Issue 調査]]></title>
            <link>https://zenn.dev/z63d/articles/48eb53ca4e8467</link>
            <guid>https://zenn.dev/z63d/articles/48eb53ca4e8467</guid>
            <pubDate>Fri, 14 Feb 2025 13:44:01 GMT</pubDate>
            <content:encoded><![CDATA[概要runwasi で cgroup に関する Issue があり、それについての調査の記録です。忘れないように。OCI Runtime ~ コンテナプロセス周りのデバッグのコツを少しつかめた。cgroup に関しても学ぶことが多かった。 runwasirunwasi は Kubernetes で Ｗasm を動かすための shim をつくるライブラリ & いくつかの Wasm runtime 用の shim です。runwasi については以前 Kubernetes Meetup Tokyo #68 KubeCon NA 2024 Recap で話した時の資料と...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nwiizo はなぜ同じPlatform Engineeringを語るのに、2つの異なる資料を作ったのか #devsumi #PFEM]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127</guid>
            <pubDate>Thu, 13 Feb 2025 22:11:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは、nwiizoです。2025年2月13日に2つのイベントで登壇する機会をいただきました。これは私が翻訳に関わった「Kubernetesで実践するPlatform Engineering」の発売を記念した販促登壇でしたが、原著者さんが書籍の内容自体について話をされると知っていたので、私はPlatform Engineeringという分野に関する自分なりの考えや経験を共有させていただく内容にしました。Kubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazon2つの異なるイベントでの発表同日に性質の異なる2つのイベントで話をさせていただきました。Developers Summitでは「インフラをつくるとはどういうことなのか、あるいはPlatform Engineeringについて」というタイトルで、幅広い技術者の方々に向けてPlatform Engineeringの基本的な考え方から実践的なアプローチまでをお話ししました。 speakerdeck.com一方、PFEM特別回では「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というテーマで、より専門的な視点からPlatform Engineeringの課題や可能性について話をしました。ただ、この回は資料作りや登壇などの疲れもピークに達していて、本来伝えたかったことと違う説明をしてしまった部分もあったように思います。 speakerdeck.com翻訳作業から得た気づき今回の発表の背景には、「Kubernetesで実践するPlatform Engineering」の翻訳作業があります。2025年2月19日に翔泳社から発売されるこの本は、"Platform Engineering on Kubernetes"の日本語翻訳版で、3-shake の同僚と一緒に取り組んだプロジェクトです。翻訳作業を通じて、Platform Engineeringの課題や可能性について考える機会を多く得ることができました。原著者のsalaboyさんのハンズオンや過去の発表資料、記事を読む中で、Platform Engineeringに対する彼の考え方を学ばせていただきました。実際に一緒に登壇する機会もいただき、私の拙い英会話力にも関わらず温かく接していただいたことも貴重な経験でした。登壇から学んだこと今回の登壇準備と実践を通じて、技術共有における重要な気づきがありました。最も重要だと感じたのは、聴衆のバックグラウンドに合わせて内容を適切に調整することです。Developers SummitとPFEM特別回では、参加者層が大きく異なりました。Developers Summitでは、DevOpsやPlatform Engineeringに詳しくない参加者が多く、日常的な開発における具体的な問題点から入り、それをPlatform Engineeringの文脈で捉え直すことで基礎的な理解を促しました。一方、PFEM特別回では参加者との間に共通認識があったため、より実践的な課題や技術的解決策について深く掘り下げることができました。この違いは技術資料の作成にも影響しました。資料作成では、「知的な発見」と「理解するためのコスト」のバランスが重要です。知的な発見とは「なるほど、そういう考え方があったのか」という新しい視点を得られる瞬間ですが、その発見に至るまでの説明が複雑すぎると理解へのコストが大きくなりすぎてしまいます。多くの技術プレゼンテーションでは既知の問題とその解決策を列挙することに終始しがちですが、それだけでは予想外の学びには至りません。予想外の学びこそが、聴衆の心に残る知的な発見として認知されやすいのです。ここで重要なのは、単に「よくある課題とその解決策」を並べるだけでなく、「明確には意識していなかったけれど、言われてみれば確かにそうだった」という新たな気づきを提供することです。例えば、日々の開発で感じている不便さを Platform Engineering の文脈で捉え直すことで、それが個人の問題ではなく構造的な課題だったと気づく瞬間を作り出せます。かといって基礎的な前提ばかりでは、聴衆にとって新しい気づきが得られません。Developers Summitでは基礎と新知見のバランスを重視し、PFEM特別回では基礎的な説明を最小限に抑え、より深い技術的な議論に時間を割きました。それ以外の「イライラ」「焦り」「困惑」といった感情は、むしろ読者の集中力を削ぎ、本質的な学びを妨げてしまう。技術資料は、共感と発見のポジティブな体験に徹するべきなのだ。確かに、高度な実装や複雑な概念を詰め込んだ資料を作ることは可能だ。しかし、そのような難解な内容は、読者の理解を遠ざけ、結果として伝えたい本質が埋もれてしまう。読者の多くがこのような否定的な感情を抱く資料は、作成者の自己満足に過ぎないと言えるでしょう。2025年ならではの発見として、Xのアルゴリズム変更により画像が優先表示されるようになった現在、印象に残るスライドを含めることが効果的です。複雑な概念を一枚の図で表現することで、SNS上での共有や議論が促進され、発表後もコミュニティでの対話が継続する可能性が高まります。また、Platform Engineeringという新しい分野では、技術コミュニティにおける「共通言語」の重要性も実感しました。Developers Summitではキーとなる概念を具体例と共に丁寧に説明し、PFEM特別回では既存の共通言語を活用してより専門的な議論を展開しました。知識を一方的に伝えるのではなく、参加者との対話を通じて互いに学び合える場を作ることを心がけ、翻訳者兼登壇者としての過剰な発言は控えました。この経験を通じて、技術を伝えることは単なる知識の転送ではなく、聴衆のコンテキストに寄り添いながら対話を生み出すプロセスだと実感しました。イベントの性質や参加者層によって求められる内容や深さが異なることを学び、今後もこの気づきを活かしながら効果的な技術共有を目指していきます。おわりに2つのイベントでの発表資料は異なる切り口で作成しましたが、どちらも力を入れて準備させていただきました。より詳細な内容についてはぜひ資料をご覧いただければと思います。また、完全版については機会があればお話させていただきたいと考えていますので、ご興味がありましたらぜひご依頼ください。最後に、この経験を通じて得られた知見を今後の活動にも活かしていきたいと考えています。ご清聴いただいた皆様、そして貴重な機会を提供してくださった関係者の皆様に心より感謝申し上げます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて]]></title>
            <link>https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite</link>
            <guid>https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite</guid>
            <pubDate>Thu, 13 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年02月13日 Developers Summit 2025 13-E-4 にて「インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて - Platform Engineeringの効果的な基盤構築のアプローチ」というタイトルで登壇します。同日にPFEM特別回 でも登壇するのですが資料頑張って作ったのでそっちも読んでください。完全版は機会があればお話するので依頼してください。イベント名:  Developers Summit 2025公式URL: https://event.shoeisha.jp/devsumi/20250213セッションURL: https://event.shoeisha.jp/devsumi/20250213/session/5546登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Platform Engineeringは自由のめまい ]]></title>
            <link>https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai</link>
            <guid>https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai</guid>
            <pubDate>Wed, 12 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年02月13日 Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回にて「Platform Engineeringは自由のめまい - 技術の選択における不確実性と向き合う」というタイトルで登壇します。同日にDevelopers Summit 2025 でも登壇したのですが資料頑張って作ったのでそっちも読んでください。イベント名: Kubernetesで実践するPlatform Engineering発売記念！ PFEM特別回公式URL: https://platformengineering.connpass.com/event/342670/登壇ブログ: https://syu-m-5151.hatenablog.com/entry/2025/02/14/071127]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimで始めるGitHub Copilot - copilot.lua による Language Server の設定方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/11/183337</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/11/183337</guid>
            <pubDate>Tue, 11 Feb 2025 09:33:37 GMT</pubDate>
            <content:encoded><![CDATA[github.blogこの設定は一時的なものであり、LSPのインストーラーが対応したらそちらで対応してください。github.comはじめに2025年2月10日、GitHubはCopilot Language Server SDKを公開しました。これは、エディタやIDEがLanguage Server Protocol（LSP）を通じてGitHub Copilotと連携できるものです。このリリースは、開発者がより柔軟にCopilotを利用できるようになる重要な一歩です。今までGitHub CopilotはVS Code、Visual Studio、JetBrains IDEs、Vim/Neovim、そして最近ではXcodeでも利用可能でしたが、これらのエディタすべてがCopilot Language Serverを使用して実装されていました。GitHubは開発者の選択肢を重視し、好みのエディタでCopilotを使用できるようにすることを目指しているみたいです。Copilotの進化NeovimでのCopilot利用は、以前はgithub/copilot.vimを通じて行われていました。このVimscriptベースのプラグインは、多くの開発者に利用されてきた公式の実装です。その後、Lua APIを活用したzbirenbaum/copilot.luaが登場しましたが、これも内部的にはcopilot.vimを通じてGitHub Copilotと通信を行っていました。このアーキテクチャでは、copilot.luaがNeovimのモダンなLua APIを活用した柔軟なインターフェースを提供し、バックエンドではcopilot.vimが実際のCopilotサービスとの通信を担当するという二層構造になっていました。そして今回のLanguage Server SDKの公開により、エディタとCopilotの連携方法が標準化され、直接Language Server Protocolを介してCopilotと通信できるようになりました。これにより、中間レイヤーが不要になり、より効率的で安定した実装が可能になりました。前提条件Neovim 0.8.0以上Node.js 18.x以上GitHubアカウント（Copilotのサブスクリプション）インストール手順1. Copilot Language Serverのインストールまず、Neovimの設定ディレクトリにCopilot用のディレクトリを作成し、Language Serverをインストールします。# Copilot用ディレクトリの作成mkdir -p ~/.config/nvim/copilot/# Language Serverのインストールnpm install @github/copilot-language-server -g --prefix ~/.config/nvim/copilot/# 実行権限の付与chmod +x ~/.config/nvim/copilot/bin/copilot-language-server2. Neovimプラグインのインストールlazy.nvimを使用している場合、以下の設定を~/.config/nvim/lua/plugins/copilot.luaに追加します。return {  "zbirenbaum/copilot.lua",  lazy = false,  priority = 1000,  config = function()    require("copilot").setup {      suggestion = { enabled = false },      panel = { enabled = false },      server_opts_overrides = {        trace = "verbose",        cmd = {          vim.fn.expand("~/.config/nvim/copilot/bin/copilot-language-server"),          "--stdio"        },        settings = {          advanced = {            listCount = 10,            inlineSuggestCount = 3,          },        },      },      filetypes = {        yaml = true,        markdown = true,        help = false,        gitcommit = true,        gitrebase = true,        hgcommit = false,        svn = false,        cvs = false,        ["."] = false,        ["*"] = true,      },    }  end,}3. 認証設定Neovimを起動後、以下のコマンドで認証を行います。:Copilot authブラウザが開き、GitHubアカウントでの認証が求められます。認証が完了すると、Copilotが使用可能になります。設定の説明設定の主要なポイントを解説します。この設定は私の設定ファイルなので自由に設定してください。suggestionとpanelenabled = false: デフォルトのサジェスト機能を無効化していますserver_opts_overridescmd: インストールしたLanguage Serverのパスと起動オプションを指定vim.fn.expand("~/.config/nvim/copilot/bin/copilot-language-server"): Language Serverの実行ファイルのパスを指定。vim.fn.expand()関数を使用して~をホームディレクトリに展開"--stdio": Language Serverが標準入出力（stdio）を使用してNeovimと通信することを指定するオプションsettings.advanced:   - settings.advanced:listCount: 候補の表示数（10個）inlineSuggestCount: インラインサジェストの数（3個）filetypes各ファイルタイプでのCopilotの有効/無効を設定["*"] = true: デフォルトですべてのファイルタイプで有効トラブルシューティングLanguage Serverが見つからない場合Error: Language server is not installed or not executableパスが正しいか確認実行権限が付与されているか確認chmod +xコマンドで実行権限を付与認証エラーの場合:Copilot authを再実行GitHubアカウントのサブスクリプション状態を確認まとめGitHub Copilot Language Server SDKの公開により、Neovimでより直接的にCopilotを利用できるようになりました。これまでのcopilot.vimを経由する方式から、直接Language Server Protocolを使用する方式への移行により、より効率的で保守性の高い実装が可能になりました。新しいSDKはnpmjs.comで公開されており、誰でも利用可能です。この変更により、エディタ開発者はより簡単にCopilotを統合でき、ユーザーはより安定した開発体験を得られるようになります。また、この方法は本来であれば不要でありlspconfigにコントリビューションすればよい()。github.com参考リンクGitHub Copilot Language Server SDK announcementCopilot.lua DocumentationLanguage Server Protocol SpecificationGitHub Copilot.vim]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[n週刊アトデ 2025-02-10]]></title>
            <link>https://blog.atusy.net/2025/02/10/atodeyomanakata/</link>
            <guid>https://blog.atusy.net/2025/02/10/atodeyomanakata/</guid>
            <pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[アトデヨム、ウソジャナイ、ヨムノタノシー]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[kubeadmでk8sクラスタを構築する]]></title>
            <link>https://zenn.dev/moz_sec/articles/k8s-by-kubeadm</link>
            <guid>https://zenn.dev/moz_sec/articles/k8s-by-kubeadm</guid>
            <pubDate>Fri, 07 Feb 2025 02:00:09 GMT</pubDate>
            <content:encoded><![CDATA[KubernetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ kubeadmkubeadmは、Kubernetesクラスタを構築するためのツールの１つです。他にも、kopsやkubesprayなどがありますが、kubeadmは最小限の構成でクラスタを構築することができます。https://kubernetes.io/...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GKEのComputeClassに関する調査]]></title>
            <link>https://sreake.com/blog/gke-computeclass/</link>
            <guid>https://sreake.com/blog/gke-computeclass/</guid>
            <pubDate>Fri, 07 Feb 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部で長期インターンをしている竜です。 本記事では、GKEのカスタムコンピューティングクラスについて調査を行いました。 カスタムコンピューティングクラスの概要 GKEのカスタムコンピューティングク […]The post GKEのComputeClassに関する調査 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes History Inspector(KHI)を触ってみた]]></title>
            <link>https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita</link>
            <guid>https://speakerdeck.com/bells17/kubernetes-history-inspector-khi-wohong-tutemita</guid>
            <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[スライド内の参考リンク・画像など引用元一覧https://zenn.dev/bells17/scraps/67c852e99ad5a5 https://github.com/GoogleCloudPlatform/khi https://zenn.dev/google_cloud_jp/articles/9a7dc0df5e8906 https://blog.g-gen.co.jp/entry/kubernetes-history-inspector-introduction https://x.com/kyasbal_k/status/1884500133183905976 https://x.com/ryusa_eng/status/1886328704432996463 https://x.com/kkuchima/status/1884503826029228189 https://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-history.pnghttps://github.com/GoogleCloudPlatform/khi/blob/main/docs/en/images/gettingstarted-views.png https://k8s-novice-jp.connpass.com/event/343899/ https://jaguer-cloud-native.connpass.com/event/342024/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[mini.testでNeovimプラグインのテストに入門した]]></title>
            <link>https://blog.atusy.net/2025/02/05/mini-test-nvim/</link>
            <guid>https://blog.atusy.net/2025/02/05/mini-test-nvim/</guid>
            <pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[以前書いた、Budouxを使ったWモーションをE/B/gEに対応させてプラグインにしようかなと思って、atusy/budouxify.nvimを作った。BudouxによりNeovimのWモーションを拡張し、日本語文章の区切りに移動させるhttps://blog.atusy.net/2024/12/27/nvim-budoux-motion/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[滅びゆく「なぜ？」と「どうして？」の学びをどう受け止めればよいのか？新人エンジニアの指導で感じる生成AI時代の指導の難しさ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/02/04/203205</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/02/04/203205</guid>
            <pubDate>Tue, 04 Feb 2025 11:32:05 GMT</pubDate>
            <content:encoded><![CDATA[anond.hatelabo.jpこの記事を読み、その内容は学生だけでなく、ソフトウェアエンジニアの教育にも適用できると考えました。以下、ソフトウェアエンジニア（以降、技術者と表記）の教育について、私見を述べさせていただきます。はじめに新人エンジニアや学生のOJTやハンズオン研修を担当する中で日々実感することがあります。生成AIの台頭により従来の指導方法が大きく揺らいでいるという現実です。特に、表面的な成果物の質と実際の理解度の乖離が、技術者教育における新たな課題として浮き彫りになってきています。この変化は、技術教育に関わる私たち全員に、新たな挑戦と機会をもたらしています。生成AIは確かに技術教育の在り方を根本から問い直すきっかけとなりましたが、それは同時に、より本質的な技術力の育成について考え直す機会でもあります。技術の進化に伴う変化は不可避ですが、その中で私たちにできることは、この変化を前向きに捉え、新しい時代にふさわしい技術教育の形を模索していくことではないでしょうか。このような問題意識のもと、本稿では2025年に向けた技術者教育の新しいアプローチについて考察していきます。変化する学習の風景これまでの技術習得プロセスには、ある種の必然性がありました。ライブラリの使い方で躓き、設計パターンの意図を理解できず悩み、そしてそれらを一つずつ克服していく。この過程で、指導者は学習者の理解度を正確に把握し、適切なサポートを提供することができました。しかし、生成AIの登場により、この学習の構図が大きく変容しています。ある日の出来事が、この変化を象徴的に表していました。新人エンジニアに依頼した簡単なAPIの実装が、驚くほど短期間で、かつ高品質なコードとして提出されたのです。しかし、コードレビューの場での会話は、次のような展開となりました。「このミドルウェアの実装パターンを選択した理由は？」「はい...Copilotが提案したものをそのまま採用しました」「例外処理の設計思想については？」「申し訳ありません。その部分はAIの出力そのままで...」更に印象的だったのは、実装中のトラブルシューティングでの出来事でした。学生がハンズオン研修で詰まっていたため、私がエラーメッセージを確認して原因を特定し、問題のファイルを開こうとした瞬間、そのファイルは既にCopilotによって修正されました。本来であれば、エラーの原因を一緒に探り、解決策を考えることで、貴重な学びの機会となるはずでした。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon理解を伴わない実装力技術者として、私自身も生成AIを積極的に活用しています。それは現代のソフトウェア開発において、もはや必須のスキルといえるでしょう。しかし、「理解を伴わない実装力」という新たな現象が、技術者教育に大きな課題を投げかけています。最近経験した出来事が、この課題を端的に表していました。新人エンジニアが実装したAPIは、一見すると申し分のない出来栄えでした。しかし、設計の意図を問うと「ChatGPTやCopilotの提案をそのまま採用した」という答えが返ってきます。エラーが発生した際も、その原因を一緒に探ろうとした矢先、Copilotが自動的に修正を施してしまう。こうした状況は、技術者としての本質的な成長機会を失わせる危険性をはらんでいます。具体的な例として、複雑なマイクロサービスアーキテクチャを構築できるのに、RESTful APIの基本原則が説明できない。網羅的なユニットテストを実装できるのに、テストピラミッドの考え方が理解できていない。Kubernetesのマニフェストが書けるのに、コンテナ化の利点を説明できない。このような状況が増えています。しかし、ここで注目すべきは「理解を伴わない実装力」にも異なるタイプが存在することです。生成AIに依存した実装を行うエンジニアと、知識はあるが実践との紐付けが発展途上のエンジニアです。前者は、高度なアーキテクチャのコードを書けるように見えても、その設計思想を説明できず、エラーが発生すると即座にAIに解決を委ねます。コードレビューでの「なぜ」という問いに対して、「AIが提案したから」や「はぁ？」という支離滅裂な回答に終始し、自身の実装に対する責任感や当事者意識が希薄です。一方後者は、デザインパターンやアーキテクチャの理論的理解はあるものの、それを実践に活かしきれていない段階にいます。しかし、レビューで指摘されると「あ、確かにそうですね」と納得し、エラーに直面しても自分なりの仮説を立てて解決を試みます。不完全でも自分の言葉で説明しようとする姿勢があり、試行錯誤を重ねながら、徐々に知識と実践を紐づけていっています。これまでの教育現場では、学習者の成長過程が自然と把握できていました。エラーメッセージと格闘し、設計パターンの意図を咀嚼し、少しずつ理解を深めていく。その過程で、「基礎概念は理解できている」「応用に課題がある」といった具合に、理解度の段階が明確だったのです。しかし今や、生成AIの支援により、理解度と実装力の相関が著しく弱まっています。特に前者のようなタイプの場合、表面的な成果物の品質だけでは、技術力を測ることが困難になっているのです。後者のような「知識はあるが実践が追いついていない」エンジニアの場合、時間とともに着実な成長が期待できますが、AIに依存した実装では、その成長機会自体が失われてしまう危険性があります。技術者教育の本質を見つめ直す私たちが目指すべきは、単なる「実装力」の向上ではありません。なぜその技術が必要とされるのか、どのような文脈で使用されるべきか、実装による影響をどう評価するか。そういった本質的な理解力を持つエンジニアの育成こそが重要です。「動くコード」を書けることは、技術者としての第一歩に過ぎません。技術力とは、技術選択の理由を説明できること、その技術がもたらす長期的な影響を予測できること、そしてプロジェクト全体における個々の実装の位置づけを理解できることです。これは単にコードを書けるということとは本質的に異なる能力です。syu-m-5151.hatenablog.comしかし、生成AIの存在は、この「理解のプロセス」を大きく変えつつあります。AIの出力を適切に編集することで「完成」にたどり着けてしまう現状は、技術習得における重要な学びの機会を奪っているかもしれません。エラーとの格闘、設計の試行錯誤、レビューでの指摘と修正—これらの経験は、表面的には非効率に見えても、実は技術者としての成長に不可欠なプロセスなのです。さらに重要なのは、技術の進化に対する適応力です。特定の実装パターンやツールの使い方を覚えることよりも、新しい技術が登場した際にその本質を理解し、適切に評価できる力を養うことが重要です。この適応力は、深い理解と経験に裏打ちされた「考える力」からしか生まれません。syu-m-5151.hatenablog.comこれからの技術者教育2025年に向けたエンジニア育成の新しいアプローチ1. 生成AIとの対話力を含めた包括的な技術教育カリキュラムの構築生成AIを効果的に活用するスキルそのものを技術教育の重要な要素として位置づける必要があります。AIへの適切なプロンプト作成能力はもはやエンジニアの基礎スキルとして不可欠です。しかし、ここで重要なのは単にAIに答えを求めることではありません。具体的には、AIに実装方針を提案させる際も、その根拠となる設計原則や参考文献を確認し、実装の背景にある理論や概念について理解を深めていく必要があります。さらに、特定の実装パターンのメリット・デメリットを比較検討させることで、技術選択の判断力を養うことができます。また、エラーが発生した際は、その原因と対処法についての理解を深めるための質問を重ねることで、問題解決力を育てていきます。つまり、AIを「答えを得るためのツール」ではなく、「理解を深めるための対話相手」として活用する姿勢が求められます。生成AIとの対話を通じて、技術の本質的な理解を深める習慣を身につけることが重要です。また、AIが出力したコードやドキュメントを適切に評価・検証する力も重要な要素となっています。プロンプトエンジニアリングの技術に加えて、AIと人間それぞれの得意分野を理解し、適切な役割分担ができる判断力が必要です。特に、AIの出力を鵜呑みにせず、常に批判的に検証し、その背景にある原理原則を理解しようとする姿勢を育むことが重要です。2. 実装スキルから設計思考力へのフォーカスシフトコーディングスキルの習得以上に、システム設計の原則や思想を理解することが重要になってきています。実装の詳細は生成AIに任せられる時代だからこそ、私たちはより本質的な設計思考力の育成に注力すべきです。システム設計において重要なのは、ビジネス要件を技術要件に適切に変換する力です。スケーラビリティ、可用性、保守性といった非機能要件をどのように満たすのか。開発効率と運用コストのバランスをどう取るのか。こうしたトレードオフを適切に判断し、プロジェクト全体の成功に導く力が、これからのエンジニアには求められます。個々の実装の詳細は生成AIにある程度任せられる一方で、システム全体を俯瞰する力は2025年においては人間にしか培えない能力なのです。この力を育むためには、実際のプロジェクトの中で判断が必要な場面に直面させ、その経験を積ませることが効果的です。例えば、新しい機能追加の要件を受けた際に、既存システムへの影響範囲を分析させたり、将来の拡張性を考慮した設計を検討させたりすることで、システム全体を見渡す視点を養うことができます。3. プロセスと思考を重視した評価方法への転換技術者の評価においても、成果物の完成度だけでなく、そこに至るまでの思考プロセスを重視する必要があります。なぜその設計を選択したのか、どのような代替案を検討したのか、想定されるリスクにどう対処するのか。こうした意思決定の過程とその根拠を、自分の言葉で説明できる力が極めて重要です。特に注目すべきは、長期的な視点での判断力です。目の前の実装だけでなく、その選択が将来的なシステムの保守性や拡張性にどのような影響を与えるのか。技術負債との向き合い方や、チーム全体での知識共有の方法など、持続可能な開発を実現するための視点も評価の重要な要素となります。この文脈で懸念されるのが、表面的な成果や「スムーズな進捗」を演出しようとする風潮です。これは特定の層に限った問題ではなく、現代の開発環境が生み出す構造的な課題といえます。重要なのは、そうした見せかけの生産性を求めない組織文化の醸成です。真摯な試行錯誤やチャレンジを認め、失敗から学ぶことを奨励する環境づくりこそが、本質的な技術力の向上につながります。結局のところ、私たちが目指すべきは、表面的な実装の速さや完成度ではなく、持続可能な開発を実現するための思考力と判断力を備えたエンジニアの育成なのです。そのためには、短期的な成果だけでなく、プロセスの質を重視する評価体系への転換が不可欠です。これは単なる評価方法の変更ではなく、組織全体で取り組むべき文化的な転換といえるでしょう。おわりに生成AI時代における技術者教育は、まさに過渡期にあります。単純な「できる/できない」の二元論では測れない、技術力をどう育成し、評価していくのか。これは私たち指導者自身にとっても、大きな学びの機会となっています。この課題に対する明確な解答は、業界全体としてもまだ模索段階にあります。しかし、技術教育の在り方を根本から見直し、新しい時代に適応した指導方法を確立していく必要性は明らかです。エンジニアの評価や育成に関する従来の常識は、生成AIの台頭により大きく揺らいでいます。多くの組織や教育機関が同様の課題に直面している中、重要なのは個々の取り組みや知見を共有し、業界全体として解決策を模索していく姿勢です。エンジニア育成は組織の壁を超えた共通の課題であり、オープンな対話と試行錯誤を通じてこそ、新しい時代にふさわしい技術教育の形が見えてくるのではないでしょうか。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform使いがOpenTofuについて入門してみる]]></title>
            <link>https://blog.masasuzu.net/entry/2025/02/04/185305</link>
            <guid>https://blog.masasuzu.net/entry/2025/02/04/185305</guid>
            <pubDate>Tue, 04 Feb 2025 09:53:05 GMT</pubDate>
            <content:encoded><![CDATA[この記事はSRETT #11で発表されたものに加筆修正したものです。OpenTofuに関して調べたこととなります。3-shake SRE Tech Talk #11 オンサイト - connpass speakerdeck.com先日KubeCon + CloudNativeCon North America 2024に行ってきてました。その中で共同開催されていたOpenTofu Dayを見てOpenTofuに関して興味を持ちました。普段はTerraformを利用しており、あまりOpenTofuについては触ってきてないので、この機会に深堀りをしてみたいと思いました。参考: OpenTofu Dayまた、社内活動として技術検証を行っており、私の検証テーマとしてTerraformを中心としたIaC周りの技術調査を行ってるので、ちょうどいい機会だとも思いました。おことわりOpenTofuとはライセンス問題HashiCorp社の言い分コミュニティの懸念OpenTofuとTerraformの違いコマンドファイルRegistryremovedブロックState Encryptionbackendブロックの変数参照バージョン管理Security checkLinterCI/CDまとめ参考リンクライセンス変更フォークソースコード問題OpenTofuを使うためにHachiCorp買収おことわりこの記事はTerraformを知っている前提で書かれています。そのため細かい説明を省略している箇所があります。また筆者は普段はTerraformをメインで使用しており、OpenTofuを業務利用はしていません。OpenTofuとは2023年8月にTerraformを含めたHashiCorp製品のライセンスの変更を発表したことにより、これを懸念した企業やコミュニティによりOpenTFとしてフォークされます。その後OpenTFの名称はHashiCorp社の商標権への懸念からOpenTofuに改名されます。そのときの議論はissueを見るとたどることができます。参考: https://github.com/opentofu/opentofu/issues/2962023年9月にLinux Foundation傘下となります。参考: Linux Foundation Launches OpenTofu: A New Open Source Alternative to TerraformTerraformをフォークしたものなので基本的な使い勝手は同じです。コマンド名が terraform から  tofu に差し替えられています。ライセンス問題前項でさらっとライセンス変更と言いましたが、HashiCorp社は2023年8月に今後のリリースに関してライセンスを変更する旨を発表しました。これはオープンソースライセンスであるMozilla Public License（MPL） v2.0から商用サービスでの利用を制限するBusiness Source License（BUSLあるいはBSL） v1.1に変更するものです。参考: HashiCorp adopts Business Source Licenseこれに対して、利用企業およびコミュニティが懸念を示し、OpenTofuをフォークしたという流れになります。HashiCorp社の言い分従来BSLは本番使用(production use)が制限されます。ただし、ライセンスのParameterとして追加使用許可(Additional Use Grant)をすることによりTerraformと「競合製品」でなければ本番利用の制限はないとしてます。参考: https://github.com/hashicorp/terraform/blob/v1.11/LICENSE「競合製品」とは、有料サポート契約を含む第三者に販売される製品で、HashiCorp のライセンス対象製品の有料版の機能と大幅に重複する製品を指します。TerraformでいうところのHCP Terraform(Terraform Cloud)を想定しているのかと思います。また組織内でTerraformをホストして利用することは「競合製品」とはみなされなません。そのため利用者としては基本的には問題なく利用できるとしてます。参考: HashiCorp Licensing FAQ問題となるのはTerraformの機能を有償で提供しているSaaSと読み取れます。コミュニティの懸念HashiCorp社が説明したBSLと追加使用許可はあいまいであるとしてます。そのため、自身の行動が許諾範囲内か判断が困難である。「競合製品」の定義やライセンス自体が今後変更されるか不確実であると懸念を示してます。また、TerraformはOSSの恩恵を受けて成長してきてため、これからもオープンソースソフトウェアであるべきだと信じていると表明しています。参考: OpenTofu FAQOpenTofuのスポンサー企業としては以下のとおりです。HarnessGruntworkSpaceliftenv0ScalrHarnessはCI/CDまわりのSaaS製品、Gruntworksはterragruntの開発元、Specelift、env0、ScalrはTerraformをホストするSaaSサービスを運営しています。OpenTofuとTerraformの違いこの項ではそれぞれの違いについて説明していきます。OpenTofuはTerraform1.6-alphaからフォークされているのでそれまでに実装されていたものは互換があります。また、Terraform 1.6以降に追加された機能に関しても随時取り込まれています。そのため、1.5までの機能を使っているのであれば素直に移行できるかとは思います。バージョンごとに移行ガイドがあるので細かくはそれを参照すると良いです。参考: https://opentofu.org/docs/intro/migration/ただし、別のコードベースで開発がされているので、OpenTofuのみの独自実装もあります。ここではいくつか個人的に気になる違いについてあげていきます。コマンド基本的には terraform を tofuに置き換えていただければよいです。サブコマンドは一緒です。# Terraformterraform initterraform planterraform applyterraform destroy# OpenTofutofu inittofu plantofu applytofu destroyファイルterraform由来の .tf または .tofu の拡張子のファイルを設定ファイルとして認識します。json形式の .tf.json または .tofu.json の拡張子のファイルも同様です。同じディレクトリ内に.tf と .tofu の両方のファイルがあった場合、.tofu ファイルだけ認識して、.tf ファイルは無視されます。foo.tf  # <=== このファイルは無視されるfoo.tofuRegistryTerraform同様OpenTofuにもプロバイダーやモジュールのレジストリがあります。Terraform: https://registry.terraform.io/OpenTofu: https://registry.opentofu.orgOpenTofu Registryが登場したときに存在したTerraform Providerは反映されています。反映されていないものに関してもissueを立てれば反映されるようですhttps://github.com/opentofu/registryremovedブロックremovedブロックは既存のリソースを削除することなく、stateから削除することができます。それぞれ下記のように記述できます。下記の例ではAWSインスタンス自体は削除せず、stateから外すことを意図してます。# Terraformremoved {  from = aws_instance.example  lifecycle {    destroy = false  }}# OpenTofuremoved {  from = aws_instance.example}Terraformではlifecyleブロックでdestroy=falseの記述が必須です。参考: https://developer.hashicorp.com/terraform/language/resources/syntax#removing-resourcesOpenTofuではremovedブロックを書くだけで stateから削除されます。参考: https://opentofu.org/docs/language/resources/syntax/#removing-resourcesremovedブロックでやりたいことはstateから削除することなので、単純にリソースを削除したいなら対象resouceブロックを削除すればいいので、Terraformの記述方法のほうがへんな気がします。State EncryptionTerraformでは平文でStateに保存されてしまうという問題がありましたが、OpenTofuではクライアントサイドで暗号化する機能が追加されてます。クラウドプロバイダーの KMSキーなどを利用してStateを暗号化することができます。参考: State and Plan Encryption | OpenTofuTerraformではたとえsopsプロバイダーで機密情報を暗号化しても、Stateファイルには平文で保存されているので権限があれば機密情報が見えてしまう状態にありました。State自体が暗号化されることにより機密情報をよりセキュアに扱えるようになります。参考: Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか - 目の前に僕らの道があるbackendブロックの変数参照OpenTofuではbackendブロックで変数参照ができます参考: https://opentofu.org/docs/language/settings/backends/configuration/#variables-and-localsvariable "env" {  type    = string}locals {  path = "${var.env}/terraform.tfstate"}terraform {  backend "local" {    path = local.path  }}tofu init -var="env=dev" -reconfiguretofu plan -var="env=dev"Terraformで同じことをしたい場合、-backend-configを渡さないといけないため、backendを切り替える際に不便となります。terraform init -backend-config=./envs/dev/terraform.backend -reconfigureterraform plan -vars-file=./envs/dev/terraform.tfvarsOpenTofu DayのLTで紹介されてた環境名だけを渡して挙動を切り替えるパターンが現状だとterraformでは使えません参考:On Best Practices with OpenTofu Structuringバージョン管理複数プロジェクトでTerraform or OpenTofuを使う場合、プロジェクトごとに使用バージョンを管理する必要があります。いくつか選択肢を見ていきます。Terraformのバージョン管理ツールとしてよく使われるtfenvはOpenTofuには対応しません。参考:https://github.com/tfutils/tfenv/issues/409代わりにTerraformとOpenTofuに対応したtenvができました。こちらを利用すると良さそうです。https://github.com/tofuutils/tenv私はTerraformも合わせてプロジェクト内のツールのバージョン管理をまとめてasdfでやってますが、こちらは対応しています。https://github.com/virtualroot/asdf-opentofu自分はあまり使わないのですが、同じようなツールのaquaやmiseも両対応しています。https://aquaproj.github.io/https://github.com/jdx/miseSecurity checkTerraformだとtfsec(現 trivy config)がセキュリティチェックとして使われてるかと思います。ディスカッションはされており優先順位をつけて対応するとのことです。参考: https://github.com/aquasecurity/trivy/discussions/5069LintertflintはOpenTofuをサポートしないようです。参考: https://github.com/terraform-linters/tflint/issues/2037Linterの議論自体はissueで続いているようです。参考: https://github.com/opentofu/opentofu/issues/2213CI/CDHCP Terraform(旧Terraform Cloud)に相当するSaaSとしては、OpenTofuスポンサーのSpacelift、env0、Scalrなどがあります。tfactions、atlantis、diggerもOpenTofuに対応している模様です。まとめ現時点でOpenTofuに移行するするべきか?の問については、利用者側として現状では引き続き様子見かと思います。足回りも概ね揃ってきているが、まだ足りないエコシステムもあります。気になるところではIBM社にHashiCorp社の買収による統合完了の様子も追っていきたいところです。予定では2025年の1-3月期に統合完了するとのことなので、その後なにか動きがあるかもしれません。参考: IBM社によるHashiCorp社買収についてとはいえ、1つのツールが使えなくなることで業務が止まるのは避けたいので常に選択肢は複数取っておきたいところです。エンジニアとしてはOpenTofuに限らず、Pulumi、CDK(AWS)なども選択肢として取っておきたいです。それはそれとして、OpenTofuはTerraformとは違う独自進化をしているので、変更を追っていきたいところです。個人的にはState暗号化とかBackendの変数参照とかTerraformに入ってほしいです。それでは良い豆腐ライフを!、、、。ここまで書いてきたのですが、minamijoyoさんのTerraform職人のためのOpenTofu再入門2024がものすごく詳しいので、この記事以上に参考になるかと思います。参考リンクライセンス変更HashiCorp adopts Business Source LicenseHashiCorp | The Infrastructure Cloud CompanyHashiCorp、全製品のライセンスを商用利用に制限があるBSLライセンスに変更すると発表 － PublickeyTerraformのライセンスの変更とその影響何故、TerraformのBUSL-1.1へのライセンス変更は反発を受けたのか？ – Shuji SadoTerraform のライセンス変更についての考察 #Azure - QiitaフォークTerraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名 － Publickeyソースコード問題【Infostand海外ITトピックス】ライセンスをめぐって対立　HashiCorpと「Terraform」派生のOpenTofu - クラウド WatchHashiCorp、TerraformをフォークしたOpenTofuに対しコードの不正コピーを警告。OpenTofuは完全否定 － PublickeyOpenTofuを使うためにTerraform職人のためのOpenTofu再入門2024 #Terraform - QiitaTerraform職人のためのOpenTofu入門 #Terraform - QiitaOpenTofuopentofu/opentofu: OpenTofu lets you declaratively manage your cloud infrastructure.Migrating to OpenTofu 1.7.x from Terraform | OpenTofuHachiCorp買収IBMがHashiCorpを64億ドルで買収、TerraformとAnsibleのシナジー効果などを見込む | IT LeadersIBM Japan Newsroom - ニュースリリースIBM社によるHashiCorp社買収について]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施]]></title>
            <link>https://sreake.com/blog/developers-summit-2025/</link>
            <guid>https://sreake.com/blog/developers-summit-2025/</guid>
            <pubDate>Tue, 04 Feb 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年2月13日（木）・14日（金）に開催される「Developers Summit 2025」にSRE総合支援サービス「Sreake（スリーク）」のブースを出展します。The post スリーシェイク、「Developers Summit 2025」にて出展・登壇、および書籍「Kubernetesで実践するPlatform Engineering」の先行販売・サイン会を実施 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
    </channel>
</rss>