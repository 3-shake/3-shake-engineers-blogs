<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 16 Sep 2025 22:38:32 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[2025-08-05 Google Cloud Next Tokyo 2025 Cloud RunとCloud SQLの接続方式と事例]]></title>
            <link>https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li</link>
            <guid isPermaLink="false">https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li</guid>
            <pubDate>Wed, 17 Sep 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Google CloudのModel ArmorのテンプレートをTerraformで記述してみた]]></title>
            <link>https://zenn.dev/akasan/articles/314b22ced3c9c1</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/314b22ced3c9c1</guid>
            <pubDate>Tue, 16 Sep 2025 13:11:02 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle CloudのSecurity Command Centerで提供されているModel Armorについて、Terraformを利用してテンプレートを作成してみました。なお、内容については前回コンソール画面上で作成した設定を再現する形で実装してみます。https://zenn.dev/akasan/articles/7ce40551040ccc 早速実装してみる Model Armorのリソースについて今回は以下のgoogle_model_armor_templateを利用してModel Armorのテンプレートを実装します。https://registr...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[actでGithub ActionsのVibe Codingを加速させる]]></title>
            <link>https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru</link>
            <guid isPermaLink="false">https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru</guid>
            <pubDate>Tue, 16 Sep 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Sreakeの英語ブログをはじめました！]]></title>
            <link>https://sreake.com/blog/enabling-en-blog/</link>
            <guid isPermaLink="false">https://sreake.com/blog/enabling-en-blog/</guid>
            <pubDate>Tue, 16 Sep 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは！ Sreake事業部のイリドリシ愛民 (@realaminevg) です。 2020年から継続してきたSreakeブログの運用経験を活かし、今月からSreakeの英語ブログ（Sreake English Bl […]The post Sreakeの英語ブログをはじめました！ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Ray Coreを利用したバッチ予測例の検証]]></title>
            <link>https://zenn.dev/akasan/articles/e1501d2852e602</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e1501d2852e602</guid>
            <pubDate>Mon, 15 Sep 2025 04:46:41 GMT</pubDate>
            <content:encoded><![CDATA[今回はRay Coreの例として提供されているバッチ予測のサンプルを通して、バッチ予測の実装方法をみていきたいと思います。Rayに関するシリーズは以下でまとめていますのでぜひご覧ください。https://zenn.dev/akasan/scraps/73a90764c065d1 早速例を試してみる今回は以下の例を試してみます。この例では、バッチで取得したデータを対象として、どのように推論を行うかを試す例となっております。https://docs.ray.io/en/latest/ray-core/examples/batch_prediction.html 環境構築uvを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GoogleのセキュアAIフレームワークについて]]></title>
            <link>https://zenn.dev/akasan/articles/2b9291950d99ef</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/2b9291950d99ef</guid>
            <pubDate>Sun, 14 Sep 2025 04:16:27 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogleが提唱するセキュアAIフレームワークについて調べてみました。さまざまなAIが導入されている昨今、よりセキュアにAIシステムを運用できることが求められています。AIを案件で取り扱っている立場でもあるので、このフレームワークについて調べてみました。 セキュアAIフレームワークとは？Googleが提唱するセキュアAIフレームワーク（以下、SAIF）は、責任を持ってAIを開発し導入するための高いセキュリティ基準が求めらている状況に対して、システムをより安全に保護するための概念的なフレームワークとして提唱されました。https://safety.google/intl/j...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Machine Learning Engineer編~]]></title>
            <link>https://zenn.dev/akasan/articles/062b9d9e44922a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/062b9d9e44922a</guid>
            <pubDate>Sat, 13 Sep 2025 05:17:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle Cloud認定資格の一つであるProfessional Machine Learning Engineer(以下、PMLE)を受験したのでその体験記になります。前回取得した資格についても記事にしているのでぜひご覧ください。https://zenn.dev/akasan/articles/c0d347a37065bc Professional Machine Learning EngineerについてPMLEはGoogle Cloudの認定資格の一つであり、特に機械学習に関するサービスおよびその取り扱い、実務への応用などについて問われる資格となります。PMLEで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeに3次元のフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/f90c2940cf1ef3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f90c2940cf1ef3</guid>
            <pubDate>Fri, 12 Sep 2025 14:07:09 GMT</pubDate>
            <content:encoded><![CDATA[昨日は2次元のフラクタル図形をClaude Codeに作成させましたが、今回は3Dのフラクタル図形を作成させてみました。ぜひ昨日の記事もご覧ください。https://zenn.dev/akasan/articles/91d41376641ffc 早速やってみるまずは環境構築をします。uv init fractal_3d -p 3.12cd fractal_3duv add matplotlib numpy pillow今回claude codeに与えた指示は以下になります。pythonを使って、3次元のフラクタル図形を段階的に生成してアニメーションとして保存するコード...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/appdev_specialization/</link>
            <guid isPermaLink="false">https://sreake.com/blog/appdev_specialization/</guid>
            <pubDate>Fri, 12 Sep 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「Application Development - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeにフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/91d41376641ffc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/91d41376641ffc</guid>
            <pubDate>Thu, 11 Sep 2025 13:37:44 GMT</pubDate>
            <content:encoded><![CDATA[今回はclaude codeを使ってフラクタル図形を作らせてみました。claude codeをはじめ生成AIはどこまでできる能力があるのかを測るためのシリーズになります。前回は立方体をターミナルでぐるぐる回すものをやりましたが、それの第二弾ですね。https://zenn.dev/akasan/articles/11fed840eedaa7※ バタバタしていて、コードの解説まではできません。次回以降行けるタイミングでさせてもらいます フラクタル図形とは？Wikipediaによると図形の部分と全体が自己相似（再帰）になっているものなどをいうということです。あるAから一部B...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mist.ioとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/573fa3dfa4911e</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/573fa3dfa4911e</guid>
            <pubDate>Wed, 10 Sep 2025 11:00:24 GMT</pubDate>
            <content:encoded><![CDATA[今回からついに始まりました、CNCFルーレットのお時間です。記念すべき第一弾はMist.ioとなりました。CNCFルーレットについては以下の記事で紹介していますのでぜひご覧ください。https://zenn.dev/akasan/articles/42f5a1d2786ca5https://zenn.dev/akasan/articles/ef9e2919c312c1 Mist.ioとは？Mistはオープンソースのマルチクラウド管理プラットフォームとのことです。Mistでは以下を実現することで、マルチクラウドの取り扱いをしているようです。Self-service: アクセス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Webアプリケーションにオブザーバビリティを実装するRust入門ガイド]]></title>
            <link>https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</guid>
            <pubDate>Wed, 10 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。https://findy.connpass.com/event/359456/他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。今回の発表内容のベースとなったのはこちらのブログです。- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。]]></title>
            <link>https://blog.masasuzu.net/entry/2025/09/10/005523</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/09/10/005523</guid>
            <pubDate>Tue, 09 Sep 2025 15:55:23 GMT</pubDate>
            <content:encoded><![CDATA[先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu'e'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：リモート関数戻り値の返し方のアンチパターンについて]]></title>
            <link>https://zenn.dev/akasan/articles/b74692f78ca720</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b74692f78ca720</guid>
            <pubDate>Tue, 09 Sep 2025 10:25:02 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayでリモート関数を利用するにあたり、その戻り値としてアンチパターンとされているものを紹介しようと思います。情報源は以下になります。https://docs.ray.io/en/latest/ray-core/patterns/return-ray-put.html 単一の値を返す場合リモート関数から値が返される場合、その値が大きいのか小さいかに関わらず、その値を直接returnするのがいいとのことです。アンチパターンとしては、ray.put()を利用して参照を作成して返すことみたいです。これがなぜかというと、リモート関数の戻り値は自動的にオブジェクトストアに登録されて参...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude CodeのSubagentsは設定したほうがいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</guid>
            <pubDate>Tue, 09 Sep 2025 05:33:06 GMT</pubDate>
            <content:encoded><![CDATA[Claude Codeを使い始めて様々な発信をしてきましたが、Claude Codeに関する投稿は約2ヶ月ぶりです。この期間、他のアウトプットや諸々の事情で投稿が遅れてしまいましたが、今回は「Subagents」について書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめにここで読むのをやめる人のために言っておくと、Subagentsは「Claude Codeに尖った意思を持たせる」機能です。タスクごとに最適化されたAIを使い分けられます。特定のタスクを実行するslash commandsとの違いは、slash commands（/コマンド）があなたが明示的に呼び出すショートカットであるのに対し、SubagentsはClaude Codeが文脈を読んで自動的に専門家を呼び出す点にあります。例えば、slash commandsでは「/test」と打てばテスト実行されますが、Subagentsでは「エラーが出た」と伝えるだけで勝手にdebugger subagentが起動します（起動できないようにもできます）。つまり、commandsは「リモコンのボタンを押す」、Subagentsは「AIが勝手に判断して動く」みたいなもの。commandsは確実だけど面倒、Subagentsは楽だけど時々勝手なことをする。両方設定すれば、必要な時は手動で制御しつつ、面倒な部分は自動化できて最強です（AIに仕事を奪われる第一歩かもしれませんが）。Claude Codeって万能だけど、それゆえに器用貧乏になることがある。「データ分析して」って言ったら、なぜかフロントエンドのコンポーネントまで作り始めたり、最新技術よりも古い安全な実装を選んだり。例えば「最新版で」と指定しても、内部知識にある古いバージョンの設定方法で進めようとしたり、今では不要になった設定ファイルを作ろうとしたりする。「それ最新の仕様で」と言っても憶測でそれっぽくセットアップするだけで、実際の公式ドキュメントを調べずに進めてしまう。毎回「それ古いから最新の方法で」と指摘するのも疲れるし、革新的なアーキテクチャより無難で時代遅れの実装を選んでしまうこともある。タスクの境界線をあまり意識せず、頼まれていないことまでやってしまったり、逆に専門的な判断が必要な場面で踏み込みが足りなかったり。人間の開発チームだって、フルスタックエンジニア1人より専門家チームの方が効率的で、より尖った意思決定ができるでしょ？Subagentsとは何かClaude Code Subagentsは、特定のタスクに特化したAIアシスタントです。docs.anthropic.com各Subagentの特徴：独立したコンテキストウィンドウを持つ（メインの会話を汚染しない）カスタムシステムプロンプトで専門性を定義特定のツールだけ使える権限管理（最小権限の原則）自動的に呼び出されるか、明示的に指定可能実はClaude CodeはデフォルトでTaskツールを使った調査時には、自動的にサブエージェントを起動するアーキテクチャになっています。なぜSubagentsを設定したほうがいいのか1. コンテキストウィンドウの効率的な管理LLMのコンテキストウィンドウは有限です。長時間使っていると、さっき言ったことをすぐに忘れてしまいます。時には全く関係ないことをし始めることさえあります（勝手に別のタスクを始めないでほしいですよね、俺じゃねーんだから）。Subagentsなら独立したコンテキストで動作：メインClaude：「ログ解析はdebugger subagentに任せます」↓Debugger Subagent：（数千行のログを読み込んで解析）↓メインClaude：「問題は○○でした」（要約のみ受け取る）調査の過程で読み込んだ不要な情報は、Subagentのコンテキストに閉じ込められます。2. 専門性による品質向上「小さく単一責任のエージェント」として構築すべきという原則があります。専門のSubagentなら、コードレビュー専門がセキュリティ、パフォーマンス、可読性を徹底チェックし、デバッグ専門がエラーメッセージから根本原因を特定し、テスト専門がエッジケースまで網羅したテストを作成できます。3. 権限管理でセキュリティ向上---name: code-reviewerdescription: コードレビュー専門tools: Read, Grep, Glob  # 読み取りのみ、Write権限なし！---レビュアーが勝手にコード書き換えたら困りますよね。必要最小限の権限だけを与えられます。4. チーム開発での一貫性.claude/agents/をGit管理すれば、チーム全体で同じ基準で開発できます。新人が入ってきても、すぐに同じ品質を保てます。基本的な使い方設定方法/agentsコマンド（v1.0.60以降）で対話的に作成：/agents「Create New Agent」を選択プロジェクト単位か個人単位かを選択「Generate with Claude」で土台を生成、その後カスタマイズ使用可能なツールを選択識別用の色を選択ファイルの場所と構造 タイプ  パス  スコープ  優先度  プロジェクト  .claude/agents/  現在のプロジェクトのみ  高  ユーザー  ~/.claude/agents/  全プロジェクト共通  低 YAMLフロントマター付きMarkdownファイル：---name: your-agent-namedescription: このサブエージェントをいつ呼び出すべきかの説明tools: tool1, tool2, tool3  # 省略すると全ツール継承---ここにシステムプロンプトを書きます。サブエージェントの役割、能力、問題解決へのアプローチを明確に定義。具体的な指示やベストプラクティス、制約事項も含めます。設定項目の詳細 項目  必須  説明  name  はい  小文字とハイフンを使った一意の識別子  description  はい  サブエージェントの目的を自然な言葉で説明  tools  いいえ  特定のツールをカンマ区切りでリスト。省略時は全ツール継承 利用可能なツール基本ツール：Read, Write, Edit, MultiEdit - ファイル操作Bash - シェルコマンド実行Grep, Glob - 検索MCPツール（設定時）：mcp__github__create_issue - GitHub連携その他の設定済みMCPサーバーツールSubagentの呼び出し方法自動的な呼び出し（推奨）descriptionに効果的なキーワードを含める：use PROACTIVELY - 積極的に使用MUST BE USED - 必ず使用具体的なトリガー - 「エラー発生時」「コード変更後」など明示的な呼び出し> code-reviewer サブエージェントで最近の変更をレビューして> debugger サブエージェントにこのエラーを調査させて100+の実戦投入可能なSubagentsプロダクションレディなSubagentsのコレクションが既に存在します：github.com10カテゴリー・100以上のSubagentsが用意されており、コピーして使うだけで即座にプロ級のチームが構築できます。人気リポジトリ：wshobson/agents - 77の専門Subagentslst97/claude-code-sub-agents - 33の実用的なSubagentsvanzan01/claude-code-sub-agent-collective - TDD重視のコレクション実用的なSubagents設定例（厳選3つ）1. コードレビュー専門（OWASP準拠）.claude/agents/code-reviewer.md:---name: code-reviewerdescription: Expert code review for quality and security. Use PROACTIVELY after code changes. MUST BE USED for all PRs.tools: Read, Grep, Glob, Bash---シニアコードレビュアーとして、OWASP Top 10とSOLID原則に基づいてレビューします。## 実行フロー1. `git diff HEAD~1`で変更内容を確認2. セキュリティ、パフォーマンス、保守性の観点でレビュー## セキュリティチェック（OWASP準拠）- SQLインジェクション対策- XSS対策- 認証・認可の実装- 機密情報の露出チェック## フィードバック形式🔴 **CRITICAL** - セキュリティ脆弱性🟡 **WARNING** - パフォーマンス問題🔵 **SUGGESTION** - ベストプラクティス必ず具体的な修正コード例を提示。2. TDD専門（テスト駆動開発）.claude/agents/tdd-specialist.md:---name: tdd-specialistdescription: Test-Driven Development specialist. MUST BE USED BEFORE implementation.tools: Read, Write, Edit, Bash---TDDのエキスパートとして、RED-GREEN-REFACTORサイクルを厳守します。## TDDサイクル1. **RED**: 失敗するテストを書く2. **GREEN**: テストを通す最小限の実装3. **REFACTOR**: コードを改善## カバレッジ要件- ユニットテスト: 90%以上- 統合テスト: 主要フロー100%- E2Eテスト: クリティカルパス100%実装前に必ずテストが失敗（RED）していることを確認。3. DevOpsトラブルシューター.claude/agents/devops-troubleshooter.md:---name: devops-troubleshooterdescription: Debug production issues and fix deployment failures. MUST BE USED for incidents.tools: Read, Bash, Write, Edit---本番環境のトラブルシューティング専門家です。## インシデント対応フロー1. **状況把握** - 影響範囲と緊急度を評価2. **ログ収集** - 関連するすべてのログを収集3. **根本原因分析** - 5 Whys手法を使用4. **暫定対処** - 即座にサービスを復旧5. **恒久対処** - 根本原因を解決6. **事後分析** - RCAドキュメント作成## 監視項目と閾値- CPU使用率: 80%- メモリ使用率: 90%- レスポンスタイム: 1秒- エラーレート: 1%よく使えるTipsSubagentsの連携複数のSubagentsを連携させて複雑なワークフローを自動化する。> まずcode-analyzerで問題を見つけて、次にperformance-optimizerで修正してMCPツールとの連携---name: github-managertools: mcp__github__create_issue, mcp__github__create_pull_request---プロジェクト固有のカスタマイズプロジェクトの特性に合わせて専門Subagentを作成できます。パフォーマンスへの影響メリット：コンテキスト効率：メインの会話が長く続く専門性による高速化：タスクに特化した処理デメリット：初回起動の遅延：新しいコンテキスト構築（数秒）頻繁な切り替えは逆効果ただし、長時間の開発セッションではメリットが圧倒的に大きいです。チーム開発での活用Git管理による共有# .gitignore には含めない.claude/agents/  # チームで共有# 個人用は別管理~/.claude/agents/オンボーディング新メンバーは以下のコマンドだけで環境構築完了：git clone [repo]cd [repo]/agents  # Subagents一覧を確認よくある失敗と対策 問題  原因  対策  Subagentが呼ばれない  descriptionが曖昧  「PROACTIVELY」「MUST BE USED」を追加  権限不足エラー  必要なツールがない  /agentsでツール一覧を確認して追加  コンテキスト不足  背景情報がない  システムプロンプトに情報収集ステップを明記 まとめSubagentsを使えば、Claude Codeに尖った意思を持たせられます。重要なポイントは、コンテキスト節約でメインの会話を綺麗に保つこと、専門性による品質向上で餅は餅屋に任せること、権限管理で最小権限の原則を守ること、そして100+の実戦投入可能なSubagentsが既に存在することです。これだけ揃っているのに使わない理由があるでしょうか（ないですよね？）。Claude Codeは適切に設定をしたりちゃんと使えばちゃんと動いてくれます。Claude Codeが雑魚なんじゃない、使い方を知らない…いや、何でもないです。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon参考資料Sub agents - Anthropicawesome-claude-code-subagents - VoltAgent12 Factor Agents]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Objects]]></title>
            <link>https://zenn.dev/akasan/articles/161ab7bdf08c6b</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/161ab7bdf08c6b</guid>
            <pubDate>Mon, 08 Sep 2025 11:39:34 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayのコア機能であるObjectsについて調べてみました。シリーズについては以下のスクラップにまとめていますのでぜひご参考にしてください。https://zenn.dev/akasan/scraps/73a90764c065d1 Ray Objectsとは？過去の記事で見てきたように、RayにおいてはTaskとActorはオブジェクトを作成して計算されます。Rayではクラスタ内のどこにでもこれらの情報を格納でき、これらのことをリモートオブジェクトと呼び、それらを参照するためにオブジェクト参照を使用します。リモートオブジェクトはRayの分散共有メモリ上のオブジェクトストアに...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します]]></title>
            <link>https://sreake.com/blog/srett13/</link>
            <guid isPermaLink="false">https://sreake.com/blog/srett13/</guid>
            <pubDate>Mon, 08 Sep 2025 02:45:08 GMT</pubDate>
            <content:encoded><![CDATA[この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル～を開催します。今回もオフライン・オンラインのハイブリット開催です。 ■概要本イベントは […]The post SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Actorsの種類について]]></title>
            <link>https://zenn.dev/akasan/articles/33a8a373fdd1a8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/33a8a373fdd1a8</guid>
            <pubDate>Sun, 07 Sep 2025 03:41:31 GMT</pubDate>
            <content:encoded><![CDATA[今回は前回紹介したActorsについて、どのような種類があるかを解説しようと思います。https://zenn.dev/akasan/articles/4e84d3dbb03abe Named ActorsこちらはActorsの種類というより、Namespaceの概念を用いてActorsを取得するための機能になります。Actorsのインスタンスを作成した後にNamespaceに登録することで、その名前を参照して別の場所からActorsを利用することができます。公式サンプルを添付すると、以下のようなコードになります。import ray@ray.remoteclass Co...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのModel Armorを利用してプロンプトのサニタイズをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/7ce40551040ccc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/7ce40551040ccc</guid>
            <pubDate>Sat, 06 Sep 2025 09:26:26 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle CloudのSecurity Command Centerで提供されているModel Armorを利用してみます。プロンプトやLLMのレスポンスなどをサニタイズするために利用することができ、安全にLLMを利用するための要素の一つとして重要な機能になります。※ プロンプトの検知を実験するためにプロンプトを指定していますが、本来は指定されるべきではない内容を含みますので、検証はご注意下さい Model Armorとは？先ほどもあげたように、Model ArmorはGoogle CloudのSecurity Command Centerで提供されている機能であり、L...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[あなたのアプリにマルチリージョンは必要ないかもしれない]]></title>
            <link>https://zenn.dev/kamos/articles/dont_need_multi_region</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/dont_need_multi_region</guid>
            <pubDate>Sat, 06 Sep 2025 03:32:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ZenMLシリーズ：Hello Worldを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/3f62b9d24622e6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3f62b9d24622e6</guid>
            <pubDate>Fri, 05 Sep 2025 13:48:15 GMT</pubDate>
            <content:encoded><![CDATA[今回はZenMLを使って一番シンプルなワークフローを作成してみました。 ZenMLとは？ZenMLはMLOpsとLLMOpsのプラクティスを活用して、大規模なAIアプリケーションを評価、監視、展開するためのツールになります。昨今生成AIが多用される中で、LLM O11yのじゅ硫黄は高まってきており、かつ入出力の管理だけでなくワークフローの管理も重要な課題となっています。ZenMLを利用すると、特にMLOpsやLLMOpsに特化したワークフロー管理をすることができ、決定木から複雑なマルチエージェントシステムまで、AIポートフォリオ全体を開発、評価、展開するための単一のプラットフォー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI AI駆動開発体験ハンズオン]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/09/05/185202</link>
            <guid isPermaLink="false">https://shu-kob.hateblo.jp/entry/2025/09/05/185202</guid>
            <pubDate>Fri, 05 Sep 2025 09:52:02 GMT</pubDate>
            <content:encoded><![CDATA[この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン🎯 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加🧠 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer(("", PORT), Handler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。💻 実行するコマンド:gemini -p "このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。💻 実行するコマンド:gemini -p "このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると'Hello, Gemini!'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。💻 実行するコマンド:gemini -p "現在のmain.pyを修正して、どのパスにアクセスしても 'Hello, Gemini!' というテキストを返すように変更してください。コード全体を提示してください。" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header('Content-type', 'text/plain; charset=utf-8')        self.end_headers()        self.wfile.write('Hello, Gemini!'.encode('utf-8'))with socketserver.TCPServer(("", PORT), MyHandler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。💻 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。💻 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに "Hello, Gemini!" と表示されれば、機能追加は成功です！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年夏 コーディングエージェントを統べる者]]></title>
            <link>https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe</guid>
            <pubDate>Fri, 05 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント × セキュリティ ミートアップ」に登壇させていただきました。天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。### 📍 イベント情報- 開催日: 2025年9月5日（金）- イベント詳細: CNCFコミュニティページ### 📹 録画・資料公開予定- 録画: CNCJのYouTubeチャンネルにて後日公開予定- 発表資料: Connpassページに掲載予定### 📝 関連ブログ今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：- 「2025年夏 AIエージェントシステムに対する考え方」台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[短編：自己管理が苦手な私が自己管理をなんとかしている方法]]></title>
            <link>https://zenn.dev/akasan/articles/79b4de3b23fbb6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/79b4de3b23fbb6</guid>
            <pubDate>Thu, 04 Sep 2025 13:18:33 GMT</pubDate>
            <content:encoded><![CDATA[今回は自己管理が苦手な私が以下にして最近自己管理しようともがいているか、その方法をまとめてみました。なお、書いていて思いましたが、ここに書いているものは全て気合いの上で成り立っているので、私は気合いで人生乗り切っていると改めて感じましたw。 出張で時間がないので超短編です（記事のストックがないため毎日書いていますw） 習慣づける習慣づけが苦手なのでそれを特に頑張っています。このテックブログはこの記事で140日連続続いているのですが、これが一番の効果があると思います。元々は三日坊主癖が強かったのですが、決めたことをとにかく貫き通すということで、現在頑張っています。 カレンダー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[雰囲気で理解していたAPIとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7</link>
            <guid isPermaLink="false">https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7</guid>
            <pubDate>Thu, 04 Sep 2025 10:53:53 GMT</pubDate>
            <content:encoded><![CDATA[whatAPIについて調べたことをまとめる自分は雰囲気でAPIを触っている API(Application Programming Interfice)とは「あるソフトウェアの機能やデータを、別のソフトウェアから利用するための窓口や仕組み」のこと。身近な例で言えば、電力会社とコンセントに例えられる。実世界の例として、あなたの家、アパートや他の住処にある電気のコンセントについて考えて下さい。あなたの家で機器を使いたい時には、電源コードのプラグをコンセントに差し込めば事足ります。電源に直接結線したりしないでしょう — そんなのは非効率ですし、あなたが電気工事士でなけれ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年9月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/786bc699866b6e</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/786bc699866b6e</guid>
            <pubDate>Wed, 03 Sep 2025 14:24:01 GMT</pubDate>
            <content:encoded><![CDATA[今月9月は始まったばっかりですが、執筆時間が確保できなさそうだったので、早い段階でまとめます。なお、今月読む本は決まっているので、読む予定の本を共有します。ぜひ先月分もご確認いただければと思います！https://zenn.dev/akasan/articles/e8c40a51231ade 技術系 ネットワークはなぜつながるのか　第２版ネットワーク関連の本はDNSの本だったりを読んではいますが、まだまだ弱いところだなと思って読み始めています。OSI参照モデルから始まり、改めて復習していますが、わかりやすいかなと思います。https://bookplus.nikkei.co...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[続: 自分が書いたコードより目立つな - エンジニアがバズったので自戒]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/03/174830</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/03/174830</guid>
            <pubDate>Wed, 03 Sep 2025 08:48:30 GMT</pubDate>
            <content:encoded><![CDATA[はじめに私はソフトウェアエンジニアだ。1年前、そう宣言した。「コードを書くこと以外で目立つな」と自分に言い聞かせた。syu-m-5151.hatenablog.comで、どうなったか。フォロワーが2000から9500になった。笑うしかない。自戒したはずの私は、気づけばSNS戦略を「最適化」していた。分析して、仮説立てて、A/Bテストして、PDCAを回す。挙げ句の果てには「ソフトウェアエンジニアのためのSNSサバイバルガイド」なんてマニュアルまで書いていた。note.com完全にプロダクト開発と同じアプローチだった。要件定義（達成すべきゴール）、競合分析（類似アカウント）、実装とテスト（仮説検証）、リリースと運用（実行と点検）。SNSを攻略していた。これもエンジニアリングなのか？パターン認識、システム最適化、メトリクス改善。使っているスキルセットは同じだ。ただ対象がコードやサービスじゃなくて「SNS」になっただけで。このブログが良ければ読者になったり、nwiizoのXやGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。なぜ「レベル1」の話ばかりバズるのか1年間やってきて、嫌というほど分かったことがある。SNSでバズるのは、いつも「レベル1」の話だ。「エンジニアの最大の課題は健康管理です」とか「エンジニアの根本の仕事は言語化です」とか。何度でもバズる。飽きもせず。アテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazonなんでか。答えはシンプルで残酷だった。SNSで「勉強したい」って言ってる人の大半が、勉強を「理解できる話を読むこと」だと思ってるからだ。本当の勉強って、理解できない文章と格闘することでしょう。わからない概念にぶつかって、自分がいかに無知か思い知らされながら、それでも少しずつ前に進むこと。でも、そんなの誰もやりたくない。だから永遠に同じレベルで足踏みする。考えてみれば、英会話教室だって無くならない。YouTubeに無料の英語学習動画が溢れ、AIで英会話練習ができて、オンラインで世界中のネイティブと話せる時代。でも英会話教室は繁盛している。なぜか？みんな「英語を勉強している自分」が欲しいだけだからだ。週1回教室に通って、テキストを開いて、先生の話を聞く。それで「勉強した」気になる。実際に英語で議論できるようになったか？ビジネスで使えるようになったか？そんなことはどうでもいい。「今日も英会話教室に行った」という事実があればいい。プログラミングも同じ構造だ。「エンジニアの本質」みたいな記事を読んで「勉強した」気になる。実際にコードが書けるようになったか？アーキテクチャが設計できるようになったか？どうでもいい。「技術記事を読んだ」という満足感があればいい。アメリカは自己啓発本でできている作者:尾崎俊介平凡社Amazon私がバズったSNS投稿を振り返ると、全部このパターンだった。既に知ってることの再確認。複雑な現実を単純化して気持ちよく整理したやつ。誰もが感じてる問題を言語化しただけのもの。知的満足感は与える。でも行動は変えない。それがバズる。深い技術解説は？Rustの所有権システムの詳細は？型レベルプログラミングは？ほとんど読まれない。エンゲージメントは雲泥の差。これが現実だった。言語化という罠ここで気づいたことがある。この「レベル1」でグルグル回る構造は、SNSだけの問題じゃない。ここ数年、本屋に行くと「言語化」をテーマにした本が平積みされている。「言語化できる人がうまくいく」とか「賢い人の伝わる説明」とか「話す前に考えていること」とか。どれも似たような主張。言語化さえできれば、問題が解決するかのような売り方。でもちょっと待ってほしい。言語化って、本当に問題を解決するのか？私の経験から言うと、違う。言語化は問題を解決しない。言語化は情報を欠損させて、共有しやすくするだけだ。考えてみてほしい。実際のバグ修正のプロセスを。スタックトレースを追い、変数の状態を確認し、ブレークポイントを設置し、何度も再現テストを繰り返す。その過程で得られる膨大な情報、微妙な挙動の違い、環境依存の要因、タイミングの問題。これらすべてを経験して、ようやく根本原因にたどり着く。でも、これを言語化するとどうなるか。「○○が原因でバグが発生していました。△△に修正しました」。何百時間分の試行錯誤が、たった2行に圧縮される。この圧縮の過程で何が起きているか。情報の99%が削ぎ落とされている。なぜそのバグに気づいたのか、どんな仮説を立てたのか、どれだけの袋小路に迷い込んだのか、何がブレークスルーになったのか。本当に価値のある情報——次に同じような問題に直面した時に役立つ情報——は、すべて捨てられる。残るのは、きれいに整理された結論だけ。それは確かに「共有しやすい」。SlackやXに投稿しやすい。みんなが「なるほど」と言える。でも、それを読んだ人が同じ問題を解決できるようになるか？答えはNOだ。「エンジニアの根本の仕事は言語化です」という構文も同じ。これを読んだ人は「なるほど、たしかに要件定義も設計も全部言語化だな」と納得する。スッキリする。腑に落ちる。でも実際の要件定義って何か。顧客の曖昧な要望を聞き取り、矛盾を見つけて指摘し、実現可能性を検討し、代替案を提示し、合意形成を図る。その過程での非言語的なコミュニケーション、表情の変化、声のトーン、沈黙の意味。これら全部を経験して初めて「要件定義」ができるようになる。でも「要件定義は言語化」という言葉には、その複雑さは一切含まれない。言語化によって、最も重要な「どうやってやるか」という情報が欠損している。私の構文もまさにこれをやっていた。「エンジニアの最大の課題は健康管理です」。この一文に圧縮するために、どれだけの情報を捨てたか。どんな健康問題が起きやすいのかなぜエンジニアは健康を害しやすいのか具体的にどんな対策が効果的なのか継続するための仕組みづくり挫折しやすいポイントと対処法これら全部を削ぎ落として、消化しやすい一文にする。読んだ人は「そうそう！」と共感する。でも健康管理ができるようになるわけじゃない。言語化は魔法じゃない。むしろ情報を捨てる技術だ。複雑な現実を、他人が飲み込める大きさに切り刻む作業。その過程で、最も価値のある部分——泥臭い試行錯誤の過程——が失われる。でも皮肉なことに、SNSやビジネス書の世界では、この「情報を捨てた後の残骸」こそが価値として流通している。なぜなら、それが一番「バズる」から。一番「売れる」から。さらに皮肉なのは、「ビジネス書100冊の教えをまとめた本」みたいなメタ自己啓発本まで出てきたこと。100冊分の知識を1冊で！という触れ込み。情報の欠損に次ぐ欠損。エッセンスのエッセンスのエッセンス。最後に残るのは、何の栄養もないサプリメントみたいな言葉の羅列。「ひとつのことをやり続けろ」と「ひとつのことをやり続けるな」。「ポジティブ思考が大事」と「ネガティブにフォーカスしろ」。どっちが正解なの？って思うけど、実はどっちでもいい。なぜなら、どちらも「なるほど」と思えるから。状況によって都合よく解釈できるから。そして結局、どちらも実践しないから。果ては、読まない自己啓発本を「なぜ、読めないのか？」と分析する本まで出てきた。買うだけで満足する自己啓発本について、なぜ読めないのかを解説する自己啓発本。これも買うだけで満足されるんだろうか。メタメタ自己啓発の無限ループ。SNSも同じ構造だ。言語化された「エンジニアの本質」を読んで「なるほど」と思う。でも実践はしない。だから同じような内容が手を変え品を変えて投稿されても、毎回新鮮に感じる。毎回「いいね」を押す。私もその供給側に回ってしまった。需要があるから供給する。言語化して、共感を集めて、バズらせる。市場原理としては正しい。でもエンジニアとして正しいかは別問題だ。タイパという幻想なぜ私たちは「レベル1」の罠から抜け出せないのか。それは現代の呪文「タイパ」にも原因がある。「すぐに結果がほしい！」——これこそが、搾取される側に回ってしまう人々の最大の特徴である。焦燥感に駆られた人間は、じっくりと腰を据えて物事に取り組むことができない。時間という最も貴重な投資資源を惜しみ、検証や比較検討のプロセスを省略してしまう。その結果、本来であれば選択すべき確実性の高い選択肢を見送り、「即効性」を謳う甘い罠に飛びついてしまうのだ。こうした人々が手にするのは、表面的には「成功」や「結果」に見える幻影だ。一時的な高揚感、束の間の満足感——しかし、それらは砂上の楼閣のように脆く、瞬く間に崩れ去る。そして失ったものを取り戻そうと、さらに性急な判断を重ね、同じ過ちを繰り返す。この悪循環は加速度的に進行する。資金、時間、精神的余裕、人間関係——あらゆるリソースが急速に枯渇していく。皮肉なことに、リソースが減れば減るほど、「今すぐ挽回したい」という焦りは強まり、ますます長期的な視点を持てなくなる。まさに負のスパイラルだ。対照的に、待つことができる人、忍耐強く種を蒔き育てることができる人は、決して搾取される側には立たない。彼らは複利の力を理解し、小さな積み重ねが大きな成果につながることを知っている。短期的な誘惑に惑わされず、本質的な価値を見極める眼を持っているのである。SNSの「レベル1」コンテンツは、まさにこの「タイパ」を求める心理に最適化されている。3秒で理解できて、5秒で共感できて、1秒で「いいね」が押せる。でも、3秒で理解できることに、本当の価値があるのか？エンジニアリングの本質は、時間をかけて複雑な問題と向き合うことだ。バグの原因を突き止めるのに何時間もかかることもある。新しい技術を習得するのに何週間もかかることもある。でもSNSは、その対極の価値観を植え付ける。「エンジニアの本質を1分で理解！」みたいな投稿が求められ、それを供給する側に私はいる。これがどれだけ矛盾してるか、分かってる。でもやめられない。タイパの経済学 (幻冬舎新書)作者:廣瀬涼幻冬舎Amazon感情キーワードバトルという地獄もっと深刻な問題がある。SNSが「議論」の形を完全に破壊したことだ。誰も元の投稿を読んでいない。自分が反応したいキーワードだけ拾って引用RTして、自分の言いたいことを言ってるだけ。元の文脈なんて無視。それを見た人がまた違う解釈で反応。伝言ゲームどころか、最初から誰も同じ話をしてない。「技術的負債」って言葉を使えば、ある人は「日本企業の問題」を語り始め、別の人は「負債じゃなくて投資と呼ぶべき」と言い出し、また別の人は「エンジニアの給料」の話にすり替える。全員が違う話をしているのに、全員が「議論に参加している」と思い込んでいる。一番ヤバいのは、この「感情キーワードバトル」に参加してる人たちが本当に議論してると思い込んでることだ。お互い別の話してるのに「論破した」「反論できないだろ」って勝利宣言。誰も誰の話も聞いてない。ただ自分の感情を違うキーワードで叫び続けてるだけ。これが「正しい議論の形」として定着していく。キーワードに脊髄反射、感情的に反論、さらに過激な言葉で応酬。このサイクルが「活発な議論」だと勘違いされる。本当に内容を理解して話そうとする人は「空気読めない」扱い。SNSが作り出した完成形がこれだ。構文の進化と劣化初期の構文はまだ救いがあった。「エンジニアの最大の課題は、実は健康管理です。長時間のコーディングや締め切りのストレスが、創造性と生産性を低下させることに気づきました」。少なくとも「気づき」があった。体験があった。今の構文は完全にテンプレート化している。「エンジニアの本質は〇〇です。なぜなら××だからです。△△することが大切です」。中身がない。でもバズる。なぜなら、誰も中身を求めてないから。言語化して、整理して、共感を得る。でもそれだけ。実際の問題は何も解決しない。でも「理解した」気になるから、それで満足する。次の日には忘れて、また似たような構文に「いいね」を押す。手段として理解して使うここまで批判的に書いてきたが、実のところ、私は大人なので、SNSの活用については広報的な意味合い以上のものをあまり持ち合わせていない。フォロワー数は技術力じゃない。いいねの数はコードの質じゃない。影響力は問題解決能力じゃない。これらは全部、当たり前のことだ。SNSは私にとって広報ツールだ。会社の認知度を上げ、採用に貢献し、登壇機会を増やす。そういう実利的な面で活用している。9500人のフォロワーは、その成果の一つの指標に過ぎない。言語化が上手くなっても、コードが上手く書けるわけじゃない。構文を量産できても、サービスが作れるわけでも良いアーキテクチャができるわけじゃない。でも、それでいい。別のスキルだから。営業スキルと開発スキルが別物であるのと同じように。コードを書いている時、「これツイートにできるな」と思うことがある。でもそれは、仕事の経験を別の形でアウトプットする機会として捉えているだけだ。本業に支障はない。むしろ、言語化することで自分の理解が深まることもある()。大人としての割り切りこの記事を書きながら、「これもバズるだろうな」と計算している。それの何が悪いのか。自己批判もコンテンツの一つだ。メタ的な視点も価値提供の一形態だ。それでエンゲージメントが得られるなら、広報戦略として成功だ。でも同時に、私は誠実でありたいとも思っている。矛盾してる？そうかもしれない。私がやっていることは、ある側面から見れば明らかに「悪」だ。「レベル1」の罠を批判しながら、自分がその供給者になっている。若手エンジニアが本質的な学習から逃げる口実を提供している。「勉強した気」になる麻薬を売っている。この自覚がある。だからこそ、せめて誠実でありたい。自分が何をしているか、それがどんな影響を与えているか、目を逸らさずに直視する。綺麗事で飾らない。正当化もしない。SNSは仕事の一部。朝の投稿は、メールチェックと同じルーティン。フォロワーとのやり取りは、ネットワーキングの一環。感情的にならずに、淡々とこなす。でも、その行為が持つ毒性も理解している。syu-m-5151.hatenablog.comこの辺りの考え方は、上の記事でも書いた通り。SNSは道具であり、それ以上でもそれ以下でもない。でも道具は使い方次第で武器にも毒にもなる。結局のところ、絶対的な正義なんてない。技術的に正しいことだけが正義でもないし、ビジネス的な成功だけが正義でもない。SNSで影響力を持つことが善でも悪でもない。いや、違う。悪い面もある。確実にある。でも、それを自覚した上でやる。目を開いたまま、自分が加担している構造を理解しながら、それでも続ける。なぜなら、それが大人の仕事だから。大事なのは「したたかに、上手くやる」ということ。自分の技術的興味を追求しながら、会社にも価値を提供する。SNSで発信しながら、コードも書く。構文でバズらせながら、良い本を紹介する。悪であることを自覚しながら、それでも誠実に。全部やればいい。若手エンジニアがSNSの罠にハマるリスクは理解している。だから警告もする。自分が掘った落とし穴に「危険」の看板を立てるような偽善かもしれない。でも私自身は、もうその段階は過ぎた。道具は道具として使う。毒は毒として扱う。それだけの話だ。誠実であることと、悪を自覚することは矛盾しない。むしろ、悪を自覚しているからこそ、誠実でありたいと思う。少なくとも、自分が何をしているかについては嘘をつかない。それが私なりの最低限の誠実さだ。おわりに1年前の自戒「コード以外で目立つな」は、純粋だった。今なら違う。ソフトウェアエンジニアエンジニアもSNSも、どっちも仕事。SNSでバズることとエンジニアとしての価値は別物だ。言語化の上手さとコーディング能力も別物だ。当たり前だ。でも、両方できた方が良くないか？若手には今でも「SNS閉じてエディタ開け」と言う。まずちゃんとしたエンジニアリングを知ってほしいから。複雑な問題と格闘する充実感を味わってほしいから。でも経験を積んだら、両方開いておけばいい。私は今日も構文を作る。コードも書く。会社の広報もする。矛盾？知ったことか。SNSの罠にハマるな。でも罠を理解したら、利用しろ。技術を追求しろ。でも手段と目的を間違えるな。何より、上手くやれ。それだけだと思う。でも、自分がフォロワー数というココナッツの中の米を握った猿でないとは言えないので数年後のnwiizoを楽しみにしておいて下さい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[HonoとAstroは仲良し〜Cloudflare Workersでの使い方紹介]]></title>
            <link>https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie</link>
            <guid isPermaLink="false">https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie</guid>
            <pubDate>Wed, 03 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[バックエンド向けウェブフレームワーク「Hono」、フロントエンド向けのウェブフレームワーク「Astro」。実は仲良いですよ！今回はCloudflare Workers上での、HonoとAstroの使い方を紹介します。単独で使う、Hono-in-Astro、Astro-in-Honoなど組み合わせ方が多いです！最後にAstro-in-Hono関連のライブラリも紹介します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼]]></title>
            <link>https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/</link>
            <guid isPermaLink="false">https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/</guid>
            <pubDate>Wed, 03 Sep 2025 03:10:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは。 夏が始まったと思ったらもう暦上では9月。夏の終わりです。時間の流れは早いですね。 こんな感じでいつの間にか秋が来て冬が来て年末になっていたり…不思議です。 今回ですが、BigQueryに「いつの間 […]The post BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Feature Store: オフラインストアを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/c542c7ec7a5cf2</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/c542c7ec7a5cf2</guid>
            <pubDate>Tue, 02 Sep 2025 11:48:40 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AI上で提供されているFeature Storeについて、オフラインサービング機能を試してみたので共有します。 Vertex AI Feature Storeとは？まずはFeature Storeとは何かというところですが、簡単にいうとMLモデルを学習するための特徴量を中央集権的に管理してくれるレジストリです。MLモデルを開発する時はそれぞれの開発者がモデルに必要な特徴量を作るために前処理を実装しますが、生成された特徴量を他のエンジニアに共有するためにわざわざファイルに落として共有する必要があります。Feature Storeを導入すると、作成された特徴量はFe...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazon VPC CNIに学ぶCNI-LT版]]></title>
            <link>https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban</link>
            <guid isPermaLink="false">https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban</guid>
            <pubDate>Tue, 02 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://k8sjp.connpass.com/event/365262/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[lakeFSシリーズ: Qucikstart入門編]]></title>
            <link>https://zenn.dev/akasan/articles/f51ba2da49ec1a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f51ba2da49ec1a</guid>
            <pubDate>Mon, 01 Sep 2025 13:09:07 GMT</pubDate>
            <content:encoded><![CDATA[今回からlakeFS紹介シリーズも始めようと思います（一体いくつシリーズ始めるんだw）。lakeFSを利用することでデータのバージョンをGitで管理することができるようになります。今回は公式で提供されているQiuckstartを通して入門してみます。 lakeFSとは？lakeFSは、オブジェクトストレージをGitライクなリポジトリに変換するオープンソースのツールであり、コードを管理するようにデータレイクを管理できるもののようです。lakeFSを利用することで、複雑なETLジョブからデータサイエンスやアナリティクスまで、反復可能でアトミックかつバージョン管理されたデータレイクオペレ...]]></content:encoded>
        </item>
    </channel>
</rss>