<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 22 Sep 2025 11:41:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Vertex AI Pipelinesを利用してエンドポイントをデプロイした]]></title>
            <link>https://zenn.dev/akasan/articles/093e1d1d3ec445</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/093e1d1d3ec445</guid>
            <pubDate>Mon, 22 Sep 2025 11:20:35 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AI Pipelinesを利用してモデルを開発してエンドポイントにデプロイするためのチュートリアルを実施しました。Google Cloudがオフィシャルで提供しているノートブックがあり、それを利用してデプロイするための方法を解説しようと思います。なお、Pipeline構成コードはサンプルに則って進めますが、インフラ構成についてはTerraformで作成します。https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cl...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[エンジニアはちゃんと身銭を切れ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/22/175353</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/22/175353</guid>
            <pubDate>Mon, 22 Sep 2025 08:53:53 GMT</pubDate>
            <content:encoded><![CDATA[はじめにnekogata.hatenablog.comを読みました。オーナーシップを阻害する構造的な問題について丁寧な分析がされていて、なるほどと思う部分が多かった。しかし、私はこの問題の核心はもっとシンプルなところにあると考えている。エンジニアが身銭を切っていない。それだけだ。構造を変えても、制度を整えても、身銭を切らないエンジニアは責任を取らない。逆に、どんな環境でも身銭を切るエンジニアは結果を出す。言い方はなんでもよいが私はそういう覚悟のキマったエンジニアを何人も見てきた。このブログが良ければ読者になったり、nwiizoのXやGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。身銭を切るとは何か身銭を切るとは「何かがうまくいかなかった場合に相応のペナルティを支払う」覚悟を持つことだ。給料が減るとか、クビになるとか、そんな極端な話ではない。自分の評判、プライド、チームからの信頼、深夜の時間、精神的なストレス。これらを賭けて仕事に臨むことが、身銭を切るということだ。プロフェッショナルとして、自分の仕事の結果に責任を持つ。失敗したら「言われた通りに作っただけ」という逃げ道を使わない。それが身銭を切る姿勢だ。身銭を切れ――「リスクを生きる」人だけが知っている人生の本質作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonなぜエンジニアは身銭を切らないのか心理的安全性の誤解近年、「心理的安全性」という言葉が流行している。本来これは「率直な意見を言える環境」を意味するが、多くの現場では「失敗しても責められない環境」と誤解されている。この誤解が、責任回避の文化を生む。「失敗は成功の母」という言葉が、失敗への恐れを完全に取り除いてしまった。恐れがなければ、緊張感もない。緊張感がなければ、真剣さもない。本当の心理的安全性とは、失敗を恐れないことではない。失敗したときに、それを認め、責任を取り、改善できる環境のことだ。しかし多くのエンジニアは、この「責任を取る」部分を都合よく忘れている。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazonキャリアの流動性という逃げ道エンジニアの転職市場は活発だ。プロジェクトが失敗しても「より良い環境を求めて」転職すればいい。技術的負債を積み上げても「新しい挑戦」として別の会社に移ればいい。この流動性が、長期的な責任から逃れる手段になっている。3年後のシステムの保守性など考えない。どうせ3年後には別の会社にいるからだ。しかし、真にプロフェッショナルなエンジニアは逃げない。彼らは自分が書いたコードの5年後、10年後を見据えて設計する。転職しても、過去に携わったシステムの成功や失敗を自分の責任として背負い続ける。一方で、転職の容易さに甘えるエンジニアは、失敗の履歴をリセットできると考える。新しい職場では、また「経験豊富なエンジニア」として振る舞い、同じ過ちを繰り返す。この差が、単なる「身銭を切らないエンジニア」と「プロフェッショナルなエンジニア」を分けている。「技術的に正しい」という隠れ蓑「技術的に正しい」という言葉は、ソフトウェアエンジニアにとって最強の防御壁だ。ユーザーが使いにくいと言っても「技術的には正しい実装」。パフォーマンスが悪くても「理論的には最適なアルゴリズム」。ビジネスが失敗しても「技術選定は間違っていなかった」。技術の複雑性を盾に、結果への責任を回避する。「素人には分からない」という態度で、批判を封じる。しかし、技術はあくまで手段だ。目的を達成できなければ、どんなに技術的に優れていても意味がない。集団責任という幻想誤解しないでほしい。チーム開発を否定しているわけではない。協力は素晴らしいし、相互レビューは品質向上に不可欠だ。問題は、「チーム全体で責任を持つ」という美しい理念が、「誰も責任を持たない」言い訳に変質していることだ。コードレビューで承認したから、バグは全員の責任。スプリント計画で合意したから、遅延は全員の責任。全員の責任は、誰の責任でもない。優れたチームこそ、個々人が明確な責任範囲を持ち、その上で協力する。しかし現実には、集団責任の名の下に、個人の責任が曖昧にされている。身銭を切らないことの代償対称性の崩壊身銭を切らない場合、リスクの非対称性が生じる。成功すれば褒められるが、失敗しても「次は気をつけましょう」で終わる。エンジニアにとって失敗は「学習機会」だが、ユーザーにとってはただの「使えないサービス」だ。火災現場で消防士が「今日は調子が悪い」と言っても、火は待ってくれない。一行のログの向こうには、一人のユーザーがいる。しかし、身銭を切らないエンジニアにとって、それは単なるデータポイントでしかない。同じ失敗の繰り返し「痛みは学びを助く」。人間は失敗して痛みを感じることで学び成長する。しかし、身銭を切らない失敗は「他人事」として処理される。「前のプロジェクトでも同じ問題があったよね」という会話を何度聞いたことか。それは誰も身銭を切っていないからだ。痛みがなければ、学びもない。新　失敗学　正解をつくる技術作者:畑村洋太郎講談社Amazonなぜ身銭を切るべきなのか意思決定の質が根本的に変わる身銭を切ると、判断基準が変わる。「この技術選定で失敗したら、自分が休日返上で修正することになる」と思えば、流行りに飛びつくことはない。「このアーキテクチャで3年運用することになる」と覚悟すれば、適当な設計はしない。他人事の意思決定は雑になる。自分事の意思決定は精緻になる。これは能力の問題ではなく、身銭を切っているかどうかの問題だ。学習曲線が急激に立ち上がる「痛みは最高の教師」という言葉がある。マニュアルを100回読んでも身につかないことが、一度の失敗で骨身に染みる。深夜3時、本番環境が止まり、冷や汗をかきながらログを追う。その時に学ぶシステムの挙動は、二度と忘れない。身銭を切らない学習は表層的だ。カンファレンスで聞いた話、ブログで読んだベストプラクティス。知識としては持っているが、判断の瞬間には出てこない。痛みを伴わない知識は、実戦では使えない。プロフェッショナルとして認められる医者が「手術は失敗したけど、僕のせいじゃない」と言ったらどう思うか。パイロットが「墜落したけど、マニュアル通りに操縦した」と言ったらどう思うか。エンジニアも同じだ。「仕様通りに作った」「指示された通りに実装した」。これは素人の言い訳だ。プロは結果に責任を持つ。だからこそ、プロの意見には重みがあり、プロの判断は尊重される。身銭を切らないエンジニアは、いつまでも「作業者」として扱われる。身銭を切るエンジニアだけが、「エンジニア」として認められる。本物の自信が身につく身銭を切って成功した経験、失敗から立ち直った経験。これらが積み重なって、揺るぎない自信になる。「あの時、全責任を負って新技術を導入した」「大規模リファクタリングを主導して成功させた」「致命的な障害を起こしたが、そこから這い上がった」。これらの経験が、次の挑戦への勇気になる。会社や上司に守られた成功体験は、環境が変われば消える。しかし、身銭を切って得た自信は、どこに行っても通用する。それが、市場価値になる。組織における身銭の力少数決原理とは組織の意思決定は多数決で行われると思われがちだが、実際は違う。重要な決定は「少数決原理」に従う。これは、最も失うものが大きい人、つまり最も身銭を切っている人の意見が採用される、という原理だ。例を挙げよう。レストランを選ぶとき、10人中9人が「何でもいい」と言い、1人だけがベジタリアンだったら、ベジタリアン対応のレストランが選ばれる。なぜか？ベジタリアンにとって「肉を食べる」ことのコストは、他の9人が「野菜を食べる」ことのコストより遥かに高いからだ。ソフトウェア開発における少数決原理この原理はソフトウェア開発でも働く。深夜対応を覚悟しているエンジニアが「このシステムは危険だ」と言えば、その声は無視できない。なぜなら、実際に深夜に呼び出されるのは彼だからだ。一方、無責任で言われたことだけやるエンジニアが「大丈夫でしょう」と言っても、その言葉に重みはない。セキュリティインシデントが起きたとき、責任を取ると宣言したエンジニアの「この対策では不十分」という意見は通る。日頃から「僕は関係ない」という態度のエンジニアがいくら正論を述べても、聞き流される。なぜ少数決原理が機能するのか身銭を切る者は、失敗したときのダメージが大きい。だから、彼らの反対意見には切実さがある。「このままでは本当にまずい」という危機感が、組織を動かす。また、身銭を切る者は信頼される。過去に責任を取ってきた実績があるから、その判断は尊重される。「あの人が言うなら」という信頼が、少数意見を多数意見に変える。身銭を切らない者がいくら集まっても、一人の身銭を切る者には勝てない。なぜなら、前者は失敗しても逃げられるが、後者は逃げられないからだ。逃げられない者の必死さが、組織の方向を決める。まとめ偉そうなことを書いてきたが、私も完璧ではない。逃げたくなることもある。「これは自分の仕事じゃない」と思うこともある。でも、そんなときこそ思い出す。プロフェッショナルとは何か。小さなことから始めればいい。自分が担当しているサービスの本番データを毎日見る。障害が起きたら、担当外でも飛び込む。「この仕様は良くない」と思ったら、代替案を提示する。そして、その結果に責任を持つ。身銭を切るとは、華々しいことではない。地味で、苦しくて、割に合わないことも多い。でも、振り返ったときに胸を張れる。「あのシステムは、俺が守った」「あの障害は、俺が未然に防いだ」「あのユーザーの課題は、俺が解決した」それが、エンジニアとしての誇りだと、私は思う。こういうマインドは先達から学んできたわけですが書籍で言うと達人プログラマーとかははとても良い本なのでオススメです。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ACPでAgentに行動させる]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/22/094533</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/22/094533</guid>
            <pubDate>Mon, 22 Sep 2025 00:45:33 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは！今回は、コードエディタや各種開発ツールとAIエージェント間の通信を標準化する Agent Client Protocol (ACP) について、その内部実装と実践的な使用方法を詳しく解説します。github.com最近の界隈では、Model Context Protocol（MCP）が大きな注目を集めていますが、その陰で着実に重要性を増している技術があります。それがACPです。MCPのような華やかさはないものの、実際にエディタプラグインやコーディングエージェントを開発する際には、ACPの理解が不可欠になってきています。なお、ACPを理解する前提としてMCPの基礎知識があると理解が深まります。MCPについては以下の記事で詳しく解説していますので、ぜひ参照してください。syu-m-5151.hatenablog.comまた、みのるんさんから献本いただいたこちらの書籍も、MCPの入門書として非常に参考になりました。実践的な内容が分かりやすくまとめられており、おすすめです。やさしいMCP入門作者:御田稔,大坪悠秀和システムAmazon同名のスライドでも良いのでMCPがわからない人は触れておくと良いと思います。 speakerdeck.comコード開発におけるAI支援ツールが急速に普及する中、実はエディタとAIツールの間には興味深い技術的課題が潜んでいます。それは、エディタごとに個別対応が必要で、使いたいツールの組み合わせが制限されるという問題です。正直なところ、多くの開発者はCopilotやCursorなどの既製品で満足しているでしょうし、この問題を意識することもないかもしれません。しかし、エディタプラグインを自作したい人や独自のAIエージェントを開発したい人、あるいは技術的な仕組みに興味がある人にとって、ACPは実に興味深い技術です。「エディタとAIエージェント間のLSP」として機能するこのプロトコルは、知らなくても困らないけれど、知っていると開発の可能性が大きく広がる、そんな技術と言えるでしょう。本記事では、このややマニアックながらも将来性のあるACPの実装詳細を通じて、プロトコル設計の面白さや、Rustによる非同期通信の実装テクニックなど、技術的に興味深いポイントを深掘りしていきます。ACPとは何か？記事を始める前に、まず ACP (Agent Client Protocol) について簡単に説明しましょう。ACP についてより詳しい情報は、公式GitHubリポジトリ や公式サイトを参照してください。ACPは、Zed Industriesが開発したオープンソースの標準プロトコルで、コードエディタとAIコーディングエージェント間の通信を標準化します。Language Server Protocol（LSP）がプログラミング言語サーバーの統合を革命的に変えたように、ACPは「LSPのAIエージェント版」として、AIツールの統合に同様の変革をもたらすことを目指しています。agentclientprotocol.comACPの仕組みACP は基本的に JSON-RPC 2.0 ベースのプロトコルで、主要な構成要素は以下のとおりです。クライアント（Client）：コードエディタ（Zed、Neovim など）エージェント（Agent）：AIコーディング支援プログラム（Claude Code、Gemini CLI など）セッション（Session）：会話の単位、複数のセッションを並行して管理可能エージェントはエディタのサブプロセスとして実行され、標準入出力（stdin/stdout）を通じて通信を行います。agentclientprotocol.comACPとMCPの関係ACPの技術仕様において重要なのは、Model Context Protocol（MCP）との関係です。MCPは、LLMが外部サービスやローカルリソースにアクセスするためのプロトコルです。ACPは可能な限りMCPの型を再利用し、エディタが既存のMCPサーバー設定を持つ場合、その設定をエージェントに渡すことができます。agentclientprotocol.com{  "mcpServers": {    "filesystem": {      "command": "npx",      "args": ["-y", "@modelcontextprotocol/server-filesystem"],      "env": {        "ALLOWED_PATHS": "/path/to/project"      }    }  }}JSON-RPC の基本ACP は JSON-RPC 2.0 仕様に基づいており、以下の3種類のメッセージ形式が使われます。agentclientprotocol.comリクエスト：クライアントからエージェントへの要求{  "jsonrpc": "2.0",  "id": 1,  "method": "prompt",  "params": {    "sessionId": "session-123",    "prompt": [{"type": "text", "text": "Hello Agent!"}]  }}レスポンス：エージェントからクライアントへの応答{  "jsonrpc": "2.0",  "id": 1,  "result": {    "stopReason": "endTurn",    "meta": null  }}通知：レスポンスを必要としない一方向メッセージ{  "jsonrpc": "2.0",  "method": "session/notification",  "params": {    "sessionId": "session-123",    "update": {      "type": "agentMessageChunk",      "content": {"type": "text", "text": "Processing..."}    }  }}Rustで実装するACPの詳細解説それでは、実際のRustコードを通じてACPの動作原理を深く理解していきましょう。公式リポジトリの実装例（agent.rsとclient.rs）を詳しく解説します。agentclientprotocol.com実装の準備と実行まず、ACPの実装を実際に動かすための手順を確認しましょう：# リポジトリのクローンgit clone https://github.com/zed-industries/agent-client-protocolcd agent-client-protocol/rust# エージェントのビルドRUST_LOG=info cargo build --example agent# クライアントの実行（エージェントを自動起動）cargo run --example client -- ../target/debug/examples/agent# 実行時の対話例> Hello, Agent!| Agent: Client sent: Hello, Agent!> How can you help me with coding?| Agent: Client sent: How can you help me with coding!この実行により、以下の通信フローが発生します。初期化フェーズ: プロトコルバージョンのネゴシエーションセッション確立: 作業ディレクトリとMCPサーバー設定の共有メッセージループ: プロンプトの送信と応答のストリーミンググレースフルシャットダウン: プロセス終了時のリソースクリーンアップエージェント側の実装（agent.rs）基本構造とトレイト実装use std::cell::Cell;use agent_client_protocol::{    self as acp, AuthenticateResponse, Client, ExtNotification,     ExtRequest, ExtResponse, SessionNotification, SetSessionModeResponse,};use tokio::sync::{mpsc, oneshot};struct ExampleAgent {    session_update_tx: mpsc::UnboundedSender<(acp::SessionNotification, oneshot::Sender<()>)>,    next_session_id: Cell<u64>,}構造体の設計思想：session_update_tx：非同期チャネルの送信側で、セッション更新をバックグラウンドタスクに送信next_session_id：Cell<u64>による内部可変性パターンで、&selfの不変参照でも値を更新可能ACPトレイトの実装#[async_trait::async_trait(?Send)]impl acp::Agent for ExampleAgent {    async fn initialize(        &self,        arguments: acp::InitializeRequest,    ) -> Result<acp::InitializeResponse, acp::Error> {        log::info!("Received initialize request {arguments:?}");        Ok(acp::InitializeResponse {            protocol_version: acp::V1,            agent_capabilities: acp::AgentCapabilities::default(),            auth_methods: Vec::new(),            meta: None,        })    }重要なポイント：async_trait(?Send)：非Sendなfutureを許可し、LocalSet環境での実行を可能にプロトコルバージョンの明示的な宣言ケイパビリティ交換による機能のネゴシエーションセッション管理async fn new_session(    &self,    arguments: acp::NewSessionRequest,) -> Result<acp::NewSessionResponse, acp::Error> {    log::info!("Received new session request {arguments:?}");    let session_id = self.next_session_id.get();    self.next_session_id.set(session_id + 1);    Ok(acp::NewSessionResponse {        session_id: acp::SessionId(session_id.to_string().into()),        modes: None,        meta: None,    })}セッションの概念：各セッションは独立した会話コンテキストMCPサーバー設定の引き継ぎ作業ディレクトリの設定プロンプト処理とストリーミングasync fn prompt(    &self,    arguments: acp::PromptRequest,) -> Result<acp::PromptResponse, acp::Error> {    log::info!("Received prompt request {arguments:?}");        for content in ["Client sent: ".into()].into_iter().chain(arguments.prompt) {        let (tx, rx) = oneshot::channel();                // セッション更新の非同期送信        self.session_update_tx            .send((                SessionNotification {                    session_id: arguments.session_id.clone(),                    update: acp::SessionUpdate::AgentMessageChunk { content },                    meta: None,                },                tx,            ))            .map_err(|_| acp::Error::internal_error())?;                // バックプレッシャー制御        rx.await.map_err(|_| acp::Error::internal_error())?;    }        Ok(acp::PromptResponse {        stop_reason: acp::StopReason::EndTurn,        meta: None,    })}ストリーミング設計：チャンク単位でのメッセージ送信oneshot::channel()による同期制御バックプレッシャーによる流量制御メインループとタスク管理メインループは、非同期ランタイムの中核部分であり、実際にエージェントが起動される場所です。#[tokio::main(flavor = "current_thread")]async fn main() -> anyhow::Result<()> {    env_logger::init();  // RUST_LOG環境変数でログレベルを制御    let outgoing = tokio::io::stdout().compat_write();    let incoming = tokio::io::stdin().compat();    let local_set = tokio::task::LocalSet::new();    local_set        .run_until(async move {            let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();                        // エージェント接続の確立            let (conn, handle_io) = acp::AgentSideConnection::new(                ExampleAgent::new(tx),                 outgoing,                 incoming,                 |fut| {                    tokio::task::spawn_local(fut);                }            );                        // セッション通知処理タスク            tokio::task::spawn_local(async move {                while let Some((session_notification, tx)) = rx.recv().await {                    let result = conn.session_notification(session_notification).await;                    if let Err(e) = result {                        log::error!("{e}");                        break;                    }                    tx.send(()).ok();                }            });                        handle_io.await        })        .await}非同期ランタイムの設計：LocalSet：シングルスレッド実行環境（current_threadフレーバーと連携）spawn_local：非Sendタスクの実行チャネルによるタスク間通信RUST_LOG=info環境変数でログ出力を制御（デバッグ時はRUST_LOG=debug）クライアント側の実装（client.rs）プロセス管理とライフサイクルクライアントは、エージェントをサブプロセスとして起動し管理します。実行時はコマンドライン引数でエージェントのパスを指定します：# 実行例：ビルド済みのエージェントを指定cargo run --example client -- target/debug/examples/agent#[tokio::main(flavor = "current_thread")]async fn main() -> anyhow::Result<()> {    let command = std::env::args().collect::<Vec<_>>();    let (outgoing, incoming, child) = match command.as_slice() {        [_, program, args @ ..] => {            let mut child = tokio::process::Command::new(program)                .args(args.iter())                .stdin(std::process::Stdio::piped())                .stdout(std::process::Stdio::piped())                .kill_on_drop(true)  // 自動クリーンアップ                .spawn()?;                        (                child.stdin.take().unwrap().compat_write(),                child.stdout.take().unwrap().compat(),                child,            )        }        _ => bail!("Usage: client AGENT_PROGRAM AGENT_ARG..."),    };プロセス管理のベストプラクティス：kill_on_drop(true)：親プロセス終了時の自動クリーンアップ（孤児プロセスを防ぐ）ストリーム所有権の明示的な管理（take()メソッド）エラー時のグレースフルシャットダウンエージェントプログラムへの引数の柔軟な受け渡しプロトコル初期化// 接続の確立let (conn, handle_io) = acp::ClientSideConnection::new(    ExampleClient {},     outgoing,     incoming,     |fut| {        tokio::task::spawn_local(fut);    });// バックグラウンドI/O処理tokio::task::spawn_local(handle_io);// 初期化ハンドシェイクconn.initialize(acp::InitializeRequest {    protocol_version: acp::V1,    client_capabilities: acp::ClientCapabilities::default(),    meta: None,}).await?;// セッション作成let response = conn    .new_session(acp::NewSessionRequest {        mcp_servers: Vec::new(),  // MCPサーバー設定        cwd: std::env::current_dir()?,        meta: None,    })    .await?;対話的REPLの実装Rustylineを使用した対話的インターフェースにより、ユーザーはエージェントと直接対話できます：// Rustylineによる対話インターフェースlet mut rl = rustyline::DefaultEditor::new()?;while let Ok(line) = rl.readline("> ") {    let result = conn        .prompt(acp::PromptRequest {            session_id: response.session_id.clone(),            prompt: vec![line.into()],            meta: None,        })        .await;        if let Err(e) = result {        log::error!("{e}");    }}REPLの動作例：> Hello, Agent!| Agent: Client sent: Hello, Agent!> What's the weather like?| Agent: Client sent: What's the weather like?> exitRustylineの利点：履歴管理（上下矢印キーで過去の入力を参照）カーソル移動とテキスト編集機能Ctrl+C/Ctrl+Dによる適切な終了処理将来的な自動補完機能の追加が可能セッション通知の処理#[async_trait::async_trait(?Send)]impl acp::Client for ExampleClient {    async fn session_notification(        &self,        args: acp::SessionNotification,    ) -> anyhow::Result<(), acp::Error> {        match args.update {            acp::SessionUpdate::AgentMessageChunk { content } => {                let text = match content {                    acp::ContentBlock::Text(text_content) => text_content.text,                    acp::ContentBlock::Image(_) => "<image>".into(),                    acp::ContentBlock::Audio(_) => "<audio>".into(),                    acp::ContentBlock::ResourceLink(resource_link) => resource_link.uri,                    acp::ContentBlock::Resource(_) => "<resource>".into(),                };                println!("| Agent: {text}");            }            acp::SessionUpdate::ToolCall(tool_call) => {                println!("| Tool call: {}", tool_call.name);            }            acp::SessionUpdate::Plan(plan) => {                println!("| Plan: {}", plan.description);            }            _ => {}        }        Ok(())    }エラーハンドリングとプロトコルの堅牢性タイムアウトとリトライの実装use tokio::time::{timeout, Duration};async fn prompt_with_timeout(    conn: &ClientSideConnection,    request: PromptRequest,    timeout_secs: u64,) -> Result<PromptResponse, Error> {    match timeout(        Duration::from_secs(timeout_secs),        conn.prompt(request)    ).await {        Ok(Ok(response)) => Ok(response),        Ok(Err(e)) => {            log::error!("Prompt error: {}", e);            Err(e)        }        Err(_) => {            log::error!("Prompt timeout after {} seconds", timeout_secs);            Err(Error::request_timeout())        }    }}エクスポネンシャルバックオフasync fn reconnect_with_backoff(    max_retries: u32,) -> Result<Connection, Error> {    let mut delay = Duration::from_secs(1);        for attempt in 1..=max_retries {        match establish_connection().await {            Ok(conn) => {                log::info!("Connected on attempt {}", attempt);                return Ok(conn);            }            Err(e) if attempt < max_retries => {                log::warn!("Attempt {} failed: {}", attempt, e);                tokio::time::sleep(delay).await;                delay *= 2;  // エクスポネンシャルバックオフ            }            Err(e) => return Err(e),        }    }        Err(Error::max_retries_exceeded())}実践的な統合例Claude Code ACPの設定Claude Code ACP は、AnthropicのClaude AIをACPプロトコル経由で利用可能にする実装です。github.com{  "agent_servers": {    "Claude Code": {      "command": "npx",      "args": ["@zed-industries/claude-code-acp"],      "env": {        "ANTHROPIC_API_KEY": "your-api-key",        "ACP_PERMISSION_MODE": "acceptEdits"      }    }  }}Avante.nvimの設定Avante.nvim は、NeovimでACPを利用するための実装です。github.com{  "yetone/avante.nvim",  event = "VeryLazy",  build = "make",  opts = {    provider = "claude",    mode = "agentic",    acp_providers = {      ["claude-code"] = {        command = "npx",        args = { "@zed-industries/claude-code-acp" },        env = { ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY") }      }    }  }}ccswarm での実装筆者が開発している ccswarm プロジェクトでは、当初は独自の仮想ターミナル実装を使用していましたが、ACPの登場を機に、より標準化されたアプローチへの移行を決定しました。github.comセキュリティに関する考慮事項ACPを使用する際には、以下の点に注意が必要です。ACPのセキュリティリスク作っていて思ったのですが、ACPはエージェントにローカル環境への強いアクセス権を付与するので、本質的にセキュリティ上の懸念があります：サードパーティエージェントのリスク: 信頼できない「野良エージェント」をインストールすると、マルウェアや情報漏洩のリスクが高まります権限の過剰付与: エージェントが必要以上の権限を持つと、システムリソースへの不正アクセスの可能性がありますデータ漏洩のリスク: ローカルファイルやクレデンシャルなどの機密情報が、エージェントを通じて外部に漏洩する可能性がありますプロンプトインジェクション攻撃: 悪意あるプロンプトを通じて、エージェントに予期しない操作を実行させるリスクがあります安全なACP利用のための対策信頼できるソースからのみエージェントをインストール: 公式リポジトリや信頼できる開発者からのエージェントのみを使用最小権限の原則を適用: エージェントには必要最小限の権限のみを付与サンドボックス環境での実行: 可能であれば、エージェントを隔離された環境で実行監査ログの有効化: エージェントを通じて実行されたすべてのコマンドや操作を記録機密情報のフィルタリング: APIキーやパスワードなどの機密情報を検出・削除するメカニズムを実装定期的なセキュリティレビュー: エージェントの設定やコードを定期的にレビュー確実なテストの実行: 本番環境に導入する前に、テスト環境で動作を徹底的に検証ACPのメリットと今後の展望開発者にもたらす価値ベンダーロックインからの解放: どのACP対応エディタでも、どのACP対応エージェントでも使用可能開発効率の向上: 統一されたプロトコルにより、新しいAIエージェントの導入が簡単にエコシステムの成長: 標準化により、開発者はそれぞれの得意分野に集中可能実践的な活用シナリオ大規模リファクタリング: プロジェクト全体の構造改善バグ修正フロー: エラー解析から修正まで一貫した支援コードレビュー自動化: セキュリティや品質の包括的チェックプロジェクト横断的な分析: アーキテクチャレベルの改善提案おわりにAgent Client Protocolは、AIコーディング支援ツールの統合における新たな標準として、着実に開発者コミュニティで採用が進んでいます。MCPが大きな話題を集めた一方で、ACPはそこまで注目を浴びていないかもしれません。しかし、エディタ開発者やコーディングエージェントを実装したい開発者にとって、ACPは極めて実用的で学ぶ価値の高い技術です。本記事で詳しく解説したRustの実装例は、ACPの設計思想を理解し、独自のエージェントを開発するための出発点となるでしょう。特に注目すべきは、Rustの所有権システムとACPの非同期通信モデルが見事に調和している点です。LocalSetによる非Sendなfutureの処理、mpscとoneshotチャネルを組み合わせた確実な通信、kill_on_dropによる安全なプロセス管理など、これらの技術的選択は、堅牢で効率的なACP実装の基礎となります。ACPの魅力は、JSON-RPCベースのシンプルなプロトコル設計により、数百行のコードで基本的なエージェントを実装できる敷居の低さにあります。一度ACPに対応すれば、Zed、Neovim、その他のACP対応エディタですぐに利用可能になり、独自のコーディングアシスタントやドメイン特化型エージェントの開発も容易になります。エディタとAIエージェントの統合は今後も加速することが予想され、ACPの知識は長期的な資産となるでしょう。一般的な開発者にとって重要なのは、ACPが派手さはないものの、日々のコーディング作業を着実に改善する実用的な基盤技術であるという点です。MCPのような革新的な印象はないかもしれませんが、LSPがそうであったように、気がつけば開発環境に不可欠な存在となっているでしょう。特に、独自のエディタプラグインやAIコーディングツールを開発したいと考えている方は、ぜひACPの仕様を学び、実装してみることをお勧めします。この標準化されたプロトコルは、あなたのツールを幅広いエコシステムに接続する架け橋となるはずです。参考リソースAgent Client Protocol GitHubリポジトリACP 公式ドキュメントClaude Code ACP実装Avante.nvim プロジェクトModel Context ProtocolJSON-RPC 2.0 仕様zed.dev]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeにtesseract書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/8ac71d6cc3057a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/8ac71d6cc3057a</guid>
            <pubDate>Sun, 21 Sep 2025 11:09:13 GMT</pubDate>
            <content:encoded><![CDATA[今回はclaude codeに作らせたシリーズの続編です。前回は3次元のフラクタル図形を書かせてみましたが、今回はtesseractを書かせてみました。https://zenn.dev/akasan/articles/f90c2940cf1ef3 tesseractとは？Wikipediaによると、正八胞体（せいはちほうたい、または四次元超立方体、英語: 8-cell、オクタコロン〈英: octachoron〉、テッセラクト〈英: tesseract、テセラクトとも〉）とは、四次元正多胞体の一種で8個の立方体からなる、四次元の超立方体である。とのことです。自分の認識では4...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[モジュールを意識したTerraform構成でColabのテンプレートを作成してみた]]></title>
            <link>https://zenn.dev/akasan/articles/9c48ed7e2457a6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/9c48ed7e2457a6</guid>
            <pubDate>Sat, 20 Sep 2025 09:15:40 GMT</pubDate>
            <content:encoded><![CDATA[今回は、昨日公開したColab Enterpriseのテンプレート作成のTerraformをモジュールを意識した構成で実装してみます。今までの記事ではルートディレクトリだけでmain.tfやvariables.tfを管理していましたが、実際に利用するときはモジュールを意識した構成が必要になるので、今回からその構成を意識して実装します。https://zenn.dev/akasan/articles/2966eb1a9f9a38 ディレクトリ構成今回は以下の構成でディレクトリを編成しました。main.tfvariables.tfmodules/  colab-templat...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[クラウド環境におけるシークレットの扱い]]></title>
            <link>https://blog.masasuzu.net/entry/2025/09/19/203626</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/09/19/203626</guid>
            <pubDate>Fri, 19 Sep 2025 11:36:26 GMT</pubDate>
            <content:encoded><![CDATA[この内容は、社内のエンジニア勉強会で話した内容です。 speakerdeck.comみなさん。プロダクション環境のシークレット情報をどう扱っていますか?クラウドネイティブなアプリケーション開発において、DBのパスワードや外部APIキーといったシークレットの管理は、セキュリティを確保する上で避けては通れない課題です。この記事では、アプリケーションとインフラそれぞれの視点から、クラウド環境におけるシークレット管理のアンチパターンとベストプラクティスを探っていきます。ここで言うシークレットとはDBのパスワードやAPIキーなどの秘匿すべき情報のことを指します。アプリケーション側の視点まずは、アプリケーションがどのようにシークレットを扱うべきかを見ていきましょう。管理のアンチパターン最初に管理方法のアンチパターンとしては以下のものがありますソースコードに直接記述設定ファイルに平文で記述環境変数に平文で記述(Dockerfileや.envファイルでgit管理するなど)base64エンコードして保存ソースコードに記述すれば、すべての環境で同じ値しか使えず柔軟性がありません。設定ファイルや環境変数に平文で記述し、それをGitで管理してしまうと、何かのミスでリポジトリが流出した際にシークレットも漏れてしまいます。また、隠しているつもりでBase64エンコードするのも同様に危険です。Base64は暗号化ではなく、誰でも簡単に元の文字列に戻せるため、平文で保存しているのと大差ありません。KMSによる暗号化の検討次に考えられるのが、暗号鍵を使った暗号化です。AWSのKMSやGoogle CloudのCloud KMSといった鍵管理サービスを利用する方法が考えられます。フローとしては以下のようになりますでしょうかアプリケーション起動時にKMSのから鍵を取得取得した鍵を利用して暗号化されたシークレットを復号平文のシークレット情報をアプリで利用する一見これで良さそうですが、復号処理をアプリケーションの責務にすると、コードが複雑になるだけでなく、KMSの復号権限をアプリケーション自体に付与する必要があり、管理の懸念点が増えてしまいます。クラウド側のシークレットストアの利用そこで推奨されるのが、クラウドが提供するシークレット管理の仕組みを利用することです。AWSAWS Secrets ManagerAWS Systems Manager Parameter Store(SecureString)Google CloudSecret Managerこれらのサービスは、ECS FargateやCloud Runなどのコンテナ実行環境と統合されています。コンテナの起動時に、これらのストアに保存されたシークレットを、自動的に環境変数やファイルとしてマウントしてくれるのです。これによりアプリケーション側では、シークレットがどこで管理されているかを意識することなく、従来通り環境変数やファイルから値を読み込むだけで済むようになり、責務をシンプルに保つことができます。インフラ側の視点さて、アプリケーションの課題は解決しました。次に、インフラ側で、そのシークレットストアをどう管理するかという課題に移りましょう。取れる手段としては主に以下ものが考えられます。手動でコンソールから設定シークレットの値を平文でIaC管理(tfvarsファイルをgit管理から外す)シークレットの値を暗号化してIaCで管理シークレットストアをIaCで管理、値は手動設定まず手動で管理ですが、これはこれでありだと思ってます。ただし、扱うシークレットの数が増えてきたときに作業が煩雑であったり、手作業がゆえに起こるリソースタグなどの付け間違いなどのミスが発生しうるので、規模が大きくなると現実的ではありません。2つ目ですが、シークレットの値だけあつかるtfvarsファイルをgitignoreしてあげることでレポジトリが漏れてもシークレットの値が漏れないことになります。が、うっかりシークレットの値を人為的なミスでコミットしうるので完全に安全とはいいにくいです。3つ目ですが、これはsops providerを利用するパターンです。これを使うことでKMSキーを利用して暗号/復号がterraformとシームレスに統合できます。一見これで良さそうですが、2点課題があります。KMSリソースを余計に管理なくてはならないStateには平文で保存される前者は必要経費としていいとして、後者は課題となります。Terraformにおいてはstateを見る権限がある人にはシークレットも見れてしまうという懸念があります。シークレットのリソースと値を分離するこの方法の利点は、IaCでシークレット リソースが存在することは管理しつつ、その実際の値はGitの管理下から完全に分離できる点です。初回適用後にコンソールから実際のシークレット値を設定すれば、それ以降 terraform apply を実行しても値がダミー値で上書きされることはありません。これにより、コードレビューなどで誤ってシークレットが漏洩するリスクを原理的に防ぐことができ、非常にバランスの取れた管理方法と言えます。以下サンプルコードです。resource "aws_ssm_parameter" "db_password" {  type     = "SecureString"  name     = "/test/db_password"  value    =  "Dummy"  lifecycle {    ignore_changes = [value]  }}まとめ現時点でのクラウドにおけるシークレット管理のベストプラクティスは、以下のようにまとめることができるでしょう。アプリケーションクラウドのシークレットストア(Secrets Managerなど)と実行環境(ECS, Cloud Runなど)の統合機能を使い、環境変数またはファイルとしてシークレットを読み込む。インフラ(IaC)クラウドのシークレットストアのリソース自体はTerraformで管理する。実際のシークレットの値は ignore_changes を活用して手動で設定し、Gitの管理から分離する。もちろん要件によって取りうる手段は変わるとは思います。他になにか良い方法をご存知でしたら教えて下さい。それでは良いシークレットライフを!関連ページblog.masasuzu.net]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Colab EnterpriseのランタイムテンプレートをTerraformで作る方法について]]></title>
            <link>https://zenn.dev/akasan/articles/2966eb1a9f9a38</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/2966eb1a9f9a38</guid>
            <pubDate>Fri, 19 Sep 2025 04:12:08 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AIのColab EnterpriseのランタイムテンプレートをTerraformで記述してみました。以前コンソールからランタイムテンプレートを作ったことはありましたが、今回はその設定をTerraformで再現してみようと思います。以前の該当記事は以下になるので、ぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/454f57beb383e9Google CloudでTerraformを試してみた系は以下のスクラップにまとめていますので合わせてご覧ください！https://zenn.dev/akasan/scraps/c6...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025-09-19 クラウドにおけるシークレット管理]]></title>
            <link>https://speakerdeck.com/masasuzu/2025-09-19-kuraudoniokerusikuretutoguan-li</link>
            <guid isPermaLink="false">https://speakerdeck.com/masasuzu/2025-09-19-kuraudoniokerusikuretutoguan-li</guid>
            <pubDate>Fri, 19 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[スリーシェイク社内のエンジニア勉強会で発表した資料クラウドにおいてプロダクション環境でのシークレットの扱い方についてアプリケーションおよびインフラ側でどう管理していくのが望ましいかを詳解]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Feature Storeの機能グループをTerraformで作る方法について]]></title>
            <link>https://zenn.dev/akasan/articles/3954f50f913bae</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3954f50f913bae</guid>
            <pubDate>Thu, 18 Sep 2025 04:55:06 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AIのFeature Storeの機能グループをTerraformから作成する方法について調べてみました。機能グループを利用するにはバックエンドとなるBigQueryデータセットの作成が必要であり、これら二つのリソースの作成をしてみます。Google CloudでTerraformを試してみた系は以下のスクラップにまとめていますので合わせてご覧ください！https://zenn.dev/akasan/scraps/c6182a7d763bc8 早速作ってみる！今回作成する機能グループについて、リソース定義は以下をベースに実施します。https://regi...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのサービスアカウントをTerraformで作る方法について]]></title>
            <link>https://zenn.dev/akasan/articles/b07c3ffab7f2ec</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b07c3ffab7f2ec</guid>
            <pubDate>Wed, 17 Sep 2025 13:32:45 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Google CloudのサービスアカウントをTerraformから作成する方法について調べてみました。最近K8sに加えてTerraformの学習もどんどん進めており、その勉強として今回はサービスアカウントを取り扱ってみます。Google CloudでTerraformを試してみた系は以下のスクラップにまとめていますので合わせてご覧ください！https://zenn.dev/akasan/scraps/c6182a7d763bc8 早速やってみる！ 変数の作成まずはGoogle CloudのプロジェクトIDやリージョンを設定するためにvariables.tfを以下の...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025-08-05 Google Cloud Next Tokyo 2025 Cloud RunとCloud SQLの接続方式と事例]]></title>
            <link>https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li</link>
            <guid isPermaLink="false">https://speakerdeck.com/masasuzu/2025-08-05-google-cloud-next-tokyo-2025-cloud-runtocloud-sqlnojie-sok-fang-shi-toshi-li</guid>
            <pubDate>Wed, 17 Sep 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Google CloudのModel ArmorのテンプレートをTerraformで記述してみた]]></title>
            <link>https://zenn.dev/akasan/articles/314b22ced3c9c1</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/314b22ced3c9c1</guid>
            <pubDate>Tue, 16 Sep 2025 13:11:02 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle CloudのSecurity Command Centerで提供されているModel Armorについて、Terraformを利用してテンプレートを作成してみました。なお、内容については前回コンソール画面上で作成した設定を再現する形で実装してみます。https://zenn.dev/akasan/articles/7ce40551040ccc 早速実装してみる Model Armorのリソースについて今回は以下のgoogle_model_armor_templateを利用してModel Armorのテンプレートを実装します。https://registr...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[actでGithub ActionsのVibe Codingを加速させる]]></title>
            <link>https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru</link>
            <guid isPermaLink="false">https://speakerdeck.com/kojake_300/actdegithub-actionsnovibe-codingwojia-su-saseru</guid>
            <pubDate>Tue, 16 Sep 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Sreakeの英語ブログをはじめました！]]></title>
            <link>https://sreake.com/blog/enabling-en-blog/</link>
            <guid isPermaLink="false">https://sreake.com/blog/enabling-en-blog/</guid>
            <pubDate>Tue, 16 Sep 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは！ Sreake事業部のイリドリシ愛民 (@realaminevg) です。 2020年から継続してきたSreakeブログの運用経験を活かし、今月からSreakeの英語ブログ（Sreake English Bl […]The post Sreakeの英語ブログをはじめました！ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Ray Coreを利用したバッチ予測例の検証]]></title>
            <link>https://zenn.dev/akasan/articles/e1501d2852e602</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e1501d2852e602</guid>
            <pubDate>Mon, 15 Sep 2025 04:46:41 GMT</pubDate>
            <content:encoded><![CDATA[今回はRay Coreの例として提供されているバッチ予測のサンプルを通して、バッチ予測の実装方法をみていきたいと思います。Rayに関するシリーズは以下でまとめていますのでぜひご覧ください。https://zenn.dev/akasan/scraps/73a90764c065d1 早速例を試してみる今回は以下の例を試してみます。この例では、バッチで取得したデータを対象として、どのように推論を行うかを試す例となっております。https://docs.ray.io/en/latest/ray-core/examples/batch_prediction.html 環境構築uvを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GoogleのセキュアAIフレームワークについて]]></title>
            <link>https://zenn.dev/akasan/articles/2b9291950d99ef</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/2b9291950d99ef</guid>
            <pubDate>Sun, 14 Sep 2025 04:16:27 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogleが提唱するセキュアAIフレームワークについて調べてみました。さまざまなAIが導入されている昨今、よりセキュアにAIシステムを運用できることが求められています。AIを案件で取り扱っている立場でもあるので、このフレームワークについて調べてみました。 セキュアAIフレームワークとは？Googleが提唱するセキュアAIフレームワーク（以下、SAIF）は、責任を持ってAIを開発し導入するための高いセキュリティ基準が求めらている状況に対して、システムをより安全に保護するための概念的なフレームワークとして提唱されました。https://safety.google/intl/j...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Machine Learning Engineer編~]]></title>
            <link>https://zenn.dev/akasan/articles/062b9d9e44922a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/062b9d9e44922a</guid>
            <pubDate>Sat, 13 Sep 2025 05:17:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle Cloud認定資格の一つであるProfessional Machine Learning Engineer(以下、PMLE)を受験したのでその体験記になります。前回取得した資格についても記事にしているのでぜひご覧ください。https://zenn.dev/akasan/articles/c0d347a37065bc Professional Machine Learning EngineerについてPMLEはGoogle Cloudの認定資格の一つであり、特に機械学習に関するサービスおよびその取り扱い、実務への応用などについて問われる資格となります。PMLEで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeに3次元のフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/f90c2940cf1ef3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f90c2940cf1ef3</guid>
            <pubDate>Fri, 12 Sep 2025 14:07:09 GMT</pubDate>
            <content:encoded><![CDATA[昨日は2次元のフラクタル図形をClaude Codeに作成させましたが、今回は3Dのフラクタル図形を作成させてみました。ぜひ昨日の記事もご覧ください。https://zenn.dev/akasan/articles/91d41376641ffc 早速やってみるまずは環境構築をします。uv init fractal_3d -p 3.12cd fractal_3duv add matplotlib numpy pillow今回claude codeに与えた指示は以下になります。pythonを使って、3次元のフラクタル図形を段階的に生成してアニメーションとして保存するコード...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/appdev_specialization/</link>
            <guid isPermaLink="false">https://sreake.com/blog/appdev_specialization/</guid>
            <pubDate>Fri, 12 Sep 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「Application Development - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeにフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/91d41376641ffc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/91d41376641ffc</guid>
            <pubDate>Thu, 11 Sep 2025 13:37:44 GMT</pubDate>
            <content:encoded><![CDATA[今回はclaude codeを使ってフラクタル図形を作らせてみました。claude codeをはじめ生成AIはどこまでできる能力があるのかを測るためのシリーズになります。前回は立方体をターミナルでぐるぐる回すものをやりましたが、それの第二弾ですね。https://zenn.dev/akasan/articles/11fed840eedaa7※ バタバタしていて、コードの解説まではできません。次回以降行けるタイミングでさせてもらいます フラクタル図形とは？Wikipediaによると図形の部分と全体が自己相似（再帰）になっているものなどをいうということです。あるAから一部B...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mist.ioとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/573fa3dfa4911e</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/573fa3dfa4911e</guid>
            <pubDate>Wed, 10 Sep 2025 11:00:24 GMT</pubDate>
            <content:encoded><![CDATA[今回からついに始まりました、CNCFルーレットのお時間です。記念すべき第一弾はMist.ioとなりました。CNCFルーレットについては以下の記事で紹介していますのでぜひご覧ください。https://zenn.dev/akasan/articles/42f5a1d2786ca5https://zenn.dev/akasan/articles/ef9e2919c312c1 Mist.ioとは？Mistはオープンソースのマルチクラウド管理プラットフォームとのことです。Mistでは以下を実現することで、マルチクラウドの取り扱いをしているようです。Self-service: アクセス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Webアプリケーションにオブザーバビリティを実装するRust入門ガイド]]></title>
            <link>https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</guid>
            <pubDate>Wed, 10 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。https://findy.connpass.com/event/359456/他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。今回の発表内容のベースとなったのはこちらのブログです。- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。]]></title>
            <link>https://blog.masasuzu.net/entry/2025/09/10/005523</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/09/10/005523</guid>
            <pubDate>Tue, 09 Sep 2025 15:55:23 GMT</pubDate>
            <content:encoded><![CDATA[先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu'e'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：リモート関数戻り値の返し方のアンチパターンについて]]></title>
            <link>https://zenn.dev/akasan/articles/b74692f78ca720</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b74692f78ca720</guid>
            <pubDate>Tue, 09 Sep 2025 10:25:02 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayでリモート関数を利用するにあたり、その戻り値としてアンチパターンとされているものを紹介しようと思います。情報源は以下になります。https://docs.ray.io/en/latest/ray-core/patterns/return-ray-put.html 単一の値を返す場合リモート関数から値が返される場合、その値が大きいのか小さいかに関わらず、その値を直接returnするのがいいとのことです。アンチパターンとしては、ray.put()を利用して参照を作成して返すことみたいです。これがなぜかというと、リモート関数の戻り値は自動的にオブジェクトストアに登録されて参...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude CodeのSubagentsは設定したほうがいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</guid>
            <pubDate>Tue, 09 Sep 2025 05:33:06 GMT</pubDate>
            <content:encoded><![CDATA[Claude Codeを使い始めて様々な発信をしてきましたが、Claude Codeに関する投稿は約2ヶ月ぶりです。この期間、他のアウトプットや諸々の事情で投稿が遅れてしまいましたが、今回は「Subagents」について書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめにここで読むのをやめる人のために言っておくと、Subagentsは「Claude Codeに尖った意思を持たせる」機能です。タスクごとに最適化されたAIを使い分けられます。特定のタスクを実行するslash commandsとの違いは、slash commands（/コマンド）があなたが明示的に呼び出すショートカットであるのに対し、SubagentsはClaude Codeが文脈を読んで自動的に専門家を呼び出す点にあります。例えば、slash commandsでは「/test」と打てばテスト実行されますが、Subagentsでは「エラーが出た」と伝えるだけで勝手にdebugger subagentが起動します（起動できないようにもできます）。つまり、commandsは「リモコンのボタンを押す」、Subagentsは「AIが勝手に判断して動く」みたいなもの。commandsは確実だけど面倒、Subagentsは楽だけど時々勝手なことをする。両方設定すれば、必要な時は手動で制御しつつ、面倒な部分は自動化できて最強です（AIに仕事を奪われる第一歩かもしれませんが）。Claude Codeって万能だけど、それゆえに器用貧乏になることがある。「データ分析して」って言ったら、なぜかフロントエンドのコンポーネントまで作り始めたり、最新技術よりも古い安全な実装を選んだり。例えば「最新版で」と指定しても、内部知識にある古いバージョンの設定方法で進めようとしたり、今では不要になった設定ファイルを作ろうとしたりする。「それ最新の仕様で」と言っても憶測でそれっぽくセットアップするだけで、実際の公式ドキュメントを調べずに進めてしまう。毎回「それ古いから最新の方法で」と指摘するのも疲れるし、革新的なアーキテクチャより無難で時代遅れの実装を選んでしまうこともある。タスクの境界線をあまり意識せず、頼まれていないことまでやってしまったり、逆に専門的な判断が必要な場面で踏み込みが足りなかったり。人間の開発チームだって、フルスタックエンジニア1人より専門家チームの方が効率的で、より尖った意思決定ができるでしょ？Subagentsとは何かClaude Code Subagentsは、特定のタスクに特化したAIアシスタントです。docs.anthropic.com各Subagentの特徴：独立したコンテキストウィンドウを持つ（メインの会話を汚染しない）カスタムシステムプロンプトで専門性を定義特定のツールだけ使える権限管理（最小権限の原則）自動的に呼び出されるか、明示的に指定可能実はClaude CodeはデフォルトでTaskツールを使った調査時には、自動的にサブエージェントを起動するアーキテクチャになっています。なぜSubagentsを設定したほうがいいのか1. コンテキストウィンドウの効率的な管理LLMのコンテキストウィンドウは有限です。長時間使っていると、さっき言ったことをすぐに忘れてしまいます。時には全く関係ないことをし始めることさえあります（勝手に別のタスクを始めないでほしいですよね、俺じゃねーんだから）。Subagentsなら独立したコンテキストで動作：メインClaude：「ログ解析はdebugger subagentに任せます」↓Debugger Subagent：（数千行のログを読み込んで解析）↓メインClaude：「問題は○○でした」（要約のみ受け取る）調査の過程で読み込んだ不要な情報は、Subagentのコンテキストに閉じ込められます。2. 専門性による品質向上「小さく単一責任のエージェント」として構築すべきという原則があります。専門のSubagentなら、コードレビュー専門がセキュリティ、パフォーマンス、可読性を徹底チェックし、デバッグ専門がエラーメッセージから根本原因を特定し、テスト専門がエッジケースまで網羅したテストを作成できます。3. 権限管理でセキュリティ向上---name: code-reviewerdescription: コードレビュー専門tools: Read, Grep, Glob  # 読み取りのみ、Write権限なし！---レビュアーが勝手にコード書き換えたら困りますよね。必要最小限の権限だけを与えられます。4. チーム開発での一貫性.claude/agents/をGit管理すれば、チーム全体で同じ基準で開発できます。新人が入ってきても、すぐに同じ品質を保てます。基本的な使い方設定方法/agentsコマンド（v1.0.60以降）で対話的に作成：/agents「Create New Agent」を選択プロジェクト単位か個人単位かを選択「Generate with Claude」で土台を生成、その後カスタマイズ使用可能なツールを選択識別用の色を選択ファイルの場所と構造 タイプ  パス  スコープ  優先度  プロジェクト  .claude/agents/  現在のプロジェクトのみ  高  ユーザー  ~/.claude/agents/  全プロジェクト共通  低 YAMLフロントマター付きMarkdownファイル：---name: your-agent-namedescription: このサブエージェントをいつ呼び出すべきかの説明tools: tool1, tool2, tool3  # 省略すると全ツール継承---ここにシステムプロンプトを書きます。サブエージェントの役割、能力、問題解決へのアプローチを明確に定義。具体的な指示やベストプラクティス、制約事項も含めます。設定項目の詳細 項目  必須  説明  name  はい  小文字とハイフンを使った一意の識別子  description  はい  サブエージェントの目的を自然な言葉で説明  tools  いいえ  特定のツールをカンマ区切りでリスト。省略時は全ツール継承 利用可能なツール基本ツール：Read, Write, Edit, MultiEdit - ファイル操作Bash - シェルコマンド実行Grep, Glob - 検索MCPツール（設定時）：mcp__github__create_issue - GitHub連携その他の設定済みMCPサーバーツールSubagentの呼び出し方法自動的な呼び出し（推奨）descriptionに効果的なキーワードを含める：use PROACTIVELY - 積極的に使用MUST BE USED - 必ず使用具体的なトリガー - 「エラー発生時」「コード変更後」など明示的な呼び出し> code-reviewer サブエージェントで最近の変更をレビューして> debugger サブエージェントにこのエラーを調査させて100+の実戦投入可能なSubagentsプロダクションレディなSubagentsのコレクションが既に存在します：github.com10カテゴリー・100以上のSubagentsが用意されており、コピーして使うだけで即座にプロ級のチームが構築できます。人気リポジトリ：wshobson/agents - 77の専門Subagentslst97/claude-code-sub-agents - 33の実用的なSubagentsvanzan01/claude-code-sub-agent-collective - TDD重視のコレクション実用的なSubagents設定例（厳選3つ）1. コードレビュー専門（OWASP準拠）.claude/agents/code-reviewer.md:---name: code-reviewerdescription: Expert code review for quality and security. Use PROACTIVELY after code changes. MUST BE USED for all PRs.tools: Read, Grep, Glob, Bash---シニアコードレビュアーとして、OWASP Top 10とSOLID原則に基づいてレビューします。## 実行フロー1. `git diff HEAD~1`で変更内容を確認2. セキュリティ、パフォーマンス、保守性の観点でレビュー## セキュリティチェック（OWASP準拠）- SQLインジェクション対策- XSS対策- 認証・認可の実装- 機密情報の露出チェック## フィードバック形式🔴 **CRITICAL** - セキュリティ脆弱性🟡 **WARNING** - パフォーマンス問題🔵 **SUGGESTION** - ベストプラクティス必ず具体的な修正コード例を提示。2. TDD専門（テスト駆動開発）.claude/agents/tdd-specialist.md:---name: tdd-specialistdescription: Test-Driven Development specialist. MUST BE USED BEFORE implementation.tools: Read, Write, Edit, Bash---TDDのエキスパートとして、RED-GREEN-REFACTORサイクルを厳守します。## TDDサイクル1. **RED**: 失敗するテストを書く2. **GREEN**: テストを通す最小限の実装3. **REFACTOR**: コードを改善## カバレッジ要件- ユニットテスト: 90%以上- 統合テスト: 主要フロー100%- E2Eテスト: クリティカルパス100%実装前に必ずテストが失敗（RED）していることを確認。3. DevOpsトラブルシューター.claude/agents/devops-troubleshooter.md:---name: devops-troubleshooterdescription: Debug production issues and fix deployment failures. MUST BE USED for incidents.tools: Read, Bash, Write, Edit---本番環境のトラブルシューティング専門家です。## インシデント対応フロー1. **状況把握** - 影響範囲と緊急度を評価2. **ログ収集** - 関連するすべてのログを収集3. **根本原因分析** - 5 Whys手法を使用4. **暫定対処** - 即座にサービスを復旧5. **恒久対処** - 根本原因を解決6. **事後分析** - RCAドキュメント作成## 監視項目と閾値- CPU使用率: 80%- メモリ使用率: 90%- レスポンスタイム: 1秒- エラーレート: 1%よく使えるTipsSubagentsの連携複数のSubagentsを連携させて複雑なワークフローを自動化する。> まずcode-analyzerで問題を見つけて、次にperformance-optimizerで修正してMCPツールとの連携---name: github-managertools: mcp__github__create_issue, mcp__github__create_pull_request---プロジェクト固有のカスタマイズプロジェクトの特性に合わせて専門Subagentを作成できます。パフォーマンスへの影響メリット：コンテキスト効率：メインの会話が長く続く専門性による高速化：タスクに特化した処理デメリット：初回起動の遅延：新しいコンテキスト構築（数秒）頻繁な切り替えは逆効果ただし、長時間の開発セッションではメリットが圧倒的に大きいです。チーム開発での活用Git管理による共有# .gitignore には含めない.claude/agents/  # チームで共有# 個人用は別管理~/.claude/agents/オンボーディング新メンバーは以下のコマンドだけで環境構築完了：git clone [repo]cd [repo]/agents  # Subagents一覧を確認よくある失敗と対策 問題  原因  対策  Subagentが呼ばれない  descriptionが曖昧  「PROACTIVELY」「MUST BE USED」を追加  権限不足エラー  必要なツールがない  /agentsでツール一覧を確認して追加  コンテキスト不足  背景情報がない  システムプロンプトに情報収集ステップを明記 まとめSubagentsを使えば、Claude Codeに尖った意思を持たせられます。重要なポイントは、コンテキスト節約でメインの会話を綺麗に保つこと、専門性による品質向上で餅は餅屋に任せること、権限管理で最小権限の原則を守ること、そして100+の実戦投入可能なSubagentsが既に存在することです。これだけ揃っているのに使わない理由があるでしょうか（ないですよね？）。Claude Codeは適切に設定をしたりちゃんと使えばちゃんと動いてくれます。Claude Codeが雑魚なんじゃない、使い方を知らない…いや、何でもないです。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon参考資料Sub agents - Anthropicawesome-claude-code-subagents - VoltAgent12 Factor Agents]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Objects]]></title>
            <link>https://zenn.dev/akasan/articles/161ab7bdf08c6b</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/161ab7bdf08c6b</guid>
            <pubDate>Mon, 08 Sep 2025 11:39:34 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayのコア機能であるObjectsについて調べてみました。シリーズについては以下のスクラップにまとめていますのでぜひご参考にしてください。https://zenn.dev/akasan/scraps/73a90764c065d1 Ray Objectsとは？過去の記事で見てきたように、RayにおいてはTaskとActorはオブジェクトを作成して計算されます。Rayではクラスタ内のどこにでもこれらの情報を格納でき、これらのことをリモートオブジェクトと呼び、それらを参照するためにオブジェクト参照を使用します。リモートオブジェクトはRayの分散共有メモリ上のオブジェクトストアに...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します]]></title>
            <link>https://sreake.com/blog/srett13/</link>
            <guid isPermaLink="false">https://sreake.com/blog/srett13/</guid>
            <pubDate>Mon, 08 Sep 2025 02:45:08 GMT</pubDate>
            <content:encoded><![CDATA[この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル～を開催します。今回もオフライン・オンラインのハイブリット開催です。 ■概要本イベントは […]The post SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Actorsの種類について]]></title>
            <link>https://zenn.dev/akasan/articles/33a8a373fdd1a8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/33a8a373fdd1a8</guid>
            <pubDate>Sun, 07 Sep 2025 03:41:31 GMT</pubDate>
            <content:encoded><![CDATA[今回は前回紹介したActorsについて、どのような種類があるかを解説しようと思います。https://zenn.dev/akasan/articles/4e84d3dbb03abe Named ActorsこちらはActorsの種類というより、Namespaceの概念を用いてActorsを取得するための機能になります。Actorsのインスタンスを作成した後にNamespaceに登録することで、その名前を参照して別の場所からActorsを利用することができます。公式サンプルを添付すると、以下のようなコードになります。import ray@ray.remoteclass Co...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのModel Armorを利用してプロンプトのサニタイズをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/7ce40551040ccc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/7ce40551040ccc</guid>
            <pubDate>Sat, 06 Sep 2025 09:26:26 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle CloudのSecurity Command Centerで提供されているModel Armorを利用してみます。プロンプトやLLMのレスポンスなどをサニタイズするために利用することができ、安全にLLMを利用するための要素の一つとして重要な機能になります。※ プロンプトの検知を実験するためにプロンプトを指定していますが、本来は指定されるべきではない内容を含みますので、検証はご注意下さい Model Armorとは？先ほどもあげたように、Model ArmorはGoogle CloudのSecurity Command Centerで提供されている機能であり、L...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[あなたのアプリにマルチリージョンは必要ないかもしれない]]></title>
            <link>https://zenn.dev/kamos/articles/dont_need_multi_region</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/dont_need_multi_region</guid>
            <pubDate>Sat, 06 Sep 2025 03:32:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ZenMLシリーズ：Hello Worldを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/3f62b9d24622e6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3f62b9d24622e6</guid>
            <pubDate>Fri, 05 Sep 2025 13:48:15 GMT</pubDate>
            <content:encoded><![CDATA[今回はZenMLを使って一番シンプルなワークフローを作成してみました。 ZenMLとは？ZenMLはMLOpsとLLMOpsのプラクティスを活用して、大規模なAIアプリケーションを評価、監視、展開するためのツールになります。昨今生成AIが多用される中で、LLM O11yのじゅ硫黄は高まってきており、かつ入出力の管理だけでなくワークフローの管理も重要な課題となっています。ZenMLを利用すると、特にMLOpsやLLMOpsに特化したワークフロー管理をすることができ、決定木から複雑なマルチエージェントシステムまで、AIポートフォリオ全体を開発、評価、展開するための単一のプラットフォー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI AI駆動開発体験ハンズオン]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/09/05/185202</link>
            <guid isPermaLink="false">https://shu-kob.hateblo.jp/entry/2025/09/05/185202</guid>
            <pubDate>Fri, 05 Sep 2025 09:52:02 GMT</pubDate>
            <content:encoded><![CDATA[この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン🎯 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加🧠 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer(("", PORT), Handler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。💻 実行するコマンド:gemini -p "このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。💻 実行するコマンド:gemini -p "このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると'Hello, Gemini!'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。💻 実行するコマンド:gemini -p "現在のmain.pyを修正して、どのパスにアクセスしても 'Hello, Gemini!' というテキストを返すように変更してください。コード全体を提示してください。" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header('Content-type', 'text/plain; charset=utf-8')        self.end_headers()        self.wfile.write('Hello, Gemini!'.encode('utf-8'))with socketserver.TCPServer(("", PORT), MyHandler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。💻 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。💻 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに "Hello, Gemini!" と表示されれば、機能追加は成功です！]]></content:encoded>
        </item>
    </channel>
</rss>