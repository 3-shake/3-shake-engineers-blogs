<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 01 May 2025 11:34:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Rustでスクリーンショットを撮影してOpenCVで画像処理を行う方法と依存せずに使う方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/01/003411</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/01/003411</guid>
            <pubDate>Wed, 30 Apr 2025 15:34:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめにMacBookでRustを使ってスクリーンショットを撮る方法について紹介します。この記事では、次の2つのアプローチを解説します：OpenCVを活用する方法 — 画像処理の多彩な機能を利用外部ライブラリに依存しない方法 — シンプルながら効果的それぞれのアプローチには利点と課題があります。詳細なコード例を交えながら、最終的にはSlackウィンドウを自動検出する実用的なテクニックまでご紹介します。最近ではマルチモーダルAIの発展により、AIシステムもスクリーンショットの取得と分析を行うことが増えています。生成AIが画面の視覚情報を理解し、より的確な支援を提供するためには、高品質なスクリーンショット機能が不可欠です。本記事で紹介する技術は、そうしたAIシステムの視覚的入力にも応用できるでしょう。目次はじめに目次使用するクレートmacOS環境のセットアップOpenCVのインストール（OpenCVアプローチの場合）LLVMとClangのインストール（OpenCVアプローチの場合）環境変数の設定（OpenCVアプローチの場合）XCapのみのセットアップ（シンプルアプローチ）Cargo.tomlの設定OpenCVアプローチの場合OpenCVに依存しないアプローチの場合OpenCVアプローチ：基本的なスクリーンショット処理MacOSでの画像保存の問題と解決策OpenCVに依存しないアプローチ簡易な画像解析を実装する実用例：Slackスクリーンショットモニタートラブルシューティング1. libclang.dylibが見つからない場合2. OpenCVのライブラリが見つからない場合3. リンクエラー: imwrite, imencodeなどの関数が見つからないまとめ参考リンク使用するクレート今回使用する主なクレートは以下の通りです：xcap - Rust製のクロスプラットフォーム対応スクリーンキャプチャライブラリopencv - OpenCVのRustバインディング（OpenCVアプローチのみ）macOS環境のセットアップMacBookでスクリーンショット処理を行うための環境構築について解説します。OpenCVのインストール（OpenCVアプローチの場合）Homebrewを使って簡単にOpenCVをインストールできます：brew install opencvLLVMとClangのインストール（OpenCVアプローチの場合）opencv-rustクレートはバインディング生成にlibclangを使用しています：brew install llvm環境変数の設定（OpenCVアプローチの場合）OpenCVとLLVMを正しく検出するために、以下の環境変数を設定します。これらの設定は.zshrcや.bash_profileに追加しておくと便利です：# OpenCV設定export OPENCV_LINK_LIBS="opencv_core,opencv_imgproc,opencv_highgui,opencv_videoio"export OPENCV_LINK_PATHS="/opt/homebrew/lib"  # Apple Siliconの場合export OPENCV_INCLUDE_PATHS="/opt/homebrew/include/opencv4"# LLVM/Clang設定export LIBCLANG_PATH=$(brew --prefix llvm)/libexport DYLD_LIBRARY_PATH=$(brew --prefix llvm)/lib:$DYLD_LIBRARY_PATH注意: パスはApple Siliconモデルの場合です。Intel Macでは異なる場合があります。brew --prefix opencv コマンドで確認できます。XCapのみのセットアップ（シンプルアプローチ）OpenCVを使わない場合は、xcapクレートだけをインストールします：cargo add xcapCargo.tomlの設定プロジェクトのCargo.tomlファイルは以下のようになります：OpenCVアプローチの場合[dependencies]xcap = "0.0.4"opencv = { version = "0.94.4", features = ["clang-runtime"] }OpenCVに依存しないアプローチの場合[dependencies]xcap = "0.0.4"OpenCVアプローチ：基本的なスクリーンショット処理OpenCVを使ったスクリーンショット処理の基本的なコードを紹介します：use std::time::Instant;use xcap::Monitor;use opencv::prelude::*;use opencv::core::{Mat, Size, CV_8UC4};use opencv::imgproc;use opencv::highgui;fn main() -> Result<(), Box<dyn std::error::Error>> {    // OpenCVのウィンドウを作成    highgui::named_window("Screenshot", highgui::WINDOW_AUTOSIZE)?;    highgui::named_window("Processed", highgui::WINDOW_AUTOSIZE)?;    println!("Press 'q' to exit");    // メインループ    loop {        let start = Instant::now();        // プライマリモニターを取得        let monitors = Monitor::all()?;        let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))            .unwrap_or(&monitors[0]);        // スクリーンショットを撮影        let image = primary_monitor.capture_image()?;        let width = image.width() as i32;        let height = image.height() as i32;                // ピクセルデータを取得        let raw_pixels = image.as_raw();        // OpenCVのMat形式に変換        let mat = unsafe {            let mut mat = Mat::new_size(Size::new(width, height), CV_8UC4)?;            let mat_data = mat.data_mut();            std::ptr::copy_nonoverlapping(                raw_pixels.as_ptr(),                mat_data,                (width * height * 4) as usize            );            mat        };        // 元のスクリーンショットを表示        highgui::imshow("Screenshot", &mat)?;        // 画像処理の例: グレースケール変換        let mut gray = Mat::default();        imgproc::cvt_color(            &mat,             &mut gray,             imgproc::COLOR_BGRA2GRAY,             0,             opencv::core::AlgorithmHint::ALGO_HINT_DEFAULT        )?;        // エッジ検出の例        let mut edges = Mat::default();        imgproc::canny(&gray, &mut edges, 100.0, 200.0, 3, false)?;        // 処理した画像を表示        highgui::imshow("Processed", &edges)?;        // 処理時間を表示        println!("処理時間: {:?}", start.elapsed());        // キー入力を待つ（10ms）        let key = highgui::wait_key(10)?;        if key == 'q' as i32 || key == 'Q' as i32 {            break;        }    }    Ok(())}このコードは以下のことを行います：XCapを使ってプライマリモニターのスクリーンショットを撮影スクリーンショットのデータをOpenCVのMat形式に変換元のスクリーンショットを表示し、グレースケール変換とエッジ検出を適用した処理結果も表示OpenCVを使う大きなメリットは、豊富な画像処理機能を利用できることです。グレースケール変換、エッジ検出、顔認識など多様な処理が可能です。MacOSでの画像保存の問題と解決策MacOSでOpenCVのimwriteやimencode関数を使用すると、リンクエラーが発生することがあります。以下のカスタム関数を使用して回避できます：// MacOS環境のためのOpenCVラッパー関数fn save_image(filename: &str, img: &Mat) -> Result<bool, Box<dyn std::error::Error>> {    // Rustのファイル操作を使用してOpenCVのMatをPNGとして保存    println!("画像を保存しています: {}", filename);        // エンコード用のベクタ    let mut buf = opencv::core::Vector::new();        // BGR形式の画像をPNGにエンコード    opencv::imgcodecs::imencode(".png", img, &mut buf, &opencv::core::Vector::new())?;        // ファイルに書き込み    fs::write(filename, buf.as_slice())?;        Ok(true)}しかし、この関数もOpenCVのバージョンやMacOSの設定によってはエラーになる場合があります。その場合は次に説明するOpenCVに依存しないアプローチを検討することをお勧めします。OpenCVに依存しないアプローチOpenCVのリンクエラーや複雑な設定を避けたい場合は、XCapクレートのみを使用したシンプルなアプローチも可能です：use std::time::Instant;use std::fs;use xcap::Monitor;fn main() -> Result<(), Box<dyn std::error::Error>> {    println!("スクリーンショットプログラムを開始しました");    println!("終了するには Ctrl+C を押してください");    // メインループ    loop {        let start = Instant::now();        // プライマリモニターを取得        let monitors = Monitor::all()?;        let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))            .unwrap_or(&monitors[0]);        // スクリーンショットを撮影        let image = primary_monitor.capture_image()?;                // スクリーンショットを保存        let timestamp = std::time::SystemTime::now()            .duration_since(std::time::SystemTime::UNIX_EPOCH)?            .as_secs();        let filename = format!("screenshot_{}.png", timestamp);                // XCapのsaveメソッドを使用して直接保存        image.save(&filename)?;                println!("スクリーンショットを保存しました: {}", filename);        println!("処理時間: {:?}", start.elapsed());                // 適当な間隔を空ける        std::thread::sleep(std::time::Duration::from_secs(5));    }    Ok(())}このアプローチのメリットは：セットアップが格段に簡単（OpenCVやLLVMのインストールが不要）リンクエラーなどのトラブルが少ない軽量で高速一方、デメリットは：高度な画像処理機能が使えない独自の画像解析ロジックを実装する必要がある簡易な画像解析を実装するOpenCVを使わずに簡易な画像解析を行う例として、特定の色を検出するコードを示します：// 簡易な色検出機能fn detect_color(rgba_data: &[u8], width: u32, height: u32) -> bool {    // 特定の色の範囲（RGB値）    let target_lower_r = 200;    let target_lower_g = 0;    let target_lower_b = 0;        let target_upper_r = 255;    let target_upper_g = 100;    let target_upper_b = 100;        let mut target_pixel_count = 0;    let total_pixels = (width * height) as usize;        // ピクセルデータを4バイトずつ処理（RGBA）    for i in (0..rgba_data.len()).step_by(4) {        if i + 2 < rgba_data.len() {            let r = rgba_data[i];            let g = rgba_data[i + 1];            let b = rgba_data[i + 2];                        // 指定した範囲内の色かどうかを判定            if r >= target_lower_r && r <= target_upper_r &&               g >= target_lower_g && g <= target_upper_g &&               b >= target_lower_b && b <= target_upper_b {                target_pixel_count += 1;            }        }    }        // 閾値: 特定の色のピクセルが一定数以上あれば検出成功    let threshold_ratio = 0.01; // 全ピクセルの1%以上    let has_enough_pixels = (target_pixel_count as f64 / total_pixels as f64) > threshold_ratio;        has_enough_pixels}このコードはRGBA値を直接処理して、指定した色範囲のピクセル数をカウントします。単純ですが、特定の色を持つUIエレメントの検出などには十分な場合があります。実用例：Slackスクリーンショットモニター参考的な例として、Slackウィンドウを自動検出してスクリーンショットを保存するアプリケーションを作ってみましょう。以下では、OpenCVに依存しないシンプルなバージョンを紹介します：use std::time::{Instant, Duration, SystemTime};use std::fs;use std::path::Path;use std::thread;use xcap::Monitor;// スクリーンショット撮影の設定const SCREENSHOT_INTERVAL: u64 = 5; // 5秒ごとにスクリーンショットを撮影const SAVE_PATH: &str = "slack_screenshots";// 簡易なSlackウィンドウ検出機能fn detect_slack_window(rgba_data: &[u8], width: u32, height: u32) -> bool {    // Slackの紫色の範囲（RGB値）    let purple_lower_r = 100;    let purple_lower_g = 50;    let purple_lower_b = 130;        let purple_upper_r = 170;    let purple_upper_g = 100;    let purple_upper_b = 210;        let mut purple_pixel_count = 0;    let total_pixels = (width * height) as usize;        // ピクセルデータを4バイトずつ処理（RGBA）    for i in (0..rgba_data.len()).step_by(4) {        if i + 2 < rgba_data.len() {            let r = rgba_data[i];            let g = rgba_data[i + 1];            let b = rgba_data[i + 2];                        // 指定した範囲内の紫色かどうかを判定            if r >= purple_lower_r && r <= purple_upper_r &&               g >= purple_lower_g && g <= purple_upper_g &&               b >= purple_lower_b && b <= purple_upper_b {                purple_pixel_count += 1;            }        }    }        // 閾値: 紫色のピクセルが一定数以上あればSlackウィンドウと判断    let threshold_ratio = 0.001; // 全ピクセルの0.1%以上が紫色    let has_enough_purple = (purple_pixel_count as f64 / total_pixels as f64) > threshold_ratio;        // デバッグ用（閾値調整に便利）    println!("紫色ピクセル数: {}, 全ピクセル数: {}, 比率: {:.6}",         purple_pixel_count, total_pixels, purple_pixel_count as f64 / total_pixels as f64);        has_enough_purple}fn main() -> Result<(), Box<dyn std::error::Error>> {    // 保存用ディレクトリの作成    if !Path::new(SAVE_PATH).exists() {        fs::create_dir(SAVE_PATH)?;    }    println!("Slackスクリーンショットモニタリングを開始しました");    println!("スクリーンショットは{}ディレクトリに保存されます", SAVE_PATH);    println!("終了するには Ctrl+C を押してください");    let mut last_saved_time = Instant::now() - Duration::from_secs(SCREENSHOT_INTERVAL);    let mut screenshot_count = 0;    // メインループ    loop {        let current_time = Instant::now();                // 指定した間隔が経過したらスクリーンショットを撮影        if current_time.duration_since(last_saved_time).as_secs() >= SCREENSHOT_INTERVAL {            last_saved_time = current_time;                        // すべてのモニターを取得            let monitors = Monitor::all()?;            let primary_monitor = monitors.iter().find(|m| m.is_primary().unwrap_or(false))                .unwrap_or(&monitors[0]);                        // スクリーンショットを撮影            let image = primary_monitor.capture_image()?;            let width = image.width();            let height = image.height();                        // XCapのImageからRGBAデータを取得            let rgba_data = image.as_raw();                        // Slackウィンドウの検出            if detect_slack_window(rgba_data, width, height) {                // スクリーンショットを保存                let timestamp = SystemTime::now()                    .duration_since(SystemTime::UNIX_EPOCH)?                    .as_secs();                let filename = format!("{}/slack_screenshot_{}.png", SAVE_PATH, timestamp);                                // XCapのsaveメソッドを使用して直接保存                image.save(&filename)?;                                println!("Slackウィンドウを検出しました。スクリーンショットを保存: {}", filename);                screenshot_count += 1;            }        }                // CPUの負荷を下げるためのスリープ        thread::sleep(Duration::from_millis(500));    }}このアプリケーションは：定期的にスクリーンショットを撮影画面上にSlackの特徴的な紫色が一定量以上あるかを検出Slackウィンドウと判断された場合、スクリーンショットを保存トラブルシューティングMacBookでRustとOpenCVを使う際によく遭遇する問題と解決法をまとめます。1. libclang.dylibが見つからない場合エラーメッセージ:dyld: Library not loaded: @rpath/libclang.dylib解決策:brew install llvmexport LIBCLANG_PATH=$(brew --prefix llvm)/libexport DYLD_LIBRARY_PATH=$(brew --prefix llvm)/lib:$DYLD_LIBRARY_PATH2. OpenCVのライブラリが見つからない場合エラーメッセージ:Failed to find installed OpenCV package解決策:正しいパスを環境変数に設定します：export OPENCV_LINK_LIBS="opencv_core,opencv_imgproc,opencv_highgui,opencv_videoio"export OPENCV_LINK_PATHS="/opt/homebrew/lib"  # Apple Siliconの場合export OPENCV_INCLUDE_PATHS="/opt/homebrew/include/opencv4"3. リンクエラー: imwrite, imencodeなどの関数が見つからないエラーメッセージ:Undefined symbols for architecture arm64: "cv::imwrite..."解決策:1. OpenCVを完全に再インストールしてみる：   bash   brew uninstall --ignore-dependencies opencv   brew install opencv  それでも解決しない場合は、OpenCVに依存しないアプローチに切り替えるまとめこの記事では、MacBook環境でRustを使ってスクリーンショットを撮影し処理する2つのアプローチを紹介しました。OpenCVを使ったアプローチ：メリット：高度な画像処理機能が使えるデメリット：セットアップが複雑、リンク問題が発生することがあるOpenCVに依存しないアプローチ：メリット：シンプルで信頼性が高い、セットアップが容易デメリット：高度な画像処理機能を自分で実装する必要があるそれぞれのアプローチにはメリット・デメリットがありますが、用途に応じて適切な方法を選択することで、Rustの安全性と高パフォーマンスを活かした画像処理アプリケーションを開発できます。実用例として紹介したSlackスクリーンショットモニターは、このようなスクリーンショット処理の応用例の一つです。この基本的なアプローチを発展させて、画面録画ツール、監視アプリケーション、自動化ツールなど、様々な実用的なアプリケーションを開発することができます。参考リンクXCap GitHub リポジトリOpenCV Rust GitHub リポジトリOpenCV 公式ドキュメントHomebrew]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[今更ながらモンテカルロ法の再勉強 ~円周率取得編~]]></title>
            <link>https://zenn.dev/akasan/articles/e6de161b97b19d</link>
            <guid>https://zenn.dev/akasan/articles/e6de161b97b19d</guid>
            <pubDate>Wed, 30 Apr 2025 13:20:05 GMT</pubDate>
            <content:encoded><![CDATA[そういえば、モンテカルロ法で円周率の取得ができるというのはずっと前からわかっていたもののやった試しがないなということで、今回は試してみようと思います。 モンテカルロ法とはWikipediaによると、モンテカルロ法（モンテカルロほう、（英: Monte Carlo method、MC）とはシミュレーションや数値計算を乱数を用いて行う手法の総称。元々は、中性子が物質中を動き回る様子を探るためにスタニスワフ・ウラムが考案しジョン・フォン・ノイマンにより命名された手法。カジノで有名な国家モナコ公国の4つの地区（カルティ）の1つであるモンテカルロから名付けられた。ランダム法とも呼ばれる。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PR概要作成・コード改善提案ツール PR-Guardianのご紹介]]></title>
            <link>https://sreake.com/blog/pr-guardian-introduction/</link>
            <guid>https://sreake.com/blog/pr-guardian-introduction/</guid>
            <pubDate>Wed, 30 Apr 2025 08:07:36 GMT</pubDate>
            <content:encoded><![CDATA[はじめに はじめまして、Sreake事業部でインターンをしている村山です。 今回は、PR Guardianというツールの開発と検証をしました。PR GuardianはPull Requestの概要の作成、コードの改善提案 […]The post PR概要作成・コード改善提案ツール PR-Guardianのご紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA NIMを使ってみた]]></title>
            <link>https://sreake.com/blog/trying-out-nvidia-nim/</link>
            <guid>https://sreake.com/blog/trying-out-nvidia-nim/</guid>
            <pubDate>Wed, 30 Apr 2025 06:13:57 GMT</pubDate>
            <content:encoded><![CDATA[NIMとは NVIDIA Inference Microservicesの頭文字をとってNIMです。迅速なエンタープライズ対応デプロイメントのためのマイクロサービスを提供してくれます。NVIDIAのGPUで動かすことに最 […]The post NVIDIA NIMを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vimでステータスラインプラグインを遅延読み込みする]]></title>
            <link>https://blog.atusy.net/2025/04/30/vim-ekiden-lazy-load-statusline-plugins/</link>
            <guid>https://blog.atusy.net/2025/04/30/vim-ekiden-lazy-load-statusline-plugins/</guid>
            <pubDate>Wed, 30 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[ステータスラインプラグインを遅延読み込みしたい場合、単一ウィンドウならステータスラインは不要と割り切るといいよ。CTRL-Gで表示すればOK。あとは表示中のウィンドウ数をカウントして、2つ以上なら遅延読み込みするようにしよう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[pyenv+virtualenv/poetryからuvに乗り換えた話]]></title>
            <link>https://zenn.dev/akasan/articles/39f81f8bd15790</link>
            <guid>https://zenn.dev/akasan/articles/39f81f8bd15790</guid>
            <pubDate>Tue, 29 Apr 2025 02:39:58 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Pythonの仮想環境管理とライブラリ管理をuvに乗り換えた経緯と使い方などについて解説していきたいと思います。 乗り換えるまでどうしていたかuvに乗り換えるまでは、仮想環境にpyenv + virtualenv、ライブラリ管理にはpoetryを利用していました。仮想環境にpyenv+virtualenvを利用していた理由ですが、何か大きな理由があったというわけではなく、環境構築がうまくいって使い慣れていたのでずっと使っていた感じです。poetryについてはuvなどが出てくるまではスタンダードなツールだったと思います。私もその流れに乗って使っておりました。poetryを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[変わったと言っちゃえ]]></title>
            <link>https://blog.atusy.net/2025/04/29/the-changing-same/</link>
            <guid>https://blog.atusy.net/2025/04/29/the-changing-same/</guid>
            <pubDate>Tue, 29 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[わずかな変化でも認めてあげることが大事だなと、ふいに思ったのだ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[dura使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/e3b8473a703d61</link>
            <guid>https://zenn.dev/akasan/articles/e3b8473a703d61</guid>
            <pubDate>Mon, 28 Apr 2025 11:45:35 GMT</pubDate>
            <content:encoded><![CDATA[みなさん、gitレポジトリで作業中に、「コミットしないファイルを間違って削除してしまった」のようなやらかしをしたことがありませんか？一度経験するともう二度とこのような経験をしたくないと思うでしょう。今回はそのような状況になりにくくするためのツールであるduraというものをご紹介させてもらいます。 duraとは？duraの公式GitHubリポジトリから引用させてもらいますと、duraとはDura is a background process that watches your Git repositories and commits your uncommitted chan...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RAGアプリ開発ハンズオン（前編：バックエンド編）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/04/28/185621</link>
            <guid>https://shu-kob.hateblo.jp/entry/2025/04/28/185621</guid>
            <pubDate>Mon, 28 Apr 2025 09:56:21 GMT</pubDate>
            <content:encoded><![CDATA[genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get('/')def index():  return 'hello'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post('/api/hello')def hello_service(user: User):    resp = { 'message': 'Hello, {}!'.format(user.name) }    return respUSER='{"name":"平賀源内"}'curl -X POST -H "Content-Type: application/json" -d "$USER" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post('/api/llm')def llm_service(question: Question):    prompt = question.query    vertexai.init(location="us-west1") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel("gemini-2.0-flash-001") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { 'answer': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION='{"query":"プロンプトエンジニアリングとは何ですか？"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    template = """質問: {question}    ステップバイステップで考えてください。"""    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記'DISCOVERY_ENGINE_ID'を書き換えます@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = 'DISCOVERY_ENGINE_ID' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -> discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f"{location}-discoveryengine.googleapis.com")            if location != "global"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble="文献の検索結果を要約してください"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version="stable",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { 'search_result': response.summary.summary_text }    print(resp)    return respQUESTION='{"query":"情報セキュリティにおいて気をつけるべきことを教えてください"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Load Balancer Controller (LBC)でkubernetesのServiceを外部に公開する]]></title>
            <link>https://zenn.dev/kamos/articles/65c7d16bf16184</link>
            <guid>https://zenn.dev/kamos/articles/65c7d16bf16184</guid>
            <pubDate>Mon, 28 Apr 2025 05:52:13 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS LBC(Load Balancer Controller)は、EKS上のリソースとしてALBを構成するための機能です。今回はこの機能の基本的な使い方や、より高度な構成について説明します。 AWS LBCとはなにかAWS LBC(Load Balancer Controller)は、Kubernetesのリソースを監視し、AWS Elastic Load Balancerをそれにあわせて管理するコンポーネントです。AWS LBCが監視する対象は、EKS内のIngressリソースとService Type LoadBalancerリソースです。これらのKubern...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[gemma3:1bのStructured Outputを安定させる工夫]]></title>
            <link>https://blog.atusy.net/2025/04/28/gemma3-structured-output/</link>
            <guid>https://blog.atusy.net/2025/04/28/gemma3-structured-output/</guid>
            <pubDate>Mon, 28 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Structured OutputはLLMの出力をプログラムで扱いやすい形式（JSONとか）に落としこむ機能です。gemma3:1bで試してみたところ、temperatureを0にする、システムプロンプトに入力に忠実に構造化出力してと指示するなどの工夫が必要なものの、期待通りの結果を得ることができそうです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[モンティ・ホール問題をPythonで確かめてみた]]></title>
            <link>https://zenn.dev/akasan/articles/90b205bc9bca23</link>
            <guid>https://zenn.dev/akasan/articles/90b205bc9bca23</guid>
            <pubDate>Sun, 27 Apr 2025 13:02:51 GMT</pubDate>
            <content:encoded><![CDATA[みなさん、モンティ・ホール問題をご存知でしょうか？今回はPythonでモンティ・ホール問題が本当にその通りなのか計算してみました。 モンティ・ホール問題とは？これは確率の勉強をする時によく出てくる直感に反する結果となるものの例として扱われます。概要についてはWikipediaを参考にすると以下のようにまとめられます。モンティ・ホール問題（モンティ・ホールもんだい、英: Monty Hall problem）とは、確率論の問題で、ベイズの定理における事後確率、あるいは主観確率の例題の一つとなっている。モンティ・ホール（英語版）（Monty Hall, 本名：Monte Halpe...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Airflow使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/bb86a3442214da</link>
            <guid>https://zenn.dev/akasan/articles/bb86a3442214da</guid>
            <pubDate>Sat, 26 Apr 2025 10:05:07 GMT</pubDate>
            <content:encoded><![CDATA[今回はApache Airflow（以下、Airflow）について調べてみました。調べようと思った理由としては以前から名前は知っていたが調べる機会がなかったGoogle Cloudの勉強をしている中でCloud ComposerがAirflowを使っているということでどんなものか気になっていたからです。今回は本格的な調査というよりは、まずはどんなものかについて調べてみようと思います。 Apache Airflowとは？一言で言ってしまえばワークフロー管理ツールということみたいです。Pythonを使ってワークフローを構成し、スケジューリングを行ったり動作のモニタリングができ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[普段使っている技術スタック紹介]]></title>
            <link>https://zenn.dev/akasan/articles/766c1c3539e778</link>
            <guid>https://zenn.dev/akasan/articles/766c1c3539e778</guid>
            <pubDate>Fri, 25 Apr 2025 14:41:45 GMT</pubDate>
            <content:encoded><![CDATA[今回もすごい簡潔になりますが、普段自分が使っている技術スタックとかを紹介しようと思います エディタ neovimneovimを一応使うことが多いです。ただしガチのvimmerではないので拡張機能をたくさん入れたりはできていません。また、比較的温和なタイプのvimmerなので、本格的に使ってる人からすると「なんでちゃんと使わないんだ」と怒られそうな気がしますw cursor小規模なコード修正とかは基本neovim使ってるんですが、大規模開発とかをする必要がある場合はcursorを使ってます。ただ拡張機能でvimのキーバインド入れているので使い勝手はvimですwcursor...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合]]></title>
            <link>https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/</link>
            <guid>https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/</guid>
            <pubDate>Fri, 25 Apr 2025 12:27:40 GMT</pubDate>
            <content:encoded><![CDATA[Sreake事業部の荒木です。KubernetesやSRE、LLM領域の関連技術など幅広い領域にわたって調査・検証を行っています。 今回、kubernetesクラスタのE2Eテストを統合、管理することができるTestku […]The post Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します]]></title>
            <link>https://sreake.com/blog/sre-tech-talk-12/</link>
            <guid>https://sreake.com/blog/sre-tech-talk-12/</guid>
            <pubDate>Fri, 25 Apr 2025 11:45:29 GMT</pubDate>
            <content:encoded><![CDATA[この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を、2025年5月16日（金）に開催します。The post SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIにペアプロのナビをさせるaibou.nvimを作った]]></title>
            <link>https://blog.atusy.net/2025/04/25/aibou-nvim/</link>
            <guid>https://blog.atusy.net/2025/04/25/aibou-nvim/</guid>
            <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[atusy/aibou.nvimはAIをペアプロのナビに変身させるNeovimプラグインです。テキストの変更を逐次把握し、リアクションしてくれるので、まるで人間がナビについてくれているような体験を得られます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年4月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/9b2e5528548353</link>
            <guid>https://zenn.dev/akasan/articles/9b2e5528548353</guid>
            <pubDate>Thu, 24 Apr 2025 13:32:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はいつもに比べてさらに短編になりますw特に技術書に絞りまして、最近または過去読んでいて良かったと思う本について紹介していこうと思います。 クラウド系 徹底攻略 Google Cloud認定資格 Associate Cloud Engineer教科書クラウドといえば、Google Cloudに入門するために買ったこの本がまず第一ですね。Associate Cloud Engineerを取るために大変お世話になりました。https://book.impress.co.jp/books/1122101107 Google Cloudではじめる実践データエンジニアリング入門...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500</guid>
            <pubDate>Thu, 24 Apr 2025 02:35:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは、nwiizoです。2025年4月22日と23日、スケジュールの都合で連続して2つの技術イベントに登壇することになりました。それぞれのイベントは異なる切り口でしたが、どちらも「生成AI」をテーマにしたものでした。1日目は「生成AI」と「クラウドネイティブ」の融合、2日目は「生成AI」の「Model Context Protocol（MCP）」に焦点を当てました。生成AI技術は近年急速に進化し、私たちエンジニアの働き方に大きな影響を与えています。私自身も数年前からnvimでGitHub Copilotを日常的に使い、その後Clineなどのコーディングエージェントブームのバズに押されつつもCursorやVSCodeを利用しています。同時に、Cloud Native技術も着実に成熟し、多くの企業のインフラ戦略の中核となっています。現在、これら二つの技術領域が交わることで、特にIaC（Infrastructure as Code）分野での応用が活発化しています。多くの開発者がこの統合に関して様々な課題に直面しており、今回の登壇では、そうした課題に対する私なりの考察と解決策を共有しました。本ブログでは、この2日間の登壇内容を振り返りながら、技術的な洞察やコミュニティでの議論から得た気づきを記録したいと思います。生成AIとクラウドネイティブ技術の統合が開発・運用プロセスを根本から変革しています。本稿はエンジニアが直面する「70%問題」（AIがコードの70%は正確に生成するが、残り30%で致命的ミスを犯す現象）に対して、ガードレールとModel Context Protocol (MCP)の相補的活用による解決策を提案します。インフラ/アプリケーションエンジニアは「思考パートナー」としてAIを活用し、検証文化を確立することで、開発効率と品質を両立できます。本記事では、両イベントでの登壇内容をもとに、AIを単なるツールから戦略的パートナーへと位置づけ直す視点と、認知労働の新たな分担を実現する実践的なフレームワークについて詳しく解説します。Day 1: 生成AIとCloud Nativeの融合を語るイベント: CloudNative Days Summer 2025 プレイベント登壇タイトル: 生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について日時: 2025年4月22日https://cloudnativedays.connpass.com/event/351211/cloudnativedays.connpass.com1日目は、CloudNative Days Summer 2025のプレイベントに参加しました。このイベントの参加者層は主にインフラエンジニアやSRE（Site Reliability Engineer）が中心で、Cloud Native技術への関心が高い方々です。私のセッションでは、生成AIを活用したCloud Native基盤構築について、実践的な観点から解説しました。発表資料 speakerdeck.com発表の詳細セッション内容は以下の4つの大きなセクションに分けて構成しました：1. 生成AIとCloud Nativeの現在地（2025年）まず、現在の生成AIによる開発プロセスの変化について解説しました。従来のコード生成から問題解決支援へと進化しており、AIは単なる「道具」から「思考パートナー」へと変わりつつあります。これは根本的な変化であり、単なる機能向上ではありません。AIが書かれるコードの構文パターンだけでなく、構築されるものの概念モデルに関与できるようになった結果、協働のダイナミクスが質的に変化しています。AIの利用パターンも単発指示→会話型→継続的協働へと発展し、長期的な文脈理解ができるようになっています。これにより、開発ワークフローも大きく変化しています。- コードレビューの前段階をAIが担当し、人間は高次の設計判断に集中- ボイラープレートコードからの解放で、より創造的な作業への時間が増加- テスト品質の標準化によるソフトウェア信頼性の向上しかし実際のところ、AIによるCloud Native実装は「完璧」ではなく、「ある程度必要」な取り組みとして捉えるべきだと強調しました。現場では、以前は「動かない定義」や「架空の機能」に悩まされましたが、モデルの精度向上により問題は大幅に減少しています。それでも、いわゆる「ハルシネーション」と呼ばれる問題は依然として存在するため、AIの出力を盲信せず、検証する姿勢が重要です。特にIaC（Infrastructure as Code）においては、コードと実際のインフラの間に差異が生じることも珍しくありません。AIが生成したインフラ定義は、理想的な環境を想定していることが多く、実際の環境の制約やレガシーシステムとの互換性といった現実的な問題に対応できていないケースがあります。そのため、多くの組織では完全自動化ではなく、ある程度抽象化したり省力化したりしながら、人間による確認と調整を組み合わせたハイブリッドなアプローチを採用しています。これにより、AIの効率性と人間の判断を最適に組み合わせたCloud Native環境の管理が実現されています。learning.oreilly.com2. 実践的なプロンプト設計効果的なAI活用のための「プロンプト設計の5原則」を紹介しました：方向性を与える（Give Direction）具体的な指示や目的を明確に示す例：「高可用性と費用対効果を重視したプロダクション環境向けECSクラスタを作成するTerraformコード」のように具体的にフォーマットを指定する（Specify Format）望ましい出力形式を明確に定義する例：コーディングスタイル、ファイル分割方針などを明示的に記述例を提供する（Provide Examples）期待する出力のサンプルを示す既存の成功パターンを参考に提示する品質を評価する（Evaluate Quality）生成された結果の品質を測定・改善する方法を組み込むセキュリティ、可用性、コスト最適化などの観点を明示作業を分割する（Break Down Tasks）複雑なタスクをより小さな段階に分割するステップバイステップのアプローチを促すこれらの原則を実践することで、生成AIからより質の高い出力を得られることを実例とともに解説しました。また、コンテキスト同梱の重要性についても言及し、意思決定の背景や根拠を明示的に残すことで、組織の暗黙知が形式知化される利点を強調しました。learning.oreilly.com3. ガードレールの構築の手引き生成AIの出力に対する「ガードレール」の重要性を解説しました。ここで特に強調したのが「70%問題」です。これは単なる効率の問題ではなく、ロジスティクスにおける「ラストマイル問題」やロボティクスにおける「不気味の谷」に類似した現象です。完成に近づくほど、残りの課題は不釣り合いに困難になります。しかし、インフラストラクチャにおいて、この残りの30%は単に非効率なだけでなく、潜在的に壊滅的な問題を引き起こす可能性があります。生成AIは通常、コードの約70%は驚くほど正確に生成できますが、残りの30%で致命的なミスを犯すことがあります。特にIaCのような厳密性が求められる領域では、この問題が顕著です。AWS IAMポリシー生成時に過剰な権限を付与する傾向リソース間の複雑な依存関係の理解不足コスト最適化を考慮しない設計提案これを「優秀だが何も確認しない若手開発者」と表現し、スピードは速いがIaC特有の制約を無視してしまう傾向があることを指摘しました。この問題への対策として、以下のようなガードレールを提案しました：コード品質検証構文チェック、静的解析、コーディング規約の自動適用セマンティック検証リソース間の整合性や依存関係の正確性を検証セキュリティ検証脆弱性スキャン、最小権限原則の適用コンプライアンス検証組織ポリシーや法規制への適合性確認コスト最適化検証リソース効率や予算管理の自動チェックこれらのガードレールは、特にPull Requestの段階で自動適用することで、問題の早期発見と修正を可能にします。また、単なる検証だけでなく、AIの解釈コストを考慮した仕様の記述方法についても言及しました。syu-m-5151.hatenablog.com4. ガードレールを超えて行動するMCP最後に、Model Context Protocol（MCP）を活用した次世代のAI活用法について紹介しました。MCPはAIモデルが外部ツールやデータにアクセスするための標準プロトコルで、「AIとシステムをつなぐUSB規格」とも表現できます。しかし、この比喩は理論的な重要性を過小評価しています。USBは物理的な接続を標準化しましたが、MCPは認識論的な接続—知識がどのようにアクセス、検証、適用されるかを標準化しているのです。MCPとガードレールの補完関係は弁証法的関係とも言えます。ガードレールは出力の「安全性」「品質」を確保（アウトプット品質）MCPは入力の「情報量」「正確性」を向上（インプット品質）この相補的な関係は、次のような弁証法的パターンを形成します。テーゼ：AIは限られたコンテキストに基づいてコードを生成アンチテーゼ：人間はガードレールを通じてこのコードを検証・修正統合：MCPはAIのコンテキストを拡張し、検証の必要性を減少（ただし排除はしない）両者を組み合わせることで、70%問題の克服に近づける可能性を示しました。ただし、人間の判断の必要性は排除されるのではなく、人間の役割が「構文の検証者」から「概念的アプローチの検証者」へとシフトします。これは認知的労働の分担の進化を示唆しています。実際の活用例として、AWS MCP ServersやGoogle Cloudのkubectl-aiなどを紹介し、これらがクラウド環境とAIの連携を実現し、複雑なインフラ管理を自然言語で操作可能にする機能について説明しました。syu-m-5151.hatenablog.com質疑応答での議論セッション後の質疑応答では、特に以下の点について活発な議論がありました：AIによるIaC生成の信頼性向上のための具体的な取り組み組織への導入方法とチーム全体でのAI活用ポリシーCI/CDパイプラインへのガードレール組み込みの実践例特に印象的だったのは、「AIを100%信頼せず、人間の検証を常に行う文化をどう作るか」という質問で、これはまさに今のAI活用における核心的な課題だと感じました。Day 2: MCPの世界を掘り下げるイベント: AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-登壇タイトル: ここはMCPの夜明けまえ日時: 2025年4月23日https://hack-at-delta.connpass.com/event/350588/hack-at-delta.connpass.com2日目は、AI駆動開発に特化したイベントで登壇しました。こちらは主にアプリケーション開発者やAI研究者が中心の聴衆で、より技術的に深い内容を求められる場でした。私のセッションではModel Context Protocol（MCP）について詳しく解説し、実装例や将来展望について語りました。発表資料 speakerdeck.com発表の詳細MCPの基本概念から始め、その主要構成要素について詳しく解説しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得・検証する「認識論的インターフェース」とも言えるものです。この枠組みは、人間の認知プロセスを模倣しながらも、機械による利用のために標準化しています。modelcontextprotocol.io1. Resources（リソース）MCPにおけるResourcesは、LLMにコンテキストを提供する読み取り専用のデータソースです。テキスト形式とバイナリ形式のデータをURIで一意に識別し、AIの会話コンテキストとして活用します。アプリケーション制御型設計: クライアントがリソースの使用時期と方法を決定人間が読みやすい名前や説明: AIの理解を促進するためのメタデータ付き動的リソース: URIテンプレートを提供して、パラメータ化されたリソースアクセスが可能クライアントはresources/listエンドポイントでリソース発見、resources/readで内容取得、さらに購読機能で更新通知を受信できます。これにより、AIは最新のドキュメントや構成情報などを参照しながら回答を生成できるようになります。2. Prompts（プロンプト）Promptsは標準化された対話パターンを定義するテンプレートです。ユーザー制御型の再利用可能なテンプレートとして設計され、一貫したLLM体験を提供します。動的な対話フロー: 引数を受け取り、リソースから文脈を含め、複数の対話をチェーン化構造化された定義: 各プロンプトは名前・説明・引数の構造で定義クライアントインターフェース: prompts/listエンドポイントで発見し、prompts/getで使用プロンプトはリソースからの情報を埋め込み、複数のメッセージ交換を事前定義して複雑な対話フローを作成可能です。クライアントUIではスラッシュコマンドやクイックアクションとして表示され、ユーザーに直感的な操作を提供します。3. Tools（ツール）Toolsは LLM に実世界での行動力を与える機能です。サーバーが公開する実行可能な機能を介して計算処理やAPI操作を実行できます。明確な構造: 各ツールは名前、説明、入力スキーマ、アノテーションで定義動作特性の明示: 読取専用・破壊的操作・べき等性などの情報を含むエンドポイント: クライアントはtools/listで発見し、tools/callで実行ツールの用途は多岐にわたり、システム操作、外部APIラッパー、データ変換など様々なパターンでAIの能力を拡張し、実世界での影響力を高めます。4. Sampling（サンプリング）Samplingは、サーバーがLLMに補完を要求できる機能です。クラスチートを行うことなく、会話中にLLMの判断を活用できる仕組みを提供します。メカニズム: サーバーがsampling/createMessageを要求し、クライアントがレビュー後にLLMから結果を取得ヒューマンインザループ設計: ユーザーが介在することでセキュリティとプライバシーを確保柔軟な設定: 様々なパラメータで出力を調整可能（temperature、maxTokens、stopSequencesなど）サンプリングによって、エージェント的ワークフローが可能になり、データ分析、意思決定、構造化データ生成、複数ステップのタスク処理などの高度な機能を実現できます。5. Roots（ルーツ）Rootsはサーバーの操作範囲を定義する機能です。クライアントがサーバーに対して関連リソースとその場所を伝える手段として機能します。操作境界の定義: ファイルシステムパスやHTTP URLなどの有効なURIを使用ワークスペース明確化: クライアントは接続時に推奨ルーツのリストを提供柔軟な範囲設定: プロジェクトディレクトリ、リポジトリ、APIエンドポイントなどを定義Rootsにより、AIの操作範囲が明確化され、異なるリソースを同時に扱う際の組織化が容易になります。実装例と活用可能性セッションの後半では、実際のMCP実装例を紹介しました。よく紹介されているMCPを紹介してもどうしようもないので他に知見になりそうでかつ応用が効きそうなMCPを紹介しています。AWS MCP ServersAWSが提供する公式MCP実装について説明しました。github.comAWS Documentation MCP Server: AWS公式ドキュメント検索と情報提供Bedrock Knowledge Bases MCP Server: カスタムナレッジベース連携CDK MCP Server: AWS CDKプロジェクト支援Terraform MCP Server: Terraformプロバイダー情報参照Lambda MCP Server: 任意のLambda関数をMCPツールとして実行kubectl-aiGoogle Cloudの大規模言語モデルを活用したkubectlプラグインについても解説しました。github.comkubectl ai "nginxのDeploymentを作成して、レプリカ数は3、リソース制限ありで"kubectl ai "なぜPodがPendingのままなのか調査して"kubectl ai "payment-serviceのレプリカを3から5に増やして"このような自然言語コマンドでKubernetesクラスタを操作できる例を紹介し、MCPによる実用的な活用方法を示しました。自作MCP実装の可能性MCPの実装を通じて得られる知見の価値について触れ、「MCPは実装してこそ理解できる。実装を通じて感覚を掴み、独自の拡張も検討できる」と強調しました。github.comMCPの課題と展望MCPの将来性について議論する中で、現状の課題も率直に指摘しました：レスポンス時間の増加: 外部API呼び出しによる遅延情報統合の難しさ: 矛盾する情報の調停コンテキスト長の制限: 大量のデータ処理における限界ハルシネーション問題: 情報アクセスは改善するが、解釈ミスの可能性は残る70%→100%ではなく、実際には70%→80%程度の改善が現実的な期待値であり、人間による最終確認は依然として重要であることを強調しました。これは漸近的な信頼性向上であり、段階的な変化ではないことを示唆しています。この分野には以下のような興味深い理論的緊張関係が存在します。信頼 vs 検証: 人間による検証の持続的な必要性は、完全に自動化された開発の約束と矛盾します。一般性 vs 特殊性: AIは一般的なパターンに優れていますが、ドメイン固有の制約に苦戦する一方、人間はその逆の傾向があります。速度 vs 信頼性: AIによる開発の加速は、増加する検証負担とのバランスが必要です。抽象化 vs 実装: エンジニアがより抽象的な思考にシフトするにつれ、実装の詳細とのつながりが弱まり、新しい種類のエラーが生じる可能性があります。連日登壇を通じて感じたこと2日間の登壇を通じて、生成AIとクラウドネイティブの融合が急速に進んでいることを実感しました。特に印象的だったのは、両者の接点において：1. 補完し合う技術領域Day 1で話したガードレールとDay 2で紹介したMCPは、互いに補完する関係にあります。ガードレールがAIの出力の「安全性」「品質」を確保し、MCPが入力の「情報量」「正確性」を向上させます。この組み合わせこそが、AIの能力を最大限に引き出すための鍵です。例えば、MCPで外部情報を参照しながらIaCコードを生成し、それをガードレールで検証するというパイプラインを構築することで、より信頼性の高いインフラ構築が可能になります。これは認知労働の新たな分担を示唆しています。パターンマッチングとリコールが機械のドメインになり、概念的統合と判断が人間のドメインとして残ります。この協業体制がもたらす最も深い洞察は、我々が「プログラミングの終焉」ではなく「プログラミングの新たな改革」を目撃しているということかもしれません。2. 実装の成熟度の差技術の普及段階にも明確な違いがあります。Cloud Native環境でのAI活用は既に実用段階に入っていますが、MCPはまさに「夜明け前」の状態です。標準化は進んでいるものの、実装はまだ発展途上であり、今後急速に普及していくでしょう。特に興味深いのは、大手クラウドプロバイダーが相次いでMCP実装を提供し始めていることで、これはMCPが業界標準になりつつある証拠と言えます。現在、私たちは重要な技術的変曲点に立っているのです。3. 共通する課題どちらの領域でも、ハルシネーション（幻覚）問題や70%問題など、AIの限界をどう乗り越えるかが共通の課題となっています。完全自動化への過信は危険であり、人間による検証と理解が依然として不可欠です。重要なのは、AIをただの便利ツールではなく、自分の技術的判断力を強化するための「知的パートナー」として活用する姿勢です。優れたエンジニアは、AIの提案を鵜呑みにせず、自らの専門知識と経験に基づいて評価し、改善します。つまり、エンジニアとしての基本的な理解力や技術センスがあってこそ、AIとの協働が真に価値を生み出すのです。両イベントの参加者との議論を通じて、多くの組織がAIツールの導入に熱心である一方で、その限界や適切な活用方法についての理解はまだ発展途上であることを実感しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得し検証する「認識論的枠組み」を表しています。これはAIと人間のコラボレーションにおける根本的なシフトを示唆しています。認知労働の新たな分業開発現場では、AIを全能の魔法ではなく、特定の目的に特化した強力な助手として位置づけています。これは認知労働の新たな分業を形成しています。戦略的なAI活用アプローチ私のチームでは、AIツールを以下のような明確な目的で活用しています。プロトタイピングの加速: 新機能やアイデアの初期実装を迅速に行い、議論の土台を作るルーティン作業の自動化: テストコード生成やボイラープレートコードなど、創造性を必要としない作業の効率化知識探索の支援: ドキュメント検索やAPI仕様の理解など、情報収集を効率化コードレビューの補助: 基本的なコーディング規約やベストプラクティスのチェックこれらの活用方法は、AIと人間の間の認知労働の分業を最適化するものです。AIはパターン認識や情報検索に優れている一方、人間はコンテキスト理解や倫理的判断に長けています。この相補的な関係を活かすことで、開発効率と品質の両方を高めることができます。レビュープロセスと制約の重要性生成AIの限界を認識した上で、以下のようなガードレールを設けています。書き込み権限の制限: 生成コードは必ずレビューを経てから取り込む、というかまだ道具として適切に動作し続けることができない重要な判断の人間による最終確認: 特に権限設計やセキュリティ関連の実装対話的な生成プロセス: 一度に大量のコードを生成するのではなく、段階的に生成・修正を繰り返すこれらの制約は一見効率を下げるように思えますが、長期的には品質と信頼性の向上につながっています。これは、速度と信頼性のトレードオフを認識し、適切なバランスを取る試みと言えるでしょう。まとめ生成AIとCloud Nativeは、かつて独立した技術領域として発展してきましたが、現在その境界線は急速に溶け合いつつあります。この2日間の登壇を通じて、両技術の融合がもたらす無限の可能性と避けられない課題を、互いに補完し合う視点から考察できたことは非常に意義深い経験でした。技術の交差点に立つ私たちは、単に新しいツールを導入するだけでなく、開発プロセス全体の再構築と認知労働の新たな分担という本質的な変革の只中にいます。連日の登壇準備は骨の折れる作業でしたが、技術コミュニティの旺盛な好奇心と革新への情熱に触れることができ、その労力を遥かに上回る充実感を得ることができました。この変革の中心には、いくつかの興味深い理論的緊張関係が存在します。信頼と検証のジレンマでは、AIの自律性向上と人間による検証の継続的必要性が矛盾します。一般と特殊の相克では、AIが一般パターンに秀でる一方、ドメイン固有の制約に弱く、人間はその逆の強みを持つという相補性があります。速度と信頼性のトレードオフでは、開発速度の飛躍的向上と増大する検証負担のバランスが求められます。そして抽象化と実装の乖離では、エンジニアの思考が高次の抽象レベルへ移行するほど、具体的実装との接点が希薄化する現象が起きています。これらの緊張関係は、単なる技術的課題ではなく、ソフトウェア開発の本質的な変容を示唆しています。クラウドネイティブと生成AIの交差点に立つ私たちは、新たな技術パラダイムの構築者として、これらの緊張関係を認識しながら、持続可能な開発文化の創造に取り組む必要があります。syu-m-5151.hatenablog.com今日から俺は今後、プログラマの役割は根本から変容していくでしょう。コードを書く職人からドメインを抽象化し構成要素を再構築する建築家へと、その専門性は高度化していきます。この変化は、ソフトウェアエンジニアリングの本質における歴史的な転換点を示唆しています。www.oreilly.comこの転換点で、エンジニアの進化には二つの道筋が開かれていると思っています。ひとつはドメインエキスパートとしての道で、AIが容易に獲得できない専門知識を磨き、AIを疑い検証するメンタリティを養い、専門知識をMCPやFunction Callingとして実装し、自らが「検証者」としての価値を高める方向性です。もうひとつはパイプライン設計者としての道で、コードを直接書くのではなく、コードを生成・検証・デプロイするシステムを構築し、プロンプトエンジニアリングの技術を磨き、言語化・設計・検証のスキルを研ぎ澄まし、AIの限界を理解しそれを補完するシステムを構築する方向性です。これらの進化は、かつてのアセンブリから高水準言語への移行や、手続き型からオブジェクト指向プログラミングへの移行に似ています。各移行は低レベルの懸念事項を抽象化し、エンジニアがより高レベルのアーキテクチャに集中できるようにしてきました。私たちはいま、そのような歴史的変革の真っただ中にいるのです。最後に、この貴重な機会を提供してくださったCloudNative Days Summer 2025プレイベントおよびAI駆動開発実践の手引きイベントの運営チームの皆様に心より感謝申し上げます。両イベントの緻密な運営と温かいサポートのおかげで、充実した登壇体験ができました。また、質疑応答で鋭い質問を投げかけ、議論を深めてくださった参加者の皆様にも深く感謝いたします。これからも技術コミュニティの発展に微力ながら貢献していきたいと思います。あとがき1日目の資料は出来があまりよくなかった。良い資料だとは思うが自分の中でもう少し整理や深堀りができたはずだし、語り尽くせなかった部分もとても多い。時間がなかったという言い訳をさせてください。そもそも、CfPも落ちて本イベントでの登壇の機会も逸してしまっている。一方、2日目のMCPの資料はよくできたと思う。元々のブログがあったというのもある。正直これは100点満点中90点ぐらいの出来栄えだと自負していた。夜を徹して準備し、最新の技術動向を盛り込み、実装例も丁寧に解説した。聴衆からの反応も上々で、「これ以上ない資料ができた」とさえ思っていた。そんな矢先、mizchi氏のAfter Cline - あるいは語りえぬ者について語ろうとする時代についてという資料を目にした瞬間、天と地の差を見せつけられた気分だった。あれは単なる150点の資料ではない。次元が違う。まるで将棋で「自分は十分に読んだ」と思った直後に、相手が5手先の必勝手順を淡々と指し示すような絶望感。技術的な深さ、哲学的考察、そして何より言語化能力の圧倒的差...。悔しさで夜も眠れない。次回こそは、このリベンジを果たしてみせる。いや、リベンジすらおこがましい。あの高みに少しでも近づけるよう、もっと考察を深めなければ。とにかく、とても、とても悔しい...。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[自分用コマンドにはプレフィックスつけるとよさげ]]></title>
            <link>https://blog.atusy.net/2025/04/24/prefix-personal-commands/</link>
            <guid>https://blog.atusy.net/2025/04/24/prefix-personal-commands/</guid>
            <pubDate>Thu, 24 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[~/.local/bin/T-hogeみたいにT-とかのprefixつけておくと、補完が効いて便利。大文字にしとくと、被りも少ないよ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Cloud Architect編~]]></title>
            <link>https://zenn.dev/akasan/articles/4d7972b7c5f84c</link>
            <guid>https://zenn.dev/akasan/articles/4d7972b7c5f84c</guid>
            <pubDate>Wed, 23 Apr 2025 12:53:56 GMT</pubDate>
            <content:encoded><![CDATA[この記事の続編になります。https://zenn.dev/akasan/articles/6b5d5f9b1446d4 Professional Cloud ArchitectについてProfessional Cloud Architect（以下、PCA）は、公式では以下のように説明されています。Professional Cloud Architects は、組織が Google Cloud 技術を利用できるように支援します。クラウドアーキテクチャと Google Cloud に関する専門的な知識を活かして、ビジネス目標を実現するために、スケーラブルで高可用性を備え、堅牢か...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenFeature を使ったアプリケーション開発]]></title>
            <link>https://sreake.com/blog/openfeature-feature-flag-management/</link>
            <guid>https://sreake.com/blog/openfeature-feature-flag-management/</guid>
            <pubDate>Wed, 23 Apr 2025 09:40:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめに はじめましての方も、そうじゃない方も、こんにちはこんばんは。Sreake 事業部 佐藤慧太(@SatohJohn)です。 皆さん、アプリケーションのコードを変更せずに機能の有効無効を切り替えることができる Fe […]The post OpenFeature を使ったアプリケーション開発 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ここはMCPの夜明けまえ]]></title>
            <link>https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae</link>
            <guid>https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae</guid>
            <pubDate>Wed, 23 Apr 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-- 公式URL: https://hack-at-delta.connpass.com/event/350588/📝 登壇ブログ- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dockerを使用せずにイメージを作成し実行してみる - go-containerregistryによる実装]]></title>
            <link>https://qiita.com/m_pig/items/82643135254b5b326e61</link>
            <guid>https://qiita.com/m_pig/items/82643135254b5b326e61</guid>
            <pubDate>Wed, 23 Apr 2025 02:38:27 GMT</pubDate>
            <content:encoded><![CDATA[このページではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコン…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[home row mods無理だったわ]]></title>
            <link>https://blog.atusy.net/2025/04/23/give-uphome-row-mods/</link>
            <guid>https://blog.atusy.net/2025/04/23/give-uphome-row-mods/</guid>
            <pubDate>Wed, 23 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[home row modsはホームポジションにあるasdfなどのキーを長押しでShiftやCtrlなどの修飾キー化する仕組みです。私はKeyball 61のファームウェアの設定変更で導入してみましたが、あまりの誤入力の多さに撤退を決意しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Taskfile（taskコマンド）のfish補完定義を改善してグローバルタスクに対応した]]></title>
            <link>https://blog.atusy.net/2025/04/23/cloud-run-with-iam/</link>
            <guid>https://blog.atusy.net/2025/04/23/cloud-run-with-iam/</guid>
            <pubDate>Wed, 23 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Taskfile（taskコマンド）は、数あるタスクランナー／ビルドツールの1つです。Makefile代替とも言えますね。詳しくは公式サイト（https://taskfile.dev/）や「Taskfileを使ってみよう」などの記事を参考にしてもらうとして、個人的にTaskfileを好んでいる理由をいくつか挙げておきます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cuMLとsklearnを簡易比較してみた]]></title>
            <link>https://zenn.dev/akasan/articles/e7d9b92bf6dee2</link>
            <guid>https://zenn.dev/akasan/articles/e7d9b92bf6dee2</guid>
            <pubDate>Tue, 22 Apr 2025 14:54:06 GMT</pubDate>
            <content:encoded><![CDATA[cuMLとは？今回利用するcuMLを説明する前に、RAPIDSについて紹介します。RAPIDSとは公式の説明を引用すると最も広く使用されているオープンソース データ ツール群と互換性のある API を備えた、GPU で高速化されたデータ サイエンスおよび AI ライブラリのオープンソース スイートです。データ パイプライン全体にわたりパフォーマンスを桁違いで大規模に高速化できます。ということです。要は、NVIDIA GPUを効率よく使うためのライブラリをユースケースごとに提供してくれているということです。詳しくは以下の公式リンクを参照ください。https://develo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[EKS Pod Identityを利用してセキュアにkubernetesリソースからAWSリソースにアクセスする]]></title>
            <link>https://zenn.dev/kamos/articles/873ecca3f9bab0</link>
            <guid>https://zenn.dev/kamos/articles/873ecca3f9bab0</guid>
            <pubDate>Tue, 22 Apr 2025 09:37:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS EKS (Elastic Kubernetes Service) を利用している場合、Kubernetes上のリソースだけで完結させることはほぼなく、多くの場合、kubernetesの世界にないAWSリソースにアクセスする必要があります。例えば、S3バケットへのファイルのアップロード、DynamoDBのテーブルへのデータの読み書き、SQSキューへのメッセージの送受信など、様々なユースケースが考えられます。その際に使用するのがPod Identityです。https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/p...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について]]></title>
            <link>https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite</link>
            <guid>https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite</guid>
            <pubDate>Tue, 22 Apr 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。---本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: CloudNative Days Summer 2025 プレイベント- 公式URL:https://cloudnativedays.connpass.com/event/351211/ - イベントのURL: https://event.cloudnativedays.jp/cnds2025📝 登壇ブログ- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerの独自言語「LookML」とは]]></title>
            <link>https://sreake.com/blog/looker%e3%81%ae%e7%8b%ac%e8%87%aa%e8%a8%80%e8%aa%9e%e3%80%8clookml%e3%80%8d%e3%81%a8%e3%81%af/</link>
            <guid>https://sreake.com/blog/looker%e3%81%ae%e7%8b%ac%e8%87%aa%e8%a8%80%e8%aa%9e%e3%80%8clookml%e3%80%8d%e3%81%a8%e3%81%af/</guid>
            <pubDate>Tue, 22 Apr 2025 03:29:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 2023年10月にGoogleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されてから、早1年と半年程が経ちました。 もしかすると、「Lookerを導入してみた」「ま […]The post Lookerの独自言語「LookML」とは first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DagsHub使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/7efdcc1c2d4141</link>
            <guid>https://zenn.dev/akasan/articles/7efdcc1c2d4141</guid>
            <pubDate>Mon, 21 Apr 2025 12:01:16 GMT</pubDate>
            <content:encoded><![CDATA[今回はAIのデータやモデルについて管理することに重きを置いたDagsHubというサービスについて、その紹介と使い方をご紹介していこうと思います。 DagsHubとは？一言で言うと、データサイエンスに関わるコードだけでなくデータについても合わせて管理するためのレポジトリを提供してくれるサービスです。コードの管理だけであればGitHubなどで問題ありませんが、いわゆるdvcを利用したデータ管理を行っているようなプロジェクトであったり、複数人でチームを組んで開発するデータサイエンスプロジェクト向けのレポジトリを探している場合は選択肢としてDagsHubも候補かと思います。特徴として、DA...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimも進化するMCPHubとAvante.nvimの連携ガイド]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837</guid>
            <pubDate>Mon, 21 Apr 2025 01:18:37 GMT</pubDate>
            <content:encoded><![CDATA[はじめにModel Context Protocol（MCP）は、LLM（大規模言語モデル）と外部システムの間の通信を可能にする標準化されたプロトコルです。これにより、LLMに追加のツールやリソースを提供して、その能力を拡張できます。MCPは、開発者がLLMに外部機能へのアクセスを提供するための統一された方法を提供します。簡単に言えば、MCPはLLMが「外の世界」と対話するための共通言語です。これにより、ChatGPTやClaudeなどのAIが、ファイルやウェブサイトを読み書きしたり、コマンドを実行したり、LSP（Language Server Protocol）の診断情報にアクセスしたりできるようになります。syu-m-5151.hatenablog.comMCPHub.nvimMCPHub.nvimは、MCPサーバーをNeovimワークフローに統合するための強力なプラグインです。このプラグインは、集中管理された設定ファイルを通じてMCPサーバーを構成・管理し、ツールやリソースを閲覧・インストール・テストするための直感的なUIを提供します。LLM統合のために設計されており、プログラムによるAPI呼び出しとインタラクティブなテスト機能の両方を提供します。https://github.com/ravitemer/mcphub.nvim より引用github.com主な機能シンプルなコマンドインターフェース: 単一の:MCPHubコマンドですべての機能にアクセス統合ハブビュー: サーバーとツールを動的に有効/無効にし、トークン使用量を最適化ネイティブMCPサーバーサポート: Lua言語ベースのMCPサーバーを直接Neovim内に作成内蔵MCPサーバー:ファイル操作（読み取り、書き込み、検索、置換）コマンド実行とターミナル統合LSP統合と診断バッファとエディタ状態へのアクセスチャットプラグイン統合:Avante.nvimCodeCompanion.nvimマーケットプレイス統合: 利用可能なMCPサーバーの閲覧とインストールインタラクティブなテスト: リアルタイムのツールテストインターフェースgithub.comLLMとMCPの連携従来のLLMチャットは「単なる会話」に過ぎませんでした。ユーザーが質問し、AIが応答する。もしくはユーザーが質問し、AIがその範囲内で変更する。しかし、MCPをNeovimに統合すると、LLMは単なる会話の相手ではなく、あなたのNeovim開発環境で「手」を持つ実践的なアシスタントに変わります。Neovimでは、MCPを通じてLLMに以下のような強力な機能へのアクセスを提供できます。ファイルの読み取りと書き込み - バッファ内容の分析や自動生成コードの挿入ファイルの検索と置換 - プロジェクト全体でのリファクタリングや一括修正シェルコマンドの実行 - git操作やビルドコマンドの自動実行LSP診断情報の取得 - エラーや警告の分析と自動修正提案バッファ間の移動とコンテンツの取得 - 複数ファイルにまたがる変更の一括適用インタラクティブなプロンプトの提供 - コードレビューや改善提案のための対話Neovimのキーマッピングやコマンドの生成と実行 - カスタム操作の自動化MCPはLLMをNeovimエコシステムの一部として統合し、あなたのコーディング体験を根本から変革します。Avante.nvimとの連携：実践的なAIペアプログラミングMCPHub.nvimは、NeovimのためのAIチャットプラグインとシームレスに連携できます。現在、Avante.nvimとCodeCompanion.nvimの両方に対応しており、どちらでも同じMCPツールを活用できます。私がAvante.nvimを使っているので紹介するのはこちらです。syu-m-5151.hatenablog.comAvante.nvimはMCPHubと統合することで、LLMに強力なツールへのアクセスを提供できます。MCPHubのツールを有効にするには、Avanteの設定に以下のように追加しますrequire("avante").setup({    -- その他の設定    system_prompt = function()        local hub = require("mcphub").get_hub_instance()        return hub:get_active_servers_prompt()    end,    custom_tools = function()        return {            require("mcphub.extensions.avante").mcp_tool(),        }    end,})github.comMCPが解決する問題従来、各LLMチャットプラグインは独自のツールシステムを実装していました。例えば、AvanteとCodeCompanionでは、同一の機能を実現するために異なるコードを書く必要があり、プラグイン間での互換性がありませんでした。また、Neovimの機能にアクセスするための標準的な方法が存在せず、各プラグイン開発者が独自の実装を行う必要がありました。MCPHubはNeovim環境において以下のような問題を解決します。一度実装すれば、どこでも動作：ツールを一度実装すれば、Avante.nvimとCodeCompanion.nvimなど、すべてのMCP対応チャットプラグインで共通して利用可能標準化されたAPI：res:text():image():send()のような直感的なチェーンAPIにより、Neovimの機能に一貫した方法でアクセス統一された指示：ツール、リソース、テンプレートを一箇所で管理し、LLMに渡す指示を簡素化完全なリソースシステム：URI型のリソースアクセスにより、Neovimバッファ、ファイルシステム、LSP情報などに統一的にアクセス標準型のレスポンス：テキスト、画像、バイナリデータなどの標準対応により、多様な出力形式をサポート集中型ライフサイクル管理：サーバーの状態を一元管理し、パフォーマンスを最適化MCPHubの実践的なNeovimワークフローNeovimでのハンズオン開発において、MCPHubを活用したワークフローは以下のようになります：:MCPHub コマンドでMCPハブUIを開き、利用可能なツールとサーバーを確認必要なMCPサーバー（ファイル操作、LSP、ターミナルなど）を有効化有効化したサーバーのツールやリソースをMCPハブUIで確認し、機能を把握<leader>aeなどのキーマップでAvanteのインターフェースを開き、タスクをLLMに依頼LLMはMCPツールを使って様々なタスクを実行し、結果をバッファに直接反映実践例: Neovimでのコードリファクタリングたとえば、「このプロジェクトでアロー関数を通常の関数に変換したい」とLLMに伝えると、NeovimとMCPを活用したLLMは以下のようなステップを自動で実行します。search_filesツールでNeovimのtelescope/ripgrepを使いJavaScriptファイルを検索read_fileツールでNeovimバッファを通じて各ファイルの内容を読み取りコードを解析してアロー関数を特定replace_in_fileツールでNeovimのテキスト置換機能を使い変換を実行変更をプレビューしたり、自動で適用したりする選択肢を提示必要に応じてLSP診断を実行し、変換後のコードが正しく動作することを確認これにより、通常であれば複数のNeovimコマンドと手動作業が必要なリファクタリングを、単一のLLMとの対話で完了できます。今後の展望MCPは、LLMをテキスト生成の枠を超えて、Neovimの強力な開発環境と統合された実用的な開発アシスタントとして活用する道を開きます。MCPHub.nvimのようなプラグインにより、Neovimユーザーはこの可能性を最大限に活用できます。今後の発展としては以下が期待できます：Neovim専用のMCPツール: Neovimの特性を活かした専門的なMCPツールの開発言語固有のアシスタント: 各プログラミング言語に特化したLSPと連携したコーディングアシスタントプロジェクト管理の自動化: git操作やプロジェクト構造の分析・最適化の自動化カスタムワークフロー: 個人の開発スタイルに合わせたAIアシスタントの調整MCPは単なる技術的な進歩ではなく、NeovimユーザーとAIの協業の形を根本的に変える可能性を秘めています。これにより、コーディングの効率性と創造性が飛躍的に向上するでしょう。]]></content:encoded>
        </item>
    </channel>
</rss>