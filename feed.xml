<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 16 Dec 2024 11:34:16 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Cloud Run GPU 上の PaliGemma2 に私の娘は可愛いと言わせるまで]]></title>
            <link>https://zenn.dev/satohjohn/articles/33b27212b3a55e</link>
            <guid>https://zenn.dev/satohjohn/articles/33b27212b3a55e</guid>
            <pubDate>Mon, 16 Dec 2024 11:20:30 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake アドベントカレンダー シーズン1 16日目の記事になります。3-shake に入社してそろそろ丸2年が経過しようとしており、感慨深く思っております。こういうカレンダーをちゃんと埋められているのをみていても、アウトプットという形で自己研鑽や表現を行う素晴らしいメンバーが多いなと日々日々感じております。そんな中で書けるのも良い経験だと感じております。という前置きを入れつつ、今回は生成 AI の中でも OSS でマルチモーダルな LLM である PaliGemma2 を使ってみたという形で書かせていただきます。正直11月初めは最初は PaliGemma だったん...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[週間アトデ 2024-12-16]]></title>
            <link>https://blog.atusy.net/2024/12/16/atodeyomanakata/</link>
            <guid>https://blog.atusy.net/2024/12/16/atodeyomanakata/</guid>
            <pubDate>Mon, 16 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[アトデヨム、ウソジャナイ、ヨムノタノシー]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: Goodbye etcd! Running Kubernetes on Distributed PostgreSQLのセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/15/goodbyte_etcd_running_kubernetes_on_distributed_postgresql</guid>
            <pubDate>Sun, 15 Dec 2024 14:16:36 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー15日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Goodbye etcd! Running Kubernetes on Distributed PostgreSQL セッションレポートセッション概要 https://kccncna2024.sched.com/event/1i7rt/goodbye-etcd-running-kubernetes-on-distributed-postgresql-denis-magda-yugabyteセッション動画 www.youtube.comこのセッションはKubernetesクラスタのメタデータストアとして利用されるetcdをDistributed PostgreSQLであるYugabyteDBに置き換えた方法を紹介し、デモを行っています。What's etcd?セッションはetcdの解説から始まりました。etcdは分散可能で可用性の高いキーバリューストアであり、シンプルながらも強力なデータベースとして機能します。Raftプロトコルを用いることで、複数のマシンやVMで構成されたクラスタ全体にわたって変更を複製し、ノード障害発生時にも一貫したデータと継続的な動作を保証します。Kubernetesはこのetcdをメタデータストアとして活用し、サービスのポート数やデプロイメントのPod数といったクラスタの状態を管理しています。このセクションはetcdの役割を明確に示し、Kubernetesにおける重要性を理解する上で有用でした。etcdがKubernetesの心臓部と言える重要な役割を担っていることを再認識させられました。Why some are not happy with etcdetcdは多くのKubernetesクラスタで標準的に利用されていますが、大規模環境（100～1000ノード）ではスケーラビリティに課題があることが指摘されました。このようなケースでは、etcdから分散データベースへの移行が必要となります。さらに、etcdプロジェクトへのコントリビュータ不足も懸念材料として挙げられており、Kubernetesが必要とする機能追加への対応が遅れる可能性が示唆されました。このセクションは、etcdの潜在的な問題点を浮き彫りにし、代替手段を検討する必要性を示唆しています。特に大規模運用を想定している場合、etcdのスケーラビリティの限界は深刻な問題になり得ます。KineKineはKubernetesクラスタとリレーショナルデータベース間の仲介役として機能するシミュレータレイヤです。etcd APIをSQLに変換することで、PostgreSQLやMySQLのようなリレーショナルデータベースをKubernetesのメタデータストアとして利用可能にします。Kubernetes APIサーバーが発行したetcd APIをKineがSQLに変換し、データベースに実行することで、etcdの代替を実現します。このセクションはKineの動作原理を簡潔に説明し、リレーショナルデータベースをKubernetesと統合する仕組みを理解する上で重要です。Kineの存在によって、既存のデータベース基盤を活用したKubernetes運用が可能になります。Hands-onデモ環境はGoogle Cloud上の3つのCompute Engine（us-westリージョンの異なるゾーン）に構築されたk3sクラスタで、純粋なPostgreSQLと分散型PostgreSQLであるYugabyteDBの2つのシナリオが示されました。純粋なPostgreSQLは単一VMで、YugabyteDBは3台のVMで実行され、マルチゾーン、マルチリージョン、マルチクラウド/オンプレミス環境への拡張可能性が示唆されました。このセクションはデモ環境の概要を説明し、異なるデータベース構成でのKubernetes運用の可能性を示しています。実環境に近い構成でのデモは、KineとYugabyteDBの有効性を理解する上で非常に役立ちます。Kubernetes on Pure PostgreSQLyoutu.beこのデモでは、PostgreSQLが動作するサーバ上でk3sを実行し、Kineが必要とするオブジェクトがPostgreSQLに作成される様子、そしてk3s自体の動作確認が示されました。既存のPostgreSQL環境へのKubernetesの導入を検討する際に、このデモは具体的な手順と動作イメージを提供してくれます。データベース管理者にとって、Kineによるデータベースへの影響を視覚的に確認できる点は非常に重要です。Kubernetes on YugabyteDBYugabyteDBとは？YugabyteDBは、PostgreSQL互換の分散SQLデータベースです。クエリレイヤはPostgreSQLからフォークされ、ストレージレイヤはLSMツリーベースの実装1を採用しています。複数サーバ・複数リージョンでの運用が可能で、クエリ分散やノード障害時の継続動作を実現します。etcdと同様にRaftプロトコルを利用することで、データの一貫性を確保し、ネットワーク分断時のスプリットブレインにも対応します。このセクションはYugabyteDBの特徴を説明し、高可用性と分散性を備えたデータベースとしての利点を明確に示しています。etcdの代替としてYugabyteDBを検討する際に、この情報は非常に重要です。デモyoutu.beYugabyteDBクラスタ上でk3sを実行するデモでは、PostgreSQLの場合とほぼ同様の手順でKubernetesを起動できることが示されました。YugabyteDBのダッシュボードを用いて、データベースの情報やKineが作成した情報を確認できる点も強調されました。さらに、Kubernetesのサンプルアプリを起動することで、etcdベースのKubernetesと同等の動作が確認されました。1台のCompute Engineを停止させることでYugabyteDBノードの障害をシミュレートし、データベースとKubernetesが継続して動作することを実証しました。このデモは、YugabyteDBの耐障害性と高可用性を視覚的に示し、実運用環境での信頼性を裏付けています。結論このセッションは、KineとYugabyteDBを用いることで、etcdの代替としてリレーショナルデータベースをKubernetesのメタデータストアとして利用できることを示しました。特に、YugabyteDBの分散性と耐障害性は、大規模Kubernetesクラスタの運用においてetcdのスケーラビリティやコントリビュータ不足といった課題を解決する可能性を示唆しています。ただし、YugabyteDBの導入には運用コストや学習コストといった新たな課題も発生するため、etcdとの比較検討が必要です。同様にセッションではKineをネイティブに利用しているk3sを利用していますが、k3sはあくまでKubernetesの軽量ディストリビューションであるため完全に同じものではないため、本当にk3sで良いのかという比較検討も必要になります。またセッション内では100を超えるノードから構成されるKubernetesクラスタではetcdのスケーラビリティが足りず、他のメタデータストアが必要になると紹介していますが、なぜ必要になるかは説明が不足していると感じました。これはKubernetesクラスタが大規模化することでAPIサーバが発行するクエリがetcdの対応可能な10000 rpsを越え始めるためです。より詳細な説明はGoogle Cloudの65000ノードを越えるGKEクラスタをSpannerでホストしていることを紹介しているブログが参考になるでしょう。cloud.google.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes The Hard Wayにトライする]]></title>
            <link>https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3</link>
            <guid>https://zenn.dev/moz_sec/articles/0dbb3b7dd08ab3</guid>
            <pubDate>Sun, 15 Dec 2024 12:14:59 GMT</pubDate>
            <content:encoded><![CDATA[KuberenetesKubernetesとは、複数のコンピュータでコンテナをいい感じに動かしてくれるものです。Kubernetesの説明はいろんなサイトに書いてあるため、そちらを参照してください。公式サイトも参考になります。https://kubernetes.io/docs/concepts/overview/ Kuberentes The Hard WayKubernetes The Hard Wayとは、kubeadmやkubesplayのような、クラスタ構築ツールに頼らず、コンテナランタイムや各コンポーネントを自分でインストールして、設定をし、Kubernetes...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Reckoner における Datadog Error Tracking の活用事例]]></title>
            <link>https://zenn.dev/nomadblacky/articles/1901ceb9154c7b</link>
            <guid>https://zenn.dev/nomadblacky/articles/1901ceb9154c7b</guid>
            <pubDate>Sun, 15 Dec 2024 10:35:38 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2024 の 15 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。Reckoner では多種多様な連携先に対応しているため、様々なエラーが発生する可能性があります。そのため、エラーの迅速な発見と...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Japan.R 2024に参加した]]></title>
            <link>https://blog.atusy.net/2024/12/15/japanr-2024/</link>
            <guid>https://blog.atusy.net/2024/12/15/japanr-2024/</guid>
            <pubDate>Sun, 15 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Hadley氏を筆頭に、本番環境や実務でRを使う話が多くて印象深かった回。色々な話を聞けてよかった。2019年以来のオフライン開催で久しくお会いしていなかった方とお話できたこと、光栄にも私に会ってみたかったという方に挨拶頂けたりブログが参考になったと言っていただけたこと、発表に対して直に感想をやりとりできたことなど、現地入りしてよかったなあと思います。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications</guid>
            <pubDate>Sat, 14 Dec 2024 18:55:02 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初回実行が遅ければ遅延初期化でやればいいじゃない - RustのTUIアプリケーション改善]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/14/121545</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/14/121545</guid>
            <pubDate>Sat, 14 Dec 2024 03:15:45 GMT</pubDate>
            <content:encoded><![CDATA[この記事はRust Advent Calendar 2024 シリーズ3の15日目の記事です。はじめにみなさん、アプリケーションの初回実行の遅さに悩んでいませんか？「初回の検索が遅い...」「起動に時間がかかる...」「ユーザーから苦情が...」といった問題は、多くの開発者が直面する共通の課題です。実は、こういった問題の多くは初期化のタイミングを工夫することで効果的に解決できます。特にRustの場合、遅延初期化の仕組みを積極的に活用することで、パフォーマンスとユーザー体験を大きく改善することが可能です。初期化処理を適切なタイミングで実行することで、アプリケーションの応答性を保ちながら、必要なデータの準備を効率的に行うことができるのです。今回は郵便番号検索アプリケーション（jposta）を具体例として、初期化の最適化手法について詳しく見ていきましょう。この実践的なケーススタディを通じて、効果的な初期化戦略の実装方法を学んでいきます。github.com遅延初期化とは遅延初期化は、「必要になるまで初期化を待つ」という考え方を基本とする重要な最適化テクニックです。アプリケーションの起動時に全てのデータを一度に読み込むのではなく、そのデータが実際に使用されるタイミングまで読み込みを延期することで、システムの効率性を高めることができます。ja.wikipedia.org特に重要な利点として、アプリケーションの起動時間の大幅な短縮が挙げられます。全ての機能を一度に初期化する代わりに、必要な機能から順次初期化することで、ユーザーは最小限の待ち時間でアプリケーションの使用を開始できます。また、大きな設定ファイルの読み込みやデータベース接続の確立、重いライブラリの初期化、キャッシュの構築といったリソース集約的な操作を必要なタイミングまで延期することで、メモリやCPUなどの限られたリソースを効率的に活用することが可能となります。さらに、遅延初期化は複雑な依存関係を持つシステムにおいても効果的です。複数のコンポーネントが互いに依存し合う状況では、初期化の順序が問題となることがありますが、各コンポーネントを必要に応じて初期化することで、この課題を自然に解決できます。加えて、テスト容易性の向上も重要な利点です。必要なコンポーネントだけを初期化できることで、単体テストやモジュールテストが容易になり、テストの実行速度も向上します。また、エラーハンドリングの改善にも貢献します。初期化時のエラーを早期に検出できるだけでなく、実際に使用されないコンポーネントの初期化エラーを回避することができます。運用環境での柔軟性も高まり、システムの一部機能が利用できない状況でも、他の機能を正常に動作させることが可能になります。このように、遅延初期化は現代のソフトウェア開発において、パフォーマンス、保守性、信頼性の面で多くのメリットをもたらす重要な設計パターンとなっています。blog1.mammb.comRustにおける遅延初期化の進化Rustにおける遅延初期化の歴史は、2014年に登場したlazy_staticから始まり、これはマクロベースの実装でスレッドセーフ性に課題があり、型の制約も厳しいものでした。github.comその後、2020年にはonce_cellが登場し、マクロを必要としないシンプルなAPIとスレッドセーフな実装、より柔軟な型のサポートを提供することで、遅延初期化の実装が大きく改善されました。github.comそして2024年になると、LazyCell/LazyLockが標準ライブラリに統合され、さらなる最適化と依存関係の削減が実現され、Rustの遅延初期化機能は新たな段階へと進化を遂げています。blog.rust-lang.orgこのように、Rustの遅延初期化は時代とともに進化し、より使いやすく堅牢な実装へと発展してきました。techblog.paild.co.jp問題の理解：なぜ初期処理が必要か？まず、jpostcode_rsライブラリの実装を見てみましょう：use std::sync::LazyLock;static ADDRESS_MAP: LazyLock<HashMap<String, Vec<Address>>> = LazyLock::new(|| {    let data = include_str!(concat!(env!("OUT_DIR"), "/address_data.json"));    let raw_map: HashMap<String, Value> =        serde_json::from_str(data).expect("Failed to parse raw data");    // ...});このコードの重要なポイントは、LazyLockによる遅延初期化を採用することで、JSONデータの初回アクセス時までパースを延期し、必要なタイミングでメモリへの展開を行う設計となっているということです。このコードから分かるように、初回アクセス時のパフォーマンス低下は遅延初期化の仕組みに起因しています。そこで私たちは、この遅延初期化の特性を活用し、ユーザーが実際にアクセスする前に初期化を完了させる戦略を考案しました。解決策：遅延初期化を活用した初期処理従来の初期化パターンfn new() -> App {    let (search_tx, search_rx) = mpsc::channel::<String>();    let (result_tx, result_rx) = mpsc::channel();    thread::spawn(move || {        while let Ok(query) = search_rx.recv() {            // 初回検索時にデータ初期化が発生 = 遅い！        }    });    App { /* ... */ }}改善後：標準ライブラリの機能を活用use std::sync::{LazyLock, Mutex};// グローバルな初期化フラグstatic INITIALIZED: LazyLock<Mutex<bool>> = LazyLock::new(|| Mutex::new(false));impl App {    fn new() -> App {        let (search_tx, search_rx) = mpsc::channel::<String>();        let (result_tx, result_rx) = mpsc::channel();        thread::spawn(move || {            // バックグラウンドで初期化            {                let mut init = INITIALIZED.lock().unwrap();                if !*init {                    // 軽いクエリで事前初期化をトリガー                    let _ = lookup_addresses("100");                    let _ = search_by_address("東京");                    *init = true;                }            }            // 以降の検索は初期化済みのデータを使用            let mut cache: HashMap<String, Vec<String>> = HashMap::new();            while let Ok(query) = search_rx.recv() {                // 通常の検索処理            }        });        App { /* ... */ }    }}この手法の効果とメリットとデメリットこの手法の中核となる標準ライブラリのLazyLockやMutexなどの基本機能は、追加のライブラリを必要としない堅牢な実装を可能にします。既存のRustプログラマーにとって馴染みのある仕組みを使用しているため、コードの理解や保守が容易であり、依存関係も最小限に抑えることができます。また、これらの機能は既にRustチームによって最適化され、徹底的にテストされているため、高いパフォーマンスと信頼性が保証されています。システムの保守性と運用面では、初期化ロジックの集中管理により、状態管理が大幅に簡素化されます。INITIALIZEDフラグを用いた明示的な制御により、初期化状態の追跡が容易になり、デバッグ性も向上します。さらに、初期化処理をバックグラウンドスレッドで実行することで、メインスレッドのブロッキングを避け、UIの即時表示とレスポンシブな操作感を実現できます。スケーラビリティの観点からは、新機能の追加や初期化順序の制御が柔軟に行えるため、システムの成長に合わせた拡張が容易です。Mutexによる適切な同期制御により、複数スレッドからの安全なアクセスが保証され、並行処理との親和性も高くなっています。また、必要なデータの予測的な先読みとメモリ使用の最適化により、効率的なリソース管理が可能です。初期化処理のモジュール化により、新しい機能の追加時も既存コードへの影響を最小限に抑えられ、キャッシュの効果的な活用によって、大規模なアプリケーションでも高いパフォーマンスを維持できます。一方で、この手法にはいくつかの重要な課題も存在します。まず、メモリ使用量の増加が挙げられます。事前初期化アプローチでは、実際には使用されない可能性のあるデータ構造も含めて、すべてのデータをメモリに展開する必要があります。これは特にメモリリソースが限られている環境において深刻な問題となる可能性があり、システムの全体的なパフォーマンスに影響を与える可能性があります。また、起動時のリソース消費も重要な課題です。バックグラウンドでの初期化処理は、システムの起動時により多くのCPUとメモリリソースを必要とします。特にモバイルデバイスやバッテリー駆動の機器では、この追加のリソース消費が電力効率に悪影響を及ぼす可能性があります。ユーザーの使用パターンによっては、この初期化コストが実際の便益を上回ってしまう場合もあります。さらに、実装の複雑性が増加することも大きな課題です。遅延初期化と事前初期化を組み合わせることで、コードベースの複雑性が著しく増加します。特に初期化の順序や依存関係の管理が複雑になり、開発者がシステムの動作を理解し、デバッグすることが困難になる可能性があります。この複雑性は、新しい機能の追加や既存機能の修正時にも影響を及ぼし、開発効率の低下につながる可能性があります。テストの複雑化も見過ごせない問題です。バックグラウンド初期化を含むコードのテストでは、タイミングや状態管理の観点から、適切なテストケースの作成と実行が困難になります。特に並行処理に関連するバグの再現や検証が複雑になり、品質保証のプロセスに追加の負担がかかる可能性があります。最後に、エラーハンドリングの複雑化も重要な課題です。バックグラウンドでの初期化中に発生したエラーの適切な処理と、それに対するユーザーへの適切なフィードバック提供が技術的な課題となります。エラーが発生した場合の回復処理や、部分的な機能提供の実装も複雑になり、システムの信頼性と保守性に影響を与える可能性があります。このように、標準ライブラリの機能を活用した実装は多くの利点をもたらす一方で、システムの要件や制約に応じて、これらのデメリットを慎重に検討する必要があります。実装時には、これらのトレードオフを考慮しながら、適切な設計判断を行うことが重要となります。実装時の注意点デッドロックの防止{  // スコープによるロックの制限    let mut init = INITIALIZED.lock().unwrap();    if !*init {        *init = true;    }}  // ロックの自動解放初期化の冪等性if !*init {    // 複数回実行されても安全な実装に    let _ = lookup_addresses("100");    *init = true;}まとめ私たちは「初回アクセスが遅いなら、事前に必要な処理を済ませておこう」というシンプルながら実用的なアプローチについて、Rustの標準ライブラリの遅延初期化機構を通じて検討してきました。この手法には、メモリ使用量の増加やコードの複雑化といった課題も存在しますが、適切に実装することで大きな効果が期待できます。標準ライブラリの機能を活用し、依存関係を最小限に抑えながら、スレッドセーフな実装を実現することで、効率的かつ安全な初期化処理が可能となります。このように、遅延初期化と事前初期化を組み合わせたアプローチは、システムの特性や要件に応じて検討すべき重要な最適化パターンの一つと言えるでしょう。参考文献The Rust Standard Library - std::sync::LazyLockThe Rust Standard Library - std::cell::LazyCellRust Performance Book]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Deploy で Cloud Run functions に継続的デリバリーする]]></title>
            <link>https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions</link>
            <guid>https://zenn.dev/kimitsu/articles/cloud-deploy-cloud-run-functions</guid>
            <pubDate>Sat, 14 Dec 2024 01:17:49 GMT</pubDate>
            <content:encoded><![CDATA[Cloud Deploy は継続的デリバリーを行うための Google Cloud のフルマネージドサービスです。標準では Google Kubernetes Engine と Cloud Run (service と job) へのデプロイをサポートしていますが、カスタムターゲットを定義することでそれ以外の対象にもデプロイすることができます。今回はカスタムターゲットを利用して Cloud Run functions へのデプロイを自動化してみます。本記事では Cloud Deploy の基本的な概念（ターゲット、リリース、デプロイパイプラインなど）については説明しません。これら...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes</guid>
            <pubDate>Fri, 13 Dec 2024 08:57:05 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション "Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*°∀°)]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03</guid>
            <pubDate>Thu, 12 Dec 2024 15:00:01 GMT</pubDate>
            <content:encoded><![CDATA[※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Japan.R 2024で地域コミュニティのOsaka.Rについて発表した]]></title>
            <link>https://blog.atusy.net/2024/12/12/japanr-logging/</link>
            <guid>https://blog.atusy.net/2024/12/12/japanr-logging/</guid>
            <pubDate>Thu, 12 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[前の発表で力尽きてて、何も考えずに楽しくお話しちゃった回。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust 再学習戦記]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/12/013950</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/12/013950</guid>
            <pubDate>Wed, 11 Dec 2024 16:39:50 GMT</pubDate>
            <content:encoded><![CDATA[プログラミング言語の再入門とは、未知の大地への探求というよりも、私たちが知っているはずの領域を新たな視点で見つめ直す営みです。それは初めての出会いのような激しい高揚感とは異なり、むしろ静かな再発見の過程といえるでしょう。この記事は3-shake Advent Calendar 2024 シリーズ2の12日目の記事です。はじめに2017年、私の心にRustという言語が静かに灯りを点しました。その光は、システムプログラミングの深い理解への憧れを呼び覚まし、私を導いていきました。情熱に突き動かされるように、DevOpsツールの創造から始まり、パケット解析の探究へ、そしてWebフレームワークの実装へと、私の歩みは広がっていきました。高速な実行速度と安全性という輝きに心を奪われながらも、未熟なエコシステムという現実が私たちの前に立ちはだかりました。パッケージの追従に心を砕き、破壊的な変更に耐え、そして孤独なメンテナンスの重みを感じながら、私は一時の別れを告げることを選びました。しかし2024年を迎えた今、私の目の前で世界は確かな変化を見せています。Rustの開発者満足度は非常に高い一方で、実務での採用はまだ限定的です。これは、現時点ではRustを業務で使用している開発者が比較的少なく、主に技術的な興味や言語の特徴に惹かれて自発的に選択している人が多いためかもしれません。まぁ何はともあれ、私もその魅力に惹かれた1人のエンジニア。最新のRustを探究すべく、再入門することにしました。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazonなぜ今、Rustなのか技術的な成熟Rustのエコシステムは大きく進化し、この数年で安定性が著しく向上しています。パッケージの破壊的変更は目に見えて減少し、Zero To Production In Rustをはじめとした実践的な運用ガイドの登場により、本番環境での運用ノウハウが充実してきました。さらに、日本語での技術記事や登壇資料も増え、日本語でのコミュニケーションも充実してきています。主要パッケージの品質向上と運用実績の蓄積により、開発環境全体の信頼性は大幅に高まっています。また、言語サーバーの進化やツールチェーンの充実により、開発効率も飛躍的に向上しました。実践的な機能面においても、目覚ましい進歩が見られます。エラーハンドリングの改善やWebAssemblyサポートの強化により、クロスプラットフォーム対応も一層充実しました。また、コンパイラの最適化改善による実行時オーバーヘッドの最小化や、所有権システムによるメモリ安全性の保証など、Rustの基本的な強みはさらに磨きがかかっています。特に、非同期プログラミングのエコシステムは大きく成熟し、堅牢な基盤が確立されています。また、2025年には2024 Rdition がリリースされる。SREとしての展望今後は、Rustで構築されたマイクロサービスや高性能なバックエンドサービスのためのインフラ構築や運用の機会が増えていくことが予想されます。特に、コンテナ環境でのデプロイメントやクラウドネイティブな環境でのインフラ構築において、Rustアプリケーションの特性を最大限に活かすための設計が求められるでしょう。例えば、Rustの低メモリ消費という特徴を活かしたコンテナリソースの最適化や、高速な実行速度を考慮したオートスケーリングの設計など、アプリケーションの特性に合わせたインフラストラクチャの構築が重要になってきます。また、モニタリングやログ収集といった運用基盤においても、Rustアプリケーションに適した構成を検討していく必要があるでしょう。SREとしてRustのプロダクションデプロイメントに関わる場合は、Zero To Production In Rustを参照することをお勧めします。この書籍では、Rustアプリケーションの本番環境への展開に関する実践的なガイドラインが提供されています。www.zero2prod.comRustの再入門のための学習コンテンツ再入門にあたり、Rustの最新のプラクティスやエコシステムの変化をキャッチアップするため、いくつかの資料に取り組みました。特に有用だった書籍を紹介していきます。書籍の良さは情報を俯瞰できる点にあると考えています。わからない点があればLLMに質問することができますので⋯。なお、この記事はRustの基礎知識がある方向けの再入門という観点で資料を選定しているため、完全な初学者向けの内容は含んでいません。参照したドキュメントや内容の詳細については、Xで共有しているドキュメントをご確認ください。プログラミングRust 第2版 を読んで可能な限り手を動かす会を実施します。https://t.co/rmUpbPtK9O— nwiizo (@nwiizo) 2024年11月21日   読んだ本についての定義についてはこちらを参考にしてほしいです。読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazonまた、yuk1tydさんのドキュメントは2021年時点の情報ですが、現在も十分に有用な内容となっているためおすすめです。blog-dry.com書籍Programming Rust, 2nd EditionO'Reilly Mediaから出版されている本書は、Rustの基本的な概念から高度な機能まで包括的に解説する定番の教科書です。特に所有権やライフタイム、並行処理といったRustの特徴的な機能について、実践的な例を交えながら詳細に説明されています。本当に再入門してから何度も読んでいる。生成AIに聞くか本を読むか実際に書いていくかの三択である。Programming Rust: Fast, Safe Systems Development作者:Blandy, Jim,Orendorff, Jason,Tindall, Leonora F SO'Reilly MediaAmazon2021年の第2版では、Rust 2021 Editionに対応し、非同期プログラミングやトレイト、ジェネリクス、マクロなど、モダンなRustの重要な機能が大幅に加筆されました。特に、パフォーマンスとメモリ安全性を両立させるためのRustの機能を、システムプログラマの視点から解説している点が特徴です。再三にはなるが2024 Rdition がリリースされる。それに合わせて再び書籍が出されるのが楽しみである。3年毎にリリースがあるのは早すぎず遅すぎずちょうど嬉しい。これまでと違う学び方をしたら挫折せずにRustを学べた話 / Programming Rust techramen24conf LTでも紹介されているように、本書は体系的な学習を可能にする構成と、実践的な例示の豊富さが特徴です。特に、Rustの概念モデルを丁寧に解説している点は、言語仕様の深い理解につながります。再入門時の体系的な知識のアップデートに最適な一冊といえるでしょう。 speakerdeck.comまた、日本語の書籍も出ているので感謝すべきである。プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonバックエンドエンジニアを目指す人のためのRust翔泳社から出版されているこの入門書は、実践的なプロジェクトを通じてRustを学ぶアプローチを採用しています。計算クイズからTODOアプリまで、段階的に難易度を上げながら、バックエンドエンジニアに必要な技術要素をカバーしている点が特徴です。バックエンドエンジニアを目指す人のためのRust作者:安東 一慈,大西 諒,徳永 裕介,中村 謙弘,山中 雄大翔泳社Amazon本書の優れている点は、各プロジェクトを通じて特定のRustの概念を深く掘り下げる構成にあります。例えば、ポーカーゲームの実装を通じてデータ構造の理解を深め、家計簿プログラムでファイルI/Oを学び、画像処理ツールで並列処理を実践的に理解できます。また、Cargoによるパッケージ管理、ユニットテスト、リンター、フォーマッターといった実務で重要となる開発ツールの活用方法も丁寧に解説されています。特筆すべきは、エラーハンドリングやOption/Result型の扱いなど、Rustの特徴的な機能を実際のユースケースに即して学べる点です。さらに、Webアプリケーション開発からデプロイメントまでをカバーしており、現代のバックエンド開発の実践的なスキルが身につく構成となっています。ただし、この本はプログラミング言語としてのRustの入門書として優れているものの、プログラミング未経験者にはRust自体の学習難度が高いため、他の言語での開発経験がある方に特にお勧めします。体系的な構成と実践的なプロジェクトを通じた学習アプローチは、技術書の模範となる一冊といえるでしょう。www.estie.jpコミュニティと情報源Rustの再入門において、コミュニティへの参加は技術的な成長と最新動向の把握に重要な役割を果たしています。日本のRustコミュニティは活発な技術交流が行われています。Rust.TokyoRust.Tokyoは日本最大のRustカンファレンスで、年に一度開催される重要なイベントです。私は再入門直後にこのカンファレンスに参加することになり、登壇資料の準備に追われる事態となりましたが、結果的に学習のよい動機付けとなりました。カンファレンスでは、企業での採用事例や実装のベストプラクティス、パフォーマンスチューニングの知見など、実践的な内容が数多く共有されます。また、国内外のRustコミュニティのメンバーとの交流を通じて、最新のトレンドやツール、開発手法について直接学ぶ機会も得られます。Rust-jp ZulipRust-jp Zulipは、日本のRustコミュニティの中心的なコミュニケーション基盤です。SlackやDiscordと異なり、トピックベースの会話構造を持つZulipを採用することで、過去の議論や質問への回答を効率的に検索できる点が特徴です。このプラットフォームでは、初心者向けの基本的な質問から、高度な実装の相談まで、幅広いディスカッションが日本語で行われています。特に、実務での問題解決やコードレビュー、アーキテクチャの相談など、実践的な議論が活発に行われており、再入門者にとって貴重な学習リソースとなっています。学びの記録2017年の実践パケット解析の実装Webフレームワーク検証Rust関連記事一覧2024 年やったことRustでterraform plan/apply のターゲット指定を簡単にするツールを作ってみた - tfocusの仕組みと使い方退屈なことはRust Build Scripts にやらせようRustで郵便番号・住所検索TUIツールを開発した - jpostaRustによる郵便番号検索API (yubin_api) の技術解説tfocusexpjpostcode_rsおわりに2017年の経験は、今となっては貴重な財産です。言語に入門し、一度は挫折を経験しながらもプロダクトへの導入に挑戦したこと、そして結果的に撤退を選択せざるを得なかったことは、私にとって大きな学びとなりました。この貴重な経験と適切な判断へと導いてくれた当時のメンターには感謝しています。パッケージ管理の困難さ、破壊的変更への対応、そして継続的な開発の課題 - これらの経験があったからこそ、現在のRustエコシステムの進化をより深く理解できています。Rustは単なるプログラミング言語の進化を超えて、エコシステム全体として大きく成長しました。特に、かつて私が直面した課題の多くが、コミュニティの成熟とツールチェーンの進化によって解決されつつあります。実践的なユースケースの蓄積は、次世代のシステム開発における新たな可能性を示唆しています。Rust 2024エディションのリリースを控え、言語とエコシステムはさらなる進化を遂げようとしています。SREとしても、このような発展を続けるRustの動向を把握し、実践的な知識を蓄積していくことは、将来への重要な投資になると確信しています。この記事を読んでいる方々も、ぜひこの成長と進化の過程に参加してみませんか？初めての方も、かつて離れた方も、今こそRustと再会するベストなタイミングかもしれません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GolangからPagerdutyのインシデントを発砲する]]></title>
            <link>https://zenn.dev/tayusa/articles/9091399d6a9018</link>
            <guid>https://zenn.dev/tayusa/articles/9091399d6a9018</guid>
            <pubDate>Wed, 11 Dec 2024 13:30:34 GMT</pubDate>
            <content:encoded><![CDATA[目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud monitoringのアラートをGitHub Issueに通知する]]></title>
            <link>https://kechigon.hatenablog.com/entry/2024/12/11/182649</link>
            <guid>https://kechigon.hatenablog.com/entry/2024/12/11/182649</guid>
            <pubDate>Wed, 11 Dec 2024 09:26:49 GMT</pubDate>
            <content:encoded><![CDATA[タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = "hashicorp/google"        version = "5.39.0"    }  }}provider "google" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource "google_compute_instance" "easybuggy" {  name         = "easybuggy-instance"  machine_type = "n1-standard-1"  zone         = var.zone  boot_disk {    initialize_params {      image = "debian-cloud/debian-11"    }  }  network_interface {    network = "default"        access_config {}  }  metadata = {    "enable-osconfig" = "true"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource "google_compute_firewall" "allow-home-ip" {  name    = "allow-home-ip"  network = "default"   allow {    protocol = "tcp"    ports    = ["8080"]  }  source_ranges = [var.my_ip]}output "instance_ip" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource "google_pubsub_topic" "alerts_topic" {  name = "alerts-topic"}resource "google_pubsub_subscription" "alerts_subscription" {  name  = "alerts-subscription"  topic = google_pubsub_topic.alerts_topic.name}resource "google_monitoring_notification_channel" "pubsub_channel" {  display_name = "Pub/Sub to Cloud Function"  type         = "pubsub"  labels = {    "topic" = google_pubsub_topic.alerts_topic.id  }}resource "google_pubsub_topic_iam_binding" "alerts_topic_publisher" {  topic = google_pubsub_topic.alerts_topic.name  role    = "roles/pubsub.publisher"  members = [    "serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com"  ]}resource "google_storage_bucket" "easybuggy_monitoring_function_bucket" {  name          = "easybubby_monitoring-functions-bucket"  location      = "ASIA-NORTHEAST1"  force_destroy = true}resource "google_storage_bucket_object" "function_source_object" {  name   = "function-source.zip"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = "function-source.zip"}resource "google_cloudfunctions_function" "issue_creator_function" {  name        = "issue-creator-function"  description = "Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue"  runtime    = "python39"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = "main"  region                = var.region  environment_variables = {    "GITHUB_API_TOKEN" = var.github_api_token    "GITHUB_REPO"      = var.github_repo    "GITHUB_OWNER"     = var.github_owner  }  event_trigger {    event_type = "providers/cloud.pubsub/eventTypes/topic.publish"    resource   = google_pubsub_topic.alerts_topic.id  }}resource "google_monitoring_alert_policy" "cpu_usage_policy" {  display_name = "High CPU Utilization Alert"  combiner     = "OR"  conditions {    display_name  = "CPU usage over 80%"    condition_threshold {      filter          = "metric.type=\"compute.googleapis.com/instance/cpu/utilization\" AND resource.type=\"gce_instance\""      duration        = "60s"      comparison      = "COMPARISON_GT"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get('GITHUB_API_TOKEN')GITHUB_REPO = os.environ.get('GITHUB_REPO')GITHUB_OWNER = os.environ.get('GITHUB_OWNER')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f"Alert: {data['incident']['incident_id']}"    issue_body = data['incident']['summary']    logger.info(f"Creating issue with title: {issue_title} body: {issue_body}")    response = requests.post(        f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues",        headers={            "Authorization": f"token {GITHUB_API_TOKEN}",            "Accept": "application/vnd.github.v3+json",        },        json={            "title": issue_title,            "body": issue_body,        },    )    if response.status_code == 201:        logger.info("Issue created successfully")        return "Issue created successfully", 201    else:        logger.error(f"Failed to create issue: {response.content}")        return f"Failed to create issue: {response.content}", response.status_code@app.route('/', methods=['POST'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error("No envelope received")        return "Bad Request", 400        logger.info(f"envelope: {envelope}")    pubsub_data = envelope.get('data', {})    logger.info(f"pub_sub_data")    if not pubsub_data:        logger.error(f"No outside data received: ")        return "Bad Request", 400    try:        data_base64 = pubsub_data.get('data', '')        if not data_base64:            raise ValueError("No data field in outside data")                data = base64.b64decode(data_base64.encode('utf-8')).decode('utf-8')        logger.info(f"Decoded data: {data}")        data = json.loads(data)                logger.info(f"Received data: {data}")    except Exception as e:        logger.error(f"Error processing message: {e}")        return "Bad Request", 400        return create_github_issue(data)if __name__ == "__main__":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kube-schedulerプラグインCoschedulingを体験してみた]]></title>
            <link>https://zenn.dev/k_nagase/articles/co_scheduling</link>
            <guid>https://zenn.dev/k_nagase/articles/co_scheduling</guid>
            <pubDate>Wed, 11 Dec 2024 01:00:01 GMT</pubDate>
            <content:encoded><![CDATA[本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 11 日目の記事です。 はじめにここ最近Kubernetesのスケジューリングについて調査する機会があり、その一環でスケジューラープラグインの1つであるCoschedulingについても調査しました。この時の調査と簡単なハンズオンについてこの記事でまとめてみたいと思います。Kubernetesのコントロールプレーンの1コンポーネントであるスケジューラはpluginによる機能拡張が可能です。プラグインは以下のリポジトリにまとまっています。https://github.com/kubernetes...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド一発で、本格的なおうちKubernetesを構築する]]></title>
            <link>https://speakerdeck.com/melanmeg/komando-fa-de-ben-ge-de-naoutikuberneteswogou-zhu-suru</link>
            <guid>https://speakerdeck.com/melanmeg/komando-fa-de-ben-ge-de-naoutikuberneteswogou-zhu-suru</guid>
            <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[作成したリポジトリ：https://github.com/melanmeg/k8s_1-30_on_noble参考：https://github.com/unchama/kube-cluster-on-proxmoxhttps://k8sh.net/arch/https://www.server-world.info/query?os=Ubuntu_24.04&p=kubernetes&f=1https://www.youtube.com/watch?v=7BLmtR1nhcY]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイクインタビュー: 技術顧問 うたもくさん編]]></title>
            <link>https://sreake.com/blog/interview-utam0k/</link>
            <guid>https://sreake.com/blog/interview-utam0k/</guid>
            <pubDate>Tue, 10 Dec 2024 04:16:19 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Japan.R 2024で構造化ログについて発表した]]></title>
            <link>https://blog.atusy.net/2024/12/10/japanr-logging/</link>
            <guid>https://blog.atusy.net/2024/12/10/japanr-logging/</guid>
            <pubDate>Tue, 10 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[オフラインイベントはリアクションがもらえて楽しい。準備や質問を通じて学びもいっぱい。またやりたい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLで値を変換したい？それならcaseはいかが?]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0</guid>
            <pubDate>Mon, 09 Dec 2024 16:42:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[オレのNeovim見て！ 2024]]></title>
            <link>https://blog.atusy.net/2024/12/09/awesome-my-neovim/</link>
            <guid>https://blog.atusy.net/2024/12/09/awesome-my-neovim/</guid>
            <pubDate>Mon, 09 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Vim/Neovimに興味を持ってほしくて、私のNeovimのカッコイイところ集を作ってみました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「Cloud Run functions」にコンテナがデプロイできるの知ってる？]]></title>
            <link>https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions</link>
            <guid>https://zenn.dev/kimitsu/articles/deploy-container-to-cloud-run-functions</guid>
            <pubDate>Sun, 08 Dec 2024 13:16:22 GMT</pubDate>
            <content:encoded><![CDATA[!本記事はネタ記事です！Cloud Run functions は Google Cloud の FaaS です。ユーザはコンテナ、ランタイム、Web サーバーを管理することなく、コードを書くだけでデプロイすることができます。本来はコンテナ化が不要な Cloud Run functions ですが、コンテナをデプロイできることをご存知でしょうか。 Cloud Run functions の仕組みユーザが Cloud Run functions にデプロイしたコードは複数の抽象化レイヤーの上で動きます。[1]一番内側にユーザが書いたコードがあり、その下にはまず Func...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes</guid>
            <pubDate>Sun, 08 Dec 2024 03:00:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story</guid>
            <pubDate>Sun, 08 Dec 2024 02:42:58 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[バッチ処理をCloud RunからCloud Run jobsに変更してみた話]]></title>
            <link>https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc</link>
            <guid>https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc</guid>
            <pubDate>Sat, 07 Dec 2024 22:06:20 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[セキュアな LLM アプリ開発：OWASP Top 10 for LLM 2025 と Vertex AI による実践]]></title>
            <link>https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai</link>
            <guid>https://zenn.dev/kimitsu/articles/owasp-for-llm-2025-and-vertex-ai</guid>
            <pubDate>Sat, 07 Dec 2024 00:14:53 GMT</pubDate>
            <content:encoded><![CDATA[本記事は 3-shake Advent Calendar 2024 シリーズ 1 の 7 日目の記事です。 はじめにOWASP Top 10 for LLM Applications の 2025 年版が 11 月 18 日に発表されました。[1]OWASP Top 10 は Web アプリケーションのセキュリティリスクの中で最も重要な 10 個をリスト化したものであり、OWASP Top 10 for LLM Applications は名前の通り LLM を利用したアプリケーションに関するものです。本家は数年に一度の改訂ですが、こちらは LLM の技術進歩が早いためほぼ毎年...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CUDAを利用したプログラムの高速化とNvidia Container Toolkit]]></title>
            <link>https://sreake.com/blog/cuda-nvidia-container-toolkit/</link>
            <guid>https://sreake.com/blog/cuda-nvidia-container-toolkit/</guid>
            <pubDate>Fri, 06 Dec 2024 01:51:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇]]></title>
            <link>https://sreake.com/blog/sre_kaigi_2025/</link>
            <guid>https://sreake.com/blog/sre_kaigi_2025/</guid>
            <pubDate>Thu, 05 Dec 2024 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、2025年1月26日（日）に開催される「SRE Kaigi 2025」にセッション登壇することをお知らせします。The post 「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rustによる郵便番号検索API (yubin_api) の技術解説]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/04/233641</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/04/233641</guid>
            <pubDate>Wed, 04 Dec 2024 14:36:41 GMT</pubDate>
            <content:encoded><![CDATA[こちらの記事は Rust Advent Calendar 2024 シリーズ 3 7日目の記事です！qiita.comはじめにRustを使用したWebアプリケーション開発は、高いパフォーマンスと堅牢性を両立させる方法として注目を集めています。本記事では、日本の郵便番号システムにアクセスするRESTful API「yubin_api」の実装を通じて、Rustの実践的な開発手法を解説します。workspace_2024/yubin_api at main · nwiizo/workspace_2024 · GitHubこのプロジェクトでは、axumを使用したWebサーバーの構築、非同期プログラミング（async/await）、構造化されたエラーハンドリングを実装しています。また、プロダクション環境を想定したメトリクス収集とモニタリング、型安全なAPIデザインにも焦点を当てています。ちなみに元ライブラリーの実装についてはsyumai さんの実装を全面的に参考にさせていただいております。blog.syum.ai1. プロジェクトの構成まず、Cargo.tomlの依存関係から見ていきましょう：[dependencies]# Webフレームワーク関連axum = { version = "0.7", features = ["macros"] }  # Webフレームワークtokio = { version = "1.0", features = ["full"] }   # 非同期ランタイムtower = { version = "0.4", features = ["full"] }   # HTTPサービス抽象化tower-http = { version = "0.5", features = ["cors", "trace", "limit", "request-id"] }# ロギングと監視tracing = "0.1"                # ログ出力tracing-subscriber = "0.3"     # ログ設定metrics = "0.21"              # メトリクス収集metrics-exporter-prometheus = "0.12"  # Prometheus形式出力# シリアライズ/デシリアライズserde = { version = "1.0", features = ["derive"] }serde_json = "1.0"# ユーティリティthiserror = "1.0"   # エラー定義uuid = { version = "1.0", features = ["v4"] }  # ユニークID生成utoipa = { version = "4.1", features = ["uuid"] }  # OpenAPI生成# 郵便番号データベースjpostcode_rs = "0.1.3"2. エラー処理の実装（error.rs）エラー処理は、APIの信頼性を確保する重要な部分です：use axum::{    http::StatusCode,    response::{IntoResponse, Response},    Json,};use thiserror::Error;use tracing::warn;// APIのエラー型を定義#[derive(Debug, Error)]pub enum ApiError {    #[error("Invalid postal code format")]    InvalidPostalCode,    #[error("Address not found")]    NotFound,    #[error("Internal server error: {0}")]    Internal(String),}// エラーをHTTPレスポンスに変換する実装impl IntoResponse for ApiError {    fn into_response(self) -> Response {        // エラーの種類に応じてステータスコードを設定        let (status, error_message) = match self {            ApiError::InvalidPostalCode => (StatusCode::BAD_REQUEST, self.to_string()),            ApiError::NotFound => (StatusCode::NOT_FOUND, self.to_string()),            ApiError::Internal(ref e) => {                // 内部エラーはログに記録                warn!("Internal server error: {}", e);                (                    StatusCode::INTERNAL_SERVER_ERROR,                    "Internal server error".to_string(),                )            }        };        // JSONレスポンスの構築        let body = Json(serde_json::json!({            "error": error_message,            "status": status.as_u16(),            // エラー追跡用のユニークID            "request_id": uuid::Uuid::new_v4().to_string()        }));        (status, body).into_response()    }}3. データモデルの定義（models.rs）APIで使用するデータ構造を定義します：use serde::{Deserialize, Serialize};// 住所情報のレスポンス構造体#[derive(Debug, Serialize, Deserialize, utoipa::ToSchema)]pub struct AddressResponse {    pub postal_code: String,    pub prefecture: String,    pub prefecture_kana: String,    pub prefecture_code: i32,    pub city: String,    pub city_kana: String,    pub town: String,    pub town_kana: String,    pub street: Option<String>,    pub office_name: Option<String>,    pub office_name_kana: Option<String>,}// jpostcode_rsのAddress型からの変換を実装impl From<jpostcode_rs::Address> for AddressResponse {    fn from(addr: jpostcode_rs::Address) -> Self {        AddressResponse {            postal_code: addr.postcode,            prefecture: addr.prefecture,            prefecture_kana: addr.prefecture_kana,            prefecture_code: addr.prefecture_code,            city: addr.city,            city_kana: addr.city_kana,            town: addr.town,            town_kana: addr.town_kana,            street: addr.street,            office_name: addr.office_name,            office_name_kana: addr.office_name_kana,        }    }}// 住所検索用のクエリ構造体#[derive(Debug, Deserialize, utoipa::ToSchema)]pub struct AddressQuery {    pub query: String,    #[serde(default = "default_limit")]    pub limit: usize,}// デフォルトの検索結果制限数fn default_limit() -> usize {    10}4. メトリクス収集の設定（metrics.rs）アプリケーションのパフォーマンスを監視するためのメトリクス設定：use metrics::{describe_counter, describe_histogram, register_counter, register_histogram};use metrics_exporter_prometheus::PrometheusBuilder;pub fn setup_metrics() {    // リクエスト数のカウンター    describe_counter!(        "yubin_api_postal_lookups_total",        "Total number of postal code lookups"    );    describe_counter!(        "yubin_api_address_searches_total",        "Total number of address searches"    );    // レスポンス時間のヒストグラム    describe_histogram!(        "yubin_api_postal_lookup_duration_seconds",        "Duration of postal code lookups in seconds"    );    describe_histogram!(        "yubin_api_address_search_duration_seconds",        "Duration of address searches in seconds"    );    // メトリクスの登録    register_counter!("yubin_api_postal_lookups_total");    register_counter!("yubin_api_address_searches_total");    register_histogram!("yubin_api_postal_lookup_duration_seconds");    register_histogram!("yubin_api_address_search_duration_seconds");    // Prometheusレコーダーの設定    PrometheusBuilder::new()        .install()        .expect("Failed to install Prometheus recorder");}Rustの知っておいたほうがいいポイント解説(前編)属性マクロの使用#[derive(...)]: 自動実装の導入#[error(...)]: エラーメッセージの定義#[serde(...)]: シリアライズ設定トレイトの実装From<T>: 型変換の実装IntoResponse: HTTPレスポンスへの変換Error: カスタムエラー型の定義ジェネリクスとライフタイムOption<T>: 省略可能な値の表現Result<T, E>: エラーハンドリングVec<T>: 可変長配列の使用型システムの活用カスタム構造体の定義列挙型によるエラー表現デフォルト値の実装Rust初学者のためのyubin_api実装解説 - 後編5. APIルートの実装（routes.rs）APIの実際のエンドポイントを実装します：use axum::{extract::Path, http::StatusCode, response::IntoResponse, Json};use metrics::{counter, histogram};use tracing::info;// ヘルスチェックエンドポイントpub async fn health_check() -> impl IntoResponse {    StatusCode::OK}// 郵便番号検索エンドポイントpub async fn lookup_by_postal_code(    Path(code): Path<String>,  // URLパスからパラメータを取得) -> Result<Json<Vec<AddressResponse>>, ApiError> {    // リクエストのログ記録    info!("Looking up postal code: {}", code);        // メトリクスのカウントアップ    counter!("yubin_api_postal_lookups_total", 1);        // 処理時間の計測開始    let start = std::time::Instant::now();    // 郵便番号検索の実行    let result = jpostcode_rs::lookup_address(&code).map_err(|e| match e {        jpostcode_rs::JPostError::InvalidFormat => ApiError::InvalidPostalCode,        jpostcode_rs::JPostError::NotFound => ApiError::NotFound,    })?;    // 処理時間の計測と記録    let duration = start.elapsed().as_secs_f64();    histogram!("yubin_api_postal_lookup_duration_seconds", duration);    // 結果の返却    Ok(Json(result.into_iter().map(Into::into).collect()))}// 住所検索エンドポイントpub async fn search_by_address(    Json(query): Json<AddressQuery>,  // リクエストボディからのJSONパース) -> Result<Json<Vec<AddressResponse>>, ApiError> {    info!("Searching address with query: {}", query.query);        // 入力値の検証    if query.query.trim().is_empty() {        return Err(ApiError::InvalidPostalCode);    }    counter!("yubin_api_address_searches_total", 1);    let start = std::time::Instant::now();    // 住所検索の実行    let mut results: Vec<AddressResponse> = jpostcode_rs::search_by_address(&query.query)        .into_iter()        .map(Into::into)        .collect();    // 結果数の制限適用    results.truncate(query.limit);    let duration = start.elapsed().as_secs_f64();    histogram!("yubin_api_address_search_duration_seconds", duration);    Ok(Json(results))}6. メインアプリケーションの実装（main.rs）アプリケーションのエントリーポイントとサーバーの設定：use axum::{routing::{get, post}, Router};use std::net::SocketAddr;use tower::ServiceBuilder;use tower_http::{    cors::{Any, CorsLayer},    trace::{DefaultMakeSpan, DefaultOnResponse, TraceLayer},};use tracing::info;#[tokio::main]async fn main() {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| "yubin_api=debug,tower_http=debug".into()),        )        .init();    // メトリクス収集の初期化    setup_metrics();    // リクエストトレース設定    let trace_layer = TraceLayer::new_for_http()        .make_span_with(DefaultMakeSpan::new().include_headers(true))        .on_response(DefaultOnResponse::new().include_headers(true));    // CORS設定    let cors = CorsLayer::new()        .allow_methods(Any)        .allow_headers(Any)        .allow_origin(Any);    // ルーターの設定    let app = Router::new()        .route("/health", get(health_check))        .route("/postal/:code", get(lookup_by_postal_code))        .route("/address/search", post(search_by_address))        .layer(ServiceBuilder::new()            .layer(trace_layer)            .layer(cors));    // サーバーアドレスの設定    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));    info!("Server listening on {}", addr);    // サーバーの起動    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();    axum::serve(listener, app).await.unwrap();}7. 重要な実装パターンの解説非同期処理// 非同期関数の定義pub async fn lookup_by_postal_code(...) -> Result<...> {    // 非同期処理の実行    let result = jpostcode_rs::lookup_address(&code)?;    // ...}// 非同期ランタイムの設定#[tokio::main]async fn main() {    // ...}エラーハンドリング// Result型を使用したエラー処理let result = jpostcode_rs::lookup_address(&code).map_err(|e| match e {    JPostError::InvalidFormat => ApiError::InvalidPostalCode,    JPostError::NotFound => ApiError::NotFound,})?;ミドルウェアの構成let app = Router::new()    .route(...)    .layer(ServiceBuilder::new()        .layer(trace_layer)        .layer(cors));8. API使用例郵便番号による検索curl http://localhost:3000/postal/1000001レスポンス例：[  {    "postal_code": "1000001",    "prefecture": "東京都",    "city": "千代田区",    "town": "千代田",    ...  }]住所による検索curl -X POST http://localhost:3000/address/search \  -H "Content-Type: application/json" \  -d '{"query": "東京都千代田区", "limit": 10}'9. Rustの知っておいたほうがいいポイント解説(後編)非同期プログラミングasync/awaitの使用方法tokioランタイムの理解非同期関数の定義と呼び出しエラーハンドリングパターンResult型の活用エラー変換のベストプラクティスエラーの伝播（?演算子）HTTPサーバーの実装ルーティング設定ミドルウェアの活用リクエスト/レスポンスの処理テスト可能な設計モジュール分割依存性の分離エラー処理の一貫性おわりにyubin_apiの実装を通じて、Rustによる実践的なWeb API開発の全体像を見てきました。このプロジェクトでは、カスタムエラー型の定義や型安全なデータ変換、トレイトの実装といった堅牢な型システムの活用を行いました。また、tokioによる非同期ランタイムやasync/awaitの効果的な使用、エラーハンドリングとの統合などの非同期プログラミングの実践も重要な要素となっています。さらに、メトリクス収集や構造化ログ、エラートラッキングといった運用面の考慮など、重要な概念と技術を学ぶことができました。このプロジェクトは、単なる郵便番号検索APIの実装を超えて、Rustの実践的な使用方法と、プロダクション品質のWebサービス開発の基本を学ぶ良い例となっています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[構造化ログのスキーマを考えてみる]]></title>
            <link>https://blog.atusy.net/2024/12/04/log-schema/</link>
            <guid>https://blog.atusy.net/2024/12/04/log-schema/</guid>
            <pubDate>Wed, 04 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[ログ設計初心者なりに、分析しやすいログってなにかなと考えてみた。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[argocd コマンドで別ブランチとの差分を確認する]]></title>
            <link>https://qiita.com/yteraoka/items/aea03d50288375f85183</link>
            <guid>https://qiita.com/yteraoka/items/aea03d50288375f85183</guid>
            <pubDate>Tue, 03 Dec 2024 15:14:17 GMT</pubDate>
            <content:encoded><![CDATA[ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に K…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LLMのモデル更新や廃止による影響を考える]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/12/03/232856</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/12/03/232856</guid>
            <pubDate>Tue, 03 Dec 2024 14:28:56 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません · Issue #3 · harukaxq/langchain-book · GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。]]></content:encoded>
        </item>
    </channel>
</rss>