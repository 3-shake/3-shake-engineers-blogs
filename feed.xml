<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 15 May 2025 22:35:25 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818</guid>
            <pubDate>Thu, 15 May 2025 14:08:18 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「新規プロジェクトに参画したら、アプリケーションがRustで書かれていた...」このような経験をされた方も多いのではないでしょうか。もしくは今後あるかもしれません。特に、オブザーバビリティの実装を担当することになったインフラエンジニアにとって、Rustは馴染みの薄い言語かもしれません。このガイドは、インフラエンジニアとしての経験は豊富だが、Rustの経験が少ないインフラエンジニアのために書かれています。既存のRustアプリケーションにログ、メトリクス、トレーシングを実装する方法を、Rustの前提知識を必要とせずに理解できるよう解説します。前提知識が不要なだけで都度学習はしてもらいます。想定読者オブザーバビリティの実装経験があるPython、Java、Goなどでの実装経験はあるRustは初めて触れる、もしくは経験が浅い既存のRustアプリケーションにオブザーバビリティを実装する必要があるこのガイドで得られることRustアプリケーションの基本的な構造の理解オブザーバビリティ実装に必要なRustの最小限の知識実装手順とコード例トラブルシューティングのポイントまず、典型的なRustのWebアプリケーションの構造を見ていきましょう。Rustの基本的な概念アトリビュート（#[...]）Rustでは#[...]という記法をアトリビュート（属性）と呼びます。これはコードに対して追加の情報や機能を付与する特別な構文です。アトリビュートを使用することで、コンパイラへの指示や機能の自動実装が可能になります。これは他の言語では以下のように表現されるものに相当します。Java: アノテーション（@SomeAnnotation）Python: デコレータ（@decorator）TypeScript: デコレータ（@decorator）参考: The Rust Reference - Attributes主なアトリビュートの例：// 自動的に特定の機能を実装する#[derive(Debug)]  // println!("{:?}", obj)でデバッグ出力を可能にする                  // 例: println!("{:?}", user); // User { id: 1, name: "John" }#[derive(Clone)]  // オブジェクトのクローン（複製）を可能にする                  // 例: let user2 = user.clone();#[derive(Serialize, Deserialize)]  // JSONとの相互変換を可能にする                  // 例: let json = serde_json::to_string(&user)?;                  // let user: User = serde_json::from_str(&json)?;// 関数やモジュールの属性を指定する#[test]  // テスト関数であることを示す         // 例: cargo testでテストとして実行される#[actix_web::main]  // actix-webのメイン関数であることを示す                    // 非同期ランタイムの設定を自動的に行うアトリビュートが実際に何をしているのかを具体例で見てみます。// #[derive(Debug)]がない場合struct User {    id: u32,    name: String,}let user = User { id: 1, name: "John".to_string() };println!("{:?}", user);  // コンパイルエラー！// #[derive(Debug)]がある場合#[derive(Debug)]struct User {    id: u32,    name: String,}let user = User { id: 1, name: "John".to_string() };println!("{:?}", user);  // User { id: 1, name: "John" } と出力されるアトリビュートを使用することで、以下のようなメリットが得られます。- ボイラープレートコードの削減- 標準的な機能の自動実装- コンパイル時の動作制御- フレームワークとの統合Rust By Example - AttributesRust Derive マクロのドキュメント構造体（struct）とパターンマッチング（match）Rustの構造体は、他の言語のクラスに相当します。また、パターンマッチングは他言語のswitch文に似ていますが、より強力です。// match式の例match result {    Some(value) => println!("値が存在します: {}", value),    None => println!("値が存在しません"),}参考: The Rust Programming Language - Pattern Matchingエンドポイントの戻り値型-> impl Responderこれは「Responderトレイトをimplementsする何らかの型」を返すことを意味します。雑に言うとJavaのインターフェースやTypeScriptの型に似た概念です。参考: Actix Web - Responder traitMutexを使用したデータの共有users: Mutex<HashMap<u32, User>>Mutexは「相互排除（Mutual Exclusion）」の略で、複数のスレッドから安全にデータにアクセスするための機構です。参考: Rust Standard Library - MutexPath引数の取得id: web::Path<u32>URLのパスパラメータを型安全に取得します。例：/users/123の123部分。参考: Actix Web - Path ExtractorWebアプリケーションの完全な実装それでは、典型的なRustのWebアプリケーションの構造を見てみましょう。// src/main.rs - 既存のWebアプリケーションuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;// Rustでは構造体の定義に#[derive(...)]という形式で機能を追加します// SerializeとDeserializeは、JSONとの相互変換を可能にします#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}// AppStateは、アプリケーション全体で共有する状態を定義します// Mutexは、複数のスレッドから安全にデータを変更するために使用しますstruct AppState {    users: Mutex<HashMap<u32, User>>,    user_counter: Mutex<u32>,}// エンドポイントの実装async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;        HttpResponse::Created().json(new_user)}async fn get_user(    state: web::Data<AppState>,    id: web::Path<u32>) -> impl Responder {    let users = state.users.lock().unwrap();        match users.get(&id.into_inner()) {        Some(user) => HttpResponse::Ok().json(user),        None => HttpResponse::NotFound().finish()    }}#[actix_web::main]async fn main() -> std::io::Result<()> {    // アプリケーションの状態を初期化    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    HttpServer::new(move || {        App::new()            .app_data(app_state.clone())            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}参考:- Actix Web Documentation- Serde JSON Documentation- Rust Standard Library - HashMapAPIの使用例# ヘルスチェックcurl http://localhost:8080/health# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0この基本的な実装を理解することで、次のステップであるオブザーバビリティの実装がより理解しやすくなります。Rustの重要な概念（インフラエンジニアが知っておくべきこと）依存関係の管理RustではCargo.tomlファイルで依存関係を管理しますnpmのpackage.jsonやrequirements.txtに相当します[dependencies]name = "version"  # 基本的な依存name = { version = "version", features = ["feature1", "feature2"] }  # 機能を指定モジュールとパスuseキーワードでモジュールをインポートしますmodキーワードで新しいモジュールを定義します// src/logging.rs などの新しいファイルを作成した場合mod logging;  // main.rsでこのように宣言use crate::logging::setup_logger;  // 関数を使用する際はこのように指定エラーハンドリングRustではResult<T, E>型でエラーハンドリングを行います?演算子でエラーを上位に伝播させます// エラーハンドリングの例fn function() -> Result<(), Box<dyn Error>> {    let result = something_that_might_fail()?;  // エラーが発生したら即座にReturnします    Ok(())}オブザーバビリティの実装syu-m-5151.hatenablog.com依存関係の追加まず、Cargo.tomlに必要な依存関係を追加します。[dependencies]# 既存の依存関係actix-web = "4.4"serde = { version = "1.0", features = ["derive"] }serde_json = "1.0"# オブザーバビリティ関連の依存関係を追加tracing = "0.1"tracing-subscriber = { version = "0.3", features = ["env-filter"] }tracing-actix-web = "0.7"prometheus = "0.13"lazy_static = "1.4"opentelemetry = { version = "0.21", features = ["rt-tokio"] }opentelemetry-otlp = "0.14"tracing-opentelemetry = "0.22"モジュール構造の作成オブザーバビリティ関連のコードを整理するために、以下のような構造を作成します。// src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::setup_metrics;pub use tracing::setup_tracing;ログの実装今度、別でRust のロギングのライブラリの比較をしたいです⋯。moriyoshi.hatenablog.comwww.forcia.comライブラリが云々よりも実際にちゃんと設計するのも大切ですよね。qiita.com// src/observability/logging.rsuse tracing::{info, warn, error, Level};use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("{}=info", env!("CARGO_PKG_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}// ログマクロの使用例// info!("メッセージ");// error!("エラー: {}", err);メトリクスの実装この辺はぜひもう一度読んでほしいです。syu-m-5151.hatenablog.com// src/observability/metrics.rsuse prometheus::{Registry, Counter, IntCounter, opts};use lazy_static::lazy_static;// メトリクスの定義lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();    pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        "http_requests_total",        "Total number of HTTP requests"    ).unwrap();    pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!("user_operations_total", "Total number of user operations")            .const_label("service", "user-api")    ).unwrap();}pub fn setup_metrics() -> Result<(), Box<dyn std::error::Error>> {    // メトリクスの登録    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}// Prometheusメトリクスエンドポイント用のハンドラpub async fn metrics_handler() -> impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(&REGISTRY.gather(), &mut buffer).unwrap();        HttpResponse::Ok()        .content_type("text/plain")        .body(buffer)}トレーシングの実装// src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -> Result<(), Box<dyn std::error::Error>> {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var("OTLP_ENDPOINT")                        .unwrap_or_else(|_| "http://localhost:4317".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new("service.name", "user-api"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    // トレーシングの初期化    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}既存のエンドポイントへの統合// 修正後のcreate_user関数#[tracing::instrument(name = "create_user", skip(state, user_data))]async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    // メトリクスのインクリメント    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    // ログの出力    info!(        user_name = %user_data.name,        user_email = %user_data.email,        "Creating new user"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, "User created successfully");        HttpResponse::Created().json(new_user)}メインアプリケーションの更新#[actix_web::main]async fn main() -> std::io::Result<()> {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect("Failed to setup metrics");    setup_tracing().expect("Failed to setup tracing");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!("Starting server at http://localhost:8080");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route("/metrics", web::get().to(metrics_handler))            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}3. 動作確認アプリケーションの起動# 開発モードで実行cargo run# 本番モードで実行（最適化あり）cargo run --releaseAPIのテスト# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsログの確認# 環境変数でログレベルを設定RUST_LOG=debug cargo run4. トラブルシューティング一般的な問題と解決方法コンパイルエラー依存関係のバージョンの不一致cargo update  # 依存関係を更新ランタイムエラーOpenTelemetryエンドポイントに接続できない# エンドポイントの確認OTLP_ENDPOINT=http://localhost:4317 cargo runメトリクスが表示されないPrometheusレジストリの確認// メトリクスが正しく登録されているか確認println!("Registered metrics: {:?}", REGISTRY.gather());5. 本番環境への展開環境変数の設定# 必要な環境変数export RUST_LOG=infoexport OTLP_ENDPOINT=http://otel-collector:4317export SERVICE_NAME=user-apiDockerファイルの例FROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-app /usr/local/bin/CMD ["my-app"]6.Rustオブザーバビリティ実装の最終成果物ディレクトリ構造my-rust-api/├── Cargo.toml├── Dockerfile├── .env└── src/    ├── main.rs    └── observability/        ├── mod.rs        ├── logging.rs        ├── metrics.rs        └── tracing.rs各ファイルの実装Cargo.toml[package]name = "my-rust-api"version = "0.1.0"edition = "2021"[dependencies]actix-web = "4.4"serde = { version = "1.0", features = ["derive"] }serde_json = "1.0"tokio = { version = "1.0", features = ["full"] }tracing = "0.1"tracing-subscriber = { version = "0.3", features = ["env-filter"] }tracing-actix-web = "0.7"prometheus = "0.13"lazy_static = "1.4"opentelemetry = { version = "0.21", features = ["rt-tokio"] }opentelemetry-otlp = "0.14"tracing-opentelemetry = "0.22"src/main.rsuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;use tracing::info;mod observability;use observability::{setup_logging, setup_metrics, setup_tracing, metrics_handler};#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}struct AppState {    users: Mutex<HashMap<u32, User>>,    user_counter: Mutex<u32>,}#[tracing::instrument(name = "create_user", skip(state, user_data))]async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    use crate::observability::metrics::USER_OPERATIONS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    info!(        user_name = %user_data.name,        user_email = %user_data.email,        "Creating new user"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, "User created successfully");    HttpResponse::Created().json(new_user)}#[tracing::instrument(name = "get_user", skip(state))]async fn get_user(    state: web::Data<AppState>,    id: web::Path<u32>) -> impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    let users = state.users.lock().unwrap();        match users.get(&id.into_inner()) {        Some(user) => {            info!(user_id = user.id, "User found");            HttpResponse::Ok().json(user)        },        None => {            info!(user_id = %id, "User not found");            HttpResponse::NotFound().finish()        }    }}#[actix_web::main]async fn main() -> std::io::Result<()> {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect("Failed to setup metrics");    setup_tracing().expect("Failed to setup tracing");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!("Starting server at http://localhost:8080");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route("/metrics", web::get().to(metrics_handler))            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::{setup_metrics, metrics_handler};pub use tracing::setup_tracing;pub(crate) use metrics::HTTP_REQUESTS_TOTAL;pub(crate) use metrics::USER_OPERATIONS_TOTAL;4. src/observability/logging.rsuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("{}=info", env!("CARGO_PKG_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}src/observability/metrics.rsuse actix_web::{HttpResponse, Responder};use prometheus::{Registry, IntCounter, opts};use lazy_static::lazy_static;lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();        pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        "http_requests_total",        "Total number of HTTP requests"    ).unwrap();        pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!("user_operations_total", "Total number of user operations")            .const_label("service", "user-api")    ).unwrap();}pub fn setup_metrics() -> Result<(), Box<dyn std::error::Error>> {    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}pub async fn metrics_handler() -> impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(&REGISTRY.gather(), &mut buffer).unwrap();        HttpResponse::Ok()        .content_type("text/plain")        .body(buffer)}src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -> Result<(), Box<dyn std::error::Error>> {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var("OTLP_ENDPOINT")                        .unwrap_or_else(|_| "http://localhost:4317".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new("service.name", "user-api"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}.envRUST_LOG=infoOTLP_ENDPOINT=http://localhost:4317SERVICE_NAME=user-apiDockerfileFROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-rust-api /usr/local/bin/COPY .env /usr/local/bin/WORKDIR /usr/local/binCMD ["my-rust-api"]動作確認方法アプリケーションの起動:cargo runAPIのテスト:# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsこの実装により、以下のオブザーバビリティ機能が利用可能になります。ログ出力：構造化ログが標準出力に出力されますメトリクス：/metricsエンドポイントでPrometheus形式のメトリクスが取得可能トレーシング：OpenTelemetryを通じて分散トレーシングが可能各機能は環境変数を通じて設定可能で、本番環境での運用に対応しています。7. 参考リンクRust公式ドキュメントActix-Web ガイドZero To Production In RustRust Web Programming - Third EditionOpenTelemetry RustPrometheus Rust Clienttracing クレートRustを使った社内用Webアプリの開発・運用を持続させるために、素材メーカーが学んだことまとめこのガイドでは、Rustの経験が浅いインフラエンジニアを対象に、既存のRustアプリケーションにオブザーバビリティを実装する方法を解説しました。アトリビュートやトレイトといったRustの基本的な概念から始め、オブザーバビリティ実装に必要な最小限の知識を説明しました。Cargoを使用した依存関係の管理方法や、モジュール構造の基本についても触れることで、Rustの開発環境への理解を深めることができたと思います。実装面では、ログ出力にtracing、メトリクスにprometheus、分散トレーシングにOpenTelemetryを採用し、それぞれを個別のモジュールとして整理された形で実装する方法を示しました。これにより、構造化ログによる効率的なログ管理や、Prometheusと互換性のあるメトリクスエンドポイント、そしてOpenTelemetryによる分散トレーシングといった実用的な機能を実現することができました。このガイドを通じて、Rustの詳細な知識がなくても、実用的なオブザーバビリティ機能を実装できることを示すことができました。Cargoのパッケージは複雑怪奇なので注意してほしいです。オブザーバビリティの実装は、アプリケーションの健全性監視と問題解決に不可欠です。このガイドが、Rustでのオブザーバビリティ実装に取り組むインフラエンジニアの一助となれば幸いです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[clickを使ってPythonのコマンドライン引数をきれいにしよう！]]></title>
            <link>https://zenn.dev/akasan/articles/034598cbd096e2</link>
            <guid>https://zenn.dev/akasan/articles/034598cbd096e2</guid>
            <pubDate>Thu, 15 May 2025 13:08:26 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Pythonできれいなコマンドラインインターフェースを実装できるclickについて紹介してみようと思います。 clickとは？clickとはPythonできれいなコマンドラインインターフェースを実装するためのライブラリです。その名前はCommand Line Interface Creation Kitの頭文字をとったようです。レポジトリは以下になります。https://github.com/pallets/clickclickはコマンドラインツールを素早く実装できることに注力しており、従来のsysやargparseを利用したものと比べて格段に実装難易度が下がっていると...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』]]></title>
            <link>https://sreake.com/blog/introduction-long-context-llms-meet-rag/</link>
            <guid>https://sreake.com/blog/introduction-long-context-llms-meet-rag/</guid>
            <pubDate>Thu, 15 May 2025 01:01:02 GMT</pubDate>
            <content:encoded><![CDATA[RAG（Retrieval Augmented Generation）は、LLM（Large Language Model：大規模言語モデル）が知らない情報を外部から与えてあげることで、LLMの知識を拡張する手法です。R […]The post 論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Guacamoleとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/6af98c0cd8fcff</link>
            <guid>https://zenn.dev/akasan/articles/6af98c0cd8fcff</guid>
            <pubDate>Wed, 14 May 2025 10:50:43 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Guacamoleとは何かについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Guacamoleとは？公式サイトを見ると、Apache Guacamole is a clientle...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[curl使い方についてまとめてみた]]></title>
            <link>https://zenn.dev/akasan/articles/4248554eb4797b</link>
            <guid>https://zenn.dev/akasan/articles/4248554eb4797b</guid>
            <pubDate>Tue, 13 May 2025 11:37:37 GMT</pubDate>
            <content:encoded><![CDATA[今回はcurlの使い方について調べてみました。今までAPIのアクセステストとかに使っていましたが、ちゃんと調べたことなかったので、この際調べてみようということで記事にしました。 curlとは？ドキュメントから拝借すると、curl is used in command lines or scripts to transfer data. curl is also libcurl, used in cars, television sets, routers, printers, audio equipment, mobile phones, tablets, medical de...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishに引っ越したい人のためのZsh履歴活用術]]></title>
            <link>https://blog.atusy.net/2025/05/13/inherit-zsh-history-in-fish/</link>
            <guid>https://blog.atusy.net/2025/05/13/inherit-zsh-history-in-fish/</guid>
            <pubDate>Tue, 13 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[シェルを移行する歳、設定だけでなくコマンド履歴も引き継ぎたいものです。Fishは設定が小さくすみやすい上に情報も多いので、今回はFishからZshのコマンド履歴を活用する方法を紹介します。fzfを使っているので、検索効率もいいですよ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovim最先端のextuiでフローティングウィンドウ化したメッセージをいつでも非表示にする方法]]></title>
            <link>https://blog.atusy.net/2025/05/13/nvim-extui-msgbox-closer/</link>
            <guid>https://blog.atusy.net/2025/05/13/nvim-extui-msgbox-closer/</guid>
            <pubDate>Tue, 13 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Neovimのextuiで表示されたメッセージボックスは、所定の時間が経過すると自動で閉じます。<C-L>で非表示にする方法を紹介します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ランレングス符号化をPythonで実装してみた]]></title>
            <link>https://zenn.dev/akasan/articles/9430f41e6cff7a</link>
            <guid>https://zenn.dev/akasan/articles/9430f41e6cff7a</guid>
            <pubDate>Mon, 12 May 2025 14:35:35 GMT</pubDate>
            <content:encoded><![CDATA[今回は、ランレングス符号化をPythonで実装してみたので、その解説をしてみようと思いまs。 ランレングス符号化とは？ランレングス符号化とはデータ圧縮方式の一つで、連続する同じデータをまとめて扱うことで圧縮をするというものです。たとえばAABBBCCCCというテキストがあった場合に、各文字とそれがいくつ連続しているかという情報に変換してみます。するとA2B3C4のように変換でき、元のテキストの長さ9文字と比較して6文字に収めることができます。ただし、ランレングス符号化では必ず圧縮後のデータ量が小さくなる保証はありません。たとえばABCDEF....XYZのようにアルファベットが...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SSHの基本を理解したい(シーケンス図付き)]]></title>
            <link>https://zenn.dev/meziron/articles/a42cef62e06a68</link>
            <guid>https://zenn.dev/meziron/articles/a42cef62e06a68</guid>
            <pubDate>Mon, 12 May 2025 00:00:05 GMT</pubDate>
            <content:encoded><![CDATA[1. 初回 SSH 接続時の流れ (秘密鍵のパスフレーズ入力あり)このシナリオでは、ユーザーが初めて特定のサーバーに SSH 接続を試みるか、あるいは SSH エージェントにまだ該当の秘密鍵がロードされていない状況を想定します。秘密鍵はパスフレーズで保護されているものとします。 登場人物User: 操作を行うユーザーSSH_Client: ユーザーが操作する SSH クライアント（例: sshコマンド）SSH_Agent: SSH エージェントプロセス（秘密鍵をメモリに保持）SSH_Server: 接続先の SSH サーバー 初回接続時の流れのポイント...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python 3.13の新機能について調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/423451d2bb8249</link>
            <guid>https://zenn.dev/akasan/articles/423451d2bb8249</guid>
            <pubDate>Sun, 11 May 2025 14:23:08 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Python3.13で導入される新機能についてまとめてみました。私自身、普段は3.11または3.12を使うことが多く、3.13についてはどのような機能が追加されるか認識していなかったので調べてみました。 追加される新機能まず、Python3.13で導入される新機能はこちらにまとまっていますので、詳しくは参照ください。https://docs.python.org/3/whatsnew/3.13.html#other-language-changes よりよいインタラクティブインタプリタPyPyプロジェクトのコードをベースとした新しいインタラクティブシェルをデフォルト...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Compress Ant Libraryとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/ba9cf85b99b68f</link>
            <guid>https://zenn.dev/akasan/articles/ba9cf85b99b68f</guid>
            <pubDate>Sat, 10 May 2025 14:08:12 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Compress Ant Libraryとは何かについて調べてみました。なぜ調べてみようかと思ったかというと、こちらで作成したツールを使う第一号をやってみたかったからです。https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Compress Ant Libraryとは...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[中学17年生]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/10/205353</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/10/205353</guid>
            <pubDate>Sat, 10 May 2025 11:53:53 GMT</pubDate>
            <content:encoded><![CDATA[はじめに気づけば「中学17年生」だ。肩書きは立派な「ソフトウェアエンジニア」「登壇者」「翻訳者」「執筆者」だが、心の奥底では未だに教室の隅っこでふざけあう中学生のような気持ちでいる。会社のIDカードをぶら下げて歩いていると、「これ、誰かの忘れ物かな？」と思うことがある。大人のコスプレが上手くなっただけで、中身はまだあの頃のまま。表向きは30歳のエンジニアでありながら、内側には未だに中学生の感性を宿している。年齢と肩書きだけが大人の証ではなく、混沌とした感情や未熟さを受け入れる勇気こそが、本当の成長の証かもしれない。教室の窓から外を眺め、「早く大人になりたい」と思っていた頃の自分に、「実はなれてないよ。でも大丈夫、みんな同じさ」と教えてあげたい。幸せな時間はあっという間に過ぎていく。「これもいつか終わるんだろうな」と考えながら楽しいひとときを過ごすのは、30歳を前にした私のような人間の性かもしれない。常に砂時計の砂が落ちていくのを見続けているような感覚だ。過去の自分を否定せず、かといって執着もせず、ただ前を向いて歩き続ける。大人になれば全てが分かると思っていたのに、実際は「分からないことが分かる」だけだった。誰かに言われて落ち込むというより、自分で自分にハードルを上げすぎて、それを超えられなかったときの静かな絶望感の方がはるかに大きい。完璧を目指すあまり、一歩も前に進めなくなるという皮肉。そして「身の程」を知るようになった。自分の能力や限界への理解が深まるほど、逆に自信を持って胸を張れるようになった。ライブラリを全部理解していなくても、「今は分からないけど調べれば理解できる」という余裕が生まれた。自分の限界を知ることは、弱さではなく強さだと気づいた。雨の日に窓辺で立ち尽くし、「早く大人になりたいな」と呟いていた中学生に言ってあげたい。「大丈夫、大人になっても同じように窓の外を眺めているよ。でも、傘を持って外に出る勇気だけは身についたかな」と。年齢は小さな枠組みで「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。いくつになっても成長できると思えるようになったのは、30歳を前にした最大の収穫かもしれない。この中学17年生、すなわち30歳になろうとしているエンジニアは、まだまだ未熟だけれど、その未熟さも含めて自分自身なのだと受け入れる勇気を持ち始めている。今日も窓の外を眺めながら、雨が降っていても傘を持って一歩踏み出す。そんな日々を、中学生のような好奇心と、大人としての覚悟を持って生きていきたい。初めてこの文章を読んでくださる方も、いつも読んでくださっている方も、お時間をいただきありがとうございます。こちらはB面シングルである。A面は「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」をぜひ読んでみてください。口太郎の焦燥「あなたは口から生まれた口太郎」母親からそう言われたことがある。幼稚園では隅っこで本を読む子だったが、小学生から急に喋り始め、人前で話すのが得意になった。母子家庭で暗い空気を変えたかったのかもしれない。もしくは治安の悪い小学校で生き抜く術だったのかもしれません。朝、パーカーを着て、オフィスに向かう。「おはようございます」と言いながら不思議な感覚に襲われる。「なんで俺、ここにいるんだろう？」スタンディングデスクに向かい、MacBookを開く髭面の男。パーマヘアとサングラスの下には、実は中学生の心を隠している。会議室で専門的な議論をする最中にも「これ、本当に俺が言ってるの？」と感じることがある。あの日、教室で絶えず喋っていた少年が、突然30代の身体に転送されたような感覚。「では○○さんはどう思いますか？」と振られた瞬間、内心は複雑だ。話す内容に本当に価値があるのか？単なる思いつきではないのか？表面上は堂々としていても、内心では「これは個人的な経験の押し付けではないか」という自問が絶えない。N=1の経験で語ることへの後ろめたさ。もっと多くの事例、体系的な知識、裏付けのある情報に基づいて話したい。この葛藤は一時期、本当に深刻だった。登壇前夜は「俺の話に価値があるのか」と不安で眠れない。「お前の知識は浅すぎる。もっと文献を読め。もっと体系的に理解しろ」という内なる声。深夜、PCに向かい論文や技術書を読み漁る。この知識が自分の存在証明になるような気がしていた。しかしある日気づいた。なぜこれほど「体系的な知識」にこだわるのか？それは単なる自己防衛ではないのか？そしてまた気づいた。自分のN=1経験を否定することは、誰にでも言える一般論だけを語ることになる。N=1がなければ、本当の「血の通った知識」にはならない。文献から得た知識も、自分の経験を通して初めて命を吹き込まれる。「N=1だから価値がない」のではなく、「N=1だからこそ伝えられる真実がある」のだ。アウトプットへの執着が、質の高いインプットを求める原動力になっていた。登壇準備では「これは他の人でも再現できるのか？」「普遍的な教訓か？」と自問自答する。そして気づいたのは、価値あるアウトプットをするためには質の高いインプットが不可欠だということ。表面的な理解だけでなく、深く掘り下げ、多角的に検証し、時に自分の考えを否定することも辞さない。N=1の限界を認識しつつも、その価値を大切にする。自分の経験こそがリアリティを生み、他者の共感を呼ぶ。一方で、N=1を超えるため、文献を読み、他者の事例を学び、様々な理論を比較検討する。この個人的体験と普遍的知識のバランスを取りながら、インプットとアウトプットのサイクルを回し続けることで、少しずつ自信がついてきた。「これは単なる個人的な意見です」と後ろめたく断るのではなく、「この考えは自分の経験と、こういう体系に基づいています」と胸を張って言えるようになった。完璧ではなくても、N=1の経験者だからこそ語れる真実があると信じ、現時点での最善を尽くすことの大切さを学んだ。それでも言葉が伝わらない日もある。説明すればするほど相手の表情が曇り、終わった後の虚無感。そんな日は電車の窓に映る自分を見て「お前、何様のつもりだ」と責める。その窓に映る自分は、かつての父親に重なる。見た目は大人になったが、中身は「テスト返却、やばい...」と思う少年のまま。それでも今日も本を開き、情報を集める。自分のN=1を大切にしながら、それを超える知識を求め続ける。それが、口太郎としての責任の果たし方なのだ。ふーん、ムッチじゃん三十路の入り口に立って思うのは、自分の知識はまだほんの入り口だということ。10代の頃は「自分はほとんど全てを知っている」と思い、20代で「自分は何も知らない」と気づき、30手前で「何も知らないことすら完全には理解していない」という事実に辿り着いた。でも、これは悪いことじゃない。この「無知の知」こそが学びの始まりだ。30歳という節目を前に、不思議な安心感がある。以前は「知らない」と認めることが弱みを晒すように感じていた。しかし今では、知らないことを素直に認め、学び続ける姿勢こそが強さだと気づいた。成長とは、わからないことが増えていく過程でもあるのだ。人生の解像度が上がってきた。初めて眼鏡をかけたような感覚だ。以前は見えなかった細部、気づかなかった背景、関連性が鮮明に浮かび上がる。かつての私は「この不具合はこのコードが原因だ」と表層的な事実に振り回され、問題を「解決すること」だけに価値を見出していた。機能するコードを書けば満足していた。しかし30歳に近づくにつれ、「なぜこのバグが発生したのか」「どんな思考プロセスがこの決断を導いたのか」という問いに関心が移ってきたのだ。解像度が上がると自分の限界も他者の弱さも鮮明に見えてくる。できると思っていたことができない自分、理解していると思っていたことが理解できない自分に直面する。同僚のコードレビューで見落としがあれば自己嫌悪に陥り、技術書を読んでも理解できない箇所があれば絶望する。同時に、かつては完璧だと思っていた上司にも弱さがあることに気づく。「みんな同じなんだ」という気づきは、時に励みになり、時に孤独を感じさせる。誰もが不安や焦り、コンプレックスを抱えているのだ。人の言動にも多角的な視点を持つようになった。同僚の一言に腹を立てる代わりに、なぜその言葉が出てきたのか、どんな背景があるのかを考えるようになった。そんな自分を周囲は「考えすぎだよ」と笑うこともある。確かに物事を複雑に考えすぎる一方で、新しい技術に出会うと少年のように純粋に熱中する自分もいる。最新ライブラリを発見して「うおおこれヤバい！」と一人テンションが上がる姿は、中学生と何も変わらない。この相反する二面性を、どちらも大切にしていきたいと思う。時々、深い孤独に襲われる。技術的な話をしていても「この人、本当はわかってないな」と感じたり、逆に「自分こそが理解できていないのでは」と不安になったりする。言葉は伝わっているようで、本当は伝わっていない。そんな夜は、パソコンの前で一人、沈黙の中に沈む。人生の解像度が上がるとは、世界をより鮮明に、立体的に、繊細に感じられるようになること。複雑さを恐れず、その豊かさを楽しめるようになること。シンプルさの中にある深い真理を見抜けるようになること。この視点の成熟こそが、30歳を前にした最大の収穫だと思う。この好奇心と探求心は、ずっと失わないでいたい。努力の質を高める戦略的サボり方のススメ子供の頃や20代前半は何事もがむしゃらにやってきた。とにかく時間をかけて、労力をかけて、血反吐を吐くほど頑張ることが美徳だと信じていた。しかし30歳を前にして、ようやく「サボり方」の本質を理解した。やるべきことの絶対的な量を減らすのではなくて、得意なことをより頑張るためにそうじゃないことをやらないことである。振り返れば、私が過剰に努力してきた背景には経験不足へのコンプレックスがあった。「努力で他の人に負けたくない」という思いが、自分を追い込む原動力だった。通勤電車でも技術記事を読み、休日も勉強会に参加し、寝る前もコードを書く。そんな日々が当たり前になっていた。以前の私は、プロジェクトの全てに関わろうとしていた。本来の開発業務だけでなく、新卒採用活動、社内勉強会の企画・運営、技術ドキュメント整備、翻訳、執筆、登壇準備まで次々と引き受けた。結果、Todo リストは膨れ上がり、何から手をつければいいのか分からなくなった。抱え込みすぎて身動きが取れなくなり、どの成果物も中途半端になり、最終的には時間も質も犠牲になった。ある日の内省で気づいたのは、「開発以外の仕事もすべて引き受ける」という強迫観念は美徳ではなく、生産性を下げる要因だということ。今は違う。「これは他の人に任せよう」「この会議は本当に私が出席すべきか」と常に問いかける。自分にとって本質的でないことを手放すことで、核心的な部分により深く集中できるようになった。これが「サボり」という名の知恵の正体だ。「推論能力が高い人は、生まれつきの才能だ」と思っていた時期もあった。しかし現実は異なる。人が「思考力」と呼ぶものの正体は、過去に勉強したり経験したりして蓄積した膨大な記憶の集合体だ。「才能だけで勝負できたらいいのに」という願望は、「努力せずに結果を出したい」という甘えに過ぎない。若かった頃は「努力の量=成果」という単純な方程式を信じていた。しかし実際は、あるポイントを超えると努力の量は結果に結びつかず、むしろパフォーマンスを低下させる。24時間コードを書き続けても、24時間分の価値は生まれない。8時間集中して働き、残りの時間は休息や刺激を得る方が生産性は高まる。今は「直線的な成果」より「累積的な成果」を重視する。一度の努力が何度も実を結ぶシステムを作ることの価値を知った。「楽をするのは悪いことだ」という思い込みを捨て、「どうやったらもっと楽になるか？」を常に考えるようになった。これはずるくなったのではなく、より賢く生きるための知恵だ。今でも時々、深夜まで技術書を読む自分がいる。違いは、それが強迫観念からではなく、純粋な好奇心から生まれていることと、「今日はここまで」と自分で線引きできるようになったこと。経験不足へのコンプレックスを糧にして前に進む方法を見つけた。適切にサボりながらマルチタスクは避け、深い思考力を養いつつ、累積的な成果を上げる方法を模索することが何より大切だと気づいた。これが30歳を前にした私が見つけた、努力の質を高める戦略だ。大人の責任と子供の好奇心のバランス年齢を重ねるごとに、肩に背負うものは確実に増えていく。責任という名の荷物は年々重くなる一方だ。給料は責任に支払われる。プロジェクトの成否、周りの成長、自分のキャリア——すべてが自分の決断にかかっている。「昨日の自分の選択が今日の現実を作っている」と痛感する日々。もはや「環境のせい」という言い訳は通用しない。そんな中で気づいたのは、「責任ある大人」と「好奇心旺盛な子供」という二つの側面を持ち続けることが、私の心のバランスを保っていることだ。これは矛盾ではなく、むしろ相互補完的な関係なのだと分かってきた。重みばかりを背負えば疲弊し、軽やかさだけを求めれば空虚になる。しかし、この二面性はコンプレックスによってさらに複雑になる。「もっとできるはずなのに」という自己期待と「周りと比べて足りない」という不安が交錯する。リリース前日の緊張感、大規模なリファクタリングの決断、若手への指導…。「間違ったらどうしよう」という恐怖と同時に、「自分にできるのか」という疑念が常につきまとう。責任を果たそうとすればするほど、コンプレックスが膨らんでいく皮肉。20代前半は「エンジニアとしてこうあるべき」という理想に縛られていた。流行りのフレームワークを追いかけ、GitHubの草を生やすことに躍起になっていた。SNSでは皆が凄いプロジェクトを作っている。オープンソースに貢献し、技術書を書き、登壇する。そんな人たちと比べて、自分は何もできていない——そんな劣等感に苛まれていた。技術の話で分からないことがあっても、怖かったのだ、無知を晒すことが。しかし30歳に近づく今、そんな見栄や焦りが少しずつ剥がれ落ちてきた。世界最高のプログラマーになる必要はない。自分にしかできないことを見つけ、それを磨いていけばいい。「これが今の自分のベストだ」と受け入れられるようになった。時に内なる声が聞こえてくる。「お前みたいに登壇ばかりしているのは、結局技術から逃げているだけだ」と。それは自分の中の「技術至上主義者」の声だ。すると別の声が反論する。「技術ブログも書いているし、普通にコードも書いている技術顧問として仕事もしているし、OSSも公開している。なぜ自分を否定するんだ」と。この内なる対話は終わりがない。表面上は微笑みながらも、心の中では「10年後、お前はどんな場所にいるだろう」という問いを抱え続けている。コンプレックスを抱えながらも、それを力に変えていく。好奇心は新しい技術への情熱として、責任感は仕事への真摯な姿勢として。この二つが時に矛盾し、時に補完し合いながら、私というエンジニアを形作っている。完璧主義のコンプレックスは、時に自分を追い詰めるが、それが高い基準を保つ原動力にもなる。大切なのは、それに押しつぶされないことだ。経験を重ねるにつれ、未熟な自分の使い方が分かってきた。自分の得意不得意を理解し、ほどよく力の抜けた自分なりのリズムを見つけられるようになった。以前のような「完璧なコード」への執着から解放され、「適切に機能するコード」「メンテナンスしやすいコード」という現実的な価値観へとシフトした。20歳の頃は周りの「すごい人たち」に圧倒されていた。それと比べて30歳を前にした今は、不思議と清々しい気持ちでいる。「完璧なエンジニア」を目指すのではなく、「自分らしいエンジニア」として歩んでいこうという気持ちが強くなった。大人の責任感と子供の好奇心、そして自分特有のコンプレックス。この複雑な混合物を抱えながらも、それを自分の個性として受け入れていく。これが私の見つけた、エンジニアとしてのバランスの取り方だ。いつかは終わるものをちゃんと楽しむ幸せな時間はあっという間に過ぎていく。楽しいプロジェクト、友人との語らい、恋の始まり——すべての良いことにはいつか終わりが来る。「これもいつか終わるんだろうな」と考えながら楽しいひとときを過ごすのは、30歳を前にした私のような人間の性かもしれない。常に砂時計の砂が落ちていくのを見続けているような感覚だ。時間の流れは誰にも平等だ。しかし、その時間をどう感じるかは人それぞれ。『これもいつか終わるんだろうな』と思いながらも、今この瞬間を大切にする。過去の自分を否定せず、かといって執着もせず、ただ前を向いて歩き続ける。砂時計を眺めながらも、その砂で自分だけの城を築いていく。それが生きることの楽しさなのかもしれない。自分の期待に応えられなかった記憶が心に残る。自分で自分にハードルを上げすぎて、それを超えられなかった日々。プロジェクトでの小さなミス、チームでの意見の違い——これらの記憶はなかなか消えない。20代の頃は自分で設定した完璧な基準に届かないことが全てを台無しにするように思えた。しかし今では、それらも人生のグラデーションとして受け入れられるようになった。理想と現実の間にある溝を認め、それでも前に進む勇気が身についた。完璧主義との戦いは今も続いている。コードを書いていて「もっと美しく書けるはず」と何度も書き直す。技術記事を書いたり、読んで「全部理解していないからと次に進めない」と足踏みする。誰からも期待されていないのに、自分だけが自分に無理な期待をかける。この自分との対話は、時に建設的で、時に破壊的だ。他人に期待しすぎない術は身についたが、自分に期待しすぎない術はまだ修行中だ。かつては「なぜ自分はもっとできないのか」と悩んでいた。しかし徐々に、人間には限界があり、すべてを完璧にこなすことは不可能だと受け入れられるようになってきた。自分への期待を下げるのではなく、不完全な自分を認めることで、むしろ心は軽くなった。そして「身の程」を知るようになった。自分の能力や限界への理解が深まるほど、逆に自信を持って胸を張れるようになった。ライブラリを全部理解していなくても、「今は分からないけど調べれば理解できる」という余裕が生まれた。「これはできない」と正直に認めることで、逆に「これならできる」という自信も育つ。自分の限界を知ることは、弱さではなく強さだと気づいた。特に痛感したのは、技術書の「全て」を理解しようとしていた自分の滑稽さだ。分からないページがあると先に進めず、一冊を完璧にマスターしようとして、結局最後まで読めずに挫折することの繰り返し。今なら分かる、必要なところだけを取り入れ、分からないところはいったん保留にして前に進む勇気の大切さを。完璧を目指すあまり、一歩も前に進めなくなるという皮肉。それでも、あの頃の完璧主義が今の技術力の土台を作ったことも確かだ。一つの概念を深く掘り下げ、原理から理解しようとする姿勢。簡単に諦めず、分からないところに何度も立ち返る粘り強さ。非効率だったかもしれないが、その過程で築いた基礎知識と思考の筋力は、今でも私の強みになっている。効率だけを求めていたら、得られなかった深い理解がある。今の「適切なバランス」は、あの頃の遠回りがあったからこそ見つけられたのだ。「大人げない」と言われるのは大人だけだ。だからこそ、時には子供のように新しい技術に夢中になり、全力でコードを書くことも恥ずかしくない。新しいフレームワークを発見して「うおおこれヤバい！」と興奮することも、バグを解決して「よっしゃー！」と雄叫びを上げることも、大切な感情表現だ。感情を抑え込むことが「大人」ではなく、感情と向き合いながらも行動を選択できることが本当の意味での「大人」なのだと分かった。年齢は「小さな枠組み」で「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。若手にもベテランにも学び、「経験が少ない」とも「古い考え方だ」とも思われることを恐れない。いくつになっても成長できると思えるようになったのは、30歳を前にした最大の収穫かもしれない。最も大切なのは、完璧を目指しながらも今この瞬間を楽しむこと。自分で自分を追い詰めるのではなく、時には立ち止まって今日までの道のりを振り返る。砂時計の砂は確実に落ちていくが、だからこそ今この瞬間が尊い。田舎者が見上げる東京の空九州の片田舎から都会へ—その落差は今でも時々現実感を失わせる。自分が歩む道が本当に現実なのか、何かの間違いなのか分からなくなることがある。高校卒業まで過ごした街では、夜になると街灯も少なく、「あそこの交差点では夜一人で歩くな」という暗黙のルールがあった。コンビニまで自転車で20分、映画館は隣の市まで行かねばならない。そんな場所から、突然、光り輝く迷路のような大都会へ放り出された感覚。最初の数ヶ月は毎日が観光気分だった。今では高層ビルのエレベーターで何十階も上がり、窓の外に街を一望できる。駅から会社までの道には世界中の料理が楽しめる店が軒を連ね、夜遅くなっても電車は頻繁に走る。この便利さに未だに慣れない自分がいる。「俺みたいな田舎者がなぜここにいるんだろう」—そう思うことがある。祖父からの電話で「都会は怖くないかい？」と聞かれると、半分笑いながら「うん、まだちょっと怖いよ」と答えてしまう。歩く人の目の冷たさ、文化や人の違い、もしくは自分がおじさんになってこの世の全員が冷たくなったのかもしれない。時々、自分が自分ではないような感覚に襲われる。駅のホームで電車を待っていたり、エレベーターの鏡に映る自分を見たりした時に、「この人は誰だろう？」と思う瞬間がある。それでも最近は変わってきた。かつては圧倒されるばかりだった都会の風景を、自分の可能性として捉えられるようになった。高層ビル群を見上げて「ここまで伸びる可能性が自分にもある」と思えるようになった。多様な価値観や文化に触れ、視野も広がった。おわりに中学17年生である自分。まだまだ成長の余地だらけの自分。それを恥じるのではなく、誇らしく思えるようになった。30歳という節目を迎え振り返ると、「まだ何も始まっていない」という気もする。これからが本番だとも思う。中学17年生としての感性と、30歳のエンジニアとしての経験。矛盾するこの二つの側面が、私という人間を形作っている。大人の顔を持つ中学生も、子供心を忘れない大人も、どちらも本当の私自身だ。複雑で矛盾に満ちた自分をそのまま受け入れ、それを誇りに思える。それこそが、いつまでも成長し続けるための原動力になる。大人になって自分のできないことを目の当たりにして歯がゆさを感じる。「もっと早くこれを知っていれば」と悔やむこともある。でも見方を変えれば、それだけ伸びしろがあるということだ。何でも知っていて、何でもできる人間なんて、それはそれで退屈な人生だろう。常に新しい課題に挑戦し、失敗し、学び続けることこそが、人生を豊かにする。砂時計の砂は上から下に確実に落ちていく。だからこそ、「これもいつか終わるんだろうな」と考えながらも、今この瞬間を大切にしたい。過去の自分を否定せず、執着もせず、前を向いて歩き続ける。「身の程」を知りながらも、少しずつ自分の領域を広げていく。完璧を目指すあまり一歩も前に進めなくなるのではなく、時には「これで十分」と自分を許せる強さも身につけたい。この文章を書いている今も、不安でいっぱいだ。「こんなことを書いて、見られたら恥ずかしい」「こんな風に悩む自分は、弱すぎるんじゃないか」「30歳になっても中学生みたいな考え方をする自分は、ダメなんじゃないか」。そんな声が頭の中でぐるぐる回っている。けれど、そんな弱さも含めて自分なのだと認められるようになってきた。自分との対話も、少しずつ優しいものに変えていきたい。誰かの役に立とうと頑張りすぎて、自分を見失うことも多かった。「良いエンジニア」「良いサラリーマン」であろうとして、本当の気持ちを押し殺してきた。これからは、もう少し素直に、もう少し自分に優しく生きていきたい。「今は分からないけど調べれば理解できる」という余裕を持ちながら、自分のペースで技術を深めていきたい。年齢は「小さな枠組み」で「ただの数字」だ。「30歳のエンジニアはこうあるべき」という固定観念に縛られず、自分らしいスタイルで前進していく。大人のコスプレが上手くなっただけの中学生。それは決して恥ずべきことではない。むしろ、その感覚を大切にしたい。中学生の頃に見上げた空と、今見上げる空は同じなのだから。感情を抑え込むことが「大人」ではなく、感情と向き合いながらも行動を選択できることが本当の意味での「大人」だと分かった。まだまだ成長の余地だらけの自分が晴れやかに歩いていく。ときにはつまずき、立ち止まることもあるだろう。それでも前を向いて、自分らしく生きていく。それが私の「大人になる」ということだ。どんなに時間が経っても、「早く大人になりたいな」と呟いていた中学生の気持ちを忘れないでいたい。ただし今は、「傘を持って外に出る勇気」も持っている。どしゃ降りの雨の中でも、自分の道を歩いていこう。B面なのでwww.amazon.jp他の記事も読んでいただけると嬉しいです。読者になってくれたり、Xをフォローしてくれたりすると、中学生の心がとても喜びます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovim最先端のextuiのcool & smartなcmdlineに特別なカラースキームをあててもっとcoolにしよう]]></title>
            <link>https://blog.atusy.net/2025/05/10/nvim-extui-cmdline-styiling/</link>
            <guid>https://blog.atusy.net/2025/05/10/nvim-extui-cmdline-styiling/</guid>
            <pubDate>Sat, 10 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[コマンドラインやメッセージをフローティングウィンドウ化するextuiはcool & smartです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Projects様を引用してブログネタを決めるためのツールを作成しました]]></title>
            <link>https://zenn.dev/akasan/articles/7e30ad266c02c4</link>
            <guid>https://zenn.dev/akasan/articles/7e30ad266c02c4</guid>
            <pubDate>Fri, 09 May 2025 13:35:49 GMT</pubDate>
            <content:encoded><![CDATA[今回は、私が今しているセルフエンドレスアドベントカレンダーのネタを決めるためのツールを作成しましたので紹介します。 対象とするものは？今回はApacheのプロジェクト一覧からランダムに抽出されたプロジェクトを対象とするようにしました。なお、これはネタが思い浮かばなかったり、思い浮かんでるけどなんか違うものがいいなと思った時に実行するようにします。https://projects.apache.org/projects.html 作成したツールについて今回はPythonを使ってツールを作成しました。まずは先ほどのApache Projectsの一覧からアイテムをテキストファ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[よく使うディレクトリ+αへの移動を便利にするzoxideとghqの組み合わせ]]></title>
            <link>https://blog.atusy.net/2025/05/09/zoxide-with-ghq/</link>
            <guid>https://blog.atusy.net/2025/05/09/zoxide-with-ghq/</guid>
            <pubDate>Fri, 09 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[zoxideはディレクトリの移動頻度を学習して、検索・移動を楽にするツールです。検索候補にまだ移動したことないけど、今後よく使いそうなディレクトリを追加するともっと便利にできます。この記事では[ghq]で管理しているGitリポジトリを移動先候補に追加する方法を紹介します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[pyarmorを使ってPythonコードを難読化してみた]]></title>
            <link>https://zenn.dev/akasan/articles/bd61954c87d4ea</link>
            <guid>https://zenn.dev/akasan/articles/bd61954c87d4ea</guid>
            <pubDate>Thu, 08 May 2025 11:15:03 GMT</pubDate>
            <content:encoded><![CDATA[今回は、pyarmorを利用してPythonのコードを難読化してみようと思います。 pyarmorとは？pyarmorとはPythonコードの難読化をするためのツールとなります。コマンドラインツールであり、難読化を初めコードの利用期限の設定などもできるものとなっております。主な特徴としてはいかがあるようです。難読化されたコードもPythonファイルであり、オリジナルのコードと置換するだけでシームレスに置き換えできますセキュリティとパフォーマンスのバランスが取れるように複数の難読化手法を提供関数名やクラス、変数などがリネームされ、復元できない難読化が実行されるいくつかのPy...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actionsから踏み台経由でプライベートCloud SQLに接続 (OS Login + WIF + SSHトンネル編)]]></title>
            <link>https://zenn.dev/meziron/articles/369504c9d84eba</link>
            <guid>https://zenn.dev/meziron/articles/369504c9d84eba</guid>
            <pubDate>Thu, 08 May 2025 08:55:26 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Actionsから踏み台サーバー経由でプライベートCloud SQLに接続する実践ガイド (OS Login + WIF + SSHトンネル編)CI/CDパイプライン、特にGitHub Actionsから、VPCのプライベートネットワーク内に配置されたCloud SQLデータベースへ安全かつ自動的に接続したい、というニーズは多いのではないでしょうか？この記事では、Workload Identity Federation (WIF), OS Login そして gcloud compute ssh (beta) を組み合わせた、管理しやすい接続方法を解説します。 1...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[クラウドネイティブ環境の脅威モデリング]]></title>
            <link>https://speakerdeck.com/kyohmizu/kuraudoneiteibuhuan-jing-noxie-wei-moderingu</link>
            <guid>https://speakerdeck.com/kyohmizu/kuraudoneiteibuhuan-jing-noxie-wei-moderingu</guid>
            <pubDate>Thu, 08 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[イベント登壇資料です。2025/05/08 #TMCTokyohttps://lu.ma/tmc-tokyo-meetup-2025-05]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策]]></title>
            <link>https://sreake.com/blog/fastapi-error-handling-basics/</link>
            <guid>https://sreake.com/blog/fastapi-error-handling-basics/</guid>
            <pubDate>Thu, 08 May 2025 03:03:29 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは。Sreake事業部の安本篤史（atusy）です。 APIサーバーの実装では、プログラムエラーをハンドリングして、クライアントエラーやサーバーエラーを適切にレスポンスすることが求められます。 同時に、エラーに関 […]The post FastAPIのエラーハンドリングの基本と、ハンドリング漏れ対策 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[入社エントリ：スリーシェイクに入社して5ヶ月目に突入！！]]></title>
            <link>https://zenn.dev/akasan/articles/c9152e75975b51</link>
            <guid>https://zenn.dev/akasan/articles/c9152e75975b51</guid>
            <pubDate>Wed, 07 May 2025 13:42:12 GMT</pubDate>
            <content:encoded><![CDATA[私の経歴まずは簡単に私の経歴についてまとめてみます某技術系の学校にて電気電子系を専攻新卒でロボットやAIの重荷受託開発企業に入社最初はロボットの制御ソフトウェアとかを結構作ってましたが、コロナ禍になってからは完全にソフトウェアにシフト入社後から主に画像処理や業務効率化ソフトウェアの開発に従事2021年11月に2社目となる会社に転職その会社ではがっつりAI開発系の会社で、動画像を対象とした異常検知モデルを主に開発後半からはそのモデルを動かすためのWebアプリケーションのフロントエンド以外（バックエンド実装、CI/CD実装など）全般を担当2025年1月から...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Argo CDのセットアップ方法を解説してみる]]></title>
            <link>https://zenn.dev/kamos/articles/0e1e6af0700f14</link>
            <guid>https://zenn.dev/kamos/articles/0e1e6af0700f14</guid>
            <pubDate>Wed, 07 May 2025 02:18:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめにArgo CDとは、Kubernetesのための継続的デリバリー（CD）ツールです。GitOpsの原則に従い、Gitリポジトリの状態をKubernetesクラスターに同期させることができます。これにより、アプリケーションのデプロイメントや管理が容易になります。Kubernetes環境では広く利用されているArgo CDですが、Argo CD自体のセットアップ方法はいくつかの方法があります。ここでは、Argo CDの初期セットアップについて解説します。 Argo CDの初期セットアップArgo CDを利用可能にするには、以下の手順が必要になります。Argo CD ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovim 0.11でシンタックスハイライトがちらつく問題の回避策]]></title>
            <link>https://blog.atusy.net/2025/05/07/workaround-nvim-async-ts-fliker/</link>
            <guid>https://blog.atusy.net/2025/05/07/workaround-nvim-async-ts-fliker/</guid>
            <pubDate>Wed, 07 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Neovim 0.11から導入された非同期処理の影響で、同一バッファを複数ウィンドウで開くとシンタックスハイライトがちらつくことがあります。0.11.2で修正予定とのことですが、不便なので状況に合わせて非同期・同期を切り替える方法を紹介します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[自分が課金しているサービス挙げてみた]]></title>
            <link>https://zenn.dev/akasan/articles/f46eda0ba43958</link>
            <guid>https://zenn.dev/akasan/articles/f46eda0ba43958</guid>
            <pubDate>Tue, 06 May 2025 11:06:13 GMT</pubDate>
            <content:encoded><![CDATA[今回は、自分がエンジニアリングに関して課金しているツールを挙げてみました。この記事の作成意図としては、「私これだけ課金して普段やってるんだぜ」という自慢ではなく、「こういうサービスを使って生産性あげたり情報収集してるんだ」ということを共有したいだけです。なお、課金してるけど全然使えてないツールもあるので、ちゃんと整理しないといけないなというのもあり、この記事を書いている部分もあります。 SlackSlackでは私個人として使っているものがあり、過去のメッセージも全て残したいのでproプランを使っています。記事作成時点では月払いにしていて¥1,050/月の支払いとなっています。使い...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud StorageへのファイルアップロードをPub/Subで受け取る]]></title>
            <link>https://zenn.dev/akasan/articles/e17a1867408c53</link>
            <guid>https://zenn.dev/akasan/articles/e17a1867408c53</guid>
            <pubDate>Mon, 05 May 2025 13:31:49 GMT</pubDate>
            <content:encoded><![CDATA[今回はCloud StorageにファイルがアップロードされたときにPub/Subdで受け取る方法についてまとめてみます。 システム構成今回の検証の環境はざっくり以下になります。Cloud Storageではファイルアップロードを受け付けますCloud Storageにファイルがアップロードされると、Pub/Subトピックに向けて通知が投げられますPub/Subが通知を受け取るとBigQueryに対して通知を配信しますBigQueryではテーブルにPub/Subから受け取った通知を蓄積します 実装 Cloud StorageまずはCloud Storageの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A2AサーバをOpenTelemetryで計装する]]></title>
            <link>https://zenn.dev/kimitsu/articles/otel-and-a2a</link>
            <guid>https://zenn.dev/kimitsu/articles/otel-and-a2a</guid>
            <pubDate>Mon, 05 May 2025 10:46:15 GMT</pubDate>
            <content:encoded><![CDATA[A2A におけるオブザーバビリティの必要性A2A[1]は Google が主導し開発を進めている、エージェント間の通信を可能にするオープンプロトコルです。A2A を利用することで生成 AI アプリケーションはマルチエージェントシステムとして実装されます。マルチエージェントシステムは分散システムであり、マイクロサービスと同様にオブザーバビリティが重要となります。小さなエージェントであればわざわざ A2A でクライアントとサーバに分ける必要はありませんが、エージェントが巨大化すれば従来の Web アプリケーションの潮流と同様に分割される方向で進化するでしょう。本記事ではA2Aサ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MCPサーバをOpenTelemetryで計装する]]></title>
            <link>https://zenn.dev/kimitsu/articles/otel-and-mcp</link>
            <guid>https://zenn.dev/kimitsu/articles/otel-and-mcp</guid>
            <pubDate>Mon, 05 May 2025 07:33:24 GMT</pubDate>
            <content:encoded><![CDATA[MCP におけるオブザーバビリティの必要性MCP の利用方法として現時点では以下がよくあると思います。MCP サーバをローカルで動かしているサードパーティーのリモートサーバを使っているクライアントがローカルアプリ上記の場合にはオブザーバビリティは比較的重要ではありません。一方で、以下のような場合にはMCP においてもオブザーバビリティが重要です。Web アプリケーションが MCP クライアント（例えば生成 AI アプリ）MCP サーバを自作しているこのような状況では MCP クライアントと MCP サーバは、マイクロサービスで構成されたアプリケーションとして...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[treesitterを使って閲覧中のヘルプのneovim.io版URLを発行する]]></title>
            <link>https://blog.atusy.net/2025/05/05/neovim-io-help/</link>
            <guid>https://blog.atusy.net/2025/05/05/neovim-io-help/</guid>
            <pubDate>Mon, 05 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Neovimのヘルプを閲覧中に、カーソル位置のヘルプのneovim.io版URLを発行するマッピングを作ってみました。treesitterを使うと、ヘルプファイルのパース結果を元にヘルプタグの位置を検出できて便利ですね。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Taskfile使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/f4a13b2e62a637</link>
            <guid>https://zenn.dev/akasan/articles/f4a13b2e62a637</guid>
            <pubDate>Sun, 04 May 2025 12:02:23 GMT</pubDate>
            <content:encoded><![CDATA[仕事でチームメンバーがTaskfileというものがあるということを共有していて、どんなものか知らなかったので、今回は入門してみようと思います。 Taskfileとは？公式ドキュメントによると、TaskfileとはGNU Makeなどと比較してシンプルであり使いやすさを求めたタスクランナーおよびビルドツールということです。Goで書かれているためバイナリとして利用でき、インストールに他の依存するソフトなどを入れることなく使えることがいいということです。また、特徴として以下があるようです。上述のようにバイナリをダウンロードするだけでよく、$PATHに追加するだけでいいのでインストー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MCP-Use を使っていきます]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/04/024730</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/04/024730</guid>
            <pubDate>Sat, 03 May 2025 17:47:30 GMT</pubDate>
            <content:encoded><![CDATA[MCP-Useとは何か？MCP-Use (Model Context Protocol - Use) は、LLM（大規模言語モデル）とMCPサーバーの間の橋渡しをするPythonライブラリです。このライブラリにより、OpenAI、Anthropic、Groqなど様々なLLMプロバイダーのモデルに、Webブラウジングやファイル操作といった外部ツールへのアクセス権を付与できます。github.com環境構築：uvの活用今回はRustベースの高速パッケージマネージャーuvを使って環境を構築します。docs.astral.sh# 仮想環境を作成uv venv# 仮想環境をアクティベートsource .venv/bin/activate.fish  # fishシェル使用時# 必要なパッケージをインストールuv pip install "mcp-use[dev,anthropic,openai,search]"uv pip install fastembeduv pip install python-dotenv langchain-openai従来のpipと比較してuvは大幅に高速で、特に複雑な依存関係を持つプロジェクトではその差が顕著です。MCP-Useはさまざまな依存関係を持つため、uvの使用が特に有効です。MCP-Useの基本構造MCP-Useの中核は以下のクラスから構成されています：MCPClient: 設定ファイルからMCPサーバーへの接続を管理MCPAgent: LLMとMCPサーバーを組み合わせてタスクを実行各種アダプター: LLMプロバイダーとMCPサーバー間の変換処理実装例：ウェブ情報取得エージェント今回はMCP-Useを使って、特定のWebサイトから情報を抽出するエージェントを構築します。import asyncioimport osfrom dotenv import load_dotenvfrom langchain_openai import ChatOpenAIfrom mcp_use import MCPAgent, MCPClientasync def main():    # 環境変数を読み込み    load_dotenv()    # 設定ファイルからMCPClientを作成    client = MCPClient.from_config_file(        os.path.join(os.path.dirname(__file__), "browser_mcp.json")    )    # LLMを初期化    llm = ChatOpenAI(model="gpt-4o")        # エージェントを作成    agent = MCPAgent(llm=llm, client=client, max_steps=30)    # クエリを実行    result = await agent.run(        "3-shake.com にアクセスして株式会社スリーシェイクのCEOのxアカウントを教えて下さい",        max_steps=30,    )    print(f"\nResult: {result}")if __name__ == "__main__":    asyncio.run(main())以下、各部分の詳細を解説します。1. MCPClient初期化とその内部構造client = MCPClient.from_config_file(    os.path.join(os.path.dirname(__file__), "browser_mcp.json"))MCPClientクラスはMCPサーバーへの接続を管理します。from_config_fileメソッドで設定ファイルから構成を読み込みます。設定ファイルbrowser_mcp.jsonの中身は以下のようになっています：{  "mcpServers": {    "playwright": {      "command": "npx",      "args": ["@playwright/mcp@latest"],      "env": {        "DISPLAY": ":1"      }    }  }}この設定は、PlaywrightをMCPサーバーとして使用することを指定しています。MCPClientはこの設定を読み込み、以下の処理を実行します：設定に基づいて適切なコネクタ（この場合はStdioConnector）を作成コネクタを使ってPlaywright MCPサーバーとの通信チャネルを確立初期化処理を実行し、利用可能なツールの一覧を取得内部的には、MCP-Useは非同期処理を多用しており、asyncioを活用した効率的な通信を実現しています。2. LLMの初期化と統合llm = ChatOpenAI(model="gpt-4o")MCP-UseはLangChainとシームレスに統合されており、様々なLLMプロバイダーのモデルを使用できます。今回はOpenAIのGPT-4oを使用していますが、以下のように簡単に切り替えることも可能です：# Anthropicのモデルを使用する場合from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model="claude-3-5-sonnet-20240620")# Groqのモデルを使用する場合from langchain_groq import ChatGroqllm = ChatGroq(model="llama3-8b-8192")MCP-Useの内部では、LangChainAdapterクラスがLLMとMCPサーバー間の変換処理を担当し、ツールの記述をLLMが理解できる形式に変換しています。3. MCPAgentの作成と実行agent = MCPAgent(llm=llm, client=client, max_steps=30)MCPAgentクラスは、LLMとMCPクライアントを組み合わせてタスクを実行するための中核コンポーネントです。主なパラメータは：llm: 使用するLLMモデルclient: MCPクライアントインスタンスmax_steps: エージェントが実行できる最大ステップ数max_stepsパラメータは特に重要で、タスクの複雑さに応じて適切な値を設定する必要があります：- 単純な情報検索: 5-10ステップ- 複数ページの探索: 15-20ステップ- 複雑な操作: 25-30ステップ4. タスク実行の内部処理result = await agent.run(    "3-shake.com にアクセスして株式会社スリーシェイクのCEOのxアカウントを教えて下さい",    max_steps=30,)agent.run()メソッドが呼び出されると、以下の処理が実行されます：指定されたクエリをLLMに送信し、実行プランを生成LLMが適切なツールを選択し、その実行をリクエストMCPクライアントがツールのリクエストをMCPサーバーに転送MCPサーバーがツールを実行し、結果を返す結果をLLMに返し、次のステップを決定最終的な回答が生成されるまで、ステップ2-5を繰り返す内部的には、この処理はMCPAgent.run()メソッド内の_agent_executor._atake_next_step()メソッドで実装されています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonを使ったチュートリアルを通してDataflow試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/e3d25446d34776</link>
            <guid>https://zenn.dev/akasan/articles/e3d25446d34776</guid>
            <pubDate>Sat, 03 May 2025 14:03:21 GMT</pubDate>
            <content:encoded><![CDATA[今回は、昨日実施したDataflowチュートリアルの続編となります。前回はDataflowのテンプレートを利用したパイプラインの動作チェックでしたが、今回はPython SDKを利用したチュートリアルを実施してみます。前回の記事はこちらですので、ぜひご参照ください。https://zenn.dev/akasan/articles/a0ebe0ae2ed2ec 早速チュートリアルを試してみる チュートリアル概要今回は、DataflowをPythonから利用するチュートリアルを利用してみます。チュートリアルの概要は以下のようです。本記事は前回の記事の続編という立て付けでいこうと思...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[チュートリアルを通してDataflow試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/a0ebe0ae2ed2ec</link>
            <guid>https://zenn.dev/akasan/articles/a0ebe0ae2ed2ec</guid>
            <pubDate>Fri, 02 May 2025 13:24:14 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Dataflowをチュートリアルを通して実際に使ってみました。 そもそもDataflowとは？Dataflowとは、公式の説明を引用させてもらうと、Dataflow は、統合されたストリーム データ処理とバッチデータ処理を大規模に提供するサービスです。 Google Cloud Dataflow を使用して、1 つ以上のソースからデータを読み取り、変換し、宛先に書き込むデータ パイプラインを作成します。Dataflow の一般的なユースケースは次のとおりです。データの移動: データの取り込みやサブシステム間でのデータの複製BigQuery などのデータ ウェアハウ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「頑張ってるので安心」から脱する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/02/191144</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/02/191144</guid>
            <pubDate>Fri, 02 May 2025 10:11:44 GMT</pubDate>
            <content:encoded><![CDATA[soudai.hatenablog.comそーだいさんの「頑張らなくてもいいから、成果で応えよう」という記事を読み、「頑張ること」について改めて考えさせられた。「頑張る」の幻想と私たちの関係日本文化においてというか自分が育ってきた環境では「頑張る」という言葉には特別な地位があった。子どもの頃から「頑張れ」と叱咤激励され、「頑張ります」と答えることが社会的な美徳や道徳的な行いとされてきた。多くの場面で「頑張ります」と宣言するだけで、一時的に評価されるか、少なくとも批判を免れる魔法のような効果を持っている。しかし、この「頑張る」という概念を現場で聞くと自分も奇妙だと感じる。専門的な仕事に対する報酬は、結局のところ労力の投入量ではなく、生み出された価値に対して支払われるものだ。高額な費用を支払う依頼者が期待するのは、徹夜して疲れた顔をすることではなく、問題解決の価値を提供することだろう。「努力」と「成果」の非対称性ビジネスの世界では、しばしば「依頼者と受託者の利害不一致」が問題になる。経済学では「エージェンシー問題」と呼ばれるこの現象は、仕事を頼む側と引き受ける側の間に生じる情報や目的の不均衡から発生する。例えば、受託者は「一生懸命頑張っている」姿を見せることで、依頼者に「価値ある仕事」をしているという印象を与えられる。しかし、依頼者が本当に必要としているのは、その問題が解決されることであって、受託者の頑張りそのものではない。受託者が自分の興味や都合を優先して「頑張る」ことで、依頼者が必要としない複雑な作業に時間を費やすこともある。これもエージェンシー問題の一例だといえる。このとき「頑張っています」という言葉は、実は成果を出せない責任から自分を守る防御機制になっていることがある。「精一杯やりました」という免罪符を先に用意しているようなものだ。プロフェッショナルは、このような情報の非対称性を利用するのではなく、依頼者の本当のニーズを理解し、それに応える成果を出すことで信頼を勝ち取る。ja.wikipedia.org個人の「頑張り」と本質的価値では個人として「頑張る」ことに価値はないのだろうか？ここで重要なのは、「頑張る」という言葉に対する冷笑的な態度と、本質的な「頑張り」の価値を区別することだ。SNSやぎむきょー時代は「頑張り」を馬鹿にする風潮も見られるが、それは本来の議論とは異なる。正直に告白すると、学生時代の私自身も「頑張っている人」を冷笑していた時期があった。努力している人を見て「あんなに必死になって」と馬鹿にしていたのは、おそらく自分の怠惰や無為を正当化するための防衛機制だったのだろう。SNSで見られる「頑張り」への皮肉や揶揄も、多くの場合、同様の心理から生まれていると思われる。しかし、本稿で論じているのはそうした冷笑とは全く異なる。単なる努力否定論ではなく、むしろ「頑張り」の本質と方向性についての考察であり、努力そのものの価値を問い直すものである。ここで大切なのは、無意味な労力を省く知恵と、本当に必要な部分への集中という、より高度な「頑張り」の形だ。もちろん、個人の成果、成長や技術向上のためには「頑張り」が必要だ。しかし、その「頑張り」は闇雲に時間や労力を投入することではなく、最も効果的な方向に集中させることが重要だろう。そして、この「方向性を見極める努力」こそが、実は最も価値のある「頑張り」なのだ。優れた個人の強みは、複雑な問題を単純化する能力にある。たとえば、長時間かけて解決できる問題を短時間で実装できれば、それはただの時間節約ではなく、将来的な労力やリスクの削減にもつながる。こうした「頑張らない工夫」のために費やす知的努力こそが、実は最も価値のある「頑張り」なのだ。つまり、見た目の労力と実質的な価値創造は必ずしも比例しないということである。何をするかを決めることと同じくらい、何をしないかを決めることが重要だ。プロフェッショナルは、あらゆることに対して「Yes」と言うのではなく、価値の低い活動には意識的に「No」と言う勇気を持っている。時間とエネルギーは有限だからこそ、本当に重要なことに集中するために、何かを捨てる決断が必要になる。この「選択する」という行為自体が、実は高度な「頑張り」を要するものだ。大企業や大規模な組織に比べて、個人や小さな組織が持つ強みの一つは、無駄な儀式的活動を省略できることにある。形式的な定例会議や不必要な報告書作成に時間を費やす代わりに、本質的な価値を生み出す活動や意思決定に集中できる自由がある。これは実は大きな競争優位性となり得る。この「本質」を見極める洞察力を養うこともまた、「頑張る」べき重要な領域なのだ。起こる可能性のあることは、いつか実際に起こる。「頑張る」という抽象的な概念から脱却するためには、具体的な仕組みを設計する思考へ転換する必要がある。努力の量よりも、その方向性と持続可能性が重要だ。問題の解決に徹夜で取り組むことを否定するわけではないが、優れたエンジニアは、より本質的には問題が再発しないような仕組みの構築に力を注ぐ。例えば、作業を手動で何度も「頑張る」のではなく、自動化の仕組みを整備する。毎回の業務で時間をかけて「頑張る」のではなく、再利用可能なテンプレートやガイドラインを整備する。問題が起きるたびに対処法を「頑張って」思い出すのではなく、解決策を体系化したマニュアルを作成する。「人間が頑張る」システムから「仕組みが支える」システムへの転換が、価値を生み出す。とにかく仕組み化――人の上に立ち続けるための思考法作者:安藤 広大ダイヤモンド社Amazon360度評価の落とし穴多くの企業で導入されている360度評価は、一見公平に見えるが、実はこの「頑張り」の価値観を強化してしまう側面がある。同僚や部下からの評価では、実際の成果や生み出した価値よりも「頑張っているように見える」人が高く評価される傾向がある。例えば、遅くまでオフィスに残っている人、頻繁にメッセージや進捗報告を送る人、会議で積極的に発言する人、多くのタスクを抱えて「忙しそう」に見える人は「熱心に働いている」という印象を与えやすい。しかし、こうした「頑張っている姿」は、必ずしも組織や顧客にとっての価値創造に結びついているとは限らない。むしろ静かに効率的に成果を出している人が、「あの人は楽をしている」と誤解されることすらある。見た目の「頑張り」で評価される環境は、本来の価値創造を歪める要因となる。この歪みが組織全体の非効率を生み出し、真に重要な成果よりも「頑張っている姿勢」が優先される文化を強化してしまうのだ。「頑張らない」の誤解を解く「頑張らない」という言葉を聞くと、「怠けている」「熱意がない」という印象を持つ人も多いだろう。しかし本質は「無駄な労力を費やさない」ということだ。優れたプロフェッショナルとは、最小限の労力で最大限の成果を出す人のことであり、闇雲に時間や労力を投入する人のことではない。例えば、ソフトウェア開発なら、少ない時間で短く洗練されたコードで同じ機能を実現できる人のほうが、多くの時間を使って冗長で複雑なコードを書く人よりも高い評価を受けるべきだ。これは他の職種でも同様だ。営業担当者が100件の見込み客に電話するよりも、10件の有望な見込み客に集中して高い成約率を出す方が価値がある。デザイナーが何十もの案を作るよりも、ユーザーの本質的なニーズを捉えた1つの優れた案を作る方が価値がある。マネージャーが長時間のミーティングを主催するよりも、短時間で明確な意思決定と方向性を示せる方が価値がある。限られた時間とエネルギーをどう使うかが、プロフェッショナルの条件だ。多くの場合、「頑張らない」と見られる人ほど、実は効率的な方法論や再利用可能な仕組みを作り出すことで、生産性を高めている。NINE LIES ABOUT WORK 仕事に関する9つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon「頑張り」の再定義個人として「頑張る」ことを完全に否定するわけではない。むしろ、その意味を再定義する必要がある。「頑張る」とは、ただ長時間働くことや疲れ果てることではなく、最も効率的な方法を見つけるために思考し、試行錯誤することかもしれない。「頑張ります」と言う代わりに、「この売上低下の問題を解決するために、まずデータを分析し、次週までに具体的な改善策を提案します」のように具体的なコミットメントを示すほうが建設的だ。抽象的な精神論ではなく、具体的で測定可能なアクションにフォーカスすることで、本当の意味での価値が生まれる。これは実は「頑張らない」ように見えて、もっとも「頑張るべき」部分かもしれない。人生は、運よりも実力よりも「勘違いさせる力」で決まっている作者:ふろむだダイヤモンド社Amazon「頑張ってるので安心」からの解放「頑張っているので安心してください」という言葉の裏には、「結果が出なくても責めないでください」という暗黙の訴えがある場合が多い。しかし、このような思考パターンからは脱却する必要がある。自分自身に対しては、「これをやって、この結果を出します」という具体的なコミットメントへと転換することが、ちゃんとした価値を生み出す第一歩だろう。ただし、この考え方を他者に向けて適用する際には注意が必要だ。相手の背景や文脈、置かれた状況を完全に理解できているわけではない。「頑張り」ではなく「成果」を求めることは理にかなっているが、相手の環境や制約条件、直面している課題の複雑さを把握せずに一方的に求めることは、非常に危険である。むしろ、他者との関係においては、まず相手の状況を理解し、適切なサポートや環境づくりを考えることが先決だ。また、自分が生み出した「価値」が適切に評価されていないと感じるなら、それは単に評価システムの問題ではなく、組織や上長、周囲の人々との間に「価値基準の違い」が存在している可能性がある。自分が重視する価値と、組織が求める価値が異なっていれば、どれだけ成果を出しても評価されにくい。このミスマッチに気づくことは、自分のキャリアを考える上で非常に重要なポイントになる。自分の価値観に合った環境を選ぶか、あるいは組織の価値基準を理解した上で自分の貢献の方向性を調整するか、選択が必要になるだろう。最終的に評価されるのは「頑張った過程」よりも「生み出した価値」だ。この現実を受け入れ、「頑張っているので安心」という幻想から脱することが、個人としての成長への本質的なステップなのかもしれない。もうそろそろ、30歳になるのでそういう事も考えます。追記: "本質的な価値"と"価値基準の違い"本稿では「本質的な価値」と「価値基準の違い」という概念を提示してきたが、果たしてこれらは矛盾しないのだろうか。実際のところ、絶対的な「本質的価値」など存在するのだろうか。冷静に考えれば、所謂誰かが言っている「本質的価値」とは常に文脈依存であり、普遍的なものではない。我々が価値と呼ぶものは、結局のところ特定の社会や組織、個人の視点から定義されたものに過ぎない。人間として普遍的な「本質的価値」を探すならば、それは生命体としての存続と尊厳、心身の調和、そして精神的充足感以外には基本的に見当たらないのではないだろうか。人間という生命体にとって生物学的な生存と精神的な均衡が確かに基礎的な価値だが、それを超えた「価値」は全て社会的に構築されたものだ。企業が求める「価値」は利益最大化かもしれないし、NPOが重視する「価値」は社会貢献かもしれない。個人が大切にする「価値」は自己実現かもしれないし、家族との時間かもしれない。つまり、「本質的価値」を絶対視することこそが、新たな幻想を生み出す危険性をはらんでいる。ある組織で評価される「価値」が、別の組織では全く評価されないこともあるのだ。重要なのは、自分が属する環境で何が「価値」とされているかを正確に理解し、それが自分の信じる「価値」と一致するかを見極めることだろう。一致しない場合、二つの選択肢がある。一つは環境を変えること、もう一つは自分の貢献の方向性を調整することだ。どちらが正しいというわけではなく、各自の状況や志向に応じた選択が必要になる。結局のところ、「頑張る」という曖昧な概念から脱却し、具体的な成果や貢献にフォーカスすることは重要だが、その「成果」や「貢献」自体も絶対的なものではなく、常に特定の文脈の中で評価されるものだということを忘れてはならない。生存と心身の調和を超えれば、あらゆる「価値」は相対的なものであり、その点を認識することこそが、現実的なキャリア構築や人間関係の基盤となるのではないだろうか。]]></content:encoded>
        </item>
    </channel>
</rss>