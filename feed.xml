<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 16 Mar 2023 18:33:46 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[[Terraform] aws_networkfirewall_firewall リソースから VPC エンドポイント ID を取り出す]]></title>
            <link>https://zenn.dev/toshikish/articles/fc08c2021811f9</link>
            <guid>https://zenn.dev/toshikish/articles/fc08c2021811f9</guid>
            <pubDate>Thu, 16 Mar 2023 07:58:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめにTerraform を使って AWS Network Firewall のファイアウォールを作るとき，生成された VPC エンドポイントの ID をサブネットのルートテーブルのルートに追加するのは自然な流れですが，VPC エンドポイント ID を取り出すのが大変だったので，やり方を記録しておきます。例えば以下のように aws_networkfirewall_firewall リソースを定義したとします。（特に説明のない変数やリソースは，なんとなくの理解で構いません。）resource "aws_networkfirewall_firewall" "firewall" ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kuberentes の運用効率化を ChatGPT で実現する 障害対応編]]></title>
            <link>https://sreake.com/blog/kuberentes-operation-with-chatgpt/</link>
            <guid>https://sreake.com/blog/kuberentes-operation-with-chatgpt/</guid>
            <pubDate>Thu, 16 Mar 2023 01:32:14 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 本記事では、Kuberen […]The post Kuberentes の運用効率化を ChatGPT で実現する 障害対応編 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform でDocker Provider を使いましょう]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/03/15/075345</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/03/15/075345</guid>
            <pubDate>Tue, 14 Mar 2023 22:53:45 GMT</pubDate>
            <content:encoded><![CDATA[概要酒を飲んでるので何でも良いのですがTerraform でDocker Provider を使いたくなったのでローカルでDockerコンテナのインフラ環境を構築してみます。あと、特に学びも書く予定がないのでここで「TerraformにDocker Provider があるんだ」という感想を持って読み終わって良いです。僕は別に移行してないです。github.com開発環境情報$ terraform versionTerraform v1.4.0Terraform 1.4 が GA になったのでついでに入れておきました。www.hashicorp.com同僚がブログ書いていたので紹介しておきます。zenn.devデプロイするファイルtutorial.tf というファイルをおきます。{  required_providers {    docker = {      source  = "kreuzwerker/docker"      version = "3.0.1"    }  }}provider "docker" {  host = "unix:///var/run/docker.sock"}# Pulls the imageresource "docker_image" "nginx" {  name = "nginx:latest"}# Create a containerresource "docker_container" "foo" {  image = docker_image.nginx.latest  name  = "foo"  ports {    internal = 80    external = 8080  }}このコードでは、Docker Providerバージョン3.0.1を使用しています。プロバイダとしてDockerを指定し、Dockerホストのソケットへのパスを指定しています。docker_imageリソースで、最新のnginxイメージをプルします。そして、docker_containerリソースで、docker_image.nginx.latestをベースに新しいコンテナを作成します。80番ポートを内部ポートとしてマッピングし、8080番ポートを外部ポートとしてマッピングしています。# Terraform初期化terraform init# プランの確認terraform plan# 実行terraform applydocker_containerリソースで作成したコンテナが起動しているはずです。docker psコマンドを使用して、コンテナが実行されているかどうかを確認できます。眠くなったのでもう寝ます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[良いドキュメントを書きたくなる本を読んだらドキュメンタリアンになりたくなった]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/03/14/130502</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/03/14/130502</guid>
            <pubDate>Tue, 14 Mar 2023 04:05:02 GMT</pubDate>
            <content:encoded><![CDATA[ドキュメンタリアンとは、役職に関係なく、ソフトウェア業界でドキュメントとコミュニケーションに関心を持つ人のことです。www.writethedocs.orgはじめにこれは主に『ユーザーの問題解決とプロダクトの成功を導く エンジニアのためのドキュメントライティング』の書評です。私はSREという役職についています。SREはサービス概要、アーキテクチャの解説や図、各種構成図、各種手順書、ポストモーテム、ポリシー、SLA(SLO) … その他の様々な場面でドキュメントを書く必要があります。しかし、ドキュメントは価値が見えにくく時間と労力がかかり品質担保の面で重要度がとても高いのにその場での価値が見えにくいので浸透しにくいです。そのため、エンジニアとしてモチベーションが保ちづらいです。2021年 State of DevOps 2021 にもドキュメントに関する言及があり今後、DevOps やSREの領域でドキュメントの重要性が高まるのは言わずもがなです。書籍情報『ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング』ジャレッド・バーティ (著), ザッカリー・サラ・コーライセン (著), ジェン・ランボーン (著), デービッド・ヌーニェス (著), ハイディ・ウォーターハウス (著), 岩瀬義昌 (翻訳)ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon本書は『Docs for Developers』の翻訳本でもあります。docsfordevelopers.com日本能率協会マネジメントセンターのサイトから引用した本書の概要です。「ドキュメントを書いておけばよかった」開発者であれば一度は思ったことがあるかもしれません。ドキュメントは開発側の生産性とユーザーの利便性を高めるものです。さらに言うと、ドキュメントがなければ、ユーザーに使われる機会が確実に減ります。開発者がいかにすばらしいプロダクトを作ろうが、ドキュメントの欠如がその価値を奪うのです。本書は経験に長けた執筆者たちがドキュメントを作成する方法をゼロから説明するフィールドガイドです。架空のソフトウェア開発チームのストーリーを追いながら、ソフトウェア開発ライフサイクルの各ステップにおいて、ユーザーニーズの理解、開発者に役立つドキュメントの作成、公開、測定、保守に至るまで、開発を最適化するためのドキュメント作成の技術を解説しています。これまで学ぶ機会のなかったREADME、APIリファレンス、チュートリアル、コンセプトドキュメント、リリースノートなど、さまざまな種類のドキュメントの書き方について学ぶことができる一冊です。ドキュメントを作成している現場のエンジニアやテクニカルライター、プロダクトマネジャーの方に最適の内容です。翻訳の方と著者の方のPodCast も公開されているのでこちらもオススメです。fukabori.fm「ユーザーの問題解決とプロダクトの成功を導く エンジニアのためのドキュメントライティング」の目次PARTごとに別れていて「PART I　ドキュメント作成の準備」→「PARTⅡ　ドキュメントの作成」→「PARTⅢ　ドキュメントの公開と運用」に分かれている。それぞれのフェーズで必要な知識や心構えが書いてある。各章とも端的にまとまっているのでオススメです。また、書籍を読んだ後に各種公式ドキュメントを読み込んでよくできているなぁって思うのは体験としてはよいのでオススメです。PART I　ドキュメント作成の準備CHAPTER 1　読み手の理解CHAPTER 2　ドキュメントの計画PARTⅡ　ドキュメントの作成CHAPTER 3　ドキュメントのドラフトCHAPTER 4　ドキュメントの編集CHAPTER 5　サンプルコードの組み込みCHAPTER 6　ビジュアルコンテンツの追加PARTⅢ　ドキュメントの公開と運用CHAPTER 7　ドキュメントの公開CHAPTER 8　フィードバックの収集と組み込みCHAPTER 9　ドキュメントの品質測定CHAPTER 10　ドキュメントの構成CHAPTER 11　ドキュメントの保守と非推奨化目的があるドキュメントを書こうと思わせてくれる本『コードを読めば分かるから、ドキュメントは今は書かなくていいかな？』って言った人はその後もほとんど、ドキュメントを書かない。ちなみにこういう人はコメントもあまり書いてくれない。エンジニアが新たにシステムを理解したいときはいくつかの場面がある。「エンジニアが新たにシステム開発/運用に参加したとき」「エンジニアが自分の担当以外の構成要素や機能を理解したい時」、その他、様々な場面etc…。システムで利用している技術スタックに十分な知見があったとしても、意外に開発を開始までには手間と時間がかかる。新しく参画したエンジニアが動いているソースコード以外に何もない状態ではシステムへの理解をする時に本当に苦戦する。場合によっては挫けてしまう。ドキュメントがあったとしてもポエムやコラムみたいにお気持ちがたくさん書かれていてもシステムの理解の助けにならなければ価値が薄い。だから、エンジニアは優れたドキュメントを継続的に存在させ続ける必要がある。ドキュメントはテストと同じくソフトウェアエンジニアリングという領域の基礎をなすものだと確信していますが良いドキュメントを書くことを意識することはよくドキュメントを読む時に書いている人の気持ちを考えたりなどいい習慣が身につきより価値のあるドキュメントが書けると思います。よいドキュメントとはどのようなものかPARTⅢ ドキュメントの公開と運用では良いドキュメントについて以下のような定義をSREの探求の19章 ドキュメント作成業務の改善：エンジニアリングワークフローへのドキュメントの統合 から引用している。『良いドキュメントとはドキュメントの品質が高いこと、ドキュメントが目的にかなっていること』もう少し品質について分類すると構造品質と機能品質にわけられる。構造品質と機能品質にはそれぞれ多くの要素が含まれますが今回は割愛します。CHAPTER 10　ドキュメントの構成 にはアクセスしやすいようにドキュメント全体をどうデザインするかについて書いてあり社内でも今後取り組んでいきたい部分が記載されていました。社内のドキュメントを整備する時に情報アーキテクチャ ―見つけやすく理解しやすい情報設計を読んでこれもとても参考になったのでオススメです。また、CHAPTER 11　ドキュメントの保守と非推奨化にはドキュメントを容赦なく刈り込む重要性について記載されています。ここがブログなどとは大きく違う点だと思う。そのドキュメントの機能構造が発揮できなくなったら削除したり非推奨にするのが大事です。陳腐化された、ドキュメントは削除する削除できない場合はアーカイブしたり、ステータスとして「廃止予定(Deprecated)」を付与することは本当に大切です。機能品質ドキュメントの目的やゴールが達成されているかどうか障害対応手順書を例に上げると全てのアラートに対して手順が用意されているか誰でも作業ができるか(1次受けができるか)定期的なアップデートがされているのか必要な人が必要なときにすぐアクセスできるかなどなどドキュメントがあることによってビジネスバリューが発揮できているか。これは読む人それぞれでとても変わりやすいと思うし評価もしずらいです。機能品質の評価の施策についても本書もしくはSREの探求19章には記載されているのでぜひ読んで下さい。構造品質ドキュメントがうまく書かれているか、うまく構成されているか？単語ミスはないか、口調はそろっているか、文法は正しいか構成が適切か(読みやすいか)評価しやすい品質textlintかけて通過しているとか構成テンプレートに沿っているとか大切なのは総合品質だが機能品質を優先せよ総合品質 = 機能品質+構造品質結局は「推測するな、計測せよ」なので本書を読んで計測方法について学んでくれ構造品質は評価しやすい一方、評価指標をこれだけにしてしまうと本質を見失ってしまう当然どちらも高いことが望ましいが、機能品質は常に構造品質よりも重視されるようにする。総合品質を守りたいんじゃぁああああPART I ドキュメント作成の準備にしてもPARTⅡ　ドキュメントの作成にしても結局は総合品質の高いドキュメントを早く作成して、保つための取り組みなのかと思いました。どのような人が読むのか想定して、ドキュメントの目的を決めてドキュメントを書く。ドキュメントを書く時に白紙からスタートするのは非常に辛いので目的が達成されやすいテンプレートを用意する。自動生成を用いる、理解を促すために図解を利用する。様々な施策を行うことで良いドキュメントを書くことに取り組む学びが多い本書です。良い技術ドキュメントの書き方がわかると良いドキュメントが書きたくなるものですよね。みんなにドキュメントを書いてほしいのでとにかく、読んでほしいとおもいました。ドキュメントに関する入門書は他の分野ではあるがソフトウェアを運用/開発するための技術ドキュメントの為に読むべき本って無いよね、という話になりがちだけど、本書はまさにそんな人たちが読みたい1冊だと思います。知識の呪いもしくは祝福人間は他人が自分と同じ知識をもっていると思い込んでしまいます。登壇資料などでも同じですがそれらを作った直後に読み返してみても全てが既知すぎて本当にこのドキュメントや資料には価値があるのか？ と自分に問い直すことがあります。その時に読み手を意識して読み手をどう結論やゴールに導きたいか事前に考えておくことは非常に助けになります。世界で一番やさしい 資料作りの教科書という書籍があるのですがエンジニアだけに向けた書籍ではないのですが読み手の設定と目的と価値のあるドキュメントやコミュニケーションをどのように作っていくか本当にわかりやすくまとまっているのでオススメです。あなたが悩んだことはいずれ誰かも悩むことになります。特にブログは技術ドキュメントとは性質が違うものなので気にせず書いていきましょう。自動化についてしたいドキュメントの中でも機械的に作業が自動化できる場合があります。相対的にトイルっぽくなる作業になるので自動化できるものに関してはCIなどで自動化せずとも存在を知ってたりとか自動化できる事実を知っていれば今後の糧にしてほしいです。個人的にはテンプレートの作成を先にやった方が効果があると思います。あくまで個人的には。issue templatesを用意しましょう。terraform-docsTerraform module を利用する際にパラメーターやアウトプットなどの機械的な情報の説明を書くのは非常に手間です。それらの機械的な情報をまとめてくれるのがterraform-docs になります。https://github.com/k1LoW/tblsDBの必要な情報をCIフレンドリーに出してくれる最高のツールなので案件でDBを使っていれば積極的に採用していきたいと思ってます。データベースのドキュメント作成を現場の開発エンジニアもやりたくない人が多いはずprotoc-gen-docProtocol Buffers 用のドキュメント生成用のプラグインhtmltesthtmltestを使えば生成されたHTML内のリンク切れを発見できます。textlinttextlintとはLintと呼ばれる静的解析ツールで、テキストファイルやMarkdownファイル等を対象に、校正ルールにもとづいて文章校正を行うツールです。様々な個人や組織やオレオレルールを公開しているので自分にあうもの自分の組織に合うものを見つけて行くのも良いと思う。ChromeやVScode などにも組み込める。よりよい文書を書くための校正ツール「textlint」のSmartHR用ルールプリセットを公開しました！ ｜SmartHRオープン社内報https://shanaiho.smarthr.co.jp/n/n881866630edaPrettier ソースコードの整形ツール。Node.js上で動作するので、ユーザーの環境に依存せずに、コードのフォーマットを開発者間で統一することのできるツールです。同僚の長谷川 氏にオススメされた。あとがき2023年3月15日の日本では、GPT-4が登場し、さまざまな意見が飛び交っています。私自身も仕事でChatGPTを利用しているため、その特徴はよく理解しています。ChatGPTが得意なのは、過去のデータを基に『ドキュメントの作成』をすることです。『ドキュメント作成の準備』と『ドキュメントの公開と運用』は依然として人間が担当していくと思います。GPT-4などの技術を適切に活用しつつ、ドキュメンテーションにおける人間の価値を維持するためには、バランスの取れた使用、クリティカルシンキングの維持、深い思考や柔軟な発想力、継続的な学習、コミュニケーションスキルの重視、そして、チームワークと組織との協力を大切にすることが重要なのではないかと思いました。遅考術――じっくりトコトン考え抜くための「１０のレッスン」作者:植原 亮ダイヤモンド社Amazon参考文献ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティングSREの探求 19章 ドキュメント作成業務の改善：エンジニアリングワークフローへのドキュメンテーションの統合目的に沿ったDocumentation as Codeをいかにして実現していくか / PHPerKaigi 2021]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cmatrix コマンドでターミナルに文字を降らせる]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/cmatrix-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/cmatrix-introduction</guid>
            <pubDate>Mon, 13 Mar 2023 09:31:04 GMT</pubDate>
            <content:encoded><![CDATA[普段ターミナルを操作しているとき、特に仕事中などはターミナルに文字を降らせたいケースがよくあると思います。そんなときに cmatrix コマンドを使用すると簡単にターミナルに文字を降らせることができます。cmatrix コマンドhttps://www.asty.org/cmatrix/https://github.com/abishekvashok/cmatrixこの記事では cmatrix コマンドのインストール方法や使い方を簡単に紹介します。 インストールHomebrew を使用している場合は brew install でインストールすることができます。$ bre...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 1.4 で導入された terraform_data リソースの使い方]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-1_4-terraform-data</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-1_4-terraform-data</guid>
            <pubDate>Thu, 09 Mar 2023 09:06:50 GMT</pubDate>
            <content:encoded><![CDATA[Terraform 1.4 が GA になりました 🎉🎉🎉https://www.hashicorp.com/blog/terraform-1-4-improves-the-cli-experience-for-terraform-cloudTerraform 1.4 では新しく terraform_data リソースが導入されました。terraform_data リソースは null_resource を置き換えるものであり、さらに異なる用途にも使用できます。https://developer.hashicorp.com/terraform/language/resources...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Notion API を使用してデータベースを操作する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/notion-api-usage</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/notion-api-usage</guid>
            <pubDate>Mon, 06 Mar 2023 09:13:09 GMT</pubDate>
            <content:encoded><![CDATA[Notion で Integration を作成して Notion API を使用してデータベースを操作するまでの手順メモ。 準備 1. Integration を作成するMy integrations ページに遷移します。Create new integration をクリックします。Name には任意の Integration 名を入力します。今回は Example Integration としておきます。Associated workspace には Integration をインストールするワークスペースを選択します。自身がワークスペースの Admin レベ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[振り返り (2020 - 2022)]]></title>
            <link>https://zenn.dev/toversus/articles/8557a7fb2bc15c</link>
            <guid>https://zenn.dev/toversus/articles/8557a7fb2bc15c</guid>
            <pubDate>Sun, 05 Mar 2023 14:17:49 GMT</pubDate>
            <content:encoded><![CDATA[コロプラに 2020/3/1 に入社して、2023/2/28 付けで退職したので、丸々 3 年間勤務したことになります。本当の意味での大規模 Kubernetes 環境で貴重な経験をさせて貰い感謝しかないです。記憶が新しい内に、この 3 年間でやってきたことを公開できる範囲で整理しました。 GitOps 風なマニフェスト管理への移行インフラチームで管理している監視ツールやアドオンなコンポーネントを Helm でインストールしていました。マルチクラスタな環境で手動インストールはスケールしないので、Helmfile で生成した各クラスタのマニフェストを Argo CD で同期する方式に...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Devbox を使った開発環境]]></title>
            <link>https://blog.1q77.com/2023/03/devbox/</link>
            <guid>https://blog.1q77.com/2023/03/devbox/</guid>
            <pubDate>Sat, 04 Mar 2023 15:05:12 GMT</pubDate>
            <content:encoded><![CDATA[ローカル環境を汚さずDockerコンテナのオーバーヘッドもなく、開発環境を自在に構築できる「Devbox 0.2.0」登場 － Publickey この記事を最初に見たときは「えーそん]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『2023年もSRE再考と叫びなさい!!』というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/03/03/105049</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/03/03/105049</guid>
            <pubDate>Fri, 03 Mar 2023 01:50:49 GMT</pubDate>
            <content:encoded><![CDATA[概要エンジニア文化祭 2023というイベントに『2023年もSRE再考と叫びなさい‼️ - SREの跡を求めず SREの求めたるところを求めよ』というタイトルで登壇しました。2023年にSREについて再び考えたりしたいなーって思いながらこのタイトルにしました。途中でこのイベントにはSREの方だけではなく開発者やその他の方もたくさん聞いてるイベントじゃーんって思い直してガッツリ資料を作り直しましたので見守ってください。サイトリライアビリティワークブック ―SREの実践方法オライリー・ジャパンAmazon資料登壇資料になります。 speakerdeck.comあとがき30分発表なのに資料が50ページ程度で、技術発表にしても高速早口オタクすぎたとおもいます。DevOpsの背景を歴史から紐解いていたりしてたらこうなりましたが後悔はしてないです。本発表に関しては2023年 SRE再考と称しておきながら最後の3つ『信頼性が確保できるとプラットフォームにしたくなる』、『信頼性が確保できると変更速度を両立したくなる』、『信頼性が確保できると未知のものを見つけたくなる』への掘り下げが少なかったと思います。それが主にガッツリ資料を作り直した部分になります。この資料はもう少し喋りたいと思うので加筆、修正して60分ぐらいで喋らせてくれるイベントがあればTwitter でDM下さい。じゃあ、あとがきに書けばよくね？参考文献SRE サイトリライアビリティエンジニアリングが”ザックリ”「すっきり」分かる本: Googleが実践している新DevOps方法論SRE サイトリライアビリティエンジニアリングサイトリライアビリティワークブックWhat's the Difference Between DevOps and SRE?Solving Reliability Fears with Site Reliability EngineeringThe History of DevOps ReportsEffective DevOps非ITの事業会社にSREと言わずにSREを持ち込んだReliability When Everything Is a Platform: Why You Need to SRE Your Customersネットワーク・エフェクト 事業とプロダクトに欠かせない強力で重要なフレームワークLeanとDevOpsの科学[Accelerate] テクノロジーの戦略的活用が組織変革を加速する継続的デリバリーのソフトウェア工学:もっと早く、もっと良いソフトウェアを作るための秘訣オブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイド反脆弱性[上]――不確実な世界を生き延びる唯一の考え方反脆弱性[下]――不確実な世界を生き延びる唯一の考え方2022年版 OpenTelemetryを知れば世界が平和に]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions Importer を使って CI/CD を GitHub Actions に移行する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-actions-importer</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-actions-importer</guid>
            <pubDate>Thu, 02 Mar 2023 08:10:59 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Actions Importer が GA になりました 🎉🎉🎉https://github.blog/2023-03-01-github-actions-importer-is-now-generally-available/GitHub Actions Importer は様々な CI サービスから GitHub Actions への移行をサポートするツールです。他の CI サービスで使用している設定ファイルを元に GitHub Actions ワークフロー定義の YAML ファイルを自動で作成することができます。2023 年 03 月 02 日現在、次の CI...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Snowflakeでのコスト管理]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/ffe6450c4cd851</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/ffe6450c4cd851</guid>
            <pubDate>Tue, 28 Feb 2023 10:45:26 GMT</pubDate>
            <content:encoded><![CDATA[Snowflakeを最近触ってみることがあったので、コスト周りについて個人的に調べたログ参考ドキュメント↓Snowflakeでのコスト管理 | Snowflake Documentation お品書きSnowflakeのコストについてSnowflakeのコスト調査Snowflakeのコスト制御 SnowflakeのコストについてSnowflakeでのコストは次の3つの領域に分類される。コンピューティング: ユーザー管理(仮想ウェアハウス)、Snowflake管理(Snowpipeなどのサーバーレス機能)、およびクラウドサービスストレージ: データステージング...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[APIのエンドポイント設計で気をつけていること~ポエム編~]]></title>
            <link>https://qiita.com/bayobayo0324/items/4b21a71c5fb0e0202fbc</link>
            <guid>https://qiita.com/bayobayo0324/items/4b21a71c5fb0e0202fbc</guid>
            <pubDate>Tue, 28 Feb 2023 01:07:37 GMT</pubDate>
            <content:encoded><![CDATA[この記事は？日々の業務のなかで、フロントエンドチームの立場でAPIを利用したりバックエンドAPIチームの立場でAPIを設計実装改修したりする私のポエムみたいなものです。みなさまが日々の業務に疲れ…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Charm 製の Go ロギングライブラリ「Log」を試してみる]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/charm-log-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/charm-log-introduction</guid>
            <pubDate>Mon, 27 Feb 2023 09:29:55 GMT</pubDate>
            <content:encoded><![CDATA[Charm 製の Go ロギングライブラリが出たので早速試してみたメモです。https://github.com/charmbracelet/log 検証環境Go v1.20charmbracelet/log v0.1.1 使い方 基本的な使い方以下のメソッドを使うと特定のレベルのログを出力します。log.Debug()log.Info()log.Warn()log.Error()log.Fatal()log.Print() は設定されているログレベルに関係なく出力されます。package mainimport "github.com/cha...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【Istio⛵️】安全なアップグレード手法の仕組み]]></title>
            <link>https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548</link>
            <guid>https://hiroki-hasegawa.hatenablog.jp/entry/2023/02/26/202548</guid>
            <pubDate>Sun, 26 Feb 2023 11:25:48 GMT</pubDate>
            <content:encoded><![CDATA[01. はじめに02. Istioのアップグレード手法を説明する前にカナリアリリースとはカナリアリリースの手順【１】【２】【３】【４】『カナリアリリース』の呼称の由来03. アップグレード手法の概要手順【１】【２】【３】【４】【５】【６】【７】【８】04. アップグレード手法の詳細手順前提NamespaceIstiodIngressGatewayマイクロサービス【１】 アップグレード前の検証ここで実施することistioctl x precheckコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration【２】 新Istiodのインストールここで実施することistioctl versionコマンドistioctl installコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration【３】 Webhookの宛先のServiceの変更ここで実施することistioctl tag setコマンド【４】 IngressGatewayをインプレースアップグレードここで実施することkubectl rollout restartコマンド【５】 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施することkubectl rollout restartコマンド【６】 ユーザの手を借りたテストここで実施することもし問題が起こった場合【７】 istio-proxyコンテナの段階的なアップグレードここで実施することkubectl rollout restartコマンド【８】 旧Istiodのアンインストールここで実施することistioctl uninstallコマンドkubectl getコマンド▼ IstiodのDeployment▼ Webhookの宛先のService▼ 宛先のServiceを決めるMutatingWebhookConfiguration05. おわりに01. はじめに隠しません。有吉弘行のサンデーナイトドリーマーが生きがいです。さて今回は、Istioの安全なアップグレード手法の仕組みに関する記事を投稿しました🚀執筆時点 (2023/02/26) では、IstioのIstiodコントロールプレーン (以降、Istiodとします) のアップグレード手法には、『インプレース方式』と『カナリア方式』があります。また合わせてアップグレードが必要なIstioのIngressGatewayにも、その手法に『インプレース方式』と『カナリア方式』があります。今回の安全なアップグレード手法として、Istiodでは『カナリアアップグレード』、IngressGatewayでは『インプレースアップグレード』を採用します。それでは、Istioの安全なアップグレード手法の仕組みをもりもり布教しようと思います😗 (沼のまわりに餌をまく)↪️ 参考：Istio / Canary UpgradesIstio / Installing Gateways02. Istioのアップグレード手法を説明する前にカナリアリリースとはIstiodのカナリアアップグレードが理解しやすくなるように、カナリアリリースから説明したいと思います。カナリアリリースは、実際のユーザーにテストしてもらいながらリリースする手法です。もしカナリアリリースをご存知の方は、 03. アップグレード手法の概要 まで飛ばしてください🙇🏻‍♂️カナリアリリースの手順カナリアリリースは、一部のユーザーを犠牲にすることになる一方で、アプリを実地的にテストできる点で優れています。手順を交えながら説明します。↪️ 参考：CanaryRelease【１】旧環境のアプリを残したまま、新環境をリリースします。この段階では、全てのユーザー (100%) を旧環境にルーティングします。【２】ロードバランサーで重み付けを変更し、一部のユーザー (ここでは10%) を新環境にルーティングします。【３】ユーザーの手を借りて新環境を実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。【４】新環境に問題が起こらなければ、重み付けを段階的に変更し、最終的には全てのユーザー (100%) を新環境にルーティングします。『カナリアリリース』の呼称の由来カナリアリリースについては、その呼称の由来を知ると、より理解が深まります。カナリアリリースは、20世紀頃の炭坑労働者の危機察知方法に由来します。炭鉱内には有毒な一酸化炭素が発生する場所がありますが、これは無色無臭なので、気づくことに遅れる可能性があります。そこで当時の炭鉱労働者は、一酸化炭素に敏感な『カナリア』を炭鉱内に持ち込み、カナリアの様子から一酸化炭素の存在を察知するようにしていたそうです。つまり、先の『犠牲になる一部のユーザー』が、ここでいうカナリアというわけです😨画像引用：George McCaa, U.S. Bureau of Mines↪️ 参考：About canary deployment in simple wordsThis Device Was Used to Resuscitate Canaries in Coal Mines After They Signaled Danger03. アップグレード手法の概要手順カナリアリリースについて理解したところで、Istioの安全なアップグレード手法の概要を説明します。おおよそ以下の手順からなります。【１】旧Istiodが稼働しています。【２】新Istiod (discoveryコンテナ) をインストールします。【３】新Istiodのistio-proxyコンテナをインジェクションできるように、Webhookの宛先のServiceを変更します。この手順は重要で、後のistioctl tag setコマンドの箇所で詳細を説明しています。【４】IngressGatewayをインプレースアップグレードします。【５】一部のNamespaceで、istio-proxyコンテナをカナリアアップグレードします。ここで、カナリアリリースのような重み付けがなく、カナリアアップグレードの『カナリア』という呼称に違和感を持つ方がいるかもしれません。これについては、全てのNamespaceのistio-proxyコンテナを一斉にアップグレードするのではなく、段階的にアップグレードしていく様子を『カナリア』と呼称している、と個人的に推測しています。もし『カナリアアップグレード』の由来をご存じの方は、教えていただきたいです🙇🏻‍♂️【６】ユーザーの手を借りて、実地的にテストします (例：該当のエラーメトリクスが基準値以下を満たすか) 。【７】新Istiodのistio-proxyコンテナに問題が起こらなければ、他のNamespaceでもistio-proxyコンテナを段階的にカナリアアップグレードしていきます。一方でもし問題が起これば、Namespaceのistio-proxyコンテナとIngressGatewayをダウングレードします。【８】最後に、旧Istiodをアンインストールします。↪️ 参考：Istio / Canary Upgrades04. アップグレード手法の詳細手順ここからは、03. アップグレード手法の概要 を深ぼっていきます。ヤサイニンニクアブラマシマシな説明になってしまったので、ここまでを食べ切れた方のみ進むことをお勧めします🥺今回は、ドキュメントで一番優先して記載されているistioctlコマンドを使用した手順を説明します。もちろん、他のツール (例：Helm、ArgoCD) を使用してもアップグレードできます。細かな手順が異なるだけで、アップグレード手法の概要に関しては同じです🙆‍♂️それでは、03. アップグレード手法の概要 の【１】〜【８】に対応させながら説明していくゾ。前提Namespaceまず最初に、前提となる状況を設定しておきます。各Namespaceのistio.io/revラベルにdefaultが設定されているとします。$ kubectl get namespace -L istio.io/revNAME              STATUS   AGE   REVfoo               Active   34d   defaultbar               Active   34d   defaultbaz               Active   34d   defaultistio-ingress     Active   34d   default...マニフェストに書き起こすと以下のようになっています。apiVersion: v1kind: Namespacemetadata:  name: foo  labels:    istio.io/rev: defaultエイリアスはどんな値でも問題なく、よくあるエイリアスとしてdefaultやstableなどを使用します。このistio.io/revラベルがあることで、そのNamespaceのPodにistio-proxyコンテナを自動的にインジェクションします。istio-proxyコンテナのインジェクションについては、こちら記事で説明しており、もし気になる方はこちらもよろしくどうぞ🙇🏻‍♂️Istiodすでに1-14-6のIstiodが動いており、1-15-4にカナリアアップグレードします。IstiodはDeployment配下のPodであり、このPodはIstiodの実体であるdiscoveryコンテナを持ちます。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6IngressGatewayIngressGatewayはIstiodとは異なるNamespaceで動いており、インプレースアップグレードします。IngressGatewayはistio-proxyコンテナを持ちます。$ kubectl get deployment -n istio-ingressNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistio-ingressgateway   1/1     1            1           47s補足として、セキュリティのベストプラクティスでは、IstiodとIngressGatewayは異なるNamespaceで動かすことが推奨されています。↪️ 参考：Istio / Installing Gatewaysマイクロサービス各Namespaceでマイクロサービスが動いています。マイクロサービスのPodはistio-proxyコンテナを持ちます。$ kubectl get deployment -n fooNAME   READY   UP-TO-DATE   AVAILABLE   AGEfoo    2/2     1            1           47s...$ kubectl get deployment -n barNAME   READY   UP-TO-DATE   AVAILABLE   AGEbar    2/2     1            1           47s..$ kubectl get deployment -n bazNAME   READY   UP-TO-DATE   AVAILABLE   AGEbaz    2/2     1            1           47s...【１】 アップグレード前の検証ここで実施することアップグレード前に、現在のKubernetes Clusterがアップグレード要件を満たしているかを検証します。↪️ 参考：Before you upgradeistioctl x precheckコマンドistioctl x precheckコマンドを実行し、アップグレード要件を検証します。$ istioctl x precheck✅ No issues found when checking the cluster.Istiois safe to install or upgrade!  To get started, check out https://istio.io/latest/docs/setup/getting-started/問題がなければ、istioctlコマンドはNo issue ...の文言を出力します。もし、問題がある場合、istioctlコマンドはエラー文言を出力します。例えば、Istioのistio-proxyコンテナのインジェクションではkube-apiserverと通信する必要があります。そのため、kube-apiserverのバージョンが古すぎるせいでIstioが非対応であると、エラーになります。kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、現在のIstiodのバージョンを確認します👀まずはIstiodのDeploymentを確認すると、1-14-6のDeploymentがあります。$ kubectl get deployment -n istio-system -l app=istiodNAME                   READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6          1/1     1            1           47s # 1-14-6istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です👇▼ Webhookの宛先のService次に、 Serviceを確認すると、1-14-6のServiceがあります。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6このServiceは、kube-apiserverからIstiodへのWebhookを仲介することにより、istio-proxyコンテナのインジェクションを可能にします。istio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です👇▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後に、MutatingWebhookConfigurationを確認すると、istio-revision-tag-<エイリアス>とistio-sidecar-injector-<リビジョン番号>のMutatingWebhookConfigurationがあります。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレード用istio-sidecar-injector-1-14-6   2          2m16s # インプレースアップグレード用のため今回は言及しないistio-proxyコンテナのインジェクションの仕組みでいうと、以下の赤枠の要素です👇これらのうち、前者 (istio-revision-tag-<エイリアス>) をカナリアアップグレードのために使用します。このMutatingWebhookConfigurationは、Webhookの宛先のServiceを決めるため、結果的にistio-proxyコンテナのバージョンを決めます。ここで、MutatingWebhookConfigurationのistio.io/revラベルとistio.io/tagラベルの値も確認しておきます。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \    | yq '.metadata.labels'...istio.io/rev: 1-14-6istio.io/tag: default...istio.io/revラベルはIstiodのバージョン、istio.io/tagラベルはこれのエイリアスを表しています。また、.webhooks[].namespaceSelectorキー配下のistio.io/revキーの検知ルールを確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \    | yq '.webhooks[]'...namespaceSelector:  matchExpressions:    - key: istio.io/rev      operator: In      values:        - default...合わせて、.webhooks[].clientConfig.serviceキー配下のServiceを名前を確認します。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \    | yq '.webhooks[].clientConfig'...service:  name: istiod-1-14-6...整理すると、Namespaceでistio.io/revラベルにdefaultを設定しておけば、MutatingWebhookConfigurationがそれを検知し、特定のIstioのバージョンのServiceにWebhookを送信できるようになっています。↪️ Istio / Safely upgrade the Istio control plane with revisions and tags【２】 新Istiodのインストールここで実施することそれでは、新Istiodをインストールします。↪️ 参考：Control planeistioctl versionコマンド新しくインストールするIstiodのバージョンは、istioctlコマンドのバージョンで決まります。そこで、istioctl versionコマンドを実行し、これのバージョンを確認します。$ istioctl versionclient version: 1.15.4        # アップグレード先のバージョンcontrol plane version: 1.14.6 # 現在のバージョンdata plane version: 1.14.6istioctl installコマンドカナリアアップグレードの場合、istioctl installコマンドを実行します。ドキュメントではrevisionキーの値がcanaryですが、今回は1-15-4とします。この値は、Istioが使用する様々なKubernetesリソースの接尾辞や、各種リソースのistio.io/revラベルの値になります。$ istioctl install --set revision=1-15-4WARNING: Istio is being upgraded from 1.14.6 -> 1.15.4WARNING: Before upgrading, you may wish to use 'istioctl analyze' to check for IST0002 and IST0135 deprecation warnings.✅ Istio core installed✅ Istiod installed✅ Ingress gateways installed✅ Installation completeThank you for installing Istio 1.15.  Please take a few minutes to tell us about your install/upgrade experience!kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl installコマンドで何をインストールしたのかを確認します👀まずはIstiodのDeploymentを確認すると、1-15-4というDeploymentが新しく増えています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-14-6   1/1     1            1           47s # 1-14-6istiod-1-15-4   1/1     1            1           47s # 1-15-4接尾辞の1-15-4は、revisionキーの値で決まります。この段階では、旧Istiodと新Istioが並行的に稼働しており、kube-apiserverはまだ旧Istiodと通信しています今の状況は以下の通りです👇▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-15-4というServiceが新しく増えています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-14-6   ClusterIP   10.96.93.151     <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   109s # 1-14-6istiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4この段階では、まだWebhookの宛先はistiod-1-14-6のServiceです。今の状況は以下の通りです👇▼ Webhookの宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-15-4というMutatingWebhookConfigurationが新しく増えています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # カナリアアップグレードで使用するistio-sidecar-injector-1-14-6   2          2m16sistio-sidecar-injector-1-15-4   2          2m16sカナリアアップグレードでは、istio-revision-tag-<エイリアス>のMutatingWebhookConfigurationを使用します。今の状況は以下の通りです👇※ 実は、他にもインストールしているものがあるのですが、話をわかりやすくするために、今回は言及していません🙇🏻‍♂️【３】 Webhookの宛先のServiceの変更ここで実施することこの手順では、エイリアスのistio.io/tagラベルはそのままに、istio.io/revラベルの値を変更します。さらに、Webhookの宛先のServiceを変更します。↪️ 参考：Default tagSafely upgrade the Istio control plane with revisions and tagsistioctl tag setコマンドistioctl tag setコマンドを実行し、istio.io/revラベルの値と宛先のServiceを変更します。$ istioctl tag set default --revision 1-15-4 --overwrite実行後に、もう一度MutatingWebhookConfigurationを確認すると、istio.io/revラベルの値が変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \    | yq '.metadata.labels'...istio.io/rev: 1-15-4istio.io/tag: default...また、Webhookの宛先のServiceも変わっています。$ kubectl get mutatingwebhookconfiguration istio-revision-tag-default -o yaml \    | yq '.webhooks[].clientConfig'...service:  name: istiod-1-15-4...これらにより、Webhookの宛先が1-15-4のServiceとなるため、1-15-4のistio-proxyコンテナをインジェクションできるようになります。今の状況は以下の通りです👇【４】 IngressGatewayをインプレースアップグレードここで実施することWebhookの宛先が1-15-4のServiceに変わったところで、IngressGatewayをインプレースアップグレードします。↪️ 参考：In place upgradekubectl rollout restartコマンドkubectl rollout restartコマンドを実行し、IngressGatewayをインプレースアップグレードします。$ kubectl rollout restart deployment istio-ingressgateway-n istio-ingress再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq '.spec.containers[].image'docker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ補足として、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです👇なお、IngressGatewayのアップグレード時、マイクロサービスへのインバウンド通信が遮断されてしまうと思った方がいるかもしれません。この点については、DeploymentがローリングアップグレードでIngressGatewayのPodを入れ替えるため、安心していただいて問題ありません🙆‍♂️【５】 一部のNamespaceのistio-proxyコンテナをアップグレードここで実施すること続けて、一部のNamespaceのistio-proxyコンテナをアップグレードします。Podの再作成により、新Istiodのistio-proxyコンテナがインジェクションされるため。istio-proxyコンテナをアップグレードできます。↪️ 参考：Data planekubectl rollout restartコマンド前提にあるように、Namespaceには foo bar baz があります。kubectl rollout restartコマンドを実行し、barのistio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment bar -n bar再作成したPodのイメージを確認してみると、istio-proxyコンテナを1-15-4にアップグレードできています。$ kubectl get pod bar -n bar -o yaml | yq '.spec.containers[].image'bar-app:1.0 # マイクロサービスdocker.io/istio/proxyv2:1.15.4 # istio-proxyコンテナ補足として、istioctl proxy-statusコマンドを使用して、アップグレードの完了を確認してもよいです。今の状況は以下の通りです👇【６】 ユーザの手を借りたテストここで実施することIstioを部分的にアップグレードしたところで、アップグレードが完了したNamespaceをテストします。ユーザーの手を借りて実地的にテストします (例：該当のエラーメトリクスが基準値を満たすか) 。今の状況は以下の通りです👇もし問題が起こった場合もし問題が起こった場合、1-14-6にダウングレードしていきます。istioctl tag setコマンドを実行し、istio.io/revラベルの値を元に戻します。$ istioctl tag set default --revision 1-14-6 --overwriteその後、kubectl rollout restartコマンドの手順を実行し、istio-proxyコンテナをダウングレードしてきます。【７】 istio-proxyコンテナの段階的なアップグレードここで実施すること先のNamespaceで問題が起こらなければ、残ったNamespace (foo、baz、...) のistio-proxyコンテナも段階的にアップグレードしていきます。kubectl rollout restartコマンド同様にkubectl rollout restartコマンドを実行し、istio-proxyコンテナからアップグレードします。$ kubectl rollout restart deployment foo -n foo$ kubectl rollout restart deployment baz -n baz...最終的に、全てのNamespacemのistio-proxyコンテナが新しくなります。今の状況は以下の通りです👇【８】 旧Istiodのアンインストールここで実施すること最後に、旧Istiodのアンインストールします。↪️ 参考：Uninstall old control planeistioctl uninstallコマンドistioctl uninstallコマンドを実行し、旧Istiodをアンインストールします。$ istioctl uninstall --revision 1-14-6✅ Uninstall complete今の状況は以下の通りです👇kubectl getコマンド▼ IstiodのDeploymentkubectl getコマンドを実行し、istioctl uninstallコマンドで何をアンインストールしたのかを確認します👀まずはIstiodのDeploymentを確認すると、1-14-6というDeploymentが無くなっています。$ kubectl get deployment -n istio-system -l app=istiodNAME            READY   UP-TO-DATE   AVAILABLE   AGEistiod-1-15-4   1/1     1            1           47s # 1-15-4▼ Webhookの宛先のService次に Webhookの宛先のServiceを確認すると、istiod-1-14-6というServiceが無くなっています。$ kubectl get service -n istio-system -l app=istiodNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                 AGEistiod-1-15-4   ClusterIP   10.104.186.250   <none>        15010/TCP,15012/TCP,443/TCP,15014/TCP   87s  # 1-15-4▼ 宛先のServiceを決めるMutatingWebhookConfiguration最後にMutatingWebhookConfigurationを確認すると、istio-sidecar-injector-1-14-6というMutatingWebhookConfigurationが無くなっています。$ kubectl get mutatingwebhookconfigurationsNAME                            WEBHOOKS   AGEistio-revision-tag-default      2          114s  # 次のカナリアアップグレードでも使用するistio-sidecar-injector-1-15-4   2          2m16sこれで、新Istiodに完全に入れ替わったため、アップグレードは完了です。今の状況は以下の通りです👇※ 実は、他にもアンインストールしているものがあるのですが、話をわかりやすくするために、今回は言及していません🙇🏻‍♂️05. おわりにIstioの安全なアップグレード手法の仕組みをもりもり布教しました。Istioへの愛が溢れてしまいました。Istioのアップグレードの異常がシステムに与える影響力は非常に大きく、様々な問題 (体験談：istio-proxyコンテナのPodへのインジェクションがずっと完了せず、アプリコンテナを作成できない) が起こる可能性があります😇これからIstioを採用予定の方は、Istioを安全にアップグレードするために十分に準備しておくことをお勧めします👍]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LINE に送ったメッセージを Google Home に読み上げさせる]]></title>
            <link>https://blog.1q77.com/2023/02/line-bot-tts/</link>
            <guid>https://blog.1q77.com/2023/02/line-bot-tts/</guid>
            <pubDate>Sat, 25 Feb 2023 12:51:58 GMT</pubDate>
            <content:encoded><![CDATA[令和の時代、家に固定電話はなく、外出先から家族に直ぐに答えて欲しいことがあってもスマホはマナーモードで手元に置いてなければ気づくことができません。 そんなわけで、]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mosquitto で AWS IoT Core にメッセージを Publish/Subscribe する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/aws-iot-core-mosquitto</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/aws-iot-core-mosquitto</guid>
            <pubDate>Mon, 20 Feb 2023 10:00:32 GMT</pubDate>
            <content:encoded><![CDATA[オープンソースの MQTT メッセージブローカーである Mosquitto を使用して Mac で AWS IoT Core にメッセージを Publish/Subscribe を行う手順のメモ。https://mosquitto.org/ 準備 Mosquitto をインストールPublish/Subscribe を行うデバイスに Mosquitto をインストールします。今回は Mac を使用します。Homebrew を使用している場合は次のコマンドでインストールすることができます。$ brew install mosquittoその他のインストール方法については...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS IoT ルールで Timestream にメッセージを保存する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/aws-iot-rule-to-timestream</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/aws-iot-rule-to-timestream</guid>
            <pubDate>Mon, 20 Feb 2023 09:32:19 GMT</pubDate>
            <content:encoded><![CDATA[メッセージを Timestream に保存する IoT ルールを作成して MQTT テストクライアントで動作確認するまでの手順メモ。 手順 1. Timestream データベースを作成するTimestream データベースを作成していきます。Amazon Timestream のマネジメントコンソールで左メニューから データベース をクリックし、 データベースを作成 をクリックします。各項目を次のように入力します。項目値設定を選択標準データベース名前任意のデータベース名。今回は example とします。その他の設定は必要に応じて入...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Casbinのポリシーを動的・同期的にRDB管理するときの注意点]]></title>
            <link>https://qiita.com/bayobayo0324/items/1aa72baafefa2dee5147</link>
            <guid>https://qiita.com/bayobayo0324/items/1aa72baafefa2dee5147</guid>
            <pubDate>Mon, 20 Feb 2023 01:26:43 GMT</pubDate>
            <content:encoded><![CDATA[どんな記事？前回、Casbinで学ぶアクセス制御モデルRBACを書いたあとに、書き足りないなと感じていたので再度Casbinについて書いてみようかと。引き続きCasbinとGoについて、業務で得…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『自由研究には向かないウェブオペレーション』というタイトルで登壇しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/02/18/201252</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/02/18/201252</guid>
            <pubDate>Sat, 18 Feb 2023 11:12:52 GMT</pubDate>
            <content:encoded><![CDATA[概要【今更聞けない】Linuxのしくみ - Forkwell Library #16 というイベントに『自由研究には向かないウェブオペレーション - サイト運用管理を取り巻く環境の変化 Cloud Native時代に考えるLinux オペレーション』というタイトルで登壇しました。自由研究には向かないウェブオペレーションというのは2023年において我流でウェブオペレーションをやっていく限界があるという思いがあってこのタイトルにしました。が、タイトルが仰々しすぎて資料作成にとても時間がかかりました。資料登壇資料になります。 speakerdeck.comあとがき上記では我流でウェブオペレーションをやっていく限界があると言ってました。が、自由研究には向かない殺人という小説を直近で読んでいて依頼されたのでタイトルを拝借しただけでした。ウェブオペレーションに関していうとパブリッククラウドやIaCその他諸々の文化の登場や発展により2010年よりは洗練されていて実は知識体系を構築しようと思えばいくつかの括りでできたりするんじゃないかなと思って酔っ払った勢いでまとめてみた。ができたものを朝確認すると公開する自信がなかったのでやめておきました。どこかで修正して発表したいと思います。最近のアプリケーションはクラウド上のLinuxでビルドしてクラウド上のLinux でデプロイしてクラウド上のLinuxで動かすので結局様々な知識が求められるよって話でした。あと、関係ないのですが今回の登壇のためにAWSで実現するモダンアプリケーション入門を読みました。AWSを使わなくても具体的にモダンアプリケーションのインフラを考えるのにとても良い本だったので一緒にオススメしておきます。参考資料ウェブオペレーション［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】スーパーユーザーなら知っておくべきLinuxシステムの仕組み詳解 システム・パフォーマンス 第2版オブザーバビリティ・エンジニアリングAWSで実現するモダンアプリケーション入門 〜サーバーレス、コンテナ、マイクロサービスで何ができるのか継続的デリバリーのソフトウェア工学　もっと早く、もっと良いソフトウェアを作るための秘訣チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよ心理的安全性のつくりかた]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Helm Chart の歩き方 導入前に読みたいドキュメントについて]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/02/16/141433</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/02/16/141433</guid>
            <pubDate>Thu, 16 Feb 2023 05:14:33 GMT</pubDate>
            <content:encoded><![CDATA[Helm  を導入する前にChartについて読んでおいてほしいドキュメントをまとました。Chart の作成各ファイルの説明についてChart.yamlvalues.yaml.helmignoretemplate/templates/NOTES.txttemplates/_helpers.tplHelm について知るHelm Template Language の記法values.yaml へのアクセスHelm Template で利用できる関数Helm Chart で利用できる制御構文Named Templates を用いて一つのページで定義していく空白を管理する - の話Helm Chart をよくしていくHelm Chart のデバッグHelm Chart のリファクタリングHelm Chart のテストHelm Chart のリポジトリ化さいごに参考資料Chart の作成helm create でHelm Chart を作成します。Chart とは、Kubernetes リソースのまとまりを定義するファイル群のことです。helm create で構築したもの雛形はここでできます。中身を見れればなんとなく動きもわかるかもしれないので実際に手を動かしながら読んでもらえると嬉しいです。$ helm create mychartCreating mychart$ tree -a ./mychart./chart-namemychart/├── .helmignore├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yamlこれにより、mychart ディレクトリが作成されます。特別なことがなければ基本的にはこれをベースに作成していくことになると思います。Helm CreateVim にもプラグイン があるので利用しているエディターごとに入れていただければと思います。各ファイルの説明について作成した mychart ディレクトリに移動して、Chart の設定を編集します。Chart.yamlChart.yaml は、作成した Chart のメタ情報を管理するファイルです。幾つかの必須パラメーターと追加のパラメーターがあります。詳細は公式のドキュメントを読んでください。Chart.yamlvalues.yamlvalues.yaml は、Helm Template Language で利用する変数の、デフォルト値を指定したファイルです。上書きしたい時は別途指定してあげます。チャート内のvalues.yamlファイルサブチャートの場合、親チャートのvalues.yamlファイルhelm install または helm upgrade に -f フラグを付けて渡した場合の values ファイル (helm install -f myvals.yaml ./mychart)set で渡される個々のパラメータ (helm install --set foo=bar ./mychart のように)Values Files.helmignoreChart をリポジトリ化する際には、作成したファイル一式を helm package コマンドを利用して tar ファイルにするのですが、.helmignore を利用すると、その tar ファイルに含めたくないファイルを指定できるようなります。The .helmignore filetemplate/templates/ はテンプレートファイル用のディレクトリです。テンプレートとして利用するファイルが納入されています。A First Templatetemplates/NOTES.txttemplates/NOTES.txt は、Chart をインストールやアップデートした時にターミナル上で表示される文言を記述できます。アクセスすべきURLやリリース結果が見れるものを記載したりしてます。{{ .Chart.Name }} や {{ .Chart.Version }} といった記述できます、これが Helm Template Language となります。Helm Template Language の記法については後述。Creating a NOTES.txt Filetemplates/_helpers.tpltemplates/\_helpers.tpl は、マニフェストファイルではなく、マニフェストファイル内で利用されるグローバル変数（Helm では Named Template と呼ばれます）を定義したファイルとなります。Using "Partials" and Template IncludesHelm について知るHelm Template Language の記法コメントは # の他、{{/*...*/}}のような記法を利用できます。# を利用したコメントはデバッグモードで表示される、という違いがあります。Comments (YAML Comments vs. Template Comments)values.yaml へのアクセスBuilt-in Object とは、Helm Template Lunguage で利用できるオブジェクトというかインスタンスとなります。values.yaml 等に定義した値を取得するには、Values オブジェクト内のインスタンス変数 なになに にアクセスする、みたいな感じで利用するイメージとなります。Release のほか、Valuesや Chart といった Built-in Object を利用しています。Values は、values.yaml に定義された値へアクセスできるオブジェクトです。Chart は、Chart.yaml に定義された値へアクセスできるオブジェクトです。Built-in ObjectsHelm Template で利用できる関数Helmファイルを書いていくとこうしたいあぁしたいとなると思うのですがHelm Template Language 内では、様々な関数がビルトインされています。Helmは60以上の利用可能な関数を持っています。そのうちのいくつかは、Go Tepｍplate自体で定義されています。{{ .Release.Name | quote }} という記述があったとして、.Release.Name という値に対して、パイプを介し、 quote という引用符を付与する関数を実行しているものになります。こんな感じで、実行したい関数をパイプを介して記述していくことなります。Template Function ListHelm Chart で利用できる制御構文Helm には制御構造が利用できます。 これは、テンプレートの生成の流れを制御する機能を提供します。制御構文は、以下が用意されています。if/else for creating conditional blockswith to specify a scoperange, which provides a "for each"-style loopちなみにGo Tepｍplate自体で定義されています。Flow ControlNamed Templates を用いて一つのページで定義していく名前付きテンプレートとは、単にファイルの中で定義され、名前が付けられたテンプレートのことです。Named Template は、{{ define }} ... {{ end }} アクションで定義を行い、{{ template }} や {{ include }} アクションで、その値を利用することになります。Named Templatesちなみに{{ template }} でなく、 {{ include }} しないと、パイプを介した関数の実行できないため、{{ include }} が良い。Using the 'include' Function空白を管理する - の話まず、テンプレート宣言の中括弧の構文を特別な文字で変更し、テンプレートエンジンに空白を切り詰めるように指示する。{{- xxx }} や {{ XX -}}とかで出てきているハイフンですが、これは Helm Template Lunguate を利用した行の空白を管理するものです。ハイフンの有無により空白の除去を実行してくれます。空白を消したあとにindentを追加するような形で利用したりもします。Helm Chart をよくしていくHelm Chart をデバッグしたりリファクタリングする時のヒントを書いていきます。Helm Chart のデバッグHelm Chart ではデバッグする方法をいくつか用意しています。Debugging Templateshelm lint は、Chart がベストプラクティスに沿っているかを確認するためのツールです。helm template --debug はローカルでChart template のレンダリングをテストします。困ったらこれでyaml を直接、確認します。helm install --dry-run --debugは、サーバーがテンプレートをレンダリングし、その結果のマニフェストファイルを返すという素晴らしい方法です。helm get manifestは、サーバーにインストールされているテンプレートを確認する良い方法です。Helm Chart のリファクタリングHelm Chart の品質をあげるためのヒントとコツをいくつか取り上げられています。テンプレートの関数を知り有用と判断すれば利用する文字列を引用する、整数を引用しない。これは絶対に頼む。1つのコマンドでリリースをインストールまたはアップグレードChart Development Tips and TricksHelm Chart のテストtemplates/tests/ ディレクトリ配下においたマニフェストファイルは、helm testコマンドにより実行することができます。Chart TestsHelm Chart のリポジトリ化リポジトリ化するには、index.yaml というファイルとChart 一式を固めた tar ファイルを静的 Web ホスティングサイトにアップロードすることで実現されます。The Chart Repository Guideさいごにこれもあれば読んでほしいという内容があれば名前付きで掲載させていただくので連絡いただきたいです。参考資料Helm Docs | Getting Started]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[運用の効率化を支える AWS Systems Manager Automation の紹介]]></title>
            <link>https://sreake.com/blog/aws-ssm-automation/</link>
            <guid>https://sreake.com/blog/aws-ssm-automation/</guid>
            <pubDate>Thu, 16 Feb 2023 02:40:28 GMT</pubDate>
            <content:encoded><![CDATA[AWS Systems Manager（SSM）では運用に役立つ機能が提供されています。 ただし、提供されている機能が多く、今まで使用した経験があるのは一部の機能に限られていましたので、どのようなことができるのか調べてみ […]The post 運用の効率化を支える AWS Systems Manager Automation の紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions でプライベートリポジトリを checkout する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-actions-checkout-private-repo</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-actions-checkout-private-repo</guid>
            <pubDate>Mon, 13 Feb 2023 09:40:56 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Actions で別のプライベートリポジトリを checkout する方法のメモ。 サンプルコードこの記事で紹介するサンプルコードは以下のリポジトリで管理しています。https://github.com/koki-develop/gh-actions-checkout-private-repo-example 前置きこのドキュメントでは次の 2 通りの方法についてまとめます。Deploy keys を使う方法Personal Access Token を使う方法いずれの方法も GitHub Actions ワークフローを作成するリポジトリと chec...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Caddy の Internal TLS 証明書の有効期間を指定する]]></title>
            <link>https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/</link>
            <guid>https://blog.1q77.com/2023/02/caddy-internal-tls-cert-lifetime/</guid>
            <pubDate>Thu, 09 Feb 2023 14:29:32 GMT</pubDate>
            <content:encoded><![CDATA[以前 ワンライナーで https の Reverse Proxy を実行する という記事で Caddy を使うと local での開発用に任意のドメインの証明書を簡単に発行できるし CA の証明書も OS の証明書ストアに保存してくれるた]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『ポストモーテムはじめました』というタイトルで登壇しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/02/09/113316</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/02/09/113316</guid>
            <pubDate>Thu, 09 Feb 2023 02:33:16 GMT</pubDate>
            <content:encoded><![CDATA[概要インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT というイベントで『ポストモーテムはじめました』というタイトルで登壇しました。この登壇には元記事があって良いポストモーテムを執筆するために必要な5つのポイントです。この記事に対していくつかの加筆修正を行い資料にしました。資料登壇資料になります。 speakerdeck.comあとがきポストモーテムについて考えたり調べていくと仕組みよりも組織としての心がけが大事だと思いました。発表の性質や時間の都合上SREでの話に留めたのですが、品質管理についても言及しながらまとめていく活動もしたい。組織を作っていくなら下の2冊はとてもオススメです。心理的安全性のつくりかた　「心理的柔軟性」が困難を乗り越えるチームに変える作者:石井遼介日本能率協会マネジメントセンターAmazon失敗の科学 失敗から学習する組織、学習できない組織作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon品質管理についてはこちらを参考にしました。失敗を後悔する「恥」として捉えてはいけない。学習する機会と捉え、次に活かせば良い。そのためのスキルが品質管理。ビジュアル品質管理の基本 第5版作者:内田 治日経BPマーケティング(日本経済新聞出版Amazon登壇した御礼をいただいた。『インシデントにどう対応してきたか？みんなで学ぶポストモーテム Lunch LT』というイベント登壇の御礼品をいただけました。　#LT_findy pic.twitter.com/9ll5ig0ZjA— nwiizo (@nwiizo) 2023年2月21日  参考資料SREとはなにかhttps://sreake.com/blog/what-is-sre/良いポストモーテムを執筆するために必要な5つのポイントhttps://sreake.com/blog/5point-good-postmortem/Part III. Practiceshttps://sre.google/sre-book/part-III-practices/SRE サイトリライアビリティエンジニアリングhttps://www.oreilly.co.jp/books/9784873117911/ウェブオペレーションhttps://www.oreilly.co.jp/books/9784873114934/Postmortem Culture: Learning from Failurehttps://sre.google/sre-book/postmortem-culture/チームが機能するとはどういうことか──「学習力」と「実行力」を高める実践アプローチよりhttps://www.amazon.co.jp/dp/B00N8J1NPQ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions から ECR に Docker イメージを push する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-actions-ecr-push-image</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-actions-ecr-push-image</guid>
            <pubDate>Wed, 08 Feb 2023 10:03:48 GMT</pubDate>
            <content:encoded><![CDATA[備忘録。 サンプルコード今回紹介するサンプルコードは以下のリポジトリで管理しています。https://github.com/koki-develop/github-actions-ecr-push-example 準備 1. GitHub Actions 用の ID プロバイダと IAM ロールを作成するGitHub Actions で OIDC を使用して AWS 認証を行うために、下記ドキュメントを参考に ID プロバイダと IAM ロールを作成します。https://zenn.dev/kou_pg_0131/articles/gh-actions-oidc-aw...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenSLO とは？]]></title>
            <link>https://sreake.com/blog/openslo/</link>
            <guid>https://sreake.com/blog/openslo/</guid>
            <pubDate>Tue, 07 Feb 2023 03:37:40 GMT</pubDate>
            <content:encoded><![CDATA[はじめに OpenSLO の概要に触れながら SLO as Code の現状についてお話しします。 OpenSLOとは？ OpenSLO とは、サービスレベル目標 (SLO)、それに関連するリソースの記述形式を標準化する […]The post OpenSLO とは？ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Docker イメージのタグ一覧を取得する docker-tags CLI の紹介]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/docker-tags-cli-usage</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/docker-tags-cli-usage</guid>
            <pubDate>Mon, 06 Feb 2023 09:19:35 GMT</pubDate>
            <content:encoded><![CDATA[概要Docker イメージのタグ一覧を取得する docker-tags CLI を公開しました。https://github.com/koki-develop/docker-tags以下のように任意の Docker イメージのタグ一覧を取得して出力することができます。$ docker-tags alpinelatestedge3.9.63.9.53.9.4# ...# 名前付きで出力することもできる$ docker-tags alpine -nalpine:latestalpine:edgealpine:3.9.6alpine:3.9.5alpin...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions で GitHub の画像キャッシュをクリアする]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/hub-purge-action-usage</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/hub-purge-action-usage</guid>
            <pubDate>Mon, 30 Jan 2023 10:22:30 GMT</pubDate>
            <content:encoded><![CDATA[GitHub では README などに載せた画像は Camo という画像プロキシ経由で https://camo.githubusercontent.com/... のような URL で配信されるのですが、たまにこれらの画像が長期間キャッシュされてしまうことがあります。例えば僕の GitHub Profile には Badge Generator で作成した Zenn や Qiita のバッジを表示しているのですが、これらの画像が長期間キャッシュされて正しい数値が表示されていないことがありました。GitHub Profileこれらの画像キャッシュをクリアするシェルスクリプトなど...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLabで指定したグループ内の全てのリポジトリを一括でcloneする]]></title>
            <link>https://zenn.dev/tayusa/articles/ae5911391c9440</link>
            <guid>https://zenn.dev/tayusa/articles/ae5911391c9440</guid>
            <pubDate>Sun, 29 Jan 2023 17:07:31 GMT</pubDate>
            <content:encoded><![CDATA[概要1個1個丹精込めて手動でcloneすることに限界を感じたので、一括で自分に関連するリポジトリをcloneする シェルスクリプト.zshrc# リポジトリのディレクトリを作成してからcloneする# 第1引数 URL(https://gitlab.example.com/diaspora/diaspora-client.git)function git_clone_to_path() {  [[ -z ${commands[git]} ]] \    && { echo 'git is required'; return 1; }  loca...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub の README はリポジトリのルートディレクトリ以外にも置ける]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/github-readme-path</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/github-readme-path</guid>
            <pubDate>Thu, 26 Jan 2023 10:02:07 GMT</pubDate>
            <content:encoded><![CDATA[Twitter で以下のツイートを見かけました。https://twitter.com/azu_re/status/1614458485055586305そこで調べてみたところ、 GitHub では次の場所に置かれている README を認識するようです。.github/リポジトリのルートディレクトリdocs/複数の README が含まれている場合は、 .github/ 、ルートディレクトリ、 docs/ の順に優先されます。例えば冒頭のツイートの reduxjs/redux-toolkit は .github/ ディレクトリ内に README.md (正確には pa...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【Terraform】CloudFront Functions を使用して Basic 認証を設定する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-cloudfront-basicauth</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-cloudfront-basicauth</guid>
            <pubDate>Mon, 23 Jan 2023 10:22:18 GMT</pubDate>
            <content:encoded><![CDATA[たまに必要になるのでメモ。 検証環境Terraform v1.3.7AWS Provider v4.49.0 サンプルコード今回紹介するサンプルコードは下記リポジトリで管理しています。https://github.com/koki-develop/cloudfront-basic-auth-example 準備今回は例として S3 バケットのオブジェクトを配信する CloudFront Distribution を作成します。主題ではないので気になる方のみ読んでください。サンプルコードprovider.tf# AWS Provider の設定prov...]]></content:encoded>
        </item>
    </channel>
</rss>