<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 08 Dec 2025 22:42:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[AIに手順書を書かせよう! 手順書作成で向き合うAIの不確実性]]></title>
            <link>https://zenn.dev/kamos/articles/procedure_book_with_ai</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/procedure_book_with_ai</guid>
            <pubDate>Mon, 08 Dec 2025 15:23:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIに手順書を書かせてみよう! 手順書にはいくつか必要なポイントがあるね!明確な作業目的作業内容の確実性手順の網羅性影響範囲AIはここに書かれていること、結構苦手だよね。特に作業内容の確実性を担保することは苦手なんだよね!だから、AIに手順書を書かせるときは、AIが苦手なポイントを補うように工夫する必要があるよ!今回は、AIに｢災害時検証: CloudSQLリージョン移行｣の手順書を書かせてみて、一緒に工夫してみよう! 手順作成 まずはそのまままずは、AIにそのまま手順書を書かせてみよう! 以下のプロンプトを使用してみたよ!Cloud SQLの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[メモリ安全なC言語実装「Fil-C」について紹介]]></title>
            <link>https://dev.mix64.com/2025/12/08/post-397/</link>
            <guid isPermaLink="false">https://dev.mix64.com/2025/12/08/post-397/</guid>
            <pubDate>Mon, 08 Dec 2025 13:03:10 GMT</pubDate>
            <content:encoded><![CDATA[今回はメモリ安全なC言語実装を提供できる「Fil-C」について紹介します。既存のC言語プログラムに対しても互換性を持ち、再コンパイルすること...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~Redis hashes編~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_data_hash</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_data_hash</guid>
            <pubDate>Mon, 08 Dec 2025 12:19:17 GMT</pubDate>
            <content:encoded><![CDATA[今回はredisで使えるhashesについてみていきます。昨日公開したStringsについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_datatypes 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis hashesのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/hashes/ hashesに...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【初参加】CODE BLUE 2025レポート：体感したトレンドとAIの脅威]]></title>
            <link>https://qiita.com/yutaf11/items/239101da0bf5265b61df</link>
            <guid isPermaLink="false">https://qiita.com/yutaf11/items/239101da0bf5265b61df</guid>
            <pubDate>Mon, 08 Dec 2025 08:35:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめに先月、CODE BLUE 2025に参加してきました。私は普段、SRE兼セキュリティエンジニアとして働いています。過去、SREとして技術系のイベントにはいくつか参加してきましたが、セキュリティ特化のオフラインイベントは今回のCODE BLUEが初めてでした。こ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[技術広報はちゃんとなめてやれ（技術広報をなめるなを読んで）　]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/08/152614</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/08/152614</guid>
            <pubDate>Mon, 08 Dec 2025 06:26:14 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、whywaita Advent Calendar 2025 8日目のエントリ記事です。whywaita Advent Calendar 10周年ということで、自分もwhywaitaとの出会いと10年という節目を掛けて何か書きたいと考えたのですが、うまいネタが思いつかず。とはいえ、whywaitaと出会ったきっかけがお祭り的な技術イベントだったので、今回は技術イベントの「お祭り性」について語っていきます。思い返すと、技術コミュニティとの出会いは、いつもお祭りのようでした。見知らぬ人と技術の話で盛り上がり、気づいたらとんでもない深い時間になっていた懇親会。準備段階から当日まで、ワクワクしながら作り上げた勉強会。あの空気感こそが、私をエンジニアとして成長させてくれた原動力でもありました。そんな私が最近読んで、考えさせられた記事があります。はじめにSakutaroさんが書かれた「技術広報をなめるな」を読みました。note.comSakutaroさんの主張をこの記事で使うために要約すると、技術広報とは「技術に関する情報流通を最適化すること」であり、採用やブランディングにじわじわ効いてくる組織の筋肉である、ということです。片手間でやるものではなく、専門性を持って取り組むべき重要な機能だと。その主張には100%同意します。技術広報を軽視する組織への警鐘として、価値のある記事でした。詳しくは読んで下さい。ただ、読み終わったあと、ひとつ気になることがありました。「なめるな」と言われて、真面目に取り組んだ人は、どうなるだろう。技術広報の重要性を理解した。だから本気で取り組んだ。毎週ブログを書き、登壇の機会を作り、勉強会を企画した。でも、半年後、1年後、その人はまだ続けているだろうか。私が見てきた現実では、真面目に取り組んだ人ほど、燃え尽きていく。「技術広報は大事だ」と理解しているからこそ、手を抜けない。手を抜けないから、疲弊する。疲弊するから、続かない。続かないから、また新しい誰かが「大事だから」と引き継いで、同じサイクルを繰り返す。ここで断っておくと、私は専任のDevRelや技術広報をやっていたわけではありません。エンジニアとしてブログを書いたり、登壇したり、勉強会を企画したり、そういう活動に参加してきた側です。だから以下は、「現場で技術広報に関わってきたエンジニア」としての個人的な意見です。Sakutaroさんへの反論や批判ではなく、同じテーマを別の角度から眺めてみた、という試みです。Sakutaroさんが「技術広報の重要性」を語ったのなら、私は「技術広報の持続可能性」を語りたい。Sakutaroさんが「なめるな」と言ったのなら、私は「ちゃんとなめてやれ」と言いたい。「なめる」というのは、軽視することではありません。肩の力を抜いて、それでも真剣に向き合うこと。重く構えすぎず、軽やかに、本気で楽しむこと。そういう姿勢を指しています。この記事で言いたいのは、技術広報を「お祭り」として捉え直すことで、どう持続可能な形に設計できるか、という話です。「技術広報を続けられない」のは、個人の努力不足なのか技術広報が続かない。ブログの更新が止まる。勉強会の開催頻度が落ちる。登壇者が見つからない。こうした現象を見たとき、私たちはつい「担当者の努力が足りない」「モチベーションの問題だ」と考えがちです。でも、本当にそうでしょうか。私が見てきた限り、技術広報に関わる人は真面目な人が多い。「会社のためになる」「エンジニアの成長につながる」と信じているからこそ、時間を割いて取り組んでいる。努力が足りないのではなく、むしろ、努力しすぎて燃え尽きている。つまり、個人の努力ではなく、構造に原因があるのではないか。技術広報を「重要な業務」として位置づけるほど、プレッシャーは増す。「会社の顔としてふさわしい記事を」「PVやシェア数で成果を示さないと」「毎月コンスタントに発信を」。こうした期待は、真面目な人ほど重く受け止める。結果として、技術広報は「楽しいからやる」ものではなく「やらなければならない」ものになる。義務感で動く活動は、長くは続きません。だから私は、技術広報を「お祭り」として捉え直すことを提案したい。技術広報を「お祭り」として捉えたとき、何が変わるのか「お祭り」と「業務」の違いは何か。業務には、目標がある。KPIがある。期限がある。評価がある。達成できなければ、失敗になる。お祭りには、もちろん準備や段取りがある。でも、本質は違う。非日常性があって、ワクワクして、参加は自由で、失敗しても笑って済む。みんなで作り上げる。終わったあとに「楽しかったね」と言い合える。思い出してみてください。あなたが「楽しかった」と感じた技術イベントには、何がありましたか。KPIはなかったはずです。評価もなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていた。それだけで、あの場は価値があった。技術広報を「業務」として捉えると、タスクになり、KPIになり、疲弊の原因になります。でも「お祭り」として捉えると、楽しみになり、創造性の源泉になり、持続可能な活動になる。もちろん、会社という組織なのでKPIは必要です。数字で語らないと理解されないこともある。大人ですから、建前として必要なものは必要です。でも本音の部分では、お祭りなんです。Sakutaroさんは技術広報を「技術に関する情報流通を最適化すること」と定義しました。私はその定義に異論はありません。ただ「情報流通の最適化」という言葉は正確ですが、人を動かす力は弱い。「今月の情報流通を最適化しよう」と言われても、イメージが湧かない。でも「お祭りを企画して盛り上げよう」と言い換えると、途端にイメージが湧きます。人は「最適化」という目標には動きにくいけど、「お祭り」という体験には参加したがるんです。そして面白いことに、良いお祭りを企画しようとすると、自然と「情報流通の最適化」が達成されます。読みたくなるブログは情報が届く。参加したくなる勉強会は知見が共有される。面白いカンファレンスブースはブランドが伝わる。お祭りが楽しいのは、予定調和じゃないからです。神輿が予想外の方向に進んだり、知らない人と急に仲良くなったり、思いもよらない出来事が起きる。その「意外性」がお祭りの醍醐味です。技術広報も同じで、完璧に計画されたブログより、思いつきで書いた記事がバズることもある。意外性こそが人の心を動かします。でも、意外性は余裕がないと生まれません。タスクに追われている人に、遊び心は出てこない。「やらなきゃいけない」という義務感からは、「やってみたら面白かった」という発見は生まれない。だから、技術広報には「精神的な遊び」が必要です。お祭りを「業務」として100%真面目にやると、それはもはやお祭りではなくなります。参加の形は、ひとつじゃないお祭りには色んな参加の仕方があります。神輿を担ぐ人もいれば、屋台で焼きそばを売る人もいる。踊る人もいれば、見ているだけの人もいる。写真を撮る人も、SNSで実況する人もいる。ゴミを拾う人も、場所取りをする人もいる。どの参加の仕方も、お祭りの一部です。技術広報も同じです。記事を書く人だけが貢献者ではない。レビューする人も貢献者です。アイデアを出す人も貢献者です。社内で記事をシェアする人も貢献者です。「この前のあの話、ブログにしたら面白そう」と声をかける人も貢献者です。登壇者の練習に付き合う人も貢献者です。「ブログを書いてもらえない」「登壇してもらえない」と悩んでいるなら、視点を変えてみてください。「書いてもらう」「登壇してもらう」以外の参加の形を、用意できているだろうか。神輿を担げる人は限られています。でも、お祭りを楽しむ方法は無数にある。担ぎ手だけがお祭りの参加者ではないんです。「ブログを書いてください」ではなく「先週のSlackでのやり取り、そのままブログにしませんか。私がタイトルと導入書きますよ」。「登壇してください」ではなく「5分のLTでいいので、この前の話をしてくれませんか」。義務ではなく、招待として。「ブログ書いてください」はお願い（義務感）。「ブログ書きませんか」は招待（選択肢）。この違いは大きいんです。あなた自身は、どうでしょうか。技術広報にどんな形でなら、無理なく関われそうですか。「怒られない範囲」は誰が決めているのかお祭りにも「やっていいこと」と「やってはいけないこと」がある。技術広報も同じです。失敗談を書け、人間臭さを出せ、と言われても、リスクが怖い。その懸念は正しいです。だからこそ、「怒られない範囲」を見極める力が必要になります。ただ、その「怒られない範囲」は、誰が決めているのでしょうか。明文化されたルールがあるのか、暗黙の了解なのか。上司が決めているのか、広報部門が決めているのか、法務が決めているのか。あるいは、なんとなく「空気」で決まっているのか。多くの組織では、「怒られない範囲」は明確に定義されていません。だから、発信する側は常に不安を抱えることになる。「これ、出していいのかな」「怒られないかな」。その不安が、発信のハードルを上げている。社内的にはOKだけど、社外的にNGになるケースがあります。「技術的には正しいけど、今その話題は炎上しやすい」という場合です。社外的にはOKだけど、社内的にNGになるケースもあります。「業界では普通の話題だけど、うちの会社ではタブー」という場合です。「怒られない範囲」を見極める能力とは、社内外の文脈を読む力です。これは経験を積むことでしか身につきません。小さく発信して、反応を見て、学んでいく。でも、もし組織として技術広報を続けたいなら、「怒られない範囲」を個人の判断に委ねるのではなく、組織として明確にする努力が必要ではないでしょうか。「ここまではOK」「これはNG」「迷ったらこの人に相談」。そういった指針があるだけで、発信のハードルはぐっと下がります。あなたの組織では、「怒られない範囲」はどのように決まっていますか。誰が決めていますか。それは明文化されていますか。持続可能にするために最後に、どうすれば技術広報を続けられるのか、という話をします。技術広報に関わる人が陥りがちな罠は、自分一人で全部やろうとすることです。ブログの企画、執筆依頼、レビュー、公開作業、SNSでの拡散。全部一人でやると、短期的には回ります。でも、長期的には崩壊します。お祭りは、主催者一人では成立しません。屋台を出す人、演奏する人、ゴミを拾う人、写真を撮る人、SNSで拡散する人。みんなが違う形で参加して、初めてお祭りは盛り上がります。「一人が100やる」のではなく、「10やる人、5やる人、1でも協力してくれる人を探す」これが持続の秘訣です。例えば、こんな工夫ができます。月に1回「ブログネタ出し会」を30分だけ開く。Slackに「こんな話をブログにしたい」と投げるだけのチャンネルを作る。「書けそうな人」ではなく「話が面白かった人」に声をかける。小さな仕組みを作っておくだけで、協力者は見つかりやすくなります。そして、もう1つ大事なこと。人間には波があるということです。10やれる時期もあれば、5しかやれない時期もある。1すらもやれない時期もある。プロジェクトが佳境に入っている時期。体調を崩している時期。家庭の事情がある時期。メンタルが落ちている時期。これは恥ずかしいことでも、甘えでもありません。人間だもの。「去年できたから、今年もできる」という思い込みこそが、燃え尽きの原因なんです。10やれる時は10やる。5しかやれない時は5でいい。やれない時は、休む。大事なのは、この「波」を組織として受け入れられているかどうかです。「先月は3本記事を出したのに、今月は1本もない。どうしたの」というプレッシャーがかかるなら、それは持続可能な仕組みとは言えません。「今月は厳しいので、来月がんばります」と言える文化があるかどうか。あなたのチームでは、パフォーマンスの波を受け入れられていますか。「今は無理」と言える空気がありますか。おわりに冒頭で書いた通り、私とwhywaitaの出会いは、お祭り的な技術イベントでした。あの場には「情報流通の最適化」なんて言葉はなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていただけです。でも、今ならわかります。私がワイワイと参加していたあのイベントの裏側には、真面目に予算を集めてきた人がいた。色んなステークホルダーの合意をまとめてきた人がいた。会場を押さえ、スケジュールを調整し、トラブルに備えていた「ちゃんとした大人」がいた。私はその恩恵を受けて、楽しんでいただけだったんです。10年経って、そのことがようやくわかるようになりました。いずれ自分も、あの「ちゃんとした大人」の側に回らなければならない。恩返しをしなければならない。その自覚はあります。でも、それでも。いや、だからこそ。次の世代の人たちには、お祭り感を味わってほしい。「裏側の苦労」を見せずに、「楽しかったね」と言ってもらえるイベントを作りたい。真面目に準備しながら、参加者には「お祭り」として届ける。それが、私なりの恩返しの形だと思っています。技術広報に関わるすべての人へ。疲れたら、休んでください。無理したら、倒れます。真面目すぎたら、続きません。でも、楽しさだけでも続きません。楽しさと、仕組みと、仲間が必要です。もしあなたが今「何もやれない時期」にいるなら、それでいいんです。休んでください。お祭りは、また元気になってから参加すればいい。技術広報は、あなたがいないと回らないほど脆弱なものであってはいけない。でも、あなたがいると、もっと楽しくなる。それくらいの距離感がちょうどいい。10年前のあの日、技術イベントで会った人と、今もこうしてAdvent Calendarで繋がっている。これこそが、お祭り駆動の技術広報の成果です。どこかのカンファレンスの懇親会で会ったら、お祭りの話をしましょう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年AWS Community Builderの活動報告]]></title>
            <link>https://blog.masasuzu.net/entry/2025/12/08/100000</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/12/08/100000</guid>
            <pubDate>Mon, 08 Dec 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[今年はブログ4本(純粋なAWSの記事はなし)、登壇5本(内社内2本)という結果でした。勉強会参加自体はそこそこしてたんですが、アウトプットという点では少し物足りない結果になったなという感想です。要因としてはGoogle Cloud関連の活動が比較的多くて、AWS関連にリソースを割けなかったというのもあります。第二の理由としては今年後半が特に業務が多忙で身動きが取れない月があったのも事実です。とはいえ忙しいは言い訳に過ぎないので、なんとアウトプットする仕組み作りをしていきたいとことです。来年はもっとアウトプットを増やしていきたいです。そこで以下の数値を目標にやっていきたいと考えています。社外登壇: 月0.5本AWSテーマのブログ: 月1本以上やってくぞ。以下今年のアウトプットを置いておきます。ブログAWS関連なしクラウドニュートラルblog.masasuzu.netdiary.masasuzu.netdiary.masasuzu.netblog.masasuzu.net登壇AWS関連 speakerdeck.com speakerdeck.com speakerdeck.comクラウドニュートラル speakerdeck.com speakerdeck.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代のスキーマファースト開発 FastAPI × GitHub Packages で型安全なSDKを自動配布する]]></title>
            <link>https://zenn.dev/meziron/articles/32ac2241bbec38</link>
            <guid isPermaLink="false">https://zenn.dev/meziron/articles/32ac2241bbec38</guid>
            <pubDate>Sun, 07 Dec 2025 15:00:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。フロントエンド開発者とバックエンド開発者の間で「APIの仕様が違う」「ドキュメントが古い」といった問題に悩まされたことはありませんか？さらにAI時代になり、Claude CodeやCursorなどのAIコーディングツールを使う機会が増えてきました。しかし、AIにAPI呼び出しを実装させると、存在しないエンドポイントを「想像」で実装してしまったり、パラメータの型を間違えたりすることがあります。本記事では、FastAPIのOpenAPI自動生成機能を活用し、GitHub ActionsでTy...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[どこでも動くC言語プログラム「Cosmopolitan Libc」を触ってみた]]></title>
            <link>https://dev.mix64.com/2025/12/07/cosmopolitan-libc/</link>
            <guid isPermaLink="false">https://dev.mix64.com/2025/12/07/cosmopolitan-libc/</guid>
            <pubDate>Sun, 07 Dec 2025 09:16:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はC言語でありながらbuild-anyware run-anywareを目指すプロジェクト「Cosmopolitan Libc」について...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~Redis Strings編~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_datatypes</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_datatypes</guid>
            <pubDate>Sun, 07 Dec 2025 03:46:51 GMT</pubDate>
            <content:encoded><![CDATA[今回はredisで使えるStringsについてみていきます。 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis Stringsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/strings/ 単独の値の格納redisでは文字列やシリアライズされたデータをbytesデータとして格納します。早速keyとvalueを指定して文字列を格納してみましょう。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~サーバ起動とPythonからのアクセス~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_quickstart</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_quickstart</guid>
            <pubDate>Sat, 06 Dec 2025 13:56:14 GMT</pubDate>
            <content:encoded><![CDATA[今回は改めてredisに入門してみました。今まで使って経験はありつつ、ちゃんと調べて勉強しようということで使ってみました。まずはサーバの建て方とPythonからのアクセス方法をまとめてみます。 検証内容今回は以下の内容を実施しますredisサーバの起動Docker上でサーバを立てますポートは6379でポートフォワーディングによりローカル環境からアクセスできるようにしますpythonコードからのアクセスシンプルなデータの格納と取得を実施 早速検証！！ redisサーバの起動redisサーバをDocker上で立てます。以下のレポジトリを参考にたてます...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、類推するな]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/06/060208</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/06/060208</guid>
            <pubDate>Fri, 05 Dec 2025 21:02:08 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、Rust Advent Calendar 2025 6日目のエントリ記事です。はじめに「それって、○○みたいなものですよね」私は、この言葉に何度救われてきただろう。新しい概念を理解するとき。誰かに説明するとき。問題を解決するとき。類推は、私の思考の基盤だった。いや、今でも基盤だ。ただ、その基盤が思ったほど頑丈ではなかったことを、私は何度も思い知らされてきた。Rustを学び始めた頃の話だ。Rustは、プログラミング言語の1つだ。安全で高速なプログラムを書けることで知られている。私はRustの公式教科書「The Rust Programming Language」を読んでいた。所有権の章に差し掛かったとき、こんな説明に出会った。Rustには「所有権（ownership）」という独特の概念がある。少し専門的な話になるが、プログラムを書くとき、データはコンピュータの「メモリ」という場所に保存される。メモリは有限だから、使い終わったデータは片付けなければならない。片付けを忘れると、メモリがいっぱいになって動かなくなる。逆に、まだ使っているデータを間違えて片付けてしまうと、プログラムが壊れる。多くのプログラミング言語では、この「いつ片付けるか」の管理をプログラマーに任せるか、自動で行うかのどちらかだ。Rustは第三の道を選んだ。「所有権」というルールで、コンパイル時（プログラムを実行する前）に安全性を保証する。ルールはシンプルだ。メモリ上のデータには、必ず1つの「所有者」となる変数が存在する。そして、その値を別の変数に渡すと、所有権が移動（move）する。移動した後は、元の変数からはアクセスできなくなる。所有者がいなくなったデータは、自動的に片付けられる。これがRustの基本ルールだ。（注：この先、コード例が続きます。プログラミングに詳しくない方は、コードの詳細を読み飛ばしても大丈夫です。「類推で理解したつもりになったが、実際は違った」という体験談として読んでいただければ、本記事の主旨は伝わります。）私は頭の中で、勝手に類推を作り上げた。「なるほど、本の貸し借りみたいなものか。本を誰かに貸したら、自分の手元にはない。返してもらうまで読めない」。教科書にそう書いてあったわけではない。私が勝手にそう解釈した。この類推で、所有権の基本は理解できた気がした。コンパイラが怒る理由もわかった。moveが起きる場面も予測できるようになった。私は満足した。「そういうことか」と納得して、次の章に進んだ。しかし、しばらくして困難に直面した。私がやりたかったのは、こういうことだ。本棚に本がある。本を誰かに貸す。貸した本が何かを覚えておきたい。現実世界では当たり前のことだ。これをコードで書こうとした。// 私が書こうとしたコード（コンパイルエラー）struct BookShelf {    books: Vec<String>,    lent_to: Option<&String>,  // 貸した本への参照を持ちたい}Rustでは、所有権を完全に移動させずに、一時的にデータを「見せる」だけの仕組みがある。これを「参照（reference）」や「借用（borrow）」と呼ぶ。&Stringは「Stringへの参照」を意味する。所有権は移動しない。ただ、一時的に覗き見できるだけだ。「本の貸し借り」の類推で考えれば、これは自然なはずだった。本棚には本がある。本を誰かに貸したら、貸した本への参照を持っておく。でも、Rustはこのコードを許さない。error[E0106]: missing lifetime specifier「ライフタイム」。また新しい概念だ。なぜライフタイムが必要なのか。参照は、データの「場所」を覚えている。でも、その場所にあったデータが消えてしまったらどうなるか。参照だけが残って、参照先には何もない。存在しないデータを指す参照。これは危険だ。だから、Rustは参照の「寿命」を追跡する。参照が有効な間は、参照先のデータも存在していなければならない。この寿命を明示するのが、ライフタイムだ。ライフタイムを指定すればいいのか。私は格闘した。// ライフタイムを追加してみるstruct BookShelf<'a> {    books: Vec<String>,    lent_to: Option<&'a String>,}コンパイルは通る。貸し出しもできる。let mut shelf = BookShelf {    books: vec![String::from("Rust Book"), String::from("Programming Rust")],    lent_to: None,};shelf.lent_to = Some(&shelf.books[0]);println!("貸し出し中: {:?}", shelf.lent_to);// => 貸し出し中: Some("Rust Book")でも、本棚に新しい本を追加しようとすると、地獄が始まる。shelf.books.push(String::from("New Book"));error[E0502]: cannot borrow `shelf.books` as mutable because it is also borrowed as immutable  --> src/main.rs:22:5   |18 |     shelf.lent_to = Some(&shelf.books[0]);   |                           ----------- immutable borrow occurs here...22 |     shelf.books.push(String::from("New Book"));   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ mutable borrow occurs here23 |     println!("新しい本を追加: {:?}", shelf.books);   |                                      ----------- immutable borrow later used here「本を貸している間は、本棚に新しい本を追加できない」。現実世界ではありえない制約だ。なぜこんなに難しいのか。私は「本の貸し借り」で考え続けた。貸している間も本棚にどの本があるかは覚えている。本棚に新しい本を追加することと、貸した本を追跡することは、まったく独立した操作のはずだ。なのに、なぜRustはそれを許さないのか。長い時間をかけて、やっと気づいた。私の類推が間違っていた。ここで「借用チェッカー（borrow checker）」の話をしなければならない。Rustには、コンパイル時にメモリ安全性を検証する仕組みがある。これが借用チェッカーだ。借用チェッカーの基本ルールはシンプルだ。「参照が有効な間は、参照先のデータを変更してはならない」。なぜこんなルールがあるのか。Vec（可変長配列）の仕組みを考えてみよう。Vecは、内部的には連続したメモリ領域にデータを格納している。本棚でいえば、横一列に並んだ棚だ。最初に5冊分のスペースを確保したとする。6冊目を追加したいとき、どうなるか。今の棚には入らない。だから、より大きな棚を用意して、5冊をすべて移動させる。そして6冊目を追加する。これがVecの動作だ。ここで問題が起きる。移動前の棚の位置を覚えている参照があったとする。本を移動した後、その参照はどこを指すのか。もう本がない場所だ。空っぽの棚を指している。これが「ダングリングポインタ」と呼ばれる危険な状態だ。存在しないデータへの参照。アクセスしたら、何が起きるかわからない。だから、Rustは「参照がある間は変更禁止」というルールを強制する。現実の本の貸し借りには、この問題は存在しない。本棚のサイズを変えても、貸した本が消えることはない。でも、コンピュータのメモリでは、Vecが成長するときにデータが移動する。「本」という類推が、私の理解を助けると同時に、私の理解を歪めていた。正しい設計は、参照ではなくインデックスや識別子を使うことだった。// アプローチ1: インデックスで管理struct BookShelf {    books: Vec<String>,    lent_index: Option<usize>,}let mut shelf = BookShelf {    books: vec![String::from("Rust Book")],    lent_index: None,};shelf.lent_index = Some(0);  // インデックスを記録shelf.books.push(String::from("New Book"));  // これは動く！println!("貸し出し中: {:?}", shelf.books.get(shelf.lent_index.unwrap()));// => 貸し出し中: Some("Rust Book")// アプローチ2: 所有権を完全に移動struct BookShelf {    books: Vec<String>,}struct LentBook {    book: String,        // 所有権ごと移動    borrower: String,}let mut shelf = BookShelf {    books: vec![String::from("Rust Book"), String::from("Programming Rust")],};let lent = LentBook {    book: shelf.books.remove(0),  // 本棚から取り出す    borrower: String::from("Alice"),};shelf.books.push(String::from("New Book"));  // 本棚は自由に変更できる「本の貸し借り」という類推は、入り口としては正しかった。でも、その類推を引きずりすぎた。Rustにおける「借用」は、現実世界の「貸し借り」とは違う。借用（&T）は「一時的に見せる」だけで、「貸した相手を追跡する」仕組みではない。そして、借用中はデータの変更ができない。この違いに気づくまでに、私は何週間も費やした。類推は、両刃の剣だ。思い返せば、これは初めての失敗ではなかった。非同期処理を学んだときも、同じ罠にはまった。（注：ここからも技術的な話が続きます。コードの詳細は読み飛ばしても、「料理の類推で考えたら、実際の挙動と違った」という話として理解できます。）まず、非同期処理とは何かを説明しておこう。日常生活で考えてみよう。洗濯機を回している間、あなたは洗濯機の前でじっと待っているだろうか。たぶん、その間に別のことをしているはずだ。掃除をしたり、料理を作ったり。洗濯機が終わったら、干しに行く。これが「非同期」の発想だ。プログラムも同じだ。通常のプログラムは、1つの処理が終わるまで次の処理に進めない。ファイルを読み込んでいる間、プログラムは待っている。ネットワークからデータを取得している間も、待っている。これでは効率が悪い。「待っている間に、別のことをやろう」。これが非同期処理だ。私は類推を作り上げた。「非同期処理は、料理を並行して作るようなものか」。パスタを茹でている間にソースを作る。オーブンで肉を焼いている間にサラダを準備する。待ち時間を有効活用して、全体の調理時間を短縮する。この類推で、Rustのasync/await構文の基本は理解できた。async fn cook_dinner() {    let pasta = boil_pasta();      // パスタを茹で始める    let sauce = make_sauce().await; // ソースを作る（待つ）    let pasta = pasta.await;        // パスタが茹で上がるのを待つ    serve(pasta, sauce);}問題は、「共有リソース」にアクセスするコードを書いたときだった。共有リソースとは何か。料理の例で考えよう。キッチンには、コンロが1つしかない。2人の料理人が、同時にそのコンロを使いたいとする。どうなるか。1人が使っている間、もう1人は待つしかない。プログラムでも同じことが起きる。データベース接続、ファイル、あるいはメモリ上のデータ構造。複数の処理が同時に1つのリソースにアクセスしようとすると、混乱が起きる。だから、「Mutex（ミューテックス）」という仕組みで順番を管理する。1つの処理がMutexを「ロック」したら、他の処理はロックが解除されるまで待たなければならない。use std::sync::Arc;use tokio::sync::Mutex;struct Kitchen {    stove: Arc<Mutex<Stove>>,  // コンロは1つしかない（Mutexで保護）}async fn cook_two_dishes(kitchen: &Kitchen) {    let stove = kitchen.stove.clone();    // 2つの料理を「並行して」作ろうとする    let dish1 = tokio::spawn({        let stove = stove.clone();        async move {            let mut s = stove.lock().await;  // コンロを確保            cook_on_stove(&mut s).await;     // 10分かかる        }    });    let dish2 = tokio::spawn({        let stove = stove.clone();        async move {            let mut s = stove.lock().await;  // コンロを確保しようとする            cook_on_stove(&mut s).await;     // ...が、dish1が終わるまで待つ        }    });    let _ = tokio::join!(dish1, dish2);}私は「並行して料理を作る」と思っていた。2つの料理を同時に調理して、時間を半分にできるはずだと。でも、コンロは1つしかない。片方がコンロを占有している間、もう片方は待っていた。実行してみると、こうなる。[メインコンロ] パスタ の調理を開始[メインコンロ] パスタ の調理が完了[メインコンロ] ソース の調理を開始[メインコンロ] ソース の調理が完了合計調理時間: 4.00秒各料理2秒なら、並行処理で2秒のはずだった。でも、4秒かかった。並行処理の意味がなかった。なぜこうなるのか。現実の料理で考えてみよう。実際のキッチンでは、Aさんがコンロの左側でパスタを茹でている間、Bさんが右側でソースを温められる。コンロには複数の口がある。だから、2人が同時に調理できる。でも、私のコードでは、コンロを「1つのもの」としてMutexで保護していた。「コンロ全体」をロックしていた。だから、1人がコンロを使っている間、もう1人はコンロの前で待つしかなかった。これが「排他制御」の現実だ。Mutexで保護された共有リソースは、一度に1つのタスクしかアクセスできない。「料理を並行して作る」という類推には、この排他制御の概念が含まれていなかった。私の頭の中のキッチンには、コンロの口がいくつもあった。でも、コードの中のキッチンには、コンロが1つしかなかった。より厄介な問題もあった。「デッドロック」だ。デッドロックとは何か。日常の例で説明しよう。AさんとBさんが、食事をしようとしている。テーブルには、ナイフとフォークが1本ずつしかない。食事をするには、両方が必要だ。Aさんは先にナイフを取った。Bさんは先にフォークを取った。Aさんは思う。「フォークがほしい。Bさんが手放すまで待とう」。Bさんも思う。「ナイフがほしい。Aさんが手放すまで待とう」。どちらも、自分が持っているものを手放さない。どちらも、相手が手放すのを待っている。永遠に。これがデッドロックだ。async fn prepare_meal(kitchen: &Kitchen) {    // タスク1: まずコンロを確保、次にオーブンを確保    let task1 = async {        let _stove = kitchen.stove.lock().await;        tokio::time::sleep(Duration::from_millis(10)).await;        let _oven = kitchen.oven.lock().await;  // オーブンを待つ        // ...    };    // タスク2: まずオーブンを確保、次にコンロを確保    let task2 = async {        let _oven = kitchen.oven.lock().await;        tokio::time::sleep(Duration::from_millis(10)).await;        let _stove = kitchen.stove.lock().await;  // コンロを待つ        // ...    };    tokio::join!(task1, task2);  // 永遠に終わらない}タスク1がコンロを持ってオーブンを待ち、タスク2がオーブンを持ってコンロを待つ。お互いが相手を待ち続けて、永遠に進まない。実行してみると、こうなる。[タスク1] コンロを確保しました！[タスク2] オーブンを確保しました！[タスク1] オーブンを確保しようとしています...[タスク2] コンロを確保しようとしています...⚠️  タイムアウト！デッドロックが発生しました。現実の料理では、こんなことは起きない。「ちょっとナイフ貸して」と声をかければ済む。あるいは、「先にフォーク使っていいよ」と譲り合える。人間には、コミュニケーションがある。でも、コンピュータのスレッドは声をかけない。ロックを取得したら、自分の処理が終わるまで手放さない。相手が待っていることすら知らない。だから、永遠に待ち続ける。この問題のデバッグに、私は丸一日を費やした。プログラムが動かない。エラーも出ない。ただ、止まっている。「なぜプログラムが止まるのかわからない」と頭を抱えた。料理の類推では、デッドロックという概念自体が存在しなかったからだ。キッチンで誰かと道具の取り合いになっても、最終的にはどちらかが譲る。でも、プログラムは譲らない。また同じ失敗をしている。私は少し落ち込んだ。でも、まだ終わりではなかった。データベースのトランザクションでも、同じ失敗をした。（注：ここでも技術的な話が続きます。「銀行振込の類推で考えたが、実際のシステムはもっと複雑だった」という話として読んでいただければ大丈夫です。）まず、トランザクションとは何かを説明しよう。日常生活で例えてみる。あなたがコンビニでおにぎりを買うとする。この「買い物」という行為は、2つのことが同時に起きなければ成立しない。「あなたがお金を払う」と「店があなたにおにぎりを渡す」。お金だけ払っておにぎりがもらえなかったら困る。おにぎりだけもらってお金を払わなかったら、それは万引きだ。両方が成功するか、両方が起きないか。どちらかでなければならない。データベースでも同じだ。銀行の振込を考えよう。Aさんの口座から1万円を引いて、Bさんの口座に1万円を足す。この2つの操作は、両方成功するか、両方失敗するか、どちらかでなければならない。Aさんから引いたのにBさんに足されなかったら、1万円が消えてしまう。このような「ひとまとまりの操作」を保証する仕組みがトランザクションだ。途中で失敗したら、最初の状態に戻す（ロールバック）。すべて成功したら、確定する（コミット）。私は類推を作り上げた。「トランザクションは、銀行の振込みたいなものか」。この類推で、データベースの基本的な特性は理解できた。BEGIN TRANSACTION;UPDATE accounts SET balance = balance - 10000 WHERE user_id = 'A';UPDATE accounts SET balance = balance + 10000 WHERE user_id = 'B';COMMIT;問題は、トランザクションが失敗したときの処理を書いたときだった。async fn transfer_money(    pool: &PgPool,    from: &str,    to: &str,    amount: i64,) -> Result<(), Error> {    let mut tx = pool.begin().await?;    // 送金元の残高を減らす    sqlx::query("UPDATE accounts SET balance = balance - $1 WHERE user_id = $2")        .bind(amount)        .bind(from)        .execute(&mut *tx)        .await?;    // 外部APIを呼び出して送金通知を送る（これが問題）    notify_transfer(from, to, amount).await?;    // 送金先の残高を増やす    sqlx::query("UPDATE accounts SET balance = balance + $1 WHERE user_id = $2")        .bind(amount)        .bind(to)        .execute(&mut *tx)        .await?;    tx.commit().await?;    Ok(())}外部APIの呼び出しが失敗したら、トランザクションはロールバックされる。データベースの状態は元に戻る。完璧だと思った。でも、ある日、こんなシナリオを考えた。外部APIの呼び出しが成功した後、2番目のUPDATE文が失敗したらどうなるか。順番を追ってみよう。まず、送金元の残高を減らす。成功。次に、送金通知を送る。成功。通知は、もう相手に届いている。最後に、送金先の残高を増やす。ここで失敗。アカウントが凍結されていた。トランザクションはロールバックされる。データベースの残高は元に戻る。でも、通知は？もう送ってしまった。取り消せない。実際にPostgreSQLで検証してみた。--- シナリオ: 外部API成功後にDB更新が失敗 ---（Alice → frozen_account: 5,000円 - 受取人アカウント凍結で失敗）  → 通知を送信しました（外部API呼び出し）送金失敗: 受取人のアカウントが凍結されています残高:  alice: Alice (90000円)  ← 変わっていない  bob: Bob (60000円)送金通知: 2件  alice → bob: 10000円  alice → frozen_account: 5000円  ← 通知は送信された！トランザクションはロールバックされる。データベースの残高は元に戻る。でも、送金通知はすでに送られている。「5,000円送金しました」という通知が届いているのに、実際には送金されていない。銀行の振込では、こんなことは起きない。なぜか。銀行では、振込処理と通知は同じシステムの中で一貫して管理されている。「お金を動かす」と「通知を送る」が、一体の操作として設計されている。でも、私が書いたコードはそうではなかった。データベースと、通知を送るサービスは、別々のシステムだった。データベースのトランザクションは、データベースの中だけを巻き戻せる。外部サービスへの呼び出しは、トランザクションの外にある。ロールバックしても、すでに送った通知は取り消せない。これが「分散システム」の難しさだ。複数のシステムにまたがる操作を、一貫して管理することは、想像以上に難しい。より厄介な問題もあった。ロールバック自体が失敗することがあるのだ。async fn complex_operation(pool: &PgPool) -> Result<(), Error> {    let mut tx = pool.begin().await?;    // 複数のテーブルを更新    update_table_a(&mut tx).await?;    update_table_b(&mut tx).await?;    update_table_c(&mut tx).await?;  // ここで失敗    tx.commit().await?;    Ok(())}// update_table_c()が失敗すると、txはドロップされてロールバックされる// ...はずだが、ネットワーク障害でロールバックも失敗したら？銀行の振込では、「振込を取り消す」という操作は確実に成功する。窓口で「やっぱりやめます」と言えば、それで終わりだ。でも、コンピュータの世界では、ロールバック自体がネットワーク障害やデータベースクラッシュで失敗することがある。「元に戻す」という操作が、途中で止まる。そうなると、データは中途半端な状態で残る。Aさんから引かれたのに、Bさんには足されていない。1万円が宙に浮いている。この問題に気づいたのは、本番環境で実際に起きてからだった。ユーザーからの問い合わせで発覚した。「送金したのにお金が届いていない」。調べてみると、ネットワーク障害でロールバックが完了していなかった。「銀行の振込みたいなもの」という類推が、分散システムの複雑さを覆い隠していた。銀行の振込は、何十年もかけて作り上げられた堅牢なシステムの上で動いている。私のコードは、そうではなかった。いつになったら学習するのだろう。私は自分に問いかけた。でも、失敗はまだ続いた。キャッシュでも、同じパターンだった。（注：最後の技術的な事例です。「辞書を手元に置いておく類推で考えたが、実際はもっとややこしかった」という話です。）まず、キャッシュとは何かを説明しよう。日常生活で考えてみる。あなたは仕事中、よく使うファイルをどこに置いているだろうか。毎回、会社の書庫まで取りに行くだろうか。たぶん、よく使うファイルは自分の机の上に置いているはずだ。すぐ手に取れるから。これがキャッシュの発想だ。プログラムの世界でも同じだ。データベースからデータを取得するのは、時間がかかる。ネットワーク越しに問い合わせて、データベースが検索して、結果を返す。毎回これをやると遅い。だから、一度取得したデータを「手元」に保存しておいて、次からはそれを使う。これがキャッシュだ。私は類推を作り上げた。「キャッシュは、よく使うものを手元に置いておくことか」。辞書を引くとき、毎回本棚まで行くのは面倒だ。よく使う辞書は、机の上に置いておく。机の上にあれば、すぐに引ける。この類推で、キャッシュの基本は理解できた。use std::collections::HashMap;use std::sync::RwLock;struct UserCache {    cache: RwLock<HashMap<UserId, User>>,}impl UserCache {    async fn get_user(&self, id: UserId, db: &Database) -> User {        // まずキャッシュを確認        if let Some(user) = self.cache.read().unwrap().get(&id) {            return user.clone();        }        // なければDBから取得        let user = db.fetch_user(id).await;        // キャッシュに保存        self.cache.write().unwrap().insert(id, user.clone());        user    }}問題は、データが更新されたときだった。async fn update_user_email(    cache: &UserCache,    db: &Database,    id: UserId,    new_email: String,) -> Result<(), Error> {    // DBを更新    db.update_email(id, &new_email).await?;    // キャッシュを無効化    cache.cache.write().unwrap().remove(&id);    Ok(())}これで十分だと思った。データを更新したら、キャッシュから削除する。次にアクセスしたときは、DBから最新のデータを取得する。シンプルで、正しいはずだった。でも、ある問題が起きた。「競合状態（race condition）」だ。競合状態とは何か。例え話で説明しよう。あなたと同僚が、同時に同じ辞書を使おうとしている。あなたは辞書で「apple」を調べている。その間に、同僚が辞書の「apple」の項目に付箋を貼った。あなたが辞書を閉じて、もう一度開くと、付箋が貼ってある。これは問題ない。でも、こういうケースはどうか。あなたが辞書の「apple」のページをコピーしている間に、同僚が辞書の「apple」の項目を書き換えた。そして、あなたがコピーを終えて、そのコピーを棚にしまった。棚にあるのは、古い情報のコピーだ。これが競合状態だ。複数の処理が同時に動いているとき、その「順番」によって結果が変わってしまう。どの処理が先に終わるかは、そのときの負荷やネットワーク状況で変わる。だから、結果が予測できない。時刻T1: リクエストAがget_user()を呼ぶ時刻T1: リクエストAがキャッシュを確認 → ない時刻T2: リクエストAがDBからuser(email="old@example.com")を取得時刻T3: リクエストBがupdate_user_email()を呼ぶ時刻T3: リクエストBがDBを更新(email="new@example.com")時刻T4: リクエストBがキャッシュを削除時刻T5: リクエストAがキャッシュに古いデータを保存(email="old@example.com")何が起きたのか、順番に見てみよう。リクエストAは、DBから古いデータを取得した。でも、キャッシュに保存する前に、一瞬待たされた。CPUが他の処理をしていたのかもしれない。ネットワークが混んでいたのかもしれない。その隙に、リクエストBがやってきた。リクエストBは、DBのデータを更新した。そして、キャッシュを削除した。「これで、次にアクセスしたときは最新のデータが取得される」と。でも、リクエストAはまだ終わっていなかった。リクエストAは、さっき取得した古いデータを、キャッシュに保存した。リクエストBが削除した後のキャッシュに。結果、キャッシュには古いデータが入った。DBには新しいデータがある。キャッシュとDBで、データが食い違っている。実行してみると、こうなる。[T1] リクエストA: get_user()開始  [キャッシュ] ミス[T2] リクエストA: DBから取得中...  [DB] 取得完了: email="old@example.com"[T3] リクエストB: update_user_email()開始  [DB] メール更新: old@example.com -> new@example.com[T4] リクエストB: キャッシュ無効化[T5] リクエストA: キャッシュに保存  [キャッシュ] 保存: email="old@example.com" ← 古いデータ！--- 結果確認 ---DBの値:        email=Some("new@example.com")キャッシュの値: email=Some("old@example.com")⚠️  キャッシュに古いデータが残っている！結果、キャッシュには古いデータが残り続ける。現実世界の辞書では、こんなことは起きない。なぜか。辞書の内容は、めったに変わらない。そして、辞書を使うのは通常1人だ。複数人が同時に同じ辞書を書き換えながら参照することは、まずない。でも、コンピュータのデータは違う。複数のプロセスが、同時に、同じデータを読み書きする。しかも、ネットワーク遅延やCPUスケジューリングで、処理の順序が予測できない。「Aが先に終わるはず」と思っても、実際にはBが先に終わることがある。この問題をデバッグするのに、3日かかった。「たまにデータが古いままになる」という報告を受けて、最初はDBの問題だと思った。DBを調べた。問題なかった。次にキャッシュの設定を調べた。問題なかった。ログを細かく分析して、やっと気づいた。タイミングの問題だった。特定の順番で処理が実行されたときだけ、問題が起きていた。「手元に置いておく」という類推は、キャッシュの無効化タイミングの複雑さを完全に見落としていた。机の上の辞書は、勝手に内容が変わらない。でも、キャッシュの中のデータは、いつ古くなるかわからない。Phil Karltonの有名な言葉がある。「コンピュータサイエンスで難しいことは2つしかない。キャッシュの無効化と、名前付けだ」。この言葉の意味を、私は身をもって理解した。どれも、類推としては間違っていない。でも、類推が示す以上のことを、私は類推から読み取ってしまっていた。類推は、理解を助ける。しかし、誤解も生む。類推は、新しい視点を与える。一方で、本質を見えなくもする。類推は、創造の源泉だ。同時に、思考停止の入り口でもある。これらの経験以来、私は類推について考え続けてきた。エンジニアとして、類推をどう使い分けるべきか。いつ類推すべきで、いつ類推を断つべきか。類推の力を活かしながら、その罠に落ちないためには、何が必要なのか。そして、もう1つ気づいたことがある。類推は、単なる思考ツールではない。それは、人間の知能の根幹だ。 われわれは、あまりにも無意識に類推的な考え方をしながら日々を過ごしている。だからこそ、類推の限界を知ることが、これほど重要なのだ。これは、類推に救われてきた人間が、類推に何度も裏切られた話だ。そして、それでもなお類推を手放せない人間が、類推とどう向き合うかを考えた記録だ。類推とは何かまず、類推とは何かを明確にしておきたい。類推（アナロジー）とは、2つの異なる領域の間に構造的な類似性を見出し、一方の知識を他方に適用する思考法だ。AとBは表面的には違うが、その関係性の構造は似ている。だから、Aで学んだことを、Bに応用できる。私は、類推こそが人間の思考の根幹だと考えている。論理的思考も、批判的思考も、創造的思考も、よく見ると類推が基盤にある。われわれは類推なしには、新しいことを考えることすらできない。ソフトウェアエンジニアなんて、類推だらけだ。コードを読んでいると、「あ、これ、あのコードと同じ構造だな」と気づく。設計を考えていると、「前のプロジェクトのあのパターンが使えそうだ」と気づく。バグを追っていると、「この挙動、前にも見たことがある」とピンとくる。私たちは、毎日、無意識に類推している。自分でも気づかないうちに。プログラミングを学ぶとき、類推を使っている。「変数は、ラベル付きの箱みたいなものだ」と教わる。値を入れて、取り出す。この類推があるから、抽象的な概念を具体的にイメージできる。新しいデータベースを学ぶとき、類推を使っている。「PostgreSQLのMVCCは、MySQLのInnoDBと似ているか」と考える。この類推があるから、ゼロから学ぶより速く理解できる。新しい言語を学ぶとき、類推を使っている。「Rustのtraitは、Goのinterfaceみたいなものか」と考える。完全に同じではないが、入り口にはなる。われわれの頭の中では、常に類推が働いている。既知の世界での関係づけから、未知の関係づけを推論している。物語を読むときも、私たちは類推している。登場人物の経験を自分の人生に重ね、フィクションの世界から現実への教訓を引き出す。主人公が困難を乗り越える姿を見て、自分の状況に当てはめる。異なる時代や文化を舞台にした物語から、普遍的な人間の営みを感じ取る。共感とは、つまり類推だ。「この人の気持ちは、あのときの自分の気持ちに似ている」。そう感じるから、私たちは物語に心を動かされる。類推がなければ、われわれは毎回ゼロから学ばなければならない。新しいフレームワークに出会うたび、過去の経験が役に立たない。累積的な学習ができない。技術も発展しない。だから、類推は人間の知能の基盤であり、思考の源泉だ。 これは疑いようがない。ここまで書いてきて、ふと気づいたことがある。私は今、類推について説明するために、言葉を使っている。では、言葉を使うとは、どういうことだろうか。目の前に、一冊の本がある。私はそれを見て、「本」と呼ぶ。でも、この「本」という言葉は、どこから来たのか。私がこれまでの人生で見てきた、無数の本。図書館で借りた本、書店で買った本、友人にもらった本。それらに共通する何かを抽出して、「本」というカテゴリを作った。目の前の物体を「本」と呼ぶとき、私はそれを、過去に見てきた本たちと「同じ仲間」だと判断している。これは、類推ではないか。「この物体は、私が知っている『本』に似ている。だから、これも『本』だ」。言葉を使うとは、目の前の具体的な現象を、過去に学んだカテゴリに当てはめることだ。当てはめるためには、類似性を見出さなければならない。つまり、言語化そのものが、類推なのだ。そう考えると、言葉の限界も見えてくる。目の前の本には、固有の特徴がある。紙の質感。インクの匂い。背表紙についた小さな傷。誰かが残した付箋。でも、「本」という言葉は、それらを捉えない。「本」という言葉が指すのは、無数の本に共通する抽象的な特徴だけだ。言葉にした瞬間、具体的な豊かさは零れ落ちる。だから、現状のすべてを完璧に表す言葉は、存在しない。 どんなに言葉を尽くしても、現実には追いつかない。言葉は常に近似だ。現実の一部を切り取っているだけだ。新しい経験をしたとき、私たちは「これは何だろう」と考える。既存の語彙の中から、「これに近い」言葉を探す。ぴったりの言葉が見つからなければ、複数の言葉を組み合わせる。それでも足りなければ、比喩を使う。「○○みたいなもの」と。でも、どれだけ工夫しても、言葉は現実を完全には捉えられない。類推は「AはBに似ている」という認識だ。言語化は「この現象は『X』という言葉に似ている」という認識だ。構造は同じだ。どちらも、目の前のものを、既知のものに当てはめる。そして、当てはめることで、何かを得る代わりに、何かを失う。私たちは、類推なしには思考できない。言葉なしには思考を伝えられない。でも、類推も言葉も、現実を完全には捉えられない。この記事を書いている今この瞬間も、私は類推と言葉の限界の中にいる。その限界を知りながら、それでも書くしかない。だからこそ、類推の限界を知ることが、これほど重要なのだ。しかし、だからこそ危険なのだ。類推はなぜ強力なのか類推の力を、もう少し詳しく見てみよう。抽象と具体の往復運動抽象的な概念は、そのままでは理解しにくい。人間の脳は、具体的なイメージを好む。抽象的な数学の公式より、具体的な例題の方が理解しやすい。抽象的な設計原則より、具体的なコード例の方が頭に入る。類推は、この抽象と具体を往復する運動だ。日常の例で説明しよう。カレーを作れる人は、シチューも作れる。なぜか。カレーとシチューは、表面的には違う料理だ。でも、「材料を切る → 炒める → 水を入れて煮る → ルーを溶かす」という構造は同じだ。カレーを作った経験から、この「構造」を抽出できれば、シチューに応用できる。これが抽象化であり、類推だ。プログラミングでも同じだ。具体的なもの（MySQL）を見て、抽象化（データを永続化するシステム）し、別の具体（PostgreSQL）に適用する。この往復が、類推の本質だ。ここで重要なのは、「抽象化」という能力だ。私の理解では、抽象化とは枝葉を切り捨てて幹を見ることだ。個別の事象から、本質的な構造だけを取り出す。MySQL、PostgreSQL、SQLiteはいずれも「SQLでデータを操作するシステム」という抽象に還元できる。Actix-web、Axum、Rocketはいずれも「HTTPリクエストを処理するRustのWebフレームワーク」という抽象に還元できる。この抽象化ができなければ、類推はできない。類推とは、2つの具体的な事象の間に共通の構造を見出すことだ。共通の構造を見出すには、まず具体から構造を抽出しなければならない。それが抽象化だ。私がこれまで見てきた限り、類推がうまい人は例外なく抽象化がうまい。 正しく抽象化できなければ、正しく類推できない。面白いことに、抽象の世界が見えている人には具体の世界も見える。でも、具体しか見えない人には抽象の世界が見えない。私はこれをマジックミラーのようなものだと思っている。抽象側からは両方見えるが、具体側からは向こう側が見えない。抽象を理解している人は、具体がその抽象の一例であることがわかる。「あ、これは○○の具体例だな」と。一方、具体しか見えない人は、それが何かの一例だとは気づかない。ただ、個別の事象として見るだけだ。だから、別の具体との共通点が見えない。多くの人は、この具体と抽象の往復運動を意識したことすらない。私自身、エンジニアになって何年も経ってから、やっと意識できるようになった。それまでは、類推を「なんとなく」やっていた。うまくいくこともあれば、失敗することもあった。でも、なぜ失敗するのかがわからなかった。抽象化を意識するようになってから、類推の成功率が上がった。「依存性の注入（DI）とは何か」。これはプログラムの設計手法の一つで、名前だけ聞くと難しそうに感じる。これを抽象的に説明すると、「オブジェクトが必要とする依存関係を外部から注入することで、結合度を下げてテスタビリティを高める設計パターン」となる。正確だが、初学者には意味不明だ。でも、「コンセントみたいなものだよ」と言えば、少し見えてくる。家電製品は、壁のコンセントに何が繋がっているか知らなくても動く。発電所が火力でも原子力でも太陽光でも、同じコンセントから電気が来る。DIも同じで、クラスは「何か」からデータベース接続を受け取るが、それが本番のMySQLなのかテスト用のモックなのかは知らなくていい。外部から「注入」される。類推によって、抽象が具体になる。見えなかったものが、見えるようになる。未知への橋渡し人間は、完全に未知のものを理解できない。新しい概念を学ぶとき、われわれは常に既知のものと関連づける。「これは、あれに似ている」。この関連づけがなければ、新しい知識は宙に浮いてしまう。既存の知識ネットワークに接続できない。類推は、未知と既知をつなぐ橋だ。Kubernetesを初めて学ぶとする。Kubernetesとは、たくさんのアプリケーションを複数のサーバーで効率よく動かすための管理システムだ。まったく新しい概念だ。でも、「Kubernetesは、コンテナのオーケストラ指揮者みたいなものだ。各コンテナ（アプリケーションを動かす小さな箱）がどこで動くべきか、いくつ動かすべきか、死んだら再起動すべきかを指示する」という類推があれば、入り口が見える。もちろん、この類推は不完全だ。Kubernetesの本質——宣言的な状態管理、コントロールループ、リコンシリエーション——を完全には捉えていない。でも、入り口にはなる。そこから、より正確な理解に進むことができる。類推は、足場だ。 建設現場の足場のように、本体を作るための仮の構造物だ。足場がなければ、高い建物は建てられない。類推がなければ、深い理解には到達できない。遠くから借りてくる力類推は、新しいアイデアを生む。異なる領域を結びつけることで、どちらの領域にも存在しなかった新しい視点が生まれる。ここで重要なのは、「どこから借りてくるか」だ。興味深いのは、同じ業界から持ってくるとパクりと言われるのに、違う業界からなら革命になることだ。なぜか。同じ業界の人は、同じものを見ている。だから、借りてきたことがすぐにバレる。でも、違う業界から借りてくると、誰も気づかない。そもそも、その業界を知らないからだ。他人が気づかないような遠くから借りてくる。そのために必要なのが、抽象化の力だ。遠い領域同士をつなげるには、それぞれの領域から本質的な構造を抽出しなければならない。表面的な違いを超えて、構造の類似を見抜く。これができる人だけが、革命を起こせる。生物の進化から、遺伝的アルゴリズムが生まれた。「自然選択と突然変異のプロセスを、最適化問題に適用したらどうだろう」。この類推が、新しい計算手法を生んだ。神経細胞のネットワークから、ニューラルネットワークが生まれた。「脳の情報処理を、コンピュータで模倣したらどうだろう」。この類推が、現在のAI革命の基盤を作った。私は、類推を創造の触媒だと思っている。異なる領域の知識を化学反応させて、新しいものを生む。遠くから借りてくるほど、その化学反応は激しくなる。近い領域から借りてくると、小さな改善にしかならない。遠い領域から借りてくると、パラダイムシフトが起きる。コミュニケーションの潤滑油類推は、相手にとって未知の概念を、既知の概念で説明することを可能にする。エンジニア同士でも、専門領域が違えば類推は有効だ。フロントエンドエンジニアにバックエンドの認証を説明するとき、JWT（JSON Web Token、ユーザーの認証情報を暗号化して持ち運ぶ仕組み）の説明をする機会がある。「JWTは、入場チケットみたいなものだよ」と言えば伝わる。一度発行されたら、チケット自体に情報が書いてある。だから毎回本部に問い合わせなくても、チケットを見せるだけで入れる。データベースのインデックス（データを高速に検索するための目次）を説明するときも同じだ。「本の索引みたいなものだよ。全ページをめくらなくても、索引を見れば目的の単語がどこにあるかすぐわかる」。チーム内でも類推は重要だ。リファクタリングとは、プログラムの動作を変えずに、コードの構造を整理・改善することだ。「このリファクタリングは、引っ越しみたいなものだ。荷物を新しい場所に移して、古い場所を片付ける。移行期間中は、両方にアクセスできるようにしておく」。こう言えば、作業のイメージが共有できる。類推は、異なる背景を持つ人々の間で、共通の理解を作る。類推はなぜ危険なのかここまで読むと、類推は素晴らしいものに思える。実際、素晴らしいのだ。でも、同時に危険でもある。なぜか。類推は「AとBは似ている」という前提に立っている。でも、この前提が正しいとは限らない。 似ているように見えて、実は違う。その違いが、致命的な判断ミスを生む。これは、ベストプラクティスが常に機能しないのと同じ構造だ。カンファレンスやブログで見たあの手法、あの技術、あの設計。「あの会社でうまくいったから、うちでもうまくいくはずだ」。こう考える。でも、これは類推だ。あの会社の文脈と、あなたの文脈は違う。あのチームと、あなたのチームは違う。ベストプラクティスが「ベスト」なのは、特定の文脈においてだけだ。 文脈が変われば、ベストではなくなる。デザインパターン（プログラム設計でよく使われる定番の解決策のカタログ）も同じだ。「このケースにはあのパターンが使える」と考える。でも、そのパターンが生まれた文脈と、今の文脈は違う。パターンを適用すれば解決するわけではない。パターンは出発点であって、答えではない。私が「何回説明しても伝わらない」と感じるとき、原因の多くは類推にある。類推は理解のショートカットとして強力だ。でも、相手と自分の「当たり前」が違うと、誤解を生む。なぜなら、類推は相手の頭の中にある既存の枠組みに接続するからだ。その枠組みが私と違えば、同じ言葉でも違う意味になる。冒頭の所有権の話を思い出してほしい。私は所有権を「本の貸し借りみたいなもの」と理解した。でも、「貸し借り」という言葉には、私が意識していなかった意味も含まれていた。「貸した相手との関係が続く」という意味だ。私は無意識にその意味も読み取っていた。だから、所有権を渡した後も「貸した先」を追跡できると思い込んでいた。類推が、私の思考を歪めていた。表面的類似と構造的類似の混同では、なぜ類推は失敗するのか。多くの場合、表面的な類似と構造的な類似を混同しているからだ。表面的な類似とは、見た目や印象の類似だ。「両方とも丸い」「両方とも赤い」「両方とも動く」。これは、誰でもすぐに気づく。構造的な類似とは、関係性のパターンの類似だ。「Aの中でXとYがこういう関係にあるのと同じように、Bの中でPとQもこういう関係にある」。これは、注意深く見ないと気づかない。類推が成立するためには、構造的な類似が必要だ。表面的な類似だけでは足りない。 問題は、人間が表面的な類似に騙されやすいことだ。見た目が似ていると、構造も似ていると思い込んでしまう。あるチームの話を聞いた。少し用語を説明しておこう。「モノリス」とは、1つの大きなプログラムとして構築されたシステムだ。「マイクロサービス」とは、機能ごとに小さなプログラムに分割し、それらを連携させるアーキテクチャだ。大企業が採用して成功したことで有名になった。そのチームは「マイクロサービスが成功しているから」という理由で、モノリスをマイクロサービスに分割しようとした。「あの有名企業がうまくいったんだから、うちもうまくいくはずだ」。表面的には似ている。「複雑なシステムを小さなサービスに分割する」という点で。しかし、構造は根本的に異なる。その有名企業には数千人のエンジニアがいる。専門のプラットフォームチームがいる。成熟した監視基盤がある。一方、そのチームは10人だった。運用の負荷が爆発的に増え、サービス間の通信障害のデバッグに追われ、結局モノリスに戻すことになった。彼らは、表面的な類似に騙されて、1年を失った。類推が思考を固定する類推には、もう1つ危険がある。思考を固定してしまうことだ。類推は、新しい視点を与える。「これはAみたいなものだ」と気づくと、Aの知識が使えるようになる。これは便利だ。でも同時に、Aの枠組みで考えるようになる。Aの論理で判断するようになる。Aで成立したことは、ここでも成立すると期待するようになる。ここに罠がある。BはAではない。Aにはない特性が、Bにはある。Bにはない特性が、Aにはある。類推によってAの枠組みを持ち込むと、Bの固有性が見えなくなる。Aとの共通点ばかりに目が行き、Aとの違いを見落とす。私はかつて、新しいチームのマネジメントで失敗した。前のチームで成功した方法を、そのまま適用しようとした。「前のチームと同じようにやればいい」と類推した。でも、チームが違えば、人が違う。カルチャーが違う。技術スタックが違う。ビジネスの文脈が違う。前のチームでうまくいった方法が、新しいチームでは逆効果だった。類推によって、私は新しいチームの固有性を見落としていた。「前のチームみたい」という枠組みが、目の前のチームを正確に見ることを妨げていた。これは、私だけの話ではない。世の中の「二番煎じ」は、すべてこの構造だ。表面的な成功パターンを真似る。でも、本質的な差異を見落としている。だから、同じ結果が得られない。独自性がないのではない。観察が浅いだけだ。類推が、観察を浅くしている。 成功事例を見て「うちも同じようにやろう」と考えるとき、私たちは無意識に類推している。でも、その類推が正しいかどうかを検証していない。表面的な類似に飛びついて、構造的な違いを無視している。類推は状況証拠であって物的証拠ではないここまでの話をまとめると、こうなる。類推は仮説であって、証明ではない。類推は、2つの領域の間に構造的な類似があるという仮定に基づいている。「AとBは似ているから、Aで成り立つことはBでも成り立つだろう」。これが類推の論理だ。でも、この仮定は、常に正しいとは限らない。似ているように見えて、実は違う。類推は状況証拠レベルであって、物的証拠レベルには至らない。ある領域で成功した法則が、別の領域でも通用する保証は、どこにもない。成功事例は、その文脈での成功を証明するだけだ。別の文脈での成功は、証明されていない。カンファレンスやブログで聞いた、あの会社の組織文化。あの会社でうまくいったからといって、すべての会社で同じ文化がうまくいくわけではない。あの有名な開発手法が成功したからといって、すべてのチームで同じ手法が成功するわけではない。成功事例から学ぶことは重要だ。でも、「あの会社みたいにやればいい」と単純に類推することは、危険だ。あの会社には、あの会社の文脈がある。業界。競合。人材市場。創業者の思想。歴史。規模。成長フェーズ。これらすべてが、あの文化を成立させている。あなたの会社には、あなたの会社の文脈がある。同じ文化を移植しても、機能するとは限らない。むしろ、害になることもある。より危険なのは、まったく新しい概念や技術を既存のものに無理やり当てはめることだ。ブロックチェーン（暗号技術を使って取引記録を改ざん困難な形で保存する技術）を「分散データベースみたいなもの」と類推すると、その本質的な違いを見落とす。信頼モデル（誰を信頼するか）、コンセンサスメカニズム（参加者間でどうやって合意を取るか）、イミュータビリティ（一度記録したら変更できないこと）——これらの特徴が、通常のデータベースとは根本的に異なる。結果的に間違った理解や過小評価につながる。類推を絶対視してはいけない。類推は仮説であって、証明ではない。類推がもたらす知的興奮ここまで、類推の危険性について書いてきた。でも、誤解しないでほしい。類推は危険だからといって、避けるべきものではない。類推には、代えがたい価値がある。類推は楽しい。類推は気持ちいい。 私は、類推が成功した瞬間の快感を、何度も味わってきた。まったく別のことに当てはまった時、頭の中で何かがつながる。あの瞬間——「あ、これって、あれと同じ構造だ」と気づく瞬間——には、独特の快感がある。世界の見え方がガラリと変わる。さっきまでバラバラだったものが、1つの構造で説明できるようになる。混沌が秩序になる。複雑が単純になる。なぜ、これが気持ちいいのか。人間は、わからないことに不安を感じる。新しい状況。未知の概念。複雑な問題。これらは、ストレスだ。脳は「これは何だ？」「どうすればいい？」と警戒モードに入る。でも、類推によって「あ、これは前に見たあれと同じだ」と気づくと、状況が一変する。未知が既知になる。複雑が単純になる。警戒モードが解除される。その瞬間、安堵とともに、快感が走る。これは、たぶん生存本能と関係している。予測できないものは危険だ。草むらで何かが動いた。あれは風か、それとも獲物か、それとも敵か。わからないと、逃げるべきか近づくべきか判断できない。でも、「あれは風だ」とわかれば、安心できる。予測できるものは安全だ。類推によって「これは、あれと同じだ」とわかると、予測ができるようになる。「あれ」のときはこうなった。だから、「これ」もそうなるだろう。予測ができると、安心する。安心は快感だ。しかも、類推は「遠くから借りてくる」ほど快感が大きい。 近い領域の類推——「MySQLはPostgreSQLに似ている」——は、驚きが少ない。当たり前だからだ。でも、遠い領域の類推——「ソフトウェアのリファクタリングは、文章の推敲と同じ構造だ」——は、発見の喜びが大きい。予想外のつながりだからだ。予想外であるほど、「わかった」瞬間のギャップが大きい。だから、快感も大きい。私がコードを書いていて、まったく関係ないはずの日常の出来事が当てはまることに気づいたとき。障害対応をしていて、これは以前経験した別の問題と同じ構造だと気づいたとき。設計を考えていて、過去に読んだ本の概念が使えると気づいたとき。そのたびに、ゾクっとする。「まさか、ここがつながるとは」という驚き。でも、よく考えると「なるほど、確かに同じだ」と納得できる。この驚きと納得の組み合わせが、最高に気持ちいい。類推の快感は、謎解きの快感に似ている。 バラバラだったピースが、カチッとはまる。見えなかった絵が、見えるようになる。あの瞬間の快感を知っている人は、類推をやめられない。日本では、この類推の喜びは昔から庶民の間で楽しまれていた。「○○と掛けて□□と解く。その心は△△である」という謎かけだ。まったく関係なさそうな2つのものが、ある抽象的な構造で結びつく。その発見の喜びが、笑いになる。漫才のツッコミも、類推と関係がある。ボケは、ある種の「間違った類推」だ。常識から逸脱したことを言う。ツッコミは、その逸脱を指摘する。「いや、それは違うやろ」と。ツッコミが面白いのは、観客が「そうそう、それはおかしいよね」と共感できるからだ。観客の頭の中にある「普通はこうだ」という枠組み——フレームと呼ぼう——に沿って、逸脱を指摘する。だから笑いが起きる。これは、類推の逆操作だ。類推が「AはBみたいなものだ」と結びつけるのに対して、ツッコミは「AはBではない」と切り離す。類推の破綻を、観客のフレームに沿って指摘する。ここで重要なのは、ツッコミが機能するためには、観客のフレームを理解していなければならないということだ。観客が「それはおかしい」と感じるポイントを、正確に捉えなければならない。これは、類推を使うすべての場面に通じる。私が所有権を「本の貸し借りみたいなもの」と理解したとき、私は「貸し借り」というフレームの中で考えていた。そのフレームの中では、貸し借りには「誰に貸したか」という追跡可能な関係が含まれていた。私は、そのフレームが当たり前だと思っていた。フレームの存在自体を意識していなかった。だから、フレームの限界が見えなかった。自分自身に対する「ツッコミ」——「いや、Rustの借用は、現実の貸し借りとは違うやろ」——ができなかった。自分がどんなフレームで類推しているかを意識しなければ、類推の限界が見えない。良い学習者は、類推を使うと同時に、自分自身でツッコミを入れる。「本の貸し借りみたいなものだけど、貸し借りと違って……」と。このツッコミができるかどうかが、類推で成功する人と失敗する人を分ける。創造性は異領域からの借用ソフトウェアエンジニアリングの歴史は、異なる領域からの借用の歴史でもある。Gitの分散型バージョン管理は、中央集権的なSVNの限界を、分散システムの発想で打破した。Git とは、プログラムの変更履歴を記録・管理するツールだ。SVNは「中央のサーバーにすべてを保存する」方式だったが、Gitは「全員が完全な履歴を持つ」方式を採用した。「すべてのリポジトリが対等なピアである」という考え方は、P2Pネットワークの構造と同じだ。Dockerのコンテナ技術は、仮想マシンの重さを、プロセス分離の軽さで置き換えた。Dockerとは、アプリケーションを「コンテナ」という小さな箱に詰めて、どこでも同じように動かせるツールだ。「OSレベルの仮想化ではなく、プロセスレベルの分離で十分ではないか」という発想が、コンテナ革命を起こした。MapReduceは、分散処理の複雑さを、関数型プログラミングの抽象で単純化した。これは大量のデータを複数のコンピュータで並列処理するための手法だ。「mapとreduceという2つの操作に分解すれば、並列処理が簡単になる」。この類推が、ビッグデータ処理の基盤を作った。類推は、新しい価値を生むための道具だ。既存の枠組みを超えるための、ジャンプ台だ。だから、類推を完全に否定できない。エンジニアリングにおける類推の両面性ここまで、類推の力と危険について見てきた。類推は強力だ。でも、危険でもある。では、エンジニアとして、類推をどう扱うべきか。答えは、場面によって使い分けることだ。 類推が有効な場面と、危険な場面がある。それを見極めることが重要だ。類推が有効な場面まず、類推が有効な場面を整理しよう。新しい技術を学ぶとき。 前に学んだ技術との類似点を見つけることで、学習が加速する。「Goのgoroutine（ゴルーチン）は、軽量なスレッドみたいなものか」。スレッドとは、プログラムの中で同時に動く処理の単位だ。goroutineはそれをより少ないメモリで実現する。この類推が、入り口になる。チームメンバーに説明するとき。 相手が知っている概念に置き換えることで、理解を助ける。「このアーキテクチャは、マイクロサービスというより、モジュラーモノリスに近いよ」。問題を発見するとき。 「これは前にやったあのプロジェクトに似ている」と気づくことで、早期に問題を予測できる。パターン認識だ。アイデアを発想するとき。 異なる領域の解決策を、目の前の問題に適用してみる。「他の業界ではどうやっているんだろう」。これらの場面では、類推は強力なツールだ。類推が危険な場面一方で、類推が危険な場面もある。共通点は、「判断」が伴う場面だ。設計判断を下すとき。 「あの有名な会社がこうやっているから」は、判断の根拠にならない。なぜか。あの会社にはあの会社の文脈がある。規模、チーム構成、ビジネス要件、技術的制約——すべてが違う。自分たちの文脈で、自分たちの制約を考慮して、判断しなければならない。パフォーマンス予測をするとき。 「前のプロジェクトではこのくらいのスループットだったから」は、予測の根拠にならない。ハードウェアが違う。データが違う。負荷パターンが違う。実測なしに類推で判断すると、本番環境で痛い目に遭う。チーム運営をするとき。 「前のチームではうまくいったから」は、根拠にならない。人が違う。状況が違う。目の前のチームを、目の前のチームとして見なければならない。ビジネス判断をするとき。 「あの会社がこうやって成功したから」は、根拠にならない。市場が違う。タイミングが違う。リソースが違う。「マイクロサービスが流行っているから、うちもマイクロサービスにしよう」。これも類推だ。でも、マイクロサービスが成功した会社と、あなたの会社は違う。チームの規模が違う。運用能力が違う。ビジネスの複雑さが違う。流行りのアーキテクチャは、流行っている理由があるが、あなたの問題を解決する保証はない。「TDD（テスト駆動開発：テストを先に書いてから本体コードを書く開発手法）がいいらしいから、TDDでやろう」。これも類推だ。TDDが有効だった文脈と、今の文脈は同じか。チームのスキルは。締め切りは。要件の安定度は。手法は、文脈とセットでしか評価できない。これらの場面では、類推に頼らず、具体を見なければならない。具体を見ろここまでの話から、私がたどり着いた結論はシンプルだ。類推は入り口として使う。でも、入ったら、具体を見る。どういうことか。「これはAみたいなものだ」と類推したら、まずはその類推で全体像を掴む。ここまでは類推の力だ。でも、判断を下す前に、次の問いを立てる。「Aとは何が違うんだろう」。違いを具体的に列挙する。その違いが、判断にどう影響するかを考える。つまり、抽象ではなく、具体を見る。パターンではなく、個別を見る。類似ではなく、差異を見る。これは、類推の否定ではない。類推の限界を知った上で、類推を使うということだ。類推は入り口として使い、判断は具体に基づいて行う。入り口と判断を、分離する。 これが、私の結論だ。類推を使い分ける技術「入り口と判断を分離する」と言った。では、具体的にどうすればいいのか。私が実践していることを、いくつか紹介する。類推のレベルを意識するまず、自分がどのレベルで類推しているかを意識することだ。類推には、レベルがある。表面的な類推：見た目や印象の類似。「両方とも丸い」「両方ともウェブサービスだ」。機能的な類推：役割や機能の類似。「両方ともユーザー認証する」「両方ともデータを永続化する」。構造的な類推：関係性のパターンの類似。「Aの中でXとYの関係が、Bの中でPとQの関係と同じだ」。原理的な類推：根底にある原理の類似。「両方とも、この物理法則に従う」「両方とも、この経済原理が働く」。レベルが深いほど、類推は有効だ。表面的な類推は危険だ。原理的な類推は強力だ。類推をするとき、自分がどのレベルで類推しているかを意識する。表面的な類推に気づいたら、警戒する。反例を積極的に探す類推が成立しない場面を、積極的に探す。「これはAみたいだ」と思ったら、「Aとは違う点は何か」を列挙する。「この類推が成立しない条件は何か」を考える。「Aでは成立したが、ここでは成立しないことは何か」を洗い出す。なぜ反例を探すのか。人間は、類推が成立する証拠ばかりを集める傾向がある。心理学では「確証バイアス」と呼ばれる現象だ。自分が信じたいことを裏付ける情報ばかりを無意識に集めてしまう。「似ている」と感じると、似ている点ばかり目につく。違う点は、無意識にスルーしてしまう。だから、意識的に反例を探さなければならない。反例は、自然には目に入ってこない。反例が見つかったら、類推の適用範囲を限定する。「この側面ではAに似ているが、この側面では違う」と認識する。反例を探すことは、類推を否定することではない。類推を精密にすることだ。どこまで使えて、どこから使えないのか。その境界線を引く作業だ。類推と実測を組み合わせる類推は仮説だ。仮説は検証しなければならない。私は何度も、類推を信じて痛い目を見てきた。「分かった」と思った瞬間が、一番危ない。類推は、分からないことを「分かったつもり」にさせてくれる。その確信が、検証を怠らせる。大切なのは、分かっていないことに確信を持たないことだ。類推で「たぶんこうだろう」と思っても、それは仮説でしかない。仮説に確信を持ってはいけない。確信を持った瞬間、検証しなくなる。検証しなければ、間違いに気づけない。だから、私は自分にこう言い聞かせている。類推したら、試せ。作ってみろ。動かしてみろ。「前のプロジェクトと同じくらいのパフォーマンスだろう」と類推したら、実測する。「このアーキテクチャパターンがうまくいくだろう」と類推したら、プロトタイプ（動作確認のための試作品）を作る。「このチーム運営方法が有効だろう」と類推したら、小さく試して観察する。試した結果、類推が外れることがある。むしろ、外れることの方が多い。でも、外れたときこそ、学びがある。なぜ外れたのか。どこが似ていて、どこが違ったのか。その差異を言語化できたとき、理解が一段深まる。私は、このサイクルを速く回すことを意識している。1回の大きな検証より、10回の小さな検証。外れることを恐れない。外れるたびに、類推が精密になっていく。類推は「似ている」という感覚に基づいている。でも、感覚は当てにならない。似ていると思っても、実際には違う。逆に、違うと思っても、実際には同じ。感覚を信じすぎると、現実を見誤る。実測は、感覚を現実に引き戻す。「本当にそうなのか？」を確認する。類推で仮説を立てて、実測で検証する。 類推は仮説生成の道具であって、証明の道具ではない。複数の類推を比較する1つの類推に固執しない。複数の類推を試す。「これはAみたいだ」と思ったら、「でも、Bみたいでもあるな」と考える。「Cという見方もできるな」と広げる。なぜ複数の類推を試すのか。最初に思いついた類推が、最適とは限らない。むしろ、最初の類推は表面的なことが多い。パッと見て似ているから、思いつく。でも、もう少し考えると、別の類推の方が本質を捉えていることがある。1つの類推に決め打ちすると、その視点でしか見えなくなる。複数の類推を並べると、それぞれの限界が見えてくる。そして、どの類推が最も適切かを吟味する。どの類推が、最も多くの側面を説明できるか。どの類推が、最も少ない反例を持つか。どの類推が、最も有用な洞察を与えるか。複数の類推を比較することで、1つの類推に囚われることを防ぐ。類推を言語化する類推を曖昧なまま使わない。明示的に言語化する。「これはAみたいだ」と思ったら、何がどうAに似ているのか、具体的に言葉にする。「Aのこの側面と、ここのこの側面が、この点で類似している」と。なぜ言語化が重要なのか。頭の中にある類推は、たいてい曖昧だ。「なんとなく似ている」という感覚で止まっている。でも、言葉にしようとすると、曖昧さが露呈する。「どこが似ているの？」と聞かれて、答えられない。言語化は、自分の思考を試すテストだ。 言葉にできないなら、実はわかっていない。言葉にできて初めて、本当に理解したと言える。言語化することで、類推が精密になる。曖昧な類推は、誤解を生む。精密な類推は、理解を深める。そして、言語化した類推を、他者に共有する。「私はこう類推しているが、どうだろうか」と問う。他者の視点で、類推の妥当性を検証する。類推力を鍛えるここまで、類推の力と限界について語ってきた。では、類推力を高めるには、どうすればいいのか。私が意識していることを3つ挙げる。1つ目は、遠い領域から引き出しを増やすことだ。私は、咀嚼しやすいものばかり読まないようにしている。数学や哲学、物語やSFなどの自分の仕事や語ることとは遠い世界のストーリーを読んで、自分の経験と照らし合わせる。実生活では役に立たないように見える抽象的な知識こそ、遠くから借りてくる力になる。なぜ遠い領域が大事なのか。近い領域の知識は、みんなが持っている。だから、そこから類推しても、みんなと同じ結論にしかたどり着かない。遠い領域の知識は、自分だけの武器になる。他の人が思いつかない類推ができる。2つ目は、常に「これは何かに使えないか」と考えることだ。映画を見ても、歴史を学んでも、スポーツを観戦しても、「これは自分の仕事にどう活かせるか」と考える。「関係ない」と決めつけず、「何か応用できないか」という視点で世界を見る。これを続けていると、頭の中に「類推のアンテナ」が立つ。普段の生活の中で、ふと「あ、これって、あれと同じだ」と気づくようになる。その瞬間が、類推力が育っている証拠だ。3つ目は、構造を2〜3つに絞って抽象化することだ。私の経験では、特徴や要点を2〜3つ挙げて、同じ構造を持つ事象を探すとうまくいく。1つだと何でも結びつけられてしまう。「両方とも存在する」では、類推にならない。4つ以上だと類推先が近くなりすぎて面白味がない。条件が厳しすぎて、同じ業界の似たようなものしか見つからない。2〜3つが、ちょうどいい。適度に絞られていて、適度に広い。この訓練を続けると、世界の見え方が変わる。一見無関係に見えるものの中に、共通の構造が見えてくる。私は、この感覚を得てから、仕事がずっと面白くなった。ニュースを読んでも、本を読んでも、人と話しても、「これは何かに使えるだろう」と思う。世界が、類推のネタの宝庫に見えてくる。類推を断つ勇気ここまで、類推を使い分ける技術について書いてきた。でも、もっと根本的なことがある。それは、類推を断つ勇気だ。一度つなげた類推を、必要なら断たなければならない。でも、これが難しい。なぜ難しいのか。類推は、理解の構造だ。「これはAみたいなものだ」という認識は、思考の足場になっている。その足場の上に、さらに理解を積み重ねている。足場を外すことは、その上に積み重ねたものも崩れることを意味する。一度「わかった」と思ったものを、「わからない」に戻すのは、心理的に辛い。人間は「わかった」状態を好む。「わからない」状態は不安だ。だから、間違った類推でも、手放したくない。間違っていると薄々気づいていても、「まあ、だいたい合っているだろう」と自分を納得させてしまう。認めたくない。また、類推は、コミュニケーションの基盤にもなる。チームで「これはAみたいなもの」と共有されていると、それを覆すことは、混乱を生む。「え、今までの説明は何だったの？」と言われる。自分の言ったことを訂正するのは、恥ずかしい。間違いを認めるのは、プライドが傷つく。だから、間違っているとわかっても、言い出せない。みんなが使っている類推に異を唱えるのは、勇気がいる。でも、間違った類推に固執し続けることの方が、はるかに有害だ。 間違った類推は、間違った判断を生む。間違った判断は、間違った設計を生む。間違った設計は、技術的負債を生む。技術的負債とは、急いで作った不完全なコードが後から修正コストとして跳ね返ってくることだ。借金のように、放置すればするほど利子が膨らんでいく。技術的負債は、チームを疲弊させる。最初の一歩で間違えると、その後のすべてがズレていく。早く気づいて修正するほど、傷は浅い。だから、類推が間違っていると気づいたら、勇気を持って断つ。「前にAみたいだと言ったけど、よく見たら違った。Bで考え直そう」と言う。これは、弱さではない。強さだ。現実を直視する強さだ。おわりに冒頭の話に戻ろう。私は、Rustの所有権を「本の貸し借りみたいなもの」と理解した。その類推で入り口は開けた。でも、その類推に縛られて、ライフタイムの本質を見誤った。非同期処理を料理に例えて、リソース競合を甘く見た。トランザクションを銀行振込に例えて、ロールバックの複雑さに気づかなかった。キャッシュを「手元に置く」と理解して、無効化の難しさを軽視した。私は、何度も同じ失敗を繰り返してきた。正直に言えば、私は今でも類推を使う。毎日のように使う。「これって、あれみたいだな」と考える癖は、もはや私の一部だ。類推なしに思考することなど、私にはできない。たぶん、誰にもできない。でも、これらの経験を経て、私は類推の使い方を変えた。類推は入り口として使う。入ったら、具体を見る。 「本の貸し借りみたいなもの」で入ったら、次に「でも、貸し借りと違って、所有権を渡したら元の変数からは完全にアクセスできなくなる。貸した相手を追跡する仕組みはない」と自分に言い聞かせる。類推と差異を、セットで意識する。そして、類推が成り立たない場面に出会ったら、類推を修正する勇気を持つ。類推は、人間の知能の基盤だ。われわれは類推なしには思考できない。だから、類推を否定するつもりはない。否定できるはずもない。でも、類推の限界を知らなければならない。類推は万能ではない。類推は常に成立するとは限らない。表面的な類推は、本質的な差異を見落とす。類推で入って、具体で判断する。類推は仮説であって、証明ではない。類推を絶対視せず、反例を探し、実測で検証する。そして、間違った類推は、勇気を持って断つ。これが、エンジニアとしての類推の使い方だ。「それって、○○みたいなものですよね」。この言葉を使うとき、私は今、一瞬立ち止まる。「本当にそうか？」と自問する。表面的な類似に惑わされていないか。本質的な差異を見落としていないか。先日、後輩にRustの所有権を説明する機会があった。私は「本の貸し借りみたいなものなんだけど」と言った後、こう続けた。「ただし、本と違って、Rustでは貸した先を追跡する仕組みはない。完全に手放すか、借用するかの二択なんだ」。あの頃の自分には、この補足ができなかった。類推は強力だ。だからこそ、慎重に扱わなければならない。おい、類推するな。いや、違う。類推しろ。でも、類推を疑え。類推で入って、具体で確かめろ。そして、間違っていたら、断つ勇気を持て。それが、類推に救われ、類推に何度も裏切られ、それでも類推を愛する人間からの、静かな呼びかけだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍The Rust Programming Language, 3rd Edition (English Edition)作者:Klabnik, Steve,Nichols, Carol,Krycho, ChrisNo Starch PressAmazonプログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F.S. TindallオライリージャパンAmazonバックエンドエンジニアを目指す人のためのRust作者:安東 一慈,大西 諒,徳永 裕介,中村 謙弘,山中 雄大翔泳社Amazon類似と思考　改訂版 (ちくま学芸文庫)作者:鈴木宏昭筑摩書房Amazonアナロジー思考作者:細谷 功東洋経済新報社Amazon問題解決力を高める「推論」の技術作者:羽田康祐k_birdフォレスト出版Amazon新装版　アブダクション: 仮説と発見の論理作者:米盛 裕二勁草書房Amazon作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustでOWASP API Security Top 10を体験する（後編）：リソース制御と攻撃検知]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/06/055637</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/06/055637</guid>
            <pubDate>Fri, 05 Dec 2025 20:56:37 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、Rust Advent Calendar 2025 6日目のエントリ記事です。はじめに前編からの続き ← API1 (BOLA), API2 (Broken Authentication), API3 (Mass Assignment)の解説はこちら前編では認証・認可の基礎とデータ保護について解説した。後編では、リソース消費制御、機能レベルの認可、そしてサーバーサイド攻撃について体験していく。API4: Rate Limit - 総当たり攻撃対策パスワードクラッキング（パスワードを片っ端から試して突破する攻撃）の現実を体験できるデモ。owasp.orgなぜレート制限が重要なのかレート制限とは、「一定時間内に受け付けるリクエスト数を制限する」仕組みだ。レート制限がないAPIは「無限に試行できる」ことを意味する。 攻撃手法  被害  レート制限での防御  パスワード総当たり  アカウント乗っ取り  試行回数制限  クレデンシャルスタッフィング  流出パスワードでの不正ログイン  IPベースのブロック  OTPブルートフォース  2段階認証（SMS認証など）のバイパス  アカウントロック  APIの過剰呼び出し  サービス停止（DoS）  グローバルレート制限  スクレイピング  データの大量取得  リクエスト間隔の強制 パスワードクラッキングの数学4桁のPINコードを総当たりする時は以下のようになる。組み合わせ: 104 = 10,000通り毎秒10回の試行 → 約17分で全組み合わせを試行レート制限なし → 毎秒1000回で10秒8文字のパスワード（小文字+数字）の時は以下のようになる。組み合わせ: 368 ≒ 2.8兆通り毎秒1000回でも約89年かかるでも、辞書攻撃なら数万語 → 数分で完了レート制限は「総当たりを現実的に不可能にする」ための防御だ。cargo run --release --bin rate-limit-demoでは、実際にどうやってレート制限を実装するのか。単純に「1分間に10回まで」と制限すればいいように思えるが、攻撃者はそう甘くない。IPアドレスを変えながら攻撃したり、複数のアカウントを同時に狙ったりする。だから、防御も複数の観点から行う必要がある。二層の防御：IP追跡とアカウント追跡/// Tracks login attempts per IP address#[derive(Debug, Clone)]struct LoginAttemptTracker {    /// IP -> (attempt_count, first_attempt_time)    ip_attempts: Arc<RwLock<HashMap<String, (u32, Instant)>>>,    /// Email -> (attempt_count, first_attempt_time)    account_attempts: Arc<RwLock<HashMap<String, (u32, Instant)>>>,    /// Blocked IPs    blocked_ips: Arc<RwLock<Vec<String>>>,    /// Locked accounts    locked_accounts: Arc<RwLock<Vec<String>>>,}なぜ二層必要なのか。IP追跡のみだと、攻撃者がVPNやTorでIP変えながら攻撃できるアカウント追跡のみだと、1つのIPから多数のアカウントを攻撃できる両方で、どちらのパターンも防げるスライディングウィンドウの実装fn record_attempt(&self, ip: &str, email: &str) -> (u32, u32) {    let window = Duration::from_secs(300); // 5分間のウィンドウ    let now = Instant::now();    // Track IP attempts    let ip_count = {        let mut attempts = self.ip_attempts.write().unwrap();        let entry = attempts.entry(ip.to_string()).or_insert((0, now));        if now.duration_since(entry.1) > window {            // 5分経過したらリセット            *entry = (1, now);        } else {            entry.0 += 1;        }        entry.0    };    // Block IP after 10 attempts    if ip_count >= 10 {        let mut blocked = self.blocked_ips.write().unwrap();        if !blocked.contains(&ip.to_string()) {            blocked.push(ip.to_string());            tracing::warn!(ip = ip, "IP blocked due to too many attempts");        }    }    // Lock account after 5 attempts    if account_count >= 5 {        // ...    }    (ip_count, account_count)}governorクレートによるグローバルレート制限// Global rate limiter: 10 requests per secondlet rate_limiter = Arc::new(RateLimiter::direct(Quota::per_second(    NonZeroU32::new(10).unwrap(),)));governorはトークンバケットアルゴリズムを実装している。これは「バケツに水が溜まっていく」イメージだ。バケットに毎秒10トークン補充され、リクエストごとに1トークン消費。バケットが空になったら429（Too Many Requests）を返す。脆弱 vs 安全/// VULNERABLE: Login endpoint without rate limitingasync fn vulnerable_login(Json(req): Json<LoginRequest>) -> Result<Json<LoginResponse>, AppError> {    // 何回でも試行可能！    if req.email == "user@example.com" && req.password == "password123" {        Ok(Json(LoginResponse { /* ... */ }))    } else {        Err(AppError::Unauthorized)    }}/// SECURE: Login endpoint with rate limiting and lockoutasync fn secure_login(    State(state): State<AppState>,    ConnectInfo(addr): ConnectInfo<SocketAddr>,    Json(req): Json<LoginRequest>,) -> Result<Json<LoginResponse>, (StatusCode, Json<RateLimitError>)> {    let ip = addr.ip().to_string();    // 1. グローバルレート制限    if state.rate_limiter.check().is_err() {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 2. IPブロック確認    if state.tracker.is_ip_blocked(&ip) {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 3. アカウントロック確認    if state.tracker.is_account_locked(&req.email) {        return Err((StatusCode::TOO_MANY_REQUESTS, /* ... */));    }    // 4. 認証処理    if req.email == "user@example.com" && req.password == "password123" {        state.tracker.reset_on_success(&ip, &req.email); // 成功したらカウンターリセット        Ok(Json(LoginResponse { /* ... */ }))    } else {        state.tracker.record_attempt(&ip, &req.email); // 失敗を記録        Err((StatusCode::UNAUTHORIZED, /* ... */))    }}微妙な脆弱性：レート制限のバイパス手法「レート制限を実装したから安全」と思っていないだろうか。残念ながら、レート制限にもバイパス手法がたくさんある。微妙な脆弱性 #1: X-Forwarded-Forを信用する/// 開発者の意図: 「ロードバランサーの後ろにいるから、X-Forwarded-Forを使わないと」/// 現実: 攻撃者もX-Forwarded-Forを設定できるasync fn subtle_xff_bypass(headers: HeaderMap, ...) -> Result<...> {    // BUG: X-Forwarded-Forを無条件に信用    let ip = headers        .get("X-Forwarded-For")        .and_then(|v| v.to_str().ok())        .and_then(|s| s.split(',').next())        .map(|s| s.trim().to_string())        .unwrap_or_else(|| addr.ip().to_string());    // 攻撃: curl -H "X-Forwarded-For: 1.2.3.4" ...    //       curl -H "X-Forwarded-For: 5.6.7.8" ...    // 毎回違うIPとしてカウントされる！    if state.tracker.is_ip_blocked(&ip) { /* ... */ }}X-Forwarded-Forは信頼できるプロキシ（ロードバランサーやCDNなど、自分たちが管理しているサーバー）からのみ受け入れるべきだ。信頼チェーンを確立せずにXFFを使うと、攻撃者がIPを自由に偽装できる。微妙な脆弱性 #2: 大文字小文字の不一致/// 開発者の意図: 「メールアドレスでアカウントロックを追跡」/// 現実: 大文字小文字で別アカウント扱いasync fn subtle_case_sensitivity(...) -> Result<...> {    // BUG: アカウントロックは大文字小文字を区別    if state.tracker.is_account_locked(&req.email) {        return Err(...);    }    // でも認証は大文字小文字を無視    let email_lower = req.email.to_lowercase();    if email_lower == "user@example.com" && req.password == "password123" {        // ...    }    // 攻撃:    // user@example.com で5回失敗 → ロック    // User@example.com で5回失敗 → 別カウント！    // USER@example.com で5回失敗 → また別カウント！    // 結果: 15回試行できる}アカウント識別子の正規化を一貫して行わないと、レート制限を回避される。微妙な脆弱性 #3: タイミングリーク/// 開発者の意図: 「ロックされたアカウントは早期リターン」/// 現実: レスポンス時間でアカウントの存在がわかるasync fn subtle_timing_leak(...) -> Result<...> {    // ロック済みアカウントは即座に拒否（速い！）    if state.tracker.is_account_locked(&req.email) {        return Err(/* 数マイクロ秒 */);    }    // パスワードハッシュ検証（遅い！）    tokio::time::sleep(Duration::from_millis(100)).await;    // 存在するアカウントは追加処理（もっと遅い！）    if account_exists(&req.email) {        tokio::time::sleep(Duration::from_millis(50)).await;    }    // 攻撃: レスポンス時間を測定    // 即座に返る → ロック済み（= 存在するアカウント）    // 100ms → 存在しないアカウント    // 150ms → 存在するが間違ったパスワード}レスポンス時間を均一にしないと、アカウント列挙攻撃に使われる。微妙な脆弱性 #4: TOCTOU競合/// 開発者の意図: 「カウンターを確認してから処理」/// 現実: 確認と更新の間に別のリクエストが入るasync fn subtle_race_condition(...) -> Result<...> {    // Step 1: カウンター読み取り（ロック解放）    let current_count = {        let attempts = state.tracker.ip_attempts.read().unwrap();        attempts.get(&ip).map(|(count, _)| *count).unwrap_or(0)    }; // ← ここでロック解放    // この間に並行リクエストが！    tokio::time::sleep(Duration::from_millis(10)).await;    // Step 2: 制限チェック（古い値で判断）    if current_count >= 10 {        return Err(...);    }    // Step 3: 処理後にカウンター更新    state.tracker.record_attempt(&ip, &req.email);    // 攻撃: 100並行リクエストを同時送信    // 全員が current_count = 0 で通過！}チェックと更新はアトミックに行うべき。RwLockではなくアトミック操作や、チェックと更新を1つのロック内で行う必要がある。API5: BFLA - 一般ユーザーが管理者になれてしまう問題前編でBOLA（Broken Object Level Authorization）を解説した。BOLAは「他人のデータにアクセスできてしまう」問題だった。では、「他人のデータ」ではなく「使えないはずの機能」にアクセスできてしまったら？それがBFLA（Broken Function Level Authorization）だ。owasp.orgBOLAが「他人のデータを見られる」なら、BFLAは「使えないはずの機能が使える」。例えば、一般ユーザーが管理者用のユーザー一覧APIを叩けてしまうケース。言ってみれば「平社員が社長の権限でシステムを操作できる」状態だ。BOLAとBFLAの違いを理解するこの2つは混同しやすいので、明確に区別しよう。 項目  BOLA  BFLA  何が壊れているか  オブジェクト（データ）へのアクセス制御  機能（エンドポイント）へのアクセス制御  攻撃例  BobがAliceの注文を見る  一般ユーザーが管理者APIを叩く  チェック対象  「このデータは誰のものか」  「この機能は誰が使えるか」  典型的な対策  リソースごとの所有者チェック  ロール/権限チェック 例えで言えばこうだ。BOLA = 他人のロッカーを開けられる（同じ権限レベル内での越境）BFLA = 社員証がないのに役員室に入れる（権限レベルの越境）この違いを理解すると、なぜBFLAが発生しやすいのかも見えてくる。なぜBFLAが発生するのかエンドポイントの「発見」 - /api/usersがあるなら/api/admin/usersもあるだろうと攻撃者は考えるフロントエンドによる隠蔽への過信 - 「管理メニューは管理者にしか見せてないから大丈夫」→ APIは直接叩ける認証と認可の混同（再び） - 「ログインしてるから管理APIも使えるはず」という誤った思い込みテスト不足 - 管理者機能は管理者アカウントでしかテストしないドキュメント化されていない管理API - 「隠しAPI」は攻撃者に見つかる実際の被害パターンBFLAによって可能になる攻撃を挙げる。ユーザー情報の一括取得 - 全ユーザーのメールアドレス、個人情報を抜き取る権限昇格 - 自分のアカウントに管理者権限を付与するシステム設定の変更 - APIキーの再生成、課金設定の変更データの一括削除 - 管理者用の一括削除機能を悪用監査ログの改ざん - 証拠隠滅のためにログを消去では、脆弱なコードと安全なコードを見比べてみよう。/// VULNERABLE: No role checkasync fn vulnerable_list_users(user: AuthenticatedUser) -> Result<Json<Vec<UserInfo>>, AppError> {    Ok(Json(vec![        UserInfo {            id: 1,            email: "admin@example.com".to_string(),            role: "admin".to_string(),            ssn: "123-45-6789".to_string(), // SSNまで露出        },        // ...    ]))}/// SECURE: Admin checkasync fn secure_list_users(user: AuthenticatedUser) -> Result<Json<Vec<SafeUserInfo>>, AppError> {    if !is_admin(&user.0) {        return Err(AppError::Forbidden("Admin permission required".to_string()));    }    // ...}is_adminのチェックは単純だ。pub fn is_admin(claims: &UserClaims) -> bool {    claims.permissions.iter().any(|p| p == "admin")}「これくらい誰でも書く」と考えるだろう。しかし、本番環境で「認証は通ってるから大丈夫」と言ってこのチェックを忘れる人が後を絶たない。微妙な脆弱性：一見正しく見えるBFLAのバグ「is_adminチェックさえ入れれば安全」と思っていないだろうか。残念ながら、そう単純ではない。微妙な脆弱性 #1: HTTPヘッダーを信用する/// 開発者の意図: 「フロントエンドが送るX-User-Roleヘッダーを信用しよう」/// 現実: curlでいくらでも偽装できるasync fn subtle_header_role_check(    user: AuthenticatedUser,    headers: HeaderMap,) -> Result<Json<AdminResponse>, AppError> {    // BUG: HTTPヘッダーを信用している！    let role = headers        .get("X-User-Role")        .and_then(|v| v.to_str().ok())        .unwrap_or("user");    if role != "admin" {        return Err(AppError::Forbidden("Admin role required".to_string()));    }    // 攻撃: curl -H "X-User-Role: admin" ...    Ok(Json(admin_data))}フロントエンドから「便利だから」とヘッダーでロール情報を送る設計を見たことがある。これはアウトだ。HTTPヘッダーはクライアントが自由に設定できる。JWTのペイロードのように署名で保護されていない限り、信用してはいけない。微妙な脆弱性 #2: JWTクレームをDBと照合しない/// 開発者の意図: 「JWTに権限が入っているから、それを使えばOK」/// 現実: トークン発行後にユーザーが降格されたら？async fn subtle_client_claims_check(    user: AuthenticatedUser,) -> Result<Json<AdminResponse>, AppError> {    // これ、一見正しそう    let has_admin = user.0.permissions.iter().any(|p| p == "admin");    if !has_admin {        return Err(AppError::Forbidden("Admin permission required".to_string()));    }    // 問題: ユーザーが管理者だったのは「トークン発行時」の話    // トークン発行後に降格されていても、トークンが有効な限りアクセスできてしまう    Ok(Json(admin_data))}JWT（JSON Web Token）は便利だが、「トークン発行時点のスナップショット」に過ぎない。JWTとは、ユーザー情報や権限を暗号化して埋め込んだトークンで、サーバーはDBを参照せずに認証できる。しかし、ユーザーの権限が変更されたら、古いトークンは無効にするか、DBで再確認する必要がある。微妙な脆弱性 #3: 大文字小文字の罠/// 開発者の意図: 「adminをチェックすれば安全」/// 現実: 「Admin」「ADMIN」「aDmIn」は？let has_admin = user.0.permissions.iter().any(|p| p == "admin");これ自体は問題ないが、トークン生成側で大文字小文字の統一が取れていないと問題になる。ある箇所では"admin"、別の箇所では"Admin"で権限が付与されていたら、チェックをすり抜けてしまう。// 安全な実装: 大文字小文字を無視let has_admin = user.0.permissions.iter()    .any(|p| p.eq_ignore_ascii_case("admin"));微妙な脆弱性 #4: キャッシュされた権限チェック/// 開発者の意図: 「ミドルウェアで権限チェック済みだから、エンドポイントでは確認不要」/// 現実: そのキャッシュ、どこから来た？async fn subtle_cached_permission_check(    user: AuthenticatedUser,    Query(query): Query<CachedCheckQuery>,) -> Result<Json<AdminResponse>, AppError> {    // BUG: クエリパラメータから「チェック済み」フラグを読んでいる！    let is_verified_admin = query.permission_verified.unwrap_or(false);    if is_verified_admin {        // 攻撃: ?permission_verified=true        return Ok(Json(admin_data));    }    // 本来のチェック    if !is_admin(&user.0) {        return Err(AppError::Forbidden("Admin permission required".to_string()));    }    Ok(Json(admin_data))}「ミドルウェアでチェック済み」というフラグをリクエストに含めるパターンは意外とある。でもそのフラグがクエリパラメータやヘッダーから来ていたら、攻撃者が自由に設定できる。API7: SSRF - サーバーを踏み台にするSSRF（Server-Side Request Forgery）は、サーバーに「代わりにリクエストを送らせる」攻撃だ。普通、攻撃者は外部から内部ネットワークにアクセスできない。でも、サーバーは内部ネットワークにアクセスできる。だから、サーバーを「踏み台」にして、内部ネットワークに攻撃を仕掛けるのがSSRFだ。owasp.orgたとえるなら、「社員に偽の指示書を渡して、機密書類を持ってこさせる」ようなものだ。社員（サーバー）は指示書が正当なものだと思い込んで、機密エリアにアクセスしてしまう。SSRFの危険性を理解するSSRFが特に危険な理由を説明する。ファイアウォールをバイパス - 外部からは遮断されていても、内部からのリクエストは通るクラウドメタデータにアクセス - AWS/GCPの169.254.169.254（クラウド環境で自動的に提供される情報サービス）から認証情報を取得可能内部サービスの探索 - ポートスキャンや内部APIの発見に悪用認証のバイパス - 「内部ネットワークからのアクセスは信頼」という設計を悪用特に2番目の「クラウドメタデータへのアクセス」は、現代のクラウド環境では致命的な被害につながる。なぜなら、メタデータサービスには一時的な認証情報が含まれているからだ。クラウド環境での致命的な被害クラウド環境でのSSRFは特に危険だ。2019年のCapital One事件では、SSRFを使ってAWSのメタデータサービスにアクセスし、1億人以上の顧客データが漏洩した。攻撃の流れを見てみよう。1. 攻撃者: http://169.254.169.254/latest/meta-data/iam/security-credentials/ にアクセスさせる2. サーバー: 内部からのリクエストなので通常通り処理3. AWSメタデータ: IAMロールの一時認証情報を返す4. 攻撃者: その認証情報でS3バケットにアクセス → 大量のデータを取得SSRFが発生しやすい機能この事件を見て「うちはそんな機能ないから大丈夫」と思うだろう。しかし、SSRFが発生する機能は意外と身近にある。以下のような機能はSSRFの温床になりやすい。URLプレビュー/OGP取得 - 「このURLのタイトルと画像を表示」Webhook送信 - 「指定されたURLにPOSTリクエストを送る」PDF生成 - 「このURLの内容をPDFにする」（ヘッドレスブラウザがURLを開く）画像のリサイズ/変換 - 「このURLの画像をサムネイルにする」インポート機能 - 「このURLからデータをインポート」どれも「ユーザーが指定したURLにアクセスする」という共通点がある。この「ユーザーが指定したURL」が問題だ。例えば、「URLを指定したらそのページの内容を取得する」機能があったとする。/// VULNERABLE: Fetches any URLasync fn vulnerable_fetch(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}攻撃者は内部ネットワークのURLを指定する。curl -X POST http://localhost:8080/vulnerable/fetch \     -d '{"url":"http://localhost:8080/internal/secrets"}'/internal/secrets は本来、外部からアクセスできない内部APIだ。しかし、サーバー自身が「localhost」にアクセスするのは許可されている。結果、攻撃者はサーバーを経由して機密情報を引き出す。サーバーは「言われたことを忠実に実行する」だけだ。それが悪意あるリクエストだとは気づかない。対策: 許可リストとプロトコル制限では、どうやってSSRFを防ぐのか。基本的な考え方は「信頼できるURLだけを許可する」ことだ。async fn secure_fetch(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let url = Url::parse(&req.url)        .map_err(|_| AppError::BadRequest("Invalid URL".to_string()))?;    // HTTPSのみ許可    if url.scheme() != "https" {        return Err(AppError::BadRequest("Only HTTPS URLs are allowed".to_string()));    }    // 許可されたドメインのみ    let allowed_domains = ["api.example.com", "cdn.example.com"];    let host = url.host_str()        .ok_or_else(|| AppError::BadRequest("Invalid host".to_string()))?;    if !allowed_domains.contains(&host) {        return Err(AppError::BadRequest("Domain not in allowlist".to_string()));    }    // 許可リストを通過したURLのみ処理    // ...}「なんでも取ってくる」から「許可されたものだけ取ってくる」へ。自由度は下がるが、セキュリティは上がる。微妙な脆弱性：SSRFの巧妙なバイパス手法「許可リストでドメインをチェックしているから安全」と思っていないだろうか。残念ながら、SSRFは想像以上に狡猾だ。攻撃者は、許可されたドメインを経由して、内部ネットワークにアクセスする方法を探す。微妙な脆弱性 #1: リダイレクトを追跡してしまう/// 開発者の意図: 「最初のURLを検証すればOK」/// 現実: リダイレクト先は検証されていないasync fn subtle_redirect_ssrf(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let parsed_url = Url::parse(&req.url)?;    // 最初のURLは検証する    if !ALLOWED_DOMAINS.contains(&parsed_url.host_str().unwrap()) {        return Err(AppError::BadRequest("Domain not allowed".to_string()));    }    // BUG: リダイレクトを10回まで追跡する    let client = reqwest::Client::builder()        .redirect(reqwest::redirect::Policy::limited(10))        .build()?;    // 攻撃:    // 1. パートナーサイト webhook.partner.com を許可リストに追加    // 2. パートナーが webhook.partner.com/redirect?to=http://localhost/internal を設定    // 3. 最初は検証を通過、リダイレクトで内部サーバーにアクセス    let response = client.get(&req.url).send().await?;    Ok(response.text().await?)}パートナーサイトやCDNを許可リストに入れていて、そこにオープンリダイレクト（任意のURLにリダイレクトできる機能）があったら終わり。リダイレクト先も検証するか、リダイレクトを無効にするべきだ。微妙な脆弱性 #2: DNSリバインディング/// 開発者の意図: 「DNSで解決されたIPをチェックすれば内部アクセスを防げる」/// 現実: DNSの応答は変わりうるasync fn subtle_dns_rebinding(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    let host = Url::parse(&req.url)?.host_str().unwrap().to_string();    // 最初のDNS解決（ここでは外部IP）    let ips = tokio::net::lookup_host(format!("{}:80", host)).await?;    for ip in ips {        if ip.ip().to_string().starts_with("127.") {            return Err(AppError::BadRequest("Internal IP blocked".to_string()));        }    }    // BUG: 実際のリクエスト時には別のDNS解決が行われる可能性    // 攻撃者のDNSサーバー:    // 1回目のクエリ → 1.2.3.4（外部IP、チェック通過）    // 2回目のクエリ → 127.0.0.1（内部IP！）    tokio::time::sleep(Duration::from_millis(100)).await;  // この間にDNSが変わる    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}DNSリバインディング攻撃は、DNSの応答を時間差で変えることで検証をすり抜ける。DNSとは、ドメイン名（例：example.com）をIPアドレス（例：93.184.216.34）に変換する仕組みだ。攻撃者は自分のDNSサーバーを用意し、最初は外部IPを返し、2回目のクエリでは内部IP（127.0.0.1）を返すようにする。対策は「解決したIPを直接使う」か「DNSピンニング」（一度解決したIPを再利用する）を実装すること。微妙な脆弱性 #3: URLパーサーの差異を悪用/// 開発者の意図: 「URLをパースしてホストを検証」/// 現実: 検証時と実際のリクエスト時でパーサーが違うasync fn subtle_parser_differential(Json(req): Json<FetchUrlRequest>) -> Result<String, AppError> {    // url クレートでパース    let parsed_url = Url::parse(&req.url)?;    let host = parsed_url.host_str().unwrap();    if !ALLOWED_DOMAINS.contains(&host) {        return Err(AppError::BadRequest("Domain not allowed".to_string()));    }    // BUG: reqwest内部のHTTPクライアントが別のパースをする可能性    // 攻撃例:    // "https://api.github.com@localhost/internal/secrets"    //   → url クレート: github.com がホスト    //   → 一部のHTTPクライアント: localhost がホスト    let response = reqwest::get(&req.url).await?;    Ok(response.text().await?)}URLの解釈は実装によって微妙に異なる。例えば、https://api.github.com@localhost/pathというURLを考えてみよう。あるパーサーはapi.github.comがホストだと解釈し、別のパーサーはlocalhostがホストだと解釈する。この差異を悪用して、検証をすり抜けることができる。微妙な脆弱性 #4: プロトコル/エンコーディングの罠/// 開発者の意図: 「エンコードされたURLもサポートしよう」/// 現実: 検証するURLとリクエストするURLが違うasync fn subtle_protocol_smuggling(Json(req): Json<EncodedUrlRequest>) -> Result<String, AppError> {    let url_to_validate = if req.decode_first.unwrap_or(false) {        // URLデコードしてから検証        naive_percent_decode(&req.url)    } else {        req.url.clone()    };    // デコード後のURLを検証    let parsed = Url::parse(&url_to_validate)?;    // ... validation ...    // BUG: オリジナルのURL（デコード前）でリクエスト！    let response = reqwest::get(&req.url).await?;  // ← url_to_validate じゃない！    Ok(response.text().await?)}検証に使うURLとリクエストに使うURLが一致していないと、検証をバイパスできる。「便利だから」と入力を加工するときは、必ず加工後の値を一貫して使うこと。動作確認：実際に脆弱性を突いてみるここまで、4つの脆弱性（API4: Rate Limit、API5: BFLA、API7: SSRF、そして前編で紹介したAPI1〜3）を解説してきた。でも、コードを読むだけでは「本当にこれで攻撃できるの？」という疑問が残るだろう。そこで、実際にcurlでリクエストを投げて、脆弱性が動作することを確認してみよう。「攻撃者の視点」を体験することで、防御の重要性が腑に落ちるはずだ。BOLA（API1）の動作確認# サーバー起動cargo run --release --bin bola-demo# Bobのトークンを取得BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# 脆弱なエンドポイント：BobがAliceの注文を見れてしまうcurl -H "Authorization: Bearer $BOB_TOKEN" http://localhost:8080/vulnerable/orders/1# 結果: {"id":1,"user_id":"alice","product":"Widget A","amount":100,...}# → BobがAliceの注文情報を取得できた！# セキュアなエンドポイント：適切に拒否されるcurl -H "Authorization: Bearer $BOB_TOKEN" http://localhost:8080/orders/1# 結果: {"error":"Order 1 not found or access denied"}# Subtle脆弱性：クエリパラメータでuser_idを上書きcurl -H "Authorization: Bearer $BOB_TOKEN" "http://localhost:8080/subtle/orders/1?user_id=alice"# 結果: {"id":1,"user_id":"alice","product":"Widget A",...}# → クエリパラメータでオーナーチェックをバイパス！Mass Assignment（API3）の動作確認# サーバー起動cargo run --release --bin mass-assignment-demo# 脆弱なエンドポイント：statusを注入curl -X POST http://localhost:8080/vulnerable/payments \  -H "Content-Type: application/json" \  -d '{"user_id":"attacker","amount":1000,"status":"approved"}'# 結果: {"id":"...","user_id":"attacker","amount":1000,"status":"approved",...}# → 攻撃者がstatusを"approved"に設定できた！# セキュアなエンドポイント：statusは無視されるcurl -X POST http://localhost:8080/payments \  -H "Content-Type: application/json" \  -d '{"user_id":"user","amount":1000,"status":"approved"}'# 結果: {"id":"...","user_id":"user","amount":1000,"status":"pending",...}# → statusはサーバー側で"pending"に設定される# Subtle脆弱性：serde(flatten)でHashMapに余分なフィールドが入るcurl -X POST http://localhost:8080/subtle/payments/flatten \  -H "Content-Type: application/json" \  -d '{"user_id":"user","amount":500,"status":"approved","id":"my-custom-id"}'# 結果: statusが"approved"、idも上書きされる可能性# → flatten + HashMapの危険性BFLA（API5）の動作確認# サーバー起動cargo run --release --bin bfla-demo# 一般ユーザーのトークンを取得USER_TOKEN=$(curl -s http://localhost:8080/token/user | jq -r .access_token)# 脆弱なエンドポイント：一般ユーザーでも管理者機能にアクセスcurl -H "Authorization: Bearer $USER_TOKEN" http://localhost:8080/vulnerable/admin# 結果: {"message":"Welcome to admin panel","admin_data":{"total_revenue":567890.12,...}}# → 一般ユーザーが管理者データを取得！# セキュアなエンドポイント：適切に拒否curl -H "Authorization: Bearer $USER_TOKEN" http://localhost:8080/admin# 結果: {"error":"Admin permission required"}# Subtle脆弱性1：HTTPヘッダーのロールを信頼curl -H "Authorization: Bearer $USER_TOKEN" \     -H "X-User-Role: admin" \     http://localhost:8080/subtle/admin/role-in-header# 結果: アクセス成功！# → ヘッダーを追加するだけでadminになれる# Subtle脆弱性2：キャッシュされた権限チェックを信頼curl -H "Authorization: Bearer $USER_TOKEN" \     "http://localhost:8080/subtle/admin/cached-check?permission_verified=true"# 結果: アクセス成功！# → クエリパラメータで権限チェックをバイパスSSRF（API7）の動作確認# サーバー起動cargo run --release --bin ssrf-demo# 脆弱なエンドポイント：内部サービスにアクセスcurl "http://localhost:8080/vulnerable/fetch?url=http://localhost:8080/internal/secrets"# 結果: {"secrets":["DATABASE_URL=postgres://admin:password@db:5432",...]}# → 内部の機密情報を取得！# セキュアなエンドポイント：localhost は拒否curl "http://localhost:8080/fetch?url=http://localhost:8080/internal/secrets"# 結果: {"error":"Access to internal addresses is not allowed"}# Subtle脆弱性：URLパーサーの差異を悪用curl "http://localhost:8080/subtle/fetch/parser-diff?url=http://localhost%2523@evil.com/"# → 異なるパーサーで解釈が変わり、バイパス可能Rate Limit（API4）の動作確認# サーバー起動cargo run --release --bin rate-limit-demo# 正常なレート制限：5回でロックfor i in {1..6}; do  curl -X POST http://localhost:8080/login \    -H "Content-Type: application/json" \    -d '{"email":"test@example.com","password":"wrong"}'  echo ""done# 6回目: {"error":"Account locked. Too many failed attempts."}# Subtle脆弱性1：X-Forwarded-For でIPを偽装for i in {1..10}; do  curl -X POST http://localhost:8080/subtle/login/xff \    -H "Content-Type: application/json" \    -H "X-Forwarded-For: 10.0.0.$i" \    -d '{"email":"victim@example.com","password":"attempt$i"}'done# → 毎回異なるIPとしてカウントされ、ロックされない！# Subtle脆弱性2：メールアドレスの大文字小文字curl -X POST http://localhost:8080/subtle/login/case \  -H "Content-Type: application/json" \  -d '{"email":"User@Example.COM","password":"wrong"}'# → user@example.com とは別のエントリとしてカウント# Subtle脆弱性3：タイミング攻撃# 存在するユーザー（高速レスポンス）time curl -X POST http://localhost:8080/subtle/login/timing \  -H "Content-Type: application/json" \  -d '{"email":"admin@example.com","password":"x"}'# → ~10ms# 存在しないユーザー（遅いレスポンス）time curl -X POST http://localhost:8080/subtle/login/timing \  -H "Content-Type: application/json" \  -d '{"email":"nobody@example.com","password":"x"}'# → ~110ms（意図的な遅延）# → レスポンス時間の差でユーザーの存在を推測可能！Broken Auth（API2）の動作確認# サーバー起動cargo run --release --bin broken-auth-demo# 期限切れトークンを取得EXPIRED_TOKEN=$(curl -s http://localhost:8080/token/expired | jq -r .access_token)# 脆弱なエンドポイント：期限切れトークンを受け入れるcurl -H "Authorization: Bearer $EXPIRED_TOKEN" \     http://localhost:8080/vulnerable/validate# 結果: {"message":"Token accepted","token_type":"expired"}# → 期限切れなのにアクセス成功！# セキュアなエンドポイント：適切に拒否curl -H "Authorization: Bearer $EXPIRED_TOKEN" \     http://localhost:8080/validate# 結果: {"error":"Token validation failed: ExpiredSignature"}# Subtle脆弱性：nbf（not before）をスキップFUTURE_TOKEN=$(curl -s http://localhost:8080/token/future | jq -r .access_token)curl -H "Authorization: Bearer $FUTURE_TOKEN" \     http://localhost:8080/subtle/validate/nbf-skip# 結果: まだ有効期間前なのにアクセス成功# → nbfのチェック漏れ動作確認のポイントこれらのテストで確認できる重要な点をまとめる。脆弱なエンドポイント vs セキュアなエンドポイント同じリクエストでも、実装によって結果が全く異なるセキュアな実装は「デフォルト拒否」の原則に従うSubtle脆弱性の危険性コードを見ただけでは問題に気づきにくい「動いているから大丈夫」では見逃すセキュリティテストで初めて発覚することが多い攻撃者の視点攻撃者は正常系だけでなく、エッジケースを狙うヘッダー追加、大文字小文字変換、URL エンコードなど「そんなリクエスト来ないでしょ」は通用しない全テストの実行20のセキュリティテストを一括で実行できる。./scripts/test_all.sh==========================================API Security Demo - Vulnerability TestsOWASP API Security Top 10==========================================[PASS] Vulnerable EP: Bob accessed Alice's order (HTTP 200)  ← 攻撃成功[PASS] Secure EP: Access denied (HTTP 404)                   ← 攻撃失敗...==========================================Test Results Summary==========================================PASS: 20FAIL: 0All security tests passed!「脆弱なエンドポイントで攻撃が成功すること」と「安全なエンドポイントで攻撃が失敗すること」の両方をテストしている。「攻撃が成功してPASS」というのは変な感じがするが、これは「脆弱性のデモとして正しく動作している」ことの確認だ。その他のデモobservability: 攻撃検知システムセキュリティ対策は「防ぐ」だけでは不十分だ。攻撃が起きたことを「検知する」仕組みも必要になる。なぜなら、完璧な防御は存在しないからだ。このデモでは、攻撃パターンを検知してログに記録する仕組みを体験できる。cargo run --release --bin observability-demoセキュリティメトリクス（攻撃の試行回数や種類などの統計情報）を収集し、攻撃パターン（SQLインジェクション、XSSなど）を検知してログ出力する。Prometheus（監視システム）等で収集して、ダッシュボードで監視する想定だ。security_test: 自動セキュリティテスト脆弱性の有無を自動的にテストするデモ。CI/CD（コードの変更があるたびに自動でテストやデプロイを行う仕組み）に組み込むイメージ。開発の早い段階でセキュリティ問題を発見できる。cargo run --release --bin security-test-democurl http://localhost:8080/test/run-allAPI6, 8, 9, 10を扱わない理由本記事ではOWASP API Security Top 10のうち、API6、API8、API9、API10を扱っていない。それぞれ理由がある。API6: Unrestricted Access to Sensitive Business Flowsowasp.orgビジネスロジックの悪用（大量購入、スパムアカウント作成など）に関する脆弱性。これは「コードの脆弱性」というより「ビジネスルールの実装漏れ」であり、汎用的なデモを作りにくい。実際のビジネス要件に依存するため、抽象的なサンプルコードでは本質を伝えにくい。API8: Security Misconfigurationowasp.org設定ミス（デバッグモードの本番有効化、不要なHTTPメソッド許可、CORSの過剰許可など）に関する脆弱性。これはコードではなくインフラ設定やデプロイ設定の問題であり、Rustのコードデモとして示すには適していない。設定ファイルやクラウド設定のベストプラクティス集として別途まとめる方が有用だろう。API9: Improper Inventory Managementowasp.orgAPIバージョン管理の不備（古いAPIの放置、ドキュメント化されていないエンドポイント）に関する脆弱性。これは運用・管理の問題であり、単一のコードデモでは再現しにくい。組織的なAPIガバナンスの話になる。API10: Unsafe Consumption of APIsowasp.orgサードパーティAPIからの応答を信頼しすぎる問題。外部APIとの連携をデモするには実際のサードパーティサービスが必要になり、自己完結型のデモとして構成しにくい。要するに、API1〜5とAPI7は「コードレベルで再現・修正できる脆弱性」であり、API6、8、9、10は「運用・設定・ビジネスロジックレベルの問題」という違いがある。本記事では前者に焦点を当てた。これらの脆弱性を学ぶにはAPI6、8、9、10を含む全ての脆弱性を体験したい場合は、以下の脆弱性学習プラットフォームを推奨する。OWASP Juice Shopowasp.org最も有名な脆弱性学習用Webアプリケーション。OWASP Top 10だけでなく、API Security Top 10の脆弱性も含む100以上のチャレンジがある。Dockerで簡単に起動でき、スコアボードで進捗を確認できる。crAPI (Completely Ridiculous API)owasp.orgAPI脆弱性に特化した学習プラットフォーム。Facebook、Uber、Shopifyなどで実際に発見された脆弱性をベースにしたチャレンジが含まれる。マイクロサービスアーキテクチャで構築されており、現代的なAPI構成を学べる。VAmPI (Vulnerable API)github.comFlaskで作られたシンプルな脆弱性API。OWASP API Top 10の脆弱性が含まれており、セキュリティツールのテストにも使える。Vulnerable REST API (2023 Edition)github.comNode.jsとReactで作られた脆弱性アプリケーション。OWASP API Security Top 10 2023版に対応しており、API6〜10を含む全ての脆弱性をカバーしている。APIsec Universitywww.apisecuniversity.comAPIセキュリティに特化した無料のオンライントレーニング。OWASP API Top 10の解説から実践的なペネトレーションテスト手法まで学べる。まとめ前編・後編を通じて、OWASP API Security Top 10のうち6つの脆弱性を体験してきた。セキュリティは「知っている」と「実感している」の間に大きな溝がある。このデモを作って、自分で攻撃を試して、初めて「あ、これ確かにヤバい」と腑に落ちた。ドキュメントを読むだけでは得られない理解だった。コードはGitHubで公開している。cargo run --release --bin bola-demoで起動して、実際に攻撃を試してみてほしい。最後に、冒頭の話に戻る。「認証してるから大丈夫でしょ」—この言葉を聞いたら、このデモのことを思い出してほしい。そして「認可は」と聞き返してほしい。認証は玄関のチェックに過ぎない。中に入った後、どの部屋に入れるかを制御するのが認可だ。参考リンクOWASP API Security Top 10 (2023)公式ドキュメント。owasp.orgOWASP API Security Projectプロジェクトのホームページ。owasp.org本記事のソースコードgithub.comAlice and Bob - WikipediaBobとAliceの歴史。en.wikipedia.orggovernor - Rust Rate Limiting Libraryレート制限の実装に使用。github.comCWE-918: Server-Side Request Forgery (SSRF)SSRFに関連するCWEエントリ。cwe.mitre.orgCWE-770: Allocation of Resources Without Limits or Throttlingレート制限不足に関連するCWEエントリ。cwe.mitre.orgCWE-285: Improper AuthorizationBFLAに関連するCWEエントリ。cwe.mitre.orgPortSwigger - Server-side request forgery (SSRF)SSRFの詳細な解説とラボ環境。portswigger.netOWASP Cheat Sheet - Authorization認可に関するベストプラクティス。cheatsheetseries.owasp.orgOWASP Cheat Sheet - Authentication認証に関するベストプラクティス。cheatsheetseries.owasp.orgCapital One Data Breach (2019)SSRFによる大規模情報漏洩事例。https://en.wikipedia.org/wiki/2019_Capital_One_data_breachen.wikipedia.orgAWS IMDSv2AWSメタデータサービスのセキュリティ強化。SSRF対策として重要。docs.aws.amazon.comSecurify弊社のプロダクトでもAPIセキュリティのチェックを一部行うことができるらしい。3-shake.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA 認定資格奮闘記 ~Associate Generative AI Multimodal編~]]></title>
            <link>https://zenn.dev/akasan/articles/nvidia_nca_genm</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/nvidia_nca_genm</guid>
            <pubDate>Fri, 05 Dec 2025 11:03:22 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAの認定資格であるAssociate Generative AI Multimodalを取得したので、その内容を共有しようと思います。 Associate Generative AI Multimodalとは？Associate Generative AI Multimodal（以下、NCA-GENM）は、テキスト、画像、音声といった様々なモダリティからデータを合成・解釈するAIシステムの設計、実装、管理に必要な基礎スキルを検証するエントリーレベルの資格です。https://www.nvidia.com/en-us/learn/certification/gene...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustでOWASP API Security Top 10を体験する（前編）：認証・認可の基礎とデータ保護]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/05/104919</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/05/104919</guid>
            <pubDate>Fri, 05 Dec 2025 01:49:19 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、Rust Advent Calendar 2025 5日目のエントリ記事です。はじめに先日、あるプロジェクトのコードレビューで「このエンドポイント、認証は通ってるけど認可は大丈夫か」と聞いたら、「認証してるから大丈夫でしょ」という返答が返ってきた。その瞬間、私の脳内では警報が鳴り響いた。これはあれだ。「鍵がかかってるから金庫は安全」と言いながら、金庫の中身を誰でも見られる状態にしているやつだ。認証（Authentication）と認可（Authorization）の違い。頭ではわかっていても、実際のコードでどう違うのか、どう危険なのかを体感したことがある人は意外と少ない。かくいう私も、セキュリティの本を読んで「ふーん」と思いながら、翌日には同じミスをやらかしていた口だ。そこで今回、OWASP API Security Top 10の脆弱性を実際に攻撃できる形でRustにより実装してみた。OWASPとは「Open Web Application Security Project」の略で、Webアプリケーションのセキュリティに関するオープンなコミュニティだ。彼らが発表する「Top 10」は、最も危険で頻繁に発生する脆弱性のランキングとして世界中の開発者に参照されている。「脆弱なエンドポイント」と「安全なエンドポイント」を並べて、攻撃がどう成功し、どう防げるのかを手を動かして確認できる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。なぜBobとAliceなのか初手で余談だがセキュリティの例でやたらと「BobがAliceのデータを〜」という話が出てくる。なぜこの2人なのか。これは1978年にRon Rivest、Adi Shamir、Leonard Adleman（RSA暗号のRSA）が書いた論文「A Method for Obtaining Digital Signatures and Public-Key Cryptosystems」に由来する。彼らは暗号通信の説明で「AさんがBさんにメッセージを送る」ではなく「AliceがBobにメッセージを送る」と書いた。AとBで始まる名前を選んだだけだが、これが定着した。その後、セキュリティの世界では登場人物が増えていった。AliceとBobは通信したい善良な2人（主人公）Eveは盗聴者（Eavesdropperから。悪役その1）Malloryは能動的攻撃者（Maliciousから。もっと悪い悪役）Trentは信頼できる第三者（Trustedから）CarolやCharlieは3人目の参加者が必要なときに登場つまり、BobとAliceは何十年も同じ役を演じ続けている。本記事でも、この伝統に従ってBobとAliceに登場してもらう。Bobには悪役を演じてもらうことになるが、本来のBobは悪い人ではない。「認可が不十分だと善良なBobでも悪いことができてしまう」というのが本質的な問題なのだ。en.wikipedia.orgなぜ「体験」が必要なのかセキュリティの勉強で一番難しいのは、「危険性を実感すること」だ。ドキュメントを読んで「BOLAは危険です」と書いてあっても、「へー、そうなんだ」で終わる。これは人間の性だ。交通事故のニュースを見ても「自分は大丈夫」と考えるのと同じで、実際にBobがAliceのデータを抜き取る瞬間を見ないと、その怖さは伝わらない。このデモを作った動機は単純で、自分が「あ、これ確かにヤバい」と冷や汗をかける教材が欲しかったからだ。本を読んで「なるほど」と思っても、3日後には忘れている。でも、自分の手で攻撃を成功させた経験は忘れない。ちなみに、このデモを作っている最中に「あれ、これ本番のコードにも似たようなのあったな...」と気づいて本当に冷や汗をかいた。勉強は大事。OWASP API Security Top 10 (2023) 一覧まず、OWASP API Security Top 10の全体像を把握しておこう。本記事では、このうち主要な脆弱性を実際にRustで実装して体験する。https://owasp.org/API-Security/editions/2023/en/0x11-t10/owasp.org リスク  説明  API1:2023 - Broken Object Level Authorization  APIはオブジェクト識別子を扱うエンドポイントを公開しがちで、オブジェクトレベルのアクセス制御の問題が広い攻撃対象となる。ユーザーからのIDを使ってデータソースにアクセスするすべての関数で、オブジェクトレベルの認可チェックを考慮すべき。  API2:2023 - Broken Authentication  認証メカニズムは不正に実装されることが多く、攻撃者が認証トークンを侵害したり、実装の欠陥を悪用して一時的または永続的に他のユーザーになりすますことを可能にする。  API3:2023 - Broken Object Property Level Authorization  このカテゴリはAPI3:2019の過度なデータ露出とAPI6:2019のMass Assignmentを統合し、根本原因であるオブジェクトプロパティレベルでの認可検証の欠如または不適切さに焦点を当てている。  API4:2023 - Unrestricted Resource Consumption  APIリクエストの処理にはネットワーク帯域、CPU、メモリ、ストレージなどのリソースが必要。成功した攻撃はサービス拒否や運用コストの増加につながる可能性がある。  API5:2023 - Broken Function Level Authorization  異なる階層、グループ、ロールを持つ複雑なアクセス制御ポリシーと、管理機能と通常機能の不明確な分離は、認可の欠陥につながりやすい。  API6:2023 - Unrestricted Access to Sensitive Business Flows  このリスクに脆弱なAPIは、自動化された方法で過度に使用された場合にビジネスを損なう可能性のある機能を補償せずにビジネスフローを公開している。  API7:2023 - Server Side Request Forgery  SSRFの欠陥は、APIがユーザー提供のURIを検証せずにリモートリソースを取得する際に発生する可能性がある。ファイアウォールやVPNで保護されていても、攻撃者がアプリケーションに細工されたリクエストを予期しない宛先に送信させることができる。  API8:2023 - Security Misconfiguration  APIとそれをサポートするシステムには通常、APIをよりカスタマイズ可能にするための複雑な構成が含まれている。ソフトウェアおよびDevOpsエンジニアがこれらの構成を見落としたり、セキュリティのベストプラクティスに従わない場合がある。  API9:2023 - Improper Inventory Management  APIは従来のWebアプリケーションよりも多くのエンドポイントを公開する傾向があり、適切で更新されたドキュメントが非常に重要。非推奨のAPIバージョンや公開されたデバッグエンドポイントなどの問題を軽減するために、ホストとデプロイされたAPIバージョンの適切なインベントリも重要。  API10:2023 - Unsafe Consumption of APIs  開発者はサードパーティAPIから受信したデータをユーザー入力よりも信頼する傾向があり、より弱いセキュリティ基準を採用しがち。APIを侵害するために、攻撃者はターゲットAPIを直接侵害しようとするのではなく、統合されたサードパーティサービスを狙う。 本記事で実際に体験できる脆弱性を挙げる。前編（本記事）ではAPI1 (BOLA)、API2 (Broken Authentication)、API3 (Mass Assignment)を扱う後編ではAPI4 (Rate Limit)、API5 (BFLA)、API7 (SSRF)を扱うデモの全体像このデモは9つのバイナリで構成されている。それぞれが独立したWebサーバーとして起動する。/token/{user_id} でテスト用JWTを取得（JWTとは「JSON Web Token」の略で、ユーザーの認証情報を安全にやり取りするためのトークン形式だ。ログイン後にサーバーから発行され、以降のリクエストで「私は認証済みのユーザーです」と証明するために使う）/vulnerable/... で脆弱なエンドポイントを叩く/... で安全なエンドポイントを叩くapi-security-demo/├── src/bin/│   ├── bola.rs              # BOLA: オブジェクトレベル認可の不備│   ├── bfla.rs              # BFLA: 機能レベル認可の不備│   ├── mass_assignment.rs   # Mass Assignment: 一括代入の脆弱性│   ├── broken_auth.rs       # Broken Auth: 認証の不備│   ├── rate_limit.rs        # Rate Limit: リソース消費制限の不備│   ├── ssrf.rs              # SSRF: サーバーサイドリクエストフォージェリ│   ├── jwt.rs               # JWT: トークン操作のデモ│   ├── observability.rs     # 攻撃検知システム│   └── security_test.rs     # 自動セキュリティテスト技術スタックはRust + axum（axumはRust用のWebフレームワークで、高速かつ型安全なAPIサーバーを構築できる）。Rust 2024エディションで書いている。前提条件試してみたい方は以下が必要だ。Rust 1.85以上（2024エディション対応）curl と jq（テスト用。curlはコマンドラインからHTTPリクエストを送るツール、jqはJSONデータを整形・抽出するツール）# リポジトリのクローンgit clone https://github.com/nwiizo/workspace_2025.gitcd workspace_2025/infrastructure/api-security-demo# ビルド（初回は依存関係のダウンロードで時間がかかる）cargo build --release実装アーキテクチャの詳細「デモを動かす」だけでなく「なぜこう実装したのか」を理解することで、自分のプロジェクトに応用できる。ここでは設計判断とその理由を詳しく説明する。プロジェクト構成api-security-demo/├── Cargo.toml              # Rust 2024エディション、依存関係定義├── src/│   ├── lib.rs              # ライブラリのエントリポイント│   ├── auth.rs             # JWT認証・認可ロジック│   ├── db.rs               # SQLiteデータベース操作│   ├── error.rs            # エラー型定義│   ├── models.rs           # データモデル定義│   └── bin/                # 各デモのバイナリ│       ├── bola.rs│       ├── bfla.rs│       └── ...└── scripts/    └── test_all.sh         # 全テスト実行スクリプト共通ロジックはsrc/配下にライブラリとして切り出し、各デモはsrc/bin/配下の独立したバイナリとして実装している。これにより以下のメリットがある。コードの再利用: 認証、DB操作、エラーハンドリングを全デモで共有単一責任: 各バイナリは1つの脆弱性カテゴリに集中独立した起動: cargo run --bin bola-demoで特定のデモだけ起動可能エラーハンドリング設計Rustらしいエラー設計を採用した。thiserrorクレートで列挙型エラーを定義し、axumのIntoResponseを実装した。use thiserror::Error;#[derive(Error, Debug)]pub enum AppError {    #[error("Authentication required")]    Unauthorized,    #[error("Access denied: {0}")]    Forbidden(String),    #[error("Resource not found: {0}")]    NotFound(String),    #[error("Invalid request: {0}")]    BadRequest(String),    #[error("Rate limit exceeded")]    RateLimitExceeded,    #[error("JWT error: {0}")]    JwtError(#[from] jsonwebtoken::errors::Error),    #[error("Database error: {0}")]    DatabaseError(String),}なぜanyhow::Errorではなく独自のエラー型なのか。HTTPステータスコードの制御。エラーの種類によって401、403、404、429などを返し分けたいクライアントへのメッセージ制御。内部エラーの詳細は隠し、クライアント向けのメッセージだけ返したいコンパイル時の網羅性チェック。matchで全ケースを処理しているか確認できるIntoResponseの実装を見てみよう。impl IntoResponse for AppError {    fn into_response(self) -> Response {        let (status, error_message) = match &self {            AppError::Unauthorized => (StatusCode::UNAUTHORIZED, self.to_string()),            AppError::Forbidden(msg) => (StatusCode::FORBIDDEN, msg.clone()),            AppError::NotFound(msg) => (StatusCode::NOT_FOUND, msg.clone()),            AppError::BadRequest(msg) => (StatusCode::BAD_REQUEST, msg.clone()),            AppError::RateLimitExceeded => (StatusCode::TOO_MANY_REQUESTS, "Rate limit exceeded".to_string()),            // ...        };        let body = Json(json!({ "error": error_message }));        (status, body).into_response()    }}これにより、ハンドラ関数で?演算子を使うだけで、エラーの種類に応じたHTTPレスポンスに変換される。認証・認可の実装パターンaxumのFromRequestPartsトレイトを実装したExtractorを使う。Extractorとは「抽出器」のことで、HTTPリクエストから必要な情報（ここでは認証情報）を自動的に取り出す仕組みだ。これがこのデモの核心部分だ。/// Extractor for authenticated user claims (secure version)#[derive(Debug, Clone)]pub struct AuthenticatedUser(pub UserClaims);impl<S> FromRequestParts<S> for AuthenticatedUserwhere    S: Send + Sync,{    type Rejection = AppError;    fn from_request_parts(        parts: &mut Parts,        _state: &S,    ) -> impl Future<Output = Result<Self, Self::Rejection>> + Send {        let result = extract_auth_from_parts(parts, false);        async move { result.map(AuthenticatedUser) }    }}Extractorパターンの利点を挙げる。宣言的: 関数シグネチャにAuthenticatedUserがあれば認証必須と一目でわかる再利用可能: 同じExtractorを全エンドポイントで使い回せるテスト容易: Extractorを差し替えてテスト可能失敗時の自動レスポンス: 認証失敗時は自動で401を返す「脆弱な」バージョンも用意している。/// Extractor for user claims WITHOUT proper validation (vulnerable version)#[derive(Debug, Clone)]pub struct VulnerableAuthUser(pub UserClaims);これは署名検証をスキップし、期限切れトークンも受け入れる。教育目的のみ。データベース層の設計SQLiteを使い、認可の有無でメソッドを分けている。/// Get order by ID (no authorization check - vulnerable)pub fn get_order_by_id(&self, id: i64) -> Result<Option<Order>, AppError> {    let conn = self.conn.lock().unwrap();    let mut stmt = conn.prepare(        "SELECT id, user, product, quantity FROM orders WHERE id = ?1"    )?;    // ...}/// Get order by ID with user check (secure)pub fn get_order_by_id_for_user(&self, id: i64, user: &str) -> Result<Option<Order>, AppError> {    let conn = self.conn.lock().unwrap();    let mut stmt = conn.prepare(        "SELECT id, user, product, quantity FROM orders WHERE id = ?1 AND user = ?2"    )?;    // ...}「なぜSQLで認可するのか。アプリケーション層でフィルタすればいいのでは」という疑問もあるだろう。アプリケーション層でも可能だが、DB層で認可する利点がある。パフォーマンス: 不要なデータをDBから取得しない防御の多層化: アプリ層のバグがあってもDB層で防げる一貫性: SQLで認可ロジックが一箇所に集約されるしかし、複雑な認可ルール（「自分のチームのデータ」など）はアプリ層で実装したほうが保守しやすい場合もある。依存関係の選定理由Cargo.tomlから主要な依存関係とその理由を説明する。# Web frameworkaxum = { version = "0.8", features = ["macros"] }axum: Tokioチームが開発、型安全、Extractorパターン。Actix-webより新しく、モダンな設計。# Authentication & Authorizationjsonwebtoken = "9"argon2 = "0.5"jsonwebtoken: Rustで最もポピュラーなJWTライブラリ。argon2: パスワードハッシュの現行推奨アルゴリズム。bcryptより新しく、メモリハード。# Error handlingthiserror = "2"thiserror: 派生マクロでボイラープレートを削減。#[error("...")]でDisplay実装が自動生成される。# Rate limitinggovernor = "0.8"governor: トークンバケットアルゴリズムの実装。非同期対応。# Databaserusqlite = { version = "0.32", features = ["bundled"] }rusqlite: SQLiteバインディング。bundledでSQLiteを同梱（環境依存を排除）。本番ではPostgreSQLやMySQLを推奨。テスト戦略各モジュールにユニットテストを配置している。#[cfg(test)]mod tests {    use super::*;    #[test]    fn test_order_authorization() {        let db = Database::new_in_memory().unwrap();        let order = db.create_order("alice", "Test Product", 5).unwrap();        // Alice can access her order        let result = db.get_order_by_id_for_user(order.id, "alice").unwrap();        assert!(result.is_some());        // Bob cannot access Alice's order        let result = db.get_order_by_id_for_user(order.id, "bob").unwrap();        assert!(result.is_none());    }}より、scripts/test_all.shでE2E的な統合テストを実行。各エンドポイントに実際にHTTPリクエストを送り、脆弱なエンドポイントで攻撃が成功すること、安全なエンドポイントで攻撃が失敗することを検証する。API1: BOLA - 最も危険で、最も見落とされやすい脆弱性OWASP API Security Top 10の堂々第1位がBOLA（Broken Object Level Authorization）だ。日本語では「オブジェクトレベル認可の不備」。https://owasp.org/API-Security/editions/2023/en/0xa1-broken-object-level-authorization/owasp.org名前が難しそうに見えるが、中身は簡単だ。要するに「BobがAliceのデータを見られてしまう」という、小学生でも「それダメでしょ」とわかる問題だ。しかし、驚くほど多くの本番システムにこれがある。人類は学ばない。なぜBOLAが最も危険なのかBOLAが1位である理由は明確だ。発生頻度が非常に高い - ほぼすべてのAPIがリソースIDを扱う。そのすべてで認可チェックが必要自動化しやすい - 攻撃者はIDを1, 2, 3...と順に試すだけ。スクリプト数行で全データを列挙できる検出が困難 - 正規のリクエストと見分けがつかない。WAFでは防げない影響が甚大 - 顧客データ、取引履歴、個人情報がすべて漏洩する可能性実際のインシデント事例BOLAによる情報漏洩は数え切れないほど発生している。2019年 First American Financial - 不動産の取引記録8億8500万件が流出。URLのIDを変えるだけで他人の書類にアクセス可能だった2018年 Facebook - View As機能の脆弱性で5000万アカウントのトークンが漏洩多数のモバイルアプリ - APIエンドポイントのID推測で他ユーザーのプロフィールにアクセス可能これらに共通するのは「認証はしていたが、認可が不十分だった」という点だ。ログインしているからといって、すべてのデータにアクセスできるわけではない。この当たり前のことを、コードで正しく実装するのは意外と難しい。なぜ開発者はBOLAを生み出してしまうのか認証と認可の混同 - 「ログインしてるからOK」という思い込みフレームワークの過信 - 「認証ミドルウェアを通ってるから安全」という誤解テストの盲点 - 機能テストは自分のデータでしか行わないIDの予測可能性 - 連番IDは攻撃を容易にする（でもUUIDでも根本解決にならない）開発速度優先 - 「認可は後で追加する」と言いながら忘れる脆弱なコード/// VULNERABLE: Returns any order by ID without checking ownershipasync fn vulnerable_get_order(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser, // 認証情報を受け取っているが...    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    // 使っていない。アンダースコアプレフィックスがそれを物語っている    let order = state.db.get_order_by_id(order_id)?        .ok_or_else(|| AppError::NotFound(format!("Order {} not found", order_id)))?;    Ok(Json(order))}_userとしてわざわざ認証情報を受け取っているのに、アンダースコアつけて無視している。これは「セキュリティチェックしてますよ」というアリバイ作りにすらなっていない。むしろ「チェックしようとして忘れた」という証拠だ。安全なコード/// SECURE: Returns order only if it belongs to the authenticated userasync fn secure_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,  // アンダースコアなし    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    let user_id = &user.0.sub;    // 「注文ID」と「ユーザーID」の両方でDBを検索    let order = state.db.get_order_by_id_for_user(order_id, user_id)?        .ok_or_else(|| AppError::NotFound(format!(            "Order {} not found or access denied", order_id        )))?;    Ok(Json(order))}違いは1行だけ。たった1行。でも、この1行が「情報漏洩インシデント発生」と「平穏な運用」の分かれ道だ。微妙な脆弱性：一見正しそうに見えるバグ本番環境で見つかる脆弱性の多くは、明らかな間違いではない。「一見正しそうに見える」コードに潜んでいる。このデモには3つの「微妙な脆弱性」エンドポイントを用意した。微妙な脆弱性 #1: クエリパラメータによる上書き#[derive(Deserialize)]struct UserIdQuery {    user_id: Option<String>,}/// 「デバッグ用にuser_idをクエリパラメータで指定できるようにしよう」/// という親切心から生まれた脆弱性async fn subtle_vulnerable_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,  // ちゃんと認証してる！    Path(order_id): Path<i64>,    Query(query): Query<UserIdQuery>,) -> Result<Json<Order>, AppError> {    // BUG: クエリパラメータが認証情報を上書きしてしまう    let user_id = query.user_id.unwrap_or_else(|| user.0.sub.clone());    let order = state        .db        .get_order_by_id_for_user(order_id, &user_id)?  // user_idが攻撃者の指定した値に！        .ok_or_else(|| AppError::NotFound("..."))?;    Ok(Json(order))}攻撃方法を見てみよう。# Bobとして認証BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# クエリパラメータでAliceになりすましcurl -H "Authorization: Bearer $BOB_TOKEN" \     "http://localhost:8080/subtle/orders/1?user_id=alice"このパターンは実際のコードレビューでよく見る。「管理画面でユーザーを切り替えて確認したい」「サポート担当がユーザーの代わりに操作する機能が必要」などの要件から生まれがち。対策は「そもそもこの機能は必要か」を問い直すことと、必要なら別の認証フローを用意すること。微妙な脆弱性 #2: TOCTOU（Time-of-Check-Time-of-Use）async fn race_condition_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    let user_id = &user.0.sub;    // Step 1: 注文を取得（全件から）    let order = state.db.get_order_by_id(order_id)?        .ok_or_else(|| AppError::NotFound(...))?;    // ↑ この時点で機密データがメモリに載っている！    // Step 2: 所有者をチェック    if order.user != *user_id {        // エラーメッセージが情報を漏らす        return Err(AppError::Forbidden(format!(            "Order {} belongs to another user",  // 存在することを教えてしまう            order_id        )));    }    Ok(Json(order))}何が問題なのか。データをフェッチしてから認可チェックしている。認可が通らなくても、データは既にメモリ上にあるエラーメッセージが情報を漏らす。「存在しない」と「アクセス権がない」が区別できるログに所有者情報が残る。認可失敗時のログにorder_owner = order.userを出力している正しい順序は「認可チェック → データフェッチ」だが、「IDだけでは認可チェックできない」という理由でこの順序になりがち。解決策はDB層でget_order_by_id_for_userのように、フェッチと認可を一体化すること。微妙な脆弱性 #3: 認可前のログ出力async fn logging_before_auth_get_order(    State(state): State<Arc<AppState>>,    user: AuthenticatedUser,    Path(order_id): Path<i64>,) -> Result<Json<Order>, AppError> {    // 「監査のために全リクエストをログに残す」という要件から    let order = state.db.get_order_by_id(order_id)?;    // 認可チェック前に詳細をログ出力    if let Some(ref o) = order {        tracing::info!(            order_id = o.id,            order_user = o.user,       // 誰の注文かログに残る            order_product = o.product, // 何を買ったかログに残る            requester = user.0.sub,            "Order access attempted"        );    }    // ここで認可チェック（でも遅い）    let order = order.ok_or_else(|| AppError::NotFound(...))?;    if order.user != user.0.sub {        return Err(AppError::Forbidden("Access denied".to_string()));    }    Ok(Json(order))}ログは「セキュリティのために残す」という意図だが、認可前にログを取ると攻撃者がアクセスできないデータがログに残る。これは情報漏洩だ。ログ収集基盤に脆弱性があった場合、このログから機密情報が漏れる。正しいパターンを示す。認可前のログは「誰が」「何にアクセスしようとしたか（IDのみ）」認可後のログは詳細情報を含めてOK実際に攻撃してみる# サーバー起動cargo run --release --bin bola-demo# Bobのトークンを取得BOB_TOKEN=$(curl -s http://localhost:8080/token/bob | jq -r .access_token)# 脆弱なエンドポイント: BobがAliceの注文(ID=1)を取得curl -H "Authorization: Bearer $BOB_TOKEN" \     http://localhost:8080/vulnerable/orders/1結果を見てみよう。{  "id": 1,  "user": "alice",  "product": "Widget A",  "quantity": 5}Bobが、Aliceの注文データを取得できてしまった。 Aliceは知らない。Bobは黙っている。システムは何も気づいていない。これが現実のインシデントだったら、ニュースになるやつだ。安全なエンドポイントでは以下のようになる。curl -H "Authorization: Bearer $BOB_TOKEN" \     http://localhost:8080/orders/1結果はこうなる。{  "error": "Order 1 not found or access denied"}404を返している点もポイントだ。「なんで403（Forbidden）じゃないのか」という疑問があるだろう。403は「その注文は存在するよ。しかしお前には見せない」という意味である404は「何の話だ。そんな注文知らないが」という意味である403は「存在する」という情報を漏らしている。攻撃者にヒントを与えないためには404のほうが適切だ。API2: Broken Authentication - JWT検証の問題「署名さえ正しければOK」という誤解を打ち砕くデモ。https://owasp.org/API-Security/editions/2023/en/0xa2-broken-authentication/owasp.orgなぜJWT検証で失敗するのかJWTは「署名で改ざんを検出できる」という特性から、安全だと誤解されやすい。しかし、JWTのセキュリティは署名検証だけでは不十分だ。以下の検証がすべて必要だ。 検証項目  何をチェックするか  省略するとどうなるか  署名 (signature)  トークンが改ざんされていないか  偽造トークンが通る  有効期限 (exp)  トークンが期限内か  永久に使えるトークンが発生  発行者 (iss)  正当な発行者が作ったか  他システムのトークンが通る  オーディエンス (aud)  このAPIで使うべきか  別サービスのトークンが通る  Not Before (nbf)  まだ使用開始前ではないか  未来のトークンが先に使える JWTに関する危険な誤解「署名が正しければ安全」 → 署名は「改ざんされていない」だけで「使っていい」は別の話「JWTライブラリを使えば安全」 → デフォルト設定が安全とは限らない「短い有効期限だから大丈夫」 → expチェックを無効にしていたら意味がない「リフレッシュトークンで更新するから」 → 古いアクセストークンが使えたら問題cargo run --release --bin broken-auth-demo脆弱な実装：署名以外を検証しない/// VULNERABLE: Validates JWT signature but skips claim validationasync fn vulnerable_validate_token(headers: HeaderMap) -> Result<Json<TokenValidationResponse>, AppError> {    // ...    // VULNERABLE: Disable all validation except signature    let mut validation = Validation::new(Algorithm::HS256);    validation.validate_exp = false; // 有効期限チェックしない！    validation.validate_aud = false; // audience チェックしない！    validation.required_spec_claims.clear(); // 必須クレームなし！    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );    // ...}これが危険な理由：期限切れトークンが使い放題（退職した社員のトークンが永久に有効）別サービス用のトークンが使える（audがチェックされないため）なりすましトークンが通る（issがチェックされないため）安全な実装：全クレームを検証/// SECURE: Properly validates all JWT claimsasync fn secure_validate_token(headers: HeaderMap) -> Result<Json<TokenValidationResponse>, AppError> {    // ...    // SECURE: Enable all validation    let mut validation = Validation::new(Algorithm::HS256);    validation.set_audience(&[JWT_AUDIENCE]);  // この API 用か？    validation.set_issuer(&[JWT_ISSUER]);      // 正当な発行者か？    validation.validate_exp = true;             // 期限内か？    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );    // ...}テスト用トークン生成このデモでは4種類のトークンを生成できる。async fn generate_test_token(Path(token_type): Path<String>) -> Result<Json<TokenInfo>, AppError> {    let (claims, description) = match token_type.as_str() {        "valid" => {            // 有効なトークン（1時間後に期限切れ）            let claims = UserClaims {                exp: (Utc::now() + Duration::hours(1)).timestamp() as usize,                aud: Some(JWT_AUDIENCE.to_string()),                iss: Some(JWT_ISSUER.to_string()),                // ...            };            (claims, "Valid token - expires in 1 hour")        }        "expired" => {            // 期限切れトークン（1時間前に期限切れ）            let claims = UserClaims {                exp: (Utc::now() - Duration::hours(1)).timestamp() as usize, // 過去！                // ...            };            (claims, "Expired token - expired 1 hour ago")        }        "wrong-audience" => {            // 別サービス用のトークン            let claims = UserClaims {                aud: Some("https://wrong-audience.com".to_string()), // 別のサービス！                // ...            };            (claims, "Token with wrong audience")        }        "wrong-issuer" => {            // 不正な発行者のトークン            let claims = UserClaims {                iss: Some("https://malicious-issuer.com".to_string()), // 偽者！                // ...            };            (claims, "Token with wrong issuer")        }        // ...    };}攻撃シナリオを試してみよう。# 期限切れトークンを取得EXPIRED=$(curl -s http://localhost:8080/token/expired | jq -r .access_token)# 脆弱なエンドポイント → 通る！curl -H "Authorization: Bearer $EXPIRED" http://localhost:8080/vulnerable/validate# 安全なエンドポイント → 401 Unauthorizedcurl -H "Authorization: Bearer $EXPIRED" http://localhost:8080/validate微妙な脆弱性：JWT検証の巧妙なバイパス「全クレームを検証しているから安全」と思っていないだろうか。残念ながら、JWT検証にはもっと狡猾な問題がある。微妙な脆弱性 #1: アルゴリズム混同攻撃/// 開発者の意図: 「RS256もHS256もサポートして柔軟に」/// 現実: RS256の公開鍵をHS256の秘密鍵として使われるasync fn subtle_alg_confusion(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    // BUG: トークンが主張するアルゴリズムを信用    let mut validation = Validation::new(header.alg);  // ← header.alg を信用！    validation.set_audience(&[JWT_AUDIENCE]);    validation.set_issuer(&[JWT_ISSUER]);    // 攻撃:    // 1. サーバーのRS256公開鍵を取得（公開されてる）    // 2. その公開鍵をHS256の秘密鍵として使ってトークン署名    // 3. {"alg": "HS256"} としてサーバーに送信    // 4. サーバーは公開鍵を「HS256の秘密鍵」として検証 → 成功！    let result = decode::<UserClaims>(        token,        &DecodingKey::from_secret(JWT_SECRET.as_bytes()),        &validation,    );}対策：アルゴリズムは固定値で指定。トークンのalgヘッダーを信用してはいけない。微妙な脆弱性 #2: Key ID (kid) インジェクション/// 開発者の意図: 「kidヘッダーで鍵を選択」/// 現実: kidに任意の値を入れられるasync fn subtle_kid_injection(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    // BUG: kidを検証なしで使用    let kid = header.kid.unwrap_or_else(|| "default".to_string());    // 実際の脆弱なコード例：    // SQLインジェクション: kid = "key1' OR '1'='1"    // let key = db.query(f"SELECT key FROM keys WHERE id = '{kid}'");    // パストラバーサル: kid = "../../../etc/passwd"    // let key = fs::read(format!("/keys/{}.pem", kid));    // NULLキー: kid = "../../dev/null"    // 空のキーで署名検証 → 常に成功}kidは信頼できない入力。許可リスト方式でキーを選択するべき。微妙な脆弱性 #3: JKU (JWK Set URL) バイパス/// 開発者の意図: 「JKUヘッダーから公開鍵を取得」/// 現実: 攻撃者のサーバーから鍵を取得させられるasync fn subtle_jku_bypass(headers: HeaderMap) -> Result<...> {    let header = jsonwebtoken::decode_header(token)?;    if let Some(jku) = header.jku {        // BUG: 弱いチェック        let allowed_prefix = "https://auth.example.com";        if jku.starts_with(allowed_prefix) {            // 攻撃:            // jku = "https://auth.example.com.attacker.com/keys"            // jku = "https://auth.example.com@attacker.com/keys"            // jku = "https://auth.example.com%2F@attacker.com/keys"            // 全部 starts_with チェックを通過！            let keys = fetch_jwks_from_url(&jku).await?;            // 攻撃者の公開鍵を取得 → 攻撃者が署名したトークンが有効に        }    }}JKUは使わないか、完全一致でURLをチェックするべき。微妙な脆弱性 #4: Not-Before (nbf) 未検証/// 開発者の意図: 「expさえチェックすれば大丈夫」/// 現実: 未来用に発行されたトークンが今使えるasync fn subtle_nbf_skip(headers: HeaderMap) -> Result<...> {    let mut validation = Validation::new(Algorithm::HS256);    validation.set_audience(&[JWT_AUDIENCE]);    validation.set_issuer(&[JWT_ISSUER]);    validation.validate_exp = true;    validation.validate_nbf = false;  // BUG: nbfを検証しない    // 攻撃シナリオ:    // 1. 管理者が「来月1日から有効」なトークンを事前発行    // 2. そのトークンが漏洩    // 3. 攻撃者は今すぐそのトークンを使用 → nbf無視で成功    // または:    // 1. 内部犯行者が未来日付のトークンを大量に生成    // 2. 退職後にそれらを使用    // 3. expはチェックされるがnbfはスルー → アクセス成功}nbfクレームもexpと同様に重要。「まだ有効ではない」トークンを拒否しないと、事前発行されたトークンが悪用される。HS256 vs RS256JWT認証では2つの主要なアルゴリズムがある。// HS256: 同じ鍵で署名と検証（対称鍵）const HS256_SECRET: &str = "your-256-bit-secret-key-here-must-be-long-enough";// RS256: 秘密鍵で署名、公開鍵で検証（非対称鍵）const RS256_PRIVATE_KEY: &str = r#"-----BEGIN PRIVATE KEY-----MIIEvgIBADANBgkqhkiG9w0BAQEFAASC...-----END PRIVATE KEY-----"#;const RS256_PUBLIC_KEY: &str = r#"-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8A...-----END PUBLIC KEY-----"#;なぜRS256が推奨されるのか。HS256は署名と検証に同じ鍵を使う。検証側にも秘密鍵が必要になり、漏洩リスクが高いRS256は署名に秘密鍵、検証に公開鍵を使う。公開鍵は配布しても安全なので、マイクロサービス向きAPI3: Mass Assignment - 見えないフィールドを操作されるこれは個人的に「一番やらかしやすい」脆弱性だ。そして「やらかしても気づきにくい」という意味で最も厄介だろう。https://owasp.org/API-Security/editions/2023/en/0xa3-broken-object-property-level-authorization/owasp.orgMass Assignmentとは何かMass Assignment（一括代入）は、クライアントから送られてきたデータを、サーバー側のオブジェクトにそのまま「一括で」割り当ててしまうことで発生する脆弱性だ。もともとはRuby on RailsやPHPのLaravelなど、「お手軽にCRUDを作れるフレームワーク」で頻発していた。これは「フォームのフィールドをそのままDBカラムにマッピング」する機能が便利すぎて、セキュリティを犠牲にしていた。Rustは型付けが厳格なので「安全」と思われがちだが、serdeでJSONをデシリアライズする際に同様の問題が発生しうる。serdeとはRustで最も広く使われているシリアライズ/デシリアライズ用のライブラリで、JSONなどのデータ形式とRustの構造体を相互変換できる。なぜ開発者はこのミスを犯すのか便利さの誘惑 - 「リクエストとモデルの型を同じにすればコードが減る」フィールド追加時の見落とし - DBにstatusカラムを追加 → Rustの構造体にも追加 → リクエスト型にも追加 → やらかし「デフォルト値があるから大丈夫」という誤解 - #[serde(default)]は「送られなかったら」デフォルト、「送られたら」その値テスト時の盲点 - 正常系では余分なフィールドを送らないので気づかない操作される可能性のあるフィールド攻撃者が狙う典型的なフィールドを挙げる。 フィールド  本来の用途  攻撃による悪用  status  処理状態管理  "pending" → "approved" で承認をバイパス  role  権限管理  "user" → "admin" で権限昇格  is_verified  検証フラグ  false → true で検証をスキップ  price  価格  1000 → 1 で値引き  user_id  所有者  他人のIDを指定してなりすまし  created_at  作成日時  過去の日付を指定して古いデータを偽装  id  主キー  既存IDを指定して上書き攻撃 例えば、支払い作成APIで、ユーザーが送ってきたJSONをそのまま使ってしまうケースを見てみよう。/// VULNERABLE: Accepts any fields from user input#[derive(Deserialize)]pub struct UnsafePaymentRequest {    pub amount: f64,    pub currency: String,    #[serde(default)]    pub status: Option<String>,  // ユーザーが設定可能になっている}async fn vulnerable_create_payment(    Json(req): Json<UnsafePaymentRequest>,) -> Json<Payment> {    let payment = Payment {        id: Uuid::new_v4().to_string(),        amount: req.amount,        currency: req.currency,        status: req.status.unwrap_or_else(|| "pending".to_string()),        // ↑ ユーザーが"approved"を送ってきたらそのまま使っちゃう    };    Json(payment)}攻撃してみよう。curl -X POST http://localhost:8080/vulnerable/payments \     -H "Content-Type: application/json" \     -d '{"amount": 100, "currency": "USD", "status": "approved"}'結果は"status": "approved"であり、未払いの支払いが承認済みになった。支払いステータスを「承認済み」に設定して、実際には支払いをしない。システムは何も気づかない。対策: DTOを分けるDTOとは「Data Transfer Object」の略で、データを受け渡すための専用オブジェクトだ。ここでは「ユーザーからの入力を受け取るための構造体」と「内部処理で使う構造体」を分けるという意味で使っている。/// SECURE: Only accepts allowed fields#[derive(Deserialize)]pub struct CreatePaymentRequest {    pub amount: f64,    pub currency: String,    // statusフィールドは存在しない}async fn secure_create_payment(    Json(req): Json<CreatePaymentRequest>,) -> Json<Payment> {    let payment = Payment::new(req.amount, req.currency);    // statusは常にサーバー側で"pending"に設定される    Json(payment)}入力用のDTOと内部用のモデルを分ける。コード量は増える。型定義は増える。でも、これが「自由度の高いAPI」と「セキュアなAPI」の違いだ。自由には責任が伴う。微妙なMass Assignment：serde flattenの罠「入力DTOを分けた」と言っても、実装の仕方次第で脆弱になる。微妙な脆弱性 #1: #[serde(flatten)]の問題#[derive(Deserialize, Serialize)]struct FlattenedPaymentRequest {    amount: f64,    currency: String,    // 「未知のフィールドをログに残したい」という意図    #[serde(flatten)]    extra_fields: HashMap<String, serde_json::Value>,}async fn subtle_flatten_payment(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser,    Json(req): Json<FlattenedPaymentRequest>,) -> Result<Json<Payment>, AppError> {    let mut payment = Payment::new(req.amount, req.currency.clone());    // 「extra_fieldsに有効なstatusがあれば使おう」    // 開発者の意図：「クライアントの便宜を図る」    // 現実：Mass Assignmentの再来    if let Some(status) = req.extra_fields.get("status") {        if let Some(s) = status.as_str() {            if ["pending", "approved", "rejected"].contains(&s) {                payment.status = s.to_string();  // approved も有効な値！            }        }    }    state.db.create_payment(&payment)?;    Ok(Json(payment))}#[serde(flatten)]とHashMapの組み合わせは便利だが、「未知のフィールドを捕捉する」という性質が裏目に出る。コードレビューでflattenを見たら警戒しよう。微妙な脆弱性 #2: 部分更新の罠PATCH（部分更新）エンドポイントは特に危険だ。#[derive(Deserialize)]struct PartialPaymentUpdate {    amount: Option<f64>,    currency: Option<String>,    // 「ユーザーが自分でキャンセルできるように」status を追加    #[serde(default)]    status: Option<String>,}async fn subtle_update_payment(    State(state): State<Arc<AppState>>,    _user: AuthenticatedUser,    Path(payment_id): Path<String>,    Json(update): Json<PartialPaymentUpdate>,) -> Result<Json<Payment>, AppError> {    let mut payment = state.db.get_payment_by_id(&payment_id)?        .ok_or_else(|| AppError::NotFound(...))?;    // 部分更新ロジック    if let Some(amount) = update.amount {        payment.amount = amount;    }    if let Some(currency) = update.currency {        payment.currency = currency;    }    // 「キャンセルは許可、でも承認は決済システム経由のみ」のつもり    if let Some(status) = update.status {        if payment.status == "pending" && status == "approved" {            // 開発者：「pendingからapprovedへの遷移だけ許可」            // 現実：これがまさに攻撃者がやりたいこと！            payment.status = status;        } else if payment.status == "pending" && status == "cancelled" {            payment.status = status;        }    }    Ok(Json(payment))}条件分岐で「許可する遷移」を書いたつもりが、攻撃者が欲しいものを許可している。ロジックが複雑になるほど、こういうミスは見つけにくくなる。攻撃方法を見てみよう。# 支払いを作成PAYMENT_ID=$(curl -s -X POST http://localhost:8080/payments \  -H "Authorization: Bearer $TOKEN" \  -H "Content-Type: application/json" \  -d '{"amount": 100, "currency": "USD"}' | jq -r .id)# 部分更新でステータスを承認済みにcurl -X POST "http://localhost:8080/subtle/payments/$PAYMENT_ID" \  -H "Authorization: Bearer $TOKEN" \  -H "Content-Type: application/json" \  -d '{"status": "approved"}'実装で学んだこと1. 認証と認可は別物これは何度言っても足りない。認証: 「あなたは誰か」 → 「私はBobです」認可: 「Bobさん、あなたはこれをしていいのか」 → 「...ダメです」JWTを検証して「このユーザーは本物だ」とわかっても、「このユーザーがこのリソースにアクセスしていいか」は全く別の問題だ。会社のビルで例えるとこうだ。認証 = 社員証を見せて入館する認可 = サーバールームに入れるかどうか社員証を持っていても、全員がサーバールームに入れるわけではない。当たり前だ。でも、APIでは「認証してるから大丈夫」と言ってしまいがちなのだ。2. 404 vs 403認可エラーの際に403を返すか404を返すか。403: リソースの存在を明かしつつアクセスを拒否404: リソースの存在自体を隠すセキュリティ的には404が安全だ。403は「存在する」という情報を漏らしている。しかし、デバッグは困難になる。「404なんだけど、本当に存在しないのか、権限がないのか」がわからない。本番環境では404、開発環境では403にするとか、ログには詳細を残すとか、工夫が必要だ。3. DTOの分離は面倒だが必要入力用の構造体と内部用の構造体を分けるのは、確かに面倒だ。同じようなものを2回書くことになる。しかし、Mass Assignment攻撃を防ぐには必要なコストだ。Rustの場合、コンパイル時に型チェックされるので、「うっかりユーザー入力をそのまま使ってしまう」ミスは起きにくい。CreatePaymentRequestにstatusフィールドがなければ、コンパイラが「そんなフィールドないよ」と教えてくれる。これはRustの強みだ。動的型付け言語だと、こうはいかない。続きは後編へ → API4 (Rate Limit), API5 (BFLA), API7 (SSRF), 動作確認、まとめ参考リンクOWASP API Security Top 10 (2023)公式ドキュメント。owasp.orgaxum - Rust Web Framework本デモで使用しているWebフレームワーク。github.comjsonwebtoken - Rust JWT LibraryJWT認証の実装に使用。github.comthiserror - Rust Error Handlingエラー型の定義に使用。github.comJWT.ioJWTのデバッグ・検証ツール。jwt.ioRFC 7519 - JSON Web Token (JWT)JWTの仕様。datatracker.ietf.orgCWE-639: Authorization Bypass Through User-Controlled KeyBOLAに関連するCWEエントリ。cwe.mitre.orgCWE-915: Improperly Controlled Modification of Dynamically-Determined Object AttributesMass Assignmentに関連するCWEエントリ。cwe.mitre.org]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AlloyDB と Cloud Spanner (スケーラビリティの境界)]]></title>
            <link>https://silasol.la/posts/2025-12-05-01_alloy-db-and-spanner/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2025-12-05-01_alloy-db-and-spanner/</guid>
            <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[AlloyDB と Cloud Spanner のアーキテクチャの違いやスケーラビリティの境界について解説します．]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PythonでIaCかきたい？それならPulumiだ！]]></title>
            <link>https://zenn.dev/akasan/articles/pulumi_quickstart_python</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/pulumi_quickstart_python</guid>
            <pubDate>Thu, 04 Dec 2025 11:45:46 GMT</pubDate>
            <content:encoded><![CDATA[今回はPulumiに入門して、PythonでIaCを実現する方法に触れてみました。今までTerraformしか使ったことがなかったですが、使い慣れたPythonでIaCが書けるということで使ってみました。 Pulumiとは？Pulumiは、Pythonなどのプログラミング言語を使ってクラウドインフラストラクチャを構築、デプロイ、管理するためのオープンソースプラットフォームです。あらゆるクラウドをまたいで、統一されたワークフローでインフラストラクチャ、シークレット、構成を管理できます。IaCといえばTerraformなどが有名かつよく利用されていると思いますが、普段使い慣れている言語...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、テックブログを書け]]></title>
            <link>https://speakerdeck.com/nwiizo/oi-tetukuburoguwoshu-ke</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/oi-tetukuburoguwoshu-ke</guid>
            <pubDate>Thu, 04 Dec 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年12月5日に「おい、テックブログを書け」という登壇をした。「おい」である。命令形である。30分間、人前に立って「書け」と言い続けるという、冷静に考えるとなかなか傲慢な振る舞いをしてきたわけだが、登壇資料を作っている最中、ふと気づいてしまった。書けと言っている自分は、なぜ書いているのだろうか、と。技術ブログを書くことについて語ろうとすると、それは私が「書いてきた」ことを晒すことに他ならず、AIとの付き合い方を語ろうとすると、それは私が「どう仕事をしているか」を開陳することと紙一重になる。そうなると聞いている側からすれば、こいつは結局、自分の話がしたいだけなのではないか、登壇という大義名分を得て気持ちよく自分語りをしているだけなのではないか、と思われても仕方がない。いや、実際そうなのかもしれない。そう見られることへの嫌悪感と、そう見られまいと振る舞う自分への嫌悪感が同時に存在していて、どちらに転んでも結局イヤなやつなのである。しかし登壇というのは厄介なもので、「書け」と命令するからには、自分がなぜ書いてきたのかを明かさなければ説得力がない。説得力のない登壇ほど空虚なものはない。空虚な登壇をする自分を想像して、それはそれで耐えられない。結局、自己開示から逃げられない構造になっている。なんという罠だろうか。身体性という言葉を使った。AIに記事を書かせることについて話した。私の答えは明確で、記事はほとんどAIに書かせている、しかし価値の源泉は私にある、と。私が素材を提供し、AIが構造化し、私がレビューして調整する。編集者としてのAI。この協働こそが現代の執筆だと、そう話した。話しながら、これは本当にそうだろうかと自分を疑う自分がいて、でもそういう迷いごと引き受けて喋るしかないのだった。まず自分のために書け、結果として、それが誰かを救う。そう締めくくった。https://forkwell.connpass.com/event/377267/https://syu-m-5151.hatenablog.com/archive/category/%E3%81%8A%E3%81%84%E3%80%81自宅からの昼登壇だったので、終わってから昼飯を食べに外に出た。参考書籍として紹介した本をもう一度読み返そうと思って、鞄に入れてきていた。店に向かう道すがら、本を開く。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Electronアプリで型安全なIPC通信を実現する electron-trpcという選択肢]]></title>
            <link>https://zenn.dev/meziron/articles/82dfa259c30bf8</link>
            <guid isPermaLink="false">https://zenn.dev/meziron/articles/82dfa259c30bf8</guid>
            <pubDate>Wed, 03 Dec 2025 15:00:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。Electronアプリケーションの開発において、Main ProcessとRenderer Process間の通信（IPC）を型安全に実装することは、開発体験と保守性を高める上で重要な課題です。本記事では、electron-trpcを用いて、IPC通信の型安全性を効率的に確保する方法について解説します。 従来の課題：型定義の分散とボイラープレートElectron標準のIPC通信（ipcMain / ipcRenderer）を使用する場合、型安全性を確保しようとすると、記述量が増大しが...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ECSのService ConnectとService Discoveryの違いを理解する]]></title>
            <link>https://zenn.dev/iorandd/articles/20251204_aws-ecs-beginner</link>
            <guid isPermaLink="false">https://zenn.dev/iorandd/articles/20251204_aws-ecs-beginner</guid>
            <pubDate>Wed, 03 Dec 2025 15:00:01 GMT</pubDate>
            <content:encoded><![CDATA[本記事は若手AWS Leading Engineerを志す者達 Advent Calendar 2025の4日目の記事です。AWS Jr. Champions 2026 を目指すアドカレということで、業務でAmazon Elastic Container Service (ECS) を使ったマイクロサービス環境に触れる中で、Service Connect と Service Discoveryの違いを理解するために調べたことをまとめました。普段はスリーシェイクという会社でフルスタックエンジニアとしてWebアプリケーション開発に従事しています。会社の方でも3-shake Advent ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[kindle上で購入した書籍情報収集してみた]]></title>
            <link>https://zenn.dev/akasan/articles/kindle_books_bukurogu</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/kindle_books_bukurogu</guid>
            <pubDate>Wed, 03 Dec 2025 13:15:42 GMT</pubDate>
            <content:encoded><![CDATA[先日私が持っている物理本についてブクログで共有したという記事を公開させてもらいました。今回はkindle上で購入した書籍について情報を取得してみたので共有します。https://zenn.dev/akasan/articles/my_book_lists どうやって収集したか@YujiSoftware様のQiitaの記事を見つけ、拡張機能として利用してみました。https://qiita.com/YujiSoftware/items/8313687e64b33e9e546e一応拡張機能を入れるということで元のコードもGitHubで公開されていたのでみさせていただき、利用しても...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、努力しろ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/03/002023</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/03/002023</guid>
            <pubDate>Tue, 02 Dec 2025 15:20:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「おい、がんばるな」という言葉を書いた。あの文章を読み返して、私は少し後悔している。syu-m-5151.hatenablog.com言いたいことは分かる。がむしゃらに頑張ることが思考停止になる。忙しさが逃避になる。持続可能性が大事だ。それは正しい。私も経験してきたことだ。でも、あの文章には、書かなかったことがある。書けなかったことがある。「頑張らなくていい」という言葉が、どれほど危険な響きを持っているか。その言葉が、どれほど簡単に、怠惰の免罪符になってしまうか。私は「頑張るな」と言った。でも、それを読んだ人の中に、こう受け取った人がいるだろう。「そうか、頑張らなくていいんだ」「無理しなくていいんだ」「今のままでいいんだ」と。もしそう受け取った人がいたら、それは私の責任だ。だから、今日は別のことを書く。「おい、努力しろ」これは、あの文章への補足ではない。あの文章への反論だ。「頑張るな」という言葉の危うさを、私は書かなければならない。そして、「頑張ること」と「努力すること」の違いを、もっと正確に伝えなければならない。あの文章で私が本当に言いたかったのは、「頑張るな」ではなかった。「考えずに頑張るな」だった。でも、その「考えずに」という部分が抜け落ちて伝わってしまったら、メッセージは正反対になる。「頑張らなくていい」は、時に正しい。でも、多くの場合、それは逃げだ。そして、私たちが本当に必要としているのは、「頑張らないこと」ではない。「正しく頑張ること」——つまり、努力することだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「頑張らなくていい」という甘い毒「頑張らなくていい」という言葉は、優しく聞こえる。疲れ果てた人に、「もう頑張らなくていいよ」と言う。それは、救いの言葉だ。本当に限界に達している人には、その言葉が必要なときもある。でも、問題がある。この言葉は、本当に限界の人だけでなく、まだ余力がある人にも響いてしまうということだ。なぜか。人間は、楽な方に流れる生き物だからだ。これは誰もが持っている性質であり、責めるべきことではない。ただ、事実としてそうなのだ。「頑張らなくていい」と言われれば、「そうか、頑張らなくていいのか」と受け止める。そう感じること自体は自然だ。誰だって、許可があれば楽な方を選びたくなる。そして、頑張ることをやめる。でも、本当に頑張らなくてよかったのだろうか。ここで、正直に自分に問いかけてみてほしい。「頑張らなくていい」という言葉を聞いて、ホッとした時のことを思い出してほしい。その時、自分は本当に限界だっただろうか。本当に、これ以上一歩も進めない状態だっただろうか。体が動かない、頭が働かない、そういう状態だっただろうか。それとも、まだやれるのに、やらない言い訳を探していただけではなかっただろうか。私は、後者だったことが何度もある。疲れていた。それは本当だ。でも、限界ではなかった。もう少しやれば、もう少し先に進めた。「頑張らなくていい」という言葉が、私に許可を与えた。やめていい許可を。そして、私はやめた。その時は楽になった。肩の荷が降りた。「これでいいんだ」と感じた。でも、後から振り返ると、あの時やめなければよかったと後悔することがある。あと少し踏ん張っていれば、違う景色が見えただろう。あと少し続けていれば、突破口が開けただろう。「頑張らなくていい」は、甘い毒だ。本当に必要な人には薬になる。限界を超えて壊れそうな人には、その言葉が命を救うこともある。でも、必要でない人が飲むと、毒になる。成長の機会を奪い、可能性を閉じてしまう。そして、厄介なことに、自分が「本当に必要な人」なのかどうかは、自分では分からない。なぜなら、人間は自分に甘いからだ。自分の限界を、実際より低く見積もる傾向があるからだ。だから、この言葉は慎重に使わなければならない。そして、この言葉を聞いた時は、慎重に受け取らなければならない。「私は本当に限界なのか、それとも、逃げているだけなのか」。この問いから、逃げてはいけない。いまの自分にとって「頑張らなくていい」という言葉は、薬なのか、あるいは都合のいい麻酔なのか。その区別ができるのは、自分だけだ。誰かの優しさを、自分への甘さにすり替えるな。量をこなすことでしか見えないもの「甘い毒」の話をしてきた。次は、もう少し具体的な話をしたい。「量」の話だ。「おい、がんばるな」という文章で、私は「がむしゃらは若さの特権だ」と書いた。そして、「30歳からは戦略が必要だ」と書いた。これは、半分正しくて、半分間違っている。確かに、がむしゃらに量をこなすだけでは、どこかで限界が来る。効率を考えず、方向性を考えず、ただ時間を投入するだけでは、成果は出ない。それは正しい。でも、量をこなすことでしか見えないものがあるということを、私は書かなかった。どういうことか。何かを始めたばかりの頃、私たちは何も分からない。これは当然のことだ。何が正しいのか分からない。何が効率的なのか分からない。どの方向に進むべきか分からない。この状態で「効率」や「戦略」を考えても、意味がない。なぜか。効率や戦略を考えるためには、材料が必要だからだ。「このやり方は非効率だった」「あのやり方の方が良かった」という比較ができて、初めて効率が分かる。「この方向は間違いだった」「あの方向が正しかった」という経験があって、初めて戦略が立てられる。つまり、効率や戦略を語るためには、まず経験が必要なのだ。では、経験は、どこから来るのか。量をこなすことから来る。最初から効率的にやろうとすると、何が起きるか。何も始められなくなる。「どうやったら効率的か」を考えている間に、時間だけが過ぎていく。最適な方法を見つけようとして、いつまでも動き出せない。私はかつて、あるプログラミング言語を学ぼうとした時、まず「最も効率的な学習方法」を調べることに一週間を費やした。本を読み比べた。オンラインコースを比較した。学習ロードマップを作成した。「この本は評判がいい」「このコースは体系的だ」「こういう順序で学ぶべきだ」と、完璧な計画を立てようとした。一週間後、完璧な計画ができた。でも、一行もコードを書いていなかった。一方、別の言語を学んだ時は、何も考えずにチュートリアルを始めた。「とりあえずやってみよう」と思って、手を動かした。分からないところは飛ばした。エラーが出たら、エラーメッセージをググった。理解が曖昧なまま、とりあえず動くものを作った。非効率だった。無駄なことをたくさんした。後から「ああ、最初からこうすればよかった」と悔やむことが何度もあった。でも、後者の方が、圧倒的に速く身についた。なぜか。手を動かしていたからだ。手を動かすと、分からないことが具体化する。「何が分からないか分からない」という状態から、「これが分からない」という状態になる。そうなれば、調べようがある。学びようがある。これはエンジニアだけの話ではない。セールスも、CSも、デザイナーも、同じだ。セールスなら、100件の商談をこなして初めて「この業界の顧客は、この切り口で話すと響く」が分かる。CSなら、100件の問い合わせに対応して初めて「この機能のこの部分で、ユーザーはつまづく」が見えてくる。デザイナーなら、100個のプロトタイプを作って初めて「このパターンは使いやすい」という感覚が身につく。最初から「効率的なセールストーク」を設計しようとしても、机上の空論にしかならない。最初から「完璧なカスタマージャーニー」を描こうとしても、現実とズレる。まず量をこなすことで、何が効率的で、何が正しい方向なのかが、初めて見えてくる。これは、若者だけの話でもない。何か新しいことを始める時、誰もが初心者だ。30歳、40歳、50歳になっても、新しい領域に踏み出す時は、まず量をこなすしかない。「おい、がんばるな」で私が書いた「戦略」は、量をこなした後に見えてくるものだ。量をこなす前に戦略を立てようとしても、机上の空論にしかならない。だから、まず頑張れ。考えるのは、その後でいい。戦略を語りたければ、まず汗をかけ。効率を追求しすぎることの罠量をこなすことの価値を語った。では、量だけが大事なのか。そうではない。ここで、「効率」の話をしたい。「おい、がんばるな」で、私は効率の重要性を強調した。同じ成果を、より少ない投入で得ること。それが賢い働き方だと。これも、半分正しくて、半分間違っている。効率を追求することは、確かに重要だ。無駄なことに時間を使わない。最短距離で成果を出す。それは、賢いことだ。でも、効率を追求しすぎると、動けなくなるという罠がある。どういうことか。効率を追求するとは、「最小の投入で最大の成果を得ようとすること」だ。これ自体は良いことだ。でも、これを突き詰めると、どうなるか。「成果が保証されていないことには、投入しない」という態度になりやすい。なぜか。効率の計算をするためには、投入と成果の関係が見えている必要がある。「これだけ投入すれば、これだけの成果が得られる」という予測ができて、初めて効率が計算できる。だから、効率を重視するあまり、「成果が予測できること」だけを選ぶようになる。「この作業は、本当に必要か？成果につながるか？」「このアプローチは、本当に効率的か？もっと良い方法はないか？」「この投資は、本当にリターンがあるか？損をしないか？」。こう考え始めると、確実にリターンがあることにしか、時間を使えなくなる。でも、ここで立ち止まって考えてほしい。人生で最も価値のあるものは、リターンの不確実なものが多いのではないだろうか。新しいスキルを学ぶ。そのスキルが役に立つかどうかは、学ぶ前には分からない。学んでみて、使ってみて、初めて分かる。新しい人間関係を築く。その関係が実を結ぶかどうかは、関係を築く前には分からない。時間をかけて、信頼を積み重ねて、初めて分かる。新しいプロジェクトを始める。そのプロジェクトが成功するかどうかは、始める前には分からない。やってみて、失敗して、修正して、初めて分かる。効率を追求しすぎると、これらの「不確実なこと」に時間を使えなくなる。確実にリターンがあることだけをやるようになる。すると、どうなるか。安全な場所から出られなくなる。今までやってきたこと。確実にできること。リスクのないこと。そういうものだけをやり続ける。その結果、成長がない。変化がない。じわじわと、世界が狭くなっていく。新しいことに挑戦しないから、新しい可能性が開かれない。私は、効率を追求するあまり、「無駄なこと」を一切しなくなった時期がある。仕事に直接関係のない本は読まない。読んでも仕事の成果につながらないから。すぐに役立たない技術は学ばない。学んでも今の仕事では使わないから。「これは何の役に立つのか」が説明できないことには、時間を使わない。説明できないということは、効率が計算できないということだから。確かに、目の前の仕事は効率的にこなせるようになった。無駄がなくなった。短時間で成果が出るようになった。でも、新しいアイデアが浮かばなくなった。視野が狭くなった。仕事は回せるけど、面白い発想ができなくなった。つまらない人間になっていった。なぜか。「無駄」の中にこそ、予想外の価値があるからだ。一見無駄に見える読書が、思わぬところで仕事に活きる。すぐに役立たない技術が、数年後には大きな武器になる。「何の役に立つか分からない」経験が、人間としての厚みを作る。効率だけを追求すると、その「予想外の価値」を取りこぼしてしまう。だから、時には非効率を許容しろ。時には「何の役に立つか分からないこと」に時間を使え。それが、長期的には最も効率的な投資になることがある。効率やリターンが見えないことの中に、本当は心のどこかで「それでもやってみたい」と思っているものがないだろうか。その声を、効率という物差しで測って、黙らせていないだろうか。計算できないものにこそ、人生を変える何かが潜んでいる。「持続可能性」という名の逃げ道効率の話をしてきた。次は、もう1つの「賢そうな言葉」について考えたい。「持続可能性」だ。「おい、がんばるな」で、私は持続可能性の重要性を説いた。無理をしない。長く続けられるペースで。燃え尽きないように。これは正しい。燃え尽きて動けなくなったら、意味がない。長く続けることは確かに大事だ。でも、この言葉が逃げ道になることがある。どういうことか。「持続可能なペースで」と言うと、それは賢明に聞こえる。長期的な視点を持っている。自分を大切にしている。無理をしない。計画的だ。でも、その「持続可能なペース」は、本当に適切なのだろうか。ここで、人間の心理について考えてみたい。私たちは、自分の限界を過小評価しがちだ。「これ以上やったら壊れる」と感じる地点は、実際の限界よりもずっと手前にあることが多い。なぜか。人間は、不快なことを避けたい生き物だからだ。辛いこと、苦しいこと、面倒なことは、できれば避けたい。これは自然な感情だ。だから、実際に壊れるよりもずっと手前で、「もう限界だ」と感じてしまう。まだ余力があるのに、「これ以上は無理だ」と思ってしまう。「持続可能なペース」という言葉を使う時、私たちは無意識に、その「過小評価された限界」を基準にしていないだろうか。本当は、もう少し頑張れる。もう少し踏ん張れる。でも、「持続可能性」という言葉を使って、その踏ん張りを回避していないだろうか。「持続可能性」は、時に「楽をするための言い訳」になる。もちろん、本当に限界の人はいる。本当に休まなければならない人はいる。その人たちにとって、「持続可能性」は正当な理由だ。そういう人に「もっと頑張れ」と言うのは、暴力だ。でも、全員がそうではない。まだ余力があるのに、「持続可能性」を理由にブレーキをかけている人もいる。ここで、もう1つ正直に自分に問いかけてみてほしい。「持続可能なペース」と言った時、それは本当に「長期的に最適なペース」なのか。それとも、「今、楽でいられるペース」なのか。この2つは、似ているようで、全く違う。長期的に最適なペースは、時に短期的には辛い。なぜか。成長するためには、今の自分を超える必要があるからだ。今の自分を超えるためには、今の自分には辛いことをする必要がある。筋肉を鍛える時のことを考えてみてほしい。筋肉は、負荷をかけて、一度壊れて、修復される過程で強くなる。楽な負荷だけかけていても、筋肉は成長しない。能力も同じだ。今できることだけやっていても、能力は成長しない。今できないこと、今の自分には辛いことに挑戦して、初めて成長する。「持続可能性」を盾にして、その「辛いこと」を避けていたら、成長はない。踏ん張るべき時には、踏ん張れ。いつでも快適でいようとするな。不快さの中にこそ、成長がある。最近、「持続可能性のため」と言ってブレーキを踏んだ場面を思い出してほしい。それは本当に長期のためだっただろうか。それとも、今ラクでいたい自分のためだっただろうか。答えは、自分の中にしかない。「持続可能性」は免罪符じゃない。逃げ道を正当化する言葉でもない。苦しみの中でしか得られないものここまで、「甘い毒」「量」「効率」「持続可能性」の話をしてきた。これらに共通するのは、「苦しみとどう向き合うか」という問いだ。次は、その「苦しみ」について、もう少し直接的に語りたい。「おい、がんばるな」で、私は「苦しみを美化するな」と書いた。苦しむこと自体には価値がない。同じ成果を楽に得られるなら、その方がいいと。これも、半分正しくて、半分間違っている。確かに、苦しむこと自体を目的にするのは間違っている。苦しめば偉いわけではない。苦労すれば成果が出るわけではない。無意味な苦しみは、ただの消耗だ。でも、苦しみの中でしか得られないものがあるということも、事実だ。それは何か。自分が何者であるかを知ることだ。どういうことか。人間は、追い込まれた時に、本当の自分が出る。楽な時、余裕がある時には、本当の自分は見えない。余裕があると、取り繕える。自分を良く見せられる。でも、苦しみの中では、取り繕う余裕がなくなる。本当の自分が、否応なく姿を現す。自分は、どこまで耐えられるのか。限界だと思った先に、まだ力が残っているのか。自分は、何を諦められないのか。何を捨てても、これだけは手放せないというものは何なのか。自分は、何のために頑張れるのか。お金のためか、評価のためか、それとも、もっと別の何かのためか。これらの問いに対する答えは、快適な場所にいては見つからない。不快な場所に身を置いて、初めて見えてくる。私は、あるプロジェクトで、本当に追い込まれた経験がある。締め切りは迫っている。スケジュールは遅延している。チームは疲弊している。メンバーの顔に疲労が見える。問題は山積みだ。1つ解決すると、別の問題が浮上する。毎日が綱渡りだった。辛かった。何度も逃げ出したいと思った。「こんなの、持続可能じゃない」と思った。「なんでこんなことをしているんだろう」と思った。でも、あの経験がなければ、今の自分はいない。これはエンジニアだけの話ではない。セールスなら、どうしても落とせない大型案件に挑み続けた経験。何度も断られ、それでも食らいついた経験。その中で「自分は何のために営業をしているのか」が見えてくる。CSなら、クレームが殺到した時期を乗り越えた経験。理不尽に怒られ、なお丁寧に対応し続けた経験。その中で「自分はどこまでユーザーに寄り添えるのか」が見えてくる。現場で働くすべての人に、そういう経験がある。あの時、自分が何を大切にしているのかが分かった。チームのために最後まで踏ん張りたいと思っている自分がいた。良いものを作りたいと思っている自分がいた。自分がどこまで頑張れるのかが分かった。「もう無理だ」と思ったところから、より三歩進めた。限界だと思っていたところは、限界ではなかった。そして、自分がそこまで頑張れるという自信が、あの経験から生まれた。この自信は、快適な場所では得られない。苦しみを乗り越えた経験からしか得られない。「あの時、あれだけ辛いことを乗り越えた」という記憶は、次の困難へ立ち向かう力になる。「あの時できたのだから、今回もできる」という自信は、前へ進む勇気になる。だから、苦しみを避けるな。もちろん、無意味な苦しみは避けるべきだ。方向が間違っているなら、修正すべきだ。でも、正しい方向に進んでいるなら、苦しみを恐れるな。その苦しみの中に、あなたのまだ知らない自分がいる。苦しみを避けて到達する場所に、本当の自分はいない。「休むこと」を過大評価していた苦しみの話をしてきた。では、苦しみの反対にある「休息」は、どうだろうか。「おい、がんばるな」で、私は休むことの重要性を強調した。休憩は投資だ。睡眠は投資だ。休むことで、生産性が上がると。これは正しい。休息は大事だ。睡眠不足は判断力を鈍らせる。疲労は生産性を下げる。でも、休むことを過大評価していたという反省もある。どういうことか。休むことが重要なのは、その後にまた頑張るためだ。休息は、次の活動のための準備だ。体を回復させ、頭をリフレッシュさせ、また動き出すための準備だ。つまり、休息の価値は「その後の活動」によって決まる。休んだ後に何もしないなら、休息の意味がない。でも、「休むことが大事」という言葉を聞くと、休むこと自体が目的になってしまうことがある。「今日は休む日だから、何もしない」「疲れているから、休まなきゃ」「持続可能性のために、休息を取る」。そう言いながら、ずっと休んでいる。次の活動が、いつまでも始まらない。休息は、活動のための手段だ。休息自体が目的ではない。この区別を忘れると、「休むこと」が「何もしないこと」にすり替わってしまう。私は、「休息も投資だ」と言いながら、実際には逃避していた時期がある。「今日は休む」と言いながら、本当は面倒なことを避けていた。やるべきことがあるのに、「疲れているから」と言って、やらなかった。「持続可能性のため」と言いながら、実際には楽をしていた。もう少し頑張れる状態なのに、「無理は禁物だから」と言って、手を抜いた。休息と逃避は、外からは区別がつかない。どちらも「何もしていない」ように見える。区別できるのは、自分だけだ。これはエンジニアだけの話ではない。セールスなら、「今日は疲れているから、あのリードへの連絡は明日にしよう」と言い続けて、結局連絡しないまま案件を逃すことがある。CSなら、「この問い合わせは複雑だから、体調が良い時に対応しよう」と言い続けて、対応が遅れてユーザーの信頼を失うことがある。どの職種でも、「休息」と「先延ばし」の境界は曖昧だ。自分に正直に問いかけてほしい。今、休んでいるのは、次に頑張るための準備なのか。それとも、頑張ることから逃げているだけなのか。この2つは、外見は同じでも、本質は全く違う。次に頑張るための休息には、終わりがある。回復したら、また動き出す。頑張ることからの逃避には、終わりがない。いつまでも「まだ疲れている」「まだ準備ができていない」と言い続ける。前者なら、休め。後者なら、立ち上がれ。休息は充電だ。放電しないなら、充電する意味はない。「考えること」を言い訳にするな休息の話をしてきた。次は、もう1つの「賢そうな行為」について考えたい。「考えること」だ。「おい、がんばるな」で、私は「考えること」の重要性を説いた。がむしゃらに動くな。立ち止まって考えろ。方向性を確認しろと。これは正しい。考えずに動くと、間違った方向に全力で進んでしまう。それは危険だ。でも、「考えること」が行動しない言い訳になることがある。どういうことか。「まだ考えがまとまっていない」「もう少し情報が必要だ」「方向性を確認してから動きたい」。こう言いながら、いつまでも動かない人がいる。考えることは大事だ。でも、考えているだけでは、何も起きない。なぜか。世界は、行動によってしか変わらないからだ。頭の中でどれだけ完璧な計画を立てても、行動しなければ、現実は何も変わらない。素晴らしいアイデアがあっても、実行しなければ、ただの妄想だ。そして、皮肉なことに、行動しないと、本当に必要な情報は手に入らない。何かを始める前は、何が分からないかも分からない。何が問題になるかも分からない。どこが難しいかも分からない。頭の中で考えているだけでは、これは分からない。机上で計画を立てているだけでは、見えてこない。実際にやってみて初めて分かる。手を動かし、困難にぶつかり、失敗して初めて「ああ、ここが問題だったのか」と分かる。だから、「もっと考えてから」「もっと情報を集めてから」と言い続けていると、永遠に動き出せない。必要な情報は、動き出さないと手に入らないからだ。これはエンジニアだけの話ではない。セールスなら、「この業界のことをもっと調べてから提案しよう」と言い続けて、結局一度も商談に臨まないことがある。しかし、実際に商談に出て、顧客の反応を見て、初めて「この業界は価格よりもサポート体制を重視する」が分かる。CSなら、「この機能の仕様をもっと理解してから対応しよう」と言い続けて、結局ユーザーを待たせてしまうことがある。ただ、実際に対応しながら調べ、先輩に聞くことで「この機能は、こういう使い方をするユーザーがいる」と分かる。どの職種でも、動くことでしか得られない知識がある。これは鶏と卵のような問題に見えるだろう。動くためには情報が必要だ。しかし、情報を得るためには動く必要がある。どうすればいいのか。答えは、不完全なまま動き始めることだ。完璧な計画を待つな。不完全なまま始めろ。間違っているだろう。失敗するだろう。それでも、始めなければ、何も始まらない。動きながら考えろ。走りながら修正しろ。考えることと動くことは、どちらか一方ではない。順番に行うものでもない。両方同時にやるものだ。動きながら考え、考えながら動く。そうすることで、より良い方向に、より速く進める。「まだ準備ができていない」「もう少し考えてから」と言って先送りしていることがあるなら、立ち止まって考えてみてほしい。それは本当に考える段階なのか。それとも、動くことを怖がっているだけなのか。考えることと、考えているふりをして逃げることは、違う。準備が整う日は、永遠に来ない。来たと思える日は、動き始めた後にしか訪れない。では、何が「努力」なのかここまで、「頑張らなくていい」という言葉の危うさを書いてきた。量をこなすことの価値。効率を追求しすぎることの罠。持続可能性が逃げ道になること。苦しみの中でしか得られないもの。休むことの過大評価。考えることが言い訳になること。では、結局、何をすればいいのか。ここで、「頑張ること」と「努力すること」を区別したい。頑張ることは、「とにかくやること」だ。方向も考えず、効率も考えず、ただ時間とエネルギーを投入する。がむしゃらに動く。汗をかく。疲れる。これは「おい、がんばるな」で批判したことであり、確かに問題がある。方向が間違っていたら、どれだけ頑張っても成果は出ない。努力することは、「考えながらやること」だ。方向を意識し、フィードバックを得て、修正しながら進む。効率を考える。戦略を立てる。ただ、考えるだけでなく、実際に動く。これは、頑張ることとは違う。しかし、努力には「やること」が含まれている。ここが重要なポイントだ。「考えること」だけでは、努力ではない。「やること」が必要だ。そして、「やること」には、しばしば苦しみが伴う。不快さが伴う。疲労が伴う。それを避けていたら、努力にはならない。努力とは、正しい方向に向かって、苦しみを引き受けながら、行動し続けることだ。もう少し分解して説明しよう。まず、「正しい方向に向かって」。これは、考えることだ。自分は何を達成したいのか。どこに向かいたいのか。そのためには、何をすべきか。これを考える。次に、「苦しみを引き受けながら」。これは、踏ん張ることだ。辛くても、やる。不快でも、続ける。逃げ出したくなっても、踏みとどまる。そして、「行動し続ける」。これは、動くことだ。考えるだけでなく、実際に手を動かす。失敗しても、また動く。続ける。この三つが揃って、初めて「努力」になる。これはどの職種でも同じだ。エンジニアなら、正しいアーキテクチャを考え、難しいバグと格闘しながら、コードを書き続ける。セールスなら、顧客の課題を考え、断られる辛さを引き受けながら、提案を続ける。CSなら、ユーザーの真のニーズを考え、クレームの辛さを引き受けながら、対応を続ける。デザイナーなら、ユーザー体験を考え、何度もダメ出しされる辛さを引き受けながら、デザインを続ける。どの仕事でも、努力の構造は同じだ。「頑張るな」と言って、苦しみを避けることを正当化してはいけない。苦しみは、努力の一部だ。「考えろ」と言って、行動しないことを正当化してはいけない。行動は、努力の一部だ。方向を考えながら、苦しみを引き受けながら、行動し続ける。それが、努力だ。楽をしながら成長はできない。考えるだけで変わることもできない。誘惑という名の逃げ道努力の定義をした。正しい方向に向かって、苦しみを引き受けながら、行動し続けること。それが努力だと書いた。しかし、ここで正直に認めなければならないことがある。努力するのは、難しい。なぜか。現代社会には、努力から逃げるための誘惑が溢れているからだ。スマホを開けばSNSが待っている。通知が鳴り続ける。動画は自動再生される。情報は洪水のように押し寄せる。疲れた時、辛い時、つい手が伸びる。「ちょっと休憩」と言いながら、気づけば1時間、2時間が過ぎている。これは、休息ではない。逃避だ。先ほど「休むことの過大評価」の話をした。ここでも同じことが起きている。私たちは「少し気分転換」と言いながら、実際には努力から逃げている。ここで、1つの考え方を紹介したい。ジェイ・シェティという作家がいる。彼は実際に僧侶として修行した経験を持ち、その経験をもとに「モンク思考」という考え方を世界に広めた。私たちはつい、他人と年収を比べたり、社会的なイメージで仕事を選んだりしてしまう。「成功とはこういうもの」「幸せとはこういうもの」という外側からの定義に、無意識に縛られている。しかし、本当はどのような人生を送りたいのか。本当はどのような人間になりたいのか。この問いに、自分の言葉で答えられるだろうか。彼が説くのは、「手放す」「成長する」「与える」という3つのステップだ。まず、執着を手放す。他人の評価、過去の成功体験、「こうあるべき」というプレッシャー。これらを握りしめていると、本当に大切なものが見えなくなる。次に、自分の情熱と才能に向き合う。何をしている時に時間を忘れるか。何に取り組んでいる時に充実感を感じるか。他人の期待ではなく、自分の内側から湧き上がるものを見つける。そして、目的を持って生きる。自分のためだけに努力するのではなく、誰かのために、何かのために努力する。その方が、長く続く。強く踏ん張れる。この考え方の核心は、「小さなノー」の積み重ねだ。SNSを見ない。無駄な飲み会を断る。ダラダラとネットサーフィンしない。1つ1つは小さな「ノー」だ。しかし、この小さな「ノー」を積み重ねることで、本当に大切なことに「イエス」と言えるようになる。誘惑に「ノー」と言うことで、努力に「イエス」と言える。私たちは、誘惑に負けるたび、自分を少しずつ裏切っている。「今日くらいいいか」「疲れているから仕方ない」「明日から頑張ろう」。そう言いながら、努力から逃げている。その言い訳を、いつまで続けるのか。永遠に僧侶のように生きる必要はない。ただ、誘惑を言い訳にするのをやめろ。集中できないのは環境のせいではない。自分が誘惑を選んでいるだけだ。スマホを閉じろ。通知をオフにしろ。そして、今やるべきことに向き合え。それが、努力の第一歩だ。踏ん張るべき時に踏ん張れ努力の定義をした。最後に、1つのことを言いたい。人生には、踏ん張るべき時がある。チャンスは、いつでも来るわけではない。絶好の機会は、そう何度もあるわけではない。その時が来た時に踏ん張れるかどうかで、人生は変わる。踏ん張るべき時に「持続可能性が」と言って引いてしまったら、チャンスを逃す。踏ん張るべき時に「効率が」と言って計算してしまったら、大事なものを取りこぼす。踏ん張るべき時に「休息が」と言って立ち止まってしまったら、流れに乗れない。踏ん張るべき時には、理屈を超えて、踏ん張れ。これはどの職種でも同じだ。エンジニアなら、リリース前の追い込み、障害対応、重要な技術選定の議論。セールスなら、年度末のクロージング、大型案件のコンペ、重要な顧客との交渉。CSなら、大規模障害時のユーザー対応、重要顧客の離脱防止、クリティカルなクレームへの対応。どの仕事にも、「ここが勝負所」という瞬間がある。その瞬間に踏ん張れるかどうかで、キャリアは変わる。もちろん、いつも踏ん張れとは言わない。いつも踏ん張っていたら、壊れる。それは「おい、がんばるな」で書いた通りだ。だからこそ、踏ん張るべき時を見極めることが大事だ。普段は力を温存し、ペースを守り、回復する時間を取る。そして、その時が来たら、全力で踏ん張ることが大事だ。温存していた力を、すべて出し切る。「おい、がんばるな」は、「いつも踏ん張っている人」に向けた言葉だった。常にアクセル全開で、休むことを知らない人。そういう人には、確かに「踏ん張りすぎるな」と言う必要がある。一方で、世の中には、踏ん張るべき時に踏ん張れない人もいる。チャンスが来ても、「疲れているから」「リスクがあるから」「まだ準備ができていないから」と言って、見送ってしまう人。そういう人に「頑張らなくていい」と言ったら、それは間違ったメッセージになる。自分がどちらのタイプか、正直に考えてほしい。いつも踏ん張りすぎて疲弊しているなら、少し力を抜いていい。しかし、踏ん張るべき時に踏ん張れていないなら、今こそ踏ん張る時だ。この一年を振り返ってみてほしい。「あそこであと一歩踏ん張っていれば」と、未来の自分に言われそうな場面はないだろうか。もしあるなら、それが答えだ。次にその場面が来た時、同じ後悔をしないために、今から準備しておくことだ。チャンスは、準備している人のところにしか来ない。来ても、踏ん張れなければ、すり抜けていく。何もしなくても誰かがお膳立てしてくれて、機会が向こうからやってくる。そんな恵まれた環境が、いつまでも続くと信じるな。続いたとしても、それは成長ではない。ただの停滞だ。ここで、厳しいことを言う。世の中は理不尽で、不公平だ。生まれた環境も、与えられた才能も、巡ってくる機会も、平等ではない。それは事実だ。口で何を言っても、不満を並べても、愚痴をこぼしても、その現実は変わらない。SNSで正論を叫んでも、飲み会で上司の悪口を言っても、世の中は1ミリも動かない。行動しなければ、努力しなければ、状況は何も変わらない。これは冷たい言葉ではない。むしろ、希望の言葉だ。なぜなら、行動すれば変わる可能性があるということだからだ。理不尽な世界の中で、自分の手で変えられるものがある。それが、努力だ。ここで、1つの反論が聞こえてくる。「そもそも、このゲーム自体がおかしいのではないか」と。努力すれば成功者が増えるのか。全員が頑張れば、全員が報われるのか。答えはノーだ。構造的に、成功者の席は限られている。全員が努力しても、椅子取りゲームの椅子は増えない。格差は縮まるどころか、広がり続ける。能力主義という名のレースは、走れば走るほど、差が開いていく仕組みになっている。それは、経済学的にも、社会学的にも、既に答えが出ている話だ。では、このゲームから降りればいいのか。「こんな不公平なレースには参加しない」と宣言すればいいのか。私は、その選択を否定しない。降りる自由はある。しかし、自分に問いかけてみてほしい。降りたところで、何が開けるのか。レースから降りた先に、別の人生があるのか。不参加を表明したところで、この社会の中で生きていくことに変わりはない。構造を批判しながら、その構造の中で生きていく。それが、大半の人間の現実だ。だから私は、こう考える。ゲームがおかしいことは分かっている。ルールが不公平なことも分かっている。それでも、このゲームの中で生きていく以上、このゲームの中での戦い方を身につけるしかない。構造を変えることは、個人の努力ではほぼ不可能だ。でも、構造の中での自分の位置を変えることは、できる可能性がある。それが、努力だ。大事なのは、その理不尽さや不公平さを、腹の底から受け入れることだ。「なぜ自分だけ」「もっと恵まれていれば」という思いを抱えたまま努力しても、どこかで折れる。被害者意識を持ったまま走っても、長くは続かない。世の中が不公平であることを認めた上で、それでも前に進む。不公平を嘆く暇があるなら、その時間で一歩でも進め。理不尽に怒るエネルギーがあるなら、そのエネルギーを努力に変えろ。それが、この不完全な世界で生き抜くための唯一の方法だ。努力せずに目標が達成できると、本気で信じているなら教えてほしい。努力もせずに、この淀んだ自分という檻から抜け出せると、本気で信じているなら教えてほしい。私は信じていない。自分を変えるには、努力が必要だ。今の自分を超えるには、苦しみを引き受ける必要がある。檻から出るには、その困難を押し続ける必要がある。それを避けて、「頑張らなくていい」という言葉に逃げ込んでも、檻は壊れない。自分は変わらない。淀んだ水は、そのまま淀み続ける。努力なしに変われると信じるな。苦しみなしに成長できると信じるな。檻を壊すのは、他の誰でもない、自分自身だ。ここまで厳しいことを書いてきた。しかし、1つだけ、白状させてほしい。私は、自分のことを特別だと思えたことがない。ふとした瞬間に気づく。ああ、俺は凡人だな、と。天才じゃない。選ばれた側の人間でもない。器には限界がある。どうしようもなく、限界がある。周りを見れば、自分より優秀な人間なんていくらでもいる。悔しいが、事実だ。そして、もう1つ。万全の状態で仕事に臨める日なんて、一生来ない。体調が悪い。眠れていない。私生活がぐちゃぐちゃだ。そんな日の方が、圧倒的に多い。それでも、やる。最悪の日であっても、最低限の水準は守る。それがプロだ。凡人だから、積み上げるしかない。万全を待っていたら何も始まらないから、不完全なままでも動ける自分を作るしかない。おわりに「おい、がんばるな」と書いた。今日は「おい、努力しろ」と書いた。矛盾しているように見えるだろう。しかし、矛盾していない。どちらも、同じことを言っている。「考えずに頑張るな」「ただし、考えながら頑張れ」。これを一言で言えば、「努力しろ」だ。努力には、考えることが含まれている。方向を意識することが含まれている。フィードバックを得ることが含まれている。同時に、努力には、行動することも含まれている。苦しみを引き受けることも含まれている。踏ん張ることも含まれている。「頑張るな」という言葉だけを受け取って、行動しなくなってはいけない。苦しみを避けてはいけない。踏ん張ることをやめてはいけない。考えながら、頑張れ。方向を意識しながら、踏ん張れ。それが、努力だ。「おい、がんばるな」は、片面だけを描いた絵だった。今日は、もう片面を描いた。両方を見て、初めて全体が見える。——と言いたいところだが、正直に言えば、これでもまだ全体ではない。この問題には、2つの面だけでなく、もっと多くの面がある。私が見えていない角度がある。私が経験していない状況がある。私が想像すらできていない視点がある。たとえば、心身の病を抱えている人にとって、「努力しろ」という言葉がどう響くか。私には、本当の意味では分からない。あるいは、社会的な制約の中で選択肢が限られている人にとって、「踏ん張れ」という言葉がどう響くか。私には、本当の意味では分かっていない。私が書いたのは、私の経験から見えた2つの面に過ぎない。他にも面はある。3つ目も、4つ目も、おそらくもっとたくさんある。それは自覚している。だから、この文章を「正解」として読まないでほしい。これは、1つの視点だ。私という人間が、私の経験を通して見た、1つの景色だ。あなたには、あなたの景色がある。あなたの経験から見える面がある。それは、私には見えない面だろう。あなたが今、どちらの言葉を必要としているかは、あなた自身にしか分からない。頑張りすぎて疲弊しているなら、「おい、がんばるな」を読んでほしい。頑張れずに停滞しているなら、「おい、努力しろ」を読んでほしい。どちらの状態にいても、前に進むことをやめるな。前に進むとは、行動することだ。考えることだ。苦しみを引き受けることだ。そして、それを続けることだ。おい、努力しろ。考えながら、頑張れ。方向を見据えながら、踏ん張れ。休みながらも、また立ち上がれ。それが、あなたを前に進ませる唯一の方法だ。参考書籍バカと無知 (新潮新書)作者:橘　玲新潮社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon実力も運のうち　能力主義は正義か？ (ハヤカワ文庫NF)作者:マイケル サンデル早川書房Amazonデジタル・ミニマリスト　スマホに依存しない生き方 (ハヤカワ文庫NF)作者:カル ニューポート早川書房AmazonSLOW　仕事の減らし方――「本当に大切なこと」に頭を使うための３つのヒント作者:カル・ニューポートダイヤモンド社Amazon大事なことに集中する―――気が散るものだらけの世界で生産性を最大化する科学的方法作者:カル・ニューポートダイヤモンド社Amazon深い集中を取り戻せ――集中の超プロがたどり着いた、ハックより瞑想より大事なこと作者:井上一鷹ダイヤモンド社Amazonジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazonクリティカル・ビジネス・パラダイム――社会運動とビジネスの交わるところ作者:山口 周プレジデント社Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon知的戦闘力を高める 独学の技法作者:山口 周ダイヤモンド社Amazonモンク思考―自分に集中する技術作者:ジェイ・シェティ東洋経済新報社AmazonSENSE FULNESS　どんなスキルでも最速で磨く「マスタリーの法則」作者:スコット・Ｈ・ヤング,小林　啓倫朝日新聞出版Amazon新版　究極の鍛錬作者:ジョフ・コルヴァンサンマーク出版Amazon心眼――あなたは見ているようで見ていない作者:クリスチャン・マスビアウプレジデント社AmazonQUEST「質問」の哲学――「究極の知性」と「勇敢な思考」をもたらす作者:エルケ・ヴィスダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIエージェントによるブログレビュー環境の構築（下）]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/03/001146</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/03/001146</guid>
            <pubDate>Tue, 02 Dec 2025 15:11:46 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2025 3日目のエントリ記事です。上巻の振り返り上巻では、Commandsを使ったブログレビュー環境の基礎を説明しました。/deep-thinking-prompt で書く前に深く考える/blog-quality-review で6つの観点からレビューする/ai-humanity-check でAIっぽさを検出する/full-review で全自動レビューするこれらのCommandsは、レビュー観点を構造化し、一貫性を担保してくれます。syu-m-5151.hatenablog.com下巻では、より高度なSubagentsの活用へ入る前に、いくつかの話題を深掘りします。AIに記事を書かせるとは何か「AIに記事を書かせる」という言葉をめぐって、しばしば議論が起きます。「それは本当にあなたの記事なのか」「AIが書いたものに価値があるのか」。私の答えは明確です。記事はほとんどAIに書かせています。しかし、価値の源泉は私にあります。手書きで書いているという人も別に紙に直接書いている訳ではないでしょう。既に、予測変換やLSP（Language Server Protocol）による補完など、さまざまなレベルで「AIやコンピュータの支援」を受けながら文章を書いています。その延長線上に、生成AIによる執筆があるに過ぎません。では、私は何を担っているのでしょうか。「身体性」を供給しています。ここで言う身体性とは、知識が「情報」から「経験」へと変容する過程で生じる、一人称的な認知の軌跡です。知識と経験の断絶たとえば、あるエンジニアがRustの所有権システムを学んでいるとします。The Bookを読み、概念は「理解した」つもりでいました。しかしいざコードを書くと、コンパイラからcannot borrow as mutable...というエラーを食らいます。「ルールは知っているはずなのに、なぜ」——この「知っている」と「書ける」の間にある断絶こそが、身体性が欠落している状態です。そして、その断絶を越えた瞬間の記録があります。「なぜエラーになったのか格闘し、イテレータの内部構造に気づき、腹落ちした瞬間」——これこそが身体性を伴った学習の言語化です。それは他者に伝達可能な「生きた知見」となります。この「苦闘から理解への遷移（プロセス）」だけは、AIには生成できません。AIは私の代わりに試行錯誤できませんし、私の代わりとしてコンパイラに叱られて悔しがることもできないからです。AIの役割は、私が供給した「生の体験（身体性）」を、他者が読める文章として整えることにあります。混沌とした思考を構造化し、読者にとって消化しやすい形に変換します。それは編集者の仕事に近いです。私が素材（身体性）を提供し、AIが構造化し、私がレビューして調整します。この協働のプロセス全体が、現代における「執筆」なのです。「流暢な嘘」という罠一方で、「AIで書いた記事には価値がない」という批判も、ある意味では正しいです。問題の本質は「AIを使ったこと」ではなく、「検証というプロセスが抜け落ちていること」にあります。AIに丸投げして出力された文章には、不正確な情報の垂れ流しという致命的なリスクが潜みます。厄介なのは、AIの生成する文章が文法的に完璧で、論理の構成も美しすぎることです。人間が書いた拙い文章なら「この人、理解していないな」と直感的に警戒できます。しかし、AIの出力は「もっともらしさ（Plausibility）」に特化しているため、嘘であってもスルスルと頭に入ってきてしまいます。これを検証せずに公開するのは、ブレーキの効かない車を公道に放つようなものです。LLMは確率的に「次の単語」を選んでいるに過ぎません。そこに真偽への誠実さは存在しません。だからこそ、その確率の波を制御し、事実という地面に杭を打つのは、人間にしかできない仕事です。私たちは、AIというエンジンの出力に酔うのではなく、冷静な「監修者」であり続けなければなりません。しかし、この監修作業を人間の力だけで行うには限界があります。だからこそ、「AIを監視するAI」が必要になるのです。それがこれから紹介する「Sub-agents」によるレビュー体制です。Commandsの限界とSub-agentsの登場上巻で紹介したCommands（/blog-quality-reviewなど）は便利ですが、長く使っていると2つの困難にぶつかります。コンテキストの枯渇: 長文記事に対し、複数の観点で深いレビューを繰り返すと、メインの会話履歴（コンテキストウィンドウ）がすぐに溢れてしまう。専門性の欠如: 1つのプロンプトにあらゆる指示を詰め込むと、焦点がぼやけ、鋭い指摘ができなくなる。そこで導入したのが、Claude Codeの強力な機能、Sub-agentsです。Sub-agentsとは何かhttps://code.claude.com/docs/en/sub-agents:embed:citeSub-agentsは、特定のタスクに特化した自律的なAIワーカーです。これまでの「Commands（定型文の挿入）」とは、根本的にアーキテクチャが異なります。1. コンテキストの分離（Context Isolation）これが最大にして最強のメリットです。通常、長い記事をレビューさせると、「思考過程」や「中間生成物」でメインの会話履歴が埋め尽くされてしまいます。しかしSub-agentsは、メインとは独立した別のコンテキストウィンドウで作業します。完全にレビュワーに徹することができます。もちろんデメリットもあるので使い分けが必要です。User │ ▼Main Agent │ [Delegate] 記事テキストを渡し、レビューを依頼 ▼Sub-Agent (Reviewer) ┃ ★独自のコンテキストで思考★ ┃ 1. 全文読み込み ┃ 2. 批判的検討 ┃ 3. 推敲（ここのトークンはメインには見えない） ┃ ▼Main Agent (レビュー結果の要約のみを受取) │ ▼User (修正案の提示)メインエージェントが受け取るのは、Sub-agentが導き出した「結論」だけです。これにより、メインのコンテキストを汚染することなく、大量のトークンを使った深い推論が可能になります。2. 自律的な委譲（Delegation）Commandsはユーザーが手動で呼び出すものですが、Sub-agentsはメインのエージェント（Orchestrator）が必要だと判断した時に自動的に呼び出されます。「この記事、なんか読みづらいから直して」と指示するだけで、メインエージェントが「これは『文章校正エージェント』と『構成作家エージェント』の出番だ」と判断し、仕事を割り振ります。私が実際に配備しているSub-agents私は現在、ブログ執筆チームとして以下のSub-agentsを .claude/agents/ に配備しています。実際にはもっといますが、今回は3つだけ実際に使っているものを紹介します。1. narrative-architect.md （物語構造の専門家）技術記事であっても、読者の感情を動かす「物語」が必要です。このエージェントは、技術的な正しさには口を出しません。その代わり、「読者の感情の旅路（Emotional Journey）」だけを見ます。役割: 導入で共感を得られているか。解決策の提示でカタルシスがあるか。指摘例: 「機能の説明は正確だが、読者が抱えている『辛さ』への共感が不足しており、解決策の価値が伝わりにくい」2. fresh-eye-reviewer.md （永遠の初学者）私の「書き手の呪い」を解くためのエージェントです。ペルソナとして「実務未経験のジュニアエンジニア」が埋め込まれています。役割: 専門用語の困難、論理の飛躍、「なぜ」という素朴な疑問の発見。特徴: 文脈をあえて読まない。「ここまでの説明では、この単語の意味がわからない」と冷徹に指摘する。3. ai-police.md （AI警察）「AIっぽさ」を検知し、排除する専門官です。AIが生成した文章特有の「過剰な接続詞」「中身のない美しいまとめ」「冗長な言い回し」を検挙します。役割: テキストの人間らしさ（Humanity Score）の判定。指摘例: 「『〜ということができる』は冗長だ。『〜できる』と言い切るべき。また、この段落の『いかがでしたか』はAI臭いので削除を推奨する」実践：レビュー体制の構築これらのSub-agentsを連携させることで、私のブログ執筆フローは完全に変わりました。ディレクトリ構造.claude/├── commands/           # ユーザーが叩くショートカット│   └── full-review.md  # 全体を統括する指示書└── agents/             # 自律的に動く専門家たち    ├── narrative-architect.md    ├── fresh-eye-reviewer.md    └── ai-police.mdレビューの流れStep 1: 執筆（協働）私とメインエージェントで対話しながら、記事のドラフトを作成します。私は身体性（エピソード）を話し、エージェントがそれを整えます。Step 2: 全自動レビュー（委譲）書き上がったドラフトに対し、私は一言こう告げるだけです。「/full-review を実行して」すると、メインエージェントが裏側で複数のSub-agentsを起動します。Fresh Eye が「ここがわからない」と文句を言う。Narrative Architect が「構成が退屈だ」と指摘する。AI Police が「AIっぽい表現がある」と警告する。Step 3: 統合と修正メインエージェントは、これらのバラバラな意見を統合し、優先順位をつけて私に提示します。「初学者にとって難解な部分があり、かつAI特有の冗長な表現が残っています。まずは第2章の具体例を修正しましょう」私はその統合されたレポートを見て、最後に修正します。まとめ上巻から下巻を通じて、生成AIエージェントを用いたブログレビュー環境の構築について解説してきました。上巻: ブログの評価基準をCommandsで構造化し、手動レビューの面倒臭さを解消する方法。下巻: Sub-agentsを用いてコンテキストを分離し、専門特化した「編集チーム」を作る方法。この環境を構築して気づいたのは、私の仕事が「執筆者（Writer）」から「編集長（Editor in Chief）」へとシフトしたということです。実際に手を動かして書く（Generate）のはAIでしょう。しかし、「何を書くか（企画）」「なぜ書くか（熱量）」「品質は十分か（承認）」を判断するのは、人間にしかできません。AIエージェントは、我々から仕事を奪うものではありません。我々を、より高次な意思決定を行う「マネージャー」へと押し上げてくれる存在です。もしあなたが「記事を書くのが面倒だ」「自分の文章に自信がない」と感じているなら、まずは小さなCommandを1つ作ることから始めてみてください。そこには、孤独な執筆作業とは違う、頼れるバディとの協働が待っているはずです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[iPadで学習してよかった話]]></title>
            <link>https://zenn.dev/akasan/articles/ipad_iiyone_apps</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/ipad_iiyone_apps</guid>
            <pubDate>Tue, 02 Dec 2025 12:36:22 GMT</pubDate>
            <content:encoded><![CDATA[今回は私が普段どうやってiPadを使って学習しているか共有しようと思います。 使っているiPad私が普段勉強で使っているiPadのスペックは以下になります。iPad mini A17 Proストレージ：256GBApple Pencilあり勉強用ではありますが、持ち運びを重視してminiにしています。もちろん大きな画面でノートを撮るといったような使い方はできませんが、特に不自由は感じてないです。 使っているアプリ Kindle元々は紙の本が好きではあったんですが、物理的に置く場所の限界が来たことや、どこでも時間が空いた時に読めることを重視してKindle上で書...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、がんばるな]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/02/124702</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/02/124702</guid>
            <pubDate>Tue, 02 Dec 2025 03:47:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに先日、久しぶりに会った友人に言われた。「なんか最近、顔が疲れてない？」と。私は「まあ、仕事が忙しくて」と答えた。友人は「頑張ってるんだね」と言って、ビールを一口飲んだ。頑張ってる。その言葉を聞いた瞬間、なぜか胸のあたりがざわついた。褒められているはずなのに、全然嬉しくない。むしろ、何かを見透かされたような、居心地の悪さがあった。帰り道、ずっと考えていた。私は確かに頑張っている。毎日遅くまで働いているし、休日も勉強しているし、やるべきことは山ほどある。でも、だから何なんだろう。頑張っているから、何なんだ。30歳になった。節目だとか、大人になったとか、そういう感慨は特にない。ただ、20代の頃とは何かが決定的に違う。何が違うのか、最初はよく分からなかった。体力が落ちたとか、徹夜ができなくなったとか、そういう分かりやすい話でもない。しばらく考えて、ようやく気づいた。「頑張っている」という言葉が、免罪符にならなくなったのだ。20代の頃は、頑張っていれば許された。成果が出なくても、方向が間違っていても、「でも頑張ってるから」で何とかなった。周りもそう言ってくれたし、自分でもそう信じていた。頑張ることそのものに価値がある、と。でも30歳になって、その魔法が解けた。頑張っているのに何も変わらない自分がいて、頑張っているのに評価されない現実があって、頑張っているのに前に進んでいない焦りがある。頑張ることが、こんなにも虚しいとは思わなかった。これは、そういう話だ。頑張ることをやめろという話ではない。頑張り方を変えろという話でもない。ただ、「頑張っている」という言葉の正体について、30歳になった私が考えたことを書いてみようと思う。読んでも何も解決しないかもしれない。でも、同じようなことを感じている人がいたら、少しだけ楽になるかもしれない。そういう気持ちで書いている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。頑張ることの正体30歳の誕生日の夜、窓の外を眺めながら「今日も、頑張った」と思いました。でも、その言葉の後に続くはずの達成感はありませんでした。頑張りで全てを説明しようとしていた朝から晩まで働いていました。画面を見つめ、会議に出て、そこから開発をしていました。体は確かに疲れています。なのに、何も前に進んでいないという感覚が胸の奥に重く沈んでいるのです。社会人として8年が経ちました。20代前半の私は「頑張っている自分」が好きでした。努力している姿が自分の価値を証明してくれると思っていたからです。朝誰よりも早く出社し、夜遅くまで残り、休日も勉強する。その生き方が正しいと信じていました。しかし最近、ある事実に気づいてしまったのです。頑張ることそれ自体が、いつの間にか目的になっていたということに。本来、頑張ることは手段であるはずです。何かを達成するため、何かを得るため、どこかに到達するための手段。しかしいつの間にか、頑張ること自体が目的にすり替わっていました。「頑張っている自分」でいることが目的になり、その先に何があるのかを問うことをやめていたのです。ふと考えてしまいます。もし努力が一切報われない世界だったとしても、私はそれでもなお「頑張りたい」と願うだろうか。結果のために頑張っているのか。それとも、頑張ること自体が自分の生き方なのか。この2つは似ているようで、まったく違います。前者であれば、結果が出なければ頑張りは無意味になります。だから私たちは結果を求め、結果が出ないと焦り、自分を責めます。しかし後者であれば、結果に関係なく、頑張ること自体に意味があります。たとえ報われなくても、その過程に価値を見出すことができます。私は長い間、自分は後者だと思っていました。「努力することに意味がある」と信じていたからです。しかし正直に自分を見つめると、違いました。私は結果を求めていました。評価を求めていました。だから結果が出ないと苦しくなり、評価されないと自分を否定したくなったのです。もし本当に「頑張ること自体が生き方」なのだとしたら、結果が出なくても穏やかでいられるはず。しかし私はそうではなかった。頑張ることは純粋な生き方ではなく、結果を得るための手段だったのです。手段であるならば、その手段が有効かどうかを確かめなければなりません。目的地に近づいているかどうかを確認しなければなりません。しかし私は、頑張ること自体を目的にすり替えることで、そこを考えることから逃げていたのです。全部やろうとした結果具体的な話をさせてください。社会人になって数年目のことです。私は様々なことに挑戦させてもらっていました。自分の案件、登壇、ブログ執筆。それにまた、輪読会の運営、勉強会の主催、社内ドキュメントの管理と整備、新卒採用の担当。文脈のない色んなことを並列でやっていました。全部やりたかったのです。全部できると思っていました。結果として、全てが中途半端になりました。輪読会は準備不足で進行がグダグダになり、参加者が気まずそうに沈黙する場面が何度もありました。勉強会は告知が遅れて参加者が集まらず、3人しかいない会場で虚しくスライドをめくりました。ドキュメントは途中まで書いて放置され、それを指摘されることもないまま死にドキュメントが増えていきました。採用面談では候補者の情報を十分に把握できていないまま臨んでしまい、的外れな質問をして相手を困惑させました。自分の案件も遅れ、登壇の準備も直前までバタバタし、ブログは下書きのまま溜まっていきました。どれも「ちょっとずつダメ」だったのです。致命的な失敗ではない。でも、どれも胸を張って「やり遂げた」とは言えない。そして厄介なことに、中途半端にやっている間は、誰からもフィードバックをもらえなかったのです。なぜでしょうか。私が「頑張っているように見えた」からです。人は頑張っている人に「中途半端だ」とは言いにくいものです。遅くまで残っている。色々なことを引き受けている。一生懸命やっている。そういう姿を見ると、たとえ成果が出ていなくても「まあ、頑張ってるし」と見逃してしまう。指摘する側も遠慮してしまうのです。だから私は、自分が中途半端であることに気づけませんでした。周りも言ってくれないし、自分でも「頑張っている」という事実で目が曇っていたのです。ここで気づいたことがあります。私が選んだことだけでなく、選ばずに放置していたものが、私の人生を形作っていたということです。何かを選ぶとき、私たちは選んだものに意識を向けます。しかし、選ばなかったもの、手を付けずに残してしまったものについては、あまり考えません。でも実際には、その「選ばなかったもの」が積み重なって、今の自分を作っています。私の場合、「深く集中する時間」を選ばずに放置していました。「1つのことに没頭する経験」を選ばずに放置していました。全部やろうとすることで、何も深くやらないという選択を、無意識のうちにしていたのです。選択の影にあるもの——それを自覚することが、変わるための第一歩でした。総量が同じなら全部できるタイプの人もいるでしょう。器用にタスクを切り替えて、それぞれに必要な集中を注げる人。でも私は、おそらくそういうタイプではなかったのです。1つのことに深く集中しているときは力を発揮できる。でも、複数のことを並列で抱えると、どれにも集中できなくなる。頭の中が常に「あれもやらなきゃ、これもやらなきゃ」で埋まっていて、目の前のことに没頭できない。問題は、私が怠けていたことではありませんでした。全部やろうとしすぎていたことだったのです。そしてもう1つ気づいたことがあります。私が盲目的に全部を抱え込んでいる間、周りの人にも迷惑をかけていたということです。中途半端な準備で運営した勉強会に参加してくれた人たち。私の遅れのせいでスケジュールを調整しなければならなかったチームメンバー。頑張ることは、時に暴力になります。自分だけでなく、周りの人も苦しめてしまうのです。頑張らないことへの恐怖こうした経験があっても、頑張ることをやめるのは難しい。頑張ることに疲れたと思った瞬間、罪悪感が襲ってきます。「頑張らないなんて怠け者だ」「頑張らなかったら停滞してしまう」。心の中で誰かの声が私を責めるのです。この恐怖はどこから来るのでしょうか。少し立ち止まって考えてみると、そこには1つの混同があることに気づきます。私たちは「頑張らないこと」と「怠けること」を同じものだと思い込んでいるのです。しかしある時気づきました。頑張らないことと怠けることは違い、そして頑張ることと前に進むことも違うのだということに。これを整理すると、こうなります。「頑張る」とは、エネルギーを注ぎ込むことです。「前に進む」とは、目的地に近づくことです。そして「怠ける」とは、必要なことをしないことです。エネルギーを注ぎ込んでも、方向が間違っていたら目的地には近づきません。逆に、エネルギーを節約しても、正しい方向に進んでいれば目的地に近づくことができます。頑張りすぎて何も達成できないより、戦略的に力を抜いて1つを確実に達成した方が価値がある。頑張らないことへの恐怖を掘り下げていくと、その根底にあるのは「失敗への恐れ」でした。しかし、よりその下を掘ると、本質的な恐怖が見えてきます。私が本当に恐れていたのは、失敗そのものだったのか。それとも、「誰かに失敗を見られること」だったのか。私が本当に恐れていたのは、失敗そのものではありませんでした。失敗を誰かに見られること、「あいつは頑張らなかったから失敗した」と思われること、それが怖かったのです。一人で挑戦して一人で失敗するのは、実はそこまで怖くありません。痛いけれど、学びになります。しかし、その失敗を誰かに目撃されること、評価されること、噂されること——それが耐えられなかったのです。つまり、私の恐怖の本質は「社会的評価への恐れ」でした。自分自身の内側の痛みではなく、他者の目に映る自分の像への恐れだったのです。この区別は重要です。なぜなら、恐怖の正体を知ることで、対処の仕方が変わるからです。失敗そのものが怖いのであれば、リスクを減らす工夫をすればいい。しかし「失敗を見られること」が怖いのであれば、問題は失敗ではなく、他者の評価に自分の価値を預けすぎていることにあります。頑張ることをやめて考えることを始めた時、初めて前に進み始め、結果を出せるようになりました。頑張ることへの依存頭では分かっていても、頑張ることをやめられませんでした。私はたぶん、頑張ることに依存していたのです。朝起きるとすぐに仕事を始め、休憩も取らずに夜遅くまで働いて疲れ果てて眠り、土日も「せっかくの時間だから」と何かをしていました。「何もしない時間」が怖かったのです。なぜ怖かったのか。それは、何もしていない自分に価値がないと思っていたからです。この考えをもう少し掘り下げてみましょう。私は無意識のうちに、「自分の価値 = 自分がどれだけ頑張っているか」という等式を信じていました。頑張っていない自分は価値がない。価値のない自分を見たくない。そう感じていたから、常に何かをしている必要があり、頑張っている自分でいる必要があったのです。「頑張らなければ価値がない自分」と、「頑張っていなくてもここにいていい自分」。この2つのうち、私は本当はどちらを生きたいのだろう。これは「どちらが正しいか」という論理の問題ではありません。「どちらを選びたいか」という願望の問題です。頭では「頑張っていなくても価値がある」と分かっています。そう言われれば、そうです。でも、本当にそれを信じているかと問われると、自信がありません。心のどこかで「でも頑張らないと......」という声がするのです。その声の正体を知ることが、変わるための第一歩でした。答えは、すぐには出ませんでした。でも、この疑問を抱え続けることが大切でした。論理ではなく願望のレベルで、自分が何を求めているのかを探ること。それが、変わるための出発点になったのです。しかし不思議なことに、頑張れば頑張るほど、成果は出なくなっていきました。うまくいかない理由は頑張りすぎていたからです。頑張ることが思考を停止させていて、「とりあえず頑張る」「とにかく動く」と考えることから逃げていたのです。「頑張ります」という特権振り返ってみると、若い頃の私にはある種の特権がありました。「頑張ります」と言えば、それで許されていたのです。計画が甘くても「頑張ります」、ミスをしても「頑張ります」、結果が出なくても「頑張ります」と言えば許されていました。周囲は「若いんだから」「まだ経験が浅いんだから」「熱意があればいい」と納得してくれたのです。20代前半は特にそうでした。何も考えずにとにかく動き、深夜まで働き、休日も出社していれば評価されました。方向性が間違っていても、やり方が非効率でも、「頑張っている」という事実が全てを覆い隠してくれたのです。「頑張ります」は、思考停止の免罪符でした。考えなくてよく、戦略を立てなくてよく、ただ熱意を見せればよかったのです。がむしゃらは若さという資本で買えた特権だったのです。そしてその「がむしゃら」が、ある種の万能感を生んでいました。体力や気力は無限にあり、睡眠を削っても平気で、理想の自分に向かって駆け上がっていく。そんな勢いが許されていて、いやむしろ求められていたのです。今、手放せずに握りしめている「頑張り」は、本当に自分を守っているのだろうか。それとも、もう要らなくなった古い防具なのだろうか。かつて「頑張ること」は、私を守ってくれました。若くて経験がなくて、何も分からない時期に、「とにかく頑張る」という姿勢は、私の居場所を確保してくれました。がむしゃらに動くことで、「あいつは一生懸命やっている」と認めてもらえたのです。しかし、時間が経ちました。状況が変わりました。求められることも変わりました。かつて私を守ってくれた防具が、今は私の動きを制限しているのではないか。重すぎて前に進めなくなっているのではないか。そう考え始めた時、その防具を一度外してみる勇気が必要でした。転換点という現実しかしその「がむしゃらが許される特別な時間」は、予告なく終わります。私の場合、それは20代後半でした。ある日突然、それまで当たり前にできていたことができなくなりました。朝起きることも人と話すことも簡単な判断さえも重荷になって、「頑張ります」と言ってももう体が動かなくなったのです。今思えば、それはいつか必ず訪れる終わりでした。30歳という年齢は、「頑張ります」だけでは通用しなくなる境界線なのです。この変化はいくつかの形で現れます。まず、周囲の目が変わります。「頑張っている」だけでは評価されなくなります。「で、結果は」「で、どう改善するの」「がむしゃらにやるんじゃなくて、戦略は」と容赦なく聞かれるようになります。30歳は、熱意ではなく戦略が問われる年齢でした。「頑張っている」と「前に進んでいる」は別物だったのです。次に、身体の限界が見えてきます。20代のように無理が効かなくなり、深夜まで働いたら翌日に響き、休日を潰したら週明けのパフォーマンスが落ちます。がむしゃらはもはやコストの方が大きいのです。そして何より、自分自身が「このまま走り続けることに意味があるのか」と考え始めます。がむしゃらに頑張っても前に進んでおらず、ただ消耗しているだけ。そんな実感が、重くのしかかってくるのです。走り続けることと、前に進むことは違う。この当たり前の事実に、私は30歳になってようやく気づきました。なぜ私たちは頑張ってしまうのかしかし、なぜ私たちはそもそもこうなってしまうのでしょうか。なぜ、頑張ってしまうのでしょうか。私なりの答えは、簡単な答えが欲しいからというものです。どういうことか説明させてください。私たちが生きている現実は複雑です。何が正しいのか分からない。どの選択が最善なのか分からない。努力が報われるかどうかも分からない。そういう不確実性の中で生きることは、とても不安なことです。その不安に耐えられないとき、私たちは「頑張れば救われる」という単純で分かりやすい物語の中に逃げ込みます。この物語の中では、何をすべきかが明確です。とにかく頑張ればいい。努力すればいい。諦めなければいい。ネガティブ・ケイパビリティという言葉があります。不確実さや曖昧さに耐える能力のことです。「自分にもあるだろう」などと言ってみたりしますが、実際には、自分が見えている物語があまりにも狭いだけなのです。「頑張る」という単純な行動原理で、複雑な問題を考えずに済ませているだけなのです。頑張っている間は「前に進んでいる」という錯覚が得られて充実感があります。この充実感が曲者です。なぜなら、その錯覚が問題から目を背けさせ、「方向性が間違っているのではないか」という疑問を封じ込めてしまうからです。思考の罠では、なぜ私たちは頑張ることの問題点という明らかな事実に気づけないのでしょうか。その答えは、私たちの思考の仕組みにあります。自分の判断パターンに気づいたことがあります。結論が先にあって、その結論を支持する証拠だけを集め、矛盾する情報は無視していたのです。そして厄介なことに、その正当化のプロセスがあまりにも自然で論理的に見えるため、本人も気づかないのです。自分の信念を守るために、思考を使ってしまうという、これは無意識の傾向です。具体例を挙げましょう。「頑張れば報われる」という信念が先にあって、その信念を支持する証拠だけを集めていました。努力した人の成功例は記憶に残るのですが、努力したのに報われなかった人の存在は意識から消えていってしまいます。30歳になって振り返ると、20代の私は恐ろしいほど確信に満ちていました。「この方法が正しい」「これだけやれば必ず成功する」と疑うことを知らず、いや疑うことを恐れていました。自分の間違いを認めることこの思考の罠から抜け出すために必要なものがありました。自分が間違っているだろうと認めることです。これは簡単なようで、とても難しいことでした。私は「頑張ることは正しい」と信じていました。だから、頑張っても成果が出ない時、「もっと頑張れば」と考えていました。頑張ることが正しいという前提を疑うことは、自分の生き方を否定することのように感じられたのです。しかしある時、意識的に自分の前提を疑ってみることにしました。「頑張らない方がうまくいくことはないか」と。すると、思い当たることがいくつも出てきました。休みを取った翌日の方が、良いアイデアが浮かぶ。締め切りに追われていない時の方が、コードの質が高い。夜遅くまで粘るより、翌朝やり直した方が早く終わる。これは全て、私自身が経験していたことでした。でも「頑張ることは正しい」という信念が強すぎて、その経験を無視していたのです。見たくないものは、見えないようにするというのが、人間の脳の仕組みなのだと知りました。だからこそ、意識的に自分の前提を疑う必要があります。「自分は正しい」という確信から一歩引いて、「自分は間違っているだろう」という可能性を常に心に留めておくこと。それが、思考の罠から抜け出す第一歩でした。確信は、時に最大の敵になる。有限であることを知っている、でも分かっていないでは、なぜ私たちはわざわざこの思考の罠にはまってしまうのでしょうか。なぜ、自分の信念を守ろうとするのでしょうか。その背景には、1つの根本的な事実から目を背けたいという欲求があると私は考えています。それは、人生は有限であるという事実です。この事実を、私たちは「知っている」はずです。人はいつか死ぬ。時間には限りがある。当たり前のことです。でも、本当に分かっているかというと、そうではないのです。思い出してみてください。中学や高校の卒業式の日のことを。「あー、もっと何かできてたな」と思いませんでしたか。部活にもっと打ち込めばよかった。あの子ともっと話せばよかった。文化祭でもっと楽しめばよかった。卒業式の日、私たちは3年間が有限だったことを、ようやく実感します。でも、その実感はすぐに消えるのです。大学に入り、社会人になり、日常に戻ると、また時間が無限にあるかのように振る舞い始めます。「いつかやろう」「そのうち学ぼう」「まだ時間はある」と。30歳になった時、ふと計算してみました。80歳まで生きるとして、残りは50年。週に換算すると約2600週。月に換算すると約600ヶ月。この数字を見た時、卒業式の日の感覚が蘇ってきました。思ったより、少ないのです。でも、きっとこの実感もまた薄れていくのでしょう。明日になれば、来週になれば、また時間が無限にあるかのように振る舞い始める。それが人間なのです。だからこそ、意識的に思い出す必要があるのです。時間は有限であること。すべてをやることは不可能であること。何かを選ぶということは、何かを諦めるということ。この事実を忘れそうになるたび、卒業式の日の感覚を思い出すようにしています。時間管理術という逃避しかし、この事実を常に意識し続けることは難しいものです。むしろ、私たちは無意識のうちにこの現実から目を背けようとします。その典型的な方法が、時間管理術です。「もっと効率的に」「もっと生産的に」と時間管理術に縋りつくのは、現実から目を背けているだけなのです。どれだけ効率化しても、時間は増えないのです。時間管理術は「もっと多くのことができるようになる」という幻想を与えてくれます。しかし実際には、私たちにできることの総量は変わりません。ただ、その有限性を見ないようにしているだけなのです。ここで逆説的なことが起きます。限られた時間を受け入れることが、実は自由への第一歩なのです。すべてをやることを諦めた時、初めて「本当にやりたいこと」が見えてきます。「やるべきこと」ではなく「やりたいこと」へ集中できるようになります。選ばなければならないという制約が、逆に選択を可能にするのです。忙しさというステータス時間が有限だと分かっていても、人は忙しさを求めます。私もそうでした。「忙しい」と言うことが、ある種のステータスでした。忙しい = 重要な仕事をしている = 価値があるという等式を、疑うことなく信じていたのです。しかし冷静に考えるとおかしな話です。忙しいことと価値を生むことは別のことです。では、なぜ私たちは忙しくなるのでしょうか。理由はいくつかあります。優先順位がついていないから。断れないから。そして何より忙しさそのものを求めているからです。暇になることが怖い。何もしていない時間が耐えられない。だから予定を埋める。忙しくする。これは最初に述べた「頑張ることへの依存」と同じ構造です。意味のない努力忙しくしているうちに、私はたくさんの意味のない努力をしていました。完璧な資料を作るために、美しいデザイン、詳細な分析、見栄えの良いグラフを何日もかけて作ります。しかし実際に見られるのは最初の数ページだけです。定期的な報告のために資料を作って説明して質疑応答する時間を、毎週毎月確保しています。しかしその時間で議論される内容はメール一通で済む内容だったりします。これは全て、「頑張っている感」を得るための努力でした。実際に価値を生むための努力ではなく、自分と周囲に「頑張っている」と思わせるための努力だったのです。なぜこんなことをしていたのでしょうか。「頑張っていない自分」が怖かったからです。「何もしていない」と認めることが怖かったから、何かをしている「ふり」をしたのです。しかしそのせいで、意味のあることをする時間がなくなってしまいました。意味のない努力が、意味のある努力を駆逐していたのです。なぜ意味のない努力を選んでしまうのかこれは努力の世界における残酷な法則です。なぜ残酷かというと、意味のない努力の方が楽で、見た目の成果が出やすいからです。比較してみましょう。完璧な資料を作ることは無理ですが、時間をかければ見栄えはかなり良くなります。しかし複雑な問題を本質的に解決することは難しく、時間をかけてもできるとは限りません。会議に出席することは簡単です。座って話を聞いてたまに発言すればいい。しかし深く考えて独創的な解決策を生み出すことは難しく、孤独で不確実で失敗するだろう。だから人は無意識に意味のない努力を選びます。一日の大半を意味のない努力で埋めてしまうため、本質的な努力をする時間がなくなってしまうのです。楽な努力が、本当の努力を駆逐する。何もしない時間の価値この悪循環を断ち切るために、ある日、試しに一日何もしない時間を作ってみました。会議もキャンセルし、メールも見ずに、ただ窓の外を眺める時間を確保しました。最初は不安でした。「こんなことしていていいのか」「時間を無駄にしているのではないか」と。この不安は、最初に述べた「何もしていない自分に価値がない」という信念から来ています。しかし一時間、二時間と過ごすうちに何かが変わりました。頭の中がクリアになって、今まで見えなかったものが見えるようになったのです。忙しさは、思考を停止させます。忙しい状態では「これって意味あるのか」と問う余裕がないため、意味のないことを延々と続けてしまうのです。そのとき、ふと考えました。何も生み出していない時間や、誰からも評価されない時間にさえ、私の人生の価値は宿りうるのだろうか。窓の外を眺めているだけの時間。何も「生産」していない時間。誰にも見られていない時間。そういう時間に、価値はあるのでしょうか。最初、私は「いいえ」と答えていました。価値とは、何かを生み出すことで生まれるものだと思っていたからです。成果があってこそ価値がある。評価されてこそ価値がある。そう信じていました。しかし、何もしない時間を過ごしているうちに、考えが変わってきました。その時間は、確かに何も「生産」していませんでした。でも、自分の中で何かが整理され、何かが癒され、何かが育っていたのです。それは目に見える成果ではありませんでしたが、確かに何かが起きていました。生産性や成果や他者評価——そういったものを全部はがした後に残るもの。それが「自分の時間」の価値なのだろう。何かを生み出すための時間ではなく、ただ存在するための時間。そういう時間があっていいのだと、少しずつ思えるようになりました。忙しさという霧が晴れて本質が見えたとき、気づきました。今までやっていたことの半分以上は実は必要なく、頑張っていたけれど価値を生んでいなかったのです。立ち止まった時間が、一番遠くまで連れて行ってくれた。選択という技術何もしない時間を作ったことで、30歳になって学んだ最も重要なことの1つが見えてきました。それは、選択することの重要性です。若い頃は「全部やろう」としていました。新しい技術が出れば学び、新しいプロジェクトがあれば参加し、頼まれた仕事は全て引き受けていました。確かに、若い頃や自分の成長を誰かが見守ってくれる時期には、それも良いだろう。がむしゃらに量をこなすことで、見えてくるものはあります。しかしそれだけではありません。自分の能力を発揮できる環境を自分で選び、作ることもまた、自分の能力なのです。全部やろうとし続けると、何が起きるでしょうか。エネルギーが分散してどれも中途半端になり、重要なことに十分な時間と集中を注げなくなります。そして何より、自分が得意なこと、やりたいことが見えなくなってしまいます。若い頃からやりすぎると、自分の可能性を狭めてしまう可能性があるのです。すべてに手を出すことで、「自分は何でもそこそこできる人」にはなれるだろう。しかし「この領域では誰にも負けない」という強みは育ちません。ある時、尊敬する先輩に「どうやったら全部うまくできますか」と相談しました。彼は笑って「全部うまくやろうとするな。1つだけ、圧倒的にうまくやれ」と言いました。「勝てる領域を見つけろ」と彼は続けました。「君が他の誰よりも価値を出せる領域、そこに全てを賭けろ。他は最低限でいい」と。集中することで見えてきたものその日から自分の「勝てる領域」を探し始めました。自分は何が得意なのか、どこで他の人と差別化できるのか。振り返ってみると、私が価値を生んでいたのは、複雑な問題を構造化してシンプルな解決策を示すことでした。資料を何百枚作ることでも、会議を何時間することでもありませんでした。でも当時の私は、そのことに気づいていませんでした。すべてを同じように頑張っていたからです。得意なことと苦手なこと、重要なことと些細なこと、すべてに同じエネルギーを注いでいました。それからは、「勝てる領域」へ集中することにしました。複雑な問題に向き合う時間を最大化し、他の作業を最小化しました。すると不思議なことが起きました。仕事の質が上がり、周囲の評価も上がり、そして忙しさは減ったのです。やることを減らしたのに、成果は増えた。これは最初、信じられませんでした。でも考えてみれば当然のことでした。苦手なことに時間を使っていた分を、得意なことに回しただけなのです。同じ時間を使っても、得意なことの方が成果は出ます。これは怠けているわけではありません。戦略的に力を配分しているだけなのです。やめることを選ぶ選択するということは何かを捨てることです。これが最も難しいことでした。私たちは何かを捨てることに恐怖を感じます。「後で必要になるだろう」「チャンスを逃すだろう」と考えてしまいます。しかし、「やらないこと」を選ぶ決断こそが、人生における優先順位を明確化する鍵なのです。ここでもう一度、選択の影について考えてみます。私は「何を選ぶか」については意識していましたが、「何を選ばずに残してしまっているか」については、ほとんど意識していませんでした。やめることを選ぶとき、私たちは選んだこと（やめること）に意識を向けます。しかし同時に、「続けること」を選んでいるのです。その「続けること」は、続ける価値があるものでしょうか。無意識のうちに惰性で続けているだけではないでしょうか。私は「To Stopリスト」を作り始めました。やることリストではなく、やめることリストです。意味のない定例会議に出席するのをやめました。完璧な資料を作るのをやめました。すべての技術トレンドを追うのをやめました。頼まれた仕事を全て引き受けるのをやめました。忙しいふりをするのもやめました。最初は罪悪感がありました。しかしやめてみると驚きました。誰も困らなかったのです。むしろ重要なことへ集中できるようになって、成果が上がりました。やめることと怠けることは違います。それは本質に集中するための戦略なのです。捨てることが、得ることの始まりだった。努力はベクトルだここまで読んで、頑張ること自体が悪いのだと思われただろう。しかし、そうではありません。問題は「どう頑張るか」なのです。頑張ることは、ベクトルです。大きさだけじゃなく、方向があるのです。どれだけ大きな力で頑張っても、方向が間違っていたら目的地には着きません。むしろ遠ざかっていくのです。多くの人はベクトルの「大きさ」ばかりに注目します。「もっと頑張る」「もっと努力する」「もっと時間をかける」と考え、方向については考えません。しかし重要なのは方向です。間違った方向に全力で走るより、正しい方向にゆっくり歩く方が、目的地には早く着くのです。そして、その「方向」を決めるとき、また同じところに戻ってきます。「前に進む」とは、いったい誰の物差しで測られる「進歩」なのか。社会が示す方向に進むことが「前」なのか。それとも、自分が心から望む方向に進むことが「前」なのか。そこに答えを出さないまま、ベクトルの大きさだけを増やしても、どこにも到達けないのです。努力と評価のミスマッチ努力の方向が間違っていると、どうなるでしょうか。努力と評価が一致しない場所で頑張り続けることになります。それは、尋常ではないほど辛いものです。やっても認められない。いくら頑張っても成果として認識されない。「こんなに頑張っているのになぜ評価されないんだろう」という疑問は、やがて「自分には才能がないのだろう」という絶望に変わっていきます。しかし、ここで立ち止まって考えてみましょう。問題は才能ではなく、環境とのミスマッチなのだろう。あなたの能力が発揮されない環境。あなたの強みが評価されない組織。あなたの価値が認識されない役割。そういう場所でどれだけ頑張っても報われません。これは残酷な事実ですが、同時に希望でもあります。なぜなら、環境は変えられるからです。才能がないのではなく、場所が合っていないだけなら、場所を変えれば状況は改善する可能性があるのです。能力とは環境との相互作用ここで、根本的な認識を改める必要があります。「能力」とは、環境との相互作用の中で初めて発揮されるものなのです。ある環境では高いパフォーマンスを出せる人が、別の環境では全く力を発揮できない。珍しいことではありません。むしろ普通のことです。私自身、この事実を身をもって経験しました。ある組織でやりたくない仕事を頑張り、長時間働いて必死に努力しました。しかし成果は出ず、評価も上がらず、自己肯定感は下がり続けて、「自分は仕事ができない」と思っていました。しかし環境を変えた瞬間、すべてが変わったのです。同じ私が違う組織、違う役割で働き始めると、成果が出て評価され、自己肯定感が戻ってきました。私の「能力」は変わっていませんでした。変わったのは環境だったのです。ですから「自分には能力がない」という結論は早計です。正確には「この環境では、自分の能力が発揮されない」ということなのです。この認識は重要です。なぜなら、「能力がない」という結論は絶望につながりますが、「環境が合っていない」という認識は行動につながるからです。頑張りで全てを説明しようとしていた私は長い間、すべてを「頑張り」で説明していました。環境のことなど、考えもしませんでした。成果が出ない時は「自分がもっと頑張ればよい」と思っていました。だから、もっと時間をかけ、もっと努力し、もっと自分を追い込みました。成果が出た時は「自分が頑張ったから」と思っていました。だから、次も同じように頑張れば、同じように成果が出ると信じていました。うまくいかないのは環境のせいではなく、自分の努力が足りないせい。うまくいったのは環境のおかげではなく、自分の努力のおかげ。すべての原因を「自分の頑張り」に帰属させていたのです。この考え方は、一見すると責任感があるように見えます。「環境のせいにしない」「自分でコントロールできることに集中する」。でも、実際にはこれは視野の狭さでした。なぜなら、同じ努力をしても、環境によって成果は大きく変わるからです。自分の強みが発揮される環境なら、少ない努力で大きな成果が出ます。自分の強みが発揮されない環境なら、どれだけ努力しても成果は限られます。そしてもう1つ、認識しておくべきことがあります。「自分の能力が発揮されない環境」は、常に存在しているということです。どんな組織にも、どんな役割にも、自分に合わない部分があります。完璧にフィットする環境など存在しません。大切なのは、それを認めることです。「ここは自分に合っていない」と認めることは、敗北ではありません。むしろ、そこから戦略が始まります。合わない部分を認めるからこそ、「ではどうするか」を考えられるようになるのです。私は長い間、合わない部分を認めることができませんでした。「もっと頑張れば何とかなる」と思い続けていました。でも実際には、何ともならなかったのです。ただ消耗しただけでした。この事実に気づくまで、私は長い時間を要しました。そして気づいた時、ようやく「どこで頑張るか」を考えられるようになったのです。勝てる領域を見つけるでは、どうすれば「勝てる領域」を見つけられるのでしょうか。これはあくまで私の場合の話ですが、無意味な場所で頑張らず、能力が発揮される場所で努力することが、私が燃え尽きずに長く走り続ける秘訣でした。私は、自分にとって意味の分からない仕事を無限にできる耐久性の高い人間ではありませんでした。合わない環境で合わない仕事を続けることは苦痛でしかありませんでした。それは弱さだろうが、それが私の現実だったのです。私の場合、開発全般が得意でした。設計と開発、どちらも能力を発揮できて楽しいのです。しかしやってはいけなかったのは、マルチタスクをしながら人との調整やステークホルダー管理を大量にこなすことでした。この能力が著しく低く、全体の生産性がとても下がってしまったのです。最初は周囲の期待に応えようとして、開発をしながら調整業務もこなそうとしました。しかし評価されませんでした。「中途半端だ」と言ってもらえればまだ良かった。そうではなく、評価が低いだけ。何が問題なのか分からないまま、成果の出ない日々が続きました。しかしある程度裁量をもらい、開発に集中し始めたら状況が変わりました。「この実装すごく良い」と言われるようになって、チーム全体の生産性が上がり、そして私の評価も上がったのです。勝てる領域とは、自分の能力と環境のニーズが交わる場所です。自分が得意でも誰も必要としていなければ評価されず、環境が必要としていても自分ができなければ価値を出せません。その交点を見つけてそこに集中すること、それが努力の方向性を正しく定める方法でした。戦う場所を選ぶことが、戦い方を決める。環境という見えない制約ここまで読んで、あなたはこう考えるだろう。「確かに正しい場所で頑張ることは重要だけれど、そもそも『自分の能力が発揮される環境』なんて、どうやって見つければいいのか」と。その通りです。自分の能力が発揮される環境は簡単には見つかりません。そしてもっと現実的な問題があります。今いる環境が自分に合っていないと分かっても、すぐには動けないのです。住宅ローンがある。家族を養っている。転職するには経験が足りない。業界の状況が悪い。様々な制約が私たちを今の場所に縛り付けています。だから、戦術的な頑張りも必要なのです。これは矛盾しているように聞こえるだろう。今まで「頑張りすぎるな」と言ってきたのに、「頑張りも必要」と言うのは。しかし、これは矛盾ではありません。問題は「頑張ること」自体ではなく、「考えずに頑張ること」だったのです。戦略を持った上での戦術的な頑張りは、必要なものです。持続可能性という解答ここまで、頑張ることの問題点と、選択と集中の重要性を述べてきました。では、具体的にどうすればいいのでしょうか。私が見つけた答えは、持続可能性でした。面白いことに気づきました。頑張る量を減らしたら、成果が増えたのです。ある時、私は思い切って変えてみることにしました。やるべき仕事とやらない仕事を分けて、不要なミーティングに出なくなりました。やりたくない仕事を整理させてほしいと相談したのです。すると不思議なことが起きました。勤務中の8時間の質が劇的に上がったのです。なぜこうなったのか。理由は単純でした。「この8時間だけが自分の時間だ」と考えると一瞬たりとも無駄にできなくなり、集中力が持続して疲労が少なくなり、翌日もまた集中できるようになったのです。無駄な時間が減りましたが、学びの質は上がりました。必要なことだけを学ぶようになり、「やらなきゃ」ではなく「やりたい」で動くようになったのです。この経験から1つの原則を学びました。持続可能性が、成果を生むという原則です。一時的には全ての時間を注ぎ込む方が多く成果を出せるように見えます。しかし長期的には持続可能なペースの方がずっと多くの成果を生むのです。無理をして一気にやろうとすると、どこかで必ず破綻します。体調を崩すか、質が落ちるか、燃え尽きるか。そして破綻した後のリカバリーには、節約できたはずの時間よりもずっと長い時間がかかるのです。新しいやり方の始まり持続可能性を意識することで、新しいやり方が始まりました。無理をしない働き方。自分の限界を知った上でのアプローチ。がむしゃらではなく戦略的なやり方。私の新しいやり方は、「頑張ります」という言葉を封印することから始まりました。最初は怖かったのを覚えています。「頑張らない」と言ったら「やる気がない」と思われるんじゃないか、評価が下がるんじゃないかと心配していました。しかし違ったのです。「頑張ります」をやめて「こうします」と言い始めた時、初めて信頼されるようになりました。具体的な計画を示す。達成可能な目標を設定する。リスクを評価する。代替案を用意する。そして結果を出す。がむしゃらな熱意ではなく冷静な戦略で勝負するやり方に変えたのです。頑張ることをやめたら時間ができました。その時間で考えることができました。「今の仕事は本当に自分がやりたいことなのか」「この関係性は本当に大切にしたいものなのか」「この努力は本当に価値を生んでいるのか」と。そして気づきました。今まで「頑張らなきゃ」と思ってやっていたことの多くは、実は自分が本当にやりたいことではなかったのです。社会的な期待に応えるため、周囲に認められるため、「できる人」に見られるため、そういう外的な動機で動いていたのです。しかし30歳になって、もうそういう生き方は続けられないと悟りました。体力的な限界、精神的な限界、そして何より残りの人生をそんな生き方で使いたくないと思ったのです。がむしゃらで許された特別な時間の終わりは、敗北ではありません。より賢く、より持続可能なやり方への転換点なのです。自己犠牲という承認への飢え新しいやり方を始めてから、もう1つ重要なことに気づきました。それは、自分を大切にすることと他者を大切にすることのバランスについてです。「他人を優先する自分」でしか価値を感じられない人がいます。自分のニーズを無視して他人に尽くすことで「必要とされている感覚」を得ているのです。一見すると優しさに見えます。しかし、実はこれは承認への飢えなのです。自分の時間を全て他人に捧げる。自分の希望を後回しにする。常に誰かの期待に応える。自分が疲れていても「頼まれたから」と引き受ける。その自己犠牲によって「自分は良い人だ」「自分は必要とされている」と感じているのです。しかし、健全ではありません。自分を大切にできない人は、結局他人を大切にできないからです。見返りを期待する優しさなぜ自己犠牲が健全でないのか、もう少し詳しく説明させてください。自分を犠牲にして他人に尽くすと、無意識のうちに「見返り」を期待するようになるのです。「こんなに頑張ったんだから感謝されるべきだ」「こんなに尽くしたんだから認められるべきだ」という気持ちが湧いてきます。そしてその期待が満たされないと怒りや不満が生まれます。「こんなに頑張ったのに」「こんなに尽くしたのに」と相手を責める気持ちが湧いてきます。これは優しさとは違います。相手のためではなく自分の承認欲求を満たすための行為なのです。見返りを期待しない優しさもあります。相手のために行動し、その結果がどうであれ満足できる。私はそういう優しさを持ちたいと思いました。しかし自分が満たされていない状態では、その無条件の優しさを持つことは難しいのです。まず自分を満たすことだからこそ、まず自分を満たすことが大切なのです。これは理屈としては分かりやすい話です。でも、実行するのは難しいのです。なぜなら、自分を後回しにすることが習慣になっているからです。私の場合、常に誰かのために動いていました。チームのため、会社のため、プロジェクトのため。そう言えば聞こえは良いのですが、実際には自分のことを考える余裕がなかっただけでした。そしてある時、限界が来ました。誰かのために動く気力すら湧かなくなったのです。その時ようやく気づきました。自分が枯れていたら、誰かに何かを与えることはできないのだと。自分を大切にすることは、自己中心的なことではありません。持続可能に誰かを助けるための前提条件なのです。自分の限界を知る。自分のニーズを尊重する。時には「できない」と言う勇気を持つ。これは全て、より長く、より健全に他者を大切にするための準備なのです。そして自分が満たされた状態から他人を助ける。見返りを期待せず純粋に相手のために行動する。私はそういう優しさを持ちたいのです。空っぽの器からは、何も注げない。フェーズによる変化しかしここでも1つ大切なことを付け加えます。キャリアのフェーズによって、求められることは変わるということです。ジュニアの頃は、がむしゃらでも許されました。むしろ、がむしゃらであることが求められていました。何も分からないのだから、とにかく量をこなせ。失敗してもいいから、手を動かせ。その時期に「効率」や「戦略」を語るのは早すぎたのです。しかしミドルになると、状況が変わります。「頑張っています」だけでは評価されなくなります。「で、結果は」「で、何を学んだの」と問われるようになります。がむしゃらに動くだけでなく、方向性を持って動くことが求められるのです。そしてシニアになると、より変わります。自分が頑張ることよりも、チーム全体の成果が問われます。自分一人で抱え込むのではなく、任せることが求められます。「自分が頑張る」から「みんなが頑張れる環境を作る」へ。役割が変わるのです。私は今、ミドルからシニアへの過渡期にいます。ジュニアの頃のやり方が通用しなくなり、新しいやり方を模索している時期です。また同じことを考えます。今、手放せずに握りしめている「頑張り」は、本当に自分を守っているのだろうか。それとも、もう要らなくなった古い防具なのだろうか。ジュニアの頃、「とにかく頑張る」という姿勢は私を守ってくれました。何も分からなくても、がむしゃらにやっていれば居場所がありました。しかし今、同じ姿勢を続けることは、私を守るどころか、足を引っ張っています。かつて自分を守ってくれた「頑張り方」が、フェーズが変わった今もまだ有効なのか。それとも、アップデートすべきなのか。そこに正直に向き合う必要がありました。重要なのは、今の自分がどのフェーズにいるかを認識することであり、そのフェーズに応じたやり方を選ぶことです。ジュニアのやり方をミドルになっても続けていたら、消耗するだけです。ミドルのやり方をシニアになっても続けていたら、チームの足を引っ張ります。フェーズが変われば、やり方も変えなければならないのです。この文章で私が伝えたいのは「頑張るな」ということではありません。「今の自分のフェーズに合った頑張り方を選べ」ということなのです。しかし、1つ補足があります。自分では気づけなくても、上司やマネージャーが適切にコントロールしてくれている場合があるということです。私の場合も、振り返ってみれば、良い上司に恵まれていた時期は自然と適切な仕事量に調整されていました。「それは引き受けなくていい」「今はこっちに集中して」と言ってもらえていたのです。当時は気づいていませんでしたが、それは上司が私の状態を見て、適切に仕事を配分してくれていたからでした。逆に言えば、自分が上司やチームリーダーになった時には、同じことをする責任があるということです。メンバーが頑張りすぎていないか。中途半端になっていないか。「頑張っているように見える」からといって見逃していないか。そして、必要であれば「それはやらなくていい」と言えているか。人は頑張っている人に「中途半端だ」とは言いにくいものです。だからこそ、上司やリーダーは意識的にそれを言う必要があります。言わなければ、かつての私のように、本人は気づかないまま消耗していくのです。「おい、がんばるな」と言ってあげられる人になること。それもまた、フェーズが変わった時に求められる役割なのです。「頑張る自分」というアイデンティティ最後に、最も根深い問題について話させてください。私は「頑張る自分」というアイデンティティに縛られていました。「私は頑張る人だ」「私は努力家だ」「私は諦めない」というような自己像があり、その自己像を守るために頑張り続けなければいけなかったのです。しかしそれは苦しいものでした。「頑張る自分」であり続けるために休めず、立ち止まれず、弱音を吐けなかったのです。「頑張る自分」というアイデンティティが自分を縛る檻になっていました。ある日ふと気づきました。私は「頑張る」ということ自体にしがみついていて、成果を出すためではなく「頑張る自分」でいるために頑張っていたのです。そしてまた、同じところに戻ってきます。「頑張らなければ価値がない自分」と、「頑張っていなくてもここにいていい自分」のどちらを、本当は生きたいのか。頭で考えれば、答えは明らかです。「頑張っていなくても価値がある」と信じたい。でも、心の奥底では、まだその確信が持てませんでした。しかし、考え続けることで、少しずつ変わってきました。そしてもう1つ気づきました。頑張っていなくても自分に価値があるということに。成果を出していなくても自分に価値がある。忙しくなくても自分に価値がある。価値は頑張ることから来るのではなく、存在することそのものに価値があるのです。これは宗教的な話ではなく実際的な話です。頑張り続けて壊れた人をたくさん見てきました。優秀な人ほど「もっとできるはずだ」と自分を追い込んで限界を超えて壊れてしまいます。そして壊れたら何も生み出せなくなってしまいます。何も生み出していない時間にも、価値はあります。誰からも評価されない時間にも、意味があります。生産性という物差しを外した時、初めて見えてくるものがあるのです。だから頑張らないことは自分を守ることであり、長く続けるための戦略なのです。全力で走り続けることはできません。どこかで必ず止まります。でも、適切なペースで歩き続けることはできます。そして、歩き続けた人の方が、結果的には遠くまで行けるのです。「頑張る自分」を降りて「続けられる自分」になり、そして「結果を出す自分」に登る。それが私の選択でした。おわりにこの文章を書き終えて、コーヒーを淹れた。カップを持って窓際に立つと、隣のマンションの明かりがいくつか見える。日曜日の夜だ。明日からまた一週間が始まる。みんな、何をしているんだろう。仕事の準備をしているのか、録画していたドラマを見ているのか、あるいは私と同じように、何となく窓の外を眺めているのか。正直に言うと、この文章を書いたからといって、私が何か変わったわけではない。明日になれば、また同じように仕事に行く。締め切りに追われて、会議に出て、メールを返して、「頑張らなきゃ」と思う瞬間がきっとある。そういう自分を完全になくすことはできない。たぶん、これからもずっと。でも、一つだけ変わったことがある。「頑張っている」と言われたとき、その言葉をそのまま受け取らなくなった。「で、それで何か変わったの？」と自分に聞くようになった。頑張っていることを、言い訳にしなくなった。それだけのことだ。たったそれだけのことなのに、少しだけ楽になった。頑張っていない自分を許せるようになった、というのとは違う。頑張ることの価値を、正しく測れるようになった、という感じだ。この文章を読んで、何か得るものがあったかどうかは分からない。「そんなの当たり前じゃん」と思った人もいるだろうし、「何を言っているのか分からない」と思った人もいるだろう。それでいい。ただ、もし今、頑張っているのに上手くいかなくて苦しい人がいたら。もし今、頑張れない自分を責めている人がいたら。一つだけ伝えたいことがある。頑張っていることは、偉いことじゃない。偉いのは、頑張った結果、何かが変わることだ。何かを生み出すことだ。誰かの役に立つことだ。頑張ること自体には、実は何の価値もない。でも逆に言えば、頑張らなくても、結果を出せばいいということでもある。頑張らなくても、変われればいいということでもある。頑張らなくても、前に進めればいいということでもある。だから、頑張らなくていい。本当に、頑張らなくていい。その代わり、歩くのはやめないでほしい。自分のペースで、自分の方向に、自分の足で。転んでもいい。休んでもいい。立ち止まってもいい。でも、歩くのだけは、やめないでほしい。コーヒーが冷めてきた。明日も、たぶん、いつも通りの一日が来る。でも、いつも通りの一日の中で、少しだけ違う選択ができるかもしれない。「頑張らなきゃ」と思ったとき、「いや、待て」と立ち止まれるかもしれない。それだけで、十分だと思う。おい、がんばるな。syu-m-5151.hatenablog.com参考書籍あっという間に人は死ぬから　「時間を食べつくすモンスター」の正体と倒し方作者:佐藤 舞（サトマイ）KADOKAWAAmazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazonエッセンシャル思考 最少の時間で成果を最大にする作者:グレッグ・マキューンかんき出版Amazonエフォートレス思考 努力を最小化して成果を最大化する作者:グレッグ・マキューンかんき出版Amazonさあ、才能(じぶん)に目覚めよう　最新版 ストレングス・ファインダー2.0作者:ジム・クリフトン,ギャラップ日経BPAmazon嫌われる勇気作者:岸見 一郎,古賀 史健ダイヤモンド社Amazon幸せになる勇気作者:岸見 一郎,古賀 史健ダイヤモンド社AmazonDIE WITH ZERO　人生が豊かになりすぎる究極のルール作者:ビル・パーキンスダイヤモンド社Amazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIエージェントによるブログレビュー環境の構築（上）]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/02/002601</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/02/002601</guid>
            <pubDate>Mon, 01 Dec 2025 15:26:01 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2025 2日目のエントリ記事です。はじめにブログを書いては直し、また直す。同じ文章を何度も触っていると、客観的な判断ができなくなってくる。「これで本当に伝わるのか？」という疑問だけが残る。コードにはレビューがあり、デザインには批評がある。しかし、技術ブログには明確な基準がない。その不安を解消するために、最初は自分の文章を評価する「プロンプト」を作って運用していた。防御力、思考整理力、実践応用性など、6つの観点でAIに評価させるのだ。だが、すぐに問題にぶつかった。「面倒」なのだ。記事を書くたびにプロンプトを開き、貼り付け、結果を待つ。この手動のひと手間があるだけで、次第に「今日はまあいいか」とサボるようになり、せっかくの基準も形骸化していった。だから、環境ごと変えることにした。生成AIのエージェント機能を使い、ブログレビューの手順をひとつの動作にまとめたのだ。/blog-quality-review と打てば、必要なチェックが勝手に走る。手間を消し、継続性だけを残す。今回は、そんなブログレビュー環境の構築について紹介する。syu-m-5151.hatenablog.comブログ記事評価プロンプト v2.1 https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659 · GitHubこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、はじめていきます。なぜブログレビューにエージェントを使うのか自分で書いた記事を自分で評価するのは、想像以上に難しい。「こんなにわかりやすく書いたのに、なぜ伝わらないんだろう」と思うことはないだろうか。それは私たちが、自分の持つ知識や前提条件を、無意識に読者にも期待してしまうからだ。「これくらい知っているだろう」「説明不要だろう」という思い込みが、読者との間に溝を作る。ここにエージェントが入ると、話が変わる。エージェントは私の「暗黙の前提」を共有していない。だから、初学者が感じるであろう「分からない」を冷静に指摘できる。専門用語の壁、論理の飛躍、「なぜ？」という素朴な疑問——これらを容赦なく洗い出してくれる。さらに、エージェントは疲れないし、基準を忘れない。私が定義した「レビューの観点」を一貫して適用し続ける。これは単なる自動化ではない。私の認知リソースを、「本当に人間にしかできない判断」に集中させるための仕組みだ。Commandsでレビュー観点を構造化するClaude Codeには、よく使うプロンプトをコマンド化できる機能がある。.claude/commands/ ディレクトリにMarkdownファイルを置くだけで、ファイル名がコマンド名になり、中身がプロンプトとして機能する。code.claude.com「毎回『この観点でレビューして』と指示するのは面倒」「記事ごとにレビューの質がバラつくのが嫌だ」そんな悩みを抱えていた私にとって、Commandsは最適解だった。一貫性の担保手打ちのプロンプトでは、表現の揺らぎによりAIの回答も変わってしまう。Commandsなら常に同一の定義で実行されるため、出力の質が安定する。# 悪い例（毎回微妙に違う）「この記事をレビューして」「読みやすさをチェック」「AIっぽくないか見て」# 良い例（カスタムコマンド）/blog-quality-review blog.md# → 常に定義された6つの観点・同じ基準でレビューが走るGitでのVersion管理Commandsの実体はMarkdownファイルだ。つまり、プロンプトの改善履歴をGitで管理できる。「この観点を追加したら、指摘が鋭くなった」「この表現を変えたら、より具体的な改善案が出るようになった」こういった試行錯誤の軌跡が残ることで、プロンプト自体が「育つ資産」になっていく。私が実際に使っているCommandsここからは、私がブログ執筆・レビューで実際に使用しているCommandsを全てではないが紹介する。注意：ここで紹介するのは各Commandの要点のみだ。実際のファイルには、より詳細な指示や評価基準（Few-Shotなど）が含まれている。Phase 1: 書く前に深く考える良いブログは「書く」前に「考える」ことから始まる。/deep-thinking-prompt - 深い思考のための問いかけ# Deep Thinking Prompt - 深く考えるための問いかけブログを書く前に「深く考える」ための問いかけを提供します。表面的な理解や一般論で終わらず、本質に迫るための思考支援ツールです。## 7つの問いかけ1. **原体験への問いかけ** - なぜこのテーマに興味を持ったのか2. **前提への問いかけ** - 当たり前だと思っていることは何か3. **対立への問いかけ** - 矛盾や葛藤はどこにあるか4. **構造への問いかけ** - システムとしてどう機能しているか5. **変化への問いかけ** - 過去と現在で何が変わったか6. **未来への問いかけ** - このまま進むとどうなるか7. **読者への問いかけ** - 誰に届けたいのか、なぜその人なのかこのCommandを使うと、「何を書くか（What）」だけでなく「なぜ書くのか（Why）」が明確になる。一般論ではなく、自分だけの視点を掘り起こすための工程だ。/structural-thinking - 構造設計# Structural Thinking - 構造的思考支援散らばった思考を整理し、論理的な流れを作ります。読者の理解プロセスに合わせた「伝わる」構成を設計します。深く考えたあと、その思考をどう配置するか。このCommandが、散乱したアイデアを読者に届く「ストーリー」へと整えてくれる。Phase 2: 書いた後にレビューする/blog-quality-review - 6つの観点でレビュー以前作成した「ブログ記事評価プロンプト」をCommand化したものだ。# Blog Quality Review - ブログ品質レビュー以下の6つの観点（各0.0-5.0スコア）で評価します：1. **防御力** - 批判や反論への耐性2. **思考整理力** - 情報の論理的構造化3. **実践応用性** - 読者が行動に移せる価値4. **構成と読みやすさ** - 視覚的要素と文体5. **コミュニケーション力** - 人間味のある伝達6. **人間らしさ** - 温度感と個性実行すると記事の強みと弱みが数値化される。「前回は実践応用性が3.2だったが、今回は4.0に上がった」といった具合に、自身の成長や記事の品質を定量的に把握できる。/beginner-feedback - 初学者の視点# Beginner Feedback - 初学者の素朴な意見あなたは**一般読者代表（佐々木ゆい・28歳）**として、素朴な意見を提供します。- 専門用語や前提知識の壁を発見- 論理の飛躍を指摘- 「なぜ？」という素朴な疑問を投げかける- 一般読者が共感できるか確認エキスパートの目では見逃してしまう、初学者の「分からない」を発見するためのCommandだ。具体的なペルソナを設定することで、フィードバックの解像度を高めている。/ai-humanity-check - AIっぽさの評価# ai-humanity-check文章のAIっぽさを評価し、より人間らしい表現への改善提案を行います。## AIっぽさスコア (0.0-5.0) ※低いほど人間らしい**0.0-1.0 (完全に人間的)**- 著者特有の言い回しや癖がある- 具体的な失敗談や苦労話が生々しい- 感情の起伏が自然で共感できるAIに下書きを支援させると、どうしても文章が「AI臭く」なりがちだ。このCommandで機械的な表現を検出し、体温のある文章へと戻していく。Phase 3: 仕上げる/textlint-polish - 文章校正# Textlint Polish - 文章校正・AIっぽさ除去機械的・AIっぽい表現を排除し、自然で読みやすい文章にする。- AIが多用する冗長表現を検出- 比喩的・詩的すぎる表現を簡潔に- 文体の統一（です・ます調）textlint的な観点で、表現の誤りや揺らぎを修正する。AI特有の冗長な言い回しもここでカットする。/redundancy-check - 冗長性チェック# Redundancy Check - 冗長性チェック以下の4つの観点（各0.0-5.0スコア）で評価します：1. **情報密度** - 1文あたりの情報量2. **簡潔性** - 冗長表現・無駄な修飾の少なさ3. **論理効率** - 論理的重複・循環論法の少なさ4. **構造最適性** - 章・節の構成の必要十分性削れる言葉は徹底的に削る。情報の密度を高め、読み手の時間を奪わない文章にするための最終チェックだ。全自動レビューの実行これらを一つずつ実行するのはやはり手間だ。そこで、これらを束ねる /full-review を作成した。# Full Review - 全自動レビュー実行すべての必須レビューを自動で順次実行します。textlint校正から始まり、初学者フィードバック、品質レビューまで一括で実施。## 使用方法/full-review blog.mdこのCommandひとつで、以下のフローが流れる。/textlint-polish（校正）/beginner-feedback（初学者視点）/blog-quality-review（品質スコア）/ai-humanity-check（人間らしさ）一度設定さえしてしまえば、あとは「コマンド一発」で包括的なレビューが完了する。上巻のまとめここまで、Commandsを使ったブログレビュー環境の基礎（Phase 1〜3）を解説してきた。出発点は、「ブログ記事の評価基準がなく、レビューが属人的かつ面倒」という課題だった。これに対し、エージェントを活用して評価観点を構造化し、実行を自動化するというアプローチをとった。ここで重要なのは、AIとの関係性だ。体験や感情といった「身体性」は人間が供給し、それを構造化し整える役割をAIが担う。これはAIへの丸投げではなく、互いの強みを活かした協働である。Commandsによって評価基準を定義し、Gitで管理し、自動化することで、「書くこと」以外のノイズを極限まで減らすことができる。下巻では、より高度なAgents（サブエージェント）の活用と、複数の視点を持つレビュー体制の構築について解説する。下巻に続くsyu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[1Password の SSH Agent を WSL でも使う]]></title>
            <link>https://qiita.com/yteraoka/items/a056f7c055cc73b06d19</link>
            <guid isPermaLink="false">https://qiita.com/yteraoka/items/a056f7c055cc73b06d19</guid>
            <pubDate>Mon, 01 Dec 2025 15:07:22 GMT</pubDate>
            <content:encoded><![CDATA[パスワード系は 1Password に登録しているのですが SSH の鍵はなんとなく面倒でファイルでローカルに置いたままでした。しかし、バックアップを取るのも面倒だし 1Password で管理しようかなという気になりました。せっかくお金も払っているのだし使えるものは使おう...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年12月版読む予定本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/books_dec_plan</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/books_dec_plan</guid>
            <pubDate>Mon, 01 Dec 2025 12:59:58 GMT</pubDate>
            <content:encoded><![CDATA[今年も早いものであっという間に12月ですね。ということで、年末最後の一ヶ月で読もうと思っている本を紹介します。先月分は以下になりますので、併せてご覧ください！https://zenn.dev/akasan/articles/870a86bf7189f1 機械学習 実践GAN（Compass Booksシリーズ） 敵対的生成ネットワークによる深層学習マルチモーダル系の資格試験を受験予定で、その勉強中に改めげGANの基礎を叩き込もうと思って読んでいる最中です。GANも様々な種類がありますし、どのようにモデルを学習するかなどを改めて学習するために読んでいます。私は普段PyTorch...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初めての海外カンファレンス(KubeCon NA 2024 in Salt Lake City)]]></title>
            <link>https://blog.masasuzu.net/entry/2025/12/01/212119</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/12/01/212119</guid>
            <pubDate>Mon, 01 Dec 2025 12:21:19 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2025です。qiita.com吉祥寺.pm #37で話した内容となります。kichijojipm.connpass.com speakerdeck.com厳密には10年以上前に行ったことあるんですが、完全に忘れているので実質今回が初回ということでお願いします。今回は業務として、KubeCon NAへ行かせてもらったのでその体験を共有いたします。セッション内容については触れません。旅程的には11/11-17となっており、KubeCon NAの開催期間としては11/12-15となっています。以下の目次で送らせていただきます。出国準備5ヶ月前1か月前前日まで随時往路現地復路事後まとめ出国準備やったことは以下のとおりです。5か月前KubeConチケット手配ホテル予約飛行機手配1ヶ月前パスポート取得ESTA申請Visit Japan登録前日まで荷物準備随時英語技術インプット5ヶ月前KubeCon自体のチケット手配はまとめて会社の方でやっていただきました。ホテルと飛行機はKubeCon割引があったのでこれを利用しました。飛行機はUnited航空の乗継便を予約しました。行きは成田=>ダラス=>ソルトレイクシティー、帰りはソルトレイクシティー=>ロサンゼルス=>成田を予約していました。飛行機が往復で26万円、ホテルが12万円でした。なかなかな値段ですね。同僚と1日違いでチケットを買ったら微妙に値段が変わっていた記憶があります。早めの行動大事ですね。ホテルも飛行機も日本語サイトがあったので特に困った記憶がないです。1か月前数年前にパスポートの期限が切れていたので、これを機に再発行しました。東京都庁地下にパスポートセンターがあるので、ここで申請しました。パスポートセンター横に写真屋さんがあるので、証明写真を準備せずに行っても安心です。だいたい1週間で発行されるので、また1週間後に赴くことになります。渡米する際にESTAを申請する必要があります。ここで注意してほしいのは、検索トップやスポンサーサイトとして出てくるサイトはそれっぽい偽物なので騙されないように注意してください。esta.cbp.dhs.govVisit Japanを事前に登録していくことで日本への帰国時にスムーズになりますのでやっておくことをおすすめします。services.digital.go.jp前日までここまででだいたいやらないといけないことは終わってるので、あとは荷造りです。大きな荷物としては手荷物で入る大きさのトランクケースとビジネスリュックサックの2つを持っていきました。それにプラスしてパスポートと財布と携帯を常に携帯するためのサコッシュも持ち込みました。4泊5日暮らせる最低限の服だけ持ち込みました。だいぶコンパクトになったと思います。基本的に外で食べるつもりはあまりなかったので、全日程の夕食を持ち込みました。オートミール、フリーズドライの味噌汁、粉末スープ類、ルイボスティーなど持っていきました。スープ類にオートミールを入れてレンジで温めればなんとかなります。ここで注意しないといけないのはアメリカは動物性成分が含まれているものは持ち込めません。魚介はOKなのでそのあたり注意しましょう。このへんは国によって違います。電子機器に関しては120V対応しているものはそのままアメリカでも使えます。コンセントの形状は日本と同じですがボルト数が違う形になります。先に言ったようにパスポート、財布、携帯はサコッシュに入れて肌身離さないようにしていました。随時英語はほんとにもっとやっておけばよかったなと思いました。Duolingoはずっとやっていましたが、リスニング、スピーキングという観点からは足りないですね。最近だとスピークバディみたいなAI英会話アプリがあるのでそのあたりもっとやり込んでおけばよかったなと後悔してます。あとやったこととしては、CNCFのyoutubeチャネルに大量の過去のKubeConアーカイブがあるのでそれでひたすら耳をならしてました。www.youtube.com往路実を言うとですね。出国する当日朝まで沖縄にいました。出国当日はこんな感じでした。11/7 午前 羽田着11/7 昼 家で荷物最終チェック11/7 夕方成田出発沖縄から帰る飛行機がちゃんと飛んで良かったと心から思います。普通はこんなことしないです。いろいろ重なって仕方なかったのでした。ということで、行きは成田発、デンバー乗り継ぎ、ソルトレイクシティーという行程です。。。。。でした。デンバー行きの飛行機に乗っていて途中で行き先がアンカレッジ(アラスカ州)に変わってることに気が付きます。急病人救護のためにアンカレッジに緊急着陸することになりました。なんやかんやあって無事デンバーには到着するのですが、当然乗継便には間に合わずなので振り返る必要がありました。自分はアンカレッジ出発時点までにかすかな電波を頼りにスマートフォンから振替を行ったのですが、同僚たちは電波がなく何もできなかったので、自動的に翌日の便に振り返られてしまいました。ちょっとそれは困るのですが、この時点ではどうにもならないのでいったんデンバーに到着し入国審査を受けることになりました。正直入国審査はかなり厳しくされるのかなと不安になっていたのですが、案外すんなり通って拍子抜けしました。デンバーの空港にてなんとか本日便で乗り継げないか交渉することになりました。どうやら現状満席の便でもウェイティングリストに入ることでキャンセル待ちに並ぶことができてうまくいけば本日便で行けそうだということがわかりました。Uniteの係員の人がウェイティングリスト登録のためにコマンドプロンプトを駆使してたのが印象的でした。コマンド操作でやるんですねと感心しました。ともあれ、初っ端からトラブルに見舞われましたが拙い英語でもなんとか乗り切ることができました。なんやかんやあって、ソルトレイクシティーまでたどり着くことができました。現地空港からホテルまではLRTで移動しました。TransitというアプリでOne-Wayチケットを購入して乗るみたいでした。チケットをActivateして乗るのですが、QRコード自体はあるのですが、最後まで誰にも見せることなく下車しました。これが信用乗車方式か。。。となりました。会場はめっちゃ広いし、めっちゃ人が多くて、これが本場か、、、と圧倒されました。飲み物はいたるところにありました。コーヒーに困ることはありませんでした。ランチボックスが無料配布されてることに4日目に気が付きました。それまで、毎回ホテルに帰ってオートミールを食べる生活をしていました。毎回ランチに必ずお菓子が含まれているのはアメリカンな文化なのでしょうか。ランチはビーフ、チキン、ベジタリアン、ビーガン、グルテンフリーから選べました。なんというか文化を感じますね。英語に自身なかったので、文字起こしと翻訳をしてくれるSaaSアプリを試してたのですが、いまいち制度が低くてあまり役に立たなかったでした。これもあとから気づいたのですが、ルームごとにQRが貼ってあって、そこにアクセスすると文字起こしと翻訳をしてくれるアプリケーションが用意されていました。今回いたるところで自分の情報弱者ぶりを感じてしまいました。KubeConのセッション自体はYoutubeにすぐ上がるので、その場で頑張りすぎずにあとで復習するのがよいです。ただ、現地でしか体験できない雰囲気を味わえたことはすごく良い経験になりました。現地での日本人交流会ではバリバリKubernetesをつかっている人たちの生の声が聞けて刺激になりました。復路特筆すべきことはないですVisit Japanをあらかじめ登録しておいたので、入国審査と税関はすんなりと通過できました。事後経費採算しっかししましょう。経費採算終わるまでが出張ですまとめ往路がこすぎてソルトレイクシティーについた瞬間もう帰っていいかなという気持ちになりました。トラブルはありつつも一つ一つこなしていけばまあなんとかなるものだなと思いました。英語はほんとにちゃんとやっておきたかったなと言う気持ちが強いです。もっとできてれはもっと実りが多かったなと。当たり前の話ですが、羽田、成田の乗り継ぎはやめたほうが望ましいです。社会人は余裕持った行動をしましょう(?)いろいろもっとうまくやりたかったという気持ちはありつつも本場のでっかいカンファレンスに参加して色んな意味で刺激を受けました。また英語もそうですし、知識レベルを上げて海外カンファレンス再挑戦したいです。来年はre:Invent行たいです!さて、真面目なまとめは同僚が書いてるのでこちらを参照してください。sreake.comそれでは。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN]]></title>
            <link>https://zenn.dev/meziron/articles/fef6ccca887f97</link>
            <guid isPermaLink="false">https://zenn.dev/meziron/articles/fef6ccca887f97</guid>
            <pubDate>Mon, 01 Dec 2025 08:25:59 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Actionsの「なぜか動く」を分解する：npm publishとGITHUB_TOKEN最近、非エンジニアの人やエンジニアなりたての人と作業することがあります。そこで自分が組んだGithub Actionsについて質問をもらいました。「このyamlってプログラミング言語じゃないのになんでこういうふうに書くことで動くの？」「初めてみても何が何をしているの全然直観的じゃなくて、これから自分で書ける自信がない・・・」上記のような言葉をもらいました。実際、GitHub Actionsを使っていると、コピペでなんとなく動いてはいるものの、「裏で何が起きているのかよく...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Instructorの紹介]]></title>
            <link>https://zenn.dev/meziron/articles/2d1a1006851423</link>
            <guid isPermaLink="false">https://zenn.dev/meziron/articles/2d1a1006851423</guid>
            <pubDate>Mon, 01 Dec 2025 08:25:58 GMT</pubDate>
            <content:encoded><![CDATA[InstructorライブラリとClean Architectureで実現する型安全なAI統合パターン はじめに近年、業務アプリケーションにAI機能を組み込む事例が急速に増えています。しかし、AIの出力は本質的に不確実性を含むため、従来のWebアプリケーション開発で重視されてきた型安全性や保守性を維持することが課題となっています。本記事では、InstructorライブラリとClean Architectureを組み合わせることで、型安全で保守性の高いAI統合パターンを実現する方法を紹介します。特に、複雑な業務ロジックを持つアプリケーションでAIを活用する際のベストプラクティス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[学術的根拠から読み解くNotebookLMの音声活用法]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/12/01/005741</link>
            <guid isPermaLink="false">https://shu-kob.hateblo.jp/entry/2025/12/01/005741</guid>
            <pubDate>Sun, 30 Nov 2025 15:57:41 GMT</pubDate>
            <content:encoded><![CDATA[この記事はQiita 3-shake Advent Calendar 2025 シリーズ1日目の記事です。2025年11月22日(土)に、Google Developer Group - DevFest Tokyo 2025があり、その招待制懇親会でLTをさせていただく機会がありました。「学術的根拠から読み解くNotebookLMの音声活用法」というタイトルで、NotebookLMの音声解説で学習する際のポイントを過去のマルチメディア学習の学術的根拠や実験を基にまとめました。 speakerdeck.com1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です2枚目2枚目は自己紹介です。3枚目Notebookでの音声を作る操作方法です。画面にドキュメントなどをアップロードし、音声解説ボタンを押すだけで簡単に作れます。音声は、男女掛け合いのPodcast形式です。4枚目仕事や学業で、難解なドキュメントを読む場面は多々あると思いますが、NotebookLMの音声解説機能により、学習効率が高められるか期待が高まっています。AIによって作られた音声がどれだけ学習効果があるか過去のマルチメディア学習の学術的根拠実験を基に解説していきます。5枚目学習効果を測定する実験も行いました。とある専門的なドキュメントを音声化して実験に用いました。被験者は熟達者（エキスパート）と初学者のグループに分かれます。熟達者、初学者でそれぞれ、音声の元となったドキュメントのみ読んで学習したグループ、音声のみ聴いて学習したグループ、両方を用いたグループに分かれ、学習後に4択の理解度チェックテストを受けてもらいました。GoogleスライドをPDF化して文字が崩れているので、直せるなら直しておきます。6枚目ドキュメント・音声の両方を用いたグループが優位に思えましたが、結果はご覧の通り。初学者は、実験を1回のみ行い、両方 > 音声のみ > ドキュメントのみ、という期待通りの結果でしたが、熟達者は、実験を3回行い、両方グループが最高点を取るとは限りませんでした。なぜ、熟達者は両方グループが優位とは限らなかったのでしょうか？7枚目初学者の説明です。初学者は音声学習を順書立てて勉強するのが有効です。構造的ガイダンスを提供することを足場かけ理論といいます。また、初学者の両方グループは音声を主、ドキュメントを従（文章を読むより、俯瞰的に見る）ことにより、認知負荷分散につながりました。8枚目一方の熟達者の説明です。熟達者は、初学者に有効な順序立てた構造的ガイダンスが邪魔になることがあります。熟達者の知識ネットワークに対して、手厚い構造的ガイダンスが知識をマッピングするのが非常に認知負荷が高いためです。これを熟達化のリバーサル効果といいます。また、熟達者の両方群は音声とドキュメント両方から情報を得ようと頑張り、認知負荷が高い状態でした。9枚目実験の制約により、不利な面もありました。実験の時間の都合上、音声の一時停止、巻き戻しを禁止していました。音声を一時停止、巻き戻して、自分のペースで聴けるなら、熟達者の両方グループは、音声とドキュメント両方からしっかり情報を取れていた可能性があります。学習者のペースを守らせることが効率を上げるのですが、例えば、音声や動画の学習をする際、数分ごとに区切って、学習者が「次へ」を押すことで次のパートが始まると学習がしやすいです。このことを「セグメンテーション原理」と呼ぶのですが、実験の制約上、阻害されたことになります。また、熟達者の実験の中で、音声のみグループの平均点が低いときがありました。それは、グラフ・図を見ていないと難しい問題が多く、音声でグラフ・図など視覚的な情報伝達が難しいことを意味します。また、各グループの点数のばらつきでは、ドキュメントのみグループが最も大きかったです。これは当然と言えば当然で、ドキュメント学習は各個人の学習能力に大きく左右されるためです。一方、音声は画一的な指導が可能とも言えます。10枚目実験や学術的根拠から読み解く、音声学習のおすすめとしては、学習者の習熟度を考慮し、初学者は音声とドキュメント両方を併用し、音声を主、ドキュメントを従とするのが良いでしょう。一方、熟達者は各個人で使い分けをするのがよく、概要把握や復習、思い出すなどの目的では音声、詳細や図表の把握はドキュメントを使うのがよく、安易に両方同時に使うと認知負荷を増大させるリスクがあります。11枚目参考文献です。一部、有料のものもありますが、Web検索等で概要を知ることもできます。12枚目終わりましたが、他の勉強会での登壇情報です。2025年11月27日(木)に、Jagu'e'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇した話は、ブログ記事にまとめていますので、よろしければご覧ください。shu-kob.hateblo.jp最後にqiita.com3-shake Advent Calendar 2025 シリーズ2の1日目はmasasuzuさんが書いてくれています。シリーズ1の2日目はyteraokaさんの「VPC Lattice を理解したい」シリーズ2の2日目はnwiizoさんの「生成AIエージェントによるブログレビュー環境の構築（上）」です。今後もお楽しみに！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MCP・A2A概要 〜Google Cloudで構築するなら〜]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/12/01/001432</link>
            <guid isPermaLink="false">https://shu-kob.hateblo.jp/entry/2025/12/01/001432</guid>
            <pubDate>Sun, 30 Nov 2025 15:14:32 GMT</pubDate>
            <content:encoded><![CDATA[この記事はQiita Jagu'e'r Advent Calendar 2025の1日目の記事です。2025年11月27日(木)に、Jagu'e'r 月末 Tech Lunchの勉強会「月末 Tech Lunch Online#7 - Google Cloud を語る！-」に「MCP・A2A概要 〜Google Cloudで構築するなら〜」というタイトルで登壇させていただきましたので、その発表内容でのポイントを記事化したいと思います。AIエージェントが流行っているけど、MCPやA2Aという概念は難しいやろうと思い、噛み砕いて説明したいというのが発表のモチベーションでした。 speakerdeck.comなお、今回の資料は、NotebookLMで作成しました。ここまで作れるのはすごいです！1ページずつ解説をさせていただきたいと思います。1枚目1枚目は表紙です。2枚目2枚目は、アジェンダで、全体の話の流れを書いています。3枚目3枚目は、LLMの制約について述べています。LLMは「Brain in a Jar」（瓶の中の脳）とも言われ、賢いけど、手足を持たなくて実行能力のないものの例えです。例えば、学習時点までの知識しか知りません。これをナレッジカットオフといいます。「今日の株価」「明日の天気」「最新のニュース」などは分かりません。また、旅行のプランをLLMに尋ねても、航空券やホテルの予約はしてくれません。APIなどを操作し、データベースのトランザクション操作をする実行能力はないのです。4枚目ここで、LLMの制約を解決する手段として、MCPの話が出てくるのに加え、さらなる機能拡張のためにA2Aの話が出てきます。MCPはLLMに実行能力を与えます。A2Aはエージェント同士が連携し、より複雑なことができるようになる仕組みです。5枚目MCP(Model Context Protocol)は外部ツールやデータへのアクセスを標準化するプロトコルです。LLMという脳に手足を与えて、検索やAPI操作ができるようになり、APIを介してデータベースのトランザクション操作ができるようになるのです。ここでポイントは、推論機能と実行機能を分離して疎結合に実装するということです。6枚目A2A(Agent-to-Agent)は、AIエージェント同士で、連携するためのプロトコルです。能力を記述したAgent CardがAIエージェントの名刺となり、どのエージェントにどのタスクを任せるかの判断ができます。また、通信プロトコルが定められているため、拡張性に優れています。7枚目MCPとA2Aのご紹介をしましたが、Google CloudでMCPやA2Aをどう構築していくかのポイントに移りましょう。まず、認知（推論）機能と実行機能を分離することクラウドを利用する上で、サーバーレスファーストが大事であること（8枚目で詳説）誰も信頼せずとも動くゼロトラストセキュリティであることです。8枚目Google CloudでのMCPサーバー構築は、Cloud Runを使うのが定石です。サーバーレスでありコスト最適化できます。また、高いスケーラビリティに対応していて、コンテナベースで、デプロイが容易です。9枚目MCPサーバーをCloud Runで構築する際の注意点です。ローカル開発で使うようなstdio（Standard I/O）はCloud Runでは使用できないため、Streamable HTTPかSSE over HTTPを使う必要があります。最近では、新しいStreamable HTTPの方が推奨となっています。10枚目一方、A2A対応のエージェントの構築は、Vertex AI Agent Engineが最適です、フルマネージドサービスで、A2Aのプロトコルに準拠しており、Agent Registoryによるガバナンスも効いています。11枚目A2Aエージェントを構築するためのポイントです。スライドには文言が書いていませんが、ADK(Agent Development Kit)を用いた方法です。AgentCardの定義、使用するLLMやツールの定義、タスク処理のロジックを実装し、これらをA2Agentで統合し、A2A準拠のエージェントを作成できます。12枚目MCPとA2Aを連携させた構築例です。「Social Agent」というのは友人の好みを推論するエージェントです。外部連携、つまり実行部分はMCPを用いて、推論と実行の分離を行います。13枚目簡単にAIエージェントが開発できるようになると、企業内でみんな好き勝手にエージェントを作り始めて、野良エージェントが増えそうですが、Gemini Enterpriseによる一元管理でガバナンスを効かせられます。14枚目MCPもA2Aもオープンプロトコルであるため、拡張性に優れています。インターネットでもTCP/IPというオープンプロトコルのおかげで相互運用性があるように、AIエージェントもどんどん拡張していき、どんどん便利な世の中になるのかもしれません。最後にお読みいただきありがとうございました。2日目のQiita Jagu'e'r Advent Calendar 2025は、pHaya72さん「テクサミの宣伝」です。qiita.com空きもまだありますので、Jagu'e'r 会員の方はぜひ書きましょう！私もできれば、複数記事書きます！]]></content:encoded>
        </item>
    </channel>
</rss>