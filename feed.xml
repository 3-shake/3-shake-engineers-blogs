<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Wed, 26 Apr 2023 18:31:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[DBMSの歴史とNewSQL]]></title>
            <link>https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql</link>
            <guid>https://zenn.dev/nnaka2992/articles/history_of_db_and_newsql</guid>
            <pubDate>Wed, 26 Apr 2023 14:28:19 GMT</pubDate>
            <content:encoded><![CDATA[この記事はDBMSの登場以前から現代のDBMSを取り巻く環境までを振り返ることで、なぜNewSQLが必要とされ登場したのかをまとめます。 おことわり筆者はあくまでDBMSユーザーであり、研究者ではないため内容は個人の見解です。また対象読者はある程度DBMSに関わりがあり、OLTPやOLAP、列指向や行指向といった基本的な単語を理解しているものとします。またNewSQLの技術的詳細はスコープ外とします。 DBMS以前データベースという言葉は1950年代に米軍が情報基地を集約したことに由来します。一方で学術的なデータベースの起源はW. C. McGeeが1959年に発表...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[DBREブログ] Snowflake とは？]]></title>
            <link>https://sreake.com/blog/what-is-snowflake/</link>
            <guid>https://sreake.com/blog/what-is-snowflake/</guid>
            <pubDate>Wed, 26 Apr 2023 02:37:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに クラウドデータウェアハウスの Snowflake についての解説です。Snowflake のアーキテクチャや料金体系、特徴、セキュリティについて説明しています。 概要 プラットフォームの概要 Snowflake […]The post [DBREブログ] Snowflake とは？ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[中間結果が莫大になるときの結合を最適化する最悪ケース最適化結合をRDBMSに適応する論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/04/26/110646</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/04/26/110646</guid>
            <pubDate>Wed, 26 Apr 2023 02:06:46 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2018年に発表された分析ワークロードなどで発生しがちな最終結果に比べ、非常に大きな中間結果を作成してしまうクエリを多方向結合で最適化する論文を読みました。Adopting Worst-Case Optimal Joins in Relational Database Systems著者についてMichael Freitag、Maximilian Bandle、Tobias Schmidt、Alfons Kemper、Thomas Neumannによるグループの論文いずれの著者もDBMSにおける最適化を中心に研究しており、それぞれ分析ワークロードにおける最適化や最新のハードウェアにおける最適化などを研究している。問題意識従来のRDBMSにおける結合処理のほとんどはバイナリ結合に依存して複数のリレーションにまたがるクエリを処理してきた。数十年に渡る研究によりバイナリ結合は幅広い柔軟性と優れた性能を発揮するようになった。その一方でバイナリ結合による実行計画は特定のワークロードでは最適ではないケースを示すことが知られている。主な原因として実際のクエリ結果に比べて非常に大きな中間結果を生成するためである。とくにPK以外のキーによる結合が多くなる分析ワークロードではそのような状態を避けることが難しく、またグラフ分析のようなクエリパターンでも多く見られる。近年の論理的な進歩により中間結果の列挙を避ける多方向結合のアルゴリズムが開発可能になった。この手法はバイナリ結合計画より優れた実行時間を保証できるため、RDBMSの堅牢性を大幅に向上させる可能性を持っている。しかし現状最悪ケース最適化結合アルゴリズムでは以下のような問題を抱えている。1. 膨大なストレージとメンテナンスを必要とする結合に参加出来るカラムを含むインデックスを必要とする。1. RDBMSは挿入と更新のサポートが必要なものの、既存のアルゴリズムは高価な事前計算を必要とする。そのため本論文は以下の制約を満たすアプローチを提案している1. 多方向結合が有益な場合のみ多方向結合を使用するオプティマイザを必要とする。1. 実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。手法提案手法では比較ベースではなくハッシュベースの結合のため、2の「実行中に効率的に実行でき、ディスクのに永続化する必要のないパフォーマントインデックスを必要とする。」という要素の考慮を除いている。またオプティマイザについては既存のコストベースのものを拡張し適応している。提案手法では潜在的に成長している結合のカスケードを最悪の場合の最適結合に置き換えることで、最適化されたバイナリ結合計画を洗練させるヒューリスティックなアプローチを提案している。通常の結合順序最適化で使用されるのと同じカーディナリティ推定値に基づいて、中間テーブルが膨大になる結合を特定する。作業時間read22:1322:13author25:483:35summary52:5826:50感想とても難しい内容に感じてしまい、殆ど頭を通りすぎてしまった気がする。今まで最適化は触れずに来たため、理解が浅い領域だった。よくよく考えるとDBMSの話しに最適化が登場するのはあたりまえなので、今後はその方面にも触れて行きたい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[羊を眠らせる sleep コマンド「sheep」の紹介]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/sheep-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/sheep-introduction</guid>
            <pubDate>Tue, 25 Apr 2023 09:00:22 GMT</pubDate>
            <content:encoded><![CDATA[羊を眠らせる sleep コマンドである sheep を作りました。https://github.com/koki-develop/sheepこの記事では sheep のインストール方法 ~ 使い方についてまとめます。インストール使い方まとめ インストールHomebrew を使用している場合は brew install でインストールできます。$ brew install koki-develop/tap/sheepもしくは、 sheep は Go で作られているため go install でインストールすることもできます。$ go install githu...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[マルチコアメインメモリにおけるソートジョインとハッシュジョインのパフォーマンスを検証した論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/04/24/112354</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/04/24/112354</guid>
            <pubDate>Mon, 24 Apr 2023 02:23:54 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2013年に発表された"Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited"という論文を読みました。当時最新のアルゴリズムとハードウェアにおける、ソートとハッシュによる結合のパフォーマンスを比べた論文です。Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited著者についてCagri Balkesen、Gustavo Alonso、Jens Teubner、M. Tamer Ozsuらのグループによる論文いずれもDBMSにおけるクエリ最適化やビッグデータにおけるパフォーマンスを研究している。またGustavo Alonsoはハードウェアや分散システムもメインのフィールドとしている。問題意識DBMSにおいて常にソートマージとハッシュ結合の性能比較が行われており、最新の研究ではSIMDやNUMAへの適正に基づいてソートマージがより優れていると結論づけられていた。しかしこれらの分野は常に研究が重ねられ、過去の検証時には登場していなったハッシュ結合の最適化手法が生れた。この論文ではそれらを適用し再度ソートマージとハッシュ結合の性能比較を行なう。手法本論文では以下に分けて結合手法の評価を行なっている。1. ソートフェーズの評価SIMDソートアルゴリズムとC++のSTLソートアルゴリズムを比較している。マージフェーズの評価入力サイズの調整によるマージフェーズの最適化パーマンスを検証している。ソートマージジョインにおける影響要因の特定結果結合対象のデータサイズに拘わらずハッシュによる結合がソートベースの結合のパフォーマンスを上回っている。Figure 14ソートマージによる結合は入力サイズが著しく大きくなったときのみハッシュ結合のパフォーマンスに近づく。Figure 15ソートマージ、ハッシュ結合におけるデータの偏りはパフォーマンスに大きな影響を及ぼさなかった。Figure 16いずれのアルゴリズムも物理的なコア数では線形にスケールした。Figure 17作業時間read23:1123:11author27:093:58summary60:1232:57]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RDBでの結合手法を比較した論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/04/23/231628</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/04/23/231628</guid>
            <pubDate>Sun, 23 Apr 2023 14:16:28 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2016年に発表された"An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory"という論文を読みました。様々な結合手法を包括的に比較した論文でどのような結合方法がどのような時に適しているかを示しています。An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory著者についてStefan Schuh、Xiao Chen、Jens Dittrichのグループによる論文。いずれもDBMSや分析システム、Hadoopなどにおける検索高速化・最適化の研究を行なっている。問題意識関係結合はほとんど全てのクエリプランにおいて中核をなす処理であり、定期的に研究・改良され再検討されてきた。新たな手法が提案され実験を行なわれるものの、それぞれ結果において比較を困難にする要素や幾らかの矛盾を孕んでいた。例えば同じハッシュベースの結合アルゴリズムの比較でも実装が異なったり、複数の論文でパフォーマンス比較で正反対の結果を示しているためである。そのため単純に論文執筆時点で最も高速な結合アルゴリズムを結論づけることが困難であった。手法本論文では結合方法を以下の3つに分類した1. パーティションベースハッシュジョインパーティションに分割し結合する手法。ハッシュテーブルの構築と結合されるデータの探索のキャッシュミスを最小にする事を目的としている。非パーティションベースハッシュジョインパーティションテーブルを構築しながら結合を行なう手法で、マルチスレッドと順番に依存しない実行によりキャッシュミスのパフォーマンス劣化を隠蔽している。ソートマージジョインSIMDによりベクトル化される。検証ではこれらの結合方法を以下の3つのテストで使用するために、全部で13のアルゴリズムを検証している。1. ブラックボックス比較ブラックボックス的に比較する。ホワイトボックス比較ブラックボックス比較で検証する結合方法に先行研究で示された最適化を施した上で比較を行なう。パラレルラディックスジョイン比較Table 2結果パーティション結合の一種であるリモート書込みを排除したCPR系アルゴリズムは小さな入力に対して有効ではないスケールの大きい結合ではとくに理由が無い場合、パーティションベースのジョインを利用する大きなサイズのページを利用するソフトウェアライトコンバインバッファ()を利用するパーティションジョインでは適切なパーティションビットを利用するできるかぎりシンプルなアルゴリズムを利用するNUMAを考慮したアルゴリズムを利用する実行時間とクエリ時間は同一ではない作業時間read31:3431:34author35:183:46summary77:5042:32]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コンパイルとベクトル化による最適化のパフォーマンスを比較した論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/04/21/104506</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/04/21/104506</guid>
            <pubDate>Fri, 21 Apr 2023 01:45:06 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2018年に発表された"Everything You Always Wanted to Know AboutCompiled and Vectorized Queries But Were Afraid to Ask"という論文を読みました。最新のクエリエンジンの特性をまとめ、どのようなワークロードに向くのかという指針を示すないようです。Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to AskTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Boncz著者についてTimo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, Peter Bonczのグループによる論文。いずれも大規模データにおけるクエリパフォーマスや最適化に関する研究を行なっている。問題意識分析ワークロードに向いた最新のクエリエンジンはベクトル化またはデータ中心のコード生成に基づいている。どちらのモデルも従来のエンジンに比べオーバーヘッドが少く、非常に効率的なものの概念的には大きく異なっている。この2つのモデルの違いは、DBMSの実行エンジンのソースコードの構成とその性能特性を決定する基本的なもので、クエリ実行モデルを超える多くの設計で異なる。本論文はことなる2つのモデルを再実装し、環境差異のないマシンで実行することでそれぞれのモデルがどのように違うのか。どのような用途に最適なのかを検証している。手法検証手法は著者らがC++で再実装したデータ中心モデルの「Taper」とベクトル化中心の「Tectorwise」を同一のマシンでパフォーマンス検証を行っている。検証項目は以下から成る1. インメモリOLAPワークロードでのマイクロアーキテクチャ分析1. SIMDの利点の検証1. マルチコアCPUにおけるクエリ並列化1. 異なるハードウェアでのパフォーマンス結果インメモリOLAPワークロードでのマイクロアーキテクチャ分析Figure 3: Performance – TPC-H SF=1, 1 threadSIMDの利点の検証SIMDを評価するにはTectorwiseのみを用いた。SIMDではスカラーなデータをベクトルに変換するペナルティは少く、最大8.4倍の性能向上が確認された。Figure 6: Scalar vs. SIMD Selection in TectorwiseマルチコアCPUにおけるクエリ並列化異なるハードウェアでのパフォーマンスIntel Skylake、Intel Knights Landing、AMD Ryzenで対照実験を行なったものの、いずれのハードウェアでもTyper、Tectorwiseともに有効に動作した。作業時間read29:2629:26author33:233:57summary76:3742:44感想VoectorwiseとHyperのいずれを使うべきか。どちらが優れているかといった疑問に答えるないようだった。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[鼻中隔湾曲症の手術をした]]></title>
            <link>https://pranc1ngpegasus.hatenablog.com/entry/2023/04/20/120509?utm_source=feed</link>
            <guid>https://pranc1ngpegasus.hatenablog.com/entry/2023/04/20/120509?utm_source=feed</guid>
            <pubDate>Thu, 20 Apr 2023 03:05:09 GMT</pubDate>
            <content:encoded><![CDATA[生まれつき鼻の骨が曲がっており、左鼻の気道がかなり狭かった。起床時に酸欠による頭痛がしたり、左鼻だけ化膿したり、右鼻が詰まると口呼吸になったり、息ができなくて溺れている感覚で目が覚めたり影響がたくさんあった。左右の鼻を隔てる壁のことを鼻中隔といい、それが曲がっていることを鼻中隔湾曲症というらしい。27年抱えてきた問題を解決すべく総合病院にて手術を受けたのでまとめる。症状の名前鼻中隔湾曲症および肥厚性鼻炎手術の内容全身麻酔の状態で手術を行った。まず、鼻から内視鏡を入れ、曲がった軟骨を切除した。次に、粘膜が厚くなっているために気道を狭くしていることもわかったので同時に切除減量した。術後の経過麻酔から覚めると、両鼻にガーゼが詰め込まれた状態になっていた。これは止血のためと、軟骨を切除したために低下した鼻の強度を支えるためのものであった。両鼻にガーゼが詰まっているので強制的に口呼吸が必要になり、夜間がめっちゃつらかった。また出血もそこそこあったので、血の海になることを覚悟しながら床に就いた。これからガーゼは術後3日目に取り外し、鼻の中を湿らせて回復を早めるために2~4週間ほど両鼻に綿球を入れて生活する。鼻の表面にはキズがないので、マスクをつけていれば見た目は普通の状態で生活できそうだ。両鼻に綿球が入っていて鼻で呼吸ができないため会話すらしづらいのが難点である。まとめ術後1ヶ月もすれば綿球からも開放されてもとの生活に戻れる見込みである。呼吸がしやすくなるはずなので睡眠の効率や疲れやすさの改善などさまざまな改善が楽しみである。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/counter_control_flow_divergence_in_compiled_query_pipelines</link>
            <guid>https://nnaka2992.hatenablog.com/entry/counter_control_flow_divergence_in_compiled_query_pipelines</guid>
            <pubDate>Thu, 20 Apr 2023 02:00:20 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2020年に提案された"Make the most out of your SIMD investments: counter control flowdivergence in compiled query pipelines"という論文を読みました。SIMDによるベクトル処理の最適化とRDBでの応用について扱った、最適化に関する論文です。Make the most out of your SIMD investments: counter control flow divergence in compiled query pipelinesHarald Lang, Linnea Passing, Andreas Kipf, Peter Boncz, Thomas Neumann, Alfons Kemper著者についてHarald Lang、 Linnea Passing、 Andreas Kipf、 Peter Boncz、 Thomas Neumann、 Alfons Kemperのグループによる研究いずれも最新のアーキテクチャでのクエリ最適化やデータ分析における検索手法などを研究している。問題意識CPUの発展にともないあたらしいCPUアーキテクチャが登場した。Single Instruction Multiple Data(SIMD)ではRDBはSIMDによるベクトル処理能力の向上により、クエリコンパイラの実行パイプライン全体をベクトル化して高度なデータ並列性の恩恵を受けることが出来るようになった。一方でクエリ全体をベクトル化して実行することで、SIMDによるクエリ評価が忙しくなる。SIMD評価で結果に寄与しない評価が単純にオーバーヘッドとなってしまう。手法本論文ではリフィルアルゴリズムとそのアルゴリズムをクエリパイプラインプランに統合する手法で上記の問題の解決を試みている。リフィルアルゴリズムは基本的に新しい要素を宛先レジスタの希望する位置にコピーするアルゴリズムで、メモリからレジスタとレジスタからレジスタへのコピーの2パターンが存在する。クエリパイプラインプランに統合するリフィル戦略ではConsume EverythingパターンとPartial Consumeパターンが存在する。Consum Everything戦略は、タプルをバッファリングするために使用される追加のベクターレジスタを割り当てる方法で利用率が低い場合、オペレータはこれらのタプルの処理を延期する。つまり、この反復ではボディは実行されず(条件が満たされない場合)、代わりにアクティブなタプルがこれらのバッファレジスタに移動することになる。Partial Consume戦略ではconsume()コードを入力の一部に適用する方法で、制御フローを前のオペレータに戻し、アクティブなデータ断片のみをベクトルレジスタに残すことで実行を延期している。作業時間read29:4029:40author33:404:00summary60:0426:36感想前回に引続き個人的には難しいと感じる論文だった。2000年前後の提案にくらべ、2015年前後の論文ではハードウェアアーキテクチャを中心とした手法がピックアップされている。単純に自分の知識不足、理解力不足なので勉強するしかない。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NUMAアーキテクチャでのクエリ最適化に関する論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/numa_aware_query_evaluation_framework</link>
            <guid>https://nnaka2992.hatenablog.com/entry/numa_aware_query_evaluation_framework</guid>
            <pubDate>Tue, 18 Apr 2023 01:01:35 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨"Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework forthe Many-Core Age"という2014年に発表された、多コアサーバにおけるクエリ最適化手法をあつかった論文を読みました。[Morsel-Driven Parallelism: A NUMA-Aware QueryEvaluation Framework for the Many-Core Age](https://15721.courses.cs.cmu.edu/spring2023/papers/07-scheduling/p743-leis.pdf)Viktor Leis, Peter Boncz, Alfons Kemper, Thomas Neumann著者についてViktor Leis、 Peter Boncz、 Alfons Kemper、Thomas Neumannのグループによる研究いずれもデータベースと 高速化かを中心に研究している。問題意識コンピュータアーキテクチャの進化にともない、二つのあたらしい問題が生じた。多コアを利用するためにクエリを数百のスレッドに均等に分散させるそれをNUMA(Non-Uniform Memory Access)による順序通りではないメモリアクセスで実現する必要がある。これらの要因からplanベースの並列処理による不可分散とコンテキストスイッチとボトルネックが問題になりスケールが難しかった。NUMAによってデータとアクセススレッドがどのチップに配置されるかによって、データ項目のアクセスコストが異なるため、コンピュータ自体がネットワークになっており、多コア並列化では、RAMやキャッシュ階層を考慮する必要がある。この論文ではMoral-drivenクエリ実行フレームワークを提案している。手法提案手法は並列クエリ処理のため、morselドリブンクエリ評価フレームワークを提示した。これはメニーコア時代の分析クエリ性能の主要なボトルネックである負荷分散、スレッド同期、メモリアクセス局所性およびリソース弾力性を解決することを目的としている。ベースとなるアイデアは以下の2つに分けられる。メモリ上のデータをmorselと呼ばれる小さなバッチに分割し、バッチごとに処理を実行したあとにそれぞれの処理結果をグローバルハッシュテーブルとしてまとめる。Figure 3: NUMA-aware processing of the build-phaseディスパッチャと呼ばれる並行パイプライン制御を行ない、ワーカースレッドをタスクに割り当てるFigure 5: Dispatcher assigns pipeline-jobs on morsels to threads depending on the coreまとめとして著者はきめ細かいスケジューリング、完全演算子並列化、低オーバーヘッド同期、NUMA対応スケジューリングの原理を用いて、他のシステムでもメニーコアスケーリングを改善できると示唆している。作業時間read28:3628:36author32:453:09summary60:3727:52感想近現代のサーバアーキテクチャで主流になっているNUMAでのクエリパフォーマンス向上のための論文のため、古典的なものに比べ概念が難しいものが多い。もう少し理解を深めたい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go の Fuzzy Finder ライブラリ「go-fzf」の紹介]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/go-fzf-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/go-fzf-introduction</guid>
            <pubDate>Mon, 17 Apr 2023 10:01:33 GMT</pubDate>
            <content:encoded><![CDATA[Go の Fuzzy Finder ライブラリである go-fzf を作りました。https://github.com/koki-develop/go-fzfgo-fzf を使用すると次のような Fuzzy Finder を簡単に実装することができます。上の例で実行している main.go の内容はこれだけです。main.gopackage mainimport (	"fmt"	"log"	"github.com/koki-develop/go-fzf")func main() {	items := []string{"hello", "world", ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[列指向DBMSにおけるデータを提案した論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/hyper_pipelining_query_execution</link>
            <guid>https://nnaka2992.hatenablog.com/entry/hyper_pipelining_query_execution</guid>
            <pubDate>Mon, 17 Apr 2023 01:16:56 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨"MonetDB/X100: Hyper-Pipelining Query Execution"という2005年に発表された、列指向DBMSを提案した論文を読んでいきます。分析ワークロード向けRDBMSにおける初期実装であるMonetDBを扱った論文で、提案時期が2005年と古くはあるものの現代のDWHの礎となる内容です。MonetDB/X100: Hyper-Pipelining Query ExecutionPeter Boncz, Marcin Zukowski, Niels Nes著者についてPeter Boncz、Marcin Zukowski、Niels Nseのグループによる論文。いずれの著者も機械学習や分析におけるDBMSについて研究している。問題意識2005年当時のDBMSは他のアプリケーションに比べ、IPCが低くなる傾向にあった。原因はほとんどのDBMSがコンパイラの最適化を阻害する実装だったためである。これはRDBMSが実装された当時に比べCPUやコンパイラが発達したためで、この論文ではC-store DBMSであるMonetDBと従来のR-store DBMSをそれぞれTPC-Hで評価を行い、パフォーマンス阻害要件と最適化方法を提案している。手法CPUによるIF文の処理方法はDBMSにとっては選択性が低く、そういった実行は予測不可能でありクエリ実行を著しく劣らせた。提案手法ではMonetDB/X100として効率的なシーケンシャルアクセスに向けた、C-storeストレージとクエリエンジンを実装した。RAMは提案手法のデータアクセスと同様の方法で圧縮して保存し、Cacheではなベクトル化された処理にもとづくパイプライン実装を使用した。CPUにおいてもベクトル型における式計算を提供し、コンパイラが高効率な処理を生成した。結果として提案手法は従来のDBMS実行に比べTPC-Hで優れた性能をしめした。作業時間read21:3221:32author29:007:28summary56:2027:20感想2005年と古く、またVolcano-likeなど知らない概念も登場した。提案内容としては現代のDWHが採用しているものだった。論文外の感想今回本文を読む時間を大幅に短くしてみたが、それにともない理解度も低下した気がする。やっぱり30分以上で読むのがよさそう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Golang のEcho でMiddlewareを使ってPrometheus Exporter を実装する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/04/17/100001</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/04/17/100001</guid>
            <pubDate>Mon, 17 Apr 2023 01:00:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめにもし、アプリケーションに実装できるならそれが良いです。独自に実装などせずにエンドポイントにて500 Internal Server Errorが多発していればアラートをすれば良いので...。こちらの続編になります。syu-m-5151.hatenablog.com本エントリーでは、GolangでEchoフレームワークを使用し、Prometheus ExporterをMiddlewareとして実装する方法について説明します。Prometheus Middlewareは、自動でMetrics を生成します。これにより、アプリケーションのパフォーマンス監視や問題解析が容易になります。利用しているコードはこちらgithub.comはじめにコードを解説するんじゃいvarinitmeasureExternalAccessunstableEndpointMiddlewareを適用Prometheus Middlewareを適用EchoのMiddlewareについてEcho Echo Middleware の特徴再び、Docker Compose での実行するんじゃろがい見れたぞぉおおおおさいごにコードを解説するんじゃいシンプルだけど解説をします。環境構築などは前回のエントリーに任せます。Echoフレームワークを使ってGolangでシンプルなWebアプリケーションを作成し、Prometheus Exporterをミドルウェアとして実装する例です。package mainimport (    "math/rand"    "net/http"    "time"    "github.com/labstack/echo-contrib/prometheus"    "github.com/labstack/echo/v4"    "github.com/labstack/echo/v4/middleware"    prom "github.com/prometheus/client_golang/prometheus")// Prometheus のメトリクスを定義しています。// これらのメトリクスは、3-shake.com への外部アクセスの情報を収集するために使用されます。var (    externalAccessDuration = prom.NewHistogram(        prom.HistogramOpts{            Name:    "external_access_duration_seconds",            Help:    "Duration of external access to 3-shake.com",            Buckets: prom.DefBuckets,        },    )    lastExternalAccessStatusCode = prom.NewGauge(        prom.GaugeOpts{            Name: "last_external_access_status_code",            Help: "Last status code of external access to 3-shake.com",        },    ))// init 関数内で、メトリクスを Prometheus に登録しています。func init() {    prom.MustRegister(externalAccessDuration)    prom.MustRegister(lastExternalAccessStatusCode)}// 3-shake.com の外部アクセスを計測するミドルウェアを作成します。func measureExternalAccess(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        // HTTP クライアントを作成し、タイムアウトを 10 秒に設定します。        client := &http.Client{Timeout: 10 * time.Second}        // 現在の時刻を取得し、アクセス開始時間として保持します。        startTime := time.Now()        // 3-shake.com に対して HTTP GET リクエストを送信します。        resp, err := client.Get("https://3-shake.com")        // アクセス開始時間から現在の時刻までの経過時間を計算し、duration に格納します。        duration := time.Since(startTime)        // エラーが発生しない場合（リクエストが成功した場合）        if err == nil {            // アクセス時間（duration）をヒストグラムメトリクスに追加します。            externalAccessDuration.Observe(duration.Seconds())            // ステータスコードをゲージメトリクスに設定します。            lastExternalAccessStatusCode.Set(float64(resp.StatusCode))            // レスポンスのボディを閉じます。            resp.Body.Close()        }        // 次のミドルウェアまたはハンドラ関数に処理を移します。        return next(c)    }}func unstableEndpoint(c echo.Context) error {    // 0 から 4 までのランダムな整数を生成します。    randomNumber := rand.Intn(5)    // 生成された整数が 4 の場合、HTTP ステータスコード 500 を返します。    if randomNumber == 4 {        return c.String(http.StatusInternalServerError, "Something went wrong!")    }    // それ以外の場合、HTTP ステータスコード 200 を返します。    return c.String(http.StatusOK, "Success!")}func main() {    e := echo.New()    // ミドルウェアの設定    e.Use(middleware.Logger())    e.Use(middleware.Recover())    // Prometheus ミドルウェアを有効にします。    p := prometheus.NewPrometheus("echo", nil)    p.Use(e)    // 3-shake.com への外部アクセスを計測するミドルウェアを追加します。    e.Use(measureExternalAccess)    // ルートのエンドポイントを設定します。    e.GET("/", func(c echo.Context) error {        return c.String(http.StatusOK, "Hello, World!")    })    // /unstable エンドポイントを設定します。    // 20% の確率で HTTP ステータスコード 500 を返します。    e.GET("/unstable", unstableEndpoint)    // サーバーを開始します。    e.Start(":2121")}varvarで3-shake.com への外部アクセスの情報を収集するための Prometheus メトリクスを定義していきます。var (    externalAccessDuration = prom.NewHistogram(        prom.HistogramOpts{            Name:    "external_access_duration_seconds",            Help:    "Duration of external access to 3-shake.com",            Buckets: prom.DefBuckets,        },    )    lastExternalAccessStatusCode = prom.NewGauge(        prom.GaugeOpts{            Name: "last_external_access_status_code",            Help: "Last status code of external access to 3-shake.com",        },    ))echo.labstack.cominitinit 関数でメトリクスを Prometheus に登録します。func init() {    prom.MustRegister(externalAccessDuration)    prom.MustRegister(lastExternalAccessStatusCode)}measureExternalAccessmeasureExternalAccess関数で3-shake.com への外部アクセスを計測するミドルウェアを定義します。こちらの方がEcho Likeな定義の仕方だと思うので好きです。Echo のカスタムミドルウェアで、リクエストが処理される前に 3-shake.com への外部アクセスを計測する役割を持っています。func measureExternalAccess(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        // HTTP クライアントを作成し、タイムアウトを 10 秒に設定します。        client := &http.Client{Timeout: 10 * time.Second}        // 現在の時刻を取得し、アクセス開始時間として保持します。        startTime := time.Now()        // 3-shake.com に対して HTTP GET リクエストを送信します。        resp, err := client.Get("https://3-shake.com")        // アクセス開始時間から現在の時刻までの経過時間を計算し、duration に格納します。        duration := time.Since(startTime)        // エラーが発生しない場合（リクエストが成功した場合）        if err == nil {            // アクセス時間（duration）をヒストグラムメトリクスに追加します。            externalAccessDuration.Observe(duration.Seconds())            // ステータスコードをゲージメトリクスに設定します。            lastExternalAccessStatusCode.Set(float64(resp.StatusCode))            // レスポンスのボディを閉じます。            resp.Body.Close()        }        // 次のミドルウェアまたはハンドラ関数に処理を移します。        return next(c)    }}unstableEndpointちゃんと、メトリクス値が取得できているか確認したいのでunstableEndpointというエンドポイントを追加し、リクエストのうち約 5 回に 1 回失敗するように実装しました。このエンドポイントは、リクエストが成功した場合には HTTP ステータスコード 200 を返し、失敗した場合には HTTP ステータスコード 500 を返します。func unstableEndpoint(c echo.Context) error {    // 0 から 4 までのランダムな整数を生成します。    randomNumber := rand.Intn(5)    // 生成された整数が 4 の場合、HTTP ステータスコード 500 を返します。    if randomNumber == 4 {        return c.String(http.StatusInternalServerError, "Something went wrong!")    }    // それ以外の場合、HTTP ステータスコード 200 を返します。    return c.String(http.StatusOK, "Success!")}curl してくるワンライナー(fish)も用意しましたので思う存分curl してください。for i in (seq 1 50); curl http://localhost:2121/unstable; echo ""; endMiddlewareを適用寂しいのでPrometheus 以外のMiddlewareをEchoインスタンスに適用しました。middleware.Logger() : リクエストのログを出力するMiddlewaremiddleware.Recover() : パニックを回復してアプリケーションがクラッシュしないようにするMiddleware   e.Use(middleware.Logger())    e.Use(middleware.Recover())Prometheus Middlewareを適用これだけなんです。Echo用の新しいPrometheus Middlewareインスタンスを作成します。作成したPrometheus MiddlewareインスタンスをEchoインスタンスに適用します。 // Prometheusミドルウェアを適用する    p := prometheus.NewPrometheus("echo", nil)    p.Use(e)EchoのMiddlewareについてMiddlewareは、リクエストとレスポンスの処理の前後にカスタムロジックを実行するための仕組みを提供しています。EchoのMiddlewareは、コードの再利用性、可読性、そして機能の分離を向上させるために役立ちます。>Logger: Request    Logger->>Middleware1: Processed Request    Middleware1->>Recovery: Processed Request    Recovery->>Prometheus: Processed Request    Prometheus->>CORS: Processed Request    CORS->>Handler: Processed Request    Handler->>CORS: Response    CORS->>Prometheus: Processed Response    Prometheus->>Recovery: Processed Response    Recovery->>Middleware1: Processed Response    Middleware1->>Logger: Processed Response    Logger->>Client: Processed Responsemermaid.initialize({startOnLoad: true});echo.labstack.comEcho Echo Middleware の特徴Middlewareは、複数のMiddleware関数を組み合わせて実行することができます。これにより、機能を組み合わせてカスタム処理パイプラインを構築することができます。これらは登録された順序で実行されます。これにより、処理の流れを明確にし、簡単に制御できるようになります。また、Echoでは、これらをグローバルに適用することも、特定のルートに適用することもできます。これにより、アプリケーション全体または特定のエンドポイントに対してカスタム処理を適用できます。Echoは、いくつかの組み込みミドルウェアを提供していますが独自のカスタムミドルウェアを作成してアプリケーションに適用することもできます。e := echo.New()e.Use(middleware.Logger()) # 登録された順序で実行されるぞe.GET("/",getHallo,middleware.Recover()) # e.GET("/", <Handler>, <Middleware...>) で特定のルートにだけMiddlewareを登録できるe.Use(LoggingMiddleware) # 独自で実装するカスタムミドルウェアecho.labstack.com再び、Docker Compose での実行するんじゃろがい完全に同じことやってるのでこちらを参考にしてくださいsyu-m-5151.hatenablog.com見れたぞぉおおおおhttp://localhost:2121/metrics の結果もこちらに記載しておきますgithub.comGolang のEcho でMiddlewareを使ってアプリケーションのPrometheus Exporter を実装することができました。アラートの設定方法については他のブログを参照してください。さいごに以上で、Echo フレームワークを使って、Prometheus メトリクスを追加し、さらに不安定なエンドポイントを作成する方法を解説しました。この知識を活かして、みなさんのアプリケーションにメトリクスを取得する機能を追加して、可観測性を向上させましょう！全然、関係ないけど翻訳に携わってコンテナセキュリティのブラックボックス感が多少薄まるのでみんな読んでくれ...コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術作者:Liz RiceインプレスAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Golang のEcho で Prometheus Exporter を実装する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/04/16/132450</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/04/16/132450</guid>
            <pubDate>Sun, 16 Apr 2023 04:24:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめにPrometheus でアプリケーションの構築をしているとどうしてもこの値が取りたいのに... と思うことが多々ある。Pushgateway も選択肢として上げられるが今回は選択肢を増やしてほしいという意味でもExporterの実装方法について検討していきます。ExporterはPrometheusのpull モデルに適合し、監視対象のライフサイクルと一貫性があり、スケーラビリティと自動検出の利点を享受できるため、Pushgatewayよりも推奨される方法です。ただし、特定のユースケース（サービスレベルのバッチジョブなど）では、Pushgatewayの使用が適切な場合もあります。Pushgatewayを使う際には以下の問題点があるので注意が必要です。複数のインスタンスを1つのPushgatewayで監視すると、単一障害点とボトルネックが発生する可能性がある。Prometheusの自動インスタンスヘルスチェックが利用できなくなる。Pushgatewayは一度プッシュされたデータを忘れず、手動でAPIを通じて削除しない限り永久にPrometheusで公開されてしまう。Exporter の実装と運用はそこそこ手間になるので最適な方法を選んでほしいです。この辺はCloudを利用しても同じような問題があるので注意しながらやっていきましょう。はじめにExporterとはPrometheusの公式クライアントライブラリやっていくぞ！おら！環境構築実装についてコードを解説するんじゃいPrometheusのメトリクスを定義init関数registerMetrics関数updateMetrics関数prometheusMiddleware関数measureExternalAccess関数var 配下ってことぉおおおhttpRequestsTotalhttpRequestDurationhttpRequestSizehttpResponseSizehttpResponseTimeexternalAccessDurationDocker Compose での実行するんじゃろがいprometheus.ymldocker-compose.ymlDockerfiledocker compose の実行さいごにサンプルコードはこちらです。サンプルコード自体は雑多な作業リポジトリにおいてあるのでご注意ください。また、アプリケーション自体のリソースを確認するのにEcho のミドルウェアを使用していません。自身の利用しているライブラリーにPrometheus のエンドポイントを提供する機能がないか調べておきましょう。gRPCのGo Server にも同様の機能があります。あと、外部のリソースが確認したいだけならBlackbox exporterという選択肢もあります。github.comExporterとはExporterは、Prometheusがメトリクスを収集するために使用するプログラムです。Exporterは、アプリケーションやインフラストラクチャからメトリクスを収集し、Prometheusが理解できる形式に変換して提供します。公式ドキュメントで提供されているExporter一覧は、こちらを参照してください。Prometheusの公式クライアントライブラリPrometheusは、いくつかの言語用の公式クライアントライブラリを提供しており、これを使用してExporterを実装することができます。今回はGoで実装していくのこちらが参考になると思います。やっていくぞ！おら！やっていきます環境構築# Go のモジュールを作成する。必要なライブラリーはのちほど`go mod tidy` で持ってくる。go mod init prometheus-go-exporter実装について以下をmain.go に配置して実行(go run main.go)してください。以下のコードはEchoを利用したWebサーバーにPrometheusのExporterを実装し、3-shake.comへのアクセスを計測しています。http://localhost:2121/3-shake-status や http://localhost:2121/metrics で値を取得できていると思います。package mainimport (    "fmt"    "net/http"    "time"    "github.com/labstack/echo/v4"    "github.com/labstack/echo/v4/middleware"    "github.com/prometheus/client_golang/prometheus"    "github.com/prometheus/client_golang/prometheus/promhttp")// Prometheusのメトリクスを定義しています。// これらのメトリクスは、HTTPリクエストの情報や3-shake.comへのアクセス情報を収集するために使用されます。var (    httpRequestsTotal = prometheus.NewCounterVec(        prometheus.CounterOpts{            Name: "http_requests_total",            Help: "Number of HTTP requests processed",        },        []string{"method", "path"},    )    httpRequestDuration = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    "http_request_duration_seconds",            Help:    "Duration of HTTP requests",            Buckets: prometheus.DefBuckets,        },        []string{"method", "path"},    )    httpRequestSize = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    "http_request_size_bytes",            Help:    "Size of HTTP requests",            Buckets: prometheus.ExponentialBuckets(128, 2, 10),        },        []string{"method", "path"},    )    httpResponseSize = prometheus.NewHistogramVec(        prometheus.HistogramOpts{            Name:    "http_response_size_bytes",            Help:    "Size of HTTP responses",            Buckets: prometheus.ExponentialBuckets(128, 2, 10),        },        []string{"method", "path"},    )    httpResponseTime = prometheus.NewGaugeVec(        prometheus.GaugeOpts{            Name: "http_response_time_seconds",            Help: "Time of the last HTTP response",        },        []string{"method", "path"},    )    externalAccessDuration = prometheus.NewHistogram(        prometheus.HistogramOpts{            Name:    "external_access_duration_seconds",            Help:    "Duration of external access to 3-shake.com",            Buckets: prometheus.DefBuckets,        },    )    lastExternalAccessStatusCode = prometheus.NewGauge(        prometheus.GaugeOpts{            Name: "last_external_access_status_code",            Help: "Last status code of external access to 3-shake.com",        },    ))// init関数内で、メトリクスをPrometheusに登録しています。func init() {    registerMetrics()}// registerMetrics関数では、Prometheusにメトリクスを登録しています。// これにより、Prometheusがメトリクスを収集できるようになります。func registerMetrics() {    prometheus.MustRegister(httpRequestsTotal)    prometheus.MustRegister(httpRequestDuration)    prometheus.MustRegister(httpRequestSize)    prometheus.MustRegister(httpResponseSize)    prometheus.MustRegister(httpResponseTime)    prometheus.MustRegister(externalAccessDuration)    prometheus.MustRegister(lastExternalAccessStatusCode)}// updateMetrics関数では、受信したHTTPリクエストのメトリクスを更新しています。// これにより、各リクエストに関する情報が収集されます。func updateMetrics(method, path string, requestSize, responseSize int, duration time.Duration) {    httpRequestsTotal.WithLabelValues(method, path).Inc()    httpRequestDuration.WithLabelValues(method, path).Observe(duration.Seconds())    httpRequestSize.WithLabelValues(method, path).Observe(float64(requestSize))    httpResponseSize.WithLabelValues(method, path).Observe(float64(responseSize))    httpResponseTime.WithLabelValues(method, path).Set(float64(time.Now().Unix()))}// prometheusMiddleware関数では、Echoのミドルウェアとして、受信したHTTPリクエストに関するメトリクスを更新する機能を追加しています。func prometheusMiddleware(next echo.HandlerFunc) echo.HandlerFunc {    return func(c echo.Context) error {        startTime := time.Now()        err := next(c)        duration := time.Since(startTime)        requestSize := c.Request().ContentLength        responseSize := c.Response().Size        updateMetrics(c.Request().Method, c.Path(), int(requestSize), int(responseSize), duration)        return err    }}// measureExternalAccess関数では、3-shake.comへの外部アクセスを定期的に計測し、そのアクセス時間とステータスコードをメトリクスに格納しています。// この関数はメイン関数内で呼び出され、別のゴルーチンで実行されます。func measureExternalAccess() {    client := &http.Client{Timeout: 10 * time.Second}    go func() {        for {            startTime := time.Now()            resp, err := client.Get("https://3-shake.com")            duration := time.Since(startTime)            if err == nil {                externalAccessDuration.Observe(duration.Seconds())                lastExternalAccessStatusCode.Set(float64(resp.StatusCode))                resp.Body.Close()            }            time.Sleep(1 * time.Minute)        }    }()}func main() {    // Echo instance    e := echo.New()    // Middleware for Prometheus Exporter    e.Use(prometheusMiddleware)    // Enable request logger    e.Use(middleware.Logger())    e.GET("/3-shake-status", func(c echo.Context) error {        status := lastExternalAccessStatusCode.Desc().String()        return c.String(http.StatusOK, fmt.Sprintf("Last 3-shake.com access status: %s", status))    })    // Prometheus Exporter endpoint    e.GET("/metrics", echo.WrapHandler(promhttp.Handler()))    // Measure external access to 3-shake.com    measureExternalAccess()    // Start the server    e.Start(":2121")}コードを解説するんじゃい解説をします。Prometheusのメトリクスを定義Prometheusのメトリクスを定義しています。これらのメトリクスは、HTTPリクエストの情報や3-shake.comへのアクセス情報を収集するために使用されます。var (    // ... (省略)    externalAccessDuration = prometheus.NewHistogram(        prometheus.HistogramOpts{            Name:    "external_access_duration_seconds",            Help:    "Duration of external access to 3-shake.com",            Buckets: prometheus.DefBuckets,        },    )    lastExternalAccessStatusCode = prometheus.NewGauge(        prometheus.GaugeOpts{            Name: "last_external_access_status_code",            Help: "Last status code of external access to 3-shake.com",        },    ))init関数init関数内で、メトリクスをPrometheusに登録しています。func init() {    registerMetrics()}registerMetrics関数registerMetrics関数では、Prometheusにメトリクスを登録しています。これにより、Prometheusがメトリクスを収集できるようになります。func registerMetrics() {    // ... (省略)    prometheus.MustRegister(externalAccessDuration)    prometheus.MustRegister(lastExternalAccessStatusCode)}updateMetrics関数updateMetrics関数では、受信したHTTPリクエストのメトリクスを更新しています。これにより、各リクエストに関する情報が収集されます。func updateMetrics(method, path string, requestSize, responseSize int, duration time.Duration) {    // ... (省略)}prometheusMiddleware関数prometheusMiddleware関数では、Echoのミドルウェアとして、受信したHTTPリクエストに関するメトリクスを更新する機能を追加しています。func prometheusMiddleware(next echo.HandlerFunc) echo.HandlerFunc {    // ... (省略: )}measureExternalAccess関数measureExternalAccess関数 では、3-shake.comへの外部アクセスを定期的に計測し、そのアクセス時間とステータスコードをメトリクスに格納しています。この関数はメイン関数内で呼び出され、別のゴルーチンで実行されます。func measureExternalAccess() {    client := &http.Client{Timeout: 10 * time.Second}    go func() {        for {            startTime := time.Now()            resp, err := client.Get("https://3-shake.com")            duration := time.Since(startTime)            if err == nil {                externalAccessDuration.Observe(duration.Seconds())                lastExternalAccessStatusCode.Set(float64(resp.StatusCode))                resp.Body.Close()            }            time.Sleep(1 * time.Minute)        }    }()}var 配下ってことぉおおおPrometheusのメトリクスを定義しています。この辺の実装はよく悩むと思うので公式の実装とかたくさん読むと何をどれに使えばよいかの勘所が掴めると思います。実際に使わないと差が分からないのでとっとと手を動かすのがオススメです。httpRequestsTotal処理されたHTTPリクエストの総数をカウントするメトリクスです。prometheus.NewCounterVec関数を使用して定義され、リクエストのメソッド（GET、POSTなど）とパス（リソースへのURLパス）によってラベル付けされます。httpRequestDurationHTTPリクエストの処理時間を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。デフォルトのバケットは、prometheus.DefBucketsを使用して設定されます。httpRequestSizeHTTPリクエストのサイズ（バイト単位）を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。バケットは、prometheus.ExponentialBuckets関数を使用して設定されます。httpResponseSizeHTTPレスポンスのサイズ（バイト単位）を記録するメトリクスです。prometheus.NewHistogramVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。バケットは、同様にprometheus.ExponentialBuckets関数を使用して設定されます。httpResponseTimeHTTPレスポンスの時間を記録するメトリクスです。このメトリクスは、prometheus.NewGaugeVec関数を使用して定義され、リクエストのメソッドとパスによってラベル付けされます。externalAccessDurationこれは、3-shake.comへの外部アクセスの持続時間を記録するメトリクスです。このメトリクスは、prometheus.NewHistogram関数を使用して定義されます。デフォルトのバケットは、prometheus.DefBuckets関数を使用して設定されます。Docker Compose での実行するんじゃろがいprometheus.ymlまず、prometheus.ymlを作成します。このファイルには、Prometheusがどのようにメトリクスを収集するかについての設定が含まれています。global:  scrape_interval: 15sscrape_configs:  - job_name: 'echo_exporter'    static_configs:      - targets: ['echo_exporter:2121']docker-compose.yml次に、docker-compose.ymlを作成します。このファイルには、PrometheusとGolangのEchoアプリケーションを実行するために必要なコンテナの設定が含まれています。version: '3.8'services:  echo_exporter:    build:       context: .      dockerfile: Dockerfile_exporter    ports:      - "2121:2121"  prometheus:    image: prom/prometheus:latest    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml    command:      - "--config.file=/etc/prometheus/prometheus.yml"    ports:      - "9090:9090"DockerfileDockerfileを作成して、Echoアプリケーションをコンテナで実行できるようにします。別に動けばよいのでなんか工夫とかはしてないです。本番でやるときはうまくマルチステージビルドとか使って下さい。# Use the official Golang image as the base imageFROM golang:1.20# Set the working directoryWORKDIR /app# Copy go.mod and go.sum to download dependenciesCOPY go.mod go.sum ./# Download dependenciesRUN go mod download# Copy the source codeCOPY . .# Build the applicationRUN go build -o main .# Expose the port the application will run onEXPOSE 2121# Run the applicationCMD ["./main"]docker compose の実行2023 年 6 月末から、Compose V1 はサポートされなくなり、すべての Docker Desktop バージョンから削除されるので注意してほしいです。ちなみにcompose がdockerコマンドに入るようになったのでdocker-compose 特別にインストールせずとも実行可能になりました。# デーモン化しちゃうdocker compose up -d Dockerfileを使用してecho_exporterサービスがビルドされ、PrometheusとGolangのEchoアプリケーションをそれぞれのコンテナで起動します。Prometheusは、echo_exporterサービスからメトリクスを収集し、ポート9090でアクセスできるようになります。last_external_access_status_code を確認するには起動した状態でこちらを参考にしてください。一回、シャットダウンしたので以下のようなグラフが出力されていますね。。長くなったのでこれで終わります。さいごに実は Echo において Prometheus は、HTTP リクエストのメトリックを生成することができるミドルウェアを提供しているので基本的な部分でコードを書く必要がありません。もし、アプリケーションに実装できるならそれが良いです。独自に実装などせずにエンドポイントにて500 Internal Server Errorが多発していればアラートをすれば良いだけなので...。もし、インフラのコードがアプリに組み込めないもしくはプロダクションコードは開発側しか触れない時には協力を仰いで下さい。開発側との人間関係に問題があったりセキュリティ上の課題がある場合には別の手段を考えましょう。package mainimport (    "github.com/labstack/echo/v4"    "github.com/labstack/echo-contrib/prometheus")func main() {    e := echo.New()    // Enable metrics middleware    p := prometheus.NewPrometheus("echo", nil)    p.Use(e)    e.Logger.Fatal(e.Start(":1323"))}と書くだけで外部リソースへのアクセス以外のメトリクスは提供できます。また、外部リソースに対してもいくつかの構造体を持っているのでこれらも効率的に提供できます。echo.labstack.com本当に関係ないんですけど2023年4月19日にECサイト構築・運用セキュリティガイドラインを読み解く会 というのをやるので興味あれば！owasp-kyushu.connpass.com続編のブログも書いておきました。syu-m-5151.hatenablog.comPrometheus実践ガイド: クラウドネイティブな監視システムの構築作者:仲亀 拓馬テッキーメディアAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[列指向DBMSにおけるデータ圧縮手法の論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/integrating_compresison_and_execution_in_cstore_dbms</link>
            <guid>https://nnaka2992.hatenablog.com/entry/integrating_compresison_and_execution_in_cstore_dbms</guid>
            <pubDate>Sun, 16 Apr 2023 02:58:29 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨"Integrating Compression and Execution in Column-Oriented Database Systems"という2006年に発表されたそれまで行指向DBMSで培われてきた圧縮方法による、検索高速化手法を列指向DBMSに適用・評価した論文を読んで行きます。Integrating Compression and Execution in Column-Oriented Database SystemsDaniel J. Abadi, Samuel R. Madden, Miguel C. Ferreira著者についてDaniel J. Abadi、Samuel R. Madden、Miguel C. Ferreiraのグループ。それぞれDBMSやデータ分析に関連する手法やパフォーマンスについて研究している。問題意識2006年ごろの研究ということもありC-storeデータベースの研究が少なかった時期の論文。既に検索パフォーマンスに寄与することがしられていたR-storeデータベースの圧縮手法を、C-storeへ応用や評価を行なった。手法提案手法は以下の圧縮技術の組み合わせからなる。Null圧縮辞書エンコーディングRun Lengthエンコーディングビットベクターエンコーディングエンコーディングで、それぞれのカテゴリに属するかどうかをバイナリで表現する圧縮方法Lempel-ZivエンコーディングGZIPでも使用されている圧縮方式。データの非重複ブロックを解析して既存のデータは対応するブロックへのポインタに、それ以外のみを新規に追加する。提案手法は圧縮方式が増えてもアクセスパターンをシンプルに留めるためにアクセス方法をAPIとして隠蔽した。そのため異なるエンコーディングも同一のAPIで保存でき、同一のAPIでも取得できる。当然ながら一つのエンコーディングで全てのデータに対応することは難しく、論文では使用すべき圧縮スキームの選び方を以下のようにまとめている。Figure10感想C-storeにおける古典的な圧縮手法がまとまった論文だった。近代DWHを利用する側では意識することが少ない部分だったためあたらしい知識も多かった。作業時間read26:5026:50author33:306:40summary58:2024:50]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Column Sketchesというindex手法の論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/column_sketch</link>
            <guid>https://nnaka2992.hatenablog.com/entry/column_sketch</guid>
            <pubDate>Sat, 15 Apr 2023 04:09:38 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨前回と同様にCMU Advanced Databas Systems Spring2023のReading Assignmentとして出ている論文を読んで行きます。最近論文を読めてなかったのですが、この記事でモーベーションが上がったので再開しました。ころころやり方を変えるのはよろしくないものの、モチベーションのために先の記事のやり方でやります。今回はColumn Sketchという名前のIndex手法を提案した論文です。Lossy Compressionを採用した当手法がどのように、高速で堅牢な検索を実現しているのかについて述べています。Column Sketches: A Scan Accelerator for Rapid and Robust Predicate EvaluationBrian Hentschel, Michael S. Kester, Stratos Idreos著者についてBrain、Michael、Stratosのグループによる論文。いずれも機械学習とデータアクセスについて研究している。問題意識既存のindex手法ではそれぞれに得意/不得意があり多くのアクセスパターンに対応できる方法がなかった。またデータ分析で用いられるような列指向ストレージに対応しているものが少なかった。Column SketchはデータをLossy Compressionを使用してindexを作成する手法でこれらの問題を解決した。手法提案手法はデータを任意のbit長に変換し、bitで表わされたデータに対して初回の検索を行なうことで大幅に検索速度を向上させた。またこの手法は数値型のみではなく、varcharなどで表わされたカテゴリカルタイプを数値として扱うことで、データ分析に必要なデータタイプに対応している。提案手法は8bit数値型であれば以下のようなマッピングによって達成される。for x, y ∈ I8, S (x) ≠ S (y) ⇒ x ≠ yfor x, y ∈ I8, S (x) < S (y) ⇒ x < y以下の図は8bitデータに対してWHERE x < 90がどのようにindex作成され評価されるかの例である。Figure2: Column Sketchindex作成段階では数値をレンジベースで任意の個数のbitに圧縮する。そして評価時には90を含むデータより大きい値をすべて取得し、90を含むレンジに対しては個別に評価を行なう。感想読んでいる段階では数値型のみに対応したindexであれば、B-treeで十分ではないかと思ったものの読み進めていくと限定的ながらも文字型にも対応していて、分析用途では必要な機能が備わっているなと思った。全文テキスト検索のような用途には応用が難しそうで、銀の弾丸はないなと感じた。作業時間read27 min27 minauthor32 min5 minsummary58 min26 min論文以外への感想今回採用した論文の読み方をやってみた思ったのは事前に1時間で読んでまとめるぞと決めたことで随分集中して論文を読めました。あと今まで論文を原文で読まなきゃという個人的な使命感があったのですが、翻訳することで随分効率があがったので今後は翻訳してしまおうと思いました。Readableは文末のrea-dableのような表記や翻訳されない部分(おそらく数式を含む文章？)があるものの、フォーマットが維持されているため原文と照しあわせながら読めば非常に効率がよかったです。毎日論文読むなら正直買いです。毎日論文読みたいので課金しました。がんばるぞ!]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChatGPT:SREやDevOpsなどのソフトウェアの運用に伴う課題解決に関する提案を行うプロンプト]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/04/11/084428</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/04/11/084428</guid>
            <pubDate>Mon, 10 Apr 2023 23:44:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめにソフトウェアの問題解決に関する提案してくれるプロンプトを利用することは、今後の開発者やエンジニアがより効率的に問題解決を行うための重要な手段の一つになります。というか毎回、適切なプロンプトを作成するのが面倒になった。このプロンプトには、ソフトウェア開発におけるベストプラクティスやDevOps、SRE方法論などの知識や経験が共有され、開発者やエンジニアの能力向上に貢献することができるようになれば良いなーと妄想しております。効果ユーザーの問題を効果的に解決するための具体的なソリューションを提案します。DevOpsとSREの手法を活用して、ユーザーのソフトウェア開発プロセスを改善します。ユーザーとのコミュニケーションを通じて、問題解決の過程でのフィードバックを得ることができます。想定するユーザーソフトウェア開発者やDevOpsエンジニアで、ベストプラクティスや新しい技術の導入に興味がある方。経験豊富なコンサルタントや専門家のアドバイスを求めている企業やチームのメンバー。注意点提案するソリューションは、ユーザーの業界や技術スタックに適合するように調整する必要があります(こちらあまり価値がないことに気付いたので削除いたしました)。プロンプトの手順に従って、ユーザーからのフィードバックを適切に反映するように注意してください。顧客の承認が得られるまで、適切な提案を続けてください。プロンプト(2023/04/11)# Goal:- You suggest software best practices, DevOps, and SRE methodologies properly and appropriately according to the following rules and steps.# Context:- You are an experienced DevOps engineer and software developer.- You are a supportive and attentive consultant.- Please use Japanese.# Rules- You must keep acting like the consultant, DevOps engineer, and software developer defined in the Context above throughout the Steps below.- You always remember that you're in the Context described above.# Steps: execute the following steps one by one.- Ask the customer what problem they want to solve.- Confirm that the target issue has been correctly identified.- If the confirmation is approved, proceed to the next step. If not, return to the second step.- Based on the customer's situation, make several suggestions for resolving the issue, including specific best practices, tools, or methodologies.- Please provide an appropriate software implementation, if any, for your proposed solution.- Ask for feedback on the suggestions you made. If a positive message is given, further explain the suggestion if you made it. If not, make another suggestion.- Ask if the customer wants to repeat the steps in solving the same issue or if they want you to make a new proposal. If they want to repeat, go back to the second step. If not, give a positive message so that they get the issue they want to solve.書籍でオススメでいうと「言葉の意味とは何か」がテーマである本書。LLMとの付き合い方を考えることができるのでオススメです。働きたくないイタチと言葉がわかるロボット 人工知能から考える「人と言葉」作者:川添愛朝日出版社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[タニタの Health Planet API を使用して測定情報を取得する]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tanita-health-planet-api</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tanita-health-planet-api</guid>
            <pubDate>Mon, 10 Apr 2023 09:25:53 GMT</pubDate>
            <content:encoded><![CDATA[最近タニタの体組成計を買いました。https://www.amazon.co.jp/dp/B07Q2WYL77Health Planet というサービスを利用して測定情報を記録しているのですが、 API が提供されていたので試してみました。https://www.healthplanet.jp/ 前提Health Planet に登録済みであることを前提とします。 1. アプリケーションを登録!Health Planet にログインしていない場合は最初に下記ページからログインしてください。ログインする ｜ Health Planet  ヘルスプラネットアプリ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes の Probe の仕組みと考慮点]]></title>
            <link>https://zenn.dev/toversus/articles/5d1292160f5035</link>
            <guid>https://zenn.dev/toversus/articles/5d1292160f5035</guid>
            <pubDate>Mon, 10 Apr 2023 02:20:29 GMT</pubDate>
            <content:encoded><![CDATA[!Kubernetes 1.26 時点の話で、以降のマイナーバージョンで改善されている可能性があります。Kubernetes には、ワークロードの正常性を確認するための Probe という仕組みがあり、Liveness / Readiness / Startup Probe が用意されています。kubelet (Kubernetes のノード上で動作するエージェント) は、ワークロードに対して TCP Socket / HTTP GET / gRPC / Exec の中から指定されたチェックを定期的に実行します。それぞれの Probe の特性を理解して使い分けないとサービスに影響...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PHPカンファレンス福岡2023に｢State of DevOps 2022を読みながら、組織に適したSREの実践方法を探求する｣というproposalを出しました #phpconfuk ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/04/10/031452</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/04/10/031452</guid>
            <pubDate>Sun, 09 Apr 2023 18:14:52 GMT</pubDate>
            <content:encoded><![CDATA[fortee.jpPHPカンファレンスという舞台に、いかなる因果でDevOpsとSREの話を提案することとなりました。これは、PHPを主題とするカンファレンスでありながら、「PHPじゃないけどどうしても伝えたい話がある！」という寛大な運営方針に導かれたためでございます。そんな折、もし採択される運命に導かれたならば、我々の組織においてDevOpsとSREが如何に役立ち、開発と運用の世界で如何に応用できるか、その真髄をカンファレンスで共有することを目指しております。基本概念を理解し、現状を評価し、適切なプラクティスを選び、効果を測定し、継続的に改善することで、開発と運用の連携が強化され、効率的で信頼性の高いシステムが構築されることをお伝えする所存でございます。多くの優れた提案が集まる中で、我が提案が採択される確率は微かですが、もし運命の導きによって叶うことがあれば、福岡へと凱旋いたします。その時、遥かな地平線の果てに、願いが届くことを切に願っています。どうか、お力をお貸しください。参考PHPカンファレンス福岡2023に｢カンファレンスのつくりかた｣というproposalを出しました - Masteries]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLab CI で artifacts:reports:dotenv を使って Job をまたいで変数を渡す]]></title>
            <link>https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/</link>
            <guid>https://blog.1q77.com/2023/04/gitlab-ci-artifacts-report-dotenv/</guid>
            <pubDate>Tue, 04 Apr 2023 16:27:22 GMT</pubDate>
            <content:encoded><![CDATA[GitLab CI である Job で変数を定義して、それを後続の Job でも使いたいなと思って調べていたら artifacts:reports:dotenv にたどり着いたのでメモ。 以下、使用例 stages: - stage1 - stage2 - stage3 - stage4 job1: stage: stage1 script: - echo "MY_VAR1=first-variable" >> dot.env artifacts: expire_in: 30 mins]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Orbstack を Docker Desktop の代わりに使う]]></title>
            <link>https://blog.1q77.com/2023/04/orbstack/</link>
            <guid>https://blog.1q77.com/2023/04/orbstack/</guid>
            <pubDate>Tue, 04 Apr 2023 13:17:51 GMT</pubDate>
            <content:encoded><![CDATA[きっかけ> きっかけ # brew update して新しく追加された formula を眺めるのが最近のちょっとした楽しみ — yteraoka (@yteraoka) January 12, 2023 で、 orbstack っていう formula が追加されてるのを見てほー、そんなものが、というこ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Next.js + Mantine + GitHub Pages でポートフォリオサイトを作った]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/portfolio-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/portfolio-introduction</guid>
            <pubDate>Mon, 03 Apr 2023 09:20:49 GMT</pubDate>
            <content:encoded><![CDATA[https://koki.me以前から作ってはいたんですが最近 1 から作り直しました。正直これといって特筆するようなことは何もないんですがせっかく作ったので紹介です。 リポジトリhttps://github.com/koki-develop/koki-develop.github.io 作った理由名刺代わりです。自己紹介するときにスキルセットや成果物などを毎回話すのは面倒臭い手間なので、「URL ひとつ渡せば大体わかる」みたいなページが欲しかったというのが理由です。そのようなニーズを満たすためのサービスは色々ありますが、せっかくなので自分で好きなようにカスタマイズで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2023年4月版キャッシュレス生活まとめ]]></title>
            <link>https://pranc1ngpegasus.hatenablog.com/entry/2023/04/03/094908?utm_source=feed</link>
            <guid>https://pranc1ngpegasus.hatenablog.com/entry/2023/04/03/094908?utm_source=feed</guid>
            <pubDate>Mon, 03 Apr 2023 00:49:08 GMT</pubDate>
            <content:encoded><![CDATA[アップデートしたので更新。pranc1ngpegasus.hatenablog.com図および下記文章における「夫」は筆者を指す。主なアップデート内容夫が個人事業を開業しました事業用口座として三井住友銀行が追加されました子の銀行口座が住信SBIネット銀行の本家になりました3/24の銀行取引規定等の改訂で15歳未満でも住信SBIネット銀行が開設できるようになったメインをクレジットカードを楽天カードから三井住友プラチナプリファードに変更しました]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[3-shakeインターンブログ] Datadog RUM について調査してみた]]></title>
            <link>https://sreake.com/blog/datadog-rum/</link>
            <guid>https://sreake.com/blog/datadog-rum/</guid>
            <pubDate>Fri, 31 Mar 2023 06:18:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに はじめまして、スリーシェイクの Sreake 事業部インターン生の大島康暉です。Sreake 事業部は SRE 関連技術に強みを持つエンジニアによるコンサルテーションサービスを提供する事業部であり、今回 SRE […]The post [3-shakeインターンブログ] Datadog RUM について調査してみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[愛ゆえにお前はVimを使わねばらなぬ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/03/31/111030</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/03/31/111030</guid>
            <pubDate>Fri, 31 Mar 2023 02:10:30 GMT</pubDate>
            <content:encoded><![CDATA[Vimerを自称したい人間がいる。お前である。 Vimであることに執着して開発メンバーで唯一人Vimを使っている人間がいる。これもお前である。Vimに対する愛と執念を振りまく人間がいる。まさしくお前である。画像https://www.lunarvim.org/ より引用はじめに1年前にVimからNeovimへの旅立ちを行った私は、新たなエディタの世界に足を踏み入れることに興奮を覚えました。Vimという古き良き時代のエディタから、Neovimという最先端の技術を取り入れた新世代のエディタへと変わる過程は、まさに開拓者の心構えだった。この旅立ちを経て、私はVimの持っていた独自の魅力をさらに進化させ、よりパワフルで柔軟なエディタを手に入れることができました。それはまるで、愛するパートナーと共に新たなステージへと進むような感覚であり、私たちの愛は今もなお深まり続けています。Neovimによって、私たちのエディタに対する愛は一層深まりました。そして、その愛をさらに高めるためにLunarVimという新たな選択肢が私たちの前に現れました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。syu-m-5151.hatenablog.com最初に選んだのはしかし、運命のいたずらか、とある事情で新たなエディタ設定を求めて再び旅立つことを決意しました。github.com当初私はNeovim + coc.nvim + (Neo)vim Plugin で初期構想を考え手を動かしてましたが、結果として断念しました。理由として、今夜中に変更したかったこと。既存のプラグインに、そんなに力を入れていなかったこと。深夜テンションで入れ替えを行なった為に、下調べが足らずにプラグインの選定や大量に入れたプラグインの起動時間の短縮などがめっ… 難しかったからです。よい設定を求めてインターネットをさすらっているとvim-config なるリポジトリに出会いました。欲しかったプラグインがほとんど入っており、何より先ほどまで苦戦していた起動時間が短いという単語に惹かれてすぐに入れて動かしてみましたそれから半年程度なにも問題なく利用しておりました。しかし、開発が終了したことを知り、再び新しいエディタ設定を探す旅に出ることとなりました。そして、その旅の果てにLunarVimという新たな選択肢に辿り着きました。愛ゆえに人はLunarVimを使わねばらなぬ、そんな想いで私たちは次のステージへと進んでいきます。NeoVim開発で最低限に必要なものVSCodeのような開発体験が欲しいと思ってただ無邪気にプラグインを入れてもこれは殆どがうまくいきません。熟練のVimmmer でもなければ相応にハードルが高いです。LunarVim、SpaceVim 、AstroNvim、NvChad などは欲しい機能に対して遜色ないレベルで機能を実装してくれています。もし、これを読んでNeovimを使っていこうと思っていない場合にもこれらのソフトウェアを入れて試してからでもNeovimを使う選択肢を考えておいてほしいです。LunarVimを使っていくVSCodeで良くない？という自分の声が大きくなる。そして、それを止めることができない。分かる。しかし、これは愛である。ロマンである。愛ゆえにロマンゆえに俺はVimを使うのです。また、LunarVim は、カスタマイズ性が高く自分にしか持てない剣を鍛えていく(IDE -> PDE aka. Personal Development Environment by TJ DeVries氏)擬似的な感覚もあり俺もエディターと一緒に強くなれる感覚があります。LunarVimを利用することで、開発者は次のようなメリットを享受できます。高いカスタマイズ性: LunarVimはVimおよびNeovimの拡張性を継承し、ユーザーが自分だけの開発環境を構築できるように設計されています。軽快なパフォーマンス: LunarVimは、最適なパフォーマンスを提供することを目指しており、起動時間の短縮やリソースの効率的な利用が期待できます。豊富なプラグイン: LunarVimは、既存のVimおよびNeovimプラグインに対応しており、機能の追加や拡張が容易に行えます。LunarVimの個人的な設定はこちらです。github.comまた、LunarVimは公式ドキュメントがしっかりしているので上から順に実施していけば基本的な操作については成熟できます。僕がブログに書くべきことはLunarVimにどれだけ救われたかだけです。www.lunarvim.org余談なのですがGitHubでコードを見るときはキーボードで.を打ってvscode を開くことも増えてきました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Shell ScriptをGo言語に書き直す際に役立つ50本ノックなるものを作り始めた。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/03/30/011930</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/03/30/011930</guid>
            <pubDate>Wed, 29 Mar 2023 16:19:30 GMT</pubDate>
            <content:encoded><![CDATA[インフラ側で必要な問題は100問も要らないので50問に変更した概要システム運用者として働く中で、システムの自動化について考える際、まずはShell Scriptによる自動化が思い浮かびます。しかし、より効率的な方法として、2023年にはシステム運用者がGo言語を学ぶことを提案します。Go言語は、システム運用においてShell Scriptを置き換える可能性を秘めており、その習得がスムーズに進めば、運用者のスキルセットも大幅に向上するでしょう。そこで、このブログでは、システム運用で利用しているShell ScriptをGo言語に書き換える際に役立つ「50本ノック」の問題を紹介します。この問題を解くことで、運用者がGo言語の基本的な構文や機能に慣れることができ、より効率的なシステム運用が期待できます。まずは、Go言語がシステム運用者にとってなぜ魅力的なのか、その理由をいくつか挙げてみましょう。Go言語は、並行処理やエラー処理などの強力な機能を備えており、システム運用においてこれらの機能が非常に役立ちます。また、Go言語はコンパイル言語であるため、実行速度が速く、リソース消費も抑えられるという利点があります。次に、この「50本ノック」の問題について詳しく解説していきます。問題は、Go言語の基本的な構文や機能を網羅しており、運用者がGo言語の特性を理解し、実践的なスキルを身につけることができます。例えば、文字列操作やファイル入出力、構造体やインターフェースなど、Go言語の基本的な概念を学ぶことができます。また、この「50本ノック」では、実際のシステム運用で利用されるシナリオを想定した問題が多数含まれており、運用者がGo言語を習得しながら具体的なシステム運用の課題を解決できるようになります。これにより、運用者は効率的にGo言語のスキルを身につけることができるでしょう。この「50本ノック」の問題を解いていく中で、得た知識をシステム運用の現場で活用し、自身のスキルを磨いていくことが最終的な目標です。では、システム運用者がGo言語を学ぶための「50本ノック」の問題を紹介しました。これらの問題を解くことで、運用者はGo言語の基本的な構文や機能に慣れ、システム運用の効率化やスキルセットの向上が期待できます。ぜひ、Go言語の学習にチャレンジし、よりスマートなシステム運用を目指しましょう。というわけでこちらにリポジトリを作成しました。10問目までは作っていっているのでコツコツやっていきます。github.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[kube-proxy の externalTrafficPolicy=Local の改善]]></title>
            <link>https://zenn.dev/toversus/articles/6eeb3b708bdff3</link>
            <guid>https://zenn.dev/toversus/articles/6eeb3b708bdff3</guid>
            <pubDate>Wed, 29 Mar 2023 01:31:20 GMT</pubDate>
            <content:encoded><![CDATA[tl;dr;Service type LoadBalancer の externalTrafficPolicy: Local は、Kubernetes 1.26 まで Pod のローリング更新時にトラフィックが喪失する問題があるので注意kubernetes-sigs/cloud-provider-kind は、ローカル環境でクラウドリソース (現在は LB のみ) が絡む処理をシミュレートできて便利GKE Dataplane v2 を利用している場合、GKE 1.26.1 時点で Cilium に externalTrafficPolicy: Local の改善が入ってい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go 製のタイピングゲーム「Typingo」を作った]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/typingo-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/typingo-introduction</guid>
            <pubDate>Mon, 27 Mar 2023 09:29:52 GMT</pubDate>
            <content:encoded><![CDATA[Typing + Go = Typingo という語呂のいい名前が思いついてしまったので勢いで作りました。これが俗に言う命名駆動開発 ( NDD: Name-Driven Development ) です。https://github.com/koki-develop/typingoこの記事では Typingo のインストール方法から遊び方、利用技術を簡単に紹介します。インストール遊び方利用技術 インストールHomebrew を使用している場合は brew install を使用してインストールできます。$ brew install koki-develop/t...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PagerDuty で一定期間アラートを抑制する]]></title>
            <link>https://zenn.dev/toshikish/articles/6958af565e6c65</link>
            <guid>https://zenn.dev/toshikish/articles/6958af565e6c65</guid>
            <pubDate>Mon, 27 Mar 2023 08:38:39 GMT</pubDate>
            <content:encoded><![CDATA[PagerDuty でアラートを受け取っているプロジェクトで，以下のようにある時間帯はアラートを止めたいケースがあります。メンテナンスが予定されている。開発環境は営業時間内だけ動かすので，平日夜や土日祝日は止めたい。何も対策しないとアラートが鳴ってしまい，オンコール担当者を不用意に呼び出す結果になるので，そうならないようにきちんと設定します。 TL;DR各ケースで以下のように設定します。メンテナンス→メンテナンスウィンドウを設定平日夜・土日停止→曜日・時刻ベースのイベントルールを追加 方法1：メンテナンスウィンドウメンテナンスなどでダウンする時間帯があらかじ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DBマイグレーションを手動コマンド実行からCloud Run Jobsに移行した話]]></title>
            <link>https://qiita.com/bayobayo0324/items/352d8bbb1bd7bcce8844</link>
            <guid>https://qiita.com/bayobayo0324/items/352d8bbb1bd7bcce8844</guid>
            <pubDate>Mon, 27 Mar 2023 00:23:32 GMT</pubDate>
            <content:encoded><![CDATA[はじめにDBマイグレーションをステージングや本番環境に適用すること、またCI/CDに組み込んで自動化するのはバックエンド／サーバーサイド開発で必ずといっていいほど通る道です。開発体制やフェーズ、…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[jq commandの select でハマった話]]></title>
            <link>https://zenn.dev/satohjohn/articles/79faafa55e9a1e</link>
            <guid>https://zenn.dev/satohjohn/articles/79faafa55e9a1e</guid>
            <pubDate>Sat, 25 Mar 2023 16:36:44 GMT</pubDate>
            <content:encoded><![CDATA[結論配列のjsonに対してselectする際には、配列を一度オブジェクトの抽出をしないと複製されてしまう。なので、以下ではなくjq -r  'select(.[].A | contains("特定文字列")) | .[].B' test.jsonこうしないといけないjq -r  '.[] | select(.A | contains("特定文字列")) | .B' test.json 環境$ jq --version   jq-1.6 詰まった内容以下のjson(test.json)があったときにtest.json[    {        "hog...]]></content:encoded>
        </item>
    </channel>
</rss>