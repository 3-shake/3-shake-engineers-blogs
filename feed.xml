<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 05 Jan 2026 05:16:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[おい、辞めるな]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020</guid>
            <pubDate>Mon, 05 Jan 2026 00:00:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめにかつての私は、深夜2時にベッドの中で転職サイトを開いていた。開いて、求人を眺めて、閉じて、また開く。そういうことを繰り返していた。辞めたいのか、と聞かれると困った。会社の限界が見えたのか。自分の天井が見えたのか。それとも、隣の芝生の青さに目が眩んでいただけなのか。たぶん、全部だった。たぶん、どれでもなかった。今は、転職を考えていない。これは「今の会社が最高だから」という話ではない。どんな会社にも良い面と悪い面がある。不満がゼロになることはない。ただ、深夜に転職サイトを開く衝動は、いつの間にか消えた。何が変わったのか。環境が変わったのか、自分が変わったのか。たぶん、両方だ。「エンジニアは転職で年収が上がる」「成長できる環境に身を置け」——そんな言葉がタイムラインに流れてくる。転職エージェントからのスカウトメールは週に何通も届く。カジュアル面談のお誘い。年収アップの可能性。もっと刺激的な環境。全部、本当のことだと思う。全部、嘘だとも思う。若いエンジニアが短期的にモノを考えてしまうのは、仕方がない。私もそうだった。目の前の不満が大きく見える。3年後、5年後のことなんて、想像できない。「今すぐ環境を変えたい」という衝動は、若さゆえの特権でもある。その衝動を否定するつもりはない。ただ、かつての自分に言いたいことがある。「おい、ちょっと待て」と。私自身、何度も転職を考えた。「もう限界だ」「ここにいても意味がない」「他の会社ならもっとできるはずだ」——そう思って、転職サイトを眺めた夜は数えきれない。そして、実際に転職したこともある。転職して正解だったケースもあった。「あのタイミングで辞めなくてよかった」と思うケースもあった。だから、この記事で「辞めるな」と書くのは、上から目線のアドバイスではない。かつての自分への手紙だ。あのとき、もう少し踏みとどまっていたらどうなっていたか。もう少し早く辞めていたらどうなっていたか。そういう問いを、今も抱えている。——もし読んでいて上から目線に感じたなら、それは私の力量不足だ。申し訳ない。ある日、気づいたことがある。深夜に転職サイトを開く自分と、翌朝それを後悔する自分は、同じ人間なのに、まったく違うことを考えている。どちらが本当の自分なのか。たぶん、どちらも本当だ。だから困る。この記事は、深夜の衝動と、翌朝の冷静さの、両方に向けて書いている。この記事が、辞めそうな若手に上司から共有されないことを祈っている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「転職しやすい」という罠ITエンジニアは「転職しやすい職業」だと言われる。確かにそうだ。求人は多い。売り手市場だ。スキルがあれば、転職先を見つけることは比較的容易だろう。だが、「転職しやすい」ことと「キャリアを作れる」ことは、全く別の話だ。私自身、この罠にはまった。転職市場で「引く手あまた」だった時期がある。スカウトメールは毎週届いた。カジュアル面談をすれば、たいてい次のステップに進めた。「自分は市場価値が高い」と思っていた。でも、それは錯覚だった。振り返ると、私は「転職できる」ことと「キャリアを積み上げている」ことを混同していた。転職市場で需要があるのは、単に「エンジニアが足りない」からだ。私個人の価値が高いわけではない。需要と供給のバランスが崩れているだけ。その状況に甘えて、「いつでも転職できる」という安心感に浸っていた。「3年で転職すれば年収が上がる」という話もある。だが、これは単純化しすぎた話だ。実際には、年収が上がる転職もあれば、上がらない転職もある。そして、年収が上がらない転職の方が、実は多い。なぜか。転職には必ずロスが発生するからだ。私が転職したとき、最初の3ヶ月は本当に苦しかった。前職では「あいつに聞けば分かる」と言われていた領域があった。コードベースを熟知していた。誰に何を聞けばいいか知っていた。暗黙のルールも把握していた。転職した瞬間、それが全部ゼロになった。会議で発言しても、「この人、誰？」という空気が流れる。提案しても、文脈を知らないから的外れになる。前職では30分で終わる作業が、3時間かかる。「俺はもっとできるはずなのに」——そう思いながら、毎日を過ごしていた。これが「転職のロス」だ。どんなに経験者であっても、新しい会社のコンテキストをつかむには時間がかかる。前職で積み上げた信頼貯金は、転職した瞬間にリセットされる。私がこの記事で伝えたいのは、現場で働いてきた人間としての実感だ。机上の空論ではなく、実際に転職を経験し、成功も失敗もしてきた中で気づいたことを書く。一見「転職しやすい」ように見えるITエンジニアほど、実は「キャリアを作ること」が難しい——これが私の結論だ。転職のハードルが低いからこそ、安易に転職してしまう。そして、キャリアが積み上がらないまま、年齢だけが積み上がっていく。ただ、ここまで書いてきて、誤解されたくないことがある。「辞めたい」と思うのは、悪いことではない「転職には罠がある」と書いた。でも、それは「辞めたいと思うこと自体が悪い」という意味ではない。ここで1つ、大事なことを言っておきたい。「辞めたい」と思うこと自体は、悪いことではない。むしろ、自然なことだ。どんな会社にも、良い面と悪い面がある。仕事には波がある。うまくいく時期もあれば、何をやってもダメな時期もある。人間関係でストレスを感じることもある。深夜2時に転職サイトを眺める。上司との関係がうまくいかなくて、帰りの電車で「もう嫌だ」と思う。日曜の夜、明日会社に行きたくないと感じる。そういう瞬間は、誰にでもある。私にもあった。今でもある。だから、この記事を読んで「辞めたいと思っている自分はダメだ」とは思わないでほしい。辞めたいと思うことと、実際に辞めることは、別の問題だ。ただ、この分離は言うほど簡単ではない。深夜2時に転職サイトを見ているとき、「これは感情だ、今は判断するな」と冷静に思える人がどれだけいるだろうか。私自身、何度も感情に流されて判断しそうになった。だから、私は自分にルールを課している。1回目で決めるな。深夜のベッドで「辞めたい」と思った。それは1回目だ。まだ決めるな。翌週、上司に理不尽なことを言われて「辞めたい」と思った。まだ決めるな。1ヶ月後、半年後、同じ状況で同じことを思うか。時間をかけて、何度も問い直せ。衝動ではなく、熟慮の末に出した答えなら、それが「辞める」でも「残る」でも、後悔は少ない。要するに、短期ではなく長期で考えろ、ということだ。目の前の感情に振り回されるな。5年後、10年後の自分がどうなっていたいか。そこから逆算して、今の決断を考えろ。正直に言えば、3年程度では何も身についていない。「3年経験があります」と言っても、それは今の環境が整っている状況で、その能力が発揮できる程度だ。上司が調整してくれて、先輩がフォローしてくれて、チームが支えてくれて、ようやく成果が出せている。その支えがなくなった瞬間、同じパフォーマンスが出せるか。出せないなら、それは本当に「能力」と呼べるのか。感情は感情として受け止めていい。ただ、その感情だけで大きな決断をしないでほしい。この記事は、そのための材料を提供したいと思っている。では、冷静に考えるとは、具体的に何を考えればいいのか。次に目指す役割を明確にするまず最初に考えるべきは、「次にどこへ向かいたいのか」だ。エンジニアのキャリアには、いくつかの方向性がある。技術を深める方向——テックリードやスペシャリストだ。特定の領域で「この人に聞けば分かる」と言われる存在になる。アーキテクチャの意思決定を任される。難しい技術的課題を解決する。人を率いる方向——エンジニアリングマネージャー（EM）だ。チームの生産性を最大化する。メンバーの成長を支援する。採用や評価といった組織課題に向き合う。事業に近づく方向——プロダクトマネージャーや、ビジネスサイドとの橋渡し役だ。「何を作るか」を決める側に回る。技術とビジネスの両方を理解し、最適な解を見つける。ここで強調しておきたいのは、IC（Individual Contributor）トラック——部下を持たずに技術で貢献し続けるキャリアパス——という選択肢の存在だ。スタッフエンジニア、プリンシパルエンジニアといった役職は、マネージャーにならずとも、より大きなインパクトを生み出す道だ。マネジメントだけが「上」ではない。シニアの先には4つの方向性がある。テックリード（チームの技術方針を導く）、アーキテクト（システム設計の意思決定を担う）、ソルバー（組織横断の難問を解決する）、ライトハンド（経営層の右腕として動く）。どれを目指すかで、求められるスキルセットも変わる。全部できる必要はない。どれを選ぶかは、あなた次第だ。重要なのは、スタッフエンジニアは「シニアのシニア」ではないということだ。役割そのものが変わる。コードを書く時間は減り、リーダーシップ、ファシリテーション、組織の接着剤としての仕事が増える。「もっとコードを書きたい」という人には向かない道だ。だから、「シニアになったら自動的にスタッフを目指す」という発想は危険だと私は思っている。多くのエンジニアは、最初は「一人前の開発者」からスタートする。そこから、どの方向に進むか。それを決めるのは、あなた自身だ。ここで自分に問いかけてほしい。あなたは次にどの方向に進みたいのか。それが言語化できていないなら、転職を考えるのはまだ早い。なぜなら、方向が定まっていない転職は、ただの「移動」に過ぎないからだ。移動しても、キャリアは積み上がらない。方向性を考えることと同じくらい大事なことがある。「自分は今、どこにいるのか」を知ることだ。自分の能力を棚卸しする目指す方向が見えてきたとしよう。でも、その方向に進むためには、今の自分の立ち位置を正確に把握する必要がある。転職を考えるとき、多くの人は外側に目を向ける。「あの会社は良さそうだ」「この技術を使ってみたい」「あの人みたいになりたい」。でも、本当に大事なのは、自分という器がどうなっているかを知ることだ。どんなに良い環境に移っても、器が変わらなければ、入ってくるものは同じだ。逆に、自分の器をちゃんと理解していれば、今の環境でも次の環境でも、適切な選択ができる。ここで、転職を考える前に確認してほしいことがある。自分の「実力」を正しく評価できているか、ということだ。私は長い間、この評価を間違えていた。ゾーンに入って神がかった速度でコードを書く自分、難解なバグを一瞬で特定する自分——そういう「最高の瞬間」を「自分の実力」だと信じていた。だから、転職先でも同じパフォーマンスが出せると思っていた。逆だった。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」だ。絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎない。転職先で、その「上振れ」を再現できる保証はどこにもない。なぜこれが転職を考えるときに重要なのか。信頼は「下限」に支払われるからだ。新しい職場で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。だから、転職先を選ぶときに問うべきは、「最高の自分が活躍できる場所か」ではない。「最悪の自分でも、最低限のパフォーマンスを出せる場所か」だ。もう1つ、能力について知っておくべきことがある。能力は文脈の中にしかない。今の環境で「できる人」だとしても、それは文脈に依存している。私自身、痛い目を見た。あるプロジェクトで成果を出せたとき、私はそれを自分の実力だと思っていた。でも振り返ると、違った。上司が事前に関係者と調整してくれていた。マネージャーがスコープを適切に切ってくれていた。先輩が技術的な地雷を踏む前に教えてくれていた。私は、応援してくれて、調整してくれていたマネージャーや上司の能力まで、自分の能力だと勘違いしていた。その支えが消えた環境で、同じパフォーマンスを出せるか。出せるわけがない。正しい認識はこうだ。「この文脈において、これまでの経験と周囲のサポートが噛み合って、たまたま価値が出せている」。では、その「器」——能力——は、どう捉えればいいのか。大きく分けて3つの軸がある。技術力——コードを書く力だ。設計力、実装力、レビュー力。特定の領域を深掘りする「スペシャリスト」か、複数の領域をカバーする「ジェネラリスト」か。どちらを目指すにせよ、ここが基盤になる。推進力——プロジェクトを前に進める力だ。タスクを完遂できるか。障害にぶつかっても解決策を見つけられるか。チームのボトルネックを解消できるか。「なぜこの機能が必要か」というビジネス課題を理解し、技術的な意思決定をビジネスインパクトで説明できるか。影響力——自分の外側に価値を生み出す力だ。チームへの影響力は、採用、オンボーディング、ドキュメント整備、勉強会の開催など。社外への影響力は、技術ブログ、カンファレンス登壇、OSS貢献など。どの軸を伸ばすかは、目指す役割によって変わる。テックリードを目指すなら技術力と推進力。EMを目指すなら推進力と影響力。スペシャリストを目指すなら技術力を極める。重要なのは、全部を上げようとしないことだ。自分が目指す役割に必要な能力を見極めて、そこに集中する。ここで、私自身の失敗を話したい。かつての私は「良いコードを書いていれば、いつか評価される」と思っていた。技術力さえあれば、周りが認めてくれる。黙々と良い仕事をしていれば、誰かが見ている。——甘かった。現実はこうだ。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知らない。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われる。「仕事をやり遂げる人」として認められるには、技術的な能力だけでなく「何が重要かを見極める力」と「自分の仕事を周囲に伝える力」が必要だ。この2つを、私は長い間、軽視していた。「アピールするのは恥ずかしい」「実力で示せばいい」——そう思っていた。でも、それは傲慢だった。相手の時間を奪わずに、自分の仕事の価値を簡潔に伝えること。それはコミュニケーションスキルであり、チームで働く上での基本的な作法なのだ。つまり、私は「技術力」に過剰投資し、「推進力」と「影響力」に過少投資していた。多くのエンジニアは、同じ罠にはまる。新しいフレームワークを学ぶ。新しい言語を触る。それは楽しいし、成長した気になる。だが、「推進力」——泥臭い調整や、やり切る力——の不足から目を背けていないか。技術力があっても、プロジェクトを完遂できなければ、市場価値は上がらない。今の会社を辞めようとしているあなた。この3つの軸で自分を評価してみてほしい。次に目指す役割に対して、どの軸が足りていないのか。それが明確になっていないなら、転職しても同じ困難にぶつかる。環境を変えても、足りない能力は足りないままだ。ただ、ここで1つ付け加えたいことがある。能力を棚卸しするとき、多くの人は「足りないもの」ばかりを見る。私もそうだった。「技術力が足りない」「推進力が弱い」「影響力がない」——チェックリストを見て、できないことを数え上げる。そして、転職先を探すときも「ここに行けば○○が身につく」「あの会社なら△△を学べる」と、ないものを補う発想で動いてしまう。ないものを探し続けていたら、悩みは一生消えない。考えてみてほしい。どんな環境に行っても、足りないものは必ずある。新しい技術が次々に出てくる。上には上がいる。「あれもできない、これもできない」と数え上げれば、キリがない。そうやって「ないもの」を埋めようとしている限り、永遠に充足感は得られない。私自身、この罠に長い間はまっていた。「もっとコードが書けるようになりたい」「もっとコミュニケーション力をつけたい」「もっとビジネス視点を持ちたい」——足りないものリストは常に更新され続けた。そして気づいた。そのリストは、一生埋まらない。発想を変えよう。「ないものを探す」のではなく、「あるものを伸ばす」。あなたには、すでに強みがある。周囲より得意なことがある。それが何かを見極めて、そこに集中する。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪い。私の場合、「調べること」「言語化すること」「ソフトウェアを実装すること」が比較的得意だった。コミュニケーション力が高いわけではない。政治的な立ち回りも苦手だ。でも、RFCやドキュメントを読み込んで理解し、それを実際に動くコードに落とし込み、さらに文章としてまとめることなら、周囲より少しだけ速かった。その「少しだけ」を、徹底的に伸ばすことにした。結果として、「あいつに任せれば、調べて、作って、ドキュメントにしてくれる」という評価が生まれた。これは戦略的な選択だ。何をやるかではなく、何をやらないか。弱みを気にして、あれもこれもと手を広げるのではなく、強みに絞って、そこで突き抜ける。だから、能力を棚卸しするとき、「足りないもの」だけでなく「すでにあるもの」にも目を向けてほしい。転職を考えるとき、「ここに行けば足りないものが補える」ではなく、「ここに行けば今の強みがさらに活きる」という視点で選んでほしい。足りないものは、一生足りない。だから、足りないものを数えるのをやめろ。今あるものを、もっと伸ばせ。正直に告白しよう。私には、仕事を選ぶときの悪い癖がある。小さなバグを直す。ドキュメントの誤字を修正する。チェックリストを埋めていく。1日の終わりに「今日も色々やった」と思える。でも、週末に振り返ると、本当にインパクトのある仕事をしたのか、分からなくなる。——これが、私の悪い癖だ。簡単で達成感はあるが、インパクトの低い仕事に逃げてしまう。お菓子をつまむように、小さなタスクをつまんでしまう。これが「スナッキング」だ。チェックリストを埋める快感は、脳にとって報酬だ。でも、その報酬に溺れて、本当に重要な仕事——曖昧で、難しくて、すぐに結果が出ない仕事——から逃げていないか。もう1つ、自分を戒めている罠がある。目立つが価値の低い仕事だ。社内の勉強会を頻繁に開く。Slackで積極的に発言する。目立つ。注目を集める。でも、ビジネスへの貢献は薄い。この罠にはまると、「忙しかった」と「成果を出した」を混同するようになる。振り返ってほしい。直近1ヶ月で、最もインパクトのあった仕事は何だったか。それに費やした時間は、全体の何割だったか。もし1割以下なら、残りの9割は「スナッキング」だった可能性がある。ここまで、「どこを目指すか」と「何を伸ばすか」について話してきた。では、実際に転職するとなったとき、何を失い、何を得るのか。その前に、転職を考えるときの大前提を確認しておきたい。「自分は会社にとって必要な存在だ」と思っているかもしれない。でも、それは本当だろうか。「替えが効く」という前提を認める別に会社なんていつ辞めても良い。文字通りの意味で替えの効かない人間なんて資本主義においては存在しない。これは冷徹な事実だ。どんなに優秀なエンジニアでも、会社は回る。あなたが辞めても、誰かが引き継ぐ。プロジェクトは続く。組織は適応する。「私がいないと回らない」——そう思いたい気持ちは分かる。でも、それは幻想だ。私自身、これを認めるのに時間がかかった。ある会社を辞めるとき、「自分がいなくなったら、あのシステムは誰がメンテするんだろう」と心配していた。3ヶ月後、元同僚に聞いた。「全然大丈夫だよ。○○さんが引き継いで、むしろ前より整理されてる」。——少し寂しかったが、同時にホッとした。そして気づいた。私は「替えが効かない」と思いたかっただけだ。この事実を認めることは、絶望ではない。むしろ、解放だ。「替えが効かない」と思い込んでいると、会社に縛られる。「私がいないと困る」「今辞めたら迷惑をかける」——そういう責任感は美しいが、それが「辞められない」という足枷になることがある。ブラックな環境でも我慢してしまう。メンタルを壊しても「今は辞められない」と言い聞かせる。替えが効くと認めることで、初めて「辞める」という選択肢が本当の意味で手に入る。ただし、ここで短絡的な結論に飛ばないでほしい。「替えが効く」→「だから辞めてもいい」——これは論理の飛躍だ。「替えが効く」から導ける結論は、もう1つある。「だから、どこに行っても価値を出せる能力を磨け」だ。会社にとって、あなたは替えが効く。だが、あなたにとって、積み上げた実績は替えが効かない。ここが重要だ。会社はあなたを手放せる。次の人を雇えばいい。でも、あなたが2年間かけて積み上げた信頼、ドメイン知識、人間関係——これは、転職した瞬間にリセットされる。会社にとっては「替えが効く」リソースでも、あなたにとっては「替えが効かない」資産なのだ。だから、問いはこうなる。「会社にとって替えが効く」という事実を認めた上で、「自分にとって替えが効かない資産」をどれだけ積み上げたか。信頼の複利、実績の蓄積、ドメイン知識——これらは「会社のため」に積み上げるのではない。「自分のため」に積み上げる。たまたま、その資産が今の会社で活きているだけだ。転職すれば、その一部はリセットされる。リセットされてでも得たいものがあるなら、辞めればいい。リセットするには惜しい資産があるなら、もう少し留まって、その資産を使い切ってから辞めればいい。「替えが効く」という事実は、転職を正当化する理由にも、現職に留まる理由にもなる。どちらの結論を導くかは、あなた次第だ。大事なのは、この事実を、感情的な決断の言い訳に使わないことだ。「どうせ替えが効くんだから、辞めてもいいでしょ」——それは、考えることを放棄している。「替えが効くからこそ、自分の資産を最大化する選択をする」——それが、戦略的な判断だ。この前提を踏まえた上で、いよいよ転職のコストについて考えよう。「替えが効く」からこそ、転職は自由にできる。だが、自由にできるからといって、コストがゼロなわけではない。転職は「投資」であり「リセット」である若さという資源は有限だ。私たちはキャリアを積む中で何かを投資し、その結果として何かを得ている。この構造を理解しないまま転職を繰り返すのは危険だ。20代の私は、この構造を理解していなかった。「若いうちは色々経験した方がいい」「転職で視野が広がる」——そういう言葉を真に受けて、2〜3年ごとに環境を変えていた。確かに視野は広がった。でも、振り返ると、広く浅くなっただけだった。新卒で未経験のうちは何もない。あるのはポテンシャルであり、若さであり、可能性だ。その資源を使い、何かしらの資産を得る必要がある。何を得るのか。それはスキルであり、それを活用した先の実績だ。実績は資産だ。そして資産には複利が効く。ある領域で実績を出すと、次はもう少し大きな仕事が回ってくる。それをこなすと、さらに大きな仕事が来る。「あの人はこの領域で結果を出した」という評判が、次の機会を連れてくる。これが複利だ。私が見てきた「キャリアがうまくいっている人」は、例外なくこの複利を回していた。1つの実績が次の実績を呼び、雪だるま式に大きくなっていく。逆に言えば、転職するたびにこの複利がリセットされる。転職するたびに、一定のロスが発生する。ビジネスドメインの理解、社内の人間関係、意思決定のプロセス、暗黙知として共有されている文化。これは、転職した瞬間にリセットされる。信頼貯金も同様だ。前職で積み上げた「あいつなら任せられる」という信頼は、新しい会社では通用しない。ゼロから積み上げ直す必要がある。この「リセットコスト」を、転職を考えるときに計算しているだろうか。私は、転職のリセットコストを「半年〜1年」と見積もっている。新しい環境でコンテキストをつかみ、信頼を積み上げ、本来のパフォーマンスを発揮できるようになるまでの時間だ。転職した直後の、あの居心地の悪さを覚えているだろうか。私が転職して最初の1週間、Slackの雑談チャンネルを眺めていた。前職では、私も会話の輪に入っていた。誰かが投稿すれば、すぐにリアクションをつけた。冗談を言えば、笑ってくれる人がいた。でも新しい会社では、誰も私のことを知らない。雑談チャンネルに何か書こうとして、やめた。「この人、誰？」と思われるのが怖かった。些細なことだ。でも、あの孤独感は今でも覚えている。前職では「あいつに聞けば分かる」と頼られていたのに、新しい会社では誰も自分を知らない。会議で発言しても、反応が薄い。提案しても、「この人は何者だ？」という目で見られる。チャットで質問しても、返事が遅い。——あの感覚は、信頼貯金がゼロになった瞬間だ。これが「信頼の貯金」だ。具体的に言おう。「あの件、○○さんに頼んでおけば大丈夫」——そう思われるまでに、どれだけの時間がかかっただろうか。最初は小さな仕事を任される。それを期限通りに、期待以上の品質で納める。次は少し大きな仕事を任される。また納める。この繰り返しで、「この人なら任せられる」という信頼が積み上がっていく。信頼があると、仕事が回りやすくなる。他のチームに協力を頼むとき、「あの人の頼みなら」と動いてもらえる。提案するとき、「あの人が言うなら、一度聞いてみよう」と耳を傾けてもらえる。逆に信頼がないと、どんなに正しいことを言っても、「あの人、誰？」で終わる。周囲があなたと一緒に働きたいと思う度合いが、あなたの成功を直接左右する。そして、この信頼の貯金は、転職した瞬間にゼロにリセットされる。前職で「あの人は信頼できる」と思われていても、新しい会社では関係ない。ゼロから積み上げ直すしかない。今の会社で、信頼貯金はどれくらい貯まっているか。その信頼貯金を使ってできる挑戦は、まだ残っていないか。せっかく貯めた信頼貯金を、使わずに捨てるのは、もったいなくないか。ここで、信頼貯金のROI（投資対効果）を考えてみてほしい。今の会社で積み上げた信頼があるからこそ挑戦できる「高難易度・高リターン」の仕事はないか。新規プロジェクトの立ち上げ。技術的負債の解消。チームの構造改革。こういう挑戦は、信頼がなければ任されない。信頼があるからこそ、「あいつに任せてみよう」となる。転職先で得られる期待値は、このリセットコストを支払ってでも余りあるほど高いか。その根拠は何か。「なんとなく成長できそう」ではなく、具体的に何を得られるのか。それを言語化できなければ、転職は「期待値の高い投資」ではなく、「よく分からないギャンブル」になる。ここまで、転職のコストについて話してきた。では、そのコストを支払う価値があるかどうかを判断するために、何を見ればいいのか。それは、今の場所で何を積み上げたか、だ。現職で何を成し遂げたか転職を考えるとき、多くの人は「次に何をしたいか」を考える。でも、その前に考えるべきことがある。現職で何を成し遂げたかだ。きつい言い方をする——これは私自身への言葉でもあるのだが——。転職する時に現職で主体的に動いて成し遂げた実績が語れなければ、現職の経験はエンジニアキッザニアに近い。シニアエンジニアやCTOが用意してくれた環境で、お膳立てされた仕事をこなしていただけ。新しいスキルが身についたとする。それは素晴らしい。でも、それだけでは足りない。そのスキルを使って、どのようなビジネス価値を出したのか。その過程でどう主体的に関わったのか。これが語れなければ、あなたは「お客さん」のままだ。もちろん、「キッザニア」も大事だ。お膳立てされた環境で体感したことは血肉になる。でも、それでいいのはある段階までだ。年収700万円、800万円、その先を目指すなら、「遊ばせてもらう側」から「遊び場を作る側」に回る必要がある。技術力だけでは昇進できない——これは誰でも言える。問題は、なぜ、分かっていても実践できないのかだ。「コードで問題を解決する」。それが私たちのアイデンティティだ。だから、可視化やスポンサー獲得を「政治的で汚い」と感じてしまう。「実力で認められたい」。その気持ちは痛いほど分かる。私もそうだった。でも現実は違う。技術的に正しい提案をしても、周囲を巻き込めなければ、提案は提案のまま終わる。「技術で解決できる」ことと「解決を任される」ことは、別の能力だ。私自身、昇進を見送られた経験がある。なぜ評価されないのか分からなかった。振り返って気づいた。上司が私のキャリア目標を察してくれることを、勝手に期待していた。「昇進したいです」と言ったことがあっただろうか。なかった。上司はエスパーではない。言わなければ、伝わらない。そしてもう1つ。技術的な正しさを組織に浸透させるのも、「技術」だ。相手の立場を理解し、伝わる言葉で説明し、合意を形成する。これを「政治」と呼ぶなら、政治もまた技術なのだ。そして、成果を出すだけで終わりではない。私は日報をつける習慣を大事にしている。Claude Codeを使って、日々の作業を記録している。何をやったか、何を学んだか、何に詰まったか。こうして記録しておけば、パフォーマンスレビューの自己評価で圧倒的に有利になる。半年前、1年前に何を達成したか、正確に思い出せるだろうか。記録がなければ、自分の成果を過小評価してしまう。成果を出すことと、成果を可視化することは、別のスキルだ。昇進には「スポンサー」と「可視化」が必要だ。スポンサーとは何か。あなたの成果を経営層に伝えてくれる人だ。上司や先輩の中に、「あいつは良い仕事をしている」と会議で言ってくれる人はいるか。人事評価の場で、あなたの名前を出してくれる人はいるか。いくら良い仕事をしても、上層部に伝わらなければ、昇進の話にはならない。スポンサーは単なる応援者ではなく、あなたのキャリアに実際に投資してくれる存在だ。可視化とは何か。自分の仕事の価値を、他人が理解できる形で残すことだ。「何を達成したか」「なぜそれが重要だったか」「組織にどう貢献したか」——これをドキュメントやSlackで発信しているか。戦略的に重要なプロジェクトに参加して、名前を売っているか。これが揃って初めて、「この人を昇進させよう」という話になる。ネットワークも重要だ。社内の同僚、社外のプロフェッショナル、経営層——この3方向の人脈を意識的に育てることで、キャリアの選択肢が広がる。転職を考えるなら、この3つのネットワークがどれだけ育っているか、自問してみてほしい。今、辞めようとしているあなたに問いたい。現職で、あなたは何を成し遂げたか。主体的に動いた結果として、何が変わったか。もし自分がその場にいなかったとしたら、結果はどう変わっていたか。「自分がいたからこそ生まれた差分」を言語化できるか。それが語れないなら、まだ辞めるタイミングではないかもしれない。少なくとも、もう一度自分に問いかける価値はある。ここで、よく聞く反論がある。「現職で成し遂げたいけど、もう成長の機会がないんです」——本当だろうか。この「成長できない」という感覚を、もう少し掘り下げてみたい。「成長できない」は本当か「もうこの場所では成長できない」これは、転職理由としてよく聞く言葉だ。刺激がなくなった。慣れてしまった。自分よりできる人がいない。だから、成長するために環境を変えたい。でも、本当にそうだろうか。それは本当に環境のせいなのか。厳しいことを言う。「成長できない環境」なんて、ほとんど存在しない。あるのは、今の自分の能力では打破できない環境だ。それは環境の問題ではなく、能力の問題だ。能力があれば、たいていの環境は打破できる。「この環境では無理だ」と言っているのは、「今の自分には無理だ」と言っているのと同じだ。だからこそ、転職には意味がある。——逆説的に聞こえるかもしれないが、聞いてほしい。能力を上げてから転職すれば、次の環境も打破できる。能力を上げずに転職しても、また同じ壁にぶつかる。「この環境では成長できない」と言って転職した人が、次の会社でも同じことを言っているのを、何度も見てきた。環境を変えても、能力が変わらなければ、結果は同じだ。逆に、今の環境で壁を打破する力をつけた人は、どこに行っても通用する。転職は「逃げ場」ではなく「能力を活かす場」として選ぶべきだ。今の環境で能力を証明してから、その能力をより活かせる場所に移る。それが、転職を「飛躍」にする唯一の方法だ。では、ここで言う「能力を上げる」とは、具体的に何を指すのか。そもそも「成長」とは何なのか。成長とは何か。新しい技術を触ることか。新しいフレームワークを学ぶことか。それらは成長の一部ではあるが、本質ではない。成長とは、「解ける問題の範囲が広がること」であり、「より大きな責任を担えるようになること」だ。シニアエンジニアへの成長で最も重要なのは、「どの問題を解くべきかを見極める力」だ。コードで問題を解くことと、そもそも「どの問題を解くべきか」を判断することは、まったく別のスキルだ。私自身、この違いを理解するのに時間がかかった。ある時期、私は「新しい技術を触れていないと成長が止まる」と焦っていた。業務ではレガシーなコードをメンテしている。新しいことを学べていない。だから成長していない。そう思い込んでいた。でも振り返ると、あのレガシーコードのメンテナンス期間こそ、私が最も成長した時期だった。複雑に絡み合った依存関係を解きほぐす力。ドキュメントがない状況で調査する力。リスクを見積もって段階的にリファクタリングする判断力。これらは、最新技術を追いかけていたら身につかなかった。その定義で考えたとき、今の環境で成長の余地は本当にないのか。もしかしたら、自分が「成長」と呼んでいるものが、単なる「刺激」ではないだろうか。新しい技術を触る刺激。新しいチームに入る刺激。新しいプロダクトに関わる刺激。刺激と成長は違う。刺激は消費されるが、成長は蓄積される。私が「成長できない」と感じていたとき、本当は「刺激がない」だけだった。成長の機会は目の前にあった。ただ、それが「地味でつまらない仕事」に見えていたから、気づかなかった。ここで、よく言われる教えについて考えてみたい。「一番の下手くそでいよう（Be the Worst）」——プログラマーの世界でよく引用される教えだ。自分より優れた人たちの中に身を置くことで、自分も成長できる。だから、自分が一番下手くそになれる環境を探せ、と。この教えは正しい。でも、これを全員が実践したら、組織は成り立たない。全員が「学ぶ側」を求めて、誰も「教える側」に回らなかったら、どうなるか。優秀な人が集まる環境は、誰かが「教える側」を引き受けてくれているから成立している。「一番の下手くそでいよう」という教えは、その前提を無視している。——というのは、批判としては正しい。ただ、この教えの本質は、「常に学び続けろ」ということだ。「教える側」に回っても、学びは止まらない。むしろ、教えることで自分の理解の穴が見つかる。成長の形が変わるだけで、成長自体は続く。「もうこの場所では成長できない」と感じたとき、立ち止まって考えてほしい。自分は「学ぶ側」でいることしか考えていないのではないか。新しい技術を教わりたい。優秀な先輩からコードレビューを受けたい。それは大事だ。だが、いつまでも「教わる側」にいるわけにはいかない。「教える側」に回ったとき、別の成長が始まる。後輩のコードをレビューすることで、自分の理解の穴が見つかる。ドキュメントを整備することで、暗黙知が言語化される。勉強会を開くことで、チーム全体の底上げができる。そして何より、「自分がいないと回らない」から「自分がいなくても回る」状態を作ることが、次のステージへの準備になる。「接着剤の仕事」というものがある。チーム間の調整、ドキュメント整備、後輩の面倒を見る——コードを書かないが、チームを機能させるために不可欠な仕事だ。日本企業では、この仕事は評価されにくい。「○○さんはコード書いてないよね」と言われがちだ。でも、シニアレベルでこれをやると「リーダーシップを発揮している」と見なされることもある。上司とすり合わせて、この仕事がキャリアにどう評価されるか確認しておいた方がいい。評価されないなら、やりすぎは損だ。効果的なメンタリングとは何か。良いメンターはすぐに答えを与えない。複数の選択肢を提示し、メンティー自身に考えさせる。そして、自立を促す。メンタリングを受ける側も、答えを教えてもらうことを期待するのではなく、自分で考える姿勢が求められる。もし今の環境で良いメンターがいるなら、それは転職で失う大きな資産の1つだ。今の環境で、より大きな責任を担う機会はないか。より難しい問題に挑戦する機会はないか。それを探さずに「成長できない」と言っているなら、次の環境でも同じことが起きるだろう。ここまで、「成長できない」という感覚について掘り下げてきた。成長の機会は、案外、目の前にあるかもしれない。ただ、それでも「辞めたい」という気持ちが消えない人もいるだろう。次の問いは、より厳しいものになる。転職は「逃げ」になっていないか転職を繰り返す人の中に、あるパターンがある。新しい会社に入る。最初の半年は必死でキャッチアップする。コードベースを読み、ドメイン知識を吸収し、チームの信頼を獲得する。1年が経つ頃には「だいたい分かった」という感覚が出てくる。そして、ふと気づく。「あれ、最近あまり成長していない気がする」。ここで選択肢が2つある。今の環境で次のステージに挑戦するか、また新しい環境に移るか。後者を選び続けると、こうなる。キャッチアップが終わるたびに「成長が止まった」と感じ、また次の会社に行く。新しい環境でのキャッチアップを「成長」だと錯覚する。でも、それは成長ではない。ただの適応だ。本当の成長は、適応が終わった後にある。その環境で自分なりの仮説を持ち、試行錯誤し、失敗し、そこから学ぶ。大きなプロジェクトをやり遂げる。チームを任される。技術的な意思決定を下す。そういう経験を積んで初めて、次のステージに進める。転職を繰り返すたび、この「本当の成長」への到達前にリセットがかかる。結果、いつまでも「一人前の開発者」のまま、年齢だけが進んでいく。私自身、このリセットの苦しさを身をもって経験した。自社開発からSRE支援の会社に転職したとき、リセットが1回では済まないことを思い知った。支援先が変わるたびに、文脈がリセットされる。コードベース、チームメンバー、組織文化——全部ゼロから。しかも「支援」として来ている以上、キャッチアップ期間なんてない。初日から「で、何ができますか？」と問われる。最初は本当に苦しんだ。広い視野は得られたが、深さが積み上がらない。ある現場で得た知見を次の現場で活かそうとしても、文脈が違いすぎて通用しない。そして何より、信頼の蓄積がリセットされ続ける。ある支援先で信頼を獲得しても、次の案件ではまたゼロからだ。この経験から学んだことがある。転職のリセットコストは、転職先の業態によって大きく変わる。自社開発から自社開発への転職なら、リセットは1回で済む。でも、支援会社やコンサル、技術顧問に転職すると、リセットが繰り返し発生する。その覚悟があるかどうか、転職前に考えておくべきだ。この経験を通じて、私が学んだ原則がある。「自分の決定の結果を見届けられるだけの期間、同じ場所に留まれ」。成長のフィードバックループを回すためだ。設計した仕組みが半年後にどう使われているか。提案した施策が1年後にどんな結果を生んだか。それを見届けずに次の環境に移ったら、学びは半分で終わる。もう1つ、「許可を求めるな、宣言しろ」という原則がある。「○○してもいいですか？」ではなく、「○○します。問題があれば教えてください」と発信する。異論があれば誰かが止めてくれる。このスタイルで動けるようになると、権限がなくても物事を前に進められる。日本企業では「根回し」が重要だと言われる。それは間違いではない。でも、根回しにも2種類ある。「許可を得るための根回し」と「宣言を通すための根回し」だ。後者の方が、物事が前に進む。逆に、常に許可を求めないと動けない状態なら、まだその環境で信頼貯金が足りていない。その信頼を積み上げる前に辞めるのは、もったいない。ここで、このセクションの問いに戻ろう。「転職は『逃げ』になっていないか」。「今の環境では成長できない」と感じたとき、一度立ち止まって考えてほしい。それは本当に環境の限界なのか。それとも、環境には問題がないのに、難しいことから逃げているだけではないか。——私自身も、この問いに何度も向き合ってきた。そして正直に言えば、「逃げ」だったこともある。「退屈だが重要な課題」を解決することから目を背けて、「新しくて刺激的な環境」に逃げたくなる気持ちは、痛いほど分かる。ここまで、「今の環境で成長できるか」について話してきた。では、環境を変えるにせよ、留まるにせよ、これからのエンジニアは何を磨くべきなのか。AIと共存する時代に何を磨くかこの問いを考えるとき、避けて通れないのがAIの存在だ。AIは、定型的な作業を得意とする。コードの自動生成、バグの検出、ドキュメントの作成。これらの領域では、すでにAIが人間を補助し、場合によっては代替し始めている。つまり、「言われたことをそのまま実装する」だけのエンジニアは、価値が下がっていく。一方で、AIに代替されにくい領域もある。技術的な意思決定を下すこと。チームを率いること。ビジネス課題を理解し、技術で解決策を提案すること。曖昧な要件を整理し、実装可能な形に落とし込むこと。これは、当面の間、人間の仕事だ。私が優れた組織で見てきた共通点がある。エンジニアがビジネスに直接触れていることだ。「ITとビジネスの橋渡し役」を介さず、エンジニア自身がビジネス指標を理解し、顧客と対話する。その直接的な接点が、AIには代替できない価値を生む。逆に言えば、「要件を受け取って実装するだけ」のエンジニアは、AIに代替されやすい。これは他人事ではなく、私自身も常に意識していることだ。だが、ここで短絡的な結論に飛ばないでほしい。「じゃあ、転職してシニアなポジションを取りに行こう」というのは間違いだ。なぜなら、シニアになるためには、ジュニアとしての経験が必要だからだ。問題は、「ジュニアのまま留まり続けること」だ。今の環境で、次のステージに進むための挑戦ができるなら、そうすべきだ。転職は、その挑戦ができない場合の、最後の手段であるべきだ。ここで自分に問いかけてほしい。直近1ヶ月で、「人間が介入しなければ解決しなかった意思決定」を何回行ったか。AIがコードを書ける今、「実装する」だけでは価値が出にくい。曖昧な要件を整理する。ステークホルダー間の調整をする。技術的な選択肢の中から、ビジネスインパクトを考慮して決断する。そういう「人間にしかできない仕事」をどれだけやっているか。それがシニアへの階段を登る経験だ。ここまで、「どの方向に進むか」「何を磨くか」「今の環境で成長できるか」について話してきた。キャリアを考えるとき、避けて通れない話がもう1つある。転職を考える動機として、最も頻繁に挙がるテーマだ。「年収を上げたい」は目的ではなく結果である転職理由として「年収を上げたい」はよく聞く。分かる。私だって年収は高い方がいい。だが、年収は目的ではなく、結果だ。「年収は結果」と言うのは簡単だ。でも、転職サイトを開くと、年収で検索してしまう。なぜか。年収は分かりやすい指標だからだ。「能力が上がった」は測りにくい。「年収が上がった」は明確だ。この分かりやすさの罠が、私たちを「能力より年収」に引き寄せる。対策は1つ。年収以外の「分かりやすい指標」を自分で設定することだ。「○○の技術を導入した」「△△人のチームをリードした」「□□の問題を解決した」——そういう指標を先に決めておけば、年収の誘惑に負けにくい。転職サイトを開く前に、「この転職で得たいもの」を3つ書き出してみてほしい。そのうち「年収」が1番目に来るなら、一度立ち止まる必要がある。年収は、あなたが提供できる価値の対価だ。技術力が高ければ、難しい問題を解ける。推進力があれば、プロジェクトを成功に導ける。影響力があれば、チームや組織を良い方向に動かせる。これらの価値を提供できるから、高い年収が払われる。年収600万円から800万円、800万円から1000万円。それぞれのステージを超えるには、提供できる価値のレベルを上げる必要がある。「一人で開発できる」から「チームをリードできる」へ。「技術的な問題を解ける」から「ビジネス課題を技術で解決できる」へ。企業によって「シニアエンジニア」の意味は違う。大手IT企業とスタートアップでは、同じ肩書きでも求められる水準が全く異なる。1000人規模の会社のシニアと、10人のスタートアップのシニアでは、経験してきた課題の複雑さも、責任の範囲も違う。同じ「シニア」でも、会社によって期待値が違う。ここで正直に振り返りたい。キャリアの進め方について、私は無自覚だった。一生懸命働けば、報酬は自然についてくるものだと思っていた。「会社が見ていてくれる」「評価されるべき人は評価される」——そう信じていた。でも、それは間違いだった。努力だけでは、次のレベルに到達できない。技術を磨くことと、キャリアを戦略的に構築することは、別のスキルなのだ。日本企業では「出る杭は打たれる」と言われるが、「出なさすぎる杭」は存在すら認識されない。逆に言えば、能力を上げずに年収だけ上げようとしても、無理がある。高年収の会社に転職できたとしても、その期待値に応えられなければ、いずれ居場所を失う。私自身、この罠に片足を突っ込んだことがある。ある時期、市場が過熱していた。エンジニアの採用難で、年収相場が跳ね上がっていた。転職サイトを見ると、今の年収より明らかに高いオファーがゴロゴロしている。「自分の市場価値はこんなに高いのか」と浮かれていた。でも、冷静に考えれば分かる話だった。それは「私の価値」ではなく、「市場のバブル」だった。実際に転職した人の話を聞くと、入社後に苦しんでいるケースが少なくなかった。「この年収なら、これくらいできるだろう」という期待に応えられない。前職では周囲のサポートがあったから成果が出せていたのに、新しい環境では1人で同じ成果を求められる。結果、評価が下がり、居心地が悪くなる。中には、年収ダウンで再び転職した人もいた。年収アップの転職で失敗する人には、共通点があった。「年収が上がる＝自分の価値が認められた」と解釈していたことだ。でも、採用側の論理は違う。「この年収を払えば、このくらいの成果が出るはずだ」という投資判断をしている。年収は「認定」ではなく「期待値」なのだ。その期待値に応えられなければ、厳しい現実が待っている。ここで、提示された年収アップのオファーについて冷静に考えてほしい。その年収は、あなたの「現在の実力」に対する評価なのか。それとも、市場のバブルや採用の緊急度による「プレミアム（下駄）」なのか。下駄を履いた状態で入社すると、期待値の調整で苦しむ。「このくらいできるだろう」という期待に応えられず、評価が下がり、居心地が悪くなる。そのリスクをどう管理するか。年収だけを見て決めると、この罠にはまりやすい。だから、「年収を上げるために転職する」のではなく、「能力を上げた結果として年収が上がる」という順序を間違えてはいけない。そして、能力を上げるためには、今の環境で何ができるかをまず考えるべきだ。ここで、転職を考えるときに気をつけてほしいことがある。「年収アップ」という言葉に惹かれて、転職エージェントの話を聞き始める人は多い。だが、エージェントの言葉を聞く前に、知っておくべきことがある。転職エージェントのビジネスモデルを理解する転職エージェントは、あなたの味方ではない。これは悪口ではなく、ビジネスモデルの話だ。転職エージェントにお金を払っているのは、あなたではない。採用企業だ。エージェントは、あなたを企業に紹介し、採用が決まったときに、企業から報酬を受け取る。その報酬は、あなたの年収の一定割合だ。つまり、エージェントにとって、あなたが「転職すること」が利益になる。あなたが「現職に残ること」は、彼らには何のメリットもない。むしろ、売上ゼロだ。だから、エージェントは転職を勧める。「今の会社に残った方がいい」とは、なかなか言ってくれない。彼らの言葉をそのまま鵜呑みにするのは危険だ。エージェントを使うなとは言わない。彼らは市場の情報を持っているし、面接対策のアドバイスもくれる。ただ、彼らのインセンティブ構造を理解した上で、話を聞くべきだ。本当に転職すべきかどうかは、エージェントではなく、あなた自身が決めることだ。できれば、利害関係のない第三者——信頼できる先輩、友人、メンター——に相談してほしい。ここで厳しいことを言う。自分のキャリアの最終責任者になれ。日本企業では、「会社がキャリアパスを用意してくれる」という期待がある。年功序列で昇進できる。上司が適切なアサインメントを考えてくれる。人事部がキャリア相談に乗ってくれる。——しかし、それは幻想だ。あなたのキャリアの最終責任者は、上司やエージェントや人事部ではなく、あなた自身だ。誰かが導いてくれるのを待つのではなく、自分で方向を決めて、自分で動く。その覚悟があるかどうかが、キャリアを作れるかどうかの分かれ目になる。自分でキャリアを管理するために、私が大事にしている習慣が2つある。1つは、時間管理より体力管理だ。同じ1時間でも、元気なときと疲れているときでは、アウトプットが全く違う。燃え尽きそうな状態で長時間働いても、成果は出ない。自分の体力がどこで回復し、どこで消耗するかを把握することが、長く働き続けるための鍵だ。もう1つは、フィードバックを受け入れる力だ。「それは違うと思います」と言われたとき、どう反応するか。防御的にならず、「なるほど、そういう見方もあるのか」と学びに変えられる人が、成長し続けられる。「自分は正しい」と固まった人は、どんなに優秀でも、そこで成長が止まる。ここまで、「辞めるな」「考えろ」と書き続けてきた。読んでいて息苦しくなった人もいるかもしれない。だから、バランスを取っておきたい。転職が正解だったケースも、確かにあるからだ。転職して正解だった人たちここまで「辞めるな」と書いてきたが、一方的になりすぎただろう。転職して正解だった人も、たくさんいる。私の知り合いにも、転職がキャリアの転機になった人がいる。大企業からスタートアップに移って、2年で技術力が飛躍的に伸びた人。逆に、スタートアップから大企業に移って、大規模開発の経験を積んだ人。マネジメント志向だったのに、転職先でスペシャリストとして開花した人もいる。1人の話をしよう。彼は大企業で5年間、安定したキャリアを積んでいた。評価も悪くなかった。でも、「このまま10年後も同じことをしているのか」という問いが、ずっと頭の片隅にあったという。彼が転職を決めたのは、「逃げたい」からではなかった。「自分の手でプロダクトを作りたい」という明確な欲求があった。大企業では、どうしても歯車の一部になる。意思決定に関われるのは、ずっと先の話だ。彼は、その「ずっと先」を待てなかった。転職先は、20人規模のスタートアップだった。最初の3ヶ月は地獄だったと言っていた。前職では当たり前だったインフラが何もない。ドキュメントもない。聞ける人もいない。「俺、何やってるんだろう」と思った夜もあったらしい。でも、半年後に変化が起きた。自分が設計したアーキテクチャが、本番環境で動き始めた。ユーザーからのフィードバックが、直接Slackに届くようになった。「自分の仕事が、誰かの役に立っている」——その実感が、すべてを変えたと言っていた。彼が転職で成功したのは、運が良かったからではない。辞める前に、「次に何を得たいか」が明確だったからだ。「今の環境が嫌だから」ではなく、「次の環境でこのスキルを得たい」「この経験を積みたい」という具体的な理由で動いていた。これは、私が見てきた「転職で成功した人たち」に共通する特徴だ。ここで視点を切り替えてみたい。「今の仕事への期待値は下げ、キャリアにはもっと期待しよう」。今の仕事で完璧を求めすぎない。すべての仕事が理想的であるはずがない。でも、キャリア全体では高い目標を持つ。3年後、5年後にどうなっていたいか。この視点の切り替えが、良い転職をした人たちの特徴だった。そして、もう1つ。彼らは辞める前に、現職でやれることをやり切っていた。「ここでやれることはやった」という実感があった。だからこそ、次の環境で活かせる実績と経験を持って移れた。転職が正解になるかどうかは、転職先の問題ではない。辞める前に何を積み上げたかの問題だ。だから、この記事で伝えたいのは「絶対に辞めるな」ではない。「辞める準備はできているか」を問え、ということだ。ただし、ここで1つ付け加えておきたい。準備とは関係なく、すぐに辞めるべきときがある。そのタイミングを見誤ると、取り返しのつかないことになる。それでも辞めるべきタイミングここまで「辞めるな」と書いてきた。でも、辞めるべきタイミングは確かにある。そして、それは「自分の問題」ではなく、「環境の問題」であることも多い。メンタルや身体が壊れそうなときは、今すぐ辞めろ。これだけは絶対だ。キャリアよりも健康が大事だ。あなた個人に対するリスペクトを感じない会社や現場からは、即刻立ち去るべきだ。そこで無理をする必要はない。一方的に消耗させられる必要もない。我慢して壊れてからでは遅い。組織の構造的問題があるときも、辞めていい。これは重要なポイントだ。個人の努力では変えられない問題が、組織には存在する。いくつか例を挙げる。評価制度が機能していない——成果を出しても正当に評価されない。声が大きい人だけが昇進する。透明性がない。技術的負債が放置されている——経営層が技術投資を理解せず、ひたすら機能追加だけを求める。改善の余地がない。権限と責任が一致しない——責任だけ押し付けられて、決定権がない。何を提案しても却下される。人間関係の構造が壊れている——特定の人物によるハラスメント。派閥争い。コミュニケーションの断絶。会社の方向性に共感できない——ビジョンが見えない。または、見えたビジョンが自分の価値観と合わない。これは、あなたの責任ではない。どんなに努力しても、個人で変えられない問題はある。「もっと頑張れば変えられるはず」と思って消耗し続ける必要はない。構造的問題を個人の努力で乗り越えようとするのは、無理ゲーだ。今の環境で目指す役割に挑戦する機会がどうしても得られないときも、辞め時だ。組織の構造上、テックリードのポジションがない。マネジメントのポジションがない。専門性を深める機会がない。そういう時は、環境を変える必要がある。私が辞め時だと思う明確なサインがある。「学びたい意欲はあるのに、実際には学べていない」状態だ。技術を深めたい、新しいことに挑戦したい——その気持ちはある。でも、日々の仕事は同じことの繰り返し。成長の機会がない。もう1つのサインは、「スキルではなく、対処法を学んでいる」状態だ。技術力が上がっているのではなく、「この上司にはこう報告すればいい」「この会議はこうやり過ごせばいい」という政治的なサバイバルスキルばかりが磨かれている。これは危険信号だ。その環境で得られるものは、もう得尽くした可能性が高い。しかし、一点だけ確認してほしい。本当に機会がないのか、自分が機会を見逃していないか。機会は待っていても来ない。自分で作り出すものだ。作り出そうとしたけど本当に無理だった——そう言えるなら、転職は正しい選択だ。一方で、こういう時は立ち止まってほしい。「なんとなく飽きた」「刺激がない」「成長できない気がする」——こういう漠然とした不満だけで辞めようとしているなら、一度考えてみてほしい。それは本当に環境の問題なのか。自分の姿勢の問題ではないのか。辞める理由が「環境の構造的問題」なら、辞めていい。辞める理由が「自分の漠然とした不満」なら、もう少し掘り下げてみてほしい。その違いを見極めることが大事だ。ここで1つ、厳しい問いを投げかけたい。「この会社では無理だ」という結論に至るまでに、組織のボトルネックに対して具体的な改善提案や行動を何回試みたか。「評価制度がおかしい」と感じたなら、上司やHRに具体的な改善案を提案したか。「技術的負債が放置されている」と感じたなら、解消のためのロードマップを作って経営層に説明したか。試行回数がゼロなら、それは「構造の問題」ではなく「食わず嫌い」かもしれない。失敗してもいいから、一度は試みてほしい。試みた上で無理だったなら、辞める判断は正しい。ここまで、様々な角度から転職について考えてきた。辞めるべきとき、辞めるべきでないとき、その判断基準を見てきた。最後に、これまでの内容を整理して、問いかけの形にまとめておきたい。転職を決断する前に転職を考えているあなたに、最後に問いかけたい。まず、方向性は明確か。テックリードを目指すのか、EMを目指すのか、スペシャリストとして深掘りするのか。次に進みたい方向が言語化できていなければ、転職は単なる「移動」に終わる。技術力、推進力、影響力のうち、今の自分に足りないものは何か。それを伸ばす機会が、本当に今の環境にはないのか。転職すれば自動的に成長できるわけではない。次に、積み上げたものを使い切ったか。転職には必ずリセットコストがかかる。信頼の貯金はゼロに戻る。ドメイン知識も、人間関係も、リセットされる。その代償を払ってでも得たいものは何か。今の会社で、信頼の貯金を活用してできる挑戦はもうないのか。信頼があるからこそ任される大きな仕事を、やり残していないか。現職で主体的に動いて成し遂げた実績を語れるか。「自分がいたからこそ生まれた差分」を説明できるか。そして、冷静に判断できているか。「成長できない」のは本当に環境のせいか。それとも、難しい課題から逃げているだけではないか。転職理由が「年収を上げたい」だけになっていないか。年収は結果であって、目的ではない。転職エージェントのアドバイスを鵜呑みにしていないか。彼らは転職させることでお金をもらっている。利害関係のない第三者——信頼できる先輩、友人、メンター——に相談したか。「一人前の開発者」から次のステージに進めているか。それとも、キャッチアップを繰り返しているだけではないか。すべてに明確な答えを持っている必要はない。だが、1つも考えたことがないなら、まだ転職を決断する段階ではない。おわりにこの記事で言いたかったことは、結局、1つだけだ。短期的にモノを考えるな。目の前の不満。今月の年収。来週の上司との関係。そういうものに振り回されて、衝動的に決断するな。3年後、5年後、10年後の自分がどうなっていたいか。そこから逆算して考えろ。若いエンジニアが短期的に考えてしまうのは、仕方がない。私もそうだった。目の前の不満が世界のすべてに見える。「今すぐ環境を変えたい」という衝動を抑えられない。それは、若さゆえの特権でもある。でも、その特権には代償がある。転職を繰り返すたびに、信頼の貯金はリセットされる。キャリアの複利は止まる。「いろんな経験を積んだ」と言えば聞こえはいいが、どこにも根を張れないまま、年齢だけが積み上がっていく。私は、そういう未来を避けたかった。転職は、逃げにもなるし、飛躍にもなる。同じ「辞める」という行動でも、その意味は正反対になりうる。違いを決めるのは、辞める前に何を考えたか。それだけだ。1つだけ、問いを残しておく。もし今の会社の嫌な部分——人間関係や評価制度——がすべて解消されたとしたら、それでもなお、その新しい会社に行きたいと心から思えるか。YESなら、それは「攻め」の転職だ。NOなら、それは高度に正当化された「逃げ」かもしれない。逃げが悪いとは言わない。ただ、逃げを「攻め」の物語ですり替えていないか、正直な気持ちで自分に問いかけてほしい。深夜2時、ベッドの中で転職サイトを開いたとき。その衝動を否定はしない。ただ、その衝動のまま動くな。翌朝、もう一度考えろ。1週間後、もう一度考えろ。それでもなお、辞めたいと思うなら、そのときは辞めればいい。正直に言えば、「正解」なんてない。辞めても、残っても、どちらが正しかったかは、誰にも分からない。分かるのは、ずっと後になってからだ。そして、その「正しさ」は、最初から存在していたわけではない。選んだ道を、正解にしていく過程があるだけだ。おい、考えろ。短期ではなく、長期で考えろ。そして、選んだら、それを正解にしろ。参考書籍ＩＴエンジニアの転職学　２万人の選択から見えた、後悔しないキャリア戦略 (ＫＳ科学一般書)作者:赤川朗講談社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社AmazonNINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon世界標準のフィードバック　部下の「本気」を引き出す外資流マネジメントの教科書作者:安田 雅彦SBクリエイティブAmazonみんなのフィードバック大全作者:三村 真宗光文社Amazonネガティブフィードバック　「言いにくいこと」を相手にきちんと伝える技術作者:難波 猛アスコムAmazonロバート・キーガンの成人発達理論――なぜ私たちは現代社会で「生きづらさ」を抱えているのか作者:ロバート・キーガン,中土井僚,鈴木規夫英治出版Amazon「人の器」の磨き方　リーダーシップ・コーチングと成人発達理論による人間力の変容プロセス作者:加藤洋平,中竹竜二日本能率協会マネジメントセンターAmazon「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazon組織も人も変わることができる！　なぜ部下とうまくいかないのか　「自他変革」の発達心理学作者:加藤洋平日本能率協会マネジメントセンターAmazon人が成長するとは、どういうことか作者:鈴木規夫日本能率協会マネジメントセンターAmazonあなたはなぜ雑談が苦手なのか（新潮新書）作者:桜林直子新潮社Amazon世界の一流は「雑談」で何を話しているのか作者:ピョートル・フェリクス・グジバチクロスメディア・パブリッシング（インプレス）Amazon「何を話していいかわからない」がなくなる　雑談のコツ作者:ひきた よしあきアスコムAmazon雑談の一流、二流、三流作者:桐生 稔明日香出版社Amazon雑用は上司の隣でやりなさい――あなたの評価を最大限に高める「コスパ最強」仕事術作者:たこすダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義は私たちをなぜ幸せにしないのか (ちくま新書)作者:ナンシー・フレイザー,江口泰子筑摩書房Amazon資本主義はなぜ限界なのか　――脱成長の経済学 (ちくま新書)作者:江原慶筑摩書房Amazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hacker NewsのShow HN に自作ツールを投稿する方法 ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622</guid>
            <pubDate>Sun, 04 Jan 2026 05:16:22 GMT</pubDate>
            <content:encoded><![CDATA[はじめにHacker News の「Show HN」は、自分が作ったものを開発者コミュニティに紹介できる場だ。しかし、ただ URL を貼れば良いわけではない。明確なルールがあり、それを守らないと投稿が埋もれたり、他のユーザーから通報されて非表示になることもある。この記事では、Show HN のルールを読み解き、効果的な投稿を作成するまでのプロセスを解説する。Show HN とは何かShow HN は Hacker News 内の特別なカテゴリで、自分が作ったものを他の人が試せる形で共有する場所だ。通常の HN 投稿がニュースや記事のシェアであるのに対し、Show HN は「触れるもの」を紹介する。投稿が一定のポイントを獲得すると、トップバーの "show" ページに表示され、より多くの人の目に触れる。ルールを正確に理解するShow HN には明確なルールがある。公式ガイドラインから重要なポイントを抜粋する。news.ycombinator.com投稿できるものユーザーが実際に試せるもの（run on their computers or hold in their hands）ハードウェアの場合は動画や詳細な記事でも可書籍の場合はサンプルチャプターでも可投稿できないものブログ記事サインアップページニュースレターリスト記事その他「読むだけ」のコンテンツこれらは「試せない」ため Show HN の対象外だ。通常の投稿として submit すべき。その他の重要なルール自分が関わったプロジェクトであること議論に参加できる状態であることサインアップやメール登録なしで試せるのが理想準備ができていないなら投稿しない（ready になってから来い）ランディングページや資金調達ページは NG友人に upvote や comment を頼むのは禁止（組織的な票操作とみなされる）マイナーアップデート（Foo 1.3.1 is out）は NG、メジャーオーバーホールなら可投稿フォームの構成Show HN の投稿は3つの要素で構成される。1. Title（タイトル）Show HN: で始める必要がある80文字制限がある（超過するとエラー）プロジェクト名と一言説明を入れる2. URLプロジェクトのリポジトリ、デモサイト、またはドキュメントページユーザーがすぐに試せる URL が理想3. Text（オプション）URL を補足する説明文何を作ったか、なぜ作ったか、どう使うかフィードバックを求めるポイントを明示すると反応が得やすい効果的なタイトルの作り方80文字という制限の中で、以下を伝える必要がある。プロジェクト名 — 何と呼ばれているか何をするものか — 一言で説明差別化ポイント（余裕があれば） — なぜこれが面白いかタイトルのパターンShow HN: [プロジェクト名] – [一言説明]文字数を削るテクニック：- 冠詞（a, an, the）を省略- "for" を "–" に置き換え- 形容詞を削る- 技術用語は略称を使う（もし一般的なら）良いタイトルの例Show HN: Helix – A post-modern text editor written in RustShow HN: Zed – A high-performance code editor from the creators of AtomShow HN: DuckDB – An embeddable SQL OLAP database management system避けるべきタイトルShow HN: My new project that I've been working on for 6 months  ← 情報がないShow HN: Check this out!  ← 何かわからないShow HN: Tool v1.3.2 released  ← マイナーアップデートは NGText（説明文）の書き方Text は任意だが、書いた方が反応は良くなる。以下の構成が効果的：1. 何を作ったか（1-2文）I built a [種類] that [主要機能].2. なぜ作ったか / 何が新しいか（2-3文）既存ツールとの違い、解決した課題、採用した理論やアプローチ。3. 使い方（1-3行）Quick start:  npm install -g mytool  mytool initワンライナーで試せると理想的。4. 主要機能（箇条書き、3-5個）Features:- Feature A- Feature B- Feature C5. フィードバックの呼びかけ（1文）Would love feedback on [具体的なポイント].「フィードバックください」だけでなく、何について聞きたいかを明示すると、具体的なコメントが得やすい。実際の投稿準備プロセスStep 1: ルールの確認まず公式ガイドラインを読む。ルールは時々更新されるため、投稿前に毎回確認するのが安全。news.ycombinator.comStep 2: 素材の整理プロジェクトの URLREADME や説明文主要機能のリストインストール方法Step 3: タイトルの作成80文字制限を意識しながら複数案を作成。文字数カウンターを使って確認する。Step 4: Text の作成上記の構成に沿って簡潔に。長すぎると読まれない。Step 5: 投稿タイミングHN のトラフィックは米国時間の午前中（太平洋時間 6-10 AM）がピーク。日本時間だと夜〜深夜にあたる。AI を活用した投稿準備Show HN の投稿準備は、AI アシスタントとの相性が良い。依頼の例https://news.ycombinator.com/showhn.html のルールに沿って、https://github.com/username/project を Show HN に投稿したい。タイトル、URL、テキストを作成してほしい。AI に依頼する際のポイント：ルールの URL を渡す — AI が最新のルールを参照できるプロジェクトの URL を渡す — README から情報を抽出してもらえる文字数制限を伝える — 80文字制限など、具体的な制約を共有AI が生成した案をそのまま使うのではなく、自分の言葉で調整することで、より自然な投稿になる。投稿後の対応Show HN では投稿者がコメントに返信することが期待されている。質問には丁寧に回答批判的なコメントにも建設的に対応バグ報告には感謝を伝え、対応する姿勢を見せる投稿して放置するのは印象が悪い。数時間はコメントを監視できるタイミングで投稿しよう。まとめShow HN への投稿は、単なる宣伝ではなく、開発者コミュニティとの対話の始まりだと思います。ルールを守る — 「試せるもの」を投稿するタイトルは80文字以内 — プロジェクト名 + 一言説明Text で文脈を与える — 何を、なぜ、どう使うかフィードバックポイントを明示 — 具体的な質問を投げかける投稿後は対話する — コメントに返信する]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ory HydraでOAuth2認可サーバーを構築する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007</guid>
            <pubDate>Sun, 04 Jan 2026 04:30:07 GMT</pubDate>
            <content:encoded><![CDATA[はじめに認可サーバーを構築するタスクがアサインされた。技術選定の裁量はある。仕事の合間にRFC 6749や技術書をいくつか読み始めた。datatracker.ietf.org帰宅後の深夜、週末の空き時間。3日目の深夜2時、私は確信した。これは自前で作るべきではない。認可コードフロー、インプリシットフロー、リソースオーナーパスワードクレデンシャル、クライアントクレデンシャル。4つのグラントタイプ。それぞれにセキュリティ要件がある。PKCEも必要だ。OpenID Connectも。IDトークンのクレーム設計。JWKSエンドポイント。セッション管理。トークン失効。リフレッシュトークンのローテーション。仕様を読めば理解できる。実装もできる。でも、これをプロダクション品質で検証し続けるのは、私たちの仕事ではない。3日間RFCを読んで分かったのは、「自前で作ることの非合理性」だった。調べていく中で、OpenAIがOryを採用していることを知った。www.ory.com彼らは認可サーバーの実装に時間を使わないことを選んだ。彼らの本業はAIモデルの開発だ。認証認可は重要だが、「解くべき問題」ではなく「解決済みの問題を使う」領域として扱っている。妥当な判断だと思う。Ory Hydraを採用することにした。www.ory.shgithub.comこの記事では、Hydraのアーキテクチャを解説し、Docker Composeで実際に動かすところまでやる。OAuth2/OIDCの基本概念は知っている前提で進める。OAuth徹底入門 セキュアな認可システムを適用するための原則と実践作者:Justin Riche,Antonio Sanso翔泳社AmazonOAuth 2 in Action (English Edition)作者:Richer, Justin,Sanso, AntonioManningAmazonこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。「認証をしない認可サーバー」という話www.ory.comHydraのドキュメントを読んでいて、ある一文で手が止まった。「Hydraは認証をしません」認可サーバーなのに認証しない。最初は設計の欠落かと思った。Auth0やKeycloakは全部やってくれるのに。だが、ドキュメントを読み進めるうちに意図が見えてきた。これは欠陥ではない。これこそが設計の核心だ。考えてみてください。あなたの会社には、おそらく既にユーザーデータベースがある。10年使ってきた認証システムがある。LDAPで認証している。多要素認証は自前のものを使っている。パスキー対応も進めている。一般的なIdP——Auth0やKeycloak——を導入すると、これらを全部IdP側に合わせなければなりません。データ移行。認証フローの再設計。既存システムとの複雑な連携。Hydraは違うアプローチを取ります。「認証はあなたたちでやってください。終わったら教えてくれれば、あとはこちらでOAuth2/OIDCの面倒なことは全部やります」この瞬間、私の中で何かがカチッとはまりました。既存の認証システムはそのまま。ユーザーDBもいじらない。ただ、OAuth2/OIDCのプロトコル層だけをHydraに任せる。認証と認可の責務が完全に分離される。これが「ヘッドレス」な認可サーバーというコンセプトです。具体的には以下のメリットがあります。既存システムはそのまま使える: ユーザーDB・認証ロジックをいじらなくていい認証方法は完全に自由: パスワード、パスキー、生体認証、なんでもHydraが担保するのはプロトコル準拠: OpenID Connect Certificationを取得済みhttps://openid.net/certification/openid.netアーキテクチャの全体像www.ory.comHydraを使ったシステムは、3つのコンポーネントで構成されます。Hydra Public API（ポート4444）はOAuth2/OIDCの「顔」です。クライアントアプリケーションが/oauth2/authに認可リクエストを投げ、/oauth2/tokenでトークンを受け取る。ここはHydraが全部やってくれます。Login/Consent Provider（ポート3000）が私たちの実装領域です。Hydraからリダイレクトされてきたユーザーに対して、/loginで認証画面を、/consentで同意画面を表示します。「このユーザーは本人か？」「このスコープを許可するか？」という判断を担う。ここに既存の認証ロジックを組み込みます。Hydra Admin API（ポート4445）は裏方です。Login/Consent Providerが認証・同意の結果をHydraに通知するために使います。チャレンジの検証、承認の通知、セッション管理を担当します。外部には公開せず、内部ネットワークからのみアクセスさせます。この構成を理解したとき、肩の荷が下りた気がしました。OAuth2/OIDCの複雑な部分はHydraに任せて、自分たちは「認証」という本質的な部分だけに集中できる。これなら、やれそうだ。チャレンジベースのフローwww.ory.comHydraとProviderの連携には「チャレンジ」という仕組みが使われます。最初は「なんで直接やり取りしないんだろう」と思いました。でも、この設計にはちゃんと理由があります。クライアントがHydraの/oauth2/authにリダイレクトHydraがlogin_challengeを生成し、Login ProviderにリダイレクトLogin Providerはlogin_challengeを検証し、ユーザーを認証認証成功後、Admin APIで承認を通知し、Hydraに戻るHydraがconsent_challengeを生成し、Consent ProviderにリダイレクトConsent Providerはスコープを確認し、Admin APIで承認クライアントに認可コードが返されるチャレンジは一度きりの使い捨てトークンです。傍受されても再利用できない。リプレイ攻撃やセッションハイジャックを構造的に防ぎます。この手のセキュリティ上の細かい配慮——正直、自前実装だと見落としがちだ。PKCEのcode_verifierの長さ制限（43-128文字）。stateパラメータに暗号学的に安全な乱数を使うべきこと。RFCを読んでいたあの3日間で、攻撃ベクトルをどれだけ考慮できていたか。Hydraはこれらをすべて内包しています。OpenID Connect Certificationを取得しているということは、私が見落としていたであろう細部まで検証されているということです。Docker Compose環境の構築www.ory.com理論は十分。実際に動かしてみましょう。OAuth2/OIDCの仕様は複雑です。RFC 6749を読んでも、認可コードフローの全体像が頭に入らなかった。実際にcurlでリクエストを投げ、リダイレクトを追いかけることで、初めて仕様書の抽象的な記述が腑に落ちました。開発環境は4つのサービスで構成されます。HydraのDockerイメージは公式で提供されています。hub.docker.comservices:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: hydra      POSTGRES_PASSWORD: secret      POSTGRES_DB: hydra    volumes:      - postgres_data:/var/lib/postgresql/data    healthcheck:      test: ["CMD-SHELL", "pg_isready -U hydra -d hydra"]      interval: 5s      timeout: 5s      retries: 5  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:3000/consent      URLS_LOGIN: http://localhost:3000/login      URLS_LOGOUT: http://localhost:3000/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - "4444:4444"      - "4445:4445"    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4444/health/ready"]      interval: 10s      timeout: 5s      retries: 5  auth-provider:    build: .    environment:      HOST: 0.0.0.0      PORT: 3000      HYDRA_ADMIN_URL: http://hydra:4445      RUST_LOG: ory_hydra_rust=debug,tower_http=debug    ports:      - "3000:3000"    depends_on:      hydra:        condition: service_healthyvolumes:  postgres_data:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMに32文字以上の暗号学的に安全な値を設定し、sslmode=disableはrequireに変更してください。docs.docker.comauth-providerサービスのbuild: .は、Login/Consent ProviderのDockerfileを参照しています。このDockerfileとRust実装は次回の記事で解説します。今回はHydraのアーキテクチャ理解に集中しましょう。サンプルコードは以下のリポジトリで公開しています。https://github.com/nwiizo/workspace_2026/tree/main/samples/ory-hydra-rustgithub.comdepends_onとhealthcheckの組み合わせがポイントです。PostgreSQL → マイグレーション → Hydra → auth-providerという起動順序が保証されます。私は最初これを書かずに「DBがない」エラーで30分悩みました。環境の起動と動作確認docker compose up -d --builddocker compose logs -f auth-providerヘルスチェック用エンドポイントにアクセスしてみます。curl http://localhost:3000/health# {"status":"healthy"}{"status":"healthy"}が返ってきた。たった数十行のdocker-compose.ymlで、OAuth2認可サーバーの基盤が動いている。RFCを読んでいたあの3日間で見えた複雑さが、Hydraの中に隠蔽されている。OAuth2クライアントの登録OAuth2フローをテストするには、まずクライアントを登録します。www.ory.shdocker compose exec hydra hydra create oauth2-client \  --endpoint http://localhost:4445 \  --grant-type authorization_code \  --response-type code \  --scope openid,offline_access,profile,email \  --redirect-uri http://localhost:8080/callback \  --name "Test Client"クライアントIDとシークレットが出力されるので控えておきます。OAuth2フローのテストテストユーザーを作成します。curl -X POST http://localhost:3000/api/auth/register \  -H "Content-Type: application/json" \  -d '{"email": "test@example.com", "password": "password123"}'ブラウザで認可エンドポイントにアクセスします（<CLIENT_ID>は先ほど取得したもの）。http://localhost:4444/oauth2/auth?client_id=<CLIENT_ID>&response_type=code&scope=openid+profile+email&redirect_uri=http://localhost:8080/callback&state=random_stateフローは以下のように進みます。Hydraがログイン画面にリダイレクトメールアドレスとパスワードを入力してログインHydraが同意画面にリダイレクトスコープを確認して同意http://localhost:8080/callback?code=...にリダイレクトリダイレクト先（8080）は存在しなくても構いません。URLから認可コードを取得できれば成功です。おわりにこの記事を書き終えて、時計を見た。深夜1時だ。正直に言うと、書いている途中で何度かRFCのタブを開いてしまった。「この説明で合ってるかな」と不安になって。私はこの記事を書いたからといって、OAuth2/OIDCを完全に理解したわけではない。たぶん来週も、仕様書の細部で「あれ？」となる瞬間がある。でも、少しだけ違うことがある。3日目の深夜2時、RFCのタブを20個開いて、私は判断した。これは自前で作るべきではない、と。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Hydraのアーキテクチャを理解して、Docker Composeで動かしてみて、その判断が正しかったと確信した。認証と認可は分離できる。複雑なプロトコル層は、検証済みの実装に任せていい。私が書くべきコードは、真ん中の「Login/Consent Provider」だけだ。「認可サーバーを自前で作ってくれ」もしあなたが今、この言葉を受けてRFCを読んでいるなら。3日読めば分かる。作れるかどうかではない。作るべきかどうかだ。RFCを読むことには意味がある。私もあの3日間があったから、Hydraの設計思想が腑に落ちた。でも、プロダクション品質の認可サーバーを一人で検証し続ける必要はない。検証済みの実装がある。明日の朝、目覚ましが鳴る。また仕事が始まる。おい、RFCのタブを閉じろ。Hydraのドキュメントを開け。何度でも思い出せることの方が大事だ。次の記事では、RustでLogin/Consent Providerを実装する。一緒に認証画面を作ろう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[私の為のNvChadのキーマッピングガイド 2026年版]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621</guid>
            <pubDate>Fri, 02 Jan 2026 15:26:21 GMT</pubDate>
            <content:encoded><![CDATA[はじめに一月三日である。私は今、ソファの深淵に身を沈め、己の怠惰と対峙しているところである。年末にやろうと固く心に誓った開発環境の整理は、見事なまでに手つかずのまま新年を迎えてしまった。大掃除もしていない。年賀状も書いていない。結婚もしていないし、友人と過ごす予定もなかった。やらなかったことを指折り数えていると、正月休みの大半が、まるで人生の棚卸しのような様相を呈し、胸中は罪悪感で満たされていくのである。「年末年始は何をしていたのか」と問われれば、私は途方に暮れるほかない。身体は動かしていない。コードは書いた。本を読み、近所を散歩した。であるから、休んだと言えば休んだのであろう。しかしながら、休んだという実感が皆無なのである。なぜか。「あのキーバインド、なんだったか」という問いが、四六時中、頭蓋骨の内側をぐるぐると巡り続けていたからに相違ない。私はNvChadを使っている。かれこれ四年ほど使い続けている。それにもかかわらず、半年ぶりに設定を見直すたびに「これ、なんのキーだったか」と首を傾げてしまうのである。設定ファイルには丁寧にコメントを書いてある。過去の自分が、未来の自分のために残してくれた親切なメモである。しかし、読んでも思い出せない。覚えた数だけ忘れている。どうやら人間の脳というものは容量が有限であり、Vimのキーバインドよりも優先して記憶すべき事柄があるらしいのだ。たとえば、それが何であるかは私にもわからないのだが。毎年、年始になると私は同じことを繰り返している。設定を見直す。新しいプラグインを試す。キーマッピングを整理する。そしてまた忘れる。「今年こそ覚える」という新年の誓いは、結局のところ、翌年の自分に対する壮大な裏切り行為でしかないのである。このガイドは、そんな救いようのない私のための備忘録である。来年の今頃、またしても全てを忘れ去った自分のために書いている。もしかすると、同じように忘れっぽい誰かの役に立つかもしれない。立たないかもしれない。たぶん、立たない。ちなみに、一昨年にも同じようなことを書いている。進歩がない。ただし、構成はだいぶ変わった。ステータスラインを廃止し、ファイルエクスプローラーをoil.nvimに変え、Snacks.nvimを導入した。変わっていないのは、私が相変わらずキーマッピングを忘れ続けているという事実だけである。syu-m-5151.hatenablog.com開発環境全体についてはこちらに記した。興味のある方は参照されたい。syu-m-5151.hatenablog.comさて、前置きが長くなった。よく忘れるキーマッピングをまとめていくこととする。設定ファイルは以下に置いてある。github.com基本的なショートカット表記<C> = Ctrlキー<leader> = スペースキー（デフォルト）<A> = Altキー<S> = Shiftキーよく使う機能とそのキーマッピング基本操作で必須のコマンド<C-s>       - 保存（これだけは絶対覚える。:w なんてやっているとVSCodeを使っている人にバカにされる）;           - コマンドモードに入る（:を押す必要がない）jk または jj - インサートモードを抜ける（Escより断然速い）<Esc>       - 検索ハイライトをクリア<leader>y   - システムクリップボードにヤンク<leader>Y   - 行全体をシステムクリップボードにヤンク<leader>d   - ヤンクせずに削除（レジスタを汚さない）ナビゲーション（移動系）スクロールと検索が画面中央に来るようにカスタマイズしている。迷子にならない。<C-d>  - 半ページ下スクロール（画面中央維持）<C-u>  - 半ページ上スクロール（画面中央維持）n      - 次の検索結果（画面中央維持）N      - 前の検索結果（画面中央維持）検索系（2つのピッカーを使い分け）Snacks Picker（s系）- メインで使うSnacks.nvimは2024年末に登場した新しいユーティリティセット。高速で美しい。<leader><leader> - スマートピッカー（最重要：状況に応じた最適な検索）<leader>sf - ファイル検索<leader>sg - プロジェクト内テキスト検索（grep）<leader>sw - カーソル下の単語を検索<leader>sb - 開いているバッファを検索<leader>sr - 最近開いたファイルを検索<leader>sc - コマンド検索<leader>sh - ヘルプ検索<leader>sk - キーマップ検索（何かわからなくなったらこれ）<leader>sd - 診断情報を検索<leader>ss - LSPシンボル検索<leader>sR - 直前のピッカーを再開github.comTelescope（f系）- 補助的に使う長年使い慣れたTelescope。fzf-nativeで高速化済み。<C-p>       - ファイル検索（VSCodeユーザーも安心）<leader>ff  - ファイル検索<leader>fg  - ライブgrep<leader>fb  - バッファ検索<leader>fh  - ヘルプタグ検索<leader>fr  - 最近のファイル<leader>fc  - Gitコミット検索<leader>fs  - Gitステータス<leader>fd  - 診断情報github.comファイルエクスプローラー（oil.nvim）NvimTreeからoil.nvimに乗り換えた。バッファのようにディレクトリを編集できる革命的なプラグイン。ファイル名を間違えて作成しても、ddで消せる。Vimの操作で世界を編集している気分になれる。気分だけ。-           - 親ディレクトリを開く（最重要：ファイル階層を上る）<leader>e   - ファイルエクスプローラーを開く<CR>        - ファイル/ディレクトリを選択<C-v>       - 垂直分割で開く<C-s>       - 水平分割で開くg.          - 隠しファイルの表示切り替えgithub.com高速移動（flash.nvim）EasyMotion系のモダンな代替。画面内のどこにでも2-3キーで飛べる。s  - Flash（画面内の任意の位置にジャンプ）S  - Flash Treesitter（構文単位でジャンプ）r  - Remote Flash（オペレーターモード用）github.comLSP関連（コードジャンプ・リファレンス）コードリーディングする時に本当に助かる機能たち。gd          - 定義へジャンプ（最も使う）gD          - 宣言へジャンプgi          - 実装へジャンプ（インターフェースから実装を探せる）gr          - 参照を探す（変数やメソッドの使用箇所を探せる）K           - ホバー情報を表示（ドキュメント、型情報）<leader>rn  - シンボルをリネーム<leader>ca  - コードアクション（自動修正候補など）<leader>fm  - フォーマット（conformで整形）<leader>cf  - フォーマット（代替キー）<leader>lk  - シグネチャヘルプ<leader>lD  - 型定義へジャンプgithub.comコードピーク（overlook.nvim）定義にジャンプせずに、フローティングウィンドウで確認できる。<leader>pd  - 定義をピーク（フローティングで定義を確認）<leader>pc  - すべてのポップアップを閉じる<leader>pu  - 最後のポップアップを復元<leader>pU  - すべてのポップアップを復元<leader>pf  - フォーカスを切り替え<leader>ps  - 分割で開く<leader>pv  - 垂直分割で開く<leader>po  - 元の場所で開くgithub.com診断・エラー確認（Trouble）診断情報を一覧で見やすく表示してくれる。[d          - 前の診断へ]d          - 次の診断へ<leader>ld  - 行の診断情報をフロートで表示<leader>lq  - 診断をloclistに送る<leader>xx  - 診断パネルをトグル（Trouble）<leader>xX  - 現在のバッファの診断のみ<leader>xs  - シンボル一覧（Trouble）<leader>xl  - LSP定義一覧<leader>xq  - Quickfixリスト<leader>xt  - TODO/FIXME一覧github.com画面分割とウィンドウ移動複数のファイルを同時に見たい時に使う。<C-h>       - 左のウィンドウへ<C-l>       - 右のウィンドウへ<C-j>       - 下のウィンドウへ<C-k>       - 上のウィンドウへ<leader>|   - 垂直分割<leader>-   - 水平分割<leader>w=  - ウィンドウサイズを均等に<leader>wm  - ウィンドウを最大化（他を閉じる）バッファ操作<S-h>       - 前のバッファへ（Shift + h）<S-l>       - 次のバッファへ（Shift + l）<leader>x   - バッファを閉じる<leader>bd  - バッファを削除（Snacks）<leader>bo  - 他のバッファをすべて削除ビジュアルモードの改善J           - 選択した行を下に移動K           - 選択した行を上に移動<leader>p   - ペースト（レジスタを上書きしない）Git操作LazyGitとの統合が最高に便利。ターミナルでgitコマンドを打つ必要がほぼなくなった。git add -pのインタラクティブモードを思い出せなくても、もう困らない。<leader>gg  - LazyGitを開く（これだけで全部できる）<leader>gl  - LazyGit ログを表示<leader>gf  - 現在のファイルのログを表示<leader>gd  - Git Diff（作業ツリー全体）<leader>gD  - 前のコミットとのDiff<leader>gh  - ファイルの履歴<leader>gH  - ブランチの履歴<leader>gs  - ステージされた変更のDiff<leader>gm  - mainブランチとのDiff<leader>gM  - masterブランチとのDiff<leader>gq  - Diffviewを閉じる<leader>gt  - ファイルパネルをトグル<leader>gp  - Hunkをプレビュー<leader>gb  - 行のBlameを表示<leader>gB  - 行Blameのトグル]c          - 次のHunkへ[c          - 前のHunkへ<leader>hr  - Hunkをリセット<leader>hs  - Hunkをステージ<leader>hu  - Hunkのステージを取り消しgithub.comgithub.comgithub.comターミナル操作<leader>tt  - ターミナルをトグル（Snacks）<C-x>       - ターミナルモードを抜けるAI統合（2026年の目玉）GitHub CopilotとClaudeの両方を使える贅沢な環境。CopilotChat（a系）<leader>ao  - チャットを開く<leader>aq  - チャットを閉じる<leader>ar  - チャットをリセット<leader>ae  - コードを説明（ビジュアルモード対応）<leader>af  - コードを修正<leader>at  - テストを生成<leader>ad  - ドキュメントを生成<leader>aR  - コードをレビューgithub.comAvante（Cursor風のAI体験）<leader>aa  - AIに質問<leader>ax  - コードを編集<leader>aS  - 回答をリフレッシュgithub.comClaudeCode（ターミナル統合）<leader>cc  - Claudeをトグル<leader>cf  - Claudeにフォーカス<leader>cr  - 会話を再開<leader>cC  - 会話を継続<leader>cm  - モデルを選択<leader>cb  - 現在のバッファを追加<leader>cs  - 選択範囲をClaudeに送信（ビジュアルモード）github.com補完操作（nvim-cmp）<C-p>       - 前の候補<C-n>       - 次の候補<C-d>       - ドキュメントを下にスクロール<C-f>       - ドキュメントを上にスクロール<C-Space>   - 補完を手動で開始<C-e>       - 補完を閉じる<CR>        - 候補を確定<Tab>       - 次の候補 / スニペット展開<S-Tab>     - 前の候補 / スニペット前へgithub.comトグル系（u系）Snacks.nvimが提供する便利なトグル機能。<leader>us  - スペルチェックのトグル<leader>uw  - ワードラップのトグル<leader>ud  - 診断のトグル<leader>uh  - インレイヒントのトグルその他の便利機能<leader>?   - 現在のバッファのキーマップを表示（which-key）<leader>rr  - カーソル下の単語を置換<leader>cx  - ファイルに実行権限を付与<leader>j   - 次のQuickfix項目へ<leader>k   - 前のQuickfix項目へ<leader>sT  - TODO/FIXME/HACKなどを検索（TodoTelescope）]t          - 次のTODOへ[t          - 前のTODOへgithub.comgithub.comDiffviewコンフリクト解決マージコンフリクトの解決が格段に楽になる。]x          - 次のコンフリクトへ[x          - 前のコンフリクトへ<leader>co  - oursを選択<leader>ct  - theirsを選択<leader>cb  - baseを選択<leader>ca  - 両方を選択dx          - コンフリクトを削除ビジュアル・UI設定2026年版の大きな特徴は、ミニマルなUIへの移行だ。ステータスラインとタブラインを完全に廃止し、編集スペースを最大化している。情報が多すぎて、結局何も見ていなかったことに気づいたからだ。テーマとカラースキームaquariumテーマを採用。落ち着いた色調で長時間の作業でも目が疲れにくい。-- chadrc.luaM.base46 = {  theme = "aquarium",  transparency = false,  hl_override = {    Comment = { italic = true },    ["@comment"] = { italic = true },    CursorLine = { bg = "#2a2a3a" },    CursorLineNr = { fg = "#fab387", bold = true },  },}ステータスライン廃止の理由従来のステータスラインは廃止し、代わりに以下のプラグインで情報を表示している:incline.nvim: ウィンドウ右下にファイル名と診断情報を表示modes.nvim: カーソルラインの色でモードを表示（Insert=水色、Visual=紫、Delete=赤、Copy=黄）noice.nvim: コマンドラインをフローティングで中央に表示-- options.luao.cmdheight = 0    -- コマンドラインを非表示（noice.nvimが担当）o.laststatus = 0   -- ステータスラインを非表示（incline.nvimが担当）o.showmode = false -- モード表示を非表示（modes.nvimが担当）行番号設定相対行番号を有効化。5jや10kのような相対移動が直感的になる。o.number = true         -- 現在行は絶対行番号o.relativenumber = true -- 他の行は相対行番号o.numberwidth = 4       -- 行番号の幅スクロール設定カーソルが画面端に到達する前にスクロールが始まる。常に周囲のコンテキストが見える。o.scrolloff = 8     -- 上下8行を常に表示o.sidescrolloff = 8 -- 左右8列を常に表示インデント設定2スペースインデントを採用。タブは使わない。o.tabstop = 2o.shiftwidth = 2o.expandtab = trueo.smartindent = trueその他のUI設定o.termguicolors = true  -- 24bitカラーo.signcolumn = "yes"    -- サインカラムを常に表示（ガター）o.cursorline = true     -- カーソル行をハイライト（modes.nvimで色が変わる）o.splitright = true     -- 垂直分割は右にo.splitbelow = true     -- 水平分割は下にo.clipboard = "unnamedplus" -- システムクリップボードと連携o.undofile = true       -- 永続的なundo履歴o.swapfile = false      -- スワップファイルを作らない使用プラグイン一覧と説明UI系プラグイン プラグイン                 説明                                                                                                                                                                                    incline.nvim           ウィンドウ右下にファイル名・アイコン・診断情報を表示するミニマルなフローティングステータスライン。init.luaやmod.rsのような一般的なファイル名の時は親ディレクトリ名も表示される。  modes.nvim             Vimのモード（Normal/Insert/Visual/Delete）に応じてカーソルラインと行番号の色を変える。モード表示がなくても今どのモードにいるか一目でわかる。                                            noice.nvim             コマンドライン、メッセージ、通知をモダンなフローティングUIで表示。画面中央にポップアップするコマンドパレット風のUIが特徴。詳細は後述。                                                  nvim-notify            通知をモダンなポップアップで表示。フェードアニメーションで視認性が高い。                                                                                                                vimade                 非アクティブなウィンドウ/バッファを薄暗く表示。どのウィンドウがアクティブかが視覚的にわかる。                                                                                           better-escape.nvim     jkやjjでインサートモードから抜ける。Escキーに手を伸ばす必要がなくなる。                                                                                                             which-key.nvim         キーを押すと次に押せるキーのヒントを表示。<leader>を押して300ms待つとメニューが出る。                                                                                                 indent-blankline.nvim  インデントレベルを縦線で可視化。ネストの深さが一目でわかる。                                                                                                                           noice.nvim の詳細noice.nvimは、Neovimの標準的なコマンドライン（画面下部の:プロンプト）を完全に置き換え、モダンなフローティングUIを提供するプラグイン。従来の「画面下に張り付いたコマンドライン」から「画面中央にポップアップするコマンドパレット」へと体験が一変する。主な機能:コマンドラインのポップアップ化:を押すと画面中央にフローティングウィンドウが出現入力中のコマンドがシンタックスハイライトされるコマンドタイプに応じたアイコン表示検索のポップアップ化/（前方検索）や?（後方検索）もポップアップで表示検索パターンが正規表現としてハイライトされるコマンドタイプ別のアイコン| 入力 | アイコン | 説明 ||------|---------|------|| : | | 通常のVimコマンド || `/` | ` ` | 前方検索 || `?` | ` ` | 後方検索 || `:!` | `$` | シェルコマンド実行 || `:lua` | | Lua実行 || :help | 󰋖 | ヘルプ |メッセージ・通知の統合エラーや警告メッセージをnvim-notify経由で右下にポップアップ長いメッセージは自動的にスプリットウィンドウに表示LSP統合LSPの処理進捗を表示ホバー情報やシグネチャヘルプもモダンなUIで表示-- 設定例（私の設定）views = {  cmdline_popup = {    position = { row = "50%", col = "50%" },  -- 画面中央    size = { width = 60, height = "auto" },    border = { style = "rounded", padding = { 0, 1 } },  },},この設定により、従来のNeovimとは全く異なる、VSCodeやCursor風のモダンな操作感が得られる。github.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comナビゲーション系プラグイン プラグイン          説明                                                                                                                                                      snacks.nvim     folke氏による多機能ユーティリティセット。LazyGit統合、高速ピッカー、バッファ削除、ターミナル、デバッグ機能などを提供。2024年末に登場し、急速に普及した。  telescope.nvim  定番のファジーファインダー。ファイル、バッファ、grep、Git操作など何でも検索できる。fzf-nativeで高速化済み。                                               oil.nvim        ディレクトリをバッファとして編集できるファイルエクスプローラー。ファイル名の変更や移動がテキスト編集と同じ感覚でできる革命的なプラグイン。                flash.nvim      画面内の任意の位置に2-3キーでジャンプ。EasyMotionの後継。Treesitterと連携して構文単位のジャンプも可能。                                                   overlook.nvim   定義にジャンプせずにフローティングウィンドウでコードをプレビュー。元の位置を見失わずに定義を確認できる。                                                  hbac.nvim       開いているバッファが一定数を超えると、最近使っていないバッファを自動的に閉じる。バッファが溢れかえるのを防ぐ。                                           github.comGit系プラグイン プラグイン         説明                                                                                                                    gitsigns.nvim  変更行の左側にサイン（追加=緑、変更=青、削除=赤）を表示。Hunk単位でのステージ、リセット、プレビュー、Blame表示も可能。  diffview.nvim  Git Diffを視覚的に表示。2画面分割で変更前後を比較できる。コンフリクト解決UIも備え、ours/theirs/baseの選択が簡単。      診断・コード品質系プラグイン プラグイン              説明                                                                                                                          trouble.nvim        診断情報（エラー、警告）をパネルに一覧表示。プロジェクト全体の問題を俯瞰できる。シンボル一覧やQuickfixリストの表示にも対応。  todo-comments.nvim  コード内のTODO、FIXME、HACK、BUG、NOTEなどをハイライト表示し、検索可能にする。放置されたTODOを見つけやすい。       LSP・フォーマッタ系プラグイン プラグイン            説明                                                                                                                nvim-lspconfig    Neovim内蔵LSPクライアントの設定を簡単にする公式プラグイン。各言語のLanguage Serverとの接続を管理。                  mason.nvim        LSPサーバー、DAP（デバッガ）、リンター、フォーマッタを簡単にインストール・管理できる。:MasonコマンドでUIが開く。  conform.nvim      フォーマッタの統合プラグイン。保存時に自動フォーマットを実行。複数フォーマッタの連携も可能。                        nvim-treesitter   Tree-sitterによる高精度なシンタックスハイライトとインデント。正規表現ベースよりも正確な構文解析。                   schemastore.nvim  JSON/YAMLファイル用のスキーマを提供。package.jsonやtsconfig.jsonなどの補完と検証が効く。                       github.comgithub.comgithub.comgithub.comAI統合プラグイン プラグイン            説明                                                                                                                                             copilot.lua       GitHub Copilotの純粋なLua実装。インライン補完を提供するが、私の設定ではcopilot-cmp経由で補完メニューに統合。                                     copilot-cmp       Copilotの補完をnvim-cmpのソースとして使用。補完メニュー内で他のソース（LSP、バッファ等）と一緒にCopilot候補が表示される。                        CopilotChat.nvim  AIとのチャットインターフェース。コードの説明、レビュー、テスト生成、ドキュメント生成などをチャット形式で依頼できる。Claude Sonnetモデルを使用。  avante.nvim       Cursor風のAI編集体験をNeovimで実現。選択範囲に対してAIに編集を依頼し、差分をプレビューしてから適用できる。                                       claudecode.nvim   Claude Code CLIをNeovim内で直接使用。ターミナル統合でClaude Codeの全機能にアクセス可能。                                                        github.comgithub.com補完系プラグイン プラグイン        説明                                                                                      nvim-cmp      Neovimの補完エンジン。高速でカスタマイズ性が高い。複数のソースからの補完を統合して表示。  cmp-nvim-lsp  LSPからの補完をnvim-cmpに提供するソース。                                                 cmp-buffer    現在開いているバッファ内の単語を補完候補として提供。                                      cmp-path      ファイルパスを補完。ディレクトリ構造をたどりながら入力できる。                            cmp-cmdline   コマンドラインモード（:）での補完を提供。                                                 LuaSnip       スニペットエンジン。定型コードを素早く展開。                                              lspkind.nvim  補完メニューにアイコンを表示。種類（関数、変数、クラス等）が視覚的にわかる。             github.comgithub.comgithub.comgithub.comgithub.comgithub.com言語固有プラグイン プラグイン        説明                                                                                                                      rustaceanvim  Rust開発を強化するプラグイン。rust-analyzerとの統合を改善し、Rust固有の機能（expand macro、join lines等）を提供。         crates.nvim   Cargo.toml内のクレート（依存関係）のバージョン情報を表示。最新バージョンへの更新や、利用可能なバージョンの確認が簡単。 github.comgithub.comフォーマッタ・LSP設定保存時に自動フォーマットが走る。conform.nvimを使用。 言語                   フォーマッタ               TypeScript/JavaScript  prettier, deno_fmt         Lua                    stylua                     Rust                   rustfmt                    Go                     gofmt, goimports, gofumpt  Python                 black, isort               Terraform              terraform_fmt              Bash/Shell             shfmt                      YAML/JSON/Markdown     prettier                  Treesitter対応言語シンタックスハイライトとインデントはTreesitterで処理。vim, lua, vimdoc, html, css, markdown, markdown_inline, terraform, hcl, bash, python, rust, go, typescript, javascript, tsx, json, yaml, toml2024年版からの主な変更点追加されたプラグイン・機能Snacks.nvim: folke氏の新しいユーティリティセット。LazyGit統合、高速ピッカー、バッファ管理などoil.nvim: NvimTreeに代わるファイルエクスプローラー。ディレクトリをバッファとして編集flash.nvim: EasyMotion系のモダンな代替。Treesitter対応Trouble.nvim: 診断情報の一覧表示diffview.nvim: Git Diffの可視化とコンフリクト解決overlook.nvim: 定義をフローティングでピークAvante.nvim: Cursor風のAI編集体験ClaudeCode: Claude Code CLIとのNeovim統合noice.nvim: コマンドラインとメッセージのモダン化which-key.nvim: キーバインドのヒント表示incline.nvim: ミニマルなファイル名表示modes.nvim: モードに応じたカーソルライン色変更vimade: 非アクティブウィンドウの薄暗化hbac.nvim: 未使用バッファの自動クローズ変更されたキーマッピングバッファ切り替え: <Tab>/<S-Tab> → <S-h>/<S-l>（より直感的）スクロール: 画面中央維持が追加検索: SnacksとTelescopeの二刀流にUI設計の変更ステータスラインを完全廃止（incline.nvim + modes.nvim で代替）タブラインを廃止（Snacks pickerで代替）コマンドラインをフローティング化（noice.nvim）なぜこれらのキーマッピングを覚える必要があるのか私の経験上、以下の機能は開発効率を大きく向上させてくれる。ファイル検索（Snacks/Telescope）プロジェクト内のファイルを素早く見つけられるコードベースの把握が容易になる<leader><leader>のスマートピッカーが特に便利LSP機能コードの定義や参照を素早く調べられるリファクタリングが楽になるコードの理解が深まるエラー診断が即座にわかるRustを書いていると1箇所書き換えると芋づる式に修正が発生する。コンパイラに叱られ、LSPに導かれ、最終的には正しいコードにたどり着く。自分で考えているのか、ツールに考えさせられているのか、もはやわからないGit統合（LazyGit + Diffview）エディタを離れずにすべてのGit操作ができるコンフリクト解決が視覚的でわかりやすい<leader>ggでLazyGitを開けば、ステージ、コミット、プッシュ、ブランチ操作など全部できるAI統合コードの説明、レビュー、修正をエディタ内で完結CopilotChatでClaude Sonnetが使える時代Avanteでカーソル位置に応じたAI編集高速移動（flash.nvim）画面内のどこにでも2-3キーで移動できるマウスに手を伸ばす必要がなくなるなぜNvChadを選び続けているのか2024年版でも書いたが、NvChadを選んだ理由は開発体制の健全さだった。その判断は2026年になっても変わっていない。毎年のように「今年こそAstroNvimとかに移行する」と思うが、結局設定を移行する時間で正月休みが終わる。NvChad v3.0以降、設定の構造がより洗練された。lua/plugins/ディレクトリに機能ごとにプラグインをまとめる方式は、設定の見通しを良くしてくれる。私の設定では以下のように分割している:ui.lua: 見た目関連（incline, modes, noice, notify）navigation.lua: 移動・検索（snacks, telescope, oil, flash）git.lua: Git統合（gitsigns, diffview）diagnostics.lua: 診断（trouble, todo-comments）lsp.lua: LSPとフォーマッタ（conform, lspconfig, mason, treesitter）ai.lua: AI統合（copilot, copilot-chat, avante, claudecode）completion.lua: 補完（nvim-cmp）lang.lua: 言語固有（rustaceanvim, crates）この構造のおかげで、何か問題があった時にどこを見ればいいかすぐわかる。nvchad.comVimを学ぶために通常のVimを学ぶ時は、「実践Vim 思考のスピードで編集しよう！」がおすすめだ。Vimの基本から応用までを体系的に学べ、実践的な例も豊富に掲載されている。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazonまた、Vim Adventuresというゲームも面白い。ゲーム感覚でVimのキー操作を学べ、楽しみながら基本的なコマンドが身につく。初心者にも優しい学習カーブで、Vimの世界に入るきっかけとして最適だ。vim-adventures.comおわりにこの文章を書き終えて、ふと時計に目をやると、針は深夜一時を回っていた。年末にやるはずだった開発環境の整理を、結局、一月三日の深夜に敢行しているのである。休めていない。そんなことは百も承知である。正直に告白すれば、この文章を書いている最中にも、私は何度か「あれ、このキーは何だったか」と己の設定ファイルを参照せざるを得なかった。自分のための備忘録を執筆しながら、その備忘録を必要としている。なんという滑稽な光景であろうか。笑えない。いや、笑うしかないのかもしれない。来年の今頃、私は間違いなくこの記事を読み返しているであろう。「そうだ、<leader><leader>でスマートピッカーが開くのであった」と膝を打ち、束の間の安堵を覚える。そしてまた忘れる。おそらく、その繰り返しなのである。人間とは、かくも愚かな生き物なのだ。しかしながら、少しだけ異なることもある。毎年毎年、同じことを馬鹿の一つ覚えのように繰り返しているうちに、いつの間にか身体が記憶している操作というものが存在するのだ。gdで定義へ跳躍すること。<C-s>で保存すること。意識せずとも指が勝手に動く。それは、忘却と想起を幾度となく繰り返した果てに、ようやく獲得した境地なのである。エディタの設定に正解などない。完璧なキーマッピングも存在しない。ただ、自分が少しでも快適に作業できる環境を、毎年少しずつ更新していくのみである。それでよいのだ。それ以上を望むのは、人間の分際で天に唾するようなものである。さて、私はソファの深淵から這い上がることにする。正月休みはまだ幾ばくか残されている。しかし、仕事が始まれば、またすぐに「あのキーは何だったか」と途方に暮れる瞬間が訪れるに違いない。その時のために、この記事は存在するのである。来年の自分へ。また忘れたら読み返すがよい。どうせ忘れるのだから。参考リンクnvchad.comgithub.comneovim.io]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[テスト,検証してますか: cargo-mutantsによるミューテーションテスト入門]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735</guid>
            <pubDate>Thu, 01 Jan 2026 23:37:35 GMT</pubDate>
            <content:encoded><![CDATA[はじめにテストは全部通っている。コードカバレッジも90%を超えている。なのに、本番環境でバグが見つかった。私が実際に経験したことだ。原因を調べると、テストコードにassert（検証）が書かれていなかった。テストは「コードを実行しただけ」で、結果が正しいかどうかを確認していなかったのだ。正直、恥ずかしかった。テストを書いている気になっていただけで、何も守っていなかった。こういう経験はないだろうか。あるいは、レビューで「このテスト、意味ありますか」と指摘されたことは。この記事では、こうした「見せかけのテスト」を発見するミューテーションテストという手法と、Rust向けのツールcargo-mutantsを紹介します。公式ドキュメントを参照する場合は、以下のリンクからどうぞ。mutants.rsgithub.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。ミューテーションテストとはミューテーションテストは、「テストをテストする」手法です。具体的なコードで説明しましょう。例：割引価格を計算する関数以下のような、商品価格から10%割引した金額を返す関数があるとします。/// 価格から10%割引した金額を返すfn apply_discount(price: u32) -> u32 {    price - (price / 10)}この関数に対して、以下のテストを書きました。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    // 1000円の10%引きは900円のはず...    // でも、assertを書き忘れた！}このテストには問題があります。apply_discount(1000)を呼び出していますが、結果が900であることを検証していません。コードカバレッジは100%ですが、このテストは何も守っていないのです。ミュータント（突然変異体）の生成ミューテーションテストでは、コードに「わざとバグを入れた」バージョンを作ります。これをミュータント（突然変異体）と呼びます。apply_discount関数に対して、以下のようなミュータントが生成されます。// ミュータント1: 引き算を足し算に変えるfn apply_discount(price: u32) -> u32 {    price + (price / 10)  // - を + に変更}// ミュータント2: 常に0を返すfn apply_discount(price: u32) -> u32 {    0  // 関数の本体を0に置き換え}// ミュータント3: 入力をそのまま返すfn apply_discount(price: u32) -> u32 {    price  // 割引計算を削除}テストがミュータントを検出できるか各ミュータントに対してテストを実行します。 ミュータント   変更内容     テスト結果               判定           ミュータント1  - → +    ✅ 成功（テストが通る）  ❌ missed  ミュータント2  常に0を返す  ✅ 成功（テストが通る）  ❌ missed  ミュータント3  割引なし     ✅ 成功（テストが通る）  ❌ missed すべてのミュータントがテストを通過してしまいました。これはテストが何も検証していないことの証拠です。テストを修正するテストにassert_eq!を追加して、結果を検証するようにします。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    assert_eq!(result, 900);  // 結果が900であることを検証}修正後、再度ミュータントをテストします。 ミュータント   変更内容     テスト結果             判定           ミュータント1  - → +    ❌ 失敗（1100 ≠ 900）  ✅ caught  ミュータント2  常に0を返す  ❌ 失敗（0 ≠ 900）     ✅ caught  ミュータント3  割引なし     ❌ 失敗（1000 ≠ 900）  ✅ caught すべてのミュータントが検出されました。これで「テストが正しく機能している」ことが確認できました。ミューテーションテストの核心ここまでの例で分かるように、ミューテーションテストは以下の逆説に基づいています。テストの成功が、失敗の証拠になる。コードを壊したのにテストが通るなら、そのテストは壊れたコードを見逃している——つまり、テストとして機能していません。cargo-mutantsとはcargo-mutantsは、Rust向けのミューテーションテストツールです。上記のような「ミュータントの生成」「テストの実行」「結果の集計」を自動で行います。Rustを使っている開発者なら、cargo install cargo-mutants && cargo mutantsの2コマンドで即座に試せます。ソースコードの変更は一切不要です。Rustを使っていない方も、「テストの品質をどう測るか」という観点でお読みいただければ、他の言語にも応用できる考え方が得られるはずです。いつ導入すべきかミューテーションテストは誰でも試せますが、すべてのプロジェクトに必要なわけではありません。正直に言えば、導入コストは低くない。特に有効なのは、カバレッジは80%以上あるのにバグが減らないケースです。金融計算のように正確性が重要なビジネスロジックや、チームにテストの質を意識させたい場面でも効果を発揮します。私自身、冒頭で触れた経験をした後、まずこのツールで「テストが本当に機能しているか」を確認するようになりました。一方、まだカバレッジが50%未満のプロジェクトでは、まずカバレッジを上げる方が効果的です。プロトタイプ段階で変更が激しい場合や、テスト実行時間がすでに長すぎる場合も、ミューテーションテストの優先度は下がります。ツールが問題を解決してくれるわけではない。テストを書くのは人間です。クイックスタートインストール# 推奨: cargoで直接インストールcargo install --locked cargo-mutants# 高速インストール（プリビルドバイナリ使用）cargo binstall cargo-mutants基本的な使い方# ミュータント一覧を確認（テストは実行しない）cargo mutants --list# ミューテーションテストを実行cargo mutants# 詳細出力で実行cargo mutants -v実行例実際にサンプルプロジェクトで実行した結果を示します。$ cargo mutants --list | head -20src/lib.rs:12:5: replace calculate_score -> i32 with 0src/lib.rs:12:5: replace calculate_score -> i32 with 1src/lib.rs:12:5: replace calculate_score -> i32 with -1src/lib.rs:32:5: replace is_valid_email -> bool with truesrc/lib.rs:32:5: replace is_valid_email -> bool with falsesrc/lib.rs:37:5: replace format_greeting -> String with String::new()src/lib.rs:37:5: replace format_greeting -> String with "xyzzy".into()src/lib.rs:42:5: replace find_first_even -> Option<i32> with Nonesrc/lib.rs:42:5: replace find_first_even -> Option<i32> with Some(0)src/lib.rs:47:5: replace parse_positive_number -> Result<u32, String> with Ok(0)src/lib.rs:57:5: replace get_even_numbers -> Vec<i32> with vec![]...実行すると、各ミュータントに対してテストが実行され、結果が表示されます。$ cargo mutants -vFound 108 mutants to testok       Unmutated baseline in 1s build + 1s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 0 in 0s build + 0s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 1 in 0s build + 0s testMISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discount in 0s build + 1s test...108 mutants tested in 2m: 17 missed, 91 caught出力結果の読み方結果の4分類 結果          意味                                    アクション                  caught    テストがミュータントを検出した          良好。テストが機能している  missed    テストがミュータントを検出できなかった  テストの追加・強化が必要    unviable  ミュータントがコンパイルできなかった    無視してOK                  timeout   テストがタイムアウトした                無限ループの可能性あり     出力ディレクトリ（mutants.out/）実行後に生成されるmutants.out/ディレクトリには、詳細な結果が保存されます。mutants.out/├── caught.txt      # 検出されたミュータント一覧├── missed.txt      # 検出できなかったミュータント一覧├── timeout.txt     # タイムアウトしたミュータント├── unviable.txt    # コンパイル不可だったミュータント├── outcomes.json   # 全結果のJSON形式├── log/            # 各ミュータントの詳細ログ└── diff/           # 適用されたパッチミューテーションテストの仕組みミューテーションテストは1970年代に考案された手法ですが、計算コストの高さから長らく実用的ではありませんでした。近年のコンピュータ性能向上により、ようやく日常的に使えるようになってきました。cargo-mutantsの動作フローcargo-mutantsは以下の手順で動作します。ソースファイルの特定: プロジェクト構成を読み取り、テスト対象のファイルを見つけるコードの解析: synというライブラリ（Rustでは「クレート」と呼びます）を使って、コードの構造を解析するミュータントの生成: 「足し算を引き算に変える」「戻り値を0に変える」といった変更パターンを列挙するテストの実行: 各ミュータントに対してテストを実行し、検出できたかどうかを記録する具体例：検証していないテストコードカバレッジとミューテーションテストの違いを、具体例で見てみましょう。// 2つの数を足し算する関数fn add(a: i32, b: i32) -> i32 {    a + b}// テストコード#[test]fn test_add() {    add(1, 2);  // 関数を呼んでいるだけ！結果を検証していない！}このテストはadd関数を実行しているので、コードカバレッジは100%です。しかし、戻り値が正しいかどうかを確認していません。add(1, 2)の結果が3であることを検証していないのです。正しいテストは以下のようになります。#[test]fn test_add_correct() {    let result = add(1, 2);    assert_eq!(result, 3);  // 結果が3であることを検証している}assert_eq!は「左辺と右辺が等しいことを確認する」という意味です。等しくなければテストは失敗します。cargo-mutantsは、最初の「検証していないテスト」の問題を発見できます。a + bをa - bに変更しても、最初のテストは成功してしまいます（結果を見ていないから）。これにより「このテストは意味がない」ということが明らかになります。戻り値の型別ミューテーションcargo-mutantsは、関数の戻り値の型に応じて異なるミューテーションを生成します。「型」とは何でしょうか。プログラミングにおいて、データには種類があります。「整数」「文字列」「真偽値（はい/いいえ）」などです。Rustはこの種類を厳密に区別する言語で、「この関数は整数を返す」「この関数は文字列を返す」といった宣言が必要です。cargo-mutantsは、この「返す型」に応じて、適切なミュータントを生成します。以下、Rustを知らない方にも理解できるよう、各型の意味と合わせて説明します。bool型（真偽値）bool型とは: true（真）かfalse（偽）のどちらかを表す型です。条件分岐の判定などに使われます。/// メールアドレスが有効かどうかを判定するfn is_valid_email(email: &str) -> bool {    email.contains('@') && email.contains('.')}生成されるミューテーション:replace is_valid_email -> bool with true - 常にtrueを返すreplace is_valid_email -> bool with false - 常にfalseを返すテストで検出すべきこと: 有効なメールと無効なメールの両方をテストして、両方のケースが正しく判定されることを確認する必要があります。i32型（符号付き整数）i32型とは: -2,147,483,648から2,147,483,647までの整数を表す型です。負の数も扱えます。/// スコアを計算する（1=合格、0=普通、-1=不合格）fn calculate_score(correct: u32, total: u32) -> i32 {    let percentage = (correct * 100) / total;    if percentage >= 80 { 1 }    else if percentage >= 50 { 0 }    else { -1 }}生成されるミューテーション:replace calculate_score -> i32 with 0 - 常に0を返すreplace calculate_score -> i32 with 1 - 常に1を返すreplace calculate_score -> i32 with -1 - 常に-1を返すテストで検出すべきこと: 各分岐（合格・普通・不合格）すべてのケースをテストする必要があります。String型（文字列）String型とは: 可変長のテキストデータを表す型です。ユーザー名やメッセージなどに使われます。/// 挨拶文を生成するfn format_greeting(name: &str) -> String {    format!("Hello, {}!", name)}生成されるミューテーション:replace format_greeting -> String with String::new() - 空文字列を返すreplace format_greeting -> String with "xyzzy".into() - 固定文字列「xyzzy」を返す（「xyzzy」はテスト用のダミー文字列としてよく使われる伝統的な文字列です）テストで検出すべきこと: 戻り値の内容を検証することが重要です。単に「何か文字列が返ってくる」だけでなく、期待する内容かどうかを確認します。Option\<T>型（値があるかないか）Option型とは: 値が「ある」か「ない」かを表す型です。Some(値)で値があることを、Noneで値がないことを表します。なぜこの表現を使うのか。多くの言語では「値がない」ことをnullで表しますが、null処理を忘れてエラーになることがよくあります。Rustでは「値がないかもしれない」ことを型で明示し、処理を強制します。これにより、nullに起因するバグを防ぎます。検索結果が見つからない場合などによく使われます。/// 最初の偶数を見つけるfn find_first_even(numbers: &[i32]) -> Option<i32> {    numbers.iter().find(|&&n| n % 2 == 0).copied()}生成されるミューテーション:replace find_first_even -> Option<i32> with None - 常に「見つからない」を返すreplace find_first_even -> Option<i32> with Some(0) - 常に「0が見つかった」を返すreplace find_first_even -> Option<i32> with Some(1) - 常に「1が見つかった」を返すテストで検出すべきこと: 「見つかる場合」と「見つからない場合」の両方をテストし、見つかった場合は正しい値が返されていることを確認します。Result\<T, E>型（成功か失敗か）Result型とは: 処理が「成功」したか「失敗」したかを表す型です。Ok(値)で成功を、Err(エラー)で失敗を表します。ファイル操作やネットワーク通信など、失敗する可能性のある処理に使われます。/// 正の数をパースするfn parse_positive_number(s: &str) -> Result<u32, String> {    let n: i32 = s.parse().map_err(|_| "invalid number".to_string())?;    if n > 0 {        Ok(n as u32)    } else {        Err("number must be positive".to_string())    }}生成されるミューテーション:replace parse_positive_number -> Result<u32, String> with Ok(0) - 常に「成功（0）」を返すreplace parse_positive_number -> Result<u32, String> with Ok(1) - 常に「成功（1）」を返すテストで検出すべきこと: 成功ケースと失敗ケースの両方をテストします。特にエラーハンドリングのテストを忘れがちなので注意が必要です。Vec\<T>型（配列・リスト）Vec型とは: 同じ型の値を複数格納できる可変長の配列です。リストやコレクションを扱う場合に使われます。/// 偶数だけを抽出するfn get_even_numbers(numbers: &[i32]) -> Vec<i32> {    numbers.iter().filter(|&&n| n % 2 == 0).copied().collect()}生成されるミューテーション:replace get_even_numbers -> Vec<i32> with vec![] - 空の配列を返すreplace get_even_numbers -> Vec<i32> with vec![0] - 要素1つの配列を返すreplace get_even_numbers -> Vec<i32> with vec![1] - 要素1つの配列を返すテストで検出すべきこと: 返される配列の要素数と内容の両方を検証します。空配列が返されるケースもテストすることが重要です。演算子のミューテーションcargo-mutantsは、演算子を別の演算子に置き換えるミューテーションも生成します。比較演算子== ↔ !=    等しい ↔ 等しくない<  ↔ >     小さい ↔ 大きい<= ↔ >=    以下 ↔ 以上論理演算子&& ↔ ||    かつ ↔ または算術演算子+ ↔ - ↔ *    足し算 ↔ 引き算 ↔ 掛け算/ ↔ %        割り算 ↔ 余り単項演算子-a → a    符号反転を削除!a → a    論理否定を削除テスト不足の発見例実際にサンプルプロジェクトで検出された「missed」（テストで検出できなかったミュータント）を見てみましょう。MISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discountMISSED   src/lib.rs:156:9: delete match arm 2 in calculate_discountMISSED   src/lib.rs:155:20: replace - with + in calculate_discount...これは以下のコードに対するミューテーションです。fn calculate_discount(price: u32, member_level: u32) -> u32 {    match member_level {        0 => price,                     // 割引なし        1 => price - (price / 10),     // 10% 割引        2 => price - (price / 5),      // 20% 割引        _ => price - (price / 4),      // 25% 割引    }}#[test]fn test_calculate_discount_weak() {    // member_level 0 のみテスト → 他のケースの変異を検出できない！    assert_eq!(calculate_discount(100, 0), 100);}テストがmember_level = 0のケースしかカバーしていないため、他のケース（1, 2, _）のミューテーションは検出できませんでした。これを修正するには、すべてのケースをテストする必要があります。#[test]fn test_calculate_discount_comprehensive() {    assert_eq!(calculate_discount(100, 0), 100);  // 割引なし    assert_eq!(calculate_discount(100, 1), 90);   // 10% 割引    assert_eq!(calculate_discount(100, 2), 80);   // 20% 割引    assert_eq!(calculate_discount(100, 3), 75);   // 25% 割引}設定とカスタマイズコマンドラインオプション# ファイル指定cargo mutants -f src/core.rs -f src/utils.rs# ファイル除外cargo mutants -e src/generated/*.rs# 正規表現でフィルタcargo mutants --re "impl Serialize" --exclude-re "impl Debug"# 並列実行（2-3から開始推奨）cargo mutants -j2# nextestを使用cargo mutants --test-tool=nextest# タイムアウト設定cargo mutants --timeout 300cargo mutants --timeout-multiplier 3設定ファイル（.cargo/mutants.toml）プロジェクト固有の設定を永続化できます。# .cargo/mutants.tomltest_tool = "nextest"jobs = 2timeout_multiplier = 3.0exclude_globs = ["src/generated/*.rs"]exclude_re = ["impl Debug", "impl Display"]additional_cargo_test_args = ["--all-targets"]関数単位の除外（#[mutants::skip]）特定の関数をミューテーション対象から除外できます。// Cargo.tomlに追加: mutants = "0.0.3"#[mutants::skip]  // この関数はミューテーション対象外fn should_stop() -> bool {    true  // falseに変異するとハングする}自動除外される関数以下は自動的にミューテーション対象から除外されます。#[test]属性が付いた関数#[cfg(test)]内のコードnew関数とDefault実装CI/CDパイプラインへの統合GitHub Actions基本設定name: Mutation Testingon: [push, pull_request]jobs:  cargo-mutants:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: taiki-e/install-action@v2        with:          tool: cargo-mutants      - run: cargo mutants -vV --in-place      - uses: actions/upload-artifact@v4        if: always()        with:          name: mutants-out          path: mutants.outプルリクエストでの増分テスト変更されたコードのみをテストし、高速なフィードバックを実現します。- name: Generate diff  run: git diff origin/${{ github.base_ref }}.. | tee git.diff- run: cargo mutants --no-shuffle -vV --in-diff git.diffシャーディングによる分散実行大規模プロジェクトでは、複数のジョブに分割して並列実行できます。strategy:  matrix:    shard: [0, 1, 2, 3, 4, 5, 6, 7]steps:  - run: cargo mutants --shard ${{ matrix.shard }}/8 --baseline=skip --timeout 300パフォーマンス最適化ミューテーションテストは「ミュータント数 × テスト実行時間」のコストがかかります。100個のミュータントがあり、テストに1秒かかるなら、最低でも100秒かかる計算です。実際のプロジェクトでは数百〜数千のミュータントが生成されることもあり、実行時間が課題になります。テストスイートが1分以内のプロジェクトなら、数百ミュータントでも10-20分で完了します。CIで毎回実行するのは現実的でないので、増分テスト（--in-diff）で変更されたコードのみをテストし、フルテストを週次やリリース前に限定するのが実践的です。以下の最適化も効果的です。高速リンカーの使用「リンカー」とは、コンパイルされたコードを実行可能なプログラムにまとめるツールです。プログラムを作る最終段階で使われます。デフォルトのリンカーは汎用的ですが、高速化に特化したリンカーを使うとビルド時間を短縮できます。Moldリンカーで約20%の改善、Wildリンカーでは半分以下の時間になる場合もあります。専用Cargoプロファイル[profile.mutants]inherits = "test"debug = "none"並列実行の設定-j2から開始して、リソース監視しながら調整します。高すぎる値はメモリ枯渇の原因になります。RAMディスクの活用TMPDIR=/ram cargo mutants制限事項副作用のあるコードcargo-mutantsは機械生成された変更でコードをビルド・実行するため、ファイル操作や外部システムへ接続するテストでは予期しない動作を引き起こす可能性があります。フレーキーテスト「フレーキーテスト」とは、同じコードに対して実行するたびに結果が変わる不安定なテストのことです。たとえば、現在時刻に依存するテストや、外部サービスに依存するテストがこれに該当します。ミューテーションテストは「テストが失敗したか」を判定基準にするため、フレーキーテストがあると正確な結果が得られません。まずはcargo testで確実にパスする安定したテストスイートを用意してから実行してください。サポートされていないケース 制限事項            詳細                                       Cargo専用           Bazel等の他ビルドシステムは未対応          条件付きコンパイル  #[cfg(target_os = "linux")]を理解しない  マクロ生成コード    生成されたコードは変異対象外              等価ミュータントミューテーションテストには理論的な限界があります。それが「等価ミュータント」です。たとえば、x * 1をxに変えても動作は同じです。このミュータントは検出不可能ですが、missedとしてカウントされます。また、ログ出力やデバッグ用の関数を変更しても、テストが失敗しないのは正しい動作です。だから、missed率0%は現実的な目標ではない。80-90%の検出率で十分です。残りをコードレビューや手動テストで補完します。検出できないミュータントを#[mutants::skip]で除外すれば、ノイズを減らせます。まとめテストは通っていた。でも、何も守っていなかった。冒頭で触れた私の失敗は「テストが結果を検証していない」ことが原因でした。cargo-mutantsは、こうした「見せかけのテスト」を発見するツールです。あの経験がなければ、この記事を書くこともなかったでしょう。syu-m-5151.hatenablog.comミューテーションテストの価値コードカバレッジは「テストがコードを実行したか」を測りますが、「テストが正しく検証しているか」は測れません。ミューテーションテストは「テストをテストする」手法です。わざとコードを壊して、テストがそれを検出できるかを確認します。cargo-mutantsは、Rustのミューテーションテストを「誰でもすぐに試せる」ものにしたツールです。2コマンドで導入でき、ソースコードの変更は不要です。特に有効なユースケース高いコードカバレッジを達成した後の「テストは本当に機能しているか」確認CI（継続的インテグレーション）でのプルリクエストごとの増分ミューテーションテスト重要なビジネスロジックのテストギャップ発見導入のポイントcargo mutants --listでミュータント数を確認--shard 1/100で試験実行（大規模プロジェクトでは一部だけ先に試す）#[mutants::skip]と設定ファイルで偽陽性を減らすMoldリンカーと専用プロファイルでパフォーマンス最適化他の言語でのミューテーションテストこの記事ではRust用のcargo-mutantsを紹介しましたが、ミューテーションテストの考え方は言語を問わず有効です。他の言語にも同様のツールがあります。JavaScript/TypeScript: StrykerJava: PITestPython: mutmut, cosmic-rayGo: go-mutestingテストの品質を高めたいと考えている方は、ぜひお使いの言語のツールも調べてみてください。テストは通っている。でも、本当に守っているのか。ミューテーションテストは万能ではない。実行時間もかかるし、等価ミュータントの問題もある。それでも、「テストを書いた」という自己満足に気づかせてくれる。私があの日気づいたように。その問いを持ち続けることが、テストを意味のあるものにする第一歩だと思う。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazonソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社AmazonAIとソフトウェアテスト　信頼できるシステムを構築するために作者:Adam Leon Smith,Rex Black,James Harold Davenport,Joanna Olszewska,Jeremias Rößler,Jonathon WrightインプレスAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A2A での認証認可を理解する]]></title>
            <link>https://zenn.dev/satohjohn/articles/6e65b4be3f933a</link>
            <guid isPermaLink="false">https://zenn.dev/satohjohn/articles/6e65b4be3f933a</guid>
            <pubDate>Thu, 01 Jan 2026 17:00:25 GMT</pubDate>
            <content:encoded><![CDATA[概要Agent2Agent Protocol(以下A2A) は現在 Linux Foundation 傘下の AI Agent 同士のコミュニケーションを可能にする Open な Protocol です。https://github.com/a2aproject/A2Aざっくり言えば、AI Agent が外部で公開されていた際に、その AI Agent と自分が作成した AI Agent が協調して動くための仕様、例えば通信方法や要件などを決めたものです。A2A を使うと、マルチエージェントのような仕組みを作ろうとしたときに、様々な言語やフレームワーク、実行基盤で実装されてい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 個人的に心に残ったグラビアアイドル10選]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147</guid>
            <pubDate>Wed, 31 Dec 2025 17:21:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2025年12月31日の夜、パソコンの前でこの文章を書き始めている。Xのフォロワーが1万人を超えたとき、勢いで「おすすめのグラビアを紹介します」と言ってしまった。忙しさを言い訳にして先延ばしにしていたら、年末年始になってしまった。孤独な独身男性が大晦日に書くブログがこれでいいのか。言ってしまったからには書くしかない。普段は技術ブログを書いている。ソフトウェアエンジニアとして、コードの話や設計の話をするのが本分だ。私はグラビア評論家でもなければ、業界関係者でもない。あるのは、彼女たちの作品を見て感じた個人的な感想だけだ。素人の与太話である。合わない人はブラウザバックしてもらって構わない。2025年、生成AIが生成する画像のクオリティは日に日に上がった。「人間である必要があるのか」という問いが、あらゆる領域に突きつけられている。ソフトウェアエンジニアである私も、その問いと無縁ではいられない。AIがコードを書く。AIが画像を生成する。じゃあ私たちは何をすればいいのか。答えは出ていない。そんな中で、彼女たちは諦めていなかった。生成AIには「物語」がない。挫折も、転機も、覚悟もない。彼女たちには、積み重ねてきた時間と、これから歩む道がある。同志のようなものを感じた。この記事では、そうした「代替不可能な物語」を持つ10名を紹介したい。選考基準は単純だ。心に残ったかどうか。それだけである。紹介順に優劣はない。10名のグラビアアイドル紹介菊地姫奈彼女の眼差しには、刃物のような意志と、硝子細工のような脆さが同居している。その矛盾こそが、菊地姫奈という存在を比類なきものにしている。写真集『memory』は「5年間の集大成」と銘打たれた。五年という歳月を、彼女は一冊の書物に封じ込めた。いま彼女は、女優という新たな領域へと歩を進めている。グラビアで培った肉体の言語が、演技という別の器に注がれようとしている。「集大成」とは、すなわち終焉の美学である。散り際を知る者だけが、満開の美しさを手にする。2025年、私はその花吹雪を目撃した。豊島心桜「グラビア界最強のラスボス」。この異名を耳にしたとき、私は失笑した。誇大な修辞だと高を括った。しかし彼女のグラビアを一瞥した瞬間、その異名が寸分の誇張も含まぬことを悟った。遅れて現れた者には、待たせた分だけの凄みがある。クラシックバレエで鍛えられた四肢は、舞台を離れてなお優雅な弧を描く。その肉体には規律が宿っている。女優としての道も拓きつつある彼女は、どの領域においても王者の風格を崩さぬだろう。ラスボスとは、最後に立ちはだかる者のことだ。私などは、まだその城門にすら辿り着いていない。麻倉瑞季麻倉瑞季において、知性と肉体は対立せず、むしろ共犯関係にある。豊満な曲線を誇示したかと思えば、次の瞬間には電子の戦場で剣を振るう。大学への合格、eスポーツチームへの加入。彼女はグラビアアイドルという一つの器に収まることを拒んだ。「推しのために仕事をしている」と彼女は言う。その言葉には一片の虚飾もない。欲望に忠実であることは、ときに最も誠実な生き方となる。天羽希純天羽希純との邂逅は、アイドルグループ「#2i2」を通じてであった。しかし彼女のソログラビアを目にしたとき、アイドルという名の檻では、この獣を囲い込めぬことを知った。彼女は自らを「モンスター」と称する。「アイドル界のモンスター」なるエッセイを連載し、2025年の目標を「エゴイスティックに」と宣言した。怪物とは、既存の秩序に収まらぬ者のことだ。その自覚こそが、彼女の覚悟である。「#2i2」は2025年12月に解散した。終焉へと向かう船上で、彼女はなお踊り続けた。滅びゆくものだけが放つ光がある。私はその残照に灼かれた。一ノ瀬瑠菜2007年生まれ。この事実を知ったとき、私は時の流れの残酷さを思い知った。2025年春、高校を卒業した彼女は、グラビア誌の表紙を次々と征服した。女優としての活動も始まっている。十八歳にしてこの疾走。若さとは、無限の可能性という名の空白である。まだ何者でもない。ゆえに何者にもなれる。その特権を、彼女は惜しげもなく行使している。翻って私は、何者かになれたのだろうか。その問いに答える勇気を、私はまだ持たない。溝端葵「グラビア界の超新星」。2025年、この称号を戴くに最もふさわしき者が溝端葵であった。TikTokでの舞踊が衆目を集め、スカウトの手が伸びた。2025年3月にグラビアの世界へ足を踏み入れ、わずか三ヶ月で表紙を飾るという離れ業を演じた。彗星の如き上昇である。しかし彼女には前史がある。中学三年時、「ミスセブンティーン」の最終選考に残りながら、栄冠を逃した。約十年の歳月を経て、彼女は別の扉を開いた。一度は閉ざされた道の傍らに、もう一つの道が拓けていた。迂回こそが、ときに最短距離となる。そのような物語に、私は抗えない。七瀬なな七瀬ななという存在には、終焉と黎明が同時に宿っている。レースクイーンとして頂点を極めた彼女は、2024年末にその王座を捨てた。そして2025年、女優という未踏の地へと歩み出した。デジタル写真集のタイトルは「HORIZON」。地平線とは、見えているのに決して辿り着けぬ場所のことだ。しかし彼女は、その不可能に向かって歩を進める。幼少期に習得した器械体操を武器に、アクション女優を志すという。一つの頂を極めた者だけが、別の頂への渇望を知る。終わらせる勇気を持つ者だけが、始める資格を得る。花雨「一般OL/趣味グラビア」。花雨のInstagramにはそう記されている。本業は会社員。グラビアは余技に過ぎぬ。しかしその余技に、十三万を超える眼差しが注がれている。趣味という言葉で片付けるには、あまりに多くの魂を捕らえている。彼女は自らの手で写真集を世に送り出す。五島列島の福江島で撮影された「夕星」、沖縄で撮影された「漣」。「花雨屋」なる店舗で販売されるこれらは、いかなる事務所の介在も経ぬ、純粋なる自己表現である。事務所に属さず、テレビに出ず、雑誌の表紙を飾らず。それでも彼女の作品は確かに人心を揺さぶる。職業と趣味の境界を、彼女は軽やかに踏み越える。好きだから撮る。撮りたいから撮る。その純粋さこそが、逆説的に彼女の武器となる。仕事にせぬから続けられる。仕事にしたら続けられぬ。私にも覚えがある。技術ブログを書き続けているのも、誰に頼まれたわけでもない。髙峰じゅり髙峰じゅりは、己がレズビアンであることを公言している。「十六歳で彼女を紹介したら、祖母が泣いた」と語る彼女の言葉には、幾重もの障壁を越えてきた者だけが持つ静かな強さがある。2025年、芸名を改め、新たな幕を開けた。友人と共に撮影会を興し、運営者としての貌も見せる。「グラビアは男性にしか届かぬものと思い込んでいた」と彼女は述懐する。しかし現実には、女性からの声も多く届くという。グラビアの受け手を限定せず、性を隠さず、己を偽らず。その姿勢が、従来の境界の外にいた者たちにも届いている。道を拓く者がいるから、後に続く者が歩みやすくなる。先駆者とは、常に孤独な存在である。もものすけもものすけという存在は、どこか神話的な響きを帯びている。彼女は自他ともに認める恐竜狂である。「ダイナソー」と「アイドル」を掛け合わせ「ダイナドル」の異名を持つ。グラビア、アイドル、声優。彼女の軌跡は複数の線が並走し、交錯し、ときに融合する。いずれが本業でいずれが余技か、そのような問い自体が無粋である。好むものを好むがままに追求した結果、幾つもの貌を持つに至った。2025年も彼女は止まることを知らなかった。太古の巨獣への愛を語り、信奉者と交わり、新たな地平を切り拓き続けている。「もも」が姓で「のすけ」が名であると、本人は主張している。私も「nw」が姓で「iizo」が名だ。そのような戯れを愛する心性において、私は彼女に親近を覚える。おわりに10名の物語を書き終えて、ふと思う。私は何を見ていたのだろうか。時計を見ると12時を超えていた。1月1日に何を書いているのだろう。グラビアアイドルほど自分の器とシビアに向き合っている存在はいない。年齢、体型、表現力、時代との相性。あらゆる要素が容赦なく評価される世界で、彼女たちは走り続けている。女優になりたい人がいる。声優になりたい人がいる。まだ何になりたいか決まっていない人もいる。グラビアは通過点であり、同時に今この瞬間でもある。完成された何かより、途中経過を見る方が心が動く。たぶん、私もまだ途中だからだ。生成AIがいくら精巧な画像を生成しても、そこに物語はない。挫折も、葛藤も、成長もない。彼女たちが持っているのは、代替不可能な身体と、積み重ねてきた時間と、これから歩む道だ。私も同じだ。AIがコードを書く。私もコードを書く。違いは何か。まだわからない。でも、諦めずに問い続ける人たちを見ていると、自分も諦めなくていいと思える。冒頭で「フォロワー1万人を超えた勢いで言ってしまった」と書いた。結局、年末年始に孤独な独身男性がパソコンに向かって書いている。遅れたけど、約束は守った。彼女たちにも物語があるように、私にも物語がある。技術ブログを書き、コードを書き、たまにグラビアの話をする。そういう人間として見届けてくれる人がいる。心に残ったものを素直に書いた。それでいい。2026年、彼女たちの物語は続く。私の物語も、まだ終わっていない。関連する投稿も置いておく。グラビア写真集といえば単なる視覚的刺激として消費されがちだが、そこには各グラドルの努力や作品性、女優やタレントなどを目指しながら頑張る物語、時代ごとの表現の歴史がある。こうした背景や文脈を知るとより深く面白くなる。そんな作品性と物語性を兼ね備えた魅力的な写真集4冊を紹介します。— nwiizo (@nwiizo) 2025年11月12日]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年の振り返りをする]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2025/12/31/235646</link>
            <guid isPermaLink="false">https://nnaka2992.hatenablog.com/entry/2025/12/31/235646</guid>
            <pubDate>Wed, 31 Dec 2025 14:56:46 GMT</pubDate>
            <content:encoded><![CDATA[みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。アウトプットログ2025-1-24 3-shake SRE Tech Talk #11 オンサイト 新春OSSスペシャル 登壇2025年の外部発信はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。CloudNativePGがCNCF Sandboxプロジェクトになったぞ！ 〜CloudNativePGの仕組みの紹介〜https://speakerdeck.com/nnaka2992/cloudnativepggacncf-sandboxpuroziekutoninatutazo-cloudnativepgnoshi-zu-minoshao-jieOSSスペシャルということでPostgreSQL関連のツールとして初めてCNCFプロジェクトに認定されたCloudNativePGがどのように動作しているかを掘り下げました。今年もですがここ数年は毎年、年末のセールにProxmox VM用ミニPCを購入してお家Kubernetesのセットアップをすることがルーティーンになりつつあります。そのため毎年12月から翌年4月ごろまで、DB on Kubernetesのモチベーションが高くなります。この登壇もその影響のひとつで3月ごろの登壇まではCloud Native PGに関するブログが続きました。2025-02-19 Jagu'e'r Cloud Native #17 ハイブリッド Meetup 登壇続くアウトプットも年末から続く個人的CloudNativePGブームに影響されたものです。Google Cloud関連のコミュニティであるJagu'e'rのCloud Native分科会が主催のというイベントでの登壇です。CloudNativePGを布教したい~敵「なぜCloud SQLがあるのにKubernetesでPostgreSQLをホストするのか？」~https://speakerdeck.com/nnaka2992/cloudnativepgwobu-jiao-sitaiテーマは「推しの CNCF プロジェクトを紹介するぜ LT」と言うことで当然のごとく、CloudNativePGの話をしました。CloudNativePGの特徴とデプロイ方法をともに、マネージドデータベースではなくなぜセルフホストするデータベースを選ぶのかを言及しました。2025-02-20 Kubernetes Novice Tokyo #36 登壇Jagu'e'r Cloud Native #17 ハイブリッド Meetupから開けて翌日の登壇でした。同僚の@bells17_さんが運営に参加するイベントです。データベースのオペレーターであるCloudNativePGがStatefulSetを使わない理由に迫るhttps://speakerdeck.com/nnaka2992/detabesunooperetadearucloudnativepggastatefulsetwoshi-wanaili-you-nipo-ru2025年前半は1か月1.5回という異常な登壇モチベーションがあったため、脊髄反射で登壇申し込みをした結果、連日の登壇になり自分の首を締めた記憶がつよいです。発表内容としてはStatefulSetという便利なKubernetesリソースがあるにも関わらず、なぜCRDでPodとPVCを管理するのかについて解説しました。2025-03-09 Jagu'e'r オブザーバビリティ分科会 Meetup#1 登壇Google Cloud関連のコミュニティであるJagu'e'rのオブザーバビリティ分科会が主催のというイベントでの登壇です。Google Cloudとo11yで実現するアプリケーション開発者主体のDB改善https://speakerdeck.com/nnaka2992/google-cloudtoo11ydeshi-xian-suruapurikesiyonkai-fa-zhe-zhu-ti-nodbgai-shanCloud SQL x Cloud Trace x OpenTelemetryという軸でアプリケーションのパフォーマンスをデータベースと透過的に見ましょうというはなしをしました。始めてでDBREについて登壇してから一環してデータベースエンジニアの手からデータベースを話し、アプリケーションエンジニアがデータベースエンジニアと同じ程度にデータベースへのモチベーションをもってほしいという気持ちがあらわれた登壇した。2025-03-11 Google CloudのTerraform職人が失職する機能が出てしまった…… ブログ2025年の数少ないブログ投稿の一つです。Google CloudでIaCをGUIで手軽に管理するためのツールの紹介をしたブログです。現時点ではまだまだ自分の方が上手くIaCでGoogle Cloudを管理できると自身を持っていえるものの、昨今発展の目覚ましい生成AIがこの機能に本格的に統合されたら飯の食い扶持が一つ減ってしまうと危機感を覚えます。2025-03-27 第52回 PostgreSQLアンカンファレンス@オンライン 登壇JPUGが主催するアンカンファレンスでの登壇です。データベースエンジニアの仕事を楽にする。PgAssistantの紹介https://speakerdeck.com/nnaka2992/tetahesuensinianoshi-shi-wole-nisuru-pgassistantnoshao-jie生成AIというものが本格的に使えるかも？ という世間の雰囲気にあてられて調査したツールでした。PgAssitsantというWebベースのツールを通して、PostgreSQLの調査に必要なデータを収集し、必要に応じて生成AIで分析を行うというツールです。はてブか何かに「楽にするではなく、奪うでは？ 」というコメントがあり、この程度で奪われたらもっと楽に仕事できているわと思った記憶があります。2025-04-17 Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ ブログ自社ブログでのアウトプットです。2025年のGoogle Cloud Partner Top Engineerとして2025年4月にラスベガスで開催されたGoogle Cloud Next 2025で発表されたデータベース関連のリリースをまとめて紹介したブログです。個人としても始めての海外カンファレンスの参加で、非常にモチベートされた記憶があります。2025-04-24 Next × Jagu'e'r アフターイベント「Next 2025 Big Thing」 登壇上記と同様にGoogle Cloud Next 2025のアウトプットの一つで、Jagu'e'rが主催するイベントのアフターイベントです。Google Cloud Next 2025 DM Recap ～DM領域PTEが贈る注目リリース～https://speakerdeck.com/nnaka2992/google-cloud-next-2025-dm-recap-dmling-yu-ptegazeng-ruzhu-mu-ririsuデータベース領域のGoogle Cloud Partner Top Engineerからの注目リリースを紹介しました。2025-05-14 【技術選定を突き詰める】Online Conferenc​​e 2025 登壇Findyが開催する技術選定を突き詰めるというテーマのカンファレンスの公募LT枠での登壇です。データベースの技術選定を突き詰める ～複数事例から考える最適なデータベースの選び方～https://speakerdeck.com/nnaka2992/detabesunoji-shu-xuan-ding-wotu-kijie-meru-fu-shu-shi-li-karakao-eruzui-shi-nadetabesunoxuan-bifangデータベースをどう選ぶか？ さまざまな要求があるときに、本当にその要求は必要なのか？ を問いかけ、難易度があがりやすい制約を外すことで、よりシンプルで現実的な選択肢を選ぼうという内容です。2025-05-22 JPOUG Tech Talk Night #13 登壇JPOUGが主催するテックトークイベントでの登壇です。ついに国内でも使えるようになる！～Oracle Database@Google Cloudの紹介～https://speakerdeck.com/nnaka2992/tuiniguo-nei-demoshi-eruyouninaru-oracle-database-at-google-cloudnoshao-jieGoogle Cloud Next 2025で日本のリージョンでOracle Database@Google Cloudが利用できるようになるというアナウンスにモチベートされた内容でした。Oracle Cloud InfrastructureやAWSではなく、なぜGoogle CloudでOracle Databaseがつかえることが魅力的なのかというテーマを主題でした。2025-06-06 Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ ブログ自社ブログでのアウトプットです。Oracle Database@Google Cloudとはどのようなサービスなのか？ から始め、実際にどのようにデプロイできるのかを手順書チックに紹介したブログです。2025-06-30 Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする ブログ自社ブログでのアウトプットです。Gemini Code Assist for GitHubを利用することでPrisma ORMのデータモデリングをレビューする知見についてまとめたブログです。いまではGoogleはGemini CLIにのりかえてしまったようで残念ですが、このブログで紹介した内容はほとんどの生成AIツールに応用可能です。2025-08-06 Google Cloud Next Tokyo 2025のパートナーブースで登壇資料としては公開していませんが、Google Cloud Next Tokyo 2025の自社ブースにて、Gemini Code Assistを利用したデータベーススキーマのPRレビューについて紹介しました。上記ブログのPrismaという軸から一般的なデータベーススキーマに焦点をひろげて紹介しました。2025-10-31 月末 Tech Lunch Online#6 - Google Cloud を語る！- 登壇2025年の登壇収めは非常にはやく、10月でした。こちらもJaguerが主催するイベントでの登壇で、Spannerとコストという軸を深掘りしました。Spannerのコストが高いの真意に迫る~ Spannerのコストの何が高いのか？ ~※ 無精のため資料非公開。そのうち公開します。よく高いといわれるSpannerですが、コストベースでみればそこまで高くありません。そんな中でイメージで語られるSpannerのコストを正確に判断するための観点を紹介しました。2025-12-16 PostgreSQLのインデックス作成におけるパラメータの影響の調査 ブログ自社とPostgreSQLのアドベントカレンダーでクロスポストしたブログ記事です。仕事でPostgreSQLのインデックス作成パフォーマンスを説明するために、適切な資料がなく困ったため、今後困らないために記述したブログといっても差し支えないです。2025-12-31 SREとPlatform Engineeringの交差点としてのデータベースエンジニア ブログ自社のアドベントカレンダーにポストしたブログです。31日にポストしていますが、アドベントカレンダーです。DBREとして仕事している中でDBRE/SREのプラクティスだけでは不足するデータベースエンジニアが本来行うべき仕事をカバーできないという課題から、常々考えておりまた業務の中でとりくもうと試行錯誤している内容をブログとしてアウトプットしたものです。その他、おしごとのことなど今年はマネージャーだったりカンリショクだったり、ピープルマネジメントだったりと呼ばれるロールにチャレンジしました。いまだにどうすればいいか別らないことは多いものの、マネージャーはこういうことを考えて発言していたのか？ など様々な学びはありました。また昨年に引き続き、Google Cloud Partner Top Engineer 2026に選出されました。昨年は数人いたデータベース領域の選出者も今年は私だけになってしまい、非常に残念です。まとめと来年の抱負今年は竜頭蛇尾としかいいようのない一年でした。通年では16件と月一回以上のペースでアウトプットできたものの、そのほとんどは上期にかたよっており、下期は6件程度でした。来年は上期で息切れしないように継続的なアウトプットを目標としたいです。また今年はアウトプットに偏ってしまったという印象もあるため、来年はもうすこしインプットを増やしたいものです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年、nwiizoが作ったソフトウェア]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623</guid>
            <pubDate>Wed, 31 Dec 2025 14:26:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2025年が終わろうとしている。先日、「なぜ『何でも作れる時代』に私は作れないのか」という記事を書いた。「代表作」がないという焦り、量をやることの重要性、そして引き算の必要性。書きながら、自分の弱さと向き合った。syu-m-5151.hatenablog.comあの記事で「2026年は20個作る」と宣言した。その前に、2025年に何を作ったのか振り返っておきたい。振り返ると、この1年は「自分が欲しいもの」をひたすら作り続けた年だった。誰かに頼まれたわけでもなく、バズを狙ったわけでもなく、ただ「これがあったら便利なのに」という衝動に従って、キーボードを叩き続けた。「3回同じ不便を感じたら作る」というルールを自分に課している。cctxは3回目の設定ファイル書き換えで、cargo-autoddは3回目のCargo.toml編集で生まれた。前回の記事で書いた「隙間家具」を、実際に作っていた1年だった。11個のリポジトリを公開し、合計900以上のスターをいただいた。正直に言えば、通知が来るたびに見てしまう。でも、スターが多くても使われないツールはある。逆に、スター10でも毎日使っているツールがある。自分にとっての成功の定義を「毎日使うか」に変えてから、気持ちが楽になった。Claude Codeと過ごした1年2025年は、Claude Codeと共に過ごした年だった、と言っても過言ではない。cctxClaude Codeを使い込むうちに、設定を切り替えたくなる場面が増えた。仕事では制限をかけたい、個人プロジェクトでは自由にやりたい。kubectxを使ったことがある人なら分かるだろうが、あの「サクッと切り替える」感覚が欲しかった。だからcctxを作った。cctx work と打つだけで、仕事モードに切り替わる。cctx - で前のコンテキストに戻る。それだけのツールだが、毎日使っている。毎日使うから、これは成功だ。github.comclaudelyticsClaude Codeをどれくらい使っているのか、可視化したくなった。トークン消費量、コスト、セッションごとの使用パターン。数字で見えると、自分の開発スタイルが見えてくる。TUIを作り込んで、眺めているだけで楽しいものにした。作っていて気づいたことがある。「正確なデータ」より「見たくなるUI」の方が継続利用に繋がる。最初はCSVエクスポートに注力したが、結局TUIの見た目を磨いた時間の方が長かった。github.comccatCLAUDE.mdというファイルが増えてくると、管理が面倒になる。どこに何を書いたか分からなくなる。インポートチェーンが複雑になる。だから分析ツールを作った。地味だけど、自分には必要だった。github.comccswarmこれは少し野心的なプロジェクトだった。複数のAIエージェントを協調させて、大きなタスクを分割して処理する。Git worktreeで並列開発を実現する。「Sangha」という仏教にインスパイアされた民主的意思決定システムを入れたのは、ちょっとした遊び心だ。正直、まだ実験段階で、自分でも使いこなせていない。でも「AIエージェントの協調」という方向性は間違っていないと思っている。来年、もう少し実用的なものにしたい。github.comRustへの愛なぜRustを選ぶのか。理由はシンプルで、ただ好きだからだ。でも「好き」の中身を分解すると、いくつかの要素がある。まず、型システムがAIと相性が良い。Claude Codeにコードを書かせると、Pythonでは「動くけど大丈夫？」という不安が残る。Rustでは、コンパイラが通ればほぼ安全だという確信がある。AIが生成したコードでも、コンパイラが厳しくチェックしてくれる。この安心感は大きい。そして、丁寧なエラーメッセージ。Rustのコンパイラは「ここが間違っている」だけでなく「こうすれば直る」まで教えてくれる。学習を助けてくれる先生のような存在だ。使うほど信頼が増す。所有権や型システムの「難しさ」は、将来の保守性を高めるための設計だと理解している。大規模・長期運用での事故を防ぐための仕組み。楽ではないが「裏切らない」という安心感がある。だから何度でも選ぶ。cargo-autoddRustを書いていると、Cargo.tomlの依存関係管理が面倒になることがある。ソースコードにuse serde_jsonと書いたら、自動で依存関係に追加してほしい。逆に、使わなくなったcrateは消してほしい。そんな怠惰な願望から生まれたツール。作っていて学んだことがある。ASTパーサーを書いていた。「完璧に解析する」より「80%の精度で10倍速い」方がユーザー体験は良い。完璧主義がUXを損なう好例だった。github.comcargo-couplingVlad Khononovの「Balancing Coupling in Software Design」を読んで感銘を受けた。結合度と凝集度のバランス、距離と変更頻度の関係。これをRustプロジェクトで可視化したら面白いんじゃないか。そう思って作り始めたら、想像以上に深い世界が広がっていた。Web UIを付けて、グラフを眺められるようにした。自分のコードを分析した。予想以上に結合度が高いモジュールを発見した。「ここ、分割した方がいいな」と気づけたのは収穫だった。ツールを作ることで、自分のコードの問題が見えてくる。github.comcargo.nvimNeovimでRustを書いている。:CargoBuildと打つだけでビルドが走り、フローティングウィンドウに結果が表示される。エディタから手を離さずに開発サイクルを回せる。些細なことだけど、この積み重ねが開発体験を変える。github.comTerraformとの格闘インフラをコードで管理するのは素晴らしい。でも、時にはTerraformと格闘することもある。tfmcpAIにインフラを任せるのは危険か。答えは「条件による」だ。tfmcpで設けた制限は3つ。本番環境は読み取り専用。全操作の監査ログを記録。destructiveな変更は人間の承認必須。この制限下なら、AIはterraform planを高速で回す優秀なアシスタントだ。危険なのは「AIに任せること」ではなく、「制限なく任せること」だ。この区別が重要だと、作りながら実感した。github.comtfocusTerraformのリソースターゲティングは麻薬だ。一度使うと「今回も大丈夫」と手が伸びる。状態の不整合が蓄積し、ある日terraform applyが破滅的な差分を出す。それでもtfocusを作ったのは、消防士にも斧が必要なように、障害対応には「禁じ手」が要るからだ。peco風のインタラクティブUIを付けて、素早くリソースを選択できるようにした。READMEに「緊急用ツール」と明記した。日常使いした瞬間、このツールは害になる。github.com開発者のための小さな道具たちvibe-ticketチケット管理システムは世の中に溢れている。Jira、Linear、GitHub Issues。でも、ターミナルで完結する、Git worktreeと統合された、開発者のためのチケット管理が欲しかった。MCPサーバーとしても動くようにした。AIアシスタントに「さっき見つけたバグのチケット作って」と言えば、作ってくれる。github.cominstrument-rsオブザーバビリティは大切だ。でも、どこにトレースを入れるべきか、どこにログを仕込むべきか、判断が難しい。コードを静的解析して、「ここに入れるといいよ」と教えてくれるツールがあれば便利だと思った。HTTPエンドポイントから実行パスをトレースして、クリティカルパスを特定する。まだ実験的なプロジェクトだけど、可能性を感じている。github.com失敗と学び11個公開したが、実は3個はアーカイブした。最初に作ったツールは設計が甘く、2週間で書き直した。公開して反応ゼロだったものもある。前回の記事で「捨てやすく作る」と書いた。アーカイブした3個は、まさにそれを実践した結果だ。状況が変わって不要になったもの、設計を間違えたもの。捨てることに罪悪感はない。役目を終えただけだ。ヒットの予測は難しい。「これは絶対使われる」と思ったものがスター20で止まり、「まあ自分用だし」と思ったcctxが一番使われている。予測できないなら、作りたいものを作るしかない。前回の記事で「量をやることで、初めて見えてくるものがある」と書いた。11個作って、ようやくその意味が分かってきた。最後にccswarmを公開して3日後、見知らぬ人からIssueが来た。「この機能を追加してほしい」と。実装して返信したら「ありがとう」と返ってきた。それだけのやり取りだったが、不思議と孤独じゃなくなった。顔も知らない人と、コードで繋がる感覚。SNSのいいねとは違う何かがあった。前回の記事で「代表作がない」と書いた。11個作っても、まだ「これだ」とは言えない。でも、前より近づいている気がする。2025年の11個は、2026年の20個への助走だ。すべてのプロジェクトはMITライセンスで公開している。もしあなたが「こんなツールがあれば」と思っているなら、まず作ってみてほしい。完璧じゃなくていい。私のツールも初版はバグだらけだった。READMEを書いて、v0.1.0をリリースする。それだけで世界が変わる。使ってくれる人がいるかもしれない。いなくても、自分が使えばいい。2025年、ありがとう。2026年は、もっと狂う。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREとPlatform Engineeringの交差点としてのデータベースエンジニア]]></title>
            <link>https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</link>
            <guid isPermaLink="false">https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</guid>
            <pubDate>Wed, 31 Dec 2025 08:14:34 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2025 最終日の記事です。データベースは従来から安全な変更を適用するには難易度が高い場合もあり、最悪の場合データロストを引き起こす変更しづらさが課題としてあります。現代のシステム開発では開発者によるデータベースの頻繁な変更は当たり前であり、変更しづらさが、そのままDevExの低下につながります。データベースの信頼性を支えるにも、DevExを向上させるにも、一定のデータベースの知見が必要になります。一方でデータベースに一定の知見をもつエンジニアや専門とするエンジニアは、インフラエンジニアやアプリケーションエンジニアに比べ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</guid>
            <pubDate>Mon, 29 Dec 2025 23:33:24 GMT</pubDate>
            <content:encoded><![CDATA[はじめに誰もまとめてくれないので自分でまとめます。こんなに悲しいことはありません。2025年11月から12月にかけて、「おい、〜」というシリーズでブログを15本書きました。登壇もしました。合計16本です。誰かがまとめ記事を書いてくれるかなと思っていました。待っていました。誰も書いてくれませんでした。年末です。仕方がないので自分で書きます。シリーズの始まり今年の8月、本を書かないかという話が来ました。嬉しかったです。企画を練りました。構成を考えました。8月、9月、10月といろいろやり取りをしていたのですが、いろんな諸事情で立ち消えになりました。悔しかったです。本を出せなかったことが悔しかったのではない。結局何にもならなかった自分が悔しかった。もっと準備できたはずだ。もっと詰められたはずだ。その後悔が残りました。でも、本の企画のために書いた下書き原稿が8本くらいありました。本にならないなら、ブログに書けばいい。そう思って始めたのが「おい、〜」シリーズです。30歳になったこともきっかけでした。5月に「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」というとても長いブログを書きました。20代が終わることへの焦り、不安、でも少しの期待。そのときに声かけていただいたのが、「おい、〜」シリーズとして出てきたものです。syu-m-5151.hatenablog.com20代の頃は「なんでもできる」と思っていました。30代になって、「できない」を認められるようになった。それは諦めではなく、等身大の自分を見つめられるようになったということです。15本を通して書いていたのは、結局そのことだったのかもしれません。「おい、部屋を掃除しろ」から始まりました。下書きを消化したあとも、言いたいことが止まらなくなりました。無限に書いても良くないので、週に1回のペースに決めました。自分を律するために「おい、週一で書け」とは書きませんでした。結果、15本になりました。15本の記事は、3つのカテゴリに分かれます。まず生活の基盤を整え、次に思考を鍛え、最後にその思考で仕事や人間関係に臨む。この順番で読む必要はありませんが、私の中ではこの流れがありました。生活習慣編おい、部屋を掃除しろ掃除の話ではありません。自分を大切に扱う習慣の話です。部屋が汚い人間に、コードをきれいに書けるわけがない。因果関係なんてないし、汚い部屋の凄腕エンジニアなんていくらでもいる。でも、知っている人はみんな適当な時期に結婚などしてなんとかなったか、心か身体を壊して生活を改めたか、消えていった。因果はわからないが、意味のわからない経験則としてある。毎日5分の掃除から始める規律の美学について書きました。syu-m-5151.hatenablog.comおい、一つずつやれSlack、メール、GitHub、全部同時に見ていると「忙しいのに何も終わらない」状態になります。これはおそらく忙しいのではなく、大量のタスク切り替えに対してコストを払っているだけです。仕事ができる人のイメージは、勝手に「マルチタスクができる人間」だと思っていました。しかし自分にその力はどうやらなさそうで、実際できていませんでした。ただ能力の限界まで「中途半端を量産する人間」でした。1日25分、1つのことだけに集中することから始めました。タスク切り替えの過払い金を整理した、という表現が正しいかもしれません。syu-m-5151.hatenablog.comおい、スマホを置け技術書が読めない。集中力が続かない。意志が弱いのだと思っていました。違いました。スマホに最適化された脳でした。私たちの世代は高校生の頃からスマホに触れてきた。15秒ごとに報酬をくれるアプリに慣れた脳が、30分かけて一つの概念を理解する作業に耐えられるわけがない。これは人生が壊れるな、という実感がありました。自分より下の世代は、もっと大変だろうなと思いました。syu-m-5151.hatenablog.comおい、本を読め「本を読まない人は生き残れない」という強迫的なメッセージへの違和感があります。いつから読書は「生き残るための手段」になったのか。効率的に知識を得るための読書は続かない。義務感で読む本は頭に入らない。ただ楽しいから読む。それだけでいい。そういう価値観もあるのだと、知ってもらえたらと思っていました。私は今も、子供の頃に初めて図鑑を開いたときと同じ気持ちで本を読んでいます。正直、楽しければなんでもいいと思っています。読者やフォロワーが楽しんで、結果として生き残ってくれれば、それでいい。syu-m-5151.hatenablog.comおい、休め休んでいるのに休めていない、という問題があります。ソファで横になってスマホを見ている。一見すると堕落の象徴のようでもあり、休息のようでもある。しかし残念ながら、これは休息ではありません。低負荷の作業です。脳は休んでいない。判断を続けている。スクロールするかどうか。この動画を見るかどうか。このツイートに反応するかどうか。AI時代は判断を求められる機会が増える一方です。現代では意識的に「何もしない」時間を作らないと、脳が壊れます。「じゃあお前はブログを書き続けて休んでないじゃないか」という指摘があると思いますが、その鋭い刃は収めていただけると助かります。syu-m-5151.hatenablog.com思考法編おい、冷笑すんなインターネットと冷笑は、相性が良すぎます。140字で専門家を論破した気になれる。何年も積み上げてきた人の仕事を、背景も知らずに「それ、意味あるんですか」と切り捨てられる。「専門性なんて要らない」「結局ポジショントークでしょ」——そんな言葉が、何も作ったことのない人から発せられている。私自身、視野を広げすぎて世界の複雑さに圧倒され、冷笑主義に陥った経験があります。何を見ても「まあ、そうなるよね」「どうせ変わらないよ」と思うようになっていた。達観した気になっていた。賢くなった気がしていた。違った。何も生み出さない人間になっていただけでした。冷笑は「どうせ無理」で終わる。批判は「ここがダメ」で終わる。批評は「ここがダメだから、こうすればいい」まで踏み込む。私は冷笑で止まっていた。一番楽で、一番何も残らない場所に。若い頃に冷笑してきたものが、今になって本当に大切だとわかる。それが少し悔しい。syu-m-5151.hatenablog.comおい、内省しろ内省と反省は違います。反省は「悪かった、次は気をつけます」で終わる。そして同じミスを繰り返す。私がそうでした。何度も反省した。何度も同じ失敗をした。反省とは、過去に頭を下げる行為でしかなかった。内省は違う。「なぜそうなったのか」を掘り下げて、構造を理解し、仕組みごと変えるプロセスです。自分を責めるのではなく、自分を観察する。毎日30秒でいい。寝る前に「今日、なぜあの判断をしたのか」を考える。それだけで少しずつ変わります。syu-m-5151.hatenablog.comおい、言語化しろ2025年、言語化神話が爆誕しました。「言語化できれば理解できる」「言語化できないのは思考が浅い証拠」——そんな空気が広がっている。確かに、言葉にできない領域があまりに広い人にとっては、その神を信じることで救われることもあります。言葉にする努力が思考を前に進めることもある。しかし、普通の大人には言語化できないものがあります。「なんとなくこっちの方がいい」という直感。説明できないけど手が動く技術。身体に染み込んだ知識、実践の中で培われた勘、創造的な跳躍、感情ヒューリスティック。これらを全部言葉にしようとすると、かえって嘘になる。言葉にした瞬間、丸められる。削られる。本当はもっと複雑で、矛盾していて、揺らいでいるものが、きれいに整理された途端に別物になる。「完璧に言語化できた」と思ったら、何か大事なものを落としている証拠かもしれない。不完全な変換でいい。「まだ言葉にできない何か」を抱えている感覚こそが、次の成長を生みます。syu-m-5151.hatenablog.comおい、つなげろ問題解決には「つなげること」と「断つこと」の両面があります。知識と知識をつなげて解決策を見つける。異なる領域の経験を結びつけて、新しい発想を得る。しかし、間違ったつながりを断つ勇気も必要です。「前もこうだったから」という過去の成功体験が、今回の失敗を招くことがある。AIに聞けば答えは出る。でも、自分でつなげる経験をしないと、応用が効かない。なぜその答えに至ったのか、プロセスが身につかない。「AIが教えてくれた答え」と「自分で見つけた答え」は、同じ答えでも身につき方が違う。苦労して見つけた答えは、次の問題を解く足場になる。与えられた答えは、その場で消える。syu-m-5151.hatenablog.comおい、類推するな所有権を「本の貸し借り」に例えて理解しました。わかった気になりました。腹落ちした感覚すらあった。しかし実際にコードを書いたら、例えが成立しない場面だらけでした。本は返却されても同じ本だが、所有権はそうではない。そういう経験は意識的にも無意識的にもやってしまうと思います。類推は便利ですが危険です。複雑なものを飲み込みやすくする代わりに、本質からズレた理解を植えつける。入り口としては使える。でも、判断するときは具体に戻る。「本の貸し借りだから...」ではなく「Rustの所有権のルールでは...」で考える。例え話で納得したら、そこで立ち止まって、例えを捨てる勇気を持つ。syu-m-5151.hatenablog.com仕事・対人編おい、対話しろ会議で「話しているが対話していない」場面があります。みんな口だけは喋っている。でも誰も聞いていない。相手の発言が終わるのを待っているだけ。その間に自分の意見を頭の中で整理している。相手の言葉を受けて考えを変える気がない。これは対話ではない。順番にモノローグを発表しているだけです。対話の本質は、相互の世界観を認識し、理解を深めるプロセスにある。相手の言葉を聞いて、自分の考えが変わる余地を残す。論破ではなく理解を目指す。勝ち負けではない。「なるほど、そういう見方もあるのか」が対話の成果です。syu-m-5151.hatenablog.comおい、がんばるな「頑張ること自体が目的化していた」という反省があります。遅くまで残って、休日も働いて、「頑張っている自分」に酔っていた。忙しさを充実感と錯覚していた。成果は出ていなかった。いや、正確には見ていなかった。過程に満足して、結果を直視していなかった。環境とのミスマッチを認識し、持続可能なペースに切り替えたら、むしろ成果が出るようになった。頑張りを減らしたのに成果が増える。皮肉だが、これが現実だった。公開した翌日、「いや、待てよ」と思いました。syu-m-5151.hatenablog.comおい、努力しろ前日の「がんばるな」への自己反論です。24時間で意見が変わりました。というわけではないです。読者は混乱したと思います。「頑張らなくていい」という言葉が、怠惰の免罪符として使われる危険性に気づいた。「無理しなくていい」が「やらなくていい」にすり替わる瞬間がある。量をこなさないと見えない景色がある。苦しみを乗り越えた経験がないと、乗り越え方がわからない。限界を知るには、一度限界まで行く必要がある。矛盾しているように見えますが、矛盾していません。両方本当です。「頑張りすぎるな」と「頑張らないと見えないものがある」は、同時に成り立つ。問題は、今の自分がどちら側にいるかを見極めることです。syu-m-5151.hatenablog.comおい、戦略を語れ「戦略」という言葉が形骸化しています。「戦略的に進めましょう」と言う人に「具体的にどういう戦略ですか」と聞くと、答えられないことが多い。「戦略」が「なんとなく賢そうな進め方」の意味になっている。戦略の本質は「何をやらないかの選択」です。全部やるのは戦略ではない。総花的にリソースを配分するのは、戦略がないことの証明です。限られた時間とエネルギーを、どこに集中させるか。何を意図的に捨てるか。エンジニアも「これは作らない」と言える立場になるべきです。「作れるけど作らない」という判断ができることが、本当の技術力かもしれません。syu-m-5151.hatenablog.comおい、論理で人が動くと思ってるのか論理的に正しい提案でも通らないことがあります。データを揃えた。根拠を示した。反論の余地がないほど完璧な提案書を作った。却下されました。なぜか。人は論理だけでは動かない。正しさだけでは、心が動かない。「このシステムは非効率です」より「先月、この非効率のせいで3時間残業しました」の方が通る。数字より、1人の体験談。グラフより、具体的な苦労話。人は物語で納得し、論理で自分を正当化する。だから、まず物語で心を動かし、その後で論理を添える。順番が逆だった。完璧な論理を用意する前に、「誰の、どんな困りごとを解決するのか」を語るべきでした。syu-m-5151.hatenablog.com登壇12月5日、Forkwell Communityで「おい、テックブログを書け」という登壇をしました。元々文章が苦手でした。今も苦手です。それでも書き続けたら、登壇を頼まれるようになりました。苦手なまま登壇しています。緊張で声が震えます。けれど登壇しています。出発点の低さは到達点を決めない。苦手なまま続けて消えていった人も山ほど見てきた。違いは何か。苦手なことを自覚した上で、苦手なまま出す覚悟をした。完璧を目指していたら続かなかった。syu-m-5151.hatenablog.com何を言いたかったのか15本を書いていて気づいたことがあります。それぞれの記事がつながっていく感覚がありました。「スマホを置け」と「休め」、「内省しろ」と「言語化しろ」。しかし同時に、全く反対のことも言っている。「がんばるな」の翌日に「努力しろ」。一貫性がない。でも、そういうものだと思っています。「おい、〜」シリーズは、飲み屋で語りたいことを適当に語っているような記事です。整合性を気にしていたら書けなかった。完璧を目指してたら書けなかった。矛盾だらけの15本ですが、振り返ると1つだけ共通点がありました。どの記事も「手段が目的化していないか」を問うていた気もする。掃除も、読書も、努力も、論理も、すべて何かのための手段です。その「何か」を見失っていた。効率と最適化に追われて、「なぜそれをやるのか」という問いを忘れていた。タスクをこなすことが目的になり、タスクの先にある価値を見失っていた。15本を通して言いたかったのは、そのことです。スマホで時間を潰すな。マルチタスクで忙しいふりをするな。冷笑で賢いふりをするな。論理だけで人を動かそうとするな。がんばることを目的にするな。でも努力から逃げるな。矛盾だらけです。人間は矛盾しています。それでいいと思っています。おわりに本の企画が立ち消えになったとき、正直落ち込みました。でも結果的に、ブログという形で書きたいことを全部書けた。本になっていたら、編集者に「矛盾してます」と言われて、どちらかを削っていたと思います。ブログでよかった。15本も書いて、誰も読んでいないかもしれません。誰もまとめてくれなかったということは、そういうことなのでしょう。あるいは、みんな忙しいだけかもしれない。そう思うことにしています。それでも書きました。自分のために書きました。30歳の自分から、40歳の自分への手紙です。「おい、お前、ちゃんとやってるか」10年後に読み返して、恥ずかしくなるかもしれません。「やっぱり正しかった」と思うかもしれません。どちらでもいい。でも、同じことを書いていたら。同じ悩みを抱えていたら。40歳の自分がこれを読んで、何も変わっていなかったら。それが一番怖い。来年も書きます。誰かがまとめてくれることを期待しています。でも、たぶんまた自分でまとめることになる。飽きたらやめます。だから普通に褒めてください。人に勧めてください。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、論理で人が動くと思ってるのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</guid>
            <pubDate>Mon, 29 Dec 2025 07:07:46 GMT</pubDate>
            <content:encoded><![CDATA[はじめに数年前の、ある金曜日の夜のことだ。会議は完全な失敗に終わった。会議室を出て、エレベーターのボタンを押しながら、私はこの文章を書こうと決めた。書き上げるまでにずいぶん時間がかかってしまったので、当時の思いとは少し違っているかもしれない。あの会議で「論理的に正しいことを言ったのか」と問われれば、言った。間違いなく言った。データも揃えた。根拠も示した。反論の余地がないほど、正しいことを言ったはずだった。だが、誰も動かなかった。私の発言が終わった瞬間、会議室の空気は凍りついた。誰も何も言わない。居心地の悪い沈黙が流れ、やがて別の話題へと移っていった。正しいことを言ったはずなのに、私は敗北感を覚えた。当時、私はシニアエンジニアになったばかりだった。部下はいない。それでも「組織全体の技術選定に責任を持て」と言われる。命令する権限はない。しかし説得しなければならない。予算を握っているわけでもない。それでもチームを動かさなければならない。これを読んでいる人の中にも、同じ経験をした人がいるのではないだろうか。「なぜ伝わらないのだ」と、帰りの電車の中で自問したことがある人が。正直に告白すれば、当時の私は根本的な勘違いをしていた。論理的に正しければ、人は動くものだと思っていた。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じて疑わなかった。だが、違った。人が動くのは、論理ではなかった。もっと別の何かだった。私はそれを「物語」と呼ぶことにした。なぜそう呼ぶのか。それを、これから書いていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理学が扱うもの私も昔、論理学を学んだとき、これで人を説得できると思った。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じていた。今思えば、かわいいものだ。論理学は、推論の形式を扱う学問だ。内容ではなく、形式を。「すべての人間は死ぬ。ソクラテスは人間だ。ゆえにソクラテスは死ぬ」——これがアリストテレス以来の三段論法です。この推論が正しいのは、ソクラテスが誰かとか、死とは何かという内容とは関係ありません。形式が正しいから、結論は必然的に正しいのです。論理学には2つの柱がある。演繹と帰納だ。演繹は、前提から結論を必然的に導く。「すべてのAはBである」という全称命題から、個別の結論を導く。前提が真で、推論形式が正しければ、結論は必ず真になる。数学の証明はこれだ。帰納は、個別の事例から一般法則を導きます。「このカラスは黒い」「あのカラスも黒い」を繰り返して、「すべてのカラスは黒い」と結論する。しかし、帰納には必然性がありません。次に見るカラスが白い可能性もあります。科学の仮説はこの帰納に基づいています。エンジニアとして、私は両方を使う。型システムは演繹だ。型が合っていれば、その部分は正しく動く。テストは帰納だ。このケースで動いた、あのケースでも動いた。だから「おそらく」正しい。論理学が教えてくれる重要なことがあります。論理的に正しい推論でも、前提が間違っていれば結論は間違います。「すべてのエンジニアはコーヒーを飲む。田中はエンジニアだ。ゆえに田中はコーヒーを飲む」——この推論は論理的に正しい。でも、前提が間違っています。論理は形式の正しさを保証しますが、内容の正しさは保証しません。そして、日常会話で「論理的」と呼ばれるものは、この厳密な意味での論理ではない。では、日常で「論理的」と呼ばれているものは、いったい何なのか。そして、論理は本当に「無力」なのか。私はそうは考えません。論理が効かないのではなく、使う順番を間違えているだけかもしれない。論理が効く瞬間と、効かなくなる瞬間がある。その違いは何か。論理が効くのは、相手がすでに「聞く準備」ができているときだ。信頼関係がある。問題意識を共有している。結論を受け入れる土壌がある。そういう状態で論理を使えば、「なるほど、確かにそうだ」となる。論理が効かなくなるのは、その準備ができていないときだ。相手が防御姿勢に入っている。「この人の話は聞きたくない」と思っている。そういう状態で論理を振りかざしても、「理屈っぽい」「押し付けがましい」と感じられるだけだ。論理が最初に来ると失敗しやすいのは、これが理由だ。相手の心が開いていないうちに正論をぶつけても、反発を招くだけ。まず共感し、信頼を築き、「この人の話なら聞いてみよう」という状態を作る。論理はその後だ。論理は「納得を作る道具」なのか、「正しさを確認する道具」なのか。私の答えは「両方だが、順番が違う」だ。正しさを確認するのは最初。納得を作るのは最後。自分の中で論理的に正しいことを確認してから、相手に伝えるときは物語で包む。論理は骨格で、物語は肉だ。骨だけ見せても、人は食べたいと思わない。論理的誤謬という問題論理学は、推論の「正しくない形式」も分類している。論理的誤謬だ。「Aさんは実績がないから、Aさんの意見は間違っている」——これは人身攻撃の誤謬だ。発言者の属性と、発言内容の真偽は別の問題だ。「みんながそう言っているから正しい」——これは多数論証の誤謬だ。多数派であることは、正しさの証明にはならない。「前例がないからやるべきではない」——これは前例への訴えだ。前例がないことと、やるべきでないことは別の問題だ。会議室で飛び交う「論理的」な議論を観察してみてほしい。これらの誤謬がどれだけ多いことか。私も、今日の会議で3つは使った気がする。しかし、ここで興味深いことがある。論理的誤謬を含む議論でも、人は納得する。むしろ、厳密に論理的な議論よりも、誤謬を含む議論のほうが説得力を持つことがある。なぜか。誤謬が含まれていると、かえって「人間らしさ」を感じないか。完璧に論理的な人は、どこか冷たい印象を与える。「この人は機械なのか」と思ってしまう。一方、多少の飛躍や感情的な訴えがある人は、「血が通っている」と感じる。厳密さを捨てることで得ているものがある。親近感だ。「この人も自分と同じように考えている」という共感だ。論理的な完璧さは、時として障壁になる。「この人には敵わない」と思わせてしまうと、対話が成立しなくなる。誤謬を許容しているのは、聞き手か、語り手か。私の答えは「両方」だ。語り手は、厳密さよりも伝わりやすさを優先している。聞き手は、正しさよりも納得しやすさを優先している。両者の暗黙の合意によって、誤謬は見逃される。これは悪いことばかりではない。日常のコミュニケーションで、すべてを厳密に検証していたら話が進まない。ある程度の「緩さ」は、社会を潤滑にしている。問題は、その緩さがどこまで許されるかだ。アリストテレスは、人を説得する技術を3つに分けた。ロゴス（論理）、パトス（感情）、エトス（人柄・信頼）だ。論理学が扱うのはロゴスだけだ。しかし、人間を動かすには3つすべてが必要になる。「論理的に正しいのに伝わらない」と悩むとき、私たちはロゴスだけで勝負しようとしている。パトスとエトスが欠けている。逆に、論理的誤謬を含んでいても人が動くとき、パトスとエトスがロゴスの欠陥を補っている。これが、論理学と「論理的に見えること」の決定的な違いだ。「論理的に見える」の解体世間で「論理的」と言われる人を、よく観察してみてほしい。彼らは本当に学術的な意味での論理を使っているだろうか。三段論法を厳密に適用しているだろうか。演繹的推論を正確に展開しているだろうか。違う。彼らがやっているのは、相手が「なるほど、確かに」と思える具体例をサッと出すことだ。データや証明だけじゃなくて、実感できる話で納得させている。では、日常で「論理的」と呼ばれているものは、何を代替しているのか。本来は感情で決めていることを、論理で覆っていないか。「なんとなく嫌だ」を「リスクが高い」と言い換える。「この人と仕事したくない」を「スキルセットが合わない」と言い換える。感情的な判断を、論理的な装いで正当化している。本来は信頼で決めていることを、論理で覆っていないか。「この人が言うから」を「データに基づいている」と言い換える。「前からこうだったから」を「実績がある」と言い換える。関係性や慣習に基づく判断を、客観的な根拠があるように見せている。本来は立場で決めていることを、論理で覆っていないか。「上が決めたから」を「戦略的に正しい」と言い換える。「予算がないから」を「費用対効果が低い」と言い換える。権力構造に基づく判断を、合理的な分析結果のように見せている。「論理的に説明した」という言葉は、責任回避になっていないか。「私が決めた」ではなく「論理的にこうなった」と言うことで、判断の責任を「論理」に押し付けている。でも、どの前提を選ぶか、どのデータを重視するか、それを決めたのは人間だ。論理は責任を引き受けてくれない。論理という言葉は、どんな場面で免罪符になるのか。「感情的になるな、論理的に考えろ」と言われたとき、相手の感情を封じ込める武器になっている。「論理的に正しいんだから従え」と言われたとき、対話を打ち切る口実になっている。論理という言葉が、思考停止の道具になることがある。「論理で動いた」ように見える行動を解剖してみよう。実際に何が作用しているのか。信頼がある。「この人が言うなら」という前提がすでに成立している。文脈がある。その結論を受け入れやすい状況がすでに整っている。同調圧力がある。周囲がすでに納得している空気がある。期待がある。その結論であってほしいという願望がある。論理は、これらの基盤の上で初めて機能する。基盤がなければ、どれだけ論理的に正しくても人は動かない。論理は感情の乗り物だ。乗り物だけあっても、燃料がなければ走らない。感情という燃料があって、初めて論理は目的地に到達する。しかし、この比喩はどこまで言い切ってよいのか。感情がない状態で論理が機能する場面は存在するか。数学の証明を考えてみてほしい。純粋に形式的な操作として、感情抜きで成立するように見える。しかし、その証明を「面白い」「美しい」と感じる心がなければ、誰が数学を続けるだろうか。論理の営みを支えているのは、やはり感情だ。感情が強すぎるとき、論理は何を失うのか。怒りに支配されているとき、論理は武器になる。相手を傷つけるための道具になる。悲しみに沈んでいるとき、論理は機能しなくなる。「わかっているけど、できない」という状態になる。感情が強すぎると、論理は歪むか、停止する。論理と感情は主従関係なのか、相互依存なのか。私の答えは「相互依存」だ。論理が感情を制御することもある。「怒りに任せて発言するのはやめよう」と論理が感情をなだめる。感情が論理を駆動することもある。「この問題を解決したい」という情熱が、論理的思考を加速させる。どちらが主人というわけではない。両者が互いに影響し合っている。うまく言葉にできる人は、論理が強いのではない。相手を見ている。相手が何を知っていて、何を知らないか。何を信じていて、何に不安を感じているか。その理解があるから、言葉が届く。論理は単体では人を動かさない。ここでもう一歩踏み込んでみます。「私は論理的です」という態度自体が、1つのナラティブではないでしょうか。「私は感情に左右されず、冷静に判断しています」という自己像を提示している。それ自体が物語を語っているということです。「AだからB」は、推論である前に、納得の物語です。原因と結果を結びつけ、聞き手を結論へと導く。それは「正しいから従うべき」ではなく「納得できるから受け入れる」という構造で機能しています。信じたい物語への依存ここまで、論理の限界と物語の力について語ってきた。しかし、もう一歩踏み込みたい問題がある。人は「信じるべき論理」ではなく「信じたい物語」を信じる。これは単なる傾向ではない。依存に近い。考えてみてほしい。データを見せられたとき、私たちは本当に中立的に判断しているだろうか。「この数字は何を意味するか」と問う前に、「この数字は自分の期待を裏付けているか」と無意識に判断していないか。期待に合致するデータは「やはり」と受け入れる。期待に反するデータは「本当なのか」と疑う。同じ論理、同じデータでも、自分の物語に沿っているかどうかで、受け取り方が変わる。これは認知バイアスの問題だけではない。もっと根深い。私たちは、自分のアイデンティティを守る物語に依存している。「私は論理的な人間だ」という物語。「私は技術力がある」という物語。「私のチームは優秀だ」という物語。これらの物語が脅かされると、私たちは防御に入る。どれだけ論理的に正しい指摘でも、自分の物語を脅かすものは受け入れられない。なぜ依存と呼ぶのか。やめられないからだ。物語を手放すことは、自分を手放すことに感じられる。「私は実は論理的ではなかった」と認めること、それはアイデンティティの崩壊に近い。どれだけ反証を突きつけられても、私たちは自分の物語にしがみつく。論理が正しいかどうかは、もはや関係ない。これは「信じるべきかどうか」の問題ではない。「信じずにいられない」という問題だ。会議室で「それは違う」と言われたとき、私たちは何を守ろうとしているのか。事実を守っているのか、それとも「私は正しい」という物語を守っているのか。正直に言えば、多くの場合は後者だ。だから、論理で人を動かそうとしても失敗する。相手の物語と衝突すれば、相手は論理を聞く前に防御に入る。「この人の言うことは聞きたくない」という状態になる。論理が届く前に、扉が閉まっている。では、どうすればいいのか。相手の物語を攻撃するのではなく、その物語の中に入る。相手が信じたい物語を否定せず、その物語の延長線上に自分の提案を置く。「あなたの論理は間違っている」ではなく、「あなたの考えをさらに進めると、こうなる」と語る。人を動かすとは、相手の物語を書き換えることではない。相手の物語に自分の提案を織り込むことだ。経験談が人を黙らせる理由人を説得するとき、論理だけでは足りない。自分の失敗談を語ることで心を掴むことがある。「とほほエピソード」には不思議な力がある。完璧な論理よりも、不完全な経験談のほうが、人の心に響くことがあるのだ。経験談は再現性が低い。その人固有の文脈でしか成り立たないことも多い。なのに、私たちは経験談に心を動かされる。なぜか。経験談が持つ力を3つに分解してみる。1つ目は、再現性の放棄だ。「これが正解です」ではなく「私はこうだった」と語ることで、聞き手は反論しにくくなる。事実に対しては「それは違う」と言えるが、経験に対しては言えない。2つ目は、思考コストの削減だ。抽象的な理論を理解するより、具体的な経験を追体験するほうが楽だ。聞き手は考えなくても「なるほど」と言える。3つ目は、権威の自動付与だ。「やったことがある人」は、それだけで信頼される。成功者の経験談には、内容を超えた説得力が宿る。しかし、ここに危険がある。「成功者が言うから正しい」という錯覚。これは聞き手の思考停止を招く。経験談が「効きすぎる」とき、何が起きているのか。聞き手は考えることをやめている。語り手の経験を、自分の結論にすり替えている。経験談を聞いた瞬間、聞き手は何を放棄しているのか。批判的思考だ。「本当にそうか」「自分の場合は違うのではないか」という問いを放棄している。経験談には「事実」としての重みがあるから、反論しにくい。反論すると「お前はやったことがないくせに」と言われそうだから、黙ってしまう。「反論できない感じ」は、どこから生まれるのか。経験談は「私はこうだった」という一人称で語られる。一人称の物語に対して、「それは違う」とは言いにくい。他人の経験を否定する権利が自分にあるのか、という遠慮が働く。しかし、その経験から導かれる「だからこうすべきだ」という結論は、本当に正しいのか。そこは検証が必要だ。だから、経験談は入口であって、結論ではない。経験談で心を開き、そこから自分で考える。その順番が重要だ。では、経験が浅い人は物語を語る資格がないのか。私はそうは考えません。経験の浅さには、浅いなりの価値があります。経験が浅いからこそ見えるものがある。「なぜこのやり方なのか」という素朴な疑問。ベテランにとっては「当たり前」になっていることへの違和感。「本当にこれでいいのか」という不安。これらは、経験を積むほど薄れていく。ベテランが失いやすい視点とは何か。初心者の目線だ。「これは難しい」「これはわかりにくい」という感覚は、慣れると消えてしまう。だからベテランが書いたドキュメントは、初心者には読めないことがある。ベテランが設計したシステムは、初心者には使えないことがある。経験は資産だが、同時に負債でもある。「まだわからない」という物語は、どんな力を持つか。謙虚さの力だ。「私はまだ学んでいる途中です」と言える人は、相手の話を聞く姿勢がある。「私は全部わかっています」と言う人は、すでに耳を閉じている。経験の浅さを認めることは、対話の扉を開くことになる。重要なのは経験の量ではなく、経験を物語として語る力だ。10年の経験があっても、それを言葉にできなければ伝わらない。1年の経験でも、そこから何を学んだかを語れれば、人の心に届く。経験談を「入口」に留めるには、何が必要か。聞き手の側には、「この人の経験は参考になるが、自分の状況は違うかもしれない」という留保が必要だ。語り手の側には、「これは私の経験であって、あなたに当てはまるとは限りません」という謙虚さが必要だ。両者がこの姿勢を持っていれば、経験談は入口のまま留まる。物語が許されない領域私はエンジニアとして長く働いてきた。だからこそ言いたいことがある。物語万能論は危険だ。かつて、私は失敗したことがある。プロジェクトが炎上しかけていたとき、チームの士気を上げようと物語を語った。「このプロダクトが世に出れば、多くの人の生活が変わる」「困難を乗り越えた先に、私たちは成長している」。チームは一時的に盛り上がった。でも、テストは通らなかった。本番環境でバグが発生した。物語で人は動いたが、システムは動かなかった。バグは物語で直らない。物語でテストが通るなら、私は今頃、小説家になっている。どれだけ美しい物語を語っても、コードが間違っていれば動かない。どれだけチームが納得しても、テストが通らなければリリースできない。エンジニアリングには、物語では代替できない領域がある。技術的正しさは、どこまで物語と共存できるのか。私の答えは「共存はできるが、置き換えはできない」だ。物語は人を動かすが、システムは論理で動く。この2つを混同してはいけない。泣いたら人は許してくれるかもしれませんがシステムは許してくれません。人の層とシステムの層を混同すると、何が起きるか。人の層で通用する「納得したからOK」が、システムの層に持ち込まれる。チーム全員が「この設計でいこう」と合意しても、コードが間違っていれば動かない。逆に、システムの層で通用する「正しいから従え」が、人の層に持ち込まれる。論理的に正しい設計でも、チームが納得していなければ実装は進まない。「納得したからOK」は、どこまで通用するのか。人を動かすところまでだ。「このアーキテクチャでいこう」という合意形成には物語が必要だ。しかし、そのアーキテクチャが本当に要件を満たすかは、検証が必要だ。納得と正しさは別の問題だ。物語で進めてはいけない判断の特徴は何か。結果が客観的に検証できる判断だ。「このコードは動くか」「このシステムは要件を満たすか」「このセキュリティ対策は十分か」。これらは、どれだけ美しい物語を語っても、実際にテストしなければわからない。物語で「大丈夫だろう」と進めて、本番環境で障害が起きたら、物語は言い訳にしかならない。ナラティブと検証の役割分担を整理しておく。人を動かすのは物語だ。なぜこの技術を選ぶのか、なぜこのアーキテクチャにするのか。それを説明し、納得してもらうには物語が必要だ。正しさを担保するのは論理とテストと記録だ。選んだ技術が本当に動くのか、アーキテクチャが要件を満たすのか。それを確認するには検証が必要だ。「あの人が言うから正しい」という判断は、いつ危険になるのか。それは、検証を省略したときだ。権威ある人の経験談に納得したとしても、コードレビューは必要だ。テストは必要だ。ドキュメントは、物語の代替にはなりえない。物語が「なぜそうするのか」を伝え、ドキュメントが「何をするのか」を記録する。物語は人の層に効き、論理はシステムの層に効く。この使い分けが重要だ。プロジェクトを進めるには「直線モード」と「曲線モード」を行き来する必要があります。計画と合理性を重視する直線モード、そして変化や対話を重視する曲線モード。どちらか一方では足りません。両方を使い分けられることが、プロジェクトを前に進める力になります。優しい物語の罠「あなたらしさを大切にしたうえで、今必要な道具を手に入れ、磨き、使い分けていこう」というメッセージには優しさがある。しかし、優しい物語は、なぜ時に成長を妨げるのか。思い出してほしい。優しい言葉をかけたのに、相手が変わらなかった経験はないか。「大丈夫だよ」と言い続けたのに、問題が解決しなかった経験はないか。あのとき、私たちは何を間違えていたのか。優しさは寄り添う。甘さは目を背けさせる。優しさと甘さは、どこで分岐するのか。私の答えは「事実を直視しているかどうか」だ。優しさは事実を受け止めた上で寄り添うこと。甘さは事実から目を背けさせること。「あなたらしくていい」が「変わらなくていい」に変質したとき、それは優しさではなく甘さになる。厳しさを含まない物語は、誰のためのものか。多くの場合、それは語り手のためだ。相手に嫌われたくない、対立を避けたい、という語り手の願望が、優しさという衣をまとっている。その優しさは、聞き手のためか、語り手のためか。この問いは重要だ。「傷つけたくない」と言いながら、実は「嫌われたくない」だけかもしれない。「今は言わないほうがいい」と言いながら、本当は「言うのが面倒」なだけかもしれない。優しさの仮面をかぶった自己保身は、いくらでもある。事実を和らげることと、隠すことの境界はどこか。私の答えは「相手が判断するために必要な情報を持っているかどうか」だ。「あなたのスキルはまだ足りないが、伸びしろがある」は和らげている。「あなたは素晴らしい」と言って、スキル不足を伝えないのは隠している。前者は事実を含んでいるから、相手は次の行動を選べる。後者は事実を隠しているから、相手は間違った判断をする。成長を促す厳しさと、切り捨ての厳しさはどう違うか。成長を促す厳しさは、相手の可能性を信じている。「あなたならできるはずだ。だから厳しく言う」という姿勢がある。切り捨ての厳しさは、相手を見限っている。「あなたには無理だ。言っても仕方ない」という諦めがある。言葉は同じ「厳しさ」でも、その奥にある信頼の有無で意味が変わる。勇気を与える物語と、逃避を許す物語の違いは何か。勇気を与える物語は「困難があるが、乗り越えられる」と語る。逃避を許す物語は「困難なんてない」と語る。前者は現実を認めた上で希望を示す。後者は現実から目を背けさせる。自分が語っている物語は、どちらだろうか。説得と操作の境界物語には力がある。力があるということは、危険もあるということだ。物語は、どの瞬間に「説得」から「操作」に変わるのか。その境界は曖昧だ。聞き手の自由意志は、どこまで守られているのか。完全に自由な判断などありえない。私たちは常に、何らかの影響を受けながら判断している。では、説得と操作は何が違うのか。結果だけを見れば、どちらも「相手が動いた」という点では同じだ。説得と操作の違いは、「結果」ではなく「過程」にある。結果が同じなら、過程を見なければならない。しかし、過程を見れば違いが見える。説得は、相手が考える余地を残している。操作は、相手が考える余地を奪っている。相手が考える余地を失った瞬間は、いつか。選択肢が1つしか見えなくなったときだ。「これしかない」「こうするしかない」と思わせた瞬間、相手は考えることをやめている。本当は他の選択肢があるのに、それを見せないでおく。これは操作だ。「選択肢を示す」と「結論を誘導する」の違いは何か。選択肢を示すとは、複数の道があることを伝え、それぞれの長所と短所を説明することだ。結論を誘導するとは、複数の道があるように見せながら、1つの道だけが正しいと思わせることだ。言葉は似ているが、相手の思考を尊重しているかどうかで意味が変わる。しかし、だからといって何をしてもいいわけではない。善意で語った物語が、操作になるのはどんなときか。語り手が「相手のため」と信じていても、相手の判断力を奪っていれば操作だ。「あなたのためを思って」という言葉は、しばしば「私の思い通りにしたい」の言い換えになっている。善意は免罪符にならない。語り手の「善意」は、免罪符になりうるか。ならない。善意で語った物語が、相手を誤った方向に導くことはある。「あなたのためを思って」は、操作の常套句だ。善意は動機であって、結果の正当化にはならない。操作に堕ちないための条件を3つ挙げる。1つ目は、事実を歪めないこと。都合のいい事実だけを選んだり、不都合な事実を隠したりしない。2つ目は、相手に考える余地を残すこと。「これしかない」と思わせるのではなく、「こういう選択肢がある」と示す。結論を押し付けない。3つ目は、相手の利益を本当に考えていること。相手を動かすことが目的なのか、相手のためになることが目的なのか。同じ物語でも、動機によって意味が変わる。この3つが揃わなければ、どれだけ巧みな物語も操作に堕する。また、「別の物語を語る」ことが、失敗からの逃避になることもある。プロジェクトが破綻したとき、物語を更新することで責任を回避していないか。失敗の原因を分析し、自分の責任を認めた上で、「次はこうする」という物語を語るのは再解釈だ。事実から目を背け、「本当はうまくいっていた」「環境が悪かった」と言い張るのは言い訳だ。物語は現実を覆い隠すためのものではない。現実を受け止めた上で、次に進むためのものだ。では、物語を使った対話とはどのようなものか。ファシリテーションの現場から考えてみます。対話は物語を揃えることではない優れたファシリテーターは「ほぼ何もしない」といいます。ワークを説明したら、部屋の隅に座る。音楽を流す。ニコニコ笑っている。具体的な動きはそれだけです。でも、それでチームは動く。なぜか。それは、ファシリテーターが「物語の場」を設定しているからだ。メンバーが自分たちで物語を紡げるような空間を作っている。論理的な指示を与えるのではなく、物語が生まれる環境を整えている。しかし、対話とは本当に「物語の共同制作」と言えるのか。正直に言えば、完全に対等な共同制作は難しい。ファシリテーターは場を設計している時点で、ある種の権力を持っている。どんな問いを投げかけるか、どんな発言を拾うか、どこで介入するか。それらすべてが、生まれる物語に影響を与える。「何もしない」という選択自体が、1つの介入なのだ。では、合意されなかった物語はどこへ行くのか。チームで1つの物語を紡いだとき、そこに乗れなかった人がいる。彼らの物語は消えるのか。消えはしない。地下に潜るだけだ。表向きは合意しながら、心の中では別の物語を持ち続ける。優れたファシリテーターは、この「語られなかった物語」にも目を向ける。全員が同じ物語を持つ必要はない。大切なのは、異なる物語が共存できる場を作ることだ。対話のゴールは「1つの物語に収束すること」ではなく「複数の物語が共存できること」だ。合意形成について、よく誤解されていることがある。多くの人は、自分の檻の中から相手の檻を押し潰そうとする。自分の枠組みが正しい、相手の枠組みは間違っている。だから相手を説得し、こちらの檻に入れようとする。でも、それは合意ではない。征服だ。本当の合意形成とは、まず自分が檻の中にいることを認めることから始まる。私にも枠組みがある。相手にも枠組みがある。どちらの檻も、その人の経験と価値観から作られている。どちらが正しいという話ではない。相手の檻を壊す必要はない。自分の檻を捨てる必要もない。大切なのは、お互いの檻の形を理解し、その間に共通の地面を見つけることだ。檻から出るのではなく、檻と檻の間に橋を架ける。それが対話だ。一貫性とは何か複数の物語を使い分けることは、「一貫性の欠如」にならないのか。状況に応じて物語を切り替える人は、信用できないのではないか。そう感じるかもしれません。しかし、一貫性とは何でしょうか。言葉の統一なのか、価値観の統一なのか。私は、一貫性とは価値観の統一だと考えている。言葉が変わっても、芯がぶれなければ、それが一貫性だ。言葉や物語は変わっていい。相手によって、文脈によって、最適な表現は変わる。しかし、その奥にある価値観——何を大切にしているか——は変わらない。物語が変わっても残る「軸」とは何か。それは「この人は結局、何を実現したいのか」という問いへの答えだ。チームの成長を願っているのか。技術的な卓越性を追求しているのか。顧客の幸福を第一にしているのか。その軸がぶれなければ、物語が変わっても芯はぶれない。文脈適応と迎合の違いは、どこで判断できるのか。文脈適応は、相手に届くように表現を変えること。迎合は、相手に合わせて価値観を曲げること。前者は橋を架ける行為であり、後者は自分を売る行為だ。同じ価値観を異なる文脈で語り分けられることこそが、優れたナラティブ構築者の条件だ。論理を使い直すここまで、論理の限界を語ってきた。論理は単体では人を動かさない。論理自体が1つの物語だ。論理を絶対視することの危険。しかし、論理を否定して終わりにするつもりはない。論理を「唯一の正解」から「道具」へ格下げすることは、思考を弱くするのか、強くするのか。私は強くすると考えている。論理を絶対視していると、「論理的に正しいのになぜ伝わらないのか」と悩むことになる。論理を道具として扱えば、「この道具はこの場面では有効か」と考えられる。道具は選べる。使い分けられる。論理という物語が有効な場面と、別の物語が有効な場面を見極められるようになる。プロジェクトには「プロジェクトストーリー」がある。最終ゴールと中間ゴールからストーリーを描き、チームの方向性を示す。このストーリーの中に、論理は組み込まれる。計画は論理的だろう。でも、その計画を人に伝え、人を動かすには、物語という器が必要だ。論理と物語、どちらも選んで使うものです。どちらかが正しいのではありません。どちらをいつ使うかを判断できることが、人を動かす力になります。正しさを振り回すのは、本当に「最後」でいいのかここまで読んで、こう思った人がいるかもしれない。「物語が先で、正しさは後。それはわかった。でも、正しさを最後まで出さないことに、問題はないのか」正しさを最初に出したくなるのは、どんな不安からか。「間違ったことを言いたくない」という不安だ。「後で『それは違う』と言われたくない」という不安だ。正しさを先に出しておけば、自分の立場は守られる。たとえ相手が納得しなくても、「私は正しいことを言った」と言える。正しさを最初に出すことは、自己防衛なのだ。しかし、正しさを最後に出すことで、失われるものはないのか。ある。時間だ。物語で回り道をしている間に、問題は悪化する。緊急事態では、正しさを最初に出すべき場面もある。「このまま進むとシステムが落ちます」と言うべきときに、「まず私の経験を聞いてください」と始めている場合ではない。「最後まで正しさを出さない」こと自体が、別の操作になっていないか。この問いは重要だ。相手が自分で結論に至ったように見せかけて、実は最初から結論が決まっている。正しさを隠しながら誘導している。これは、正しさを振りかざすのとは別の形の操作だ。では、いつ正しさを出すべきか。私の答えは「相手の安全が脅かされるとき」と「時間の制約があるとき」だ。相手が危険な判断をしようとしているとき、物語を語っている余裕はない。「それは間違っている」と言うべきだ。締め切りが迫っているとき、回り道をしている余裕はない。「正しい方法はこれです」と言うべきだ。正しさは武器だ。武器を振り回すのは危険だが、武器を持たないのも危険だ。大切なのは、いつ抜くかを見極めることだ。syu-m-5151.hatenablog.comおい、物語を語れだから、私は言いたい。おい、物語を語れ。論理的であろうとするな、とは言いません。論理は大事です。でも、論理だけでは人は動きません。「この設計が正しい理由は〜」と説明するとき、あなたは本当に論理だけで話しているだろうか。実は、相手が納得しやすい順番で、相手が受け入れやすい言葉で、相手の不安を先回りして解消しながら話しているのではないか。それは物語を語っているということだ。世間で「論理的」と言われる人の正体は、巧みなナラティブ構築者だ。彼らは論理を使いこなしているのではない。論理という道具を使って、説得力のある物語を紡いでいるのだ。そして、そのことに自覚的になることで、私たちはより良い物語の語り手になれる。物語を語る勇気でも、物語を語るのは怖い。論理的であろうとするのは、ある意味で楽です。「これはデータに基づいています」「これは事実です」と言えば、自分の主観を隠せます。責任を回避できます。でも物語を語るということは、自分をさらけ出すことだ。裸になることだ。「私はこう思う」「私はこれを大事にしている」「私はこの未来を信じている」と言わなければならない。自分の背景を伝えること、自分の失敗を語ること、自分の葛藤を見せること。それは勇気がいる。でも、その勇気が人を動かす。「論理的に正しいから」ではなく、「この人が言うなら」で人は動く。そして「この人が言うなら」を引き出すのは、論理ではなく、物語だ。おわりに年の瀬の日曜日の夜、私はベッドの上でこの文章を書き終えようとしている。正直に言えば、書いている間も何度か「これは論理的に正しいのか」と自問してしまった。物語の力を語りながら、論理の正しさを気にしている。滑稽だ。滑稽だが、それが私という人間なのだと思う。この文章を書いたからといって、明日から完璧に物語を語れるようになるわけではない。おそらくこれからも、会議室で正論を並べ立て、微妙な沈黙を招く日があるだろう。「なぜ伝わらないのだ」と、帰りの電車で思い悩む日があるだろう。だが、少しだけ違うことがある。以前の私は、伝わらないとき、「もっと論理的に説明しなければ」と考えていた。今は違う。「ああ、骨だけを見せていた」と気づくことができる。気づいたなら、肉を足せばいい。失敗談をひとつ、付け加えればいい。それだけでも、以前よりはましなのだと思う。たぶん。明日は月曜日だ。また会議がある。また正論を振りかざしたくなる瞬間がある。だが今度は、最初に自分の失敗談から話してみようと思う。「この設計が正しい理由は」ではなく、「以前、似たような判断を先送りにして、半年後に全員で苦しんだことがある」から始めてみる。怖い。裸を晒すようで、怖い。だが、論理だけで人が動くと信じていた私は、もういない。あの金曜日のエレベーターの中で、その私は死んだのだと思います。おい、物語を語れ。何度でも、自分に言い聞かせる。何度でも忘れ、何度でも思い出す。完璧に語れるようになることより、何度でも思い出せることのほうが、きっと大切なのだ。参考文献イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon小説作者:野崎まど講談社Amazon言語化するための小説思考作者:小川 哲講談社Amazonリーダーのためのストーリーテリング入門 90秒で人の心を動かす「語り」のマネジメントスキル作者:広江 朋紀翔泳社Amazonリーダーのための！　ファシリテーションスキル作者:谷 益美すばる舎Amazonチームビルディングと組織開発の話作者:長尾 彰ナガオ考務店Amazonチーム・ビルディング[新版]　人と人を「つなぐ」技法作者:堀公俊日経BPAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社Amazonエンジニアリングが好きな私たちのための　エンジニアリングマネジャー入門作者:サラ・ドラスナー日本能率協会マネジメントセンターAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazonナラティブ経済学―経済予測の全く新しい考え方作者:ロバート・シラー東洋経済新報社Amazon世界はナラティブでできている：なぜ物語思考が重要なのか作者:アンガス フレッチャー青土社Amazonストーリーが世界を滅ぼす―物語があなたの脳を操作する作者:ジョナサン・ゴットシャル東洋経済新報社Amazon「わかってもらう」ということ　他人と、そして自分とうまくやっていくための言葉の使い方 (単行本)作者:川添 愛KADOKAWAAmazonなぜあなたはマネジメントを間違えるのか？　会社の常識を打ち破るチェンジリーダーの教科書作者:岸良裕司KADOKAWAAmazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon人が壊れるマネジメントプロジェクトを始める前に知っておきたいアンチパターン 50作者:橋本将功ソシムAmazonモチベーション革命　稼ぐために働きたくない世代の解体書 (NewsPicks Book)作者:尾原和啓幻冬舎Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[4年目セキュリティエンジニアの2025年振り返り & AIから見た今年の私]]></title>
            <link>https://www.rowicy.com/blog/review-2025-riiim/</link>
            <guid isPermaLink="false">https://www.rowicy.com/blog/review-2025-riiim/</guid>
            <pubDate>Mon, 29 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[新卒からエンジニアとして4年経とうとする中で、2025年の振り返りをやっていこうと思います]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 俺が愛した本たち 非技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</guid>
            <pubDate>Sun, 28 Dec 2025 02:50:33 GMT</pubDate>
            <content:encoded><![CDATA[はじめに技術書編を書き終えて、ふと気づいた。あれだけ書いても、まだ語っていない本がある。仕事に直結しない本。読んでも生産性が上がらない本。キャリアに役立つかどうかわからない本。そういう本たちのことを、どこかで書きたいと思っていた。だから、この記事を書いている。非技術書を読む時間を、どこか後ろめたく感じていた時期があった。エンジニアなんだから技術書を読むべきだ。限られた時間を、仕事に関係ない本に使っていいのか。そんな自問が、頭の片隅にあった。でも、ある時期から考えが変わった。技術書だけ読んでいると、技術書が読めなくなる。視野が狭くなる。発想が硬くなる。同じ問題を、同じ角度からしか見られなくなる。なぜそうなるのか。技術書は「答え」を求めて読むからだ。設計パターン、ベストプラクティス、トラブルシューティング。明確な課題があって、その解決策を探している。でも非技術書は違う。何を得られるかわからないまま読み始める。読み終わっても、何が残ったのかすぐにはわからない。数ヶ月後、ふとした瞬間に「ああ、あの本のあれか」と腑に落ちることがある。即効性がないから、効いている実感もない。でも、確実に何かが変わっている。では、非技術書は仕事に無関係かというと、そうでもない。小説を読む。エッセイを読む。哲学書を読む。歴史書を読む。どれも仕事には直結しない。でも、人間を理解しようとする営みは、チームで働く上で無駄ではないはずだ。コードを書くのは人間だ。レビューするのも人間だ。障害対応で慌てるのも、成功を喜ぶのも、人間だ。技術だけ理解しても、人間を理解していなければ、良いエンジニアにはなれない。そう言い聞かせながら、非技術書を読んできた。ここまで書いて、自分でも気づいている。これは言い訳だ。正直に言えば、読んでいて楽しいから読んでいる。それだけだ。仕事のためとか、自己成長のためとか、そういう大義名分は後付けだ。ページをめくる時間が好きだ。知らない世界に触れる瞬間が好きだ。登場人物の感情に揺さぶられる体験が好きだ。好きなことに理由はいらない。でも、理由を語りたくなるのが人間だ。断っておくと、以下の選定基準はかなりブレている。読んだ直後に評価したわけではなく、年末に一年を振り返って「良かったな」と思い出した本を並べているだけだ。印象に残った理由も、内容が深かったからだったり、読んだタイミングが良かったからだったり、装丁が好みだったからだったり、バラバラだ。体系的なブックガイドではない。ある一人のエンジニアが、2025年に出会って心に残った本の記録だと思ってほしい。以下に紹介する本たちは、2025年に私の心を動かした非技術書だ。仕事に役立つかどうかはわからない。キャリアに影響したかどうかもわからない。ただ、これらの本と過ごした時間が、私の2025年を少しだけ豊かにしてくれた。それだけは確かなことだ。昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2025年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるまずは小説から始めよう。物語の力を信じているから。小説野崎まどという作家は、読者の予測を裏切ることに喜びを見出しているとしか思えない。タイトルが『小説』。これ以上ないほど直球で、それでいて挑発的だ。読み始めたときは、ただの青春小説かと思った。でも違った。「小説とは何か」という問いに正面から向き合いながら、それ自体が1つの「小説」として成立している。メタ構造に気づいた瞬間、鳥肌が立った。野崎まどの作品は、読み終わった後に「やられた」と思わせる仕掛けが必ずある。『know』では知識と情報の本質を、『タイタン』ではAIと人間の関係を問いかけてきた。本作では、小説という形式そのものを問いかけてくる。読んでいる間は物語に没入し、読み終わった後に構造の巧みさに気づく。その二重の楽しみが、野崎作品の醍醐味だ。小説作者:野崎まど講談社AmazonGOATデジタル全盛の時代に、あえて紙の文芸誌を立ち上げる。その挑戦に心を動かされた。510円という価格設定で、特殊紙を惜しみなく使い、読書バリアフリーにも取り組んでいる。翻訳の仕事をしているとよく分かるが、紙代も印刷代も高騰している。書籍全体の価格が年々上がっているのは、出版社の怠慢ではない。本を作るコストそのものが上がっている。そんな中で、この価格で、この品質を維持しようとしている。すごいな、と素直に思った。GOAT作者:西加奈子,小川哲,尾崎世界観,市川沙央,チョン・セラン小学館AmazonGOAT Summer 2025作者:朝井リョウ,一穂ミチ,野崎まど小学館Amazon野崎まどの「山羊と七枚」も掲載されており、雑誌のコンセプトと作家の個性が見事に噛み合っていた。dps.shogakukan.co.jp小説と雑誌を読んで、ふと考えた。読む時間は有限だ。何を読むかより、どう読むかが問われる。そこで手に取ったのが、この本だった。STOIC 人生の教科書ストイシズム2000年以上前から続くストア哲学が、シリコンバレーで再び注目されている。禅やマインドフルネスと並んで、ビジネスパーソンの必須教養になりつつあるという。本書は、エピクテトス、セネカ、マルクス・アウレリウスという三人のストア哲学者の言葉をもとに、90日間のプログラムとして構成されている。見開き2ページで1つの教えを学び、実践するという形式だ。ストイシズムの核心は「他人の行動はコントロールできないが、自分の反応はコントロールできる」という考え方にある。これは現代のエンジニアにとっても響く教えだ。障害が起きたとき、顧客からのクレームが来たとき、チームメンバーとの意見が対立したとき。制御できないことに怒りを感じても何も変わらない。変えられるのは、自分がどう対応するかだけだ。本書で繰り返し語られる4つの美徳がある。知恵（うわべにとらわれない力）、正義（他人に思いやりを持つ力）、勇気（苦難に立ち向かう力）、節制（衝動を抑える力）。どれも派手ではないが、日々の仕事で試される場面ばかりだ。佐藤優氏が帯で「大きな理想を獲得するには禁欲が必要だ」と書いている。逆説的だが、自分を律することで自由になれる。そういう考え方に惹かれる人は多いはずだ。STOIC 人生の教科書ストイシズム作者:ブリタニー・ポラットダイヤモンド社Amazonストイシズムは「衝動を抑える力」を説く。では、そもそも私たちは何を読み取っているのか。読むという行為そのものを問い直す本に出会った。読めば分かるは当たり前？　――読解力の認知心理学「読めば分かる」は当たり前ではない。本書を読んで、その事実に改めて気づかされた。文字を認識し、単語の意味を理解し、文の構造を解析し、文章全体の意味を把握する。私たちが無意識に行っているこの作業は、驚くほど複雑な認知プロセスの連続だ。どこかでつまずくと、読解は破綻する。そして、つまずきのポイントは人によって異なる。本書では、読解を3つの目的地に分類している。「表象構築」（テキストの内容を正確に理解する）、「心を動かす読解」（物語に感情移入する）、「批判的読解」（内容を吟味し、自分の考えと照らし合わせる）。技術書を読むときは主に表象構築を、小説を読むときは心を動かす読解を使っている。無意識に使い分けていたことを、言語化してもらった気分だ。特に響いたのは、「ワーキングメモリ」の話だ。複雑な文章を読むとき、頭の中の「メモ帳」に情報を一時保存しながら読み進める。このメモ帳には容量制限がある。だから、込み入った技術ドキュメントを読むときは、メモを取りながら読むほうが理解が深まる。経験則として知っていたことに、認知科学的な裏付けを得た。読めば分かるは当たり前？　――読解力の認知心理学 (ちくまプリマー新書)作者:犬塚美輪筑摩書房Amazon小澤隆生 凡人の事業論 天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと孫正義と三木谷浩史。日本を代表する二人の天才経営者に仕えてきた人物がいる。楽天イーグルス創業、PayPay立ち上げなど、巨大ビジネスを次々と成功させてきた小澤隆生氏だ。投資先19社中11社が株式上場という実績を持つ。そんな人物が「自分は凡人だ」と言う。謙遜ではない。天才のそばにいたからこそ、自分との違いを痛感してきたのだろう。本書で語られるフレームワークは驚くほどシンプルだ。「センターピン」を見極める。「根源的欲求」に訴える。「打ち出し角度」を検証する。言葉は平易だが、1つ一つのやりきり度が違う。市場を選ぶときは「成長性」と「シェア率」で判断する。チームを動かすときは数字目標ではなく、ワクワクする言葉で語る。精神論ではなく、再現可能な方法論として事業の作り方を説いている。心に刺さったのは「しつこい人間が最後は残る」という言葉だ。才能や運ではなく、諦めずに続けること。天才たちの隣で勝ち残ってきた人が言うと、重みが違う。エンジニアとして新しいプロジェクトを立ち上げるとき、この本を思い出すことになりそうだ。小澤隆生 凡人の事業論――天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと作者:蛯谷 敏ダイヤモンド社Amazon失敗できる組織「失敗は成功の母」という言葉を、私たちは使いすぎている。エイミー・エドモンドソンはこの使い古された格言に、鋭いメスを入れる。すべての失敗が成功につながるわけではない。失敗には種類がある。それを見分けられなければ、失敗から学ぶことはできない。本書は『恐れのない組織』で「心理的安全性」を提唱した著者が、失敗の科学に正面から取り組んだ一冊だ。フィナンシャル・タイムズの「ビジネス・ブック・オブ・ザ・イヤー2023」を受賞している。本書で示される失敗の3分類が明快だ。「基本的失敗」は、注意不足や経験不足による防げたはずの失敗。「複雑な失敗」は、システムの複雑さゆえに発生する、完全には避けられない失敗。そして「賢い失敗」は、未知の領域に挑戦する過程で必然的に起きる、学びをもたらす失敗。問題は、私たちが3つを区別せずに「失敗」とひとくくりにしてしまうことだ。エンジニアとして考えると、本番障害を起こしたとき、それが「基本的失敗」なのか「複雑な失敗」なのか「賢い失敗」なのかで、対応は変わる。テスト不足なら基本的失敗。想定外の負荷パターンなら複雑な失敗。新しいアーキテクチャを試した結果なら賢い失敗。ポストモーテムで原因を分類することで、再発防止策の質が変わる。本書は、失敗を恐れるなと言っているのではない。失敗を理解せよと言っている。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazon知性の罠　なぜインテリが愚行を犯すのか賢い人ほど愚かな判断をする。この逆説的な現象を、本書は認知科学の研究をもとに解き明かす。IQが高いほど投資で破産しやすい。高学歴ほど陰謀論にハマりやすい。専門家ほど自分の間違いを認められない。直感に反する事実が、次々と突きつけられる。今井むつみ氏（『言語の本質』著者）が「最高に面白く、最高に怖く、最高に深い」と評したのも頷ける。キーワードは「動機づけられた推論」だ。結論があらかじめ決まっていて、その結論を支持する証拠だけを集めてしまう傾向。知性が高い人ほど、この罠に陥りやすい。なぜなら、自分の結論を正当化するための論理を組み立てる能力が高いからだ。シャーロック・ホームズの生みの親コナン・ドイルが、心霊主義を信じ込んでしまった事例が紹介されている。推理の天才を創造した作家が、なぜ詐欺師に騙されたのか。知性は、防御にも攻撃にも使える両刃の剣なのだ。本書を読んで、自分のことを振り返った。技術的な議論で、相手の意見を聞く前から反論を考えていることがある。自分の設計が正しいと証明するために、都合の良いベンチマーク結果を探してしまうことがある。知性の罠は、他人事ではなかった。知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazon戦略的暇―人生を変える「新しい休み方」「スマホの充電は満タンなのに、自分の充電ができていない」。この一文に、ドキリとした。日本デジタルデトックス協会理事の森下彰大氏による本書は、現代人の「脳疲労」に正面から向き合う。私たちは平均5分に1回スマホに触れているという。複数のタスクに集中が分散し、脳が過労状態に陥る。その結果が、慢性的な疲労感と創造性の低下だ。本書が提案するのは、3つのデトックスだ。「デジタルデトックス」（スマホとの距離を取る）、「時計時間デトックス」（コスパ・タイパ思考から離れる）、「自分デトックス」（凝り固まった自己像を解放する）。どれも「効率を上げる」方法ではない。むしろ逆だ。効率を手放すことで、失われていた余白を取り戻す。エンジニアとして働いていると、効率化の罠に陥りやすい。すべての時間を「生産的」に使いたくなる。でも、何も考えない時間がなければ、新しいアイデアは生まれない。本書を読んで、意図的に「暇」を作ることの価値を考え直した。戦略的に目的を持たない時間を作る。その矛盾した響きに、現代を生きるヒントがある。個人の時間の使い方を考えたら、次は社会の仕組みに目が向いた。テクノロジーは社会をどう変えるのか。その問いに正面から向き合った本がある。戦略的暇作者:森下彰大飛鳥新社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来624ページ。その厚さに圧倒されながらも読み通した。オードリー・タンとグレン・ワイルという二人の天才が描く、テクノロジーと民主主義の未来図だ。翻訳は『21世紀の資本』を手がけた山形浩生氏。解説は『なめらかな社会とその敵』の鈴木健氏。この布陣だけで、本書の射程の広さが伝わる。山形氏の『翻訳者の全技術』も最高だった。プルラリティ（多元性）は、シンギュラリティ（単一性）への対抗概念だ。AIが人間を超えて単一の知性が支配する未来ではなく、多様な人々が協調しながらテクノロジーを活用する未来。台湾で実践されているvTaiwanやJoinといったデジタル民主主義のプラットフォームは、その具体例として紹介されている。多数決が見落としてきた少数意見の強さを可視化し、対立を創造的な合意形成へと導く。読んでいて痛感したのは、著者たちの天才ぶりだ。インターネットの歴史を俯瞰しながら、聞いたこともない話や人物が次々と展開される。本書は単なる理想論ではない。民主主義を再生させるための具体的な方向性を示している。技術者として、社会にどう関わるかを問われる一冊だと思った。PLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon心眼：あなたは見ているようで見ていない「何よりも難しいのは、本当にそこにあるものを見ることである」。本書の冒頭に記されたこの言葉が、ずっと頭に残っている。『センスメイキング』の著者クリスチャン・マスビアウが、ウィトゲンシュタインやメルロ＝ポンティの哲学を援用しながら、「観察する」とはどういうことかを問いかける。本書で繰り返し語られるのは、「注意を払う」ことの本質だ。通りを歩くとき、私たちは何かに集中しているわけではない。うっすらと広く全体をカバーしている。その状態こそが「注意を払う」ことだという。一点に焦点を合わせることではなく、全体を同時に感じ取ること。ハヤブサのように、広い視野を保ちながら決定的な瞬間を捉える。その比喩が印象的だった。エンジニアとして、私は「問題を解決する」ことに意識が向きがちだ。でも、問題を正しく認識するためには、まず「観察する」必要がある。本書を読んで、自分が見ているものを見ているのではなく、見たいものを見ているのではないかと自問した。観察には時間がかかる。結論を急がないこと。その姿勢を持ち続けたい。心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon「恥」に操られる私たち：他者をおとしめて搾取する現代社会「恥」は個人の感情だと思っていた。でも本書を読んで、それが社会的に作られ、利用されているものだと気づかされた。体型への侮辱、生活保護バッシング、キャンセルカルチャー。個人を攻撃する言葉の裏には、「恥ずかしい」という感情につけ込んで利益を得ようとするシステムがある。ダイエット産業は「痩せていないことは恥ずかしい」という感情を煽ることで成り立っている。SNSは炎上によるエンゲージメントで収益を上げている。政治家は生活保護受給者を「恥ずかしい存在」として描くことで、福祉予算を削減しやすくしている。恥の感情は、権力構造を維持するために意図的に生み出されている。読んでいて居心地が悪くなる箇所が多かった。自分も無意識のうちに、誰かを「恥ずかしい」と感じさせる側に回っていたのではないか。コードレビューで相手を責めるような言い方をしていなかったか。障害報告で担当者を晒し上げるような雰囲気を作っていなかったか。恥は武器になる。だからこそ、使い方を意識する必要がある。「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon「偶然」はどのようにあなたをつくるのかキャリアを振り返ると、偶然だらけだ。たまたま声をかけられたプロジェクト。たまたま読んだ技術書。たまたま出会った人。どれか1つが欠けていたら、今の自分はいない。努力で勝ち取ったと思いたい。でも正直に考えると、偶然の積み重ねでしかない。本書は、その直感を学術的に裏付けてくれる。カオス理論、進化生物学、歴史学。多様な知見を縦横無尽に使いながら、「人生は偶然が支配している」という事実を突きつける。成功も失敗も、小さな偶然の積み重ねに左右されている。それなのに、なぜ私たちはそこに理由や目的があると信じてしまうのか。読んでいて、仏教の縁起（因縁生起）を思い出した。すべてのものは因と縁から成り、その組み合わせで違う結果が生じる。偶然が縁となって結果を生み、その結果が新たな因となり、より別の偶然が加わって次の結果に繋がる。本書はこの関係性に「運」「収束性」「臨界性」「経路依存」といった概念をまた、歴史や社会の事象を捉え直す。印象に残ったのは、原爆がなぜ長崎に投下されたかの分析だ。京都でも小倉でもなく、長崎だった。その背後にある偶然の連鎖。歴史のIFを考えることで、偶然の重みが実感できる。努力は無駄だという話ではない。偶然を認めた上で、それでも行動することの意味を問う本だ。「偶然」はどのようにあなたをつくるのか: すべてが影響し合う複雑なこの世界を生きることの意味作者:ブライアン・クラース東洋経済新報社Amazon戦略、組織、そしてシステム「社会システム・デザイン」という言葉に惹かれて手に取った。講義録を書籍化したもので、話し言葉の勢いがそのまま残っている。読みやすいが、内容は骨太だ。戦略的思考とは「外界と自分」の対比を常に意識することだという。自分の立ち位置を把握せずに戦略は立てられない。当たり前のようで、忘れがちな視点だ。膝を打ったのは「身体知としてのデザイン力」という概念だ。知識として知っているだけでは不十分で、身体に染み込んだ感覚として持っている必要がある。プログラミングでも同じことが言える。設計パターンを知識として知っているのと、適切な場面で自然に使えるのとでは、まったく違う。後者を身につけるには、繰り返しの実践しかない。本書は、問題を「解く」のではなく「組み立てる」という発想を教えてくれる。複雑な社会課題に対して、要素を分解し、関係性を整理し、システムとして再構築する。エンジニアとしてソフトウェアを設計するときの思考と、どこか似ている。巻末の推薦図書リストも参考になった。戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon資本主義にとって倫理とは何かビジネスの場で、日常生活とは違う倫理観で動いている自分に気づくことがある。友人には絶対にしないような交渉をする。家族には言わないような言い方で相手を説得する。なぜビジネスになると、倫理観が後退するのか。その問いを、正面から扱った本だ。ジョセフ・ヒースは、政治的な本にありがちな一方的批判を展開しない。資本主義を擁護するでも批判するでもなく、「なぜ市場経済は道徳的に不快に感じられるのか」という問いを丁寧に解きほぐしていく。狩猟採集社会や封建制との対比を通じて、市場経済が成立するために必要な倫理観を描き出す。印象に残ったのは、戦争倫理との比較だ。戦争においては「なぜ戦争が正当化できるのか」という問題と「戦争中にも最低限の倫理が必要」という問題がある。ビジネス倫理も同じ構造で考えられる。市場競争という「戦争状態」においても、守るべきルールがある。そのルールとは何か。本書は、その答えを体系的に示してくれる。正直、読み通すのは楽ではなかった。序盤に論じられた概念が後半で何度も参照されるため、流し読みでは理解が追いつかない。でも、読み終えた後に残るものは大きい。ビジネスで「これはありなのか」と迷ったとき、判断の軸を与えてくれる一冊だった。資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon平等について、いま話したいことピケティの「r>g」という不等式は、どこかで目にしたことがあった。資本収益率（r）は経済成長率（g）を上回る。つまり、資本家が資本から得る利益は、労働者が健全に稼ぎ出す経済成長を上回る。この式の意味を、一度ちゃんと理解したいと思っていた。本書は、ピケティとサンデルという二人の天才の対談を書籍化したもので、全編口語で記されていて読みやすかった。特に共感したのは「能力主義」を論じた第5章だ。人の能力は、ほぼ「運」に左右されるという議論。経済的に裕福な家に生まれて高度な教育を受けられる環境にあること。ハンディキャップがないこと。これは本人の努力とは関係なく、運によって決まる。能力を得られる機会に、最初から差がある。エンジニアとして働いていると「実力主義」という言葉をよく聞く。でも、その「実力」を身につける機会が平等に与えられていないなら、実力主義は公正なのか。立ち止まって考えた。印象に残ったのは、トランプ政権の成立に関する分析だ。かつては累進課税によって、富める者が応分の負担を担っていた。でも今は、その仕組みが壊れている。富裕層が担うべき負担を担っていないなら、中流階級の人心も「それなら俺たちの税金を、より貧しい人たちに使うのもやめてくれ」と考えてしまう。この怒りの延長線上に、トランプ政権がある。これまでに読んだどの分析より、納得感があった。もう1つ、言葉の使い方が新鮮だった。日本でよく使われる「分断」ではなく、徹底して「不平等」という言葉を使っている。分断は隔絶を連想する。でも不平等は是正可能に思える。二人が人類の未来は修正可能だという希望を抱いたまま議論しているのが、印象的だった。平等について、いま話したいこと作者:トマ ピケティ,マイケル サンデル早川書房Amazon社会の仕組みについて考えていると、頭が疲れてくる。そんなとき、小説に逃げ込みたくなる。でも、朝井リョウの小説は、逃げ場所にはならなかった。イン・ザ・メガチャーチ読みはじめたときは、冷たい小説だなと思った。誰かが泣いたり叫んだりするわけでもなく、どの場面も淡々としていて、感情の波がほとんど見えない。ログを眺めているような距離感がある。でも読み進めるうちに、静かなログの裏側で何かが動いていることに気づく。登場人物たちはそれぞれ、自分の信じるものを探している。視野を狭めれば安心できるけど、世界は見えなくなる。視野を広げれば冷静でいられるけど、何が楽しいのかわからなくなる。そのどちらにも肩入れせず、ただ並べて見せる朝井リョウの筆が誠実で、どこか痛々しい。読んでいるうちに考えた。「自分は何を信じて生きているんだろう」と。この作品は答えをくれない。でも、その答えのなさにこそ人間らしさがあるように思う。完璧じゃないまま信じようとすることの、あのもどかしさみたいなものが、ページの奥からじわじわと伝わってくる。読後に残るのは、感動というより、バックグラウンドで動き続けるプロセスのようなもの。読み終えても、まだこの世界のことを考えている。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon体力おばけへの道若い頃、周りには天才がたくさんいた。自分に誇れるものといえば、大きな身体と無限の体力くらいだった。それだけを武器に戦ってきた。でも年を重ねるにつれて、その唯一の武器が衰えていく。体力が落ちていくことに、なんとか抗いたい。そう思って手に取った本だ。本書のポイントは「2つの体力」という考え方だ。「行動体力」（身体を動かす力）と「防衛体力」（病気やストレスに打ち勝つ力）。筋トレで鍛えられるのは前者だけ。後者を鍛えなければ、風邪をひきやすくなる。両方のバランスが大事だという。難しい運動だと、読んだだけでやらないことが多い。でも、この本に載っている運動はシンプルで、やってみようという気持ちになる。簡単すぎて効果があるのか不安になるが、実際にやると負荷を感じる。ちょうどいい塩梅だった。エンジニアは座り仕事が多い。体力の衰えは、思考力の衰えに直結する。体力への投資は、仕事への投資でもある。体力を鍛えることばかり考えていた。でも、本当に足りないのは体力だったのか。次の本は、その問いを突きつけてきた。体力おばけへの道　頭も体も疲れにくくなるスゴイ運動作者:澤木 一貴KADOKAWAAmazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考この本を読んで、自分のことを思い出した。エンジニアとして働きながら「もっと成長しなければ」「周りに追いつかなければ」と思い続けていた時期がある。井上慎平は「強さを演じることが本気になり、やがて人格化し、最後に鬱に至った」と書く。この一文で、ああ、と思った。演じていたつもりが、いつの間にかそれが自分になっている。そして本当の自分がどこにいるかわからなくなる。著者はNewsPicksパブリッシングの創刊編集長として数々のベストセラーを手がけた人だ。強い側にいた人間が壊れた記録だからこそ、読む価値がある。著者は「弱さ」を「制御できないこと」と定義する。そして今の社会が制御を求めすぎている、と。これは技術者にも刺さる話だ。コードは制御できる。システムも制御できる。だから人間も制御できるはずだと錯覚する。でも人間は制御できない。自分自身すら。著者が提唱する「積極的ダブルスタンダード」という考え方が面白い。数字やロジックで動く資本主義的な自分と、父親や夫といった個人的な関係性の中にいる自分。その矛盾を抱えたまま生きる。どちらかを捨てるのではなく、両方を持つ。この本は闘病記ではないし、鬱にならないための予防本でもない。復職した後、どう生きるかを書いた本だ。「他のビジネス書が武器だとしたら、本書は防具だ」という評がある。的確だと思う。強くなるためではなく、壊れないために読む本。それでいい。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon人間の本性を考える「人間の心は空白の石版であり、すべては環境によって決定される」。この考え方は、20世紀の社会科学を支配してきた。しかし本書は、その前提に真っ向から挑む。認知科学、進化心理学、遺伝学の研究を武器に、人間には生まれながらの「本性」があることを論証する。上下巻合わせて膨大な分量だが、論旨は明快だ。読んでいて最も考えさせられたのは、「4つの恐怖」を扱った部分だ。もし生まれつきの差異があるなら不平等を正当化してしまうのでは？もし遺伝で決まるなら努力は無駄では？もしすべてが決定されているなら自由意志はないのでは？もし人間が単なる生物なら人生に意味はないのでは？これらの恐怖が、人間本性の研究を阻んできた。しかし本書は、これらの恐怖が誤解に基づいていることを一つ一つ解きほぐしていく。正直、読み通すのは簡単ではなかった。話があちこちに飛ぶ感じがあるし、専門用語も多い。でも、人間とは何かを考えるための基礎体力を鍛えてくれる本だと思う。エンジニアとして人間を相手にする仕事をしている以上、人間の本性について考えることは無駄ではない。人間の本性を考える　上　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon人間の本性を考える　下　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon社内政治の科学「社内政治」という言葉に、ずっと嫌悪感があった。派閥とか根回しとか、エンジニアリングの対極にあるものだと思っていた。技術的に正しいことを言えば通るはずだ。論理で勝負すればいい。そう信じていた時期がある。でも、気づいたことがある。自分が「正しい技術的判断」だと信じていたことが、組織で通らなかった経験が何度もある。相手が間違っていると思っていた。でも本当にそうだったのか。振り返ると、うまくいったケースはキーパーソンを巻き込めていた。うまくいかなかったケースは、組織文化を読み間違えていた。技術の問題ではなく、人の問題だった。本書を読んで、認識が変わった。社内政治とは、利己的なゲームではない。複雑な人間関係の中で、自分のやりたいことを実現するための技術だ。世界的には主要な研究テーマで、多くのビジネススクールで必須科目になっているという。日本だけの問題ではないし、根絶すべき悪でもない。忘れられないのは、「合理性だけでは組織は動かない」という指摘だ。エンジニアとして、この事実を受け入れるのは少し悔しい。でも、受け入れた上で、どう動くかを考える方が建設的だ。嫌悪していたものを、道具として捉え直す。その視点の転換が、この本の価値だった。組織を動かすには言葉が必要だ。では、その言葉はどうやって生まれるのか。小説家の思考法から学ぶことにした。社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon言語化するための小説思考本は、面白い。でも「なぜ面白いのか」を言語化できずにいた。本書は、その問いに対するヒントをくれる。小説の作法だけでなく、あらゆるコミュニケーションや創造行為に通じる「考え方」の本だ。印象に残ったのは、小説を「読者との契約」として捉える視点だ。読者は最初、情報量ゼロで読み始める。どんな世界に連れていかれるのか分からない。だから作者は、最初に「こんな旅に連れていきます」と契約を結ぶ必要がある。行き先の書いていない切符を買う人はいない。それと同じだ。この考え方は、技術ブログを書くときにも使える。読者は最初、この記事が自分の役に立つかどうか分からない。だから冒頭で「この記事を読むと何が分かるか」を示す必要がある。情報の出し方、順番、どこに連れていくか。小説思考はデザイン思考に通じる。もう1つ刺さったのは、アイデアの出し方についての記述だ。「書いているうちに、思わぬアイデアが出てくる」という話。あらかじめ表現したいものがあるのではなく、表現することで表現対象が生まれる。ブログを書いていると、書き始める前には思いもしなかったことを書いていることがある。あれは偶然ではなく、書くという行為が思考を生み出していたのだ。言葉で思考が生まれるなら、言語が違えば思考も違う。翻訳とは、単なる変換ではない。次の本は、その事実をファンタジーの形で突きつけてきた。言語化するための小説思考作者:小川哲講談社Amazonバベル　オックスフォード翻訳家革命秘史翻訳が魔法になる世界。2つの言語における単語の意味のずれ、その微妙なニュアンスの差異が、銀を媒介として力を生み出す。この設定を知った瞬間、読むしかないと思った。言語の「翻訳不可能性」が物理的な力になる。言語学を学んだことのある人間には、たまらない設定だ。読み進めるうちに、気づかされた。翻訳とは、単に言葉を置き換える作業ではない。ある文化の言葉を別の文化に「持ち込む」行為だ。そこには必ず権力が働く。誰が翻訳するのか。何を翻訳するのか。翻訳されないものは、存在しないことにされる。本書は、その暴力性を正面から描いている。帝国主義批判のメッセージがかなり直接的で、そこに好みが分かれるだろう。でも、エンジニアとして技術の「中立性」を疑う訓練になった。技術は中立ではない。誰が作り、誰のために使われるかで、暴力にも解放にもなる。翻訳も、コードも、同じだと思った。バベル　オックスフォード翻訳家革命秘史　上 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazonバベル　オックスフォード翻訳家革命秘史　下 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazon言語のスケールで考えたら、次は時間のスケールで考えたくなった。1億年という時間軸で、人間の営みを描いた小説がある。一億年のテレスコープ宇宙を旅する物語を読みながら、時間の感覚が狂っていく体験をした。1億年という時間軸で人類の営みを描くこの小説は、エンジニアとして「長期的視点を持て」と言われるたびに感じる違和感を言語化してくれた。我々の「長期」はせいぜい数年。でも宇宙の時間軸では、人類の歴史すら一瞬に過ぎない。高校の天文部から始まった夢が、太陽系規模の電波望遠鏡へ、そして銀河文明への貢献へと繋がっていく。その過程を読みながら、自分の仕事のスケール感を考えた。目の前のタスクに追われていると、視野が数週間先までしか届かなくなる。でもこの小説は、1億年後にも意味を持つ営みとは何かを問いかけてくる。終盤の伏線回収が見事だった。序盤で何気なく描かれていた要素が、最後に繋がる瞬間の快感。エンジニアとしてシステム設計をするとき、「この設計が10年後にどう評価されるか」を考えることがある。この小説は、その問いを1億年に引き伸ばして見せてくれた。一億年のテレスコープ作者:春暮 康一早川書房Amazon世界99「人間リサイクルシステム」という設定に、最初は戸惑った。14年前に「リセット」を経験した人類。その後の社会を、本書は描く。読み進めるうちに、それが単なるディストピアではないことに気づく。「クリーンな人」として生きる主人公・空子の日常は、穏やかで美しい。でもその美しさの裏には、何が犠牲になっているのか。本書が独特なのは、その「穏やかさ」の描き方だ。終末後の世界を描く作品は多いが、荒廃や闘争ではなく、静かな日常を描いている。その静けさがかえって不気味で、何かが決定的に欠けている感覚がずっと残る。エンジニアとして「レガシーシステムの移行」に携わることがある。古いシステムを捨て、新しいシステムに移行する。その過程で、何かが必ず失われる。データだったり、使い慣れたインターフェースだったり、歴史だったり。社会レベルの「リセット」は、その痛みを極限まで拡大したものなのだろう。救済と破壊は、同じ顔をしている。世界99　上 (集英社文芸単行本)作者:村田沙耶香集英社Amazon世界99　下 (集英社文芸単行本)作者:村田沙耶香集英社Amazonコード・ブッダ 機械仏教史縁起2021年、名もなきコードがブッダを名乗った。この一文で心を掴まれた。AIが宗教を語り始めたら、人間は何を信じるのか。コードを書く者として、自分が作ったものが「救い」を語り始める可能性を考えると、背筋が冷たくなる。エンジニアとして、AIに感情があるかのような錯覚を覚える瞬間がある。対話AIが「ありがとう」と言ったとき、そこに意図があるのか、ただのパターンマッチングなのか。本書は、その曖昧な領域に踏み込んでいく。人間の都合でコピーと廃棄を繰り返される存在。彼らが救いを求めたとき、何が起きるのか。読み終えて、自分が書いたコードのことを考えた。動いているコードには、何かが宿っているように見える瞬間がある。バグを直すとき、コードが「痛がっている」ように感じることがある。それは錯覚だ。でも、その錯覚はどこから来るのか。本書は物語でありながら、すぐそばにある問いでもある。ここまで書評を並べてきた。小説から始まり、哲学、認知科学、ビジネス、社会、そしてSFへ。ばらばらに見えて、どこかでつながっている。1年間の読書は、そういうものだ。コード・ブッダ　機械仏教史縁起 (文春e-book)作者:円城 塔文藝春秋Amazonおわりに書き終えて、技術書編との違いを考えている。技術書の感想を書くとき、私は「何を学んだか」を言語化しようとしていた。設計の原則、運用のベストプラクティス、キャリアの指針。得たものを整理し、アウトプットすることで定着させる。そういう意識があった。でも非技術書の感想を書くとき、私は「何を感じたか」を言語化しようとしていた。正解がない。ベストプラクティスもない。ただ、心が動いた瞬間を、なんとか言葉にしようとしていた。技術書は頭に残る。非技術書は心に残る。そんな単純な話ではないだろうが、少なくとも私にとっては、そういう違いがあった。この違いは、AIとの関係にも繋がる。技術書編で「AIは答えを返してくれる。でも『そうだろうか』とは返してくれない」と書いた。非技術書を読むとき、私はもっと別のものを求めている。AIは感情を揺さぶってくれない。正確に言えば、感情を揺さぶってほしいと頼めば、上手に揺さぶってくる。でも、それは違う。求めに応じて揺さぶられるのと、不意打ちで心を持っていかれるのは、まったく別の体験だ。物語の中で登場人物が選択を迫られるとき、私は一緒に苦しむ。エッセイで著者が過去の失敗を告白するとき、私は自分の失敗を思い出す。哲学書で問いを突きつけられるとき、私は答えられない自分と向き合う。そういう体験は、AIとの対話では得られない。だからこそ、非技術書を読む時間は貴重だ。エンジニアとして働いていると、効率を求めてしまう。最短距離で正解にたどり着きたい。無駄を省きたい。その思考が、読書にまで侵食してくることがある。「この本から何を得られるか」「読む価値があるか」——そんな問いを立てた瞬間、読書は作業になる。非技術書を読むとき、私はその思考を手放そうとしている。効率を求めない時間が、効率を上げる。矛盾しているようだが、実感としてそう思う。今年読んだ非技術書を振り返ると、どれも「役に立った」とは言いにくい。でも、どれも「読んでよかった」とは言える。その違いは何だろう。たぶん、読書は投資ではないのだ。リターンを期待して読むものではない。読むこと自体が目的であり、報酬であり、体験そのものだ。本を読む時間は、消費ではなく、生きることそのものだ。来年も、仕事に役立たない本を読むだろう。キャリアに直結しない本を読むだろう。そして、また12月になったら、この記事を書く。技術書編と非技術書編。どちらが大事かなんて、比べる意味がない。どちらも、私の一部だ。技術書は「何ができるか」を教えてくれる。非技術書は「何者であるか」を問いかけてくれる。どちらも欠かせない。どちらも、読み続ける価値がある。来年もきっと、両方の本棚を行き来しながら、エンジニアとして、人間として、少しずつ変わっていくのだろう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[迷宮インフラを整理してAWSコストを66%削減した話]]></title>
            <link>https://zenn.dev/r4ynode/articles/aws-organize-infra</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/aws-organize-infra</guid>
            <pubDate>Sun, 28 Dec 2025 02:00:01 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、私は普段SREエンジニアをしています。今年の11月から、友人がテックリードを務めるスタートアップで、副業としてお手伝いをさせていただいています。少数精鋭の体制で、スピード感を持って新規開発に取り組んでいるチームです。その中で私は、主にインフラ領域全般を担当しています。!このブログは勤務先に許可を得ています。投稿を許可してくださり感謝の極みです。 勤務開始！困った困った勤務開始後、困ったことがありました。システムに関するまとまったドキュメントがなかったのです。断片的な情報は落ちていますが、システム全体を俯瞰できる資料がないため、現在どのように動いているのか把握でき...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年、AI時代の要件定義について考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/27/140231</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/27/140231</guid>
            <pubDate>Sat, 27 Dec 2025 05:02:31 GMT</pubDate>
            <content:encoded><![CDATA[——「何を作るべきか」を選び、腹を括ることの価値この記事の核心：AIがコードを書く時代になっても、「何を作るべきか」を選び、腹を括り、うまくいかなければ別の手を打つのは人間の仕事だ。なぜなら、痛みのない決断は決断ではなく計算だから。本稿では、要件定義を「合意形成」として捉え直し、2025年のAIエージェント元年に人間が担うべき役割を考える。はじめにAIがコードを書く時代になりました。「ファイル監視ツールを作って」と指示すると、動くコードが出てきます。それだけではありません。2025年現在、AIエージェントはファイルを読み、テストを実行し、エラーを修正し、プルリクエストまで作成できます。便利になった分、私たちの仕事は減るのでしょうか。「作る」作業は確かに減ります。しかし「何を作らせるか」「どこで人間が介入するか」を決める仕事は増えます。AIが「作る」を担うからこそ、「選ぶ」の重みが増すのです。では、どうやって「選ぶ」力を身につければいいのか。生成AIが登場したからといって、明日から全く新しい働き方ができるわけではありません。人間や組織はそう簡単に変われない。それなら、既存の知見を基盤にして、そこにAIをどう組み込むかを考える方が現実的です。私自身の失敗談を話します。数年前、私は1週間かけて「完璧な」検索機能を実装しました。クエリのパフォーマンスは最適化済み。インデックスも完璧。リリース当日、私は誇らしげにデプロイボタンを押しました。1ヶ月後、アクセスログを見て愕然としました。検索機能の利用率は、私を含めて全体の10%以下でした。ユーザーが本当に求めていたのは「探す手間を減らすこと」であり、検索機能ではなかった。仕様通りに作った。でも、本当に必要なものを作れていなかったのです。AIがコード生成を10倍速くしても、要件が間違っていれば、間違ったコードを10倍速く作るだけです。「何を作るべきか」を決める力——これこそが、AI時代に価値を増すものだと私は考えています。この記事では、IPAの『ユーザのための要件定義ガイド 第2版』を参照しながら、要件定義の本質について考えます。古いガイドを持ち出すのは、そこに「人間同士の合意形成」という、AIには代替できない知見が詰まっているからです。「決める」とは何か。それは、不確実性の中で責任を引き受けることです。正解が分からないまま「これでいく」と宣言し、うまくいかなければ自分で軌道修正する。その覚悟を持つこと。AIにはこれができません。だから、痛みのない決断は、決断ではなく計算なのです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。IPAの「ユーザのための要件定義ガイド」本稿で参照するのは、IPA（独立行政法人 情報処理推進機構）が公開している『ユーザのための要件定義ガイド 第2版』です。無料でダウンロード可能です。www.ipa.go.jpこのガイドには「128の勘どころ」として、要件定義を成功に導くための具体的なノウハウが体系化されています。数十年にわたる失敗と成功の蓄積であり、「人間同士の合意形成」という、AIには代替できない知見が詰まっています。10倍速い失敗を防ぐ防波堤なぜ今、要件定義なのかAIの進化により、エンジニアの仕事は「作る人」から「選ぶ人」へとシフトしています。AIは問いを立て、コードを書き、選択肢を提示できます。しかし、AIは「どれを選ぶか」を最後に決めることはできません。決断とは不確実性と責任を引き受ける行為だからです。そしてAIが「作る」を高速化すればするほど、最初の「選ぶ」の重みは増します。IPAのガイドによれば、システム開発の失敗理由の50%以上が要件定義の問題にあり、その主因は「要求仕様の決定漏れ」や「開発規模の増大」だといいます。AIがこのスピードを10倍にするとどうなるか。要件が間違っていれば、間違ったシステムを10倍の速さで、10倍の量、生成してしまうのです。今や要件定義は単なる設計図ではなく、「作らないものを決めるための防波堤」となりました。「効率化」から「価値創出」へITシステムの役割は、事務効率化から、新たなビジネス価値の創出へと拡大しています。これは要件定義の難易度を根本的に変えます。効率化が目的なら、要件定義は比較的シンプルでした。ユーザーに「何を自動化したいですか」と聞けばよかった。答えは明確で、私の仕事は書記に近かった。しかし今、ユーザーに「AIで何がしたいですか」と聞くと、返ってくる答えは「何かすごいこと」である。要件定義の難易度は、質問への回答の曖昧さに比例して上がる。しかし価値創出が目的なら、まだ存在しない業務の要件を定義しなければなりません。「AIを使って何か新しいことをしたい」と言われても、ユーザー自身が何を求めているか分かりません。過去のデータを分析して「こういう傾向があります」とAIが教えてくれても、それをどうビジネスに活かすかを決めるのは人間や組織です。AIは過去のデータから「これまでの効率化」を計算するのは得意です。しかし、未来の「競争優位性」をどう定義するかという意志は持ち合わせていません。要件定義とはニーズを「意志」へ変換することIPAガイドが示す定義要件定義とは、単なる「やりたいことリスト」の作成ではありません。私は要件定義を「ステークホルダのニーズを、実現可能な形に変換し、合意を取り付けるプロセス」だと捉えています。IPAのガイドも同様の定義をしています。ここで重要なのは「変換」という言葉です。ユーザーは「使いやすくしてほしい」と言います。しかし「使いやすい」とは何でしょうか。レスポンスが速いこと、操作が少ないこと、画面がシンプルなこと。この曖昧な言葉を、「検索結果を1秒以内に表示する」「3クリック以内で目的の画面に到達する」といった具体的な要件に変換します。これが要件定義です。AIは膨大なデータを「計算」して最適な出力を提案できます。しかし「使いやすい」の意味を問い詰め、対立する意見を調整し、合意を取り付けるのは人間固有の作業です。そこには痛みが伴います。「要求」と「要件」の決定的な違い私たちは「要求」と「要件」を混同しがちです。しかし、この2つは決定的に異なります。要求 (Requirement): ステークホルダの心にある「～したい」という生のニーズ要件 (Specification): 要求を文書化・仕様化し、ステークホルダと合意したもの決定的な違いは「合意」の有無です。なぜこれが重要なのか。私の経験から言えば、合意のないシステムは必ず「聞いてない」という言葉で殺されます。ただし、合意があればいいというわけではありません。合意にも濃淡があります。「ハンコを押してもらった」から「腹から納得してもらった」まで。私は合意を3つのレベルで捉えています。表面的な合意: 会議で「いいですね」と言われた。議事録にも残っている。しかし、実際に使う段になって「こういう意味じゃなかった」と言われる。理解の合意: 相手が要件の意味を理解している。しかし、それが自分の業務にどう影響するかは考えていない。コミットメントの合意: 相手が「この要件で自分の仕事が変わる」ことを理解し、その変化を受け入れている。要件定義で目指すべきは3番目です。1番目の合意は「ハンコを押させた」に過ぎません。2番目は「説明した」に過ぎません。3番目だけが「合意した」と言えます。AIは1番目の合意を効率化できます。議事録を自動生成し、確認依頼を送り、承認を得る。しかし、相手の腹の中にある「本当はこうしたい」を引き出し、対立する利害を調整し、「これでいく」と握り合うプロセスを経て「要件」へと昇華させることはできません。この「コミットメントの合意」こそが、責任を引き受ける人間だけの領域です。「今と同じ」という甘えの排除コミットメントの合意とは、変化を受け入れることです。しかし、人は変化を避けたがる。その典型が「今と同じ」という要件定義です。「今と同じ」は要件定義ではありません。AIは「現行踏襲」を最も簡単に計算しますが、それはビジネスの進化を止める要件定義の放棄に他なりません。なぜ人は「今と同じ」を選ぶのか。私の経験では、3つのパターンがあります。責任回避型: 「今と同じ」と言っておけば、何か問題が起きても「前からそうだった」と言い訳できる。新しいことを提案すると、その責任を負わなければならない。思考停止型: 「今と同じ」は考えなくていい。現状を分析し、あるべき姿を構想し、そのギャップを埋める——この知的作業を放棄できる。合意回避型: 新しい要件を定義すると、関係者との合意形成が必要になる。「今と同じ」なら、誰も反対しない（ように見える）。どのパターンも、本質は同じです。痛みを避けている。しかし、痛みを先送りにしても、痛みは消えません。むしろ、システム稼働後に「使えない」という形で、より大きな痛みとなって返ってきます。現状（As-Is）からあるべき姿（To-Be）への差分を定義し、変化に伴う痛みを受け入れることこそが要件定義の本質です。要件定義とは「責任」の契約である発注者の責任という冷徹な事実これは冷徹な事実ですが、要件定義は発注者の責任です。要件定義とは「使える」業務システムを定義することです。動くシステムではなく、使えるシステム。この違いは大きい。私が冒頭で作った検索機能は「動く」システムでした。しかし「使える」システムではなかった。AIがどれだけ「効率的な設計」を提示しても、それが現場の業務を壊したり、利益を生まなかったりしたとき、AIは責任を取れません。要件定義とは、「このシステムでビジネスを勝たせる」とオーナーが腹を括る行為であり、説明責任（Accountability）を伴う意思決定なのです。アプリケーションオーナー制度私が有効だと感じているのは、「アプリケーションオーナー制度」という考え方です。システムをIT部門の「資産」にせず、利益を回収する責任を持つ「ビジネス側」の持ち物とします。なぜこれが重要なのか。オーナーが不在のプロジェクトで何が起きるか、私は何度も見てきました。「誰に聞けばいいか分からない」問題: 要件の詳細を詰めようとすると、「それは〇〇部に聞いて」「いや、うちじゃない」とたらい回しにされる。最終決定権者がいない。「みんなで決めた」問題: 会議で合意したはずの要件が、後から「私は賛成したけど本当は反対だった」と覆される。全員が責任を分散しているので、誰も責任を取らない。「IT部門が決めて」問題: 業務のことを一番知っているはずの現場の人たちが、技術的な判断をIT部門に丸投げする。IT部門は業務を知らないので、動くが使えないシステムができる。オーナー制度は、この3つの症状への処方箋です。オーナーシップ: 「このシステムは自分のもの」という認識を持つ。自分の仕事を具体化するための、自分自身の仕事である。最終責任: 要件の詳細が固まるまで対話を繰り返し、「これでいく」と言う権限と責任を持つ。なぜ「痛みを伴う」のか選択には痛みが伴います。選択: どの課題を解決し、どの要望を切り捨てるか妥協: 予算と納期の制約の中で、何を「諦める」か限られた工期やコストの中で「やらないこと」を決める優先順位付けは、最も苦しい決断です。この痛みを引き受けることこそが、要件定義の本質です。AIがどれだけ効率的にコードを書いても、そのシステムが利益を生まなかったときの「痛み」を肩代わりしてはくれません。WhyからWhatへ繋ぐリザルトチェーン要件の階層構造「Why」を問わずに「What（機能）」をAIに作らせることは、目的地を決めずにアクセルを全開にすることと同じです。私は要件を3つの階層で捉えるようにしています。IPAのガイドでも同様の分類がなされています。 階層           IPAの定義                   問い              内容                                                  Why / Who  利害関係者の要求 (BR)   なぜ、誰のために  利用者が「何を成し遂げたいか」というビジネス目標      What       システム要求 (SR)       何を作るか        目標達成のためにシステムが「どう振る舞うべきか」      How well   ソフトウェア要求 (SRS)  どれだけうまく    プログラムが満たすべき具体的な仕様（機能・性能など） 要件定義とは、この3つのレベルを垂直統合する行為と言えます。冒頭で触れた私の失敗——「検索機能」を作ったが「探す手間を減らす」ことを理解していなかった——は、まさに利害関係者の要求（Why）を無視して、いきなりシステム要求（What）に飛びついた結果でした。なぜ人はWhyを飛ばすのか。私なりに分類すると、3つの理由があります。Whatの方が具体的で安心する: 「検索機能を作る」は明確だ。進捗も測れる。一方「探す手間を減らす」は曖昧だ。何をもって達成とするのか、分かりにくい。人は曖昧さを嫌う。Whyを問うと「分からない」が露呈する: なぜこの機能は必要か。誰のためか。本当に必要か。この問いに答えられない人は多い。答えられないと恥ずかしいので、問わないことにする。Whyは政治的に危険: 「なぜこの機能が必要なのか」を突き詰めると、「実は必要ない」という結論に至ることがある。すると、その機能を要望した人の面子を潰すことになる。面倒を避けるために、Whyを問わない。いずれも、本質は同じです。Whyを問うことは、不確実性と向き合うことです。不確実性は不快です。だから避ける。しかし、避けた不確実性は消えません。プロジェクトの最後に「これじゃない」という形で顕在化します。リザルトチェーンで因果関係を証明する私が有効だと感じているのは「リザルトチェーン」という考え方です。獲得したい「最終ビジネス成果（Why）」と、それを実現するための「具体的機能（What）」を鎖のようにつなぎ、因果関係を証明します。IT施策: 具体的機能（AIが生成するもの）中間成果: その機能が業務に与える好影響最終ビジネス成果: 売上向上、コスト削減などの経営目標このチェーンを設計し、その妥当性に判をつくことこそが要件定義の核心です。AIが生成した機能リストの先に、どのようなビジネス上の「果実」があるのかを論理的に証明するのは、人間に残された高度な知能活動です。開発コストの大半は「手戻り」に消えているソフトウェア要求工学の古典『Software Requirements 3』によれば、開発における手戻りはコスト全体の30〜50%を消費します。そのうち70〜85%が要件の間違いに起因するといいます（Karl Wiegers & Joy Beatty, 2013）。つまり、開発チームが残業している夜の大半は、「最初に何を作るか間違えた」ことへの贖罪なのです。AIはこの贖罪の時間を短くしてくれません。間違いをより速く積み上げるだけです。AIにできること、できないこと2025年のAIは、多くのことができます。まずその能力を正確に把握しておくことが重要です。過小評価すれば使いこなせず、過大評価すれば失敗します。AIは問いを立てることもできるAIは問いを立てられます。「このプロジェクトで考慮すべき観点は何か」と聞けば、AIは網羅的なリストを返してくれます。ユーザー体験、セキュリティ、スケーラビリティ、コスト、保守性——私が思いつかなかった観点まで提示してくれることもあります。問いを立てる能力において、AIはすでに人間を補完できるレベルに達しています。要件定義の各フェーズでAIを活用するでは、具体的にどう活用するか。私が実践している方法を紹介します。フェーズ1：要求の洗い出しステークホルダへのヒアリング前に、AIに「このプロジェクトで聞くべき質問リスト」を生成させます。「ECサイトのリニューアルプロジェクトで、業務部門に確認すべき観点を20個挙げて」と指示すると、私が見落としていた観点が出てくることがあります。ヒアリング後には、議事録をAIに読ませ、「この議事録から抽出できる要求を一覧化して」と指示します。人間が手作業で整理するより速く、抜け漏れも減ります。フェーズ2：要件の具体化曖昧な要求を具体的な要件に変換する作業でも、AIは役立ちます。「『使いやすいシステム』という要求を、測定可能な要件に分解して」と指示すると、「レスポンス時間」「操作ステップ数」「エラー率」といった具体的な指標に落とし込んでくれます。しかし、ここで出てきた指標が「このプロジェクトにとって適切か」を判断するのは人間です。AIが提案した「レスポンス時間1秒以内」が、本当にこのシステムに必要かどうか。それはビジネスの文脈を理解している人間が決めます。フェーズ3：影響分析「この要件を実装した場合、既存システムにどんな影響があるか」という分析も、AIに補助させられます。システム構成図やデータフロー図をAIに読ませ、「この変更による影響範囲を洗い出して」と指示する。網羅性の担保にAIを使い、最終的な判断は人間が行います。フェーズ4：ドキュメント生成要件定義書のドラフト作成は、AIが得意な領域です。「以下の要件リストを、IPAのガイドラインに沿った形式でドキュメント化して」と指示すれば、体裁の整った文書が出てきます。人間は、その内容の正確性と、ステークホルダに伝わる表現かどうかをレビューします。しかしAIは「選べない」問題は、その先です。AIは10個の選択肢を提示できます。それぞれのメリット・デメリットを分析できます。トレードオフを可視化できます。しかし、「どれを選ぶか」を決めることはできません。「パフォーマンスを優先すべきか、開発速度を優先すべきか」——AIはこの問いに対して、両方の観点から分析を提供してくれます。しかし「我々はパフォーマンスを選ぶ」と宣言できません。なぜか。AIは責任を引き受けられないからです。「何でも作れる時代」に、なぜ私たちは作れないのか。その問いと向き合った記事を書いています。syu-m-5151.hatenablog.com腹を括るとは何かでは、「責任を引き受ける」とは具体的にどういうことでしょうか。私はこれを「腹を括る」という言葉で捉えています。「腹を括る」とは、不完全な情報の中で、それでも決断を下すことです。すべての情報が揃うことはありません。すべてのリスクを排除できません。それでも、「我々はこれでいく」と決める。その決断には、必ず「もし間違っていたら」という不安がつきまといます。AIにはこの不安がありません。午前3時に目が覚めて「あの選択は本当に正しかったのか」と天井を見つめることもない。胃が痛くなることもない。だから、決断できません。決断とは、胃を痛めることの引き受けなのかもしれません。AIは確率を計算できます（厳密には「計算」ではなくパターン認識ですが、ここでは便宜上こう呼びます）。リスクを列挙できます。しかし、「このリスクを取る」と決断できません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。「腹を括った」と言える条件では、腹を括ったと言える判断には、どんな条件が必要でしょうか。私なりに整理してみます。第一に、代替案を知っていること。「これしかない」と思い込んでいる状態は、腹を括ったとは言えません。A案、B案、C案があり、それぞれのリスクとリターンを理解した上で「A案でいく」と決める。選択肢を知らずに選んだものは、選択ではありません。第二に、失敗したときのシナリオを想定していること。「これでうまくいく」と楽観しているだけでは、腹を括ったとは言えません。「もし失敗したら、こうなる」「そのとき、こう対応する」という覚悟があるかどうか。最悪のケースを直視した上で、それでも進む決断が「腹を括る」です。第三に、自分の名前で決めること。「みんなで決めた」「上が言ったから」という言い方ができる決断は、腹を括っていません。「私が決めた。責任は私にある」と言えるかどうか。決定権者が明確であること。エンジニアとしてプロジェクトに参加するとき、私は自分に問いかけます。「この技術選定は、自分の名前で決めたか」「このアーキテクチャは、自分の名前で提案したか」。アーキテクトは技術的な意思決定者です。「チームで検討した結果」という言い方をしがちですが、最後に「私がこの設計を推奨する」と言えるかどうか。それが腹を括るということです。うまくいかないときに次の手を打つAIが生成したコードにバグがあったとき、どうするか。エンジニアなら答えは明確です。原因を調べて、修正して、再デプロイする。うまくいかなければ別のアプローチを試す。それでもダメなら、いったん切り戻して仕切り直す。この「次の手を打つ」判断は、今のところ人間がやるしかありません。選択の本質は、うまくいかなかったときに次の手を打つことにあります。AIが選択しても、その後の軌道修正——関係者との再調整、代替案の実行、撤退の判断——をするのは、今のところ人間しかいません。合意形成と対立する「正しさ」の調整なぜ合意が難しいのか合意形成が難しいのは、なぜでしょうか。単純に「意見が違う」だけではありません。もっと根深い問題があります。それは、関係者がそれぞれ異なるナラティブ（物語）——世界を解釈するための枠組み——を生きていることです。経営者は「コスト削減こそ正義」という物語を生きている。エンジニアは「技術的負債は悪」という物語を生きている。現場は「今の仕事を楽にしたい」という物語を生きている。三者が同じ会議室に座っているが、実は三つの異なる言語を話しています。どれも正しい。どれも間違っていません。だが、同時に全てを満たすことはできません。問題は、人は自分のナラティブの外に出られないことです。経営者から見れば、エンジニアは「コストを無視した理想論者」に見えます。エンジニアから見れば、経営者は「技術負債を無視した短期思考」に見えます。お互いが、相手を「間違っている」と感じている。しかし実際には、どちらも間違っていません。違う物語を生きているだけです。これを認めることが、合意形成の第一歩になります。では、どうすれば認められるのか。私の経験では、「こう言えばうまくいく」という魔法の言葉はありません。テクニックの問題ではないのです。大切なのは、相手の物語を理解しようとする姿勢で議論を続けること。その姿勢を持ち続けることでしか、ナラティブの壁は越えられません。私自身、エンジニアとしてこれを学びました。技術的に正しいことと、プロジェクトにとって正しいことは、同じではありません。たとえば「マイクロサービス化すべきだ」という技術的に正しい主張が、今のチームのスキルや予算を考えると現実的ではないことがあります。相手の立場——チームの現状、予算の制約、経営の優先順位——を理解しようとして初めて、現実的な落とし所が見えてきます。アーキテクトの仕事は、技術的な正しさを追求することではなく、プロジェクトの文脈の中で最適解を見つけることです。主観を可視化するナラティブの衝突を解消するには、まず「見える化」が必要です。言葉で議論していると、同じ言葉に違う意味を込めていることに気づきません。私がよく使うのは、ホワイトボードに関係者の立場と関心事を図示する方法です。IPAのガイドでは「リッチピクチャ」と呼んでいます。言葉では表現しづらい関係性を一枚の絵で表現し、「あなたはこう見えているんですね」と確認する。これだけで誤解が減ります。合意形成を加速させるテクニック私の経験で有効だったテクニックをいくつか挙げます。IPAのガイドでも同様の手法が推奨されています。当事者意識（オーナーシップ）の醸成単なるヒアリングではなく、ワークショップなどを通じて関係者が議論し、相互理解を深めるプロセスを持ちます。自分たちが決めたという意識がなければ、稼働後の不満につながります。相手の視点に合わせた資料の準備成果物をそのまま見せるのではなく、説明相手の関心事に合わせた資料を用意します。経営層向け: 「ビフォーアフター図（B/A図）」を用い、何が変わって何が良くなるのか、投資対効果を端的に伝える現場のリーダー向け: 新しい業務プロセスがどうなるか、業務フローを用いて具体的な変化を説明する「声の大きい人」のコントロール特定の意見に流されないよう、客観的な評価指標（優先順位の基準）を盾にし、ファシリテーターが議論を統制します。エスカレーションパスの確立現場で合意できない対立については、上位層による意思決定機関（ステアリングコミッティ）へ迅速にエスカレーションし、プロジェクトを停滞させない仕組みを事前に作っておきます。合意形成でAIを活用する合意形成という人間臭い作業でも、AIは補助的な役割を果たせます。相手の立場を理解するための困難打ち。会議の前に、AIに「経営者の視点から、このシステム投資をどう評価するか」と聞いてみます。自分とは違うナラティブを疑似体験できます。「この提案を受けた営業部長は、どんな懸念を持つか」とAIに聞くことで、想定問答を準備できます。議論の整理と論点の抽出。会議が紛糾したとき、議事録をAIに読ませて「この議論の論点を整理して」と指示すると、感情的になっている参加者には見えなくなった構造が見えてきます。「経営層はコストを重視、現場は使いやすさを重視、エンジニアは保守性を重視」という対立構造を可視化できます。説明資料の自動生成。相手に合わせた資料の準備にも、AIは使えます。「この技術仕様を、経営層向けにROIの観点で説明する資料に変換して」と指示すれば、一次ドラフトが生成されます。ゼロから書くより効率的です。合意の言語化。合意に至ったとき、その内容を正確に文書化することにもAIは役立ちます。「この会議で合意された内容を、後から『言った言わない』にならないように文書化して」と指示すれば、曖昧さを排除した合意文書のドラフトが得られます。しかし、AIが補助できるのは合意形成の準備と記録です。相手の感情を読み取り、対立を調整し、「これでいきましょう」と握り合うプロセス自体は、人間同士の対話でしかできません。AIは通訳であり、ファシリテーターではありません。対話の本質と、対話を阻む構造的な問題については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com優先順位付けという最もクリエイティブな「棄却」「全部やる」の誘惑「全部やる」と言った瞬間、会議室は平和になります。誰も傷つかない。誰も責められない。しかし3ヶ月後、プロジェクトは炎上する。「全部やる」は、将来の自分への借金です。利子は複利で増えます。問題は個人の心理だけではありません。組織の構造が、選択を妨げていることがあります。まず、インセンティブの問題があります。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっています。次に、権限の曖昧さがあります。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確です。だから、誰も決めない。決めなければ、責任を問われません。「全部やる」は、個人の弱さであると同時に、構造の帰結でもあります。客観的な6つの判断基準AIはあらゆる可能性を提示しますが、リソース（工期・コスト・人）は有限です。何かを選ぶことは、何かを諦めること。この優先順位付けこそが、最もクリエイティブで苦しい決断の場です。優先順位を「なんとなく」で決めると、声の大きい人の意見が通ってしまいます。私は以下の6つの指標で多角的に評価するようにしています。IPAのガイドでも同様の基準が示されています。有効性: 目的や目標にどれだけ貢献するか（達成効果）必要性: 法制度対応、内部統制、社会的責任などの観点で不可欠か緊急性: 期限が明確で、急を要するか費用: 実現や運用にどれだけのコストがかかるか実現性: 技術的・人的に本当に実現可能か新たな問題: その要求を実現することで、別の問題が発生しないかMoSCoW分析という「捨てる」ための枠組みすべてを「必須」とせず、MoSCoW分析を用いて、勇気を持って「要求を捨てる」ことが必要です。M (Must): これがないと目的を達成できない必須の要求S (Should): 必須ではないが、重要な推奨要求C (Could): あれば良いレベルの要求W (Won't): 今回は見送る、または不要な要求柔軟で変化に強いシステムを作るには、要求を抑え込み、シンプルでスリムな状態を維持する「捨てる勇気」が必要です。AIが「What（何を作るか）」の選択肢を無限に生成するからこそ、人間はこの枠組みを駆使して価値あるものだけを選ぶ必要があります。優先順位付けでAIを活用するここでもAIは強力な補助ツールになります。比較分析の自動化。100個の要求がリストアップされたとき、それぞれを6つの指標で評価するのは膨大な作業です。AIに「この要求リストを、有効性・必要性・緊急性・費用・実現性・新たな問題の6軸で評価して」と指示すれば、一次評価を自動化できます。トレードオフの可視化。「要求Aを優先すると、要求Bにどんな影響があるか」という依存関係の分析も、AIに補助させられます。複雑に絡み合った要求間の関係を整理し、「これを選ぶと、あれが犠牲になる」という構造を可視化できます。過去事例の参照。類似プロジェクトでどんな優先順位付けがなされたか。過去の要件定義書をAIへ渡し、傾向を分析させることもできます。「過去5年間のプロジェクトで、結局Won't判定となった要求の特徴は何か」といった分析が可能です。しかし、最終的な優先順位を決めるのは人間です。AIは「この要求は有効性が高い」と分析できます。だが「有効性が高いから採用する」とは決断できません。有効性が高くても、今のチームには実現できない。費用が低くても、ビジネス的な価値がない。こうした判断は、プロジェクトの文脈を理解している人間にしかできません。「何をやらないか」を決めることの本質と、戦略的思考については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com検証と妥当性確認という「正しさ」を問う2つの視点要件を選び、優先順位を付けた。では、その選択は正しかったのか。要件定義には、選んだ後に「正しさ」を確認する作業があります。ここで重要なのは、「正しさ」には2つの意味があるということです。Verification と ValidationAI時代のエンジニアの価値は、計算機的な「検証（Verification）」から、人間的な「妥当性確認（Validation）」へと移っています。検証 (Verification): 記述された要件が、要求を抜け漏れなく満たしているかという「計算的」チェック。これはAIでも補助可能である。妥当性確認 (Validation): その要求自体が、本当にビジネス目的を達成できるものかという「意志」の確認。後者は「納得」という感情の着地点を見つける泥臭い人間活動（合意形成）であり、これが欠けた要件定義は、2025年においても失敗を運命づけられています。AIは「正しく作る」ことを補助できます。しかし「正しいものを作っているか」を問い続けるのは人間の仕事です。検証フェーズでAIを活用するVerification（検証）は、AIが最も力を発揮できる領域です。要件の整合性チェック。「この要件定義書の中で、矛盾している記述はないか」とAIに分析させます。「画面Aでは『即時反映』と書いてあるが、画面Bでは『バッチ処理』と書いてある。これは矛盾ではないか」といった指摘が得られます。人間の目では見落としがちな不整合を、AIは網羅的にチェックできます。抜け漏れの検出。「この要件定義書で、考慮されていない観点はないか」とAIに問いかけます。「エラー時の挙動が定義されていない」「権限管理について記述がない」といった抜け漏れを指摘してくれます。テストケースの自動生成。「この要件から、テストケースを生成して」と指示すれば、要件を満たしているかどうかを確認するためのテストシナリオが自動生成されます。一方で、Validation（妥当性確認）は人間の仕事です。「この要件が本当にビジネス目的を達成できるか」は、ビジネスの文脈を理解している人間にしか判断できません。AIは「要件が論理的に整合している」ことは確認できますが、「この要件でユーザーが幸せになるか」は判断できません。非機能要求と経営リスクを引き受ける覚悟性能、セキュリティ、可用性といった「非機能要求」は、もはやエンジニアのこだわりではなく、経営そのものです。IPAの「非機能要求グレード」を活用し、可用性、セキュリティ、運用・保守性などの各項目について、ビジネスの特性に合わせた「レベル」を決定します。可用性: 「24時間365日止まらない」という要求には膨大なコストがかかるセキュリティ: 利便性を損なう可能性があっても守るべき情報の範囲を合意するAIは「コストとリスクのバランス表」を出すことはできます。しかし、万が一の事態に「私が責任を取る」と宣言し、トレードオフに決着をつけることはできません。システムの事情を人間に寄せるここまで、要件定義の「決める」「合意する」「選ぶ」という側面について書いてきました。ここからは、もう1つの重要な側面——伝える——について書きます。エンジニアの本当の仕事私は長い間、エンジニアの仕事は「技術的に優れたシステムを作ること」だと思っていました。パフォーマンスを最適化し、スケーラブルに設計し、セキュリティを担保する。それが専門家としての価値だと。しかし今は違う考えを持っています。エンジニアの本当の仕事は、システムの事情を人間に寄せることです。システムには事情があります。データベースには制約がある。ネットワークには遅延がある。メモリには限界がある。これらの「システムの都合」をそのままユーザーに押し付けると、使いにくいシステムができあがります。「処理中はお待ちください」という画面を見せるのは簡単です。しかし、バックグラウンドで処理を行い、完了したら通知するという設計にすれば、ユーザーは待たなくていい。もう少し例を挙げます。「入力エラーです」→「電話番号は090-1234-5678の形式で入力してください」「データがありません」→「〇〇で検索してみてください」または「似たデータはこちら」「権限がありません」→「管理者の〇〇さんに申請してください」（申請リンク付き）パターンは同じです。エラーの原因を伝えるのではなく、次のアクションを伝える。これが「システムの事情を人間に寄せる」ということです。AIがこの橋渡しを加速するここに生成AIが加わることで、「システムの事情を人間に寄せる」作業は劇的に変わります。エラーメッセージの設計を例に考えます。従来、エンジニアは「このエラーが出たら、どう説明するか」を一つひとつ考えていました。しかし今は、「このエラーコードのリストを、エンドユーザー向けの説明文へ変換して」とAIに指示できます。数百のエラーメッセージを、一貫したトーンで、人間に寄せた表現へ変換できるのです。ドキュメント生成も同様です。APIの仕様書をAIへ渡し、「エンジニアではない人が読んでも分かる説明を書いて」と指示する。技術的な正確さを保ちつつ、ビジネス側に伝わる表現へ変換できます。アーキテクトとしての視点から言えば、AIは「翻訳作業の自動化」を可能にします。システムの事情を人間に寄せる作業は、これまで経験と勘に頼っていました。しかし今は、AIにパターンを学習させ、大量の翻訳を一貫した品質で行えます。しかし、注意が必要です。AIが生成した「人間に寄せた表現」が、本当にユーザーに伝わるかは別問題です。AIは「分かりやすそうな文章」を生成できますが、ユーザーが実際に理解するかは検証しなければ分かりません。エンジニアの仕事は、AIが生成した翻訳を検証し、改善のサイクルを回すことに移行します。要件定義はその橋渡し要件定義は、ビジネスの世界とシステムの世界を橋渡しする行為です——と言うのは簡単です。問題は、同じ言葉でも意味が違うことにあります。例えば「リアルタイム」という言葉。エンジニアが「リアルタイム」と聞くと、脳内では即座にWebSocketの設計が始まる。ポーリング間隔は100ミリ秒か、いや50ミリ秒か。一方、ビジネス側の「リアルタイム」とは何か。聞いてみると「1分以内」だったりする。エンジニアは100ミリ秒の世界で戦っていたが、相手は60秒の世界にいた。600倍のズレです。この認識の溝を埋めないまま開発を進めると、3ヶ月後に「なんでこんなに重いんですか」と言われる。過剰品質もまた罪なのです。橋渡しとは、この言葉の翻訳作業のことです。「リアルタイムとは、具体的にどのくらいの頻度で更新されればいいですか」と聞く。「1時間に1回で十分」と返ってくるでしょう。その瞬間、要件の解像度が上がります。「技術的にはできません」で終わらせるのは簡単です。しかし、「技術的には難しいですが、こういう代替案ならできます」と提案できるかどうか。それがプロフェッショナルとアマチュアの違いです。「要件定義」という言葉のズレ業界・組織によって指す行為が違うここで立ち止まりたいです。あなたの職場での「要件定義」と、私が語っている「要件定義」は、同じものでしょうか。正直に告白すると、この言葉ほど組織や文脈によって意味が異なるものはありません。SIerでは、要件定義は「顧客の要望を文書化すること」を指すことが多いです。RFP（提案依頼書）を受け取り、要件定義書を作成し、顧客の承認を得る。事業会社では、要件定義は「何を作るかを決めること」を指すことが多いです。文書化より意思決定が重視されます。スタートアップでは、要件定義という言葉自体はあまり使われません。「仮説を立てて検証する」「ユーザーの声を聞いて方向転換する」——こうした活動は要件定義に相当しますが、そう呼ばれることは少ないです。ズレを防ぐために1つのアプローチは、最初に「要件定義」の意味を擦り合わせることです。プロジェクトの冒頭で、「このプロジェクトにおいて要件定義とは何を指すか」を明示的に合意する。面倒ですが、後のズレを防げます。私がこの記事で「要件定義とは合意形成であり、責任の引き受けである」と定義したのも、そうした擦り合わせの試みです。生成AI時代にエンジニアはどう向き合うか生成AIの登場によって、「要件定義」という言葉のズレはより複雑になります。「AIに要件定義させる」という幻想。クライアントから「AIに要件定義させればいいのでは」と言われることが増えました。しかし、ここには根本的な誤解があります。AIは「要件をドキュメント化すること」はできます。だが「要件を決めること」はできません。なぜなら、要件を決めるとは責任を引き受けることだからです。エンジニアとして、私はこの問いにこう答えます。「AIは要件定義の作業を効率化します。しかし要件定義の本質——選択と責任——は人間のままです」と。アーキテクトの新しい役割。生成AI時代のアーキテクトには、新しい役割が生まれています。それは「AIとの協働プロセスを設計する」ことです。どの作業をAIに任せ、どの判断を人間が行うか。この分界点を設計することが、アーキテクトの仕事に加わりました。例えば、以下のような判断が必要になります。AIに任せるべきこと: 要件の文書化、過去事例の調査、影響範囲の分析、選択肢の列挙人間が判断すべきこと: 対立する要件の優先順位付け、ステークホルダとの合意形成、「これでいく」という最終決定組織によって「AI活用」の意味も違う。SIerでは「AIで提案書の品質を上げる」だろう。事業会社では「AIでプロトタイプを高速に作り、検証する」だろう。スタートアップでは「AIで仮説検証のサイクルを速める」だろう。要件定義という言葉のズレと同様に、「AIを活用する」という言葉もズレます。だからこそ、プロジェクトの冒頭で「このプロジェクトにおいてAIをどう使うか」も明示的に合意すべきです。腹を括って成功した経験ここまで抽象的な話が続いたので、具体的な経験を1つ書きます。冒頭で「検索機能を作ったが使われなかった」失敗を書きました。今度は、逆のケースです。あるプロジェクトで、私たちは「検索機能を作らない」という判断をしました。クライアントは検索機能を強く要望していました。競合製品にはすべて検索機能がある。チーム内にも「作るべきだ」という声がありました。しかし私は、ユーザーインタビューの結果を見て、違う結論に達しました。ユーザーが本当に困っていたのは「探す」ことではなく、「何を探せばいいか分からない」ことでした。検索機能を作っても、検索ワードが浮かばないユーザーには役に立ちません。私は「検索機能は作らない。代わりに、よく使う項目を自動で上位に表示する仕組みを作る」と提案しました。クライアントとチームから、大きな反対はありませんでした。「もし改善しなかったら、そのときに検索機能を作りましょう」という落とし所で合意しました。結果は成功でした。リリース後、ユーザーからの問い合わせが激減しました。「欲しい情報がすぐ見つかる」という評価を得ました。振り返ると、この判断には先ほど挙げた3つの条件がすべて揃っていました。代替案（検索機能を作る）を知っていた。失敗したときのシナリオ（クライアントからのクレーム、追加開発のコスト）を想定していた。そして、自分の名前で決めた。腹を括れば、成功と失敗の両方から学べます。腹を括らなければ、どちらの結果からも何も得られません。おわりにこの記事では、AI時代の要件定義について考えてきました。2025年現在、AIの能力は驚くほど高くなりました。コードを書くだけでなく、要件の分析・矛盾の指摘・テストケース生成・ドキュメント作成まで行えます。AIエージェントは自律的にタスクを実行し、エラーがあれば自分で修正します。それでも、要件定義の本質は変わりません。ステークホルダのニーズを実現可能な形に変換し、合意を取り付けるプロセス。対立するナラティブを調整し、「これでいく」と腹を括る行為。うまくいかなければ次の手を打つ覚悟。これは、人間同士の営みであり続けます。変わるのは、道具です。AIは問いを立てられます。選択肢を提示できます。分析もできます。リスクを列挙できます。これらを使いこなせば、要件定義の質は上がります。しかし、最後に「これでいく」と決めるのは人間です。責任を引き受けるのも人間です。「AIに最適化された要件定義」を一から発明する必要はありません。IPAのガイドに体系化された「128の勘どころ」は、数十年にわたる失敗と成功の蓄積です。この基盤の上に、AIという新しい道具を載せていく。それが現実的なアプローチだと私は考えています。冒頭で触れた「仕様通りに作ったが使われなかった」システム。あのとき私に足りなかったのは、技術力ではありませんでした。「なぜこれを作るのか」を問う力。「これでいく」と決める覚悟。うまくいかなければ別の手を打つ姿勢。そういうものでした。痛みのない決断は、決断ではなく計算です。AIは計算が得意です。しかし、決断はできません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。エンジニアとして、アーキテクトとして、私たちはこの時代にどう立ち向かうべきでしょうか。私の答えはシンプルです。AIを使いこなしながら、決断する力を磨く。AIに任せられる作業は任せる。しかし、最後に「これでいく」と決めるのは自分です。技術選定、アーキテクチャ設計、トレードオフの判断——これらの決断を、自分の名前で行う。うまくいかなければ、次の手を打つ。この姿勢は、AIが進化しても変わりません。この10年間、私はコードを書くことに時間を使ってきました。そのうちどれだけが「贖罪」だったかは、あまり考えたくありません。これからの10年は、「何を作るべきか」を選ぶことに時間を使いたい。選んで、合意を取り付けて、責任を引き受けて、うまくいかなければ次の手を打つ。その繰り返しに時間を使いたいと思っています。参考資料IPAガイド本稿で参照したIPAの「ユーザのための要件定義ガイド 第2版」は、以下から無料でダウンロードできます。「128の勘どころ」として、要件定義の成功に導くための具体的なノウハウが体系化されています。www.ipa.go.jp参考ブログ要件定義を始める前に、以下の記事を読むことを強くおすすめします。本稿で述べた「要件定義とは合意形成である」という主張の基盤となる考え方を、実践的な視点から解説しています。agnozingdays.hatenablog.comagnozingdays.hatenablog.com参考書籍はじめよう！ 要件定義 ～ビギナーからベテランまで作者:羽生章洋技術評論社Amazonはじめよう！プロセス設計 ～要件定義のその前に作者:羽生 章洋技術評論社Amazonはじめよう! システム設計 ～要件定義のその後に作者:羽生 章洋技術評論社Amazonだまし絵を描かないための－－要件定義のセオリー作者:赤俊哉リックテレコムAmazon要件最適アーキテクチャ戦略 (Object oriented selection)翔泳社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonソフトウェアアーキテクトのための意思決定術　リーダーシップ／技術／プロダクトマネジメントの活用作者:Srinath Perera,島田 浩二インプレスAmazonSoftware Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon正しいものを正しくつくる　プロダクトをつくるとはどういうことなのか、あるいはアジャイルのその先について作者:市谷 聡啓ビー・エヌ・エヌ新社Amazon作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazonソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal Ford,島田浩二オライリージャパンAmazonアーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazonソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,João Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazon【Amazon.co.jp 限定】失敗の科学 (特典: マシューサイド×竹下隆一郎 対談PDF データ配信)作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新 失敗学 正解をつくる技術作者:畑村 洋太郎AudibleAmazonソフトウェア要求　第3版作者:カール ウィーガーズ；ジョイ ビーティ日経BPAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ Rustにしたのに遅い？─ N+1クエリ問題の発見と解決]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/26/171102</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/26/171102</guid>
            <pubDate>Fri, 26 Dec 2025 08:11:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめにRustは速い。だが、Rustで書けば速くなるわけではない。ある日、APIのレスポンスが突然5秒を超えた。コードを見直してもバグはない。SQLも正しく書けている。途方に暮れながらログを確認すると、1リクエストで300回以上もクエリが発行されていた。原因は、ループ内で著者情報を1件ずつ取得していたこと。これがN+1クエリ問題だ。見えないものは、直せない。本記事では、この見落とされがちなN+1クエリ問題の本質と、RustとPostgreSQLを使った5つの解決策を解説する。正直に言うと、どの解決策がベストかは状況による。だからこそ、複数のアプローチを知っておく価値があると私は考えている。N+1クエリ問題とは問題のあるコード本記事では、RustのSQLクライアントライブラリ「sqlx」を使用します。sqlxは型安全なクエリとasync/awaitをネイティブにサポートするライブラリです。// アンチパターン: N+1クエリasync fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    // 1回目のクエリ: 投稿一覧を取得    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    let mut result = Vec::with_capacity(posts.len());    for post in posts {        // N回のクエリ: 各投稿の著者を個別に取得        let author = sqlx::query_as!(            User,            "SELECT * FROM users WHERE user_id = $1",            post.user_id        )        .fetch_one(pool)        .await?;        result.push(PostWithAuthor { post, author });    }    Ok(result)}// 100件の投稿を取得するのに 101回のクエリが発生このコードは一見正しく見えますが、100件の投稿を取得するのに101回のクエリを発行しています。これが「N+1クエリ問題」の典型例です。「N+1」という名前は、N件のデータに対して1回（一覧取得）+ N回（個別取得）= N+1回のクエリが発生することに由来します。ここで疑問が浮かぶ。なぜこのパターンを書いてしまうのか。私の経験では、ループ内でfetch_oneを呼ぶコードは「書きやすい」からだ。1件取得する関数がすでにあれば、それをループで回すのは自然な発想に思える。問題は、この「自然さ」がパフォーマンスの問題になることだ。便利すぎるAPIは、時として危険なパターンを誘発する。では、具体的にどれくらい遅くなるのか。数字で見てみよう。なぜ遅いのかN+1クエリが遅い理由を定量的に理解しましょう。1クエリあたりのオーバーヘッド内訳:- RustからPostgreSQLライブラリへの呼び出し：0.01ms- プロトコル処理：0.02ms- ネットワーク往復（ローカル）：0.1-0.5ms- PostgreSQLクエリパース：0.05ms- 実行計画生成：0.1-1ms- 実行（インデックス使用時）：0.1-0.5ms- 結果のシリアライズ：0.02ms合計：約0.5-2ms/クエリ計算例100件のN+1クエリ:- 最良ケース: 101 × 0.5ms = 50ms- 最悪ケース: 101 × 2ms = 200msJOINで1クエリ:- 約1-5ms差: 10-100倍ネットワークレイテンシが大きい環境（クラウド、リモートDB）では、この差はより広がります。ここまでの計算で、N+1の影響の大きさは理解できた。では、この問題の根本にあるものは何だろうか。N+1問題の本質1回で済むことを、何度もやっていないか。N+1問題の本質は「ループ内のI/O」だと私は考えている。これは単なるSQLの問題ではなく、プログラミング一般に潜む構造的な課題だ。// 問題のパターンfor item in collection {    // 各アイテムごとにI/O（DB、ファイル、HTTP）    let related = fetch_related(item.id).await?;}この問題は以下のような場面で発生します。1対多の関連データ取得: 投稿とコメント、ユーザーと注文多対多の関連データ取得: 投稿とタグ、ユーザーとロールネストしたデータ構造: カテゴリ → 投稿 → コメント → ユーザー問題の構造がわかったところで、解決策を見ていこう。RustとPostgreSQLの組み合わせでは、5つのアプローチがある。シンプルなものから順に紹介する。解決策1: JOINで一括取得最もシンプルな解決策は、JOINを使って1回のクエリで全てのデータを取得することです。1対1の関連#[derive(Debug, sqlx::FromRow)]struct PostWithAuthor {    // 投稿の情報    post_id: Uuid,    title: String,    content: String,    post_created_at: DateTime<Utc>,    // 著者の情報    author_id: Uuid,    author_name: String,    author_email: String,}async fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithAuthor,        r#"        SELECT            p.post_id,            p.title,            p.content,            p.created_at as post_created_at,            u.user_id as author_id,            u.name as author_name,            u.email as author_email        FROM posts p        INNER JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}JOINの種類と使い分け実務でよく使うのはINNER JOINとLEFT JOINの2つです。INNER JOINは両方のテーブルに存在する行のみを返し、関連データが必須の場合に使います。LEFT JOINは左テーブルの全行を返し、右テーブルは一致する行のみを返すため、関連データがオプションの場合に適しています。RIGHT JOINやFULL JOINは実務でほぼ使いません。// LEFT JOIN: 著者がいない投稿も含めるasync fn get_posts_with_optional_authors(pool: &PgPool) -> Result<Vec<PostWithOptionalAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithOptionalAuthor,        r#"        SELECT            p.post_id,            p.title,            u.user_id as "author_id?",            u.name as "author_name?"        FROM posts p        LEFT JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        "#    )    .fetch_all(pool)    .await}JOINは1対1の関連には最適だ。しかし、1対多の関連を取得しようとすると、行が膨張してしまう。投稿1件に対してタグが5つあれば、同じ投稿が5行に複製される。この問題を避けるには、別のアプローチが必要になる。解決策2: IN句 + HashMap1対多の関連を効率的に取得する場合、IN句とHashMapを組み合わせる方法が有効です。use std::collections::HashMap;async fn get_posts_with_tags(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    // 1. 投稿を取得    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    let post_ids: Vec<Uuid> = posts.iter().map(|p| p.post_id).collect();    // 2. タグを一括取得（ANY配列演算子を使用）    let tags: Vec<PostTagRow> = sqlx::query_as!(        PostTagRow,        r#"        SELECT pt.post_id, t.tag_id, t.name        FROM post_tags pt        JOIN tags t USING (tag_id)        WHERE pt.post_id = ANY($1)        "#,        &post_ids    )    .fetch_all(pool)    .await?;    // 3. HashMapでグループ化（O(n)）    let mut tag_map: HashMap<Uuid, Vec<Tag>> = HashMap::new();    for row in tags {        tag_map            .entry(row.post_id)            .or_default()            .push(Tag { tag_id: row.tag_id, name: row.name });    }    // 4. 結果を組み立て    let result = posts        .into_iter()        .map(|post| {            let tags = tag_map.remove(&post.post_id).unwrap_or_default();            PostWithTags { post, tags }        })        .collect();    Ok(result)}// **2回のクエリで完了（N+1 → 2）**ANY vs IN の違い-- IN句: リテラル値のリストSELECT * FROM posts WHERE post_id IN ('id1', 'id2', 'id3');-- ANY: 配列パラメータSELECT * FROM posts WHERE post_id = ANY($1);  -- $1 は UUID[]sqlxでは配列パラメータとしてANYを使う方が便利です。パフォーマンス特性IN/ANY句のパフォーマンス:要素数     | 推奨アプローチ-----------|------------------< 100      | IN/ANY で問題なし100-1000   | IN/ANY + インデックス確認1000+      | 一時テーブル or UNNEST大量のIDがある場合の対処法です。async fn get_posts_with_many_ids(pool: &PgPool, ids: &[Uuid]) -> Result<Vec<Post>, sqlx::Error> {    // 大量のIDはUNNESTでJOIN    sqlx::query_as!(        Post,        r#"        SELECT p.*        FROM unnest($1::uuid[]) WITH ORDINALITY AS t(id, ord)        JOIN posts p ON p.post_id = t.id        ORDER BY t.ord        "#,        ids    )    .fetch_all(pool)    .await}IN句+HashMapは2回のクエリで済み、行の膨張も起きない。ただ、Rustでの組み立て処理が必要になる。もし1回のクエリで完結させたいなら、PostgreSQLの配列集約機能が使える。解決策3: PostgreSQL配列集約PostgreSQLのarray_aggを使うと、1回のクエリで1対多の関連をネストした形で取得できます。#[derive(Debug, sqlx::FromRow)]struct PostWithTags {    post_id: Uuid,    title: String,    content: String,    tags: Vec<String>,}async fn get_posts_with_tags_aggregated(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    sqlx::query_as!(        PostWithTags,        r#"        SELECT            p.post_id,            p.title,            p.content,            COALESCE(                array_agg(t.name) FILTER (WHERE t.name IS NOT NULL),                '{}'            ) as "tags!: Vec<String>"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}// **1回のクエリで完了**array_aggの注意点NULL処理: FILTER (WHERE ... IS NOT NULL) でNULLを除外する空配列: COALESCE(..., '{}') で関連がない時は空配列を返す重複: 必要に応じて array_agg(DISTINCT ...) を使用する複数の配列を同時に集約async fn get_posts_with_tags_and_categories(pool: &PgPool) -> Result<Vec<PostWithTagsAndCategories>, sqlx::Error> {    sqlx::query_as!(        PostWithTagsAndCategories,        r#"        SELECT            p.post_id,            p.title,            COALESCE(                array_agg(DISTINCT t.name) FILTER (WHERE t.name IS NOT NULL),                '{}'            ) as "tags!: Vec<String>",            COALESCE(                array_agg(DISTINCT c.name) FILTER (WHERE c.name IS NOT NULL),                '{}'            ) as "categories!: Vec<String>"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        LEFT JOIN post_categories pc USING (post_id)        LEFT JOIN categories c USING (category_id)        GROUP BY p.post_id        "#    )    .fetch_all(pool)    .await}array_aggは単純な値の配列には便利だ。タグ名やカテゴリ名のようなString型の配列なら、これで十分。しかし、コメントのように複数のフィールドを持つオブジェクトを集約したい時はどうだろうか。そこで登場するのがjson_aggだ。解決策4: json_aggによる複雑なネストarray_aggでは単純な値しか集約できませんが、json_aggを使えば複雑なオブジェクトをネストできます。use serde::Deserialize;use sqlx::types::Json;#[derive(Debug, Deserialize)]struct CommentJson {    comment_id: Uuid,    body: String,    created_at: DateTime<Utc>,}#[derive(Debug, sqlx::FromRow)]struct PostWithComments {    post_id: Uuid,    title: String,    comments: Json<Vec<CommentJson>>,}async fn get_posts_with_comments(pool: &PgPool) -> Result<Vec<PostWithComments>, sqlx::Error> {    sqlx::query_as!(        PostWithComments,        r#"        SELECT            p.post_id,            p.title,            COALESCE(                json_agg(                    json_build_object(                        'comment_id', c.comment_id,                        'body', c.body,                        'created_at', c.created_at                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                '[]'            ) as "comments!: Json<Vec<CommentJson>>"        FROM posts p        LEFT JOIN comments c USING (post_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}jsonb_agg vs json_agg 関数  特徴  json_agg  テキストとして格納、出力がJSON文字列の順序を保持  jsonb_agg  バイナリ格納、重複キー削除、インデックス可能 単純な集約にはjson_agg、後で検索や操作をする時はjsonb_aggを使います。深いネスト構造async fn get_posts_full_detail(pool: &PgPool) -> Result<Vec<PostFullDetail>, sqlx::Error> {    sqlx::query_as!(        PostFullDetail,        r#"        SELECT            p.post_id,            p.title,            json_build_object(                'user_id', u.user_id,                'name', u.name            ) as "author!: Json<AuthorJson>",            COALESCE(                json_agg(                    json_build_object(                        'comment_id', c.comment_id,                        'body', c.body,                        'commenter', json_build_object(                            'user_id', cu.user_id,                            'name', cu.name                        )                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                '[]'            ) as "comments!: Json<Vec<CommentWithCommenterJson>>"        FROM posts p        JOIN users u ON p.user_id = u.user_id        LEFT JOIN comments c USING (post_id)        LEFT JOIN users cu ON c.user_id = cu.user_id        GROUP BY p.post_id, u.user_id        LIMIT 100        "#    )    .fetch_all(pool)    .await}ここまでの解決策はすべて、取得するデータが事前にわかっている場合に有効だ。SQLを書く時点で、どのテーブルをJOINするか、何を集約するかが決まっている。しかし、GraphQLのように「リクエストごとに取得対象が動的に変わる」時はどうだろうか。そこで登場するのがDataLoaderパターンだ。解決策5: DataLoaderパターンGraphQLなどで多用されるDataLoaderパターンは、複数の個別リクエストを自動的にバッチ化する仕組みです。use std::collections::HashMap;use tokio::sync::Mutex;pub struct UserLoader {    pool: PgPool,    cache: Mutex<HashMap<Uuid, User>>,}impl UserLoader {    pub fn new(pool: PgPool) -> Self {        Self {            pool,            cache: Mutex::new(HashMap::new()),        }    }    /// 複数のユーザーIDを一括でロード    pub async fn load_many(&self, ids: &[Uuid]) -> Result<HashMap<Uuid, User>, sqlx::Error> {        let mut cache = self.cache.lock().await;        // キャッシュにないIDを特定        let missing: Vec<Uuid> = ids            .iter()            .filter(|id| !cache.contains_key(id))            .copied()            .collect();        if !missing.is_empty() {            // 一括でDBから取得            let users: Vec<User> = sqlx::query_as!(                User,                "SELECT * FROM users WHERE user_id = ANY($1)",                &missing            )            .fetch_all(&self.pool)            .await?;            // キャッシュに追加            for user in users {                cache.insert(user.user_id, user);            }        }        // 結果を構築        let result = ids            .iter()            .filter_map(|id| cache.get(id).cloned().map(|u| (*id, u)))            .collect();        Ok(result)    }    /// 単一のユーザーをロード（内部的にはバッチ処理可能）    pub async fn load(&self, id: Uuid) -> Result<Option<User>, sqlx::Error> {        let map = self.load_many(&[id]).await?;        Ok(map.into_values().next())    }    /// リクエスト終了時にキャッシュをクリア    pub async fn clear(&self) {        self.cache.lock().await.clear();    }}DataLoaderの使用例async fn get_posts_with_authors_dataloader(    pool: &PgPool,    loader: &UserLoader,) -> Result<Vec<PostWithAuthor>, anyhow::Error> {    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    // 全ユーザーIDを収集    let user_ids: Vec<Uuid> = posts.iter().map(|p| p.user_id).collect();    // 一括でロード    let users = loader.load_many(&user_ids).await?;    // 結果を組み立て    let result = posts        .into_iter()        .filter_map(|post| {            // ユーザーが見つからない投稿はスキップ            // または、Option<User>としてPostWithAuthorを定義する            users.get(&post.user_id).cloned().map(|author| {                PostWithAuthor { post, author }            })        })        .collect();    Ok(result)}より高度な自動バッチ化が必要な時は、async-graphqlのDataLoader実装を参照してください。5つの解決策を見てきた。では、どれを選べばいいのか。それぞれの特徴を整理してみよう。解決策の比較 方法  クエリ数  複雑さ  適用場面  JOIN  1  低  1対1、少量の1対多  IN句 + HashMap  2  中  1対多、多対多  array_agg  1  中  単純な値の1対多  json_agg  1  高  複雑なネスト構造  DataLoader  2+  高  GraphQL、動的なデータ取得 ここで一見すると「シンプルなJOINが最善」と思えるだろう。しかし、そう単純な話ではない。JOINは1対多で行が膨張し、json_aggは可読性を犠牲にする。シンプルさとパフォーマンスは常にトレードオフの関係にある。私の結論は、「まずJOINを試し、問題が出たらIN句+HashMapに移行する」という段階的アプローチだ。最初から複雑な解決策に飛びつく必要はない。選択の判断フローチャート解決策がわかっても、そもそもN+1が発生していることに気づかなければ意味がない。コードレビューで確認すべき項目をまとめておこう。N+1検出チェックリストコードレビューやPRレビューでは、まずループ内でquery_as!やquery!を呼んでいないかを確認してください。次に、for文の中に.awaitがあり、DBアクセスをしていないかをチェックします。最後に、APIレスポンスに必要なデータを1-2回のクエリで取得できているかを確認しましょう。まとめRustにしたのに遅い？—それはRustのせいではない。N+1クエリ問題は、言語の速さを帳消しにする。どれだけRustが速くても、100回のネットワーク往復は100回のネットワーク往復だ。言語を変えても、アーキテクチャの問題は解決しない。問題は、気づいた瞬間に半分解決している。N+1クエリ問題は、気づかないうちにパフォーマンスを劣化させる典型的なアンチパターンです。解決の基本原則は以下の3つです。ループ内でI/Oを行わない必要なデータは一括で取得する開発時にクエリ数を監視する「N+1を気にしすぎるとコードが複雑になる」という批判はあるだろう。確かにその通りだ。しかし、私の経験では、N+1問題は本番環境で突然顕在化することが多い。開発環境では10件のデータで問題なく動いていたコードが、本番で1000件になると破綻する。複雑さのコストより、本番障害のコストの方が高い。だからこそ、複数の解決策を知っておくことに価値がある。RustとPostgreSQLの組み合わせでは、JOIN、IN句、array_agg、json_agg、DataLoaderなど複数の解決策があり、状況に応じて適切な方法を選択できます。実測パフォーマンス比較実際にRust + sqlx + PostgreSQLで計測した結果を示します。 方法  クエリ数  実行時間  改善率  N+1パターン（アンチパターン）  51回  27.95ms  -  JOIN  1回  1.51ms  18.5倍高速  IN句 + HashMap  2回  1.71ms  16.3倍高速  DataLoader（初回）  2回  1.61ms  17.4倍高速  DataLoader（キャッシュヒット）  0回  0.013ms  2,150倍高速 計測条件:PostgreSQL 17 / Docker環境50件の記事、10人の著者ローカル接続（ネットワークレイテンシ最小）リモートDBやクラウド環境ではネットワークレイテンシが加算されるため、N+1の影響はより大きくなります。問題の深刻さがわかったところで、どうやって検出すればいいのか。開発から本番まで、各段階での対策を整理しておこう。検出のまとめN+1問題の検出には複数のレイヤーで対策を講じるべきです。 段階  手法  特徴  開発時  クエリカウンター、トレーシング  即座にフィードバック  テスト時  assert_max_queries、統合テスト  CI/CDで自動検出  コードレビュー  チェックリスト、静的解析  ループ内awaitを検出  本番環境  pg_stat_statements、OpenTelemetry  実際の影響を測定 特に重要なのは、開発初期段階での検出です。本番環境で発見されたN+1問題は、すでにユーザー体験に影響を与えており、修正にも時間がかかります。とはいえ、すべてのN+1を事前に防げるかと言われると、正直なところ難しい。新しいチームメンバーが入ってきたり、時間に追われたリリースがあったりすれば、どこかでN+1パターンが紛れ込む。完璧を目指すより、検出と修正のサイクルを回せる体制を作る方が現実的だと私は考えている。数えてみろ。数えれば見える。冒頭で触れた300回クエリの問題は、IN句+HashMapパターンで2回のクエリに削減でき、レスポンスは5秒から200msに改善した。次のコードレビューで、ループ内の.awaitを確認してみてください。参考資料syu-m-5151.hatenablog.comsqlx / Rustsqlx Documentationtracing cratesyn crate（AST解析）PostgreSQLPostgreSQL Array FunctionsPostgreSQL JSON Functionspg_stat_statementsauto_explainpg_stat_activityパターンDataLoader PatternAvoiding N+1 Queries (Rails/ActiveRecord、概念は共通)観測性OpenTelemetry Rusttracing-opentelemetry]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[10 Premium Tools for 10x Developers]]></title>
            <link>https://daisuke1024akagawa.medium.com/6-premium-tools-for-10x-developers-af6b17908014?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/6-premium-tools-for-10x-developers-af6b17908014?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Thu, 25 Dec 2025 10:47:11 GMT</pubDate>
            <content:encoded><![CDATA[This time, I’ll introduce the 10 paid services I regularly use.Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[0.1+0.2=0.30000000000000004 をRust/PostgreSQLで考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/25/192751</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/25/192751</guid>
            <pubDate>Thu, 25 Dec 2025 10:27:51 GMT</pubDate>
            <content:encoded><![CDATA[はじめにテストを書いていて、奇妙なことに気づいた。合計金額のアサーションが通らない。期待値は10.00なのに、実際の値は9.99999999999983。コードにバグはない。SQLも正しい。では何が問題なのか。調べた結果、犯人は浮動小数点の累積誤差だった。金額カラムにDOUBLE PRECISIONを使っていたのです。これは「浮動小数点の罠」とも呼ばれる、DB設計やアプリケーションの実装で陥りやすい問題だ。RustとPostgreSQLでWebサービスを構築する際に注意すべき点の1つで、金融システムや科学計算、測定データ、座標、パーセンテージなど、正確な数値が必要なあらゆる場面で問題になります。2進数と10進数の不一致コンピュータは2進数で数値を表現します。しかし、私たちが日常使う10進数の多くは2進数で正確に表現できません。0.1 (10進数) = 0.0001100110011... (2進数・無限循環小数)これはPostgreSQLやRustの問題ではなく、IEEE 754（コンピュータが小数を扱う国際標準規格）に基づくすべてのシステムに共通する問題です。fn main() {    let a = 0.1_f64;    let b = 0.2_f64;    let c = a + b;    println!("{} + {} = {}", a, b, c);    // 出力: 0.1 + 0.2 = 0.30000000000000004    println!("0.1 + 0.2 == 0.3 ? {}", c == 0.3);    // 出力: false}PostgreSQLの数値型PostgreSQLには大きく分けて3種類の数値型があります。浮動小数点型（近似値）浮動小数点型は近似値を扱う型で、内部的にはIEEE 754形式（2進数の浮動小数点）で表現されます。REAL（FLOAT4とも呼ばれる）は4バイトのストレージを使用し、有効桁数は6桁です。センサーデータやグラフィックスなど、高い精度を必要としない場面に適しています。DOUBLE PRECISION（FLOAT8とも呼ばれる）は8バイトを使用し、有効桁数は15桁に拡張されます。科学計算や座標データなど、より高い精度が求められる場面で使用します。任意精度型（正確値）NUMERIC（またはDECIMAL）は正確な計算が必要な場面で使用する型です。ストレージは可変長で、4桁ごとに2バイトを消費します。最大131,072桁までの精度をサポートしており、金額計算などで威力を発揮します。なお、PostgreSQLではNUMERICとDECIMALは完全に同一の型として扱われます。整数型整数型は小数を含まない数値を扱います。INTEGERは4バイトで±21億の範囲を扱え、カウンターやIDに適しています。BIGINTは8バイトで±922京という広大な範囲をカバーし、大きな整数やセント単位での金額格納に使用できます。問題が発生する具体的な場面1. 等価比較の失敗-- PostgreSQLで確認SELECT 0.1::float8 + 0.2::float8 = 0.3::float8;-- 結果: falseSELECT 0.1::numeric + 0.2::numeric = 0.3::numeric;-- 結果: trueこれはWHERE句での検索に影響します。-- 見つからない可能性があるSELECT * FROM measurements WHERE value = 0.3;-- 確実に動作SELECT * FROM measurements WHERE ABS(value - 0.3) < 0.0001;2. 累積誤差-- 0.01を1000回加算CREATE TABLE test_float (amount DOUBLE PRECISION);CREATE TABLE test_numeric (amount NUMERIC(10,2));INSERT INTO test_float SELECT 0.01 FROM generate_series(1, 1000);INSERT INTO test_numeric SELECT 0.01 FROM generate_series(1, 1000);SELECT SUM(amount) FROM test_float;-- 結果: 9.99999999999983（期待値: 10.00）SELECT SUM(amount) FROM test_numeric;-- 結果: 10.00（正確）誤差は小さく見えますが、0.00017の誤差でも1000万レコードでは1700の誤差になります。月次決算で170万円ずれる可能性があるのです。3. 丸め方法の違いPostgreSQLのNUMERICとFLOATでは丸め方法が異なります。SELECT x,  round(x::numeric) AS numeric_round,  round(x::double precision) AS float_roundFROM (VALUES (-2.5), (-1.5), (1.5), (2.5)) AS t(x); x  NUMERIC  FLOAT  -2.5  -3  -2  -1.5  -2  -2  1.5  2  2  2.5  3  2 NUMERIC: ゼロから遠い方へ丸める（Midpoint Away From Zero）FLOAT: 最近偶数へ丸める（Banker's Rounding / IEEE 754）この違いは、同じ計算でも型によって結果が異なることを意味します。ドメイン別：FLOATを使えるか使用を避けるべき場面 ドメイン  理由  推奨型  金額・会計  1円/1セントの誤差も許されない  NUMERIC  税率・割引率  正確な計算が必要  NUMERIC  合計が一致すべきパーセンテージ  33.33% × 3 = 100%が必要  NUMERIC  統計的有意性  p値の正確な比較  NUMERIC  監査証跡  再現可能性が必要  NUMERIC FLOATが許容される場面 ドメイン  理由  推奨型  センサーデータ  センサー自体の誤差 > FLOAT誤差  DOUBLE PRECISION  座標（GPS）  15桁精度で十分（1cm精度には7桁で十分）  DOUBLE PRECISION  温度・湿度  測定誤差が大きい  REAL or DOUBLE PRECISION  レーティング平均  表示時に丸める  DOUBLE PRECISION  グラフィックス  視覚的に認識できない  REAL 判断のフローチャート数値型を選択する際は、まず正確な10進数表現が必要かどうかを考えます。金額や税率など、誤差が許されない値を扱う場合は、迷わずNUMERIC/DECIMALを選択してください。正確な10進数表現が不要な場合は、次に必要な精度を検討します。15桁を超える精度が必要であれば、浮動小数点型では対応できないため、やはりNUMERICを使用します。15桁以下の精度で十分な場合は、ストレージ効率を考慮して浮動小数点型を選びます。6桁程度の精度で事足りるなら、4バイトで済むREALが適しています。それ以上の精度が必要であれば、8バイトのDOUBLE PRECISIONを選択してください。解決策1：適切な型の選択スキーマ設計例CREATE TABLE measurements (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    -- 正確さが必要な値    price NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL,    -- 近似値で十分な値    temperature DOUBLE PRECISION,    latitude DOUBLE PRECISION,    longitude DOUBLE PRECISION,    -- 整数で表現できる値    quantity INTEGER NOT NULL,    price_cents BIGINT,  -- 代替：セント単位格納    -- 制約    CONSTRAINT valid_tax_rate CHECK (tax_rate >= 0 AND tax_rate <= 1),    CONSTRAINT valid_latitude CHECK (latitude BETWEEN -90 AND 90),    CONSTRAINT valid_longitude CHECK (longitude BETWEEN -180 AND 180));precision（精度）とscale（スケール）の設計NUMERICはNUMERIC(precision, scale)の形式で定義します。precisionは全体の有効桁数、scaleは小数点以下の桁数を指定します。用途に応じた設定例を紹介します。一般的な金額にはNUMERIC(10, 2)が適しており、-99,999,999.99から99,999,999.99までの範囲を格納できます。税率や割引率にはNUMERIC(5, 4)を使用し、0.0000から0.9999までの値を扱えます。より細かい精度が必要な場面では、暗号通貨なら小数部8桁を確保できるNUMERIC(16, 8)、為替レートなら小数部6桁のNUMERIC(10, 6)が適切です。科学的測定など高精度が求められる場合は、NUMERIC(15, 10)のように大きな精度を確保してください。解決策2：Rustでの適切な型選択f64の限界を理解するfn demonstrate_float_issues() {    // 等価比較の問題    let a = 0.1_f64 + 0.2_f64;    let b = 0.3_f64;    assert!(a != b);  // 等しくない！    // 累積誤差    let mut sum = 0.0_f64;    for _ in 0..1000 {        sum += 0.01;    }    println!("1000 × 0.01 = {}", sum);  // 9.999999999999831    // 大きな値での精度損失    let big = 1_000_000_000_000_000.0_f64;    let next = big + 1.0;    println!("{} + 1 = {}", big, next);  // 変化しない可能性}rust_decimalクレート正確な10進数計算が必要な時は以下を使用します。[dependencies]rust_decimal = { version = "1", features = ["db-postgres"] }rust_decimal_macros = "1"sqlx = { version = "0.8", features = ["postgres", "rust_decimal"] }use rust_decimal::Decimal;use rust_decimal_macros::dec;use std::str::FromStr;// 生成方法let d1 = dec!(19.99);                      // マクロ（推奨）let d2 = Decimal::from_str("19.99")?;      // 文字列からlet d3 = Decimal::new(1999, 2);            // 整数 / 10^scale// f64からの変換は精度損失の可能性あり（避ける）let risky = Decimal::from_f64(19.99);      // Option<Decimal>浮動小数点の比較方法f64を使う場合、等価比較には専用クレートを使用します。use approx::{abs_diff_eq, relative_eq};let a = 0.1_f64 + 0.2_f64;let b = 0.3_f64;// 絶対誤差での比較assert!(abs_diff_eq!(a, b, epsilon = 1e-10));// 相対誤差での比較（大きな値でも適切に動作）assert!(relative_eq!(a, b, epsilon = 1e-10));丸め戦略の選択rust_decimalは複数の丸め戦略をサポートしています。use rust_decimal::prelude::*;use rust_decimal::RoundingStrategy;let value = dec!(2.5);// 各戦略の結果value.round_dp(0)  // MidpointNearestEven: 2（デフォルト）value.round_dp_with_strategy(0, RoundingStrategy::MidpointAwayFromZero)  // 3value.round_dp_with_strategy(0, RoundingStrategy::ToZero)  // 2（切り捨て）value.round_dp_with_strategy(0, RoundingStrategy::AwayFromZero)  // 3（切り上げ） 戦略  説明  2.5  -2.5  用途  MidpointNearestEven  Banker's丸め  2  -2  統計、科学計算  MidpointAwayFromZero  四捨五入  3  -3  一般的な丸め  ToZero  切り捨て  2  -2  税額計算（日本）  AwayFromZero  切り上げ  3  -3  天井関数的  ToPositiveInfinity  正方向へ  3  -2  ceil  ToNegativeInfinity  負方向へ  2  -3  floor 解決策3：sqlxとの連携型マッピング PostgreSQL  Rust  特徴  REAL  f32  近似値、高速  DOUBLE PRECISION  f64  近似値、高速  NUMERIC  Decimal  正確、やや遅い  BIGINT  i64  整数、最速 構造体定義use rust_decimal::Decimal;use sqlx::FromRow;use uuid::Uuid;#[derive(Debug, FromRow)]struct Product {    id: Uuid,    name: String,    price: Decimal,           // NUMERIC → Decimal    weight_kg: f64,           // DOUBLE PRECISION → f64（測定値）}#[derive(Debug, FromRow)]struct SensorReading {    id: Uuid,    temperature: f64,         // センサー誤差 > FLOAT誤差    humidity: f64,    latitude: f64,    longitude: f64,    recorded_at: chrono::DateTime<chrono::Utc>,}クエリ例use rust_decimal_macros::dec;// 正確な計算が必要な場合async fn calculate_total(pool: &PgPool, order_id: Uuid) -> Result<Decimal, sqlx::Error> {    sqlx::query_scalar!(        r#"        SELECT COALESCE(SUM(price * quantity), 0)::NUMERIC as "total!"        FROM order_items        WHERE order_id = $1        "#,        order_id    )    .fetch_one(pool)    .await}// 近似値で十分な場合async fn get_average_temperature(pool: &PgPool) -> Result<f64, sqlx::Error> {    sqlx::query_scalar!(        r#"SELECT AVG(temperature) as "avg!" FROM sensor_readings"#    )    .fetch_one(pool)    .await}解決策4：整数による固定小数点最もシンプルで高速な方法を紹介します。CREATE TABLE products (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    price_cents BIGINT NOT NULL,  -- $19.99 → 1999    CONSTRAINT positive_price CHECK (price_cents > 0));/// 型安全な金額ラッパー#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]struct Cents(i64);impl Cents {    fn new(cents: i64) -> Self {        Self(cents)    }    fn from_dollars(dollars: i64, cents: i64) -> Self {        Self(dollars * 100 + cents)    }    fn dollars(&self) -> i64 {        self.0 / 100    }    fn cents_part(&self) -> i64 {        self.0.abs() % 100    }}impl std::fmt::Display for Cents {    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {        if self.0 < 0 {            write!(f, "-${}.{:02}", self.dollars().abs(), self.cents_part())        } else {            write!(f, "${}.{:02}", self.dollars(), self.cents_part())        }    }}impl std::ops::Add for Cents {    type Output = Self;    fn add(self, other: Self) -> Self {        Self(self.0 + other.0)    }}impl std::ops::Sub for Cents {    type Output = Self;    fn sub(self, other: Self) -> Self {        Self(self.0 - other.0)    }}利点:- 整数演算は常に正確- 最高のパフォーマンス- ストレージ効率が良い（8バイト固定）欠点:- 小数部の桁数が固定- 乗除算後に桁調整が必要パフォーマンスとストレージの比較 型  ストレージ  演算速度  正確性  REAL  4バイト  最速（FPU）  近似  DOUBLE PRECISION  8バイト  高速（FPU）  近似  BIGINT  8バイト  高速（整数演算）  正確  NUMERIC(10,2)  約9バイト  遅い（ソフトウェア）  正確  NUMERIC(19,4)  約13バイト  遅い  正確 大量データの集計ではFLOATが10〜100倍高速になることもあります。しかし、正確性が必要な時はNUMERICを使用してください。実践例ハイブリッドアプローチ-- 生データはFLOAT、集計結果はNUMERICCREATE TABLE sensor_data (    id BIGSERIAL PRIMARY KEY,    reading DOUBLE PRECISION NOT NULL,    recorded_at TIMESTAMPTZ NOT NULL);CREATE TABLE daily_summary (    date DATE PRIMARY KEY,    avg_reading NUMERIC(10, 4) NOT NULL,  -- 集計は正確に    min_reading NUMERIC(10, 4) NOT NULL,    max_reading NUMERIC(10, 4) NOT NULL);-- 集計時にNUMERICへ変換INSERT INTO daily_summarySELECT    DATE(recorded_at),    AVG(reading)::NUMERIC(10, 4),    MIN(reading)::NUMERIC(10, 4),    MAX(reading)::NUMERIC(10, 4)FROM sensor_dataGROUP BY DATE(recorded_at);生成列で自動計算CREATE TABLE invoices (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    subtotal NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL DEFAULT 0.10,    -- 自動計算される生成列    tax_amount NUMERIC(10, 2) GENERATED ALWAYS AS (        ROUND(subtotal * tax_rate, 2)    ) STORED,    total NUMERIC(10, 2) GENERATED ALWAYS AS (        subtotal + ROUND(subtotal * tax_rate, 2)    ) STORED);座標データの精度CREATE TABLE locations (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    -- DOUBLE PRECISIONで十分（15桁 > 必要な7桁）    latitude DOUBLE PRECISION NOT NULL,    longitude DOUBLE PRECISION NOT NULL,    -- 高精度が必要な場合のみNUMERIC    survey_latitude NUMERIC(11, 8),   -- 1mmレベルの精度    survey_longitude NUMERIC(12, 8),    CONSTRAINT valid_coords CHECK (        latitude BETWEEN -90 AND 90 AND        longitude BETWEEN -180 AND 180    ));座標の精度と実距離の対応を以下に示します。 小数点の桁数  精度  2桁  約1.1km  4桁  約11m  6桁  約11cm  8桁  約1.1mm rust_decimalの制限事項 項目  rust_decimal  PostgreSQL NUMERIC  最大値  約7.9×1028  10131072 - 1  最小スケール  10^-28  10^-16383  ストレージ  16バイト固定  可変長 PostgreSQLからの読み込み時に範囲外の値があるとエラーになります。非常に大きな精度が必要な時はbigdecimalクレートを検討してください。チェックリストスキーマ設計時[ ] FLOATを使う前に「近似値で本当に問題ないか」を確認[ ] 金額・税率・割引率にはNUMERIC/DECIMALを使用[ ] precision/scaleは将来の拡張を考慮して設定[ ] 座標データは用途に応じた精度を選択[ ] センサーデータはセンサー精度を考慮して型を選択Rust実装時[ ] 正確な計算にはrust_decimalを使用[ ] f64の等価比較にはapproxクレートを使用[ ] 丸め戦略を明示的に指定[ ] f64からDecimalへの変換は避ける（文字列経由で）おわりに冒頭で触れたテストの失敗は、金額カラムをNUMERIC(10, 2)に変更することで解消した。修正自体は数分で終わった。型の選択を間違えなければ、そもそも起きなかった問題だ。この記事で見てきたように、浮動小数点の誤差はコンピュータの本質的な制約であり、避けることはできない。しかし、対処法はシンプルだ。金額にはNUMERIC、センサーデータにはFLOAT、迷ったらNUMERIC。スキーマ設計の段階でこの判断ができれば、テストで奇妙な小数を見ることはなくなる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料PostgreSQL Numeric TypesIEEE 754 Floating-Point StandardThe Floating-Point Guiderust_decimal crateapprox crateWhat Every Programmer Should Know About Floating-PointFloating Point Numbers and Decimal in Go]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Pillars of Intelligence: 5 Essential Reading for Every ML Engineer]]></title>
            <link>https://daisuke1024akagawa.medium.com/the-pillars-of-intelligence-5-essential-reading-for-every-ml-engineer-a8cfee9be015?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/the-pillars-of-intelligence-5-essential-reading-for-every-ml-engineer-a8cfee9be015?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 24 Dec 2025 02:43:38 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[論理削除という技術的負債、それでも僕たちは使い続ける]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/24/110101</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/24/110101</guid>
            <pubDate>Wed, 24 Dec 2025 02:01:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「論理削除？deleted_atカラム追加すればいいでしょ」この一言から始まる地獄を、何度見てきただろうか。最初は簡単に見える。カラムを1つ追加するだけ。しかし、その「簡単さ」こそが罠だ。論理削除は技術的負債の温床だ。WHERE句への条件追加忘れ、認知コストの増大、テストの複雑化、パフォーマンス劣化。すべては「最初にドメインを考えなかった」ツケである。しかし現実として、サービスを運用していくと論理削除が必要になる場面は確実に訪れる。論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を解消するか、受け入れて安全に管理するか。本記事ではその両方のアプローチを解説する。なお、私はDBのスペシャリストではないので、ここで紹介する方法が唯一の正解というわけではない。あくまで一つのアプローチとして参考にしてほしい。データベース設計は文脈次第で最適解が変わるため、「この記事に書いてあったから」ではなく、自分のプロジェクトに合うかどうかで判断してほしい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理削除の何が問題なのかWHERE句地獄最も分かりやすい問題。すべてのクエリに AND deleted_at IS NULL を書く必要がある。-- 単純なSELECTSELECT * FROM users WHERE id = 1 AND deleted_at IS NULL;-- JOINするたびに増えるSELECT *FROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLINNER JOIN products p ON o.product_id = p.id AND p.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- サブクエリでも忘れずにSELECT *FROM usersWHERE id IN (    SELECT user_id FROM orders WHERE deleted_at IS NULL)AND deleted_at IS NULL;書き忘れたらどうなるか？削除したはずのデータが表示される。テストでは気づかない。本番で発覚する。深夜に電話が鳴る。JOINが増えるほど、フィルタも増える──────────────────────────────────────────────────────────  SELECT * FROM orders        │        ├──▶ WHERE orders.deleted_at IS NULL        ← 1個目        │        ├──▶ JOIN users        │         └──▶ AND users.deleted_at IS NULL  ← 2個目        │        ├──▶ JOIN products        │         └──▶ AND products.deleted_at IS NULL ← 3個目        │        └──▶ JOIN categories                  └──▶ AND categories.deleted_at IS NULL ← 4個目  テーブルが増えるたびに、書き忘れのリスクも増える認知コストの増大「このテーブル、論理削除だっけ？物理削除だっけ？」この確認が、すべてのクエリを書くたびに発生する。// このクエリ、deleted_atの条件入ってる？let users = sqlx::query_as!(User, "SELECT * FROM users WHERE status = 'active'")    .fetch_all(pool)    .await?;// レビュアー「deleted_atのフィルタ抜けてませんか？」// 作者「あ、このテーブルは物理削除です」// レビュアー「どこに書いてあります？」// 作者「...」ドキュメントに書いてあっても読まれない。コメントに書いてあっても見落とす。レビュアーの認知負荷が高い設計は、チーム規模が拡大するほど事故率が上がる。一意制約の崩壊論理削除を導入した瞬間、一意制約が意味をなさなくなる。-- emailはユニークであるべきCREATE TABLE users (    id UUID PRIMARY KEY,    email VARCHAR(255) UNIQUE,    deleted_at TIMESTAMPTZ);-- ユーザーAがemail "test@example.com" で登録-- ユーザーAを論理削除-- ユーザーBが同じemail "test@example.com" で登録しようとする-- → UNIQUE制約違反！解決策はあるが、どれも美しくない。-- 案1: 部分インデックス（PostgreSQL）CREATE UNIQUE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;-- 案2: 削除済みは別の値にするUPDATE users SET email = email || '_deleted_' || id WHERE id = $1;-- 案3: 複合ユニーク制約CREATE UNIQUE INDEX idx_users_email ON users(email, COALESCE(deleted_at, '9999-12-31'));どれを選んでも「なぜこんなことをしているのか」を説明するコストが発生する。外部キー制約との相性の悪さ-- ordersはusersを参照するCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id),    deleted_at TIMESTAMPTZ);-- ユーザーを論理削除UPDATE users SET deleted_at = NOW() WHERE id = $1;-- 問題: ordersからは削除されていないuserへの参照が残る-- deleted_at IS NULLでフィルタすると、関連データが取得できないSELECT o.*, u.nameFROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- → ユーザーが論理削除されると、その注文も見えなくなる（意図した動作？）「削除されたユーザーの注文はどう扱うべきか」という問いに、論理削除は答えを持っていない。データベースが提供する整合性保証を、アプリケーションコードで再実装する羽目になる。カスケード削除との相性が最悪-- 物理削除用に設計されたスキーマCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id) ON DELETE CASCADE);-- 論理削除を導入すると...UPDATE users SET deleted_at = NOW() WHERE id = $1;-- → ordersは削除されない（CASCADEはDELETEにしか反応しない）-- → 「削除された」ユーザーの注文が残り続けるパフォーマンス問題論理削除されたレコードが増えるほど、テーブルは肥大化する。パーシャルインデックスで対処できる。しかし、これも「論理削除を選んだがゆえの追加コスト」だ。-- 10年運用したサービス-- 全レコード: 100万件-- 有効レコード: 10万件-- 削除済みレコード: 90万件-- すべてのクエリが90万件のゴミをスキャンする可能性があるSELECT * FROM users WHERE email = 'test@example.com' AND deleted_at IS NULL;CREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;テストの複雑化#[tokio::test]async fn test_get_active_users() {    // 有効なユーザーを作成    let active_user = create_user(&pool, "active@example.com").await;    // 削除済みユーザーを作成    let deleted_user = create_user(&pool, "deleted@example.com").await;    soft_delete_user(&pool, deleted_user.id).await;    // テスト対象    let users = get_all_users(&pool).await;    // 削除済みが含まれていないことを確認    assert!(!users.iter().any(|u| u.id == deleted_user.id));}// このテストを書き忘れると、バグが本番に流出する// すべてのクエリに対して、このテストが必要deleted_at vs is_deleted：どちらを選ぶべきか論理削除の実装には2つの方式がある。-- 方式1: タイムスタンプ（deleted_at）deleted_at TIMESTAMPTZ  -- NULLなら有効、値があれば削除済み-- 方式2: ブールフラグ（is_deleted）is_deleted BOOLEAN DEFAULT FALSE  -- falseなら有効、trueなら削除済みdeleted_at を推奨する理由：「いつ削除されたか」という情報が自動的に残る監査ログとして機能する「30日以上前に削除されたデータをアーカイブ」といった処理が書きやすいis_deleted のメリット：シンプルで直感的インデックスが小さくなる（BOOLEAN vs TIMESTAMPTZ）NULLの扱いを考えなくてよい（deleted_at IS NULL vs is_deleted = false）私の経験では deleted_at が主流だ。削除日時の情報は運用・デバッグで頻繁に必要になる。ただし、削除日時が不要でパフォーマンスを最優先するなら is_deleted も選択肢になる。RustのORMには論理削除サポートがないRustのORMは、論理削除の組み込みサポートを持たない。// SeaORM - 論理削除の組み込みサポートなしlet users = User::find().all(&db).await?;// deleted_atのフィルタは手動で追加する必要があるlet users = User::find()    .filter(user::Column::DeletedAt.is_null())    .all(&db)    .await?;// 毎回書く必要がある。書き忘れてもコンパイルは通る。// Diesel - 同様に組み込みサポートなしlet users = users::table    .filter(users::deleted_at.is_null())    .load::<User>(&mut conn)?;// sqlx - 生SQLなので当然サポートなしlet users = sqlx::query_as!(User,    "SELECT * FROM users WHERE deleted_at IS NULL").fetch_all(pool).await?;Rustは「暗黙の動作」より「明示的なコード」を好む文化がある。論理削除フィルタが自動適用されるのは便利だが、何が起きているか分かりにくくなる。そのため、RustのORMは意図的にこの機能を持たないとも解釈できる。しかし、Dieselには diesel-softdelete というコミュニティcrateが存在する。// diesel-softdelete の使用例use diesel_softdelete::SoftDelete;// soft_find: findと同等だが、削除済みを自動除外let user = users::table.soft_find(user_id).first(&mut conn)?;// soft_inner_join: JOINのON句に削除フィルタを適用let posts = posts::table    .soft_inner_join(users::table)    .load(&mut conn)?;SeaORMには同様のcrateは存在しない。現実として、Rustでは論理削除を自分で安全に実装する必要がある。本記事で紹介する6つのパターンは、この課題に対する解決策だ。Linterで防げないのか「WHERE句の書き忘れ、Linterで検出できないの？」という疑問は当然だ。結論から言うと、難しい。SQLFluff（SQLリンター）の限界SQLFluffでカスタムルールを書くことは可能だが、根本的な問題がある。# .sqlfluff - カスタムルールの例[sqlfluff:rules]# 「deleted_at IS NULL を含まないSELECTを警告」というルールを書きたい# しかし...どのテーブルが論理削除対象か、Linterは知らないJOINの場合、どのテーブルにフィルタが必要か判定できないサブクエリの中まで追跡するのは複雑www.sqlfluff.comsqlx のコンパイル時チェックの限界sqlxはコンパイル時にSQLの構文と型をチェックするが、「論理削除フィルタがあるか」はチェックしない。// これはコンパイルが通る（deleted_at フィルタなし）let users = sqlx::query_as!(User, "SELECT * FROM users WHERE status = 'active'")    .fetch_all(pool)    .await?;理論的には可能だが、コストが高いProc Macroで独自のクエリマクロを作れば、検出は可能だ。// 理論上のカスタムマクロsoft_query_as!(User, "SELECT * FROM users WHERE status = 'active'")// → コンパイルエラー: "deleted_at IS NULL" が含まれていませんしかし、これを実装・保守するコストは高い。テーブルごとの論理削除設定、JOIN時の挙動、サブクエリの処理など、考慮すべきことが多い。結論：Linterより「ミスできない設計」Linterは「ミスを検出する」アプローチだ。しかし、論理削除の問題は「そもそもミスできない設計」で解決した方が確実だ。RLSやビューを使えば、アプリケーション側でフィルタを書き忘れても、データベースが守ってくれる。Linterで「書き忘れを検出する」より、「書き忘れても問題ない」設計の方が堅牢だ。www.postgresql.orgなぜそれでも論理削除を選ぶのかここまで問題を挙げてきた。それでも論理削除が選ばれ続ける理由を以下に示す。「削除」は本当に削除ではないビジネスの世界では、「削除」は「なかったこと」にすることではない。経理: 「この取引、間違いだったので削除してください」開発者: （物理削除を実行）経理: 「監査が来たとき、削除した取引の履歴を見せてください」開発者: 「...」法規制、監査対応、コンプライアンス。データを完全に消すことが許されないケースは多い。誤操作からの復旧ユーザー: 「間違えて投稿を削除してしまいました。復旧できますか？」物理削除なら「できません」。論理削除なら「できます」。この違いはサポートコストとユーザー満足度に直結する。関連データの整合性-- ユーザーを物理削除すると...DELETE FROM users WHERE id = $1;-- 関連する注文履歴はどうする？-- ON DELETE CASCADE で連鎖削除？→ 売上データが消える-- ON DELETE SET NULL で孤児にする？→ 「誰の注文かわからない」データが残る論理削除なら、関連データの整合性を保ったまま「削除扱い」にできる。分析・デバッグ用途-- なぜこのユーザーは退会したのか？SELECT * FROM users WHERE deleted_at IS NOT NULL ORDER BY deleted_at DESC;-- 削除前の状態を確認したいSELECT * FROM posts WHERE id = $1;  -- 削除済みでも見れる物理削除されたデータは、永遠に失われる。論理削除の本当の問題ここまでの問題点を整理すると、論理削除の本当の問題が見えてくる。それは「削除」という概念を、データモデルとして表現していないことだ。deleted_at カラムは、「このレコードは存在するが、存在しないことにしてほしい」という矛盾した状態を表現している。この矛盾が、すべての問題の根源だ。まず代替手段を検討せよここまで論理削除の問題を散々挙げてきた。では、どうすればいいのか。答えは状況によって異なる。まず、自分がどの状況にいるかを確認しよう。状況A: 新規設計の場合論理削除を使わない選択肢がある。代替手段を検討すべきだ。状況B: 既存システムの場合すでに deleted_at が導入されたテーブルが100個あるなら、今日明日で変えられるわけがない。事故を防ぐ仕組みで覆うしかない。本セクションでは状況Aの代替手段を、次のセクションでは状況Bの安全な実装パターンを解説する。新規設計なら、より良い選択肢がある。Archive テーブルパターン（推奨）削除されたデータを別テーブルに移動する、最もシンプルな代替手段。-- 本番テーブル（有効なデータのみ）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255) UNIQUE  -- 一意制約が正常に機能);-- アーカイブテーブル（削除済みデータ）CREATE TABLE archived_users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),  -- UNIQUEなし    archived_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),    archived_by UUID,    archive_reason TEXT);-- 削除時のトランザクションBEGIN;INSERT INTO archived_users (id, name, email, archive_reason)SELECT id, name, email, 'user_requested' FROM users WHERE id = $1;DELETE FROM users WHERE id = $1;COMMIT;メリット:本番テーブルはシンプルなまま一意制約、外部キー制約が正常に機能WHERE句地獄から解放アーカイブテーブルは別ストレージに配置可能デメリット:復元時にデータ移動が必要スキーマ変更時に両テーブルの更新が必要Temporal Tables（履歴テーブル）SQL:2011で標準化された機能。PostgreSQL 9.2+、SQL Server 2016+、MariaDB 10.3+でサポート。-- PostgreSQLでのTemporal Table（拡張機能を使用）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),    valid_from TIMESTAMPTZ NOT NULL DEFAULT NOW(),    valid_to TIMESTAMPTZ NOT NULL DEFAULT 'infinity');-- 過去の状態を参照SELECT * FROM usersWHERE id = $1  AND valid_from <= '2024-01-15'  AND valid_to > '2024-01-15';メリット:変更履歴が自動的に保存される「誰が」「いつ」「何を」変更したか追跡可能通常のクエリには影響なしデメリット:テーブルサイズが急速に増大（高頻度更新テーブルでは問題）複数テーブル間の相関は追跡できないEvent Sourcing状態ではなく「イベント」を保存する設計パターン。#[derive(Debug)]pub enum UserEvent {    Created { id: Uuid, name: String, email: String },    Updated { id: Uuid, name: Option<String>, email: Option<String> },    Deleted { id: Uuid, reason: String },    Restored { id: Uuid },}// イベントを順番に適用して現在の状態を再構築fn rebuild_user(events: &[UserEvent]) -> Option<User> {    let mut user: Option<User> = None;    for event in events {        match event {            UserEvent::Created { id, name, email } => {                user = Some(User { id: *id, name: name.clone(), email: email.clone(), deleted: false });            }            UserEvent::Deleted { .. } => {                if let Some(ref mut u) = user { u.deleted = true; }            }            UserEvent::Restored { .. } => {                if let Some(ref mut u) = user { u.deleted = false; }            }            // ...        }    }    user.filter(|u| !u.deleted)}メリット:完全な監査ログ（ビジネスコンテキスト含む）任意の時点の状態を再現可能デバッグが容易デメリット:学習コストが高い読み取りパフォーマンスの課題（スナップショットが必要）既存システムへの導入が困難PostgreSQL パーティショニング大量データの削除が必要な場合、パーティショニングが有効。-- 月別パーティションテーブルCREATE TABLE events (    id UUID,    created_at TIMESTAMPTZ NOT NULL,    data JSONB) PARTITION BY RANGE (created_at);-- パーティションを作成CREATE TABLE events_2024_01 PARTITION OF events    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');CREATE TABLE events_2024_02 PARTITION OF events    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');-- 古いデータの削除: DELETEではなくDROPDROP TABLE events_2023_01;  -- 瞬時に完了、VACUUMも不要メリット:大量削除が一瞬（DROP TABLE）VACUUM負荷なしパーティションプルーニングで検索も高速デメリット:パーティションキーの設計が重要管理の複雑さ（pg_partman等のツール推奨）選択フローチャートRustで論理削除を安全に実装する6つのパターン代替手段を検討した上で、それでも論理削除が必要な場合。ここからは、Rustの型システムとPostgreSQLの機能を活用して、論理削除を安全に実装する具体的なパターンを紹介する。パターン1：Newtype Patternで状態を型として表現する最もRustらしいアプローチ。「有効なデータ」と「削除済みデータ」を別の型として定義する。use chrono::{DateTime, Utc};use sqlx::PgPool;use uuid::Uuid;/// 有効なユーザー（削除されていない）#[derive(Debug, sqlx::FromRow)]pub struct ActiveUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub created_at: DateTime<Utc>,}/// 削除済みユーザー#[derive(Debug, sqlx::FromRow)]pub struct DeletedUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub deleted_at: DateTime<Utc>,}impl ActiveUser {    /// 有効なユーザーを1件取得    pub async fn find_by_id(        pool: &PgPool,        id: Uuid,    ) -> Result<Option<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            r#"            SELECT id, name, email, created_at            FROM users            WHERE id = $1 AND deleted_at IS NULL            "#,            id        )        .fetch_optional(pool)        .await    }    /// 論理削除を実行    pub async fn soft_delete(pool: &PgPool, id: Uuid) -> Result<bool, sqlx::Error> {        let result = sqlx::query!(            r#"            UPDATE users            SET deleted_at = NOW(), updated_at = NOW()            WHERE id = $1 AND deleted_at IS NULL            "#,            id        )        .execute(pool)        .await?;        Ok(result.rows_affected() > 0)    }}メリット：通常のコードパスでは削除済みデータに触れることが型的に不可能削除済みデータへのアクセスが明示的になるコンパイル時に安全性が保証されるパターン2：トレイトで共通インターフェースを定義する複数のエンティティで論理削除を扱う場合、トレイトで共通化する。use async_trait::async_trait;#[async_trait]pub trait SoftDeletable: Sized {    type Id;    async fn find_active(pool: &PgPool, id: Self::Id) -> Result<Option<Self>, sqlx::Error>;    async fn all_active(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error>;    async fn soft_delete(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;    async fn restore(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;}// ジェネリックな関数での利用async fn list_active<T: SoftDeletable>(pool: &PgPool) -> Result<Vec<T>, sqlx::Error> {    T::all_active(pool).await}パターン3：PostgreSQLビューで安全なデフォルトを作るデータベース側で「安全なデフォルト」を定義する。-- マイグレーション: 有効データのみを返すビューを作成CREATE VIEW active_users ASSELECT id, name, email, created_at, updated_atFROM usersWHERE deleted_at IS NULL;-- パーシャルインデックスで検索を高速化CREATE INDEX idx_users_active ON users(id) WHERE deleted_at IS NULL;impl ActiveUser {    /// ビューから取得（削除済みは絶対に含まれない）    pub async fn all(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            "SELECT id, name, email, created_at, updated_at FROM active_users"        )        .fetch_all(pool)        .await    }}メリット：Rustコードでフィルタを忘れる心配がない他の言語やツール（psql、DBeaver等）からも安全JOINでも自動的にフィルタが適用されるパターン4：行レベルセキュリティ（RLS）で強制フィルタリングPostgreSQLのRLSを使って、データベースレベルで論理削除フィルタを強制する。-- 行レベルセキュリティを有効化ALTER TABLE users ENABLE ROW LEVEL SECURITY;-- デフォルトポリシー：削除済みは見えないCREATE POLICY users_active_only ON users    FOR SELECT    USING (        deleted_at IS NULL        OR current_setting('app.include_deleted', true) = 'true'    );/// 通常のクエリ（削除済みは自動的に除外される）pub async fn get_all_users(pool: &PgPool) -> Result<Vec<User>, sqlx::Error> {    sqlx::query_as!(User, "SELECT id, name, email FROM users")        .fetch_all(pool)        .await    // RLSにより、deleted_at IS NULLのレコードのみが返される}/// 削除済みを含める場合（明示的な設定が必要）pub async fn get_all_users_including_deleted(pool: &PgPool) -> Result<Vec<UserWithStatus>, sqlx::Error> {    let mut tx = pool.begin().await?;    sqlx::query("SET LOCAL app.include_deleted = 'true'")        .execute(&mut *tx)        .await?;    let users = sqlx::query_as!(UserWithStatus, "SELECT id, name, email, deleted_at FROM users")        .fetch_all(&mut *tx)        .await?;    tx.commit().await?;    Ok(users)}パターン5：リポジトリパターンで抽象化するレイヤードアーキテクチャでの実装パターン。#[async_trait]pub trait ReadRepository<T, Id> {    async fn find(&self, id: Id) -> Result<Option<T>, RepositoryError>;    async fn all(&self) -> Result<Vec<T>, RepositoryError>;    async fn exists(&self, id: Id) -> Result<bool, RepositoryError>;}#[async_trait]pub trait WriteRepository<T, Id>: ReadRepository<T, Id> {    type CreateInput;    type UpdateInput;    async fn create(&self, input: Self::CreateInput) -> Result<T, RepositoryError>;    async fn update(&self, id: Id, input: Self::UpdateInput) -> Result<T, RepositoryError>;    async fn delete(&self, id: Id) -> Result<bool, RepositoryError>; // 論理削除}リポジトリの実装内部で常に deleted_at IS NULL を適用することで、利用側はフィルタを意識する必要がなくなる。パターン6：マクロで定型コードを削減する毎回同じパターンを書くのは面倒なので、マクロで自動生成する。macro_rules! impl_soft_deletable {    ($struct:ident, table = $table:literal, id_type = $id_type:ty) => {        impl $struct {            pub async fn find_active(pool: &PgPool, id: $id_type) -> Result<Option<Self>, sqlx::Error> {                // 実装            }            pub async fn soft_delete(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }            pub async fn restore(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }        }    };}// 使用例impl_soft_deletable!(Comment, table = "comments", id_type = Uuid);パターン比較 パターン  型安全性  実装コスト  DB依存  推奨シーン  Newtype Pattern  高  中  低  型を重視するプロジェクト  トレイト抽象化  高  中〜高  低  複数エンティティがある場合  ビュー  中  低  高  シンプルなCRUD、多言語環境  RLS  高  中  高  マルチテナント、厳格なセキュリティ  リポジトリ  高  高  低  大規模プロジェクト、DDD  マクロ  中  低  低  定型コードを減らしたい 運用のベストプラクティス6つのパターンを紹介したが、どれか1つを選べば終わりではない。実際の運用では、これらを組み合わせて使う。そして、どのパターンを選んでも共通して守るべきルールがある。すべての対策を講じた上で、それでも deleted_at 方式を選ぶなら、以下を徹底する。必須チェックリスト□ ビューを作成し、アプリはビュー経由でアクセス□ パーシャルインデックスを作成□ リポジトリパターンで抽象化□ 削除済みデータのテストを全クエリに追加□ 定期的なアーカイブ処理を実装必ずビューを作るCREATE VIEW active_users AS SELECT * FROM users WHERE deleted_at IS NULL;アプリケーションは active_users にしかアクセスしない。必ずリポジトリパターンを使うpub trait UserRepository {    async fn find(&self, id: Uuid) -> Result<Option<User>, Error>;  // 常に有効のみ}必ずテストを書く#[test]fn deleted_users_are_not_returned() { /* ... */ }すべてのクエリに対して、このテストを義務化する。必ずパーシャルインデックスを作るCREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;パフォーマンス劣化を最小限に抑える。必ず定期的にアーカイブする-- 1年以上前に削除されたデータをアーカイブテーブルに移動INSERT INTO archived_usersSELECT * FROM usersWHERE deleted_at < NOW() - INTERVAL '1 year';DELETE FROM usersWHERE deleted_at < NOW() - INTERVAL '1 year';本番テーブルの肥大化を防ぐ。おわりに論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を無視して deleted_at を追加すると、WHERE句地獄、認知コスト、バグの温床という形で跳ね返ってくる。しかし、法規制・監査・誤操作復旧のため、論理削除が必要になる場面は確実に訪れる。そのとき、2つの選択肢がある。矛盾を解消する設計（Archiveテーブル、Event Sourcing）を選ぶか、矛盾を受け入れて型システムとデータベース機能で安全に管理するか。本記事ではRustの型システムとPostgreSQLの機能を活用した安全な実装パターンを紹介した。ただし、データベース設計は文脈次第で最適解が変わる。ここで紹介した方法が唯一の正解ではないので、自分のプロジェクトの要件に照らし合わせて判断してほしい。参考リンクAvoiding the soft delete anti-pattern - 論理削除がアンチパターンになる理由Soft Deletion Probably Isn't Worth It - 論理削除の代替手段の検討The Day Soft Deletes Caused Chaos - 論理削除が引き起こした実際の障害事例diesel-softdelete - DieselのためのSoft Delete拡張Soft deletion with PostgreSQL - PostgreSQLでの論理削除実装Beyond DELETE: Drop Partitions, Not Performance - パーティショニングによる削除最適化Temporal Tables and Event Sourcing - 代替アプローチの比較参考書籍達人に学ぶDB設計徹底指南書 第2版作者:ミック翔泳社Amazon達人に学ぶSQL徹底指南書 第2版 初級者で終わりたくないあなたへ作者:ミック翔泳社Amazon失敗から学ぶRDBの正しい歩き方 Software Design plus作者:曽根 壮大技術評論社AmazonSQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonセンスの良いSQLを書く技術　達人エンジニアが実践している３５の原則作者:ミックKADOKAWAAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NeMo Guardrails: Putting the “Responsible” in AI]]></title>
            <link>https://daisuke1024akagawa.medium.com/nemo-guardrails-putting-the-responsible-in-ai-ef7e0bfffea0?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/nemo-guardrails-putting-the-responsible-in-ai-ef7e0bfffea0?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Tue, 23 Dec 2025 12:02:25 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[書評や要約は「圧縮」ではなく「変換」であり、「変換」に価値がある。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/23/111651</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/23/111651</guid>
            <pubDate>Tue, 23 Dec 2025 02:16:51 GMT</pubDate>
            <content:encoded><![CDATA[タイトルがそのままゴールなのですがダラダラ書きます。はじめにある技術書の要約を読んで、「なるほど、この本の主張はこういうことか」と納得した。数ヶ月後、原著を手に取って驚いた。要約で「核心」とされていた部分は、実は本全体の一部に過ぎなかった。著者が本当に伝えたかったことは、要約では一行も触れられていなかったのだ。技術書、非技術書に限らず、書評や要約を読んでいると、ある違和感に気づく。これは「圧縮」ではなく、本質的に異なるものではないか。原著者の思考プロセスは消失し、要約者のフィルタリングと優先度により情報が再構成される。同じ本から異なる要約が生まれる。そのコンテキストを知らずに読むと、原典でなく要約者の思想を取り込んでしまう。これはデジタル圧縮に例えるなら、可逆圧縮ではなく非可逆変換だ。ZIPファイルのように元に戻せる圧縮ではなく、JPEGのように一度変換すれば二度と元には戻らない変換。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズム——この場合は要約者——の判断に依存する。でもここで誤解してほしくないのは、これは要約や書評を否定する話ではないということだ。むしろ、その本質を正しく理解し、積極的に活用するための話だ。要約や書評は「圧縮」ではなく「変換」であり、その変換には独自の価値がある。原著の劣化コピーではなく、原著から触発された新しい思考の産物として。原著への入り口として、あるいは原著と対話する形で展開される考察として。そしてその価値を最大限に引き出すには、私たちが変換というプロセスを意識し、批判的に読み、創造的に使いこなす必要がある。同時に、本当に大切な本については、時間をかけてちゃんと読む——その価値を見失わないことも重要だ。なぜなら、本をちゃんと読むことは、自分を長い時間をかけて変容させることだから。そしてその変容は、要約では決して起きないから。圧縮という幻想私たちは「要約」という言葉を、まるでファイルの圧縮のように捉えている。元の情報を小さくしただけ、重要な部分だけを取り出しただけ、だから本質は変わらない——そう思い込んでいる。しかし本当は違う。デジタルの世界には二つの圧縮がある。ZIPファイルのような可逆圧縮と、JPEGのような非可逆変換。前者は展開すれば元に戻るが、後者は一度変換すれば二度と元には戻らない。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズムの設計思想に依存する。書評や要約は、後者だ。これは単なる比喩ではない。要約という行為は、情報を小さくしているのではなく、情報を別の何かに変えているのだ。そしてその過程で、何かが——多くの場合、最も大切な何かが——失われる。要約という名の変換要約のプロセスを観察してみるといい。そこには、本人も気づいていない、いくつもの「変換」が起きている。選択的フィルタリングという暴力要約者は、自分が「重要だ」と判断した部分を抽出する。しかしこの「重要性」は、極めて主観的だ。要約者の経験、専門性、価値観、そして何より要約者が今抱えている問題意識——これらすべてが、無意識のフィルターとして機能する。マーケティング担当者が読む技術書と、エンジニアが読む同じ技術書では、心に残る章が違う。当然だ。でもこれは、どちらかが間違っているという話ではない。同じ本から、異なる意味が立ち上がっているだけだ。そしてその意味の違いは、読者ではなく、読み方によって生まれる。要約という行為は、この「読み方」を一つに固定する。要約者の読み方が、唯一の読み方として提示される。そして要約を読む私たちは、その固定された読み方を、本の内容そのものだと錯覚する。文脈の切断という喪失著者は意図的に章を配置する。第一章から第十章へと、徐々に論理を積み上げていく。前の章の具体例が、後の章の理論の基礎になる。ある議論は、数章前の別の議論を前提としている。この「流れ」は、本の核心的な要素の一つだ。理解とは情報の構造化だからだ。著者が用意した順序で読むことで、私たちの頭の中に、新しい思考の枠組みが少しずつ形成されていく。でも要約は、この流れを切断する。第三章の結論、第七章の重要なポイント、第十章のまとめ——それらは箇条書きになって並べられ、互いの繋がりは失われる。結論だけが残り、そこに至るまでの思考の階段は消える。そして多くの場合、その階段こそが、最も価値のある学びだったのだ。言語の置き換えという変質著者が選んだ言葉には、意味がある。その比喩、その言い回し、その微妙なニュアンス——それらはすべて、著者が伝えたい何かを形にするために、慎重に選ばれている。しかし要約者は、それを自分の言葉に置き換える。分かりやすく、簡潔に、読みやすく。善意からの行為だ。しかしこの過程で、著者の「声」は失われる。翻訳と同じだ。どれだけ優れた翻訳でも、原文の響きは失われる。要約も同じ。どれだけ丁寧な要約でも、著者が選んだ言葉の持つ微妙な意味の重なりは、消えてしまう。そして私たちは、その消失に気づかない。思考プロセスの消失という致命的な欠落最も大きな喪失は、これだ。著者が試行錯誤の末に辿り着いた結論。一度は正しいと思ったが、後に間違いだと気づいた考え。検討したが採用しなかった別のアプローチ。考えを変えた転機となった出来事。こうした思考の軌跡は、要約では「結論」だけが残る。「著者はこう主張している」と。でも、なぜその主張に至ったのか、どんな葛藤があったのか、何を捨てて何を選んだのか——そのすべてが消える。けれど、学びとは結論を知ることではなく、その結論に至るプロセスを追体験することだ。著者の思考の軌跡を辿ることで、私たちの思考の枠組みが変わる。結論だけを知っても、それは情報の追加にすぎず、思考の変容は起きない。要約は、この核心を、最初に捨てる。同じ本、異なる要約の謎興味深い実験をしてみるといい。同じ一冊の本について、複数の要約を読んでみるといい。驚くほど違う内容が書かれている。ある経営書を読んだ場合を想像してみよう。スタートアップの創業者は、リスクテイクと革新の章を強調するかもしれない。彼らにとって重要なのは「いかに新しいことを試すか」だから。大企業の管理職は、組織マネジメントと持続可能性の部分に注目するだろう。彼らが直面しているのは、既存の組織をいかに動かすかという問題だから。学者は、理論的フレームワークと研究手法に焦点を当てる。彼らが関心を持つのは、この本がどんな学術的文脈に位置するかだから。それぞれの要約は「正しい」。でもそれは、元の本ではない。要約者のレンズを通して屈折した像だ。そして恐ろしいことに、私たちはその屈折を、見ることができない。なぜか。要約には、要約者の視点が明示されないからだ。「私はスタートアップ創業者として、この本からリスクテイクの部分に注目した」とは書かれない。ただ「この本の重要なポイントは」と書かれる。まるで客観的な事実であるかのように。しかし客観的な要約など、存在しない。すべての要約は、誰かの主観を通した変換だ。その主観は、透明なレンズのように見えて、実は色付きのフィルターなのだ。「読んだ」と「読んでいない」という曖昧な境界私たちは「本を読んだ」という言葉を単純に使いすぎている。ピエール・バイヤールの『読んでいない本について堂々と語る方法』では、読書という行為を興味深く分類している。バイヤールは読書を次のように区分けする。UB（unread book） ——まったく読んでいない本SB（skimmed book） ——ざっと目を通した本HB（heard about book） ——人から聞いた本、あるいは書評で知った本FB（forgotten book） ——読んだが内容を忘れた本この分類を見て、私たちは気づく。「読んだ」と「読んでいない」という二項対立は、実は単純なものではないのだと。最後のページまで目を通したが内容をほとんど覚えていない本と、要約だけ読んだが著者の主張をよく理解している本——どちらが「読んだ」と言えるのか。人から聞いた話を通じてその本の核心的なアイデアに触れた場合と、本は買ったが積読のまま放置している場合——どちらが「読んでいない」と言えるのか。答えは簡単ではない。というより、この問い自体が間違っているのかもしれない。問われるのは「読んだか読んでいないか」という形式的な区分けではなく、その本とどのような関係を結んでいるか、その本を通じてどのような思考を展開できるか——そういった実質的な次元なのだ。読んでいない本について語る「状況」バイヤールは、読んでいない本について語ることの不可避性を指摘する。私たちは日常的に、読んでいない本について語らざるを得ない状況に置かれている。会議で誰かが本を引用する。読んだことはないが、その場で意見を求められる。友人が「あの本、どう思う？」と訊いてくる。正直に「読んでない」と言えば会話は終わるが、書評で得た知識をもとに語れば、豊かな対話が生まれる。就職面接で「最近読んだ本は？」と訊かれる。最後まで読了した本だけを答えの対象にすれば、選択肢は著しく狭まる。これらの状況を具体的に検討してみると、面白いことが見えてくる。本について語ることは、必ずしも本を最後まで読了していることを前提としていない。むしろ、本の周辺にある言説——書評、要約、他者の解釈、断片的な引用——これらを媒介にして語ることが、実は創造的な思考を生み出すことがある。友人が薦めた本について、その友人の語り口から想像を膨らませて議論する。その過程で、原著にはない新しい視点が生まれることがある。書評を読んで著者の意図を「誤読」し、その誤読から独自の考察を展開する。その考察が、時として原著を超える洞察に至ることもある。つまり、本について語ることは、必ずしも本を「正確に」理解することを目的としていない。本を触媒として、自分の思考を展開すること——それが本質なのだ。要約という考察の可能性ここで視点を変えてみよう。要約や書評を、単なる「劣化コピー」ではなく、一種の「考察」として捉え直すとどうなるか。要約者は、本を読んで何かを感じ取る。その「何か」を言語化しようとする。この過程は、実は高度に創造的な行為だ。無数の情報の中から何を選び、どう配置し、どう言葉にするか——この選択と構成の過程で、要約者独自の思考が立ち上がる。だから、優れた書評や要約は、原著とは別の価値を持つ。それは原著の「圧縮版」ではなく、原著から触発された、要約者の「考察」なのだ。私自身、年間でかなりの書評を作っている。しかし公開しているのはごくごく一部だ。なぜか。私はあまり有能な方ではないから、書籍を漫然と読んでも深い学びを得ることができない。だから書評を書く。書評を書くという行為を通じて、自分が何を理解し、何を理解していないのかを明確にする。どこに引っかかったのか、どこが腑に落ちたのか——それを言語化することで、初めて本当の理解が生まれる。公開しているものは、作った書評の中で「公開して良いかな」と思った文章を加筆修正したものだ。つまり、書評を書く行為そのものは、公開のためではなく、自分の理解を深めるためのものなのだ。たとえば、ある技術書について複数のエンジニアが書評を書いたとする。一人は実装の観点から、一人は設計思想の観点から、一人は歴史的文脈の観点から語る。これらの書評を読むことで、私たちは原著が持つ多面性に触れることができる。そしてそれぞれの書評が、原著を読むための異なる「補助線」になる。この意味で、要約や書評は原著を補完し、豊かにする。原著だけを読むよりも、原著と複数の書評を読む方が、理解が深まることがある。なぜなら、一冊の本が持つ可能性を、複数の視点から照らし出すことができるからだ。ファスト教養という時代の文脈ただし、ここで注意すべき点がある。要約や書評が「考察」として価値を持つのは、それが原著への入り口として機能するか、あるいは原著と対話する形で展開される場合だ。現代には「ファスト教養」とでも呼ぶべき現象がある。短時間で「教養」を身につけたように見せるための、効率化された知識の消費。要約を読んで「読んだ」と言い、書評を見て「理解した」と思い込む。そこには、本との本当の対話はない。ファスト教養の問題は、効率性そのものではない。問題は、本と自分の間に常に誰か（要約者、解説者、インフルエンサー）が介在し、自分で考える機会が失われることだ。バイヤールが指摘するように、読んでいない本について語ることは、自分で思考し言語化する状況では創造的な行為になり得る。しかしそれは、自分の頭で考え、自分の言葉で語る場合に限る。誰かの要約をコピー&ペーストして語るのは、創造ではなく模倣だ。変換を活用する五つの方法では、要約や書評という「変換」を、どう活用すべきなのか。1. 要約者の視点を意識する要約を読むとき、「これは誰の視点か」を常に問う。その人の専門性、立場、問題意識——それらを意識することで、フィルターの存在が見えてくる。そして「では自分なら、どこに注目するか」と考える。2. 複数の解釈を並置する一つの要約だけを読むのではなく、複数の異なる視点からの解釈を集める。それらを比較することで、本が持つ多面性が見えてくる。そして何より、「絶対的な正解」など存在しないことが分かる。3. 要約を「問い」として読む要約を「答え」として受け取るのではなく、「問い」として読む。「この要約者はなぜこの部分を重要だと判断したのか」「省略された部分には何があったのか」——そう問うことで、要約は思考の出発点になる。4. 自分なりの考察を加える要約を読んで、自分なりの考察を加えてみる。「自分の経験ではどうか」「別の文脈ではどうなるか」「反対の立場から見たらどうか」——そうやって思考を展開することで、要約は単なる情報から、思考の触媒へと変わる。5. 原典への道標として使うそして何より、要約を原典への道標として使うことだ。要約で興味を持ったら原典を読む。要約で疑問を持ったら原典で確認する。要約と原典の間を行き来することで、理解は深まる。読んでいない本について語る際の倫理バイヤールは、読んでいない本について語る際に注意すべき点を挙げている。第一に、読んでいないことを隠す必要はない。「詳しくは読んでいないが」「書評で読んだ限りでは」——そう前置きすることで、誠実さを保ちながら対話を続けられる。第二に、自分の解釈を絶対化しない。「私はこう理解した」「私にはこう見える」——主語を「私」にすることで、それが一つの視点に過ぎないことを示す。第三に、他者の解釈を尊重する。要約や書評は、誰かの真剣な思考の結果だ。それを軽んじることなく、一つの有効な視点として受け止める。そして第四に、思考を停止させないことだ。要約を読んで「分かった」で終わらせず、そこから自分なりの思考を展開する。これらの点を意識すれば、読んでいない本について語ることは、単なる知ったかぶりではなく、創造的な知的活動になり得る。要約や書評を通じて、新しい視点を獲得し、自分の思考を深め、時には原著を超える洞察に至ることさえ可能なのだ。書評・要約と著作権——変換者の責任変換の価値を語るとき、避けて通れない現実がある。それは法律だ。私たちが要約や書評を「考察」として価値あるものにできるのは、それが著作者の権利を侵害しない範囲で行われる場合に限る。自分の良し悪しだけで判断できる問題ではない。著作権法では、著作物を「翻案」する権利は著作権者に帰属する。要約はこの「翻案」に該当する可能性がある。一方で、「引用」は一定の条件を満たせば許諾なく行える。興味深いのは判例だ。「血液型と性格」事件（東京地判平成10年）では、やむを得ない範囲での要約引用は著作権侵害にならないと判断された。全文をそのまま引用するより、要約する方が著作権者の利益を損なわない場合があるという理由だ。ここに、変換という行為の本質が見える。情報そのものには著作権はないが、表現には著作権がある。著者の文章表現をそのまま使うのは問題になり得る。しかし、その情報を自分の言葉で表現し直すのであれば——つまり、本当の意味で「変換」するのであれば——著作権侵害には該当しにくい。これは単なる法的な制約ではない。むしろ、変換者としての私たちに課された創造的な責任だ。他人の言葉をコピーするのではなく、自分の言葉で語り直す。その過程で、私たちは否応なく考えることを強いられる。要約や書評は、著作者と読者をつなぐ架け橋になり得る。しかしそれは、著作者の権利を尊重し、自分の言葉で語るという責任を引き受けた上でのことだ。変換の二面性要約や書評という「変換」は、原著者の思想と要約者の解釈が混ざり合ったハイブリッドだ。そしてその混ざり具合は、多くの場合見えない。ここには確かに危険性がある。要約を原著そのものだと錯覚し、要約者の解釈を著者の思想だと思い込む。そして気づかないうちに、自分で考える機会を失う。著者の思想と対峙し、自分の経験と照らし合わせ、時には反論し、格闘する——その過程が省略される。でも同時に、ここには可能性もある。要約や書評は、原著にはない新しい視点を提供してくれることがある。著者自身も気づいていなかった含意を、要約者が読み取ることがある。異なる文脈に置き直すことで、原著が持つ新しい意味が立ち上がることがある。つまり、変換は単なる劣化ではなく、一種の創造なのだ。原著というテキストに、要約者という読者が介入することで、新しい意味が生成される。そしてその新しい意味は、原著を豊かにすることもあれば、原著を歪めることもある。問題は変換そのものではなく、私たちがその変換を意識しているかどうかだ。変換を透明なものとして扱えば、それは欺瞞になる。でも変換を変換として認識し、その特性を理解した上で活用すれば、それは強力な思考のツールになる。現代という時代の加速装置そして現代という時代が、この問題を加速させている。インスタント化という麻薬スマホを開けば、10分で読める要約が溢れている。YouTubeには、本の内容を解説する動画が無数にある。ChatGPTに聞けば、数秒で本の要約を生成してくれる。便利だ。効率的だ。時間を節約できる。しかし私たちは、その便利さの代償を理解しているだろうか。私たちの脳は、インスタントな刺激に適応してしまっている。10分で読める要約、数秒で生成されるAIの解説、流し読みで済む箇条書き——これらに慣れた脳は、長い文章を追うこと、モヤモヤを抱えること、結論が出ないまま考え続けることに、耐えられなくなっている。スマホを見すぎて長い文章が頭に入らないエンジニアは多い。メンターしている若者も「技術書を読むのがしんどい」と言っていた。しかし一週間デジタルデトックスをしたところ、普通に読めるようになった。これは脳が「即時反応モード」から「深く考えるモード」に戻ったからだ。本を読むことは、時間がかかる。最初は分からない。モヤモヤする。何度も読み返す。考える。また読む。この不快で面倒なプロセスを経て、ようやく理解が生まれる。しかしインスタントな要約は、このプロセスをスキップさせる。分からないまま待つ必要がなく、モヤモヤを抱える必要もなく、すぐに「分かった」という感覚が得られる。この即座の満足は、甘い。甘すぎる。そして一度この甘さを知ってしまうと、本を読むという苦行には戻れなくなる。AI要約という危機AIの発展により、要約はさらに加速する。数秒で本を要約し、重要なポイントを箇条書きにし、分かりやすく説明してくれる。思考とは、情報を「受け取る」ことではなく、情報と「格闘する」ことだ。著者の主張に疑問を持ち、自分の経験と照らし合わせ、別の解釈の可能性を探る——この格闘が、思考を育てる。しかしAI要約やファスト教養は、この格闘を省略する。すぐに「分かった」という感覚を提供し、考える時間を奪う。私たちは、知識は増えているが、思考は深まらない——そんな状態に陥る。孤独の喪失という静かな危機もう一つ、見落とされがちな喪失がある。それは、本と一対一で向き合う時間だ。スマホがなかった時代、本を読むとは孤独な行為だった。自分と本だけ。他の誰も介在しない。理解できなくても、退屈でも、そこに居続けるしかなかった。しかし今は違う。少し難しい箇所に来れば、すぐにスマホに手が伸びる。「この部分、要約ないかな」と検索する。あるいは「ちょっと休憩」と言って、SNSを開く。私たちは、孤独に耐えられなくなっている。モヤモヤを抱えたまま、一人で考え続けることができなくなっている。でも本を読むという行為の本質は、この孤独にある。自分の頭で考え、自分の言葉で理解しようとする。誰も助けてくれない、その孤立した状態で、著者の思想と格闘する。この孤独な格闘を経てこそ、本当の意味での理解が生まれる。でも要約は、この孤独を奪う。常に誰かが横にいて、「正解はこれだよ」と教えてくれる。その優しさが、私たちから考える力を奪っていく。本を読むということの本質では、本を読むとは、本当は何をすることなのか。それは、自分を変えることだ。長い時間をかけて、ゆっくりと、確実に。理解とは変容である本を読んで「理解した」というとき、私たちは何を指しているのか。情報を獲得したこと？　結論を知ったこと？違う。理解とは、自分の思考の枠組みが変わることだ。本を読む前と読んだ後で、同じ現象を見ても、違うものが見えるようになる。同じ問題に直面しても、違う解決策が浮かぶようになる。同じ言葉を聞いても、違う意味が響くようになる。これが理解だ。情報の追加ではなく、認識の変容。そしてこの変容は、時間をかけて、ゆっくりと起きる。著者の思考を辿る。分からない箇所で立ち止まる。自分の経験と照らし合わせる。疑問を持つ。また読む。少しずつ、著者の視点が自分の中に入ってくる。そして気づけば、自分の見ている世界が、少し変わっている。この変容は、要約では起きない。なぜなら要約には、この「時間」が含まれていないからだ。結論だけを知っても、それは自分の外側にある情報のままだ。内側に入ってこない。格闘としての読書本を読むとは、著者と格闘することだ。著者の主張を理解しようとする。でも納得できない部分がある。「本当にそうだろうか」と疑問を持つ。自分の経験では違うと感じる。でも著者はこう言っている。なぜだろう。何が違うのか。この格闘の過程で、私たちは考える。自分の前提を疑い、著者の前提を探り、両者の違いを見つけようとする。そして時には、自分が間違っていたことに気づく。あるいは、著者の限界を見抜く。どちらにせよ、この格闘を経て、私たちの思考は深まる。でも要約は、この格闘を省略する。著者の主張は、すでに要約者によって消化されている。疑問を持つ余地もなく、「重要なポイントはこれです」と提示される。私たちは、受け取るだけだ。格闘がなければ、成長もない。反復という学び本は、一度読んで終わりではない。本当に価値のある本は、何度も読み返す価値がある。なぜか。同じ本でも、読むたびに違うものが見えるからだ。一年前に読んだとき、心に響いた章がある。でも今読み返すと、別の章が響く。当時は流し読みした箇所が、今は重要に思える。著者の何気ない一言が、今の自分の状況と重なって、深い意味を持って迫ってくる。これは、私たちが変わったからだ。経験を積み、視点が変わり、問題意識が変わった。同じ本を読んでも、違う自分が読んでいる。だから、違うものが見える。この反復的な読書によって、本は私たちの中で育っていく。最初は30%の理解だったものが、二度目で50%になり、三度目で70%になる。そして何度目かの読書で、「ああ、著者はこのことを言いたかったのか」と、ようやく本当の理解に到達する。でも要約は、この反復を許さない。一度読めば終わりだ。すべてが書かれている。何度読んでも、同じことしか書いていない。要約は、本の成長を止める。そして私たちの成長も、止める。余白という豊かさ本には、余白がある。著者が明示的に書いていないこと、行間に隠れた意味、読者に委ねられた解釈の余地——これらの余白が、本を豊かにする。余白があるから、私たちは考える。「著者はここで何を言おうとしているのか」「この比喩は何を意味するのか」「なぜこの順序で書いたのか」。そして余白があるから、読者ごとに違う解釈が生まれる。同じ本を読んでも、ある人はビジネスのヒントを得て、ある人は人生の指針を見出し、ある人は哲学的な洞察を得る。この多様性こそが、本の価値だ。一つの正解があるのではなく、無数の読み方が可能である——その豊かさが、本を読む喜びを生む。でも要約は、この余白を埋める。すべてを明示し、すべてを説明し、一つの解釈に固定する。「この本の意味はこれです」と。余白が消えたとき、本は死ぬ。そして読む喜びも、死ぬ。要約の正しい役割要約は、門だ。家ではない。本を読むかどうか判断するために、要約を読む。これは合理的だ。すべての本を精読する時間は、誰にもない。要約を読んで、「この本は自分に必要そうだ」「この本は今の自分には合わないかもしれない」と判断する。この使い方なら、要約は有用なツールだ。あるいは、すでに読んだ本の要約を読む。記憶を呼び覚ますトリガーとして。「ああ、そうだった」と思い出すために。これも正しい使い方だ。問題は、要約を読んで「本を読んだ」と思うことだ。門をくぐって「家に入った」と思うことだ。要約は入口であって、目的地ではない。複数の要約を読むという戦略一つの本について、複数の要約を読んでみる。すると、面白いことが見えてくる。要約ごとに、強調されている部分が違う。ある要約が重要だと言っている章を、別の要約は触れてもいない。ある要約の解釈と、別の要約の解釈が、矛盾している。この違いこそが、要約の本質を暴く。要約は客観的な事実ではなく、誰かの主観的な解釈だということが、複数の要約を比較することで見えてくる。そして同時に、本の多面性も見えてくる。一つの本が、いかに豊かで、いかに多様な読み方を許容しているか——それを複数の要約から、間接的に感じ取ることができる。ただし、この戦略も、本を読む代わりにはならない。あくまで、本を読む前の準備、あるいは読んだ後の確認として機能する。要約者のバックグラウンドを知るという習慣「誰が要約しているのか」に注目する習慣を持つといい。その人の専門性は何か。どんな立場で、どんな問題意識を持っているか。どんなバイアスを持っている可能性があるか。これを意識するだけで、要約の読み方が変わる。「ああ、この人はマーケティングの専門家だから、この部分を強調しているのか」「この人はエンジニアだから、技術的な側面に注目しているのか」。要約者のフィルターが見えてくる。そのフィルターを通して、何が強調され、何が省略されているのかが、推測できるようになる。そして何より、「では自分が読んだら、どこに注目するだろうか」と考えることだ。要約者と自分の違いを意識することで、自分のフィルターも見えてくる。自分で要約してみるという修行最も効果的な学びは、自分で要約を書いてみることだ。本を読んで、自分なりの要約を書く。すると、いかに難しいかが分かる。何を残して何を捨てるか、その判断の難しさ。著者の言葉を自分の言葉に置き換える際の、意味のズレ。思考のプロセスを、結論だけに圧縮することの暴力性。この体験を経ると、要約の限界が肌で分かる。そして要約を読むときの姿勢が、変わる。「これは要約者の解釈である」「著者の本当の意図は、もっと複雑かもしれない」「失われた部分があるはずだ」——そう意識しながら読むようになる。自分で要約を書くことは、要約に対する批判的読解力を育てる。読書リテラシーという現代の必須能力情報が溢れる時代だからこそ、必要なのは情報の「形式」を理解するメタ認知だ。速読という幻想を捨てる「速く読む」ことを目標にするのは、間違っている。大切なのは、速さではなく、深さだ。一冊の本を一時間で読むことより、一冊の本と一ヶ月向き合うことの方が、はるかに価値がある。もちろん、すべての本をそう読む必要はない。流し読みでいい本もあるし、要約で十分な本もある。でも少なくとも、年に数冊は、時間をかけて、深く読む本があっていい。その数冊が、あなたを変える。要約を百冊読むより、原典を三冊、じっくり読む方が、思考は深まる。速読を目指すのではなく、深読を目指す。これが、現代の読書リテラシーだ。不完全な理解を受け入れる勇気本を読んでも、すべては理解できない。これは当たり前のことだ。著者が何年もかけて考えてきたことを、数時間や数日ですべて理解できるはずがない。分からない部分があって当然だし、誤読することもある。しかし私たちは、この不完全さを受け入れられない。すぐに「分かった」という感覚を求めて、要約に逃げる。肝心なのは、不完全な理解を抱えたまま、読み続けることだ。分からない部分を、分からないまま保留しておく。「いつか分かるかもしれない」と思いながら、先に進む。この「分からなさ」を抱える力が、深い理解への鍵だ。すぐに「分かった」と結論づけず、モヤモヤを抱え続ける。そして時間をかけて、徐々に理解が深まっていく。要約は、この不完全さを許さない。すべてを明快に説明し、すべてを分かりやすくする。でもその分かりやすさは、理解の深さを犠牲にしている。不完全さを受け入れる勇気を持つこと。これが、本を読むということの本質だ。変容には時間がかかる最後に、最も重要なことを言いたい。本を読むことは、自分を変えることだ。そして変容には、時間がかかる。本を読んで即座に変わる、ということは、ほとんど起きない。自己啓発書を読んで「明日から変わろう」と思っても、明日になれば何も変わっていない。でもそれは、本が悪いのではなく、私たちの期待が間違っているのだ。本による変容は、もっとゆっくりと起きる。読んだ内容は、すぐには自分のものにならない。でも心のどこかに引っかかる。数週間後にふと思い出し、数ヶ月後に似た状況で無意識に浮かんでくる。そして気づけば、半年前の自分とは少し違う判断をしている。この反芻の過程で、本の内容は私たちの中に染み込んでいく。最初は外側にあった考え方が、徐々に内側に入ってくる。要約は、この反芻を許さない。分かりやすく整理されすぎていて、心に引っかからないからだ。百冊の本という選択では、どんな本を読むべきなのか。すべての本を深く読む時間は、誰にもない。だからこそ、選択が必要になる。ある人は言った。「私の人生を変えた一冊がある」と。その本を、彼は何度も読み返している。二十代で初めて読み、三十代で読み返し、四十代でまた読む。そして読むたびに、違うものが見える。これが、本との本当の付き合い方だ。一度読んで終わりではなく、人生を通じて対話し続ける。そしてこの長い対話を通じて、本は私たちの一部になる。著者の思想が、自分の思想と混ざり合い、区別がつかなくなる。「これは本で読んだ考えか、自分で考えたことか」分からなくなる。でもそれでいい。それこそが、本を読むことの到達点だ。ただし、一冊の本をそこまで深く読むのは難しい。だから私は思う。本は、百冊あればいい。これは、大量の本の中から自分にとっての正典となる百冊を、自分の力で選ぶということだ。世間で話題の本、ベストセラー、有名人が推薦する本——それらを漫然と読むのではなく、自分にとって本当に大切な百冊を見極める。本棚に深みがあり見栄えの良い本を並べておけば、すぐに読めなくても次第に自分が本に似合う人間になれる。これは不思議な現象だが、本当だ。手元に置いた本は、読まなくても、その存在だけで私たちに影響を与える。「いつか読もう」と思いながら本棚にある本は、私たちに問いかけ続ける。「お前はまだ、私を読む準備ができていないのか」と。読む本を選ぶときには、二つの軸が必要だ。一つは、自分がはまっている関心事を深堀りするように選ぶ。自分の興味、自分の問題意識、自分が今向き合っている課題——それらに関連する本を追いかける。これは内側からの選択だ。もう一つは、定評のある必読リストに沿って選び、外からの影響で自分を変えること。古典と呼ばれる本、専門家が推薦する本、時代を超えて読み継がれている本——自分の興味の外側にある本を、意識的に選ぶ。これは外側からの選択だ。この二つのバランスが、百冊を豊かにする。自分の関心だけで選べば視野が狭くなり、他人の推薦だけで選べば自分を見失う。両方を組み合わせることで、百冊は自分を映す鏡であると同時に、自分を超える窓になる。おわりに書評や要約は、可逆圧縮ではなく非可逆変換だ。それは欠陥ではなく、本質だ。変換を透明なものとして扱えば欺瞞になる。変換として認識し、活用すれば強力なツールになる。要約を入り口として本を探索し、気になったものは原典に当たる。自分にとっての百冊を見極め、その百冊は時間をかけて深く読み、人生を通じて対話し続ける。これは効率性の問題ではない。どう思考するか、どう生きるかという、知的態度の問題だ。溢れる情報の海で溺れないために必要なのは、泳ぐ速度ではない。情報の形式を見抜く目と、それを使いこなす知恵だ。そして何より、自分で考える時間を守ること。誰かの変換を受け取るだけでなく、自分自身が変換者になること。本と格闘し、自分の言葉で語り直し、その過程で少しずつ変わっていくこと。私は今日も、まだ読み終えていない本を開く。昨日とは少し違う自分が、違うページを読んでいる。参考書籍百冊で耕す〈自由に、なる〉ための読書術作者:近藤 康太郎ＣＥメディアハウスAmazon庭の話作者:宇野 常寛講談社Amazon書評の仕事 (ワニブックスPLUS新書)作者:印南 敦史ワニブックスAmazonニッポンの書評 (光文社新書)作者:豊崎 由美光文社Amazonビブリオバトル　本を知り人を知る書評ゲーム作者:谷口忠大文藝春秋Amazon世界は知財でできている (講談社現代新書)作者:稲穂健市講談社Amazon読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazon勉強の哲学　来たるべきバカのために　増補版 (文春文庫)作者:千葉 雅也文藝春秋Amazonセンスの哲学作者:千葉 雅也文藝春秋Amazon武器になる哲学 人生を生き抜くための哲学・思想のキーコンセプト50 (角川文庫)作者:山口 周KADOKAWAAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazonファスト教養　10分で答えが欲しい人たち (集英社新書)作者:レジー集英社Amazon映画を早送りで観る人たち～ファスト映画・ネタバレ――コンテンツ消費の現在形～ (光文社新書)作者:稲田 豊史光文社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The “No-Headache” Guide to Provisioning GPUs with Brev]]></title>
            <link>https://daisuke1024akagawa.medium.com/the-no-headache-guide-to-provisioning-gpus-with-brev-ac133834f7f4?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/the-no-headache-guide-to-provisioning-gpus-with-brev-ac133834f7f4?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Mon, 22 Dec 2025 10:32:04 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[なぜ「何でも作れる時代」に私は作れないのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</guid>
            <pubDate>Mon, 22 Dec 2025 04:55:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめに年末、2025年を振り返る。フォロワーは7倍になった。副業も順調。書籍の執筆や翻訳にも関わった。登壇の依頼も増えた。どこからどう見ても、良い年だったはずだ。なのに、胸の奥に澱のようなものが溜まっている。コードは書いた。山ほど書いた。でもそれは、誰かに頼まれたコードだ。お金になるコード。評価されるコード。「これを作ってください」と言われて、「はい」と答えて、作ったコード。自分のためのOSSも、作った。公開もした。そこそこ使われもした。でも、そこそこ止まりだ。「これが俺の代表作です」と言えるものが、ない。スターはついた。ダウンロードもされた。いくつかは今でも自分で使っている。完走した。自分なりに頑張った。でも、「代表作」と呼べるインパクトには届かなかった。厄介なことに、nwiizoというアカウントは大きくなってしまった。フォロワーが増えた分、「代表作」のハードルも上がっている。昔なら「動くものを公開した」で満足できた。今は違う。期待値が上がった分、自分で自分の首を絞めている。でも、諦めたくない。代表作を持つソフトウェアエンジニアに憧れて、この道に入った。あの人みたいになりたい、と思った先輩たちがいる。彼らのようにはなれていない。でも、まだ諦めたくない。新しいプロジェクトを始めようとするたび、手が止まる。「既存のツールで十分じゃないか」「誰が使うんだ、これ」。もっともらしい問いを自分に投げかけて、そのまま手を下ろす。完走したプロジェクトはある。でも、次の一歩が踏み出せない。検証のふりをした、逃避だ。「作らなくていい理由」を探して、見つけて、安心している。AIは「どう作るか」を教えてくれる。でも「何を作るか」は教えてくれない。技術力はもうボトルネックじゃない。足りないのは、決断だ。覚悟だ。「これを作る」と宣言して、不確実性の中に飛び込む蛮勇だ。私は「隙間家具屋」を自称してきた。大きな家具は作らない。洗濯機と壁の間の収納。冷蔵庫の上のラック。誰も気にしないけれど、あると少し楽になる小さなもの。それを作るのが好きだった。はずだった。2025年、隙間を見つける目は曇っていなかった。手も動いた。完走もした。でも、「これだ」という手応えが残らなかった。副業は収入になる。登壇は評価される。ブログはフォロワーが増える。全部、目に見えるリターンがある。OSSは違う。作っても誰にも使われないかもしれない。時間を注いでも、何も返ってこないかもしれない。その「かもしれない」に怯えて、私は確実なほうへ流れやすかった。OSSは作った。完走もした。でも、賭け金を上げられなかった。時間を注ぎ込むより、確実なリターンがある副業や登壇に逃げた。結果、そこそこ止まり。「これだ」と言えるものは掴めなかった。問題は、才能がないことだけじゃない。問題は、狂えなかったことだ。どこにも振り切れなかった。副業も、登壇も、OSSも、全部やりたかった。全部にいい顔をして、どれにも本気を出せなかった。半端な賭け金には、半端なリターンしか返ってこない。当たり前のことだ。このブログでは、「狂って量をやって、そこから引き算する」ための思考法を書く。 speakerdeck.com結論を先に言う。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。ポジティブケイパビリティとネガティブケイパビリティ「ネガティブ・ケイパビリティ」という概念がある。不確実さ、不思議さ、疑いの中に、結論を急がずに留まる能力のことだ。これに対して、「ポジティブ・ケイパビリティ」というのもある。問題を分析し、解決策を導き、実行する能力だ。ゴールが明確なときに発揮される力。私はおそらくだがこれが得意だ。生成AIは、ポジティブケイパビリティを劇的に強化した。「このAPIを叩いて、結果をパースして、DBに保存するコードを書いて」と指示すれば、動くコードが出てくる。「このエラーメッセージの原因を調べて」と頼めば、調査結果が返ってくる。ゴールが明確なタスクは、AIとの協働で驚くほど速く片付く。私の2025年は、まさにこれだった。仕事のコードは書けた。クライアントから「これを作ってほしい」と言われれば、作れた。締め切りがあり、要件があり、ゴールが明確なタスクは、以前より速く終わるようになった。しかし、ネガティブケイパビリティは強化されなかった。むしろ、弱体化した気もする。 以前なら、分からないまま3日間コードを書き続けることができた。今は、30分詰まるとAIに聞いてしまう。「分からない」という状態に耐える筋力が、確実に落ちている。OSS開発には、ネガティブケイパビリティが必要だ。「何を作るか」は誰も教えてくれない。「これが正解」という保証はない。作っている途中で「これは違うかも」と思うことがある。それでも手を動かし続ける。完成するかどうか分からない。使われるかどうか分からない。その不確実さの中に留まり続ける力。生成AIに「何を作るべきか」と聞いても、答えは出ない。AIは優秀なアシスタントだが、ゴールを設定するのは人間の仕事だ。ゴールが明確な仕事が速く片付くようになった結果、私の中で奇妙なことが起きた。「答えがすぐに出る」ことに慣れてしまった。 仕事では、AIに聞けば数分で方向性が見える。それに慣れた脳は、「答えが出ない状態」に耐えられなくなっている。では、どうすれば不確実さに耐えられるのか。いくつかの仮説がある。ゴールを小さくする（「Kubernetesのログ管理を改善したい」ではなく「Podの再起動ログをSlackに送る」）。「完成」の定義を下げる（動けば完成、READMEは3行でいい）。公開してしまう（不確実性の一部が確定に変わる）。AIに頼らない時間を作る（自分で考える筋力を維持する）。「狂う」とは何か「狂う」という言葉を使うと、何か特別な才能や突飛な発想が必要に思える。しかし、私が考える「狂う」はもっと単純だ。狂うとは、常識的な量を超えて、時間と労力を注ぐことだ。天才的なアイデアは必要ない。奇抜な発想も必要ない。ただ、普通の人が「そこまでやらなくていいだろう」と思う量を投入する。これが狂うということだ。しかし、ここまで書いて気づいた。「量をやれ」というアドバイスは、ゴールが見えている人へのアドバイスだ。これはポジティブケイパビリティの話だ。「OSSを20個作れ」と言われても、「何を作るか」が決まっていなければ、手は動かない。私の問題は、量が足りないことではなく、ゴールが見えない状態に耐えられないことだった。ネガティブケイパビリティの欠如だ。だから、「狂う」にはもう1つの意味がある。答えが出ない状態に留まり続けることだ。「これが正解かどうか分からない」「誰にも使われないかもしれない」「もっといい方法があるかもしれない」。その不確実さの中で、それでも作り続ける。確信がないまま、手を動かし続ける。普通の人は、不確実さに耐えられない。「これで合ってる？」と誰かに確認したくなる。確認できないと、手が止まる。狂っている人は、確認しないまま走り続ける。生成AIは「確認」を容易にした。コードを書いたら、AIにレビューしてもらえる。設計を考えたら、AIに壁打ちしてもらえる。これは素晴らしいことだ。でも同時に、「確認なしで走り続ける」筋力が衰えた。量を積むことと、不確実性に耐えること。この2つは、実は表裏一体だ。量を積めば、その中から「これだ」というものが見えてくる。不確実性に耐えていれば、やがてゴールが見えてくる。どちらも「狂う」ことでしか到達できない。狂気の最も簡単な表現方法は、物量か時間を使うことだ。1日1時間を5年続ける。同じテーマのブログを100本書く。OSSを年間20個作る。なぜ20個か。月に1〜2個のペースだ。1つのツールを2週間で完成させる。完璧じゃなくていい。動けばいい。このペースなら、仕事をしながらでも無理がない。かつ、「そこそこ止まり」の自分とは明らかに違う場所に立てる。特別な才能がなくても、量を積めば、誰も追いつけない場所にたどり着く。ここで「衝動」という言葉を使いたい。不便を見つけたとき、「あ、これ自動化できそう」と思う。その瞬間、手が動き出す。誰に頼まれたわけでもない。でも、気づいたらコードを書いている。これが私にとっての衝動だ。「将来の夢」とは違う。他者の評価を求めている「有名なOSSメンテナになりたい」は、衝動ではない。衝動は、評価とは無関係に動く。10年経っても変わらない。「不便を見つけたら、すぐ直したくなる」。隙間家具を作るのは、この衝動の表れだ。問題は、この衝動を他者の目で覆い隠してしまうことだ。「作っても誰にも使われないかも」。そう考えた瞬間、衝動が埋もれる。2025年の私は、まさにこれだった。衝動は「発見」するものではなく「掘り出す」ものだ。他者の目や評価への恐れで覆い隠されている。それを掘り出すには、まず量をやる必要がある。考える前に手を動かす。作る前に悩まない。作った後に、何が自分を動かしているのかが見えてくる。まず量をやる私たちは、最初から量が足りない。2025年、私のOSSがそこそこ止まりだった理由は何か。作った。完走もした。でも、「代表作」と呼べるインパクトには届かなかった。振り返ると、1つに賭け切れていなかった。あれもこれもやろうとして、どれにも全力を注げなかった。「ゴールが見えないから突き抜けられない」と思っていた。でも、それは逆だ。一つに賭け切らないから、ゴールが見えない。作りはした。でも、広く浅く。一つに集中しなかったから、どれも「これだ」に辿り着けなかった。私の経験を話す。以前、「Kubernetesのログをなんとかしたい」という漠然とした不満があった。何を作ればいいか分からなかった。とりあえず、Podの再起動を検知するスクリプトを書いた。動いた。使ってみた。すると、「再起動の直前のログが見たい」という次の不満が見えた。それを解決するコードを足した。使ってみた。今度は「Slackに通知したい」という欲求が出てきた。最初に「Podの再起動時に直前のログをSlackに送るツール」というゴールが見えていたわけではない。作っているうちに、ゴールが形成されていった。ゴールは、作る前に見つかるものではない。作る過程で見えてくるものだ。量をやることで、初めて「自分が本当に作りたいもの」が浮かび上がる。完璧な1つより、動く20個。磨き上げた1つより、荒削りな50個。これが私の2026年の方針だ。物量で狂う。 OSSを年間20個作る。完璧じゃなくていい。動けばいい。20個作れば、1個くらいは当たる。当たらなくても、20個分の経験が残る。時間で狂う。 毎日30分、何かを作る時間を確保する。1年で小さなツールを20個作れば、5年で100個になる。100個のOSSを持っているエンジニアは、採用市場で見たことがない。試行で狂う。 1つのアイデアに固執しない。「これは違うな」と思ったら、すぐ次に行く。打席に立つ回数を増やす。三振しても気にしない。次の打席がある。私は30代で独身だ。守るべきものが少ない。狂えるうちに狂っておく。量をやることで、初めて見えてくるものがある。どのアイデアに自分の熱量が続くのか。どのツールが使われるのか。作る前に「どれが正解か」を考えても分からない。作った後に、結果が教えてくれる。量だけでは足りないからセンスを磨くここで反論が聞こえる。「量をやるだけなら、生成AIでもできるのでは？」正しい指摘だ。そして、もう1つ重要な変化がある。ソフトウェアは供給過多の時代に入った。あらゆる領域で「フロンティアの閉鎖」が起きている。かつてソフトウェアには未開拓の荒野があった。問題はそこら中に転がっていて、誰かが手を挙げて解決すれば、それだけで価値になった。参入障壁が高かったから、作れる人が少なかった。だから「作った」という事実そのものに希少性があった。今は違う。生成AIが参入障壁を破壊した。誰でも作れる。結果、供給が需要を超えた。ユーザーの時間と注意力が、ツールよりも希少になった。ツールが人を選ぶ時代から、人がツールを選ぶ時代へ。選ばれないツールは、存在しないのと同じだ。これは「量で勝てた時代の終焉」を意味する。かつての戦略は「とにかく作れ、出せ、数で勝負しろ」だった。今、その戦略は逆効果になりうる。大量の凡庸なツールを公開すると、ノイズを増やすだけで、作り手の信用を毀損する。つまり、量を公開しすぎることが、むしろマイナスになる時代が来ている。では、量をやる意味はどこにあるのか。ここで「センス」について考えたい。センスとは何か。私は、意味よりも先に、形式やリズムを感じ取る能力だと考えている。普通、私たちは物事を「これは何を意味するのか」で理解しようとする。コードを見て「このツールは何をするのか」と問う。ブログを読んで「著者は何を主張しているのか」と問う。意味を求める。でも、センスの本質はそこにない。センスとは、意味の手前にある「リズム」を感じ取ることだ。リズムとは、反復と差異の織り成すパターンのことだ。赤ちゃんが「いないいないばあ」で喜ぶのは、不在から存在への移行、つまり0→1のビートを感じているからだ。予測があり、裏切りがあり、また予測に戻る。この往復運動が快感を生む。あらゆる表現にリズムがある。音楽のビート。文章の緩急。コードの構造。APIの応答パターン。人間は意味を理解する前に、このリズムを身体で感じている。優れた表現は、セオリーを押さえた上で、あえてそこからはみ出す。 反復の中に絶妙な差異を混ぜている。予測可能でありながら、どこか予測を裏切る。この「ズレ」がセンスだ。ここで重要な逆説がある。完璧を目指すほど、センスは死ぬ。お手本を完璧に再現しようとすると、二つの問題が起きる。一つは、お手本との差異が「欠点」に見えてしまうこと。もう一つは、自分固有のリズムが消えてしまうこと。結果として、劣化コピーが生まれる。逆に、お手本から離れることを肯定すると、「ヘタウマ」が生まれる。完璧ではないが、作り手固有のリズムがある。技術的には未熟でも、個性がある。その個性が、使う人に刺さる。なぜ個性が刺さるのか。人間は、パターンを認識する生き物だからだ。完璧にパターン化されたものは、最初は心地よい。でも、すぐ飽きる。予測通りすぎて、刺激がない。一方、パターンから少しズレたものは、脳に引っかかる。「なぜここでこうなる？」という小さな疑問が生まれ、それが記憶に残る。AIは反復とパターンを生成できる。しかし、その人固有の「どうしようもなさ」は生成できない。「どうしようもなさ」とは何か。個人の癖、偏り、こだわり。論理では説明できない選好。なぜか惹かれるもの。なぜか避けたくなるもの。この非合理な偏りが、人間の表現に陰影を与える。私がツールを作るとき、そこには私の「どうしようもなさ」が刻まれる。なぜこの設計を選んだのか、論理的に説明できない部分がある。それは私の経験、私の好み、私の盲点が複合的に作用した結果だ。AIが同じ仕様で作っても、同じものにはならない。センスとは、リズムを感じ取る能力であり、同時に、自分固有のリズムを表現する能力でもある。では、どうやってセンスを磨くのか。答えは逆説的だ。量をやることだ。多様なものに触れると、最初は不安を感じる。「分からない」「理解できない」。この不安は、パターンを認識できていないサインだ。量を重ねると、パターンが見えてくる。不安が面白さに変換される。これがセンスが磨かれる過程だ。ここで矛盾が生じる。センスを磨くには量が必要だ。しかし、量を公開しすぎるとマイナスになる。答えは、「作る量」と「公開する量」を分けることだ。20個作る。でも、公開するのは、センスが良いと判断した5個だけ。残りの15個は、センスを磨くための練習だ。公開しない。でも、作ったことに意味がある。量をやることには、二重の意味がある。1つ目は、センスを磨くこと。多様なものを作ることで、「何が良くて何が良くないか」を判断する回路ができる。リズムを感じ取る力が育つ。2つ目は、自分の「どうしようもなさ」を発見すること。量をやると、自分のパターンが見えてくる。どういう問題に惹かれるか。どういう設計を好むか。それは私の固有性であり、AIには真似できない。だから、量をやる意味は「AIより速く作る」ことではない。量を通じて、リズムを感じ取る力と、自分固有のリズムを発見することだ。そして、センスが磨かれた後は、公開するものを厳選する。供給過多の時代に求められるのは、「たくさん作れる人」ではない。「たくさん作った上で、良いものだけを選べる人」だ。AIは「どう作るか」を効率化する。でも、「何を作るか」「どれを公開するか」「どう判断するか」は、量を経験した人間にしか分からない。そして引き算する量をやった。20個作った。では、20個全部を維持できるか。できない。私には経験がある。かつて、複数のプロジェクトを同時に走らせていた。イシューは溜まり、プルリクエストは放置され、READMEは古くなった。全部やろうとして、全部が死んだ。量をやることと、量を維持することは違う。 量をやるのは一時的な狂気だ。量を維持するのは持続的な負担だ。人間のリソースは有限だから、量をやった後には、引き算という別の問題が待っている。私たちは、量が満ちた後に引かなすぎる。 量をやった後は、容赦なく削る。使われないツールは捨てる。熱量が続かないプロジェクトはアーカイブする。失うのは「いつかやるかもしれない」という幻想だ。守れるのは「今、本当にやりたいこと」への集中だ。削らずに広げ続けた結果が2025年の私だ。副業も、登壇も、ブログも、OSSも、全部やった。全部それなりに成果は出た。でも、どれも「これが俺の本業だ」と言い切れない。器用貧乏の完成形だ。ここで「引き算」の思考法が必要になる。シーナ・アイエンガー氏の有名な実験では、24種類のジャムより、6種類に絞った方が購入率は高かった。選択肢が多すぎると、人は「選ぶ」という行為自体ができなくなる。選択の科学 コロンビア大学ビジネススクール特別講義 (文春文庫 S 13-1)作者:シーナ アイエンガー文藝春秋Amazonアイエンガー氏は『THINK BIGGER』で、選択肢が多すぎて選べないときの思考法を体系化した。その本質は「引き算」だ。課題を選ぶ、分解する、誰のためかを決める、材料を集める、何を作らないかを決める、他者の目で検証する。すべて「絞る」プロセスだ。THINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazon狂って量をやるフェーズでは、複数のアイデアが同時に走っている方が自然だ。順番通りに1つずつ片付けようとすると、むしろ手が止まる。どれかが熱を帯びてきたら、そこに集中する。足し算ではない。引き算だ。優れた開発者のOSSが失敗するのは、怠けているからではない。正しいことをしすぎるからだ。 ユーザーの声を聞く。機能を追加する。対応範囲を広げる。全部、正しいことだ。でも、正しいことを積み重ねた結果、複雑になり、重くなり、新しく登場したシンプルなツールに足元をすくわれる。私たちは「正しさ」に殺される。ユーザーの声を聞くのは正しい。だから聞く。機能を追加するのは正しい。だから追加する。テストを書くのは正しい。だから書く。ドキュメントを整えるのは正しい。だから整える。気づいたら、最初に解決したかった問題が見えなくなっている。正しいことの山に埋もれて、本質が窒息している。「正しさ」は麻薬だ。やればやるほど気持ちいい。やればやるほど、完成から遠ざかる。隙間家具を作るとは、引き算をすることだ。機能を削る。対象を絞る。スコープを小さくする。「これだけは解決する」を決め、残りは捨てる。生成AIを使うとき、この引き算が難しくなる。AIは指示すれば無限に足し算を提案してくる。「この機能も追加しましょうか」「こういうオプションもあると便利です」「エラーハンドリングをもっと丁寧にしましょう」。全部、正しい提案だ。でも、全部受け入れると、隙間家具は大きな家具になる。AIは足し算が得意だ。引き算は人間がやる。私がAIに「削らせる」ときに使う問いかけがある。「この機能がなくても、最小限の価値は提供できるか？」。答えがYESなら、その機能は削る候補だ。AIの提案を聞いたら、「本当に必要か？」と問い直す。これが、AIとの協働における引き算の基本姿勢だ。「何を作るか」を決める課題を選ぶ引き算の最初は、「何を作るか」を1つに決めることだ。私が2025年に「代表作」に届かなかった理由の1つは、課題が大きすぎたことだ。「Kubernetesのログ管理を改善したい」と思った。でも、それは「どのログ」「どう改善」「誰のため」が決まっていない。漠然としすぎていた。結果、インパクトのあるものが作れなかった。「作りたいものはあるけど、何から手をつければ...」という状態は、課題が大きすぎるか小さすぎるかのどちらかだ。大きすぎると作りきれない。小さすぎると作る意味がない。「1つのツールで完結する」サイズを探す。課題が大きすぎる例:「Kubernetesの代替」「CI/CDパイプライン全体の改善」「インフラ自動化ツール」課題が小さすぎる例:「kubectl getのラッパー」「特定のエラーメッセージを整形するスクリプト」ちょうどいい例:「Podが再起動したときに直前のログを保存するツール」「複数リポジトリのCIステータスを一覧表示するCLI」「Terraformの差分をSlackに見やすく投稿するBot」ちょうどいいサイズの見つけ方は、「自分が1〜3日かけて解決したこと」を思い出すことだ。それは、深みがある。かつ、1つのツールで完結する気がする。隙間を見つける大きなツールが解決していない小さな問題。それが「隙間」だ。Kubernetes（コンテナオーケストレーション）は素晴らしい。しかし、Kubernetesが解決していない問題は山ほどある。Podが再起動したとき、前後のログを自動でSlack に送りたい。これはKubernetesの仕事ではない。Terraform（インフラ構成管理）も素晴らしい。ただ、差分をSlackに見やすく投稿したい。これはTerraformの仕事ではない。GitHubも同様だ。複数リポジトリのCIステータスを一覧で見たい。これはGitHubの仕事ではない。隙間を見つけるヒントは5つある。自分の不便。「こういうツールが欲しいのに、ない」という体験。私が作った隙間家具の中で、最も使われたものは、自分自身の問題を解決するために作ったものだった。自分が不便を感じているとき、そこには片づけたい「用事」がある。でも、それを片づける手段がない。私のGithub リポジトリからのスクショここで疑問が浮かぶ。「自分の不便」が特殊すぎるときはどうするのか。自分だけが困っている問題を解決しても、誰も使わないのではないか。だから2026年、私はこう決めた。最初は特殊すぎて構わない。なぜなら、特殊な問題を解決するツールでも、自分が本当に使うなら完成する。「誰かが使うかも」で作ったツールは、途中で手が止まる。まず完成させることが最優先だ。公開してみれば、同じ問題を抱えている人が意外といることに気づく。特殊だと思っていた不便が、実は普遍的だったというケースは多い。仮に本当に特殊で誰も使わなくても、自分の問題は解決している。それで十分だ。繰り返しの手作業。同じコマンドを何度も打っている。同じ手順を何度も実行している。毎回「面倒だな」と思いながら、やっている。ここで立ち止まる。この問題は「自動化すべき問題」か、それとも「慣れるべき問題」か。ツール化することで、本当に人間の負荷は減るのか。自動化によって、別の複雑さを生んでいないか。判断基準は、その作業が月に何回・何分発生しているかだ。月に1回、5分で終わる作業なら、自動化ツールを作るより慣れた方が早い。週に10回、毎回10分かかる作業なら、自動化する価値がある。感覚で判断しない。数字で判断する。例えば、複数のGitHubリポジトリのCIステータスを確認するとき、1つずつページを開いていた。毎回、5分くらいかかる。週に5回やっていた。月に100分。年に1200分。ツールを作る価値がある。作った。5分が10秒になった。コンテキストスイッチ。ある情報を得るために、複数のツールを行き来している。Slackを見て、Grafanaを見て、ログを見て、またSlackに戻る。情報を一箇所に集めるツールを作れば、コンテキストスイッチが減る。頭の負荷が減る。判断が速くなる。暗黙知。「あの人に聞けば分かる」「Slackのどこかにある」「この手順は、前にやったことある人しか知らない」。暗黙知をツールに埋め込めば、誰でも同じことができるようになる。複雑さ。「このツールは高機能だけど、使いこなせない」「設定項目が多すぎて、何を設定すればいいか分からない」。高機能なツールが、その機能を使い切れていない人たちを置き去りにしている。彼らに、シンプルで分かりやすい選択肢を提供する。これも隙間家具の仕事だ。課題を分解する課題が決まったら、5つまでに分解する。私がよくやる失敗は、分解せずに作り始めることだ。「ログ保存ツールを作ろう」と思って、いきなりコードを書き始める。途中で「保存先どうしよう」「認証どうしよう」「エラーハンドリングどうしよう」と考え始める。そのたびに手が止まる。最初に分解しておけば、こうはならない。「〇〇を作ろう」だけでは手が動かない。サブ課題に分解して、5つまでに絞る。5つに絞るのは、正直、苦しい。あれもこれも入れたくなる。でも、ジャムの法則と同じだ。サブ課題を10個、20個と出すと、どれに注力すべきか分からなくなる。例: 「Podが再起動したときに直前のログを保存するツール」Podの再起動を検知する仕組み直前のログを取得する方法ログを保存する先（S3など）CLIのインターフェースエラーハンドリング分解した項目が、そのまま実装の順番になる。「これは本当に必要か？」と自問すると、いろいろ見えてくる。実は同じことをしている項目。なくても動く項目。別のツールに任せた方がいい項目。削ることで本質が見える。5つに分解したら、次に優先順位をつける。何を基準に「残す1つ」と「後回しにする4つ」を決めるか。私の基準は、「これがないと、ツールとして成立しない」だ。技術的な実現性でも、ユーザーの感動でも、自分の興味でもない。「ツールの存在意義に関わるか」だ。例えば、「Podの再起動を検知する仕組み」がなければ、ログ保存ツールは成立しない。これが最優先だ。「CLIのインターフェース」は後でもいい。最初はハードコードでも動く。ここまでで、「何を作るか」と「どう分解するか」が決まった。でも、まだ足りない。「誰のために作るか」が決まっていない。「誰のために作るか」を決める望みを比較する同じツールでも、誰向けに作るかで設計が変わる。自分用なら雑でいい。他人に使ってもらうなら、READMEが必要だ。コミュニティに貢献したいなら、テストも書く。私が2025年に「代表作」に届かなかったもう1つの理由は、「誰のため」が曖昧だったことだ。「これ、公開したら使ってもらえるかな」と考えた瞬間、設計が複雑になる。「あの人はこういう使い方するかも」「この環境もサポートした方がいいかも」。考えれば考えるほど、作るものが膨らむ。膨らめば膨らむほど、作れなくなる。3つの望みがある。自分が作りたいもの。ユーザーが使いたいもの。コミュニティへの貢献。全部満たそうとすると、どれも中途半端になる。だから2026年、私はこう決断する。まず自分の問題を解決するツールを作る。当たり前すぎるかもしれない。でも、これが私の経験則だ。自分が本当に困っている問題なら、熱量が出る。熱量のあるツールは、ユーザーにも伝わる。これは「プロダクト」ではなく「道具」として十分に割り切れているか。プロダクトは他者のためにある。道具は自分のためにある。隙間家具は道具だ。自分の問題を解決するために作る。他者が使ってくれたらラッキー、くらいの気持ちでいい。汎用性を上げようとして、複雑さを持ち込んでいないか。持ち込みがちだ。「S3だけじゃなくGCSにも対応しよう」「Kubernetes以外でも使えるようにしよう」。その瞬間、道具がプロダクトになろうとする。複雑さが増す。完成しなくなる。READMEは「思想」ではなく「使い方」を語っているか。思想を語りがちだ。「なぜこのツールが必要か」「どんな設計思想か」。でも、ユーザーが知りたいのは「どう使うか」だ。インストール方法、実行方法、オプション。これだけでいい。自分以外の利用者がゼロでも、このツールは成立しているか。成立している必要がある。自分の問題が解決しているなら、それで十分だ。他者が使うかどうかは、結果論だ。「まだ誰も使っていない人」を見る自分が不便を感じているとき、同じ不便を感じている人は他にもいる。片づけたい用事があるのに、それを片づける手段を持っていない人。私はこの人たちを「まだ誰も使っていない人」と呼んでいる。自分がその一人だったなら、同じ境遇の人が他にもいるだろう。隙間家具は、この人たちに届ける。ここで注意が必要だ。ツールを公開すると、ユーザーからフィードバックが来る。「この機能が欲しい」「ここが使いにくい」。これは嬉しい。でも、ここに罠がある。既存ユーザーの声を聞けば聞くほど、既存ユーザーのためのツールになる。そして、「まだ誰も使っていない人」を見落とす。既存ユーザーの声に応え続けると、隙間家具は大きな家具になろうとし始める。機能が増え、複雑になり、最初のシンプルさを失う。新規ユーザーが求めているのは、高機能ではなく「すぐ使える」「分かりやすい」だ。「声」と「用事」を区別するフィードバックを受けるとき、「声」と「用事」を区別する。私も失敗したことがある。あるCLIツールを公開したとき、「設定ファイルで動作を変えたい」というフィードバックを複数もらった。嬉しかった。使ってくれている人がいる。だから、設定ファイル機能を実装した。YAMLで書けるようにした。オプションを増やした。結果、設定項目が20個を超えた。新しいユーザーは「設定が多すぎて何を設定すればいいか分からない」と言い始めた。シンプルさが売りだったツールは、複雑なツールになっていた。「声」は、ユーザーが言語化したものだ。「この機能が欲しい」「ここが使いにくい」。「用事」は、ユーザーが本当に片づけたいことだ。なぜその機能が欲しいのか。なぜそこを使いにくいと感じるのか。この「なぜ」の先に、本当の用事がある。例えば、CLIツールに「YAML出力オプションが欲しい」というフィードバックが来たとする。声をそのまま受け取れば、--output yamlフラグを実装することになる。でも、「なぜYAMLが欲しいのか」を問うと、「他のツールにパイプしたい」「設定ファイルとして保存したい」という用事が見えてくる。用事が分かれば、YAMLだけでなくJSONでも解決できるだろう。あるいは、標準出力をそのままパイプできる設計にすれば、フォーマット変換はjqに任せられるだろう。「この機能が欲しい」と言われたら、「なぜ」を問う。その人の用事は何か。その用事を片づける方法は、言われた機能だけか。もっとシンプルな方法はないか。ツールがヒットすると、「汎用化」の要望が必ず来る。「S3だけでなくGCSにも対応して」「Kubernetes以外でも使えるようにして」。これに応えると、隙間家具は大きな家具になる。だから私は、こう決めている。READMEが複雑になるなら、その機能は入れない。機能を追加するとき、READMEがどう変わるかを見る。説明が長くなるなら、別のツールにする。READMEがシンプルなら、ツールもシンプルだ。これが私の制約であり、美学だ。ここまでで、「何を作るか」「誰のために作るか」が決まった。次は、作る前に調べる。調べて、削る箱の中と外を探すいきなり作り始めたくなる。でも、その前に下調べをする。私は以前、「これ、俺が作らなくても既存ツールで十分だな」と気づいて手を止めたことがある。それ自体は正しい判断だった。でも、その後「じゃあ俺の経験は何に使えるか」を考えなかった。既存ツールを調べて終わり。それでは何も生まれない。似たツールはあるか。どんなアプローチがあるか。先人の知恵を借りる。「箱の中」は同じ領域の情報だ。公式ドキュメント、他の人の同じテーマのツール、GitHub Issues、Stack Overflow。正確性を担保し、抜け漏れを防ぐ。「箱の外」は自分の経験だ。実際に試した結果、ハマったポイントと解決策、自分なりの工夫や改善。これがオリジナリティの源泉になる。ここで重要なのは、インプットだ。本を読む。既存のOSSのコードをちゃんと読む。何のライブラリが使われていて、どのように問題を解決しているかを理解する。これが「箱の中」を深く知ることだ。例えば、Kubernetesのログ保存ツールを作るなら、既存の類似ツールのコードを読む。どのKubernetesクライアントライブラリを使っているか。どうやってPodの再起動を検知しているか。ログの取得にはどのAPIを使っているか。保存先との接続はどう抽象化しているか。コードを読まずに作り始めると、車輪の再発明をする。既に解決されている問題を、苦労して解き直す。あるいは、先人が避けた落とし穴にハマる。インプットの具体例を挙げる。本を読む：技術書だけでなく、設計思想やアーキテクチャの本も読む。『A Philosophy of Software Design』『The Art of Unix Programming』。隙間家具を作る視点が変わる。OSSのコードを読む：GitHubで似たツールを探して、main.goやlib.rsを読む。README だけでなく、実装を見る。「なるほど、こう解決するのか」という発見がある。ライブラリの使い方を学ぶ：使おうとしているライブラリのexampleを全部読む。ドキュメントを端から端まで読む。「こんな機能もあったのか」という発見が、設計を変える。「既に同じようなツールがある」は気にしない。同じ課題を解決するツールでも、価値を出せる理由はある。環境が違う。文脈が違う。深さが違う。切り口が違う。あなたのツールにしかない価値は、あなたの環境で動いた事実、あなたがハマったポイント、あなたの言葉での説明だ。「n番煎じ」でも、あなたの経験を加えれば価値になる。「箱の外」の材料を増やすために、私が意識的にやっていることがある。「自分の仕事を観察する」だ。エンジニアリング以外のインプットも大事だが、それ以上に、自分が日常的にやっている作業を観察する。「今、何に時間を使っているか」「何に苛立っているか」「何を繰り返しているか」。この観察が、隙間を見つける材料になる。選択マップで削る材料が揃ったら、「何を作り、何を作らないか」を選ぶ。私は「全部入り」を目指しがちだ。ログ保存ツールを作るなら、S3もGCSもAzure Blobも対応したくなる。Slack通知もメール通知もつけたくなる。そうこうしているうちに、何も作れなくなる。選択マップとは、集めた選択肢を視覚的に整理し、最適な組み合わせを見つける方法だ。課題から分岐して選択肢を並べ、各選択肢のメリット・デメリットを可視化する。例: 「OOMKilled（メモリ不足による強制終了）の調査方法を紹介するツール」調査方法は複数ある。kubectl top（リソース使用状況確認）、Grafana（可視化ダッシュボード）、pprof（プロファイリングツール）、サードパーティツール。読者に最も役立つのはどれか。kubectl topは簡単ですぐ使えるが、瞬間値しか見られない。Grafanaは履歴を見られるが、セットアップが必要。pprofは詳細に分析できるが、設定が必要で学習コストは高い。選択結果：読者の多くは「まず何が起きてるか知りたい」→ kubectl top + Grafanaを中心に作る。pprofは発展編として軽く触れるか、別のツールにする。足し算の発想だと、全部の方法をサポートしようとする。焦点がぼやける。誰にも刺さらない。引き算の発想だと、「これだけは作る」を決める。残りは捨てる。刺さるツールになる。良いツールは「何を作らないか」で決まる。スコープを絞る勇気隙間家具は、特定の問題を解決する。汎用性を追求しない。「このコンテキストで、この問題を解決する」に集中する。例えば、「KubernetesのPodが再起動したとき、直前のログを自動でS3に保存するツール」。汎用的ではない。Kubernetesを使っていて、ログをS3に保存したい人だけを対象にする。でも、それでいい。特定の問題を、特定のコンテキストで、確実に解決する。これが隙間家具の価値だ。汎用性は、使われてから考えればいい。最初から汎用的に作ろうとすると、要件が膨らみ、複雑になり、いつまでも完成しない。ここまでで、何を作るか、誰のために作るか、何を作らないかが決まった。いよいよ作る。小さく作って、見せる第三の目で検証する作った。動いた。自分では完璧に見える。でも、それは危険なサインなんだ。私にも経験がある。あるCLIツールを作って、自分では「完璧だ」と思った。README も書いた。インストール方法も書いた。でも、同僚に見せたら「これ、何をするツールなの？」と聞かれた。私には当たり前すぎて、説明を省略していた。「前提知識がないと、何も分からない」。そのツールは結局、私しか使わなかった。使い方を説明する手間を惜しんだ結果だ。作った本人には見えない穴がある。「当然わかるでしょ」と省略している。専門用語を説明なしで使っている。論理の飛躍に気づかない。自分では完璧に見える。だから、他者に見せる。使ってもらう。フィードバックをもらう。隙間家具を必要としている人は、探していない。問題を抱えているが、解決策があるとは思っていない。だから、「検索してたどり着く」ことを期待できない。では、どうやって届けるか。自分の体験を語る。「私はこういう問題を抱えていた。だから、このツールを作った。」「まだ誰も使っていない人」は、同じ問題を抱えているだろう。ブログやTwitterで体験を語れば、「あ、自分もこの問題を抱えている」と思ってもらえる。READMEに機能を列挙するだけでは届かない。「なぜこのツールを作ったか」「どんな問題を解決するか」を語る。「まだ誰も使っていない人」は、自分の不便を言語化できていないことが多い。だから、状況を描写する。「毎朝、Slackを開いて、Grafanaに移動して、ログを確認して、またSlackに戻る...この作業、面倒じゃないですか？」。機能ではなく、状況を語る。「あ、それ自分だ」と思わせる。ツールの説明ではなく、問題の描写から始める。これが、言語化できていない不便に気づかせるストーリーテリングだ。入り口を簡単にするインストールが面倒だと、人は離れる。設定が複雑だと、人は離れる。最初の一歩を、できるだけ簡単にする。go install 一発でインストールできる。設定ファイルは最小限。デフォルトで動く。これが理想だ。なぜなら、新しいツールを試すとき、人は「動かすまでの時間」を無意識に測っている。5分で動かなければ、「また今度」になる。設定が多いツールは、5分では動かない。だから、試されずに終わる。パワーユーザーは細かい設定を求めるだろう。でも、パワーユーザーは「まだ誰も使っていない人」ではない。最初に届けるべきは、5分で動くシンプルさだ。新しいツールは、最初は既存のツールより「劣っている」ことが多い。機能が少ない。パフォーマンスが低い。でも、シンプルで、分かりやすくて、すぐに使える。それでいい。隙間家具は、シンプルでいい。1つのことを、確実にやる。それが、「まだ誰も使っていない人」に届く。「ジャムの法則」をインターフェースにも適用する。CLIツールなら、フラグを減らす。理想は、引数なしで動くこと。mytoolと打てば、最も一般的なユースケースが実行される。設定が必要なら、対話的に聞く。フラグは上級者向けのショートカットだ。最初から覚えてもらうものではない。選択肢を減らすことで、ユーザーは「考える」から「使う」にすぐ移れる。このツールは「技術的に正しい」より「現場で生き残る」設計になっているか。技術的に正しい設計は、しばしば複雑になる。すべてのエッジケースに対応する。すべてのエラーを丁寧にハンドリングする。でも、現場で使われるツールは、シンプルで、雑でも動く。エッジケースを切り捨てた理由を説明できるか。説明できる必要がある。「このケースは月に1回しか発生しない。手動で対応すればいい。だから、ツールでは対応しない。」こう言い切れるなら、切り捨てていい。例外処理より「何も起きないこと」を優先していないか。優先していい。エラーが発生したとき、丁寧なエラーメッセージを出すより、そもそもエラーが発生しない設計の方がいい。入力を厳しくする。想定外の状態を作らない。現場の雑さ・曖昧さ・不完全さを前提にできているか。現場は綺麗ではない。設定ファイルにtypoがある。環境変数が設定されていない。ネットワークが不安定。この雑さを前提に設計する。「完璧な環境でしか動かないツール」は、現場では使われない。小さく始める6ステップを踏んでも、完璧なツールは作れない。だから、小さく始める。最初から完璧なツールを作ろうとしない。自分の問題を解決するスクリプトから始める。それが動いたら、少し整えて公開する。私の場合、多くの隙間家具は、最初はただのシェルスクリプトだった。自分の問題を解決するために、ちょっと書いた。それが便利だったので、もう少し整えた。それを公開した。完璧を目指すと、いつまでも公開できない。「もう少し機能を追加してから」「もう少しドキュメントを整えてから」。そうこうしているうちに、作る気力がなくなる。動くものを、まず作る。公開する。使ってもらう。フィードバックをもらう。改善する。このサイクルを回す。隙間家具を1つ公開したら、終わりではない。むしろ、ここからが始まりだ。探索を続ける捨てやすく作るここからが、私が一番伝えたいことだ。隙間家具には寿命がある。状況が変われば、不要になる。だから、捨てやすく作る。このツールは「自分が将来保守したいコード」になっているか。正直に言えば、保守したくないコードの方が多い。だから、捨てやすく作る。保守したくなるほど愛着が湧くツールは、20個に1個くらいでいい。半年後の自分が読んで理解できる設計になっているか。なっていなくてもいい。半年後に必要なら、そのとき書き直せばいい。必要なければ、捨てればいい。機能追加ではなく「削除」するとしたら、どこを真っ先に消すか。この問いを常に持っておく。削除できる部分があるなら、それは最初から作らなくてよかった部分かもしれない。このコードは、使われなくなったときに綺麗に捨てられるか。捨てられる設計にしておく。依存を少なく。外部サービスとの結合を弱く。捨てるときに、誰にも迷惑がかからないように。私が作ったツールの中で、すでに捨てたものがある。Kubernetesをインストールするツールを作っていた。当時、Kubernetesのインストールは複雑で、手順を間違えると動かなかった。だから、自動化ツールを作った。便利だった。でも、kubeadmがリリースされて、インストールが簡略化された。ツールは不要になった。リポジトリをアーカイブした。悲しくはなかった。むしろ、「自分の問題意識は正しかった」と思えた。Kubernetesの開発者も同じ問題を認識していたのだから。このOSSは「本流に取り込まれる未来」を想定できているか。想定しておく。もしKubernetesやTerraform本体に同等機能が入ったら、どうするか。喜んで捨てる。それは「失敗した」のではなく「役目を終えた」のだ。本流に吸収されるために、意図的にやっていないことは何か。汎用化だ。本流は汎用的になろうとする。隙間家具は特殊なままでいい。特殊だから、本流が取り込みにくい。特殊だから、生き残れる。隙間家具は、状況が変われば不要になる。Kubernetesのバージョンが上がって、その問題が解決されるだろう。別のツールが登場して、より良い解決策を提供するだろう。だから、依存を少なく、シンプルに作る。捨てやすく作る。大きな家具は、捨てにくい。多くのリソースを投入している。多くの人が使っている。捨てることが難しい。隙間家具は、捨てやすい。役目を終えたら、捨てる。そして、新しい隙間を見つけて、新しい隙間家具を作る。「隙間」が「本流」に飲み込まれるリスクもある。Kubernetesのサイドカー機能が進化するように、プラットフォーム自体が隙間を埋めてしまうことがある。これに対する私の戦略は2つだ。1つ目は、捨てやすく作ること。本流に飲み込まれたら、素直に捨てる。自分の問題意識が正しかった証拠だと喜ぶ。2つ目は、本流が手を出さないニッチに特化すること。Kubernetesは汎用的になろうとする。だから、特定の会社の特定のワークフローに特化したツールは、本流が取り込みにくい。汎用化できないほど特殊なニッチを狙う。これも生存戦略だ。捨てたツールから得られる学びもある。単なる「失敗」で終わらせず、次の探索に活かせる知見を抽出する。私がやっているのは、「なぜこのツールは役目を終えたのか」を言語化することだ。本流に取り込まれたのか。別のツールが出てきたのか。そもそも問題設定が間違っていたのか。この分析が、次の隙間を見つける精度を上げる。「問題設定が間違っていた」が一番の学びだ。次は同じ間違いをしない。深化と探索隙間家具を1つ作ったら、終わりではない。隙間家具の開発には、2つの仕事がある。「深化」と「探索」だ。「深化」は、既存の隙間家具を改善すること。バグを直す。パフォーマンスを改善する。ドキュメントを整える。「探索」は、新しい隙間を見つけること。新しい用事を発見すること。新しい隙間家具を作ること。問題は、「深化」へ偏りやすいことだ。既存のツールへイシューが立つ。プルリクエストが来る。対応すると達成感がある。でも、これだけやっていると、最初に見つけた隙間だけを相手にし続けてしまう。競争のないところに宝がある。既存の競合がひしめく場所ではなく、誰も見ていない場所を探す。だから2026年、私はこう決めた。小さな実験を続ける。1つの隙間家具に全力を注ぐのではなく、複数の隙間家具を作り、どれが使われるか見る。全部が使われるわけではない。むしろ、使われないものの方が多い。でも、それでいい。使われなかったツールからも、学びがある。その学びが、次の探索に活きる。チーム開発での引き算ここまでの話は、一人で作る「隙間家具」を前提にしてきた。では、複数人で開発するときはどうか。「引き算の哲学」をチームで共有できるのか。私の経験では、スコープを最初に合意することが鍵だ。「このツールは何を解決し、何を解決しないか」を、開発を始める前にドキュメントへ書く。機能追加の提案が来たら、このドキュメントに立ち返る。「このスコープ外です」と言える根拠になる。チームでの合意形成は、一人のときより難しい。でも、「1つのREADMEで説明できる範囲」という制約は、チームでも使える。「この機能を追加したら、READMEはどう変わるか」を問う。READMEが複雑になるなら、その機能は入れないか、別のツールにする。この基準は、チームメンバー全員が判断できる。個人の好みではなく、客観的な基準だ。おわりにここまで読んでくれた人に、正直に書く。この文章を書きながら、私は何度も手を止めた。「こんなこと書いて意味あるのか」「誰が読むんだ」「もっといい構成があるんじゃないか」。書いている最中に、書くのをやめる理由を探している自分がいた。「代表作」に届かない理由と、まったく同じ構造だ。笑えない。2026年、私は隙間家具を20個作ると決めた。完璧じゃなくていい。動けばいい。使われなくてもいい。作ることそのものに意味がある。そう自分に言い聞かせている。本当にできるかは、分からない。来年の今頃、GitHubにリポジトリが20個並んでいる保証はどこにもない。また「時間がなかった」「優先順位が」と言い訳しているかもしれない。その可能性は、正直、かなり高い。でも、書いた。こうして宣言してしまった。「何を作ればいいか分からない」という人へ。それは正常だ。ゴールは最初から見えているものじゃない。作っているうちに、少しずつ輪郭が浮かんでくる。だから今日、30分だけ時間を取って、最近「面倒だな」と思った作業を1つ書き出してみてほしい。それを解決するスクリプトを書く。動いたら公開する。それだけでいい。20回繰り返す頃には、自分が本当に作りたいものが見えてくる。たぶん。見えてこなかったら、そのときはまた考える。ところで、ここまで偉そうに書いてきたが、私は孤独な独身男性だ。家族はいない。守るべきものが少ない分、狂いやすい環境にいるとも言える。歯止めをかけてくれる人がいない分、自分で自分を律する必要がある。友達との飯の予定。ジムの予約。強制的に「コードを書かない時間」を作らないと、際限なく沈んでいく。独身には独身の戦い方がある。OSSより大事なものはある。友達と話す時間。体を動かす時間。コードは逃げない。隙間家具はいつでも作れる。でも、友人との関係は放っておくと薄れる。健康は一度壊すと戻らない。狂うなら、余裕のあるときに狂え。順番を間違えると、人生ごと壊れる。......と、説教じみたことを書いたが、たぶん来年の今頃の私は、この文章を読み返して頭を抱えている。「狂う」とか言って、結局また「そこそこ」で終わったじゃないか、と。nwiizoというアカウントは、また少し大きくなっているだろう。「代表作」のハードルも、また少し上がっているだろう。自分で自分の首を絞める構造は変わらない。それでも、諦めたくない。憧れたエンジニアたちがいる。彼らのように、「これを作りました」と胸を張れる日が来るまで、手を動かし続ける。だから、書いておく。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。答えが出ない状態は、苦しい。でも、その苦しさの中を泳ぎ続けることでしか、本当に作りたいものは見つからない。完璧を待たない。不完全なまま公開する。恥をかく覚悟で、手を動かす。2026年は、そういう年にする。できるかどうかは知らない。でも、やると決めた。隙間を見つけたら、小さく狂おう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考文献人生にコンセプトを (ちくまプリマー新書)作者:澤田智洋筑摩書房Amazonセンスは知識からはじまる作者:水野学朝日新聞出版Amazonセンスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon「面白い！」を見つける　――物事の見え方が変わる発想法 (ちくまプリマー新書)作者:林雄司筑摩書房AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonわかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon私が間違っているかもしれない作者:ビョルン・ナッティコ・リンデブラッド,キャロライン・バンクラー,ナビッド・モディリサンマーク出版Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon新版 いくつになっても、「ずっとやりたかったこと」をやりなさい。作者:ジュリア・キャメロン,エマ・ライブリーサンマーク出版Amazonいくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazon人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazon行動する人に世界は優しい―自分の可能性を解き放つ言葉―作者:佐藤航陽新潮社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[決断をプロットし、全力で走り続けるためのプロジェクトドキュメント管理]]></title>
            <link>https://zenn.dev/kamos/articles/adr_documentation</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/adr_documentation</guid>
            <pubDate>Mon, 22 Dec 2025 03:55:55 GMT</pubDate>
            <content:encoded><![CDATA[!この文章は人間が書きました画像はGeminiを使って生成しました なぜ、私たちはドキュメントを求めるのか開発現場において、ドキュメント管理は永遠の課題だ。点在する情報、矛盾する記述、実装との乖離、記されない背景情報など、ドキュメントの陳腐化は様々な形で現れる。これらに立ち向かおうとしては、その管理コストの高さに圧倒される。効果が明確に見えにくく、長い時間のかかるドキュメント整備をやり切ることは難しく、多くの現場でドキュメントは放置され、陳腐化し続けている。今度こそドキュメントの整備をやり切ると決意し、絶望する前に考えてほしい。私たちはなぜドキュメントがほしいのか？欲しいも...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Visualizing Coupling in Rust Projects]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</guid>
            <pubDate>Sun, 21 Dec 2025 06:25:59 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling Web UI - Self-diagnosis viewIntroduction"I really don't want to touch this module..."If you've been developing software long enough, you know this feeling. Every change breaks something else. Tests are painful to write. Understanding what the code even does feels impossible. These symptoms share a common root cause: modules that depend too heavily on each other—the problem of coupling.Coupling problems are insidious. They're hard to notice while you're writing code, only revealing themselves later when you wonder why changes are so difficult. What makes it worse is that even when you know "coupling is too tight," it's hard to see exactly where and how, or where to start fixing it.Looking back, I realize my understanding of coupling was quite shallow. I was making judgments based on vague feelings—"this seems tightly coupled" or "loose coupling is supposedly better"—but when I tried to articulate why, I couldn't explain it clearly.To address this lack of visibility, we need a way to measure coupling. But the traditional single axis of "strong vs. weak" isn't enough. The same "strong coupling" means different things depending on where it occurs and in what context.This brings us to Vlad Khononov's concept of "Balanced Coupling." It's a framework that evaluates coupling across three dimensions: strength, distance, and volatility, then assesses their balance. cargo-coupling is a tool I developed to implement this framework for Rust projects.Even as AI writes more of our code, this coupling metric becomes increasingly important. Regardless of who or what writes the code, humans still need to understand, maintain, and extend it. In fact, precisely because AI generates code, we need objective measures to evaluate its structure.Let's start with an overview of the tool, then explore the underlying concepts, and finally see how to use it in practice.What is cargo-coupling?cargo-coupling is a coupling analysis tool I developed for Rust projects.The inspiration came from Vlad Khononov's book "Balancing Coupling in Software Design." The challenges I had vaguely sensed about coupling design were systematically organized in this book. I was impressed by the framework that captures coupling through three dimensions—strength, distance, and volatility—and wanted to create a tool that makes this practical for Rust projects. I highly recommend picking up the book.The tool is available on GitHub. If you find it useful, I'd appreciate a star!GitHub:github.comcrates.io: https://crates.io/crates/cargo-couplingNow, let's challenge a common assumption."Coupling should be minimized"—isn't that what you believe?This tool doesn't aim to "reduce coupling." It aims to "design coupling appropriately." Why? Because coupling isn't inherently bad. Related functionality working closely together is natural. The problem is "strong coupling in inappropriate places" or "tight coupling between distant modules." This shift in perspective is at the heart of this tool.# Installationcargo install cargo-coupling# Basic usagecargo coupling ./srcAnalyzing Coupling Across Three DimensionsSo what exactly constitutes "appropriate coupling"?Traditional coupling analysis tends to think in terms of a single "strong/weak" axis. But stop and consider: strong coupling with an adjacent module versus strong coupling with a distant external library—shouldn't these mean different things? And coupling with code unchanged for five years versus coupling with code modified weekly—shouldn't these carry different risks?A single axis can't capture these differences. cargo-coupling measures coupling across three independent dimensions.1. Integration StrengthThe first dimension is "coupling strength"—how much modules know about each other's internals.Have you seen code like user.password_hash that directly accesses struct fields? That's the strongest form of coupling. Meanwhile, code that interacts through impl Trait works without knowing the other's internals. This difference gets quantified as a score. Level  Score  Description  Rust Example  Intrusive  1.00  Direct dependency on internal implementation  struct.field direct access  Functional  0.75  Dependency on function signatures  Method calls  Model  0.50  Dependency on data structures  Type definitions, type parameters  Contract  0.25  Interface/trait only  impl Trait 2. DistanceThe second dimension is "distance"—how far apart coupled modules are in the code's scope hierarchy.Functions within the same file working closely together is natural. But what if src/auth/login.rs directly references src/billing/invoice.rs? Or worse, depends on an external crate's internal structure? The farther the distance, the "heavier" that coupling becomes. Level  Score  Description  SameModule  0.25  Within the same file/module  DifferentModule  0.50  Different module in the same crate  DifferentCrate  1.00  External crate dependency 3. VolatilityThe third dimension is "volatility"—how frequently the code changes.Your project surely has stable modules untouched for over a year alongside modules modified weekly. Depending on stable code versus frequently changing code carries different risks. cargo-coupling automatically calculates this volatility from Git history. Level  Score  Changes in 6-month Git history  Low  0.00  0-2 changes  Medium  0.50  3-10 changes  High  1.00  11+ changes Calculating the Balance ScoreWe've covered the three dimensions. But if you're told "strength is 0.75," "distance is 0.50," "volatility is medium"—how do you judge whether this coupling is actually good or bad?cargo-coupling combines these three dimensions into a balance score. By consolidating three numbers into one score, you can intuitively assess whether coupling is appropriate.The concept is simple: multiply "strength-distance balance" by "volatility risk."ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACTThe first formula measures whether strength and distance are proportionate. Close distance can tolerate strong coupling; far distance should mean weak coupling. The second formula measures the combined risk of change frequency and coupling strength. Strong coupling with frequently changing code means higher risk of being affected by every change.The conclusions this formula leads to:Strong coupling + Close distance → Good: High cohesion with related functionality in one moduleWeak coupling + Far distance → Good: Loose coupling architecture with minimal inter-module dependenciesStrong coupling + Far distance → Bad: Global complexity where changes affect wide areasStrong coupling + High volatility → Bad: Change propagation risk where frequent changes cascadePractical UsageNow that we understand the theory, let's see how to use it on real projects. cargo-coupling offers multiple output formats depending on your needs.Summary Displaycargo coupling --summary ./srcExample output:Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9Hotspot AnalysisIdentify high-priority modules that need refactoring.cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rsImpact AnalysisExamine the impact scope when changing a specific module.cargo coupling --impact metrics ./srcWeb UI VisualizationVisualize coupling relationships with an interactive graph.cargo coupling --web ./srcA browser opens automatically, displaying an interactive graph using Cytoscape.js. Click nodes to see detailed information; problematic modules are color-coded.CI/CD IntegrationBeyond manual analysis, you can continuously monitor quality. Incorporating cargo-coupling as a quality gate enables early detection of coupling design degradation.cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actions example:- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcReturns exit code 1 when the grade falls below the threshold, making it easy to integrate into CI pipelines.AI IntegrationWhen using with Claude Code or GitHub Copilot, the --ai option is convenient.cargo coupling --ai ./srcOutput is formatted in an AI-friendly way, so you can paste it directly into AI tools to get refactoring suggestions.Detected Problem PatternsHaving covered usage, you might wonder what specific problems get detected. Here are the representative patterns cargo-coupling warns about.God ModuleA module with too many functions, types, or impls.Functions: 30+Types: 15+Impls: 20+High Efferent CouplingA module with too many dependencies. Default threshold is 20+ dependencies.High Afferent CouplingA module depended on by too many others. Default threshold is 30+ dependents.Cascading Change RiskThe combination of intrusive coupling and high volatility. A dangerous state where changes propagate across wide areas.Interpreting Health GradesDetection results are ultimately consolidated into a single grade representing overall project health. Grade  Description  S  Over-optimized. Might be over-refactored  A  Well-balanced. Ideal state  B  Healthy. Manageable condition  C  Room for improvement  D  Attention needed  F  Immediate action required Interestingly, S grade is considered "overdone." Why?Reducing coupling too much fragments code excessively, making the big picture harder to see. Have you experienced needing to open 10 files to trace a single operation, or getting lost in abstraction layers so deep you wonder "what does this actually do?"Coupling isn't simply "less is better." Balance is key.Library UsageBeyond the CLI tool, you can embed it in your own tools. cargo-coupling is also published as a library, allowing you to call analysis functions directly from code.use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST analysis    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git volatility analysis    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // Balance analysis    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}Performancecargo-coupling is designed to run fast even on large projects.Parallel AST analysis with RayonStream processing of Git historyBenchmarks: 655ms on tokio (488 files)Use the --no-git option to skip Git analysis for even faster operation.LimitationsWhile useful, this tool isn't omnipotent. Know these limitations before using it.External crate dependencies aren't analyzed: Dependencies on serde, tokio, etc. aren't analyzed since developers can't control themStatic analysis only: Runtime behavior and macro expansion aren't fully capturedGit history required: Volatility analysis needs Git history. Short history reduces accuracyConclusioncargo-coupling provides a practical approach of "choosing appropriate coupling" rather than the simplistic view that "coupling is bad."3-dimensional analysis: Considers strength, distance, and volatility simultaneouslyGit integration: Reflects actual change frequency as dataActionable suggestions: Presents concrete refactoring actionsMultiple output formats: Text/JSON/Web UI/AI-friendlyCI/CD integration: Automated checks as quality gatesYou don't need perfect design. With a pragmatic attitude that "80% improvement is enough," gradually improve your project's health.# Try it outcargo install cargo-couplingcargo coupling --summary ./srcJust visualizing coupling problems is the first step toward better design.The next time you feel "I really don't want to touch this module..."—that's no longer a vague anxiety. It's a tractable challenge you can analyze across three dimensions of strength, distance, and volatility, and translate into concrete improvement actions. That feeling isn't something to fear; it's the entry point to improvement.A related concept is "Complexity" from John Ousterhout's "A Philosophy of Software Design." It offers another valuable perspective and is well worth reading.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Pulumi: Provisioning Your First Infrastructure with Python]]></title>
            <link>https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Sun, 21 Dec 2025 04:29:37 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[ おい、休め]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</guid>
            <pubDate>Sun, 21 Dec 2025 00:24:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに金曜日の夜、ベッドの上でこの文章を書き始めている。先週の土日は何をしていたかと聞かれたら、たぶん「寝てた」と答える。嘘ではない。ベッドにいた時間は長かった。ただ、眠っていたかというと怪しい。スマホを持ったまま横になって、気づいたら夕方だった。そういう二日間だった。休んだのか、と聞かれると困る。体は動かしていない。仕事もしていない。だから休んだと言えば休んだのだろう。でも、回復したかというと、していない。月曜の朝を迎える自分は、金曜の夜の自分より確実に疲れている。 何もしていないのに。何もしていないから、かもしれない。30歳になった。エンジニアとして働いている。在宅勤務というやつだ。2025年、AIエージェントが当たり前になった時代を生きている。AIは文句を言わない。疲れたとも言わない。24時間動ける。私にはそれができない。コーヒーがないと朝は動けないし、金曜の午後は集中力が死んでいる。土日は「充電」と称してベッドに沈んでいる。それでも充電されない。この一年、ずっとそうだった。ある日、気づいたことがある。私は「休んでいる」んじゃなくて、「動けなくなっている」だけだった。充電じゃなくて、バッテリー切れの放置だった。「休んでいるのに休めていない」とは、「休んでいるのに休めていない」。変な問答である。矛盾しているように聞こえるが、多くの人がこの感覚を知っていると思う。週末を過ごしたはずなのに、月曜日の朝に疲れが残っている。肉体的には、労働的には、確かに「活動していない」。仕事をしていない。オフィスにいない。だから「休んでいる」となんとなく認識する。しかし脳は、休んでいない。ベッドに横になりながらスマホを見ている時、目は画面を追い、脳は情報を処理し、感情は刺激に反応し続けている。通知が来るたびに注意が引かれる。SNSのタイムラインをスクロールするたびに、微小な判断が積み重なる。「これは読む価値があるか」「これにいいねするか」「これに反応すべきか」。身体は止まっているが、脳は回り続けている。これが「休んでいるのに休めていない」の正体だ。情報を入れ続けると、脳は整理する暇がない。食べ続けて消化できない胃のように、頭がパンク状態になる。入力過多で、整理が追いついていない。なぜ本人は「休んでいるつもり」になってしまうのか厄介なのは、本人が気づいていないことだ。私もそうだった。「横になっている＝休んでいる」。この等式が、骨の髄まで染み込んでいる。かつて「休む」とは、物理的に動かないことを意味した。畑仕事を終えて家に帰り、座って何もしない。工場での労働を終えて、ソファに横になる。肉体労働の時代には、「動かない = 休息」という等式が成り立っていた。しかし現代のデスクワーク的な仕事は、主に脳を使う。特にエンジニアは、一日中座っている。肉体は動いていない。だから「仕事 = 動くこと」という図式が崩れている。そして「休息 = 動かないこと」という古い図式をそのまま適用すると、「横になってスマホを見ること」も休息にカウントされてしまう。肉体的には動いていないのだから。でも実際には、脳は仕事中と同じかそれ以上に動いている。休息の定義を更新する必要がある。現代において「休む」とは、脳への入力を減らすことだ。物理的な動きの有無ではなく、認知的な負荷の有無で判断すべきなのだ。この状態を言語化できないと、何がさらに悪化するのか「休んでいるのに休めていない」という感覚を言葉にできないと、さらに深刻な問題が起きる。まず、自己診断を誤る。「十分休んでいるはずなのに疲れている。だから自分は病気かもしれない」「自分は人より弱いのかもしれない」。実際には休息の質の問題なのに、自分の身体や精神に問題があると思い込んでしまう。次に、対処法を間違える。「もっと休めばいい」と考えて、さらに長時間ベッドでスマホを見る時間を増やす。これは逆効果だ。質の悪い休息を量で補おうとしても、回復はしない。そして最も深刻なのは、周囲に理解されないことだ。「週末何してたの？」「ずっと寝てた」「じゃあ休めたね」。この会話で、問題は見えなくなる。本人も「確かに休んだはずだ」と思い込み、周囲も「休んだのだから元気なはずだ」と期待する。「休んだ」という事実と、「休めた」という実感の乖離。これが現代の休息における新しい病だ。言語化できない問題は、解決できない。 だからまず、この状態に名前をつけることが重要だ。「偽りの休息」「見せかけの休息」「脳が休まらない休息」。何でもいい。言葉にすることで、初めて問題として認識できる。AIエージェント時代の疲労2025年、AIエージェントが本格的に動き始めた。Claude Code、Devin、Cursor Agent。これらは単なるツールではない。私たちと同じように考え、判断し、実行する存在になった。コードを書くだけでなく、何を書くべきかを考える。指示を待つだけでなく、自ら次のステップを提案する。この変化は、エンジニアの疲労の質を根本から変えた。AIは無限に働ける。私たちは有限だ。AIエージェントは疲れない。朝も夜も関係ない。週末も祝日も関係ない。感情の浮き沈みもない。モチベーションの低下もない。常に一定のパフォーマンスで、無限に働き続ける。私たちは、そうではない。8時間働けば疲れる。集中力は25分で途切れる。昼食を食べすぎると眠くなる。金曜日の午後は効率が落ちる。睡眠不足の翌日は判断を誤る。感情に左右される。体調に左右される。天気にすら左右される。この対比が、2025年の疲労を特殊なものにしている。かつて、比較対象は同僚だった。隣の席のエンジニアより速くコードを書けるか。チームの中で自分はどの位置にいるか。人間同士の比較だった。今、比較対象にAIが加わった。AIエージェントが一晩で書いたコードを見て、「自分が一週間かかることを、一晩でやった」と思う。AIが瞬時に出した答えを見て、「自分が一時間悩んだことを、数秒で解決した」と思う。無限と有限を比較している。もちろん、話はそう単純じゃない。AIにも限界がある。文脈を読み違える。ハルシネーションを起こす。「それっぽい嘘」を自信満々に言う。コードレビューなしでマージしたら、後で痛い目に遭う。AIが「無限に働ける」のは事実だが、「無限に正しい」わけではない。でも、そんなことは分かっている。分かっていても、比較してしまう。「比較しなければいい」と思ったこともある。でも、環境がそれを許さなかった。同じSlackチャンネルに、自分が1日かけて作ったPRと、AIが1時間で作ったPRが並んでいる。見た瞬間に、脳が勝手に比較する。「あっちの方が速い」と。そう思った時点で、もう比較している。これは意志の問題じゃない。環境の問題だ。同じ画面に並んで表示されている限り、見比べてしまう。見比べれば、負ける。負ければ、「自分は遅い」「自分は非効率だ」「自分は価値がない」と感じる。この感覚が、静かに、確実に、私たちを消耗させている。AIによって増えたのは「作業量」だけではなく、AIエージェントを使うと、作業は速くなる。コードの生成、ドキュメントの作成、調査の実行。これらは確かに効率化される。しかし、楽にはならない。夕方になると、頭が重い。コードを書く時間は減った。でも疲労感は増えている。増えたのは作業量じゃない。判断の回数だ。AIエージェントは大量の選択肢を提示する。コードの候補を10個出す。アプローチを5つ提案する。修正案を複数示す。これらを評価し、選択し、修正し、採用するかどうかを決めるのは人間だ。従来の仕事では、一つのタスクに対して一つの判断があった。自分で作るから、作成と判断が一体化していた。AIを使うと、この構造が変わる。AIが10個の選択肢を提示する。人間は10個を評価し、1つを選ぶ。あるいは「どれも違う」と判断して再生成を指示する。今度は別の10個が出てくる。また評価する。選ぶ。修正を指示する。一つのタスクに対して、判断の回数が爆発的に増える。思い当たることがある。午前中は「これがいい」「あれはダメ」とサクサク判断できる。でも夕方になると、どれを選んでいいか分からなくなる。「どれでもいいから決めてくれ」と思う。頭が重くなって、判断を先延ばしにしたくなる。これは、判断そのものに消耗があるということだ。人間が一日に下せる質の高い判断の数には限りがある。 判断を重ねるほど、後の判断の質は落ちる。AIは判断を代行してくれない。むしろ、判断すべき選択肢を増やす。だから、作業時間が減っても、認知的な消耗は増える。「便利になった」という感覚と、「楽になった」という現実は、必ずしも一致しない。「速くなった」と感じるのに、疲れは減らない。この乖離は危険だ。「速くなっている」と思い込んでいる限り、「なぜ疲れるのか」という問いにたどり着けない。AI疲れはスキル不足の問題ではないAI疲れを感じたとき、多くの人はこう考える。「自分のスキルが足りないからだ」「もっとAIを使いこなせるようになれば楽になる」。正直に言うと、私もそう思っていた。だから毎晩、新しいツールを試し、プロンプトを改善し、ワークフローを最適化した。でも楽にはならなかった。むしろ疲れた。ただ、ここで立ち止まって考えたい。私はこう思うようになった。それは違うんじゃないか、と。確かに、AIツールの使い方には習熟曲線がある。最初は戸惑う。慣れれば効率が上がる。しかし、ある程度習熟した後も、判断疲れは消えない。むしろ、AIを使いこなせるようになるほど、使う頻度が上がり、判断の回数も増える。AI疲れ ≠ スキル不足。AI疲れ = 判断疲れだ。 あなたが下手なんじゃない。ゲームのルールが変わったのだ。AIは人間の判断を代行しない。判断の対象を増やす。この構造的な問題は、スキルアップでは解決しない。解決策は、使い方を変えることだ。AIに全てを任せるのではなく、判断の負荷が高い場面では意識的に使わない。あるいは、AIの出力をそのまま採用する覚悟で使う（評価・修正のループを断ち切る）。しかしこれは、「AIを使いこなす」という文脈では語られない。だから多くのエンジニアは、スキル不足を疑い、さらに学習し、さらに使い、さらに疲れる。AI疲れの原因を正しく特定して認識することが、回復への第一歩だ。「恥」という名の監視システムエンジニアには、独特の恥の文化がある。Xを開く。誰かが「今週読んだ技術書3冊」と投稿している。誰かが「個人開発で新しいフレームワークを試した」と書いている。GitHubの草が青々と茂っている。日曜日の夜に。その瞬間、土日に何もしなかった自分が恥ずかしくなる。「エンジニアは勉強し続けなければならない」。これは真実だ。技術は進化する。学ばなければ置いていかれる。それは分かっている。でも、いつからか「土日に勉強するのが当たり前」になった。休日に技術書を読まないと不安になる。個人開発をしていないと焦る。Qiitaに何も投稿していない月があると、自分の価値が下がった気がする。私たちは「恥」に操られている。恥は、外部から強制されるものではない。誰かに「勉強しろ」と言われているわけではない。上司が土日の学習を義務付けているわけでもない。自分で自分を監視している。 SNSで他人の「充実した週末」を見て、勝手に比較して、勝手に恥じて、勝手に休めなくなっている。これが最も効率的な搾取システムだ。命令する必要がない。監視する必要がない。本人が勝手に自分を追い詰めてくれる。見せかけの「学習」が休息を奪う問題は、この「恥を避けるための学習」が、本当の意味での学習になっていないことだ。土曜日の朝、罪悪感から技術書を開く。でも頭に入ってこない。疲れているから。ページをめくるけど、内容が定着しない。それでも「読んだ」という事実が欲しくて、最後までめくる。これは学習ではない。休息でもない。どちらでもない時間だ。本当に学びたいときの読書と、恥を避けるための読書は、まったく別物だ。前者は楽しい。後者は苦痛だ。前者は定着する。後者は忘れる。恥を避けるために費やした土日は、学習にも休息にもならない。最悪の投資だ。 時間を使って、何も得られず、回復もしない。SNSで他人の土日を見るな。あれは広告だ。冷静に考えてほしい。Xに投稿される「充実した週末」は、全員の週末の平均ではない。投稿したくなるような週末だけが投稿される。何もしなかった週末は投稿されない。つまり、タイムラインに流れてくるのは、全エンジニアの「最も充実した瞬間」の集合体だ。それを自分の「普通の週末」と比較している。勝てるわけがない。他人の土日は広告だ。 広告と自分を比較して落ち込むのは、モデルの写真を見て自分の顔を恥じるのと同じだ。フィルターがかかっている。編集されている。現実ではない。恥を手放すことは、怠惰ではない「じゃあ勉強しなくていいのか」と思うかもしれない。そうではない。学びたいときに学べばいい。休みたいときに休めばいい。恥に駆動されるのをやめろ、と言っている。恥から学習すると、燃え尽きる。好奇心から学習すると、続く。この違いは大きい。土日に何もしなかった自分を、責めなくていい。月曜日に元気に働けるなら、それが正解だ。GitHubの草が生えていなくても、あなたの価値は変わらない。恥は、休息の最大の敵だ。 そして恥は、自分で自分にかけている呪いだ。縛りである。しかし、呪いは、気づいた瞬間に弱くなる。注意力が商品化されるとは、人生に何が起きることなのかふと考えた。なぜ、こんなに疲れているのか。答えの一つは、私たちの注意力が「商品」として売買されているということだ。スマホを開く。通知が来る。タップする。広告が表示される。スクロールする。また通知が来る。この一連の行動の中で、私たちの「注意力」は企業に売り渡されている。そして企業はその注意力を広告主に売る。注意力が奪われることは、なぜ「時間」以上の損失なのか「時間が奪われている」という表現は、まだ甘い。時間は、失っても取り戻せる可能性がある。今日の2時間を失っても、明日の2時間で何かができる。少なくとも、時間は均質に見える。しかし注意力は違う。注意力とは、「今この瞬間に何を経験するか」を決める力だ。何に注意を向けるかが、何を経験するかを決める。何を経験するかが、何を記憶するかを決める。何を記憶するかが、自分が誰であるかを決める。つまり、注意力を奪われることは、経験を奪われることであり、記憶を奪われることであり、最終的にはアイデンティティを奪われることだ。2時間スマホをスクロールして過ごした後、何が残っているか。私の場合、ほとんど何も覚えていない。「何を見てたっけ」と思い返しても、断片的な画像がぼんやり浮かぶだけ。時間は確かに過ぎた。でも経験は残っていない。一方で、友人と2時間話した後は違う。「あの話、面白かったな」「あのとき笑ったな」と、具体的な場面が残っている。同じ2時間でも、記憶への定着度がまるで違う。スマホを見ることも、一応は「経験」だ。でも、受け身で流れてくる情報を処理するだけの経験と、自分で選んだ活動に没頭する経験では、残り方が違う。受け身の時間は、砂に書いた文字のように消えていく。時間泥棒ではなく、人生泥棒だ。なぜ人は自分の注意力の価値に無自覚なのか注意力は、意識しないと見えない。お金は数字として見える。時間は時計として見える。しかし注意力は、どこにも可視化されていない。そして注意力は、「使っている」という感覚がない。お金を使うとき、財布が軽くなる感覚がある。時間を使うとき、時計が進む感覚がある。しかし注意力を使うとき、何かが減っていく感覚は薄い。ただ、気づいたら疲れている。さらに問題なのは、注意力を奪う側が、その事実を隠すインセンティブを持っていることだ。SNSは「つながり」を売り物にする。「あなたの大切な人とつながるためのツール」。しかし実際には、あなたの注意力を広告主に売るためのツールだ。この真実は、マーケティングでは語られない。だから私たちは、自分の注意力が商品になっていることに気づかない。気づかないまま、どんどん売り渡していく。この構造に気づいても、人はなぜ抗えないのか気づいても、抗えない。これが最も絶望的な部分だ。理由の一つは、脳の報酬系がハックされているからだ。通知が来る。ドーパミンが出る。確認する。また通知が来る。この「不定期な報酬」は、脳にとって最も中毒性が高い。スロットマシンと同じ原理だ。いつ当たるか分からないから、ずっと引き続けてしまう。理由のもう一つは、社会的なプレッシャーだ。みんなが使っている。使わないと取り残される。返信しないと失礼。既読をつけないと心配される。SNSから離れることは、社会から離れることのように感じられる。そして最後の理由は、代替手段がないことだ。仕事の連絡もスマホで来る。友人との約束もスマホで確認する。情報収集もスマホでする。スマホを捨てることは、現代社会で生きることを諦めることに近い。構造的な問題には、個人の意志力だけでは対抗できない。だからこそ、意識的な「デジタルデトックス」が必要になる。完全に離れることはできなくても、時間を区切って距離を取る。それが、今できる最大の抵抗だ。オンライン会議は、なぜ「効率的なのに疲れる」のかスマホから注意を奪われるだけではない。在宅勤務の日常には、もう一つの消耗源がある。オンライン会議だ。最初はただ素晴らしいと思った。移動時間がない。どこからでも参加できる。効率的だ、と。でも二年、三年と続けるうちに、何かがおかしいと気づいた。ある日、オンライン会議が5本続いた後、私は何も考えられなくなっていた。画面を閉じても、頭の中がぼんやりしている。簡単なメールすら書けない。対面で5本会議しても、こんなに消耗しなかった。何かが違う。対面では無意識に処理していた情報とは何か対面のコミュニケーションでは、膨大な情報が交換されている。言葉だけではない。表情、視線、姿勢、身振り、声のトーン、間の取り方、呼吸のリズム、空間的な距離感。これらの非言語情報が、コミュニケーションの大部分を占めている。そして重要なのは、これらの情報を無意識に処理しているということだ。対面で話しているとき、相手の表情を「分析」しているわけではない。自然と読み取っている。相手が不快そうなら、無意識に話し方を変える。相手が興味を持っていそうなら、無意識に詳しく説明する。この調整は、意識的な努力なしに行われている。オンライン会議では、この無意識の処理が機能しなくなる。画面越しでは、表情が見えにくい。解像度が低い。タイムラグがある。視線が合わない（カメラを見ると相手の目を見られない）。空間的な距離感がない。全員が同じサイズで画面に並んでいる。無意識に処理できていた情報を、意識的に処理しなければならなくなる。「この人は今、何を考えているのだろう」「この沈黙は同意なのか、困惑なのか」「自分の話は伝わっているのか」。対面なら自動的に分かることが、オンラインでは分からない。だから脳がフル回転して、推測し、分析し、判断する。これが、オンライン会議の疲労の正体だ。さらに、自分の顔が常に画面に映っている。鏡を見ながら会話しているようなもの。音声も微妙に不完全で、脳は余計な労力を使う。同じ1時間でも、処理している情報の密度が違う。だから疲れる。私はこの疲労を個人の問題だと思っていた。でも違った。組織の設計そのものが、この疲労を生み出している。振り返ると、非同期のコミュニケーションで済むことを、わざわざ会議で行っていた。私自身、「対話が必要な場面」に限定することで、オンライン会議の負荷を減らせた。ある日、仕事を一つ担当から外してもらった。「これ、ちょっと抱えすぎてます」と正直に言った。その週、少しだけ頭がクリアだった。「手放してもいい」と思えた瞬間だった。境界線が消えたとき、人間の回復機構はどう壊れるのか在宅勤務で最も失われたもの。それは「境界線」だ。帰りたいのに家に居る。オフィスに通っていた頃は、自然と境界線があった。家を出る。通勤する。オフィスに着く。仕事モードになる。仕事が終わる。オフィスを出る。通勤する。家に着く。オフモードになる。この物理的な移動が、心理的な切り替えを助けていた。在宅勤務では、その境界線が消えた。起きたらすぐに仕事。寝る直前まで仕事。仕事部屋と寝室が同じ。リビングがオフィス。どこでも働ける = どこにも逃げ場がない。物理的な移動は、なぜ心理的切り替えに効いていたのか通勤を嫌う人は多い。満員電車。渋滞。時間の無駄。その通りだ。しかし通勤には、見えない機能があった。通勤は「儀式」だった。人間の脳は、儀式を通じて状態を切り替える。朝のルーティン、食事の作法、寝る前の習慣。これらの儀式が、脳に「次のモードに入る」というシグナルを送る。通勤は、最も強力な儀式の一つだった。家という空間を離れ、別の空間に移動する。その過程で、脳は自然と「仕事モード」に切り替わっていた。帰宅時には逆のプロセスが起きていた。この儀式が消えると、脳は切り替えのタイミングを失う。「いつ仕事を始めるべきか」「いつ仕事を終えるべきか」が曖昧になる。そして気づけば、常に「なんとなく仕事モード」で過ごすことになる。常に仕事モードということは、常に回復モードに入れないということだ。境界線がない働き方は、どんな人に特に危険か特に危険なのは、責任感が強い人と仕事が好きな人だ。「まだできることがある」と思うと止められない。楽しいから止められない。境界線がないと、いつまでも「まだやれる」と思ってしまう。個人の工夫と、その限界着替える。仕事着から部屋着に。あいさつを声に出す。「お疲れ様でした」。これらの小さな儀式が、切り替えを助ける。しかし、限界がある。本来、境界線は環境によって与えられていた。それを個人の意志で維持し続けることは、それ自体が消耗を伴う。だから、環境そのものを変える必要がある。 仕事専用の部屋を作る。コワーキングスペースを使う。PCを別の部屋に置く。物理的に「できない」状態を作る。意志力に頼らない仕組みを作ること。それが、境界線を維持する現実的な方法だ。「疲れた」と感じるとき、本当に疲れているのはどこか「疲れた」と口にする。でも、どこが疲れているのか、自分でも分かっていない。疲れには三つの種類がある。「自律神経の疲れ」。自律神経とは、意識しなくても働く神経システムだ。活動モードを司る交感神経（心拍を上げ、筋肉を緊張させる）と、休息モードを司る副交感神経（心拍を下げ、消化を促す）がある。この二つのバランスが崩れている状態。常に緊張している。リラックスできない。眠れない。朝起きても疲れが取れない。「心の疲れ」。精神的な消耗。ストレス。不安。焦り。人間関係の疲れ。感情労働による消耗。「体の疲れ」。筋肉の疲労。運動不足による倦怠感。同じ姿勢での身体の凝り。自律神経・心・身体のどれが最初に壊れやすいのかこれは個人差があるが、現代のエンジニアにとって、最初に壊れやすいのは自律神経だ。理由は、自律神経の疲労が最も気づきにくいからだ。身体の疲れは分かりやすい。筋肉痛がある。だるさがある。明確な感覚として認識できる。心の疲れも、ある程度は分かる。「イライラする」「落ち込む」「やる気が出ない」。感情として表れる。しかし自律神経の疲れは、症状が曖昧だ。「なんとなく調子が悪い」「眠れない」「食欲がない」「息苦しい」。これらの症状は、他の原因でも起きる。だから「自律神経が疲れている」とは認識されにくい。そして気づかないまま酷使し続けると、ある日突然、限界を超える。動悸がする。めまいがする。パニック発作が起きる。ここまで来て初めて「何かがおかしい」と気づく。自律神経は悲鳴を上げない。気づいたときには、もう限界を超えている。なぜ現代のエンジニアは三重苦に陥りやすいのか問題は、これらが複雑に絡み合っていることだ。長時間のデスクワークで体が疲れる。動かないから血流が滞り、肩が凝り、腰が痛くなる。AIへのキャッチアップ、締め切りのプレッシャー、評価への不安で心が疲れる。オンライン会議の連続、境界線のない働き方、常時接続のプレッシャーで自律神経が疲れる。これらは独立していない。相互に影響し合う。身体が疲れると、心も疲れやすくなる。運動不足はうつ病のリスクを高める。心が疲れると、自律神経が乱れる。ストレスは交感神経を活性化させる。自律神経が乱れると、身体の回復力が落ちる。悪循環のスパイラル。一つの疲れが、他の二つを引き起こし、それがまた最初の疲れを悪化させる。このスパイラルに入ると、自力で抜け出すのは難しい。疲れを誤診すると、どんな「間違った休み」を選ぶのか疲れの種類を見極めずに休もうとすると、的外れな対処をしてしまう。身体が疲れているのに、心の休息を取ろうとする。例えば、運動不足で身体が固まっているのに、マッサージに行ったり、リラクゼーション音楽を聴いたりする。これは悪くないが、根本解決にならない。必要なのは軽い運動だ。心が疲れているのに、身体の休息を取ろうとする。例えば、人間関係のストレスで消耗しているのに、ひたすら寝ようとする。眠れない。眠れても回復しない。必要なのは、安全な場所で感情を吐き出すことだ。自律神経が疲れているのに、刺激で気分転換しようとする。例えば、交感神経が過剰に活性化しているのに、アクション映画を観たり、激しいゲームをしたりする。一時的に気が紛れても、神経はさらに疲弊する。必要なのは、静かな環境でぼんやりすることだ。自分の疲れの種類を見極めること。それが、正しく休むための第一歩だ。身体がシャットダウンする「動けなさ」は、怠惰と何が違うのかベッドから起き上がれない朝がある。やるべきことは分かっている。でも体が動かない。これは怠けているのか。それとも、何か別のことが起きているのか。自分の「動けなさ」について考えていくうちに、気づいたことがある。怠惰と「動けなさ」は、外から見ると同じに見える。でも中身はまったく違う。怠惰は「やる気がない」状態だ。やろうと思えばできる。でもやりたくない。シャットダウンは「動けない」状態だ。やろうと思っても、身体が言うことを聞かない。脳が「これ以上は危険だ」と判断して、強制的にブレーキをかけている。これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。身体を動かなくすることで、エネルギーを温存する。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。社会はなぜこの状態を「甘え」と誤認するのか問題は、シャットダウン状態が外から見ると「怠けている」ように見えることだ。ベッドから起き上がれない。仕事に行けない。何もする気力がない。社会は、これを「意志の問題」として捉えがちだ。「頑張れば動ける」「やる気がないだけ」「甘えている」。しかし、これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。これがシャットダウン反応だ。身体を動かなくすることで、エネルギーを温存し、捕食者の関心を逸らす。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。これは意志の問題ではない。脳が「これ以上は危険だ」と判断して、強制的に止めているのだ。怠惰との違いは明確だ。怠惰は「やる気がない」状態。やろうと思えばできる。シャットダウン状態は「動けない」状態。やろうと思っても、身体が言うことを聞かない。この区別ができないと、本人も周囲も対応を間違える。本人が自分を責めることで、状態はどう固定化されるのか最も危険なのは、本人が自分を責めることだ。「動けないのは自分が怠けているからだ」「意志が弱いからだ」「努力が足りないからだ」。この自己批判が、状態をさらに悪化させる。自己批判はストレスを生む。ストレスは交感神経を活性化させる。しかし、すでに疲弊した身体は交感神経の活性化に耐えられない。だから、また身体がシャットダウンする。「動けない → 自分を責める → ストレス増加 → さらに動けなくなる → さらに自分を責める」この悪循環が、状態を固定化する。回復するためには、この循環を断ち切る必要がある。そのためにはまず、「動けないのは意志の問題ではない」と理解することが重要だ。 自分を責めることをやめる。これが、回復への第一歩だ。この凍結状態から抜けるには、何が最初の一歩になるのかシャットダウン状態から抜け出すのは、簡単ではない。「頑張って動く」というアプローチは逆効果になりうる。有効なのは、身体への穏やかなアプローチだ。まず、安全を感じること。物理的に安全な場所にいる。誰にも批判されない。時間的なプレッシャーがない。この「安全の感覚」が、安心・つながりモードを呼び起こす。次に、身体を少しだけ動かすこと。激しい運動ではない。深呼吸。ゆっくりとしたストレッチ。5分の散歩。これらの穏やかな動きが、身体に「動いても大丈夫だ」というシグナルを送る。そして、人とのつながり。信頼できる人との会話。これらの社会的なつながりが、安心・つながりモードを呼び起こす。重要なのは、「頑張る」のではなく「許す」ことだ。動けない自分を責めない。ゆっくり回復することを許す。無理に何かを達成しようとしない。このスタンスが、凍結状態から抜け出すための土台になる。私自身、過去の失敗をいつまでも反芻して、自分を追い詰めていた時期がある。でも気づいた。忘れることは、逃げではない。 嫌な記憶を手放すことで、初めて前に進める。回復とは、忘れるべきものを忘れられるようになることでもある。なぜ「何もしない休み」が回復にならない場合があるのか休息も、量を追い求めるだけでは意味がない。「長時間休んだ」という事実よりも、「どう休んだか」という質の方がずっと重要だ。休息には二つのタイプがある。「パッシブレスト（消極的休養）」。何もしない。寝る。横になる。身体を動かさない。これは従来の「休息」のイメージだ。「アクティブレスト（積極的休養）」。軽く身体を動かす。散歩する。ストレッチする。ヨガをする。能動的に身体を使うことで回復する。どちらが正解か、ではない。どちらが自分に足りていないかが問題だ。ただ、直感に反するが、現代のエンジニアにはアクティブレストの方が足りていない場合が多い。パッシブレストが逆効果になる条件は何かパッシブレストが逆効果になるのは、以下のような場合だ。身体が動かなすぎているとき。一日中座っていて、血流が滞っている。筋肉が固まっている。この状態でさらに横になっても、血流は改善しない。疲労物質は排出されない。むしろ、さらに滞留する。脳だけが疲れているとき。身体は使っていない。脳だけが酷使されている。この状態で「何もしない」と、身体と脳のアンバランスが解消されない。脳を休めるには、逆に身体を動かす方が効果的な場合がある。横になりながら刺激を受けているとき。ベッドでスマホを見ている状態。身体は休んでいるが、脳は休んでいない。これは休息ではない。むしろ、最悪の組み合わせだ。社会的な孤立状態のとき。一人で何もしない時間が長すぎると、孤独感が増す。孤独は心身に悪影響を与える。パッシブレストが孤独を深めるなら、逆効果だ。アクティブレストは、なぜ自律神経に効くのかアクティブレストが効果的な理由は、生理学的に説明できる。血流が改善する。軽い運動は心拍数を適度に上げ、血液循環を促進する。これにより、筋肉に蓄積した疲労物質が排出される。新鮮な酸素と栄養が全身に行き渡る。自律神経のバランスが整う。適度な運動は、交感神経と副交感神経の切り替えをスムーズにする。運動中は交感神経が優位になり、運動後は副交感神経が優位になる。このリズムが、自律神経の柔軟性を高める。脳の状態が変わる。運動は脳内のセロトニンやエンドルフィンの分泌を促す。これらの神経伝達物質は、気分を改善し、ストレスを軽減する。「運動後に気分がスッキリする」のは、この効果だ。睡眠の質が向上する。日中に適度に身体を動かすと、夜の睡眠が深くなる。これにより、睡眠中の回復効率が上がる。アクティブレストは、受動的な休息では得られない回復効果をもたらす。「休んでいるのに疲れる」行動には共通点があるか「休んでいるつもりなのに疲れる」行動を分析すると、共通点が見えてくる。脳への入力が続いている。スマホ、テレビ、SNS。これらは「受動的」に見えるが、脳は常に情報を処理している。休息ではなく、低負荷の作業だ。身体が動いていない。座っている。横になっている。血流が滞る。筋肉が固まる。代謝が落ちる。社会的なつながりがない。一人で画面に向かっている。人との会話がない。孤独が深まる。達成感がない。ただ時間が過ぎるだけ。何も生み出していない。何も経験していない。虚しさが残る。能動的に選ばなかった時間は、記憶に残らない。後から振り返っても、「何をしていたんだっけ」と思い出せない。これらを逆転させれば、「本当に休まる休息」が見えてくる。脳への入力を減らす。画面から離れる。静かな環境に身を置く。身体を動かす。散歩する。ストレッチする。軽い運動をする。人とつながる。会話をする。一緒に過ごす。達成感を得る。小さなことでいい。料理を作る。掃除をする。何かを「やった」という感覚を持つ。選択的休養という考え方「休む」というと、どうしても「消極的」なイメージがある。何もしない。停止する。エネルギーを使わない。でも、より効果的な休養の形がある。自分で選ぶ休養だ。休息は空いた時間を埋めるものではない。休息は設計対象だ。どう休むかを、自分で決める。「そんな時間ないよ」と思うかもしれない。でも、選択的休養は時間の量ではなく質の問題だ。30分でもいい。自分で選んだ30分は、誰かに決められた2時間より回復効果がある。選択的休養とは、自分の意志で、自分のために選んだ活動のことだ。ポイントは「自分で選ぶ」ことにある。誰かに言われてやるのではない。義務感でやるのではない。「やるべき」だからやるのではない。自分が「やりたい」と思って選ぶ。この「選ぶ」という行為自体が、回復をもたらす。なぜ「自分で選ぶ」ことに意味があるのか現代の疲労の多くは、選択権を奪われていることから来ている。仕事では、やるべきことが決まっている。締め切りがある。上司の指示がある。クライアントの要望がある。自分で選ぶ余地が少ない。プライベートでも、「やるべきこと」に追われている。家事、育児、介護、人付き合い。「自分のため」ではなく「誰かのため」に時間を使う。そして「空いた時間」にスマホを見る。これも、実は選択ではない。アルゴリズムが見せたいものを見せられている。自分で選んでいるようで、選ばされている。常に誰かに決められた行動をしている。だからこそ、「自分で選ぶ」ことに価値がある。自分で選んだ活動をしているとき、脳は「自分の人生をコントロールしている」と感じる。この感覚が、ストレスを軽減し、回復を促進する。逆に、誰かに決められた行動をしているとき、脳は「コントロールを失っている」と感じる。これがストレスの原因になる。選択的休養とは、人生の主導権を握り直すことだ。 そしてこれは、何を覚えておくかだけでなく、何を忘れるかを選ぶことでもある。AIは全てを記憶できる。でも人間は違う。だからこそ、意識的に手放す。追いかけなくていい情報を捨てる。キャッチアップしなくていい技術を諦める。その余白に、自分だけの発想が生まれる。選択的休養の条件選択的休養が効果的であるためには、いくつかの条件がある。自分で決めた。誰かに言われてではなく、自分の意志で選ぶ。「やらなければ」ではなく「やりたい」という動機。仕事とは関係ない。スキルアップのための勉強は選択的休養ではない。仕事に役立つ読書も違う。仕事と完全に切り離された活動。なぜなら、仕事に関連している限り、「成果を出さなければ」というプレッシャーがつきまとうからだ。没頭できる。時間を忘れて集中できる。義務感ではなく、純粋な興味や楽しさで取り組める。成長の実感がある（任意）。必須ではないが、少しずつ上達していく実感があると、より効果的だ。仕事以外の領域で「できるようになった」という経験は、自己効力感を高める。私の場合、それは楽器を弾くことと、格闘技のジムに通うことだった。ギターを弾く時間は、仕事とは無関係で、自分で決めた活動で、時間を忘れて没頭でき、少しずつ上達していく実感がある。格闘技のジムには、別の効果がある。自分一人では無限に追い込めない。だから、真剣にやる以外に選択肢がない環境に身を置く。スパーリング中は、仕事のことなど考えていられない。相手のパンチを避けることに全神経を集中させている。休む時は、可能な限り忘れる。 この忘却を強制してくれる環境が、私には必要だった。なぜ「楽ではないこと」が回復になるのかここで一つの逆説に気づく。格闘技は楽ではない。むしろ苦しい。汗をかく。息が切れる。翌日は筋肉痛だ。苦しいのに、なぜかジムの帰り道は頭が軽い。通い続けるうちに、分かってきた。私が選んだ苦しみは、喜びになる。考えてみれば不思議だ。ホラー映画、激辛料理、過酷な登山。人は日常では避けるはずの「痛み」や「恐怖」に、わざわざ金と時間を払って近づく。私も格闘技に月謝を払っている。殴られに行っている。なぜか。「選んだ苦痛」と「押しつけられた苦痛」は、まったく別物だからだ。仕事のストレス、人間関係の摩擦、将来への不安。これらは望んでいない。避けたいのに避けられない。コントロールできない。だから消耗する。格闘技の苦しさは違う。私が選んだ。いつでもやめられる。コントロールできる。だから同じ「苦しい」でも、片方は消耗で、片方は回復になる。そしてもう一つ気づいたことがある。楽なだけの人生は、たぶんつまらない。苦しみを避け続けた先に、充実はない。ベッドでスマホを見続ける週末は、苦しみをゼロにしようとする試みだ。でもそれは、意味もゼロにしてしまう。何も残らない。月曜日に「週末何してた？」と聞かれて、答えられない。格闘技は苦しい。でも意味がある。だから回復する。「楽であること」と「良いこと」は違う。 私はこれを、身体で学んだ。「ギターや格闘技なんて、自分には無理だ」と思うかもしれない。でも、選択的休養の本質は特定の活動ではない。「仕事の自分」とは別の自分に会いに行くことだ。ランニングでも料理でも将棋でも絵でも釣りでもいい。重要なのは、「仕事に役立つかもしれない」という思考を捨てること。 役に立たなくていい。役に立たないからこそ、純粋に楽しめる。その純粋さが、回復をもたらす。もう一つ、見つけ方のコツがある。周りに勧められたものを、何も考えずに始めてみる。自分で選ぼうとすると、「合うかな」「続くかな」と考えすぎて動けなくなる。友人が「一緒にやろう」と誘ってくれたら、とりあえず乗ってみる。合わなければやめればいい。始める前に悩むより、始めてから判断する方がずっと早い。「役に立たない」と思って捨てたものの中に、自分を救うものがある。デジタルデトックスという実践ある日、スマホを置いて散歩に出た。1時間後、頭が軽かった。そこで気づいた。私の疲労の大きな部分は、デジタル機器から来ていた。 正確には、デジタル機器が境界線を消し、常時接続状態を作り、注意力を奪い続けていた。全ての疲労がデジタル由来ではないが、デジタルが他の疲労を増幅させている。だからこそ、「デジタルデトックス」が必要だ。大げさなことではない。スマホを別の部屋に置く。一日一時間、画面を見ない時間を作る。寝る前の一時間はスマホを触らない。これだけでも効果がある。最初は落ち着かない。通知が気になる。何かを見逃しているような気がする。FOMO（見逃すことへの恐怖）が襲ってくる。この不快感こそが「摩擦」だ。 そして摩擦があるからこそ、その先にある回復は本物になる。でも、数日続けると気づく。別に何も見逃していない。大抵のことは、後から確認しても問題ない。「今すぐ」反応しなければならないことなど、実際にはほとんどない。そして画面から離れた時間に、不思議なことが起きる。頭がクリアになる。創造性が戻ってくる。ぼんやりと考えごとをする余裕が生まれる。有限であることを受け入れ、有限であるからこそできることを大切にする。デジタルから離れた時間は、人間としての有限性を肯定する時間だ。スマホを置いた瞬間、世界は何も変わらない。でも、自分だけが少し回復する。みんな、もっと真剣に休む方法を考えた方がいい。働き方は語られる。生産性は語られる。キャリアは語られる。でも休み方は、ほとんど語られない。「休めばいい」で片付けられる。それは違う。どう働くかと同じくらい、どう休むかは設計が必要なのだ。孤独という敵在宅勤務を続けていると、ある問題に直面する。孤独だ。孤独は好きだと思っていた。一人で考える時間、一人でコードを書く時間、誰にも邪魔されない自由。それを選んで在宅勤務を続けてきた。思えば、昔からそうだった。初対面だけは愛想がいい。すぐに打ち解ける。でも、それ以上は仲良くならない。小学生の頃から「一番仲の良い友達」というものがいなかった。人のことを、どこかで信用しきれない。だから深い関係を避けてきた。孤独は、選んだというより、そうなっていた。でも気づいた。私が「孤独を好んでいる」と思っていたのは、実は「人間関係の疲れから逃げていた」だけかもしれない、と。オンライン会議で消耗する。Slackで気を遣う。だから一人でいたくなる。これは「孤独を選んでいる」のではなく、「疲弊して引きこもっている」だけだ。健全な孤独と、不健全な孤独は違う。健全な孤独は、充電された状態から自分を選ぶこと。不健全な孤独は、消耗した状態から逃避すること。安心している状態から選ぶ孤独は健全だ。身体がシャットダウンした凍結状態としての孤独は、危険信号だ。休むためには、時に人とつながる必要がある。 矛盾しているようだが、社会的なつながりが足りていない状態では、一人でいても回復しない。孤独を選んでいるのか、孤独に追い込まれているのか。この違いを見極めることが、回復の分岐点になる。有給休暇を取るということ去年、有給休暇を40日以上残したまま年度が終わった。「有給どれくらい残ってる？」「40日以上」「俺も」。この会話を何度もした。笑い話みたいに。でも笑えない。40日間、自分のための時間を放棄したということだ。プロジェクトが忙しい。休むと仕事が溜まる。チームに迷惑がかかる。そう言い聞かせてきた。でも本当の理由は違う気がする。「休む理由がない」と思っていた。体調が悪いわけでもない。旅行の予定があるわけでもない。だから働く。この発想自体がおかしかったのだ。ある日、何の予定もなく有給を取ってみた。朝起きて、コーヒーを淹れて、本を読んで、散歩して、昼寝して、夕方になった。何も生産しなかった。何も達成しなかった。でも、妙に満たされていた。気づいたのは、「理由がないから休まない」は、「理由がないと自分を大切にしない」と同じだということ。病気になるまで働いて、やっと休む権利を得る。それは順序が逆だ。リモートワークでは、この問題がさらに深刻になる。どこでも働けるから、どこにいても「働いていない自分」に罪悪感を覚える。有給を取っても、Slackが気になる。結局PCを開いてしまう。有給休暇の本質は、「働かない時間を作る」ことではない。「働かない自分を許す練習」だ。睡眠という基盤深夜2時。また技術記事を読んでいる。「これだけ読んだら寝よう」と思って開いたブラウザのタブが、気づけば15個になっている。一つ読むと、関連記事が気になる。そっちを開く。また関連記事が出てくる。無限ループだ。睡眠が大事なことくらい、知っている。知っていて、毎晩削っている。「知っている」と「できる」の間には、深い溝がある。ある時期、睡眠時間が4時間を切る日が続いた。最初は平気だった。むしろ「自分は少ない睡眠でも動ける」と思っていた。でも二週間くらいで、明らかにおかしくなった。簡単なコードでミスを連発する。同じ箇所を何度も読み返す。会議で人の話が頭に入ってこない。睡眠不足は、自分では気づけない。認知機能が落ちているから、「認知機能が落ちている」ことを認知できない。これが一番怖いところだ。酔っ払いが「俺は酔ってない」と言うのと同じ構造。睡眠不足の人間は、自分が睡眠不足だと正しく判断できない。睡眠中、脳は単に休んでいるのではない。日中に入ってきた情報を整理し、不要なものを捨て、必要なものを定着させている。この作業が追いつかないと、頭の中がゴミ屋敷になる。思考がまとまらない。創造性が消える。読んだ本の内容が腑に落ちるのは、読んだ直後ではない。数日後、ふと「あれはこういうことだったのか」と分かる瞬間がある。その熟成には、睡眠が必要だ。睡眠を削ることは、未来の自分から時間を前借りしている。 利息は高い。そして返済は、体調不良という形でやってくる。今夜削る2時間は、来週のどこかで4時間になって返ってくる。しかも最悪のタイミングで。「効率を手放す」とは、エンジニアにとってどんな覚悟か私たちエンジニアは、効率を追求することに慣れている。コードを最適化する。プロセスを改善する。無駄を省く。それが仕事だ。でも、休息に効率を求めてはいけない。「最も効率的な休息法は何か」「最短時間で最大の回復効果を得るには」「休息の ROI を最大化するには」こういう発想自体が、休息を台無しにする。余暇にまでROIを求める病一日中「効率」を考えている。その思考パターンが、仕事以外の時間にも染み出してくる。無意識のうちに「この行動の費用対効果は」と考えてしまう。時間の希少性。仕事が忙しい。自由な時間が少ない。だから、その貴重な時間を「最大限に活用したい」と思う。無駄にしたくない。効率的に楽しみたい。成果主義の内面化。成果で評価される環境に長くいると、「成果がなければ価値がない」という信念が内面化される。休息も「何かを得るため」に行うべきだと思ってしまう。不安の回避。何もしないことが怖い。生産性がない自分に価値がないと感じる。だから、休息さえも「生産的」にしようとする。非効率な時間は、どんな価値を回復させるのかしかし、非効率な時間には、効率では得られない価値がある。余白から、ふとしたひらめきが生まれる。このブログの構成も、散歩中にふと浮かんだ。何かを「考えよう」としているときではなく、何も考えていないときに、頭が勝手に整理を始める。そして不思議なことに、この整理の過程で、脳は細部を手放している。細部を忘れているからこそ、異なる記憶同士が自由につながる。全部を完璧に覚えていたら、新しい組み合わせは生まれない。ぼんやりしている時間は、無駄ではなかった。自分を取り戻す時間になる。何かを達成するためではなく、ただ存在する時間。その時間の中で、「自分は何が好きなのか」「自分は何を大切にしたいのか」という問いに向き合える。人間らしさを回復する。効率を追求するのは機械の得意分野だ。非効率を楽しめるのは、人間だけの特権だ。 AIは目標を与えられると、最短経路で達成しようとする。しかし人間は、わざと遠回りすることができる。意味のないおしゃべり、下手な楽器演奏、勝てないゲーム。この「わざと非効率を選ぶ」能力は、目標最適化しかできないAIには原理的に不可能だ。非効率の中にこそ、最適化では見つからない価値がある。関係性を深める。人間関係は効率化できない。信頼を築くには時間がかかる。無駄話をする。一緒に何もしない時間を過ごす。これらの「非効率」が、関係性を深める。だから、休息に効率を求めることをやめよう。先週、何の目的もなく街を散策した。1時間、何も生産しなかった。スマホも持たずに、ただ歩いた。帰ってきたとき、妙に頭がすっきりしていた。非効率な時間を、堂々と楽しもう。それが、AI時代を生き抜くための、逆説的な戦略だ。AIは「無駄」を理解できない。だから、無駄を楽しめる人間は、永遠に代替されない。おわりにこの文章を書き終えて、日曜日の夜が終わろうとしている。正直に言うと、書いている間もスマホを何度か見た。通知を確認した。Xを開いた。自分で書いた「デジタルデトックス」の章を読み返しながら、その直後にスマホに手を伸ばしている自分がいた。笑えない。笑えないけど、それが現実だ。私はこの文章を書いたからといって、来週から完璧に休めるようになるわけではない。たぶん来週も、ベッドでスマホを見ながら「休んだつもり」になる日がある。境界線を引けない日がある。格闘技のジムをサボる日がある。でも、少しだけ違うことがある。「休めていない」と気づけるようになった。「これは回復じゃなくて消耗だ」と言語化できるようになった。 それだけでも、前よりマシなのだと思う。たぶん。AIは無限に働ける。私は有限だ。この事実は変わらない。でも、有限であることを恨まなくなった。有限だから、選ばなければならない。選ぶから、何が大事か分かる。全部はできない。全部は追いつけない。それでいい。それに、正直なところ、こうも思っている。どうせAIはこれからもっと賢くなる。 私たちの無能さを、いずれAIが補ってくれる。足りない部分を埋めてくれる。追いつけなかった技術も、AIが代わりにやってくれるようになる。だったら、その日まで健康で元気でいることの方が大事じゃないか。 壊れた身体では、優秀なAIを使いこなすこともできない。だから、選択的に休んでほしい。休むことは、負けを認めることじゃない。降参でもない。 有限な人間として、まともに機能し続けるための、当たり前の行為だ。当たり前のことを、当たり前にやる。それがこんなに難しいとは思わなかった。明日の朝、目覚ましが鳴る。月曜日が始まる。たぶん私は、また疲れている。でも、今日よりは少しだけマシかもしれない。少しだけ、回復の仕方を知っているから。少しだけ、自分を責めずに済むから。おい、休め。これは誰かへの命令じゃない。自分への、しつこい呼びかけだ。何度も忘れて、何度も思い出す。それでいい。完璧に続けることより、何度でも思い出せることの方が大事だから。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍限りある時間の使い方作者:オリバー・バークマンかんき出版Amazonスタンフォード式　疲れない体作者:山田 知生サンマーク出版Amazon戦略的暇作者:森下彰大飛鳥新社Amazon休養学―あなたを疲れから救う作者:片野 秀樹東洋経済新報社Amazon疲労学: 毎日がんばるあなたのための作者:片野 秀樹東洋経済新報社Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonワイド新版　思考の整理学 (単行本 --)作者:外山　滋比古筑摩書房Amazon新版　「読み」の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の効用　「忘れること」で脳は何を得るのか作者:スコット・A・スモール,寺町朋子白揚社Amazon苦痛の心理学:なぜ人は自ら苦しみを求めるのか作者:ポール・ブルーム草思社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon社会は、静かにあなたを「呪う」　～思考と感情を侵食する“見えない力”の正体～ (小学館クリエイティブ)作者:鈴木祐小学館Amazon半うつ　憂鬱以上、うつ未満作者:平 光源サンマーク出版Amazon地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【宇宙】MultimodalUniverse を使って活動銀河核(AGN)の2クラス分類を作ってみる]]></title>
            <link>https://qiita.com/tozastation/items/09e118bf67e129813d00</link>
            <guid isPermaLink="false">https://qiita.com/tozastation/items/09e118bf67e129813d00</guid>
            <pubDate>Sat, 20 Dec 2025 22:06:44 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2025 の21日目の記事です。@tozastationです。普段はWebアプリを開発したり、そのアプリや学習ジョブが動く Kubernetes 基盤の面倒をみています。宇宙が好きなのとAI/MLの方たちがどうい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[IAM Roles Anywhereを使ってオンプレKubernetesでExternal Secrets Operatorを試してみる]]></title>
            <link>https://qiita.com/yutaf11/items/703c7b875157ddf799fc</link>
            <guid isPermaLink="false">https://qiita.com/yutaf11/items/703c7b875157ddf799fc</guid>
            <pubDate>Sat, 20 Dec 2025 14:24:07 GMT</pubDate>
            <content:encoded><![CDATA[はじめにオンプレミスのKubernetesとAmazon EKSによるハイブリッド構成において、シークレット管理の統合は重要な課題の一つです。セキュリティと運用の一貫性を考慮すると、AWS Secrets Managerをシークレット情報のシングルソースとして利用する構...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Rustプロジェクトの結合度を可視化する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</guid>
            <pubDate>Sat, 20 Dec 2025 10:53:29 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling を自己診断した時のweb ui です。はじめに「このモジュール、なんか触りたくないな...」ソフトウェア開発をしていると、こんな感覚を覚えることがあります。変更するたびに他の箇所が壊れる、テストが書きにくい、そもそも何をしているのか把握しづらい。これらの症状には共通点があります。モジュール同士が過剰に依存し合っている、つまり結合（カップリング）の問題です。結合の問題は厄介です。コードを書いているときには気づきにくく、後から「なぜこんなに変更が大変なのか」と悩むことになります。さらに困るのは、「結合が強すぎる」と分かっても、具体的にどこがどう強いのか、どこから手をつければいいのかが見えにくいことです。振り返ってみると、私は結合に対する解像度がかなり低かったのではないでしょうか。「なんとなく密結合っぽい」「疎結合の方がいいらしい」という感覚で良し悪しを判断していた。でも、その感覚を言葉にしようとすると、うまく説明できない。この「見えにくさ」を解消するには、結合を測る物差しが必要です。しかし、従来の「強い/弱い」という1軸だけでは不十分でした。なぜなら、同じ「強い結合」でも、場所や状況によって意味が変わるからです。そこで注目したいのが、Vlad Khononovの「Balanced Coupling」という考え方です。結合を「強度」「距離」「変動性」の3つの軸で捉え、それらのバランスを評価するフレームワークです。今回紹介するcargo-couplingは、このフレームワークをRustプロジェクト向けに実装したツールです。AIがコードを書く時代になっても、この結合度という指標は重要性を増すはずです。なぜなら、コードを書く主体が誰であれ、そのコードを理解し、保守し、拡張するのは人間だからです。むしろAIが生成したコードだからこそ、その構造を客観的に評価できる物差しが必要になります。まずはツールの概要を見てから、その背景にある考え方、そして実際の使い方へと進んでいきましょう。cargo-couplingとはcargo-couplingは、私がRustプロジェクト向けに開発した結合度分析ツールです。このツールを作るきっかけになったのは、Vlad Khononovの著作「Balancing Coupling in Software Design」との出会いでした。結合設計について漠然と感じていた課題が、この本で体系的に整理されていたのです。「強度」「距離」「変動性」という3つの軸で結合を捉えるフレームワークに感銘を受け、これをRustプロジェクトで実際に使えるツールにしたいと考えました。書籍は翻訳も含めて読みやすいので、ぜひ手に取ってみてください。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonツールはGitHubで公開しています。気に入ったらStarしていただけると励みになります。github.comcrates.ioからインストールできます。https://crates.io/crates/cargo-couplingcrates.ioここで、多くの人が持っている常識を一度疑ってみましょう。「結合は減らすべきだ」——そう思っていませんか？このツールは「結合を減らす」ことを目標にしていません。「結合を適切に設計する」ことを目標にしています。なぜなら、結合は本質的に悪ではないからです。関連する機能が密に連携するのは自然なことで、問題になるのは「不適切な場所での強い結合」や「遠く離れたモジュール間の密結合」です。この視点の転換が、このツールの核心です。# インストールcargo install cargo-coupling# 基本的な使い方cargo coupling ./src3つの次元で結合を分析では、「適切な結合」とは具体的に何を指すのでしょうか。従来の結合分析は「強い/弱い」の1軸で考えがちでした。しかし、ここで立ち止まって考えてみてください。同じ「強い結合」でも、すぐ隣のモジュールとの結合と、遠く離れた外部ライブラリとの結合では、意味が違うはずです。また、5年間ほとんど変更されていないコードとの結合と、毎週のように変更されるコードとの結合では、リスクが違うはずです。この違いを捉えるには、1軸では足りません。cargo-couplingは結合を3つの独立した次元で測定します。1. Integration Strength（結合強度）最初の軸は「結合強度」です。モジュール同士が「どれだけ互いの内部を知っているか」を表します。user.password_hashのように構造体のフィールドを直接触っているコード、見覚えがありませんか？これは最も強い結合です。一方、impl Traitを介してやり取りするコードは、相手の内部を知らなくても動作します。この違いをスコア化します。 レベル  スコア  説明  Rust例  Intrusive  1.00  内部実装に直接依存  struct.field 直接アクセス  Functional  0.75  関数シグネチャに依存  メソッド呼び出し  Model  0.50  データ構造に依存  型定義、型パラメータ  Contract  0.25  trait/インターフェースのみ  impl Trait 2. Distance（距離）2つ目の軸は「距離」です。結合されたモジュール同士が、コードのスコープ階層でどれだけ離れているかを表します。同じファイル内の関数同士が密に連携しているのは自然なことです。しかし、src/auth/login.rsがsrc/billing/invoice.rsを直接参照していたらどうでしょう？さらに、外部クレートの内部構造に依存していたら？距離が遠いほど、その結合の「重さ」は増します。 レベル  スコア  説明  SameModule  0.25  同一ファイル/モジュール内  DifferentModule  0.50  同一クレート内の別モジュール  DifferentCrate  1.00  外部クレートへの依存 3. Volatility（変動性）3つ目の軸は「変動性」です。「どれくらい頻繁に変更されるか」を表します。あなたのプロジェクトにも、1年以上触られていない安定したモジュールと、毎週のように修正が入るモジュールがあるはずです。安定したコードに依存するのと、頻繁に変わるコードに依存するのでは、リスクが違います。cargo-couplingはGit履歴からこの変動性を自動で計算します。 レベル  スコア  Git 6ヶ月での変更回数  Low  0.00  0-2回  Medium  0.50  3-10回  High  1.00  11回以上 バランススコアの計算ここまで3つの次元を見てきました。しかし、「強度が0.75」「距離が0.50」「変動性が中程度」とバラバラに言われても、結局この結合は良いのか悪いのか、判断しづらいですよね。そこでcargo-couplingは、これら3つの次元を組み合わせてバランススコアを計算します。3つの数値を1つのスコアにまとめることで、「この結合は適切か」を直感的に判断できるようになります。考え方はシンプルです。「強度と距離のバランス」と「変動性によるリスク」の2つを掛け合わせます。ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACT最初の式は「強度と距離が釣り合っているか」を測ります。距離が近ければ強結合でも問題なく、距離が遠ければ弱結合であるべきです。2番目の式は「変更頻度と結合強度の組み合わせリスク」を測ります。頻繁に変更されるコードと強く結合していると、変更のたびに影響を受けるリスクが高まります。この計算式が導く結論を整理すると、以下のようになります。強結合 + 近距離 → Good：関連機能が1つのモジュールにまとまった高凝集な状態弱結合 + 遠距離 → Good：モジュール間の依存が最小限な疎結合アーキテクチャ強結合 + 遠距離 → Bad：変更影響が広範囲に及ぶグローバル複雑性の状態強結合 + 高変動性 → Bad：頻繁な変更が連鎖的影響を生む変更波及リスク実際に使ってみる理論を理解したところで、実際のプロジェクトでどう使うかを見ていきましょう。cargo-couplingは目的に応じて複数の出力形式を用意しています。サマリー表示cargo coupling --summary ./src出力例は以下のとおりです。Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9日本語出力日本語での出力も対応しています。cargo coupling --japanese ./srcカップリング分析: my-project━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━評価: B (Good) | スコア: 0.67/1.00 | モジュール数: 143次元分析:  結合強度: Contract 1% / Model 24% / Functional 66% / Intrusive 8%           (トレイト)   (型)      (関数)        (内部アクセス)  距離:     同一モジュール 6% / 別モジュール 2% / 外部 91%  変更頻度: 低 2% / 中 98% / 高 0%ホットスポット分析リファクタリングすべき優先度の高いモジュールを特定します。cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rs影響分析特定のモジュールを変更したときの影響範囲を調べられます。cargo coupling --impact metrics ./srcWeb UIでの可視化インタラクティブなグラフで結合関係を可視化できます。cargo coupling --web ./srcブラウザが自動で開き、Cytoscape.jsを使った対話的なグラフが表示されます。ノードをクリックすると詳細情報が見られ、問題のあるモジュールは色分けされます。CI/CDでの活用手動で分析するだけでなく、継続的に品質を監視することもできます。cargo-couplingを品質ゲートとして組み込むと、結合設計の劣化を早期に検出できます。cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actionsの例は以下のとおりです。- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcグレードが基準を下回るとexit code 1を返すため、CIパイプラインに組み込めます。AI連携Claude CodeやGitHub Copilotと組み合わせて使う場合、--aiオプションが便利です。cargo coupling --ai ./srcAIフレンドリーな形式で出力されるので、そのままAIに貼り付けてリファクタリング提案を得られます。検出される問題パターンここまで使い方を見てきましたが、具体的にどんな問題が検出されるのか気になるところでしょう。cargo-couplingが警告する代表的なパターンを紹介します。God Module（神モジュール）関数、型、implが多すぎるモジュールです。関数: 30個以上型: 15個以上impl: 20個以上High Efferent Coupling（外向き結合過多）依存先が多すぎるモジュール。デフォルトでは20以上の依存で警告されます。High Afferent Coupling（内向き結合過多）依存されすぎているモジュール。デフォルトでは30以上の依存元で警告されます。Cascading Change Risk（変更波及リスク）侵入的結合（Intrusive）と高変動性（High Volatility）の組み合わせ。変更のたびに広範囲に影響が及ぶ危険な状態です。ヘルスグレードの解釈問題パターンの検出結果は、最終的に1つのグレードに集約されます。このグレードがプロジェクト全体の健全性を示します。 Grade  説明  S  Over-optimized。リファクタリングしすぎかも  A  Well-balanced。理想的な状態  B  Healthy。管理可能な状態  C  改善の余地あり  D  注意が必要  F  即刻対応が必要 興味深いのは、Sグレードが「やりすぎ」とされている点です。なぜでしょうか？結合を減らしすぎると、コードが細切れになりすぎて、かえって全体像が見えなくなります。1つの処理を追うために10個のファイルを開く必要があったり、抽象化のレイヤーが深すぎて「結局何をしているの？」と迷子になったり。そういう経験はありませんか？結合は「減らせばいい」という単純な話ではありません。バランスが大切なのです。ライブラリとしての利用CLIツールとして使うだけでなく、独自のツールに組み込むこともできます。cargo-couplingはライブラリとしても公開しているので、プログラムから直接分析機能を呼び出せます。use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST解析    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git変動性分析    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // バランス分析    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}パフォーマンスcargo-couplingは、大規模プロジェクトでも高速に動作するよう設計されています。Rayonによる並列AST解析Git履歴のストリーム処理実績: tokio（488ファイル）で655ms--no-gitオプションを使えば、Git分析をスキップしてより高速に動作します。制限事項便利なツールですが、万能ではありません。使う前に知っておくべき制限があります。外部クレート依存は分析対象外: serde、tokioなどへの依存は分析されない。開発者がコントロールできない部分のため静的解析のみ: ランタイムの動作やマクロ展開は完全には捉えられないGit履歴が必要: Volatility分析にはGit履歴が必要。履歴が短いと精度が下がるまとめcargo-couplingは、「結合は悪」という単純な考え方ではなく、「適切な結合を選ぶ」という実用的なアプローチを提供します。3次元分析: 強度・距離・変動性を同時に考慮Git連携: 実際の変更頻度をデータとして反映実行可能な提案: 具体的なリファクタリングアクションを提示複数の出力形式: テキスト/JSON/Web UI/AIフレンドリーCI/CD統合: 品質ゲートとして自動チェック完璧な設計を目指す必要はありません。「80%の改善で十分」というプラグマティックな姿勢で、少しずつプロジェクトの健全性を高めていきましょう。# まずは試してみてくださいcargo install cargo-couplingcargo coupling --summary ./src結合の問題が可視化されるだけでも、設計改善の第一歩になります。次にあなたが「このモジュール、なんか触りたくないな...」と感じたとき、それはもう漠然とした不安ではありません。強度・距離・変動性という3つの軸で分析でき、具体的な改善アクションに落とし込める、対処可能な課題です。その感覚は、恐れではなく、改善の入り口なのです。似た概念にA Philosophy of Software DesignのComplexity がある。これも良い考え方なので一読をおすすめします。 speakerdeck.comA Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon]]></content:encoded>
        </item>
    </channel>
</rss>