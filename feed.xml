<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 11 Dec 2023 18:32:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Helmfile でちょっとしたリソースを追加したい]]></title>
            <link>https://zenn.dev/toshikish/articles/5ead548816e618</link>
            <guid>https://zenn.dev/toshikish/articles/5ead548816e618</guid>
            <pubDate>Mon, 11 Dec 2023 10:57:21 GMT</pubDate>
            <content:encoded><![CDATA[動機Helmfile で公式のチャートをインストールしていて，追加で関連リソースを追加したいことがあります。関連リソースの数が多い，内容が環境によって変わるなどの場合は，カスタムチャートを追加することになるでしょう。ただ，そこまで複雑ではない，関連リソースが数個レベルの場合，カスタムチャートだと大げさに感じることがあります。そこでどうすべきか迷っていたところ，同僚の toVersus さんに別の方法を教えていただきました。 extraTemplates 系の変数を使うHelm チャートによっては extraTemplates や extraObjects といった変数が...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazon S3 バケットの terraform destroy に注意]]></title>
            <link>https://zenn.dev/toshikish/articles/190fe076cc63f4</link>
            <guid>https://zenn.dev/toshikish/articles/190fe076cc63f4</guid>
            <pubDate>Mon, 11 Dec 2023 09:03:06 GMT</pubDate>
            <content:encoded><![CDATA[TL;DRAmazon S3 バケットを削除する前には，必ずすべてのオブジェクトを削除しよう。aws_s3_bucket リソースの force_destroy 引数 を true にしてもよい。terraform destroy で削除すると，パブリックアクセスできる旨のアラートが出る場合があるので注意しよう。aws_s3_bucket_public_access_block リソースを terraform state rm するとアラートが出ない。マネジメントコンソールから削除してもアラートは出ない。 S3 バケットの terraform dest...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメント]]></title>
            <link>https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll</link>
            <guid>https://zenn.dev/nnaka2992/articles/blue_grean_on_postgres_with_sqldeff_and_pgroll</guid>
            <pubDate>Sun, 10 Dec 2023 23:30:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事はこのエントリー以下のアドベントカレンダーの11日目の記事です。3-shake Advent Calendar 2023昨日はtoyb0xによるTODOコメントをチケット管理するためのESLint Custom Ruleでした。PostgreSQL Advent Calendar 2023昨日は@ozozatyによるPostgreSQLのjsonb型でJSONパス式(JSONPath)を使うでした。 はじめにPostgreSQLではDDLはその性質からテーブルレベルでロックを取得してしまいます。SREやPlatform EngineeringなどDev...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GolangでSQSのメッセージを取得する]]></title>
            <link>https://zenn.dev/tayusa/articles/ef4c30c0449a6e</link>
            <guid>https://zenn.dev/tayusa/articles/ef4c30c0449a6e</guid>
            <pubDate>Sun, 10 Dec 2023 00:00:01 GMT</pubDate>
            <content:encoded><![CDATA[キューの取得特に考えることはなくconfig.LoadDefaultConfig()とsqs.NewFromConfig()で取得できるpackage mainimport (	"context"	"github.com/aws/aws-sdk-go-v2/config"	"github.com/aws/aws-sdk-go-v2/service/sqs"	"log")func main() {	ctx := context.Background()	cfg, err := config.LoadDefaultConfig(ctx)	if err !...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLab CIでKICSを実行する]]></title>
            <link>https://zenn.dev/tayusa/articles/d28865c5ce49c6</link>
            <guid>https://zenn.dev/tayusa/articles/d28865c5ce49c6</guid>
            <pubDate>Sun, 10 Dec 2023 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[やることTerraformの静的解析を行うKICSの結果をgitlab-commentでMRに出力するhttps://github.com/yuyaban/gitlab-commentKICSの結果を基にMRにReviewdogで指摘するhttps://github.com/reviewdog/reviewdog KICSの実行$ kics scan --config kics.yamlkics.yamlpath: "." # クエリのパスoutput-path: "." # 結果のパスreport-formats: json # 結果を...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Golangでk8s Deploymentを再起動させる]]></title>
            <link>https://zenn.dev/tayusa/articles/a7df40b7d6fd5b</link>
            <guid>https://zenn.dev/tayusa/articles/a7df40b7d6fd5b</guid>
            <pubDate>Sun, 10 Dec 2023 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[やることclient-goを使って複数のDeploymentを同時に再起動させる Golang Deploymentの取得Pod内であればrest.InClusterConfig()でPodのServiceAccountを使用するconfigを取得できるclientset.AppsV1().Deployments(namespace).Get(ctx, deploymentName, metav1.GetOptions{}) でDeploymentを取得NamespaceとDeploymentの名前が必要k8s.gopackage maini...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TypeScript で LangChain の最初の一歩]]></title>
            <link>https://zenn.dev/satohjohn/articles/9415f85be332e6</link>
            <guid>https://zenn.dev/satohjohn/articles/9415f85be332e6</guid>
            <pubDate>Sat, 09 Dec 2023 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[このエントリーは 3-shake Advent Calendar 2023 の10日目の記事です。今年は Python をガッツリ触ったり、 LLM などの方面に手を出してきており、新しいことにまみれております。その中で LLM のシステム作るんだったら Python だろ？っていう中で TypeScript でもちゃんとできるよーっていうことで紹介していきたいと思います。 私が、あんまり Python でアプリ作っていくのが好きじゃないのもありますもちろん、 Python よりも TypeScript のほうが機能が少なめではありますので、そのあたりは、目をつぶっております。今...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraformのsopsプロバイダーを使用するだけで機密情報は守られるのか]]></title>
            <link>https://blog.masasuzu.net/entry/2023/12/09/014230</link>
            <guid>https://blog.masasuzu.net/entry/2023/12/09/014230</guid>
            <pubDate>Fri, 08 Dec 2023 16:42:30 GMT</pubDate>
            <content:encoded><![CDATA[qiita.comこの記事は、3-shake Advent Calendar 2023の9日目の記事となります。sops プロバイダーとはcarlpett/terraform-provider-sops: A Terraform provider for reading Mozilla sops filesDocs overview | carlpett/sops | Terraform | Terraform RegistrysopsプロバイダーはMozilla sopsを使用して暗号化されたファイルから機密情報を取り出して、terraform上で使用できるようにしたものです。暗号化の鍵をAWS KMS等を使うことにより、KMSキーを使う権限を持つ人だけ機密情報にアクセスできるようにするものです。sopsで機密情報を暗号化することにより、平文で機密情報をgitレポジトリに保存することがなくなり安全ということになります。機密情報を管理したい。でも平文では保存したくない。そういう用途にこちらは使用されます。本当に安心?SOPSを使って機密情報を暗号化することによりgitレポジトリには機密情報が平文で残らない。これで安心と言われていますが、よく考えると機密情報をterraform実行時にはリソースに対して平文で与えているはずです。つまり、tfstate上は機密情報が平文で保存されています。例えば、tfstateがS3に保存されているとして、KMSキーへの権限がない人でもS3バケットにアクセスする権限があれば、平文の機密情報が見れてしまいます。あまりないと思いますが、tfstateをlocalに保存するようにしていてそれをgit管理していてらなんのために暗号化しているのか。。。。ということになります。こう考えると組織のポリシーによるが、sopsプロバイダーによる暗号化では不十分ではないかという疑問が生まれます。ドキュメントを調べるまずプロバイダードキュメントを当たってみます。Docs overview | carlpett/sops | Terraform | Terraform RegistryTo prevent plaintext secrets from being written to disk, you must use a secure remote state backend. See the official docs on Sensitive Data in State for more information.これが意味してるのはバックエンドをlocalにした場合平文で機密情報が書かれるので、安全なリモートバックエンドを利用すべきということだと思います。State: Sensitive Data | Terraform | HashiCorp Developer参照しろと言われたドキュメントの該当部分を読んでみましょう。ローカルディスクにtfstateを保存した場合は、機密情報が平文で保存されます。リモートにtfstateを保存する場合、保存時に暗号化されるかはバックエンドに依存します。基本的にリモートステートを使うことを推奨しています。例えば、Terraform Cloudを使う場合、tfstateは暗号化され、転送時もTLSで暗号化されます。S3を使う場合もSSE-S3やSSE-KMS等でサーバサイド暗号化を有効にしておくことで、保管時の暗号化がされます。バケットポリシーでHTTPSを強制することで通信時の暗号化も保証することができます。参考: 暗号化によるデータの保護 - Amazon Simple Storage Service参考: Amazon S3 のセキュリティのベストプラクティス - Amazon Simple Storage Serviceところがですね。保存時、通信時の暗号化をしても、terraform state pullすると平文でtfstateが手に入ってしまうんですよ。。。後述します。挙動を実験する以下のような設定ファイルを作ります。sopsで暗号化したdb_userとdb_passwordをパラメータストアに設定するものになります。tools-versionsterraform 1.5.5sops 3.7.3main.tfterraform {  required_version = "~> 1.5.5"  required_providers {    aws = {      source  = "hashicorp/aws"      version = "~> 5.15"    }    sops = {      source  = "carlpett/sops"      version = "~> 0.7.2"    }  }  backend "s3" {    region  = "ap-northeast-1"    bucket  = "xxxxxxxxxx"    key     = "test.tfstate"  }}provider "sops" {}provider "aws" {  region = "ap-northeast-1"}data "sops_file" "secrets" {  source_file = "secrets.yaml"}resource "aws_ssm_parameter" "db_user" {  type     = "String"  name     = "/test/db_user"  value    = data.sops_file.secrets.data.db_user}resource "aws_ssm_parameter" "db_password" {  type     = "SecureString"  name     = "/test/db_password"  value    = data.sops_file.secrets.data.db_password}暗号化前の secrets.yamldb_user: userdb_password: passwordapply結果がこちらとなります。terraform apply% export SOPS_KMS_ARN=arn:aws:kms:ap-northeast-1:xxxxxxxxx:key/yyyyyyyyyyyyyyyyyy% terraform applydata.sops_file.secrets: Reading...data.sops_file.secrets: Read complete after 1s [id=-]Terraform used the selected providers to generate the following execution plan. Resource actions areindicated with the following symbols:  + createTerraform will perform the following actions:  # aws_ssm_parameter.db_password will be created  + resource "aws_ssm_parameter" "db_password" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = "/test/db_password"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = "SecureString"      + value          = (sensitive value)      + version        = (known after apply)    }  # aws_ssm_parameter.db_user will be created  + resource "aws_ssm_parameter" "db_user" {      + arn            = (known after apply)      + data_type      = (known after apply)      + id             = (known after apply)      + insecure_value = (known after apply)      + key_id         = (known after apply)      + name           = "/test/db_user"      + tags_all       = (known after apply)      + tier           = (known after apply)      + type           = "String"      + value          = (sensitive value)      + version        = (known after apply)    }Plan: 2 to add, 0 to change, 0 to destroy.Do you want to perform these actions?  Terraform will perform the actions described above.  Only 'yes' will be accepted to approve.  Enter a value: yesaws_ssm_parameter.db_password: Creating...aws_ssm_parameter.db_user: Creating...aws_ssm_parameter.db_user: Creation complete after 0s [id=/test/db_user]aws_ssm_parameter.db_password: Creation complete after 0s [id=/test/db_password]Apply complete! Resources: 2 added, 0 changed, 0 destroyed.terraform apply  8.91s user 0.78s system 124% cpu 7.811 totalstate showするとパラメータストアなのでsensitive扱いになっていて、見れません。これはいけるか?terraform state show% terraform state show aws_ssm_parameter.db_password# aws_ssm_parameter.db_password:resource "aws_ssm_parameter" "db_password" {    arn       = "arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password"    data_type = "text"    id        = "/test/db_password"    key_id    = "alias/aws/ssm"    name      = "/test/db_password"    tags_all  = {}    tier      = "Standard"    type      = "SecureString"    value     = (sensitive value)    version   = 1}% terraform state show aws_ssm_parameter.db_user    # aws_ssm_parameter.db_user:resource "aws_ssm_parameter" "db_user" {    arn       = "arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_user"    data_type = "text"    id        = "/test/db_user"    name      = "/test/db_user"    tags_all  = {}    tier      = "Standard"    type      = "String"    value     = (sensitive value)    version   = 1}ここで、terraform state pullをしてみて、tfstateファイルをローカルにダウンロードします。そのtfstateファイルの中の該当部分はこちらとなります。    {      "mode": "managed",      "type": "aws_ssm_parameter",      "name": "db_password",      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",      "instances": [        {          "schema_version": 0,          "attributes": {            "allowed_pattern": "",            "arn": "arn:aws:ssm:ap-northeast-1:xxxxxxxxx:parameter/test/db_password",            "data_type": "text",            "description": "",            "id": "/test/db_password",            "insecure_value": null,            "key_id": "alias/aws/ssm",            "name": "/test/db_password",            "overwrite": null,            "tags": null,            "tags_all": {},            "tier": "Standard",            "type": "SecureString",            "value": "password",            "version": 1          },          "sensitive_attributes": [            [              {                "type": "get_attr",                "value": "value"              }            ]          ],          "private": "bnVsbA==",          "dependencies": [            "data.sops_file.secrets"          ]        }      ]    },tfstateファイルの中身をよく確認するとしっかり平文で見えています。残念。"value": "password",結論sopsプロバイダーを使用することによりgitレポジトリ上に機密情報を平文で保存することはなくなります。しかしながら、tfstateのデータ上では設定値が平文で保存されることを防ぐことはできません。terraform state pullする権限があれば、機密情報が見れてしまいます。運用組織のポリシーで、tfstateへのアクセス権限を適切に権限管理することができるのであれば、選択肢としては取りうります。暗号化のためのKMSキー、tfstateを保存するS3バケットを機密情報をアクセス可能な人のみ権限を与えることが徹底できればよいです。しかしながら、機密情報をいかなる場合でもローカルに平文で保存することが許容されない組織であれば、機密情報は手動で設定することを選択したほうが望ましいと思います。どうしても機密情報をterraformで管理したのであれば、クライアントサイドで暗号化した機密情報をterraformで管理し、アプリ等で使用時にクライアントサイドで復号を行う形も考えられます。安全かどうかは、tfstateの保存場所、tfstateへのアクセス権限、暗号化鍵のアクセス権限それぞれが適切に設定されているかどうかが鍵となります。他に何かうまい方法で機密情報を管理しているという方がいらっしゃれば、ご意見ください。ワークアラウンドこれは自分がよく使う手段となります。リソースの箱だけ作って、作成時にダミーの値を入れておき、実際の値は手動で設定するという手法です。ignore_changesを入れておくことで、手動で値を変更しても、terraform的には差分ができないようにしています。これにより、機密情報をterraformの外に追い出しつつも、機密情報を入れるリソース自体は監理するということが実現できます。resource "aws_ssm_parameter" "db_password" {  type     = "SecureString"  name     = "/test/db_password"  value    =  "Dummy"  lifecycle {    ignore_changes = [value]  }}]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[はんだ付けから始めるEmbedded Rust on Espressif(3)]]></title>
            <link>https://zenn.dev/satoken/articles/rust-on-esp3</link>
            <guid>https://zenn.dev/satoken/articles/rust-on-esp3</guid>
            <pubDate>Thu, 07 Dec 2023 16:40:18 GMT</pubDate>
            <content:encoded><![CDATA[prometheusで値を取得する前回まででESP32をWifiに接続してDHT11から温湿度を返す簡単なAPIサーバが作成できました。JSONを返すのを変更してprometheusでmetricsを取得できるように変更してみます。HTTPのハンドラ部分のURLを/からmetricsにしてpromethuesの書式を返すように変更しました。    let mut server = EspHttpServer::new(&Configuration::default())?;    server.fn_handler("/metrics", Method::Get, ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[はんだ付けから始めるEmbedded Rust on Espressif(2)]]></title>
            <link>https://zenn.dev/satoken/articles/rust-on-esp2</link>
            <guid>https://zenn.dev/satoken/articles/rust-on-esp2</guid>
            <pubDate>Wed, 06 Dec 2023 15:45:17 GMT</pubDate>
            <content:encoded><![CDATA[温湿度の取得前回まではLEDを光らせてきました。光り物はもう十分なので他のことをやります。これは温湿度が取得できるDHT11センサーです。これを利用して温湿度を取得してみます。https://akizukidenshi.com/catalog/g/gM-07003/以下のように回路を組みます。ちょうど同じことをやっている方がいるので新しくプロジェクトを作成してそのままコードをコピペします。https://www.youtube.com/watch?v=5qYswqbZUDshttps://github.com/shanemmattner/ESP32-C3_Rus...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AlloyDB omni on Kubernetesを眺める]]></title>
            <link>https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator</link>
            <guid>https://zenn.dev/nnaka2992/articles/viewing_alloydb_omni_operator</guid>
            <pubDate>Tue, 05 Dec 2023 23:30:00 GMT</pubDate>
            <content:encoded><![CDATA[このエントリーは以下のアドベントカレンダーの6日目の記事です。3-shake Advent Calendar 2023 シリーズ1昨日は@bells17さんによるChainguard imagesについて調べてみたでした。PostgreSQL Advent Calendar 2023 シリーズ2Kubernetes Advent Calendar 2023昨日は@yassan168さんによるRKE2ノードのCiliumを使ったeBPFな帯域制限をする話でした。 背景を眺める2023年10月12日にAlloyDB OmniのGAに併せてAlloyDB Omni o...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[はんだ付けから始めるEmbedded Rust on Espressif]]></title>
            <link>https://zenn.dev/satoken/articles/rust-on-esp1</link>
            <guid>https://zenn.dev/satoken/articles/rust-on-esp1</guid>
            <pubDate>Tue, 05 Dec 2023 16:22:25 GMT</pubDate>
            <content:encoded><![CDATA[はじめに突然ですがここに秋月電子で購入したESP32-C3があります。1個310円と他のESP32と比べても安価でCPUにRISC-Vを使ったチップです。https://akizukidenshi.com/catalog/g/gM-17493/以下のドキュメントはESP32シリーズを製造しているEspressifによるRustのハンズオンドキュメントです。今回これを読みながらESP32-C3でRustを動かして遊んでみます。Embedded Rust on EspressifThe Rust on ESP BookESP32単体ではPCと接続してプログラムを書き込め...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Chainguard imagesについて調べてみた]]></title>
            <link>https://zenn.dev/bells17/articles/chainguard-images</link>
            <guid>https://zenn.dev/bells17/articles/chainguard-images</guid>
            <pubDate>Tue, 05 Dec 2023 03:58:09 GMT</pubDate>
            <content:encoded><![CDATA[※この記事は3-shake Advent Calendar 2023 シリーズ1の12月5日の記事です最近Chainguard imagesというdistrolessコンテナイメージについて知ったので、簡単に調べてみました。 Chainguard imagesとは？Chainguard imagesはChainguard社によって提供されているdistrolessを中心としたセキュアなコンテナイメージ群だ、という理解です。Wolfiという(おそらくこれもChainguard社が開発している)コンテナ・クラウドネイティブ用途向けのLinux undistroなOSを利用して各C...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ECSの可用性設計を4つの軸で整理する]]></title>
            <link>https://sreake.com/blog/ecs-availability-4-factors/</link>
            <guid>https://sreake.com/blog/ecs-availability-4-factors/</guid>
            <pubDate>Tue, 05 Dec 2023 02:48:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは！Sreake事業部 志羅山です。今年3月に3-shakeに入社し、長野県からリモートで仕事をしています（東京にも定期的に行ってます）。 最近、とあるお客様環境におけるECS（AWSのフルマネージド型 […]The post ECSの可用性設計を4つの軸で整理する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Loggingについて]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/ef07acbb983d01</guid>
            <pubDate>Mon, 04 Dec 2023 11:05:41 GMT</pubDate>
            <content:encoded><![CDATA[whatGoogle CloudのCloud Loggingについて基本概要など調べたことをまとめる適宜追記予定 Cloud Loggingとはhttps://cloud.google.com/logging/docs/overview?hl=jaGoogleCloud上のシステム等が生成したログを収集・保管・管理するための仕組み。基本的にGoogleCloud上のサービスが出力するログはCloud Loggingへと集められる。収集されたログはログバケットと呼ばれるストレージで保管され、期間が過ぎたら破棄するといった設定を行うことが可能。ログはコンソールのログ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[吉祥寺.pm35 でLTしてきました。 #kichijojipm]]></title>
            <link>https://blog.masasuzu.net/entry/2023/12/03/161754</link>
            <guid>https://blog.masasuzu.net/entry/2023/12/03/161754</guid>
            <pubDate>Sun, 03 Dec 2023 07:17:54 GMT</pubDate>
            <content:encoded><![CDATA[吉祥寺.pm こと 句会吉祥寺.pm35 に参加して、LTしてきました。kichijojipm.connpass.com資料はこちら。言いたいこととしてはベストプラクティスなんてないよ。一般的によりよいプラクティスやパターンはあるけど、どんなときには適用できる銀の弾丸的なものはないから、自身の組織とサービスに合わせてくみ上げていきましょうということ。正解はひとつ!じゃない!!その上で、ざっくりとどんな選択肢と選択するための観点を述べていきました。まだ全然ブラッシュアップできるのでどこかでまとめてブログに書きたいところです。ちなみに最後に出てくる あなたらしく○○ は同僚のスライドのパロディです。毎回時間オーバーするのでトークで申し込んだ方が良いのでは?というツッコミはごもっともです。懇親会でもTerraformのお悩みとか短いですが話せて楽しかったです。また参加したいですね。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Auroraアップグレード時のBlue/Green Deploymentsの利用]]></title>
            <link>https://zenn.dev/hakushou41/articles/70b83066cd1741</link>
            <guid>https://zenn.dev/hakushou41/articles/70b83066cd1741</guid>
            <pubDate>Sun, 03 Dec 2023 07:12:32 GMT</pubDate>
            <content:encoded><![CDATA[このエントリーは3-shake Advent Calendar 2023 4日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめにAmazon Aurora2系について、標準サポート終了日(2024/10/31)まで1年を切りました。依然として、Aurora2系を利用しているシステムは多いのではないでしょうか。アプリケーションのテストや検証を考えると早めに動いていかなければならない時期となりました。本記事では、アップグレード方式・方針の一つとして、AWSからも推奨されているRDS Blue/Green Deplo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Playwright Test generatorを利用したE2Eテスト ことはじめ]]></title>
            <link>https://zenn.dev/hakushou41/articles/65bc815b14354f</link>
            <guid>https://zenn.dev/hakushou41/articles/65bc815b14354f</guid>
            <pubDate>Sat, 02 Dec 2023 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[このエントリーは3-shake Advent Calendar 2023 3日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに現在、私はマイクロサービスを運用するSREとして活動しています。運用チームやSREが主導となって実施するメンテナンスやアップデート作業などでは、アップデート後の動作確認として、ブラウザを介したWebアプリケーションの簡易目視確認をします。これらの確認項目は、手順書へ項目を記載し、必要に応じてエビデンスをスクリーンショットで取得する必要があります。確認作業を網羅的にしようとすればするほど...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2023年 俺が愛した本たち 技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/12/02/141455</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/12/02/141455</guid>
            <pubDate>Sat, 02 Dec 2023 05:14:55 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2023 2日目のエントリ記事です。はじめに2023年がそろそろ幕を閉じようとしています。年末に差し掛かると、時間が流れる水のように止まらないことを感じながら、過ぎ去った一年を振り返るのは、私にとって欠かせない習慣です。この一年も、技術書の海に身を投じて、多くの本に心を奪われ、狂気のような積読を重ねました。積めば技術力が向上すると信じている。現代科学では解明できない電波が(諸説あり)積み上がった本からは出ていてこれらが私の知識の山となりました。が、来年はこの山を一歩一歩登り、購入する本の数を読む本の数に下回らせることを心に誓います。2023年は、特に技術の世界で学びは終わりがないことを実感した年でした。読書を通じて得た知識と経験は、来年もまた新たな知識の旅へと私を導くでしょう。また、みなさんが読んで良かったと思うおすすめの本をぜひ教えてください。お互いに良書を共有し、知識を深め合えることを楽しみにしています。昨年の読んだ本syu-m-5151.hatenablog.comはじめに有用情報2023年に読んでよかった技術書サイトリライアビリティワークブックSoftware Requirements Essentialsシステム障害対応 実践ガイドコンテナセキュリティTerraform: Up and Running, 3rd EditionEfficient GoエンジニアのためのドキュメントライティングKubernetes Best Practices, 2nd Editionルールズ・オブ・プログラミング達人プログラマー 第2版スタッフエンジニアさいごに有用情報昨年惜しまれつつ終了したACM会員特典、O'Reilly Online Learningの読み放題サブスクが、2023年に復活しました！これは大きなニュースですね。新しい年間料金は＄174と少々お高くなってしまいましたが、通常の＄499と比較するとかなりの節約です。ちなみに、私は5月に＄499でこのサブスクを手に入れました。興味がある方は、ACM登録ページより登録が可能です。ACM Professional Membership（年間＄99）にACM Skills Bundle Add-On（追加＄75）を組み合わせることで、O'Reilly Online Learning、Skillsoft Percipioのeラーニング、PluralsightのIT技術学習プラットフォームといった3つの学習コンテンツのサブスクを登録できます。2023年に読んでよかった技術書2023年は、読書から得た知識をソフトウェアエンジニアとしての実務経験に結びつけ、いくつかのイベントで登壇する機会に恵まれました。これらの登壇では、本で学んだ理論やアイデアを実際の業務に応用し、それらを共有することで得られた知見が非常に貴重なものでした。今後も、この経験を活かして、より多くの人々と知識を共有し、相互に学び合う機会を創出していきたいと考えています。また、2023年に私が特に愛読した本を紹介し、読書を通じたさらなる知見の共有を図っていく予定です。これらの本が、皆さんの技術的な成長や新しい洞察を得るための一助となれば幸いです。speakerdeck.comサイトリライアビリティワークブック『サイトリライアビリティワークブック ―SREの実践方法』は、『SRE サイトリライアビリティエンジニアリング』の実践編として、SRE（サイトリライアビリティエンジニアリング）を組織やプロジェクトに導入する際に必要な具体的な方法や手順を詳しく解説した本です。Google内部での技術的ノウハウに加え、Evernote、The Home Depot、New York Timesなど、様々な企業での事例を紹介しています。本書は、クラウド環境など制御できない環境での信頼性の高いサービスの実行方法、サービスレベル目標に基づくサービスの作成・監視・運用、運用チームをSREに変換する方法、新規開発や既存サービスにおけるSREの始め方などをカバーしています。また、SREとDevOpsの関係性についても詳しく触れています。この本は、前作『SRE サイトリライアビリティエンジニアリング』と対になる本であり、前作が原理と哲学を紹介するのに対し、本書はそれらの原理の適用方法に焦点を当てています。また、Googleだけでなく、さまざまな企業でのSREプラクティスについても解説しています。本書は前作と比較して内容が身近で読みやすく、SREの理解をさらに深めることができます。基本的な用語や他社の事例が分かりやすく説明されており、SREの実践に関して具体的かつ実用的な内容が盛り込まれています。さらに、分散システムの信頼性に関する知識を深めたい方には、『Go言語による分散サービス―信頼性、拡張性、保守性の高いシステムの構築』がおすすめです。この本は『Distributed Services with Go』の翻訳版であり、2022年8月に発売されました。また、『Designing Data-Intensive Applications』も非常に役立ちここ数年で最も読んでよかった技術書の一冊です。この本はデータ集約型アプリケーションの設計における核心的な概念と技術を網羅的に解説し、信頼性の高い分散システム構築に必要な知識が詳細に説明されています。時間を巻き戻して本を読む順番を選べるなら、もっと早く手に取りたかったと感じています。翻訳版である『データ指向アプリケーションデザイン』も知っておくと有益です。関連するイベントの詳細はこちらで確認できます。イベントは既に終了していますが、本の内容を深く理解し、専門家から新しい視点や知見を得る絶好の機会です。このイベントに参加することで、読書体験がより充実したものになることは間違いありません。動画www.youtube.com発表資料 speakerdeck.comちょっと脱線してしまいましたが総じて、『サイトリライアビリティワークブック ―SREの実践方法』は、SREを導入し、SREの考え方をプロダクト開発に導入しようとしている人にとって有益な情報が豊富に含まれています。サイトリライアビリティワークブック ―SREの実践方法オライリー・ジャパンAmazon英語版を読みたい方のために、Googleが無料で公開しているリンクは以下です。sre.googleSoftware Requirements Essentials「私は過去 10 年間でベストセラーになった要件エンジニアリングの本 10 冊を読んだことがあります。この 1 冊には、それらの 10 冊を合わせたものよりも有益な情報が簡潔に記載されています。」--Mike Cohn, author of User Stories Applied and co-founder, Scrum Allianceこの表現が過剰ではないことがわかる一冊である。はやく読みたかった本つながりで。『Software Requirements Essentials: Core Practices for Successful Business Analysis』は、要件開発と管理における20のコアプラクティスを紹介する重要な本です。著者のKarl WiegersとCandase Hokansonは、伝統的なプロジェクトからアジャイルプロジェクトまで、あらゆるアプリケーションドメインにおいて、優れた価値を提供する可能性が最も高いプラクティスに焦点を当てています。これらのコアプラクティスは、チームがビジネス問題を理解し、適切な参加者を巻き込み、より良い解決策を明確にし、コミュニケーションを改善し、最も価値のある機能を適切な順序で実装し、変化と成長に適応するのに役立ちます。これもサブスクで読めるのでおすすめです。ソフトウェア要求 第3版 を読むほど時間がないのであればおすすめです。learning.oreilly.comソフトウェア要求 第3版 の本も読めます(原書)。やっててよかったO'Reillyサブスクlearning.oreilly.comこの本はソフトウェア要求 第3版を簡潔で焦点を絞った内容であり、「どのように」するかについての実用的な詳細がほどよく含まれているため、すべてのプロジェクト参加者におすすめできます。本書を使用することで、チーム全体が重要な概念、用語、技術、理論について共通の理解を築き、プロジェクトごとにより効果的に協力できます。主な内容には、問題の明確化、ビジネス目標の定義、ソリューションの境界設定、利害関係者と意思決定者の特定、ユーザータスク、イベント、応答の調査、データの概念と関係の評価、品質属性の取り扱い、要件の分析、モデリング、優先順位付け、要件の明確かつ整理された方法での記述、要件のレビュー、テスト、変更管理などが含まれています。Software Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon本当に良い内容だったのですが自分が本として言及するには深すぎる内容だったのでざっくり雰囲気を知りたい人はこちらのブログを確認してほしいです。agnozingdays.hatenablog.comシステム障害対応 実践ガイド『3カ月で改善！システム障害対応 実践ガイド』は、システム障害対応とプロセス改善の実践的なアプローチを提供する画期的な本です。著者の野村浩司氏と松浦修治氏は、それぞれNTTデータとリクルートでの豊富な経験を基に、実際の業務に即した方法を提供しています。本書の大きな特徴は、障害対応の具体的な手法を「メソッド化」している点です。理論だけでなく、「どうすればいいのか？」という実践的な問いに答えており、情報システム担当者や運用リーダーにとって最適な内容となっています。また、本書は障害対応の本質的価値にも触れています。障害対応の改善は、顧客満足度、従業員満足度、そして財務観点からもプラスの効果をもたらします。この点を丁寧に説明しており、運用担当者のモチベーション向上にも寄与する内容です。大規模な障害対応経験がない方でも、対応のイメージがつかめるように工夫されています。障害対応の難所にも言及し、読者が共感しやすい内容となっています。システム障害が起こりうるすべての現場の人々に推奨されるこの本は、システム障害対応をどのように捉え、判断し、対応するべきかについてのフローや表を豊富に掲載しています。これらは特にシステム障害マニュアルが整備されていないチームにとって非常に有用です。1000件以上の事例を分析し生み出されたこのメソッドは、障害対応改善のための役立つ雛形と共に、3カ月での改善を可能にします。インシデント分析から障害訓練まで、各プロセスに役立つ情報が満載です。システム障害対応における課題の特定から改善ステップまで、具体的なガイダンスを提供し、障害対応を改善するための実践的な指針を提供します。3カ月で改善！システム障害対応 実践ガイド インシデントの洗い出しから障害訓練まで、開発チームとユーザー企業の「協同」で現場を変える作者:野村 浩司,松浦 修治翔泳社Amazonまた、SREの観点からいうと『Implementing Service Level Objectives』は、SLO文化をゼロから構築するための具体的なガイダンスを提供する貴重な本です。著者のAlex Hidalgoは、ユーザーの視点からサービスの信頼性を測定するSLIの定義、SLO目標の選択と統計的分析、エラーバジェットの利用方法など、SLOベースのアプローチに必要なツールとリソースの構築について詳しく説明しています。このガイドは、SLOデータを活用して経営陣やユーザーに意味のあるレポートを作成する方法を含め、SLOの実装に関わる全てのステークホルダーにとって非常に価値ある本なので読んでほしいです。この分野では「Webエンジニアのための監視システム実装ガイド」、「運用設計の教科書 ~現場で困らないITサービスマネジメントの実践ノウハウ」などもとてもおもしろかったのでおすすめです。learning.oreilly.comコンテナセキュリティ『コンテナセキュリティ：コンテナ化されたアプリケーションを保護する要素技術』は、Liz Riceによる原著『Container Security: Fundamental Technology Concepts that Protect Containerized Applications』の翻訳版で、コンテナセキュリティに関する深い理解を提供してくれる本です。この本は、コンテナへの攻撃経路、Linuxの構造、コンテナの堅牢化、設定ミスによるセキュリティ侵害のリスク、コンテナイメージビルドのベストプラクティスなど、コンテナセキュリティに関する要素技術を幅広くカバーしています。開発者、運用者、セキュリティ専門家にとって、コンテナセキュリティの理解を深めるための優れた本であり、翻訳を担当しました。コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術作者:Liz Rice,株式会社スリーシェイク　監修,水元 恭平　訳,生賀 一輝　訳,戸澤 涼　訳,元内 柊也　訳インプレスAmazon一方で、同様の本もリリースされております。『基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策』は、森田浩平著による、コンテナセキュリティの基本から応用までを解説した本です。Dockerの普及に伴い、コンテナ技術が広く使用されていますが、そのセキュリティ面についての理解が不十分な点が多々あります。この本は、コンテナ利用時のセキュリティ上の問題を防ぎ、安全に活用するための基本的なガイダンスを提供します。コンテナ型仮想化の概要、コンテナの主要な攻撃ルート、堅牢なコンテナイメージの作り方、セキュアなコンテナ環境の構築など、実践的な内容が盛り込まれています。ちなみにContainer Security Book というこれから Linux コンテナのセキュリティを学びたい人のための文書を公開しているのでこちらを最初に読んでみるのが良いかと思います。基礎から学ぶコンテナセキュリティ――Dockerを通して理解するコンテナの攻撃例と対策 (Software Design plusシリーズ)作者:森田 浩平技術評論社Amazonこれらの本は、コンテナセキュリティに関心が高いエンジニアにとって、理論と実践のバランスを持ち、現代のコンテナ環境で必要とされる重要な知識とスキルを提供します。コンテナ技術のセキュリティ面に関する包括的な理解を深めるために、有益です。Terraform: Up and Running, 3rd Edition『Terraform: Up and Running, 3rd Edition』は、Terraformについての優れた入門書です。とりあえず、何も考えずにTerraform を書くなら読んでほしいです。本書は、Terraformを使用して、様々なクラウドや仮想化プラットフォームでインフラをコードとして定義、立ち上げ、管理する方法を示しています。著者Yevgeniy (Jim) Brikmanは、Terraformのシンプルで宣言的なプログラミング言語を通じて、インフラを数コマンドでデプロイおよび管理する方法を示すコード例を提供しています。この第3版は、Terraform 1.0に対応するために大幅に拡張され、最新の情報が追加されています。Terraformの基本から、大量のトラフィックをサポートし、大規模な開発チームを運営できるフルスタックの実行まで、システム管理者、DevOpsエンジニア、初心者開発者が素早く学べる内容になっています。本書の最大の特徴は、ただコードをコピー＆ペーストするのではなく、読者自身に実際に作業を行わせることを強く推奨している点です。実際に手を動かして学ぶことが、Terraformの理解を深める最善の方法だと著者は語っています。また、gitやdockerなど、本書で使用されるすべての技術について、読者が日常業務で別のツールを使用している場合でもついていけるようにミニチュートリアルが用意されています。さらに、本書は、IaC（Infrastructure as Code）とDevOpsの実践、Terraform、パブリッククラウド、バージョンコントロールの統合、プロビジョニングツールを通じてインフラを作成・デプロイする効果について、基本から細かなニュアンスまでをわかりやすく説明しています。実際にコードを書いてテストする経験は、初心者にとって非常に価値のある学びの機会となります。Infrastructure as Code の3版もEarly Releaseされています(翻訳されて...)。learning.oreilly.comTerraformは進化し続けており、最新機能は絶えず追加されています。例えばTerraform v1.6のtestが追加されますが本書では一切触れられておりません。そのため、最新のリリースや動向に注意を払い続けることが重要です。また、HashiCorpがTerraformを含む自社製品のライセンスをオープンソースから変更したこともあり、今後もその動向に注目する必要があるでしょう。Terraformのフォークが「OpenTofu」としてLinux Foundation傘下で正式ローンチ。OpenTFから改名総じて、TerraformやIaCを学び、理解し、実践したい人にとって、非常におすすめの入門 本です。翻訳本が2023年11月21日に出ましたね。幸せです。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy Brikmanオーム社AmazonEfficient Go『Efficient Go: Data-Driven Performance Optimization』は、計測方法や目的設定から方法から始まり、様々なレベルでの効率を最適化する方法、CPUやメモリなどの一般的なリソースを効果的に使用する技術、Prometheus、Jaeger、Parcaなどのオープンソースプロジェクトを通じてメトリクス、ログ、トレーシング、（連続的な）プロファイリングによる効率評価方法、go test、pprof、benchstat、k6などのツールを使用して信頼性のあるマイクロおよびマクロベンチマークを作成する技術に至るまで、幅広い内容が網羅されています。また、Goの機能であるスライス、ジェネリクス、ゴルーチン、割り当てセマンティクス、ガベージコレクションなどを効率的に使用する方法についても解説されており、記事として散見されるものがまとめて読めることと自体に勝ちがある。加えて最適化の限界を超えると、得るものと失うものが等しくなるみたないマインドセットの部分も含めてとても価値があるのでGoやシステムの最適化を目指す方には必読の内容かと思います。Efficient Go: Data-Driven Performance Optimization作者:Plotka, BartlomiejOreilly & Associates IncAmazonエンジニアのためのドキュメントライティングDocs for Developers: An Engineer’s Field Guide to Technical Writingの翻訳本です。ブログを書いたので読んでほしいです。syu-m-5151.hatenablog.com原著は読んでないです。やっててよかったO'Reillyサブスクは原著版のみあります。learning.oreilly.comまた、技術ドキュメントではないいですが『三行で撃つ 〈善く、生きる〉ための文章塾』もおすすめです。この本は読者に向けた独特なアプローチで、文章技術の向上を目指す実用書です。作家の近藤康太郎氏によるこの本は、ただのテクニック本にとどまらず、書くという行為を通じて自己の実存を考えさせられる思想書としての側面も持ち合わせています。文章テクニックだけでなく、企画の立て方、時間・自己管理術、インプットの方法、思考の深め方に至るまで幅広くカバーし、リリカルな思想とロジカルな技術を融合させています。また、他人の目で空を見ず、自分だけの言葉で書くことの重要性や、「説明しない技術」を身に付けることの必要性を強調し、読者が自然に感情を動かされる文章を書くための技術を教えてくれます。文章を通じて善く生きるための深い洞察を提供する、稀有な一冊です。技術ドキュメントとの差異が分かるので理科系の作文技術や数学文章作法などと一緒に読むと自分がその時に書くべき文章がわかってくる。同著者の近藤康太郎の『百冊で耕す 〈自由に、なる〉ための読書術』は、読む行為を通じて自己を見つめ、新しい自己を発見するための思想書としても機能します。速読や遅読、批判的読書や没入的読書など、対立する読書法を探求し、それらを融合させることで多面的な読書体験を提案しています。近藤氏は、「本は百冊あればいい」と述べ、読者に自分にとってのカノン(聖典)100冊を選び、深く読み込むことで、知識を内面化し、己の一部にする方法を説いています。本書は、読書のご利益を探求し、勉強、孤独、愛、幸せ、生きることについての疑問を掘り下げ、読むことで自分が変わり、他者や世界を愛する新たな自分を発見する旅を提案しています。Kubernetes Best Practices, 2nd Edition『Kubernetes Best Practices, 2nd Edition』は、Kubernetesを活用してアプリケーションを構築するプロセスに焦点を当てた実践的なガイドです。著者たちは、分散システム、エンタープライズアプリケーション開発、オープンソース分野での豊富な経験を活かし、最新のKubernetesの機能や新しいツールに関する知見を提供しています。この本は、Kubernetesの基本概念に精通しているが、最新のベストプラクティスに迅速に対応したい開発者やアーキテクトに最適です。また、既にある程度の知識を持っている方にとって、知識を更新し、新たな視点を得るためのデトックスにも役立ちます。入門書を読みたいならKubernetes: Up and Running, 3rd Editionを読めばよいとおもいます。最新のKubernetesの機能、新しいツール、および廃止された機能についてカバーされており、意外と知らなかったり古くなっている知識があったので知識のデトックスにもオススメです。一方で、『Kubernetes Patterns, 2nd Edition』は、クラウドネイティブアプリケーションの設計と実装におけるパターンと原則に重点を置いています。著者のBilgin IbryamとRoland Hussは、再利用可能なパターンとKubernetesに特化した解決策を提供し、具体的なコード例を通じてこれらのパターンを実演します。読者は、コンテナベースのクラウドネイティブアプリケーションの構築と運用に関する基本原則や、より複雑なトピックを含む様々なパターンを学ぶことができます。個人的にはKubernetes Best Practices, 2nd Editionは良識ある大人が寄ってきてKubernetesについて手取り足取り教えてくれる本。learning.oreilly.comKubernetes Patterns, 2nd Edition はKubernetes について知りたいって言ったら勢いよくオタクが寄ってきてその全てを教えて去っていく本。learning.oreilly.com総じて、『Kubernetes Best Practices』はKubernetesの進んだ使い方やベストプラクティスに焦点を当てており、『Kubernetes Patterns』はKubernetesを用いたアプリケーション設計における具体的なパターンと原則に重点を置いています。どちらの本も、Kubernetesの利用を最大限に活かしたいと考える技術者にとって、非常に価値あるリソースです。ルールズ・オブ・プログラミング『ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール』は、大ヒットゲーム『Ghost of Tsushima』の開発現場で培われた、ゲーム制作スタジオSucker Punch Productionsの共同創設者であるChris Zimmermanによる、すべてのプログラマーにとって必読のプログラミング哲学です。この本では、プログラミングに関する21の本質的なルールが紹介されており、単純化とバランスの取り方、バグの扱い、命名の重要性、一般化のプロセス、最適化のタイミング、コードレビューの価値、失敗の回避、実行されないコードの対応、複雑性の管理など、プログラミングにおける幅広いトピックにわたる洞察が提供されています。C++で書かれたコード例を用いながらも、C++の知識がない読者でも理解できるよう配慮されており、PythonやJavaScriptプログラマー向けのC++コード読解法も掲載されています。この本は、入門書では決してないですがトレードオフを意識したことがある全てのプログラマーにとってプログラミングの日々の課題を解決し、優れたコードを書くための実践的なガイドとして推奨されます。ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール作者:Chris Zimmermanオーム社Amazonこちらは、『ルールズ・オブ・プログラミング』を2倍楽しむための1つのルール というイベントの動画があるのでぜひご覧いただきたいです。www.youtube.com達人プログラマー 第2版『達人プログラマー ―熟達に向けたあなたの旅― 第2版』は、David ThomasとAndrew Huntによる名著で、ソフトウェア開発者がより効率的かつ生産的になるための実践的アプローチを提供する一冊です。本書は特に今年読んだわけではないものの、非常に多く引用して、活用している価値のある本としてあげておきます。プログラマーとしての技術面だけでなく、問題解決の姿勢やプロフェッショナリズムについても深く掘り下げています。例えば、「猫がソースコードを食べちゃった」というセクションでは、責任を持つ重要性を強調し、「石のスープとゆでガエル」では、プロジェクト進行の重要なポイントを示唆します。また、「伝達しよう！」のセクションでは、効果的なコミュニケーションの重要性を説いています。また、プロジェクトマネジメントやチームワーク、プロフェッショナルとしての姿勢に関する深い洞察を提供し、エンジニアとしてのキャリアを積む上での貴重な指針となります。本書はあまりに網羅的な内容のため、各セクションに関連する本での補完が必要だと思います。しかし、特に技術系のポエム記事に触れたことがある読者には、この一冊を深く読み込むことを強くお勧めします。『達人プログラマー』は、プログラマーだけでなく、あらゆるソフトウェア開発に関わる全ての人にとって、読む価値のある一冊です。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonスタッフエンジニア『スタッフエンジニア　マネジメントを超えるリーダーシップ』はWill Larsonによる本で、エンジニアリングキャリアのシニアレベル以上を目指す人にとって重要な指針を提供する一冊です。Will Larsonは、EM（エンジニアリングマネージャー）としてのチームのつくりかた、VPやDirectorとしての組織のつくりかたに関する洞察を提供する『An Elegant Puzzle』の著者でもあります。本書の洋書版を読む気力がなかった私にとって、翻訳本の出版はありがたいことでした。また、LarsonのHow to invest in technical infrastructureという記事も、共通基盤への投資方法について記述しており、非常に参考になるためオススメです。さて、本の内容に戻りますと、第1章ではスタッフエンジニアの役割とその意味を深く掘り下げ、技術力だけでなく組織内での影響力とリーダーシップの重要性を強調しています。これらの役割をどのように達成し、キャリアを前進させるかについて詳細に説明しており、特に印象的なのは、「スタッフエンジニアになれば自分の仕事を自分で管理でき、誰もがあなたに従い、あなたの望むことをするようになると考えたら大間違いだ」という言葉です。これはスタッフエンジニアの役割に関する一般的な誤解を解き明かしています。さらに、シニアエンジニアからスタッフプラスエンジニアへの進化を探る第3章、転職の決断を考慮する第4章、そして現役スタッフエンジニアのインタビューを通じて彼らの日常と役割の変化を深く掘り下げる第5章が続きます。全体を通して、この本は技術的なキャリアパスにおいてマネジメントの道を選ばないエンジニアにとって、必読の書です。各章は、スタッフエンジニアとしての役割を深く理解し、実現するための具体的な手法を提供しています。この本は、私のような経験豊富なエンジニアにとっても新たな学びとなり、これからのキャリアにおいて大いに参考になります。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonさいごに今年一年を通して読み漁った数々の技術書は、私にとって新たな知識の扉を開く鍵となりました。それぞれの本が持つ独自の視点や深い洞察は、技術者としての私の視野を広げ、思考を豊かにしてくれました。皆さんからのおすすめの本も、来年の読書リストに加えて楽しみにしています。読書は単なる趣味ではなく、私たちの知識を形成し、成長させる重要な行為です。皆さんも、来年は私と一緒に、新たな知識の探求に挑戦してみませんか？ それでは、2024年も充実した読書ライフをお過ごし下さい。読書を通じて、皆さんが新しい自分を発見し、さらなる成長を遂げる一年となりますように。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lima で vz + rosetta を使って ARM VM 上で x86_64 バイナリを実行する]]></title>
            <link>https://qiita.com/yteraoka/items/0d793d06cddccad73b0b</link>
            <guid>https://qiita.com/yteraoka/items/0d793d06cddccad73b0b</guid>
            <pubDate>Fri, 01 Dec 2023 22:02:03 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2023 2日目のエントリ記事です。2023年10月に Docker Desktop for Apple silicon での Rose…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[データベースエンジニアのためのDB on Kubernetes入門ガイド]]></title>
            <link>https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers</link>
            <guid>https://zenn.dev/nnaka2992/articles/db_on_k8s_guide_for_db_engineers</guid>
            <pubDate>Thu, 30 Nov 2023 23:30:01 GMT</pubDate>
            <content:encoded><![CDATA[このエントリーは3-shake Advent Calendar 2023 1日目の記事です。株式会社スリーシェイクのメンバーが各々自由に技術・非技術ネタを投稿するカレンダーとなります。 はじめに1959年にW. C. McGeeがデータベースという概念を提唱してから約65年、様々なアーキテクチャのデータベースが提案され様々なプラットフォームで利用されてきました。古くはメインフレームを中心に動作していたデータベースは、マイコンブームとともにそのアーキテクチャを変えながらにオープン系システムへと主戦場を移して行きました。オープン系が主流になってからもその進化は止まることなく、ベア...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[データベース輪読会をやってみた話]]></title>
            <link>https://sreake.com/blog/database-reading-circle/</link>
            <guid>https://sreake.com/blog/database-reading-circle/</guid>
            <pubDate>Wed, 29 Nov 2023 03:45:53 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは。株式会社スリーシェイク Sreake 事業部に所属している @suganamao です。Sreake 事業部は技術力が求められる領域で豊富な経験を持つ SRE の専門家が集まったチームです。事業部に […]The post データベース輪読会をやってみた話 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KEP-4188: New kubelet gRPC API with endpoint returning local pods info]]></title>
            <link>https://zenn.dev/toversus/articles/791c7916e21059</link>
            <guid>https://zenn.dev/toversus/articles/791c7916e21059</guid>
            <pubDate>Mon, 27 Nov 2023 08:23:13 GMT</pubDate>
            <content:encoded><![CDATA[!KEP 持ち寄り会 #1 の登壇資料です。2023/11/27 時点の KEP-4188 の内容です。Kubernetes 1.29 時点で機能として入っていないので注意して下さい。また、後半の文章は考察を含んでおり、正確な情報でない可能性があります。 概要KEP-4188 は、Kubelet に Pod Conditions を公開する gRPC API を追加する KEP です。Pod Conditions は Status フィールドに含まれています。❯ kubectl get pods -n kube-system coredns-5d78c9869d-8gglh ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubとCircleCIからFour Keysを計測する]]></title>
            <link>https://sreake.com/blog/four-keys-with-github-circleci/</link>
            <guid>https://sreake.com/blog/four-keys-with-github-circleci/</guid>
            <pubDate>Wed, 22 Nov 2023 01:25:41 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部でインターンをしている村山です。私は以前に、DORAチームの提案したFour Keysという指標の計測システムの調査・検証を行いました。以前の検証では、GitHubとGitLab、及びモックデ […]The post GitHubとCircleCIからFour Keysを計測する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryの メタデータってどこから見れるの？]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/f6ccafeceac4a3</guid>
            <pubDate>Tue, 21 Nov 2023 10:26:24 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryのメタデータの取得先について簡単にまとめたもの BigQueryのメタデータ、調べることが出来るの?A. 出来るということで、メタデータの主な取得先について記載していく テーブル情報やレコード数BigQueryにはINFORMATION_SCHEMAという、メタデータなどを保持しているビューが存在している。これらを利用してメタデータを取得することが出来る。ただし、テーブルの更新日やテーブルのデータ量については記録されていない。https://cloud.google.com/bigquery/docs/information-sche...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『走馬灯のIaCは考えておいて』というタイトルで登壇しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/21/132144</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/21/132144</guid>
            <pubDate>Tue, 21 Nov 2023 04:21:44 GMT</pubDate>
            <content:encoded><![CDATA[概要2023年11月23日、私は技術的負債に向き合う Online Conference 」にて「走馬灯のIaCは考えておいて - Infrastructure as Codeの導入において技術的負債を考える」というテーマで登壇しました。このセッションでは、Infrastructure as Code（IaC）の実践方法と、技術的負債に対処する際の考慮点について深掘りしました。資料かなり概念系の資料になっているので実践編の登壇の登壇したいので誰か招待してくれ！！！この辺を先に整理しておかないと先の進化的アーキテクチャやA Philosophy of Software Designの話ができないので前提条件をまとめておきました。 speakerdeck.com技術的負債というメタファー に対する違和感私は、技術的な負債についての一般的な表現に違和感を感じています。この点で、まつもとりーさんも技術的負債という表現に対して抵抗を感じていたようです。M年N回目なんですけど、技術的負債という言語化にはずっと抵抗がありまして.......困ったな— まつもとりー / Ryosuke Matsumoto (@matsumotory) 2023年11月21日  この言葉の「負債」という部分が、技術的な問題の本質や性質を正確に捉えていないと感じたため、私は「技術的な腐敗と発酵」という言葉に置き換えることにしました。この新しいメタファーは、技術的問題が時間の経過とともに変化し、時には複雑化や悪化するプロセスをより的確に表現しています。例えば、「腐敗」は、問題が放置されることでシステムの健全性が低下する様子を示し、「発酵」は、初めは小さな問題が時間とともに変化し、場合によっては新たな価値を生み出す可能性があることを意味します。この観点から、私は自身のプレゼンテーションや議論の中で、技術的な問題を扱う際にこれらの言葉を使用しました。普通に元ネタがあります。メタファーとしての発酵 (Make: Japan Books)作者:Sandor Ellix KatzオライリージャパンAmazon実生活の発酵と腐敗の違い実生活における「発酵」と「腐敗」はどちらも微生物の作用による物質の変化プロセスであり、人間にとっての利益に基づいて定義されます。発酵は、生物の作用によって物質が変化し、人間にとって有益なものに変わるプロセスを指し、ヨーグルト、チーズ、醤油などが例として挙げられます。一方、腐敗は同じく微生物の作用による物質の変化ですが、不快な臭いや有害な物質が発生し、人間にとって有害とされるプロセスを指します。この考え方は、インフラの世界にも当てはまります。時間の経過とともに技術が進化し、新しい技術が古い技術に取って代わることが多い中で、長く使用され信頼性が高まった「枯れた技術」は発酵に、時代遅れとなりリスクを引き起こす技術は腐敗に例えられます。これにより、古い技術を見直し、必要に応じて新しい技術に移行するかの判断が容易になり、インフラの健全性と持続可能性を保つ上で重要な役割を果たします。発酵と腐敗・熟成の違いって何？負債と言わないことが負債と向き合うこと「負債と言わないことが負債と向き合うこと」という素晴らしい発表があった。メタファーの限界と実際の技術的課題への取り組みの重要性を改めて感じました。この発表は、言葉だけでなく、根本的な問題解決に焦点を当てることの大切さを示しています。私は向き合わずに逃げたので...。確かに、メタファーは理解を深めるための一つの手段ですが、それにとどまらず、具体的な問題や課題に目を向け、解決策を見つけて実行することが不可欠です。この点において、私は自分の業務、特にSRE（Site Reliability Engineering）の領域において「トイル」という用語が使われていることに気づきました(これも状況を整理するためのメタファーではある)。「トイル」とは、SREのコンテキストで使われる用語で、繰り返し行われる、自動化されていない、戦略的価値の低い作業を指します。この用語を用いることで、SREは単に作業を行うのではなく、その作業がなぜ存在し、どのように改善できるかを考えるように促されます。このような言葉の使い方は、メタファーを超えて、実際の作業の性質や価値を正確に捉え、それに基づいて改善策を模索する手助けとなります。最終的には、このような言葉の使い方が、より効果的で生産的な仕事に取り組むことができます。言葉は単なるコミュニケーションの道具ではなく、私たちの思考や行動に影響を与える強力なツールです。そのため、技術的な課題に取り組む際には、適切な用語を選び、それを戦略的に活用することが重要です。sreake.com speakerdeck.com何が技術的負債に変わるのか技術的負債という言葉のメタファーとしての強さ。技術的負債に向き合う幾つかのヒントをいくつかいただいたので気になった人はぜひ、読んでみてほしい。junkyard.song.mu決定版・ゲームの神様 横井軍平のことばが気になったのでAmazonで調べたところ2023年11月21日現在では20000円だった。ソフトウェアの内部品質に生じる様々な問題は組織設計にその原因があることも多い良い内容だったので感想書く speakerdeck.com異なる思想で書かれたコードの統一に動く -Terraformの場合-良い内容だったので感想書く speakerdeck.com技術的負債が生まれる背景を理解して，アーリーからレイター向けの根本的なアプローチを考える良い内容だったので感想書く speakerdeck.com参考資料Infrastructure as CodeInfrastructure as Code 再考Infrastructure as Codeのこれまでとこれから/Infra Study Meetup #1わたしたちにIaCはまだ早かったのかもしれないThe History of DevOps ReportsEffective DevOpsLeanとDevOpsの科学[Accelerate] テクノロジーの戦略的活用が組織変革を加速する継続的デリバリーのソフトウェア工学:もっと早く、もっと良いソフトウェアを作るための秘訣メタファーとしての発酵Hashicorp DeveloperChef InfraAnsible - Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain.aws-cdk - The AWS Cloud Development Kit is a framework for defining cloud infrastructure in codePulumi - Infrastructure as Code in any programming language.dapr - Dapr is a portable, event-driven, runtime for building distributed applications across cloud and edge.dagger - Application Delivery as Code that Runs AnywhereInfrastructure as Code, 3rd EditionPlatform Engineering MeetupBackstage - Backstage is an open platform for building developer portalsbackstage.ioWhat is platform engineering?DXを成功に導くクラウド活用推進ガイド CCoEベストプラクティスウェブオペレーション―サイト運用管理の実践テクニック]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、Google Cloud Japan の「Google Cloud Partner Top Engineer 2024」にて3名のエンジニアが受賞]]></title>
            <link>https://sreake.com/blog/google-cloud-partner-top-engineer-2024/</link>
            <guid>https://sreake.com/blog/google-cloud-partner-top-engineer-2024/</guid>
            <pubDate>Mon, 20 Nov 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイクは、この度 Google Cloud Japan の「Google Cloud Partner Top Engineer 2024」において、スリーシェイクから3名のエンジニアが受賞したことをお知らせいたします。The post スリーシェイク、Google Cloud Japan の「Google Cloud Partner Top Engineer 2024」にて3名のエンジニアが受賞 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChatGPTのFunctionCallをGolangで試してみる]]></title>
            <link>https://sreake.com/blog/chatgpt-function-call-with-golang/</link>
            <guid>https://sreake.com/blog/chatgpt-function-call-with-golang/</guid>
            <pubDate>Fri, 17 Nov 2023 11:24:01 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 今回、ChatGPTの新機 […]The post ChatGPTのFunctionCallをGolangで試してみる first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/16/161320</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/16/161320</guid>
            <pubDate>Thu, 16 Nov 2023 07:13:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の続きで第四部のV. Delivering Infrastructure (インフラストラクチャの提供)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第五部 目次V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)この章では、スタック定義、サーバー設定、モジュール、ライブラリ、テスト、設定、ユーティリティなど、さまざまな種類のコードが含まれる可能性があります。これらのコードをプロジェクト間およびリポジトリ内でどのように整理するか、またインフラストラクチャコードとアプリケーションコードを一緒に管理するべきか、分けるべきかという問題が提起されています。これには、複数部分からなるエステートのコードをどのように整理するかという課題も含まれます。Organizing Projects and Repositoriesこのセクションでは、プロジェクトがシステムの個別のコンポーネントを構築するために使用されるコードの集まりであると説明されています。プロジェクトやそのコンポーネントがどれだけ含むべきかについての硬いルールはありません。プロジェクト間の依存関係と境界は、プロジェクトコードの整理方法に明確に反映されるべきです。コンウェイの法則によれば、組織の構造とそれが構築するシステムの間には直接的な関係があります。チーム構造とシステムの所有権、およびそれらのシステムを定義するコードの不整合は、摩擦と非効率を生み出します。One Repository, or Many?複数のプロジェクトを持つ場合、それらを単一のリポジトリに入れるべきか、複数のリポジトリに分散させるべきかという問題があります。コードを同じリポジトリに保持すると、バージョン管理やブランチ化が一緒に行えるため、いくつかのプロジェクト統合およびデリバリー戦略を簡素化します。One Repository for Everythingすべてのコードを単一のリポジトリで管理する戦略は、ビルド時のプロジェクト統合パターンでうまく機能します。この戦略では、リポジトリ内のすべてのプロジェクトを一緒にビルドしますが、アプリケーションパッケージ、インフラストラクチャスタック、サーバーイメージなど、複数の成果物を生み出すことがあります。Figure 18-1. Building all projects in a repository togetherA Separate Repository for Each Project (Microrepo)各プロジェクトごとに別のリポジトリを持つ戦略は、プロジェクト間のクリーンな分離を保証します。特に、各プロジェクトを別々にビルドしてテストするパイプラインを持つ場合に効果的です。Multiple Repositories with Multiple Projects一つのリポジトリですべてを管理する極端な戦略と、各プロジェクトごとに別のリポジトリを持つ極端な戦略の間で、多くの組織は複数のリポジトリを持ち、複数のプロジェクトを含む方法を採用しています。Organizing Different Types of Code異なるタイプのコードを整理する戦略を持つことは、コードベースを維持可能にするのに役立ちます。例えば、スタックのプロジェクトレイアウトは、インフラストラクチャスタックコード、テストコード、設定ファイル、デリバリー設定などを含む可能性があります。Delivering Infrastructure and Applicationsアプリケーションとインフラストラクチャのコードを一緒に管理するか、別々にするかという選択は、組織の構造と所有権の分割に依存します。アプリケーションチームがインフラストラクチャに関する責任を持つ場合、コードを分けることは認知的な障壁を生み出す可能性があります。システムのインフラストラクチャのアーキテクチャ、品質、および管理をコードベースから導くという概念を持っています。したがって、コードベースはビジネス要件とシステムアーキテクチャに応じて構築され、管理される必要があります。それはまた、チームが効果的であるためのエンジニアリング原則と実践をサポートする必要があります。19. Delivering Infrastructure Code (インフラストラクチャコードのデリバリー)インフラストラクチャコードのデリバリーについての章では、ソフトウェアのデリバリーライフサイクルが重要なコンセプトとして強調されています。しかし、インフラストラクチャのデリバリーは、しばしば異なるタイプのプロセスに従います。例えば、本番環境でテストされないハードウェアの変更が一般的です。しかし、コードを使ってインフラストラクチャを定義することで、より包括的なプロセスで変更を管理する機会が生まれます。例えば、サーバーのRAMを変更するような手動で構築されたシステムへの変更を開発環境で複製することは、ばかげているように思えるかもしれません。しかし、コードで実装された変更は、パイプラインを通じて本番環境へ簡単に展開することができます。Delivering Infrastructure Codeパイプラインのメタファーは、インフラストラクチャコードの変更が開発者から本番インスタンスへ進む方法を説明しています。このデリバリープロセスに必要なアクティビティは、コードベースの整理方法に影響を与えます。Figure 19-1. Infrastructure code project delivery phasesBuilding an Infrastructure Projectインフラストラクチャプロジェクトのビルドは、コードを使用するための準備を行います。これには、ライブラリの取得、ビルド時の設定の解決、コードのコンパイルまたは変換、テストの実行、ツールが適用するためのフォーマットでコードを準備することなどが含まれます。Packaging Infrastructure Code as an Artifact一部のツールでは、「コードの使用準備」は特定のフォーマットのパッケージファイルにファイルを組み立てることを意味します。これは、Ruby（gems）、JavaScript（NPM）、Python（pipインストーラーを使用するPythonパッケージ）などの一般的なプログラミング言語で一般的なプロセスです。Using a Repository to Deliver Infrastructure Codeチームはソースコードリポジトリを使用して、インフラストラクチャソースコードの変更を保存し、管理します。多くのチームは、環境やインスタンスにデリバリーする準備ができたコードを保存するために、別のリポジトリを使用します。Figure 19-2. Build stage publishes code to the delivery repositoryIntegrating Projects「Organizing Projects and Repositories」で述べたように、コードベース内のプロジェクト間には通常、依存関係があります。次に、互いに依存するプロジェクトの異なるバージョンをいつ、どのように組み合わせるかという問題があります。Pattern: Build-Time Project Integrationビルド時のプロジェクト統合パターンは、複数のプロジェクトをまたいでビルドアクティビティを実行します。これには、それらの依存関係を統合し、プロジェクト間のコードバージョンを設定することが含まれます。Pattern: Delivery-Time Project Integrationデリバリー時のプロジェクト統合パターンは、それぞれのプロジェクトを個別にビルドおよびテストした後で組み合わせます。このアプローチでは、ビルド時の統合よりも後の段階でコードのバージョンを統合します。Pattern: Apply-Time Project Integration適用時のプロジェクト統合は、複数のプロジェクトを別々にデリバリーステージを進めることを含みます。プロジェクトのコードに変更が加えられたとき、パイプラインはそのプロジェクトの更新されたコードをそのプロジェクトのデリバリーパスの各環境に適用します。Using Scripts to Wrap Infrastructure Tools多くのチームは、インフラストラクチャツールをオーケストレーションし、実行するためにカスタムスクリプトを作成します。これには、Make、Rake、Gradleなどのソフトウェアビルドツールを使用する場合や、Bash、Python、PowerShellでスクリプトを書く場合があります。多くの場合、このサポートコードはインフラストラクチャを定義するコードと同じくらい、またはそれ以上に複雑になり、チームはそのデバッグと維持に多くの時間を費やすことになります。確実で信頼性の高いインフラストラクチャコードのデリバリープロセスを作成することは、4つの主要なメトリクスに対して良好なパフォーマンスを達成するための鍵です。あなたのデリバリーシステムは、システムへの変更を迅速かつ信頼性高くデリバリーすることの実際の実装です。Only build packages once. を参考にしてください。20. Team Workflows (チームワークフロー)IaCを利用することによる作業方法の根本的な変化に焦点を当てています。従来のアプローチとは異なり、仮想サーバーやネットワーク構成の変更をコマンド入力やライブ設定の直接編集ではなく、コードの記述と自動化システムによる適用を通じて行います。これは新しいツールやスキルの習得を超えた変化であり、インフラストラクチャを設計、構築、管理する全ての人々の働き方に影響を与えます。Figure 20-1. A classic mapping of a dedicated team to each part of a workflowThe People信頼できる自動化ITシステムでは、人々が重要な役割を果たします。コード変更を本番システムに反映させるためには、テスト結果のレビューやボタンの操作以外に、人の手は必要ありませんが、システムの継続的な構築、修正、適応、改善には人間が不可欠です。Who Writes Infrastructure Code?組織によってインフラストラクチャコードを誰が書くかという問いに対する答えは異なります。伝統的なプロセスとチーム構造を維持しようとする組織では、インフラストラクチャを構築（およびサポート）するチームがインフラストラクチャ・アズ・コードのツールを使用して作業を最適化します。また、多くの組織ではアプリケーションチームが自分たちのアプリケーションに必要なインフラストラクチャを定義しています。Applying Code to Infrastructureインフラストラクチャへのコード適用に関する一般的なワークフローは、共有ソースリポジトリ内のコードから始まります。チームメンバーは最新バージョンのコードを自分の作業環境にプルし、編集した後、ソースリポジトリにプッシュして新しいバージョンのコードを様々な環境に適用します。Applying Code from Your Local Workstationローカルワークステーションからインフラストラクチャコードを適用することは、他の誰も使用していないインフラストラクチャのテストインスタンスに対しては有用です。しかし、ローカル作業環境からツールを実行すると、共有インフラストラクチャインスタンスに問題を引き起こす可能性があります。Applying Code from a Centralized Serviceインフラストラクチャコードをインスタンスに適用するために、中央集権的なサービスを使用できます。このサービスはソースコードリポジトリまたはアーティファクトリポジトリからコードをプルし、インフラストラクチャに適用します。Personal Infrastructure Instances理想的には、共有リポジトリにプッシュする前にコード変更をテストできる方法があります。これにより、変更が期待通りの動作をするかどうかを確認でき、パイプラインがオンラインテストステージまでコードを実行するのを待つよりも高速です。Source Code Branches in Workflowsソースリポジトリのブランチは、コードベースの異なるコピー（ブランチ）で作業を行い、準備ができたら統合する際に役立ちます。Martin Fowlerの記事「Patterns for Managing Source Code Branches」には、チームのワークフローの一部としてブランチを使用する様々な戦略やパターンが説明されています。Preventing Configuration Drift設定のドリフトを防ぐために、ワークフローにおいていくつかの対策を講じることができます。これには、自動化の遅れを最小限に抑える、アドホックな適用を避ける、コードを継続的に適用する、不変のインフラストラクチャを使用するなどが含まれます。Governance in a Pipeline-based Workflowパイプラインベースのワークフローにおけるガバナンスでは、責任の再配置、左へのシフト、インフラストラクチャ・アズ・コードのガバナンスを持つ例示プロセスなどが議論されます。インフラストラクチャをコードとして定義する組織では、人々は日々のルーチン活動やゲートキーパーとしての作業に費やす時間が減り、システム自体の改善能力を向上させるためにより多くの時間を費やすことになるはずです。彼らの努力は、ソフトウェアのデプロイおよび運用パフォーマンスの4つの指標に反映されます。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)Chapter 21: Safely Changing Infrastructure21. Safely Changing Infrastructure本章では、インフラの迅速かつ頻繁な変更の重要性に焦点を当てています。私のSREとしての経験では、速さと安定性は相補的な要素であることが多くのプロジェクトで証明されています。特に、インフラストラクチャー・アズ・コード(IaC)の実践において、このアプローチは効率と品質を大幅に向上させることができます。変更の頻度を上げることで、小さな問題を迅速に検出し、修正することが可能になります。Reduce the Scope of Change小さな変更の範囲を制限することは、リスクの軽減に寄与します。私の経験からも、小さな変更ほど管理が容易であり、予期せぬ問題への対応も迅速になるということが証明されています。このアプローチは、大規模な変更を小分けにして取り組むことで、変更の複雑性とリスクを管理するのに有効です。Figure 21-2. Plan to split out multiple stacksSmall Changes小さな変更を積極的に行うことの利点は、私のプロジェクト経験で明らかです。バッチサイズを小さくすることで、リスクを最小限に抑え、より迅速なフィードバックを得ることが可能になります。これは特に複雑なシステムにおいて、問題の特定と修正を容易にします。小さな変更は、大きなリリースの複雑さを減らし、より継続的なデリバリーを可能にします。Example of Refactoringリファクタリングの例は、コードベースを改善し、将来の変更を容易にするための重要な手段です。実際、私の経験では、リファクタリングはしばしば次のステップへの道を開くための重要なプロセスであり、これによりコードの保守性と拡張性が向上します。リファクタリングは、既存の機能を維持しつつ、コードの構造を改善することで、新しい機能の追加や将来的な変更を容易にします。Pushing Incomplete Changes to Production不完全な変更を本番環境に押し出すことは、段階的なデプロイメントの一環として重要です。この戦略は、変更の影響を小さく保ちながらも、継続的な進化を促進します。特に、リリース前のテスト段階でのフィードバックを得るために役立ちます。Parallel Instances並行インスタンスの概念は、本番環境でのリスクを軽減する上で非常に効果的です。これにより、新しい変更を既存のシステムと並行してテストし、徐々に本番環境に移行することが可能になります。これは、特に大規模なシステムや重要な機能の更新において、ダウンタイムを避けるための重要な戦略です。Backward Compatible Transformations後方互換性を持つ変更は、サービスの中断を防ぎつつ進化を遂げるための鍵です。このアプローチにより、既存の機能を維持しつつ、新しい機能や改善を段階的に導入することができます。これは、システムの安定性を保ちながらも、進歩と成長を促すために非常に効果的です。Feature Toggles機能トグルは、新旧の機能を柔軟に管理できる強力なツールです。これにより、新しい機能を段階的に導入し、必要に応じて迅速に変更を反映することができます。段階的なデプロイメントやA/Bテストにおいてこの技術は特に有効で、リスクを最小限に抑えつつ、ユーザーの反応を評価することができます。Changing Live Infrastructureライブインフラの変更は、サービスの中断を最小限に抑えながらインフラを最新の状態に保つために不可欠です。このセクションでは、インフラストラクチャーの更新がサービスの連続性に与える影響を最小限に抑えるための技術と戦略が紹介されています。Infrastructure Surgeryインフラの手術は、既存のインフラを修正しつつサービスを維持するための洗練された方法です。これにより、サービスの中断を最小限に抑えながら、重要なインフラの変更や改善を行うことができます。このアプローチは、特にデータ損失のリスクを最小限に抑えたい場合や、既存のシステムを段階的に改善したい場合に有効です。Expand and Contract拡張と収縮のパターンは、インフラの柔軟性を最大限に活用する素晴らしい方法です。このアプローチは、リソースの効率的な利用とスケーラビリティの向上に寄与します。特にクラウド環境において、この手法を利用することで、リソースの迅速な拡張と収縮が可能になり、需要の変動に応じたスケーリングが実現できます。Zero Downtime Changesダウンタイムのない変更は、ユーザーエクスペリエンスを維持しつつ、システムのアップデートを行う上で非常に重要です。これにより、サービスの中断を防ぎつつ、新しい機能や修正を順次適用することができます。この手法は、特にユーザーへの影響を最小限に抑えたい場合に有効です。Continuity継続性は、変更管理における中心的な考え方です。エラーを防ぐことによる継続性、速やかな回復による継続性、継続的な災害復旧、カオスエンジニアリング、そして失敗計画は、システムの安定性と耐久性を確保するために重要な要素です。これらのアプローチは、リスクを軽減し、システムの回復力を高めるのに役立ちます。Continuity by Preventing Errorsエラーを予防することによる継続性は、事前の計画と迅速な回復のバランスを取ることが重要です。このアプローチにより、システムの安定性を維持しながら、予期せぬ問題に迅速に対応することが可能になります。エラーの予防と迅速な修正は、特に大規模なシステムにおいて、サービスの連続性と信頼性を確保するために不可欠です。Continuity by Fast Recovery速やかな回復による継続性は、現代のインフラにおいて不可欠な要素です。システムの迅速な回復は、特に予期せぬ障害やエラーが発生した場合に、サービスの中断を最小限に抑えるために重要です。これは、特にビジネスクリティカルなアプリケーションやサービスにおいて、信頼性と利用可能性を確保するための鍵となります。Continuous Disaster Recovery継続的な災害復旧は、システムの耐障害性を高め、ビジネスの継続性を保証するために不可欠です。このアプローチは、システムの変更に関連するリスクを管理し、不測の事態が発生した場合に迅速に対応できるようにすることが重要です。私の経験では、継続的な災害復旧の計画と実施は、組織の全体的なリスク管理戦略の核心部分を形成します。これにより、システムが予期せぬ障害にも迅速に対応し、サービスの継続性を維持できるようになります。システムのバックアップと復旧プロセスを定期的にテストし、改善することで、災害発生時のリカバリー時間を短縮し、ビジネスへの影響を最小限に抑えることが可能です。Chaos Engineeringカオスエンジニアリングは、システムの弱点を明らかにし、それらを改善するための実践的なアプローチです。この手法は、システムの耐障害性を試験し、実際の環境での挙動を理解するのに非常に有効です。私のキャリアの中で、カオスエンジニアリングはシステムの弱点を早期に特定し、それに対処する機会を提供する重要なツールとなっています。意図的に障害を引き起こすことで、システムの回復力をテストし、実際の災害時に備えることができます。このようなプラクティスにより、システムの安定性と信頼性が向上し、ユーザー体験の質が保たれます。Planning for Failure失敗計画は、システムの回復力を高めるために重要です。失敗を計画することは、システムの弱点を特定し、それらに対応するための戦略を立てることを意味します。私が経験したプロジェクトでは、様々な失敗シナリオを想定し、それぞれに対する回復計画を策定することが、システムの全体的な堅牢性を高める上で非常に重要でした。失敗計画は、リスクの評価と緩和策の策定を通じて、システムの安全性と効率性を保証します。また、失敗に迅速かつ効果的に対応するための準備とプロセスを確立することで、ビジネスの中断を最小限に抑えることができます。Data Continuity in a Changing Systemデータの連続性は、変更のあるシステムにおいて最も重要な側面の一つです。私の経験では、データの安全性と一貫性を維持することは、サービスの品質と顧客信頼の基盤となります。Lockロック機能は、特定のリソースを変更から保護する効果的な方法です。しかし、自動化と手動の介入のバランスを見極めることが重要です。過度に手動の介入に依存することはリスクを高める可能性があります。Segregateデータを他のシステムコンポーネントから分離することにより、より柔軟かつ安全に変更を行うことが可能になります。このアプローチは、データを中心としたアーキテクチャ設計において特に有効です。Replicateデータの複製は、可用性と耐障害性の向上に寄与します。分散型データベースのようなシステムでは、データの複製が自動化されることが多く、このプロセスはデータの保護に不可欠です。Reloadデータの再ロードやバックアップは、データ損失を防ぐ上で基本的です。バックアップと復元のプロセスを自動化することで、データの信頼性とアクセス性が大幅に向上します。Mixing Data Continuity Approachesデータの継続性を確保する最善の方法は、分離、複製、再ロードの組み合わせです。この複合的なアプローチにより、データの安全性とアクセス性の両方を最大化できます。データの継続性は、単一の手法に依存するのではなく、複数の手法をバランスよく組み合わせることで、最も効果的に実現されます。この章の締めくくりでは、インフラ変更におけるデータの継続性の重要性が強調されています。クラウド時代におけるインフラ管理の進化に伴い、速度と品質のバランスを取りながらも、データの安全性を維持することの重要性が明確にされています。データはビジネスの中心にあり、その連続性と安全性を確保することが、サービスの品質と顧客信頼を維持するための鍵であることが再確認されます。総括 Infrastructure as Code, 2nd Edition の読書感想文『Infrastructure as Code, 2nd Edition』は、現代のITインフラストラクチャ管理の進化に対応するための重要なガイドです。この書籍は、インフラストラクチャをコードとして扱うことの重要性と、それを実現するための具体的な方法を体系的に説明しています。第一部では、インフラストラクチャをコードとして管理する基本原則に焦点を当て、クラウド時代のダイナミクスを解説しています。特に、変更の速度を利用してリスクを減らし、品質を向上させる新しいマインドセットの必要性が強調されています。第二部では、インフラストラクチャスタックの構築と管理に関して詳述し、スタックの構築、環境の設定、および継続的なテストと提供の重要性について論じています。ここでは、インフラストラクチャの自動化におけるスタックの重要性を明確にし、技術的な洞察と実践的な指針を提供します。第三部は、サーバーと他のアプリケーションランタイムプラットフォームとの作業に注目し、アプリケーションランタイム、サーバーのコード化、サーバーへの変更管理などを取り上げています。この部分は、アプリケーション主導のインフラストラクチャ戦略を通じて、現代の動的インフラを使用してアプリケーションランタイム環境を構築する方法に重点を置いています。第四部では、インフラストラクチャの設計に関して、小さく単純な部品の使用、モジュラリティ、コンポーネント設計のルール、モジュール化、およびスタックコンポーネントの設計パターンとアンチパターンについて論じています。このセクションは、効率的で持続可能なインフラストラクチャを設計するための具体的な方法とベストプラクティスを提供します。第五部では、インフラストラクチャコードの整理、提供、チームワークフロー、およびインフラストラクチャの安全な変更に焦点を当てています。インフラストラクチャコードの整理と管理、デリバリープロセス、プロジェクトの統合、および安全な変更の方法に関する洞察が提供されています。全体として、この書籍は、インフラストラクチャとしてのコードの採用と適用において、技術者や専門家に重要な洞察と価値ある情報を提供し、インフラストラクチャ管理の現代的なアプローチを実現するための実践的なガイドとなっています。その詳細な解説と実用的なアドバイスは、この分野で働く専門家にとって非常に役立つものです。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/16/143554</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/16/143554</guid>
            <pubDate>Thu, 16 Nov 2023 05:35:54 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の続きで第四部のIV. Designing Infrastructure (インフラストラクチャの設計)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com次回の記事* Infrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第四部 目次IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)Designing for Modularityモジュラリティの設計は、システムの変更を安全かつ容易にすることを目的としています。これは、ソフトウェア開発経験においても非常に重要です。モジュール式の設計は変更管理を簡素化し、技術的負債の蓄積を防ぐ効果があります。インフラコードにおいても、このアプローチは同様に有効であり、システムの成長に伴う複雑さとリスクを管理するための鍵となります。コンポーネントをより小さく、単純に保つことで、システム全体の品質と反応性が向上します。Characteristics of Well-Designed Components良く設計されたコンポーネントは、低い結合度と高い凝集度を持ちます。これは、各コンポーネントが独立して機能し、他の部分に影響を及ぼすことなく変更可能であることを意味します。これらの特徴はシステムの長期的な安定性とメンテナンスの容易さに大きく貢献します。低結合度は、一部の変更が全体のシステムに広範な影響を与えるリスクを最小限に抑え、高凝集度は、コンポーネントがその機能に集中し、より効率的に動作することを可能にします。Rules for Designing Componentsコンポーネントの設計におけるルールには、重複の排除や単一責任原則などが含まれます。これらはコードの可読性と保守性を高め、変更を容易にします。重複の排除は、同じ機能やデータの複数のコピーを避けることで、変更時の労力を減らし、エラーの可能性を下げます。一方、単一責任原則は、各コンポーネントが一つの機能または責任を持つべきであるという原則です。これにより、システムはより整理され、理解しやすくなります。Use Testing to Drive Design Decisionsテスト駆動設計は、インフラコードの品質を向上させます。テストは、コードの継続的な改善を促進し、設計の効率化に寄与します。テスト可能なコードは、自然とより良い設計に導かれます。テストを重視することで、コードの変更が容易になり、新しい機能の追加や既存機能の改善がスムーズに行えるようになります。また、自動化されたテストは、システムの信頼性を確保し、デプロイメントプロセスを加速します。Modularizing Infrastructureインフラのモジュラー化は、システムの柔軟性とスケールアップを促進します。構成要素を効果的に分割することで、変更が容易になり、システムの拡張がスムーズに行えます。このアプローチは、インフラストラクチャの管理と運用においても有効であり、特に大規模なシステムでは、異なる部分を個別に更新、拡張、または縮小できる柔軟性が重要です。モジュール化されたインフラストラクチャは、変更のスピードを高め、システムの全体的な効率を改善します。Stack Components Versus Stacks as Componentsスタックコンポーネントとしてのスタックは、独立性を提供し、変更を容易にします。分離されたスタックは変更管理とスケーラビリティにおいて重要な役割を果たします。スタックとしてのコンポーネントは、システムの一部として独立してデプロイおよび管理することができ、これにより大規模な変更や障害が他の部分に波及するリスクを最小限に抑えます。Figure 15-1. Shared code module used by two stacks より引用Using a Server in a Stackスタック内でサーバーを使用することは、設定変更の容易さを提供します。これにより、運用上の柔軟性が高まります。サーバーをスタックの一部として扱うことで、サーバーの設定やソフトウェアの更新が簡単になり、システム全体のメンテナンスが容易になります。また、サーバーの迅速な追加や削除が可能となり、システムのスケーラビリティが向上します。Drawing Boundaries Between Componentsコンポーネント間の境界を適切に設定することは、システムの成長と変更を管理する上で重要です。これはシステムの安定性と拡張性を支えます。境界線を引くことで、システムの異なる部分を明確に区分し、それぞれが独立して機能し、互いに干渉しないようにします。これにより、システムの一部を変更しても、他の部分に予期しない影響を与えるリスクが減少します。Align Boundaries with Natural Change Patterns変更パターンに合わせた境界線は、システムの自然な進化を促進します。これにより、継続的な改善が可能になります。システムの異なる部分がどのように変化し、成長するかを理解することで、それらの部分を適切に区分することができます。これは、変更の管理を容易にし、システム全体の効率を高めます。Align Boundaries with Component Life Cyclesコンポーネントのライフサイクルに合わせた境界線は、管理の簡素化をもたらします。特定のコンポーネントの更新や交換が容易になります。例えば、頻繁に更新が必要なコンポーネントと、長期間安定して運用されるコンポーネントを区別することで、各コンポーネントをより効果的に管理することが可能になります。Align Boundaries with Organizational Structures組織構造に合わせた境界線の設定は、チーム間のコラボレーションを促進し、システムの全体的な一貫性を向上させます。Conwayの法則によれば、システムの設計はしばしばその開発を行う組織の構造を反映します。例えば、開発と運用が別々のチームによって行われる場合、それぞれのチームはシステムの異なる部分を管理することになり、結果としてシステム全体が分断されがちです。これを避けるためには、チームの組織構造をシステムのアーキテクチャに合わせて調整することが有効です。これにより、各チームは自分たちの責任範囲内で効率的に作業を進めることができ、全体としてのシステムの一貫性と効率が向上します。Create Boundaries That Support Resilience回復力を支持する境界線の設定は、システムの耐障害性と回復力を強化します。これは、特定のコンポーネントやサービスが障害に遭遇した場合に、システム全体が影響を受けるリスクを最小限に抑えることを意味します。例えば、システムの一部が故障した場合に、他の部分が正常に機能し続けるように設計することです。これにより、障害発生時にもシステムの主要な機能が維持され、迅速な回復が可能になります。また、このような設計は、障害発生時の影響範囲（ブラストラジアス）を小さくすることも目的としています。Create Boundaries That Support Scalingスケーリングを支持する境界線の設定は、システムの拡張性を高めることを目指します。これにより、需要の増大や減少に応じてシステムのリソースを柔軟に調整することが可能になります。例えば、特定のサービスやコンポーネントの利用が増加した場合に、追加のリソースを割り当てることで対応することができます。また、リソースの利用が減少した場合には、不要なリソースを削減してコストを節約することも可能です。このように、スケーリングを支持する境界線を設定することで、システムは変動する需要に柔軟に対応し、最適なパフォーマンスを維持することができます。Align Boundaries to Security and Governance Concernsセキュリティとガバナンスの懸念に合わせて境界線を設定することは、システムのセキュリティを強化し、規制遵守を容易にします。これは、異なるセキュリティ要件を持つシステムの部分に対して適切な保護措置を施すことを意味します。例えば、金融情報や個人データを扱う部分には、より厳格なセキュリティ対策が必要です。セキュリティとガバナンスに基づいて境界線を設定することにより、これらの要件を満たすための管理が容易になり、システム全体のセキュリティが向上します。この章は、インフラストラクチャをコードとして定義する際の、より小さな部分への分割の重要性を強調しています。分割されたコンポーネントは、変更、スケーリング、回復力の向上に寄与し、システム全体の運用効率を高めます。また、組織構造、セキュリティ、ガバナンスの観点から適切に境界線を設定することで、システムはより安全で管理しやすい状態になります。16. Building Stacks From Components (コンポーネントからスタックを構築する)Infrastructure Languages for Stack Componentsインフラストラクチャ言語の選択は、スタックコンポーネントの設計と実装において非常に重要です。宣言型言語は、その明確な構造と予測可能性により、特に大規模なシステムの設計において有効です。一方、命令型言語は、より動的で柔軟なシステムの構築に適しています。個人的な感覚では宣言型言語はインフラストラクチャの基本的な構造を定義するのに適しており、命令型言語はより複雑なロジックや条件分岐が必要な場面で役立ちます。Reuse Declarative Code with Modules宣言型コードのモジュール化による再利用は、システムの整合性を高め、変更の管理を容易にします。私は、モジュールを利用して共通の機能を効率的に管理し、コードベースの複雑さを減らすことができると感じています。宣言型言語で書かれたモジュールは、その明確さと一貫性により、特に大規模なプロジェクトや多くの開発者が関与する環境において有効です。Dynamically Create Stack Elements with Librariesライブラリを利用した動的なスタック要素の作成は、システムの設計における柔軟性を大幅に向上させます。命令型言語を用いることで、条件に応じたリソースの動的な生成や複雑なロジックの実装が可能になり、システムのカスタマイズが容易になります。これは、特に要件が頻繁に変更されるプロジェクトや、特定の条件に基づいて異なる動作をさせる必要があるシステムにおいて有用です。Patterns for Stack Componentsスタックコンポーネントを設計する際には、適切なパターンの選択が重要です。これにより、システムの一貫性、再利用性、そして将来の拡張性が向上します。良い設計パターンを採用することで、システム全体の品質を高めることができます。Pattern: Facade Moduleファサードモジュールは、複雑なリソースをよりシンプルに扱えるようにすることで、開発者の負担を軽減します。これは、複数のプロジェクトやチーム間で共通のリソースや設定を共有する際に特に有効で、一貫性のあるアプローチを提供します。ファサードモジュールを使用することで、開発者はより高度なタスクに集中でき、基盤となる複雑な詳細について心配する必要がなくなります。Antipattern: Obfuscation Moduleオブフスケーションモジュールは、実際には価値を追加せず、むしろシステムの複雑さを増加させるものです。このようなモジュールは、コードの可読性を低下させ、保守や拡張を困難にします。開発者がモジュールの背後にあるロジックを理解するのが難しくなり、結果として効率性が損なわれます。Antipattern: Unshared Module共有されていないモジュールは、その再利用性が低く、開発プロセスにおける効率性に欠けます。モジュール化の主な目的は、コードの再利用を促進することにありますが、この目的が達成されていない場合、モジュールの価値は大幅に低下します。このようなモジュールは、システム全体の一貫性を損なう可能性があります。Pattern: Bundle Moduleバンドルモジュールは、関連する複数のリソースを単一のインターフェースで管理することを可能にします。これにより、システムの一貫性と管理の容易さが向上します。特に、異なるリソースが密接に連携して動作する必要がある場合に有効で、開発者はより高度なタスクに集中できるようになります。Antipattern: Spaghetti Moduleスパゲッティモジュールは、パラメータに応じて大きく異なる結果を生み出すような複雑な設定が特徴です。これらのモジュールは、多くの動的な部分を含むため、実装が雑然として理解しにくくなりがちです。このようなモジュールはメンテナンスが困難で、変更を加える際には他の部分に予期せぬ影響を与えやすいことが分かっています。重要なのは、モジュールが単一の明確な目的を持ち、必要な機能だけを提供することです。複雑さを避けるためには、モジュールをより小さく、シンプルに保つことが重要です。Pattern: Infrastructure Domain Entityインフラストラクチャのドメインエンティティは、複数の低レベルのリソースを組み合わせて、より高度なスタックコンポーネントを実装するパターンです。このパターンは、特定のアプリケーションやサービスに必要なインフラストラクチャの全体像を捉え、その要件に基づいてリソースを動的に構築します。このアプローチは特に大規模で複雑な環境において効果的で、異なる要件に応じて柔軟にインフラストラクチャを構築できるようにします。しかし、これを実装するには、インフラストラクチャ自体をドメインとして捉え、その上で適切な設計を行う必要があります。Building an Abstraction Layer抽象化レイヤーを構築することで、より低レベルのリソースへの直接的なアクセスを抽象化し、より高レベルのタスクに集中できるようにします。これは、特に複数のチームが関わる大規模なプロジェクトにおいて有用です。抽象化レイヤーを使用することで、開発者はインフラストラクチャの詳細を気にせずに、アプリケーションの開発やビジネスロジックに集中できます。しかし、抽象化には適度なレベルが必要であり、過度な抽象化はシステムの理解を難しくし、問題の診断や解決を複雑化することもあります。第16章では、コンポーネントからスタックを構築する方法とその利点について説明されていますが、同時に、抽象化のレイヤーやコンポーネントのライブラリがもたらす複雑さに注意する必要があるとも指摘しています。システムの規模や複雑さに応じて、これらの構造を適切に使用することが重要です。適切な抽象化レベルの選択は、システムの効率をあげることにつながります。17. Using Stacks As Components (スタックをコンポーネントとして使用する)17. Using Stacks As ComponentsDiscovering Dependencies Across Stacksスタック間の依存関係の発見は、インフラストラクチャの複雑な環境において、異なるスタック間の統合を容易にするために重要です。依存関係を発見する方法を選ぶ際には、システムの拡張性、メンテナンスの容易さ、そして再利用性のバランスを考慮することが必要です。スタック間の依存関係を効果的に管理することは、システム全体の効率を向上させることに繋がります。Pattern: Resource Matchingリソースマッチングパターンは、名前、タグ、または他の識別特性を使用して、必要なリソースを発見する方法です。このパターンは、特に大規模なプロジェクトや、異なるチームや環境間での統合において有効です。実際、私が過去に関わったプロジェクトでは、リソースマッチングを使用することで、複数の環境やチーム間でのリソースの共有が容易になりました。Figure 17-1. Resource matching for discovering dependencies より引用Pattern: Stack Data Lookupスタックデータルックアップパターンは、提供側スタックが管理するデータ構造に基づいて、必要なリソースを見つける方法です。このアプローチは、全てのインフラストラクチャが同じツールを使用して管理されている場合に特に効果的です。スタックデータルックアップは、依存関係を明確にし、統合を容易にするために役立ちます。Pattern: Integration Registry Lookup統合レジストリルックアップパターンは、両方のスタックが一つのレジストリを使用して値を保存し、それを読み取る方法です。これは、異なるツールを使用している複数のチーム間の統合に非常に適しています。私自身も、異なる技術スタックを持つチーム間での統合にこのパターンを利用したことがあり、その柔軟性と効率性に非常に満足しています。Dependency Injection依存性の注入は、スタック定義から依存性の発見を分離することで、スタックの再利用性と柔軟性を向上させるテクニックです。このアプローチにより、異なるプロバイダー実装を容易に切り替えることが可能になり、より包括的に統合されたシステムのテストが容易になります。依存性の注入を使用することで、スタックをよりモジュラー化し、システムの各部分を独立して開発し、テストすることが可能になります。スタックをコンポーネントとして使用することは、システムの変更を容易にし、品質を向上させる効果的な方法です。このアプローチの成功は、スタックを適切に設計し、サイズを適切に保ち、スタック間の緩い結合を維持することに依存しています。スタックをコンポーネントとしてうまく利用することで、システム全体の可用性と拡張性が大幅に向上し、チームの生産性が向上しました。まとめインフラストラクチャをコードとして扱う際のベストプラクティス、効果的な設計パターン、および一般的なアンチパターンに焦点を当てています。この部分は、インフラストラクチャのモジュラリティの重要性を強調し、スタックのデザインパターンとアンチパターンを紹介します。依存関係の管理に関する方法論や依存性の注入の利点も説明されており、全体として、インフラストラクチャを効果的に設計し、管理するための重要な原則と方法論を提供しています。これらのガイドラインは、インフラストラクチャをコードとして扱う際に直面する一般的な課題に対する解決策を提示し、システムの効率性、拡張性、および信頼性を高めるための具体的な指針を提供しています。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/16/124030</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/16/124030</guid>
            <pubDate>Thu, 16 Nov 2023 03:40:30 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の続きで第二部のIII. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)という部の読書感想文になります。前回の記事syu-m-5151.hatenablog.com 次回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第三部 目次III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes(アプリケーションランタイム)アプリケーションランタイムの章では、システムの3層モデルの一部として「インフラストラクチャシステムの部品」でアプリケーションランタイムを導入しています。ここでは、インフラ層からリソースを組み合わせて、アプリケーションをデプロイできるランタイムプラットフォームを提供する方法に焦点を当てています。アプリケーションランタイムは、インフラ管理ツールを使用して定義および作成されたインフラストラクチャスタックで構成されています。これは、どの言語や実行スタックで実行されるか、サーバー、コンテナ、またはFaaSサーバーレスコードにパッケージ化してデプロイされるかなど、それを使用するアプリケーションの理解から始まります。本章は、アプリケーションに対するランタイムプラットフォームとしてのインフラリソースの構成方法に焦点を当て、後の章でこれらのリソースをコードとして定義および管理する方法について詳しく説明しています。Figure 10-1. The application layer composed of infrastructure stacks より引用Cloud Native and Application-Driven Infrastructureクラウドネイティブとアプリケーション主導のインフラに関するこのセクションは、現代インフラのダイナミックな性質を最大限に活用するソフトウェア設計に重点を置いています。Herokuの12ファクターメソドロジーやKubernetesエコシステムとの関連性は、現代のアプリケーション開発の重要性を強調しています。このアプローチは、特に大規模なシステムの再構築や運用において、私の経験と一致しています。クラウドネイティブは、可変性と拡張性を重視したアプローチであり、これが現代のソフトウェア開発の標準となっています。Application Runtime Targetsアプリケーションランタイムターゲットを選定する際には、アプリケーションポートフォリオのランタイム要件を分析し、それに合わせたランタイムソリューションを設計することが重要です。これは、特に異なる技術スタックを持つ複数のプロジェクトを管理する場合に非常に役立ちます。ランタイムターゲットの選択は、アプリケーションのパフォーマンスと効率に大きく影響します。例えば、サーバーレス環境やコンテナベースの環境では、従来のサーバーベースのランタイムとは異なるアプローチが必要です。Deployable Parts of an Applicationアプリケーションのデプロイ可能な部分を理解することは、効率的なアプリケーションデプロイメント戦略を策定する上で重要です。実行可能ファイル、サーバー設定、データ構造などを適切に管理することは、私の経験上、運用の効率化に直結します。デプロイメントの自動化は、特に大規模なアプリケーションにおいて、時間とリソースの節約につながります。Deployment Packagesデプロイメントパッケージのセクションは、異なるランタイム環境に適したパッケージ形式の理解を深めます。これは、適切なツールとプロセスを選択する上でのガイドとなります。デプロイメントパッケージは、アプリケーションの構成とデプロイメントを標準化し、異なる環境間での一貫性を保証します。Deploying Applications to Serversサーバーへのアプリケーションデプロイメントに関しては、物理的または仮想的なサーバーを利用する従来のアプローチに焦点を当てています。これは、インフラの柔軟性とアプリケーションのニーズのバランスをとる上で重要な考慮点です。サーバーベースのデプロイメントは、特にレガシーシステムや特定のセキュリティ要件を持つアプリケーションにおいて、依然として重要な役割を果たします。Packaging Applications in Containersコンテナでのアプリケーションパッケージングについては、依存関係をアプリケーションパッケージに取り込むことの利点と課題を詳述しています。コンテナ化の進展は、アプリケーションのデプロイメントと運用の柔軟性を大きく向上させています。コンテナは、異なる環境間でのアプリケーションの実行を標準化し、デプロイメントプロセスを単純化します。Deploying Applications to Server Clustersサーバークラスターへのアプリケーションデプロイメントは、スケーラビリティと冗長性を確保するための重要な手法です。私の経験でも、効果的なクラスターマネジメントはシステムの可用性を大幅に向上させることができます。サーバークラスターは、負荷分散や障害耐性の向上に寄与します。Deploying Applications to Application Clustersアプリケーションクラスターへのデプロイメントは、ホストサーバー間でのアプリケーションインスタンスの分散に注目しています。これは、特に大規模なアプリケーションにおいて、リソースの効率的な利用とスケーラビリティの向上を実現します。クラスター内の異なるサーバーで異なるアプリケーションを実行することにより、リソースの最適化と柔軟な運用が可能になります。Packages for Deploying Applications to Clustersクラスターへのアプリケーションデプロイメントに必要なパッケージに関するセクションでは、複雑なインフラストラクチャ上で複数のプロセスとコンポーネントをデプロイする方法について説明しています。このアプローチは、現代の大規模アプリケーションの運用に不可欠です。クラスターベースのデプロイメントは、アプリケーションのスケールアップとスケールダウンを効率的に管理するための鍵となります。Deploying FaaS Serverless ApplicationsFaaS（Function as a Service）サーバーレスアプリケーションのデプロイメントは、サーバーやコンテナの詳細を抽象化し、インフラの複雑さから開発者を解放します。これは、迅速な開発とデプロイメントを可能にし、特にイベント駆動型アプリケーションやマイクロサービスアーキテクチャに適しています。サーバーレスは、リソースの使用に基づいた課金モデルを提供し、コスト効率を向上させます。Application Dataアプリケーションデータに関して、特にデータ構造の変更やデータの継続性の確保の重要性に焦点を当てています。これは、データベースの設計と運用における私の経験と一致し、データの変更と管理がシステムの信頼性と拡張性に大きく寄与することを示しています。Data Schemas and Structuresデータスキーマと構造のセクションでは、構造化されたデータストレージと非構造化、またはスキーマレスなデータストレージの違いを説明しています。スキーマ移行ツールの使用は、私の経験では、データベースのバージョン管理と変更の追跡に非常に有効であることが分かりました。Cloud Native Application Storage Infrastructureクラウドネイティブアプリケーションストレージインフラストラクチャは、動的に割り当てられるストレージリソースに重点を置いています。これは、拡張性とリソースの最適化におけるクラウドネイティブのアプローチの利点を反映しています。Application Connectivityアプリケーションの接続性に関するセクションでは、インバウンドとアウトバウンドの接続要件と、これらをインフラストラクチャスタックの一部として定義する方法について説明しています。これは、ネットワーク設計とセキュリティを考慮したアプリケーション開発に不可欠な要素です。Service Discoveryサービスディスカバリーに関しては、動的なインフラストラクチャでのサービスの発見方法として、DNS、リソースタグ、構成レジストリなどを含む様々なメカニズムに焦点を当てています。これは、マイクロサービスアーキテクチャや大規模な分散システムにおいて、サービス間の連携と通信のための重要な概念です。最後に、この章の結論では、インフラストラクチャの目的は有用なアプリケーションとサービスを実行することであると強調しています。アプリケーション主導のインフラストラクチャアプローチは、アプリケーションのランタイム要件に焦点を当て、アプリケーションの実行に必要なスタック、サーバー、クラスターなどの中間層構造を設計するのに役立ちます。「アプリケーション主導のインフラストラクチャ戦略では、現代的な動的インフラを使用してアプリケーションランタイム環境を構築します。(原文: An application-driven infrastructure strategy involves building application runtime environments for applications using modern, dynamic infrastructure.)」は、現代のインフラストラクチャ設計の核心をついており、私自身の経験でも、動的で柔軟なインフラストラクチャの設計と実装が、効率的で拡張性のあるシステムの構築に不可欠であることを強く感じています。アプリケーションのニーズに応じてインフラを適応させることが、現代のソフトウェア開発と運用の鍵となっています。11. Building Servers As Code (サーバーをコードとして構築する)「サーバーをコードとして構築する」章では、サーバーの設定を自動化する方法としてインフラストラクチャとしてのコードが最初に登場したことについて説明しています。システム管理者は、シェル、バッチ、Perlスクリプトを書いてサーバーを設定し、CFEngineはサーバー上のパッケージのインストールと設定ファイルの管理に対して、宣言型で冪等なDSLの使用を先駆けました。そして、PuppetやChefがこれに続きました。これらのツールは、物理サーバーやVMwareを使用した仮想マシン、後にはクラウドインスタンスなど、既存のサーバーから始めることを前提としています。現在では、サーバーがインフラスタックの一部であるか、コンテナクラスターの下層の詳細であるかに焦点を当てています。しかし、サーバーはほとんどのアプリケーションランタイム環境において依然として不可欠な部分です。この章では、サーバーの構成内容（設定する必要があるもの）とサーバーのライフサイクル（設定活動が行われるタイミング）から始まり、サーバー設定コードとツールに関する視点に移ります。この章の中心的な内容は、サーバーインスタンスの作成方法、サーバーを事前に構築して複数の一貫性のあるインスタンスを作成する方法、およびサーバーライフサイクル全体にわたるサーバー設定の適用方法に関する異なる方法を見ています。サーバーのライフサイクルをいくつかの遷移フェーズに分けて考えることが役立つ場合があります。サーバーの基本的なライフサイクルには、サーバーインスタンスの作成と設定、既存のサーバーインスタンスの変更、サーバーインスタンスの破棄という3つの遷移フェーズがあります。Figure 11-1. The basic server life cycle より引用What’s on a Serverサーバーに存在するものを理解することは、システムの安定性と効率を高める上で重要です。サーバー上のソフトウェア、設定、データの区別は、特に自動化されたインフラ管理において、適切なツールの選択と利用に不可欠です。私の経験からも、これらの要素を適切に管理することがシステムの安定稼働に直接影響を与えます。Where Things Come Fromサーバーの要素がどこから来るかを理解することは、サーバー構築と運用の複雑さを浮き彫りにします。OSのインストール、OSパッケージリポジトリ、言語やフレームワークのパッケージなど、多様な要素の組み合わせがサーバーのセットアップにおいて重要です。私の経験では、これらの要素を適切に組み合わせることが、効率的で堅牢なサーバーインフラの構築に不可欠であることが明らかです。Server Configuration Codeサーバー設定コードのセクションは、自動化されたサーバー設定のためのツールとアプローチを詳述しています。Ansible、Chef、Puppetなどのツールは、サーバー設定の自動化において非常に重要な役割を果たし、私の経験からもこれらのツールの有効性を実感しています。Server Configuration Code Modulesサーバー設定コードモジュールについてのこの部分は、コードの組織化とモジュール化の重要性を強調しています。実際のプロジェクトでは、これらの原則がサーバー設定の複雑さを管理するために不可欠です。コードのモジュール化は、メンテナンスの容易さと拡張性を提供します。Designing Server Configuration Code Modulesサーバー設定コードモジュールの設計についてのセクションは、単一の関心事に焦点を当てたモジュールの重要性を説明しています。これは、効率的なインフラストラクチャ管理に必要なベストプラクティスです。私の経験でも、関心の分離を行うことで、より管理しやすく、エラーの少ないインフラを構築できることが実証されています。Versioning and Promoting Server Codeサーバーコードのバージョニングと昇格に関するこの部分は、サーバー設定の変更を管理するための戦略を提供します。コードのバージョン管理は、安定したインフラストラクチャ環境の維持において重要です。バージョン管理を通じて、安定性と再現性を保証することができます。Server Rolesサーバーの役割に関するセクションは、特定の設定モジュール群をサーバーに適用する方法を示しています。これは、サーバー設定の柔軟性と適用性を高めるための有効な手法です。役割に基づくモジュール管理は、特に大規模な環境において、サーバーの設定と運用を簡素化します。Testing Server Codeサーバーコードのテストに関するこの部分は、インフラストラクチャコードのテスト戦略を提供し、品質保証において重要な役割を果たします。私の経験では、テストはインフラストラクチャの信頼性と整合性を保証するための鍵です。Progressively Testing Server Codeサーバーコードの段階的なテストについてのセクションは、テスト戦略を効果的に組み立てる方法を示しています。これは、インフラストラクチャの信頼性を高めるために不可欠です。段階的なテストは、コードの整合性を保ちながら、継続的に品質を向上させることができます。What to Test with Server Codeサーバーコードで何をテストするかについてのこのセクションは、テストの焦点と目的を明確にします。これは、サーバー設定の精度と効率を保証するために重要です。テストを通じて、異なる環境や条件下でのサーバーの挙動を確認し、予期せぬ問題の早期発見と修正を行うことができます。How to Test Server Codeサーバーコードをどのようにテストするかに関するセクションは、効果的なテスト方法とツールを提供します。InspecやServerspecなどのツールは、サーバーの状態を検証し、期待される動作を保証するために役立ちます。実際のテストプロセスは、特定の条件下でサーバーの設定と動作を確認し、必要に応じて調整を行うことを目的としています。Creating a New Server Instance新しいサーバーインスタンスを作成する際には、物理サーバーや仮想マシンの選択、OSのインストール、初期設定の適用が含まれます。これは、効率的で再現性の高いサーバー環境を構築するために重要です。私の経験では、新しいサーバーインスタンスの作成は、システムの拡張性と柔軟性に大きく寄与します。Hand-Building a New Server Instance手作業で新しいサーバーインスタンスを構築する方法は、特に小規模な環境や実験的な目的に適しています。しかし、大規模な運用環境においては、この方法は非効率的でエラーが発生しやすいため、自動化されたプロセスに置き換えることが望ましいです。Using a Script to Create a Serverサーバー作成のためのスクリプト使用に関して、このセクションはサーバー作成プロセスの自動化の重要性を強調しています。コマンドラインツールやAPIを利用するスクリプトを作成することで、サーバーの設定が一貫性を持ち、透明性が向上します。私の経験では、このようなスクリプトを活用することで、サーバーのデプロイメントプロセスの効率化とエラーの削減が可能です。Using a Stack Management Tool to Create a Serverスタック管理ツールを使用したサーバー作成に関するこの部分では、サーバーを他のインフラリソースと一緒に定義する利点を説明しています。Terraformなどのツールを使用することで、サーバーインスタンスの作成や更新が簡素化されます。私の経験上、スタックツールの使用は、インフラリソースの統合と管理を効率的に行うのに役立ちます。Configuring the Platform to Automatically Create Serversプラットフォームを設定して自動的にサーバーを作成するこのセクションは、オートスケーリングやオートリカバリーのような機能を利用する方法を示しています。これは、負荷の増加に応じたサーバーの追加や障害発生時のサーバーインスタンスの交換といった、動的な環境において特に重要です。Using a Networked Provisioning Tool to Build a Serverネットワークプロビジョニングツールを使用してサーバーを構築するこの部分では、ハードウェアサーバーの動的なプロビジョニングプロセスについて説明しています。PXEブートなどの手法を利用して物理サーバーをリモートで起動し、OSインストールや設定を行うプロセスは、特に物理的なインフラを管理する際に有効です。Prebuilding Servers事前にサーバーを構築するこのセクションでは、サーバーの内容を事前に準備する複数の方法を提供しています。これにより、サーバーの構築プロセスを高速化し、複数の一貫性のあるサーバーインスタンスを容易に作成できます。実際に、事前に構築されたサーバーイメージを使用することで、デプロイメントの時間と労力を大幅に削減できることを経験しています。Hot-Cloning a Server実行中のサーバーをホットクローニングするこの部分では、クローニングを行う際の利便性とリスクについて説明しています。特に、本番環境のサーバーをクローニングする際には、意図しない影響を避けるために注意が必要です。Using a Server Snapshotサーバースナップショットの使用に関するこのセクションでは、ライブサーバーからスナップショットを取得し、そのスナップショットを使用して新しいサーバーを作成する方法を提供しています。これは、特に大規模な環境において、サーバーの一貫性を保つための有効な方法です。Creating a Clean Server Imageクリーンなサーバーイメージを作成するこの部分では、複数の一貫性のあるサーバーインスタンスを作成するための基盤となるイメージを作成するプロセスを説明しています。これは、サーバーのデプロイメントを標準化し、品質を保つために非常に重要です。Configuring a New Server Instance新しいサーバーインスタンスの設定に関するこのセクションでは、サーバーの作成とプロビジョニングプロセスの最後の部分である自動化されたサーバー設定コードの適用について説明しています。このプロセスは、新しいサーバーを作成する際の構成を決定する上で重要な要素です。最後に、この章はサーバーの作成とプロビジョニングに関する様々な側面をカバーしています。サーバーに含まれる要素にはソフトウェア、設定、データがあり、これらは通常、サーバーイメージとサーバー設定ツールを使用して追加されるパッケージと設定から構成されます。サーバーを作成するためには、コマンドラインツールを使用するかUIを使用することができますが、コード駆動のプロセスを使用することが好ましいです。今日では、カスタムスクリプトを作成することは少なく、スタック管理ツールを使用することが一般的です。サーバーを構築するためのさまざまなアプローチについて説明していますが、通常、サーバーイメージを構築することをお勧めします。12. Managing Changes To Servers (サーバーへの変更の管理)この章は、サーバーとそのインフラに対する変更を管理するための多様なアプローチとパターンを探求しています。この章を読んで、サーバーの変更管理における自動化の重要性が強く印象に残りました。特に、変更を例外的なイベントではなく、日常的なルーチンとして取り扱うことの重要性が強調されている点に共感しました。私自身の経験からも、一貫性のある自動化された変更プロセスは、システムの安定性と信頼性を大きく向上させると確信しています。また、この章で提案されている様々なパターン、特に「継続的な設定同期」と「不変のサーバー」というパターンは、サーバー運用の効率を高める上で非常に有効です。サーバーの設定を定期的に同期することで、予期せぬ変更や誤差を早期に検出し、対処することが可能になります。また、不変のサーバーの概念は、変更によるリスクを減らす効果的な手法として、私のプロジェクトでも積極的に採用しています。サーバー設定コードをどのように適用するかに関しても、プッシュとプルの2つのパターンを詳しく説明しています。これらのパターンの選択は、サーバーのライフサイクルイベントに合わせて行う必要があり、特定の状況や要件に基づいて適切なアプローチを選択することが重要です。サーバーの他のライフサイクルイベント、例えばサーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などについても、有益な洞察を提供しています。特に、サーバーの回復プロセスは、クラウドインフラストラクチャの信頼性の限界に対処するために不可欠です。総じて、サーバーのライフサイクル管理における現代的なアプローチを包括的に提示しており、サーバーの設定と変更プロセスを最適化するための貴重なリソースとなっています。Change Management Patterns: When to Apply Changesサーバーの変更管理パターンは、変更を適用するタイミングを決定するための重要なガイドラインを提供します。変更が必要となった場合にそれを例外的なイベントとして扱うのではなく、ルーチンとして組み込むことで、システムの一貫性とポリシーへの準拠を確保できます。これは、私が経験したシステムの自動化における重要な一歩です。Antipattern: Apply On Changeこのアンチパターンは、特定の変更を適用するためにのみ設定コードを使用することを示しています。変更を例外として扱うことは、システムの不整合とエラーの原因となることが多いです。これは、私の経験でも、効率的なシステム管理において避けるべき方法です。Pattern: Continuous Configuration Synchronization継続的な設定同期は、変更があるかどうかに関わらず、定期的に設定コードを適用することを意味します。これにより、サーバーの設定の一貫性が保たれ、予期せぬ違いを早期に検出できます。これは、私のSREとしての実践において、サーバー運用の効率を大幅に向上させた方法です。Pattern: Immutable Server不変のサーバーとは、設定が変更されないサーバーインスタンスを意味します。変更を配信するために、変更された設定で新しいサーバーインスタンスを作成し、既存のサーバーを置き換えます。これは、特に安定性と整合性が重要な環境で有効な手法です。How to Apply Server Configuration Codeサーバー設定コードの適用方法に関するこのセクションは、サーバーに変更を適用するためのパターンを検討します。サーバーの新規構築、既存インスタンスの更新、サーバーイメージの構築において、これらのパターンは不可欠です。Pattern: Push Server Configurationプッシュサーバー設定パターンでは、新しいサーバーインスタンスの外部からサーバーに接続してコードを実行し、適用します。これは、サーバーインスタンスへのタイムリーな設定更新が必要な場合に特に有効です。Pattern: Pull Server Configurationプルサーバー設定パターンでは、サーバーインスタンス自体で実行されるプロセスが設定コードをダウンロードして適用します。これは、サーバーインスタンスが入ってくる接続を受け入れる必要がないため、攻撃面を減らすのに役立ちます。Other Server Life Cycle Eventsサーバーの他のライフサイクルイベントに関するこのセクションでは、サーバーインスタンスの停止、再起動、置換、失敗したサーバーの回復などを検討します。これらは、サーバーの管理と運用において、特に重要なフェーズです。Stopping and Restarting a Server Instanceサーバーインスタンスの停止と再起動に関するこのセクションは、特定の目的のためにサーバーを一時的に停止または再起動する方法を示しています。これは、コスト削減やメンテナンスのために、しばしば実践されます。Figure 12-1. Server life cycle—stopping and restarting より引用Replacing a Server Instanceサーバーインスタンスの置換に関するこの部分は、新しいサーバーインスタンスを作成し、古いインスタンスと交換するプロセスを説明しています。これは、特に自動スケーリングや自動回復を利用する環境で役立つアプローチです。Recovering a Failed Server失敗したサーバーの回復についてのこのセクションでは、サーバーインスタンスが失敗した場合の回復プロセスについて説明しています。これは、クラウドインフラストラクチャの信頼性が常に保証されるわけではないため、特に重要です。この章は、サーバーのライフサイクルにおける核心的なイベントを網羅しています。サーバーの作成と変更に関するアプローチの多くは、サーバーイメージをカスタマイズし、それを使用して複数のサーバーインスタンスを作成または更新することに依存しています。13. Server Images As Code (サーバーイメージをコードとして扱う)サーバーイメージの自動化された構築と維持に関する包括的なガイドを提供しています。この章を読む中で、サーバーイメージの構築と管理を自動化することの重要性が強調されてました。特に、サーバーイメージのライフサイクルを通じて、一貫性と品質の確保に焦点を当てることが重要であると感じました。サーバーイメージの構築プロセスは、オンラインとオフラインの二つのアプローチが存在し、各々の利点と制約について詳しく解説されています。私の経験上、オフラインのイメージ構築は迅速で、特定のシナリオでは非常に有効ですが、より複雑な設定を必要とすることがあります。また、サーバーイメージの異なる起源、例えばベンダー提供のストックイメージやゼロからの構築、そしてそのコンテンツの出所に関する議論は、セキュリティとパフォーマンスのバランスを取る上で非常に有益です。セキュリティに関する考慮事項は、特に重要であり、サーバーイメージの構築プロセスにおいて常に優先されるべきです。サーバーイメージのバージョニングと更新の管理は、章の中でも特に興味深い部分でした。これにより、サーバーイメージが最新のセキュリティパッチや設定で常に最新の状態を保つための効率的な方法が提供されます。私の経験では、サーバーイメージの定期的な更新は、インフラの安定性と運用の効率を大幅に向上させることができます。さらに、サーバーイメージをパイプラインを通じてテストおよび配信することに関するセクションは、インフラストラクチャの自動化とCI/CDの実践において非常に重要な概念を提供します。パイプラインを使用することで、サーバーイメージの構築、テスト、配布が容易かつ効率的になります。この章全体を通して、サーバーイメージを効率的に管理し、継続的に改善するための強固な基盤が提示されています。これは、現代のインフラストラクチャ管理において不可欠なリソースであり、その実践は技術的な洞察とともに、ビジネスの効率性とセキュリティを高める重要な手段となります。Figure 13-1. Server image life cycle より引用Building a Server Imageサーバーイメージの構築に関するセクションでは、カスタムサーバーイメージの作成プロセスの重要性とその利点について深く掘り下げられています。このプロセスを通じて、組織固有の要件やセキュリティ基準に合致したイメージを作成することの価値が明らかにされました。このセクションは、自動化されたイメージ作成のアプローチが、サーバーのデプロイメントをより迅速かつ安全にする方法を示しています。実際に、カスタマイズされたイメージを使用することで、セキュリティやパフォーマンスの最適化が可能になると私は経験しています。Why Build a Server Image?サーバーイメージを構築する理由についてのセクションは、特に啓発的でした。組織のガバナンス、セキュリティの強化、パフォーマンスの最適化など、カスタムイメージを構築するための具体的な理由が挙げられています。これらの要因は、私が直面する日常の課題と密接に関連しており、カスタムサーバーイメージを活用することの価値を再確認させてくれました。How to Build a Server Imageサーバーイメージの構築方法に関する部分は、理論的かつ実践的なアプローチを提供しており、非常に役立ちました。オンラインとオフラインの両方のイメージ構築方法が詳細に説明されており、これは技術的な選択肢を検討する際に重要なガイドラインとなります。Tools for Building Server Imagesこのセクションでは、サーバーイメージを構築するためのツールとサービスが詳述されています。Packerのようなツールの利用が、イメージ構築プロセスを効率化する上でいかに重要かが強調されているのを見て、私の現在のワークフローに対する洞察を得ることができました。Online Image Building Processオンラインでのイメージ構築プロセスについてのセクションは、イメージを作成する実際の手順を明確に説明しています。このプロセスに関する詳細な説明は、実務での応用を容易にし、サーバーイメージの構築方法の理解を深めました。Offline Image Building Processオフラインイメージ構築プロセスに関する説明は、オンラインプロセスとの比較を通じて、異なるアプローチの利点と制約を理解するのに役立ちました。オフラインでのイメージ構築方法は、特定の状況下での効率性を考慮する上で重要です。Origin Content for a Server Imageサーバーイメージの起源コンテンツに関するセクションは、イメージ構築の基礎となる要素についての理解を深めるのに役立ちました。ストックイメージからの構築、スクラッチからの構築、そしてサーバーイメージとそのコンテンツの由来に関する議論は、イメージ構築プロセスの基礎を形成します。Building from a Stock Server Imageストックサーバーイメージからの構築に関するセクションは、既存のイメージをカスタマイズする方法とその利点を解説しています。このアプローチは、特にセキュリティやパフォーマンスの最適化を目指す際に重要です。Building a Server Image from Scratchゼロからサーバーイメージを構築するプロセスに関する詳細は、完全にカスタマイズされたイメージを作成するための重要なガイドラインを提供しています。これは、特定の高度な要件を持つ組織にとって特に有益です。Provenance of a Server Image and its Contentサーバーイメージとそのコンテンツの出所に関するセクションは、セキュリティと信頼性の側面を考慮する上で特に重要です。サードパーティからのコンテンツを使用する際の潜在的なリスクを理解し、適切なチェックを実施することが強調されています。Changing a Server Imageサーバーイメージの変更に関するセクションは、イメージの維持と更新のプロセスに光を当てています。定期的なリフレッシュとバージョニングの重要性に関する洞察は、効率的で安全なインフラストラクチャ管理のために不可欠です。Reheating or Baking a Fresh Imageイメージの再加熱または新たなイメージの焼き直しに関するセクションは、サーバーイメージの更新方法に関する具体的な選択肢を提示しています。どちらのアプローチもそれぞれのメリットがあり、状況に応じて適切な方法を選択することが重要です。Versioning a Server Imageサーバーイメージのバージョニングに関する議論は、イメージの追跡と管理の重要性を強調しています。バージョニングは、イメージの透明性と一貫性を保つ上で不可欠な要素です。Updating Server Instances When an Image Changesイメージが変更された場合のサーバーインスタンスの更新についてのセクションは、イメージを基に作成されたインスタンスの一貫Updating Server Instances When an Image Changes「イメージが変更されたときのサーバーインスタンスの更新」に関するセクションは、サーバーイメージの更新とサーバーインスタンスの同期に関する洞察を提供しました。この部分では、新しいサーバーイメージを作成した後のサーバーインスタンスの管理方法について考察しています。サーバーインスタンスを即座に更新するか、自然に時間が経過するまで待つかという選択は、システムの整合性と運用の効率の両方に影響を及ぼします。私の経験では、定期的なサーバーインスタンスの更新は、セキュリティとパフォーマンスの観点から重要です。また、適切なバージョン管理と更新ポリシーは、サーバー環境の一貫性を保ち、予期せぬ問題を回避するために不可欠です。Providing and Using a Server Image Across Teams「チーム間でのサーバーイメージの提供と使用」は、サーバーイメージを異なるチーム間で共有する際のベストプラクティスに焦点を当てています。このセクションは、サーバーイメージを中央チームが作成し、他のチームが使用する場合のダイナミクスを明確に説明しています。イメージのバージョン管理と共有に関する洞察は、大規模な組織における効果的なインフラ管理に特に関連しています。私が以前関わったプロジェクトでは、チーム間でサーバーイメージを共有することで、作業の重複を防ぎ、一貫性を保つことができました。Handling Major Changes to an Image「イメージの大きな変更を扱う」セクションは、サーバーイメージに対する大規模な変更を適切に管理する方法に関する重要な洞察を提供しています。このセクションでは、大きな変更をセマンティックバージョニングを使用して管理することの重要性が強調されています。私の経験では、サーバーイメージに大きな変更を加える際には、特に慎重なテストと段階的な導入が重要です。これにより、変更による影響を最小限に抑え、システムの安定性を保つことができます。Using a Pipeline to Test and Deliver a Server Image「サーバーイメージをテストおよび配信するためのパイプラインの使用」セクションは、サーバーイメージのライフサイクルを自動化し、品質を確保するための強力なアプローチを提供しています。パイプラインを通じてサーバーイメージを構築、テスト、配信することは、継続的な改善と効率化のための鍵です。私の経験では、CI/CDパイプラインを使用することで、サーバーイメージの作成と更新が格段に効率的になり、システムの全体的な信頼性が向上します。Using Multiple Server Images「複数のサーバーイメージの使用」セクションは、異なる環境や用途に合わせて複数のサーバーイメージを維持する必要性を説明しています。異なるプラットフォーム、オペレーティングシステム、ハードウェアアーキテクチャに対応するためのサーバーイメージの管理は、特に複雑なインフラストラクチャを持つ組織において重要です。私の経験では、特定の役割や要件に合わせてサーバーイメージを最適化することで、運用の効率を大幅に向上させることが可能です。サーバーイメージの管理に関するこの章の総括として、サーバーイメージをコードとして扱うことの利点が明確に示されています。自動化されたプロセスを通じてサーバーイメージを維持し、定期的に更新することで、インフラストラクチャの効率性とセキュリティが大きく向上することが示されています。14. Building Clusters As Code (クラスターをコードとして構築する)この章は、クラスターをコードとして構築する方法について詳しく解説しています。ソフトウェアエンジニアリングの経験から、このアプローチの強みは、システムの柔軟性と再現性にあります。KubernetesやAWS ECSなどの例が挙げられ、クラスター管理の複雑さを隠蔽しながらも、コードを介して制御可能であることが強調されています。Figure 14-1. An application cluster creates a layer between infrastructure resources and the applications running on them より引用Application Cluster Solutionsアプリケーションクラスターのソリューションに関しては、クラウドベースのサービスとオンプレミスのソリューション間の選択肢を詳細に検討しています。私の経験では、クラウドサービスは迅速な展開と低い初期コストを提供しますが、長期的にはカスタマイズの柔軟性とコントロールの観点で限界があります。一方で、オンプレミスソリューションは初期設定が複雑であり、維持管理のコストが高くなる可能性がありますが、長期的にはより制御可能で安定しています。Cluster as a Serviceクラウドプラットフォームが提供するCluster as a Service は、設定や管理の簡素化を可能にします。しかし、クラウド固有のサービスに依存することのリスクも伴います。この点は、多くのプロジェクトで検討すべき重要なトレードオフです。Packaged Cluster Distributionパッケージ化されたクラスター配布は、よりカスタマイズ可能で、組織固有のニーズに合わせた設定が可能です。Kubernetesのようなオープンソースソリューションの利用は、柔軟性をもたらしますが、メンテナンスとサポートにおいて自組織のリソースを要求します。Stack Topologies for Application Clustersアプリケーションクラスターのスタックトポロジーについては、モノリシックなスタックと分散型スタックの両方が詳述されています。私の観点からは、モノリシックなアプローチは小規模なプロジェクトや初期段階でのプロトタイピングに適しています。しかし、規模が大きくなると、スタックを分割し、各機能を別々に管理することで、より効率的な運用と拡張性が得られます。特に大規模なシステムでは、分散型のアプローチがシステムの複雑さを管理しやすくします。Monolithic Stack Using Cluster as a Serviceモノリシック・スタックを使用する場合、初期段階では管理が簡単ですが、規模が大きくなるにつれて、複雑さとリスクが増大します。このアンチパターンは、特に大規模なシステムでの問題につながり得ます。Monolithic Stack for a Packaged Cluster Solutionパッケージ化されたクラスター・ソリューションにおけるモノリシック・スタックは、より管理が複雑ですが、カスタマイズの自由度が高いです。インフラのスタックとアプリケーションのクラスターが別々に管理される点は、運用において重要な考慮事項です。Pipeline for a Monolithic Application Cluster Stackモノリシック・アプリケーション・クラスター・スタックのパイプラインは、インフラとアプリケーションの両方に影響を及ぼします。この一元管理は、変更の際に大きな影響を及ぼす可能性があります。Example of Multiple Stacks for a Clusterクラスターのための複数スタックの例は、変更の影響を局所化し、リスクを分散させるのに役立ちます。スタックを分割することで、より効率的かつ安全に変更を行うことができます。Sharing Strategies for Application Clustersアプリケーションクラスターの共有戦略に関するセクションは、特に多様な環境やニーズを持つ組織にとって重要です。一つの大きなクラスターをすべての用途に使用するのではなく、目的やチームごとにクラスターを分割することで、セキュリティ、パフォーマンス、および管理の観点から優れた結果を得ることができます。私の経験上、チームやプロジェクトごとに専用のクラスターを用意することは、リソースの効率的な利用とセキュリティリスクの軽減に繋がります。また、ガバナンスやコンプライアンスの要件に基づいてクラスターを分割することは、特に規制の厳しい業界での運用において重要です。One Big Cluster for Everything全てを一つの大きなクラスターで管理するアプローチは、シンプルさと効率の面で魅力的ですが、変更管理の複雑さやリスクの集中が懸念されます。Separate Clusters for Delivery Stages異なるデリバリー段階ごとに別々のクラスターを用意する戦略は、リスクの分散と環境間の独立性を提供します。これにより、特定の環境に特化した最適化が可能になります。Clusters for Governanceガバナンスのためのクラスターは、特定のコンプライアンス要件を持つアプリケーションに対して、より厳格な環境を提供することができます。これにより、セキュリティとパフォーマンスの向上が期待できます。Clusters for Teamsチームごとのクラスターは、チームの特定のニーズに合わせたカスタマイズを可能にします。これは、チームの生産性を向上させると同時に、システムの全体的な効率を高めることができます。Service Meshサービスメッシュは、アプリケーション間の通信を効率化し、複雑な分散システムにおける管理を容易にします。これにより、開発者はアプリケーションのロジックに集中でき、インフラストラクチャの詳細から解放されます。Infrastructure for FaaS ServerlessFaaS Serverlessのインフラストラクチャは、従来のアプリケーション・ホスティングとは異なり、イベント駆動のコード実行をサポートします。これにより、負荷が不規則なワークロードに対して、高い効率性とスケーラビリティが得られます。この章の総括として、クラスターをコードとして構築するアプローチは、アプリケーションをサポートするためのインフラストラクチャを効率的に管理するための強力な方法です。個々の技術や戦略の選択は、組織の特定のニーズに基づいて行われるべきです。まとめサーバーとその他のアプリケーションランタイムプラットフォームの扱いに焦点を当てています。このセクションは、現代のインフラストラクチャ管理における重要なトピックを深く掘り下げており、Infrastructure as Code (IaC) の実践において不可欠な洞察を提供しています。特に、アプリケーションクラスターの構築、スタックトポロジーの設計、そしてクラスター共有戦略の選択に関する章は、システムのスケーラビリティと耐障害性を高める方法論を提示しています。これらの章では、クラウドサービスとオンプレミスソリューションの利点と欠点が比較され、プロジェクトの要件に応じた適切な選択を行うための洞察が提供されています。本書は、インフラストラクチャをコードとして扱うことの重要性を強調し、変更管理、セキュリティ、およびコンプライアンスを効率的に運用するための具体的な手法を提供しています。また、サービスメッシュやサーバーレスアーキテクチャなどの先進的なトピックにも言及し、読者がこれらの技術を理解し、適切に活用するためのガイダンスを提供しています。全体を通して、この部分は、インフラストラクチャの自動化とオーケストレーションに関する実用的なアプローチを強調しており、読者がより堅牢で効率的なシステムを構築するための知識を深めるのに役立ちます。結果として、サーバーとアプリケーションランタイムプラットフォームの管理において、より戦略的で洗練されたアプローチを採用するための基盤を築くことができます。Infrastructure as Code, 2nd Editionの読書感想文Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition の III. Working With Servers And Other Application Runtime Platforms 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のIV. Designing Infrastructure 読書感想文 - じゃあ、おうちで学べるInfrastructure as Code, 2nd Edition のV. Delivering Infrastructure 読書感想文 - じゃあ、おうちで学べる]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ツールごとのOPA/Regoの書き方]]></title>
            <link>https://zenn.dev/tayusa/articles/63f286f4733a87</link>
            <guid>https://zenn.dev/tayusa/articles/63f286f4733a87</guid>
            <pubDate>Thu, 16 Nov 2023 03:05:53 GMT</pubDate>
            <content:encoded><![CDATA[RegoとはKubernetesやTerraformの静的解析で既存のルールでは足りないときや自分でカスタマイズしたいときにRegoというポリシー言語でコードを書くhttps://www.openpolicyagent.org/docs/latest/policy-language/ Regoを利用できるツールの例conftesthttps://www.conftest.dev/自分で全部書くtrivyhttps://aquasecurity.github.io/trivy/latest/docs/scanner/misconfiguration/cust...]]></content:encoded>
        </item>
    </channel>
</rss>