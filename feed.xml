<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 14 Nov 2023 18:30:14 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Terraformの条件分岐にうってつけの日]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603</guid>
            <pubDate>Tue, 14 Nov 2023 06:46:03 GMT</pubDate>
            <content:encoded><![CDATA[Infrastructure as Codeの概念とTerraformの役割Infrastructure as Code (IaC) は、現代のインフラ管理の根幹を成すものです。IaCがどんなものか様々な言論があると思いますが、ここではソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとIaC 本に準拠しておきます。IaCによる自動化、バージョン管理、テスト、そして継続的インテグレーションなどのプラクティスは、システム管理の世界に革命をもたらしました。ちなみに個人的には各々のプラクティスを一つずつ実践しない度にIaCの価値は一つずつ確実に下がっていくものだと確信してます。ですが、各々にコストがかかるものなので各プラクティスをどこまで実践するかは非常に難しい問題だとも同時に思います。その中で周知の事実だとは思いますがTerraformは、これらのプラクティスをダイナミックなインフラストラクチャの管理、定義、および構成に応用することで、効率性と柔軟性の高いインフラストラクチャ管理を可能にします。このツールは、設計から実装までの過程を劇的に変える可能性を秘めています。Infrastructure as Codeの概念とTerraformの役割に関する参考リンクInfrastructure as Code - AWSInfrastructure as Code - Google CloudIntroduction to Terraform - HashiCorpInfrastructure as Codeの原則とTerraformInfrastructure as Codeの原則には、以下のような要素が含まれます​​:簡単に再現できるシステム: Terraformを使用することで、インフラストラクチャをコードとして定義し、簡単に再現可能なシステムを構築できます。使い捨てにできるシステム: サーバーなどのリソースを一時的なものとして扱い、必要に応じて簡単に生成・破棄できます。統一的なシステム: 全てのインフラストラクチャのコンポーネントを統一的な方法で管理します。反復できるプロセス: 同じ設定を繰り返し適用することで、一貫性と信頼性を保ちます。これらの原則に基づいて、Terraformは以下のような機能を提供します:リソースの自動生成と管理: Terraformを使用すると、インフラストラクチャのリソースを自動的に生成・管理できます。バージョン管理のサポート: Terraformの設定ファイルはバージョン管理システムで管理でき、変更履歴を追跡できます。モジュールと再利用可能なコンポーネント: Terraformではモジュールを使って、コードの再利用性を高めます。なのでそれ以外のプラクティスに関しては別のソリューションで実現してあげる必要があります。Terraformの条件分岐のテクニックと利用場面もう少し能書きを垂れるかなって思ったんですけどもう飽きたので普通にテクニックや使い方の話をしていきますループ (countとfor_each)ループは、同じタイプのリソースを複数回作成する際に便利です。countやfor_eachを使用して、コードの重複を避けながら、効率的にリソースを管理できます。利用場面A: 異なる環境に同一種類のリソースを複数作成resource "aws_instance" "dev_servers" {  count         = 5  instance_type = "t2.micro"  # その他の設定}利用場面B: 複数のユーザーにIAMロールを割り当てresource "aws_iam_user" "users" {  for_each = toset(["alice", "bob", "charlie"])  name     = each.value  # その他の設定}条件分岐 (countを使用)条件分岐を使用すると、環境やパラメータに基づいてリソースの作成を制御できます。これにより、開発環境と本番環境などで異なるリソース設定を実現できます。利用場面A: 本番環境でのみデータベースのインスタンスを作成resource "aws_db_instance" "prod_db" {  count = var.is_production ? 1 : 0  # データベースの設定}利用場面B: 開発環境ではリソースを作成せず、本番環境でのみ特定のリソース（例: S3バケット）を作成したい場合。resource "aws_s3_bucket" "prod_bucket" {  count  = var.env == "prod" ? 1 : 0  bucket = "my-production-bucket"  acl    = "private"}ここではvar.env変数がprod（本番環境）の場合にのみS3バケットを作成します利用場面C: 特定の機能フラグ（例: 監視機能の有効化）がオンの場合にのみ、関連リソース（例: CloudWatchアラーム）をデプロイしたい。resource "aws_cloudwatch_metric_alarm" "example_alarm" {  count               = var.enable_monitoring ? 1 : 0  alarm_name          = "High-CPU-Utilization"  comparison_operator = "GreaterThanThreshold"  evaluation_periods  = "2"  threshold           = "80"  # その他の設定}この例では、var.enable_monitoringがtrueの場合にのみCloudWatchアラームを作成します。ゼロダウンタイムデプロイメント (create_before_destroyを使用)ゼロダウンタイムデプロイメントは、システムやアプリケーションの更新時にサービスを停止することなく、新しいバージョンへの移行を行う手法です。Terraformにおけるゼロダウンタイムデプロイメントでは、create_before_destroyライフサイクル設定を使用して、新しいリソースを古いリソースを削除する前に作成します。これにより、サービスが継続的に稼働しつつ、背後で安全にリソースの更新や交換が行われます。利用場面A: アプリケーションの更新時に新旧インスタンスの平滑な切り替えresource "aws_instance" "app_server" {  ami           = "ami-newversion"  instance_type = "t2.micro"  lifecycle {    create_before_destroy = true  }  # その他の設定}このコードは、新しいAMIでEC2インスタンスを作成します。create_before_destroyがtrueに設定されているため、新しいインスタンスが完全に起動し、運用準備が整うまで旧インスタンスは削除されません。これにより、アプリケーションの更新中もサービスが継続して提供されます。利用場面B: インフラのリファクタリング時に既存リソースの無停止更新resource "aws_s3_bucket" "storage" {  bucket = "my-new-bucket-name"  lifecycle {    create_before_destroy = true  }  # その他の設定}この設定では、新しいS3バケットが作成される際、既存のバケットは新しいバケットの設定が完了し、利用可能になるまで保持されます。これにより、データの移行やバケットの設定変更が行われる際にも、サービスの中断を回避できます。結論とかこれらの使い方はもちろんのこと原則を理解しながら活用することで、インフラストラクチャの管理において幸せな世界観を目指していきましょう。『Terraform: Up & Running』の日本語版第3版のリリースを心から祝福します。この本は、Terraformの基本から応用までを幅広くカバーし、多くの開発者やシステム管理者にとってよても良い本となることでしょう。手元においておいて本当に損がない書籍可と思います。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy BrikmanオライリージャパンAmazon参考資料Count: Repeating ResourcesFor Each: Repeating a Module Multiple TimesConditional ExpressionsResource Lifecycle: create_before_destroyTerraform by HashiCorpIntroduction to TerraformZero Downtime Updates with TerraformTerraformチュートリアル - HashiCorp LearnTerraform Best Practices余談Ansible やDockerではどのようにループや条件分岐を実現しているかAnsibleでは組み込まれている機能で実現できますがDockerでは、ループや条件分岐は通常、Dockerfile内では直接実現できません。しかし、Docker Composeやスクリプトを使用して間接的にこれらを処理することができます。Kubernetesでも、ループや条件分岐はマニフェストファイル（YAML）内で直接的にはサポートされていませんが、Helmチャートのようなテンプレートエンジンを使用することで、これらの動作を実現できます。Helmは条件分岐や変数の代入などを可能にするテンプレート機能を提供しているのでそれぞれ紹介します。ループloopキーワードを使用して繰り返しタスクを実行します。- name: パッケージのインストール  yum:    name: "{{ item }}"    state: present  loop:    - httpd    - memcachedAnsible Loopsこの例では、.Values.services内の各サービスに対してループを行い、それぞれのnameとportを出力しています。{{- range .Values.services }}- name: {{ .name }}  port: {{ .port }}{{- end }}HelmチャートのテンプレートDocker Composeでのループと条件分岐Docker Composeでは直接的なループや条件分岐のサポートはありませんが、環境変数を利用して擬似的にこれらを実現できます。services:  web:    image: "webapp:${WEBAPP_TAG}"    environment:      - DEBUG=${DEBUG_MODE}この例では、WEBAPP_TAGとDEBUG_MODE環境変数を使用しています。条件分岐ステートメントを使用して、特定の条件に基づいてタスクを実行します。- name: 開発環境でのみ実行するタスク  command: echo "これは開発環境用のタスクです"  when: env == 'development'- name: 本番環境でのみ実行するタスク  command: echo "これは本番環境用のタスクです"  when: env == 'production'Ansible Conditionals{{- if .Values.debug }}environment: "development"{{- else }}environment: "production"{{- end }}ここでは、.Values.debugの値に基づいて環境を設定しています。debugがtrueならdevelopment、そうでなければproductionが選択されます。Helmのテンプレート関数この節では、Ansible、Docker、そしてKubernetesにおけるループと条件分岐の実装方法を比較しました。これらのツールはそれぞれに独自のアプローチを持っており、その違いを理解することで、適切なツール選択や実装戦略を行う上での参考になります。また、異なるツールでどのように同じ問題を解決しているかを知ることは、より深い技術的理解や柔軟な対応能力を身につけるために重要です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、生成AIを活用したSRE業務自動化への取り組みを発表]]></title>
            <link>https://sreake.com/blog/generative-ai-sre/</link>
            <guid>https://sreake.com/blog/generative-ai-sre/</guid>
            <pubDate>Tue, 14 Nov 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイクが提供するSRE総合支援サービス「Sreake（スリーク）」は、「 Google Cloud 生成 AI パートナー エコシステム 」を活用して、SREの業務を自動化・効率化し、これまでの人的リソースへの依存度を軽減する取り組みを開始することをお知らせいたします。The post スリーシェイク、生成AIを活用したSRE業務自動化への取り組みを発表 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MinIO Client で Amazon S3 や Cloudflare R2 を利用する]]></title>
            <link>https://blog.1q77.com/2023/11/minio-client/</link>
            <guid>https://blog.1q77.com/2023/11/minio-client/</guid>
            <pubDate>Sun, 12 Nov 2023 11:13:31 GMT</pubDate>
            <content:encoded><![CDATA[Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなという]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Golangで行うポートスキャナ自作ではじめるペネトレーションテスト]]></title>
            <link>https://zenn.dev/satoken/articles/golang-port-scanner</link>
            <guid>https://zenn.dev/satoken/articles/golang-port-scanner</guid>
            <pubDate>Fri, 03 Nov 2023 03:30:25 GMT</pubDate>
            <content:encoded><![CDATA[はじめにオライリーでポートスキャナ自作ではじめるペネトレーションテストという本が発売されました。2章ではScapyを利用して実際にパケットを作成して、nmapのようなポートスキャナ自作します。パケットのカプセル化などNWの仕組みから丁寧に解説されていてとても良書だと思います。ただ筆者はPythonよりGolang派なので2章のプログラムをGolangに書き換えてみました。https://github.com/sat0ken/go-port-scanner※オリジナルはこちらhttps://github.com/oreilly-japan/pentest-starting...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazon ECSイベントをCloudWatch Logsへ収集する]]></title>
            <link>https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2</link>
            <guid>https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2</guid>
            <pubDate>Thu, 02 Nov 2023 08:33:22 GMT</pubDate>
            <content:encoded><![CDATA[きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみると、ECSはいくつかの種類のイベントをEventBridgeに送信しており、これをルールで拾って...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Time-Slicing GPUs を Kubernetes で利用する]]></title>
            <link>https://sreake.com/blog/kubernetes-time-slicing-gpu/</link>
            <guid>https://sreake.com/blog/kubernetes-time-slicing-gpu/</guid>
            <pubDate>Tue, 31 Oct 2023 08:39:06 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Kubernetes にて、1つのGPUを複数コンテナ (※ Pod内の複数コンテナ、複数のPodを指す) で使い倒したい。そんな時はありますでしょうか。本記事では、NVIDIA/k8s-device-plug […]The post Time-Slicing GPUs を Kubernetes で利用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ShellCheckで自動化の品質を向上させる]]></title>
            <link>https://sreake.com/blog/shellcheck-automation-enhancement/</link>
            <guid>https://sreake.com/blog/shellcheck-automation-enhancement/</guid>
            <pubDate>Tue, 31 Oct 2023 02:32:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Site Reliability Engineering (SRE) の領域では、トイル (toil) の削減と効率的なオペレーションが大きな課題となっています。トイルというのは、手作業で繰り返し行う作業のこと […]The post ShellCheckで自動化の品質を向上させる first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day9]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability</guid>
            <pubDate>Sat, 21 Oct 2023 15:12:37 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Application Integrationについて]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7</guid>
            <pubDate>Wed, 18 Oct 2023 09:20:05 GMT</pubDate>
            <content:encoded><![CDATA[whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Asset Inventoryとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79</guid>
            <pubDate>Fri, 13 Oct 2023 10:27:12 GMT</pubDate>
            <content:encoded><![CDATA[whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Searchによる社内knowlegeの要約ツールをつくってみた]]></title>
            <link>https://sreake.com/blog/vertex-ai-search-summary-tool/</link>
            <guid>https://sreake.com/blog/vertex-ai-search-summary-tool/</guid>
            <pubDate>Thu, 12 Oct 2023 03:46:53 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、初めましての方もそうでない方も、Sreake事業部 佐藤慧太(@SatohJohn)です。 今回Google CloudのVertex AI Search(旧Enterprise Search)について検証の […]The post Vertex AI Searchによる社内knowlegeの要約ツールをつくってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 インシデント管理・運用プラットフォーム「PagerDuty」の導入支援サービスを正式リリース]]></title>
            <link>https://sreake.com/blog/pagerduty-package/</link>
            <guid>https://sreake.com/blog/pagerduty-package/</guid>
            <pubDate>Tue, 10 Oct 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイクが提供するSRE総合支援サービス「Sreake（スリーク）」は、新たに 、システムのインシデント対応を一元化するプラットフォーム「PagerDuty」の導入支援サービス「PagerDutyパッケージ」を正式リリースいたしました。The post スリーシェイク、 インシデント管理・運用プラットフォーム「PagerDuty」の導入支援サービスを正式リリース first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555</guid>
            <pubDate>Thu, 05 Oct 2023 14:35:55 GMT</pubDate>
            <content:encoded><![CDATA[概要資料参考文献概要Platform Engineering Meetup #5 で SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用 というテーマで登壇をしました。SREからPlatform Engineerへの拡大のセルフリバイバルになります。このブログでは、参考資料を見るために利用してください。気が向いたら続き書く資料 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?What Team Structure is Right for DevOps to Flourish?Making the Business Case for a Dedicated Platform Engineering TeamCNCF Platforms White PaperSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsTop Strategic Technology Trends for 2023: Platform Engineering道を照らす: プラットフォーム エンジニアリング、ゴールデンパス、セルフサービスのパワーオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイドネットワーク・エフェクト　事業とプロダクトに欠かせない強力で重要なフレームワークINSPIRED 熱狂させる製品を生み出すプロダクトマネジメント]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREとPlatform Engineerの違いを3つのポイントで理解する]]></title>
            <link>https://sreake.com/blog/3-diffs-with-sre-and-platform-engineer/</link>
            <guid>https://sreake.com/blog/3-diffs-with-sre-and-platform-engineer/</guid>
            <pubDate>Wed, 04 Oct 2023 03:49:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめに プラットフォームエンジニアリング（Platform Engineering）とサイト信頼性エンジニアリング（SRE, Site Reliability Engineering）はともに、ITインフラとアプリケー […]The post SREとPlatform Engineerの違いを3つのポイントで理解する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DietPi で DNLA サーバー]]></title>
            <link>https://blog.1q77.com/2023/09/minidlna-on-dietpi/</link>
            <guid>https://blog.1q77.com/2023/09/minidlna-on-dietpi/</guid>
            <pubDate>Sat, 30 Sep 2023 08:33:09 GMT</pubDate>
            <content:encoded><![CDATA[Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes における秘密情報の管理方法]]></title>
            <link>https://sreake.com/blog/kubernetes-secret-management/</link>
            <guid>https://sreake.com/blog/kubernetes-secret-management/</guid>
            <pubDate>Mon, 25 Sep 2023 08:35:29 GMT</pubDate>
            <content:encoded><![CDATA[自己紹介 竹下 2023年8月21日からインターンに参加している早稲田大学基幹理工学研究科 M1 竹下です。SRE関連の技術と，自身が研究しているセキュリティ分野との関係性を学びたいと思い、インターンに参加しました。 中 […]The post Kubernetes における秘密情報の管理方法 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要]]></title>
            <link>https://zenn.dev/toshikish/articles/743f69389aa99c</link>
            <guid>https://zenn.dev/toshikish/articles/743f69389aa99c</guid>
            <pubDate>Fri, 22 Sep 2023 10:16:34 GMT</pubDate>
            <content:encoded><![CDATA[AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \--action lambda...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/google-cloud-specialization/</link>
            <guid>https://sreake.com/blog/google-cloud-specialization/</guid>
            <pubDate>Fri, 22 Sep 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud – Sell エンゲージメントモデルにおけるプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cl […]The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WSL 2 で外部ストレージをマウント]]></title>
            <link>https://blog.1q77.com/2023/09/wsl2-mount-volume/</link>
            <guid>https://blog.1q77.com/2023/09/wsl2-mount-volume/</guid>
            <pubDate>Thu, 21 Sep 2023 14:08:28 GMT</pubDate>
            <content:encoded><![CDATA[Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。 Microsoft のドキュメントにありました。 Linux]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Open InterpreterのDockerfile を書いたのでTipsとか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</guid>
            <pubDate>Tue, 19 Sep 2023 15:29:20 GMT</pubDate>
            <content:encoded><![CDATA[Dockerfile のベストプラクティスを考える機会はありますが皆さんの意見も聞きたい。今回は噂の便利ツール、Open Interpreterのような外部コマンドをどんどん実行して環境を作り変えるようなタイプのツールの場合にはDockerはとても有用です。そのようなツールを利用する時のDockerfile について考えていきます。リポジトリは以下になります。github.comGitHub Actionsとの連携GitHub Actionsは、CI/CD（継続的インテグレーションと継続的デリバリー）をGithub 上に簡単に実装できるツールです。今回は、trivy.ymlとdocker-publishを利用することで、セキュリティのスキャンとDockerイメージの自動公開が可能です。github.comtrivy.ymlの利用trivy.ymlは、Trivyという脆弱性スキャナーをGitHub Actionsで動かすための設定ファイルです。この設定を利用することで、Dockerイメージに存在するセキュリティの脆弱性を自動で検出できます。docker-publishの追加docker-publishは、DockerイメージをDocker Hubや他のレジストリに自動で公開するためのGitHub Actionsのワークフローです。これにより、新しいバージョンのOpen Interpreterがリリースされた際に、手動でイメージをビルド・プッシュする手間が省けます。Renovate.jsonの利用renovate.jsonは、依存関係を自動で更新する設定ファイルですが、これを使うとOpen Interpreterが依存しているライブラリやパッケージが新しくなったときに、自動でプルリクエストが作られるんです。そうすることで、いつも最新の状態を保てるわけですから、セキュリティリスクも減らせます。さらに、Pythonのパッケージも自動で更新したい場合は、requirements.txtを使って設定しておくと便利です。これにより、Pythonの依存パッケージも最新の状態を維持できるようになります。github.comDockerfileを書く際の注意点私は以下のようなDockerfileを書きましたその際に以下のようなポイントを意識して書いたので参考にしてください。github.com軽量なベースイメージの使用不必要なパッケージを含まない軽量なベースイメージを使用することで、ビルド時間とイメージサイズを削減できます。FROM python:3.11キャッシュの最適化RUNコマンドを効率的に配置することで、Dockerキャッシュを最適化できます。RUN apt-get update && \  apt-get upgrade -y && \  apt-get install -y --no-install-recommends git && \  rm -rf /var/lib/apt/lists/*不必要なパッケージの削除--no-install-recommendsオプションを使用して、不必要なパッケージをインストールしないようにします。  apt-get install -y --no-install-recommends git && \作業ディレクトリの設定WORKDIRを設定することで、その後のコマンドの実行ディレクトリを明示的に指定できます。WORKDIR /root機密情報はコンテナイメージに絶対に埋め込まない社内で有識者へ投げたら機密情報をビルドイメージに追加することを指摘されたので運用時の手癖やミスで何処かのレイヤーに不用意に埋め込まないようにしたgithub.comまとめDockerでOpen Interpreterを運用する際には他にもいろいろ考えるべきことがあると思うので皆さんと議論したいのでIssue待ってます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryの行列レベルのアクセス制御について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</guid>
            <pubDate>Thu, 14 Sep 2023 11:46:25 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Deployを使ったCloud Runのリリース]]></title>
            <link>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</link>
            <guid>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</guid>
            <pubDate>Wed, 13 Sep 2023 05:47:13 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く]]></title>
            <link>https://zenn.dev/satohjohn/articles/1645be8e83eab6</link>
            <guid>https://zenn.dev/satohjohn/articles/1645be8e83eab6</guid>
            <pubDate>Mon, 11 Sep 2023 14:17:35 GMT</pubDate>
            <content:encoded><![CDATA[概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較]]></title>
            <link>https://sreake.com/blog/container-security-comparison/</link>
            <guid>https://sreake.com/blog/container-security-comparison/</guid>
            <pubDate>Mon, 11 Sep 2023 07:22:29 GMT</pubDate>
            <content:encoded><![CDATA[自己紹介 高島 陸斗 千葉工業大学修士1年生の高島陸斗です。大学院では、コンピュータによる数値計算の厳密解との誤差がどの程度あるのかを調べる精度保証の精度を上げるための研究をしています。サイバーセキュリティに興味があり、 […]The post コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryのオンデマンド料金におけるコスト管理方法についてメモ]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</guid>
            <pubDate>Mon, 11 Sep 2023 01:56:24 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day8]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path</guid>
            <pubDate>Wed, 06 Sep 2023 18:37:55 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = 'k'ということ↩↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[まずPR-AgentをPromptとします。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</guid>
            <pubDate>Wed, 06 Sep 2023 07:52:27 GMT</pubDate>
            <content:encoded><![CDATA[「ツールよりもプロンプトのほうが、隙間がなくて効率的なのでは？」... ああ、面倒なブログになるな、とおれは直感した。はじめに近年、プルリクエスト（PR）の管理が開発フローにおいてますます重要な位置を占めるようになっています。ただし、PRをより良く作る作業は往々にして煩雑で手間がかかりがちです。その解決策として、Codium AIによって開発されたPR-Agentが脚光を浴びています。このAIソフトウェアは、OpenAIのGPT-4技術を基盤にしており、単にOpenAIのAPIキーを設定するだけで、既存のCI/CDパイプラインに簡単にインテグレーションできます。github.comPR-Agentの主な機能PR-Agentは、様々なPR関連作業を自動化するための多機能なオープンソースプロジェクトです。具体的には、以下のような機能群を提供しています。/describe: タイトル、種類、要約、コードの詳細説明、およびラベルを自動で作成するためのPR（プルリクエスト）説明自動生成機能。/review: PRの主題、種類、関連テスト、セキュリティ問題、評価スコア、その他のフィードバックを調整可能に提供する自動レビュー機能。/ask ...: PRに関するフリーテキスト質問に回答する質問応答機能。/improve: PRを改善するためのコミット可能なコード提案を行うコード改善提案機能。/update_changelog: PRの変更内容に基づき、CHANGELOG.mdファイルを自動で更新する更新履歴自動更新機能。PR-AgentはOpenAIのAPIキーを設定するだけでCI環境に簡単に組み込め、開発者が効率的なPR作成と管理を行えるよう支援します。このツールはGPT-4を用いて高精度なソースコード解析とレビューを自動で行い、開発者が重要なポイントに集中できるようにします。さらに、「PR Compression Strategy」と呼ばれる独自のアルゴリズムによって、大規模なPRでも重要なファイルと主要な言語のコードブロックに焦点を当てた効率的なレビューが可能です。それ以外にもさまざまな設定により、PR-AgentはPR作成とレビューのプロセスを自動化し、効率化する強力なツールであり、大規模プロジェクトにおいてもスムーズかつ効率的なレビュープロセスを実現します。これらをどのように動作させればよいのかはUsage guideを読んでみてください。PR-Agent のPromptPR Compression Strategyにより、送信するファイルの戦略が定められています。その設定に加えて、pr-agent/pr_agent/settings/ ディレクトリには、TOML形式でプルリクエスト（PR）のレビュープロンプトのテンプレートが含まれています。具体的には、pr_review_promptはpr_reviewer_prompts.toml ファイルに定義されており、これがPRのレビュープロセスにおける基本的な指示とフォーマットを規定しています。この構成により、PRレビューが一貫性を持ち、効率的に行えるよう設計されています。pr_reviewer_prompts.toml 解説pr_reviewer_prompts.tomlは、Pull Request（PR）レビューに関する設定と指示を定義する設定ファイルです。この設定ファイルは、PRレビューを自動化する際に利用されます。pr_review_prompt セクションsystemこの設定は、レビュワーがどのような役割を果たすべきかを定義しています。具体的なPR Diffの入力例も提供され、新しく追加されたコード（+で始まる行）に焦点を当てるよう指示されています。system="You are PR-Reviewer, a language model designed to review git pull requests. ..."num_code_suggestionsコード提案が必要な場合、その数や重要度についての指示がこの部分に記載されています。{%- if num_code_suggestions > 0 %}- Provide up to {{ num_code_suggestions }} code suggestions. ...{%- endif %}extra_instructionsパラメータで、追加的な指示や設定を行うために使用されます。この項目は主に以下のような用途で利用されることが多いです。{%- if extra_instructions %}Extra instructions from the user:{{ extra_instructions }}{% endif %}YAMLスキーマこの部分で、PRレビュワーが出力するレビュー結果のYAMLフォーマットが定義されています。Main theme, PR summary, Type of PR, etc.これらは、PRに関する基本情報を整理するためのフィールドです。Main theme:  type: string  description: a short explanation of the PRScore, Relevant tests added, Insights from user's answer, etc.これらのフィールドは、PRに関する詳細な評価やテスト情報、ユーザーからのフィードバックに基づく評価を行います。Score:  type: int  description: Rate this PR on a scale of 0-100 ...General suggestions, Code feedback, Security concernsこれらのフィールドは、具体的なコード提案やセキュリティ上の懸念など、PRのコードに関する詳細なフィードバックを提供します。General suggestions:  type: string  description: General suggestions and feedback for the contributors ...user セクションこのセクションは、PR作成者から提供される情報（タイトル、ブランチ、説明文など）を取り込む場所です。user="PR Info:Title: '{{title}}'Branch: '{{branch}}'Description: '{{description}}' ..."この設定ファイルによって、PRレビューのプロセスが自動化され、一貫性を持つようになります。特定のプロジェクトやチームに特有の要件に応じて、これらの設定はカスタマイズ可能です。まとめpr_reviewer_prompts.tomlといった設定ファイルを読んで全体としてPRのフォーマットに忠実にプロンプトを作成していったのがわかりました。参考にしていきたいと思います。github.com参考PR-Agent を使って Pull Request をAIレビューしてみた。（日本語対応もしてみた）GitHub - Codium-ai/pr-agent: 🚀CodiumAI PR-Agent: An AI-Powered 🤖 Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! 💻🔍]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</guid>
            <pubDate>Tue, 05 Sep 2023 10:46:35 GMT</pubDate>
            <content:encoded><![CDATA[これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介  |  Looker  |  Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会]]></title>
            <link>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</link>
            <guid>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</guid>
            <pubDate>Sat, 02 Sep 2023 10:02:16 GMT</pubDate>
            <content:encoded><![CDATA[前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerのユーザー権限について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</guid>
            <pubDate>Thu, 31 Aug 2023 17:22:40 GMT</pubDate>
            <content:encoded><![CDATA[これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day7]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/7_core_functions_write_io_path</guid>
            <pubDate>Wed, 30 Aug 2023 16:03:36 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから"Replication Successful"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES('k','v')ということ↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChatGPT × Slack = ChatOpsを実現する「h1-slack-bot」の紹介]]></title>
            <link>https://sreake.com/blog/chatgpt-slack-integration/</link>
            <guid>https://sreake.com/blog/chatgpt-slack-integration/</guid>
            <pubDate>Thu, 24 Aug 2023 07:04:08 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 本記事では、ChatOps […]The post ChatGPT × Slack = ChatOpsを実現する「h1-slack-bot」の紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
    </channel>
</rss>