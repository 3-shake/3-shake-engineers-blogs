<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Thu, 18 Dec 2025 22:42:31 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[My Plans of how to spend the New Year’s holiday from 2025 to 2026]]></title>
            <link>https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Thu, 18 Dec 2025 13:10:41 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Apache Commons Numbersとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_numbers</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_numbers</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はApache Commons Numbersについて調べてみました。 今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Numbersとは？公式サイトによると、Apache Commons Numbers...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Commons Chainとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_chain</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_chain</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:56 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Commons Chainについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Chainとは？公式サイトによると、Gang of Fourの責任連鎖パターン(chain ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Causewayとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_causeway_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_causeway_intro</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:56 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Causeway。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Causewayとは？公式サイトによると、Apache Causeway™ enables domain-driven applicat...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Avroとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_avro_serialization</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_avro_serialization</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:55 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Avro（以下、Avro）について調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Avroとは？公式サイトによると、Apache Avro™ is the leading serialization ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「自分の環境では動く」から解放される Nix Flake ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500</guid>
            <pubDate>Thu, 18 Dec 2025 02:15:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「自分の環境では動くんだけど...」という言葉を、何度聞いたことがあるだろうか。開発環境の差異は、これまで「手順書」「Docker」「asdf/anyenv」で解決を試みてきたが、いずれも時間経過で破綻する。手順書は陳腐化し、Dockerfileのベースイメージは変わり、asdfは言語ごとにツールが分散する。問題の本質は「環境の固定」ではなく「依存関係の完全な追跡」にあった。これを根本から解決するのが、純粋関数型パッケージマネージャ「Nix」と、その最新機能「Nix Flake」だ。これらの課題感については Infrastructure as Code, 3rd Edition が詳しく論じており、参考になる。2025年 俺が愛した本たち 技術書編 に入れれていなくて悲しいほどよい書籍である。オライリー・ジャパンさん 自分は翻訳の準備できてます！！！Infrastructure as Code: Designing and Delivering Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon本記事では、Nix Flake を使った開発環境の統一について、Docker との比較を交えながら包括的に解説する。実際に複数言語のプロジェクトで検証した結果も含めて、実践的な導入方法を紹介する。この記事で分かることNix Flake の基本概念と従来の Nix との違いDocker と Nix の使い分け・組み合わせ方各プログラミング言語（Rust, Go, Python, TypeScript）での開発環境の構築方法CI/CD との統合方法と direnv による自動環境切り替えNix とは何か純粋関数型パッケージマネージャNix は、従来のパッケージマネージャ（apt, brew, npm など）とは根本的に異なるアプローチを取る。その核心は「純粋関数型」（入力が同じなら出力も必ず同じになる仕組み）という概念にある。数学の関数と同様に、Nix では「同じ入力からは常に同じ出力が得られる」。パッケージのビルドに必要な全ての依存関係を明示的に指定し、外部環境に依存しない閉じた環境でビルドを行う。この仕組みにより、以下が保証される。再現性: 誰がいつどこでビルドしても、同じ結果が得られる分離性: システムの既存環境を汚さない共存性: 同じパッケージの異なるバージョンが同時に存在できるnixos.orgハッシュベースの依存管理Nix は全てのパッケージを /nix/store/ 以下にハッシュ付きで保存する。例えば、Node.js 20.10.0 は以下のようなパスに保存される。/nix/store/abc123...-nodejs-20.10.0/このハッシュは、パッケージのソースコード、ビルドスクリプト、全ての依存関係から計算される。つまり、依存関係が少しでも異なれば、異なるハッシュ（異なるパス）になる。これにより、バージョン競合が原理的に発生しない。Nix の核心概念Nix を理解するには、いくつかの重要な概念を押さえておく必要がある。Derivation（導出）Derivation はビルドレシピのようなもので、Nix の中核概念だ。「既存の store object から新しい store object を生成する純粋関数」と捉えれば理解しやすい。ビルドは sandboxed プロセスとして実行され、指定された入力のみを読み込み、決定論的に出力を生成する。Store（ストア）Store は /nix/store/ に存在するオブジェクトの集合だ。全てのパッケージ、ビルド成果物、依存関係がここに保存される。Store は不変（immutable）であり、一度書き込まれたオブジェクトは変更されない。Store PathStore path は store object の一意な識別子だ。例えば以下のような形式になる。/nix/store/a040m110amc4h71lds2jmr8qrkj2jhxd-git-2.38.1この長い文字列（a040m110...）は、パッケージの全ての入力から計算されたハッシュだ。入力が変われば、パスも変わる。これが Nix の再現性を支える基盤となっている。Realise（実現化）Realise は derivation を実際にビルドし、store path を valid な状態にすることだ。既にキャッシュにあればダウンロードされ、なければビルドが実行される。これらの概念については、公式マニュアルと用語集で詳しく解説されている。nix.devnix.devNix Flake とはFlake の基本構造Nix Flake は、Nix の最新機能であり、プロジェクトの依存関係を宣言的に管理する仕組みだ。従来の Nix には2つの問題があった。(1) NIX_PATH や <nixpkgs> などグローバルな状態に依存し、マシンごとに異なる結果を生む可能性があった。(2) 依存関係のバージョンを固定する標準的な方法を欠いていた。nix-channel の更新で環境が変わってしまうのだ。Flake は flake.lock でこれらを解決する。project/├── flake.nix          # プロジェクト定義├── flake.lock         # 依存関係のロックファイル└── src/               # ソースコードflake.nix は以下の構造を持つ。{  description = "プロジェクトの説明";  inputs = {    # 依存する外部 Flake を定義    nixpkgs.url = "github:nixos/nixpkgs?ref=nixpkgs-unstable";  };  outputs = { self, nixpkgs }: {    # 出力（devShells, packages, etc.）を定義  };}flake.lock による再現性flake.lock は npm の package-lock.json や Rust の Cargo.lock に相当する。全ての依存関係のコミットハッシュが固定されるため、時間が経っても同じ環境を再現できる。{  "nodes": {    "nixpkgs": {      "locked": {        "lastModified": 1702312524,        "narHash": "sha256-...",        "rev": "abc123...",        "type": "github"      }    }  }}Flake についての詳細は NixOS Wiki を参照してほしい。nixos.wikiDocker / コンテナエコシステムとの比較Nix と Docker は競合ではなく補完関係にある。Nix は「ビルド時の再現性」を、Docker は「ランタイムの分離とデプロイ」を担う。各ツールとの関係 ツール  役割  Nix との関係  Dockerfile  イメージビルド  Nix で置き換え可能（より再現性が高い）  Docker Compose  マルチコンテナ構成  devenv/process-compose で補完  Kubernetes  コンテナオーケストレーション  Nixidy/kubenix で統合可能  Helm  K8s パッケージ管理  nix-helm で Nix から利用可能  Skaffold  開発ワークフロー自動化  ビルドフェーズで Nix を使用可能 Dockerfile の課題と Nix の解決策Dockerfile は広く普及しているが、再現性に課題がある。# Dockerfile: 再現性の問題FROM python:3.12  # タグは可変RUN apt-get update && apt-get install -y curl  # バージョン固定なしRUN pip install requests  # バージョン固定なし# Nix: 完全な再現性{  packages.docker-image = pkgs.dockerTools.buildImage {    name = "my-app";    copyToRoot = pkgs.buildEnv {      name = "image-root";      paths = [ pkgs.python312 pkgs.curl pkgs.python312Packages.requests ];    };  };}Nix の優位点:- ビット単位で同一の結果を保証- 全ての依存を明示的に管理（暗黙の依存が混入しない）- パッケージ単位の効率的なキャッシュ- SBOM（Software Bill of Materials）の自動生成blog.replit.comwww.devzero.ioNix + Docker の組み合わせ両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。{  packages.docker-image = pkgs.dockerTools.buildLayeredImage {    name = "my-app";    tag = "latest";    contents = [ myApp pkgs.cacert ];    config.Cmd = [ "/bin/my-app" ];  };}各依存パッケージが独立したレイヤーになるため、パッケージAを更新してもパッケージBのレイヤーは再利用される。Dockerfile を書く必要がなく、Nix の宣言的な記述で完結する。flox.devKubernetes との統合: NixidyNixidy は Nix と Argo CD を組み合わせた GitOps ツールで、クラスター全体を NixOS のように管理できる。{  applications.nginx = {    namespace = "default";    helm.releases.nginx = {      chart = inputs.nixhelm.chartsDerivations.nginx;      values = { replicaCount = 3; service.type = "LoadBalancer"; };    };  };}nixidy.dev近年、ソフトウェアサプライチェーンのセキュリティが重視されている。ビルドの再現性と依存関係の透明性は「必須」になりつつある。Nix はビルドプロセス全体を宣言的に記述するため、SBOM の自動生成と来歴の追跡が容易だ。thenewstack.io実践：複数言語での開発環境構築flake-parts によるモジュール化複雑な Flake を管理しやすくするために、flake-parts を使う。これは NixOS モジュールシステムの考え方を Flake に適用したもので、設定を複数ファイルに分割できる。{  inputs = {    nixpkgs.url = "github:nixos/nixpkgs?ref=nixpkgs-unstable";    flake-parts.url = "github:hercules-ci/flake-parts";    treefmt-nix.url = "github:numtide/treefmt-nix";  };  outputs = { flake-parts, ... }@inputs:    flake-parts.lib.mkFlake { inherit inputs; } {      imports = [ inputs.treefmt-nix.flakeModule ];      systems = [ "aarch64-darwin" "aarch64-linux" "x86_64-linux" ];      perSystem = { config, pkgs, ... }: {        devShells.default = pkgs.mkShell {          packages = with pkgs; [            nodejs_22            config.treefmt.build.wrapper          ];        };        treefmt = {          projectRootFile = "flake.nix";          programs.prettier.enable = true;          programs.nixfmt.enable = true;        };      };    };}flake.partsRust 開発環境Rust プロジェクトでは、rust-overlay を使う。rustupなしで stable/nightly を切り替えられる。rust-analyzer や clippy も flake.nix で宣言的に管理できる。{  inputs.rust-overlay.url = "github:oxalica/rust-overlay";  perSystem = { pkgs, system, ... }:    let      overlayPkgs = import inputs.nixpkgs {        inherit system;        overlays = [ inputs.rust-overlay.overlays.default ];      };      rustToolchain = overlayPkgs.rust-bin.stable.latest.default.override {        extensions = [ "rust-src" "rust-analyzer" "clippy" ];      };    in {      devShells.default = pkgs.mkShell {        packages = [          rustToolchain          pkgs.cargo-watch          pkgs.cargo-edit        ];      };    };}github.comGo 開発環境{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      go      golangci-lint      gopls      delve    ];    env = {      CGO_ENABLED = "0";    };  };}Python 開発環境Python では uv との組み合わせを推奨する。Nix で Python 本体と uv を提供し、パッケージ管理は uv に任せる。pyenv/venv/pip の組み合わせより高速で、依存解決も確実だ。{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      python312      uv      ruff      pyright    ];    env = {      UV_PROJECT_ENVIRONMENT = ".venv";    };  };}マルチ言語プロジェクト1つの Flake で複数の開発環境を提供できる。{  devShells = {    default = pkgs.mkShell {      packages = [ rustToolchain pkgs.go pkgs.nodejs_22 ];    };    rust = pkgs.mkShell { packages = [ rustToolchain ]; };    go = pkgs.mkShell { packages = [ pkgs.go ]; };    nodejs = pkgs.mkShell { packages = [ pkgs.nodejs_22 ]; };  };}使用時は以下のように選択できる。nix develop        # デフォルト（全言語）nix develop .#rust # Rust のみnix develop .#go   # Go のみ様々な言語向けのテンプレートが dev-templates リポジトリで公開されている。github.comdirenv との連携direnv とはdirenv は、ディレクトリごとに環境変数を自動で切り替えるツールだ。.envrc ファイルを配置したディレクトリに入ると自動的に環境がロードされ、離れるとアンロードされる。direnv.netnix-direnv のセットアップNix Flake と direnv を連携させるには、nix-direnv が必要だ。実際にセットアップした手順を紹介する。1. nix-direnv のインストール# Nix profile でインストールnix profile install nixpkgs#nix-direnv# インストール確認ls ~/.nix-profile/share/nix-direnv/# direnvrc が存在することを確認2. direnvrc の設定~/.config/direnv/direnvrc に以下を追加する。# nix-direnv を使用して Nix Flake 環境を高速にロード# キャッシュにより、シェル起動時の遅延を大幅に削減if [ -f "$HOME/.nix-profile/share/nix-direnv/direnvrc" ]; then  source "$HOME/.nix-profile/share/nix-direnv/direnvrc"elif [ -f "/nix/var/nix/profiles/default/share/nix-direnv/direnvrc" ]; then  source "/nix/var/nix/profiles/default/share/nix-direnv/direnvrc"elif [ -f "/run/current-system/sw/share/nix-direnv/direnvrc" ]; then  source "/run/current-system/sw/share/nix-direnv/direnvrc"fi3. シェルへの hook 追加使用しているシェルに応じて設定を追加する。# bash (~/.bashrc)eval "$(direnv hook bash)"# zsh (~/.zshrc)eval "$(direnv hook zsh)"# fish (~/.config/fish/config.fish)direnv hook fish | sourcegithub.comプロジェクトでの使用1. .envrc ファイルの作成プロジェクトルートに .envrc を作成する。# .envrc - 基本的な使い方use flakeより詳細な設定も可能だ。# .envrc - 詳細な設定例# nix-direnv を使用（高速・キャッシュ対応）use flake# 特定の devShell を使用する場合# use flake .#rust# 追加の環境変数export EDITOR="nvim"export MY_PROJECT_ENV="development"2. direnv の許可セキュリティのため、初回は明示的に許可が必要だ。cd my-projectdirenv allow動作確認実際に動作を確認した結果を示す。# direnv のステータス確認$ direnv statusdirenv exec path /opt/homebrew/bin/direnvDIRENV_CONFIG /Users/nwiizo/.config/direnvFound RC path /path/to/project/.envrcFound RC allowed 0Found RC allowPath /Users/nwiizo/.local/share/direnv/allow/...nix-direnv のキャッシュ機構nix-direnv は .direnv/ ディレクトリにキャッシュを作成する。実際のキャッシュ構造は以下のようになる。.direnv/├── bin/                    # 一時的なバイナリラッパー├── flake-inputs/           # 入力 Flake のキャッシュ├── flake-profile-*         # Nix Store へのシンボリックリンク└── flake-profile-*.rc      # 環境変数のキャッシュ（約86KB）キャッシュの効果flake-profile-* は Nix Store の実際のパッケージを指す例: /nix/store/l5rhpr6i98h3kvydy6gww5cvszmqi05a-nix-shell-env2回目以降のロードは数ミリ秒で完了nix-collect-garbage でもキャッシュは保護されるnix-direnv vs 標準 direnv 観点  nix-direnv  標準 direnv + use nix  初回ロード  同等（ビルドが必要）  同等  2回目以降  数ミリ秒  数秒〜数十秒  GC 耐性  保護される  削除される可能性  Flake 対応  ネイティブ  追加設定が必要  キャッシュサイズ  〜100KB/プロジェクト  なし マルチ言語プロジェクトでの設定複数の devShell を持つプロジェクトでは、以下のように使い分けられる。# .envrc# デフォルトで全言語環境をロードuse flake# または特定の言語環境のみロードする場合:# use flake .#rust# use flake .#go# use flake .#python# use flake .#nodejsトラブルシューティングdirenv が反応しない# シェルフックが設定されているか確認which direnvdirenv status# 許可されているか確認direnv allow環境がロードされない# .envrc の構文エラーをチェックdirenv edit# キャッシュをクリアして再構築rm -rf .direnvdirenv allowFlake が見つからない# flake.nix が Git に追加されているか確認git status flake.nixgit add flake.nix flake.lockDeterminate Systems のブログでは、direnv と Nix の連携について詳しく解説されている。determinate.systemsCI/CD との統合GitHub Actions での使用name: CI with Nix Flakeon: [push, pull_request]jobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      # Nix インストール（Determinate Systems 推奨）      - uses: DeterminateSystems/nix-installer-action@main      # Magic Nix Cache でビルドを高速化      - uses: DeterminateSystems/magic-nix-cache-action@main      # Flake のチェック      - run: nix flake check      # フォーマットチェック      - run: nix develop --command treefmt --ci      # ビルド      - run: nix buildgithub.comCachix によるバイナリキャッシュCI でビルドした成果物を Cachix にプッシュすると、他の開発者やCI環境ではビルド済みバイナリをダウンロードするだけで済む。ビルド時間が大幅に短縮される。- uses: cachix/cachix-action@v15  with:    name: your-cache    authToken: '${{ secrets.CACHIX_AUTH_TOKEN }}'overlay によるカスタマイズパッケージのカスタマイズoverlay を使うと、既存のパッケージをカスタマイズしたり、独自のパッケージを追加したりできる。{  customOverlay = final: prev: {    # 既存パッケージをラップ    myGit = prev.writeShellScriptBin "git" ''      exec ${prev.git}/bin/git -c init.defaultBranch=main "$@"    '';    # カスタムスクリプト    project-init = prev.writeShellScriptBin "project-init" ''      echo "Initializing project..."      ${prev.git}/bin/git init      echo "# New Project" > README.md    '';  };}treefmt による統一フォーマット複数言語のフォーマッターを1つのコマンドで実行できる。{  treefmt = {    projectRootFile = "flake.nix";    programs = {      nixfmt.enable = true;      rustfmt.enable = true;      gofmt.enable = true;      prettier.enable = true;      ruff-format.enable = true;    };  };}treefmt      # 全ファイルをフォーマットtreefmt --ci # CI でのチェック（変更があればエラー）github.comトラブルシューティングexperimental-features エラーerror: experimental Nix feature 'nix-command' is disabled~/.config/nix/nix.conf に以下を追加する。experimental-features = nix-command flakesnix develop が遅い初回は依存関係のダウンロードとビルドに時間がかかる。2回目以降はキャッシュが効くため高速だ。Cachix を使うとより高速化できる。direnv が無限ループするFish shell を使っている場合、shellHook で exec fish を呼ばないように注意する。Flake が見つからないFlake ファイルは Git に追加されている必要がある。未追跡ファイルは Nix から見えない。git add flake.nix flake.lockまとめNix Flake を導入することで、開発環境の「再現性」「分離性」「共有性」を根本から改善できる。Docker とは競合ではなく補完関係にあり、両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。導入の主なメリットをまとめる。開発環境のセットアップが nix develop の1コマンドにチーム全員が同じツールバージョンを使用CI と開発環境の乖離がなくなるフォーマットの一貫性を自動で保証Docker イメージのビルドも再現可能に学習コストは確かに高い。Nix言語の習得やStore/Derivationの概念理解には時間がかかる。しかし一度導入すれば、環境構築が1コマンドで完了する。「環境差異によるバグ」が原理的になくなり、CIと開発環境が同一になる。特に複数言語プロジェクトでは、rustup/pyenv/nvm/goenvの個別管理から解放され、単一のflake.nixで全ての言語ツールチェーンを統一できる。まずは小規模なサイドプロジェクトで試してみてほしい。nix flake init -t github:the-nix-way/dev-templates#rust ですぐに始められる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Interested in Self-Endless Advent Calendar?]]></title>
            <link>https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 17 Dec 2025 13:29:58 GMT</pubDate>
            <content:encoded><![CDATA[I’ve been writing tech blog on Japanese tech blog media, Zenn, since April 18, 2025 everyday. I’ll share why I started this activity and…Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubで管理しているZennのファイル名を一括修正した話]]></title>
            <link>https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 17 Dec 2025 13:04:22 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Aimシリーズ：OptunaとPytorch Lightningを組み合わせたMNIST実験管理]]></title>
            <link>https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:24 GMT</pubDate>
            <content:encoded><![CDATA[今回はAimで実験管理を行いつつ、OptunaとPytorch Lightningを使ってMNISTの分類をしてみました。ぜひ過去の以下の記事を参考にしてください。https://zenn.dev/akasan/articles/6221f74bea622dhttps://zenn.dev/akasan/articles/a75361d039906f 早速実装 環境構築uvを使って以下で環境を構築します。uv init aim_optuna_lightning_mnist -p 3.12cd aim_optuna_lightning_mnistuv add aim l...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Aimシリーズ：入門してみた]]></title>
            <link>https://zenn.dev/akasan/articles/aim_ml_tracking_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/aim_ml_tracking_intro</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:23 GMT</pubDate>
            <content:encoded><![CDATA[今回から、Aimという実験管理ツールに入門してみます。※ 出張中につき、短編になります。 Aimとは？Aimとはオープンソースの実験管理ツールになります。Aimを利用すると実験を実行し、その結果発生する様々なメタデータを一元的に取り扱い、グラフィカルに解析することができます。Aimを利用することで以下のようなことが実現できます。MLパイプラインのロギングを可能にするUIを通してメタデータを比較分析できるML学習を効率的に実行可能実験管理のオーガナイズができるhttps://github.com/aimhubio/aim/ 早速使ってみる今回はGitHub上で提...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoを使ってOpenAIのエージェントを作成してみた]]></title>
            <link>https://zenn.dev/akasan/articles/agno_openai_agent_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/agno_openai_agent_intro</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:23 GMT</pubDate>
            <content:encoded><![CDATA[今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoのGuardrail機能を試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/agno_guardrail_feature</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/agno_guardrail_feature</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:22 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年版 私がAIエージェントと協働しながら学習する方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705</guid>
            <pubDate>Wed, 17 Dec 2025 03:17:05 GMT</pubDate>
            <content:encoded><![CDATA[労働こそが最高の学習だったあなたは最近、「成長している」と感じているだろうか。かつて、プログラマーにとって、労働こそが最高の学習の場だった。なぜか。労働には「摩擦」があったからだ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わっていた。労働は、経験を意味に変換する装置だった。以前の開発を思い出す。新しいフレームワークを覚えなければならない。エラーと格闘して、ドキュメントを読み漁って、やっと動いたとき。あの達成感は、単なる満足ではなかった。「なぜ動かなかったか」「どう直したか」「次に同じ問題が起きたらどうするか」——この因果の記憶が、脳に刻み込まれていた。困難を乗り越えた記録が、自分の中に残っていた。Claude Codeで開発している今、コードは書ける。動く。レビューも通る。Claude CodeはAnthropicが提供するAIエージェント型の開発ツールで、ターミナル上で動作し、コードの生成・編集・実行・デバッグまでを自然言語で指示できる。従来の「コード補完」とは次元が違う。プロジェクト全体を理解し、ファイルを横断して作業し、テストまで書いてくれる。開発のあり方が、根本から変わった。しかし、その便利さの裏で、何かがおかしくなっていた。コードは書ける。動く。レビューも通る。でも、後から「なぜそう書いたの？」と聞かれても、答えに淀む。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。因果を辿れない。「なぜこの実装なのか」「他の選択肢は何だったか」「どこで判断したか」——この記憶がない。このままでは「実装ガチャ」を回し続けるだけの存在になってしまう。先日、それを痛感する出来事があった。本番環境で障害が起きた。自分が2週間前に実装した機能だ。ログを見る。エラーメッセージを読む。でも、原因の見当がつかない。「この処理、どういう順序で動くんだっけ」と考える。思い出せない。自分で書いたコードなのに、頭の中でトレースできない。因果がわからない。結局、AIにコードを貼り付けて「このエラーの原因は？」と聞いた。答えは返ってきた。直った。しかし、自分では何も解決していない。2週間前の自分が書いたコードを、今日の自分が理解できていなかった。もしかして、あなたも同じ感覚を持っていないだろうか。最初は自分を責めた。集中力が落ちたのか。学習能力が衰えたのか。でも違った。労働と学習が、分離した。摩擦が消えた。経験が意味に変わる機会が消えた。厄介だったのは、見せかけ上の生産性は上がっていたことだ。タスクは消化されている。アウトプットも出ている。しかし、3ヶ月前にやった案件の技術スタックを聞かれても、ほとんど思い出せない。生産性は上がった。成長は止まった。労働から学習が抜け落ちていた。「成長していない」と感じるとき、私たちは何を失っているのか。成果と経験と理解は、同じものだろうか。違う。成果は外に出たもの。経験は時間の中で起きたこと。理解は内側に残ったもの。成果が出ても、経験を積んでも、理解が残らなければ成長は感じられない。失われているのは「苦労」ではない。「プロセスの記憶」だ。自分が何を考え、どこで躓き、どう乗り越えたか。この記憶が消えている。AIが生成したコードは動く。でも、そこに至るまでに自分が何を試し、何を捨て、何を選んだか——その記憶がない。なぜ過去の仕事を説明できないと不安になるのか。説明できないということは、プロセスの記憶がないということだ。記憶がないということは、自分の中で何も変化が起きていないということだ。成長実感とは、能力の増加ではない。自分の内部で変化が起きたと確認できる手応えだ。では、記憶に残らない仕事は価値がないのか。そうではない。成果としての価値はある。でも、自分を成長させる価値はない。成果は外に残る。成長は内に残る。両者は別物だ。これは集中力の問題ではなかった。前回の記事「2025年版 私がAIエージェントと協働しながら集中する方法」で書いた微観法は、集中の持ち方を変えてくれた。でも、学習の問題は別だった。集中できても、学べていなかったのだ。syu-m-5151.hatenablog.com『信長の野望』をやっているのに『戦国無双』のような強さを求めるのは違う、と言われるかもしれない。地道な内政と、爽快なアクション。求めているものが違う。でも正直なところ、私たちはいつだってエンジニアなのでエンジニア領域で無双したいのです。AI時代の3つの非対称性ここまで、私個人の経験として「労働と学習の分離」を語ってきた。でも、ここまで読んで、「これは自分だけの問題かもしれない。単に自分の学び方が下手なだけでは？」と思った人もいるだろう。そうではない。これは個人の問題ではない。構造の問題だ。なぜ労働と学習が分離してしまったのか。その構造を理解するには、AIがもたらした3つの非対称性を見る必要がある。詳しくは別の記事で書いたが、ここでも簡単に触れておきたい。syu-m-5151.hatenablog.com第一の非対称性：生産と理解の乖離。AIでコードを書く速度は上がった。でも、そのコードを修正しようとすると、予想以上に時間がかかる。システム内にコードが流入する速度と、人間がそれを理解する速度の間に、決定的なギャップが生まれている。第二の非対称性：生産量と成長の乖離。AIを使えば、経験1年目でも大量のコードを生産できる。PRの数も増える。でも半年後、1年後、エンジニアとしての地力はどうなっているだろうか。問題を自分で分析し、設計を考え、トレードオフを検討するプロセス。これがエンジニアの地力を育てる。AIに頼りすぎると、この思考プロセスそのものを外部化してしまう。第三の非対称性：経験の量と学びの質の乖離。毎日AIを使って100行のコードを書く経験を1年積んでも、そこから「AIへの依存」しか学ばなければ、地力にはつながらない。「何を経験したか」ではなく、「そこから何を学んだか」が重要なのだ。この3つの非対称性は、1つのシステムとして機能している。速く書けることを追求すれば、理解が追いつかなくなる。理解しないまま大量に生産すれば、思考力が育たない。経験を積んでも、そこから学ばなければ、成長は起きない。根底にあるメンタルモデル—「速さが価値」「量が成果」「経験が成長」—を変えない限り、どんな対症療法も一時的な効果しか生まない。ここまでで、外部から見た構造——AIと人間の関係性——は理解できた。しかし、これだけでは「なぜ学べないのか」の本当の理由は見えてこない。構造は外側の話だ。学習が起きるのは、私たちの脳の内側だ。では、この構造が私たちの脳に何をしているのか。もう少し掘り下げてみよう。脳が「処理」していない構造の問題は、最終的に脳の問題に帰着する。なぜ知識が残らないのか。しばらく自分を観察してみた。気づいたのは、AIエージェントと働いていると、認知的負荷が下がりすぎるということだ。認知的負荷とは、頭を使う度合いのことだ。問題を解くとき、脳は情報を処理し、比較し、判断する。この「頭を使う」プロセスが、認知的負荷を生む。負荷が下がること自体は、一見良いことに思える。楽に仕事ができる。疲れにくい。でも、学習の観点からは最悪だった。脳は適度な負荷がかからないと、情報を長期記憶に格納しない。「苦労せずに得た情報」は、脳にとって重要度が低いと判断される。楽に得た知識は、楽に消える。では、認知的負荷はどこからが「害」になるのか。問題は量ではない。質だ。認知的負荷には種類がある。タイピングの負荷。構文を思い出す負荷。そして、比較・判断・仮説といった意味処理の負荷。AIが減らしてくれるのは、すべての負荷だ。だが、害になるのは意味処理の負荷が消えたときだ。なぜ脳は負荷がないと学ばないのか。脳は「重要でない」と判断した情報を捨てる。重要かどうかの判断基準は、処理にかかった負荷だ。苦労して得た情報は重要。楽に得た情報は重要でない。意味処理の負荷が消えた瞬間、脳は「これは覚えなくていい」と判断する。記憶も学習も、起こらなくなる。「ちょうどよい負荷」は誰が決めるのか。AIではない。あなただ。負荷をAIに外注すると、脳は怠ける。怠けた脳は弱くなる。認知的負荷は削減対象ではない。設計対象だ。どの負荷を残し、どの負荷を外注するか。その設計を自分でしなければ、学習は起こらない。楽になることと、考えなくなることは同じか。違う。作業が楽になるのはいい。思考が楽になるのは危険だ。手を動かす負荷は減らしていい。意味を処理する負荷は、意図的に残せ。以前のプログラミングを思い出す。エラーが出る。ググる。ブログや公式ドキュメントを読む。試す。またエラー。別の方法を試す。やっと動く。このプロセス全体が、学習だった。途中で「わからない」状態に耐える必要があった。その「耐える時間」が、脳を鍛えていた。記憶を定着させていた。今はどうか。エラーが出る。AIに投げる。答えが返ってくる。動く。終わり。プロセスが消えた。プロセスが死ぬと、学習も死ぬ。考えてみてほしい。あなたが最後に「わからない」と感じたのは、いつだろうか。私は本当に思い出せなかった。AI時代において、「わからない」が絶滅したのだ。聞けば答えが返ってくる。どんな質問にも、それらしい回答が生成される。以前は「わからない」状態で立ち止まり、悩み、調べ、試行錯誤した。その時間が学習だった。今は「わからない」と感じる前に、答えが手に入る。「わからない状態」に耐える力こそ、学習に不可欠だ。わからない状態は不快だ。不確実性は脳にストレスを与える。だから、答えを求める。AIはその欲求を即座に満たしてくれる。だが、「わからない」は単なる欠如ではない。意味を構築するための空白だ。以前の学習を思い出してほしい。エラーが出て、原因がわからない。ドキュメントを読んでも、ピンとこない。仮説を立てて、試して、また失敗する。その空白の中で、脳は問題を構造化していた。何がわかっていて、何がわかっていないか。どこまでは正しくて、どこからが怪しいか。仮説を立て、壊し、更新する。このプロセスを通じて、人は「思考の型」と「判断の軸」を獲得してきた。わからない経験がなくなると、思考の型が育たない。問題をどう分解するか。仮説をどう立てるか。どの順番で検証するか。これは、わからない状態を何度も経験することでしか身につかない。答えが即座に与えられる世界では、この「思考の筋トレ」そのものが消える。AIはわからないと言わない。常に何かを返す。それが正しいかどうかは別として。人間だけが「わからない」を経験できる。その経験を捨てるのは、思考力を捨てることだ。でも、その「すぐわかる」が、実は思考力を奪っていた。自分一人で「じっくり」考える時間が消えた。わからないまま考え続ける能力。不確実性の中にとどまる能力。それが失われていく。「わからない」を経験しないまま、「わかった」に到達してしまう。ここまでは「わからない状態」の話だった。つまり、問題に直面したとき、AIがすぐに答えを出してしまうから、自分で考える時間がなくなるという話だ。でも、認知的負荷が下がる問題は、これだけではない。AIの答えを受け取って「わかった」と思った後にも、別の問題がある。コードへの解像度が下がるのだ。以前、自分で書いたコードは、補完もありながらちゃんと打ち込んでいた。変数名を決めるときに悩んだ。ループの終了条件を頭の中でシミュレートした。このif文の分岐は、こういうケースでtrueになる。この変数には、この時点でこの値が入っている。コードは指先から脳へ流れ込んでいた。AIが生成したコードは、目で見ているだけだ。なんとなく動く気がするから動かす。動く。テストも通る。でも、変数の1つに至るまで把握しているかと言われると、怪しい。コードが「通過」していく感覚。身体に染み込んでいない。見ているのに、触れていない。この違和感の正体は何か。自分で書いたコードと、AIが書いたコードは何が違うのか。結果は同じだろう。動作も同じだろう。でも、因果関係を自分で通ったかどうかが違う。自分で書いたコードには、因果の記憶がある。「この変数名、最初はdataにしようと思った。でも、後から読んだときに意味がわからなくなると思って、userResponseに変えた」。「このループ、最初はforで書いた。でも、副作用がないからmapの方がきれいだと思って書き直した」。迷い、選択し、決断した記憶。その因果を自分で通った記憶が、コードを「理解している」という感覚を生む。AIが生成したコードには、この因果がない。結果だけがある。「なぜこの変数名なのか」「なぜこの書き方なのか」。AIには理由があるのだろう。でも、その理由を自分で通っていない。書く・迷う・選ぶという行為を経ていないコードは、頭の中で「実行」されていない。なぜ説明できないと不安になるのか。説明できないということは、因果を再構成できないということだ。因果がわからないコードは、壊れたとき直せない。変更したとき、何が起きるか予測できない。「動くこと」と「わかること」は別だ。動くことは確認できる。わかることは、因果を辿れるかどうかで決まる。理解とは知識量ではない。因果を身体でトレースできるかどうかだ。「見ているが触っていない」とは、この状態だ。視覚的には認識している。でも、因果を身体で通過していない。だから、記憶に残らない。応用が利かない。自分のものにならない。解像度が低い理解は、何を引き起こすのか。判断ができなくなる。「この実装でいいのか」「この変更は安全か」。判断には、因果の理解が必要だ。因果がわからなければ、判断できない。判断できない人間は、AIの出力を受け入れるしかない。私は自分で書いたコードは、書く過程で何度も頭の中で実行している。「この変数がnullだったらどうなる」「このループは何回まわる」「この関数の戻り値は何型か」。無意識に検証している。AIが生成したコードには、この検証プロセスがない。結果、コードの「解像度」が違う。自分で書いたコードは、ズームインしてもくっきり見える。AIが生成したコードは、全体像はわかるが、細部がぼやけている。動くことは知っている。なぜ動くかは、よくわからない。解像度が低いと、記憶にも残りにくい。ぼんやりした情報は、脳に定着しない。そしてもう1つ、記憶を弱くする要因がある。解像度の問題とは別に、「思い出す」作業をしていないのだ。記憶を定着させるには、能動的に思い出す作業が必要だ。一度覚えたことを、何も見ずに思い出す。その「引き出す」作業が、記憶を強化する。でもAIと働いていると、思い出す必要がない。わからないときは聞けばいい。脳が「引き出す」練習をしなくなった。筋トレと同じだ。重いものを持ち上げないと筋肉はつかない。代わりに機械が持ち上げてくれたら、楽だけど、筋肉は衰える。AIは脳の代行業者だ。頼りすぎると、依頼主が衰える。何をしたか覚えていない、だから自分を過小評価するここまで、認知的負荷が下がることで起きる3つの問題を見てきた。「わからない」状態を経験しなくなること。コードへの解像度が下がること。そして、「思い出す」作業をしなくなること。これらは脳の内側で起きている問題だった。しかし、認知的負荷が下がることには、もう1つ厄介な副作用がある。脳の外側、つまり自分自身の認識に関わる問題だ。自分が何をしたのか覚えていないのだ。1日の終わりに「今日、何やったっけ？」と振り返る。AIと働いていると、驚くほど思い出せない。タスクは消化した。PRはマージされた。でも、何をどう解決したのか、記憶がぼんやりしている。なぜか。苦労しなかったからだ。痛みを伴わない経験は、砂に書いた文字だ。苦労は記憶のアンカーになる。あのエラーで3時間ハマった。あの設計で悩んで何度も書き直した。そういう「苦労の記憶」が、「自分がやった」という実感を生む。AIが苦労を肩代わりすると、このアンカーがなくなる。アンカーがないと、何が起きるか。自分を過小評価するようになる。「今日、大したことやってないな」と感じる。でも実際には、かなりの量のコードがマージされている。客観的には生産性が上がっているのに、主観的には「何もやっていない」気がする。成果と実感が乖離する。これは私だけの感覚ではない。知り合いのエンジニアと話していても、同じことを言う人が多い。「なんか最近、成長している実感がない」「仕事はこなせているけど、自分が何をやったか説明できない」。みんな同じ違和感を抱えている。感覚と現実が、乖離しているのだ。なぜ「何をしたか」を覚えていないと不安になるのか。自己評価はどこから生まれているのか。自己評価は、成果から生まれるのではない。「自分が困難にどう向き合ったか」という記憶から生まれる。あのバグを3時間かけて潰した。あの設計を何度も書き直した。あの障害対応で深夜まで粘った。こうした記憶が、「自分はやれる」という感覚を作る。苦労は自己評価の原材料だ。AIが苦労を肩代わりすると、何が起きるか。成果はある。でも、「自分がやった」という実感が残らない。困難と向き合った記憶がないから、自分を評価する材料がない。結果、成果が出ているのに自分を信じられなくなる。成果と達成感はなぜズレるのか。達成感は「困難を乗り越えた」という認識から生まれる。困難がなければ、達成感も生まれない。AIが困難を消してくれると、成果だけが残り、達成感は消える。成果と達成感の乖離。これがAI時代の新しい病だ。このズレは長期的に何を壊すのか。まず、挑戦を避けるようになる。「どうせAIがやってくれる」と思う。自分で考えることを放棄する。次に、自分を信じられなくなる。難しい問題に直面したとき、「自分にはできない」と感じる。かつて乗り越えた経験がないから、乗り越えられるイメージが湧かない。そして最後に、エンジニアとしてのアイデンティティが揺らぐ。「自分は何ができる人間なのか」がわからなくなる。成果は出ている。でも、それは自分の力なのか、AIの力なのか。区別がつかなくなる。達成の記憶がないなら、何かで補うしかない。では、何で補うのか。答えを先に言う。記録だ。達成の記憶がないなら、記録で作ればいい。苦労の記憶がないなら、躓きを記録で残せばいい。AIが消してしまう「プロセスの記憶」を、意図的に書き留める。それが私の出した答えだった。日報が労働と学習をつなぎ直したここまで読んで、「わかる、でもどうすればいいの？」と思っただろうか。私も同じだった。記録が大事だとわかっても、何をどう記録すればいいかわからなかった。行き詰まっていたとき、藁にもすがる思いで、ある習慣を始めた。日報だ。正直、日報は嫌いだった。面倒くさい。忙しい。後で書こうと思って忘れる。3日分まとめて書いて、何をやったか思い出せない。典型的なサボりパターンだった。何度も挫折した。でも、このままでは本当にまずいと思った。自分が書いたコードを説明できない。障害が起きても自分で解決できない。エンジニアとして、このまま衰えていくのか。その恐怖が、嫌いな日報を続けさせた。でも、日報の目的を変えてみた。上司への報告のためではなく、労働の中で生まれた曖昧さを捕まえるために書く。自分が何をわかっていて、何をわかっていないか。その現状を記録する仕組みだ。日報を続けて、衝撃的な事実に気づいた。その話は後で詳しく書く。でもその前に、一度立ち止まって考えたい。日報を書いて躓きを記録する。それは「学習」につながるはずだ。しかし、そもそも「学習する」とは何なのだろうか。この根本的な問いを考えないと、日報を書く意味も見えてこない。では、「学習する」とは、そもそも何なのでしょうか。この問いを考えるとき、私は為末大さんの『熟達論——人はいつまでも学び、成長できる』（新潮社、2023年）に大きな影響を受けました。400mハードルで日本記録を持つ「走る哲学者」が、様々な分野の達人たちとの対話を重ねて到達した方法論です。www.shinchosha.co.jp為末さんは、人が何かを学び、熟達していくプロセスには、分野を超えた普遍的な構造があると言います。陸上であれプログラミングであれ、学習のプロセスは同じです。技能と自分のどちらかだけを高めても成長できないと説きます。技能と自分は、切り離すことのできない「ひとつのもの」——つまり人間という総体として捉えるべきだと。この人間総体を高めていくことが、学習なのです。この考え方は、ソフトウェアエンジニアとしても腑に落ちます。プログラミングスキルだけを磨いても、良いエンジニアにはなれません。問題を分解する力、チームで働く力、技術を選ぶ判断力。技能と自分の総体が、エンジニアとしての実力です。為末さんによれば、学習には5つの段階があります。この5段階は「学習がどう進むか」を示す地図です。まず、その地図を見てみましょう。「遊（ゆう）」——学習の入口です。新しい技術に触れて、面白いから触る。効率は求めません。目的もありません。遊びとは主体的であり、面白さを伴い、不規則なもの。このモチベーションの源泉が、学習の入口になります。エンジニアなら、新しいフレームワークを触ってみる。ドキュメントを読む前に動かしてみる。「これ何ができるんだろう」と試す。壊してみる。変なパラメータを渡してみる。遊びが好奇心を育て、好奇心が学習を駆動します。「型（かた）」——基礎を身につける段階です。お手本を真似る。ドキュメント通りに書く。型とは「基盤となる最も基本的なもの」であり、個人差を超えて最も安定している普遍的なものです。型は丸呑みするもの。なぜそうするかはわからなくても、まず形から入ります。エンジニアなら、公式チュートリアルを写経する。ベストプラクティスをそのまま真似る。「なぜこう書くのか」は後回し。まず手が覚えるまで繰り返します。型が身体に入ると、考えなくても書けるようになります。「観（かん）」——構造を理解する段階です。「なぜこの書き方なのか」と問う。「見る」とは「分ける」こと。動作を分けて見ることで、技術を構造化します。ある技能は別の技能に支えられている。その関係性が見えてきます。エンジニアなら、コードの設計意図を読み取る。「この抽象化は何のためか」「このパターンはどこで使えるか」と問う。部分（関数）と全体（システム）の関係が見えます。観ができると、他人のコードから学べるようになります。また、コードを「意味の塊」として捉えられるようになります。初心者が「if文があって、関数呼び出しがあって...」と一行ずつ追う場面で、「これはトークン検証の処理だ」と全体を1つの塊として認識できる。塊で捉えるから、複雑なコードも把握できるのです。「心（しん）」——本質を掴む段階です。見極めた本質を軸に、自分なりに自由に動ける状態。いつでもニュートラルポジションに戻れるから、応用的な技術も試せます。中心を柔らかくつかむと、冒険できるようになります。エンジニアなら、技術の本質を掴んでいる状態です。「認証の本質は信頼の証明だ」とわかれば、JWT でも OAuth でも Session でも、状況に応じて選べます。心を掴むと、新しい技術もすぐ理解できます。また、具体的な事例から抽象的なパターンを抽出できます。「このエラーはnullチェック漏れ」という具体から「外部データは信頼しない」という原則へ昇華する。この抽象化ができると、問題を絞り込む力も育ちます。「Invalid token」というエラーを見て、「トークン生成か検証のどちらかが問題」と可能性を狭められる。原理原則を理解していれば、推論で問題にたどり着けるのです。「空（くう）」——学習の到達点です。制約から解き放たれて、技能が自然な形で表現できる状態。いわゆる「ゾーン」です。論理よりも勘が働く。そしてまた「遊」に戻る。学習は循環します。エンジニアなら、コードが自然に流れ出る状態です。設計を考えなくても、手が正しい方向に動く。深夜のデバッグで「なぜかここが怪しい」と直感が働く。空に達した技能は、意識せずに発揮されます。重要なのは、部分の学習が全体を高めるという構造です。「認証処理」という部分を学ぶと、「Webアプリケーション開発」という全体の質が上がります。そして全体の質が上がると、今度は別の部分——たとえば「データベース設計」——を学ぶ意欲が湧いてきます。部分と全体が相互に作用しながら、エンジニアとしての総体が高まっていく。この循環こそが、成長を楽しめる理由です。ここまでが、学習の地図です。でも、抽象的な説明だけでは実感が湧かないかもしれません。私自身の経験に当てはめてみましょう。以前、新しい技術を学ぶとき、何が起きていたでしょうか。ドキュメントを読む。知らない概念が出てくる。調べる。言葉の意味はわかった。でも、まだ腑に落ちない。実際にコードを書いてみる。動かない。なぜ動かないか考える。仮説を立てる。試す。また動かない。別の仮説を立てる。3時間が経つ。ようやく動いた。「ああ、こういうことか」。次からは同じ間違いをしなくなる。この過程で、学習の段階を登っていました。最初は遊びから入った。動かしてみる。壊してみる。次に型を学んだ。ドキュメントを読み、お手本通りに書いた。型を繰り返すうちに、「なぜ」が見えてきた。観の段階です。より深まると、パターンが見える。心の段階です。そして最後に、考えなくても手が動くようになる。摩擦が、学習を生んでいました。繰り返しが、成長を生んでいました。今は違います。AIに聞く。完璧なコードが返ってくる。動く。終わり。私は遊んでいません。型も知りません。観ることもありません。心を掴めません。当然、空には程遠い。結果は出ました。でも、自分の中に何も残っていません。成果だけが先に行き、自分は置き去りにされました。これがAI時代の問題の核心です。摩擦がないから、学べない。繰り返す機会がないから、成長しない。問題の核心は見えました。では、もう少し細かく見てみましょう。学習の5段階で、AIはどこを加速し、どこを壊しているのでしょうか。AIはどの段階を代替しやすいでしょうか。「型」です。正しい書き方、ベストプラクティス、パターンの適用。AIはこれらを高速に提供してくれます。初心者がいきなり熟練者と同じ「型」を使えるようになる。これ自体は悪くありません。では、AIが壊すのはどこでしょうか。「遊」と「観」です。特に「遊」のダメージは深刻です。「遊」が消えると何が起きるのでしょうか。遊びとは、目的なく触ること。壊してみること。限界を探ること。正解がすぐ手に入る環境では、不規則さ・寄り道・失敗が排除されます。効率を求めると、遊びは最初に切り捨てられます。しかし、遊びは単なる入口ではありません。型や観に進むためのエネルギー源でもあります。なぜでしょうか。「型」を学ぶのは退屈です。ドキュメント通りに書く。お手本を真似る。地味な作業です。この退屈に耐えられるのは、「遊」の段階で「面白い」という感覚を得ているからです。「この技術、面白い。だから、ちゃんと学びたい」。このモチベーションがなければ、「型」の段階で挫折します。「観」も同様です。「なぜこうするのか」と問うのは、好奇心がなければできません。好奇心は「遊」で育ちます。遊びがないと、「なぜ」を問う動機がない。「動くからいい」で終わります。遊びがないと、「面白いから学ぶ」がなくなります。「必要だから学ぶ」だけになる。必要性で駆動される学習は、必要がなくなった瞬間に止まります。遊びが失われると、学習への意欲そのものが枯れるのです。「観」も壊れやすい段階です。「なぜこうするのか」と問う前に、AIが答えを出してしまう。構造を自分で見出すプロセスがスキップされます。答えは知っている。でも、答えに至る道筋が見えない。観る力はどこで育つのでしょうか。自分で構造を発見する経験の中です。AIがその経験を奪います。型を飛ばすと、なぜ応用できないのでしょうか。型は「基盤となる最も基本的なもの」です。基盤がないと、その上に何も建てられません。AIが型を代替してくれると、基盤が自分の中にない。だから、少し変わった状況に対応できないのです。学習はなぜ循環構造なのでしょうか。「空」に達しても、また「遊」に戻ります。新しい領域を学ぶとき、再び遊びから始まる。この循環が止まらない限り、人は成長し続けます。AIが「遊」を奪うと、循環そのものが止まります。「心」と「空」は、そもそも到達しにくくなります。基盤となる「遊」と「観」が欠けているからです。本質を掴むには、周辺を十分に探索している必要があります。無意識に動けるようになるには、意識的に何度も繰り返した経験が必要です。AIは上層を加速しますが、基盤を掘り崩します。思い返せば、私が一番成長したのは「遊んでいた」時期でした。学生時代、深夜にLinuxをいじっていました。「このコマンドに変なオプションを渡したらどうなるんだろう」と試した。システムが壊れた。復旧に3時間かかった。でも、その3時間でファイルシステムの構造を理解しました。教科書を読むより、壊して直す方がずっと早く学べました。社会人になってからも、余裕があるときは遊んでいました。「この機能、公式ドキュメントにはこう書いてあるけど、本当にそうなのか」と検証した。ドキュメントが間違っていることもありました。公式が想定していないパターンを見つけることもありました。遊びは、ドキュメントの外側を教えてくれました。今はどうでしょうか。遊ぶ暇があったら、次のタスクをAIに投げています。効率的です。生産的です。でも、技術との「雑談」がなくなりました。目的のない探索がなくなりました。効率を追求した結果、学習の肥沃な土壌を捨てていたのです。遊びがないと、表面的な理解で終わります。ドキュメントに書いてあることは知っている。でも、書いていないことは知らない。想定外の状況に遭遇したとき、対処できません。遊んでいないから、技術の「手触り」がわからないのです。ここまで、学習の5段階と、AIがそれをどう壊すかを説明しました。問題は見えました。では、どうすればいいのでしょうか。答えは単純です。何がわかっていないのかを、見えるようにする。何が欠けているのか。どこで躓いているのか。それを捕まえる。見えれば、対策が打てます。学習の段階で言えば、自分が「遊」で止まっているのか、「型」が足りないのか、「観」ができていないのか。それを知る必要がある。しかし、AIと効率的に働いていると、自分がどこで止まっているかすら見えない。見えないものは改善できない。だから、見えるようにする仕組みが必要だ。そこで私は、先に触れた日報を本格的に活用することにしました。1週間続けて、衝撃を受けました。自分がこんなにも理解していなかったのか。金曜の夜、その週の日報を見返した。「わからない」と書いた項目を数えてみようと思った。月曜の分から順番に。1、2、3... 10を超えたあたりで、手が止まった。まだ火曜だった。水曜、木曜、金曜と続く。「なぜ」がわからないもの、「本質」が見えないもの。多すぎた。画面を見つめながら、胃のあたりがざわついた。正直、途中で数えるのをやめた。自分は理解の入口にすら立っていなかった。しばらく、椅子に座ったまま動けなかった。これが自分の実力なのか。毎日コードを書いて、PRをマージして、それなりにやっているつもりだった。でも、蓋を開けてみれば、理解の穴だらけだった。恥ずかしさ、情けなさ、少しの怒り。それらの混ざった感情が胸に込み上げてきた。でも、その夜、不思議と眠れた。これは希望でもあったからだ。自分の現状を捕まえさえすれば、次に進める。見えない敵は怖いが、見える敵は対策できる。何より、問題が見えた。見えないまま衰えていくより、ずっといい。だから、日報について詳しく説明したい。なぜ日報が効くのか。どう書けばいいのか。日報がなぜ「記録」以上の意味を持つのか。それを理解するには、日報が何を可視化しているかを知る必要がある。日報は単なるログではない。曖昧さを捕まえるためのセンサーだ。書くことは、なぜ理解を深めるのか。AIと働いていると、違和感は一瞬で消える。「なんかわからないな」と思った次の瞬間、AIに聞いている。違和感を感じている時間がない。日報に「なぜ:」と書こうとすると、その違和感を言語化しなければならない。「何がわからないのか」を言葉にする。この言語化のプロセスで、曖昧だった問題が明確になる。書くことは、理解を深める。なぜなら、書けないことは理解していないことだからだ。その場で書くことに意味はあるのか。ある。学習の起点は「わからなかった点」にある。しかし、「わからなかった」という感覚は、時間とともに薄れる。翌日には忘れている。1週間後には、何がわからなかったかすら思い出せない。日報は、躓きを時間差で消えない形に固定する。その場で書かないと、学習の種が消える。日報は何を可視化しているのか。自分が何をわかっていて、何をわかっていないか。どこで繰り返し躓いているか。どのパターンが苦手か。可視化されて初めて、対策が可能になる。見えないものは改善できない。日報は、見えないものを見えるようにする。なぜ「躓き」が重要なのか。躓きは、成長の種だ。スムーズにできたことからは、何も学べない。躓いたところに、学びがある。日報は、躓きを収集するシステムだ。躓きを記録し、パターンを見つけ、対策を打つ。このサイクルが学習を生む。日報がないと何が起きるのか。躓きが流れていく。同じところで何度も躓く。でも、躓いていることに気づかない。気づかないから、対策も打てない。日報がない状態は、センサーのない飛行だ。どこに向かっているかわからない。何が起きているかわからない。墜落してから、問題に気づく。では、日報には何を書けばいいのか。私がよく使うのは「なぜ:」と「試した:」だ。「なぜ:」——理由がわからなかったことを記録する。「なぜ: この実装パターンを選んだ理由」。表面的な理解で終わらせない。「試した:」——目的のない探索を記録する。「試した: このライブラリ、何ができるんだろう。ドキュメントを読まずに動かしてみた」。好奇心が動いた瞬間を残す。キーワードは自分で決めればいい。「写経:」「本質:」「ハマった:」など、必要に応じて増やせばいい。大事なのは、何がわからなかったかを捕まえること。記録することで、自分の躓きパターンが見えてくる。以前は、労働の中で自然と学んでいた。困難にぶつかり、格闘し、乗り越える。そのプロセスが、理解を深めてくれた。今は違う。AIが困難を消してくれるから、格闘する機会がない。だから、意識的に躓きを記録し、学習の種類を分類する必要がある。日報は、そのための道具だ。ここまでは日報の「考え方」を説明した。では、具体的にどう実装するのか。私はClaude Codeのカスタムslash commandsで日報システムを作った。詳しい実装は以前の記事に書いた。syu-m-5151.hatenablog.comClaude Codeには強力なカスタマイズ機能がある。CLAUDE.mdというMarkdownファイルをプロジェクトルートや~/.claude/に置くと、AIがそれを読み込んで動作を調整する。コーディング規約、プロジェクト固有のルール、よく使うパターンなどを書いておけば、AIがそれを参照しながら作業してくれる。また、~/.claude/commands/にMarkdownファイルを置くと、カスタムslash commandsとして使える。/nippo-addと打てば、日報追加用のプロンプトが実行される。AIを「自分専用の道具」に育てる仕組みだ。私の日報システムは3つのコマンドで構成される。/nippo-add - 作業中にその場で記録する。Issue番号や感情も一緒に書く。後から検索しやすくなる。/nippo-finalize - 1日の終わりに実行。散らばった記録をAIが整理して、読みやすい日報に仕上げる。/nippo-show - 日次・週次のサマリーを表示。繰り返し躓いているパターンを可視化する。コマンドファイルは ~/.claude/commands/ に置く。プロジェクトをまたいで使える。CLAUDE.mdにはプロジェクトの文脈を、commands/には繰り返し使う操作を。この2つで、AIは「汎用ツール」から「自分の相棒」に変わる。/nippo-add #456 JWTの検証ロジック実装開始/nippo-add #456 AIが書いたコード動いた。でもなぜRS256なのかわからない/nippo-add なぜ: RS256とHS256の違い/nippo-add 試した: JWTのペイロードに変なデータを入れたらどうなるかポイントは作業中に記録すること。1日の終わりにまとめて書こうとすると、何をやったか思い出せない。その場で書けば、摩擦がない。「なぜ:」「試した:」などのキーワードを入れておけば、後から抽出しやすい。自分がどこで躓いているか、一目でわかる。キーワードは何でもいい。「ハマった:」「理由:」でも、英語で「why:」でも構わない。大事なのは、自分が後から検索しやすく、学習のパターンを把握できること。正解はない。自分にしっくりくる言葉を見つければいい。日報を見返すと、同じ技術で同じ種類の躓きが繰り返されている。非同期処理では「なぜ」がわからない。エラーハンドリングでは「本質」が見えない。新しいライブラリでは「試した」が足りない。繰り返し出てくるということは、その部分で理解が止まっているということだ。弱点が見える。弱点が見えれば、対策が打てる。日報は、学習のガイドになった。日報のキーワードが学習のトリガーここまで、日報を使って躓きを「記録する」方法を説明した。しかし、記録しただけでは学習は起きない。記録は入口に過ぎない。日報に「なぜ:」「試した:」と書いたら、それは学習のトリガーだ。記録して終わりではない。そのまま次に進まない。徹底的にAIと対話する。なぜ「対話する」なのか。ここが重要だ。キーワードで記録した躓きは、「わかっていない」ということだ。わかっていないことを、わかるようにするには、どうすればいいか。自分で調べてもいい。でも、AIがいる。AIは、わからないことを説明してくれる。問題は、AIの説明を受動的に聞くか、能動的に引き出すか、だ。私のルールは単純だ。これらのキーワードを書いたら、その場で最低10分はAIと対話する。10分で理解できなければ、20分かける。理解できるまでやる。次のタスクには進まない。ただ、ここで重要な反論がある。「10分で理解できるわけがない」という反論だ。確かにそうだ。複雑な概念を10分で完全に理解するのは無理がある。でも、重要なのは「10分という制約を設けること」自体にある。制約があるから、「本当にわからないこと」だけに集中できる。制約がなければ、際限なく調べ続けて、結局何も身につかない。では、具体的にどう「徹底的に対話する」のか。ここが最も重要なところだ。「AIと対話する」と言っても、やり方次第で効果は天と地ほど違う。徹底的に対話する技術「AIと対話する」とは具体的にどういうことか。まず、よくある間違いから見てみよう。AIに「答えをもらう」ことと、AIと「徹底的に対話する」ことは、本質的に違う。答えは受動。対話は能動だ。答えをもらう：「このエラーを直して」→ 直るコードが返ってくる → 動く → 終わり。人間側の思考は、ほぼゼロだ。問題を投げて、解決策を受け取る。コピペする。動く。何も考えていない。徹底的に対話する：「このエラーの原因は何？」→「なぜそうなる？」→「他にも同じパターンはある？」→「どう防げる？」。人間側に思考が発生する。質問を組み立てる段階で、自分が何をわかっていないか考える。答えを聞いて、次の質問を考える。このサイクル全体で、脳が動いている。なぜ「教えて」では足りないのか。「教えて」は丸投げだ。AIは何かを返す。でも、それがあなたに必要な説明かどうかわからない。あなたが何を知っていて、何を知らないか、AIには見えない。だから、的外れな説明が返ってくることもある。説明を引き出す側に何が求められるか。自分の理解の輪郭を先に差し出すことだ。「私はここまでわかっている。でも、ここからがわからない」。この輪郭を示すことで、AIは適切な説明を返せる。そして、輪郭を示す行為自体が、すでに学習だ。自分が何をわかっていないか言語化する。これは思考を整理する作業だ。説明を引き出す行為は、どの段階で人間側の思考を必要とするか。最初から最後までだ。何を聞くか考える。聞いた答えを解釈する。次に何を聞くか決める。答えを自分の文脈に当てはめる。このすべてが、能動的な思考だ。答えをもらうだけなら、受動的でいい。説明を引き出すには、能動的でなければならない。なぜ「自分の言葉で書き直す」ことが理解の判定基準になるのか。AIの言葉をそのまま使えるなら、理解していなくてもコピペできる。自分の言葉に置き換えるには、一度、頭の中で「翻訳」する必要がある。翻訳には理解が必要だ。書き直せない説明は、理解ではない。説明できるとはどういう状態か。因果を辿れる状態だ。「なぜこうなるか」を自分の言葉で説明できる。別の人に質問されても、答えられる。説明できるようになって初めて、その知識は「使える」ようになる。この違いは学習速度にどう影響するか。答えをもらい続けると、学習速度はゼロに近づく。説明を引き出し続けると、学習速度は加速する。同じAIを使っても、使い方で学習効果は天と地ほど違う。最初は恥ずかしかった。「こんな基本的なことも知らないのか」と思われるのが怖かった。でも、AIは笑わない。何度聞いても呆れない。AIは、最高の学習パートナーだ。この発見が、学び方を変えた。ステップ1: 自分の理解を言語化するいきなり「教えて」と聞かない。まず自分が何をわかっていて、何がわからないかを言語化する。RS256とHS256について、私の現在の理解を確認させて。私の理解：- 両方ともJWTの署名アルゴリズム- HS256は「対称鍵」を使う（たぶん）- RS256は「非対称鍵」を使う（たぶん）わからないこと：- なぜRS256の方が「セキュア」と言われるのか- どういう場面でどちらを選ぶべきかこの理解は合ってる？こうすることで、AIは私の理解レベルに合わせた説明をしてくれる。輪郭を示す行為自体が、すでに学習だ。ステップ2: 「なぜ」を3回以上繰り返す表面的な理解で終わらせない。本質に到達するまで「なぜ」を繰り返す。なぜJWTの署名にRS256を使うの？→ 「秘密鍵と公開鍵を分離できるから」なぜ分離する必要があるの？→ 「検証側に秘密鍵を渡さなくて済むから」なぜ検証側に秘密鍵を渡すとまずいの？→ 「サービスが増えると秘密鍵を知る場所が増える。1箇所でも漏洩したら全体が危険になる」3回目の「なぜ」あたりから、本質的な理解が始まる。ここで「逆に、HS256を使うべきケースは？」「RS256のデメリットは？」と逆のケースも聞く。正解だけでなく不正解を知ることで、判断基準が明確になる。ステップ3: 自分の言葉で要約するここまで理解したら、AIの説明をコピペせず、自分の言葉で要約する。/nippo-add 振り返り: RS256 vs HS256 を理解した【本質】- HS256 = 共通鍵。署名も検証も同じ秘密を使う- RS256 = 公開鍵暗号。検証側に秘密を渡さなくて済む【使い分け】- モノリス → HS256で十分- マイクロサービス → RS256一択書き直せなかったら、まだ理解していない。もう一度ステップ1から繰り返す。復習のサイクルここまでで、2つのことを説明した。日報で躓きを記録すること。そして、その躓きについてAIと徹底的に対話すること。記録と対話。この2つで、学習は起きるはずだ。でも、実際にやってみると、これだけでは足りなかった。理解しても、忘れる。日報を書いた。AIと対話した。その場では理解した。「ああ、そういうことか」と納得した。でも1週間後、同じことでまた躓いている。「あれ、これ前にも調べなかったか？」。書いただけでは、脳に定着しない。同じ内容を間隔をあけて復習すると、記憶に残りやすい。だから復習のサイクルを作った。翌朝（5分）：前日の日報を見返す。見返すだけでいい。「ああ、これ昨日引っかかったやつだ」と思い出す。思い出す行為自体が、記憶を強化する。実際にやってみると、面白いことが起きた。朝、コーヒーを淹れながら昨日の日報を開く。「RS256とHS256の違い」という項目を見る。「えーと、RS256は公開鍵暗号で...」と頭の中で再生しようとする。すると、昨日は理解したはずなのに、もう曖昧になっている部分がある。忘れかけているタイミングで思い出すことが、記憶を強化する。これを毎朝やるだけで、定着率が全然違う。週末（30分）：その週の日報をまとめて確認。2回以上出てきた項目は、その場でAIと対話して理解を深める。理解できたらチェックを入れる。ある週末、日報を見返していて気づいた。「非同期処理」という項目が、月曜、水曜、金曜と3回出てきている。3回も「なぜ」がわからないと書いているのに、そのたびに次のタスクに進んでいた。繰り返し出てくるということは、その部分の理解が止まっているということだ。その週末、2時間かけてPromiseとasync/awaitを徹底的に理解した。翌週から、非同期処理で詰まることがなくなった。月末（1時間）：月間の傾向分析。3回以上出てきた項目は、根本的な知識の穴だ。書籍を買って体系的に学ぶ。月末の分析で、自分の弱点のパターンが見えてきた。私の場合、「認証・認可」「データベースの最適化」「インフラ周り」が繰り返し出てくる。これは断片的な理解では対応できない。体系的に学ぶ必要がある。だから、月末に1冊ずつ関連書籍を買うことにした。日報は、次に買うべき本を教えてくれる。学んだことは、忘れる。これは避けられない。忘却は敵ではない。思い出せないことが敵だ。日報は「思い出すためのフック」を作る作業だ。完璧に覚えようとしなくていい。戻れる仕組みを作ればいい。人間は意志を保てない。「毎日復習しよう」と決めても、忙しくなれば忘れる。だから仕組みを作る。日報システムは、学習の意志を外部化したものだ。意志に頼らず、習慣に組み込む。学習時間の設計ここまで、日報の書き方、AIとの対話の仕方、復習のサイクルを説明した。方法論は揃った。しかし、ここで当然の疑問が浮かぶ。「いつやるのか？」だ。日報を書く。復習する。わからないことはAIと対話する。週末にまとめて振り返る。どれも時間がかかる。全部やるのは大変そうだ。正直、私もそう思った。会社によっては、学習時間を労働時間としてカウントしてくれるところもある。成果を出すタイミングと学習するタイミングが違っても、それを認めてくれる環境もある。もしそういう会社にいるなら、堂々と労働時間内で学習すればいい。ただ、認めなければならない現実がある。成果を出す時間と、学習する時間は、同時には起きにくくなった。かつて労働は最高の学習だった。しかし今は違う。AIと協働する効率化されたプロセスの中では、学習に必要な「摩擦」が発生しない。タスクは完了する。成果物は出る。それでも、脳には何も残らない。効率の代償は、成長だった。これは構造的な問題だ。だから私は、一度分けることにした。成果を出す時間と学習する時間を、意識的に。成果を出す時間は、AIと一緒に効率よくタスクを消化する。学習する時間は、AIなしで、あるいはAIと徹底的に対話しながら、理解を深める。分けた上で、日報で再接続する。私の1週間はこうなっている。月曜 6:00-6:30：先週の日報を見返す。躓いている項目の中で、今週取り組むべきものを3つ選ぶ。カレンダーに学習時間をブロックする。「今週はこの3つを理解すれば、来週の開発が楽になるはず」。仮説を立て、検証し、修正する。学習も開発と同じだ。水曜 12:00-12:30：昼休みを使って、月曜に選んだ項目を深掘りする。わからないことをAIに問いかけ、徹底的に対話する時間だ。金曜 6:30-8:30：「素手の時間」。AIなしでコードを書く。「AIがあるのに使わないのは非効率だ」という反論があるだろう。確かに、短期的には非効率だ。でも、AIと働き続けていると、基礎力が衰える。使わない筋肉は、静かに萎える。基礎がわかっていれば、AIの出力を評価できる。基礎が怪しければ、動くまでガチャを回すだけになる。この時間にやることは3つある。日報で見つけた躓きをAIなしで調べる。小さなユーティリティ関数を手書きする。エラーメッセージを自力で読み解く。AIに聞けば5分で済むことを、30分かけてやる。この30分が、理解の深さを変える。最初の金曜日、2時間が永遠に感じた。簡単なはずの処理が書けない。「こんなことも自分でできないのか」と、情けなくなった。でも、2時間が終わったとき、達成感があった。自分の手で書いた。久しぶりの感覚だった。AIなしで書いてみると、「本当にわかっていること」と「AIに頼っていたこと」の境界が明確になる。自分の実力が、残酷なほど見える。見えるからこそ、対策が打てる。土曜 朝30分：週の振り返り。3つの項目は理解できたか。理解できなかったものは、来週に持ち越す。完璧を求めない。7割理解できれば、次に進む。最初は週3時間も取れないと思った。でも、試してみると、この3時間で週の残り37時間の労働効率が上がった。学習は消費ではない。複利で回収できる投資だ。理解が深まると、AIへの指示が的確になる。学習への投資は、労働の効率で回収できる。私の場合、成果を出すことと学ぶことが自然には重ならなくなった。だから意識的に交差点を作っている。日報が教えてくれる「次に学ぶべきこと」ここまで、学習の「方法」を説明した。日報で記録する。わからないことはAIと対話して理解を深める。復習する。学習時間を確保する。これで「どう学ぶか」は揃った。しかし、「何を学ぶか」は、まだ説明していない。時間は限られている。何を優先すべきか。闇雲に学んでも、効率が悪い。答えは、日報の中にある。日報を続けていると、躓きのパターンが見えてくる。同じ項目が繰り返し出てくる。認証。非同期処理。データベース。繰り返し出てくるということは、断片的な理解では足りないということだ。そこで、日報をインプットのガイドにする。月末に日報を見返して、3回以上出てきた項目を特定する。それに関連する学習リソースを選ぶ。日報は「次に何を学ぶべきか」を教えてくれる。私の場合、月に技術書を10冊、非技術書を10冊、合わせて20冊前後読んでいる。しかし、これは極端な例だ。最初は月1冊でも十分効果がある。大事なのは冊数ではなく、日報で見つけた躓きに関連する本を選ぶことだ。書籍の良いところは、最低限のクオリティが担保されていることだ。最高のブログは刺さる。でも、最低のブログを引くこともある。書籍は編集者の目を通っている。時間は有限だから、ハズレを引きたくない。日報で繰り返し出てくる躓きを見て、関連する技術書を選ぶ。書籍だけではない。公式ドキュメントやRFC、OSSのソースコードも読む。二次情報で満足せず、一次情報に戻る習慣。これが理解の深さを決める。使っているライブラリの実装を見ると、設計判断の理由がわかる。上級者向けだが、他社の障害報告書も参考になる。ポッドキャストも意外と効く。特にリモートワーカーにおすすめしたい。ちゃんと聞かなくていい。BGMのように流しておくだけでいい。リモートワークを続けていると、雑談が絶望的に下手になる。下手になると、雑談をしたくなくなる。したくなくなると、技術的なことを気軽に話す機会が減る。機会が減ると、間違った理解を指摘してもらえなくなる。悪循環だ。技術系ポッドキャストを聞いていると、エンジニア同士の会話のリズムが耳に残る。話題の引き出しも増える。Xで信用できるアカウントをフォローしておくのもいい。タイムラインを眺めているだけで、今何が話題になっているかがわかる。しかし、Xは使い方が難しい。今やアテンション・エコノミーのど真ん中で、みんなが揉めている。情報収集のつもりが、気づいたら論争を眺めて時間を溶かしていることがある。意識的に距離を取る必要がある。AIに聞けば答えは返ってくる。でも、体系的な理解は書籍や公式ドキュメントでないと得られない。AIは「この問題の解決策」を教えてくれる。書籍は「なぜその解決策が正しいか」を教えてくれる。AIとの協働で生まれた躓きを、AIの外で埋める。あなたの現在地を見つけるためにここまで、私がやってきたことを説明した。日報で躓きを記録する。AIと徹底的に対話する。復習のサイクルを回す。学習時間を確保する。日報から次に学ぶべきことを見つける。インプットを選ぶ。たくさんあるように見えるかもしれない。全部やる必要はない。でも、何かを始める必要はある。ここまで読んでくれたあなたに、問いかけたい。この1週間を振り返ってみてほしい。AIに聞いて解決したけど、なぜその解決策が正しいのか説明できない問題はなかっただろうか。同じ種類の問題に、何度も遭遇していないだろうか。コードは動いた。でも「なぜ動くのか」を同僚に説明できるだろうか。もし1つでも「怪しい」と感じるものがあれば、それがあなたの躓きだ。今日から日報に書き始めてほしい。日報を1週間続けたら、見返してみてほしい。何が繰り返し出てくるか。認証なのか、非同期処理なのか、データベースなのか。繰り返し出てくるものが、次に学ぶべきことだ。そのとき、インプットを意識的に選んでほしい。体系的に理解したいなら書籍。正確な仕様や実装の判断基準を知りたいなら公式ドキュメントやOSSのソースコード。リモートワーカーならポッドキャストもいい。Xで信用できるアカウントをフォローしておくのも悪くない。日報が「次に何を学ぶべきか」を教えてくれる。インプットは、日報を見て選ぶ。AIに聞けば答えは返ってくる。でも、「なぜその答えが正しいか」を理解するのは、AIの外でやる仕事だ。日報は、その仕事を始める場所を教えてくれる。おわりにここまで、私がやってきたことをすべて説明した。日報、AIとの対話の技術、復習のサイクル、学習時間の設計、インプットの選び方。これらは、私がAI時代に「学ぶ」ために見つけた方法だ。最後に、1つだけ伝えたいことがある。この記事で一番大事なことだ。ここまで読んで、気づいた人もいるだろう。私はCLAUDE.mdに学びを書き込んでいる。プロジェクトの文脈、コーディング規約、過去に得た知見。では、AIは賢くなっているのか。答えはNoだ。AIは何も学んでいない。CLAUDE.mdに書かれた内容は、セッションの最初に読み込まれる。でも、それは「学習」ではない。ただの「入力」だ。AIは前回の会話を覚えていない。経験を蓄積しない。「わからない」を経験しない。AIは、このブログが警告している「学ばない労働者」そのものだ。CLAUDE.mdを充実させれば、AIの出力は変わる。使い込むほど手に馴染む道具にはなる。でも、設定を書いたのは誰か。あなただ。試行錯誤したのは誰か。あなただ。AIが賢くなったように見えるのは、あなたが賢くなったからだ。学習とは、経験を意味に変換する行為だ。これが、この記事を通じて私がたどり着いた核心だ。AIは情報を処理できる。でも、AIにとってそれは「意味」を持たない。人間は違う。経験が意味になる。「あのバグを直した」という経験が、「自分はできる」という自信になる。経験を意味に変換できるのは、人間だけだ。AIと協働しながらも、熟達する主体であり続けるために必要な設計がある。遊びの時間を確保すること。目的のない探索がないと、好奇心が死ぬ。「わからない」状態を意図的に作ること。AIに聞けばすぐわかる。でも、あえて聞かない時間が思考力を維持する。記録を習慣にすること。書かないと忘れる。説明を練習すること。説明できなければ、理解していない。「素手」で戦う時間を持つこと。AIなしでコードを書く時間が、基礎力を維持する。これらに共通するのは、摩擦・記録・言語化だ。摩擦が経験を生む。記録が経験を残す。言語化が経験を意味に変える。AIはこの3つを肩代わりしてくれる。だから楽になる。でも、肩代わりさせると、人間は主体でなくなる。最後に、もう一度聞かせてほしい。あなたは最近、「成長している」と感じているだろうか。もし少しでも不安があるなら、今日から日報を開いてみてほしい。「なぜ:」「試した:」と書いてみてほしい。たった1行、それだけでいい。完璧な日報を書く必要はない。その不完全な1行が、次の1行を呼ぶ。そして、その積み重ねがあなたの脳を取り戻す。3日で挫折するだろう。私自身、何度も挫折した。でも、4日目にまた始めればいい。何度でもやり直せる。完璧に続けることより、何度でも再開できることの方が大事だ。1ヶ月後、あなたは変わっている。同僚に「この実装、どうしてこうしたの？」と聞かれたとき、淀みなく答えられる自分がいる。障害が起きたとき、自分のコードを頭の中でトレースできる自分がいる。日報を見返すと、「なぜ:」で埋まっていた項目が、少しずつ減っている。それが、成長の証だ。あなたの脳は、取り戻せる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon学びをやめない生き方入門作者:中原淳,パーソル総合研究所,ベネッセ教育総合研究所テオリアAmazon私たちはどう学んでいるのか: 創発から見る認知の変化 (ちくまプリマー新書 403)作者:鈴木 宏昭筑摩書房Amazonシン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon夏蜜柑とソクラテス作者:新井 紀子草思社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[最近読んでいて興味深かった記事紹介 Vol.4]]></title>
            <link>https://zenn.dev/akasan/articles/interesting_tech_blog_4</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/interesting_tech_blog_4</guid>
            <pubDate>Tue, 16 Dec 2025 13:14:53 GMT</pubDate>
            <content:encoded><![CDATA[今回で4回目の、最近読んで気になっている記事紹介になります！年末に向けて色々読んでいきたいので、最近見たものを紹介できればと思います！過去の記事は以下に載っていますので、ご興味ある方は是非ご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Docker MCP Gateway:エージェントAIのためのオープンソースの安全なインフラストラクチャ私自身あまりMCPを利用できていないのが現状なのですが、dockerを利用してMCPをうまく運用するための方法をキャッチアップするために見ています！https://www.docker...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[地球規模の「時間のずれ」を Cloud Spanner はどう解決したか]]></title>
            <link>https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</link>
            <guid isPermaLink="false">https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</guid>
            <pubDate>Tue, 16 Dec 2025 01:39:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake 事業部の芳賀雅樹 (@silasolla) です．普段はアプリケーションの開発支援を担当していますが，今回はその基盤となるデータベースの裏側の仕組みが気になり，深掘りしてみました． 早速ですが，G […]The post 地球規模の「時間のずれ」を Cloud Spanner はどう解決したか first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代の異常系テストについて考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</guid>
            <pubDate>Tue, 16 Dec 2025 01:22:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに深夜2時、本番環境のアラートが鳴り響きます。外部APIがタイムアウトを返し始め、リトライが暴発し、システム全体が連鎖的に停止しました。原因を調べると、外部サービスの一時的な遅延でした。たった数秒の遅延が、なぜシステム全体を止めたのか。答えは単純です。「外部APIが遅延したらどうなるか」を、誰もテストしていなかったからです。私自身、このような障害を何度か経験してきました。コードをマージした翌朝にSlackが炎上していたこともあります。「なぜこのケースを考えなかったのか」と自分を責めながら、ホットフィックスを書いた夜もあります。そのたびに思います。あのとき、たった1つのテストを書いていれば。これは「異常系テスト」の不足が引き起こした障害です。正常系のテストは比較的書きやすいです。入力があり、期待する出力があり、それを検証します。しかし、プロダクション環境で本当に問題になるのは異常系です。ネットワークが切断されたとき、システムはどう振る舞うべきか。データベースがタイムアウトしたとき、ユーザーには何を伝えるべきか。想定外の入力が来たとき、エラーメッセージは適切か。こうした問いに答えるのが、異常系テストです。そして今、この異常系テストの世界が大きく変わりつつあります。2024年、AIがOpenSSLに20年間潜伏していた脆弱性を発見しました。人間が書いたファジング（ランダムなデータを入力してバグを探す手法）では見つけられなかった欠陥です。Google OSS-FuzzはAIによるファズターゲット生成で26件の脆弱性を発見し、既存の人間作成ターゲットから最大29%のカバレッジ向上を実現しました。人間だけでは見つけられなかった異常を、AIが発見する時代になりました。本記事では、この変化を踏まえて異常系テストの考え方をまとめました。まず基本的な技法を押さえ、その上でAIやカオスエンジニアリングといったものを紹介します。あの深夜のアラートを、未来の自分や読者が経験しなくて済むように。本題に入る前に本記事を読む前に、いくつか断っておきたいことがあります。私はテストの専門家ではありません。日々コードを書きながら、「この処理が失敗したらどうなるだろう」と考える、一人のエンジニアです。ここに書いてあることは、思いついたものをまとめただけなので不足もあるでしょう。実装しながら単体テストやエラーハンドリングを考える際のヒントとして使ってもらえればと思います。もう一つ、大事なことがあります。すべてのパターンをテストする必要はありません。過度なテストパターンは無駄な工数を生むだけではありません。テストが増えれば増えるほどCIの実行時間は長くなり、開発サイクルは遅くなります。テストコードを読んで理解するにも認知コストがかかります。テストが多すぎると、「このテストは何を確認しているのか」を把握するだけで疲弊してしまいます。テストのROI（投資対効果）を意識し、リスクの高い箇所に集中することが重要です。とはいえ、最近は生成AIのモデル精度が上がったおかげで、文脈を読み取ってテストコードを生成してくれるようになりました。「何をテストすべきか」を判断し、AIに生成を任せる。その使い分けが、今のエンジニアに求められています。そして、ここが難しいところなのですが、異常系テストがどれくらい必要かは、その人の経験に大きく依存します。本番障害で痛い目を見た人は「ここまでテストすべきだ」と感じます。幸運にも大きな障害を経験していない人は「そこまでやる必要があるのか」と思います。これは良い悪いではなく、思考の枠組みそのものが異なるのです。だからこそ、チームとして、組織として「どこまでの異常を許容するのか」を明確にしておく必要があります。暗黙の了解ではなく、言語化する。そうしないと、「テストが多すぎる」「テストが足りない」という不毛な議論が続くことになります。では、本題に入りましょう。異常系テストとは異常系テストとは、システムが想定外の状況に遭遇したとき、適切にエラーハンドリングできるかを検証するテストです。正常系テストが「うまくいくパス」を確認するのに対し、異常系テストは「うまくいかないパス」を確認します。異常系と一口に言っても、その原因はさまざまです。「どこから異常が来るか」という視点で整理すると、4つの観点に分けられます。入力値の異常: ユーザーやクライアントから来ます。空文字、境界値超過、不正な形式など状態の異常: システム内部のデータに起因します。リソースが見つからない、すでに処理済み、権限不足など環境の異常: 外部依存に起因します。ネットワーク障害、DB接続失敗、ディスク容量不足など競合の異常: 並行処理に起因します。同時更新、デッドロック、レースコンディションなどこの順番には意味があります。入力値の異常は最も頻繁に発生し、テストも書きやすいです。状態の異常はビジネスロジックと密接に関わります。環境の異常はテストが難しいですが、本番では必ず起きます。競合の異常は最も見つけにくく、再現も難しいです。つまり、テストの書きやすさと、問題の発見しにくさは、おおむね逆の関係にあります。それぞれについて見ていきましょう。入力値の異常フォームに全角スペースだけを入力して送信したら、システムがエラーを吐いた。そんな経験はないでしょうか。あるいは、絵文字を含む名前を登録しようとしたら、データベースエラーが返ってきた。ユーザーは悪意を持っていたわけではありません。ただ、開発者が「想定していなかった」だけです。どれだけ想像力を働かせても、ユーザーは必ずその想像の外側から来ます。ユーザーからの入力は信用できません。これはセキュリティの基本原則ですが、テストにおいても同様です。境界値分析（Boundary Value Analysis）境界値分析は、ソフトウェアテストの古典的な技法です。入力値の境界付近でエラーが発生しやすいという経験則に基づいています。# 例: 文字数制限が255文字の場合- 255文字 → 成功するべき- 256文字 → エラーになるべき- 0文字（空文字） → 要件によるよくある境界値のテストケース：最大値・最小値最大値+1・最小値-1ゼロ負の値（許可されていない場合）この技法は同値分割法（Equivalence Partitioning）と組み合わせて使うことが多いです。同値分割法では、入力値を「同じ振る舞いをするグループ」に分割し、各グループから代表値を選んでテストします。たとえば「1〜255文字」「256文字以上」「0文字」の3グループに分け、それぞれの代表値と境界値をテストします。現代のAPI開発では、境界値分析の対象は数値入力を超えて拡張されています。APIのページネーション制限（page size=99, 100, 101）、リクエストペイロードサイズ制限、タイムアウト閾値、レートリミットの境界などが現代的なBVA対象です。空値の扱い境界値の中でも、特に扱いが難しいのが「空」という概念です。空値の扱いは設計上の判断が必要になります。 値  検討ポイント  空文字 ""  許容するか、エラーにするか  スペースのみ "   "  トリムするか、エラーにするか  NULL  必須項目か、オプショナルか  undefined  デフォルト値を使うか テストを書くことで、こうした設計の曖昧さが明確になることがあります。「空文字を許容するか」という問いに対して、チームで合意を取る機会になります。ここで気づくべき重要なことがあります。異常系テストの気付きにくい価値は、バグを見つけることではありません。設計を問い直すことです。「この入力が来たらどうするか」という問いを立てることで、仕様の穴が見えます。テストを書く行為そのものが、システムの堅牢性を高めています。テストが通るかどうかは、実は二次的な問題なのです。文字種と特殊文字空値に続いて、もう一つ厄介なのが文字種です。日本語を扱うシステムでは、文字種のテストが特に重要になります。カタカナ・半角カタカナ環境依存文字（㈱、①など）サロゲートペア（𠮷野家の「𠮷」など）絵文字これらの文字が入力されたとき、システムがどう振る舞うかを確認します。データベースの文字コード設定やAPIのエンコーディングによっては、予期しない動作をすることがあります。セキュリティ関連の入力ここまでは「意図しない入力」の話でした。しかし、世の中には「意図的に悪意のある入力」を送りつけてくる人もいます。セキュリティ関連の入力値テストは、インジェクション攻撃（悪意のあるコードを入力に紛れ込ませる攻撃）への耐性を確認します。OWASP Testing Guideは、このようなセキュリティテストの標準的な指針を提供しています。XSS（クロスサイトスクリプティング）: <script>alert('XSS')</script> — Webページに悪意のあるスクリプトを埋め込む攻撃SQLインジェクション: '; DROP TABLE users;-- — データベースを不正に操作する攻撃コマンドインジェクション: ; rm -rf / — サーバーで不正なコマンドを実行させる攻撃パストラバーサル: ../../../etc/passwd — 本来アクセスできないファイルを読み取る攻撃インジェクション攻撃への対策はセキュリティテストの領域でもありますが、異常系テストとして「不正な入力が来たときにシステムが適切にエラーを返すか」を確認しておくことは重要です。エラー推測（Error Guessing）という経験ベースの技法も有効です。過去のバグ傾向から共通パターン（NullPointerException、ゼロ除算、日時パース問題など）を識別し、重点的にテストします。AIとファジングによる入力値テストここまで紹介した技法は、人間がテストケースを考えるものでした。しかし、人間の想像力には限界があります。そこで注目されているのが、ランダムな入力を自動生成してバグを探すファジング（Fuzzing）です。冒頭で触れたGoogle OSS-FuzzのAI活用は、まさにこの領域での成果です。AIが生成したファズターゲットにより26件の脆弱性が発見され、OpenSSLに20年間潜伏していた欠陥も見つかりました。人間が「こういう入力が来るかも」と想像する範囲を超えて、AIが異常な入力パターンを生成します。www.theregister.comもう一つ、Property-based testing（性質ベーステスト）という手法も企業での採用が加速しています。従来のテストは「入力Aに対して出力Bが返る」という具体的なペアを書きます。Property-based testingでは「どんな入力に対しても、この性質が成り立つ」という形で定義します。たとえば「リストをソートして逆順にしても、要素数は変わらない」といった性質です。Python向けのHypothesisは週間300万ダウンロードを超え、numpyやastropyなどの科学ライブラリでバグを発見した実績があります。QuickCheck（Haskell）、fast-check（JavaScript）、proptest（Rust）など、各言語でエコシステムが成熟しています。入力値の異常は、ユーザーから直接来るものでした。次に見るのは、システムの内部で起きる異常です。状態の異常「さっきまで動いていたのに」。この言葉に覚えはないでしょうか。ユーザーが画面を開いている間に、別のユーザーがデータを削除します。システムの状態は常に変化しています。画面に表示された瞬間、それはもう過去です。リソースの状態に関するテストでは、以下のようなケースを考慮します。存在しないリソース存在しないIDでアクセスしたときに、適切なエラー（404 Not Foundなど）が返ることを確認します。削除済みリソース削除されたリソースに再度アクセスしたときの動作を確認します。ユーザーがブックマークしていたページが、管理者によって削除されていた。よくある話です。「404 Not Found」で終わりなのか、「このコンテンツは削除されました」と丁寧に伝えるのか。論理削除と物理削除では挙動が異なります。論理削除なら「削除済み」というステータスを返せます。物理削除ならレコード自体が存在しないため、404を返すことになります。どちらの設計を採用しているかで、テストの期待値も変わります。処理中のリソース処理中（アップロード中、変換中など）のリソースにアクセスしたときの動作を確認します。「まだ準備ができていない」ことをクライアントに適切に伝えられるか。不正な状態遷移状態遷移が定義されているシステムでは、不正な遷移を試みたときの動作を確認します。# 例: 注文のステータス遷移作成 → 確定 → 発送 → 完了# 不正な遷移作成 → 完了（確定と発送をスキップ）完了 → 作成（逆方向の遷移）入力値の異常、状態の異常は、どちらもアプリケーション内部の話でした。しかし、システムは単独で動いているわけではありません。次は、システムの外側から来る異常を見ていきます。環境の異常環境の異常は、テストが最も難しい領域です。開発環境では再現しにくいですが、プロダクション環境では必ず発生します。ローカルで動いたからといって、本番で動く保証はありません。開発環境は、ある意味で嘘をつきます。ネットワークは常に安定し、データベースは常に応答し、ディスクは無限にあります。そんな理想的な環境でテストしても、現実の障害には備えられません。だからこそ、どういう異常が起こりうるかを知っておくことが重要です。近年ではChaos Engineering（カオスエンジニアリング）という手法が注目されています。Netflixが提唱したこのアプローチでは、本番環境に意図的に障害を注入し、システムの回復力を検証します。AWS Fault Injection ServiceやAzure Chaos Studioといったクラウドサービスも登場しています。これは上級者向けの手法ですが、まずは以下のような基本的な異常パターンを理解しておきましょう。ネットワーク障害通信経路の遮断タイムアウトオンライン→オフラインの遷移対応方法としては、タイムアウト設定、リトライ、サーキットブレーカーなどがあります。サーキットブレーカーとは、外部サービスへのリクエストが連続して失敗したとき、一時的にリクエストを遮断する仕組みです。電気のブレーカーが過電流を検知して回路を遮断するのと同じ発想で、障害の連鎖を防ぎます。データベース障害DB応答不可コネクションプール枯渇デッドロック対応方法としては、コネクションプールの適切な設定、リトライ、タイムアウトなどがあります。外部サービス障害API応答不可レートリミット予期しないレスポンス形式対応方法としては、サーキットブレーカー、フォールバック、キャッシュなどがあります。リソース枯渇ディスク容量不足メモリ不足ファイルディスクリプタ枯渇リソース枯渇は、テストで再現するより監視とアラートで早期に検知する方が現実的です。とはいえ、リソースが枯渇したときにシステムがどう振る舞うか（gracefulに停止するか、エラーメッセージを出すか）は、設計段階で決めておく必要があります。カオスエンジニアリングの実践「本番環境に障害を注入する？ 正気か？」。最初は誰もがそう思います。しかし、問いを変えてみましょう。「本番で障害が起きたとき、それが予期せぬものであることと、計画されたものであること、どちらがマシか？」カオスエンジニアリングの市場規模は2025年に23.6億ドル、2030年には35.1億ドルに達すると予測されています。もはやニッチな手法ではなく、エンタープライズ標準になりつつあります。www.mordorintelligence.comKubernetes環境ではLitmusChaosとChaos Meshが代表的なツールです。LitmusChaosはCNCFインキュベーティングプロジェクトとして活発に開発が続いています。Chaos MeshはPodChaos、NetworkChaos、IOChaos、StressChaosなど多様な障害タイプを提供します。hub.litmuschaos.ioGameDay（計画的なカオス実験演習）の実践も広がっています。まず最小の爆発半径（障害の影響範囲）から開始し、単一コンテナ→サービス→ゾーンと段階的にスケールアップします。本番環境を最初のターゲットにしてはなりません。レジリエンスパターン環境の異常に備えるには、コードにレジリエンスパターンを組み込む必要があります。先に紹介したサーキットブレーカーに加え、以下のパターンが重要です。Bulkhead（バルクヘッド）: 船の隔壁のように、リソースを区画化して一部の障害が全体に波及することを防ぎますRetry with Exponential Backoff（指数バックオフ付きリトライ）: 失敗したら1秒後、2秒後、4秒後…と間隔を広げてリトライします。リトライストームを防止しながら一時的障害から回復しますこれらのパターンを実装したら、カオスエンジニアリングで実際に障害を注入し、期待通りに動作するか検証します。パターンを実装しただけでは不十分で、テストして初めて信頼できます。ここまで、入力値、状態、環境の異常を見てきました。最後に残るのは、最も厄介な異常です。複数のユーザーが同時にシステムを使うときに起きる問題、競合の異常です。競合の異常「ローカルでは動いたのに」。開発者なら誰もが経験するこの言葉の裏には、しばしば競合の問題が潜んでいます。開発環境では自分一人しかアクセスしません。しかし本番環境では、何百人ものユーザーが同時にボタンを押します。本番は、常に渋滞しています。その渋滞の中で、単体テストでは見えなかった問題が姿を現します。複数のユーザーやプロセスが同時にリソースにアクセスすると、競合が発生しえます。これは単体テストでは見つけにくく、負荷テストや本番環境で初めて発覚することも多いです。だからこそ、「競合が起きたらどうなるか」を事前に設計しておくことが重要です。同時更新典型的なシナリオを考えてみましょう。1. ユーザーAがデータを取得2. ユーザーBが同じデータを取得3. ユーザーAが更新を実行4. ユーザーBが更新を実行 → どうなるべきか？ユーザーBの更新時点で、データはすでにユーザーAによって変更されています。このとき、システムはどう振る舞うべきでしょうか。主な対応方法は3つあります。楽観的ロック: データ取得時にバージョン番号を記録し、更新時に照合します。バージョンが変わっていれば「誰かが先に更新した」と判断し、後から更新しようとした側にエラーを返します悲観的ロック: 更新する意思を示した時点で排他ロックを取得し、他者は同じデータを更新できなくなります。確実ですが、ロック待ちによる遅延が発生しえます最後の更新が勝つ: 競合を検出せず、後から来た更新で上書きします。シンプルですが、先の更新は失われますどの方法を採用するかは、ビジネス要件によります。在庫数のように「先の更新が失われると困る」データには楽観的ロックか悲観的ロック、ユーザーのプロフィールのように「最新の状態が正」でよいデータには最後の更新が勝つ方式、といった使い分けになります。ボタン連打UIにおいて、ユーザーがボタンを連打した場合の動作を確認します。「送信ボタンを押したけど反応がない。もう一度押そう」。ユーザーは待ってくれません。ネットワークが遅いとき、ボタンが反応しないとき、人は本能的に連打します。「購入する」ボタンを連打したら2回購入されてしまった、という事故は避けたいところです。対応方法としては、デバウンス（一定時間内の連続クリックを1回とみなす）や、送信中はボタンを無効化する二重送信防止の仕組みがあります。サーバー側でも、同一リクエストを検出するためにリクエストIDを使った冪等性の担保を検討します。ここまで、4種類の異常（入力値、状態、環境、競合）を見てきました。これらの異常が発生したとき、システムは何らかのエラーを返す必要があります。では、どのようなエラーを返すべきでしょうか。次は、エラーレスポンスの設計について考えていきます。エラーレスポンスの設計異常系テストでは、「エラーが起きないこと」ではなく「適切なエラーが返ること」を検証します。エラーレスポンスの設計は、クライアント側のエラーハンドリングに大きく影響します。適切なエラーを返せば、呼び出し側は何が起きたかを判断し、適切に対処できます。ステータスコードの使い分けステータスコードとは、サーバーがクライアント（ブラウザやアプリ）に返す3桁の数字です。この数字を見れば、リクエストが成功したのか、失敗したのか、何が原因なのかが分かります。HTTPの場合：400 Bad Request: 入力値が不正401 Unauthorized: 認証失敗（ログインが必要）403 Forbidden: 権限不足（ログイン済みだがアクセス権がない）404 Not Found: リソースが存在しない409 Conflict: 競合（同時更新など）429 Too Many Requests: レートリミット（リクエストが多すぎる）500 Internal Server Error: サーバー内部エラー503 Service Unavailable: サービス利用不可（メンテナンス中など）gRPCの場合（gRPCはGoogleが開発した高速な通信方式）：INVALID_ARGUMENT: 入力値が不正NOT_FOUND: リソースが存在しないALREADY_EXISTS: リソースが既に存在FAILED_PRECONDITION: 前提条件不成立PERMISSION_DENIED: 権限不足RESOURCE_EXHAUSTED: リソース枯渇セキュリティ観点でのエラー設計他ユーザーのリソースへのアクセスには、エラーコードの選び方に注意が必要です。ここには、多くの開発者が見落としている盲点があります。素直に考えると、「存在するが権限がない」なら403 Forbiddenを返したくなります。HTTPの仕様としては正しいです。しかし、これには問題があります。攻撃者がIDを総当たりで試したとき、403が返れば「このIDのリソースは存在する」と分かってしまいます。つまり、正しいエラーコードを返すことが、セキュリティホールになるという逆説です。そこで、他ユーザーのリソースへのアクセスには404 Not Foundを返すという設計があります。「存在するが権限がない」と「存在しない」を区別できないようにすることで、攻撃者に情報を与えません。GitHubのプライベートリポジトリも、この設計を採用しています。権限のないリポジトリにアクセスすると、「存在しない」と表示されます。これは「嘘をつく」のではなく、「必要以上の情報を与えない」という設計です。エラーメッセージは親切であるべきですが、攻撃者にも親切である必要はありません。異常の種類と、返すべきエラーレスポンスが分かりました。では、実際にどうやってテストを書けばいいのでしょうか。ここからは、異常系テストの書き方について説明します。テストの書き方期待するエラーの検証異常系テストで最も基本的なのは、「期待するエラーが返ること」の検証です。正常系では「期待する結果が返ること」を確認しますが、異常系では「期待するエラーが返ること」を確認します。# 例: 存在しないリソースへのアクセスで404が返ることを検証def test_get_not_found():    response = client.get("/resources/nonexistent-id")    assert response.status_code == 404テストの独立性各テストは独立して実行できるようにします。テスト間でデータを共有しません。# テストごとに一意のIDを使用TEST_ID="test-$(date +%s)"クリーンアップテスト終了後は作成したリソースを削除します。テストデータが残っていると、次回のテスト実行に影響を与える可能性があります。テストピラミッドにおける異常系テストMike Cohnの伝統的なテストピラミッド（ユニット→インテグレーション→E2E）では「各要件に対し少なくとも2つのテスト、1つは正常系、1つは異常系」が原則です。Kent C. Doddsの「Testing Trophy」モデルでは、インテグレーションテストを重視します。「テストがソフトウェアの使用方法に似ているほど、より多くの信頼を与える」という原則のもと、インテグレーションテストはユニットテストが見逃すエラー（コンポーネント間の相互作用問題）を捕捉します。AIによるテスト生成「テストケースを考えるのが面倒」「どこまでカバーすればいいか分からない」。そんな悩みを抱えたことはないでしょうか。AIによるテスト生成は、この問題に一つの解を与えます。NVIDIAのHEPHフレームワークはLLM（大規模言語モデル）を用いてドキュメントからテストを自動生成します。Diffblue CoverはJavaコードの静的解析からユニットテストを生成します。qodo（旧Codium）はコード動作を分析してエッジケースを含むテストケースを生成します。これらのツールはエラーシナリオ、境界条件、例外処理パスを自動的に導出します。ただし、AIが生成したテストをそのまま使うのは危険です。「何をテストすべきか」の判断は人間がすべきであり、AIはその実装を支援するツールに過ぎません。テストの質を検証する：Mutation Testingテストを書きました。カバレッジも高いです。しかし、そのテストは本当にバグを見つけられるのでしょうか。Mutation testing（変異テスト）は、コードに意図的なバグを埋め込み、テストがそれを検出できるか評価する手法です。たとえばif (x > 0)をif (x >= 0)に変更します。この変更をテストが検出できなければ、そのテストには穴があります。PITest（Java）、Stryker Mutator（JS/TS/C#）、cargo-mutants（Rust）などのツールがCI/CDへの統合を進めています。cargo-mutantsはRustConf 2024で発表され、ソースコード変更なしで任意のRustプロジェクトに適用できます。 speakerdeck.com異常系テストの優先順位すべての異常をテストする時間はありません。リスクベースで優先順位をつけます。Priority 1（毎スプリント）: セキュリティ敏感入力（SQLインジェクション、XSS）、金融・トランザクション操作、認証・認可障害Priority 2（毎リリース）: コアビジネス機能のエラーパス、統合ポイント障害、境界値違反Priority 3（定期テスト）: 複雑なエラーハンドリングフロー、二次機能のエッジケースPriority 4（メジャーリリース前）: 安定したレガシー機能、低トラフィック機能のエラーハンドリングまとめ異常系テストは「何が起きたら困るか」を事前に洗い出し、システムが適切に対処できることを検証する作業です。本記事で紹介した内容を振り返ると、以下の5点が重要になります。すべてをテストする必要はない - リスクの高い箇所に集中します。テストにもROIがあります。チームで「どこまでの異常を許容するか」を言語化しておきましょうAIとツールを活用する - ファジング、Property-based testing、Mutation testingなど、人間の想像力を超える異常を発見する手法があります。AIによるテスト生成も現実的な選択肢になりました環境の異常にはカオスエンジニアリング - 本番環境で必ず起きる障害を、事前に計画して注入します。レジリエンスパターン（サーキットブレーカー、バルクヘッド、指数バックオフ）を実装し、実際にテストしますセキュリティ観点を忘れない - エラーメッセージやエラーコードが情報漏洩につながることがあります。403と404の使い分けはその典型例ですテストを書くことで設計が明確になる - 「空文字を許容するか」「同時更新をどう扱うか」といった曖昧だった仕様が、テストを書く過程で具体化されます異常系テストは面倒に感じることもあります。しかし、プロダクション環境で障害が発生してから対処するコストに比べれば、事前にテストを書くコストは安いです。深夜2時のアラート対応、原因調査、ホットフィックス、ポストモーテム。そのすべてを、1つのテストが防いでくれることがあります。障害が起きたら、その教訓をテストとして残す。それが本当の意味での振り返りです。異常系テストは、将来の自分を助けるための投資です。3ヶ月後の深夜2時、アラートが鳴らなかったとき、過去の自分へ感謝するでしょう。明日からできること大げさに考える必要はありません。次にコードを書くとき、1つだけ試してみてください。「この処理が失敗したら、何が起きるか」を考える。その問いを立てるだけで、異常系テストは始まっています。APIを呼ぶコードを書いたら、「このAPIがタイムアウトしたらどうなるか」と考えます。データベースに保存するコードを書いたら、「保存に失敗したらどうなるか」と考えます。その問いに対する答えをテストとして書く。それだけでいいのです。完璧を目指す必要はありません。昨日より1つだけ、システムを堅牢にする。その積み重ねが、深夜のアラートを1回減らし、ユーザーの信頼を1つ守ります。今日書いた1つのテストが、3ヶ月後の深夜2時を救います。AIがテスト生成を支援してくれる時代だからこそ、この「問いを立てる力」は人間にしかできない価値になります。3ヶ月後の深夜2時。あなたのスマートフォンは静かなままです。アラートは鳴りません。それは偶然ではありません。過去のあなたが書いた1つのテストが、その夜の安眠を守っています。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料ソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonソフトウェアテスト技法練習帳 ~知識を経験に変える40問~作者:梅津 正洋,竹内 亜未,伊藤 由貴,浦山 さつき,佐々木 千絵美,高橋 理,武田 春恵,根本 紀之,藤沢 耕助,真鍋 俊之,山岡 悠,吉田 直史技術評論社Amazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon知識ゼロから学ぶソフトウェアテスト 第3版 アジャイル・AI時代の必携教科書作者:高橋 寿一翔泳社Amazonフルスタックテスティング【リフロー型】 10のテスト手法で実践する高品質ソフトウェア開発作者:Gayathri Mohan翔泳社Amazonソフトウェア品質保証入門: 高品質を実現する考え方とマネジメントの要点作者:保田 勝通,奈良 隆正日科技連出版社Amazonソフトウェア品質保証の極意 ―経験者が語る、組織を強く進化させる勘所―オーム社Amazon生成AIによるソフトウェア開発 ―設計からテスト,マネジメントまでをすべて変革するLLM活用の実践体系―オーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Spanner の記事を書きました (+ 技術的な蛇足)]]></title>
            <link>https://silasol.la/posts/2025-12-16-01_cloud-spanner/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2025-12-16-01_cloud-spanner/</guid>
            <pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Cloud Spanner のコアアーキテクチャについて，職場の Tech Blog 補足と技術的な余談 (Paxos, CAP 定理, NewSQL) をまとめました．]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[クラウド破産回避ガイド - AWSコスト管理の実践]]></title>
            <link>https://zenn.dev/r4ynode/articles/aws-cost-management</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/aws-cost-management</guid>
            <pubDate>Mon, 15 Dec 2025 22:00:06 GMT</pubDate>
            <content:encoded><![CDATA[要約AWSのコスト管理は「Billing and Cost Management」の機能を知るところから「AWS Budgets」も良いけど、「AWS Cost Anomaly Detection」も一緒に使うといいよ原因調査は、、がんばろう、、、（頑張るTipsは紹介します） はじめにAWSを利用し、高額な請求が来てクラウド破産する方々を見かけます。きっとこれからもそのような経験をする方は絶えないでしょう。原因としてサービスの多さやクラウドの料金体系の複雑さが挙げられます。これを真に理解するには時間を要し面倒に思えますが、すべてを理解しなくても事前に対策することは容...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PostgreSQLのインデックス作成におけるパラメータの影響の調査]]></title>
            <link>https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation</link>
            <guid isPermaLink="false">https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation</guid>
            <pubDate>Mon, 15 Dec 2025 15:43:00 GMT</pubDate>
            <content:encoded><![CDATA[このブログは3-shake Advent Calendar 2025 およびPostgreSQL Advent Calendar 2025のクロスポストです。PostgreSQLのインデックス作成のパフォーマンスには下記の2つのパラメータが特に大きく影響する。maintenance_work_memほとんどのインデックスメソッドにおいて、インデックス作成速度はmaintenance_work_memの設定に依存します。 より大きな値を設定すると、インデックス作成に必要となる時間が短縮されます。 ただし、実際に使用できるメモリ量を超えるほど大きくすると、マシンがスワップ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Langfuseに入門しないか？ ~ローカルホストで使ってみよう~]]></title>
            <link>https://zenn.dev/akasan/articles/langfuse_localhost</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/langfuse_localhost</guid>
            <pubDate>Mon, 15 Dec 2025 12:39:39 GMT</pubDate>
            <content:encoded><![CDATA[今回からLangfuseも取り扱っていこうと思います。Langfuseを利用することで、LLMの挙動をトレースすることができます。 Langfuseとは？Langfuseは、オープンソースのLLMエンジニアリングプラットフォームです。チームがLLMアプリケーションを共同でデバッグや分析、反復開発するのを支援してくれます。また、プラットフォームのすべての機能はネイティブに統合されており、開発ワークフローを加速します。Langfuseはオープンで、セルフホスト可能、そして拡張性に優れています。https://langfuse.com/docs主なインテグレーションについては以下にま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、戦略を語れ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/15/130000</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/15/130000</guid>
            <pubDate>Mon, 15 Dec 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに会議室で誰かが「戦略」と言った瞬間、空気が変わる。みんなの背筋が伸びる。うなずきが深くなる。誰かがおもむろにホワイトボードの前に立ち、矢印を描き始める。私も「なるほど」という顔をしてみる。眉間にしわを寄せ、顎に手を当て、いかにも深く考えているふうを装う。会議室にいる全員が、突然「戦略を理解している側の人間」になる。ただ、私は知っている。この部屋にいる何人かは、私と同じことを思っているはずだ。「で、結局、何をするの？」言えない。絶対に言えない。「戦略」という言葉が持つ重厚感に押しつぶされて、そんな素朴な疑問は喉の奥に引っ込んでしまう。分かっていないことがバレたら終わりだ。「あいつ、戦略を理解していない」というレッテルを貼られたら、もうこの会議室での発言権はない。だから黙る。黙って、賢そうな顔を続ける。不思議なのは、誰もが同じ演技をしているように見えることだ。部長も、課長も、隣に座っている同僚も。みんな「戦略」という言葉に真剣な顔で向き合っている。でも、その「真剣な顔」は、本当に理解しているから出てくる表情なのだろうか。それとも、理解していないことを悟られないための防衛反応なのだろうか。私には、区別がつかない。会議が終わると、みんな自分のデスクに戻っていく。誰も「さっきの戦略、よく分からなかったね」とは言わない。私も言わない。言ったら負けだ。何に負けるのかは分からないけど、とにかく負ける気がする。だから、分かったふりを続ける。これは、そういう自分への苛立ちから始まった文章だ。「戦略的に考えろ」と言われるたびに、心の中で「戦略的って何だよ」と毒づいてきた。でも調べなかった。調べるのが怖かった。調べて、やっぱり分からなかったらどうしよう。そんな不安があった。聞くこともできなかった。「戦略って何ですか」なんて質問は、新卒1年目ならまだ許される。でも、何年も働いてきた人間が今さら聞けるわけがない。だから分かったふりを続けてきた。その居心地の悪さを、いい加減どうにかしたかった。だからこの文章を書いている。誰かのためではない。自分のためだ。「おい、戦略を語れ」という言葉は、会議室の誰かに向けているようで、実は鏡の中の自分に向けている。お前は本当に分かっているのか。分かったふりをしているだけじゃないのか。その問いに、いい加減決着をつけたかった。戦略という言葉の氾濫私たちの周りには、「戦略」という言葉が溢れている。経営戦略。マーケティング戦略。販売戦略。顧客戦略。人材戦略。DX戦略。グローバル戦略。デジタル田園都市国家構想総合戦略。こんなに幅広く使われている「戦略」だが、その核心が何なのかと聞かれると、答えられない。いや、答えられないだけならまだいい。答えが人によって違いすぎる。ある人は言う。「戦略とは、目標を達成するための手段だ」。別の人は言う。「戦略とは、ビジョンを実現するための計画だ」。また別の人は言う。「戦略とは、競合に勝つための差別化だ」。どれも間違ってはいない。しかし、どれも正しくはない。なぜなら、これは戦略の「結果」であって、戦略の「核心」ではないからだ。戦略会議で何が起きているか、もう一度見てみよう。「今期の戦略は、売上を前年比130%にすることです」。これは戦略ではない。目標だ。どうやって達成するのかは、何も語られていない。「我々の戦略は、顧客第一、品質重視、イノベーション推進です」。これも戦略ではない。スローガンだ。具体的に何をするのかは、何も示されていない。「我々のマーケティング戦略は、デジタルチャネルの強化、SNS活用の拡大です」。これも戦略ではない。施策の羅列だ。なぜその打ち手なのか、どうつながっているのか、何が問題でそれがどう解決するのかは説明されていない。そして、最悪なのは、これらを「悪い戦略」と呼ぶことさえ正しくないということだ。悪い戦略とは、内部の対立を曖昧にするための妥協の産物である、という指摘がある。経営会議で、営業部と開発部が対立する。営業は「もっと新機能を」と言う。開発は「品質を優先すべき」と言う。すると、誰かが言う。「では、両方やりましょう。それが我々の戦略です」。これは妥協だ。誰も傷つけないための八方美人だ。でも、これを「戦略」と呼んではいけない。なぜなら、戦略とは、選択だからだ。何をやるかを決めることではない。何をやらないかを決めることだ。しかし、私たちは選択できない。なぜか。もちろん、個人の心理もある。選択することは、責任を負うことだ。「これをやる」と決めた人間は、それが間違っていた時、責任を取らなければならない。だから、選択を避ける。全部やると言えば、誰も傷つかない。ただ、問題は個人の心理だけではない。組織の構造が、選択を妨げている。まず、インセンティブの問題がある。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっている。「うちの部門の予算を削るな」という力学が働く。次に、権限の曖昧さがある。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確だ。だから、誰も決めない。決めなければ、責任を問われない。また、評価制度との不整合がある。「やらないと決めた」ことは、評価されにくい。成果として見えないからだ。「100のことをやって80点」より「30に絞って95点」の方が戦略的には正しい。しかし、評価制度が前者を高く評価することがある。だからといって、個人の責任がないわけではない。選択する勇気は必要だ。ただ、勇気だけで組織を変えることはできない。構造を変えなければ、選択は起きない。「全部やる」は、個人の弱さであると同時に、構造の帰結でもある。選択を避け、妥協を繰り返す。その結果、戦略という言葉は、中身のない器になった。何を入れても受け入れる、便利な箱になった。目標を入れる。スローガンを入れる。希望を入れる。妥協を入れる。蓋を閉じて、「戦略」というラベルを貼る。これが、私たちが「戦略」と呼んでいるものの正体なのだろう。この空洞さは、どの立場にいても感じることがあるだろう。ただ、私のように技術寄りの立場にいると、余計に気になることがある。技術顧問として呼ばれているのに、いつの間にか「経営戦略」のスライドを見せられている。自分はシステムのアーキテクチャについて聞かれると思っていたのに、気づくと「売上130%」のスライドの前に立たされている。その「戦略」がどのレイヤーの話なのか、技術側から見るとよくわからない。事業の話なのか、組織の話なのか、プロダクトの話なのか。全部が「戦略」という言葉で括られている。しかし、だからといってエンジニアが戦略と無縁でいられるわけではない。プロダクトのどこにリソースを割くか。どの技術的負債を今返し、どれを後回しにするか。このアーキテクチャで将来の拡張性を取るか、今のシンプルさを取るか。これはすべて戦略的な判断だ。経営会議に出なくても、コードを書いていても、私たちは日々、戦略的な選択をしている。だからこそ、「戦略とは何か」を理解することは、エンジニアにとっても他人事ではない。私自身、最近作った資料を振り返ることがある。「戦略」と書いたスライド。本当に「解決すべき最重要課題と、その解き方」になっていたか。目標やスローガン、施策の羅列に留まっていなかったか。正直、自信がない。核心を見極める戦略を一言で表すなら、こうなる。「戦略とは、解決可能な最重要課題を見極め、それを解決する方法を見つけることだ」。シンプルだ。しかし、深い。まず、「解決可能な最重要課題」とは何か。組織が直面している問題は無数にある。しかし、すべてが同じ重さではない。ある問題を解決すると、他の問題も連鎖的に解決に向かう。そういう問題がある。それが「核心的な課題」だ。技術選定を考えてみよう。新しいプロジェクトを始める時、検討すべきことは無数にある。言語は何にするか。フレームワークは何を使うか。データベースは何が適切か。インフラはどう構成するか。すべて重要だ。ただ、すべてを同時には最適化できない。ここで、核心を見極める必要がある。たとえば、「チームの習熟度」が核心だとする。どんなに優れた技術でも、チームが使いこなせなければ意味がない。だから、チームが慣れている言語を選ぶ。すると、立ち上がりが早くなり、バグも減り、メンテナンスも楽になる。1つの核心を押さえたら、他の問題も動き始めた。戦略も同じだ。核心的な課題を見つけ、そこにリソースを集中させる。戦略とは、この課題を見つけることから始まる。会社が直面している問題は無数にある。売上が伸びない。競合が強い。人材が足りない。技術が古い。すべて問題だ。すべて解決したい。だが、すべてを同時に解決できない。だから、見極める。どれが核心的な課題なのか。どれを解決すれば、他の問題も動き始めるのか。私が関わったある組織で、プラットフォームエンジニアリングチームを立ち上げようとした時、無数の技術的課題があった。どれも難しい。どれも重要だ。Kubernetesの運用。CI/CDパイプラインの整備。監視基盤の構築。セキュリティポリシーの策定。ただ、本当の核心的な課題は、別のところにあった。「開発者がインフラを触るまでのリードタイムが長すぎる」。これが核心だった。どんなに優れた基盤があっても、開発者が使い始めるまでに2週間かかるなら、誰も使わない。だから、セルフサービス化を最優先にした。申請から環境構築までを30分に短縮した。すると、利用率が上がり、開発速度も上がり、プラットフォームチームへの信頼も高まった。1つの核心を解いたら、他の問題も動き始めた。これが、戦略だ。核心的な課題を見つける。解決策を見つける。実行する。もう1つ、私自身のプラットフォームエンジニアリングの経験を話そう。以前いたチームでは、コードの品質、テストのカバレッジ、ドキュメントの不足、レガシーシステムとの連携と、無数の課題があった。ただ、本当の核心的な課題は別のところにあった。「開発者がステージング環境を立てるのに2日かかる」。これが核心だった。インフラチームへの申請、承認待ち、手動でのセットアップ。ステージング環境が作れなければ、検証できない。検証できなければ、リリースできない。Terraformでインフラをコード化し、GitHubのPRをマージするだけで環境が立ち上がるようにした。30分で完了する。すると、リリース頻度が上がり、バグも減り、開発者体験も改善された。1つの核心を解いたら、他の問題も動き始めた。シンプルだが、簡単ではない。課題を見極めることは、選択だからだ。「これが最も重要だ」と決めることは、「他は優先しない」と決めることでもある。戦略会議を思い出そう。「売上を前年比130%にする」は核心的な課題ではない。売上を伸ばすことは結果であって、問題ではない。問題は、なぜ売上が伸びないのか、だ。競合が強いのか。商品が古いのか。チャネルが弱いのか。ブランドが知られていないのか。価格が高いのか。営業力が足りないのか。どれが核心なのか。どれを解決すれば、売上が伸びるのか。それを見極めることが、戦略の第一歩だ。しかし、私たちはそれをしない。見極めることは、責任を負うことだからだ。「これが核心だ」と言った人間は、それが間違っていた時、責任を取らなければならない。だから、誰も言わない。全部重要だと言う。全部やると言う。そして、何も解決しない。選択から逃げる方法は、もう1つある。パーパスやミッションに逃げ込むことだ。パーパスやミッションは、戦略ではない。パーパスとは、企業の存在意義だ。ミッションは、企業が果たすべき使命だ。どちらも重要だ。だが、戦略ではない。「世界中の人々に幸せを届ける」。美しいパーパスだ。では、どうやって届けるのか。それが戦略だ。パーパスは方向を示す。道を示すのは戦略だ。多くの企業が、パーパスを掲げて満足してしまう。具体的に何をするのかは、曖昧なままだ。これは、戦略の放棄だ。難しい選択から逃げているだけだ。これは事業側の話だけではない。技術側にも同じ罠がある。「技術負債をなくす」「きれいなアーキテクチャにする」「開発者体験を向上させる」。美しい技術パーパスだ。しかし、具体的にどの負債を、いつまでに、どうやって返すのか。何を「きれい」と定義し、どの部分から手をつけるのか。開発者体験のどの側面を、どの程度まで改善するのか。それが示されていなければ、技術パーパスもまた、戦略ではない。事業側であれ技術側であれ、パーパスごっこに陥りやすい。美しい言葉を掲げて、具体的な選択から逃げる。私自身、「解決可能な最重要課題」を1つだけ挙げろと言われると、考え込んでしまうことがある。なぜそれが「最重要」だと言えるのか。即答できない時、見極めができていないと気づく。戦略はストーリーであるここまで、戦略の「内容」について語ってきた。何を解決するか。どこに集中するか。これが内容だ。次は、戦略の「形」について考えよう。同じ内容でも、伝え方によって実行力が変わる。バラバラの施策として並べるか、一貫したストーリーとして語るか。この違いが、戦略の成否を分ける。良い戦略は、施策ではなくストーリーだ。ストーリーとは何か。物語だ。因果の連鎖だ。「AだからB、BだからC、CだからD」という流れだ。良い戦略は、この流れがある。個々の施策が、バラバラに存在するのではない。互いに補強し合っている。前の手が、次の手を可能にする。次の手が、前の手の効果を高める。プロダクト開発で考えてみよう。「このアーキテクチャにしたからこそ、新機能の実験が低コストで回せる」。「このモジュール分割をしておくから、将来の料金プランのバリエーションを増やせる」。「このAPIの設計にしたから、パートナー連携がスムーズにできる」。コードの書き方と、事業側の選択肢が、一本の物語になっているかどうか。技術的な決定が、事業の可能性を広げている。事業の方向性が、技術的な決定を正当化している。この双方向のつながりがあるかどうか。それが、技術戦略がストーリーになっているかどうかの分かれ目だ。逆に、悪い戦略には、ストーリーがない。「我々は、高品質な商品を、低価格で、迅速に提供します」。一見、良さそうだ。でも、これはストーリーではない。施策の羅列だ。高品質と低価格は矛盾する。高品質にはコストがかかり、低価格にするにはコストを削る。迅速さも、品質と矛盾することが多い。これらの施策は、互いに補強し合っていない。むしろ、打ち消し合っている。因果の連鎖がないから、実行できない。なぜ、こうなるのか。多くの場合、「あれもこれも」と欲張るからだ。高品質が欲しい。低価格だって欲しい。迅速さまで欲しい。全部欲しい。でも、全部は取れない。ストーリーを一貫させるには、「これ一本」が必要になる。何かを選び、何かを捨てる。この「これ一本」の考え方は、企業の戦略だけでなく、チームや個人にも当てはまる。私が特に強く感じるのは、専業性の強さだ。誤解のないように言えば、多角化がつねに悪いわけではない。あるプラットフォームチームは、CI/CDパイプラインの整備から始まり、監視基盤、セキュリティスキャン、開発者ポータルへと領域を広げた。別のチームは、Kubernetesクラスタの運用から、GitOpsの導入、Terraformによるインフラ管理、コスト最適化へと拡張した。これは成功した多角化だ。しかし、共通するのは、核となる強みから派生して広がったことだ。前者は「開発者体験の向上」を軸に広がった。後者は「セルフサービス化による開発者の自律性」を軸に広がった。つまり、多角化と専業性は二項対立ではない。「何を軸にするか」が明確かどうかが分かれ目だ。問題なのは、軸のない多角化だ。「他のチームがやっているから自分たちも」「とりあえずKubernetesを入れよう」。このタイプの多角化は、リソースを分散させ、どの領域も「そこそこ」にしてしまう。専業的なチームが強いのは、専業だからではない。1つのことを徹底的に掘り下げているからだ。多角化していても、軸が明確で、そこを徹底的に掘り下げているチームは強い。チームの話をしてきたが、これは個人のキャリアにも当てはまる。私は、エンジニアとして働いている。プログラミングができる。インフラも分かる。データベースも触れる。フロントエンドもできる。「フルスタックエンジニア」という肩書きを持っている。しかし、あるとき気づいた。私は、多くのことを「そこそこ」できる。ただ、何1つ「徹底的に」できない。専門性がない。深さがない。だから、代替可能だ。誰かが、私より少し上手にできる。常に、そういう誰かがいる。専業性。1つのことを、徹底的に掘る。それが、競争優位の源泉だ。もしあなたが「何でもそこそこできる人」なのであれば、それをどうポジショニングするのかも戦略だ。「何でも屋」として埋もれるのか、「事業と技術をつなぐ翻訳者」として立つのか。どちらを選ぶかは、「何をやらないか」の選択だ。翻訳者として立つなら、深い専門性を追求することは諦める。代わりに、異なる専門性を持つ人々の間を橋渡しする能力を磨く。これも戦略的な選択だ。私自身、この問いを自分に向けることがある。戦略を説明する時、ストーリーになっているか。キーワードの寄せ集めか。専業性があるのか、何でもそこそこなのか。流されてそうなっているだけではないか。答えは、いつも曖昧だ。明確に「できている」とは言えない。ただ、問い続けること自体に意味があると思っている。まだ顧客ではない人を見つけるあるとき、プラットフォームチームのダッシュボードを眺めていて、違和感を覚えた。利用者数が伸びていない。一方で、既存ユーザーからの機能要望は山のように来ている。私たちは、その要望に応え続けていた。新機能を追加した。ドキュメントを充実させた。既存ユーザーは喜んだ。しかし、利用者数は変わらなかった。何かがおかしい。ふと疑問が浮かんだ。「使っていない人は、なぜ使っていないのか」。私たちは、その問いを持っていなかった。ここまで、戦略の「何を」「どう」の話をしてきた。次は、「誰に」の話だ。戦略を考える時、私たちは既存の顧客ばかり見てしまう。「この機能がほしい」「ここが使いにくい」。フィードバックは大事だ。ただ、本当の成長機会は、別のところにあることが多い。本当の顧客は、まだ顧客ではない。「まだ顧客ではない人」とは、ただ「使っていない人」ではない。彼らは、その機能を必要としていないのではない。「高すぎる」「難しすぎる」「面倒くさすぎる」など、どこかでバリアに引っかかっている。価格のバリア。複雑さのバリア。心理的なバリア。面倒くささのバリア。どのバリアが最も高いのかを見極め、それを下げる。これが、潜在顧客へのアプローチだ。私が関わったあるプラットフォームエンジニアリングのプロジェクトでは、社内の開発者向けに整備したCI/CDパイプラインやKubernetesクラスタが、なかなか使われない問題があった。機能を追加しても、ドキュメントを増やしても、利用率は上がらなかった。調べてみると、問題は別のところにあった。「初期設定が面倒」。パイプラインの機能は十分だった。ただ、自分のプロジェクトに適用するには、YAMLを何十行も書き、権限設定を複数箇所で行う必要があった。これがバリアだった。テンプレートを用意し、3つの質問に答えるだけで初期設定が完了するCLIツールを作った。利用率は上がった。機能の問題でも、ドキュメントの問題でもなかった。面倒くささのバリアだった。別の例を挙げよう。ある組織で、SREチームの構築した本格的な開発者プラットフォームがあったとする。Kubernetesクラスタ、Terraformによるインフラ管理、Prometheusによる監視、ArgoCD によるGitOps。高機能で、クラウドネイティブな開発には必須の基盤だ。ただ、使いこなすにはKubernetesの知識が必要で、YAMLの書き方を理解し、GitOpsのワークフローに慣れなければならない。このプラットフォームの「まだ顧客ではない人」は誰か。入社したばかりの新人エンジニアだ。別チームから異動してきたバックエンドエンジニアだ。彼らも同じ課題を抱えている。「自分のアプリケーションを安定して動かしたい」という同じ「進歩」を求めている。ただ、学習コストが高すぎる。複雑すぎる。だから、ローカル環境や古いVMで我慢している。ここで、セルフサービスポータルが登場したとする。Webの画面でアプリ名と言語を選ぶだけ。裏側ではKubernetesが動いているが、ユーザーはそれを意識しなくていい。すると、今までプラットフォームを使っていなかった新人や他チームのエンジニアが、ユーザーになる。使っているうちに理解が深まり、もっと高度なカスタマイズがしたくなる。直接YAMLを書くようになる。「まだユーザーではない人」が、ユーザーになる。そして、成長とともにプラットフォームのパワーユーザーになる。重要なのは、「機能を削った劣化版」を作ることではない。「まだ顧客ではない人」が抱えているバリアを特定し、そのバリアを下げることだ。価格がバリアなら、価格を下げる。複雑さがバリアなら、シンプルにする。心理的なハードルがバリアなら、入口を低くする。どのバリアが最も高いかを見誤ると、的外れな施策になる。「まだ顧客ではない人」を見つけて、バリアを下げる。この視点は、開発のやり方そのものを変える。開発には2つのアプローチがある。1つは「押しつけ」型だ。上から降りてきた仕様をそのまま実装する。なぜこの機能が必要なのか。誰のどんな課題を解決するのか。それが見えないまま、言われた通りに作る。すると、何が起きるか。作ったものが使われない。ユーザーが喜ばない。現場のモチベーションが下がる。もう1つは「引き寄せ」型だ。ユーザーの「本当に欲しい進歩」を理解する。そこから逆算して、仕様を決める。機能がユーザーのニーズに「引き寄せられている」状態だ。「まだ顧客ではない人」を見つけ、彼らのバリアを理解し、そこから仕様を導く。これこそが、戦略と開発が噛み合っている状態だ。私自身、「まだ顧客ではない人」を見落としていることに気づくことがある。既存ユーザーの声ばかり聞いて、「まだ使っていない人」のことを考えていない。彼らは何を求めているのか。何がバリアになっているのか。この視点を持つだけで、見える景色が変わる。ここで、1つ問いを立てたい。「まだ顧客ではない人」を見つけるのは、誰の仕事だろうか。マーケティング部門の仕事だと思われがちだ。しかし、現場こそ、潜在顧客のバリアを理解できる独自の視点を持っている。セールスは「買わない理由」を知っている。CSは「使い続けない理由」を知っている。そしてエンジニアは、バリアの多くが技術的な問題であることを知っている。「設定が複雑すぎる」。これは技術で解決できる。「動作が遅すぎる」。これも技術で解決できる。「他のツールと連携できない」。これも技術で解決できる。マーケティング部門は「バリアがある」と気づくことはできる。だが、「そのバリアをどう下げるか」を具体的に設計できるのは、現場だ。ここまで読むと、「現場が重要だ」という話に聞こえる。確かにそうだ。ただ、もう1つ、見落としがちな点がある。現場が価値を発揮できるのは、ある条件が揃っている時だけだ。その条件とは、制約だ。制約がなければ、現場は潜在顧客について何も語れない。逆説的に聞こえるだろう。説明しよう。どういうことか。もしリソースに何の制約もなければ、「全部やればいい」で終わる。高速にする。簡単にする。安くする。連携できるようにする。全部やる。それで解決だ。でも、現実にはリソースは有限だ。時間も、人も、予算も。だから、「どのバリアを下げるか」を選ばなければならない。この「選ぶ」という行為において、現場の知見が活きる。エンジニアなら「このバリアを下げるには3ヶ月かかる。でも、こっちのバリアなら1週間で下げられる」と判断できる。セールスなら「このバリアを下げれば、商談の成約率が上がる」と判断できる。制約があるからこそ、優先順位が生まれる。優先順位があるからこそ、戦略が必要になる。制約こそが、現場の貢献を可能にしている。つまり、「まだ顧客ではない人」を見つけて、そのバリアを下げる方法を提案すること。これは、現場ができる最大の「事業への貢献」の1つだ。指示を待つだけの現場には、この貢献はできない。「誰が使っていないのか」「なぜ使っていないのか」「どうすれば使えるようになるのか」。そして、「限られたリソースで、どのバリアから下げるべきか」。この問いを持つ現場だけが、事業の成長に直接貢献できる。理論と実践の間でここまで、戦略について語ってきた。核心的な課題を見極めること。ストーリーとしての一貫性。専業性の強さ。「まだ顧客ではない人」という視点。これらの考え方は、理解できる。頭では分かる。しかし、1つ重要な疑問が残る。これらの考え方を、どう使えばいいのか。正直に言えば、私はエンジニアだ。設計パターンやアーキテクチャの本を何冊も読んできた。ドメイン駆動設計。クリーンアーキテクチャ。マイクロサービス。モジュラーモノリス。どれも「ソフトウェアをどう構造化するか」についての理論だ。複雑さをどう分割するか。変更をどう局所化するか。チーム間の依存をどう減らすか。これらの理論や仕組みについて、語ることはできる。だが、それを自分のプロジェクトに適用できるかは、別の話だ。どの理論が自分たちの状況に適用可能なのか。どのパターンが今の組織規模とスキルセットに合っているのか。それを判断するには、理論を超えた洞察が必要だ。理論を語れることと、戦略を立てられることは、別だ。ただ、「戦略を語れない」ことと「戦略を実行できない」ことは、同じだろうか。私は「戦略を語れ」と言っている。しかし、語れることと実行できることは別だ。美しい戦略を語れても、実行できなければ意味がない。逆に、言葉にできなくても、体で分かっている人もいる。私は、どちらだろうか。語れるけど実行できないのか。実行できるけど語れないのか。それとも、どちらもできていないのか。正直に言えば、分からない。理論は、現実を説明する。「なぜこうなったのか」を教えてくれる。しかし、「どうすればいいのか」は教えてくれない。マイクロサービスアーキテクチャは、システムを小さな独立したサービスに分割する手法だ。各チームが自分のサービスを独立してデプロイできる。大規模組織では強力だ。ただ、5人のチームで導入すべきか。サービス間の通信、障害の伝播、デバッグの難しさ。小さなチームには重荷になる。モノリスのままでいいのか。将来の拡張性は諦めるのか。ドメイン駆動設計は、複雑なビジネスロジックを「境界づけられたコンテキスト」で整理する手法だ。だが、今のプロジェクトは、本当にそこまで複雑か。学習コストに見合う複雑さがあるのか。それを判断するには、理論を超えた洞察が必要だ。理論は、説明する。しかし、処方箋は出さない。これは、理論の限界だ。いや、限界というより、理論というものの性質だ。理論は、世界を理解するためのツールだ。世界を変えるためのツールではない。理論には、必ず適用範囲がある。マイクロサービスは、組織がスケールしている時に有効だ。ただ、チームが小さい時は、むしろ足かせになる。クリーンアーキテクチャは、ビジネスロジックを外部依存から切り離す設計思想だ。データベースやフレームワークを後から差し替えられる。長期保守が前提のプロダクトでは有効だ。一方、3ヶ月で検証して捨てるプロトタイプでは、過剰投資になる。テスト駆動開発は、テストを先に書き、そのテストを通すコードを後から書く手法だ。仕様が明確な時に有効だ。けれど、何を作るか探索している段階では、テストが足かせになることもある。つまり、理論を使うには、まず「どの理論が適用可能か」を判断しなければならない。だが、それを判断するには、理論を超えた洞察が必要だ。これは、逆説だ。理論を使うために、理論を超えた何かが必要だ。その「何か」とは何か。経験だ。直感だ。センスだ。結局、理論は、センスの補助線に過ぎない。センスのある人が理論を使えば、より深く考えられる。一方、センスのない人は理論だけに頼っても、何もできない。では、センスはどう磨くのか。「経験を積め」では答えになっていない。私なりに考えた方法を3つ挙げる。第一に、「判断の言語化」を習慣にする。何かを決めた時、なぜその判断をしたのかを書き残す。1ヶ月後、3ヶ月後に振り返る。当時の判断は正しかったか。何を見落としていたか。この繰り返しが、判断の精度を上げる。第二に、「他者の判断を追体験する」。本を読む時、著者がなぜその結論に至ったかを考える。「自分ならどう判断したか」を先に考えてから、著者の結論を読む。このギャップが学びになる。成功事例だけでなく、失敗事例を読むことも重要だ。第三に、「小さな賭けを繰り返す」。大きな戦略を立てる機会は少ない。ただ、小さな判断は毎日ある。「このタスクを先にやるか、後にやるか」「この機能を入れるか、外すか」。この小さな判断を意識的に行い、結果を観察する。センスは、大きな決断ではなく、小さな判断の積み重ねで磨かれる。センスは才能ではない、と私は思う。観察と振り返りの習慣なのではないか。私自身、この「センス」の不足を痛感したことがある。プラットフォームエンジニアとして「開発者体験を向上させるべきだ」と理論を実践しようとした。ツールのドキュメントを整備し、社内ドキュメントにまとめて共有した。ところが、利用率は変わらなかった。理論を機械的に適用したからだ。開発者体験は、ドキュメントだけでは向上しない。開発者が実際につまずく瞬間を観察する必要がある。「困ったらあの人に聞こう」と思われるプラットフォームチームが必要だ。これは信頼関係であり、組織文化だ。理論の外にある領域だが、理論を機能させるには不可欠だ。理論と実践の間には、常にギャップがある。理論は一般化された知識だ。実践は個別の状況だ。一般を個別に適用する翻訳こそが、実践者のスキルだ。だから、私は「この技術を使うべきか」と聞かれた時、即答しない。「チームの規模は」「プロダクトのフェーズは」「今の技術的負債はどこにある」と聞き返す。理論を適用する前に、文脈を理解しなければならない。文脈なき理論の適用は、害にすらなる。私はエンジニアだ。だから、目の前の現実と向き合うしかなかった。うまくいかないことを何度も経験した。その度に、なぜうまくいかなかったのかを考えた。理論を読み、現実と照らし合わせ、自分なりの理解を深めていった。この捻り出した思考は、今、個人やチームの戦略を立てる時に役立っている。理論を知っている。ただ、理論に頼りすぎない。現場を見る。人を見る。文脈を理解する。その状況に合った答えを探す。これが、実践者の仕事だ。小さな適応範囲なら、語れる。自分のチームで、どういう問題があって、どう解決しようとしたか。何がうまくいって、何がうまくいかなかったか。次はどうするか。この小さな範囲での試行錯誤が、戦略を立てる力を育てる。しかし、この「小さな適応範囲」の中には、純粋な技術領域だけでなく、事業寄りの判断もじわじわと入り込んでくる。「プロダクトのどこにリソースを割くか」「どの顧客セグメントに寄せるか」「この機能を今作るか、後で作るか」。これは、技術的な判断に見えて、実は事業の方向性に関わる判断だ。技術の現場にいながら、事業の戦略にも口を出すことになる。企業全体の戦略を立てることは、私にはできない。立場も違う。経験も足りない。だが、自分の責任範囲では、できる。自分のチームでは、できる。個人の仕事では、できる。この小さな範囲での実践こそが、本当の学びになる。理論を読むことは、重要だ。ただ、理論を読んだだけでは、何も変わらない。理論を使って、現場で試す。失敗する。振り返る。この繰り返しの中でしか、戦略を立てる力は身につかない。私自身、「戦略と言いながら、実は何も捨てていない」ものに関わってきた。理論やフレームワークを「そのまま」適用して、うまくいかなかったことも多い。足りなかったのは、現場の事情への理解だった。人の感情への配慮だった。技術戦略と事業戦略の距離を縮めるここまで、戦略を立てる「個人」の話をしてきた。だが、戦略は組織の中で機能する。特にエンジニアとして気になるのは、技術戦略と事業戦略の関係だ。長いあいだ、自分の中に「事業戦略→技術戦略」という一方向の矢印があった。事業側が「何を作るか」を決め、技術側は「どう作るか」を決める。経営が方向を決めて、エンジニアはそれを実装する。この一方向依存のメンタルモデルは、長らく私の中に染みついていた。しかし、現実には、「どう作るか」が「何ができるか」を大きく変える。変更コストの低いアーキテクチャだから、競合が半年かかる機能を1ヶ月で検証できる。このモジュールの切り方にしておくから、「この部分だけを切り出して別料金プランにする」という事業のオプションが生まれる。このAPIの設計にしておくから、将来のパートナー連携がスムーズにいく。技術戦略は、事業の選択肢を増やす。事業戦略から技術戦略への一方向ではなく、双方向の依存関係がある。技術が事業を制約することもあれば、技術が事業の可能性を広げることもある。この双方向性を理解すると、開発現場で起きる摩擦の見え方が変わる。技術的チャレンジは、想定外の遅延や不具合を生む。これを「技術の問題」として閉じてしまうと、現場は追い詰められる。「なんとかしろ」という圧力だけがかかる。しかし、技術的な課題を「事業戦略を動かす材料」として扱うと、話が変わる。「この技術的な制約があるなら、ローンチ時期をずらすか」。「このリスクがあるなら、この機能は一旦やめて、こっちの顧客セグメントを先に取るか」。技術の現場からの情報が、事業側の判断材料になる。不確実性を飼いならすための対話が生まれる。エンジニアだけでなく、デザイナー、PdM、ドメインエキスパートも同じだ。現場でプロダクトの手触りを一番知っている人たちが、事業戦略の「定数」ではなく「変数」をいじれる立場になっていい。「この仕様だとユーザーは混乱する」というデザイナーの声。「この機能は、実はこの顧客セグメントには刺さらない」というPdMの洞察。「この業界の慣習を考えると、この方向は難しい」というドメインエキスパートの知見。これは、事業戦略を修正するクリティカルなインプットだ。越権行為ではない。むしろ、健康な組織の姿だ。ここまで、技術と事業の対話について語ってきた。対話の相手は人間を想定してきた。しかし最近、対話の相手が変わりつつある。AIを戦略の壁打ち相手にする場面が増えた。試しにAIへ聞いてみたことがある。「戦略を考えてください」。出てきた答えは、驚くほど整っていた。SWOT分析。ファイブフォース分析。「デジタルチャネルの強化」「顧客体験の向上」といった施策。ロジックも通っている。これは、先ほど述べた「理論の限界」と同じ構造だ。AIは理論を適用できる。分析もできる。ただ、「どの理論が今の状況に適用可能か」を判断するのは、AIではなく人間だ。そして、最後に「これでいく」と賭けるのも人間だ。技術戦略と事業戦略の対話において、AIは優秀な壁打ち相手になる。「この技術的制約がある時、事業戦略はどう変わりうるか」と問えば、選択肢を整理してくれる。ただ、その選択肢の中からどれを選ぶかは、現場を知り、責任を負う人間が決める。これは、技術と事業の対話が人間同士であるべき理由と、根は同じだ。私自身、「本当はもっとこうすれば速く進めるのに」と感じることがある。技術の現場から見えている事業の可能性。それを戦略の議論にインプットしようとしたことはある。うまくいった時もあれば、スルーされた時もある。それでも、言い続けることに意味があると思っている。現場こそが仮説を持つべきだここまで、戦略について語ってきた。しかし、1つ疑問が残るだろう。現場の人間は、そもそも戦略なんて考える必要があるのか。与えられた目標を追いかけ、仕様通りに実装するのが仕事ではないのか。私の答えは明確だ。現場こそ、仮説を持つべきだ。エンジニアも、デザイナーも、セールスも、CSもだ。現場は、ビジネスの「手触り」を最も知っている立場だからだ。エンジニアは、プロダクトの構造的な手触りを知っている。「この機能は技術的に難しい」「ここがボトルネックになる」。これはコードを書く人間にしか分からない。同様に、セールスは顧客の「断る理由」の手触りを知っている。CSはユーザーが「つまづく瞬間」の手触りを知っている。本部で数字をこねくり回している時には見えない「事実の断片」を、現場は握っている。この手触りを「仮説」に昇華できた時、現場は戦略を変える力を持つ。たとえば、カスタマーサクセス（CS）。彼らは日々、「解約」という事実に直面する。戦略のないCSは、解約阻止のマニュアル通りに動き、ダメなら「顧客の事情」として処理する。しかし、仮説を持つCSは問う。「なぜ、このタイミングで解約するのか」。彼らは気づく。「機能不足ではなく、オンボーディングの3日目に発生する『設定の面倒さ』に心が折れているのではないか」。この仮説があれば、開発チームに「新機能より設定ウィザードの改善を」と要求できる。それは単なるクレーム処理ではない。立派な「チャーン（解約）阻止戦略」だ。たとえば、セールス。「価格が高いと言われました」と報告するだけなら、誰でもできる。AIでも集計できる。しかし、仮説を持つセールスは考える。「高いと言われるのは、価値が伝わっていないからか、それとも比較対象が間違っているからか」。もし顧客が、競合他社のツールではなく、Excelと比較して「高い」と言っているなら、戦い方は変わる。機能の多さをアピールするのではなく、「手入力のコスト」を訴求すべきだ。その気づきは、マーケティング戦略やプライシング戦略を根底から覆す可能性がある。仮説を持たない現場は、ただの「手足」になる。言われた通りに作り、言われた通りに売る。なぜやるのかは考えない。楽だが、キャリアとしては危うい。「言われたことを正確にやる」だけなら、代替可能だからだ。一方、仮説を持つ現場は、戦略の「センサー」になる。「本社が考えている戦略は、現場感覚とズレているぞ」と気づける。そのズレを言語化し、フィードバックする。時にそれは、経営陣にとって不都合な真実だろう。「今の売り方では絶対に売れない」「この機能は誰も使わない」。しかし、その不都合な真実こそが、組織を救う。仮説を持つことの有用性は、職種を問わず共通している。第一に、学習速度が上がる。仮説を持っていると、結果との差分が学びになる。「このトークなら刺さるはずだ」と思っていたことが、刺さらなかった。このギャップが、次の商談の精度を上げる。仮説がなければ、何が起きても「そんなものか」で終わる。第二に、議論に参加できる。仮説を持っていれば、それをぶつけることができる。「開発側はこう見ていますが、セールス側はどうですか」と問える。これは、単なる状況確認ではない。お互いの「手触り」を照らし合わせる行為だ。この対話の中で、事業の解像度が上がる。第三に、主体性が生まれる。仮説を持つと、「自分ごと」になる。この仮説が正しいかどうか、確かめたくなる。うまくいけば嬉しいし、間違っていれば悔しい。この感情が、仕事へのコミットメントを高める。私はエンジニアだ。だからコードを通じて事業を見る。セールスは対話を通じて、デザイナーは体験を通じて事業を見る。それぞれの「現場」からしか見えない景色がある。その景色を「仮説」という形にしてテーブルに乗せること。それが、私たちが戦略に参加する唯一の方法だ。現場は、戦略の「消費者」ではない。戦略の「参加者」になれる。そのためには、仮説を持つこと。問いを持つこと。それを声に出すこと。これが、現場と経営の距離、技術と事業の距離を縮める第一歩だ。戦略を語れ、責任を持ってここまで、戦略について長々と語ってきた。最後に、個人的な話をしたい。あの会議から、数年が経った。今も、お手伝いしてきた会社で、技術顧問として経営者たちと話をすることがある。会議で、誰かが「戦略」という言葉を使う。相変わらず、中身のない戦略が語られる。正直に言えば、私はそこで「それは戦略ですか」とは言えない。言えなかった。なぜなら、それは私の仕事の範疇を超えているからだ。技術顧問として呼ばれている。システムのアーキテクチャについて助言する立場だ。経営戦略に口を出すのは、越権行為だ。それでも、心のどこかで引っかかっている。本当に必要な場面であれば、立場を超えてでも言うべきではないのか。会社が明らかに間違った方向に進もうとしている時。誰も指摘しない時。そういう時こそ、言うべきではないのか。だが、言わない。言えない。その境界線がどこにあるのか、自分でもわからない。だから、内心では思っている。「その戦略で、どんな問題を解決するのか」。「その問題は、本当に最も重要な問題なのか」。「なぜ、その解決策なのか」。「他の選択肢は、検討したのか」。「何を捨てたのか」。これらの疑問が、頭の中を巡る。だが、口には出さない。出せない。立場が違う。責任の範囲が違う。その代わり、私は慎重に言葉を選ぶ。技術的な観点から、問いを投げかける。「その施策を実現するには、どんな技術的な課題がありますか」。「優先順位をつけるとしたら、どの順番で進めますか」。「リソースの制約を考えると、何かを諦める必要がありませんか」。気を使いながら、遠回しに。それでも、核心を突く問いを。これらの質問は、時に受け入れられる。時に、無視される。経営陣は、自分たちの「戦略」を語り続ける。ただ、不思議なことに、この経験が無駄になることはなかった。経営会議で言えなかったこと。内心で感じていたこと。絞り出した思考。気を使って口に出した言葉。すべて蓄積されていった。自分のチームを持った時、個人として仕事をする時、この経験が役に立った。エンジニアリングチームの方向性を決める時。技術的な選択をする時。プロジェクトの優先順位を決める時。そこでは、私は問うことができた。「この取り組みで、何を解決するのか」。「本当に、それが最も重要な課題なのか」。「なぜ、この方法なのか」。「他にやり方はないのか」。「何を捨てるのか」。チームメンバーと話す。一対一で。ホワイトボードの前で。Slackで。経営会議とは違う。ここでは、私が責任を持てる。私の範疇だ。だから、問える。そして、気づいた。戦略は、スケールの問題ではない。企業全体の戦略でも、チームの戦略でも、個人の戦略でも、根っこは同じだ。核心的な課題を見極める。解決策を見つける。何かを捨てる。実行する。経営会議で見てきた「戦略ごっこ」。あれを、自分のチームでは繰り返さない。そう決めた。チームの目標を立てる時。「全部やる」とは言わない。「これをやる。これはやらない」と明確にする。新しい技術を導入する時。「なんとなく良さそう」では進めない。「どの問題を解決するのか」を明確にする。プロジェクトの優先順位を決める時。「全部重要」とは言わない。「これが最重要。他は後回し」と決める。これは、不快だ。チームメンバーから反発されることもある。「なぜ、私のタスクは優先されないのか」。「なぜ、この技術は使わないのか」。それでも、説明する。なぜその判断をしたのか。何を最優先にしたのか。何を捨てたのか。時に、判断が間違っていることもある。やってみて、うまくいかない。その時は、認める。修正する。ただ、少なくとも、判断はしている。選択はしている。「全部やる」という逃げ方はしていない。これが、私なりの戦略だ。企業全体ではない。自分の責任範囲での戦略だ。それで十分だ。いや、それこそが核心だ。ただ、「小さな戦略で十分だ」と言っているが、それは「逃げ」ではないか。本当は、もっと大きな影響力を持ちたいのに、怖くて小さな範囲に留まっているだけだろう。「小さな戦略」という言葉で、自分の臆病さを正当化しているだけだろう。逆も考えられる。大きな戦略を語りたがる人の中には、目の前の小さな選択から逃げている人もいる。抽象的な「ビジョン」を語ることで、具体的な「何を捨てるか」から逃げている人。私は、少なくともそうはなりたくない。だから、小さな範囲でもいいから、選択し続ける。それが「逃げ」かどうかは、結果が教えてくれるだろう。戦略を立てるスキルは、3つの要素で形成される。第一に、本当に重要なものとそうでないものを見極める能力。第二に、その重要な問題が手持ちのリソースで解決可能かを判断する能力。第三に、リソースを集中投入する決断を下す能力。見極める。判断する。決断する。フレームワークでは学べない。理論でも教えられない。AIにも任せられない。では、どうやって身につけるのか。経験だ。失敗だ。振り返りだ。そして、自分の責任範囲で実践することだ。経営会議では言えなくても、自分のチームでは実践できる。そこで、何度も試す。何度も失敗する。何度も学ぶ。数年間、何度も失敗した。ある時、プラットフォームエンジニアとして、CI/CDパイプラインの刷新を提案した。分析は完璧だった。ビルド時間の短縮率も、デプロイ頻度の改善予測も計算した。しかし、導入されなかった。なぜなら、開発チームの理解が得られなかったからだ。彼らは、新しいパイプラインを信じていなかった。今のJenkinsで十分だと思っていた。彼らの視点を理解していなかった。だから、提案は受け入れられなかった。別の時、Kubernetesへの移行について相談された。コスト分析も、リスク分析も、移行計画も、調べて用意した。しかし、実行されなかった。なぜなら、組織がリスクを取れなかったからだ。今の運用で手一杯だった。新しい基盤に投資する余裕がなかった。組織の状況を理解していなかった。だから、提案は棚上げされた。自分のチームでも失敗した。開発者プラットフォームの改善プログラムを進めようとした。どこを改善すれば、どれだけ効果が出るか、細かく計算した。しかし、実行は中途半端に終わった。なぜなら、改善すべきものを明確にしなかったからだ。「全体的に改善しましょう」と言った。結果、誰もが「自分のところは変えなくていい」と思った。中途半端に変えて、効果も中途半端だった。選択する勇気がなかった。だから、失敗した。これらの失敗から、私は学んだ。戦略は、論理だけでは動かない。人を動かさなければならない。人を動かすには、彼らの視点を理解しなければならない。彼らの懸念を理解しなければならない。彼らの制約を理解しなければならない。戦略は、分析だけでは生まれない。判断が必要だ。「これが最重要だ」という判断。「これは捨てる」という判断。判断には、勇気が必要だ。間違うだろう恐怖と向き合う勇気が。戦略は、計画だけでは実現しない。実行が必要だ。実行には、コミットメントが必要だ。「これをやり遂げる」というコミットメント。困難に直面しても、諦めないコミットメント。論理。判断。コミットメント。この三つが揃って、初めて戦略は機能する。そして、これは、本を読むだけでは身につかない。理論を学ぶだけでは得られない。AIに聞いても教えてくれない。現場で、実際に戦略を作る。実行する。失敗する。振り返る。この繰り返しの中でしか、身につかない。経営は、科学ではない。人に依る。どれだけ理論を学んでも、どれだけデータを分析しても、最後は人の判断だ。その人が、どう見るか。どう感じるか。どう決めるか。そして、その判断は、再現性が低い。同じ状況でも、違う人なら、違う判断をする。同じ人でも、違うタイミングなら、違う判断をする。だから、経営には「正解」がない。あるのは、「その時、その人が、最善だと信じた選択」だけだ。これは、不安だ。頼りない。でも、これが現実だ。戦略を語る人は、多い。でも、戦略を作る人は、少ない。戦略を作ることは、快適ではないからだ。答えのない問いと向き合う。対立を引き受ける。リスクを負う。責任を取る。だからこそ、「語れ」と言いたい。しかし、責任を持って。美しい言葉を並べるだけではなく。フレームワークを使って終わりではなく。スライドを作って満足するのではなく。本当の戦略は、もっと地味だ。もっと泥臭い。現場を見る。数字を見る。人と話す。何度も考える。何度も見直す。何度も修正する。そして、決める。やると決める。やらないと決める。これが、戦略だ。企業全体の戦略を作ることは、私にはできない。立場が違う。責任の範囲が違う。でも、自分の責任範囲では、できる。そして、それで十分だ。小さな範囲でも、根っこは同じだからだ。問題を見極める。解決策を見つける。選択する。実行する。これができれば、それは戦略だ。私自身、最近やったことがある。自分の「責任範囲」で、今週中にやめると決められることを1つだけ、紙に書き出した。それをやめることで、どんなリソースが解放されるか考えた。そして、「戦略」という言葉を使わずに、これから1年の方針を「問題→選択→行動」の3行で書いてみた。書けた時、少しだけ、戦略を作る側に立てた気がした。そして、もう1つ。声に出すことの価値について。私は長いあいだ、「立場を超えて意見するのは越権行為だ」と思っていた。技術顧問は技術のことだけ言えばいい。経営戦略に口を出すのは筋違いだ。そう思っていた。でも、最近は少し考えが変わった。黙っていても、組織が良くなることはない。「これ、おかしいのではないか」と感じた時、黙っていれば波風が立たない。ただ、波風を立てないことと、組織を良くすることは別だ。誰かが声を上げなければ、おかしいことはおかしいままだ。もちろん、声の上げ方は重要だ。対立を煽る言い方ではなく、建設的な問いかけとして。「これは戦略ですか」と詰問するのではなく、「この戦略で解決したい最重要課題は何ですか」と問う。相手を追い詰めるのではなく、一緒に考える姿勢で。「おい、戦略を語れ」。このタイトルには、怒りがある。「おい」という呼びかけには、苛立ちがある。会議で空虚な戦略を語る人たちへの怒り。それもある。しかし、正直に言えば、怒りの多くは自分に向いている。かつての自分も、同じことをしていたから。今でも、完璧にはできていないから。「戦略を語れ」と他人に言いながら、自分は語れているのか。この怒りの裏には、期待がある。もっとうまくやれるはずだ、という期待。自分に対しても、組織に対しても。その期待が裏切られるたびに、怒りが生まれる。そして、その怒りを誰かにぶつけたくなる。「おい、戦略を語れ」と。しかし、怒りだけでは何も変わらない。怒りを、行動に変えなければならない。自分の責任範囲で、選択し続けること。声を上げ続けること。それが、怒りを建設的なものに変える唯一の方法だ。だから、この言葉は、他人に向けているようで、実は自分に向けている。お前は本当に戦略を語れているのか。中身のない言葉を並べていないか。選択から逃げていないか。そう自分に問いかけている。でも同時に、この言葉は、外に向けても発したい。会議で空虚な「戦略」が語られている時。誰もがうなずいているけれど、誰も本当には信じていない時。そういう時に、「それは本当に戦略ですか」と問いかける勇気を持ちたい。声を上げることは、リスクだ。嫌われるだろう。場の空気を壊すだろう。「余計なことを言う奴」と思われるだろう。それでも、本当に重要なことは、声に出さなければ伝わらない。心の中で思っているだけでは、何も変わらない。自分の責任範囲で戦略を実践すること。そして、必要な時には、声を上げること。この2つが揃って、初めて「戦略を語れ」というタイトルに応えられる気がする。「それだけ」の難しさ結局、戦略とは何なのか。長々と書いてきたが、煎じ詰めれば、やるべきことはシンプルだ。核心的な課題を見極めているか、確認する。その課題を本当に解決できているか、問い続ける。妥協なく、選択と集中ができているか、点検する。うまくいっていないなら、うまくいきそうな方に舵を切る。それだけだ。こう書くと、「そんなの当然だ」と感じるだろう。しかし、自分の仕事を振り返ってみてほしい。本当にこれができているだろうか。「課題を見極めているか」を確認するとは、自分たちの判断を直視することだ。これは、自分たちの見立て違いや判断ミスと向き合うことでもある。誰だって、自分が間違っていたとは認めたくない。だから、別の指標を見てしまう。納期に間に合ったか、予算内に収まったか、上司に怒られなかったか。「核心を突けているか」ではなく、「うまくやり過ごせているか」を見てしまう。仕事をしていると、いつの間にか「課題を解決する」という目的が薄れていく。たとえば、内部開発者プラットフォームの構築プロジェクト。最初は「開発者の生産性を上げる」という明確な目的があったはずだ。しかし、プロジェクトが進むにつれて、目的は変質していく。「Kubernetesクラスタを予定通りに構築する」「監視ツールを導入する」「経営層への報告をうまくまとめる」。気づけば、開発者が本当に使いやすいかどうかより、プロジェクトとして「成功」と言えるかどうかが関心事になっている。「課題を解決しているか」という問いは、常に意識しないと蒸発してしまう。なぜなら、その問いに向き合うのは苦しいからだ。解決できていないという不安と向き合わなければならない。「妥協なく」という言葉も、簡単ではない。妥協は悪意からではなく、善意や現実主義から生まれる。「この機能、完璧ではないけど、ないよりましだろう」「全員が満足するものを作れないから、ある程度のところで折り合いをつけよう」「理想を追求していたら、いつまでも終わらない」。一見、成熟した判断に見える。しかし、この「妥協」が積み重なると、最後に出来上がるものが「そこそこ」になる。誰も強く不満を言わないが、強く満足する人もいない。一応使えるが、積極的に使いたいとは思わない。「そこそこ」は、失敗より危険だ。失敗は直せる。「そこそこ」は直せない。明らかな失敗なら、原因を追求して改善できる。しかし「そこそこ」は改善の動機を奪う。「一応は使われている」「致命的な問題はない」という状態は、変化への意欲を殺す。その状態が何年も続いた先に、誰も欲しがらないが捨てることもできない、ゾンビのようなプロダクトやサービスが生まれる。「うまくいっていないなら、舵を切る」。この言葉の中で、最も実行が難しいのはこの部分だろう。まず、「うまくいっていない」と認めることが難しい。これまでの努力を否定することになるからだ。「方向性は間違っていないが、やり方に問題があった」「もう少し続ければ成果が出る」と思いたい。次に、「うまくいきそうな方向」を見つけることが難しい。うまくいっていないことは分かっても、代わりにどうすればいいかは分からない。だから、現状維持を選んでしまう。少なくとも、今のやり方なら「最悪ではない」ことは分かっている。未知の方向に舵を切るのは、博打に見える。では、この「それだけ」を実践するには何が必要なのか。目的を見失わない仕組み。日常の作業に埋没すると、なぜこれをやっているのかを忘れる。定期的に、しかも形式的にではなく真剣に、「何のためにやっているのか」を問い直す機会が必要だ。週に一度でも、チームで「これは本当に問題を解決しているか」と話し合う。その習慣があるかないかで、結果は大きく変わる。小さく試す文化。大きな賭けは、舵を切りにくくする。三年かけて作ったものを「やっぱりダメでした」とは言いにくい。しかし、二週間で作ったものなら、「これは違った、次を試そう」と言える。小さく作り、早く確認し、素早く方向修正する。このサイクルを速く回せる環境があれば、舵取りは格段に楽になる。失敗を許容する空気。「うまくいっていない」と言えるかどうかは、それを言った時に何が起こるかで決まる。責められるなら、誰も言わない。隠す。ごまかす。「うまくいっていない」という報告が、責任追及ではなく改善の起点として扱われる組織でなければ、正直な確認はできない。判断の軸を持つこと。舵を切る方向を決めるには、判断の軸が必要だ。「顧客の困りごとを減らす」「使う人の時間を節約する」「この体験を心地よくする」。何でもいい、しかし具体的で、検証可能な軸。それがあれば、「こっちの方がうまくいくだろう」という仮説を立てられる。軸がなければ、どこに舵を切っていいか分からない。「それだけ」という言葉は、謙遜ではない。本当に、やるべきことはそれだけなのだ。作れているかを見る。問題を解決しているかを問う。妥協しない。確認し続ける。必要なら方向を変える。しかし、この「それだけ」を本当に実践している組織やチームや個人は驚くほど少ない。私たちは目的を忘れ、妥協に流され、現実から目を逸らし、変化を恐れる。「それだけ」の中に、ものづくりの、いや、あらゆる仕事の核心がある。そして、その核心を貫くことの難しさと向き合い続けることが、良い仕事をするということなのだろう。おわりにここまで読んでしまった人がいるとしたら、申し訳ない気持ちが少しある。この文章を読んでも、明日から「戦略が立てられる人」にはならない。私自身がそうだったから分かる。本を読んだ直後は「分かった」と思う。会議で使えそうなフレーズをいくつかメモする。「核心的な課題を見極める」「何をやらないかを決める」。いい言葉だ。これを使えば、自分も戦略を語れる側の人間になれる気がする。でも翌週、いざ自分の仕事で使おうとすると手が止まる。「で、何から始めるんだっけ」。頭の中でフレーズは踊っているのに、目の前の仕事にどう適用すればいいか分からない。結局、また賢そうな顔をして会議に座っている。何も変わっていない。たぶん、戦略を立てる力は、戦略を立てることでしか身につかない。走り方の本を読んでも走れるようにならないのと同じだ。転んで、膝を擦りむいて、また走る。そうやってしか身につかない。身も蓋もないけど、そうとしか言いようがない。だから、この文章には限界がある。読んだだけでは何も変わらない。でも、もしかしたら、何かが引っかかるかもしれない。次の会議で「戦略」という言葉を聞いた時、「それ、本当に戦略？」と心の中でツッコめるようになったら、それだけで意味がある。自分のチームの方向性を考える時に「で、何を捨てるの？」という問いが頭をよぎるようになったら、それで十分だ。その小さな引っかかりが、いつか行動に変わるかもしれない。変わらないかもしれない。でも、引っかかりがなければ、変わる可能性すらない。正直に言えば、この文章は誰かのためというより、自分のために書いた。書きながら「お前、分かってないじゃん」と何度も思った。調べれば調べるほど、自分の理解の浅さが見えてくる。偉そうに「戦略とは何か」を語っているけど、じゃあお前は実践できているのか。そう問われたら、黙るしかない。「おい、戦略を語れ」という怒りは、他人への苛立ちではなかった。鏡に映った自分への問いかけだった。語れているのか。実行できているのか。逃げていないか。分かったふりを続けていないか。その問いに、まだ答えられていない。明日も会議がある。誰かが「戦略」と言うだろう。私はまた、眉間にしわを寄せて「なるほど」という顔をするだろう。それは変わらない。でも、今度は少しだけ、違う気持ちで聞けるかもしれない。「それ、本当に戦略？」と心の中で問いかけながら。その問いかけは、きっと会議室の誰かにではなく、自分自身に向けられている。そう思えるだけで、この長い文章を書いた甲斐はあった。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍ストーリーとしての競争戦略 Hitotsubashi Business Review Books作者:楠木 建東洋経済新報社Amazon戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon「暗記する」戦略思考　「唱えるだけで」深く、面白い「解」を作り出す破壊的なコンサル思考【電子限定特典付】作者:高松智史かんき出版AmazonArchitecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazonプラットフォームエンジニアリング ―成功するプラットフォームとチームを作るガイドライン作者:Camille Fournier,Ian Nowland,松浦 隼人（翻訳）オーム社AmazonKubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazonジョブ理論　イノベーションを予測可能にする消費のメカニズム作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションの経済学　「繁栄のパラドクス」に学ぶ巨大市場の創り方作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションのジレンマ 増補改訂版 Harvard business school press作者:Clayton M. Christensen翔泳社Amazon【Amazon.co.jp 限定】戦略のデザイン ゼロから「勝ち筋」を導き出す10の問い（ダウンロード特典：『戦略デザイン力』セルフ診断シート データ配信）: ゼロから「勝ち筋」を導き出す１０の問い作者:坂田 幸樹ダイヤモンド社Amazon良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon君は戦略を立てることができるか 視点と考え方を実感する４時間作者:音部大輔Amazon戦略的思考とは何か 改版 (中公新書 700)作者:岡崎 久彦中央公論新社Amazon戦略、組織、そしてシステム: 「組み立てる」戦略思考の方法論作者:横山　禎徳東洋経済新報社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~Redis lists編~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_data_list</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_data_list</guid>
            <pubDate>Sun, 14 Dec 2025 09:21:41 GMT</pubDate>
            <content:encoded><![CDATA[今回はredisで使えるlistsについてみていきます。先日公開したHashesについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_data_hash 早速検証redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis listsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/lists/#performance ス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年版 PDE（Personal Development Environment）のすすめ：自分だけの刀を打つ開発環境構築]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/14/132552</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/14/132552</guid>
            <pubDate>Sun, 14 Dec 2025 04:25:52 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、Vim Advent Calendar 2025 13日目のエントリ記事です。はじめにVSCodeやJetBrains製品は、膨大な開発リソースを投じて作られた最強の武器だ。補完、デバッグ、Git統合、拡張機能——すべてが高度に洗練されている。多くの開発者にとって、これらを選ぶのは賢明な判断だと思う。それでも、私は自分で刀を打ちたい。ただし、誤解のないように言っておくと、名刀を打ちたいわけではない。美術館に飾られるような、完璧な一振りを目指しているわけではない。私が欲しいのは、戦場で戦うための道具だ。多少キズがあってもいい。見栄えが悪くてもいい。自分の手に馴染んで、明日の仕事で使えればそれでいい。では、なぜ自分で作るのか。正直に言えば、効率の問題ではない。もっと根本的な、性分の問題だ。思い返すと、私は子供の頃から構造や仕組みがどうしても気になって、分解してしまうクセがあった。おもちゃ、家電、何でも中がどうなっているか知りたくなる。そして仕組みを理解したら、自分なりに改修して「自分だけのもの」を作りたくなる。完成品を受け取るより、自分で手を入れる余地があるものに惹かれる。開発環境も同じだ。私は元々Vimユーザーで、その後Neovimに移行した。途中でVSCode、JetBrains、Cursorに浮気したこともある。どれも素晴らしいツールだった。だが、どうしても「自分で鍛えている」という感覚がなかった。「自分のもの」という実感が湧かなかった。具体的に言うと、こういうことだ。VSCodeを使っていたとき、settings.jsonをいじり、拡張機能を入れ替え、キーバインドを変え——気づけば「VSCodeをカスタマイズする」こと自体が目的になっていた。ならば、最初からカスタマイズ前提のツールを使えばいい。そう考えてNeovimに戻った。理由を論理的に説明するのは難しい。効率だけで言えば、IDEを使いこなす方が早いかもしれない。それでも、自分の手で環境を組み上げ、日々磨き、少しずつ自分の形に変えていく。その過程そのものに惹かれている。これは性分だ。こうした考え方には、実は名前がある。PDE（Personal Development Environment）——「個人開発環境」だ。自分のワークフローに最適化された、自分だけの開発環境を指す。私が10年かけてやってきたことは、まさにこのPDEの構築だった。この記事では、2025年現在の私のPDE構成を紹介する。Rust、Go、TypeScript、Pythonでの開発、そしてKubernetesやTerraformを使ったインフラ作業を想定した構成だ。IDEが合う人にはIDEを勧める。でも、もし「自分で作ってみたい」という気持ちがあるなら、この記事が参考になれば嬉しい。PDEとIDEの違いIDEは万人向けに最適化されており、インストール直後から高い生産性が得られる。学習曲線は緩やか、メンテナンスはベンダー任せ。一方PDEは個人最適化の代わりに、学習コストとメンテナンスを自分で負担する。どちらが優れているかではなく、「すぐ使える便利さ」と「自分で作る楽しさ」のトレードオフだ。もちろん、IDEにも自分の設定を入れられることは知っている。キーバインドを変更できるし、拡張機能は豊富だし、自分でプラグインを開発できる。VSCodeのsettings.jsonを何百行も書いた。それでも、私には「自分で作っている」という実感が足りなかった。論理的に説明するのは難しい。ただ、その実感の有無が、私にとっては大きかった。では、PDEとは結局何なのか。PDEの本質は「自分の手に馴染む道具を自分で作る」こと。職人が道具を磨くように、開発者も環境を育てていく。ただし、職人の道具は飾るためではなく使うためにある。PDEも同じだ。完璧な環境を作ることが目的ではなく、日々の開発で戦えることが目的だ。効率だけを求めるなら、IDEを使った方がいい場面も多い。私のPDE構成概要基盤はWarp Terminal。その上でFish Shellを動かし、プロンプトにはStarshipを使っている。エディタはNeovim（NvChadベース）で、LSPとTreesitterで補完とシンタックスハイライトを実現している。CLIツールはUnixの古典を現代版に置き換えた。lsの代わりにeza、catの代わりにbat、grepの代わりにripgrep。ディレクトリ移動はzoxide、リポジトリ管理はghq + fzf、差分表示はdeltaを使っている。AIアシスタントは複数導入しているが、主軸はClaude Code。Neovim内ではCopilotとAvanteも使っている。1. ターミナル：Warpwww.warp.devかつてはtmux + iTerm2の組み合わせを使っていた。しかし2024年、Warpに移行した。tmuxでやりたかったこと（ペイン分割、セッション管理）がWarp単体でできるし、見た目もかっこいい。使っていて特に不満もない。正直なところ、tmuxの設定をメンテナンスするのが面倒になっていた。tmux + Bash時代は.tmux.confが600行を超えていて、何がどう動いているのか自分でも把握しきれなくなっていた。現在はWarp + Fishという構成で、tmuxの設定は丸ごと不要になった。設定ファイルが減るのは精神衛生上とても良い。あと、Warpはモダンなターミナルらしく、補完がよく効く。コマンドを途中まで打つと候補が出てくる。tmux時代は「あのコマンドなんだっけ」とhistoryを漁ることが多かったが、その頻度が減った。気に入っている点ブロックベースの出力: コマンドの出力が独立したブロックとして扱われ、コピーや再利用が容易。長いログの一部だけコピーしたいときに便利セッション管理の内蔵: tmuxのペイン分割・セッション管理相当の機能が標準搭載。tmuxのプレフィックスキーを覚えなくていいAIアシスタント: 自然言語でコマンドを生成できる。正直あまり使っていないが、たまに「あのコマンドなんだっけ」というときに便利見た目: 単純にかっこいい。毎日使うものなので、見た目の満足度は意外と大事設定のポイント# ~/.warp/keybindings.yamlkeybindings:  # Vim風のペインナビゲーション  - command: move_focus_to_left_pane    keys: ctrl-h  - command: move_focus_to_right_pane    keys: ctrl-l  - command: move_focus_to_pane_above    keys: ctrl-k  - command: move_focus_to_pane_below    keys: ctrl-jtmuxの設定をメンテナンスする必要がなくなったのは大きい。.tmux.confの600行が不要になった。2. シェル：Fish Shellfishshell.comBashやZshではなくFishを選んだ理由は明確だ。設定なしで賢い。「それならIDEを使えばいいのでは」と思うかもしれないが、シェルは基盤だ。基盤が安定しているからこそ、その上で動くエディタやツールを自由にカスタマイズできる。すべてを自分で作る必要はない。Fish選択の決め手補完がすごい: 設定なしでコマンド履歴、ファイルパス、オプションを補完シンタックスハイライト: コマンド入力中にエラーが分かる設定の簡潔さ: ZshからFishに移行して、設定行数が600行から400行に減ったモダンCLIツール統合Unixの古典的コマンドを現代版に置き換えている。# ~/.config/fish/config.fish# ls → eza (icons + git status)if type -q eza    function ls --wraps eza        eza --icons --group-directories-first $argv    endend# cat → bat (syntax highlighting)if type -q bat    function cat --wraps bat        bat --paging=never $argv    endend# grep → ripgrep (faster + smarter)if type -q rg    function grep --wraps rg        rg $argv    endendgithub.comgithub.comgithub.com省略形（abbr）Fishにはabbr（abbreviation、省略形）という機能がある。入力してスペースを押すと、その場で展開される。# ~/.config/fish/config.fish# Git省略形abbr -a g gitabbr -a ga "git add"abbr -a gc "git commit"abbr -a gco "git checkout"abbr -a gd "git diff"abbr -a gp "git push"abbr -a gl "git pull"abbr -a gs "git status"abbr -a glog "git log --oneline --graph"# Docker省略形abbr -a d dockerabbr -a dc "docker compose"abbr -a dcu "docker compose up -d"abbr -a dcd "docker compose down"abbr -a dps "docker ps"# Kubernetes省略形abbr -a k kubectlabbr -a kgp "kubectl get pods"abbr -a kgs "kubectl get svc"abbr -a kgd "kubectl get deploy"abbr -a kd "kubectl describe"abbr -a kl "kubectl logs"abbr -a kex "kubectl exec -it"gsと入力してスペースを押すとgit statusに展開される。私がabbrを気に入っている理由は、展開後のコマンドが履歴に残ること、そして展開後に編集できることだ。Gitコマンドを1日に数十回打つ私にとって、この小さな省力化の積み重ねは大きい。ディレクトリ移動の革命：zoxidecdコマンドをzoxideで置き換えた。一度訪れたディレクトリは、部分一致でジャンプできる。# zoxideの有効化if type -q zoxide    zoxide init fish --cmd z | sourceend# 例：~/ghq/github.com/nwiizo/projectに移動z project  # これだけでOKgithub.comghq + fzf によるリポジトリ管理全てのリポジトリをghqで管理し、fzfで瞬時に移動する。function ghq_fzf_repo -d "Select repository with fzf"    set -l selected (ghq list -p | fzf \        --prompt="Repository: " \        --preview='ls -la {}')    if test -n "$selected"        cd $selected    endend# Ctrl+G でリポジトリ選択bind \cg ghq_fzf_repogithub.comdirenv による環境の自動切り替えプロジェクトごとの環境変数を.envrcで管理。ディレクトリに入ると自動で読み込まれる。# direnvの有効化（2025年現在のベストプラクティス）if type -q direnv    set -g direnv_fish_mode eval_on_arrow    direnv hook fish | sourceenddirenv.net3. プロンプト：Starshipstarship.rsStarshipは、Rustで書かれた高速なクロスシェルプロンプト。Git状態、言語バージョン、クラウド環境を一目で確認できる。# ~/.config/starship.tomlformat = """$directory\$git_branch\$git_status\$golang\$rust\$python\$kubernetes\$cmd_duration\$line_break\$character"""[character]success_symbol = "[❯](bold green)"error_symbol = "[❯](bold red)"[kubernetes]symbol = "☸ "disabled = falseKubernetes contextが常に表示されるので、本番環境で作業しているか一目で分かる。これで何度か事故を防げた。4. エディタ：Neovim + NvChadneovim.ionvchad.comVim/Neovimを使い始めて10年以上になる。途中でVSCode、JetBrains、Cursorを試したこともあるが、どれも1ヶ月以上メインに居座ったことはない。併用はしても、結局Neovimに戻ってきた。VSCodeもJetBrainsも素晴らしいエディタで、今でもそう思っている。ただ、私は自分で環境を組み立てたかった。その欲求が、他のエディタでは満たされなかった。2025年版 Minimal UI アーキテクチャ2025年の私のNeovim設定で最も特徴的なのは、statusline-less workflowだ。従来のstatuslineやtabuflineを廃止し、必要な情報のみをfloating windowで表示する。編集領域を最大化しつつ、必要な情報は失わない。 コンポーネント  プラグイン  役割  ファイル情報  incline.nvim  右下floating statusline  モード表示  modes.nvim  cursorline色でモード表示  コマンドライン  noice.nvim  floating cmdline (cmdheight=0)  バッファ薄暗化  vimade  非アクティブバッファをdim  コードピーク  overlook.nvim  LSP定義をstackable popup表示  ファイル選択  Snacks.nvim  smart pickerでbufferline代替 github.comincline.nvimは画面右下に小さなfloating windowでファイル情報を表示する。ファイルアイコン、ファイル名、未保存マーク、診断数が一目で分かる。init.luaのような汎用的なファイル名の場合は親ディレクトリも表示される（plugins/init.luaのように）。github.commodes.nvimはInsert/Visual/Deleteなどのモードをcursorlineの色で表現する。Insertはシアン、Visualは紫、Deleteは赤。-- INSERT --のようなテキスト表示が不要になり、視覚的に直感的。-- options.lua での設定vim.o.cmdheight = 0      -- コマンドライン非表示（noice.nvimが代替）vim.o.laststatus = 0     -- statusline非表示（incline.nvimが代替）vim.o.showmode = false   -- モード表示非表示（modes.nvimが代替）キーマップの発見性：which-key.nvimgithub.com2025年のNeovim設定で欠かせないのがwhich-key.nvimだ。キーを押すと、次に押せるキーの一覧がポップアップで表示される。「あのキーマップなんだったっけ」という問題が解消される。{  "folke/which-key.nvim",  opts = {    preset = "helix",    spec = {      { "<leader>a", group = "AI" },      { "<leader>g", group = "Git" },      { "<leader>s", group = "Search" },      { "<leader>x", group = "Diagnostics" },    },  },  keys = {    { "<leader>?", function() require("which-key").show() end, desc = "Buffer Keymaps" },  },}<leader>を押して少し待つと、aでAI、gでGit、sでSearch...とグループ分けされたキーマップが表示される。新しいプラグインを入れてもキーマップを覚える必要がない。ナビゲーションSnacks.nvim - 2025年のモダンユーティリティ集。github.comSnacks.nvimはfolke氏による新しいプラグインで、picker、lazygit統合、buffer削除などを統合している。特にsmart pickerが便利で、ファイル・バッファ・最近使用したファイルを一つのインターフェースで検索できる。{  "folke/snacks.nvim",  keys = {    { "<leader><leader>", function() Snacks.picker.smart() end, desc = "Smart Picker" },    { "<leader>gg", function() Snacks.lazygit.open() end, desc = "LazyGit" },    { "<leader>sf", function() Snacks.picker.files() end, desc = "Find Files" },    { "<leader>sg", function() Snacks.picker.grep() end, desc = "Grep" },  },}lazygit統合ではeditPreset = "nvim-remote"を設定することで、lazygit内でファイルを開くと現在のNeovimインスタンスで開かれる。別ウィンドウが立ち上がらない。Telescope - 検索のハブ（サブとして併用）。github.com{  "nvim-telescope/telescope.nvim",  keys = {    { "<leader>ff", "<cmd>Telescope find_files<cr>", desc = "Find Files" },    { "<leader>fg", "<cmd>Telescope live_grep<cr>", desc = "Live Grep" },    { "<C-p>", "<cmd>Telescope find_files<cr>", desc = "Find Files" },  },}oil.nvim - ファイルシステムをバッファとして編集。github.comneo-treeのようなツリー表示ではなく、ファイルシステムを通常のバッファとして扱う。ファイル名の変更は行の編集、削除は行の削除。Vimユーザーには直感的。{  "stevearc/oil.nvim",  keys = {    { "-", "<cmd>Oil<cr>", desc = "Open parent directory" },  },}flash.nvim - 画面内の任意の位置にジャンプ。github.comsを押して文字を入力すると、その文字にラベルが表示される。ラベルを押すとジャンプ。hop.nvimの後継で、メンテナンスも活発。overlook.nvim - コードピーク。github.comLSPの定義をfloating popupで表示する。ファイルを開かずに定義を確認できる。popupはスタック可能で、複数の定義を同時に表示できる。{  "WilliamHsieh/overlook.nvim",  keys = {    { "<leader>pd", function() require("overlook").open_definition() end, desc = "Peek Definition" },    { "<leader>pc", function() require("overlook").close_all() end, desc = "Close All Popups" },  },}診断・デバッグtrouble.nvim v3 - 診断情報のUI。github.com2024年にv3として完全書き直しされた。ツリービュー対応で、エラーの階層構造が見やすい。{  "folke/trouble.nvim",  keys = {    { "<leader>xx", "<cmd>Trouble diagnostics toggle<cr>" },    { "<leader>xX", "<cmd>Trouble diagnostics toggle filter.buf=0<cr>" },    { "<leader>xs", "<cmd>Trouble symbols toggle<cr>" },  },}todo-comments.nvim - TODO/FIXME/NOTEのハイライト。コード内のTODOコメントを自動検出してハイライト。Telescopeと連携してプロジェクト全体のTODOを一覧表示できる。Git統合gitsigns.nvim - インラインGit情報。github.com変更行の横にサイン（│）が表示される。hunk単位でのステージ、リセット、プレビューが可能。{  "lewis6991/gitsigns.nvim",  opts = {    on_attach = function(bufnr)      local gs = package.loaded.gitsigns      vim.keymap.set("n", "]c", gs.next_hunk, { buffer = bufnr, desc = "Next Hunk" })      vim.keymap.set("n", "[c", gs.prev_hunk, { buffer = bufnr, desc = "Prev Hunk" })      vim.keymap.set("n", "<leader>gp", gs.preview_hunk, { buffer = bufnr, desc = "Preview Hunk" })      vim.keymap.set("n", "<leader>gb", function() gs.blame_line { full = true } end, { buffer = bufnr, desc = "Blame Line" })    end,  },}diffview.nvim - Git diffの可視化。github.comGit差分をNeovim内で確認できる。ファイル履歴も見やすい。2025年版では、より多くのキーマップを設定している。{  "sindrets/diffview.nvim",  keys = {    { "<leader>gd", "<cmd>DiffviewOpen<cr>", desc = "Git Diff (working tree)" },    { "<leader>gD", "<cmd>DiffviewOpen HEAD~1<cr>", desc = "Diff vs previous commit" },    { "<leader>gh", "<cmd>DiffviewFileHistory %<cr>", desc = "File History" },    { "<leader>gH", "<cmd>DiffviewFileHistory<cr>", desc = "Branch History" },    { "<leader>gm", "<cmd>DiffviewOpen main...HEAD<cr>", desc = "Diff vs main branch" },    { "<leader>gs", "<cmd>DiffviewOpen --staged<cr>", desc = "Staged changes" },    { "<leader>gq", "<cmd>DiffviewClose<cr>", desc = "Close Diffview" },  },}Diffview内では-でステージ/アンステージ、Sで全てステージ、Xで変更を復元。コンフリクト解決も<leader>co（ours）、<leader>ct（theirs）で直感的に操作できる。LSP設定Mason.nvimで言語サーバーを管理。主要な言語はすべてカバー。ensure_installed = {  -- Rust  "rust-analyzer",  -- Go  "gopls", "gofumpt", "goimports",  -- TypeScript/JavaScript  "typescript-language-server", "prettier",  -- Python  "pyright", "black", "isort",  -- Infrastructure  "terraform-ls", "yaml-language-server",  -- Shell  "bash-language-server", "shellcheck",}2025年のポイントとして、JSON/YAMLにはSchemaStoreを統合している。package.jsonやdocker-compose.ymlの補完がスキーマベースで効くようになる。github.com5. AIアシスタント統合2024年から2025年にかけて、開発環境で最も大きく変わったのはAIの存在だ。コード補完、生成、レビュー、デバッグ——あらゆる場面でAIが介在するようになった。2025年のPDEにおいて、AIツールは最も重要な要素になっている。私は複数のAIツールを導入しているが、主軸はClaude Codeだ。Claude Code - 開発の中心docs.anthropic.comターミナルで起動し、コード生成、リファクタリング、デバッグ、質問——ほとんどの作業をClaude Codeで完結させている。私の使い方の特徴は、プロジェクトごとにカスタマイズしている点だ。やっていることはシンプルで、3つのファイルを育て続けている。project/├── CLAUDE.md              # プロジェクト固有の指示├── .claude/│   ├── commands/          # カスタムスラッシュコマンド│   │   ├── review.md│   │   └── test.md│   └── agents/            # 特化型エージェント│       └── reviewer.mdCLAUDE.md にはプロジェクトの文脈を書く。使用技術、コーディング規約、避けるべきパターンなど。これがあるとClaude Codeの回答精度が劇的に上がる。commands にはよく使う操作をスラッシュコマンドとして定義する。/reviewでコードレビュー、/testでテスト生成など。毎回同じプロンプトを書く手間が省ける。agents には特定タスクに特化したエージェントを定義する。レビュー専門、リファクタリング専門など、役割を分けることで精度が上がる。重要なのは、これらを使いながら修正し続けること。「この指示だと意図と違う結果になる」と気づいたらCLAUDE.mdを更新する。コマンドの出力が物足りなければcommandを調整する。PDEと同じで、日々の開発の中で育てていく。Neovimとの連携にはclaude-code.nvimを使っている。github.com{  "greggh/claude-code.nvim",  keys = {    { "<leader>cc", "<cmd>ClaudeCode<cr>", desc = "Claude Code" },    { "<leader>cr", "<cmd>ClaudeCodeResume<cr>", desc = "Resume Conversation" },  },}<leader>ccでClaude Codeのターミナルウィンドウをトグル。エディタで開いているファイルをそのままClaude Codeに渡せる。Neovim内のAIツールNeovim内ではCopilotとAvanteを併用している。github.comCopilotはインライン補完用。コードを書いている最中に候補が表示され、Tabで確定する。考えながら書くときに便利。copilot-cmpと組み合わせて、補完メニューの最上位にCopilotの提案が表示されるようにしている。github.comCopilotChatはAIチャット用。コードの説明、修正、テスト生成、ドキュメント生成などをチャット形式で行える。モデルはclaude-sonnet-4を使用。{  "CopilotC-Nvim/CopilotChat.nvim",  opts = { model = "claude-sonnet-4" },  keys = {    { "<leader>ao", "<cmd>CopilotChatOpen<cr>", desc = "Open Chat" },    { "<leader>ae", "<cmd>CopilotChatExplain<cr>", desc = "Explain Code", mode = { "n", "v" } },    { "<leader>af", "<cmd>CopilotChatFix<cr>", desc = "Fix Code", mode = { "n", "v" } },    { "<leader>at", "<cmd>CopilotChatTests<cr>", desc = "Generate Tests", mode = { "n", "v" } },    { "<leader>ad", "<cmd>CopilotChatDocs<cr>", desc = "Generate Docs", mode = { "n", "v" } },    { "<leader>aR", "<cmd>CopilotChatReview<cr>", desc = "Review Code", mode = { "n", "v" } },  },}github.comAvanteはCursorエディタのAI機能をNeovim上に再現するプラグイン。ファイル横断の変更や設計相談に使う。<leader>aaで質問すると、サイドパネルが開いてAIとの対話が始まる。{  "yetone/avante.nvim",  opts = {    provider = "copilot",    mode = "agentic",    providers = {      copilot = { model = "claude-sonnet-4" },    },    mappings = {      ask = "<leader>aa",      edit = "<leader>ax",    },  },}AI統合のキーマップまとめ キー  プラグイン  説明  <leader>aa  Avante  AI質問  <leader>ao  CopilotChat  チャットを開く  <leader>ae  CopilotChat  コードを説明  <leader>af  CopilotChat  コードを修正  <leader>at  CopilotChat  テスト生成  <leader>ad  CopilotChat  ドキュメント生成  <leader>aR  CopilotChat  コードレビュー  <leader>cc  Claude Code  Claude Code起動  <leader>cr  Claude Code  会話を再開 6. 言語別の設定Rustは私のメイン言語なので、専用プラグインを導入している。rustaceanvimでrust-analyzerを強化し、crates.nvimでCargo.tomlのバージョンを管理する。Cargo.tomlを開くと、各クレートの最新バージョンがインラインで表示される。github.comgithub.comGo、TypeScript、Pythonは特別な設定をしていない。LSP設定セクションで示したensure_installedにより、各言語サーバーが自動でセットアップされる。保存時の自動フォーマットはconform.nvimに任せている。詳細な設定はdotfilesリポジトリを参照してほしい。7. フォーマッター統合conform.nvimで保存時に自動フォーマット。言語ごとに適切なフォーマッターを設定。{  "stevearc/conform.nvim",  opts = {    formatters_by_ft = {      lua = { "stylua" },      rust = { "rustfmt" },      go = { "gofmt", "goimports", "gofumpt" },      python = { "black", "isort" },      typescript = { "prettier" },      javascript = { "prettier" },      yaml = { "prettier" },      json = { "prettier" },      markdown = { "prettier" },    },    format_on_save = { timeout_ms = 500, lsp_fallback = true },  },}github.comPDEを育てるということPDEは完成することがない。日々の開発の中で、少しずつ手を入れ続ける。刀から庭へこの記事のタイトルには「刀を打つ」と書いた。実際、PDEには刀を打つ行為がある。ターミナルを選び、シェルを設定し、エディタを組み上げる。ゼロから自分の道具を作り上げていく。ただ、刀には完成がある。名刀は打ち上がれば、あとは研ぎ澄ますだけ。床の間に飾られ、鑑賞される。しかしPDEには完成がない。プラグインは更新され、新しいツールが登場し、自分の作業スタイルも変わる。「完成した」と思った翌週には、また何かをいじっている。最初は名刀を打つつもりだった。「理想の開発環境を作り上げる」という完成形を目指していた。だが10年経って気づいた。私が欲しかったのは名刀ではなく、戦場で使える道具だった。戦場で使える道具とは何か。それは、完成を待たずに使い始められるものだ。使いながら調整し、壊れたら直し、足りなければ足す。常に未完成で、常に変化している。ここで気づいた。私がやっていることは、刀を打つだけではない。打った刀を、日々手入れし続けている。使いながら研ぎ、傷がつけば直し、必要に応じて改良する。この「手入れし続ける」という感覚——何かに似ている。そうだ、庭だ。庭も完成しない。季節ごとに姿を変え、草木は勝手に育ち、手入れを怠れば荒れる。人間が設計するが、人間の思い通りにはならない。それでも手を入れ続けることで、少しずつ自分の形になっていく。宇野常寛さんの『庭の話』という本が、この感覚を言語化してくれた。www.kodansha.co.jp宇野さんは、現代のプラットフォーム（SNS）を「相互評価のゲームに特化した空間」として批判し、対抗概念として「庭」を提示する。プラットフォームが画一化された承認欲求の交換の場であるのに対し、庭は「完全にはコントロールできないもの」との共存の場だ。草木が勝手に育ち、虫が飛び交い、季節によって姿を変える。人間が設計するが、人間の思い通りにはならない。この説明を読んだとき、私は自分のPDEのことを思い浮かべた。プラグインが勝手にアップデートされ、設定が壊れ、新しいツールが登場する。思い通りにならない。でも、手を入れ続けることで、少しずつ自分の形になっていく。宇野さんの言う「プラットフォーム」と「庭」の対比は、そのまま開発環境にも当てはまる。IDEはプラットフォームだ。ベンダーが設計し、万人に最適化されたサービスを提供する。ユーザーはそれを消費する。便利で、効率的で、すぐに使える。しかし、自分でコントロールできる範囲は限られている。一方、PDEは刀を打ち、庭として育てるものだ。自分で道具を作り、その道具を手入れし続ける。プラグインが競合し、設定が壊れ、アップデートで挙動が変わる。それでも、手を入れ続けることで、少しずつ自分の形になっていく。消費ではなく、制作。受け取るのではなく、育てる。宇野さんは「消費から制作へ」という転換を説く。プラットフォームで承認を求めるのではなく、制作に没頭すること。エンジニアとして、私たちは「正解」を求めがちだ。最適解を見つけ、効率を最大化し、その成果で報われたいと思う。だが、PDEにはそういう正解がない。「正しい設定」も「最適なプラグイン構成」も存在しない。ネットで見つけた「おすすめ設定」をコピペしても、それは自分の刀にはならない。正解を求めて報われようとするのをやめる。他者から評価される「模範解答」を探すのではなく、自分の手に馴染む道具を、自分のために作る。PDEを構築する行為は、まさにこの「制作」だ。誰かに見せるためではなく、自分のために作る。その過程で、ツールとの対話が生まれる。「家庭」という言葉は「家」と「庭」でできている。宇野さんは「家」の内部で承認を交換するだけでは見えないものが「庭」にはあると言う。開発環境も同じだ。IDEという「家」の中で完結するのではなく、PDEという「庭」に出ることで、ツールとの新しい関係が見えてくる。ツールと思考の相互作用ツールとの新しい関係とは何か。PDEを10年実践する中で、1つ気づいたことがある。ツールは思考に影響し、思考はツールに影響される。これは単なる比喩ではない。以前、AIエージェントとの協働について書いた記事で、私は「集中とは自分の能力ではなく環境との関係である」と述べた。syu-m-5151.hatenablog.com環境との関係——これはPDEにも当てはまる。具体的な例を挙げよう。Vimのモーダル編集を使い始めると、テキスト操作を「動詞＋名詞」で考えるようになる。d（削除）+ w（単語）で「単語を削除」。この思考パターンは、コードを書くときの発想にも影響する。操作を小さな単位に分解し、組み合わせて目的を達成する。逆に、自分の思考スタイルに合わないツールは、どれだけ高機能でも使いこなせない。合わないものは合わない。それだけのことだ。重要なのは、この相互作用を意識的に活用することだ。新しいツールを導入するとき、私は「このツールは自分の思考をどう変えるか」を考える。AIエージェントを使い始めたとき、深く没入する集中から、複数タスクを並行監視する集中へと、思考のモードを切り替える必要があった。環境が変われば、思考も変わるべきなのだ。PDEとは、単にツールをカスタマイズすることではない。自分の思考とツールの関係を最適化し続けることだ。AIは庭の一部か、庭師か2025年のPDEを語る上で、AIツールの位置づけは避けて通れない。私はClaude Codeを「主軸」と書いた。しかし、これは従来のツールとは異なる存在だ。Neovimは私が設定し、私が操作する。一方Claude Codeは、私と対話し、私の意図を解釈し、時に私が思いつかなかったアプローチを提案する。これは庭の一部なのか、それとも共に庭を育てる存在なのか。正直に言えば、まだ答えは出ていない。ただ、1つ確かなことがある。CLAUDE.mdを更新し、カスタムコマンドを調整し、エージェントを育てる——この作業は、Neovimのプラグイン設定と同じ感覚だ。AIツールもまた、PDEの一部として「育てる」対象になっている。同時に、Claude Codeは私のPDEを育てる側でもある。「この設定、冗長では」「こういうプラグインがある」と提案してくる。人間が庭を育て、庭が人間を育てる。その関係がAIツールとの間にも成り立っている。私のPDE改善サイクルでは、具体的にどうやってPDEを育てているのか。私の場合、こんなサイクルを回している。気づく: 「この操作、毎日10回はやってるな」調べる: 既存のプラグインや設定で解決できないか試す: 設定を追加して数日使ってみる磨く: 使いにくければ調整、良ければ定着このサイクルを回し続けていると、つい完璧を目指したくなる。だが、ここで立ち止まる必要がある。すべてを自作する必要はない。すべてをOSSで揃える必要もない。それをやると疲れる。Fish、Warp、Starshipを選んだのも「設定なしで賢い」からだ。力を入れるところと抜くところを分ける。適度にやっていくことが、PDEを長く続けるコツだと思う。これもまた、刀を打ち、庭として育てることの本質だ。名刀を打つなら妥協は許されない。だが戦場で使う刀は違う。多少キズがあっても戦えればいい。庭も同じだ。すべてを自分で育てる必要はなく、買ってきた苗を植えてもいい。大事なのは、戦場で戦えること。実際の開発で使えること。完璧な道具を作ることではない。設定ファイルの管理dotfilesはGitで管理。どのマシンでも同じ環境を再現できる。dotfiles/├── fish/           # Fish shell├── nvim/           # Neovim├── warp/           # Warp terminal├── starship/       # Starship prompt└── git/            # Git config5年後、PDEは存在するかAIの進化を見ていると、ふと考えることがある。5年後、開発環境を「自分で構築する」という行為に意味はあるのか。AIがコードを書き、テストを実行し、デプロイまで行う時代が来るかもしれない。そのとき、エディタの設定にこだわる意味があるのか。Neovimのキーバインドを覚える価値があるのか。正直に言えば、分からない。5年後の開発がどうなっているか、誰にも予測できない。ただ、こうも思う。むしろ逆かもしれない、と。従来、PDEの構築には学習コストとメンテナンスコストがかかり、それに見合う生産性向上が得られるかは不透明だった。しかしAIは、このトレードオフを限りなく等価に近づけてくれる。環境を改善すれば、その改善がAIを介して直接生産性に反映される。CLAUDE.mdを1行書き足せば、その分だけAIの出力が良くなる。PDEが「趣味」から「現実的に有効な投資」になる時代が来ているのかもしれない。ただ、1つだけ確信していることがある。「自分で作りたい」という欲求は消えない。ツールが変わっても、プラットフォームが変わっても、「与えられたものをそのまま使うのではなく、自分の手を入れたい」という欲求は残る。少なくとも、私はそういう人間だ。AIがすべてを生成する時代が来ても、そのAIをどう使うか、どうカスタマイズするか、どう自分のワークフローに組み込むか——そこにPDEの精神は生き続けると思う。道具は変わっても、道具との関係を自分で設計したいという欲求は変わらない。まとめここまで私のPDE構成を紹介してきた。Warp上でFishを動かし、NeovimとClaude Codeを併用する——これらを組み合わせて、自分だけの「刀」を作り上げて「庭」を育てている。PDEを選ぶ理由は効率では説明できない。最初の2週間は生産性が落ちるし、1ヶ月かけて元に戻る。それでも、自分で組み上げ、日々改善していく過程そのものに価値がある。消費ではなく制作、受け取るのではなく育てる。だからといって、完璧を目指す必要はない。名刀を打つ必要はない。すべてを自作する必要もない。大事なのは、明日の開発で戦えること。そのために、今日少しだけ環境を良くする。その繰り返しがPDEだ。もし「自分で作ってみたい」という気持ちがあるなら、試してみてほしい。合わなかったら戻ればいい。IDEという最強の武器は、いつでもそこにある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。この記事で紹介した設定ファイルは以下のリポジトリで公開している。github.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Raycast Extension 開発のすすめ]]></title>
            <link>https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev</link>
            <guid isPermaLink="false">https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev</guid>
            <pubDate>Sat, 13 Dec 2025 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本記事は 3-shake Advent Calendar 2025 14日目の記事です。Raycast Advent Calendar 2025 でも2025年10月下旬に行われたRaycast Community Japan 主催イベントに3連続で参加した話を書きます。Raycast Extension開発やコミュニティに興味を持ったきっかけとなったイベントなので、よければ読んでください。この記事ではRaycast Extension をローカルで作ってStoreに出すまでの手順を解説します。 1. Extensionを作るべき理由 RaycastとはRaycast は...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[デタッチドマウントとコンテナランタイム]]></title>
            <link>https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7</link>
            <guid isPermaLink="false">https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7</guid>
            <pubDate>Sat, 13 Dec 2025 11:58:19 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ13日目の記事です。最近、低レベルコンテナランタイムである youki にコントリビュートしており、特にデタッチドマウントについて調べる機会があったので、その内容を共有しま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『おい、テックブログを書け』というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/13/145159</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/13/145159</guid>
            <pubDate>Sat, 13 Dec 2025 05:51:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに正直に言うと、私はキャリアの序盤、破滅的な文章を書く人間だった。誰が読むのか考えていない文章を書きまくっていた。学生時代に読書感想文のコンクールで優勝したこともなければ、文章を褒められた経験もほとんどない。それでも書き続けて、今はこうして登壇の機会をいただけるようになった。2025年12月5日、Forkwell Communityのイベント「おい、テックブログを書け」で登壇しました。forkwell.connpass.com発表資料はこちらです。 speakerdeck.com「おい、」シリーズがイベントになった私は「おい、」シリーズというブログを書いている。元々は書籍用に書き溜めていた文章を公開する場所として始めたものだが、ありがたいことに多くの反響をいただいている。syu-m-5151.hatenablog.com今回のイベントは、Forkwellのかわまたさんにお誘いいただいて実現した。かわまたさんには以前も「転職したらMCPサーバーだった件」というイベントでお声がけいただいた。 speakerdeck.com貴重な登壇の機会をいただいているのにこんなことを言うのはあれだが、結構変なことをさせてくれる。変な人だ（褒めている）。自分もこれぐらいふざけた企画をできるくらい組織で信用されたい。とめちゃくちゃに思う。こうした機会をもらえるのは、発信を続けてきたからだ。私よりエンジニアとしても語り手や書き手としても才能のある人はたくさんいる。でも、その才能を発揮せずに誰からも見つからないままでいる人も多い。なぜ発信しないのか。まず、炎上が怖い。間違ったことを書いたら叩かれるんじゃないか。知識不足を晒して恥をかくんじゃないか。そう思うと、公開ボタンを押す手が止まる。次に、時間がない。業務が終わってから記事を書くのは大変だ。言いたいことを整理して、文章にまとめて、推敲して。そこまでの気力が残っていない日も多い。組織の問題もある。評価制度が発信を評価しない会社では、ブログを書いても給料は上がらない。それどころか「そんな暇があったらコードを書け」と言われることもある。発信は「業務外の趣味」として扱われる。こうした障壁は確かに存在する。でも、それらすべてを解決してから書き始める必要はない。まず書いてみることなら、今日からでもできる。炎上が怖いなら、小さな技術メモから始めればいい。時間がないなら、完璧を目指さず短い記事でいい。組織が変わらなくても、自分のブログは自分で始められる。書き始めるとき、人は出発点ばかり気にしがちだ。「自分には文章の才能がない」「最初からうまく書ける人には敵わない」──そう思って発信をためらう人がいる。でも、書く力は後天的になんとかなる。出発点が低くても、続けていれば追いつける。追い越せることだってある。見てくれた皆さんには、発信やアウトプットを通じて才能を発揮し、それに見合った評価や機会を得てほしい。そう思って今回の登壇資料を作った。書くときに大切にしていること資料では「どう書くか」の型を紹介したが、その前提にある考え方も書いておきたい。私が意識しているのは3つある。「なぜ」を問うこと、「変化」を描くこと、「ゆらぎ」を残すこと。この3つは独立しているようで、実は重なり合っているので紹介していきたい。「なぜ」を問い続ける単なる事実や記録ではなく、理由や背景を深掘りする姿勢が大切だ。たとえば「Aを使った」だけでなく「なぜAを選んだのか」「なぜBではダメだったのか」を書く。読者が最も知りたいのは「なぜ」の部分だ。選択の理由を言語化することで、自分の理解も深まる。ところが、技術ブログでありがちなのは、手順だけを淡々と書いてしまうこと。「この設定を入れます」「このコマンドを実行します」──それだけでは公式ドキュメントの劣化コピーになる。「なぜこの設定なのか」「なぜこの順番なのか」「なぜ他の方法ではダメだったのか」を書くことで、初めて読む価値が生まれる。「なぜ？」の部分が業務事情に抵触する場合もある。具体的な数値や社内の意思決定プロセスは書けない。そういうときは、一般的な観点に置き換える工夫をすればいい。「弊社の事情で」ではなく「〇〇のようなケースでは」と書く。具体的な比較ができないなら「一般的にAとBにはこういう違いがある」と整理する。工夫次第で、機密を守りながら「なぜ」を伝える方法はいくらでもある。「なぜ？」を問い続けると、自分の理解の浅さに気づくこともある。それでいい。書くことは、自分の理解を試す行為でもある。書けないということは、わかっていないということだ。その気づきこそが成長の起点になる。「行動」と「変化」のあるストーリーにする「なぜ」を問い続けていると、自然と「変化」が見えてくる。最初はこう思っていた、でも調べていくうちにこう変わった。その変化こそが、記事の核になる。人は変化の物語に心を動かされる。問題に出会い、試行錯誤し、解決に至る。その過程で自分の理解がどう変わったか。「わからない」から「わかった」への変化こそが、読者にとって価値のある情報だ。だから、静的な情報の羅列は退屈だ。「Kubernetesのリソース制限には以下の種類があります」と書くより、「OOMKilledで3時間溶かした。原因を調べていくうちに、リソース制限の仕組みが腹落ちした」と書く方が読まれる。同じ情報でも、変化の物語として語ることで、読者は追体験できる。行動と変化を意識すると、自然と時系列が生まれる。最初に何を思っていたか、何をしたか、何が起きたか、どう理解が変わったか。この流れがあるだけで、記事は格段に読みやすくなる。そして、変化には「失敗」も含まれる。むしろ失敗からの学びの方が読者には刺さる。「最初からうまくいきました」という記事より、「こう考えて失敗し、別のアプローチで解決した」という記事の方が、読者の記憶に残る。失敗を隠さず、そこから何を学んだかを書くことで、記事に深みが出る。「気持ちのゆらぎ」を素直に残す失敗を書くとき、その時の迷いや不安も一緒に残しておくといい。整いすぎた文章は、かえって心に響かない。なぜか。人間味が消えてしまうからだ。「最初は〇〇だと思っていたけど、実際は違った」「正直、これでいいのか迷った」「ここは今でも自信がない」──そうした揺れを正直に書くことで、読者との距離が縮まる。完璧を装う必要はない。技術ブログを書くとき、つい「わかっている人」として振る舞いたくなる。でも、読者が共感するのは「わかっていなかった人がわかるようになる過程」だ。迷い、間違え、遠回りした経験こそが、読者にとって価値がある。気持ちのゆらぎを残すことには、もう1つ意味がある。後から読み返したとき、その時の自分に出会える。「あの頃はこんなことで悩んでいたのか」と思えるのは、整いすぎていない文章だからこそだ。ゆらぎを残すことに抵抗がある人もいるだろう。弱く見えるのではないか、と。でも私の考えは違う。ゆらぎを残すことは、弱さを見せることではない。誠実さを見せることだ。「これが正解です」と断言する記事より、「私はこう考えてこうした、でも別の方法もあるかもしれない」と書く記事の方が、読者は信頼する。技術の世界に絶対の正解は少ない。その不確かさに正直であることが、かえって記事の信頼性を高める。おわりに技術ブログを書くことは、自分の成長のためだ。「なぜ？」を問い続け、変化の物語として語り、気持ちのゆらぎを素直に残す。結果として、それが誰かを救うこともあるかもしれない。私自身がそうだった。冒頭で書いたように、私は「破滅的な文章を書く人間」だった。それでも書き続けて、今がある。苦手から逃げても、その先にあるのはまた別の苦手だ「文章が苦手だから書かない」「人前で話すのが苦手だから発信しない」──そう言って避け続ける人は多い。気持ちはわかる。苦手なことに向き合うのは辛い。できない自分を直視するのは苦しい。でも、逃げた先に何があるだろうか。苦手なことを避け続けても、人生から苦手がなくなるわけではない。文章から逃げれば、別の場面でまた「苦手」にぶつかる。逃げ続けた結果、選択肢がどんどん狭まっていく。気づいたときには、逃げ場すらなくなっている。いま苦手であることと、将来成果を出せるかどうかには、おそらく何の因果関係もない。初期能力が高い人が最終的に優れた成果を出すとは限らない。むしろ、最初から得意な人は壁にぶつかったとき折れやすい。苦手だった人の方が、泥臭く続ける力を持っていたりする。私は明らかに後者だった。最初からうまく書けたわけではない。読み返すと恥ずかしい文章をたくさん書いた。それでも書き続けた結果、今がある。出発点の低さは、到達点を決めない。「自分探し」という名の逃避「自分に向いていることを見つければ、苦労せずに成果が出る」──そんな幻想がある。「自分探し」という言葉は、その幻想を正当化する。本当の自分を見つければ、努力なしに輝ける場所がある。そう信じたい気持ちはわかる。でも、多くの場合それは苦手や欠損から逃れるための言い訳でしかない。向いていないから別のことを探す。それも向いていないから、また別のことを探す。その繰り返しで時間だけが過ぎていく。本当の自分は、探すものではない。目の前のことに向き合い、苦手なことに取り組み続ける中で、少しずつ形作られていくものだ。「これが自分だ」と思えるようになるのは、何かをやり抜いた後だ。やる前からわかるものではない。向いていることを探すより、目の前のことに向き合う方が、よほど確実に成長できる。向いているかどうかは、やってみなければわからない。やり続けてみなければわからない。最初の苦手意識だけで判断するのは、あまりに早すぎる。正しい方向に努力すれば、必ず上達するとはいえ、漫然と続けるだけでは上達しない。書くことと、うまくなることは、自動的にはつながらない。読者の反応を見る。うまい人の文章を読んで、何が違うのか考える。自分の過去記事を読み返して、恥ずかしくなる。そうやってフィードバックを受け取り、意識的に改善しようとすることで、少しずつ書けるようになる。大事なのは、フィードバックループを回すことだ。書く→反応を見る→改善点を見つける→また書く。このサイクルを回し続ければ、必ず上達する。才能の有無ではなく、このループを回し続けられるかどうかが、成長を決める。こう書くと「それは書けた側の言い分だ」と思う人もいるかもしれない。生存者バイアスじゃないか、と。確かにそうだ。書けなかった人の声は届かない。でも、だからこそ書けた側が伝えるしかない。書けないと思っている人、文章に自信がない人に、「それでも書ける」と伝えられるのは、同じ場所から歩いてきた人間だけだ。だから、今日からでも始めてほしい。まずは今日学んだこと、ハマったこと、気づいたことを3行だけ書いてみる。下書きのまま放置している記事があるなら、不完全でもいいから公開してみる。完璧を待っていたら、いつまでも始まらない。苦手だと思っていることほど、始めてしまえば案外なんとかなる。登壇・技術顧問のご依頼について登壇依頼はいつでも募集しています。今回のようなちょっと変わった企画でも大歓迎です。気軽にDMしてください。また、技術顧問業もやっています。SRE、プラットフォームエンジニアリング、組織づくりなど、雑多な質問でもお待ちしております。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA 認定資格奮闘記 ~Professional Agentic AI編~]]></title>
            <link>https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai</guid>
            <pubDate>Sat, 13 Dec 2025 05:21:28 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAの認定資格であるProfessional Agentic AIを取得したので、その内容を共有しようと思います。 Professional Agentic AIとは？Professional Agentic AI（以下、NCP-AAI）は、マルチエージェントインタラクションや分散推論、スケーラビリティ、倫理的セーフガードに重点を置き、高度なエージェントAIソリューションを設計、開発、展開、管理する能力を試される試験です。エージェント開発だけなくそのサービングやモニタリングなど、DevOpsやMLOpsに関わるような内容が網羅的に出されるのが特徴です。https:/...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[短編：ブログネタってどうやって探してる？お答えします]]></title>
            <link>https://zenn.dev/akasan/articles/blog_neta_howto</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/blog_neta_howto</guid>
            <pubDate>Fri, 12 Dec 2025 14:01:24 GMT</pubDate>
            <content:encoded><![CDATA[今回は短編です。のべ240日程度連日テックブログを書いている私ですが、どのようにネタを探しているのかを共有しようと思います。 そもそも何で毎日ブログ書いてるの？詳細は以下の記事にて共有していますが、今改めて毎日書いているモチベをまとめると以下になります。自分の技術に対する興味をせっかくなら発信したいそもそも三日坊主だったので、ちゃんと習慣化できるようになりたかった今更引けないw単純に楽しいhttps://zenn.dev/akasan/articles/4aba4d3a0616ce ネタの探し方私のブログではいくつかの要因によってネタが決まっています。選び方の順...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[専門家は話さないですよ(『専門家が「力」をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい』を読んで)]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/12/163220</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/12/163220</guid>
            <pubDate>Fri, 12 Dec 2025 07:32:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに正直に言う。この文章を書くかどうか、ずいぶん迷った。「専門家はもっと声を上げるべきだ」という意見に対して、「いや、話さないんですよ」と返すのは、なんだか後ろ向きに見えるかもしれない。諦めているように聞こえるかもしれない。そういう風に受け取られるのは、ちょっと嫌だな、と思った。でも、書くことにした。なぜなら、「話せばいいじゃん」「振りかざせばいいじゃん」という言葉に、ずっと違和感を抱えてきたからだ。その違和感の正体を、自分なりに言葉にしてみたかった。これは、専門家として組織の中で働いてきた、私個人の経験と考えだ。すべての人に当てはまるとは思わない。でも、同じような経験をしている人が、もしかしたらいるかもしれない。そういう人に届いたらいいな、と思いながら書いている。「専門性の刃で殴りかかってこい」への違和感「専門家が『力』をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい」という記事を読んだ。専門家はプロらしく専門知識を振りかざしてほしい。そこに忖度はいらない。殺す気でかかってきていい。言っていることが難しくて良い。専門家ってのは、そういうもんだろ、と。痛快だし、気持ちはわかる。専門家がセーブせずに力を振るえる組織という理想像は、多くのエンジニアやデザイナーが心の底で望んでいることだろう。その理想を堂々と語る姿勢には敬意を覚える。フジイさんの記事は、専門家の側に立って「もっと力を発揮していいんだ」と背中を押してくれる。それ自体は素晴らしいことだ。でも、私はこの説明に違和感がある。そして、専門家としては、そういう組織を期待して待っていても仕方ないと思っている。専門家は話さない。振りかざす以前の問題として、そもそも話さない。fujii-yuji.net話すことの面倒くささ専門家が話さない理由は、実はとても単純だ。面倒くさいのだ。自分の中にある専門的な知見を言葉にして口から出した瞬間、それは相手の解釈に委ねられる。どれだけ正確に伝えようとしても、相手の受け取り方は相手次第だ。ずれが生じる。これはいかなるコミュニケーションにおいても不可避だ。そして、ずれた理解に基づいて余計なことを言われる。「それってつまりこういうことですよね」と、全然違う解釈を返される。「でもそれって現実的じゃないですよね」と、文脈を無視した反論が来る。そのたびに「いや、そういうことではなくて」と釈明しなければならない。これが、本当に面倒くさい。だから専門家は話さない。話しても伝わらないし、伝わらなかったときの釈明が面倒くさいから。専門家の言葉が届かなくなるとき他にも組織の中で、専門家の言葉が届かなくなる瞬間がある。エンジニアが「この設計だと将来困ります」と言っても、「今はそれどころではない」と退けられる。デザイナーが「このUIは使いにくい」と指摘しても、「ユーザーは慣れる」と押し切られる。セキュリティの専門家が「この実装は危険です」と警告しても、「リリースを優先して」と言われる。なぜこうなるのか。専門家の意見と非専門家の意見が、同じ重みで扱われるからだ。あるいは、声の大きさや立場の強さで、専門家の意見が上書きされるからだ。「それはあなたの感想ですよね」と言われる。「他の見方もある」と言われる。正しいことを言っているのに、「意見の違い」として処理される。これは単なる無関心ではない。専門知への拒絶だ。専門家が何か言うと、面倒くさがられる。「また難しいことを言っている」「理想論だ」「現場を知らない」と思われる。そのうち、専門家の発言自体が疎まれるようになる。私はこれを「専門家の言葉が死ぬ瞬間」だと思っている。言葉が発せられても、届かない。届いても、受け止められない。受け止められても、行動に変わらない。そういう組織では、専門家は黙るようになる。分業が生む視野の狭さなぜこうなるのか。私なりに考えてみた。こんな経験がある。セキュリティの観点から「この実装は危険だ」と2回警告した。2回とも「リリースを優先して」と言われた。3回目は言わなかった。そして半年後、その実装が遠因でインシデントが起きた。「なぜ発生した」と言われた。言ったんだけどな、と思った。組織が大きくなると、分業が進む。営業、開発、デザイン、マーケティング。それぞれが専門性を高め、効率よく仕事を回せるようになる。これ自体は正しい。でも、分業には副作用がある。自分の担当範囲だけを見るようになる。隣のチームが何をしているか、知らなくても仕事は回る。全体像が見えなくなる。自分の視野がどんどん狭くなっていることに、気づかない。視野が狭くなると、判断がずれる。自分の担当範囲では正しいことが、全体で見ると間違っていることがある。でも、全体が見えないから、そのずれに気づけない。そして、何かを変えようとしても、壁にぶつかる。「それは私の管轄じゃない」「そっちのチームに言ってくれ」「今はそれどころじゃない」。組織の境界線が、行動を阻む。やがて、組織全体が「どうもうまくいっていない」と感じるようになる。でも、何が問題なのかがわからない。みんなが自分の持ち場で懸命に働いているのに、全体としては空回りしている。これが、ある程度成熟した組織が陥る罠だ。誰かが悪いわけではない。構造がそうさせている。話しても届かない構造この構造の中で、専門家はどうなるか。まず、自分の視野が狭くなっていることに気づかなくなる。自分の担当領域のことしか見えない。全体像が見えないから、自分の懸念が組織全体にとってどれだけ重要か、判断できない。「言っても仕方ない」と思ってしまう。次に、何か言っても壁にぶつかる経験を重ねる。「それは私の管轄ではない」「今はそれどころではない」と言われる。何度かそういう経験をすると、言うこと自体をやめる。学習性無力感だ。そして、本質的な問題を指摘しても、表面的な対応で済まされる。「技術的負債を返済しないと」と言っても、「今月のリリースが優先だ」と返される。根本的な問題が見えない組織では、根本的な指摘は届かない。専門家が話さないのは、怠けているからではない。プロ意識が低いからでもない。話しても届かない構造の中に置かれているからだ。何度も壁にぶつかって、学習した結果だ。専門家と非専門家の間にある溝専門家の言葉が届かないのは、誰かが悪いからではない。専門家は自分の領域を深く知っている。だからこそ、何が重要で何が危険かがわかる。でも、その「わかる」が、相手に伝わるとは限らない。非専門家には、非専門家の世界がある。締め切りがあり、予算があり、上からのプレッシャーがある。彼らは彼らなりに合理的に判断している。専門家の言うことが理解できないとき、「今は優先度が低い」と判断するのは、彼らにとっては当然のことだ。つまり、どちらも自分の世界では正しいことを言っている。問題は、それぞれの世界が交差しないことだ。専門家の「危険です」と、非専門家の「今はそれどころじゃない」が、同じ言語で話されているようで、まったく違う文脈に立っている。この溝を埋めるには、お互いの世界を理解しようとする努力がいる。でも、その努力には時間がかかる。そして、時間をかける余裕がない組織では、溝は埋まらないまま放置される。専門知識を振りかざしても、この溝は埋まらない。むしろ、溝を広げてしまうことさえある。「振りかざす」だけでは何も変わらないフジイさんは「専門知識を振りかざせ」と言う。力をセーブするな、忖度するな、と。気持ちはわかる。でも、私の経験では、振りかざしてもうまくいかなかった。専門家が強く主張すればするほど、相手は身構える。「また難しいことを言い始めた」「仕事を遅らせるつもりか」と思われる。こちらは正しいことを言っているつもりなのに、「面倒くさい人」として扱われる。そして、一度そういう印象を持たれると、次から話を聞いてもらえなくなる。「あの人はいつも理想論ばかり言う」というレッテルが貼られる。正しいことを言っているのに、聞いてもらえない。悪循環だ。振りかざすという態度は、相手に「自分の世界を押し付けられている」と感じさせる。人は押し付けられると、反発する。これは自然な反応だ。だから、振りかざしても状況は良くならない。むしろ、悪くなることのほうが多い。対話とは何かじゃあ、どうすればいいのか。私は「対話」だと思っている。ただし、ここで言う対話は「話し合う」という単純なものではない。対話とは、相手の世界に入っていくことだ。相手が何を見ているのか。何を気にしているのか。何を恐れているのか。どういうプレッシャーの中にいるのか。それを理解しようとすること。そして、理解した上で、相手の言葉で、相手の文脈で、自分の知っていることを伝えること。これは「振りかざす」とは正反対の態度だ。振りかざすとは、自分の世界から一歩も出ないまま、相手に自分の言葉を投げつけること。相手が理解できないなら、相手が悪い。対話とは、自分の世界を一度脇に置いて、相手の世界に足を踏み入れること。相手の言葉で考え、相手の文脈で説明する。これは、とても難しい。そして、とても面倒くさい。対話のコストを払える組織対話には膨大なコストがかかる。相手の世界を理解するために時間をかける。相手の言葉で説明するために言葉を選ぶ。ずれが生じたら、丁寧に修正する。誤解が生まれたら、根気強く解きほぐす。このコストを、組織が払えるかどうか。「今月のリリースが優先だ」「そんな時間はない」「とにかく早く作れ」という組織では、対話のコストは払えない。対話に時間をかける人は「仕事が遅い人」として評価を下げられる。対話のコストを払える組織とは、どういう組織か。意思決定のプロセスに専門家を巻き込む組織。評価制度が「言われたものを早く作る」ではなく「価値あるものを作る」を評価する組織。専門家の意見が「めんどくさいこと」ではなく「必要なこと」として扱われる組織。そして、相手の世界を理解しようとする姿勢が、当たり前のこととして共有されている組織。対立を放っておかない対立は放っておくと腐る。私自身、何度も失敗した。相手の話を遮って、自分の正しさを主張して、結局何も変わらなかった。そのたびに学んだのは、急いで反応しないことの価値だ。対立を放っておくと気まずさが積み重なる。仕事の判断がぶれ、人が協力しにくくなる。でも、対立が起きた瞬間に「正しさ」で押し切ろうとすると、もっと悪くなる。私はそれを何度も経験した。だから今は、衝突の場面では一度立ち止まるようにしている。相手の話を最後まで聞く。相手が何を恐れているのか、何を守ろうとしているのかを理解しようとする。それだけで、相手の硬さがゆるむことがある。争点をはっきりさせると、不要な言い合いが減る。「ここは合意できる」「ここは意見が違う」と整理するだけで、議論が前に進む。小さな合意を積み上げると、相手への不信が弱まる。これは言うのは簡単だが、やるのは難しい。私も何度も失敗した。でも、やる価値はある。専門家が話せる組織を作るというのは、対立を避けることではない。対立が起きたときに、それを丁寧に扱える組織を作ることだ。「あなたになら話したい」専門家が話すのは、話しても大丈夫だと思える相手に対してだけだ。自分の言葉が曲解されない。余計な解釈を加えられない。「そういうことではない」と釈明する必要がない。相手が自分の世界を理解しようとしてくれている。そういう相手に対してだけ、専門家は話す。「あなたになら話したい」——この感覚が、専門家に話をさせる。話すことのリスクでも、「あなたになら話したい」と思える相手は、実はとても少ない。専門家が話さないのは、構造の問題だけではない。話すこと自体に、あまりにもリスクがある。曲解される。余計なことを言われる。釈明が必要になる。プライドを刺激する。張り合われる。情報を軽々しく扱われる。他の人に言いふらされる。これだけのリスクを負って、それでも話す価値があるか。多くの場合、ない。だから専門家は黙る。専門知識を振りかざすどころか、そもそも口を開かない。コミュニケーションの不可避的なずれどれだけ丁寧に対話しても、ずれは生じる。私が話したい出来事が言葉となって口から出た時点で、それは私のものではなくなる。相手がどう受け取るかは、相手次第だ。これは、いかなるコミュニケーションにおいても不可避だ。だからこそ、対話のコストを払う意志があるかどうかが重要になる。ずれが生じたときに、「そういうことではない」と切り捨てるのではなく、「どうずれているのか」を一緒に探る。誤解が生まれたときに、「わかってないですね」と責めるのではなく、「どう誤解されたのか」を一緒に確認する。そして、聞いたことを軽々しく他の人に話さない。他者の情報を、自分の優越感のために消費しない。そのコストを払う意志があり、その倫理観を共有できる組織に対してだけ、専門家は話す。組織に期待しても仕方ない専門家が専門家としてリスペクトされる組織。フジイさんが描く理想は、私も心から望んでいる。でも、そういう組織を期待して待っていても、来ない。組織が変わるのを待っていたら、専門家は永遠に黙ったままだ。「いつか理解してくれる組織に出会えるはず」「いつかリスペクトされる日が来るはず」。そう思って待っていても、その日は来ない。だから、専門家の側から動くしかない。振りかざすのではなく、対話する。相手の世界に入っていく。相手の言葉で、相手の文脈で、自分の知っていることを伝える。面倒くさいけど、そのコストを自分から払う。組織が対話のコストを払ってくれるのを待つのではなく、自分から払う。相手が自分の世界を理解してくれるのを待つのではなく、自分から相手の世界を理解しにいく。これは不公平だ。専門家の側だけが努力するのはおかしい。でも、待っていても状況は変わらない。専門家に「振りかざせ」と言うのは、順番が逆だ。でも、「組織が変われ」と言うのも、期待しすぎだ。組織は簡単には変わらない。変わるのを待っていたら、自分が消耗するだけだ。だから、自分から動く。対話のコストを、自分から払う。専門家は話さない、でも専門家は話さない。話しても届かないから。話しても曲解されるから。話しても釈明が面倒くさいから。話したことを軽々しく扱われるから。他人を嫌いになりたくないから。専門家の言葉が届かなくなった組織では、専門家は黙る。それは怠慢ではない。何度も壁にぶつかった結果の、合理的な適応だ。でも、黙ったままでいいのか。フジイさんの理想は素晴らしい。専門家がリスペクトされる組織。専門家が力をセーブせずに振るえる組織。私もそういう組織で働きたい。でも、そういう組織を待っていても来ない。だから、自分から動くしかない。振りかざすのではなく、対話する。面倒くさいけど、相手の世界に入っていく。組織が変わるのを待つのではなく、自分から対話のコストを払う。「あなたになら話したい」——そう思ってもらえる相手に、自分からなる。組織に期待するのではなく、自分がその一人目になる。振りかざせと言う前に、自分から対話のコストを払う。それが、専門家として生き残る唯一の方法だと、私は思っている。私もまだ道半ばだ。何度も失敗するし、面倒くさいと思うこともある。でも、やるしかない。一緒にやっていこう。おわりにここまで書いてきて、ふと思う。結局、私は何を言いたかったんだろう。「専門家は話さない」という事実を伝えたかったのか。「組織に期待するな」と言いたかったのか。「自分から動け」と説教したかったのか。たぶん、どれでもない。私が本当に言いたかったのは、「話さないことを選んでいる自分を、責めなくていい」ということかもしれない。黙っているのは怠慢じゃない。何度も壁にぶつかって、学習した結果だ。それは合理的な適応だ。でも同時に、「黙ったままでいいのか」という問いも、ずっと抱えている。この矛盾を、私はまだ解決できていない。だから、「自分から対話のコストを払う」という答えを、自分自身に言い聞かせているのかもしれない。フジイさんの記事に対する反論というより、自分への言い訳、あるいは自分への励まし。そういう側面もあると思う。この文章を読んで、「わかる」と思ってくれた人がいたら嬉しい。「違う」と思った人もいるだろう。それでいい。ただ、もし同じような経験をして、同じように黙ることを選んでいる人がいたら、伝えたい。あなたは間違っていない。でも、黙ったままでいいのか、という問いは、たぶん消えない。その問いと一緒に、私はこれからも対話のコストを払い続けるんだと思う。面倒くさいけど。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Workstations入門: 安全かつ再現可能な開発環境の作り方]]></title>
            <link>https://qiita.com/aminevg/items/b953ae647c81eef59e95</link>
            <guid isPermaLink="false">https://qiita.com/aminevg/items/b953ae647c81eef59e95</guid>
            <pubDate>Thu, 11 Dec 2025 22:08:14 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2025 (12 日目) の投稿です。こんにちは！ スリーシェイクのイリドリシ愛民 (@realaminevg) です。最近は主にクライアントワークを行なっているため、セキュリティやオンボーディングを徹底する必...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA NeMo Agent Toolkitを使ってみた]]></title>
            <link>https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/</link>
            <guid isPermaLink="false">https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/</guid>
            <pubDate>Thu, 11 Dec 2025 13:35:36 GMT</pubDate>
            <content:encoded><![CDATA[概要 こんにちは佐藤慧太@SatohJohnです。 NVIDIA NeMo Agent Toolkit（以下、この記事ではNATと呼ぶことにします）は生成AIに関する様々なツール・フレームワーク・言語モデルを組み合わせて […]The post NVIDIA NeMo Agent Toolkitを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[登壇記録：NVIDIA NIMとNVIDAI NeMo Guardrailsの紹介]]></title>
            <link>https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann</guid>
            <pubDate>Thu, 11 Dec 2025 13:28:09 GMT</pubDate>
            <content:encoded><![CDATA[今回は本日以下のイベントで登壇しましたので、そちらの資料の共有と簡単な概要の共有になります。https://3-shake.connpass.com/event/373638/ 登壇資料の共有今回の登壇資料は以下のspeackerdeckにアップロードしておりますのでぜひご覧ください。 登壇内容今回の登壇では主に以下のトピックについて取り扱いました。NVIDIA NIMを用いた最適化された環境でのモデルのサービングについてgarakを用いたLLMの脆弱性診断NeMo Guardrailsを用いたLLMに対するガードレールの設定LLMをアプリケーションを組み込む...]]></content:encoded>
        </item>
    </channel>
</rss>